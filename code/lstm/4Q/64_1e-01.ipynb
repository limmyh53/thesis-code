{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Directories\n",
    "MODEL_FOLDER = \"../../../models/lstm/\"\n",
    "MODEL_FILENAME = MODEL_FOLDER + \"4Q/64_units/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: model saver\n",
    "def saveModel(sess, MODEL_FILENAME):\n",
    "    if not os.path.exists(MODEL_FOLDER):\n",
    "        print('Creating path where to save model: ' + MODEL_FOLDER)\n",
    "        os.mkdir(MODEL_FOLDER)\n",
    "\n",
    "    #print('Saving model at: ' + MODEL_FILENAME)\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, MODEL_FILENAME)\n",
    "    #print('Model successfully saved.\\n')\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: model loader\n",
    "def loadModel(sess, MODEL_FILENAME):\n",
    "    if os.path.exists(MODEL_FILENAME + \".index\"):\n",
    "        print('Loading save model from: ' + MODEL_FILENAME)\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, MODEL_FILENAME)\n",
    "        print('Model successfully loaded.\\n')\n",
    "        return True\n",
    "    else:\n",
    "        print('Model file <<' + MODEL_FILENAME + '>> does not exists!')\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Hyperparameters\n",
    "epochs = 500\n",
    "learning_rate = 1e-1\n",
    "batch_size = 5\n",
    "early_stop_iters = 10\n",
    "folds = 32\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 3  # data input\n",
    "n_steps = 4  # timesteps\n",
    "n_hidden = 64 # dimension of recurrent unit\n",
    "\n",
    "# (REPRODUCIBILITY) set random seeds\n",
    "tf.set_random_seed(123)\n",
    "\n",
    "# Define weights and biases\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.truncated_normal([n_hidden, 1], stddev = 1.0 / tf.sqrt(float(n_hidden))),\n",
    "        name='out_weight')\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.zeros([1]),\n",
    "        name='out_bias')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: Build model\n",
    "def RNN(X, weights, biases, n_hidden):\n",
    "\n",
    "    # Define a LSTM cell with tensorflow\n",
    "    lstm_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden, state_is_tuple=True)\n",
    "    outputs, _ = tf.nn.dynamic_rnn(lstm_cell, X, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    out_layer = tf.matmul(outputs[:,-1,:], weights['out']) + biases['out']\n",
    "\n",
    "    return out_layer\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: select batch\n",
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the data...\n",
      "Finished: data loaded. Stats below: \n",
      "Nr of training samples: 193\n",
      "Nr of testing  samples: 77\n",
      "Number of variables: 3\n",
      "Number of lags: 4\n",
      "Window length: 65\n",
      "Number of validation folds: 32\n"
     ]
    }
   ],
   "source": [
    "# =================================\n",
    "# 0. Load dataset\n",
    "# =================================\n",
    "print(\"Loading the data...\")\n",
    "# Training set pre-processing\n",
    "train = pd.read_csv('../../../Data/train.csv')\n",
    "train_4lag_inflation = np.array(train[['inflation.lag4',\n",
    "                                       'inflation.lag5',\n",
    "                                       'inflation.lag6',\n",
    "                                       'inflation.lag7']])\n",
    "train_4lag_unemp = np.array(train[['unemp.lag4',\n",
    "                                   'unemp.lag5',\n",
    "                                   'unemp.lag6',\n",
    "                                   'unemp.lag7']])\n",
    "train_4lag_oil = np.array(train[['oil.lag4',\n",
    "                                 'oil.lag5',\n",
    "                                 'oil.lag6',\n",
    "                                 'oil.lag7']])\n",
    "train_features = np.concatenate((train_4lag_inflation[:,:,np.newaxis], \n",
    "\t                             train_4lag_unemp[:,:,np.newaxis],\n",
    "\t                             train_4lag_oil[:,:,np.newaxis]),\n",
    "\t                             axis=2)\n",
    "train_target = np.array(train['inflation.target'])\n",
    "\n",
    "# Test set pre-processing\n",
    "test = pd.read_csv('../../../Data/test.csv')\n",
    "test_4lag_inflation = np.array(test[['inflation.lag4',\n",
    "                                     'inflation.lag5',\n",
    "                                     'inflation.lag6',\n",
    "                                     'inflation.lag7']])\n",
    "test_4lag_unemp = np.array(test[['unemp.lag4',\n",
    "                                 'unemp.lag5',\n",
    "                                 'unemp.lag6',\n",
    "                                 'unemp.lag7']])\n",
    "test_4lag_oil = np.array(test[['oil.lag4',\n",
    "                               'oil.lag5',\n",
    "                               'oil.lag6',\n",
    "                               'oil.lag7']])\n",
    "test_features = np.concatenate((test_4lag_inflation[:,:,np.newaxis], \n",
    "\t                            test_4lag_unemp[:,:,np.newaxis],\n",
    "\t                            test_4lag_oil[:,:,np.newaxis]),\n",
    "\t                            axis=2)\n",
    "test_target = np.array(test['inflation.target'])\n",
    "\n",
    "(nrTrainSamples, timesteps, variables) = train_features.shape\n",
    "(nrTestSamples, _, _) = test_features.shape\n",
    "\n",
    "# Window length and validation fold index\n",
    "window_length = 65\n",
    "valIndex = np.linspace(start=window_length, stop=nrTrainSamples, \n",
    "                       endpoint=True, num=folds+1, dtype=np.int)\n",
    "\n",
    "print(\"Finished: data loaded. Stats below: \")\n",
    "print(\"Nr of training samples: %d\" % nrTrainSamples)\n",
    "print(\"Nr of testing  samples: %d\" % nrTestSamples)\n",
    "print(\"Number of variables: %d\" % variables)\n",
    "print(\"Number of lags: %d\" % timesteps)\n",
    "print(\"Window length: %d\" % window_length)\n",
    "print(\"Number of validation folds: %d\" % folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 1. Build model\n",
    "# ==================================\n",
    "# tf graph input\n",
    "x = tf.placeholder(\"float\", [None, n_steps, n_input], name='Batch')\n",
    "y = tf.placeholder(\"float\", name='True_labels_of_batch')\n",
    "lr = tf.placeholder(\"float\", name='Learning_rate')\n",
    "\n",
    "# Make predictions with the model\n",
    "pred = RNN(x, weights, biases, n_hidden)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss = tf.reduce_mean(tf.diag_part(tf.square(tf.subtract(x=pred, y=y))))\n",
    "optimizer = tf.train.GradientDescentOptimizer(lr).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training \n",
      "Hyperparameters: \n",
      "Dimension of recurrent unit = 64 \n",
      "Learning rate = 0.1 \n",
      "Epochs = 500 \n",
      "Batch size = 5 \n",
      "Early stopping epochs = 10 \n",
      "Learning rate = 0.1\n",
      "Fold: 1  Epoch: 1  Training loss = 2.7365  Validation loss = 2.4219  \n",
      "\n",
      "Fold: 1  Epoch: 2  Training loss = 2.3319  Validation loss = 1.5513  \n",
      "\n",
      "Fold: 1  Epoch: 3  Training loss = 2.3656  Validation loss = 1.8716  \n",
      "\n",
      "Fold: 1  Epoch: 4  Training loss = 2.2604  Validation loss = 1.5052  \n",
      "\n",
      "Fold: 1  Epoch: 5  Training loss = 2.4201  Validation loss = 2.5755  \n",
      "\n",
      "Fold: 1  Epoch: 6  Training loss = 2.2380  Validation loss = 1.9982  \n",
      "\n",
      "Fold: 1  Epoch: 7  Training loss = 2.2896  Validation loss = 2.1628  \n",
      "\n",
      "Fold: 1  Epoch: 8  Training loss = 2.2992  Validation loss = 2.3249  \n",
      "\n",
      "Fold: 1  Epoch: 9  Training loss = 2.2436  Validation loss = 1.8046  \n",
      "\n",
      "Fold: 1  Epoch: 10  Training loss = 2.1580  Validation loss = 2.5906  \n",
      "\n",
      "Fold: 1  Epoch: 11  Training loss = 2.1854  Validation loss = 1.8434  \n",
      "\n",
      "Fold: 1  Epoch: 12  Training loss = 2.2446  Validation loss = 1.6871  \n",
      "\n",
      "Fold: 1  Epoch: 13  Training loss = 2.2307  Validation loss = 2.4422  \n",
      "\n",
      "Fold: 1  Epoch: 14  Training loss = 2.1672  Validation loss = 2.3003  \n",
      "\n",
      "Fold: 1  Epoch: 15  Training loss = 2.2986  Validation loss = 2.5115  \n",
      "\n",
      "Fold: 1  Epoch: 16  Training loss = 2.1866  Validation loss = 1.9185  \n",
      "\n",
      "Fold: 1  Epoch: 17  Training loss = 2.1585  Validation loss = 1.9013  \n",
      "\n",
      "Fold: 1  Epoch: 18  Training loss = 2.1695  Validation loss = 1.9912  \n",
      "\n",
      "Fold: 1  Epoch: 19  Training loss = 2.2389  Validation loss = 2.6653  \n",
      "\n",
      "Check model:  Fold: 1  Optimal epoch: 4  \n",
      "\n",
      "Fold: 2  Epoch: 1  Training loss = 2.1608  Validation loss = 2.3117  \n",
      "\n",
      "Fold: 2  Epoch: 2  Training loss = 2.1823  Validation loss = 2.3192  \n",
      "\n",
      "Fold: 2  Epoch: 3  Training loss = 2.1780  Validation loss = 2.4547  \n",
      "\n",
      "Fold: 2  Epoch: 4  Training loss = 2.2273  Validation loss = 2.5858  \n",
      "\n",
      "Fold: 2  Epoch: 5  Training loss = 2.3267  Validation loss = 2.2962  \n",
      "\n",
      "Fold: 2  Epoch: 6  Training loss = 2.1230  Validation loss = 1.8021  \n",
      "\n",
      "Fold: 2  Epoch: 7  Training loss = 2.1958  Validation loss = 2.2294  \n",
      "\n",
      "Fold: 2  Epoch: 8  Training loss = 2.5101  Validation loss = 1.9212  \n",
      "\n",
      "Fold: 2  Epoch: 9  Training loss = 2.0639  Validation loss = 2.2394  \n",
      "\n",
      "Fold: 2  Epoch: 10  Training loss = 2.0761  Validation loss = 2.0645  \n",
      "\n",
      "Fold: 2  Epoch: 11  Training loss = 2.1335  Validation loss = 1.9291  \n",
      "\n",
      "Fold: 2  Epoch: 12  Training loss = 4.4780  Validation loss = 1.6940  \n",
      "\n",
      "Fold: 2  Epoch: 13  Training loss = 2.1340  Validation loss = 2.1101  \n",
      "\n",
      "Fold: 2  Epoch: 14  Training loss = 2.1739  Validation loss = 1.9829  \n",
      "\n",
      "Fold: 2  Epoch: 15  Training loss = 2.1941  Validation loss = 2.1845  \n",
      "\n",
      "Fold: 2  Epoch: 16  Training loss = 2.3543  Validation loss = 2.4788  \n",
      "\n",
      "Check model:  Fold: 2  Optimal epoch: 12  \n",
      "\n",
      "Fold: 3  Epoch: 1  Training loss = 1.3545  Validation loss = 3.2396  \n",
      "\n",
      "Fold: 3  Epoch: 2  Training loss = 1.3124  Validation loss = 2.8965  \n",
      "\n",
      "Fold: 3  Epoch: 3  Training loss = 1.2955  Validation loss = 2.8574  \n",
      "\n",
      "Fold: 3  Epoch: 4  Training loss = 1.2962  Validation loss = 3.2301  \n",
      "\n",
      "Fold: 3  Epoch: 5  Training loss = 1.2787  Validation loss = 3.1751  \n",
      "\n",
      "Fold: 3  Epoch: 6  Training loss = 1.2803  Validation loss = 2.7555  \n",
      "\n",
      "Fold: 3  Epoch: 7  Training loss = 1.2341  Validation loss = 3.0332  \n",
      "\n",
      "Fold: 3  Epoch: 8  Training loss = 1.2193  Validation loss = 2.3890  \n",
      "\n",
      "Fold: 3  Epoch: 9  Training loss = 1.1988  Validation loss = 2.7595  \n",
      "\n",
      "Fold: 3  Epoch: 10  Training loss = 1.2435  Validation loss = 2.9856  \n",
      "\n",
      "Fold: 3  Epoch: 11  Training loss = 1.1899  Validation loss = 2.4086  \n",
      "\n",
      "Fold: 3  Epoch: 12  Training loss = 1.1527  Validation loss = 2.5292  \n",
      "\n",
      "Fold: 3  Epoch: 13  Training loss = 1.1549  Validation loss = 2.4019  \n",
      "\n",
      "Fold: 3  Epoch: 14  Training loss = 1.1952  Validation loss = 2.4592  \n",
      "\n",
      "Fold: 3  Epoch: 15  Training loss = 1.2526  Validation loss = 2.9768  \n",
      "\n",
      "Fold: 3  Epoch: 16  Training loss = 1.1994  Validation loss = 2.9578  \n",
      "\n",
      "Fold: 3  Epoch: 17  Training loss = 1.1567  Validation loss = 3.0059  \n",
      "\n",
      "Check model:  Fold: 3  Optimal epoch: 8  \n",
      "\n",
      "Fold: 4  Epoch: 1  Training loss = 1.2267  Validation loss = 3.4537  \n",
      "\n",
      "Fold: 4  Epoch: 2  Training loss = 1.2062  Validation loss = 2.6830  \n",
      "\n",
      "Fold: 4  Epoch: 3  Training loss = 1.1717  Validation loss = 3.1727  \n",
      "\n",
      "Fold: 4  Epoch: 4  Training loss = 1.1899  Validation loss = 2.3684  \n",
      "\n",
      "Fold: 4  Epoch: 5  Training loss = 1.1604  Validation loss = 3.0145  \n",
      "\n",
      "Fold: 4  Epoch: 6  Training loss = 1.1794  Validation loss = 3.1928  \n",
      "\n",
      "Fold: 4  Epoch: 7  Training loss = 1.0349  Validation loss = 2.5554  \n",
      "\n",
      "Fold: 4  Epoch: 8  Training loss = 1.0310  Validation loss = 2.0766  \n",
      "\n",
      "Fold: 4  Epoch: 9  Training loss = 1.0447  Validation loss = 2.6741  \n",
      "\n",
      "Fold: 4  Epoch: 10  Training loss = 1.0006  Validation loss = 2.1007  \n",
      "\n",
      "Fold: 4  Epoch: 11  Training loss = 1.0349  Validation loss = 2.4574  \n",
      "\n",
      "Fold: 4  Epoch: 12  Training loss = 1.0406  Validation loss = 2.3842  \n",
      "\n",
      "Fold: 4  Epoch: 13  Training loss = 1.0193  Validation loss = 2.1862  \n",
      "\n",
      "Fold: 4  Epoch: 14  Training loss = 1.1092  Validation loss = 2.1934  \n",
      "\n",
      "Fold: 4  Epoch: 15  Training loss = 0.9625  Validation loss = 2.4846  \n",
      "\n",
      "Fold: 4  Epoch: 16  Training loss = 0.9693  Validation loss = 2.4583  \n",
      "\n",
      "Fold: 4  Epoch: 17  Training loss = 0.9708  Validation loss = 2.3657  \n",
      "\n",
      "Fold: 4  Epoch: 18  Training loss = 0.9344  Validation loss = 2.7154  \n",
      "\n",
      "Check model:  Fold: 4  Optimal epoch: 8  \n",
      "\n",
      "Fold: 5  Epoch: 1  Training loss = 0.9431  Validation loss = 1.3106  \n",
      "\n",
      "Fold: 5  Epoch: 2  Training loss = 1.1068  Validation loss = 1.8246  \n",
      "\n",
      "Fold: 5  Epoch: 3  Training loss = 0.9514  Validation loss = 1.6902  \n",
      "\n",
      "Fold: 5  Epoch: 4  Training loss = 1.1344  Validation loss = 2.2403  \n",
      "\n",
      "Fold: 5  Epoch: 5  Training loss = 0.9495  Validation loss = 1.5896  \n",
      "\n",
      "Fold: 5  Epoch: 6  Training loss = 0.9260  Validation loss = 1.7674  \n",
      "\n",
      "Fold: 5  Epoch: 7  Training loss = 0.9085  Validation loss = 1.7024  \n",
      "\n",
      "Fold: 5  Epoch: 8  Training loss = 0.9173  Validation loss = 2.0277  \n",
      "\n",
      "Fold: 5  Epoch: 9  Training loss = 0.8786  Validation loss = 1.9425  \n",
      "\n",
      "Fold: 5  Epoch: 10  Training loss = 0.8869  Validation loss = 1.2779  \n",
      "\n",
      "Fold: 5  Epoch: 11  Training loss = 0.8800  Validation loss = 1.7045  \n",
      "\n",
      "Fold: 5  Epoch: 12  Training loss = 0.8784  Validation loss = 1.5483  \n",
      "\n",
      "Fold: 5  Epoch: 13  Training loss = 0.8584  Validation loss = 1.7336  \n",
      "\n",
      "Fold: 5  Epoch: 14  Training loss = 0.8817  Validation loss = 1.4717  \n",
      "\n",
      "Fold: 5  Epoch: 15  Training loss = 0.8448  Validation loss = 1.6132  \n",
      "\n",
      "Fold: 5  Epoch: 16  Training loss = 1.0234  Validation loss = 2.0666  \n",
      "\n",
      "Check model:  Fold: 5  Optimal epoch: 10  \n",
      "\n",
      "Fold: 6  Epoch: 1  Training loss = 0.9734  Validation loss = 1.4634  \n",
      "\n",
      "Fold: 6  Epoch: 2  Training loss = 1.0213  Validation loss = 1.5811  \n",
      "\n",
      "Fold: 6  Epoch: 3  Training loss = 1.0269  Validation loss = 1.5620  \n",
      "\n",
      "Fold: 6  Epoch: 4  Training loss = 0.9291  Validation loss = 1.5008  \n",
      "\n",
      "Fold: 6  Epoch: 5  Training loss = 1.0364  Validation loss = 2.1553  \n",
      "\n",
      "Fold: 6  Epoch: 6  Training loss = 0.9423  Validation loss = 1.5011  \n",
      "\n",
      "Fold: 6  Epoch: 7  Training loss = 0.8388  Validation loss = 1.4722  \n",
      "\n",
      "Fold: 6  Epoch: 8  Training loss = 0.9836  Validation loss = 1.3125  \n",
      "\n",
      "Fold: 6  Epoch: 9  Training loss = 0.8490  Validation loss = 1.7728  \n",
      "\n",
      "Fold: 6  Epoch: 10  Training loss = 0.8175  Validation loss = 1.7246  \n",
      "\n",
      "Fold: 6  Epoch: 11  Training loss = 0.9118  Validation loss = 1.5862  \n",
      "\n",
      "Fold: 6  Epoch: 12  Training loss = 0.9405  Validation loss = 1.4328  \n",
      "\n",
      "Fold: 6  Epoch: 13  Training loss = 0.8272  Validation loss = 1.4706  \n",
      "\n",
      "Fold: 6  Epoch: 14  Training loss = 0.8671  Validation loss = 1.4761  \n",
      "\n",
      "Fold: 6  Epoch: 15  Training loss = 0.8615  Validation loss = 1.5924  \n",
      "\n",
      "Fold: 6  Epoch: 16  Training loss = 0.8256  Validation loss = 1.7235  \n",
      "\n",
      "Fold: 6  Epoch: 17  Training loss = 0.8988  Validation loss = 1.4735  \n",
      "\n",
      "Fold: 6  Epoch: 18  Training loss = 0.8205  Validation loss = 1.5210  \n",
      "\n",
      "Fold: 6  Epoch: 19  Training loss = 0.8500  Validation loss = 1.4839  \n",
      "\n",
      "Fold: 6  Epoch: 20  Training loss = 0.8556  Validation loss = 1.5192  \n",
      "\n",
      "Fold: 6  Epoch: 21  Training loss = 0.8031  Validation loss = 1.7115  \n",
      "\n",
      "Fold: 6  Epoch: 22  Training loss = 0.7967  Validation loss = 1.4302  \n",
      "\n",
      "Fold: 6  Epoch: 23  Training loss = 1.0903  Validation loss = 1.6658  \n",
      "\n",
      "Fold: 6  Epoch: 24  Training loss = 0.7597  Validation loss = 1.7296  \n",
      "\n",
      "Check model:  Fold: 6  Optimal epoch: 8  \n",
      "\n",
      "Fold: 7  Epoch: 1  Training loss = 1.0621  Validation loss = 2.6793  \n",
      "\n",
      "Fold: 7  Epoch: 2  Training loss = 0.9479  Validation loss = 2.6382  \n",
      "\n",
      "Fold: 7  Epoch: 3  Training loss = 0.8729  Validation loss = 2.6056  \n",
      "\n",
      "Fold: 7  Epoch: 4  Training loss = 0.8626  Validation loss = 2.6917  \n",
      "\n",
      "Fold: 7  Epoch: 5  Training loss = 0.8825  Validation loss = 2.7403  \n",
      "\n",
      "Fold: 7  Epoch: 6  Training loss = 0.9391  Validation loss = 2.3291  \n",
      "\n",
      "Fold: 7  Epoch: 7  Training loss = 0.9470  Validation loss = 2.3309  \n",
      "\n",
      "Fold: 7  Epoch: 8  Training loss = 0.7962  Validation loss = 2.1007  \n",
      "\n",
      "Fold: 7  Epoch: 9  Training loss = 0.7927  Validation loss = 2.0929  \n",
      "\n",
      "Fold: 7  Epoch: 10  Training loss = 0.8210  Validation loss = 2.1720  \n",
      "\n",
      "Fold: 7  Epoch: 11  Training loss = 1.0895  Validation loss = 2.2404  \n",
      "\n",
      "Fold: 7  Epoch: 12  Training loss = 0.8266  Validation loss = 1.9801  \n",
      "\n",
      "Fold: 7  Epoch: 13  Training loss = 0.7964  Validation loss = 2.2004  \n",
      "\n",
      "Fold: 7  Epoch: 14  Training loss = 0.8026  Validation loss = 2.5073  \n",
      "\n",
      "Fold: 7  Epoch: 15  Training loss = 0.7384  Validation loss = 2.0620  \n",
      "\n",
      "Fold: 7  Epoch: 16  Training loss = 0.7738  Validation loss = 2.4331  \n",
      "\n",
      "Fold: 7  Epoch: 17  Training loss = 0.7085  Validation loss = 2.4172  \n",
      "\n",
      "Fold: 7  Epoch: 18  Training loss = 0.7241  Validation loss = 2.3564  \n",
      "\n",
      "Fold: 7  Epoch: 19  Training loss = 0.7097  Validation loss = 2.2846  \n",
      "\n",
      "Fold: 7  Epoch: 20  Training loss = 0.6677  Validation loss = 2.3562  \n",
      "\n",
      "Fold: 7  Epoch: 21  Training loss = 0.6726  Validation loss = 2.5352  \n",
      "\n",
      "Check model:  Fold: 7  Optimal epoch: 12  \n",
      "\n",
      "Fold: 8  Epoch: 1  Training loss = 0.9786  Validation loss = 8.2634  \n",
      "\n",
      "Fold: 8  Epoch: 2  Training loss = 0.9349  Validation loss = 7.6642  \n",
      "\n",
      "Fold: 8  Epoch: 3  Training loss = 0.8674  Validation loss = 7.0727  \n",
      "\n",
      "Fold: 8  Epoch: 4  Training loss = 0.8119  Validation loss = 7.1254  \n",
      "\n",
      "Fold: 8  Epoch: 5  Training loss = 0.7930  Validation loss = 7.7292  \n",
      "\n",
      "Fold: 8  Epoch: 6  Training loss = 0.8021  Validation loss = 7.4227  \n",
      "\n",
      "Fold: 8  Epoch: 7  Training loss = 0.7482  Validation loss = 7.8715  \n",
      "\n",
      "Fold: 8  Epoch: 8  Training loss = 0.8054  Validation loss = 7.7543  \n",
      "\n",
      "Fold: 8  Epoch: 9  Training loss = 0.7555  Validation loss = 7.6837  \n",
      "\n",
      "Fold: 8  Epoch: 10  Training loss = 0.7470  Validation loss = 7.4754  \n",
      "\n",
      "Fold: 8  Epoch: 11  Training loss = 0.8378  Validation loss = 7.6396  \n",
      "\n",
      "Fold: 8  Epoch: 12  Training loss = 0.8596  Validation loss = 8.0290  \n",
      "\n",
      "Check model:  Fold: 8  Optimal epoch: 3  \n",
      "\n",
      "Fold: 9  Epoch: 1  Training loss = 1.9246  Validation loss = 8.3988  \n",
      "\n",
      "Fold: 9  Epoch: 2  Training loss = 1.6510  Validation loss = 6.9876  \n",
      "\n",
      "Fold: 9  Epoch: 3  Training loss = 1.7716  Validation loss = 7.6530  \n",
      "\n",
      "Fold: 9  Epoch: 4  Training loss = 1.5468  Validation loss = 7.3553  \n",
      "\n",
      "Fold: 9  Epoch: 5  Training loss = 1.7265  Validation loss = 7.7736  \n",
      "\n",
      "Fold: 9  Epoch: 6  Training loss = 1.6939  Validation loss = 6.1766  \n",
      "\n",
      "Fold: 9  Epoch: 7  Training loss = 1.6682  Validation loss = 6.6646  \n",
      "\n",
      "Fold: 9  Epoch: 8  Training loss = 1.3970  Validation loss = 7.4962  \n",
      "\n",
      "Fold: 9  Epoch: 9  Training loss = 1.4181  Validation loss = 7.0298  \n",
      "\n",
      "Fold: 9  Epoch: 10  Training loss = 1.4841  Validation loss = 7.9943  \n",
      "\n",
      "Fold: 9  Epoch: 11  Training loss = 1.6126  Validation loss = 8.0172  \n",
      "\n",
      "Check model:  Fold: 9  Optimal epoch: 6  \n",
      "\n",
      "Fold: 10  Epoch: 1  Training loss = 2.1480  Validation loss = 5.8172  \n",
      "\n",
      "Fold: 10  Epoch: 2  Training loss = 2.1575  Validation loss = 6.2533  \n",
      "\n",
      "Fold: 10  Epoch: 3  Training loss = 2.3393  Validation loss = 6.1625  \n",
      "\n",
      "Fold: 10  Epoch: 4  Training loss = 2.3188  Validation loss = 5.3834  \n",
      "\n",
      "Fold: 10  Epoch: 5  Training loss = 2.6891  Validation loss = 6.4760  \n",
      "\n",
      "Fold: 10  Epoch: 6  Training loss = 2.3596  Validation loss = 4.4252  \n",
      "\n",
      "Fold: 10  Epoch: 7  Training loss = 2.1630  Validation loss = 6.5961  \n",
      "\n",
      "Fold: 10  Epoch: 8  Training loss = 1.9397  Validation loss = 5.1768  \n",
      "\n",
      "Fold: 10  Epoch: 9  Training loss = 1.9306  Validation loss = 5.7317  \n",
      "\n",
      "Fold: 10  Epoch: 10  Training loss = 1.8382  Validation loss = 5.6089  \n",
      "\n",
      "Fold: 10  Epoch: 11  Training loss = 1.9525  Validation loss = 5.4077  \n",
      "\n",
      "Fold: 10  Epoch: 12  Training loss = 1.7969  Validation loss = 5.6601  \n",
      "\n",
      "Fold: 10  Epoch: 13  Training loss = 2.3211  Validation loss = 6.0460  \n",
      "\n",
      "Fold: 10  Epoch: 14  Training loss = 1.9485  Validation loss = 5.3134  \n",
      "\n",
      "Fold: 10  Epoch: 15  Training loss = 1.7232  Validation loss = 4.8509  \n",
      "\n",
      "Fold: 10  Epoch: 16  Training loss = 1.6439  Validation loss = 4.8673  \n",
      "\n",
      "Fold: 10  Epoch: 17  Training loss = 1.7015  Validation loss = 5.1525  \n",
      "\n",
      "Fold: 10  Epoch: 18  Training loss = 1.7185  Validation loss = 4.9652  \n",
      "\n",
      "Fold: 10  Epoch: 19  Training loss = 1.5507  Validation loss = 5.2457  \n",
      "\n",
      "Fold: 10  Epoch: 20  Training loss = 1.5828  Validation loss = 4.9452  \n",
      "\n",
      "Fold: 10  Epoch: 21  Training loss = 1.6826  Validation loss = 5.3156  \n",
      "\n",
      "Fold: 10  Epoch: 22  Training loss = 1.6881  Validation loss = 5.7920  \n",
      "\n",
      "Fold: 10  Epoch: 23  Training loss = 1.7297  Validation loss = 5.3917  \n",
      "\n",
      "Fold: 10  Epoch: 24  Training loss = 1.7597  Validation loss = 5.0380  \n",
      "\n",
      "Fold: 10  Epoch: 25  Training loss = 1.7466  Validation loss = 5.2269  \n",
      "\n",
      "Fold: 10  Epoch: 26  Training loss = 1.5497  Validation loss = 4.9165  \n",
      "\n",
      "Fold: 10  Epoch: 27  Training loss = 1.3654  Validation loss = 4.3043  \n",
      "\n",
      "Fold: 10  Epoch: 28  Training loss = 1.5183  Validation loss = 5.0500  \n",
      "\n",
      "Fold: 10  Epoch: 29  Training loss = 1.6074  Validation loss = 5.3676  \n",
      "\n",
      "Fold: 10  Epoch: 30  Training loss = 1.6523  Validation loss = 3.6623  \n",
      "\n",
      "Fold: 10  Epoch: 31  Training loss = 1.5038  Validation loss = 4.4715  \n",
      "\n",
      "Fold: 10  Epoch: 32  Training loss = 1.7541  Validation loss = 4.5547  \n",
      "\n",
      "Fold: 10  Epoch: 33  Training loss = 1.8392  Validation loss = 4.1221  \n",
      "\n",
      "Fold: 10  Epoch: 34  Training loss = 1.4852  Validation loss = 4.6800  \n",
      "\n",
      "Fold: 10  Epoch: 35  Training loss = 1.5602  Validation loss = 4.2505  \n",
      "\n",
      "Fold: 10  Epoch: 36  Training loss = 1.5124  Validation loss = 4.1985  \n",
      "\n",
      "Fold: 10  Epoch: 37  Training loss = 1.3398  Validation loss = 4.2457  \n",
      "\n",
      "Fold: 10  Epoch: 38  Training loss = 1.3706  Validation loss = 3.9519  \n",
      "\n",
      "Fold: 10  Epoch: 39  Training loss = 1.8142  Validation loss = 3.8545  \n",
      "\n",
      "Fold: 10  Epoch: 40  Training loss = 1.3464  Validation loss = 3.8706  \n",
      "\n",
      "Fold: 10  Epoch: 41  Training loss = 1.8984  Validation loss = 4.0349  \n",
      "\n",
      "Fold: 10  Epoch: 42  Training loss = 1.4668  Validation loss = 4.2184  \n",
      "\n",
      "Fold: 10  Epoch: 43  Training loss = 1.6594  Validation loss = 3.7616  \n",
      "\n",
      "Fold: 10  Epoch: 44  Training loss = 1.3465  Validation loss = 4.4733  \n",
      "\n",
      "Check model:  Fold: 10  Optimal epoch: 30  \n",
      "\n",
      "Fold: 11  Epoch: 1  Training loss = 1.5056  Validation loss = 1.9245  \n",
      "\n",
      "Fold: 11  Epoch: 2  Training loss = 1.4002  Validation loss = 0.9354  \n",
      "\n",
      "Fold: 11  Epoch: 3  Training loss = 1.4468  Validation loss = 1.1738  \n",
      "\n",
      "Fold: 11  Epoch: 4  Training loss = 2.4379  Validation loss = 1.0651  \n",
      "\n",
      "Fold: 11  Epoch: 5  Training loss = 1.3928  Validation loss = 1.1483  \n",
      "\n",
      "Fold: 11  Epoch: 6  Training loss = 1.3444  Validation loss = 2.4929  \n",
      "\n",
      "Fold: 11  Epoch: 7  Training loss = 1.3249  Validation loss = 2.0002  \n",
      "\n",
      "Fold: 11  Epoch: 8  Training loss = 1.4728  Validation loss = 1.6251  \n",
      "\n",
      "Fold: 11  Epoch: 9  Training loss = 1.5010  Validation loss = 1.5663  \n",
      "\n",
      "Fold: 11  Epoch: 10  Training loss = 1.2640  Validation loss = 1.2980  \n",
      "\n",
      "Fold: 11  Epoch: 11  Training loss = 1.2826  Validation loss = 2.3169  \n",
      "\n",
      "Fold: 11  Epoch: 12  Training loss = 1.1992  Validation loss = 1.9633  \n",
      "\n",
      "Fold: 11  Epoch: 13  Training loss = 1.2527  Validation loss = 1.4808  \n",
      "\n",
      "Fold: 11  Epoch: 14  Training loss = 1.0331  Validation loss = 2.0373  \n",
      "\n",
      "Fold: 11  Epoch: 15  Training loss = 1.0912  Validation loss = 1.7631  \n",
      "\n",
      "Fold: 11  Epoch: 16  Training loss = 1.1085  Validation loss = 1.5298  \n",
      "\n",
      "Fold: 11  Epoch: 17  Training loss = 2.0307  Validation loss = 1.8800  \n",
      "\n",
      "Fold: 11  Epoch: 18  Training loss = 1.1059  Validation loss = 1.5600  \n",
      "\n",
      "Fold: 11  Epoch: 19  Training loss = 1.2187  Validation loss = 2.3366  \n",
      "\n",
      "Check model:  Fold: 11  Optimal epoch: 2  \n",
      "\n",
      "Fold: 12  Epoch: 1  Training loss = 1.1495  Validation loss = 2.3429  \n",
      "\n",
      "Fold: 12  Epoch: 2  Training loss = 1.3622  Validation loss = 4.3014  \n",
      "\n",
      "Fold: 12  Epoch: 3  Training loss = 1.5023  Validation loss = 4.2113  \n",
      "\n",
      "Fold: 12  Epoch: 4  Training loss = 1.4154  Validation loss = 2.5350  \n",
      "\n",
      "Fold: 12  Epoch: 5  Training loss = 1.3979  Validation loss = 1.6534  \n",
      "\n",
      "Fold: 12  Epoch: 6  Training loss = 1.2148  Validation loss = 2.1956  \n",
      "\n",
      "Fold: 12  Epoch: 7  Training loss = 1.4495  Validation loss = 2.3614  \n",
      "\n",
      "Fold: 12  Epoch: 8  Training loss = 1.2144  Validation loss = 1.8257  \n",
      "\n",
      "Fold: 12  Epoch: 9  Training loss = 1.1549  Validation loss = 1.6536  \n",
      "\n",
      "Fold: 12  Epoch: 10  Training loss = 1.2099  Validation loss = 1.5859  \n",
      "\n",
      "Fold: 12  Epoch: 11  Training loss = 1.2748  Validation loss = 2.0604  \n",
      "\n",
      "Fold: 12  Epoch: 12  Training loss = 1.1018  Validation loss = 1.9333  \n",
      "\n",
      "Fold: 12  Epoch: 13  Training loss = 1.2454  Validation loss = 2.5134  \n",
      "\n",
      "Fold: 12  Epoch: 14  Training loss = 1.0071  Validation loss = 2.3251  \n",
      "\n",
      "Fold: 12  Epoch: 15  Training loss = 0.9692  Validation loss = 1.5952  \n",
      "\n",
      "Fold: 12  Epoch: 16  Training loss = 1.1889  Validation loss = 2.6754  \n",
      "\n",
      "Check model:  Fold: 12  Optimal epoch: 10  \n",
      "\n",
      "Fold: 13  Epoch: 1  Training loss = 1.9530  Validation loss = 3.9759  \n",
      "\n",
      "Fold: 13  Epoch: 2  Training loss = 1.0264  Validation loss = 2.7955  \n",
      "\n",
      "Fold: 13  Epoch: 3  Training loss = 1.2673  Validation loss = 4.0465  \n",
      "\n",
      "Fold: 13  Epoch: 4  Training loss = 1.3176  Validation loss = 1.9072  \n",
      "\n",
      "Fold: 13  Epoch: 5  Training loss = 0.9752  Validation loss = 2.8448  \n",
      "\n",
      "Fold: 13  Epoch: 6  Training loss = 0.9087  Validation loss = 3.0308  \n",
      "\n",
      "Fold: 13  Epoch: 7  Training loss = 1.0176  Validation loss = 3.3779  \n",
      "\n",
      "Fold: 13  Epoch: 8  Training loss = 0.9329  Validation loss = 3.1300  \n",
      "\n",
      "Fold: 13  Epoch: 9  Training loss = 1.0568  Validation loss = 3.3818  \n",
      "\n",
      "Fold: 13  Epoch: 10  Training loss = 0.9274  Validation loss = 3.3106  \n",
      "\n",
      "Fold: 13  Epoch: 11  Training loss = 0.9949  Validation loss = 3.5429  \n",
      "\n",
      "Fold: 13  Epoch: 12  Training loss = 1.0475  Validation loss = 3.1955  \n",
      "\n",
      "Fold: 13  Epoch: 13  Training loss = 0.9035  Validation loss = 2.7248  \n",
      "\n",
      "Fold: 13  Epoch: 14  Training loss = 1.0930  Validation loss = 3.0299  \n",
      "\n",
      "Fold: 13  Epoch: 15  Training loss = 1.3351  Validation loss = 2.6178  \n",
      "\n",
      "Fold: 13  Epoch: 16  Training loss = 1.0334  Validation loss = 3.2419  \n",
      "\n",
      "Fold: 13  Epoch: 17  Training loss = 1.0143  Validation loss = 3.3997  \n",
      "\n",
      "Fold: 13  Epoch: 18  Training loss = 1.2244  Validation loss = 2.7853  \n",
      "\n",
      "Fold: 13  Epoch: 19  Training loss = 1.0664  Validation loss = 3.6710  \n",
      "\n",
      "Check model:  Fold: 13  Optimal epoch: 4  \n",
      "\n",
      "Fold: 14  Epoch: 1  Training loss = 1.8001  Validation loss = 5.4085  \n",
      "\n",
      "Fold: 14  Epoch: 2  Training loss = 1.3554  Validation loss = 5.6774  \n",
      "\n",
      "Fold: 14  Epoch: 3  Training loss = 1.6567  Validation loss = 7.2444  \n",
      "\n",
      "Fold: 14  Epoch: 4  Training loss = 1.2921  Validation loss = 5.7350  \n",
      "\n",
      "Fold: 14  Epoch: 5  Training loss = 1.4418  Validation loss = 6.9762  \n",
      "\n",
      "Fold: 14  Epoch: 6  Training loss = 1.1921  Validation loss = 6.5700  \n",
      "\n",
      "Fold: 14  Epoch: 7  Training loss = 1.5201  Validation loss = 7.4440  \n",
      "\n",
      "Fold: 14  Epoch: 8  Training loss = 1.1623  Validation loss = 6.3118  \n",
      "\n",
      "Fold: 14  Epoch: 9  Training loss = 1.4237  Validation loss = 5.7423  \n",
      "\n",
      "Fold: 14  Epoch: 10  Training loss = 1.1995  Validation loss = 6.1539  \n",
      "\n",
      "Fold: 14  Epoch: 11  Training loss = 1.4817  Validation loss = 5.4102  \n",
      "\n",
      "Fold: 14  Epoch: 12  Training loss = 1.2066  Validation loss = 6.3606  \n",
      "\n",
      "Fold: 14  Epoch: 13  Training loss = 1.2616  Validation loss = 6.6598  \n",
      "\n",
      "Fold: 14  Epoch: 14  Training loss = 1.1675  Validation loss = 6.4985  \n",
      "\n",
      "Fold: 14  Epoch: 15  Training loss = 1.3668  Validation loss = 5.6538  \n",
      "\n",
      "Fold: 14  Epoch: 16  Training loss = 1.1877  Validation loss = 6.1700  \n",
      "\n",
      "Fold: 14  Epoch: 17  Training loss = 1.4777  Validation loss = 4.9256  \n",
      "\n",
      "Fold: 14  Epoch: 18  Training loss = 1.2239  Validation loss = 5.8942  \n",
      "\n",
      "Fold: 14  Epoch: 19  Training loss = 1.1406  Validation loss = 6.2967  \n",
      "\n",
      "Fold: 14  Epoch: 20  Training loss = 1.3043  Validation loss = 5.7640  \n",
      "\n",
      "Fold: 14  Epoch: 21  Training loss = 1.2075  Validation loss = 6.3901  \n",
      "\n",
      "Fold: 14  Epoch: 22  Training loss = 1.2567  Validation loss = 6.4259  \n",
      "\n",
      "Fold: 14  Epoch: 23  Training loss = 1.3985  Validation loss = 6.0177  \n",
      "\n",
      "Fold: 14  Epoch: 24  Training loss = 1.4404  Validation loss = 6.9161  \n",
      "\n",
      "Check model:  Fold: 14  Optimal epoch: 17  \n",
      "\n",
      "Fold: 15  Epoch: 1  Training loss = 2.0293  Validation loss = 8.6986  \n",
      "\n",
      "Fold: 15  Epoch: 2  Training loss = 2.1634  Validation loss = 6.3581  \n",
      "\n",
      "Fold: 15  Epoch: 3  Training loss = 2.1281  Validation loss = 6.2317  \n",
      "\n",
      "Fold: 15  Epoch: 4  Training loss = 1.7311  Validation loss = 5.8449  \n",
      "\n",
      "Fold: 15  Epoch: 5  Training loss = 1.7679  Validation loss = 5.6424  \n",
      "\n",
      "Fold: 15  Epoch: 6  Training loss = 1.8047  Validation loss = 8.1157  \n",
      "\n",
      "Fold: 15  Epoch: 7  Training loss = 1.8129  Validation loss = 8.0964  \n",
      "\n",
      "Fold: 15  Epoch: 8  Training loss = 1.7708  Validation loss = 6.9205  \n",
      "\n",
      "Fold: 15  Epoch: 9  Training loss = 1.9726  Validation loss = 7.9405  \n",
      "\n",
      "Fold: 15  Epoch: 10  Training loss = 1.8350  Validation loss = 5.9824  \n",
      "\n",
      "Fold: 15  Epoch: 11  Training loss = 2.0566  Validation loss = 5.2528  \n",
      "\n",
      "Fold: 15  Epoch: 12  Training loss = 1.7292  Validation loss = 6.9892  \n",
      "\n",
      "Fold: 15  Epoch: 13  Training loss = 1.7237  Validation loss = 5.7641  \n",
      "\n",
      "Fold: 15  Epoch: 14  Training loss = 1.8005  Validation loss = 6.3689  \n",
      "\n",
      "Fold: 15  Epoch: 15  Training loss = 1.9860  Validation loss = 7.4071  \n",
      "\n",
      "Fold: 15  Epoch: 16  Training loss = 1.8308  Validation loss = 7.7712  \n",
      "\n",
      "Fold: 15  Epoch: 17  Training loss = 1.7141  Validation loss = 7.3328  \n",
      "\n",
      "Fold: 15  Epoch: 18  Training loss = 1.5561  Validation loss = 6.5897  \n",
      "\n",
      "Fold: 15  Epoch: 19  Training loss = 1.9502  Validation loss = 7.4634  \n",
      "\n",
      "Fold: 15  Epoch: 20  Training loss = 2.0809  Validation loss = 8.1321  \n",
      "\n",
      "Check model:  Fold: 15  Optimal epoch: 11  \n",
      "\n",
      "Fold: 16  Epoch: 1  Training loss = 2.3773  Validation loss = 3.9720  \n",
      "\n",
      "Fold: 16  Epoch: 2  Training loss = 2.5144  Validation loss = 5.0726  \n",
      "\n",
      "Fold: 16  Epoch: 3  Training loss = 3.4122  Validation loss = 2.2756  \n",
      "\n",
      "Fold: 16  Epoch: 4  Training loss = 2.7957  Validation loss = 6.2484  \n",
      "\n",
      "Fold: 16  Epoch: 5  Training loss = 2.7581  Validation loss = 5.3083  \n",
      "\n",
      "Fold: 16  Epoch: 6  Training loss = 2.5639  Validation loss = 5.5434  \n",
      "\n",
      "Fold: 16  Epoch: 7  Training loss = 2.3800  Validation loss = 2.9244  \n",
      "\n",
      "Fold: 16  Epoch: 8  Training loss = 2.3884  Validation loss = 2.9015  \n",
      "\n",
      "Fold: 16  Epoch: 9  Training loss = 2.5807  Validation loss = 4.6551  \n",
      "\n",
      "Fold: 16  Epoch: 10  Training loss = 3.5096  Validation loss = 6.2345  \n",
      "\n",
      "Fold: 16  Epoch: 11  Training loss = 2.4849  Validation loss = 5.4429  \n",
      "\n",
      "Fold: 16  Epoch: 12  Training loss = 2.5871  Validation loss = 3.4753  \n",
      "\n",
      "Fold: 16  Epoch: 13  Training loss = 2.8248  Validation loss = 2.8412  \n",
      "\n",
      "Fold: 16  Epoch: 14  Training loss = 2.7708  Validation loss = 6.0366  \n",
      "\n",
      "Fold: 16  Epoch: 15  Training loss = 2.6592  Validation loss = 5.1678  \n",
      "\n",
      "Fold: 16  Epoch: 16  Training loss = 3.2126  Validation loss = 3.4466  \n",
      "\n",
      "Fold: 16  Epoch: 17  Training loss = 2.6284  Validation loss = 3.7096  \n",
      "\n",
      "Fold: 16  Epoch: 18  Training loss = 2.6581  Validation loss = 4.8050  \n",
      "\n",
      "Fold: 16  Epoch: 19  Training loss = 2.7403  Validation loss = 4.6727  \n",
      "\n",
      "Fold: 16  Epoch: 20  Training loss = 2.9634  Validation loss = 2.7499  \n",
      "\n",
      "Fold: 16  Epoch: 21  Training loss = 3.2476  Validation loss = 3.3400  \n",
      "\n",
      "Fold: 16  Epoch: 22  Training loss = 4.3793  Validation loss = 4.3091  \n",
      "\n",
      "Fold: 16  Epoch: 23  Training loss = 3.1386  Validation loss = 3.8769  \n",
      "\n",
      "Fold: 16  Epoch: 24  Training loss = 2.8497  Validation loss = 4.1174  \n",
      "\n",
      "Fold: 16  Epoch: 25  Training loss = 2.8096  Validation loss = 3.7735  \n",
      "\n",
      "Fold: 16  Epoch: 26  Training loss = 2.6064  Validation loss = 3.1971  \n",
      "\n",
      "Fold: 16  Epoch: 27  Training loss = 2.7669  Validation loss = 2.9403  \n",
      "\n",
      "Fold: 16  Epoch: 28  Training loss = 2.6260  Validation loss = 1.9702  \n",
      "\n",
      "Fold: 16  Epoch: 29  Training loss = 2.8486  Validation loss = 4.1083  \n",
      "\n",
      "Fold: 16  Epoch: 30  Training loss = 3.3560  Validation loss = 4.4016  \n",
      "\n",
      "Check model:  Fold: 16  Optimal epoch: 28  \n",
      "\n",
      "Fold: 17  Epoch: 1  Training loss = 2.9452  Validation loss = 5.9369  \n",
      "\n",
      "Fold: 17  Epoch: 2  Training loss = 3.1051  Validation loss = 4.5130  \n",
      "\n",
      "Fold: 17  Epoch: 3  Training loss = 3.4631  Validation loss = 4.8496  \n",
      "\n",
      "Fold: 17  Epoch: 4  Training loss = 3.3846  Validation loss = 6.5395  \n",
      "\n",
      "Fold: 17  Epoch: 5  Training loss = 5.4238  Validation loss = 4.8836  \n",
      "\n",
      "Fold: 17  Epoch: 6  Training loss = 3.9116  Validation loss = 4.8784  \n",
      "\n",
      "Fold: 17  Epoch: 7  Training loss = 2.8769  Validation loss = 5.5913  \n",
      "\n",
      "Fold: 17  Epoch: 8  Training loss = 2.8270  Validation loss = 4.2405  \n",
      "\n",
      "Fold: 17  Epoch: 9  Training loss = 2.6922  Validation loss = 4.9318  \n",
      "\n",
      "Fold: 17  Epoch: 10  Training loss = 2.7878  Validation loss = 6.4856  \n",
      "\n",
      "Fold: 17  Epoch: 11  Training loss = 2.7391  Validation loss = 6.3922  \n",
      "\n",
      "Fold: 17  Epoch: 12  Training loss = 3.0092  Validation loss = 4.9756  \n",
      "\n",
      "Fold: 17  Epoch: 13  Training loss = 2.6593  Validation loss = 5.1649  \n",
      "\n",
      "Fold: 17  Epoch: 14  Training loss = 2.6453  Validation loss = 5.6284  \n",
      "\n",
      "Fold: 17  Epoch: 15  Training loss = 2.8036  Validation loss = 4.7388  \n",
      "\n",
      "Fold: 17  Epoch: 16  Training loss = 2.9015  Validation loss = 4.2487  \n",
      "\n",
      "Fold: 17  Epoch: 17  Training loss = 3.1680  Validation loss = 5.5936  \n",
      "\n",
      "Fold: 17  Epoch: 18  Training loss = 2.5845  Validation loss = 4.5264  \n",
      "\n",
      "Fold: 17  Epoch: 19  Training loss = 3.0679  Validation loss = 3.9599  \n",
      "\n",
      "Fold: 17  Epoch: 20  Training loss = 2.6577  Validation loss = 4.5797  \n",
      "\n",
      "Fold: 17  Epoch: 21  Training loss = 2.7968  Validation loss = 4.2438  \n",
      "\n",
      "Fold: 17  Epoch: 22  Training loss = 2.6855  Validation loss = 5.5789  \n",
      "\n",
      "Fold: 17  Epoch: 23  Training loss = 3.8915  Validation loss = 4.4627  \n",
      "\n",
      "Fold: 17  Epoch: 24  Training loss = 2.6828  Validation loss = 4.7722  \n",
      "\n",
      "Fold: 17  Epoch: 25  Training loss = 2.9042  Validation loss = 3.7809  \n",
      "\n",
      "Fold: 17  Epoch: 26  Training loss = 2.8009  Validation loss = 4.3149  \n",
      "\n",
      "Fold: 17  Epoch: 27  Training loss = 2.9337  Validation loss = 4.5347  \n",
      "\n",
      "Fold: 17  Epoch: 28  Training loss = 2.8192  Validation loss = 4.0239  \n",
      "\n",
      "Fold: 17  Epoch: 29  Training loss = 2.7038  Validation loss = 4.6810  \n",
      "\n",
      "Fold: 17  Epoch: 30  Training loss = 2.8084  Validation loss = 5.6948  \n",
      "\n",
      "Check model:  Fold: 17  Optimal epoch: 25  \n",
      "\n",
      "Fold: 18  Epoch: 1  Training loss = 3.0092  Validation loss = 3.5560  \n",
      "\n",
      "Fold: 18  Epoch: 2  Training loss = 4.7754  Validation loss = 3.2386  \n",
      "\n",
      "Fold: 18  Epoch: 3  Training loss = 3.5280  Validation loss = 1.9513  \n",
      "\n",
      "Fold: 18  Epoch: 4  Training loss = 3.0040  Validation loss = 1.6805  \n",
      "\n",
      "Fold: 18  Epoch: 5  Training loss = 3.7415  Validation loss = 2.9001  \n",
      "\n",
      "Fold: 18  Epoch: 6  Training loss = 3.1150  Validation loss = 1.9842  \n",
      "\n",
      "Fold: 18  Epoch: 7  Training loss = 2.9321  Validation loss = 1.5910  \n",
      "\n",
      "Fold: 18  Epoch: 8  Training loss = 2.9290  Validation loss = 1.1744  \n",
      "\n",
      "Fold: 18  Epoch: 9  Training loss = 2.8562  Validation loss = 2.0933  \n",
      "\n",
      "Fold: 18  Epoch: 10  Training loss = 2.9222  Validation loss = 1.6996  \n",
      "\n",
      "Fold: 18  Epoch: 11  Training loss = 3.1340  Validation loss = 2.1896  \n",
      "\n",
      "Fold: 18  Epoch: 12  Training loss = 3.0005  Validation loss = 1.9086  \n",
      "\n",
      "Fold: 18  Epoch: 13  Training loss = 3.3123  Validation loss = 2.0853  \n",
      "\n",
      "Fold: 18  Epoch: 14  Training loss = 2.8100  Validation loss = 1.6290  \n",
      "\n",
      "Fold: 18  Epoch: 15  Training loss = 3.3755  Validation loss = 2.0391  \n",
      "\n",
      "Fold: 18  Epoch: 16  Training loss = 2.8529  Validation loss = 1.5343  \n",
      "\n",
      "Fold: 18  Epoch: 17  Training loss = 3.2659  Validation loss = 1.8039  \n",
      "\n",
      "Fold: 18  Epoch: 18  Training loss = 2.9328  Validation loss = 1.4447  \n",
      "\n",
      "Fold: 18  Epoch: 19  Training loss = 3.0248  Validation loss = 2.0491  \n",
      "\n",
      "Fold: 18  Epoch: 20  Training loss = 2.8956  Validation loss = 1.3006  \n",
      "\n",
      "Fold: 18  Epoch: 21  Training loss = 3.1744  Validation loss = 1.5348  \n",
      "\n",
      "Fold: 18  Epoch: 22  Training loss = 3.0466  Validation loss = 1.3295  \n",
      "\n",
      "Fold: 18  Epoch: 23  Training loss = 2.8672  Validation loss = 1.4351  \n",
      "\n",
      "Fold: 18  Epoch: 24  Training loss = 2.7164  Validation loss = 1.7835  \n",
      "\n",
      "Fold: 18  Epoch: 25  Training loss = 2.8599  Validation loss = 2.2409  \n",
      "\n",
      "Check model:  Fold: 18  Optimal epoch: 8  \n",
      "\n",
      "Fold: 19  Epoch: 1  Training loss = 3.1604  Validation loss = 2.3172  \n",
      "\n",
      "Fold: 19  Epoch: 2  Training loss = 3.1255  Validation loss = 3.6218  \n",
      "\n",
      "Fold: 19  Epoch: 3  Training loss = 3.5732  Validation loss = 4.0769  \n",
      "\n",
      "Fold: 19  Epoch: 4  Training loss = 2.7778  Validation loss = 2.0446  \n",
      "\n",
      "Fold: 19  Epoch: 5  Training loss = 2.8370  Validation loss = 2.2728  \n",
      "\n",
      "Fold: 19  Epoch: 6  Training loss = 3.3243  Validation loss = 1.2439  \n",
      "\n",
      "Fold: 19  Epoch: 7  Training loss = 3.3944  Validation loss = 1.0254  \n",
      "\n",
      "Fold: 19  Epoch: 8  Training loss = 4.9740  Validation loss = 4.3007  \n",
      "\n",
      "Fold: 19  Epoch: 9  Training loss = 3.1308  Validation loss = 2.7909  \n",
      "\n",
      "Fold: 19  Epoch: 10  Training loss = 2.8193  Validation loss = 2.0528  \n",
      "\n",
      "Fold: 19  Epoch: 11  Training loss = 3.6164  Validation loss = 2.0511  \n",
      "\n",
      "Fold: 19  Epoch: 12  Training loss = 3.1971  Validation loss = 2.0358  \n",
      "\n",
      "Fold: 19  Epoch: 13  Training loss = 4.1993  Validation loss = 2.9174  \n",
      "\n",
      "Fold: 19  Epoch: 14  Training loss = 3.0890  Validation loss = 2.4016  \n",
      "\n",
      "Fold: 19  Epoch: 15  Training loss = 2.6869  Validation loss = 1.5836  \n",
      "\n",
      "Fold: 19  Epoch: 16  Training loss = 2.9485  Validation loss = 1.6829  \n",
      "\n",
      "Fold: 19  Epoch: 17  Training loss = 2.6287  Validation loss = 1.8799  \n",
      "\n",
      "Fold: 19  Epoch: 18  Training loss = 2.6345  Validation loss = 1.9202  \n",
      "\n",
      "Fold: 19  Epoch: 19  Training loss = 2.7666  Validation loss = 2.1585  \n",
      "\n",
      "Fold: 19  Epoch: 20  Training loss = 2.7425  Validation loss = 2.0341  \n",
      "\n",
      "Fold: 19  Epoch: 21  Training loss = 2.8161  Validation loss = 1.3609  \n",
      "\n",
      "Fold: 19  Epoch: 22  Training loss = 2.8464  Validation loss = 2.1468  \n",
      "\n",
      "Fold: 19  Epoch: 23  Training loss = 2.9819  Validation loss = 1.7763  \n",
      "\n",
      "Fold: 19  Epoch: 24  Training loss = 3.1001  Validation loss = 2.0205  \n",
      "\n",
      "Fold: 19  Epoch: 25  Training loss = 2.9219  Validation loss = 2.1787  \n",
      "\n",
      "Check model:  Fold: 19  Optimal epoch: 7  \n",
      "\n",
      "Fold: 20  Epoch: 1  Training loss = 2.8174  Validation loss = 3.5235  \n",
      "\n",
      "Fold: 20  Epoch: 2  Training loss = 2.7603  Validation loss = 3.3603  \n",
      "\n",
      "Fold: 20  Epoch: 3  Training loss = 3.0351  Validation loss = 3.3149  \n",
      "\n",
      "Fold: 20  Epoch: 4  Training loss = 2.8126  Validation loss = 3.5993  \n",
      "\n",
      "Fold: 20  Epoch: 5  Training loss = 3.3304  Validation loss = 2.6879  \n",
      "\n",
      "Fold: 20  Epoch: 6  Training loss = 2.8632  Validation loss = 3.6496  \n",
      "\n",
      "Fold: 20  Epoch: 7  Training loss = 3.1647  Validation loss = 4.8660  \n",
      "\n",
      "Fold: 20  Epoch: 8  Training loss = 2.8105  Validation loss = 3.4441  \n",
      "\n",
      "Fold: 20  Epoch: 9  Training loss = 3.2508  Validation loss = 3.7245  \n",
      "\n",
      "Fold: 20  Epoch: 10  Training loss = 3.1255  Validation loss = 2.8142  \n",
      "\n",
      "Fold: 20  Epoch: 11  Training loss = 3.4553  Validation loss = 3.1556  \n",
      "\n",
      "Fold: 20  Epoch: 12  Training loss = 3.6826  Validation loss = 2.3170  \n",
      "\n",
      "Fold: 20  Epoch: 13  Training loss = 3.0990  Validation loss = 3.8522  \n",
      "\n",
      "Fold: 20  Epoch: 14  Training loss = 2.9173  Validation loss = 4.3643  \n",
      "\n",
      "Fold: 20  Epoch: 15  Training loss = 2.8289  Validation loss = 3.9460  \n",
      "\n",
      "Fold: 20  Epoch: 16  Training loss = 2.6825  Validation loss = 3.8410  \n",
      "\n",
      "Fold: 20  Epoch: 17  Training loss = 3.0566  Validation loss = 4.5484  \n",
      "\n",
      "Check model:  Fold: 20  Optimal epoch: 12  \n",
      "\n",
      "Fold: 21  Epoch: 1  Training loss = 3.1519  Validation loss = 4.8666  \n",
      "\n",
      "Fold: 21  Epoch: 2  Training loss = 3.0766  Validation loss = 5.6904  \n",
      "\n",
      "Fold: 21  Epoch: 3  Training loss = 2.9078  Validation loss = 5.7594  \n",
      "\n",
      "Fold: 21  Epoch: 4  Training loss = 3.0909  Validation loss = 5.4087  \n",
      "\n",
      "Fold: 21  Epoch: 5  Training loss = 3.0234  Validation loss = 5.4188  \n",
      "\n",
      "Fold: 21  Epoch: 6  Training loss = 2.9982  Validation loss = 4.4977  \n",
      "\n",
      "Fold: 21  Epoch: 7  Training loss = 2.8187  Validation loss = 4.3830  \n",
      "\n",
      "Fold: 21  Epoch: 8  Training loss = 2.8098  Validation loss = 4.0031  \n",
      "\n",
      "Fold: 21  Epoch: 9  Training loss = 2.8948  Validation loss = 4.0356  \n",
      "\n",
      "Fold: 21  Epoch: 10  Training loss = 3.0420  Validation loss = 5.1042  \n",
      "\n",
      "Fold: 21  Epoch: 11  Training loss = 3.0942  Validation loss = 5.8007  \n",
      "\n",
      "Check model:  Fold: 21  Optimal epoch: 8  \n",
      "\n",
      "Fold: 22  Epoch: 1  Training loss = 2.9619  Validation loss = 2.6836  \n",
      "\n",
      "Fold: 22  Epoch: 2  Training loss = 3.1104  Validation loss = 3.1057  \n",
      "\n",
      "Fold: 22  Epoch: 3  Training loss = 2.7538  Validation loss = 1.5669  \n",
      "\n",
      "Fold: 22  Epoch: 4  Training loss = 2.7678  Validation loss = 1.2278  \n",
      "\n",
      "Fold: 22  Epoch: 5  Training loss = 2.8489  Validation loss = 1.9100  \n",
      "\n",
      "Fold: 22  Epoch: 6  Training loss = 2.6592  Validation loss = 1.5901  \n",
      "\n",
      "Fold: 22  Epoch: 7  Training loss = 2.6340  Validation loss = 2.0580  \n",
      "\n",
      "Fold: 22  Epoch: 8  Training loss = 2.8350  Validation loss = 2.4388  \n",
      "\n",
      "Fold: 22  Epoch: 9  Training loss = 2.5547  Validation loss = 1.8946  \n",
      "\n",
      "Fold: 22  Epoch: 10  Training loss = 2.6026  Validation loss = 2.6399  \n",
      "\n",
      "Fold: 22  Epoch: 11  Training loss = 2.6224  Validation loss = 2.0606  \n",
      "\n",
      "Fold: 22  Epoch: 12  Training loss = 3.1155  Validation loss = 1.8695  \n",
      "\n",
      "Fold: 22  Epoch: 13  Training loss = 2.7374  Validation loss = 2.7214  \n",
      "\n",
      "Check model:  Fold: 22  Optimal epoch: 4  \n",
      "\n",
      "Fold: 23  Epoch: 1  Training loss = 2.7102  Validation loss = 4.5577  \n",
      "\n",
      "Fold: 23  Epoch: 2  Training loss = 2.6234  Validation loss = 3.8530  \n",
      "\n",
      "Fold: 23  Epoch: 3  Training loss = 2.6234  Validation loss = 3.5336  \n",
      "\n",
      "Fold: 23  Epoch: 4  Training loss = 2.5305  Validation loss = 4.3441  \n",
      "\n",
      "Fold: 23  Epoch: 5  Training loss = 2.4414  Validation loss = 2.5881  \n",
      "\n",
      "Fold: 23  Epoch: 6  Training loss = 2.7669  Validation loss = 2.7068  \n",
      "\n",
      "Fold: 23  Epoch: 7  Training loss = 2.7979  Validation loss = 3.6502  \n",
      "\n",
      "Fold: 23  Epoch: 8  Training loss = 2.5362  Validation loss = 4.1658  \n",
      "\n",
      "Fold: 23  Epoch: 9  Training loss = 2.3782  Validation loss = 3.5160  \n",
      "\n",
      "Fold: 23  Epoch: 10  Training loss = 3.2142  Validation loss = 5.2767  \n",
      "\n",
      "Fold: 23  Epoch: 11  Training loss = 2.4813  Validation loss = 3.5284  \n",
      "\n",
      "Fold: 23  Epoch: 12  Training loss = 2.4729  Validation loss = 3.8352  \n",
      "\n",
      "Fold: 23  Epoch: 13  Training loss = 3.0935  Validation loss = 5.0186  \n",
      "\n",
      "Fold: 23  Epoch: 14  Training loss = 2.6413  Validation loss = 3.4372  \n",
      "\n",
      "Fold: 23  Epoch: 15  Training loss = 3.1570  Validation loss = 1.7336  \n",
      "\n",
      "Fold: 23  Epoch: 16  Training loss = 2.5423  Validation loss = 2.6953  \n",
      "\n",
      "Fold: 23  Epoch: 17  Training loss = 2.6083  Validation loss = 4.6948  \n",
      "\n",
      "Fold: 23  Epoch: 18  Training loss = 2.1947  Validation loss = 3.0899  \n",
      "\n",
      "Fold: 23  Epoch: 19  Training loss = 2.1988  Validation loss = 3.1686  \n",
      "\n",
      "Fold: 23  Epoch: 20  Training loss = 2.5051  Validation loss = 2.3365  \n",
      "\n",
      "Fold: 23  Epoch: 21  Training loss = 2.2668  Validation loss = 3.3205  \n",
      "\n",
      "Fold: 23  Epoch: 22  Training loss = 2.4080  Validation loss = 4.0249  \n",
      "\n",
      "Fold: 23  Epoch: 23  Training loss = 2.5834  Validation loss = 2.6697  \n",
      "\n",
      "Fold: 23  Epoch: 24  Training loss = 2.3309  Validation loss = 3.4121  \n",
      "\n",
      "Fold: 23  Epoch: 25  Training loss = 2.2240  Validation loss = 3.7206  \n",
      "\n",
      "Fold: 23  Epoch: 26  Training loss = 2.2403  Validation loss = 4.0633  \n",
      "\n",
      "Fold: 23  Epoch: 27  Training loss = 2.4263  Validation loss = 4.8916  \n",
      "\n",
      "Check model:  Fold: 23  Optimal epoch: 15  \n",
      "\n",
      "Fold: 24  Epoch: 1  Training loss = 2.2696  Validation loss = 1.0487  \n",
      "\n",
      "Fold: 24  Epoch: 2  Training loss = 2.1810  Validation loss = 1.9997  \n",
      "\n",
      "Fold: 24  Epoch: 3  Training loss = 2.1866  Validation loss = 1.4545  \n",
      "\n",
      "Fold: 24  Epoch: 4  Training loss = 2.4000  Validation loss = 1.7094  \n",
      "\n",
      "Fold: 24  Epoch: 5  Training loss = 3.0262  Validation loss = 3.4134  \n",
      "\n",
      "Fold: 24  Epoch: 6  Training loss = 2.3748  Validation loss = 1.5215  \n",
      "\n",
      "Fold: 24  Epoch: 7  Training loss = 2.2963  Validation loss = 1.8051  \n",
      "\n",
      "Fold: 24  Epoch: 8  Training loss = 2.8276  Validation loss = 2.0941  \n",
      "\n",
      "Fold: 24  Epoch: 9  Training loss = 2.3234  Validation loss = 1.1167  \n",
      "\n",
      "Fold: 24  Epoch: 10  Training loss = 2.1971  Validation loss = 1.6601  \n",
      "\n",
      "Fold: 24  Epoch: 11  Training loss = 2.2751  Validation loss = 1.7479  \n",
      "\n",
      "Fold: 24  Epoch: 12  Training loss = 2.2600  Validation loss = 1.6248  \n",
      "\n",
      "Fold: 24  Epoch: 13  Training loss = 2.4142  Validation loss = 1.8360  \n",
      "\n",
      "Fold: 24  Epoch: 14  Training loss = 2.5318  Validation loss = 1.1604  \n",
      "\n",
      "Fold: 24  Epoch: 15  Training loss = 2.5851  Validation loss = 1.2132  \n",
      "\n",
      "Fold: 24  Epoch: 16  Training loss = 2.7415  Validation loss = 0.9113  \n",
      "\n",
      "Fold: 24  Epoch: 17  Training loss = 2.3355  Validation loss = 0.6881  \n",
      "\n",
      "Fold: 24  Epoch: 18  Training loss = 2.5782  Validation loss = 1.2776  \n",
      "\n",
      "Fold: 24  Epoch: 19  Training loss = 2.4522  Validation loss = 0.7539  \n",
      "\n",
      "Fold: 24  Epoch: 20  Training loss = 2.4194  Validation loss = 0.9644  \n",
      "\n",
      "Fold: 24  Epoch: 21  Training loss = 2.3253  Validation loss = 1.3417  \n",
      "\n",
      "Fold: 24  Epoch: 22  Training loss = 2.4799  Validation loss = 1.3630  \n",
      "\n",
      "Fold: 24  Epoch: 23  Training loss = 3.0026  Validation loss = 2.2497  \n",
      "\n",
      "Check model:  Fold: 24  Optimal epoch: 17  \n",
      "\n",
      "Fold: 25  Epoch: 1  Training loss = 2.6624  Validation loss = 1.8854  \n",
      "\n",
      "Fold: 25  Epoch: 2  Training loss = 2.5166  Validation loss = 2.4830  \n",
      "\n",
      "Fold: 25  Epoch: 3  Training loss = 2.2626  Validation loss = 2.4518  \n",
      "\n",
      "Fold: 25  Epoch: 4  Training loss = 2.4287  Validation loss = 2.9411  \n",
      "\n",
      "Fold: 25  Epoch: 5  Training loss = 2.1981  Validation loss = 2.9882  \n",
      "\n",
      "Fold: 25  Epoch: 6  Training loss = 3.0516  Validation loss = 5.0345  \n",
      "\n",
      "Fold: 25  Epoch: 7  Training loss = 2.3372  Validation loss = 2.4845  \n",
      "\n",
      "Fold: 25  Epoch: 8  Training loss = 4.1721  Validation loss = 2.9575  \n",
      "\n",
      "Fold: 25  Epoch: 9  Training loss = 2.5407  Validation loss = 2.5588  \n",
      "\n",
      "Fold: 25  Epoch: 10  Training loss = 2.4861  Validation loss = 1.8942  \n",
      "\n",
      "Fold: 25  Epoch: 11  Training loss = 2.4195  Validation loss = 1.4375  \n",
      "\n",
      "Fold: 25  Epoch: 12  Training loss = 2.3691  Validation loss = 1.4645  \n",
      "\n",
      "Fold: 25  Epoch: 13  Training loss = 2.2572  Validation loss = 1.9485  \n",
      "\n",
      "Fold: 25  Epoch: 14  Training loss = 2.4550  Validation loss = 2.8889  \n",
      "\n",
      "Fold: 25  Epoch: 15  Training loss = 2.3689  Validation loss = 2.6189  \n",
      "\n",
      "Fold: 25  Epoch: 16  Training loss = 2.7924  Validation loss = 4.1824  \n",
      "\n",
      "Check model:  Fold: 25  Optimal epoch: 11  \n",
      "\n",
      "Fold: 26  Epoch: 1  Training loss = 2.5270  Validation loss = 1.3075  \n",
      "\n",
      "Fold: 26  Epoch: 2  Training loss = 2.4330  Validation loss = 3.6822  \n",
      "\n",
      "Fold: 26  Epoch: 3  Training loss = 2.3017  Validation loss = 1.8361  \n",
      "\n",
      "Fold: 26  Epoch: 4  Training loss = 2.5669  Validation loss = 0.8603  \n",
      "\n",
      "Fold: 26  Epoch: 5  Training loss = 2.3626  Validation loss = 3.9008  \n",
      "\n",
      "Fold: 26  Epoch: 6  Training loss = 2.3511  Validation loss = 3.6993  \n",
      "\n",
      "Fold: 26  Epoch: 7  Training loss = 2.3631  Validation loss = 2.9248  \n",
      "\n",
      "Fold: 26  Epoch: 8  Training loss = 2.7077  Validation loss = 3.8813  \n",
      "\n",
      "Fold: 26  Epoch: 9  Training loss = 2.4193  Validation loss = 2.5343  \n",
      "\n",
      "Fold: 26  Epoch: 10  Training loss = 2.4565  Validation loss = 2.4944  \n",
      "\n",
      "Fold: 26  Epoch: 11  Training loss = 2.9829  Validation loss = 1.6024  \n",
      "\n",
      "Fold: 26  Epoch: 12  Training loss = 2.5086  Validation loss = 1.6114  \n",
      "\n",
      "Fold: 26  Epoch: 13  Training loss = 2.7931  Validation loss = 5.3333  \n",
      "\n",
      "Check model:  Fold: 26  Optimal epoch: 4  \n",
      "\n",
      "Fold: 27  Epoch: 1  Training loss = 2.6822  Validation loss = 2.4651  \n",
      "\n",
      "Fold: 27  Epoch: 2  Training loss = 2.6850  Validation loss = 1.9711  \n",
      "\n",
      "Fold: 27  Epoch: 3  Training loss = 2.4094  Validation loss = 2.3905  \n",
      "\n",
      "Fold: 27  Epoch: 4  Training loss = 2.4703  Validation loss = 1.4250  \n",
      "\n",
      "Fold: 27  Epoch: 5  Training loss = 2.9804  Validation loss = 4.3790  \n",
      "\n",
      "Fold: 27  Epoch: 6  Training loss = 3.2192  Validation loss = 4.1142  \n",
      "\n",
      "Fold: 27  Epoch: 7  Training loss = 2.6927  Validation loss = 1.8787  \n",
      "\n",
      "Fold: 27  Epoch: 8  Training loss = 2.7984  Validation loss = 1.9084  \n",
      "\n",
      "Fold: 27  Epoch: 9  Training loss = 2.5748  Validation loss = 2.7825  \n",
      "\n",
      "Fold: 27  Epoch: 10  Training loss = 2.5644  Validation loss = 2.8256  \n",
      "\n",
      "Fold: 27  Epoch: 11  Training loss = 2.4974  Validation loss = 2.7791  \n",
      "\n",
      "Fold: 27  Epoch: 12  Training loss = 2.4753  Validation loss = 1.3507  \n",
      "\n",
      "Fold: 27  Epoch: 13  Training loss = 2.3247  Validation loss = 1.4646  \n",
      "\n",
      "Fold: 27  Epoch: 14  Training loss = 2.8595  Validation loss = 2.8428  \n",
      "\n",
      "Fold: 27  Epoch: 15  Training loss = 2.2744  Validation loss = 1.9248  \n",
      "\n",
      "Fold: 27  Epoch: 16  Training loss = 2.2990  Validation loss = 1.4524  \n",
      "\n",
      "Fold: 27  Epoch: 17  Training loss = 2.8397  Validation loss = 3.9046  \n",
      "\n",
      "Check model:  Fold: 27  Optimal epoch: 12  \n",
      "\n",
      "Fold: 28  Epoch: 1  Training loss = 2.2660  Validation loss = 3.7190  \n",
      "\n",
      "Fold: 28  Epoch: 2  Training loss = 2.1646  Validation loss = 3.6704  \n",
      "\n",
      "Fold: 28  Epoch: 3  Training loss = 2.0431  Validation loss = 2.8767  \n",
      "\n",
      "Fold: 28  Epoch: 4  Training loss = 2.1469  Validation loss = 2.6213  \n",
      "\n",
      "Fold: 28  Epoch: 5  Training loss = 2.2563  Validation loss = 2.8880  \n",
      "\n",
      "Fold: 28  Epoch: 6  Training loss = 1.9850  Validation loss = 3.1189  \n",
      "\n",
      "Fold: 28  Epoch: 7  Training loss = 2.1130  Validation loss = 3.1384  \n",
      "\n",
      "Fold: 28  Epoch: 8  Training loss = 2.1652  Validation loss = 3.6849  \n",
      "\n",
      "Fold: 28  Epoch: 9  Training loss = 2.0044  Validation loss = 3.7113  \n",
      "\n",
      "Fold: 28  Epoch: 10  Training loss = 2.0853  Validation loss = 3.0466  \n",
      "\n",
      "Fold: 28  Epoch: 11  Training loss = 2.1646  Validation loss = 2.8266  \n",
      "\n",
      "Fold: 28  Epoch: 12  Training loss = 2.0405  Validation loss = 3.3176  \n",
      "\n",
      "Fold: 28  Epoch: 13  Training loss = 2.1776  Validation loss = 3.9610  \n",
      "\n",
      "Check model:  Fold: 28  Optimal epoch: 4  \n",
      "\n",
      "Fold: 29  Epoch: 1  Training loss = 2.4143  Validation loss = 1.9290  \n",
      "\n",
      "Fold: 29  Epoch: 2  Training loss = 2.3831  Validation loss = 0.8854  \n",
      "\n",
      "Fold: 29  Epoch: 3  Training loss = 1.9471  Validation loss = 2.1428  \n",
      "\n",
      "Fold: 29  Epoch: 4  Training loss = 1.8943  Validation loss = 2.3221  \n",
      "\n",
      "Fold: 29  Epoch: 5  Training loss = 2.1445  Validation loss = 2.6978  \n",
      "\n",
      "Fold: 29  Epoch: 6  Training loss = 2.0923  Validation loss = 1.3649  \n",
      "\n",
      "Fold: 29  Epoch: 7  Training loss = 2.0213  Validation loss = 2.9907  \n",
      "\n",
      "Fold: 29  Epoch: 8  Training loss = 2.0155  Validation loss = 2.6022  \n",
      "\n",
      "Fold: 29  Epoch: 9  Training loss = 2.3731  Validation loss = 3.7730  \n",
      "\n",
      "Fold: 29  Epoch: 10  Training loss = 1.9539  Validation loss = 1.9547  \n",
      "\n",
      "Fold: 29  Epoch: 11  Training loss = 1.9757  Validation loss = 3.0095  \n",
      "\n",
      "Fold: 29  Epoch: 12  Training loss = 2.5197  Validation loss = 1.7172  \n",
      "\n",
      "Fold: 29  Epoch: 13  Training loss = 2.1607  Validation loss = 3.3739  \n",
      "\n",
      "Fold: 29  Epoch: 14  Training loss = 1.9444  Validation loss = 1.4835  \n",
      "\n",
      "Fold: 29  Epoch: 15  Training loss = 1.8591  Validation loss = 1.9688  \n",
      "\n",
      "Fold: 29  Epoch: 16  Training loss = 2.8114  Validation loss = 4.6813  \n",
      "\n",
      "Check model:  Fold: 29  Optimal epoch: 2  \n",
      "\n",
      "Fold: 30  Epoch: 1  Training loss = 3.2902  Validation loss = 4.8465  \n",
      "\n",
      "Fold: 30  Epoch: 2  Training loss = 2.2871  Validation loss = 2.0768  \n",
      "\n",
      "Fold: 30  Epoch: 3  Training loss = 2.0934  Validation loss = 1.9418  \n",
      "\n",
      "Fold: 30  Epoch: 4  Training loss = 2.0041  Validation loss = 1.7789  \n",
      "\n",
      "Fold: 30  Epoch: 5  Training loss = 1.8648  Validation loss = 1.5824  \n",
      "\n",
      "Fold: 30  Epoch: 6  Training loss = 2.0925  Validation loss = 2.0369  \n",
      "\n",
      "Fold: 30  Epoch: 7  Training loss = 1.8447  Validation loss = 1.5920  \n",
      "\n",
      "Fold: 30  Epoch: 8  Training loss = 1.9728  Validation loss = 1.5380  \n",
      "\n",
      "Fold: 30  Epoch: 9  Training loss = 1.8851  Validation loss = 1.4372  \n",
      "\n",
      "Fold: 30  Epoch: 10  Training loss = 1.9858  Validation loss = 1.4773  \n",
      "\n",
      "Fold: 30  Epoch: 11  Training loss = 2.1757  Validation loss = 2.1384  \n",
      "\n",
      "Check model:  Fold: 30  Optimal epoch: 9  \n",
      "\n",
      "Fold: 31  Epoch: 1  Training loss = 1.8694  Validation loss = 1.4885  \n",
      "\n",
      "Fold: 31  Epoch: 2  Training loss = 1.7908  Validation loss = 1.6209  \n",
      "\n",
      "Fold: 31  Epoch: 3  Training loss = 2.2661  Validation loss = 3.0146  \n",
      "\n",
      "Fold: 31  Epoch: 4  Training loss = 1.9081  Validation loss = 2.1728  \n",
      "\n",
      "Fold: 31  Epoch: 5  Training loss = 2.8760  Validation loss = 3.5917  \n",
      "\n",
      "Fold: 31  Epoch: 6  Training loss = 1.9602  Validation loss = 0.6482  \n",
      "\n",
      "Fold: 31  Epoch: 7  Training loss = 2.3170  Validation loss = 1.3281  \n",
      "\n",
      "Fold: 31  Epoch: 8  Training loss = 1.6651  Validation loss = 1.1513  \n",
      "\n",
      "Fold: 31  Epoch: 9  Training loss = 1.7561  Validation loss = 0.4833  \n",
      "\n",
      "Fold: 31  Epoch: 10  Training loss = 2.1715  Validation loss = 1.2820  \n",
      "\n",
      "Fold: 31  Epoch: 11  Training loss = 1.6559  Validation loss = 1.5005  \n",
      "\n",
      "Fold: 31  Epoch: 12  Training loss = 1.7173  Validation loss = 0.6657  \n",
      "\n",
      "Fold: 31  Epoch: 13  Training loss = 1.8089  Validation loss = 0.7425  \n",
      "\n",
      "Fold: 31  Epoch: 14  Training loss = 2.2336  Validation loss = 0.6165  \n",
      "\n",
      "Fold: 31  Epoch: 15  Training loss = 1.7321  Validation loss = 0.6220  \n",
      "\n",
      "Fold: 31  Epoch: 16  Training loss = 2.0528  Validation loss = 2.7027  \n",
      "\n",
      "Check model:  Fold: 31  Optimal epoch: 9  \n",
      "\n",
      "Fold: 32  Epoch: 1  Training loss = 1.6672  Validation loss = 5.0268  \n",
      "\n",
      "Fold: 32  Epoch: 2  Training loss = 2.2659  Validation loss = 6.5169  \n",
      "\n",
      "Fold: 32  Epoch: 3  Training loss = 2.2592  Validation loss = 6.7126  \n",
      "\n",
      "Fold: 32  Epoch: 4  Training loss = 2.0851  Validation loss = 3.6555  \n",
      "\n",
      "Fold: 32  Epoch: 5  Training loss = 1.7235  Validation loss = 4.4462  \n",
      "\n",
      "Fold: 32  Epoch: 6  Training loss = 1.8157  Validation loss = 5.3752  \n",
      "\n",
      "Fold: 32  Epoch: 7  Training loss = 1.8943  Validation loss = 3.9115  \n",
      "\n",
      "Fold: 32  Epoch: 8  Training loss = 2.3749  Validation loss = 5.8645  \n",
      "\n",
      "Fold: 32  Epoch: 9  Training loss = 2.2856  Validation loss = 6.7027  \n",
      "\n",
      "Fold: 32  Epoch: 10  Training loss = 1.9574  Validation loss = 3.9162  \n",
      "\n",
      "Fold: 32  Epoch: 11  Training loss = 1.7395  Validation loss = 5.7683  \n",
      "\n",
      "Fold: 32  Epoch: 12  Training loss = 2.2260  Validation loss = 3.6281  \n",
      "\n",
      "Fold: 32  Epoch: 13  Training loss = 1.7054  Validation loss = 4.1269  \n",
      "\n",
      "Fold: 32  Epoch: 14  Training loss = 1.5762  Validation loss = 5.1079  \n",
      "\n",
      "Fold: 32  Epoch: 15  Training loss = 2.0123  Validation loss = 4.1066  \n",
      "\n",
      "Fold: 32  Epoch: 16  Training loss = 1.6188  Validation loss = 5.0591  \n",
      "\n",
      "Fold: 32  Epoch: 17  Training loss = 1.6581  Validation loss = 5.0866  \n",
      "\n",
      "Fold: 32  Epoch: 18  Training loss = 1.9165  Validation loss = 6.0173  \n",
      "\n",
      "Fold: 32  Epoch: 19  Training loss = 1.8837  Validation loss = 4.1935  \n",
      "\n",
      "Fold: 32  Epoch: 20  Training loss = 1.6602  Validation loss = 4.2030  \n",
      "\n",
      "Fold: 32  Epoch: 21  Training loss = 1.8967  Validation loss = 5.9506  \n",
      "\n",
      "Fold: 32  Epoch: 22  Training loss = 1.6440  Validation loss = 5.0024  \n",
      "\n",
      "Fold: 32  Epoch: 23  Training loss = 2.0520  Validation loss = 6.2144  \n",
      "\n",
      "Check model:  Fold: 32  Optimal epoch: 12  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 2. Train model\n",
    "# ==================================\n",
    "sess = tf.InteractiveSession()  # Launch Graph\n",
    "sess.run(tf.global_variables_initializer())  # Initialise all variables\n",
    "\n",
    "print(\"Start training\", \n",
    "      \"\\nHyperparameters:\",\n",
    "      \"\\nDimension of recurrent unit =\", n_hidden,\n",
    "      \"\\nLearning rate =\", learning_rate,\n",
    "      \"\\nEpochs =\", epochs,\n",
    "      \"\\nBatch size =\", batch_size,\n",
    "      \"\\nEarly stopping epochs =\", early_stop_iters,\n",
    "      \"\\nLearning rate =\", learning_rate)\n",
    "\n",
    "total_batch = int(window_length / batch_size)\n",
    "validation_fold_error = [] # store validation error of each fold\n",
    "optimal_epochs = []\n",
    "\n",
    "# loop through folds\n",
    "for fold in range(1, len(valIndex)):\n",
    "    validx = train_features[valIndex[fold-1]:valIndex[fold]]\n",
    "    validy = train_target[valIndex[fold-1]:valIndex[fold]]\n",
    "    trainx = train_features[(fold-1)*4:valIndex[(fold-1)]]\n",
    "    trainy = train_target[(fold-1)*4:valIndex[(fold-1)]]\n",
    "\n",
    "    loss_list = [] # store validation loss after each epoch for early stopping\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i in range(total_batch):\n",
    "            # Backprop\n",
    "            batch_xs, batch_ys = next_batch(num=batch_size, data=trainx, labels=trainy)\n",
    "            optimizer.run(feed_dict={x:batch_xs, y:batch_ys, lr:learning_rate})\n",
    "\n",
    "        # Loss\n",
    "        loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "        loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "        loss_list.append(loss_valid)\n",
    "\n",
    "        print(\"Fold: {0:d}\".format(fold),\n",
    "              \" Epoch: {0:d}\".format(epoch+1),\n",
    "              \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "              \" Validation loss = {0:.4f}\".format(np.sqrt(loss_valid)),\n",
    "              \" \\n\")\n",
    "\n",
    "        if all(j <= loss_valid for j in loss_list[-early_stop_iters:]) and len(loss_list)>early_stop_iters:\n",
    "            break\n",
    "    \n",
    "    # Load model with lowest validation error for each fold\n",
    "    epoch_hat = np.argmin(loss_list) + 1\n",
    "    optimal_epochs.append(epoch_hat) # store optimal number of epochs for each fold\n",
    "    \n",
    "    # RMSE\n",
    "    loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "    loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "    validation_fold_error.append(np.sqrt(loss_valid))\n",
    "    \n",
    "    print(\"Check model:\",\n",
    "          \" Fold: {0:d}\".format(fold),\n",
    "          \" Optimal epoch: {0:d}\".format(epoch_hat),\n",
    "          \" \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average number of epochs: 10\n",
      "Average validation error: 4.04041\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 3. Optimal epoch choice\n",
    "# ==================================\n",
    "# Pick number of epochs to train model for out-of-sample testing\n",
    "epoch_hat = int(np.mean(optimal_epochs))\n",
    "print(\"\\nAverage number of epochs:\", epoch_hat)\n",
    "# Average validation error\n",
    "print(\"Average validation error:\", np.mean(validation_fold_error))\n",
    "\n",
    "# Save validated model\n",
    "saveModel(sess, \n",
    "          MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + str(epoch_hat) + \"_validated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fixed scheme:\n",
      "Epoch: 1  Training loss = 1.6561  Test loss = 3.9409  \n",
      "\n",
      "Epoch: 2  Training loss = 1.6083  Test loss = 3.8039  \n",
      "\n",
      "Epoch: 3  Training loss = 1.5930  Test loss = 3.7564  \n",
      "\n",
      "Epoch: 4  Training loss = 1.5812  Test loss = 3.7282  \n",
      "\n",
      "Epoch: 5  Training loss = 1.5700  Test loss = 3.7059  \n",
      "\n",
      "Epoch: 6  Training loss = 1.5592  Test loss = 3.6856  \n",
      "\n",
      "Epoch: 7  Training loss = 1.5487  Test loss = 3.6662  \n",
      "\n",
      "Epoch: 8  Training loss = 1.5386  Test loss = 3.6474  \n",
      "\n",
      "Epoch: 9  Training loss = 1.5287  Test loss = 3.6291  \n",
      "\n",
      "Epoch: 10  Training loss = 1.5192  Test loss = 3.6113  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 4. Fixed scheme\n",
    "# ==================================\n",
    "print(\"\\nFixed scheme:\")\n",
    "for epoch in range(epoch_hat):\n",
    "    x_train = train_features[-window_length:]\n",
    "    y_train = train_target[-window_length:]\n",
    "    optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:test_features, y:test_target})\n",
    "    print(\"Epoch: {0:d}\".format(epoch+1),\n",
    "          \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "          \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "          \" \\n\")\n",
    "\n",
    "# Forecasts\n",
    "yhat_test_fixed = pred.eval(feed_dict={x:test_features})\n",
    "yhat_train_fixed = pred.eval(feed_dict={x:x_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njIvdzCwzLnYzs8y42M3MMuNiNzPLzH8B00PbLxeeUAYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc5cae80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train set\n",
    "plt.plot(y_train, 'black')\n",
    "plt.plot(yhat_train_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xcc09cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: fixed scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_test_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed scheme RMSE: 3.61125394032 \n",
      "Fixed scheme MAE:  2.6394963964\n"
     ]
    }
   ],
   "source": [
    "rmse_fixed = np.sqrt(np.mean((yhat_test_fixed[:,0]-test_target)**2))\n",
    "mae_fixed = np.mean(np.abs((yhat_test_fixed[:,0]-test_target)))\n",
    "print(\"Fixed scheme RMSE:\", rmse_fixed,\n",
    "     \"\\nFixed scheme MAE: \", mae_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Stack training and test set, this makes updating scheme easier to train\n",
    "all_features = np.concatenate((train_features[-window_length:], test_features), axis=0)\n",
    "all_target = np.concatenate((train_target[-window_length:], test_target), axis=0)\n",
    "\n",
    "# Vectors to store loss and forecasts\n",
    "test_loss = np.zeros(len(test_target))\n",
    "yhat_update = np.zeros(len(test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test period = 1  Training loss = 1.5192  Test loss = 3.5359  Model updated 0 times  \n",
      "\n",
      "Test period = 2  Training loss = 1.5516  Test loss = 2.8892  Model updated 0 times  \n",
      "\n",
      "Test period = 3  Training loss = 1.5918  Test loss = 1.1805  Model updated 0 times  \n",
      "\n",
      "Test period = 4  Training loss = 1.5983  Test loss = 0.1091  Model updated 0 times  \n",
      "\n",
      "Test period = 5  Training loss = 1.1754  Test loss = 0.2491  Model updated 1 times  \n",
      "\n",
      "Test period = 6  Training loss = 1.1749  Test loss = 5.0590  Model updated 1 times  \n",
      "\n",
      "Test period = 7  Training loss = 1.3319  Test loss = 1.2552  Model updated 1 times  \n",
      "\n",
      "Test period = 8  Training loss = 1.3410  Test loss = 0.0656  Model updated 1 times  \n",
      "\n",
      "Test period = 9  Training loss = 1.0836  Test loss = 3.2807  Model updated 2 times  \n",
      "\n",
      "Test period = 10  Training loss = 1.1548  Test loss = 2.4711  Model updated 2 times  \n",
      "\n",
      "Test period = 11  Training loss = 1.1907  Test loss = 1.7937  Model updated 2 times  \n",
      "\n",
      "Test period = 12  Training loss = 1.2111  Test loss = 0.0916  Model updated 2 times  \n",
      "\n",
      "Test period = 13  Training loss = 1.0859  Test loss = 0.4396  Model updated 3 times  \n",
      "\n",
      "Test period = 14  Training loss = 1.0827  Test loss = 1.9907  Model updated 3 times  \n",
      "\n",
      "Test period = 15  Training loss = 1.1101  Test loss = 3.6117  Model updated 3 times  \n",
      "\n",
      "Test period = 16  Training loss = 1.1970  Test loss = 4.6587  Model updated 3 times  \n",
      "\n",
      "Test period = 17  Training loss = 1.1509  Test loss = 5.4742  Model updated 4 times  \n",
      "\n",
      "Test period = 18  Training loss = 1.3363  Test loss = 1.3375  Model updated 4 times  \n",
      "\n",
      "Test period = 19  Training loss = 1.3465  Test loss = 3.3771  Model updated 4 times  \n",
      "\n",
      "Test period = 20  Training loss = 1.3692  Test loss = 1.4296  Model updated 4 times  \n",
      "\n",
      "Test period = 21  Training loss = 1.0149  Test loss = 2.1704  Model updated 5 times  \n",
      "\n",
      "Test period = 22  Training loss = 1.0500  Test loss = 3.4862  Model updated 5 times  \n",
      "\n",
      "Test period = 23  Training loss = 1.1187  Test loss = 0.1269  Model updated 5 times  \n",
      "\n",
      "Test period = 24  Training loss = 1.1187  Test loss = 0.4906  Model updated 5 times  \n",
      "\n",
      "Test period = 25  Training loss = 0.9864  Test loss = 1.9844  Model updated 6 times  \n",
      "\n",
      "Test period = 26  Training loss = 1.0167  Test loss = 2.5322  Model updated 6 times  \n",
      "\n",
      "Test period = 27  Training loss = 1.0640  Test loss = 3.1497  Model updated 6 times  \n",
      "\n",
      "Test period = 28  Training loss = 1.1335  Test loss = 0.8888  Model updated 6 times  \n",
      "\n",
      "Test period = 29  Training loss = 0.9616  Test loss = 0.9582  Model updated 7 times  \n",
      "\n",
      "Test period = 30  Training loss = 0.9658  Test loss = 0.2084  Model updated 7 times  \n",
      "\n",
      "Test period = 31  Training loss = 0.9609  Test loss = 4.2218  Model updated 7 times  \n",
      "\n",
      "Test period = 32  Training loss = 1.0325  Test loss = 0.2340  Model updated 7 times  \n",
      "\n",
      "Test period = 33  Training loss = 0.9021  Test loss = 1.4259  Model updated 8 times  \n",
      "\n",
      "Test period = 34  Training loss = 0.9187  Test loss = 0.1340  Model updated 8 times  \n",
      "\n",
      "Test period = 35  Training loss = 0.9073  Test loss = 0.3051  Model updated 8 times  \n",
      "\n",
      "Test period = 36  Training loss = 0.9070  Test loss = 4.9729  Model updated 8 times  \n",
      "\n",
      "Test period = 37  Training loss = 0.9108  Test loss = 0.6226  Model updated 9 times  \n",
      "\n",
      "Test period = 38  Training loss = 0.7946  Test loss = 1.6419  Model updated 9 times  \n",
      "\n",
      "Test period = 39  Training loss = 0.8203  Test loss = 0.8929  Model updated 9 times  \n",
      "\n",
      "Test period = 40  Training loss = 0.8276  Test loss = 3.2209  Model updated 9 times  \n",
      "\n",
      "Test period = 41  Training loss = 0.7697  Test loss = 2.4837  Model updated 10 times  \n",
      "\n",
      "Test period = 42  Training loss = 0.8281  Test loss = 5.1819  Model updated 10 times  \n",
      "\n",
      "Test period = 43  Training loss = 1.0439  Test loss = 3.3926  Model updated 10 times  \n",
      "\n",
      "Test period = 44  Training loss = 1.1255  Test loss = 15.3618  Model updated 10 times  \n",
      "\n",
      "Test period = 45  Training loss = 2.0207  Test loss = 5.9536  Model updated 11 times  \n",
      "\n",
      "Test period = 46  Training loss = 2.1510  Test loss = 1.0253  Model updated 11 times  \n",
      "\n",
      "Test period = 47  Training loss = 2.1547  Test loss = 0.3786  Model updated 11 times  \n",
      "\n",
      "Test period = 48  Training loss = 2.1523  Test loss = 0.3442  Model updated 11 times  \n",
      "\n",
      "Test period = 49  Training loss = 1.0791  Test loss = 2.6461  Model updated 12 times  \n",
      "\n",
      "Test period = 50  Training loss = 1.1273  Test loss = 2.2893  Model updated 12 times  \n",
      "\n",
      "Test period = 51  Training loss = 1.1607  Test loss = 3.4351  Model updated 12 times  \n",
      "\n",
      "Test period = 52  Training loss = 1.2362  Test loss = 0.7583  Model updated 12 times  \n",
      "\n",
      "Test period = 53  Training loss = 1.0004  Test loss = 1.6652  Model updated 13 times  \n",
      "\n",
      "Test period = 54  Training loss = 1.0215  Test loss = 3.6336  Model updated 13 times  \n",
      "\n",
      "Test period = 55  Training loss = 1.1165  Test loss = 1.8380  Model updated 13 times  \n",
      "\n",
      "Test period = 56  Training loss = 1.1395  Test loss = 1.5353  Model updated 13 times  \n",
      "\n",
      "Test period = 57  Training loss = 1.0732  Test loss = 6.0439  Model updated 14 times  \n",
      "\n",
      "Test period = 58  Training loss = 1.3090  Test loss = 7.5462  Model updated 14 times  \n",
      "\n",
      "Test period = 59  Training loss = 1.6089  Test loss = 1.5581  Model updated 14 times  \n",
      "\n",
      "Test period = 60  Training loss = 1.6205  Test loss = 0.7186  Model updated 14 times  \n",
      "\n",
      "Test period = 61  Training loss = 0.9979  Test loss = 1.3755  Model updated 15 times  \n",
      "\n",
      "Test period = 62  Training loss = 1.0094  Test loss = 1.9529  Model updated 15 times  \n",
      "\n",
      "Test period = 63  Training loss = 1.0352  Test loss = 1.2837  Model updated 15 times  \n",
      "\n",
      "Test period = 64  Training loss = 1.0473  Test loss = 1.5031  Model updated 15 times  \n",
      "\n",
      "Test period = 65  Training loss = 1.0233  Test loss = 1.8399  Model updated 16 times  \n",
      "\n",
      "Test period = 66  Training loss = 1.0478  Test loss = 3.0146  Model updated 16 times  \n",
      "\n",
      "Test period = 67  Training loss = 1.1122  Test loss = 2.2969  Model updated 16 times  \n",
      "\n",
      "Test period = 68  Training loss = 1.1328  Test loss = 2.0798  Model updated 16 times  \n",
      "\n",
      "Test period = 69  Training loss = 1.0210  Test loss = 5.8641  Model updated 17 times  \n",
      "\n",
      "Test period = 70  Training loss = 1.2528  Test loss = 0.3815  Model updated 17 times  \n",
      "\n",
      "Test period = 71  Training loss = 1.2534  Test loss = 2.7109  Model updated 17 times  \n",
      "\n",
      "Test period = 72  Training loss = 1.2977  Test loss = 1.5925  Model updated 17 times  \n",
      "\n",
      "Test period = 73  Training loss = 0.9949  Test loss = 2.9225  Model updated 18 times  \n",
      "\n",
      "Test period = 74  Training loss = 1.0585  Test loss = 2.7881  Model updated 18 times  \n",
      "\n",
      "Test period = 75  Training loss = 1.1091  Test loss = 1.3491  Model updated 18 times  \n",
      "\n",
      "Test period = 76  Training loss = 1.1205  Test loss = 1.1104  Model updated 18 times  \n",
      "\n",
      "Test period = 77  Training loss = 1.0238  Test loss = 1.4398  Model updated 19 times  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "retrain_count = 0\n",
    "for t in range(len(test_target)):\n",
    "    x_test = np.reshape(test_features[t], newshape=(1,4,3))\n",
    "    y_test = test_target[t]\n",
    "    test_loss[t] = np.sqrt(sess.run(loss, feed_dict={x:x_test, y:y_test}))\n",
    "    yhat_update[t] = pred.eval(feed_dict={x:x_test})\n",
    "\n",
    "    x_train = all_features[t:(window_length+t)]\n",
    "    y_train = all_target[t:(window_length+t)]\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:x_test, y:y_test})\n",
    "    \n",
    "    print(\"Test period = {0:d}\".format(t+1),\n",
    "      \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "      \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "      \" Model updated {0:d} times\".format(retrain_count),\n",
    "      \" \\n\")\n",
    "\n",
    "    if (t+1)%4==0:\n",
    "        retrain_count += 1\n",
    "        for epoch in range(epoch_hat):\n",
    "            for i in range(total_batch):\n",
    "                optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxW5m1jD/BWI98MdLJabQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd2c0630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: updating scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_update, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating scheme RMSE: 3.24219535022 \n",
      "Updating scheme MAE:  2.35405398045\n"
     ]
    }
   ],
   "source": [
    "rmse_update = np.sqrt(np.mean((yhat_update-test_target)**2))\n",
    "mae_update = np.mean(np.abs((yhat_update-test_target)))\n",
    "print(\"Updating scheme RMSE:\", rmse_update,\n",
    "     \"\\nUpdating scheme MAE: \", mae_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + \"yhat_test_fixed.csv\", yhat_test_fixed)\n",
    "np.savetxt(MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + \"yhat_update.csv\", yhat_update)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
