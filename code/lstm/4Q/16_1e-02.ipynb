{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Directories\n",
    "MODEL_FOLDER = \"../../../models/lstm/\"\n",
    "MODEL_FILENAME = MODEL_FOLDER + \"4Q/16_units/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: model saver\n",
    "def saveModel(sess, MODEL_FILENAME):\n",
    "    if not os.path.exists(MODEL_FOLDER):\n",
    "        print('Creating path where to save model: ' + MODEL_FOLDER)\n",
    "        os.mkdir(MODEL_FOLDER)\n",
    "\n",
    "    #print('Saving model at: ' + MODEL_FILENAME)\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, MODEL_FILENAME)\n",
    "    #print('Model successfully saved.\\n')\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: model loader\n",
    "def loadModel(sess, MODEL_FILENAME):\n",
    "    if os.path.exists(MODEL_FILENAME + \".index\"):\n",
    "        print('Loading save model from: ' + MODEL_FILENAME)\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, MODEL_FILENAME)\n",
    "        print('Model successfully loaded.\\n')\n",
    "        return True\n",
    "    else:\n",
    "        print('Model file <<' + MODEL_FILENAME + '>> does not exists!')\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Hyperparameters\n",
    "epochs = 500\n",
    "learning_rate = 1e-2\n",
    "batch_size = 5\n",
    "early_stop_iters = 10\n",
    "folds = 32\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 3  # data input\n",
    "n_steps = 4  # timesteps\n",
    "n_hidden = 16 # dimension of recurrent unit\n",
    "\n",
    "# (REPRODUCIBILITY) set random seeds\n",
    "tf.set_random_seed(123)\n",
    "\n",
    "# Define weights and biases\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.truncated_normal([n_hidden, 1], stddev = 1.0 / tf.sqrt(float(n_hidden))),\n",
    "        name='out_weight')\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.zeros([1]),\n",
    "        name='out_bias')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: Build model\n",
    "def RNN(X, weights, biases, n_hidden):\n",
    "\n",
    "    # Define a LSTM cell with tensorflow\n",
    "    lstm_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden, state_is_tuple=True)\n",
    "    outputs, _ = tf.nn.dynamic_rnn(lstm_cell, X, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    out_layer = tf.matmul(outputs[:,-1,:], weights['out']) + biases['out']\n",
    "\n",
    "    return out_layer\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: select batch\n",
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the data...\n",
      "Finished: data loaded. Stats below: \n",
      "Nr of training samples: 193\n",
      "Nr of testing  samples: 77\n",
      "Number of variables: 3\n",
      "Number of lags: 4\n",
      "Window length: 65\n",
      "Number of validation folds: 32\n"
     ]
    }
   ],
   "source": [
    "# =================================\n",
    "# 0. Load dataset\n",
    "# =================================\n",
    "print(\"Loading the data...\")\n",
    "# Training set pre-processing\n",
    "train = pd.read_csv('../../../Data/train.csv')\n",
    "train_4lag_inflation = np.array(train[['inflation.lag4',\n",
    "                                       'inflation.lag5',\n",
    "                                       'inflation.lag6',\n",
    "                                       'inflation.lag7']])\n",
    "train_4lag_unemp = np.array(train[['unemp.lag4',\n",
    "                                   'unemp.lag5',\n",
    "                                   'unemp.lag6',\n",
    "                                   'unemp.lag7']])\n",
    "train_4lag_oil = np.array(train[['oil.lag4',\n",
    "                                 'oil.lag5',\n",
    "                                 'oil.lag6',\n",
    "                                 'oil.lag7']])\n",
    "train_features = np.concatenate((train_4lag_inflation[:,:,np.newaxis], \n",
    "\t                             train_4lag_unemp[:,:,np.newaxis],\n",
    "\t                             train_4lag_oil[:,:,np.newaxis]),\n",
    "\t                             axis=2)\n",
    "train_target = np.array(train['inflation.target'])\n",
    "\n",
    "# Test set pre-processing\n",
    "test = pd.read_csv('../../../Data/test.csv')\n",
    "test_4lag_inflation = np.array(test[['inflation.lag4',\n",
    "                                     'inflation.lag5',\n",
    "                                     'inflation.lag6',\n",
    "                                     'inflation.lag7']])\n",
    "test_4lag_unemp = np.array(test[['unemp.lag4',\n",
    "                                 'unemp.lag5',\n",
    "                                 'unemp.lag6',\n",
    "                                 'unemp.lag7']])\n",
    "test_4lag_oil = np.array(test[['oil.lag4',\n",
    "                               'oil.lag5',\n",
    "                               'oil.lag6',\n",
    "                               'oil.lag7']])\n",
    "test_features = np.concatenate((test_4lag_inflation[:,:,np.newaxis], \n",
    "\t                            test_4lag_unemp[:,:,np.newaxis],\n",
    "\t                            test_4lag_oil[:,:,np.newaxis]),\n",
    "\t                            axis=2)\n",
    "test_target = np.array(test['inflation.target'])\n",
    "\n",
    "(nrTrainSamples, timesteps, variables) = train_features.shape\n",
    "(nrTestSamples, _, _) = test_features.shape\n",
    "\n",
    "# Window length and validation fold index\n",
    "window_length = 65\n",
    "valIndex = np.linspace(start=window_length, stop=nrTrainSamples, \n",
    "                       endpoint=True, num=folds+1, dtype=np.int)\n",
    "\n",
    "print(\"Finished: data loaded. Stats below: \")\n",
    "print(\"Nr of training samples: %d\" % nrTrainSamples)\n",
    "print(\"Nr of testing  samples: %d\" % nrTestSamples)\n",
    "print(\"Number of variables: %d\" % variables)\n",
    "print(\"Number of lags: %d\" % timesteps)\n",
    "print(\"Window length: %d\" % window_length)\n",
    "print(\"Number of validation folds: %d\" % folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 1. Build model\n",
    "# ==================================\n",
    "# tf graph input\n",
    "x = tf.placeholder(\"float\", [None, n_steps, n_input], name='Batch')\n",
    "y = tf.placeholder(\"float\", name='True_labels_of_batch')\n",
    "lr = tf.placeholder(\"float\", name='Learning_rate')\n",
    "\n",
    "# Make predictions with the model\n",
    "pred = RNN(x, weights, biases, n_hidden)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss = tf.reduce_mean(tf.diag_part(tf.square(tf.subtract(x=pred, y=y))))\n",
    "optimizer = tf.train.GradientDescentOptimizer(lr).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training \n",
      "Hyperparameters: \n",
      "Dimension of recurrent unit = 16 \n",
      "Learning rate = 0.01 \n",
      "Epochs = 500 \n",
      "Batch size = 5 \n",
      "Early stopping epochs = 10 \n",
      "Learning rate = 0.01\n",
      "Fold: 1  Epoch: 1  Training loss = 2.7194  Validation loss = 2.3068  \n",
      "\n",
      "Fold: 1  Epoch: 2  Training loss = 2.5394  Validation loss = 1.5719  \n",
      "\n",
      "Fold: 1  Epoch: 3  Training loss = 2.5008  Validation loss = 1.7481  \n",
      "\n",
      "Fold: 1  Epoch: 4  Training loss = 2.4388  Validation loss = 1.5582  \n",
      "\n",
      "Fold: 1  Epoch: 5  Training loss = 2.3925  Validation loss = 1.8207  \n",
      "\n",
      "Fold: 1  Epoch: 6  Training loss = 2.3810  Validation loss = 1.8463  \n",
      "\n",
      "Fold: 1  Epoch: 7  Training loss = 2.3389  Validation loss = 1.7286  \n",
      "\n",
      "Fold: 1  Epoch: 8  Training loss = 2.3053  Validation loss = 1.7329  \n",
      "\n",
      "Fold: 1  Epoch: 9  Training loss = 2.3169  Validation loss = 1.7770  \n",
      "\n",
      "Fold: 1  Epoch: 10  Training loss = 2.2894  Validation loss = 1.7535  \n",
      "\n",
      "Fold: 1  Epoch: 11  Training loss = 2.3822  Validation loss = 2.2381  \n",
      "\n",
      "Check model:  Fold: 1  Optimal epoch: 4  \n",
      "\n",
      "Fold: 2  Epoch: 1  Training loss = 2.2320  Validation loss = 2.1297  \n",
      "\n",
      "Fold: 2  Epoch: 2  Training loss = 2.2371  Validation loss = 2.1358  \n",
      "\n",
      "Fold: 2  Epoch: 3  Training loss = 2.1611  Validation loss = 2.3758  \n",
      "\n",
      "Fold: 2  Epoch: 4  Training loss = 2.2562  Validation loss = 2.1360  \n",
      "\n",
      "Fold: 2  Epoch: 5  Training loss = 2.2091  Validation loss = 2.0812  \n",
      "\n",
      "Fold: 2  Epoch: 6  Training loss = 2.2204  Validation loss = 2.0070  \n",
      "\n",
      "Fold: 2  Epoch: 7  Training loss = 2.2779  Validation loss = 1.8115  \n",
      "\n",
      "Fold: 2  Epoch: 8  Training loss = 2.1247  Validation loss = 2.1139  \n",
      "\n",
      "Fold: 2  Epoch: 9  Training loss = 2.1645  Validation loss = 2.0338  \n",
      "\n",
      "Fold: 2  Epoch: 10  Training loss = 2.1661  Validation loss = 1.8914  \n",
      "\n",
      "Fold: 2  Epoch: 11  Training loss = 2.6343  Validation loss = 1.7517  \n",
      "\n",
      "Fold: 2  Epoch: 12  Training loss = 2.2000  Validation loss = 2.3916  \n",
      "\n",
      "Check model:  Fold: 2  Optimal epoch: 11  \n",
      "\n",
      "Fold: 3  Epoch: 1  Training loss = 1.3676  Validation loss = 2.9835  \n",
      "\n",
      "Fold: 3  Epoch: 2  Training loss = 1.3094  Validation loss = 2.7150  \n",
      "\n",
      "Fold: 3  Epoch: 3  Training loss = 1.2953  Validation loss = 2.7289  \n",
      "\n",
      "Fold: 3  Epoch: 4  Training loss = 1.2946  Validation loss = 2.5872  \n",
      "\n",
      "Fold: 3  Epoch: 5  Training loss = 1.3473  Validation loss = 3.0177  \n",
      "\n",
      "Fold: 3  Epoch: 6  Training loss = 1.2938  Validation loss = 3.0556  \n",
      "\n",
      "Fold: 3  Epoch: 7  Training loss = 1.2865  Validation loss = 2.8286  \n",
      "\n",
      "Fold: 3  Epoch: 8  Training loss = 1.2716  Validation loss = 2.7212  \n",
      "\n",
      "Fold: 3  Epoch: 9  Training loss = 1.2717  Validation loss = 2.5534  \n",
      "\n",
      "Fold: 3  Epoch: 10  Training loss = 1.2434  Validation loss = 2.7774  \n",
      "\n",
      "Fold: 3  Epoch: 11  Training loss = 1.2751  Validation loss = 2.9475  \n",
      "\n",
      "Fold: 3  Epoch: 12  Training loss = 1.2937  Validation loss = 2.7766  \n",
      "\n",
      "Fold: 3  Epoch: 13  Training loss = 1.3280  Validation loss = 3.0032  \n",
      "\n",
      "Fold: 3  Epoch: 14  Training loss = 1.2321  Validation loss = 3.1602  \n",
      "\n",
      "Check model:  Fold: 3  Optimal epoch: 9  \n",
      "\n",
      "Fold: 4  Epoch: 1  Training loss = 1.2905  Validation loss = 3.5911  \n",
      "\n",
      "Fold: 4  Epoch: 2  Training loss = 1.2569  Validation loss = 3.2491  \n",
      "\n",
      "Fold: 4  Epoch: 3  Training loss = 1.2641  Validation loss = 3.4917  \n",
      "\n",
      "Fold: 4  Epoch: 4  Training loss = 1.2676  Validation loss = 2.9752  \n",
      "\n",
      "Fold: 4  Epoch: 5  Training loss = 1.2216  Validation loss = 2.9876  \n",
      "\n",
      "Fold: 4  Epoch: 6  Training loss = 1.2158  Validation loss = 3.2450  \n",
      "\n",
      "Fold: 4  Epoch: 7  Training loss = 1.2382  Validation loss = 2.8420  \n",
      "\n",
      "Fold: 4  Epoch: 8  Training loss = 1.1843  Validation loss = 2.9684  \n",
      "\n",
      "Fold: 4  Epoch: 9  Training loss = 1.3072  Validation loss = 3.4841  \n",
      "\n",
      "Fold: 4  Epoch: 10  Training loss = 1.2073  Validation loss = 3.3782  \n",
      "\n",
      "Fold: 4  Epoch: 11  Training loss = 1.1488  Validation loss = 2.9954  \n",
      "\n",
      "Fold: 4  Epoch: 12  Training loss = 1.1503  Validation loss = 2.6210  \n",
      "\n",
      "Fold: 4  Epoch: 13  Training loss = 1.1352  Validation loss = 2.9072  \n",
      "\n",
      "Fold: 4  Epoch: 14  Training loss = 1.1359  Validation loss = 3.0346  \n",
      "\n",
      "Fold: 4  Epoch: 15  Training loss = 1.1255  Validation loss = 2.8089  \n",
      "\n",
      "Fold: 4  Epoch: 16  Training loss = 1.1382  Validation loss = 2.4818  \n",
      "\n",
      "Fold: 4  Epoch: 17  Training loss = 1.1364  Validation loss = 2.4024  \n",
      "\n",
      "Fold: 4  Epoch: 18  Training loss = 1.1262  Validation loss = 3.0232  \n",
      "\n",
      "Fold: 4  Epoch: 19  Training loss = 1.1209  Validation loss = 2.5764  \n",
      "\n",
      "Fold: 4  Epoch: 20  Training loss = 1.1265  Validation loss = 3.0926  \n",
      "\n",
      "Check model:  Fold: 4  Optimal epoch: 17  \n",
      "\n",
      "Fold: 5  Epoch: 1  Training loss = 1.1715  Validation loss = 3.0935  \n",
      "\n",
      "Fold: 5  Epoch: 2  Training loss = 1.1183  Validation loss = 2.9111  \n",
      "\n",
      "Fold: 5  Epoch: 3  Training loss = 1.1478  Validation loss = 2.8960  \n",
      "\n",
      "Fold: 5  Epoch: 4  Training loss = 1.1079  Validation loss = 3.1056  \n",
      "\n",
      "Fold: 5  Epoch: 5  Training loss = 1.1051  Validation loss = 3.2693  \n",
      "\n",
      "Fold: 5  Epoch: 6  Training loss = 1.0472  Validation loss = 3.0574  \n",
      "\n",
      "Fold: 5  Epoch: 7  Training loss = 1.0527  Validation loss = 3.2267  \n",
      "\n",
      "Fold: 5  Epoch: 8  Training loss = 1.0425  Validation loss = 3.2250  \n",
      "\n",
      "Fold: 5  Epoch: 9  Training loss = 1.0703  Validation loss = 3.1276  \n",
      "\n",
      "Fold: 5  Epoch: 10  Training loss = 1.0377  Validation loss = 3.1527  \n",
      "\n",
      "Fold: 5  Epoch: 11  Training loss = 1.0216  Validation loss = 3.1542  \n",
      "\n",
      "Fold: 5  Epoch: 12  Training loss = 1.0119  Validation loss = 3.1876  \n",
      "\n",
      "Fold: 5  Epoch: 13  Training loss = 1.0349  Validation loss = 3.0546  \n",
      "\n",
      "Fold: 5  Epoch: 14  Training loss = 1.1127  Validation loss = 3.3087  \n",
      "\n",
      "Check model:  Fold: 5  Optimal epoch: 3  \n",
      "\n",
      "Fold: 6  Epoch: 1  Training loss = 1.2137  Validation loss = 1.1798  \n",
      "\n",
      "Fold: 6  Epoch: 2  Training loss = 1.2202  Validation loss = 1.1332  \n",
      "\n",
      "Fold: 6  Epoch: 3  Training loss = 1.1660  Validation loss = 0.9587  \n",
      "\n",
      "Fold: 6  Epoch: 4  Training loss = 1.2053  Validation loss = 1.4440  \n",
      "\n",
      "Fold: 6  Epoch: 5  Training loss = 1.1311  Validation loss = 1.2734  \n",
      "\n",
      "Fold: 6  Epoch: 6  Training loss = 1.0610  Validation loss = 1.1321  \n",
      "\n",
      "Fold: 6  Epoch: 7  Training loss = 1.0648  Validation loss = 1.2308  \n",
      "\n",
      "Fold: 6  Epoch: 8  Training loss = 1.0647  Validation loss = 1.0833  \n",
      "\n",
      "Fold: 6  Epoch: 9  Training loss = 1.0113  Validation loss = 1.2149  \n",
      "\n",
      "Fold: 6  Epoch: 10  Training loss = 1.0204  Validation loss = 1.1725  \n",
      "\n",
      "Fold: 6  Epoch: 11  Training loss = 1.0090  Validation loss = 1.0483  \n",
      "\n",
      "Fold: 6  Epoch: 12  Training loss = 0.9967  Validation loss = 1.1501  \n",
      "\n",
      "Fold: 6  Epoch: 13  Training loss = 1.0097  Validation loss = 1.0282  \n",
      "\n",
      "Fold: 6  Epoch: 14  Training loss = 0.9888  Validation loss = 1.1305  \n",
      "\n",
      "Fold: 6  Epoch: 15  Training loss = 1.0190  Validation loss = 1.0249  \n",
      "\n",
      "Fold: 6  Epoch: 16  Training loss = 0.9888  Validation loss = 0.9968  \n",
      "\n",
      "Fold: 6  Epoch: 17  Training loss = 0.9633  Validation loss = 1.1372  \n",
      "\n",
      "Fold: 6  Epoch: 18  Training loss = 0.9805  Validation loss = 1.0264  \n",
      "\n",
      "Fold: 6  Epoch: 19  Training loss = 1.0136  Validation loss = 1.0055  \n",
      "\n",
      "Fold: 6  Epoch: 20  Training loss = 0.9513  Validation loss = 1.2276  \n",
      "\n",
      "Check model:  Fold: 6  Optimal epoch: 3  \n",
      "\n",
      "Fold: 7  Epoch: 1  Training loss = 0.9899  Validation loss = 2.8324  \n",
      "\n",
      "Fold: 7  Epoch: 2  Training loss = 1.0009  Validation loss = 2.8667  \n",
      "\n",
      "Fold: 7  Epoch: 3  Training loss = 0.9706  Validation loss = 2.9518  \n",
      "\n",
      "Fold: 7  Epoch: 4  Training loss = 0.9706  Validation loss = 3.0210  \n",
      "\n",
      "Fold: 7  Epoch: 5  Training loss = 0.9745  Validation loss = 2.9674  \n",
      "\n",
      "Fold: 7  Epoch: 6  Training loss = 0.9897  Validation loss = 3.0275  \n",
      "\n",
      "Fold: 7  Epoch: 7  Training loss = 0.9659  Validation loss = 3.0180  \n",
      "\n",
      "Fold: 7  Epoch: 8  Training loss = 0.9558  Validation loss = 2.9976  \n",
      "\n",
      "Fold: 7  Epoch: 9  Training loss = 0.9991  Validation loss = 2.9899  \n",
      "\n",
      "Fold: 7  Epoch: 10  Training loss = 0.9590  Validation loss = 2.9503  \n",
      "\n",
      "Fold: 7  Epoch: 11  Training loss = 0.9693  Validation loss = 2.9864  \n",
      "\n",
      "Fold: 7  Epoch: 12  Training loss = 0.9404  Validation loss = 3.0120  \n",
      "\n",
      "Fold: 7  Epoch: 13  Training loss = 0.9776  Validation loss = 2.9708  \n",
      "\n",
      "Fold: 7  Epoch: 14  Training loss = 0.9565  Validation loss = 3.0165  \n",
      "\n",
      "Fold: 7  Epoch: 15  Training loss = 0.9408  Validation loss = 3.0491  \n",
      "\n",
      "Check model:  Fold: 7  Optimal epoch: 1  \n",
      "\n",
      "Fold: 8  Epoch: 1  Training loss = 1.0963  Validation loss = 7.0952  \n",
      "\n",
      "Fold: 8  Epoch: 2  Training loss = 1.0619  Validation loss = 6.8883  \n",
      "\n",
      "Fold: 8  Epoch: 3  Training loss = 1.0586  Validation loss = 7.0359  \n",
      "\n",
      "Fold: 8  Epoch: 4  Training loss = 1.0590  Validation loss = 6.9888  \n",
      "\n",
      "Fold: 8  Epoch: 5  Training loss = 1.0615  Validation loss = 7.2045  \n",
      "\n",
      "Fold: 8  Epoch: 6  Training loss = 1.0766  Validation loss = 7.3389  \n",
      "\n",
      "Fold: 8  Epoch: 7  Training loss = 1.0410  Validation loss = 7.1001  \n",
      "\n",
      "Fold: 8  Epoch: 8  Training loss = 1.0478  Validation loss = 6.9119  \n",
      "\n",
      "Fold: 8  Epoch: 9  Training loss = 1.0405  Validation loss = 7.2255  \n",
      "\n",
      "Fold: 8  Epoch: 10  Training loss = 1.0761  Validation loss = 7.4454  \n",
      "\n",
      "Fold: 8  Epoch: 11  Training loss = 1.0245  Validation loss = 7.1725  \n",
      "\n",
      "Fold: 8  Epoch: 12  Training loss = 1.0273  Validation loss = 6.9655  \n",
      "\n",
      "Fold: 8  Epoch: 13  Training loss = 1.0179  Validation loss = 7.1184  \n",
      "\n",
      "Fold: 8  Epoch: 14  Training loss = 1.0276  Validation loss = 7.1690  \n",
      "\n",
      "Fold: 8  Epoch: 15  Training loss = 1.0168  Validation loss = 6.9863  \n",
      "\n",
      "Fold: 8  Epoch: 16  Training loss = 1.0130  Validation loss = 6.9356  \n",
      "\n",
      "Fold: 8  Epoch: 17  Training loss = 1.0096  Validation loss = 6.7445  \n",
      "\n",
      "Fold: 8  Epoch: 18  Training loss = 1.0042  Validation loss = 6.5745  \n",
      "\n",
      "Fold: 8  Epoch: 19  Training loss = 1.0016  Validation loss = 6.8902  \n",
      "\n",
      "Fold: 8  Epoch: 20  Training loss = 0.9819  Validation loss = 6.9077  \n",
      "\n",
      "Fold: 8  Epoch: 21  Training loss = 0.9869  Validation loss = 6.6060  \n",
      "\n",
      "Fold: 8  Epoch: 22  Training loss = 0.9719  Validation loss = 6.6563  \n",
      "\n",
      "Fold: 8  Epoch: 23  Training loss = 0.9741  Validation loss = 6.8866  \n",
      "\n",
      "Fold: 8  Epoch: 24  Training loss = 0.9778  Validation loss = 6.9852  \n",
      "\n",
      "Fold: 8  Epoch: 25  Training loss = 0.9589  Validation loss = 6.7998  \n",
      "\n",
      "Fold: 8  Epoch: 26  Training loss = 0.9507  Validation loss = 6.7649  \n",
      "\n",
      "Fold: 8  Epoch: 27  Training loss = 0.9665  Validation loss = 6.7621  \n",
      "\n",
      "Fold: 8  Epoch: 28  Training loss = 0.9687  Validation loss = 6.8595  \n",
      "\n",
      "Fold: 8  Epoch: 29  Training loss = 0.9630  Validation loss = 6.7121  \n",
      "\n",
      "Fold: 8  Epoch: 30  Training loss = 0.9548  Validation loss = 6.6703  \n",
      "\n",
      "Fold: 8  Epoch: 31  Training loss = 0.9793  Validation loss = 6.2054  \n",
      "\n",
      "Fold: 8  Epoch: 32  Training loss = 0.9603  Validation loss = 6.3512  \n",
      "\n",
      "Fold: 8  Epoch: 33  Training loss = 0.9390  Validation loss = 6.3720  \n",
      "\n",
      "Fold: 8  Epoch: 34  Training loss = 0.9419  Validation loss = 6.5179  \n",
      "\n",
      "Fold: 8  Epoch: 35  Training loss = 0.9454  Validation loss = 6.5933  \n",
      "\n",
      "Fold: 8  Epoch: 36  Training loss = 0.9404  Validation loss = 6.5815  \n",
      "\n",
      "Fold: 8  Epoch: 37  Training loss = 0.9236  Validation loss = 6.5094  \n",
      "\n",
      "Fold: 8  Epoch: 38  Training loss = 0.9654  Validation loss = 6.9201  \n",
      "\n",
      "Check model:  Fold: 8  Optimal epoch: 31  \n",
      "\n",
      "Fold: 9  Epoch: 1  Training loss = 1.9090  Validation loss = 7.4932  \n",
      "\n",
      "Fold: 9  Epoch: 2  Training loss = 1.7260  Validation loss = 8.1515  \n",
      "\n",
      "Fold: 9  Epoch: 3  Training loss = 1.7154  Validation loss = 8.2485  \n",
      "\n",
      "Fold: 9  Epoch: 4  Training loss = 1.6726  Validation loss = 7.6753  \n",
      "\n",
      "Fold: 9  Epoch: 5  Training loss = 1.6257  Validation loss = 7.8626  \n",
      "\n",
      "Fold: 9  Epoch: 6  Training loss = 1.6536  Validation loss = 7.3618  \n",
      "\n",
      "Fold: 9  Epoch: 7  Training loss = 1.5714  Validation loss = 7.6621  \n",
      "\n",
      "Fold: 9  Epoch: 8  Training loss = 1.7002  Validation loss = 8.2338  \n",
      "\n",
      "Fold: 9  Epoch: 9  Training loss = 1.7010  Validation loss = 8.0922  \n",
      "\n",
      "Fold: 9  Epoch: 10  Training loss = 1.5305  Validation loss = 7.5389  \n",
      "\n",
      "Fold: 9  Epoch: 11  Training loss = 1.5222  Validation loss = 7.7397  \n",
      "\n",
      "Fold: 9  Epoch: 12  Training loss = 1.6355  Validation loss = 7.0834  \n",
      "\n",
      "Fold: 9  Epoch: 13  Training loss = 1.4768  Validation loss = 7.3483  \n",
      "\n",
      "Fold: 9  Epoch: 14  Training loss = 1.4400  Validation loss = 7.4544  \n",
      "\n",
      "Fold: 9  Epoch: 15  Training loss = 1.4720  Validation loss = 7.4620  \n",
      "\n",
      "Fold: 9  Epoch: 16  Training loss = 1.4212  Validation loss = 7.4139  \n",
      "\n",
      "Fold: 9  Epoch: 17  Training loss = 1.5645  Validation loss = 7.5604  \n",
      "\n",
      "Fold: 9  Epoch: 18  Training loss = 1.3998  Validation loss = 7.0326  \n",
      "\n",
      "Fold: 9  Epoch: 19  Training loss = 1.3991  Validation loss = 7.0352  \n",
      "\n",
      "Fold: 9  Epoch: 20  Training loss = 1.4333  Validation loss = 6.5953  \n",
      "\n",
      "Fold: 9  Epoch: 21  Training loss = 1.4577  Validation loss = 7.2641  \n",
      "\n",
      "Fold: 9  Epoch: 22  Training loss = 1.4113  Validation loss = 7.2341  \n",
      "\n",
      "Fold: 9  Epoch: 23  Training loss = 1.3877  Validation loss = 7.1412  \n",
      "\n",
      "Fold: 9  Epoch: 24  Training loss = 1.3560  Validation loss = 7.2585  \n",
      "\n",
      "Fold: 9  Epoch: 25  Training loss = 1.4059  Validation loss = 7.3492  \n",
      "\n",
      "Fold: 9  Epoch: 26  Training loss = 1.3237  Validation loss = 7.0699  \n",
      "\n",
      "Fold: 9  Epoch: 27  Training loss = 1.3438  Validation loss = 6.8164  \n",
      "\n",
      "Fold: 9  Epoch: 28  Training loss = 1.2987  Validation loss = 6.9928  \n",
      "\n",
      "Fold: 9  Epoch: 29  Training loss = 1.3249  Validation loss = 7.1271  \n",
      "\n",
      "Fold: 9  Epoch: 30  Training loss = 1.3265  Validation loss = 6.7347  \n",
      "\n",
      "Fold: 9  Epoch: 31  Training loss = 1.2668  Validation loss = 6.8162  \n",
      "\n",
      "Fold: 9  Epoch: 32  Training loss = 1.2792  Validation loss = 6.6533  \n",
      "\n",
      "Fold: 9  Epoch: 33  Training loss = 1.4557  Validation loss = 6.4927  \n",
      "\n",
      "Fold: 9  Epoch: 34  Training loss = 1.2645  Validation loss = 6.9530  \n",
      "\n",
      "Fold: 9  Epoch: 35  Training loss = 1.2676  Validation loss = 7.0149  \n",
      "\n",
      "Fold: 9  Epoch: 36  Training loss = 1.3907  Validation loss = 7.1273  \n",
      "\n",
      "Check model:  Fold: 9  Optimal epoch: 33  \n",
      "\n",
      "Fold: 10  Epoch: 1  Training loss = 1.9560  Validation loss = 4.0878  \n",
      "\n",
      "Fold: 10  Epoch: 2  Training loss = 1.8502  Validation loss = 4.3216  \n",
      "\n",
      "Fold: 10  Epoch: 3  Training loss = 1.8240  Validation loss = 3.8957  \n",
      "\n",
      "Fold: 10  Epoch: 4  Training loss = 1.9282  Validation loss = 3.7690  \n",
      "\n",
      "Fold: 10  Epoch: 5  Training loss = 1.7685  Validation loss = 3.8687  \n",
      "\n",
      "Fold: 10  Epoch: 6  Training loss = 1.6912  Validation loss = 3.7635  \n",
      "\n",
      "Fold: 10  Epoch: 7  Training loss = 1.7446  Validation loss = 3.9301  \n",
      "\n",
      "Fold: 10  Epoch: 8  Training loss = 1.6847  Validation loss = 3.7115  \n",
      "\n",
      "Fold: 10  Epoch: 9  Training loss = 1.7034  Validation loss = 3.6085  \n",
      "\n",
      "Fold: 10  Epoch: 10  Training loss = 1.6582  Validation loss = 3.6093  \n",
      "\n",
      "Fold: 10  Epoch: 11  Training loss = 1.6700  Validation loss = 3.6155  \n",
      "\n",
      "Fold: 10  Epoch: 12  Training loss = 1.6640  Validation loss = 3.5168  \n",
      "\n",
      "Fold: 10  Epoch: 13  Training loss = 1.6373  Validation loss = 3.5179  \n",
      "\n",
      "Fold: 10  Epoch: 14  Training loss = 1.6127  Validation loss = 3.2937  \n",
      "\n",
      "Fold: 10  Epoch: 15  Training loss = 1.8250  Validation loss = 3.4277  \n",
      "\n",
      "Fold: 10  Epoch: 16  Training loss = 1.6116  Validation loss = 3.2285  \n",
      "\n",
      "Fold: 10  Epoch: 17  Training loss = 1.7088  Validation loss = 3.5217  \n",
      "\n",
      "Fold: 10  Epoch: 18  Training loss = 1.6717  Validation loss = 3.6479  \n",
      "\n",
      "Check model:  Fold: 10  Optimal epoch: 16  \n",
      "\n",
      "Fold: 11  Epoch: 1  Training loss = 1.8707  Validation loss = 2.3080  \n",
      "\n",
      "Fold: 11  Epoch: 2  Training loss = 1.6109  Validation loss = 1.6669  \n",
      "\n",
      "Fold: 11  Epoch: 3  Training loss = 1.5630  Validation loss = 2.1810  \n",
      "\n",
      "Fold: 11  Epoch: 4  Training loss = 1.5580  Validation loss = 2.1384  \n",
      "\n",
      "Fold: 11  Epoch: 5  Training loss = 1.5912  Validation loss = 2.1529  \n",
      "\n",
      "Fold: 11  Epoch: 6  Training loss = 1.4954  Validation loss = 2.2885  \n",
      "\n",
      "Fold: 11  Epoch: 7  Training loss = 1.5434  Validation loss = 2.1085  \n",
      "\n",
      "Fold: 11  Epoch: 8  Training loss = 1.6048  Validation loss = 2.3971  \n",
      "\n",
      "Fold: 11  Epoch: 9  Training loss = 1.5410  Validation loss = 1.8461  \n",
      "\n",
      "Fold: 11  Epoch: 10  Training loss = 1.4792  Validation loss = 1.9194  \n",
      "\n",
      "Fold: 11  Epoch: 11  Training loss = 1.6384  Validation loss = 3.1832  \n",
      "\n",
      "Check model:  Fold: 11  Optimal epoch: 2  \n",
      "\n",
      "Fold: 12  Epoch: 1  Training loss = 1.5655  Validation loss = 1.2627  \n",
      "\n",
      "Fold: 12  Epoch: 2  Training loss = 1.5919  Validation loss = 1.8915  \n",
      "\n",
      "Fold: 12  Epoch: 3  Training loss = 1.6363  Validation loss = 1.8029  \n",
      "\n",
      "Fold: 12  Epoch: 4  Training loss = 1.5085  Validation loss = 1.8938  \n",
      "\n",
      "Fold: 12  Epoch: 5  Training loss = 1.6116  Validation loss = 1.8784  \n",
      "\n",
      "Fold: 12  Epoch: 6  Training loss = 1.5059  Validation loss = 1.8606  \n",
      "\n",
      "Fold: 12  Epoch: 7  Training loss = 1.6304  Validation loss = 1.5704  \n",
      "\n",
      "Fold: 12  Epoch: 8  Training loss = 1.9392  Validation loss = 1.5248  \n",
      "\n",
      "Fold: 12  Epoch: 9  Training loss = 1.6012  Validation loss = 1.8915  \n",
      "\n",
      "Fold: 12  Epoch: 10  Training loss = 1.5647  Validation loss = 1.8256  \n",
      "\n",
      "Fold: 12  Epoch: 11  Training loss = 1.5042  Validation loss = 2.4139  \n",
      "\n",
      "Check model:  Fold: 12  Optimal epoch: 1  \n",
      "\n",
      "Fold: 13  Epoch: 1  Training loss = 1.5850  Validation loss = 4.0964  \n",
      "\n",
      "Fold: 13  Epoch: 2  Training loss = 1.5379  Validation loss = 4.1780  \n",
      "\n",
      "Fold: 13  Epoch: 3  Training loss = 1.4935  Validation loss = 4.1903  \n",
      "\n",
      "Fold: 13  Epoch: 4  Training loss = 1.4668  Validation loss = 4.1489  \n",
      "\n",
      "Fold: 13  Epoch: 5  Training loss = 1.5744  Validation loss = 3.8168  \n",
      "\n",
      "Fold: 13  Epoch: 6  Training loss = 1.5566  Validation loss = 3.7796  \n",
      "\n",
      "Fold: 13  Epoch: 7  Training loss = 1.4557  Validation loss = 3.9388  \n",
      "\n",
      "Fold: 13  Epoch: 8  Training loss = 1.4323  Validation loss = 3.6490  \n",
      "\n",
      "Fold: 13  Epoch: 9  Training loss = 1.4656  Validation loss = 3.4750  \n",
      "\n",
      "Fold: 13  Epoch: 10  Training loss = 1.4050  Validation loss = 3.7847  \n",
      "\n",
      "Fold: 13  Epoch: 11  Training loss = 1.3841  Validation loss = 4.3046  \n",
      "\n",
      "Check model:  Fold: 13  Optimal epoch: 9  \n",
      "\n",
      "Fold: 14  Epoch: 1  Training loss = 1.6184  Validation loss = 6.5619  \n",
      "\n",
      "Fold: 14  Epoch: 2  Training loss = 1.6066  Validation loss = 6.5752  \n",
      "\n",
      "Fold: 14  Epoch: 3  Training loss = 1.6571  Validation loss = 6.4840  \n",
      "\n",
      "Fold: 14  Epoch: 4  Training loss = 1.6041  Validation loss = 6.2166  \n",
      "\n",
      "Fold: 14  Epoch: 5  Training loss = 1.6368  Validation loss = 5.9144  \n",
      "\n",
      "Fold: 14  Epoch: 6  Training loss = 1.6203  Validation loss = 5.3763  \n",
      "\n",
      "Fold: 14  Epoch: 7  Training loss = 1.6006  Validation loss = 5.9839  \n",
      "\n",
      "Fold: 14  Epoch: 8  Training loss = 1.6259  Validation loss = 5.7480  \n",
      "\n",
      "Fold: 14  Epoch: 9  Training loss = 1.4968  Validation loss = 6.3310  \n",
      "\n",
      "Fold: 14  Epoch: 10  Training loss = 1.4969  Validation loss = 6.3529  \n",
      "\n",
      "Fold: 14  Epoch: 11  Training loss = 1.5376  Validation loss = 5.8004  \n",
      "\n",
      "Fold: 14  Epoch: 12  Training loss = 1.4742  Validation loss = 5.7497  \n",
      "\n",
      "Fold: 14  Epoch: 13  Training loss = 1.4545  Validation loss = 5.9699  \n",
      "\n",
      "Fold: 14  Epoch: 14  Training loss = 1.4617  Validation loss = 6.0519  \n",
      "\n",
      "Fold: 14  Epoch: 15  Training loss = 1.4196  Validation loss = 5.9272  \n",
      "\n",
      "Fold: 14  Epoch: 16  Training loss = 1.4603  Validation loss = 6.0887  \n",
      "\n",
      "Fold: 14  Epoch: 17  Training loss = 1.4432  Validation loss = 5.9413  \n",
      "\n",
      "Fold: 14  Epoch: 18  Training loss = 1.4496  Validation loss = 5.6358  \n",
      "\n",
      "Fold: 14  Epoch: 19  Training loss = 1.4814  Validation loss = 5.3700  \n",
      "\n",
      "Fold: 14  Epoch: 20  Training loss = 1.4222  Validation loss = 6.0201  \n",
      "\n",
      "Fold: 14  Epoch: 21  Training loss = 1.6096  Validation loss = 6.7051  \n",
      "\n",
      "Check model:  Fold: 14  Optimal epoch: 19  \n",
      "\n",
      "Fold: 15  Epoch: 1  Training loss = 2.4308  Validation loss = 6.9263  \n",
      "\n",
      "Fold: 15  Epoch: 2  Training loss = 2.0074  Validation loss = 5.6698  \n",
      "\n",
      "Fold: 15  Epoch: 3  Training loss = 2.4781  Validation loss = 6.9783  \n",
      "\n",
      "Fold: 15  Epoch: 4  Training loss = 1.8849  Validation loss = 6.1980  \n",
      "\n",
      "Fold: 15  Epoch: 5  Training loss = 2.3308  Validation loss = 7.4037  \n",
      "\n",
      "Fold: 15  Epoch: 6  Training loss = 1.8758  Validation loss = 6.2516  \n",
      "\n",
      "Fold: 15  Epoch: 7  Training loss = 1.9222  Validation loss = 6.0721  \n",
      "\n",
      "Fold: 15  Epoch: 8  Training loss = 1.9556  Validation loss = 6.2322  \n",
      "\n",
      "Fold: 15  Epoch: 9  Training loss = 1.9006  Validation loss = 5.9603  \n",
      "\n",
      "Fold: 15  Epoch: 10  Training loss = 1.8830  Validation loss = 6.3900  \n",
      "\n",
      "Fold: 15  Epoch: 11  Training loss = 1.9118  Validation loss = 6.1900  \n",
      "\n",
      "Fold: 15  Epoch: 12  Training loss = 1.7806  Validation loss = 6.3967  \n",
      "\n",
      "Fold: 15  Epoch: 13  Training loss = 1.8128  Validation loss = 5.8557  \n",
      "\n",
      "Fold: 15  Epoch: 14  Training loss = 1.8639  Validation loss = 5.6144  \n",
      "\n",
      "Fold: 15  Epoch: 15  Training loss = 1.7952  Validation loss = 6.4219  \n",
      "\n",
      "Check model:  Fold: 15  Optimal epoch: 14  \n",
      "\n",
      "Fold: 16  Epoch: 1  Training loss = 2.6112  Validation loss = 3.2636  \n",
      "\n",
      "Fold: 16  Epoch: 2  Training loss = 2.9560  Validation loss = 3.7997  \n",
      "\n",
      "Fold: 16  Epoch: 3  Training loss = 2.4703  Validation loss = 4.2147  \n",
      "\n",
      "Fold: 16  Epoch: 4  Training loss = 2.4843  Validation loss = 4.2632  \n",
      "\n",
      "Fold: 16  Epoch: 5  Training loss = 2.3498  Validation loss = 3.9957  \n",
      "\n",
      "Fold: 16  Epoch: 6  Training loss = 2.4741  Validation loss = 4.1419  \n",
      "\n",
      "Fold: 16  Epoch: 7  Training loss = 2.5334  Validation loss = 4.0887  \n",
      "\n",
      "Fold: 16  Epoch: 8  Training loss = 2.2292  Validation loss = 4.8905  \n",
      "\n",
      "Fold: 16  Epoch: 9  Training loss = 2.2120  Validation loss = 3.7215  \n",
      "\n",
      "Fold: 16  Epoch: 10  Training loss = 2.3875  Validation loss = 3.5769  \n",
      "\n",
      "Fold: 16  Epoch: 11  Training loss = 2.6599  Validation loss = 3.5164  \n",
      "\n",
      "Fold: 16  Epoch: 12  Training loss = 2.4661  Validation loss = 3.4786  \n",
      "\n",
      "Fold: 16  Epoch: 13  Training loss = 2.3588  Validation loss = 3.2015  \n",
      "\n",
      "Fold: 16  Epoch: 14  Training loss = 2.3766  Validation loss = 3.0029  \n",
      "\n",
      "Fold: 16  Epoch: 15  Training loss = 2.6425  Validation loss = 3.0091  \n",
      "\n",
      "Fold: 16  Epoch: 16  Training loss = 2.2133  Validation loss = 2.8955  \n",
      "\n",
      "Fold: 16  Epoch: 17  Training loss = 2.2233  Validation loss = 3.0853  \n",
      "\n",
      "Fold: 16  Epoch: 18  Training loss = 2.1287  Validation loss = 3.2362  \n",
      "\n",
      "Fold: 16  Epoch: 19  Training loss = 2.2011  Validation loss = 2.9774  \n",
      "\n",
      "Fold: 16  Epoch: 20  Training loss = 2.1955  Validation loss = 2.9767  \n",
      "\n",
      "Fold: 16  Epoch: 21  Training loss = 2.0886  Validation loss = 3.5329  \n",
      "\n",
      "Check model:  Fold: 16  Optimal epoch: 16  \n",
      "\n",
      "Fold: 17  Epoch: 1  Training loss = 2.2634  Validation loss = 2.1150  \n",
      "\n",
      "Fold: 17  Epoch: 2  Training loss = 2.3668  Validation loss = 2.4762  \n",
      "\n",
      "Fold: 17  Epoch: 3  Training loss = 2.5752  Validation loss = 2.0277  \n",
      "\n",
      "Fold: 17  Epoch: 4  Training loss = 2.3244  Validation loss = 2.8040  \n",
      "\n",
      "Fold: 17  Epoch: 5  Training loss = 2.7067  Validation loss = 2.7211  \n",
      "\n",
      "Fold: 17  Epoch: 6  Training loss = 2.5460  Validation loss = 2.7876  \n",
      "\n",
      "Fold: 17  Epoch: 7  Training loss = 2.3240  Validation loss = 2.9158  \n",
      "\n",
      "Fold: 17  Epoch: 8  Training loss = 2.3578  Validation loss = 3.1586  \n",
      "\n",
      "Fold: 17  Epoch: 9  Training loss = 2.3819  Validation loss = 2.4940  \n",
      "\n",
      "Fold: 17  Epoch: 10  Training loss = 2.1977  Validation loss = 2.6248  \n",
      "\n",
      "Fold: 17  Epoch: 11  Training loss = 2.4467  Validation loss = 2.5002  \n",
      "\n",
      "Fold: 17  Epoch: 12  Training loss = 2.3773  Validation loss = 2.3911  \n",
      "\n",
      "Fold: 17  Epoch: 13  Training loss = 2.2110  Validation loss = 2.8716  \n",
      "\n",
      "Fold: 17  Epoch: 14  Training loss = 2.4112  Validation loss = 3.3878  \n",
      "\n",
      "Check model:  Fold: 17  Optimal epoch: 3  \n",
      "\n",
      "Fold: 18  Epoch: 1  Training loss = 2.5932  Validation loss = 3.2394  \n",
      "\n",
      "Fold: 18  Epoch: 2  Training loss = 2.3388  Validation loss = 3.0441  \n",
      "\n",
      "Fold: 18  Epoch: 3  Training loss = 2.2061  Validation loss = 3.9990  \n",
      "\n",
      "Fold: 18  Epoch: 4  Training loss = 2.2656  Validation loss = 3.0210  \n",
      "\n",
      "Fold: 18  Epoch: 5  Training loss = 2.6825  Validation loss = 3.5717  \n",
      "\n",
      "Fold: 18  Epoch: 6  Training loss = 2.4245  Validation loss = 3.5137  \n",
      "\n",
      "Fold: 18  Epoch: 7  Training loss = 2.3119  Validation loss = 3.2989  \n",
      "\n",
      "Fold: 18  Epoch: 8  Training loss = 2.3244  Validation loss = 4.1084  \n",
      "\n",
      "Fold: 18  Epoch: 9  Training loss = 2.4503  Validation loss = 3.8796  \n",
      "\n",
      "Fold: 18  Epoch: 10  Training loss = 2.6471  Validation loss = 3.5320  \n",
      "\n",
      "Fold: 18  Epoch: 11  Training loss = 2.4455  Validation loss = 2.6885  \n",
      "\n",
      "Fold: 18  Epoch: 12  Training loss = 2.3610  Validation loss = 3.3829  \n",
      "\n",
      "Fold: 18  Epoch: 13  Training loss = 2.5088  Validation loss = 2.1735  \n",
      "\n",
      "Fold: 18  Epoch: 14  Training loss = 2.3121  Validation loss = 3.2418  \n",
      "\n",
      "Fold: 18  Epoch: 15  Training loss = 2.1971  Validation loss = 1.7361  \n",
      "\n",
      "Fold: 18  Epoch: 16  Training loss = 2.6782  Validation loss = 1.8881  \n",
      "\n",
      "Fold: 18  Epoch: 17  Training loss = 2.7398  Validation loss = 2.2525  \n",
      "\n",
      "Fold: 18  Epoch: 18  Training loss = 2.3519  Validation loss = 2.6876  \n",
      "\n",
      "Fold: 18  Epoch: 19  Training loss = 2.4290  Validation loss = 2.8072  \n",
      "\n",
      "Fold: 18  Epoch: 20  Training loss = 2.5081  Validation loss = 3.3179  \n",
      "\n",
      "Fold: 18  Epoch: 21  Training loss = 2.4523  Validation loss = 3.0885  \n",
      "\n",
      "Fold: 18  Epoch: 22  Training loss = 2.3000  Validation loss = 3.2257  \n",
      "\n",
      "Fold: 18  Epoch: 23  Training loss = 2.2484  Validation loss = 3.2086  \n",
      "\n",
      "Fold: 18  Epoch: 24  Training loss = 2.2482  Validation loss = 3.3120  \n",
      "\n",
      "Fold: 18  Epoch: 25  Training loss = 2.1933  Validation loss = 3.3231  \n",
      "\n",
      "Check model:  Fold: 18  Optimal epoch: 15  \n",
      "\n",
      "Fold: 19  Epoch: 1  Training loss = 2.3246  Validation loss = 1.9103  \n",
      "\n",
      "Fold: 19  Epoch: 2  Training loss = 2.4377  Validation loss = 1.9406  \n",
      "\n",
      "Fold: 19  Epoch: 3  Training loss = 2.2887  Validation loss = 1.6935  \n",
      "\n",
      "Fold: 19  Epoch: 4  Training loss = 2.2772  Validation loss = 1.7275  \n",
      "\n",
      "Fold: 19  Epoch: 5  Training loss = 2.4034  Validation loss = 1.7734  \n",
      "\n",
      "Fold: 19  Epoch: 6  Training loss = 2.1241  Validation loss = 1.6685  \n",
      "\n",
      "Fold: 19  Epoch: 7  Training loss = 2.3720  Validation loss = 1.5528  \n",
      "\n",
      "Fold: 19  Epoch: 8  Training loss = 2.1129  Validation loss = 1.6226  \n",
      "\n",
      "Fold: 19  Epoch: 9  Training loss = 2.1324  Validation loss = 1.7020  \n",
      "\n",
      "Fold: 19  Epoch: 10  Training loss = 2.0726  Validation loss = 1.5711  \n",
      "\n",
      "Fold: 19  Epoch: 11  Training loss = 2.0654  Validation loss = 1.5502  \n",
      "\n",
      "Fold: 19  Epoch: 12  Training loss = 2.0327  Validation loss = 1.5068  \n",
      "\n",
      "Fold: 19  Epoch: 13  Training loss = 2.0465  Validation loss = 1.4736  \n",
      "\n",
      "Fold: 19  Epoch: 14  Training loss = 2.0357  Validation loss = 1.4576  \n",
      "\n",
      "Fold: 19  Epoch: 15  Training loss = 1.9952  Validation loss = 1.5725  \n",
      "\n",
      "Fold: 19  Epoch: 16  Training loss = 2.0909  Validation loss = 1.7066  \n",
      "\n",
      "Check model:  Fold: 19  Optimal epoch: 14  \n",
      "\n",
      "Fold: 20  Epoch: 1  Training loss = 2.0209  Validation loss = 0.6418  \n",
      "\n",
      "Fold: 20  Epoch: 2  Training loss = 1.9429  Validation loss = 0.9240  \n",
      "\n",
      "Fold: 20  Epoch: 3  Training loss = 2.2034  Validation loss = 0.8303  \n",
      "\n",
      "Fold: 20  Epoch: 4  Training loss = 2.1372  Validation loss = 0.4029  \n",
      "\n",
      "Fold: 20  Epoch: 5  Training loss = 1.9836  Validation loss = 0.9057  \n",
      "\n",
      "Fold: 20  Epoch: 6  Training loss = 2.0533  Validation loss = 1.0811  \n",
      "\n",
      "Fold: 20  Epoch: 7  Training loss = 2.2783  Validation loss = 0.8151  \n",
      "\n",
      "Fold: 20  Epoch: 8  Training loss = 2.0761  Validation loss = 0.2770  \n",
      "\n",
      "Fold: 20  Epoch: 9  Training loss = 1.9953  Validation loss = 0.6284  \n",
      "\n",
      "Fold: 20  Epoch: 10  Training loss = 1.9380  Validation loss = 0.6730  \n",
      "\n",
      "Fold: 20  Epoch: 11  Training loss = 1.8633  Validation loss = 0.9435  \n",
      "\n",
      "Fold: 20  Epoch: 12  Training loss = 1.9131  Validation loss = 0.8001  \n",
      "\n",
      "Fold: 20  Epoch: 13  Training loss = 1.8437  Validation loss = 0.8390  \n",
      "\n",
      "Fold: 20  Epoch: 14  Training loss = 1.8666  Validation loss = 0.6810  \n",
      "\n",
      "Fold: 20  Epoch: 15  Training loss = 1.9781  Validation loss = 1.1840  \n",
      "\n",
      "Check model:  Fold: 20  Optimal epoch: 8  \n",
      "\n",
      "Fold: 21  Epoch: 1  Training loss = 2.0190  Validation loss = 4.7991  \n",
      "\n",
      "Fold: 21  Epoch: 2  Training loss = 1.8800  Validation loss = 4.7343  \n",
      "\n",
      "Fold: 21  Epoch: 3  Training loss = 1.9395  Validation loss = 4.6380  \n",
      "\n",
      "Fold: 21  Epoch: 4  Training loss = 1.7737  Validation loss = 4.7675  \n",
      "\n",
      "Fold: 21  Epoch: 5  Training loss = 1.8885  Validation loss = 4.6195  \n",
      "\n",
      "Fold: 21  Epoch: 6  Training loss = 1.8367  Validation loss = 4.7140  \n",
      "\n",
      "Fold: 21  Epoch: 7  Training loss = 1.8135  Validation loss = 4.7124  \n",
      "\n",
      "Fold: 21  Epoch: 8  Training loss = 1.8118  Validation loss = 4.8438  \n",
      "\n",
      "Fold: 21  Epoch: 9  Training loss = 1.8429  Validation loss = 4.7796  \n",
      "\n",
      "Fold: 21  Epoch: 10  Training loss = 1.8072  Validation loss = 4.6733  \n",
      "\n",
      "Fold: 21  Epoch: 11  Training loss = 1.8290  Validation loss = 4.3860  \n",
      "\n",
      "Fold: 21  Epoch: 12  Training loss = 1.7827  Validation loss = 4.5828  \n",
      "\n",
      "Fold: 21  Epoch: 13  Training loss = 1.9380  Validation loss = 4.5847  \n",
      "\n",
      "Fold: 21  Epoch: 14  Training loss = 1.9327  Validation loss = 4.4832  \n",
      "\n",
      "Fold: 21  Epoch: 15  Training loss = 1.8772  Validation loss = 4.6937  \n",
      "\n",
      "Fold: 21  Epoch: 16  Training loss = 1.8975  Validation loss = 4.6979  \n",
      "\n",
      "Fold: 21  Epoch: 17  Training loss = 1.8180  Validation loss = 4.5807  \n",
      "\n",
      "Fold: 21  Epoch: 18  Training loss = 1.8373  Validation loss = 4.5007  \n",
      "\n",
      "Fold: 21  Epoch: 19  Training loss = 1.9263  Validation loss = 4.6537  \n",
      "\n",
      "Fold: 21  Epoch: 20  Training loss = 2.0182  Validation loss = 4.4412  \n",
      "\n",
      "Fold: 21  Epoch: 21  Training loss = 1.7839  Validation loss = 4.5806  \n",
      "\n",
      "Fold: 21  Epoch: 22  Training loss = 1.6677  Validation loss = 4.5927  \n",
      "\n",
      "Fold: 21  Epoch: 23  Training loss = 1.7282  Validation loss = 4.7889  \n",
      "\n",
      "Check model:  Fold: 21  Optimal epoch: 11  \n",
      "\n",
      "Fold: 22  Epoch: 1  Training loss = 1.9299  Validation loss = 1.5901  \n",
      "\n",
      "Fold: 22  Epoch: 2  Training loss = 1.9417  Validation loss = 1.7622  \n",
      "\n",
      "Fold: 22  Epoch: 3  Training loss = 1.9825  Validation loss = 1.7367  \n",
      "\n",
      "Fold: 22  Epoch: 4  Training loss = 2.0195  Validation loss = 1.5715  \n",
      "\n",
      "Fold: 22  Epoch: 5  Training loss = 1.9875  Validation loss = 1.6344  \n",
      "\n",
      "Fold: 22  Epoch: 6  Training loss = 1.9033  Validation loss = 1.6073  \n",
      "\n",
      "Fold: 22  Epoch: 7  Training loss = 1.8274  Validation loss = 1.8064  \n",
      "\n",
      "Fold: 22  Epoch: 8  Training loss = 1.9138  Validation loss = 1.7014  \n",
      "\n",
      "Fold: 22  Epoch: 9  Training loss = 1.7334  Validation loss = 2.2273  \n",
      "\n",
      "Fold: 22  Epoch: 10  Training loss = 1.7509  Validation loss = 2.2068  \n",
      "\n",
      "Fold: 22  Epoch: 11  Training loss = 1.7698  Validation loss = 1.9174  \n",
      "\n",
      "Fold: 22  Epoch: 12  Training loss = 1.7552  Validation loss = 1.9959  \n",
      "\n",
      "Fold: 22  Epoch: 13  Training loss = 1.7507  Validation loss = 1.8786  \n",
      "\n",
      "Fold: 22  Epoch: 14  Training loss = 1.7615  Validation loss = 2.0537  \n",
      "\n",
      "Fold: 22  Epoch: 15  Training loss = 1.6973  Validation loss = 2.2590  \n",
      "\n",
      "Check model:  Fold: 22  Optimal epoch: 4  \n",
      "\n",
      "Fold: 23  Epoch: 1  Training loss = 1.7311  Validation loss = 2.9326  \n",
      "\n",
      "Fold: 23  Epoch: 2  Training loss = 1.6591  Validation loss = 2.8002  \n",
      "\n",
      "Fold: 23  Epoch: 3  Training loss = 1.6183  Validation loss = 2.9256  \n",
      "\n",
      "Fold: 23  Epoch: 4  Training loss = 1.6622  Validation loss = 2.8381  \n",
      "\n",
      "Fold: 23  Epoch: 5  Training loss = 1.6009  Validation loss = 2.9728  \n",
      "\n",
      "Fold: 23  Epoch: 6  Training loss = 1.6506  Validation loss = 3.2847  \n",
      "\n",
      "Fold: 23  Epoch: 7  Training loss = 1.6542  Validation loss = 3.1995  \n",
      "\n",
      "Fold: 23  Epoch: 8  Training loss = 1.6130  Validation loss = 3.1662  \n",
      "\n",
      "Fold: 23  Epoch: 9  Training loss = 1.6302  Validation loss = 3.3869  \n",
      "\n",
      "Fold: 23  Epoch: 10  Training loss = 1.5246  Validation loss = 3.1932  \n",
      "\n",
      "Fold: 23  Epoch: 11  Training loss = 1.5896  Validation loss = 3.2050  \n",
      "\n",
      "Fold: 23  Epoch: 12  Training loss = 1.6098  Validation loss = 3.1248  \n",
      "\n",
      "Fold: 23  Epoch: 13  Training loss = 1.5547  Validation loss = 2.9906  \n",
      "\n",
      "Fold: 23  Epoch: 14  Training loss = 1.7255  Validation loss = 3.0623  \n",
      "\n",
      "Fold: 23  Epoch: 15  Training loss = 1.5675  Validation loss = 2.9137  \n",
      "\n",
      "Fold: 23  Epoch: 16  Training loss = 1.5592  Validation loss = 3.0334  \n",
      "\n",
      "Fold: 23  Epoch: 17  Training loss = 1.5477  Validation loss = 3.1285  \n",
      "\n",
      "Fold: 23  Epoch: 18  Training loss = 1.5136  Validation loss = 3.0010  \n",
      "\n",
      "Fold: 23  Epoch: 19  Training loss = 1.5774  Validation loss = 3.2262  \n",
      "\n",
      "Check model:  Fold: 23  Optimal epoch: 2  \n",
      "\n",
      "Fold: 24  Epoch: 1  Training loss = 1.7471  Validation loss = 2.3224  \n",
      "\n",
      "Fold: 24  Epoch: 2  Training loss = 1.6592  Validation loss = 2.3686  \n",
      "\n",
      "Fold: 24  Epoch: 3  Training loss = 1.6077  Validation loss = 2.8996  \n",
      "\n",
      "Fold: 24  Epoch: 4  Training loss = 1.6398  Validation loss = 2.4328  \n",
      "\n",
      "Fold: 24  Epoch: 5  Training loss = 1.6865  Validation loss = 2.7075  \n",
      "\n",
      "Fold: 24  Epoch: 6  Training loss = 1.6136  Validation loss = 2.6853  \n",
      "\n",
      "Fold: 24  Epoch: 7  Training loss = 1.5988  Validation loss = 2.5160  \n",
      "\n",
      "Fold: 24  Epoch: 8  Training loss = 1.6144  Validation loss = 2.3067  \n",
      "\n",
      "Fold: 24  Epoch: 9  Training loss = 1.5493  Validation loss = 2.8367  \n",
      "\n",
      "Fold: 24  Epoch: 10  Training loss = 1.5496  Validation loss = 2.8457  \n",
      "\n",
      "Fold: 24  Epoch: 11  Training loss = 1.5790  Validation loss = 3.3458  \n",
      "\n",
      "Check model:  Fold: 24  Optimal epoch: 8  \n",
      "\n",
      "Fold: 25  Epoch: 1  Training loss = 1.8674  Validation loss = 4.0617  \n",
      "\n",
      "Fold: 25  Epoch: 2  Training loss = 1.7540  Validation loss = 3.8396  \n",
      "\n",
      "Fold: 25  Epoch: 3  Training loss = 1.6476  Validation loss = 3.6319  \n",
      "\n",
      "Fold: 25  Epoch: 4  Training loss = 1.6730  Validation loss = 3.6627  \n",
      "\n",
      "Fold: 25  Epoch: 5  Training loss = 1.6414  Validation loss = 3.3654  \n",
      "\n",
      "Fold: 25  Epoch: 6  Training loss = 1.6787  Validation loss = 3.8759  \n",
      "\n",
      "Fold: 25  Epoch: 7  Training loss = 1.4581  Validation loss = 2.5001  \n",
      "\n",
      "Fold: 25  Epoch: 8  Training loss = 1.4364  Validation loss = 3.3286  \n",
      "\n",
      "Fold: 25  Epoch: 9  Training loss = 1.4582  Validation loss = 2.7587  \n",
      "\n",
      "Fold: 25  Epoch: 10  Training loss = 1.4853  Validation loss = 3.3506  \n",
      "\n",
      "Fold: 25  Epoch: 11  Training loss = 1.4068  Validation loss = 3.4223  \n",
      "\n",
      "Fold: 25  Epoch: 12  Training loss = 1.4343  Validation loss = 3.4793  \n",
      "\n",
      "Fold: 25  Epoch: 13  Training loss = 1.3629  Validation loss = 3.1226  \n",
      "\n",
      "Fold: 25  Epoch: 14  Training loss = 1.3368  Validation loss = 3.1817  \n",
      "\n",
      "Fold: 25  Epoch: 15  Training loss = 1.3082  Validation loss = 3.2525  \n",
      "\n",
      "Fold: 25  Epoch: 16  Training loss = 1.3961  Validation loss = 2.9541  \n",
      "\n",
      "Fold: 25  Epoch: 17  Training loss = 1.4247  Validation loss = 3.1041  \n",
      "\n",
      "Fold: 25  Epoch: 18  Training loss = 1.3970  Validation loss = 2.8541  \n",
      "\n",
      "Fold: 25  Epoch: 19  Training loss = 1.5129  Validation loss = 3.0326  \n",
      "\n",
      "Fold: 25  Epoch: 20  Training loss = 1.3460  Validation loss = 2.8170  \n",
      "\n",
      "Fold: 25  Epoch: 21  Training loss = 1.2718  Validation loss = 2.9529  \n",
      "\n",
      "Fold: 25  Epoch: 22  Training loss = 1.4948  Validation loss = 3.8401  \n",
      "\n",
      "Check model:  Fold: 25  Optimal epoch: 7  \n",
      "\n",
      "Fold: 26  Epoch: 1  Training loss = 1.6331  Validation loss = 1.3799  \n",
      "\n",
      "Fold: 26  Epoch: 2  Training loss = 1.6465  Validation loss = 1.4743  \n",
      "\n",
      "Fold: 26  Epoch: 3  Training loss = 1.4811  Validation loss = 1.6475  \n",
      "\n",
      "Fold: 26  Epoch: 4  Training loss = 1.4346  Validation loss = 1.3608  \n",
      "\n",
      "Fold: 26  Epoch: 5  Training loss = 1.4018  Validation loss = 1.8451  \n",
      "\n",
      "Fold: 26  Epoch: 6  Training loss = 1.4241  Validation loss = 1.5207  \n",
      "\n",
      "Fold: 26  Epoch: 7  Training loss = 1.4414  Validation loss = 1.6974  \n",
      "\n",
      "Fold: 26  Epoch: 8  Training loss = 1.4005  Validation loss = 1.9612  \n",
      "\n",
      "Fold: 26  Epoch: 9  Training loss = 1.3946  Validation loss = 2.0178  \n",
      "\n",
      "Fold: 26  Epoch: 10  Training loss = 1.3257  Validation loss = 1.7925  \n",
      "\n",
      "Fold: 26  Epoch: 11  Training loss = 1.3531  Validation loss = 1.7069  \n",
      "\n",
      "Fold: 26  Epoch: 12  Training loss = 1.3091  Validation loss = 1.7987  \n",
      "\n",
      "Fold: 26  Epoch: 13  Training loss = 1.7656  Validation loss = 1.8371  \n",
      "\n",
      "Fold: 26  Epoch: 14  Training loss = 1.5570  Validation loss = 1.5629  \n",
      "\n",
      "Fold: 26  Epoch: 15  Training loss = 1.3852  Validation loss = 1.9085  \n",
      "\n",
      "Fold: 26  Epoch: 16  Training loss = 1.4430  Validation loss = 1.5396  \n",
      "\n",
      "Fold: 26  Epoch: 17  Training loss = 1.4243  Validation loss = 1.6807  \n",
      "\n",
      "Fold: 26  Epoch: 18  Training loss = 1.5001  Validation loss = 2.2078  \n",
      "\n",
      "Check model:  Fold: 26  Optimal epoch: 4  \n",
      "\n",
      "Fold: 27  Epoch: 1  Training loss = 1.5045  Validation loss = 1.8159  \n",
      "\n",
      "Fold: 27  Epoch: 2  Training loss = 1.4130  Validation loss = 1.5269  \n",
      "\n",
      "Fold: 27  Epoch: 3  Training loss = 1.4123  Validation loss = 1.4911  \n",
      "\n",
      "Fold: 27  Epoch: 4  Training loss = 1.5036  Validation loss = 1.4706  \n",
      "\n",
      "Fold: 27  Epoch: 5  Training loss = 1.5148  Validation loss = 1.8327  \n",
      "\n",
      "Fold: 27  Epoch: 6  Training loss = 1.4298  Validation loss = 1.6532  \n",
      "\n",
      "Fold: 27  Epoch: 7  Training loss = 1.4261  Validation loss = 1.7484  \n",
      "\n",
      "Fold: 27  Epoch: 8  Training loss = 1.3925  Validation loss = 1.9649  \n",
      "\n",
      "Fold: 27  Epoch: 9  Training loss = 1.4047  Validation loss = 1.9802  \n",
      "\n",
      "Fold: 27  Epoch: 10  Training loss = 1.3362  Validation loss = 1.8381  \n",
      "\n",
      "Fold: 27  Epoch: 11  Training loss = 1.3450  Validation loss = 1.7322  \n",
      "\n",
      "Fold: 27  Epoch: 12  Training loss = 1.3547  Validation loss = 1.7496  \n",
      "\n",
      "Fold: 27  Epoch: 13  Training loss = 1.3744  Validation loss = 1.8430  \n",
      "\n",
      "Fold: 27  Epoch: 14  Training loss = 1.3414  Validation loss = 1.8434  \n",
      "\n",
      "Fold: 27  Epoch: 15  Training loss = 1.3266  Validation loss = 1.8586  \n",
      "\n",
      "Fold: 27  Epoch: 16  Training loss = 1.3282  Validation loss = 1.6522  \n",
      "\n",
      "Fold: 27  Epoch: 17  Training loss = 1.3111  Validation loss = 1.6466  \n",
      "\n",
      "Fold: 27  Epoch: 18  Training loss = 1.2800  Validation loss = 1.5095  \n",
      "\n",
      "Fold: 27  Epoch: 19  Training loss = 1.2892  Validation loss = 1.6524  \n",
      "\n",
      "Fold: 27  Epoch: 20  Training loss = 1.3014  Validation loss = 1.6796  \n",
      "\n",
      "Fold: 27  Epoch: 21  Training loss = 1.2460  Validation loss = 1.8128  \n",
      "\n",
      "Fold: 27  Epoch: 22  Training loss = 1.3387  Validation loss = 1.3087  \n",
      "\n",
      "Fold: 27  Epoch: 23  Training loss = 1.3235  Validation loss = 1.3005  \n",
      "\n",
      "Fold: 27  Epoch: 24  Training loss = 1.2157  Validation loss = 1.5328  \n",
      "\n",
      "Fold: 27  Epoch: 25  Training loss = 1.3764  Validation loss = 1.8892  \n",
      "\n",
      "Check model:  Fold: 27  Optimal epoch: 23  \n",
      "\n",
      "Fold: 28  Epoch: 1  Training loss = 1.3890  Validation loss = 1.7566  \n",
      "\n",
      "Fold: 28  Epoch: 2  Training loss = 1.4344  Validation loss = 1.8603  \n",
      "\n",
      "Fold: 28  Epoch: 3  Training loss = 1.3795  Validation loss = 1.7021  \n",
      "\n",
      "Fold: 28  Epoch: 4  Training loss = 1.3873  Validation loss = 1.7523  \n",
      "\n",
      "Fold: 28  Epoch: 5  Training loss = 1.3834  Validation loss = 1.7047  \n",
      "\n",
      "Fold: 28  Epoch: 6  Training loss = 1.3510  Validation loss = 1.7907  \n",
      "\n",
      "Fold: 28  Epoch: 7  Training loss = 1.3266  Validation loss = 1.6385  \n",
      "\n",
      "Fold: 28  Epoch: 8  Training loss = 1.2965  Validation loss = 1.7067  \n",
      "\n",
      "Fold: 28  Epoch: 9  Training loss = 1.3057  Validation loss = 1.6197  \n",
      "\n",
      "Fold: 28  Epoch: 10  Training loss = 1.3077  Validation loss = 1.6608  \n",
      "\n",
      "Fold: 28  Epoch: 11  Training loss = 1.2802  Validation loss = 1.7392  \n",
      "\n",
      "Fold: 28  Epoch: 12  Training loss = 1.2805  Validation loss = 1.6361  \n",
      "\n",
      "Fold: 28  Epoch: 13  Training loss = 1.3278  Validation loss = 1.6491  \n",
      "\n",
      "Fold: 28  Epoch: 14  Training loss = 1.3084  Validation loss = 1.6924  \n",
      "\n",
      "Fold: 28  Epoch: 15  Training loss = 1.2932  Validation loss = 1.5919  \n",
      "\n",
      "Fold: 28  Epoch: 16  Training loss = 1.2747  Validation loss = 1.6927  \n",
      "\n",
      "Fold: 28  Epoch: 17  Training loss = 1.2790  Validation loss = 1.7082  \n",
      "\n",
      "Fold: 28  Epoch: 18  Training loss = 1.2864  Validation loss = 1.6205  \n",
      "\n",
      "Fold: 28  Epoch: 19  Training loss = 1.2792  Validation loss = 1.7508  \n",
      "\n",
      "Check model:  Fold: 28  Optimal epoch: 15  \n",
      "\n",
      "Fold: 29  Epoch: 1  Training loss = 1.3151  Validation loss = 2.2785  \n",
      "\n",
      "Fold: 29  Epoch: 2  Training loss = 1.3306  Validation loss = 2.1661  \n",
      "\n",
      "Fold: 29  Epoch: 3  Training loss = 1.3511  Validation loss = 2.0201  \n",
      "\n",
      "Fold: 29  Epoch: 4  Training loss = 1.3004  Validation loss = 2.0617  \n",
      "\n",
      "Fold: 29  Epoch: 5  Training loss = 1.3516  Validation loss = 2.0858  \n",
      "\n",
      "Fold: 29  Epoch: 6  Training loss = 1.3279  Validation loss = 2.2140  \n",
      "\n",
      "Fold: 29  Epoch: 7  Training loss = 1.3255  Validation loss = 1.9989  \n",
      "\n",
      "Fold: 29  Epoch: 8  Training loss = 1.3021  Validation loss = 2.0157  \n",
      "\n",
      "Fold: 29  Epoch: 9  Training loss = 1.2884  Validation loss = 2.1414  \n",
      "\n",
      "Fold: 29  Epoch: 10  Training loss = 1.2970  Validation loss = 2.0735  \n",
      "\n",
      "Fold: 29  Epoch: 11  Training loss = 1.2802  Validation loss = 2.2266  \n",
      "\n",
      "Check model:  Fold: 29  Optimal epoch: 7  \n",
      "\n",
      "Fold: 30  Epoch: 1  Training loss = 1.3685  Validation loss = 1.8118  \n",
      "\n",
      "Fold: 30  Epoch: 2  Training loss = 1.3716  Validation loss = 1.8053  \n",
      "\n",
      "Fold: 30  Epoch: 3  Training loss = 1.3440  Validation loss = 1.7488  \n",
      "\n",
      "Fold: 30  Epoch: 4  Training loss = 1.4362  Validation loss = 1.9858  \n",
      "\n",
      "Fold: 30  Epoch: 5  Training loss = 1.4470  Validation loss = 1.9593  \n",
      "\n",
      "Fold: 30  Epoch: 6  Training loss = 1.4425  Validation loss = 1.9359  \n",
      "\n",
      "Fold: 30  Epoch: 7  Training loss = 1.3919  Validation loss = 1.8568  \n",
      "\n",
      "Fold: 30  Epoch: 8  Training loss = 1.3870  Validation loss = 2.0224  \n",
      "\n",
      "Fold: 30  Epoch: 9  Training loss = 1.3660  Validation loss = 2.1835  \n",
      "\n",
      "Fold: 30  Epoch: 10  Training loss = 1.3043  Validation loss = 2.0190  \n",
      "\n",
      "Fold: 30  Epoch: 11  Training loss = 1.3665  Validation loss = 2.1001  \n",
      "\n",
      "Fold: 30  Epoch: 12  Training loss = 1.3151  Validation loss = 2.0089  \n",
      "\n",
      "Fold: 30  Epoch: 13  Training loss = 1.3074  Validation loss = 2.0431  \n",
      "\n",
      "Fold: 30  Epoch: 14  Training loss = 1.6597  Validation loss = 2.1417  \n",
      "\n",
      "Fold: 30  Epoch: 15  Training loss = 1.5024  Validation loss = 2.5621  \n",
      "\n",
      "Check model:  Fold: 30  Optimal epoch: 3  \n",
      "\n",
      "Fold: 31  Epoch: 1  Training loss = 1.3970  Validation loss = 1.0522  \n",
      "\n",
      "Fold: 31  Epoch: 2  Training loss = 1.4006  Validation loss = 1.1514  \n",
      "\n",
      "Fold: 31  Epoch: 3  Training loss = 1.3517  Validation loss = 0.8310  \n",
      "\n",
      "Fold: 31  Epoch: 4  Training loss = 1.3770  Validation loss = 1.1416  \n",
      "\n",
      "Fold: 31  Epoch: 5  Training loss = 1.3704  Validation loss = 0.8294  \n",
      "\n",
      "Fold: 31  Epoch: 6  Training loss = 1.3326  Validation loss = 1.0588  \n",
      "\n",
      "Fold: 31  Epoch: 7  Training loss = 1.3031  Validation loss = 0.5692  \n",
      "\n",
      "Fold: 31  Epoch: 8  Training loss = 1.3029  Validation loss = 1.1632  \n",
      "\n",
      "Fold: 31  Epoch: 9  Training loss = 1.3730  Validation loss = 1.3913  \n",
      "\n",
      "Fold: 31  Epoch: 10  Training loss = 1.3743  Validation loss = 0.9144  \n",
      "\n",
      "Fold: 31  Epoch: 11  Training loss = 1.3503  Validation loss = 0.9974  \n",
      "\n",
      "Fold: 31  Epoch: 12  Training loss = 1.3317  Validation loss = 1.2826  \n",
      "\n",
      "Fold: 31  Epoch: 13  Training loss = 1.4544  Validation loss = 1.1064  \n",
      "\n",
      "Fold: 31  Epoch: 14  Training loss = 1.2684  Validation loss = 0.7508  \n",
      "\n",
      "Fold: 31  Epoch: 15  Training loss = 1.1828  Validation loss = 0.7208  \n",
      "\n",
      "Fold: 31  Epoch: 16  Training loss = 1.2645  Validation loss = 0.9311  \n",
      "\n",
      "Fold: 31  Epoch: 17  Training loss = 1.2664  Validation loss = 0.9708  \n",
      "\n",
      "Fold: 31  Epoch: 18  Training loss = 1.2913  Validation loss = 1.1628  \n",
      "\n",
      "Fold: 31  Epoch: 19  Training loss = 1.4459  Validation loss = 1.4629  \n",
      "\n",
      "Check model:  Fold: 31  Optimal epoch: 7  \n",
      "\n",
      "Fold: 32  Epoch: 1  Training loss = 1.2933  Validation loss = 3.7151  \n",
      "\n",
      "Fold: 32  Epoch: 2  Training loss = 1.5096  Validation loss = 4.5457  \n",
      "\n",
      "Fold: 32  Epoch: 3  Training loss = 1.4612  Validation loss = 4.3170  \n",
      "\n",
      "Fold: 32  Epoch: 4  Training loss = 1.3204  Validation loss = 4.0210  \n",
      "\n",
      "Fold: 32  Epoch: 5  Training loss = 1.2988  Validation loss = 3.4963  \n",
      "\n",
      "Fold: 32  Epoch: 6  Training loss = 1.3806  Validation loss = 4.3279  \n",
      "\n",
      "Fold: 32  Epoch: 7  Training loss = 1.2409  Validation loss = 3.6831  \n",
      "\n",
      "Fold: 32  Epoch: 8  Training loss = 1.3008  Validation loss = 3.6059  \n",
      "\n",
      "Fold: 32  Epoch: 9  Training loss = 1.2784  Validation loss = 3.4987  \n",
      "\n",
      "Fold: 32  Epoch: 10  Training loss = 1.3895  Validation loss = 4.1203  \n",
      "\n",
      "Fold: 32  Epoch: 11  Training loss = 1.3997  Validation loss = 4.0553  \n",
      "\n",
      "Fold: 32  Epoch: 12  Training loss = 1.3956  Validation loss = 4.0905  \n",
      "\n",
      "Fold: 32  Epoch: 13  Training loss = 1.4118  Validation loss = 3.9468  \n",
      "\n",
      "Fold: 32  Epoch: 14  Training loss = 1.3893  Validation loss = 3.9543  \n",
      "\n",
      "Fold: 32  Epoch: 15  Training loss = 1.3880  Validation loss = 4.1335  \n",
      "\n",
      "Fold: 32  Epoch: 16  Training loss = 1.4009  Validation loss = 4.1553  \n",
      "\n",
      "Check model:  Fold: 32  Optimal epoch: 5  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 2. Train model\n",
    "# ==================================\n",
    "sess = tf.InteractiveSession()  # Launch Graph\n",
    "sess.run(tf.global_variables_initializer())  # Initialise all variables\n",
    "\n",
    "print(\"Start training\", \n",
    "      \"\\nHyperparameters:\",\n",
    "      \"\\nDimension of recurrent unit =\", n_hidden,\n",
    "      \"\\nLearning rate =\", learning_rate,\n",
    "      \"\\nEpochs =\", epochs,\n",
    "      \"\\nBatch size =\", batch_size,\n",
    "      \"\\nEarly stopping epochs =\", early_stop_iters,\n",
    "      \"\\nLearning rate =\", learning_rate)\n",
    "\n",
    "total_batch = int(window_length / batch_size)\n",
    "validation_fold_error = [] # store validation error of each fold\n",
    "optimal_epochs = []\n",
    "\n",
    "# loop through folds\n",
    "for fold in range(1, len(valIndex)):\n",
    "    validx = train_features[valIndex[fold-1]:valIndex[fold]]\n",
    "    validy = train_target[valIndex[fold-1]:valIndex[fold]]\n",
    "    trainx = train_features[(fold-1)*4:valIndex[(fold-1)]]\n",
    "    trainy = train_target[(fold-1)*4:valIndex[(fold-1)]]\n",
    "\n",
    "    loss_list = [] # store validation loss after each epoch for early stopping\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i in range(total_batch):\n",
    "            # Backprop\n",
    "            batch_xs, batch_ys = next_batch(num=batch_size, data=trainx, labels=trainy)\n",
    "            optimizer.run(feed_dict={x:batch_xs, y:batch_ys, lr:learning_rate})\n",
    "\n",
    "        # Loss\n",
    "        loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "        loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "        loss_list.append(loss_valid)\n",
    "\n",
    "        print(\"Fold: {0:d}\".format(fold),\n",
    "              \" Epoch: {0:d}\".format(epoch+1),\n",
    "              \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "              \" Validation loss = {0:.4f}\".format(np.sqrt(loss_valid)),\n",
    "              \" \\n\")\n",
    "\n",
    "        if all(j <= loss_valid for j in loss_list[-early_stop_iters:]) and len(loss_list)>early_stop_iters:\n",
    "            break\n",
    "    \n",
    "    # Load model with lowest validation error for each fold\n",
    "    epoch_hat = np.argmin(loss_list) + 1\n",
    "    optimal_epochs.append(epoch_hat) # store optimal number of epochs for each fold\n",
    "    \n",
    "    # RMSE\n",
    "    loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "    loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "    validation_fold_error.append(np.sqrt(loss_valid))\n",
    "    \n",
    "    print(\"Check model:\",\n",
    "          \" Fold: {0:d}\".format(fold),\n",
    "          \" Optimal epoch: {0:d}\".format(epoch_hat),\n",
    "          \" \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average number of epochs: 10\n",
      "Average validation error: 3.31378\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 3. Optimal epoch choice\n",
    "# ==================================\n",
    "# Pick number of epochs to train model for out-of-sample testing\n",
    "epoch_hat = int(np.mean(optimal_epochs))\n",
    "print(\"\\nAverage number of epochs:\", epoch_hat)\n",
    "# Average validation error\n",
    "print(\"Average validation error:\", np.mean(validation_fold_error))\n",
    "\n",
    "# Save validated model\n",
    "saveModel(sess, \n",
    "          MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + str(epoch_hat) + \"_validated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fixed scheme:\n",
      "Epoch: 1  Training loss = 1.5142  Test loss = 3.8582  \n",
      "\n",
      "Epoch: 2  Training loss = 1.4947  Test loss = 3.8359  \n",
      "\n",
      "Epoch: 3  Training loss = 1.4795  Test loss = 3.8173  \n",
      "\n",
      "Epoch: 4  Training loss = 1.4675  Test loss = 3.8015  \n",
      "\n",
      "Epoch: 5  Training loss = 1.4574  Test loss = 3.7880  \n",
      "\n",
      "Epoch: 6  Training loss = 1.4482  Test loss = 3.7762  \n",
      "\n",
      "Epoch: 7  Training loss = 1.4395  Test loss = 3.7658  \n",
      "\n",
      "Epoch: 8  Training loss = 1.4311  Test loss = 3.7566  \n",
      "\n",
      "Epoch: 9  Training loss = 1.4228  Test loss = 3.7486  \n",
      "\n",
      "Epoch: 10  Training loss = 1.4147  Test loss = 3.7417  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 4. Fixed scheme\n",
    "# ==================================\n",
    "print(\"\\nFixed scheme:\")\n",
    "for epoch in range(epoch_hat):\n",
    "    x_train = train_features[-window_length:]\n",
    "    y_train = train_target[-window_length:]\n",
    "    optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:test_features, y:test_target})\n",
    "    print(\"Epoch: {0:d}\".format(epoch+1),\n",
    "          \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "          \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "          \" \\n\")\n",
    "\n",
    "# Forecasts\n",
    "yhat_test_fixed = pred.eval(feed_dict={x:test_features})\n",
    "yhat_train_fixed = pred.eval(feed_dict={x:x_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc206cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train set\n",
    "plt.plot(y_train, 'black')\n",
    "plt.plot(yhat_train_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc8d1dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: fixed scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_test_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed scheme RMSE: 3.74168337111 \n",
      "Fixed scheme MAE:  2.79028804114\n"
     ]
    }
   ],
   "source": [
    "rmse_fixed = np.sqrt(np.mean((yhat_test_fixed[:,0]-test_target)**2))\n",
    "mae_fixed = np.mean(np.abs((yhat_test_fixed[:,0]-test_target)))\n",
    "print(\"Fixed scheme RMSE:\", rmse_fixed,\n",
    "     \"\\nFixed scheme MAE: \", mae_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Stack training and test set, this makes updating scheme easier to train\n",
    "all_features = np.concatenate((train_features[-window_length:], test_features), axis=0)\n",
    "all_target = np.concatenate((train_target[-window_length:], test_target), axis=0)\n",
    "\n",
    "# Vectors to store loss and forecasts\n",
    "test_loss = np.zeros(len(test_target))\n",
    "yhat_update = np.zeros(len(test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test period = 1  Training loss = 1.4147  Test loss = 4.7220  Model updated 0 times  \n",
      "\n",
      "Test period = 2  Training loss = 1.5164  Test loss = 2.5393  Model updated 0 times  \n",
      "\n",
      "Test period = 3  Training loss = 1.5478  Test loss = 1.7743  Model updated 0 times  \n",
      "\n",
      "Test period = 4  Training loss = 1.5625  Test loss = 1.8632  Model updated 0 times  \n",
      "\n",
      "Test period = 5  Training loss = 1.0471  Test loss = 2.0151  Model updated 1 times  \n",
      "\n",
      "Test period = 6  Training loss = 1.0765  Test loss = 0.8588  Model updated 1 times  \n",
      "\n",
      "Test period = 7  Training loss = 1.0818  Test loss = 0.2191  Model updated 1 times  \n",
      "\n",
      "Test period = 8  Training loss = 1.0815  Test loss = 1.9023  Model updated 1 times  \n",
      "\n",
      "Test period = 9  Training loss = 1.0096  Test loss = 1.7506  Model updated 2 times  \n",
      "\n",
      "Test period = 10  Training loss = 1.0306  Test loss = 2.7662  Model updated 2 times  \n",
      "\n",
      "Test period = 11  Training loss = 1.0783  Test loss = 1.9697  Model updated 2 times  \n",
      "\n",
      "Test period = 12  Training loss = 1.1051  Test loss = 1.5374  Model updated 2 times  \n",
      "\n",
      "Test period = 13  Training loss = 0.9802  Test loss = 1.5533  Model updated 3 times  \n",
      "\n",
      "Test period = 14  Training loss = 0.9990  Test loss = 1.7076  Model updated 3 times  \n",
      "\n",
      "Test period = 15  Training loss = 1.0206  Test loss = 3.6208  Model updated 3 times  \n",
      "\n",
      "Test period = 16  Training loss = 1.1150  Test loss = 5.9087  Model updated 3 times  \n",
      "\n",
      "Test period = 17  Training loss = 1.2244  Test loss = 5.0030  Model updated 4 times  \n",
      "\n",
      "Test period = 18  Training loss = 1.3727  Test loss = 0.1708  Model updated 4 times  \n",
      "\n",
      "Test period = 19  Training loss = 1.3727  Test loss = 1.7726  Model updated 4 times  \n",
      "\n",
      "Test period = 20  Training loss = 1.3886  Test loss = 1.4513  Model updated 4 times  \n",
      "\n",
      "Test period = 21  Training loss = 1.1180  Test loss = 0.2198  Model updated 5 times  \n",
      "\n",
      "Test period = 22  Training loss = 1.1182  Test loss = 3.3717  Model updated 5 times  \n",
      "\n",
      "Test period = 23  Training loss = 1.1929  Test loss = 0.0428  Model updated 5 times  \n",
      "\n",
      "Test period = 24  Training loss = 1.1924  Test loss = 1.9185  Model updated 5 times  \n",
      "\n",
      "Test period = 25  Training loss = 1.1047  Test loss = 0.0650  Model updated 6 times  \n",
      "\n",
      "Test period = 26  Training loss = 1.1036  Test loss = 0.9459  Model updated 6 times  \n",
      "\n",
      "Test period = 27  Training loss = 1.1098  Test loss = 0.8942  Model updated 6 times  \n",
      "\n",
      "Test period = 28  Training loss = 1.1091  Test loss = 2.4257  Model updated 6 times  \n",
      "\n",
      "Test period = 29  Training loss = 1.0930  Test loss = 1.3520  Model updated 7 times  \n",
      "\n",
      "Test period = 30  Training loss = 1.0856  Test loss = 1.3674  Model updated 7 times  \n",
      "\n",
      "Test period = 31  Training loss = 1.0952  Test loss = 3.7819  Model updated 7 times  \n",
      "\n",
      "Test period = 32  Training loss = 1.1380  Test loss = 0.1622  Model updated 7 times  \n",
      "\n",
      "Test period = 33  Training loss = 1.0544  Test loss = 1.7603  Model updated 8 times  \n",
      "\n",
      "Test period = 34  Training loss = 1.0728  Test loss = 0.2004  Model updated 8 times  \n",
      "\n",
      "Test period = 35  Training loss = 1.0599  Test loss = 0.0299  Model updated 8 times  \n",
      "\n",
      "Test period = 36  Training loss = 1.0594  Test loss = 3.8024  Model updated 8 times  \n",
      "\n",
      "Test period = 37  Training loss = 1.1372  Test loss = 1.2236  Model updated 9 times  \n",
      "\n",
      "Test period = 38  Training loss = 1.0200  Test loss = 1.8669  Model updated 9 times  \n",
      "\n",
      "Test period = 39  Training loss = 1.0452  Test loss = 1.4892  Model updated 9 times  \n",
      "\n",
      "Test period = 40  Training loss = 1.0611  Test loss = 2.2507  Model updated 9 times  \n",
      "\n",
      "Test period = 41  Training loss = 1.0341  Test loss = 0.5895  Model updated 10 times  \n",
      "\n",
      "Test period = 42  Training loss = 1.0367  Test loss = 0.3581  Model updated 10 times  \n",
      "\n",
      "Test period = 43  Training loss = 1.0353  Test loss = 0.2727  Model updated 10 times  \n",
      "\n",
      "Test period = 44  Training loss = 1.0336  Test loss = 15.4968  Model updated 10 times  \n",
      "\n",
      "Test period = 45  Training loss = 2.1896  Test loss = 6.3401  Model updated 11 times  \n",
      "\n",
      "Test period = 46  Training loss = 2.3265  Test loss = 1.4122  Model updated 11 times  \n",
      "\n",
      "Test period = 47  Training loss = 2.3331  Test loss = 0.7965  Model updated 11 times  \n",
      "\n",
      "Test period = 48  Training loss = 2.3344  Test loss = 0.1782  Model updated 11 times  \n",
      "\n",
      "Test period = 49  Training loss = 1.5431  Test loss = 2.1838  Model updated 12 times  \n",
      "\n",
      "Test period = 50  Training loss = 1.5663  Test loss = 7.6512  Model updated 12 times  \n",
      "\n",
      "Test period = 51  Training loss = 1.8314  Test loss = 7.0070  Model updated 12 times  \n",
      "\n",
      "Test period = 52  Training loss = 2.0264  Test loss = 2.0727  Model updated 12 times  \n",
      "\n",
      "Test period = 53  Training loss = 1.5230  Test loss = 1.6451  Model updated 13 times  \n",
      "\n",
      "Test period = 54  Training loss = 1.5361  Test loss = 2.6947  Model updated 13 times  \n",
      "\n",
      "Test period = 55  Training loss = 1.5720  Test loss = 0.3044  Model updated 13 times  \n",
      "\n",
      "Test period = 56  Training loss = 1.5697  Test loss = 0.0290  Model updated 13 times  \n",
      "\n",
      "Test period = 57  Training loss = 1.5112  Test loss = 2.1568  Model updated 14 times  \n",
      "\n",
      "Test period = 58  Training loss = 1.5338  Test loss = 0.8374  Model updated 14 times  \n",
      "\n",
      "Test period = 59  Training loss = 1.5285  Test loss = 0.2647  Model updated 14 times  \n",
      "\n",
      "Test period = 60  Training loss = 1.5262  Test loss = 0.5970  Model updated 14 times  \n",
      "\n",
      "Test period = 61  Training loss = 1.4371  Test loss = 0.6760  Model updated 15 times  \n",
      "\n",
      "Test period = 62  Training loss = 1.4362  Test loss = 1.8211  Model updated 15 times  \n",
      "\n",
      "Test period = 63  Training loss = 1.4508  Test loss = 0.5055  Model updated 15 times  \n",
      "\n",
      "Test period = 64  Training loss = 1.4498  Test loss = 0.1645  Model updated 15 times  \n",
      "\n",
      "Test period = 65  Training loss = 1.3886  Test loss = 1.2327  Model updated 16 times  \n",
      "\n",
      "Test period = 66  Training loss = 1.3930  Test loss = 0.3545  Model updated 16 times  \n",
      "\n",
      "Test period = 67  Training loss = 1.3829  Test loss = 0.8204  Model updated 16 times  \n",
      "\n",
      "Test period = 68  Training loss = 1.3864  Test loss = 4.3925  Model updated 16 times  \n",
      "\n",
      "Test period = 69  Training loss = 1.4892  Test loss = 3.8602  Model updated 17 times  \n",
      "\n",
      "Test period = 70  Training loss = 1.5641  Test loss = 0.8316  Model updated 17 times  \n",
      "\n",
      "Test period = 71  Training loss = 1.5646  Test loss = 0.1755  Model updated 17 times  \n",
      "\n",
      "Test period = 72  Training loss = 1.5647  Test loss = 0.2335  Model updated 17 times  \n",
      "\n",
      "Test period = 73  Training loss = 1.4910  Test loss = 1.7352  Model updated 18 times  \n",
      "\n",
      "Test period = 74  Training loss = 1.5042  Test loss = 0.5096  Model updated 18 times  \n",
      "\n",
      "Test period = 75  Training loss = 1.5035  Test loss = 0.8911  Model updated 18 times  \n",
      "\n",
      "Test period = 76  Training loss = 1.4904  Test loss = 0.5536  Model updated 18 times  \n",
      "\n",
      "Test period = 77  Training loss = 1.3900  Test loss = 0.4569  Model updated 19 times  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "retrain_count = 0\n",
    "for t in range(len(test_target)):\n",
    "    x_test = np.reshape(test_features[t], newshape=(1,4,3))\n",
    "    y_test = test_target[t]\n",
    "    test_loss[t] = np.sqrt(sess.run(loss, feed_dict={x:x_test, y:y_test}))\n",
    "    yhat_update[t] = pred.eval(feed_dict={x:x_test})\n",
    "\n",
    "    x_train = all_features[t:(window_length+t)]\n",
    "    y_train = all_target[t:(window_length+t)]\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:x_test, y:y_test})\n",
    "    \n",
    "    print(\"Test period = {0:d}\".format(t+1),\n",
    "      \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "      \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "      \" Model updated {0:d} times\".format(retrain_count),\n",
    "      \" \\n\")\n",
    "\n",
    "    if (t+1)%4==0:\n",
    "        retrain_count += 1\n",
    "        for epoch in range(epoch_hat):\n",
    "            for i in range(total_batch):\n",
    "                optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nuQDMzFrKBWBm1lIuADOzlnIBmJm11P8Aptrw2h9erXMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd24edd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: updating scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_update, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating scheme RMSE: 2.96527894256 \n",
      "Updating scheme MAE:  1.90102642888\n"
     ]
    }
   ],
   "source": [
    "rmse_update = np.sqrt(np.mean((yhat_update-test_target)**2))\n",
    "mae_update = np.mean(np.abs((yhat_update-test_target)))\n",
    "print(\"Updating scheme RMSE:\", rmse_update,\n",
    "     \"\\nUpdating scheme MAE: \", mae_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + \"yhat_test_fixed.csv\", yhat_test_fixed)\n",
    "np.savetxt(MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + \"yhat_update.csv\", yhat_update)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
