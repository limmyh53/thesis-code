{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Directories\n",
    "MODEL_FOLDER = \"../../../models/lstm/\"\n",
    "MODEL_FILENAME = MODEL_FOLDER + \"4Q/16_units/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: model saver\n",
    "def saveModel(sess, MODEL_FILENAME):\n",
    "    if not os.path.exists(MODEL_FOLDER):\n",
    "        print('Creating path where to save model: ' + MODEL_FOLDER)\n",
    "        os.mkdir(MODEL_FOLDER)\n",
    "\n",
    "    #print('Saving model at: ' + MODEL_FILENAME)\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, MODEL_FILENAME)\n",
    "    #print('Model successfully saved.\\n')\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: model loader\n",
    "def loadModel(sess, MODEL_FILENAME):\n",
    "    if os.path.exists(MODEL_FILENAME + \".index\"):\n",
    "        print('Loading save model from: ' + MODEL_FILENAME)\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, MODEL_FILENAME)\n",
    "        print('Model successfully loaded.\\n')\n",
    "        return True\n",
    "    else:\n",
    "        print('Model file <<' + MODEL_FILENAME + '>> does not exists!')\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Hyperparameters\n",
    "epochs = 500\n",
    "learning_rate = 1e-6\n",
    "batch_size = 5\n",
    "early_stop_iters = 10\n",
    "folds = 32\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 3  # data input\n",
    "n_steps = 4  # timesteps\n",
    "n_hidden = 16 # dimension of recurrent unit\n",
    "\n",
    "# (REPRODUCIBILITY) set random seeds\n",
    "tf.set_random_seed(123)\n",
    "\n",
    "# Define weights and biases\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.truncated_normal([n_hidden, 1], stddev = 1.0 / tf.sqrt(float(n_hidden))),\n",
    "        name='out_weight')\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.zeros([1]),\n",
    "        name='out_bias')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: Build model\n",
    "def RNN(X, weights, biases, n_hidden):\n",
    "\n",
    "    # Define a LSTM cell with tensorflow\n",
    "    lstm_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden, state_is_tuple=True)\n",
    "    outputs, _ = tf.nn.dynamic_rnn(lstm_cell, X, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    out_layer = tf.matmul(outputs[:,-1,:], weights['out']) + biases['out']\n",
    "\n",
    "    return out_layer\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: select batch\n",
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the data...\n",
      "Finished: data loaded. Stats below: \n",
      "Nr of training samples: 193\n",
      "Nr of testing  samples: 77\n",
      "Number of variables: 3\n",
      "Number of lags: 4\n",
      "Window length: 65\n",
      "Number of validation folds: 32\n"
     ]
    }
   ],
   "source": [
    "# =================================\n",
    "# 0. Load dataset\n",
    "# =================================\n",
    "print(\"Loading the data...\")\n",
    "# Training set pre-processing\n",
    "train = pd.read_csv('../../../Data/train.csv')\n",
    "train_4lag_inflation = np.array(train[['inflation.lag4',\n",
    "                                       'inflation.lag5',\n",
    "                                       'inflation.lag6',\n",
    "                                       'inflation.lag7']])\n",
    "train_4lag_unemp = np.array(train[['unemp.lag4',\n",
    "                                   'unemp.lag5',\n",
    "                                   'unemp.lag6',\n",
    "                                   'unemp.lag7']])\n",
    "train_4lag_oil = np.array(train[['oil.lag4',\n",
    "                                 'oil.lag5',\n",
    "                                 'oil.lag6',\n",
    "                                 'oil.lag7']])\n",
    "train_features = np.concatenate((train_4lag_inflation[:,:,np.newaxis], \n",
    "\t                             train_4lag_unemp[:,:,np.newaxis],\n",
    "\t                             train_4lag_oil[:,:,np.newaxis]),\n",
    "\t                             axis=2)\n",
    "train_target = np.array(train['inflation.target'])\n",
    "\n",
    "# Test set pre-processing\n",
    "test = pd.read_csv('../../../Data/test.csv')\n",
    "test_4lag_inflation = np.array(test[['inflation.lag4',\n",
    "                                     'inflation.lag5',\n",
    "                                     'inflation.lag6',\n",
    "                                     'inflation.lag7']])\n",
    "test_4lag_unemp = np.array(test[['unemp.lag4',\n",
    "                                 'unemp.lag5',\n",
    "                                 'unemp.lag6',\n",
    "                                 'unemp.lag7']])\n",
    "test_4lag_oil = np.array(test[['oil.lag4',\n",
    "                               'oil.lag5',\n",
    "                               'oil.lag6',\n",
    "                               'oil.lag7']])\n",
    "test_features = np.concatenate((test_4lag_inflation[:,:,np.newaxis], \n",
    "\t                            test_4lag_unemp[:,:,np.newaxis],\n",
    "\t                            test_4lag_oil[:,:,np.newaxis]),\n",
    "\t                            axis=2)\n",
    "test_target = np.array(test['inflation.target'])\n",
    "\n",
    "(nrTrainSamples, timesteps, variables) = train_features.shape\n",
    "(nrTestSamples, _, _) = test_features.shape\n",
    "\n",
    "# Window length and validation fold index\n",
    "window_length = 65\n",
    "valIndex = np.linspace(start=window_length, stop=nrTrainSamples, \n",
    "                       endpoint=True, num=folds+1, dtype=np.int)\n",
    "\n",
    "print(\"Finished: data loaded. Stats below: \")\n",
    "print(\"Nr of training samples: %d\" % nrTrainSamples)\n",
    "print(\"Nr of testing  samples: %d\" % nrTestSamples)\n",
    "print(\"Number of variables: %d\" % variables)\n",
    "print(\"Number of lags: %d\" % timesteps)\n",
    "print(\"Window length: %d\" % window_length)\n",
    "print(\"Number of validation folds: %d\" % folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 1. Build model\n",
    "# ==================================\n",
    "# tf graph input\n",
    "x = tf.placeholder(\"float\", [None, n_steps, n_input], name='Batch')\n",
    "y = tf.placeholder(\"float\", name='True_labels_of_batch')\n",
    "lr = tf.placeholder(\"float\", name='Learning_rate')\n",
    "\n",
    "# Make predictions with the model\n",
    "pred = RNN(x, weights, biases, n_hidden)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss = tf.reduce_mean(tf.diag_part(tf.square(tf.subtract(x=pred, y=y))))\n",
    "optimizer = tf.train.GradientDescentOptimizer(lr).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training \n",
      "Hyperparameters: \n",
      "Dimension of recurrent unit = 16 \n",
      "Learning rate = 1e-06 \n",
      "Epochs = 500 \n",
      "Batch size = 5 \n",
      "Early stopping epochs = 10 \n",
      "Learning rate = 1e-06\n",
      "Fold: 1  Epoch: 1  Training loss = 3.2108  Validation loss = 3.4320  \n",
      "\n",
      "Fold: 1  Epoch: 2  Training loss = 3.2107  Validation loss = 3.4318  \n",
      "\n",
      "Fold: 1  Epoch: 3  Training loss = 3.2105  Validation loss = 3.4314  \n",
      "\n",
      "Fold: 1  Epoch: 4  Training loss = 3.2103  Validation loss = 3.4311  \n",
      "\n",
      "Fold: 1  Epoch: 5  Training loss = 3.2102  Validation loss = 3.4309  \n",
      "\n",
      "Fold: 1  Epoch: 6  Training loss = 3.2101  Validation loss = 3.4307  \n",
      "\n",
      "Fold: 1  Epoch: 7  Training loss = 3.2099  Validation loss = 3.4304  \n",
      "\n",
      "Fold: 1  Epoch: 8  Training loss = 3.2098  Validation loss = 3.4301  \n",
      "\n",
      "Fold: 1  Epoch: 9  Training loss = 3.2096  Validation loss = 3.4299  \n",
      "\n",
      "Fold: 1  Epoch: 10  Training loss = 3.2095  Validation loss = 3.4297  \n",
      "\n",
      "Fold: 1  Epoch: 11  Training loss = 3.2094  Validation loss = 3.4294  \n",
      "\n",
      "Fold: 1  Epoch: 12  Training loss = 3.2093  Validation loss = 3.4292  \n",
      "\n",
      "Fold: 1  Epoch: 13  Training loss = 3.2091  Validation loss = 3.4289  \n",
      "\n",
      "Fold: 1  Epoch: 14  Training loss = 3.2090  Validation loss = 3.4287  \n",
      "\n",
      "Fold: 1  Epoch: 15  Training loss = 3.2088  Validation loss = 3.4283  \n",
      "\n",
      "Fold: 1  Epoch: 16  Training loss = 3.2086  Validation loss = 3.4281  \n",
      "\n",
      "Fold: 1  Epoch: 17  Training loss = 3.2084  Validation loss = 3.4277  \n",
      "\n",
      "Fold: 1  Epoch: 18  Training loss = 3.2083  Validation loss = 3.4275  \n",
      "\n",
      "Fold: 1  Epoch: 19  Training loss = 3.2081  Validation loss = 3.4272  \n",
      "\n",
      "Fold: 1  Epoch: 20  Training loss = 3.2080  Validation loss = 3.4270  \n",
      "\n",
      "Fold: 1  Epoch: 21  Training loss = 3.2078  Validation loss = 3.4267  \n",
      "\n",
      "Fold: 1  Epoch: 22  Training loss = 3.2077  Validation loss = 3.4264  \n",
      "\n",
      "Fold: 1  Epoch: 23  Training loss = 3.2075  Validation loss = 3.4261  \n",
      "\n",
      "Fold: 1  Epoch: 24  Training loss = 3.2074  Validation loss = 3.4259  \n",
      "\n",
      "Fold: 1  Epoch: 25  Training loss = 3.2073  Validation loss = 3.4256  \n",
      "\n",
      "Fold: 1  Epoch: 26  Training loss = 3.2072  Validation loss = 3.4255  \n",
      "\n",
      "Fold: 1  Epoch: 27  Training loss = 3.2071  Validation loss = 3.4253  \n",
      "\n",
      "Fold: 1  Epoch: 28  Training loss = 3.2070  Validation loss = 3.4250  \n",
      "\n",
      "Fold: 1  Epoch: 29  Training loss = 3.2068  Validation loss = 3.4247  \n",
      "\n",
      "Fold: 1  Epoch: 30  Training loss = 3.2066  Validation loss = 3.4245  \n",
      "\n",
      "Fold: 1  Epoch: 31  Training loss = 3.2065  Validation loss = 3.4242  \n",
      "\n",
      "Fold: 1  Epoch: 32  Training loss = 3.2063  Validation loss = 3.4239  \n",
      "\n",
      "Fold: 1  Epoch: 33  Training loss = 3.2062  Validation loss = 3.4237  \n",
      "\n",
      "Fold: 1  Epoch: 34  Training loss = 3.2061  Validation loss = 3.4234  \n",
      "\n",
      "Fold: 1  Epoch: 35  Training loss = 3.2059  Validation loss = 3.4232  \n",
      "\n",
      "Fold: 1  Epoch: 36  Training loss = 3.2058  Validation loss = 3.4230  \n",
      "\n",
      "Fold: 1  Epoch: 37  Training loss = 3.2057  Validation loss = 3.4227  \n",
      "\n",
      "Fold: 1  Epoch: 38  Training loss = 3.2055  Validation loss = 3.4224  \n",
      "\n",
      "Fold: 1  Epoch: 39  Training loss = 3.2054  Validation loss = 3.4222  \n",
      "\n",
      "Fold: 1  Epoch: 40  Training loss = 3.2052  Validation loss = 3.4219  \n",
      "\n",
      "Fold: 1  Epoch: 41  Training loss = 3.2051  Validation loss = 3.4217  \n",
      "\n",
      "Fold: 1  Epoch: 42  Training loss = 3.2050  Validation loss = 3.4214  \n",
      "\n",
      "Fold: 1  Epoch: 43  Training loss = 3.2049  Validation loss = 3.4212  \n",
      "\n",
      "Fold: 1  Epoch: 44  Training loss = 3.2047  Validation loss = 3.4209  \n",
      "\n",
      "Fold: 1  Epoch: 45  Training loss = 3.2046  Validation loss = 3.4207  \n",
      "\n",
      "Fold: 1  Epoch: 46  Training loss = 3.2045  Validation loss = 3.4205  \n",
      "\n",
      "Fold: 1  Epoch: 47  Training loss = 3.2044  Validation loss = 3.4203  \n",
      "\n",
      "Fold: 1  Epoch: 48  Training loss = 3.2042  Validation loss = 3.4201  \n",
      "\n",
      "Fold: 1  Epoch: 49  Training loss = 3.2041  Validation loss = 3.4197  \n",
      "\n",
      "Fold: 1  Epoch: 50  Training loss = 3.2039  Validation loss = 3.4195  \n",
      "\n",
      "Fold: 1  Epoch: 51  Training loss = 3.2038  Validation loss = 3.4192  \n",
      "\n",
      "Fold: 1  Epoch: 52  Training loss = 3.2037  Validation loss = 3.4191  \n",
      "\n",
      "Fold: 1  Epoch: 53  Training loss = 3.2036  Validation loss = 3.4188  \n",
      "\n",
      "Fold: 1  Epoch: 54  Training loss = 3.2034  Validation loss = 3.4186  \n",
      "\n",
      "Fold: 1  Epoch: 55  Training loss = 3.2033  Validation loss = 3.4184  \n",
      "\n",
      "Fold: 1  Epoch: 56  Training loss = 3.2032  Validation loss = 3.4181  \n",
      "\n",
      "Fold: 1  Epoch: 57  Training loss = 3.2030  Validation loss = 3.4178  \n",
      "\n",
      "Fold: 1  Epoch: 58  Training loss = 3.2029  Validation loss = 3.4176  \n",
      "\n",
      "Fold: 1  Epoch: 59  Training loss = 3.2028  Validation loss = 3.4174  \n",
      "\n",
      "Fold: 1  Epoch: 60  Training loss = 3.2027  Validation loss = 3.4172  \n",
      "\n",
      "Fold: 1  Epoch: 61  Training loss = 3.2026  Validation loss = 3.4170  \n",
      "\n",
      "Fold: 1  Epoch: 62  Training loss = 3.2025  Validation loss = 3.4168  \n",
      "\n",
      "Fold: 1  Epoch: 63  Training loss = 3.2023  Validation loss = 3.4166  \n",
      "\n",
      "Fold: 1  Epoch: 64  Training loss = 3.2022  Validation loss = 3.4162  \n",
      "\n",
      "Fold: 1  Epoch: 65  Training loss = 3.2020  Validation loss = 3.4159  \n",
      "\n",
      "Fold: 1  Epoch: 66  Training loss = 3.2018  Validation loss = 3.4156  \n",
      "\n",
      "Fold: 1  Epoch: 67  Training loss = 3.2017  Validation loss = 3.4154  \n",
      "\n",
      "Fold: 1  Epoch: 68  Training loss = 3.2016  Validation loss = 3.4152  \n",
      "\n",
      "Fold: 1  Epoch: 69  Training loss = 3.2015  Validation loss = 3.4150  \n",
      "\n",
      "Fold: 1  Epoch: 70  Training loss = 3.2013  Validation loss = 3.4147  \n",
      "\n",
      "Fold: 1  Epoch: 71  Training loss = 3.2012  Validation loss = 3.4145  \n",
      "\n",
      "Fold: 1  Epoch: 72  Training loss = 3.2011  Validation loss = 3.4143  \n",
      "\n",
      "Fold: 1  Epoch: 73  Training loss = 3.2010  Validation loss = 3.4141  \n",
      "\n",
      "Fold: 1  Epoch: 74  Training loss = 3.2008  Validation loss = 3.4138  \n",
      "\n",
      "Fold: 1  Epoch: 75  Training loss = 3.2007  Validation loss = 3.4136  \n",
      "\n",
      "Fold: 1  Epoch: 76  Training loss = 3.2006  Validation loss = 3.4134  \n",
      "\n",
      "Fold: 1  Epoch: 77  Training loss = 3.2005  Validation loss = 3.4132  \n",
      "\n",
      "Fold: 1  Epoch: 78  Training loss = 3.2004  Validation loss = 3.4130  \n",
      "\n",
      "Fold: 1  Epoch: 79  Training loss = 3.2003  Validation loss = 3.4128  \n",
      "\n",
      "Fold: 1  Epoch: 80  Training loss = 3.2001  Validation loss = 3.4125  \n",
      "\n",
      "Fold: 1  Epoch: 81  Training loss = 3.2000  Validation loss = 3.4123  \n",
      "\n",
      "Fold: 1  Epoch: 82  Training loss = 3.1999  Validation loss = 3.4121  \n",
      "\n",
      "Fold: 1  Epoch: 83  Training loss = 3.1998  Validation loss = 3.4119  \n",
      "\n",
      "Fold: 1  Epoch: 84  Training loss = 3.1997  Validation loss = 3.4117  \n",
      "\n",
      "Fold: 1  Epoch: 85  Training loss = 3.1995  Validation loss = 3.4114  \n",
      "\n",
      "Fold: 1  Epoch: 86  Training loss = 3.1994  Validation loss = 3.4112  \n",
      "\n",
      "Fold: 1  Epoch: 87  Training loss = 3.1993  Validation loss = 3.4110  \n",
      "\n",
      "Fold: 1  Epoch: 88  Training loss = 3.1992  Validation loss = 3.4107  \n",
      "\n",
      "Fold: 1  Epoch: 89  Training loss = 3.1990  Validation loss = 3.4105  \n",
      "\n",
      "Fold: 1  Epoch: 90  Training loss = 3.1988  Validation loss = 3.4102  \n",
      "\n",
      "Fold: 1  Epoch: 91  Training loss = 3.1987  Validation loss = 3.4099  \n",
      "\n",
      "Fold: 1  Epoch: 92  Training loss = 3.1986  Validation loss = 3.4097  \n",
      "\n",
      "Fold: 1  Epoch: 93  Training loss = 3.1985  Validation loss = 3.4095  \n",
      "\n",
      "Fold: 1  Epoch: 94  Training loss = 3.1983  Validation loss = 3.4092  \n",
      "\n",
      "Fold: 1  Epoch: 95  Training loss = 3.1982  Validation loss = 3.4090  \n",
      "\n",
      "Fold: 1  Epoch: 96  Training loss = 3.1981  Validation loss = 3.4088  \n",
      "\n",
      "Fold: 1  Epoch: 97  Training loss = 3.1980  Validation loss = 3.4086  \n",
      "\n",
      "Fold: 1  Epoch: 98  Training loss = 3.1979  Validation loss = 3.4084  \n",
      "\n",
      "Fold: 1  Epoch: 99  Training loss = 3.1977  Validation loss = 3.4081  \n",
      "\n",
      "Fold: 1  Epoch: 100  Training loss = 3.1976  Validation loss = 3.4079  \n",
      "\n",
      "Fold: 1  Epoch: 101  Training loss = 3.1975  Validation loss = 3.4076  \n",
      "\n",
      "Fold: 1  Epoch: 102  Training loss = 3.1974  Validation loss = 3.4075  \n",
      "\n",
      "Fold: 1  Epoch: 103  Training loss = 3.1973  Validation loss = 3.4072  \n",
      "\n",
      "Fold: 1  Epoch: 104  Training loss = 3.1971  Validation loss = 3.4070  \n",
      "\n",
      "Fold: 1  Epoch: 105  Training loss = 3.1970  Validation loss = 3.4067  \n",
      "\n",
      "Fold: 1  Epoch: 106  Training loss = 3.1968  Validation loss = 3.4065  \n",
      "\n",
      "Fold: 1  Epoch: 107  Training loss = 3.1967  Validation loss = 3.4062  \n",
      "\n",
      "Fold: 1  Epoch: 108  Training loss = 3.1966  Validation loss = 3.4059  \n",
      "\n",
      "Fold: 1  Epoch: 109  Training loss = 3.1964  Validation loss = 3.4057  \n",
      "\n",
      "Fold: 1  Epoch: 110  Training loss = 3.1963  Validation loss = 3.4055  \n",
      "\n",
      "Fold: 1  Epoch: 111  Training loss = 3.1962  Validation loss = 3.4053  \n",
      "\n",
      "Fold: 1  Epoch: 112  Training loss = 3.1961  Validation loss = 3.4050  \n",
      "\n",
      "Fold: 1  Epoch: 113  Training loss = 3.1959  Validation loss = 3.4048  \n",
      "\n",
      "Fold: 1  Epoch: 114  Training loss = 3.1958  Validation loss = 3.4045  \n",
      "\n",
      "Fold: 1  Epoch: 115  Training loss = 3.1956  Validation loss = 3.4042  \n",
      "\n",
      "Fold: 1  Epoch: 116  Training loss = 3.1955  Validation loss = 3.4040  \n",
      "\n",
      "Fold: 1  Epoch: 117  Training loss = 3.1953  Validation loss = 3.4037  \n",
      "\n",
      "Fold: 1  Epoch: 118  Training loss = 3.1952  Validation loss = 3.4035  \n",
      "\n",
      "Fold: 1  Epoch: 119  Training loss = 3.1951  Validation loss = 3.4032  \n",
      "\n",
      "Fold: 1  Epoch: 120  Training loss = 3.1949  Validation loss = 3.4030  \n",
      "\n",
      "Fold: 1  Epoch: 121  Training loss = 3.1948  Validation loss = 3.4027  \n",
      "\n",
      "Fold: 1  Epoch: 122  Training loss = 3.1947  Validation loss = 3.4026  \n",
      "\n",
      "Fold: 1  Epoch: 123  Training loss = 3.1946  Validation loss = 3.4024  \n",
      "\n",
      "Fold: 1  Epoch: 124  Training loss = 3.1944  Validation loss = 3.4020  \n",
      "\n",
      "Fold: 1  Epoch: 125  Training loss = 3.1943  Validation loss = 3.4018  \n",
      "\n",
      "Fold: 1  Epoch: 126  Training loss = 3.1942  Validation loss = 3.4016  \n",
      "\n",
      "Fold: 1  Epoch: 127  Training loss = 3.1940  Validation loss = 3.4014  \n",
      "\n",
      "Fold: 1  Epoch: 128  Training loss = 3.1939  Validation loss = 3.4011  \n",
      "\n",
      "Fold: 1  Epoch: 129  Training loss = 3.1938  Validation loss = 3.4009  \n",
      "\n",
      "Fold: 1  Epoch: 130  Training loss = 3.1936  Validation loss = 3.4006  \n",
      "\n",
      "Fold: 1  Epoch: 131  Training loss = 3.1935  Validation loss = 3.4003  \n",
      "\n",
      "Fold: 1  Epoch: 132  Training loss = 3.1934  Validation loss = 3.4001  \n",
      "\n",
      "Fold: 1  Epoch: 133  Training loss = 3.1933  Validation loss = 3.3999  \n",
      "\n",
      "Fold: 1  Epoch: 134  Training loss = 3.1932  Validation loss = 3.3997  \n",
      "\n",
      "Fold: 1  Epoch: 135  Training loss = 3.1930  Validation loss = 3.3995  \n",
      "\n",
      "Fold: 1  Epoch: 136  Training loss = 3.1929  Validation loss = 3.3993  \n",
      "\n",
      "Fold: 1  Epoch: 137  Training loss = 3.1928  Validation loss = 3.3991  \n",
      "\n",
      "Fold: 1  Epoch: 138  Training loss = 3.1927  Validation loss = 3.3989  \n",
      "\n",
      "Fold: 1  Epoch: 139  Training loss = 3.1926  Validation loss = 3.3986  \n",
      "\n",
      "Fold: 1  Epoch: 140  Training loss = 3.1925  Validation loss = 3.3984  \n",
      "\n",
      "Fold: 1  Epoch: 141  Training loss = 3.1923  Validation loss = 3.3982  \n",
      "\n",
      "Fold: 1  Epoch: 142  Training loss = 3.1922  Validation loss = 3.3979  \n",
      "\n",
      "Fold: 1  Epoch: 143  Training loss = 3.1920  Validation loss = 3.3976  \n",
      "\n",
      "Fold: 1  Epoch: 144  Training loss = 3.1919  Validation loss = 3.3974  \n",
      "\n",
      "Fold: 1  Epoch: 145  Training loss = 3.1918  Validation loss = 3.3971  \n",
      "\n",
      "Fold: 1  Epoch: 146  Training loss = 3.1916  Validation loss = 3.3969  \n",
      "\n",
      "Fold: 1  Epoch: 147  Training loss = 3.1915  Validation loss = 3.3966  \n",
      "\n",
      "Fold: 1  Epoch: 148  Training loss = 3.1914  Validation loss = 3.3965  \n",
      "\n",
      "Fold: 1  Epoch: 149  Training loss = 3.1912  Validation loss = 3.3962  \n",
      "\n",
      "Fold: 1  Epoch: 150  Training loss = 3.1911  Validation loss = 3.3960  \n",
      "\n",
      "Fold: 1  Epoch: 151  Training loss = 3.1910  Validation loss = 3.3958  \n",
      "\n",
      "Fold: 1  Epoch: 152  Training loss = 3.1909  Validation loss = 3.3955  \n",
      "\n",
      "Fold: 1  Epoch: 153  Training loss = 3.1907  Validation loss = 3.3953  \n",
      "\n",
      "Fold: 1  Epoch: 154  Training loss = 3.1906  Validation loss = 3.3950  \n",
      "\n",
      "Fold: 1  Epoch: 155  Training loss = 3.1905  Validation loss = 3.3948  \n",
      "\n",
      "Fold: 1  Epoch: 156  Training loss = 3.1903  Validation loss = 3.3945  \n",
      "\n",
      "Fold: 1  Epoch: 157  Training loss = 3.1902  Validation loss = 3.3943  \n",
      "\n",
      "Fold: 1  Epoch: 158  Training loss = 3.1901  Validation loss = 3.3941  \n",
      "\n",
      "Fold: 1  Epoch: 159  Training loss = 3.1900  Validation loss = 3.3939  \n",
      "\n",
      "Fold: 1  Epoch: 160  Training loss = 3.1898  Validation loss = 3.3936  \n",
      "\n",
      "Fold: 1  Epoch: 161  Training loss = 3.1897  Validation loss = 3.3933  \n",
      "\n",
      "Fold: 1  Epoch: 162  Training loss = 3.1896  Validation loss = 3.3931  \n",
      "\n",
      "Fold: 1  Epoch: 163  Training loss = 3.1895  Validation loss = 3.3929  \n",
      "\n",
      "Fold: 1  Epoch: 164  Training loss = 3.1893  Validation loss = 3.3927  \n",
      "\n",
      "Fold: 1  Epoch: 165  Training loss = 3.1892  Validation loss = 3.3924  \n",
      "\n",
      "Fold: 1  Epoch: 166  Training loss = 3.1891  Validation loss = 3.3922  \n",
      "\n",
      "Fold: 1  Epoch: 167  Training loss = 3.1889  Validation loss = 3.3919  \n",
      "\n",
      "Fold: 1  Epoch: 168  Training loss = 3.1888  Validation loss = 3.3917  \n",
      "\n",
      "Fold: 1  Epoch: 169  Training loss = 3.1887  Validation loss = 3.3915  \n",
      "\n",
      "Fold: 1  Epoch: 170  Training loss = 3.1886  Validation loss = 3.3913  \n",
      "\n",
      "Fold: 1  Epoch: 171  Training loss = 3.1884  Validation loss = 3.3910  \n",
      "\n",
      "Fold: 1  Epoch: 172  Training loss = 3.1883  Validation loss = 3.3907  \n",
      "\n",
      "Fold: 1  Epoch: 173  Training loss = 3.1882  Validation loss = 3.3905  \n",
      "\n",
      "Fold: 1  Epoch: 174  Training loss = 3.1880  Validation loss = 3.3903  \n",
      "\n",
      "Fold: 1  Epoch: 175  Training loss = 3.1879  Validation loss = 3.3901  \n",
      "\n",
      "Fold: 1  Epoch: 176  Training loss = 3.1878  Validation loss = 3.3898  \n",
      "\n",
      "Fold: 1  Epoch: 177  Training loss = 3.1877  Validation loss = 3.3896  \n",
      "\n",
      "Fold: 1  Epoch: 178  Training loss = 3.1876  Validation loss = 3.3894  \n",
      "\n",
      "Fold: 1  Epoch: 179  Training loss = 3.1874  Validation loss = 3.3892  \n",
      "\n",
      "Fold: 1  Epoch: 180  Training loss = 3.1873  Validation loss = 3.3889  \n",
      "\n",
      "Fold: 1  Epoch: 181  Training loss = 3.1872  Validation loss = 3.3887  \n",
      "\n",
      "Fold: 1  Epoch: 182  Training loss = 3.1870  Validation loss = 3.3884  \n",
      "\n",
      "Fold: 1  Epoch: 183  Training loss = 3.1869  Validation loss = 3.3882  \n",
      "\n",
      "Fold: 1  Epoch: 184  Training loss = 3.1867  Validation loss = 3.3879  \n",
      "\n",
      "Fold: 1  Epoch: 185  Training loss = 3.1866  Validation loss = 3.3877  \n",
      "\n",
      "Fold: 1  Epoch: 186  Training loss = 3.1865  Validation loss = 3.3875  \n",
      "\n",
      "Fold: 1  Epoch: 187  Training loss = 3.1864  Validation loss = 3.3873  \n",
      "\n",
      "Fold: 1  Epoch: 188  Training loss = 3.1863  Validation loss = 3.3871  \n",
      "\n",
      "Fold: 1  Epoch: 189  Training loss = 3.1861  Validation loss = 3.3868  \n",
      "\n",
      "Fold: 1  Epoch: 190  Training loss = 3.1860  Validation loss = 3.3866  \n",
      "\n",
      "Fold: 1  Epoch: 191  Training loss = 3.1859  Validation loss = 3.3864  \n",
      "\n",
      "Fold: 1  Epoch: 192  Training loss = 3.1858  Validation loss = 3.3861  \n",
      "\n",
      "Fold: 1  Epoch: 193  Training loss = 3.1856  Validation loss = 3.3859  \n",
      "\n",
      "Fold: 1  Epoch: 194  Training loss = 3.1855  Validation loss = 3.3857  \n",
      "\n",
      "Fold: 1  Epoch: 195  Training loss = 3.1854  Validation loss = 3.3855  \n",
      "\n",
      "Fold: 1  Epoch: 196  Training loss = 3.1853  Validation loss = 3.3853  \n",
      "\n",
      "Fold: 1  Epoch: 197  Training loss = 3.1852  Validation loss = 3.3850  \n",
      "\n",
      "Fold: 1  Epoch: 198  Training loss = 3.1850  Validation loss = 3.3848  \n",
      "\n",
      "Fold: 1  Epoch: 199  Training loss = 3.1849  Validation loss = 3.3846  \n",
      "\n",
      "Fold: 1  Epoch: 200  Training loss = 3.1848  Validation loss = 3.3844  \n",
      "\n",
      "Fold: 1  Epoch: 201  Training loss = 3.1847  Validation loss = 3.3842  \n",
      "\n",
      "Fold: 1  Epoch: 202  Training loss = 3.1846  Validation loss = 3.3840  \n",
      "\n",
      "Fold: 1  Epoch: 203  Training loss = 3.1845  Validation loss = 3.3837  \n",
      "\n",
      "Fold: 1  Epoch: 204  Training loss = 3.1843  Validation loss = 3.3835  \n",
      "\n",
      "Fold: 1  Epoch: 205  Training loss = 3.1842  Validation loss = 3.3833  \n",
      "\n",
      "Fold: 1  Epoch: 206  Training loss = 3.1841  Validation loss = 3.3830  \n",
      "\n",
      "Fold: 1  Epoch: 207  Training loss = 3.1840  Validation loss = 3.3828  \n",
      "\n",
      "Fold: 1  Epoch: 208  Training loss = 3.1838  Validation loss = 3.3826  \n",
      "\n",
      "Fold: 1  Epoch: 209  Training loss = 3.1837  Validation loss = 3.3824  \n",
      "\n",
      "Fold: 1  Epoch: 210  Training loss = 3.1836  Validation loss = 3.3822  \n",
      "\n",
      "Fold: 1  Epoch: 211  Training loss = 3.1835  Validation loss = 3.3819  \n",
      "\n",
      "Fold: 1  Epoch: 212  Training loss = 3.1834  Validation loss = 3.3817  \n",
      "\n",
      "Fold: 1  Epoch: 213  Training loss = 3.1833  Validation loss = 3.3815  \n",
      "\n",
      "Fold: 1  Epoch: 214  Training loss = 3.1831  Validation loss = 3.3813  \n",
      "\n",
      "Fold: 1  Epoch: 215  Training loss = 3.1830  Validation loss = 3.3810  \n",
      "\n",
      "Fold: 1  Epoch: 216  Training loss = 3.1829  Validation loss = 3.3807  \n",
      "\n",
      "Fold: 1  Epoch: 217  Training loss = 3.1827  Validation loss = 3.3805  \n",
      "\n",
      "Fold: 1  Epoch: 218  Training loss = 3.1826  Validation loss = 3.3802  \n",
      "\n",
      "Fold: 1  Epoch: 219  Training loss = 3.1825  Validation loss = 3.3800  \n",
      "\n",
      "Fold: 1  Epoch: 220  Training loss = 3.1823  Validation loss = 3.3798  \n",
      "\n",
      "Fold: 1  Epoch: 221  Training loss = 3.1822  Validation loss = 3.3795  \n",
      "\n",
      "Fold: 1  Epoch: 222  Training loss = 3.1820  Validation loss = 3.3792  \n",
      "\n",
      "Fold: 1  Epoch: 223  Training loss = 3.1819  Validation loss = 3.3790  \n",
      "\n",
      "Fold: 1  Epoch: 224  Training loss = 3.1818  Validation loss = 3.3787  \n",
      "\n",
      "Fold: 1  Epoch: 225  Training loss = 3.1816  Validation loss = 3.3785  \n",
      "\n",
      "Fold: 1  Epoch: 226  Training loss = 3.1815  Validation loss = 3.3783  \n",
      "\n",
      "Fold: 1  Epoch: 227  Training loss = 3.1814  Validation loss = 3.3780  \n",
      "\n",
      "Fold: 1  Epoch: 228  Training loss = 3.1813  Validation loss = 3.3778  \n",
      "\n",
      "Fold: 1  Epoch: 229  Training loss = 3.1811  Validation loss = 3.3776  \n",
      "\n",
      "Fold: 1  Epoch: 230  Training loss = 3.1810  Validation loss = 3.3774  \n",
      "\n",
      "Fold: 1  Epoch: 231  Training loss = 3.1809  Validation loss = 3.3771  \n",
      "\n",
      "Fold: 1  Epoch: 232  Training loss = 3.1807  Validation loss = 3.3768  \n",
      "\n",
      "Fold: 1  Epoch: 233  Training loss = 3.1806  Validation loss = 3.3766  \n",
      "\n",
      "Fold: 1  Epoch: 234  Training loss = 3.1805  Validation loss = 3.3764  \n",
      "\n",
      "Fold: 1  Epoch: 235  Training loss = 3.1804  Validation loss = 3.3762  \n",
      "\n",
      "Fold: 1  Epoch: 236  Training loss = 3.1803  Validation loss = 3.3759  \n",
      "\n",
      "Fold: 1  Epoch: 237  Training loss = 3.1800  Validation loss = 3.3756  \n",
      "\n",
      "Fold: 1  Epoch: 238  Training loss = 3.1799  Validation loss = 3.3754  \n",
      "\n",
      "Fold: 1  Epoch: 239  Training loss = 3.1798  Validation loss = 3.3751  \n",
      "\n",
      "Fold: 1  Epoch: 240  Training loss = 3.1797  Validation loss = 3.3749  \n",
      "\n",
      "Fold: 1  Epoch: 241  Training loss = 3.1795  Validation loss = 3.3746  \n",
      "\n",
      "Fold: 1  Epoch: 242  Training loss = 3.1794  Validation loss = 3.3744  \n",
      "\n",
      "Fold: 1  Epoch: 243  Training loss = 3.1793  Validation loss = 3.3741  \n",
      "\n",
      "Fold: 1  Epoch: 244  Training loss = 3.1791  Validation loss = 3.3739  \n",
      "\n",
      "Fold: 1  Epoch: 245  Training loss = 3.1790  Validation loss = 3.3737  \n",
      "\n",
      "Fold: 1  Epoch: 246  Training loss = 3.1790  Validation loss = 3.3735  \n",
      "\n",
      "Fold: 1  Epoch: 247  Training loss = 3.1788  Validation loss = 3.3733  \n",
      "\n",
      "Fold: 1  Epoch: 248  Training loss = 3.1787  Validation loss = 3.3731  \n",
      "\n",
      "Fold: 1  Epoch: 249  Training loss = 3.1786  Validation loss = 3.3728  \n",
      "\n",
      "Fold: 1  Epoch: 250  Training loss = 3.1784  Validation loss = 3.3725  \n",
      "\n",
      "Fold: 1  Epoch: 251  Training loss = 3.1783  Validation loss = 3.3723  \n",
      "\n",
      "Fold: 1  Epoch: 252  Training loss = 3.1782  Validation loss = 3.3721  \n",
      "\n",
      "Fold: 1  Epoch: 253  Training loss = 3.1781  Validation loss = 3.3719  \n",
      "\n",
      "Fold: 1  Epoch: 254  Training loss = 3.1779  Validation loss = 3.3716  \n",
      "\n",
      "Fold: 1  Epoch: 255  Training loss = 3.1778  Validation loss = 3.3714  \n",
      "\n",
      "Fold: 1  Epoch: 256  Training loss = 3.1777  Validation loss = 3.3712  \n",
      "\n",
      "Fold: 1  Epoch: 257  Training loss = 3.1776  Validation loss = 3.3709  \n",
      "\n",
      "Fold: 1  Epoch: 258  Training loss = 3.1774  Validation loss = 3.3707  \n",
      "\n",
      "Fold: 1  Epoch: 259  Training loss = 3.1773  Validation loss = 3.3705  \n",
      "\n",
      "Fold: 1  Epoch: 260  Training loss = 3.1771  Validation loss = 3.3702  \n",
      "\n",
      "Fold: 1  Epoch: 261  Training loss = 3.1770  Validation loss = 3.3699  \n",
      "\n",
      "Fold: 1  Epoch: 262  Training loss = 3.1769  Validation loss = 3.3697  \n",
      "\n",
      "Fold: 1  Epoch: 263  Training loss = 3.1768  Validation loss = 3.3695  \n",
      "\n",
      "Fold: 1  Epoch: 264  Training loss = 3.1766  Validation loss = 3.3692  \n",
      "\n",
      "Fold: 1  Epoch: 265  Training loss = 3.1765  Validation loss = 3.3690  \n",
      "\n",
      "Fold: 1  Epoch: 266  Training loss = 3.1764  Validation loss = 3.3687  \n",
      "\n",
      "Fold: 1  Epoch: 267  Training loss = 3.1762  Validation loss = 3.3684  \n",
      "\n",
      "Fold: 1  Epoch: 268  Training loss = 3.1761  Validation loss = 3.3682  \n",
      "\n",
      "Fold: 1  Epoch: 269  Training loss = 3.1760  Validation loss = 3.3680  \n",
      "\n",
      "Fold: 1  Epoch: 270  Training loss = 3.1758  Validation loss = 3.3677  \n",
      "\n",
      "Fold: 1  Epoch: 271  Training loss = 3.1757  Validation loss = 3.3676  \n",
      "\n",
      "Fold: 1  Epoch: 272  Training loss = 3.1756  Validation loss = 3.3673  \n",
      "\n",
      "Fold: 1  Epoch: 273  Training loss = 3.1754  Validation loss = 3.3670  \n",
      "\n",
      "Fold: 1  Epoch: 274  Training loss = 3.1753  Validation loss = 3.3668  \n",
      "\n",
      "Fold: 1  Epoch: 275  Training loss = 3.1752  Validation loss = 3.3666  \n",
      "\n",
      "Fold: 1  Epoch: 276  Training loss = 3.1751  Validation loss = 3.3664  \n",
      "\n",
      "Fold: 1  Epoch: 277  Training loss = 3.1750  Validation loss = 3.3662  \n",
      "\n",
      "Fold: 1  Epoch: 278  Training loss = 3.1748  Validation loss = 3.3659  \n",
      "\n",
      "Fold: 1  Epoch: 279  Training loss = 3.1747  Validation loss = 3.3657  \n",
      "\n",
      "Fold: 1  Epoch: 280  Training loss = 3.1746  Validation loss = 3.3654  \n",
      "\n",
      "Fold: 1  Epoch: 281  Training loss = 3.1744  Validation loss = 3.3652  \n",
      "\n",
      "Fold: 1  Epoch: 282  Training loss = 3.1742  Validation loss = 3.3648  \n",
      "\n",
      "Fold: 1  Epoch: 283  Training loss = 3.1741  Validation loss = 3.3646  \n",
      "\n",
      "Fold: 1  Epoch: 284  Training loss = 3.1740  Validation loss = 3.3644  \n",
      "\n",
      "Fold: 1  Epoch: 285  Training loss = 3.1739  Validation loss = 3.3642  \n",
      "\n",
      "Fold: 1  Epoch: 286  Training loss = 3.1738  Validation loss = 3.3640  \n",
      "\n",
      "Fold: 1  Epoch: 287  Training loss = 3.1737  Validation loss = 3.3637  \n",
      "\n",
      "Fold: 1  Epoch: 288  Training loss = 3.1735  Validation loss = 3.3635  \n",
      "\n",
      "Fold: 1  Epoch: 289  Training loss = 3.1734  Validation loss = 3.3632  \n",
      "\n",
      "Fold: 1  Epoch: 290  Training loss = 3.1733  Validation loss = 3.3631  \n",
      "\n",
      "Fold: 1  Epoch: 291  Training loss = 3.1732  Validation loss = 3.3628  \n",
      "\n",
      "Fold: 1  Epoch: 292  Training loss = 3.1730  Validation loss = 3.3626  \n",
      "\n",
      "Fold: 1  Epoch: 293  Training loss = 3.1729  Validation loss = 3.3624  \n",
      "\n",
      "Fold: 1  Epoch: 294  Training loss = 3.1728  Validation loss = 3.3621  \n",
      "\n",
      "Fold: 1  Epoch: 295  Training loss = 3.1727  Validation loss = 3.3619  \n",
      "\n",
      "Fold: 1  Epoch: 296  Training loss = 3.1726  Validation loss = 3.3617  \n",
      "\n",
      "Fold: 1  Epoch: 297  Training loss = 3.1724  Validation loss = 3.3615  \n",
      "\n",
      "Fold: 1  Epoch: 298  Training loss = 3.1723  Validation loss = 3.3612  \n",
      "\n",
      "Fold: 1  Epoch: 299  Training loss = 3.1721  Validation loss = 3.3609  \n",
      "\n",
      "Fold: 1  Epoch: 300  Training loss = 3.1721  Validation loss = 3.3608  \n",
      "\n",
      "Fold: 1  Epoch: 301  Training loss = 3.1719  Validation loss = 3.3605  \n",
      "\n",
      "Fold: 1  Epoch: 302  Training loss = 3.1718  Validation loss = 3.3603  \n",
      "\n",
      "Fold: 1  Epoch: 303  Training loss = 3.1717  Validation loss = 3.3601  \n",
      "\n",
      "Fold: 1  Epoch: 304  Training loss = 3.1715  Validation loss = 3.3598  \n",
      "\n",
      "Fold: 1  Epoch: 305  Training loss = 3.1714  Validation loss = 3.3596  \n",
      "\n",
      "Fold: 1  Epoch: 306  Training loss = 3.1713  Validation loss = 3.3593  \n",
      "\n",
      "Fold: 1  Epoch: 307  Training loss = 3.1711  Validation loss = 3.3590  \n",
      "\n",
      "Fold: 1  Epoch: 308  Training loss = 3.1710  Validation loss = 3.3588  \n",
      "\n",
      "Fold: 1  Epoch: 309  Training loss = 3.1708  Validation loss = 3.3585  \n",
      "\n",
      "Fold: 1  Epoch: 310  Training loss = 3.1707  Validation loss = 3.3583  \n",
      "\n",
      "Fold: 1  Epoch: 311  Training loss = 3.1706  Validation loss = 3.3581  \n",
      "\n",
      "Fold: 1  Epoch: 312  Training loss = 3.1705  Validation loss = 3.3579  \n",
      "\n",
      "Fold: 1  Epoch: 313  Training loss = 3.1704  Validation loss = 3.3577  \n",
      "\n",
      "Fold: 1  Epoch: 314  Training loss = 3.1702  Validation loss = 3.3574  \n",
      "\n",
      "Fold: 1  Epoch: 315  Training loss = 3.1701  Validation loss = 3.3571  \n",
      "\n",
      "Fold: 1  Epoch: 316  Training loss = 3.1700  Validation loss = 3.3569  \n",
      "\n",
      "Fold: 1  Epoch: 317  Training loss = 3.1699  Validation loss = 3.3567  \n",
      "\n",
      "Fold: 1  Epoch: 318  Training loss = 3.1697  Validation loss = 3.3564  \n",
      "\n",
      "Fold: 1  Epoch: 319  Training loss = 3.1696  Validation loss = 3.3561  \n",
      "\n",
      "Fold: 1  Epoch: 320  Training loss = 3.1694  Validation loss = 3.3559  \n",
      "\n",
      "Fold: 1  Epoch: 321  Training loss = 3.1693  Validation loss = 3.3557  \n",
      "\n",
      "Fold: 1  Epoch: 322  Training loss = 3.1692  Validation loss = 3.3555  \n",
      "\n",
      "Fold: 1  Epoch: 323  Training loss = 3.1691  Validation loss = 3.3552  \n",
      "\n",
      "Fold: 1  Epoch: 324  Training loss = 3.1689  Validation loss = 3.3549  \n",
      "\n",
      "Fold: 1  Epoch: 325  Training loss = 3.1687  Validation loss = 3.3546  \n",
      "\n",
      "Fold: 1  Epoch: 326  Training loss = 3.1687  Validation loss = 3.3545  \n",
      "\n",
      "Fold: 1  Epoch: 327  Training loss = 3.1685  Validation loss = 3.3542  \n",
      "\n",
      "Fold: 1  Epoch: 328  Training loss = 3.1684  Validation loss = 3.3540  \n",
      "\n",
      "Fold: 1  Epoch: 329  Training loss = 3.1683  Validation loss = 3.3538  \n",
      "\n",
      "Fold: 1  Epoch: 330  Training loss = 3.1681  Validation loss = 3.3535  \n",
      "\n",
      "Fold: 1  Epoch: 331  Training loss = 3.1680  Validation loss = 3.3533  \n",
      "\n",
      "Fold: 1  Epoch: 332  Training loss = 3.1679  Validation loss = 3.3530  \n",
      "\n",
      "Fold: 1  Epoch: 333  Training loss = 3.1678  Validation loss = 3.3529  \n",
      "\n",
      "Fold: 1  Epoch: 334  Training loss = 3.1677  Validation loss = 3.3526  \n",
      "\n",
      "Fold: 1  Epoch: 335  Training loss = 3.1675  Validation loss = 3.3524  \n",
      "\n",
      "Fold: 1  Epoch: 336  Training loss = 3.1674  Validation loss = 3.3522  \n",
      "\n",
      "Fold: 1  Epoch: 337  Training loss = 3.1673  Validation loss = 3.3519  \n",
      "\n",
      "Fold: 1  Epoch: 338  Training loss = 3.1672  Validation loss = 3.3517  \n",
      "\n",
      "Fold: 1  Epoch: 339  Training loss = 3.1671  Validation loss = 3.3515  \n",
      "\n",
      "Fold: 1  Epoch: 340  Training loss = 3.1670  Validation loss = 3.3513  \n",
      "\n",
      "Fold: 1  Epoch: 341  Training loss = 3.1669  Validation loss = 3.3511  \n",
      "\n",
      "Fold: 1  Epoch: 342  Training loss = 3.1667  Validation loss = 3.3509  \n",
      "\n",
      "Fold: 1  Epoch: 343  Training loss = 3.1666  Validation loss = 3.3506  \n",
      "\n",
      "Fold: 1  Epoch: 344  Training loss = 3.1665  Validation loss = 3.3504  \n",
      "\n",
      "Fold: 1  Epoch: 345  Training loss = 3.1664  Validation loss = 3.3502  \n",
      "\n",
      "Fold: 1  Epoch: 346  Training loss = 3.1663  Validation loss = 3.3500  \n",
      "\n",
      "Fold: 1  Epoch: 347  Training loss = 3.1662  Validation loss = 3.3498  \n",
      "\n",
      "Fold: 1  Epoch: 348  Training loss = 3.1660  Validation loss = 3.3496  \n",
      "\n",
      "Fold: 1  Epoch: 349  Training loss = 3.1659  Validation loss = 3.3493  \n",
      "\n",
      "Fold: 1  Epoch: 350  Training loss = 3.1659  Validation loss = 3.3492  \n",
      "\n",
      "Fold: 1  Epoch: 351  Training loss = 3.1657  Validation loss = 3.3489  \n",
      "\n",
      "Fold: 1  Epoch: 352  Training loss = 3.1656  Validation loss = 3.3487  \n",
      "\n",
      "Fold: 1  Epoch: 353  Training loss = 3.1654  Validation loss = 3.3484  \n",
      "\n",
      "Fold: 1  Epoch: 354  Training loss = 3.1653  Validation loss = 3.3482  \n",
      "\n",
      "Fold: 1  Epoch: 355  Training loss = 3.1651  Validation loss = 3.3479  \n",
      "\n",
      "Fold: 1  Epoch: 356  Training loss = 3.1650  Validation loss = 3.3477  \n",
      "\n",
      "Fold: 1  Epoch: 357  Training loss = 3.1649  Validation loss = 3.3474  \n",
      "\n",
      "Fold: 1  Epoch: 358  Training loss = 3.1648  Validation loss = 3.3472  \n",
      "\n",
      "Fold: 1  Epoch: 359  Training loss = 3.1646  Validation loss = 3.3469  \n",
      "\n",
      "Fold: 1  Epoch: 360  Training loss = 3.1645  Validation loss = 3.3466  \n",
      "\n",
      "Fold: 1  Epoch: 361  Training loss = 3.1644  Validation loss = 3.3465  \n",
      "\n",
      "Fold: 1  Epoch: 362  Training loss = 3.1643  Validation loss = 3.3463  \n",
      "\n",
      "Fold: 1  Epoch: 363  Training loss = 3.1642  Validation loss = 3.3460  \n",
      "\n",
      "Fold: 1  Epoch: 364  Training loss = 3.1640  Validation loss = 3.3458  \n",
      "\n",
      "Fold: 1  Epoch: 365  Training loss = 3.1639  Validation loss = 3.3456  \n",
      "\n",
      "Fold: 1  Epoch: 366  Training loss = 3.1638  Validation loss = 3.3454  \n",
      "\n",
      "Fold: 1  Epoch: 367  Training loss = 3.1637  Validation loss = 3.3451  \n",
      "\n",
      "Fold: 1  Epoch: 368  Training loss = 3.1636  Validation loss = 3.3449  \n",
      "\n",
      "Fold: 1  Epoch: 369  Training loss = 3.1634  Validation loss = 3.3447  \n",
      "\n",
      "Fold: 1  Epoch: 370  Training loss = 3.1633  Validation loss = 3.3444  \n",
      "\n",
      "Fold: 1  Epoch: 371  Training loss = 3.1632  Validation loss = 3.3442  \n",
      "\n",
      "Fold: 1  Epoch: 372  Training loss = 3.1631  Validation loss = 3.3441  \n",
      "\n",
      "Fold: 1  Epoch: 373  Training loss = 3.1630  Validation loss = 3.3439  \n",
      "\n",
      "Fold: 1  Epoch: 374  Training loss = 3.1629  Validation loss = 3.3436  \n",
      "\n",
      "Fold: 1  Epoch: 375  Training loss = 3.1628  Validation loss = 3.3434  \n",
      "\n",
      "Fold: 1  Epoch: 376  Training loss = 3.1627  Validation loss = 3.3432  \n",
      "\n",
      "Fold: 1  Epoch: 377  Training loss = 3.1626  Validation loss = 3.3430  \n",
      "\n",
      "Fold: 1  Epoch: 378  Training loss = 3.1624  Validation loss = 3.3428  \n",
      "\n",
      "Fold: 1  Epoch: 379  Training loss = 3.1623  Validation loss = 3.3426  \n",
      "\n",
      "Fold: 1  Epoch: 380  Training loss = 3.1622  Validation loss = 3.3423  \n",
      "\n",
      "Fold: 1  Epoch: 381  Training loss = 3.1621  Validation loss = 3.3421  \n",
      "\n",
      "Fold: 1  Epoch: 382  Training loss = 3.1620  Validation loss = 3.3419  \n",
      "\n",
      "Fold: 1  Epoch: 383  Training loss = 3.1619  Validation loss = 3.3417  \n",
      "\n",
      "Fold: 1  Epoch: 384  Training loss = 3.1618  Validation loss = 3.3415  \n",
      "\n",
      "Fold: 1  Epoch: 385  Training loss = 3.1616  Validation loss = 3.3413  \n",
      "\n",
      "Fold: 1  Epoch: 386  Training loss = 3.1615  Validation loss = 3.3410  \n",
      "\n",
      "Fold: 1  Epoch: 387  Training loss = 3.1614  Validation loss = 3.3408  \n",
      "\n",
      "Fold: 1  Epoch: 388  Training loss = 3.1613  Validation loss = 3.3406  \n",
      "\n",
      "Fold: 1  Epoch: 389  Training loss = 3.1611  Validation loss = 3.3403  \n",
      "\n",
      "Fold: 1  Epoch: 390  Training loss = 3.1610  Validation loss = 3.3401  \n",
      "\n",
      "Fold: 1  Epoch: 391  Training loss = 3.1609  Validation loss = 3.3399  \n",
      "\n",
      "Fold: 1  Epoch: 392  Training loss = 3.1608  Validation loss = 3.3396  \n",
      "\n",
      "Fold: 1  Epoch: 393  Training loss = 3.1607  Validation loss = 3.3394  \n",
      "\n",
      "Fold: 1  Epoch: 394  Training loss = 3.1606  Validation loss = 3.3393  \n",
      "\n",
      "Fold: 1  Epoch: 395  Training loss = 3.1605  Validation loss = 3.3391  \n",
      "\n",
      "Fold: 1  Epoch: 396  Training loss = 3.1603  Validation loss = 3.3387  \n",
      "\n",
      "Fold: 1  Epoch: 397  Training loss = 3.1602  Validation loss = 3.3385  \n",
      "\n",
      "Fold: 1  Epoch: 398  Training loss = 3.1600  Validation loss = 3.3383  \n",
      "\n",
      "Fold: 1  Epoch: 399  Training loss = 3.1599  Validation loss = 3.3380  \n",
      "\n",
      "Fold: 1  Epoch: 400  Training loss = 3.1598  Validation loss = 3.3378  \n",
      "\n",
      "Fold: 1  Epoch: 401  Training loss = 3.1597  Validation loss = 3.3376  \n",
      "\n",
      "Fold: 1  Epoch: 402  Training loss = 3.1596  Validation loss = 3.3374  \n",
      "\n",
      "Fold: 1  Epoch: 403  Training loss = 3.1595  Validation loss = 3.3372  \n",
      "\n",
      "Fold: 1  Epoch: 404  Training loss = 3.1594  Validation loss = 3.3370  \n",
      "\n",
      "Fold: 1  Epoch: 405  Training loss = 3.1593  Validation loss = 3.3368  \n",
      "\n",
      "Fold: 1  Epoch: 406  Training loss = 3.1591  Validation loss = 3.3365  \n",
      "\n",
      "Fold: 1  Epoch: 407  Training loss = 3.1590  Validation loss = 3.3363  \n",
      "\n",
      "Fold: 1  Epoch: 408  Training loss = 3.1589  Validation loss = 3.3362  \n",
      "\n",
      "Fold: 1  Epoch: 409  Training loss = 3.1588  Validation loss = 3.3359  \n",
      "\n",
      "Fold: 1  Epoch: 410  Training loss = 3.1587  Validation loss = 3.3357  \n",
      "\n",
      "Fold: 1  Epoch: 411  Training loss = 3.1586  Validation loss = 3.3355  \n",
      "\n",
      "Fold: 1  Epoch: 412  Training loss = 3.1585  Validation loss = 3.3352  \n",
      "\n",
      "Fold: 1  Epoch: 413  Training loss = 3.1584  Validation loss = 3.3351  \n",
      "\n",
      "Fold: 1  Epoch: 414  Training loss = 3.1582  Validation loss = 3.3348  \n",
      "\n",
      "Fold: 1  Epoch: 415  Training loss = 3.1581  Validation loss = 3.3345  \n",
      "\n",
      "Fold: 1  Epoch: 416  Training loss = 3.1579  Validation loss = 3.3343  \n",
      "\n",
      "Fold: 1  Epoch: 417  Training loss = 3.1578  Validation loss = 3.3340  \n",
      "\n",
      "Fold: 1  Epoch: 418  Training loss = 3.1576  Validation loss = 3.3338  \n",
      "\n",
      "Fold: 1  Epoch: 419  Training loss = 3.1575  Validation loss = 3.3336  \n",
      "\n",
      "Fold: 1  Epoch: 420  Training loss = 3.1574  Validation loss = 3.3333  \n",
      "\n",
      "Fold: 1  Epoch: 421  Training loss = 3.1573  Validation loss = 3.3331  \n",
      "\n",
      "Fold: 1  Epoch: 422  Training loss = 3.1572  Validation loss = 3.3329  \n",
      "\n",
      "Fold: 1  Epoch: 423  Training loss = 3.1571  Validation loss = 3.3326  \n",
      "\n",
      "Fold: 1  Epoch: 424  Training loss = 3.1570  Validation loss = 3.3324  \n",
      "\n",
      "Fold: 1  Epoch: 425  Training loss = 3.1568  Validation loss = 3.3322  \n",
      "\n",
      "Fold: 1  Epoch: 426  Training loss = 3.1567  Validation loss = 3.3319  \n",
      "\n",
      "Fold: 1  Epoch: 427  Training loss = 3.1566  Validation loss = 3.3317  \n",
      "\n",
      "Fold: 1  Epoch: 428  Training loss = 3.1564  Validation loss = 3.3315  \n",
      "\n",
      "Fold: 1  Epoch: 429  Training loss = 3.1563  Validation loss = 3.3312  \n",
      "\n",
      "Fold: 1  Epoch: 430  Training loss = 3.1562  Validation loss = 3.3310  \n",
      "\n",
      "Fold: 1  Epoch: 431  Training loss = 3.1561  Validation loss = 3.3308  \n",
      "\n",
      "Fold: 1  Epoch: 432  Training loss = 3.1560  Validation loss = 3.3306  \n",
      "\n",
      "Fold: 1  Epoch: 433  Training loss = 3.1559  Validation loss = 3.3304  \n",
      "\n",
      "Fold: 1  Epoch: 434  Training loss = 3.1557  Validation loss = 3.3301  \n",
      "\n",
      "Fold: 1  Epoch: 435  Training loss = 3.1556  Validation loss = 3.3299  \n",
      "\n",
      "Fold: 1  Epoch: 436  Training loss = 3.1554  Validation loss = 3.3296  \n",
      "\n",
      "Fold: 1  Epoch: 437  Training loss = 3.1553  Validation loss = 3.3294  \n",
      "\n",
      "Fold: 1  Epoch: 438  Training loss = 3.1552  Validation loss = 3.3291  \n",
      "\n",
      "Fold: 1  Epoch: 439  Training loss = 3.1550  Validation loss = 3.3289  \n",
      "\n",
      "Fold: 1  Epoch: 440  Training loss = 3.1549  Validation loss = 3.3286  \n",
      "\n",
      "Fold: 1  Epoch: 441  Training loss = 3.1549  Validation loss = 3.3285  \n",
      "\n",
      "Fold: 1  Epoch: 442  Training loss = 3.1547  Validation loss = 3.3283  \n",
      "\n",
      "Fold: 1  Epoch: 443  Training loss = 3.1546  Validation loss = 3.3281  \n",
      "\n",
      "Fold: 1  Epoch: 444  Training loss = 3.1545  Validation loss = 3.3278  \n",
      "\n",
      "Fold: 1  Epoch: 445  Training loss = 3.1544  Validation loss = 3.3276  \n",
      "\n",
      "Fold: 1  Epoch: 446  Training loss = 3.1542  Validation loss = 3.3274  \n",
      "\n",
      "Fold: 1  Epoch: 447  Training loss = 3.1541  Validation loss = 3.3272  \n",
      "\n",
      "Fold: 1  Epoch: 448  Training loss = 3.1540  Validation loss = 3.3269  \n",
      "\n",
      "Fold: 1  Epoch: 449  Training loss = 3.1539  Validation loss = 3.3267  \n",
      "\n",
      "Fold: 1  Epoch: 450  Training loss = 3.1538  Validation loss = 3.3264  \n",
      "\n",
      "Fold: 1  Epoch: 451  Training loss = 3.1536  Validation loss = 3.3262  \n",
      "\n",
      "Fold: 1  Epoch: 452  Training loss = 3.1535  Validation loss = 3.3260  \n",
      "\n",
      "Fold: 1  Epoch: 453  Training loss = 3.1534  Validation loss = 3.3258  \n",
      "\n",
      "Fold: 1  Epoch: 454  Training loss = 3.1533  Validation loss = 3.3256  \n",
      "\n",
      "Fold: 1  Epoch: 455  Training loss = 3.1532  Validation loss = 3.3254  \n",
      "\n",
      "Fold: 1  Epoch: 456  Training loss = 3.1531  Validation loss = 3.3252  \n",
      "\n",
      "Fold: 1  Epoch: 457  Training loss = 3.1530  Validation loss = 3.3250  \n",
      "\n",
      "Fold: 1  Epoch: 458  Training loss = 3.1529  Validation loss = 3.3248  \n",
      "\n",
      "Fold: 1  Epoch: 459  Training loss = 3.1528  Validation loss = 3.3246  \n",
      "\n",
      "Fold: 1  Epoch: 460  Training loss = 3.1526  Validation loss = 3.3243  \n",
      "\n",
      "Fold: 1  Epoch: 461  Training loss = 3.1525  Validation loss = 3.3241  \n",
      "\n",
      "Fold: 1  Epoch: 462  Training loss = 3.1524  Validation loss = 3.3238  \n",
      "\n",
      "Fold: 1  Epoch: 463  Training loss = 3.1523  Validation loss = 3.3236  \n",
      "\n",
      "Fold: 1  Epoch: 464  Training loss = 3.1522  Validation loss = 3.3234  \n",
      "\n",
      "Fold: 1  Epoch: 465  Training loss = 3.1520  Validation loss = 3.3232  \n",
      "\n",
      "Fold: 1  Epoch: 466  Training loss = 3.1519  Validation loss = 3.3230  \n",
      "\n",
      "Fold: 1  Epoch: 467  Training loss = 3.1518  Validation loss = 3.3227  \n",
      "\n",
      "Fold: 1  Epoch: 468  Training loss = 3.1516  Validation loss = 3.3224  \n",
      "\n",
      "Fold: 1  Epoch: 469  Training loss = 3.1515  Validation loss = 3.3222  \n",
      "\n",
      "Fold: 1  Epoch: 470  Training loss = 3.1514  Validation loss = 3.3220  \n",
      "\n",
      "Fold: 1  Epoch: 471  Training loss = 3.1513  Validation loss = 3.3218  \n",
      "\n",
      "Fold: 1  Epoch: 472  Training loss = 3.1512  Validation loss = 3.3216  \n",
      "\n",
      "Fold: 1  Epoch: 473  Training loss = 3.1511  Validation loss = 3.3214  \n",
      "\n",
      "Fold: 1  Epoch: 474  Training loss = 3.1509  Validation loss = 3.3211  \n",
      "\n",
      "Fold: 1  Epoch: 475  Training loss = 3.1509  Validation loss = 3.3210  \n",
      "\n",
      "Fold: 1  Epoch: 476  Training loss = 3.1507  Validation loss = 3.3207  \n",
      "\n",
      "Fold: 1  Epoch: 477  Training loss = 3.1506  Validation loss = 3.3205  \n",
      "\n",
      "Fold: 1  Epoch: 478  Training loss = 3.1505  Validation loss = 3.3203  \n",
      "\n",
      "Fold: 1  Epoch: 479  Training loss = 3.1504  Validation loss = 3.3201  \n",
      "\n",
      "Fold: 1  Epoch: 480  Training loss = 3.1503  Validation loss = 3.3199  \n",
      "\n",
      "Fold: 1  Epoch: 481  Training loss = 3.1502  Validation loss = 3.3197  \n",
      "\n",
      "Fold: 1  Epoch: 482  Training loss = 3.1501  Validation loss = 3.3196  \n",
      "\n",
      "Fold: 1  Epoch: 483  Training loss = 3.1500  Validation loss = 3.3193  \n",
      "\n",
      "Fold: 1  Epoch: 484  Training loss = 3.1499  Validation loss = 3.3192  \n",
      "\n",
      "Fold: 1  Epoch: 485  Training loss = 3.1498  Validation loss = 3.3189  \n",
      "\n",
      "Fold: 1  Epoch: 486  Training loss = 3.1496  Validation loss = 3.3186  \n",
      "\n",
      "Fold: 1  Epoch: 487  Training loss = 3.1495  Validation loss = 3.3184  \n",
      "\n",
      "Fold: 1  Epoch: 488  Training loss = 3.1494  Validation loss = 3.3182  \n",
      "\n",
      "Fold: 1  Epoch: 489  Training loss = 3.1492  Validation loss = 3.3179  \n",
      "\n",
      "Fold: 1  Epoch: 490  Training loss = 3.1491  Validation loss = 3.3177  \n",
      "\n",
      "Fold: 1  Epoch: 491  Training loss = 3.1490  Validation loss = 3.3175  \n",
      "\n",
      "Fold: 1  Epoch: 492  Training loss = 3.1489  Validation loss = 3.3173  \n",
      "\n",
      "Fold: 1  Epoch: 493  Training loss = 3.1488  Validation loss = 3.3171  \n",
      "\n",
      "Fold: 1  Epoch: 494  Training loss = 3.1487  Validation loss = 3.3169  \n",
      "\n",
      "Fold: 1  Epoch: 495  Training loss = 3.1486  Validation loss = 3.3167  \n",
      "\n",
      "Fold: 1  Epoch: 496  Training loss = 3.1485  Validation loss = 3.3165  \n",
      "\n",
      "Fold: 1  Epoch: 497  Training loss = 3.1483  Validation loss = 3.3162  \n",
      "\n",
      "Fold: 1  Epoch: 498  Training loss = 3.1482  Validation loss = 3.3160  \n",
      "\n",
      "Fold: 1  Epoch: 499  Training loss = 3.1481  Validation loss = 3.3158  \n",
      "\n",
      "Fold: 1  Epoch: 500  Training loss = 3.1480  Validation loss = 3.3156  \n",
      "\n",
      "Check model:  Fold: 1  Optimal epoch: 500  \n",
      "\n",
      "Fold: 2  Epoch: 1  Training loss = 3.1063  Validation loss = 3.2985  \n",
      "\n",
      "Fold: 2  Epoch: 2  Training loss = 3.1062  Validation loss = 3.2984  \n",
      "\n",
      "Fold: 2  Epoch: 3  Training loss = 3.1060  Validation loss = 3.2982  \n",
      "\n",
      "Fold: 2  Epoch: 4  Training loss = 3.1059  Validation loss = 3.2980  \n",
      "\n",
      "Fold: 2  Epoch: 5  Training loss = 3.1057  Validation loss = 3.2978  \n",
      "\n",
      "Fold: 2  Epoch: 6  Training loss = 3.1056  Validation loss = 3.2976  \n",
      "\n",
      "Fold: 2  Epoch: 7  Training loss = 3.1054  Validation loss = 3.2975  \n",
      "\n",
      "Fold: 2  Epoch: 8  Training loss = 3.1053  Validation loss = 3.2973  \n",
      "\n",
      "Fold: 2  Epoch: 9  Training loss = 3.1052  Validation loss = 3.2971  \n",
      "\n",
      "Fold: 2  Epoch: 10  Training loss = 3.1051  Validation loss = 3.2970  \n",
      "\n",
      "Fold: 2  Epoch: 11  Training loss = 3.1050  Validation loss = 3.2968  \n",
      "\n",
      "Fold: 2  Epoch: 12  Training loss = 3.1048  Validation loss = 3.2967  \n",
      "\n",
      "Fold: 2  Epoch: 13  Training loss = 3.1047  Validation loss = 3.2965  \n",
      "\n",
      "Fold: 2  Epoch: 14  Training loss = 3.1045  Validation loss = 3.2963  \n",
      "\n",
      "Fold: 2  Epoch: 15  Training loss = 3.1044  Validation loss = 3.2962  \n",
      "\n",
      "Fold: 2  Epoch: 16  Training loss = 3.1043  Validation loss = 3.2960  \n",
      "\n",
      "Fold: 2  Epoch: 17  Training loss = 3.1041  Validation loss = 3.2958  \n",
      "\n",
      "Fold: 2  Epoch: 18  Training loss = 3.1039  Validation loss = 3.2956  \n",
      "\n",
      "Fold: 2  Epoch: 19  Training loss = 3.1038  Validation loss = 3.2954  \n",
      "\n",
      "Fold: 2  Epoch: 20  Training loss = 3.1037  Validation loss = 3.2953  \n",
      "\n",
      "Fold: 2  Epoch: 21  Training loss = 3.1035  Validation loss = 3.2951  \n",
      "\n",
      "Fold: 2  Epoch: 22  Training loss = 3.1034  Validation loss = 3.2949  \n",
      "\n",
      "Fold: 2  Epoch: 23  Training loss = 3.1032  Validation loss = 3.2947  \n",
      "\n",
      "Fold: 2  Epoch: 24  Training loss = 3.1031  Validation loss = 3.2945  \n",
      "\n",
      "Fold: 2  Epoch: 25  Training loss = 3.1029  Validation loss = 3.2944  \n",
      "\n",
      "Fold: 2  Epoch: 26  Training loss = 3.1028  Validation loss = 3.2942  \n",
      "\n",
      "Fold: 2  Epoch: 27  Training loss = 3.1027  Validation loss = 3.2940  \n",
      "\n",
      "Fold: 2  Epoch: 28  Training loss = 3.1025  Validation loss = 3.2938  \n",
      "\n",
      "Fold: 2  Epoch: 29  Training loss = 3.1024  Validation loss = 3.2936  \n",
      "\n",
      "Fold: 2  Epoch: 30  Training loss = 3.1023  Validation loss = 3.2935  \n",
      "\n",
      "Fold: 2  Epoch: 31  Training loss = 3.1022  Validation loss = 3.2934  \n",
      "\n",
      "Fold: 2  Epoch: 32  Training loss = 3.1020  Validation loss = 3.2932  \n",
      "\n",
      "Fold: 2  Epoch: 33  Training loss = 3.1019  Validation loss = 3.2930  \n",
      "\n",
      "Fold: 2  Epoch: 34  Training loss = 3.1018  Validation loss = 3.2928  \n",
      "\n",
      "Fold: 2  Epoch: 35  Training loss = 3.1016  Validation loss = 3.2927  \n",
      "\n",
      "Fold: 2  Epoch: 36  Training loss = 3.1015  Validation loss = 3.2925  \n",
      "\n",
      "Fold: 2  Epoch: 37  Training loss = 3.1013  Validation loss = 3.2923  \n",
      "\n",
      "Fold: 2  Epoch: 38  Training loss = 3.1012  Validation loss = 3.2922  \n",
      "\n",
      "Fold: 2  Epoch: 39  Training loss = 3.1010  Validation loss = 3.2920  \n",
      "\n",
      "Fold: 2  Epoch: 40  Training loss = 3.1009  Validation loss = 3.2919  \n",
      "\n",
      "Fold: 2  Epoch: 41  Training loss = 3.1008  Validation loss = 3.2917  \n",
      "\n",
      "Fold: 2  Epoch: 42  Training loss = 3.1007  Validation loss = 3.2915  \n",
      "\n",
      "Fold: 2  Epoch: 43  Training loss = 3.1006  Validation loss = 3.2914  \n",
      "\n",
      "Fold: 2  Epoch: 44  Training loss = 3.1004  Validation loss = 3.2912  \n",
      "\n",
      "Fold: 2  Epoch: 45  Training loss = 3.1003  Validation loss = 3.2911  \n",
      "\n",
      "Fold: 2  Epoch: 46  Training loss = 3.1002  Validation loss = 3.2909  \n",
      "\n",
      "Fold: 2  Epoch: 47  Training loss = 3.1000  Validation loss = 3.2907  \n",
      "\n",
      "Fold: 2  Epoch: 48  Training loss = 3.0999  Validation loss = 3.2906  \n",
      "\n",
      "Fold: 2  Epoch: 49  Training loss = 3.0997  Validation loss = 3.2903  \n",
      "\n",
      "Fold: 2  Epoch: 50  Training loss = 3.0995  Validation loss = 3.2901  \n",
      "\n",
      "Fold: 2  Epoch: 51  Training loss = 3.0994  Validation loss = 3.2900  \n",
      "\n",
      "Fold: 2  Epoch: 52  Training loss = 3.0992  Validation loss = 3.2898  \n",
      "\n",
      "Fold: 2  Epoch: 53  Training loss = 3.0991  Validation loss = 3.2897  \n",
      "\n",
      "Fold: 2  Epoch: 54  Training loss = 3.0990  Validation loss = 3.2895  \n",
      "\n",
      "Fold: 2  Epoch: 55  Training loss = 3.0988  Validation loss = 3.2893  \n",
      "\n",
      "Fold: 2  Epoch: 56  Training loss = 3.0987  Validation loss = 3.2891  \n",
      "\n",
      "Fold: 2  Epoch: 57  Training loss = 3.0985  Validation loss = 3.2889  \n",
      "\n",
      "Fold: 2  Epoch: 58  Training loss = 3.0984  Validation loss = 3.2888  \n",
      "\n",
      "Fold: 2  Epoch: 59  Training loss = 3.0983  Validation loss = 3.2886  \n",
      "\n",
      "Fold: 2  Epoch: 60  Training loss = 3.0981  Validation loss = 3.2884  \n",
      "\n",
      "Fold: 2  Epoch: 61  Training loss = 3.0980  Validation loss = 3.2882  \n",
      "\n",
      "Fold: 2  Epoch: 62  Training loss = 3.0979  Validation loss = 3.2881  \n",
      "\n",
      "Fold: 2  Epoch: 63  Training loss = 3.0977  Validation loss = 3.2879  \n",
      "\n",
      "Fold: 2  Epoch: 64  Training loss = 3.0976  Validation loss = 3.2877  \n",
      "\n",
      "Fold: 2  Epoch: 65  Training loss = 3.0974  Validation loss = 3.2875  \n",
      "\n",
      "Fold: 2  Epoch: 66  Training loss = 3.0973  Validation loss = 3.2874  \n",
      "\n",
      "Fold: 2  Epoch: 67  Training loss = 3.0971  Validation loss = 3.2872  \n",
      "\n",
      "Fold: 2  Epoch: 68  Training loss = 3.0970  Validation loss = 3.2871  \n",
      "\n",
      "Fold: 2  Epoch: 69  Training loss = 3.0969  Validation loss = 3.2869  \n",
      "\n",
      "Fold: 2  Epoch: 70  Training loss = 3.0968  Validation loss = 3.2867  \n",
      "\n",
      "Fold: 2  Epoch: 71  Training loss = 3.0966  Validation loss = 3.2866  \n",
      "\n",
      "Fold: 2  Epoch: 72  Training loss = 3.0965  Validation loss = 3.2864  \n",
      "\n",
      "Fold: 2  Epoch: 73  Training loss = 3.0964  Validation loss = 3.2863  \n",
      "\n",
      "Fold: 2  Epoch: 74  Training loss = 3.0963  Validation loss = 3.2861  \n",
      "\n",
      "Fold: 2  Epoch: 75  Training loss = 3.0962  Validation loss = 3.2860  \n",
      "\n",
      "Fold: 2  Epoch: 76  Training loss = 3.0960  Validation loss = 3.2858  \n",
      "\n",
      "Fold: 2  Epoch: 77  Training loss = 3.0958  Validation loss = 3.2856  \n",
      "\n",
      "Fold: 2  Epoch: 78  Training loss = 3.0957  Validation loss = 3.2854  \n",
      "\n",
      "Fold: 2  Epoch: 79  Training loss = 3.0955  Validation loss = 3.2852  \n",
      "\n",
      "Fold: 2  Epoch: 80  Training loss = 3.0954  Validation loss = 3.2850  \n",
      "\n",
      "Fold: 2  Epoch: 81  Training loss = 3.0952  Validation loss = 3.2848  \n",
      "\n",
      "Fold: 2  Epoch: 82  Training loss = 3.0951  Validation loss = 3.2846  \n",
      "\n",
      "Fold: 2  Epoch: 83  Training loss = 3.0949  Validation loss = 3.2845  \n",
      "\n",
      "Fold: 2  Epoch: 84  Training loss = 3.0948  Validation loss = 3.2843  \n",
      "\n",
      "Fold: 2  Epoch: 85  Training loss = 3.0947  Validation loss = 3.2841  \n",
      "\n",
      "Fold: 2  Epoch: 86  Training loss = 3.0946  Validation loss = 3.2840  \n",
      "\n",
      "Fold: 2  Epoch: 87  Training loss = 3.0945  Validation loss = 3.2838  \n",
      "\n",
      "Fold: 2  Epoch: 88  Training loss = 3.0944  Validation loss = 3.2837  \n",
      "\n",
      "Fold: 2  Epoch: 89  Training loss = 3.0942  Validation loss = 3.2835  \n",
      "\n",
      "Fold: 2  Epoch: 90  Training loss = 3.0941  Validation loss = 3.2834  \n",
      "\n",
      "Fold: 2  Epoch: 91  Training loss = 3.0940  Validation loss = 3.2832  \n",
      "\n",
      "Fold: 2  Epoch: 92  Training loss = 3.0939  Validation loss = 3.2830  \n",
      "\n",
      "Fold: 2  Epoch: 93  Training loss = 3.0937  Validation loss = 3.2829  \n",
      "\n",
      "Fold: 2  Epoch: 94  Training loss = 3.0936  Validation loss = 3.2827  \n",
      "\n",
      "Fold: 2  Epoch: 95  Training loss = 3.0935  Validation loss = 3.2825  \n",
      "\n",
      "Fold: 2  Epoch: 96  Training loss = 3.0934  Validation loss = 3.2824  \n",
      "\n",
      "Fold: 2  Epoch: 97  Training loss = 3.0933  Validation loss = 3.2822  \n",
      "\n",
      "Fold: 2  Epoch: 98  Training loss = 3.0932  Validation loss = 3.2821  \n",
      "\n",
      "Fold: 2  Epoch: 99  Training loss = 3.0931  Validation loss = 3.2820  \n",
      "\n",
      "Fold: 2  Epoch: 100  Training loss = 3.0929  Validation loss = 3.2818  \n",
      "\n",
      "Fold: 2  Epoch: 101  Training loss = 3.0928  Validation loss = 3.2816  \n",
      "\n",
      "Fold: 2  Epoch: 102  Training loss = 3.0926  Validation loss = 3.2814  \n",
      "\n",
      "Fold: 2  Epoch: 103  Training loss = 3.0925  Validation loss = 3.2813  \n",
      "\n",
      "Fold: 2  Epoch: 104  Training loss = 3.0924  Validation loss = 3.2811  \n",
      "\n",
      "Fold: 2  Epoch: 105  Training loss = 3.0923  Validation loss = 3.2810  \n",
      "\n",
      "Fold: 2  Epoch: 106  Training loss = 3.0921  Validation loss = 3.2808  \n",
      "\n",
      "Fold: 2  Epoch: 107  Training loss = 3.0920  Validation loss = 3.2807  \n",
      "\n",
      "Fold: 2  Epoch: 108  Training loss = 3.0918  Validation loss = 3.2805  \n",
      "\n",
      "Fold: 2  Epoch: 109  Training loss = 3.0917  Validation loss = 3.2803  \n",
      "\n",
      "Fold: 2  Epoch: 110  Training loss = 3.0916  Validation loss = 3.2802  \n",
      "\n",
      "Fold: 2  Epoch: 111  Training loss = 3.0915  Validation loss = 3.2800  \n",
      "\n",
      "Fold: 2  Epoch: 112  Training loss = 3.0914  Validation loss = 3.2799  \n",
      "\n",
      "Fold: 2  Epoch: 113  Training loss = 3.0912  Validation loss = 3.2797  \n",
      "\n",
      "Fold: 2  Epoch: 114  Training loss = 3.0911  Validation loss = 3.2796  \n",
      "\n",
      "Fold: 2  Epoch: 115  Training loss = 3.0910  Validation loss = 3.2794  \n",
      "\n",
      "Fold: 2  Epoch: 116  Training loss = 3.0909  Validation loss = 3.2793  \n",
      "\n",
      "Fold: 2  Epoch: 117  Training loss = 3.0908  Validation loss = 3.2792  \n",
      "\n",
      "Fold: 2  Epoch: 118  Training loss = 3.0906  Validation loss = 3.2789  \n",
      "\n",
      "Fold: 2  Epoch: 119  Training loss = 3.0905  Validation loss = 3.2788  \n",
      "\n",
      "Fold: 2  Epoch: 120  Training loss = 3.0904  Validation loss = 3.2786  \n",
      "\n",
      "Fold: 2  Epoch: 121  Training loss = 3.0902  Validation loss = 3.2785  \n",
      "\n",
      "Fold: 2  Epoch: 122  Training loss = 3.0901  Validation loss = 3.2783  \n",
      "\n",
      "Fold: 2  Epoch: 123  Training loss = 3.0900  Validation loss = 3.2782  \n",
      "\n",
      "Fold: 2  Epoch: 124  Training loss = 3.0898  Validation loss = 3.2780  \n",
      "\n",
      "Fold: 2  Epoch: 125  Training loss = 3.0897  Validation loss = 3.2778  \n",
      "\n",
      "Fold: 2  Epoch: 126  Training loss = 3.0896  Validation loss = 3.2777  \n",
      "\n",
      "Fold: 2  Epoch: 127  Training loss = 3.0895  Validation loss = 3.2775  \n",
      "\n",
      "Fold: 2  Epoch: 128  Training loss = 3.0893  Validation loss = 3.2773  \n",
      "\n",
      "Fold: 2  Epoch: 129  Training loss = 3.0892  Validation loss = 3.2772  \n",
      "\n",
      "Fold: 2  Epoch: 130  Training loss = 3.0891  Validation loss = 3.2770  \n",
      "\n",
      "Fold: 2  Epoch: 131  Training loss = 3.0890  Validation loss = 3.2769  \n",
      "\n",
      "Fold: 2  Epoch: 132  Training loss = 3.0888  Validation loss = 3.2767  \n",
      "\n",
      "Fold: 2  Epoch: 133  Training loss = 3.0887  Validation loss = 3.2766  \n",
      "\n",
      "Fold: 2  Epoch: 134  Training loss = 3.0886  Validation loss = 3.2764  \n",
      "\n",
      "Fold: 2  Epoch: 135  Training loss = 3.0885  Validation loss = 3.2763  \n",
      "\n",
      "Fold: 2  Epoch: 136  Training loss = 3.0884  Validation loss = 3.2761  \n",
      "\n",
      "Fold: 2  Epoch: 137  Training loss = 3.0883  Validation loss = 3.2760  \n",
      "\n",
      "Fold: 2  Epoch: 138  Training loss = 3.0882  Validation loss = 3.2758  \n",
      "\n",
      "Fold: 2  Epoch: 139  Training loss = 3.0880  Validation loss = 3.2756  \n",
      "\n",
      "Fold: 2  Epoch: 140  Training loss = 3.0879  Validation loss = 3.2755  \n",
      "\n",
      "Fold: 2  Epoch: 141  Training loss = 3.0878  Validation loss = 3.2754  \n",
      "\n",
      "Fold: 2  Epoch: 142  Training loss = 3.0877  Validation loss = 3.2752  \n",
      "\n",
      "Fold: 2  Epoch: 143  Training loss = 3.0876  Validation loss = 3.2750  \n",
      "\n",
      "Fold: 2  Epoch: 144  Training loss = 3.0874  Validation loss = 3.2749  \n",
      "\n",
      "Fold: 2  Epoch: 145  Training loss = 3.0873  Validation loss = 3.2748  \n",
      "\n",
      "Fold: 2  Epoch: 146  Training loss = 3.0872  Validation loss = 3.2746  \n",
      "\n",
      "Fold: 2  Epoch: 147  Training loss = 3.0871  Validation loss = 3.2744  \n",
      "\n",
      "Fold: 2  Epoch: 148  Training loss = 3.0870  Validation loss = 3.2743  \n",
      "\n",
      "Fold: 2  Epoch: 149  Training loss = 3.0869  Validation loss = 3.2741  \n",
      "\n",
      "Fold: 2  Epoch: 150  Training loss = 3.0867  Validation loss = 3.2739  \n",
      "\n",
      "Fold: 2  Epoch: 151  Training loss = 3.0866  Validation loss = 3.2738  \n",
      "\n",
      "Fold: 2  Epoch: 152  Training loss = 3.0864  Validation loss = 3.2736  \n",
      "\n",
      "Fold: 2  Epoch: 153  Training loss = 3.0863  Validation loss = 3.2734  \n",
      "\n",
      "Fold: 2  Epoch: 154  Training loss = 3.0862  Validation loss = 3.2733  \n",
      "\n",
      "Fold: 2  Epoch: 155  Training loss = 3.0861  Validation loss = 3.2732  \n",
      "\n",
      "Fold: 2  Epoch: 156  Training loss = 3.0860  Validation loss = 3.2730  \n",
      "\n",
      "Fold: 2  Epoch: 157  Training loss = 3.0858  Validation loss = 3.2728  \n",
      "\n",
      "Fold: 2  Epoch: 158  Training loss = 3.0857  Validation loss = 3.2727  \n",
      "\n",
      "Fold: 2  Epoch: 159  Training loss = 3.0856  Validation loss = 3.2725  \n",
      "\n",
      "Fold: 2  Epoch: 160  Training loss = 3.0854  Validation loss = 3.2723  \n",
      "\n",
      "Fold: 2  Epoch: 161  Training loss = 3.0853  Validation loss = 3.2722  \n",
      "\n",
      "Fold: 2  Epoch: 162  Training loss = 3.0852  Validation loss = 3.2720  \n",
      "\n",
      "Fold: 2  Epoch: 163  Training loss = 3.0851  Validation loss = 3.2718  \n",
      "\n",
      "Fold: 2  Epoch: 164  Training loss = 3.0849  Validation loss = 3.2717  \n",
      "\n",
      "Fold: 2  Epoch: 165  Training loss = 3.0848  Validation loss = 3.2715  \n",
      "\n",
      "Fold: 2  Epoch: 166  Training loss = 3.0846  Validation loss = 3.2713  \n",
      "\n",
      "Fold: 2  Epoch: 167  Training loss = 3.0845  Validation loss = 3.2712  \n",
      "\n",
      "Fold: 2  Epoch: 168  Training loss = 3.0844  Validation loss = 3.2710  \n",
      "\n",
      "Fold: 2  Epoch: 169  Training loss = 3.0843  Validation loss = 3.2708  \n",
      "\n",
      "Fold: 2  Epoch: 170  Training loss = 3.0842  Validation loss = 3.2707  \n",
      "\n",
      "Fold: 2  Epoch: 171  Training loss = 3.0840  Validation loss = 3.2705  \n",
      "\n",
      "Fold: 2  Epoch: 172  Training loss = 3.0839  Validation loss = 3.2704  \n",
      "\n",
      "Fold: 2  Epoch: 173  Training loss = 3.0838  Validation loss = 3.2702  \n",
      "\n",
      "Fold: 2  Epoch: 174  Training loss = 3.0837  Validation loss = 3.2700  \n",
      "\n",
      "Fold: 2  Epoch: 175  Training loss = 3.0836  Validation loss = 3.2699  \n",
      "\n",
      "Fold: 2  Epoch: 176  Training loss = 3.0834  Validation loss = 3.2698  \n",
      "\n",
      "Fold: 2  Epoch: 177  Training loss = 3.0833  Validation loss = 3.2696  \n",
      "\n",
      "Fold: 2  Epoch: 178  Training loss = 3.0832  Validation loss = 3.2694  \n",
      "\n",
      "Fold: 2  Epoch: 179  Training loss = 3.0830  Validation loss = 3.2693  \n",
      "\n",
      "Fold: 2  Epoch: 180  Training loss = 3.0829  Validation loss = 3.2691  \n",
      "\n",
      "Fold: 2  Epoch: 181  Training loss = 3.0828  Validation loss = 3.2689  \n",
      "\n",
      "Fold: 2  Epoch: 182  Training loss = 3.0827  Validation loss = 3.2688  \n",
      "\n",
      "Fold: 2  Epoch: 183  Training loss = 3.0826  Validation loss = 3.2686  \n",
      "\n",
      "Fold: 2  Epoch: 184  Training loss = 3.0824  Validation loss = 3.2684  \n",
      "\n",
      "Fold: 2  Epoch: 185  Training loss = 3.0823  Validation loss = 3.2683  \n",
      "\n",
      "Fold: 2  Epoch: 186  Training loss = 3.0822  Validation loss = 3.2682  \n",
      "\n",
      "Fold: 2  Epoch: 187  Training loss = 3.0821  Validation loss = 3.2680  \n",
      "\n",
      "Fold: 2  Epoch: 188  Training loss = 3.0820  Validation loss = 3.2679  \n",
      "\n",
      "Fold: 2  Epoch: 189  Training loss = 3.0819  Validation loss = 3.2677  \n",
      "\n",
      "Fold: 2  Epoch: 190  Training loss = 3.0818  Validation loss = 3.2676  \n",
      "\n",
      "Fold: 2  Epoch: 191  Training loss = 3.0817  Validation loss = 3.2674  \n",
      "\n",
      "Fold: 2  Epoch: 192  Training loss = 3.0816  Validation loss = 3.2673  \n",
      "\n",
      "Fold: 2  Epoch: 193  Training loss = 3.0815  Validation loss = 3.2671  \n",
      "\n",
      "Fold: 2  Epoch: 194  Training loss = 3.0813  Validation loss = 3.2669  \n",
      "\n",
      "Fold: 2  Epoch: 195  Training loss = 3.0811  Validation loss = 3.2667  \n",
      "\n",
      "Fold: 2  Epoch: 196  Training loss = 3.0810  Validation loss = 3.2665  \n",
      "\n",
      "Fold: 2  Epoch: 197  Training loss = 3.0808  Validation loss = 3.2663  \n",
      "\n",
      "Fold: 2  Epoch: 198  Training loss = 3.0807  Validation loss = 3.2662  \n",
      "\n",
      "Fold: 2  Epoch: 199  Training loss = 3.0806  Validation loss = 3.2660  \n",
      "\n",
      "Fold: 2  Epoch: 200  Training loss = 3.0805  Validation loss = 3.2659  \n",
      "\n",
      "Fold: 2  Epoch: 201  Training loss = 3.0803  Validation loss = 3.2657  \n",
      "\n",
      "Fold: 2  Epoch: 202  Training loss = 3.0802  Validation loss = 3.2655  \n",
      "\n",
      "Fold: 2  Epoch: 203  Training loss = 3.0801  Validation loss = 3.2653  \n",
      "\n",
      "Fold: 2  Epoch: 204  Training loss = 3.0800  Validation loss = 3.2652  \n",
      "\n",
      "Fold: 2  Epoch: 205  Training loss = 3.0798  Validation loss = 3.2650  \n",
      "\n",
      "Fold: 2  Epoch: 206  Training loss = 3.0797  Validation loss = 3.2649  \n",
      "\n",
      "Fold: 2  Epoch: 207  Training loss = 3.0796  Validation loss = 3.2647  \n",
      "\n",
      "Fold: 2  Epoch: 208  Training loss = 3.0795  Validation loss = 3.2646  \n",
      "\n",
      "Fold: 2  Epoch: 209  Training loss = 3.0794  Validation loss = 3.2645  \n",
      "\n",
      "Fold: 2  Epoch: 210  Training loss = 3.0793  Validation loss = 3.2643  \n",
      "\n",
      "Fold: 2  Epoch: 211  Training loss = 3.0791  Validation loss = 3.2641  \n",
      "\n",
      "Fold: 2  Epoch: 212  Training loss = 3.0790  Validation loss = 3.2640  \n",
      "\n",
      "Fold: 2  Epoch: 213  Training loss = 3.0789  Validation loss = 3.2639  \n",
      "\n",
      "Fold: 2  Epoch: 214  Training loss = 3.0788  Validation loss = 3.2637  \n",
      "\n",
      "Fold: 2  Epoch: 215  Training loss = 3.0787  Validation loss = 3.2635  \n",
      "\n",
      "Fold: 2  Epoch: 216  Training loss = 3.0785  Validation loss = 3.2634  \n",
      "\n",
      "Fold: 2  Epoch: 217  Training loss = 3.0784  Validation loss = 3.2632  \n",
      "\n",
      "Fold: 2  Epoch: 218  Training loss = 3.0783  Validation loss = 3.2630  \n",
      "\n",
      "Fold: 2  Epoch: 219  Training loss = 3.0782  Validation loss = 3.2629  \n",
      "\n",
      "Fold: 2  Epoch: 220  Training loss = 3.0780  Validation loss = 3.2627  \n",
      "\n",
      "Fold: 2  Epoch: 221  Training loss = 3.0779  Validation loss = 3.2625  \n",
      "\n",
      "Fold: 2  Epoch: 222  Training loss = 3.0777  Validation loss = 3.2623  \n",
      "\n",
      "Fold: 2  Epoch: 223  Training loss = 3.0776  Validation loss = 3.2622  \n",
      "\n",
      "Fold: 2  Epoch: 224  Training loss = 3.0775  Validation loss = 3.2620  \n",
      "\n",
      "Fold: 2  Epoch: 225  Training loss = 3.0774  Validation loss = 3.2619  \n",
      "\n",
      "Fold: 2  Epoch: 226  Training loss = 3.0773  Validation loss = 3.2617  \n",
      "\n",
      "Fold: 2  Epoch: 227  Training loss = 3.0772  Validation loss = 3.2616  \n",
      "\n",
      "Fold: 2  Epoch: 228  Training loss = 3.0770  Validation loss = 3.2614  \n",
      "\n",
      "Fold: 2  Epoch: 229  Training loss = 3.0769  Validation loss = 3.2612  \n",
      "\n",
      "Fold: 2  Epoch: 230  Training loss = 3.0767  Validation loss = 3.2610  \n",
      "\n",
      "Fold: 2  Epoch: 231  Training loss = 3.0766  Validation loss = 3.2609  \n",
      "\n",
      "Fold: 2  Epoch: 232  Training loss = 3.0765  Validation loss = 3.2607  \n",
      "\n",
      "Fold: 2  Epoch: 233  Training loss = 3.0764  Validation loss = 3.2606  \n",
      "\n",
      "Fold: 2  Epoch: 234  Training loss = 3.0762  Validation loss = 3.2604  \n",
      "\n",
      "Fold: 2  Epoch: 235  Training loss = 3.0761  Validation loss = 3.2603  \n",
      "\n",
      "Fold: 2  Epoch: 236  Training loss = 3.0760  Validation loss = 3.2602  \n",
      "\n",
      "Fold: 2  Epoch: 237  Training loss = 3.0759  Validation loss = 3.2600  \n",
      "\n",
      "Fold: 2  Epoch: 238  Training loss = 3.0758  Validation loss = 3.2598  \n",
      "\n",
      "Fold: 2  Epoch: 239  Training loss = 3.0756  Validation loss = 3.2597  \n",
      "\n",
      "Fold: 2  Epoch: 240  Training loss = 3.0755  Validation loss = 3.2595  \n",
      "\n",
      "Fold: 2  Epoch: 241  Training loss = 3.0754  Validation loss = 3.2594  \n",
      "\n",
      "Fold: 2  Epoch: 242  Training loss = 3.0753  Validation loss = 3.2592  \n",
      "\n",
      "Fold: 2  Epoch: 243  Training loss = 3.0752  Validation loss = 3.2591  \n",
      "\n",
      "Fold: 2  Epoch: 244  Training loss = 3.0751  Validation loss = 3.2589  \n",
      "\n",
      "Fold: 2  Epoch: 245  Training loss = 3.0749  Validation loss = 3.2588  \n",
      "\n",
      "Fold: 2  Epoch: 246  Training loss = 3.0749  Validation loss = 3.2586  \n",
      "\n",
      "Fold: 2  Epoch: 247  Training loss = 3.0748  Validation loss = 3.2585  \n",
      "\n",
      "Fold: 2  Epoch: 248  Training loss = 3.0747  Validation loss = 3.2584  \n",
      "\n",
      "Fold: 2  Epoch: 249  Training loss = 3.0746  Validation loss = 3.2582  \n",
      "\n",
      "Fold: 2  Epoch: 250  Training loss = 3.0744  Validation loss = 3.2580  \n",
      "\n",
      "Fold: 2  Epoch: 251  Training loss = 3.0743  Validation loss = 3.2579  \n",
      "\n",
      "Fold: 2  Epoch: 252  Training loss = 3.0742  Validation loss = 3.2578  \n",
      "\n",
      "Fold: 2  Epoch: 253  Training loss = 3.0741  Validation loss = 3.2576  \n",
      "\n",
      "Fold: 2  Epoch: 254  Training loss = 3.0740  Validation loss = 3.2575  \n",
      "\n",
      "Fold: 2  Epoch: 255  Training loss = 3.0739  Validation loss = 3.2573  \n",
      "\n",
      "Fold: 2  Epoch: 256  Training loss = 3.0737  Validation loss = 3.2571  \n",
      "\n",
      "Fold: 2  Epoch: 257  Training loss = 3.0736  Validation loss = 3.2570  \n",
      "\n",
      "Fold: 2  Epoch: 258  Training loss = 3.0735  Validation loss = 3.2568  \n",
      "\n",
      "Fold: 2  Epoch: 259  Training loss = 3.0733  Validation loss = 3.2566  \n",
      "\n",
      "Fold: 2  Epoch: 260  Training loss = 3.0732  Validation loss = 3.2565  \n",
      "\n",
      "Fold: 2  Epoch: 261  Training loss = 3.0730  Validation loss = 3.2563  \n",
      "\n",
      "Fold: 2  Epoch: 262  Training loss = 3.0729  Validation loss = 3.2561  \n",
      "\n",
      "Fold: 2  Epoch: 263  Training loss = 3.0728  Validation loss = 3.2560  \n",
      "\n",
      "Fold: 2  Epoch: 264  Training loss = 3.0727  Validation loss = 3.2558  \n",
      "\n",
      "Fold: 2  Epoch: 265  Training loss = 3.0725  Validation loss = 3.2556  \n",
      "\n",
      "Fold: 2  Epoch: 266  Training loss = 3.0724  Validation loss = 3.2555  \n",
      "\n",
      "Fold: 2  Epoch: 267  Training loss = 3.0723  Validation loss = 3.2554  \n",
      "\n",
      "Fold: 2  Epoch: 268  Training loss = 3.0722  Validation loss = 3.2552  \n",
      "\n",
      "Fold: 2  Epoch: 269  Training loss = 3.0721  Validation loss = 3.2550  \n",
      "\n",
      "Fold: 2  Epoch: 270  Training loss = 3.0720  Validation loss = 3.2549  \n",
      "\n",
      "Fold: 2  Epoch: 271  Training loss = 3.0719  Validation loss = 3.2548  \n",
      "\n",
      "Fold: 2  Epoch: 272  Training loss = 3.0718  Validation loss = 3.2547  \n",
      "\n",
      "Fold: 2  Epoch: 273  Training loss = 3.0717  Validation loss = 3.2545  \n",
      "\n",
      "Fold: 2  Epoch: 274  Training loss = 3.0716  Validation loss = 3.2544  \n",
      "\n",
      "Fold: 2  Epoch: 275  Training loss = 3.0714  Validation loss = 3.2542  \n",
      "\n",
      "Fold: 2  Epoch: 276  Training loss = 3.0714  Validation loss = 3.2541  \n",
      "\n",
      "Fold: 2  Epoch: 277  Training loss = 3.0713  Validation loss = 3.2539  \n",
      "\n",
      "Fold: 2  Epoch: 278  Training loss = 3.0711  Validation loss = 3.2538  \n",
      "\n",
      "Fold: 2  Epoch: 279  Training loss = 3.0710  Validation loss = 3.2536  \n",
      "\n",
      "Fold: 2  Epoch: 280  Training loss = 3.0709  Validation loss = 3.2534  \n",
      "\n",
      "Fold: 2  Epoch: 281  Training loss = 3.0708  Validation loss = 3.2533  \n",
      "\n",
      "Fold: 2  Epoch: 282  Training loss = 3.0706  Validation loss = 3.2531  \n",
      "\n",
      "Fold: 2  Epoch: 283  Training loss = 3.0705  Validation loss = 3.2530  \n",
      "\n",
      "Fold: 2  Epoch: 284  Training loss = 3.0704  Validation loss = 3.2528  \n",
      "\n",
      "Fold: 2  Epoch: 285  Training loss = 3.0703  Validation loss = 3.2527  \n",
      "\n",
      "Fold: 2  Epoch: 286  Training loss = 3.0702  Validation loss = 3.2525  \n",
      "\n",
      "Fold: 2  Epoch: 287  Training loss = 3.0701  Validation loss = 3.2524  \n",
      "\n",
      "Fold: 2  Epoch: 288  Training loss = 3.0700  Validation loss = 3.2522  \n",
      "\n",
      "Fold: 2  Epoch: 289  Training loss = 3.0698  Validation loss = 3.2521  \n",
      "\n",
      "Fold: 2  Epoch: 290  Training loss = 3.0697  Validation loss = 3.2519  \n",
      "\n",
      "Fold: 2  Epoch: 291  Training loss = 3.0696  Validation loss = 3.2517  \n",
      "\n",
      "Fold: 2  Epoch: 292  Training loss = 3.0695  Validation loss = 3.2516  \n",
      "\n",
      "Fold: 2  Epoch: 293  Training loss = 3.0694  Validation loss = 3.2514  \n",
      "\n",
      "Fold: 2  Epoch: 294  Training loss = 3.0692  Validation loss = 3.2512  \n",
      "\n",
      "Fold: 2  Epoch: 295  Training loss = 3.0691  Validation loss = 3.2511  \n",
      "\n",
      "Fold: 2  Epoch: 296  Training loss = 3.0690  Validation loss = 3.2509  \n",
      "\n",
      "Fold: 2  Epoch: 297  Training loss = 3.0688  Validation loss = 3.2507  \n",
      "\n",
      "Fold: 2  Epoch: 298  Training loss = 3.0687  Validation loss = 3.2505  \n",
      "\n",
      "Fold: 2  Epoch: 299  Training loss = 3.0686  Validation loss = 3.2504  \n",
      "\n",
      "Fold: 2  Epoch: 300  Training loss = 3.0684  Validation loss = 3.2502  \n",
      "\n",
      "Fold: 2  Epoch: 301  Training loss = 3.0683  Validation loss = 3.2501  \n",
      "\n",
      "Fold: 2  Epoch: 302  Training loss = 3.0682  Validation loss = 3.2499  \n",
      "\n",
      "Fold: 2  Epoch: 303  Training loss = 3.0681  Validation loss = 3.2498  \n",
      "\n",
      "Fold: 2  Epoch: 304  Training loss = 3.0680  Validation loss = 3.2496  \n",
      "\n",
      "Fold: 2  Epoch: 305  Training loss = 3.0679  Validation loss = 3.2495  \n",
      "\n",
      "Fold: 2  Epoch: 306  Training loss = 3.0678  Validation loss = 3.2494  \n",
      "\n",
      "Fold: 2  Epoch: 307  Training loss = 3.0677  Validation loss = 3.2492  \n",
      "\n",
      "Fold: 2  Epoch: 308  Training loss = 3.0676  Validation loss = 3.2491  \n",
      "\n",
      "Fold: 2  Epoch: 309  Training loss = 3.0675  Validation loss = 3.2489  \n",
      "\n",
      "Fold: 2  Epoch: 310  Training loss = 3.0674  Validation loss = 3.2488  \n",
      "\n",
      "Fold: 2  Epoch: 311  Training loss = 3.0673  Validation loss = 3.2487  \n",
      "\n",
      "Fold: 2  Epoch: 312  Training loss = 3.0671  Validation loss = 3.2485  \n",
      "\n",
      "Fold: 2  Epoch: 313  Training loss = 3.0670  Validation loss = 3.2484  \n",
      "\n",
      "Fold: 2  Epoch: 314  Training loss = 3.0669  Validation loss = 3.2483  \n",
      "\n",
      "Fold: 2  Epoch: 315  Training loss = 3.0668  Validation loss = 3.2481  \n",
      "\n",
      "Fold: 2  Epoch: 316  Training loss = 3.0666  Validation loss = 3.2479  \n",
      "\n",
      "Fold: 2  Epoch: 317  Training loss = 3.0665  Validation loss = 3.2477  \n",
      "\n",
      "Fold: 2  Epoch: 318  Training loss = 3.0664  Validation loss = 3.2476  \n",
      "\n",
      "Fold: 2  Epoch: 319  Training loss = 3.0663  Validation loss = 3.2475  \n",
      "\n",
      "Fold: 2  Epoch: 320  Training loss = 3.0662  Validation loss = 3.2473  \n",
      "\n",
      "Fold: 2  Epoch: 321  Training loss = 3.0660  Validation loss = 3.2471  \n",
      "\n",
      "Fold: 2  Epoch: 322  Training loss = 3.0659  Validation loss = 3.2470  \n",
      "\n",
      "Fold: 2  Epoch: 323  Training loss = 3.0658  Validation loss = 3.2468  \n",
      "\n",
      "Fold: 2  Epoch: 324  Training loss = 3.0657  Validation loss = 3.2467  \n",
      "\n",
      "Fold: 2  Epoch: 325  Training loss = 3.0655  Validation loss = 3.2465  \n",
      "\n",
      "Fold: 2  Epoch: 326  Training loss = 3.0654  Validation loss = 3.2464  \n",
      "\n",
      "Fold: 2  Epoch: 327  Training loss = 3.0653  Validation loss = 3.2462  \n",
      "\n",
      "Fold: 2  Epoch: 328  Training loss = 3.0652  Validation loss = 3.2460  \n",
      "\n",
      "Fold: 2  Epoch: 329  Training loss = 3.0650  Validation loss = 3.2459  \n",
      "\n",
      "Fold: 2  Epoch: 330  Training loss = 3.0649  Validation loss = 3.2458  \n",
      "\n",
      "Fold: 2  Epoch: 331  Training loss = 3.0649  Validation loss = 3.2457  \n",
      "\n",
      "Fold: 2  Epoch: 332  Training loss = 3.0647  Validation loss = 3.2455  \n",
      "\n",
      "Fold: 2  Epoch: 333  Training loss = 3.0646  Validation loss = 3.2453  \n",
      "\n",
      "Fold: 2  Epoch: 334  Training loss = 3.0644  Validation loss = 3.2451  \n",
      "\n",
      "Fold: 2  Epoch: 335  Training loss = 3.0643  Validation loss = 3.2450  \n",
      "\n",
      "Fold: 2  Epoch: 336  Training loss = 3.0642  Validation loss = 3.2448  \n",
      "\n",
      "Fold: 2  Epoch: 337  Training loss = 3.0641  Validation loss = 3.2447  \n",
      "\n",
      "Fold: 2  Epoch: 338  Training loss = 3.0639  Validation loss = 3.2445  \n",
      "\n",
      "Fold: 2  Epoch: 339  Training loss = 3.0638  Validation loss = 3.2444  \n",
      "\n",
      "Fold: 2  Epoch: 340  Training loss = 3.0637  Validation loss = 3.2442  \n",
      "\n",
      "Fold: 2  Epoch: 341  Training loss = 3.0636  Validation loss = 3.2441  \n",
      "\n",
      "Fold: 2  Epoch: 342  Training loss = 3.0634  Validation loss = 3.2438  \n",
      "\n",
      "Fold: 2  Epoch: 343  Training loss = 3.0633  Validation loss = 3.2437  \n",
      "\n",
      "Fold: 2  Epoch: 344  Training loss = 3.0631  Validation loss = 3.2435  \n",
      "\n",
      "Fold: 2  Epoch: 345  Training loss = 3.0630  Validation loss = 3.2434  \n",
      "\n",
      "Fold: 2  Epoch: 346  Training loss = 3.0629  Validation loss = 3.2432  \n",
      "\n",
      "Fold: 2  Epoch: 347  Training loss = 3.0628  Validation loss = 3.2431  \n",
      "\n",
      "Fold: 2  Epoch: 348  Training loss = 3.0627  Validation loss = 3.2429  \n",
      "\n",
      "Fold: 2  Epoch: 349  Training loss = 3.0626  Validation loss = 3.2428  \n",
      "\n",
      "Fold: 2  Epoch: 350  Training loss = 3.0625  Validation loss = 3.2426  \n",
      "\n",
      "Fold: 2  Epoch: 351  Training loss = 3.0623  Validation loss = 3.2425  \n",
      "\n",
      "Fold: 2  Epoch: 352  Training loss = 3.0622  Validation loss = 3.2424  \n",
      "\n",
      "Fold: 2  Epoch: 353  Training loss = 3.0622  Validation loss = 3.2422  \n",
      "\n",
      "Fold: 2  Epoch: 354  Training loss = 3.0620  Validation loss = 3.2421  \n",
      "\n",
      "Fold: 2  Epoch: 355  Training loss = 3.0619  Validation loss = 3.2419  \n",
      "\n",
      "Fold: 2  Epoch: 356  Training loss = 3.0618  Validation loss = 3.2418  \n",
      "\n",
      "Fold: 2  Epoch: 357  Training loss = 3.0617  Validation loss = 3.2416  \n",
      "\n",
      "Fold: 2  Epoch: 358  Training loss = 3.0616  Validation loss = 3.2415  \n",
      "\n",
      "Fold: 2  Epoch: 359  Training loss = 3.0615  Validation loss = 3.2413  \n",
      "\n",
      "Fold: 2  Epoch: 360  Training loss = 3.0613  Validation loss = 3.2411  \n",
      "\n",
      "Fold: 2  Epoch: 361  Training loss = 3.0612  Validation loss = 3.2409  \n",
      "\n",
      "Fold: 2  Epoch: 362  Training loss = 3.0611  Validation loss = 3.2408  \n",
      "\n",
      "Fold: 2  Epoch: 363  Training loss = 3.0610  Validation loss = 3.2407  \n",
      "\n",
      "Fold: 2  Epoch: 364  Training loss = 3.0610  Validation loss = 3.2406  \n",
      "\n",
      "Fold: 2  Epoch: 365  Training loss = 3.0609  Validation loss = 3.2404  \n",
      "\n",
      "Fold: 2  Epoch: 366  Training loss = 3.0607  Validation loss = 3.2403  \n",
      "\n",
      "Fold: 2  Epoch: 367  Training loss = 3.0606  Validation loss = 3.2401  \n",
      "\n",
      "Fold: 2  Epoch: 368  Training loss = 3.0605  Validation loss = 3.2400  \n",
      "\n",
      "Fold: 2  Epoch: 369  Training loss = 3.0604  Validation loss = 3.2398  \n",
      "\n",
      "Fold: 2  Epoch: 370  Training loss = 3.0602  Validation loss = 3.2397  \n",
      "\n",
      "Fold: 2  Epoch: 371  Training loss = 3.0601  Validation loss = 3.2395  \n",
      "\n",
      "Fold: 2  Epoch: 372  Training loss = 3.0600  Validation loss = 3.2394  \n",
      "\n",
      "Fold: 2  Epoch: 373  Training loss = 3.0599  Validation loss = 3.2392  \n",
      "\n",
      "Fold: 2  Epoch: 374  Training loss = 3.0598  Validation loss = 3.2391  \n",
      "\n",
      "Fold: 2  Epoch: 375  Training loss = 3.0597  Validation loss = 3.2389  \n",
      "\n",
      "Fold: 2  Epoch: 376  Training loss = 3.0596  Validation loss = 3.2388  \n",
      "\n",
      "Fold: 2  Epoch: 377  Training loss = 3.0594  Validation loss = 3.2386  \n",
      "\n",
      "Fold: 2  Epoch: 378  Training loss = 3.0594  Validation loss = 3.2385  \n",
      "\n",
      "Fold: 2  Epoch: 379  Training loss = 3.0593  Validation loss = 3.2384  \n",
      "\n",
      "Fold: 2  Epoch: 380  Training loss = 3.0591  Validation loss = 3.2382  \n",
      "\n",
      "Fold: 2  Epoch: 381  Training loss = 3.0590  Validation loss = 3.2381  \n",
      "\n",
      "Fold: 2  Epoch: 382  Training loss = 3.0590  Validation loss = 3.2380  \n",
      "\n",
      "Fold: 2  Epoch: 383  Training loss = 3.0589  Validation loss = 3.2378  \n",
      "\n",
      "Fold: 2  Epoch: 384  Training loss = 3.0588  Validation loss = 3.2377  \n",
      "\n",
      "Fold: 2  Epoch: 385  Training loss = 3.0586  Validation loss = 3.2375  \n",
      "\n",
      "Fold: 2  Epoch: 386  Training loss = 3.0585  Validation loss = 3.2374  \n",
      "\n",
      "Fold: 2  Epoch: 387  Training loss = 3.0584  Validation loss = 3.2373  \n",
      "\n",
      "Fold: 2  Epoch: 388  Training loss = 3.0583  Validation loss = 3.2371  \n",
      "\n",
      "Fold: 2  Epoch: 389  Training loss = 3.0582  Validation loss = 3.2370  \n",
      "\n",
      "Fold: 2  Epoch: 390  Training loss = 3.0581  Validation loss = 3.2368  \n",
      "\n",
      "Fold: 2  Epoch: 391  Training loss = 3.0580  Validation loss = 3.2367  \n",
      "\n",
      "Fold: 2  Epoch: 392  Training loss = 3.0579  Validation loss = 3.2365  \n",
      "\n",
      "Fold: 2  Epoch: 393  Training loss = 3.0578  Validation loss = 3.2364  \n",
      "\n",
      "Fold: 2  Epoch: 394  Training loss = 3.0576  Validation loss = 3.2363  \n",
      "\n",
      "Fold: 2  Epoch: 395  Training loss = 3.0575  Validation loss = 3.2361  \n",
      "\n",
      "Fold: 2  Epoch: 396  Training loss = 3.0574  Validation loss = 3.2359  \n",
      "\n",
      "Fold: 2  Epoch: 397  Training loss = 3.0573  Validation loss = 3.2358  \n",
      "\n",
      "Fold: 2  Epoch: 398  Training loss = 3.0571  Validation loss = 3.2356  \n",
      "\n",
      "Fold: 2  Epoch: 399  Training loss = 3.0570  Validation loss = 3.2355  \n",
      "\n",
      "Fold: 2  Epoch: 400  Training loss = 3.0569  Validation loss = 3.2353  \n",
      "\n",
      "Fold: 2  Epoch: 401  Training loss = 3.0568  Validation loss = 3.2352  \n",
      "\n",
      "Fold: 2  Epoch: 402  Training loss = 3.0567  Validation loss = 3.2350  \n",
      "\n",
      "Fold: 2  Epoch: 403  Training loss = 3.0565  Validation loss = 3.2349  \n",
      "\n",
      "Fold: 2  Epoch: 404  Training loss = 3.0564  Validation loss = 3.2347  \n",
      "\n",
      "Fold: 2  Epoch: 405  Training loss = 3.0563  Validation loss = 3.2345  \n",
      "\n",
      "Fold: 2  Epoch: 406  Training loss = 3.0562  Validation loss = 3.2344  \n",
      "\n",
      "Fold: 2  Epoch: 407  Training loss = 3.0561  Validation loss = 3.2342  \n",
      "\n",
      "Fold: 2  Epoch: 408  Training loss = 3.0559  Validation loss = 3.2340  \n",
      "\n",
      "Fold: 2  Epoch: 409  Training loss = 3.0557  Validation loss = 3.2338  \n",
      "\n",
      "Fold: 2  Epoch: 410  Training loss = 3.0556  Validation loss = 3.2337  \n",
      "\n",
      "Fold: 2  Epoch: 411  Training loss = 3.0555  Validation loss = 3.2336  \n",
      "\n",
      "Fold: 2  Epoch: 412  Training loss = 3.0554  Validation loss = 3.2334  \n",
      "\n",
      "Fold: 2  Epoch: 413  Training loss = 3.0552  Validation loss = 3.2332  \n",
      "\n",
      "Fold: 2  Epoch: 414  Training loss = 3.0552  Validation loss = 3.2331  \n",
      "\n",
      "Fold: 2  Epoch: 415  Training loss = 3.0551  Validation loss = 3.2330  \n",
      "\n",
      "Fold: 2  Epoch: 416  Training loss = 3.0550  Validation loss = 3.2328  \n",
      "\n",
      "Fold: 2  Epoch: 417  Training loss = 3.0549  Validation loss = 3.2327  \n",
      "\n",
      "Fold: 2  Epoch: 418  Training loss = 3.0548  Validation loss = 3.2326  \n",
      "\n",
      "Fold: 2  Epoch: 419  Training loss = 3.0547  Validation loss = 3.2324  \n",
      "\n",
      "Fold: 2  Epoch: 420  Training loss = 3.0546  Validation loss = 3.2323  \n",
      "\n",
      "Fold: 2  Epoch: 421  Training loss = 3.0545  Validation loss = 3.2322  \n",
      "\n",
      "Fold: 2  Epoch: 422  Training loss = 3.0543  Validation loss = 3.2320  \n",
      "\n",
      "Fold: 2  Epoch: 423  Training loss = 3.0542  Validation loss = 3.2318  \n",
      "\n",
      "Fold: 2  Epoch: 424  Training loss = 3.0541  Validation loss = 3.2316  \n",
      "\n",
      "Fold: 2  Epoch: 425  Training loss = 3.0540  Validation loss = 3.2315  \n",
      "\n",
      "Fold: 2  Epoch: 426  Training loss = 3.0538  Validation loss = 3.2313  \n",
      "\n",
      "Fold: 2  Epoch: 427  Training loss = 3.0537  Validation loss = 3.2312  \n",
      "\n",
      "Fold: 2  Epoch: 428  Training loss = 3.0536  Validation loss = 3.2310  \n",
      "\n",
      "Fold: 2  Epoch: 429  Training loss = 3.0535  Validation loss = 3.2309  \n",
      "\n",
      "Fold: 2  Epoch: 430  Training loss = 3.0534  Validation loss = 3.2308  \n",
      "\n",
      "Fold: 2  Epoch: 431  Training loss = 3.0533  Validation loss = 3.2306  \n",
      "\n",
      "Fold: 2  Epoch: 432  Training loss = 3.0532  Validation loss = 3.2305  \n",
      "\n",
      "Fold: 2  Epoch: 433  Training loss = 3.0531  Validation loss = 3.2303  \n",
      "\n",
      "Fold: 2  Epoch: 434  Training loss = 3.0530  Validation loss = 3.2301  \n",
      "\n",
      "Fold: 2  Epoch: 435  Training loss = 3.0528  Validation loss = 3.2300  \n",
      "\n",
      "Fold: 2  Epoch: 436  Training loss = 3.0527  Validation loss = 3.2298  \n",
      "\n",
      "Fold: 2  Epoch: 437  Training loss = 3.0526  Validation loss = 3.2297  \n",
      "\n",
      "Fold: 2  Epoch: 438  Training loss = 3.0525  Validation loss = 3.2296  \n",
      "\n",
      "Fold: 2  Epoch: 439  Training loss = 3.0524  Validation loss = 3.2294  \n",
      "\n",
      "Fold: 2  Epoch: 440  Training loss = 3.0523  Validation loss = 3.2293  \n",
      "\n",
      "Fold: 2  Epoch: 441  Training loss = 3.0522  Validation loss = 3.2291  \n",
      "\n",
      "Fold: 2  Epoch: 442  Training loss = 3.0521  Validation loss = 3.2290  \n",
      "\n",
      "Fold: 2  Epoch: 443  Training loss = 3.0520  Validation loss = 3.2288  \n",
      "\n",
      "Fold: 2  Epoch: 444  Training loss = 3.0519  Validation loss = 3.2287  \n",
      "\n",
      "Fold: 2  Epoch: 445  Training loss = 3.0518  Validation loss = 3.2286  \n",
      "\n",
      "Fold: 2  Epoch: 446  Training loss = 3.0517  Validation loss = 3.2285  \n",
      "\n",
      "Fold: 2  Epoch: 447  Training loss = 3.0516  Validation loss = 3.2283  \n",
      "\n",
      "Fold: 2  Epoch: 448  Training loss = 3.0514  Validation loss = 3.2281  \n",
      "\n",
      "Fold: 2  Epoch: 449  Training loss = 3.0513  Validation loss = 3.2280  \n",
      "\n",
      "Fold: 2  Epoch: 450  Training loss = 3.0512  Validation loss = 3.2278  \n",
      "\n",
      "Fold: 2  Epoch: 451  Training loss = 3.0511  Validation loss = 3.2277  \n",
      "\n",
      "Fold: 2  Epoch: 452  Training loss = 3.0509  Validation loss = 3.2275  \n",
      "\n",
      "Fold: 2  Epoch: 453  Training loss = 3.0508  Validation loss = 3.2273  \n",
      "\n",
      "Fold: 2  Epoch: 454  Training loss = 3.0507  Validation loss = 3.2272  \n",
      "\n",
      "Fold: 2  Epoch: 455  Training loss = 3.0506  Validation loss = 3.2270  \n",
      "\n",
      "Fold: 2  Epoch: 456  Training loss = 3.0505  Validation loss = 3.2269  \n",
      "\n",
      "Fold: 2  Epoch: 457  Training loss = 3.0503  Validation loss = 3.2267  \n",
      "\n",
      "Fold: 2  Epoch: 458  Training loss = 3.0502  Validation loss = 3.2266  \n",
      "\n",
      "Fold: 2  Epoch: 459  Training loss = 3.0501  Validation loss = 3.2265  \n",
      "\n",
      "Fold: 2  Epoch: 460  Training loss = 3.0500  Validation loss = 3.2263  \n",
      "\n",
      "Fold: 2  Epoch: 461  Training loss = 3.0499  Validation loss = 3.2262  \n",
      "\n",
      "Fold: 2  Epoch: 462  Training loss = 3.0498  Validation loss = 3.2260  \n",
      "\n",
      "Fold: 2  Epoch: 463  Training loss = 3.0497  Validation loss = 3.2258  \n",
      "\n",
      "Fold: 2  Epoch: 464  Training loss = 3.0496  Validation loss = 3.2257  \n",
      "\n",
      "Fold: 2  Epoch: 465  Training loss = 3.0495  Validation loss = 3.2256  \n",
      "\n",
      "Fold: 2  Epoch: 466  Training loss = 3.0494  Validation loss = 3.2255  \n",
      "\n",
      "Fold: 2  Epoch: 467  Training loss = 3.0493  Validation loss = 3.2254  \n",
      "\n",
      "Fold: 2  Epoch: 468  Training loss = 3.0492  Validation loss = 3.2252  \n",
      "\n",
      "Fold: 2  Epoch: 469  Training loss = 3.0491  Validation loss = 3.2251  \n",
      "\n",
      "Fold: 2  Epoch: 470  Training loss = 3.0490  Validation loss = 3.2250  \n",
      "\n",
      "Fold: 2  Epoch: 471  Training loss = 3.0489  Validation loss = 3.2248  \n",
      "\n",
      "Fold: 2  Epoch: 472  Training loss = 3.0488  Validation loss = 3.2246  \n",
      "\n",
      "Fold: 2  Epoch: 473  Training loss = 3.0487  Validation loss = 3.2245  \n",
      "\n",
      "Fold: 2  Epoch: 474  Training loss = 3.0486  Validation loss = 3.2244  \n",
      "\n",
      "Fold: 2  Epoch: 475  Training loss = 3.0484  Validation loss = 3.2242  \n",
      "\n",
      "Fold: 2  Epoch: 476  Training loss = 3.0483  Validation loss = 3.2240  \n",
      "\n",
      "Fold: 2  Epoch: 477  Training loss = 3.0482  Validation loss = 3.2239  \n",
      "\n",
      "Fold: 2  Epoch: 478  Training loss = 3.0481  Validation loss = 3.2237  \n",
      "\n",
      "Fold: 2  Epoch: 479  Training loss = 3.0480  Validation loss = 3.2236  \n",
      "\n",
      "Fold: 2  Epoch: 480  Training loss = 3.0479  Validation loss = 3.2234  \n",
      "\n",
      "Fold: 2  Epoch: 481  Training loss = 3.0477  Validation loss = 3.2233  \n",
      "\n",
      "Fold: 2  Epoch: 482  Training loss = 3.0476  Validation loss = 3.2231  \n",
      "\n",
      "Fold: 2  Epoch: 483  Training loss = 3.0475  Validation loss = 3.2230  \n",
      "\n",
      "Fold: 2  Epoch: 484  Training loss = 3.0474  Validation loss = 3.2228  \n",
      "\n",
      "Fold: 2  Epoch: 485  Training loss = 3.0473  Validation loss = 3.2227  \n",
      "\n",
      "Fold: 2  Epoch: 486  Training loss = 3.0472  Validation loss = 3.2226  \n",
      "\n",
      "Fold: 2  Epoch: 487  Training loss = 3.0471  Validation loss = 3.2224  \n",
      "\n",
      "Fold: 2  Epoch: 488  Training loss = 3.0470  Validation loss = 3.2223  \n",
      "\n",
      "Fold: 2  Epoch: 489  Training loss = 3.0469  Validation loss = 3.2221  \n",
      "\n",
      "Fold: 2  Epoch: 490  Training loss = 3.0468  Validation loss = 3.2220  \n",
      "\n",
      "Fold: 2  Epoch: 491  Training loss = 3.0467  Validation loss = 3.2218  \n",
      "\n",
      "Fold: 2  Epoch: 492  Training loss = 3.0466  Validation loss = 3.2217  \n",
      "\n",
      "Fold: 2  Epoch: 493  Training loss = 3.0465  Validation loss = 3.2215  \n",
      "\n",
      "Fold: 2  Epoch: 494  Training loss = 3.0463  Validation loss = 3.2214  \n",
      "\n",
      "Fold: 2  Epoch: 495  Training loss = 3.0462  Validation loss = 3.2212  \n",
      "\n",
      "Fold: 2  Epoch: 496  Training loss = 3.0461  Validation loss = 3.2210  \n",
      "\n",
      "Fold: 2  Epoch: 497  Training loss = 3.0460  Validation loss = 3.2208  \n",
      "\n",
      "Fold: 2  Epoch: 498  Training loss = 3.0459  Validation loss = 3.2207  \n",
      "\n",
      "Fold: 2  Epoch: 499  Training loss = 3.0457  Validation loss = 3.2205  \n",
      "\n",
      "Fold: 2  Epoch: 500  Training loss = 3.0456  Validation loss = 3.2204  \n",
      "\n",
      "Check model:  Fold: 2  Optimal epoch: 500  \n",
      "\n",
      "Fold: 3  Epoch: 1  Training loss = 2.1071  Validation loss = 4.6074  \n",
      "\n",
      "Fold: 3  Epoch: 2  Training loss = 2.1069  Validation loss = 4.6072  \n",
      "\n",
      "Fold: 3  Epoch: 3  Training loss = 2.1068  Validation loss = 4.6071  \n",
      "\n",
      "Fold: 3  Epoch: 4  Training loss = 2.1067  Validation loss = 4.6069  \n",
      "\n",
      "Fold: 3  Epoch: 5  Training loss = 2.1066  Validation loss = 4.6068  \n",
      "\n",
      "Fold: 3  Epoch: 6  Training loss = 2.1064  Validation loss = 4.6067  \n",
      "\n",
      "Fold: 3  Epoch: 7  Training loss = 2.1063  Validation loss = 4.6066  \n",
      "\n",
      "Fold: 3  Epoch: 8  Training loss = 2.1062  Validation loss = 4.6064  \n",
      "\n",
      "Fold: 3  Epoch: 9  Training loss = 2.1061  Validation loss = 4.6063  \n",
      "\n",
      "Fold: 3  Epoch: 10  Training loss = 2.1060  Validation loss = 4.6062  \n",
      "\n",
      "Fold: 3  Epoch: 11  Training loss = 2.1059  Validation loss = 4.6060  \n",
      "\n",
      "Fold: 3  Epoch: 12  Training loss = 2.1058  Validation loss = 4.6059  \n",
      "\n",
      "Fold: 3  Epoch: 13  Training loss = 2.1056  Validation loss = 4.6058  \n",
      "\n",
      "Fold: 3  Epoch: 14  Training loss = 2.1055  Validation loss = 4.6057  \n",
      "\n",
      "Fold: 3  Epoch: 15  Training loss = 2.1054  Validation loss = 4.6055  \n",
      "\n",
      "Fold: 3  Epoch: 16  Training loss = 2.1053  Validation loss = 4.6054  \n",
      "\n",
      "Fold: 3  Epoch: 17  Training loss = 2.1052  Validation loss = 4.6053  \n",
      "\n",
      "Fold: 3  Epoch: 18  Training loss = 2.1051  Validation loss = 4.6051  \n",
      "\n",
      "Fold: 3  Epoch: 19  Training loss = 2.1049  Validation loss = 4.6050  \n",
      "\n",
      "Fold: 3  Epoch: 20  Training loss = 2.1048  Validation loss = 4.6049  \n",
      "\n",
      "Fold: 3  Epoch: 21  Training loss = 2.1047  Validation loss = 4.6048  \n",
      "\n",
      "Fold: 3  Epoch: 22  Training loss = 2.1046  Validation loss = 4.6047  \n",
      "\n",
      "Fold: 3  Epoch: 23  Training loss = 2.1045  Validation loss = 4.6045  \n",
      "\n",
      "Fold: 3  Epoch: 24  Training loss = 2.1044  Validation loss = 4.6044  \n",
      "\n",
      "Fold: 3  Epoch: 25  Training loss = 2.1043  Validation loss = 4.6043  \n",
      "\n",
      "Fold: 3  Epoch: 26  Training loss = 2.1042  Validation loss = 4.6042  \n",
      "\n",
      "Fold: 3  Epoch: 27  Training loss = 2.1041  Validation loss = 4.6041  \n",
      "\n",
      "Fold: 3  Epoch: 28  Training loss = 2.1039  Validation loss = 4.6039  \n",
      "\n",
      "Fold: 3  Epoch: 29  Training loss = 2.1038  Validation loss = 4.6038  \n",
      "\n",
      "Fold: 3  Epoch: 30  Training loss = 2.1037  Validation loss = 4.6037  \n",
      "\n",
      "Fold: 3  Epoch: 31  Training loss = 2.1036  Validation loss = 4.6036  \n",
      "\n",
      "Fold: 3  Epoch: 32  Training loss = 2.1035  Validation loss = 4.6034  \n",
      "\n",
      "Fold: 3  Epoch: 33  Training loss = 2.1034  Validation loss = 4.6033  \n",
      "\n",
      "Fold: 3  Epoch: 34  Training loss = 2.1032  Validation loss = 4.6032  \n",
      "\n",
      "Fold: 3  Epoch: 35  Training loss = 2.1031  Validation loss = 4.6031  \n",
      "\n",
      "Fold: 3  Epoch: 36  Training loss = 2.1030  Validation loss = 4.6029  \n",
      "\n",
      "Fold: 3  Epoch: 37  Training loss = 2.1029  Validation loss = 4.6028  \n",
      "\n",
      "Fold: 3  Epoch: 38  Training loss = 2.1028  Validation loss = 4.6027  \n",
      "\n",
      "Fold: 3  Epoch: 39  Training loss = 2.1027  Validation loss = 4.6025  \n",
      "\n",
      "Fold: 3  Epoch: 40  Training loss = 2.1025  Validation loss = 4.6024  \n",
      "\n",
      "Fold: 3  Epoch: 41  Training loss = 2.1024  Validation loss = 4.6023  \n",
      "\n",
      "Fold: 3  Epoch: 42  Training loss = 2.1023  Validation loss = 4.6021  \n",
      "\n",
      "Fold: 3  Epoch: 43  Training loss = 2.1022  Validation loss = 4.6020  \n",
      "\n",
      "Fold: 3  Epoch: 44  Training loss = 2.1021  Validation loss = 4.6019  \n",
      "\n",
      "Fold: 3  Epoch: 45  Training loss = 2.1020  Validation loss = 4.6018  \n",
      "\n",
      "Fold: 3  Epoch: 46  Training loss = 2.1019  Validation loss = 4.6017  \n",
      "\n",
      "Fold: 3  Epoch: 47  Training loss = 2.1018  Validation loss = 4.6015  \n",
      "\n",
      "Fold: 3  Epoch: 48  Training loss = 2.1016  Validation loss = 4.6014  \n",
      "\n",
      "Fold: 3  Epoch: 49  Training loss = 2.1015  Validation loss = 4.6013  \n",
      "\n",
      "Fold: 3  Epoch: 50  Training loss = 2.1014  Validation loss = 4.6012  \n",
      "\n",
      "Fold: 3  Epoch: 51  Training loss = 2.1013  Validation loss = 4.6011  \n",
      "\n",
      "Fold: 3  Epoch: 52  Training loss = 2.1012  Validation loss = 4.6009  \n",
      "\n",
      "Fold: 3  Epoch: 53  Training loss = 2.1011  Validation loss = 4.6008  \n",
      "\n",
      "Fold: 3  Epoch: 54  Training loss = 2.1009  Validation loss = 4.6007  \n",
      "\n",
      "Fold: 3  Epoch: 55  Training loss = 2.1008  Validation loss = 4.6005  \n",
      "\n",
      "Fold: 3  Epoch: 56  Training loss = 2.1007  Validation loss = 4.6004  \n",
      "\n",
      "Fold: 3  Epoch: 57  Training loss = 2.1006  Validation loss = 4.6003  \n",
      "\n",
      "Fold: 3  Epoch: 58  Training loss = 2.1005  Validation loss = 4.6002  \n",
      "\n",
      "Fold: 3  Epoch: 59  Training loss = 2.1004  Validation loss = 4.6000  \n",
      "\n",
      "Fold: 3  Epoch: 60  Training loss = 2.1003  Validation loss = 4.5999  \n",
      "\n",
      "Fold: 3  Epoch: 61  Training loss = 2.1002  Validation loss = 4.5998  \n",
      "\n",
      "Fold: 3  Epoch: 62  Training loss = 2.1001  Validation loss = 4.5997  \n",
      "\n",
      "Fold: 3  Epoch: 63  Training loss = 2.1000  Validation loss = 4.5996  \n",
      "\n",
      "Fold: 3  Epoch: 64  Training loss = 2.0998  Validation loss = 4.5994  \n",
      "\n",
      "Fold: 3  Epoch: 65  Training loss = 2.0997  Validation loss = 4.5993  \n",
      "\n",
      "Fold: 3  Epoch: 66  Training loss = 2.0996  Validation loss = 4.5992  \n",
      "\n",
      "Fold: 3  Epoch: 67  Training loss = 2.0995  Validation loss = 4.5990  \n",
      "\n",
      "Fold: 3  Epoch: 68  Training loss = 2.0994  Validation loss = 4.5989  \n",
      "\n",
      "Fold: 3  Epoch: 69  Training loss = 2.0993  Validation loss = 4.5988  \n",
      "\n",
      "Fold: 3  Epoch: 70  Training loss = 2.0992  Validation loss = 4.5987  \n",
      "\n",
      "Fold: 3  Epoch: 71  Training loss = 2.0991  Validation loss = 4.5986  \n",
      "\n",
      "Fold: 3  Epoch: 72  Training loss = 2.0990  Validation loss = 4.5984  \n",
      "\n",
      "Fold: 3  Epoch: 73  Training loss = 2.0988  Validation loss = 4.5983  \n",
      "\n",
      "Fold: 3  Epoch: 74  Training loss = 2.0987  Validation loss = 4.5982  \n",
      "\n",
      "Fold: 3  Epoch: 75  Training loss = 2.0986  Validation loss = 4.5980  \n",
      "\n",
      "Fold: 3  Epoch: 76  Training loss = 2.0985  Validation loss = 4.5979  \n",
      "\n",
      "Fold: 3  Epoch: 77  Training loss = 2.0984  Validation loss = 4.5978  \n",
      "\n",
      "Fold: 3  Epoch: 78  Training loss = 2.0983  Validation loss = 4.5977  \n",
      "\n",
      "Fold: 3  Epoch: 79  Training loss = 2.0982  Validation loss = 4.5976  \n",
      "\n",
      "Fold: 3  Epoch: 80  Training loss = 2.0981  Validation loss = 4.5974  \n",
      "\n",
      "Fold: 3  Epoch: 81  Training loss = 2.0980  Validation loss = 4.5973  \n",
      "\n",
      "Fold: 3  Epoch: 82  Training loss = 2.0979  Validation loss = 4.5972  \n",
      "\n",
      "Fold: 3  Epoch: 83  Training loss = 2.0977  Validation loss = 4.5970  \n",
      "\n",
      "Fold: 3  Epoch: 84  Training loss = 2.0976  Validation loss = 4.5969  \n",
      "\n",
      "Fold: 3  Epoch: 85  Training loss = 2.0975  Validation loss = 4.5968  \n",
      "\n",
      "Fold: 3  Epoch: 86  Training loss = 2.0974  Validation loss = 4.5967  \n",
      "\n",
      "Fold: 3  Epoch: 87  Training loss = 2.0973  Validation loss = 4.5966  \n",
      "\n",
      "Fold: 3  Epoch: 88  Training loss = 2.0972  Validation loss = 4.5965  \n",
      "\n",
      "Fold: 3  Epoch: 89  Training loss = 2.0971  Validation loss = 4.5963  \n",
      "\n",
      "Fold: 3  Epoch: 90  Training loss = 2.0970  Validation loss = 4.5962  \n",
      "\n",
      "Fold: 3  Epoch: 91  Training loss = 2.0969  Validation loss = 4.5961  \n",
      "\n",
      "Fold: 3  Epoch: 92  Training loss = 2.0968  Validation loss = 4.5960  \n",
      "\n",
      "Fold: 3  Epoch: 93  Training loss = 2.0967  Validation loss = 4.5959  \n",
      "\n",
      "Fold: 3  Epoch: 94  Training loss = 2.0965  Validation loss = 4.5957  \n",
      "\n",
      "Fold: 3  Epoch: 95  Training loss = 2.0965  Validation loss = 4.5956  \n",
      "\n",
      "Fold: 3  Epoch: 96  Training loss = 2.0964  Validation loss = 4.5955  \n",
      "\n",
      "Fold: 3  Epoch: 97  Training loss = 2.0962  Validation loss = 4.5954  \n",
      "\n",
      "Fold: 3  Epoch: 98  Training loss = 2.0961  Validation loss = 4.5952  \n",
      "\n",
      "Fold: 3  Epoch: 99  Training loss = 2.0960  Validation loss = 4.5951  \n",
      "\n",
      "Fold: 3  Epoch: 100  Training loss = 2.0959  Validation loss = 4.5949  \n",
      "\n",
      "Fold: 3  Epoch: 101  Training loss = 2.0958  Validation loss = 4.5949  \n",
      "\n",
      "Fold: 3  Epoch: 102  Training loss = 2.0957  Validation loss = 4.5947  \n",
      "\n",
      "Fold: 3  Epoch: 103  Training loss = 2.0956  Validation loss = 4.5946  \n",
      "\n",
      "Fold: 3  Epoch: 104  Training loss = 2.0955  Validation loss = 4.5945  \n",
      "\n",
      "Fold: 3  Epoch: 105  Training loss = 2.0953  Validation loss = 4.5944  \n",
      "\n",
      "Fold: 3  Epoch: 106  Training loss = 2.0953  Validation loss = 4.5943  \n",
      "\n",
      "Fold: 3  Epoch: 107  Training loss = 2.0952  Validation loss = 4.5942  \n",
      "\n",
      "Fold: 3  Epoch: 108  Training loss = 2.0950  Validation loss = 4.5940  \n",
      "\n",
      "Fold: 3  Epoch: 109  Training loss = 2.0949  Validation loss = 4.5939  \n",
      "\n",
      "Fold: 3  Epoch: 110  Training loss = 2.0948  Validation loss = 4.5938  \n",
      "\n",
      "Fold: 3  Epoch: 111  Training loss = 2.0947  Validation loss = 4.5937  \n",
      "\n",
      "Fold: 3  Epoch: 112  Training loss = 2.0946  Validation loss = 4.5935  \n",
      "\n",
      "Fold: 3  Epoch: 113  Training loss = 2.0944  Validation loss = 4.5934  \n",
      "\n",
      "Fold: 3  Epoch: 114  Training loss = 2.0943  Validation loss = 4.5933  \n",
      "\n",
      "Fold: 3  Epoch: 115  Training loss = 2.0942  Validation loss = 4.5932  \n",
      "\n",
      "Fold: 3  Epoch: 116  Training loss = 2.0941  Validation loss = 4.5931  \n",
      "\n",
      "Fold: 3  Epoch: 117  Training loss = 2.0940  Validation loss = 4.5929  \n",
      "\n",
      "Fold: 3  Epoch: 118  Training loss = 2.0939  Validation loss = 4.5928  \n",
      "\n",
      "Fold: 3  Epoch: 119  Training loss = 2.0938  Validation loss = 4.5926  \n",
      "\n",
      "Fold: 3  Epoch: 120  Training loss = 2.0936  Validation loss = 4.5925  \n",
      "\n",
      "Fold: 3  Epoch: 121  Training loss = 2.0935  Validation loss = 4.5924  \n",
      "\n",
      "Fold: 3  Epoch: 122  Training loss = 2.0934  Validation loss = 4.5923  \n",
      "\n",
      "Fold: 3  Epoch: 123  Training loss = 2.0933  Validation loss = 4.5921  \n",
      "\n",
      "Fold: 3  Epoch: 124  Training loss = 2.0932  Validation loss = 4.5920  \n",
      "\n",
      "Fold: 3  Epoch: 125  Training loss = 2.0931  Validation loss = 4.5919  \n",
      "\n",
      "Fold: 3  Epoch: 126  Training loss = 2.0930  Validation loss = 4.5918  \n",
      "\n",
      "Fold: 3  Epoch: 127  Training loss = 2.0929  Validation loss = 4.5917  \n",
      "\n",
      "Fold: 3  Epoch: 128  Training loss = 2.0928  Validation loss = 4.5916  \n",
      "\n",
      "Fold: 3  Epoch: 129  Training loss = 2.0927  Validation loss = 4.5915  \n",
      "\n",
      "Fold: 3  Epoch: 130  Training loss = 2.0926  Validation loss = 4.5914  \n",
      "\n",
      "Fold: 3  Epoch: 131  Training loss = 2.0925  Validation loss = 4.5913  \n",
      "\n",
      "Fold: 3  Epoch: 132  Training loss = 2.0924  Validation loss = 4.5912  \n",
      "\n",
      "Fold: 3  Epoch: 133  Training loss = 2.0923  Validation loss = 4.5910  \n",
      "\n",
      "Fold: 3  Epoch: 134  Training loss = 2.0922  Validation loss = 4.5909  \n",
      "\n",
      "Fold: 3  Epoch: 135  Training loss = 2.0921  Validation loss = 4.5908  \n",
      "\n",
      "Fold: 3  Epoch: 136  Training loss = 2.0919  Validation loss = 4.5907  \n",
      "\n",
      "Fold: 3  Epoch: 137  Training loss = 2.0918  Validation loss = 4.5905  \n",
      "\n",
      "Fold: 3  Epoch: 138  Training loss = 2.0916  Validation loss = 4.5904  \n",
      "\n",
      "Fold: 3  Epoch: 139  Training loss = 2.0915  Validation loss = 4.5902  \n",
      "\n",
      "Fold: 3  Epoch: 140  Training loss = 2.0914  Validation loss = 4.5901  \n",
      "\n",
      "Fold: 3  Epoch: 141  Training loss = 2.0913  Validation loss = 4.5899  \n",
      "\n",
      "Fold: 3  Epoch: 142  Training loss = 2.0911  Validation loss = 4.5898  \n",
      "\n",
      "Fold: 3  Epoch: 143  Training loss = 2.0911  Validation loss = 4.5897  \n",
      "\n",
      "Fold: 3  Epoch: 144  Training loss = 2.0909  Validation loss = 4.5896  \n",
      "\n",
      "Fold: 3  Epoch: 145  Training loss = 2.0908  Validation loss = 4.5894  \n",
      "\n",
      "Fold: 3  Epoch: 146  Training loss = 2.0907  Validation loss = 4.5893  \n",
      "\n",
      "Fold: 3  Epoch: 147  Training loss = 2.0906  Validation loss = 4.5892  \n",
      "\n",
      "Fold: 3  Epoch: 148  Training loss = 2.0904  Validation loss = 4.5890  \n",
      "\n",
      "Fold: 3  Epoch: 149  Training loss = 2.0903  Validation loss = 4.5889  \n",
      "\n",
      "Fold: 3  Epoch: 150  Training loss = 2.0902  Validation loss = 4.5888  \n",
      "\n",
      "Fold: 3  Epoch: 151  Training loss = 2.0901  Validation loss = 4.5887  \n",
      "\n",
      "Fold: 3  Epoch: 152  Training loss = 2.0900  Validation loss = 4.5885  \n",
      "\n",
      "Fold: 3  Epoch: 153  Training loss = 2.0899  Validation loss = 4.5884  \n",
      "\n",
      "Fold: 3  Epoch: 154  Training loss = 2.0898  Validation loss = 4.5883  \n",
      "\n",
      "Fold: 3  Epoch: 155  Training loss = 2.0897  Validation loss = 4.5882  \n",
      "\n",
      "Fold: 3  Epoch: 156  Training loss = 2.0896  Validation loss = 4.5880  \n",
      "\n",
      "Fold: 3  Epoch: 157  Training loss = 2.0894  Validation loss = 4.5879  \n",
      "\n",
      "Fold: 3  Epoch: 158  Training loss = 2.0893  Validation loss = 4.5878  \n",
      "\n",
      "Fold: 3  Epoch: 159  Training loss = 2.0892  Validation loss = 4.5877  \n",
      "\n",
      "Fold: 3  Epoch: 160  Training loss = 2.0891  Validation loss = 4.5876  \n",
      "\n",
      "Fold: 3  Epoch: 161  Training loss = 2.0890  Validation loss = 4.5874  \n",
      "\n",
      "Fold: 3  Epoch: 162  Training loss = 2.0889  Validation loss = 4.5873  \n",
      "\n",
      "Fold: 3  Epoch: 163  Training loss = 2.0888  Validation loss = 4.5872  \n",
      "\n",
      "Fold: 3  Epoch: 164  Training loss = 2.0887  Validation loss = 4.5870  \n",
      "\n",
      "Fold: 3  Epoch: 165  Training loss = 2.0886  Validation loss = 4.5869  \n",
      "\n",
      "Fold: 3  Epoch: 166  Training loss = 2.0885  Validation loss = 4.5868  \n",
      "\n",
      "Fold: 3  Epoch: 167  Training loss = 2.0883  Validation loss = 4.5867  \n",
      "\n",
      "Fold: 3  Epoch: 168  Training loss = 2.0882  Validation loss = 4.5865  \n",
      "\n",
      "Fold: 3  Epoch: 169  Training loss = 2.0881  Validation loss = 4.5864  \n",
      "\n",
      "Fold: 3  Epoch: 170  Training loss = 2.0879  Validation loss = 4.5862  \n",
      "\n",
      "Fold: 3  Epoch: 171  Training loss = 2.0878  Validation loss = 4.5861  \n",
      "\n",
      "Fold: 3  Epoch: 172  Training loss = 2.0877  Validation loss = 4.5860  \n",
      "\n",
      "Fold: 3  Epoch: 173  Training loss = 2.0876  Validation loss = 4.5859  \n",
      "\n",
      "Fold: 3  Epoch: 174  Training loss = 2.0875  Validation loss = 4.5857  \n",
      "\n",
      "Fold: 3  Epoch: 175  Training loss = 2.0874  Validation loss = 4.5856  \n",
      "\n",
      "Fold: 3  Epoch: 176  Training loss = 2.0872  Validation loss = 4.5855  \n",
      "\n",
      "Fold: 3  Epoch: 177  Training loss = 2.0871  Validation loss = 4.5853  \n",
      "\n",
      "Fold: 3  Epoch: 178  Training loss = 2.0870  Validation loss = 4.5852  \n",
      "\n",
      "Fold: 3  Epoch: 179  Training loss = 2.0869  Validation loss = 4.5851  \n",
      "\n",
      "Fold: 3  Epoch: 180  Training loss = 2.0868  Validation loss = 4.5849  \n",
      "\n",
      "Fold: 3  Epoch: 181  Training loss = 2.0867  Validation loss = 4.5848  \n",
      "\n",
      "Fold: 3  Epoch: 182  Training loss = 2.0865  Validation loss = 4.5847  \n",
      "\n",
      "Fold: 3  Epoch: 183  Training loss = 2.0865  Validation loss = 4.5846  \n",
      "\n",
      "Fold: 3  Epoch: 184  Training loss = 2.0863  Validation loss = 4.5845  \n",
      "\n",
      "Fold: 3  Epoch: 185  Training loss = 2.0862  Validation loss = 4.5843  \n",
      "\n",
      "Fold: 3  Epoch: 186  Training loss = 2.0861  Validation loss = 4.5842  \n",
      "\n",
      "Fold: 3  Epoch: 187  Training loss = 2.0860  Validation loss = 4.5841  \n",
      "\n",
      "Fold: 3  Epoch: 188  Training loss = 2.0859  Validation loss = 4.5840  \n",
      "\n",
      "Fold: 3  Epoch: 189  Training loss = 2.0858  Validation loss = 4.5838  \n",
      "\n",
      "Fold: 3  Epoch: 190  Training loss = 2.0857  Validation loss = 4.5837  \n",
      "\n",
      "Fold: 3  Epoch: 191  Training loss = 2.0855  Validation loss = 4.5836  \n",
      "\n",
      "Fold: 3  Epoch: 192  Training loss = 2.0855  Validation loss = 4.5835  \n",
      "\n",
      "Fold: 3  Epoch: 193  Training loss = 2.0854  Validation loss = 4.5834  \n",
      "\n",
      "Fold: 3  Epoch: 194  Training loss = 2.0853  Validation loss = 4.5833  \n",
      "\n",
      "Fold: 3  Epoch: 195  Training loss = 2.0852  Validation loss = 4.5831  \n",
      "\n",
      "Fold: 3  Epoch: 196  Training loss = 2.0851  Validation loss = 4.5831  \n",
      "\n",
      "Fold: 3  Epoch: 197  Training loss = 2.0850  Validation loss = 4.5829  \n",
      "\n",
      "Fold: 3  Epoch: 198  Training loss = 2.0849  Validation loss = 4.5828  \n",
      "\n",
      "Fold: 3  Epoch: 199  Training loss = 2.0848  Validation loss = 4.5827  \n",
      "\n",
      "Fold: 3  Epoch: 200  Training loss = 2.0846  Validation loss = 4.5826  \n",
      "\n",
      "Fold: 3  Epoch: 201  Training loss = 2.0846  Validation loss = 4.5825  \n",
      "\n",
      "Fold: 3  Epoch: 202  Training loss = 2.0845  Validation loss = 4.5824  \n",
      "\n",
      "Fold: 3  Epoch: 203  Training loss = 2.0844  Validation loss = 4.5823  \n",
      "\n",
      "Fold: 3  Epoch: 204  Training loss = 2.0843  Validation loss = 4.5821  \n",
      "\n",
      "Fold: 3  Epoch: 205  Training loss = 2.0841  Validation loss = 4.5820  \n",
      "\n",
      "Fold: 3  Epoch: 206  Training loss = 2.0841  Validation loss = 4.5819  \n",
      "\n",
      "Fold: 3  Epoch: 207  Training loss = 2.0840  Validation loss = 4.5818  \n",
      "\n",
      "Fold: 3  Epoch: 208  Training loss = 2.0838  Validation loss = 4.5817  \n",
      "\n",
      "Fold: 3  Epoch: 209  Training loss = 2.0837  Validation loss = 4.5816  \n",
      "\n",
      "Fold: 3  Epoch: 210  Training loss = 2.0836  Validation loss = 4.5815  \n",
      "\n",
      "Fold: 3  Epoch: 211  Training loss = 2.0835  Validation loss = 4.5813  \n",
      "\n",
      "Fold: 3  Epoch: 212  Training loss = 2.0834  Validation loss = 4.5812  \n",
      "\n",
      "Fold: 3  Epoch: 213  Training loss = 2.0833  Validation loss = 4.5811  \n",
      "\n",
      "Fold: 3  Epoch: 214  Training loss = 2.0832  Validation loss = 4.5810  \n",
      "\n",
      "Fold: 3  Epoch: 215  Training loss = 2.0831  Validation loss = 4.5809  \n",
      "\n",
      "Fold: 3  Epoch: 216  Training loss = 2.0830  Validation loss = 4.5808  \n",
      "\n",
      "Fold: 3  Epoch: 217  Training loss = 2.0829  Validation loss = 4.5806  \n",
      "\n",
      "Fold: 3  Epoch: 218  Training loss = 2.0828  Validation loss = 4.5805  \n",
      "\n",
      "Fold: 3  Epoch: 219  Training loss = 2.0827  Validation loss = 4.5804  \n",
      "\n",
      "Fold: 3  Epoch: 220  Training loss = 2.0826  Validation loss = 4.5803  \n",
      "\n",
      "Fold: 3  Epoch: 221  Training loss = 2.0825  Validation loss = 4.5802  \n",
      "\n",
      "Fold: 3  Epoch: 222  Training loss = 2.0824  Validation loss = 4.5801  \n",
      "\n",
      "Fold: 3  Epoch: 223  Training loss = 2.0823  Validation loss = 4.5800  \n",
      "\n",
      "Fold: 3  Epoch: 224  Training loss = 2.0822  Validation loss = 4.5798  \n",
      "\n",
      "Fold: 3  Epoch: 225  Training loss = 2.0821  Validation loss = 4.5797  \n",
      "\n",
      "Fold: 3  Epoch: 226  Training loss = 2.0820  Validation loss = 4.5796  \n",
      "\n",
      "Fold: 3  Epoch: 227  Training loss = 2.0819  Validation loss = 4.5795  \n",
      "\n",
      "Fold: 3  Epoch: 228  Training loss = 2.0818  Validation loss = 4.5794  \n",
      "\n",
      "Fold: 3  Epoch: 229  Training loss = 2.0817  Validation loss = 4.5793  \n",
      "\n",
      "Fold: 3  Epoch: 230  Training loss = 2.0815  Validation loss = 4.5791  \n",
      "\n",
      "Fold: 3  Epoch: 231  Training loss = 2.0814  Validation loss = 4.5790  \n",
      "\n",
      "Fold: 3  Epoch: 232  Training loss = 2.0813  Validation loss = 4.5789  \n",
      "\n",
      "Fold: 3  Epoch: 233  Training loss = 2.0812  Validation loss = 4.5788  \n",
      "\n",
      "Fold: 3  Epoch: 234  Training loss = 2.0811  Validation loss = 4.5787  \n",
      "\n",
      "Fold: 3  Epoch: 235  Training loss = 2.0810  Validation loss = 4.5786  \n",
      "\n",
      "Fold: 3  Epoch: 236  Training loss = 2.0809  Validation loss = 4.5784  \n",
      "\n",
      "Fold: 3  Epoch: 237  Training loss = 2.0808  Validation loss = 4.5783  \n",
      "\n",
      "Fold: 3  Epoch: 238  Training loss = 2.0807  Validation loss = 4.5782  \n",
      "\n",
      "Fold: 3  Epoch: 239  Training loss = 2.0806  Validation loss = 4.5781  \n",
      "\n",
      "Fold: 3  Epoch: 240  Training loss = 2.0805  Validation loss = 4.5779  \n",
      "\n",
      "Fold: 3  Epoch: 241  Training loss = 2.0804  Validation loss = 4.5778  \n",
      "\n",
      "Fold: 3  Epoch: 242  Training loss = 2.0803  Validation loss = 4.5777  \n",
      "\n",
      "Fold: 3  Epoch: 243  Training loss = 2.0802  Validation loss = 4.5776  \n",
      "\n",
      "Fold: 3  Epoch: 244  Training loss = 2.0801  Validation loss = 4.5775  \n",
      "\n",
      "Fold: 3  Epoch: 245  Training loss = 2.0800  Validation loss = 4.5774  \n",
      "\n",
      "Fold: 3  Epoch: 246  Training loss = 2.0799  Validation loss = 4.5772  \n",
      "\n",
      "Fold: 3  Epoch: 247  Training loss = 2.0797  Validation loss = 4.5771  \n",
      "\n",
      "Fold: 3  Epoch: 248  Training loss = 2.0796  Validation loss = 4.5770  \n",
      "\n",
      "Fold: 3  Epoch: 249  Training loss = 2.0795  Validation loss = 4.5768  \n",
      "\n",
      "Fold: 3  Epoch: 250  Training loss = 2.0794  Validation loss = 4.5767  \n",
      "\n",
      "Fold: 3  Epoch: 251  Training loss = 2.0793  Validation loss = 4.5766  \n",
      "\n",
      "Fold: 3  Epoch: 252  Training loss = 2.0792  Validation loss = 4.5765  \n",
      "\n",
      "Fold: 3  Epoch: 253  Training loss = 2.0791  Validation loss = 4.5763  \n",
      "\n",
      "Fold: 3  Epoch: 254  Training loss = 2.0790  Validation loss = 4.5762  \n",
      "\n",
      "Fold: 3  Epoch: 255  Training loss = 2.0789  Validation loss = 4.5761  \n",
      "\n",
      "Fold: 3  Epoch: 256  Training loss = 2.0788  Validation loss = 4.5760  \n",
      "\n",
      "Fold: 3  Epoch: 257  Training loss = 2.0786  Validation loss = 4.5758  \n",
      "\n",
      "Fold: 3  Epoch: 258  Training loss = 2.0785  Validation loss = 4.5757  \n",
      "\n",
      "Fold: 3  Epoch: 259  Training loss = 2.0784  Validation loss = 4.5756  \n",
      "\n",
      "Fold: 3  Epoch: 260  Training loss = 2.0783  Validation loss = 4.5755  \n",
      "\n",
      "Fold: 3  Epoch: 261  Training loss = 2.0782  Validation loss = 4.5753  \n",
      "\n",
      "Fold: 3  Epoch: 262  Training loss = 2.0781  Validation loss = 4.5752  \n",
      "\n",
      "Fold: 3  Epoch: 263  Training loss = 2.0780  Validation loss = 4.5751  \n",
      "\n",
      "Fold: 3  Epoch: 264  Training loss = 2.0780  Validation loss = 4.5750  \n",
      "\n",
      "Fold: 3  Epoch: 265  Training loss = 2.0778  Validation loss = 4.5749  \n",
      "\n",
      "Fold: 3  Epoch: 266  Training loss = 2.0777  Validation loss = 4.5747  \n",
      "\n",
      "Fold: 3  Epoch: 267  Training loss = 2.0776  Validation loss = 4.5746  \n",
      "\n",
      "Fold: 3  Epoch: 268  Training loss = 2.0775  Validation loss = 4.5745  \n",
      "\n",
      "Fold: 3  Epoch: 269  Training loss = 2.0774  Validation loss = 4.5744  \n",
      "\n",
      "Fold: 3  Epoch: 270  Training loss = 2.0773  Validation loss = 4.5743  \n",
      "\n",
      "Fold: 3  Epoch: 271  Training loss = 2.0772  Validation loss = 4.5741  \n",
      "\n",
      "Fold: 3  Epoch: 272  Training loss = 2.0771  Validation loss = 4.5740  \n",
      "\n",
      "Fold: 3  Epoch: 273  Training loss = 2.0769  Validation loss = 4.5739  \n",
      "\n",
      "Fold: 3  Epoch: 274  Training loss = 2.0768  Validation loss = 4.5738  \n",
      "\n",
      "Fold: 3  Epoch: 275  Training loss = 2.0767  Validation loss = 4.5736  \n",
      "\n",
      "Fold: 3  Epoch: 276  Training loss = 2.0766  Validation loss = 4.5735  \n",
      "\n",
      "Fold: 3  Epoch: 277  Training loss = 2.0765  Validation loss = 4.5734  \n",
      "\n",
      "Fold: 3  Epoch: 278  Training loss = 2.0764  Validation loss = 4.5733  \n",
      "\n",
      "Fold: 3  Epoch: 279  Training loss = 2.0763  Validation loss = 4.5732  \n",
      "\n",
      "Fold: 3  Epoch: 280  Training loss = 2.0762  Validation loss = 4.5731  \n",
      "\n",
      "Fold: 3  Epoch: 281  Training loss = 2.0761  Validation loss = 4.5729  \n",
      "\n",
      "Fold: 3  Epoch: 282  Training loss = 2.0760  Validation loss = 4.5728  \n",
      "\n",
      "Fold: 3  Epoch: 283  Training loss = 2.0759  Validation loss = 4.5727  \n",
      "\n",
      "Fold: 3  Epoch: 284  Training loss = 2.0758  Validation loss = 4.5726  \n",
      "\n",
      "Fold: 3  Epoch: 285  Training loss = 2.0757  Validation loss = 4.5725  \n",
      "\n",
      "Fold: 3  Epoch: 286  Training loss = 2.0756  Validation loss = 4.5724  \n",
      "\n",
      "Fold: 3  Epoch: 287  Training loss = 2.0755  Validation loss = 4.5722  \n",
      "\n",
      "Fold: 3  Epoch: 288  Training loss = 2.0753  Validation loss = 4.5721  \n",
      "\n",
      "Fold: 3  Epoch: 289  Training loss = 2.0753  Validation loss = 4.5720  \n",
      "\n",
      "Fold: 3  Epoch: 290  Training loss = 2.0752  Validation loss = 4.5719  \n",
      "\n",
      "Fold: 3  Epoch: 291  Training loss = 2.0751  Validation loss = 4.5718  \n",
      "\n",
      "Fold: 3  Epoch: 292  Training loss = 2.0750  Validation loss = 4.5717  \n",
      "\n",
      "Fold: 3  Epoch: 293  Training loss = 2.0748  Validation loss = 4.5715  \n",
      "\n",
      "Fold: 3  Epoch: 294  Training loss = 2.0747  Validation loss = 4.5714  \n",
      "\n",
      "Fold: 3  Epoch: 295  Training loss = 2.0747  Validation loss = 4.5714  \n",
      "\n",
      "Fold: 3  Epoch: 296  Training loss = 2.0745  Validation loss = 4.5712  \n",
      "\n",
      "Fold: 3  Epoch: 297  Training loss = 2.0745  Validation loss = 4.5711  \n",
      "\n",
      "Fold: 3  Epoch: 298  Training loss = 2.0744  Validation loss = 4.5710  \n",
      "\n",
      "Fold: 3  Epoch: 299  Training loss = 2.0743  Validation loss = 4.5709  \n",
      "\n",
      "Fold: 3  Epoch: 300  Training loss = 2.0741  Validation loss = 4.5708  \n",
      "\n",
      "Fold: 3  Epoch: 301  Training loss = 2.0741  Validation loss = 4.5706  \n",
      "\n",
      "Fold: 3  Epoch: 302  Training loss = 2.0740  Validation loss = 4.5705  \n",
      "\n",
      "Fold: 3  Epoch: 303  Training loss = 2.0738  Validation loss = 4.5703  \n",
      "\n",
      "Fold: 3  Epoch: 304  Training loss = 2.0737  Validation loss = 4.5703  \n",
      "\n",
      "Fold: 3  Epoch: 305  Training loss = 2.0736  Validation loss = 4.5701  \n",
      "\n",
      "Fold: 3  Epoch: 306  Training loss = 2.0735  Validation loss = 4.5700  \n",
      "\n",
      "Fold: 3  Epoch: 307  Training loss = 2.0734  Validation loss = 4.5699  \n",
      "\n",
      "Fold: 3  Epoch: 308  Training loss = 2.0733  Validation loss = 4.5698  \n",
      "\n",
      "Fold: 3  Epoch: 309  Training loss = 2.0732  Validation loss = 4.5696  \n",
      "\n",
      "Fold: 3  Epoch: 310  Training loss = 2.0731  Validation loss = 4.5695  \n",
      "\n",
      "Fold: 3  Epoch: 311  Training loss = 2.0730  Validation loss = 4.5694  \n",
      "\n",
      "Fold: 3  Epoch: 312  Training loss = 2.0729  Validation loss = 4.5693  \n",
      "\n",
      "Fold: 3  Epoch: 313  Training loss = 2.0728  Validation loss = 4.5692  \n",
      "\n",
      "Fold: 3  Epoch: 314  Training loss = 2.0727  Validation loss = 4.5691  \n",
      "\n",
      "Fold: 3  Epoch: 315  Training loss = 2.0726  Validation loss = 4.5690  \n",
      "\n",
      "Fold: 3  Epoch: 316  Training loss = 2.0725  Validation loss = 4.5688  \n",
      "\n",
      "Fold: 3  Epoch: 317  Training loss = 2.0724  Validation loss = 4.5687  \n",
      "\n",
      "Fold: 3  Epoch: 318  Training loss = 2.0722  Validation loss = 4.5686  \n",
      "\n",
      "Fold: 3  Epoch: 319  Training loss = 2.0721  Validation loss = 4.5685  \n",
      "\n",
      "Fold: 3  Epoch: 320  Training loss = 2.0720  Validation loss = 4.5683  \n",
      "\n",
      "Fold: 3  Epoch: 321  Training loss = 2.0719  Validation loss = 4.5682  \n",
      "\n",
      "Fold: 3  Epoch: 322  Training loss = 2.0718  Validation loss = 4.5681  \n",
      "\n",
      "Fold: 3  Epoch: 323  Training loss = 2.0717  Validation loss = 4.5680  \n",
      "\n",
      "Fold: 3  Epoch: 324  Training loss = 2.0716  Validation loss = 4.5679  \n",
      "\n",
      "Fold: 3  Epoch: 325  Training loss = 2.0715  Validation loss = 4.5678  \n",
      "\n",
      "Fold: 3  Epoch: 326  Training loss = 2.0714  Validation loss = 4.5676  \n",
      "\n",
      "Fold: 3  Epoch: 327  Training loss = 2.0713  Validation loss = 4.5675  \n",
      "\n",
      "Fold: 3  Epoch: 328  Training loss = 2.0712  Validation loss = 4.5674  \n",
      "\n",
      "Fold: 3  Epoch: 329  Training loss = 2.0711  Validation loss = 4.5673  \n",
      "\n",
      "Fold: 3  Epoch: 330  Training loss = 2.0710  Validation loss = 4.5672  \n",
      "\n",
      "Fold: 3  Epoch: 331  Training loss = 2.0709  Validation loss = 4.5670  \n",
      "\n",
      "Fold: 3  Epoch: 332  Training loss = 2.0707  Validation loss = 4.5669  \n",
      "\n",
      "Fold: 3  Epoch: 333  Training loss = 2.0706  Validation loss = 4.5668  \n",
      "\n",
      "Fold: 3  Epoch: 334  Training loss = 2.0705  Validation loss = 4.5666  \n",
      "\n",
      "Fold: 3  Epoch: 335  Training loss = 2.0704  Validation loss = 4.5666  \n",
      "\n",
      "Fold: 3  Epoch: 336  Training loss = 2.0703  Validation loss = 4.5665  \n",
      "\n",
      "Fold: 3  Epoch: 337  Training loss = 2.0702  Validation loss = 4.5663  \n",
      "\n",
      "Fold: 3  Epoch: 338  Training loss = 2.0701  Validation loss = 4.5662  \n",
      "\n",
      "Fold: 3  Epoch: 339  Training loss = 2.0700  Validation loss = 4.5661  \n",
      "\n",
      "Fold: 3  Epoch: 340  Training loss = 2.0699  Validation loss = 4.5660  \n",
      "\n",
      "Fold: 3  Epoch: 341  Training loss = 2.0698  Validation loss = 4.5658  \n",
      "\n",
      "Fold: 3  Epoch: 342  Training loss = 2.0697  Validation loss = 4.5657  \n",
      "\n",
      "Fold: 3  Epoch: 343  Training loss = 2.0696  Validation loss = 4.5656  \n",
      "\n",
      "Fold: 3  Epoch: 344  Training loss = 2.0694  Validation loss = 4.5654  \n",
      "\n",
      "Fold: 3  Epoch: 345  Training loss = 2.0694  Validation loss = 4.5653  \n",
      "\n",
      "Fold: 3  Epoch: 346  Training loss = 2.0693  Validation loss = 4.5652  \n",
      "\n",
      "Fold: 3  Epoch: 347  Training loss = 2.0691  Validation loss = 4.5651  \n",
      "\n",
      "Fold: 3  Epoch: 348  Training loss = 2.0690  Validation loss = 4.5650  \n",
      "\n",
      "Fold: 3  Epoch: 349  Training loss = 2.0689  Validation loss = 4.5648  \n",
      "\n",
      "Fold: 3  Epoch: 350  Training loss = 2.0688  Validation loss = 4.5647  \n",
      "\n",
      "Fold: 3  Epoch: 351  Training loss = 2.0687  Validation loss = 4.5646  \n",
      "\n",
      "Fold: 3  Epoch: 352  Training loss = 2.0686  Validation loss = 4.5645  \n",
      "\n",
      "Fold: 3  Epoch: 353  Training loss = 2.0685  Validation loss = 4.5644  \n",
      "\n",
      "Fold: 3  Epoch: 354  Training loss = 2.0684  Validation loss = 4.5643  \n",
      "\n",
      "Fold: 3  Epoch: 355  Training loss = 2.0683  Validation loss = 4.5642  \n",
      "\n",
      "Fold: 3  Epoch: 356  Training loss = 2.0682  Validation loss = 4.5641  \n",
      "\n",
      "Fold: 3  Epoch: 357  Training loss = 2.0681  Validation loss = 4.5640  \n",
      "\n",
      "Fold: 3  Epoch: 358  Training loss = 2.0680  Validation loss = 4.5638  \n",
      "\n",
      "Fold: 3  Epoch: 359  Training loss = 2.0679  Validation loss = 4.5637  \n",
      "\n",
      "Fold: 3  Epoch: 360  Training loss = 2.0678  Validation loss = 4.5636  \n",
      "\n",
      "Fold: 3  Epoch: 361  Training loss = 2.0677  Validation loss = 4.5635  \n",
      "\n",
      "Fold: 3  Epoch: 362  Training loss = 2.0676  Validation loss = 4.5634  \n",
      "\n",
      "Fold: 3  Epoch: 363  Training loss = 2.0675  Validation loss = 4.5633  \n",
      "\n",
      "Fold: 3  Epoch: 364  Training loss = 2.0674  Validation loss = 4.5631  \n",
      "\n",
      "Fold: 3  Epoch: 365  Training loss = 2.0673  Validation loss = 4.5630  \n",
      "\n",
      "Fold: 3  Epoch: 366  Training loss = 2.0672  Validation loss = 4.5629  \n",
      "\n",
      "Fold: 3  Epoch: 367  Training loss = 2.0670  Validation loss = 4.5627  \n",
      "\n",
      "Fold: 3  Epoch: 368  Training loss = 2.0669  Validation loss = 4.5626  \n",
      "\n",
      "Fold: 3  Epoch: 369  Training loss = 2.0668  Validation loss = 4.5624  \n",
      "\n",
      "Fold: 3  Epoch: 370  Training loss = 2.0667  Validation loss = 4.5623  \n",
      "\n",
      "Fold: 3  Epoch: 371  Training loss = 2.0666  Validation loss = 4.5622  \n",
      "\n",
      "Fold: 3  Epoch: 372  Training loss = 2.0665  Validation loss = 4.5621  \n",
      "\n",
      "Fold: 3  Epoch: 373  Training loss = 2.0664  Validation loss = 4.5620  \n",
      "\n",
      "Fold: 3  Epoch: 374  Training loss = 2.0663  Validation loss = 4.5619  \n",
      "\n",
      "Fold: 3  Epoch: 375  Training loss = 2.0662  Validation loss = 4.5618  \n",
      "\n",
      "Fold: 3  Epoch: 376  Training loss = 2.0661  Validation loss = 4.5617  \n",
      "\n",
      "Fold: 3  Epoch: 377  Training loss = 2.0660  Validation loss = 4.5615  \n",
      "\n",
      "Fold: 3  Epoch: 378  Training loss = 2.0659  Validation loss = 4.5614  \n",
      "\n",
      "Fold: 3  Epoch: 379  Training loss = 2.0657  Validation loss = 4.5613  \n",
      "\n",
      "Fold: 3  Epoch: 380  Training loss = 2.0656  Validation loss = 4.5612  \n",
      "\n",
      "Fold: 3  Epoch: 381  Training loss = 2.0655  Validation loss = 4.5610  \n",
      "\n",
      "Fold: 3  Epoch: 382  Training loss = 2.0654  Validation loss = 4.5609  \n",
      "\n",
      "Fold: 3  Epoch: 383  Training loss = 2.0653  Validation loss = 4.5608  \n",
      "\n",
      "Fold: 3  Epoch: 384  Training loss = 2.0652  Validation loss = 4.5607  \n",
      "\n",
      "Fold: 3  Epoch: 385  Training loss = 2.0651  Validation loss = 4.5606  \n",
      "\n",
      "Fold: 3  Epoch: 386  Training loss = 2.0650  Validation loss = 4.5605  \n",
      "\n",
      "Fold: 3  Epoch: 387  Training loss = 2.0649  Validation loss = 4.5603  \n",
      "\n",
      "Fold: 3  Epoch: 388  Training loss = 2.0648  Validation loss = 4.5602  \n",
      "\n",
      "Fold: 3  Epoch: 389  Training loss = 2.0646  Validation loss = 4.5601  \n",
      "\n",
      "Fold: 3  Epoch: 390  Training loss = 2.0646  Validation loss = 4.5600  \n",
      "\n",
      "Fold: 3  Epoch: 391  Training loss = 2.0644  Validation loss = 4.5598  \n",
      "\n",
      "Fold: 3  Epoch: 392  Training loss = 2.0644  Validation loss = 4.5597  \n",
      "\n",
      "Fold: 3  Epoch: 393  Training loss = 2.0642  Validation loss = 4.5596  \n",
      "\n",
      "Fold: 3  Epoch: 394  Training loss = 2.0641  Validation loss = 4.5595  \n",
      "\n",
      "Fold: 3  Epoch: 395  Training loss = 2.0640  Validation loss = 4.5594  \n",
      "\n",
      "Fold: 3  Epoch: 396  Training loss = 2.0640  Validation loss = 4.5593  \n",
      "\n",
      "Fold: 3  Epoch: 397  Training loss = 2.0638  Validation loss = 4.5592  \n",
      "\n",
      "Fold: 3  Epoch: 398  Training loss = 2.0637  Validation loss = 4.5591  \n",
      "\n",
      "Fold: 3  Epoch: 399  Training loss = 2.0636  Validation loss = 4.5589  \n",
      "\n",
      "Fold: 3  Epoch: 400  Training loss = 2.0635  Validation loss = 4.5588  \n",
      "\n",
      "Fold: 3  Epoch: 401  Training loss = 2.0634  Validation loss = 4.5587  \n",
      "\n",
      "Fold: 3  Epoch: 402  Training loss = 2.0633  Validation loss = 4.5586  \n",
      "\n",
      "Fold: 3  Epoch: 403  Training loss = 2.0632  Validation loss = 4.5584  \n",
      "\n",
      "Fold: 3  Epoch: 404  Training loss = 2.0631  Validation loss = 4.5583  \n",
      "\n",
      "Fold: 3  Epoch: 405  Training loss = 2.0630  Validation loss = 4.5582  \n",
      "\n",
      "Fold: 3  Epoch: 406  Training loss = 2.0629  Validation loss = 4.5581  \n",
      "\n",
      "Fold: 3  Epoch: 407  Training loss = 2.0628  Validation loss = 4.5580  \n",
      "\n",
      "Fold: 3  Epoch: 408  Training loss = 2.0627  Validation loss = 4.5579  \n",
      "\n",
      "Fold: 3  Epoch: 409  Training loss = 2.0626  Validation loss = 4.5577  \n",
      "\n",
      "Fold: 3  Epoch: 410  Training loss = 2.0625  Validation loss = 4.5576  \n",
      "\n",
      "Fold: 3  Epoch: 411  Training loss = 2.0624  Validation loss = 4.5575  \n",
      "\n",
      "Fold: 3  Epoch: 412  Training loss = 2.0623  Validation loss = 4.5574  \n",
      "\n",
      "Fold: 3  Epoch: 413  Training loss = 2.0622  Validation loss = 4.5573  \n",
      "\n",
      "Fold: 3  Epoch: 414  Training loss = 2.0621  Validation loss = 4.5572  \n",
      "\n",
      "Fold: 3  Epoch: 415  Training loss = 2.0620  Validation loss = 4.5571  \n",
      "\n",
      "Fold: 3  Epoch: 416  Training loss = 2.0619  Validation loss = 4.5570  \n",
      "\n",
      "Fold: 3  Epoch: 417  Training loss = 2.0618  Validation loss = 4.5569  \n",
      "\n",
      "Fold: 3  Epoch: 418  Training loss = 2.0617  Validation loss = 4.5568  \n",
      "\n",
      "Fold: 3  Epoch: 419  Training loss = 2.0616  Validation loss = 4.5566  \n",
      "\n",
      "Fold: 3  Epoch: 420  Training loss = 2.0615  Validation loss = 4.5565  \n",
      "\n",
      "Fold: 3  Epoch: 421  Training loss = 2.0614  Validation loss = 4.5564  \n",
      "\n",
      "Fold: 3  Epoch: 422  Training loss = 2.0613  Validation loss = 4.5562  \n",
      "\n",
      "Fold: 3  Epoch: 423  Training loss = 2.0612  Validation loss = 4.5561  \n",
      "\n",
      "Fold: 3  Epoch: 424  Training loss = 2.0610  Validation loss = 4.5560  \n",
      "\n",
      "Fold: 3  Epoch: 425  Training loss = 2.0609  Validation loss = 4.5559  \n",
      "\n",
      "Fold: 3  Epoch: 426  Training loss = 2.0608  Validation loss = 4.5557  \n",
      "\n",
      "Fold: 3  Epoch: 427  Training loss = 2.0607  Validation loss = 4.5556  \n",
      "\n",
      "Fold: 3  Epoch: 428  Training loss = 2.0606  Validation loss = 4.5555  \n",
      "\n",
      "Fold: 3  Epoch: 429  Training loss = 2.0605  Validation loss = 4.5554  \n",
      "\n",
      "Fold: 3  Epoch: 430  Training loss = 2.0604  Validation loss = 4.5553  \n",
      "\n",
      "Fold: 3  Epoch: 431  Training loss = 2.0603  Validation loss = 4.5552  \n",
      "\n",
      "Fold: 3  Epoch: 432  Training loss = 2.0602  Validation loss = 4.5550  \n",
      "\n",
      "Fold: 3  Epoch: 433  Training loss = 2.0601  Validation loss = 4.5549  \n",
      "\n",
      "Fold: 3  Epoch: 434  Training loss = 2.0600  Validation loss = 4.5548  \n",
      "\n",
      "Fold: 3  Epoch: 435  Training loss = 2.0599  Validation loss = 4.5546  \n",
      "\n",
      "Fold: 3  Epoch: 436  Training loss = 2.0597  Validation loss = 4.5545  \n",
      "\n",
      "Fold: 3  Epoch: 437  Training loss = 2.0596  Validation loss = 4.5544  \n",
      "\n",
      "Fold: 3  Epoch: 438  Training loss = 2.0595  Validation loss = 4.5543  \n",
      "\n",
      "Fold: 3  Epoch: 439  Training loss = 2.0594  Validation loss = 4.5541  \n",
      "\n",
      "Fold: 3  Epoch: 440  Training loss = 2.0593  Validation loss = 4.5540  \n",
      "\n",
      "Fold: 3  Epoch: 441  Training loss = 2.0592  Validation loss = 4.5539  \n",
      "\n",
      "Fold: 3  Epoch: 442  Training loss = 2.0591  Validation loss = 4.5538  \n",
      "\n",
      "Fold: 3  Epoch: 443  Training loss = 2.0590  Validation loss = 4.5537  \n",
      "\n",
      "Fold: 3  Epoch: 444  Training loss = 2.0589  Validation loss = 4.5536  \n",
      "\n",
      "Fold: 3  Epoch: 445  Training loss = 2.0588  Validation loss = 4.5535  \n",
      "\n",
      "Fold: 3  Epoch: 446  Training loss = 2.0587  Validation loss = 4.5534  \n",
      "\n",
      "Fold: 3  Epoch: 447  Training loss = 2.0586  Validation loss = 4.5533  \n",
      "\n",
      "Fold: 3  Epoch: 448  Training loss = 2.0585  Validation loss = 4.5531  \n",
      "\n",
      "Fold: 3  Epoch: 449  Training loss = 2.0584  Validation loss = 4.5530  \n",
      "\n",
      "Fold: 3  Epoch: 450  Training loss = 2.0583  Validation loss = 4.5529  \n",
      "\n",
      "Fold: 3  Epoch: 451  Training loss = 2.0582  Validation loss = 4.5528  \n",
      "\n",
      "Fold: 3  Epoch: 452  Training loss = 2.0581  Validation loss = 4.5526  \n",
      "\n",
      "Fold: 3  Epoch: 453  Training loss = 2.0580  Validation loss = 4.5525  \n",
      "\n",
      "Fold: 3  Epoch: 454  Training loss = 2.0579  Validation loss = 4.5524  \n",
      "\n",
      "Fold: 3  Epoch: 455  Training loss = 2.0578  Validation loss = 4.5523  \n",
      "\n",
      "Fold: 3  Epoch: 456  Training loss = 2.0577  Validation loss = 4.5522  \n",
      "\n",
      "Fold: 3  Epoch: 457  Training loss = 2.0576  Validation loss = 4.5521  \n",
      "\n",
      "Fold: 3  Epoch: 458  Training loss = 2.0575  Validation loss = 4.5519  \n",
      "\n",
      "Fold: 3  Epoch: 459  Training loss = 2.0574  Validation loss = 4.5518  \n",
      "\n",
      "Fold: 3  Epoch: 460  Training loss = 2.0573  Validation loss = 4.5517  \n",
      "\n",
      "Fold: 3  Epoch: 461  Training loss = 2.0572  Validation loss = 4.5516  \n",
      "\n",
      "Fold: 3  Epoch: 462  Training loss = 2.0571  Validation loss = 4.5515  \n",
      "\n",
      "Fold: 3  Epoch: 463  Training loss = 2.0570  Validation loss = 4.5513  \n",
      "\n",
      "Fold: 3  Epoch: 464  Training loss = 2.0569  Validation loss = 4.5512  \n",
      "\n",
      "Fold: 3  Epoch: 465  Training loss = 2.0568  Validation loss = 4.5511  \n",
      "\n",
      "Fold: 3  Epoch: 466  Training loss = 2.0566  Validation loss = 4.5509  \n",
      "\n",
      "Fold: 3  Epoch: 467  Training loss = 2.0565  Validation loss = 4.5508  \n",
      "\n",
      "Fold: 3  Epoch: 468  Training loss = 2.0565  Validation loss = 4.5507  \n",
      "\n",
      "Fold: 3  Epoch: 469  Training loss = 2.0564  Validation loss = 4.5506  \n",
      "\n",
      "Fold: 3  Epoch: 470  Training loss = 2.0563  Validation loss = 4.5505  \n",
      "\n",
      "Fold: 3  Epoch: 471  Training loss = 2.0562  Validation loss = 4.5504  \n",
      "\n",
      "Fold: 3  Epoch: 472  Training loss = 2.0561  Validation loss = 4.5503  \n",
      "\n",
      "Fold: 3  Epoch: 473  Training loss = 2.0560  Validation loss = 4.5502  \n",
      "\n",
      "Fold: 3  Epoch: 474  Training loss = 2.0559  Validation loss = 4.5501  \n",
      "\n",
      "Fold: 3  Epoch: 475  Training loss = 2.0558  Validation loss = 4.5500  \n",
      "\n",
      "Fold: 3  Epoch: 476  Training loss = 2.0557  Validation loss = 4.5499  \n",
      "\n",
      "Fold: 3  Epoch: 477  Training loss = 2.0556  Validation loss = 4.5498  \n",
      "\n",
      "Fold: 3  Epoch: 478  Training loss = 2.0555  Validation loss = 4.5496  \n",
      "\n",
      "Fold: 3  Epoch: 479  Training loss = 2.0554  Validation loss = 4.5495  \n",
      "\n",
      "Fold: 3  Epoch: 480  Training loss = 2.0553  Validation loss = 4.5494  \n",
      "\n",
      "Fold: 3  Epoch: 481  Training loss = 2.0552  Validation loss = 4.5492  \n",
      "\n",
      "Fold: 3  Epoch: 482  Training loss = 2.0551  Validation loss = 4.5491  \n",
      "\n",
      "Fold: 3  Epoch: 483  Training loss = 2.0549  Validation loss = 4.5490  \n",
      "\n",
      "Fold: 3  Epoch: 484  Training loss = 2.0549  Validation loss = 4.5489  \n",
      "\n",
      "Fold: 3  Epoch: 485  Training loss = 2.0548  Validation loss = 4.5488  \n",
      "\n",
      "Fold: 3  Epoch: 486  Training loss = 2.0547  Validation loss = 4.5487  \n",
      "\n",
      "Fold: 3  Epoch: 487  Training loss = 2.0546  Validation loss = 4.5485  \n",
      "\n",
      "Fold: 3  Epoch: 488  Training loss = 2.0545  Validation loss = 4.5484  \n",
      "\n",
      "Fold: 3  Epoch: 489  Training loss = 2.0544  Validation loss = 4.5483  \n",
      "\n",
      "Fold: 3  Epoch: 490  Training loss = 2.0543  Validation loss = 4.5482  \n",
      "\n",
      "Fold: 3  Epoch: 491  Training loss = 2.0542  Validation loss = 4.5481  \n",
      "\n",
      "Fold: 3  Epoch: 492  Training loss = 2.0541  Validation loss = 4.5480  \n",
      "\n",
      "Fold: 3  Epoch: 493  Training loss = 2.0540  Validation loss = 4.5478  \n",
      "\n",
      "Fold: 3  Epoch: 494  Training loss = 2.0539  Validation loss = 4.5477  \n",
      "\n",
      "Fold: 3  Epoch: 495  Training loss = 2.0538  Validation loss = 4.5476  \n",
      "\n",
      "Fold: 3  Epoch: 496  Training loss = 2.0537  Validation loss = 4.5475  \n",
      "\n",
      "Fold: 3  Epoch: 497  Training loss = 2.0536  Validation loss = 4.5474  \n",
      "\n",
      "Fold: 3  Epoch: 498  Training loss = 2.0535  Validation loss = 4.5473  \n",
      "\n",
      "Fold: 3  Epoch: 499  Training loss = 2.0534  Validation loss = 4.5472  \n",
      "\n",
      "Fold: 3  Epoch: 500  Training loss = 2.0533  Validation loss = 4.5471  \n",
      "\n",
      "Check model:  Fold: 3  Optimal epoch: 500  \n",
      "\n",
      "Fold: 4  Epoch: 1  Training loss = 2.1785  Validation loss = 5.7720  \n",
      "\n",
      "Fold: 4  Epoch: 2  Training loss = 2.1784  Validation loss = 5.7719  \n",
      "\n",
      "Fold: 4  Epoch: 3  Training loss = 2.1783  Validation loss = 5.7717  \n",
      "\n",
      "Fold: 4  Epoch: 4  Training loss = 2.1781  Validation loss = 5.7716  \n",
      "\n",
      "Fold: 4  Epoch: 5  Training loss = 2.1780  Validation loss = 5.7714  \n",
      "\n",
      "Fold: 4  Epoch: 6  Training loss = 2.1780  Validation loss = 5.7713  \n",
      "\n",
      "Fold: 4  Epoch: 7  Training loss = 2.1778  Validation loss = 5.7712  \n",
      "\n",
      "Fold: 4  Epoch: 8  Training loss = 2.1777  Validation loss = 5.7710  \n",
      "\n",
      "Fold: 4  Epoch: 9  Training loss = 2.1776  Validation loss = 5.7709  \n",
      "\n",
      "Fold: 4  Epoch: 10  Training loss = 2.1775  Validation loss = 5.7707  \n",
      "\n",
      "Fold: 4  Epoch: 11  Training loss = 2.1774  Validation loss = 5.7706  \n",
      "\n",
      "Fold: 4  Epoch: 12  Training loss = 2.1773  Validation loss = 5.7704  \n",
      "\n",
      "Fold: 4  Epoch: 13  Training loss = 2.1772  Validation loss = 5.7702  \n",
      "\n",
      "Fold: 4  Epoch: 14  Training loss = 2.1771  Validation loss = 5.7701  \n",
      "\n",
      "Fold: 4  Epoch: 15  Training loss = 2.1770  Validation loss = 5.7699  \n",
      "\n",
      "Fold: 4  Epoch: 16  Training loss = 2.1768  Validation loss = 5.7697  \n",
      "\n",
      "Fold: 4  Epoch: 17  Training loss = 2.1767  Validation loss = 5.7696  \n",
      "\n",
      "Fold: 4  Epoch: 18  Training loss = 2.1766  Validation loss = 5.7695  \n",
      "\n",
      "Fold: 4  Epoch: 19  Training loss = 2.1765  Validation loss = 5.7693  \n",
      "\n",
      "Fold: 4  Epoch: 20  Training loss = 2.1764  Validation loss = 5.7691  \n",
      "\n",
      "Fold: 4  Epoch: 21  Training loss = 2.1763  Validation loss = 5.7690  \n",
      "\n",
      "Fold: 4  Epoch: 22  Training loss = 2.1762  Validation loss = 5.7688  \n",
      "\n",
      "Fold: 4  Epoch: 23  Training loss = 2.1761  Validation loss = 5.7687  \n",
      "\n",
      "Fold: 4  Epoch: 24  Training loss = 2.1760  Validation loss = 5.7686  \n",
      "\n",
      "Fold: 4  Epoch: 25  Training loss = 2.1759  Validation loss = 5.7684  \n",
      "\n",
      "Fold: 4  Epoch: 26  Training loss = 2.1758  Validation loss = 5.7683  \n",
      "\n",
      "Fold: 4  Epoch: 27  Training loss = 2.1757  Validation loss = 5.7682  \n",
      "\n",
      "Fold: 4  Epoch: 28  Training loss = 2.1756  Validation loss = 5.7680  \n",
      "\n",
      "Fold: 4  Epoch: 29  Training loss = 2.1755  Validation loss = 5.7679  \n",
      "\n",
      "Fold: 4  Epoch: 30  Training loss = 2.1754  Validation loss = 5.7678  \n",
      "\n",
      "Fold: 4  Epoch: 31  Training loss = 2.1753  Validation loss = 5.7677  \n",
      "\n",
      "Fold: 4  Epoch: 32  Training loss = 2.1752  Validation loss = 5.7675  \n",
      "\n",
      "Fold: 4  Epoch: 33  Training loss = 2.1751  Validation loss = 5.7674  \n",
      "\n",
      "Fold: 4  Epoch: 34  Training loss = 2.1750  Validation loss = 5.7672  \n",
      "\n",
      "Fold: 4  Epoch: 35  Training loss = 2.1749  Validation loss = 5.7671  \n",
      "\n",
      "Fold: 4  Epoch: 36  Training loss = 2.1748  Validation loss = 5.7669  \n",
      "\n",
      "Fold: 4  Epoch: 37  Training loss = 2.1747  Validation loss = 5.7667  \n",
      "\n",
      "Fold: 4  Epoch: 38  Training loss = 2.1746  Validation loss = 5.7666  \n",
      "\n",
      "Fold: 4  Epoch: 39  Training loss = 2.1744  Validation loss = 5.7664  \n",
      "\n",
      "Fold: 4  Epoch: 40  Training loss = 2.1744  Validation loss = 5.7663  \n",
      "\n",
      "Fold: 4  Epoch: 41  Training loss = 2.1742  Validation loss = 5.7661  \n",
      "\n",
      "Fold: 4  Epoch: 42  Training loss = 2.1741  Validation loss = 5.7660  \n",
      "\n",
      "Fold: 4  Epoch: 43  Training loss = 2.1740  Validation loss = 5.7658  \n",
      "\n",
      "Fold: 4  Epoch: 44  Training loss = 2.1739  Validation loss = 5.7656  \n",
      "\n",
      "Fold: 4  Epoch: 45  Training loss = 2.1738  Validation loss = 5.7655  \n",
      "\n",
      "Fold: 4  Epoch: 46  Training loss = 2.1737  Validation loss = 5.7653  \n",
      "\n",
      "Fold: 4  Epoch: 47  Training loss = 2.1736  Validation loss = 5.7652  \n",
      "\n",
      "Fold: 4  Epoch: 48  Training loss = 2.1735  Validation loss = 5.7650  \n",
      "\n",
      "Fold: 4  Epoch: 49  Training loss = 2.1734  Validation loss = 5.7649  \n",
      "\n",
      "Fold: 4  Epoch: 50  Training loss = 2.1733  Validation loss = 5.7647  \n",
      "\n",
      "Fold: 4  Epoch: 51  Training loss = 2.1732  Validation loss = 5.7646  \n",
      "\n",
      "Fold: 4  Epoch: 52  Training loss = 2.1731  Validation loss = 5.7644  \n",
      "\n",
      "Fold: 4  Epoch: 53  Training loss = 2.1730  Validation loss = 5.7643  \n",
      "\n",
      "Fold: 4  Epoch: 54  Training loss = 2.1729  Validation loss = 5.7642  \n",
      "\n",
      "Fold: 4  Epoch: 55  Training loss = 2.1728  Validation loss = 5.7641  \n",
      "\n",
      "Fold: 4  Epoch: 56  Training loss = 2.1727  Validation loss = 5.7639  \n",
      "\n",
      "Fold: 4  Epoch: 57  Training loss = 2.1725  Validation loss = 5.7637  \n",
      "\n",
      "Fold: 4  Epoch: 58  Training loss = 2.1724  Validation loss = 5.7635  \n",
      "\n",
      "Fold: 4  Epoch: 59  Training loss = 2.1723  Validation loss = 5.7634  \n",
      "\n",
      "Fold: 4  Epoch: 60  Training loss = 2.1722  Validation loss = 5.7632  \n",
      "\n",
      "Fold: 4  Epoch: 61  Training loss = 2.1721  Validation loss = 5.7630  \n",
      "\n",
      "Fold: 4  Epoch: 62  Training loss = 2.1719  Validation loss = 5.7628  \n",
      "\n",
      "Fold: 4  Epoch: 63  Training loss = 2.1718  Validation loss = 5.7626  \n",
      "\n",
      "Fold: 4  Epoch: 64  Training loss = 2.1717  Validation loss = 5.7625  \n",
      "\n",
      "Fold: 4  Epoch: 65  Training loss = 2.1716  Validation loss = 5.7623  \n",
      "\n",
      "Fold: 4  Epoch: 66  Training loss = 2.1715  Validation loss = 5.7622  \n",
      "\n",
      "Fold: 4  Epoch: 67  Training loss = 2.1714  Validation loss = 5.7620  \n",
      "\n",
      "Fold: 4  Epoch: 68  Training loss = 2.1713  Validation loss = 5.7619  \n",
      "\n",
      "Fold: 4  Epoch: 69  Training loss = 2.1712  Validation loss = 5.7617  \n",
      "\n",
      "Fold: 4  Epoch: 70  Training loss = 2.1711  Validation loss = 5.7616  \n",
      "\n",
      "Fold: 4  Epoch: 71  Training loss = 2.1709  Validation loss = 5.7614  \n",
      "\n",
      "Fold: 4  Epoch: 72  Training loss = 2.1708  Validation loss = 5.7612  \n",
      "\n",
      "Fold: 4  Epoch: 73  Training loss = 2.1707  Validation loss = 5.7611  \n",
      "\n",
      "Fold: 4  Epoch: 74  Training loss = 2.1706  Validation loss = 5.7609  \n",
      "\n",
      "Fold: 4  Epoch: 75  Training loss = 2.1705  Validation loss = 5.7608  \n",
      "\n",
      "Fold: 4  Epoch: 76  Training loss = 2.1704  Validation loss = 5.7606  \n",
      "\n",
      "Fold: 4  Epoch: 77  Training loss = 2.1703  Validation loss = 5.7605  \n",
      "\n",
      "Fold: 4  Epoch: 78  Training loss = 2.1702  Validation loss = 5.7603  \n",
      "\n",
      "Fold: 4  Epoch: 79  Training loss = 2.1701  Validation loss = 5.7602  \n",
      "\n",
      "Fold: 4  Epoch: 80  Training loss = 2.1700  Validation loss = 5.7600  \n",
      "\n",
      "Fold: 4  Epoch: 81  Training loss = 2.1699  Validation loss = 5.7599  \n",
      "\n",
      "Fold: 4  Epoch: 82  Training loss = 2.1697  Validation loss = 5.7597  \n",
      "\n",
      "Fold: 4  Epoch: 83  Training loss = 2.1696  Validation loss = 5.7596  \n",
      "\n",
      "Fold: 4  Epoch: 84  Training loss = 2.1695  Validation loss = 5.7594  \n",
      "\n",
      "Fold: 4  Epoch: 85  Training loss = 2.1694  Validation loss = 5.7593  \n",
      "\n",
      "Fold: 4  Epoch: 86  Training loss = 2.1694  Validation loss = 5.7592  \n",
      "\n",
      "Fold: 4  Epoch: 87  Training loss = 2.1693  Validation loss = 5.7590  \n",
      "\n",
      "Fold: 4  Epoch: 88  Training loss = 2.1691  Validation loss = 5.7588  \n",
      "\n",
      "Fold: 4  Epoch: 89  Training loss = 2.1690  Validation loss = 5.7586  \n",
      "\n",
      "Fold: 4  Epoch: 90  Training loss = 2.1689  Validation loss = 5.7585  \n",
      "\n",
      "Fold: 4  Epoch: 91  Training loss = 2.1688  Validation loss = 5.7584  \n",
      "\n",
      "Fold: 4  Epoch: 92  Training loss = 2.1687  Validation loss = 5.7583  \n",
      "\n",
      "Fold: 4  Epoch: 93  Training loss = 2.1686  Validation loss = 5.7581  \n",
      "\n",
      "Fold: 4  Epoch: 94  Training loss = 2.1685  Validation loss = 5.7579  \n",
      "\n",
      "Fold: 4  Epoch: 95  Training loss = 2.1684  Validation loss = 5.7578  \n",
      "\n",
      "Fold: 4  Epoch: 96  Training loss = 2.1683  Validation loss = 5.7576  \n",
      "\n",
      "Fold: 4  Epoch: 97  Training loss = 2.1682  Validation loss = 5.7574  \n",
      "\n",
      "Fold: 4  Epoch: 98  Training loss = 2.1681  Validation loss = 5.7573  \n",
      "\n",
      "Fold: 4  Epoch: 99  Training loss = 2.1680  Validation loss = 5.7571  \n",
      "\n",
      "Fold: 4  Epoch: 100  Training loss = 2.1679  Validation loss = 5.7570  \n",
      "\n",
      "Fold: 4  Epoch: 101  Training loss = 2.1678  Validation loss = 5.7569  \n",
      "\n",
      "Fold: 4  Epoch: 102  Training loss = 2.1677  Validation loss = 5.7567  \n",
      "\n",
      "Fold: 4  Epoch: 103  Training loss = 2.1675  Validation loss = 5.7566  \n",
      "\n",
      "Fold: 4  Epoch: 104  Training loss = 2.1674  Validation loss = 5.7564  \n",
      "\n",
      "Fold: 4  Epoch: 105  Training loss = 2.1673  Validation loss = 5.7562  \n",
      "\n",
      "Fold: 4  Epoch: 106  Training loss = 2.1672  Validation loss = 5.7561  \n",
      "\n",
      "Fold: 4  Epoch: 107  Training loss = 2.1671  Validation loss = 5.7559  \n",
      "\n",
      "Fold: 4  Epoch: 108  Training loss = 2.1670  Validation loss = 5.7557  \n",
      "\n",
      "Fold: 4  Epoch: 109  Training loss = 2.1669  Validation loss = 5.7556  \n",
      "\n",
      "Fold: 4  Epoch: 110  Training loss = 2.1668  Validation loss = 5.7555  \n",
      "\n",
      "Fold: 4  Epoch: 111  Training loss = 2.1667  Validation loss = 5.7553  \n",
      "\n",
      "Fold: 4  Epoch: 112  Training loss = 2.1666  Validation loss = 5.7552  \n",
      "\n",
      "Fold: 4  Epoch: 113  Training loss = 2.1665  Validation loss = 5.7550  \n",
      "\n",
      "Fold: 4  Epoch: 114  Training loss = 2.1664  Validation loss = 5.7549  \n",
      "\n",
      "Fold: 4  Epoch: 115  Training loss = 2.1662  Validation loss = 5.7547  \n",
      "\n",
      "Fold: 4  Epoch: 116  Training loss = 2.1661  Validation loss = 5.7546  \n",
      "\n",
      "Fold: 4  Epoch: 117  Training loss = 2.1660  Validation loss = 5.7544  \n",
      "\n",
      "Fold: 4  Epoch: 118  Training loss = 2.1659  Validation loss = 5.7542  \n",
      "\n",
      "Fold: 4  Epoch: 119  Training loss = 2.1658  Validation loss = 5.7541  \n",
      "\n",
      "Fold: 4  Epoch: 120  Training loss = 2.1657  Validation loss = 5.7539  \n",
      "\n",
      "Fold: 4  Epoch: 121  Training loss = 2.1655  Validation loss = 5.7537  \n",
      "\n",
      "Fold: 4  Epoch: 122  Training loss = 2.1654  Validation loss = 5.7535  \n",
      "\n",
      "Fold: 4  Epoch: 123  Training loss = 2.1654  Validation loss = 5.7535  \n",
      "\n",
      "Fold: 4  Epoch: 124  Training loss = 2.1652  Validation loss = 5.7533  \n",
      "\n",
      "Fold: 4  Epoch: 125  Training loss = 2.1651  Validation loss = 5.7531  \n",
      "\n",
      "Fold: 4  Epoch: 126  Training loss = 2.1650  Validation loss = 5.7530  \n",
      "\n",
      "Fold: 4  Epoch: 127  Training loss = 2.1649  Validation loss = 5.7528  \n",
      "\n",
      "Fold: 4  Epoch: 128  Training loss = 2.1648  Validation loss = 5.7526  \n",
      "\n",
      "Fold: 4  Epoch: 129  Training loss = 2.1647  Validation loss = 5.7525  \n",
      "\n",
      "Fold: 4  Epoch: 130  Training loss = 2.1646  Validation loss = 5.7524  \n",
      "\n",
      "Fold: 4  Epoch: 131  Training loss = 2.1645  Validation loss = 5.7522  \n",
      "\n",
      "Fold: 4  Epoch: 132  Training loss = 2.1644  Validation loss = 5.7520  \n",
      "\n",
      "Fold: 4  Epoch: 133  Training loss = 2.1642  Validation loss = 5.7518  \n",
      "\n",
      "Fold: 4  Epoch: 134  Training loss = 2.1641  Validation loss = 5.7517  \n",
      "\n",
      "Fold: 4  Epoch: 135  Training loss = 2.1640  Validation loss = 5.7515  \n",
      "\n",
      "Fold: 4  Epoch: 136  Training loss = 2.1640  Validation loss = 5.7514  \n",
      "\n",
      "Fold: 4  Epoch: 137  Training loss = 2.1639  Validation loss = 5.7513  \n",
      "\n",
      "Fold: 4  Epoch: 138  Training loss = 2.1638  Validation loss = 5.7511  \n",
      "\n",
      "Fold: 4  Epoch: 139  Training loss = 2.1637  Validation loss = 5.7510  \n",
      "\n",
      "Fold: 4  Epoch: 140  Training loss = 2.1636  Validation loss = 5.7509  \n",
      "\n",
      "Fold: 4  Epoch: 141  Training loss = 2.1635  Validation loss = 5.7507  \n",
      "\n",
      "Fold: 4  Epoch: 142  Training loss = 2.1634  Validation loss = 5.7506  \n",
      "\n",
      "Fold: 4  Epoch: 143  Training loss = 2.1633  Validation loss = 5.7504  \n",
      "\n",
      "Fold: 4  Epoch: 144  Training loss = 2.1632  Validation loss = 5.7503  \n",
      "\n",
      "Fold: 4  Epoch: 145  Training loss = 2.1631  Validation loss = 5.7501  \n",
      "\n",
      "Fold: 4  Epoch: 146  Training loss = 2.1629  Validation loss = 5.7499  \n",
      "\n",
      "Fold: 4  Epoch: 147  Training loss = 2.1629  Validation loss = 5.7499  \n",
      "\n",
      "Fold: 4  Epoch: 148  Training loss = 2.1627  Validation loss = 5.7497  \n",
      "\n",
      "Fold: 4  Epoch: 149  Training loss = 2.1626  Validation loss = 5.7496  \n",
      "\n",
      "Fold: 4  Epoch: 150  Training loss = 2.1626  Validation loss = 5.7494  \n",
      "\n",
      "Fold: 4  Epoch: 151  Training loss = 2.1624  Validation loss = 5.7492  \n",
      "\n",
      "Fold: 4  Epoch: 152  Training loss = 2.1623  Validation loss = 5.7491  \n",
      "\n",
      "Fold: 4  Epoch: 153  Training loss = 2.1622  Validation loss = 5.7489  \n",
      "\n",
      "Fold: 4  Epoch: 154  Training loss = 2.1621  Validation loss = 5.7488  \n",
      "\n",
      "Fold: 4  Epoch: 155  Training loss = 2.1620  Validation loss = 5.7487  \n",
      "\n",
      "Fold: 4  Epoch: 156  Training loss = 2.1619  Validation loss = 5.7485  \n",
      "\n",
      "Fold: 4  Epoch: 157  Training loss = 2.1618  Validation loss = 5.7484  \n",
      "\n",
      "Fold: 4  Epoch: 158  Training loss = 2.1617  Validation loss = 5.7482  \n",
      "\n",
      "Fold: 4  Epoch: 159  Training loss = 2.1616  Validation loss = 5.7481  \n",
      "\n",
      "Fold: 4  Epoch: 160  Training loss = 2.1615  Validation loss = 5.7479  \n",
      "\n",
      "Fold: 4  Epoch: 161  Training loss = 2.1614  Validation loss = 5.7478  \n",
      "\n",
      "Fold: 4  Epoch: 162  Training loss = 2.1612  Validation loss = 5.7476  \n",
      "\n",
      "Fold: 4  Epoch: 163  Training loss = 2.1611  Validation loss = 5.7474  \n",
      "\n",
      "Fold: 4  Epoch: 164  Training loss = 2.1611  Validation loss = 5.7473  \n",
      "\n",
      "Fold: 4  Epoch: 165  Training loss = 2.1610  Validation loss = 5.7472  \n",
      "\n",
      "Fold: 4  Epoch: 166  Training loss = 2.1608  Validation loss = 5.7470  \n",
      "\n",
      "Fold: 4  Epoch: 167  Training loss = 2.1608  Validation loss = 5.7469  \n",
      "\n",
      "Fold: 4  Epoch: 168  Training loss = 2.1607  Validation loss = 5.7468  \n",
      "\n",
      "Fold: 4  Epoch: 169  Training loss = 2.1606  Validation loss = 5.7467  \n",
      "\n",
      "Fold: 4  Epoch: 170  Training loss = 2.1604  Validation loss = 5.7465  \n",
      "\n",
      "Fold: 4  Epoch: 171  Training loss = 2.1603  Validation loss = 5.7463  \n",
      "\n",
      "Fold: 4  Epoch: 172  Training loss = 2.1602  Validation loss = 5.7462  \n",
      "\n",
      "Fold: 4  Epoch: 173  Training loss = 2.1601  Validation loss = 5.7460  \n",
      "\n",
      "Fold: 4  Epoch: 174  Training loss = 2.1600  Validation loss = 5.7459  \n",
      "\n",
      "Fold: 4  Epoch: 175  Training loss = 2.1599  Validation loss = 5.7457  \n",
      "\n",
      "Fold: 4  Epoch: 176  Training loss = 2.1598  Validation loss = 5.7456  \n",
      "\n",
      "Fold: 4  Epoch: 177  Training loss = 2.1597  Validation loss = 5.7454  \n",
      "\n",
      "Fold: 4  Epoch: 178  Training loss = 2.1596  Validation loss = 5.7453  \n",
      "\n",
      "Fold: 4  Epoch: 179  Training loss = 2.1595  Validation loss = 5.7451  \n",
      "\n",
      "Fold: 4  Epoch: 180  Training loss = 2.1594  Validation loss = 5.7450  \n",
      "\n",
      "Fold: 4  Epoch: 181  Training loss = 2.1593  Validation loss = 5.7449  \n",
      "\n",
      "Fold: 4  Epoch: 182  Training loss = 2.1592  Validation loss = 5.7447  \n",
      "\n",
      "Fold: 4  Epoch: 183  Training loss = 2.1591  Validation loss = 5.7446  \n",
      "\n",
      "Fold: 4  Epoch: 184  Training loss = 2.1590  Validation loss = 5.7444  \n",
      "\n",
      "Fold: 4  Epoch: 185  Training loss = 2.1589  Validation loss = 5.7443  \n",
      "\n",
      "Fold: 4  Epoch: 186  Training loss = 2.1588  Validation loss = 5.7442  \n",
      "\n",
      "Fold: 4  Epoch: 187  Training loss = 2.1587  Validation loss = 5.7440  \n",
      "\n",
      "Fold: 4  Epoch: 188  Training loss = 2.1586  Validation loss = 5.7438  \n",
      "\n",
      "Fold: 4  Epoch: 189  Training loss = 2.1585  Validation loss = 5.7437  \n",
      "\n",
      "Fold: 4  Epoch: 190  Training loss = 2.1584  Validation loss = 5.7435  \n",
      "\n",
      "Fold: 4  Epoch: 191  Training loss = 2.1583  Validation loss = 5.7434  \n",
      "\n",
      "Fold: 4  Epoch: 192  Training loss = 2.1582  Validation loss = 5.7433  \n",
      "\n",
      "Fold: 4  Epoch: 193  Training loss = 2.1581  Validation loss = 5.7431  \n",
      "\n",
      "Fold: 4  Epoch: 194  Training loss = 2.1579  Validation loss = 5.7430  \n",
      "\n",
      "Fold: 4  Epoch: 195  Training loss = 2.1578  Validation loss = 5.7428  \n",
      "\n",
      "Fold: 4  Epoch: 196  Training loss = 2.1577  Validation loss = 5.7426  \n",
      "\n",
      "Fold: 4  Epoch: 197  Training loss = 2.1576  Validation loss = 5.7425  \n",
      "\n",
      "Fold: 4  Epoch: 198  Training loss = 2.1575  Validation loss = 5.7424  \n",
      "\n",
      "Fold: 4  Epoch: 199  Training loss = 2.1575  Validation loss = 5.7423  \n",
      "\n",
      "Fold: 4  Epoch: 200  Training loss = 2.1573  Validation loss = 5.7421  \n",
      "\n",
      "Fold: 4  Epoch: 201  Training loss = 2.1572  Validation loss = 5.7420  \n",
      "\n",
      "Fold: 4  Epoch: 202  Training loss = 2.1571  Validation loss = 5.7418  \n",
      "\n",
      "Fold: 4  Epoch: 203  Training loss = 2.1570  Validation loss = 5.7417  \n",
      "\n",
      "Fold: 4  Epoch: 204  Training loss = 2.1569  Validation loss = 5.7415  \n",
      "\n",
      "Fold: 4  Epoch: 205  Training loss = 2.1568  Validation loss = 5.7413  \n",
      "\n",
      "Fold: 4  Epoch: 206  Training loss = 2.1567  Validation loss = 5.7412  \n",
      "\n",
      "Fold: 4  Epoch: 207  Training loss = 2.1566  Validation loss = 5.7410  \n",
      "\n",
      "Fold: 4  Epoch: 208  Training loss = 2.1565  Validation loss = 5.7409  \n",
      "\n",
      "Fold: 4  Epoch: 209  Training loss = 2.1564  Validation loss = 5.7407  \n",
      "\n",
      "Fold: 4  Epoch: 210  Training loss = 2.1563  Validation loss = 5.7405  \n",
      "\n",
      "Fold: 4  Epoch: 211  Training loss = 2.1562  Validation loss = 5.7403  \n",
      "\n",
      "Fold: 4  Epoch: 212  Training loss = 2.1561  Validation loss = 5.7402  \n",
      "\n",
      "Fold: 4  Epoch: 213  Training loss = 2.1559  Validation loss = 5.7400  \n",
      "\n",
      "Fold: 4  Epoch: 214  Training loss = 2.1559  Validation loss = 5.7399  \n",
      "\n",
      "Fold: 4  Epoch: 215  Training loss = 2.1558  Validation loss = 5.7398  \n",
      "\n",
      "Fold: 4  Epoch: 216  Training loss = 2.1557  Validation loss = 5.7396  \n",
      "\n",
      "Fold: 4  Epoch: 217  Training loss = 2.1556  Validation loss = 5.7395  \n",
      "\n",
      "Fold: 4  Epoch: 218  Training loss = 2.1555  Validation loss = 5.7394  \n",
      "\n",
      "Fold: 4  Epoch: 219  Training loss = 2.1554  Validation loss = 5.7392  \n",
      "\n",
      "Fold: 4  Epoch: 220  Training loss = 2.1553  Validation loss = 5.7391  \n",
      "\n",
      "Fold: 4  Epoch: 221  Training loss = 2.1552  Validation loss = 5.7389  \n",
      "\n",
      "Fold: 4  Epoch: 222  Training loss = 2.1551  Validation loss = 5.7388  \n",
      "\n",
      "Fold: 4  Epoch: 223  Training loss = 2.1549  Validation loss = 5.7386  \n",
      "\n",
      "Fold: 4  Epoch: 224  Training loss = 2.1548  Validation loss = 5.7384  \n",
      "\n",
      "Fold: 4  Epoch: 225  Training loss = 2.1547  Validation loss = 5.7383  \n",
      "\n",
      "Fold: 4  Epoch: 226  Training loss = 2.1546  Validation loss = 5.7382  \n",
      "\n",
      "Fold: 4  Epoch: 227  Training loss = 2.1545  Validation loss = 5.7380  \n",
      "\n",
      "Fold: 4  Epoch: 228  Training loss = 2.1544  Validation loss = 5.7379  \n",
      "\n",
      "Fold: 4  Epoch: 229  Training loss = 2.1544  Validation loss = 5.7378  \n",
      "\n",
      "Fold: 4  Epoch: 230  Training loss = 2.1543  Validation loss = 5.7376  \n",
      "\n",
      "Fold: 4  Epoch: 231  Training loss = 2.1542  Validation loss = 5.7375  \n",
      "\n",
      "Fold: 4  Epoch: 232  Training loss = 2.1541  Validation loss = 5.7374  \n",
      "\n",
      "Fold: 4  Epoch: 233  Training loss = 2.1540  Validation loss = 5.7373  \n",
      "\n",
      "Fold: 4  Epoch: 234  Training loss = 2.1539  Validation loss = 5.7372  \n",
      "\n",
      "Fold: 4  Epoch: 235  Training loss = 2.1538  Validation loss = 5.7370  \n",
      "\n",
      "Fold: 4  Epoch: 236  Training loss = 2.1537  Validation loss = 5.7369  \n",
      "\n",
      "Fold: 4  Epoch: 237  Training loss = 2.1536  Validation loss = 5.7367  \n",
      "\n",
      "Fold: 4  Epoch: 238  Training loss = 2.1535  Validation loss = 5.7366  \n",
      "\n",
      "Fold: 4  Epoch: 239  Training loss = 2.1534  Validation loss = 5.7364  \n",
      "\n",
      "Fold: 4  Epoch: 240  Training loss = 2.1533  Validation loss = 5.7363  \n",
      "\n",
      "Fold: 4  Epoch: 241  Training loss = 2.1532  Validation loss = 5.7361  \n",
      "\n",
      "Fold: 4  Epoch: 242  Training loss = 2.1531  Validation loss = 5.7360  \n",
      "\n",
      "Fold: 4  Epoch: 243  Training loss = 2.1530  Validation loss = 5.7358  \n",
      "\n",
      "Fold: 4  Epoch: 244  Training loss = 2.1529  Validation loss = 5.7356  \n",
      "\n",
      "Fold: 4  Epoch: 245  Training loss = 2.1528  Validation loss = 5.7355  \n",
      "\n",
      "Fold: 4  Epoch: 246  Training loss = 2.1527  Validation loss = 5.7354  \n",
      "\n",
      "Fold: 4  Epoch: 247  Training loss = 2.1526  Validation loss = 5.7352  \n",
      "\n",
      "Fold: 4  Epoch: 248  Training loss = 2.1525  Validation loss = 5.7351  \n",
      "\n",
      "Fold: 4  Epoch: 249  Training loss = 2.1524  Validation loss = 5.7349  \n",
      "\n",
      "Fold: 4  Epoch: 250  Training loss = 2.1523  Validation loss = 5.7348  \n",
      "\n",
      "Fold: 4  Epoch: 251  Training loss = 2.1522  Validation loss = 5.7347  \n",
      "\n",
      "Fold: 4  Epoch: 252  Training loss = 2.1521  Validation loss = 5.7345  \n",
      "\n",
      "Fold: 4  Epoch: 253  Training loss = 2.1520  Validation loss = 5.7344  \n",
      "\n",
      "Fold: 4  Epoch: 254  Training loss = 2.1519  Validation loss = 5.7343  \n",
      "\n",
      "Fold: 4  Epoch: 255  Training loss = 2.1518  Validation loss = 5.7341  \n",
      "\n",
      "Fold: 4  Epoch: 256  Training loss = 2.1517  Validation loss = 5.7340  \n",
      "\n",
      "Fold: 4  Epoch: 257  Training loss = 2.1516  Validation loss = 5.7339  \n",
      "\n",
      "Fold: 4  Epoch: 258  Training loss = 2.1515  Validation loss = 5.7337  \n",
      "\n",
      "Fold: 4  Epoch: 259  Training loss = 2.1514  Validation loss = 5.7336  \n",
      "\n",
      "Fold: 4  Epoch: 260  Training loss = 2.1513  Validation loss = 5.7334  \n",
      "\n",
      "Fold: 4  Epoch: 261  Training loss = 2.1512  Validation loss = 5.7333  \n",
      "\n",
      "Fold: 4  Epoch: 262  Training loss = 2.1511  Validation loss = 5.7331  \n",
      "\n",
      "Fold: 4  Epoch: 263  Training loss = 2.1510  Validation loss = 5.7330  \n",
      "\n",
      "Fold: 4  Epoch: 264  Training loss = 2.1509  Validation loss = 5.7328  \n",
      "\n",
      "Fold: 4  Epoch: 265  Training loss = 2.1508  Validation loss = 5.7327  \n",
      "\n",
      "Fold: 4  Epoch: 266  Training loss = 2.1507  Validation loss = 5.7326  \n",
      "\n",
      "Fold: 4  Epoch: 267  Training loss = 2.1506  Validation loss = 5.7325  \n",
      "\n",
      "Fold: 4  Epoch: 268  Training loss = 2.1506  Validation loss = 5.7324  \n",
      "\n",
      "Fold: 4  Epoch: 269  Training loss = 2.1505  Validation loss = 5.7322  \n",
      "\n",
      "Fold: 4  Epoch: 270  Training loss = 2.1504  Validation loss = 5.7321  \n",
      "\n",
      "Fold: 4  Epoch: 271  Training loss = 2.1503  Validation loss = 5.7320  \n",
      "\n",
      "Fold: 4  Epoch: 272  Training loss = 2.1502  Validation loss = 5.7319  \n",
      "\n",
      "Fold: 4  Epoch: 273  Training loss = 2.1501  Validation loss = 5.7318  \n",
      "\n",
      "Fold: 4  Epoch: 274  Training loss = 2.1500  Validation loss = 5.7316  \n",
      "\n",
      "Fold: 4  Epoch: 275  Training loss = 2.1499  Validation loss = 5.7314  \n",
      "\n",
      "Fold: 4  Epoch: 276  Training loss = 2.1498  Validation loss = 5.7312  \n",
      "\n",
      "Fold: 4  Epoch: 277  Training loss = 2.1497  Validation loss = 5.7311  \n",
      "\n",
      "Fold: 4  Epoch: 278  Training loss = 2.1496  Validation loss = 5.7310  \n",
      "\n",
      "Fold: 4  Epoch: 279  Training loss = 2.1495  Validation loss = 5.7308  \n",
      "\n",
      "Fold: 4  Epoch: 280  Training loss = 2.1494  Validation loss = 5.7307  \n",
      "\n",
      "Fold: 4  Epoch: 281  Training loss = 2.1493  Validation loss = 5.7306  \n",
      "\n",
      "Fold: 4  Epoch: 282  Training loss = 2.1492  Validation loss = 5.7304  \n",
      "\n",
      "Fold: 4  Epoch: 283  Training loss = 2.1491  Validation loss = 5.7303  \n",
      "\n",
      "Fold: 4  Epoch: 284  Training loss = 2.1490  Validation loss = 5.7301  \n",
      "\n",
      "Fold: 4  Epoch: 285  Training loss = 2.1489  Validation loss = 5.7300  \n",
      "\n",
      "Fold: 4  Epoch: 286  Training loss = 2.1488  Validation loss = 5.7298  \n",
      "\n",
      "Fold: 4  Epoch: 287  Training loss = 2.1487  Validation loss = 5.7297  \n",
      "\n",
      "Fold: 4  Epoch: 288  Training loss = 2.1486  Validation loss = 5.7295  \n",
      "\n",
      "Fold: 4  Epoch: 289  Training loss = 2.1485  Validation loss = 5.7294  \n",
      "\n",
      "Fold: 4  Epoch: 290  Training loss = 2.1484  Validation loss = 5.7292  \n",
      "\n",
      "Fold: 4  Epoch: 291  Training loss = 2.1482  Validation loss = 5.7291  \n",
      "\n",
      "Fold: 4  Epoch: 292  Training loss = 2.1481  Validation loss = 5.7289  \n",
      "\n",
      "Fold: 4  Epoch: 293  Training loss = 2.1481  Validation loss = 5.7288  \n",
      "\n",
      "Fold: 4  Epoch: 294  Training loss = 2.1479  Validation loss = 5.7286  \n",
      "\n",
      "Fold: 4  Epoch: 295  Training loss = 2.1479  Validation loss = 5.7285  \n",
      "\n",
      "Fold: 4  Epoch: 296  Training loss = 2.1477  Validation loss = 5.7283  \n",
      "\n",
      "Fold: 4  Epoch: 297  Training loss = 2.1476  Validation loss = 5.7282  \n",
      "\n",
      "Fold: 4  Epoch: 298  Training loss = 2.1475  Validation loss = 5.7280  \n",
      "\n",
      "Fold: 4  Epoch: 299  Training loss = 2.1474  Validation loss = 5.7279  \n",
      "\n",
      "Fold: 4  Epoch: 300  Training loss = 2.1474  Validation loss = 5.7278  \n",
      "\n",
      "Fold: 4  Epoch: 301  Training loss = 2.1473  Validation loss = 5.7276  \n",
      "\n",
      "Fold: 4  Epoch: 302  Training loss = 2.1472  Validation loss = 5.7275  \n",
      "\n",
      "Fold: 4  Epoch: 303  Training loss = 2.1471  Validation loss = 5.7273  \n",
      "\n",
      "Fold: 4  Epoch: 304  Training loss = 2.1470  Validation loss = 5.7272  \n",
      "\n",
      "Fold: 4  Epoch: 305  Training loss = 2.1469  Validation loss = 5.7271  \n",
      "\n",
      "Fold: 4  Epoch: 306  Training loss = 2.1468  Validation loss = 5.7269  \n",
      "\n",
      "Fold: 4  Epoch: 307  Training loss = 2.1467  Validation loss = 5.7268  \n",
      "\n",
      "Fold: 4  Epoch: 308  Training loss = 2.1466  Validation loss = 5.7267  \n",
      "\n",
      "Fold: 4  Epoch: 309  Training loss = 2.1465  Validation loss = 5.7265  \n",
      "\n",
      "Fold: 4  Epoch: 310  Training loss = 2.1464  Validation loss = 5.7264  \n",
      "\n",
      "Fold: 4  Epoch: 311  Training loss = 2.1462  Validation loss = 5.7262  \n",
      "\n",
      "Fold: 4  Epoch: 312  Training loss = 2.1462  Validation loss = 5.7261  \n",
      "\n",
      "Fold: 4  Epoch: 313  Training loss = 2.1461  Validation loss = 5.7260  \n",
      "\n",
      "Fold: 4  Epoch: 314  Training loss = 2.1460  Validation loss = 5.7258  \n",
      "\n",
      "Fold: 4  Epoch: 315  Training loss = 2.1459  Validation loss = 5.7257  \n",
      "\n",
      "Fold: 4  Epoch: 316  Training loss = 2.1457  Validation loss = 5.7255  \n",
      "\n",
      "Fold: 4  Epoch: 317  Training loss = 2.1456  Validation loss = 5.7253  \n",
      "\n",
      "Fold: 4  Epoch: 318  Training loss = 2.1455  Validation loss = 5.7251  \n",
      "\n",
      "Fold: 4  Epoch: 319  Training loss = 2.1454  Validation loss = 5.7250  \n",
      "\n",
      "Fold: 4  Epoch: 320  Training loss = 2.1453  Validation loss = 5.7249  \n",
      "\n",
      "Fold: 4  Epoch: 321  Training loss = 2.1452  Validation loss = 5.7247  \n",
      "\n",
      "Fold: 4  Epoch: 322  Training loss = 2.1451  Validation loss = 5.7246  \n",
      "\n",
      "Fold: 4  Epoch: 323  Training loss = 2.1451  Validation loss = 5.7245  \n",
      "\n",
      "Fold: 4  Epoch: 324  Training loss = 2.1449  Validation loss = 5.7243  \n",
      "\n",
      "Fold: 4  Epoch: 325  Training loss = 2.1449  Validation loss = 5.7242  \n",
      "\n",
      "Fold: 4  Epoch: 326  Training loss = 2.1448  Validation loss = 5.7240  \n",
      "\n",
      "Fold: 4  Epoch: 327  Training loss = 2.1447  Validation loss = 5.7239  \n",
      "\n",
      "Fold: 4  Epoch: 328  Training loss = 2.1445  Validation loss = 5.7237  \n",
      "\n",
      "Fold: 4  Epoch: 329  Training loss = 2.1444  Validation loss = 5.7236  \n",
      "\n",
      "Fold: 4  Epoch: 330  Training loss = 2.1443  Validation loss = 5.7235  \n",
      "\n",
      "Fold: 4  Epoch: 331  Training loss = 2.1443  Validation loss = 5.7233  \n",
      "\n",
      "Fold: 4  Epoch: 332  Training loss = 2.1442  Validation loss = 5.7232  \n",
      "\n",
      "Fold: 4  Epoch: 333  Training loss = 2.1441  Validation loss = 5.7231  \n",
      "\n",
      "Fold: 4  Epoch: 334  Training loss = 2.1439  Validation loss = 5.7229  \n",
      "\n",
      "Fold: 4  Epoch: 335  Training loss = 2.1439  Validation loss = 5.7227  \n",
      "\n",
      "Fold: 4  Epoch: 336  Training loss = 2.1438  Validation loss = 5.7226  \n",
      "\n",
      "Fold: 4  Epoch: 337  Training loss = 2.1437  Validation loss = 5.7225  \n",
      "\n",
      "Fold: 4  Epoch: 338  Training loss = 2.1436  Validation loss = 5.7223  \n",
      "\n",
      "Fold: 4  Epoch: 339  Training loss = 2.1435  Validation loss = 5.7222  \n",
      "\n",
      "Fold: 4  Epoch: 340  Training loss = 2.1434  Validation loss = 5.7220  \n",
      "\n",
      "Fold: 4  Epoch: 341  Training loss = 2.1433  Validation loss = 5.7219  \n",
      "\n",
      "Fold: 4  Epoch: 342  Training loss = 2.1432  Validation loss = 5.7217  \n",
      "\n",
      "Fold: 4  Epoch: 343  Training loss = 2.1430  Validation loss = 5.7215  \n",
      "\n",
      "Fold: 4  Epoch: 344  Training loss = 2.1430  Validation loss = 5.7214  \n",
      "\n",
      "Fold: 4  Epoch: 345  Training loss = 2.1429  Validation loss = 5.7213  \n",
      "\n",
      "Fold: 4  Epoch: 346  Training loss = 2.1428  Validation loss = 5.7212  \n",
      "\n",
      "Fold: 4  Epoch: 347  Training loss = 2.1427  Validation loss = 5.7210  \n",
      "\n",
      "Fold: 4  Epoch: 348  Training loss = 2.1426  Validation loss = 5.7208  \n",
      "\n",
      "Fold: 4  Epoch: 349  Training loss = 2.1425  Validation loss = 5.7207  \n",
      "\n",
      "Fold: 4  Epoch: 350  Training loss = 2.1424  Validation loss = 5.7205  \n",
      "\n",
      "Fold: 4  Epoch: 351  Training loss = 2.1423  Validation loss = 5.7204  \n",
      "\n",
      "Fold: 4  Epoch: 352  Training loss = 2.1422  Validation loss = 5.7203  \n",
      "\n",
      "Fold: 4  Epoch: 353  Training loss = 2.1421  Validation loss = 5.7202  \n",
      "\n",
      "Fold: 4  Epoch: 354  Training loss = 2.1420  Validation loss = 5.7200  \n",
      "\n",
      "Fold: 4  Epoch: 355  Training loss = 2.1419  Validation loss = 5.7199  \n",
      "\n",
      "Fold: 4  Epoch: 356  Training loss = 2.1418  Validation loss = 5.7198  \n",
      "\n",
      "Fold: 4  Epoch: 357  Training loss = 2.1417  Validation loss = 5.7196  \n",
      "\n",
      "Fold: 4  Epoch: 358  Training loss = 2.1416  Validation loss = 5.7195  \n",
      "\n",
      "Fold: 4  Epoch: 359  Training loss = 2.1415  Validation loss = 5.7193  \n",
      "\n",
      "Fold: 4  Epoch: 360  Training loss = 2.1413  Validation loss = 5.7191  \n",
      "\n",
      "Fold: 4  Epoch: 361  Training loss = 2.1413  Validation loss = 5.7190  \n",
      "\n",
      "Fold: 4  Epoch: 362  Training loss = 2.1412  Validation loss = 5.7189  \n",
      "\n",
      "Fold: 4  Epoch: 363  Training loss = 2.1411  Validation loss = 5.7188  \n",
      "\n",
      "Fold: 4  Epoch: 364  Training loss = 2.1409  Validation loss = 5.7186  \n",
      "\n",
      "Fold: 4  Epoch: 365  Training loss = 2.1408  Validation loss = 5.7184  \n",
      "\n",
      "Fold: 4  Epoch: 366  Training loss = 2.1407  Validation loss = 5.7183  \n",
      "\n",
      "Fold: 4  Epoch: 367  Training loss = 2.1406  Validation loss = 5.7181  \n",
      "\n",
      "Fold: 4  Epoch: 368  Training loss = 2.1405  Validation loss = 5.7180  \n",
      "\n",
      "Fold: 4  Epoch: 369  Training loss = 2.1404  Validation loss = 5.7178  \n",
      "\n",
      "Fold: 4  Epoch: 370  Training loss = 2.1403  Validation loss = 5.7177  \n",
      "\n",
      "Fold: 4  Epoch: 371  Training loss = 2.1402  Validation loss = 5.7175  \n",
      "\n",
      "Fold: 4  Epoch: 372  Training loss = 2.1401  Validation loss = 5.7174  \n",
      "\n",
      "Fold: 4  Epoch: 373  Training loss = 2.1400  Validation loss = 5.7173  \n",
      "\n",
      "Fold: 4  Epoch: 374  Training loss = 2.1399  Validation loss = 5.7171  \n",
      "\n",
      "Fold: 4  Epoch: 375  Training loss = 2.1398  Validation loss = 5.7170  \n",
      "\n",
      "Fold: 4  Epoch: 376  Training loss = 2.1398  Validation loss = 5.7169  \n",
      "\n",
      "Fold: 4  Epoch: 377  Training loss = 2.1396  Validation loss = 5.7167  \n",
      "\n",
      "Fold: 4  Epoch: 378  Training loss = 2.1396  Validation loss = 5.7166  \n",
      "\n",
      "Fold: 4  Epoch: 379  Training loss = 2.1395  Validation loss = 5.7164  \n",
      "\n",
      "Fold: 4  Epoch: 380  Training loss = 2.1394  Validation loss = 5.7163  \n",
      "\n",
      "Fold: 4  Epoch: 381  Training loss = 2.1392  Validation loss = 5.7161  \n",
      "\n",
      "Fold: 4  Epoch: 382  Training loss = 2.1391  Validation loss = 5.7160  \n",
      "\n",
      "Fold: 4  Epoch: 383  Training loss = 2.1391  Validation loss = 5.7159  \n",
      "\n",
      "Fold: 4  Epoch: 384  Training loss = 2.1390  Validation loss = 5.7157  \n",
      "\n",
      "Fold: 4  Epoch: 385  Training loss = 2.1389  Validation loss = 5.7156  \n",
      "\n",
      "Fold: 4  Epoch: 386  Training loss = 2.1388  Validation loss = 5.7154  \n",
      "\n",
      "Fold: 4  Epoch: 387  Training loss = 2.1387  Validation loss = 5.7153  \n",
      "\n",
      "Fold: 4  Epoch: 388  Training loss = 2.1386  Validation loss = 5.7151  \n",
      "\n",
      "Fold: 4  Epoch: 389  Training loss = 2.1385  Validation loss = 5.7150  \n",
      "\n",
      "Fold: 4  Epoch: 390  Training loss = 2.1384  Validation loss = 5.7148  \n",
      "\n",
      "Fold: 4  Epoch: 391  Training loss = 2.1383  Validation loss = 5.7147  \n",
      "\n",
      "Fold: 4  Epoch: 392  Training loss = 2.1382  Validation loss = 5.7145  \n",
      "\n",
      "Fold: 4  Epoch: 393  Training loss = 2.1381  Validation loss = 5.7144  \n",
      "\n",
      "Fold: 4  Epoch: 394  Training loss = 2.1379  Validation loss = 5.7142  \n",
      "\n",
      "Fold: 4  Epoch: 395  Training loss = 2.1379  Validation loss = 5.7141  \n",
      "\n",
      "Fold: 4  Epoch: 396  Training loss = 2.1377  Validation loss = 5.7139  \n",
      "\n",
      "Fold: 4  Epoch: 397  Training loss = 2.1377  Validation loss = 5.7138  \n",
      "\n",
      "Fold: 4  Epoch: 398  Training loss = 2.1375  Validation loss = 5.7136  \n",
      "\n",
      "Fold: 4  Epoch: 399  Training loss = 2.1375  Validation loss = 5.7135  \n",
      "\n",
      "Fold: 4  Epoch: 400  Training loss = 2.1374  Validation loss = 5.7134  \n",
      "\n",
      "Fold: 4  Epoch: 401  Training loss = 2.1373  Validation loss = 5.7133  \n",
      "\n",
      "Fold: 4  Epoch: 402  Training loss = 2.1372  Validation loss = 5.7132  \n",
      "\n",
      "Fold: 4  Epoch: 403  Training loss = 2.1371  Validation loss = 5.7130  \n",
      "\n",
      "Fold: 4  Epoch: 404  Training loss = 2.1370  Validation loss = 5.7129  \n",
      "\n",
      "Fold: 4  Epoch: 405  Training loss = 2.1369  Validation loss = 5.7127  \n",
      "\n",
      "Fold: 4  Epoch: 406  Training loss = 2.1368  Validation loss = 5.7125  \n",
      "\n",
      "Fold: 4  Epoch: 407  Training loss = 2.1367  Validation loss = 5.7124  \n",
      "\n",
      "Fold: 4  Epoch: 408  Training loss = 2.1366  Validation loss = 5.7123  \n",
      "\n",
      "Fold: 4  Epoch: 409  Training loss = 2.1365  Validation loss = 5.7121  \n",
      "\n",
      "Fold: 4  Epoch: 410  Training loss = 2.1363  Validation loss = 5.7119  \n",
      "\n",
      "Fold: 4  Epoch: 411  Training loss = 2.1362  Validation loss = 5.7118  \n",
      "\n",
      "Fold: 4  Epoch: 412  Training loss = 2.1361  Validation loss = 5.7116  \n",
      "\n",
      "Fold: 4  Epoch: 413  Training loss = 2.1360  Validation loss = 5.7114  \n",
      "\n",
      "Fold: 4  Epoch: 414  Training loss = 2.1359  Validation loss = 5.7113  \n",
      "\n",
      "Fold: 4  Epoch: 415  Training loss = 2.1358  Validation loss = 5.7111  \n",
      "\n",
      "Fold: 4  Epoch: 416  Training loss = 2.1357  Validation loss = 5.7109  \n",
      "\n",
      "Fold: 4  Epoch: 417  Training loss = 2.1356  Validation loss = 5.7108  \n",
      "\n",
      "Fold: 4  Epoch: 418  Training loss = 2.1355  Validation loss = 5.7107  \n",
      "\n",
      "Fold: 4  Epoch: 419  Training loss = 2.1355  Validation loss = 5.7106  \n",
      "\n",
      "Fold: 4  Epoch: 420  Training loss = 2.1354  Validation loss = 5.7105  \n",
      "\n",
      "Fold: 4  Epoch: 421  Training loss = 2.1353  Validation loss = 5.7103  \n",
      "\n",
      "Fold: 4  Epoch: 422  Training loss = 2.1352  Validation loss = 5.7102  \n",
      "\n",
      "Fold: 4  Epoch: 423  Training loss = 2.1351  Validation loss = 5.7101  \n",
      "\n",
      "Fold: 4  Epoch: 424  Training loss = 2.1350  Validation loss = 5.7099  \n",
      "\n",
      "Fold: 4  Epoch: 425  Training loss = 2.1349  Validation loss = 5.7098  \n",
      "\n",
      "Fold: 4  Epoch: 426  Training loss = 2.1348  Validation loss = 5.7096  \n",
      "\n",
      "Fold: 4  Epoch: 427  Training loss = 2.1347  Validation loss = 5.7094  \n",
      "\n",
      "Fold: 4  Epoch: 428  Training loss = 2.1346  Validation loss = 5.7093  \n",
      "\n",
      "Fold: 4  Epoch: 429  Training loss = 2.1345  Validation loss = 5.7091  \n",
      "\n",
      "Fold: 4  Epoch: 430  Training loss = 2.1344  Validation loss = 5.7090  \n",
      "\n",
      "Fold: 4  Epoch: 431  Training loss = 2.1343  Validation loss = 5.7089  \n",
      "\n",
      "Fold: 4  Epoch: 432  Training loss = 2.1342  Validation loss = 5.7087  \n",
      "\n",
      "Fold: 4  Epoch: 433  Training loss = 2.1341  Validation loss = 5.7085  \n",
      "\n",
      "Fold: 4  Epoch: 434  Training loss = 2.1340  Validation loss = 5.7084  \n",
      "\n",
      "Fold: 4  Epoch: 435  Training loss = 2.1339  Validation loss = 5.7083  \n",
      "\n",
      "Fold: 4  Epoch: 436  Training loss = 2.1338  Validation loss = 5.7081  \n",
      "\n",
      "Fold: 4  Epoch: 437  Training loss = 2.1337  Validation loss = 5.7080  \n",
      "\n",
      "Fold: 4  Epoch: 438  Training loss = 2.1336  Validation loss = 5.7079  \n",
      "\n",
      "Fold: 4  Epoch: 439  Training loss = 2.1335  Validation loss = 5.7076  \n",
      "\n",
      "Fold: 4  Epoch: 440  Training loss = 2.1334  Validation loss = 5.7075  \n",
      "\n",
      "Fold: 4  Epoch: 441  Training loss = 2.1333  Validation loss = 5.7074  \n",
      "\n",
      "Fold: 4  Epoch: 442  Training loss = 2.1332  Validation loss = 5.7072  \n",
      "\n",
      "Fold: 4  Epoch: 443  Training loss = 2.1331  Validation loss = 5.7071  \n",
      "\n",
      "Fold: 4  Epoch: 444  Training loss = 2.1330  Validation loss = 5.7069  \n",
      "\n",
      "Fold: 4  Epoch: 445  Training loss = 2.1329  Validation loss = 5.7068  \n",
      "\n",
      "Fold: 4  Epoch: 446  Training loss = 2.1328  Validation loss = 5.7066  \n",
      "\n",
      "Fold: 4  Epoch: 447  Training loss = 2.1327  Validation loss = 5.7064  \n",
      "\n",
      "Fold: 4  Epoch: 448  Training loss = 2.1326  Validation loss = 5.7063  \n",
      "\n",
      "Fold: 4  Epoch: 449  Training loss = 2.1325  Validation loss = 5.7062  \n",
      "\n",
      "Fold: 4  Epoch: 450  Training loss = 2.1324  Validation loss = 5.7060  \n",
      "\n",
      "Fold: 4  Epoch: 451  Training loss = 2.1323  Validation loss = 5.7058  \n",
      "\n",
      "Fold: 4  Epoch: 452  Training loss = 2.1322  Validation loss = 5.7057  \n",
      "\n",
      "Fold: 4  Epoch: 453  Training loss = 2.1321  Validation loss = 5.7055  \n",
      "\n",
      "Fold: 4  Epoch: 454  Training loss = 2.1320  Validation loss = 5.7054  \n",
      "\n",
      "Fold: 4  Epoch: 455  Training loss = 2.1319  Validation loss = 5.7053  \n",
      "\n",
      "Fold: 4  Epoch: 456  Training loss = 2.1318  Validation loss = 5.7052  \n",
      "\n",
      "Fold: 4  Epoch: 457  Training loss = 2.1317  Validation loss = 5.7050  \n",
      "\n",
      "Fold: 4  Epoch: 458  Training loss = 2.1316  Validation loss = 5.7049  \n",
      "\n",
      "Fold: 4  Epoch: 459  Training loss = 2.1315  Validation loss = 5.7047  \n",
      "\n",
      "Fold: 4  Epoch: 460  Training loss = 2.1314  Validation loss = 5.7046  \n",
      "\n",
      "Fold: 4  Epoch: 461  Training loss = 2.1313  Validation loss = 5.7044  \n",
      "\n",
      "Fold: 4  Epoch: 462  Training loss = 2.1312  Validation loss = 5.7043  \n",
      "\n",
      "Fold: 4  Epoch: 463  Training loss = 2.1312  Validation loss = 5.7042  \n",
      "\n",
      "Fold: 4  Epoch: 464  Training loss = 2.1311  Validation loss = 5.7040  \n",
      "\n",
      "Fold: 4  Epoch: 465  Training loss = 2.1310  Validation loss = 5.7039  \n",
      "\n",
      "Fold: 4  Epoch: 466  Training loss = 2.1309  Validation loss = 5.7037  \n",
      "\n",
      "Fold: 4  Epoch: 467  Training loss = 2.1308  Validation loss = 5.7036  \n",
      "\n",
      "Fold: 4  Epoch: 468  Training loss = 2.1307  Validation loss = 5.7034  \n",
      "\n",
      "Fold: 4  Epoch: 469  Training loss = 2.1306  Validation loss = 5.7033  \n",
      "\n",
      "Fold: 4  Epoch: 470  Training loss = 2.1305  Validation loss = 5.7032  \n",
      "\n",
      "Fold: 4  Epoch: 471  Training loss = 2.1304  Validation loss = 5.7031  \n",
      "\n",
      "Fold: 4  Epoch: 472  Training loss = 2.1303  Validation loss = 5.7029  \n",
      "\n",
      "Fold: 4  Epoch: 473  Training loss = 2.1302  Validation loss = 5.7027  \n",
      "\n",
      "Fold: 4  Epoch: 474  Training loss = 2.1301  Validation loss = 5.7026  \n",
      "\n",
      "Fold: 4  Epoch: 475  Training loss = 2.1300  Validation loss = 5.7025  \n",
      "\n",
      "Fold: 4  Epoch: 476  Training loss = 2.1300  Validation loss = 5.7024  \n",
      "\n",
      "Fold: 4  Epoch: 477  Training loss = 2.1298  Validation loss = 5.7022  \n",
      "\n",
      "Fold: 4  Epoch: 478  Training loss = 2.1297  Validation loss = 5.7021  \n",
      "\n",
      "Fold: 4  Epoch: 479  Training loss = 2.1296  Validation loss = 5.7019  \n",
      "\n",
      "Fold: 4  Epoch: 480  Training loss = 2.1295  Validation loss = 5.7018  \n",
      "\n",
      "Fold: 4  Epoch: 481  Training loss = 2.1294  Validation loss = 5.7016  \n",
      "\n",
      "Fold: 4  Epoch: 482  Training loss = 2.1293  Validation loss = 5.7015  \n",
      "\n",
      "Fold: 4  Epoch: 483  Training loss = 2.1292  Validation loss = 5.7014  \n",
      "\n",
      "Fold: 4  Epoch: 484  Training loss = 2.1291  Validation loss = 5.7012  \n",
      "\n",
      "Fold: 4  Epoch: 485  Training loss = 2.1290  Validation loss = 5.7011  \n",
      "\n",
      "Fold: 4  Epoch: 486  Training loss = 2.1289  Validation loss = 5.7009  \n",
      "\n",
      "Fold: 4  Epoch: 487  Training loss = 2.1288  Validation loss = 5.7008  \n",
      "\n",
      "Fold: 4  Epoch: 488  Training loss = 2.1287  Validation loss = 5.7007  \n",
      "\n",
      "Fold: 4  Epoch: 489  Training loss = 2.1286  Validation loss = 5.7005  \n",
      "\n",
      "Fold: 4  Epoch: 490  Training loss = 2.1285  Validation loss = 5.7004  \n",
      "\n",
      "Fold: 4  Epoch: 491  Training loss = 2.1284  Validation loss = 5.7002  \n",
      "\n",
      "Fold: 4  Epoch: 492  Training loss = 2.1283  Validation loss = 5.7001  \n",
      "\n",
      "Fold: 4  Epoch: 493  Training loss = 2.1283  Validation loss = 5.7000  \n",
      "\n",
      "Fold: 4  Epoch: 494  Training loss = 2.1282  Validation loss = 5.6998  \n",
      "\n",
      "Fold: 4  Epoch: 495  Training loss = 2.1281  Validation loss = 5.6997  \n",
      "\n",
      "Fold: 4  Epoch: 496  Training loss = 2.1280  Validation loss = 5.6995  \n",
      "\n",
      "Fold: 4  Epoch: 497  Training loss = 2.1278  Validation loss = 5.6993  \n",
      "\n",
      "Fold: 4  Epoch: 498  Training loss = 2.1277  Validation loss = 5.6992  \n",
      "\n",
      "Fold: 4  Epoch: 499  Training loss = 2.1276  Validation loss = 5.6991  \n",
      "\n",
      "Fold: 4  Epoch: 500  Training loss = 2.1275  Validation loss = 5.6989  \n",
      "\n",
      "Check model:  Fold: 4  Optimal epoch: 500  \n",
      "\n",
      "Fold: 5  Epoch: 1  Training loss = 2.5266  Validation loss = 5.5267  \n",
      "\n",
      "Fold: 5  Epoch: 2  Training loss = 2.5265  Validation loss = 5.5265  \n",
      "\n",
      "Fold: 5  Epoch: 3  Training loss = 2.5263  Validation loss = 5.5263  \n",
      "\n",
      "Fold: 5  Epoch: 4  Training loss = 2.5262  Validation loss = 5.5261  \n",
      "\n",
      "Fold: 5  Epoch: 5  Training loss = 2.5261  Validation loss = 5.5259  \n",
      "\n",
      "Fold: 5  Epoch: 6  Training loss = 2.5260  Validation loss = 5.5258  \n",
      "\n",
      "Fold: 5  Epoch: 7  Training loss = 2.5259  Validation loss = 5.5256  \n",
      "\n",
      "Fold: 5  Epoch: 8  Training loss = 2.5257  Validation loss = 5.5254  \n",
      "\n",
      "Fold: 5  Epoch: 9  Training loss = 2.5256  Validation loss = 5.5252  \n",
      "\n",
      "Fold: 5  Epoch: 10  Training loss = 2.5255  Validation loss = 5.5250  \n",
      "\n",
      "Fold: 5  Epoch: 11  Training loss = 2.5253  Validation loss = 5.5248  \n",
      "\n",
      "Fold: 5  Epoch: 12  Training loss = 2.5252  Validation loss = 5.5246  \n",
      "\n",
      "Fold: 5  Epoch: 13  Training loss = 2.5251  Validation loss = 5.5245  \n",
      "\n",
      "Fold: 5  Epoch: 14  Training loss = 2.5250  Validation loss = 5.5243  \n",
      "\n",
      "Fold: 5  Epoch: 15  Training loss = 2.5249  Validation loss = 5.5242  \n",
      "\n",
      "Fold: 5  Epoch: 16  Training loss = 2.5248  Validation loss = 5.5240  \n",
      "\n",
      "Fold: 5  Epoch: 17  Training loss = 2.5246  Validation loss = 5.5239  \n",
      "\n",
      "Fold: 5  Epoch: 18  Training loss = 2.5245  Validation loss = 5.5237  \n",
      "\n",
      "Fold: 5  Epoch: 19  Training loss = 2.5244  Validation loss = 5.5235  \n",
      "\n",
      "Fold: 5  Epoch: 20  Training loss = 2.5243  Validation loss = 5.5234  \n",
      "\n",
      "Fold: 5  Epoch: 21  Training loss = 2.5242  Validation loss = 5.5232  \n",
      "\n",
      "Fold: 5  Epoch: 22  Training loss = 2.5240  Validation loss = 5.5230  \n",
      "\n",
      "Fold: 5  Epoch: 23  Training loss = 2.5239  Validation loss = 5.5229  \n",
      "\n",
      "Fold: 5  Epoch: 24  Training loss = 2.5238  Validation loss = 5.5227  \n",
      "\n",
      "Fold: 5  Epoch: 25  Training loss = 2.5237  Validation loss = 5.5225  \n",
      "\n",
      "Fold: 5  Epoch: 26  Training loss = 2.5235  Validation loss = 5.5224  \n",
      "\n",
      "Fold: 5  Epoch: 27  Training loss = 2.5234  Validation loss = 5.5222  \n",
      "\n",
      "Fold: 5  Epoch: 28  Training loss = 2.5233  Validation loss = 5.5220  \n",
      "\n",
      "Fold: 5  Epoch: 29  Training loss = 2.5231  Validation loss = 5.5218  \n",
      "\n",
      "Fold: 5  Epoch: 30  Training loss = 2.5230  Validation loss = 5.5215  \n",
      "\n",
      "Fold: 5  Epoch: 31  Training loss = 2.5229  Validation loss = 5.5214  \n",
      "\n",
      "Fold: 5  Epoch: 32  Training loss = 2.5227  Validation loss = 5.5212  \n",
      "\n",
      "Fold: 5  Epoch: 33  Training loss = 2.5226  Validation loss = 5.5210  \n",
      "\n",
      "Fold: 5  Epoch: 34  Training loss = 2.5225  Validation loss = 5.5208  \n",
      "\n",
      "Fold: 5  Epoch: 35  Training loss = 2.5223  Validation loss = 5.5205  \n",
      "\n",
      "Fold: 5  Epoch: 36  Training loss = 2.5222  Validation loss = 5.5203  \n",
      "\n",
      "Fold: 5  Epoch: 37  Training loss = 2.5220  Validation loss = 5.5201  \n",
      "\n",
      "Fold: 5  Epoch: 38  Training loss = 2.5219  Validation loss = 5.5200  \n",
      "\n",
      "Fold: 5  Epoch: 39  Training loss = 2.5218  Validation loss = 5.5198  \n",
      "\n",
      "Fold: 5  Epoch: 40  Training loss = 2.5217  Validation loss = 5.5196  \n",
      "\n",
      "Fold: 5  Epoch: 41  Training loss = 2.5215  Validation loss = 5.5194  \n",
      "\n",
      "Fold: 5  Epoch: 42  Training loss = 2.5214  Validation loss = 5.5192  \n",
      "\n",
      "Fold: 5  Epoch: 43  Training loss = 2.5213  Validation loss = 5.5190  \n",
      "\n",
      "Fold: 5  Epoch: 44  Training loss = 2.5211  Validation loss = 5.5189  \n",
      "\n",
      "Fold: 5  Epoch: 45  Training loss = 2.5210  Validation loss = 5.5187  \n",
      "\n",
      "Fold: 5  Epoch: 46  Training loss = 2.5209  Validation loss = 5.5185  \n",
      "\n",
      "Fold: 5  Epoch: 47  Training loss = 2.5208  Validation loss = 5.5183  \n",
      "\n",
      "Fold: 5  Epoch: 48  Training loss = 2.5206  Validation loss = 5.5181  \n",
      "\n",
      "Fold: 5  Epoch: 49  Training loss = 2.5205  Validation loss = 5.5179  \n",
      "\n",
      "Fold: 5  Epoch: 50  Training loss = 2.5204  Validation loss = 5.5177  \n",
      "\n",
      "Fold: 5  Epoch: 51  Training loss = 2.5202  Validation loss = 5.5175  \n",
      "\n",
      "Fold: 5  Epoch: 52  Training loss = 2.5200  Validation loss = 5.5172  \n",
      "\n",
      "Fold: 5  Epoch: 53  Training loss = 2.5199  Validation loss = 5.5170  \n",
      "\n",
      "Fold: 5  Epoch: 54  Training loss = 2.5198  Validation loss = 5.5169  \n",
      "\n",
      "Fold: 5  Epoch: 55  Training loss = 2.5197  Validation loss = 5.5167  \n",
      "\n",
      "Fold: 5  Epoch: 56  Training loss = 2.5196  Validation loss = 5.5165  \n",
      "\n",
      "Fold: 5  Epoch: 57  Training loss = 2.5195  Validation loss = 5.5164  \n",
      "\n",
      "Fold: 5  Epoch: 58  Training loss = 2.5194  Validation loss = 5.5163  \n",
      "\n",
      "Fold: 5  Epoch: 59  Training loss = 2.5193  Validation loss = 5.5161  \n",
      "\n",
      "Fold: 5  Epoch: 60  Training loss = 2.5191  Validation loss = 5.5160  \n",
      "\n",
      "Fold: 5  Epoch: 61  Training loss = 2.5190  Validation loss = 5.5158  \n",
      "\n",
      "Fold: 5  Epoch: 62  Training loss = 2.5189  Validation loss = 5.5156  \n",
      "\n",
      "Fold: 5  Epoch: 63  Training loss = 2.5188  Validation loss = 5.5154  \n",
      "\n",
      "Fold: 5  Epoch: 64  Training loss = 2.5186  Validation loss = 5.5152  \n",
      "\n",
      "Fold: 5  Epoch: 65  Training loss = 2.5186  Validation loss = 5.5151  \n",
      "\n",
      "Fold: 5  Epoch: 66  Training loss = 2.5184  Validation loss = 5.5150  \n",
      "\n",
      "Fold: 5  Epoch: 67  Training loss = 2.5183  Validation loss = 5.5148  \n",
      "\n",
      "Fold: 5  Epoch: 68  Training loss = 2.5182  Validation loss = 5.5146  \n",
      "\n",
      "Fold: 5  Epoch: 69  Training loss = 2.5181  Validation loss = 5.5144  \n",
      "\n",
      "Fold: 5  Epoch: 70  Training loss = 2.5180  Validation loss = 5.5143  \n",
      "\n",
      "Fold: 5  Epoch: 71  Training loss = 2.5179  Validation loss = 5.5141  \n",
      "\n",
      "Fold: 5  Epoch: 72  Training loss = 2.5178  Validation loss = 5.5140  \n",
      "\n",
      "Fold: 5  Epoch: 73  Training loss = 2.5177  Validation loss = 5.5138  \n",
      "\n",
      "Fold: 5  Epoch: 74  Training loss = 2.5175  Validation loss = 5.5137  \n",
      "\n",
      "Fold: 5  Epoch: 75  Training loss = 2.5174  Validation loss = 5.5135  \n",
      "\n",
      "Fold: 5  Epoch: 76  Training loss = 2.5173  Validation loss = 5.5133  \n",
      "\n",
      "Fold: 5  Epoch: 77  Training loss = 2.5172  Validation loss = 5.5131  \n",
      "\n",
      "Fold: 5  Epoch: 78  Training loss = 2.5170  Validation loss = 5.5129  \n",
      "\n",
      "Fold: 5  Epoch: 79  Training loss = 2.5169  Validation loss = 5.5127  \n",
      "\n",
      "Fold: 5  Epoch: 80  Training loss = 2.5168  Validation loss = 5.5125  \n",
      "\n",
      "Fold: 5  Epoch: 81  Training loss = 2.5166  Validation loss = 5.5123  \n",
      "\n",
      "Fold: 5  Epoch: 82  Training loss = 2.5165  Validation loss = 5.5122  \n",
      "\n",
      "Fold: 5  Epoch: 83  Training loss = 2.5164  Validation loss = 5.5120  \n",
      "\n",
      "Fold: 5  Epoch: 84  Training loss = 2.5162  Validation loss = 5.5118  \n",
      "\n",
      "Fold: 5  Epoch: 85  Training loss = 2.5161  Validation loss = 5.5115  \n",
      "\n",
      "Fold: 5  Epoch: 86  Training loss = 2.5159  Validation loss = 5.5113  \n",
      "\n",
      "Fold: 5  Epoch: 87  Training loss = 2.5158  Validation loss = 5.5112  \n",
      "\n",
      "Fold: 5  Epoch: 88  Training loss = 2.5157  Validation loss = 5.5111  \n",
      "\n",
      "Fold: 5  Epoch: 89  Training loss = 2.5157  Validation loss = 5.5110  \n",
      "\n",
      "Fold: 5  Epoch: 90  Training loss = 2.5155  Validation loss = 5.5108  \n",
      "\n",
      "Fold: 5  Epoch: 91  Training loss = 2.5154  Validation loss = 5.5107  \n",
      "\n",
      "Fold: 5  Epoch: 92  Training loss = 2.5153  Validation loss = 5.5105  \n",
      "\n",
      "Fold: 5  Epoch: 93  Training loss = 2.5152  Validation loss = 5.5103  \n",
      "\n",
      "Fold: 5  Epoch: 94  Training loss = 2.5151  Validation loss = 5.5101  \n",
      "\n",
      "Fold: 5  Epoch: 95  Training loss = 2.5149  Validation loss = 5.5100  \n",
      "\n",
      "Fold: 5  Epoch: 96  Training loss = 2.5148  Validation loss = 5.5098  \n",
      "\n",
      "Fold: 5  Epoch: 97  Training loss = 2.5147  Validation loss = 5.5096  \n",
      "\n",
      "Fold: 5  Epoch: 98  Training loss = 2.5146  Validation loss = 5.5094  \n",
      "\n",
      "Fold: 5  Epoch: 99  Training loss = 2.5144  Validation loss = 5.5092  \n",
      "\n",
      "Fold: 5  Epoch: 100  Training loss = 2.5143  Validation loss = 5.5091  \n",
      "\n",
      "Fold: 5  Epoch: 101  Training loss = 2.5142  Validation loss = 5.5089  \n",
      "\n",
      "Fold: 5  Epoch: 102  Training loss = 2.5140  Validation loss = 5.5087  \n",
      "\n",
      "Fold: 5  Epoch: 103  Training loss = 2.5139  Validation loss = 5.5085  \n",
      "\n",
      "Fold: 5  Epoch: 104  Training loss = 2.5138  Validation loss = 5.5083  \n",
      "\n",
      "Fold: 5  Epoch: 105  Training loss = 2.5136  Validation loss = 5.5080  \n",
      "\n",
      "Fold: 5  Epoch: 106  Training loss = 2.5135  Validation loss = 5.5078  \n",
      "\n",
      "Fold: 5  Epoch: 107  Training loss = 2.5134  Validation loss = 5.5077  \n",
      "\n",
      "Fold: 5  Epoch: 108  Training loss = 2.5133  Validation loss = 5.5075  \n",
      "\n",
      "Fold: 5  Epoch: 109  Training loss = 2.5132  Validation loss = 5.5074  \n",
      "\n",
      "Fold: 5  Epoch: 110  Training loss = 2.5130  Validation loss = 5.5072  \n",
      "\n",
      "Fold: 5  Epoch: 111  Training loss = 2.5129  Validation loss = 5.5071  \n",
      "\n",
      "Fold: 5  Epoch: 112  Training loss = 2.5128  Validation loss = 5.5069  \n",
      "\n",
      "Fold: 5  Epoch: 113  Training loss = 2.5127  Validation loss = 5.5067  \n",
      "\n",
      "Fold: 5  Epoch: 114  Training loss = 2.5126  Validation loss = 5.5066  \n",
      "\n",
      "Fold: 5  Epoch: 115  Training loss = 2.5125  Validation loss = 5.5064  \n",
      "\n",
      "Fold: 5  Epoch: 116  Training loss = 2.5123  Validation loss = 5.5062  \n",
      "\n",
      "Fold: 5  Epoch: 117  Training loss = 2.5122  Validation loss = 5.5060  \n",
      "\n",
      "Fold: 5  Epoch: 118  Training loss = 2.5121  Validation loss = 5.5059  \n",
      "\n",
      "Fold: 5  Epoch: 119  Training loss = 2.5120  Validation loss = 5.5057  \n",
      "\n",
      "Fold: 5  Epoch: 120  Training loss = 2.5119  Validation loss = 5.5056  \n",
      "\n",
      "Fold: 5  Epoch: 121  Training loss = 2.5117  Validation loss = 5.5054  \n",
      "\n",
      "Fold: 5  Epoch: 122  Training loss = 2.5116  Validation loss = 5.5052  \n",
      "\n",
      "Fold: 5  Epoch: 123  Training loss = 2.5115  Validation loss = 5.5050  \n",
      "\n",
      "Fold: 5  Epoch: 124  Training loss = 2.5114  Validation loss = 5.5048  \n",
      "\n",
      "Fold: 5  Epoch: 125  Training loss = 2.5113  Validation loss = 5.5047  \n",
      "\n",
      "Fold: 5  Epoch: 126  Training loss = 2.5111  Validation loss = 5.5045  \n",
      "\n",
      "Fold: 5  Epoch: 127  Training loss = 2.5110  Validation loss = 5.5044  \n",
      "\n",
      "Fold: 5  Epoch: 128  Training loss = 2.5109  Validation loss = 5.5042  \n",
      "\n",
      "Fold: 5  Epoch: 129  Training loss = 2.5108  Validation loss = 5.5040  \n",
      "\n",
      "Fold: 5  Epoch: 130  Training loss = 2.5107  Validation loss = 5.5038  \n",
      "\n",
      "Fold: 5  Epoch: 131  Training loss = 2.5106  Validation loss = 5.5037  \n",
      "\n",
      "Fold: 5  Epoch: 132  Training loss = 2.5105  Validation loss = 5.5036  \n",
      "\n",
      "Fold: 5  Epoch: 133  Training loss = 2.5104  Validation loss = 5.5034  \n",
      "\n",
      "Fold: 5  Epoch: 134  Training loss = 2.5103  Validation loss = 5.5032  \n",
      "\n",
      "Fold: 5  Epoch: 135  Training loss = 2.5101  Validation loss = 5.5031  \n",
      "\n",
      "Fold: 5  Epoch: 136  Training loss = 2.5100  Validation loss = 5.5029  \n",
      "\n",
      "Fold: 5  Epoch: 137  Training loss = 2.5099  Validation loss = 5.5028  \n",
      "\n",
      "Fold: 5  Epoch: 138  Training loss = 2.5098  Validation loss = 5.5026  \n",
      "\n",
      "Fold: 5  Epoch: 139  Training loss = 2.5097  Validation loss = 5.5024  \n",
      "\n",
      "Fold: 5  Epoch: 140  Training loss = 2.5096  Validation loss = 5.5023  \n",
      "\n",
      "Fold: 5  Epoch: 141  Training loss = 2.5095  Validation loss = 5.5021  \n",
      "\n",
      "Fold: 5  Epoch: 142  Training loss = 2.5094  Validation loss = 5.5020  \n",
      "\n",
      "Fold: 5  Epoch: 143  Training loss = 2.5092  Validation loss = 5.5017  \n",
      "\n",
      "Fold: 5  Epoch: 144  Training loss = 2.5091  Validation loss = 5.5016  \n",
      "\n",
      "Fold: 5  Epoch: 145  Training loss = 2.5090  Validation loss = 5.5014  \n",
      "\n",
      "Fold: 5  Epoch: 146  Training loss = 2.5089  Validation loss = 5.5012  \n",
      "\n",
      "Fold: 5  Epoch: 147  Training loss = 2.5088  Validation loss = 5.5011  \n",
      "\n",
      "Fold: 5  Epoch: 148  Training loss = 2.5086  Validation loss = 5.5009  \n",
      "\n",
      "Fold: 5  Epoch: 149  Training loss = 2.5085  Validation loss = 5.5007  \n",
      "\n",
      "Fold: 5  Epoch: 150  Training loss = 2.5084  Validation loss = 5.5005  \n",
      "\n",
      "Fold: 5  Epoch: 151  Training loss = 2.5083  Validation loss = 5.5003  \n",
      "\n",
      "Fold: 5  Epoch: 152  Training loss = 2.5082  Validation loss = 5.5002  \n",
      "\n",
      "Fold: 5  Epoch: 153  Training loss = 2.5080  Validation loss = 5.4999  \n",
      "\n",
      "Fold: 5  Epoch: 154  Training loss = 2.5079  Validation loss = 5.4998  \n",
      "\n",
      "Fold: 5  Epoch: 155  Training loss = 2.5078  Validation loss = 5.4997  \n",
      "\n",
      "Fold: 5  Epoch: 156  Training loss = 2.5077  Validation loss = 5.4995  \n",
      "\n",
      "Fold: 5  Epoch: 157  Training loss = 2.5076  Validation loss = 5.4993  \n",
      "\n",
      "Fold: 5  Epoch: 158  Training loss = 2.5074  Validation loss = 5.4991  \n",
      "\n",
      "Fold: 5  Epoch: 159  Training loss = 2.5073  Validation loss = 5.4989  \n",
      "\n",
      "Fold: 5  Epoch: 160  Training loss = 2.5072  Validation loss = 5.4987  \n",
      "\n",
      "Fold: 5  Epoch: 161  Training loss = 2.5070  Validation loss = 5.4985  \n",
      "\n",
      "Fold: 5  Epoch: 162  Training loss = 2.5069  Validation loss = 5.4983  \n",
      "\n",
      "Fold: 5  Epoch: 163  Training loss = 2.5068  Validation loss = 5.4982  \n",
      "\n",
      "Fold: 5  Epoch: 164  Training loss = 2.5067  Validation loss = 5.4980  \n",
      "\n",
      "Fold: 5  Epoch: 165  Training loss = 2.5065  Validation loss = 5.4978  \n",
      "\n",
      "Fold: 5  Epoch: 166  Training loss = 2.5064  Validation loss = 5.4976  \n",
      "\n",
      "Fold: 5  Epoch: 167  Training loss = 2.5063  Validation loss = 5.4974  \n",
      "\n",
      "Fold: 5  Epoch: 168  Training loss = 2.5061  Validation loss = 5.4972  \n",
      "\n",
      "Fold: 5  Epoch: 169  Training loss = 2.5060  Validation loss = 5.4970  \n",
      "\n",
      "Fold: 5  Epoch: 170  Training loss = 2.5058  Validation loss = 5.4967  \n",
      "\n",
      "Fold: 5  Epoch: 171  Training loss = 2.5057  Validation loss = 5.4965  \n",
      "\n",
      "Fold: 5  Epoch: 172  Training loss = 2.5056  Validation loss = 5.4964  \n",
      "\n",
      "Fold: 5  Epoch: 173  Training loss = 2.5055  Validation loss = 5.4962  \n",
      "\n",
      "Fold: 5  Epoch: 174  Training loss = 2.5054  Validation loss = 5.4960  \n",
      "\n",
      "Fold: 5  Epoch: 175  Training loss = 2.5052  Validation loss = 5.4959  \n",
      "\n",
      "Fold: 5  Epoch: 176  Training loss = 2.5051  Validation loss = 5.4956  \n",
      "\n",
      "Fold: 5  Epoch: 177  Training loss = 2.5050  Validation loss = 5.4955  \n",
      "\n",
      "Fold: 5  Epoch: 178  Training loss = 2.5048  Validation loss = 5.4952  \n",
      "\n",
      "Fold: 5  Epoch: 179  Training loss = 2.5047  Validation loss = 5.4951  \n",
      "\n",
      "Fold: 5  Epoch: 180  Training loss = 2.5046  Validation loss = 5.4949  \n",
      "\n",
      "Fold: 5  Epoch: 181  Training loss = 2.5045  Validation loss = 5.4947  \n",
      "\n",
      "Fold: 5  Epoch: 182  Training loss = 2.5044  Validation loss = 5.4946  \n",
      "\n",
      "Fold: 5  Epoch: 183  Training loss = 2.5043  Validation loss = 5.4944  \n",
      "\n",
      "Fold: 5  Epoch: 184  Training loss = 2.5042  Validation loss = 5.4943  \n",
      "\n",
      "Fold: 5  Epoch: 185  Training loss = 2.5041  Validation loss = 5.4941  \n",
      "\n",
      "Fold: 5  Epoch: 186  Training loss = 2.5039  Validation loss = 5.4939  \n",
      "\n",
      "Fold: 5  Epoch: 187  Training loss = 2.5038  Validation loss = 5.4937  \n",
      "\n",
      "Fold: 5  Epoch: 188  Training loss = 2.5037  Validation loss = 5.4935  \n",
      "\n",
      "Fold: 5  Epoch: 189  Training loss = 2.5036  Validation loss = 5.4934  \n",
      "\n",
      "Fold: 5  Epoch: 190  Training loss = 2.5034  Validation loss = 5.4931  \n",
      "\n",
      "Fold: 5  Epoch: 191  Training loss = 2.5033  Validation loss = 5.4930  \n",
      "\n",
      "Fold: 5  Epoch: 192  Training loss = 2.5032  Validation loss = 5.4927  \n",
      "\n",
      "Fold: 5  Epoch: 193  Training loss = 2.5030  Validation loss = 5.4925  \n",
      "\n",
      "Fold: 5  Epoch: 194  Training loss = 2.5029  Validation loss = 5.4924  \n",
      "\n",
      "Fold: 5  Epoch: 195  Training loss = 2.5028  Validation loss = 5.4923  \n",
      "\n",
      "Fold: 5  Epoch: 196  Training loss = 2.5028  Validation loss = 5.4922  \n",
      "\n",
      "Fold: 5  Epoch: 197  Training loss = 2.5026  Validation loss = 5.4920  \n",
      "\n",
      "Fold: 5  Epoch: 198  Training loss = 2.5025  Validation loss = 5.4918  \n",
      "\n",
      "Fold: 5  Epoch: 199  Training loss = 2.5024  Validation loss = 5.4916  \n",
      "\n",
      "Fold: 5  Epoch: 200  Training loss = 2.5023  Validation loss = 5.4914  \n",
      "\n",
      "Fold: 5  Epoch: 201  Training loss = 2.5022  Validation loss = 5.4912  \n",
      "\n",
      "Fold: 5  Epoch: 202  Training loss = 2.5020  Validation loss = 5.4910  \n",
      "\n",
      "Fold: 5  Epoch: 203  Training loss = 2.5019  Validation loss = 5.4909  \n",
      "\n",
      "Fold: 5  Epoch: 204  Training loss = 2.5018  Validation loss = 5.4907  \n",
      "\n",
      "Fold: 5  Epoch: 205  Training loss = 2.5017  Validation loss = 5.4905  \n",
      "\n",
      "Fold: 5  Epoch: 206  Training loss = 2.5015  Validation loss = 5.4903  \n",
      "\n",
      "Fold: 5  Epoch: 207  Training loss = 2.5014  Validation loss = 5.4901  \n",
      "\n",
      "Fold: 5  Epoch: 208  Training loss = 2.5013  Validation loss = 5.4900  \n",
      "\n",
      "Fold: 5  Epoch: 209  Training loss = 2.5012  Validation loss = 5.4899  \n",
      "\n",
      "Fold: 5  Epoch: 210  Training loss = 2.5011  Validation loss = 5.4897  \n",
      "\n",
      "Fold: 5  Epoch: 211  Training loss = 2.5010  Validation loss = 5.4895  \n",
      "\n",
      "Fold: 5  Epoch: 212  Training loss = 2.5008  Validation loss = 5.4894  \n",
      "\n",
      "Fold: 5  Epoch: 213  Training loss = 2.5007  Validation loss = 5.4892  \n",
      "\n",
      "Fold: 5  Epoch: 214  Training loss = 2.5006  Validation loss = 5.4890  \n",
      "\n",
      "Fold: 5  Epoch: 215  Training loss = 2.5005  Validation loss = 5.4889  \n",
      "\n",
      "Fold: 5  Epoch: 216  Training loss = 2.5003  Validation loss = 5.4886  \n",
      "\n",
      "Fold: 5  Epoch: 217  Training loss = 2.5002  Validation loss = 5.4885  \n",
      "\n",
      "Fold: 5  Epoch: 218  Training loss = 2.5001  Validation loss = 5.4883  \n",
      "\n",
      "Fold: 5  Epoch: 219  Training loss = 2.5000  Validation loss = 5.4881  \n",
      "\n",
      "Fold: 5  Epoch: 220  Training loss = 2.4998  Validation loss = 5.4879  \n",
      "\n",
      "Fold: 5  Epoch: 221  Training loss = 2.4997  Validation loss = 5.4878  \n",
      "\n",
      "Fold: 5  Epoch: 222  Training loss = 2.4996  Validation loss = 5.4876  \n",
      "\n",
      "Fold: 5  Epoch: 223  Training loss = 2.4995  Validation loss = 5.4874  \n",
      "\n",
      "Fold: 5  Epoch: 224  Training loss = 2.4994  Validation loss = 5.4873  \n",
      "\n",
      "Fold: 5  Epoch: 225  Training loss = 2.4993  Validation loss = 5.4871  \n",
      "\n",
      "Fold: 5  Epoch: 226  Training loss = 2.4992  Validation loss = 5.4870  \n",
      "\n",
      "Fold: 5  Epoch: 227  Training loss = 2.4991  Validation loss = 5.4868  \n",
      "\n",
      "Fold: 5  Epoch: 228  Training loss = 2.4989  Validation loss = 5.4866  \n",
      "\n",
      "Fold: 5  Epoch: 229  Training loss = 2.4988  Validation loss = 5.4864  \n",
      "\n",
      "Fold: 5  Epoch: 230  Training loss = 2.4987  Validation loss = 5.4862  \n",
      "\n",
      "Fold: 5  Epoch: 231  Training loss = 2.4986  Validation loss = 5.4861  \n",
      "\n",
      "Fold: 5  Epoch: 232  Training loss = 2.4984  Validation loss = 5.4859  \n",
      "\n",
      "Fold: 5  Epoch: 233  Training loss = 2.4983  Validation loss = 5.4857  \n",
      "\n",
      "Fold: 5  Epoch: 234  Training loss = 2.4982  Validation loss = 5.4855  \n",
      "\n",
      "Fold: 5  Epoch: 235  Training loss = 2.4981  Validation loss = 5.4853  \n",
      "\n",
      "Fold: 5  Epoch: 236  Training loss = 2.4980  Validation loss = 5.4852  \n",
      "\n",
      "Fold: 5  Epoch: 237  Training loss = 2.4978  Validation loss = 5.4850  \n",
      "\n",
      "Fold: 5  Epoch: 238  Training loss = 2.4977  Validation loss = 5.4848  \n",
      "\n",
      "Fold: 5  Epoch: 239  Training loss = 2.4976  Validation loss = 5.4846  \n",
      "\n",
      "Fold: 5  Epoch: 240  Training loss = 2.4975  Validation loss = 5.4844  \n",
      "\n",
      "Fold: 5  Epoch: 241  Training loss = 2.4974  Validation loss = 5.4843  \n",
      "\n",
      "Fold: 5  Epoch: 242  Training loss = 2.4972  Validation loss = 5.4840  \n",
      "\n",
      "Fold: 5  Epoch: 243  Training loss = 2.4971  Validation loss = 5.4839  \n",
      "\n",
      "Fold: 5  Epoch: 244  Training loss = 2.4970  Validation loss = 5.4837  \n",
      "\n",
      "Fold: 5  Epoch: 245  Training loss = 2.4969  Validation loss = 5.4836  \n",
      "\n",
      "Fold: 5  Epoch: 246  Training loss = 2.4967  Validation loss = 5.4834  \n",
      "\n",
      "Fold: 5  Epoch: 247  Training loss = 2.4966  Validation loss = 5.4831  \n",
      "\n",
      "Fold: 5  Epoch: 248  Training loss = 2.4965  Validation loss = 5.4830  \n",
      "\n",
      "Fold: 5  Epoch: 249  Training loss = 2.4964  Validation loss = 5.4828  \n",
      "\n",
      "Fold: 5  Epoch: 250  Training loss = 2.4962  Validation loss = 5.4826  \n",
      "\n",
      "Fold: 5  Epoch: 251  Training loss = 2.4961  Validation loss = 5.4824  \n",
      "\n",
      "Fold: 5  Epoch: 252  Training loss = 2.4960  Validation loss = 5.4823  \n",
      "\n",
      "Fold: 5  Epoch: 253  Training loss = 2.4959  Validation loss = 5.4821  \n",
      "\n",
      "Fold: 5  Epoch: 254  Training loss = 2.4958  Validation loss = 5.4819  \n",
      "\n",
      "Fold: 5  Epoch: 255  Training loss = 2.4957  Validation loss = 5.4818  \n",
      "\n",
      "Fold: 5  Epoch: 256  Training loss = 2.4956  Validation loss = 5.4817  \n",
      "\n",
      "Fold: 5  Epoch: 257  Training loss = 2.4955  Validation loss = 5.4815  \n",
      "\n",
      "Fold: 5  Epoch: 258  Training loss = 2.4953  Validation loss = 5.4813  \n",
      "\n",
      "Fold: 5  Epoch: 259  Training loss = 2.4952  Validation loss = 5.4811  \n",
      "\n",
      "Fold: 5  Epoch: 260  Training loss = 2.4951  Validation loss = 5.4809  \n",
      "\n",
      "Fold: 5  Epoch: 261  Training loss = 2.4949  Validation loss = 5.4807  \n",
      "\n",
      "Fold: 5  Epoch: 262  Training loss = 2.4948  Validation loss = 5.4805  \n",
      "\n",
      "Fold: 5  Epoch: 263  Training loss = 2.4947  Validation loss = 5.4804  \n",
      "\n",
      "Fold: 5  Epoch: 264  Training loss = 2.4946  Validation loss = 5.4801  \n",
      "\n",
      "Fold: 5  Epoch: 265  Training loss = 2.4945  Validation loss = 5.4800  \n",
      "\n",
      "Fold: 5  Epoch: 266  Training loss = 2.4943  Validation loss = 5.4798  \n",
      "\n",
      "Fold: 5  Epoch: 267  Training loss = 2.4942  Validation loss = 5.4796  \n",
      "\n",
      "Fold: 5  Epoch: 268  Training loss = 2.4941  Validation loss = 5.4795  \n",
      "\n",
      "Fold: 5  Epoch: 269  Training loss = 2.4940  Validation loss = 5.4793  \n",
      "\n",
      "Fold: 5  Epoch: 270  Training loss = 2.4939  Validation loss = 5.4791  \n",
      "\n",
      "Fold: 5  Epoch: 271  Training loss = 2.4938  Validation loss = 5.4790  \n",
      "\n",
      "Fold: 5  Epoch: 272  Training loss = 2.4936  Validation loss = 5.4788  \n",
      "\n",
      "Fold: 5  Epoch: 273  Training loss = 2.4935  Validation loss = 5.4786  \n",
      "\n",
      "Fold: 5  Epoch: 274  Training loss = 2.4934  Validation loss = 5.4785  \n",
      "\n",
      "Fold: 5  Epoch: 275  Training loss = 2.4933  Validation loss = 5.4783  \n",
      "\n",
      "Fold: 5  Epoch: 276  Training loss = 2.4932  Validation loss = 5.4781  \n",
      "\n",
      "Fold: 5  Epoch: 277  Training loss = 2.4930  Validation loss = 5.4779  \n",
      "\n",
      "Fold: 5  Epoch: 278  Training loss = 2.4929  Validation loss = 5.4777  \n",
      "\n",
      "Fold: 5  Epoch: 279  Training loss = 2.4928  Validation loss = 5.4775  \n",
      "\n",
      "Fold: 5  Epoch: 280  Training loss = 2.4926  Validation loss = 5.4773  \n",
      "\n",
      "Fold: 5  Epoch: 281  Training loss = 2.4925  Validation loss = 5.4771  \n",
      "\n",
      "Fold: 5  Epoch: 282  Training loss = 2.4924  Validation loss = 5.4769  \n",
      "\n",
      "Fold: 5  Epoch: 283  Training loss = 2.4923  Validation loss = 5.4768  \n",
      "\n",
      "Fold: 5  Epoch: 284  Training loss = 2.4921  Validation loss = 5.4766  \n",
      "\n",
      "Fold: 5  Epoch: 285  Training loss = 2.4920  Validation loss = 5.4763  \n",
      "\n",
      "Fold: 5  Epoch: 286  Training loss = 2.4919  Validation loss = 5.4761  \n",
      "\n",
      "Fold: 5  Epoch: 287  Training loss = 2.4917  Validation loss = 5.4760  \n",
      "\n",
      "Fold: 5  Epoch: 288  Training loss = 2.4916  Validation loss = 5.4758  \n",
      "\n",
      "Fold: 5  Epoch: 289  Training loss = 2.4915  Validation loss = 5.4756  \n",
      "\n",
      "Fold: 5  Epoch: 290  Training loss = 2.4914  Validation loss = 5.4755  \n",
      "\n",
      "Fold: 5  Epoch: 291  Training loss = 2.4913  Validation loss = 5.4754  \n",
      "\n",
      "Fold: 5  Epoch: 292  Training loss = 2.4912  Validation loss = 5.4752  \n",
      "\n",
      "Fold: 5  Epoch: 293  Training loss = 2.4910  Validation loss = 5.4749  \n",
      "\n",
      "Fold: 5  Epoch: 294  Training loss = 2.4909  Validation loss = 5.4747  \n",
      "\n",
      "Fold: 5  Epoch: 295  Training loss = 2.4908  Validation loss = 5.4745  \n",
      "\n",
      "Fold: 5  Epoch: 296  Training loss = 2.4906  Validation loss = 5.4743  \n",
      "\n",
      "Fold: 5  Epoch: 297  Training loss = 2.4905  Validation loss = 5.4741  \n",
      "\n",
      "Fold: 5  Epoch: 298  Training loss = 2.4904  Validation loss = 5.4740  \n",
      "\n",
      "Fold: 5  Epoch: 299  Training loss = 2.4903  Validation loss = 5.4737  \n",
      "\n",
      "Fold: 5  Epoch: 300  Training loss = 2.4902  Validation loss = 5.4736  \n",
      "\n",
      "Fold: 5  Epoch: 301  Training loss = 2.4900  Validation loss = 5.4734  \n",
      "\n",
      "Fold: 5  Epoch: 302  Training loss = 2.4899  Validation loss = 5.4733  \n",
      "\n",
      "Fold: 5  Epoch: 303  Training loss = 2.4898  Validation loss = 5.4731  \n",
      "\n",
      "Fold: 5  Epoch: 304  Training loss = 2.4897  Validation loss = 5.4729  \n",
      "\n",
      "Fold: 5  Epoch: 305  Training loss = 2.4896  Validation loss = 5.4728  \n",
      "\n",
      "Fold: 5  Epoch: 306  Training loss = 2.4895  Validation loss = 5.4726  \n",
      "\n",
      "Fold: 5  Epoch: 307  Training loss = 2.4894  Validation loss = 5.4724  \n",
      "\n",
      "Fold: 5  Epoch: 308  Training loss = 2.4893  Validation loss = 5.4723  \n",
      "\n",
      "Fold: 5  Epoch: 309  Training loss = 2.4892  Validation loss = 5.4722  \n",
      "\n",
      "Fold: 5  Epoch: 310  Training loss = 2.4891  Validation loss = 5.4720  \n",
      "\n",
      "Fold: 5  Epoch: 311  Training loss = 2.4889  Validation loss = 5.4718  \n",
      "\n",
      "Fold: 5  Epoch: 312  Training loss = 2.4888  Validation loss = 5.4716  \n",
      "\n",
      "Fold: 5  Epoch: 313  Training loss = 2.4887  Validation loss = 5.4714  \n",
      "\n",
      "Fold: 5  Epoch: 314  Training loss = 2.4886  Validation loss = 5.4713  \n",
      "\n",
      "Fold: 5  Epoch: 315  Training loss = 2.4884  Validation loss = 5.4710  \n",
      "\n",
      "Fold: 5  Epoch: 316  Training loss = 2.4883  Validation loss = 5.4708  \n",
      "\n",
      "Fold: 5  Epoch: 317  Training loss = 2.4881  Validation loss = 5.4706  \n",
      "\n",
      "Fold: 5  Epoch: 318  Training loss = 2.4880  Validation loss = 5.4704  \n",
      "\n",
      "Fold: 5  Epoch: 319  Training loss = 2.4879  Validation loss = 5.4702  \n",
      "\n",
      "Fold: 5  Epoch: 320  Training loss = 2.4878  Validation loss = 5.4700  \n",
      "\n",
      "Fold: 5  Epoch: 321  Training loss = 2.4876  Validation loss = 5.4699  \n",
      "\n",
      "Fold: 5  Epoch: 322  Training loss = 2.4875  Validation loss = 5.4696  \n",
      "\n",
      "Fold: 5  Epoch: 323  Training loss = 2.4874  Validation loss = 5.4694  \n",
      "\n",
      "Fold: 5  Epoch: 324  Training loss = 2.4872  Validation loss = 5.4692  \n",
      "\n",
      "Fold: 5  Epoch: 325  Training loss = 2.4871  Validation loss = 5.4690  \n",
      "\n",
      "Fold: 5  Epoch: 326  Training loss = 2.4870  Validation loss = 5.4688  \n",
      "\n",
      "Fold: 5  Epoch: 327  Training loss = 2.4868  Validation loss = 5.4686  \n",
      "\n",
      "Fold: 5  Epoch: 328  Training loss = 2.4867  Validation loss = 5.4684  \n",
      "\n",
      "Fold: 5  Epoch: 329  Training loss = 2.4866  Validation loss = 5.4683  \n",
      "\n",
      "Fold: 5  Epoch: 330  Training loss = 2.4865  Validation loss = 5.4681  \n",
      "\n",
      "Fold: 5  Epoch: 331  Training loss = 2.4864  Validation loss = 5.4679  \n",
      "\n",
      "Fold: 5  Epoch: 332  Training loss = 2.4862  Validation loss = 5.4677  \n",
      "\n",
      "Fold: 5  Epoch: 333  Training loss = 2.4861  Validation loss = 5.4676  \n",
      "\n",
      "Fold: 5  Epoch: 334  Training loss = 2.4860  Validation loss = 5.4674  \n",
      "\n",
      "Fold: 5  Epoch: 335  Training loss = 2.4859  Validation loss = 5.4673  \n",
      "\n",
      "Fold: 5  Epoch: 336  Training loss = 2.4858  Validation loss = 5.4671  \n",
      "\n",
      "Fold: 5  Epoch: 337  Training loss = 2.4857  Validation loss = 5.4669  \n",
      "\n",
      "Fold: 5  Epoch: 338  Training loss = 2.4855  Validation loss = 5.4668  \n",
      "\n",
      "Fold: 5  Epoch: 339  Training loss = 2.4854  Validation loss = 5.4666  \n",
      "\n",
      "Fold: 5  Epoch: 340  Training loss = 2.4853  Validation loss = 5.4664  \n",
      "\n",
      "Fold: 5  Epoch: 341  Training loss = 2.4852  Validation loss = 5.4663  \n",
      "\n",
      "Fold: 5  Epoch: 342  Training loss = 2.4851  Validation loss = 5.4661  \n",
      "\n",
      "Fold: 5  Epoch: 343  Training loss = 2.4850  Validation loss = 5.4659  \n",
      "\n",
      "Fold: 5  Epoch: 344  Training loss = 2.4848  Validation loss = 5.4656  \n",
      "\n",
      "Fold: 5  Epoch: 345  Training loss = 2.4847  Validation loss = 5.4655  \n",
      "\n",
      "Fold: 5  Epoch: 346  Training loss = 2.4846  Validation loss = 5.4653  \n",
      "\n",
      "Fold: 5  Epoch: 347  Training loss = 2.4845  Validation loss = 5.4652  \n",
      "\n",
      "Fold: 5  Epoch: 348  Training loss = 2.4844  Validation loss = 5.4650  \n",
      "\n",
      "Fold: 5  Epoch: 349  Training loss = 2.4843  Validation loss = 5.4648  \n",
      "\n",
      "Fold: 5  Epoch: 350  Training loss = 2.4841  Validation loss = 5.4646  \n",
      "\n",
      "Fold: 5  Epoch: 351  Training loss = 2.4840  Validation loss = 5.4645  \n",
      "\n",
      "Fold: 5  Epoch: 352  Training loss = 2.4839  Validation loss = 5.4644  \n",
      "\n",
      "Fold: 5  Epoch: 353  Training loss = 2.4838  Validation loss = 5.4642  \n",
      "\n",
      "Fold: 5  Epoch: 354  Training loss = 2.4837  Validation loss = 5.4640  \n",
      "\n",
      "Fold: 5  Epoch: 355  Training loss = 2.4836  Validation loss = 5.4639  \n",
      "\n",
      "Fold: 5  Epoch: 356  Training loss = 2.4835  Validation loss = 5.4637  \n",
      "\n",
      "Fold: 5  Epoch: 357  Training loss = 2.4833  Validation loss = 5.4635  \n",
      "\n",
      "Fold: 5  Epoch: 358  Training loss = 2.4832  Validation loss = 5.4633  \n",
      "\n",
      "Fold: 5  Epoch: 359  Training loss = 2.4831  Validation loss = 5.4631  \n",
      "\n",
      "Fold: 5  Epoch: 360  Training loss = 2.4830  Validation loss = 5.4630  \n",
      "\n",
      "Fold: 5  Epoch: 361  Training loss = 2.4829  Validation loss = 5.4628  \n",
      "\n",
      "Fold: 5  Epoch: 362  Training loss = 2.4827  Validation loss = 5.4626  \n",
      "\n",
      "Fold: 5  Epoch: 363  Training loss = 2.4826  Validation loss = 5.4624  \n",
      "\n",
      "Fold: 5  Epoch: 364  Training loss = 2.4825  Validation loss = 5.4622  \n",
      "\n",
      "Fold: 5  Epoch: 365  Training loss = 2.4824  Validation loss = 5.4621  \n",
      "\n",
      "Fold: 5  Epoch: 366  Training loss = 2.4822  Validation loss = 5.4619  \n",
      "\n",
      "Fold: 5  Epoch: 367  Training loss = 2.4821  Validation loss = 5.4617  \n",
      "\n",
      "Fold: 5  Epoch: 368  Training loss = 2.4820  Validation loss = 5.4615  \n",
      "\n",
      "Fold: 5  Epoch: 369  Training loss = 2.4819  Validation loss = 5.4613  \n",
      "\n",
      "Fold: 5  Epoch: 370  Training loss = 2.4818  Validation loss = 5.4612  \n",
      "\n",
      "Fold: 5  Epoch: 371  Training loss = 2.4817  Validation loss = 5.4610  \n",
      "\n",
      "Fold: 5  Epoch: 372  Training loss = 2.4815  Validation loss = 5.4608  \n",
      "\n",
      "Fold: 5  Epoch: 373  Training loss = 2.4814  Validation loss = 5.4606  \n",
      "\n",
      "Fold: 5  Epoch: 374  Training loss = 2.4813  Validation loss = 5.4605  \n",
      "\n",
      "Fold: 5  Epoch: 375  Training loss = 2.4812  Validation loss = 5.4603  \n",
      "\n",
      "Fold: 5  Epoch: 376  Training loss = 2.4811  Validation loss = 5.4601  \n",
      "\n",
      "Fold: 5  Epoch: 377  Training loss = 2.4810  Validation loss = 5.4599  \n",
      "\n",
      "Fold: 5  Epoch: 378  Training loss = 2.4808  Validation loss = 5.4597  \n",
      "\n",
      "Fold: 5  Epoch: 379  Training loss = 2.4807  Validation loss = 5.4595  \n",
      "\n",
      "Fold: 5  Epoch: 380  Training loss = 2.4806  Validation loss = 5.4593  \n",
      "\n",
      "Fold: 5  Epoch: 381  Training loss = 2.4804  Validation loss = 5.4591  \n",
      "\n",
      "Fold: 5  Epoch: 382  Training loss = 2.4803  Validation loss = 5.4588  \n",
      "\n",
      "Fold: 5  Epoch: 383  Training loss = 2.4802  Validation loss = 5.4587  \n",
      "\n",
      "Fold: 5  Epoch: 384  Training loss = 2.4800  Validation loss = 5.4585  \n",
      "\n",
      "Fold: 5  Epoch: 385  Training loss = 2.4800  Validation loss = 5.4584  \n",
      "\n",
      "Fold: 5  Epoch: 386  Training loss = 2.4798  Validation loss = 5.4583  \n",
      "\n",
      "Fold: 5  Epoch: 387  Training loss = 2.4797  Validation loss = 5.4580  \n",
      "\n",
      "Fold: 5  Epoch: 388  Training loss = 2.4796  Validation loss = 5.4579  \n",
      "\n",
      "Fold: 5  Epoch: 389  Training loss = 2.4795  Validation loss = 5.4577  \n",
      "\n",
      "Fold: 5  Epoch: 390  Training loss = 2.4794  Validation loss = 5.4576  \n",
      "\n",
      "Fold: 5  Epoch: 391  Training loss = 2.4793  Validation loss = 5.4574  \n",
      "\n",
      "Fold: 5  Epoch: 392  Training loss = 2.4792  Validation loss = 5.4572  \n",
      "\n",
      "Fold: 5  Epoch: 393  Training loss = 2.4791  Validation loss = 5.4571  \n",
      "\n",
      "Fold: 5  Epoch: 394  Training loss = 2.4790  Validation loss = 5.4569  \n",
      "\n",
      "Fold: 5  Epoch: 395  Training loss = 2.4788  Validation loss = 5.4567  \n",
      "\n",
      "Fold: 5  Epoch: 396  Training loss = 2.4787  Validation loss = 5.4564  \n",
      "\n",
      "Fold: 5  Epoch: 397  Training loss = 2.4786  Validation loss = 5.4563  \n",
      "\n",
      "Fold: 5  Epoch: 398  Training loss = 2.4785  Validation loss = 5.4562  \n",
      "\n",
      "Fold: 5  Epoch: 399  Training loss = 2.4783  Validation loss = 5.4560  \n",
      "\n",
      "Fold: 5  Epoch: 400  Training loss = 2.4782  Validation loss = 5.4558  \n",
      "\n",
      "Fold: 5  Epoch: 401  Training loss = 2.4781  Validation loss = 5.4556  \n",
      "\n",
      "Fold: 5  Epoch: 402  Training loss = 2.4780  Validation loss = 5.4554  \n",
      "\n",
      "Fold: 5  Epoch: 403  Training loss = 2.4778  Validation loss = 5.4552  \n",
      "\n",
      "Fold: 5  Epoch: 404  Training loss = 2.4777  Validation loss = 5.4550  \n",
      "\n",
      "Fold: 5  Epoch: 405  Training loss = 2.4776  Validation loss = 5.4549  \n",
      "\n",
      "Fold: 5  Epoch: 406  Training loss = 2.4775  Validation loss = 5.4547  \n",
      "\n",
      "Fold: 5  Epoch: 407  Training loss = 2.4774  Validation loss = 5.4546  \n",
      "\n",
      "Fold: 5  Epoch: 408  Training loss = 2.4773  Validation loss = 5.4545  \n",
      "\n",
      "Fold: 5  Epoch: 409  Training loss = 2.4772  Validation loss = 5.4543  \n",
      "\n",
      "Fold: 5  Epoch: 410  Training loss = 2.4771  Validation loss = 5.4541  \n",
      "\n",
      "Fold: 5  Epoch: 411  Training loss = 2.4769  Validation loss = 5.4539  \n",
      "\n",
      "Fold: 5  Epoch: 412  Training loss = 2.4768  Validation loss = 5.4537  \n",
      "\n",
      "Fold: 5  Epoch: 413  Training loss = 2.4767  Validation loss = 5.4535  \n",
      "\n",
      "Fold: 5  Epoch: 414  Training loss = 2.4765  Validation loss = 5.4533  \n",
      "\n",
      "Fold: 5  Epoch: 415  Training loss = 2.4764  Validation loss = 5.4531  \n",
      "\n",
      "Fold: 5  Epoch: 416  Training loss = 2.4763  Validation loss = 5.4530  \n",
      "\n",
      "Fold: 5  Epoch: 417  Training loss = 2.4762  Validation loss = 5.4528  \n",
      "\n",
      "Fold: 5  Epoch: 418  Training loss = 2.4761  Validation loss = 5.4526  \n",
      "\n",
      "Fold: 5  Epoch: 419  Training loss = 2.4760  Validation loss = 5.4525  \n",
      "\n",
      "Fold: 5  Epoch: 420  Training loss = 2.4758  Validation loss = 5.4522  \n",
      "\n",
      "Fold: 5  Epoch: 421  Training loss = 2.4757  Validation loss = 5.4520  \n",
      "\n",
      "Fold: 5  Epoch: 422  Training loss = 2.4755  Validation loss = 5.4517  \n",
      "\n",
      "Fold: 5  Epoch: 423  Training loss = 2.4754  Validation loss = 5.4516  \n",
      "\n",
      "Fold: 5  Epoch: 424  Training loss = 2.4753  Validation loss = 5.4514  \n",
      "\n",
      "Fold: 5  Epoch: 425  Training loss = 2.4752  Validation loss = 5.4512  \n",
      "\n",
      "Fold: 5  Epoch: 426  Training loss = 2.4751  Validation loss = 5.4511  \n",
      "\n",
      "Fold: 5  Epoch: 427  Training loss = 2.4749  Validation loss = 5.4508  \n",
      "\n",
      "Fold: 5  Epoch: 428  Training loss = 2.4748  Validation loss = 5.4507  \n",
      "\n",
      "Fold: 5  Epoch: 429  Training loss = 2.4747  Validation loss = 5.4505  \n",
      "\n",
      "Fold: 5  Epoch: 430  Training loss = 2.4746  Validation loss = 5.4503  \n",
      "\n",
      "Fold: 5  Epoch: 431  Training loss = 2.4745  Validation loss = 5.4502  \n",
      "\n",
      "Fold: 5  Epoch: 432  Training loss = 2.4744  Validation loss = 5.4500  \n",
      "\n",
      "Fold: 5  Epoch: 433  Training loss = 2.4743  Validation loss = 5.4498  \n",
      "\n",
      "Fold: 5  Epoch: 434  Training loss = 2.4741  Validation loss = 5.4496  \n",
      "\n",
      "Fold: 5  Epoch: 435  Training loss = 2.4740  Validation loss = 5.4494  \n",
      "\n",
      "Fold: 5  Epoch: 436  Training loss = 2.4739  Validation loss = 5.4493  \n",
      "\n",
      "Fold: 5  Epoch: 437  Training loss = 2.4738  Validation loss = 5.4491  \n",
      "\n",
      "Fold: 5  Epoch: 438  Training loss = 2.4737  Validation loss = 5.4489  \n",
      "\n",
      "Fold: 5  Epoch: 439  Training loss = 2.4736  Validation loss = 5.4488  \n",
      "\n",
      "Fold: 5  Epoch: 440  Training loss = 2.4735  Validation loss = 5.4486  \n",
      "\n",
      "Fold: 5  Epoch: 441  Training loss = 2.4734  Validation loss = 5.4485  \n",
      "\n",
      "Fold: 5  Epoch: 442  Training loss = 2.4732  Validation loss = 5.4483  \n",
      "\n",
      "Fold: 5  Epoch: 443  Training loss = 2.4731  Validation loss = 5.4481  \n",
      "\n",
      "Fold: 5  Epoch: 444  Training loss = 2.4730  Validation loss = 5.4479  \n",
      "\n",
      "Fold: 5  Epoch: 445  Training loss = 2.4729  Validation loss = 5.4477  \n",
      "\n",
      "Fold: 5  Epoch: 446  Training loss = 2.4728  Validation loss = 5.4476  \n",
      "\n",
      "Fold: 5  Epoch: 447  Training loss = 2.4726  Validation loss = 5.4473  \n",
      "\n",
      "Fold: 5  Epoch: 448  Training loss = 2.4725  Validation loss = 5.4472  \n",
      "\n",
      "Fold: 5  Epoch: 449  Training loss = 2.4724  Validation loss = 5.4471  \n",
      "\n",
      "Fold: 5  Epoch: 450  Training loss = 2.4723  Validation loss = 5.4468  \n",
      "\n",
      "Fold: 5  Epoch: 451  Training loss = 2.4722  Validation loss = 5.4467  \n",
      "\n",
      "Fold: 5  Epoch: 452  Training loss = 2.4721  Validation loss = 5.4466  \n",
      "\n",
      "Fold: 5  Epoch: 453  Training loss = 2.4720  Validation loss = 5.4464  \n",
      "\n",
      "Fold: 5  Epoch: 454  Training loss = 2.4719  Validation loss = 5.4463  \n",
      "\n",
      "Fold: 5  Epoch: 455  Training loss = 2.4718  Validation loss = 5.4461  \n",
      "\n",
      "Fold: 5  Epoch: 456  Training loss = 2.4717  Validation loss = 5.4460  \n",
      "\n",
      "Fold: 5  Epoch: 457  Training loss = 2.4715  Validation loss = 5.4458  \n",
      "\n",
      "Fold: 5  Epoch: 458  Training loss = 2.4714  Validation loss = 5.4456  \n",
      "\n",
      "Fold: 5  Epoch: 459  Training loss = 2.4713  Validation loss = 5.4454  \n",
      "\n",
      "Fold: 5  Epoch: 460  Training loss = 2.4712  Validation loss = 5.4453  \n",
      "\n",
      "Fold: 5  Epoch: 461  Training loss = 2.4711  Validation loss = 5.4451  \n",
      "\n",
      "Fold: 5  Epoch: 462  Training loss = 2.4710  Validation loss = 5.4449  \n",
      "\n",
      "Fold: 5  Epoch: 463  Training loss = 2.4709  Validation loss = 5.4448  \n",
      "\n",
      "Fold: 5  Epoch: 464  Training loss = 2.4708  Validation loss = 5.4446  \n",
      "\n",
      "Fold: 5  Epoch: 465  Training loss = 2.4706  Validation loss = 5.4444  \n",
      "\n",
      "Fold: 5  Epoch: 466  Training loss = 2.4705  Validation loss = 5.4442  \n",
      "\n",
      "Fold: 5  Epoch: 467  Training loss = 2.4704  Validation loss = 5.4441  \n",
      "\n",
      "Fold: 5  Epoch: 468  Training loss = 2.4703  Validation loss = 5.4439  \n",
      "\n",
      "Fold: 5  Epoch: 469  Training loss = 2.4701  Validation loss = 5.4437  \n",
      "\n",
      "Fold: 5  Epoch: 470  Training loss = 2.4700  Validation loss = 5.4435  \n",
      "\n",
      "Fold: 5  Epoch: 471  Training loss = 2.4699  Validation loss = 5.4433  \n",
      "\n",
      "Fold: 5  Epoch: 472  Training loss = 2.4698  Validation loss = 5.4432  \n",
      "\n",
      "Fold: 5  Epoch: 473  Training loss = 2.4697  Validation loss = 5.4430  \n",
      "\n",
      "Fold: 5  Epoch: 474  Training loss = 2.4695  Validation loss = 5.4427  \n",
      "\n",
      "Fold: 5  Epoch: 475  Training loss = 2.4694  Validation loss = 5.4425  \n",
      "\n",
      "Fold: 5  Epoch: 476  Training loss = 2.4693  Validation loss = 5.4423  \n",
      "\n",
      "Fold: 5  Epoch: 477  Training loss = 2.4691  Validation loss = 5.4421  \n",
      "\n",
      "Fold: 5  Epoch: 478  Training loss = 2.4690  Validation loss = 5.4419  \n",
      "\n",
      "Fold: 5  Epoch: 479  Training loss = 2.4689  Validation loss = 5.4417  \n",
      "\n",
      "Fold: 5  Epoch: 480  Training loss = 2.4688  Validation loss = 5.4415  \n",
      "\n",
      "Fold: 5  Epoch: 481  Training loss = 2.4686  Validation loss = 5.4413  \n",
      "\n",
      "Fold: 5  Epoch: 482  Training loss = 2.4685  Validation loss = 5.4411  \n",
      "\n",
      "Fold: 5  Epoch: 483  Training loss = 2.4684  Validation loss = 5.4410  \n",
      "\n",
      "Fold: 5  Epoch: 484  Training loss = 2.4683  Validation loss = 5.4408  \n",
      "\n",
      "Fold: 5  Epoch: 485  Training loss = 2.4681  Validation loss = 5.4406  \n",
      "\n",
      "Fold: 5  Epoch: 486  Training loss = 2.4680  Validation loss = 5.4403  \n",
      "\n",
      "Fold: 5  Epoch: 487  Training loss = 2.4678  Validation loss = 5.4401  \n",
      "\n",
      "Fold: 5  Epoch: 488  Training loss = 2.4677  Validation loss = 5.4399  \n",
      "\n",
      "Fold: 5  Epoch: 489  Training loss = 2.4676  Validation loss = 5.4398  \n",
      "\n",
      "Fold: 5  Epoch: 490  Training loss = 2.4675  Validation loss = 5.4396  \n",
      "\n",
      "Fold: 5  Epoch: 491  Training loss = 2.4674  Validation loss = 5.4395  \n",
      "\n",
      "Fold: 5  Epoch: 492  Training loss = 2.4673  Validation loss = 5.4393  \n",
      "\n",
      "Fold: 5  Epoch: 493  Training loss = 2.4672  Validation loss = 5.4391  \n",
      "\n",
      "Fold: 5  Epoch: 494  Training loss = 2.4671  Validation loss = 5.4390  \n",
      "\n",
      "Fold: 5  Epoch: 495  Training loss = 2.4670  Validation loss = 5.4388  \n",
      "\n",
      "Fold: 5  Epoch: 496  Training loss = 2.4668  Validation loss = 5.4386  \n",
      "\n",
      "Fold: 5  Epoch: 497  Training loss = 2.4667  Validation loss = 5.4385  \n",
      "\n",
      "Fold: 5  Epoch: 498  Training loss = 2.4666  Validation loss = 5.4383  \n",
      "\n",
      "Fold: 5  Epoch: 499  Training loss = 2.4665  Validation loss = 5.4382  \n",
      "\n",
      "Fold: 5  Epoch: 500  Training loss = 2.4664  Validation loss = 5.4380  \n",
      "\n",
      "Check model:  Fold: 5  Optimal epoch: 500  \n",
      "\n",
      "Fold: 6  Epoch: 1  Training loss = 2.8060  Validation loss = 3.3341  \n",
      "\n",
      "Fold: 6  Epoch: 2  Training loss = 2.8058  Validation loss = 3.3338  \n",
      "\n",
      "Fold: 6  Epoch: 3  Training loss = 2.8057  Validation loss = 3.3336  \n",
      "\n",
      "Fold: 6  Epoch: 4  Training loss = 2.8055  Validation loss = 3.3333  \n",
      "\n",
      "Fold: 6  Epoch: 5  Training loss = 2.8054  Validation loss = 3.3331  \n",
      "\n",
      "Fold: 6  Epoch: 6  Training loss = 2.8052  Validation loss = 3.3329  \n",
      "\n",
      "Fold: 6  Epoch: 7  Training loss = 2.8051  Validation loss = 3.3326  \n",
      "\n",
      "Fold: 6  Epoch: 8  Training loss = 2.8049  Validation loss = 3.3324  \n",
      "\n",
      "Fold: 6  Epoch: 9  Training loss = 2.8048  Validation loss = 3.3322  \n",
      "\n",
      "Fold: 6  Epoch: 10  Training loss = 2.8046  Validation loss = 3.3319  \n",
      "\n",
      "Fold: 6  Epoch: 11  Training loss = 2.8045  Validation loss = 3.3316  \n",
      "\n",
      "Fold: 6  Epoch: 12  Training loss = 2.8043  Validation loss = 3.3314  \n",
      "\n",
      "Fold: 6  Epoch: 13  Training loss = 2.8042  Validation loss = 3.3312  \n",
      "\n",
      "Fold: 6  Epoch: 14  Training loss = 2.8041  Validation loss = 3.3310  \n",
      "\n",
      "Fold: 6  Epoch: 15  Training loss = 2.8039  Validation loss = 3.3307  \n",
      "\n",
      "Fold: 6  Epoch: 16  Training loss = 2.8038  Validation loss = 3.3305  \n",
      "\n",
      "Fold: 6  Epoch: 17  Training loss = 2.8036  Validation loss = 3.3302  \n",
      "\n",
      "Fold: 6  Epoch: 18  Training loss = 2.8035  Validation loss = 3.3300  \n",
      "\n",
      "Fold: 6  Epoch: 19  Training loss = 2.8033  Validation loss = 3.3297  \n",
      "\n",
      "Fold: 6  Epoch: 20  Training loss = 2.8032  Validation loss = 3.3295  \n",
      "\n",
      "Fold: 6  Epoch: 21  Training loss = 2.8030  Validation loss = 3.3293  \n",
      "\n",
      "Fold: 6  Epoch: 22  Training loss = 2.8029  Validation loss = 3.3290  \n",
      "\n",
      "Fold: 6  Epoch: 23  Training loss = 2.8027  Validation loss = 3.3287  \n",
      "\n",
      "Fold: 6  Epoch: 24  Training loss = 2.8026  Validation loss = 3.3285  \n",
      "\n",
      "Fold: 6  Epoch: 25  Training loss = 2.8024  Validation loss = 3.3283  \n",
      "\n",
      "Fold: 6  Epoch: 26  Training loss = 2.8023  Validation loss = 3.3280  \n",
      "\n",
      "Fold: 6  Epoch: 27  Training loss = 2.8021  Validation loss = 3.3278  \n",
      "\n",
      "Fold: 6  Epoch: 28  Training loss = 2.8020  Validation loss = 3.3276  \n",
      "\n",
      "Fold: 6  Epoch: 29  Training loss = 2.8018  Validation loss = 3.3273  \n",
      "\n",
      "Fold: 6  Epoch: 30  Training loss = 2.8016  Validation loss = 3.3270  \n",
      "\n",
      "Fold: 6  Epoch: 31  Training loss = 2.8015  Validation loss = 3.3267  \n",
      "\n",
      "Fold: 6  Epoch: 32  Training loss = 2.8013  Validation loss = 3.3265  \n",
      "\n",
      "Fold: 6  Epoch: 33  Training loss = 2.8012  Validation loss = 3.3263  \n",
      "\n",
      "Fold: 6  Epoch: 34  Training loss = 2.8011  Validation loss = 3.3260  \n",
      "\n",
      "Fold: 6  Epoch: 35  Training loss = 2.8009  Validation loss = 3.3258  \n",
      "\n",
      "Fold: 6  Epoch: 36  Training loss = 2.8008  Validation loss = 3.3256  \n",
      "\n",
      "Fold: 6  Epoch: 37  Training loss = 2.8006  Validation loss = 3.3253  \n",
      "\n",
      "Fold: 6  Epoch: 38  Training loss = 2.8004  Validation loss = 3.3250  \n",
      "\n",
      "Fold: 6  Epoch: 39  Training loss = 2.8003  Validation loss = 3.3248  \n",
      "\n",
      "Fold: 6  Epoch: 40  Training loss = 2.8001  Validation loss = 3.3245  \n",
      "\n",
      "Fold: 6  Epoch: 41  Training loss = 2.8000  Validation loss = 3.3242  \n",
      "\n",
      "Fold: 6  Epoch: 42  Training loss = 2.7998  Validation loss = 3.3239  \n",
      "\n",
      "Fold: 6  Epoch: 43  Training loss = 2.7996  Validation loss = 3.3237  \n",
      "\n",
      "Fold: 6  Epoch: 44  Training loss = 2.7994  Validation loss = 3.3233  \n",
      "\n",
      "Fold: 6  Epoch: 45  Training loss = 2.7993  Validation loss = 3.3231  \n",
      "\n",
      "Fold: 6  Epoch: 46  Training loss = 2.7992  Validation loss = 3.3229  \n",
      "\n",
      "Fold: 6  Epoch: 47  Training loss = 2.7990  Validation loss = 3.3227  \n",
      "\n",
      "Fold: 6  Epoch: 48  Training loss = 2.7989  Validation loss = 3.3224  \n",
      "\n",
      "Fold: 6  Epoch: 49  Training loss = 2.7988  Validation loss = 3.3222  \n",
      "\n",
      "Fold: 6  Epoch: 50  Training loss = 2.7986  Validation loss = 3.3220  \n",
      "\n",
      "Fold: 6  Epoch: 51  Training loss = 2.7985  Validation loss = 3.3217  \n",
      "\n",
      "Fold: 6  Epoch: 52  Training loss = 2.7983  Validation loss = 3.3215  \n",
      "\n",
      "Fold: 6  Epoch: 53  Training loss = 2.7981  Validation loss = 3.3212  \n",
      "\n",
      "Fold: 6  Epoch: 54  Training loss = 2.7980  Validation loss = 3.3209  \n",
      "\n",
      "Fold: 6  Epoch: 55  Training loss = 2.7978  Validation loss = 3.3206  \n",
      "\n",
      "Fold: 6  Epoch: 56  Training loss = 2.7976  Validation loss = 3.3203  \n",
      "\n",
      "Fold: 6  Epoch: 57  Training loss = 2.7975  Validation loss = 3.3200  \n",
      "\n",
      "Fold: 6  Epoch: 58  Training loss = 2.7973  Validation loss = 3.3198  \n",
      "\n",
      "Fold: 6  Epoch: 59  Training loss = 2.7972  Validation loss = 3.3195  \n",
      "\n",
      "Fold: 6  Epoch: 60  Training loss = 2.7970  Validation loss = 3.3193  \n",
      "\n",
      "Fold: 6  Epoch: 61  Training loss = 2.7969  Validation loss = 3.3191  \n",
      "\n",
      "Fold: 6  Epoch: 62  Training loss = 2.7967  Validation loss = 3.3188  \n",
      "\n",
      "Fold: 6  Epoch: 63  Training loss = 2.7966  Validation loss = 3.3186  \n",
      "\n",
      "Fold: 6  Epoch: 64  Training loss = 2.7965  Validation loss = 3.3184  \n",
      "\n",
      "Fold: 6  Epoch: 65  Training loss = 2.7963  Validation loss = 3.3181  \n",
      "\n",
      "Fold: 6  Epoch: 66  Training loss = 2.7962  Validation loss = 3.3179  \n",
      "\n",
      "Fold: 6  Epoch: 67  Training loss = 2.7960  Validation loss = 3.3176  \n",
      "\n",
      "Fold: 6  Epoch: 68  Training loss = 2.7958  Validation loss = 3.3173  \n",
      "\n",
      "Fold: 6  Epoch: 69  Training loss = 2.7957  Validation loss = 3.3170  \n",
      "\n",
      "Fold: 6  Epoch: 70  Training loss = 2.7955  Validation loss = 3.3168  \n",
      "\n",
      "Fold: 6  Epoch: 71  Training loss = 2.7953  Validation loss = 3.3164  \n",
      "\n",
      "Fold: 6  Epoch: 72  Training loss = 2.7951  Validation loss = 3.3162  \n",
      "\n",
      "Fold: 6  Epoch: 73  Training loss = 2.7950  Validation loss = 3.3159  \n",
      "\n",
      "Fold: 6  Epoch: 74  Training loss = 2.7949  Validation loss = 3.3157  \n",
      "\n",
      "Fold: 6  Epoch: 75  Training loss = 2.7947  Validation loss = 3.3155  \n",
      "\n",
      "Fold: 6  Epoch: 76  Training loss = 2.7946  Validation loss = 3.3153  \n",
      "\n",
      "Fold: 6  Epoch: 77  Training loss = 2.7945  Validation loss = 3.3150  \n",
      "\n",
      "Fold: 6  Epoch: 78  Training loss = 2.7943  Validation loss = 3.3148  \n",
      "\n",
      "Fold: 6  Epoch: 79  Training loss = 2.7942  Validation loss = 3.3145  \n",
      "\n",
      "Fold: 6  Epoch: 80  Training loss = 2.7940  Validation loss = 3.3143  \n",
      "\n",
      "Fold: 6  Epoch: 81  Training loss = 2.7938  Validation loss = 3.3140  \n",
      "\n",
      "Fold: 6  Epoch: 82  Training loss = 2.7937  Validation loss = 3.3138  \n",
      "\n",
      "Fold: 6  Epoch: 83  Training loss = 2.7936  Validation loss = 3.3136  \n",
      "\n",
      "Fold: 6  Epoch: 84  Training loss = 2.7934  Validation loss = 3.3133  \n",
      "\n",
      "Fold: 6  Epoch: 85  Training loss = 2.7933  Validation loss = 3.3131  \n",
      "\n",
      "Fold: 6  Epoch: 86  Training loss = 2.7931  Validation loss = 3.3128  \n",
      "\n",
      "Fold: 6  Epoch: 87  Training loss = 2.7929  Validation loss = 3.3125  \n",
      "\n",
      "Fold: 6  Epoch: 88  Training loss = 2.7928  Validation loss = 3.3123  \n",
      "\n",
      "Fold: 6  Epoch: 89  Training loss = 2.7926  Validation loss = 3.3120  \n",
      "\n",
      "Fold: 6  Epoch: 90  Training loss = 2.7925  Validation loss = 3.3117  \n",
      "\n",
      "Fold: 6  Epoch: 91  Training loss = 2.7923  Validation loss = 3.3115  \n",
      "\n",
      "Fold: 6  Epoch: 92  Training loss = 2.7922  Validation loss = 3.3112  \n",
      "\n",
      "Fold: 6  Epoch: 93  Training loss = 2.7920  Validation loss = 3.3110  \n",
      "\n",
      "Fold: 6  Epoch: 94  Training loss = 2.7919  Validation loss = 3.3107  \n",
      "\n",
      "Fold: 6  Epoch: 95  Training loss = 2.7917  Validation loss = 3.3105  \n",
      "\n",
      "Fold: 6  Epoch: 96  Training loss = 2.7916  Validation loss = 3.3103  \n",
      "\n",
      "Fold: 6  Epoch: 97  Training loss = 2.7914  Validation loss = 3.3100  \n",
      "\n",
      "Fold: 6  Epoch: 98  Training loss = 2.7913  Validation loss = 3.3097  \n",
      "\n",
      "Fold: 6  Epoch: 99  Training loss = 2.7911  Validation loss = 3.3095  \n",
      "\n",
      "Fold: 6  Epoch: 100  Training loss = 2.7910  Validation loss = 3.3092  \n",
      "\n",
      "Fold: 6  Epoch: 101  Training loss = 2.7908  Validation loss = 3.3090  \n",
      "\n",
      "Fold: 6  Epoch: 102  Training loss = 2.7907  Validation loss = 3.3087  \n",
      "\n",
      "Fold: 6  Epoch: 103  Training loss = 2.7905  Validation loss = 3.3085  \n",
      "\n",
      "Fold: 6  Epoch: 104  Training loss = 2.7904  Validation loss = 3.3082  \n",
      "\n",
      "Fold: 6  Epoch: 105  Training loss = 2.7903  Validation loss = 3.3080  \n",
      "\n",
      "Fold: 6  Epoch: 106  Training loss = 2.7901  Validation loss = 3.3078  \n",
      "\n",
      "Fold: 6  Epoch: 107  Training loss = 2.7899  Validation loss = 3.3075  \n",
      "\n",
      "Fold: 6  Epoch: 108  Training loss = 2.7898  Validation loss = 3.3072  \n",
      "\n",
      "Fold: 6  Epoch: 109  Training loss = 2.7896  Validation loss = 3.3070  \n",
      "\n",
      "Fold: 6  Epoch: 110  Training loss = 2.7895  Validation loss = 3.3067  \n",
      "\n",
      "Fold: 6  Epoch: 111  Training loss = 2.7893  Validation loss = 3.3065  \n",
      "\n",
      "Fold: 6  Epoch: 112  Training loss = 2.7892  Validation loss = 3.3063  \n",
      "\n",
      "Fold: 6  Epoch: 113  Training loss = 2.7891  Validation loss = 3.3061  \n",
      "\n",
      "Fold: 6  Epoch: 114  Training loss = 2.7889  Validation loss = 3.3058  \n",
      "\n",
      "Fold: 6  Epoch: 115  Training loss = 2.7888  Validation loss = 3.3056  \n",
      "\n",
      "Fold: 6  Epoch: 116  Training loss = 2.7886  Validation loss = 3.3054  \n",
      "\n",
      "Fold: 6  Epoch: 117  Training loss = 2.7885  Validation loss = 3.3051  \n",
      "\n",
      "Fold: 6  Epoch: 118  Training loss = 2.7884  Validation loss = 3.3049  \n",
      "\n",
      "Fold: 6  Epoch: 119  Training loss = 2.7882  Validation loss = 3.3047  \n",
      "\n",
      "Fold: 6  Epoch: 120  Training loss = 2.7880  Validation loss = 3.3044  \n",
      "\n",
      "Fold: 6  Epoch: 121  Training loss = 2.7879  Validation loss = 3.3042  \n",
      "\n",
      "Fold: 6  Epoch: 122  Training loss = 2.7878  Validation loss = 3.3039  \n",
      "\n",
      "Fold: 6  Epoch: 123  Training loss = 2.7876  Validation loss = 3.3036  \n",
      "\n",
      "Fold: 6  Epoch: 124  Training loss = 2.7875  Validation loss = 3.3034  \n",
      "\n",
      "Fold: 6  Epoch: 125  Training loss = 2.7873  Validation loss = 3.3032  \n",
      "\n",
      "Fold: 6  Epoch: 126  Training loss = 2.7871  Validation loss = 3.3029  \n",
      "\n",
      "Fold: 6  Epoch: 127  Training loss = 2.7870  Validation loss = 3.3026  \n",
      "\n",
      "Fold: 6  Epoch: 128  Training loss = 2.7868  Validation loss = 3.3024  \n",
      "\n",
      "Fold: 6  Epoch: 129  Training loss = 2.7867  Validation loss = 3.3021  \n",
      "\n",
      "Fold: 6  Epoch: 130  Training loss = 2.7865  Validation loss = 3.3019  \n",
      "\n",
      "Fold: 6  Epoch: 131  Training loss = 2.7863  Validation loss = 3.3015  \n",
      "\n",
      "Fold: 6  Epoch: 132  Training loss = 2.7862  Validation loss = 3.3013  \n",
      "\n",
      "Fold: 6  Epoch: 133  Training loss = 2.7860  Validation loss = 3.3010  \n",
      "\n",
      "Fold: 6  Epoch: 134  Training loss = 2.7859  Validation loss = 3.3007  \n",
      "\n",
      "Fold: 6  Epoch: 135  Training loss = 2.7857  Validation loss = 3.3004  \n",
      "\n",
      "Fold: 6  Epoch: 136  Training loss = 2.7855  Validation loss = 3.3002  \n",
      "\n",
      "Fold: 6  Epoch: 137  Training loss = 2.7854  Validation loss = 3.3000  \n",
      "\n",
      "Fold: 6  Epoch: 138  Training loss = 2.7853  Validation loss = 3.2997  \n",
      "\n",
      "Fold: 6  Epoch: 139  Training loss = 2.7851  Validation loss = 3.2995  \n",
      "\n",
      "Fold: 6  Epoch: 140  Training loss = 2.7849  Validation loss = 3.2992  \n",
      "\n",
      "Fold: 6  Epoch: 141  Training loss = 2.7848  Validation loss = 3.2990  \n",
      "\n",
      "Fold: 6  Epoch: 142  Training loss = 2.7847  Validation loss = 3.2988  \n",
      "\n",
      "Fold: 6  Epoch: 143  Training loss = 2.7846  Validation loss = 3.2986  \n",
      "\n",
      "Fold: 6  Epoch: 144  Training loss = 2.7844  Validation loss = 3.2983  \n",
      "\n",
      "Fold: 6  Epoch: 145  Training loss = 2.7842  Validation loss = 3.2981  \n",
      "\n",
      "Fold: 6  Epoch: 146  Training loss = 2.7841  Validation loss = 3.2978  \n",
      "\n",
      "Fold: 6  Epoch: 147  Training loss = 2.7839  Validation loss = 3.2976  \n",
      "\n",
      "Fold: 6  Epoch: 148  Training loss = 2.7838  Validation loss = 3.2974  \n",
      "\n",
      "Fold: 6  Epoch: 149  Training loss = 2.7837  Validation loss = 3.2972  \n",
      "\n",
      "Fold: 6  Epoch: 150  Training loss = 2.7835  Validation loss = 3.2969  \n",
      "\n",
      "Fold: 6  Epoch: 151  Training loss = 2.7834  Validation loss = 3.2967  \n",
      "\n",
      "Fold: 6  Epoch: 152  Training loss = 2.7832  Validation loss = 3.2964  \n",
      "\n",
      "Fold: 6  Epoch: 153  Training loss = 2.7831  Validation loss = 3.2961  \n",
      "\n",
      "Fold: 6  Epoch: 154  Training loss = 2.7829  Validation loss = 3.2958  \n",
      "\n",
      "Fold: 6  Epoch: 155  Training loss = 2.7827  Validation loss = 3.2956  \n",
      "\n",
      "Fold: 6  Epoch: 156  Training loss = 2.7826  Validation loss = 3.2953  \n",
      "\n",
      "Fold: 6  Epoch: 157  Training loss = 2.7824  Validation loss = 3.2951  \n",
      "\n",
      "Fold: 6  Epoch: 158  Training loss = 2.7823  Validation loss = 3.2948  \n",
      "\n",
      "Fold: 6  Epoch: 159  Training loss = 2.7821  Validation loss = 3.2945  \n",
      "\n",
      "Fold: 6  Epoch: 160  Training loss = 2.7820  Validation loss = 3.2943  \n",
      "\n",
      "Fold: 6  Epoch: 161  Training loss = 2.7818  Validation loss = 3.2941  \n",
      "\n",
      "Fold: 6  Epoch: 162  Training loss = 2.7817  Validation loss = 3.2938  \n",
      "\n",
      "Fold: 6  Epoch: 163  Training loss = 2.7815  Validation loss = 3.2935  \n",
      "\n",
      "Fold: 6  Epoch: 164  Training loss = 2.7814  Validation loss = 3.2933  \n",
      "\n",
      "Fold: 6  Epoch: 165  Training loss = 2.7812  Validation loss = 3.2930  \n",
      "\n",
      "Fold: 6  Epoch: 166  Training loss = 2.7810  Validation loss = 3.2927  \n",
      "\n",
      "Fold: 6  Epoch: 167  Training loss = 2.7809  Validation loss = 3.2924  \n",
      "\n",
      "Fold: 6  Epoch: 168  Training loss = 2.7807  Validation loss = 3.2922  \n",
      "\n",
      "Fold: 6  Epoch: 169  Training loss = 2.7806  Validation loss = 3.2920  \n",
      "\n",
      "Fold: 6  Epoch: 170  Training loss = 2.7804  Validation loss = 3.2917  \n",
      "\n",
      "Fold: 6  Epoch: 171  Training loss = 2.7803  Validation loss = 3.2914  \n",
      "\n",
      "Fold: 6  Epoch: 172  Training loss = 2.7801  Validation loss = 3.2912  \n",
      "\n",
      "Fold: 6  Epoch: 173  Training loss = 2.7800  Validation loss = 3.2910  \n",
      "\n",
      "Fold: 6  Epoch: 174  Training loss = 2.7798  Validation loss = 3.2907  \n",
      "\n",
      "Fold: 6  Epoch: 175  Training loss = 2.7797  Validation loss = 3.2905  \n",
      "\n",
      "Fold: 6  Epoch: 176  Training loss = 2.7796  Validation loss = 3.2903  \n",
      "\n",
      "Fold: 6  Epoch: 177  Training loss = 2.7794  Validation loss = 3.2900  \n",
      "\n",
      "Fold: 6  Epoch: 178  Training loss = 2.7792  Validation loss = 3.2897  \n",
      "\n",
      "Fold: 6  Epoch: 179  Training loss = 2.7791  Validation loss = 3.2894  \n",
      "\n",
      "Fold: 6  Epoch: 180  Training loss = 2.7789  Validation loss = 3.2892  \n",
      "\n",
      "Fold: 6  Epoch: 181  Training loss = 2.7787  Validation loss = 3.2889  \n",
      "\n",
      "Fold: 6  Epoch: 182  Training loss = 2.7786  Validation loss = 3.2886  \n",
      "\n",
      "Fold: 6  Epoch: 183  Training loss = 2.7784  Validation loss = 3.2884  \n",
      "\n",
      "Fold: 6  Epoch: 184  Training loss = 2.7783  Validation loss = 3.2881  \n",
      "\n",
      "Fold: 6  Epoch: 185  Training loss = 2.7781  Validation loss = 3.2879  \n",
      "\n",
      "Fold: 6  Epoch: 186  Training loss = 2.7780  Validation loss = 3.2876  \n",
      "\n",
      "Fold: 6  Epoch: 187  Training loss = 2.7778  Validation loss = 3.2874  \n",
      "\n",
      "Fold: 6  Epoch: 188  Training loss = 2.7777  Validation loss = 3.2871  \n",
      "\n",
      "Fold: 6  Epoch: 189  Training loss = 2.7775  Validation loss = 3.2869  \n",
      "\n",
      "Fold: 6  Epoch: 190  Training loss = 2.7774  Validation loss = 3.2867  \n",
      "\n",
      "Fold: 6  Epoch: 191  Training loss = 2.7772  Validation loss = 3.2864  \n",
      "\n",
      "Fold: 6  Epoch: 192  Training loss = 2.7771  Validation loss = 3.2862  \n",
      "\n",
      "Fold: 6  Epoch: 193  Training loss = 2.7769  Validation loss = 3.2859  \n",
      "\n",
      "Fold: 6  Epoch: 194  Training loss = 2.7768  Validation loss = 3.2856  \n",
      "\n",
      "Fold: 6  Epoch: 195  Training loss = 2.7766  Validation loss = 3.2854  \n",
      "\n",
      "Fold: 6  Epoch: 196  Training loss = 2.7765  Validation loss = 3.2852  \n",
      "\n",
      "Fold: 6  Epoch: 197  Training loss = 2.7764  Validation loss = 3.2849  \n",
      "\n",
      "Fold: 6  Epoch: 198  Training loss = 2.7762  Validation loss = 3.2846  \n",
      "\n",
      "Fold: 6  Epoch: 199  Training loss = 2.7760  Validation loss = 3.2844  \n",
      "\n",
      "Fold: 6  Epoch: 200  Training loss = 2.7759  Validation loss = 3.2840  \n",
      "\n",
      "Fold: 6  Epoch: 201  Training loss = 2.7757  Validation loss = 3.2837  \n",
      "\n",
      "Fold: 6  Epoch: 202  Training loss = 2.7755  Validation loss = 3.2835  \n",
      "\n",
      "Fold: 6  Epoch: 203  Training loss = 2.7754  Validation loss = 3.2833  \n",
      "\n",
      "Fold: 6  Epoch: 204  Training loss = 2.7753  Validation loss = 3.2831  \n",
      "\n",
      "Fold: 6  Epoch: 205  Training loss = 2.7751  Validation loss = 3.2828  \n",
      "\n",
      "Fold: 6  Epoch: 206  Training loss = 2.7750  Validation loss = 3.2826  \n",
      "\n",
      "Fold: 6  Epoch: 207  Training loss = 2.7748  Validation loss = 3.2823  \n",
      "\n",
      "Fold: 6  Epoch: 208  Training loss = 2.7747  Validation loss = 3.2821  \n",
      "\n",
      "Fold: 6  Epoch: 209  Training loss = 2.7745  Validation loss = 3.2819  \n",
      "\n",
      "Fold: 6  Epoch: 210  Training loss = 2.7744  Validation loss = 3.2816  \n",
      "\n",
      "Fold: 6  Epoch: 211  Training loss = 2.7742  Validation loss = 3.2814  \n",
      "\n",
      "Fold: 6  Epoch: 212  Training loss = 2.7741  Validation loss = 3.2811  \n",
      "\n",
      "Fold: 6  Epoch: 213  Training loss = 2.7739  Validation loss = 3.2808  \n",
      "\n",
      "Fold: 6  Epoch: 214  Training loss = 2.7738  Validation loss = 3.2806  \n",
      "\n",
      "Fold: 6  Epoch: 215  Training loss = 2.7736  Validation loss = 3.2802  \n",
      "\n",
      "Fold: 6  Epoch: 216  Training loss = 2.7735  Validation loss = 3.2800  \n",
      "\n",
      "Fold: 6  Epoch: 217  Training loss = 2.7733  Validation loss = 3.2798  \n",
      "\n",
      "Fold: 6  Epoch: 218  Training loss = 2.7732  Validation loss = 3.2795  \n",
      "\n",
      "Fold: 6  Epoch: 219  Training loss = 2.7730  Validation loss = 3.2793  \n",
      "\n",
      "Fold: 6  Epoch: 220  Training loss = 2.7729  Validation loss = 3.2791  \n",
      "\n",
      "Fold: 6  Epoch: 221  Training loss = 2.7728  Validation loss = 3.2789  \n",
      "\n",
      "Fold: 6  Epoch: 222  Training loss = 2.7726  Validation loss = 3.2786  \n",
      "\n",
      "Fold: 6  Epoch: 223  Training loss = 2.7725  Validation loss = 3.2783  \n",
      "\n",
      "Fold: 6  Epoch: 224  Training loss = 2.7723  Validation loss = 3.2780  \n",
      "\n",
      "Fold: 6  Epoch: 225  Training loss = 2.7721  Validation loss = 3.2777  \n",
      "\n",
      "Fold: 6  Epoch: 226  Training loss = 2.7720  Validation loss = 3.2775  \n",
      "\n",
      "Fold: 6  Epoch: 227  Training loss = 2.7718  Validation loss = 3.2772  \n",
      "\n",
      "Fold: 6  Epoch: 228  Training loss = 2.7717  Validation loss = 3.2770  \n",
      "\n",
      "Fold: 6  Epoch: 229  Training loss = 2.7715  Validation loss = 3.2767  \n",
      "\n",
      "Fold: 6  Epoch: 230  Training loss = 2.7713  Validation loss = 3.2764  \n",
      "\n",
      "Fold: 6  Epoch: 231  Training loss = 2.7712  Validation loss = 3.2762  \n",
      "\n",
      "Fold: 6  Epoch: 232  Training loss = 2.7711  Validation loss = 3.2759  \n",
      "\n",
      "Fold: 6  Epoch: 233  Training loss = 2.7709  Validation loss = 3.2756  \n",
      "\n",
      "Fold: 6  Epoch: 234  Training loss = 2.7707  Validation loss = 3.2754  \n",
      "\n",
      "Fold: 6  Epoch: 235  Training loss = 2.7706  Validation loss = 3.2751  \n",
      "\n",
      "Fold: 6  Epoch: 236  Training loss = 2.7704  Validation loss = 3.2748  \n",
      "\n",
      "Fold: 6  Epoch: 237  Training loss = 2.7702  Validation loss = 3.2744  \n",
      "\n",
      "Fold: 6  Epoch: 238  Training loss = 2.7701  Validation loss = 3.2742  \n",
      "\n",
      "Fold: 6  Epoch: 239  Training loss = 2.7699  Validation loss = 3.2739  \n",
      "\n",
      "Fold: 6  Epoch: 240  Training loss = 2.7697  Validation loss = 3.2736  \n",
      "\n",
      "Fold: 6  Epoch: 241  Training loss = 2.7696  Validation loss = 3.2733  \n",
      "\n",
      "Fold: 6  Epoch: 242  Training loss = 2.7694  Validation loss = 3.2731  \n",
      "\n",
      "Fold: 6  Epoch: 243  Training loss = 2.7693  Validation loss = 3.2728  \n",
      "\n",
      "Fold: 6  Epoch: 244  Training loss = 2.7691  Validation loss = 3.2726  \n",
      "\n",
      "Fold: 6  Epoch: 245  Training loss = 2.7690  Validation loss = 3.2725  \n",
      "\n",
      "Fold: 6  Epoch: 246  Training loss = 2.7689  Validation loss = 3.2723  \n",
      "\n",
      "Fold: 6  Epoch: 247  Training loss = 2.7688  Validation loss = 3.2720  \n",
      "\n",
      "Fold: 6  Epoch: 248  Training loss = 2.7686  Validation loss = 3.2718  \n",
      "\n",
      "Fold: 6  Epoch: 249  Training loss = 2.7685  Validation loss = 3.2715  \n",
      "\n",
      "Fold: 6  Epoch: 250  Training loss = 2.7683  Validation loss = 3.2712  \n",
      "\n",
      "Fold: 6  Epoch: 251  Training loss = 2.7682  Validation loss = 3.2710  \n",
      "\n",
      "Fold: 6  Epoch: 252  Training loss = 2.7680  Validation loss = 3.2708  \n",
      "\n",
      "Fold: 6  Epoch: 253  Training loss = 2.7679  Validation loss = 3.2705  \n",
      "\n",
      "Fold: 6  Epoch: 254  Training loss = 2.7677  Validation loss = 3.2702  \n",
      "\n",
      "Fold: 6  Epoch: 255  Training loss = 2.7676  Validation loss = 3.2700  \n",
      "\n",
      "Fold: 6  Epoch: 256  Training loss = 2.7674  Validation loss = 3.2697  \n",
      "\n",
      "Fold: 6  Epoch: 257  Training loss = 2.7672  Validation loss = 3.2694  \n",
      "\n",
      "Fold: 6  Epoch: 258  Training loss = 2.7671  Validation loss = 3.2692  \n",
      "\n",
      "Fold: 6  Epoch: 259  Training loss = 2.7670  Validation loss = 3.2690  \n",
      "\n",
      "Fold: 6  Epoch: 260  Training loss = 2.7668  Validation loss = 3.2687  \n",
      "\n",
      "Fold: 6  Epoch: 261  Training loss = 2.7666  Validation loss = 3.2684  \n",
      "\n",
      "Fold: 6  Epoch: 262  Training loss = 2.7664  Validation loss = 3.2681  \n",
      "\n",
      "Fold: 6  Epoch: 263  Training loss = 2.7663  Validation loss = 3.2678  \n",
      "\n",
      "Fold: 6  Epoch: 264  Training loss = 2.7662  Validation loss = 3.2676  \n",
      "\n",
      "Fold: 6  Epoch: 265  Training loss = 2.7660  Validation loss = 3.2673  \n",
      "\n",
      "Fold: 6  Epoch: 266  Training loss = 2.7659  Validation loss = 3.2671  \n",
      "\n",
      "Fold: 6  Epoch: 267  Training loss = 2.7658  Validation loss = 3.2669  \n",
      "\n",
      "Fold: 6  Epoch: 268  Training loss = 2.7656  Validation loss = 3.2667  \n",
      "\n",
      "Fold: 6  Epoch: 269  Training loss = 2.7655  Validation loss = 3.2664  \n",
      "\n",
      "Fold: 6  Epoch: 270  Training loss = 2.7653  Validation loss = 3.2662  \n",
      "\n",
      "Fold: 6  Epoch: 271  Training loss = 2.7652  Validation loss = 3.2660  \n",
      "\n",
      "Fold: 6  Epoch: 272  Training loss = 2.7651  Validation loss = 3.2658  \n",
      "\n",
      "Fold: 6  Epoch: 273  Training loss = 2.7649  Validation loss = 3.2656  \n",
      "\n",
      "Fold: 6  Epoch: 274  Training loss = 2.7648  Validation loss = 3.2653  \n",
      "\n",
      "Fold: 6  Epoch: 275  Training loss = 2.7647  Validation loss = 3.2651  \n",
      "\n",
      "Fold: 6  Epoch: 276  Training loss = 2.7645  Validation loss = 3.2648  \n",
      "\n",
      "Fold: 6  Epoch: 277  Training loss = 2.7643  Validation loss = 3.2644  \n",
      "\n",
      "Fold: 6  Epoch: 278  Training loss = 2.7642  Validation loss = 3.2642  \n",
      "\n",
      "Fold: 6  Epoch: 279  Training loss = 2.7640  Validation loss = 3.2640  \n",
      "\n",
      "Fold: 6  Epoch: 280  Training loss = 2.7639  Validation loss = 3.2637  \n",
      "\n",
      "Fold: 6  Epoch: 281  Training loss = 2.7637  Validation loss = 3.2634  \n",
      "\n",
      "Fold: 6  Epoch: 282  Training loss = 2.7636  Validation loss = 3.2632  \n",
      "\n",
      "Fold: 6  Epoch: 283  Training loss = 2.7634  Validation loss = 3.2629  \n",
      "\n",
      "Fold: 6  Epoch: 284  Training loss = 2.7633  Validation loss = 3.2627  \n",
      "\n",
      "Fold: 6  Epoch: 285  Training loss = 2.7631  Validation loss = 3.2624  \n",
      "\n",
      "Fold: 6  Epoch: 286  Training loss = 2.7630  Validation loss = 3.2622  \n",
      "\n",
      "Fold: 6  Epoch: 287  Training loss = 2.7628  Validation loss = 3.2619  \n",
      "\n",
      "Fold: 6  Epoch: 288  Training loss = 2.7627  Validation loss = 3.2617  \n",
      "\n",
      "Fold: 6  Epoch: 289  Training loss = 2.7625  Validation loss = 3.2614  \n",
      "\n",
      "Fold: 6  Epoch: 290  Training loss = 2.7624  Validation loss = 3.2612  \n",
      "\n",
      "Fold: 6  Epoch: 291  Training loss = 2.7622  Validation loss = 3.2609  \n",
      "\n",
      "Fold: 6  Epoch: 292  Training loss = 2.7620  Validation loss = 3.2606  \n",
      "\n",
      "Fold: 6  Epoch: 293  Training loss = 2.7619  Validation loss = 3.2604  \n",
      "\n",
      "Fold: 6  Epoch: 294  Training loss = 2.7618  Validation loss = 3.2602  \n",
      "\n",
      "Fold: 6  Epoch: 295  Training loss = 2.7617  Validation loss = 3.2600  \n",
      "\n",
      "Fold: 6  Epoch: 296  Training loss = 2.7615  Validation loss = 3.2597  \n",
      "\n",
      "Fold: 6  Epoch: 297  Training loss = 2.7613  Validation loss = 3.2595  \n",
      "\n",
      "Fold: 6  Epoch: 298  Training loss = 2.7612  Validation loss = 3.2592  \n",
      "\n",
      "Fold: 6  Epoch: 299  Training loss = 2.7611  Validation loss = 3.2590  \n",
      "\n",
      "Fold: 6  Epoch: 300  Training loss = 2.7610  Validation loss = 3.2588  \n",
      "\n",
      "Fold: 6  Epoch: 301  Training loss = 2.7608  Validation loss = 3.2585  \n",
      "\n",
      "Fold: 6  Epoch: 302  Training loss = 2.7606  Validation loss = 3.2583  \n",
      "\n",
      "Fold: 6  Epoch: 303  Training loss = 2.7605  Validation loss = 3.2580  \n",
      "\n",
      "Fold: 6  Epoch: 304  Training loss = 2.7604  Validation loss = 3.2578  \n",
      "\n",
      "Fold: 6  Epoch: 305  Training loss = 2.7602  Validation loss = 3.2576  \n",
      "\n",
      "Fold: 6  Epoch: 306  Training loss = 2.7601  Validation loss = 3.2574  \n",
      "\n",
      "Fold: 6  Epoch: 307  Training loss = 2.7600  Validation loss = 3.2571  \n",
      "\n",
      "Fold: 6  Epoch: 308  Training loss = 2.7598  Validation loss = 3.2569  \n",
      "\n",
      "Fold: 6  Epoch: 309  Training loss = 2.7597  Validation loss = 3.2567  \n",
      "\n",
      "Fold: 6  Epoch: 310  Training loss = 2.7595  Validation loss = 3.2565  \n",
      "\n",
      "Fold: 6  Epoch: 311  Training loss = 2.7594  Validation loss = 3.2562  \n",
      "\n",
      "Fold: 6  Epoch: 312  Training loss = 2.7592  Validation loss = 3.2558  \n",
      "\n",
      "Fold: 6  Epoch: 313  Training loss = 2.7591  Validation loss = 3.2556  \n",
      "\n",
      "Fold: 6  Epoch: 314  Training loss = 2.7589  Validation loss = 3.2554  \n",
      "\n",
      "Fold: 6  Epoch: 315  Training loss = 2.7588  Validation loss = 3.2551  \n",
      "\n",
      "Fold: 6  Epoch: 316  Training loss = 2.7586  Validation loss = 3.2548  \n",
      "\n",
      "Fold: 6  Epoch: 317  Training loss = 2.7584  Validation loss = 3.2545  \n",
      "\n",
      "Fold: 6  Epoch: 318  Training loss = 2.7583  Validation loss = 3.2544  \n",
      "\n",
      "Fold: 6  Epoch: 319  Training loss = 2.7581  Validation loss = 3.2540  \n",
      "\n",
      "Fold: 6  Epoch: 320  Training loss = 2.7580  Validation loss = 3.2538  \n",
      "\n",
      "Fold: 6  Epoch: 321  Training loss = 2.7579  Validation loss = 3.2535  \n",
      "\n",
      "Fold: 6  Epoch: 322  Training loss = 2.7577  Validation loss = 3.2533  \n",
      "\n",
      "Fold: 6  Epoch: 323  Training loss = 2.7576  Validation loss = 3.2530  \n",
      "\n",
      "Fold: 6  Epoch: 324  Training loss = 2.7574  Validation loss = 3.2527  \n",
      "\n",
      "Fold: 6  Epoch: 325  Training loss = 2.7572  Validation loss = 3.2524  \n",
      "\n",
      "Fold: 6  Epoch: 326  Training loss = 2.7571  Validation loss = 3.2521  \n",
      "\n",
      "Fold: 6  Epoch: 327  Training loss = 2.7569  Validation loss = 3.2519  \n",
      "\n",
      "Fold: 6  Epoch: 328  Training loss = 2.7568  Validation loss = 3.2517  \n",
      "\n",
      "Fold: 6  Epoch: 329  Training loss = 2.7566  Validation loss = 3.2514  \n",
      "\n",
      "Fold: 6  Epoch: 330  Training loss = 2.7565  Validation loss = 3.2511  \n",
      "\n",
      "Fold: 6  Epoch: 331  Training loss = 2.7563  Validation loss = 3.2509  \n",
      "\n",
      "Fold: 6  Epoch: 332  Training loss = 2.7562  Validation loss = 3.2506  \n",
      "\n",
      "Fold: 6  Epoch: 333  Training loss = 2.7560  Validation loss = 3.2504  \n",
      "\n",
      "Fold: 6  Epoch: 334  Training loss = 2.7559  Validation loss = 3.2501  \n",
      "\n",
      "Fold: 6  Epoch: 335  Training loss = 2.7557  Validation loss = 3.2499  \n",
      "\n",
      "Fold: 6  Epoch: 336  Training loss = 2.7555  Validation loss = 3.2496  \n",
      "\n",
      "Fold: 6  Epoch: 337  Training loss = 2.7554  Validation loss = 3.2493  \n",
      "\n",
      "Fold: 6  Epoch: 338  Training loss = 2.7552  Validation loss = 3.2490  \n",
      "\n",
      "Fold: 6  Epoch: 339  Training loss = 2.7551  Validation loss = 3.2489  \n",
      "\n",
      "Fold: 6  Epoch: 340  Training loss = 2.7550  Validation loss = 3.2486  \n",
      "\n",
      "Fold: 6  Epoch: 341  Training loss = 2.7548  Validation loss = 3.2483  \n",
      "\n",
      "Fold: 6  Epoch: 342  Training loss = 2.7546  Validation loss = 3.2481  \n",
      "\n",
      "Fold: 6  Epoch: 343  Training loss = 2.7545  Validation loss = 3.2478  \n",
      "\n",
      "Fold: 6  Epoch: 344  Training loss = 2.7544  Validation loss = 3.2476  \n",
      "\n",
      "Fold: 6  Epoch: 345  Training loss = 2.7542  Validation loss = 3.2473  \n",
      "\n",
      "Fold: 6  Epoch: 346  Training loss = 2.7541  Validation loss = 3.2471  \n",
      "\n",
      "Fold: 6  Epoch: 347  Training loss = 2.7539  Validation loss = 3.2468  \n",
      "\n",
      "Fold: 6  Epoch: 348  Training loss = 2.7538  Validation loss = 3.2466  \n",
      "\n",
      "Fold: 6  Epoch: 349  Training loss = 2.7537  Validation loss = 3.2464  \n",
      "\n",
      "Fold: 6  Epoch: 350  Training loss = 2.7535  Validation loss = 3.2462  \n",
      "\n",
      "Fold: 6  Epoch: 351  Training loss = 2.7534  Validation loss = 3.2459  \n",
      "\n",
      "Fold: 6  Epoch: 352  Training loss = 2.7532  Validation loss = 3.2456  \n",
      "\n",
      "Fold: 6  Epoch: 353  Training loss = 2.7531  Validation loss = 3.2454  \n",
      "\n",
      "Fold: 6  Epoch: 354  Training loss = 2.7529  Validation loss = 3.2451  \n",
      "\n",
      "Fold: 6  Epoch: 355  Training loss = 2.7528  Validation loss = 3.2448  \n",
      "\n",
      "Fold: 6  Epoch: 356  Training loss = 2.7526  Validation loss = 3.2446  \n",
      "\n",
      "Fold: 6  Epoch: 357  Training loss = 2.7525  Validation loss = 3.2444  \n",
      "\n",
      "Fold: 6  Epoch: 358  Training loss = 2.7524  Validation loss = 3.2442  \n",
      "\n",
      "Fold: 6  Epoch: 359  Training loss = 2.7523  Validation loss = 3.2440  \n",
      "\n",
      "Fold: 6  Epoch: 360  Training loss = 2.7521  Validation loss = 3.2437  \n",
      "\n",
      "Fold: 6  Epoch: 361  Training loss = 2.7520  Validation loss = 3.2435  \n",
      "\n",
      "Fold: 6  Epoch: 362  Training loss = 2.7518  Validation loss = 3.2433  \n",
      "\n",
      "Fold: 6  Epoch: 363  Training loss = 2.7517  Validation loss = 3.2431  \n",
      "\n",
      "Fold: 6  Epoch: 364  Training loss = 2.7515  Validation loss = 3.2428  \n",
      "\n",
      "Fold: 6  Epoch: 365  Training loss = 2.7514  Validation loss = 3.2426  \n",
      "\n",
      "Fold: 6  Epoch: 366  Training loss = 2.7512  Validation loss = 3.2422  \n",
      "\n",
      "Fold: 6  Epoch: 367  Training loss = 2.7510  Validation loss = 3.2419  \n",
      "\n",
      "Fold: 6  Epoch: 368  Training loss = 2.7509  Validation loss = 3.2417  \n",
      "\n",
      "Fold: 6  Epoch: 369  Training loss = 2.7508  Validation loss = 3.2414  \n",
      "\n",
      "Fold: 6  Epoch: 370  Training loss = 2.7506  Validation loss = 3.2412  \n",
      "\n",
      "Fold: 6  Epoch: 371  Training loss = 2.7505  Validation loss = 3.2410  \n",
      "\n",
      "Fold: 6  Epoch: 372  Training loss = 2.7503  Validation loss = 3.2407  \n",
      "\n",
      "Fold: 6  Epoch: 373  Training loss = 2.7502  Validation loss = 3.2405  \n",
      "\n",
      "Fold: 6  Epoch: 374  Training loss = 2.7501  Validation loss = 3.2402  \n",
      "\n",
      "Fold: 6  Epoch: 375  Training loss = 2.7499  Validation loss = 3.2399  \n",
      "\n",
      "Fold: 6  Epoch: 376  Training loss = 2.7497  Validation loss = 3.2397  \n",
      "\n",
      "Fold: 6  Epoch: 377  Training loss = 2.7496  Validation loss = 3.2394  \n",
      "\n",
      "Fold: 6  Epoch: 378  Training loss = 2.7495  Validation loss = 3.2392  \n",
      "\n",
      "Fold: 6  Epoch: 379  Training loss = 2.7493  Validation loss = 3.2389  \n",
      "\n",
      "Fold: 6  Epoch: 380  Training loss = 2.7492  Validation loss = 3.2387  \n",
      "\n",
      "Fold: 6  Epoch: 381  Training loss = 2.7490  Validation loss = 3.2384  \n",
      "\n",
      "Fold: 6  Epoch: 382  Training loss = 2.7488  Validation loss = 3.2381  \n",
      "\n",
      "Fold: 6  Epoch: 383  Training loss = 2.7487  Validation loss = 3.2378  \n",
      "\n",
      "Fold: 6  Epoch: 384  Training loss = 2.7485  Validation loss = 3.2375  \n",
      "\n",
      "Fold: 6  Epoch: 385  Training loss = 2.7484  Validation loss = 3.2374  \n",
      "\n",
      "Fold: 6  Epoch: 386  Training loss = 2.7482  Validation loss = 3.2371  \n",
      "\n",
      "Fold: 6  Epoch: 387  Training loss = 2.7481  Validation loss = 3.2368  \n",
      "\n",
      "Fold: 6  Epoch: 388  Training loss = 2.7479  Validation loss = 3.2365  \n",
      "\n",
      "Fold: 6  Epoch: 389  Training loss = 2.7478  Validation loss = 3.2363  \n",
      "\n",
      "Fold: 6  Epoch: 390  Training loss = 2.7477  Validation loss = 3.2361  \n",
      "\n",
      "Fold: 6  Epoch: 391  Training loss = 2.7475  Validation loss = 3.2359  \n",
      "\n",
      "Fold: 6  Epoch: 392  Training loss = 2.7474  Validation loss = 3.2356  \n",
      "\n",
      "Fold: 6  Epoch: 393  Training loss = 2.7472  Validation loss = 3.2354  \n",
      "\n",
      "Fold: 6  Epoch: 394  Training loss = 2.7471  Validation loss = 3.2351  \n",
      "\n",
      "Fold: 6  Epoch: 395  Training loss = 2.7469  Validation loss = 3.2349  \n",
      "\n",
      "Fold: 6  Epoch: 396  Training loss = 2.7468  Validation loss = 3.2346  \n",
      "\n",
      "Fold: 6  Epoch: 397  Training loss = 2.7466  Validation loss = 3.2344  \n",
      "\n",
      "Fold: 6  Epoch: 398  Training loss = 2.7465  Validation loss = 3.2341  \n",
      "\n",
      "Fold: 6  Epoch: 399  Training loss = 2.7463  Validation loss = 3.2338  \n",
      "\n",
      "Fold: 6  Epoch: 400  Training loss = 2.7462  Validation loss = 3.2336  \n",
      "\n",
      "Fold: 6  Epoch: 401  Training loss = 2.7461  Validation loss = 3.2333  \n",
      "\n",
      "Fold: 6  Epoch: 402  Training loss = 2.7459  Validation loss = 3.2331  \n",
      "\n",
      "Fold: 6  Epoch: 403  Training loss = 2.7458  Validation loss = 3.2328  \n",
      "\n",
      "Fold: 6  Epoch: 404  Training loss = 2.7456  Validation loss = 3.2325  \n",
      "\n",
      "Fold: 6  Epoch: 405  Training loss = 2.7454  Validation loss = 3.2323  \n",
      "\n",
      "Fold: 6  Epoch: 406  Training loss = 2.7453  Validation loss = 3.2320  \n",
      "\n",
      "Fold: 6  Epoch: 407  Training loss = 2.7452  Validation loss = 3.2318  \n",
      "\n",
      "Fold: 6  Epoch: 408  Training loss = 2.7450  Validation loss = 3.2316  \n",
      "\n",
      "Fold: 6  Epoch: 409  Training loss = 2.7449  Validation loss = 3.2313  \n",
      "\n",
      "Fold: 6  Epoch: 410  Training loss = 2.7447  Validation loss = 3.2310  \n",
      "\n",
      "Fold: 6  Epoch: 411  Training loss = 2.7446  Validation loss = 3.2308  \n",
      "\n",
      "Fold: 6  Epoch: 412  Training loss = 2.7444  Validation loss = 3.2305  \n",
      "\n",
      "Fold: 6  Epoch: 413  Training loss = 2.7443  Validation loss = 3.2302  \n",
      "\n",
      "Fold: 6  Epoch: 414  Training loss = 2.7441  Validation loss = 3.2300  \n",
      "\n",
      "Fold: 6  Epoch: 415  Training loss = 2.7440  Validation loss = 3.2298  \n",
      "\n",
      "Fold: 6  Epoch: 416  Training loss = 2.7438  Validation loss = 3.2294  \n",
      "\n",
      "Fold: 6  Epoch: 417  Training loss = 2.7437  Validation loss = 3.2292  \n",
      "\n",
      "Fold: 6  Epoch: 418  Training loss = 2.7435  Validation loss = 3.2289  \n",
      "\n",
      "Fold: 6  Epoch: 419  Training loss = 2.7434  Validation loss = 3.2286  \n",
      "\n",
      "Fold: 6  Epoch: 420  Training loss = 2.7432  Validation loss = 3.2284  \n",
      "\n",
      "Fold: 6  Epoch: 421  Training loss = 2.7431  Validation loss = 3.2282  \n",
      "\n",
      "Fold: 6  Epoch: 422  Training loss = 2.7429  Validation loss = 3.2279  \n",
      "\n",
      "Fold: 6  Epoch: 423  Training loss = 2.7428  Validation loss = 3.2276  \n",
      "\n",
      "Fold: 6  Epoch: 424  Training loss = 2.7426  Validation loss = 3.2273  \n",
      "\n",
      "Fold: 6  Epoch: 425  Training loss = 2.7425  Validation loss = 3.2271  \n",
      "\n",
      "Fold: 6  Epoch: 426  Training loss = 2.7423  Validation loss = 3.2268  \n",
      "\n",
      "Fold: 6  Epoch: 427  Training loss = 2.7422  Validation loss = 3.2265  \n",
      "\n",
      "Fold: 6  Epoch: 428  Training loss = 2.7420  Validation loss = 3.2262  \n",
      "\n",
      "Fold: 6  Epoch: 429  Training loss = 2.7418  Validation loss = 3.2259  \n",
      "\n",
      "Fold: 6  Epoch: 430  Training loss = 2.7417  Validation loss = 3.2256  \n",
      "\n",
      "Fold: 6  Epoch: 431  Training loss = 2.7415  Validation loss = 3.2254  \n",
      "\n",
      "Fold: 6  Epoch: 432  Training loss = 2.7414  Validation loss = 3.2251  \n",
      "\n",
      "Fold: 6  Epoch: 433  Training loss = 2.7412  Validation loss = 3.2248  \n",
      "\n",
      "Fold: 6  Epoch: 434  Training loss = 2.7410  Validation loss = 3.2246  \n",
      "\n",
      "Fold: 6  Epoch: 435  Training loss = 2.7409  Validation loss = 3.2244  \n",
      "\n",
      "Fold: 6  Epoch: 436  Training loss = 2.7408  Validation loss = 3.2241  \n",
      "\n",
      "Fold: 6  Epoch: 437  Training loss = 2.7406  Validation loss = 3.2238  \n",
      "\n",
      "Fold: 6  Epoch: 438  Training loss = 2.7405  Validation loss = 3.2236  \n",
      "\n",
      "Fold: 6  Epoch: 439  Training loss = 2.7403  Validation loss = 3.2233  \n",
      "\n",
      "Fold: 6  Epoch: 440  Training loss = 2.7402  Validation loss = 3.2231  \n",
      "\n",
      "Fold: 6  Epoch: 441  Training loss = 2.7400  Validation loss = 3.2228  \n",
      "\n",
      "Fold: 6  Epoch: 442  Training loss = 2.7399  Validation loss = 3.2226  \n",
      "\n",
      "Fold: 6  Epoch: 443  Training loss = 2.7398  Validation loss = 3.2224  \n",
      "\n",
      "Fold: 6  Epoch: 444  Training loss = 2.7396  Validation loss = 3.2221  \n",
      "\n",
      "Fold: 6  Epoch: 445  Training loss = 2.7395  Validation loss = 3.2219  \n",
      "\n",
      "Fold: 6  Epoch: 446  Training loss = 2.7394  Validation loss = 3.2217  \n",
      "\n",
      "Fold: 6  Epoch: 447  Training loss = 2.7392  Validation loss = 3.2215  \n",
      "\n",
      "Fold: 6  Epoch: 448  Training loss = 2.7391  Validation loss = 3.2213  \n",
      "\n",
      "Fold: 6  Epoch: 449  Training loss = 2.7390  Validation loss = 3.2211  \n",
      "\n",
      "Fold: 6  Epoch: 450  Training loss = 2.7388  Validation loss = 3.2208  \n",
      "\n",
      "Fold: 6  Epoch: 451  Training loss = 2.7387  Validation loss = 3.2205  \n",
      "\n",
      "Fold: 6  Epoch: 452  Training loss = 2.7385  Validation loss = 3.2202  \n",
      "\n",
      "Fold: 6  Epoch: 453  Training loss = 2.7384  Validation loss = 3.2199  \n",
      "\n",
      "Fold: 6  Epoch: 454  Training loss = 2.7382  Validation loss = 3.2197  \n",
      "\n",
      "Fold: 6  Epoch: 455  Training loss = 2.7380  Validation loss = 3.2194  \n",
      "\n",
      "Fold: 6  Epoch: 456  Training loss = 2.7379  Validation loss = 3.2191  \n",
      "\n",
      "Fold: 6  Epoch: 457  Training loss = 2.7377  Validation loss = 3.2189  \n",
      "\n",
      "Fold: 6  Epoch: 458  Training loss = 2.7376  Validation loss = 3.2186  \n",
      "\n",
      "Fold: 6  Epoch: 459  Training loss = 2.7375  Validation loss = 3.2184  \n",
      "\n",
      "Fold: 6  Epoch: 460  Training loss = 2.7373  Validation loss = 3.2182  \n",
      "\n",
      "Fold: 6  Epoch: 461  Training loss = 2.7372  Validation loss = 3.2180  \n",
      "\n",
      "Fold: 6  Epoch: 462  Training loss = 2.7371  Validation loss = 3.2177  \n",
      "\n",
      "Fold: 6  Epoch: 463  Training loss = 2.7369  Validation loss = 3.2174  \n",
      "\n",
      "Fold: 6  Epoch: 464  Training loss = 2.7367  Validation loss = 3.2171  \n",
      "\n",
      "Fold: 6  Epoch: 465  Training loss = 2.7366  Validation loss = 3.2168  \n",
      "\n",
      "Fold: 6  Epoch: 466  Training loss = 2.7364  Validation loss = 3.2165  \n",
      "\n",
      "Fold: 6  Epoch: 467  Training loss = 2.7362  Validation loss = 3.2162  \n",
      "\n",
      "Fold: 6  Epoch: 468  Training loss = 2.7361  Validation loss = 3.2160  \n",
      "\n",
      "Fold: 6  Epoch: 469  Training loss = 2.7360  Validation loss = 3.2159  \n",
      "\n",
      "Fold: 6  Epoch: 470  Training loss = 2.7359  Validation loss = 3.2156  \n",
      "\n",
      "Fold: 6  Epoch: 471  Training loss = 2.7357  Validation loss = 3.2154  \n",
      "\n",
      "Fold: 6  Epoch: 472  Training loss = 2.7356  Validation loss = 3.2151  \n",
      "\n",
      "Fold: 6  Epoch: 473  Training loss = 2.7354  Validation loss = 3.2149  \n",
      "\n",
      "Fold: 6  Epoch: 474  Training loss = 2.7353  Validation loss = 3.2146  \n",
      "\n",
      "Fold: 6  Epoch: 475  Training loss = 2.7351  Validation loss = 3.2143  \n",
      "\n",
      "Fold: 6  Epoch: 476  Training loss = 2.7349  Validation loss = 3.2139  \n",
      "\n",
      "Fold: 6  Epoch: 477  Training loss = 2.7348  Validation loss = 3.2137  \n",
      "\n",
      "Fold: 6  Epoch: 478  Training loss = 2.7347  Validation loss = 3.2135  \n",
      "\n",
      "Fold: 6  Epoch: 479  Training loss = 2.7345  Validation loss = 3.2133  \n",
      "\n",
      "Fold: 6  Epoch: 480  Training loss = 2.7344  Validation loss = 3.2130  \n",
      "\n",
      "Fold: 6  Epoch: 481  Training loss = 2.7342  Validation loss = 3.2128  \n",
      "\n",
      "Fold: 6  Epoch: 482  Training loss = 2.7341  Validation loss = 3.2126  \n",
      "\n",
      "Fold: 6  Epoch: 483  Training loss = 2.7339  Validation loss = 3.2123  \n",
      "\n",
      "Fold: 6  Epoch: 484  Training loss = 2.7338  Validation loss = 3.2121  \n",
      "\n",
      "Fold: 6  Epoch: 485  Training loss = 2.7337  Validation loss = 3.2119  \n",
      "\n",
      "Fold: 6  Epoch: 486  Training loss = 2.7335  Validation loss = 3.2116  \n",
      "\n",
      "Fold: 6  Epoch: 487  Training loss = 2.7334  Validation loss = 3.2114  \n",
      "\n",
      "Fold: 6  Epoch: 488  Training loss = 2.7332  Validation loss = 3.2111  \n",
      "\n",
      "Fold: 6  Epoch: 489  Training loss = 2.7331  Validation loss = 3.2108  \n",
      "\n",
      "Fold: 6  Epoch: 490  Training loss = 2.7329  Validation loss = 3.2106  \n",
      "\n",
      "Fold: 6  Epoch: 491  Training loss = 2.7328  Validation loss = 3.2104  \n",
      "\n",
      "Fold: 6  Epoch: 492  Training loss = 2.7326  Validation loss = 3.2101  \n",
      "\n",
      "Fold: 6  Epoch: 493  Training loss = 2.7325  Validation loss = 3.2099  \n",
      "\n",
      "Fold: 6  Epoch: 494  Training loss = 2.7323  Validation loss = 3.2096  \n",
      "\n",
      "Fold: 6  Epoch: 495  Training loss = 2.7322  Validation loss = 3.2093  \n",
      "\n",
      "Fold: 6  Epoch: 496  Training loss = 2.7321  Validation loss = 3.2091  \n",
      "\n",
      "Fold: 6  Epoch: 497  Training loss = 2.7319  Validation loss = 3.2089  \n",
      "\n",
      "Fold: 6  Epoch: 498  Training loss = 2.7318  Validation loss = 3.2086  \n",
      "\n",
      "Fold: 6  Epoch: 499  Training loss = 2.7316  Validation loss = 3.2083  \n",
      "\n",
      "Fold: 6  Epoch: 500  Training loss = 2.7315  Validation loss = 3.2080  \n",
      "\n",
      "Check model:  Fold: 6  Optimal epoch: 500  \n",
      "\n",
      "Fold: 7  Epoch: 1  Training loss = 2.8328  Validation loss = 3.0214  \n",
      "\n",
      "Fold: 7  Epoch: 2  Training loss = 2.8326  Validation loss = 3.0211  \n",
      "\n",
      "Fold: 7  Epoch: 3  Training loss = 2.8325  Validation loss = 3.0208  \n",
      "\n",
      "Fold: 7  Epoch: 4  Training loss = 2.8323  Validation loss = 3.0205  \n",
      "\n",
      "Fold: 7  Epoch: 5  Training loss = 2.8321  Validation loss = 3.0201  \n",
      "\n",
      "Fold: 7  Epoch: 6  Training loss = 2.8318  Validation loss = 3.0197  \n",
      "\n",
      "Fold: 7  Epoch: 7  Training loss = 2.8316  Validation loss = 3.0194  \n",
      "\n",
      "Fold: 7  Epoch: 8  Training loss = 2.8315  Validation loss = 3.0192  \n",
      "\n",
      "Fold: 7  Epoch: 9  Training loss = 2.8313  Validation loss = 3.0189  \n",
      "\n",
      "Fold: 7  Epoch: 10  Training loss = 2.8311  Validation loss = 3.0186  \n",
      "\n",
      "Fold: 7  Epoch: 11  Training loss = 2.8309  Validation loss = 3.0183  \n",
      "\n",
      "Fold: 7  Epoch: 12  Training loss = 2.8307  Validation loss = 3.0179  \n",
      "\n",
      "Fold: 7  Epoch: 13  Training loss = 2.8305  Validation loss = 3.0176  \n",
      "\n",
      "Fold: 7  Epoch: 14  Training loss = 2.8303  Validation loss = 3.0173  \n",
      "\n",
      "Fold: 7  Epoch: 15  Training loss = 2.8301  Validation loss = 3.0171  \n",
      "\n",
      "Fold: 7  Epoch: 16  Training loss = 2.8300  Validation loss = 3.0168  \n",
      "\n",
      "Fold: 7  Epoch: 17  Training loss = 2.8298  Validation loss = 3.0165  \n",
      "\n",
      "Fold: 7  Epoch: 18  Training loss = 2.8295  Validation loss = 3.0161  \n",
      "\n",
      "Fold: 7  Epoch: 19  Training loss = 2.8294  Validation loss = 3.0159  \n",
      "\n",
      "Fold: 7  Epoch: 20  Training loss = 2.8292  Validation loss = 3.0156  \n",
      "\n",
      "Fold: 7  Epoch: 21  Training loss = 2.8290  Validation loss = 3.0152  \n",
      "\n",
      "Fold: 7  Epoch: 22  Training loss = 2.8288  Validation loss = 3.0150  \n",
      "\n",
      "Fold: 7  Epoch: 23  Training loss = 2.8286  Validation loss = 3.0147  \n",
      "\n",
      "Fold: 7  Epoch: 24  Training loss = 2.8284  Validation loss = 3.0144  \n",
      "\n",
      "Fold: 7  Epoch: 25  Training loss = 2.8283  Validation loss = 3.0141  \n",
      "\n",
      "Fold: 7  Epoch: 26  Training loss = 2.8281  Validation loss = 3.0138  \n",
      "\n",
      "Fold: 7  Epoch: 27  Training loss = 2.8279  Validation loss = 3.0136  \n",
      "\n",
      "Fold: 7  Epoch: 28  Training loss = 2.8278  Validation loss = 3.0133  \n",
      "\n",
      "Fold: 7  Epoch: 29  Training loss = 2.8276  Validation loss = 3.0130  \n",
      "\n",
      "Fold: 7  Epoch: 30  Training loss = 2.8274  Validation loss = 3.0127  \n",
      "\n",
      "Fold: 7  Epoch: 31  Training loss = 2.8272  Validation loss = 3.0125  \n",
      "\n",
      "Fold: 7  Epoch: 32  Training loss = 2.8270  Validation loss = 3.0122  \n",
      "\n",
      "Fold: 7  Epoch: 33  Training loss = 2.8268  Validation loss = 3.0119  \n",
      "\n",
      "Fold: 7  Epoch: 34  Training loss = 2.8267  Validation loss = 3.0116  \n",
      "\n",
      "Fold: 7  Epoch: 35  Training loss = 2.8265  Validation loss = 3.0113  \n",
      "\n",
      "Fold: 7  Epoch: 36  Training loss = 2.8263  Validation loss = 3.0110  \n",
      "\n",
      "Fold: 7  Epoch: 37  Training loss = 2.8261  Validation loss = 3.0107  \n",
      "\n",
      "Fold: 7  Epoch: 38  Training loss = 2.8259  Validation loss = 3.0104  \n",
      "\n",
      "Fold: 7  Epoch: 39  Training loss = 2.8257  Validation loss = 3.0101  \n",
      "\n",
      "Fold: 7  Epoch: 40  Training loss = 2.8255  Validation loss = 3.0098  \n",
      "\n",
      "Fold: 7  Epoch: 41  Training loss = 2.8253  Validation loss = 3.0096  \n",
      "\n",
      "Fold: 7  Epoch: 42  Training loss = 2.8252  Validation loss = 3.0093  \n",
      "\n",
      "Fold: 7  Epoch: 43  Training loss = 2.8250  Validation loss = 3.0090  \n",
      "\n",
      "Fold: 7  Epoch: 44  Training loss = 2.8248  Validation loss = 3.0087  \n",
      "\n",
      "Fold: 7  Epoch: 45  Training loss = 2.8246  Validation loss = 3.0084  \n",
      "\n",
      "Fold: 7  Epoch: 46  Training loss = 2.8244  Validation loss = 3.0081  \n",
      "\n",
      "Fold: 7  Epoch: 47  Training loss = 2.8242  Validation loss = 3.0078  \n",
      "\n",
      "Fold: 7  Epoch: 48  Training loss = 2.8241  Validation loss = 3.0075  \n",
      "\n",
      "Fold: 7  Epoch: 49  Training loss = 2.8239  Validation loss = 3.0073  \n",
      "\n",
      "Fold: 7  Epoch: 50  Training loss = 2.8237  Validation loss = 3.0070  \n",
      "\n",
      "Fold: 7  Epoch: 51  Training loss = 2.8235  Validation loss = 3.0067  \n",
      "\n",
      "Fold: 7  Epoch: 52  Training loss = 2.8234  Validation loss = 3.0064  \n",
      "\n",
      "Fold: 7  Epoch: 53  Training loss = 2.8232  Validation loss = 3.0062  \n",
      "\n",
      "Fold: 7  Epoch: 54  Training loss = 2.8230  Validation loss = 3.0059  \n",
      "\n",
      "Fold: 7  Epoch: 55  Training loss = 2.8228  Validation loss = 3.0056  \n",
      "\n",
      "Fold: 7  Epoch: 56  Training loss = 2.8226  Validation loss = 3.0053  \n",
      "\n",
      "Fold: 7  Epoch: 57  Training loss = 2.8225  Validation loss = 3.0050  \n",
      "\n",
      "Fold: 7  Epoch: 58  Training loss = 2.8223  Validation loss = 3.0047  \n",
      "\n",
      "Fold: 7  Epoch: 59  Training loss = 2.8220  Validation loss = 3.0044  \n",
      "\n",
      "Fold: 7  Epoch: 60  Training loss = 2.8219  Validation loss = 3.0041  \n",
      "\n",
      "Fold: 7  Epoch: 61  Training loss = 2.8217  Validation loss = 3.0038  \n",
      "\n",
      "Fold: 7  Epoch: 62  Training loss = 2.8215  Validation loss = 3.0036  \n",
      "\n",
      "Fold: 7  Epoch: 63  Training loss = 2.8213  Validation loss = 3.0033  \n",
      "\n",
      "Fold: 7  Epoch: 64  Training loss = 2.8212  Validation loss = 3.0030  \n",
      "\n",
      "Fold: 7  Epoch: 65  Training loss = 2.8210  Validation loss = 3.0028  \n",
      "\n",
      "Fold: 7  Epoch: 66  Training loss = 2.8208  Validation loss = 3.0024  \n",
      "\n",
      "Fold: 7  Epoch: 67  Training loss = 2.8206  Validation loss = 3.0022  \n",
      "\n",
      "Fold: 7  Epoch: 68  Training loss = 2.8204  Validation loss = 3.0018  \n",
      "\n",
      "Fold: 7  Epoch: 69  Training loss = 2.8202  Validation loss = 3.0015  \n",
      "\n",
      "Fold: 7  Epoch: 70  Training loss = 2.8201  Validation loss = 3.0013  \n",
      "\n",
      "Fold: 7  Epoch: 71  Training loss = 2.8199  Validation loss = 3.0010  \n",
      "\n",
      "Fold: 7  Epoch: 72  Training loss = 2.8197  Validation loss = 3.0007  \n",
      "\n",
      "Fold: 7  Epoch: 73  Training loss = 2.8195  Validation loss = 3.0004  \n",
      "\n",
      "Fold: 7  Epoch: 74  Training loss = 2.8193  Validation loss = 3.0001  \n",
      "\n",
      "Fold: 7  Epoch: 75  Training loss = 2.8191  Validation loss = 2.9998  \n",
      "\n",
      "Fold: 7  Epoch: 76  Training loss = 2.8189  Validation loss = 2.9995  \n",
      "\n",
      "Fold: 7  Epoch: 77  Training loss = 2.8187  Validation loss = 2.9992  \n",
      "\n",
      "Fold: 7  Epoch: 78  Training loss = 2.8185  Validation loss = 2.9989  \n",
      "\n",
      "Fold: 7  Epoch: 79  Training loss = 2.8183  Validation loss = 2.9987  \n",
      "\n",
      "Fold: 7  Epoch: 80  Training loss = 2.8181  Validation loss = 2.9984  \n",
      "\n",
      "Fold: 7  Epoch: 81  Training loss = 2.8180  Validation loss = 2.9981  \n",
      "\n",
      "Fold: 7  Epoch: 82  Training loss = 2.8178  Validation loss = 2.9978  \n",
      "\n",
      "Fold: 7  Epoch: 83  Training loss = 2.8175  Validation loss = 2.9975  \n",
      "\n",
      "Fold: 7  Epoch: 84  Training loss = 2.8174  Validation loss = 2.9972  \n",
      "\n",
      "Fold: 7  Epoch: 85  Training loss = 2.8172  Validation loss = 2.9969  \n",
      "\n",
      "Fold: 7  Epoch: 86  Training loss = 2.8170  Validation loss = 2.9967  \n",
      "\n",
      "Fold: 7  Epoch: 87  Training loss = 2.8169  Validation loss = 2.9964  \n",
      "\n",
      "Fold: 7  Epoch: 88  Training loss = 2.8167  Validation loss = 2.9960  \n",
      "\n",
      "Fold: 7  Epoch: 89  Training loss = 2.8164  Validation loss = 2.9957  \n",
      "\n",
      "Fold: 7  Epoch: 90  Training loss = 2.8163  Validation loss = 2.9954  \n",
      "\n",
      "Fold: 7  Epoch: 91  Training loss = 2.8161  Validation loss = 2.9951  \n",
      "\n",
      "Fold: 7  Epoch: 92  Training loss = 2.8158  Validation loss = 2.9947  \n",
      "\n",
      "Fold: 7  Epoch: 93  Training loss = 2.8157  Validation loss = 2.9945  \n",
      "\n",
      "Fold: 7  Epoch: 94  Training loss = 2.8155  Validation loss = 2.9941  \n",
      "\n",
      "Fold: 7  Epoch: 95  Training loss = 2.8154  Validation loss = 2.9939  \n",
      "\n",
      "Fold: 7  Epoch: 96  Training loss = 2.8152  Validation loss = 2.9936  \n",
      "\n",
      "Fold: 7  Epoch: 97  Training loss = 2.8150  Validation loss = 2.9934  \n",
      "\n",
      "Fold: 7  Epoch: 98  Training loss = 2.8148  Validation loss = 2.9932  \n",
      "\n",
      "Fold: 7  Epoch: 99  Training loss = 2.8147  Validation loss = 2.9929  \n",
      "\n",
      "Fold: 7  Epoch: 100  Training loss = 2.8145  Validation loss = 2.9927  \n",
      "\n",
      "Fold: 7  Epoch: 101  Training loss = 2.8143  Validation loss = 2.9924  \n",
      "\n",
      "Fold: 7  Epoch: 102  Training loss = 2.8142  Validation loss = 2.9922  \n",
      "\n",
      "Fold: 7  Epoch: 103  Training loss = 2.8140  Validation loss = 2.9919  \n",
      "\n",
      "Fold: 7  Epoch: 104  Training loss = 2.8138  Validation loss = 2.9916  \n",
      "\n",
      "Fold: 7  Epoch: 105  Training loss = 2.8136  Validation loss = 2.9913  \n",
      "\n",
      "Fold: 7  Epoch: 106  Training loss = 2.8134  Validation loss = 2.9911  \n",
      "\n",
      "Fold: 7  Epoch: 107  Training loss = 2.8132  Validation loss = 2.9908  \n",
      "\n",
      "Fold: 7  Epoch: 108  Training loss = 2.8131  Validation loss = 2.9905  \n",
      "\n",
      "Fold: 7  Epoch: 109  Training loss = 2.8129  Validation loss = 2.9902  \n",
      "\n",
      "Fold: 7  Epoch: 110  Training loss = 2.8127  Validation loss = 2.9899  \n",
      "\n",
      "Fold: 7  Epoch: 111  Training loss = 2.8125  Validation loss = 2.9897  \n",
      "\n",
      "Fold: 7  Epoch: 112  Training loss = 2.8123  Validation loss = 2.9893  \n",
      "\n",
      "Fold: 7  Epoch: 113  Training loss = 2.8121  Validation loss = 2.9890  \n",
      "\n",
      "Fold: 7  Epoch: 114  Training loss = 2.8119  Validation loss = 2.9887  \n",
      "\n",
      "Fold: 7  Epoch: 115  Training loss = 2.8117  Validation loss = 2.9883  \n",
      "\n",
      "Fold: 7  Epoch: 116  Training loss = 2.8114  Validation loss = 2.9879  \n",
      "\n",
      "Fold: 7  Epoch: 117  Training loss = 2.8113  Validation loss = 2.9877  \n",
      "\n",
      "Fold: 7  Epoch: 118  Training loss = 2.8111  Validation loss = 2.9875  \n",
      "\n",
      "Fold: 7  Epoch: 119  Training loss = 2.8109  Validation loss = 2.9872  \n",
      "\n",
      "Fold: 7  Epoch: 120  Training loss = 2.8108  Validation loss = 2.9869  \n",
      "\n",
      "Fold: 7  Epoch: 121  Training loss = 2.8106  Validation loss = 2.9867  \n",
      "\n",
      "Fold: 7  Epoch: 122  Training loss = 2.8104  Validation loss = 2.9864  \n",
      "\n",
      "Fold: 7  Epoch: 123  Training loss = 2.8102  Validation loss = 2.9861  \n",
      "\n",
      "Fold: 7  Epoch: 124  Training loss = 2.8100  Validation loss = 2.9857  \n",
      "\n",
      "Fold: 7  Epoch: 125  Training loss = 2.8098  Validation loss = 2.9855  \n",
      "\n",
      "Fold: 7  Epoch: 126  Training loss = 2.8096  Validation loss = 2.9852  \n",
      "\n",
      "Fold: 7  Epoch: 127  Training loss = 2.8094  Validation loss = 2.9848  \n",
      "\n",
      "Fold: 7  Epoch: 128  Training loss = 2.8092  Validation loss = 2.9845  \n",
      "\n",
      "Fold: 7  Epoch: 129  Training loss = 2.8090  Validation loss = 2.9842  \n",
      "\n",
      "Fold: 7  Epoch: 130  Training loss = 2.8088  Validation loss = 2.9839  \n",
      "\n",
      "Fold: 7  Epoch: 131  Training loss = 2.8086  Validation loss = 2.9836  \n",
      "\n",
      "Fold: 7  Epoch: 132  Training loss = 2.8084  Validation loss = 2.9833  \n",
      "\n",
      "Fold: 7  Epoch: 133  Training loss = 2.8082  Validation loss = 2.9830  \n",
      "\n",
      "Fold: 7  Epoch: 134  Training loss = 2.8080  Validation loss = 2.9828  \n",
      "\n",
      "Fold: 7  Epoch: 135  Training loss = 2.8078  Validation loss = 2.9825  \n",
      "\n",
      "Fold: 7  Epoch: 136  Training loss = 2.8076  Validation loss = 2.9821  \n",
      "\n",
      "Fold: 7  Epoch: 137  Training loss = 2.8074  Validation loss = 2.9818  \n",
      "\n",
      "Fold: 7  Epoch: 138  Training loss = 2.8073  Validation loss = 2.9816  \n",
      "\n",
      "Fold: 7  Epoch: 139  Training loss = 2.8071  Validation loss = 2.9813  \n",
      "\n",
      "Fold: 7  Epoch: 140  Training loss = 2.8069  Validation loss = 2.9810  \n",
      "\n",
      "Fold: 7  Epoch: 141  Training loss = 2.8067  Validation loss = 2.9808  \n",
      "\n",
      "Fold: 7  Epoch: 142  Training loss = 2.8066  Validation loss = 2.9805  \n",
      "\n",
      "Fold: 7  Epoch: 143  Training loss = 2.8064  Validation loss = 2.9803  \n",
      "\n",
      "Fold: 7  Epoch: 144  Training loss = 2.8062  Validation loss = 2.9800  \n",
      "\n",
      "Fold: 7  Epoch: 145  Training loss = 2.8060  Validation loss = 2.9796  \n",
      "\n",
      "Fold: 7  Epoch: 146  Training loss = 2.8058  Validation loss = 2.9793  \n",
      "\n",
      "Fold: 7  Epoch: 147  Training loss = 2.8056  Validation loss = 2.9789  \n",
      "\n",
      "Fold: 7  Epoch: 148  Training loss = 2.8054  Validation loss = 2.9787  \n",
      "\n",
      "Fold: 7  Epoch: 149  Training loss = 2.8053  Validation loss = 2.9785  \n",
      "\n",
      "Fold: 7  Epoch: 150  Training loss = 2.8051  Validation loss = 2.9782  \n",
      "\n",
      "Fold: 7  Epoch: 151  Training loss = 2.8050  Validation loss = 2.9780  \n",
      "\n",
      "Fold: 7  Epoch: 152  Training loss = 2.8048  Validation loss = 2.9777  \n",
      "\n",
      "Fold: 7  Epoch: 153  Training loss = 2.8046  Validation loss = 2.9775  \n",
      "\n",
      "Fold: 7  Epoch: 154  Training loss = 2.8044  Validation loss = 2.9771  \n",
      "\n",
      "Fold: 7  Epoch: 155  Training loss = 2.8041  Validation loss = 2.9767  \n",
      "\n",
      "Fold: 7  Epoch: 156  Training loss = 2.8040  Validation loss = 2.9764  \n",
      "\n",
      "Fold: 7  Epoch: 157  Training loss = 2.8038  Validation loss = 2.9762  \n",
      "\n",
      "Fold: 7  Epoch: 158  Training loss = 2.8036  Validation loss = 2.9758  \n",
      "\n",
      "Fold: 7  Epoch: 159  Training loss = 2.8034  Validation loss = 2.9756  \n",
      "\n",
      "Fold: 7  Epoch: 160  Training loss = 2.8032  Validation loss = 2.9753  \n",
      "\n",
      "Fold: 7  Epoch: 161  Training loss = 2.8030  Validation loss = 2.9750  \n",
      "\n",
      "Fold: 7  Epoch: 162  Training loss = 2.8029  Validation loss = 2.9747  \n",
      "\n",
      "Fold: 7  Epoch: 163  Training loss = 2.8027  Validation loss = 2.9745  \n",
      "\n",
      "Fold: 7  Epoch: 164  Training loss = 2.8025  Validation loss = 2.9742  \n",
      "\n",
      "Fold: 7  Epoch: 165  Training loss = 2.8023  Validation loss = 2.9740  \n",
      "\n",
      "Fold: 7  Epoch: 166  Training loss = 2.8021  Validation loss = 2.9737  \n",
      "\n",
      "Fold: 7  Epoch: 167  Training loss = 2.8020  Validation loss = 2.9734  \n",
      "\n",
      "Fold: 7  Epoch: 168  Training loss = 2.8018  Validation loss = 2.9732  \n",
      "\n",
      "Fold: 7  Epoch: 169  Training loss = 2.8016  Validation loss = 2.9729  \n",
      "\n",
      "Fold: 7  Epoch: 170  Training loss = 2.8014  Validation loss = 2.9726  \n",
      "\n",
      "Fold: 7  Epoch: 171  Training loss = 2.8013  Validation loss = 2.9723  \n",
      "\n",
      "Fold: 7  Epoch: 172  Training loss = 2.8011  Validation loss = 2.9720  \n",
      "\n",
      "Fold: 7  Epoch: 173  Training loss = 2.8009  Validation loss = 2.9717  \n",
      "\n",
      "Fold: 7  Epoch: 174  Training loss = 2.8007  Validation loss = 2.9715  \n",
      "\n",
      "Fold: 7  Epoch: 175  Training loss = 2.8005  Validation loss = 2.9712  \n",
      "\n",
      "Fold: 7  Epoch: 176  Training loss = 2.8003  Validation loss = 2.9709  \n",
      "\n",
      "Fold: 7  Epoch: 177  Training loss = 2.8002  Validation loss = 2.9706  \n",
      "\n",
      "Fold: 7  Epoch: 178  Training loss = 2.8000  Validation loss = 2.9704  \n",
      "\n",
      "Fold: 7  Epoch: 179  Training loss = 2.7998  Validation loss = 2.9701  \n",
      "\n",
      "Fold: 7  Epoch: 180  Training loss = 2.7996  Validation loss = 2.9698  \n",
      "\n",
      "Fold: 7  Epoch: 181  Training loss = 2.7994  Validation loss = 2.9695  \n",
      "\n",
      "Fold: 7  Epoch: 182  Training loss = 2.7992  Validation loss = 2.9692  \n",
      "\n",
      "Fold: 7  Epoch: 183  Training loss = 2.7990  Validation loss = 2.9689  \n",
      "\n",
      "Fold: 7  Epoch: 184  Training loss = 2.7988  Validation loss = 2.9686  \n",
      "\n",
      "Fold: 7  Epoch: 185  Training loss = 2.7986  Validation loss = 2.9683  \n",
      "\n",
      "Fold: 7  Epoch: 186  Training loss = 2.7985  Validation loss = 2.9681  \n",
      "\n",
      "Fold: 7  Epoch: 187  Training loss = 2.7983  Validation loss = 2.9678  \n",
      "\n",
      "Fold: 7  Epoch: 188  Training loss = 2.7981  Validation loss = 2.9675  \n",
      "\n",
      "Fold: 7  Epoch: 189  Training loss = 2.7979  Validation loss = 2.9673  \n",
      "\n",
      "Fold: 7  Epoch: 190  Training loss = 2.7977  Validation loss = 2.9670  \n",
      "\n",
      "Fold: 7  Epoch: 191  Training loss = 2.7975  Validation loss = 2.9667  \n",
      "\n",
      "Fold: 7  Epoch: 192  Training loss = 2.7974  Validation loss = 2.9665  \n",
      "\n",
      "Fold: 7  Epoch: 193  Training loss = 2.7972  Validation loss = 2.9662  \n",
      "\n",
      "Fold: 7  Epoch: 194  Training loss = 2.7970  Validation loss = 2.9659  \n",
      "\n",
      "Fold: 7  Epoch: 195  Training loss = 2.7968  Validation loss = 2.9656  \n",
      "\n",
      "Fold: 7  Epoch: 196  Training loss = 2.7966  Validation loss = 2.9652  \n",
      "\n",
      "Fold: 7  Epoch: 197  Training loss = 2.7964  Validation loss = 2.9649  \n",
      "\n",
      "Fold: 7  Epoch: 198  Training loss = 2.7962  Validation loss = 2.9647  \n",
      "\n",
      "Fold: 7  Epoch: 199  Training loss = 2.7961  Validation loss = 2.9645  \n",
      "\n",
      "Fold: 7  Epoch: 200  Training loss = 2.7958  Validation loss = 2.9641  \n",
      "\n",
      "Fold: 7  Epoch: 201  Training loss = 2.7956  Validation loss = 2.9638  \n",
      "\n",
      "Fold: 7  Epoch: 202  Training loss = 2.7955  Validation loss = 2.9636  \n",
      "\n",
      "Fold: 7  Epoch: 203  Training loss = 2.7953  Validation loss = 2.9633  \n",
      "\n",
      "Fold: 7  Epoch: 204  Training loss = 2.7951  Validation loss = 2.9630  \n",
      "\n",
      "Fold: 7  Epoch: 205  Training loss = 2.7949  Validation loss = 2.9627  \n",
      "\n",
      "Fold: 7  Epoch: 206  Training loss = 2.7948  Validation loss = 2.9625  \n",
      "\n",
      "Fold: 7  Epoch: 207  Training loss = 2.7946  Validation loss = 2.9623  \n",
      "\n",
      "Fold: 7  Epoch: 208  Training loss = 2.7944  Validation loss = 2.9620  \n",
      "\n",
      "Fold: 7  Epoch: 209  Training loss = 2.7942  Validation loss = 2.9617  \n",
      "\n",
      "Fold: 7  Epoch: 210  Training loss = 2.7941  Validation loss = 2.9615  \n",
      "\n",
      "Fold: 7  Epoch: 211  Training loss = 2.7939  Validation loss = 2.9613  \n",
      "\n",
      "Fold: 7  Epoch: 212  Training loss = 2.7937  Validation loss = 2.9610  \n",
      "\n",
      "Fold: 7  Epoch: 213  Training loss = 2.7936  Validation loss = 2.9608  \n",
      "\n",
      "Fold: 7  Epoch: 214  Training loss = 2.7934  Validation loss = 2.9605  \n",
      "\n",
      "Fold: 7  Epoch: 215  Training loss = 2.7932  Validation loss = 2.9602  \n",
      "\n",
      "Fold: 7  Epoch: 216  Training loss = 2.7930  Validation loss = 2.9600  \n",
      "\n",
      "Fold: 7  Epoch: 217  Training loss = 2.7928  Validation loss = 2.9597  \n",
      "\n",
      "Fold: 7  Epoch: 218  Training loss = 2.7927  Validation loss = 2.9594  \n",
      "\n",
      "Fold: 7  Epoch: 219  Training loss = 2.7924  Validation loss = 2.9591  \n",
      "\n",
      "Fold: 7  Epoch: 220  Training loss = 2.7923  Validation loss = 2.9589  \n",
      "\n",
      "Fold: 7  Epoch: 221  Training loss = 2.7921  Validation loss = 2.9586  \n",
      "\n",
      "Fold: 7  Epoch: 222  Training loss = 2.7919  Validation loss = 2.9583  \n",
      "\n",
      "Fold: 7  Epoch: 223  Training loss = 2.7917  Validation loss = 2.9580  \n",
      "\n",
      "Fold: 7  Epoch: 224  Training loss = 2.7915  Validation loss = 2.9576  \n",
      "\n",
      "Fold: 7  Epoch: 225  Training loss = 2.7913  Validation loss = 2.9573  \n",
      "\n",
      "Fold: 7  Epoch: 226  Training loss = 2.7912  Validation loss = 2.9571  \n",
      "\n",
      "Fold: 7  Epoch: 227  Training loss = 2.7910  Validation loss = 2.9568  \n",
      "\n",
      "Fold: 7  Epoch: 228  Training loss = 2.7908  Validation loss = 2.9566  \n",
      "\n",
      "Fold: 7  Epoch: 229  Training loss = 2.7906  Validation loss = 2.9563  \n",
      "\n",
      "Fold: 7  Epoch: 230  Training loss = 2.7904  Validation loss = 2.9561  \n",
      "\n",
      "Fold: 7  Epoch: 231  Training loss = 2.7903  Validation loss = 2.9559  \n",
      "\n",
      "Fold: 7  Epoch: 232  Training loss = 2.7901  Validation loss = 2.9556  \n",
      "\n",
      "Fold: 7  Epoch: 233  Training loss = 2.7899  Validation loss = 2.9553  \n",
      "\n",
      "Fold: 7  Epoch: 234  Training loss = 2.7897  Validation loss = 2.9549  \n",
      "\n",
      "Fold: 7  Epoch: 235  Training loss = 2.7895  Validation loss = 2.9547  \n",
      "\n",
      "Fold: 7  Epoch: 236  Training loss = 2.7893  Validation loss = 2.9544  \n",
      "\n",
      "Fold: 7  Epoch: 237  Training loss = 2.7892  Validation loss = 2.9541  \n",
      "\n",
      "Fold: 7  Epoch: 238  Training loss = 2.7890  Validation loss = 2.9538  \n",
      "\n",
      "Fold: 7  Epoch: 239  Training loss = 2.7888  Validation loss = 2.9536  \n",
      "\n",
      "Fold: 7  Epoch: 240  Training loss = 2.7887  Validation loss = 2.9533  \n",
      "\n",
      "Fold: 7  Epoch: 241  Training loss = 2.7885  Validation loss = 2.9530  \n",
      "\n",
      "Fold: 7  Epoch: 242  Training loss = 2.7882  Validation loss = 2.9527  \n",
      "\n",
      "Fold: 7  Epoch: 243  Training loss = 2.7880  Validation loss = 2.9524  \n",
      "\n",
      "Fold: 7  Epoch: 244  Training loss = 2.7878  Validation loss = 2.9521  \n",
      "\n",
      "Fold: 7  Epoch: 245  Training loss = 2.7877  Validation loss = 2.9519  \n",
      "\n",
      "Fold: 7  Epoch: 246  Training loss = 2.7875  Validation loss = 2.9516  \n",
      "\n",
      "Fold: 7  Epoch: 247  Training loss = 2.7873  Validation loss = 2.9514  \n",
      "\n",
      "Fold: 7  Epoch: 248  Training loss = 2.7871  Validation loss = 2.9511  \n",
      "\n",
      "Fold: 7  Epoch: 249  Training loss = 2.7869  Validation loss = 2.9508  \n",
      "\n",
      "Fold: 7  Epoch: 250  Training loss = 2.7868  Validation loss = 2.9505  \n",
      "\n",
      "Fold: 7  Epoch: 251  Training loss = 2.7866  Validation loss = 2.9503  \n",
      "\n",
      "Fold: 7  Epoch: 252  Training loss = 2.7864  Validation loss = 2.9500  \n",
      "\n",
      "Fold: 7  Epoch: 253  Training loss = 2.7863  Validation loss = 2.9498  \n",
      "\n",
      "Fold: 7  Epoch: 254  Training loss = 2.7861  Validation loss = 2.9496  \n",
      "\n",
      "Fold: 7  Epoch: 255  Training loss = 2.7859  Validation loss = 2.9493  \n",
      "\n",
      "Fold: 7  Epoch: 256  Training loss = 2.7857  Validation loss = 2.9490  \n",
      "\n",
      "Fold: 7  Epoch: 257  Training loss = 2.7855  Validation loss = 2.9487  \n",
      "\n",
      "Fold: 7  Epoch: 258  Training loss = 2.7853  Validation loss = 2.9485  \n",
      "\n",
      "Fold: 7  Epoch: 259  Training loss = 2.7851  Validation loss = 2.9481  \n",
      "\n",
      "Fold: 7  Epoch: 260  Training loss = 2.7850  Validation loss = 2.9478  \n",
      "\n",
      "Fold: 7  Epoch: 261  Training loss = 2.7848  Validation loss = 2.9475  \n",
      "\n",
      "Fold: 7  Epoch: 262  Training loss = 2.7846  Validation loss = 2.9473  \n",
      "\n",
      "Fold: 7  Epoch: 263  Training loss = 2.7844  Validation loss = 2.9470  \n",
      "\n",
      "Fold: 7  Epoch: 264  Training loss = 2.7842  Validation loss = 2.9468  \n",
      "\n",
      "Fold: 7  Epoch: 265  Training loss = 2.7840  Validation loss = 2.9465  \n",
      "\n",
      "Fold: 7  Epoch: 266  Training loss = 2.7839  Validation loss = 2.9462  \n",
      "\n",
      "Fold: 7  Epoch: 267  Training loss = 2.7837  Validation loss = 2.9460  \n",
      "\n",
      "Fold: 7  Epoch: 268  Training loss = 2.7835  Validation loss = 2.9457  \n",
      "\n",
      "Fold: 7  Epoch: 269  Training loss = 2.7833  Validation loss = 2.9454  \n",
      "\n",
      "Fold: 7  Epoch: 270  Training loss = 2.7832  Validation loss = 2.9452  \n",
      "\n",
      "Fold: 7  Epoch: 271  Training loss = 2.7830  Validation loss = 2.9449  \n",
      "\n",
      "Fold: 7  Epoch: 272  Training loss = 2.7828  Validation loss = 2.9447  \n",
      "\n",
      "Fold: 7  Epoch: 273  Training loss = 2.7826  Validation loss = 2.9444  \n",
      "\n",
      "Fold: 7  Epoch: 274  Training loss = 2.7825  Validation loss = 2.9441  \n",
      "\n",
      "Fold: 7  Epoch: 275  Training loss = 2.7823  Validation loss = 2.9438  \n",
      "\n",
      "Fold: 7  Epoch: 276  Training loss = 2.7821  Validation loss = 2.9435  \n",
      "\n",
      "Fold: 7  Epoch: 277  Training loss = 2.7819  Validation loss = 2.9433  \n",
      "\n",
      "Fold: 7  Epoch: 278  Training loss = 2.7817  Validation loss = 2.9430  \n",
      "\n",
      "Fold: 7  Epoch: 279  Training loss = 2.7815  Validation loss = 2.9428  \n",
      "\n",
      "Fold: 7  Epoch: 280  Training loss = 2.7813  Validation loss = 2.9425  \n",
      "\n",
      "Fold: 7  Epoch: 281  Training loss = 2.7811  Validation loss = 2.9422  \n",
      "\n",
      "Fold: 7  Epoch: 282  Training loss = 2.7810  Validation loss = 2.9420  \n",
      "\n",
      "Fold: 7  Epoch: 283  Training loss = 2.7808  Validation loss = 2.9416  \n",
      "\n",
      "Fold: 7  Epoch: 284  Training loss = 2.7806  Validation loss = 2.9414  \n",
      "\n",
      "Fold: 7  Epoch: 285  Training loss = 2.7804  Validation loss = 2.9411  \n",
      "\n",
      "Fold: 7  Epoch: 286  Training loss = 2.7802  Validation loss = 2.9408  \n",
      "\n",
      "Fold: 7  Epoch: 287  Training loss = 2.7800  Validation loss = 2.9405  \n",
      "\n",
      "Fold: 7  Epoch: 288  Training loss = 2.7799  Validation loss = 2.9403  \n",
      "\n",
      "Fold: 7  Epoch: 289  Training loss = 2.7797  Validation loss = 2.9400  \n",
      "\n",
      "Fold: 7  Epoch: 290  Training loss = 2.7795  Validation loss = 2.9397  \n",
      "\n",
      "Fold: 7  Epoch: 291  Training loss = 2.7793  Validation loss = 2.9395  \n",
      "\n",
      "Fold: 7  Epoch: 292  Training loss = 2.7791  Validation loss = 2.9392  \n",
      "\n",
      "Fold: 7  Epoch: 293  Training loss = 2.7790  Validation loss = 2.9390  \n",
      "\n",
      "Fold: 7  Epoch: 294  Training loss = 2.7788  Validation loss = 2.9387  \n",
      "\n",
      "Fold: 7  Epoch: 295  Training loss = 2.7786  Validation loss = 2.9385  \n",
      "\n",
      "Fold: 7  Epoch: 296  Training loss = 2.7784  Validation loss = 2.9382  \n",
      "\n",
      "Fold: 7  Epoch: 297  Training loss = 2.7783  Validation loss = 2.9379  \n",
      "\n",
      "Fold: 7  Epoch: 298  Training loss = 2.7781  Validation loss = 2.9376  \n",
      "\n",
      "Fold: 7  Epoch: 299  Training loss = 2.7779  Validation loss = 2.9374  \n",
      "\n",
      "Fold: 7  Epoch: 300  Training loss = 2.7777  Validation loss = 2.9371  \n",
      "\n",
      "Fold: 7  Epoch: 301  Training loss = 2.7775  Validation loss = 2.9368  \n",
      "\n",
      "Fold: 7  Epoch: 302  Training loss = 2.7773  Validation loss = 2.9366  \n",
      "\n",
      "Fold: 7  Epoch: 303  Training loss = 2.7771  Validation loss = 2.9363  \n",
      "\n",
      "Fold: 7  Epoch: 304  Training loss = 2.7769  Validation loss = 2.9360  \n",
      "\n",
      "Fold: 7  Epoch: 305  Training loss = 2.7768  Validation loss = 2.9358  \n",
      "\n",
      "Fold: 7  Epoch: 306  Training loss = 2.7766  Validation loss = 2.9355  \n",
      "\n",
      "Fold: 7  Epoch: 307  Training loss = 2.7764  Validation loss = 2.9352  \n",
      "\n",
      "Fold: 7  Epoch: 308  Training loss = 2.7763  Validation loss = 2.9350  \n",
      "\n",
      "Fold: 7  Epoch: 309  Training loss = 2.7761  Validation loss = 2.9347  \n",
      "\n",
      "Fold: 7  Epoch: 310  Training loss = 2.7759  Validation loss = 2.9344  \n",
      "\n",
      "Fold: 7  Epoch: 311  Training loss = 2.7757  Validation loss = 2.9342  \n",
      "\n",
      "Fold: 7  Epoch: 312  Training loss = 2.7755  Validation loss = 2.9339  \n",
      "\n",
      "Fold: 7  Epoch: 313  Training loss = 2.7753  Validation loss = 2.9336  \n",
      "\n",
      "Fold: 7  Epoch: 314  Training loss = 2.7752  Validation loss = 2.9334  \n",
      "\n",
      "Fold: 7  Epoch: 315  Training loss = 2.7749  Validation loss = 2.9330  \n",
      "\n",
      "Fold: 7  Epoch: 316  Training loss = 2.7748  Validation loss = 2.9327  \n",
      "\n",
      "Fold: 7  Epoch: 317  Training loss = 2.7746  Validation loss = 2.9325  \n",
      "\n",
      "Fold: 7  Epoch: 318  Training loss = 2.7744  Validation loss = 2.9322  \n",
      "\n",
      "Fold: 7  Epoch: 319  Training loss = 2.7742  Validation loss = 2.9320  \n",
      "\n",
      "Fold: 7  Epoch: 320  Training loss = 2.7740  Validation loss = 2.9317  \n",
      "\n",
      "Fold: 7  Epoch: 321  Training loss = 2.7739  Validation loss = 2.9315  \n",
      "\n",
      "Fold: 7  Epoch: 322  Training loss = 2.7737  Validation loss = 2.9312  \n",
      "\n",
      "Fold: 7  Epoch: 323  Training loss = 2.7735  Validation loss = 2.9309  \n",
      "\n",
      "Fold: 7  Epoch: 324  Training loss = 2.7733  Validation loss = 2.9306  \n",
      "\n",
      "Fold: 7  Epoch: 325  Training loss = 2.7731  Validation loss = 2.9304  \n",
      "\n",
      "Fold: 7  Epoch: 326  Training loss = 2.7729  Validation loss = 2.9301  \n",
      "\n",
      "Fold: 7  Epoch: 327  Training loss = 2.7728  Validation loss = 2.9299  \n",
      "\n",
      "Fold: 7  Epoch: 328  Training loss = 2.7726  Validation loss = 2.9297  \n",
      "\n",
      "Fold: 7  Epoch: 329  Training loss = 2.7724  Validation loss = 2.9294  \n",
      "\n",
      "Fold: 7  Epoch: 330  Training loss = 2.7722  Validation loss = 2.9291  \n",
      "\n",
      "Fold: 7  Epoch: 331  Training loss = 2.7720  Validation loss = 2.9288  \n",
      "\n",
      "Fold: 7  Epoch: 332  Training loss = 2.7718  Validation loss = 2.9286  \n",
      "\n",
      "Fold: 7  Epoch: 333  Training loss = 2.7716  Validation loss = 2.9283  \n",
      "\n",
      "Fold: 7  Epoch: 334  Training loss = 2.7714  Validation loss = 2.9280  \n",
      "\n",
      "Fold: 7  Epoch: 335  Training loss = 2.7713  Validation loss = 2.9277  \n",
      "\n",
      "Fold: 7  Epoch: 336  Training loss = 2.7711  Validation loss = 2.9275  \n",
      "\n",
      "Fold: 7  Epoch: 337  Training loss = 2.7709  Validation loss = 2.9272  \n",
      "\n",
      "Fold: 7  Epoch: 338  Training loss = 2.7707  Validation loss = 2.9270  \n",
      "\n",
      "Fold: 7  Epoch: 339  Training loss = 2.7706  Validation loss = 2.9268  \n",
      "\n",
      "Fold: 7  Epoch: 340  Training loss = 2.7705  Validation loss = 2.9266  \n",
      "\n",
      "Fold: 7  Epoch: 341  Training loss = 2.7703  Validation loss = 2.9264  \n",
      "\n",
      "Fold: 7  Epoch: 342  Training loss = 2.7702  Validation loss = 2.9262  \n",
      "\n",
      "Fold: 7  Epoch: 343  Training loss = 2.7700  Validation loss = 2.9259  \n",
      "\n",
      "Fold: 7  Epoch: 344  Training loss = 2.7698  Validation loss = 2.9256  \n",
      "\n",
      "Fold: 7  Epoch: 345  Training loss = 2.7696  Validation loss = 2.9254  \n",
      "\n",
      "Fold: 7  Epoch: 346  Training loss = 2.7694  Validation loss = 2.9251  \n",
      "\n",
      "Fold: 7  Epoch: 347  Training loss = 2.7693  Validation loss = 2.9248  \n",
      "\n",
      "Fold: 7  Epoch: 348  Training loss = 2.7691  Validation loss = 2.9246  \n",
      "\n",
      "Fold: 7  Epoch: 349  Training loss = 2.7690  Validation loss = 2.9244  \n",
      "\n",
      "Fold: 7  Epoch: 350  Training loss = 2.7688  Validation loss = 2.9242  \n",
      "\n",
      "Fold: 7  Epoch: 351  Training loss = 2.7686  Validation loss = 2.9240  \n",
      "\n",
      "Fold: 7  Epoch: 352  Training loss = 2.7685  Validation loss = 2.9237  \n",
      "\n",
      "Fold: 7  Epoch: 353  Training loss = 2.7683  Validation loss = 2.9234  \n",
      "\n",
      "Fold: 7  Epoch: 354  Training loss = 2.7681  Validation loss = 2.9232  \n",
      "\n",
      "Fold: 7  Epoch: 355  Training loss = 2.7679  Validation loss = 2.9229  \n",
      "\n",
      "Fold: 7  Epoch: 356  Training loss = 2.7677  Validation loss = 2.9227  \n",
      "\n",
      "Fold: 7  Epoch: 357  Training loss = 2.7675  Validation loss = 2.9224  \n",
      "\n",
      "Fold: 7  Epoch: 358  Training loss = 2.7674  Validation loss = 2.9222  \n",
      "\n",
      "Fold: 7  Epoch: 359  Training loss = 2.7672  Validation loss = 2.9220  \n",
      "\n",
      "Fold: 7  Epoch: 360  Training loss = 2.7671  Validation loss = 2.9217  \n",
      "\n",
      "Fold: 7  Epoch: 361  Training loss = 2.7669  Validation loss = 2.9215  \n",
      "\n",
      "Fold: 7  Epoch: 362  Training loss = 2.7667  Validation loss = 2.9212  \n",
      "\n",
      "Fold: 7  Epoch: 363  Training loss = 2.7664  Validation loss = 2.9208  \n",
      "\n",
      "Fold: 7  Epoch: 364  Training loss = 2.7663  Validation loss = 2.9206  \n",
      "\n",
      "Fold: 7  Epoch: 365  Training loss = 2.7661  Validation loss = 2.9203  \n",
      "\n",
      "Fold: 7  Epoch: 366  Training loss = 2.7659  Validation loss = 2.9201  \n",
      "\n",
      "Fold: 7  Epoch: 367  Training loss = 2.7658  Validation loss = 2.9198  \n",
      "\n",
      "Fold: 7  Epoch: 368  Training loss = 2.7656  Validation loss = 2.9196  \n",
      "\n",
      "Fold: 7  Epoch: 369  Training loss = 2.7653  Validation loss = 2.9192  \n",
      "\n",
      "Fold: 7  Epoch: 370  Training loss = 2.7651  Validation loss = 2.9189  \n",
      "\n",
      "Fold: 7  Epoch: 371  Training loss = 2.7649  Validation loss = 2.9186  \n",
      "\n",
      "Fold: 7  Epoch: 372  Training loss = 2.7648  Validation loss = 2.9184  \n",
      "\n",
      "Fold: 7  Epoch: 373  Training loss = 2.7647  Validation loss = 2.9182  \n",
      "\n",
      "Fold: 7  Epoch: 374  Training loss = 2.7645  Validation loss = 2.9180  \n",
      "\n",
      "Fold: 7  Epoch: 375  Training loss = 2.7643  Validation loss = 2.9178  \n",
      "\n",
      "Fold: 7  Epoch: 376  Training loss = 2.7642  Validation loss = 2.9175  \n",
      "\n",
      "Fold: 7  Epoch: 377  Training loss = 2.7640  Validation loss = 2.9172  \n",
      "\n",
      "Fold: 7  Epoch: 378  Training loss = 2.7638  Validation loss = 2.9169  \n",
      "\n",
      "Fold: 7  Epoch: 379  Training loss = 2.7637  Validation loss = 2.9167  \n",
      "\n",
      "Fold: 7  Epoch: 380  Training loss = 2.7635  Validation loss = 2.9165  \n",
      "\n",
      "Fold: 7  Epoch: 381  Training loss = 2.7632  Validation loss = 2.9161  \n",
      "\n",
      "Fold: 7  Epoch: 382  Training loss = 2.7631  Validation loss = 2.9159  \n",
      "\n",
      "Fold: 7  Epoch: 383  Training loss = 2.7629  Validation loss = 2.9157  \n",
      "\n",
      "Fold: 7  Epoch: 384  Training loss = 2.7628  Validation loss = 2.9154  \n",
      "\n",
      "Fold: 7  Epoch: 385  Training loss = 2.7626  Validation loss = 2.9152  \n",
      "\n",
      "Fold: 7  Epoch: 386  Training loss = 2.7624  Validation loss = 2.9149  \n",
      "\n",
      "Fold: 7  Epoch: 387  Training loss = 2.7622  Validation loss = 2.9146  \n",
      "\n",
      "Fold: 7  Epoch: 388  Training loss = 2.7620  Validation loss = 2.9144  \n",
      "\n",
      "Fold: 7  Epoch: 389  Training loss = 2.7619  Validation loss = 2.9141  \n",
      "\n",
      "Fold: 7  Epoch: 390  Training loss = 2.7617  Validation loss = 2.9139  \n",
      "\n",
      "Fold: 7  Epoch: 391  Training loss = 2.7615  Validation loss = 2.9136  \n",
      "\n",
      "Fold: 7  Epoch: 392  Training loss = 2.7614  Validation loss = 2.9133  \n",
      "\n",
      "Fold: 7  Epoch: 393  Training loss = 2.7612  Validation loss = 2.9131  \n",
      "\n",
      "Fold: 7  Epoch: 394  Training loss = 2.7610  Validation loss = 2.9128  \n",
      "\n",
      "Fold: 7  Epoch: 395  Training loss = 2.7608  Validation loss = 2.9126  \n",
      "\n",
      "Fold: 7  Epoch: 396  Training loss = 2.7607  Validation loss = 2.9124  \n",
      "\n",
      "Fold: 7  Epoch: 397  Training loss = 2.7605  Validation loss = 2.9122  \n",
      "\n",
      "Fold: 7  Epoch: 398  Training loss = 2.7603  Validation loss = 2.9119  \n",
      "\n",
      "Fold: 7  Epoch: 399  Training loss = 2.7601  Validation loss = 2.9116  \n",
      "\n",
      "Fold: 7  Epoch: 400  Training loss = 2.7599  Validation loss = 2.9114  \n",
      "\n",
      "Fold: 7  Epoch: 401  Training loss = 2.7598  Validation loss = 2.9111  \n",
      "\n",
      "Fold: 7  Epoch: 402  Training loss = 2.7596  Validation loss = 2.9108  \n",
      "\n",
      "Fold: 7  Epoch: 403  Training loss = 2.7594  Validation loss = 2.9106  \n",
      "\n",
      "Fold: 7  Epoch: 404  Training loss = 2.7592  Validation loss = 2.9103  \n",
      "\n",
      "Fold: 7  Epoch: 405  Training loss = 2.7590  Validation loss = 2.9100  \n",
      "\n",
      "Fold: 7  Epoch: 406  Training loss = 2.7588  Validation loss = 2.9098  \n",
      "\n",
      "Fold: 7  Epoch: 407  Training loss = 2.7587  Validation loss = 2.9095  \n",
      "\n",
      "Fold: 7  Epoch: 408  Training loss = 2.7585  Validation loss = 2.9093  \n",
      "\n",
      "Fold: 7  Epoch: 409  Training loss = 2.7583  Validation loss = 2.9091  \n",
      "\n",
      "Fold: 7  Epoch: 410  Training loss = 2.7581  Validation loss = 2.9088  \n",
      "\n",
      "Fold: 7  Epoch: 411  Training loss = 2.7580  Validation loss = 2.9086  \n",
      "\n",
      "Fold: 7  Epoch: 412  Training loss = 2.7578  Validation loss = 2.9083  \n",
      "\n",
      "Fold: 7  Epoch: 413  Training loss = 2.7576  Validation loss = 2.9080  \n",
      "\n",
      "Fold: 7  Epoch: 414  Training loss = 2.7574  Validation loss = 2.9078  \n",
      "\n",
      "Fold: 7  Epoch: 415  Training loss = 2.7572  Validation loss = 2.9075  \n",
      "\n",
      "Fold: 7  Epoch: 416  Training loss = 2.7570  Validation loss = 2.9072  \n",
      "\n",
      "Fold: 7  Epoch: 417  Training loss = 2.7568  Validation loss = 2.9069  \n",
      "\n",
      "Fold: 7  Epoch: 418  Training loss = 2.7567  Validation loss = 2.9067  \n",
      "\n",
      "Fold: 7  Epoch: 419  Training loss = 2.7565  Validation loss = 2.9064  \n",
      "\n",
      "Fold: 7  Epoch: 420  Training loss = 2.7563  Validation loss = 2.9061  \n",
      "\n",
      "Fold: 7  Epoch: 421  Training loss = 2.7561  Validation loss = 2.9059  \n",
      "\n",
      "Fold: 7  Epoch: 422  Training loss = 2.7559  Validation loss = 2.9056  \n",
      "\n",
      "Fold: 7  Epoch: 423  Training loss = 2.7558  Validation loss = 2.9054  \n",
      "\n",
      "Fold: 7  Epoch: 424  Training loss = 2.7556  Validation loss = 2.9051  \n",
      "\n",
      "Fold: 7  Epoch: 425  Training loss = 2.7554  Validation loss = 2.9049  \n",
      "\n",
      "Fold: 7  Epoch: 426  Training loss = 2.7552  Validation loss = 2.9046  \n",
      "\n",
      "Fold: 7  Epoch: 427  Training loss = 2.7551  Validation loss = 2.9044  \n",
      "\n",
      "Fold: 7  Epoch: 428  Training loss = 2.7549  Validation loss = 2.9041  \n",
      "\n",
      "Fold: 7  Epoch: 429  Training loss = 2.7547  Validation loss = 2.9039  \n",
      "\n",
      "Fold: 7  Epoch: 430  Training loss = 2.7545  Validation loss = 2.9036  \n",
      "\n",
      "Fold: 7  Epoch: 431  Training loss = 2.7544  Validation loss = 2.9034  \n",
      "\n",
      "Fold: 7  Epoch: 432  Training loss = 2.7542  Validation loss = 2.9031  \n",
      "\n",
      "Fold: 7  Epoch: 433  Training loss = 2.7540  Validation loss = 2.9028  \n",
      "\n",
      "Fold: 7  Epoch: 434  Training loss = 2.7538  Validation loss = 2.9026  \n",
      "\n",
      "Fold: 7  Epoch: 435  Training loss = 2.7537  Validation loss = 2.9024  \n",
      "\n",
      "Fold: 7  Epoch: 436  Training loss = 2.7535  Validation loss = 2.9022  \n",
      "\n",
      "Fold: 7  Epoch: 437  Training loss = 2.7534  Validation loss = 2.9020  \n",
      "\n",
      "Fold: 7  Epoch: 438  Training loss = 2.7532  Validation loss = 2.9018  \n",
      "\n",
      "Fold: 7  Epoch: 439  Training loss = 2.7530  Validation loss = 2.9015  \n",
      "\n",
      "Fold: 7  Epoch: 440  Training loss = 2.7528  Validation loss = 2.9012  \n",
      "\n",
      "Fold: 7  Epoch: 441  Training loss = 2.7526  Validation loss = 2.9009  \n",
      "\n",
      "Fold: 7  Epoch: 442  Training loss = 2.7524  Validation loss = 2.9006  \n",
      "\n",
      "Fold: 7  Epoch: 443  Training loss = 2.7522  Validation loss = 2.9003  \n",
      "\n",
      "Fold: 7  Epoch: 444  Training loss = 2.7521  Validation loss = 2.9001  \n",
      "\n",
      "Fold: 7  Epoch: 445  Training loss = 2.7519  Validation loss = 2.8999  \n",
      "\n",
      "Fold: 7  Epoch: 446  Training loss = 2.7517  Validation loss = 2.8996  \n",
      "\n",
      "Fold: 7  Epoch: 447  Training loss = 2.7515  Validation loss = 2.8993  \n",
      "\n",
      "Fold: 7  Epoch: 448  Training loss = 2.7514  Validation loss = 2.8991  \n",
      "\n",
      "Fold: 7  Epoch: 449  Training loss = 2.7512  Validation loss = 2.8989  \n",
      "\n",
      "Fold: 7  Epoch: 450  Training loss = 2.7509  Validation loss = 2.8985  \n",
      "\n",
      "Fold: 7  Epoch: 451  Training loss = 2.7508  Validation loss = 2.8983  \n",
      "\n",
      "Fold: 7  Epoch: 452  Training loss = 2.7506  Validation loss = 2.8980  \n",
      "\n",
      "Fold: 7  Epoch: 453  Training loss = 2.7504  Validation loss = 2.8977  \n",
      "\n",
      "Fold: 7  Epoch: 454  Training loss = 2.7502  Validation loss = 2.8974  \n",
      "\n",
      "Fold: 7  Epoch: 455  Training loss = 2.7500  Validation loss = 2.8972  \n",
      "\n",
      "Fold: 7  Epoch: 456  Training loss = 2.7498  Validation loss = 2.8970  \n",
      "\n",
      "Fold: 7  Epoch: 457  Training loss = 2.7497  Validation loss = 2.8967  \n",
      "\n",
      "Fold: 7  Epoch: 458  Training loss = 2.7495  Validation loss = 2.8964  \n",
      "\n",
      "Fold: 7  Epoch: 459  Training loss = 2.7493  Validation loss = 2.8962  \n",
      "\n",
      "Fold: 7  Epoch: 460  Training loss = 2.7492  Validation loss = 2.8960  \n",
      "\n",
      "Fold: 7  Epoch: 461  Training loss = 2.7490  Validation loss = 2.8957  \n",
      "\n",
      "Fold: 7  Epoch: 462  Training loss = 2.7488  Validation loss = 2.8954  \n",
      "\n",
      "Fold: 7  Epoch: 463  Training loss = 2.7485  Validation loss = 2.8951  \n",
      "\n",
      "Fold: 7  Epoch: 464  Training loss = 2.7484  Validation loss = 2.8948  \n",
      "\n",
      "Fold: 7  Epoch: 465  Training loss = 2.7482  Validation loss = 2.8945  \n",
      "\n",
      "Fold: 7  Epoch: 466  Training loss = 2.7480  Validation loss = 2.8943  \n",
      "\n",
      "Fold: 7  Epoch: 467  Training loss = 2.7478  Validation loss = 2.8941  \n",
      "\n",
      "Fold: 7  Epoch: 468  Training loss = 2.7476  Validation loss = 2.8938  \n",
      "\n",
      "Fold: 7  Epoch: 469  Training loss = 2.7475  Validation loss = 2.8936  \n",
      "\n",
      "Fold: 7  Epoch: 470  Training loss = 2.7474  Validation loss = 2.8934  \n",
      "\n",
      "Fold: 7  Epoch: 471  Training loss = 2.7472  Validation loss = 2.8932  \n",
      "\n",
      "Fold: 7  Epoch: 472  Training loss = 2.7470  Validation loss = 2.8929  \n",
      "\n",
      "Fold: 7  Epoch: 473  Training loss = 2.7468  Validation loss = 2.8926  \n",
      "\n",
      "Fold: 7  Epoch: 474  Training loss = 2.7466  Validation loss = 2.8924  \n",
      "\n",
      "Fold: 7  Epoch: 475  Training loss = 2.7465  Validation loss = 2.8922  \n",
      "\n",
      "Fold: 7  Epoch: 476  Training loss = 2.7463  Validation loss = 2.8919  \n",
      "\n",
      "Fold: 7  Epoch: 477  Training loss = 2.7461  Validation loss = 2.8916  \n",
      "\n",
      "Fold: 7  Epoch: 478  Training loss = 2.7459  Validation loss = 2.8914  \n",
      "\n",
      "Fold: 7  Epoch: 479  Training loss = 2.7457  Validation loss = 2.8911  \n",
      "\n",
      "Fold: 7  Epoch: 480  Training loss = 2.7455  Validation loss = 2.8909  \n",
      "\n",
      "Fold: 7  Epoch: 481  Training loss = 2.7454  Validation loss = 2.8907  \n",
      "\n",
      "Fold: 7  Epoch: 482  Training loss = 2.7452  Validation loss = 2.8904  \n",
      "\n",
      "Fold: 7  Epoch: 483  Training loss = 2.7450  Validation loss = 2.8901  \n",
      "\n",
      "Fold: 7  Epoch: 484  Training loss = 2.7448  Validation loss = 2.8899  \n",
      "\n",
      "Fold: 7  Epoch: 485  Training loss = 2.7446  Validation loss = 2.8896  \n",
      "\n",
      "Fold: 7  Epoch: 486  Training loss = 2.7445  Validation loss = 2.8894  \n",
      "\n",
      "Fold: 7  Epoch: 487  Training loss = 2.7443  Validation loss = 2.8891  \n",
      "\n",
      "Fold: 7  Epoch: 488  Training loss = 2.7441  Validation loss = 2.8889  \n",
      "\n",
      "Fold: 7  Epoch: 489  Training loss = 2.7440  Validation loss = 2.8886  \n",
      "\n",
      "Fold: 7  Epoch: 490  Training loss = 2.7438  Validation loss = 2.8884  \n",
      "\n",
      "Fold: 7  Epoch: 491  Training loss = 2.7436  Validation loss = 2.8881  \n",
      "\n",
      "Fold: 7  Epoch: 492  Training loss = 2.7434  Validation loss = 2.8879  \n",
      "\n",
      "Fold: 7  Epoch: 493  Training loss = 2.7433  Validation loss = 2.8877  \n",
      "\n",
      "Fold: 7  Epoch: 494  Training loss = 2.7431  Validation loss = 2.8874  \n",
      "\n",
      "Fold: 7  Epoch: 495  Training loss = 2.7429  Validation loss = 2.8872  \n",
      "\n",
      "Fold: 7  Epoch: 496  Training loss = 2.7428  Validation loss = 2.8869  \n",
      "\n",
      "Fold: 7  Epoch: 497  Training loss = 2.7426  Validation loss = 2.8867  \n",
      "\n",
      "Fold: 7  Epoch: 498  Training loss = 2.7424  Validation loss = 2.8865  \n",
      "\n",
      "Fold: 7  Epoch: 499  Training loss = 2.7422  Validation loss = 2.8862  \n",
      "\n",
      "Fold: 7  Epoch: 500  Training loss = 2.7421  Validation loss = 2.8860  \n",
      "\n",
      "Check model:  Fold: 7  Optimal epoch: 500  \n",
      "\n",
      "Fold: 8  Epoch: 1  Training loss = 2.7852  Validation loss = 7.7663  \n",
      "\n",
      "Fold: 8  Epoch: 2  Training loss = 2.7850  Validation loss = 7.7661  \n",
      "\n",
      "Fold: 8  Epoch: 3  Training loss = 2.7848  Validation loss = 7.7658  \n",
      "\n",
      "Fold: 8  Epoch: 4  Training loss = 2.7845  Validation loss = 7.7656  \n",
      "\n",
      "Fold: 8  Epoch: 5  Training loss = 2.7844  Validation loss = 7.7654  \n",
      "\n",
      "Fold: 8  Epoch: 6  Training loss = 2.7841  Validation loss = 7.7651  \n",
      "\n",
      "Fold: 8  Epoch: 7  Training loss = 2.7840  Validation loss = 7.7649  \n",
      "\n",
      "Fold: 8  Epoch: 8  Training loss = 2.7838  Validation loss = 7.7647  \n",
      "\n",
      "Fold: 8  Epoch: 9  Training loss = 2.7835  Validation loss = 7.7645  \n",
      "\n",
      "Fold: 8  Epoch: 10  Training loss = 2.7833  Validation loss = 7.7643  \n",
      "\n",
      "Fold: 8  Epoch: 11  Training loss = 2.7831  Validation loss = 7.7640  \n",
      "\n",
      "Fold: 8  Epoch: 12  Training loss = 2.7829  Validation loss = 7.7638  \n",
      "\n",
      "Fold: 8  Epoch: 13  Training loss = 2.7827  Validation loss = 7.7636  \n",
      "\n",
      "Fold: 8  Epoch: 14  Training loss = 2.7825  Validation loss = 7.7634  \n",
      "\n",
      "Fold: 8  Epoch: 15  Training loss = 2.7823  Validation loss = 7.7632  \n",
      "\n",
      "Fold: 8  Epoch: 16  Training loss = 2.7822  Validation loss = 7.7630  \n",
      "\n",
      "Fold: 8  Epoch: 17  Training loss = 2.7819  Validation loss = 7.7627  \n",
      "\n",
      "Fold: 8  Epoch: 18  Training loss = 2.7818  Validation loss = 7.7625  \n",
      "\n",
      "Fold: 8  Epoch: 19  Training loss = 2.7815  Validation loss = 7.7623  \n",
      "\n",
      "Fold: 8  Epoch: 20  Training loss = 2.7813  Validation loss = 7.7620  \n",
      "\n",
      "Fold: 8  Epoch: 21  Training loss = 2.7811  Validation loss = 7.7619  \n",
      "\n",
      "Fold: 8  Epoch: 22  Training loss = 2.7810  Validation loss = 7.7617  \n",
      "\n",
      "Fold: 8  Epoch: 23  Training loss = 2.7808  Validation loss = 7.7614  \n",
      "\n",
      "Fold: 8  Epoch: 24  Training loss = 2.7806  Validation loss = 7.7612  \n",
      "\n",
      "Fold: 8  Epoch: 25  Training loss = 2.7804  Validation loss = 7.7610  \n",
      "\n",
      "Fold: 8  Epoch: 26  Training loss = 2.7802  Validation loss = 7.7608  \n",
      "\n",
      "Fold: 8  Epoch: 27  Training loss = 2.7800  Validation loss = 7.7605  \n",
      "\n",
      "Fold: 8  Epoch: 28  Training loss = 2.7797  Validation loss = 7.7603  \n",
      "\n",
      "Fold: 8  Epoch: 29  Training loss = 2.7795  Validation loss = 7.7601  \n",
      "\n",
      "Fold: 8  Epoch: 30  Training loss = 2.7793  Validation loss = 7.7598  \n",
      "\n",
      "Fold: 8  Epoch: 31  Training loss = 2.7791  Validation loss = 7.7596  \n",
      "\n",
      "Fold: 8  Epoch: 32  Training loss = 2.7789  Validation loss = 7.7593  \n",
      "\n",
      "Fold: 8  Epoch: 33  Training loss = 2.7787  Validation loss = 7.7591  \n",
      "\n",
      "Fold: 8  Epoch: 34  Training loss = 2.7785  Validation loss = 7.7589  \n",
      "\n",
      "Fold: 8  Epoch: 35  Training loss = 2.7783  Validation loss = 7.7587  \n",
      "\n",
      "Fold: 8  Epoch: 36  Training loss = 2.7781  Validation loss = 7.7584  \n",
      "\n",
      "Fold: 8  Epoch: 37  Training loss = 2.7779  Validation loss = 7.7582  \n",
      "\n",
      "Fold: 8  Epoch: 38  Training loss = 2.7776  Validation loss = 7.7580  \n",
      "\n",
      "Fold: 8  Epoch: 39  Training loss = 2.7774  Validation loss = 7.7577  \n",
      "\n",
      "Fold: 8  Epoch: 40  Training loss = 2.7772  Validation loss = 7.7575  \n",
      "\n",
      "Fold: 8  Epoch: 41  Training loss = 2.7769  Validation loss = 7.7572  \n",
      "\n",
      "Fold: 8  Epoch: 42  Training loss = 2.7768  Validation loss = 7.7570  \n",
      "\n",
      "Fold: 8  Epoch: 43  Training loss = 2.7765  Validation loss = 7.7568  \n",
      "\n",
      "Fold: 8  Epoch: 44  Training loss = 2.7763  Validation loss = 7.7565  \n",
      "\n",
      "Fold: 8  Epoch: 45  Training loss = 2.7761  Validation loss = 7.7563  \n",
      "\n",
      "Fold: 8  Epoch: 46  Training loss = 2.7759  Validation loss = 7.7561  \n",
      "\n",
      "Fold: 8  Epoch: 47  Training loss = 2.7757  Validation loss = 7.7558  \n",
      "\n",
      "Fold: 8  Epoch: 48  Training loss = 2.7755  Validation loss = 7.7556  \n",
      "\n",
      "Fold: 8  Epoch: 49  Training loss = 2.7753  Validation loss = 7.7554  \n",
      "\n",
      "Fold: 8  Epoch: 50  Training loss = 2.7751  Validation loss = 7.7552  \n",
      "\n",
      "Fold: 8  Epoch: 51  Training loss = 2.7749  Validation loss = 7.7550  \n",
      "\n",
      "Fold: 8  Epoch: 52  Training loss = 2.7747  Validation loss = 7.7547  \n",
      "\n",
      "Fold: 8  Epoch: 53  Training loss = 2.7745  Validation loss = 7.7545  \n",
      "\n",
      "Fold: 8  Epoch: 54  Training loss = 2.7742  Validation loss = 7.7543  \n",
      "\n",
      "Fold: 8  Epoch: 55  Training loss = 2.7740  Validation loss = 7.7540  \n",
      "\n",
      "Fold: 8  Epoch: 56  Training loss = 2.7738  Validation loss = 7.7538  \n",
      "\n",
      "Fold: 8  Epoch: 57  Training loss = 2.7736  Validation loss = 7.7535  \n",
      "\n",
      "Fold: 8  Epoch: 58  Training loss = 2.7734  Validation loss = 7.7533  \n",
      "\n",
      "Fold: 8  Epoch: 59  Training loss = 2.7732  Validation loss = 7.7531  \n",
      "\n",
      "Fold: 8  Epoch: 60  Training loss = 2.7730  Validation loss = 7.7529  \n",
      "\n",
      "Fold: 8  Epoch: 61  Training loss = 2.7728  Validation loss = 7.7526  \n",
      "\n",
      "Fold: 8  Epoch: 62  Training loss = 2.7726  Validation loss = 7.7524  \n",
      "\n",
      "Fold: 8  Epoch: 63  Training loss = 2.7723  Validation loss = 7.7521  \n",
      "\n",
      "Fold: 8  Epoch: 64  Training loss = 2.7721  Validation loss = 7.7519  \n",
      "\n",
      "Fold: 8  Epoch: 65  Training loss = 2.7719  Validation loss = 7.7517  \n",
      "\n",
      "Fold: 8  Epoch: 66  Training loss = 2.7717  Validation loss = 7.7514  \n",
      "\n",
      "Fold: 8  Epoch: 67  Training loss = 2.7715  Validation loss = 7.7512  \n",
      "\n",
      "Fold: 8  Epoch: 68  Training loss = 2.7713  Validation loss = 7.7510  \n",
      "\n",
      "Fold: 8  Epoch: 69  Training loss = 2.7711  Validation loss = 7.7507  \n",
      "\n",
      "Fold: 8  Epoch: 70  Training loss = 2.7709  Validation loss = 7.7505  \n",
      "\n",
      "Fold: 8  Epoch: 71  Training loss = 2.7707  Validation loss = 7.7503  \n",
      "\n",
      "Fold: 8  Epoch: 72  Training loss = 2.7705  Validation loss = 7.7501  \n",
      "\n",
      "Fold: 8  Epoch: 73  Training loss = 2.7703  Validation loss = 7.7499  \n",
      "\n",
      "Fold: 8  Epoch: 74  Training loss = 2.7701  Validation loss = 7.7496  \n",
      "\n",
      "Fold: 8  Epoch: 75  Training loss = 2.7698  Validation loss = 7.7494  \n",
      "\n",
      "Fold: 8  Epoch: 76  Training loss = 2.7696  Validation loss = 7.7491  \n",
      "\n",
      "Fold: 8  Epoch: 77  Training loss = 2.7695  Validation loss = 7.7489  \n",
      "\n",
      "Fold: 8  Epoch: 78  Training loss = 2.7692  Validation loss = 7.7487  \n",
      "\n",
      "Fold: 8  Epoch: 79  Training loss = 2.7690  Validation loss = 7.7484  \n",
      "\n",
      "Fold: 8  Epoch: 80  Training loss = 2.7688  Validation loss = 7.7482  \n",
      "\n",
      "Fold: 8  Epoch: 81  Training loss = 2.7686  Validation loss = 7.7480  \n",
      "\n",
      "Fold: 8  Epoch: 82  Training loss = 2.7684  Validation loss = 7.7478  \n",
      "\n",
      "Fold: 8  Epoch: 83  Training loss = 2.7682  Validation loss = 7.7476  \n",
      "\n",
      "Fold: 8  Epoch: 84  Training loss = 2.7680  Validation loss = 7.7474  \n",
      "\n",
      "Fold: 8  Epoch: 85  Training loss = 2.7678  Validation loss = 7.7471  \n",
      "\n",
      "Fold: 8  Epoch: 86  Training loss = 2.7676  Validation loss = 7.7470  \n",
      "\n",
      "Fold: 8  Epoch: 87  Training loss = 2.7674  Validation loss = 7.7467  \n",
      "\n",
      "Fold: 8  Epoch: 88  Training loss = 2.7672  Validation loss = 7.7465  \n",
      "\n",
      "Fold: 8  Epoch: 89  Training loss = 2.7671  Validation loss = 7.7463  \n",
      "\n",
      "Fold: 8  Epoch: 90  Training loss = 2.7669  Validation loss = 7.7461  \n",
      "\n",
      "Fold: 8  Epoch: 91  Training loss = 2.7667  Validation loss = 7.7459  \n",
      "\n",
      "Fold: 8  Epoch: 92  Training loss = 2.7665  Validation loss = 7.7457  \n",
      "\n",
      "Fold: 8  Epoch: 93  Training loss = 2.7663  Validation loss = 7.7455  \n",
      "\n",
      "Fold: 8  Epoch: 94  Training loss = 2.7661  Validation loss = 7.7453  \n",
      "\n",
      "Fold: 8  Epoch: 95  Training loss = 2.7660  Validation loss = 7.7451  \n",
      "\n",
      "Fold: 8  Epoch: 96  Training loss = 2.7658  Validation loss = 7.7449  \n",
      "\n",
      "Fold: 8  Epoch: 97  Training loss = 2.7655  Validation loss = 7.7446  \n",
      "\n",
      "Fold: 8  Epoch: 98  Training loss = 2.7654  Validation loss = 7.7444  \n",
      "\n",
      "Fold: 8  Epoch: 99  Training loss = 2.7652  Validation loss = 7.7442  \n",
      "\n",
      "Fold: 8  Epoch: 100  Training loss = 2.7650  Validation loss = 7.7440  \n",
      "\n",
      "Fold: 8  Epoch: 101  Training loss = 2.7648  Validation loss = 7.7438  \n",
      "\n",
      "Fold: 8  Epoch: 102  Training loss = 2.7646  Validation loss = 7.7436  \n",
      "\n",
      "Fold: 8  Epoch: 103  Training loss = 2.7644  Validation loss = 7.7433  \n",
      "\n",
      "Fold: 8  Epoch: 104  Training loss = 2.7642  Validation loss = 7.7431  \n",
      "\n",
      "Fold: 8  Epoch: 105  Training loss = 2.7640  Validation loss = 7.7429  \n",
      "\n",
      "Fold: 8  Epoch: 106  Training loss = 2.7638  Validation loss = 7.7427  \n",
      "\n",
      "Fold: 8  Epoch: 107  Training loss = 2.7636  Validation loss = 7.7425  \n",
      "\n",
      "Fold: 8  Epoch: 108  Training loss = 2.7634  Validation loss = 7.7423  \n",
      "\n",
      "Fold: 8  Epoch: 109  Training loss = 2.7632  Validation loss = 7.7421  \n",
      "\n",
      "Fold: 8  Epoch: 110  Training loss = 2.7630  Validation loss = 7.7418  \n",
      "\n",
      "Fold: 8  Epoch: 111  Training loss = 2.7628  Validation loss = 7.7416  \n",
      "\n",
      "Fold: 8  Epoch: 112  Training loss = 2.7626  Validation loss = 7.7414  \n",
      "\n",
      "Fold: 8  Epoch: 113  Training loss = 2.7624  Validation loss = 7.7412  \n",
      "\n",
      "Fold: 8  Epoch: 114  Training loss = 2.7622  Validation loss = 7.7409  \n",
      "\n",
      "Fold: 8  Epoch: 115  Training loss = 2.7620  Validation loss = 7.7407  \n",
      "\n",
      "Fold: 8  Epoch: 116  Training loss = 2.7618  Validation loss = 7.7405  \n",
      "\n",
      "Fold: 8  Epoch: 117  Training loss = 2.7616  Validation loss = 7.7403  \n",
      "\n",
      "Fold: 8  Epoch: 118  Training loss = 2.7614  Validation loss = 7.7400  \n",
      "\n",
      "Fold: 8  Epoch: 119  Training loss = 2.7612  Validation loss = 7.7398  \n",
      "\n",
      "Fold: 8  Epoch: 120  Training loss = 2.7610  Validation loss = 7.7396  \n",
      "\n",
      "Fold: 8  Epoch: 121  Training loss = 2.7608  Validation loss = 7.7394  \n",
      "\n",
      "Fold: 8  Epoch: 122  Training loss = 2.7606  Validation loss = 7.7392  \n",
      "\n",
      "Fold: 8  Epoch: 123  Training loss = 2.7604  Validation loss = 7.7390  \n",
      "\n",
      "Fold: 8  Epoch: 124  Training loss = 2.7602  Validation loss = 7.7388  \n",
      "\n",
      "Fold: 8  Epoch: 125  Training loss = 2.7601  Validation loss = 7.7386  \n",
      "\n",
      "Fold: 8  Epoch: 126  Training loss = 2.7599  Validation loss = 7.7384  \n",
      "\n",
      "Fold: 8  Epoch: 127  Training loss = 2.7596  Validation loss = 7.7381  \n",
      "\n",
      "Fold: 8  Epoch: 128  Training loss = 2.7594  Validation loss = 7.7379  \n",
      "\n",
      "Fold: 8  Epoch: 129  Training loss = 2.7591  Validation loss = 7.7376  \n",
      "\n",
      "Fold: 8  Epoch: 130  Training loss = 2.7589  Validation loss = 7.7374  \n",
      "\n",
      "Fold: 8  Epoch: 131  Training loss = 2.7587  Validation loss = 7.7372  \n",
      "\n",
      "Fold: 8  Epoch: 132  Training loss = 2.7586  Validation loss = 7.7370  \n",
      "\n",
      "Fold: 8  Epoch: 133  Training loss = 2.7584  Validation loss = 7.7367  \n",
      "\n",
      "Fold: 8  Epoch: 134  Training loss = 2.7581  Validation loss = 7.7365  \n",
      "\n",
      "Fold: 8  Epoch: 135  Training loss = 2.7580  Validation loss = 7.7363  \n",
      "\n",
      "Fold: 8  Epoch: 136  Training loss = 2.7578  Validation loss = 7.7361  \n",
      "\n",
      "Fold: 8  Epoch: 137  Training loss = 2.7575  Validation loss = 7.7358  \n",
      "\n",
      "Fold: 8  Epoch: 138  Training loss = 2.7573  Validation loss = 7.7356  \n",
      "\n",
      "Fold: 8  Epoch: 139  Training loss = 2.7571  Validation loss = 7.7354  \n",
      "\n",
      "Fold: 8  Epoch: 140  Training loss = 2.7569  Validation loss = 7.7352  \n",
      "\n",
      "Fold: 8  Epoch: 141  Training loss = 2.7567  Validation loss = 7.7349  \n",
      "\n",
      "Fold: 8  Epoch: 142  Training loss = 2.7565  Validation loss = 7.7347  \n",
      "\n",
      "Fold: 8  Epoch: 143  Training loss = 2.7563  Validation loss = 7.7345  \n",
      "\n",
      "Fold: 8  Epoch: 144  Training loss = 2.7561  Validation loss = 7.7343  \n",
      "\n",
      "Fold: 8  Epoch: 145  Training loss = 2.7559  Validation loss = 7.7341  \n",
      "\n",
      "Fold: 8  Epoch: 146  Training loss = 2.7557  Validation loss = 7.7339  \n",
      "\n",
      "Fold: 8  Epoch: 147  Training loss = 2.7555  Validation loss = 7.7336  \n",
      "\n",
      "Fold: 8  Epoch: 148  Training loss = 2.7553  Validation loss = 7.7334  \n",
      "\n",
      "Fold: 8  Epoch: 149  Training loss = 2.7551  Validation loss = 7.7332  \n",
      "\n",
      "Fold: 8  Epoch: 150  Training loss = 2.7549  Validation loss = 7.7330  \n",
      "\n",
      "Fold: 8  Epoch: 151  Training loss = 2.7547  Validation loss = 7.7327  \n",
      "\n",
      "Fold: 8  Epoch: 152  Training loss = 2.7545  Validation loss = 7.7325  \n",
      "\n",
      "Fold: 8  Epoch: 153  Training loss = 2.7543  Validation loss = 7.7323  \n",
      "\n",
      "Fold: 8  Epoch: 154  Training loss = 2.7540  Validation loss = 7.7320  \n",
      "\n",
      "Fold: 8  Epoch: 155  Training loss = 2.7538  Validation loss = 7.7318  \n",
      "\n",
      "Fold: 8  Epoch: 156  Training loss = 2.7537  Validation loss = 7.7316  \n",
      "\n",
      "Fold: 8  Epoch: 157  Training loss = 2.7534  Validation loss = 7.7314  \n",
      "\n",
      "Fold: 8  Epoch: 158  Training loss = 2.7532  Validation loss = 7.7311  \n",
      "\n",
      "Fold: 8  Epoch: 159  Training loss = 2.7530  Validation loss = 7.7310  \n",
      "\n",
      "Fold: 8  Epoch: 160  Training loss = 2.7529  Validation loss = 7.7307  \n",
      "\n",
      "Fold: 8  Epoch: 161  Training loss = 2.7527  Validation loss = 7.7305  \n",
      "\n",
      "Fold: 8  Epoch: 162  Training loss = 2.7524  Validation loss = 7.7303  \n",
      "\n",
      "Fold: 8  Epoch: 163  Training loss = 2.7523  Validation loss = 7.7301  \n",
      "\n",
      "Fold: 8  Epoch: 164  Training loss = 2.7520  Validation loss = 7.7299  \n",
      "\n",
      "Fold: 8  Epoch: 165  Training loss = 2.7518  Validation loss = 7.7296  \n",
      "\n",
      "Fold: 8  Epoch: 166  Training loss = 2.7517  Validation loss = 7.7295  \n",
      "\n",
      "Fold: 8  Epoch: 167  Training loss = 2.7515  Validation loss = 7.7293  \n",
      "\n",
      "Fold: 8  Epoch: 168  Training loss = 2.7513  Validation loss = 7.7291  \n",
      "\n",
      "Fold: 8  Epoch: 169  Training loss = 2.7512  Validation loss = 7.7289  \n",
      "\n",
      "Fold: 8  Epoch: 170  Training loss = 2.7509  Validation loss = 7.7286  \n",
      "\n",
      "Fold: 8  Epoch: 171  Training loss = 2.7507  Validation loss = 7.7284  \n",
      "\n",
      "Fold: 8  Epoch: 172  Training loss = 2.7505  Validation loss = 7.7282  \n",
      "\n",
      "Fold: 8  Epoch: 173  Training loss = 2.7503  Validation loss = 7.7279  \n",
      "\n",
      "Fold: 8  Epoch: 174  Training loss = 2.7501  Validation loss = 7.7277  \n",
      "\n",
      "Fold: 8  Epoch: 175  Training loss = 2.7499  Validation loss = 7.7275  \n",
      "\n",
      "Fold: 8  Epoch: 176  Training loss = 2.7498  Validation loss = 7.7274  \n",
      "\n",
      "Fold: 8  Epoch: 177  Training loss = 2.7496  Validation loss = 7.7271  \n",
      "\n",
      "Fold: 8  Epoch: 178  Training loss = 2.7493  Validation loss = 7.7269  \n",
      "\n",
      "Fold: 8  Epoch: 179  Training loss = 2.7491  Validation loss = 7.7267  \n",
      "\n",
      "Fold: 8  Epoch: 180  Training loss = 2.7489  Validation loss = 7.7264  \n",
      "\n",
      "Fold: 8  Epoch: 181  Training loss = 2.7487  Validation loss = 7.7262  \n",
      "\n",
      "Fold: 8  Epoch: 182  Training loss = 2.7485  Validation loss = 7.7260  \n",
      "\n",
      "Fold: 8  Epoch: 183  Training loss = 2.7483  Validation loss = 7.7258  \n",
      "\n",
      "Fold: 8  Epoch: 184  Training loss = 2.7481  Validation loss = 7.7256  \n",
      "\n",
      "Fold: 8  Epoch: 185  Training loss = 2.7479  Validation loss = 7.7254  \n",
      "\n",
      "Fold: 8  Epoch: 186  Training loss = 2.7477  Validation loss = 7.7251  \n",
      "\n",
      "Fold: 8  Epoch: 187  Training loss = 2.7475  Validation loss = 7.7249  \n",
      "\n",
      "Fold: 8  Epoch: 188  Training loss = 2.7473  Validation loss = 7.7247  \n",
      "\n",
      "Fold: 8  Epoch: 189  Training loss = 2.7471  Validation loss = 7.7245  \n",
      "\n",
      "Fold: 8  Epoch: 190  Training loss = 2.7469  Validation loss = 7.7243  \n",
      "\n",
      "Fold: 8  Epoch: 191  Training loss = 2.7468  Validation loss = 7.7241  \n",
      "\n",
      "Fold: 8  Epoch: 192  Training loss = 2.7466  Validation loss = 7.7239  \n",
      "\n",
      "Fold: 8  Epoch: 193  Training loss = 2.7463  Validation loss = 7.7236  \n",
      "\n",
      "Fold: 8  Epoch: 194  Training loss = 2.7462  Validation loss = 7.7234  \n",
      "\n",
      "Fold: 8  Epoch: 195  Training loss = 2.7459  Validation loss = 7.7232  \n",
      "\n",
      "Fold: 8  Epoch: 196  Training loss = 2.7457  Validation loss = 7.7230  \n",
      "\n",
      "Fold: 8  Epoch: 197  Training loss = 2.7455  Validation loss = 7.7227  \n",
      "\n",
      "Fold: 8  Epoch: 198  Training loss = 2.7453  Validation loss = 7.7225  \n",
      "\n",
      "Fold: 8  Epoch: 199  Training loss = 2.7451  Validation loss = 7.7223  \n",
      "\n",
      "Fold: 8  Epoch: 200  Training loss = 2.7449  Validation loss = 7.7221  \n",
      "\n",
      "Fold: 8  Epoch: 201  Training loss = 2.7448  Validation loss = 7.7219  \n",
      "\n",
      "Fold: 8  Epoch: 202  Training loss = 2.7446  Validation loss = 7.7217  \n",
      "\n",
      "Fold: 8  Epoch: 203  Training loss = 2.7444  Validation loss = 7.7215  \n",
      "\n",
      "Fold: 8  Epoch: 204  Training loss = 2.7442  Validation loss = 7.7213  \n",
      "\n",
      "Fold: 8  Epoch: 205  Training loss = 2.7440  Validation loss = 7.7211  \n",
      "\n",
      "Fold: 8  Epoch: 206  Training loss = 2.7438  Validation loss = 7.7208  \n",
      "\n",
      "Fold: 8  Epoch: 207  Training loss = 2.7436  Validation loss = 7.7206  \n",
      "\n",
      "Fold: 8  Epoch: 208  Training loss = 2.7434  Validation loss = 7.7204  \n",
      "\n",
      "Fold: 8  Epoch: 209  Training loss = 2.7432  Validation loss = 7.7202  \n",
      "\n",
      "Fold: 8  Epoch: 210  Training loss = 2.7430  Validation loss = 7.7200  \n",
      "\n",
      "Fold: 8  Epoch: 211  Training loss = 2.7428  Validation loss = 7.7197  \n",
      "\n",
      "Fold: 8  Epoch: 212  Training loss = 2.7426  Validation loss = 7.7195  \n",
      "\n",
      "Fold: 8  Epoch: 213  Training loss = 2.7424  Validation loss = 7.7193  \n",
      "\n",
      "Fold: 8  Epoch: 214  Training loss = 2.7423  Validation loss = 7.7191  \n",
      "\n",
      "Fold: 8  Epoch: 215  Training loss = 2.7421  Validation loss = 7.7189  \n",
      "\n",
      "Fold: 8  Epoch: 216  Training loss = 2.7419  Validation loss = 7.7187  \n",
      "\n",
      "Fold: 8  Epoch: 217  Training loss = 2.7417  Validation loss = 7.7185  \n",
      "\n",
      "Fold: 8  Epoch: 218  Training loss = 2.7415  Validation loss = 7.7183  \n",
      "\n",
      "Fold: 8  Epoch: 219  Training loss = 2.7413  Validation loss = 7.7181  \n",
      "\n",
      "Fold: 8  Epoch: 220  Training loss = 2.7411  Validation loss = 7.7179  \n",
      "\n",
      "Fold: 8  Epoch: 221  Training loss = 2.7409  Validation loss = 7.7177  \n",
      "\n",
      "Fold: 8  Epoch: 222  Training loss = 2.7407  Validation loss = 7.7174  \n",
      "\n",
      "Fold: 8  Epoch: 223  Training loss = 2.7405  Validation loss = 7.7172  \n",
      "\n",
      "Fold: 8  Epoch: 224  Training loss = 2.7403  Validation loss = 7.7170  \n",
      "\n",
      "Fold: 8  Epoch: 225  Training loss = 2.7401  Validation loss = 7.7168  \n",
      "\n",
      "Fold: 8  Epoch: 226  Training loss = 2.7399  Validation loss = 7.7166  \n",
      "\n",
      "Fold: 8  Epoch: 227  Training loss = 2.7397  Validation loss = 7.7164  \n",
      "\n",
      "Fold: 8  Epoch: 228  Training loss = 2.7395  Validation loss = 7.7162  \n",
      "\n",
      "Fold: 8  Epoch: 229  Training loss = 2.7393  Validation loss = 7.7159  \n",
      "\n",
      "Fold: 8  Epoch: 230  Training loss = 2.7391  Validation loss = 7.7157  \n",
      "\n",
      "Fold: 8  Epoch: 231  Training loss = 2.7389  Validation loss = 7.7155  \n",
      "\n",
      "Fold: 8  Epoch: 232  Training loss = 2.7387  Validation loss = 7.7153  \n",
      "\n",
      "Fold: 8  Epoch: 233  Training loss = 2.7385  Validation loss = 7.7151  \n",
      "\n",
      "Fold: 8  Epoch: 234  Training loss = 2.7383  Validation loss = 7.7149  \n",
      "\n",
      "Fold: 8  Epoch: 235  Training loss = 2.7381  Validation loss = 7.7147  \n",
      "\n",
      "Fold: 8  Epoch: 236  Training loss = 2.7380  Validation loss = 7.7145  \n",
      "\n",
      "Fold: 8  Epoch: 237  Training loss = 2.7378  Validation loss = 7.7143  \n",
      "\n",
      "Fold: 8  Epoch: 238  Training loss = 2.7376  Validation loss = 7.7141  \n",
      "\n",
      "Fold: 8  Epoch: 239  Training loss = 2.7374  Validation loss = 7.7139  \n",
      "\n",
      "Fold: 8  Epoch: 240  Training loss = 2.7372  Validation loss = 7.7137  \n",
      "\n",
      "Fold: 8  Epoch: 241  Training loss = 2.7370  Validation loss = 7.7134  \n",
      "\n",
      "Fold: 8  Epoch: 242  Training loss = 2.7368  Validation loss = 7.7132  \n",
      "\n",
      "Fold: 8  Epoch: 243  Training loss = 2.7365  Validation loss = 7.7130  \n",
      "\n",
      "Fold: 8  Epoch: 244  Training loss = 2.7363  Validation loss = 7.7128  \n",
      "\n",
      "Fold: 8  Epoch: 245  Training loss = 2.7362  Validation loss = 7.7125  \n",
      "\n",
      "Fold: 8  Epoch: 246  Training loss = 2.7360  Validation loss = 7.7123  \n",
      "\n",
      "Fold: 8  Epoch: 247  Training loss = 2.7358  Validation loss = 7.7122  \n",
      "\n",
      "Fold: 8  Epoch: 248  Training loss = 2.7356  Validation loss = 7.7119  \n",
      "\n",
      "Fold: 8  Epoch: 249  Training loss = 2.7354  Validation loss = 7.7117  \n",
      "\n",
      "Fold: 8  Epoch: 250  Training loss = 2.7352  Validation loss = 7.7115  \n",
      "\n",
      "Fold: 8  Epoch: 251  Training loss = 2.7349  Validation loss = 7.7112  \n",
      "\n",
      "Fold: 8  Epoch: 252  Training loss = 2.7348  Validation loss = 7.7111  \n",
      "\n",
      "Fold: 8  Epoch: 253  Training loss = 2.7346  Validation loss = 7.7108  \n",
      "\n",
      "Fold: 8  Epoch: 254  Training loss = 2.7344  Validation loss = 7.7106  \n",
      "\n",
      "Fold: 8  Epoch: 255  Training loss = 2.7342  Validation loss = 7.7104  \n",
      "\n",
      "Fold: 8  Epoch: 256  Training loss = 2.7340  Validation loss = 7.7102  \n",
      "\n",
      "Fold: 8  Epoch: 257  Training loss = 2.7337  Validation loss = 7.7099  \n",
      "\n",
      "Fold: 8  Epoch: 258  Training loss = 2.7335  Validation loss = 7.7097  \n",
      "\n",
      "Fold: 8  Epoch: 259  Training loss = 2.7333  Validation loss = 7.7095  \n",
      "\n",
      "Fold: 8  Epoch: 260  Training loss = 2.7331  Validation loss = 7.7093  \n",
      "\n",
      "Fold: 8  Epoch: 261  Training loss = 2.7329  Validation loss = 7.7091  \n",
      "\n",
      "Fold: 8  Epoch: 262  Training loss = 2.7327  Validation loss = 7.7089  \n",
      "\n",
      "Fold: 8  Epoch: 263  Training loss = 2.7325  Validation loss = 7.7086  \n",
      "\n",
      "Fold: 8  Epoch: 264  Training loss = 2.7323  Validation loss = 7.7084  \n",
      "\n",
      "Fold: 8  Epoch: 265  Training loss = 2.7322  Validation loss = 7.7082  \n",
      "\n",
      "Fold: 8  Epoch: 266  Training loss = 2.7320  Validation loss = 7.7080  \n",
      "\n",
      "Fold: 8  Epoch: 267  Training loss = 2.7318  Validation loss = 7.7078  \n",
      "\n",
      "Fold: 8  Epoch: 268  Training loss = 2.7316  Validation loss = 7.7076  \n",
      "\n",
      "Fold: 8  Epoch: 269  Training loss = 2.7313  Validation loss = 7.7074  \n",
      "\n",
      "Fold: 8  Epoch: 270  Training loss = 2.7312  Validation loss = 7.7072  \n",
      "\n",
      "Fold: 8  Epoch: 271  Training loss = 2.7310  Validation loss = 7.7070  \n",
      "\n",
      "Fold: 8  Epoch: 272  Training loss = 2.7308  Validation loss = 7.7067  \n",
      "\n",
      "Fold: 8  Epoch: 273  Training loss = 2.7305  Validation loss = 7.7064  \n",
      "\n",
      "Fold: 8  Epoch: 274  Training loss = 2.7303  Validation loss = 7.7062  \n",
      "\n",
      "Fold: 8  Epoch: 275  Training loss = 2.7301  Validation loss = 7.7060  \n",
      "\n",
      "Fold: 8  Epoch: 276  Training loss = 2.7299  Validation loss = 7.7058  \n",
      "\n",
      "Fold: 8  Epoch: 277  Training loss = 2.7297  Validation loss = 7.7056  \n",
      "\n",
      "Fold: 8  Epoch: 278  Training loss = 2.7295  Validation loss = 7.7054  \n",
      "\n",
      "Fold: 8  Epoch: 279  Training loss = 2.7293  Validation loss = 7.7051  \n",
      "\n",
      "Fold: 8  Epoch: 280  Training loss = 2.7291  Validation loss = 7.7049  \n",
      "\n",
      "Fold: 8  Epoch: 281  Training loss = 2.7289  Validation loss = 7.7047  \n",
      "\n",
      "Fold: 8  Epoch: 282  Training loss = 2.7286  Validation loss = 7.7045  \n",
      "\n",
      "Fold: 8  Epoch: 283  Training loss = 2.7284  Validation loss = 7.7042  \n",
      "\n",
      "Fold: 8  Epoch: 284  Training loss = 2.7283  Validation loss = 7.7040  \n",
      "\n",
      "Fold: 8  Epoch: 285  Training loss = 2.7281  Validation loss = 7.7038  \n",
      "\n",
      "Fold: 8  Epoch: 286  Training loss = 2.7279  Validation loss = 7.7036  \n",
      "\n",
      "Fold: 8  Epoch: 287  Training loss = 2.7277  Validation loss = 7.7034  \n",
      "\n",
      "Fold: 8  Epoch: 288  Training loss = 2.7275  Validation loss = 7.7032  \n",
      "\n",
      "Fold: 8  Epoch: 289  Training loss = 2.7273  Validation loss = 7.7029  \n",
      "\n",
      "Fold: 8  Epoch: 290  Training loss = 2.7271  Validation loss = 7.7028  \n",
      "\n",
      "Fold: 8  Epoch: 291  Training loss = 2.7269  Validation loss = 7.7025  \n",
      "\n",
      "Fold: 8  Epoch: 292  Training loss = 2.7267  Validation loss = 7.7023  \n",
      "\n",
      "Fold: 8  Epoch: 293  Training loss = 2.7265  Validation loss = 7.7021  \n",
      "\n",
      "Fold: 8  Epoch: 294  Training loss = 2.7263  Validation loss = 7.7019  \n",
      "\n",
      "Fold: 8  Epoch: 295  Training loss = 2.7261  Validation loss = 7.7017  \n",
      "\n",
      "Fold: 8  Epoch: 296  Training loss = 2.7259  Validation loss = 7.7015  \n",
      "\n",
      "Fold: 8  Epoch: 297  Training loss = 2.7257  Validation loss = 7.7013  \n",
      "\n",
      "Fold: 8  Epoch: 298  Training loss = 2.7255  Validation loss = 7.7010  \n",
      "\n",
      "Fold: 8  Epoch: 299  Training loss = 2.7253  Validation loss = 7.7008  \n",
      "\n",
      "Fold: 8  Epoch: 300  Training loss = 2.7251  Validation loss = 7.7006  \n",
      "\n",
      "Fold: 8  Epoch: 301  Training loss = 2.7249  Validation loss = 7.7004  \n",
      "\n",
      "Fold: 8  Epoch: 302  Training loss = 2.7247  Validation loss = 7.7002  \n",
      "\n",
      "Fold: 8  Epoch: 303  Training loss = 2.7245  Validation loss = 7.6999  \n",
      "\n",
      "Fold: 8  Epoch: 304  Training loss = 2.7243  Validation loss = 7.6997  \n",
      "\n",
      "Fold: 8  Epoch: 305  Training loss = 2.7242  Validation loss = 7.6995  \n",
      "\n",
      "Fold: 8  Epoch: 306  Training loss = 2.7240  Validation loss = 7.6993  \n",
      "\n",
      "Fold: 8  Epoch: 307  Training loss = 2.7238  Validation loss = 7.6991  \n",
      "\n",
      "Fold: 8  Epoch: 308  Training loss = 2.7236  Validation loss = 7.6989  \n",
      "\n",
      "Fold: 8  Epoch: 309  Training loss = 2.7234  Validation loss = 7.6987  \n",
      "\n",
      "Fold: 8  Epoch: 310  Training loss = 2.7232  Validation loss = 7.6985  \n",
      "\n",
      "Fold: 8  Epoch: 311  Training loss = 2.7230  Validation loss = 7.6983  \n",
      "\n",
      "Fold: 8  Epoch: 312  Training loss = 2.7228  Validation loss = 7.6981  \n",
      "\n",
      "Fold: 8  Epoch: 313  Training loss = 2.7226  Validation loss = 7.6979  \n",
      "\n",
      "Fold: 8  Epoch: 314  Training loss = 2.7224  Validation loss = 7.6976  \n",
      "\n",
      "Fold: 8  Epoch: 315  Training loss = 2.7222  Validation loss = 7.6974  \n",
      "\n",
      "Fold: 8  Epoch: 316  Training loss = 2.7220  Validation loss = 7.6972  \n",
      "\n",
      "Fold: 8  Epoch: 317  Training loss = 2.7218  Validation loss = 7.6970  \n",
      "\n",
      "Fold: 8  Epoch: 318  Training loss = 2.7217  Validation loss = 7.6968  \n",
      "\n",
      "Fold: 8  Epoch: 319  Training loss = 2.7215  Validation loss = 7.6966  \n",
      "\n",
      "Fold: 8  Epoch: 320  Training loss = 2.7213  Validation loss = 7.6964  \n",
      "\n",
      "Fold: 8  Epoch: 321  Training loss = 2.7211  Validation loss = 7.6962  \n",
      "\n",
      "Fold: 8  Epoch: 322  Training loss = 2.7208  Validation loss = 7.6959  \n",
      "\n",
      "Fold: 8  Epoch: 323  Training loss = 2.7206  Validation loss = 7.6957  \n",
      "\n",
      "Fold: 8  Epoch: 324  Training loss = 2.7204  Validation loss = 7.6955  \n",
      "\n",
      "Fold: 8  Epoch: 325  Training loss = 2.7201  Validation loss = 7.6952  \n",
      "\n",
      "Fold: 8  Epoch: 326  Training loss = 2.7199  Validation loss = 7.6950  \n",
      "\n",
      "Fold: 8  Epoch: 327  Training loss = 2.7197  Validation loss = 7.6947  \n",
      "\n",
      "Fold: 8  Epoch: 328  Training loss = 2.7195  Validation loss = 7.6946  \n",
      "\n",
      "Fold: 8  Epoch: 329  Training loss = 2.7194  Validation loss = 7.6944  \n",
      "\n",
      "Fold: 8  Epoch: 330  Training loss = 2.7192  Validation loss = 7.6942  \n",
      "\n",
      "Fold: 8  Epoch: 331  Training loss = 2.7190  Validation loss = 7.6940  \n",
      "\n",
      "Fold: 8  Epoch: 332  Training loss = 2.7188  Validation loss = 7.6938  \n",
      "\n",
      "Fold: 8  Epoch: 333  Training loss = 2.7186  Validation loss = 7.6936  \n",
      "\n",
      "Fold: 8  Epoch: 334  Training loss = 2.7184  Validation loss = 7.6934  \n",
      "\n",
      "Fold: 8  Epoch: 335  Training loss = 2.7182  Validation loss = 7.6932  \n",
      "\n",
      "Fold: 8  Epoch: 336  Training loss = 2.7180  Validation loss = 7.6929  \n",
      "\n",
      "Fold: 8  Epoch: 337  Training loss = 2.7178  Validation loss = 7.6927  \n",
      "\n",
      "Fold: 8  Epoch: 338  Training loss = 2.7176  Validation loss = 7.6925  \n",
      "\n",
      "Fold: 8  Epoch: 339  Training loss = 2.7174  Validation loss = 7.6923  \n",
      "\n",
      "Fold: 8  Epoch: 340  Training loss = 2.7172  Validation loss = 7.6921  \n",
      "\n",
      "Fold: 8  Epoch: 341  Training loss = 2.7170  Validation loss = 7.6918  \n",
      "\n",
      "Fold: 8  Epoch: 342  Training loss = 2.7167  Validation loss = 7.6916  \n",
      "\n",
      "Fold: 8  Epoch: 343  Training loss = 2.7165  Validation loss = 7.6913  \n",
      "\n",
      "Fold: 8  Epoch: 344  Training loss = 2.7163  Validation loss = 7.6911  \n",
      "\n",
      "Fold: 8  Epoch: 345  Training loss = 2.7161  Validation loss = 7.6909  \n",
      "\n",
      "Fold: 8  Epoch: 346  Training loss = 2.7160  Validation loss = 7.6907  \n",
      "\n",
      "Fold: 8  Epoch: 347  Training loss = 2.7157  Validation loss = 7.6905  \n",
      "\n",
      "Fold: 8  Epoch: 348  Training loss = 2.7155  Validation loss = 7.6903  \n",
      "\n",
      "Fold: 8  Epoch: 349  Training loss = 2.7154  Validation loss = 7.6901  \n",
      "\n",
      "Fold: 8  Epoch: 350  Training loss = 2.7152  Validation loss = 7.6899  \n",
      "\n",
      "Fold: 8  Epoch: 351  Training loss = 2.7150  Validation loss = 7.6897  \n",
      "\n",
      "Fold: 8  Epoch: 352  Training loss = 2.7148  Validation loss = 7.6894  \n",
      "\n",
      "Fold: 8  Epoch: 353  Training loss = 2.7145  Validation loss = 7.6892  \n",
      "\n",
      "Fold: 8  Epoch: 354  Training loss = 2.7144  Validation loss = 7.6890  \n",
      "\n",
      "Fold: 8  Epoch: 355  Training loss = 2.7142  Validation loss = 7.6888  \n",
      "\n",
      "Fold: 8  Epoch: 356  Training loss = 2.7140  Validation loss = 7.6886  \n",
      "\n",
      "Fold: 8  Epoch: 357  Training loss = 2.7138  Validation loss = 7.6883  \n",
      "\n",
      "Fold: 8  Epoch: 358  Training loss = 2.7136  Validation loss = 7.6881  \n",
      "\n",
      "Fold: 8  Epoch: 359  Training loss = 2.7134  Validation loss = 7.6879  \n",
      "\n",
      "Fold: 8  Epoch: 360  Training loss = 2.7132  Validation loss = 7.6878  \n",
      "\n",
      "Fold: 8  Epoch: 361  Training loss = 2.7130  Validation loss = 7.6876  \n",
      "\n",
      "Fold: 8  Epoch: 362  Training loss = 2.7128  Validation loss = 7.6873  \n",
      "\n",
      "Fold: 8  Epoch: 363  Training loss = 2.7126  Validation loss = 7.6871  \n",
      "\n",
      "Fold: 8  Epoch: 364  Training loss = 2.7125  Validation loss = 7.6869  \n",
      "\n",
      "Fold: 8  Epoch: 365  Training loss = 2.7123  Validation loss = 7.6868  \n",
      "\n",
      "Fold: 8  Epoch: 366  Training loss = 2.7121  Validation loss = 7.6865  \n",
      "\n",
      "Fold: 8  Epoch: 367  Training loss = 2.7120  Validation loss = 7.6864  \n",
      "\n",
      "Fold: 8  Epoch: 368  Training loss = 2.7118  Validation loss = 7.6862  \n",
      "\n",
      "Fold: 8  Epoch: 369  Training loss = 2.7116  Validation loss = 7.6860  \n",
      "\n",
      "Fold: 8  Epoch: 370  Training loss = 2.7114  Validation loss = 7.6858  \n",
      "\n",
      "Fold: 8  Epoch: 371  Training loss = 2.7112  Validation loss = 7.6856  \n",
      "\n",
      "Fold: 8  Epoch: 372  Training loss = 2.7111  Validation loss = 7.6854  \n",
      "\n",
      "Fold: 8  Epoch: 373  Training loss = 2.7109  Validation loss = 7.6852  \n",
      "\n",
      "Fold: 8  Epoch: 374  Training loss = 2.7107  Validation loss = 7.6850  \n",
      "\n",
      "Fold: 8  Epoch: 375  Training loss = 2.7105  Validation loss = 7.6847  \n",
      "\n",
      "Fold: 8  Epoch: 376  Training loss = 2.7103  Validation loss = 7.6845  \n",
      "\n",
      "Fold: 8  Epoch: 377  Training loss = 2.7101  Validation loss = 7.6843  \n",
      "\n",
      "Fold: 8  Epoch: 378  Training loss = 2.7099  Validation loss = 7.6842  \n",
      "\n",
      "Fold: 8  Epoch: 379  Training loss = 2.7097  Validation loss = 7.6839  \n",
      "\n",
      "Fold: 8  Epoch: 380  Training loss = 2.7095  Validation loss = 7.6837  \n",
      "\n",
      "Fold: 8  Epoch: 381  Training loss = 2.7093  Validation loss = 7.6835  \n",
      "\n",
      "Fold: 8  Epoch: 382  Training loss = 2.7090  Validation loss = 7.6832  \n",
      "\n",
      "Fold: 8  Epoch: 383  Training loss = 2.7089  Validation loss = 7.6830  \n",
      "\n",
      "Fold: 8  Epoch: 384  Training loss = 2.7087  Validation loss = 7.6828  \n",
      "\n",
      "Fold: 8  Epoch: 385  Training loss = 2.7085  Validation loss = 7.6826  \n",
      "\n",
      "Fold: 8  Epoch: 386  Training loss = 2.7083  Validation loss = 7.6824  \n",
      "\n",
      "Fold: 8  Epoch: 387  Training loss = 2.7081  Validation loss = 7.6822  \n",
      "\n",
      "Fold: 8  Epoch: 388  Training loss = 2.7079  Validation loss = 7.6820  \n",
      "\n",
      "Fold: 8  Epoch: 389  Training loss = 2.7077  Validation loss = 7.6817  \n",
      "\n",
      "Fold: 8  Epoch: 390  Training loss = 2.7075  Validation loss = 7.6815  \n",
      "\n",
      "Fold: 8  Epoch: 391  Training loss = 2.7073  Validation loss = 7.6813  \n",
      "\n",
      "Fold: 8  Epoch: 392  Training loss = 2.7070  Validation loss = 7.6811  \n",
      "\n",
      "Fold: 8  Epoch: 393  Training loss = 2.7068  Validation loss = 7.6808  \n",
      "\n",
      "Fold: 8  Epoch: 394  Training loss = 2.7066  Validation loss = 7.6806  \n",
      "\n",
      "Fold: 8  Epoch: 395  Training loss = 2.7064  Validation loss = 7.6804  \n",
      "\n",
      "Fold: 8  Epoch: 396  Training loss = 2.7063  Validation loss = 7.6802  \n",
      "\n",
      "Fold: 8  Epoch: 397  Training loss = 2.7061  Validation loss = 7.6800  \n",
      "\n",
      "Fold: 8  Epoch: 398  Training loss = 2.7059  Validation loss = 7.6798  \n",
      "\n",
      "Fold: 8  Epoch: 399  Training loss = 2.7057  Validation loss = 7.6796  \n",
      "\n",
      "Fold: 8  Epoch: 400  Training loss = 2.7055  Validation loss = 7.6794  \n",
      "\n",
      "Fold: 8  Epoch: 401  Training loss = 2.7053  Validation loss = 7.6792  \n",
      "\n",
      "Fold: 8  Epoch: 402  Training loss = 2.7051  Validation loss = 7.6790  \n",
      "\n",
      "Fold: 8  Epoch: 403  Training loss = 2.7049  Validation loss = 7.6788  \n",
      "\n",
      "Fold: 8  Epoch: 404  Training loss = 2.7047  Validation loss = 7.6785  \n",
      "\n",
      "Fold: 8  Epoch: 405  Training loss = 2.7044  Validation loss = 7.6783  \n",
      "\n",
      "Fold: 8  Epoch: 406  Training loss = 2.7043  Validation loss = 7.6781  \n",
      "\n",
      "Fold: 8  Epoch: 407  Training loss = 2.7041  Validation loss = 7.6779  \n",
      "\n",
      "Fold: 8  Epoch: 408  Training loss = 2.7039  Validation loss = 7.6777  \n",
      "\n",
      "Fold: 8  Epoch: 409  Training loss = 2.7037  Validation loss = 7.6775  \n",
      "\n",
      "Fold: 8  Epoch: 410  Training loss = 2.7036  Validation loss = 7.6773  \n",
      "\n",
      "Fold: 8  Epoch: 411  Training loss = 2.7034  Validation loss = 7.6771  \n",
      "\n",
      "Fold: 8  Epoch: 412  Training loss = 2.7032  Validation loss = 7.6769  \n",
      "\n",
      "Fold: 8  Epoch: 413  Training loss = 2.7030  Validation loss = 7.6767  \n",
      "\n",
      "Fold: 8  Epoch: 414  Training loss = 2.7029  Validation loss = 7.6765  \n",
      "\n",
      "Fold: 8  Epoch: 415  Training loss = 2.7027  Validation loss = 7.6763  \n",
      "\n",
      "Fold: 8  Epoch: 416  Training loss = 2.7025  Validation loss = 7.6761  \n",
      "\n",
      "Fold: 8  Epoch: 417  Training loss = 2.7022  Validation loss = 7.6759  \n",
      "\n",
      "Fold: 8  Epoch: 418  Training loss = 2.7021  Validation loss = 7.6757  \n",
      "\n",
      "Fold: 8  Epoch: 419  Training loss = 2.7018  Validation loss = 7.6754  \n",
      "\n",
      "Fold: 8  Epoch: 420  Training loss = 2.7017  Validation loss = 7.6753  \n",
      "\n",
      "Fold: 8  Epoch: 421  Training loss = 2.7014  Validation loss = 7.6750  \n",
      "\n",
      "Fold: 8  Epoch: 422  Training loss = 2.7012  Validation loss = 7.6748  \n",
      "\n",
      "Fold: 8  Epoch: 423  Training loss = 2.7010  Validation loss = 7.6746  \n",
      "\n",
      "Fold: 8  Epoch: 424  Training loss = 2.7008  Validation loss = 7.6743  \n",
      "\n",
      "Fold: 8  Epoch: 425  Training loss = 2.7006  Validation loss = 7.6741  \n",
      "\n",
      "Fold: 8  Epoch: 426  Training loss = 2.7004  Validation loss = 7.6739  \n",
      "\n",
      "Fold: 8  Epoch: 427  Training loss = 2.7002  Validation loss = 7.6737  \n",
      "\n",
      "Fold: 8  Epoch: 428  Training loss = 2.7000  Validation loss = 7.6735  \n",
      "\n",
      "Fold: 8  Epoch: 429  Training loss = 2.6998  Validation loss = 7.6733  \n",
      "\n",
      "Fold: 8  Epoch: 430  Training loss = 2.6996  Validation loss = 7.6731  \n",
      "\n",
      "Fold: 8  Epoch: 431  Training loss = 2.6994  Validation loss = 7.6729  \n",
      "\n",
      "Fold: 8  Epoch: 432  Training loss = 2.6993  Validation loss = 7.6727  \n",
      "\n",
      "Fold: 8  Epoch: 433  Training loss = 2.6991  Validation loss = 7.6725  \n",
      "\n",
      "Fold: 8  Epoch: 434  Training loss = 2.6989  Validation loss = 7.6723  \n",
      "\n",
      "Fold: 8  Epoch: 435  Training loss = 2.6987  Validation loss = 7.6721  \n",
      "\n",
      "Fold: 8  Epoch: 436  Training loss = 2.6985  Validation loss = 7.6719  \n",
      "\n",
      "Fold: 8  Epoch: 437  Training loss = 2.6982  Validation loss = 7.6716  \n",
      "\n",
      "Fold: 8  Epoch: 438  Training loss = 2.6980  Validation loss = 7.6714  \n",
      "\n",
      "Fold: 8  Epoch: 439  Training loss = 2.6978  Validation loss = 7.6711  \n",
      "\n",
      "Fold: 8  Epoch: 440  Training loss = 2.6976  Validation loss = 7.6709  \n",
      "\n",
      "Fold: 8  Epoch: 441  Training loss = 2.6974  Validation loss = 7.6707  \n",
      "\n",
      "Fold: 8  Epoch: 442  Training loss = 2.6972  Validation loss = 7.6705  \n",
      "\n",
      "Fold: 8  Epoch: 443  Training loss = 2.6971  Validation loss = 7.6703  \n",
      "\n",
      "Fold: 8  Epoch: 444  Training loss = 2.6969  Validation loss = 7.6701  \n",
      "\n",
      "Fold: 8  Epoch: 445  Training loss = 2.6966  Validation loss = 7.6699  \n",
      "\n",
      "Fold: 8  Epoch: 446  Training loss = 2.6964  Validation loss = 7.6696  \n",
      "\n",
      "Fold: 8  Epoch: 447  Training loss = 2.6962  Validation loss = 7.6694  \n",
      "\n",
      "Fold: 8  Epoch: 448  Training loss = 2.6960  Validation loss = 7.6692  \n",
      "\n",
      "Fold: 8  Epoch: 449  Training loss = 2.6958  Validation loss = 7.6690  \n",
      "\n",
      "Fold: 8  Epoch: 450  Training loss = 2.6957  Validation loss = 7.6688  \n",
      "\n",
      "Fold: 8  Epoch: 451  Training loss = 2.6955  Validation loss = 7.6686  \n",
      "\n",
      "Fold: 8  Epoch: 452  Training loss = 2.6952  Validation loss = 7.6684  \n",
      "\n",
      "Fold: 8  Epoch: 453  Training loss = 2.6950  Validation loss = 7.6681  \n",
      "\n",
      "Fold: 8  Epoch: 454  Training loss = 2.6949  Validation loss = 7.6680  \n",
      "\n",
      "Fold: 8  Epoch: 455  Training loss = 2.6946  Validation loss = 7.6677  \n",
      "\n",
      "Fold: 8  Epoch: 456  Training loss = 2.6944  Validation loss = 7.6675  \n",
      "\n",
      "Fold: 8  Epoch: 457  Training loss = 2.6943  Validation loss = 7.6673  \n",
      "\n",
      "Fold: 8  Epoch: 458  Training loss = 2.6940  Validation loss = 7.6671  \n",
      "\n",
      "Fold: 8  Epoch: 459  Training loss = 2.6939  Validation loss = 7.6669  \n",
      "\n",
      "Fold: 8  Epoch: 460  Training loss = 2.6937  Validation loss = 7.6667  \n",
      "\n",
      "Fold: 8  Epoch: 461  Training loss = 2.6935  Validation loss = 7.6664  \n",
      "\n",
      "Fold: 8  Epoch: 462  Training loss = 2.6933  Validation loss = 7.6663  \n",
      "\n",
      "Fold: 8  Epoch: 463  Training loss = 2.6931  Validation loss = 7.6661  \n",
      "\n",
      "Fold: 8  Epoch: 464  Training loss = 2.6929  Validation loss = 7.6658  \n",
      "\n",
      "Fold: 8  Epoch: 465  Training loss = 2.6927  Validation loss = 7.6657  \n",
      "\n",
      "Fold: 8  Epoch: 466  Training loss = 2.6925  Validation loss = 7.6654  \n",
      "\n",
      "Fold: 8  Epoch: 467  Training loss = 2.6923  Validation loss = 7.6652  \n",
      "\n",
      "Fold: 8  Epoch: 468  Training loss = 2.6921  Validation loss = 7.6649  \n",
      "\n",
      "Fold: 8  Epoch: 469  Training loss = 2.6919  Validation loss = 7.6647  \n",
      "\n",
      "Fold: 8  Epoch: 470  Training loss = 2.6917  Validation loss = 7.6645  \n",
      "\n",
      "Fold: 8  Epoch: 471  Training loss = 2.6915  Validation loss = 7.6643  \n",
      "\n",
      "Fold: 8  Epoch: 472  Training loss = 2.6913  Validation loss = 7.6641  \n",
      "\n",
      "Fold: 8  Epoch: 473  Training loss = 2.6911  Validation loss = 7.6639  \n",
      "\n",
      "Fold: 8  Epoch: 474  Training loss = 2.6909  Validation loss = 7.6637  \n",
      "\n",
      "Fold: 8  Epoch: 475  Training loss = 2.6907  Validation loss = 7.6634  \n",
      "\n",
      "Fold: 8  Epoch: 476  Training loss = 2.6905  Validation loss = 7.6632  \n",
      "\n",
      "Fold: 8  Epoch: 477  Training loss = 2.6903  Validation loss = 7.6630  \n",
      "\n",
      "Fold: 8  Epoch: 478  Training loss = 2.6900  Validation loss = 7.6627  \n",
      "\n",
      "Fold: 8  Epoch: 479  Training loss = 2.6898  Validation loss = 7.6625  \n",
      "\n",
      "Fold: 8  Epoch: 480  Training loss = 2.6896  Validation loss = 7.6623  \n",
      "\n",
      "Fold: 8  Epoch: 481  Training loss = 2.6894  Validation loss = 7.6621  \n",
      "\n",
      "Fold: 8  Epoch: 482  Training loss = 2.6892  Validation loss = 7.6619  \n",
      "\n",
      "Fold: 8  Epoch: 483  Training loss = 2.6891  Validation loss = 7.6617  \n",
      "\n",
      "Fold: 8  Epoch: 484  Training loss = 2.6889  Validation loss = 7.6615  \n",
      "\n",
      "Fold: 8  Epoch: 485  Training loss = 2.6886  Validation loss = 7.6613  \n",
      "\n",
      "Fold: 8  Epoch: 486  Training loss = 2.6884  Validation loss = 7.6611  \n",
      "\n",
      "Fold: 8  Epoch: 487  Training loss = 2.6883  Validation loss = 7.6608  \n",
      "\n",
      "Fold: 8  Epoch: 488  Training loss = 2.6881  Validation loss = 7.6607  \n",
      "\n",
      "Fold: 8  Epoch: 489  Training loss = 2.6878  Validation loss = 7.6604  \n",
      "\n",
      "Fold: 8  Epoch: 490  Training loss = 2.6876  Validation loss = 7.6602  \n",
      "\n",
      "Fold: 8  Epoch: 491  Training loss = 2.6874  Validation loss = 7.6600  \n",
      "\n",
      "Fold: 8  Epoch: 492  Training loss = 2.6873  Validation loss = 7.6598  \n",
      "\n",
      "Fold: 8  Epoch: 493  Training loss = 2.6871  Validation loss = 7.6596  \n",
      "\n",
      "Fold: 8  Epoch: 494  Training loss = 2.6869  Validation loss = 7.6594  \n",
      "\n",
      "Fold: 8  Epoch: 495  Training loss = 2.6867  Validation loss = 7.6592  \n",
      "\n",
      "Fold: 8  Epoch: 496  Training loss = 2.6866  Validation loss = 7.6590  \n",
      "\n",
      "Fold: 8  Epoch: 497  Training loss = 2.6864  Validation loss = 7.6588  \n",
      "\n",
      "Fold: 8  Epoch: 498  Training loss = 2.6862  Validation loss = 7.6586  \n",
      "\n",
      "Fold: 8  Epoch: 499  Training loss = 2.6860  Validation loss = 7.6584  \n",
      "\n",
      "Fold: 8  Epoch: 500  Training loss = 2.6858  Validation loss = 7.6582  \n",
      "\n",
      "Check model:  Fold: 8  Optimal epoch: 500  \n",
      "\n",
      "Fold: 9  Epoch: 1  Training loss = 3.2237  Validation loss = 11.3733  \n",
      "\n",
      "Fold: 9  Epoch: 2  Training loss = 3.2235  Validation loss = 11.3730  \n",
      "\n",
      "Fold: 9  Epoch: 3  Training loss = 3.2233  Validation loss = 11.3727  \n",
      "\n",
      "Fold: 9  Epoch: 4  Training loss = 3.2231  Validation loss = 11.3724  \n",
      "\n",
      "Fold: 9  Epoch: 5  Training loss = 3.2229  Validation loss = 11.3720  \n",
      "\n",
      "Fold: 9  Epoch: 6  Training loss = 3.2226  Validation loss = 11.3716  \n",
      "\n",
      "Fold: 9  Epoch: 7  Training loss = 3.2224  Validation loss = 11.3713  \n",
      "\n",
      "Fold: 9  Epoch: 8  Training loss = 3.2222  Validation loss = 11.3710  \n",
      "\n",
      "Fold: 9  Epoch: 9  Training loss = 3.2221  Validation loss = 11.3707  \n",
      "\n",
      "Fold: 9  Epoch: 10  Training loss = 3.2218  Validation loss = 11.3703  \n",
      "\n",
      "Fold: 9  Epoch: 11  Training loss = 3.2216  Validation loss = 11.3699  \n",
      "\n",
      "Fold: 9  Epoch: 12  Training loss = 3.2214  Validation loss = 11.3697  \n",
      "\n",
      "Fold: 9  Epoch: 13  Training loss = 3.2212  Validation loss = 11.3693  \n",
      "\n",
      "Fold: 9  Epoch: 14  Training loss = 3.2210  Validation loss = 11.3689  \n",
      "\n",
      "Fold: 9  Epoch: 15  Training loss = 3.2208  Validation loss = 11.3686  \n",
      "\n",
      "Fold: 9  Epoch: 16  Training loss = 3.2206  Validation loss = 11.3683  \n",
      "\n",
      "Fold: 9  Epoch: 17  Training loss = 3.2204  Validation loss = 11.3680  \n",
      "\n",
      "Fold: 9  Epoch: 18  Training loss = 3.2202  Validation loss = 11.3676  \n",
      "\n",
      "Fold: 9  Epoch: 19  Training loss = 3.2200  Validation loss = 11.3673  \n",
      "\n",
      "Fold: 9  Epoch: 20  Training loss = 3.2198  Validation loss = 11.3670  \n",
      "\n",
      "Fold: 9  Epoch: 21  Training loss = 3.2195  Validation loss = 11.3666  \n",
      "\n",
      "Fold: 9  Epoch: 22  Training loss = 3.2193  Validation loss = 11.3662  \n",
      "\n",
      "Fold: 9  Epoch: 23  Training loss = 3.2190  Validation loss = 11.3658  \n",
      "\n",
      "Fold: 9  Epoch: 24  Training loss = 3.2188  Validation loss = 11.3654  \n",
      "\n",
      "Fold: 9  Epoch: 25  Training loss = 3.2186  Validation loss = 11.3651  \n",
      "\n",
      "Fold: 9  Epoch: 26  Training loss = 3.2184  Validation loss = 11.3648  \n",
      "\n",
      "Fold: 9  Epoch: 27  Training loss = 3.2182  Validation loss = 11.3644  \n",
      "\n",
      "Fold: 9  Epoch: 28  Training loss = 3.2180  Validation loss = 11.3641  \n",
      "\n",
      "Fold: 9  Epoch: 29  Training loss = 3.2178  Validation loss = 11.3638  \n",
      "\n",
      "Fold: 9  Epoch: 30  Training loss = 3.2176  Validation loss = 11.3635  \n",
      "\n",
      "Fold: 9  Epoch: 31  Training loss = 3.2174  Validation loss = 11.3631  \n",
      "\n",
      "Fold: 9  Epoch: 32  Training loss = 3.2172  Validation loss = 11.3628  \n",
      "\n",
      "Fold: 9  Epoch: 33  Training loss = 3.2169  Validation loss = 11.3624  \n",
      "\n",
      "Fold: 9  Epoch: 34  Training loss = 3.2167  Validation loss = 11.3620  \n",
      "\n",
      "Fold: 9  Epoch: 35  Training loss = 3.2165  Validation loss = 11.3616  \n",
      "\n",
      "Fold: 9  Epoch: 36  Training loss = 3.2163  Validation loss = 11.3613  \n",
      "\n",
      "Fold: 9  Epoch: 37  Training loss = 3.2160  Validation loss = 11.3609  \n",
      "\n",
      "Fold: 9  Epoch: 38  Training loss = 3.2158  Validation loss = 11.3606  \n",
      "\n",
      "Fold: 9  Epoch: 39  Training loss = 3.2157  Validation loss = 11.3603  \n",
      "\n",
      "Fold: 9  Epoch: 40  Training loss = 3.2154  Validation loss = 11.3600  \n",
      "\n",
      "Fold: 9  Epoch: 41  Training loss = 3.2152  Validation loss = 11.3596  \n",
      "\n",
      "Fold: 9  Epoch: 42  Training loss = 3.2150  Validation loss = 11.3593  \n",
      "\n",
      "Fold: 9  Epoch: 43  Training loss = 3.2148  Validation loss = 11.3590  \n",
      "\n",
      "Fold: 9  Epoch: 44  Training loss = 3.2147  Validation loss = 11.3587  \n",
      "\n",
      "Fold: 9  Epoch: 45  Training loss = 3.2145  Validation loss = 11.3584  \n",
      "\n",
      "Fold: 9  Epoch: 46  Training loss = 3.2142  Validation loss = 11.3580  \n",
      "\n",
      "Fold: 9  Epoch: 47  Training loss = 3.2140  Validation loss = 11.3576  \n",
      "\n",
      "Fold: 9  Epoch: 48  Training loss = 3.2138  Validation loss = 11.3573  \n",
      "\n",
      "Fold: 9  Epoch: 49  Training loss = 3.2136  Validation loss = 11.3569  \n",
      "\n",
      "Fold: 9  Epoch: 50  Training loss = 3.2134  Validation loss = 11.3566  \n",
      "\n",
      "Fold: 9  Epoch: 51  Training loss = 3.2132  Validation loss = 11.3563  \n",
      "\n",
      "Fold: 9  Epoch: 52  Training loss = 3.2130  Validation loss = 11.3560  \n",
      "\n",
      "Fold: 9  Epoch: 53  Training loss = 3.2128  Validation loss = 11.3557  \n",
      "\n",
      "Fold: 9  Epoch: 54  Training loss = 3.2126  Validation loss = 11.3553  \n",
      "\n",
      "Fold: 9  Epoch: 55  Training loss = 3.2123  Validation loss = 11.3549  \n",
      "\n",
      "Fold: 9  Epoch: 56  Training loss = 3.2121  Validation loss = 11.3546  \n",
      "\n",
      "Fold: 9  Epoch: 57  Training loss = 3.2119  Validation loss = 11.3543  \n",
      "\n",
      "Fold: 9  Epoch: 58  Training loss = 3.2117  Validation loss = 11.3539  \n",
      "\n",
      "Fold: 9  Epoch: 59  Training loss = 3.2116  Validation loss = 11.3537  \n",
      "\n",
      "Fold: 9  Epoch: 60  Training loss = 3.2114  Validation loss = 11.3534  \n",
      "\n",
      "Fold: 9  Epoch: 61  Training loss = 3.2111  Validation loss = 11.3529  \n",
      "\n",
      "Fold: 9  Epoch: 62  Training loss = 3.2109  Validation loss = 11.3525  \n",
      "\n",
      "Fold: 9  Epoch: 63  Training loss = 3.2106  Validation loss = 11.3522  \n",
      "\n",
      "Fold: 9  Epoch: 64  Training loss = 3.2104  Validation loss = 11.3518  \n",
      "\n",
      "Fold: 9  Epoch: 65  Training loss = 3.2103  Validation loss = 11.3515  \n",
      "\n",
      "Fold: 9  Epoch: 66  Training loss = 3.2101  Validation loss = 11.3513  \n",
      "\n",
      "Fold: 9  Epoch: 67  Training loss = 3.2099  Validation loss = 11.3509  \n",
      "\n",
      "Fold: 9  Epoch: 68  Training loss = 3.2097  Validation loss = 11.3506  \n",
      "\n",
      "Fold: 9  Epoch: 69  Training loss = 3.2095  Validation loss = 11.3503  \n",
      "\n",
      "Fold: 9  Epoch: 70  Training loss = 3.2093  Validation loss = 11.3500  \n",
      "\n",
      "Fold: 9  Epoch: 71  Training loss = 3.2091  Validation loss = 11.3496  \n",
      "\n",
      "Fold: 9  Epoch: 72  Training loss = 3.2088  Validation loss = 11.3491  \n",
      "\n",
      "Fold: 9  Epoch: 73  Training loss = 3.2086  Validation loss = 11.3488  \n",
      "\n",
      "Fold: 9  Epoch: 74  Training loss = 3.2084  Validation loss = 11.3485  \n",
      "\n",
      "Fold: 9  Epoch: 75  Training loss = 3.2082  Validation loss = 11.3482  \n",
      "\n",
      "Fold: 9  Epoch: 76  Training loss = 3.2079  Validation loss = 11.3478  \n",
      "\n",
      "Fold: 9  Epoch: 77  Training loss = 3.2077  Validation loss = 11.3474  \n",
      "\n",
      "Fold: 9  Epoch: 78  Training loss = 3.2075  Validation loss = 11.3471  \n",
      "\n",
      "Fold: 9  Epoch: 79  Training loss = 3.2073  Validation loss = 11.3467  \n",
      "\n",
      "Fold: 9  Epoch: 80  Training loss = 3.2070  Validation loss = 11.3463  \n",
      "\n",
      "Fold: 9  Epoch: 81  Training loss = 3.2068  Validation loss = 11.3460  \n",
      "\n",
      "Fold: 9  Epoch: 82  Training loss = 3.2066  Validation loss = 11.3457  \n",
      "\n",
      "Fold: 9  Epoch: 83  Training loss = 3.2064  Validation loss = 11.3454  \n",
      "\n",
      "Fold: 9  Epoch: 84  Training loss = 3.2063  Validation loss = 11.3451  \n",
      "\n",
      "Fold: 9  Epoch: 85  Training loss = 3.2060  Validation loss = 11.3447  \n",
      "\n",
      "Fold: 9  Epoch: 86  Training loss = 3.2059  Validation loss = 11.3444  \n",
      "\n",
      "Fold: 9  Epoch: 87  Training loss = 3.2057  Validation loss = 11.3441  \n",
      "\n",
      "Fold: 9  Epoch: 88  Training loss = 3.2054  Validation loss = 11.3437  \n",
      "\n",
      "Fold: 9  Epoch: 89  Training loss = 3.2052  Validation loss = 11.3434  \n",
      "\n",
      "Fold: 9  Epoch: 90  Training loss = 3.2050  Validation loss = 11.3430  \n",
      "\n",
      "Fold: 9  Epoch: 91  Training loss = 3.2048  Validation loss = 11.3427  \n",
      "\n",
      "Fold: 9  Epoch: 92  Training loss = 3.2046  Validation loss = 11.3423  \n",
      "\n",
      "Fold: 9  Epoch: 93  Training loss = 3.2044  Validation loss = 11.3420  \n",
      "\n",
      "Fold: 9  Epoch: 94  Training loss = 3.2042  Validation loss = 11.3417  \n",
      "\n",
      "Fold: 9  Epoch: 95  Training loss = 3.2040  Validation loss = 11.3414  \n",
      "\n",
      "Fold: 9  Epoch: 96  Training loss = 3.2038  Validation loss = 11.3411  \n",
      "\n",
      "Fold: 9  Epoch: 97  Training loss = 3.2036  Validation loss = 11.3407  \n",
      "\n",
      "Fold: 9  Epoch: 98  Training loss = 3.2033  Validation loss = 11.3403  \n",
      "\n",
      "Fold: 9  Epoch: 99  Training loss = 3.2031  Validation loss = 11.3399  \n",
      "\n",
      "Fold: 9  Epoch: 100  Training loss = 3.2029  Validation loss = 11.3396  \n",
      "\n",
      "Fold: 9  Epoch: 101  Training loss = 3.2027  Validation loss = 11.3392  \n",
      "\n",
      "Fold: 9  Epoch: 102  Training loss = 3.2025  Validation loss = 11.3389  \n",
      "\n",
      "Fold: 9  Epoch: 103  Training loss = 3.2023  Validation loss = 11.3385  \n",
      "\n",
      "Fold: 9  Epoch: 104  Training loss = 3.2021  Validation loss = 11.3382  \n",
      "\n",
      "Fold: 9  Epoch: 105  Training loss = 3.2019  Validation loss = 11.3379  \n",
      "\n",
      "Fold: 9  Epoch: 106  Training loss = 3.2016  Validation loss = 11.3375  \n",
      "\n",
      "Fold: 9  Epoch: 107  Training loss = 3.2015  Validation loss = 11.3372  \n",
      "\n",
      "Fold: 9  Epoch: 108  Training loss = 3.2012  Validation loss = 11.3368  \n",
      "\n",
      "Fold: 9  Epoch: 109  Training loss = 3.2010  Validation loss = 11.3364  \n",
      "\n",
      "Fold: 9  Epoch: 110  Training loss = 3.2008  Validation loss = 11.3361  \n",
      "\n",
      "Fold: 9  Epoch: 111  Training loss = 3.2005  Validation loss = 11.3357  \n",
      "\n",
      "Fold: 9  Epoch: 112  Training loss = 3.2003  Validation loss = 11.3353  \n",
      "\n",
      "Fold: 9  Epoch: 113  Training loss = 3.2001  Validation loss = 11.3350  \n",
      "\n",
      "Fold: 9  Epoch: 114  Training loss = 3.1999  Validation loss = 11.3347  \n",
      "\n",
      "Fold: 9  Epoch: 115  Training loss = 3.1997  Validation loss = 11.3343  \n",
      "\n",
      "Fold: 9  Epoch: 116  Training loss = 3.1995  Validation loss = 11.3340  \n",
      "\n",
      "Fold: 9  Epoch: 117  Training loss = 3.1993  Validation loss = 11.3337  \n",
      "\n",
      "Fold: 9  Epoch: 118  Training loss = 3.1991  Validation loss = 11.3334  \n",
      "\n",
      "Fold: 9  Epoch: 119  Training loss = 3.1989  Validation loss = 11.3330  \n",
      "\n",
      "Fold: 9  Epoch: 120  Training loss = 3.1987  Validation loss = 11.3327  \n",
      "\n",
      "Fold: 9  Epoch: 121  Training loss = 3.1985  Validation loss = 11.3323  \n",
      "\n",
      "Fold: 9  Epoch: 122  Training loss = 3.1982  Validation loss = 11.3319  \n",
      "\n",
      "Fold: 9  Epoch: 123  Training loss = 3.1980  Validation loss = 11.3316  \n",
      "\n",
      "Fold: 9  Epoch: 124  Training loss = 3.1978  Validation loss = 11.3313  \n",
      "\n",
      "Fold: 9  Epoch: 125  Training loss = 3.1976  Validation loss = 11.3310  \n",
      "\n",
      "Fold: 9  Epoch: 126  Training loss = 3.1975  Validation loss = 11.3307  \n",
      "\n",
      "Fold: 9  Epoch: 127  Training loss = 3.1973  Validation loss = 11.3304  \n",
      "\n",
      "Fold: 9  Epoch: 128  Training loss = 3.1971  Validation loss = 11.3300  \n",
      "\n",
      "Fold: 9  Epoch: 129  Training loss = 3.1969  Validation loss = 11.3297  \n",
      "\n",
      "Fold: 9  Epoch: 130  Training loss = 3.1967  Validation loss = 11.3294  \n",
      "\n",
      "Fold: 9  Epoch: 131  Training loss = 3.1964  Validation loss = 11.3290  \n",
      "\n",
      "Fold: 9  Epoch: 132  Training loss = 3.1962  Validation loss = 11.3286  \n",
      "\n",
      "Fold: 9  Epoch: 133  Training loss = 3.1961  Validation loss = 11.3285  \n",
      "\n",
      "Fold: 9  Epoch: 134  Training loss = 3.1958  Validation loss = 11.3280  \n",
      "\n",
      "Fold: 9  Epoch: 135  Training loss = 3.1956  Validation loss = 11.3276  \n",
      "\n",
      "Fold: 9  Epoch: 136  Training loss = 3.1953  Validation loss = 11.3272  \n",
      "\n",
      "Fold: 9  Epoch: 137  Training loss = 3.1952  Validation loss = 11.3269  \n",
      "\n",
      "Fold: 9  Epoch: 138  Training loss = 3.1949  Validation loss = 11.3265  \n",
      "\n",
      "Fold: 9  Epoch: 139  Training loss = 3.1946  Validation loss = 11.3261  \n",
      "\n",
      "Fold: 9  Epoch: 140  Training loss = 3.1944  Validation loss = 11.3257  \n",
      "\n",
      "Fold: 9  Epoch: 141  Training loss = 3.1942  Validation loss = 11.3254  \n",
      "\n",
      "Fold: 9  Epoch: 142  Training loss = 3.1940  Validation loss = 11.3250  \n",
      "\n",
      "Fold: 9  Epoch: 143  Training loss = 3.1938  Validation loss = 11.3247  \n",
      "\n",
      "Fold: 9  Epoch: 144  Training loss = 3.1936  Validation loss = 11.3244  \n",
      "\n",
      "Fold: 9  Epoch: 145  Training loss = 3.1934  Validation loss = 11.3240  \n",
      "\n",
      "Fold: 9  Epoch: 146  Training loss = 3.1932  Validation loss = 11.3238  \n",
      "\n",
      "Fold: 9  Epoch: 147  Training loss = 3.1930  Validation loss = 11.3234  \n",
      "\n",
      "Fold: 9  Epoch: 148  Training loss = 3.1928  Validation loss = 11.3230  \n",
      "\n",
      "Fold: 9  Epoch: 149  Training loss = 3.1925  Validation loss = 11.3226  \n",
      "\n",
      "Fold: 9  Epoch: 150  Training loss = 3.1924  Validation loss = 11.3223  \n",
      "\n",
      "Fold: 9  Epoch: 151  Training loss = 3.1921  Validation loss = 11.3219  \n",
      "\n",
      "Fold: 9  Epoch: 152  Training loss = 3.1919  Validation loss = 11.3216  \n",
      "\n",
      "Fold: 9  Epoch: 153  Training loss = 3.1917  Validation loss = 11.3212  \n",
      "\n",
      "Fold: 9  Epoch: 154  Training loss = 3.1915  Validation loss = 11.3209  \n",
      "\n",
      "Fold: 9  Epoch: 155  Training loss = 3.1912  Validation loss = 11.3205  \n",
      "\n",
      "Fold: 9  Epoch: 156  Training loss = 3.1911  Validation loss = 11.3202  \n",
      "\n",
      "Fold: 9  Epoch: 157  Training loss = 3.1909  Validation loss = 11.3198  \n",
      "\n",
      "Fold: 9  Epoch: 158  Training loss = 3.1906  Validation loss = 11.3195  \n",
      "\n",
      "Fold: 9  Epoch: 159  Training loss = 3.1904  Validation loss = 11.3191  \n",
      "\n",
      "Fold: 9  Epoch: 160  Training loss = 3.1902  Validation loss = 11.3188  \n",
      "\n",
      "Fold: 9  Epoch: 161  Training loss = 3.1900  Validation loss = 11.3185  \n",
      "\n",
      "Fold: 9  Epoch: 162  Training loss = 3.1898  Validation loss = 11.3181  \n",
      "\n",
      "Fold: 9  Epoch: 163  Training loss = 3.1896  Validation loss = 11.3178  \n",
      "\n",
      "Fold: 9  Epoch: 164  Training loss = 3.1894  Validation loss = 11.3174  \n",
      "\n",
      "Fold: 9  Epoch: 165  Training loss = 3.1892  Validation loss = 11.3171  \n",
      "\n",
      "Fold: 9  Epoch: 166  Training loss = 3.1890  Validation loss = 11.3167  \n",
      "\n",
      "Fold: 9  Epoch: 167  Training loss = 3.1888  Validation loss = 11.3164  \n",
      "\n",
      "Fold: 9  Epoch: 168  Training loss = 3.1886  Validation loss = 11.3161  \n",
      "\n",
      "Fold: 9  Epoch: 169  Training loss = 3.1884  Validation loss = 11.3158  \n",
      "\n",
      "Fold: 9  Epoch: 170  Training loss = 3.1882  Validation loss = 11.3154  \n",
      "\n",
      "Fold: 9  Epoch: 171  Training loss = 3.1879  Validation loss = 11.3150  \n",
      "\n",
      "Fold: 9  Epoch: 172  Training loss = 3.1877  Validation loss = 11.3147  \n",
      "\n",
      "Fold: 9  Epoch: 173  Training loss = 3.1875  Validation loss = 11.3143  \n",
      "\n",
      "Fold: 9  Epoch: 174  Training loss = 3.1872  Validation loss = 11.3139  \n",
      "\n",
      "Fold: 9  Epoch: 175  Training loss = 3.1870  Validation loss = 11.3135  \n",
      "\n",
      "Fold: 9  Epoch: 176  Training loss = 3.1868  Validation loss = 11.3132  \n",
      "\n",
      "Fold: 9  Epoch: 177  Training loss = 3.1866  Validation loss = 11.3128  \n",
      "\n",
      "Fold: 9  Epoch: 178  Training loss = 3.1864  Validation loss = 11.3126  \n",
      "\n",
      "Fold: 9  Epoch: 179  Training loss = 3.1862  Validation loss = 11.3122  \n",
      "\n",
      "Fold: 9  Epoch: 180  Training loss = 3.1860  Validation loss = 11.3118  \n",
      "\n",
      "Fold: 9  Epoch: 181  Training loss = 3.1858  Validation loss = 11.3115  \n",
      "\n",
      "Fold: 9  Epoch: 182  Training loss = 3.1856  Validation loss = 11.3112  \n",
      "\n",
      "Fold: 9  Epoch: 183  Training loss = 3.1854  Validation loss = 11.3108  \n",
      "\n",
      "Fold: 9  Epoch: 184  Training loss = 3.1852  Validation loss = 11.3105  \n",
      "\n",
      "Fold: 9  Epoch: 185  Training loss = 3.1850  Validation loss = 11.3101  \n",
      "\n",
      "Fold: 9  Epoch: 186  Training loss = 3.1848  Validation loss = 11.3098  \n",
      "\n",
      "Fold: 9  Epoch: 187  Training loss = 3.1846  Validation loss = 11.3094  \n",
      "\n",
      "Fold: 9  Epoch: 188  Training loss = 3.1843  Validation loss = 11.3090  \n",
      "\n",
      "Fold: 9  Epoch: 189  Training loss = 3.1841  Validation loss = 11.3087  \n",
      "\n",
      "Fold: 9  Epoch: 190  Training loss = 3.1839  Validation loss = 11.3084  \n",
      "\n",
      "Fold: 9  Epoch: 191  Training loss = 3.1837  Validation loss = 11.3081  \n",
      "\n",
      "Fold: 9  Epoch: 192  Training loss = 3.1835  Validation loss = 11.3077  \n",
      "\n",
      "Fold: 9  Epoch: 193  Training loss = 3.1833  Validation loss = 11.3074  \n",
      "\n",
      "Fold: 9  Epoch: 194  Training loss = 3.1831  Validation loss = 11.3071  \n",
      "\n",
      "Fold: 9  Epoch: 195  Training loss = 3.1829  Validation loss = 11.3067  \n",
      "\n",
      "Fold: 9  Epoch: 196  Training loss = 3.1827  Validation loss = 11.3064  \n",
      "\n",
      "Fold: 9  Epoch: 197  Training loss = 3.1825  Validation loss = 11.3061  \n",
      "\n",
      "Fold: 9  Epoch: 198  Training loss = 3.1823  Validation loss = 11.3058  \n",
      "\n",
      "Fold: 9  Epoch: 199  Training loss = 3.1821  Validation loss = 11.3055  \n",
      "\n",
      "Fold: 9  Epoch: 200  Training loss = 3.1820  Validation loss = 11.3052  \n",
      "\n",
      "Fold: 9  Epoch: 201  Training loss = 3.1817  Validation loss = 11.3048  \n",
      "\n",
      "Fold: 9  Epoch: 202  Training loss = 3.1815  Validation loss = 11.3044  \n",
      "\n",
      "Fold: 9  Epoch: 203  Training loss = 3.1813  Validation loss = 11.3042  \n",
      "\n",
      "Fold: 9  Epoch: 204  Training loss = 3.1811  Validation loss = 11.3038  \n",
      "\n",
      "Fold: 9  Epoch: 205  Training loss = 3.1810  Validation loss = 11.3035  \n",
      "\n",
      "Fold: 9  Epoch: 206  Training loss = 3.1807  Validation loss = 11.3032  \n",
      "\n",
      "Fold: 9  Epoch: 207  Training loss = 3.1805  Validation loss = 11.3028  \n",
      "\n",
      "Fold: 9  Epoch: 208  Training loss = 3.1803  Validation loss = 11.3024  \n",
      "\n",
      "Fold: 9  Epoch: 209  Training loss = 3.1801  Validation loss = 11.3021  \n",
      "\n",
      "Fold: 9  Epoch: 210  Training loss = 3.1799  Validation loss = 11.3018  \n",
      "\n",
      "Fold: 9  Epoch: 211  Training loss = 3.1797  Validation loss = 11.3014  \n",
      "\n",
      "Fold: 9  Epoch: 212  Training loss = 3.1795  Validation loss = 11.3011  \n",
      "\n",
      "Fold: 9  Epoch: 213  Training loss = 3.1793  Validation loss = 11.3008  \n",
      "\n",
      "Fold: 9  Epoch: 214  Training loss = 3.1791  Validation loss = 11.3005  \n",
      "\n",
      "Fold: 9  Epoch: 215  Training loss = 3.1790  Validation loss = 11.3002  \n",
      "\n",
      "Fold: 9  Epoch: 216  Training loss = 3.1787  Validation loss = 11.2998  \n",
      "\n",
      "Fold: 9  Epoch: 217  Training loss = 3.1786  Validation loss = 11.2995  \n",
      "\n",
      "Fold: 9  Epoch: 218  Training loss = 3.1784  Validation loss = 11.2992  \n",
      "\n",
      "Fold: 9  Epoch: 219  Training loss = 3.1782  Validation loss = 11.2989  \n",
      "\n",
      "Fold: 9  Epoch: 220  Training loss = 3.1780  Validation loss = 11.2987  \n",
      "\n",
      "Fold: 9  Epoch: 221  Training loss = 3.1778  Validation loss = 11.2983  \n",
      "\n",
      "Fold: 9  Epoch: 222  Training loss = 3.1776  Validation loss = 11.2980  \n",
      "\n",
      "Fold: 9  Epoch: 223  Training loss = 3.1774  Validation loss = 11.2976  \n",
      "\n",
      "Fold: 9  Epoch: 224  Training loss = 3.1772  Validation loss = 11.2973  \n",
      "\n",
      "Fold: 9  Epoch: 225  Training loss = 3.1770  Validation loss = 11.2969  \n",
      "\n",
      "Fold: 9  Epoch: 226  Training loss = 3.1768  Validation loss = 11.2966  \n",
      "\n",
      "Fold: 9  Epoch: 227  Training loss = 3.1766  Validation loss = 11.2963  \n",
      "\n",
      "Fold: 9  Epoch: 228  Training loss = 3.1763  Validation loss = 11.2959  \n",
      "\n",
      "Fold: 9  Epoch: 229  Training loss = 3.1761  Validation loss = 11.2955  \n",
      "\n",
      "Fold: 9  Epoch: 230  Training loss = 3.1759  Validation loss = 11.2951  \n",
      "\n",
      "Fold: 9  Epoch: 231  Training loss = 3.1757  Validation loss = 11.2948  \n",
      "\n",
      "Fold: 9  Epoch: 232  Training loss = 3.1755  Validation loss = 11.2945  \n",
      "\n",
      "Fold: 9  Epoch: 233  Training loss = 3.1753  Validation loss = 11.2941  \n",
      "\n",
      "Fold: 9  Epoch: 234  Training loss = 3.1751  Validation loss = 11.2938  \n",
      "\n",
      "Fold: 9  Epoch: 235  Training loss = 3.1749  Validation loss = 11.2934  \n",
      "\n",
      "Fold: 9  Epoch: 236  Training loss = 3.1747  Validation loss = 11.2931  \n",
      "\n",
      "Fold: 9  Epoch: 237  Training loss = 3.1745  Validation loss = 11.2927  \n",
      "\n",
      "Fold: 9  Epoch: 238  Training loss = 3.1743  Validation loss = 11.2924  \n",
      "\n",
      "Fold: 9  Epoch: 239  Training loss = 3.1741  Validation loss = 11.2921  \n",
      "\n",
      "Fold: 9  Epoch: 240  Training loss = 3.1739  Validation loss = 11.2917  \n",
      "\n",
      "Fold: 9  Epoch: 241  Training loss = 3.1737  Validation loss = 11.2914  \n",
      "\n",
      "Fold: 9  Epoch: 242  Training loss = 3.1735  Validation loss = 11.2911  \n",
      "\n",
      "Fold: 9  Epoch: 243  Training loss = 3.1733  Validation loss = 11.2908  \n",
      "\n",
      "Fold: 9  Epoch: 244  Training loss = 3.1731  Validation loss = 11.2905  \n",
      "\n",
      "Fold: 9  Epoch: 245  Training loss = 3.1729  Validation loss = 11.2901  \n",
      "\n",
      "Fold: 9  Epoch: 246  Training loss = 3.1727  Validation loss = 11.2897  \n",
      "\n",
      "Fold: 9  Epoch: 247  Training loss = 3.1725  Validation loss = 11.2894  \n",
      "\n",
      "Fold: 9  Epoch: 248  Training loss = 3.1722  Validation loss = 11.2890  \n",
      "\n",
      "Fold: 9  Epoch: 249  Training loss = 3.1720  Validation loss = 11.2886  \n",
      "\n",
      "Fold: 9  Epoch: 250  Training loss = 3.1718  Validation loss = 11.2882  \n",
      "\n",
      "Fold: 9  Epoch: 251  Training loss = 3.1715  Validation loss = 11.2878  \n",
      "\n",
      "Fold: 9  Epoch: 252  Training loss = 3.1712  Validation loss = 11.2873  \n",
      "\n",
      "Fold: 9  Epoch: 253  Training loss = 3.1710  Validation loss = 11.2868  \n",
      "\n",
      "Fold: 9  Epoch: 254  Training loss = 3.1708  Validation loss = 11.2865  \n",
      "\n",
      "Fold: 9  Epoch: 255  Training loss = 3.1705  Validation loss = 11.2861  \n",
      "\n",
      "Fold: 9  Epoch: 256  Training loss = 3.1703  Validation loss = 11.2858  \n",
      "\n",
      "Fold: 9  Epoch: 257  Training loss = 3.1701  Validation loss = 11.2853  \n",
      "\n",
      "Fold: 9  Epoch: 258  Training loss = 3.1699  Validation loss = 11.2850  \n",
      "\n",
      "Fold: 9  Epoch: 259  Training loss = 3.1697  Validation loss = 11.2847  \n",
      "\n",
      "Fold: 9  Epoch: 260  Training loss = 3.1695  Validation loss = 11.2843  \n",
      "\n",
      "Fold: 9  Epoch: 261  Training loss = 3.1693  Validation loss = 11.2840  \n",
      "\n",
      "Fold: 9  Epoch: 262  Training loss = 3.1691  Validation loss = 11.2837  \n",
      "\n",
      "Fold: 9  Epoch: 263  Training loss = 3.1689  Validation loss = 11.2834  \n",
      "\n",
      "Fold: 9  Epoch: 264  Training loss = 3.1686  Validation loss = 11.2829  \n",
      "\n",
      "Fold: 9  Epoch: 265  Training loss = 3.1684  Validation loss = 11.2825  \n",
      "\n",
      "Fold: 9  Epoch: 266  Training loss = 3.1682  Validation loss = 11.2822  \n",
      "\n",
      "Fold: 9  Epoch: 267  Training loss = 3.1679  Validation loss = 11.2818  \n",
      "\n",
      "Fold: 9  Epoch: 268  Training loss = 3.1677  Validation loss = 11.2814  \n",
      "\n",
      "Fold: 9  Epoch: 269  Training loss = 3.1675  Validation loss = 11.2810  \n",
      "\n",
      "Fold: 9  Epoch: 270  Training loss = 3.1673  Validation loss = 11.2806  \n",
      "\n",
      "Fold: 9  Epoch: 271  Training loss = 3.1670  Validation loss = 11.2802  \n",
      "\n",
      "Fold: 9  Epoch: 272  Training loss = 3.1668  Validation loss = 11.2798  \n",
      "\n",
      "Fold: 9  Epoch: 273  Training loss = 3.1666  Validation loss = 11.2795  \n",
      "\n",
      "Fold: 9  Epoch: 274  Training loss = 3.1663  Validation loss = 11.2791  \n",
      "\n",
      "Fold: 9  Epoch: 275  Training loss = 3.1661  Validation loss = 11.2788  \n",
      "\n",
      "Fold: 9  Epoch: 276  Training loss = 3.1659  Validation loss = 11.2784  \n",
      "\n",
      "Fold: 9  Epoch: 277  Training loss = 3.1657  Validation loss = 11.2781  \n",
      "\n",
      "Fold: 9  Epoch: 278  Training loss = 3.1655  Validation loss = 11.2778  \n",
      "\n",
      "Fold: 9  Epoch: 279  Training loss = 3.1653  Validation loss = 11.2774  \n",
      "\n",
      "Fold: 9  Epoch: 280  Training loss = 3.1651  Validation loss = 11.2770  \n",
      "\n",
      "Fold: 9  Epoch: 281  Training loss = 3.1649  Validation loss = 11.2766  \n",
      "\n",
      "Fold: 9  Epoch: 282  Training loss = 3.1647  Validation loss = 11.2763  \n",
      "\n",
      "Fold: 9  Epoch: 283  Training loss = 3.1644  Validation loss = 11.2759  \n",
      "\n",
      "Fold: 9  Epoch: 284  Training loss = 3.1642  Validation loss = 11.2756  \n",
      "\n",
      "Fold: 9  Epoch: 285  Training loss = 3.1640  Validation loss = 11.2753  \n",
      "\n",
      "Fold: 9  Epoch: 286  Training loss = 3.1639  Validation loss = 11.2750  \n",
      "\n",
      "Fold: 9  Epoch: 287  Training loss = 3.1637  Validation loss = 11.2746  \n",
      "\n",
      "Fold: 9  Epoch: 288  Training loss = 3.1635  Validation loss = 11.2743  \n",
      "\n",
      "Fold: 9  Epoch: 289  Training loss = 3.1632  Validation loss = 11.2739  \n",
      "\n",
      "Fold: 9  Epoch: 290  Training loss = 3.1630  Validation loss = 11.2735  \n",
      "\n",
      "Fold: 9  Epoch: 291  Training loss = 3.1628  Validation loss = 11.2732  \n",
      "\n",
      "Fold: 9  Epoch: 292  Training loss = 3.1626  Validation loss = 11.2729  \n",
      "\n",
      "Fold: 9  Epoch: 293  Training loss = 3.1624  Validation loss = 11.2726  \n",
      "\n",
      "Fold: 9  Epoch: 294  Training loss = 3.1622  Validation loss = 11.2722  \n",
      "\n",
      "Fold: 9  Epoch: 295  Training loss = 3.1620  Validation loss = 11.2718  \n",
      "\n",
      "Fold: 9  Epoch: 296  Training loss = 3.1618  Validation loss = 11.2716  \n",
      "\n",
      "Fold: 9  Epoch: 297  Training loss = 3.1616  Validation loss = 11.2712  \n",
      "\n",
      "Fold: 9  Epoch: 298  Training loss = 3.1615  Validation loss = 11.2710  \n",
      "\n",
      "Fold: 9  Epoch: 299  Training loss = 3.1613  Validation loss = 11.2706  \n",
      "\n",
      "Fold: 9  Epoch: 300  Training loss = 3.1610  Validation loss = 11.2702  \n",
      "\n",
      "Fold: 9  Epoch: 301  Training loss = 3.1608  Validation loss = 11.2699  \n",
      "\n",
      "Fold: 9  Epoch: 302  Training loss = 3.1606  Validation loss = 11.2696  \n",
      "\n",
      "Fold: 9  Epoch: 303  Training loss = 3.1604  Validation loss = 11.2692  \n",
      "\n",
      "Fold: 9  Epoch: 304  Training loss = 3.1602  Validation loss = 11.2689  \n",
      "\n",
      "Fold: 9  Epoch: 305  Training loss = 3.1600  Validation loss = 11.2685  \n",
      "\n",
      "Fold: 9  Epoch: 306  Training loss = 3.1598  Validation loss = 11.2681  \n",
      "\n",
      "Fold: 9  Epoch: 307  Training loss = 3.1595  Validation loss = 11.2677  \n",
      "\n",
      "Fold: 9  Epoch: 308  Training loss = 3.1593  Validation loss = 11.2673  \n",
      "\n",
      "Fold: 9  Epoch: 309  Training loss = 3.1591  Validation loss = 11.2669  \n",
      "\n",
      "Fold: 9  Epoch: 310  Training loss = 3.1588  Validation loss = 11.2665  \n",
      "\n",
      "Fold: 9  Epoch: 311  Training loss = 3.1586  Validation loss = 11.2661  \n",
      "\n",
      "Fold: 9  Epoch: 312  Training loss = 3.1583  Validation loss = 11.2656  \n",
      "\n",
      "Fold: 9  Epoch: 313  Training loss = 3.1581  Validation loss = 11.2653  \n",
      "\n",
      "Fold: 9  Epoch: 314  Training loss = 3.1579  Validation loss = 11.2650  \n",
      "\n",
      "Fold: 9  Epoch: 315  Training loss = 3.1577  Validation loss = 11.2646  \n",
      "\n",
      "Fold: 9  Epoch: 316  Training loss = 3.1575  Validation loss = 11.2642  \n",
      "\n",
      "Fold: 9  Epoch: 317  Training loss = 3.1573  Validation loss = 11.2639  \n",
      "\n",
      "Fold: 9  Epoch: 318  Training loss = 3.1571  Validation loss = 11.2636  \n",
      "\n",
      "Fold: 9  Epoch: 319  Training loss = 3.1569  Validation loss = 11.2632  \n",
      "\n",
      "Fold: 9  Epoch: 320  Training loss = 3.1567  Validation loss = 11.2629  \n",
      "\n",
      "Fold: 9  Epoch: 321  Training loss = 3.1565  Validation loss = 11.2625  \n",
      "\n",
      "Fold: 9  Epoch: 322  Training loss = 3.1563  Validation loss = 11.2622  \n",
      "\n",
      "Fold: 9  Epoch: 323  Training loss = 3.1561  Validation loss = 11.2619  \n",
      "\n",
      "Fold: 9  Epoch: 324  Training loss = 3.1559  Validation loss = 11.2615  \n",
      "\n",
      "Fold: 9  Epoch: 325  Training loss = 3.1557  Validation loss = 11.2612  \n",
      "\n",
      "Fold: 9  Epoch: 326  Training loss = 3.1555  Validation loss = 11.2609  \n",
      "\n",
      "Fold: 9  Epoch: 327  Training loss = 3.1553  Validation loss = 11.2606  \n",
      "\n",
      "Fold: 9  Epoch: 328  Training loss = 3.1552  Validation loss = 11.2603  \n",
      "\n",
      "Fold: 9  Epoch: 329  Training loss = 3.1550  Validation loss = 11.2600  \n",
      "\n",
      "Fold: 9  Epoch: 330  Training loss = 3.1548  Validation loss = 11.2597  \n",
      "\n",
      "Fold: 9  Epoch: 331  Training loss = 3.1546  Validation loss = 11.2594  \n",
      "\n",
      "Fold: 9  Epoch: 332  Training loss = 3.1544  Validation loss = 11.2590  \n",
      "\n",
      "Fold: 9  Epoch: 333  Training loss = 3.1543  Validation loss = 11.2588  \n",
      "\n",
      "Fold: 9  Epoch: 334  Training loss = 3.1541  Validation loss = 11.2584  \n",
      "\n",
      "Fold: 9  Epoch: 335  Training loss = 3.1539  Validation loss = 11.2581  \n",
      "\n",
      "Fold: 9  Epoch: 336  Training loss = 3.1537  Validation loss = 11.2578  \n",
      "\n",
      "Fold: 9  Epoch: 337  Training loss = 3.1535  Validation loss = 11.2575  \n",
      "\n",
      "Fold: 9  Epoch: 338  Training loss = 3.1533  Validation loss = 11.2571  \n",
      "\n",
      "Fold: 9  Epoch: 339  Training loss = 3.1531  Validation loss = 11.2568  \n",
      "\n",
      "Fold: 9  Epoch: 340  Training loss = 3.1529  Validation loss = 11.2565  \n",
      "\n",
      "Fold: 9  Epoch: 341  Training loss = 3.1527  Validation loss = 11.2562  \n",
      "\n",
      "Fold: 9  Epoch: 342  Training loss = 3.1525  Validation loss = 11.2558  \n",
      "\n",
      "Fold: 9  Epoch: 343  Training loss = 3.1523  Validation loss = 11.2555  \n",
      "\n",
      "Fold: 9  Epoch: 344  Training loss = 3.1521  Validation loss = 11.2551  \n",
      "\n",
      "Fold: 9  Epoch: 345  Training loss = 3.1519  Validation loss = 11.2548  \n",
      "\n",
      "Fold: 9  Epoch: 346  Training loss = 3.1517  Validation loss = 11.2545  \n",
      "\n",
      "Fold: 9  Epoch: 347  Training loss = 3.1516  Validation loss = 11.2542  \n",
      "\n",
      "Fold: 9  Epoch: 348  Training loss = 3.1514  Validation loss = 11.2539  \n",
      "\n",
      "Fold: 9  Epoch: 349  Training loss = 3.1511  Validation loss = 11.2535  \n",
      "\n",
      "Fold: 9  Epoch: 350  Training loss = 3.1509  Validation loss = 11.2531  \n",
      "\n",
      "Fold: 9  Epoch: 351  Training loss = 3.1507  Validation loss = 11.2527  \n",
      "\n",
      "Fold: 9  Epoch: 352  Training loss = 3.1504  Validation loss = 11.2523  \n",
      "\n",
      "Fold: 9  Epoch: 353  Training loss = 3.1502  Validation loss = 11.2519  \n",
      "\n",
      "Fold: 9  Epoch: 354  Training loss = 3.1499  Validation loss = 11.2515  \n",
      "\n",
      "Fold: 9  Epoch: 355  Training loss = 3.1498  Validation loss = 11.2512  \n",
      "\n",
      "Fold: 9  Epoch: 356  Training loss = 3.1495  Validation loss = 11.2508  \n",
      "\n",
      "Fold: 9  Epoch: 357  Training loss = 3.1494  Validation loss = 11.2505  \n",
      "\n",
      "Fold: 9  Epoch: 358  Training loss = 3.1492  Validation loss = 11.2502  \n",
      "\n",
      "Fold: 9  Epoch: 359  Training loss = 3.1489  Validation loss = 11.2498  \n",
      "\n",
      "Fold: 9  Epoch: 360  Training loss = 3.1487  Validation loss = 11.2494  \n",
      "\n",
      "Fold: 9  Epoch: 361  Training loss = 3.1485  Validation loss = 11.2490  \n",
      "\n",
      "Fold: 9  Epoch: 362  Training loss = 3.1483  Validation loss = 11.2487  \n",
      "\n",
      "Fold: 9  Epoch: 363  Training loss = 3.1481  Validation loss = 11.2484  \n",
      "\n",
      "Fold: 9  Epoch: 364  Training loss = 3.1479  Validation loss = 11.2480  \n",
      "\n",
      "Fold: 9  Epoch: 365  Training loss = 3.1477  Validation loss = 11.2476  \n",
      "\n",
      "Fold: 9  Epoch: 366  Training loss = 3.1475  Validation loss = 11.2473  \n",
      "\n",
      "Fold: 9  Epoch: 367  Training loss = 3.1473  Validation loss = 11.2470  \n",
      "\n",
      "Fold: 9  Epoch: 368  Training loss = 3.1471  Validation loss = 11.2467  \n",
      "\n",
      "Fold: 9  Epoch: 369  Training loss = 3.1469  Validation loss = 11.2463  \n",
      "\n",
      "Fold: 9  Epoch: 370  Training loss = 3.1467  Validation loss = 11.2460  \n",
      "\n",
      "Fold: 9  Epoch: 371  Training loss = 3.1465  Validation loss = 11.2456  \n",
      "\n",
      "Fold: 9  Epoch: 372  Training loss = 3.1463  Validation loss = 11.2454  \n",
      "\n",
      "Fold: 9  Epoch: 373  Training loss = 3.1461  Validation loss = 11.2450  \n",
      "\n",
      "Fold: 9  Epoch: 374  Training loss = 3.1459  Validation loss = 11.2447  \n",
      "\n",
      "Fold: 9  Epoch: 375  Training loss = 3.1457  Validation loss = 11.2443  \n",
      "\n",
      "Fold: 9  Epoch: 376  Training loss = 3.1455  Validation loss = 11.2440  \n",
      "\n",
      "Fold: 9  Epoch: 377  Training loss = 3.1453  Validation loss = 11.2437  \n",
      "\n",
      "Fold: 9  Epoch: 378  Training loss = 3.1451  Validation loss = 11.2433  \n",
      "\n",
      "Fold: 9  Epoch: 379  Training loss = 3.1449  Validation loss = 11.2429  \n",
      "\n",
      "Fold: 9  Epoch: 380  Training loss = 3.1447  Validation loss = 11.2426  \n",
      "\n",
      "Fold: 9  Epoch: 381  Training loss = 3.1445  Validation loss = 11.2423  \n",
      "\n",
      "Fold: 9  Epoch: 382  Training loss = 3.1443  Validation loss = 11.2419  \n",
      "\n",
      "Fold: 9  Epoch: 383  Training loss = 3.1441  Validation loss = 11.2416  \n",
      "\n",
      "Fold: 9  Epoch: 384  Training loss = 3.1439  Validation loss = 11.2412  \n",
      "\n",
      "Fold: 9  Epoch: 385  Training loss = 3.1437  Validation loss = 11.2409  \n",
      "\n",
      "Fold: 9  Epoch: 386  Training loss = 3.1435  Validation loss = 11.2406  \n",
      "\n",
      "Fold: 9  Epoch: 387  Training loss = 3.1433  Validation loss = 11.2402  \n",
      "\n",
      "Fold: 9  Epoch: 388  Training loss = 3.1431  Validation loss = 11.2399  \n",
      "\n",
      "Fold: 9  Epoch: 389  Training loss = 3.1429  Validation loss = 11.2395  \n",
      "\n",
      "Fold: 9  Epoch: 390  Training loss = 3.1427  Validation loss = 11.2392  \n",
      "\n",
      "Fold: 9  Epoch: 391  Training loss = 3.1425  Validation loss = 11.2388  \n",
      "\n",
      "Fold: 9  Epoch: 392  Training loss = 3.1422  Validation loss = 11.2384  \n",
      "\n",
      "Fold: 9  Epoch: 393  Training loss = 3.1420  Validation loss = 11.2381  \n",
      "\n",
      "Fold: 9  Epoch: 394  Training loss = 3.1418  Validation loss = 11.2377  \n",
      "\n",
      "Fold: 9  Epoch: 395  Training loss = 3.1416  Validation loss = 11.2374  \n",
      "\n",
      "Fold: 9  Epoch: 396  Training loss = 3.1414  Validation loss = 11.2370  \n",
      "\n",
      "Fold: 9  Epoch: 397  Training loss = 3.1412  Validation loss = 11.2367  \n",
      "\n",
      "Fold: 9  Epoch: 398  Training loss = 3.1410  Validation loss = 11.2364  \n",
      "\n",
      "Fold: 9  Epoch: 399  Training loss = 3.1408  Validation loss = 11.2361  \n",
      "\n",
      "Fold: 9  Epoch: 400  Training loss = 3.1406  Validation loss = 11.2357  \n",
      "\n",
      "Fold: 9  Epoch: 401  Training loss = 3.1404  Validation loss = 11.2353  \n",
      "\n",
      "Fold: 9  Epoch: 402  Training loss = 3.1402  Validation loss = 11.2351  \n",
      "\n",
      "Fold: 9  Epoch: 403  Training loss = 3.1401  Validation loss = 11.2347  \n",
      "\n",
      "Fold: 9  Epoch: 404  Training loss = 3.1399  Validation loss = 11.2344  \n",
      "\n",
      "Fold: 9  Epoch: 405  Training loss = 3.1397  Validation loss = 11.2341  \n",
      "\n",
      "Fold: 9  Epoch: 406  Training loss = 3.1395  Validation loss = 11.2338  \n",
      "\n",
      "Fold: 9  Epoch: 407  Training loss = 3.1392  Validation loss = 11.2333  \n",
      "\n",
      "Fold: 9  Epoch: 408  Training loss = 3.1391  Validation loss = 11.2330  \n",
      "\n",
      "Fold: 9  Epoch: 409  Training loss = 3.1389  Validation loss = 11.2327  \n",
      "\n",
      "Fold: 9  Epoch: 410  Training loss = 3.1387  Validation loss = 11.2323  \n",
      "\n",
      "Fold: 9  Epoch: 411  Training loss = 3.1385  Validation loss = 11.2320  \n",
      "\n",
      "Fold: 9  Epoch: 412  Training loss = 3.1383  Validation loss = 11.2316  \n",
      "\n",
      "Fold: 9  Epoch: 413  Training loss = 3.1381  Validation loss = 11.2313  \n",
      "\n",
      "Fold: 9  Epoch: 414  Training loss = 3.1379  Validation loss = 11.2310  \n",
      "\n",
      "Fold: 9  Epoch: 415  Training loss = 3.1377  Validation loss = 11.2307  \n",
      "\n",
      "Fold: 9  Epoch: 416  Training loss = 3.1375  Validation loss = 11.2303  \n",
      "\n",
      "Fold: 9  Epoch: 417  Training loss = 3.1373  Validation loss = 11.2300  \n",
      "\n",
      "Fold: 9  Epoch: 418  Training loss = 3.1371  Validation loss = 11.2296  \n",
      "\n",
      "Fold: 9  Epoch: 419  Training loss = 3.1369  Validation loss = 11.2293  \n",
      "\n",
      "Fold: 9  Epoch: 420  Training loss = 3.1366  Validation loss = 11.2289  \n",
      "\n",
      "Fold: 9  Epoch: 421  Training loss = 3.1364  Validation loss = 11.2286  \n",
      "\n",
      "Fold: 9  Epoch: 422  Training loss = 3.1362  Validation loss = 11.2282  \n",
      "\n",
      "Fold: 9  Epoch: 423  Training loss = 3.1360  Validation loss = 11.2278  \n",
      "\n",
      "Fold: 9  Epoch: 424  Training loss = 3.1358  Validation loss = 11.2275  \n",
      "\n",
      "Fold: 9  Epoch: 425  Training loss = 3.1356  Validation loss = 11.2271  \n",
      "\n",
      "Fold: 9  Epoch: 426  Training loss = 3.1354  Validation loss = 11.2268  \n",
      "\n",
      "Fold: 9  Epoch: 427  Training loss = 3.1352  Validation loss = 11.2264  \n",
      "\n",
      "Fold: 9  Epoch: 428  Training loss = 3.1350  Validation loss = 11.2260  \n",
      "\n",
      "Fold: 9  Epoch: 429  Training loss = 3.1348  Validation loss = 11.2257  \n",
      "\n",
      "Fold: 9  Epoch: 430  Training loss = 3.1346  Validation loss = 11.2254  \n",
      "\n",
      "Fold: 9  Epoch: 431  Training loss = 3.1344  Validation loss = 11.2251  \n",
      "\n",
      "Fold: 9  Epoch: 432  Training loss = 3.1343  Validation loss = 11.2248  \n",
      "\n",
      "Fold: 9  Epoch: 433  Training loss = 3.1341  Validation loss = 11.2244  \n",
      "\n",
      "Fold: 9  Epoch: 434  Training loss = 3.1339  Validation loss = 11.2241  \n",
      "\n",
      "Fold: 9  Epoch: 435  Training loss = 3.1336  Validation loss = 11.2237  \n",
      "\n",
      "Fold: 9  Epoch: 436  Training loss = 3.1335  Validation loss = 11.2234  \n",
      "\n",
      "Fold: 9  Epoch: 437  Training loss = 3.1333  Validation loss = 11.2231  \n",
      "\n",
      "Fold: 9  Epoch: 438  Training loss = 3.1331  Validation loss = 11.2228  \n",
      "\n",
      "Fold: 9  Epoch: 439  Training loss = 3.1329  Validation loss = 11.2225  \n",
      "\n",
      "Fold: 9  Epoch: 440  Training loss = 3.1327  Validation loss = 11.2221  \n",
      "\n",
      "Fold: 9  Epoch: 441  Training loss = 3.1325  Validation loss = 11.2218  \n",
      "\n",
      "Fold: 9  Epoch: 442  Training loss = 3.1323  Validation loss = 11.2214  \n",
      "\n",
      "Fold: 9  Epoch: 443  Training loss = 3.1320  Validation loss = 11.2210  \n",
      "\n",
      "Fold: 9  Epoch: 444  Training loss = 3.1318  Validation loss = 11.2206  \n",
      "\n",
      "Fold: 9  Epoch: 445  Training loss = 3.1316  Validation loss = 11.2202  \n",
      "\n",
      "Fold: 9  Epoch: 446  Training loss = 3.1314  Validation loss = 11.2199  \n",
      "\n",
      "Fold: 9  Epoch: 447  Training loss = 3.1312  Validation loss = 11.2196  \n",
      "\n",
      "Fold: 9  Epoch: 448  Training loss = 3.1310  Validation loss = 11.2192  \n",
      "\n",
      "Fold: 9  Epoch: 449  Training loss = 3.1308  Validation loss = 11.2189  \n",
      "\n",
      "Fold: 9  Epoch: 450  Training loss = 3.1306  Validation loss = 11.2185  \n",
      "\n",
      "Fold: 9  Epoch: 451  Training loss = 3.1304  Validation loss = 11.2182  \n",
      "\n",
      "Fold: 9  Epoch: 452  Training loss = 3.1302  Validation loss = 11.2179  \n",
      "\n",
      "Fold: 9  Epoch: 453  Training loss = 3.1300  Validation loss = 11.2175  \n",
      "\n",
      "Fold: 9  Epoch: 454  Training loss = 3.1298  Validation loss = 11.2172  \n",
      "\n",
      "Fold: 9  Epoch: 455  Training loss = 3.1296  Validation loss = 11.2169  \n",
      "\n",
      "Fold: 9  Epoch: 456  Training loss = 3.1294  Validation loss = 11.2165  \n",
      "\n",
      "Fold: 9  Epoch: 457  Training loss = 3.1292  Validation loss = 11.2162  \n",
      "\n",
      "Fold: 9  Epoch: 458  Training loss = 3.1290  Validation loss = 11.2158  \n",
      "\n",
      "Fold: 9  Epoch: 459  Training loss = 3.1288  Validation loss = 11.2154  \n",
      "\n",
      "Fold: 9  Epoch: 460  Training loss = 3.1286  Validation loss = 11.2151  \n",
      "\n",
      "Fold: 9  Epoch: 461  Training loss = 3.1284  Validation loss = 11.2147  \n",
      "\n",
      "Fold: 9  Epoch: 462  Training loss = 3.1282  Validation loss = 11.2144  \n",
      "\n",
      "Fold: 9  Epoch: 463  Training loss = 3.1280  Validation loss = 11.2140  \n",
      "\n",
      "Fold: 9  Epoch: 464  Training loss = 3.1278  Validation loss = 11.2136  \n",
      "\n",
      "Fold: 9  Epoch: 465  Training loss = 3.1276  Validation loss = 11.2134  \n",
      "\n",
      "Fold: 9  Epoch: 466  Training loss = 3.1274  Validation loss = 11.2131  \n",
      "\n",
      "Fold: 9  Epoch: 467  Training loss = 3.1273  Validation loss = 11.2128  \n",
      "\n",
      "Fold: 9  Epoch: 468  Training loss = 3.1271  Validation loss = 11.2125  \n",
      "\n",
      "Fold: 9  Epoch: 469  Training loss = 3.1269  Validation loss = 11.2122  \n",
      "\n",
      "Fold: 9  Epoch: 470  Training loss = 3.1267  Validation loss = 11.2118  \n",
      "\n",
      "Fold: 9  Epoch: 471  Training loss = 3.1265  Validation loss = 11.2115  \n",
      "\n",
      "Fold: 9  Epoch: 472  Training loss = 3.1263  Validation loss = 11.2111  \n",
      "\n",
      "Fold: 9  Epoch: 473  Training loss = 3.1261  Validation loss = 11.2108  \n",
      "\n",
      "Fold: 9  Epoch: 474  Training loss = 3.1259  Validation loss = 11.2104  \n",
      "\n",
      "Fold: 9  Epoch: 475  Training loss = 3.1257  Validation loss = 11.2101  \n",
      "\n",
      "Fold: 9  Epoch: 476  Training loss = 3.1255  Validation loss = 11.2098  \n",
      "\n",
      "Fold: 9  Epoch: 477  Training loss = 3.1253  Validation loss = 11.2095  \n",
      "\n",
      "Fold: 9  Epoch: 478  Training loss = 3.1251  Validation loss = 11.2091  \n",
      "\n",
      "Fold: 9  Epoch: 479  Training loss = 3.1250  Validation loss = 11.2088  \n",
      "\n",
      "Fold: 9  Epoch: 480  Training loss = 3.1247  Validation loss = 11.2085  \n",
      "\n",
      "Fold: 9  Epoch: 481  Training loss = 3.1245  Validation loss = 11.2081  \n",
      "\n",
      "Fold: 9  Epoch: 482  Training loss = 3.1243  Validation loss = 11.2078  \n",
      "\n",
      "Fold: 9  Epoch: 483  Training loss = 3.1241  Validation loss = 11.2074  \n",
      "\n",
      "Fold: 9  Epoch: 484  Training loss = 3.1239  Validation loss = 11.2070  \n",
      "\n",
      "Fold: 9  Epoch: 485  Training loss = 3.1237  Validation loss = 11.2066  \n",
      "\n",
      "Fold: 9  Epoch: 486  Training loss = 3.1235  Validation loss = 11.2063  \n",
      "\n",
      "Fold: 9  Epoch: 487  Training loss = 3.1233  Validation loss = 11.2060  \n",
      "\n",
      "Fold: 9  Epoch: 488  Training loss = 3.1232  Validation loss = 11.2057  \n",
      "\n",
      "Fold: 9  Epoch: 489  Training loss = 3.1230  Validation loss = 11.2054  \n",
      "\n",
      "Fold: 9  Epoch: 490  Training loss = 3.1228  Validation loss = 11.2051  \n",
      "\n",
      "Fold: 9  Epoch: 491  Training loss = 3.1226  Validation loss = 11.2048  \n",
      "\n",
      "Fold: 9  Epoch: 492  Training loss = 3.1224  Validation loss = 11.2044  \n",
      "\n",
      "Fold: 9  Epoch: 493  Training loss = 3.1221  Validation loss = 11.2040  \n",
      "\n",
      "Fold: 9  Epoch: 494  Training loss = 3.1219  Validation loss = 11.2036  \n",
      "\n",
      "Fold: 9  Epoch: 495  Training loss = 3.1217  Validation loss = 11.2032  \n",
      "\n",
      "Fold: 9  Epoch: 496  Training loss = 3.1215  Validation loss = 11.2029  \n",
      "\n",
      "Fold: 9  Epoch: 497  Training loss = 3.1213  Validation loss = 11.2025  \n",
      "\n",
      "Fold: 9  Epoch: 498  Training loss = 3.1211  Validation loss = 11.2022  \n",
      "\n",
      "Fold: 9  Epoch: 499  Training loss = 3.1209  Validation loss = 11.2018  \n",
      "\n",
      "Fold: 9  Epoch: 500  Training loss = 3.1207  Validation loss = 11.2015  \n",
      "\n",
      "Check model:  Fold: 9  Optimal epoch: 500  \n",
      "\n",
      "Fold: 10  Epoch: 1  Training loss = 4.1425  Validation loss = 6.8551  \n",
      "\n",
      "Fold: 10  Epoch: 2  Training loss = 4.1422  Validation loss = 6.8546  \n",
      "\n",
      "Fold: 10  Epoch: 3  Training loss = 4.1419  Validation loss = 6.8542  \n",
      "\n",
      "Fold: 10  Epoch: 4  Training loss = 4.1416  Validation loss = 6.8537  \n",
      "\n",
      "Fold: 10  Epoch: 5  Training loss = 4.1413  Validation loss = 6.8533  \n",
      "\n",
      "Fold: 10  Epoch: 6  Training loss = 4.1410  Validation loss = 6.8528  \n",
      "\n",
      "Fold: 10  Epoch: 7  Training loss = 4.1408  Validation loss = 6.8524  \n",
      "\n",
      "Fold: 10  Epoch: 8  Training loss = 4.1405  Validation loss = 6.8520  \n",
      "\n",
      "Fold: 10  Epoch: 9  Training loss = 4.1401  Validation loss = 6.8514  \n",
      "\n",
      "Fold: 10  Epoch: 10  Training loss = 4.1398  Validation loss = 6.8510  \n",
      "\n",
      "Fold: 10  Epoch: 11  Training loss = 4.1395  Validation loss = 6.8506  \n",
      "\n",
      "Fold: 10  Epoch: 12  Training loss = 4.1392  Validation loss = 6.8501  \n",
      "\n",
      "Fold: 10  Epoch: 13  Training loss = 4.1390  Validation loss = 6.8496  \n",
      "\n",
      "Fold: 10  Epoch: 14  Training loss = 4.1387  Validation loss = 6.8492  \n",
      "\n",
      "Fold: 10  Epoch: 15  Training loss = 4.1384  Validation loss = 6.8487  \n",
      "\n",
      "Fold: 10  Epoch: 16  Training loss = 4.1382  Validation loss = 6.8485  \n",
      "\n",
      "Fold: 10  Epoch: 17  Training loss = 4.1379  Validation loss = 6.8479  \n",
      "\n",
      "Fold: 10  Epoch: 18  Training loss = 4.1376  Validation loss = 6.8475  \n",
      "\n",
      "Fold: 10  Epoch: 19  Training loss = 4.1374  Validation loss = 6.8471  \n",
      "\n",
      "Fold: 10  Epoch: 20  Training loss = 4.1371  Validation loss = 6.8467  \n",
      "\n",
      "Fold: 10  Epoch: 21  Training loss = 4.1369  Validation loss = 6.8464  \n",
      "\n",
      "Fold: 10  Epoch: 22  Training loss = 4.1366  Validation loss = 6.8461  \n",
      "\n",
      "Fold: 10  Epoch: 23  Training loss = 4.1364  Validation loss = 6.8457  \n",
      "\n",
      "Fold: 10  Epoch: 24  Training loss = 4.1361  Validation loss = 6.8452  \n",
      "\n",
      "Fold: 10  Epoch: 25  Training loss = 4.1358  Validation loss = 6.8448  \n",
      "\n",
      "Fold: 10  Epoch: 26  Training loss = 4.1355  Validation loss = 6.8444  \n",
      "\n",
      "Fold: 10  Epoch: 27  Training loss = 4.1352  Validation loss = 6.8440  \n",
      "\n",
      "Fold: 10  Epoch: 28  Training loss = 4.1350  Validation loss = 6.8436  \n",
      "\n",
      "Fold: 10  Epoch: 29  Training loss = 4.1347  Validation loss = 6.8432  \n",
      "\n",
      "Fold: 10  Epoch: 30  Training loss = 4.1345  Validation loss = 6.8428  \n",
      "\n",
      "Fold: 10  Epoch: 31  Training loss = 4.1342  Validation loss = 6.8424  \n",
      "\n",
      "Fold: 10  Epoch: 32  Training loss = 4.1339  Validation loss = 6.8420  \n",
      "\n",
      "Fold: 10  Epoch: 33  Training loss = 4.1336  Validation loss = 6.8414  \n",
      "\n",
      "Fold: 10  Epoch: 34  Training loss = 4.1332  Validation loss = 6.8409  \n",
      "\n",
      "Fold: 10  Epoch: 35  Training loss = 4.1329  Validation loss = 6.8404  \n",
      "\n",
      "Fold: 10  Epoch: 36  Training loss = 4.1327  Validation loss = 6.8401  \n",
      "\n",
      "Fold: 10  Epoch: 37  Training loss = 4.1325  Validation loss = 6.8398  \n",
      "\n",
      "Fold: 10  Epoch: 38  Training loss = 4.1323  Validation loss = 6.8395  \n",
      "\n",
      "Fold: 10  Epoch: 39  Training loss = 4.1320  Validation loss = 6.8391  \n",
      "\n",
      "Fold: 10  Epoch: 40  Training loss = 4.1318  Validation loss = 6.8387  \n",
      "\n",
      "Fold: 10  Epoch: 41  Training loss = 4.1314  Validation loss = 6.8382  \n",
      "\n",
      "Fold: 10  Epoch: 42  Training loss = 4.1312  Validation loss = 6.8379  \n",
      "\n",
      "Fold: 10  Epoch: 43  Training loss = 4.1309  Validation loss = 6.8375  \n",
      "\n",
      "Fold: 10  Epoch: 44  Training loss = 4.1306  Validation loss = 6.8371  \n",
      "\n",
      "Fold: 10  Epoch: 45  Training loss = 4.1303  Validation loss = 6.8366  \n",
      "\n",
      "Fold: 10  Epoch: 46  Training loss = 4.1301  Validation loss = 6.8363  \n",
      "\n",
      "Fold: 10  Epoch: 47  Training loss = 4.1298  Validation loss = 6.8358  \n",
      "\n",
      "Fold: 10  Epoch: 48  Training loss = 4.1295  Validation loss = 6.8353  \n",
      "\n",
      "Fold: 10  Epoch: 49  Training loss = 4.1292  Validation loss = 6.8350  \n",
      "\n",
      "Fold: 10  Epoch: 50  Training loss = 4.1290  Validation loss = 6.8346  \n",
      "\n",
      "Fold: 10  Epoch: 51  Training loss = 4.1287  Validation loss = 6.8342  \n",
      "\n",
      "Fold: 10  Epoch: 52  Training loss = 4.1284  Validation loss = 6.8338  \n",
      "\n",
      "Fold: 10  Epoch: 53  Training loss = 4.1281  Validation loss = 6.8334  \n",
      "\n",
      "Fold: 10  Epoch: 54  Training loss = 4.1278  Validation loss = 6.8329  \n",
      "\n",
      "Fold: 10  Epoch: 55  Training loss = 4.1276  Validation loss = 6.8326  \n",
      "\n",
      "Fold: 10  Epoch: 56  Training loss = 4.1274  Validation loss = 6.8323  \n",
      "\n",
      "Fold: 10  Epoch: 57  Training loss = 4.1270  Validation loss = 6.8317  \n",
      "\n",
      "Fold: 10  Epoch: 58  Training loss = 4.1268  Validation loss = 6.8313  \n",
      "\n",
      "Fold: 10  Epoch: 59  Training loss = 4.1265  Validation loss = 6.8309  \n",
      "\n",
      "Fold: 10  Epoch: 60  Training loss = 4.1262  Validation loss = 6.8305  \n",
      "\n",
      "Fold: 10  Epoch: 61  Training loss = 4.1259  Validation loss = 6.8300  \n",
      "\n",
      "Fold: 10  Epoch: 62  Training loss = 4.1256  Validation loss = 6.8295  \n",
      "\n",
      "Fold: 10  Epoch: 63  Training loss = 4.1253  Validation loss = 6.8290  \n",
      "\n",
      "Fold: 10  Epoch: 64  Training loss = 4.1251  Validation loss = 6.8287  \n",
      "\n",
      "Fold: 10  Epoch: 65  Training loss = 4.1248  Validation loss = 6.8284  \n",
      "\n",
      "Fold: 10  Epoch: 66  Training loss = 4.1245  Validation loss = 6.8280  \n",
      "\n",
      "Fold: 10  Epoch: 67  Training loss = 4.1242  Validation loss = 6.8275  \n",
      "\n",
      "Fold: 10  Epoch: 68  Training loss = 4.1240  Validation loss = 6.8272  \n",
      "\n",
      "Fold: 10  Epoch: 69  Training loss = 4.1237  Validation loss = 6.8267  \n",
      "\n",
      "Fold: 10  Epoch: 70  Training loss = 4.1234  Validation loss = 6.8264  \n",
      "\n",
      "Fold: 10  Epoch: 71  Training loss = 4.1231  Validation loss = 6.8259  \n",
      "\n",
      "Fold: 10  Epoch: 72  Training loss = 4.1229  Validation loss = 6.8255  \n",
      "\n",
      "Fold: 10  Epoch: 73  Training loss = 4.1226  Validation loss = 6.8252  \n",
      "\n",
      "Fold: 10  Epoch: 74  Training loss = 4.1224  Validation loss = 6.8248  \n",
      "\n",
      "Fold: 10  Epoch: 75  Training loss = 4.1221  Validation loss = 6.8244  \n",
      "\n",
      "Fold: 10  Epoch: 76  Training loss = 4.1218  Validation loss = 6.8239  \n",
      "\n",
      "Fold: 10  Epoch: 77  Training loss = 4.1215  Validation loss = 6.8236  \n",
      "\n",
      "Fold: 10  Epoch: 78  Training loss = 4.1213  Validation loss = 6.8233  \n",
      "\n",
      "Fold: 10  Epoch: 79  Training loss = 4.1210  Validation loss = 6.8229  \n",
      "\n",
      "Fold: 10  Epoch: 80  Training loss = 4.1206  Validation loss = 6.8223  \n",
      "\n",
      "Fold: 10  Epoch: 81  Training loss = 4.1204  Validation loss = 6.8221  \n",
      "\n",
      "Fold: 10  Epoch: 82  Training loss = 4.1202  Validation loss = 6.8217  \n",
      "\n",
      "Fold: 10  Epoch: 83  Training loss = 4.1200  Validation loss = 6.8214  \n",
      "\n",
      "Fold: 10  Epoch: 84  Training loss = 4.1196  Validation loss = 6.8209  \n",
      "\n",
      "Fold: 10  Epoch: 85  Training loss = 4.1194  Validation loss = 6.8205  \n",
      "\n",
      "Fold: 10  Epoch: 86  Training loss = 4.1191  Validation loss = 6.8202  \n",
      "\n",
      "Fold: 10  Epoch: 87  Training loss = 4.1187  Validation loss = 6.8195  \n",
      "\n",
      "Fold: 10  Epoch: 88  Training loss = 4.1184  Validation loss = 6.8192  \n",
      "\n",
      "Fold: 10  Epoch: 89  Training loss = 4.1182  Validation loss = 6.8188  \n",
      "\n",
      "Fold: 10  Epoch: 90  Training loss = 4.1179  Validation loss = 6.8185  \n",
      "\n",
      "Fold: 10  Epoch: 91  Training loss = 4.1177  Validation loss = 6.8181  \n",
      "\n",
      "Fold: 10  Epoch: 92  Training loss = 4.1174  Validation loss = 6.8177  \n",
      "\n",
      "Fold: 10  Epoch: 93  Training loss = 4.1172  Validation loss = 6.8174  \n",
      "\n",
      "Fold: 10  Epoch: 94  Training loss = 4.1168  Validation loss = 6.8169  \n",
      "\n",
      "Fold: 10  Epoch: 95  Training loss = 4.1166  Validation loss = 6.8165  \n",
      "\n",
      "Fold: 10  Epoch: 96  Training loss = 4.1163  Validation loss = 6.8161  \n",
      "\n",
      "Fold: 10  Epoch: 97  Training loss = 4.1160  Validation loss = 6.8156  \n",
      "\n",
      "Fold: 10  Epoch: 98  Training loss = 4.1158  Validation loss = 6.8153  \n",
      "\n",
      "Fold: 10  Epoch: 99  Training loss = 4.1154  Validation loss = 6.8147  \n",
      "\n",
      "Fold: 10  Epoch: 100  Training loss = 4.1152  Validation loss = 6.8144  \n",
      "\n",
      "Fold: 10  Epoch: 101  Training loss = 4.1149  Validation loss = 6.8141  \n",
      "\n",
      "Fold: 10  Epoch: 102  Training loss = 4.1146  Validation loss = 6.8137  \n",
      "\n",
      "Fold: 10  Epoch: 103  Training loss = 4.1144  Validation loss = 6.8133  \n",
      "\n",
      "Fold: 10  Epoch: 104  Training loss = 4.1141  Validation loss = 6.8129  \n",
      "\n",
      "Fold: 10  Epoch: 105  Training loss = 4.1138  Validation loss = 6.8125  \n",
      "\n",
      "Fold: 10  Epoch: 106  Training loss = 4.1135  Validation loss = 6.8121  \n",
      "\n",
      "Fold: 10  Epoch: 107  Training loss = 4.1133  Validation loss = 6.8117  \n",
      "\n",
      "Fold: 10  Epoch: 108  Training loss = 4.1130  Validation loss = 6.8114  \n",
      "\n",
      "Fold: 10  Epoch: 109  Training loss = 4.1126  Validation loss = 6.8109  \n",
      "\n",
      "Fold: 10  Epoch: 110  Training loss = 4.1125  Validation loss = 6.8106  \n",
      "\n",
      "Fold: 10  Epoch: 111  Training loss = 4.1121  Validation loss = 6.8101  \n",
      "\n",
      "Fold: 10  Epoch: 112  Training loss = 4.1119  Validation loss = 6.8098  \n",
      "\n",
      "Fold: 10  Epoch: 113  Training loss = 4.1117  Validation loss = 6.8096  \n",
      "\n",
      "Fold: 10  Epoch: 114  Training loss = 4.1115  Validation loss = 6.8093  \n",
      "\n",
      "Fold: 10  Epoch: 115  Training loss = 4.1113  Validation loss = 6.8090  \n",
      "\n",
      "Fold: 10  Epoch: 116  Training loss = 4.1110  Validation loss = 6.8086  \n",
      "\n",
      "Fold: 10  Epoch: 117  Training loss = 4.1107  Validation loss = 6.8081  \n",
      "\n",
      "Fold: 10  Epoch: 118  Training loss = 4.1104  Validation loss = 6.8077  \n",
      "\n",
      "Fold: 10  Epoch: 119  Training loss = 4.1102  Validation loss = 6.8074  \n",
      "\n",
      "Fold: 10  Epoch: 120  Training loss = 4.1098  Validation loss = 6.8069  \n",
      "\n",
      "Fold: 10  Epoch: 121  Training loss = 4.1095  Validation loss = 6.8064  \n",
      "\n",
      "Fold: 10  Epoch: 122  Training loss = 4.1092  Validation loss = 6.8061  \n",
      "\n",
      "Fold: 10  Epoch: 123  Training loss = 4.1089  Validation loss = 6.8056  \n",
      "\n",
      "Fold: 10  Epoch: 124  Training loss = 4.1087  Validation loss = 6.8053  \n",
      "\n",
      "Fold: 10  Epoch: 125  Training loss = 4.1084  Validation loss = 6.8049  \n",
      "\n",
      "Fold: 10  Epoch: 126  Training loss = 4.1081  Validation loss = 6.8045  \n",
      "\n",
      "Fold: 10  Epoch: 127  Training loss = 4.1079  Validation loss = 6.8043  \n",
      "\n",
      "Fold: 10  Epoch: 128  Training loss = 4.1077  Validation loss = 6.8039  \n",
      "\n",
      "Fold: 10  Epoch: 129  Training loss = 4.1074  Validation loss = 6.8034  \n",
      "\n",
      "Fold: 10  Epoch: 130  Training loss = 4.1072  Validation loss = 6.8031  \n",
      "\n",
      "Fold: 10  Epoch: 131  Training loss = 4.1069  Validation loss = 6.8027  \n",
      "\n",
      "Fold: 10  Epoch: 132  Training loss = 4.1067  Validation loss = 6.8025  \n",
      "\n",
      "Fold: 10  Epoch: 133  Training loss = 4.1064  Validation loss = 6.8021  \n",
      "\n",
      "Fold: 10  Epoch: 134  Training loss = 4.1062  Validation loss = 6.8018  \n",
      "\n",
      "Fold: 10  Epoch: 135  Training loss = 4.1060  Validation loss = 6.8015  \n",
      "\n",
      "Fold: 10  Epoch: 136  Training loss = 4.1056  Validation loss = 6.8011  \n",
      "\n",
      "Fold: 10  Epoch: 137  Training loss = 4.1053  Validation loss = 6.8007  \n",
      "\n",
      "Fold: 10  Epoch: 138  Training loss = 4.1051  Validation loss = 6.8003  \n",
      "\n",
      "Fold: 10  Epoch: 139  Training loss = 4.1049  Validation loss = 6.8000  \n",
      "\n",
      "Fold: 10  Epoch: 140  Training loss = 4.1046  Validation loss = 6.7996  \n",
      "\n",
      "Fold: 10  Epoch: 141  Training loss = 4.1044  Validation loss = 6.7993  \n",
      "\n",
      "Fold: 10  Epoch: 142  Training loss = 4.1041  Validation loss = 6.7990  \n",
      "\n",
      "Fold: 10  Epoch: 143  Training loss = 4.1038  Validation loss = 6.7985  \n",
      "\n",
      "Fold: 10  Epoch: 144  Training loss = 4.1035  Validation loss = 6.7981  \n",
      "\n",
      "Fold: 10  Epoch: 145  Training loss = 4.1032  Validation loss = 6.7977  \n",
      "\n",
      "Fold: 10  Epoch: 146  Training loss = 4.1029  Validation loss = 6.7974  \n",
      "\n",
      "Fold: 10  Epoch: 147  Training loss = 4.1027  Validation loss = 6.7971  \n",
      "\n",
      "Fold: 10  Epoch: 148  Training loss = 4.1025  Validation loss = 6.7968  \n",
      "\n",
      "Fold: 10  Epoch: 149  Training loss = 4.1023  Validation loss = 6.7966  \n",
      "\n",
      "Fold: 10  Epoch: 150  Training loss = 4.1020  Validation loss = 6.7962  \n",
      "\n",
      "Fold: 10  Epoch: 151  Training loss = 4.1018  Validation loss = 6.7959  \n",
      "\n",
      "Fold: 10  Epoch: 152  Training loss = 4.1015  Validation loss = 6.7955  \n",
      "\n",
      "Fold: 10  Epoch: 153  Training loss = 4.1012  Validation loss = 6.7952  \n",
      "\n",
      "Fold: 10  Epoch: 154  Training loss = 4.1009  Validation loss = 6.7948  \n",
      "\n",
      "Fold: 10  Epoch: 155  Training loss = 4.1007  Validation loss = 6.7944  \n",
      "\n",
      "Fold: 10  Epoch: 156  Training loss = 4.1004  Validation loss = 6.7941  \n",
      "\n",
      "Fold: 10  Epoch: 157  Training loss = 4.1001  Validation loss = 6.7937  \n",
      "\n",
      "Fold: 10  Epoch: 158  Training loss = 4.0999  Validation loss = 6.7934  \n",
      "\n",
      "Fold: 10  Epoch: 159  Training loss = 4.0996  Validation loss = 6.7930  \n",
      "\n",
      "Fold: 10  Epoch: 160  Training loss = 4.0995  Validation loss = 6.7928  \n",
      "\n",
      "Fold: 10  Epoch: 161  Training loss = 4.0992  Validation loss = 6.7924  \n",
      "\n",
      "Fold: 10  Epoch: 162  Training loss = 4.0989  Validation loss = 6.7920  \n",
      "\n",
      "Fold: 10  Epoch: 163  Training loss = 4.0986  Validation loss = 6.7916  \n",
      "\n",
      "Fold: 10  Epoch: 164  Training loss = 4.0985  Validation loss = 6.7915  \n",
      "\n",
      "Fold: 10  Epoch: 165  Training loss = 4.0981  Validation loss = 6.7910  \n",
      "\n",
      "Fold: 10  Epoch: 166  Training loss = 4.0979  Validation loss = 6.7907  \n",
      "\n",
      "Fold: 10  Epoch: 167  Training loss = 4.0976  Validation loss = 6.7903  \n",
      "\n",
      "Fold: 10  Epoch: 168  Training loss = 4.0974  Validation loss = 6.7901  \n",
      "\n",
      "Fold: 10  Epoch: 169  Training loss = 4.0971  Validation loss = 6.7897  \n",
      "\n",
      "Fold: 10  Epoch: 170  Training loss = 4.0969  Validation loss = 6.7893  \n",
      "\n",
      "Fold: 10  Epoch: 171  Training loss = 4.0966  Validation loss = 6.7890  \n",
      "\n",
      "Fold: 10  Epoch: 172  Training loss = 4.0963  Validation loss = 6.7886  \n",
      "\n",
      "Fold: 10  Epoch: 173  Training loss = 4.0961  Validation loss = 6.7883  \n",
      "\n",
      "Fold: 10  Epoch: 174  Training loss = 4.0959  Validation loss = 6.7879  \n",
      "\n",
      "Fold: 10  Epoch: 175  Training loss = 4.0956  Validation loss = 6.7875  \n",
      "\n",
      "Fold: 10  Epoch: 176  Training loss = 4.0953  Validation loss = 6.7872  \n",
      "\n",
      "Fold: 10  Epoch: 177  Training loss = 4.0950  Validation loss = 6.7868  \n",
      "\n",
      "Fold: 10  Epoch: 178  Training loss = 4.0947  Validation loss = 6.7864  \n",
      "\n",
      "Fold: 10  Epoch: 179  Training loss = 4.0945  Validation loss = 6.7860  \n",
      "\n",
      "Fold: 10  Epoch: 180  Training loss = 4.0942  Validation loss = 6.7856  \n",
      "\n",
      "Fold: 10  Epoch: 181  Training loss = 4.0939  Validation loss = 6.7853  \n",
      "\n",
      "Fold: 10  Epoch: 182  Training loss = 4.0937  Validation loss = 6.7850  \n",
      "\n",
      "Fold: 10  Epoch: 183  Training loss = 4.0935  Validation loss = 6.7847  \n",
      "\n",
      "Fold: 10  Epoch: 184  Training loss = 4.0932  Validation loss = 6.7843  \n",
      "\n",
      "Fold: 10  Epoch: 185  Training loss = 4.0929  Validation loss = 6.7839  \n",
      "\n",
      "Fold: 10  Epoch: 186  Training loss = 4.0927  Validation loss = 6.7836  \n",
      "\n",
      "Fold: 10  Epoch: 187  Training loss = 4.0924  Validation loss = 6.7832  \n",
      "\n",
      "Fold: 10  Epoch: 188  Training loss = 4.0922  Validation loss = 6.7829  \n",
      "\n",
      "Fold: 10  Epoch: 189  Training loss = 4.0920  Validation loss = 6.7826  \n",
      "\n",
      "Fold: 10  Epoch: 190  Training loss = 4.0917  Validation loss = 6.7823  \n",
      "\n",
      "Fold: 10  Epoch: 191  Training loss = 4.0915  Validation loss = 6.7820  \n",
      "\n",
      "Fold: 10  Epoch: 192  Training loss = 4.0912  Validation loss = 6.7816  \n",
      "\n",
      "Fold: 10  Epoch: 193  Training loss = 4.0910  Validation loss = 6.7813  \n",
      "\n",
      "Fold: 10  Epoch: 194  Training loss = 4.0907  Validation loss = 6.7809  \n",
      "\n",
      "Fold: 10  Epoch: 195  Training loss = 4.0904  Validation loss = 6.7805  \n",
      "\n",
      "Fold: 10  Epoch: 196  Training loss = 4.0902  Validation loss = 6.7802  \n",
      "\n",
      "Fold: 10  Epoch: 197  Training loss = 4.0898  Validation loss = 6.7798  \n",
      "\n",
      "Fold: 10  Epoch: 198  Training loss = 4.0895  Validation loss = 6.7794  \n",
      "\n",
      "Fold: 10  Epoch: 199  Training loss = 4.0893  Validation loss = 6.7791  \n",
      "\n",
      "Fold: 10  Epoch: 200  Training loss = 4.0890  Validation loss = 6.7787  \n",
      "\n",
      "Fold: 10  Epoch: 201  Training loss = 4.0887  Validation loss = 6.7784  \n",
      "\n",
      "Fold: 10  Epoch: 202  Training loss = 4.0884  Validation loss = 6.7779  \n",
      "\n",
      "Fold: 10  Epoch: 203  Training loss = 4.0881  Validation loss = 6.7775  \n",
      "\n",
      "Fold: 10  Epoch: 204  Training loss = 4.0878  Validation loss = 6.7772  \n",
      "\n",
      "Fold: 10  Epoch: 205  Training loss = 4.0876  Validation loss = 6.7768  \n",
      "\n",
      "Fold: 10  Epoch: 206  Training loss = 4.0873  Validation loss = 6.7764  \n",
      "\n",
      "Fold: 10  Epoch: 207  Training loss = 4.0870  Validation loss = 6.7761  \n",
      "\n",
      "Fold: 10  Epoch: 208  Training loss = 4.0868  Validation loss = 6.7758  \n",
      "\n",
      "Fold: 10  Epoch: 209  Training loss = 4.0865  Validation loss = 6.7754  \n",
      "\n",
      "Fold: 10  Epoch: 210  Training loss = 4.0863  Validation loss = 6.7752  \n",
      "\n",
      "Fold: 10  Epoch: 211  Training loss = 4.0861  Validation loss = 6.7749  \n",
      "\n",
      "Fold: 10  Epoch: 212  Training loss = 4.0858  Validation loss = 6.7745  \n",
      "\n",
      "Fold: 10  Epoch: 213  Training loss = 4.0855  Validation loss = 6.7742  \n",
      "\n",
      "Fold: 10  Epoch: 214  Training loss = 4.0853  Validation loss = 6.7739  \n",
      "\n",
      "Fold: 10  Epoch: 215  Training loss = 4.0850  Validation loss = 6.7736  \n",
      "\n",
      "Fold: 10  Epoch: 216  Training loss = 4.0848  Validation loss = 6.7733  \n",
      "\n",
      "Fold: 10  Epoch: 217  Training loss = 4.0845  Validation loss = 6.7729  \n",
      "\n",
      "Fold: 10  Epoch: 218  Training loss = 4.0842  Validation loss = 6.7725  \n",
      "\n",
      "Fold: 10  Epoch: 219  Training loss = 4.0840  Validation loss = 6.7722  \n",
      "\n",
      "Fold: 10  Epoch: 220  Training loss = 4.0837  Validation loss = 6.7719  \n",
      "\n",
      "Fold: 10  Epoch: 221  Training loss = 4.0834  Validation loss = 6.7714  \n",
      "\n",
      "Fold: 10  Epoch: 222  Training loss = 4.0832  Validation loss = 6.7711  \n",
      "\n",
      "Fold: 10  Epoch: 223  Training loss = 4.0829  Validation loss = 6.7708  \n",
      "\n",
      "Fold: 10  Epoch: 224  Training loss = 4.0827  Validation loss = 6.7705  \n",
      "\n",
      "Fold: 10  Epoch: 225  Training loss = 4.0824  Validation loss = 6.7702  \n",
      "\n",
      "Fold: 10  Epoch: 226  Training loss = 4.0822  Validation loss = 6.7698  \n",
      "\n",
      "Fold: 10  Epoch: 227  Training loss = 4.0819  Validation loss = 6.7695  \n",
      "\n",
      "Fold: 10  Epoch: 228  Training loss = 4.0817  Validation loss = 6.7692  \n",
      "\n",
      "Fold: 10  Epoch: 229  Training loss = 4.0815  Validation loss = 6.7689  \n",
      "\n",
      "Fold: 10  Epoch: 230  Training loss = 4.0812  Validation loss = 6.7685  \n",
      "\n",
      "Fold: 10  Epoch: 231  Training loss = 4.0809  Validation loss = 6.7682  \n",
      "\n",
      "Fold: 10  Epoch: 232  Training loss = 4.0807  Validation loss = 6.7679  \n",
      "\n",
      "Fold: 10  Epoch: 233  Training loss = 4.0804  Validation loss = 6.7676  \n",
      "\n",
      "Fold: 10  Epoch: 234  Training loss = 4.0802  Validation loss = 6.7673  \n",
      "\n",
      "Fold: 10  Epoch: 235  Training loss = 4.0800  Validation loss = 6.7670  \n",
      "\n",
      "Fold: 10  Epoch: 236  Training loss = 4.0797  Validation loss = 6.7667  \n",
      "\n",
      "Fold: 10  Epoch: 237  Training loss = 4.0794  Validation loss = 6.7664  \n",
      "\n",
      "Fold: 10  Epoch: 238  Training loss = 4.0792  Validation loss = 6.7660  \n",
      "\n",
      "Fold: 10  Epoch: 239  Training loss = 4.0789  Validation loss = 6.7656  \n",
      "\n",
      "Fold: 10  Epoch: 240  Training loss = 4.0786  Validation loss = 6.7652  \n",
      "\n",
      "Fold: 10  Epoch: 241  Training loss = 4.0783  Validation loss = 6.7649  \n",
      "\n",
      "Fold: 10  Epoch: 242  Training loss = 4.0781  Validation loss = 6.7645  \n",
      "\n",
      "Fold: 10  Epoch: 243  Training loss = 4.0778  Validation loss = 6.7642  \n",
      "\n",
      "Fold: 10  Epoch: 244  Training loss = 4.0776  Validation loss = 6.7638  \n",
      "\n",
      "Fold: 10  Epoch: 245  Training loss = 4.0774  Validation loss = 6.7636  \n",
      "\n",
      "Fold: 10  Epoch: 246  Training loss = 4.0771  Validation loss = 6.7633  \n",
      "\n",
      "Fold: 10  Epoch: 247  Training loss = 4.0769  Validation loss = 6.7629  \n",
      "\n",
      "Fold: 10  Epoch: 248  Training loss = 4.0766  Validation loss = 6.7625  \n",
      "\n",
      "Fold: 10  Epoch: 249  Training loss = 4.0764  Validation loss = 6.7622  \n",
      "\n",
      "Fold: 10  Epoch: 250  Training loss = 4.0761  Validation loss = 6.7619  \n",
      "\n",
      "Fold: 10  Epoch: 251  Training loss = 4.0759  Validation loss = 6.7616  \n",
      "\n",
      "Fold: 10  Epoch: 252  Training loss = 4.0756  Validation loss = 6.7612  \n",
      "\n",
      "Fold: 10  Epoch: 253  Training loss = 4.0754  Validation loss = 6.7610  \n",
      "\n",
      "Fold: 10  Epoch: 254  Training loss = 4.0751  Validation loss = 6.7606  \n",
      "\n",
      "Fold: 10  Epoch: 255  Training loss = 4.0749  Validation loss = 6.7603  \n",
      "\n",
      "Fold: 10  Epoch: 256  Training loss = 4.0746  Validation loss = 6.7600  \n",
      "\n",
      "Fold: 10  Epoch: 257  Training loss = 4.0744  Validation loss = 6.7597  \n",
      "\n",
      "Fold: 10  Epoch: 258  Training loss = 4.0742  Validation loss = 6.7594  \n",
      "\n",
      "Fold: 10  Epoch: 259  Training loss = 4.0739  Validation loss = 6.7590  \n",
      "\n",
      "Fold: 10  Epoch: 260  Training loss = 4.0736  Validation loss = 6.7586  \n",
      "\n",
      "Fold: 10  Epoch: 261  Training loss = 4.0734  Validation loss = 6.7583  \n",
      "\n",
      "Fold: 10  Epoch: 262  Training loss = 4.0732  Validation loss = 6.7580  \n",
      "\n",
      "Fold: 10  Epoch: 263  Training loss = 4.0729  Validation loss = 6.7576  \n",
      "\n",
      "Fold: 10  Epoch: 264  Training loss = 4.0725  Validation loss = 6.7572  \n",
      "\n",
      "Fold: 10  Epoch: 265  Training loss = 4.0723  Validation loss = 6.7568  \n",
      "\n",
      "Fold: 10  Epoch: 266  Training loss = 4.0721  Validation loss = 6.7566  \n",
      "\n",
      "Fold: 10  Epoch: 267  Training loss = 4.0718  Validation loss = 6.7562  \n",
      "\n",
      "Fold: 10  Epoch: 268  Training loss = 4.0715  Validation loss = 6.7558  \n",
      "\n",
      "Fold: 10  Epoch: 269  Training loss = 4.0713  Validation loss = 6.7555  \n",
      "\n",
      "Fold: 10  Epoch: 270  Training loss = 4.0710  Validation loss = 6.7552  \n",
      "\n",
      "Fold: 10  Epoch: 271  Training loss = 4.0708  Validation loss = 6.7548  \n",
      "\n",
      "Fold: 10  Epoch: 272  Training loss = 4.0705  Validation loss = 6.7545  \n",
      "\n",
      "Fold: 10  Epoch: 273  Training loss = 4.0703  Validation loss = 6.7542  \n",
      "\n",
      "Fold: 10  Epoch: 274  Training loss = 4.0701  Validation loss = 6.7539  \n",
      "\n",
      "Fold: 10  Epoch: 275  Training loss = 4.0698  Validation loss = 6.7536  \n",
      "\n",
      "Fold: 10  Epoch: 276  Training loss = 4.0695  Validation loss = 6.7532  \n",
      "\n",
      "Fold: 10  Epoch: 277  Training loss = 4.0693  Validation loss = 6.7529  \n",
      "\n",
      "Fold: 10  Epoch: 278  Training loss = 4.0691  Validation loss = 6.7527  \n",
      "\n",
      "Fold: 10  Epoch: 279  Training loss = 4.0689  Validation loss = 6.7524  \n",
      "\n",
      "Fold: 10  Epoch: 280  Training loss = 4.0686  Validation loss = 6.7521  \n",
      "\n",
      "Fold: 10  Epoch: 281  Training loss = 4.0684  Validation loss = 6.7519  \n",
      "\n",
      "Fold: 10  Epoch: 282  Training loss = 4.0681  Validation loss = 6.7514  \n",
      "\n",
      "Fold: 10  Epoch: 283  Training loss = 4.0679  Validation loss = 6.7511  \n",
      "\n",
      "Fold: 10  Epoch: 284  Training loss = 4.0677  Validation loss = 6.7509  \n",
      "\n",
      "Fold: 10  Epoch: 285  Training loss = 4.0675  Validation loss = 6.7506  \n",
      "\n",
      "Fold: 10  Epoch: 286  Training loss = 4.0673  Validation loss = 6.7503  \n",
      "\n",
      "Fold: 10  Epoch: 287  Training loss = 4.0669  Validation loss = 6.7499  \n",
      "\n",
      "Fold: 10  Epoch: 288  Training loss = 4.0667  Validation loss = 6.7496  \n",
      "\n",
      "Fold: 10  Epoch: 289  Training loss = 4.0665  Validation loss = 6.7494  \n",
      "\n",
      "Fold: 10  Epoch: 290  Training loss = 4.0662  Validation loss = 6.7490  \n",
      "\n",
      "Fold: 10  Epoch: 291  Training loss = 4.0660  Validation loss = 6.7488  \n",
      "\n",
      "Fold: 10  Epoch: 292  Training loss = 4.0657  Validation loss = 6.7484  \n",
      "\n",
      "Fold: 10  Epoch: 293  Training loss = 4.0654  Validation loss = 6.7480  \n",
      "\n",
      "Fold: 10  Epoch: 294  Training loss = 4.0652  Validation loss = 6.7478  \n",
      "\n",
      "Fold: 10  Epoch: 295  Training loss = 4.0650  Validation loss = 6.7475  \n",
      "\n",
      "Fold: 10  Epoch: 296  Training loss = 4.0647  Validation loss = 6.7471  \n",
      "\n",
      "Fold: 10  Epoch: 297  Training loss = 4.0645  Validation loss = 6.7468  \n",
      "\n",
      "Fold: 10  Epoch: 298  Training loss = 4.0642  Validation loss = 6.7464  \n",
      "\n",
      "Fold: 10  Epoch: 299  Training loss = 4.0639  Validation loss = 6.7461  \n",
      "\n",
      "Fold: 10  Epoch: 300  Training loss = 4.0638  Validation loss = 6.7458  \n",
      "\n",
      "Fold: 10  Epoch: 301  Training loss = 4.0635  Validation loss = 6.7455  \n",
      "\n",
      "Fold: 10  Epoch: 302  Training loss = 4.0633  Validation loss = 6.7452  \n",
      "\n",
      "Fold: 10  Epoch: 303  Training loss = 4.0630  Validation loss = 6.7449  \n",
      "\n",
      "Fold: 10  Epoch: 304  Training loss = 4.0627  Validation loss = 6.7445  \n",
      "\n",
      "Fold: 10  Epoch: 305  Training loss = 4.0624  Validation loss = 6.7440  \n",
      "\n",
      "Fold: 10  Epoch: 306  Training loss = 4.0621  Validation loss = 6.7437  \n",
      "\n",
      "Fold: 10  Epoch: 307  Training loss = 4.0618  Validation loss = 6.7433  \n",
      "\n",
      "Fold: 10  Epoch: 308  Training loss = 4.0616  Validation loss = 6.7430  \n",
      "\n",
      "Fold: 10  Epoch: 309  Training loss = 4.0614  Validation loss = 6.7427  \n",
      "\n",
      "Fold: 10  Epoch: 310  Training loss = 4.0611  Validation loss = 6.7423  \n",
      "\n",
      "Fold: 10  Epoch: 311  Training loss = 4.0609  Validation loss = 6.7420  \n",
      "\n",
      "Fold: 10  Epoch: 312  Training loss = 4.0607  Validation loss = 6.7417  \n",
      "\n",
      "Fold: 10  Epoch: 313  Training loss = 4.0604  Validation loss = 6.7414  \n",
      "\n",
      "Fold: 10  Epoch: 314  Training loss = 4.0601  Validation loss = 6.7411  \n",
      "\n",
      "Fold: 10  Epoch: 315  Training loss = 4.0599  Validation loss = 6.7407  \n",
      "\n",
      "Fold: 10  Epoch: 316  Training loss = 4.0596  Validation loss = 6.7403  \n",
      "\n",
      "Fold: 10  Epoch: 317  Training loss = 4.0594  Validation loss = 6.7401  \n",
      "\n",
      "Fold: 10  Epoch: 318  Training loss = 4.0591  Validation loss = 6.7397  \n",
      "\n",
      "Fold: 10  Epoch: 319  Training loss = 4.0589  Validation loss = 6.7394  \n",
      "\n",
      "Fold: 10  Epoch: 320  Training loss = 4.0587  Validation loss = 6.7391  \n",
      "\n",
      "Fold: 10  Epoch: 321  Training loss = 4.0584  Validation loss = 6.7388  \n",
      "\n",
      "Fold: 10  Epoch: 322  Training loss = 4.0581  Validation loss = 6.7384  \n",
      "\n",
      "Fold: 10  Epoch: 323  Training loss = 4.0578  Validation loss = 6.7380  \n",
      "\n",
      "Fold: 10  Epoch: 324  Training loss = 4.0576  Validation loss = 6.7377  \n",
      "\n",
      "Fold: 10  Epoch: 325  Training loss = 4.0574  Validation loss = 6.7374  \n",
      "\n",
      "Fold: 10  Epoch: 326  Training loss = 4.0572  Validation loss = 6.7371  \n",
      "\n",
      "Fold: 10  Epoch: 327  Training loss = 4.0569  Validation loss = 6.7368  \n",
      "\n",
      "Fold: 10  Epoch: 328  Training loss = 4.0567  Validation loss = 6.7365  \n",
      "\n",
      "Fold: 10  Epoch: 329  Training loss = 4.0564  Validation loss = 6.7361  \n",
      "\n",
      "Fold: 10  Epoch: 330  Training loss = 4.0562  Validation loss = 6.7359  \n",
      "\n",
      "Fold: 10  Epoch: 331  Training loss = 4.0560  Validation loss = 6.7355  \n",
      "\n",
      "Fold: 10  Epoch: 332  Training loss = 4.0558  Validation loss = 6.7353  \n",
      "\n",
      "Fold: 10  Epoch: 333  Training loss = 4.0555  Validation loss = 6.7350  \n",
      "\n",
      "Fold: 10  Epoch: 334  Training loss = 4.0553  Validation loss = 6.7346  \n",
      "\n",
      "Fold: 10  Epoch: 335  Training loss = 4.0550  Validation loss = 6.7342  \n",
      "\n",
      "Fold: 10  Epoch: 336  Training loss = 4.0547  Validation loss = 6.7339  \n",
      "\n",
      "Fold: 10  Epoch: 337  Training loss = 4.0544  Validation loss = 6.7335  \n",
      "\n",
      "Fold: 10  Epoch: 338  Training loss = 4.0541  Validation loss = 6.7332  \n",
      "\n",
      "Fold: 10  Epoch: 339  Training loss = 4.0539  Validation loss = 6.7328  \n",
      "\n",
      "Fold: 10  Epoch: 340  Training loss = 4.0536  Validation loss = 6.7325  \n",
      "\n",
      "Fold: 10  Epoch: 341  Training loss = 4.0534  Validation loss = 6.7322  \n",
      "\n",
      "Fold: 10  Epoch: 342  Training loss = 4.0532  Validation loss = 6.7319  \n",
      "\n",
      "Fold: 10  Epoch: 343  Training loss = 4.0530  Validation loss = 6.7317  \n",
      "\n",
      "Fold: 10  Epoch: 344  Training loss = 4.0527  Validation loss = 6.7313  \n",
      "\n",
      "Fold: 10  Epoch: 345  Training loss = 4.0525  Validation loss = 6.7310  \n",
      "\n",
      "Fold: 10  Epoch: 346  Training loss = 4.0522  Validation loss = 6.7307  \n",
      "\n",
      "Fold: 10  Epoch: 347  Training loss = 4.0520  Validation loss = 6.7304  \n",
      "\n",
      "Fold: 10  Epoch: 348  Training loss = 4.0517  Validation loss = 6.7301  \n",
      "\n",
      "Fold: 10  Epoch: 349  Training loss = 4.0515  Validation loss = 6.7297  \n",
      "\n",
      "Fold: 10  Epoch: 350  Training loss = 4.0512  Validation loss = 6.7294  \n",
      "\n",
      "Fold: 10  Epoch: 351  Training loss = 4.0510  Validation loss = 6.7291  \n",
      "\n",
      "Fold: 10  Epoch: 352  Training loss = 4.0507  Validation loss = 6.7288  \n",
      "\n",
      "Fold: 10  Epoch: 353  Training loss = 4.0505  Validation loss = 6.7285  \n",
      "\n",
      "Fold: 10  Epoch: 354  Training loss = 4.0503  Validation loss = 6.7282  \n",
      "\n",
      "Fold: 10  Epoch: 355  Training loss = 4.0501  Validation loss = 6.7279  \n",
      "\n",
      "Fold: 10  Epoch: 356  Training loss = 4.0499  Validation loss = 6.7277  \n",
      "\n",
      "Fold: 10  Epoch: 357  Training loss = 4.0496  Validation loss = 6.7273  \n",
      "\n",
      "Fold: 10  Epoch: 358  Training loss = 4.0494  Validation loss = 6.7270  \n",
      "\n",
      "Fold: 10  Epoch: 359  Training loss = 4.0492  Validation loss = 6.7268  \n",
      "\n",
      "Fold: 10  Epoch: 360  Training loss = 4.0489  Validation loss = 6.7264  \n",
      "\n",
      "Fold: 10  Epoch: 361  Training loss = 4.0487  Validation loss = 6.7262  \n",
      "\n",
      "Fold: 10  Epoch: 362  Training loss = 4.0484  Validation loss = 6.7259  \n",
      "\n",
      "Fold: 10  Epoch: 363  Training loss = 4.0482  Validation loss = 6.7255  \n",
      "\n",
      "Fold: 10  Epoch: 364  Training loss = 4.0479  Validation loss = 6.7252  \n",
      "\n",
      "Fold: 10  Epoch: 365  Training loss = 4.0477  Validation loss = 6.7250  \n",
      "\n",
      "Fold: 10  Epoch: 366  Training loss = 4.0475  Validation loss = 6.7246  \n",
      "\n",
      "Fold: 10  Epoch: 367  Training loss = 4.0473  Validation loss = 6.7243  \n",
      "\n",
      "Fold: 10  Epoch: 368  Training loss = 4.0470  Validation loss = 6.7240  \n",
      "\n",
      "Fold: 10  Epoch: 369  Training loss = 4.0467  Validation loss = 6.7236  \n",
      "\n",
      "Fold: 10  Epoch: 370  Training loss = 4.0465  Validation loss = 6.7234  \n",
      "\n",
      "Fold: 10  Epoch: 371  Training loss = 4.0463  Validation loss = 6.7231  \n",
      "\n",
      "Fold: 10  Epoch: 372  Training loss = 4.0461  Validation loss = 6.7228  \n",
      "\n",
      "Fold: 10  Epoch: 373  Training loss = 4.0459  Validation loss = 6.7225  \n",
      "\n",
      "Fold: 10  Epoch: 374  Training loss = 4.0456  Validation loss = 6.7223  \n",
      "\n",
      "Fold: 10  Epoch: 375  Training loss = 4.0454  Validation loss = 6.7220  \n",
      "\n",
      "Fold: 10  Epoch: 376  Training loss = 4.0451  Validation loss = 6.7215  \n",
      "\n",
      "Fold: 10  Epoch: 377  Training loss = 4.0448  Validation loss = 6.7212  \n",
      "\n",
      "Fold: 10  Epoch: 378  Training loss = 4.0446  Validation loss = 6.7208  \n",
      "\n",
      "Fold: 10  Epoch: 379  Training loss = 4.0443  Validation loss = 6.7205  \n",
      "\n",
      "Fold: 10  Epoch: 380  Training loss = 4.0442  Validation loss = 6.7202  \n",
      "\n",
      "Fold: 10  Epoch: 381  Training loss = 4.0439  Validation loss = 6.7200  \n",
      "\n",
      "Fold: 10  Epoch: 382  Training loss = 4.0437  Validation loss = 6.7196  \n",
      "\n",
      "Fold: 10  Epoch: 383  Training loss = 4.0435  Validation loss = 6.7194  \n",
      "\n",
      "Fold: 10  Epoch: 384  Training loss = 4.0432  Validation loss = 6.7190  \n",
      "\n",
      "Fold: 10  Epoch: 385  Training loss = 4.0429  Validation loss = 6.7187  \n",
      "\n",
      "Fold: 10  Epoch: 386  Training loss = 4.0427  Validation loss = 6.7184  \n",
      "\n",
      "Fold: 10  Epoch: 387  Training loss = 4.0425  Validation loss = 6.7181  \n",
      "\n",
      "Fold: 10  Epoch: 388  Training loss = 4.0422  Validation loss = 6.7178  \n",
      "\n",
      "Fold: 10  Epoch: 389  Training loss = 4.0420  Validation loss = 6.7175  \n",
      "\n",
      "Fold: 10  Epoch: 390  Training loss = 4.0418  Validation loss = 6.7171  \n",
      "\n",
      "Fold: 10  Epoch: 391  Training loss = 4.0415  Validation loss = 6.7168  \n",
      "\n",
      "Fold: 10  Epoch: 392  Training loss = 4.0412  Validation loss = 6.7165  \n",
      "\n",
      "Fold: 10  Epoch: 393  Training loss = 4.0409  Validation loss = 6.7161  \n",
      "\n",
      "Fold: 10  Epoch: 394  Training loss = 4.0407  Validation loss = 6.7158  \n",
      "\n",
      "Fold: 10  Epoch: 395  Training loss = 4.0405  Validation loss = 6.7155  \n",
      "\n",
      "Fold: 10  Epoch: 396  Training loss = 4.0403  Validation loss = 6.7152  \n",
      "\n",
      "Fold: 10  Epoch: 397  Training loss = 4.0400  Validation loss = 6.7149  \n",
      "\n",
      "Fold: 10  Epoch: 398  Training loss = 4.0397  Validation loss = 6.7145  \n",
      "\n",
      "Fold: 10  Epoch: 399  Training loss = 4.0394  Validation loss = 6.7141  \n",
      "\n",
      "Fold: 10  Epoch: 400  Training loss = 4.0392  Validation loss = 6.7138  \n",
      "\n",
      "Fold: 10  Epoch: 401  Training loss = 4.0390  Validation loss = 6.7135  \n",
      "\n",
      "Fold: 10  Epoch: 402  Training loss = 4.0387  Validation loss = 6.7131  \n",
      "\n",
      "Fold: 10  Epoch: 403  Training loss = 4.0385  Validation loss = 6.7128  \n",
      "\n",
      "Fold: 10  Epoch: 404  Training loss = 4.0383  Validation loss = 6.7125  \n",
      "\n",
      "Fold: 10  Epoch: 405  Training loss = 4.0380  Validation loss = 6.7122  \n",
      "\n",
      "Fold: 10  Epoch: 406  Training loss = 4.0378  Validation loss = 6.7119  \n",
      "\n",
      "Fold: 10  Epoch: 407  Training loss = 4.0375  Validation loss = 6.7116  \n",
      "\n",
      "Fold: 10  Epoch: 408  Training loss = 4.0373  Validation loss = 6.7113  \n",
      "\n",
      "Fold: 10  Epoch: 409  Training loss = 4.0371  Validation loss = 6.7110  \n",
      "\n",
      "Fold: 10  Epoch: 410  Training loss = 4.0368  Validation loss = 6.7107  \n",
      "\n",
      "Fold: 10  Epoch: 411  Training loss = 4.0366  Validation loss = 6.7104  \n",
      "\n",
      "Fold: 10  Epoch: 412  Training loss = 4.0364  Validation loss = 6.7102  \n",
      "\n",
      "Fold: 10  Epoch: 413  Training loss = 4.0361  Validation loss = 6.7099  \n",
      "\n",
      "Fold: 10  Epoch: 414  Training loss = 4.0358  Validation loss = 6.7094  \n",
      "\n",
      "Fold: 10  Epoch: 415  Training loss = 4.0356  Validation loss = 6.7091  \n",
      "\n",
      "Fold: 10  Epoch: 416  Training loss = 4.0353  Validation loss = 6.7088  \n",
      "\n",
      "Fold: 10  Epoch: 417  Training loss = 4.0351  Validation loss = 6.7085  \n",
      "\n",
      "Fold: 10  Epoch: 418  Training loss = 4.0349  Validation loss = 6.7083  \n",
      "\n",
      "Fold: 10  Epoch: 419  Training loss = 4.0347  Validation loss = 6.7080  \n",
      "\n",
      "Fold: 10  Epoch: 420  Training loss = 4.0344  Validation loss = 6.7076  \n",
      "\n",
      "Fold: 10  Epoch: 421  Training loss = 4.0342  Validation loss = 6.7073  \n",
      "\n",
      "Fold: 10  Epoch: 422  Training loss = 4.0339  Validation loss = 6.7070  \n",
      "\n",
      "Fold: 10  Epoch: 423  Training loss = 4.0336  Validation loss = 6.7066  \n",
      "\n",
      "Fold: 10  Epoch: 424  Training loss = 4.0334  Validation loss = 6.7063  \n",
      "\n",
      "Fold: 10  Epoch: 425  Training loss = 4.0332  Validation loss = 6.7061  \n",
      "\n",
      "Fold: 10  Epoch: 426  Training loss = 4.0329  Validation loss = 6.7057  \n",
      "\n",
      "Fold: 10  Epoch: 427  Training loss = 4.0326  Validation loss = 6.7053  \n",
      "\n",
      "Fold: 10  Epoch: 428  Training loss = 4.0323  Validation loss = 6.7049  \n",
      "\n",
      "Fold: 10  Epoch: 429  Training loss = 4.0320  Validation loss = 6.7046  \n",
      "\n",
      "Fold: 10  Epoch: 430  Training loss = 4.0319  Validation loss = 6.7044  \n",
      "\n",
      "Fold: 10  Epoch: 431  Training loss = 4.0316  Validation loss = 6.7041  \n",
      "\n",
      "Fold: 10  Epoch: 432  Training loss = 4.0314  Validation loss = 6.7038  \n",
      "\n",
      "Fold: 10  Epoch: 433  Training loss = 4.0312  Validation loss = 6.7036  \n",
      "\n",
      "Fold: 10  Epoch: 434  Training loss = 4.0310  Validation loss = 6.7032  \n",
      "\n",
      "Fold: 10  Epoch: 435  Training loss = 4.0307  Validation loss = 6.7029  \n",
      "\n",
      "Fold: 10  Epoch: 436  Training loss = 4.0305  Validation loss = 6.7026  \n",
      "\n",
      "Fold: 10  Epoch: 437  Training loss = 4.0303  Validation loss = 6.7023  \n",
      "\n",
      "Fold: 10  Epoch: 438  Training loss = 4.0300  Validation loss = 6.7020  \n",
      "\n",
      "Fold: 10  Epoch: 439  Training loss = 4.0299  Validation loss = 6.7018  \n",
      "\n",
      "Fold: 10  Epoch: 440  Training loss = 4.0297  Validation loss = 6.7015  \n",
      "\n",
      "Fold: 10  Epoch: 441  Training loss = 4.0294  Validation loss = 6.7012  \n",
      "\n",
      "Fold: 10  Epoch: 442  Training loss = 4.0292  Validation loss = 6.7009  \n",
      "\n",
      "Fold: 10  Epoch: 443  Training loss = 4.0289  Validation loss = 6.7006  \n",
      "\n",
      "Fold: 10  Epoch: 444  Training loss = 4.0287  Validation loss = 6.7003  \n",
      "\n",
      "Fold: 10  Epoch: 445  Training loss = 4.0285  Validation loss = 6.7001  \n",
      "\n",
      "Fold: 10  Epoch: 446  Training loss = 4.0283  Validation loss = 6.6998  \n",
      "\n",
      "Fold: 10  Epoch: 447  Training loss = 4.0281  Validation loss = 6.6995  \n",
      "\n",
      "Fold: 10  Epoch: 448  Training loss = 4.0278  Validation loss = 6.6992  \n",
      "\n",
      "Fold: 10  Epoch: 449  Training loss = 4.0276  Validation loss = 6.6989  \n",
      "\n",
      "Fold: 10  Epoch: 450  Training loss = 4.0274  Validation loss = 6.6987  \n",
      "\n",
      "Fold: 10  Epoch: 451  Training loss = 4.0272  Validation loss = 6.6983  \n",
      "\n",
      "Fold: 10  Epoch: 452  Training loss = 4.0268  Validation loss = 6.6979  \n",
      "\n",
      "Fold: 10  Epoch: 453  Training loss = 4.0266  Validation loss = 6.6976  \n",
      "\n",
      "Fold: 10  Epoch: 454  Training loss = 4.0264  Validation loss = 6.6973  \n",
      "\n",
      "Fold: 10  Epoch: 455  Training loss = 4.0261  Validation loss = 6.6971  \n",
      "\n",
      "Fold: 10  Epoch: 456  Training loss = 4.0260  Validation loss = 6.6968  \n",
      "\n",
      "Fold: 10  Epoch: 457  Training loss = 4.0257  Validation loss = 6.6965  \n",
      "\n",
      "Fold: 10  Epoch: 458  Training loss = 4.0254  Validation loss = 6.6961  \n",
      "\n",
      "Fold: 10  Epoch: 459  Training loss = 4.0252  Validation loss = 6.6958  \n",
      "\n",
      "Fold: 10  Epoch: 460  Training loss = 4.0249  Validation loss = 6.6955  \n",
      "\n",
      "Fold: 10  Epoch: 461  Training loss = 4.0247  Validation loss = 6.6952  \n",
      "\n",
      "Fold: 10  Epoch: 462  Training loss = 4.0244  Validation loss = 6.6949  \n",
      "\n",
      "Fold: 10  Epoch: 463  Training loss = 4.0242  Validation loss = 6.6945  \n",
      "\n",
      "Fold: 10  Epoch: 464  Training loss = 4.0240  Validation loss = 6.6943  \n",
      "\n",
      "Fold: 10  Epoch: 465  Training loss = 4.0237  Validation loss = 6.6940  \n",
      "\n",
      "Fold: 10  Epoch: 466  Training loss = 4.0235  Validation loss = 6.6937  \n",
      "\n",
      "Fold: 10  Epoch: 467  Training loss = 4.0232  Validation loss = 6.6934  \n",
      "\n",
      "Fold: 10  Epoch: 468  Training loss = 4.0231  Validation loss = 6.6932  \n",
      "\n",
      "Fold: 10  Epoch: 469  Training loss = 4.0228  Validation loss = 6.6928  \n",
      "\n",
      "Fold: 10  Epoch: 470  Training loss = 4.0226  Validation loss = 6.6925  \n",
      "\n",
      "Fold: 10  Epoch: 471  Training loss = 4.0223  Validation loss = 6.6921  \n",
      "\n",
      "Fold: 10  Epoch: 472  Training loss = 4.0220  Validation loss = 6.6919  \n",
      "\n",
      "Fold: 10  Epoch: 473  Training loss = 4.0218  Validation loss = 6.6915  \n",
      "\n",
      "Fold: 10  Epoch: 474  Training loss = 4.0215  Validation loss = 6.6912  \n",
      "\n",
      "Fold: 10  Epoch: 475  Training loss = 4.0213  Validation loss = 6.6909  \n",
      "\n",
      "Fold: 10  Epoch: 476  Training loss = 4.0211  Validation loss = 6.6906  \n",
      "\n",
      "Fold: 10  Epoch: 477  Training loss = 4.0208  Validation loss = 6.6902  \n",
      "\n",
      "Fold: 10  Epoch: 478  Training loss = 4.0206  Validation loss = 6.6900  \n",
      "\n",
      "Fold: 10  Epoch: 479  Training loss = 4.0203  Validation loss = 6.6897  \n",
      "\n",
      "Fold: 10  Epoch: 480  Training loss = 4.0202  Validation loss = 6.6895  \n",
      "\n",
      "Fold: 10  Epoch: 481  Training loss = 4.0199  Validation loss = 6.6891  \n",
      "\n",
      "Fold: 10  Epoch: 482  Training loss = 4.0196  Validation loss = 6.6887  \n",
      "\n",
      "Fold: 10  Epoch: 483  Training loss = 4.0194  Validation loss = 6.6885  \n",
      "\n",
      "Fold: 10  Epoch: 484  Training loss = 4.0191  Validation loss = 6.6881  \n",
      "\n",
      "Fold: 10  Epoch: 485  Training loss = 4.0189  Validation loss = 6.6878  \n",
      "\n",
      "Fold: 10  Epoch: 486  Training loss = 4.0187  Validation loss = 6.6875  \n",
      "\n",
      "Fold: 10  Epoch: 487  Training loss = 4.0184  Validation loss = 6.6870  \n",
      "\n",
      "Fold: 10  Epoch: 488  Training loss = 4.0181  Validation loss = 6.6867  \n",
      "\n",
      "Fold: 10  Epoch: 489  Training loss = 4.0179  Validation loss = 6.6864  \n",
      "\n",
      "Fold: 10  Epoch: 490  Training loss = 4.0177  Validation loss = 6.6861  \n",
      "\n",
      "Fold: 10  Epoch: 491  Training loss = 4.0174  Validation loss = 6.6858  \n",
      "\n",
      "Fold: 10  Epoch: 492  Training loss = 4.0172  Validation loss = 6.6855  \n",
      "\n",
      "Fold: 10  Epoch: 493  Training loss = 4.0170  Validation loss = 6.6852  \n",
      "\n",
      "Fold: 10  Epoch: 494  Training loss = 4.0168  Validation loss = 6.6850  \n",
      "\n",
      "Fold: 10  Epoch: 495  Training loss = 4.0165  Validation loss = 6.6847  \n",
      "\n",
      "Fold: 10  Epoch: 496  Training loss = 4.0163  Validation loss = 6.6844  \n",
      "\n",
      "Fold: 10  Epoch: 497  Training loss = 4.0161  Validation loss = 6.6841  \n",
      "\n",
      "Fold: 10  Epoch: 498  Training loss = 4.0158  Validation loss = 6.6837  \n",
      "\n",
      "Fold: 10  Epoch: 499  Training loss = 4.0156  Validation loss = 6.6834  \n",
      "\n",
      "Fold: 10  Epoch: 500  Training loss = 4.0153  Validation loss = 6.6830  \n",
      "\n",
      "Check model:  Fold: 10  Optimal epoch: 500  \n",
      "\n",
      "Fold: 11  Epoch: 1  Training loss = 4.3376  Validation loss = 4.3267  \n",
      "\n",
      "Fold: 11  Epoch: 2  Training loss = 4.3373  Validation loss = 4.3262  \n",
      "\n",
      "Fold: 11  Epoch: 3  Training loss = 4.3370  Validation loss = 4.3257  \n",
      "\n",
      "Fold: 11  Epoch: 4  Training loss = 4.3367  Validation loss = 4.3253  \n",
      "\n",
      "Fold: 11  Epoch: 5  Training loss = 4.3364  Validation loss = 4.3248  \n",
      "\n",
      "Fold: 11  Epoch: 6  Training loss = 4.3362  Validation loss = 4.3245  \n",
      "\n",
      "Fold: 11  Epoch: 7  Training loss = 4.3359  Validation loss = 4.3240  \n",
      "\n",
      "Fold: 11  Epoch: 8  Training loss = 4.3356  Validation loss = 4.3235  \n",
      "\n",
      "Fold: 11  Epoch: 9  Training loss = 4.3353  Validation loss = 4.3230  \n",
      "\n",
      "Fold: 11  Epoch: 10  Training loss = 4.3349  Validation loss = 4.3225  \n",
      "\n",
      "Fold: 11  Epoch: 11  Training loss = 4.3347  Validation loss = 4.3221  \n",
      "\n",
      "Fold: 11  Epoch: 12  Training loss = 4.3343  Validation loss = 4.3216  \n",
      "\n",
      "Fold: 11  Epoch: 13  Training loss = 4.3340  Validation loss = 4.3211  \n",
      "\n",
      "Fold: 11  Epoch: 14  Training loss = 4.3338  Validation loss = 4.3207  \n",
      "\n",
      "Fold: 11  Epoch: 15  Training loss = 4.3335  Validation loss = 4.3203  \n",
      "\n",
      "Fold: 11  Epoch: 16  Training loss = 4.3332  Validation loss = 4.3198  \n",
      "\n",
      "Fold: 11  Epoch: 17  Training loss = 4.3329  Validation loss = 4.3194  \n",
      "\n",
      "Fold: 11  Epoch: 18  Training loss = 4.3326  Validation loss = 4.3189  \n",
      "\n",
      "Fold: 11  Epoch: 19  Training loss = 4.3323  Validation loss = 4.3185  \n",
      "\n",
      "Fold: 11  Epoch: 20  Training loss = 4.3321  Validation loss = 4.3181  \n",
      "\n",
      "Fold: 11  Epoch: 21  Training loss = 4.3318  Validation loss = 4.3176  \n",
      "\n",
      "Fold: 11  Epoch: 22  Training loss = 4.3314  Validation loss = 4.3170  \n",
      "\n",
      "Fold: 11  Epoch: 23  Training loss = 4.3310  Validation loss = 4.3164  \n",
      "\n",
      "Fold: 11  Epoch: 24  Training loss = 4.3307  Validation loss = 4.3159  \n",
      "\n",
      "Fold: 11  Epoch: 25  Training loss = 4.3304  Validation loss = 4.3154  \n",
      "\n",
      "Fold: 11  Epoch: 26  Training loss = 4.3302  Validation loss = 4.3150  \n",
      "\n",
      "Fold: 11  Epoch: 27  Training loss = 4.3299  Validation loss = 4.3145  \n",
      "\n",
      "Fold: 11  Epoch: 28  Training loss = 4.3296  Validation loss = 4.3140  \n",
      "\n",
      "Fold: 11  Epoch: 29  Training loss = 4.3293  Validation loss = 4.3136  \n",
      "\n",
      "Fold: 11  Epoch: 30  Training loss = 4.3291  Validation loss = 4.3131  \n",
      "\n",
      "Fold: 11  Epoch: 31  Training loss = 4.3288  Validation loss = 4.3127  \n",
      "\n",
      "Fold: 11  Epoch: 32  Training loss = 4.3285  Validation loss = 4.3122  \n",
      "\n",
      "Fold: 11  Epoch: 33  Training loss = 4.3282  Validation loss = 4.3118  \n",
      "\n",
      "Fold: 11  Epoch: 34  Training loss = 4.3280  Validation loss = 4.3115  \n",
      "\n",
      "Fold: 11  Epoch: 35  Training loss = 4.3277  Validation loss = 4.3109  \n",
      "\n",
      "Fold: 11  Epoch: 36  Training loss = 4.3274  Validation loss = 4.3104  \n",
      "\n",
      "Fold: 11  Epoch: 37  Training loss = 4.3272  Validation loss = 4.3100  \n",
      "\n",
      "Fold: 11  Epoch: 38  Training loss = 4.3269  Validation loss = 4.3095  \n",
      "\n",
      "Fold: 11  Epoch: 39  Training loss = 4.3266  Validation loss = 4.3091  \n",
      "\n",
      "Fold: 11  Epoch: 40  Training loss = 4.3263  Validation loss = 4.3087  \n",
      "\n",
      "Fold: 11  Epoch: 41  Training loss = 4.3261  Validation loss = 4.3083  \n",
      "\n",
      "Fold: 11  Epoch: 42  Training loss = 4.3258  Validation loss = 4.3078  \n",
      "\n",
      "Fold: 11  Epoch: 43  Training loss = 4.3256  Validation loss = 4.3074  \n",
      "\n",
      "Fold: 11  Epoch: 44  Training loss = 4.3253  Validation loss = 4.3070  \n",
      "\n",
      "Fold: 11  Epoch: 45  Training loss = 4.3250  Validation loss = 4.3065  \n",
      "\n",
      "Fold: 11  Epoch: 46  Training loss = 4.3247  Validation loss = 4.3061  \n",
      "\n",
      "Fold: 11  Epoch: 47  Training loss = 4.3245  Validation loss = 4.3056  \n",
      "\n",
      "Fold: 11  Epoch: 48  Training loss = 4.3242  Validation loss = 4.3052  \n",
      "\n",
      "Fold: 11  Epoch: 49  Training loss = 4.3239  Validation loss = 4.3047  \n",
      "\n",
      "Fold: 11  Epoch: 50  Training loss = 4.3237  Validation loss = 4.3043  \n",
      "\n",
      "Fold: 11  Epoch: 51  Training loss = 4.3234  Validation loss = 4.3039  \n",
      "\n",
      "Fold: 11  Epoch: 52  Training loss = 4.3231  Validation loss = 4.3034  \n",
      "\n",
      "Fold: 11  Epoch: 53  Training loss = 4.3228  Validation loss = 4.3029  \n",
      "\n",
      "Fold: 11  Epoch: 54  Training loss = 4.3226  Validation loss = 4.3025  \n",
      "\n",
      "Fold: 11  Epoch: 55  Training loss = 4.3223  Validation loss = 4.3020  \n",
      "\n",
      "Fold: 11  Epoch: 56  Training loss = 4.3221  Validation loss = 4.3017  \n",
      "\n",
      "Fold: 11  Epoch: 57  Training loss = 4.3218  Validation loss = 4.3011  \n",
      "\n",
      "Fold: 11  Epoch: 58  Training loss = 4.3215  Validation loss = 4.3007  \n",
      "\n",
      "Fold: 11  Epoch: 59  Training loss = 4.3212  Validation loss = 4.3002  \n",
      "\n",
      "Fold: 11  Epoch: 60  Training loss = 4.3209  Validation loss = 4.2998  \n",
      "\n",
      "Fold: 11  Epoch: 61  Training loss = 4.3206  Validation loss = 4.2991  \n",
      "\n",
      "Fold: 11  Epoch: 62  Training loss = 4.3203  Validation loss = 4.2986  \n",
      "\n",
      "Fold: 11  Epoch: 63  Training loss = 4.3200  Validation loss = 4.2982  \n",
      "\n",
      "Fold: 11  Epoch: 64  Training loss = 4.3197  Validation loss = 4.2977  \n",
      "\n",
      "Fold: 11  Epoch: 65  Training loss = 4.3195  Validation loss = 4.2973  \n",
      "\n",
      "Fold: 11  Epoch: 66  Training loss = 4.3192  Validation loss = 4.2969  \n",
      "\n",
      "Fold: 11  Epoch: 67  Training loss = 4.3189  Validation loss = 4.2965  \n",
      "\n",
      "Fold: 11  Epoch: 68  Training loss = 4.3186  Validation loss = 4.2959  \n",
      "\n",
      "Fold: 11  Epoch: 69  Training loss = 4.3183  Validation loss = 4.2954  \n",
      "\n",
      "Fold: 11  Epoch: 70  Training loss = 4.3181  Validation loss = 4.2951  \n",
      "\n",
      "Fold: 11  Epoch: 71  Training loss = 4.3179  Validation loss = 4.2947  \n",
      "\n",
      "Fold: 11  Epoch: 72  Training loss = 4.3177  Validation loss = 4.2944  \n",
      "\n",
      "Fold: 11  Epoch: 73  Training loss = 4.3175  Validation loss = 4.2941  \n",
      "\n",
      "Fold: 11  Epoch: 74  Training loss = 4.3172  Validation loss = 4.2937  \n",
      "\n",
      "Fold: 11  Epoch: 75  Training loss = 4.3169  Validation loss = 4.2932  \n",
      "\n",
      "Fold: 11  Epoch: 76  Training loss = 4.3166  Validation loss = 4.2927  \n",
      "\n",
      "Fold: 11  Epoch: 77  Training loss = 4.3164  Validation loss = 4.2922  \n",
      "\n",
      "Fold: 11  Epoch: 78  Training loss = 4.3162  Validation loss = 4.2919  \n",
      "\n",
      "Fold: 11  Epoch: 79  Training loss = 4.3159  Validation loss = 4.2914  \n",
      "\n",
      "Fold: 11  Epoch: 80  Training loss = 4.3156  Validation loss = 4.2910  \n",
      "\n",
      "Fold: 11  Epoch: 81  Training loss = 4.3153  Validation loss = 4.2905  \n",
      "\n",
      "Fold: 11  Epoch: 82  Training loss = 4.3149  Validation loss = 4.2899  \n",
      "\n",
      "Fold: 11  Epoch: 83  Training loss = 4.3147  Validation loss = 4.2895  \n",
      "\n",
      "Fold: 11  Epoch: 84  Training loss = 4.3144  Validation loss = 4.2891  \n",
      "\n",
      "Fold: 11  Epoch: 85  Training loss = 4.3142  Validation loss = 4.2887  \n",
      "\n",
      "Fold: 11  Epoch: 86  Training loss = 4.3139  Validation loss = 4.2883  \n",
      "\n",
      "Fold: 11  Epoch: 87  Training loss = 4.3136  Validation loss = 4.2878  \n",
      "\n",
      "Fold: 11  Epoch: 88  Training loss = 4.3132  Validation loss = 4.2873  \n",
      "\n",
      "Fold: 11  Epoch: 89  Training loss = 4.3127  Validation loss = 4.2868  \n",
      "\n",
      "Fold: 11  Epoch: 90  Training loss = 4.3121  Validation loss = 4.2864  \n",
      "\n",
      "Fold: 11  Epoch: 91  Training loss = 4.3108  Validation loss = 4.2860  \n",
      "\n",
      "Fold: 11  Epoch: 92  Training loss = 4.3105  Validation loss = 4.2856  \n",
      "\n",
      "Fold: 11  Epoch: 93  Training loss = 4.3100  Validation loss = 4.2850  \n",
      "\n",
      "Fold: 11  Epoch: 94  Training loss = 4.3098  Validation loss = 4.2847  \n",
      "\n",
      "Fold: 11  Epoch: 95  Training loss = 4.3095  Validation loss = 4.2842  \n",
      "\n",
      "Fold: 11  Epoch: 96  Training loss = 4.3092  Validation loss = 4.2837  \n",
      "\n",
      "Fold: 11  Epoch: 97  Training loss = 4.3089  Validation loss = 4.2832  \n",
      "\n",
      "Fold: 11  Epoch: 98  Training loss = 4.3086  Validation loss = 4.2828  \n",
      "\n",
      "Fold: 11  Epoch: 99  Training loss = 4.3084  Validation loss = 4.2823  \n",
      "\n",
      "Fold: 11  Epoch: 100  Training loss = 4.3080  Validation loss = 4.2817  \n",
      "\n",
      "Fold: 11  Epoch: 101  Training loss = 4.3077  Validation loss = 4.2812  \n",
      "\n",
      "Fold: 11  Epoch: 102  Training loss = 4.3074  Validation loss = 4.2807  \n",
      "\n",
      "Fold: 11  Epoch: 103  Training loss = 4.3071  Validation loss = 4.2802  \n",
      "\n",
      "Fold: 11  Epoch: 104  Training loss = 4.3068  Validation loss = 4.2797  \n",
      "\n",
      "Fold: 11  Epoch: 105  Training loss = 4.3066  Validation loss = 4.2793  \n",
      "\n",
      "Fold: 11  Epoch: 106  Training loss = 4.3063  Validation loss = 4.2789  \n",
      "\n",
      "Fold: 11  Epoch: 107  Training loss = 4.3060  Validation loss = 4.2783  \n",
      "\n",
      "Fold: 11  Epoch: 108  Training loss = 4.3058  Validation loss = 4.2780  \n",
      "\n",
      "Fold: 11  Epoch: 109  Training loss = 4.3056  Validation loss = 4.2776  \n",
      "\n",
      "Fold: 11  Epoch: 110  Training loss = 4.3053  Validation loss = 4.2771  \n",
      "\n",
      "Fold: 11  Epoch: 111  Training loss = 4.3050  Validation loss = 4.2766  \n",
      "\n",
      "Fold: 11  Epoch: 112  Training loss = 4.3047  Validation loss = 4.2761  \n",
      "\n",
      "Fold: 11  Epoch: 113  Training loss = 4.3045  Validation loss = 4.2758  \n",
      "\n",
      "Fold: 11  Epoch: 114  Training loss = 4.3042  Validation loss = 4.2753  \n",
      "\n",
      "Fold: 11  Epoch: 115  Training loss = 4.3039  Validation loss = 4.2748  \n",
      "\n",
      "Fold: 11  Epoch: 116  Training loss = 4.3037  Validation loss = 4.2744  \n",
      "\n",
      "Fold: 11  Epoch: 117  Training loss = 4.3034  Validation loss = 4.2739  \n",
      "\n",
      "Fold: 11  Epoch: 118  Training loss = 4.3031  Validation loss = 4.2735  \n",
      "\n",
      "Fold: 11  Epoch: 119  Training loss = 4.3028  Validation loss = 4.2730  \n",
      "\n",
      "Fold: 11  Epoch: 120  Training loss = 4.3025  Validation loss = 4.2725  \n",
      "\n",
      "Fold: 11  Epoch: 121  Training loss = 4.3023  Validation loss = 4.2720  \n",
      "\n",
      "Fold: 11  Epoch: 122  Training loss = 4.3020  Validation loss = 4.2715  \n",
      "\n",
      "Fold: 11  Epoch: 123  Training loss = 4.3017  Validation loss = 4.2711  \n",
      "\n",
      "Fold: 11  Epoch: 124  Training loss = 4.3015  Validation loss = 4.2707  \n",
      "\n",
      "Fold: 11  Epoch: 125  Training loss = 4.3013  Validation loss = 4.2703  \n",
      "\n",
      "Fold: 11  Epoch: 126  Training loss = 4.3010  Validation loss = 4.2699  \n",
      "\n",
      "Fold: 11  Epoch: 127  Training loss = 4.3007  Validation loss = 4.2694  \n",
      "\n",
      "Fold: 11  Epoch: 128  Training loss = 4.3005  Validation loss = 4.2690  \n",
      "\n",
      "Fold: 11  Epoch: 129  Training loss = 4.3002  Validation loss = 4.2685  \n",
      "\n",
      "Fold: 11  Epoch: 130  Training loss = 4.2999  Validation loss = 4.2680  \n",
      "\n",
      "Fold: 11  Epoch: 131  Training loss = 4.2996  Validation loss = 4.2675  \n",
      "\n",
      "Fold: 11  Epoch: 132  Training loss = 4.2994  Validation loss = 4.2671  \n",
      "\n",
      "Fold: 11  Epoch: 133  Training loss = 4.2992  Validation loss = 4.2668  \n",
      "\n",
      "Fold: 11  Epoch: 134  Training loss = 4.2989  Validation loss = 4.2664  \n",
      "\n",
      "Fold: 11  Epoch: 135  Training loss = 4.2986  Validation loss = 4.2658  \n",
      "\n",
      "Fold: 11  Epoch: 136  Training loss = 4.2983  Validation loss = 4.2653  \n",
      "\n",
      "Fold: 11  Epoch: 137  Training loss = 4.2980  Validation loss = 4.2648  \n",
      "\n",
      "Fold: 11  Epoch: 138  Training loss = 4.2978  Validation loss = 4.2644  \n",
      "\n",
      "Fold: 11  Epoch: 139  Training loss = 4.2975  Validation loss = 4.2640  \n",
      "\n",
      "Fold: 11  Epoch: 140  Training loss = 4.2972  Validation loss = 4.2634  \n",
      "\n",
      "Fold: 11  Epoch: 141  Training loss = 4.2969  Validation loss = 4.2629  \n",
      "\n",
      "Fold: 11  Epoch: 142  Training loss = 4.2966  Validation loss = 4.2624  \n",
      "\n",
      "Fold: 11  Epoch: 143  Training loss = 4.2963  Validation loss = 4.2619  \n",
      "\n",
      "Fold: 11  Epoch: 144  Training loss = 4.2960  Validation loss = 4.2615  \n",
      "\n",
      "Fold: 11  Epoch: 145  Training loss = 4.2958  Validation loss = 4.2611  \n",
      "\n",
      "Fold: 11  Epoch: 146  Training loss = 4.2956  Validation loss = 4.2607  \n",
      "\n",
      "Fold: 11  Epoch: 147  Training loss = 4.2953  Validation loss = 4.2602  \n",
      "\n",
      "Fold: 11  Epoch: 148  Training loss = 4.2951  Validation loss = 4.2599  \n",
      "\n",
      "Fold: 11  Epoch: 149  Training loss = 4.2948  Validation loss = 4.2595  \n",
      "\n",
      "Fold: 11  Epoch: 150  Training loss = 4.2945  Validation loss = 4.2590  \n",
      "\n",
      "Fold: 11  Epoch: 151  Training loss = 4.2942  Validation loss = 4.2584  \n",
      "\n",
      "Fold: 11  Epoch: 152  Training loss = 4.2940  Validation loss = 4.2580  \n",
      "\n",
      "Fold: 11  Epoch: 153  Training loss = 4.2938  Validation loss = 4.2576  \n",
      "\n",
      "Fold: 11  Epoch: 154  Training loss = 4.2935  Validation loss = 4.2572  \n",
      "\n",
      "Fold: 11  Epoch: 155  Training loss = 4.2932  Validation loss = 4.2567  \n",
      "\n",
      "Fold: 11  Epoch: 156  Training loss = 4.2929  Validation loss = 4.2561  \n",
      "\n",
      "Fold: 11  Epoch: 157  Training loss = 4.2926  Validation loss = 4.2557  \n",
      "\n",
      "Fold: 11  Epoch: 158  Training loss = 4.2924  Validation loss = 4.2551  \n",
      "\n",
      "Fold: 11  Epoch: 159  Training loss = 4.2920  Validation loss = 4.2546  \n",
      "\n",
      "Fold: 11  Epoch: 160  Training loss = 4.2918  Validation loss = 4.2542  \n",
      "\n",
      "Fold: 11  Epoch: 161  Training loss = 4.2916  Validation loss = 4.2539  \n",
      "\n",
      "Fold: 11  Epoch: 162  Training loss = 4.2913  Validation loss = 4.2534  \n",
      "\n",
      "Fold: 11  Epoch: 163  Training loss = 4.2910  Validation loss = 4.2529  \n",
      "\n",
      "Fold: 11  Epoch: 164  Training loss = 4.2907  Validation loss = 4.2523  \n",
      "\n",
      "Fold: 11  Epoch: 165  Training loss = 4.2904  Validation loss = 4.2517  \n",
      "\n",
      "Fold: 11  Epoch: 166  Training loss = 4.2902  Validation loss = 4.2513  \n",
      "\n",
      "Fold: 11  Epoch: 167  Training loss = 4.2899  Validation loss = 4.2509  \n",
      "\n",
      "Fold: 11  Epoch: 168  Training loss = 4.2897  Validation loss = 4.2505  \n",
      "\n",
      "Fold: 11  Epoch: 169  Training loss = 4.2894  Validation loss = 4.2501  \n",
      "\n",
      "Fold: 11  Epoch: 170  Training loss = 4.2892  Validation loss = 4.2496  \n",
      "\n",
      "Fold: 11  Epoch: 171  Training loss = 4.2889  Validation loss = 4.2492  \n",
      "\n",
      "Fold: 11  Epoch: 172  Training loss = 4.2886  Validation loss = 4.2486  \n",
      "\n",
      "Fold: 11  Epoch: 173  Training loss = 4.2884  Validation loss = 4.2481  \n",
      "\n",
      "Fold: 11  Epoch: 174  Training loss = 4.2880  Validation loss = 4.2476  \n",
      "\n",
      "Fold: 11  Epoch: 175  Training loss = 4.2878  Validation loss = 4.2471  \n",
      "\n",
      "Fold: 11  Epoch: 176  Training loss = 4.2875  Validation loss = 4.2466  \n",
      "\n",
      "Fold: 11  Epoch: 177  Training loss = 4.2873  Validation loss = 4.2462  \n",
      "\n",
      "Fold: 11  Epoch: 178  Training loss = 4.2870  Validation loss = 4.2458  \n",
      "\n",
      "Fold: 11  Epoch: 179  Training loss = 4.2868  Validation loss = 4.2454  \n",
      "\n",
      "Fold: 11  Epoch: 180  Training loss = 4.2866  Validation loss = 4.2450  \n",
      "\n",
      "Fold: 11  Epoch: 181  Training loss = 4.2863  Validation loss = 4.2446  \n",
      "\n",
      "Fold: 11  Epoch: 182  Training loss = 4.2860  Validation loss = 4.2441  \n",
      "\n",
      "Fold: 11  Epoch: 183  Training loss = 4.2858  Validation loss = 4.2437  \n",
      "\n",
      "Fold: 11  Epoch: 184  Training loss = 4.2855  Validation loss = 4.2432  \n",
      "\n",
      "Fold: 11  Epoch: 185  Training loss = 4.2852  Validation loss = 4.2428  \n",
      "\n",
      "Fold: 11  Epoch: 186  Training loss = 4.2849  Validation loss = 4.2422  \n",
      "\n",
      "Fold: 11  Epoch: 187  Training loss = 4.2847  Validation loss = 4.2418  \n",
      "\n",
      "Fold: 11  Epoch: 188  Training loss = 4.2844  Validation loss = 4.2413  \n",
      "\n",
      "Fold: 11  Epoch: 189  Training loss = 4.2841  Validation loss = 4.2409  \n",
      "\n",
      "Fold: 11  Epoch: 190  Training loss = 4.2839  Validation loss = 4.2405  \n",
      "\n",
      "Fold: 11  Epoch: 191  Training loss = 4.2836  Validation loss = 4.2400  \n",
      "\n",
      "Fold: 11  Epoch: 192  Training loss = 4.2834  Validation loss = 4.2396  \n",
      "\n",
      "Fold: 11  Epoch: 193  Training loss = 4.2831  Validation loss = 4.2391  \n",
      "\n",
      "Fold: 11  Epoch: 194  Training loss = 4.2828  Validation loss = 4.2386  \n",
      "\n",
      "Fold: 11  Epoch: 195  Training loss = 4.2826  Validation loss = 4.2382  \n",
      "\n",
      "Fold: 11  Epoch: 196  Training loss = 4.2823  Validation loss = 4.2377  \n",
      "\n",
      "Fold: 11  Epoch: 197  Training loss = 4.2821  Validation loss = 4.2374  \n",
      "\n",
      "Fold: 11  Epoch: 198  Training loss = 4.2818  Validation loss = 4.2368  \n",
      "\n",
      "Fold: 11  Epoch: 199  Training loss = 4.2816  Validation loss = 4.2364  \n",
      "\n",
      "Fold: 11  Epoch: 200  Training loss = 4.2813  Validation loss = 4.2359  \n",
      "\n",
      "Fold: 11  Epoch: 201  Training loss = 4.2810  Validation loss = 4.2354  \n",
      "\n",
      "Fold: 11  Epoch: 202  Training loss = 4.2808  Validation loss = 4.2350  \n",
      "\n",
      "Fold: 11  Epoch: 203  Training loss = 4.2806  Validation loss = 4.2346  \n",
      "\n",
      "Fold: 11  Epoch: 204  Training loss = 4.2803  Validation loss = 4.2341  \n",
      "\n",
      "Fold: 11  Epoch: 205  Training loss = 4.2800  Validation loss = 4.2336  \n",
      "\n",
      "Fold: 11  Epoch: 206  Training loss = 4.2797  Validation loss = 4.2332  \n",
      "\n",
      "Fold: 11  Epoch: 207  Training loss = 4.2795  Validation loss = 4.2327  \n",
      "\n",
      "Fold: 11  Epoch: 208  Training loss = 4.2792  Validation loss = 4.2322  \n",
      "\n",
      "Fold: 11  Epoch: 209  Training loss = 4.2789  Validation loss = 4.2318  \n",
      "\n",
      "Fold: 11  Epoch: 210  Training loss = 4.2786  Validation loss = 4.2313  \n",
      "\n",
      "Fold: 11  Epoch: 211  Training loss = 4.2784  Validation loss = 4.2309  \n",
      "\n",
      "Fold: 11  Epoch: 212  Training loss = 4.2781  Validation loss = 4.2304  \n",
      "\n",
      "Fold: 11  Epoch: 213  Training loss = 4.2778  Validation loss = 4.2299  \n",
      "\n",
      "Fold: 11  Epoch: 214  Training loss = 4.2775  Validation loss = 4.2294  \n",
      "\n",
      "Fold: 11  Epoch: 215  Training loss = 4.2773  Validation loss = 4.2290  \n",
      "\n",
      "Fold: 11  Epoch: 216  Training loss = 4.2770  Validation loss = 4.2284  \n",
      "\n",
      "Fold: 11  Epoch: 217  Training loss = 4.2767  Validation loss = 4.2279  \n",
      "\n",
      "Fold: 11  Epoch: 218  Training loss = 4.2764  Validation loss = 4.2275  \n",
      "\n",
      "Fold: 11  Epoch: 219  Training loss = 4.2762  Validation loss = 4.2271  \n",
      "\n",
      "Fold: 11  Epoch: 220  Training loss = 4.2759  Validation loss = 4.2266  \n",
      "\n",
      "Fold: 11  Epoch: 221  Training loss = 4.2756  Validation loss = 4.2262  \n",
      "\n",
      "Fold: 11  Epoch: 222  Training loss = 4.2754  Validation loss = 4.2257  \n",
      "\n",
      "Fold: 11  Epoch: 223  Training loss = 4.2751  Validation loss = 4.2252  \n",
      "\n",
      "Fold: 11  Epoch: 224  Training loss = 4.2749  Validation loss = 4.2248  \n",
      "\n",
      "Fold: 11  Epoch: 225  Training loss = 4.2746  Validation loss = 4.2244  \n",
      "\n",
      "Fold: 11  Epoch: 226  Training loss = 4.2744  Validation loss = 4.2240  \n",
      "\n",
      "Fold: 11  Epoch: 227  Training loss = 4.2742  Validation loss = 4.2235  \n",
      "\n",
      "Fold: 11  Epoch: 228  Training loss = 4.2739  Validation loss = 4.2231  \n",
      "\n",
      "Fold: 11  Epoch: 229  Training loss = 4.2736  Validation loss = 4.2226  \n",
      "\n",
      "Fold: 11  Epoch: 230  Training loss = 4.2734  Validation loss = 4.2221  \n",
      "\n",
      "Fold: 11  Epoch: 231  Training loss = 4.2731  Validation loss = 4.2216  \n",
      "\n",
      "Fold: 11  Epoch: 232  Training loss = 4.2728  Validation loss = 4.2212  \n",
      "\n",
      "Fold: 11  Epoch: 233  Training loss = 4.2726  Validation loss = 4.2208  \n",
      "\n",
      "Fold: 11  Epoch: 234  Training loss = 4.2723  Validation loss = 4.2203  \n",
      "\n",
      "Fold: 11  Epoch: 235  Training loss = 4.2720  Validation loss = 4.2199  \n",
      "\n",
      "Fold: 11  Epoch: 236  Training loss = 4.2718  Validation loss = 4.2195  \n",
      "\n",
      "Fold: 11  Epoch: 237  Training loss = 4.2715  Validation loss = 4.2189  \n",
      "\n",
      "Fold: 11  Epoch: 238  Training loss = 4.2712  Validation loss = 4.2184  \n",
      "\n",
      "Fold: 11  Epoch: 239  Training loss = 4.2709  Validation loss = 4.2179  \n",
      "\n",
      "Fold: 11  Epoch: 240  Training loss = 4.2706  Validation loss = 4.2174  \n",
      "\n",
      "Fold: 11  Epoch: 241  Training loss = 4.2704  Validation loss = 4.2169  \n",
      "\n",
      "Fold: 11  Epoch: 242  Training loss = 4.2700  Validation loss = 4.2164  \n",
      "\n",
      "Fold: 11  Epoch: 243  Training loss = 4.2698  Validation loss = 4.2159  \n",
      "\n",
      "Fold: 11  Epoch: 244  Training loss = 4.2696  Validation loss = 4.2155  \n",
      "\n",
      "Fold: 11  Epoch: 245  Training loss = 4.2693  Validation loss = 4.2150  \n",
      "\n",
      "Fold: 11  Epoch: 246  Training loss = 4.2690  Validation loss = 4.2145  \n",
      "\n",
      "Fold: 11  Epoch: 247  Training loss = 4.2688  Validation loss = 4.2141  \n",
      "\n",
      "Fold: 11  Epoch: 248  Training loss = 4.2685  Validation loss = 4.2136  \n",
      "\n",
      "Fold: 11  Epoch: 249  Training loss = 4.2682  Validation loss = 4.2131  \n",
      "\n",
      "Fold: 11  Epoch: 250  Training loss = 4.2680  Validation loss = 4.2127  \n",
      "\n",
      "Fold: 11  Epoch: 251  Training loss = 4.2677  Validation loss = 4.2121  \n",
      "\n",
      "Fold: 11  Epoch: 252  Training loss = 4.2675  Validation loss = 4.2117  \n",
      "\n",
      "Fold: 11  Epoch: 253  Training loss = 4.2672  Validation loss = 4.2112  \n",
      "\n",
      "Fold: 11  Epoch: 254  Training loss = 4.2669  Validation loss = 4.2107  \n",
      "\n",
      "Fold: 11  Epoch: 255  Training loss = 4.2666  Validation loss = 4.2103  \n",
      "\n",
      "Fold: 11  Epoch: 256  Training loss = 4.2664  Validation loss = 4.2098  \n",
      "\n",
      "Fold: 11  Epoch: 257  Training loss = 4.2662  Validation loss = 4.2094  \n",
      "\n",
      "Fold: 11  Epoch: 258  Training loss = 4.2659  Validation loss = 4.2090  \n",
      "\n",
      "Fold: 11  Epoch: 259  Training loss = 4.2657  Validation loss = 4.2086  \n",
      "\n",
      "Fold: 11  Epoch: 260  Training loss = 4.2655  Validation loss = 4.2082  \n",
      "\n",
      "Fold: 11  Epoch: 261  Training loss = 4.2652  Validation loss = 4.2078  \n",
      "\n",
      "Fold: 11  Epoch: 262  Training loss = 4.2650  Validation loss = 4.2073  \n",
      "\n",
      "Fold: 11  Epoch: 263  Training loss = 4.2646  Validation loss = 4.2068  \n",
      "\n",
      "Fold: 11  Epoch: 264  Training loss = 4.2644  Validation loss = 4.2064  \n",
      "\n",
      "Fold: 11  Epoch: 265  Training loss = 4.2642  Validation loss = 4.2060  \n",
      "\n",
      "Fold: 11  Epoch: 266  Training loss = 4.2639  Validation loss = 4.2055  \n",
      "\n",
      "Fold: 11  Epoch: 267  Training loss = 4.2637  Validation loss = 4.2051  \n",
      "\n",
      "Fold: 11  Epoch: 268  Training loss = 4.2634  Validation loss = 4.2046  \n",
      "\n",
      "Fold: 11  Epoch: 269  Training loss = 4.2631  Validation loss = 4.2040  \n",
      "\n",
      "Fold: 11  Epoch: 270  Training loss = 4.2629  Validation loss = 4.2035  \n",
      "\n",
      "Fold: 11  Epoch: 271  Training loss = 4.2626  Validation loss = 4.2030  \n",
      "\n",
      "Fold: 11  Epoch: 272  Training loss = 4.2623  Validation loss = 4.2026  \n",
      "\n",
      "Fold: 11  Epoch: 273  Training loss = 4.2620  Validation loss = 4.2021  \n",
      "\n",
      "Fold: 11  Epoch: 274  Training loss = 4.2618  Validation loss = 4.2016  \n",
      "\n",
      "Fold: 11  Epoch: 275  Training loss = 4.2616  Validation loss = 4.2012  \n",
      "\n",
      "Fold: 11  Epoch: 276  Training loss = 4.2613  Validation loss = 4.2007  \n",
      "\n",
      "Fold: 11  Epoch: 277  Training loss = 4.2611  Validation loss = 4.2004  \n",
      "\n",
      "Fold: 11  Epoch: 278  Training loss = 4.2609  Validation loss = 4.2000  \n",
      "\n",
      "Fold: 11  Epoch: 279  Training loss = 4.2606  Validation loss = 4.1995  \n",
      "\n",
      "Fold: 11  Epoch: 280  Training loss = 4.2604  Validation loss = 4.1991  \n",
      "\n",
      "Fold: 11  Epoch: 281  Training loss = 4.2601  Validation loss = 4.1987  \n",
      "\n",
      "Fold: 11  Epoch: 282  Training loss = 4.2599  Validation loss = 4.1982  \n",
      "\n",
      "Fold: 11  Epoch: 283  Training loss = 4.2596  Validation loss = 4.1977  \n",
      "\n",
      "Fold: 11  Epoch: 284  Training loss = 4.2593  Validation loss = 4.1972  \n",
      "\n",
      "Fold: 11  Epoch: 285  Training loss = 4.2591  Validation loss = 4.1968  \n",
      "\n",
      "Fold: 11  Epoch: 286  Training loss = 4.2589  Validation loss = 4.1964  \n",
      "\n",
      "Fold: 11  Epoch: 287  Training loss = 4.2586  Validation loss = 4.1959  \n",
      "\n",
      "Fold: 11  Epoch: 288  Training loss = 4.2583  Validation loss = 4.1955  \n",
      "\n",
      "Fold: 11  Epoch: 289  Training loss = 4.2581  Validation loss = 4.1951  \n",
      "\n",
      "Fold: 11  Epoch: 290  Training loss = 4.2578  Validation loss = 4.1946  \n",
      "\n",
      "Fold: 11  Epoch: 291  Training loss = 4.2575  Validation loss = 4.1941  \n",
      "\n",
      "Fold: 11  Epoch: 292  Training loss = 4.2573  Validation loss = 4.1937  \n",
      "\n",
      "Fold: 11  Epoch: 293  Training loss = 4.2570  Validation loss = 4.1932  \n",
      "\n",
      "Fold: 11  Epoch: 294  Training loss = 4.2567  Validation loss = 4.1926  \n",
      "\n",
      "Fold: 11  Epoch: 295  Training loss = 4.2564  Validation loss = 4.1922  \n",
      "\n",
      "Fold: 11  Epoch: 296  Training loss = 4.2562  Validation loss = 4.1917  \n",
      "\n",
      "Fold: 11  Epoch: 297  Training loss = 4.2559  Validation loss = 4.1913  \n",
      "\n",
      "Fold: 11  Epoch: 298  Training loss = 4.2557  Validation loss = 4.1909  \n",
      "\n",
      "Fold: 11  Epoch: 299  Training loss = 4.2555  Validation loss = 4.1905  \n",
      "\n",
      "Fold: 11  Epoch: 300  Training loss = 4.2552  Validation loss = 4.1900  \n",
      "\n",
      "Fold: 11  Epoch: 301  Training loss = 4.2550  Validation loss = 4.1897  \n",
      "\n",
      "Fold: 11  Epoch: 302  Training loss = 4.2548  Validation loss = 4.1893  \n",
      "\n",
      "Fold: 11  Epoch: 303  Training loss = 4.2545  Validation loss = 4.1888  \n",
      "\n",
      "Fold: 11  Epoch: 304  Training loss = 4.2542  Validation loss = 4.1883  \n",
      "\n",
      "Fold: 11  Epoch: 305  Training loss = 4.2540  Validation loss = 4.1880  \n",
      "\n",
      "Fold: 11  Epoch: 306  Training loss = 4.2538  Validation loss = 4.1877  \n",
      "\n",
      "Fold: 11  Epoch: 307  Training loss = 4.2536  Validation loss = 4.1873  \n",
      "\n",
      "Fold: 11  Epoch: 308  Training loss = 4.2533  Validation loss = 4.1868  \n",
      "\n",
      "Fold: 11  Epoch: 309  Training loss = 4.2530  Validation loss = 4.1863  \n",
      "\n",
      "Fold: 11  Epoch: 310  Training loss = 4.2527  Validation loss = 4.1859  \n",
      "\n",
      "Fold: 11  Epoch: 311  Training loss = 4.2525  Validation loss = 4.1854  \n",
      "\n",
      "Fold: 11  Epoch: 312  Training loss = 4.2523  Validation loss = 4.1851  \n",
      "\n",
      "Fold: 11  Epoch: 313  Training loss = 4.2521  Validation loss = 4.1847  \n",
      "\n",
      "Fold: 11  Epoch: 314  Training loss = 4.2518  Validation loss = 4.1842  \n",
      "\n",
      "Fold: 11  Epoch: 315  Training loss = 4.2515  Validation loss = 4.1837  \n",
      "\n",
      "Fold: 11  Epoch: 316  Training loss = 4.2512  Validation loss = 4.1832  \n",
      "\n",
      "Fold: 11  Epoch: 317  Training loss = 4.2510  Validation loss = 4.1827  \n",
      "\n",
      "Fold: 11  Epoch: 318  Training loss = 4.2506  Validation loss = 4.1822  \n",
      "\n",
      "Fold: 11  Epoch: 319  Training loss = 4.2503  Validation loss = 4.1816  \n",
      "\n",
      "Fold: 11  Epoch: 320  Training loss = 4.2500  Validation loss = 4.1811  \n",
      "\n",
      "Fold: 11  Epoch: 321  Training loss = 4.2497  Validation loss = 4.1806  \n",
      "\n",
      "Fold: 11  Epoch: 322  Training loss = 4.2495  Validation loss = 4.1801  \n",
      "\n",
      "Fold: 11  Epoch: 323  Training loss = 4.2493  Validation loss = 4.1798  \n",
      "\n",
      "Fold: 11  Epoch: 324  Training loss = 4.2490  Validation loss = 4.1794  \n",
      "\n",
      "Fold: 11  Epoch: 325  Training loss = 4.2488  Validation loss = 4.1789  \n",
      "\n",
      "Fold: 11  Epoch: 326  Training loss = 4.2486  Validation loss = 4.1785  \n",
      "\n",
      "Fold: 11  Epoch: 327  Training loss = 4.2483  Validation loss = 4.1780  \n",
      "\n",
      "Fold: 11  Epoch: 328  Training loss = 4.2480  Validation loss = 4.1775  \n",
      "\n",
      "Fold: 11  Epoch: 329  Training loss = 4.2477  Validation loss = 4.1770  \n",
      "\n",
      "Fold: 11  Epoch: 330  Training loss = 4.2475  Validation loss = 4.1766  \n",
      "\n",
      "Fold: 11  Epoch: 331  Training loss = 4.2472  Validation loss = 4.1761  \n",
      "\n",
      "Fold: 11  Epoch: 332  Training loss = 4.2470  Validation loss = 4.1756  \n",
      "\n",
      "Fold: 11  Epoch: 333  Training loss = 4.2467  Validation loss = 4.1751  \n",
      "\n",
      "Fold: 11  Epoch: 334  Training loss = 4.2464  Validation loss = 4.1746  \n",
      "\n",
      "Fold: 11  Epoch: 335  Training loss = 4.2461  Validation loss = 4.1741  \n",
      "\n",
      "Fold: 11  Epoch: 336  Training loss = 4.2458  Validation loss = 4.1735  \n",
      "\n",
      "Fold: 11  Epoch: 337  Training loss = 4.2456  Validation loss = 4.1731  \n",
      "\n",
      "Fold: 11  Epoch: 338  Training loss = 4.2453  Validation loss = 4.1725  \n",
      "\n",
      "Fold: 11  Epoch: 339  Training loss = 4.2450  Validation loss = 4.1720  \n",
      "\n",
      "Fold: 11  Epoch: 340  Training loss = 4.2447  Validation loss = 4.1714  \n",
      "\n",
      "Fold: 11  Epoch: 341  Training loss = 4.2444  Validation loss = 4.1710  \n",
      "\n",
      "Fold: 11  Epoch: 342  Training loss = 4.2442  Validation loss = 4.1705  \n",
      "\n",
      "Fold: 11  Epoch: 343  Training loss = 4.2439  Validation loss = 4.1701  \n",
      "\n",
      "Fold: 11  Epoch: 344  Training loss = 4.2436  Validation loss = 4.1695  \n",
      "\n",
      "Fold: 11  Epoch: 345  Training loss = 4.2434  Validation loss = 4.1691  \n",
      "\n",
      "Fold: 11  Epoch: 346  Training loss = 4.2431  Validation loss = 4.1686  \n",
      "\n",
      "Fold: 11  Epoch: 347  Training loss = 4.2429  Validation loss = 4.1682  \n",
      "\n",
      "Fold: 11  Epoch: 348  Training loss = 4.2427  Validation loss = 4.1678  \n",
      "\n",
      "Fold: 11  Epoch: 349  Training loss = 4.2425  Validation loss = 4.1674  \n",
      "\n",
      "Fold: 11  Epoch: 350  Training loss = 4.2422  Validation loss = 4.1669  \n",
      "\n",
      "Fold: 11  Epoch: 351  Training loss = 4.2419  Validation loss = 4.1664  \n",
      "\n",
      "Fold: 11  Epoch: 352  Training loss = 4.2417  Validation loss = 4.1660  \n",
      "\n",
      "Fold: 11  Epoch: 353  Training loss = 4.2414  Validation loss = 4.1656  \n",
      "\n",
      "Fold: 11  Epoch: 354  Training loss = 4.2412  Validation loss = 4.1652  \n",
      "\n",
      "Fold: 11  Epoch: 355  Training loss = 4.2409  Validation loss = 4.1647  \n",
      "\n",
      "Fold: 11  Epoch: 356  Training loss = 4.2407  Validation loss = 4.1642  \n",
      "\n",
      "Fold: 11  Epoch: 357  Training loss = 4.2405  Validation loss = 4.1639  \n",
      "\n",
      "Fold: 11  Epoch: 358  Training loss = 4.2402  Validation loss = 4.1634  \n",
      "\n",
      "Fold: 11  Epoch: 359  Training loss = 4.2400  Validation loss = 4.1630  \n",
      "\n",
      "Fold: 11  Epoch: 360  Training loss = 4.2397  Validation loss = 4.1625  \n",
      "\n",
      "Fold: 11  Epoch: 361  Training loss = 4.2395  Validation loss = 4.1621  \n",
      "\n",
      "Fold: 11  Epoch: 362  Training loss = 4.2392  Validation loss = 4.1616  \n",
      "\n",
      "Fold: 11  Epoch: 363  Training loss = 4.2389  Validation loss = 4.1611  \n",
      "\n",
      "Fold: 11  Epoch: 364  Training loss = 4.2387  Validation loss = 4.1608  \n",
      "\n",
      "Fold: 11  Epoch: 365  Training loss = 4.2385  Validation loss = 4.1604  \n",
      "\n",
      "Fold: 11  Epoch: 366  Training loss = 4.2383  Validation loss = 4.1600  \n",
      "\n",
      "Fold: 11  Epoch: 367  Training loss = 4.2380  Validation loss = 4.1595  \n",
      "\n",
      "Fold: 11  Epoch: 368  Training loss = 4.2378  Validation loss = 4.1591  \n",
      "\n",
      "Fold: 11  Epoch: 369  Training loss = 4.2376  Validation loss = 4.1587  \n",
      "\n",
      "Fold: 11  Epoch: 370  Training loss = 4.2373  Validation loss = 4.1582  \n",
      "\n",
      "Fold: 11  Epoch: 371  Training loss = 4.2370  Validation loss = 4.1578  \n",
      "\n",
      "Fold: 11  Epoch: 372  Training loss = 4.2368  Validation loss = 4.1572  \n",
      "\n",
      "Fold: 11  Epoch: 373  Training loss = 4.2365  Validation loss = 4.1569  \n",
      "\n",
      "Fold: 11  Epoch: 374  Training loss = 4.2363  Validation loss = 4.1564  \n",
      "\n",
      "Fold: 11  Epoch: 375  Training loss = 4.2361  Validation loss = 4.1560  \n",
      "\n",
      "Fold: 11  Epoch: 376  Training loss = 4.2358  Validation loss = 4.1555  \n",
      "\n",
      "Fold: 11  Epoch: 377  Training loss = 4.2356  Validation loss = 4.1551  \n",
      "\n",
      "Fold: 11  Epoch: 378  Training loss = 4.2354  Validation loss = 4.1547  \n",
      "\n",
      "Fold: 11  Epoch: 379  Training loss = 4.2351  Validation loss = 4.1543  \n",
      "\n",
      "Fold: 11  Epoch: 380  Training loss = 4.2349  Validation loss = 4.1538  \n",
      "\n",
      "Fold: 11  Epoch: 381  Training loss = 4.2346  Validation loss = 4.1534  \n",
      "\n",
      "Fold: 11  Epoch: 382  Training loss = 4.2343  Validation loss = 4.1529  \n",
      "\n",
      "Fold: 11  Epoch: 383  Training loss = 4.2341  Validation loss = 4.1526  \n",
      "\n",
      "Fold: 11  Epoch: 384  Training loss = 4.2338  Validation loss = 4.1520  \n",
      "\n",
      "Fold: 11  Epoch: 385  Training loss = 4.2336  Validation loss = 4.1516  \n",
      "\n",
      "Fold: 11  Epoch: 386  Training loss = 4.2333  Validation loss = 4.1511  \n",
      "\n",
      "Fold: 11  Epoch: 387  Training loss = 4.2331  Validation loss = 4.1507  \n",
      "\n",
      "Fold: 11  Epoch: 388  Training loss = 4.2329  Validation loss = 4.1503  \n",
      "\n",
      "Fold: 11  Epoch: 389  Training loss = 4.2326  Validation loss = 4.1499  \n",
      "\n",
      "Fold: 11  Epoch: 390  Training loss = 4.2324  Validation loss = 4.1494  \n",
      "\n",
      "Fold: 11  Epoch: 391  Training loss = 4.2321  Validation loss = 4.1489  \n",
      "\n",
      "Fold: 11  Epoch: 392  Training loss = 4.2319  Validation loss = 4.1485  \n",
      "\n",
      "Fold: 11  Epoch: 393  Training loss = 4.2316  Validation loss = 4.1481  \n",
      "\n",
      "Fold: 11  Epoch: 394  Training loss = 4.2314  Validation loss = 4.1476  \n",
      "\n",
      "Fold: 11  Epoch: 395  Training loss = 4.2312  Validation loss = 4.1472  \n",
      "\n",
      "Fold: 11  Epoch: 396  Training loss = 4.2309  Validation loss = 4.1468  \n",
      "\n",
      "Fold: 11  Epoch: 397  Training loss = 4.2307  Validation loss = 4.1464  \n",
      "\n",
      "Fold: 11  Epoch: 398  Training loss = 4.2304  Validation loss = 4.1459  \n",
      "\n",
      "Fold: 11  Epoch: 399  Training loss = 4.2302  Validation loss = 4.1454  \n",
      "\n",
      "Fold: 11  Epoch: 400  Training loss = 4.2299  Validation loss = 4.1449  \n",
      "\n",
      "Fold: 11  Epoch: 401  Training loss = 4.2297  Validation loss = 4.1445  \n",
      "\n",
      "Fold: 11  Epoch: 402  Training loss = 4.2294  Validation loss = 4.1441  \n",
      "\n",
      "Fold: 11  Epoch: 403  Training loss = 4.2291  Validation loss = 4.1435  \n",
      "\n",
      "Fold: 11  Epoch: 404  Training loss = 4.2288  Validation loss = 4.1430  \n",
      "\n",
      "Fold: 11  Epoch: 405  Training loss = 4.2286  Validation loss = 4.1426  \n",
      "\n",
      "Fold: 11  Epoch: 406  Training loss = 4.2283  Validation loss = 4.1422  \n",
      "\n",
      "Fold: 11  Epoch: 407  Training loss = 4.2280  Validation loss = 4.1417  \n",
      "\n",
      "Fold: 11  Epoch: 408  Training loss = 4.2278  Validation loss = 4.1413  \n",
      "\n",
      "Fold: 11  Epoch: 409  Training loss = 4.2275  Validation loss = 4.1408  \n",
      "\n",
      "Fold: 11  Epoch: 410  Training loss = 4.2272  Validation loss = 4.1403  \n",
      "\n",
      "Fold: 11  Epoch: 411  Training loss = 4.2270  Validation loss = 4.1398  \n",
      "\n",
      "Fold: 11  Epoch: 412  Training loss = 4.2268  Validation loss = 4.1394  \n",
      "\n",
      "Fold: 11  Epoch: 413  Training loss = 4.2265  Validation loss = 4.1389  \n",
      "\n",
      "Fold: 11  Epoch: 414  Training loss = 4.2263  Validation loss = 4.1384  \n",
      "\n",
      "Fold: 11  Epoch: 415  Training loss = 4.2260  Validation loss = 4.1380  \n",
      "\n",
      "Fold: 11  Epoch: 416  Training loss = 4.2257  Validation loss = 4.1376  \n",
      "\n",
      "Fold: 11  Epoch: 417  Training loss = 4.2255  Validation loss = 4.1371  \n",
      "\n",
      "Fold: 11  Epoch: 418  Training loss = 4.2252  Validation loss = 4.1366  \n",
      "\n",
      "Fold: 11  Epoch: 419  Training loss = 4.2249  Validation loss = 4.1360  \n",
      "\n",
      "Fold: 11  Epoch: 420  Training loss = 4.2246  Validation loss = 4.1356  \n",
      "\n",
      "Fold: 11  Epoch: 421  Training loss = 4.2243  Validation loss = 4.1350  \n",
      "\n",
      "Fold: 11  Epoch: 422  Training loss = 4.2242  Validation loss = 4.1347  \n",
      "\n",
      "Fold: 11  Epoch: 423  Training loss = 4.2239  Validation loss = 4.1343  \n",
      "\n",
      "Fold: 11  Epoch: 424  Training loss = 4.2237  Validation loss = 4.1339  \n",
      "\n",
      "Fold: 11  Epoch: 425  Training loss = 4.2235  Validation loss = 4.1334  \n",
      "\n",
      "Fold: 11  Epoch: 426  Training loss = 4.2232  Validation loss = 4.1329  \n",
      "\n",
      "Fold: 11  Epoch: 427  Training loss = 4.2230  Validation loss = 4.1325  \n",
      "\n",
      "Fold: 11  Epoch: 428  Training loss = 4.2227  Validation loss = 4.1320  \n",
      "\n",
      "Fold: 11  Epoch: 429  Training loss = 4.2224  Validation loss = 4.1316  \n",
      "\n",
      "Fold: 11  Epoch: 430  Training loss = 4.2221  Validation loss = 4.1311  \n",
      "\n",
      "Fold: 11  Epoch: 431  Training loss = 4.2219  Validation loss = 4.1305  \n",
      "\n",
      "Fold: 11  Epoch: 432  Training loss = 4.2217  Validation loss = 4.1302  \n",
      "\n",
      "Fold: 11  Epoch: 433  Training loss = 4.2214  Validation loss = 4.1296  \n",
      "\n",
      "Fold: 11  Epoch: 434  Training loss = 4.2210  Validation loss = 4.1290  \n",
      "\n",
      "Fold: 11  Epoch: 435  Training loss = 4.2208  Validation loss = 4.1286  \n",
      "\n",
      "Fold: 11  Epoch: 436  Training loss = 4.2205  Validation loss = 4.1281  \n",
      "\n",
      "Fold: 11  Epoch: 437  Training loss = 4.2202  Validation loss = 4.1276  \n",
      "\n",
      "Fold: 11  Epoch: 438  Training loss = 4.2200  Validation loss = 4.1271  \n",
      "\n",
      "Fold: 11  Epoch: 439  Training loss = 4.2197  Validation loss = 4.1266  \n",
      "\n",
      "Fold: 11  Epoch: 440  Training loss = 4.2195  Validation loss = 4.1262  \n",
      "\n",
      "Fold: 11  Epoch: 441  Training loss = 4.2192  Validation loss = 4.1257  \n",
      "\n",
      "Fold: 11  Epoch: 442  Training loss = 4.2189  Validation loss = 4.1253  \n",
      "\n",
      "Fold: 11  Epoch: 443  Training loss = 4.2187  Validation loss = 4.1248  \n",
      "\n",
      "Fold: 11  Epoch: 444  Training loss = 4.2184  Validation loss = 4.1243  \n",
      "\n",
      "Fold: 11  Epoch: 445  Training loss = 4.2181  Validation loss = 4.1238  \n",
      "\n",
      "Fold: 11  Epoch: 446  Training loss = 4.2178  Validation loss = 4.1233  \n",
      "\n",
      "Fold: 11  Epoch: 447  Training loss = 4.2175  Validation loss = 4.1227  \n",
      "\n",
      "Fold: 11  Epoch: 448  Training loss = 4.2173  Validation loss = 4.1223  \n",
      "\n",
      "Fold: 11  Epoch: 449  Training loss = 4.2170  Validation loss = 4.1218  \n",
      "\n",
      "Fold: 11  Epoch: 450  Training loss = 4.2168  Validation loss = 4.1214  \n",
      "\n",
      "Fold: 11  Epoch: 451  Training loss = 4.2165  Validation loss = 4.1209  \n",
      "\n",
      "Fold: 11  Epoch: 452  Training loss = 4.2162  Validation loss = 4.1204  \n",
      "\n",
      "Fold: 11  Epoch: 453  Training loss = 4.2159  Validation loss = 4.1198  \n",
      "\n",
      "Fold: 11  Epoch: 454  Training loss = 4.2157  Validation loss = 4.1194  \n",
      "\n",
      "Fold: 11  Epoch: 455  Training loss = 4.2154  Validation loss = 4.1189  \n",
      "\n",
      "Fold: 11  Epoch: 456  Training loss = 4.2152  Validation loss = 4.1185  \n",
      "\n",
      "Fold: 11  Epoch: 457  Training loss = 4.2149  Validation loss = 4.1180  \n",
      "\n",
      "Fold: 11  Epoch: 458  Training loss = 4.2147  Validation loss = 4.1176  \n",
      "\n",
      "Fold: 11  Epoch: 459  Training loss = 4.2143  Validation loss = 4.1170  \n",
      "\n",
      "Fold: 11  Epoch: 460  Training loss = 4.2141  Validation loss = 4.1165  \n",
      "\n",
      "Fold: 11  Epoch: 461  Training loss = 4.2138  Validation loss = 4.1160  \n",
      "\n",
      "Fold: 11  Epoch: 462  Training loss = 4.2136  Validation loss = 4.1157  \n",
      "\n",
      "Fold: 11  Epoch: 463  Training loss = 4.2134  Validation loss = 4.1152  \n",
      "\n",
      "Fold: 11  Epoch: 464  Training loss = 4.2131  Validation loss = 4.1148  \n",
      "\n",
      "Fold: 11  Epoch: 465  Training loss = 4.2129  Validation loss = 4.1144  \n",
      "\n",
      "Fold: 11  Epoch: 466  Training loss = 4.2126  Validation loss = 4.1138  \n",
      "\n",
      "Fold: 11  Epoch: 467  Training loss = 4.2123  Validation loss = 4.1133  \n",
      "\n",
      "Fold: 11  Epoch: 468  Training loss = 4.2122  Validation loss = 4.1130  \n",
      "\n",
      "Fold: 11  Epoch: 469  Training loss = 4.2119  Validation loss = 4.1125  \n",
      "\n",
      "Fold: 11  Epoch: 470  Training loss = 4.2116  Validation loss = 4.1121  \n",
      "\n",
      "Fold: 11  Epoch: 471  Training loss = 4.2114  Validation loss = 4.1117  \n",
      "\n",
      "Fold: 11  Epoch: 472  Training loss = 4.2111  Validation loss = 4.1112  \n",
      "\n",
      "Fold: 11  Epoch: 473  Training loss = 4.2109  Validation loss = 4.1108  \n",
      "\n",
      "Fold: 11  Epoch: 474  Training loss = 4.2106  Validation loss = 4.1103  \n",
      "\n",
      "Fold: 11  Epoch: 475  Training loss = 4.2103  Validation loss = 4.1098  \n",
      "\n",
      "Fold: 11  Epoch: 476  Training loss = 4.2101  Validation loss = 4.1093  \n",
      "\n",
      "Fold: 11  Epoch: 477  Training loss = 4.2098  Validation loss = 4.1088  \n",
      "\n",
      "Fold: 11  Epoch: 478  Training loss = 4.2095  Validation loss = 4.1083  \n",
      "\n",
      "Fold: 11  Epoch: 479  Training loss = 4.2093  Validation loss = 4.1079  \n",
      "\n",
      "Fold: 11  Epoch: 480  Training loss = 4.2090  Validation loss = 4.1074  \n",
      "\n",
      "Fold: 11  Epoch: 481  Training loss = 4.2087  Validation loss = 4.1069  \n",
      "\n",
      "Fold: 11  Epoch: 482  Training loss = 4.2084  Validation loss = 4.1064  \n",
      "\n",
      "Fold: 11  Epoch: 483  Training loss = 4.2081  Validation loss = 4.1058  \n",
      "\n",
      "Fold: 11  Epoch: 484  Training loss = 4.2079  Validation loss = 4.1054  \n",
      "\n",
      "Fold: 11  Epoch: 485  Training loss = 4.2076  Validation loss = 4.1050  \n",
      "\n",
      "Fold: 11  Epoch: 486  Training loss = 4.2074  Validation loss = 4.1046  \n",
      "\n",
      "Fold: 11  Epoch: 487  Training loss = 4.2072  Validation loss = 4.1042  \n",
      "\n",
      "Fold: 11  Epoch: 488  Training loss = 4.2070  Validation loss = 4.1038  \n",
      "\n",
      "Fold: 11  Epoch: 489  Training loss = 4.2067  Validation loss = 4.1034  \n",
      "\n",
      "Fold: 11  Epoch: 490  Training loss = 4.2065  Validation loss = 4.1029  \n",
      "\n",
      "Fold: 11  Epoch: 491  Training loss = 4.2062  Validation loss = 4.1024  \n",
      "\n",
      "Fold: 11  Epoch: 492  Training loss = 4.2060  Validation loss = 4.1019  \n",
      "\n",
      "Fold: 11  Epoch: 493  Training loss = 4.2057  Validation loss = 4.1015  \n",
      "\n",
      "Fold: 11  Epoch: 494  Training loss = 4.2054  Validation loss = 4.1009  \n",
      "\n",
      "Fold: 11  Epoch: 495  Training loss = 4.2052  Validation loss = 4.1005  \n",
      "\n",
      "Fold: 11  Epoch: 496  Training loss = 4.2049  Validation loss = 4.1000  \n",
      "\n",
      "Fold: 11  Epoch: 497  Training loss = 4.2047  Validation loss = 4.0995  \n",
      "\n",
      "Fold: 11  Epoch: 498  Training loss = 4.2044  Validation loss = 4.0990  \n",
      "\n",
      "Fold: 11  Epoch: 499  Training loss = 4.2042  Validation loss = 4.0986  \n",
      "\n",
      "Fold: 11  Epoch: 500  Training loss = 4.2040  Validation loss = 4.0983  \n",
      "\n",
      "Check model:  Fold: 11  Optimal epoch: 500  \n",
      "\n",
      "Fold: 12  Epoch: 1  Training loss = 4.3178  Validation loss = 5.4244  \n",
      "\n",
      "Fold: 12  Epoch: 2  Training loss = 4.3176  Validation loss = 5.4240  \n",
      "\n",
      "Fold: 12  Epoch: 3  Training loss = 4.3172  Validation loss = 5.4235  \n",
      "\n",
      "Fold: 12  Epoch: 4  Training loss = 4.3169  Validation loss = 5.4231  \n",
      "\n",
      "Fold: 12  Epoch: 5  Training loss = 4.3165  Validation loss = 5.4225  \n",
      "\n",
      "Fold: 12  Epoch: 6  Training loss = 4.3162  Validation loss = 5.4222  \n",
      "\n",
      "Fold: 12  Epoch: 7  Training loss = 4.3159  Validation loss = 5.4218  \n",
      "\n",
      "Fold: 12  Epoch: 8  Training loss = 4.3156  Validation loss = 5.4213  \n",
      "\n",
      "Fold: 12  Epoch: 9  Training loss = 4.3152  Validation loss = 5.4208  \n",
      "\n",
      "Fold: 12  Epoch: 10  Training loss = 4.3149  Validation loss = 5.4204  \n",
      "\n",
      "Fold: 12  Epoch: 11  Training loss = 4.3147  Validation loss = 5.4201  \n",
      "\n",
      "Fold: 12  Epoch: 12  Training loss = 4.3144  Validation loss = 5.4197  \n",
      "\n",
      "Fold: 12  Epoch: 13  Training loss = 4.3141  Validation loss = 5.4192  \n",
      "\n",
      "Fold: 12  Epoch: 14  Training loss = 4.3138  Validation loss = 5.4189  \n",
      "\n",
      "Fold: 12  Epoch: 15  Training loss = 4.3135  Validation loss = 5.4185  \n",
      "\n",
      "Fold: 12  Epoch: 16  Training loss = 4.3132  Validation loss = 5.4181  \n",
      "\n",
      "Fold: 12  Epoch: 17  Training loss = 4.3129  Validation loss = 5.4176  \n",
      "\n",
      "Fold: 12  Epoch: 18  Training loss = 4.3126  Validation loss = 5.4172  \n",
      "\n",
      "Fold: 12  Epoch: 19  Training loss = 4.3123  Validation loss = 5.4168  \n",
      "\n",
      "Fold: 12  Epoch: 20  Training loss = 4.3120  Validation loss = 5.4164  \n",
      "\n",
      "Fold: 12  Epoch: 21  Training loss = 4.3118  Validation loss = 5.4160  \n",
      "\n",
      "Fold: 12  Epoch: 22  Training loss = 4.3115  Validation loss = 5.4157  \n",
      "\n",
      "Fold: 12  Epoch: 23  Training loss = 4.3112  Validation loss = 5.4152  \n",
      "\n",
      "Fold: 12  Epoch: 24  Training loss = 4.3109  Validation loss = 5.4149  \n",
      "\n",
      "Fold: 12  Epoch: 25  Training loss = 4.3106  Validation loss = 5.4145  \n",
      "\n",
      "Fold: 12  Epoch: 26  Training loss = 4.3102  Validation loss = 5.4140  \n",
      "\n",
      "Fold: 12  Epoch: 27  Training loss = 4.3099  Validation loss = 5.4136  \n",
      "\n",
      "Fold: 12  Epoch: 28  Training loss = 4.3097  Validation loss = 5.4132  \n",
      "\n",
      "Fold: 12  Epoch: 29  Training loss = 4.3094  Validation loss = 5.4128  \n",
      "\n",
      "Fold: 12  Epoch: 30  Training loss = 4.3091  Validation loss = 5.4124  \n",
      "\n",
      "Fold: 12  Epoch: 31  Training loss = 4.3088  Validation loss = 5.4119  \n",
      "\n",
      "Fold: 12  Epoch: 32  Training loss = 4.3084  Validation loss = 5.4114  \n",
      "\n",
      "Fold: 12  Epoch: 33  Training loss = 4.3081  Validation loss = 5.4111  \n",
      "\n",
      "Fold: 12  Epoch: 34  Training loss = 4.3078  Validation loss = 5.4106  \n",
      "\n",
      "Fold: 12  Epoch: 35  Training loss = 4.3075  Validation loss = 5.4102  \n",
      "\n",
      "Fold: 12  Epoch: 36  Training loss = 4.3072  Validation loss = 5.4098  \n",
      "\n",
      "Fold: 12  Epoch: 37  Training loss = 4.3069  Validation loss = 5.4094  \n",
      "\n",
      "Fold: 12  Epoch: 38  Training loss = 4.3065  Validation loss = 5.4089  \n",
      "\n",
      "Fold: 12  Epoch: 39  Training loss = 4.3063  Validation loss = 5.4086  \n",
      "\n",
      "Fold: 12  Epoch: 40  Training loss = 4.3060  Validation loss = 5.4082  \n",
      "\n",
      "Fold: 12  Epoch: 41  Training loss = 4.3057  Validation loss = 5.4077  \n",
      "\n",
      "Fold: 12  Epoch: 42  Training loss = 4.3053  Validation loss = 5.4073  \n",
      "\n",
      "Fold: 12  Epoch: 43  Training loss = 4.3050  Validation loss = 5.4068  \n",
      "\n",
      "Fold: 12  Epoch: 44  Training loss = 4.3047  Validation loss = 5.4064  \n",
      "\n",
      "Fold: 12  Epoch: 45  Training loss = 4.3044  Validation loss = 5.4060  \n",
      "\n",
      "Fold: 12  Epoch: 46  Training loss = 4.3042  Validation loss = 5.4056  \n",
      "\n",
      "Fold: 12  Epoch: 47  Training loss = 4.3038  Validation loss = 5.4052  \n",
      "\n",
      "Fold: 12  Epoch: 48  Training loss = 4.3035  Validation loss = 5.4048  \n",
      "\n",
      "Fold: 12  Epoch: 49  Training loss = 4.3032  Validation loss = 5.4043  \n",
      "\n",
      "Fold: 12  Epoch: 50  Training loss = 4.3029  Validation loss = 5.4039  \n",
      "\n",
      "Fold: 12  Epoch: 51  Training loss = 4.3027  Validation loss = 5.4036  \n",
      "\n",
      "Fold: 12  Epoch: 52  Training loss = 4.3024  Validation loss = 5.4032  \n",
      "\n",
      "Fold: 12  Epoch: 53  Training loss = 4.3022  Validation loss = 5.4029  \n",
      "\n",
      "Fold: 12  Epoch: 54  Training loss = 4.3019  Validation loss = 5.4026  \n",
      "\n",
      "Fold: 12  Epoch: 55  Training loss = 4.3016  Validation loss = 5.4022  \n",
      "\n",
      "Fold: 12  Epoch: 56  Training loss = 4.3013  Validation loss = 5.4017  \n",
      "\n",
      "Fold: 12  Epoch: 57  Training loss = 4.3010  Validation loss = 5.4014  \n",
      "\n",
      "Fold: 12  Epoch: 58  Training loss = 4.3008  Validation loss = 5.4010  \n",
      "\n",
      "Fold: 12  Epoch: 59  Training loss = 4.3005  Validation loss = 5.4006  \n",
      "\n",
      "Fold: 12  Epoch: 60  Training loss = 4.3001  Validation loss = 5.4001  \n",
      "\n",
      "Fold: 12  Epoch: 61  Training loss = 4.2998  Validation loss = 5.3996  \n",
      "\n",
      "Fold: 12  Epoch: 62  Training loss = 4.2995  Validation loss = 5.3992  \n",
      "\n",
      "Fold: 12  Epoch: 63  Training loss = 4.2992  Validation loss = 5.3988  \n",
      "\n",
      "Fold: 12  Epoch: 64  Training loss = 4.2989  Validation loss = 5.3984  \n",
      "\n",
      "Fold: 12  Epoch: 65  Training loss = 4.2986  Validation loss = 5.3980  \n",
      "\n",
      "Fold: 12  Epoch: 66  Training loss = 4.2983  Validation loss = 5.3976  \n",
      "\n",
      "Fold: 12  Epoch: 67  Training loss = 4.2980  Validation loss = 5.3972  \n",
      "\n",
      "Fold: 12  Epoch: 68  Training loss = 4.2976  Validation loss = 5.3967  \n",
      "\n",
      "Fold: 12  Epoch: 69  Training loss = 4.2974  Validation loss = 5.3963  \n",
      "\n",
      "Fold: 12  Epoch: 70  Training loss = 4.2971  Validation loss = 5.3959  \n",
      "\n",
      "Fold: 12  Epoch: 71  Training loss = 4.2968  Validation loss = 5.3955  \n",
      "\n",
      "Fold: 12  Epoch: 72  Training loss = 4.2965  Validation loss = 5.3951  \n",
      "\n",
      "Fold: 12  Epoch: 73  Training loss = 4.2961  Validation loss = 5.3946  \n",
      "\n",
      "Fold: 12  Epoch: 74  Training loss = 4.2959  Validation loss = 5.3942  \n",
      "\n",
      "Fold: 12  Epoch: 75  Training loss = 4.2955  Validation loss = 5.3938  \n",
      "\n",
      "Fold: 12  Epoch: 76  Training loss = 4.2953  Validation loss = 5.3934  \n",
      "\n",
      "Fold: 12  Epoch: 77  Training loss = 4.2950  Validation loss = 5.3930  \n",
      "\n",
      "Fold: 12  Epoch: 78  Training loss = 4.2947  Validation loss = 5.3926  \n",
      "\n",
      "Fold: 12  Epoch: 79  Training loss = 4.2944  Validation loss = 5.3922  \n",
      "\n",
      "Fold: 12  Epoch: 80  Training loss = 4.2940  Validation loss = 5.3917  \n",
      "\n",
      "Fold: 12  Epoch: 81  Training loss = 4.2938  Validation loss = 5.3914  \n",
      "\n",
      "Fold: 12  Epoch: 82  Training loss = 4.2935  Validation loss = 5.3909  \n",
      "\n",
      "Fold: 12  Epoch: 83  Training loss = 4.2931  Validation loss = 5.3904  \n",
      "\n",
      "Fold: 12  Epoch: 84  Training loss = 4.2928  Validation loss = 5.3900  \n",
      "\n",
      "Fold: 12  Epoch: 85  Training loss = 4.2925  Validation loss = 5.3895  \n",
      "\n",
      "Fold: 12  Epoch: 86  Training loss = 4.2922  Validation loss = 5.3891  \n",
      "\n",
      "Fold: 12  Epoch: 87  Training loss = 4.2918  Validation loss = 5.3886  \n",
      "\n",
      "Fold: 12  Epoch: 88  Training loss = 4.2915  Validation loss = 5.3882  \n",
      "\n",
      "Fold: 12  Epoch: 89  Training loss = 4.2912  Validation loss = 5.3878  \n",
      "\n",
      "Fold: 12  Epoch: 90  Training loss = 4.2908  Validation loss = 5.3872  \n",
      "\n",
      "Fold: 12  Epoch: 91  Training loss = 4.2905  Validation loss = 5.3868  \n",
      "\n",
      "Fold: 12  Epoch: 92  Training loss = 4.2902  Validation loss = 5.3865  \n",
      "\n",
      "Fold: 12  Epoch: 93  Training loss = 4.2900  Validation loss = 5.3861  \n",
      "\n",
      "Fold: 12  Epoch: 94  Training loss = 4.2897  Validation loss = 5.3857  \n",
      "\n",
      "Fold: 12  Epoch: 95  Training loss = 4.2894  Validation loss = 5.3853  \n",
      "\n",
      "Fold: 12  Epoch: 96  Training loss = 4.2891  Validation loss = 5.3849  \n",
      "\n",
      "Fold: 12  Epoch: 97  Training loss = 4.2888  Validation loss = 5.3845  \n",
      "\n",
      "Fold: 12  Epoch: 98  Training loss = 4.2885  Validation loss = 5.3841  \n",
      "\n",
      "Fold: 12  Epoch: 99  Training loss = 4.2883  Validation loss = 5.3837  \n",
      "\n",
      "Fold: 12  Epoch: 100  Training loss = 4.2879  Validation loss = 5.3833  \n",
      "\n",
      "Fold: 12  Epoch: 101  Training loss = 4.2876  Validation loss = 5.3829  \n",
      "\n",
      "Fold: 12  Epoch: 102  Training loss = 4.2873  Validation loss = 5.3824  \n",
      "\n",
      "Fold: 12  Epoch: 103  Training loss = 4.2870  Validation loss = 5.3820  \n",
      "\n",
      "Fold: 12  Epoch: 104  Training loss = 4.2867  Validation loss = 5.3816  \n",
      "\n",
      "Fold: 12  Epoch: 105  Training loss = 4.2864  Validation loss = 5.3811  \n",
      "\n",
      "Fold: 12  Epoch: 106  Training loss = 4.2861  Validation loss = 5.3807  \n",
      "\n",
      "Fold: 12  Epoch: 107  Training loss = 4.2857  Validation loss = 5.3802  \n",
      "\n",
      "Fold: 12  Epoch: 108  Training loss = 4.2854  Validation loss = 5.3798  \n",
      "\n",
      "Fold: 12  Epoch: 109  Training loss = 4.2851  Validation loss = 5.3794  \n",
      "\n",
      "Fold: 12  Epoch: 110  Training loss = 4.2848  Validation loss = 5.3790  \n",
      "\n",
      "Fold: 12  Epoch: 111  Training loss = 4.2845  Validation loss = 5.3785  \n",
      "\n",
      "Fold: 12  Epoch: 112  Training loss = 4.2842  Validation loss = 5.3782  \n",
      "\n",
      "Fold: 12  Epoch: 113  Training loss = 4.2839  Validation loss = 5.3778  \n",
      "\n",
      "Fold: 12  Epoch: 114  Training loss = 4.2836  Validation loss = 5.3773  \n",
      "\n",
      "Fold: 12  Epoch: 115  Training loss = 4.2833  Validation loss = 5.3769  \n",
      "\n",
      "Fold: 12  Epoch: 116  Training loss = 4.2830  Validation loss = 5.3764  \n",
      "\n",
      "Fold: 12  Epoch: 117  Training loss = 4.2827  Validation loss = 5.3760  \n",
      "\n",
      "Fold: 12  Epoch: 118  Training loss = 4.2824  Validation loss = 5.3756  \n",
      "\n",
      "Fold: 12  Epoch: 119  Training loss = 4.2820  Validation loss = 5.3751  \n",
      "\n",
      "Fold: 12  Epoch: 120  Training loss = 4.2817  Validation loss = 5.3747  \n",
      "\n",
      "Fold: 12  Epoch: 121  Training loss = 4.2814  Validation loss = 5.3742  \n",
      "\n",
      "Fold: 12  Epoch: 122  Training loss = 4.2811  Validation loss = 5.3738  \n",
      "\n",
      "Fold: 12  Epoch: 123  Training loss = 4.2809  Validation loss = 5.3735  \n",
      "\n",
      "Fold: 12  Epoch: 124  Training loss = 4.2806  Validation loss = 5.3731  \n",
      "\n",
      "Fold: 12  Epoch: 125  Training loss = 4.2802  Validation loss = 5.3726  \n",
      "\n",
      "Fold: 12  Epoch: 126  Training loss = 4.2799  Validation loss = 5.3722  \n",
      "\n",
      "Fold: 12  Epoch: 127  Training loss = 4.2797  Validation loss = 5.3718  \n",
      "\n",
      "Fold: 12  Epoch: 128  Training loss = 4.2794  Validation loss = 5.3714  \n",
      "\n",
      "Fold: 12  Epoch: 129  Training loss = 4.2791  Validation loss = 5.3711  \n",
      "\n",
      "Fold: 12  Epoch: 130  Training loss = 4.2788  Validation loss = 5.3706  \n",
      "\n",
      "Fold: 12  Epoch: 131  Training loss = 4.2785  Validation loss = 5.3701  \n",
      "\n",
      "Fold: 12  Epoch: 132  Training loss = 4.2781  Validation loss = 5.3697  \n",
      "\n",
      "Fold: 12  Epoch: 133  Training loss = 4.2778  Validation loss = 5.3692  \n",
      "\n",
      "Fold: 12  Epoch: 134  Training loss = 4.2774  Validation loss = 5.3687  \n",
      "\n",
      "Fold: 12  Epoch: 135  Training loss = 4.2771  Validation loss = 5.3682  \n",
      "\n",
      "Fold: 12  Epoch: 136  Training loss = 4.2767  Validation loss = 5.3677  \n",
      "\n",
      "Fold: 12  Epoch: 137  Training loss = 4.2763  Validation loss = 5.3672  \n",
      "\n",
      "Fold: 12  Epoch: 138  Training loss = 4.2760  Validation loss = 5.3668  \n",
      "\n",
      "Fold: 12  Epoch: 139  Training loss = 4.2757  Validation loss = 5.3663  \n",
      "\n",
      "Fold: 12  Epoch: 140  Training loss = 4.2755  Validation loss = 5.3660  \n",
      "\n",
      "Fold: 12  Epoch: 141  Training loss = 4.2752  Validation loss = 5.3656  \n",
      "\n",
      "Fold: 12  Epoch: 142  Training loss = 4.2749  Validation loss = 5.3652  \n",
      "\n",
      "Fold: 12  Epoch: 143  Training loss = 4.2747  Validation loss = 5.3649  \n",
      "\n",
      "Fold: 12  Epoch: 144  Training loss = 4.2744  Validation loss = 5.3645  \n",
      "\n",
      "Fold: 12  Epoch: 145  Training loss = 4.2740  Validation loss = 5.3640  \n",
      "\n",
      "Fold: 12  Epoch: 146  Training loss = 4.2737  Validation loss = 5.3635  \n",
      "\n",
      "Fold: 12  Epoch: 147  Training loss = 4.2734  Validation loss = 5.3630  \n",
      "\n",
      "Fold: 12  Epoch: 148  Training loss = 4.2730  Validation loss = 5.3626  \n",
      "\n",
      "Fold: 12  Epoch: 149  Training loss = 4.2727  Validation loss = 5.3621  \n",
      "\n",
      "Fold: 12  Epoch: 150  Training loss = 4.2724  Validation loss = 5.3618  \n",
      "\n",
      "Fold: 12  Epoch: 151  Training loss = 4.2721  Validation loss = 5.3613  \n",
      "\n",
      "Fold: 12  Epoch: 152  Training loss = 4.2718  Validation loss = 5.3609  \n",
      "\n",
      "Fold: 12  Epoch: 153  Training loss = 4.2715  Validation loss = 5.3604  \n",
      "\n",
      "Fold: 12  Epoch: 154  Training loss = 4.2712  Validation loss = 5.3600  \n",
      "\n",
      "Fold: 12  Epoch: 155  Training loss = 4.2709  Validation loss = 5.3597  \n",
      "\n",
      "Fold: 12  Epoch: 156  Training loss = 4.2707  Validation loss = 5.3593  \n",
      "\n",
      "Fold: 12  Epoch: 157  Training loss = 4.2704  Validation loss = 5.3589  \n",
      "\n",
      "Fold: 12  Epoch: 158  Training loss = 4.2701  Validation loss = 5.3585  \n",
      "\n",
      "Fold: 12  Epoch: 159  Training loss = 4.2697  Validation loss = 5.3580  \n",
      "\n",
      "Fold: 12  Epoch: 160  Training loss = 4.2694  Validation loss = 5.3575  \n",
      "\n",
      "Fold: 12  Epoch: 161  Training loss = 4.2691  Validation loss = 5.3571  \n",
      "\n",
      "Fold: 12  Epoch: 162  Training loss = 4.2688  Validation loss = 5.3567  \n",
      "\n",
      "Fold: 12  Epoch: 163  Training loss = 4.2684  Validation loss = 5.3562  \n",
      "\n",
      "Fold: 12  Epoch: 164  Training loss = 4.2681  Validation loss = 5.3558  \n",
      "\n",
      "Fold: 12  Epoch: 165  Training loss = 4.2678  Validation loss = 5.3554  \n",
      "\n",
      "Fold: 12  Epoch: 166  Training loss = 4.2676  Validation loss = 5.3550  \n",
      "\n",
      "Fold: 12  Epoch: 167  Training loss = 4.2673  Validation loss = 5.3546  \n",
      "\n",
      "Fold: 12  Epoch: 168  Training loss = 4.2670  Validation loss = 5.3542  \n",
      "\n",
      "Fold: 12  Epoch: 169  Training loss = 4.2666  Validation loss = 5.3537  \n",
      "\n",
      "Fold: 12  Epoch: 170  Training loss = 4.2663  Validation loss = 5.3532  \n",
      "\n",
      "Fold: 12  Epoch: 171  Training loss = 4.2659  Validation loss = 5.3526  \n",
      "\n",
      "Fold: 12  Epoch: 172  Training loss = 4.2656  Validation loss = 5.3522  \n",
      "\n",
      "Fold: 12  Epoch: 173  Training loss = 4.2653  Validation loss = 5.3518  \n",
      "\n",
      "Fold: 12  Epoch: 174  Training loss = 4.2649  Validation loss = 5.3513  \n",
      "\n",
      "Fold: 12  Epoch: 175  Training loss = 4.2646  Validation loss = 5.3509  \n",
      "\n",
      "Fold: 12  Epoch: 176  Training loss = 4.2644  Validation loss = 5.3506  \n",
      "\n",
      "Fold: 12  Epoch: 177  Training loss = 4.2641  Validation loss = 5.3501  \n",
      "\n",
      "Fold: 12  Epoch: 178  Training loss = 4.2638  Validation loss = 5.3497  \n",
      "\n",
      "Fold: 12  Epoch: 179  Training loss = 4.2634  Validation loss = 5.3492  \n",
      "\n",
      "Fold: 12  Epoch: 180  Training loss = 4.2631  Validation loss = 5.3487  \n",
      "\n",
      "Fold: 12  Epoch: 181  Training loss = 4.2628  Validation loss = 5.3484  \n",
      "\n",
      "Fold: 12  Epoch: 182  Training loss = 4.2625  Validation loss = 5.3480  \n",
      "\n",
      "Fold: 12  Epoch: 183  Training loss = 4.2622  Validation loss = 5.3475  \n",
      "\n",
      "Fold: 12  Epoch: 184  Training loss = 4.2619  Validation loss = 5.3471  \n",
      "\n",
      "Fold: 12  Epoch: 185  Training loss = 4.2616  Validation loss = 5.3467  \n",
      "\n",
      "Fold: 12  Epoch: 186  Training loss = 4.2613  Validation loss = 5.3462  \n",
      "\n",
      "Fold: 12  Epoch: 187  Training loss = 4.2610  Validation loss = 5.3458  \n",
      "\n",
      "Fold: 12  Epoch: 188  Training loss = 4.2607  Validation loss = 5.3455  \n",
      "\n",
      "Fold: 12  Epoch: 189  Training loss = 4.2605  Validation loss = 5.3452  \n",
      "\n",
      "Fold: 12  Epoch: 190  Training loss = 4.2602  Validation loss = 5.3448  \n",
      "\n",
      "Fold: 12  Epoch: 191  Training loss = 4.2600  Validation loss = 5.3444  \n",
      "\n",
      "Fold: 12  Epoch: 192  Training loss = 4.2597  Validation loss = 5.3440  \n",
      "\n",
      "Fold: 12  Epoch: 193  Training loss = 4.2595  Validation loss = 5.3437  \n",
      "\n",
      "Fold: 12  Epoch: 194  Training loss = 4.2592  Validation loss = 5.3433  \n",
      "\n",
      "Fold: 12  Epoch: 195  Training loss = 4.2589  Validation loss = 5.3429  \n",
      "\n",
      "Fold: 12  Epoch: 196  Training loss = 4.2586  Validation loss = 5.3425  \n",
      "\n",
      "Fold: 12  Epoch: 197  Training loss = 4.2583  Validation loss = 5.3420  \n",
      "\n",
      "Fold: 12  Epoch: 198  Training loss = 4.2580  Validation loss = 5.3416  \n",
      "\n",
      "Fold: 12  Epoch: 199  Training loss = 4.2577  Validation loss = 5.3412  \n",
      "\n",
      "Fold: 12  Epoch: 200  Training loss = 4.2574  Validation loss = 5.3408  \n",
      "\n",
      "Fold: 12  Epoch: 201  Training loss = 4.2570  Validation loss = 5.3403  \n",
      "\n",
      "Fold: 12  Epoch: 202  Training loss = 4.2567  Validation loss = 5.3399  \n",
      "\n",
      "Fold: 12  Epoch: 203  Training loss = 4.2565  Validation loss = 5.3395  \n",
      "\n",
      "Fold: 12  Epoch: 204  Training loss = 4.2562  Validation loss = 5.3391  \n",
      "\n",
      "Fold: 12  Epoch: 205  Training loss = 4.2559  Validation loss = 5.3388  \n",
      "\n",
      "Fold: 12  Epoch: 206  Training loss = 4.2556  Validation loss = 5.3383  \n",
      "\n",
      "Fold: 12  Epoch: 207  Training loss = 4.2553  Validation loss = 5.3379  \n",
      "\n",
      "Fold: 12  Epoch: 208  Training loss = 4.2551  Validation loss = 5.3375  \n",
      "\n",
      "Fold: 12  Epoch: 209  Training loss = 4.2547  Validation loss = 5.3370  \n",
      "\n",
      "Fold: 12  Epoch: 210  Training loss = 4.2545  Validation loss = 5.3367  \n",
      "\n",
      "Fold: 12  Epoch: 211  Training loss = 4.2541  Validation loss = 5.3362  \n",
      "\n",
      "Fold: 12  Epoch: 212  Training loss = 4.2538  Validation loss = 5.3358  \n",
      "\n",
      "Fold: 12  Epoch: 213  Training loss = 4.2536  Validation loss = 5.3355  \n",
      "\n",
      "Fold: 12  Epoch: 214  Training loss = 4.2534  Validation loss = 5.3352  \n",
      "\n",
      "Fold: 12  Epoch: 215  Training loss = 4.2531  Validation loss = 5.3348  \n",
      "\n",
      "Fold: 12  Epoch: 216  Training loss = 4.2528  Validation loss = 5.3343  \n",
      "\n",
      "Fold: 12  Epoch: 217  Training loss = 4.2524  Validation loss = 5.3338  \n",
      "\n",
      "Fold: 12  Epoch: 218  Training loss = 4.2520  Validation loss = 5.3333  \n",
      "\n",
      "Fold: 12  Epoch: 219  Training loss = 4.2517  Validation loss = 5.3329  \n",
      "\n",
      "Fold: 12  Epoch: 220  Training loss = 4.2514  Validation loss = 5.3324  \n",
      "\n",
      "Fold: 12  Epoch: 221  Training loss = 4.2511  Validation loss = 5.3319  \n",
      "\n",
      "Fold: 12  Epoch: 222  Training loss = 4.2508  Validation loss = 5.3315  \n",
      "\n",
      "Fold: 12  Epoch: 223  Training loss = 4.2505  Validation loss = 5.3311  \n",
      "\n",
      "Fold: 12  Epoch: 224  Training loss = 4.2502  Validation loss = 5.3307  \n",
      "\n",
      "Fold: 12  Epoch: 225  Training loss = 4.2498  Validation loss = 5.3302  \n",
      "\n",
      "Fold: 12  Epoch: 226  Training loss = 4.2495  Validation loss = 5.3298  \n",
      "\n",
      "Fold: 12  Epoch: 227  Training loss = 4.2492  Validation loss = 5.3293  \n",
      "\n",
      "Fold: 12  Epoch: 228  Training loss = 4.2489  Validation loss = 5.3289  \n",
      "\n",
      "Fold: 12  Epoch: 229  Training loss = 4.2487  Validation loss = 5.3286  \n",
      "\n",
      "Fold: 12  Epoch: 230  Training loss = 4.2483  Validation loss = 5.3281  \n",
      "\n",
      "Fold: 12  Epoch: 231  Training loss = 4.2479  Validation loss = 5.3275  \n",
      "\n",
      "Fold: 12  Epoch: 232  Training loss = 4.2477  Validation loss = 5.3272  \n",
      "\n",
      "Fold: 12  Epoch: 233  Training loss = 4.2474  Validation loss = 5.3268  \n",
      "\n",
      "Fold: 12  Epoch: 234  Training loss = 4.2472  Validation loss = 5.3265  \n",
      "\n",
      "Fold: 12  Epoch: 235  Training loss = 4.2468  Validation loss = 5.3260  \n",
      "\n",
      "Fold: 12  Epoch: 236  Training loss = 4.2465  Validation loss = 5.3256  \n",
      "\n",
      "Fold: 12  Epoch: 237  Training loss = 4.2462  Validation loss = 5.3252  \n",
      "\n",
      "Fold: 12  Epoch: 238  Training loss = 4.2459  Validation loss = 5.3248  \n",
      "\n",
      "Fold: 12  Epoch: 239  Training loss = 4.2457  Validation loss = 5.3243  \n",
      "\n",
      "Fold: 12  Epoch: 240  Training loss = 4.2453  Validation loss = 5.3239  \n",
      "\n",
      "Fold: 12  Epoch: 241  Training loss = 4.2450  Validation loss = 5.3235  \n",
      "\n",
      "Fold: 12  Epoch: 242  Training loss = 4.2447  Validation loss = 5.3230  \n",
      "\n",
      "Fold: 12  Epoch: 243  Training loss = 4.2443  Validation loss = 5.3224  \n",
      "\n",
      "Fold: 12  Epoch: 244  Training loss = 4.2439  Validation loss = 5.3219  \n",
      "\n",
      "Fold: 12  Epoch: 245  Training loss = 4.2436  Validation loss = 5.3214  \n",
      "\n",
      "Fold: 12  Epoch: 246  Training loss = 4.2433  Validation loss = 5.3210  \n",
      "\n",
      "Fold: 12  Epoch: 247  Training loss = 4.2430  Validation loss = 5.3207  \n",
      "\n",
      "Fold: 12  Epoch: 248  Training loss = 4.2427  Validation loss = 5.3202  \n",
      "\n",
      "Fold: 12  Epoch: 249  Training loss = 4.2424  Validation loss = 5.3198  \n",
      "\n",
      "Fold: 12  Epoch: 250  Training loss = 4.2421  Validation loss = 5.3194  \n",
      "\n",
      "Fold: 12  Epoch: 251  Training loss = 4.2418  Validation loss = 5.3190  \n",
      "\n",
      "Fold: 12  Epoch: 252  Training loss = 4.2415  Validation loss = 5.3185  \n",
      "\n",
      "Fold: 12  Epoch: 253  Training loss = 4.2412  Validation loss = 5.3182  \n",
      "\n",
      "Fold: 12  Epoch: 254  Training loss = 4.2409  Validation loss = 5.3177  \n",
      "\n",
      "Fold: 12  Epoch: 255  Training loss = 4.2407  Validation loss = 5.3174  \n",
      "\n",
      "Fold: 12  Epoch: 256  Training loss = 4.2404  Validation loss = 5.3170  \n",
      "\n",
      "Fold: 12  Epoch: 257  Training loss = 4.2401  Validation loss = 5.3166  \n",
      "\n",
      "Fold: 12  Epoch: 258  Training loss = 4.2398  Validation loss = 5.3162  \n",
      "\n",
      "Fold: 12  Epoch: 259  Training loss = 4.2395  Validation loss = 5.3158  \n",
      "\n",
      "Fold: 12  Epoch: 260  Training loss = 4.2392  Validation loss = 5.3154  \n",
      "\n",
      "Fold: 12  Epoch: 261  Training loss = 4.2390  Validation loss = 5.3150  \n",
      "\n",
      "Fold: 12  Epoch: 262  Training loss = 4.2387  Validation loss = 5.3146  \n",
      "\n",
      "Fold: 12  Epoch: 263  Training loss = 4.2384  Validation loss = 5.3142  \n",
      "\n",
      "Fold: 12  Epoch: 264  Training loss = 4.2382  Validation loss = 5.3139  \n",
      "\n",
      "Fold: 12  Epoch: 265  Training loss = 4.2379  Validation loss = 5.3135  \n",
      "\n",
      "Fold: 12  Epoch: 266  Training loss = 4.2376  Validation loss = 5.3130  \n",
      "\n",
      "Fold: 12  Epoch: 267  Training loss = 4.2373  Validation loss = 5.3126  \n",
      "\n",
      "Fold: 12  Epoch: 268  Training loss = 4.2370  Validation loss = 5.3122  \n",
      "\n",
      "Fold: 12  Epoch: 269  Training loss = 4.2367  Validation loss = 5.3118  \n",
      "\n",
      "Fold: 12  Epoch: 270  Training loss = 4.2364  Validation loss = 5.3113  \n",
      "\n",
      "Fold: 12  Epoch: 271  Training loss = 4.2361  Validation loss = 5.3109  \n",
      "\n",
      "Fold: 12  Epoch: 272  Training loss = 4.2358  Validation loss = 5.3105  \n",
      "\n",
      "Fold: 12  Epoch: 273  Training loss = 4.2355  Validation loss = 5.3100  \n",
      "\n",
      "Fold: 12  Epoch: 274  Training loss = 4.2352  Validation loss = 5.3097  \n",
      "\n",
      "Fold: 12  Epoch: 275  Training loss = 4.2349  Validation loss = 5.3092  \n",
      "\n",
      "Fold: 12  Epoch: 276  Training loss = 4.2345  Validation loss = 5.3087  \n",
      "\n",
      "Fold: 12  Epoch: 277  Training loss = 4.2343  Validation loss = 5.3084  \n",
      "\n",
      "Fold: 12  Epoch: 278  Training loss = 4.2340  Validation loss = 5.3079  \n",
      "\n",
      "Fold: 12  Epoch: 279  Training loss = 4.2336  Validation loss = 5.3074  \n",
      "\n",
      "Fold: 12  Epoch: 280  Training loss = 4.2333  Validation loss = 5.3070  \n",
      "\n",
      "Fold: 12  Epoch: 281  Training loss = 4.2330  Validation loss = 5.3066  \n",
      "\n",
      "Fold: 12  Epoch: 282  Training loss = 4.2327  Validation loss = 5.3061  \n",
      "\n",
      "Fold: 12  Epoch: 283  Training loss = 4.2325  Validation loss = 5.3058  \n",
      "\n",
      "Fold: 12  Epoch: 284  Training loss = 4.2322  Validation loss = 5.3054  \n",
      "\n",
      "Fold: 12  Epoch: 285  Training loss = 4.2318  Validation loss = 5.3049  \n",
      "\n",
      "Fold: 12  Epoch: 286  Training loss = 4.2316  Validation loss = 5.3045  \n",
      "\n",
      "Fold: 12  Epoch: 287  Training loss = 4.2313  Validation loss = 5.3042  \n",
      "\n",
      "Fold: 12  Epoch: 288  Training loss = 4.2310  Validation loss = 5.3038  \n",
      "\n",
      "Fold: 12  Epoch: 289  Training loss = 4.2307  Validation loss = 5.3033  \n",
      "\n",
      "Fold: 12  Epoch: 290  Training loss = 4.2304  Validation loss = 5.3028  \n",
      "\n",
      "Fold: 12  Epoch: 291  Training loss = 4.2300  Validation loss = 5.3023  \n",
      "\n",
      "Fold: 12  Epoch: 292  Training loss = 4.2297  Validation loss = 5.3019  \n",
      "\n",
      "Fold: 12  Epoch: 293  Training loss = 4.2295  Validation loss = 5.3016  \n",
      "\n",
      "Fold: 12  Epoch: 294  Training loss = 4.2292  Validation loss = 5.3012  \n",
      "\n",
      "Fold: 12  Epoch: 295  Training loss = 4.2289  Validation loss = 5.3007  \n",
      "\n",
      "Fold: 12  Epoch: 296  Training loss = 4.2286  Validation loss = 5.3003  \n",
      "\n",
      "Fold: 12  Epoch: 297  Training loss = 4.2283  Validation loss = 5.3000  \n",
      "\n",
      "Fold: 12  Epoch: 298  Training loss = 4.2281  Validation loss = 5.2996  \n",
      "\n",
      "Fold: 12  Epoch: 299  Training loss = 4.2278  Validation loss = 5.2992  \n",
      "\n",
      "Fold: 12  Epoch: 300  Training loss = 4.2275  Validation loss = 5.2988  \n",
      "\n",
      "Fold: 12  Epoch: 301  Training loss = 4.2273  Validation loss = 5.2984  \n",
      "\n",
      "Fold: 12  Epoch: 302  Training loss = 4.2270  Validation loss = 5.2980  \n",
      "\n",
      "Fold: 12  Epoch: 303  Training loss = 4.2267  Validation loss = 5.2977  \n",
      "\n",
      "Fold: 12  Epoch: 304  Training loss = 4.2265  Validation loss = 5.2973  \n",
      "\n",
      "Fold: 12  Epoch: 305  Training loss = 4.2262  Validation loss = 5.2969  \n",
      "\n",
      "Fold: 12  Epoch: 306  Training loss = 4.2259  Validation loss = 5.2965  \n",
      "\n",
      "Fold: 12  Epoch: 307  Training loss = 4.2256  Validation loss = 5.2961  \n",
      "\n",
      "Fold: 12  Epoch: 308  Training loss = 4.2254  Validation loss = 5.2957  \n",
      "\n",
      "Fold: 12  Epoch: 309  Training loss = 4.2251  Validation loss = 5.2953  \n",
      "\n",
      "Fold: 12  Epoch: 310  Training loss = 4.2248  Validation loss = 5.2949  \n",
      "\n",
      "Fold: 12  Epoch: 311  Training loss = 4.2244  Validation loss = 5.2944  \n",
      "\n",
      "Fold: 12  Epoch: 312  Training loss = 4.2241  Validation loss = 5.2940  \n",
      "\n",
      "Fold: 12  Epoch: 313  Training loss = 4.2238  Validation loss = 5.2935  \n",
      "\n",
      "Fold: 12  Epoch: 314  Training loss = 4.2236  Validation loss = 5.2932  \n",
      "\n",
      "Fold: 12  Epoch: 315  Training loss = 4.2232  Validation loss = 5.2927  \n",
      "\n",
      "Fold: 12  Epoch: 316  Training loss = 4.2229  Validation loss = 5.2923  \n",
      "\n",
      "Fold: 12  Epoch: 317  Training loss = 4.2226  Validation loss = 5.2918  \n",
      "\n",
      "Fold: 12  Epoch: 318  Training loss = 4.2223  Validation loss = 5.2914  \n",
      "\n",
      "Fold: 12  Epoch: 319  Training loss = 4.2220  Validation loss = 5.2910  \n",
      "\n",
      "Fold: 12  Epoch: 320  Training loss = 4.2217  Validation loss = 5.2906  \n",
      "\n",
      "Fold: 12  Epoch: 321  Training loss = 4.2214  Validation loss = 5.2902  \n",
      "\n",
      "Fold: 12  Epoch: 322  Training loss = 4.2212  Validation loss = 5.2898  \n",
      "\n",
      "Fold: 12  Epoch: 323  Training loss = 4.2209  Validation loss = 5.2895  \n",
      "\n",
      "Fold: 12  Epoch: 324  Training loss = 4.2207  Validation loss = 5.2891  \n",
      "\n",
      "Fold: 12  Epoch: 325  Training loss = 4.2204  Validation loss = 5.2887  \n",
      "\n",
      "Fold: 12  Epoch: 326  Training loss = 4.2201  Validation loss = 5.2883  \n",
      "\n",
      "Fold: 12  Epoch: 327  Training loss = 4.2198  Validation loss = 5.2879  \n",
      "\n",
      "Fold: 12  Epoch: 328  Training loss = 4.2196  Validation loss = 5.2875  \n",
      "\n",
      "Fold: 12  Epoch: 329  Training loss = 4.2193  Validation loss = 5.2871  \n",
      "\n",
      "Fold: 12  Epoch: 330  Training loss = 4.2191  Validation loss = 5.2868  \n",
      "\n",
      "Fold: 12  Epoch: 331  Training loss = 4.2188  Validation loss = 5.2864  \n",
      "\n",
      "Fold: 12  Epoch: 332  Training loss = 4.2184  Validation loss = 5.2859  \n",
      "\n",
      "Fold: 12  Epoch: 333  Training loss = 4.2182  Validation loss = 5.2855  \n",
      "\n",
      "Fold: 12  Epoch: 334  Training loss = 4.2179  Validation loss = 5.2851  \n",
      "\n",
      "Fold: 12  Epoch: 335  Training loss = 4.2177  Validation loss = 5.2848  \n",
      "\n",
      "Fold: 12  Epoch: 336  Training loss = 4.2174  Validation loss = 5.2844  \n",
      "\n",
      "Fold: 12  Epoch: 337  Training loss = 4.2171  Validation loss = 5.2839  \n",
      "\n",
      "Fold: 12  Epoch: 338  Training loss = 4.2167  Validation loss = 5.2835  \n",
      "\n",
      "Fold: 12  Epoch: 339  Training loss = 4.2164  Validation loss = 5.2830  \n",
      "\n",
      "Fold: 12  Epoch: 340  Training loss = 4.2161  Validation loss = 5.2825  \n",
      "\n",
      "Fold: 12  Epoch: 341  Training loss = 4.2157  Validation loss = 5.2821  \n",
      "\n",
      "Fold: 12  Epoch: 342  Training loss = 4.2154  Validation loss = 5.2816  \n",
      "\n",
      "Fold: 12  Epoch: 343  Training loss = 4.2152  Validation loss = 5.2813  \n",
      "\n",
      "Fold: 12  Epoch: 344  Training loss = 4.2149  Validation loss = 5.2809  \n",
      "\n",
      "Fold: 12  Epoch: 345  Training loss = 4.2147  Validation loss = 5.2805  \n",
      "\n",
      "Fold: 12  Epoch: 346  Training loss = 4.2144  Validation loss = 5.2802  \n",
      "\n",
      "Fold: 12  Epoch: 347  Training loss = 4.2142  Validation loss = 5.2798  \n",
      "\n",
      "Fold: 12  Epoch: 348  Training loss = 4.2139  Validation loss = 5.2795  \n",
      "\n",
      "Fold: 12  Epoch: 349  Training loss = 4.2136  Validation loss = 5.2790  \n",
      "\n",
      "Fold: 12  Epoch: 350  Training loss = 4.2133  Validation loss = 5.2786  \n",
      "\n",
      "Fold: 12  Epoch: 351  Training loss = 4.2131  Validation loss = 5.2783  \n",
      "\n",
      "Fold: 12  Epoch: 352  Training loss = 4.2127  Validation loss = 5.2778  \n",
      "\n",
      "Fold: 12  Epoch: 353  Training loss = 4.2125  Validation loss = 5.2774  \n",
      "\n",
      "Fold: 12  Epoch: 354  Training loss = 4.2122  Validation loss = 5.2770  \n",
      "\n",
      "Fold: 12  Epoch: 355  Training loss = 4.2119  Validation loss = 5.2765  \n",
      "\n",
      "Fold: 12  Epoch: 356  Training loss = 4.2116  Validation loss = 5.2762  \n",
      "\n",
      "Fold: 12  Epoch: 357  Training loss = 4.2113  Validation loss = 5.2758  \n",
      "\n",
      "Fold: 12  Epoch: 358  Training loss = 4.2110  Validation loss = 5.2753  \n",
      "\n",
      "Fold: 12  Epoch: 359  Training loss = 4.2107  Validation loss = 5.2749  \n",
      "\n",
      "Fold: 12  Epoch: 360  Training loss = 4.2104  Validation loss = 5.2745  \n",
      "\n",
      "Fold: 12  Epoch: 361  Training loss = 4.2101  Validation loss = 5.2740  \n",
      "\n",
      "Fold: 12  Epoch: 362  Training loss = 4.2098  Validation loss = 5.2735  \n",
      "\n",
      "Fold: 12  Epoch: 363  Training loss = 4.2095  Validation loss = 5.2731  \n",
      "\n",
      "Fold: 12  Epoch: 364  Training loss = 4.2092  Validation loss = 5.2727  \n",
      "\n",
      "Fold: 12  Epoch: 365  Training loss = 4.2088  Validation loss = 5.2722  \n",
      "\n",
      "Fold: 12  Epoch: 366  Training loss = 4.2085  Validation loss = 5.2718  \n",
      "\n",
      "Fold: 12  Epoch: 367  Training loss = 4.2082  Validation loss = 5.2713  \n",
      "\n",
      "Fold: 12  Epoch: 368  Training loss = 4.2079  Validation loss = 5.2708  \n",
      "\n",
      "Fold: 12  Epoch: 369  Training loss = 4.2076  Validation loss = 5.2705  \n",
      "\n",
      "Fold: 12  Epoch: 370  Training loss = 4.2074  Validation loss = 5.2701  \n",
      "\n",
      "Fold: 12  Epoch: 371  Training loss = 4.2070  Validation loss = 5.2696  \n",
      "\n",
      "Fold: 12  Epoch: 372  Training loss = 4.2066  Validation loss = 5.2691  \n",
      "\n",
      "Fold: 12  Epoch: 373  Training loss = 4.2063  Validation loss = 5.2686  \n",
      "\n",
      "Fold: 12  Epoch: 374  Training loss = 4.2060  Validation loss = 5.2682  \n",
      "\n",
      "Fold: 12  Epoch: 375  Training loss = 4.2058  Validation loss = 5.2679  \n",
      "\n",
      "Fold: 12  Epoch: 376  Training loss = 4.2055  Validation loss = 5.2675  \n",
      "\n",
      "Fold: 12  Epoch: 377  Training loss = 4.2052  Validation loss = 5.2671  \n",
      "\n",
      "Fold: 12  Epoch: 378  Training loss = 4.2050  Validation loss = 5.2667  \n",
      "\n",
      "Fold: 12  Epoch: 379  Training loss = 4.2047  Validation loss = 5.2663  \n",
      "\n",
      "Fold: 12  Epoch: 380  Training loss = 4.2044  Validation loss = 5.2658  \n",
      "\n",
      "Fold: 12  Epoch: 381  Training loss = 4.2040  Validation loss = 5.2654  \n",
      "\n",
      "Fold: 12  Epoch: 382  Training loss = 4.2037  Validation loss = 5.2649  \n",
      "\n",
      "Fold: 12  Epoch: 383  Training loss = 4.2034  Validation loss = 5.2645  \n",
      "\n",
      "Fold: 12  Epoch: 384  Training loss = 4.2031  Validation loss = 5.2641  \n",
      "\n",
      "Fold: 12  Epoch: 385  Training loss = 4.2028  Validation loss = 5.2636  \n",
      "\n",
      "Fold: 12  Epoch: 386  Training loss = 4.2025  Validation loss = 5.2632  \n",
      "\n",
      "Fold: 12  Epoch: 387  Training loss = 4.2022  Validation loss = 5.2628  \n",
      "\n",
      "Fold: 12  Epoch: 388  Training loss = 4.2019  Validation loss = 5.2623  \n",
      "\n",
      "Fold: 12  Epoch: 389  Training loss = 4.2016  Validation loss = 5.2618  \n",
      "\n",
      "Fold: 12  Epoch: 390  Training loss = 4.2012  Validation loss = 5.2613  \n",
      "\n",
      "Fold: 12  Epoch: 391  Training loss = 4.2009  Validation loss = 5.2609  \n",
      "\n",
      "Fold: 12  Epoch: 392  Training loss = 4.2007  Validation loss = 5.2606  \n",
      "\n",
      "Fold: 12  Epoch: 393  Training loss = 4.2004  Validation loss = 5.2602  \n",
      "\n",
      "Fold: 12  Epoch: 394  Training loss = 4.2001  Validation loss = 5.2597  \n",
      "\n",
      "Fold: 12  Epoch: 395  Training loss = 4.1998  Validation loss = 5.2593  \n",
      "\n",
      "Fold: 12  Epoch: 396  Training loss = 4.1996  Validation loss = 5.2590  \n",
      "\n",
      "Fold: 12  Epoch: 397  Training loss = 4.1994  Validation loss = 5.2587  \n",
      "\n",
      "Fold: 12  Epoch: 398  Training loss = 4.1991  Validation loss = 5.2583  \n",
      "\n",
      "Fold: 12  Epoch: 399  Training loss = 4.1988  Validation loss = 5.2578  \n",
      "\n",
      "Fold: 12  Epoch: 400  Training loss = 4.1985  Validation loss = 5.2573  \n",
      "\n",
      "Fold: 12  Epoch: 401  Training loss = 4.1982  Validation loss = 5.2570  \n",
      "\n",
      "Fold: 12  Epoch: 402  Training loss = 4.1979  Validation loss = 5.2565  \n",
      "\n",
      "Fold: 12  Epoch: 403  Training loss = 4.1976  Validation loss = 5.2561  \n",
      "\n",
      "Fold: 12  Epoch: 404  Training loss = 4.1973  Validation loss = 5.2557  \n",
      "\n",
      "Fold: 12  Epoch: 405  Training loss = 4.1971  Validation loss = 5.2554  \n",
      "\n",
      "Fold: 12  Epoch: 406  Training loss = 4.1969  Validation loss = 5.2550  \n",
      "\n",
      "Fold: 12  Epoch: 407  Training loss = 4.1965  Validation loss = 5.2546  \n",
      "\n",
      "Fold: 12  Epoch: 408  Training loss = 4.1962  Validation loss = 5.2541  \n",
      "\n",
      "Fold: 12  Epoch: 409  Training loss = 4.1960  Validation loss = 5.2538  \n",
      "\n",
      "Fold: 12  Epoch: 410  Training loss = 4.1957  Validation loss = 5.2534  \n",
      "\n",
      "Fold: 12  Epoch: 411  Training loss = 4.1955  Validation loss = 5.2531  \n",
      "\n",
      "Fold: 12  Epoch: 412  Training loss = 4.1952  Validation loss = 5.2526  \n",
      "\n",
      "Fold: 12  Epoch: 413  Training loss = 4.1948  Validation loss = 5.2522  \n",
      "\n",
      "Fold: 12  Epoch: 414  Training loss = 4.1946  Validation loss = 5.2518  \n",
      "\n",
      "Fold: 12  Epoch: 415  Training loss = 4.1943  Validation loss = 5.2514  \n",
      "\n",
      "Fold: 12  Epoch: 416  Training loss = 4.1941  Validation loss = 5.2511  \n",
      "\n",
      "Fold: 12  Epoch: 417  Training loss = 4.1938  Validation loss = 5.2507  \n",
      "\n",
      "Fold: 12  Epoch: 418  Training loss = 4.1935  Validation loss = 5.2503  \n",
      "\n",
      "Fold: 12  Epoch: 419  Training loss = 4.1933  Validation loss = 5.2499  \n",
      "\n",
      "Fold: 12  Epoch: 420  Training loss = 4.1930  Validation loss = 5.2495  \n",
      "\n",
      "Fold: 12  Epoch: 421  Training loss = 4.1928  Validation loss = 5.2492  \n",
      "\n",
      "Fold: 12  Epoch: 422  Training loss = 4.1924  Validation loss = 5.2487  \n",
      "\n",
      "Fold: 12  Epoch: 423  Training loss = 4.1922  Validation loss = 5.2484  \n",
      "\n",
      "Fold: 12  Epoch: 424  Training loss = 4.1919  Validation loss = 5.2480  \n",
      "\n",
      "Fold: 12  Epoch: 425  Training loss = 4.1916  Validation loss = 5.2475  \n",
      "\n",
      "Fold: 12  Epoch: 426  Training loss = 4.1913  Validation loss = 5.2471  \n",
      "\n",
      "Fold: 12  Epoch: 427  Training loss = 4.1910  Validation loss = 5.2466  \n",
      "\n",
      "Fold: 12  Epoch: 428  Training loss = 4.1906  Validation loss = 5.2460  \n",
      "\n",
      "Fold: 12  Epoch: 429  Training loss = 4.1903  Validation loss = 5.2456  \n",
      "\n",
      "Fold: 12  Epoch: 430  Training loss = 4.1899  Validation loss = 5.2451  \n",
      "\n",
      "Fold: 12  Epoch: 431  Training loss = 4.1897  Validation loss = 5.2447  \n",
      "\n",
      "Fold: 12  Epoch: 432  Training loss = 4.1894  Validation loss = 5.2444  \n",
      "\n",
      "Fold: 12  Epoch: 433  Training loss = 4.1891  Validation loss = 5.2439  \n",
      "\n",
      "Fold: 12  Epoch: 434  Training loss = 4.1888  Validation loss = 5.2435  \n",
      "\n",
      "Fold: 12  Epoch: 435  Training loss = 4.1885  Validation loss = 5.2431  \n",
      "\n",
      "Fold: 12  Epoch: 436  Training loss = 4.1882  Validation loss = 5.2426  \n",
      "\n",
      "Fold: 12  Epoch: 437  Training loss = 4.1880  Validation loss = 5.2423  \n",
      "\n",
      "Fold: 12  Epoch: 438  Training loss = 4.1877  Validation loss = 5.2419  \n",
      "\n",
      "Fold: 12  Epoch: 439  Training loss = 4.1875  Validation loss = 5.2416  \n",
      "\n",
      "Fold: 12  Epoch: 440  Training loss = 4.1871  Validation loss = 5.2410  \n",
      "\n",
      "Fold: 12  Epoch: 441  Training loss = 4.1868  Validation loss = 5.2405  \n",
      "\n",
      "Fold: 12  Epoch: 442  Training loss = 4.1865  Validation loss = 5.2401  \n",
      "\n",
      "Fold: 12  Epoch: 443  Training loss = 4.1862  Validation loss = 5.2398  \n",
      "\n",
      "Fold: 12  Epoch: 444  Training loss = 4.1860  Validation loss = 5.2394  \n",
      "\n",
      "Fold: 12  Epoch: 445  Training loss = 4.1857  Validation loss = 5.2390  \n",
      "\n",
      "Fold: 12  Epoch: 446  Training loss = 4.1854  Validation loss = 5.2386  \n",
      "\n",
      "Fold: 12  Epoch: 447  Training loss = 4.1851  Validation loss = 5.2381  \n",
      "\n",
      "Fold: 12  Epoch: 448  Training loss = 4.1847  Validation loss = 5.2376  \n",
      "\n",
      "Fold: 12  Epoch: 449  Training loss = 4.1844  Validation loss = 5.2371  \n",
      "\n",
      "Fold: 12  Epoch: 450  Training loss = 4.1841  Validation loss = 5.2367  \n",
      "\n",
      "Fold: 12  Epoch: 451  Training loss = 4.1838  Validation loss = 5.2363  \n",
      "\n",
      "Fold: 12  Epoch: 452  Training loss = 4.1835  Validation loss = 5.2358  \n",
      "\n",
      "Fold: 12  Epoch: 453  Training loss = 4.1833  Validation loss = 5.2354  \n",
      "\n",
      "Fold: 12  Epoch: 454  Training loss = 4.1829  Validation loss = 5.2350  \n",
      "\n",
      "Fold: 12  Epoch: 455  Training loss = 4.1826  Validation loss = 5.2345  \n",
      "\n",
      "Fold: 12  Epoch: 456  Training loss = 4.1823  Validation loss = 5.2340  \n",
      "\n",
      "Fold: 12  Epoch: 457  Training loss = 4.1820  Validation loss = 5.2336  \n",
      "\n",
      "Fold: 12  Epoch: 458  Training loss = 4.1817  Validation loss = 5.2333  \n",
      "\n",
      "Fold: 12  Epoch: 459  Training loss = 4.1815  Validation loss = 5.2329  \n",
      "\n",
      "Fold: 12  Epoch: 460  Training loss = 4.1811  Validation loss = 5.2324  \n",
      "\n",
      "Fold: 12  Epoch: 461  Training loss = 4.1809  Validation loss = 5.2320  \n",
      "\n",
      "Fold: 12  Epoch: 462  Training loss = 4.1806  Validation loss = 5.2316  \n",
      "\n",
      "Fold: 12  Epoch: 463  Training loss = 4.1803  Validation loss = 5.2311  \n",
      "\n",
      "Fold: 12  Epoch: 464  Training loss = 4.1799  Validation loss = 5.2306  \n",
      "\n",
      "Fold: 12  Epoch: 465  Training loss = 4.1797  Validation loss = 5.2303  \n",
      "\n",
      "Fold: 12  Epoch: 466  Training loss = 4.1794  Validation loss = 5.2299  \n",
      "\n",
      "Fold: 12  Epoch: 467  Training loss = 4.1791  Validation loss = 5.2294  \n",
      "\n",
      "Fold: 12  Epoch: 468  Training loss = 4.1788  Validation loss = 5.2290  \n",
      "\n",
      "Fold: 12  Epoch: 469  Training loss = 4.1784  Validation loss = 5.2285  \n",
      "\n",
      "Fold: 12  Epoch: 470  Training loss = 4.1782  Validation loss = 5.2281  \n",
      "\n",
      "Fold: 12  Epoch: 471  Training loss = 4.1778  Validation loss = 5.2276  \n",
      "\n",
      "Fold: 12  Epoch: 472  Training loss = 4.1776  Validation loss = 5.2272  \n",
      "\n",
      "Fold: 12  Epoch: 473  Training loss = 4.1773  Validation loss = 5.2268  \n",
      "\n",
      "Fold: 12  Epoch: 474  Training loss = 4.1770  Validation loss = 5.2264  \n",
      "\n",
      "Fold: 12  Epoch: 475  Training loss = 4.1767  Validation loss = 5.2259  \n",
      "\n",
      "Fold: 12  Epoch: 476  Training loss = 4.1764  Validation loss = 5.2256  \n",
      "\n",
      "Fold: 12  Epoch: 477  Training loss = 4.1762  Validation loss = 5.2252  \n",
      "\n",
      "Fold: 12  Epoch: 478  Training loss = 4.1759  Validation loss = 5.2248  \n",
      "\n",
      "Fold: 12  Epoch: 479  Training loss = 4.1755  Validation loss = 5.2243  \n",
      "\n",
      "Fold: 12  Epoch: 480  Training loss = 4.1753  Validation loss = 5.2239  \n",
      "\n",
      "Fold: 12  Epoch: 481  Training loss = 4.1750  Validation loss = 5.2235  \n",
      "\n",
      "Fold: 12  Epoch: 482  Training loss = 4.1748  Validation loss = 5.2232  \n",
      "\n",
      "Fold: 12  Epoch: 483  Training loss = 4.1745  Validation loss = 5.2227  \n",
      "\n",
      "Fold: 12  Epoch: 484  Training loss = 4.1742  Validation loss = 5.2223  \n",
      "\n",
      "Fold: 12  Epoch: 485  Training loss = 4.1739  Validation loss = 5.2219  \n",
      "\n",
      "Fold: 12  Epoch: 486  Training loss = 4.1737  Validation loss = 5.2215  \n",
      "\n",
      "Fold: 12  Epoch: 487  Training loss = 4.1733  Validation loss = 5.2211  \n",
      "\n",
      "Fold: 12  Epoch: 488  Training loss = 4.1731  Validation loss = 5.2207  \n",
      "\n",
      "Fold: 12  Epoch: 489  Training loss = 4.1728  Validation loss = 5.2203  \n",
      "\n",
      "Fold: 12  Epoch: 490  Training loss = 4.1725  Validation loss = 5.2198  \n",
      "\n",
      "Fold: 12  Epoch: 491  Training loss = 4.1721  Validation loss = 5.2193  \n",
      "\n",
      "Fold: 12  Epoch: 492  Training loss = 4.1718  Validation loss = 5.2189  \n",
      "\n",
      "Fold: 12  Epoch: 493  Training loss = 4.1716  Validation loss = 5.2185  \n",
      "\n",
      "Fold: 12  Epoch: 494  Training loss = 4.1712  Validation loss = 5.2180  \n",
      "\n",
      "Fold: 12  Epoch: 495  Training loss = 4.1710  Validation loss = 5.2176  \n",
      "\n",
      "Fold: 12  Epoch: 496  Training loss = 4.1707  Validation loss = 5.2173  \n",
      "\n",
      "Fold: 12  Epoch: 497  Training loss = 4.1704  Validation loss = 5.2168  \n",
      "\n",
      "Fold: 12  Epoch: 498  Training loss = 4.1701  Validation loss = 5.2164  \n",
      "\n",
      "Fold: 12  Epoch: 499  Training loss = 4.1698  Validation loss = 5.2159  \n",
      "\n",
      "Fold: 12  Epoch: 500  Training loss = 4.1696  Validation loss = 5.2156  \n",
      "\n",
      "Check model:  Fold: 12  Optimal epoch: 500  \n",
      "\n",
      "Fold: 13  Epoch: 1  Training loss = 4.3537  Validation loss = 7.6235  \n",
      "\n",
      "Fold: 13  Epoch: 2  Training loss = 4.3534  Validation loss = 7.6230  \n",
      "\n",
      "Fold: 13  Epoch: 3  Training loss = 4.3531  Validation loss = 7.6224  \n",
      "\n",
      "Fold: 13  Epoch: 4  Training loss = 4.3528  Validation loss = 7.6219  \n",
      "\n",
      "Fold: 13  Epoch: 5  Training loss = 4.3524  Validation loss = 7.6213  \n",
      "\n",
      "Fold: 13  Epoch: 6  Training loss = 4.3520  Validation loss = 7.6207  \n",
      "\n",
      "Fold: 13  Epoch: 7  Training loss = 4.3517  Validation loss = 7.6201  \n",
      "\n",
      "Fold: 13  Epoch: 8  Training loss = 4.3513  Validation loss = 7.6195  \n",
      "\n",
      "Fold: 13  Epoch: 9  Training loss = 4.3509  Validation loss = 7.6189  \n",
      "\n",
      "Fold: 13  Epoch: 10  Training loss = 4.3505  Validation loss = 7.6182  \n",
      "\n",
      "Fold: 13  Epoch: 11  Training loss = 4.3502  Validation loss = 7.6176  \n",
      "\n",
      "Fold: 13  Epoch: 12  Training loss = 4.3499  Validation loss = 7.6172  \n",
      "\n",
      "Fold: 13  Epoch: 13  Training loss = 4.3496  Validation loss = 7.6167  \n",
      "\n",
      "Fold: 13  Epoch: 14  Training loss = 4.3492  Validation loss = 7.6161  \n",
      "\n",
      "Fold: 13  Epoch: 15  Training loss = 4.3489  Validation loss = 7.6155  \n",
      "\n",
      "Fold: 13  Epoch: 16  Training loss = 4.3485  Validation loss = 7.6150  \n",
      "\n",
      "Fold: 13  Epoch: 17  Training loss = 4.3482  Validation loss = 7.6144  \n",
      "\n",
      "Fold: 13  Epoch: 18  Training loss = 4.3479  Validation loss = 7.6140  \n",
      "\n",
      "Fold: 13  Epoch: 19  Training loss = 4.3476  Validation loss = 7.6134  \n",
      "\n",
      "Fold: 13  Epoch: 20  Training loss = 4.3472  Validation loss = 7.6128  \n",
      "\n",
      "Fold: 13  Epoch: 21  Training loss = 4.3469  Validation loss = 7.6122  \n",
      "\n",
      "Fold: 13  Epoch: 22  Training loss = 4.3465  Validation loss = 7.6118  \n",
      "\n",
      "Fold: 13  Epoch: 23  Training loss = 4.3462  Validation loss = 7.6112  \n",
      "\n",
      "Fold: 13  Epoch: 24  Training loss = 4.3458  Validation loss = 7.6105  \n",
      "\n",
      "Fold: 13  Epoch: 25  Training loss = 4.3454  Validation loss = 7.6099  \n",
      "\n",
      "Fold: 13  Epoch: 26  Training loss = 4.3451  Validation loss = 7.6093  \n",
      "\n",
      "Fold: 13  Epoch: 27  Training loss = 4.3447  Validation loss = 7.6087  \n",
      "\n",
      "Fold: 13  Epoch: 28  Training loss = 4.3444  Validation loss = 7.6082  \n",
      "\n",
      "Fold: 13  Epoch: 29  Training loss = 4.3440  Validation loss = 7.6076  \n",
      "\n",
      "Fold: 13  Epoch: 30  Training loss = 4.3437  Validation loss = 7.6071  \n",
      "\n",
      "Fold: 13  Epoch: 31  Training loss = 4.3434  Validation loss = 7.6065  \n",
      "\n",
      "Fold: 13  Epoch: 32  Training loss = 4.3430  Validation loss = 7.6058  \n",
      "\n",
      "Fold: 13  Epoch: 33  Training loss = 4.3426  Validation loss = 7.6053  \n",
      "\n",
      "Fold: 13  Epoch: 34  Training loss = 4.3423  Validation loss = 7.6047  \n",
      "\n",
      "Fold: 13  Epoch: 35  Training loss = 4.3419  Validation loss = 7.6041  \n",
      "\n",
      "Fold: 13  Epoch: 36  Training loss = 4.3416  Validation loss = 7.6037  \n",
      "\n",
      "Fold: 13  Epoch: 37  Training loss = 4.3413  Validation loss = 7.6032  \n",
      "\n",
      "Fold: 13  Epoch: 38  Training loss = 4.3410  Validation loss = 7.6026  \n",
      "\n",
      "Fold: 13  Epoch: 39  Training loss = 4.3406  Validation loss = 7.6020  \n",
      "\n",
      "Fold: 13  Epoch: 40  Training loss = 4.3403  Validation loss = 7.6013  \n",
      "\n",
      "Fold: 13  Epoch: 41  Training loss = 4.3399  Validation loss = 7.6008  \n",
      "\n",
      "Fold: 13  Epoch: 42  Training loss = 4.3396  Validation loss = 7.6002  \n",
      "\n",
      "Fold: 13  Epoch: 43  Training loss = 4.3393  Validation loss = 7.5998  \n",
      "\n",
      "Fold: 13  Epoch: 44  Training loss = 4.3390  Validation loss = 7.5992  \n",
      "\n",
      "Fold: 13  Epoch: 45  Training loss = 4.3387  Validation loss = 7.5988  \n",
      "\n",
      "Fold: 13  Epoch: 46  Training loss = 4.3383  Validation loss = 7.5981  \n",
      "\n",
      "Fold: 13  Epoch: 47  Training loss = 4.3380  Validation loss = 7.5976  \n",
      "\n",
      "Fold: 13  Epoch: 48  Training loss = 4.3377  Validation loss = 7.5971  \n",
      "\n",
      "Fold: 13  Epoch: 49  Training loss = 4.3373  Validation loss = 7.5966  \n",
      "\n",
      "Fold: 13  Epoch: 50  Training loss = 4.3370  Validation loss = 7.5960  \n",
      "\n",
      "Fold: 13  Epoch: 51  Training loss = 4.3366  Validation loss = 7.5953  \n",
      "\n",
      "Fold: 13  Epoch: 52  Training loss = 4.3362  Validation loss = 7.5947  \n",
      "\n",
      "Fold: 13  Epoch: 53  Training loss = 4.3359  Validation loss = 7.5942  \n",
      "\n",
      "Fold: 13  Epoch: 54  Training loss = 4.3355  Validation loss = 7.5936  \n",
      "\n",
      "Fold: 13  Epoch: 55  Training loss = 4.3352  Validation loss = 7.5931  \n",
      "\n",
      "Fold: 13  Epoch: 56  Training loss = 4.3349  Validation loss = 7.5926  \n",
      "\n",
      "Fold: 13  Epoch: 57  Training loss = 4.3346  Validation loss = 7.5922  \n",
      "\n",
      "Fold: 13  Epoch: 58  Training loss = 4.3343  Validation loss = 7.5917  \n",
      "\n",
      "Fold: 13  Epoch: 59  Training loss = 4.3339  Validation loss = 7.5911  \n",
      "\n",
      "Fold: 13  Epoch: 60  Training loss = 4.3336  Validation loss = 7.5906  \n",
      "\n",
      "Fold: 13  Epoch: 61  Training loss = 4.3333  Validation loss = 7.5901  \n",
      "\n",
      "Fold: 13  Epoch: 62  Training loss = 4.3329  Validation loss = 7.5896  \n",
      "\n",
      "Fold: 13  Epoch: 63  Training loss = 4.3326  Validation loss = 7.5890  \n",
      "\n",
      "Fold: 13  Epoch: 64  Training loss = 4.3323  Validation loss = 7.5886  \n",
      "\n",
      "Fold: 13  Epoch: 65  Training loss = 4.3320  Validation loss = 7.5881  \n",
      "\n",
      "Fold: 13  Epoch: 66  Training loss = 4.3316  Validation loss = 7.5876  \n",
      "\n",
      "Fold: 13  Epoch: 67  Training loss = 4.3313  Validation loss = 7.5871  \n",
      "\n",
      "Fold: 13  Epoch: 68  Training loss = 4.3311  Validation loss = 7.5867  \n",
      "\n",
      "Fold: 13  Epoch: 69  Training loss = 4.3307  Validation loss = 7.5860  \n",
      "\n",
      "Fold: 13  Epoch: 70  Training loss = 4.3303  Validation loss = 7.5854  \n",
      "\n",
      "Fold: 13  Epoch: 71  Training loss = 4.3300  Validation loss = 7.5850  \n",
      "\n",
      "Fold: 13  Epoch: 72  Training loss = 4.3298  Validation loss = 7.5845  \n",
      "\n",
      "Fold: 13  Epoch: 73  Training loss = 4.3294  Validation loss = 7.5839  \n",
      "\n",
      "Fold: 13  Epoch: 74  Training loss = 4.3290  Validation loss = 7.5833  \n",
      "\n",
      "Fold: 13  Epoch: 75  Training loss = 4.3287  Validation loss = 7.5828  \n",
      "\n",
      "Fold: 13  Epoch: 76  Training loss = 4.3284  Validation loss = 7.5821  \n",
      "\n",
      "Fold: 13  Epoch: 77  Training loss = 4.3281  Validation loss = 7.5817  \n",
      "\n",
      "Fold: 13  Epoch: 78  Training loss = 4.3278  Validation loss = 7.5812  \n",
      "\n",
      "Fold: 13  Epoch: 79  Training loss = 4.3274  Validation loss = 7.5806  \n",
      "\n",
      "Fold: 13  Epoch: 80  Training loss = 4.3271  Validation loss = 7.5801  \n",
      "\n",
      "Fold: 13  Epoch: 81  Training loss = 4.3267  Validation loss = 7.5795  \n",
      "\n",
      "Fold: 13  Epoch: 82  Training loss = 4.3263  Validation loss = 7.5789  \n",
      "\n",
      "Fold: 13  Epoch: 83  Training loss = 4.3260  Validation loss = 7.5784  \n",
      "\n",
      "Fold: 13  Epoch: 84  Training loss = 4.3256  Validation loss = 7.5778  \n",
      "\n",
      "Fold: 13  Epoch: 85  Training loss = 4.3253  Validation loss = 7.5773  \n",
      "\n",
      "Fold: 13  Epoch: 86  Training loss = 4.3250  Validation loss = 7.5768  \n",
      "\n",
      "Fold: 13  Epoch: 87  Training loss = 4.3247  Validation loss = 7.5764  \n",
      "\n",
      "Fold: 13  Epoch: 88  Training loss = 4.3244  Validation loss = 7.5758  \n",
      "\n",
      "Fold: 13  Epoch: 89  Training loss = 4.3241  Validation loss = 7.5754  \n",
      "\n",
      "Fold: 13  Epoch: 90  Training loss = 4.3238  Validation loss = 7.5749  \n",
      "\n",
      "Fold: 13  Epoch: 91  Training loss = 4.3235  Validation loss = 7.5744  \n",
      "\n",
      "Fold: 13  Epoch: 92  Training loss = 4.3232  Validation loss = 7.5738  \n",
      "\n",
      "Fold: 13  Epoch: 93  Training loss = 4.3228  Validation loss = 7.5733  \n",
      "\n",
      "Fold: 13  Epoch: 94  Training loss = 4.3225  Validation loss = 7.5728  \n",
      "\n",
      "Fold: 13  Epoch: 95  Training loss = 4.3222  Validation loss = 7.5722  \n",
      "\n",
      "Fold: 13  Epoch: 96  Training loss = 4.3218  Validation loss = 7.5716  \n",
      "\n",
      "Fold: 13  Epoch: 97  Training loss = 4.3215  Validation loss = 7.5711  \n",
      "\n",
      "Fold: 13  Epoch: 98  Training loss = 4.3211  Validation loss = 7.5704  \n",
      "\n",
      "Fold: 13  Epoch: 99  Training loss = 4.3207  Validation loss = 7.5698  \n",
      "\n",
      "Fold: 13  Epoch: 100  Training loss = 4.3204  Validation loss = 7.5693  \n",
      "\n",
      "Fold: 13  Epoch: 101  Training loss = 4.3201  Validation loss = 7.5689  \n",
      "\n",
      "Fold: 13  Epoch: 102  Training loss = 4.3197  Validation loss = 7.5682  \n",
      "\n",
      "Fold: 13  Epoch: 103  Training loss = 4.3194  Validation loss = 7.5677  \n",
      "\n",
      "Fold: 13  Epoch: 104  Training loss = 4.3190  Validation loss = 7.5672  \n",
      "\n",
      "Fold: 13  Epoch: 105  Training loss = 4.3187  Validation loss = 7.5667  \n",
      "\n",
      "Fold: 13  Epoch: 106  Training loss = 4.3184  Validation loss = 7.5662  \n",
      "\n",
      "Fold: 13  Epoch: 107  Training loss = 4.3181  Validation loss = 7.5657  \n",
      "\n",
      "Fold: 13  Epoch: 108  Training loss = 4.3178  Validation loss = 7.5652  \n",
      "\n",
      "Fold: 13  Epoch: 109  Training loss = 4.3175  Validation loss = 7.5647  \n",
      "\n",
      "Fold: 13  Epoch: 110  Training loss = 4.3171  Validation loss = 7.5641  \n",
      "\n",
      "Fold: 13  Epoch: 111  Training loss = 4.3168  Validation loss = 7.5636  \n",
      "\n",
      "Fold: 13  Epoch: 112  Training loss = 4.3165  Validation loss = 7.5632  \n",
      "\n",
      "Fold: 13  Epoch: 113  Training loss = 4.3161  Validation loss = 7.5626  \n",
      "\n",
      "Fold: 13  Epoch: 114  Training loss = 4.3157  Validation loss = 7.5619  \n",
      "\n",
      "Fold: 13  Epoch: 115  Training loss = 4.3153  Validation loss = 7.5613  \n",
      "\n",
      "Fold: 13  Epoch: 116  Training loss = 4.3149  Validation loss = 7.5607  \n",
      "\n",
      "Fold: 13  Epoch: 117  Training loss = 4.3146  Validation loss = 7.5601  \n",
      "\n",
      "Fold: 13  Epoch: 118  Training loss = 4.3142  Validation loss = 7.5595  \n",
      "\n",
      "Fold: 13  Epoch: 119  Training loss = 4.3138  Validation loss = 7.5588  \n",
      "\n",
      "Fold: 13  Epoch: 120  Training loss = 4.3135  Validation loss = 7.5583  \n",
      "\n",
      "Fold: 13  Epoch: 121  Training loss = 4.3131  Validation loss = 7.5578  \n",
      "\n",
      "Fold: 13  Epoch: 122  Training loss = 4.3128  Validation loss = 7.5573  \n",
      "\n",
      "Fold: 13  Epoch: 123  Training loss = 4.3125  Validation loss = 7.5568  \n",
      "\n",
      "Fold: 13  Epoch: 124  Training loss = 4.3122  Validation loss = 7.5563  \n",
      "\n",
      "Fold: 13  Epoch: 125  Training loss = 4.3119  Validation loss = 7.5558  \n",
      "\n",
      "Fold: 13  Epoch: 126  Training loss = 4.3115  Validation loss = 7.5552  \n",
      "\n",
      "Fold: 13  Epoch: 127  Training loss = 4.3112  Validation loss = 7.5547  \n",
      "\n",
      "Fold: 13  Epoch: 128  Training loss = 4.3108  Validation loss = 7.5541  \n",
      "\n",
      "Fold: 13  Epoch: 129  Training loss = 4.3105  Validation loss = 7.5536  \n",
      "\n",
      "Fold: 13  Epoch: 130  Training loss = 4.3102  Validation loss = 7.5530  \n",
      "\n",
      "Fold: 13  Epoch: 131  Training loss = 4.3098  Validation loss = 7.5524  \n",
      "\n",
      "Fold: 13  Epoch: 132  Training loss = 4.3095  Validation loss = 7.5518  \n",
      "\n",
      "Fold: 13  Epoch: 133  Training loss = 4.3091  Validation loss = 7.5513  \n",
      "\n",
      "Fold: 13  Epoch: 134  Training loss = 4.3088  Validation loss = 7.5508  \n",
      "\n",
      "Fold: 13  Epoch: 135  Training loss = 4.3085  Validation loss = 7.5502  \n",
      "\n",
      "Fold: 13  Epoch: 136  Training loss = 4.3081  Validation loss = 7.5497  \n",
      "\n",
      "Fold: 13  Epoch: 137  Training loss = 4.3078  Validation loss = 7.5491  \n",
      "\n",
      "Fold: 13  Epoch: 138  Training loss = 4.3075  Validation loss = 7.5485  \n",
      "\n",
      "Fold: 13  Epoch: 139  Training loss = 4.3072  Validation loss = 7.5480  \n",
      "\n",
      "Fold: 13  Epoch: 140  Training loss = 4.3068  Validation loss = 7.5474  \n",
      "\n",
      "Fold: 13  Epoch: 141  Training loss = 4.3065  Validation loss = 7.5469  \n",
      "\n",
      "Fold: 13  Epoch: 142  Training loss = 4.3061  Validation loss = 7.5463  \n",
      "\n",
      "Fold: 13  Epoch: 143  Training loss = 4.3058  Validation loss = 7.5458  \n",
      "\n",
      "Fold: 13  Epoch: 144  Training loss = 4.3055  Validation loss = 7.5453  \n",
      "\n",
      "Fold: 13  Epoch: 145  Training loss = 4.3052  Validation loss = 7.5448  \n",
      "\n",
      "Fold: 13  Epoch: 146  Training loss = 4.3049  Validation loss = 7.5444  \n",
      "\n",
      "Fold: 13  Epoch: 147  Training loss = 4.3046  Validation loss = 7.5438  \n",
      "\n",
      "Fold: 13  Epoch: 148  Training loss = 4.3042  Validation loss = 7.5433  \n",
      "\n",
      "Fold: 13  Epoch: 149  Training loss = 4.3040  Validation loss = 7.5428  \n",
      "\n",
      "Fold: 13  Epoch: 150  Training loss = 4.3036  Validation loss = 7.5422  \n",
      "\n",
      "Fold: 13  Epoch: 151  Training loss = 4.3033  Validation loss = 7.5418  \n",
      "\n",
      "Fold: 13  Epoch: 152  Training loss = 4.3029  Validation loss = 7.5411  \n",
      "\n",
      "Fold: 13  Epoch: 153  Training loss = 4.3026  Validation loss = 7.5405  \n",
      "\n",
      "Fold: 13  Epoch: 154  Training loss = 4.3022  Validation loss = 7.5399  \n",
      "\n",
      "Fold: 13  Epoch: 155  Training loss = 4.3018  Validation loss = 7.5393  \n",
      "\n",
      "Fold: 13  Epoch: 156  Training loss = 4.3014  Validation loss = 7.5387  \n",
      "\n",
      "Fold: 13  Epoch: 157  Training loss = 4.3012  Validation loss = 7.5383  \n",
      "\n",
      "Fold: 13  Epoch: 158  Training loss = 4.3009  Validation loss = 7.5377  \n",
      "\n",
      "Fold: 13  Epoch: 159  Training loss = 4.3005  Validation loss = 7.5371  \n",
      "\n",
      "Fold: 13  Epoch: 160  Training loss = 4.3001  Validation loss = 7.5365  \n",
      "\n",
      "Fold: 13  Epoch: 161  Training loss = 4.2998  Validation loss = 7.5360  \n",
      "\n",
      "Fold: 13  Epoch: 162  Training loss = 4.2995  Validation loss = 7.5354  \n",
      "\n",
      "Fold: 13  Epoch: 163  Training loss = 4.2992  Validation loss = 7.5349  \n",
      "\n",
      "Fold: 13  Epoch: 164  Training loss = 4.2989  Validation loss = 7.5345  \n",
      "\n",
      "Fold: 13  Epoch: 165  Training loss = 4.2985  Validation loss = 7.5339  \n",
      "\n",
      "Fold: 13  Epoch: 166  Training loss = 4.2982  Validation loss = 7.5333  \n",
      "\n",
      "Fold: 13  Epoch: 167  Training loss = 4.2978  Validation loss = 7.5326  \n",
      "\n",
      "Fold: 13  Epoch: 168  Training loss = 4.2975  Validation loss = 7.5320  \n",
      "\n",
      "Fold: 13  Epoch: 169  Training loss = 4.2972  Validation loss = 7.5315  \n",
      "\n",
      "Fold: 13  Epoch: 170  Training loss = 4.2968  Validation loss = 7.5308  \n",
      "\n",
      "Fold: 13  Epoch: 171  Training loss = 4.2965  Validation loss = 7.5302  \n",
      "\n",
      "Fold: 13  Epoch: 172  Training loss = 4.2961  Validation loss = 7.5297  \n",
      "\n",
      "Fold: 13  Epoch: 173  Training loss = 4.2958  Validation loss = 7.5291  \n",
      "\n",
      "Fold: 13  Epoch: 174  Training loss = 4.2954  Validation loss = 7.5286  \n",
      "\n",
      "Fold: 13  Epoch: 175  Training loss = 4.2950  Validation loss = 7.5279  \n",
      "\n",
      "Fold: 13  Epoch: 176  Training loss = 4.2947  Validation loss = 7.5275  \n",
      "\n",
      "Fold: 13  Epoch: 177  Training loss = 4.2944  Validation loss = 7.5269  \n",
      "\n",
      "Fold: 13  Epoch: 178  Training loss = 4.2940  Validation loss = 7.5263  \n",
      "\n",
      "Fold: 13  Epoch: 179  Training loss = 4.2937  Validation loss = 7.5258  \n",
      "\n",
      "Fold: 13  Epoch: 180  Training loss = 4.2933  Validation loss = 7.5252  \n",
      "\n",
      "Fold: 13  Epoch: 181  Training loss = 4.2930  Validation loss = 7.5247  \n",
      "\n",
      "Fold: 13  Epoch: 182  Training loss = 4.2927  Validation loss = 7.5242  \n",
      "\n",
      "Fold: 13  Epoch: 183  Training loss = 4.2923  Validation loss = 7.5236  \n",
      "\n",
      "Fold: 13  Epoch: 184  Training loss = 4.2920  Validation loss = 7.5232  \n",
      "\n",
      "Fold: 13  Epoch: 185  Training loss = 4.2916  Validation loss = 7.5224  \n",
      "\n",
      "Fold: 13  Epoch: 186  Training loss = 4.2913  Validation loss = 7.5220  \n",
      "\n",
      "Fold: 13  Epoch: 187  Training loss = 4.2909  Validation loss = 7.5214  \n",
      "\n",
      "Fold: 13  Epoch: 188  Training loss = 4.2905  Validation loss = 7.5207  \n",
      "\n",
      "Fold: 13  Epoch: 189  Training loss = 4.2902  Validation loss = 7.5201  \n",
      "\n",
      "Fold: 13  Epoch: 190  Training loss = 4.2899  Validation loss = 7.5195  \n",
      "\n",
      "Fold: 13  Epoch: 191  Training loss = 4.2896  Validation loss = 7.5190  \n",
      "\n",
      "Fold: 13  Epoch: 192  Training loss = 4.2893  Validation loss = 7.5186  \n",
      "\n",
      "Fold: 13  Epoch: 193  Training loss = 4.2889  Validation loss = 7.5179  \n",
      "\n",
      "Fold: 13  Epoch: 194  Training loss = 4.2886  Validation loss = 7.5174  \n",
      "\n",
      "Fold: 13  Epoch: 195  Training loss = 4.2883  Validation loss = 7.5167  \n",
      "\n",
      "Fold: 13  Epoch: 196  Training loss = 4.2879  Validation loss = 7.5162  \n",
      "\n",
      "Fold: 13  Epoch: 197  Training loss = 4.2876  Validation loss = 7.5156  \n",
      "\n",
      "Fold: 13  Epoch: 198  Training loss = 4.2872  Validation loss = 7.5150  \n",
      "\n",
      "Fold: 13  Epoch: 199  Training loss = 4.2869  Validation loss = 7.5145  \n",
      "\n",
      "Fold: 13  Epoch: 200  Training loss = 4.2865  Validation loss = 7.5139  \n",
      "\n",
      "Fold: 13  Epoch: 201  Training loss = 4.2862  Validation loss = 7.5134  \n",
      "\n",
      "Fold: 13  Epoch: 202  Training loss = 4.2859  Validation loss = 7.5128  \n",
      "\n",
      "Fold: 13  Epoch: 203  Training loss = 4.2855  Validation loss = 7.5122  \n",
      "\n",
      "Fold: 13  Epoch: 204  Training loss = 4.2853  Validation loss = 7.5117  \n",
      "\n",
      "Fold: 13  Epoch: 205  Training loss = 4.2849  Validation loss = 7.5111  \n",
      "\n",
      "Fold: 13  Epoch: 206  Training loss = 4.2846  Validation loss = 7.5106  \n",
      "\n",
      "Fold: 13  Epoch: 207  Training loss = 4.2843  Validation loss = 7.5101  \n",
      "\n",
      "Fold: 13  Epoch: 208  Training loss = 4.2840  Validation loss = 7.5096  \n",
      "\n",
      "Fold: 13  Epoch: 209  Training loss = 4.2836  Validation loss = 7.5091  \n",
      "\n",
      "Fold: 13  Epoch: 210  Training loss = 4.2833  Validation loss = 7.5085  \n",
      "\n",
      "Fold: 13  Epoch: 211  Training loss = 4.2830  Validation loss = 7.5080  \n",
      "\n",
      "Fold: 13  Epoch: 212  Training loss = 4.2827  Validation loss = 7.5076  \n",
      "\n",
      "Fold: 13  Epoch: 213  Training loss = 4.2824  Validation loss = 7.5070  \n",
      "\n",
      "Fold: 13  Epoch: 214  Training loss = 4.2820  Validation loss = 7.5064  \n",
      "\n",
      "Fold: 13  Epoch: 215  Training loss = 4.2817  Validation loss = 7.5058  \n",
      "\n",
      "Fold: 13  Epoch: 216  Training loss = 4.2813  Validation loss = 7.5052  \n",
      "\n",
      "Fold: 13  Epoch: 217  Training loss = 4.2810  Validation loss = 7.5047  \n",
      "\n",
      "Fold: 13  Epoch: 218  Training loss = 4.2807  Validation loss = 7.5044  \n",
      "\n",
      "Fold: 13  Epoch: 219  Training loss = 4.2804  Validation loss = 7.5038  \n",
      "\n",
      "Fold: 13  Epoch: 220  Training loss = 4.2801  Validation loss = 7.5034  \n",
      "\n",
      "Fold: 13  Epoch: 221  Training loss = 4.2798  Validation loss = 7.5028  \n",
      "\n",
      "Fold: 13  Epoch: 222  Training loss = 4.2794  Validation loss = 7.5022  \n",
      "\n",
      "Fold: 13  Epoch: 223  Training loss = 4.2791  Validation loss = 7.5018  \n",
      "\n",
      "Fold: 13  Epoch: 224  Training loss = 4.2789  Validation loss = 7.5013  \n",
      "\n",
      "Fold: 13  Epoch: 225  Training loss = 4.2785  Validation loss = 7.5008  \n",
      "\n",
      "Fold: 13  Epoch: 226  Training loss = 4.2782  Validation loss = 7.5002  \n",
      "\n",
      "Fold: 13  Epoch: 227  Training loss = 4.2778  Validation loss = 7.4996  \n",
      "\n",
      "Fold: 13  Epoch: 228  Training loss = 4.2774  Validation loss = 7.4990  \n",
      "\n",
      "Fold: 13  Epoch: 229  Training loss = 4.2771  Validation loss = 7.4985  \n",
      "\n",
      "Fold: 13  Epoch: 230  Training loss = 4.2767  Validation loss = 7.4979  \n",
      "\n",
      "Fold: 13  Epoch: 231  Training loss = 4.2764  Validation loss = 7.4973  \n",
      "\n",
      "Fold: 13  Epoch: 232  Training loss = 4.2760  Validation loss = 7.4968  \n",
      "\n",
      "Fold: 13  Epoch: 233  Training loss = 4.2758  Validation loss = 7.4964  \n",
      "\n",
      "Fold: 13  Epoch: 234  Training loss = 4.2754  Validation loss = 7.4959  \n",
      "\n",
      "Fold: 13  Epoch: 235  Training loss = 4.2751  Validation loss = 7.4953  \n",
      "\n",
      "Fold: 13  Epoch: 236  Training loss = 4.2747  Validation loss = 7.4947  \n",
      "\n",
      "Fold: 13  Epoch: 237  Training loss = 4.2744  Validation loss = 7.4941  \n",
      "\n",
      "Fold: 13  Epoch: 238  Training loss = 4.2741  Validation loss = 7.4934  \n",
      "\n",
      "Fold: 13  Epoch: 239  Training loss = 4.2738  Validation loss = 7.4930  \n",
      "\n",
      "Fold: 13  Epoch: 240  Training loss = 4.2735  Validation loss = 7.4925  \n",
      "\n",
      "Fold: 13  Epoch: 241  Training loss = 4.2732  Validation loss = 7.4920  \n",
      "\n",
      "Fold: 13  Epoch: 242  Training loss = 4.2728  Validation loss = 7.4914  \n",
      "\n",
      "Fold: 13  Epoch: 243  Training loss = 4.2725  Validation loss = 7.4909  \n",
      "\n",
      "Fold: 13  Epoch: 244  Training loss = 4.2722  Validation loss = 7.4904  \n",
      "\n",
      "Fold: 13  Epoch: 245  Training loss = 4.2719  Validation loss = 7.4899  \n",
      "\n",
      "Fold: 13  Epoch: 246  Training loss = 4.2716  Validation loss = 7.4893  \n",
      "\n",
      "Fold: 13  Epoch: 247  Training loss = 4.2713  Validation loss = 7.4888  \n",
      "\n",
      "Fold: 13  Epoch: 248  Training loss = 4.2710  Validation loss = 7.4883  \n",
      "\n",
      "Fold: 13  Epoch: 249  Training loss = 4.2706  Validation loss = 7.4877  \n",
      "\n",
      "Fold: 13  Epoch: 250  Training loss = 4.2703  Validation loss = 7.4871  \n",
      "\n",
      "Fold: 13  Epoch: 251  Training loss = 4.2699  Validation loss = 7.4864  \n",
      "\n",
      "Fold: 13  Epoch: 252  Training loss = 4.2695  Validation loss = 7.4858  \n",
      "\n",
      "Fold: 13  Epoch: 253  Training loss = 4.2692  Validation loss = 7.4853  \n",
      "\n",
      "Fold: 13  Epoch: 254  Training loss = 4.2689  Validation loss = 7.4847  \n",
      "\n",
      "Fold: 13  Epoch: 255  Training loss = 4.2685  Validation loss = 7.4841  \n",
      "\n",
      "Fold: 13  Epoch: 256  Training loss = 4.2682  Validation loss = 7.4834  \n",
      "\n",
      "Fold: 13  Epoch: 257  Training loss = 4.2679  Validation loss = 7.4830  \n",
      "\n",
      "Fold: 13  Epoch: 258  Training loss = 4.2675  Validation loss = 7.4823  \n",
      "\n",
      "Fold: 13  Epoch: 259  Training loss = 4.2672  Validation loss = 7.4818  \n",
      "\n",
      "Fold: 13  Epoch: 260  Training loss = 4.2668  Validation loss = 7.4812  \n",
      "\n",
      "Fold: 13  Epoch: 261  Training loss = 4.2664  Validation loss = 7.4806  \n",
      "\n",
      "Fold: 13  Epoch: 262  Training loss = 4.2661  Validation loss = 7.4801  \n",
      "\n",
      "Fold: 13  Epoch: 263  Training loss = 4.2658  Validation loss = 7.4796  \n",
      "\n",
      "Fold: 13  Epoch: 264  Training loss = 4.2654  Validation loss = 7.4790  \n",
      "\n",
      "Fold: 13  Epoch: 265  Training loss = 4.2651  Validation loss = 7.4784  \n",
      "\n",
      "Fold: 13  Epoch: 266  Training loss = 4.2648  Validation loss = 7.4779  \n",
      "\n",
      "Fold: 13  Epoch: 267  Training loss = 4.2644  Validation loss = 7.4774  \n",
      "\n",
      "Fold: 13  Epoch: 268  Training loss = 4.2642  Validation loss = 7.4769  \n",
      "\n",
      "Fold: 13  Epoch: 269  Training loss = 4.2639  Validation loss = 7.4764  \n",
      "\n",
      "Fold: 13  Epoch: 270  Training loss = 4.2636  Validation loss = 7.4760  \n",
      "\n",
      "Fold: 13  Epoch: 271  Training loss = 4.2632  Validation loss = 7.4754  \n",
      "\n",
      "Fold: 13  Epoch: 272  Training loss = 4.2629  Validation loss = 7.4748  \n",
      "\n",
      "Fold: 13  Epoch: 273  Training loss = 4.2625  Validation loss = 7.4742  \n",
      "\n",
      "Fold: 13  Epoch: 274  Training loss = 4.2622  Validation loss = 7.4736  \n",
      "\n",
      "Fold: 13  Epoch: 275  Training loss = 4.2618  Validation loss = 7.4730  \n",
      "\n",
      "Fold: 13  Epoch: 276  Training loss = 4.2615  Validation loss = 7.4725  \n",
      "\n",
      "Fold: 13  Epoch: 277  Training loss = 4.2612  Validation loss = 7.4720  \n",
      "\n",
      "Fold: 13  Epoch: 278  Training loss = 4.2608  Validation loss = 7.4715  \n",
      "\n",
      "Fold: 13  Epoch: 279  Training loss = 4.2605  Validation loss = 7.4710  \n",
      "\n",
      "Fold: 13  Epoch: 280  Training loss = 4.2602  Validation loss = 7.4703  \n",
      "\n",
      "Fold: 13  Epoch: 281  Training loss = 4.2599  Validation loss = 7.4699  \n",
      "\n",
      "Fold: 13  Epoch: 282  Training loss = 4.2596  Validation loss = 7.4694  \n",
      "\n",
      "Fold: 13  Epoch: 283  Training loss = 4.2593  Validation loss = 7.4689  \n",
      "\n",
      "Fold: 13  Epoch: 284  Training loss = 4.2589  Validation loss = 7.4684  \n",
      "\n",
      "Fold: 13  Epoch: 285  Training loss = 4.2586  Validation loss = 7.4678  \n",
      "\n",
      "Fold: 13  Epoch: 286  Training loss = 4.2582  Validation loss = 7.4672  \n",
      "\n",
      "Fold: 13  Epoch: 287  Training loss = 4.2579  Validation loss = 7.4667  \n",
      "\n",
      "Fold: 13  Epoch: 288  Training loss = 4.2576  Validation loss = 7.4662  \n",
      "\n",
      "Fold: 13  Epoch: 289  Training loss = 4.2572  Validation loss = 7.4655  \n",
      "\n",
      "Fold: 13  Epoch: 290  Training loss = 4.2569  Validation loss = 7.4648  \n",
      "\n",
      "Fold: 13  Epoch: 291  Training loss = 4.2565  Validation loss = 7.4643  \n",
      "\n",
      "Fold: 13  Epoch: 292  Training loss = 4.2562  Validation loss = 7.4637  \n",
      "\n",
      "Fold: 13  Epoch: 293  Training loss = 4.2559  Validation loss = 7.4633  \n",
      "\n",
      "Fold: 13  Epoch: 294  Training loss = 4.2555  Validation loss = 7.4627  \n",
      "\n",
      "Fold: 13  Epoch: 295  Training loss = 4.2551  Validation loss = 7.4621  \n",
      "\n",
      "Fold: 13  Epoch: 296  Training loss = 4.2548  Validation loss = 7.4615  \n",
      "\n",
      "Fold: 13  Epoch: 297  Training loss = 4.2544  Validation loss = 7.4608  \n",
      "\n",
      "Fold: 13  Epoch: 298  Training loss = 4.2540  Validation loss = 7.4602  \n",
      "\n",
      "Fold: 13  Epoch: 299  Training loss = 4.2537  Validation loss = 7.4597  \n",
      "\n",
      "Fold: 13  Epoch: 300  Training loss = 4.2534  Validation loss = 7.4591  \n",
      "\n",
      "Fold: 13  Epoch: 301  Training loss = 4.2531  Validation loss = 7.4586  \n",
      "\n",
      "Fold: 13  Epoch: 302  Training loss = 4.2528  Validation loss = 7.4580  \n",
      "\n",
      "Fold: 13  Epoch: 303  Training loss = 4.2525  Validation loss = 7.4574  \n",
      "\n",
      "Fold: 13  Epoch: 304  Training loss = 4.2521  Validation loss = 7.4568  \n",
      "\n",
      "Fold: 13  Epoch: 305  Training loss = 4.2518  Validation loss = 7.4563  \n",
      "\n",
      "Fold: 13  Epoch: 306  Training loss = 4.2515  Validation loss = 7.4557  \n",
      "\n",
      "Fold: 13  Epoch: 307  Training loss = 4.2512  Validation loss = 7.4552  \n",
      "\n",
      "Fold: 13  Epoch: 308  Training loss = 4.2508  Validation loss = 7.4546  \n",
      "\n",
      "Fold: 13  Epoch: 309  Training loss = 4.2505  Validation loss = 7.4541  \n",
      "\n",
      "Fold: 13  Epoch: 310  Training loss = 4.2502  Validation loss = 7.4536  \n",
      "\n",
      "Fold: 13  Epoch: 311  Training loss = 4.2499  Validation loss = 7.4530  \n",
      "\n",
      "Fold: 13  Epoch: 312  Training loss = 4.2496  Validation loss = 7.4525  \n",
      "\n",
      "Fold: 13  Epoch: 313  Training loss = 4.2492  Validation loss = 7.4520  \n",
      "\n",
      "Fold: 13  Epoch: 314  Training loss = 4.2489  Validation loss = 7.4514  \n",
      "\n",
      "Fold: 13  Epoch: 315  Training loss = 4.2485  Validation loss = 7.4508  \n",
      "\n",
      "Fold: 13  Epoch: 316  Training loss = 4.2482  Validation loss = 7.4503  \n",
      "\n",
      "Fold: 13  Epoch: 317  Training loss = 4.2479  Validation loss = 7.4497  \n",
      "\n",
      "Fold: 13  Epoch: 318  Training loss = 4.2476  Validation loss = 7.4492  \n",
      "\n",
      "Fold: 13  Epoch: 319  Training loss = 4.2473  Validation loss = 7.4487  \n",
      "\n",
      "Fold: 13  Epoch: 320  Training loss = 4.2469  Validation loss = 7.4481  \n",
      "\n",
      "Fold: 13  Epoch: 321  Training loss = 4.2466  Validation loss = 7.4476  \n",
      "\n",
      "Fold: 13  Epoch: 322  Training loss = 4.2463  Validation loss = 7.4471  \n",
      "\n",
      "Fold: 13  Epoch: 323  Training loss = 4.2460  Validation loss = 7.4465  \n",
      "\n",
      "Fold: 13  Epoch: 324  Training loss = 4.2456  Validation loss = 7.4459  \n",
      "\n",
      "Fold: 13  Epoch: 325  Training loss = 4.2453  Validation loss = 7.4454  \n",
      "\n",
      "Fold: 13  Epoch: 326  Training loss = 4.2449  Validation loss = 7.4448  \n",
      "\n",
      "Fold: 13  Epoch: 327  Training loss = 4.2447  Validation loss = 7.4443  \n",
      "\n",
      "Fold: 13  Epoch: 328  Training loss = 4.2443  Validation loss = 7.4438  \n",
      "\n",
      "Fold: 13  Epoch: 329  Training loss = 4.2440  Validation loss = 7.4433  \n",
      "\n",
      "Fold: 13  Epoch: 330  Training loss = 4.2437  Validation loss = 7.4427  \n",
      "\n",
      "Fold: 13  Epoch: 331  Training loss = 4.2433  Validation loss = 7.4421  \n",
      "\n",
      "Fold: 13  Epoch: 332  Training loss = 4.2430  Validation loss = 7.4415  \n",
      "\n",
      "Fold: 13  Epoch: 333  Training loss = 4.2427  Validation loss = 7.4410  \n",
      "\n",
      "Fold: 13  Epoch: 334  Training loss = 4.2424  Validation loss = 7.4405  \n",
      "\n",
      "Fold: 13  Epoch: 335  Training loss = 4.2420  Validation loss = 7.4399  \n",
      "\n",
      "Fold: 13  Epoch: 336  Training loss = 4.2417  Validation loss = 7.4393  \n",
      "\n",
      "Fold: 13  Epoch: 337  Training loss = 4.2413  Validation loss = 7.4387  \n",
      "\n",
      "Fold: 13  Epoch: 338  Training loss = 4.2410  Validation loss = 7.4381  \n",
      "\n",
      "Fold: 13  Epoch: 339  Training loss = 4.2406  Validation loss = 7.4375  \n",
      "\n",
      "Fold: 13  Epoch: 340  Training loss = 4.2403  Validation loss = 7.4370  \n",
      "\n",
      "Fold: 13  Epoch: 341  Training loss = 4.2399  Validation loss = 7.4364  \n",
      "\n",
      "Fold: 13  Epoch: 342  Training loss = 4.2396  Validation loss = 7.4359  \n",
      "\n",
      "Fold: 13  Epoch: 343  Training loss = 4.2393  Validation loss = 7.4353  \n",
      "\n",
      "Fold: 13  Epoch: 344  Training loss = 4.2389  Validation loss = 7.4346  \n",
      "\n",
      "Fold: 13  Epoch: 345  Training loss = 4.2386  Validation loss = 7.4339  \n",
      "\n",
      "Fold: 13  Epoch: 346  Training loss = 4.2382  Validation loss = 7.4333  \n",
      "\n",
      "Fold: 13  Epoch: 347  Training loss = 4.2379  Validation loss = 7.4329  \n",
      "\n",
      "Fold: 13  Epoch: 348  Training loss = 4.2376  Validation loss = 7.4324  \n",
      "\n",
      "Fold: 13  Epoch: 349  Training loss = 4.2373  Validation loss = 7.4319  \n",
      "\n",
      "Fold: 13  Epoch: 350  Training loss = 4.2370  Validation loss = 7.4313  \n",
      "\n",
      "Fold: 13  Epoch: 351  Training loss = 4.2366  Validation loss = 7.4308  \n",
      "\n",
      "Fold: 13  Epoch: 352  Training loss = 4.2363  Validation loss = 7.4303  \n",
      "\n",
      "Fold: 13  Epoch: 353  Training loss = 4.2360  Validation loss = 7.4298  \n",
      "\n",
      "Fold: 13  Epoch: 354  Training loss = 4.2357  Validation loss = 7.4293  \n",
      "\n",
      "Fold: 13  Epoch: 355  Training loss = 4.2354  Validation loss = 7.4286  \n",
      "\n",
      "Fold: 13  Epoch: 356  Training loss = 4.2351  Validation loss = 7.4281  \n",
      "\n",
      "Fold: 13  Epoch: 357  Training loss = 4.2348  Validation loss = 7.4276  \n",
      "\n",
      "Fold: 13  Epoch: 358  Training loss = 4.2346  Validation loss = 7.4272  \n",
      "\n",
      "Fold: 13  Epoch: 359  Training loss = 4.2342  Validation loss = 7.4266  \n",
      "\n",
      "Fold: 13  Epoch: 360  Training loss = 4.2340  Validation loss = 7.4262  \n",
      "\n",
      "Fold: 13  Epoch: 361  Training loss = 4.2337  Validation loss = 7.4257  \n",
      "\n",
      "Fold: 13  Epoch: 362  Training loss = 4.2333  Validation loss = 7.4251  \n",
      "\n",
      "Fold: 13  Epoch: 363  Training loss = 4.2330  Validation loss = 7.4246  \n",
      "\n",
      "Fold: 13  Epoch: 364  Training loss = 4.2327  Validation loss = 7.4240  \n",
      "\n",
      "Fold: 13  Epoch: 365  Training loss = 4.2324  Validation loss = 7.4235  \n",
      "\n",
      "Fold: 13  Epoch: 366  Training loss = 4.2320  Validation loss = 7.4229  \n",
      "\n",
      "Fold: 13  Epoch: 367  Training loss = 4.2318  Validation loss = 7.4224  \n",
      "\n",
      "Fold: 13  Epoch: 368  Training loss = 4.2314  Validation loss = 7.4218  \n",
      "\n",
      "Fold: 13  Epoch: 369  Training loss = 4.2311  Validation loss = 7.4213  \n",
      "\n",
      "Fold: 13  Epoch: 370  Training loss = 4.2307  Validation loss = 7.4208  \n",
      "\n",
      "Fold: 13  Epoch: 371  Training loss = 4.2304  Validation loss = 7.4203  \n",
      "\n",
      "Fold: 13  Epoch: 372  Training loss = 4.2301  Validation loss = 7.4197  \n",
      "\n",
      "Fold: 13  Epoch: 373  Training loss = 4.2297  Validation loss = 7.4190  \n",
      "\n",
      "Fold: 13  Epoch: 374  Training loss = 4.2294  Validation loss = 7.4184  \n",
      "\n",
      "Fold: 13  Epoch: 375  Training loss = 4.2290  Validation loss = 7.4178  \n",
      "\n",
      "Fold: 13  Epoch: 376  Training loss = 4.2287  Validation loss = 7.4172  \n",
      "\n",
      "Fold: 13  Epoch: 377  Training loss = 4.2284  Validation loss = 7.4166  \n",
      "\n",
      "Fold: 13  Epoch: 378  Training loss = 4.2280  Validation loss = 7.4160  \n",
      "\n",
      "Fold: 13  Epoch: 379  Training loss = 4.2277  Validation loss = 7.4154  \n",
      "\n",
      "Fold: 13  Epoch: 380  Training loss = 4.2273  Validation loss = 7.4148  \n",
      "\n",
      "Fold: 13  Epoch: 381  Training loss = 4.2270  Validation loss = 7.4143  \n",
      "\n",
      "Fold: 13  Epoch: 382  Training loss = 4.2266  Validation loss = 7.4137  \n",
      "\n",
      "Fold: 13  Epoch: 383  Training loss = 4.2263  Validation loss = 7.4132  \n",
      "\n",
      "Fold: 13  Epoch: 384  Training loss = 4.2260  Validation loss = 7.4128  \n",
      "\n",
      "Fold: 13  Epoch: 385  Training loss = 4.2257  Validation loss = 7.4123  \n",
      "\n",
      "Fold: 13  Epoch: 386  Training loss = 4.2253  Validation loss = 7.4115  \n",
      "\n",
      "Fold: 13  Epoch: 387  Training loss = 4.2249  Validation loss = 7.4109  \n",
      "\n",
      "Fold: 13  Epoch: 388  Training loss = 4.2246  Validation loss = 7.4103  \n",
      "\n",
      "Fold: 13  Epoch: 389  Training loss = 4.2242  Validation loss = 7.4098  \n",
      "\n",
      "Fold: 13  Epoch: 390  Training loss = 4.2239  Validation loss = 7.4092  \n",
      "\n",
      "Fold: 13  Epoch: 391  Training loss = 4.2236  Validation loss = 7.4086  \n",
      "\n",
      "Fold: 13  Epoch: 392  Training loss = 4.2232  Validation loss = 7.4081  \n",
      "\n",
      "Fold: 13  Epoch: 393  Training loss = 4.2228  Validation loss = 7.4074  \n",
      "\n",
      "Fold: 13  Epoch: 394  Training loss = 4.2225  Validation loss = 7.4070  \n",
      "\n",
      "Fold: 13  Epoch: 395  Training loss = 4.2222  Validation loss = 7.4065  \n",
      "\n",
      "Fold: 13  Epoch: 396  Training loss = 4.2218  Validation loss = 7.4057  \n",
      "\n",
      "Fold: 13  Epoch: 397  Training loss = 4.2216  Validation loss = 7.4052  \n",
      "\n",
      "Fold: 13  Epoch: 398  Training loss = 4.2212  Validation loss = 7.4045  \n",
      "\n",
      "Fold: 13  Epoch: 399  Training loss = 4.2208  Validation loss = 7.4040  \n",
      "\n",
      "Fold: 13  Epoch: 400  Training loss = 4.2205  Validation loss = 7.4035  \n",
      "\n",
      "Fold: 13  Epoch: 401  Training loss = 4.2202  Validation loss = 7.4030  \n",
      "\n",
      "Fold: 13  Epoch: 402  Training loss = 4.2199  Validation loss = 7.4025  \n",
      "\n",
      "Fold: 13  Epoch: 403  Training loss = 4.2196  Validation loss = 7.4020  \n",
      "\n",
      "Fold: 13  Epoch: 404  Training loss = 4.2192  Validation loss = 7.4014  \n",
      "\n",
      "Fold: 13  Epoch: 405  Training loss = 4.2189  Validation loss = 7.4009  \n",
      "\n",
      "Fold: 13  Epoch: 406  Training loss = 4.2185  Validation loss = 7.4002  \n",
      "\n",
      "Fold: 13  Epoch: 407  Training loss = 4.2182  Validation loss = 7.3997  \n",
      "\n",
      "Fold: 13  Epoch: 408  Training loss = 4.2179  Validation loss = 7.3992  \n",
      "\n",
      "Fold: 13  Epoch: 409  Training loss = 4.2175  Validation loss = 7.3984  \n",
      "\n",
      "Fold: 13  Epoch: 410  Training loss = 4.2172  Validation loss = 7.3979  \n",
      "\n",
      "Fold: 13  Epoch: 411  Training loss = 4.2168  Validation loss = 7.3972  \n",
      "\n",
      "Fold: 13  Epoch: 412  Training loss = 4.2164  Validation loss = 7.3966  \n",
      "\n",
      "Fold: 13  Epoch: 413  Training loss = 4.2161  Validation loss = 7.3961  \n",
      "\n",
      "Fold: 13  Epoch: 414  Training loss = 4.2157  Validation loss = 7.3954  \n",
      "\n",
      "Fold: 13  Epoch: 415  Training loss = 4.2154  Validation loss = 7.3949  \n",
      "\n",
      "Fold: 13  Epoch: 416  Training loss = 4.2151  Validation loss = 7.3945  \n",
      "\n",
      "Fold: 13  Epoch: 417  Training loss = 4.2148  Validation loss = 7.3940  \n",
      "\n",
      "Fold: 13  Epoch: 418  Training loss = 4.2146  Validation loss = 7.3936  \n",
      "\n",
      "Fold: 13  Epoch: 419  Training loss = 4.2142  Validation loss = 7.3930  \n",
      "\n",
      "Fold: 13  Epoch: 420  Training loss = 4.2138  Validation loss = 7.3924  \n",
      "\n",
      "Fold: 13  Epoch: 421  Training loss = 4.2135  Validation loss = 7.3919  \n",
      "\n",
      "Fold: 13  Epoch: 422  Training loss = 4.2132  Validation loss = 7.3915  \n",
      "\n",
      "Fold: 13  Epoch: 423  Training loss = 4.2129  Validation loss = 7.3910  \n",
      "\n",
      "Fold: 13  Epoch: 424  Training loss = 4.2125  Validation loss = 7.3903  \n",
      "\n",
      "Fold: 13  Epoch: 425  Training loss = 4.2122  Validation loss = 7.3899  \n",
      "\n",
      "Fold: 13  Epoch: 426  Training loss = 4.2119  Validation loss = 7.3893  \n",
      "\n",
      "Fold: 13  Epoch: 427  Training loss = 4.2116  Validation loss = 7.3887  \n",
      "\n",
      "Fold: 13  Epoch: 428  Training loss = 4.2113  Validation loss = 7.3883  \n",
      "\n",
      "Fold: 13  Epoch: 429  Training loss = 4.2110  Validation loss = 7.3878  \n",
      "\n",
      "Fold: 13  Epoch: 430  Training loss = 4.2107  Validation loss = 7.3872  \n",
      "\n",
      "Fold: 13  Epoch: 431  Training loss = 4.2104  Validation loss = 7.3868  \n",
      "\n",
      "Fold: 13  Epoch: 432  Training loss = 4.2101  Validation loss = 7.3862  \n",
      "\n",
      "Fold: 13  Epoch: 433  Training loss = 4.2097  Validation loss = 7.3856  \n",
      "\n",
      "Fold: 13  Epoch: 434  Training loss = 4.2094  Validation loss = 7.3851  \n",
      "\n",
      "Fold: 13  Epoch: 435  Training loss = 4.2091  Validation loss = 7.3846  \n",
      "\n",
      "Fold: 13  Epoch: 436  Training loss = 4.2088  Validation loss = 7.3841  \n",
      "\n",
      "Fold: 13  Epoch: 437  Training loss = 4.2085  Validation loss = 7.3836  \n",
      "\n",
      "Fold: 13  Epoch: 438  Training loss = 4.2082  Validation loss = 7.3831  \n",
      "\n",
      "Fold: 13  Epoch: 439  Training loss = 4.2079  Validation loss = 7.3827  \n",
      "\n",
      "Fold: 13  Epoch: 440  Training loss = 4.2077  Validation loss = 7.3823  \n",
      "\n",
      "Fold: 13  Epoch: 441  Training loss = 4.2074  Validation loss = 7.3818  \n",
      "\n",
      "Fold: 13  Epoch: 442  Training loss = 4.2071  Validation loss = 7.3813  \n",
      "\n",
      "Fold: 13  Epoch: 443  Training loss = 4.2068  Validation loss = 7.3808  \n",
      "\n",
      "Fold: 13  Epoch: 444  Training loss = 4.2065  Validation loss = 7.3803  \n",
      "\n",
      "Fold: 13  Epoch: 445  Training loss = 4.2061  Validation loss = 7.3797  \n",
      "\n",
      "Fold: 13  Epoch: 446  Training loss = 4.2058  Validation loss = 7.3792  \n",
      "\n",
      "Fold: 13  Epoch: 447  Training loss = 4.2054  Validation loss = 7.3786  \n",
      "\n",
      "Fold: 13  Epoch: 448  Training loss = 4.2051  Validation loss = 7.3781  \n",
      "\n",
      "Fold: 13  Epoch: 449  Training loss = 4.2048  Validation loss = 7.3775  \n",
      "\n",
      "Fold: 13  Epoch: 450  Training loss = 4.2044  Validation loss = 7.3769  \n",
      "\n",
      "Fold: 13  Epoch: 451  Training loss = 4.2041  Validation loss = 7.3763  \n",
      "\n",
      "Fold: 13  Epoch: 452  Training loss = 4.2038  Validation loss = 7.3758  \n",
      "\n",
      "Fold: 13  Epoch: 453  Training loss = 4.2035  Validation loss = 7.3754  \n",
      "\n",
      "Fold: 13  Epoch: 454  Training loss = 4.2032  Validation loss = 7.3748  \n",
      "\n",
      "Fold: 13  Epoch: 455  Training loss = 4.2028  Validation loss = 7.3742  \n",
      "\n",
      "Fold: 13  Epoch: 456  Training loss = 4.2026  Validation loss = 7.3737  \n",
      "\n",
      "Fold: 13  Epoch: 457  Training loss = 4.2022  Validation loss = 7.3732  \n",
      "\n",
      "Fold: 13  Epoch: 458  Training loss = 4.2019  Validation loss = 7.3726  \n",
      "\n",
      "Fold: 13  Epoch: 459  Training loss = 4.2015  Validation loss = 7.3720  \n",
      "\n",
      "Fold: 13  Epoch: 460  Training loss = 4.2013  Validation loss = 7.3716  \n",
      "\n",
      "Fold: 13  Epoch: 461  Training loss = 4.2010  Validation loss = 7.3710  \n",
      "\n",
      "Fold: 13  Epoch: 462  Training loss = 4.2007  Validation loss = 7.3705  \n",
      "\n",
      "Fold: 13  Epoch: 463  Training loss = 4.2004  Validation loss = 7.3700  \n",
      "\n",
      "Fold: 13  Epoch: 464  Training loss = 4.2000  Validation loss = 7.3694  \n",
      "\n",
      "Fold: 13  Epoch: 465  Training loss = 4.1997  Validation loss = 7.3689  \n",
      "\n",
      "Fold: 13  Epoch: 466  Training loss = 4.1993  Validation loss = 7.3683  \n",
      "\n",
      "Fold: 13  Epoch: 467  Training loss = 4.1990  Validation loss = 7.3676  \n",
      "\n",
      "Fold: 13  Epoch: 468  Training loss = 4.1987  Validation loss = 7.3671  \n",
      "\n",
      "Fold: 13  Epoch: 469  Training loss = 4.1983  Validation loss = 7.3664  \n",
      "\n",
      "Fold: 13  Epoch: 470  Training loss = 4.1980  Validation loss = 7.3659  \n",
      "\n",
      "Fold: 13  Epoch: 471  Training loss = 4.1976  Validation loss = 7.3653  \n",
      "\n",
      "Fold: 13  Epoch: 472  Training loss = 4.1973  Validation loss = 7.3647  \n",
      "\n",
      "Fold: 13  Epoch: 473  Training loss = 4.1971  Validation loss = 7.3643  \n",
      "\n",
      "Fold: 13  Epoch: 474  Training loss = 4.1967  Validation loss = 7.3638  \n",
      "\n",
      "Fold: 13  Epoch: 475  Training loss = 4.1965  Validation loss = 7.3633  \n",
      "\n",
      "Fold: 13  Epoch: 476  Training loss = 4.1962  Validation loss = 7.3629  \n",
      "\n",
      "Fold: 13  Epoch: 477  Training loss = 4.1959  Validation loss = 7.3623  \n",
      "\n",
      "Fold: 13  Epoch: 478  Training loss = 4.1955  Validation loss = 7.3618  \n",
      "\n",
      "Fold: 13  Epoch: 479  Training loss = 4.1952  Validation loss = 7.3612  \n",
      "\n",
      "Fold: 13  Epoch: 480  Training loss = 4.1948  Validation loss = 7.3606  \n",
      "\n",
      "Fold: 13  Epoch: 481  Training loss = 4.1945  Validation loss = 7.3601  \n",
      "\n",
      "Fold: 13  Epoch: 482  Training loss = 4.1942  Validation loss = 7.3595  \n",
      "\n",
      "Fold: 13  Epoch: 483  Training loss = 4.1939  Validation loss = 7.3591  \n",
      "\n",
      "Fold: 13  Epoch: 484  Training loss = 4.1936  Validation loss = 7.3585  \n",
      "\n",
      "Fold: 13  Epoch: 485  Training loss = 4.1932  Validation loss = 7.3578  \n",
      "\n",
      "Fold: 13  Epoch: 486  Training loss = 4.1929  Validation loss = 7.3574  \n",
      "\n",
      "Fold: 13  Epoch: 487  Training loss = 4.1926  Validation loss = 7.3570  \n",
      "\n",
      "Fold: 13  Epoch: 488  Training loss = 4.1923  Validation loss = 7.3565  \n",
      "\n",
      "Fold: 13  Epoch: 489  Training loss = 4.1920  Validation loss = 7.3559  \n",
      "\n",
      "Fold: 13  Epoch: 490  Training loss = 4.1917  Validation loss = 7.3554  \n",
      "\n",
      "Fold: 13  Epoch: 491  Training loss = 4.1913  Validation loss = 7.3548  \n",
      "\n",
      "Fold: 13  Epoch: 492  Training loss = 4.1909  Validation loss = 7.3542  \n",
      "\n",
      "Fold: 13  Epoch: 493  Training loss = 4.1906  Validation loss = 7.3537  \n",
      "\n",
      "Fold: 13  Epoch: 494  Training loss = 4.1903  Validation loss = 7.3531  \n",
      "\n",
      "Fold: 13  Epoch: 495  Training loss = 4.1900  Validation loss = 7.3526  \n",
      "\n",
      "Fold: 13  Epoch: 496  Training loss = 4.1897  Validation loss = 7.3522  \n",
      "\n",
      "Fold: 13  Epoch: 497  Training loss = 4.1894  Validation loss = 7.3516  \n",
      "\n",
      "Fold: 13  Epoch: 498  Training loss = 4.1891  Validation loss = 7.3510  \n",
      "\n",
      "Fold: 13  Epoch: 499  Training loss = 4.1888  Validation loss = 7.3504  \n",
      "\n",
      "Fold: 13  Epoch: 500  Training loss = 4.1885  Validation loss = 7.3500  \n",
      "\n",
      "Check model:  Fold: 13  Optimal epoch: 500  \n",
      "\n",
      "Fold: 14  Epoch: 1  Training loss = 4.5663  Validation loss = 10.9023  \n",
      "\n",
      "Fold: 14  Epoch: 2  Training loss = 4.5658  Validation loss = 10.9015  \n",
      "\n",
      "Fold: 14  Epoch: 3  Training loss = 4.5654  Validation loss = 10.9009  \n",
      "\n",
      "Fold: 14  Epoch: 4  Training loss = 4.5650  Validation loss = 10.9003  \n",
      "\n",
      "Fold: 14  Epoch: 5  Training loss = 4.5646  Validation loss = 10.8997  \n",
      "\n",
      "Fold: 14  Epoch: 6  Training loss = 4.5641  Validation loss = 10.8989  \n",
      "\n",
      "Fold: 14  Epoch: 7  Training loss = 4.5636  Validation loss = 10.8981  \n",
      "\n",
      "Fold: 14  Epoch: 8  Training loss = 4.5631  Validation loss = 10.8975  \n",
      "\n",
      "Fold: 14  Epoch: 9  Training loss = 4.5627  Validation loss = 10.8968  \n",
      "\n",
      "Fold: 14  Epoch: 10  Training loss = 4.5622  Validation loss = 10.8961  \n",
      "\n",
      "Fold: 14  Epoch: 11  Training loss = 4.5618  Validation loss = 10.8955  \n",
      "\n",
      "Fold: 14  Epoch: 12  Training loss = 4.5615  Validation loss = 10.8949  \n",
      "\n",
      "Fold: 14  Epoch: 13  Training loss = 4.5611  Validation loss = 10.8943  \n",
      "\n",
      "Fold: 14  Epoch: 14  Training loss = 4.5606  Validation loss = 10.8937  \n",
      "\n",
      "Fold: 14  Epoch: 15  Training loss = 4.5602  Validation loss = 10.8929  \n",
      "\n",
      "Fold: 14  Epoch: 16  Training loss = 4.5596  Validation loss = 10.8921  \n",
      "\n",
      "Fold: 14  Epoch: 17  Training loss = 4.5592  Validation loss = 10.8915  \n",
      "\n",
      "Fold: 14  Epoch: 18  Training loss = 4.5588  Validation loss = 10.8909  \n",
      "\n",
      "Fold: 14  Epoch: 19  Training loss = 4.5584  Validation loss = 10.8902  \n",
      "\n",
      "Fold: 14  Epoch: 20  Training loss = 4.5580  Validation loss = 10.8897  \n",
      "\n",
      "Fold: 14  Epoch: 21  Training loss = 4.5576  Validation loss = 10.8891  \n",
      "\n",
      "Fold: 14  Epoch: 22  Training loss = 4.5572  Validation loss = 10.8884  \n",
      "\n",
      "Fold: 14  Epoch: 23  Training loss = 4.5568  Validation loss = 10.8877  \n",
      "\n",
      "Fold: 14  Epoch: 24  Training loss = 4.5564  Validation loss = 10.8871  \n",
      "\n",
      "Fold: 14  Epoch: 25  Training loss = 4.5560  Validation loss = 10.8865  \n",
      "\n",
      "Fold: 14  Epoch: 26  Training loss = 4.5556  Validation loss = 10.8859  \n",
      "\n",
      "Fold: 14  Epoch: 27  Training loss = 4.5551  Validation loss = 10.8852  \n",
      "\n",
      "Fold: 14  Epoch: 28  Training loss = 4.5547  Validation loss = 10.8846  \n",
      "\n",
      "Fold: 14  Epoch: 29  Training loss = 4.5543  Validation loss = 10.8840  \n",
      "\n",
      "Fold: 14  Epoch: 30  Training loss = 4.5539  Validation loss = 10.8834  \n",
      "\n",
      "Fold: 14  Epoch: 31  Training loss = 4.5535  Validation loss = 10.8827  \n",
      "\n",
      "Fold: 14  Epoch: 32  Training loss = 4.5530  Validation loss = 10.8819  \n",
      "\n",
      "Fold: 14  Epoch: 33  Training loss = 4.5525  Validation loss = 10.8813  \n",
      "\n",
      "Fold: 14  Epoch: 34  Training loss = 4.5521  Validation loss = 10.8807  \n",
      "\n",
      "Fold: 14  Epoch: 35  Training loss = 4.5517  Validation loss = 10.8801  \n",
      "\n",
      "Fold: 14  Epoch: 36  Training loss = 4.5513  Validation loss = 10.8793  \n",
      "\n",
      "Fold: 14  Epoch: 37  Training loss = 4.5508  Validation loss = 10.8787  \n",
      "\n",
      "Fold: 14  Epoch: 38  Training loss = 4.5504  Validation loss = 10.8780  \n",
      "\n",
      "Fold: 14  Epoch: 39  Training loss = 4.5499  Validation loss = 10.8773  \n",
      "\n",
      "Fold: 14  Epoch: 40  Training loss = 4.5496  Validation loss = 10.8767  \n",
      "\n",
      "Fold: 14  Epoch: 41  Training loss = 4.5491  Validation loss = 10.8759  \n",
      "\n",
      "Fold: 14  Epoch: 42  Training loss = 4.5487  Validation loss = 10.8753  \n",
      "\n",
      "Fold: 14  Epoch: 43  Training loss = 4.5483  Validation loss = 10.8747  \n",
      "\n",
      "Fold: 14  Epoch: 44  Training loss = 4.5479  Validation loss = 10.8741  \n",
      "\n",
      "Fold: 14  Epoch: 45  Training loss = 4.5474  Validation loss = 10.8734  \n",
      "\n",
      "Fold: 14  Epoch: 46  Training loss = 4.5470  Validation loss = 10.8727  \n",
      "\n",
      "Fold: 14  Epoch: 47  Training loss = 4.5465  Validation loss = 10.8720  \n",
      "\n",
      "Fold: 14  Epoch: 48  Training loss = 4.5461  Validation loss = 10.8713  \n",
      "\n",
      "Fold: 14  Epoch: 49  Training loss = 4.5456  Validation loss = 10.8706  \n",
      "\n",
      "Fold: 14  Epoch: 50  Training loss = 4.5453  Validation loss = 10.8701  \n",
      "\n",
      "Fold: 14  Epoch: 51  Training loss = 4.5448  Validation loss = 10.8695  \n",
      "\n",
      "Fold: 14  Epoch: 52  Training loss = 4.5445  Validation loss = 10.8689  \n",
      "\n",
      "Fold: 14  Epoch: 53  Training loss = 4.5439  Validation loss = 10.8681  \n",
      "\n",
      "Fold: 14  Epoch: 54  Training loss = 4.5435  Validation loss = 10.8675  \n",
      "\n",
      "Fold: 14  Epoch: 55  Training loss = 4.5431  Validation loss = 10.8668  \n",
      "\n",
      "Fold: 14  Epoch: 56  Training loss = 4.5426  Validation loss = 10.8660  \n",
      "\n",
      "Fold: 14  Epoch: 57  Training loss = 4.5421  Validation loss = 10.8653  \n",
      "\n",
      "Fold: 14  Epoch: 58  Training loss = 4.5417  Validation loss = 10.8647  \n",
      "\n",
      "Fold: 14  Epoch: 59  Training loss = 4.5413  Validation loss = 10.8640  \n",
      "\n",
      "Fold: 14  Epoch: 60  Training loss = 4.5409  Validation loss = 10.8634  \n",
      "\n",
      "Fold: 14  Epoch: 61  Training loss = 4.5405  Validation loss = 10.8628  \n",
      "\n",
      "Fold: 14  Epoch: 62  Training loss = 4.5401  Validation loss = 10.8622  \n",
      "\n",
      "Fold: 14  Epoch: 63  Training loss = 4.5397  Validation loss = 10.8615  \n",
      "\n",
      "Fold: 14  Epoch: 64  Training loss = 4.5391  Validation loss = 10.8607  \n",
      "\n",
      "Fold: 14  Epoch: 65  Training loss = 4.5387  Validation loss = 10.8600  \n",
      "\n",
      "Fold: 14  Epoch: 66  Training loss = 4.5383  Validation loss = 10.8595  \n",
      "\n",
      "Fold: 14  Epoch: 67  Training loss = 4.5379  Validation loss = 10.8589  \n",
      "\n",
      "Fold: 14  Epoch: 68  Training loss = 4.5375  Validation loss = 10.8581  \n",
      "\n",
      "Fold: 14  Epoch: 69  Training loss = 4.5371  Validation loss = 10.8575  \n",
      "\n",
      "Fold: 14  Epoch: 70  Training loss = 4.5366  Validation loss = 10.8569  \n",
      "\n",
      "Fold: 14  Epoch: 71  Training loss = 4.5362  Validation loss = 10.8562  \n",
      "\n",
      "Fold: 14  Epoch: 72  Training loss = 4.5357  Validation loss = 10.8554  \n",
      "\n",
      "Fold: 14  Epoch: 73  Training loss = 4.5352  Validation loss = 10.8548  \n",
      "\n",
      "Fold: 14  Epoch: 74  Training loss = 4.5349  Validation loss = 10.8541  \n",
      "\n",
      "Fold: 14  Epoch: 75  Training loss = 4.5344  Validation loss = 10.8534  \n",
      "\n",
      "Fold: 14  Epoch: 76  Training loss = 4.5340  Validation loss = 10.8528  \n",
      "\n",
      "Fold: 14  Epoch: 77  Training loss = 4.5335  Validation loss = 10.8521  \n",
      "\n",
      "Fold: 14  Epoch: 78  Training loss = 4.5332  Validation loss = 10.8516  \n",
      "\n",
      "Fold: 14  Epoch: 79  Training loss = 4.5327  Validation loss = 10.8508  \n",
      "\n",
      "Fold: 14  Epoch: 80  Training loss = 4.5324  Validation loss = 10.8503  \n",
      "\n",
      "Fold: 14  Epoch: 81  Training loss = 4.5319  Validation loss = 10.8497  \n",
      "\n",
      "Fold: 14  Epoch: 82  Training loss = 4.5315  Validation loss = 10.8490  \n",
      "\n",
      "Fold: 14  Epoch: 83  Training loss = 4.5311  Validation loss = 10.8483  \n",
      "\n",
      "Fold: 14  Epoch: 84  Training loss = 4.5307  Validation loss = 10.8477  \n",
      "\n",
      "Fold: 14  Epoch: 85  Training loss = 4.5302  Validation loss = 10.8471  \n",
      "\n",
      "Fold: 14  Epoch: 86  Training loss = 4.5298  Validation loss = 10.8464  \n",
      "\n",
      "Fold: 14  Epoch: 87  Training loss = 4.5294  Validation loss = 10.8458  \n",
      "\n",
      "Fold: 14  Epoch: 88  Training loss = 4.5289  Validation loss = 10.8451  \n",
      "\n",
      "Fold: 14  Epoch: 89  Training loss = 4.5286  Validation loss = 10.8446  \n",
      "\n",
      "Fold: 14  Epoch: 90  Training loss = 4.5282  Validation loss = 10.8440  \n",
      "\n",
      "Fold: 14  Epoch: 91  Training loss = 4.5278  Validation loss = 10.8433  \n",
      "\n",
      "Fold: 14  Epoch: 92  Training loss = 4.5274  Validation loss = 10.8427  \n",
      "\n",
      "Fold: 14  Epoch: 93  Training loss = 4.5270  Validation loss = 10.8421  \n",
      "\n",
      "Fold: 14  Epoch: 94  Training loss = 4.5266  Validation loss = 10.8414  \n",
      "\n",
      "Fold: 14  Epoch: 95  Training loss = 4.5262  Validation loss = 10.8408  \n",
      "\n",
      "Fold: 14  Epoch: 96  Training loss = 4.5258  Validation loss = 10.8402  \n",
      "\n",
      "Fold: 14  Epoch: 97  Training loss = 4.5254  Validation loss = 10.8396  \n",
      "\n",
      "Fold: 14  Epoch: 98  Training loss = 4.5250  Validation loss = 10.8389  \n",
      "\n",
      "Fold: 14  Epoch: 99  Training loss = 4.5246  Validation loss = 10.8384  \n",
      "\n",
      "Fold: 14  Epoch: 100  Training loss = 4.5242  Validation loss = 10.8378  \n",
      "\n",
      "Fold: 14  Epoch: 101  Training loss = 4.5238  Validation loss = 10.8372  \n",
      "\n",
      "Fold: 14  Epoch: 102  Training loss = 4.5235  Validation loss = 10.8366  \n",
      "\n",
      "Fold: 14  Epoch: 103  Training loss = 4.5231  Validation loss = 10.8360  \n",
      "\n",
      "Fold: 14  Epoch: 104  Training loss = 4.5227  Validation loss = 10.8354  \n",
      "\n",
      "Fold: 14  Epoch: 105  Training loss = 4.5223  Validation loss = 10.8348  \n",
      "\n",
      "Fold: 14  Epoch: 106  Training loss = 4.5219  Validation loss = 10.8342  \n",
      "\n",
      "Fold: 14  Epoch: 107  Training loss = 4.5214  Validation loss = 10.8335  \n",
      "\n",
      "Fold: 14  Epoch: 108  Training loss = 4.5210  Validation loss = 10.8328  \n",
      "\n",
      "Fold: 14  Epoch: 109  Training loss = 4.5206  Validation loss = 10.8322  \n",
      "\n",
      "Fold: 14  Epoch: 110  Training loss = 4.5201  Validation loss = 10.8315  \n",
      "\n",
      "Fold: 14  Epoch: 111  Training loss = 4.5197  Validation loss = 10.8309  \n",
      "\n",
      "Fold: 14  Epoch: 112  Training loss = 4.5193  Validation loss = 10.8302  \n",
      "\n",
      "Fold: 14  Epoch: 113  Training loss = 4.5189  Validation loss = 10.8296  \n",
      "\n",
      "Fold: 14  Epoch: 114  Training loss = 4.5185  Validation loss = 10.8289  \n",
      "\n",
      "Fold: 14  Epoch: 115  Training loss = 4.5180  Validation loss = 10.8282  \n",
      "\n",
      "Fold: 14  Epoch: 116  Training loss = 4.5176  Validation loss = 10.8276  \n",
      "\n",
      "Fold: 14  Epoch: 117  Training loss = 4.5172  Validation loss = 10.8270  \n",
      "\n",
      "Fold: 14  Epoch: 118  Training loss = 4.5167  Validation loss = 10.8263  \n",
      "\n",
      "Fold: 14  Epoch: 119  Training loss = 4.5163  Validation loss = 10.8256  \n",
      "\n",
      "Fold: 14  Epoch: 120  Training loss = 4.5159  Validation loss = 10.8250  \n",
      "\n",
      "Fold: 14  Epoch: 121  Training loss = 4.5154  Validation loss = 10.8243  \n",
      "\n",
      "Fold: 14  Epoch: 122  Training loss = 4.5150  Validation loss = 10.8237  \n",
      "\n",
      "Fold: 14  Epoch: 123  Training loss = 4.5145  Validation loss = 10.8229  \n",
      "\n",
      "Fold: 14  Epoch: 124  Training loss = 4.5141  Validation loss = 10.8222  \n",
      "\n",
      "Fold: 14  Epoch: 125  Training loss = 4.5137  Validation loss = 10.8217  \n",
      "\n",
      "Fold: 14  Epoch: 126  Training loss = 4.5134  Validation loss = 10.8212  \n",
      "\n",
      "Fold: 14  Epoch: 127  Training loss = 4.5130  Validation loss = 10.8205  \n",
      "\n",
      "Fold: 14  Epoch: 128  Training loss = 4.5125  Validation loss = 10.8198  \n",
      "\n",
      "Fold: 14  Epoch: 129  Training loss = 4.5121  Validation loss = 10.8191  \n",
      "\n",
      "Fold: 14  Epoch: 130  Training loss = 4.5117  Validation loss = 10.8185  \n",
      "\n",
      "Fold: 14  Epoch: 131  Training loss = 4.5113  Validation loss = 10.8179  \n",
      "\n",
      "Fold: 14  Epoch: 132  Training loss = 4.5109  Validation loss = 10.8172  \n",
      "\n",
      "Fold: 14  Epoch: 133  Training loss = 4.5105  Validation loss = 10.8167  \n",
      "\n",
      "Fold: 14  Epoch: 134  Training loss = 4.5102  Validation loss = 10.8162  \n",
      "\n",
      "Fold: 14  Epoch: 135  Training loss = 4.5098  Validation loss = 10.8156  \n",
      "\n",
      "Fold: 14  Epoch: 136  Training loss = 4.5094  Validation loss = 10.8149  \n",
      "\n",
      "Fold: 14  Epoch: 137  Training loss = 4.5090  Validation loss = 10.8144  \n",
      "\n",
      "Fold: 14  Epoch: 138  Training loss = 4.5086  Validation loss = 10.8137  \n",
      "\n",
      "Fold: 14  Epoch: 139  Training loss = 4.5081  Validation loss = 10.8130  \n",
      "\n",
      "Fold: 14  Epoch: 140  Training loss = 4.5076  Validation loss = 10.8122  \n",
      "\n",
      "Fold: 14  Epoch: 141  Training loss = 4.5072  Validation loss = 10.8115  \n",
      "\n",
      "Fold: 14  Epoch: 142  Training loss = 4.5068  Validation loss = 10.8109  \n",
      "\n",
      "Fold: 14  Epoch: 143  Training loss = 4.5064  Validation loss = 10.8103  \n",
      "\n",
      "Fold: 14  Epoch: 144  Training loss = 4.5059  Validation loss = 10.8096  \n",
      "\n",
      "Fold: 14  Epoch: 145  Training loss = 4.5055  Validation loss = 10.8089  \n",
      "\n",
      "Fold: 14  Epoch: 146  Training loss = 4.5051  Validation loss = 10.8083  \n",
      "\n",
      "Fold: 14  Epoch: 147  Training loss = 4.5047  Validation loss = 10.8077  \n",
      "\n",
      "Fold: 14  Epoch: 148  Training loss = 4.5043  Validation loss = 10.8070  \n",
      "\n",
      "Fold: 14  Epoch: 149  Training loss = 4.5038  Validation loss = 10.8063  \n",
      "\n",
      "Fold: 14  Epoch: 150  Training loss = 4.5033  Validation loss = 10.8056  \n",
      "\n",
      "Fold: 14  Epoch: 151  Training loss = 4.5029  Validation loss = 10.8049  \n",
      "\n",
      "Fold: 14  Epoch: 152  Training loss = 4.5025  Validation loss = 10.8042  \n",
      "\n",
      "Fold: 14  Epoch: 153  Training loss = 4.5020  Validation loss = 10.8036  \n",
      "\n",
      "Fold: 14  Epoch: 154  Training loss = 4.5016  Validation loss = 10.8029  \n",
      "\n",
      "Fold: 14  Epoch: 155  Training loss = 4.5012  Validation loss = 10.8023  \n",
      "\n",
      "Fold: 14  Epoch: 156  Training loss = 4.5009  Validation loss = 10.8018  \n",
      "\n",
      "Fold: 14  Epoch: 157  Training loss = 4.5004  Validation loss = 10.8011  \n",
      "\n",
      "Fold: 14  Epoch: 158  Training loss = 4.4999  Validation loss = 10.8004  \n",
      "\n",
      "Fold: 14  Epoch: 159  Training loss = 4.4996  Validation loss = 10.7998  \n",
      "\n",
      "Fold: 14  Epoch: 160  Training loss = 4.4992  Validation loss = 10.7992  \n",
      "\n",
      "Fold: 14  Epoch: 161  Training loss = 4.4988  Validation loss = 10.7985  \n",
      "\n",
      "Fold: 14  Epoch: 162  Training loss = 4.4984  Validation loss = 10.7980  \n",
      "\n",
      "Fold: 14  Epoch: 163  Training loss = 4.4980  Validation loss = 10.7974  \n",
      "\n",
      "Fold: 14  Epoch: 164  Training loss = 4.4976  Validation loss = 10.7968  \n",
      "\n",
      "Fold: 14  Epoch: 165  Training loss = 4.4972  Validation loss = 10.7962  \n",
      "\n",
      "Fold: 14  Epoch: 166  Training loss = 4.4968  Validation loss = 10.7956  \n",
      "\n",
      "Fold: 14  Epoch: 167  Training loss = 4.4964  Validation loss = 10.7950  \n",
      "\n",
      "Fold: 14  Epoch: 168  Training loss = 4.4961  Validation loss = 10.7944  \n",
      "\n",
      "Fold: 14  Epoch: 169  Training loss = 4.4957  Validation loss = 10.7939  \n",
      "\n",
      "Fold: 14  Epoch: 170  Training loss = 4.4953  Validation loss = 10.7933  \n",
      "\n",
      "Fold: 14  Epoch: 171  Training loss = 4.4949  Validation loss = 10.7926  \n",
      "\n",
      "Fold: 14  Epoch: 172  Training loss = 4.4944  Validation loss = 10.7919  \n",
      "\n",
      "Fold: 14  Epoch: 173  Training loss = 4.4940  Validation loss = 10.7912  \n",
      "\n",
      "Fold: 14  Epoch: 174  Training loss = 4.4935  Validation loss = 10.7905  \n",
      "\n",
      "Fold: 14  Epoch: 175  Training loss = 4.4930  Validation loss = 10.7897  \n",
      "\n",
      "Fold: 14  Epoch: 176  Training loss = 4.4925  Validation loss = 10.7889  \n",
      "\n",
      "Fold: 14  Epoch: 177  Training loss = 4.4921  Validation loss = 10.7884  \n",
      "\n",
      "Fold: 14  Epoch: 178  Training loss = 4.4917  Validation loss = 10.7877  \n",
      "\n",
      "Fold: 14  Epoch: 179  Training loss = 4.4913  Validation loss = 10.7871  \n",
      "\n",
      "Fold: 14  Epoch: 180  Training loss = 4.4908  Validation loss = 10.7863  \n",
      "\n",
      "Fold: 14  Epoch: 181  Training loss = 4.4904  Validation loss = 10.7856  \n",
      "\n",
      "Fold: 14  Epoch: 182  Training loss = 4.4899  Validation loss = 10.7849  \n",
      "\n",
      "Fold: 14  Epoch: 183  Training loss = 4.4895  Validation loss = 10.7843  \n",
      "\n",
      "Fold: 14  Epoch: 184  Training loss = 4.4890  Validation loss = 10.7835  \n",
      "\n",
      "Fold: 14  Epoch: 185  Training loss = 4.4886  Validation loss = 10.7829  \n",
      "\n",
      "Fold: 14  Epoch: 186  Training loss = 4.4882  Validation loss = 10.7822  \n",
      "\n",
      "Fold: 14  Epoch: 187  Training loss = 4.4877  Validation loss = 10.7815  \n",
      "\n",
      "Fold: 14  Epoch: 188  Training loss = 4.4873  Validation loss = 10.7809  \n",
      "\n",
      "Fold: 14  Epoch: 189  Training loss = 4.4869  Validation loss = 10.7802  \n",
      "\n",
      "Fold: 14  Epoch: 190  Training loss = 4.4864  Validation loss = 10.7795  \n",
      "\n",
      "Fold: 14  Epoch: 191  Training loss = 4.4859  Validation loss = 10.7788  \n",
      "\n",
      "Fold: 14  Epoch: 192  Training loss = 4.4856  Validation loss = 10.7783  \n",
      "\n",
      "Fold: 14  Epoch: 193  Training loss = 4.4852  Validation loss = 10.7777  \n",
      "\n",
      "Fold: 14  Epoch: 194  Training loss = 4.4848  Validation loss = 10.7771  \n",
      "\n",
      "Fold: 14  Epoch: 195  Training loss = 4.4844  Validation loss = 10.7764  \n",
      "\n",
      "Fold: 14  Epoch: 196  Training loss = 4.4839  Validation loss = 10.7757  \n",
      "\n",
      "Fold: 14  Epoch: 197  Training loss = 4.4835  Validation loss = 10.7750  \n",
      "\n",
      "Fold: 14  Epoch: 198  Training loss = 4.4830  Validation loss = 10.7743  \n",
      "\n",
      "Fold: 14  Epoch: 199  Training loss = 4.4826  Validation loss = 10.7736  \n",
      "\n",
      "Fold: 14  Epoch: 200  Training loss = 4.4822  Validation loss = 10.7730  \n",
      "\n",
      "Fold: 14  Epoch: 201  Training loss = 4.4817  Validation loss = 10.7722  \n",
      "\n",
      "Fold: 14  Epoch: 202  Training loss = 4.4813  Validation loss = 10.7716  \n",
      "\n",
      "Fold: 14  Epoch: 203  Training loss = 4.4808  Validation loss = 10.7709  \n",
      "\n",
      "Fold: 14  Epoch: 204  Training loss = 4.4804  Validation loss = 10.7703  \n",
      "\n",
      "Fold: 14  Epoch: 205  Training loss = 4.4801  Validation loss = 10.7697  \n",
      "\n",
      "Fold: 14  Epoch: 206  Training loss = 4.4797  Validation loss = 10.7691  \n",
      "\n",
      "Fold: 14  Epoch: 207  Training loss = 4.4793  Validation loss = 10.7684  \n",
      "\n",
      "Fold: 14  Epoch: 208  Training loss = 4.4789  Validation loss = 10.7678  \n",
      "\n",
      "Fold: 14  Epoch: 209  Training loss = 4.4785  Validation loss = 10.7673  \n",
      "\n",
      "Fold: 14  Epoch: 210  Training loss = 4.4781  Validation loss = 10.7667  \n",
      "\n",
      "Fold: 14  Epoch: 211  Training loss = 4.4777  Validation loss = 10.7660  \n",
      "\n",
      "Fold: 14  Epoch: 212  Training loss = 4.4773  Validation loss = 10.7654  \n",
      "\n",
      "Fold: 14  Epoch: 213  Training loss = 4.4769  Validation loss = 10.7648  \n",
      "\n",
      "Fold: 14  Epoch: 214  Training loss = 4.4765  Validation loss = 10.7641  \n",
      "\n",
      "Fold: 14  Epoch: 215  Training loss = 4.4760  Validation loss = 10.7635  \n",
      "\n",
      "Fold: 14  Epoch: 216  Training loss = 4.4756  Validation loss = 10.7628  \n",
      "\n",
      "Fold: 14  Epoch: 217  Training loss = 4.4752  Validation loss = 10.7622  \n",
      "\n",
      "Fold: 14  Epoch: 218  Training loss = 4.4748  Validation loss = 10.7615  \n",
      "\n",
      "Fold: 14  Epoch: 219  Training loss = 4.4744  Validation loss = 10.7609  \n",
      "\n",
      "Fold: 14  Epoch: 220  Training loss = 4.4740  Validation loss = 10.7603  \n",
      "\n",
      "Fold: 14  Epoch: 221  Training loss = 4.4736  Validation loss = 10.7597  \n",
      "\n",
      "Fold: 14  Epoch: 222  Training loss = 4.4732  Validation loss = 10.7590  \n",
      "\n",
      "Fold: 14  Epoch: 223  Training loss = 4.4728  Validation loss = 10.7584  \n",
      "\n",
      "Fold: 14  Epoch: 224  Training loss = 4.4724  Validation loss = 10.7578  \n",
      "\n",
      "Fold: 14  Epoch: 225  Training loss = 4.4720  Validation loss = 10.7571  \n",
      "\n",
      "Fold: 14  Epoch: 226  Training loss = 4.4716  Validation loss = 10.7566  \n",
      "\n",
      "Fold: 14  Epoch: 227  Training loss = 4.4712  Validation loss = 10.7560  \n",
      "\n",
      "Fold: 14  Epoch: 228  Training loss = 4.4708  Validation loss = 10.7553  \n",
      "\n",
      "Fold: 14  Epoch: 229  Training loss = 4.4704  Validation loss = 10.7548  \n",
      "\n",
      "Fold: 14  Epoch: 230  Training loss = 4.4701  Validation loss = 10.7542  \n",
      "\n",
      "Fold: 14  Epoch: 231  Training loss = 4.4696  Validation loss = 10.7535  \n",
      "\n",
      "Fold: 14  Epoch: 232  Training loss = 4.4692  Validation loss = 10.7529  \n",
      "\n",
      "Fold: 14  Epoch: 233  Training loss = 4.4688  Validation loss = 10.7522  \n",
      "\n",
      "Fold: 14  Epoch: 234  Training loss = 4.4684  Validation loss = 10.7516  \n",
      "\n",
      "Fold: 14  Epoch: 235  Training loss = 4.4680  Validation loss = 10.7510  \n",
      "\n",
      "Fold: 14  Epoch: 236  Training loss = 4.4676  Validation loss = 10.7504  \n",
      "\n",
      "Fold: 14  Epoch: 237  Training loss = 4.4671  Validation loss = 10.7496  \n",
      "\n",
      "Fold: 14  Epoch: 238  Training loss = 4.4667  Validation loss = 10.7490  \n",
      "\n",
      "Fold: 14  Epoch: 239  Training loss = 4.4663  Validation loss = 10.7484  \n",
      "\n",
      "Fold: 14  Epoch: 240  Training loss = 4.4659  Validation loss = 10.7477  \n",
      "\n",
      "Fold: 14  Epoch: 241  Training loss = 4.4655  Validation loss = 10.7471  \n",
      "\n",
      "Fold: 14  Epoch: 242  Training loss = 4.4651  Validation loss = 10.7465  \n",
      "\n",
      "Fold: 14  Epoch: 243  Training loss = 4.4646  Validation loss = 10.7458  \n",
      "\n",
      "Fold: 14  Epoch: 244  Training loss = 4.4642  Validation loss = 10.7451  \n",
      "\n",
      "Fold: 14  Epoch: 245  Training loss = 4.4638  Validation loss = 10.7446  \n",
      "\n",
      "Fold: 14  Epoch: 246  Training loss = 4.4635  Validation loss = 10.7440  \n",
      "\n",
      "Fold: 14  Epoch: 247  Training loss = 4.4631  Validation loss = 10.7434  \n",
      "\n",
      "Fold: 14  Epoch: 248  Training loss = 4.4627  Validation loss = 10.7428  \n",
      "\n",
      "Fold: 14  Epoch: 249  Training loss = 4.4623  Validation loss = 10.7421  \n",
      "\n",
      "Fold: 14  Epoch: 250  Training loss = 4.4619  Validation loss = 10.7416  \n",
      "\n",
      "Fold: 14  Epoch: 251  Training loss = 4.4615  Validation loss = 10.7410  \n",
      "\n",
      "Fold: 14  Epoch: 252  Training loss = 4.4612  Validation loss = 10.7404  \n",
      "\n",
      "Fold: 14  Epoch: 253  Training loss = 4.4608  Validation loss = 10.7399  \n",
      "\n",
      "Fold: 14  Epoch: 254  Training loss = 4.4605  Validation loss = 10.7393  \n",
      "\n",
      "Fold: 14  Epoch: 255  Training loss = 4.4600  Validation loss = 10.7387  \n",
      "\n",
      "Fold: 14  Epoch: 256  Training loss = 4.4597  Validation loss = 10.7381  \n",
      "\n",
      "Fold: 14  Epoch: 257  Training loss = 4.4593  Validation loss = 10.7375  \n",
      "\n",
      "Fold: 14  Epoch: 258  Training loss = 4.4589  Validation loss = 10.7369  \n",
      "\n",
      "Fold: 14  Epoch: 259  Training loss = 4.4585  Validation loss = 10.7363  \n",
      "\n",
      "Fold: 14  Epoch: 260  Training loss = 4.4581  Validation loss = 10.7357  \n",
      "\n",
      "Fold: 14  Epoch: 261  Training loss = 4.4577  Validation loss = 10.7351  \n",
      "\n",
      "Fold: 14  Epoch: 262  Training loss = 4.4574  Validation loss = 10.7346  \n",
      "\n",
      "Fold: 14  Epoch: 263  Training loss = 4.4570  Validation loss = 10.7340  \n",
      "\n",
      "Fold: 14  Epoch: 264  Training loss = 4.4567  Validation loss = 10.7335  \n",
      "\n",
      "Fold: 14  Epoch: 265  Training loss = 4.4563  Validation loss = 10.7328  \n",
      "\n",
      "Fold: 14  Epoch: 266  Training loss = 4.4558  Validation loss = 10.7321  \n",
      "\n",
      "Fold: 14  Epoch: 267  Training loss = 4.4554  Validation loss = 10.7315  \n",
      "\n",
      "Fold: 14  Epoch: 268  Training loss = 4.4550  Validation loss = 10.7309  \n",
      "\n",
      "Fold: 14  Epoch: 269  Training loss = 4.4546  Validation loss = 10.7303  \n",
      "\n",
      "Fold: 14  Epoch: 270  Training loss = 4.4542  Validation loss = 10.7296  \n",
      "\n",
      "Fold: 14  Epoch: 271  Training loss = 4.4538  Validation loss = 10.7290  \n",
      "\n",
      "Fold: 14  Epoch: 272  Training loss = 4.4535  Validation loss = 10.7284  \n",
      "\n",
      "Fold: 14  Epoch: 273  Training loss = 4.4530  Validation loss = 10.7278  \n",
      "\n",
      "Fold: 14  Epoch: 274  Training loss = 4.4526  Validation loss = 10.7271  \n",
      "\n",
      "Fold: 14  Epoch: 275  Training loss = 4.4522  Validation loss = 10.7264  \n",
      "\n",
      "Fold: 14  Epoch: 276  Training loss = 4.4518  Validation loss = 10.7258  \n",
      "\n",
      "Fold: 14  Epoch: 277  Training loss = 4.4513  Validation loss = 10.7251  \n",
      "\n",
      "Fold: 14  Epoch: 278  Training loss = 4.4510  Validation loss = 10.7246  \n",
      "\n",
      "Fold: 14  Epoch: 279  Training loss = 4.4506  Validation loss = 10.7239  \n",
      "\n",
      "Fold: 14  Epoch: 280  Training loss = 4.4502  Validation loss = 10.7233  \n",
      "\n",
      "Fold: 14  Epoch: 281  Training loss = 4.4498  Validation loss = 10.7227  \n",
      "\n",
      "Fold: 14  Epoch: 282  Training loss = 4.4493  Validation loss = 10.7220  \n",
      "\n",
      "Fold: 14  Epoch: 283  Training loss = 4.4490  Validation loss = 10.7214  \n",
      "\n",
      "Fold: 14  Epoch: 284  Training loss = 4.4486  Validation loss = 10.7208  \n",
      "\n",
      "Fold: 14  Epoch: 285  Training loss = 4.4482  Validation loss = 10.7202  \n",
      "\n",
      "Fold: 14  Epoch: 286  Training loss = 4.4478  Validation loss = 10.7196  \n",
      "\n",
      "Fold: 14  Epoch: 287  Training loss = 4.4474  Validation loss = 10.7190  \n",
      "\n",
      "Fold: 14  Epoch: 288  Training loss = 4.4470  Validation loss = 10.7183  \n",
      "\n",
      "Fold: 14  Epoch: 289  Training loss = 4.4466  Validation loss = 10.7178  \n",
      "\n",
      "Fold: 14  Epoch: 290  Training loss = 4.4462  Validation loss = 10.7171  \n",
      "\n",
      "Fold: 14  Epoch: 291  Training loss = 4.4458  Validation loss = 10.7165  \n",
      "\n",
      "Fold: 14  Epoch: 292  Training loss = 4.4454  Validation loss = 10.7158  \n",
      "\n",
      "Fold: 14  Epoch: 293  Training loss = 4.4449  Validation loss = 10.7151  \n",
      "\n",
      "Fold: 14  Epoch: 294  Training loss = 4.4445  Validation loss = 10.7145  \n",
      "\n",
      "Fold: 14  Epoch: 295  Training loss = 4.4441  Validation loss = 10.7137  \n",
      "\n",
      "Fold: 14  Epoch: 296  Training loss = 4.4436  Validation loss = 10.7131  \n",
      "\n",
      "Fold: 14  Epoch: 297  Training loss = 4.4432  Validation loss = 10.7123  \n",
      "\n",
      "Fold: 14  Epoch: 298  Training loss = 4.4428  Validation loss = 10.7118  \n",
      "\n",
      "Fold: 14  Epoch: 299  Training loss = 4.4424  Validation loss = 10.7112  \n",
      "\n",
      "Fold: 14  Epoch: 300  Training loss = 4.4420  Validation loss = 10.7105  \n",
      "\n",
      "Fold: 14  Epoch: 301  Training loss = 4.4416  Validation loss = 10.7098  \n",
      "\n",
      "Fold: 14  Epoch: 302  Training loss = 4.4412  Validation loss = 10.7092  \n",
      "\n",
      "Fold: 14  Epoch: 303  Training loss = 4.4408  Validation loss = 10.7086  \n",
      "\n",
      "Fold: 14  Epoch: 304  Training loss = 4.4404  Validation loss = 10.7080  \n",
      "\n",
      "Fold: 14  Epoch: 305  Training loss = 4.4399  Validation loss = 10.7073  \n",
      "\n",
      "Fold: 14  Epoch: 306  Training loss = 4.4396  Validation loss = 10.7068  \n",
      "\n",
      "Fold: 14  Epoch: 307  Training loss = 4.4392  Validation loss = 10.7061  \n",
      "\n",
      "Fold: 14  Epoch: 308  Training loss = 4.4387  Validation loss = 10.7055  \n",
      "\n",
      "Fold: 14  Epoch: 309  Training loss = 4.4383  Validation loss = 10.7047  \n",
      "\n",
      "Fold: 14  Epoch: 310  Training loss = 4.4379  Validation loss = 10.7041  \n",
      "\n",
      "Fold: 14  Epoch: 311  Training loss = 4.4374  Validation loss = 10.7034  \n",
      "\n",
      "Fold: 14  Epoch: 312  Training loss = 4.4370  Validation loss = 10.7028  \n",
      "\n",
      "Fold: 14  Epoch: 313  Training loss = 4.4366  Validation loss = 10.7021  \n",
      "\n",
      "Fold: 14  Epoch: 314  Training loss = 4.4363  Validation loss = 10.7017  \n",
      "\n",
      "Fold: 14  Epoch: 315  Training loss = 4.4359  Validation loss = 10.7010  \n",
      "\n",
      "Fold: 14  Epoch: 316  Training loss = 4.4354  Validation loss = 10.7002  \n",
      "\n",
      "Fold: 14  Epoch: 317  Training loss = 4.4350  Validation loss = 10.6996  \n",
      "\n",
      "Fold: 14  Epoch: 318  Training loss = 4.4346  Validation loss = 10.6991  \n",
      "\n",
      "Fold: 14  Epoch: 319  Training loss = 4.4342  Validation loss = 10.6985  \n",
      "\n",
      "Fold: 14  Epoch: 320  Training loss = 4.4339  Validation loss = 10.6979  \n",
      "\n",
      "Fold: 14  Epoch: 321  Training loss = 4.4335  Validation loss = 10.6973  \n",
      "\n",
      "Fold: 14  Epoch: 322  Training loss = 4.4331  Validation loss = 10.6966  \n",
      "\n",
      "Fold: 14  Epoch: 323  Training loss = 4.4326  Validation loss = 10.6960  \n",
      "\n",
      "Fold: 14  Epoch: 324  Training loss = 4.4323  Validation loss = 10.6954  \n",
      "\n",
      "Fold: 14  Epoch: 325  Training loss = 4.4319  Validation loss = 10.6947  \n",
      "\n",
      "Fold: 14  Epoch: 326  Training loss = 4.4314  Validation loss = 10.6940  \n",
      "\n",
      "Fold: 14  Epoch: 327  Training loss = 4.4310  Validation loss = 10.6934  \n",
      "\n",
      "Fold: 14  Epoch: 328  Training loss = 4.4306  Validation loss = 10.6928  \n",
      "\n",
      "Fold: 14  Epoch: 329  Training loss = 4.4302  Validation loss = 10.6921  \n",
      "\n",
      "Fold: 14  Epoch: 330  Training loss = 4.4298  Validation loss = 10.6916  \n",
      "\n",
      "Fold: 14  Epoch: 331  Training loss = 4.4294  Validation loss = 10.6909  \n",
      "\n",
      "Fold: 14  Epoch: 332  Training loss = 4.4290  Validation loss = 10.6903  \n",
      "\n",
      "Fold: 14  Epoch: 333  Training loss = 4.4286  Validation loss = 10.6897  \n",
      "\n",
      "Fold: 14  Epoch: 334  Training loss = 4.4282  Validation loss = 10.6890  \n",
      "\n",
      "Fold: 14  Epoch: 335  Training loss = 4.4278  Validation loss = 10.6884  \n",
      "\n",
      "Fold: 14  Epoch: 336  Training loss = 4.4274  Validation loss = 10.6877  \n",
      "\n",
      "Fold: 14  Epoch: 337  Training loss = 4.4270  Validation loss = 10.6871  \n",
      "\n",
      "Fold: 14  Epoch: 338  Training loss = 4.4266  Validation loss = 10.6865  \n",
      "\n",
      "Fold: 14  Epoch: 339  Training loss = 4.4263  Validation loss = 10.6860  \n",
      "\n",
      "Fold: 14  Epoch: 340  Training loss = 4.4259  Validation loss = 10.6854  \n",
      "\n",
      "Fold: 14  Epoch: 341  Training loss = 4.4256  Validation loss = 10.6850  \n",
      "\n",
      "Fold: 14  Epoch: 342  Training loss = 4.4251  Validation loss = 10.6842  \n",
      "\n",
      "Fold: 14  Epoch: 343  Training loss = 4.4247  Validation loss = 10.6836  \n",
      "\n",
      "Fold: 14  Epoch: 344  Training loss = 4.4243  Validation loss = 10.6829  \n",
      "\n",
      "Fold: 14  Epoch: 345  Training loss = 4.4239  Validation loss = 10.6824  \n",
      "\n",
      "Fold: 14  Epoch: 346  Training loss = 4.4236  Validation loss = 10.6818  \n",
      "\n",
      "Fold: 14  Epoch: 347  Training loss = 4.4232  Validation loss = 10.6813  \n",
      "\n",
      "Fold: 14  Epoch: 348  Training loss = 4.4227  Validation loss = 10.6804  \n",
      "\n",
      "Fold: 14  Epoch: 349  Training loss = 4.4223  Validation loss = 10.6798  \n",
      "\n",
      "Fold: 14  Epoch: 350  Training loss = 4.4219  Validation loss = 10.6792  \n",
      "\n",
      "Fold: 14  Epoch: 351  Training loss = 4.4215  Validation loss = 10.6785  \n",
      "\n",
      "Fold: 14  Epoch: 352  Training loss = 4.4210  Validation loss = 10.6778  \n",
      "\n",
      "Fold: 14  Epoch: 353  Training loss = 4.4206  Validation loss = 10.6772  \n",
      "\n",
      "Fold: 14  Epoch: 354  Training loss = 4.4202  Validation loss = 10.6766  \n",
      "\n",
      "Fold: 14  Epoch: 355  Training loss = 4.4199  Validation loss = 10.6761  \n",
      "\n",
      "Fold: 14  Epoch: 356  Training loss = 4.4196  Validation loss = 10.6756  \n",
      "\n",
      "Fold: 14  Epoch: 357  Training loss = 4.4192  Validation loss = 10.6749  \n",
      "\n",
      "Fold: 14  Epoch: 358  Training loss = 4.4188  Validation loss = 10.6743  \n",
      "\n",
      "Fold: 14  Epoch: 359  Training loss = 4.4184  Validation loss = 10.6737  \n",
      "\n",
      "Fold: 14  Epoch: 360  Training loss = 4.4179  Validation loss = 10.6729  \n",
      "\n",
      "Fold: 14  Epoch: 361  Training loss = 4.4175  Validation loss = 10.6722  \n",
      "\n",
      "Fold: 14  Epoch: 362  Training loss = 4.4171  Validation loss = 10.6716  \n",
      "\n",
      "Fold: 14  Epoch: 363  Training loss = 4.4167  Validation loss = 10.6710  \n",
      "\n",
      "Fold: 14  Epoch: 364  Training loss = 4.4162  Validation loss = 10.6703  \n",
      "\n",
      "Fold: 14  Epoch: 365  Training loss = 4.4158  Validation loss = 10.6697  \n",
      "\n",
      "Fold: 14  Epoch: 366  Training loss = 4.4155  Validation loss = 10.6691  \n",
      "\n",
      "Fold: 14  Epoch: 367  Training loss = 4.4150  Validation loss = 10.6684  \n",
      "\n",
      "Fold: 14  Epoch: 368  Training loss = 4.4145  Validation loss = 10.6676  \n",
      "\n",
      "Fold: 14  Epoch: 369  Training loss = 4.4142  Validation loss = 10.6670  \n",
      "\n",
      "Fold: 14  Epoch: 370  Training loss = 4.4138  Validation loss = 10.6664  \n",
      "\n",
      "Fold: 14  Epoch: 371  Training loss = 4.4134  Validation loss = 10.6658  \n",
      "\n",
      "Fold: 14  Epoch: 372  Training loss = 4.4130  Validation loss = 10.6652  \n",
      "\n",
      "Fold: 14  Epoch: 373  Training loss = 4.4126  Validation loss = 10.6646  \n",
      "\n",
      "Fold: 14  Epoch: 374  Training loss = 4.4121  Validation loss = 10.6638  \n",
      "\n",
      "Fold: 14  Epoch: 375  Training loss = 4.4118  Validation loss = 10.6633  \n",
      "\n",
      "Fold: 14  Epoch: 376  Training loss = 4.4113  Validation loss = 10.6626  \n",
      "\n",
      "Fold: 14  Epoch: 377  Training loss = 4.4110  Validation loss = 10.6620  \n",
      "\n",
      "Fold: 14  Epoch: 378  Training loss = 4.4105  Validation loss = 10.6613  \n",
      "\n",
      "Fold: 14  Epoch: 379  Training loss = 4.4101  Validation loss = 10.6606  \n",
      "\n",
      "Fold: 14  Epoch: 380  Training loss = 4.4096  Validation loss = 10.6599  \n",
      "\n",
      "Fold: 14  Epoch: 381  Training loss = 4.4092  Validation loss = 10.6593  \n",
      "\n",
      "Fold: 14  Epoch: 382  Training loss = 4.4088  Validation loss = 10.6586  \n",
      "\n",
      "Fold: 14  Epoch: 383  Training loss = 4.4084  Validation loss = 10.6580  \n",
      "\n",
      "Fold: 14  Epoch: 384  Training loss = 4.4080  Validation loss = 10.6573  \n",
      "\n",
      "Fold: 14  Epoch: 385  Training loss = 4.4076  Validation loss = 10.6568  \n",
      "\n",
      "Fold: 14  Epoch: 386  Training loss = 4.4073  Validation loss = 10.6562  \n",
      "\n",
      "Fold: 14  Epoch: 387  Training loss = 4.4068  Validation loss = 10.6555  \n",
      "\n",
      "Fold: 14  Epoch: 388  Training loss = 4.4064  Validation loss = 10.6549  \n",
      "\n",
      "Fold: 14  Epoch: 389  Training loss = 4.4060  Validation loss = 10.6542  \n",
      "\n",
      "Fold: 14  Epoch: 390  Training loss = 4.4055  Validation loss = 10.6535  \n",
      "\n",
      "Fold: 14  Epoch: 391  Training loss = 4.4051  Validation loss = 10.6527  \n",
      "\n",
      "Fold: 14  Epoch: 392  Training loss = 4.4046  Validation loss = 10.6520  \n",
      "\n",
      "Fold: 14  Epoch: 393  Training loss = 4.4041  Validation loss = 10.6513  \n",
      "\n",
      "Fold: 14  Epoch: 394  Training loss = 4.4037  Validation loss = 10.6507  \n",
      "\n",
      "Fold: 14  Epoch: 395  Training loss = 4.4033  Validation loss = 10.6500  \n",
      "\n",
      "Fold: 14  Epoch: 396  Training loss = 4.4029  Validation loss = 10.6493  \n",
      "\n",
      "Fold: 14  Epoch: 397  Training loss = 4.4024  Validation loss = 10.6486  \n",
      "\n",
      "Fold: 14  Epoch: 398  Training loss = 4.4020  Validation loss = 10.6480  \n",
      "\n",
      "Fold: 14  Epoch: 399  Training loss = 4.4016  Validation loss = 10.6473  \n",
      "\n",
      "Fold: 14  Epoch: 400  Training loss = 4.4011  Validation loss = 10.6466  \n",
      "\n",
      "Fold: 14  Epoch: 401  Training loss = 4.4007  Validation loss = 10.6458  \n",
      "\n",
      "Fold: 14  Epoch: 402  Training loss = 4.4004  Validation loss = 10.6454  \n",
      "\n",
      "Fold: 14  Epoch: 403  Training loss = 4.4001  Validation loss = 10.6449  \n",
      "\n",
      "Fold: 14  Epoch: 404  Training loss = 4.3997  Validation loss = 10.6444  \n",
      "\n",
      "Fold: 14  Epoch: 405  Training loss = 4.3994  Validation loss = 10.6438  \n",
      "\n",
      "Fold: 14  Epoch: 406  Training loss = 4.3990  Validation loss = 10.6432  \n",
      "\n",
      "Fold: 14  Epoch: 407  Training loss = 4.3985  Validation loss = 10.6425  \n",
      "\n",
      "Fold: 14  Epoch: 408  Training loss = 4.3981  Validation loss = 10.6418  \n",
      "\n",
      "Fold: 14  Epoch: 409  Training loss = 4.3977  Validation loss = 10.6412  \n",
      "\n",
      "Fold: 14  Epoch: 410  Training loss = 4.3973  Validation loss = 10.6405  \n",
      "\n",
      "Fold: 14  Epoch: 411  Training loss = 4.3969  Validation loss = 10.6399  \n",
      "\n",
      "Fold: 14  Epoch: 412  Training loss = 4.3965  Validation loss = 10.6393  \n",
      "\n",
      "Fold: 14  Epoch: 413  Training loss = 4.3961  Validation loss = 10.6387  \n",
      "\n",
      "Fold: 14  Epoch: 414  Training loss = 4.3957  Validation loss = 10.6380  \n",
      "\n",
      "Fold: 14  Epoch: 415  Training loss = 4.3953  Validation loss = 10.6374  \n",
      "\n",
      "Fold: 14  Epoch: 416  Training loss = 4.3949  Validation loss = 10.6367  \n",
      "\n",
      "Fold: 14  Epoch: 417  Training loss = 4.3944  Validation loss = 10.6360  \n",
      "\n",
      "Fold: 14  Epoch: 418  Training loss = 4.3940  Validation loss = 10.6353  \n",
      "\n",
      "Fold: 14  Epoch: 419  Training loss = 4.3936  Validation loss = 10.6347  \n",
      "\n",
      "Fold: 14  Epoch: 420  Training loss = 4.3932  Validation loss = 10.6341  \n",
      "\n",
      "Fold: 14  Epoch: 421  Training loss = 4.3928  Validation loss = 10.6335  \n",
      "\n",
      "Fold: 14  Epoch: 422  Training loss = 4.3925  Validation loss = 10.6330  \n",
      "\n",
      "Fold: 14  Epoch: 423  Training loss = 4.3921  Validation loss = 10.6323  \n",
      "\n",
      "Fold: 14  Epoch: 424  Training loss = 4.3917  Validation loss = 10.6317  \n",
      "\n",
      "Fold: 14  Epoch: 425  Training loss = 4.3913  Validation loss = 10.6310  \n",
      "\n",
      "Fold: 14  Epoch: 426  Training loss = 4.3909  Validation loss = 10.6304  \n",
      "\n",
      "Fold: 14  Epoch: 427  Training loss = 4.3906  Validation loss = 10.6299  \n",
      "\n",
      "Fold: 14  Epoch: 428  Training loss = 4.3902  Validation loss = 10.6293  \n",
      "\n",
      "Fold: 14  Epoch: 429  Training loss = 4.3898  Validation loss = 10.6287  \n",
      "\n",
      "Fold: 14  Epoch: 430  Training loss = 4.3894  Validation loss = 10.6280  \n",
      "\n",
      "Fold: 14  Epoch: 431  Training loss = 4.3890  Validation loss = 10.6274  \n",
      "\n",
      "Fold: 14  Epoch: 432  Training loss = 4.3886  Validation loss = 10.6269  \n",
      "\n",
      "Fold: 14  Epoch: 433  Training loss = 4.3882  Validation loss = 10.6262  \n",
      "\n",
      "Fold: 14  Epoch: 434  Training loss = 4.3878  Validation loss = 10.6255  \n",
      "\n",
      "Fold: 14  Epoch: 435  Training loss = 4.3874  Validation loss = 10.6249  \n",
      "\n",
      "Fold: 14  Epoch: 436  Training loss = 4.3871  Validation loss = 10.6243  \n",
      "\n",
      "Fold: 14  Epoch: 437  Training loss = 4.3866  Validation loss = 10.6236  \n",
      "\n",
      "Fold: 14  Epoch: 438  Training loss = 4.3863  Validation loss = 10.6231  \n",
      "\n",
      "Fold: 14  Epoch: 439  Training loss = 4.3858  Validation loss = 10.6224  \n",
      "\n",
      "Fold: 14  Epoch: 440  Training loss = 4.3854  Validation loss = 10.6217  \n",
      "\n",
      "Fold: 14  Epoch: 441  Training loss = 4.3850  Validation loss = 10.6211  \n",
      "\n",
      "Fold: 14  Epoch: 442  Training loss = 4.3846  Validation loss = 10.6205  \n",
      "\n",
      "Fold: 14  Epoch: 443  Training loss = 4.3842  Validation loss = 10.6198  \n",
      "\n",
      "Fold: 14  Epoch: 444  Training loss = 4.3839  Validation loss = 10.6193  \n",
      "\n",
      "Fold: 14  Epoch: 445  Training loss = 4.3835  Validation loss = 10.6187  \n",
      "\n",
      "Fold: 14  Epoch: 446  Training loss = 4.3831  Validation loss = 10.6181  \n",
      "\n",
      "Fold: 14  Epoch: 447  Training loss = 4.3827  Validation loss = 10.6175  \n",
      "\n",
      "Fold: 14  Epoch: 448  Training loss = 4.3824  Validation loss = 10.6169  \n",
      "\n",
      "Fold: 14  Epoch: 449  Training loss = 4.3820  Validation loss = 10.6164  \n",
      "\n",
      "Fold: 14  Epoch: 450  Training loss = 4.3817  Validation loss = 10.6159  \n",
      "\n",
      "Fold: 14  Epoch: 451  Training loss = 4.3813  Validation loss = 10.6152  \n",
      "\n",
      "Fold: 14  Epoch: 452  Training loss = 4.3810  Validation loss = 10.6147  \n",
      "\n",
      "Fold: 14  Epoch: 453  Training loss = 4.3806  Validation loss = 10.6141  \n",
      "\n",
      "Fold: 14  Epoch: 454  Training loss = 4.3802  Validation loss = 10.6134  \n",
      "\n",
      "Fold: 14  Epoch: 455  Training loss = 4.3798  Validation loss = 10.6128  \n",
      "\n",
      "Fold: 14  Epoch: 456  Training loss = 4.3793  Validation loss = 10.6121  \n",
      "\n",
      "Fold: 14  Epoch: 457  Training loss = 4.3789  Validation loss = 10.6114  \n",
      "\n",
      "Fold: 14  Epoch: 458  Training loss = 4.3785  Validation loss = 10.6108  \n",
      "\n",
      "Fold: 14  Epoch: 459  Training loss = 4.3782  Validation loss = 10.6103  \n",
      "\n",
      "Fold: 14  Epoch: 460  Training loss = 4.3778  Validation loss = 10.6097  \n",
      "\n",
      "Fold: 14  Epoch: 461  Training loss = 4.3774  Validation loss = 10.6091  \n",
      "\n",
      "Fold: 14  Epoch: 462  Training loss = 4.3770  Validation loss = 10.6085  \n",
      "\n",
      "Fold: 14  Epoch: 463  Training loss = 4.3766  Validation loss = 10.6079  \n",
      "\n",
      "Fold: 14  Epoch: 464  Training loss = 4.3762  Validation loss = 10.6072  \n",
      "\n",
      "Fold: 14  Epoch: 465  Training loss = 4.3759  Validation loss = 10.6066  \n",
      "\n",
      "Fold: 14  Epoch: 466  Training loss = 4.3755  Validation loss = 10.6061  \n",
      "\n",
      "Fold: 14  Epoch: 467  Training loss = 4.3751  Validation loss = 10.6055  \n",
      "\n",
      "Fold: 14  Epoch: 468  Training loss = 4.3747  Validation loss = 10.6047  \n",
      "\n",
      "Fold: 14  Epoch: 469  Training loss = 4.3742  Validation loss = 10.6041  \n",
      "\n",
      "Fold: 14  Epoch: 470  Training loss = 4.3738  Validation loss = 10.6035  \n",
      "\n",
      "Fold: 14  Epoch: 471  Training loss = 4.3734  Validation loss = 10.6028  \n",
      "\n",
      "Fold: 14  Epoch: 472  Training loss = 4.3730  Validation loss = 10.6022  \n",
      "\n",
      "Fold: 14  Epoch: 473  Training loss = 4.3727  Validation loss = 10.6016  \n",
      "\n",
      "Fold: 14  Epoch: 474  Training loss = 4.3722  Validation loss = 10.6009  \n",
      "\n",
      "Fold: 14  Epoch: 475  Training loss = 4.3718  Validation loss = 10.6002  \n",
      "\n",
      "Fold: 14  Epoch: 476  Training loss = 4.3714  Validation loss = 10.5997  \n",
      "\n",
      "Fold: 14  Epoch: 477  Training loss = 4.3710  Validation loss = 10.5990  \n",
      "\n",
      "Fold: 14  Epoch: 478  Training loss = 4.3706  Validation loss = 10.5983  \n",
      "\n",
      "Fold: 14  Epoch: 479  Training loss = 4.3702  Validation loss = 10.5977  \n",
      "\n",
      "Fold: 14  Epoch: 480  Training loss = 4.3697  Validation loss = 10.5969  \n",
      "\n",
      "Fold: 14  Epoch: 481  Training loss = 4.3693  Validation loss = 10.5963  \n",
      "\n",
      "Fold: 14  Epoch: 482  Training loss = 4.3689  Validation loss = 10.5956  \n",
      "\n",
      "Fold: 14  Epoch: 483  Training loss = 4.3686  Validation loss = 10.5951  \n",
      "\n",
      "Fold: 14  Epoch: 484  Training loss = 4.3682  Validation loss = 10.5944  \n",
      "\n",
      "Fold: 14  Epoch: 485  Training loss = 4.3678  Validation loss = 10.5939  \n",
      "\n",
      "Fold: 14  Epoch: 486  Training loss = 4.3675  Validation loss = 10.5935  \n",
      "\n",
      "Fold: 14  Epoch: 487  Training loss = 4.3671  Validation loss = 10.5929  \n",
      "\n",
      "Fold: 14  Epoch: 488  Training loss = 4.3668  Validation loss = 10.5923  \n",
      "\n",
      "Fold: 14  Epoch: 489  Training loss = 4.3663  Validation loss = 10.5916  \n",
      "\n",
      "Fold: 14  Epoch: 490  Training loss = 4.3659  Validation loss = 10.5908  \n",
      "\n",
      "Fold: 14  Epoch: 491  Training loss = 4.3654  Validation loss = 10.5901  \n",
      "\n",
      "Fold: 14  Epoch: 492  Training loss = 4.3650  Validation loss = 10.5894  \n",
      "\n",
      "Fold: 14  Epoch: 493  Training loss = 4.3646  Validation loss = 10.5888  \n",
      "\n",
      "Fold: 14  Epoch: 494  Training loss = 4.3642  Validation loss = 10.5882  \n",
      "\n",
      "Fold: 14  Epoch: 495  Training loss = 4.3638  Validation loss = 10.5875  \n",
      "\n",
      "Fold: 14  Epoch: 496  Training loss = 4.3633  Validation loss = 10.5868  \n",
      "\n",
      "Fold: 14  Epoch: 497  Training loss = 4.3630  Validation loss = 10.5863  \n",
      "\n",
      "Fold: 14  Epoch: 498  Training loss = 4.3626  Validation loss = 10.5856  \n",
      "\n",
      "Fold: 14  Epoch: 499  Training loss = 4.3622  Validation loss = 10.5850  \n",
      "\n",
      "Fold: 14  Epoch: 500  Training loss = 4.3618  Validation loss = 10.5843  \n",
      "\n",
      "Check model:  Fold: 14  Optimal epoch: 500  \n",
      "\n",
      "Fold: 15  Epoch: 1  Training loss = 5.0864  Validation loss = 11.1310  \n",
      "\n",
      "Fold: 15  Epoch: 2  Training loss = 5.0858  Validation loss = 11.1303  \n",
      "\n",
      "Fold: 15  Epoch: 3  Training loss = 5.0854  Validation loss = 11.1297  \n",
      "\n",
      "Fold: 15  Epoch: 4  Training loss = 5.0848  Validation loss = 11.1290  \n",
      "\n",
      "Fold: 15  Epoch: 5  Training loss = 5.0843  Validation loss = 11.1284  \n",
      "\n",
      "Fold: 15  Epoch: 6  Training loss = 5.0839  Validation loss = 11.1278  \n",
      "\n",
      "Fold: 15  Epoch: 7  Training loss = 5.0834  Validation loss = 11.1272  \n",
      "\n",
      "Fold: 15  Epoch: 8  Training loss = 5.0829  Validation loss = 11.1266  \n",
      "\n",
      "Fold: 15  Epoch: 9  Training loss = 5.0824  Validation loss = 11.1260  \n",
      "\n",
      "Fold: 15  Epoch: 10  Training loss = 5.0819  Validation loss = 11.1253  \n",
      "\n",
      "Fold: 15  Epoch: 11  Training loss = 5.0814  Validation loss = 11.1247  \n",
      "\n",
      "Fold: 15  Epoch: 12  Training loss = 5.0808  Validation loss = 11.1240  \n",
      "\n",
      "Fold: 15  Epoch: 13  Training loss = 5.0803  Validation loss = 11.1233  \n",
      "\n",
      "Fold: 15  Epoch: 14  Training loss = 5.0798  Validation loss = 11.1226  \n",
      "\n",
      "Fold: 15  Epoch: 15  Training loss = 5.0793  Validation loss = 11.1219  \n",
      "\n",
      "Fold: 15  Epoch: 16  Training loss = 5.0786  Validation loss = 11.1211  \n",
      "\n",
      "Fold: 15  Epoch: 17  Training loss = 5.0781  Validation loss = 11.1204  \n",
      "\n",
      "Fold: 15  Epoch: 18  Training loss = 5.0775  Validation loss = 11.1197  \n",
      "\n",
      "Fold: 15  Epoch: 19  Training loss = 5.0771  Validation loss = 11.1190  \n",
      "\n",
      "Fold: 15  Epoch: 20  Training loss = 5.0765  Validation loss = 11.1182  \n",
      "\n",
      "Fold: 15  Epoch: 21  Training loss = 5.0759  Validation loss = 11.1175  \n",
      "\n",
      "Fold: 15  Epoch: 22  Training loss = 5.0754  Validation loss = 11.1169  \n",
      "\n",
      "Fold: 15  Epoch: 23  Training loss = 5.0749  Validation loss = 11.1163  \n",
      "\n",
      "Fold: 15  Epoch: 24  Training loss = 5.0745  Validation loss = 11.1156  \n",
      "\n",
      "Fold: 15  Epoch: 25  Training loss = 5.0738  Validation loss = 11.1148  \n",
      "\n",
      "Fold: 15  Epoch: 26  Training loss = 5.0734  Validation loss = 11.1142  \n",
      "\n",
      "Fold: 15  Epoch: 27  Training loss = 5.0728  Validation loss = 11.1135  \n",
      "\n",
      "Fold: 15  Epoch: 28  Training loss = 5.0722  Validation loss = 11.1126  \n",
      "\n",
      "Fold: 15  Epoch: 29  Training loss = 5.0717  Validation loss = 11.1120  \n",
      "\n",
      "Fold: 15  Epoch: 30  Training loss = 5.0710  Validation loss = 11.1112  \n",
      "\n",
      "Fold: 15  Epoch: 31  Training loss = 5.0705  Validation loss = 11.1105  \n",
      "\n",
      "Fold: 15  Epoch: 32  Training loss = 5.0700  Validation loss = 11.1098  \n",
      "\n",
      "Fold: 15  Epoch: 33  Training loss = 5.0694  Validation loss = 11.1091  \n",
      "\n",
      "Fold: 15  Epoch: 34  Training loss = 5.0689  Validation loss = 11.1083  \n",
      "\n",
      "Fold: 15  Epoch: 35  Training loss = 5.0683  Validation loss = 11.1077  \n",
      "\n",
      "Fold: 15  Epoch: 36  Training loss = 5.0679  Validation loss = 11.1071  \n",
      "\n",
      "Fold: 15  Epoch: 37  Training loss = 5.0673  Validation loss = 11.1063  \n",
      "\n",
      "Fold: 15  Epoch: 38  Training loss = 5.0668  Validation loss = 11.1057  \n",
      "\n",
      "Fold: 15  Epoch: 39  Training loss = 5.0663  Validation loss = 11.1050  \n",
      "\n",
      "Fold: 15  Epoch: 40  Training loss = 5.0658  Validation loss = 11.1044  \n",
      "\n",
      "Fold: 15  Epoch: 41  Training loss = 5.0653  Validation loss = 11.1038  \n",
      "\n",
      "Fold: 15  Epoch: 42  Training loss = 5.0649  Validation loss = 11.1032  \n",
      "\n",
      "Fold: 15  Epoch: 43  Training loss = 5.0644  Validation loss = 11.1026  \n",
      "\n",
      "Fold: 15  Epoch: 44  Training loss = 5.0639  Validation loss = 11.1019  \n",
      "\n",
      "Fold: 15  Epoch: 45  Training loss = 5.0633  Validation loss = 11.1013  \n",
      "\n",
      "Fold: 15  Epoch: 46  Training loss = 5.0628  Validation loss = 11.1005  \n",
      "\n",
      "Fold: 15  Epoch: 47  Training loss = 5.0623  Validation loss = 11.0999  \n",
      "\n",
      "Fold: 15  Epoch: 48  Training loss = 5.0617  Validation loss = 11.0992  \n",
      "\n",
      "Fold: 15  Epoch: 49  Training loss = 5.0612  Validation loss = 11.0985  \n",
      "\n",
      "Fold: 15  Epoch: 50  Training loss = 5.0606  Validation loss = 11.0977  \n",
      "\n",
      "Fold: 15  Epoch: 51  Training loss = 5.0601  Validation loss = 11.0970  \n",
      "\n",
      "Fold: 15  Epoch: 52  Training loss = 5.0595  Validation loss = 11.0963  \n",
      "\n",
      "Fold: 15  Epoch: 53  Training loss = 5.0590  Validation loss = 11.0957  \n",
      "\n",
      "Fold: 15  Epoch: 54  Training loss = 5.0584  Validation loss = 11.0949  \n",
      "\n",
      "Fold: 15  Epoch: 55  Training loss = 5.0580  Validation loss = 11.0943  \n",
      "\n",
      "Fold: 15  Epoch: 56  Training loss = 5.0574  Validation loss = 11.0935  \n",
      "\n",
      "Fold: 15  Epoch: 57  Training loss = 5.0570  Validation loss = 11.0930  \n",
      "\n",
      "Fold: 15  Epoch: 58  Training loss = 5.0565  Validation loss = 11.0924  \n",
      "\n",
      "Fold: 15  Epoch: 59  Training loss = 5.0559  Validation loss = 11.0916  \n",
      "\n",
      "Fold: 15  Epoch: 60  Training loss = 5.0554  Validation loss = 11.0910  \n",
      "\n",
      "Fold: 15  Epoch: 61  Training loss = 5.0549  Validation loss = 11.0903  \n",
      "\n",
      "Fold: 15  Epoch: 62  Training loss = 5.0544  Validation loss = 11.0897  \n",
      "\n",
      "Fold: 15  Epoch: 63  Training loss = 5.0538  Validation loss = 11.0889  \n",
      "\n",
      "Fold: 15  Epoch: 64  Training loss = 5.0533  Validation loss = 11.0883  \n",
      "\n",
      "Fold: 15  Epoch: 65  Training loss = 5.0528  Validation loss = 11.0876  \n",
      "\n",
      "Fold: 15  Epoch: 66  Training loss = 5.0523  Validation loss = 11.0869  \n",
      "\n",
      "Fold: 15  Epoch: 67  Training loss = 5.0518  Validation loss = 11.0863  \n",
      "\n",
      "Fold: 15  Epoch: 68  Training loss = 5.0513  Validation loss = 11.0857  \n",
      "\n",
      "Fold: 15  Epoch: 69  Training loss = 5.0507  Validation loss = 11.0850  \n",
      "\n",
      "Fold: 15  Epoch: 70  Training loss = 5.0503  Validation loss = 11.0843  \n",
      "\n",
      "Fold: 15  Epoch: 71  Training loss = 5.0496  Validation loss = 11.0834  \n",
      "\n",
      "Fold: 15  Epoch: 72  Training loss = 5.0491  Validation loss = 11.0829  \n",
      "\n",
      "Fold: 15  Epoch: 73  Training loss = 5.0486  Validation loss = 11.0822  \n",
      "\n",
      "Fold: 15  Epoch: 74  Training loss = 5.0481  Validation loss = 11.0815  \n",
      "\n",
      "Fold: 15  Epoch: 75  Training loss = 5.0475  Validation loss = 11.0808  \n",
      "\n",
      "Fold: 15  Epoch: 76  Training loss = 5.0470  Validation loss = 11.0801  \n",
      "\n",
      "Fold: 15  Epoch: 77  Training loss = 5.0465  Validation loss = 11.0795  \n",
      "\n",
      "Fold: 15  Epoch: 78  Training loss = 5.0461  Validation loss = 11.0789  \n",
      "\n",
      "Fold: 15  Epoch: 79  Training loss = 5.0454  Validation loss = 11.0781  \n",
      "\n",
      "Fold: 15  Epoch: 80  Training loss = 5.0448  Validation loss = 11.0774  \n",
      "\n",
      "Fold: 15  Epoch: 81  Training loss = 5.0444  Validation loss = 11.0767  \n",
      "\n",
      "Fold: 15  Epoch: 82  Training loss = 5.0438  Validation loss = 11.0760  \n",
      "\n",
      "Fold: 15  Epoch: 83  Training loss = 5.0434  Validation loss = 11.0754  \n",
      "\n",
      "Fold: 15  Epoch: 84  Training loss = 5.0429  Validation loss = 11.0748  \n",
      "\n",
      "Fold: 15  Epoch: 85  Training loss = 5.0424  Validation loss = 11.0742  \n",
      "\n",
      "Fold: 15  Epoch: 86  Training loss = 5.0420  Validation loss = 11.0737  \n",
      "\n",
      "Fold: 15  Epoch: 87  Training loss = 5.0415  Validation loss = 11.0731  \n",
      "\n",
      "Fold: 15  Epoch: 88  Training loss = 5.0411  Validation loss = 11.0725  \n",
      "\n",
      "Fold: 15  Epoch: 89  Training loss = 5.0405  Validation loss = 11.0717  \n",
      "\n",
      "Fold: 15  Epoch: 90  Training loss = 5.0400  Validation loss = 11.0710  \n",
      "\n",
      "Fold: 15  Epoch: 91  Training loss = 5.0394  Validation loss = 11.0703  \n",
      "\n",
      "Fold: 15  Epoch: 92  Training loss = 5.0388  Validation loss = 11.0695  \n",
      "\n",
      "Fold: 15  Epoch: 93  Training loss = 5.0383  Validation loss = 11.0689  \n",
      "\n",
      "Fold: 15  Epoch: 94  Training loss = 5.0379  Validation loss = 11.0682  \n",
      "\n",
      "Fold: 15  Epoch: 95  Training loss = 5.0374  Validation loss = 11.0676  \n",
      "\n",
      "Fold: 15  Epoch: 96  Training loss = 5.0369  Validation loss = 11.0671  \n",
      "\n",
      "Fold: 15  Epoch: 97  Training loss = 5.0364  Validation loss = 11.0663  \n",
      "\n",
      "Fold: 15  Epoch: 98  Training loss = 5.0358  Validation loss = 11.0656  \n",
      "\n",
      "Fold: 15  Epoch: 99  Training loss = 5.0353  Validation loss = 11.0650  \n",
      "\n",
      "Fold: 15  Epoch: 100  Training loss = 5.0347  Validation loss = 11.0642  \n",
      "\n",
      "Fold: 15  Epoch: 101  Training loss = 5.0343  Validation loss = 11.0636  \n",
      "\n",
      "Fold: 15  Epoch: 102  Training loss = 5.0337  Validation loss = 11.0629  \n",
      "\n",
      "Fold: 15  Epoch: 103  Training loss = 5.0331  Validation loss = 11.0621  \n",
      "\n",
      "Fold: 15  Epoch: 104  Training loss = 5.0326  Validation loss = 11.0615  \n",
      "\n",
      "Fold: 15  Epoch: 105  Training loss = 5.0321  Validation loss = 11.0608  \n",
      "\n",
      "Fold: 15  Epoch: 106  Training loss = 5.0316  Validation loss = 11.0601  \n",
      "\n",
      "Fold: 15  Epoch: 107  Training loss = 5.0311  Validation loss = 11.0595  \n",
      "\n",
      "Fold: 15  Epoch: 108  Training loss = 5.0305  Validation loss = 11.0587  \n",
      "\n",
      "Fold: 15  Epoch: 109  Training loss = 5.0299  Validation loss = 11.0579  \n",
      "\n",
      "Fold: 15  Epoch: 110  Training loss = 5.0294  Validation loss = 11.0573  \n",
      "\n",
      "Fold: 15  Epoch: 111  Training loss = 5.0288  Validation loss = 11.0566  \n",
      "\n",
      "Fold: 15  Epoch: 112  Training loss = 5.0283  Validation loss = 11.0559  \n",
      "\n",
      "Fold: 15  Epoch: 113  Training loss = 5.0278  Validation loss = 11.0552  \n",
      "\n",
      "Fold: 15  Epoch: 114  Training loss = 5.0273  Validation loss = 11.0545  \n",
      "\n",
      "Fold: 15  Epoch: 115  Training loss = 5.0268  Validation loss = 11.0539  \n",
      "\n",
      "Fold: 15  Epoch: 116  Training loss = 5.0263  Validation loss = 11.0532  \n",
      "\n",
      "Fold: 15  Epoch: 117  Training loss = 5.0258  Validation loss = 11.0526  \n",
      "\n",
      "Fold: 15  Epoch: 118  Training loss = 5.0254  Validation loss = 11.0520  \n",
      "\n",
      "Fold: 15  Epoch: 119  Training loss = 5.0248  Validation loss = 11.0513  \n",
      "\n",
      "Fold: 15  Epoch: 120  Training loss = 5.0244  Validation loss = 11.0507  \n",
      "\n",
      "Fold: 15  Epoch: 121  Training loss = 5.0240  Validation loss = 11.0502  \n",
      "\n",
      "Fold: 15  Epoch: 122  Training loss = 5.0234  Validation loss = 11.0494  \n",
      "\n",
      "Fold: 15  Epoch: 123  Training loss = 5.0229  Validation loss = 11.0489  \n",
      "\n",
      "Fold: 15  Epoch: 124  Training loss = 5.0223  Validation loss = 11.0481  \n",
      "\n",
      "Fold: 15  Epoch: 125  Training loss = 5.0218  Validation loss = 11.0474  \n",
      "\n",
      "Fold: 15  Epoch: 126  Training loss = 5.0213  Validation loss = 11.0467  \n",
      "\n",
      "Fold: 15  Epoch: 127  Training loss = 5.0207  Validation loss = 11.0459  \n",
      "\n",
      "Fold: 15  Epoch: 128  Training loss = 5.0201  Validation loss = 11.0452  \n",
      "\n",
      "Fold: 15  Epoch: 129  Training loss = 5.0196  Validation loss = 11.0445  \n",
      "\n",
      "Fold: 15  Epoch: 130  Training loss = 5.0191  Validation loss = 11.0438  \n",
      "\n",
      "Fold: 15  Epoch: 131  Training loss = 5.0186  Validation loss = 11.0432  \n",
      "\n",
      "Fold: 15  Epoch: 132  Training loss = 5.0181  Validation loss = 11.0426  \n",
      "\n",
      "Fold: 15  Epoch: 133  Training loss = 5.0176  Validation loss = 11.0419  \n",
      "\n",
      "Fold: 15  Epoch: 134  Training loss = 5.0171  Validation loss = 11.0413  \n",
      "\n",
      "Fold: 15  Epoch: 135  Training loss = 5.0166  Validation loss = 11.0407  \n",
      "\n",
      "Fold: 15  Epoch: 136  Training loss = 5.0160  Validation loss = 11.0399  \n",
      "\n",
      "Fold: 15  Epoch: 137  Training loss = 5.0154  Validation loss = 11.0391  \n",
      "\n",
      "Fold: 15  Epoch: 138  Training loss = 5.0150  Validation loss = 11.0385  \n",
      "\n",
      "Fold: 15  Epoch: 139  Training loss = 5.0145  Validation loss = 11.0379  \n",
      "\n",
      "Fold: 15  Epoch: 140  Training loss = 5.0140  Validation loss = 11.0371  \n",
      "\n",
      "Fold: 15  Epoch: 141  Training loss = 5.0134  Validation loss = 11.0364  \n",
      "\n",
      "Fold: 15  Epoch: 142  Training loss = 5.0128  Validation loss = 11.0357  \n",
      "\n",
      "Fold: 15  Epoch: 143  Training loss = 5.0123  Validation loss = 11.0350  \n",
      "\n",
      "Fold: 15  Epoch: 144  Training loss = 5.0118  Validation loss = 11.0343  \n",
      "\n",
      "Fold: 15  Epoch: 145  Training loss = 5.0113  Validation loss = 11.0337  \n",
      "\n",
      "Fold: 15  Epoch: 146  Training loss = 5.0108  Validation loss = 11.0330  \n",
      "\n",
      "Fold: 15  Epoch: 147  Training loss = 5.0103  Validation loss = 11.0323  \n",
      "\n",
      "Fold: 15  Epoch: 148  Training loss = 5.0098  Validation loss = 11.0316  \n",
      "\n",
      "Fold: 15  Epoch: 149  Training loss = 5.0093  Validation loss = 11.0310  \n",
      "\n",
      "Fold: 15  Epoch: 150  Training loss = 5.0086  Validation loss = 11.0302  \n",
      "\n",
      "Fold: 15  Epoch: 151  Training loss = 5.0081  Validation loss = 11.0295  \n",
      "\n",
      "Fold: 15  Epoch: 152  Training loss = 5.0076  Validation loss = 11.0288  \n",
      "\n",
      "Fold: 15  Epoch: 153  Training loss = 5.0070  Validation loss = 11.0280  \n",
      "\n",
      "Fold: 15  Epoch: 154  Training loss = 5.0064  Validation loss = 11.0273  \n",
      "\n",
      "Fold: 15  Epoch: 155  Training loss = 5.0058  Validation loss = 11.0264  \n",
      "\n",
      "Fold: 15  Epoch: 156  Training loss = 5.0052  Validation loss = 11.0257  \n",
      "\n",
      "Fold: 15  Epoch: 157  Training loss = 5.0047  Validation loss = 11.0251  \n",
      "\n",
      "Fold: 15  Epoch: 158  Training loss = 5.0042  Validation loss = 11.0243  \n",
      "\n",
      "Fold: 15  Epoch: 159  Training loss = 5.0036  Validation loss = 11.0236  \n",
      "\n",
      "Fold: 15  Epoch: 160  Training loss = 5.0031  Validation loss = 11.0229  \n",
      "\n",
      "Fold: 15  Epoch: 161  Training loss = 5.0026  Validation loss = 11.0223  \n",
      "\n",
      "Fold: 15  Epoch: 162  Training loss = 5.0022  Validation loss = 11.0218  \n",
      "\n",
      "Fold: 15  Epoch: 163  Training loss = 5.0017  Validation loss = 11.0211  \n",
      "\n",
      "Fold: 15  Epoch: 164  Training loss = 5.0011  Validation loss = 11.0204  \n",
      "\n",
      "Fold: 15  Epoch: 165  Training loss = 5.0007  Validation loss = 11.0198  \n",
      "\n",
      "Fold: 15  Epoch: 166  Training loss = 5.0001  Validation loss = 11.0191  \n",
      "\n",
      "Fold: 15  Epoch: 167  Training loss = 4.9996  Validation loss = 11.0184  \n",
      "\n",
      "Fold: 15  Epoch: 168  Training loss = 4.9990  Validation loss = 11.0176  \n",
      "\n",
      "Fold: 15  Epoch: 169  Training loss = 4.9985  Validation loss = 11.0169  \n",
      "\n",
      "Fold: 15  Epoch: 170  Training loss = 4.9980  Validation loss = 11.0163  \n",
      "\n",
      "Fold: 15  Epoch: 171  Training loss = 4.9975  Validation loss = 11.0156  \n",
      "\n",
      "Fold: 15  Epoch: 172  Training loss = 4.9970  Validation loss = 11.0149  \n",
      "\n",
      "Fold: 15  Epoch: 173  Training loss = 4.9964  Validation loss = 11.0142  \n",
      "\n",
      "Fold: 15  Epoch: 174  Training loss = 4.9959  Validation loss = 11.0134  \n",
      "\n",
      "Fold: 15  Epoch: 175  Training loss = 4.9954  Validation loss = 11.0128  \n",
      "\n",
      "Fold: 15  Epoch: 176  Training loss = 4.9949  Validation loss = 11.0121  \n",
      "\n",
      "Fold: 15  Epoch: 177  Training loss = 4.9943  Validation loss = 11.0113  \n",
      "\n",
      "Fold: 15  Epoch: 178  Training loss = 4.9937  Validation loss = 11.0105  \n",
      "\n",
      "Fold: 15  Epoch: 179  Training loss = 4.9931  Validation loss = 11.0098  \n",
      "\n",
      "Fold: 15  Epoch: 180  Training loss = 4.9926  Validation loss = 11.0092  \n",
      "\n",
      "Fold: 15  Epoch: 181  Training loss = 4.9921  Validation loss = 11.0085  \n",
      "\n",
      "Fold: 15  Epoch: 182  Training loss = 4.9916  Validation loss = 11.0079  \n",
      "\n",
      "Fold: 15  Epoch: 183  Training loss = 4.9911  Validation loss = 11.0072  \n",
      "\n",
      "Fold: 15  Epoch: 184  Training loss = 4.9905  Validation loss = 11.0065  \n",
      "\n",
      "Fold: 15  Epoch: 185  Training loss = 4.9899  Validation loss = 11.0057  \n",
      "\n",
      "Fold: 15  Epoch: 186  Training loss = 4.9894  Validation loss = 11.0049  \n",
      "\n",
      "Fold: 15  Epoch: 187  Training loss = 4.9888  Validation loss = 11.0042  \n",
      "\n",
      "Fold: 15  Epoch: 188  Training loss = 4.9883  Validation loss = 11.0035  \n",
      "\n",
      "Fold: 15  Epoch: 189  Training loss = 4.9878  Validation loss = 11.0029  \n",
      "\n",
      "Fold: 15  Epoch: 190  Training loss = 4.9873  Validation loss = 11.0022  \n",
      "\n",
      "Fold: 15  Epoch: 191  Training loss = 4.9868  Validation loss = 11.0016  \n",
      "\n",
      "Fold: 15  Epoch: 192  Training loss = 4.9864  Validation loss = 11.0010  \n",
      "\n",
      "Fold: 15  Epoch: 193  Training loss = 4.9858  Validation loss = 11.0002  \n",
      "\n",
      "Fold: 15  Epoch: 194  Training loss = 4.9853  Validation loss = 10.9995  \n",
      "\n",
      "Fold: 15  Epoch: 195  Training loss = 4.9847  Validation loss = 10.9988  \n",
      "\n",
      "Fold: 15  Epoch: 196  Training loss = 4.9843  Validation loss = 10.9982  \n",
      "\n",
      "Fold: 15  Epoch: 197  Training loss = 4.9838  Validation loss = 10.9976  \n",
      "\n",
      "Fold: 15  Epoch: 198  Training loss = 4.9833  Validation loss = 10.9970  \n",
      "\n",
      "Fold: 15  Epoch: 199  Training loss = 4.9828  Validation loss = 10.9963  \n",
      "\n",
      "Fold: 15  Epoch: 200  Training loss = 4.9823  Validation loss = 10.9956  \n",
      "\n",
      "Fold: 15  Epoch: 201  Training loss = 4.9818  Validation loss = 10.9949  \n",
      "\n",
      "Fold: 15  Epoch: 202  Training loss = 4.9813  Validation loss = 10.9943  \n",
      "\n",
      "Fold: 15  Epoch: 203  Training loss = 4.9809  Validation loss = 10.9937  \n",
      "\n",
      "Fold: 15  Epoch: 204  Training loss = 4.9804  Validation loss = 10.9931  \n",
      "\n",
      "Fold: 15  Epoch: 205  Training loss = 4.9799  Validation loss = 10.9924  \n",
      "\n",
      "Fold: 15  Epoch: 206  Training loss = 4.9794  Validation loss = 10.9917  \n",
      "\n",
      "Fold: 15  Epoch: 207  Training loss = 4.9789  Validation loss = 10.9911  \n",
      "\n",
      "Fold: 15  Epoch: 208  Training loss = 4.9784  Validation loss = 10.9905  \n",
      "\n",
      "Fold: 15  Epoch: 209  Training loss = 4.9779  Validation loss = 10.9897  \n",
      "\n",
      "Fold: 15  Epoch: 210  Training loss = 4.9774  Validation loss = 10.9891  \n",
      "\n",
      "Fold: 15  Epoch: 211  Training loss = 4.9768  Validation loss = 10.9883  \n",
      "\n",
      "Fold: 15  Epoch: 212  Training loss = 4.9763  Validation loss = 10.9876  \n",
      "\n",
      "Fold: 15  Epoch: 213  Training loss = 4.9757  Validation loss = 10.9868  \n",
      "\n",
      "Fold: 15  Epoch: 214  Training loss = 4.9752  Validation loss = 10.9862  \n",
      "\n",
      "Fold: 15  Epoch: 215  Training loss = 4.9747  Validation loss = 10.9855  \n",
      "\n",
      "Fold: 15  Epoch: 216  Training loss = 4.9742  Validation loss = 10.9849  \n",
      "\n",
      "Fold: 15  Epoch: 217  Training loss = 4.9737  Validation loss = 10.9843  \n",
      "\n",
      "Fold: 15  Epoch: 218  Training loss = 4.9731  Validation loss = 10.9835  \n",
      "\n",
      "Fold: 15  Epoch: 219  Training loss = 4.9726  Validation loss = 10.9827  \n",
      "\n",
      "Fold: 15  Epoch: 220  Training loss = 4.9720  Validation loss = 10.9820  \n",
      "\n",
      "Fold: 15  Epoch: 221  Training loss = 4.9715  Validation loss = 10.9813  \n",
      "\n",
      "Fold: 15  Epoch: 222  Training loss = 4.9708  Validation loss = 10.9804  \n",
      "\n",
      "Fold: 15  Epoch: 223  Training loss = 4.9703  Validation loss = 10.9797  \n",
      "\n",
      "Fold: 15  Epoch: 224  Training loss = 4.9698  Validation loss = 10.9791  \n",
      "\n",
      "Fold: 15  Epoch: 225  Training loss = 4.9693  Validation loss = 10.9784  \n",
      "\n",
      "Fold: 15  Epoch: 226  Training loss = 4.9688  Validation loss = 10.9778  \n",
      "\n",
      "Fold: 15  Epoch: 227  Training loss = 4.9682  Validation loss = 10.9770  \n",
      "\n",
      "Fold: 15  Epoch: 228  Training loss = 4.9677  Validation loss = 10.9763  \n",
      "\n",
      "Fold: 15  Epoch: 229  Training loss = 4.9672  Validation loss = 10.9756  \n",
      "\n",
      "Fold: 15  Epoch: 230  Training loss = 4.9667  Validation loss = 10.9750  \n",
      "\n",
      "Fold: 15  Epoch: 231  Training loss = 4.9662  Validation loss = 10.9743  \n",
      "\n",
      "Fold: 15  Epoch: 232  Training loss = 4.9656  Validation loss = 10.9736  \n",
      "\n",
      "Fold: 15  Epoch: 233  Training loss = 4.9652  Validation loss = 10.9729  \n",
      "\n",
      "Fold: 15  Epoch: 234  Training loss = 4.9648  Validation loss = 10.9724  \n",
      "\n",
      "Fold: 15  Epoch: 235  Training loss = 4.9642  Validation loss = 10.9717  \n",
      "\n",
      "Fold: 15  Epoch: 236  Training loss = 4.9637  Validation loss = 10.9709  \n",
      "\n",
      "Fold: 15  Epoch: 237  Training loss = 4.9630  Validation loss = 10.9700  \n",
      "\n",
      "Fold: 15  Epoch: 238  Training loss = 4.9624  Validation loss = 10.9692  \n",
      "\n",
      "Fold: 15  Epoch: 239  Training loss = 4.9619  Validation loss = 10.9686  \n",
      "\n",
      "Fold: 15  Epoch: 240  Training loss = 4.9613  Validation loss = 10.9678  \n",
      "\n",
      "Fold: 15  Epoch: 241  Training loss = 4.9608  Validation loss = 10.9671  \n",
      "\n",
      "Fold: 15  Epoch: 242  Training loss = 4.9603  Validation loss = 10.9663  \n",
      "\n",
      "Fold: 15  Epoch: 243  Training loss = 4.9598  Validation loss = 10.9657  \n",
      "\n",
      "Fold: 15  Epoch: 244  Training loss = 4.9593  Validation loss = 10.9650  \n",
      "\n",
      "Fold: 15  Epoch: 245  Training loss = 4.9587  Validation loss = 10.9643  \n",
      "\n",
      "Fold: 15  Epoch: 246  Training loss = 4.9582  Validation loss = 10.9636  \n",
      "\n",
      "Fold: 15  Epoch: 247  Training loss = 4.9577  Validation loss = 10.9629  \n",
      "\n",
      "Fold: 15  Epoch: 248  Training loss = 4.9571  Validation loss = 10.9621  \n",
      "\n",
      "Fold: 15  Epoch: 249  Training loss = 4.9565  Validation loss = 10.9613  \n",
      "\n",
      "Fold: 15  Epoch: 250  Training loss = 4.9561  Validation loss = 10.9607  \n",
      "\n",
      "Fold: 15  Epoch: 251  Training loss = 4.9555  Validation loss = 10.9599  \n",
      "\n",
      "Fold: 15  Epoch: 252  Training loss = 4.9550  Validation loss = 10.9593  \n",
      "\n",
      "Fold: 15  Epoch: 253  Training loss = 4.9545  Validation loss = 10.9586  \n",
      "\n",
      "Fold: 15  Epoch: 254  Training loss = 4.9539  Validation loss = 10.9578  \n",
      "\n",
      "Fold: 15  Epoch: 255  Training loss = 4.9534  Validation loss = 10.9571  \n",
      "\n",
      "Fold: 15  Epoch: 256  Training loss = 4.9527  Validation loss = 10.9563  \n",
      "\n",
      "Fold: 15  Epoch: 257  Training loss = 4.9522  Validation loss = 10.9556  \n",
      "\n",
      "Fold: 15  Epoch: 258  Training loss = 4.9517  Validation loss = 10.9549  \n",
      "\n",
      "Fold: 15  Epoch: 259  Training loss = 4.9512  Validation loss = 10.9542  \n",
      "\n",
      "Fold: 15  Epoch: 260  Training loss = 4.9506  Validation loss = 10.9535  \n",
      "\n",
      "Fold: 15  Epoch: 261  Training loss = 4.9501  Validation loss = 10.9528  \n",
      "\n",
      "Fold: 15  Epoch: 262  Training loss = 4.9496  Validation loss = 10.9521  \n",
      "\n",
      "Fold: 15  Epoch: 263  Training loss = 4.9491  Validation loss = 10.9514  \n",
      "\n",
      "Fold: 15  Epoch: 264  Training loss = 4.9486  Validation loss = 10.9508  \n",
      "\n",
      "Fold: 15  Epoch: 265  Training loss = 4.9480  Validation loss = 10.9500  \n",
      "\n",
      "Fold: 15  Epoch: 266  Training loss = 4.9475  Validation loss = 10.9493  \n",
      "\n",
      "Fold: 15  Epoch: 267  Training loss = 4.9470  Validation loss = 10.9486  \n",
      "\n",
      "Fold: 15  Epoch: 268  Training loss = 4.9465  Validation loss = 10.9480  \n",
      "\n",
      "Fold: 15  Epoch: 269  Training loss = 4.9459  Validation loss = 10.9472  \n",
      "\n",
      "Fold: 15  Epoch: 270  Training loss = 4.9455  Validation loss = 10.9466  \n",
      "\n",
      "Fold: 15  Epoch: 271  Training loss = 4.9449  Validation loss = 10.9458  \n",
      "\n",
      "Fold: 15  Epoch: 272  Training loss = 4.9445  Validation loss = 10.9452  \n",
      "\n",
      "Fold: 15  Epoch: 273  Training loss = 4.9440  Validation loss = 10.9446  \n",
      "\n",
      "Fold: 15  Epoch: 274  Training loss = 4.9435  Validation loss = 10.9439  \n",
      "\n",
      "Fold: 15  Epoch: 275  Training loss = 4.9431  Validation loss = 10.9434  \n",
      "\n",
      "Fold: 15  Epoch: 276  Training loss = 4.9426  Validation loss = 10.9427  \n",
      "\n",
      "Fold: 15  Epoch: 277  Training loss = 4.9421  Validation loss = 10.9420  \n",
      "\n",
      "Fold: 15  Epoch: 278  Training loss = 4.9415  Validation loss = 10.9412  \n",
      "\n",
      "Fold: 15  Epoch: 279  Training loss = 4.9409  Validation loss = 10.9405  \n",
      "\n",
      "Fold: 15  Epoch: 280  Training loss = 4.9405  Validation loss = 10.9399  \n",
      "\n",
      "Fold: 15  Epoch: 281  Training loss = 4.9400  Validation loss = 10.9393  \n",
      "\n",
      "Fold: 15  Epoch: 282  Training loss = 4.9394  Validation loss = 10.9385  \n",
      "\n",
      "Fold: 15  Epoch: 283  Training loss = 4.9389  Validation loss = 10.9377  \n",
      "\n",
      "Fold: 15  Epoch: 284  Training loss = 4.9383  Validation loss = 10.9370  \n",
      "\n",
      "Fold: 15  Epoch: 285  Training loss = 4.9379  Validation loss = 10.9364  \n",
      "\n",
      "Fold: 15  Epoch: 286  Training loss = 4.9374  Validation loss = 10.9358  \n",
      "\n",
      "Fold: 15  Epoch: 287  Training loss = 4.9369  Validation loss = 10.9351  \n",
      "\n",
      "Fold: 15  Epoch: 288  Training loss = 4.9363  Validation loss = 10.9343  \n",
      "\n",
      "Fold: 15  Epoch: 289  Training loss = 4.9358  Validation loss = 10.9336  \n",
      "\n",
      "Fold: 15  Epoch: 290  Training loss = 4.9353  Validation loss = 10.9329  \n",
      "\n",
      "Fold: 15  Epoch: 291  Training loss = 4.9348  Validation loss = 10.9322  \n",
      "\n",
      "Fold: 15  Epoch: 292  Training loss = 4.9343  Validation loss = 10.9316  \n",
      "\n",
      "Fold: 15  Epoch: 293  Training loss = 4.9338  Validation loss = 10.9309  \n",
      "\n",
      "Fold: 15  Epoch: 294  Training loss = 4.9333  Validation loss = 10.9302  \n",
      "\n",
      "Fold: 15  Epoch: 295  Training loss = 4.9327  Validation loss = 10.9295  \n",
      "\n",
      "Fold: 15  Epoch: 296  Training loss = 4.9323  Validation loss = 10.9289  \n",
      "\n",
      "Fold: 15  Epoch: 297  Training loss = 4.9317  Validation loss = 10.9281  \n",
      "\n",
      "Fold: 15  Epoch: 298  Training loss = 4.9312  Validation loss = 10.9275  \n",
      "\n",
      "Fold: 15  Epoch: 299  Training loss = 4.9307  Validation loss = 10.9268  \n",
      "\n",
      "Fold: 15  Epoch: 300  Training loss = 4.9302  Validation loss = 10.9262  \n",
      "\n",
      "Fold: 15  Epoch: 301  Training loss = 4.9296  Validation loss = 10.9254  \n",
      "\n",
      "Fold: 15  Epoch: 302  Training loss = 4.9292  Validation loss = 10.9248  \n",
      "\n",
      "Fold: 15  Epoch: 303  Training loss = 4.9287  Validation loss = 10.9242  \n",
      "\n",
      "Fold: 15  Epoch: 304  Training loss = 4.9282  Validation loss = 10.9235  \n",
      "\n",
      "Fold: 15  Epoch: 305  Training loss = 4.9277  Validation loss = 10.9228  \n",
      "\n",
      "Fold: 15  Epoch: 306  Training loss = 4.9272  Validation loss = 10.9221  \n",
      "\n",
      "Fold: 15  Epoch: 307  Training loss = 4.9267  Validation loss = 10.9214  \n",
      "\n",
      "Fold: 15  Epoch: 308  Training loss = 4.9262  Validation loss = 10.9208  \n",
      "\n",
      "Fold: 15  Epoch: 309  Training loss = 4.9257  Validation loss = 10.9201  \n",
      "\n",
      "Fold: 15  Epoch: 310  Training loss = 4.9251  Validation loss = 10.9193  \n",
      "\n",
      "Fold: 15  Epoch: 311  Training loss = 4.9247  Validation loss = 10.9188  \n",
      "\n",
      "Fold: 15  Epoch: 312  Training loss = 4.9241  Validation loss = 10.9180  \n",
      "\n",
      "Fold: 15  Epoch: 313  Training loss = 4.9236  Validation loss = 10.9173  \n",
      "\n",
      "Fold: 15  Epoch: 314  Training loss = 4.9231  Validation loss = 10.9165  \n",
      "\n",
      "Fold: 15  Epoch: 315  Training loss = 4.9224  Validation loss = 10.9157  \n",
      "\n",
      "Fold: 15  Epoch: 316  Training loss = 4.9220  Validation loss = 10.9150  \n",
      "\n",
      "Fold: 15  Epoch: 317  Training loss = 4.9214  Validation loss = 10.9143  \n",
      "\n",
      "Fold: 15  Epoch: 318  Training loss = 4.9209  Validation loss = 10.9136  \n",
      "\n",
      "Fold: 15  Epoch: 319  Training loss = 4.9204  Validation loss = 10.9129  \n",
      "\n",
      "Fold: 15  Epoch: 320  Training loss = 4.9200  Validation loss = 10.9123  \n",
      "\n",
      "Fold: 15  Epoch: 321  Training loss = 4.9196  Validation loss = 10.9117  \n",
      "\n",
      "Fold: 15  Epoch: 322  Training loss = 4.9191  Validation loss = 10.9111  \n",
      "\n",
      "Fold: 15  Epoch: 323  Training loss = 4.9186  Validation loss = 10.9104  \n",
      "\n",
      "Fold: 15  Epoch: 324  Training loss = 4.9181  Validation loss = 10.9098  \n",
      "\n",
      "Fold: 15  Epoch: 325  Training loss = 4.9176  Validation loss = 10.9092  \n",
      "\n",
      "Fold: 15  Epoch: 326  Training loss = 4.9171  Validation loss = 10.9084  \n",
      "\n",
      "Fold: 15  Epoch: 327  Training loss = 4.9165  Validation loss = 10.9077  \n",
      "\n",
      "Fold: 15  Epoch: 328  Training loss = 4.9161  Validation loss = 10.9071  \n",
      "\n",
      "Fold: 15  Epoch: 329  Training loss = 4.9156  Validation loss = 10.9065  \n",
      "\n",
      "Fold: 15  Epoch: 330  Training loss = 4.9151  Validation loss = 10.9057  \n",
      "\n",
      "Fold: 15  Epoch: 331  Training loss = 4.9145  Validation loss = 10.9050  \n",
      "\n",
      "Fold: 15  Epoch: 332  Training loss = 4.9140  Validation loss = 10.9043  \n",
      "\n",
      "Fold: 15  Epoch: 333  Training loss = 4.9135  Validation loss = 10.9037  \n",
      "\n",
      "Fold: 15  Epoch: 334  Training loss = 4.9131  Validation loss = 10.9031  \n",
      "\n",
      "Fold: 15  Epoch: 335  Training loss = 4.9125  Validation loss = 10.9023  \n",
      "\n",
      "Fold: 15  Epoch: 336  Training loss = 4.9121  Validation loss = 10.9017  \n",
      "\n",
      "Fold: 15  Epoch: 337  Training loss = 4.9116  Validation loss = 10.9011  \n",
      "\n",
      "Fold: 15  Epoch: 338  Training loss = 4.9111  Validation loss = 10.9004  \n",
      "\n",
      "Fold: 15  Epoch: 339  Training loss = 4.9106  Validation loss = 10.8996  \n",
      "\n",
      "Fold: 15  Epoch: 340  Training loss = 4.9100  Validation loss = 10.8989  \n",
      "\n",
      "Fold: 15  Epoch: 341  Training loss = 4.9096  Validation loss = 10.8983  \n",
      "\n",
      "Fold: 15  Epoch: 342  Training loss = 4.9092  Validation loss = 10.8978  \n",
      "\n",
      "Fold: 15  Epoch: 343  Training loss = 4.9085  Validation loss = 10.8969  \n",
      "\n",
      "Fold: 15  Epoch: 344  Training loss = 4.9081  Validation loss = 10.8963  \n",
      "\n",
      "Fold: 15  Epoch: 345  Training loss = 4.9076  Validation loss = 10.8957  \n",
      "\n",
      "Fold: 15  Epoch: 346  Training loss = 4.9070  Validation loss = 10.8949  \n",
      "\n",
      "Fold: 15  Epoch: 347  Training loss = 4.9065  Validation loss = 10.8941  \n",
      "\n",
      "Fold: 15  Epoch: 348  Training loss = 4.9059  Validation loss = 10.8934  \n",
      "\n",
      "Fold: 15  Epoch: 349  Training loss = 4.9054  Validation loss = 10.8928  \n",
      "\n",
      "Fold: 15  Epoch: 350  Training loss = 4.9050  Validation loss = 10.8921  \n",
      "\n",
      "Fold: 15  Epoch: 351  Training loss = 4.9044  Validation loss = 10.8913  \n",
      "\n",
      "Fold: 15  Epoch: 352  Training loss = 4.9039  Validation loss = 10.8907  \n",
      "\n",
      "Fold: 15  Epoch: 353  Training loss = 4.9033  Validation loss = 10.8899  \n",
      "\n",
      "Fold: 15  Epoch: 354  Training loss = 4.9027  Validation loss = 10.8890  \n",
      "\n",
      "Fold: 15  Epoch: 355  Training loss = 4.9022  Validation loss = 10.8884  \n",
      "\n",
      "Fold: 15  Epoch: 356  Training loss = 4.9018  Validation loss = 10.8878  \n",
      "\n",
      "Fold: 15  Epoch: 357  Training loss = 4.9013  Validation loss = 10.8871  \n",
      "\n",
      "Fold: 15  Epoch: 358  Training loss = 4.9008  Validation loss = 10.8865  \n",
      "\n",
      "Fold: 15  Epoch: 359  Training loss = 4.9004  Validation loss = 10.8859  \n",
      "\n",
      "Fold: 15  Epoch: 360  Training loss = 4.8999  Validation loss = 10.8852  \n",
      "\n",
      "Fold: 15  Epoch: 361  Training loss = 4.8993  Validation loss = 10.8844  \n",
      "\n",
      "Fold: 15  Epoch: 362  Training loss = 4.8987  Validation loss = 10.8836  \n",
      "\n",
      "Fold: 15  Epoch: 363  Training loss = 4.8981  Validation loss = 10.8827  \n",
      "\n",
      "Fold: 15  Epoch: 364  Training loss = 4.8975  Validation loss = 10.8820  \n",
      "\n",
      "Fold: 15  Epoch: 365  Training loss = 4.8970  Validation loss = 10.8812  \n",
      "\n",
      "Fold: 15  Epoch: 366  Training loss = 4.8965  Validation loss = 10.8805  \n",
      "\n",
      "Fold: 15  Epoch: 367  Training loss = 4.8960  Validation loss = 10.8799  \n",
      "\n",
      "Fold: 15  Epoch: 368  Training loss = 4.8955  Validation loss = 10.8791  \n",
      "\n",
      "Fold: 15  Epoch: 369  Training loss = 4.8948  Validation loss = 10.8783  \n",
      "\n",
      "Fold: 15  Epoch: 370  Training loss = 4.8943  Validation loss = 10.8776  \n",
      "\n",
      "Fold: 15  Epoch: 371  Training loss = 4.8939  Validation loss = 10.8770  \n",
      "\n",
      "Fold: 15  Epoch: 372  Training loss = 4.8935  Validation loss = 10.8764  \n",
      "\n",
      "Fold: 15  Epoch: 373  Training loss = 4.8930  Validation loss = 10.8757  \n",
      "\n",
      "Fold: 15  Epoch: 374  Training loss = 4.8925  Validation loss = 10.8750  \n",
      "\n",
      "Fold: 15  Epoch: 375  Training loss = 4.8918  Validation loss = 10.8741  \n",
      "\n",
      "Fold: 15  Epoch: 376  Training loss = 4.8912  Validation loss = 10.8733  \n",
      "\n",
      "Fold: 15  Epoch: 377  Training loss = 4.8906  Validation loss = 10.8725  \n",
      "\n",
      "Fold: 15  Epoch: 378  Training loss = 4.8901  Validation loss = 10.8718  \n",
      "\n",
      "Fold: 15  Epoch: 379  Training loss = 4.8895  Validation loss = 10.8710  \n",
      "\n",
      "Fold: 15  Epoch: 380  Training loss = 4.8890  Validation loss = 10.8703  \n",
      "\n",
      "Fold: 15  Epoch: 381  Training loss = 4.8885  Validation loss = 10.8695  \n",
      "\n",
      "Fold: 15  Epoch: 382  Training loss = 4.8880  Validation loss = 10.8689  \n",
      "\n",
      "Fold: 15  Epoch: 383  Training loss = 4.8876  Validation loss = 10.8683  \n",
      "\n",
      "Fold: 15  Epoch: 384  Training loss = 4.8872  Validation loss = 10.8677  \n",
      "\n",
      "Fold: 15  Epoch: 385  Training loss = 4.8865  Validation loss = 10.8668  \n",
      "\n",
      "Fold: 15  Epoch: 386  Training loss = 4.8859  Validation loss = 10.8661  \n",
      "\n",
      "Fold: 15  Epoch: 387  Training loss = 4.8855  Validation loss = 10.8655  \n",
      "\n",
      "Fold: 15  Epoch: 388  Training loss = 4.8850  Validation loss = 10.8648  \n",
      "\n",
      "Fold: 15  Epoch: 389  Training loss = 4.8845  Validation loss = 10.8641  \n",
      "\n",
      "Fold: 15  Epoch: 390  Training loss = 4.8839  Validation loss = 10.8633  \n",
      "\n",
      "Fold: 15  Epoch: 391  Training loss = 4.8835  Validation loss = 10.8627  \n",
      "\n",
      "Fold: 15  Epoch: 392  Training loss = 4.8830  Validation loss = 10.8620  \n",
      "\n",
      "Fold: 15  Epoch: 393  Training loss = 4.8824  Validation loss = 10.8613  \n",
      "\n",
      "Fold: 15  Epoch: 394  Training loss = 4.8818  Validation loss = 10.8604  \n",
      "\n",
      "Fold: 15  Epoch: 395  Training loss = 4.8811  Validation loss = 10.8594  \n",
      "\n",
      "Fold: 15  Epoch: 396  Training loss = 4.8806  Validation loss = 10.8587  \n",
      "\n",
      "Fold: 15  Epoch: 397  Training loss = 4.8801  Validation loss = 10.8580  \n",
      "\n",
      "Fold: 15  Epoch: 398  Training loss = 4.8795  Validation loss = 10.8572  \n",
      "\n",
      "Fold: 15  Epoch: 399  Training loss = 4.8789  Validation loss = 10.8565  \n",
      "\n",
      "Fold: 15  Epoch: 400  Training loss = 4.8784  Validation loss = 10.8557  \n",
      "\n",
      "Fold: 15  Epoch: 401  Training loss = 4.8779  Validation loss = 10.8550  \n",
      "\n",
      "Fold: 15  Epoch: 402  Training loss = 4.8774  Validation loss = 10.8543  \n",
      "\n",
      "Fold: 15  Epoch: 403  Training loss = 4.8769  Validation loss = 10.8536  \n",
      "\n",
      "Fold: 15  Epoch: 404  Training loss = 4.8763  Validation loss = 10.8528  \n",
      "\n",
      "Fold: 15  Epoch: 405  Training loss = 4.8759  Validation loss = 10.8522  \n",
      "\n",
      "Fold: 15  Epoch: 406  Training loss = 4.8754  Validation loss = 10.8515  \n",
      "\n",
      "Fold: 15  Epoch: 407  Training loss = 4.8749  Validation loss = 10.8509  \n",
      "\n",
      "Fold: 15  Epoch: 408  Training loss = 4.8744  Validation loss = 10.8501  \n",
      "\n",
      "Fold: 15  Epoch: 409  Training loss = 4.8738  Validation loss = 10.8493  \n",
      "\n",
      "Fold: 15  Epoch: 410  Training loss = 4.8733  Validation loss = 10.8487  \n",
      "\n",
      "Fold: 15  Epoch: 411  Training loss = 4.8729  Validation loss = 10.8481  \n",
      "\n",
      "Fold: 15  Epoch: 412  Training loss = 4.8724  Validation loss = 10.8474  \n",
      "\n",
      "Fold: 15  Epoch: 413  Training loss = 4.8718  Validation loss = 10.8466  \n",
      "\n",
      "Fold: 15  Epoch: 414  Training loss = 4.8713  Validation loss = 10.8459  \n",
      "\n",
      "Fold: 15  Epoch: 415  Training loss = 4.8707  Validation loss = 10.8451  \n",
      "\n",
      "Fold: 15  Epoch: 416  Training loss = 4.8702  Validation loss = 10.8444  \n",
      "\n",
      "Fold: 15  Epoch: 417  Training loss = 4.8696  Validation loss = 10.8436  \n",
      "\n",
      "Fold: 15  Epoch: 418  Training loss = 4.8691  Validation loss = 10.8429  \n",
      "\n",
      "Fold: 15  Epoch: 419  Training loss = 4.8685  Validation loss = 10.8421  \n",
      "\n",
      "Fold: 15  Epoch: 420  Training loss = 4.8680  Validation loss = 10.8414  \n",
      "\n",
      "Fold: 15  Epoch: 421  Training loss = 4.8675  Validation loss = 10.8407  \n",
      "\n",
      "Fold: 15  Epoch: 422  Training loss = 4.8669  Validation loss = 10.8398  \n",
      "\n",
      "Fold: 15  Epoch: 423  Training loss = 4.8663  Validation loss = 10.8391  \n",
      "\n",
      "Fold: 15  Epoch: 424  Training loss = 4.8657  Validation loss = 10.8382  \n",
      "\n",
      "Fold: 15  Epoch: 425  Training loss = 4.8653  Validation loss = 10.8377  \n",
      "\n",
      "Fold: 15  Epoch: 426  Training loss = 4.8648  Validation loss = 10.8369  \n",
      "\n",
      "Fold: 15  Epoch: 427  Training loss = 4.8643  Validation loss = 10.8362  \n",
      "\n",
      "Fold: 15  Epoch: 428  Training loss = 4.8637  Validation loss = 10.8354  \n",
      "\n",
      "Fold: 15  Epoch: 429  Training loss = 4.8631  Validation loss = 10.8346  \n",
      "\n",
      "Fold: 15  Epoch: 430  Training loss = 4.8626  Validation loss = 10.8339  \n",
      "\n",
      "Fold: 15  Epoch: 431  Training loss = 4.8620  Validation loss = 10.8331  \n",
      "\n",
      "Fold: 15  Epoch: 432  Training loss = 4.8615  Validation loss = 10.8323  \n",
      "\n",
      "Fold: 15  Epoch: 433  Training loss = 4.8609  Validation loss = 10.8316  \n",
      "\n",
      "Fold: 15  Epoch: 434  Training loss = 4.8605  Validation loss = 10.8309  \n",
      "\n",
      "Fold: 15  Epoch: 435  Training loss = 4.8600  Validation loss = 10.8303  \n",
      "\n",
      "Fold: 15  Epoch: 436  Training loss = 4.8596  Validation loss = 10.8297  \n",
      "\n",
      "Fold: 15  Epoch: 437  Training loss = 4.8591  Validation loss = 10.8290  \n",
      "\n",
      "Fold: 15  Epoch: 438  Training loss = 4.8586  Validation loss = 10.8284  \n",
      "\n",
      "Fold: 15  Epoch: 439  Training loss = 4.8581  Validation loss = 10.8276  \n",
      "\n",
      "Fold: 15  Epoch: 440  Training loss = 4.8576  Validation loss = 10.8269  \n",
      "\n",
      "Fold: 15  Epoch: 441  Training loss = 4.8571  Validation loss = 10.8262  \n",
      "\n",
      "Fold: 15  Epoch: 442  Training loss = 4.8567  Validation loss = 10.8256  \n",
      "\n",
      "Fold: 15  Epoch: 443  Training loss = 4.8562  Validation loss = 10.8250  \n",
      "\n",
      "Fold: 15  Epoch: 444  Training loss = 4.8558  Validation loss = 10.8245  \n",
      "\n",
      "Fold: 15  Epoch: 445  Training loss = 4.8554  Validation loss = 10.8238  \n",
      "\n",
      "Fold: 15  Epoch: 446  Training loss = 4.8548  Validation loss = 10.8231  \n",
      "\n",
      "Fold: 15  Epoch: 447  Training loss = 4.8543  Validation loss = 10.8224  \n",
      "\n",
      "Fold: 15  Epoch: 448  Training loss = 4.8538  Validation loss = 10.8216  \n",
      "\n",
      "Fold: 15  Epoch: 449  Training loss = 4.8533  Validation loss = 10.8209  \n",
      "\n",
      "Fold: 15  Epoch: 450  Training loss = 4.8527  Validation loss = 10.8201  \n",
      "\n",
      "Fold: 15  Epoch: 451  Training loss = 4.8522  Validation loss = 10.8194  \n",
      "\n",
      "Fold: 15  Epoch: 452  Training loss = 4.8515  Validation loss = 10.8185  \n",
      "\n",
      "Fold: 15  Epoch: 453  Training loss = 4.8509  Validation loss = 10.8177  \n",
      "\n",
      "Fold: 15  Epoch: 454  Training loss = 4.8504  Validation loss = 10.8170  \n",
      "\n",
      "Fold: 15  Epoch: 455  Training loss = 4.8498  Validation loss = 10.8162  \n",
      "\n",
      "Fold: 15  Epoch: 456  Training loss = 4.8494  Validation loss = 10.8155  \n",
      "\n",
      "Fold: 15  Epoch: 457  Training loss = 4.8489  Validation loss = 10.8148  \n",
      "\n",
      "Fold: 15  Epoch: 458  Training loss = 4.8484  Validation loss = 10.8141  \n",
      "\n",
      "Fold: 15  Epoch: 459  Training loss = 4.8479  Validation loss = 10.8135  \n",
      "\n",
      "Fold: 15  Epoch: 460  Training loss = 4.8475  Validation loss = 10.8129  \n",
      "\n",
      "Fold: 15  Epoch: 461  Training loss = 4.8468  Validation loss = 10.8119  \n",
      "\n",
      "Fold: 15  Epoch: 462  Training loss = 4.8463  Validation loss = 10.8112  \n",
      "\n",
      "Fold: 15  Epoch: 463  Training loss = 4.8458  Validation loss = 10.8104  \n",
      "\n",
      "Fold: 15  Epoch: 464  Training loss = 4.8452  Validation loss = 10.8097  \n",
      "\n",
      "Fold: 15  Epoch: 465  Training loss = 4.8446  Validation loss = 10.8088  \n",
      "\n",
      "Fold: 15  Epoch: 466  Training loss = 4.8440  Validation loss = 10.8080  \n",
      "\n",
      "Fold: 15  Epoch: 467  Training loss = 4.8435  Validation loss = 10.8073  \n",
      "\n",
      "Fold: 15  Epoch: 468  Training loss = 4.8430  Validation loss = 10.8066  \n",
      "\n",
      "Fold: 15  Epoch: 469  Training loss = 4.8424  Validation loss = 10.8058  \n",
      "\n",
      "Fold: 15  Epoch: 470  Training loss = 4.8419  Validation loss = 10.8050  \n",
      "\n",
      "Fold: 15  Epoch: 471  Training loss = 4.8414  Validation loss = 10.8044  \n",
      "\n",
      "Fold: 15  Epoch: 472  Training loss = 4.8408  Validation loss = 10.8036  \n",
      "\n",
      "Fold: 15  Epoch: 473  Training loss = 4.8403  Validation loss = 10.8028  \n",
      "\n",
      "Fold: 15  Epoch: 474  Training loss = 4.8398  Validation loss = 10.8021  \n",
      "\n",
      "Fold: 15  Epoch: 475  Training loss = 4.8393  Validation loss = 10.8014  \n",
      "\n",
      "Fold: 15  Epoch: 476  Training loss = 4.8387  Validation loss = 10.8006  \n",
      "\n",
      "Fold: 15  Epoch: 477  Training loss = 4.8382  Validation loss = 10.7999  \n",
      "\n",
      "Fold: 15  Epoch: 478  Training loss = 4.8378  Validation loss = 10.7993  \n",
      "\n",
      "Fold: 15  Epoch: 479  Training loss = 4.8373  Validation loss = 10.7986  \n",
      "\n",
      "Fold: 15  Epoch: 480  Training loss = 4.8368  Validation loss = 10.7980  \n",
      "\n",
      "Fold: 15  Epoch: 481  Training loss = 4.8363  Validation loss = 10.7972  \n",
      "\n",
      "Fold: 15  Epoch: 482  Training loss = 4.8357  Validation loss = 10.7964  \n",
      "\n",
      "Fold: 15  Epoch: 483  Training loss = 4.8352  Validation loss = 10.7956  \n",
      "\n",
      "Fold: 15  Epoch: 484  Training loss = 4.8348  Validation loss = 10.7950  \n",
      "\n",
      "Fold: 15  Epoch: 485  Training loss = 4.8343  Validation loss = 10.7944  \n",
      "\n",
      "Fold: 15  Epoch: 486  Training loss = 4.8337  Validation loss = 10.7936  \n",
      "\n",
      "Fold: 15  Epoch: 487  Training loss = 4.8332  Validation loss = 10.7929  \n",
      "\n",
      "Fold: 15  Epoch: 488  Training loss = 4.8326  Validation loss = 10.7920  \n",
      "\n",
      "Fold: 15  Epoch: 489  Training loss = 4.8320  Validation loss = 10.7912  \n",
      "\n",
      "Fold: 15  Epoch: 490  Training loss = 4.8314  Validation loss = 10.7904  \n",
      "\n",
      "Fold: 15  Epoch: 491  Training loss = 4.8310  Validation loss = 10.7898  \n",
      "\n",
      "Fold: 15  Epoch: 492  Training loss = 4.8305  Validation loss = 10.7890  \n",
      "\n",
      "Fold: 15  Epoch: 493  Training loss = 4.8299  Validation loss = 10.7882  \n",
      "\n",
      "Fold: 15  Epoch: 494  Training loss = 4.8294  Validation loss = 10.7875  \n",
      "\n",
      "Fold: 15  Epoch: 495  Training loss = 4.8290  Validation loss = 10.7869  \n",
      "\n",
      "Fold: 15  Epoch: 496  Training loss = 4.8284  Validation loss = 10.7862  \n",
      "\n",
      "Fold: 15  Epoch: 497  Training loss = 4.8280  Validation loss = 10.7855  \n",
      "\n",
      "Fold: 15  Epoch: 498  Training loss = 4.8274  Validation loss = 10.7847  \n",
      "\n",
      "Fold: 15  Epoch: 499  Training loss = 4.8270  Validation loss = 10.7841  \n",
      "\n",
      "Fold: 15  Epoch: 500  Training loss = 4.8265  Validation loss = 10.7833  \n",
      "\n",
      "Check model:  Fold: 15  Optimal epoch: 500  \n",
      "\n",
      "Fold: 16  Epoch: 1  Training loss = 5.5115  Validation loss = 8.2173  \n",
      "\n",
      "Fold: 16  Epoch: 2  Training loss = 5.5108  Validation loss = 8.2165  \n",
      "\n",
      "Fold: 16  Epoch: 3  Training loss = 5.5102  Validation loss = 8.2158  \n",
      "\n",
      "Fold: 16  Epoch: 4  Training loss = 5.5095  Validation loss = 8.2152  \n",
      "\n",
      "Fold: 16  Epoch: 5  Training loss = 5.5088  Validation loss = 8.2144  \n",
      "\n",
      "Fold: 16  Epoch: 6  Training loss = 5.5081  Validation loss = 8.2135  \n",
      "\n",
      "Fold: 16  Epoch: 7  Training loss = 5.5075  Validation loss = 8.2128  \n",
      "\n",
      "Fold: 16  Epoch: 8  Training loss = 5.5069  Validation loss = 8.2122  \n",
      "\n",
      "Fold: 16  Epoch: 9  Training loss = 5.5062  Validation loss = 8.2116  \n",
      "\n",
      "Fold: 16  Epoch: 10  Training loss = 5.5055  Validation loss = 8.2110  \n",
      "\n",
      "Fold: 16  Epoch: 11  Training loss = 5.5049  Validation loss = 8.2103  \n",
      "\n",
      "Fold: 16  Epoch: 12  Training loss = 5.5042  Validation loss = 8.2097  \n",
      "\n",
      "Fold: 16  Epoch: 13  Training loss = 5.5036  Validation loss = 8.2092  \n",
      "\n",
      "Fold: 16  Epoch: 14  Training loss = 5.5031  Validation loss = 8.2085  \n",
      "\n",
      "Fold: 16  Epoch: 15  Training loss = 5.5025  Validation loss = 8.2079  \n",
      "\n",
      "Fold: 16  Epoch: 16  Training loss = 5.5019  Validation loss = 8.2073  \n",
      "\n",
      "Fold: 16  Epoch: 17  Training loss = 5.5011  Validation loss = 8.2066  \n",
      "\n",
      "Fold: 16  Epoch: 18  Training loss = 5.5003  Validation loss = 8.2058  \n",
      "\n",
      "Fold: 16  Epoch: 19  Training loss = 5.4996  Validation loss = 8.2051  \n",
      "\n",
      "Fold: 16  Epoch: 20  Training loss = 5.4989  Validation loss = 8.2043  \n",
      "\n",
      "Fold: 16  Epoch: 21  Training loss = 5.4982  Validation loss = 8.2037  \n",
      "\n",
      "Fold: 16  Epoch: 22  Training loss = 5.4974  Validation loss = 8.2028  \n",
      "\n",
      "Fold: 16  Epoch: 23  Training loss = 5.4967  Validation loss = 8.2022  \n",
      "\n",
      "Fold: 16  Epoch: 24  Training loss = 5.4960  Validation loss = 8.2012  \n",
      "\n",
      "Fold: 16  Epoch: 25  Training loss = 5.4953  Validation loss = 8.2006  \n",
      "\n",
      "Fold: 16  Epoch: 26  Training loss = 5.4948  Validation loss = 8.1999  \n",
      "\n",
      "Fold: 16  Epoch: 27  Training loss = 5.4941  Validation loss = 8.1993  \n",
      "\n",
      "Fold: 16  Epoch: 28  Training loss = 5.4933  Validation loss = 8.1984  \n",
      "\n",
      "Fold: 16  Epoch: 29  Training loss = 5.4926  Validation loss = 8.1976  \n",
      "\n",
      "Fold: 16  Epoch: 30  Training loss = 5.4920  Validation loss = 8.1969  \n",
      "\n",
      "Fold: 16  Epoch: 31  Training loss = 5.4914  Validation loss = 8.1963  \n",
      "\n",
      "Fold: 16  Epoch: 32  Training loss = 5.4908  Validation loss = 8.1957  \n",
      "\n",
      "Fold: 16  Epoch: 33  Training loss = 5.4901  Validation loss = 8.1949  \n",
      "\n",
      "Fold: 16  Epoch: 34  Training loss = 5.4895  Validation loss = 8.1941  \n",
      "\n",
      "Fold: 16  Epoch: 35  Training loss = 5.4887  Validation loss = 8.1934  \n",
      "\n",
      "Fold: 16  Epoch: 36  Training loss = 5.4880  Validation loss = 8.1927  \n",
      "\n",
      "Fold: 16  Epoch: 37  Training loss = 5.4873  Validation loss = 8.1920  \n",
      "\n",
      "Fold: 16  Epoch: 38  Training loss = 5.4865  Validation loss = 8.1912  \n",
      "\n",
      "Fold: 16  Epoch: 39  Training loss = 5.4858  Validation loss = 8.1904  \n",
      "\n",
      "Fold: 16  Epoch: 40  Training loss = 5.4850  Validation loss = 8.1897  \n",
      "\n",
      "Fold: 16  Epoch: 41  Training loss = 5.4843  Validation loss = 8.1889  \n",
      "\n",
      "Fold: 16  Epoch: 42  Training loss = 5.4836  Validation loss = 8.1881  \n",
      "\n",
      "Fold: 16  Epoch: 43  Training loss = 5.4829  Validation loss = 8.1874  \n",
      "\n",
      "Fold: 16  Epoch: 44  Training loss = 5.4823  Validation loss = 8.1866  \n",
      "\n",
      "Fold: 16  Epoch: 45  Training loss = 5.4819  Validation loss = 8.1863  \n",
      "\n",
      "Fold: 16  Epoch: 46  Training loss = 5.4812  Validation loss = 8.1855  \n",
      "\n",
      "Fold: 16  Epoch: 47  Training loss = 5.4804  Validation loss = 8.1847  \n",
      "\n",
      "Fold: 16  Epoch: 48  Training loss = 5.4796  Validation loss = 8.1839  \n",
      "\n",
      "Fold: 16  Epoch: 49  Training loss = 5.4789  Validation loss = 8.1832  \n",
      "\n",
      "Fold: 16  Epoch: 50  Training loss = 5.4782  Validation loss = 8.1825  \n",
      "\n",
      "Fold: 16  Epoch: 51  Training loss = 5.4776  Validation loss = 8.1818  \n",
      "\n",
      "Fold: 16  Epoch: 52  Training loss = 5.4770  Validation loss = 8.1813  \n",
      "\n",
      "Fold: 16  Epoch: 53  Training loss = 5.4763  Validation loss = 8.1807  \n",
      "\n",
      "Fold: 16  Epoch: 54  Training loss = 5.4757  Validation loss = 8.1800  \n",
      "\n",
      "Fold: 16  Epoch: 55  Training loss = 5.4751  Validation loss = 8.1794  \n",
      "\n",
      "Fold: 16  Epoch: 56  Training loss = 5.4745  Validation loss = 8.1787  \n",
      "\n",
      "Fold: 16  Epoch: 57  Training loss = 5.4738  Validation loss = 8.1780  \n",
      "\n",
      "Fold: 16  Epoch: 58  Training loss = 5.4731  Validation loss = 8.1773  \n",
      "\n",
      "Fold: 16  Epoch: 59  Training loss = 5.4724  Validation loss = 8.1766  \n",
      "\n",
      "Fold: 16  Epoch: 60  Training loss = 5.4718  Validation loss = 8.1761  \n",
      "\n",
      "Fold: 16  Epoch: 61  Training loss = 5.4711  Validation loss = 8.1756  \n",
      "\n",
      "Fold: 16  Epoch: 62  Training loss = 5.4705  Validation loss = 8.1748  \n",
      "\n",
      "Fold: 16  Epoch: 63  Training loss = 5.4699  Validation loss = 8.1741  \n",
      "\n",
      "Fold: 16  Epoch: 64  Training loss = 5.4692  Validation loss = 8.1734  \n",
      "\n",
      "Fold: 16  Epoch: 65  Training loss = 5.4685  Validation loss = 8.1726  \n",
      "\n",
      "Fold: 16  Epoch: 66  Training loss = 5.4678  Validation loss = 8.1720  \n",
      "\n",
      "Fold: 16  Epoch: 67  Training loss = 5.4671  Validation loss = 8.1711  \n",
      "\n",
      "Fold: 16  Epoch: 68  Training loss = 5.4664  Validation loss = 8.1705  \n",
      "\n",
      "Fold: 16  Epoch: 69  Training loss = 5.4656  Validation loss = 8.1697  \n",
      "\n",
      "Fold: 16  Epoch: 70  Training loss = 5.4650  Validation loss = 8.1692  \n",
      "\n",
      "Fold: 16  Epoch: 71  Training loss = 5.4643  Validation loss = 8.1681  \n",
      "\n",
      "Fold: 16  Epoch: 72  Training loss = 5.4637  Validation loss = 8.1676  \n",
      "\n",
      "Fold: 16  Epoch: 73  Training loss = 5.4629  Validation loss = 8.1668  \n",
      "\n",
      "Fold: 16  Epoch: 74  Training loss = 5.4622  Validation loss = 8.1660  \n",
      "\n",
      "Fold: 16  Epoch: 75  Training loss = 5.4615  Validation loss = 8.1652  \n",
      "\n",
      "Fold: 16  Epoch: 76  Training loss = 5.4609  Validation loss = 8.1644  \n",
      "\n",
      "Fold: 16  Epoch: 77  Training loss = 5.4602  Validation loss = 8.1636  \n",
      "\n",
      "Fold: 16  Epoch: 78  Training loss = 5.4593  Validation loss = 8.1624  \n",
      "\n",
      "Fold: 16  Epoch: 79  Training loss = 5.4586  Validation loss = 8.1616  \n",
      "\n",
      "Fold: 16  Epoch: 80  Training loss = 5.4578  Validation loss = 8.1607  \n",
      "\n",
      "Fold: 16  Epoch: 81  Training loss = 5.4572  Validation loss = 8.1600  \n",
      "\n",
      "Fold: 16  Epoch: 82  Training loss = 5.4565  Validation loss = 8.1594  \n",
      "\n",
      "Fold: 16  Epoch: 83  Training loss = 5.4558  Validation loss = 8.1584  \n",
      "\n",
      "Fold: 16  Epoch: 84  Training loss = 5.4552  Validation loss = 8.1577  \n",
      "\n",
      "Fold: 16  Epoch: 85  Training loss = 5.4544  Validation loss = 8.1569  \n",
      "\n",
      "Fold: 16  Epoch: 86  Training loss = 5.4537  Validation loss = 8.1562  \n",
      "\n",
      "Fold: 16  Epoch: 87  Training loss = 5.4530  Validation loss = 8.1554  \n",
      "\n",
      "Fold: 16  Epoch: 88  Training loss = 5.4524  Validation loss = 8.1547  \n",
      "\n",
      "Fold: 16  Epoch: 89  Training loss = 5.4517  Validation loss = 8.1537  \n",
      "\n",
      "Fold: 16  Epoch: 90  Training loss = 5.4510  Validation loss = 8.1528  \n",
      "\n",
      "Fold: 16  Epoch: 91  Training loss = 5.4503  Validation loss = 8.1519  \n",
      "\n",
      "Fold: 16  Epoch: 92  Training loss = 5.4497  Validation loss = 8.1513  \n",
      "\n",
      "Fold: 16  Epoch: 93  Training loss = 5.4490  Validation loss = 8.1506  \n",
      "\n",
      "Fold: 16  Epoch: 94  Training loss = 5.4484  Validation loss = 8.1500  \n",
      "\n",
      "Fold: 16  Epoch: 95  Training loss = 5.4478  Validation loss = 8.1493  \n",
      "\n",
      "Fold: 16  Epoch: 96  Training loss = 5.4470  Validation loss = 8.1485  \n",
      "\n",
      "Fold: 16  Epoch: 97  Training loss = 5.4463  Validation loss = 8.1478  \n",
      "\n",
      "Fold: 16  Epoch: 98  Training loss = 5.4457  Validation loss = 8.1470  \n",
      "\n",
      "Fold: 16  Epoch: 99  Training loss = 5.4451  Validation loss = 8.1464  \n",
      "\n",
      "Fold: 16  Epoch: 100  Training loss = 5.4444  Validation loss = 8.1455  \n",
      "\n",
      "Fold: 16  Epoch: 101  Training loss = 5.4436  Validation loss = 8.1447  \n",
      "\n",
      "Fold: 16  Epoch: 102  Training loss = 5.4429  Validation loss = 8.1439  \n",
      "\n",
      "Fold: 16  Epoch: 103  Training loss = 5.4424  Validation loss = 8.1433  \n",
      "\n",
      "Fold: 16  Epoch: 104  Training loss = 5.4417  Validation loss = 8.1427  \n",
      "\n",
      "Fold: 16  Epoch: 105  Training loss = 5.4410  Validation loss = 8.1420  \n",
      "\n",
      "Fold: 16  Epoch: 106  Training loss = 5.4404  Validation loss = 8.1414  \n",
      "\n",
      "Fold: 16  Epoch: 107  Training loss = 5.4397  Validation loss = 8.1407  \n",
      "\n",
      "Fold: 16  Epoch: 108  Training loss = 5.4389  Validation loss = 8.1398  \n",
      "\n",
      "Fold: 16  Epoch: 109  Training loss = 5.4382  Validation loss = 8.1390  \n",
      "\n",
      "Fold: 16  Epoch: 110  Training loss = 5.4375  Validation loss = 8.1381  \n",
      "\n",
      "Fold: 16  Epoch: 111  Training loss = 5.4368  Validation loss = 8.1373  \n",
      "\n",
      "Fold: 16  Epoch: 112  Training loss = 5.4361  Validation loss = 8.1364  \n",
      "\n",
      "Fold: 16  Epoch: 113  Training loss = 5.4353  Validation loss = 8.1357  \n",
      "\n",
      "Fold: 16  Epoch: 114  Training loss = 5.4345  Validation loss = 8.1350  \n",
      "\n",
      "Fold: 16  Epoch: 115  Training loss = 5.4340  Validation loss = 8.1344  \n",
      "\n",
      "Fold: 16  Epoch: 116  Training loss = 5.4332  Validation loss = 8.1334  \n",
      "\n",
      "Fold: 16  Epoch: 117  Training loss = 5.4327  Validation loss = 8.1328  \n",
      "\n",
      "Fold: 16  Epoch: 118  Training loss = 5.4321  Validation loss = 8.1321  \n",
      "\n",
      "Fold: 16  Epoch: 119  Training loss = 5.4315  Validation loss = 8.1315  \n",
      "\n",
      "Fold: 16  Epoch: 120  Training loss = 5.4308  Validation loss = 8.1307  \n",
      "\n",
      "Fold: 16  Epoch: 121  Training loss = 5.4300  Validation loss = 8.1297  \n",
      "\n",
      "Fold: 16  Epoch: 122  Training loss = 5.4293  Validation loss = 8.1291  \n",
      "\n",
      "Fold: 16  Epoch: 123  Training loss = 5.4285  Validation loss = 8.1281  \n",
      "\n",
      "Fold: 16  Epoch: 124  Training loss = 5.4279  Validation loss = 8.1276  \n",
      "\n",
      "Fold: 16  Epoch: 125  Training loss = 5.4272  Validation loss = 8.1268  \n",
      "\n",
      "Fold: 16  Epoch: 126  Training loss = 5.4266  Validation loss = 8.1261  \n",
      "\n",
      "Fold: 16  Epoch: 127  Training loss = 5.4258  Validation loss = 8.1252  \n",
      "\n",
      "Fold: 16  Epoch: 128  Training loss = 5.4250  Validation loss = 8.1244  \n",
      "\n",
      "Fold: 16  Epoch: 129  Training loss = 5.4245  Validation loss = 8.1239  \n",
      "\n",
      "Fold: 16  Epoch: 130  Training loss = 5.4239  Validation loss = 8.1233  \n",
      "\n",
      "Fold: 16  Epoch: 131  Training loss = 5.4233  Validation loss = 8.1227  \n",
      "\n",
      "Fold: 16  Epoch: 132  Training loss = 5.4226  Validation loss = 8.1219  \n",
      "\n",
      "Fold: 16  Epoch: 133  Training loss = 5.4220  Validation loss = 8.1213  \n",
      "\n",
      "Fold: 16  Epoch: 134  Training loss = 5.4213  Validation loss = 8.1204  \n",
      "\n",
      "Fold: 16  Epoch: 135  Training loss = 5.4206  Validation loss = 8.1195  \n",
      "\n",
      "Fold: 16  Epoch: 136  Training loss = 5.4199  Validation loss = 8.1185  \n",
      "\n",
      "Fold: 16  Epoch: 137  Training loss = 5.4191  Validation loss = 8.1174  \n",
      "\n",
      "Fold: 16  Epoch: 138  Training loss = 5.4185  Validation loss = 8.1167  \n",
      "\n",
      "Fold: 16  Epoch: 139  Training loss = 5.4177  Validation loss = 8.1157  \n",
      "\n",
      "Fold: 16  Epoch: 140  Training loss = 5.4169  Validation loss = 8.1148  \n",
      "\n",
      "Fold: 16  Epoch: 141  Training loss = 5.4162  Validation loss = 8.1139  \n",
      "\n",
      "Fold: 16  Epoch: 142  Training loss = 5.4155  Validation loss = 8.1127  \n",
      "\n",
      "Fold: 16  Epoch: 143  Training loss = 5.4148  Validation loss = 8.1119  \n",
      "\n",
      "Fold: 16  Epoch: 144  Training loss = 5.4142  Validation loss = 8.1111  \n",
      "\n",
      "Fold: 16  Epoch: 145  Training loss = 5.4135  Validation loss = 8.1102  \n",
      "\n",
      "Fold: 16  Epoch: 146  Training loss = 5.4127  Validation loss = 8.1092  \n",
      "\n",
      "Fold: 16  Epoch: 147  Training loss = 5.4119  Validation loss = 8.1083  \n",
      "\n",
      "Fold: 16  Epoch: 148  Training loss = 5.4113  Validation loss = 8.1075  \n",
      "\n",
      "Fold: 16  Epoch: 149  Training loss = 5.4106  Validation loss = 8.1066  \n",
      "\n",
      "Fold: 16  Epoch: 150  Training loss = 5.4099  Validation loss = 8.1057  \n",
      "\n",
      "Fold: 16  Epoch: 151  Training loss = 5.4092  Validation loss = 8.1051  \n",
      "\n",
      "Fold: 16  Epoch: 152  Training loss = 5.4085  Validation loss = 8.1041  \n",
      "\n",
      "Fold: 16  Epoch: 153  Training loss = 5.4078  Validation loss = 8.1033  \n",
      "\n",
      "Fold: 16  Epoch: 154  Training loss = 5.4070  Validation loss = 8.1022  \n",
      "\n",
      "Fold: 16  Epoch: 155  Training loss = 5.4062  Validation loss = 8.1012  \n",
      "\n",
      "Fold: 16  Epoch: 156  Training loss = 5.4054  Validation loss = 8.1003  \n",
      "\n",
      "Fold: 16  Epoch: 157  Training loss = 5.4046  Validation loss = 8.0993  \n",
      "\n",
      "Fold: 16  Epoch: 158  Training loss = 5.4039  Validation loss = 8.0983  \n",
      "\n",
      "Fold: 16  Epoch: 159  Training loss = 5.4033  Validation loss = 8.0977  \n",
      "\n",
      "Fold: 16  Epoch: 160  Training loss = 5.4025  Validation loss = 8.0968  \n",
      "\n",
      "Fold: 16  Epoch: 161  Training loss = 5.4020  Validation loss = 8.0962  \n",
      "\n",
      "Fold: 16  Epoch: 162  Training loss = 5.4013  Validation loss = 8.0955  \n",
      "\n",
      "Fold: 16  Epoch: 163  Training loss = 5.4007  Validation loss = 8.0949  \n",
      "\n",
      "Fold: 16  Epoch: 164  Training loss = 5.4000  Validation loss = 8.0940  \n",
      "\n",
      "Fold: 16  Epoch: 165  Training loss = 5.3991  Validation loss = 8.0930  \n",
      "\n",
      "Fold: 16  Epoch: 166  Training loss = 5.3984  Validation loss = 8.0920  \n",
      "\n",
      "Fold: 16  Epoch: 167  Training loss = 5.3977  Validation loss = 8.0911  \n",
      "\n",
      "Fold: 16  Epoch: 168  Training loss = 5.3972  Validation loss = 8.0901  \n",
      "\n",
      "Fold: 16  Epoch: 169  Training loss = 5.3965  Validation loss = 8.0892  \n",
      "\n",
      "Fold: 16  Epoch: 170  Training loss = 5.3957  Validation loss = 8.0881  \n",
      "\n",
      "Fold: 16  Epoch: 171  Training loss = 5.3951  Validation loss = 8.0875  \n",
      "\n",
      "Fold: 16  Epoch: 172  Training loss = 5.3943  Validation loss = 8.0865  \n",
      "\n",
      "Fold: 16  Epoch: 173  Training loss = 5.3937  Validation loss = 8.0855  \n",
      "\n",
      "Fold: 16  Epoch: 174  Training loss = 5.3928  Validation loss = 8.0846  \n",
      "\n",
      "Fold: 16  Epoch: 175  Training loss = 5.3921  Validation loss = 8.0838  \n",
      "\n",
      "Fold: 16  Epoch: 176  Training loss = 5.3913  Validation loss = 8.0828  \n",
      "\n",
      "Fold: 16  Epoch: 177  Training loss = 5.3906  Validation loss = 8.0821  \n",
      "\n",
      "Fold: 16  Epoch: 178  Training loss = 5.3900  Validation loss = 8.0814  \n",
      "\n",
      "Fold: 16  Epoch: 179  Training loss = 5.3893  Validation loss = 8.0806  \n",
      "\n",
      "Fold: 16  Epoch: 180  Training loss = 5.3886  Validation loss = 8.0796  \n",
      "\n",
      "Fold: 16  Epoch: 181  Training loss = 5.3881  Validation loss = 8.0787  \n",
      "\n",
      "Fold: 16  Epoch: 182  Training loss = 5.3873  Validation loss = 8.0779  \n",
      "\n",
      "Fold: 16  Epoch: 183  Training loss = 5.3866  Validation loss = 8.0768  \n",
      "\n",
      "Fold: 16  Epoch: 184  Training loss = 5.3858  Validation loss = 8.0760  \n",
      "\n",
      "Fold: 16  Epoch: 185  Training loss = 5.3851  Validation loss = 8.0751  \n",
      "\n",
      "Fold: 16  Epoch: 186  Training loss = 5.3845  Validation loss = 8.0744  \n",
      "\n",
      "Fold: 16  Epoch: 187  Training loss = 5.3838  Validation loss = 8.0733  \n",
      "\n",
      "Fold: 16  Epoch: 188  Training loss = 5.3831  Validation loss = 8.0724  \n",
      "\n",
      "Fold: 16  Epoch: 189  Training loss = 5.3823  Validation loss = 8.0716  \n",
      "\n",
      "Fold: 16  Epoch: 190  Training loss = 5.3815  Validation loss = 8.0709  \n",
      "\n",
      "Fold: 16  Epoch: 191  Training loss = 5.3810  Validation loss = 8.0703  \n",
      "\n",
      "Fold: 16  Epoch: 192  Training loss = 5.3802  Validation loss = 8.0693  \n",
      "\n",
      "Fold: 16  Epoch: 193  Training loss = 5.3795  Validation loss = 8.0683  \n",
      "\n",
      "Fold: 16  Epoch: 194  Training loss = 5.3789  Validation loss = 8.0674  \n",
      "\n",
      "Fold: 16  Epoch: 195  Training loss = 5.3782  Validation loss = 8.0665  \n",
      "\n",
      "Fold: 16  Epoch: 196  Training loss = 5.3774  Validation loss = 8.0655  \n",
      "\n",
      "Fold: 16  Epoch: 197  Training loss = 5.3767  Validation loss = 8.0648  \n",
      "\n",
      "Fold: 16  Epoch: 198  Training loss = 5.3760  Validation loss = 8.0639  \n",
      "\n",
      "Fold: 16  Epoch: 199  Training loss = 5.3754  Validation loss = 8.0632  \n",
      "\n",
      "Fold: 16  Epoch: 200  Training loss = 5.3748  Validation loss = 8.0624  \n",
      "\n",
      "Fold: 16  Epoch: 201  Training loss = 5.3740  Validation loss = 8.0613  \n",
      "\n",
      "Fold: 16  Epoch: 202  Training loss = 5.3733  Validation loss = 8.0603  \n",
      "\n",
      "Fold: 16  Epoch: 203  Training loss = 5.3726  Validation loss = 8.0595  \n",
      "\n",
      "Fold: 16  Epoch: 204  Training loss = 5.3721  Validation loss = 8.0587  \n",
      "\n",
      "Fold: 16  Epoch: 205  Training loss = 5.3715  Validation loss = 8.0579  \n",
      "\n",
      "Fold: 16  Epoch: 206  Training loss = 5.3710  Validation loss = 8.0572  \n",
      "\n",
      "Fold: 16  Epoch: 207  Training loss = 5.3703  Validation loss = 8.0564  \n",
      "\n",
      "Fold: 16  Epoch: 208  Training loss = 5.3696  Validation loss = 8.0555  \n",
      "\n",
      "Fold: 16  Epoch: 209  Training loss = 5.3689  Validation loss = 8.0547  \n",
      "\n",
      "Fold: 16  Epoch: 210  Training loss = 5.3683  Validation loss = 8.0537  \n",
      "\n",
      "Fold: 16  Epoch: 211  Training loss = 5.3677  Validation loss = 8.0527  \n",
      "\n",
      "Fold: 16  Epoch: 212  Training loss = 5.3670  Validation loss = 8.0520  \n",
      "\n",
      "Fold: 16  Epoch: 213  Training loss = 5.3662  Validation loss = 8.0511  \n",
      "\n",
      "Fold: 16  Epoch: 214  Training loss = 5.3655  Validation loss = 8.0503  \n",
      "\n",
      "Fold: 16  Epoch: 215  Training loss = 5.3650  Validation loss = 8.0496  \n",
      "\n",
      "Fold: 16  Epoch: 216  Training loss = 5.3643  Validation loss = 8.0488  \n",
      "\n",
      "Fold: 16  Epoch: 217  Training loss = 5.3637  Validation loss = 8.0479  \n",
      "\n",
      "Fold: 16  Epoch: 218  Training loss = 5.3630  Validation loss = 8.0469  \n",
      "\n",
      "Fold: 16  Epoch: 219  Training loss = 5.3624  Validation loss = 8.0461  \n",
      "\n",
      "Fold: 16  Epoch: 220  Training loss = 5.3616  Validation loss = 8.0452  \n",
      "\n",
      "Fold: 16  Epoch: 221  Training loss = 5.3610  Validation loss = 8.0446  \n",
      "\n",
      "Fold: 16  Epoch: 222  Training loss = 5.3604  Validation loss = 8.0438  \n",
      "\n",
      "Fold: 16  Epoch: 223  Training loss = 5.3597  Validation loss = 8.0430  \n",
      "\n",
      "Fold: 16  Epoch: 224  Training loss = 5.3589  Validation loss = 8.0417  \n",
      "\n",
      "Fold: 16  Epoch: 225  Training loss = 5.3583  Validation loss = 8.0408  \n",
      "\n",
      "Fold: 16  Epoch: 226  Training loss = 5.3576  Validation loss = 8.0398  \n",
      "\n",
      "Fold: 16  Epoch: 227  Training loss = 5.3568  Validation loss = 8.0387  \n",
      "\n",
      "Fold: 16  Epoch: 228  Training loss = 5.3562  Validation loss = 8.0378  \n",
      "\n",
      "Fold: 16  Epoch: 229  Training loss = 5.3555  Validation loss = 8.0371  \n",
      "\n",
      "Fold: 16  Epoch: 230  Training loss = 5.3550  Validation loss = 8.0363  \n",
      "\n",
      "Fold: 16  Epoch: 231  Training loss = 5.3543  Validation loss = 8.0352  \n",
      "\n",
      "Fold: 16  Epoch: 232  Training loss = 5.3535  Validation loss = 8.0342  \n",
      "\n",
      "Fold: 16  Epoch: 233  Training loss = 5.3528  Validation loss = 8.0333  \n",
      "\n",
      "Fold: 16  Epoch: 234  Training loss = 5.3523  Validation loss = 8.0325  \n",
      "\n",
      "Fold: 16  Epoch: 235  Training loss = 5.3514  Validation loss = 8.0316  \n",
      "\n",
      "Fold: 16  Epoch: 236  Training loss = 5.3508  Validation loss = 8.0306  \n",
      "\n",
      "Fold: 16  Epoch: 237  Training loss = 5.3501  Validation loss = 8.0298  \n",
      "\n",
      "Fold: 16  Epoch: 238  Training loss = 5.3493  Validation loss = 8.0288  \n",
      "\n",
      "Fold: 16  Epoch: 239  Training loss = 5.3488  Validation loss = 8.0281  \n",
      "\n",
      "Fold: 16  Epoch: 240  Training loss = 5.3481  Validation loss = 8.0272  \n",
      "\n",
      "Fold: 16  Epoch: 241  Training loss = 5.3475  Validation loss = 8.0264  \n",
      "\n",
      "Fold: 16  Epoch: 242  Training loss = 5.3468  Validation loss = 8.0251  \n",
      "\n",
      "Fold: 16  Epoch: 243  Training loss = 5.3460  Validation loss = 8.0241  \n",
      "\n",
      "Fold: 16  Epoch: 244  Training loss = 5.3453  Validation loss = 8.0232  \n",
      "\n",
      "Fold: 16  Epoch: 245  Training loss = 5.3446  Validation loss = 8.0222  \n",
      "\n",
      "Fold: 16  Epoch: 246  Training loss = 5.3441  Validation loss = 8.0217  \n",
      "\n",
      "Fold: 16  Epoch: 247  Training loss = 5.3433  Validation loss = 8.0207  \n",
      "\n",
      "Fold: 16  Epoch: 248  Training loss = 5.3427  Validation loss = 8.0200  \n",
      "\n",
      "Fold: 16  Epoch: 249  Training loss = 5.3420  Validation loss = 8.0192  \n",
      "\n",
      "Fold: 16  Epoch: 250  Training loss = 5.3413  Validation loss = 8.0181  \n",
      "\n",
      "Fold: 16  Epoch: 251  Training loss = 5.3406  Validation loss = 8.0171  \n",
      "\n",
      "Fold: 16  Epoch: 252  Training loss = 5.3399  Validation loss = 8.0164  \n",
      "\n",
      "Fold: 16  Epoch: 253  Training loss = 5.3391  Validation loss = 8.0153  \n",
      "\n",
      "Fold: 16  Epoch: 254  Training loss = 5.3386  Validation loss = 8.0147  \n",
      "\n",
      "Fold: 16  Epoch: 255  Training loss = 5.3381  Validation loss = 8.0140  \n",
      "\n",
      "Fold: 16  Epoch: 256  Training loss = 5.3375  Validation loss = 8.0131  \n",
      "\n",
      "Fold: 16  Epoch: 257  Training loss = 5.3367  Validation loss = 8.0120  \n",
      "\n",
      "Fold: 16  Epoch: 258  Training loss = 5.3361  Validation loss = 8.0111  \n",
      "\n",
      "Fold: 16  Epoch: 259  Training loss = 5.3354  Validation loss = 8.0101  \n",
      "\n",
      "Fold: 16  Epoch: 260  Training loss = 5.3347  Validation loss = 8.0090  \n",
      "\n",
      "Fold: 16  Epoch: 261  Training loss = 5.3340  Validation loss = 8.0079  \n",
      "\n",
      "Fold: 16  Epoch: 262  Training loss = 5.3334  Validation loss = 8.0072  \n",
      "\n",
      "Fold: 16  Epoch: 263  Training loss = 5.3325  Validation loss = 8.0062  \n",
      "\n",
      "Fold: 16  Epoch: 264  Training loss = 5.3318  Validation loss = 8.0052  \n",
      "\n",
      "Fold: 16  Epoch: 265  Training loss = 5.3310  Validation loss = 8.0041  \n",
      "\n",
      "Fold: 16  Epoch: 266  Training loss = 5.3302  Validation loss = 8.0030  \n",
      "\n",
      "Fold: 16  Epoch: 267  Training loss = 5.3296  Validation loss = 8.0022  \n",
      "\n",
      "Fold: 16  Epoch: 268  Training loss = 5.3290  Validation loss = 8.0014  \n",
      "\n",
      "Fold: 16  Epoch: 269  Training loss = 5.3284  Validation loss = 8.0004  \n",
      "\n",
      "Fold: 16  Epoch: 270  Training loss = 5.3277  Validation loss = 7.9993  \n",
      "\n",
      "Fold: 16  Epoch: 271  Training loss = 5.3269  Validation loss = 7.9982  \n",
      "\n",
      "Fold: 16  Epoch: 272  Training loss = 5.3262  Validation loss = 7.9972  \n",
      "\n",
      "Fold: 16  Epoch: 273  Training loss = 5.3255  Validation loss = 7.9962  \n",
      "\n",
      "Fold: 16  Epoch: 274  Training loss = 5.3249  Validation loss = 7.9956  \n",
      "\n",
      "Fold: 16  Epoch: 275  Training loss = 5.3241  Validation loss = 7.9946  \n",
      "\n",
      "Fold: 16  Epoch: 276  Training loss = 5.3235  Validation loss = 7.9938  \n",
      "\n",
      "Fold: 16  Epoch: 277  Training loss = 5.3228  Validation loss = 7.9930  \n",
      "\n",
      "Fold: 16  Epoch: 278  Training loss = 5.3222  Validation loss = 7.9920  \n",
      "\n",
      "Fold: 16  Epoch: 279  Training loss = 5.3216  Validation loss = 7.9911  \n",
      "\n",
      "Fold: 16  Epoch: 280  Training loss = 5.3209  Validation loss = 7.9902  \n",
      "\n",
      "Fold: 16  Epoch: 281  Training loss = 5.3202  Validation loss = 7.9894  \n",
      "\n",
      "Fold: 16  Epoch: 282  Training loss = 5.3195  Validation loss = 7.9884  \n",
      "\n",
      "Fold: 16  Epoch: 283  Training loss = 5.3189  Validation loss = 7.9877  \n",
      "\n",
      "Fold: 16  Epoch: 284  Training loss = 5.3183  Validation loss = 7.9869  \n",
      "\n",
      "Fold: 16  Epoch: 285  Training loss = 5.3175  Validation loss = 7.9855  \n",
      "\n",
      "Fold: 16  Epoch: 286  Training loss = 5.3169  Validation loss = 7.9847  \n",
      "\n",
      "Fold: 16  Epoch: 287  Training loss = 5.3163  Validation loss = 7.9840  \n",
      "\n",
      "Fold: 16  Epoch: 288  Training loss = 5.3156  Validation loss = 7.9831  \n",
      "\n",
      "Fold: 16  Epoch: 289  Training loss = 5.3150  Validation loss = 7.9820  \n",
      "\n",
      "Fold: 16  Epoch: 290  Training loss = 5.3142  Validation loss = 7.9810  \n",
      "\n",
      "Fold: 16  Epoch: 291  Training loss = 5.3136  Validation loss = 7.9800  \n",
      "\n",
      "Fold: 16  Epoch: 292  Training loss = 5.3129  Validation loss = 7.9790  \n",
      "\n",
      "Fold: 16  Epoch: 293  Training loss = 5.3121  Validation loss = 7.9781  \n",
      "\n",
      "Fold: 16  Epoch: 294  Training loss = 5.3115  Validation loss = 7.9774  \n",
      "\n",
      "Fold: 16  Epoch: 295  Training loss = 5.3108  Validation loss = 7.9765  \n",
      "\n",
      "Fold: 16  Epoch: 296  Training loss = 5.3101  Validation loss = 7.9755  \n",
      "\n",
      "Fold: 16  Epoch: 297  Training loss = 5.3094  Validation loss = 7.9748  \n",
      "\n",
      "Fold: 16  Epoch: 298  Training loss = 5.3086  Validation loss = 7.9738  \n",
      "\n",
      "Fold: 16  Epoch: 299  Training loss = 5.3079  Validation loss = 7.9728  \n",
      "\n",
      "Fold: 16  Epoch: 300  Training loss = 5.3074  Validation loss = 7.9721  \n",
      "\n",
      "Fold: 16  Epoch: 301  Training loss = 5.3065  Validation loss = 7.9710  \n",
      "\n",
      "Fold: 16  Epoch: 302  Training loss = 5.3058  Validation loss = 7.9701  \n",
      "\n",
      "Fold: 16  Epoch: 303  Training loss = 5.3052  Validation loss = 7.9694  \n",
      "\n",
      "Fold: 16  Epoch: 304  Training loss = 5.3046  Validation loss = 7.9684  \n",
      "\n",
      "Fold: 16  Epoch: 305  Training loss = 5.3041  Validation loss = 7.9678  \n",
      "\n",
      "Fold: 16  Epoch: 306  Training loss = 5.3034  Validation loss = 7.9670  \n",
      "\n",
      "Fold: 16  Epoch: 307  Training loss = 5.3026  Validation loss = 7.9661  \n",
      "\n",
      "Fold: 16  Epoch: 308  Training loss = 5.3019  Validation loss = 7.9654  \n",
      "\n",
      "Fold: 16  Epoch: 309  Training loss = 5.3013  Validation loss = 7.9644  \n",
      "\n",
      "Fold: 16  Epoch: 310  Training loss = 5.3006  Validation loss = 7.9635  \n",
      "\n",
      "Fold: 16  Epoch: 311  Training loss = 5.3000  Validation loss = 7.9625  \n",
      "\n",
      "Fold: 16  Epoch: 312  Training loss = 5.2994  Validation loss = 7.9618  \n",
      "\n",
      "Fold: 16  Epoch: 313  Training loss = 5.2988  Validation loss = 7.9611  \n",
      "\n",
      "Fold: 16  Epoch: 314  Training loss = 5.2981  Validation loss = 7.9602  \n",
      "\n",
      "Fold: 16  Epoch: 315  Training loss = 5.2974  Validation loss = 7.9592  \n",
      "\n",
      "Fold: 16  Epoch: 316  Training loss = 5.2968  Validation loss = 7.9585  \n",
      "\n",
      "Fold: 16  Epoch: 317  Training loss = 5.2961  Validation loss = 7.9575  \n",
      "\n",
      "Fold: 16  Epoch: 318  Training loss = 5.2955  Validation loss = 7.9565  \n",
      "\n",
      "Fold: 16  Epoch: 319  Training loss = 5.2949  Validation loss = 7.9556  \n",
      "\n",
      "Fold: 16  Epoch: 320  Training loss = 5.2942  Validation loss = 7.9546  \n",
      "\n",
      "Fold: 16  Epoch: 321  Training loss = 5.2936  Validation loss = 7.9537  \n",
      "\n",
      "Fold: 16  Epoch: 322  Training loss = 5.2929  Validation loss = 7.9529  \n",
      "\n",
      "Fold: 16  Epoch: 323  Training loss = 5.2923  Validation loss = 7.9520  \n",
      "\n",
      "Fold: 16  Epoch: 324  Training loss = 5.2916  Validation loss = 7.9511  \n",
      "\n",
      "Fold: 16  Epoch: 325  Training loss = 5.2909  Validation loss = 7.9504  \n",
      "\n",
      "Fold: 16  Epoch: 326  Training loss = 5.2904  Validation loss = 7.9495  \n",
      "\n",
      "Fold: 16  Epoch: 327  Training loss = 5.2897  Validation loss = 7.9487  \n",
      "\n",
      "Fold: 16  Epoch: 328  Training loss = 5.2889  Validation loss = 7.9475  \n",
      "\n",
      "Fold: 16  Epoch: 329  Training loss = 5.2882  Validation loss = 7.9465  \n",
      "\n",
      "Fold: 16  Epoch: 330  Training loss = 5.2875  Validation loss = 7.9456  \n",
      "\n",
      "Fold: 16  Epoch: 331  Training loss = 5.2868  Validation loss = 7.9446  \n",
      "\n",
      "Fold: 16  Epoch: 332  Training loss = 5.2862  Validation loss = 7.9437  \n",
      "\n",
      "Fold: 16  Epoch: 333  Training loss = 5.2856  Validation loss = 7.9429  \n",
      "\n",
      "Fold: 16  Epoch: 334  Training loss = 5.2849  Validation loss = 7.9419  \n",
      "\n",
      "Fold: 16  Epoch: 335  Training loss = 5.2843  Validation loss = 7.9411  \n",
      "\n",
      "Fold: 16  Epoch: 336  Training loss = 5.2837  Validation loss = 7.9404  \n",
      "\n",
      "Fold: 16  Epoch: 337  Training loss = 5.2829  Validation loss = 7.9393  \n",
      "\n",
      "Fold: 16  Epoch: 338  Training loss = 5.2822  Validation loss = 7.9384  \n",
      "\n",
      "Fold: 16  Epoch: 339  Training loss = 5.2815  Validation loss = 7.9375  \n",
      "\n",
      "Fold: 16  Epoch: 340  Training loss = 5.2808  Validation loss = 7.9366  \n",
      "\n",
      "Fold: 16  Epoch: 341  Training loss = 5.2801  Validation loss = 7.9356  \n",
      "\n",
      "Fold: 16  Epoch: 342  Training loss = 5.2794  Validation loss = 7.9346  \n",
      "\n",
      "Fold: 16  Epoch: 343  Training loss = 5.2787  Validation loss = 7.9338  \n",
      "\n",
      "Fold: 16  Epoch: 344  Training loss = 5.2780  Validation loss = 7.9328  \n",
      "\n",
      "Fold: 16  Epoch: 345  Training loss = 5.2773  Validation loss = 7.9318  \n",
      "\n",
      "Fold: 16  Epoch: 346  Training loss = 5.2766  Validation loss = 7.9307  \n",
      "\n",
      "Fold: 16  Epoch: 347  Training loss = 5.2758  Validation loss = 7.9297  \n",
      "\n",
      "Fold: 16  Epoch: 348  Training loss = 5.2752  Validation loss = 7.9288  \n",
      "\n",
      "Fold: 16  Epoch: 349  Training loss = 5.2745  Validation loss = 7.9279  \n",
      "\n",
      "Fold: 16  Epoch: 350  Training loss = 5.2738  Validation loss = 7.9271  \n",
      "\n",
      "Fold: 16  Epoch: 351  Training loss = 5.2732  Validation loss = 7.9262  \n",
      "\n",
      "Fold: 16  Epoch: 352  Training loss = 5.2726  Validation loss = 7.9254  \n",
      "\n",
      "Fold: 16  Epoch: 353  Training loss = 5.2719  Validation loss = 7.9244  \n",
      "\n",
      "Fold: 16  Epoch: 354  Training loss = 5.2713  Validation loss = 7.9237  \n",
      "\n",
      "Fold: 16  Epoch: 355  Training loss = 5.2707  Validation loss = 7.9229  \n",
      "\n",
      "Fold: 16  Epoch: 356  Training loss = 5.2699  Validation loss = 7.9219  \n",
      "\n",
      "Fold: 16  Epoch: 357  Training loss = 5.2692  Validation loss = 7.9210  \n",
      "\n",
      "Fold: 16  Epoch: 358  Training loss = 5.2687  Validation loss = 7.9202  \n",
      "\n",
      "Fold: 16  Epoch: 359  Training loss = 5.2680  Validation loss = 7.9192  \n",
      "\n",
      "Fold: 16  Epoch: 360  Training loss = 5.2673  Validation loss = 7.9185  \n",
      "\n",
      "Fold: 16  Epoch: 361  Training loss = 5.2667  Validation loss = 7.9178  \n",
      "\n",
      "Fold: 16  Epoch: 362  Training loss = 5.2662  Validation loss = 7.9170  \n",
      "\n",
      "Fold: 16  Epoch: 363  Training loss = 5.2655  Validation loss = 7.9162  \n",
      "\n",
      "Fold: 16  Epoch: 364  Training loss = 5.2648  Validation loss = 7.9153  \n",
      "\n",
      "Fold: 16  Epoch: 365  Training loss = 5.2640  Validation loss = 7.9143  \n",
      "\n",
      "Fold: 16  Epoch: 366  Training loss = 5.2633  Validation loss = 7.9133  \n",
      "\n",
      "Fold: 16  Epoch: 367  Training loss = 5.2627  Validation loss = 7.9124  \n",
      "\n",
      "Fold: 16  Epoch: 368  Training loss = 5.2620  Validation loss = 7.9116  \n",
      "\n",
      "Fold: 16  Epoch: 369  Training loss = 5.2611  Validation loss = 7.9102  \n",
      "\n",
      "Fold: 16  Epoch: 370  Training loss = 5.2604  Validation loss = 7.9094  \n",
      "\n",
      "Fold: 16  Epoch: 371  Training loss = 5.2597  Validation loss = 7.9084  \n",
      "\n",
      "Fold: 16  Epoch: 372  Training loss = 5.2589  Validation loss = 7.9073  \n",
      "\n",
      "Fold: 16  Epoch: 373  Training loss = 5.2582  Validation loss = 7.9062  \n",
      "\n",
      "Fold: 16  Epoch: 374  Training loss = 5.2574  Validation loss = 7.9051  \n",
      "\n",
      "Fold: 16  Epoch: 375  Training loss = 5.2568  Validation loss = 7.9043  \n",
      "\n",
      "Fold: 16  Epoch: 376  Training loss = 5.2561  Validation loss = 7.9035  \n",
      "\n",
      "Fold: 16  Epoch: 377  Training loss = 5.2554  Validation loss = 7.9024  \n",
      "\n",
      "Fold: 16  Epoch: 378  Training loss = 5.2547  Validation loss = 7.9016  \n",
      "\n",
      "Fold: 16  Epoch: 379  Training loss = 5.2542  Validation loss = 7.9008  \n",
      "\n",
      "Fold: 16  Epoch: 380  Training loss = 5.2535  Validation loss = 7.9000  \n",
      "\n",
      "Fold: 16  Epoch: 381  Training loss = 5.2530  Validation loss = 7.8994  \n",
      "\n",
      "Fold: 16  Epoch: 382  Training loss = 5.2524  Validation loss = 7.8987  \n",
      "\n",
      "Fold: 16  Epoch: 383  Training loss = 5.2518  Validation loss = 7.8978  \n",
      "\n",
      "Fold: 16  Epoch: 384  Training loss = 5.2512  Validation loss = 7.8968  \n",
      "\n",
      "Fold: 16  Epoch: 385  Training loss = 5.2505  Validation loss = 7.8961  \n",
      "\n",
      "Fold: 16  Epoch: 386  Training loss = 5.2498  Validation loss = 7.8951  \n",
      "\n",
      "Fold: 16  Epoch: 387  Training loss = 5.2490  Validation loss = 7.8941  \n",
      "\n",
      "Fold: 16  Epoch: 388  Training loss = 5.2484  Validation loss = 7.8931  \n",
      "\n",
      "Fold: 16  Epoch: 389  Training loss = 5.2477  Validation loss = 7.8922  \n",
      "\n",
      "Fold: 16  Epoch: 390  Training loss = 5.2470  Validation loss = 7.8911  \n",
      "\n",
      "Fold: 16  Epoch: 391  Training loss = 5.2464  Validation loss = 7.8903  \n",
      "\n",
      "Fold: 16  Epoch: 392  Training loss = 5.2458  Validation loss = 7.8894  \n",
      "\n",
      "Fold: 16  Epoch: 393  Training loss = 5.2451  Validation loss = 7.8885  \n",
      "\n",
      "Fold: 16  Epoch: 394  Training loss = 5.2444  Validation loss = 7.8875  \n",
      "\n",
      "Fold: 16  Epoch: 395  Training loss = 5.2438  Validation loss = 7.8866  \n",
      "\n",
      "Fold: 16  Epoch: 396  Training loss = 5.2431  Validation loss = 7.8856  \n",
      "\n",
      "Fold: 16  Epoch: 397  Training loss = 5.2426  Validation loss = 7.8850  \n",
      "\n",
      "Fold: 16  Epoch: 398  Training loss = 5.2421  Validation loss = 7.8843  \n",
      "\n",
      "Fold: 16  Epoch: 399  Training loss = 5.2415  Validation loss = 7.8834  \n",
      "\n",
      "Fold: 16  Epoch: 400  Training loss = 5.2408  Validation loss = 7.8826  \n",
      "\n",
      "Fold: 16  Epoch: 401  Training loss = 5.2401  Validation loss = 7.8817  \n",
      "\n",
      "Fold: 16  Epoch: 402  Training loss = 5.2396  Validation loss = 7.8809  \n",
      "\n",
      "Fold: 16  Epoch: 403  Training loss = 5.2390  Validation loss = 7.8802  \n",
      "\n",
      "Fold: 16  Epoch: 404  Training loss = 5.2384  Validation loss = 7.8793  \n",
      "\n",
      "Fold: 16  Epoch: 405  Training loss = 5.2379  Validation loss = 7.8785  \n",
      "\n",
      "Fold: 16  Epoch: 406  Training loss = 5.2371  Validation loss = 7.8774  \n",
      "\n",
      "Fold: 16  Epoch: 407  Training loss = 5.2363  Validation loss = 7.8764  \n",
      "\n",
      "Fold: 16  Epoch: 408  Training loss = 5.2356  Validation loss = 7.8755  \n",
      "\n",
      "Fold: 16  Epoch: 409  Training loss = 5.2348  Validation loss = 7.8745  \n",
      "\n",
      "Fold: 16  Epoch: 410  Training loss = 5.2342  Validation loss = 7.8737  \n",
      "\n",
      "Fold: 16  Epoch: 411  Training loss = 5.2335  Validation loss = 7.8728  \n",
      "\n",
      "Fold: 16  Epoch: 412  Training loss = 5.2329  Validation loss = 7.8720  \n",
      "\n",
      "Fold: 16  Epoch: 413  Training loss = 5.2322  Validation loss = 7.8710  \n",
      "\n",
      "Fold: 16  Epoch: 414  Training loss = 5.2315  Validation loss = 7.8701  \n",
      "\n",
      "Fold: 16  Epoch: 415  Training loss = 5.2307  Validation loss = 7.8689  \n",
      "\n",
      "Fold: 16  Epoch: 416  Training loss = 5.2301  Validation loss = 7.8679  \n",
      "\n",
      "Fold: 16  Epoch: 417  Training loss = 5.2294  Validation loss = 7.8670  \n",
      "\n",
      "Fold: 16  Epoch: 418  Training loss = 5.2288  Validation loss = 7.8662  \n",
      "\n",
      "Fold: 16  Epoch: 419  Training loss = 5.2282  Validation loss = 7.8655  \n",
      "\n",
      "Fold: 16  Epoch: 420  Training loss = 5.2275  Validation loss = 7.8648  \n",
      "\n",
      "Fold: 16  Epoch: 421  Training loss = 5.2270  Validation loss = 7.8640  \n",
      "\n",
      "Fold: 16  Epoch: 422  Training loss = 5.2263  Validation loss = 7.8631  \n",
      "\n",
      "Fold: 16  Epoch: 423  Training loss = 5.2257  Validation loss = 7.8623  \n",
      "\n",
      "Fold: 16  Epoch: 424  Training loss = 5.2251  Validation loss = 7.8616  \n",
      "\n",
      "Fold: 16  Epoch: 425  Training loss = 5.2244  Validation loss = 7.8605  \n",
      "\n",
      "Fold: 16  Epoch: 426  Training loss = 5.2238  Validation loss = 7.8596  \n",
      "\n",
      "Fold: 16  Epoch: 427  Training loss = 5.2233  Validation loss = 7.8588  \n",
      "\n",
      "Fold: 16  Epoch: 428  Training loss = 5.2227  Validation loss = 7.8582  \n",
      "\n",
      "Fold: 16  Epoch: 429  Training loss = 5.2221  Validation loss = 7.8573  \n",
      "\n",
      "Fold: 16  Epoch: 430  Training loss = 5.2215  Validation loss = 7.8565  \n",
      "\n",
      "Fold: 16  Epoch: 431  Training loss = 5.2207  Validation loss = 7.8556  \n",
      "\n",
      "Fold: 16  Epoch: 432  Training loss = 5.2201  Validation loss = 7.8546  \n",
      "\n",
      "Fold: 16  Epoch: 433  Training loss = 5.2195  Validation loss = 7.8538  \n",
      "\n",
      "Fold: 16  Epoch: 434  Training loss = 5.2189  Validation loss = 7.8530  \n",
      "\n",
      "Fold: 16  Epoch: 435  Training loss = 5.2182  Validation loss = 7.8520  \n",
      "\n",
      "Fold: 16  Epoch: 436  Training loss = 5.2175  Validation loss = 7.8511  \n",
      "\n",
      "Fold: 16  Epoch: 437  Training loss = 5.2169  Validation loss = 7.8502  \n",
      "\n",
      "Fold: 16  Epoch: 438  Training loss = 5.2163  Validation loss = 7.8496  \n",
      "\n",
      "Fold: 16  Epoch: 439  Training loss = 5.2156  Validation loss = 7.8487  \n",
      "\n",
      "Fold: 16  Epoch: 440  Training loss = 5.2150  Validation loss = 7.8479  \n",
      "\n",
      "Fold: 16  Epoch: 441  Training loss = 5.2143  Validation loss = 7.8471  \n",
      "\n",
      "Fold: 16  Epoch: 442  Training loss = 5.2137  Validation loss = 7.8463  \n",
      "\n",
      "Fold: 16  Epoch: 443  Training loss = 5.2129  Validation loss = 7.8453  \n",
      "\n",
      "Fold: 16  Epoch: 444  Training loss = 5.2123  Validation loss = 7.8441  \n",
      "\n",
      "Fold: 16  Epoch: 445  Training loss = 5.2117  Validation loss = 7.8433  \n",
      "\n",
      "Fold: 16  Epoch: 446  Training loss = 5.2111  Validation loss = 7.8425  \n",
      "\n",
      "Fold: 16  Epoch: 447  Training loss = 5.2104  Validation loss = 7.8414  \n",
      "\n",
      "Fold: 16  Epoch: 448  Training loss = 5.2098  Validation loss = 7.8406  \n",
      "\n",
      "Fold: 16  Epoch: 449  Training loss = 5.2092  Validation loss = 7.8398  \n",
      "\n",
      "Fold: 16  Epoch: 450  Training loss = 5.2085  Validation loss = 7.8387  \n",
      "\n",
      "Fold: 16  Epoch: 451  Training loss = 5.2080  Validation loss = 7.8380  \n",
      "\n",
      "Fold: 16  Epoch: 452  Training loss = 5.2073  Validation loss = 7.8372  \n",
      "\n",
      "Fold: 16  Epoch: 453  Training loss = 5.2068  Validation loss = 7.8363  \n",
      "\n",
      "Fold: 16  Epoch: 454  Training loss = 5.2062  Validation loss = 7.8355  \n",
      "\n",
      "Fold: 16  Epoch: 455  Training loss = 5.2055  Validation loss = 7.8343  \n",
      "\n",
      "Fold: 16  Epoch: 456  Training loss = 5.2047  Validation loss = 7.8333  \n",
      "\n",
      "Fold: 16  Epoch: 457  Training loss = 5.2041  Validation loss = 7.8324  \n",
      "\n",
      "Fold: 16  Epoch: 458  Training loss = 5.2033  Validation loss = 7.8312  \n",
      "\n",
      "Fold: 16  Epoch: 459  Training loss = 5.2026  Validation loss = 7.8302  \n",
      "\n",
      "Fold: 16  Epoch: 460  Training loss = 5.2020  Validation loss = 7.8295  \n",
      "\n",
      "Fold: 16  Epoch: 461  Training loss = 5.2014  Validation loss = 7.8289  \n",
      "\n",
      "Fold: 16  Epoch: 462  Training loss = 5.2008  Validation loss = 7.8279  \n",
      "\n",
      "Fold: 16  Epoch: 463  Training loss = 5.2002  Validation loss = 7.8270  \n",
      "\n",
      "Fold: 16  Epoch: 464  Training loss = 5.1994  Validation loss = 7.8258  \n",
      "\n",
      "Fold: 16  Epoch: 465  Training loss = 5.1986  Validation loss = 7.8249  \n",
      "\n",
      "Fold: 16  Epoch: 466  Training loss = 5.1980  Validation loss = 7.8239  \n",
      "\n",
      "Fold: 16  Epoch: 467  Training loss = 5.1973  Validation loss = 7.8229  \n",
      "\n",
      "Fold: 16  Epoch: 468  Training loss = 5.1966  Validation loss = 7.8218  \n",
      "\n",
      "Fold: 16  Epoch: 469  Training loss = 5.1961  Validation loss = 7.8209  \n",
      "\n",
      "Fold: 16  Epoch: 470  Training loss = 5.1955  Validation loss = 7.8202  \n",
      "\n",
      "Fold: 16  Epoch: 471  Training loss = 5.1950  Validation loss = 7.8196  \n",
      "\n",
      "Fold: 16  Epoch: 472  Training loss = 5.1945  Validation loss = 7.8188  \n",
      "\n",
      "Fold: 16  Epoch: 473  Training loss = 5.1938  Validation loss = 7.8178  \n",
      "\n",
      "Fold: 16  Epoch: 474  Training loss = 5.1932  Validation loss = 7.8168  \n",
      "\n",
      "Fold: 16  Epoch: 475  Training loss = 5.1925  Validation loss = 7.8159  \n",
      "\n",
      "Fold: 16  Epoch: 476  Training loss = 5.1920  Validation loss = 7.8152  \n",
      "\n",
      "Fold: 16  Epoch: 477  Training loss = 5.1914  Validation loss = 7.8145  \n",
      "\n",
      "Fold: 16  Epoch: 478  Training loss = 5.1907  Validation loss = 7.8135  \n",
      "\n",
      "Fold: 16  Epoch: 479  Training loss = 5.1901  Validation loss = 7.8126  \n",
      "\n",
      "Fold: 16  Epoch: 480  Training loss = 5.1895  Validation loss = 7.8117  \n",
      "\n",
      "Fold: 16  Epoch: 481  Training loss = 5.1889  Validation loss = 7.8110  \n",
      "\n",
      "Fold: 16  Epoch: 482  Training loss = 5.1882  Validation loss = 7.8102  \n",
      "\n",
      "Fold: 16  Epoch: 483  Training loss = 5.1876  Validation loss = 7.8093  \n",
      "\n",
      "Fold: 16  Epoch: 484  Training loss = 5.1870  Validation loss = 7.8085  \n",
      "\n",
      "Fold: 16  Epoch: 485  Training loss = 5.1865  Validation loss = 7.8078  \n",
      "\n",
      "Fold: 16  Epoch: 486  Training loss = 5.1857  Validation loss = 7.8065  \n",
      "\n",
      "Fold: 16  Epoch: 487  Training loss = 5.1851  Validation loss = 7.8057  \n",
      "\n",
      "Fold: 16  Epoch: 488  Training loss = 5.1846  Validation loss = 7.8048  \n",
      "\n",
      "Fold: 16  Epoch: 489  Training loss = 5.1839  Validation loss = 7.8040  \n",
      "\n",
      "Fold: 16  Epoch: 490  Training loss = 5.1832  Validation loss = 7.8029  \n",
      "\n",
      "Fold: 16  Epoch: 491  Training loss = 5.1826  Validation loss = 7.8020  \n",
      "\n",
      "Fold: 16  Epoch: 492  Training loss = 5.1820  Validation loss = 7.8012  \n",
      "\n",
      "Fold: 16  Epoch: 493  Training loss = 5.1814  Validation loss = 7.8002  \n",
      "\n",
      "Fold: 16  Epoch: 494  Training loss = 5.1808  Validation loss = 7.7994  \n",
      "\n",
      "Fold: 16  Epoch: 495  Training loss = 5.1802  Validation loss = 7.7986  \n",
      "\n",
      "Fold: 16  Epoch: 496  Training loss = 5.1796  Validation loss = 7.7975  \n",
      "\n",
      "Fold: 16  Epoch: 497  Training loss = 5.1791  Validation loss = 7.7968  \n",
      "\n",
      "Fold: 16  Epoch: 498  Training loss = 5.1785  Validation loss = 7.7960  \n",
      "\n",
      "Fold: 16  Epoch: 499  Training loss = 5.1779  Validation loss = 7.7951  \n",
      "\n",
      "Fold: 16  Epoch: 500  Training loss = 5.1773  Validation loss = 7.7943  \n",
      "\n",
      "Check model:  Fold: 16  Optimal epoch: 500  \n",
      "\n",
      "Fold: 17  Epoch: 1  Training loss = 5.5222  Validation loss = 3.3098  \n",
      "\n",
      "Fold: 17  Epoch: 2  Training loss = 5.5213  Validation loss = 3.3094  \n",
      "\n",
      "Fold: 17  Epoch: 3  Training loss = 5.5203  Validation loss = 3.3089  \n",
      "\n",
      "Fold: 17  Epoch: 4  Training loss = 5.5195  Validation loss = 3.3086  \n",
      "\n",
      "Fold: 17  Epoch: 5  Training loss = 5.5188  Validation loss = 3.3083  \n",
      "\n",
      "Fold: 17  Epoch: 6  Training loss = 5.5181  Validation loss = 3.3079  \n",
      "\n",
      "Fold: 17  Epoch: 7  Training loss = 5.5172  Validation loss = 3.3076  \n",
      "\n",
      "Fold: 17  Epoch: 8  Training loss = 5.5163  Validation loss = 3.3072  \n",
      "\n",
      "Fold: 17  Epoch: 9  Training loss = 5.5153  Validation loss = 3.3068  \n",
      "\n",
      "Fold: 17  Epoch: 10  Training loss = 5.5145  Validation loss = 3.3064  \n",
      "\n",
      "Fold: 17  Epoch: 11  Training loss = 5.5135  Validation loss = 3.3059  \n",
      "\n",
      "Fold: 17  Epoch: 12  Training loss = 5.5126  Validation loss = 3.3055  \n",
      "\n",
      "Fold: 17  Epoch: 13  Training loss = 5.5117  Validation loss = 3.3051  \n",
      "\n",
      "Fold: 17  Epoch: 14  Training loss = 5.5109  Validation loss = 3.3047  \n",
      "\n",
      "Fold: 17  Epoch: 15  Training loss = 5.5102  Validation loss = 3.3044  \n",
      "\n",
      "Fold: 17  Epoch: 16  Training loss = 5.5094  Validation loss = 3.3040  \n",
      "\n",
      "Fold: 17  Epoch: 17  Training loss = 5.5084  Validation loss = 3.3037  \n",
      "\n",
      "Fold: 17  Epoch: 18  Training loss = 5.5075  Validation loss = 3.3033  \n",
      "\n",
      "Fold: 17  Epoch: 19  Training loss = 5.5065  Validation loss = 3.3029  \n",
      "\n",
      "Fold: 17  Epoch: 20  Training loss = 5.5058  Validation loss = 3.3026  \n",
      "\n",
      "Fold: 17  Epoch: 21  Training loss = 5.5048  Validation loss = 3.3021  \n",
      "\n",
      "Fold: 17  Epoch: 22  Training loss = 5.5040  Validation loss = 3.3017  \n",
      "\n",
      "Fold: 17  Epoch: 23  Training loss = 5.5032  Validation loss = 3.3013  \n",
      "\n",
      "Fold: 17  Epoch: 24  Training loss = 5.5023  Validation loss = 3.3009  \n",
      "\n",
      "Fold: 17  Epoch: 25  Training loss = 5.5015  Validation loss = 3.3006  \n",
      "\n",
      "Fold: 17  Epoch: 26  Training loss = 5.5006  Validation loss = 3.3002  \n",
      "\n",
      "Fold: 17  Epoch: 27  Training loss = 5.4997  Validation loss = 3.2999  \n",
      "\n",
      "Fold: 17  Epoch: 28  Training loss = 5.4989  Validation loss = 3.2995  \n",
      "\n",
      "Fold: 17  Epoch: 29  Training loss = 5.4981  Validation loss = 3.2992  \n",
      "\n",
      "Fold: 17  Epoch: 30  Training loss = 5.4974  Validation loss = 3.2988  \n",
      "\n",
      "Fold: 17  Epoch: 31  Training loss = 5.4967  Validation loss = 3.2985  \n",
      "\n",
      "Fold: 17  Epoch: 32  Training loss = 5.4959  Validation loss = 3.2981  \n",
      "\n",
      "Fold: 17  Epoch: 33  Training loss = 5.4949  Validation loss = 3.2977  \n",
      "\n",
      "Fold: 17  Epoch: 34  Training loss = 5.4940  Validation loss = 3.2973  \n",
      "\n",
      "Fold: 17  Epoch: 35  Training loss = 5.4930  Validation loss = 3.2969  \n",
      "\n",
      "Fold: 17  Epoch: 36  Training loss = 5.4921  Validation loss = 3.2965  \n",
      "\n",
      "Fold: 17  Epoch: 37  Training loss = 5.4913  Validation loss = 3.2961  \n",
      "\n",
      "Fold: 17  Epoch: 38  Training loss = 5.4904  Validation loss = 3.2958  \n",
      "\n",
      "Fold: 17  Epoch: 39  Training loss = 5.4897  Validation loss = 3.2955  \n",
      "\n",
      "Fold: 17  Epoch: 40  Training loss = 5.4888  Validation loss = 3.2951  \n",
      "\n",
      "Fold: 17  Epoch: 41  Training loss = 5.4879  Validation loss = 3.2948  \n",
      "\n",
      "Fold: 17  Epoch: 42  Training loss = 5.4870  Validation loss = 3.2944  \n",
      "\n",
      "Fold: 17  Epoch: 43  Training loss = 5.4861  Validation loss = 3.2940  \n",
      "\n",
      "Fold: 17  Epoch: 44  Training loss = 5.4853  Validation loss = 3.2937  \n",
      "\n",
      "Fold: 17  Epoch: 45  Training loss = 5.4843  Validation loss = 3.2932  \n",
      "\n",
      "Fold: 17  Epoch: 46  Training loss = 5.4833  Validation loss = 3.2929  \n",
      "\n",
      "Fold: 17  Epoch: 47  Training loss = 5.4824  Validation loss = 3.2926  \n",
      "\n",
      "Fold: 17  Epoch: 48  Training loss = 5.4816  Validation loss = 3.2922  \n",
      "\n",
      "Fold: 17  Epoch: 49  Training loss = 5.4808  Validation loss = 3.2918  \n",
      "\n",
      "Fold: 17  Epoch: 50  Training loss = 5.4801  Validation loss = 3.2915  \n",
      "\n",
      "Fold: 17  Epoch: 51  Training loss = 5.4794  Validation loss = 3.2911  \n",
      "\n",
      "Fold: 17  Epoch: 52  Training loss = 5.4786  Validation loss = 3.2908  \n",
      "\n",
      "Fold: 17  Epoch: 53  Training loss = 5.4776  Validation loss = 3.2904  \n",
      "\n",
      "Fold: 17  Epoch: 54  Training loss = 5.4767  Validation loss = 3.2900  \n",
      "\n",
      "Fold: 17  Epoch: 55  Training loss = 5.4757  Validation loss = 3.2896  \n",
      "\n",
      "Fold: 17  Epoch: 56  Training loss = 5.4747  Validation loss = 3.2892  \n",
      "\n",
      "Fold: 17  Epoch: 57  Training loss = 5.4740  Validation loss = 3.2889  \n",
      "\n",
      "Fold: 17  Epoch: 58  Training loss = 5.4731  Validation loss = 3.2885  \n",
      "\n",
      "Fold: 17  Epoch: 59  Training loss = 5.4722  Validation loss = 3.2882  \n",
      "\n",
      "Fold: 17  Epoch: 60  Training loss = 5.4713  Validation loss = 3.2878  \n",
      "\n",
      "Fold: 17  Epoch: 61  Training loss = 5.4703  Validation loss = 3.2875  \n",
      "\n",
      "Fold: 17  Epoch: 62  Training loss = 5.4692  Validation loss = 3.2870  \n",
      "\n",
      "Fold: 17  Epoch: 63  Training loss = 5.4682  Validation loss = 3.2866  \n",
      "\n",
      "Fold: 17  Epoch: 64  Training loss = 5.4672  Validation loss = 3.2862  \n",
      "\n",
      "Fold: 17  Epoch: 65  Training loss = 5.4662  Validation loss = 3.2858  \n",
      "\n",
      "Fold: 17  Epoch: 66  Training loss = 5.4652  Validation loss = 3.2854  \n",
      "\n",
      "Fold: 17  Epoch: 67  Training loss = 5.4642  Validation loss = 3.2850  \n",
      "\n",
      "Fold: 17  Epoch: 68  Training loss = 5.4632  Validation loss = 3.2845  \n",
      "\n",
      "Fold: 17  Epoch: 69  Training loss = 5.4619  Validation loss = 3.2841  \n",
      "\n",
      "Fold: 17  Epoch: 70  Training loss = 5.4610  Validation loss = 3.2837  \n",
      "\n",
      "Fold: 17  Epoch: 71  Training loss = 5.4601  Validation loss = 3.2834  \n",
      "\n",
      "Fold: 17  Epoch: 72  Training loss = 5.4591  Validation loss = 3.2830  \n",
      "\n",
      "Fold: 17  Epoch: 73  Training loss = 5.4583  Validation loss = 3.2827  \n",
      "\n",
      "Fold: 17  Epoch: 74  Training loss = 5.4572  Validation loss = 3.2823  \n",
      "\n",
      "Fold: 17  Epoch: 75  Training loss = 5.4546  Validation loss = 3.2820  \n",
      "\n",
      "Fold: 17  Epoch: 76  Training loss = 5.4500  Validation loss = 3.2817  \n",
      "\n",
      "Fold: 17  Epoch: 77  Training loss = 5.4469  Validation loss = 3.2814  \n",
      "\n",
      "Fold: 17  Epoch: 78  Training loss = 5.4457  Validation loss = 3.2811  \n",
      "\n",
      "Fold: 17  Epoch: 79  Training loss = 5.4448  Validation loss = 3.2808  \n",
      "\n",
      "Fold: 17  Epoch: 80  Training loss = 5.4437  Validation loss = 3.2804  \n",
      "\n",
      "Fold: 17  Epoch: 81  Training loss = 5.4429  Validation loss = 3.2800  \n",
      "\n",
      "Fold: 17  Epoch: 82  Training loss = 5.4420  Validation loss = 3.2797  \n",
      "\n",
      "Fold: 17  Epoch: 83  Training loss = 5.4411  Validation loss = 3.2794  \n",
      "\n",
      "Fold: 17  Epoch: 84  Training loss = 5.4400  Validation loss = 3.2789  \n",
      "\n",
      "Fold: 17  Epoch: 85  Training loss = 5.4391  Validation loss = 3.2786  \n",
      "\n",
      "Fold: 17  Epoch: 86  Training loss = 5.4381  Validation loss = 3.2782  \n",
      "\n",
      "Fold: 17  Epoch: 87  Training loss = 5.4372  Validation loss = 3.2778  \n",
      "\n",
      "Fold: 17  Epoch: 88  Training loss = 5.4362  Validation loss = 3.2774  \n",
      "\n",
      "Fold: 17  Epoch: 89  Training loss = 5.4354  Validation loss = 3.2771  \n",
      "\n",
      "Fold: 17  Epoch: 90  Training loss = 5.4342  Validation loss = 3.2767  \n",
      "\n",
      "Fold: 17  Epoch: 91  Training loss = 5.4334  Validation loss = 3.2763  \n",
      "\n",
      "Fold: 17  Epoch: 92  Training loss = 5.4324  Validation loss = 3.2759  \n",
      "\n",
      "Fold: 17  Epoch: 93  Training loss = 5.4313  Validation loss = 3.2755  \n",
      "\n",
      "Fold: 17  Epoch: 94  Training loss = 5.4304  Validation loss = 3.2751  \n",
      "\n",
      "Fold: 17  Epoch: 95  Training loss = 5.4292  Validation loss = 3.2748  \n",
      "\n",
      "Fold: 17  Epoch: 96  Training loss = 5.4281  Validation loss = 3.2743  \n",
      "\n",
      "Fold: 17  Epoch: 97  Training loss = 5.4272  Validation loss = 3.2739  \n",
      "\n",
      "Fold: 17  Epoch: 98  Training loss = 5.4265  Validation loss = 3.2736  \n",
      "\n",
      "Fold: 17  Epoch: 99  Training loss = 5.4258  Validation loss = 3.2733  \n",
      "\n",
      "Fold: 17  Epoch: 100  Training loss = 5.4248  Validation loss = 3.2729  \n",
      "\n",
      "Fold: 17  Epoch: 101  Training loss = 5.4239  Validation loss = 3.2726  \n",
      "\n",
      "Fold: 17  Epoch: 102  Training loss = 5.4227  Validation loss = 3.2721  \n",
      "\n",
      "Fold: 17  Epoch: 103  Training loss = 5.4220  Validation loss = 3.2718  \n",
      "\n",
      "Fold: 17  Epoch: 104  Training loss = 5.4211  Validation loss = 3.2714  \n",
      "\n",
      "Fold: 17  Epoch: 105  Training loss = 5.4203  Validation loss = 3.2711  \n",
      "\n",
      "Fold: 17  Epoch: 106  Training loss = 5.4196  Validation loss = 3.2708  \n",
      "\n",
      "Fold: 17  Epoch: 107  Training loss = 5.4184  Validation loss = 3.2704  \n",
      "\n",
      "Fold: 17  Epoch: 108  Training loss = 5.4173  Validation loss = 3.2700  \n",
      "\n",
      "Fold: 17  Epoch: 109  Training loss = 5.4165  Validation loss = 3.2697  \n",
      "\n",
      "Fold: 17  Epoch: 110  Training loss = 5.4156  Validation loss = 3.2693  \n",
      "\n",
      "Fold: 17  Epoch: 111  Training loss = 5.4145  Validation loss = 3.2689  \n",
      "\n",
      "Fold: 17  Epoch: 112  Training loss = 5.4136  Validation loss = 3.2685  \n",
      "\n",
      "Fold: 17  Epoch: 113  Training loss = 5.4130  Validation loss = 3.2683  \n",
      "\n",
      "Fold: 17  Epoch: 114  Training loss = 5.4122  Validation loss = 3.2679  \n",
      "\n",
      "Fold: 17  Epoch: 115  Training loss = 5.4111  Validation loss = 3.2675  \n",
      "\n",
      "Fold: 17  Epoch: 116  Training loss = 5.4102  Validation loss = 3.2672  \n",
      "\n",
      "Fold: 17  Epoch: 117  Training loss = 5.4093  Validation loss = 3.2667  \n",
      "\n",
      "Fold: 17  Epoch: 118  Training loss = 5.4083  Validation loss = 3.2664  \n",
      "\n",
      "Fold: 17  Epoch: 119  Training loss = 5.4074  Validation loss = 3.2660  \n",
      "\n",
      "Fold: 17  Epoch: 120  Training loss = 5.4067  Validation loss = 3.2656  \n",
      "\n",
      "Fold: 17  Epoch: 121  Training loss = 5.4058  Validation loss = 3.2653  \n",
      "\n",
      "Fold: 17  Epoch: 122  Training loss = 5.4050  Validation loss = 3.2649  \n",
      "\n",
      "Fold: 17  Epoch: 123  Training loss = 5.4041  Validation loss = 3.2645  \n",
      "\n",
      "Fold: 17  Epoch: 124  Training loss = 5.4032  Validation loss = 3.2642  \n",
      "\n",
      "Fold: 17  Epoch: 125  Training loss = 5.4021  Validation loss = 3.2638  \n",
      "\n",
      "Fold: 17  Epoch: 126  Training loss = 5.4013  Validation loss = 3.2635  \n",
      "\n",
      "Fold: 17  Epoch: 127  Training loss = 5.4004  Validation loss = 3.2631  \n",
      "\n",
      "Fold: 17  Epoch: 128  Training loss = 5.3996  Validation loss = 3.2628  \n",
      "\n",
      "Fold: 17  Epoch: 129  Training loss = 5.3986  Validation loss = 3.2624  \n",
      "\n",
      "Fold: 17  Epoch: 130  Training loss = 5.3976  Validation loss = 3.2621  \n",
      "\n",
      "Fold: 17  Epoch: 131  Training loss = 5.3969  Validation loss = 3.2618  \n",
      "\n",
      "Fold: 17  Epoch: 132  Training loss = 5.3959  Validation loss = 3.2614  \n",
      "\n",
      "Fold: 17  Epoch: 133  Training loss = 5.3952  Validation loss = 3.2611  \n",
      "\n",
      "Fold: 17  Epoch: 134  Training loss = 5.3944  Validation loss = 3.2607  \n",
      "\n",
      "Fold: 17  Epoch: 135  Training loss = 5.3936  Validation loss = 3.2604  \n",
      "\n",
      "Fold: 17  Epoch: 136  Training loss = 5.3927  Validation loss = 3.2600  \n",
      "\n",
      "Fold: 17  Epoch: 137  Training loss = 5.3919  Validation loss = 3.2597  \n",
      "\n",
      "Fold: 17  Epoch: 138  Training loss = 5.3910  Validation loss = 3.2593  \n",
      "\n",
      "Fold: 17  Epoch: 139  Training loss = 5.3901  Validation loss = 3.2589  \n",
      "\n",
      "Fold: 17  Epoch: 140  Training loss = 5.3892  Validation loss = 3.2585  \n",
      "\n",
      "Fold: 17  Epoch: 141  Training loss = 5.3884  Validation loss = 3.2582  \n",
      "\n",
      "Fold: 17  Epoch: 142  Training loss = 5.3878  Validation loss = 3.2580  \n",
      "\n",
      "Fold: 17  Epoch: 143  Training loss = 5.3869  Validation loss = 3.2576  \n",
      "\n",
      "Fold: 17  Epoch: 144  Training loss = 5.3858  Validation loss = 3.2571  \n",
      "\n",
      "Fold: 17  Epoch: 145  Training loss = 5.3849  Validation loss = 3.2568  \n",
      "\n",
      "Fold: 17  Epoch: 146  Training loss = 5.3841  Validation loss = 3.2565  \n",
      "\n",
      "Fold: 17  Epoch: 147  Training loss = 5.3832  Validation loss = 3.2561  \n",
      "\n",
      "Fold: 17  Epoch: 148  Training loss = 5.3825  Validation loss = 3.2558  \n",
      "\n",
      "Fold: 17  Epoch: 149  Training loss = 5.3816  Validation loss = 3.2554  \n",
      "\n",
      "Fold: 17  Epoch: 150  Training loss = 5.3808  Validation loss = 3.2550  \n",
      "\n",
      "Fold: 17  Epoch: 151  Training loss = 5.3800  Validation loss = 3.2547  \n",
      "\n",
      "Fold: 17  Epoch: 152  Training loss = 5.3792  Validation loss = 3.2544  \n",
      "\n",
      "Fold: 17  Epoch: 153  Training loss = 5.3784  Validation loss = 3.2541  \n",
      "\n",
      "Fold: 17  Epoch: 154  Training loss = 5.3776  Validation loss = 3.2538  \n",
      "\n",
      "Fold: 17  Epoch: 155  Training loss = 5.3767  Validation loss = 3.2534  \n",
      "\n",
      "Fold: 17  Epoch: 156  Training loss = 5.3759  Validation loss = 3.2531  \n",
      "\n",
      "Fold: 17  Epoch: 157  Training loss = 5.3752  Validation loss = 3.2528  \n",
      "\n",
      "Fold: 17  Epoch: 158  Training loss = 5.3745  Validation loss = 3.2525  \n",
      "\n",
      "Fold: 17  Epoch: 159  Training loss = 5.3739  Validation loss = 3.2522  \n",
      "\n",
      "Fold: 17  Epoch: 160  Training loss = 5.3733  Validation loss = 3.2520  \n",
      "\n",
      "Fold: 17  Epoch: 161  Training loss = 5.3725  Validation loss = 3.2516  \n",
      "\n",
      "Fold: 17  Epoch: 162  Training loss = 5.3717  Validation loss = 3.2513  \n",
      "\n",
      "Fold: 17  Epoch: 163  Training loss = 5.3707  Validation loss = 3.2509  \n",
      "\n",
      "Fold: 17  Epoch: 164  Training loss = 5.3699  Validation loss = 3.2506  \n",
      "\n",
      "Fold: 17  Epoch: 165  Training loss = 5.3692  Validation loss = 3.2503  \n",
      "\n",
      "Fold: 17  Epoch: 166  Training loss = 5.3684  Validation loss = 3.2499  \n",
      "\n",
      "Fold: 17  Epoch: 167  Training loss = 5.3678  Validation loss = 3.2497  \n",
      "\n",
      "Fold: 17  Epoch: 168  Training loss = 5.3671  Validation loss = 3.2493  \n",
      "\n",
      "Fold: 17  Epoch: 169  Training loss = 5.3665  Validation loss = 3.2490  \n",
      "\n",
      "Fold: 17  Epoch: 170  Training loss = 5.3659  Validation loss = 3.2488  \n",
      "\n",
      "Fold: 17  Epoch: 171  Training loss = 5.3652  Validation loss = 3.2485  \n",
      "\n",
      "Fold: 17  Epoch: 172  Training loss = 5.3644  Validation loss = 3.2481  \n",
      "\n",
      "Fold: 17  Epoch: 173  Training loss = 5.3637  Validation loss = 3.2478  \n",
      "\n",
      "Fold: 17  Epoch: 174  Training loss = 5.3630  Validation loss = 3.2475  \n",
      "\n",
      "Fold: 17  Epoch: 175  Training loss = 5.3623  Validation loss = 3.2472  \n",
      "\n",
      "Fold: 17  Epoch: 176  Training loss = 5.3614  Validation loss = 3.2468  \n",
      "\n",
      "Fold: 17  Epoch: 177  Training loss = 5.3607  Validation loss = 3.2465  \n",
      "\n",
      "Fold: 17  Epoch: 178  Training loss = 5.3599  Validation loss = 3.2462  \n",
      "\n",
      "Fold: 17  Epoch: 179  Training loss = 5.3591  Validation loss = 3.2459  \n",
      "\n",
      "Fold: 17  Epoch: 180  Training loss = 5.3583  Validation loss = 3.2455  \n",
      "\n",
      "Fold: 17  Epoch: 181  Training loss = 5.3576  Validation loss = 3.2452  \n",
      "\n",
      "Fold: 17  Epoch: 182  Training loss = 5.3569  Validation loss = 3.2449  \n",
      "\n",
      "Fold: 17  Epoch: 183  Training loss = 5.3563  Validation loss = 3.2446  \n",
      "\n",
      "Fold: 17  Epoch: 184  Training loss = 5.3555  Validation loss = 3.2443  \n",
      "\n",
      "Fold: 17  Epoch: 185  Training loss = 5.3549  Validation loss = 3.2440  \n",
      "\n",
      "Fold: 17  Epoch: 186  Training loss = 5.3541  Validation loss = 3.2437  \n",
      "\n",
      "Fold: 17  Epoch: 187  Training loss = 5.3533  Validation loss = 3.2433  \n",
      "\n",
      "Fold: 17  Epoch: 188  Training loss = 5.3526  Validation loss = 3.2429  \n",
      "\n",
      "Fold: 17  Epoch: 189  Training loss = 5.3519  Validation loss = 3.2426  \n",
      "\n",
      "Fold: 17  Epoch: 190  Training loss = 5.3512  Validation loss = 3.2423  \n",
      "\n",
      "Fold: 17  Epoch: 191  Training loss = 5.3504  Validation loss = 3.2420  \n",
      "\n",
      "Fold: 17  Epoch: 192  Training loss = 5.3497  Validation loss = 3.2417  \n",
      "\n",
      "Fold: 17  Epoch: 193  Training loss = 5.3489  Validation loss = 3.2413  \n",
      "\n",
      "Fold: 17  Epoch: 194  Training loss = 5.3479  Validation loss = 3.2409  \n",
      "\n",
      "Fold: 17  Epoch: 195  Training loss = 5.3471  Validation loss = 3.2405  \n",
      "\n",
      "Fold: 17  Epoch: 196  Training loss = 5.3464  Validation loss = 3.2402  \n",
      "\n",
      "Fold: 17  Epoch: 197  Training loss = 5.3457  Validation loss = 3.2399  \n",
      "\n",
      "Fold: 17  Epoch: 198  Training loss = 5.3449  Validation loss = 3.2395  \n",
      "\n",
      "Fold: 17  Epoch: 199  Training loss = 5.3442  Validation loss = 3.2392  \n",
      "\n",
      "Fold: 17  Epoch: 200  Training loss = 5.3435  Validation loss = 3.2389  \n",
      "\n",
      "Fold: 17  Epoch: 201  Training loss = 5.3428  Validation loss = 3.2386  \n",
      "\n",
      "Fold: 17  Epoch: 202  Training loss = 5.3420  Validation loss = 3.2382  \n",
      "\n",
      "Fold: 17  Epoch: 203  Training loss = 5.3412  Validation loss = 3.2379  \n",
      "\n",
      "Fold: 17  Epoch: 204  Training loss = 5.3406  Validation loss = 3.2376  \n",
      "\n",
      "Fold: 17  Epoch: 205  Training loss = 5.3399  Validation loss = 3.2373  \n",
      "\n",
      "Fold: 17  Epoch: 206  Training loss = 5.3391  Validation loss = 3.2370  \n",
      "\n",
      "Fold: 17  Epoch: 207  Training loss = 5.3384  Validation loss = 3.2366  \n",
      "\n",
      "Fold: 17  Epoch: 208  Training loss = 5.3376  Validation loss = 3.2364  \n",
      "\n",
      "Fold: 17  Epoch: 209  Training loss = 5.3369  Validation loss = 3.2360  \n",
      "\n",
      "Fold: 17  Epoch: 210  Training loss = 5.3363  Validation loss = 3.2357  \n",
      "\n",
      "Fold: 17  Epoch: 211  Training loss = 5.3357  Validation loss = 3.2354  \n",
      "\n",
      "Fold: 17  Epoch: 212  Training loss = 5.3349  Validation loss = 3.2351  \n",
      "\n",
      "Fold: 17  Epoch: 213  Training loss = 5.3343  Validation loss = 3.2348  \n",
      "\n",
      "Fold: 17  Epoch: 214  Training loss = 5.3337  Validation loss = 3.2345  \n",
      "\n",
      "Fold: 17  Epoch: 215  Training loss = 5.3330  Validation loss = 3.2342  \n",
      "\n",
      "Fold: 17  Epoch: 216  Training loss = 5.3323  Validation loss = 3.2339  \n",
      "\n",
      "Fold: 17  Epoch: 217  Training loss = 5.3314  Validation loss = 3.2334  \n",
      "\n",
      "Fold: 17  Epoch: 218  Training loss = 5.3307  Validation loss = 3.2331  \n",
      "\n",
      "Fold: 17  Epoch: 219  Training loss = 5.3299  Validation loss = 3.2327  \n",
      "\n",
      "Fold: 17  Epoch: 220  Training loss = 5.3293  Validation loss = 3.2324  \n",
      "\n",
      "Fold: 17  Epoch: 221  Training loss = 5.3285  Validation loss = 3.2320  \n",
      "\n",
      "Fold: 17  Epoch: 222  Training loss = 5.3278  Validation loss = 3.2317  \n",
      "\n",
      "Fold: 17  Epoch: 223  Training loss = 5.3272  Validation loss = 3.2314  \n",
      "\n",
      "Fold: 17  Epoch: 224  Training loss = 5.3264  Validation loss = 3.2311  \n",
      "\n",
      "Fold: 17  Epoch: 225  Training loss = 5.3257  Validation loss = 3.2308  \n",
      "\n",
      "Fold: 17  Epoch: 226  Training loss = 5.3250  Validation loss = 3.2305  \n",
      "\n",
      "Fold: 17  Epoch: 227  Training loss = 5.3244  Validation loss = 3.2302  \n",
      "\n",
      "Fold: 17  Epoch: 228  Training loss = 5.3238  Validation loss = 3.2299  \n",
      "\n",
      "Fold: 17  Epoch: 229  Training loss = 5.3231  Validation loss = 3.2296  \n",
      "\n",
      "Fold: 17  Epoch: 230  Training loss = 5.3223  Validation loss = 3.2293  \n",
      "\n",
      "Fold: 17  Epoch: 231  Training loss = 5.3216  Validation loss = 3.2290  \n",
      "\n",
      "Fold: 17  Epoch: 232  Training loss = 5.3209  Validation loss = 3.2286  \n",
      "\n",
      "Fold: 17  Epoch: 233  Training loss = 5.3203  Validation loss = 3.2283  \n",
      "\n",
      "Fold: 17  Epoch: 234  Training loss = 5.3197  Validation loss = 3.2280  \n",
      "\n",
      "Fold: 17  Epoch: 235  Training loss = 5.3190  Validation loss = 3.2277  \n",
      "\n",
      "Fold: 17  Epoch: 236  Training loss = 5.3182  Validation loss = 3.2273  \n",
      "\n",
      "Fold: 17  Epoch: 237  Training loss = 5.3175  Validation loss = 3.2270  \n",
      "\n",
      "Fold: 17  Epoch: 238  Training loss = 5.3167  Validation loss = 3.2266  \n",
      "\n",
      "Fold: 17  Epoch: 239  Training loss = 5.3160  Validation loss = 3.2263  \n",
      "\n",
      "Fold: 17  Epoch: 240  Training loss = 5.3153  Validation loss = 3.2259  \n",
      "\n",
      "Fold: 17  Epoch: 241  Training loss = 5.3145  Validation loss = 3.2255  \n",
      "\n",
      "Fold: 17  Epoch: 242  Training loss = 5.3137  Validation loss = 3.2252  \n",
      "\n",
      "Fold: 17  Epoch: 243  Training loss = 5.3131  Validation loss = 3.2249  \n",
      "\n",
      "Fold: 17  Epoch: 244  Training loss = 5.3123  Validation loss = 3.2246  \n",
      "\n",
      "Fold: 17  Epoch: 245  Training loss = 5.3116  Validation loss = 3.2242  \n",
      "\n",
      "Fold: 17  Epoch: 246  Training loss = 5.3110  Validation loss = 3.2239  \n",
      "\n",
      "Fold: 17  Epoch: 247  Training loss = 5.3103  Validation loss = 3.2236  \n",
      "\n",
      "Fold: 17  Epoch: 248  Training loss = 5.3095  Validation loss = 3.2232  \n",
      "\n",
      "Fold: 17  Epoch: 249  Training loss = 5.3088  Validation loss = 3.2229  \n",
      "\n",
      "Fold: 17  Epoch: 250  Training loss = 5.3080  Validation loss = 3.2225  \n",
      "\n",
      "Fold: 17  Epoch: 251  Training loss = 5.3073  Validation loss = 3.2222  \n",
      "\n",
      "Fold: 17  Epoch: 252  Training loss = 5.3066  Validation loss = 3.2219  \n",
      "\n",
      "Fold: 17  Epoch: 253  Training loss = 5.3059  Validation loss = 3.2215  \n",
      "\n",
      "Fold: 17  Epoch: 254  Training loss = 5.3052  Validation loss = 3.2212  \n",
      "\n",
      "Fold: 17  Epoch: 255  Training loss = 5.3046  Validation loss = 3.2209  \n",
      "\n",
      "Fold: 17  Epoch: 256  Training loss = 5.3039  Validation loss = 3.2205  \n",
      "\n",
      "Fold: 17  Epoch: 257  Training loss = 5.3033  Validation loss = 3.2202  \n",
      "\n",
      "Fold: 17  Epoch: 258  Training loss = 5.3025  Validation loss = 3.2199  \n",
      "\n",
      "Fold: 17  Epoch: 259  Training loss = 5.3018  Validation loss = 3.2195  \n",
      "\n",
      "Fold: 17  Epoch: 260  Training loss = 5.3011  Validation loss = 3.2192  \n",
      "\n",
      "Fold: 17  Epoch: 261  Training loss = 5.3003  Validation loss = 3.2189  \n",
      "\n",
      "Fold: 17  Epoch: 262  Training loss = 5.2998  Validation loss = 3.2186  \n",
      "\n",
      "Fold: 17  Epoch: 263  Training loss = 5.2990  Validation loss = 3.2183  \n",
      "\n",
      "Fold: 17  Epoch: 264  Training loss = 5.2983  Validation loss = 3.2179  \n",
      "\n",
      "Fold: 17  Epoch: 265  Training loss = 5.2977  Validation loss = 3.2176  \n",
      "\n",
      "Fold: 17  Epoch: 266  Training loss = 5.2970  Validation loss = 3.2172  \n",
      "\n",
      "Fold: 17  Epoch: 267  Training loss = 5.2964  Validation loss = 3.2170  \n",
      "\n",
      "Fold: 17  Epoch: 268  Training loss = 5.2957  Validation loss = 3.2167  \n",
      "\n",
      "Fold: 17  Epoch: 269  Training loss = 5.2951  Validation loss = 3.2164  \n",
      "\n",
      "Fold: 17  Epoch: 270  Training loss = 5.2945  Validation loss = 3.2160  \n",
      "\n",
      "Fold: 17  Epoch: 271  Training loss = 5.2937  Validation loss = 3.2157  \n",
      "\n",
      "Fold: 17  Epoch: 272  Training loss = 5.2930  Validation loss = 3.2153  \n",
      "\n",
      "Fold: 17  Epoch: 273  Training loss = 5.2922  Validation loss = 3.2150  \n",
      "\n",
      "Fold: 17  Epoch: 274  Training loss = 5.2916  Validation loss = 3.2147  \n",
      "\n",
      "Fold: 17  Epoch: 275  Training loss = 5.2910  Validation loss = 3.2144  \n",
      "\n",
      "Fold: 17  Epoch: 276  Training loss = 5.2903  Validation loss = 3.2140  \n",
      "\n",
      "Fold: 17  Epoch: 277  Training loss = 5.2895  Validation loss = 3.2137  \n",
      "\n",
      "Fold: 17  Epoch: 278  Training loss = 5.2888  Validation loss = 3.2133  \n",
      "\n",
      "Fold: 17  Epoch: 279  Training loss = 5.2881  Validation loss = 3.2130  \n",
      "\n",
      "Fold: 17  Epoch: 280  Training loss = 5.2873  Validation loss = 3.2126  \n",
      "\n",
      "Fold: 17  Epoch: 281  Training loss = 5.2866  Validation loss = 3.2123  \n",
      "\n",
      "Fold: 17  Epoch: 282  Training loss = 5.2859  Validation loss = 3.2120  \n",
      "\n",
      "Fold: 17  Epoch: 283  Training loss = 5.2853  Validation loss = 3.2116  \n",
      "\n",
      "Fold: 17  Epoch: 284  Training loss = 5.2847  Validation loss = 3.2114  \n",
      "\n",
      "Fold: 17  Epoch: 285  Training loss = 5.2840  Validation loss = 3.2110  \n",
      "\n",
      "Fold: 17  Epoch: 286  Training loss = 5.2833  Validation loss = 3.2107  \n",
      "\n",
      "Fold: 17  Epoch: 287  Training loss = 5.2826  Validation loss = 3.2104  \n",
      "\n",
      "Fold: 17  Epoch: 288  Training loss = 5.2819  Validation loss = 3.2101  \n",
      "\n",
      "Fold: 17  Epoch: 289  Training loss = 5.2811  Validation loss = 3.2096  \n",
      "\n",
      "Fold: 17  Epoch: 290  Training loss = 5.2803  Validation loss = 3.2093  \n",
      "\n",
      "Fold: 17  Epoch: 291  Training loss = 5.2796  Validation loss = 3.2090  \n",
      "\n",
      "Fold: 17  Epoch: 292  Training loss = 5.2788  Validation loss = 3.2086  \n",
      "\n",
      "Fold: 17  Epoch: 293  Training loss = 5.2781  Validation loss = 3.2082  \n",
      "\n",
      "Fold: 17  Epoch: 294  Training loss = 5.2774  Validation loss = 3.2078  \n",
      "\n",
      "Fold: 17  Epoch: 295  Training loss = 5.2767  Validation loss = 3.2074  \n",
      "\n",
      "Fold: 17  Epoch: 296  Training loss = 5.2760  Validation loss = 3.2071  \n",
      "\n",
      "Fold: 17  Epoch: 297  Training loss = 5.2753  Validation loss = 3.2068  \n",
      "\n",
      "Fold: 17  Epoch: 298  Training loss = 5.2744  Validation loss = 3.2064  \n",
      "\n",
      "Fold: 17  Epoch: 299  Training loss = 5.2737  Validation loss = 3.2061  \n",
      "\n",
      "Fold: 17  Epoch: 300  Training loss = 5.2730  Validation loss = 3.2057  \n",
      "\n",
      "Fold: 17  Epoch: 301  Training loss = 5.2722  Validation loss = 3.2053  \n",
      "\n",
      "Fold: 17  Epoch: 302  Training loss = 5.2716  Validation loss = 3.2050  \n",
      "\n",
      "Fold: 17  Epoch: 303  Training loss = 5.2709  Validation loss = 3.2047  \n",
      "\n",
      "Fold: 17  Epoch: 304  Training loss = 5.2701  Validation loss = 3.2043  \n",
      "\n",
      "Fold: 17  Epoch: 305  Training loss = 5.2694  Validation loss = 3.2039  \n",
      "\n",
      "Fold: 17  Epoch: 306  Training loss = 5.2688  Validation loss = 3.2037  \n",
      "\n",
      "Fold: 17  Epoch: 307  Training loss = 5.2681  Validation loss = 3.2034  \n",
      "\n",
      "Fold: 17  Epoch: 308  Training loss = 5.2674  Validation loss = 3.2031  \n",
      "\n",
      "Fold: 17  Epoch: 309  Training loss = 5.2668  Validation loss = 3.2028  \n",
      "\n",
      "Fold: 17  Epoch: 310  Training loss = 5.2662  Validation loss = 3.2025  \n",
      "\n",
      "Fold: 17  Epoch: 311  Training loss = 5.2655  Validation loss = 3.2022  \n",
      "\n",
      "Fold: 17  Epoch: 312  Training loss = 5.2648  Validation loss = 3.2018  \n",
      "\n",
      "Fold: 17  Epoch: 313  Training loss = 5.2639  Validation loss = 3.2015  \n",
      "\n",
      "Fold: 17  Epoch: 314  Training loss = 5.2631  Validation loss = 3.2011  \n",
      "\n",
      "Fold: 17  Epoch: 315  Training loss = 5.2624  Validation loss = 3.2008  \n",
      "\n",
      "Fold: 17  Epoch: 316  Training loss = 5.2615  Validation loss = 3.2004  \n",
      "\n",
      "Fold: 17  Epoch: 317  Training loss = 5.2608  Validation loss = 3.2001  \n",
      "\n",
      "Fold: 17  Epoch: 318  Training loss = 5.2600  Validation loss = 3.1997  \n",
      "\n",
      "Fold: 17  Epoch: 319  Training loss = 5.2594  Validation loss = 3.1994  \n",
      "\n",
      "Fold: 17  Epoch: 320  Training loss = 5.2586  Validation loss = 3.1991  \n",
      "\n",
      "Fold: 17  Epoch: 321  Training loss = 5.2579  Validation loss = 3.1987  \n",
      "\n",
      "Fold: 17  Epoch: 322  Training loss = 5.2571  Validation loss = 3.1984  \n",
      "\n",
      "Fold: 17  Epoch: 323  Training loss = 5.2562  Validation loss = 3.1980  \n",
      "\n",
      "Fold: 17  Epoch: 324  Training loss = 5.2556  Validation loss = 3.1977  \n",
      "\n",
      "Fold: 17  Epoch: 325  Training loss = 5.2548  Validation loss = 3.1973  \n",
      "\n",
      "Fold: 17  Epoch: 326  Training loss = 5.2541  Validation loss = 3.1970  \n",
      "\n",
      "Fold: 17  Epoch: 327  Training loss = 5.2535  Validation loss = 3.1966  \n",
      "\n",
      "Fold: 17  Epoch: 328  Training loss = 5.2527  Validation loss = 3.1962  \n",
      "\n",
      "Fold: 17  Epoch: 329  Training loss = 5.2519  Validation loss = 3.1958  \n",
      "\n",
      "Fold: 17  Epoch: 330  Training loss = 5.2511  Validation loss = 3.1953  \n",
      "\n",
      "Fold: 17  Epoch: 331  Training loss = 5.2503  Validation loss = 3.1950  \n",
      "\n",
      "Fold: 17  Epoch: 332  Training loss = 5.2496  Validation loss = 3.1946  \n",
      "\n",
      "Fold: 17  Epoch: 333  Training loss = 5.2489  Validation loss = 3.1943  \n",
      "\n",
      "Fold: 17  Epoch: 334  Training loss = 5.2483  Validation loss = 3.1940  \n",
      "\n",
      "Fold: 17  Epoch: 335  Training loss = 5.2476  Validation loss = 3.1936  \n",
      "\n",
      "Fold: 17  Epoch: 336  Training loss = 5.2469  Validation loss = 3.1934  \n",
      "\n",
      "Fold: 17  Epoch: 337  Training loss = 5.2462  Validation loss = 3.1930  \n",
      "\n",
      "Fold: 17  Epoch: 338  Training loss = 5.2455  Validation loss = 3.1927  \n",
      "\n",
      "Fold: 17  Epoch: 339  Training loss = 5.2448  Validation loss = 3.1923  \n",
      "\n",
      "Fold: 17  Epoch: 340  Training loss = 5.2441  Validation loss = 3.1920  \n",
      "\n",
      "Fold: 17  Epoch: 341  Training loss = 5.2434  Validation loss = 3.1916  \n",
      "\n",
      "Fold: 17  Epoch: 342  Training loss = 5.2426  Validation loss = 3.1912  \n",
      "\n",
      "Fold: 17  Epoch: 343  Training loss = 5.2419  Validation loss = 3.1909  \n",
      "\n",
      "Fold: 17  Epoch: 344  Training loss = 5.2412  Validation loss = 3.1905  \n",
      "\n",
      "Fold: 17  Epoch: 345  Training loss = 5.2405  Validation loss = 3.1902  \n",
      "\n",
      "Fold: 17  Epoch: 346  Training loss = 5.2398  Validation loss = 3.1898  \n",
      "\n",
      "Fold: 17  Epoch: 347  Training loss = 5.2393  Validation loss = 3.1896  \n",
      "\n",
      "Fold: 17  Epoch: 348  Training loss = 5.2387  Validation loss = 3.1892  \n",
      "\n",
      "Fold: 17  Epoch: 349  Training loss = 5.2380  Validation loss = 3.1889  \n",
      "\n",
      "Fold: 17  Epoch: 350  Training loss = 5.2374  Validation loss = 3.1885  \n",
      "\n",
      "Fold: 17  Epoch: 351  Training loss = 5.2365  Validation loss = 3.1881  \n",
      "\n",
      "Fold: 17  Epoch: 352  Training loss = 5.2358  Validation loss = 3.1878  \n",
      "\n",
      "Fold: 17  Epoch: 353  Training loss = 5.2350  Validation loss = 3.1874  \n",
      "\n",
      "Fold: 17  Epoch: 354  Training loss = 5.2345  Validation loss = 3.1871  \n",
      "\n",
      "Fold: 17  Epoch: 355  Training loss = 5.2339  Validation loss = 3.1868  \n",
      "\n",
      "Fold: 17  Epoch: 356  Training loss = 5.2333  Validation loss = 3.1865  \n",
      "\n",
      "Fold: 17  Epoch: 357  Training loss = 5.2325  Validation loss = 3.1862  \n",
      "\n",
      "Fold: 17  Epoch: 358  Training loss = 5.2319  Validation loss = 3.1859  \n",
      "\n",
      "Fold: 17  Epoch: 359  Training loss = 5.2313  Validation loss = 3.1856  \n",
      "\n",
      "Fold: 17  Epoch: 360  Training loss = 5.2307  Validation loss = 3.1852  \n",
      "\n",
      "Fold: 17  Epoch: 361  Training loss = 5.2299  Validation loss = 3.1849  \n",
      "\n",
      "Fold: 17  Epoch: 362  Training loss = 5.2293  Validation loss = 3.1846  \n",
      "\n",
      "Fold: 17  Epoch: 363  Training loss = 5.2285  Validation loss = 3.1842  \n",
      "\n",
      "Fold: 17  Epoch: 364  Training loss = 5.2280  Validation loss = 3.1840  \n",
      "\n",
      "Fold: 17  Epoch: 365  Training loss = 5.2273  Validation loss = 3.1837  \n",
      "\n",
      "Fold: 17  Epoch: 366  Training loss = 5.2267  Validation loss = 3.1834  \n",
      "\n",
      "Fold: 17  Epoch: 367  Training loss = 5.2261  Validation loss = 3.1832  \n",
      "\n",
      "Fold: 17  Epoch: 368  Training loss = 5.2256  Validation loss = 3.1829  \n",
      "\n",
      "Fold: 17  Epoch: 369  Training loss = 5.2249  Validation loss = 3.1825  \n",
      "\n",
      "Fold: 17  Epoch: 370  Training loss = 5.2242  Validation loss = 3.1823  \n",
      "\n",
      "Fold: 17  Epoch: 371  Training loss = 5.2236  Validation loss = 3.1819  \n",
      "\n",
      "Fold: 17  Epoch: 372  Training loss = 5.2229  Validation loss = 3.1816  \n",
      "\n",
      "Fold: 17  Epoch: 373  Training loss = 5.2222  Validation loss = 3.1813  \n",
      "\n",
      "Fold: 17  Epoch: 374  Training loss = 5.2216  Validation loss = 3.1810  \n",
      "\n",
      "Fold: 17  Epoch: 375  Training loss = 5.2210  Validation loss = 3.1808  \n",
      "\n",
      "Fold: 17  Epoch: 376  Training loss = 5.2204  Validation loss = 3.1805  \n",
      "\n",
      "Fold: 17  Epoch: 377  Training loss = 5.2198  Validation loss = 3.1802  \n",
      "\n",
      "Fold: 17  Epoch: 378  Training loss = 5.2192  Validation loss = 3.1799  \n",
      "\n",
      "Fold: 17  Epoch: 379  Training loss = 5.2186  Validation loss = 3.1796  \n",
      "\n",
      "Fold: 17  Epoch: 380  Training loss = 5.2179  Validation loss = 3.1793  \n",
      "\n",
      "Fold: 17  Epoch: 381  Training loss = 5.2172  Validation loss = 3.1790  \n",
      "\n",
      "Fold: 17  Epoch: 382  Training loss = 5.2166  Validation loss = 3.1787  \n",
      "\n",
      "Fold: 17  Epoch: 383  Training loss = 5.2159  Validation loss = 3.1784  \n",
      "\n",
      "Fold: 17  Epoch: 384  Training loss = 5.2152  Validation loss = 3.1780  \n",
      "\n",
      "Fold: 17  Epoch: 385  Training loss = 5.2146  Validation loss = 3.1778  \n",
      "\n",
      "Fold: 17  Epoch: 386  Training loss = 5.2138  Validation loss = 3.1774  \n",
      "\n",
      "Fold: 17  Epoch: 387  Training loss = 5.2132  Validation loss = 3.1771  \n",
      "\n",
      "Fold: 17  Epoch: 388  Training loss = 5.2125  Validation loss = 3.1768  \n",
      "\n",
      "Fold: 17  Epoch: 389  Training loss = 5.2119  Validation loss = 3.1765  \n",
      "\n",
      "Fold: 17  Epoch: 390  Training loss = 5.2113  Validation loss = 3.1762  \n",
      "\n",
      "Fold: 17  Epoch: 391  Training loss = 5.2107  Validation loss = 3.1760  \n",
      "\n",
      "Fold: 17  Epoch: 392  Training loss = 5.2100  Validation loss = 3.1756  \n",
      "\n",
      "Fold: 17  Epoch: 393  Training loss = 5.2093  Validation loss = 3.1753  \n",
      "\n",
      "Fold: 17  Epoch: 394  Training loss = 5.2086  Validation loss = 3.1750  \n",
      "\n",
      "Fold: 17  Epoch: 395  Training loss = 5.2080  Validation loss = 3.1748  \n",
      "\n",
      "Fold: 17  Epoch: 396  Training loss = 5.2074  Validation loss = 3.1745  \n",
      "\n",
      "Fold: 17  Epoch: 397  Training loss = 5.2067  Validation loss = 3.1741  \n",
      "\n",
      "Fold: 17  Epoch: 398  Training loss = 5.2061  Validation loss = 3.1739  \n",
      "\n",
      "Fold: 17  Epoch: 399  Training loss = 5.2055  Validation loss = 3.1736  \n",
      "\n",
      "Fold: 17  Epoch: 400  Training loss = 5.2049  Validation loss = 3.1733  \n",
      "\n",
      "Fold: 17  Epoch: 401  Training loss = 5.2042  Validation loss = 3.1730  \n",
      "\n",
      "Fold: 17  Epoch: 402  Training loss = 5.2036  Validation loss = 3.1727  \n",
      "\n",
      "Fold: 17  Epoch: 403  Training loss = 5.2029  Validation loss = 3.1724  \n",
      "\n",
      "Fold: 17  Epoch: 404  Training loss = 5.2023  Validation loss = 3.1721  \n",
      "\n",
      "Fold: 17  Epoch: 405  Training loss = 5.2015  Validation loss = 3.1717  \n",
      "\n",
      "Fold: 17  Epoch: 406  Training loss = 5.2009  Validation loss = 3.1715  \n",
      "\n",
      "Fold: 17  Epoch: 407  Training loss = 5.2001  Validation loss = 3.1711  \n",
      "\n",
      "Fold: 17  Epoch: 408  Training loss = 5.1994  Validation loss = 3.1708  \n",
      "\n",
      "Fold: 17  Epoch: 409  Training loss = 5.1988  Validation loss = 3.1705  \n",
      "\n",
      "Fold: 17  Epoch: 410  Training loss = 5.1983  Validation loss = 3.1702  \n",
      "\n",
      "Fold: 17  Epoch: 411  Training loss = 5.1977  Validation loss = 3.1700  \n",
      "\n",
      "Fold: 17  Epoch: 412  Training loss = 5.1969  Validation loss = 3.1696  \n",
      "\n",
      "Fold: 17  Epoch: 413  Training loss = 5.1962  Validation loss = 3.1693  \n",
      "\n",
      "Fold: 17  Epoch: 414  Training loss = 5.1957  Validation loss = 3.1690  \n",
      "\n",
      "Fold: 17  Epoch: 415  Training loss = 5.1950  Validation loss = 3.1687  \n",
      "\n",
      "Fold: 17  Epoch: 416  Training loss = 5.1943  Validation loss = 3.1684  \n",
      "\n",
      "Fold: 17  Epoch: 417  Training loss = 5.1936  Validation loss = 3.1681  \n",
      "\n",
      "Fold: 17  Epoch: 418  Training loss = 5.1929  Validation loss = 3.1678  \n",
      "\n",
      "Fold: 17  Epoch: 419  Training loss = 5.1922  Validation loss = 3.1674  \n",
      "\n",
      "Fold: 17  Epoch: 420  Training loss = 5.1915  Validation loss = 3.1671  \n",
      "\n",
      "Fold: 17  Epoch: 421  Training loss = 5.1909  Validation loss = 3.1669  \n",
      "\n",
      "Fold: 17  Epoch: 422  Training loss = 5.1903  Validation loss = 3.1666  \n",
      "\n",
      "Fold: 17  Epoch: 423  Training loss = 5.1896  Validation loss = 3.1663  \n",
      "\n",
      "Fold: 17  Epoch: 424  Training loss = 5.1890  Validation loss = 3.1661  \n",
      "\n",
      "Fold: 17  Epoch: 425  Training loss = 5.1883  Validation loss = 3.1658  \n",
      "\n",
      "Fold: 17  Epoch: 426  Training loss = 5.1877  Validation loss = 3.1655  \n",
      "\n",
      "Fold: 17  Epoch: 427  Training loss = 5.1870  Validation loss = 3.1652  \n",
      "\n",
      "Fold: 17  Epoch: 428  Training loss = 5.1863  Validation loss = 3.1649  \n",
      "\n",
      "Fold: 17  Epoch: 429  Training loss = 5.1856  Validation loss = 3.1646  \n",
      "\n",
      "Fold: 17  Epoch: 430  Training loss = 5.1849  Validation loss = 3.1642  \n",
      "\n",
      "Fold: 17  Epoch: 431  Training loss = 5.1844  Validation loss = 3.1640  \n",
      "\n",
      "Fold: 17  Epoch: 432  Training loss = 5.1838  Validation loss = 3.1637  \n",
      "\n",
      "Fold: 17  Epoch: 433  Training loss = 5.1832  Validation loss = 3.1635  \n",
      "\n",
      "Fold: 17  Epoch: 434  Training loss = 5.1826  Validation loss = 3.1632  \n",
      "\n",
      "Fold: 17  Epoch: 435  Training loss = 5.1819  Validation loss = 3.1630  \n",
      "\n",
      "Fold: 17  Epoch: 436  Training loss = 5.1812  Validation loss = 3.1626  \n",
      "\n",
      "Fold: 17  Epoch: 437  Training loss = 5.1806  Validation loss = 3.1624  \n",
      "\n",
      "Fold: 17  Epoch: 438  Training loss = 5.1801  Validation loss = 3.1622  \n",
      "\n",
      "Fold: 17  Epoch: 439  Training loss = 5.1794  Validation loss = 3.1619  \n",
      "\n",
      "Fold: 17  Epoch: 440  Training loss = 5.1789  Validation loss = 3.1617  \n",
      "\n",
      "Fold: 17  Epoch: 441  Training loss = 5.1783  Validation loss = 3.1614  \n",
      "\n",
      "Fold: 17  Epoch: 442  Training loss = 5.1776  Validation loss = 3.1611  \n",
      "\n",
      "Fold: 17  Epoch: 443  Training loss = 5.1770  Validation loss = 3.1608  \n",
      "\n",
      "Fold: 17  Epoch: 444  Training loss = 5.1763  Validation loss = 3.1606  \n",
      "\n",
      "Fold: 17  Epoch: 445  Training loss = 5.1757  Validation loss = 3.1603  \n",
      "\n",
      "Fold: 17  Epoch: 446  Training loss = 5.1750  Validation loss = 3.1600  \n",
      "\n",
      "Fold: 17  Epoch: 447  Training loss = 5.1743  Validation loss = 3.1597  \n",
      "\n",
      "Fold: 17  Epoch: 448  Training loss = 5.1737  Validation loss = 3.1594  \n",
      "\n",
      "Fold: 17  Epoch: 449  Training loss = 5.1730  Validation loss = 3.1591  \n",
      "\n",
      "Fold: 17  Epoch: 450  Training loss = 5.1723  Validation loss = 3.1588  \n",
      "\n",
      "Fold: 17  Epoch: 451  Training loss = 5.1716  Validation loss = 3.1585  \n",
      "\n",
      "Fold: 17  Epoch: 452  Training loss = 5.1709  Validation loss = 3.1583  \n",
      "\n",
      "Fold: 17  Epoch: 453  Training loss = 5.1703  Validation loss = 3.1580  \n",
      "\n",
      "Fold: 17  Epoch: 454  Training loss = 5.1697  Validation loss = 3.1578  \n",
      "\n",
      "Fold: 17  Epoch: 455  Training loss = 5.1691  Validation loss = 3.1575  \n",
      "\n",
      "Fold: 17  Epoch: 456  Training loss = 5.1684  Validation loss = 3.1572  \n",
      "\n",
      "Fold: 17  Epoch: 457  Training loss = 5.1677  Validation loss = 3.1569  \n",
      "\n",
      "Fold: 17  Epoch: 458  Training loss = 5.1671  Validation loss = 3.1567  \n",
      "\n",
      "Fold: 17  Epoch: 459  Training loss = 5.1666  Validation loss = 3.1565  \n",
      "\n",
      "Fold: 17  Epoch: 460  Training loss = 5.1659  Validation loss = 3.1562  \n",
      "\n",
      "Fold: 17  Epoch: 461  Training loss = 5.1654  Validation loss = 3.1560  \n",
      "\n",
      "Fold: 17  Epoch: 462  Training loss = 5.1647  Validation loss = 3.1557  \n",
      "\n",
      "Fold: 17  Epoch: 463  Training loss = 5.1640  Validation loss = 3.1554  \n",
      "\n",
      "Fold: 17  Epoch: 464  Training loss = 5.1632  Validation loss = 3.1551  \n",
      "\n",
      "Fold: 17  Epoch: 465  Training loss = 5.1626  Validation loss = 3.1549  \n",
      "\n",
      "Fold: 17  Epoch: 466  Training loss = 5.1619  Validation loss = 3.1546  \n",
      "\n",
      "Fold: 17  Epoch: 467  Training loss = 5.1613  Validation loss = 3.1544  \n",
      "\n",
      "Fold: 17  Epoch: 468  Training loss = 5.1606  Validation loss = 3.1540  \n",
      "\n",
      "Fold: 17  Epoch: 469  Training loss = 5.1600  Validation loss = 3.1538  \n",
      "\n",
      "Fold: 17  Epoch: 470  Training loss = 5.1593  Validation loss = 3.1535  \n",
      "\n",
      "Fold: 17  Epoch: 471  Training loss = 5.1586  Validation loss = 3.1532  \n",
      "\n",
      "Fold: 17  Epoch: 472  Training loss = 5.1580  Validation loss = 3.1530  \n",
      "\n",
      "Fold: 17  Epoch: 473  Training loss = 5.1573  Validation loss = 3.1527  \n",
      "\n",
      "Fold: 17  Epoch: 474  Training loss = 5.1567  Validation loss = 3.1524  \n",
      "\n",
      "Fold: 17  Epoch: 475  Training loss = 5.1560  Validation loss = 3.1522  \n",
      "\n",
      "Fold: 17  Epoch: 476  Training loss = 5.1554  Validation loss = 3.1519  \n",
      "\n",
      "Fold: 17  Epoch: 477  Training loss = 5.1550  Validation loss = 3.1517  \n",
      "\n",
      "Fold: 17  Epoch: 478  Training loss = 5.1544  Validation loss = 3.1515  \n",
      "\n",
      "Fold: 17  Epoch: 479  Training loss = 5.1537  Validation loss = 3.1513  \n",
      "\n",
      "Fold: 17  Epoch: 480  Training loss = 5.1530  Validation loss = 3.1509  \n",
      "\n",
      "Fold: 17  Epoch: 481  Training loss = 5.1524  Validation loss = 3.1507  \n",
      "\n",
      "Fold: 17  Epoch: 482  Training loss = 5.1517  Validation loss = 3.1504  \n",
      "\n",
      "Fold: 17  Epoch: 483  Training loss = 5.1511  Validation loss = 3.1502  \n",
      "\n",
      "Fold: 17  Epoch: 484  Training loss = 5.1504  Validation loss = 3.1499  \n",
      "\n",
      "Fold: 17  Epoch: 485  Training loss = 5.1498  Validation loss = 3.1496  \n",
      "\n",
      "Fold: 17  Epoch: 486  Training loss = 5.1493  Validation loss = 3.1494  \n",
      "\n",
      "Fold: 17  Epoch: 487  Training loss = 5.1487  Validation loss = 3.1492  \n",
      "\n",
      "Fold: 17  Epoch: 488  Training loss = 5.1480  Validation loss = 3.1489  \n",
      "\n",
      "Fold: 17  Epoch: 489  Training loss = 5.1474  Validation loss = 3.1486  \n",
      "\n",
      "Fold: 17  Epoch: 490  Training loss = 5.1467  Validation loss = 3.1483  \n",
      "\n",
      "Fold: 17  Epoch: 491  Training loss = 5.1462  Validation loss = 3.1481  \n",
      "\n",
      "Fold: 17  Epoch: 492  Training loss = 5.1455  Validation loss = 3.1478  \n",
      "\n",
      "Fold: 17  Epoch: 493  Training loss = 5.1448  Validation loss = 3.1476  \n",
      "\n",
      "Fold: 17  Epoch: 494  Training loss = 5.1443  Validation loss = 3.1475  \n",
      "\n",
      "Fold: 17  Epoch: 495  Training loss = 5.1437  Validation loss = 3.1472  \n",
      "\n",
      "Fold: 17  Epoch: 496  Training loss = 5.1430  Validation loss = 3.1470  \n",
      "\n",
      "Fold: 17  Epoch: 497  Training loss = 5.1425  Validation loss = 3.1468  \n",
      "\n",
      "Fold: 17  Epoch: 498  Training loss = 5.1419  Validation loss = 3.1466  \n",
      "\n",
      "Fold: 17  Epoch: 499  Training loss = 5.1412  Validation loss = 3.1463  \n",
      "\n",
      "Fold: 17  Epoch: 500  Training loss = 5.1407  Validation loss = 3.1462  \n",
      "\n",
      "Check model:  Fold: 17  Optimal epoch: 500  \n",
      "\n",
      "Fold: 18  Epoch: 1  Training loss = 5.1912  Validation loss = 2.1229  \n",
      "\n",
      "Fold: 18  Epoch: 2  Training loss = 5.1906  Validation loss = 2.1227  \n",
      "\n",
      "Fold: 18  Epoch: 3  Training loss = 5.1900  Validation loss = 2.1224  \n",
      "\n",
      "Fold: 18  Epoch: 4  Training loss = 5.1894  Validation loss = 2.1221  \n",
      "\n",
      "Fold: 18  Epoch: 5  Training loss = 5.1887  Validation loss = 2.1218  \n",
      "\n",
      "Fold: 18  Epoch: 6  Training loss = 5.1882  Validation loss = 2.1216  \n",
      "\n",
      "Fold: 18  Epoch: 7  Training loss = 5.1877  Validation loss = 2.1214  \n",
      "\n",
      "Fold: 18  Epoch: 8  Training loss = 5.1869  Validation loss = 2.1210  \n",
      "\n",
      "Fold: 18  Epoch: 9  Training loss = 5.1862  Validation loss = 2.1208  \n",
      "\n",
      "Fold: 18  Epoch: 10  Training loss = 5.1856  Validation loss = 2.1205  \n",
      "\n",
      "Fold: 18  Epoch: 11  Training loss = 5.1849  Validation loss = 2.1202  \n",
      "\n",
      "Fold: 18  Epoch: 12  Training loss = 5.1843  Validation loss = 2.1199  \n",
      "\n",
      "Fold: 18  Epoch: 13  Training loss = 5.1836  Validation loss = 2.1196  \n",
      "\n",
      "Fold: 18  Epoch: 14  Training loss = 5.1829  Validation loss = 2.1193  \n",
      "\n",
      "Fold: 18  Epoch: 15  Training loss = 5.1823  Validation loss = 2.1190  \n",
      "\n",
      "Fold: 18  Epoch: 16  Training loss = 5.1817  Validation loss = 2.1188  \n",
      "\n",
      "Fold: 18  Epoch: 17  Training loss = 5.1811  Validation loss = 2.1185  \n",
      "\n",
      "Fold: 18  Epoch: 18  Training loss = 5.1805  Validation loss = 2.1183  \n",
      "\n",
      "Fold: 18  Epoch: 19  Training loss = 5.1798  Validation loss = 2.1180  \n",
      "\n",
      "Fold: 18  Epoch: 20  Training loss = 5.1792  Validation loss = 2.1177  \n",
      "\n",
      "Fold: 18  Epoch: 21  Training loss = 5.1785  Validation loss = 2.1175  \n",
      "\n",
      "Fold: 18  Epoch: 22  Training loss = 5.1779  Validation loss = 2.1172  \n",
      "\n",
      "Fold: 18  Epoch: 23  Training loss = 5.1772  Validation loss = 2.1169  \n",
      "\n",
      "Fold: 18  Epoch: 24  Training loss = 5.1766  Validation loss = 2.1166  \n",
      "\n",
      "Fold: 18  Epoch: 25  Training loss = 5.1759  Validation loss = 2.1163  \n",
      "\n",
      "Fold: 18  Epoch: 26  Training loss = 5.1751  Validation loss = 2.1160  \n",
      "\n",
      "Fold: 18  Epoch: 27  Training loss = 5.1745  Validation loss = 2.1157  \n",
      "\n",
      "Fold: 18  Epoch: 28  Training loss = 5.1738  Validation loss = 2.1154  \n",
      "\n",
      "Fold: 18  Epoch: 29  Training loss = 5.1731  Validation loss = 2.1152  \n",
      "\n",
      "Fold: 18  Epoch: 30  Training loss = 5.1725  Validation loss = 2.1149  \n",
      "\n",
      "Fold: 18  Epoch: 31  Training loss = 5.1719  Validation loss = 2.1147  \n",
      "\n",
      "Fold: 18  Epoch: 32  Training loss = 5.1713  Validation loss = 2.1144  \n",
      "\n",
      "Fold: 18  Epoch: 33  Training loss = 5.1706  Validation loss = 2.1141  \n",
      "\n",
      "Fold: 18  Epoch: 34  Training loss = 5.1698  Validation loss = 2.1138  \n",
      "\n",
      "Fold: 18  Epoch: 35  Training loss = 5.1693  Validation loss = 2.1136  \n",
      "\n",
      "Fold: 18  Epoch: 36  Training loss = 5.1686  Validation loss = 2.1133  \n",
      "\n",
      "Fold: 18  Epoch: 37  Training loss = 5.1678  Validation loss = 2.1131  \n",
      "\n",
      "Fold: 18  Epoch: 38  Training loss = 5.1671  Validation loss = 2.1128  \n",
      "\n",
      "Fold: 18  Epoch: 39  Training loss = 5.1663  Validation loss = 2.1125  \n",
      "\n",
      "Fold: 18  Epoch: 40  Training loss = 5.1657  Validation loss = 2.1122  \n",
      "\n",
      "Fold: 18  Epoch: 41  Training loss = 5.1650  Validation loss = 2.1119  \n",
      "\n",
      "Fold: 18  Epoch: 42  Training loss = 5.1642  Validation loss = 2.1116  \n",
      "\n",
      "Fold: 18  Epoch: 43  Training loss = 5.1637  Validation loss = 2.1114  \n",
      "\n",
      "Fold: 18  Epoch: 44  Training loss = 5.1630  Validation loss = 2.1111  \n",
      "\n",
      "Fold: 18  Epoch: 45  Training loss = 5.1623  Validation loss = 2.1108  \n",
      "\n",
      "Fold: 18  Epoch: 46  Training loss = 5.1615  Validation loss = 2.1106  \n",
      "\n",
      "Fold: 18  Epoch: 47  Training loss = 5.1609  Validation loss = 2.1103  \n",
      "\n",
      "Fold: 18  Epoch: 48  Training loss = 5.1602  Validation loss = 2.1101  \n",
      "\n",
      "Fold: 18  Epoch: 49  Training loss = 5.1594  Validation loss = 2.1097  \n",
      "\n",
      "Fold: 18  Epoch: 50  Training loss = 5.1587  Validation loss = 2.1095  \n",
      "\n",
      "Fold: 18  Epoch: 51  Training loss = 5.1580  Validation loss = 2.1093  \n",
      "\n",
      "Fold: 18  Epoch: 52  Training loss = 5.1573  Validation loss = 2.1090  \n",
      "\n",
      "Fold: 18  Epoch: 53  Training loss = 5.1566  Validation loss = 2.1088  \n",
      "\n",
      "Fold: 18  Epoch: 54  Training loss = 5.1561  Validation loss = 2.1086  \n",
      "\n",
      "Fold: 18  Epoch: 55  Training loss = 5.1553  Validation loss = 2.1083  \n",
      "\n",
      "Fold: 18  Epoch: 56  Training loss = 5.1548  Validation loss = 2.1081  \n",
      "\n",
      "Fold: 18  Epoch: 57  Training loss = 5.1542  Validation loss = 2.1079  \n",
      "\n",
      "Fold: 18  Epoch: 58  Training loss = 5.1535  Validation loss = 2.1077  \n",
      "\n",
      "Fold: 18  Epoch: 59  Training loss = 5.1529  Validation loss = 2.1075  \n",
      "\n",
      "Fold: 18  Epoch: 60  Training loss = 5.1523  Validation loss = 2.1073  \n",
      "\n",
      "Fold: 18  Epoch: 61  Training loss = 5.1517  Validation loss = 2.1070  \n",
      "\n",
      "Fold: 18  Epoch: 62  Training loss = 5.1509  Validation loss = 2.1067  \n",
      "\n",
      "Fold: 18  Epoch: 63  Training loss = 5.1503  Validation loss = 2.1065  \n",
      "\n",
      "Fold: 18  Epoch: 64  Training loss = 5.1497  Validation loss = 2.1063  \n",
      "\n",
      "Fold: 18  Epoch: 65  Training loss = 5.1489  Validation loss = 2.1060  \n",
      "\n",
      "Fold: 18  Epoch: 66  Training loss = 5.1483  Validation loss = 2.1058  \n",
      "\n",
      "Fold: 18  Epoch: 67  Training loss = 5.1476  Validation loss = 2.1055  \n",
      "\n",
      "Fold: 18  Epoch: 68  Training loss = 5.1470  Validation loss = 2.1053  \n",
      "\n",
      "Fold: 18  Epoch: 69  Training loss = 5.1465  Validation loss = 2.1051  \n",
      "\n",
      "Fold: 18  Epoch: 70  Training loss = 5.1458  Validation loss = 2.1049  \n",
      "\n",
      "Fold: 18  Epoch: 71  Training loss = 5.1451  Validation loss = 2.1047  \n",
      "\n",
      "Fold: 18  Epoch: 72  Training loss = 5.1445  Validation loss = 2.1044  \n",
      "\n",
      "Fold: 18  Epoch: 73  Training loss = 5.1438  Validation loss = 2.1042  \n",
      "\n",
      "Fold: 18  Epoch: 74  Training loss = 5.1431  Validation loss = 2.1040  \n",
      "\n",
      "Fold: 18  Epoch: 75  Training loss = 5.1425  Validation loss = 2.1037  \n",
      "\n",
      "Fold: 18  Epoch: 76  Training loss = 5.1418  Validation loss = 2.1035  \n",
      "\n",
      "Fold: 18  Epoch: 77  Training loss = 5.1410  Validation loss = 2.1032  \n",
      "\n",
      "Fold: 18  Epoch: 78  Training loss = 5.1404  Validation loss = 2.1030  \n",
      "\n",
      "Fold: 18  Epoch: 79  Training loss = 5.1396  Validation loss = 2.1027  \n",
      "\n",
      "Fold: 18  Epoch: 80  Training loss = 5.1389  Validation loss = 2.1025  \n",
      "\n",
      "Fold: 18  Epoch: 81  Training loss = 5.1382  Validation loss = 2.1023  \n",
      "\n",
      "Fold: 18  Epoch: 82  Training loss = 5.1376  Validation loss = 2.1021  \n",
      "\n",
      "Fold: 18  Epoch: 83  Training loss = 5.1368  Validation loss = 2.1018  \n",
      "\n",
      "Fold: 18  Epoch: 84  Training loss = 5.1360  Validation loss = 2.1016  \n",
      "\n",
      "Fold: 18  Epoch: 85  Training loss = 5.1352  Validation loss = 2.1013  \n",
      "\n",
      "Fold: 18  Epoch: 86  Training loss = 5.1345  Validation loss = 2.1011  \n",
      "\n",
      "Fold: 18  Epoch: 87  Training loss = 5.1338  Validation loss = 2.1009  \n",
      "\n",
      "Fold: 18  Epoch: 88  Training loss = 5.1331  Validation loss = 2.1006  \n",
      "\n",
      "Fold: 18  Epoch: 89  Training loss = 5.1325  Validation loss = 2.1004  \n",
      "\n",
      "Fold: 18  Epoch: 90  Training loss = 5.1318  Validation loss = 2.1002  \n",
      "\n",
      "Fold: 18  Epoch: 91  Training loss = 5.1312  Validation loss = 2.1000  \n",
      "\n",
      "Fold: 18  Epoch: 92  Training loss = 5.1304  Validation loss = 2.0997  \n",
      "\n",
      "Fold: 18  Epoch: 93  Training loss = 5.1297  Validation loss = 2.0995  \n",
      "\n",
      "Fold: 18  Epoch: 94  Training loss = 5.1289  Validation loss = 2.0993  \n",
      "\n",
      "Fold: 18  Epoch: 95  Training loss = 5.1281  Validation loss = 2.0990  \n",
      "\n",
      "Fold: 18  Epoch: 96  Training loss = 5.1274  Validation loss = 2.0988  \n",
      "\n",
      "Fold: 18  Epoch: 97  Training loss = 5.1265  Validation loss = 2.0985  \n",
      "\n",
      "Fold: 18  Epoch: 98  Training loss = 5.1260  Validation loss = 2.0984  \n",
      "\n",
      "Fold: 18  Epoch: 99  Training loss = 5.1253  Validation loss = 2.0982  \n",
      "\n",
      "Fold: 18  Epoch: 100  Training loss = 5.1245  Validation loss = 2.0979  \n",
      "\n",
      "Fold: 18  Epoch: 101  Training loss = 5.1237  Validation loss = 2.0977  \n",
      "\n",
      "Fold: 18  Epoch: 102  Training loss = 5.1229  Validation loss = 2.0975  \n",
      "\n",
      "Fold: 18  Epoch: 103  Training loss = 5.1223  Validation loss = 2.0973  \n",
      "\n",
      "Fold: 18  Epoch: 104  Training loss = 5.1215  Validation loss = 2.0971  \n",
      "\n",
      "Fold: 18  Epoch: 105  Training loss = 5.1207  Validation loss = 2.0968  \n",
      "\n",
      "Fold: 18  Epoch: 106  Training loss = 5.1198  Validation loss = 2.0966  \n",
      "\n",
      "Fold: 18  Epoch: 107  Training loss = 5.1189  Validation loss = 2.0963  \n",
      "\n",
      "Fold: 18  Epoch: 108  Training loss = 5.1182  Validation loss = 2.0961  \n",
      "\n",
      "Fold: 18  Epoch: 109  Training loss = 5.1174  Validation loss = 2.0959  \n",
      "\n",
      "Fold: 18  Epoch: 110  Training loss = 5.1168  Validation loss = 2.0957  \n",
      "\n",
      "Fold: 18  Epoch: 111  Training loss = 5.1160  Validation loss = 2.0955  \n",
      "\n",
      "Fold: 18  Epoch: 112  Training loss = 5.1153  Validation loss = 2.0953  \n",
      "\n",
      "Fold: 18  Epoch: 113  Training loss = 5.1148  Validation loss = 2.0951  \n",
      "\n",
      "Fold: 18  Epoch: 114  Training loss = 5.1138  Validation loss = 2.0949  \n",
      "\n",
      "Fold: 18  Epoch: 115  Training loss = 5.1129  Validation loss = 2.0946  \n",
      "\n",
      "Fold: 18  Epoch: 116  Training loss = 5.1121  Validation loss = 2.0944  \n",
      "\n",
      "Fold: 18  Epoch: 117  Training loss = 5.1113  Validation loss = 2.0942  \n",
      "\n",
      "Fold: 18  Epoch: 118  Training loss = 5.1106  Validation loss = 2.0940  \n",
      "\n",
      "Fold: 18  Epoch: 119  Training loss = 5.1096  Validation loss = 2.0938  \n",
      "\n",
      "Fold: 18  Epoch: 120  Training loss = 5.1086  Validation loss = 2.0935  \n",
      "\n",
      "Fold: 18  Epoch: 121  Training loss = 5.1077  Validation loss = 2.0933  \n",
      "\n",
      "Fold: 18  Epoch: 122  Training loss = 5.1068  Validation loss = 2.0931  \n",
      "\n",
      "Fold: 18  Epoch: 123  Training loss = 5.1059  Validation loss = 2.0929  \n",
      "\n",
      "Fold: 18  Epoch: 124  Training loss = 5.1052  Validation loss = 2.0927  \n",
      "\n",
      "Fold: 18  Epoch: 125  Training loss = 5.1045  Validation loss = 2.0925  \n",
      "\n",
      "Fold: 18  Epoch: 126  Training loss = 5.1033  Validation loss = 2.0923  \n",
      "\n",
      "Fold: 18  Epoch: 127  Training loss = 5.1025  Validation loss = 2.0921  \n",
      "\n",
      "Fold: 18  Epoch: 128  Training loss = 5.1015  Validation loss = 2.0918  \n",
      "\n",
      "Fold: 18  Epoch: 129  Training loss = 5.1006  Validation loss = 2.0916  \n",
      "\n",
      "Fold: 18  Epoch: 130  Training loss = 5.0998  Validation loss = 2.0914  \n",
      "\n",
      "Fold: 18  Epoch: 131  Training loss = 5.0988  Validation loss = 2.0912  \n",
      "\n",
      "Fold: 18  Epoch: 132  Training loss = 5.0979  Validation loss = 2.0910  \n",
      "\n",
      "Fold: 18  Epoch: 133  Training loss = 5.0969  Validation loss = 2.0908  \n",
      "\n",
      "Fold: 18  Epoch: 134  Training loss = 5.0958  Validation loss = 2.0905  \n",
      "\n",
      "Fold: 18  Epoch: 135  Training loss = 5.0945  Validation loss = 2.0903  \n",
      "\n",
      "Fold: 18  Epoch: 136  Training loss = 5.0939  Validation loss = 2.0901  \n",
      "\n",
      "Fold: 18  Epoch: 137  Training loss = 5.0931  Validation loss = 2.0899  \n",
      "\n",
      "Fold: 18  Epoch: 138  Training loss = 5.0924  Validation loss = 2.0898  \n",
      "\n",
      "Fold: 18  Epoch: 139  Training loss = 5.0915  Validation loss = 2.0896  \n",
      "\n",
      "Fold: 18  Epoch: 140  Training loss = 5.0906  Validation loss = 2.0894  \n",
      "\n",
      "Fold: 18  Epoch: 141  Training loss = 5.0899  Validation loss = 2.0892  \n",
      "\n",
      "Fold: 18  Epoch: 142  Training loss = 5.0890  Validation loss = 2.0890  \n",
      "\n",
      "Fold: 18  Epoch: 143  Training loss = 5.0879  Validation loss = 2.0888  \n",
      "\n",
      "Fold: 18  Epoch: 144  Training loss = 5.0872  Validation loss = 2.0887  \n",
      "\n",
      "Fold: 18  Epoch: 145  Training loss = 5.0861  Validation loss = 2.0884  \n",
      "\n",
      "Fold: 18  Epoch: 146  Training loss = 5.0849  Validation loss = 2.0882  \n",
      "\n",
      "Fold: 18  Epoch: 147  Training loss = 5.0840  Validation loss = 2.0880  \n",
      "\n",
      "Fold: 18  Epoch: 148  Training loss = 5.0828  Validation loss = 2.0878  \n",
      "\n",
      "Fold: 18  Epoch: 149  Training loss = 5.0814  Validation loss = 2.0876  \n",
      "\n",
      "Fold: 18  Epoch: 150  Training loss = 5.0805  Validation loss = 2.0874  \n",
      "\n",
      "Fold: 18  Epoch: 151  Training loss = 5.0795  Validation loss = 2.0872  \n",
      "\n",
      "Fold: 18  Epoch: 152  Training loss = 5.0785  Validation loss = 2.0870  \n",
      "\n",
      "Fold: 18  Epoch: 153  Training loss = 5.0775  Validation loss = 2.0868  \n",
      "\n",
      "Fold: 18  Epoch: 154  Training loss = 5.0769  Validation loss = 2.0867  \n",
      "\n",
      "Fold: 18  Epoch: 155  Training loss = 5.0759  Validation loss = 2.0865  \n",
      "\n",
      "Fold: 18  Epoch: 156  Training loss = 5.0750  Validation loss = 2.0863  \n",
      "\n",
      "Fold: 18  Epoch: 157  Training loss = 5.0740  Validation loss = 2.0861  \n",
      "\n",
      "Fold: 18  Epoch: 158  Training loss = 5.0731  Validation loss = 2.0859  \n",
      "\n",
      "Fold: 18  Epoch: 159  Training loss = 5.0719  Validation loss = 2.0858  \n",
      "\n",
      "Fold: 18  Epoch: 160  Training loss = 5.0713  Validation loss = 2.0856  \n",
      "\n",
      "Fold: 18  Epoch: 161  Training loss = 5.0700  Validation loss = 2.0854  \n",
      "\n",
      "Fold: 18  Epoch: 162  Training loss = 5.0691  Validation loss = 2.0853  \n",
      "\n",
      "Fold: 18  Epoch: 163  Training loss = 5.0680  Validation loss = 2.0851  \n",
      "\n",
      "Fold: 18  Epoch: 164  Training loss = 5.0669  Validation loss = 2.0849  \n",
      "\n",
      "Fold: 18  Epoch: 165  Training loss = 5.0660  Validation loss = 2.0847  \n",
      "\n",
      "Fold: 18  Epoch: 166  Training loss = 5.0649  Validation loss = 2.0845  \n",
      "\n",
      "Fold: 18  Epoch: 167  Training loss = 5.0637  Validation loss = 2.0843  \n",
      "\n",
      "Fold: 18  Epoch: 168  Training loss = 5.0626  Validation loss = 2.0841  \n",
      "\n",
      "Fold: 18  Epoch: 169  Training loss = 5.0613  Validation loss = 2.0839  \n",
      "\n",
      "Fold: 18  Epoch: 170  Training loss = 5.0604  Validation loss = 2.0837  \n",
      "\n",
      "Fold: 18  Epoch: 171  Training loss = 5.0593  Validation loss = 2.0836  \n",
      "\n",
      "Fold: 18  Epoch: 172  Training loss = 5.0578  Validation loss = 2.0833  \n",
      "\n",
      "Fold: 18  Epoch: 173  Training loss = 5.0566  Validation loss = 2.0832  \n",
      "\n",
      "Fold: 18  Epoch: 174  Training loss = 5.0555  Validation loss = 2.0829  \n",
      "\n",
      "Fold: 18  Epoch: 175  Training loss = 5.0545  Validation loss = 2.0828  \n",
      "\n",
      "Fold: 18  Epoch: 176  Training loss = 5.0536  Validation loss = 2.0826  \n",
      "\n",
      "Fold: 18  Epoch: 177  Training loss = 5.0529  Validation loss = 2.0824  \n",
      "\n",
      "Fold: 18  Epoch: 178  Training loss = 5.0517  Validation loss = 2.0822  \n",
      "\n",
      "Fold: 18  Epoch: 179  Training loss = 5.0509  Validation loss = 2.0820  \n",
      "\n",
      "Fold: 18  Epoch: 180  Training loss = 5.0499  Validation loss = 2.0819  \n",
      "\n",
      "Fold: 18  Epoch: 181  Training loss = 5.0487  Validation loss = 2.0817  \n",
      "\n",
      "Fold: 18  Epoch: 182  Training loss = 5.0481  Validation loss = 2.0815  \n",
      "\n",
      "Fold: 18  Epoch: 183  Training loss = 5.0475  Validation loss = 2.0814  \n",
      "\n",
      "Fold: 18  Epoch: 184  Training loss = 5.0470  Validation loss = 2.0812  \n",
      "\n",
      "Fold: 18  Epoch: 185  Training loss = 5.0462  Validation loss = 2.0810  \n",
      "\n",
      "Fold: 18  Epoch: 186  Training loss = 5.0454  Validation loss = 2.0808  \n",
      "\n",
      "Fold: 18  Epoch: 187  Training loss = 5.0446  Validation loss = 2.0807  \n",
      "\n",
      "Fold: 18  Epoch: 188  Training loss = 5.0435  Validation loss = 2.0805  \n",
      "\n",
      "Fold: 18  Epoch: 189  Training loss = 5.0429  Validation loss = 2.0803  \n",
      "\n",
      "Fold: 18  Epoch: 190  Training loss = 5.0421  Validation loss = 2.0802  \n",
      "\n",
      "Fold: 18  Epoch: 191  Training loss = 5.0409  Validation loss = 2.0800  \n",
      "\n",
      "Fold: 18  Epoch: 192  Training loss = 5.0403  Validation loss = 2.0798  \n",
      "\n",
      "Fold: 18  Epoch: 193  Training loss = 5.0393  Validation loss = 2.0797  \n",
      "\n",
      "Fold: 18  Epoch: 194  Training loss = 5.0386  Validation loss = 2.0795  \n",
      "\n",
      "Fold: 18  Epoch: 195  Training loss = 5.0378  Validation loss = 2.0794  \n",
      "\n",
      "Fold: 18  Epoch: 196  Training loss = 5.0369  Validation loss = 2.0792  \n",
      "\n",
      "Fold: 18  Epoch: 197  Training loss = 5.0359  Validation loss = 2.0790  \n",
      "\n",
      "Fold: 18  Epoch: 198  Training loss = 5.0350  Validation loss = 2.0788  \n",
      "\n",
      "Fold: 18  Epoch: 199  Training loss = 5.0342  Validation loss = 2.0786  \n",
      "\n",
      "Fold: 18  Epoch: 200  Training loss = 5.0331  Validation loss = 2.0784  \n",
      "\n",
      "Fold: 18  Epoch: 201  Training loss = 5.0326  Validation loss = 2.0783  \n",
      "\n",
      "Fold: 18  Epoch: 202  Training loss = 5.0320  Validation loss = 2.0781  \n",
      "\n",
      "Fold: 18  Epoch: 203  Training loss = 5.0312  Validation loss = 2.0779  \n",
      "\n",
      "Fold: 18  Epoch: 204  Training loss = 5.0307  Validation loss = 2.0778  \n",
      "\n",
      "Fold: 18  Epoch: 205  Training loss = 5.0298  Validation loss = 2.0776  \n",
      "\n",
      "Fold: 18  Epoch: 206  Training loss = 5.0291  Validation loss = 2.0774  \n",
      "\n",
      "Fold: 18  Epoch: 207  Training loss = 5.0284  Validation loss = 2.0773  \n",
      "\n",
      "Fold: 18  Epoch: 208  Training loss = 5.0278  Validation loss = 2.0771  \n",
      "\n",
      "Fold: 18  Epoch: 209  Training loss = 5.0270  Validation loss = 2.0770  \n",
      "\n",
      "Fold: 18  Epoch: 210  Training loss = 5.0264  Validation loss = 2.0768  \n",
      "\n",
      "Fold: 18  Epoch: 211  Training loss = 5.0258  Validation loss = 2.0766  \n",
      "\n",
      "Fold: 18  Epoch: 212  Training loss = 5.0251  Validation loss = 2.0765  \n",
      "\n",
      "Fold: 18  Epoch: 213  Training loss = 5.0245  Validation loss = 2.0763  \n",
      "\n",
      "Fold: 18  Epoch: 214  Training loss = 5.0239  Validation loss = 2.0761  \n",
      "\n",
      "Fold: 18  Epoch: 215  Training loss = 5.0232  Validation loss = 2.0760  \n",
      "\n",
      "Fold: 18  Epoch: 216  Training loss = 5.0225  Validation loss = 2.0758  \n",
      "\n",
      "Fold: 18  Epoch: 217  Training loss = 5.0219  Validation loss = 2.0757  \n",
      "\n",
      "Fold: 18  Epoch: 218  Training loss = 5.0212  Validation loss = 2.0755  \n",
      "\n",
      "Fold: 18  Epoch: 219  Training loss = 5.0206  Validation loss = 2.0754  \n",
      "\n",
      "Fold: 18  Epoch: 220  Training loss = 5.0198  Validation loss = 2.0752  \n",
      "\n",
      "Fold: 18  Epoch: 221  Training loss = 5.0189  Validation loss = 2.0750  \n",
      "\n",
      "Fold: 18  Epoch: 222  Training loss = 5.0184  Validation loss = 2.0748  \n",
      "\n",
      "Fold: 18  Epoch: 223  Training loss = 5.0178  Validation loss = 2.0747  \n",
      "\n",
      "Fold: 18  Epoch: 224  Training loss = 5.0174  Validation loss = 2.0745  \n",
      "\n",
      "Fold: 18  Epoch: 225  Training loss = 5.0166  Validation loss = 2.0743  \n",
      "\n",
      "Fold: 18  Epoch: 226  Training loss = 5.0160  Validation loss = 2.0742  \n",
      "\n",
      "Fold: 18  Epoch: 227  Training loss = 5.0153  Validation loss = 2.0740  \n",
      "\n",
      "Fold: 18  Epoch: 228  Training loss = 5.0148  Validation loss = 2.0738  \n",
      "\n",
      "Fold: 18  Epoch: 229  Training loss = 5.0142  Validation loss = 2.0737  \n",
      "\n",
      "Fold: 18  Epoch: 230  Training loss = 5.0138  Validation loss = 2.0736  \n",
      "\n",
      "Fold: 18  Epoch: 231  Training loss = 5.0132  Validation loss = 2.0734  \n",
      "\n",
      "Fold: 18  Epoch: 232  Training loss = 5.0126  Validation loss = 2.0733  \n",
      "\n",
      "Fold: 18  Epoch: 233  Training loss = 5.0119  Validation loss = 2.0731  \n",
      "\n",
      "Fold: 18  Epoch: 234  Training loss = 5.0112  Validation loss = 2.0729  \n",
      "\n",
      "Fold: 18  Epoch: 235  Training loss = 5.0108  Validation loss = 2.0727  \n",
      "\n",
      "Fold: 18  Epoch: 236  Training loss = 5.0101  Validation loss = 2.0726  \n",
      "\n",
      "Fold: 18  Epoch: 237  Training loss = 5.0096  Validation loss = 2.0724  \n",
      "\n",
      "Fold: 18  Epoch: 238  Training loss = 5.0090  Validation loss = 2.0723  \n",
      "\n",
      "Fold: 18  Epoch: 239  Training loss = 5.0084  Validation loss = 2.0722  \n",
      "\n",
      "Fold: 18  Epoch: 240  Training loss = 5.0078  Validation loss = 2.0720  \n",
      "\n",
      "Fold: 18  Epoch: 241  Training loss = 5.0072  Validation loss = 2.0719  \n",
      "\n",
      "Fold: 18  Epoch: 242  Training loss = 5.0066  Validation loss = 2.0717  \n",
      "\n",
      "Fold: 18  Epoch: 243  Training loss = 5.0062  Validation loss = 2.0716  \n",
      "\n",
      "Fold: 18  Epoch: 244  Training loss = 5.0057  Validation loss = 2.0714  \n",
      "\n",
      "Fold: 18  Epoch: 245  Training loss = 5.0051  Validation loss = 2.0713  \n",
      "\n",
      "Fold: 18  Epoch: 246  Training loss = 5.0046  Validation loss = 2.0711  \n",
      "\n",
      "Fold: 18  Epoch: 247  Training loss = 5.0040  Validation loss = 2.0710  \n",
      "\n",
      "Fold: 18  Epoch: 248  Training loss = 5.0034  Validation loss = 2.0708  \n",
      "\n",
      "Fold: 18  Epoch: 249  Training loss = 5.0027  Validation loss = 2.0706  \n",
      "\n",
      "Fold: 18  Epoch: 250  Training loss = 5.0020  Validation loss = 2.0704  \n",
      "\n",
      "Fold: 18  Epoch: 251  Training loss = 5.0014  Validation loss = 2.0703  \n",
      "\n",
      "Fold: 18  Epoch: 252  Training loss = 5.0008  Validation loss = 2.0701  \n",
      "\n",
      "Fold: 18  Epoch: 253  Training loss = 5.0001  Validation loss = 2.0700  \n",
      "\n",
      "Fold: 18  Epoch: 254  Training loss = 4.9994  Validation loss = 2.0698  \n",
      "\n",
      "Fold: 18  Epoch: 255  Training loss = 4.9988  Validation loss = 2.0696  \n",
      "\n",
      "Fold: 18  Epoch: 256  Training loss = 4.9982  Validation loss = 2.0695  \n",
      "\n",
      "Fold: 18  Epoch: 257  Training loss = 4.9975  Validation loss = 2.0693  \n",
      "\n",
      "Fold: 18  Epoch: 258  Training loss = 4.9971  Validation loss = 2.0692  \n",
      "\n",
      "Fold: 18  Epoch: 259  Training loss = 4.9964  Validation loss = 2.0690  \n",
      "\n",
      "Fold: 18  Epoch: 260  Training loss = 4.9957  Validation loss = 2.0688  \n",
      "\n",
      "Fold: 18  Epoch: 261  Training loss = 4.9951  Validation loss = 2.0687  \n",
      "\n",
      "Fold: 18  Epoch: 262  Training loss = 4.9945  Validation loss = 2.0685  \n",
      "\n",
      "Fold: 18  Epoch: 263  Training loss = 4.9939  Validation loss = 2.0684  \n",
      "\n",
      "Fold: 18  Epoch: 264  Training loss = 4.9933  Validation loss = 2.0682  \n",
      "\n",
      "Fold: 18  Epoch: 265  Training loss = 4.9928  Validation loss = 2.0681  \n",
      "\n",
      "Fold: 18  Epoch: 266  Training loss = 4.9923  Validation loss = 2.0679  \n",
      "\n",
      "Fold: 18  Epoch: 267  Training loss = 4.9918  Validation loss = 2.0678  \n",
      "\n",
      "Fold: 18  Epoch: 268  Training loss = 4.9911  Validation loss = 2.0676  \n",
      "\n",
      "Fold: 18  Epoch: 269  Training loss = 4.9906  Validation loss = 2.0674  \n",
      "\n",
      "Fold: 18  Epoch: 270  Training loss = 4.9900  Validation loss = 2.0673  \n",
      "\n",
      "Fold: 18  Epoch: 271  Training loss = 4.9894  Validation loss = 2.0671  \n",
      "\n",
      "Fold: 18  Epoch: 272  Training loss = 4.9887  Validation loss = 2.0669  \n",
      "\n",
      "Fold: 18  Epoch: 273  Training loss = 4.9881  Validation loss = 2.0668  \n",
      "\n",
      "Fold: 18  Epoch: 274  Training loss = 4.9875  Validation loss = 2.0666  \n",
      "\n",
      "Fold: 18  Epoch: 275  Training loss = 4.9868  Validation loss = 2.0665  \n",
      "\n",
      "Fold: 18  Epoch: 276  Training loss = 4.9864  Validation loss = 2.0663  \n",
      "\n",
      "Fold: 18  Epoch: 277  Training loss = 4.9858  Validation loss = 2.0662  \n",
      "\n",
      "Fold: 18  Epoch: 278  Training loss = 4.9851  Validation loss = 2.0660  \n",
      "\n",
      "Fold: 18  Epoch: 279  Training loss = 4.9844  Validation loss = 2.0658  \n",
      "\n",
      "Fold: 18  Epoch: 280  Training loss = 4.9838  Validation loss = 2.0657  \n",
      "\n",
      "Fold: 18  Epoch: 281  Training loss = 4.9832  Validation loss = 2.0655  \n",
      "\n",
      "Fold: 18  Epoch: 282  Training loss = 4.9825  Validation loss = 2.0654  \n",
      "\n",
      "Fold: 18  Epoch: 283  Training loss = 4.9819  Validation loss = 2.0652  \n",
      "\n",
      "Fold: 18  Epoch: 284  Training loss = 4.9812  Validation loss = 2.0650  \n",
      "\n",
      "Fold: 18  Epoch: 285  Training loss = 4.9805  Validation loss = 2.0649  \n",
      "\n",
      "Fold: 18  Epoch: 286  Training loss = 4.9798  Validation loss = 2.0647  \n",
      "\n",
      "Fold: 18  Epoch: 287  Training loss = 4.9790  Validation loss = 2.0645  \n",
      "\n",
      "Fold: 18  Epoch: 288  Training loss = 4.9783  Validation loss = 2.0643  \n",
      "\n",
      "Fold: 18  Epoch: 289  Training loss = 4.9776  Validation loss = 2.0642  \n",
      "\n",
      "Fold: 18  Epoch: 290  Training loss = 4.9770  Validation loss = 2.0640  \n",
      "\n",
      "Fold: 18  Epoch: 291  Training loss = 4.9763  Validation loss = 2.0639  \n",
      "\n",
      "Fold: 18  Epoch: 292  Training loss = 4.9758  Validation loss = 2.0638  \n",
      "\n",
      "Fold: 18  Epoch: 293  Training loss = 4.9748  Validation loss = 2.0636  \n",
      "\n",
      "Fold: 18  Epoch: 294  Training loss = 4.9740  Validation loss = 2.0634  \n",
      "\n",
      "Fold: 18  Epoch: 295  Training loss = 4.9731  Validation loss = 2.0633  \n",
      "\n",
      "Fold: 18  Epoch: 296  Training loss = 4.9725  Validation loss = 2.0632  \n",
      "\n",
      "Fold: 18  Epoch: 297  Training loss = 4.9718  Validation loss = 2.0630  \n",
      "\n",
      "Fold: 18  Epoch: 298  Training loss = 4.9711  Validation loss = 2.0628  \n",
      "\n",
      "Fold: 18  Epoch: 299  Training loss = 4.9704  Validation loss = 2.0627  \n",
      "\n",
      "Fold: 18  Epoch: 300  Training loss = 4.9694  Validation loss = 2.0625  \n",
      "\n",
      "Fold: 18  Epoch: 301  Training loss = 4.9677  Validation loss = 2.0624  \n",
      "\n",
      "Fold: 18  Epoch: 302  Training loss = 4.9664  Validation loss = 2.0622  \n",
      "\n",
      "Fold: 18  Epoch: 303  Training loss = 4.9644  Validation loss = 2.0621  \n",
      "\n",
      "Fold: 18  Epoch: 304  Training loss = 4.9621  Validation loss = 2.0619  \n",
      "\n",
      "Fold: 18  Epoch: 305  Training loss = 4.9609  Validation loss = 2.0617  \n",
      "\n",
      "Fold: 18  Epoch: 306  Training loss = 4.9602  Validation loss = 2.0616  \n",
      "\n",
      "Fold: 18  Epoch: 307  Training loss = 4.9594  Validation loss = 2.0614  \n",
      "\n",
      "Fold: 18  Epoch: 308  Training loss = 4.9589  Validation loss = 2.0613  \n",
      "\n",
      "Fold: 18  Epoch: 309  Training loss = 4.9580  Validation loss = 2.0612  \n",
      "\n",
      "Fold: 18  Epoch: 310  Training loss = 4.9573  Validation loss = 2.0610  \n",
      "\n",
      "Fold: 18  Epoch: 311  Training loss = 4.9566  Validation loss = 2.0609  \n",
      "\n",
      "Fold: 18  Epoch: 312  Training loss = 4.9558  Validation loss = 2.0607  \n",
      "\n",
      "Fold: 18  Epoch: 313  Training loss = 4.9552  Validation loss = 2.0605  \n",
      "\n",
      "Fold: 18  Epoch: 314  Training loss = 4.9546  Validation loss = 2.0604  \n",
      "\n",
      "Fold: 18  Epoch: 315  Training loss = 4.9539  Validation loss = 2.0602  \n",
      "\n",
      "Fold: 18  Epoch: 316  Training loss = 4.9533  Validation loss = 2.0601  \n",
      "\n",
      "Fold: 18  Epoch: 317  Training loss = 4.9527  Validation loss = 2.0599  \n",
      "\n",
      "Fold: 18  Epoch: 318  Training loss = 4.9521  Validation loss = 2.0597  \n",
      "\n",
      "Fold: 18  Epoch: 319  Training loss = 4.9516  Validation loss = 2.0596  \n",
      "\n",
      "Fold: 18  Epoch: 320  Training loss = 4.9510  Validation loss = 2.0595  \n",
      "\n",
      "Fold: 18  Epoch: 321  Training loss = 4.9503  Validation loss = 2.0593  \n",
      "\n",
      "Fold: 18  Epoch: 322  Training loss = 4.9497  Validation loss = 2.0592  \n",
      "\n",
      "Fold: 18  Epoch: 323  Training loss = 4.9490  Validation loss = 2.0590  \n",
      "\n",
      "Fold: 18  Epoch: 324  Training loss = 4.9485  Validation loss = 2.0589  \n",
      "\n",
      "Fold: 18  Epoch: 325  Training loss = 4.9480  Validation loss = 2.0587  \n",
      "\n",
      "Fold: 18  Epoch: 326  Training loss = 4.9473  Validation loss = 2.0586  \n",
      "\n",
      "Fold: 18  Epoch: 327  Training loss = 4.9468  Validation loss = 2.0585  \n",
      "\n",
      "Fold: 18  Epoch: 328  Training loss = 4.9461  Validation loss = 2.0583  \n",
      "\n",
      "Fold: 18  Epoch: 329  Training loss = 4.9455  Validation loss = 2.0581  \n",
      "\n",
      "Fold: 18  Epoch: 330  Training loss = 4.9449  Validation loss = 2.0580  \n",
      "\n",
      "Fold: 18  Epoch: 331  Training loss = 4.9443  Validation loss = 2.0578  \n",
      "\n",
      "Fold: 18  Epoch: 332  Training loss = 4.9437  Validation loss = 2.0576  \n",
      "\n",
      "Fold: 18  Epoch: 333  Training loss = 4.9432  Validation loss = 2.0575  \n",
      "\n",
      "Fold: 18  Epoch: 334  Training loss = 4.9427  Validation loss = 2.0574  \n",
      "\n",
      "Fold: 18  Epoch: 335  Training loss = 4.9421  Validation loss = 2.0572  \n",
      "\n",
      "Fold: 18  Epoch: 336  Training loss = 4.9416  Validation loss = 2.0571  \n",
      "\n",
      "Fold: 18  Epoch: 337  Training loss = 4.9411  Validation loss = 2.0570  \n",
      "\n",
      "Fold: 18  Epoch: 338  Training loss = 4.9404  Validation loss = 2.0568  \n",
      "\n",
      "Fold: 18  Epoch: 339  Training loss = 4.9398  Validation loss = 2.0566  \n",
      "\n",
      "Fold: 18  Epoch: 340  Training loss = 4.9391  Validation loss = 2.0565  \n",
      "\n",
      "Fold: 18  Epoch: 341  Training loss = 4.9386  Validation loss = 2.0563  \n",
      "\n",
      "Fold: 18  Epoch: 342  Training loss = 4.9379  Validation loss = 2.0562  \n",
      "\n",
      "Fold: 18  Epoch: 343  Training loss = 4.9374  Validation loss = 2.0560  \n",
      "\n",
      "Fold: 18  Epoch: 344  Training loss = 4.9368  Validation loss = 2.0559  \n",
      "\n",
      "Fold: 18  Epoch: 345  Training loss = 4.9362  Validation loss = 2.0557  \n",
      "\n",
      "Fold: 18  Epoch: 346  Training loss = 4.9356  Validation loss = 2.0556  \n",
      "\n",
      "Fold: 18  Epoch: 347  Training loss = 4.9349  Validation loss = 2.0554  \n",
      "\n",
      "Fold: 18  Epoch: 348  Training loss = 4.9343  Validation loss = 2.0552  \n",
      "\n",
      "Fold: 18  Epoch: 349  Training loss = 4.9337  Validation loss = 2.0551  \n",
      "\n",
      "Fold: 18  Epoch: 350  Training loss = 4.9331  Validation loss = 2.0549  \n",
      "\n",
      "Fold: 18  Epoch: 351  Training loss = 4.9327  Validation loss = 2.0548  \n",
      "\n",
      "Fold: 18  Epoch: 352  Training loss = 4.9321  Validation loss = 2.0547  \n",
      "\n",
      "Fold: 18  Epoch: 353  Training loss = 4.9317  Validation loss = 2.0546  \n",
      "\n",
      "Fold: 18  Epoch: 354  Training loss = 4.9312  Validation loss = 2.0544  \n",
      "\n",
      "Fold: 18  Epoch: 355  Training loss = 4.9305  Validation loss = 2.0543  \n",
      "\n",
      "Fold: 18  Epoch: 356  Training loss = 4.9301  Validation loss = 2.0542  \n",
      "\n",
      "Fold: 18  Epoch: 357  Training loss = 4.9295  Validation loss = 2.0540  \n",
      "\n",
      "Fold: 18  Epoch: 358  Training loss = 4.9289  Validation loss = 2.0539  \n",
      "\n",
      "Fold: 18  Epoch: 359  Training loss = 4.9285  Validation loss = 2.0538  \n",
      "\n",
      "Fold: 18  Epoch: 360  Training loss = 4.9279  Validation loss = 2.0536  \n",
      "\n",
      "Fold: 18  Epoch: 361  Training loss = 4.9273  Validation loss = 2.0535  \n",
      "\n",
      "Fold: 18  Epoch: 362  Training loss = 4.9267  Validation loss = 2.0533  \n",
      "\n",
      "Fold: 18  Epoch: 363  Training loss = 4.9262  Validation loss = 2.0532  \n",
      "\n",
      "Fold: 18  Epoch: 364  Training loss = 4.9257  Validation loss = 2.0531  \n",
      "\n",
      "Fold: 18  Epoch: 365  Training loss = 4.9252  Validation loss = 2.0529  \n",
      "\n",
      "Fold: 18  Epoch: 366  Training loss = 4.9246  Validation loss = 2.0528  \n",
      "\n",
      "Fold: 18  Epoch: 367  Training loss = 4.9238  Validation loss = 2.0526  \n",
      "\n",
      "Fold: 18  Epoch: 368  Training loss = 4.9229  Validation loss = 2.0524  \n",
      "\n",
      "Fold: 18  Epoch: 369  Training loss = 4.9223  Validation loss = 2.0523  \n",
      "\n",
      "Fold: 18  Epoch: 370  Training loss = 4.9216  Validation loss = 2.0522  \n",
      "\n",
      "Fold: 18  Epoch: 371  Training loss = 4.9209  Validation loss = 2.0521  \n",
      "\n",
      "Fold: 18  Epoch: 372  Training loss = 4.9137  Validation loss = 2.0519  \n",
      "\n",
      "Fold: 18  Epoch: 373  Training loss = 4.9131  Validation loss = 2.0518  \n",
      "\n",
      "Fold: 18  Epoch: 374  Training loss = 4.9125  Validation loss = 2.0516  \n",
      "\n",
      "Fold: 18  Epoch: 375  Training loss = 4.9119  Validation loss = 2.0514  \n",
      "\n",
      "Fold: 18  Epoch: 376  Training loss = 4.9114  Validation loss = 2.0513  \n",
      "\n",
      "Fold: 18  Epoch: 377  Training loss = 4.9109  Validation loss = 2.0512  \n",
      "\n",
      "Fold: 18  Epoch: 378  Training loss = 4.9104  Validation loss = 2.0511  \n",
      "\n",
      "Fold: 18  Epoch: 379  Training loss = 4.9099  Validation loss = 2.0510  \n",
      "\n",
      "Fold: 18  Epoch: 380  Training loss = 4.9094  Validation loss = 2.0508  \n",
      "\n",
      "Fold: 18  Epoch: 381  Training loss = 4.9087  Validation loss = 2.0507  \n",
      "\n",
      "Fold: 18  Epoch: 382  Training loss = 4.9081  Validation loss = 2.0505  \n",
      "\n",
      "Fold: 18  Epoch: 383  Training loss = 4.9076  Validation loss = 2.0504  \n",
      "\n",
      "Fold: 18  Epoch: 384  Training loss = 4.9072  Validation loss = 2.0503  \n",
      "\n",
      "Fold: 18  Epoch: 385  Training loss = 4.9066  Validation loss = 2.0501  \n",
      "\n",
      "Fold: 18  Epoch: 386  Training loss = 4.9061  Validation loss = 2.0500  \n",
      "\n",
      "Fold: 18  Epoch: 387  Training loss = 4.9056  Validation loss = 2.0499  \n",
      "\n",
      "Fold: 18  Epoch: 388  Training loss = 4.9050  Validation loss = 2.0497  \n",
      "\n",
      "Fold: 18  Epoch: 389  Training loss = 4.9045  Validation loss = 2.0496  \n",
      "\n",
      "Fold: 18  Epoch: 390  Training loss = 4.9039  Validation loss = 2.0494  \n",
      "\n",
      "Fold: 18  Epoch: 391  Training loss = 4.9033  Validation loss = 2.0493  \n",
      "\n",
      "Fold: 18  Epoch: 392  Training loss = 4.9027  Validation loss = 2.0491  \n",
      "\n",
      "Fold: 18  Epoch: 393  Training loss = 4.9022  Validation loss = 2.0490  \n",
      "\n",
      "Fold: 18  Epoch: 394  Training loss = 4.9016  Validation loss = 2.0489  \n",
      "\n",
      "Fold: 18  Epoch: 395  Training loss = 4.9009  Validation loss = 2.0487  \n",
      "\n",
      "Fold: 18  Epoch: 396  Training loss = 4.9003  Validation loss = 2.0486  \n",
      "\n",
      "Fold: 18  Epoch: 397  Training loss = 4.8998  Validation loss = 2.0484  \n",
      "\n",
      "Fold: 18  Epoch: 398  Training loss = 4.8991  Validation loss = 2.0483  \n",
      "\n",
      "Fold: 18  Epoch: 399  Training loss = 4.8986  Validation loss = 2.0481  \n",
      "\n",
      "Fold: 18  Epoch: 400  Training loss = 4.8980  Validation loss = 2.0480  \n",
      "\n",
      "Fold: 18  Epoch: 401  Training loss = 4.8976  Validation loss = 2.0479  \n",
      "\n",
      "Fold: 18  Epoch: 402  Training loss = 4.8970  Validation loss = 2.0478  \n",
      "\n",
      "Fold: 18  Epoch: 403  Training loss = 4.8964  Validation loss = 2.0476  \n",
      "\n",
      "Fold: 18  Epoch: 404  Training loss = 4.8959  Validation loss = 2.0475  \n",
      "\n",
      "Fold: 18  Epoch: 405  Training loss = 4.8954  Validation loss = 2.0474  \n",
      "\n",
      "Fold: 18  Epoch: 406  Training loss = 4.8948  Validation loss = 2.0472  \n",
      "\n",
      "Fold: 18  Epoch: 407  Training loss = 4.8942  Validation loss = 2.0471  \n",
      "\n",
      "Fold: 18  Epoch: 408  Training loss = 4.8936  Validation loss = 2.0469  \n",
      "\n",
      "Fold: 18  Epoch: 409  Training loss = 4.8931  Validation loss = 2.0468  \n",
      "\n",
      "Fold: 18  Epoch: 410  Training loss = 4.8925  Validation loss = 2.0467  \n",
      "\n",
      "Fold: 18  Epoch: 411  Training loss = 4.8920  Validation loss = 2.0465  \n",
      "\n",
      "Fold: 18  Epoch: 412  Training loss = 4.8913  Validation loss = 2.0464  \n",
      "\n",
      "Fold: 18  Epoch: 413  Training loss = 4.8908  Validation loss = 2.0462  \n",
      "\n",
      "Fold: 18  Epoch: 414  Training loss = 4.8903  Validation loss = 2.0461  \n",
      "\n",
      "Fold: 18  Epoch: 415  Training loss = 4.8897  Validation loss = 2.0460  \n",
      "\n",
      "Fold: 18  Epoch: 416  Training loss = 4.8891  Validation loss = 2.0458  \n",
      "\n",
      "Fold: 18  Epoch: 417  Training loss = 4.8885  Validation loss = 2.0457  \n",
      "\n",
      "Fold: 18  Epoch: 418  Training loss = 4.8880  Validation loss = 2.0456  \n",
      "\n",
      "Fold: 18  Epoch: 419  Training loss = 4.8874  Validation loss = 2.0454  \n",
      "\n",
      "Fold: 18  Epoch: 420  Training loss = 4.8869  Validation loss = 2.0453  \n",
      "\n",
      "Fold: 18  Epoch: 421  Training loss = 4.8863  Validation loss = 2.0452  \n",
      "\n",
      "Fold: 18  Epoch: 422  Training loss = 4.8859  Validation loss = 2.0451  \n",
      "\n",
      "Fold: 18  Epoch: 423  Training loss = 4.8854  Validation loss = 2.0449  \n",
      "\n",
      "Fold: 18  Epoch: 424  Training loss = 4.8849  Validation loss = 2.0448  \n",
      "\n",
      "Fold: 18  Epoch: 425  Training loss = 4.8844  Validation loss = 2.0447  \n",
      "\n",
      "Fold: 18  Epoch: 426  Training loss = 4.8839  Validation loss = 2.0446  \n",
      "\n",
      "Fold: 18  Epoch: 427  Training loss = 4.8834  Validation loss = 2.0444  \n",
      "\n",
      "Fold: 18  Epoch: 428  Training loss = 4.8828  Validation loss = 2.0443  \n",
      "\n",
      "Fold: 18  Epoch: 429  Training loss = 4.8822  Validation loss = 2.0442  \n",
      "\n",
      "Fold: 18  Epoch: 430  Training loss = 4.8817  Validation loss = 2.0440  \n",
      "\n",
      "Fold: 18  Epoch: 431  Training loss = 4.8811  Validation loss = 2.0439  \n",
      "\n",
      "Fold: 18  Epoch: 432  Training loss = 4.8805  Validation loss = 2.0438  \n",
      "\n",
      "Fold: 18  Epoch: 433  Training loss = 4.8800  Validation loss = 2.0437  \n",
      "\n",
      "Fold: 18  Epoch: 434  Training loss = 4.8794  Validation loss = 2.0435  \n",
      "\n",
      "Fold: 18  Epoch: 435  Training loss = 4.8789  Validation loss = 2.0434  \n",
      "\n",
      "Fold: 18  Epoch: 436  Training loss = 4.8783  Validation loss = 2.0432  \n",
      "\n",
      "Fold: 18  Epoch: 437  Training loss = 4.8777  Validation loss = 2.0431  \n",
      "\n",
      "Fold: 18  Epoch: 438  Training loss = 4.8771  Validation loss = 2.0430  \n",
      "\n",
      "Fold: 18  Epoch: 439  Training loss = 4.8766  Validation loss = 2.0428  \n",
      "\n",
      "Fold: 18  Epoch: 440  Training loss = 4.8760  Validation loss = 2.0427  \n",
      "\n",
      "Fold: 18  Epoch: 441  Training loss = 4.8754  Validation loss = 2.0425  \n",
      "\n",
      "Fold: 18  Epoch: 442  Training loss = 4.8750  Validation loss = 2.0424  \n",
      "\n",
      "Fold: 18  Epoch: 443  Training loss = 4.8745  Validation loss = 2.0423  \n",
      "\n",
      "Fold: 18  Epoch: 444  Training loss = 4.8740  Validation loss = 2.0422  \n",
      "\n",
      "Fold: 18  Epoch: 445  Training loss = 4.8736  Validation loss = 2.0421  \n",
      "\n",
      "Fold: 18  Epoch: 446  Training loss = 4.8730  Validation loss = 2.0420  \n",
      "\n",
      "Fold: 18  Epoch: 447  Training loss = 4.8725  Validation loss = 2.0418  \n",
      "\n",
      "Fold: 18  Epoch: 448  Training loss = 4.8718  Validation loss = 2.0417  \n",
      "\n",
      "Fold: 18  Epoch: 449  Training loss = 4.8712  Validation loss = 2.0416  \n",
      "\n",
      "Fold: 18  Epoch: 450  Training loss = 4.8707  Validation loss = 2.0414  \n",
      "\n",
      "Fold: 18  Epoch: 451  Training loss = 4.8700  Validation loss = 2.0413  \n",
      "\n",
      "Fold: 18  Epoch: 452  Training loss = 4.8693  Validation loss = 2.0411  \n",
      "\n",
      "Fold: 18  Epoch: 453  Training loss = 4.8688  Validation loss = 2.0410  \n",
      "\n",
      "Fold: 18  Epoch: 454  Training loss = 4.8681  Validation loss = 2.0408  \n",
      "\n",
      "Fold: 18  Epoch: 455  Training loss = 4.8678  Validation loss = 2.0407  \n",
      "\n",
      "Fold: 18  Epoch: 456  Training loss = 4.8672  Validation loss = 2.0406  \n",
      "\n",
      "Fold: 18  Epoch: 457  Training loss = 4.8667  Validation loss = 2.0405  \n",
      "\n",
      "Fold: 18  Epoch: 458  Training loss = 4.8661  Validation loss = 2.0404  \n",
      "\n",
      "Fold: 18  Epoch: 459  Training loss = 4.8656  Validation loss = 2.0402  \n",
      "\n",
      "Fold: 18  Epoch: 460  Training loss = 4.8650  Validation loss = 2.0401  \n",
      "\n",
      "Fold: 18  Epoch: 461  Training loss = 4.8645  Validation loss = 2.0400  \n",
      "\n",
      "Fold: 18  Epoch: 462  Training loss = 4.8640  Validation loss = 2.0398  \n",
      "\n",
      "Fold: 18  Epoch: 463  Training loss = 4.8633  Validation loss = 2.0397  \n",
      "\n",
      "Fold: 18  Epoch: 464  Training loss = 4.8629  Validation loss = 2.0396  \n",
      "\n",
      "Fold: 18  Epoch: 465  Training loss = 4.8624  Validation loss = 2.0395  \n",
      "\n",
      "Fold: 18  Epoch: 466  Training loss = 4.8619  Validation loss = 2.0393  \n",
      "\n",
      "Fold: 18  Epoch: 467  Training loss = 4.8613  Validation loss = 2.0392  \n",
      "\n",
      "Fold: 18  Epoch: 468  Training loss = 4.8607  Validation loss = 2.0391  \n",
      "\n",
      "Fold: 18  Epoch: 469  Training loss = 4.8602  Validation loss = 2.0390  \n",
      "\n",
      "Fold: 18  Epoch: 470  Training loss = 4.8597  Validation loss = 2.0388  \n",
      "\n",
      "Fold: 18  Epoch: 471  Training loss = 4.8592  Validation loss = 2.0387  \n",
      "\n",
      "Fold: 18  Epoch: 472  Training loss = 4.8586  Validation loss = 2.0386  \n",
      "\n",
      "Fold: 18  Epoch: 473  Training loss = 4.8579  Validation loss = 2.0384  \n",
      "\n",
      "Fold: 18  Epoch: 474  Training loss = 4.8574  Validation loss = 2.0383  \n",
      "\n",
      "Fold: 18  Epoch: 475  Training loss = 4.8569  Validation loss = 2.0382  \n",
      "\n",
      "Fold: 18  Epoch: 476  Training loss = 4.8564  Validation loss = 2.0381  \n",
      "\n",
      "Fold: 18  Epoch: 477  Training loss = 4.8559  Validation loss = 2.0380  \n",
      "\n",
      "Fold: 18  Epoch: 478  Training loss = 4.8552  Validation loss = 2.0378  \n",
      "\n",
      "Fold: 18  Epoch: 479  Training loss = 4.8547  Validation loss = 2.0377  \n",
      "\n",
      "Fold: 18  Epoch: 480  Training loss = 4.8542  Validation loss = 2.0376  \n",
      "\n",
      "Fold: 18  Epoch: 481  Training loss = 4.8536  Validation loss = 2.0374  \n",
      "\n",
      "Fold: 18  Epoch: 482  Training loss = 4.8531  Validation loss = 2.0373  \n",
      "\n",
      "Fold: 18  Epoch: 483  Training loss = 4.8525  Validation loss = 2.0372  \n",
      "\n",
      "Fold: 18  Epoch: 484  Training loss = 4.8518  Validation loss = 2.0370  \n",
      "\n",
      "Fold: 18  Epoch: 485  Training loss = 4.8514  Validation loss = 2.0369  \n",
      "\n",
      "Fold: 18  Epoch: 486  Training loss = 4.8508  Validation loss = 2.0368  \n",
      "\n",
      "Fold: 18  Epoch: 487  Training loss = 4.8502  Validation loss = 2.0366  \n",
      "\n",
      "Fold: 18  Epoch: 488  Training loss = 4.8496  Validation loss = 2.0365  \n",
      "\n",
      "Fold: 18  Epoch: 489  Training loss = 4.8492  Validation loss = 2.0364  \n",
      "\n",
      "Fold: 18  Epoch: 490  Training loss = 4.8487  Validation loss = 2.0363  \n",
      "\n",
      "Fold: 18  Epoch: 491  Training loss = 4.8481  Validation loss = 2.0362  \n",
      "\n",
      "Fold: 18  Epoch: 492  Training loss = 4.8475  Validation loss = 2.0360  \n",
      "\n",
      "Fold: 18  Epoch: 493  Training loss = 4.8469  Validation loss = 2.0359  \n",
      "\n",
      "Fold: 18  Epoch: 494  Training loss = 4.8463  Validation loss = 2.0358  \n",
      "\n",
      "Fold: 18  Epoch: 495  Training loss = 4.8457  Validation loss = 2.0356  \n",
      "\n",
      "Fold: 18  Epoch: 496  Training loss = 4.8452  Validation loss = 2.0355  \n",
      "\n",
      "Fold: 18  Epoch: 497  Training loss = 4.8447  Validation loss = 2.0354  \n",
      "\n",
      "Fold: 18  Epoch: 498  Training loss = 4.8441  Validation loss = 2.0353  \n",
      "\n",
      "Fold: 18  Epoch: 499  Training loss = 4.8435  Validation loss = 2.0351  \n",
      "\n",
      "Fold: 18  Epoch: 500  Training loss = 4.8429  Validation loss = 2.0350  \n",
      "\n",
      "Check model:  Fold: 18  Optimal epoch: 500  \n",
      "\n",
      "Fold: 19  Epoch: 1  Training loss = 4.8585  Validation loss = 1.4359  \n",
      "\n",
      "Fold: 19  Epoch: 2  Training loss = 4.8578  Validation loss = 1.4353  \n",
      "\n",
      "Fold: 19  Epoch: 3  Training loss = 4.8573  Validation loss = 1.4349  \n",
      "\n",
      "Fold: 19  Epoch: 4  Training loss = 4.8568  Validation loss = 1.4345  \n",
      "\n",
      "Fold: 19  Epoch: 5  Training loss = 4.8562  Validation loss = 1.4339  \n",
      "\n",
      "Fold: 19  Epoch: 6  Training loss = 4.8556  Validation loss = 1.4333  \n",
      "\n",
      "Fold: 19  Epoch: 7  Training loss = 4.8550  Validation loss = 1.4328  \n",
      "\n",
      "Fold: 19  Epoch: 8  Training loss = 4.8545  Validation loss = 1.4324  \n",
      "\n",
      "Fold: 19  Epoch: 9  Training loss = 4.8540  Validation loss = 1.4319  \n",
      "\n",
      "Fold: 19  Epoch: 10  Training loss = 4.8534  Validation loss = 1.4314  \n",
      "\n",
      "Fold: 19  Epoch: 11  Training loss = 4.8529  Validation loss = 1.4309  \n",
      "\n",
      "Fold: 19  Epoch: 12  Training loss = 4.8523  Validation loss = 1.4304  \n",
      "\n",
      "Fold: 19  Epoch: 13  Training loss = 4.8517  Validation loss = 1.4298  \n",
      "\n",
      "Fold: 19  Epoch: 14  Training loss = 4.8511  Validation loss = 1.4293  \n",
      "\n",
      "Fold: 19  Epoch: 15  Training loss = 4.8505  Validation loss = 1.4287  \n",
      "\n",
      "Fold: 19  Epoch: 16  Training loss = 4.8499  Validation loss = 1.4282  \n",
      "\n",
      "Fold: 19  Epoch: 17  Training loss = 4.8494  Validation loss = 1.4277  \n",
      "\n",
      "Fold: 19  Epoch: 18  Training loss = 4.8489  Validation loss = 1.4273  \n",
      "\n",
      "Fold: 19  Epoch: 19  Training loss = 4.8483  Validation loss = 1.4268  \n",
      "\n",
      "Fold: 19  Epoch: 20  Training loss = 4.8477  Validation loss = 1.4263  \n",
      "\n",
      "Fold: 19  Epoch: 21  Training loss = 4.8472  Validation loss = 1.4258  \n",
      "\n",
      "Fold: 19  Epoch: 22  Training loss = 4.8467  Validation loss = 1.4253  \n",
      "\n",
      "Fold: 19  Epoch: 23  Training loss = 4.8462  Validation loss = 1.4249  \n",
      "\n",
      "Fold: 19  Epoch: 24  Training loss = 4.8457  Validation loss = 1.4244  \n",
      "\n",
      "Fold: 19  Epoch: 25  Training loss = 4.8452  Validation loss = 1.4240  \n",
      "\n",
      "Fold: 19  Epoch: 26  Training loss = 4.8446  Validation loss = 1.4235  \n",
      "\n",
      "Fold: 19  Epoch: 27  Training loss = 4.8441  Validation loss = 1.4230  \n",
      "\n",
      "Fold: 19  Epoch: 28  Training loss = 4.8435  Validation loss = 1.4225  \n",
      "\n",
      "Fold: 19  Epoch: 29  Training loss = 4.8428  Validation loss = 1.4219  \n",
      "\n",
      "Fold: 19  Epoch: 30  Training loss = 4.8422  Validation loss = 1.4213  \n",
      "\n",
      "Fold: 19  Epoch: 31  Training loss = 4.8416  Validation loss = 1.4208  \n",
      "\n",
      "Fold: 19  Epoch: 32  Training loss = 4.8410  Validation loss = 1.4203  \n",
      "\n",
      "Fold: 19  Epoch: 33  Training loss = 4.8405  Validation loss = 1.4198  \n",
      "\n",
      "Fold: 19  Epoch: 34  Training loss = 4.8401  Validation loss = 1.4194  \n",
      "\n",
      "Fold: 19  Epoch: 35  Training loss = 4.8395  Validation loss = 1.4189  \n",
      "\n",
      "Fold: 19  Epoch: 36  Training loss = 4.8390  Validation loss = 1.4184  \n",
      "\n",
      "Fold: 19  Epoch: 37  Training loss = 4.8385  Validation loss = 1.4180  \n",
      "\n",
      "Fold: 19  Epoch: 38  Training loss = 4.8380  Validation loss = 1.4175  \n",
      "\n",
      "Fold: 19  Epoch: 39  Training loss = 4.8375  Validation loss = 1.4171  \n",
      "\n",
      "Fold: 19  Epoch: 40  Training loss = 4.8370  Validation loss = 1.4166  \n",
      "\n",
      "Fold: 19  Epoch: 41  Training loss = 4.8364  Validation loss = 1.4161  \n",
      "\n",
      "Fold: 19  Epoch: 42  Training loss = 4.8359  Validation loss = 1.4156  \n",
      "\n",
      "Fold: 19  Epoch: 43  Training loss = 4.8354  Validation loss = 1.4152  \n",
      "\n",
      "Fold: 19  Epoch: 44  Training loss = 4.8349  Validation loss = 1.4148  \n",
      "\n",
      "Fold: 19  Epoch: 45  Training loss = 4.8342  Validation loss = 1.4141  \n",
      "\n",
      "Fold: 19  Epoch: 46  Training loss = 4.8337  Validation loss = 1.4137  \n",
      "\n",
      "Fold: 19  Epoch: 47  Training loss = 4.8331  Validation loss = 1.4131  \n",
      "\n",
      "Fold: 19  Epoch: 48  Training loss = 4.8325  Validation loss = 1.4126  \n",
      "\n",
      "Fold: 19  Epoch: 49  Training loss = 4.8319  Validation loss = 1.4120  \n",
      "\n",
      "Fold: 19  Epoch: 50  Training loss = 4.8314  Validation loss = 1.4116  \n",
      "\n",
      "Fold: 19  Epoch: 51  Training loss = 4.8308  Validation loss = 1.4110  \n",
      "\n",
      "Fold: 19  Epoch: 52  Training loss = 4.8302  Validation loss = 1.4105  \n",
      "\n",
      "Fold: 19  Epoch: 53  Training loss = 4.8298  Validation loss = 1.4102  \n",
      "\n",
      "Fold: 19  Epoch: 54  Training loss = 4.8293  Validation loss = 1.4097  \n",
      "\n",
      "Fold: 19  Epoch: 55  Training loss = 4.8287  Validation loss = 1.4092  \n",
      "\n",
      "Fold: 19  Epoch: 56  Training loss = 4.8282  Validation loss = 1.4087  \n",
      "\n",
      "Fold: 19  Epoch: 57  Training loss = 4.8276  Validation loss = 1.4082  \n",
      "\n",
      "Fold: 19  Epoch: 58  Training loss = 4.8271  Validation loss = 1.4077  \n",
      "\n",
      "Fold: 19  Epoch: 59  Training loss = 4.8265  Validation loss = 1.4072  \n",
      "\n",
      "Fold: 19  Epoch: 60  Training loss = 4.8259  Validation loss = 1.4066  \n",
      "\n",
      "Fold: 19  Epoch: 61  Training loss = 4.8253  Validation loss = 1.4061  \n",
      "\n",
      "Fold: 19  Epoch: 62  Training loss = 4.8248  Validation loss = 1.4056  \n",
      "\n",
      "Fold: 19  Epoch: 63  Training loss = 4.8243  Validation loss = 1.4052  \n",
      "\n",
      "Fold: 19  Epoch: 64  Training loss = 4.8238  Validation loss = 1.4047  \n",
      "\n",
      "Fold: 19  Epoch: 65  Training loss = 4.8233  Validation loss = 1.4042  \n",
      "\n",
      "Fold: 19  Epoch: 66  Training loss = 4.8228  Validation loss = 1.4038  \n",
      "\n",
      "Fold: 19  Epoch: 67  Training loss = 4.8223  Validation loss = 1.4033  \n",
      "\n",
      "Fold: 19  Epoch: 68  Training loss = 4.8217  Validation loss = 1.4028  \n",
      "\n",
      "Fold: 19  Epoch: 69  Training loss = 4.8212  Validation loss = 1.4023  \n",
      "\n",
      "Fold: 19  Epoch: 70  Training loss = 4.8207  Validation loss = 1.4019  \n",
      "\n",
      "Fold: 19  Epoch: 71  Training loss = 4.8202  Validation loss = 1.4015  \n",
      "\n",
      "Fold: 19  Epoch: 72  Training loss = 4.8194  Validation loss = 1.4008  \n",
      "\n",
      "Fold: 19  Epoch: 73  Training loss = 4.8189  Validation loss = 1.4003  \n",
      "\n",
      "Fold: 19  Epoch: 74  Training loss = 4.8186  Validation loss = 1.4000  \n",
      "\n",
      "Fold: 19  Epoch: 75  Training loss = 4.8180  Validation loss = 1.3995  \n",
      "\n",
      "Fold: 19  Epoch: 76  Training loss = 4.8175  Validation loss = 1.3990  \n",
      "\n",
      "Fold: 19  Epoch: 77  Training loss = 4.8171  Validation loss = 1.3986  \n",
      "\n",
      "Fold: 19  Epoch: 78  Training loss = 4.8166  Validation loss = 1.3982  \n",
      "\n",
      "Fold: 19  Epoch: 79  Training loss = 4.8160  Validation loss = 1.3977  \n",
      "\n",
      "Fold: 19  Epoch: 80  Training loss = 4.8154  Validation loss = 1.3971  \n",
      "\n",
      "Fold: 19  Epoch: 81  Training loss = 4.8149  Validation loss = 1.3966  \n",
      "\n",
      "Fold: 19  Epoch: 82  Training loss = 4.8143  Validation loss = 1.3961  \n",
      "\n",
      "Fold: 19  Epoch: 83  Training loss = 4.8137  Validation loss = 1.3956  \n",
      "\n",
      "Fold: 19  Epoch: 84  Training loss = 4.8131  Validation loss = 1.3951  \n",
      "\n",
      "Fold: 19  Epoch: 85  Training loss = 4.8126  Validation loss = 1.3946  \n",
      "\n",
      "Fold: 19  Epoch: 86  Training loss = 4.8120  Validation loss = 1.3941  \n",
      "\n",
      "Fold: 19  Epoch: 87  Training loss = 4.8115  Validation loss = 1.3937  \n",
      "\n",
      "Fold: 19  Epoch: 88  Training loss = 4.8110  Validation loss = 1.3931  \n",
      "\n",
      "Fold: 19  Epoch: 89  Training loss = 4.8104  Validation loss = 1.3926  \n",
      "\n",
      "Fold: 19  Epoch: 90  Training loss = 4.8099  Validation loss = 1.3921  \n",
      "\n",
      "Fold: 19  Epoch: 91  Training loss = 4.8093  Validation loss = 1.3916  \n",
      "\n",
      "Fold: 19  Epoch: 92  Training loss = 4.8086  Validation loss = 1.3909  \n",
      "\n",
      "Fold: 19  Epoch: 93  Training loss = 4.8080  Validation loss = 1.3904  \n",
      "\n",
      "Fold: 19  Epoch: 94  Training loss = 4.8073  Validation loss = 1.3898  \n",
      "\n",
      "Fold: 19  Epoch: 95  Training loss = 4.8068  Validation loss = 1.3893  \n",
      "\n",
      "Fold: 19  Epoch: 96  Training loss = 4.8063  Validation loss = 1.3888  \n",
      "\n",
      "Fold: 19  Epoch: 97  Training loss = 4.8057  Validation loss = 1.3883  \n",
      "\n",
      "Fold: 19  Epoch: 98  Training loss = 4.8051  Validation loss = 1.3877  \n",
      "\n",
      "Fold: 19  Epoch: 99  Training loss = 4.8045  Validation loss = 1.3872  \n",
      "\n",
      "Fold: 19  Epoch: 100  Training loss = 4.8039  Validation loss = 1.3867  \n",
      "\n",
      "Fold: 19  Epoch: 101  Training loss = 4.8034  Validation loss = 1.3862  \n",
      "\n",
      "Fold: 19  Epoch: 102  Training loss = 4.8028  Validation loss = 1.3857  \n",
      "\n",
      "Fold: 19  Epoch: 103  Training loss = 4.8022  Validation loss = 1.3852  \n",
      "\n",
      "Fold: 19  Epoch: 104  Training loss = 4.8017  Validation loss = 1.3847  \n",
      "\n",
      "Fold: 19  Epoch: 105  Training loss = 4.8010  Validation loss = 1.3841  \n",
      "\n",
      "Fold: 19  Epoch: 106  Training loss = 4.8005  Validation loss = 1.3836  \n",
      "\n",
      "Fold: 19  Epoch: 107  Training loss = 4.7999  Validation loss = 1.3831  \n",
      "\n",
      "Fold: 19  Epoch: 108  Training loss = 4.7994  Validation loss = 1.3826  \n",
      "\n",
      "Fold: 19  Epoch: 109  Training loss = 4.7990  Validation loss = 1.3823  \n",
      "\n",
      "Fold: 19  Epoch: 110  Training loss = 4.7984  Validation loss = 1.3818  \n",
      "\n",
      "Fold: 19  Epoch: 111  Training loss = 4.7979  Validation loss = 1.3814  \n",
      "\n",
      "Fold: 19  Epoch: 112  Training loss = 4.7973  Validation loss = 1.3808  \n",
      "\n",
      "Fold: 19  Epoch: 113  Training loss = 4.7968  Validation loss = 1.3804  \n",
      "\n",
      "Fold: 19  Epoch: 114  Training loss = 4.7964  Validation loss = 1.3800  \n",
      "\n",
      "Fold: 19  Epoch: 115  Training loss = 4.7958  Validation loss = 1.3795  \n",
      "\n",
      "Fold: 19  Epoch: 116  Training loss = 4.7953  Validation loss = 1.3790  \n",
      "\n",
      "Fold: 19  Epoch: 117  Training loss = 4.7948  Validation loss = 1.3786  \n",
      "\n",
      "Fold: 19  Epoch: 118  Training loss = 4.7943  Validation loss = 1.3780  \n",
      "\n",
      "Fold: 19  Epoch: 119  Training loss = 4.7938  Validation loss = 1.3776  \n",
      "\n",
      "Fold: 19  Epoch: 120  Training loss = 4.7932  Validation loss = 1.3771  \n",
      "\n",
      "Fold: 19  Epoch: 121  Training loss = 4.7927  Validation loss = 1.3766  \n",
      "\n",
      "Fold: 19  Epoch: 122  Training loss = 4.7922  Validation loss = 1.3762  \n",
      "\n",
      "Fold: 19  Epoch: 123  Training loss = 4.7917  Validation loss = 1.3757  \n",
      "\n",
      "Fold: 19  Epoch: 124  Training loss = 4.7912  Validation loss = 1.3753  \n",
      "\n",
      "Fold: 19  Epoch: 125  Training loss = 4.7906  Validation loss = 1.3748  \n",
      "\n",
      "Fold: 19  Epoch: 126  Training loss = 4.7900  Validation loss = 1.3742  \n",
      "\n",
      "Fold: 19  Epoch: 127  Training loss = 4.7896  Validation loss = 1.3738  \n",
      "\n",
      "Fold: 19  Epoch: 128  Training loss = 4.7891  Validation loss = 1.3734  \n",
      "\n",
      "Fold: 19  Epoch: 129  Training loss = 4.7885  Validation loss = 1.3729  \n",
      "\n",
      "Fold: 19  Epoch: 130  Training loss = 4.7881  Validation loss = 1.3725  \n",
      "\n",
      "Fold: 19  Epoch: 131  Training loss = 4.7874  Validation loss = 1.3719  \n",
      "\n",
      "Fold: 19  Epoch: 132  Training loss = 4.7870  Validation loss = 1.3715  \n",
      "\n",
      "Fold: 19  Epoch: 133  Training loss = 4.7864  Validation loss = 1.3710  \n",
      "\n",
      "Fold: 19  Epoch: 134  Training loss = 4.7858  Validation loss = 1.3704  \n",
      "\n",
      "Fold: 19  Epoch: 135  Training loss = 4.7853  Validation loss = 1.3700  \n",
      "\n",
      "Fold: 19  Epoch: 136  Training loss = 4.7847  Validation loss = 1.3695  \n",
      "\n",
      "Fold: 19  Epoch: 137  Training loss = 4.7842  Validation loss = 1.3690  \n",
      "\n",
      "Fold: 19  Epoch: 138  Training loss = 4.7837  Validation loss = 1.3686  \n",
      "\n",
      "Fold: 19  Epoch: 139  Training loss = 4.7832  Validation loss = 1.3682  \n",
      "\n",
      "Fold: 19  Epoch: 140  Training loss = 4.7827  Validation loss = 1.3677  \n",
      "\n",
      "Fold: 19  Epoch: 141  Training loss = 4.7821  Validation loss = 1.3672  \n",
      "\n",
      "Fold: 19  Epoch: 142  Training loss = 4.7817  Validation loss = 1.3668  \n",
      "\n",
      "Fold: 19  Epoch: 143  Training loss = 4.7812  Validation loss = 1.3664  \n",
      "\n",
      "Fold: 19  Epoch: 144  Training loss = 4.7807  Validation loss = 1.3659  \n",
      "\n",
      "Fold: 19  Epoch: 145  Training loss = 4.7803  Validation loss = 1.3655  \n",
      "\n",
      "Fold: 19  Epoch: 146  Training loss = 4.7796  Validation loss = 1.3649  \n",
      "\n",
      "Fold: 19  Epoch: 147  Training loss = 4.7791  Validation loss = 1.3645  \n",
      "\n",
      "Fold: 19  Epoch: 148  Training loss = 4.7785  Validation loss = 1.3640  \n",
      "\n",
      "Fold: 19  Epoch: 149  Training loss = 4.7779  Validation loss = 1.3634  \n",
      "\n",
      "Fold: 19  Epoch: 150  Training loss = 4.7774  Validation loss = 1.3629  \n",
      "\n",
      "Fold: 19  Epoch: 151  Training loss = 4.7769  Validation loss = 1.3625  \n",
      "\n",
      "Fold: 19  Epoch: 152  Training loss = 4.7764  Validation loss = 1.3620  \n",
      "\n",
      "Fold: 19  Epoch: 153  Training loss = 4.7759  Validation loss = 1.3617  \n",
      "\n",
      "Fold: 19  Epoch: 154  Training loss = 4.7755  Validation loss = 1.3612  \n",
      "\n",
      "Fold: 19  Epoch: 155  Training loss = 4.7749  Validation loss = 1.3607  \n",
      "\n",
      "Fold: 19  Epoch: 156  Training loss = 4.7743  Validation loss = 1.3602  \n",
      "\n",
      "Fold: 19  Epoch: 157  Training loss = 4.7738  Validation loss = 1.3598  \n",
      "\n",
      "Fold: 19  Epoch: 158  Training loss = 4.7734  Validation loss = 1.3594  \n",
      "\n",
      "Fold: 19  Epoch: 159  Training loss = 4.7729  Validation loss = 1.3589  \n",
      "\n",
      "Fold: 19  Epoch: 160  Training loss = 4.7725  Validation loss = 1.3585  \n",
      "\n",
      "Fold: 19  Epoch: 161  Training loss = 4.7719  Validation loss = 1.3580  \n",
      "\n",
      "Fold: 19  Epoch: 162  Training loss = 4.7714  Validation loss = 1.3576  \n",
      "\n",
      "Fold: 19  Epoch: 163  Training loss = 4.7709  Validation loss = 1.3571  \n",
      "\n",
      "Fold: 19  Epoch: 164  Training loss = 4.7704  Validation loss = 1.3567  \n",
      "\n",
      "Fold: 19  Epoch: 165  Training loss = 4.7699  Validation loss = 1.3562  \n",
      "\n",
      "Fold: 19  Epoch: 166  Training loss = 4.7693  Validation loss = 1.3557  \n",
      "\n",
      "Fold: 19  Epoch: 167  Training loss = 4.7687  Validation loss = 1.3552  \n",
      "\n",
      "Fold: 19  Epoch: 168  Training loss = 4.7682  Validation loss = 1.3547  \n",
      "\n",
      "Fold: 19  Epoch: 169  Training loss = 4.7676  Validation loss = 1.3542  \n",
      "\n",
      "Fold: 19  Epoch: 170  Training loss = 4.7671  Validation loss = 1.3537  \n",
      "\n",
      "Fold: 19  Epoch: 171  Training loss = 4.7666  Validation loss = 1.3533  \n",
      "\n",
      "Fold: 19  Epoch: 172  Training loss = 4.7661  Validation loss = 1.3528  \n",
      "\n",
      "Fold: 19  Epoch: 173  Training loss = 4.7655  Validation loss = 1.3523  \n",
      "\n",
      "Fold: 19  Epoch: 174  Training loss = 4.7650  Validation loss = 1.3518  \n",
      "\n",
      "Fold: 19  Epoch: 175  Training loss = 4.7643  Validation loss = 1.3512  \n",
      "\n",
      "Fold: 19  Epoch: 176  Training loss = 4.7638  Validation loss = 1.3508  \n",
      "\n",
      "Fold: 19  Epoch: 177  Training loss = 4.7633  Validation loss = 1.3503  \n",
      "\n",
      "Fold: 19  Epoch: 178  Training loss = 4.7628  Validation loss = 1.3498  \n",
      "\n",
      "Fold: 19  Epoch: 179  Training loss = 4.7622  Validation loss = 1.3494  \n",
      "\n",
      "Fold: 19  Epoch: 180  Training loss = 4.7618  Validation loss = 1.3490  \n",
      "\n",
      "Fold: 19  Epoch: 181  Training loss = 4.7614  Validation loss = 1.3486  \n",
      "\n",
      "Fold: 19  Epoch: 182  Training loss = 4.7609  Validation loss = 1.3481  \n",
      "\n",
      "Fold: 19  Epoch: 183  Training loss = 4.7604  Validation loss = 1.3477  \n",
      "\n",
      "Fold: 19  Epoch: 184  Training loss = 4.7599  Validation loss = 1.3473  \n",
      "\n",
      "Fold: 19  Epoch: 185  Training loss = 4.7594  Validation loss = 1.3468  \n",
      "\n",
      "Fold: 19  Epoch: 186  Training loss = 4.7588  Validation loss = 1.3463  \n",
      "\n",
      "Fold: 19  Epoch: 187  Training loss = 4.7585  Validation loss = 1.3459  \n",
      "\n",
      "Fold: 19  Epoch: 188  Training loss = 4.7580  Validation loss = 1.3455  \n",
      "\n",
      "Fold: 19  Epoch: 189  Training loss = 4.7575  Validation loss = 1.3450  \n",
      "\n",
      "Fold: 19  Epoch: 190  Training loss = 4.7569  Validation loss = 1.3446  \n",
      "\n",
      "Fold: 19  Epoch: 191  Training loss = 4.7565  Validation loss = 1.3442  \n",
      "\n",
      "Fold: 19  Epoch: 192  Training loss = 4.7560  Validation loss = 1.3438  \n",
      "\n",
      "Fold: 19  Epoch: 193  Training loss = 4.7554  Validation loss = 1.3432  \n",
      "\n",
      "Fold: 19  Epoch: 194  Training loss = 4.7549  Validation loss = 1.3428  \n",
      "\n",
      "Fold: 19  Epoch: 195  Training loss = 4.7544  Validation loss = 1.3423  \n",
      "\n",
      "Fold: 19  Epoch: 196  Training loss = 4.7539  Validation loss = 1.3419  \n",
      "\n",
      "Fold: 19  Epoch: 197  Training loss = 4.7533  Validation loss = 1.3413  \n",
      "\n",
      "Fold: 19  Epoch: 198  Training loss = 4.7526  Validation loss = 1.3408  \n",
      "\n",
      "Fold: 19  Epoch: 199  Training loss = 4.7521  Validation loss = 1.3403  \n",
      "\n",
      "Fold: 19  Epoch: 200  Training loss = 4.7517  Validation loss = 1.3399  \n",
      "\n",
      "Fold: 19  Epoch: 201  Training loss = 4.7510  Validation loss = 1.3393  \n",
      "\n",
      "Fold: 19  Epoch: 202  Training loss = 4.7506  Validation loss = 1.3389  \n",
      "\n",
      "Fold: 19  Epoch: 203  Training loss = 4.7501  Validation loss = 1.3385  \n",
      "\n",
      "Fold: 19  Epoch: 204  Training loss = 4.7496  Validation loss = 1.3380  \n",
      "\n",
      "Fold: 19  Epoch: 205  Training loss = 4.7490  Validation loss = 1.3375  \n",
      "\n",
      "Fold: 19  Epoch: 206  Training loss = 4.7486  Validation loss = 1.3371  \n",
      "\n",
      "Fold: 19  Epoch: 207  Training loss = 4.7482  Validation loss = 1.3367  \n",
      "\n",
      "Fold: 19  Epoch: 208  Training loss = 4.7478  Validation loss = 1.3363  \n",
      "\n",
      "Fold: 19  Epoch: 209  Training loss = 4.7471  Validation loss = 1.3358  \n",
      "\n",
      "Fold: 19  Epoch: 210  Training loss = 4.7466  Validation loss = 1.3353  \n",
      "\n",
      "Fold: 19  Epoch: 211  Training loss = 4.7460  Validation loss = 1.3348  \n",
      "\n",
      "Fold: 19  Epoch: 212  Training loss = 4.7454  Validation loss = 1.3343  \n",
      "\n",
      "Fold: 19  Epoch: 213  Training loss = 4.7449  Validation loss = 1.3338  \n",
      "\n",
      "Fold: 19  Epoch: 214  Training loss = 4.7444  Validation loss = 1.3333  \n",
      "\n",
      "Fold: 19  Epoch: 215  Training loss = 4.7439  Validation loss = 1.3329  \n",
      "\n",
      "Fold: 19  Epoch: 216  Training loss = 4.7434  Validation loss = 1.3324  \n",
      "\n",
      "Fold: 19  Epoch: 217  Training loss = 4.7429  Validation loss = 1.3319  \n",
      "\n",
      "Fold: 19  Epoch: 218  Training loss = 4.7422  Validation loss = 1.3313  \n",
      "\n",
      "Fold: 19  Epoch: 219  Training loss = 4.7416  Validation loss = 1.3308  \n",
      "\n",
      "Fold: 19  Epoch: 220  Training loss = 4.7409  Validation loss = 1.3302  \n",
      "\n",
      "Fold: 19  Epoch: 221  Training loss = 4.7404  Validation loss = 1.3297  \n",
      "\n",
      "Fold: 19  Epoch: 222  Training loss = 4.7398  Validation loss = 1.3292  \n",
      "\n",
      "Fold: 19  Epoch: 223  Training loss = 4.7393  Validation loss = 1.3288  \n",
      "\n",
      "Fold: 19  Epoch: 224  Training loss = 4.7388  Validation loss = 1.3283  \n",
      "\n",
      "Fold: 19  Epoch: 225  Training loss = 4.7384  Validation loss = 1.3279  \n",
      "\n",
      "Fold: 19  Epoch: 226  Training loss = 4.7378  Validation loss = 1.3274  \n",
      "\n",
      "Fold: 19  Epoch: 227  Training loss = 4.7373  Validation loss = 1.3269  \n",
      "\n",
      "Fold: 19  Epoch: 228  Training loss = 4.7368  Validation loss = 1.3265  \n",
      "\n",
      "Fold: 19  Epoch: 229  Training loss = 4.7361  Validation loss = 1.3259  \n",
      "\n",
      "Fold: 19  Epoch: 230  Training loss = 4.7355  Validation loss = 1.3253  \n",
      "\n",
      "Fold: 19  Epoch: 231  Training loss = 4.7349  Validation loss = 1.3248  \n",
      "\n",
      "Fold: 19  Epoch: 232  Training loss = 4.7344  Validation loss = 1.3243  \n",
      "\n",
      "Fold: 19  Epoch: 233  Training loss = 4.7337  Validation loss = 1.3238  \n",
      "\n",
      "Fold: 19  Epoch: 234  Training loss = 4.7332  Validation loss = 1.3233  \n",
      "\n",
      "Fold: 19  Epoch: 235  Training loss = 4.7326  Validation loss = 1.3228  \n",
      "\n",
      "Fold: 19  Epoch: 236  Training loss = 4.7320  Validation loss = 1.3222  \n",
      "\n",
      "Fold: 19  Epoch: 237  Training loss = 4.7315  Validation loss = 1.3218  \n",
      "\n",
      "Fold: 19  Epoch: 238  Training loss = 4.7309  Validation loss = 1.3212  \n",
      "\n",
      "Fold: 19  Epoch: 239  Training loss = 4.7305  Validation loss = 1.3209  \n",
      "\n",
      "Fold: 19  Epoch: 240  Training loss = 4.7300  Validation loss = 1.3205  \n",
      "\n",
      "Fold: 19  Epoch: 241  Training loss = 4.7295  Validation loss = 1.3200  \n",
      "\n",
      "Fold: 19  Epoch: 242  Training loss = 4.7290  Validation loss = 1.3195  \n",
      "\n",
      "Fold: 19  Epoch: 243  Training loss = 4.7284  Validation loss = 1.3190  \n",
      "\n",
      "Fold: 19  Epoch: 244  Training loss = 4.7279  Validation loss = 1.3186  \n",
      "\n",
      "Fold: 19  Epoch: 245  Training loss = 4.7275  Validation loss = 1.3182  \n",
      "\n",
      "Fold: 19  Epoch: 246  Training loss = 4.7271  Validation loss = 1.3178  \n",
      "\n",
      "Fold: 19  Epoch: 247  Training loss = 4.7265  Validation loss = 1.3173  \n",
      "\n",
      "Fold: 19  Epoch: 248  Training loss = 4.7260  Validation loss = 1.3168  \n",
      "\n",
      "Fold: 19  Epoch: 249  Training loss = 4.7254  Validation loss = 1.3163  \n",
      "\n",
      "Fold: 19  Epoch: 250  Training loss = 4.7248  Validation loss = 1.3157  \n",
      "\n",
      "Fold: 19  Epoch: 251  Training loss = 4.7242  Validation loss = 1.3152  \n",
      "\n",
      "Fold: 19  Epoch: 252  Training loss = 4.7236  Validation loss = 1.3147  \n",
      "\n",
      "Fold: 19  Epoch: 253  Training loss = 4.7231  Validation loss = 1.3143  \n",
      "\n",
      "Fold: 19  Epoch: 254  Training loss = 4.7226  Validation loss = 1.3138  \n",
      "\n",
      "Fold: 19  Epoch: 255  Training loss = 4.7220  Validation loss = 1.3133  \n",
      "\n",
      "Fold: 19  Epoch: 256  Training loss = 4.7215  Validation loss = 1.3128  \n",
      "\n",
      "Fold: 19  Epoch: 257  Training loss = 4.7209  Validation loss = 1.3123  \n",
      "\n",
      "Fold: 19  Epoch: 258  Training loss = 4.7203  Validation loss = 1.3118  \n",
      "\n",
      "Fold: 19  Epoch: 259  Training loss = 4.7198  Validation loss = 1.3113  \n",
      "\n",
      "Fold: 19  Epoch: 260  Training loss = 4.7194  Validation loss = 1.3110  \n",
      "\n",
      "Fold: 19  Epoch: 261  Training loss = 4.7189  Validation loss = 1.3106  \n",
      "\n",
      "Fold: 19  Epoch: 262  Training loss = 4.7184  Validation loss = 1.3101  \n",
      "\n",
      "Fold: 19  Epoch: 263  Training loss = 4.7177  Validation loss = 1.3095  \n",
      "\n",
      "Fold: 19  Epoch: 264  Training loss = 4.7172  Validation loss = 1.3091  \n",
      "\n",
      "Fold: 19  Epoch: 265  Training loss = 4.7166  Validation loss = 1.3086  \n",
      "\n",
      "Fold: 19  Epoch: 266  Training loss = 4.7161  Validation loss = 1.3080  \n",
      "\n",
      "Fold: 19  Epoch: 267  Training loss = 4.7154  Validation loss = 1.3074  \n",
      "\n",
      "Fold: 19  Epoch: 268  Training loss = 4.7147  Validation loss = 1.3069  \n",
      "\n",
      "Fold: 19  Epoch: 269  Training loss = 4.7142  Validation loss = 1.3064  \n",
      "\n",
      "Fold: 19  Epoch: 270  Training loss = 4.7138  Validation loss = 1.3061  \n",
      "\n",
      "Fold: 19  Epoch: 271  Training loss = 4.7131  Validation loss = 1.3054  \n",
      "\n",
      "Fold: 19  Epoch: 272  Training loss = 4.7126  Validation loss = 1.3050  \n",
      "\n",
      "Fold: 19  Epoch: 273  Training loss = 4.7123  Validation loss = 1.3047  \n",
      "\n",
      "Fold: 19  Epoch: 274  Training loss = 4.7118  Validation loss = 1.3043  \n",
      "\n",
      "Fold: 19  Epoch: 275  Training loss = 4.7113  Validation loss = 1.3038  \n",
      "\n",
      "Fold: 19  Epoch: 276  Training loss = 4.7108  Validation loss = 1.3034  \n",
      "\n",
      "Fold: 19  Epoch: 277  Training loss = 4.7104  Validation loss = 1.3030  \n",
      "\n",
      "Fold: 19  Epoch: 278  Training loss = 4.7098  Validation loss = 1.3025  \n",
      "\n",
      "Fold: 19  Epoch: 279  Training loss = 4.7093  Validation loss = 1.3021  \n",
      "\n",
      "Fold: 19  Epoch: 280  Training loss = 4.7089  Validation loss = 1.3016  \n",
      "\n",
      "Fold: 19  Epoch: 281  Training loss = 4.7082  Validation loss = 1.3010  \n",
      "\n",
      "Fold: 19  Epoch: 282  Training loss = 4.7076  Validation loss = 1.3005  \n",
      "\n",
      "Fold: 19  Epoch: 283  Training loss = 4.7071  Validation loss = 1.3001  \n",
      "\n",
      "Fold: 19  Epoch: 284  Training loss = 4.7066  Validation loss = 1.2996  \n",
      "\n",
      "Fold: 19  Epoch: 285  Training loss = 4.7062  Validation loss = 1.2993  \n",
      "\n",
      "Fold: 19  Epoch: 286  Training loss = 4.7056  Validation loss = 1.2987  \n",
      "\n",
      "Fold: 19  Epoch: 287  Training loss = 4.7051  Validation loss = 1.2983  \n",
      "\n",
      "Fold: 19  Epoch: 288  Training loss = 4.7046  Validation loss = 1.2979  \n",
      "\n",
      "Fold: 19  Epoch: 289  Training loss = 4.7040  Validation loss = 1.2973  \n",
      "\n",
      "Fold: 19  Epoch: 290  Training loss = 4.7034  Validation loss = 1.2968  \n",
      "\n",
      "Fold: 19  Epoch: 291  Training loss = 4.7030  Validation loss = 1.2964  \n",
      "\n",
      "Fold: 19  Epoch: 292  Training loss = 4.7024  Validation loss = 1.2959  \n",
      "\n",
      "Fold: 19  Epoch: 293  Training loss = 4.7020  Validation loss = 1.2955  \n",
      "\n",
      "Fold: 19  Epoch: 294  Training loss = 4.7014  Validation loss = 1.2950  \n",
      "\n",
      "Fold: 19  Epoch: 295  Training loss = 4.7009  Validation loss = 1.2945  \n",
      "\n",
      "Fold: 19  Epoch: 296  Training loss = 4.7003  Validation loss = 1.2940  \n",
      "\n",
      "Fold: 19  Epoch: 297  Training loss = 4.6998  Validation loss = 1.2935  \n",
      "\n",
      "Fold: 19  Epoch: 298  Training loss = 4.6992  Validation loss = 1.2930  \n",
      "\n",
      "Fold: 19  Epoch: 299  Training loss = 4.6988  Validation loss = 1.2926  \n",
      "\n",
      "Fold: 19  Epoch: 300  Training loss = 4.6983  Validation loss = 1.2922  \n",
      "\n",
      "Fold: 19  Epoch: 301  Training loss = 4.6977  Validation loss = 1.2917  \n",
      "\n",
      "Fold: 19  Epoch: 302  Training loss = 4.6971  Validation loss = 1.2911  \n",
      "\n",
      "Fold: 19  Epoch: 303  Training loss = 4.6966  Validation loss = 1.2906  \n",
      "\n",
      "Fold: 19  Epoch: 304  Training loss = 4.6960  Validation loss = 1.2901  \n",
      "\n",
      "Fold: 19  Epoch: 305  Training loss = 4.6954  Validation loss = 1.2896  \n",
      "\n",
      "Fold: 19  Epoch: 306  Training loss = 4.6948  Validation loss = 1.2891  \n",
      "\n",
      "Fold: 19  Epoch: 307  Training loss = 4.6943  Validation loss = 1.2886  \n",
      "\n",
      "Fold: 19  Epoch: 308  Training loss = 4.6935  Validation loss = 1.2880  \n",
      "\n",
      "Fold: 19  Epoch: 309  Training loss = 4.6929  Validation loss = 1.2874  \n",
      "\n",
      "Fold: 19  Epoch: 310  Training loss = 4.6924  Validation loss = 1.2869  \n",
      "\n",
      "Fold: 19  Epoch: 311  Training loss = 4.6918  Validation loss = 1.2864  \n",
      "\n",
      "Fold: 19  Epoch: 312  Training loss = 4.6913  Validation loss = 1.2860  \n",
      "\n",
      "Fold: 19  Epoch: 313  Training loss = 4.6907  Validation loss = 1.2854  \n",
      "\n",
      "Fold: 19  Epoch: 314  Training loss = 4.6902  Validation loss = 1.2850  \n",
      "\n",
      "Fold: 19  Epoch: 315  Training loss = 4.6897  Validation loss = 1.2846  \n",
      "\n",
      "Fold: 19  Epoch: 316  Training loss = 4.6893  Validation loss = 1.2842  \n",
      "\n",
      "Fold: 19  Epoch: 317  Training loss = 4.6889  Validation loss = 1.2839  \n",
      "\n",
      "Fold: 19  Epoch: 318  Training loss = 4.6884  Validation loss = 1.2835  \n",
      "\n",
      "Fold: 19  Epoch: 319  Training loss = 4.6879  Validation loss = 1.2830  \n",
      "\n",
      "Fold: 19  Epoch: 320  Training loss = 4.6873  Validation loss = 1.2825  \n",
      "\n",
      "Fold: 19  Epoch: 321  Training loss = 4.6868  Validation loss = 1.2821  \n",
      "\n",
      "Fold: 19  Epoch: 322  Training loss = 4.6862  Validation loss = 1.2815  \n",
      "\n",
      "Fold: 19  Epoch: 323  Training loss = 4.6857  Validation loss = 1.2810  \n",
      "\n",
      "Fold: 19  Epoch: 324  Training loss = 4.6852  Validation loss = 1.2806  \n",
      "\n",
      "Fold: 19  Epoch: 325  Training loss = 4.6847  Validation loss = 1.2802  \n",
      "\n",
      "Fold: 19  Epoch: 326  Training loss = 4.6843  Validation loss = 1.2799  \n",
      "\n",
      "Fold: 19  Epoch: 327  Training loss = 4.6839  Validation loss = 1.2795  \n",
      "\n",
      "Fold: 19  Epoch: 328  Training loss = 4.6834  Validation loss = 1.2790  \n",
      "\n",
      "Fold: 19  Epoch: 329  Training loss = 4.6829  Validation loss = 1.2786  \n",
      "\n",
      "Fold: 19  Epoch: 330  Training loss = 4.6824  Validation loss = 1.2781  \n",
      "\n",
      "Fold: 19  Epoch: 331  Training loss = 4.6819  Validation loss = 1.2777  \n",
      "\n",
      "Fold: 19  Epoch: 332  Training loss = 4.6814  Validation loss = 1.2773  \n",
      "\n",
      "Fold: 19  Epoch: 333  Training loss = 4.6808  Validation loss = 1.2768  \n",
      "\n",
      "Fold: 19  Epoch: 334  Training loss = 4.6802  Validation loss = 1.2762  \n",
      "\n",
      "Fold: 19  Epoch: 335  Training loss = 4.6796  Validation loss = 1.2756  \n",
      "\n",
      "Fold: 19  Epoch: 336  Training loss = 4.6790  Validation loss = 1.2752  \n",
      "\n",
      "Fold: 19  Epoch: 337  Training loss = 4.6786  Validation loss = 1.2748  \n",
      "\n",
      "Fold: 19  Epoch: 338  Training loss = 4.6781  Validation loss = 1.2743  \n",
      "\n",
      "Fold: 19  Epoch: 339  Training loss = 4.6776  Validation loss = 1.2739  \n",
      "\n",
      "Fold: 19  Epoch: 340  Training loss = 4.6770  Validation loss = 1.2734  \n",
      "\n",
      "Fold: 19  Epoch: 341  Training loss = 4.6765  Validation loss = 1.2729  \n",
      "\n",
      "Fold: 19  Epoch: 342  Training loss = 4.6758  Validation loss = 1.2723  \n",
      "\n",
      "Fold: 19  Epoch: 343  Training loss = 4.6752  Validation loss = 1.2717  \n",
      "\n",
      "Fold: 19  Epoch: 344  Training loss = 4.6747  Validation loss = 1.2713  \n",
      "\n",
      "Fold: 19  Epoch: 345  Training loss = 4.6743  Validation loss = 1.2709  \n",
      "\n",
      "Fold: 19  Epoch: 346  Training loss = 4.6738  Validation loss = 1.2705  \n",
      "\n",
      "Fold: 19  Epoch: 347  Training loss = 4.6733  Validation loss = 1.2700  \n",
      "\n",
      "Fold: 19  Epoch: 348  Training loss = 4.6727  Validation loss = 1.2695  \n",
      "\n",
      "Fold: 19  Epoch: 349  Training loss = 4.6721  Validation loss = 1.2690  \n",
      "\n",
      "Fold: 19  Epoch: 350  Training loss = 4.6715  Validation loss = 1.2685  \n",
      "\n",
      "Fold: 19  Epoch: 351  Training loss = 4.6709  Validation loss = 1.2680  \n",
      "\n",
      "Fold: 19  Epoch: 352  Training loss = 4.6703  Validation loss = 1.2675  \n",
      "\n",
      "Fold: 19  Epoch: 353  Training loss = 4.6698  Validation loss = 1.2670  \n",
      "\n",
      "Fold: 19  Epoch: 354  Training loss = 4.6692  Validation loss = 1.2665  \n",
      "\n",
      "Fold: 19  Epoch: 355  Training loss = 4.6688  Validation loss = 1.2661  \n",
      "\n",
      "Fold: 19  Epoch: 356  Training loss = 4.6681  Validation loss = 1.2656  \n",
      "\n",
      "Fold: 19  Epoch: 357  Training loss = 4.6677  Validation loss = 1.2651  \n",
      "\n",
      "Fold: 19  Epoch: 358  Training loss = 4.6671  Validation loss = 1.2647  \n",
      "\n",
      "Fold: 19  Epoch: 359  Training loss = 4.6666  Validation loss = 1.2642  \n",
      "\n",
      "Fold: 19  Epoch: 360  Training loss = 4.6662  Validation loss = 1.2638  \n",
      "\n",
      "Fold: 19  Epoch: 361  Training loss = 4.6656  Validation loss = 1.2633  \n",
      "\n",
      "Fold: 19  Epoch: 362  Training loss = 4.6652  Validation loss = 1.2630  \n",
      "\n",
      "Fold: 19  Epoch: 363  Training loss = 4.6647  Validation loss = 1.2625  \n",
      "\n",
      "Fold: 19  Epoch: 364  Training loss = 4.6642  Validation loss = 1.2621  \n",
      "\n",
      "Fold: 19  Epoch: 365  Training loss = 4.6636  Validation loss = 1.2616  \n",
      "\n",
      "Fold: 19  Epoch: 366  Training loss = 4.6632  Validation loss = 1.2612  \n",
      "\n",
      "Fold: 19  Epoch: 367  Training loss = 4.6626  Validation loss = 1.2607  \n",
      "\n",
      "Fold: 19  Epoch: 368  Training loss = 4.6621  Validation loss = 1.2603  \n",
      "\n",
      "Fold: 19  Epoch: 369  Training loss = 4.6616  Validation loss = 1.2598  \n",
      "\n",
      "Fold: 19  Epoch: 370  Training loss = 4.6611  Validation loss = 1.2594  \n",
      "\n",
      "Fold: 19  Epoch: 371  Training loss = 4.6607  Validation loss = 1.2589  \n",
      "\n",
      "Fold: 19  Epoch: 372  Training loss = 4.6602  Validation loss = 1.2585  \n",
      "\n",
      "Fold: 19  Epoch: 373  Training loss = 4.6597  Validation loss = 1.2580  \n",
      "\n",
      "Fold: 19  Epoch: 374  Training loss = 4.6592  Validation loss = 1.2576  \n",
      "\n",
      "Fold: 19  Epoch: 375  Training loss = 4.6586  Validation loss = 1.2571  \n",
      "\n",
      "Fold: 19  Epoch: 376  Training loss = 4.6581  Validation loss = 1.2567  \n",
      "\n",
      "Fold: 19  Epoch: 377  Training loss = 4.6575  Validation loss = 1.2561  \n",
      "\n",
      "Fold: 19  Epoch: 378  Training loss = 4.6572  Validation loss = 1.2558  \n",
      "\n",
      "Fold: 19  Epoch: 379  Training loss = 4.6566  Validation loss = 1.2553  \n",
      "\n",
      "Fold: 19  Epoch: 380  Training loss = 4.6561  Validation loss = 1.2548  \n",
      "\n",
      "Fold: 19  Epoch: 381  Training loss = 4.6555  Validation loss = 1.2543  \n",
      "\n",
      "Fold: 19  Epoch: 382  Training loss = 4.6549  Validation loss = 1.2538  \n",
      "\n",
      "Fold: 19  Epoch: 383  Training loss = 4.6544  Validation loss = 1.2533  \n",
      "\n",
      "Fold: 19  Epoch: 384  Training loss = 4.6539  Validation loss = 1.2529  \n",
      "\n",
      "Fold: 19  Epoch: 385  Training loss = 4.6534  Validation loss = 1.2524  \n",
      "\n",
      "Fold: 19  Epoch: 386  Training loss = 4.6529  Validation loss = 1.2520  \n",
      "\n",
      "Fold: 19  Epoch: 387  Training loss = 4.6524  Validation loss = 1.2515  \n",
      "\n",
      "Fold: 19  Epoch: 388  Training loss = 4.6519  Validation loss = 1.2511  \n",
      "\n",
      "Fold: 19  Epoch: 389  Training loss = 4.6515  Validation loss = 1.2507  \n",
      "\n",
      "Fold: 19  Epoch: 390  Training loss = 4.6511  Validation loss = 1.2503  \n",
      "\n",
      "Fold: 19  Epoch: 391  Training loss = 4.6504  Validation loss = 1.2498  \n",
      "\n",
      "Fold: 19  Epoch: 392  Training loss = 4.6500  Validation loss = 1.2494  \n",
      "\n",
      "Fold: 19  Epoch: 393  Training loss = 4.6495  Validation loss = 1.2490  \n",
      "\n",
      "Fold: 19  Epoch: 394  Training loss = 4.6490  Validation loss = 1.2486  \n",
      "\n",
      "Fold: 19  Epoch: 395  Training loss = 4.6485  Validation loss = 1.2481  \n",
      "\n",
      "Fold: 19  Epoch: 396  Training loss = 4.6479  Validation loss = 1.2476  \n",
      "\n",
      "Fold: 19  Epoch: 397  Training loss = 4.6473  Validation loss = 1.2470  \n",
      "\n",
      "Fold: 19  Epoch: 398  Training loss = 4.6468  Validation loss = 1.2466  \n",
      "\n",
      "Fold: 19  Epoch: 399  Training loss = 4.6463  Validation loss = 1.2462  \n",
      "\n",
      "Fold: 19  Epoch: 400  Training loss = 4.6459  Validation loss = 1.2458  \n",
      "\n",
      "Fold: 19  Epoch: 401  Training loss = 4.6453  Validation loss = 1.2453  \n",
      "\n",
      "Fold: 19  Epoch: 402  Training loss = 4.6448  Validation loss = 1.2449  \n",
      "\n",
      "Fold: 19  Epoch: 403  Training loss = 4.6442  Validation loss = 1.2444  \n",
      "\n",
      "Fold: 19  Epoch: 404  Training loss = 4.6437  Validation loss = 1.2439  \n",
      "\n",
      "Fold: 19  Epoch: 405  Training loss = 4.6431  Validation loss = 1.2434  \n",
      "\n",
      "Fold: 19  Epoch: 406  Training loss = 4.6426  Validation loss = 1.2429  \n",
      "\n",
      "Fold: 19  Epoch: 407  Training loss = 4.6421  Validation loss = 1.2425  \n",
      "\n",
      "Fold: 19  Epoch: 408  Training loss = 4.6416  Validation loss = 1.2421  \n",
      "\n",
      "Fold: 19  Epoch: 409  Training loss = 4.6411  Validation loss = 1.2416  \n",
      "\n",
      "Fold: 19  Epoch: 410  Training loss = 4.6405  Validation loss = 1.2411  \n",
      "\n",
      "Fold: 19  Epoch: 411  Training loss = 4.6401  Validation loss = 1.2407  \n",
      "\n",
      "Fold: 19  Epoch: 412  Training loss = 4.6396  Validation loss = 1.2403  \n",
      "\n",
      "Fold: 19  Epoch: 413  Training loss = 4.6392  Validation loss = 1.2399  \n",
      "\n",
      "Fold: 19  Epoch: 414  Training loss = 4.6387  Validation loss = 1.2395  \n",
      "\n",
      "Fold: 19  Epoch: 415  Training loss = 4.6382  Validation loss = 1.2391  \n",
      "\n",
      "Fold: 19  Epoch: 416  Training loss = 4.6377  Validation loss = 1.2386  \n",
      "\n",
      "Fold: 19  Epoch: 417  Training loss = 4.6372  Validation loss = 1.2383  \n",
      "\n",
      "Fold: 19  Epoch: 418  Training loss = 4.6366  Validation loss = 1.2377  \n",
      "\n",
      "Fold: 19  Epoch: 419  Training loss = 4.6361  Validation loss = 1.2372  \n",
      "\n",
      "Fold: 19  Epoch: 420  Training loss = 4.6356  Validation loss = 1.2368  \n",
      "\n",
      "Fold: 19  Epoch: 421  Training loss = 4.6350  Validation loss = 1.2363  \n",
      "\n",
      "Fold: 19  Epoch: 422  Training loss = 4.6344  Validation loss = 1.2358  \n",
      "\n",
      "Fold: 19  Epoch: 423  Training loss = 4.6340  Validation loss = 1.2355  \n",
      "\n",
      "Fold: 19  Epoch: 424  Training loss = 4.6334  Validation loss = 1.2349  \n",
      "\n",
      "Fold: 19  Epoch: 425  Training loss = 4.6329  Validation loss = 1.2345  \n",
      "\n",
      "Fold: 19  Epoch: 426  Training loss = 4.6325  Validation loss = 1.2341  \n",
      "\n",
      "Fold: 19  Epoch: 427  Training loss = 4.6320  Validation loss = 1.2337  \n",
      "\n",
      "Fold: 19  Epoch: 428  Training loss = 4.6315  Validation loss = 1.2333  \n",
      "\n",
      "Fold: 19  Epoch: 429  Training loss = 4.6310  Validation loss = 1.2329  \n",
      "\n",
      "Fold: 19  Epoch: 430  Training loss = 4.6304  Validation loss = 1.2323  \n",
      "\n",
      "Fold: 19  Epoch: 431  Training loss = 4.6298  Validation loss = 1.2318  \n",
      "\n",
      "Fold: 19  Epoch: 432  Training loss = 4.6294  Validation loss = 1.2315  \n",
      "\n",
      "Fold: 19  Epoch: 433  Training loss = 4.6289  Validation loss = 1.2310  \n",
      "\n",
      "Fold: 19  Epoch: 434  Training loss = 4.6284  Validation loss = 1.2306  \n",
      "\n",
      "Fold: 19  Epoch: 435  Training loss = 4.6280  Validation loss = 1.2302  \n",
      "\n",
      "Fold: 19  Epoch: 436  Training loss = 4.6274  Validation loss = 1.2297  \n",
      "\n",
      "Fold: 19  Epoch: 437  Training loss = 4.6270  Validation loss = 1.2293  \n",
      "\n",
      "Fold: 19  Epoch: 438  Training loss = 4.6265  Validation loss = 1.2288  \n",
      "\n",
      "Fold: 19  Epoch: 439  Training loss = 4.6258  Validation loss = 1.2283  \n",
      "\n",
      "Fold: 19  Epoch: 440  Training loss = 4.6254  Validation loss = 1.2279  \n",
      "\n",
      "Fold: 19  Epoch: 441  Training loss = 4.6249  Validation loss = 1.2274  \n",
      "\n",
      "Fold: 19  Epoch: 442  Training loss = 4.6244  Validation loss = 1.2270  \n",
      "\n",
      "Fold: 19  Epoch: 443  Training loss = 4.6239  Validation loss = 1.2266  \n",
      "\n",
      "Fold: 19  Epoch: 444  Training loss = 4.6234  Validation loss = 1.2261  \n",
      "\n",
      "Fold: 19  Epoch: 445  Training loss = 4.6230  Validation loss = 1.2257  \n",
      "\n",
      "Fold: 19  Epoch: 446  Training loss = 4.6226  Validation loss = 1.2254  \n",
      "\n",
      "Fold: 19  Epoch: 447  Training loss = 4.6221  Validation loss = 1.2249  \n",
      "\n",
      "Fold: 19  Epoch: 448  Training loss = 4.6216  Validation loss = 1.2245  \n",
      "\n",
      "Fold: 19  Epoch: 449  Training loss = 4.6211  Validation loss = 1.2241  \n",
      "\n",
      "Fold: 19  Epoch: 450  Training loss = 4.6207  Validation loss = 1.2237  \n",
      "\n",
      "Fold: 19  Epoch: 451  Training loss = 4.6203  Validation loss = 1.2234  \n",
      "\n",
      "Fold: 19  Epoch: 452  Training loss = 4.6198  Validation loss = 1.2230  \n",
      "\n",
      "Fold: 19  Epoch: 453  Training loss = 4.6193  Validation loss = 1.2225  \n",
      "\n",
      "Fold: 19  Epoch: 454  Training loss = 4.6188  Validation loss = 1.2221  \n",
      "\n",
      "Fold: 19  Epoch: 455  Training loss = 4.6183  Validation loss = 1.2216  \n",
      "\n",
      "Fold: 19  Epoch: 456  Training loss = 4.6178  Validation loss = 1.2212  \n",
      "\n",
      "Fold: 19  Epoch: 457  Training loss = 4.6174  Validation loss = 1.2209  \n",
      "\n",
      "Fold: 19  Epoch: 458  Training loss = 4.6170  Validation loss = 1.2205  \n",
      "\n",
      "Fold: 19  Epoch: 459  Training loss = 4.6166  Validation loss = 1.2201  \n",
      "\n",
      "Fold: 19  Epoch: 460  Training loss = 4.6162  Validation loss = 1.2198  \n",
      "\n",
      "Fold: 19  Epoch: 461  Training loss = 4.6158  Validation loss = 1.2194  \n",
      "\n",
      "Fold: 19  Epoch: 462  Training loss = 4.6154  Validation loss = 1.2191  \n",
      "\n",
      "Fold: 19  Epoch: 463  Training loss = 4.6148  Validation loss = 1.2186  \n",
      "\n",
      "Fold: 19  Epoch: 464  Training loss = 4.6143  Validation loss = 1.2181  \n",
      "\n",
      "Fold: 19  Epoch: 465  Training loss = 4.6137  Validation loss = 1.2176  \n",
      "\n",
      "Fold: 19  Epoch: 466  Training loss = 4.6132  Validation loss = 1.2172  \n",
      "\n",
      "Fold: 19  Epoch: 467  Training loss = 4.6127  Validation loss = 1.2168  \n",
      "\n",
      "Fold: 19  Epoch: 468  Training loss = 4.6122  Validation loss = 1.2164  \n",
      "\n",
      "Fold: 19  Epoch: 469  Training loss = 4.6117  Validation loss = 1.2159  \n",
      "\n",
      "Fold: 19  Epoch: 470  Training loss = 4.6113  Validation loss = 1.2156  \n",
      "\n",
      "Fold: 19  Epoch: 471  Training loss = 4.6108  Validation loss = 1.2151  \n",
      "\n",
      "Fold: 19  Epoch: 472  Training loss = 4.6102  Validation loss = 1.2147  \n",
      "\n",
      "Fold: 19  Epoch: 473  Training loss = 4.6098  Validation loss = 1.2143  \n",
      "\n",
      "Fold: 19  Epoch: 474  Training loss = 4.6093  Validation loss = 1.2139  \n",
      "\n",
      "Fold: 19  Epoch: 475  Training loss = 4.6088  Validation loss = 1.2134  \n",
      "\n",
      "Fold: 19  Epoch: 476  Training loss = 4.6084  Validation loss = 1.2130  \n",
      "\n",
      "Fold: 19  Epoch: 477  Training loss = 4.6079  Validation loss = 1.2126  \n",
      "\n",
      "Fold: 19  Epoch: 478  Training loss = 4.6075  Validation loss = 1.2123  \n",
      "\n",
      "Fold: 19  Epoch: 479  Training loss = 4.6071  Validation loss = 1.2119  \n",
      "\n",
      "Fold: 19  Epoch: 480  Training loss = 4.6064  Validation loss = 1.2114  \n",
      "\n",
      "Fold: 19  Epoch: 481  Training loss = 4.6060  Validation loss = 1.2110  \n",
      "\n",
      "Fold: 19  Epoch: 482  Training loss = 4.6054  Validation loss = 1.2105  \n",
      "\n",
      "Fold: 19  Epoch: 483  Training loss = 4.6049  Validation loss = 1.2101  \n",
      "\n",
      "Fold: 19  Epoch: 484  Training loss = 4.6044  Validation loss = 1.2097  \n",
      "\n",
      "Fold: 19  Epoch: 485  Training loss = 4.6039  Validation loss = 1.2092  \n",
      "\n",
      "Fold: 19  Epoch: 486  Training loss = 4.6033  Validation loss = 1.2087  \n",
      "\n",
      "Fold: 19  Epoch: 487  Training loss = 4.6027  Validation loss = 1.2082  \n",
      "\n",
      "Fold: 19  Epoch: 488  Training loss = 4.6022  Validation loss = 1.2077  \n",
      "\n",
      "Fold: 19  Epoch: 489  Training loss = 4.6015  Validation loss = 1.2072  \n",
      "\n",
      "Fold: 19  Epoch: 490  Training loss = 4.6010  Validation loss = 1.2067  \n",
      "\n",
      "Fold: 19  Epoch: 491  Training loss = 4.6006  Validation loss = 1.2063  \n",
      "\n",
      "Fold: 19  Epoch: 492  Training loss = 4.6000  Validation loss = 1.2058  \n",
      "\n",
      "Fold: 19  Epoch: 493  Training loss = 4.5995  Validation loss = 1.2054  \n",
      "\n",
      "Fold: 19  Epoch: 494  Training loss = 4.5990  Validation loss = 1.2049  \n",
      "\n",
      "Fold: 19  Epoch: 495  Training loss = 4.5986  Validation loss = 1.2046  \n",
      "\n",
      "Fold: 19  Epoch: 496  Training loss = 4.5980  Validation loss = 1.2041  \n",
      "\n",
      "Fold: 19  Epoch: 497  Training loss = 4.5976  Validation loss = 1.2037  \n",
      "\n",
      "Fold: 19  Epoch: 498  Training loss = 4.5970  Validation loss = 1.2033  \n",
      "\n",
      "Fold: 19  Epoch: 499  Training loss = 4.5965  Validation loss = 1.2028  \n",
      "\n",
      "Fold: 19  Epoch: 500  Training loss = 4.5959  Validation loss = 1.2023  \n",
      "\n",
      "Check model:  Fold: 19  Optimal epoch: 500  \n",
      "\n",
      "Fold: 20  Epoch: 1  Training loss = 4.5995  Validation loss = 0.3691  \n",
      "\n",
      "Fold: 20  Epoch: 2  Training loss = 4.5990  Validation loss = 0.3695  \n",
      "\n",
      "Fold: 20  Epoch: 3  Training loss = 4.5986  Validation loss = 0.3699  \n",
      "\n",
      "Fold: 20  Epoch: 4  Training loss = 4.5981  Validation loss = 0.3703  \n",
      "\n",
      "Fold: 20  Epoch: 5  Training loss = 4.5975  Validation loss = 0.3708  \n",
      "\n",
      "Fold: 20  Epoch: 6  Training loss = 4.5970  Validation loss = 0.3711  \n",
      "\n",
      "Fold: 20  Epoch: 7  Training loss = 4.5965  Validation loss = 0.3715  \n",
      "\n",
      "Fold: 20  Epoch: 8  Training loss = 4.5961  Validation loss = 0.3719  \n",
      "\n",
      "Fold: 20  Epoch: 9  Training loss = 4.5955  Validation loss = 0.3723  \n",
      "\n",
      "Fold: 20  Epoch: 10  Training loss = 4.5950  Validation loss = 0.3727  \n",
      "\n",
      "Fold: 20  Epoch: 11  Training loss = 4.5946  Validation loss = 0.3731  \n",
      "\n",
      "Check model:  Fold: 20  Optimal epoch: 1  \n",
      "\n",
      "Fold: 21  Epoch: 1  Training loss = 4.5748  Validation loss = 2.1516  \n",
      "\n",
      "Fold: 21  Epoch: 2  Training loss = 4.5743  Validation loss = 2.1520  \n",
      "\n",
      "Fold: 21  Epoch: 3  Training loss = 4.5738  Validation loss = 2.1523  \n",
      "\n",
      "Fold: 21  Epoch: 4  Training loss = 4.5733  Validation loss = 2.1525  \n",
      "\n",
      "Fold: 21  Epoch: 5  Training loss = 4.5729  Validation loss = 2.1528  \n",
      "\n",
      "Fold: 21  Epoch: 6  Training loss = 4.5725  Validation loss = 2.1531  \n",
      "\n",
      "Fold: 21  Epoch: 7  Training loss = 4.5720  Validation loss = 2.1534  \n",
      "\n",
      "Fold: 21  Epoch: 8  Training loss = 4.5716  Validation loss = 2.1537  \n",
      "\n",
      "Fold: 21  Epoch: 9  Training loss = 4.5711  Validation loss = 2.1539  \n",
      "\n",
      "Fold: 21  Epoch: 10  Training loss = 4.5707  Validation loss = 2.1542  \n",
      "\n",
      "Fold: 21  Epoch: 11  Training loss = 4.5702  Validation loss = 2.1545  \n",
      "\n",
      "Check model:  Fold: 21  Optimal epoch: 1  \n",
      "\n",
      "Fold: 22  Epoch: 1  Training loss = 4.5713  Validation loss = 1.3527  \n",
      "\n",
      "Fold: 22  Epoch: 2  Training loss = 4.5708  Validation loss = 1.3522  \n",
      "\n",
      "Fold: 22  Epoch: 3  Training loss = 4.5703  Validation loss = 1.3517  \n",
      "\n",
      "Fold: 22  Epoch: 4  Training loss = 4.5700  Validation loss = 1.3514  \n",
      "\n",
      "Fold: 22  Epoch: 5  Training loss = 4.5695  Validation loss = 1.3510  \n",
      "\n",
      "Fold: 22  Epoch: 6  Training loss = 4.5690  Validation loss = 1.3505  \n",
      "\n",
      "Fold: 22  Epoch: 7  Training loss = 4.5685  Validation loss = 1.3502  \n",
      "\n",
      "Fold: 22  Epoch: 8  Training loss = 4.5681  Validation loss = 1.3498  \n",
      "\n",
      "Fold: 22  Epoch: 9  Training loss = 4.5678  Validation loss = 1.3495  \n",
      "\n",
      "Fold: 22  Epoch: 10  Training loss = 4.5674  Validation loss = 1.3491  \n",
      "\n",
      "Fold: 22  Epoch: 11  Training loss = 4.5670  Validation loss = 1.3488  \n",
      "\n",
      "Fold: 22  Epoch: 12  Training loss = 4.5665  Validation loss = 1.3483  \n",
      "\n",
      "Fold: 22  Epoch: 13  Training loss = 4.5661  Validation loss = 1.3480  \n",
      "\n",
      "Fold: 22  Epoch: 14  Training loss = 4.5658  Validation loss = 1.3477  \n",
      "\n",
      "Fold: 22  Epoch: 15  Training loss = 4.5653  Validation loss = 1.3473  \n",
      "\n",
      "Fold: 22  Epoch: 16  Training loss = 4.5648  Validation loss = 1.3468  \n",
      "\n",
      "Fold: 22  Epoch: 17  Training loss = 4.5644  Validation loss = 1.3465  \n",
      "\n",
      "Fold: 22  Epoch: 18  Training loss = 4.5641  Validation loss = 1.3461  \n",
      "\n",
      "Fold: 22  Epoch: 19  Training loss = 4.5637  Validation loss = 1.3458  \n",
      "\n",
      "Fold: 22  Epoch: 20  Training loss = 4.5632  Validation loss = 1.3454  \n",
      "\n",
      "Fold: 22  Epoch: 21  Training loss = 4.5628  Validation loss = 1.3449  \n",
      "\n",
      "Fold: 22  Epoch: 22  Training loss = 4.5623  Validation loss = 1.3444  \n",
      "\n",
      "Fold: 22  Epoch: 23  Training loss = 4.5619  Validation loss = 1.3441  \n",
      "\n",
      "Fold: 22  Epoch: 24  Training loss = 4.5617  Validation loss = 1.3439  \n",
      "\n",
      "Fold: 22  Epoch: 25  Training loss = 4.5612  Validation loss = 1.3435  \n",
      "\n",
      "Fold: 22  Epoch: 26  Training loss = 4.5608  Validation loss = 1.3430  \n",
      "\n",
      "Fold: 22  Epoch: 27  Training loss = 4.5604  Validation loss = 1.3428  \n",
      "\n",
      "Fold: 22  Epoch: 28  Training loss = 4.5600  Validation loss = 1.3424  \n",
      "\n",
      "Fold: 22  Epoch: 29  Training loss = 4.5596  Validation loss = 1.3420  \n",
      "\n",
      "Fold: 22  Epoch: 30  Training loss = 4.5592  Validation loss = 1.3417  \n",
      "\n",
      "Fold: 22  Epoch: 31  Training loss = 4.5587  Validation loss = 1.3412  \n",
      "\n",
      "Fold: 22  Epoch: 32  Training loss = 4.5582  Validation loss = 1.3408  \n",
      "\n",
      "Fold: 22  Epoch: 33  Training loss = 4.5579  Validation loss = 1.3405  \n",
      "\n",
      "Fold: 22  Epoch: 34  Training loss = 4.5574  Validation loss = 1.3401  \n",
      "\n",
      "Fold: 22  Epoch: 35  Training loss = 4.5569  Validation loss = 1.3396  \n",
      "\n",
      "Fold: 22  Epoch: 36  Training loss = 4.5565  Validation loss = 1.3393  \n",
      "\n",
      "Fold: 22  Epoch: 37  Training loss = 4.5560  Validation loss = 1.3388  \n",
      "\n",
      "Fold: 22  Epoch: 38  Training loss = 4.5557  Validation loss = 1.3385  \n",
      "\n",
      "Fold: 22  Epoch: 39  Training loss = 4.5554  Validation loss = 1.3382  \n",
      "\n",
      "Fold: 22  Epoch: 40  Training loss = 4.5550  Validation loss = 1.3379  \n",
      "\n",
      "Fold: 22  Epoch: 41  Training loss = 4.5546  Validation loss = 1.3375  \n",
      "\n",
      "Fold: 22  Epoch: 42  Training loss = 4.5542  Validation loss = 1.3371  \n",
      "\n",
      "Fold: 22  Epoch: 43  Training loss = 4.5538  Validation loss = 1.3368  \n",
      "\n",
      "Fold: 22  Epoch: 44  Training loss = 4.5534  Validation loss = 1.3365  \n",
      "\n",
      "Fold: 22  Epoch: 45  Training loss = 4.5530  Validation loss = 1.3360  \n",
      "\n",
      "Fold: 22  Epoch: 46  Training loss = 4.5525  Validation loss = 1.3356  \n",
      "\n",
      "Fold: 22  Epoch: 47  Training loss = 4.5521  Validation loss = 1.3352  \n",
      "\n",
      "Fold: 22  Epoch: 48  Training loss = 4.5516  Validation loss = 1.3347  \n",
      "\n",
      "Fold: 22  Epoch: 49  Training loss = 4.5512  Validation loss = 1.3344  \n",
      "\n",
      "Fold: 22  Epoch: 50  Training loss = 4.5509  Validation loss = 1.3341  \n",
      "\n",
      "Fold: 22  Epoch: 51  Training loss = 4.5505  Validation loss = 1.3337  \n",
      "\n",
      "Fold: 22  Epoch: 52  Training loss = 4.5501  Validation loss = 1.3334  \n",
      "\n",
      "Fold: 22  Epoch: 53  Training loss = 4.5498  Validation loss = 1.3331  \n",
      "\n",
      "Fold: 22  Epoch: 54  Training loss = 4.5494  Validation loss = 1.3328  \n",
      "\n",
      "Fold: 22  Epoch: 55  Training loss = 4.5490  Validation loss = 1.3324  \n",
      "\n",
      "Fold: 22  Epoch: 56  Training loss = 4.5485  Validation loss = 1.3320  \n",
      "\n",
      "Fold: 22  Epoch: 57  Training loss = 4.5481  Validation loss = 1.3316  \n",
      "\n",
      "Fold: 22  Epoch: 58  Training loss = 4.5477  Validation loss = 1.3312  \n",
      "\n",
      "Fold: 22  Epoch: 59  Training loss = 4.5472  Validation loss = 1.3308  \n",
      "\n",
      "Fold: 22  Epoch: 60  Training loss = 4.5467  Validation loss = 1.3304  \n",
      "\n",
      "Fold: 22  Epoch: 61  Training loss = 4.5464  Validation loss = 1.3301  \n",
      "\n",
      "Fold: 22  Epoch: 62  Training loss = 4.5459  Validation loss = 1.3297  \n",
      "\n",
      "Fold: 22  Epoch: 63  Training loss = 4.5453  Validation loss = 1.3292  \n",
      "\n",
      "Fold: 22  Epoch: 64  Training loss = 4.5449  Validation loss = 1.3288  \n",
      "\n",
      "Fold: 22  Epoch: 65  Training loss = 4.5445  Validation loss = 1.3284  \n",
      "\n",
      "Fold: 22  Epoch: 66  Training loss = 4.5440  Validation loss = 1.3280  \n",
      "\n",
      "Fold: 22  Epoch: 67  Training loss = 4.5436  Validation loss = 1.3277  \n",
      "\n",
      "Fold: 22  Epoch: 68  Training loss = 4.5432  Validation loss = 1.3273  \n",
      "\n",
      "Fold: 22  Epoch: 69  Training loss = 4.5429  Validation loss = 1.3270  \n",
      "\n",
      "Fold: 22  Epoch: 70  Training loss = 4.5426  Validation loss = 1.3267  \n",
      "\n",
      "Fold: 22  Epoch: 71  Training loss = 4.5422  Validation loss = 1.3264  \n",
      "\n",
      "Fold: 22  Epoch: 72  Training loss = 4.5418  Validation loss = 1.3260  \n",
      "\n",
      "Fold: 22  Epoch: 73  Training loss = 4.5415  Validation loss = 1.3257  \n",
      "\n",
      "Fold: 22  Epoch: 74  Training loss = 4.5411  Validation loss = 1.3254  \n",
      "\n",
      "Fold: 22  Epoch: 75  Training loss = 4.5408  Validation loss = 1.3251  \n",
      "\n",
      "Fold: 22  Epoch: 76  Training loss = 4.5404  Validation loss = 1.3248  \n",
      "\n",
      "Fold: 22  Epoch: 77  Training loss = 4.5401  Validation loss = 1.3245  \n",
      "\n",
      "Fold: 22  Epoch: 78  Training loss = 4.5397  Validation loss = 1.3241  \n",
      "\n",
      "Fold: 22  Epoch: 79  Training loss = 4.5392  Validation loss = 1.3237  \n",
      "\n",
      "Fold: 22  Epoch: 80  Training loss = 4.5388  Validation loss = 1.3234  \n",
      "\n",
      "Fold: 22  Epoch: 81  Training loss = 4.5384  Validation loss = 1.3230  \n",
      "\n",
      "Fold: 22  Epoch: 82  Training loss = 4.5381  Validation loss = 1.3227  \n",
      "\n",
      "Fold: 22  Epoch: 83  Training loss = 4.5376  Validation loss = 1.3224  \n",
      "\n",
      "Fold: 22  Epoch: 84  Training loss = 4.5371  Validation loss = 1.3219  \n",
      "\n",
      "Fold: 22  Epoch: 85  Training loss = 4.5366  Validation loss = 1.3216  \n",
      "\n",
      "Fold: 22  Epoch: 86  Training loss = 4.5362  Validation loss = 1.3212  \n",
      "\n",
      "Fold: 22  Epoch: 87  Training loss = 4.5359  Validation loss = 1.3210  \n",
      "\n",
      "Fold: 22  Epoch: 88  Training loss = 4.5354  Validation loss = 1.3206  \n",
      "\n",
      "Fold: 22  Epoch: 89  Training loss = 4.5350  Validation loss = 1.3202  \n",
      "\n",
      "Fold: 22  Epoch: 90  Training loss = 4.5346  Validation loss = 1.3199  \n",
      "\n",
      "Fold: 22  Epoch: 91  Training loss = 4.5344  Validation loss = 1.3197  \n",
      "\n",
      "Fold: 22  Epoch: 92  Training loss = 4.5340  Validation loss = 1.3193  \n",
      "\n",
      "Fold: 22  Epoch: 93  Training loss = 4.5335  Validation loss = 1.3189  \n",
      "\n",
      "Fold: 22  Epoch: 94  Training loss = 4.5332  Validation loss = 1.3186  \n",
      "\n",
      "Fold: 22  Epoch: 95  Training loss = 4.5328  Validation loss = 1.3183  \n",
      "\n",
      "Fold: 22  Epoch: 96  Training loss = 4.5324  Validation loss = 1.3180  \n",
      "\n",
      "Fold: 22  Epoch: 97  Training loss = 4.5320  Validation loss = 1.3177  \n",
      "\n",
      "Fold: 22  Epoch: 98  Training loss = 4.5316  Validation loss = 1.3173  \n",
      "\n",
      "Fold: 22  Epoch: 99  Training loss = 4.5312  Validation loss = 1.3169  \n",
      "\n",
      "Fold: 22  Epoch: 100  Training loss = 4.5307  Validation loss = 1.3165  \n",
      "\n",
      "Fold: 22  Epoch: 101  Training loss = 4.5304  Validation loss = 1.3162  \n",
      "\n",
      "Fold: 22  Epoch: 102  Training loss = 4.5299  Validation loss = 1.3158  \n",
      "\n",
      "Fold: 22  Epoch: 103  Training loss = 4.5295  Validation loss = 1.3155  \n",
      "\n",
      "Fold: 22  Epoch: 104  Training loss = 4.5291  Validation loss = 1.3152  \n",
      "\n",
      "Fold: 22  Epoch: 105  Training loss = 4.5287  Validation loss = 1.3149  \n",
      "\n",
      "Fold: 22  Epoch: 106  Training loss = 4.5283  Validation loss = 1.3145  \n",
      "\n",
      "Fold: 22  Epoch: 107  Training loss = 4.5279  Validation loss = 1.3142  \n",
      "\n",
      "Fold: 22  Epoch: 108  Training loss = 4.5276  Validation loss = 1.3139  \n",
      "\n",
      "Fold: 22  Epoch: 109  Training loss = 4.5272  Validation loss = 1.3135  \n",
      "\n",
      "Fold: 22  Epoch: 110  Training loss = 4.5269  Validation loss = 1.3133  \n",
      "\n",
      "Fold: 22  Epoch: 111  Training loss = 4.5265  Validation loss = 1.3129  \n",
      "\n",
      "Fold: 22  Epoch: 112  Training loss = 4.5260  Validation loss = 1.3126  \n",
      "\n",
      "Fold: 22  Epoch: 113  Training loss = 4.5256  Validation loss = 1.3122  \n",
      "\n",
      "Fold: 22  Epoch: 114  Training loss = 4.5253  Validation loss = 1.3120  \n",
      "\n",
      "Fold: 22  Epoch: 115  Training loss = 4.5249  Validation loss = 1.3116  \n",
      "\n",
      "Fold: 22  Epoch: 116  Training loss = 4.5246  Validation loss = 1.3113  \n",
      "\n",
      "Fold: 22  Epoch: 117  Training loss = 4.5242  Validation loss = 1.3109  \n",
      "\n",
      "Fold: 22  Epoch: 118  Training loss = 4.5238  Validation loss = 1.3105  \n",
      "\n",
      "Fold: 22  Epoch: 119  Training loss = 4.5233  Validation loss = 1.3101  \n",
      "\n",
      "Fold: 22  Epoch: 120  Training loss = 4.5229  Validation loss = 1.3098  \n",
      "\n",
      "Fold: 22  Epoch: 121  Training loss = 4.5225  Validation loss = 1.3094  \n",
      "\n",
      "Fold: 22  Epoch: 122  Training loss = 4.5222  Validation loss = 1.3091  \n",
      "\n",
      "Fold: 22  Epoch: 123  Training loss = 4.5217  Validation loss = 1.3087  \n",
      "\n",
      "Fold: 22  Epoch: 124  Training loss = 4.5213  Validation loss = 1.3083  \n",
      "\n",
      "Fold: 22  Epoch: 125  Training loss = 4.5209  Validation loss = 1.3080  \n",
      "\n",
      "Fold: 22  Epoch: 126  Training loss = 4.5205  Validation loss = 1.3076  \n",
      "\n",
      "Fold: 22  Epoch: 127  Training loss = 4.5200  Validation loss = 1.3072  \n",
      "\n",
      "Fold: 22  Epoch: 128  Training loss = 4.5196  Validation loss = 1.3069  \n",
      "\n",
      "Fold: 22  Epoch: 129  Training loss = 4.5191  Validation loss = 1.3065  \n",
      "\n",
      "Fold: 22  Epoch: 130  Training loss = 4.5189  Validation loss = 1.3063  \n",
      "\n",
      "Fold: 22  Epoch: 131  Training loss = 4.5185  Validation loss = 1.3060  \n",
      "\n",
      "Fold: 22  Epoch: 132  Training loss = 4.5180  Validation loss = 1.3056  \n",
      "\n",
      "Fold: 22  Epoch: 133  Training loss = 4.5176  Validation loss = 1.3052  \n",
      "\n",
      "Fold: 22  Epoch: 134  Training loss = 4.5173  Validation loss = 1.3049  \n",
      "\n",
      "Fold: 22  Epoch: 135  Training loss = 4.5170  Validation loss = 1.3046  \n",
      "\n",
      "Fold: 22  Epoch: 136  Training loss = 4.5165  Validation loss = 1.3042  \n",
      "\n",
      "Fold: 22  Epoch: 137  Training loss = 4.5162  Validation loss = 1.3039  \n",
      "\n",
      "Fold: 22  Epoch: 138  Training loss = 4.5157  Validation loss = 1.3035  \n",
      "\n",
      "Fold: 22  Epoch: 139  Training loss = 4.5154  Validation loss = 1.3032  \n",
      "\n",
      "Fold: 22  Epoch: 140  Training loss = 4.5149  Validation loss = 1.3027  \n",
      "\n",
      "Fold: 22  Epoch: 141  Training loss = 4.5145  Validation loss = 1.3024  \n",
      "\n",
      "Fold: 22  Epoch: 142  Training loss = 4.5141  Validation loss = 1.3020  \n",
      "\n",
      "Fold: 22  Epoch: 143  Training loss = 4.5137  Validation loss = 1.3017  \n",
      "\n",
      "Fold: 22  Epoch: 144  Training loss = 4.5133  Validation loss = 1.3013  \n",
      "\n",
      "Fold: 22  Epoch: 145  Training loss = 4.5129  Validation loss = 1.3011  \n",
      "\n",
      "Fold: 22  Epoch: 146  Training loss = 4.5126  Validation loss = 1.3008  \n",
      "\n",
      "Fold: 22  Epoch: 147  Training loss = 4.5122  Validation loss = 1.3004  \n",
      "\n",
      "Fold: 22  Epoch: 148  Training loss = 4.5118  Validation loss = 1.3001  \n",
      "\n",
      "Fold: 22  Epoch: 149  Training loss = 4.5113  Validation loss = 1.2997  \n",
      "\n",
      "Fold: 22  Epoch: 150  Training loss = 4.5108  Validation loss = 1.2993  \n",
      "\n",
      "Fold: 22  Epoch: 151  Training loss = 4.5104  Validation loss = 1.2989  \n",
      "\n",
      "Fold: 22  Epoch: 152  Training loss = 4.5100  Validation loss = 1.2987  \n",
      "\n",
      "Fold: 22  Epoch: 153  Training loss = 4.5095  Validation loss = 1.2983  \n",
      "\n",
      "Fold: 22  Epoch: 154  Training loss = 4.5091  Validation loss = 1.2979  \n",
      "\n",
      "Fold: 22  Epoch: 155  Training loss = 4.5087  Validation loss = 1.2975  \n",
      "\n",
      "Fold: 22  Epoch: 156  Training loss = 4.5083  Validation loss = 1.2971  \n",
      "\n",
      "Fold: 22  Epoch: 157  Training loss = 4.5078  Validation loss = 1.2967  \n",
      "\n",
      "Fold: 22  Epoch: 158  Training loss = 4.5074  Validation loss = 1.2963  \n",
      "\n",
      "Fold: 22  Epoch: 159  Training loss = 4.5069  Validation loss = 1.2959  \n",
      "\n",
      "Fold: 22  Epoch: 160  Training loss = 4.5065  Validation loss = 1.2956  \n",
      "\n",
      "Fold: 22  Epoch: 161  Training loss = 4.5061  Validation loss = 1.2953  \n",
      "\n",
      "Fold: 22  Epoch: 162  Training loss = 4.5057  Validation loss = 1.2950  \n",
      "\n",
      "Fold: 22  Epoch: 163  Training loss = 4.5055  Validation loss = 1.2947  \n",
      "\n",
      "Fold: 22  Epoch: 164  Training loss = 4.5050  Validation loss = 1.2944  \n",
      "\n",
      "Fold: 22  Epoch: 165  Training loss = 4.5046  Validation loss = 1.2940  \n",
      "\n",
      "Fold: 22  Epoch: 166  Training loss = 4.5043  Validation loss = 1.2937  \n",
      "\n",
      "Fold: 22  Epoch: 167  Training loss = 4.5038  Validation loss = 1.2934  \n",
      "\n",
      "Fold: 22  Epoch: 168  Training loss = 4.5035  Validation loss = 1.2931  \n",
      "\n",
      "Fold: 22  Epoch: 169  Training loss = 4.5031  Validation loss = 1.2927  \n",
      "\n",
      "Fold: 22  Epoch: 170  Training loss = 4.5026  Validation loss = 1.2922  \n",
      "\n",
      "Fold: 22  Epoch: 171  Training loss = 4.5022  Validation loss = 1.2919  \n",
      "\n",
      "Fold: 22  Epoch: 172  Training loss = 4.5018  Validation loss = 1.2916  \n",
      "\n",
      "Fold: 22  Epoch: 173  Training loss = 4.5014  Validation loss = 1.2913  \n",
      "\n",
      "Fold: 22  Epoch: 174  Training loss = 4.5009  Validation loss = 1.2909  \n",
      "\n",
      "Fold: 22  Epoch: 175  Training loss = 4.5004  Validation loss = 1.2905  \n",
      "\n",
      "Fold: 22  Epoch: 176  Training loss = 4.5002  Validation loss = 1.2903  \n",
      "\n",
      "Fold: 22  Epoch: 177  Training loss = 4.4998  Validation loss = 1.2900  \n",
      "\n",
      "Fold: 22  Epoch: 178  Training loss = 4.4995  Validation loss = 1.2897  \n",
      "\n",
      "Fold: 22  Epoch: 179  Training loss = 4.4991  Validation loss = 1.2894  \n",
      "\n",
      "Fold: 22  Epoch: 180  Training loss = 4.4987  Validation loss = 1.2890  \n",
      "\n",
      "Fold: 22  Epoch: 181  Training loss = 4.4983  Validation loss = 1.2887  \n",
      "\n",
      "Fold: 22  Epoch: 182  Training loss = 4.4979  Validation loss = 1.2884  \n",
      "\n",
      "Fold: 22  Epoch: 183  Training loss = 4.4974  Validation loss = 1.2880  \n",
      "\n",
      "Fold: 22  Epoch: 184  Training loss = 4.4970  Validation loss = 1.2876  \n",
      "\n",
      "Fold: 22  Epoch: 185  Training loss = 4.4965  Validation loss = 1.2872  \n",
      "\n",
      "Fold: 22  Epoch: 186  Training loss = 4.4963  Validation loss = 1.2870  \n",
      "\n",
      "Fold: 22  Epoch: 187  Training loss = 4.4958  Validation loss = 1.2866  \n",
      "\n",
      "Fold: 22  Epoch: 188  Training loss = 4.4955  Validation loss = 1.2864  \n",
      "\n",
      "Fold: 22  Epoch: 189  Training loss = 4.4952  Validation loss = 1.2861  \n",
      "\n",
      "Fold: 22  Epoch: 190  Training loss = 4.4948  Validation loss = 1.2858  \n",
      "\n",
      "Fold: 22  Epoch: 191  Training loss = 4.4944  Validation loss = 1.2855  \n",
      "\n",
      "Fold: 22  Epoch: 192  Training loss = 4.4939  Validation loss = 1.2851  \n",
      "\n",
      "Fold: 22  Epoch: 193  Training loss = 4.4935  Validation loss = 1.2847  \n",
      "\n",
      "Fold: 22  Epoch: 194  Training loss = 4.4931  Validation loss = 1.2843  \n",
      "\n",
      "Fold: 22  Epoch: 195  Training loss = 4.4928  Validation loss = 1.2841  \n",
      "\n",
      "Fold: 22  Epoch: 196  Training loss = 4.4924  Validation loss = 1.2838  \n",
      "\n",
      "Fold: 22  Epoch: 197  Training loss = 4.4921  Validation loss = 1.2835  \n",
      "\n",
      "Fold: 22  Epoch: 198  Training loss = 4.4917  Validation loss = 1.2832  \n",
      "\n",
      "Fold: 22  Epoch: 199  Training loss = 4.4913  Validation loss = 1.2828  \n",
      "\n",
      "Fold: 22  Epoch: 200  Training loss = 4.4910  Validation loss = 1.2825  \n",
      "\n",
      "Fold: 22  Epoch: 201  Training loss = 4.4907  Validation loss = 1.2822  \n",
      "\n",
      "Fold: 22  Epoch: 202  Training loss = 4.4903  Validation loss = 1.2819  \n",
      "\n",
      "Fold: 22  Epoch: 203  Training loss = 4.4900  Validation loss = 1.2816  \n",
      "\n",
      "Fold: 22  Epoch: 204  Training loss = 4.4895  Validation loss = 1.2813  \n",
      "\n",
      "Fold: 22  Epoch: 205  Training loss = 4.4891  Validation loss = 1.2809  \n",
      "\n",
      "Fold: 22  Epoch: 206  Training loss = 4.4885  Validation loss = 1.2804  \n",
      "\n",
      "Fold: 22  Epoch: 207  Training loss = 4.4882  Validation loss = 1.2800  \n",
      "\n",
      "Fold: 22  Epoch: 208  Training loss = 4.4877  Validation loss = 1.2796  \n",
      "\n",
      "Fold: 22  Epoch: 209  Training loss = 4.4873  Validation loss = 1.2793  \n",
      "\n",
      "Fold: 22  Epoch: 210  Training loss = 4.4869  Validation loss = 1.2790  \n",
      "\n",
      "Fold: 22  Epoch: 211  Training loss = 4.4866  Validation loss = 1.2788  \n",
      "\n",
      "Fold: 22  Epoch: 212  Training loss = 4.4862  Validation loss = 1.2784  \n",
      "\n",
      "Fold: 22  Epoch: 213  Training loss = 4.4859  Validation loss = 1.2781  \n",
      "\n",
      "Fold: 22  Epoch: 214  Training loss = 4.4855  Validation loss = 1.2779  \n",
      "\n",
      "Fold: 22  Epoch: 215  Training loss = 4.4851  Validation loss = 1.2775  \n",
      "\n",
      "Fold: 22  Epoch: 216  Training loss = 4.4847  Validation loss = 1.2772  \n",
      "\n",
      "Fold: 22  Epoch: 217  Training loss = 4.4843  Validation loss = 1.2768  \n",
      "\n",
      "Fold: 22  Epoch: 218  Training loss = 4.4839  Validation loss = 1.2765  \n",
      "\n",
      "Fold: 22  Epoch: 219  Training loss = 4.4837  Validation loss = 1.2763  \n",
      "\n",
      "Fold: 22  Epoch: 220  Training loss = 4.4833  Validation loss = 1.2760  \n",
      "\n",
      "Fold: 22  Epoch: 221  Training loss = 4.4830  Validation loss = 1.2758  \n",
      "\n",
      "Fold: 22  Epoch: 222  Training loss = 4.4826  Validation loss = 1.2755  \n",
      "\n",
      "Fold: 22  Epoch: 223  Training loss = 4.4822  Validation loss = 1.2751  \n",
      "\n",
      "Fold: 22  Epoch: 224  Training loss = 4.4818  Validation loss = 1.2747  \n",
      "\n",
      "Fold: 22  Epoch: 225  Training loss = 4.4813  Validation loss = 1.2743  \n",
      "\n",
      "Fold: 22  Epoch: 226  Training loss = 4.4809  Validation loss = 1.2740  \n",
      "\n",
      "Fold: 22  Epoch: 227  Training loss = 4.4805  Validation loss = 1.2737  \n",
      "\n",
      "Fold: 22  Epoch: 228  Training loss = 4.4801  Validation loss = 1.2734  \n",
      "\n",
      "Fold: 22  Epoch: 229  Training loss = 4.4798  Validation loss = 1.2732  \n",
      "\n",
      "Fold: 22  Epoch: 230  Training loss = 4.4795  Validation loss = 1.2728  \n",
      "\n",
      "Fold: 22  Epoch: 231  Training loss = 4.4790  Validation loss = 1.2725  \n",
      "\n",
      "Fold: 22  Epoch: 232  Training loss = 4.4786  Validation loss = 1.2722  \n",
      "\n",
      "Fold: 22  Epoch: 233  Training loss = 4.4783  Validation loss = 1.2719  \n",
      "\n",
      "Fold: 22  Epoch: 234  Training loss = 4.4780  Validation loss = 1.2716  \n",
      "\n",
      "Fold: 22  Epoch: 235  Training loss = 4.4775  Validation loss = 1.2713  \n",
      "\n",
      "Fold: 22  Epoch: 236  Training loss = 4.4772  Validation loss = 1.2710  \n",
      "\n",
      "Fold: 22  Epoch: 237  Training loss = 4.4769  Validation loss = 1.2708  \n",
      "\n",
      "Fold: 22  Epoch: 238  Training loss = 4.4765  Validation loss = 1.2705  \n",
      "\n",
      "Fold: 22  Epoch: 239  Training loss = 4.4760  Validation loss = 1.2701  \n",
      "\n",
      "Fold: 22  Epoch: 240  Training loss = 4.4756  Validation loss = 1.2697  \n",
      "\n",
      "Fold: 22  Epoch: 241  Training loss = 4.4752  Validation loss = 1.2694  \n",
      "\n",
      "Fold: 22  Epoch: 242  Training loss = 4.4749  Validation loss = 1.2692  \n",
      "\n",
      "Fold: 22  Epoch: 243  Training loss = 4.4746  Validation loss = 1.2689  \n",
      "\n",
      "Fold: 22  Epoch: 244  Training loss = 4.4742  Validation loss = 1.2686  \n",
      "\n",
      "Fold: 22  Epoch: 245  Training loss = 4.4738  Validation loss = 1.2683  \n",
      "\n",
      "Fold: 22  Epoch: 246  Training loss = 4.4735  Validation loss = 1.2681  \n",
      "\n",
      "Fold: 22  Epoch: 247  Training loss = 4.4730  Validation loss = 1.2677  \n",
      "\n",
      "Fold: 22  Epoch: 248  Training loss = 4.4727  Validation loss = 1.2675  \n",
      "\n",
      "Fold: 22  Epoch: 249  Training loss = 4.4724  Validation loss = 1.2673  \n",
      "\n",
      "Fold: 22  Epoch: 250  Training loss = 4.4720  Validation loss = 1.2669  \n",
      "\n",
      "Fold: 22  Epoch: 251  Training loss = 4.4717  Validation loss = 1.2666  \n",
      "\n",
      "Fold: 22  Epoch: 252  Training loss = 4.4713  Validation loss = 1.2662  \n",
      "\n",
      "Fold: 22  Epoch: 253  Training loss = 4.4708  Validation loss = 1.2659  \n",
      "\n",
      "Fold: 22  Epoch: 254  Training loss = 4.4704  Validation loss = 1.2655  \n",
      "\n",
      "Fold: 22  Epoch: 255  Training loss = 4.4699  Validation loss = 1.2651  \n",
      "\n",
      "Fold: 22  Epoch: 256  Training loss = 4.4696  Validation loss = 1.2648  \n",
      "\n",
      "Fold: 22  Epoch: 257  Training loss = 4.4692  Validation loss = 1.2645  \n",
      "\n",
      "Fold: 22  Epoch: 258  Training loss = 4.4688  Validation loss = 1.2642  \n",
      "\n",
      "Fold: 22  Epoch: 259  Training loss = 4.4685  Validation loss = 1.2640  \n",
      "\n",
      "Fold: 22  Epoch: 260  Training loss = 4.4682  Validation loss = 1.2638  \n",
      "\n",
      "Fold: 22  Epoch: 261  Training loss = 4.4679  Validation loss = 1.2636  \n",
      "\n",
      "Fold: 22  Epoch: 262  Training loss = 4.4675  Validation loss = 1.2632  \n",
      "\n",
      "Fold: 22  Epoch: 263  Training loss = 4.4671  Validation loss = 1.2629  \n",
      "\n",
      "Fold: 22  Epoch: 264  Training loss = 4.4666  Validation loss = 1.2624  \n",
      "\n",
      "Fold: 22  Epoch: 265  Training loss = 4.4661  Validation loss = 1.2621  \n",
      "\n",
      "Fold: 22  Epoch: 266  Training loss = 4.4657  Validation loss = 1.2618  \n",
      "\n",
      "Fold: 22  Epoch: 267  Training loss = 4.4652  Validation loss = 1.2613  \n",
      "\n",
      "Fold: 22  Epoch: 268  Training loss = 4.4648  Validation loss = 1.2610  \n",
      "\n",
      "Fold: 22  Epoch: 269  Training loss = 4.4645  Validation loss = 1.2608  \n",
      "\n",
      "Fold: 22  Epoch: 270  Training loss = 4.4641  Validation loss = 1.2604  \n",
      "\n",
      "Fold: 22  Epoch: 271  Training loss = 4.4637  Validation loss = 1.2601  \n",
      "\n",
      "Fold: 22  Epoch: 272  Training loss = 4.4634  Validation loss = 1.2598  \n",
      "\n",
      "Fold: 22  Epoch: 273  Training loss = 4.4630  Validation loss = 1.2595  \n",
      "\n",
      "Fold: 22  Epoch: 274  Training loss = 4.4626  Validation loss = 1.2591  \n",
      "\n",
      "Fold: 22  Epoch: 275  Training loss = 4.4622  Validation loss = 1.2588  \n",
      "\n",
      "Fold: 22  Epoch: 276  Training loss = 4.4617  Validation loss = 1.2584  \n",
      "\n",
      "Fold: 22  Epoch: 277  Training loss = 4.4614  Validation loss = 1.2582  \n",
      "\n",
      "Fold: 22  Epoch: 278  Training loss = 4.4610  Validation loss = 1.2578  \n",
      "\n",
      "Fold: 22  Epoch: 279  Training loss = 4.4606  Validation loss = 1.2575  \n",
      "\n",
      "Fold: 22  Epoch: 280  Training loss = 4.4602  Validation loss = 1.2572  \n",
      "\n",
      "Fold: 22  Epoch: 281  Training loss = 4.4598  Validation loss = 1.2568  \n",
      "\n",
      "Fold: 22  Epoch: 282  Training loss = 4.4593  Validation loss = 1.2564  \n",
      "\n",
      "Fold: 22  Epoch: 283  Training loss = 4.4590  Validation loss = 1.2562  \n",
      "\n",
      "Fold: 22  Epoch: 284  Training loss = 4.4586  Validation loss = 1.2559  \n",
      "\n",
      "Fold: 22  Epoch: 285  Training loss = 4.4582  Validation loss = 1.2556  \n",
      "\n",
      "Fold: 22  Epoch: 286  Training loss = 4.4578  Validation loss = 1.2553  \n",
      "\n",
      "Fold: 22  Epoch: 287  Training loss = 4.4574  Validation loss = 1.2549  \n",
      "\n",
      "Fold: 22  Epoch: 288  Training loss = 4.4571  Validation loss = 1.2546  \n",
      "\n",
      "Fold: 22  Epoch: 289  Training loss = 4.4565  Validation loss = 1.2542  \n",
      "\n",
      "Fold: 22  Epoch: 290  Training loss = 4.4562  Validation loss = 1.2539  \n",
      "\n",
      "Fold: 22  Epoch: 291  Training loss = 4.4558  Validation loss = 1.2536  \n",
      "\n",
      "Fold: 22  Epoch: 292  Training loss = 4.4553  Validation loss = 1.2532  \n",
      "\n",
      "Fold: 22  Epoch: 293  Training loss = 4.4549  Validation loss = 1.2529  \n",
      "\n",
      "Fold: 22  Epoch: 294  Training loss = 4.4546  Validation loss = 1.2526  \n",
      "\n",
      "Fold: 22  Epoch: 295  Training loss = 4.4541  Validation loss = 1.2523  \n",
      "\n",
      "Fold: 22  Epoch: 296  Training loss = 4.4537  Validation loss = 1.2520  \n",
      "\n",
      "Fold: 22  Epoch: 297  Training loss = 4.4534  Validation loss = 1.2518  \n",
      "\n",
      "Fold: 22  Epoch: 298  Training loss = 4.4529  Validation loss = 1.2514  \n",
      "\n",
      "Fold: 22  Epoch: 299  Training loss = 4.4526  Validation loss = 1.2511  \n",
      "\n",
      "Fold: 22  Epoch: 300  Training loss = 4.4523  Validation loss = 1.2509  \n",
      "\n",
      "Fold: 22  Epoch: 301  Training loss = 4.4519  Validation loss = 1.2506  \n",
      "\n",
      "Fold: 22  Epoch: 302  Training loss = 4.4516  Validation loss = 1.2503  \n",
      "\n",
      "Fold: 22  Epoch: 303  Training loss = 4.4511  Validation loss = 1.2499  \n",
      "\n",
      "Fold: 22  Epoch: 304  Training loss = 4.4508  Validation loss = 1.2497  \n",
      "\n",
      "Fold: 22  Epoch: 305  Training loss = 4.4504  Validation loss = 1.2494  \n",
      "\n",
      "Fold: 22  Epoch: 306  Training loss = 4.4500  Validation loss = 1.2490  \n",
      "\n",
      "Fold: 22  Epoch: 307  Training loss = 4.4496  Validation loss = 1.2487  \n",
      "\n",
      "Fold: 22  Epoch: 308  Training loss = 4.4493  Validation loss = 1.2486  \n",
      "\n",
      "Fold: 22  Epoch: 309  Training loss = 4.4489  Validation loss = 1.2482  \n",
      "\n",
      "Fold: 22  Epoch: 310  Training loss = 4.4487  Validation loss = 1.2481  \n",
      "\n",
      "Fold: 22  Epoch: 311  Training loss = 4.4483  Validation loss = 1.2477  \n",
      "\n",
      "Fold: 22  Epoch: 312  Training loss = 4.4481  Validation loss = 1.2476  \n",
      "\n",
      "Fold: 22  Epoch: 313  Training loss = 4.4478  Validation loss = 1.2473  \n",
      "\n",
      "Fold: 22  Epoch: 314  Training loss = 4.4474  Validation loss = 1.2470  \n",
      "\n",
      "Fold: 22  Epoch: 315  Training loss = 4.4470  Validation loss = 1.2466  \n",
      "\n",
      "Fold: 22  Epoch: 316  Training loss = 4.4465  Validation loss = 1.2462  \n",
      "\n",
      "Fold: 22  Epoch: 317  Training loss = 4.4462  Validation loss = 1.2460  \n",
      "\n",
      "Fold: 22  Epoch: 318  Training loss = 4.4459  Validation loss = 1.2458  \n",
      "\n",
      "Fold: 22  Epoch: 319  Training loss = 4.4456  Validation loss = 1.2455  \n",
      "\n",
      "Fold: 22  Epoch: 320  Training loss = 4.4451  Validation loss = 1.2452  \n",
      "\n",
      "Fold: 22  Epoch: 321  Training loss = 4.4448  Validation loss = 1.2449  \n",
      "\n",
      "Fold: 22  Epoch: 322  Training loss = 4.4445  Validation loss = 1.2448  \n",
      "\n",
      "Fold: 22  Epoch: 323  Training loss = 4.4441  Validation loss = 1.2446  \n",
      "\n",
      "Fold: 22  Epoch: 324  Training loss = 4.4436  Validation loss = 1.2441  \n",
      "\n",
      "Fold: 22  Epoch: 325  Training loss = 4.4432  Validation loss = 1.2438  \n",
      "\n",
      "Fold: 22  Epoch: 326  Training loss = 4.4427  Validation loss = 1.2434  \n",
      "\n",
      "Fold: 22  Epoch: 327  Training loss = 4.4424  Validation loss = 1.2431  \n",
      "\n",
      "Fold: 22  Epoch: 328  Training loss = 4.4421  Validation loss = 1.2428  \n",
      "\n",
      "Fold: 22  Epoch: 329  Training loss = 4.4417  Validation loss = 1.2425  \n",
      "\n",
      "Fold: 22  Epoch: 330  Training loss = 4.4413  Validation loss = 1.2422  \n",
      "\n",
      "Fold: 22  Epoch: 331  Training loss = 4.4410  Validation loss = 1.2420  \n",
      "\n",
      "Fold: 22  Epoch: 332  Training loss = 4.4406  Validation loss = 1.2417  \n",
      "\n",
      "Fold: 22  Epoch: 333  Training loss = 4.4402  Validation loss = 1.2414  \n",
      "\n",
      "Fold: 22  Epoch: 334  Training loss = 4.4398  Validation loss = 1.2411  \n",
      "\n",
      "Fold: 22  Epoch: 335  Training loss = 4.4395  Validation loss = 1.2408  \n",
      "\n",
      "Fold: 22  Epoch: 336  Training loss = 4.4391  Validation loss = 1.2406  \n",
      "\n",
      "Fold: 22  Epoch: 337  Training loss = 4.4388  Validation loss = 1.2403  \n",
      "\n",
      "Fold: 22  Epoch: 338  Training loss = 4.4385  Validation loss = 1.2401  \n",
      "\n",
      "Fold: 22  Epoch: 339  Training loss = 4.4381  Validation loss = 1.2398  \n",
      "\n",
      "Fold: 22  Epoch: 340  Training loss = 4.4378  Validation loss = 1.2395  \n",
      "\n",
      "Fold: 22  Epoch: 341  Training loss = 4.4374  Validation loss = 1.2392  \n",
      "\n",
      "Fold: 22  Epoch: 342  Training loss = 4.4370  Validation loss = 1.2389  \n",
      "\n",
      "Fold: 22  Epoch: 343  Training loss = 4.4367  Validation loss = 1.2386  \n",
      "\n",
      "Fold: 22  Epoch: 344  Training loss = 4.4363  Validation loss = 1.2383  \n",
      "\n",
      "Fold: 22  Epoch: 345  Training loss = 4.4358  Validation loss = 1.2380  \n",
      "\n",
      "Fold: 22  Epoch: 346  Training loss = 4.4355  Validation loss = 1.2377  \n",
      "\n",
      "Fold: 22  Epoch: 347  Training loss = 4.4351  Validation loss = 1.2374  \n",
      "\n",
      "Fold: 22  Epoch: 348  Training loss = 4.4348  Validation loss = 1.2371  \n",
      "\n",
      "Fold: 22  Epoch: 349  Training loss = 4.4343  Validation loss = 1.2368  \n",
      "\n",
      "Fold: 22  Epoch: 350  Training loss = 4.4340  Validation loss = 1.2365  \n",
      "\n",
      "Fold: 22  Epoch: 351  Training loss = 4.4336  Validation loss = 1.2362  \n",
      "\n",
      "Fold: 22  Epoch: 352  Training loss = 4.4330  Validation loss = 1.2358  \n",
      "\n",
      "Fold: 22  Epoch: 353  Training loss = 4.4326  Validation loss = 1.2354  \n",
      "\n",
      "Fold: 22  Epoch: 354  Training loss = 4.4323  Validation loss = 1.2352  \n",
      "\n",
      "Fold: 22  Epoch: 355  Training loss = 4.4318  Validation loss = 1.2349  \n",
      "\n",
      "Fold: 22  Epoch: 356  Training loss = 4.4315  Validation loss = 1.2346  \n",
      "\n",
      "Fold: 22  Epoch: 357  Training loss = 4.4311  Validation loss = 1.2342  \n",
      "\n",
      "Fold: 22  Epoch: 358  Training loss = 4.4306  Validation loss = 1.2339  \n",
      "\n",
      "Fold: 22  Epoch: 359  Training loss = 4.4303  Validation loss = 1.2337  \n",
      "\n",
      "Fold: 22  Epoch: 360  Training loss = 4.4299  Validation loss = 1.2333  \n",
      "\n",
      "Fold: 22  Epoch: 361  Training loss = 4.4295  Validation loss = 1.2331  \n",
      "\n",
      "Fold: 22  Epoch: 362  Training loss = 4.4291  Validation loss = 1.2328  \n",
      "\n",
      "Fold: 22  Epoch: 363  Training loss = 4.4288  Validation loss = 1.2326  \n",
      "\n",
      "Fold: 22  Epoch: 364  Training loss = 4.4283  Validation loss = 1.2323  \n",
      "\n",
      "Fold: 22  Epoch: 365  Training loss = 4.4280  Validation loss = 1.2319  \n",
      "\n",
      "Fold: 22  Epoch: 366  Training loss = 4.4277  Validation loss = 1.2317  \n",
      "\n",
      "Fold: 22  Epoch: 367  Training loss = 4.4274  Validation loss = 1.2314  \n",
      "\n",
      "Fold: 22  Epoch: 368  Training loss = 4.4270  Validation loss = 1.2312  \n",
      "\n",
      "Fold: 22  Epoch: 369  Training loss = 4.4267  Validation loss = 1.2309  \n",
      "\n",
      "Fold: 22  Epoch: 370  Training loss = 4.4264  Validation loss = 1.2306  \n",
      "\n",
      "Fold: 22  Epoch: 371  Training loss = 4.4261  Validation loss = 1.2304  \n",
      "\n",
      "Fold: 22  Epoch: 372  Training loss = 4.4256  Validation loss = 1.2300  \n",
      "\n",
      "Fold: 22  Epoch: 373  Training loss = 4.4253  Validation loss = 1.2298  \n",
      "\n",
      "Fold: 22  Epoch: 374  Training loss = 4.4248  Validation loss = 1.2294  \n",
      "\n",
      "Fold: 22  Epoch: 375  Training loss = 4.4244  Validation loss = 1.2291  \n",
      "\n",
      "Fold: 22  Epoch: 376  Training loss = 4.4241  Validation loss = 1.2288  \n",
      "\n",
      "Fold: 22  Epoch: 377  Training loss = 4.4236  Validation loss = 1.2285  \n",
      "\n",
      "Fold: 22  Epoch: 378  Training loss = 4.4233  Validation loss = 1.2283  \n",
      "\n",
      "Fold: 22  Epoch: 379  Training loss = 4.4230  Validation loss = 1.2280  \n",
      "\n",
      "Fold: 22  Epoch: 380  Training loss = 4.4226  Validation loss = 1.2278  \n",
      "\n",
      "Fold: 22  Epoch: 381  Training loss = 4.4221  Validation loss = 1.2274  \n",
      "\n",
      "Fold: 22  Epoch: 382  Training loss = 4.4217  Validation loss = 1.2271  \n",
      "\n",
      "Fold: 22  Epoch: 383  Training loss = 4.4215  Validation loss = 1.2269  \n",
      "\n",
      "Fold: 22  Epoch: 384  Training loss = 4.4209  Validation loss = 1.2264  \n",
      "\n",
      "Fold: 22  Epoch: 385  Training loss = 4.4206  Validation loss = 1.2262  \n",
      "\n",
      "Fold: 22  Epoch: 386  Training loss = 4.4202  Validation loss = 1.2259  \n",
      "\n",
      "Fold: 22  Epoch: 387  Training loss = 4.4198  Validation loss = 1.2255  \n",
      "\n",
      "Fold: 22  Epoch: 388  Training loss = 4.4195  Validation loss = 1.2253  \n",
      "\n",
      "Fold: 22  Epoch: 389  Training loss = 4.4191  Validation loss = 1.2250  \n",
      "\n",
      "Fold: 22  Epoch: 390  Training loss = 4.4188  Validation loss = 1.2247  \n",
      "\n",
      "Fold: 22  Epoch: 391  Training loss = 4.4185  Validation loss = 1.2244  \n",
      "\n",
      "Fold: 22  Epoch: 392  Training loss = 4.4181  Validation loss = 1.2240  \n",
      "\n",
      "Fold: 22  Epoch: 393  Training loss = 4.4177  Validation loss = 1.2237  \n",
      "\n",
      "Fold: 22  Epoch: 394  Training loss = 4.4175  Validation loss = 1.2236  \n",
      "\n",
      "Fold: 22  Epoch: 395  Training loss = 4.4172  Validation loss = 1.2234  \n",
      "\n",
      "Fold: 22  Epoch: 396  Training loss = 4.4167  Validation loss = 1.2230  \n",
      "\n",
      "Fold: 22  Epoch: 397  Training loss = 4.4162  Validation loss = 1.2227  \n",
      "\n",
      "Fold: 22  Epoch: 398  Training loss = 4.4158  Validation loss = 1.2223  \n",
      "\n",
      "Fold: 22  Epoch: 399  Training loss = 4.4154  Validation loss = 1.2219  \n",
      "\n",
      "Fold: 22  Epoch: 400  Training loss = 4.4150  Validation loss = 1.2216  \n",
      "\n",
      "Fold: 22  Epoch: 401  Training loss = 4.4147  Validation loss = 1.2214  \n",
      "\n",
      "Fold: 22  Epoch: 402  Training loss = 4.4143  Validation loss = 1.2211  \n",
      "\n",
      "Fold: 22  Epoch: 403  Training loss = 4.4139  Validation loss = 1.2208  \n",
      "\n",
      "Fold: 22  Epoch: 404  Training loss = 4.4136  Validation loss = 1.2206  \n",
      "\n",
      "Fold: 22  Epoch: 405  Training loss = 4.4133  Validation loss = 1.2203  \n",
      "\n",
      "Fold: 22  Epoch: 406  Training loss = 4.4129  Validation loss = 1.2200  \n",
      "\n",
      "Fold: 22  Epoch: 407  Training loss = 4.4125  Validation loss = 1.2197  \n",
      "\n",
      "Fold: 22  Epoch: 408  Training loss = 4.4121  Validation loss = 1.2194  \n",
      "\n",
      "Fold: 22  Epoch: 409  Training loss = 4.4118  Validation loss = 1.2191  \n",
      "\n",
      "Fold: 22  Epoch: 410  Training loss = 4.4115  Validation loss = 1.2189  \n",
      "\n",
      "Fold: 22  Epoch: 411  Training loss = 4.4112  Validation loss = 1.2187  \n",
      "\n",
      "Fold: 22  Epoch: 412  Training loss = 4.4108  Validation loss = 1.2183  \n",
      "\n",
      "Fold: 22  Epoch: 413  Training loss = 4.4104  Validation loss = 1.2181  \n",
      "\n",
      "Fold: 22  Epoch: 414  Training loss = 4.4101  Validation loss = 1.2178  \n",
      "\n",
      "Fold: 22  Epoch: 415  Training loss = 4.4098  Validation loss = 1.2176  \n",
      "\n",
      "Fold: 22  Epoch: 416  Training loss = 4.4094  Validation loss = 1.2173  \n",
      "\n",
      "Fold: 22  Epoch: 417  Training loss = 4.4090  Validation loss = 1.2169  \n",
      "\n",
      "Fold: 22  Epoch: 418  Training loss = 4.4086  Validation loss = 1.2166  \n",
      "\n",
      "Fold: 22  Epoch: 419  Training loss = 4.4082  Validation loss = 1.2163  \n",
      "\n",
      "Fold: 22  Epoch: 420  Training loss = 4.4078  Validation loss = 1.2160  \n",
      "\n",
      "Fold: 22  Epoch: 421  Training loss = 4.4075  Validation loss = 1.2157  \n",
      "\n",
      "Fold: 22  Epoch: 422  Training loss = 4.4071  Validation loss = 1.2154  \n",
      "\n",
      "Fold: 22  Epoch: 423  Training loss = 4.4068  Validation loss = 1.2152  \n",
      "\n",
      "Fold: 22  Epoch: 424  Training loss = 4.4065  Validation loss = 1.2150  \n",
      "\n",
      "Fold: 22  Epoch: 425  Training loss = 4.4060  Validation loss = 1.2146  \n",
      "\n",
      "Fold: 22  Epoch: 426  Training loss = 4.4058  Validation loss = 1.2144  \n",
      "\n",
      "Fold: 22  Epoch: 427  Training loss = 4.4054  Validation loss = 1.2141  \n",
      "\n",
      "Fold: 22  Epoch: 428  Training loss = 4.4050  Validation loss = 1.2139  \n",
      "\n",
      "Fold: 22  Epoch: 429  Training loss = 4.4047  Validation loss = 1.2136  \n",
      "\n",
      "Fold: 22  Epoch: 430  Training loss = 4.4044  Validation loss = 1.2134  \n",
      "\n",
      "Fold: 22  Epoch: 431  Training loss = 4.4039  Validation loss = 1.2130  \n",
      "\n",
      "Fold: 22  Epoch: 432  Training loss = 4.4036  Validation loss = 1.2127  \n",
      "\n",
      "Fold: 22  Epoch: 433  Training loss = 4.4032  Validation loss = 1.2124  \n",
      "\n",
      "Fold: 22  Epoch: 434  Training loss = 4.4028  Validation loss = 1.2122  \n",
      "\n",
      "Fold: 22  Epoch: 435  Training loss = 4.4023  Validation loss = 1.2118  \n",
      "\n",
      "Fold: 22  Epoch: 436  Training loss = 4.4020  Validation loss = 1.2116  \n",
      "\n",
      "Fold: 22  Epoch: 437  Training loss = 4.4016  Validation loss = 1.2113  \n",
      "\n",
      "Fold: 22  Epoch: 438  Training loss = 4.4014  Validation loss = 1.2111  \n",
      "\n",
      "Fold: 22  Epoch: 439  Training loss = 4.4009  Validation loss = 1.2107  \n",
      "\n",
      "Fold: 22  Epoch: 440  Training loss = 4.4005  Validation loss = 1.2104  \n",
      "\n",
      "Fold: 22  Epoch: 441  Training loss = 4.4002  Validation loss = 1.2101  \n",
      "\n",
      "Fold: 22  Epoch: 442  Training loss = 4.3998  Validation loss = 1.2098  \n",
      "\n",
      "Fold: 22  Epoch: 443  Training loss = 4.3994  Validation loss = 1.2095  \n",
      "\n",
      "Fold: 22  Epoch: 444  Training loss = 4.3991  Validation loss = 1.2093  \n",
      "\n",
      "Fold: 22  Epoch: 445  Training loss = 4.3987  Validation loss = 1.2089  \n",
      "\n",
      "Fold: 22  Epoch: 446  Training loss = 4.3983  Validation loss = 1.2086  \n",
      "\n",
      "Fold: 22  Epoch: 447  Training loss = 4.3979  Validation loss = 1.2083  \n",
      "\n",
      "Fold: 22  Epoch: 448  Training loss = 4.3975  Validation loss = 1.2081  \n",
      "\n",
      "Fold: 22  Epoch: 449  Training loss = 4.3972  Validation loss = 1.2078  \n",
      "\n",
      "Fold: 22  Epoch: 450  Training loss = 4.3968  Validation loss = 1.2075  \n",
      "\n",
      "Fold: 22  Epoch: 451  Training loss = 4.3966  Validation loss = 1.2073  \n",
      "\n",
      "Fold: 22  Epoch: 452  Training loss = 4.3961  Validation loss = 1.2070  \n",
      "\n",
      "Fold: 22  Epoch: 453  Training loss = 4.3957  Validation loss = 1.2067  \n",
      "\n",
      "Fold: 22  Epoch: 454  Training loss = 4.3953  Validation loss = 1.2065  \n",
      "\n",
      "Fold: 22  Epoch: 455  Training loss = 4.3950  Validation loss = 1.2063  \n",
      "\n",
      "Fold: 22  Epoch: 456  Training loss = 4.3947  Validation loss = 1.2061  \n",
      "\n",
      "Fold: 22  Epoch: 457  Training loss = 4.3945  Validation loss = 1.2059  \n",
      "\n",
      "Fold: 22  Epoch: 458  Training loss = 4.3941  Validation loss = 1.2056  \n",
      "\n",
      "Fold: 22  Epoch: 459  Training loss = 4.3937  Validation loss = 1.2053  \n",
      "\n",
      "Fold: 22  Epoch: 460  Training loss = 4.3934  Validation loss = 1.2050  \n",
      "\n",
      "Fold: 22  Epoch: 461  Training loss = 4.3930  Validation loss = 1.2048  \n",
      "\n",
      "Fold: 22  Epoch: 462  Training loss = 4.3927  Validation loss = 1.2045  \n",
      "\n",
      "Fold: 22  Epoch: 463  Training loss = 4.3922  Validation loss = 1.2042  \n",
      "\n",
      "Fold: 22  Epoch: 464  Training loss = 4.3918  Validation loss = 1.2038  \n",
      "\n",
      "Fold: 22  Epoch: 465  Training loss = 4.3915  Validation loss = 1.2036  \n",
      "\n",
      "Fold: 22  Epoch: 466  Training loss = 4.3913  Validation loss = 1.2035  \n",
      "\n",
      "Fold: 22  Epoch: 467  Training loss = 4.3908  Validation loss = 1.2032  \n",
      "\n",
      "Fold: 22  Epoch: 468  Training loss = 4.3904  Validation loss = 1.2028  \n",
      "\n",
      "Fold: 22  Epoch: 469  Training loss = 4.3902  Validation loss = 1.2027  \n",
      "\n",
      "Fold: 22  Epoch: 470  Training loss = 4.3899  Validation loss = 1.2025  \n",
      "\n",
      "Fold: 22  Epoch: 471  Training loss = 4.3895  Validation loss = 1.2022  \n",
      "\n",
      "Fold: 22  Epoch: 472  Training loss = 4.3892  Validation loss = 1.2020  \n",
      "\n",
      "Fold: 22  Epoch: 473  Training loss = 4.3888  Validation loss = 1.2017  \n",
      "\n",
      "Fold: 22  Epoch: 474  Training loss = 4.3884  Validation loss = 1.2014  \n",
      "\n",
      "Fold: 22  Epoch: 475  Training loss = 4.3880  Validation loss = 1.2012  \n",
      "\n",
      "Fold: 22  Epoch: 476  Training loss = 4.3876  Validation loss = 1.2010  \n",
      "\n",
      "Fold: 22  Epoch: 477  Training loss = 4.3872  Validation loss = 1.2007  \n",
      "\n",
      "Fold: 22  Epoch: 478  Training loss = 4.3868  Validation loss = 1.2005  \n",
      "\n",
      "Fold: 22  Epoch: 479  Training loss = 4.3864  Validation loss = 1.2001  \n",
      "\n",
      "Fold: 22  Epoch: 480  Training loss = 4.3860  Validation loss = 1.2000  \n",
      "\n",
      "Fold: 22  Epoch: 481  Training loss = 4.3856  Validation loss = 1.1996  \n",
      "\n",
      "Fold: 22  Epoch: 482  Training loss = 4.3852  Validation loss = 1.1994  \n",
      "\n",
      "Fold: 22  Epoch: 483  Training loss = 4.3849  Validation loss = 1.1991  \n",
      "\n",
      "Fold: 22  Epoch: 484  Training loss = 4.3846  Validation loss = 1.1988  \n",
      "\n",
      "Fold: 22  Epoch: 485  Training loss = 4.3842  Validation loss = 1.1986  \n",
      "\n",
      "Fold: 22  Epoch: 486  Training loss = 4.3839  Validation loss = 1.1984  \n",
      "\n",
      "Fold: 22  Epoch: 487  Training loss = 4.3836  Validation loss = 1.1981  \n",
      "\n",
      "Fold: 22  Epoch: 488  Training loss = 4.3831  Validation loss = 1.1977  \n",
      "\n",
      "Fold: 22  Epoch: 489  Training loss = 4.3828  Validation loss = 1.1975  \n",
      "\n",
      "Fold: 22  Epoch: 490  Training loss = 4.3825  Validation loss = 1.1972  \n",
      "\n",
      "Fold: 22  Epoch: 491  Training loss = 4.3821  Validation loss = 1.1970  \n",
      "\n",
      "Fold: 22  Epoch: 492  Training loss = 4.3818  Validation loss = 1.1968  \n",
      "\n",
      "Fold: 22  Epoch: 493  Training loss = 4.3814  Validation loss = 1.1965  \n",
      "\n",
      "Fold: 22  Epoch: 494  Training loss = 4.3811  Validation loss = 1.1963  \n",
      "\n",
      "Fold: 22  Epoch: 495  Training loss = 4.3808  Validation loss = 1.1962  \n",
      "\n",
      "Fold: 22  Epoch: 496  Training loss = 4.3805  Validation loss = 1.1959  \n",
      "\n",
      "Fold: 22  Epoch: 497  Training loss = 4.3801  Validation loss = 1.1957  \n",
      "\n",
      "Fold: 22  Epoch: 498  Training loss = 4.3797  Validation loss = 1.1954  \n",
      "\n",
      "Fold: 22  Epoch: 499  Training loss = 4.3793  Validation loss = 1.1952  \n",
      "\n",
      "Fold: 22  Epoch: 500  Training loss = 4.3789  Validation loss = 1.1948  \n",
      "\n",
      "Check model:  Fold: 22  Optimal epoch: 500  \n",
      "\n",
      "Fold: 23  Epoch: 1  Training loss = 4.3823  Validation loss = 0.9629  \n",
      "\n",
      "Fold: 23  Epoch: 2  Training loss = 4.3818  Validation loss = 0.9624  \n",
      "\n",
      "Fold: 23  Epoch: 3  Training loss = 4.3815  Validation loss = 0.9620  \n",
      "\n",
      "Fold: 23  Epoch: 4  Training loss = 4.3811  Validation loss = 0.9616  \n",
      "\n",
      "Fold: 23  Epoch: 5  Training loss = 4.3807  Validation loss = 0.9613  \n",
      "\n",
      "Fold: 23  Epoch: 6  Training loss = 4.3803  Validation loss = 0.9609  \n",
      "\n",
      "Fold: 23  Epoch: 7  Training loss = 4.3799  Validation loss = 0.9605  \n",
      "\n",
      "Fold: 23  Epoch: 8  Training loss = 4.3796  Validation loss = 0.9602  \n",
      "\n",
      "Fold: 23  Epoch: 9  Training loss = 4.3793  Validation loss = 0.9598  \n",
      "\n",
      "Fold: 23  Epoch: 10  Training loss = 4.3789  Validation loss = 0.9595  \n",
      "\n",
      "Fold: 23  Epoch: 11  Training loss = 4.3785  Validation loss = 0.9591  \n",
      "\n",
      "Fold: 23  Epoch: 12  Training loss = 4.3781  Validation loss = 0.9587  \n",
      "\n",
      "Fold: 23  Epoch: 13  Training loss = 4.3777  Validation loss = 0.9584  \n",
      "\n",
      "Fold: 23  Epoch: 14  Training loss = 4.3774  Validation loss = 0.9581  \n",
      "\n",
      "Fold: 23  Epoch: 15  Training loss = 4.3769  Validation loss = 0.9577  \n",
      "\n",
      "Fold: 23  Epoch: 16  Training loss = 4.3765  Validation loss = 0.9573  \n",
      "\n",
      "Fold: 23  Epoch: 17  Training loss = 4.3761  Validation loss = 0.9568  \n",
      "\n",
      "Fold: 23  Epoch: 18  Training loss = 4.3757  Validation loss = 0.9564  \n",
      "\n",
      "Fold: 23  Epoch: 19  Training loss = 4.3753  Validation loss = 0.9561  \n",
      "\n",
      "Fold: 23  Epoch: 20  Training loss = 4.3749  Validation loss = 0.9557  \n",
      "\n",
      "Fold: 23  Epoch: 21  Training loss = 4.3745  Validation loss = 0.9553  \n",
      "\n",
      "Fold: 23  Epoch: 22  Training loss = 4.3739  Validation loss = 0.9547  \n",
      "\n",
      "Fold: 23  Epoch: 23  Training loss = 4.3735  Validation loss = 0.9543  \n",
      "\n",
      "Fold: 23  Epoch: 24  Training loss = 4.3730  Validation loss = 0.9539  \n",
      "\n",
      "Fold: 23  Epoch: 25  Training loss = 4.3727  Validation loss = 0.9535  \n",
      "\n",
      "Fold: 23  Epoch: 26  Training loss = 4.3723  Validation loss = 0.9532  \n",
      "\n",
      "Fold: 23  Epoch: 27  Training loss = 4.3720  Validation loss = 0.9529  \n",
      "\n",
      "Fold: 23  Epoch: 28  Training loss = 4.3717  Validation loss = 0.9526  \n",
      "\n",
      "Fold: 23  Epoch: 29  Training loss = 4.3713  Validation loss = 0.9522  \n",
      "\n",
      "Fold: 23  Epoch: 30  Training loss = 4.3709  Validation loss = 0.9518  \n",
      "\n",
      "Fold: 23  Epoch: 31  Training loss = 4.3704  Validation loss = 0.9514  \n",
      "\n",
      "Fold: 23  Epoch: 32  Training loss = 4.3701  Validation loss = 0.9510  \n",
      "\n",
      "Fold: 23  Epoch: 33  Training loss = 4.3697  Validation loss = 0.9506  \n",
      "\n",
      "Fold: 23  Epoch: 34  Training loss = 4.3692  Validation loss = 0.9502  \n",
      "\n",
      "Fold: 23  Epoch: 35  Training loss = 4.3689  Validation loss = 0.9498  \n",
      "\n",
      "Fold: 23  Epoch: 36  Training loss = 4.3686  Validation loss = 0.9496  \n",
      "\n",
      "Fold: 23  Epoch: 37  Training loss = 4.3682  Validation loss = 0.9492  \n",
      "\n",
      "Fold: 23  Epoch: 38  Training loss = 4.3679  Validation loss = 0.9489  \n",
      "\n",
      "Fold: 23  Epoch: 39  Training loss = 4.3675  Validation loss = 0.9486  \n",
      "\n",
      "Fold: 23  Epoch: 40  Training loss = 4.3672  Validation loss = 0.9482  \n",
      "\n",
      "Fold: 23  Epoch: 41  Training loss = 4.3667  Validation loss = 0.9477  \n",
      "\n",
      "Fold: 23  Epoch: 42  Training loss = 4.3664  Validation loss = 0.9474  \n",
      "\n",
      "Fold: 23  Epoch: 43  Training loss = 4.3661  Validation loss = 0.9471  \n",
      "\n",
      "Fold: 23  Epoch: 44  Training loss = 4.3657  Validation loss = 0.9467  \n",
      "\n",
      "Fold: 23  Epoch: 45  Training loss = 4.3653  Validation loss = 0.9464  \n",
      "\n",
      "Fold: 23  Epoch: 46  Training loss = 4.3650  Validation loss = 0.9461  \n",
      "\n",
      "Fold: 23  Epoch: 47  Training loss = 4.3646  Validation loss = 0.9457  \n",
      "\n",
      "Fold: 23  Epoch: 48  Training loss = 4.3642  Validation loss = 0.9454  \n",
      "\n",
      "Fold: 23  Epoch: 49  Training loss = 4.3640  Validation loss = 0.9451  \n",
      "\n",
      "Fold: 23  Epoch: 50  Training loss = 4.3635  Validation loss = 0.9448  \n",
      "\n",
      "Fold: 23  Epoch: 51  Training loss = 4.3632  Validation loss = 0.9445  \n",
      "\n",
      "Fold: 23  Epoch: 52  Training loss = 4.3628  Validation loss = 0.9441  \n",
      "\n",
      "Fold: 23  Epoch: 53  Training loss = 4.3624  Validation loss = 0.9436  \n",
      "\n",
      "Fold: 23  Epoch: 54  Training loss = 4.3619  Validation loss = 0.9432  \n",
      "\n",
      "Fold: 23  Epoch: 55  Training loss = 4.3615  Validation loss = 0.9428  \n",
      "\n",
      "Fold: 23  Epoch: 56  Training loss = 4.3612  Validation loss = 0.9425  \n",
      "\n",
      "Fold: 23  Epoch: 57  Training loss = 4.3609  Validation loss = 0.9422  \n",
      "\n",
      "Fold: 23  Epoch: 58  Training loss = 4.3606  Validation loss = 0.9419  \n",
      "\n",
      "Fold: 23  Epoch: 59  Training loss = 4.3602  Validation loss = 0.9415  \n",
      "\n",
      "Fold: 23  Epoch: 60  Training loss = 4.3598  Validation loss = 0.9411  \n",
      "\n",
      "Fold: 23  Epoch: 61  Training loss = 4.3594  Validation loss = 0.9408  \n",
      "\n",
      "Fold: 23  Epoch: 62  Training loss = 4.3591  Validation loss = 0.9405  \n",
      "\n",
      "Fold: 23  Epoch: 63  Training loss = 4.3587  Validation loss = 0.9401  \n",
      "\n",
      "Fold: 23  Epoch: 64  Training loss = 4.3584  Validation loss = 0.9398  \n",
      "\n",
      "Fold: 23  Epoch: 65  Training loss = 4.3581  Validation loss = 0.9395  \n",
      "\n",
      "Fold: 23  Epoch: 66  Training loss = 4.3576  Validation loss = 0.9391  \n",
      "\n",
      "Fold: 23  Epoch: 67  Training loss = 4.3573  Validation loss = 0.9388  \n",
      "\n",
      "Fold: 23  Epoch: 68  Training loss = 4.3568  Validation loss = 0.9384  \n",
      "\n",
      "Fold: 23  Epoch: 69  Training loss = 4.3566  Validation loss = 0.9381  \n",
      "\n",
      "Fold: 23  Epoch: 70  Training loss = 4.3561  Validation loss = 0.9377  \n",
      "\n",
      "Fold: 23  Epoch: 71  Training loss = 4.3558  Validation loss = 0.9374  \n",
      "\n",
      "Fold: 23  Epoch: 72  Training loss = 4.3554  Validation loss = 0.9370  \n",
      "\n",
      "Fold: 23  Epoch: 73  Training loss = 4.3551  Validation loss = 0.9368  \n",
      "\n",
      "Fold: 23  Epoch: 74  Training loss = 4.3548  Validation loss = 0.9364  \n",
      "\n",
      "Fold: 23  Epoch: 75  Training loss = 4.3543  Validation loss = 0.9359  \n",
      "\n",
      "Fold: 23  Epoch: 76  Training loss = 4.3539  Validation loss = 0.9356  \n",
      "\n",
      "Fold: 23  Epoch: 77  Training loss = 4.3537  Validation loss = 0.9353  \n",
      "\n",
      "Fold: 23  Epoch: 78  Training loss = 4.3534  Validation loss = 0.9350  \n",
      "\n",
      "Fold: 23  Epoch: 79  Training loss = 4.3531  Validation loss = 0.9347  \n",
      "\n",
      "Fold: 23  Epoch: 80  Training loss = 4.3526  Validation loss = 0.9343  \n",
      "\n",
      "Fold: 23  Epoch: 81  Training loss = 4.3523  Validation loss = 0.9340  \n",
      "\n",
      "Fold: 23  Epoch: 82  Training loss = 4.3519  Validation loss = 0.9337  \n",
      "\n",
      "Fold: 23  Epoch: 83  Training loss = 4.3515  Validation loss = 0.9333  \n",
      "\n",
      "Fold: 23  Epoch: 84  Training loss = 4.3511  Validation loss = 0.9330  \n",
      "\n",
      "Fold: 23  Epoch: 85  Training loss = 4.3509  Validation loss = 0.9327  \n",
      "\n",
      "Fold: 23  Epoch: 86  Training loss = 4.3505  Validation loss = 0.9324  \n",
      "\n",
      "Fold: 23  Epoch: 87  Training loss = 4.3501  Validation loss = 0.9320  \n",
      "\n",
      "Fold: 23  Epoch: 88  Training loss = 4.3497  Validation loss = 0.9316  \n",
      "\n",
      "Fold: 23  Epoch: 89  Training loss = 4.3493  Validation loss = 0.9313  \n",
      "\n",
      "Fold: 23  Epoch: 90  Training loss = 4.3490  Validation loss = 0.9310  \n",
      "\n",
      "Fold: 23  Epoch: 91  Training loss = 4.3487  Validation loss = 0.9307  \n",
      "\n",
      "Fold: 23  Epoch: 92  Training loss = 4.3485  Validation loss = 0.9305  \n",
      "\n",
      "Fold: 23  Epoch: 93  Training loss = 4.3482  Validation loss = 0.9303  \n",
      "\n",
      "Fold: 23  Epoch: 94  Training loss = 4.3477  Validation loss = 0.9298  \n",
      "\n",
      "Fold: 23  Epoch: 95  Training loss = 4.3472  Validation loss = 0.9294  \n",
      "\n",
      "Fold: 23  Epoch: 96  Training loss = 4.3469  Validation loss = 0.9291  \n",
      "\n",
      "Fold: 23  Epoch: 97  Training loss = 4.3465  Validation loss = 0.9288  \n",
      "\n",
      "Fold: 23  Epoch: 98  Training loss = 4.3462  Validation loss = 0.9284  \n",
      "\n",
      "Fold: 23  Epoch: 99  Training loss = 4.3457  Validation loss = 0.9280  \n",
      "\n",
      "Fold: 23  Epoch: 100  Training loss = 4.3453  Validation loss = 0.9276  \n",
      "\n",
      "Fold: 23  Epoch: 101  Training loss = 4.3450  Validation loss = 0.9273  \n",
      "\n",
      "Fold: 23  Epoch: 102  Training loss = 4.3447  Validation loss = 0.9271  \n",
      "\n",
      "Fold: 23  Epoch: 103  Training loss = 4.3445  Validation loss = 0.9268  \n",
      "\n",
      "Fold: 23  Epoch: 104  Training loss = 4.3441  Validation loss = 0.9265  \n",
      "\n",
      "Fold: 23  Epoch: 105  Training loss = 4.3438  Validation loss = 0.9262  \n",
      "\n",
      "Fold: 23  Epoch: 106  Training loss = 4.3435  Validation loss = 0.9259  \n",
      "\n",
      "Fold: 23  Epoch: 107  Training loss = 4.3431  Validation loss = 0.9256  \n",
      "\n",
      "Fold: 23  Epoch: 108  Training loss = 4.3428  Validation loss = 0.9253  \n",
      "\n",
      "Fold: 23  Epoch: 109  Training loss = 4.3425  Validation loss = 0.9249  \n",
      "\n",
      "Fold: 23  Epoch: 110  Training loss = 4.3421  Validation loss = 0.9245  \n",
      "\n",
      "Fold: 23  Epoch: 111  Training loss = 4.3418  Validation loss = 0.9242  \n",
      "\n",
      "Fold: 23  Epoch: 112  Training loss = 4.3413  Validation loss = 0.9238  \n",
      "\n",
      "Fold: 23  Epoch: 113  Training loss = 4.3410  Validation loss = 0.9235  \n",
      "\n",
      "Fold: 23  Epoch: 114  Training loss = 4.3407  Validation loss = 0.9231  \n",
      "\n",
      "Fold: 23  Epoch: 115  Training loss = 4.3403  Validation loss = 0.9227  \n",
      "\n",
      "Fold: 23  Epoch: 116  Training loss = 4.3400  Validation loss = 0.9224  \n",
      "\n",
      "Fold: 23  Epoch: 117  Training loss = 4.3397  Validation loss = 0.9221  \n",
      "\n",
      "Fold: 23  Epoch: 118  Training loss = 4.3393  Validation loss = 0.9218  \n",
      "\n",
      "Fold: 23  Epoch: 119  Training loss = 4.3389  Validation loss = 0.9214  \n",
      "\n",
      "Fold: 23  Epoch: 120  Training loss = 4.3385  Validation loss = 0.9210  \n",
      "\n",
      "Fold: 23  Epoch: 121  Training loss = 4.3382  Validation loss = 0.9207  \n",
      "\n",
      "Fold: 23  Epoch: 122  Training loss = 4.3378  Validation loss = 0.9204  \n",
      "\n",
      "Fold: 23  Epoch: 123  Training loss = 4.3375  Validation loss = 0.9200  \n",
      "\n",
      "Fold: 23  Epoch: 124  Training loss = 4.3370  Validation loss = 0.9196  \n",
      "\n",
      "Fold: 23  Epoch: 125  Training loss = 4.3366  Validation loss = 0.9193  \n",
      "\n",
      "Fold: 23  Epoch: 126  Training loss = 4.3362  Validation loss = 0.9189  \n",
      "\n",
      "Fold: 23  Epoch: 127  Training loss = 4.3359  Validation loss = 0.9186  \n",
      "\n",
      "Fold: 23  Epoch: 128  Training loss = 4.3356  Validation loss = 0.9183  \n",
      "\n",
      "Fold: 23  Epoch: 129  Training loss = 4.3353  Validation loss = 0.9180  \n",
      "\n",
      "Fold: 23  Epoch: 130  Training loss = 4.3350  Validation loss = 0.9177  \n",
      "\n",
      "Fold: 23  Epoch: 131  Training loss = 4.3347  Validation loss = 0.9174  \n",
      "\n",
      "Fold: 23  Epoch: 132  Training loss = 4.3344  Validation loss = 0.9171  \n",
      "\n",
      "Fold: 23  Epoch: 133  Training loss = 4.3341  Validation loss = 0.9168  \n",
      "\n",
      "Fold: 23  Epoch: 134  Training loss = 4.3337  Validation loss = 0.9165  \n",
      "\n",
      "Fold: 23  Epoch: 135  Training loss = 4.3334  Validation loss = 0.9162  \n",
      "\n",
      "Fold: 23  Epoch: 136  Training loss = 4.3330  Validation loss = 0.9159  \n",
      "\n",
      "Fold: 23  Epoch: 137  Training loss = 4.3327  Validation loss = 0.9156  \n",
      "\n",
      "Fold: 23  Epoch: 138  Training loss = 4.3323  Validation loss = 0.9153  \n",
      "\n",
      "Fold: 23  Epoch: 139  Training loss = 4.3320  Validation loss = 0.9149  \n",
      "\n",
      "Fold: 23  Epoch: 140  Training loss = 4.3316  Validation loss = 0.9146  \n",
      "\n",
      "Fold: 23  Epoch: 141  Training loss = 4.3312  Validation loss = 0.9142  \n",
      "\n",
      "Fold: 23  Epoch: 142  Training loss = 4.3309  Validation loss = 0.9140  \n",
      "\n",
      "Fold: 23  Epoch: 143  Training loss = 4.3306  Validation loss = 0.9137  \n",
      "\n",
      "Fold: 23  Epoch: 144  Training loss = 4.3303  Validation loss = 0.9134  \n",
      "\n",
      "Fold: 23  Epoch: 145  Training loss = 4.3298  Validation loss = 0.9130  \n",
      "\n",
      "Fold: 23  Epoch: 146  Training loss = 4.3294  Validation loss = 0.9127  \n",
      "\n",
      "Fold: 23  Epoch: 147  Training loss = 4.3290  Validation loss = 0.9123  \n",
      "\n",
      "Fold: 23  Epoch: 148  Training loss = 4.3286  Validation loss = 0.9119  \n",
      "\n",
      "Fold: 23  Epoch: 149  Training loss = 4.3283  Validation loss = 0.9116  \n",
      "\n",
      "Fold: 23  Epoch: 150  Training loss = 4.3280  Validation loss = 0.9113  \n",
      "\n",
      "Fold: 23  Epoch: 151  Training loss = 4.3276  Validation loss = 0.9110  \n",
      "\n",
      "Fold: 23  Epoch: 152  Training loss = 4.3272  Validation loss = 0.9106  \n",
      "\n",
      "Fold: 23  Epoch: 153  Training loss = 4.3268  Validation loss = 0.9103  \n",
      "\n",
      "Fold: 23  Epoch: 154  Training loss = 4.3264  Validation loss = 0.9100  \n",
      "\n",
      "Fold: 23  Epoch: 155  Training loss = 4.3261  Validation loss = 0.9097  \n",
      "\n",
      "Fold: 23  Epoch: 156  Training loss = 4.3256  Validation loss = 0.9093  \n",
      "\n",
      "Fold: 23  Epoch: 157  Training loss = 4.3254  Validation loss = 0.9090  \n",
      "\n",
      "Fold: 23  Epoch: 158  Training loss = 4.3250  Validation loss = 0.9087  \n",
      "\n",
      "Fold: 23  Epoch: 159  Training loss = 4.3246  Validation loss = 0.9083  \n",
      "\n",
      "Fold: 23  Epoch: 160  Training loss = 4.3242  Validation loss = 0.9080  \n",
      "\n",
      "Fold: 23  Epoch: 161  Training loss = 4.3238  Validation loss = 0.9077  \n",
      "\n",
      "Fold: 23  Epoch: 162  Training loss = 4.3235  Validation loss = 0.9075  \n",
      "\n",
      "Fold: 23  Epoch: 163  Training loss = 4.3231  Validation loss = 0.9071  \n",
      "\n",
      "Fold: 23  Epoch: 164  Training loss = 4.3227  Validation loss = 0.9068  \n",
      "\n",
      "Fold: 23  Epoch: 165  Training loss = 4.3223  Validation loss = 0.9064  \n",
      "\n",
      "Fold: 23  Epoch: 166  Training loss = 4.3219  Validation loss = 0.9061  \n",
      "\n",
      "Fold: 23  Epoch: 167  Training loss = 4.3216  Validation loss = 0.9058  \n",
      "\n",
      "Fold: 23  Epoch: 168  Training loss = 4.3211  Validation loss = 0.9054  \n",
      "\n",
      "Fold: 23  Epoch: 169  Training loss = 4.3209  Validation loss = 0.9051  \n",
      "\n",
      "Fold: 23  Epoch: 170  Training loss = 4.3205  Validation loss = 0.9047  \n",
      "\n",
      "Fold: 23  Epoch: 171  Training loss = 4.3201  Validation loss = 0.9043  \n",
      "\n",
      "Fold: 23  Epoch: 172  Training loss = 4.3197  Validation loss = 0.9039  \n",
      "\n",
      "Fold: 23  Epoch: 173  Training loss = 4.3194  Validation loss = 0.9036  \n",
      "\n",
      "Fold: 23  Epoch: 174  Training loss = 4.3189  Validation loss = 0.9032  \n",
      "\n",
      "Fold: 23  Epoch: 175  Training loss = 4.3185  Validation loss = 0.9029  \n",
      "\n",
      "Fold: 23  Epoch: 176  Training loss = 4.3182  Validation loss = 0.9026  \n",
      "\n",
      "Fold: 23  Epoch: 177  Training loss = 4.3179  Validation loss = 0.9024  \n",
      "\n",
      "Fold: 23  Epoch: 178  Training loss = 4.3177  Validation loss = 0.9022  \n",
      "\n",
      "Fold: 23  Epoch: 179  Training loss = 4.3174  Validation loss = 0.9018  \n",
      "\n",
      "Fold: 23  Epoch: 180  Training loss = 4.3170  Validation loss = 0.9015  \n",
      "\n",
      "Fold: 23  Epoch: 181  Training loss = 4.3166  Validation loss = 0.9011  \n",
      "\n",
      "Fold: 23  Epoch: 182  Training loss = 4.3163  Validation loss = 0.9008  \n",
      "\n",
      "Fold: 23  Epoch: 183  Training loss = 4.3159  Validation loss = 0.9004  \n",
      "\n",
      "Fold: 23  Epoch: 184  Training loss = 4.3155  Validation loss = 0.9001  \n",
      "\n",
      "Fold: 23  Epoch: 185  Training loss = 4.3150  Validation loss = 0.8997  \n",
      "\n",
      "Fold: 23  Epoch: 186  Training loss = 4.3146  Validation loss = 0.8994  \n",
      "\n",
      "Fold: 23  Epoch: 187  Training loss = 4.3141  Validation loss = 0.8990  \n",
      "\n",
      "Fold: 23  Epoch: 188  Training loss = 4.3139  Validation loss = 0.8987  \n",
      "\n",
      "Fold: 23  Epoch: 189  Training loss = 4.3135  Validation loss = 0.8984  \n",
      "\n",
      "Fold: 23  Epoch: 190  Training loss = 4.3131  Validation loss = 0.8980  \n",
      "\n",
      "Fold: 23  Epoch: 191  Training loss = 4.3127  Validation loss = 0.8977  \n",
      "\n",
      "Fold: 23  Epoch: 192  Training loss = 4.3124  Validation loss = 0.8975  \n",
      "\n",
      "Fold: 23  Epoch: 193  Training loss = 4.3121  Validation loss = 0.8972  \n",
      "\n",
      "Fold: 23  Epoch: 194  Training loss = 4.3117  Validation loss = 0.8969  \n",
      "\n",
      "Fold: 23  Epoch: 195  Training loss = 4.3114  Validation loss = 0.8966  \n",
      "\n",
      "Fold: 23  Epoch: 196  Training loss = 4.3111  Validation loss = 0.8963  \n",
      "\n",
      "Fold: 23  Epoch: 197  Training loss = 4.3107  Validation loss = 0.8960  \n",
      "\n",
      "Fold: 23  Epoch: 198  Training loss = 4.3104  Validation loss = 0.8957  \n",
      "\n",
      "Fold: 23  Epoch: 199  Training loss = 4.3102  Validation loss = 0.8955  \n",
      "\n",
      "Fold: 23  Epoch: 200  Training loss = 4.3099  Validation loss = 0.8953  \n",
      "\n",
      "Fold: 23  Epoch: 201  Training loss = 4.3094  Validation loss = 0.8949  \n",
      "\n",
      "Fold: 23  Epoch: 202  Training loss = 4.3090  Validation loss = 0.8945  \n",
      "\n",
      "Fold: 23  Epoch: 203  Training loss = 4.3087  Validation loss = 0.8942  \n",
      "\n",
      "Fold: 23  Epoch: 204  Training loss = 4.3084  Validation loss = 0.8940  \n",
      "\n",
      "Fold: 23  Epoch: 205  Training loss = 4.3080  Validation loss = 0.8937  \n",
      "\n",
      "Fold: 23  Epoch: 206  Training loss = 4.3077  Validation loss = 0.8934  \n",
      "\n",
      "Fold: 23  Epoch: 207  Training loss = 4.3073  Validation loss = 0.8931  \n",
      "\n",
      "Fold: 23  Epoch: 208  Training loss = 4.3070  Validation loss = 0.8928  \n",
      "\n",
      "Fold: 23  Epoch: 209  Training loss = 4.3067  Validation loss = 0.8925  \n",
      "\n",
      "Fold: 23  Epoch: 210  Training loss = 4.3063  Validation loss = 0.8923  \n",
      "\n",
      "Fold: 23  Epoch: 211  Training loss = 4.3060  Validation loss = 0.8920  \n",
      "\n",
      "Fold: 23  Epoch: 212  Training loss = 4.3056  Validation loss = 0.8916  \n",
      "\n",
      "Fold: 23  Epoch: 213  Training loss = 4.3052  Validation loss = 0.8912  \n",
      "\n",
      "Fold: 23  Epoch: 214  Training loss = 4.3049  Validation loss = 0.8909  \n",
      "\n",
      "Fold: 23  Epoch: 215  Training loss = 4.3045  Validation loss = 0.8905  \n",
      "\n",
      "Fold: 23  Epoch: 216  Training loss = 4.3042  Validation loss = 0.8902  \n",
      "\n",
      "Fold: 23  Epoch: 217  Training loss = 4.3038  Validation loss = 0.8899  \n",
      "\n",
      "Fold: 23  Epoch: 218  Training loss = 4.3035  Validation loss = 0.8896  \n",
      "\n",
      "Fold: 23  Epoch: 219  Training loss = 4.3031  Validation loss = 0.8893  \n",
      "\n",
      "Fold: 23  Epoch: 220  Training loss = 4.3027  Validation loss = 0.8889  \n",
      "\n",
      "Fold: 23  Epoch: 221  Training loss = 4.3024  Validation loss = 0.8887  \n",
      "\n",
      "Fold: 23  Epoch: 222  Training loss = 4.3020  Validation loss = 0.8883  \n",
      "\n",
      "Fold: 23  Epoch: 223  Training loss = 4.3017  Validation loss = 0.8880  \n",
      "\n",
      "Fold: 23  Epoch: 224  Training loss = 4.3012  Validation loss = 0.8876  \n",
      "\n",
      "Fold: 23  Epoch: 225  Training loss = 4.3010  Validation loss = 0.8874  \n",
      "\n",
      "Fold: 23  Epoch: 226  Training loss = 4.3007  Validation loss = 0.8872  \n",
      "\n",
      "Fold: 23  Epoch: 227  Training loss = 4.3003  Validation loss = 0.8868  \n",
      "\n",
      "Fold: 23  Epoch: 228  Training loss = 4.2999  Validation loss = 0.8865  \n",
      "\n",
      "Fold: 23  Epoch: 229  Training loss = 4.2995  Validation loss = 0.8861  \n",
      "\n",
      "Fold: 23  Epoch: 230  Training loss = 4.2992  Validation loss = 0.8858  \n",
      "\n",
      "Fold: 23  Epoch: 231  Training loss = 4.2987  Validation loss = 0.8854  \n",
      "\n",
      "Fold: 23  Epoch: 232  Training loss = 4.2984  Validation loss = 0.8852  \n",
      "\n",
      "Fold: 23  Epoch: 233  Training loss = 4.2982  Validation loss = 0.8849  \n",
      "\n",
      "Fold: 23  Epoch: 234  Training loss = 4.2978  Validation loss = 0.8846  \n",
      "\n",
      "Fold: 23  Epoch: 235  Training loss = 4.2975  Validation loss = 0.8843  \n",
      "\n",
      "Fold: 23  Epoch: 236  Training loss = 4.2971  Validation loss = 0.8840  \n",
      "\n",
      "Fold: 23  Epoch: 237  Training loss = 4.2967  Validation loss = 0.8837  \n",
      "\n",
      "Fold: 23  Epoch: 238  Training loss = 4.2964  Validation loss = 0.8834  \n",
      "\n",
      "Fold: 23  Epoch: 239  Training loss = 4.2961  Validation loss = 0.8831  \n",
      "\n",
      "Fold: 23  Epoch: 240  Training loss = 4.2958  Validation loss = 0.8828  \n",
      "\n",
      "Fold: 23  Epoch: 241  Training loss = 4.2955  Validation loss = 0.8825  \n",
      "\n",
      "Fold: 23  Epoch: 242  Training loss = 4.2951  Validation loss = 0.8822  \n",
      "\n",
      "Fold: 23  Epoch: 243  Training loss = 4.2947  Validation loss = 0.8819  \n",
      "\n",
      "Fold: 23  Epoch: 244  Training loss = 4.2943  Validation loss = 0.8815  \n",
      "\n",
      "Fold: 23  Epoch: 245  Training loss = 4.2940  Validation loss = 0.8812  \n",
      "\n",
      "Fold: 23  Epoch: 246  Training loss = 4.2936  Validation loss = 0.8809  \n",
      "\n",
      "Fold: 23  Epoch: 247  Training loss = 4.2932  Validation loss = 0.8806  \n",
      "\n",
      "Fold: 23  Epoch: 248  Training loss = 4.2928  Validation loss = 0.8802  \n",
      "\n",
      "Fold: 23  Epoch: 249  Training loss = 4.2923  Validation loss = 0.8798  \n",
      "\n",
      "Fold: 23  Epoch: 250  Training loss = 4.2918  Validation loss = 0.8795  \n",
      "\n",
      "Fold: 23  Epoch: 251  Training loss = 4.2914  Validation loss = 0.8791  \n",
      "\n",
      "Fold: 23  Epoch: 252  Training loss = 4.2911  Validation loss = 0.8788  \n",
      "\n",
      "Fold: 23  Epoch: 253  Training loss = 4.2907  Validation loss = 0.8785  \n",
      "\n",
      "Fold: 23  Epoch: 254  Training loss = 4.2903  Validation loss = 0.8782  \n",
      "\n",
      "Fold: 23  Epoch: 255  Training loss = 4.2899  Validation loss = 0.8778  \n",
      "\n",
      "Fold: 23  Epoch: 256  Training loss = 4.2895  Validation loss = 0.8775  \n",
      "\n",
      "Fold: 23  Epoch: 257  Training loss = 4.2891  Validation loss = 0.8772  \n",
      "\n",
      "Fold: 23  Epoch: 258  Training loss = 4.2887  Validation loss = 0.8769  \n",
      "\n",
      "Fold: 23  Epoch: 259  Training loss = 4.2884  Validation loss = 0.8766  \n",
      "\n",
      "Fold: 23  Epoch: 260  Training loss = 4.2880  Validation loss = 0.8763  \n",
      "\n",
      "Fold: 23  Epoch: 261  Training loss = 4.2877  Validation loss = 0.8760  \n",
      "\n",
      "Fold: 23  Epoch: 262  Training loss = 4.2875  Validation loss = 0.8758  \n",
      "\n",
      "Fold: 23  Epoch: 263  Training loss = 4.2871  Validation loss = 0.8754  \n",
      "\n",
      "Fold: 23  Epoch: 264  Training loss = 4.2868  Validation loss = 0.8751  \n",
      "\n",
      "Fold: 23  Epoch: 265  Training loss = 4.2864  Validation loss = 0.8748  \n",
      "\n",
      "Fold: 23  Epoch: 266  Training loss = 4.2862  Validation loss = 0.8746  \n",
      "\n",
      "Fold: 23  Epoch: 267  Training loss = 4.2859  Validation loss = 0.8744  \n",
      "\n",
      "Fold: 23  Epoch: 268  Training loss = 4.2855  Validation loss = 0.8741  \n",
      "\n",
      "Fold: 23  Epoch: 269  Training loss = 4.2851  Validation loss = 0.8737  \n",
      "\n",
      "Fold: 23  Epoch: 270  Training loss = 4.2849  Validation loss = 0.8736  \n",
      "\n",
      "Fold: 23  Epoch: 271  Training loss = 4.2846  Validation loss = 0.8733  \n",
      "\n",
      "Fold: 23  Epoch: 272  Training loss = 4.2842  Validation loss = 0.8730  \n",
      "\n",
      "Fold: 23  Epoch: 273  Training loss = 4.2838  Validation loss = 0.8727  \n",
      "\n",
      "Fold: 23  Epoch: 274  Training loss = 4.2834  Validation loss = 0.8723  \n",
      "\n",
      "Fold: 23  Epoch: 275  Training loss = 4.2832  Validation loss = 0.8720  \n",
      "\n",
      "Fold: 23  Epoch: 276  Training loss = 4.2828  Validation loss = 0.8716  \n",
      "\n",
      "Fold: 23  Epoch: 277  Training loss = 4.2825  Validation loss = 0.8714  \n",
      "\n",
      "Fold: 23  Epoch: 278  Training loss = 4.2822  Validation loss = 0.8711  \n",
      "\n",
      "Fold: 23  Epoch: 279  Training loss = 4.2818  Validation loss = 0.8708  \n",
      "\n",
      "Fold: 23  Epoch: 280  Training loss = 4.2814  Validation loss = 0.8705  \n",
      "\n",
      "Fold: 23  Epoch: 281  Training loss = 4.2811  Validation loss = 0.8701  \n",
      "\n",
      "Fold: 23  Epoch: 282  Training loss = 4.2808  Validation loss = 0.8699  \n",
      "\n",
      "Fold: 23  Epoch: 283  Training loss = 4.2804  Validation loss = 0.8695  \n",
      "\n",
      "Fold: 23  Epoch: 284  Training loss = 4.2801  Validation loss = 0.8692  \n",
      "\n",
      "Fold: 23  Epoch: 285  Training loss = 4.2797  Validation loss = 0.8688  \n",
      "\n",
      "Fold: 23  Epoch: 286  Training loss = 4.2794  Validation loss = 0.8685  \n",
      "\n",
      "Fold: 23  Epoch: 287  Training loss = 4.2791  Validation loss = 0.8682  \n",
      "\n",
      "Fold: 23  Epoch: 288  Training loss = 4.2788  Validation loss = 0.8679  \n",
      "\n",
      "Fold: 23  Epoch: 289  Training loss = 4.2785  Validation loss = 0.8676  \n",
      "\n",
      "Fold: 23  Epoch: 290  Training loss = 4.2781  Validation loss = 0.8672  \n",
      "\n",
      "Fold: 23  Epoch: 291  Training loss = 4.2778  Validation loss = 0.8669  \n",
      "\n",
      "Fold: 23  Epoch: 292  Training loss = 4.2774  Validation loss = 0.8666  \n",
      "\n",
      "Fold: 23  Epoch: 293  Training loss = 4.2770  Validation loss = 0.8663  \n",
      "\n",
      "Fold: 23  Epoch: 294  Training loss = 4.2766  Validation loss = 0.8660  \n",
      "\n",
      "Fold: 23  Epoch: 295  Training loss = 4.2763  Validation loss = 0.8657  \n",
      "\n",
      "Fold: 23  Epoch: 296  Training loss = 4.2760  Validation loss = 0.8655  \n",
      "\n",
      "Fold: 23  Epoch: 297  Training loss = 4.2757  Validation loss = 0.8651  \n",
      "\n",
      "Fold: 23  Epoch: 298  Training loss = 4.2753  Validation loss = 0.8648  \n",
      "\n",
      "Fold: 23  Epoch: 299  Training loss = 4.2749  Validation loss = 0.8645  \n",
      "\n",
      "Fold: 23  Epoch: 300  Training loss = 4.2745  Validation loss = 0.8642  \n",
      "\n",
      "Fold: 23  Epoch: 301  Training loss = 4.2742  Validation loss = 0.8639  \n",
      "\n",
      "Fold: 23  Epoch: 302  Training loss = 4.2739  Validation loss = 0.8636  \n",
      "\n",
      "Fold: 23  Epoch: 303  Training loss = 4.2735  Validation loss = 0.8633  \n",
      "\n",
      "Fold: 23  Epoch: 304  Training loss = 4.2733  Validation loss = 0.8631  \n",
      "\n",
      "Fold: 23  Epoch: 305  Training loss = 4.2728  Validation loss = 0.8627  \n",
      "\n",
      "Fold: 23  Epoch: 306  Training loss = 4.2725  Validation loss = 0.8624  \n",
      "\n",
      "Fold: 23  Epoch: 307  Training loss = 4.2720  Validation loss = 0.8621  \n",
      "\n",
      "Fold: 23  Epoch: 308  Training loss = 4.2717  Validation loss = 0.8618  \n",
      "\n",
      "Fold: 23  Epoch: 309  Training loss = 4.2714  Validation loss = 0.8615  \n",
      "\n",
      "Fold: 23  Epoch: 310  Training loss = 4.2712  Validation loss = 0.8613  \n",
      "\n",
      "Fold: 23  Epoch: 311  Training loss = 4.2709  Validation loss = 0.8610  \n",
      "\n",
      "Fold: 23  Epoch: 312  Training loss = 4.2706  Validation loss = 0.8608  \n",
      "\n",
      "Fold: 23  Epoch: 313  Training loss = 4.2702  Validation loss = 0.8605  \n",
      "\n",
      "Fold: 23  Epoch: 314  Training loss = 4.2699  Validation loss = 0.8601  \n",
      "\n",
      "Fold: 23  Epoch: 315  Training loss = 4.2697  Validation loss = 0.8599  \n",
      "\n",
      "Fold: 23  Epoch: 316  Training loss = 4.2694  Validation loss = 0.8596  \n",
      "\n",
      "Fold: 23  Epoch: 317  Training loss = 4.2691  Validation loss = 0.8594  \n",
      "\n",
      "Fold: 23  Epoch: 318  Training loss = 4.2687  Validation loss = 0.8591  \n",
      "\n",
      "Fold: 23  Epoch: 319  Training loss = 4.2683  Validation loss = 0.8587  \n",
      "\n",
      "Fold: 23  Epoch: 320  Training loss = 4.2679  Validation loss = 0.8584  \n",
      "\n",
      "Fold: 23  Epoch: 321  Training loss = 4.2677  Validation loss = 0.8581  \n",
      "\n",
      "Fold: 23  Epoch: 322  Training loss = 4.2673  Validation loss = 0.8578  \n",
      "\n",
      "Fold: 23  Epoch: 323  Training loss = 4.2669  Validation loss = 0.8576  \n",
      "\n",
      "Fold: 23  Epoch: 324  Training loss = 4.2666  Validation loss = 0.8572  \n",
      "\n",
      "Fold: 23  Epoch: 325  Training loss = 4.2662  Validation loss = 0.8569  \n",
      "\n",
      "Fold: 23  Epoch: 326  Training loss = 4.2658  Validation loss = 0.8566  \n",
      "\n",
      "Fold: 23  Epoch: 327  Training loss = 4.2654  Validation loss = 0.8562  \n",
      "\n",
      "Fold: 23  Epoch: 328  Training loss = 4.2650  Validation loss = 0.8559  \n",
      "\n",
      "Fold: 23  Epoch: 329  Training loss = 4.2647  Validation loss = 0.8557  \n",
      "\n",
      "Fold: 23  Epoch: 330  Training loss = 4.2643  Validation loss = 0.8554  \n",
      "\n",
      "Fold: 23  Epoch: 331  Training loss = 4.2640  Validation loss = 0.8551  \n",
      "\n",
      "Fold: 23  Epoch: 332  Training loss = 4.2636  Validation loss = 0.8547  \n",
      "\n",
      "Fold: 23  Epoch: 333  Training loss = 4.2633  Validation loss = 0.8545  \n",
      "\n",
      "Fold: 23  Epoch: 334  Training loss = 4.2630  Validation loss = 0.8542  \n",
      "\n",
      "Fold: 23  Epoch: 335  Training loss = 4.2626  Validation loss = 0.8539  \n",
      "\n",
      "Fold: 23  Epoch: 336  Training loss = 4.2624  Validation loss = 0.8537  \n",
      "\n",
      "Fold: 23  Epoch: 337  Training loss = 4.2620  Validation loss = 0.8534  \n",
      "\n",
      "Fold: 23  Epoch: 338  Training loss = 4.2617  Validation loss = 0.8531  \n",
      "\n",
      "Fold: 23  Epoch: 339  Training loss = 4.2614  Validation loss = 0.8529  \n",
      "\n",
      "Fold: 23  Epoch: 340  Training loss = 4.2610  Validation loss = 0.8526  \n",
      "\n",
      "Fold: 23  Epoch: 341  Training loss = 4.2608  Validation loss = 0.8524  \n",
      "\n",
      "Fold: 23  Epoch: 342  Training loss = 4.2604  Validation loss = 0.8520  \n",
      "\n",
      "Fold: 23  Epoch: 343  Training loss = 4.2602  Validation loss = 0.8517  \n",
      "\n",
      "Fold: 23  Epoch: 344  Training loss = 4.2598  Validation loss = 0.8513  \n",
      "\n",
      "Fold: 23  Epoch: 345  Training loss = 4.2596  Validation loss = 0.8511  \n",
      "\n",
      "Fold: 23  Epoch: 346  Training loss = 4.2591  Validation loss = 0.8507  \n",
      "\n",
      "Fold: 23  Epoch: 347  Training loss = 4.2589  Validation loss = 0.8505  \n",
      "\n",
      "Fold: 23  Epoch: 348  Training loss = 4.2585  Validation loss = 0.8501  \n",
      "\n",
      "Fold: 23  Epoch: 349  Training loss = 4.2582  Validation loss = 0.8498  \n",
      "\n",
      "Fold: 23  Epoch: 350  Training loss = 4.2578  Validation loss = 0.8495  \n",
      "\n",
      "Fold: 23  Epoch: 351  Training loss = 4.2576  Validation loss = 0.8493  \n",
      "\n",
      "Fold: 23  Epoch: 352  Training loss = 4.2572  Validation loss = 0.8489  \n",
      "\n",
      "Fold: 23  Epoch: 353  Training loss = 4.2568  Validation loss = 0.8486  \n",
      "\n",
      "Fold: 23  Epoch: 354  Training loss = 4.2564  Validation loss = 0.8483  \n",
      "\n",
      "Fold: 23  Epoch: 355  Training loss = 4.2562  Validation loss = 0.8481  \n",
      "\n",
      "Fold: 23  Epoch: 356  Training loss = 4.2559  Validation loss = 0.8479  \n",
      "\n",
      "Fold: 23  Epoch: 357  Training loss = 4.2556  Validation loss = 0.8476  \n",
      "\n",
      "Fold: 23  Epoch: 358  Training loss = 4.2552  Validation loss = 0.8473  \n",
      "\n",
      "Fold: 23  Epoch: 359  Training loss = 4.2549  Validation loss = 0.8470  \n",
      "\n",
      "Fold: 23  Epoch: 360  Training loss = 4.2546  Validation loss = 0.8467  \n",
      "\n",
      "Fold: 23  Epoch: 361  Training loss = 4.2543  Validation loss = 0.8464  \n",
      "\n",
      "Fold: 23  Epoch: 362  Training loss = 4.2539  Validation loss = 0.8460  \n",
      "\n",
      "Fold: 23  Epoch: 363  Training loss = 4.2535  Validation loss = 0.8456  \n",
      "\n",
      "Fold: 23  Epoch: 364  Training loss = 4.2531  Validation loss = 0.8454  \n",
      "\n",
      "Fold: 23  Epoch: 365  Training loss = 4.2528  Validation loss = 0.8450  \n",
      "\n",
      "Fold: 23  Epoch: 366  Training loss = 4.2525  Validation loss = 0.8447  \n",
      "\n",
      "Fold: 23  Epoch: 367  Training loss = 4.2521  Validation loss = 0.8444  \n",
      "\n",
      "Fold: 23  Epoch: 368  Training loss = 4.2518  Validation loss = 0.8442  \n",
      "\n",
      "Fold: 23  Epoch: 369  Training loss = 4.2516  Validation loss = 0.8440  \n",
      "\n",
      "Fold: 23  Epoch: 370  Training loss = 4.2513  Validation loss = 0.8436  \n",
      "\n",
      "Fold: 23  Epoch: 371  Training loss = 4.2510  Validation loss = 0.8435  \n",
      "\n",
      "Fold: 23  Epoch: 372  Training loss = 4.2506  Validation loss = 0.8432  \n",
      "\n",
      "Fold: 23  Epoch: 373  Training loss = 4.2504  Validation loss = 0.8429  \n",
      "\n",
      "Fold: 23  Epoch: 374  Training loss = 4.2501  Validation loss = 0.8426  \n",
      "\n",
      "Fold: 23  Epoch: 375  Training loss = 4.2499  Validation loss = 0.8424  \n",
      "\n",
      "Fold: 23  Epoch: 376  Training loss = 4.2496  Validation loss = 0.8421  \n",
      "\n",
      "Fold: 23  Epoch: 377  Training loss = 4.2492  Validation loss = 0.8418  \n",
      "\n",
      "Fold: 23  Epoch: 378  Training loss = 4.2488  Validation loss = 0.8415  \n",
      "\n",
      "Fold: 23  Epoch: 379  Training loss = 4.2486  Validation loss = 0.8413  \n",
      "\n",
      "Fold: 23  Epoch: 380  Training loss = 4.2483  Validation loss = 0.8410  \n",
      "\n",
      "Fold: 23  Epoch: 381  Training loss = 4.2480  Validation loss = 0.8408  \n",
      "\n",
      "Fold: 23  Epoch: 382  Training loss = 4.2475  Validation loss = 0.8405  \n",
      "\n",
      "Fold: 23  Epoch: 383  Training loss = 4.2474  Validation loss = 0.8403  \n",
      "\n",
      "Fold: 23  Epoch: 384  Training loss = 4.2470  Validation loss = 0.8399  \n",
      "\n",
      "Fold: 23  Epoch: 385  Training loss = 4.2467  Validation loss = 0.8397  \n",
      "\n",
      "Fold: 23  Epoch: 386  Training loss = 4.2464  Validation loss = 0.8394  \n",
      "\n",
      "Fold: 23  Epoch: 387  Training loss = 4.2460  Validation loss = 0.8391  \n",
      "\n",
      "Fold: 23  Epoch: 388  Training loss = 4.2457  Validation loss = 0.8388  \n",
      "\n",
      "Fold: 23  Epoch: 389  Training loss = 4.2454  Validation loss = 0.8386  \n",
      "\n",
      "Fold: 23  Epoch: 390  Training loss = 4.2451  Validation loss = 0.8382  \n",
      "\n",
      "Fold: 23  Epoch: 391  Training loss = 4.2447  Validation loss = 0.8379  \n",
      "\n",
      "Fold: 23  Epoch: 392  Training loss = 4.2444  Validation loss = 0.8376  \n",
      "\n",
      "Fold: 23  Epoch: 393  Training loss = 4.2441  Validation loss = 0.8374  \n",
      "\n",
      "Fold: 23  Epoch: 394  Training loss = 4.2438  Validation loss = 0.8371  \n",
      "\n",
      "Fold: 23  Epoch: 395  Training loss = 4.2433  Validation loss = 0.8368  \n",
      "\n",
      "Fold: 23  Epoch: 396  Training loss = 4.2429  Validation loss = 0.8364  \n",
      "\n",
      "Fold: 23  Epoch: 397  Training loss = 4.2426  Validation loss = 0.8361  \n",
      "\n",
      "Fold: 23  Epoch: 398  Training loss = 4.2422  Validation loss = 0.8359  \n",
      "\n",
      "Fold: 23  Epoch: 399  Training loss = 4.2420  Validation loss = 0.8358  \n",
      "\n",
      "Fold: 23  Epoch: 400  Training loss = 4.2418  Validation loss = 0.8355  \n",
      "\n",
      "Fold: 23  Epoch: 401  Training loss = 4.2415  Validation loss = 0.8353  \n",
      "\n",
      "Fold: 23  Epoch: 402  Training loss = 4.2412  Validation loss = 0.8351  \n",
      "\n",
      "Fold: 23  Epoch: 403  Training loss = 4.2408  Validation loss = 0.8348  \n",
      "\n",
      "Fold: 23  Epoch: 404  Training loss = 4.2405  Validation loss = 0.8345  \n",
      "\n",
      "Fold: 23  Epoch: 405  Training loss = 4.2401  Validation loss = 0.8342  \n",
      "\n",
      "Fold: 23  Epoch: 406  Training loss = 4.2398  Validation loss = 0.8340  \n",
      "\n",
      "Fold: 23  Epoch: 407  Training loss = 4.2395  Validation loss = 0.8338  \n",
      "\n",
      "Fold: 23  Epoch: 408  Training loss = 4.2392  Validation loss = 0.8335  \n",
      "\n",
      "Fold: 23  Epoch: 409  Training loss = 4.2389  Validation loss = 0.8332  \n",
      "\n",
      "Fold: 23  Epoch: 410  Training loss = 4.2386  Validation loss = 0.8329  \n",
      "\n",
      "Fold: 23  Epoch: 411  Training loss = 4.2383  Validation loss = 0.8327  \n",
      "\n",
      "Fold: 23  Epoch: 412  Training loss = 4.2379  Validation loss = 0.8324  \n",
      "\n",
      "Fold: 23  Epoch: 413  Training loss = 4.2375  Validation loss = 0.8320  \n",
      "\n",
      "Fold: 23  Epoch: 414  Training loss = 4.2372  Validation loss = 0.8317  \n",
      "\n",
      "Fold: 23  Epoch: 415  Training loss = 4.2369  Validation loss = 0.8314  \n",
      "\n",
      "Fold: 23  Epoch: 416  Training loss = 4.2365  Validation loss = 0.8311  \n",
      "\n",
      "Fold: 23  Epoch: 417  Training loss = 4.2362  Validation loss = 0.8309  \n",
      "\n",
      "Fold: 23  Epoch: 418  Training loss = 4.2360  Validation loss = 0.8306  \n",
      "\n",
      "Fold: 23  Epoch: 419  Training loss = 4.2356  Validation loss = 0.8303  \n",
      "\n",
      "Fold: 23  Epoch: 420  Training loss = 4.2353  Validation loss = 0.8300  \n",
      "\n",
      "Fold: 23  Epoch: 421  Training loss = 4.2350  Validation loss = 0.8298  \n",
      "\n",
      "Fold: 23  Epoch: 422  Training loss = 4.2346  Validation loss = 0.8295  \n",
      "\n",
      "Fold: 23  Epoch: 423  Training loss = 4.2342  Validation loss = 0.8292  \n",
      "\n",
      "Fold: 23  Epoch: 424  Training loss = 4.2338  Validation loss = 0.8289  \n",
      "\n",
      "Fold: 23  Epoch: 425  Training loss = 4.2335  Validation loss = 0.8286  \n",
      "\n",
      "Fold: 23  Epoch: 426  Training loss = 4.2331  Validation loss = 0.8283  \n",
      "\n",
      "Fold: 23  Epoch: 427  Training loss = 4.2328  Validation loss = 0.8280  \n",
      "\n",
      "Fold: 23  Epoch: 428  Training loss = 4.2324  Validation loss = 0.8277  \n",
      "\n",
      "Fold: 23  Epoch: 429  Training loss = 4.2320  Validation loss = 0.8274  \n",
      "\n",
      "Fold: 23  Epoch: 430  Training loss = 4.2316  Validation loss = 0.8272  \n",
      "\n",
      "Fold: 23  Epoch: 431  Training loss = 4.2313  Validation loss = 0.8269  \n",
      "\n",
      "Fold: 23  Epoch: 432  Training loss = 4.2311  Validation loss = 0.8267  \n",
      "\n",
      "Fold: 23  Epoch: 433  Training loss = 4.2308  Validation loss = 0.8264  \n",
      "\n",
      "Fold: 23  Epoch: 434  Training loss = 4.2304  Validation loss = 0.8261  \n",
      "\n",
      "Fold: 23  Epoch: 435  Training loss = 4.2301  Validation loss = 0.8258  \n",
      "\n",
      "Fold: 23  Epoch: 436  Training loss = 4.2298  Validation loss = 0.8255  \n",
      "\n",
      "Fold: 23  Epoch: 437  Training loss = 4.2294  Validation loss = 0.8251  \n",
      "\n",
      "Fold: 23  Epoch: 438  Training loss = 4.2290  Validation loss = 0.8247  \n",
      "\n",
      "Fold: 23  Epoch: 439  Training loss = 4.2287  Validation loss = 0.8245  \n",
      "\n",
      "Fold: 23  Epoch: 440  Training loss = 4.2283  Validation loss = 0.8243  \n",
      "\n",
      "Fold: 23  Epoch: 441  Training loss = 4.2279  Validation loss = 0.8240  \n",
      "\n",
      "Fold: 23  Epoch: 442  Training loss = 4.2276  Validation loss = 0.8236  \n",
      "\n",
      "Fold: 23  Epoch: 443  Training loss = 4.2271  Validation loss = 0.8234  \n",
      "\n",
      "Fold: 23  Epoch: 444  Training loss = 4.2267  Validation loss = 0.8230  \n",
      "\n",
      "Fold: 23  Epoch: 445  Training loss = 4.2260  Validation loss = 0.8228  \n",
      "\n",
      "Fold: 23  Epoch: 446  Training loss = 4.2251  Validation loss = 0.8227  \n",
      "\n",
      "Fold: 23  Epoch: 447  Training loss = 4.2246  Validation loss = 0.8225  \n",
      "\n",
      "Fold: 23  Epoch: 448  Training loss = 4.2242  Validation loss = 0.8223  \n",
      "\n",
      "Fold: 23  Epoch: 449  Training loss = 4.2238  Validation loss = 0.8221  \n",
      "\n",
      "Fold: 23  Epoch: 450  Training loss = 4.2235  Validation loss = 0.8218  \n",
      "\n",
      "Fold: 23  Epoch: 451  Training loss = 4.2230  Validation loss = 0.8216  \n",
      "\n",
      "Fold: 23  Epoch: 452  Training loss = 4.2226  Validation loss = 0.8213  \n",
      "\n",
      "Fold: 23  Epoch: 453  Training loss = 4.2223  Validation loss = 0.8211  \n",
      "\n",
      "Fold: 23  Epoch: 454  Training loss = 4.2220  Validation loss = 0.8208  \n",
      "\n",
      "Fold: 23  Epoch: 455  Training loss = 4.2217  Validation loss = 0.8205  \n",
      "\n",
      "Fold: 23  Epoch: 456  Training loss = 4.2213  Validation loss = 0.8202  \n",
      "\n",
      "Fold: 23  Epoch: 457  Training loss = 4.2210  Validation loss = 0.8200  \n",
      "\n",
      "Fold: 23  Epoch: 458  Training loss = 4.2207  Validation loss = 0.8198  \n",
      "\n",
      "Fold: 23  Epoch: 459  Training loss = 4.2205  Validation loss = 0.8195  \n",
      "\n",
      "Fold: 23  Epoch: 460  Training loss = 4.2202  Validation loss = 0.8193  \n",
      "\n",
      "Fold: 23  Epoch: 461  Training loss = 4.2199  Validation loss = 0.8191  \n",
      "\n",
      "Fold: 23  Epoch: 462  Training loss = 4.2196  Validation loss = 0.8189  \n",
      "\n",
      "Fold: 23  Epoch: 463  Training loss = 4.2193  Validation loss = 0.8186  \n",
      "\n",
      "Fold: 23  Epoch: 464  Training loss = 4.2189  Validation loss = 0.8184  \n",
      "\n",
      "Fold: 23  Epoch: 465  Training loss = 4.2186  Validation loss = 0.8182  \n",
      "\n",
      "Fold: 23  Epoch: 466  Training loss = 4.2182  Validation loss = 0.8178  \n",
      "\n",
      "Fold: 23  Epoch: 467  Training loss = 4.2179  Validation loss = 0.8176  \n",
      "\n",
      "Fold: 23  Epoch: 468  Training loss = 4.2176  Validation loss = 0.8174  \n",
      "\n",
      "Fold: 23  Epoch: 469  Training loss = 4.2172  Validation loss = 0.8171  \n",
      "\n",
      "Fold: 23  Epoch: 470  Training loss = 4.2169  Validation loss = 0.8169  \n",
      "\n",
      "Fold: 23  Epoch: 471  Training loss = 4.2166  Validation loss = 0.8166  \n",
      "\n",
      "Fold: 23  Epoch: 472  Training loss = 4.2161  Validation loss = 0.8163  \n",
      "\n",
      "Fold: 23  Epoch: 473  Training loss = 4.2157  Validation loss = 0.8160  \n",
      "\n",
      "Fold: 23  Epoch: 474  Training loss = 4.2154  Validation loss = 0.8157  \n",
      "\n",
      "Fold: 23  Epoch: 475  Training loss = 4.2151  Validation loss = 0.8154  \n",
      "\n",
      "Fold: 23  Epoch: 476  Training loss = 4.2147  Validation loss = 0.8151  \n",
      "\n",
      "Fold: 23  Epoch: 477  Training loss = 4.2145  Validation loss = 0.8149  \n",
      "\n",
      "Fold: 23  Epoch: 478  Training loss = 4.2142  Validation loss = 0.8147  \n",
      "\n",
      "Fold: 23  Epoch: 479  Training loss = 4.2139  Validation loss = 0.8144  \n",
      "\n",
      "Fold: 23  Epoch: 480  Training loss = 4.2136  Validation loss = 0.8141  \n",
      "\n",
      "Fold: 23  Epoch: 481  Training loss = 4.2133  Validation loss = 0.8138  \n",
      "\n",
      "Fold: 23  Epoch: 482  Training loss = 4.2129  Validation loss = 0.8135  \n",
      "\n",
      "Fold: 23  Epoch: 483  Training loss = 4.2126  Validation loss = 0.8133  \n",
      "\n",
      "Fold: 23  Epoch: 484  Training loss = 4.2124  Validation loss = 0.8130  \n",
      "\n",
      "Fold: 23  Epoch: 485  Training loss = 4.2121  Validation loss = 0.8128  \n",
      "\n",
      "Fold: 23  Epoch: 486  Training loss = 4.2117  Validation loss = 0.8125  \n",
      "\n",
      "Fold: 23  Epoch: 487  Training loss = 4.2114  Validation loss = 0.8123  \n",
      "\n",
      "Fold: 23  Epoch: 488  Training loss = 4.2110  Validation loss = 0.8120  \n",
      "\n",
      "Fold: 23  Epoch: 489  Training loss = 4.2106  Validation loss = 0.8117  \n",
      "\n",
      "Fold: 23  Epoch: 490  Training loss = 4.2103  Validation loss = 0.8115  \n",
      "\n",
      "Fold: 23  Epoch: 491  Training loss = 4.2101  Validation loss = 0.8113  \n",
      "\n",
      "Fold: 23  Epoch: 492  Training loss = 4.2098  Validation loss = 0.8111  \n",
      "\n",
      "Fold: 23  Epoch: 493  Training loss = 4.2092  Validation loss = 0.8107  \n",
      "\n",
      "Fold: 23  Epoch: 494  Training loss = 4.2089  Validation loss = 0.8104  \n",
      "\n",
      "Fold: 23  Epoch: 495  Training loss = 4.2086  Validation loss = 0.8101  \n",
      "\n",
      "Fold: 23  Epoch: 496  Training loss = 4.2083  Validation loss = 0.8099  \n",
      "\n",
      "Fold: 23  Epoch: 497  Training loss = 4.2080  Validation loss = 0.8097  \n",
      "\n",
      "Fold: 23  Epoch: 498  Training loss = 4.2077  Validation loss = 0.8094  \n",
      "\n",
      "Fold: 23  Epoch: 499  Training loss = 4.2073  Validation loss = 0.8091  \n",
      "\n",
      "Fold: 23  Epoch: 500  Training loss = 4.2070  Validation loss = 0.8088  \n",
      "\n",
      "Check model:  Fold: 23  Optimal epoch: 500  \n",
      "\n",
      "Fold: 24  Epoch: 1  Training loss = 4.1912  Validation loss = 1.8460  \n",
      "\n",
      "Fold: 24  Epoch: 2  Training loss = 4.1908  Validation loss = 1.8457  \n",
      "\n",
      "Fold: 24  Epoch: 3  Training loss = 4.1904  Validation loss = 1.8453  \n",
      "\n",
      "Fold: 24  Epoch: 4  Training loss = 4.1900  Validation loss = 1.8450  \n",
      "\n",
      "Fold: 24  Epoch: 5  Training loss = 4.1897  Validation loss = 1.8448  \n",
      "\n",
      "Fold: 24  Epoch: 6  Training loss = 4.1894  Validation loss = 1.8445  \n",
      "\n",
      "Fold: 24  Epoch: 7  Training loss = 4.1890  Validation loss = 1.8442  \n",
      "\n",
      "Fold: 24  Epoch: 8  Training loss = 4.1886  Validation loss = 1.8438  \n",
      "\n",
      "Fold: 24  Epoch: 9  Training loss = 4.1883  Validation loss = 1.8435  \n",
      "\n",
      "Fold: 24  Epoch: 10  Training loss = 4.1879  Validation loss = 1.8432  \n",
      "\n",
      "Fold: 24  Epoch: 11  Training loss = 4.1876  Validation loss = 1.8429  \n",
      "\n",
      "Fold: 24  Epoch: 12  Training loss = 4.1873  Validation loss = 1.8426  \n",
      "\n",
      "Fold: 24  Epoch: 13  Training loss = 4.1869  Validation loss = 1.8423  \n",
      "\n",
      "Fold: 24  Epoch: 14  Training loss = 4.1866  Validation loss = 1.8421  \n",
      "\n",
      "Fold: 24  Epoch: 15  Training loss = 4.1862  Validation loss = 1.8417  \n",
      "\n",
      "Fold: 24  Epoch: 16  Training loss = 4.1859  Validation loss = 1.8414  \n",
      "\n",
      "Fold: 24  Epoch: 17  Training loss = 4.1854  Validation loss = 1.8410  \n",
      "\n",
      "Fold: 24  Epoch: 18  Training loss = 4.1851  Validation loss = 1.8408  \n",
      "\n",
      "Fold: 24  Epoch: 19  Training loss = 4.1847  Validation loss = 1.8404  \n",
      "\n",
      "Fold: 24  Epoch: 20  Training loss = 4.1843  Validation loss = 1.8401  \n",
      "\n",
      "Fold: 24  Epoch: 21  Training loss = 4.1840  Validation loss = 1.8399  \n",
      "\n",
      "Fold: 24  Epoch: 22  Training loss = 4.1837  Validation loss = 1.8396  \n",
      "\n",
      "Fold: 24  Epoch: 23  Training loss = 4.1833  Validation loss = 1.8393  \n",
      "\n",
      "Fold: 24  Epoch: 24  Training loss = 4.1829  Validation loss = 1.8389  \n",
      "\n",
      "Fold: 24  Epoch: 25  Training loss = 4.1825  Validation loss = 1.8386  \n",
      "\n",
      "Fold: 24  Epoch: 26  Training loss = 4.1822  Validation loss = 1.8384  \n",
      "\n",
      "Fold: 24  Epoch: 27  Training loss = 4.1818  Validation loss = 1.8380  \n",
      "\n",
      "Fold: 24  Epoch: 28  Training loss = 4.1814  Validation loss = 1.8377  \n",
      "\n",
      "Fold: 24  Epoch: 29  Training loss = 4.1811  Validation loss = 1.8375  \n",
      "\n",
      "Fold: 24  Epoch: 30  Training loss = 4.1809  Validation loss = 1.8372  \n",
      "\n",
      "Fold: 24  Epoch: 31  Training loss = 4.1804  Validation loss = 1.8369  \n",
      "\n",
      "Fold: 24  Epoch: 32  Training loss = 4.1801  Validation loss = 1.8365  \n",
      "\n",
      "Fold: 24  Epoch: 33  Training loss = 4.1797  Validation loss = 1.8362  \n",
      "\n",
      "Fold: 24  Epoch: 34  Training loss = 4.1795  Validation loss = 1.8360  \n",
      "\n",
      "Fold: 24  Epoch: 35  Training loss = 4.1790  Validation loss = 1.8356  \n",
      "\n",
      "Fold: 24  Epoch: 36  Training loss = 4.1787  Validation loss = 1.8354  \n",
      "\n",
      "Fold: 24  Epoch: 37  Training loss = 4.1784  Validation loss = 1.8351  \n",
      "\n",
      "Fold: 24  Epoch: 38  Training loss = 4.1779  Validation loss = 1.8347  \n",
      "\n",
      "Fold: 24  Epoch: 39  Training loss = 4.1776  Validation loss = 1.8343  \n",
      "\n",
      "Fold: 24  Epoch: 40  Training loss = 4.1772  Validation loss = 1.8340  \n",
      "\n",
      "Fold: 24  Epoch: 41  Training loss = 4.1769  Validation loss = 1.8338  \n",
      "\n",
      "Fold: 24  Epoch: 42  Training loss = 4.1765  Validation loss = 1.8335  \n",
      "\n",
      "Fold: 24  Epoch: 43  Training loss = 4.1762  Validation loss = 1.8332  \n",
      "\n",
      "Fold: 24  Epoch: 44  Training loss = 4.1759  Validation loss = 1.8330  \n",
      "\n",
      "Fold: 24  Epoch: 45  Training loss = 4.1757  Validation loss = 1.8327  \n",
      "\n",
      "Fold: 24  Epoch: 46  Training loss = 4.1752  Validation loss = 1.8323  \n",
      "\n",
      "Fold: 24  Epoch: 47  Training loss = 4.1748  Validation loss = 1.8320  \n",
      "\n",
      "Fold: 24  Epoch: 48  Training loss = 4.1744  Validation loss = 1.8317  \n",
      "\n",
      "Fold: 24  Epoch: 49  Training loss = 4.1740  Validation loss = 1.8313  \n",
      "\n",
      "Fold: 24  Epoch: 50  Training loss = 4.1736  Validation loss = 1.8310  \n",
      "\n",
      "Fold: 24  Epoch: 51  Training loss = 4.1732  Validation loss = 1.8307  \n",
      "\n",
      "Fold: 24  Epoch: 52  Training loss = 4.1729  Validation loss = 1.8304  \n",
      "\n",
      "Fold: 24  Epoch: 53  Training loss = 4.1725  Validation loss = 1.8301  \n",
      "\n",
      "Fold: 24  Epoch: 54  Training loss = 4.1722  Validation loss = 1.8298  \n",
      "\n",
      "Fold: 24  Epoch: 55  Training loss = 4.1719  Validation loss = 1.8296  \n",
      "\n",
      "Fold: 24  Epoch: 56  Training loss = 4.1716  Validation loss = 1.8293  \n",
      "\n",
      "Fold: 24  Epoch: 57  Training loss = 4.1713  Validation loss = 1.8291  \n",
      "\n",
      "Fold: 24  Epoch: 58  Training loss = 4.1710  Validation loss = 1.8289  \n",
      "\n",
      "Fold: 24  Epoch: 59  Training loss = 4.1707  Validation loss = 1.8286  \n",
      "\n",
      "Fold: 24  Epoch: 60  Training loss = 4.1704  Validation loss = 1.8283  \n",
      "\n",
      "Fold: 24  Epoch: 61  Training loss = 4.1701  Validation loss = 1.8280  \n",
      "\n",
      "Fold: 24  Epoch: 62  Training loss = 4.1697  Validation loss = 1.8277  \n",
      "\n",
      "Fold: 24  Epoch: 63  Training loss = 4.1694  Validation loss = 1.8274  \n",
      "\n",
      "Fold: 24  Epoch: 64  Training loss = 4.1690  Validation loss = 1.8271  \n",
      "\n",
      "Fold: 24  Epoch: 65  Training loss = 4.1687  Validation loss = 1.8268  \n",
      "\n",
      "Fold: 24  Epoch: 66  Training loss = 4.1683  Validation loss = 1.8265  \n",
      "\n",
      "Fold: 24  Epoch: 67  Training loss = 4.1680  Validation loss = 1.8262  \n",
      "\n",
      "Fold: 24  Epoch: 68  Training loss = 4.1677  Validation loss = 1.8260  \n",
      "\n",
      "Fold: 24  Epoch: 69  Training loss = 4.1674  Validation loss = 1.8257  \n",
      "\n",
      "Fold: 24  Epoch: 70  Training loss = 4.1670  Validation loss = 1.8253  \n",
      "\n",
      "Fold: 24  Epoch: 71  Training loss = 4.1667  Validation loss = 1.8251  \n",
      "\n",
      "Fold: 24  Epoch: 72  Training loss = 4.1663  Validation loss = 1.8247  \n",
      "\n",
      "Fold: 24  Epoch: 73  Training loss = 4.1659  Validation loss = 1.8244  \n",
      "\n",
      "Fold: 24  Epoch: 74  Training loss = 4.1656  Validation loss = 1.8241  \n",
      "\n",
      "Fold: 24  Epoch: 75  Training loss = 4.1652  Validation loss = 1.8238  \n",
      "\n",
      "Fold: 24  Epoch: 76  Training loss = 4.1648  Validation loss = 1.8234  \n",
      "\n",
      "Fold: 24  Epoch: 77  Training loss = 4.1644  Validation loss = 1.8231  \n",
      "\n",
      "Fold: 24  Epoch: 78  Training loss = 4.1640  Validation loss = 1.8228  \n",
      "\n",
      "Fold: 24  Epoch: 79  Training loss = 4.1637  Validation loss = 1.8224  \n",
      "\n",
      "Fold: 24  Epoch: 80  Training loss = 4.1634  Validation loss = 1.8222  \n",
      "\n",
      "Fold: 24  Epoch: 81  Training loss = 4.1631  Validation loss = 1.8220  \n",
      "\n",
      "Fold: 24  Epoch: 82  Training loss = 4.1628  Validation loss = 1.8217  \n",
      "\n",
      "Fold: 24  Epoch: 83  Training loss = 4.1624  Validation loss = 1.8213  \n",
      "\n",
      "Fold: 24  Epoch: 84  Training loss = 4.1621  Validation loss = 1.8211  \n",
      "\n",
      "Fold: 24  Epoch: 85  Training loss = 4.1618  Validation loss = 1.8208  \n",
      "\n",
      "Fold: 24  Epoch: 86  Training loss = 4.1616  Validation loss = 1.8206  \n",
      "\n",
      "Fold: 24  Epoch: 87  Training loss = 4.1613  Validation loss = 1.8203  \n",
      "\n",
      "Fold: 24  Epoch: 88  Training loss = 4.1610  Validation loss = 1.8200  \n",
      "\n",
      "Fold: 24  Epoch: 89  Training loss = 4.1606  Validation loss = 1.8197  \n",
      "\n",
      "Fold: 24  Epoch: 90  Training loss = 4.1603  Validation loss = 1.8194  \n",
      "\n",
      "Fold: 24  Epoch: 91  Training loss = 4.1601  Validation loss = 1.8193  \n",
      "\n",
      "Fold: 24  Epoch: 92  Training loss = 4.1598  Validation loss = 1.8190  \n",
      "\n",
      "Fold: 24  Epoch: 93  Training loss = 4.1594  Validation loss = 1.8187  \n",
      "\n",
      "Fold: 24  Epoch: 94  Training loss = 4.1591  Validation loss = 1.8185  \n",
      "\n",
      "Fold: 24  Epoch: 95  Training loss = 4.1587  Validation loss = 1.8182  \n",
      "\n",
      "Fold: 24  Epoch: 96  Training loss = 4.1584  Validation loss = 1.8179  \n",
      "\n",
      "Fold: 24  Epoch: 97  Training loss = 4.1580  Validation loss = 1.8175  \n",
      "\n",
      "Fold: 24  Epoch: 98  Training loss = 4.1576  Validation loss = 1.8171  \n",
      "\n",
      "Fold: 24  Epoch: 99  Training loss = 4.1574  Validation loss = 1.8169  \n",
      "\n",
      "Fold: 24  Epoch: 100  Training loss = 4.1568  Validation loss = 1.8164  \n",
      "\n",
      "Fold: 24  Epoch: 101  Training loss = 4.1565  Validation loss = 1.8161  \n",
      "\n",
      "Fold: 24  Epoch: 102  Training loss = 4.1562  Validation loss = 1.8158  \n",
      "\n",
      "Fold: 24  Epoch: 103  Training loss = 4.1559  Validation loss = 1.8156  \n",
      "\n",
      "Fold: 24  Epoch: 104  Training loss = 4.1555  Validation loss = 1.8153  \n",
      "\n",
      "Fold: 24  Epoch: 105  Training loss = 4.1553  Validation loss = 1.8150  \n",
      "\n",
      "Fold: 24  Epoch: 106  Training loss = 4.1549  Validation loss = 1.8148  \n",
      "\n",
      "Fold: 24  Epoch: 107  Training loss = 4.1546  Validation loss = 1.8145  \n",
      "\n",
      "Fold: 24  Epoch: 108  Training loss = 4.1543  Validation loss = 1.8143  \n",
      "\n",
      "Fold: 24  Epoch: 109  Training loss = 4.1540  Validation loss = 1.8140  \n",
      "\n",
      "Fold: 24  Epoch: 110  Training loss = 4.1536  Validation loss = 1.8137  \n",
      "\n",
      "Fold: 24  Epoch: 111  Training loss = 4.1532  Validation loss = 1.8134  \n",
      "\n",
      "Fold: 24  Epoch: 112  Training loss = 4.1529  Validation loss = 1.8131  \n",
      "\n",
      "Fold: 24  Epoch: 113  Training loss = 4.1526  Validation loss = 1.8128  \n",
      "\n",
      "Fold: 24  Epoch: 114  Training loss = 4.1524  Validation loss = 1.8126  \n",
      "\n",
      "Fold: 24  Epoch: 115  Training loss = 4.1521  Validation loss = 1.8124  \n",
      "\n",
      "Fold: 24  Epoch: 116  Training loss = 4.1517  Validation loss = 1.8121  \n",
      "\n",
      "Fold: 24  Epoch: 117  Training loss = 4.1515  Validation loss = 1.8118  \n",
      "\n",
      "Fold: 24  Epoch: 118  Training loss = 4.1511  Validation loss = 1.8116  \n",
      "\n",
      "Fold: 24  Epoch: 119  Training loss = 4.1509  Validation loss = 1.8113  \n",
      "\n",
      "Fold: 24  Epoch: 120  Training loss = 4.1505  Validation loss = 1.8110  \n",
      "\n",
      "Fold: 24  Epoch: 121  Training loss = 4.1502  Validation loss = 1.8108  \n",
      "\n",
      "Fold: 24  Epoch: 122  Training loss = 4.1498  Validation loss = 1.8105  \n",
      "\n",
      "Fold: 24  Epoch: 123  Training loss = 4.1496  Validation loss = 1.8103  \n",
      "\n",
      "Fold: 24  Epoch: 124  Training loss = 4.1493  Validation loss = 1.8100  \n",
      "\n",
      "Fold: 24  Epoch: 125  Training loss = 4.1489  Validation loss = 1.8096  \n",
      "\n",
      "Fold: 24  Epoch: 126  Training loss = 4.1484  Validation loss = 1.8093  \n",
      "\n",
      "Fold: 24  Epoch: 127  Training loss = 4.1480  Validation loss = 1.8090  \n",
      "\n",
      "Fold: 24  Epoch: 128  Training loss = 4.1477  Validation loss = 1.8088  \n",
      "\n",
      "Fold: 24  Epoch: 129  Training loss = 4.1474  Validation loss = 1.8085  \n",
      "\n",
      "Fold: 24  Epoch: 130  Training loss = 4.1470  Validation loss = 1.8082  \n",
      "\n",
      "Fold: 24  Epoch: 131  Training loss = 4.1467  Validation loss = 1.8079  \n",
      "\n",
      "Fold: 24  Epoch: 132  Training loss = 4.1464  Validation loss = 1.8077  \n",
      "\n",
      "Fold: 24  Epoch: 133  Training loss = 4.1461  Validation loss = 1.8073  \n",
      "\n",
      "Fold: 24  Epoch: 134  Training loss = 4.1457  Validation loss = 1.8070  \n",
      "\n",
      "Fold: 24  Epoch: 135  Training loss = 4.1454  Validation loss = 1.8067  \n",
      "\n",
      "Fold: 24  Epoch: 136  Training loss = 4.1451  Validation loss = 1.8065  \n",
      "\n",
      "Fold: 24  Epoch: 137  Training loss = 4.1448  Validation loss = 1.8063  \n",
      "\n",
      "Fold: 24  Epoch: 138  Training loss = 4.1445  Validation loss = 1.8060  \n",
      "\n",
      "Fold: 24  Epoch: 139  Training loss = 4.1441  Validation loss = 1.8057  \n",
      "\n",
      "Fold: 24  Epoch: 140  Training loss = 4.1438  Validation loss = 1.8055  \n",
      "\n",
      "Fold: 24  Epoch: 141  Training loss = 4.1435  Validation loss = 1.8052  \n",
      "\n",
      "Fold: 24  Epoch: 142  Training loss = 4.1432  Validation loss = 1.8050  \n",
      "\n",
      "Fold: 24  Epoch: 143  Training loss = 4.1429  Validation loss = 1.8047  \n",
      "\n",
      "Fold: 24  Epoch: 144  Training loss = 4.1426  Validation loss = 1.8044  \n",
      "\n",
      "Fold: 24  Epoch: 145  Training loss = 4.1422  Validation loss = 1.8041  \n",
      "\n",
      "Fold: 24  Epoch: 146  Training loss = 4.1420  Validation loss = 1.8039  \n",
      "\n",
      "Fold: 24  Epoch: 147  Training loss = 4.1415  Validation loss = 1.8035  \n",
      "\n",
      "Fold: 24  Epoch: 148  Training loss = 4.1412  Validation loss = 1.8032  \n",
      "\n",
      "Fold: 24  Epoch: 149  Training loss = 4.1408  Validation loss = 1.8029  \n",
      "\n",
      "Fold: 24  Epoch: 150  Training loss = 4.1405  Validation loss = 1.8027  \n",
      "\n",
      "Fold: 24  Epoch: 151  Training loss = 4.1401  Validation loss = 1.8024  \n",
      "\n",
      "Fold: 24  Epoch: 152  Training loss = 4.1398  Validation loss = 1.8020  \n",
      "\n",
      "Fold: 24  Epoch: 153  Training loss = 4.1394  Validation loss = 1.8017  \n",
      "\n",
      "Fold: 24  Epoch: 154  Training loss = 4.1391  Validation loss = 1.8015  \n",
      "\n",
      "Fold: 24  Epoch: 155  Training loss = 4.1388  Validation loss = 1.8012  \n",
      "\n",
      "Fold: 24  Epoch: 156  Training loss = 4.1385  Validation loss = 1.8010  \n",
      "\n",
      "Fold: 24  Epoch: 157  Training loss = 4.1380  Validation loss = 1.8006  \n",
      "\n",
      "Fold: 24  Epoch: 158  Training loss = 4.1377  Validation loss = 1.8003  \n",
      "\n",
      "Fold: 24  Epoch: 159  Training loss = 4.1374  Validation loss = 1.7999  \n",
      "\n",
      "Fold: 24  Epoch: 160  Training loss = 4.1371  Validation loss = 1.7997  \n",
      "\n",
      "Fold: 24  Epoch: 161  Training loss = 4.1367  Validation loss = 1.7995  \n",
      "\n",
      "Fold: 24  Epoch: 162  Training loss = 4.1365  Validation loss = 1.7993  \n",
      "\n",
      "Fold: 24  Epoch: 163  Training loss = 4.1361  Validation loss = 1.7990  \n",
      "\n",
      "Fold: 24  Epoch: 164  Training loss = 4.1358  Validation loss = 1.7987  \n",
      "\n",
      "Fold: 24  Epoch: 165  Training loss = 4.1355  Validation loss = 1.7984  \n",
      "\n",
      "Fold: 24  Epoch: 166  Training loss = 4.1352  Validation loss = 1.7982  \n",
      "\n",
      "Fold: 24  Epoch: 167  Training loss = 4.1348  Validation loss = 1.7978  \n",
      "\n",
      "Fold: 24  Epoch: 168  Training loss = 4.1346  Validation loss = 1.7976  \n",
      "\n",
      "Fold: 24  Epoch: 169  Training loss = 4.1343  Validation loss = 1.7974  \n",
      "\n",
      "Fold: 24  Epoch: 170  Training loss = 4.1339  Validation loss = 1.7971  \n",
      "\n",
      "Fold: 24  Epoch: 171  Training loss = 4.1335  Validation loss = 1.7968  \n",
      "\n",
      "Fold: 24  Epoch: 172  Training loss = 4.1332  Validation loss = 1.7964  \n",
      "\n",
      "Fold: 24  Epoch: 173  Training loss = 4.1328  Validation loss = 1.7962  \n",
      "\n",
      "Fold: 24  Epoch: 174  Training loss = 4.1325  Validation loss = 1.7959  \n",
      "\n",
      "Fold: 24  Epoch: 175  Training loss = 4.1321  Validation loss = 1.7956  \n",
      "\n",
      "Fold: 24  Epoch: 176  Training loss = 4.1318  Validation loss = 1.7954  \n",
      "\n",
      "Fold: 24  Epoch: 177  Training loss = 4.1316  Validation loss = 1.7952  \n",
      "\n",
      "Fold: 24  Epoch: 178  Training loss = 4.1312  Validation loss = 1.7948  \n",
      "\n",
      "Fold: 24  Epoch: 179  Training loss = 4.1308  Validation loss = 1.7946  \n",
      "\n",
      "Fold: 24  Epoch: 180  Training loss = 4.1306  Validation loss = 1.7944  \n",
      "\n",
      "Fold: 24  Epoch: 181  Training loss = 4.1302  Validation loss = 1.7941  \n",
      "\n",
      "Fold: 24  Epoch: 182  Training loss = 4.1299  Validation loss = 1.7938  \n",
      "\n",
      "Fold: 24  Epoch: 183  Training loss = 4.1295  Validation loss = 1.7935  \n",
      "\n",
      "Fold: 24  Epoch: 184  Training loss = 4.1292  Validation loss = 1.7932  \n",
      "\n",
      "Fold: 24  Epoch: 185  Training loss = 4.1288  Validation loss = 1.7929  \n",
      "\n",
      "Fold: 24  Epoch: 186  Training loss = 4.1285  Validation loss = 1.7926  \n",
      "\n",
      "Fold: 24  Epoch: 187  Training loss = 4.1283  Validation loss = 1.7924  \n",
      "\n",
      "Fold: 24  Epoch: 188  Training loss = 4.1279  Validation loss = 1.7921  \n",
      "\n",
      "Fold: 24  Epoch: 189  Training loss = 4.1277  Validation loss = 1.7919  \n",
      "\n",
      "Fold: 24  Epoch: 190  Training loss = 4.1273  Validation loss = 1.7916  \n",
      "\n",
      "Fold: 24  Epoch: 191  Training loss = 4.1269  Validation loss = 1.7913  \n",
      "\n",
      "Fold: 24  Epoch: 192  Training loss = 4.1266  Validation loss = 1.7910  \n",
      "\n",
      "Fold: 24  Epoch: 193  Training loss = 4.1263  Validation loss = 1.7907  \n",
      "\n",
      "Fold: 24  Epoch: 194  Training loss = 4.1259  Validation loss = 1.7904  \n",
      "\n",
      "Fold: 24  Epoch: 195  Training loss = 4.1256  Validation loss = 1.7901  \n",
      "\n",
      "Fold: 24  Epoch: 196  Training loss = 4.1253  Validation loss = 1.7899  \n",
      "\n",
      "Fold: 24  Epoch: 197  Training loss = 4.1250  Validation loss = 1.7896  \n",
      "\n",
      "Fold: 24  Epoch: 198  Training loss = 4.1247  Validation loss = 1.7894  \n",
      "\n",
      "Fold: 24  Epoch: 199  Training loss = 4.1245  Validation loss = 1.7891  \n",
      "\n",
      "Fold: 24  Epoch: 200  Training loss = 4.1242  Validation loss = 1.7889  \n",
      "\n",
      "Fold: 24  Epoch: 201  Training loss = 4.1240  Validation loss = 1.7888  \n",
      "\n",
      "Fold: 24  Epoch: 202  Training loss = 4.1236  Validation loss = 1.7884  \n",
      "\n",
      "Fold: 24  Epoch: 203  Training loss = 4.1233  Validation loss = 1.7882  \n",
      "\n",
      "Fold: 24  Epoch: 204  Training loss = 4.1229  Validation loss = 1.7878  \n",
      "\n",
      "Fold: 24  Epoch: 205  Training loss = 4.1226  Validation loss = 1.7876  \n",
      "\n",
      "Fold: 24  Epoch: 206  Training loss = 4.1223  Validation loss = 1.7873  \n",
      "\n",
      "Fold: 24  Epoch: 207  Training loss = 4.1220  Validation loss = 1.7871  \n",
      "\n",
      "Fold: 24  Epoch: 208  Training loss = 4.1216  Validation loss = 1.7868  \n",
      "\n",
      "Fold: 24  Epoch: 209  Training loss = 4.1211  Validation loss = 1.7864  \n",
      "\n",
      "Fold: 24  Epoch: 210  Training loss = 4.1208  Validation loss = 1.7861  \n",
      "\n",
      "Fold: 24  Epoch: 211  Training loss = 4.1204  Validation loss = 1.7858  \n",
      "\n",
      "Fold: 24  Epoch: 212  Training loss = 4.1201  Validation loss = 1.7855  \n",
      "\n",
      "Fold: 24  Epoch: 213  Training loss = 4.1197  Validation loss = 1.7851  \n",
      "\n",
      "Fold: 24  Epoch: 214  Training loss = 4.1194  Validation loss = 1.7849  \n",
      "\n",
      "Fold: 24  Epoch: 215  Training loss = 4.1190  Validation loss = 1.7846  \n",
      "\n",
      "Fold: 24  Epoch: 216  Training loss = 4.1186  Validation loss = 1.7843  \n",
      "\n",
      "Fold: 24  Epoch: 217  Training loss = 4.1183  Validation loss = 1.7840  \n",
      "\n",
      "Fold: 24  Epoch: 218  Training loss = 4.1179  Validation loss = 1.7837  \n",
      "\n",
      "Fold: 24  Epoch: 219  Training loss = 4.1175  Validation loss = 1.7834  \n",
      "\n",
      "Fold: 24  Epoch: 220  Training loss = 4.1172  Validation loss = 1.7831  \n",
      "\n",
      "Fold: 24  Epoch: 221  Training loss = 4.1170  Validation loss = 1.7829  \n",
      "\n",
      "Fold: 24  Epoch: 222  Training loss = 4.1167  Validation loss = 1.7826  \n",
      "\n",
      "Fold: 24  Epoch: 223  Training loss = 4.1163  Validation loss = 1.7823  \n",
      "\n",
      "Fold: 24  Epoch: 224  Training loss = 4.1160  Validation loss = 1.7820  \n",
      "\n",
      "Fold: 24  Epoch: 225  Training loss = 4.1156  Validation loss = 1.7816  \n",
      "\n",
      "Fold: 24  Epoch: 226  Training loss = 4.1154  Validation loss = 1.7814  \n",
      "\n",
      "Fold: 24  Epoch: 227  Training loss = 4.1151  Validation loss = 1.7812  \n",
      "\n",
      "Fold: 24  Epoch: 228  Training loss = 4.1148  Validation loss = 1.7809  \n",
      "\n",
      "Fold: 24  Epoch: 229  Training loss = 4.1144  Validation loss = 1.7806  \n",
      "\n",
      "Fold: 24  Epoch: 230  Training loss = 4.1142  Validation loss = 1.7804  \n",
      "\n",
      "Fold: 24  Epoch: 231  Training loss = 4.1138  Validation loss = 1.7801  \n",
      "\n",
      "Fold: 24  Epoch: 232  Training loss = 4.1134  Validation loss = 1.7798  \n",
      "\n",
      "Fold: 24  Epoch: 233  Training loss = 4.1129  Validation loss = 1.7795  \n",
      "\n",
      "Fold: 24  Epoch: 234  Training loss = 4.1126  Validation loss = 1.7792  \n",
      "\n",
      "Fold: 24  Epoch: 235  Training loss = 4.1122  Validation loss = 1.7789  \n",
      "\n",
      "Fold: 24  Epoch: 236  Training loss = 4.1119  Validation loss = 1.7786  \n",
      "\n",
      "Fold: 24  Epoch: 237  Training loss = 4.1115  Validation loss = 1.7783  \n",
      "\n",
      "Fold: 24  Epoch: 238  Training loss = 4.1111  Validation loss = 1.7779  \n",
      "\n",
      "Fold: 24  Epoch: 239  Training loss = 4.1108  Validation loss = 1.7777  \n",
      "\n",
      "Fold: 24  Epoch: 240  Training loss = 4.1105  Validation loss = 1.7774  \n",
      "\n",
      "Fold: 24  Epoch: 241  Training loss = 4.1103  Validation loss = 1.7772  \n",
      "\n",
      "Fold: 24  Epoch: 242  Training loss = 4.1099  Validation loss = 1.7769  \n",
      "\n",
      "Fold: 24  Epoch: 243  Training loss = 4.1096  Validation loss = 1.7767  \n",
      "\n",
      "Fold: 24  Epoch: 244  Training loss = 4.1093  Validation loss = 1.7764  \n",
      "\n",
      "Fold: 24  Epoch: 245  Training loss = 4.1091  Validation loss = 1.7762  \n",
      "\n",
      "Fold: 24  Epoch: 246  Training loss = 4.1087  Validation loss = 1.7759  \n",
      "\n",
      "Fold: 24  Epoch: 247  Training loss = 4.1084  Validation loss = 1.7756  \n",
      "\n",
      "Fold: 24  Epoch: 248  Training loss = 4.1081  Validation loss = 1.7753  \n",
      "\n",
      "Fold: 24  Epoch: 249  Training loss = 4.1077  Validation loss = 1.7750  \n",
      "\n",
      "Fold: 24  Epoch: 250  Training loss = 4.1074  Validation loss = 1.7748  \n",
      "\n",
      "Fold: 24  Epoch: 251  Training loss = 4.1072  Validation loss = 1.7746  \n",
      "\n",
      "Fold: 24  Epoch: 252  Training loss = 4.1069  Validation loss = 1.7745  \n",
      "\n",
      "Fold: 24  Epoch: 253  Training loss = 4.1066  Validation loss = 1.7742  \n",
      "\n",
      "Fold: 24  Epoch: 254  Training loss = 4.1063  Validation loss = 1.7739  \n",
      "\n",
      "Fold: 24  Epoch: 255  Training loss = 4.1059  Validation loss = 1.7736  \n",
      "\n",
      "Fold: 24  Epoch: 256  Training loss = 4.1057  Validation loss = 1.7734  \n",
      "\n",
      "Fold: 24  Epoch: 257  Training loss = 4.1055  Validation loss = 1.7732  \n",
      "\n",
      "Fold: 24  Epoch: 258  Training loss = 4.1051  Validation loss = 1.7728  \n",
      "\n",
      "Fold: 24  Epoch: 259  Training loss = 4.1047  Validation loss = 1.7725  \n",
      "\n",
      "Fold: 24  Epoch: 260  Training loss = 4.1043  Validation loss = 1.7721  \n",
      "\n",
      "Fold: 24  Epoch: 261  Training loss = 4.1040  Validation loss = 1.7719  \n",
      "\n",
      "Fold: 24  Epoch: 262  Training loss = 4.1037  Validation loss = 1.7716  \n",
      "\n",
      "Fold: 24  Epoch: 263  Training loss = 4.1033  Validation loss = 1.7713  \n",
      "\n",
      "Fold: 24  Epoch: 264  Training loss = 4.1030  Validation loss = 1.7711  \n",
      "\n",
      "Fold: 24  Epoch: 265  Training loss = 4.1026  Validation loss = 1.7707  \n",
      "\n",
      "Fold: 24  Epoch: 266  Training loss = 4.1023  Validation loss = 1.7704  \n",
      "\n",
      "Fold: 24  Epoch: 267  Training loss = 4.1020  Validation loss = 1.7701  \n",
      "\n",
      "Fold: 24  Epoch: 268  Training loss = 4.1017  Validation loss = 1.7700  \n",
      "\n",
      "Fold: 24  Epoch: 269  Training loss = 4.1013  Validation loss = 1.7696  \n",
      "\n",
      "Fold: 24  Epoch: 270  Training loss = 4.1010  Validation loss = 1.7694  \n",
      "\n",
      "Fold: 24  Epoch: 271  Training loss = 4.1007  Validation loss = 1.7691  \n",
      "\n",
      "Fold: 24  Epoch: 272  Training loss = 4.1003  Validation loss = 1.7688  \n",
      "\n",
      "Fold: 24  Epoch: 273  Training loss = 4.0999  Validation loss = 1.7685  \n",
      "\n",
      "Fold: 24  Epoch: 274  Training loss = 4.0996  Validation loss = 1.7682  \n",
      "\n",
      "Fold: 24  Epoch: 275  Training loss = 4.0993  Validation loss = 1.7679  \n",
      "\n",
      "Fold: 24  Epoch: 276  Training loss = 4.0990  Validation loss = 1.7677  \n",
      "\n",
      "Fold: 24  Epoch: 277  Training loss = 4.0986  Validation loss = 1.7674  \n",
      "\n",
      "Fold: 24  Epoch: 278  Training loss = 4.0983  Validation loss = 1.7671  \n",
      "\n",
      "Fold: 24  Epoch: 279  Training loss = 4.0980  Validation loss = 1.7669  \n",
      "\n",
      "Fold: 24  Epoch: 280  Training loss = 4.0978  Validation loss = 1.7667  \n",
      "\n",
      "Fold: 24  Epoch: 281  Training loss = 4.0974  Validation loss = 1.7664  \n",
      "\n",
      "Fold: 24  Epoch: 282  Training loss = 4.0971  Validation loss = 1.7662  \n",
      "\n",
      "Fold: 24  Epoch: 283  Training loss = 4.0966  Validation loss = 1.7658  \n",
      "\n",
      "Fold: 24  Epoch: 284  Training loss = 4.0963  Validation loss = 1.7656  \n",
      "\n",
      "Fold: 24  Epoch: 285  Training loss = 4.0961  Validation loss = 1.7654  \n",
      "\n",
      "Fold: 24  Epoch: 286  Training loss = 4.0958  Validation loss = 1.7651  \n",
      "\n",
      "Fold: 24  Epoch: 287  Training loss = 4.0955  Validation loss = 1.7648  \n",
      "\n",
      "Fold: 24  Epoch: 288  Training loss = 4.0952  Validation loss = 1.7646  \n",
      "\n",
      "Fold: 24  Epoch: 289  Training loss = 4.0949  Validation loss = 1.7643  \n",
      "\n",
      "Fold: 24  Epoch: 290  Training loss = 4.0946  Validation loss = 1.7640  \n",
      "\n",
      "Fold: 24  Epoch: 291  Training loss = 4.0941  Validation loss = 1.7636  \n",
      "\n",
      "Fold: 24  Epoch: 292  Training loss = 4.0939  Validation loss = 1.7634  \n",
      "\n",
      "Fold: 24  Epoch: 293  Training loss = 4.0935  Validation loss = 1.7630  \n",
      "\n",
      "Fold: 24  Epoch: 294  Training loss = 4.0932  Validation loss = 1.7628  \n",
      "\n",
      "Fold: 24  Epoch: 295  Training loss = 4.0929  Validation loss = 1.7626  \n",
      "\n",
      "Fold: 24  Epoch: 296  Training loss = 4.0926  Validation loss = 1.7624  \n",
      "\n",
      "Fold: 24  Epoch: 297  Training loss = 4.0923  Validation loss = 1.7620  \n",
      "\n",
      "Fold: 24  Epoch: 298  Training loss = 4.0919  Validation loss = 1.7617  \n",
      "\n",
      "Fold: 24  Epoch: 299  Training loss = 4.0916  Validation loss = 1.7614  \n",
      "\n",
      "Fold: 24  Epoch: 300  Training loss = 4.0912  Validation loss = 1.7611  \n",
      "\n",
      "Fold: 24  Epoch: 301  Training loss = 4.0909  Validation loss = 1.7608  \n",
      "\n",
      "Fold: 24  Epoch: 302  Training loss = 4.0907  Validation loss = 1.7606  \n",
      "\n",
      "Fold: 24  Epoch: 303  Training loss = 4.0903  Validation loss = 1.7603  \n",
      "\n",
      "Fold: 24  Epoch: 304  Training loss = 4.0899  Validation loss = 1.7599  \n",
      "\n",
      "Fold: 24  Epoch: 305  Training loss = 4.0897  Validation loss = 1.7597  \n",
      "\n",
      "Fold: 24  Epoch: 306  Training loss = 4.0894  Validation loss = 1.7595  \n",
      "\n",
      "Fold: 24  Epoch: 307  Training loss = 4.0891  Validation loss = 1.7593  \n",
      "\n",
      "Fold: 24  Epoch: 308  Training loss = 4.0888  Validation loss = 1.7591  \n",
      "\n",
      "Fold: 24  Epoch: 309  Training loss = 4.0884  Validation loss = 1.7588  \n",
      "\n",
      "Fold: 24  Epoch: 310  Training loss = 4.0882  Validation loss = 1.7586  \n",
      "\n",
      "Fold: 24  Epoch: 311  Training loss = 4.0878  Validation loss = 1.7583  \n",
      "\n",
      "Fold: 24  Epoch: 312  Training loss = 4.0875  Validation loss = 1.7580  \n",
      "\n",
      "Fold: 24  Epoch: 313  Training loss = 4.0873  Validation loss = 1.7579  \n",
      "\n",
      "Fold: 24  Epoch: 314  Training loss = 4.0870  Validation loss = 1.7576  \n",
      "\n",
      "Fold: 24  Epoch: 315  Training loss = 4.0866  Validation loss = 1.7573  \n",
      "\n",
      "Fold: 24  Epoch: 316  Training loss = 4.0864  Validation loss = 1.7571  \n",
      "\n",
      "Fold: 24  Epoch: 317  Training loss = 4.0861  Validation loss = 1.7568  \n",
      "\n",
      "Fold: 24  Epoch: 318  Training loss = 4.0858  Validation loss = 1.7566  \n",
      "\n",
      "Fold: 24  Epoch: 319  Training loss = 4.0854  Validation loss = 1.7563  \n",
      "\n",
      "Fold: 24  Epoch: 320  Training loss = 4.0851  Validation loss = 1.7560  \n",
      "\n",
      "Fold: 24  Epoch: 321  Training loss = 4.0848  Validation loss = 1.7558  \n",
      "\n",
      "Fold: 24  Epoch: 322  Training loss = 4.0844  Validation loss = 1.7554  \n",
      "\n",
      "Fold: 24  Epoch: 323  Training loss = 4.0841  Validation loss = 1.7552  \n",
      "\n",
      "Fold: 24  Epoch: 324  Training loss = 4.0838  Validation loss = 1.7549  \n",
      "\n",
      "Fold: 24  Epoch: 325  Training loss = 4.0835  Validation loss = 1.7546  \n",
      "\n",
      "Fold: 24  Epoch: 326  Training loss = 4.0832  Validation loss = 1.7544  \n",
      "\n",
      "Fold: 24  Epoch: 327  Training loss = 4.0828  Validation loss = 1.7540  \n",
      "\n",
      "Fold: 24  Epoch: 328  Training loss = 4.0824  Validation loss = 1.7537  \n",
      "\n",
      "Fold: 24  Epoch: 329  Training loss = 4.0822  Validation loss = 1.7535  \n",
      "\n",
      "Fold: 24  Epoch: 330  Training loss = 4.0818  Validation loss = 1.7532  \n",
      "\n",
      "Fold: 24  Epoch: 331  Training loss = 4.0815  Validation loss = 1.7530  \n",
      "\n",
      "Fold: 24  Epoch: 332  Training loss = 4.0812  Validation loss = 1.7527  \n",
      "\n",
      "Fold: 24  Epoch: 333  Training loss = 4.0808  Validation loss = 1.7523  \n",
      "\n",
      "Fold: 24  Epoch: 334  Training loss = 4.0805  Validation loss = 1.7521  \n",
      "\n",
      "Fold: 24  Epoch: 335  Training loss = 4.0803  Validation loss = 1.7519  \n",
      "\n",
      "Fold: 24  Epoch: 336  Training loss = 4.0800  Validation loss = 1.7516  \n",
      "\n",
      "Fold: 24  Epoch: 337  Training loss = 4.0797  Validation loss = 1.7514  \n",
      "\n",
      "Fold: 24  Epoch: 338  Training loss = 4.0793  Validation loss = 1.7511  \n",
      "\n",
      "Fold: 24  Epoch: 339  Training loss = 4.0789  Validation loss = 1.7508  \n",
      "\n",
      "Fold: 24  Epoch: 340  Training loss = 4.0785  Validation loss = 1.7505  \n",
      "\n",
      "Fold: 24  Epoch: 341  Training loss = 4.0783  Validation loss = 1.7502  \n",
      "\n",
      "Fold: 24  Epoch: 342  Training loss = 4.0778  Validation loss = 1.7498  \n",
      "\n",
      "Fold: 24  Epoch: 343  Training loss = 4.0775  Validation loss = 1.7496  \n",
      "\n",
      "Fold: 24  Epoch: 344  Training loss = 4.0772  Validation loss = 1.7493  \n",
      "\n",
      "Fold: 24  Epoch: 345  Training loss = 4.0769  Validation loss = 1.7491  \n",
      "\n",
      "Fold: 24  Epoch: 346  Training loss = 4.0767  Validation loss = 1.7489  \n",
      "\n",
      "Fold: 24  Epoch: 347  Training loss = 4.0764  Validation loss = 1.7487  \n",
      "\n",
      "Fold: 24  Epoch: 348  Training loss = 4.0761  Validation loss = 1.7485  \n",
      "\n",
      "Fold: 24  Epoch: 349  Training loss = 4.0757  Validation loss = 1.7481  \n",
      "\n",
      "Fold: 24  Epoch: 350  Training loss = 4.0754  Validation loss = 1.7479  \n",
      "\n",
      "Fold: 24  Epoch: 351  Training loss = 4.0752  Validation loss = 1.7477  \n",
      "\n",
      "Fold: 24  Epoch: 352  Training loss = 4.0748  Validation loss = 1.7474  \n",
      "\n",
      "Fold: 24  Epoch: 353  Training loss = 4.0745  Validation loss = 1.7471  \n",
      "\n",
      "Fold: 24  Epoch: 354  Training loss = 4.0742  Validation loss = 1.7468  \n",
      "\n",
      "Fold: 24  Epoch: 355  Training loss = 4.0738  Validation loss = 1.7465  \n",
      "\n",
      "Fold: 24  Epoch: 356  Training loss = 4.0734  Validation loss = 1.7462  \n",
      "\n",
      "Fold: 24  Epoch: 357  Training loss = 4.0731  Validation loss = 1.7460  \n",
      "\n",
      "Fold: 24  Epoch: 358  Training loss = 4.0727  Validation loss = 1.7457  \n",
      "\n",
      "Fold: 24  Epoch: 359  Training loss = 4.0725  Validation loss = 1.7455  \n",
      "\n",
      "Fold: 24  Epoch: 360  Training loss = 4.0722  Validation loss = 1.7452  \n",
      "\n",
      "Fold: 24  Epoch: 361  Training loss = 4.0719  Validation loss = 1.7450  \n",
      "\n",
      "Fold: 24  Epoch: 362  Training loss = 4.0715  Validation loss = 1.7447  \n",
      "\n",
      "Fold: 24  Epoch: 363  Training loss = 4.0712  Validation loss = 1.7444  \n",
      "\n",
      "Fold: 24  Epoch: 364  Training loss = 4.0709  Validation loss = 1.7441  \n",
      "\n",
      "Fold: 24  Epoch: 365  Training loss = 4.0706  Validation loss = 1.7439  \n",
      "\n",
      "Fold: 24  Epoch: 366  Training loss = 4.0704  Validation loss = 1.7437  \n",
      "\n",
      "Fold: 24  Epoch: 367  Training loss = 4.0700  Validation loss = 1.7434  \n",
      "\n",
      "Fold: 24  Epoch: 368  Training loss = 4.0697  Validation loss = 1.7431  \n",
      "\n",
      "Fold: 24  Epoch: 369  Training loss = 4.0694  Validation loss = 1.7429  \n",
      "\n",
      "Fold: 24  Epoch: 370  Training loss = 4.0690  Validation loss = 1.7426  \n",
      "\n",
      "Fold: 24  Epoch: 371  Training loss = 4.0687  Validation loss = 1.7423  \n",
      "\n",
      "Fold: 24  Epoch: 372  Training loss = 4.0684  Validation loss = 1.7420  \n",
      "\n",
      "Fold: 24  Epoch: 373  Training loss = 4.0681  Validation loss = 1.7419  \n",
      "\n",
      "Fold: 24  Epoch: 374  Training loss = 4.0677  Validation loss = 1.7414  \n",
      "\n",
      "Fold: 24  Epoch: 375  Training loss = 4.0672  Validation loss = 1.7411  \n",
      "\n",
      "Fold: 24  Epoch: 376  Training loss = 4.0669  Validation loss = 1.7408  \n",
      "\n",
      "Fold: 24  Epoch: 377  Training loss = 4.0666  Validation loss = 1.7406  \n",
      "\n",
      "Fold: 24  Epoch: 378  Training loss = 4.0663  Validation loss = 1.7402  \n",
      "\n",
      "Fold: 24  Epoch: 379  Training loss = 4.0659  Validation loss = 1.7400  \n",
      "\n",
      "Fold: 24  Epoch: 380  Training loss = 4.0656  Validation loss = 1.7397  \n",
      "\n",
      "Fold: 24  Epoch: 381  Training loss = 4.0652  Validation loss = 1.7394  \n",
      "\n",
      "Fold: 24  Epoch: 382  Training loss = 4.0649  Validation loss = 1.7391  \n",
      "\n",
      "Fold: 24  Epoch: 383  Training loss = 4.0646  Validation loss = 1.7389  \n",
      "\n",
      "Fold: 24  Epoch: 384  Training loss = 4.0644  Validation loss = 1.7387  \n",
      "\n",
      "Fold: 24  Epoch: 385  Training loss = 4.0641  Validation loss = 1.7385  \n",
      "\n",
      "Fold: 24  Epoch: 386  Training loss = 4.0637  Validation loss = 1.7381  \n",
      "\n",
      "Fold: 24  Epoch: 387  Training loss = 4.0634  Validation loss = 1.7379  \n",
      "\n",
      "Fold: 24  Epoch: 388  Training loss = 4.0631  Validation loss = 1.7377  \n",
      "\n",
      "Fold: 24  Epoch: 389  Training loss = 4.0627  Validation loss = 1.7373  \n",
      "\n",
      "Fold: 24  Epoch: 390  Training loss = 4.0625  Validation loss = 1.7371  \n",
      "\n",
      "Fold: 24  Epoch: 391  Training loss = 4.0621  Validation loss = 1.7368  \n",
      "\n",
      "Fold: 24  Epoch: 392  Training loss = 4.0620  Validation loss = 1.7366  \n",
      "\n",
      "Fold: 24  Epoch: 393  Training loss = 4.0616  Validation loss = 1.7363  \n",
      "\n",
      "Fold: 24  Epoch: 394  Training loss = 4.0612  Validation loss = 1.7360  \n",
      "\n",
      "Fold: 24  Epoch: 395  Training loss = 4.0610  Validation loss = 1.7358  \n",
      "\n",
      "Fold: 24  Epoch: 396  Training loss = 4.0607  Validation loss = 1.7356  \n",
      "\n",
      "Fold: 24  Epoch: 397  Training loss = 4.0604  Validation loss = 1.7354  \n",
      "\n",
      "Fold: 24  Epoch: 398  Training loss = 4.0601  Validation loss = 1.7352  \n",
      "\n",
      "Fold: 24  Epoch: 399  Training loss = 4.0598  Validation loss = 1.7349  \n",
      "\n",
      "Fold: 24  Epoch: 400  Training loss = 4.0594  Validation loss = 1.7346  \n",
      "\n",
      "Fold: 24  Epoch: 401  Training loss = 4.0591  Validation loss = 1.7344  \n",
      "\n",
      "Fold: 24  Epoch: 402  Training loss = 4.0589  Validation loss = 1.7342  \n",
      "\n",
      "Fold: 24  Epoch: 403  Training loss = 4.0586  Validation loss = 1.7339  \n",
      "\n",
      "Fold: 24  Epoch: 404  Training loss = 4.0583  Validation loss = 1.7337  \n",
      "\n",
      "Fold: 24  Epoch: 405  Training loss = 4.0579  Validation loss = 1.7334  \n",
      "\n",
      "Fold: 24  Epoch: 406  Training loss = 4.0576  Validation loss = 1.7332  \n",
      "\n",
      "Fold: 24  Epoch: 407  Training loss = 4.0573  Validation loss = 1.7330  \n",
      "\n",
      "Fold: 24  Epoch: 408  Training loss = 4.0571  Validation loss = 1.7327  \n",
      "\n",
      "Fold: 24  Epoch: 409  Training loss = 4.0567  Validation loss = 1.7324  \n",
      "\n",
      "Fold: 24  Epoch: 410  Training loss = 4.0564  Validation loss = 1.7322  \n",
      "\n",
      "Fold: 24  Epoch: 411  Training loss = 4.0561  Validation loss = 1.7319  \n",
      "\n",
      "Fold: 24  Epoch: 412  Training loss = 4.0558  Validation loss = 1.7317  \n",
      "\n",
      "Fold: 24  Epoch: 413  Training loss = 4.0556  Validation loss = 1.7315  \n",
      "\n",
      "Fold: 24  Epoch: 414  Training loss = 4.0554  Validation loss = 1.7313  \n",
      "\n",
      "Fold: 24  Epoch: 415  Training loss = 4.0550  Validation loss = 1.7310  \n",
      "\n",
      "Fold: 24  Epoch: 416  Training loss = 4.0547  Validation loss = 1.7308  \n",
      "\n",
      "Fold: 24  Epoch: 417  Training loss = 4.0544  Validation loss = 1.7305  \n",
      "\n",
      "Fold: 24  Epoch: 418  Training loss = 4.0540  Validation loss = 1.7302  \n",
      "\n",
      "Fold: 24  Epoch: 419  Training loss = 4.0537  Validation loss = 1.7299  \n",
      "\n",
      "Fold: 24  Epoch: 420  Training loss = 4.0534  Validation loss = 1.7297  \n",
      "\n",
      "Fold: 24  Epoch: 421  Training loss = 4.0532  Validation loss = 1.7296  \n",
      "\n",
      "Fold: 24  Epoch: 422  Training loss = 4.0529  Validation loss = 1.7293  \n",
      "\n",
      "Fold: 24  Epoch: 423  Training loss = 4.0526  Validation loss = 1.7291  \n",
      "\n",
      "Fold: 24  Epoch: 424  Training loss = 4.0523  Validation loss = 1.7287  \n",
      "\n",
      "Fold: 24  Epoch: 425  Training loss = 4.0520  Validation loss = 1.7285  \n",
      "\n",
      "Fold: 24  Epoch: 426  Training loss = 4.0517  Validation loss = 1.7283  \n",
      "\n",
      "Fold: 24  Epoch: 427  Training loss = 4.0515  Validation loss = 1.7281  \n",
      "\n",
      "Fold: 24  Epoch: 428  Training loss = 4.0512  Validation loss = 1.7279  \n",
      "\n",
      "Fold: 24  Epoch: 429  Training loss = 4.0509  Validation loss = 1.7276  \n",
      "\n",
      "Fold: 24  Epoch: 430  Training loss = 4.0505  Validation loss = 1.7273  \n",
      "\n",
      "Fold: 24  Epoch: 431  Training loss = 4.0503  Validation loss = 1.7272  \n",
      "\n",
      "Fold: 24  Epoch: 432  Training loss = 4.0500  Validation loss = 1.7270  \n",
      "\n",
      "Fold: 24  Epoch: 433  Training loss = 4.0497  Validation loss = 1.7267  \n",
      "\n",
      "Fold: 24  Epoch: 434  Training loss = 4.0495  Validation loss = 1.7266  \n",
      "\n",
      "Fold: 24  Epoch: 435  Training loss = 4.0493  Validation loss = 1.7264  \n",
      "\n",
      "Fold: 24  Epoch: 436  Training loss = 4.0489  Validation loss = 1.7261  \n",
      "\n",
      "Fold: 24  Epoch: 437  Training loss = 4.0486  Validation loss = 1.7258  \n",
      "\n",
      "Fold: 24  Epoch: 438  Training loss = 4.0482  Validation loss = 1.7255  \n",
      "\n",
      "Fold: 24  Epoch: 439  Training loss = 4.0479  Validation loss = 1.7252  \n",
      "\n",
      "Fold: 24  Epoch: 440  Training loss = 4.0476  Validation loss = 1.7250  \n",
      "\n",
      "Fold: 24  Epoch: 441  Training loss = 4.0473  Validation loss = 1.7247  \n",
      "\n",
      "Fold: 24  Epoch: 442  Training loss = 4.0470  Validation loss = 1.7245  \n",
      "\n",
      "Fold: 24  Epoch: 443  Training loss = 4.0467  Validation loss = 1.7243  \n",
      "\n",
      "Fold: 24  Epoch: 444  Training loss = 4.0463  Validation loss = 1.7239  \n",
      "\n",
      "Fold: 24  Epoch: 445  Training loss = 4.0460  Validation loss = 1.7237  \n",
      "\n",
      "Fold: 24  Epoch: 446  Training loss = 4.0458  Validation loss = 1.7235  \n",
      "\n",
      "Fold: 24  Epoch: 447  Training loss = 4.0454  Validation loss = 1.7232  \n",
      "\n",
      "Fold: 24  Epoch: 448  Training loss = 4.0450  Validation loss = 1.7229  \n",
      "\n",
      "Fold: 24  Epoch: 449  Training loss = 4.0448  Validation loss = 1.7228  \n",
      "\n",
      "Fold: 24  Epoch: 450  Training loss = 4.0445  Validation loss = 1.7226  \n",
      "\n",
      "Fold: 24  Epoch: 451  Training loss = 4.0441  Validation loss = 1.7222  \n",
      "\n",
      "Fold: 24  Epoch: 452  Training loss = 4.0438  Validation loss = 1.7220  \n",
      "\n",
      "Fold: 24  Epoch: 453  Training loss = 4.0435  Validation loss = 1.7217  \n",
      "\n",
      "Fold: 24  Epoch: 454  Training loss = 4.0433  Validation loss = 1.7215  \n",
      "\n",
      "Fold: 24  Epoch: 455  Training loss = 4.0430  Validation loss = 1.7213  \n",
      "\n",
      "Fold: 24  Epoch: 456  Training loss = 4.0426  Validation loss = 1.7209  \n",
      "\n",
      "Fold: 24  Epoch: 457  Training loss = 4.0423  Validation loss = 1.7206  \n",
      "\n",
      "Fold: 24  Epoch: 458  Training loss = 4.0420  Validation loss = 1.7204  \n",
      "\n",
      "Fold: 24  Epoch: 459  Training loss = 4.0417  Validation loss = 1.7202  \n",
      "\n",
      "Fold: 24  Epoch: 460  Training loss = 4.0414  Validation loss = 1.7200  \n",
      "\n",
      "Fold: 24  Epoch: 461  Training loss = 4.0412  Validation loss = 1.7198  \n",
      "\n",
      "Fold: 24  Epoch: 462  Training loss = 4.0409  Validation loss = 1.7195  \n",
      "\n",
      "Fold: 24  Epoch: 463  Training loss = 4.0406  Validation loss = 1.7192  \n",
      "\n",
      "Fold: 24  Epoch: 464  Training loss = 4.0404  Validation loss = 1.7191  \n",
      "\n",
      "Fold: 24  Epoch: 465  Training loss = 4.0400  Validation loss = 1.7188  \n",
      "\n",
      "Fold: 24  Epoch: 466  Training loss = 4.0396  Validation loss = 1.7185  \n",
      "\n",
      "Fold: 24  Epoch: 467  Training loss = 4.0393  Validation loss = 1.7182  \n",
      "\n",
      "Fold: 24  Epoch: 468  Training loss = 4.0391  Validation loss = 1.7180  \n",
      "\n",
      "Fold: 24  Epoch: 469  Training loss = 4.0388  Validation loss = 1.7177  \n",
      "\n",
      "Fold: 24  Epoch: 470  Training loss = 4.0384  Validation loss = 1.7175  \n",
      "\n",
      "Fold: 24  Epoch: 471  Training loss = 4.0382  Validation loss = 1.7173  \n",
      "\n",
      "Fold: 24  Epoch: 472  Training loss = 4.0380  Validation loss = 1.7171  \n",
      "\n",
      "Fold: 24  Epoch: 473  Training loss = 4.0377  Validation loss = 1.7169  \n",
      "\n",
      "Fold: 24  Epoch: 474  Training loss = 4.0373  Validation loss = 1.7165  \n",
      "\n",
      "Fold: 24  Epoch: 475  Training loss = 4.0370  Validation loss = 1.7162  \n",
      "\n",
      "Fold: 24  Epoch: 476  Training loss = 4.0367  Validation loss = 1.7160  \n",
      "\n",
      "Fold: 24  Epoch: 477  Training loss = 4.0365  Validation loss = 1.7158  \n",
      "\n",
      "Fold: 24  Epoch: 478  Training loss = 4.0361  Validation loss = 1.7155  \n",
      "\n",
      "Fold: 24  Epoch: 479  Training loss = 4.0358  Validation loss = 1.7152  \n",
      "\n",
      "Fold: 24  Epoch: 480  Training loss = 4.0354  Validation loss = 1.7149  \n",
      "\n",
      "Fold: 24  Epoch: 481  Training loss = 4.0351  Validation loss = 1.7146  \n",
      "\n",
      "Fold: 24  Epoch: 482  Training loss = 4.0348  Validation loss = 1.7144  \n",
      "\n",
      "Fold: 24  Epoch: 483  Training loss = 4.0345  Validation loss = 1.7141  \n",
      "\n",
      "Fold: 24  Epoch: 484  Training loss = 4.0343  Validation loss = 1.7139  \n",
      "\n",
      "Fold: 24  Epoch: 485  Training loss = 4.0339  Validation loss = 1.7136  \n",
      "\n",
      "Fold: 24  Epoch: 486  Training loss = 4.0335  Validation loss = 1.7133  \n",
      "\n",
      "Fold: 24  Epoch: 487  Training loss = 4.0331  Validation loss = 1.7130  \n",
      "\n",
      "Fold: 24  Epoch: 488  Training loss = 4.0328  Validation loss = 1.7127  \n",
      "\n",
      "Fold: 24  Epoch: 489  Training loss = 4.0325  Validation loss = 1.7124  \n",
      "\n",
      "Fold: 24  Epoch: 490  Training loss = 4.0321  Validation loss = 1.7121  \n",
      "\n",
      "Fold: 24  Epoch: 491  Training loss = 4.0318  Validation loss = 1.7118  \n",
      "\n",
      "Fold: 24  Epoch: 492  Training loss = 4.0315  Validation loss = 1.7116  \n",
      "\n",
      "Fold: 24  Epoch: 493  Training loss = 4.0311  Validation loss = 1.7112  \n",
      "\n",
      "Fold: 24  Epoch: 494  Training loss = 4.0308  Validation loss = 1.7109  \n",
      "\n",
      "Fold: 24  Epoch: 495  Training loss = 4.0305  Validation loss = 1.7107  \n",
      "\n",
      "Fold: 24  Epoch: 496  Training loss = 4.0303  Validation loss = 1.7105  \n",
      "\n",
      "Fold: 24  Epoch: 497  Training loss = 4.0300  Validation loss = 1.7102  \n",
      "\n",
      "Fold: 24  Epoch: 498  Training loss = 4.0297  Validation loss = 1.7100  \n",
      "\n",
      "Fold: 24  Epoch: 499  Training loss = 4.0294  Validation loss = 1.7098  \n",
      "\n",
      "Fold: 24  Epoch: 500  Training loss = 4.0290  Validation loss = 1.7094  \n",
      "\n",
      "Check model:  Fold: 24  Optimal epoch: 500  \n",
      "\n",
      "Fold: 25  Epoch: 1  Training loss = 3.9903  Validation loss = 2.5962  \n",
      "\n",
      "Fold: 25  Epoch: 2  Training loss = 3.9900  Validation loss = 2.5958  \n",
      "\n",
      "Fold: 25  Epoch: 3  Training loss = 3.9897  Validation loss = 2.5954  \n",
      "\n",
      "Fold: 25  Epoch: 4  Training loss = 3.9894  Validation loss = 2.5950  \n",
      "\n",
      "Fold: 25  Epoch: 5  Training loss = 3.9891  Validation loss = 2.5946  \n",
      "\n",
      "Fold: 25  Epoch: 6  Training loss = 3.9890  Validation loss = 2.5943  \n",
      "\n",
      "Fold: 25  Epoch: 7  Training loss = 3.9886  Validation loss = 2.5937  \n",
      "\n",
      "Fold: 25  Epoch: 8  Training loss = 3.9883  Validation loss = 2.5934  \n",
      "\n",
      "Fold: 25  Epoch: 9  Training loss = 3.9880  Validation loss = 2.5929  \n",
      "\n",
      "Fold: 25  Epoch: 10  Training loss = 3.9878  Validation loss = 2.5926  \n",
      "\n",
      "Fold: 25  Epoch: 11  Training loss = 3.9875  Validation loss = 2.5922  \n",
      "\n",
      "Fold: 25  Epoch: 12  Training loss = 3.9872  Validation loss = 2.5918  \n",
      "\n",
      "Fold: 25  Epoch: 13  Training loss = 3.9869  Validation loss = 2.5913  \n",
      "\n",
      "Fold: 25  Epoch: 14  Training loss = 3.9865  Validation loss = 2.5908  \n",
      "\n",
      "Fold: 25  Epoch: 15  Training loss = 3.9863  Validation loss = 2.5905  \n",
      "\n",
      "Fold: 25  Epoch: 16  Training loss = 3.9860  Validation loss = 2.5900  \n",
      "\n",
      "Fold: 25  Epoch: 17  Training loss = 3.9857  Validation loss = 2.5896  \n",
      "\n",
      "Fold: 25  Epoch: 18  Training loss = 3.9854  Validation loss = 2.5892  \n",
      "\n",
      "Fold: 25  Epoch: 19  Training loss = 3.9851  Validation loss = 2.5887  \n",
      "\n",
      "Fold: 25  Epoch: 20  Training loss = 3.9848  Validation loss = 2.5884  \n",
      "\n",
      "Fold: 25  Epoch: 21  Training loss = 3.9845  Validation loss = 2.5880  \n",
      "\n",
      "Fold: 25  Epoch: 22  Training loss = 3.9843  Validation loss = 2.5877  \n",
      "\n",
      "Fold: 25  Epoch: 23  Training loss = 3.9841  Validation loss = 2.5874  \n",
      "\n",
      "Fold: 25  Epoch: 24  Training loss = 3.9838  Validation loss = 2.5870  \n",
      "\n",
      "Fold: 25  Epoch: 25  Training loss = 3.9835  Validation loss = 2.5866  \n",
      "\n",
      "Fold: 25  Epoch: 26  Training loss = 3.9832  Validation loss = 2.5861  \n",
      "\n",
      "Fold: 25  Epoch: 27  Training loss = 3.9829  Validation loss = 2.5856  \n",
      "\n",
      "Fold: 25  Epoch: 28  Training loss = 3.9826  Validation loss = 2.5852  \n",
      "\n",
      "Fold: 25  Epoch: 29  Training loss = 3.9822  Validation loss = 2.5846  \n",
      "\n",
      "Fold: 25  Epoch: 30  Training loss = 3.9820  Validation loss = 2.5844  \n",
      "\n",
      "Fold: 25  Epoch: 31  Training loss = 3.9817  Validation loss = 2.5840  \n",
      "\n",
      "Fold: 25  Epoch: 32  Training loss = 3.9814  Validation loss = 2.5836  \n",
      "\n",
      "Fold: 25  Epoch: 33  Training loss = 3.9811  Validation loss = 2.5832  \n",
      "\n",
      "Fold: 25  Epoch: 34  Training loss = 3.9808  Validation loss = 2.5828  \n",
      "\n",
      "Fold: 25  Epoch: 35  Training loss = 3.9806  Validation loss = 2.5825  \n",
      "\n",
      "Fold: 25  Epoch: 36  Training loss = 3.9803  Validation loss = 2.5822  \n",
      "\n",
      "Fold: 25  Epoch: 37  Training loss = 3.9801  Validation loss = 2.5817  \n",
      "\n",
      "Fold: 25  Epoch: 38  Training loss = 3.9798  Validation loss = 2.5814  \n",
      "\n",
      "Fold: 25  Epoch: 39  Training loss = 3.9795  Validation loss = 2.5809  \n",
      "\n",
      "Fold: 25  Epoch: 40  Training loss = 3.9793  Validation loss = 2.5807  \n",
      "\n",
      "Fold: 25  Epoch: 41  Training loss = 3.9790  Validation loss = 2.5802  \n",
      "\n",
      "Fold: 25  Epoch: 42  Training loss = 3.9787  Validation loss = 2.5798  \n",
      "\n",
      "Fold: 25  Epoch: 43  Training loss = 3.9784  Validation loss = 2.5793  \n",
      "\n",
      "Fold: 25  Epoch: 44  Training loss = 3.9781  Validation loss = 2.5789  \n",
      "\n",
      "Fold: 25  Epoch: 45  Training loss = 3.9777  Validation loss = 2.5785  \n",
      "\n",
      "Fold: 25  Epoch: 46  Training loss = 3.9776  Validation loss = 2.5782  \n",
      "\n",
      "Fold: 25  Epoch: 47  Training loss = 3.9774  Validation loss = 2.5779  \n",
      "\n",
      "Fold: 25  Epoch: 48  Training loss = 3.9770  Validation loss = 2.5775  \n",
      "\n",
      "Fold: 25  Epoch: 49  Training loss = 3.9768  Validation loss = 2.5771  \n",
      "\n",
      "Fold: 25  Epoch: 50  Training loss = 3.9765  Validation loss = 2.5767  \n",
      "\n",
      "Fold: 25  Epoch: 51  Training loss = 3.9762  Validation loss = 2.5763  \n",
      "\n",
      "Fold: 25  Epoch: 52  Training loss = 3.9760  Validation loss = 2.5759  \n",
      "\n",
      "Fold: 25  Epoch: 53  Training loss = 3.9757  Validation loss = 2.5755  \n",
      "\n",
      "Fold: 25  Epoch: 54  Training loss = 3.9754  Validation loss = 2.5750  \n",
      "\n",
      "Fold: 25  Epoch: 55  Training loss = 3.9751  Validation loss = 2.5747  \n",
      "\n",
      "Fold: 25  Epoch: 56  Training loss = 3.9748  Validation loss = 2.5742  \n",
      "\n",
      "Fold: 25  Epoch: 57  Training loss = 3.9746  Validation loss = 2.5739  \n",
      "\n",
      "Fold: 25  Epoch: 58  Training loss = 3.9744  Validation loss = 2.5736  \n",
      "\n",
      "Fold: 25  Epoch: 59  Training loss = 3.9740  Validation loss = 2.5731  \n",
      "\n",
      "Fold: 25  Epoch: 60  Training loss = 3.9737  Validation loss = 2.5726  \n",
      "\n",
      "Fold: 25  Epoch: 61  Training loss = 3.9734  Validation loss = 2.5722  \n",
      "\n",
      "Fold: 25  Epoch: 62  Training loss = 3.9731  Validation loss = 2.5718  \n",
      "\n",
      "Fold: 25  Epoch: 63  Training loss = 3.9729  Validation loss = 2.5715  \n",
      "\n",
      "Fold: 25  Epoch: 64  Training loss = 3.9726  Validation loss = 2.5711  \n",
      "\n",
      "Fold: 25  Epoch: 65  Training loss = 3.9724  Validation loss = 2.5708  \n",
      "\n",
      "Fold: 25  Epoch: 66  Training loss = 3.9721  Validation loss = 2.5704  \n",
      "\n",
      "Fold: 25  Epoch: 67  Training loss = 3.9719  Validation loss = 2.5701  \n",
      "\n",
      "Fold: 25  Epoch: 68  Training loss = 3.9718  Validation loss = 2.5699  \n",
      "\n",
      "Fold: 25  Epoch: 69  Training loss = 3.9716  Validation loss = 2.5696  \n",
      "\n",
      "Fold: 25  Epoch: 70  Training loss = 3.9713  Validation loss = 2.5693  \n",
      "\n",
      "Fold: 25  Epoch: 71  Training loss = 3.9711  Validation loss = 2.5690  \n",
      "\n",
      "Fold: 25  Epoch: 72  Training loss = 3.9708  Validation loss = 2.5686  \n",
      "\n",
      "Fold: 25  Epoch: 73  Training loss = 3.9705  Validation loss = 2.5682  \n",
      "\n",
      "Fold: 25  Epoch: 74  Training loss = 3.9703  Validation loss = 2.5679  \n",
      "\n",
      "Fold: 25  Epoch: 75  Training loss = 3.9700  Validation loss = 2.5675  \n",
      "\n",
      "Fold: 25  Epoch: 76  Training loss = 3.9697  Validation loss = 2.5671  \n",
      "\n",
      "Fold: 25  Epoch: 77  Training loss = 3.9695  Validation loss = 2.5668  \n",
      "\n",
      "Fold: 25  Epoch: 78  Training loss = 3.9693  Validation loss = 2.5665  \n",
      "\n",
      "Fold: 25  Epoch: 79  Training loss = 3.9690  Validation loss = 2.5661  \n",
      "\n",
      "Fold: 25  Epoch: 80  Training loss = 3.9687  Validation loss = 2.5656  \n",
      "\n",
      "Fold: 25  Epoch: 81  Training loss = 3.9684  Validation loss = 2.5652  \n",
      "\n",
      "Fold: 25  Epoch: 82  Training loss = 3.9682  Validation loss = 2.5648  \n",
      "\n",
      "Fold: 25  Epoch: 83  Training loss = 3.9679  Validation loss = 2.5645  \n",
      "\n",
      "Fold: 25  Epoch: 84  Training loss = 3.9677  Validation loss = 2.5641  \n",
      "\n",
      "Fold: 25  Epoch: 85  Training loss = 3.9674  Validation loss = 2.5637  \n",
      "\n",
      "Fold: 25  Epoch: 86  Training loss = 3.9671  Validation loss = 2.5632  \n",
      "\n",
      "Fold: 25  Epoch: 87  Training loss = 3.9668  Validation loss = 2.5628  \n",
      "\n",
      "Fold: 25  Epoch: 88  Training loss = 3.9665  Validation loss = 2.5624  \n",
      "\n",
      "Fold: 25  Epoch: 89  Training loss = 3.9660  Validation loss = 2.5618  \n",
      "\n",
      "Fold: 25  Epoch: 90  Training loss = 3.9658  Validation loss = 2.5615  \n",
      "\n",
      "Fold: 25  Epoch: 91  Training loss = 3.9654  Validation loss = 2.5609  \n",
      "\n",
      "Fold: 25  Epoch: 92  Training loss = 3.9651  Validation loss = 2.5605  \n",
      "\n",
      "Fold: 25  Epoch: 93  Training loss = 3.9649  Validation loss = 2.5602  \n",
      "\n",
      "Fold: 25  Epoch: 94  Training loss = 3.9645  Validation loss = 2.5597  \n",
      "\n",
      "Fold: 25  Epoch: 95  Training loss = 3.9643  Validation loss = 2.5594  \n",
      "\n",
      "Fold: 25  Epoch: 96  Training loss = 3.9641  Validation loss = 2.5591  \n",
      "\n",
      "Fold: 25  Epoch: 97  Training loss = 3.9639  Validation loss = 2.5588  \n",
      "\n",
      "Fold: 25  Epoch: 98  Training loss = 3.9636  Validation loss = 2.5583  \n",
      "\n",
      "Fold: 25  Epoch: 99  Training loss = 3.9632  Validation loss = 2.5578  \n",
      "\n",
      "Fold: 25  Epoch: 100  Training loss = 3.9630  Validation loss = 2.5575  \n",
      "\n",
      "Fold: 25  Epoch: 101  Training loss = 3.9628  Validation loss = 2.5572  \n",
      "\n",
      "Fold: 25  Epoch: 102  Training loss = 3.9625  Validation loss = 2.5568  \n",
      "\n",
      "Fold: 25  Epoch: 103  Training loss = 3.9622  Validation loss = 2.5563  \n",
      "\n",
      "Fold: 25  Epoch: 104  Training loss = 3.9619  Validation loss = 2.5560  \n",
      "\n",
      "Fold: 25  Epoch: 105  Training loss = 3.9616  Validation loss = 2.5556  \n",
      "\n",
      "Fold: 25  Epoch: 106  Training loss = 3.9612  Validation loss = 2.5550  \n",
      "\n",
      "Fold: 25  Epoch: 107  Training loss = 3.9611  Validation loss = 2.5549  \n",
      "\n",
      "Fold: 25  Epoch: 108  Training loss = 3.9608  Validation loss = 2.5545  \n",
      "\n",
      "Fold: 25  Epoch: 109  Training loss = 3.9607  Validation loss = 2.5543  \n",
      "\n",
      "Fold: 25  Epoch: 110  Training loss = 3.9603  Validation loss = 2.5538  \n",
      "\n",
      "Fold: 25  Epoch: 111  Training loss = 3.9601  Validation loss = 2.5534  \n",
      "\n",
      "Fold: 25  Epoch: 112  Training loss = 3.9599  Validation loss = 2.5532  \n",
      "\n",
      "Fold: 25  Epoch: 113  Training loss = 3.9597  Validation loss = 2.5529  \n",
      "\n",
      "Fold: 25  Epoch: 114  Training loss = 3.9594  Validation loss = 2.5525  \n",
      "\n",
      "Fold: 25  Epoch: 115  Training loss = 3.9592  Validation loss = 2.5522  \n",
      "\n",
      "Fold: 25  Epoch: 116  Training loss = 3.9590  Validation loss = 2.5519  \n",
      "\n",
      "Fold: 25  Epoch: 117  Training loss = 3.9587  Validation loss = 2.5514  \n",
      "\n",
      "Fold: 25  Epoch: 118  Training loss = 3.9584  Validation loss = 2.5511  \n",
      "\n",
      "Fold: 25  Epoch: 119  Training loss = 3.9582  Validation loss = 2.5507  \n",
      "\n",
      "Fold: 25  Epoch: 120  Training loss = 3.9579  Validation loss = 2.5504  \n",
      "\n",
      "Fold: 25  Epoch: 121  Training loss = 3.9577  Validation loss = 2.5501  \n",
      "\n",
      "Fold: 25  Epoch: 122  Training loss = 3.9574  Validation loss = 2.5497  \n",
      "\n",
      "Fold: 25  Epoch: 123  Training loss = 3.9572  Validation loss = 2.5494  \n",
      "\n",
      "Fold: 25  Epoch: 124  Training loss = 3.9569  Validation loss = 2.5489  \n",
      "\n",
      "Fold: 25  Epoch: 125  Training loss = 3.9565  Validation loss = 2.5483  \n",
      "\n",
      "Fold: 25  Epoch: 126  Training loss = 3.9562  Validation loss = 2.5479  \n",
      "\n",
      "Fold: 25  Epoch: 127  Training loss = 3.9560  Validation loss = 2.5477  \n",
      "\n",
      "Fold: 25  Epoch: 128  Training loss = 3.9557  Validation loss = 2.5473  \n",
      "\n",
      "Fold: 25  Epoch: 129  Training loss = 3.9556  Validation loss = 2.5470  \n",
      "\n",
      "Fold: 25  Epoch: 130  Training loss = 3.9554  Validation loss = 2.5467  \n",
      "\n",
      "Fold: 25  Epoch: 131  Training loss = 3.9551  Validation loss = 2.5463  \n",
      "\n",
      "Fold: 25  Epoch: 132  Training loss = 3.9547  Validation loss = 2.5458  \n",
      "\n",
      "Fold: 25  Epoch: 133  Training loss = 3.9545  Validation loss = 2.5456  \n",
      "\n",
      "Fold: 25  Epoch: 134  Training loss = 3.9543  Validation loss = 2.5452  \n",
      "\n",
      "Fold: 25  Epoch: 135  Training loss = 3.9540  Validation loss = 2.5448  \n",
      "\n",
      "Fold: 25  Epoch: 136  Training loss = 3.9538  Validation loss = 2.5444  \n",
      "\n",
      "Fold: 25  Epoch: 137  Training loss = 3.9535  Validation loss = 2.5441  \n",
      "\n",
      "Fold: 25  Epoch: 138  Training loss = 3.9533  Validation loss = 2.5438  \n",
      "\n",
      "Fold: 25  Epoch: 139  Training loss = 3.9530  Validation loss = 2.5434  \n",
      "\n",
      "Fold: 25  Epoch: 140  Training loss = 3.9528  Validation loss = 2.5430  \n",
      "\n",
      "Fold: 25  Epoch: 141  Training loss = 3.9524  Validation loss = 2.5426  \n",
      "\n",
      "Fold: 25  Epoch: 142  Training loss = 3.9521  Validation loss = 2.5422  \n",
      "\n",
      "Fold: 25  Epoch: 143  Training loss = 3.9519  Validation loss = 2.5418  \n",
      "\n",
      "Fold: 25  Epoch: 144  Training loss = 3.9516  Validation loss = 2.5415  \n",
      "\n",
      "Fold: 25  Epoch: 145  Training loss = 3.9514  Validation loss = 2.5411  \n",
      "\n",
      "Fold: 25  Epoch: 146  Training loss = 3.9510  Validation loss = 2.5407  \n",
      "\n",
      "Fold: 25  Epoch: 147  Training loss = 3.9508  Validation loss = 2.5404  \n",
      "\n",
      "Fold: 25  Epoch: 148  Training loss = 3.9506  Validation loss = 2.5401  \n",
      "\n",
      "Fold: 25  Epoch: 149  Training loss = 3.9504  Validation loss = 2.5398  \n",
      "\n",
      "Fold: 25  Epoch: 150  Training loss = 3.9501  Validation loss = 2.5394  \n",
      "\n",
      "Fold: 25  Epoch: 151  Training loss = 3.9499  Validation loss = 2.5391  \n",
      "\n",
      "Fold: 25  Epoch: 152  Training loss = 3.9496  Validation loss = 2.5387  \n",
      "\n",
      "Fold: 25  Epoch: 153  Training loss = 3.9494  Validation loss = 2.5383  \n",
      "\n",
      "Fold: 25  Epoch: 154  Training loss = 3.9491  Validation loss = 2.5379  \n",
      "\n",
      "Fold: 25  Epoch: 155  Training loss = 3.9488  Validation loss = 2.5374  \n",
      "\n",
      "Fold: 25  Epoch: 156  Training loss = 3.9485  Validation loss = 2.5370  \n",
      "\n",
      "Fold: 25  Epoch: 157  Training loss = 3.9481  Validation loss = 2.5365  \n",
      "\n",
      "Fold: 25  Epoch: 158  Training loss = 3.9479  Validation loss = 2.5363  \n",
      "\n",
      "Fold: 25  Epoch: 159  Training loss = 3.9476  Validation loss = 2.5359  \n",
      "\n",
      "Fold: 25  Epoch: 160  Training loss = 3.9475  Validation loss = 2.5356  \n",
      "\n",
      "Fold: 25  Epoch: 161  Training loss = 3.9473  Validation loss = 2.5354  \n",
      "\n",
      "Fold: 25  Epoch: 162  Training loss = 3.9470  Validation loss = 2.5350  \n",
      "\n",
      "Fold: 25  Epoch: 163  Training loss = 3.9467  Validation loss = 2.5346  \n",
      "\n",
      "Fold: 25  Epoch: 164  Training loss = 3.9465  Validation loss = 2.5343  \n",
      "\n",
      "Fold: 25  Epoch: 165  Training loss = 3.9463  Validation loss = 2.5340  \n",
      "\n",
      "Fold: 25  Epoch: 166  Training loss = 3.9460  Validation loss = 2.5335  \n",
      "\n",
      "Fold: 25  Epoch: 167  Training loss = 3.9457  Validation loss = 2.5332  \n",
      "\n",
      "Fold: 25  Epoch: 168  Training loss = 3.9454  Validation loss = 2.5327  \n",
      "\n",
      "Fold: 25  Epoch: 169  Training loss = 3.9452  Validation loss = 2.5324  \n",
      "\n",
      "Fold: 25  Epoch: 170  Training loss = 3.9450  Validation loss = 2.5321  \n",
      "\n",
      "Fold: 25  Epoch: 171  Training loss = 3.9448  Validation loss = 2.5317  \n",
      "\n",
      "Fold: 25  Epoch: 172  Training loss = 3.9445  Validation loss = 2.5313  \n",
      "\n",
      "Fold: 25  Epoch: 173  Training loss = 3.9443  Validation loss = 2.5310  \n",
      "\n",
      "Fold: 25  Epoch: 174  Training loss = 3.9441  Validation loss = 2.5307  \n",
      "\n",
      "Fold: 25  Epoch: 175  Training loss = 3.9438  Validation loss = 2.5304  \n",
      "\n",
      "Fold: 25  Epoch: 176  Training loss = 3.9435  Validation loss = 2.5299  \n",
      "\n",
      "Fold: 25  Epoch: 177  Training loss = 3.9433  Validation loss = 2.5296  \n",
      "\n",
      "Fold: 25  Epoch: 178  Training loss = 3.9430  Validation loss = 2.5292  \n",
      "\n",
      "Fold: 25  Epoch: 179  Training loss = 3.9427  Validation loss = 2.5288  \n",
      "\n",
      "Fold: 25  Epoch: 180  Training loss = 3.9424  Validation loss = 2.5284  \n",
      "\n",
      "Fold: 25  Epoch: 181  Training loss = 3.9421  Validation loss = 2.5280  \n",
      "\n",
      "Fold: 25  Epoch: 182  Training loss = 3.9420  Validation loss = 2.5278  \n",
      "\n",
      "Fold: 25  Epoch: 183  Training loss = 3.9417  Validation loss = 2.5274  \n",
      "\n",
      "Fold: 25  Epoch: 184  Training loss = 3.9414  Validation loss = 2.5270  \n",
      "\n",
      "Fold: 25  Epoch: 185  Training loss = 3.9412  Validation loss = 2.5267  \n",
      "\n",
      "Fold: 25  Epoch: 186  Training loss = 3.9410  Validation loss = 2.5263  \n",
      "\n",
      "Fold: 25  Epoch: 187  Training loss = 3.9407  Validation loss = 2.5259  \n",
      "\n",
      "Fold: 25  Epoch: 188  Training loss = 3.9403  Validation loss = 2.5254  \n",
      "\n",
      "Fold: 25  Epoch: 189  Training loss = 3.9401  Validation loss = 2.5250  \n",
      "\n",
      "Fold: 25  Epoch: 190  Training loss = 3.9399  Validation loss = 2.5248  \n",
      "\n",
      "Fold: 25  Epoch: 191  Training loss = 3.9396  Validation loss = 2.5244  \n",
      "\n",
      "Fold: 25  Epoch: 192  Training loss = 3.9393  Validation loss = 2.5240  \n",
      "\n",
      "Fold: 25  Epoch: 193  Training loss = 3.9391  Validation loss = 2.5236  \n",
      "\n",
      "Fold: 25  Epoch: 194  Training loss = 3.9389  Validation loss = 2.5233  \n",
      "\n",
      "Fold: 25  Epoch: 195  Training loss = 3.9387  Validation loss = 2.5230  \n",
      "\n",
      "Fold: 25  Epoch: 196  Training loss = 3.9384  Validation loss = 2.5226  \n",
      "\n",
      "Fold: 25  Epoch: 197  Training loss = 3.9381  Validation loss = 2.5221  \n",
      "\n",
      "Fold: 25  Epoch: 198  Training loss = 3.9378  Validation loss = 2.5218  \n",
      "\n",
      "Fold: 25  Epoch: 199  Training loss = 3.9377  Validation loss = 2.5216  \n",
      "\n",
      "Fold: 25  Epoch: 200  Training loss = 3.9375  Validation loss = 2.5213  \n",
      "\n",
      "Fold: 25  Epoch: 201  Training loss = 3.9371  Validation loss = 2.5208  \n",
      "\n",
      "Fold: 25  Epoch: 202  Training loss = 3.9369  Validation loss = 2.5204  \n",
      "\n",
      "Fold: 25  Epoch: 203  Training loss = 3.9366  Validation loss = 2.5200  \n",
      "\n",
      "Fold: 25  Epoch: 204  Training loss = 3.9364  Validation loss = 2.5197  \n",
      "\n",
      "Fold: 25  Epoch: 205  Training loss = 3.9361  Validation loss = 2.5193  \n",
      "\n",
      "Fold: 25  Epoch: 206  Training loss = 3.9359  Validation loss = 2.5190  \n",
      "\n",
      "Fold: 25  Epoch: 207  Training loss = 3.9356  Validation loss = 2.5186  \n",
      "\n",
      "Fold: 25  Epoch: 208  Training loss = 3.9354  Validation loss = 2.5183  \n",
      "\n",
      "Fold: 25  Epoch: 209  Training loss = 3.9352  Validation loss = 2.5181  \n",
      "\n",
      "Fold: 25  Epoch: 210  Training loss = 3.9349  Validation loss = 2.5176  \n",
      "\n",
      "Fold: 25  Epoch: 211  Training loss = 3.9347  Validation loss = 2.5173  \n",
      "\n",
      "Fold: 25  Epoch: 212  Training loss = 3.9344  Validation loss = 2.5170  \n",
      "\n",
      "Fold: 25  Epoch: 213  Training loss = 3.9342  Validation loss = 2.5166  \n",
      "\n",
      "Fold: 25  Epoch: 214  Training loss = 3.9340  Validation loss = 2.5163  \n",
      "\n",
      "Fold: 25  Epoch: 215  Training loss = 3.9337  Validation loss = 2.5160  \n",
      "\n",
      "Fold: 25  Epoch: 216  Training loss = 3.9334  Validation loss = 2.5155  \n",
      "\n",
      "Fold: 25  Epoch: 217  Training loss = 3.9332  Validation loss = 2.5152  \n",
      "\n",
      "Fold: 25  Epoch: 218  Training loss = 3.9329  Validation loss = 2.5148  \n",
      "\n",
      "Fold: 25  Epoch: 219  Training loss = 3.9326  Validation loss = 2.5143  \n",
      "\n",
      "Fold: 25  Epoch: 220  Training loss = 3.9324  Validation loss = 2.5140  \n",
      "\n",
      "Fold: 25  Epoch: 221  Training loss = 3.9321  Validation loss = 2.5136  \n",
      "\n",
      "Fold: 25  Epoch: 222  Training loss = 3.9318  Validation loss = 2.5132  \n",
      "\n",
      "Fold: 25  Epoch: 223  Training loss = 3.9316  Validation loss = 2.5128  \n",
      "\n",
      "Fold: 25  Epoch: 224  Training loss = 3.9313  Validation loss = 2.5124  \n",
      "\n",
      "Fold: 25  Epoch: 225  Training loss = 3.9311  Validation loss = 2.5120  \n",
      "\n",
      "Fold: 25  Epoch: 226  Training loss = 3.9308  Validation loss = 2.5116  \n",
      "\n",
      "Fold: 25  Epoch: 227  Training loss = 3.9305  Validation loss = 2.5112  \n",
      "\n",
      "Fold: 25  Epoch: 228  Training loss = 3.9302  Validation loss = 2.5108  \n",
      "\n",
      "Fold: 25  Epoch: 229  Training loss = 3.9299  Validation loss = 2.5103  \n",
      "\n",
      "Fold: 25  Epoch: 230  Training loss = 3.9296  Validation loss = 2.5100  \n",
      "\n",
      "Fold: 25  Epoch: 231  Training loss = 3.9293  Validation loss = 2.5095  \n",
      "\n",
      "Fold: 25  Epoch: 232  Training loss = 3.9290  Validation loss = 2.5092  \n",
      "\n",
      "Fold: 25  Epoch: 233  Training loss = 3.9288  Validation loss = 2.5088  \n",
      "\n",
      "Fold: 25  Epoch: 234  Training loss = 3.9285  Validation loss = 2.5084  \n",
      "\n",
      "Fold: 25  Epoch: 235  Training loss = 3.9282  Validation loss = 2.5081  \n",
      "\n",
      "Fold: 25  Epoch: 236  Training loss = 3.9279  Validation loss = 2.5076  \n",
      "\n",
      "Fold: 25  Epoch: 237  Training loss = 3.9276  Validation loss = 2.5072  \n",
      "\n",
      "Fold: 25  Epoch: 238  Training loss = 3.9274  Validation loss = 2.5069  \n",
      "\n",
      "Fold: 25  Epoch: 239  Training loss = 3.9272  Validation loss = 2.5065  \n",
      "\n",
      "Fold: 25  Epoch: 240  Training loss = 3.9269  Validation loss = 2.5062  \n",
      "\n",
      "Fold: 25  Epoch: 241  Training loss = 3.9267  Validation loss = 2.5059  \n",
      "\n",
      "Fold: 25  Epoch: 242  Training loss = 3.9264  Validation loss = 2.5055  \n",
      "\n",
      "Fold: 25  Epoch: 243  Training loss = 3.9262  Validation loss = 2.5051  \n",
      "\n",
      "Fold: 25  Epoch: 244  Training loss = 3.9259  Validation loss = 2.5047  \n",
      "\n",
      "Fold: 25  Epoch: 245  Training loss = 3.9256  Validation loss = 2.5044  \n",
      "\n",
      "Fold: 25  Epoch: 246  Training loss = 3.9253  Validation loss = 2.5039  \n",
      "\n",
      "Fold: 25  Epoch: 247  Training loss = 3.9251  Validation loss = 2.5037  \n",
      "\n",
      "Fold: 25  Epoch: 248  Training loss = 3.9249  Validation loss = 2.5033  \n",
      "\n",
      "Fold: 25  Epoch: 249  Training loss = 3.9247  Validation loss = 2.5030  \n",
      "\n",
      "Fold: 25  Epoch: 250  Training loss = 3.9244  Validation loss = 2.5025  \n",
      "\n",
      "Fold: 25  Epoch: 251  Training loss = 3.9241  Validation loss = 2.5021  \n",
      "\n",
      "Fold: 25  Epoch: 252  Training loss = 3.9239  Validation loss = 2.5018  \n",
      "\n",
      "Fold: 25  Epoch: 253  Training loss = 3.9236  Validation loss = 2.5014  \n",
      "\n",
      "Fold: 25  Epoch: 254  Training loss = 3.9234  Validation loss = 2.5011  \n",
      "\n",
      "Fold: 25  Epoch: 255  Training loss = 3.9231  Validation loss = 2.5008  \n",
      "\n",
      "Fold: 25  Epoch: 256  Training loss = 3.9229  Validation loss = 2.5005  \n",
      "\n",
      "Fold: 25  Epoch: 257  Training loss = 3.9226  Validation loss = 2.5000  \n",
      "\n",
      "Fold: 25  Epoch: 258  Training loss = 3.9223  Validation loss = 2.4996  \n",
      "\n",
      "Fold: 25  Epoch: 259  Training loss = 3.9220  Validation loss = 2.4992  \n",
      "\n",
      "Fold: 25  Epoch: 260  Training loss = 3.9217  Validation loss = 2.4987  \n",
      "\n",
      "Fold: 25  Epoch: 261  Training loss = 3.9215  Validation loss = 2.4984  \n",
      "\n",
      "Fold: 25  Epoch: 262  Training loss = 3.9212  Validation loss = 2.4980  \n",
      "\n",
      "Fold: 25  Epoch: 263  Training loss = 3.9210  Validation loss = 2.4978  \n",
      "\n",
      "Fold: 25  Epoch: 264  Training loss = 3.9207  Validation loss = 2.4974  \n",
      "\n",
      "Fold: 25  Epoch: 265  Training loss = 3.9205  Validation loss = 2.4970  \n",
      "\n",
      "Fold: 25  Epoch: 266  Training loss = 3.9203  Validation loss = 2.4967  \n",
      "\n",
      "Fold: 25  Epoch: 267  Training loss = 3.9200  Validation loss = 2.4963  \n",
      "\n",
      "Fold: 25  Epoch: 268  Training loss = 3.9198  Validation loss = 2.4960  \n",
      "\n",
      "Fold: 25  Epoch: 269  Training loss = 3.9195  Validation loss = 2.4956  \n",
      "\n",
      "Fold: 25  Epoch: 270  Training loss = 3.9194  Validation loss = 2.4954  \n",
      "\n",
      "Fold: 25  Epoch: 271  Training loss = 3.9191  Validation loss = 2.4951  \n",
      "\n",
      "Fold: 25  Epoch: 272  Training loss = 3.9189  Validation loss = 2.4948  \n",
      "\n",
      "Fold: 25  Epoch: 273  Training loss = 3.9185  Validation loss = 2.4943  \n",
      "\n",
      "Fold: 25  Epoch: 274  Training loss = 3.9183  Validation loss = 2.4939  \n",
      "\n",
      "Fold: 25  Epoch: 275  Training loss = 3.9180  Validation loss = 2.4935  \n",
      "\n",
      "Fold: 25  Epoch: 276  Training loss = 3.9177  Validation loss = 2.4931  \n",
      "\n",
      "Fold: 25  Epoch: 277  Training loss = 3.9174  Validation loss = 2.4927  \n",
      "\n",
      "Fold: 25  Epoch: 278  Training loss = 3.9173  Validation loss = 2.4924  \n",
      "\n",
      "Fold: 25  Epoch: 279  Training loss = 3.9170  Validation loss = 2.4920  \n",
      "\n",
      "Fold: 25  Epoch: 280  Training loss = 3.9167  Validation loss = 2.4916  \n",
      "\n",
      "Fold: 25  Epoch: 281  Training loss = 3.9164  Validation loss = 2.4912  \n",
      "\n",
      "Fold: 25  Epoch: 282  Training loss = 3.9161  Validation loss = 2.4908  \n",
      "\n",
      "Fold: 25  Epoch: 283  Training loss = 3.9158  Validation loss = 2.4903  \n",
      "\n",
      "Fold: 25  Epoch: 284  Training loss = 3.9154  Validation loss = 2.4898  \n",
      "\n",
      "Fold: 25  Epoch: 285  Training loss = 3.9152  Validation loss = 2.4895  \n",
      "\n",
      "Fold: 25  Epoch: 286  Training loss = 3.9149  Validation loss = 2.4891  \n",
      "\n",
      "Fold: 25  Epoch: 287  Training loss = 3.9146  Validation loss = 2.4887  \n",
      "\n",
      "Fold: 25  Epoch: 288  Training loss = 3.9144  Validation loss = 2.4884  \n",
      "\n",
      "Fold: 25  Epoch: 289  Training loss = 3.9141  Validation loss = 2.4879  \n",
      "\n",
      "Fold: 25  Epoch: 290  Training loss = 3.9138  Validation loss = 2.4876  \n",
      "\n",
      "Fold: 25  Epoch: 291  Training loss = 3.9136  Validation loss = 2.4873  \n",
      "\n",
      "Fold: 25  Epoch: 292  Training loss = 3.9133  Validation loss = 2.4868  \n",
      "\n",
      "Fold: 25  Epoch: 293  Training loss = 3.9130  Validation loss = 2.4864  \n",
      "\n",
      "Fold: 25  Epoch: 294  Training loss = 3.9128  Validation loss = 2.4861  \n",
      "\n",
      "Fold: 25  Epoch: 295  Training loss = 3.9125  Validation loss = 2.4858  \n",
      "\n",
      "Fold: 25  Epoch: 296  Training loss = 3.9123  Validation loss = 2.4854  \n",
      "\n",
      "Fold: 25  Epoch: 297  Training loss = 3.9120  Validation loss = 2.4851  \n",
      "\n",
      "Fold: 25  Epoch: 298  Training loss = 3.9118  Validation loss = 2.4847  \n",
      "\n",
      "Fold: 25  Epoch: 299  Training loss = 3.9114  Validation loss = 2.4842  \n",
      "\n",
      "Fold: 25  Epoch: 300  Training loss = 3.9112  Validation loss = 2.4839  \n",
      "\n",
      "Fold: 25  Epoch: 301  Training loss = 3.9108  Validation loss = 2.4834  \n",
      "\n",
      "Fold: 25  Epoch: 302  Training loss = 3.9106  Validation loss = 2.4831  \n",
      "\n",
      "Fold: 25  Epoch: 303  Training loss = 3.9103  Validation loss = 2.4826  \n",
      "\n",
      "Fold: 25  Epoch: 304  Training loss = 3.9101  Validation loss = 2.4824  \n",
      "\n",
      "Fold: 25  Epoch: 305  Training loss = 3.9097  Validation loss = 2.4819  \n",
      "\n",
      "Fold: 25  Epoch: 306  Training loss = 3.9095  Validation loss = 2.4816  \n",
      "\n",
      "Fold: 25  Epoch: 307  Training loss = 3.9093  Validation loss = 2.4813  \n",
      "\n",
      "Fold: 25  Epoch: 308  Training loss = 3.9091  Validation loss = 2.4811  \n",
      "\n",
      "Fold: 25  Epoch: 309  Training loss = 3.9089  Validation loss = 2.4808  \n",
      "\n",
      "Fold: 25  Epoch: 310  Training loss = 3.9088  Validation loss = 2.4805  \n",
      "\n",
      "Fold: 25  Epoch: 311  Training loss = 3.9084  Validation loss = 2.4801  \n",
      "\n",
      "Fold: 25  Epoch: 312  Training loss = 3.9081  Validation loss = 2.4795  \n",
      "\n",
      "Fold: 25  Epoch: 313  Training loss = 3.9078  Validation loss = 2.4792  \n",
      "\n",
      "Fold: 25  Epoch: 314  Training loss = 3.9077  Validation loss = 2.4790  \n",
      "\n",
      "Fold: 25  Epoch: 315  Training loss = 3.9075  Validation loss = 2.4787  \n",
      "\n",
      "Fold: 25  Epoch: 316  Training loss = 3.9072  Validation loss = 2.4784  \n",
      "\n",
      "Fold: 25  Epoch: 317  Training loss = 3.9069  Validation loss = 2.4778  \n",
      "\n",
      "Fold: 25  Epoch: 318  Training loss = 3.9066  Validation loss = 2.4775  \n",
      "\n",
      "Fold: 25  Epoch: 319  Training loss = 3.9064  Validation loss = 2.4772  \n",
      "\n",
      "Fold: 25  Epoch: 320  Training loss = 3.9060  Validation loss = 2.4766  \n",
      "\n",
      "Fold: 25  Epoch: 321  Training loss = 3.9057  Validation loss = 2.4761  \n",
      "\n",
      "Fold: 25  Epoch: 322  Training loss = 3.9053  Validation loss = 2.4756  \n",
      "\n",
      "Fold: 25  Epoch: 323  Training loss = 3.9050  Validation loss = 2.4751  \n",
      "\n",
      "Fold: 25  Epoch: 324  Training loss = 3.9048  Validation loss = 2.4748  \n",
      "\n",
      "Fold: 25  Epoch: 325  Training loss = 3.9045  Validation loss = 2.4745  \n",
      "\n",
      "Fold: 25  Epoch: 326  Training loss = 3.9043  Validation loss = 2.4741  \n",
      "\n",
      "Fold: 25  Epoch: 327  Training loss = 3.9040  Validation loss = 2.4737  \n",
      "\n",
      "Fold: 25  Epoch: 328  Training loss = 3.9037  Validation loss = 2.4733  \n",
      "\n",
      "Fold: 25  Epoch: 329  Training loss = 3.9035  Validation loss = 2.4730  \n",
      "\n",
      "Fold: 25  Epoch: 330  Training loss = 3.9033  Validation loss = 2.4726  \n",
      "\n",
      "Fold: 25  Epoch: 331  Training loss = 3.9030  Validation loss = 2.4722  \n",
      "\n",
      "Fold: 25  Epoch: 332  Training loss = 3.9027  Validation loss = 2.4719  \n",
      "\n",
      "Fold: 25  Epoch: 333  Training loss = 3.9025  Validation loss = 2.4715  \n",
      "\n",
      "Fold: 25  Epoch: 334  Training loss = 3.9022  Validation loss = 2.4711  \n",
      "\n",
      "Fold: 25  Epoch: 335  Training loss = 3.9020  Validation loss = 2.4708  \n",
      "\n",
      "Fold: 25  Epoch: 336  Training loss = 3.9018  Validation loss = 2.4705  \n",
      "\n",
      "Fold: 25  Epoch: 337  Training loss = 3.9016  Validation loss = 2.4702  \n",
      "\n",
      "Fold: 25  Epoch: 338  Training loss = 3.9013  Validation loss = 2.4698  \n",
      "\n",
      "Fold: 25  Epoch: 339  Training loss = 3.9011  Validation loss = 2.4696  \n",
      "\n",
      "Fold: 25  Epoch: 340  Training loss = 3.9008  Validation loss = 2.4692  \n",
      "\n",
      "Fold: 25  Epoch: 341  Training loss = 3.9005  Validation loss = 2.4688  \n",
      "\n",
      "Fold: 25  Epoch: 342  Training loss = 3.9003  Validation loss = 2.4684  \n",
      "\n",
      "Fold: 25  Epoch: 343  Training loss = 3.9000  Validation loss = 2.4680  \n",
      "\n",
      "Fold: 25  Epoch: 344  Training loss = 3.8998  Validation loss = 2.4676  \n",
      "\n",
      "Fold: 25  Epoch: 345  Training loss = 3.8995  Validation loss = 2.4673  \n",
      "\n",
      "Fold: 25  Epoch: 346  Training loss = 3.8993  Validation loss = 2.4670  \n",
      "\n",
      "Fold: 25  Epoch: 347  Training loss = 3.8992  Validation loss = 2.4668  \n",
      "\n",
      "Fold: 25  Epoch: 348  Training loss = 3.8988  Validation loss = 2.4663  \n",
      "\n",
      "Fold: 25  Epoch: 349  Training loss = 3.8984  Validation loss = 2.4658  \n",
      "\n",
      "Fold: 25  Epoch: 350  Training loss = 3.8983  Validation loss = 2.4656  \n",
      "\n",
      "Fold: 25  Epoch: 351  Training loss = 3.8981  Validation loss = 2.4653  \n",
      "\n",
      "Fold: 25  Epoch: 352  Training loss = 3.8980  Validation loss = 2.4651  \n",
      "\n",
      "Fold: 25  Epoch: 353  Training loss = 3.8978  Validation loss = 2.4649  \n",
      "\n",
      "Fold: 25  Epoch: 354  Training loss = 3.8976  Validation loss = 2.4646  \n",
      "\n",
      "Fold: 25  Epoch: 355  Training loss = 3.8973  Validation loss = 2.4642  \n",
      "\n",
      "Fold: 25  Epoch: 356  Training loss = 3.8972  Validation loss = 2.4640  \n",
      "\n",
      "Fold: 25  Epoch: 357  Training loss = 3.8969  Validation loss = 2.4637  \n",
      "\n",
      "Fold: 25  Epoch: 358  Training loss = 3.8968  Validation loss = 2.4635  \n",
      "\n",
      "Fold: 25  Epoch: 359  Training loss = 3.8966  Validation loss = 2.4632  \n",
      "\n",
      "Fold: 25  Epoch: 360  Training loss = 3.8964  Validation loss = 2.4629  \n",
      "\n",
      "Fold: 25  Epoch: 361  Training loss = 3.8962  Validation loss = 2.4626  \n",
      "\n",
      "Fold: 25  Epoch: 362  Training loss = 3.8959  Validation loss = 2.4623  \n",
      "\n",
      "Fold: 25  Epoch: 363  Training loss = 3.8956  Validation loss = 2.4618  \n",
      "\n",
      "Fold: 25  Epoch: 364  Training loss = 3.8954  Validation loss = 2.4615  \n",
      "\n",
      "Fold: 25  Epoch: 365  Training loss = 3.8952  Validation loss = 2.4612  \n",
      "\n",
      "Fold: 25  Epoch: 366  Training loss = 3.8949  Validation loss = 2.4608  \n",
      "\n",
      "Fold: 25  Epoch: 367  Training loss = 3.8947  Validation loss = 2.4604  \n",
      "\n",
      "Fold: 25  Epoch: 368  Training loss = 3.8944  Validation loss = 2.4600  \n",
      "\n",
      "Fold: 25  Epoch: 369  Training loss = 3.8941  Validation loss = 2.4596  \n",
      "\n",
      "Fold: 25  Epoch: 370  Training loss = 3.8938  Validation loss = 2.4592  \n",
      "\n",
      "Fold: 25  Epoch: 371  Training loss = 3.8936  Validation loss = 2.4589  \n",
      "\n",
      "Fold: 25  Epoch: 372  Training loss = 3.8933  Validation loss = 2.4585  \n",
      "\n",
      "Fold: 25  Epoch: 373  Training loss = 3.8931  Validation loss = 2.4583  \n",
      "\n",
      "Fold: 25  Epoch: 374  Training loss = 3.8928  Validation loss = 2.4578  \n",
      "\n",
      "Fold: 25  Epoch: 375  Training loss = 3.8925  Validation loss = 2.4574  \n",
      "\n",
      "Fold: 25  Epoch: 376  Training loss = 3.8922  Validation loss = 2.4570  \n",
      "\n",
      "Fold: 25  Epoch: 377  Training loss = 3.8919  Validation loss = 2.4565  \n",
      "\n",
      "Fold: 25  Epoch: 378  Training loss = 3.8917  Validation loss = 2.4562  \n",
      "\n",
      "Fold: 25  Epoch: 379  Training loss = 3.8915  Validation loss = 2.4559  \n",
      "\n",
      "Fold: 25  Epoch: 380  Training loss = 3.8912  Validation loss = 2.4554  \n",
      "\n",
      "Fold: 25  Epoch: 381  Training loss = 3.8910  Validation loss = 2.4552  \n",
      "\n",
      "Fold: 25  Epoch: 382  Training loss = 3.8907  Validation loss = 2.4548  \n",
      "\n",
      "Fold: 25  Epoch: 383  Training loss = 3.8904  Validation loss = 2.4544  \n",
      "\n",
      "Fold: 25  Epoch: 384  Training loss = 3.8902  Validation loss = 2.4541  \n",
      "\n",
      "Fold: 25  Epoch: 385  Training loss = 3.8899  Validation loss = 2.4536  \n",
      "\n",
      "Fold: 25  Epoch: 386  Training loss = 3.8897  Validation loss = 2.4533  \n",
      "\n",
      "Fold: 25  Epoch: 387  Training loss = 3.8893  Validation loss = 2.4528  \n",
      "\n",
      "Fold: 25  Epoch: 388  Training loss = 3.8891  Validation loss = 2.4525  \n",
      "\n",
      "Fold: 25  Epoch: 389  Training loss = 3.8888  Validation loss = 2.4521  \n",
      "\n",
      "Fold: 25  Epoch: 390  Training loss = 3.8886  Validation loss = 2.4517  \n",
      "\n",
      "Fold: 25  Epoch: 391  Training loss = 3.8884  Validation loss = 2.4514  \n",
      "\n",
      "Fold: 25  Epoch: 392  Training loss = 3.8881  Validation loss = 2.4510  \n",
      "\n",
      "Fold: 25  Epoch: 393  Training loss = 3.8878  Validation loss = 2.4506  \n",
      "\n",
      "Fold: 25  Epoch: 394  Training loss = 3.8876  Validation loss = 2.4503  \n",
      "\n",
      "Fold: 25  Epoch: 395  Training loss = 3.8873  Validation loss = 2.4499  \n",
      "\n",
      "Fold: 25  Epoch: 396  Training loss = 3.8870  Validation loss = 2.4495  \n",
      "\n",
      "Fold: 25  Epoch: 397  Training loss = 3.8867  Validation loss = 2.4491  \n",
      "\n",
      "Fold: 25  Epoch: 398  Training loss = 3.8865  Validation loss = 2.4487  \n",
      "\n",
      "Fold: 25  Epoch: 399  Training loss = 3.8862  Validation loss = 2.4482  \n",
      "\n",
      "Fold: 25  Epoch: 400  Training loss = 3.8859  Validation loss = 2.4478  \n",
      "\n",
      "Fold: 25  Epoch: 401  Training loss = 3.8857  Validation loss = 2.4475  \n",
      "\n",
      "Fold: 25  Epoch: 402  Training loss = 3.8854  Validation loss = 2.4471  \n",
      "\n",
      "Fold: 25  Epoch: 403  Training loss = 3.8851  Validation loss = 2.4467  \n",
      "\n",
      "Fold: 25  Epoch: 404  Training loss = 3.8849  Validation loss = 2.4464  \n",
      "\n",
      "Fold: 25  Epoch: 405  Training loss = 3.8846  Validation loss = 2.4460  \n",
      "\n",
      "Fold: 25  Epoch: 406  Training loss = 3.8844  Validation loss = 2.4457  \n",
      "\n",
      "Fold: 25  Epoch: 407  Training loss = 3.8842  Validation loss = 2.4454  \n",
      "\n",
      "Fold: 25  Epoch: 408  Training loss = 3.8840  Validation loss = 2.4451  \n",
      "\n",
      "Fold: 25  Epoch: 409  Training loss = 3.8837  Validation loss = 2.4447  \n",
      "\n",
      "Fold: 25  Epoch: 410  Training loss = 3.8834  Validation loss = 2.4443  \n",
      "\n",
      "Fold: 25  Epoch: 411  Training loss = 3.8831  Validation loss = 2.4438  \n",
      "\n",
      "Fold: 25  Epoch: 412  Training loss = 3.8828  Validation loss = 2.4433  \n",
      "\n",
      "Fold: 25  Epoch: 413  Training loss = 3.8825  Validation loss = 2.4430  \n",
      "\n",
      "Fold: 25  Epoch: 414  Training loss = 3.8824  Validation loss = 2.4427  \n",
      "\n",
      "Fold: 25  Epoch: 415  Training loss = 3.8821  Validation loss = 2.4424  \n",
      "\n",
      "Fold: 25  Epoch: 416  Training loss = 3.8818  Validation loss = 2.4419  \n",
      "\n",
      "Fold: 25  Epoch: 417  Training loss = 3.8816  Validation loss = 2.4417  \n",
      "\n",
      "Fold: 25  Epoch: 418  Training loss = 3.8814  Validation loss = 2.4413  \n",
      "\n",
      "Fold: 25  Epoch: 419  Training loss = 3.8811  Validation loss = 2.4409  \n",
      "\n",
      "Fold: 25  Epoch: 420  Training loss = 3.8809  Validation loss = 2.4405  \n",
      "\n",
      "Fold: 25  Epoch: 421  Training loss = 3.8805  Validation loss = 2.4400  \n",
      "\n",
      "Fold: 25  Epoch: 422  Training loss = 3.8802  Validation loss = 2.4396  \n",
      "\n",
      "Fold: 25  Epoch: 423  Training loss = 3.8800  Validation loss = 2.4392  \n",
      "\n",
      "Fold: 25  Epoch: 424  Training loss = 3.8797  Validation loss = 2.4388  \n",
      "\n",
      "Fold: 25  Epoch: 425  Training loss = 3.8794  Validation loss = 2.4384  \n",
      "\n",
      "Fold: 25  Epoch: 426  Training loss = 3.8790  Validation loss = 2.4378  \n",
      "\n",
      "Fold: 25  Epoch: 427  Training loss = 3.8788  Validation loss = 2.4375  \n",
      "\n",
      "Fold: 25  Epoch: 428  Training loss = 3.8786  Validation loss = 2.4372  \n",
      "\n",
      "Fold: 25  Epoch: 429  Training loss = 3.8784  Validation loss = 2.4370  \n",
      "\n",
      "Fold: 25  Epoch: 430  Training loss = 3.8783  Validation loss = 2.4367  \n",
      "\n",
      "Fold: 25  Epoch: 431  Training loss = 3.8780  Validation loss = 2.4363  \n",
      "\n",
      "Fold: 25  Epoch: 432  Training loss = 3.8778  Validation loss = 2.4360  \n",
      "\n",
      "Fold: 25  Epoch: 433  Training loss = 3.8775  Validation loss = 2.4356  \n",
      "\n",
      "Fold: 25  Epoch: 434  Training loss = 3.8772  Validation loss = 2.4352  \n",
      "\n",
      "Fold: 25  Epoch: 435  Training loss = 3.8770  Validation loss = 2.4349  \n",
      "\n",
      "Fold: 25  Epoch: 436  Training loss = 3.8767  Validation loss = 2.4344  \n",
      "\n",
      "Fold: 25  Epoch: 437  Training loss = 3.8763  Validation loss = 2.4338  \n",
      "\n",
      "Fold: 25  Epoch: 438  Training loss = 3.8761  Validation loss = 2.4334  \n",
      "\n",
      "Fold: 25  Epoch: 439  Training loss = 3.8758  Validation loss = 2.4330  \n",
      "\n",
      "Fold: 25  Epoch: 440  Training loss = 3.8755  Validation loss = 2.4327  \n",
      "\n",
      "Fold: 25  Epoch: 441  Training loss = 3.8753  Validation loss = 2.4324  \n",
      "\n",
      "Fold: 25  Epoch: 442  Training loss = 3.8750  Validation loss = 2.4319  \n",
      "\n",
      "Fold: 25  Epoch: 443  Training loss = 3.8748  Validation loss = 2.4316  \n",
      "\n",
      "Fold: 25  Epoch: 444  Training loss = 3.8746  Validation loss = 2.4313  \n",
      "\n",
      "Fold: 25  Epoch: 445  Training loss = 3.8744  Validation loss = 2.4310  \n",
      "\n",
      "Fold: 25  Epoch: 446  Training loss = 3.8741  Validation loss = 2.4306  \n",
      "\n",
      "Fold: 25  Epoch: 447  Training loss = 3.8738  Validation loss = 2.4301  \n",
      "\n",
      "Fold: 25  Epoch: 448  Training loss = 3.8735  Validation loss = 2.4298  \n",
      "\n",
      "Fold: 25  Epoch: 449  Training loss = 3.8733  Validation loss = 2.4295  \n",
      "\n",
      "Fold: 25  Epoch: 450  Training loss = 3.8730  Validation loss = 2.4290  \n",
      "\n",
      "Fold: 25  Epoch: 451  Training loss = 3.8728  Validation loss = 2.4288  \n",
      "\n",
      "Fold: 25  Epoch: 452  Training loss = 3.8726  Validation loss = 2.4284  \n",
      "\n",
      "Fold: 25  Epoch: 453  Training loss = 3.8723  Validation loss = 2.4281  \n",
      "\n",
      "Fold: 25  Epoch: 454  Training loss = 3.8721  Validation loss = 2.4276  \n",
      "\n",
      "Fold: 25  Epoch: 455  Training loss = 3.8718  Validation loss = 2.4273  \n",
      "\n",
      "Fold: 25  Epoch: 456  Training loss = 3.8716  Validation loss = 2.4269  \n",
      "\n",
      "Fold: 25  Epoch: 457  Training loss = 3.8714  Validation loss = 2.4266  \n",
      "\n",
      "Fold: 25  Epoch: 458  Training loss = 3.8712  Validation loss = 2.4264  \n",
      "\n",
      "Fold: 25  Epoch: 459  Training loss = 3.8710  Validation loss = 2.4261  \n",
      "\n",
      "Fold: 25  Epoch: 460  Training loss = 3.8707  Validation loss = 2.4256  \n",
      "\n",
      "Fold: 25  Epoch: 461  Training loss = 3.8705  Validation loss = 2.4253  \n",
      "\n",
      "Fold: 25  Epoch: 462  Training loss = 3.8703  Validation loss = 2.4251  \n",
      "\n",
      "Fold: 25  Epoch: 463  Training loss = 3.8700  Validation loss = 2.4246  \n",
      "\n",
      "Fold: 25  Epoch: 464  Training loss = 3.8697  Validation loss = 2.4242  \n",
      "\n",
      "Fold: 25  Epoch: 465  Training loss = 3.8695  Validation loss = 2.4238  \n",
      "\n",
      "Fold: 25  Epoch: 466  Training loss = 3.8692  Validation loss = 2.4234  \n",
      "\n",
      "Fold: 25  Epoch: 467  Training loss = 3.8689  Validation loss = 2.4231  \n",
      "\n",
      "Fold: 25  Epoch: 468  Training loss = 3.8687  Validation loss = 2.4228  \n",
      "\n",
      "Fold: 25  Epoch: 469  Training loss = 3.8685  Validation loss = 2.4225  \n",
      "\n",
      "Fold: 25  Epoch: 470  Training loss = 3.8682  Validation loss = 2.4221  \n",
      "\n",
      "Fold: 25  Epoch: 471  Training loss = 3.8680  Validation loss = 2.4218  \n",
      "\n",
      "Fold: 25  Epoch: 472  Training loss = 3.8677  Validation loss = 2.4214  \n",
      "\n",
      "Fold: 25  Epoch: 473  Training loss = 3.8675  Validation loss = 2.4211  \n",
      "\n",
      "Fold: 25  Epoch: 474  Training loss = 3.8673  Validation loss = 2.4207  \n",
      "\n",
      "Fold: 25  Epoch: 475  Training loss = 3.8670  Validation loss = 2.4204  \n",
      "\n",
      "Fold: 25  Epoch: 476  Training loss = 3.8668  Validation loss = 2.4201  \n",
      "\n",
      "Fold: 25  Epoch: 477  Training loss = 3.8666  Validation loss = 2.4198  \n",
      "\n",
      "Fold: 25  Epoch: 478  Training loss = 3.8665  Validation loss = 2.4196  \n",
      "\n",
      "Fold: 25  Epoch: 479  Training loss = 3.8662  Validation loss = 2.4192  \n",
      "\n",
      "Fold: 25  Epoch: 480  Training loss = 3.8659  Validation loss = 2.4188  \n",
      "\n",
      "Fold: 25  Epoch: 481  Training loss = 3.8657  Validation loss = 2.4184  \n",
      "\n",
      "Fold: 25  Epoch: 482  Training loss = 3.8655  Validation loss = 2.4182  \n",
      "\n",
      "Fold: 25  Epoch: 483  Training loss = 3.8653  Validation loss = 2.4179  \n",
      "\n",
      "Fold: 25  Epoch: 484  Training loss = 3.8650  Validation loss = 2.4175  \n",
      "\n",
      "Fold: 25  Epoch: 485  Training loss = 3.8647  Validation loss = 2.4171  \n",
      "\n",
      "Fold: 25  Epoch: 486  Training loss = 3.8646  Validation loss = 2.4168  \n",
      "\n",
      "Fold: 25  Epoch: 487  Training loss = 3.8643  Validation loss = 2.4164  \n",
      "\n",
      "Fold: 25  Epoch: 488  Training loss = 3.8641  Validation loss = 2.4161  \n",
      "\n",
      "Fold: 25  Epoch: 489  Training loss = 3.8638  Validation loss = 2.4156  \n",
      "\n",
      "Fold: 25  Epoch: 490  Training loss = 3.8635  Validation loss = 2.4153  \n",
      "\n",
      "Fold: 25  Epoch: 491  Training loss = 3.8633  Validation loss = 2.4149  \n",
      "\n",
      "Fold: 25  Epoch: 492  Training loss = 3.8631  Validation loss = 2.4147  \n",
      "\n",
      "Fold: 25  Epoch: 493  Training loss = 3.8628  Validation loss = 2.4143  \n",
      "\n",
      "Fold: 25  Epoch: 494  Training loss = 3.8626  Validation loss = 2.4139  \n",
      "\n",
      "Fold: 25  Epoch: 495  Training loss = 3.8624  Validation loss = 2.4136  \n",
      "\n",
      "Fold: 25  Epoch: 496  Training loss = 3.8622  Validation loss = 2.4134  \n",
      "\n",
      "Fold: 25  Epoch: 497  Training loss = 3.8619  Validation loss = 2.4129  \n",
      "\n",
      "Fold: 25  Epoch: 498  Training loss = 3.8618  Validation loss = 2.4127  \n",
      "\n",
      "Fold: 25  Epoch: 499  Training loss = 3.8616  Validation loss = 2.4124  \n",
      "\n",
      "Fold: 25  Epoch: 500  Training loss = 3.8613  Validation loss = 2.4121  \n",
      "\n",
      "Check model:  Fold: 25  Optimal epoch: 500  \n",
      "\n",
      "Fold: 26  Epoch: 1  Training loss = 3.5471  Validation loss = 1.5082  \n",
      "\n",
      "Fold: 26  Epoch: 2  Training loss = 3.5469  Validation loss = 1.5085  \n",
      "\n",
      "Fold: 26  Epoch: 3  Training loss = 3.5468  Validation loss = 1.5087  \n",
      "\n",
      "Fold: 26  Epoch: 4  Training loss = 3.5466  Validation loss = 1.5090  \n",
      "\n",
      "Fold: 26  Epoch: 5  Training loss = 3.5464  Validation loss = 1.5094  \n",
      "\n",
      "Fold: 26  Epoch: 6  Training loss = 3.5462  Validation loss = 1.5099  \n",
      "\n",
      "Fold: 26  Epoch: 7  Training loss = 3.5460  Validation loss = 1.5102  \n",
      "\n",
      "Fold: 26  Epoch: 8  Training loss = 3.5458  Validation loss = 1.5105  \n",
      "\n",
      "Fold: 26  Epoch: 9  Training loss = 3.5456  Validation loss = 1.5108  \n",
      "\n",
      "Fold: 26  Epoch: 10  Training loss = 3.5454  Validation loss = 1.5111  \n",
      "\n",
      "Fold: 26  Epoch: 11  Training loss = 3.5452  Validation loss = 1.5115  \n",
      "\n",
      "Check model:  Fold: 26  Optimal epoch: 1  \n",
      "\n",
      "Fold: 27  Epoch: 1  Training loss = 3.3995  Validation loss = 1.3797  \n",
      "\n",
      "Fold: 27  Epoch: 2  Training loss = 3.3994  Validation loss = 1.3798  \n",
      "\n",
      "Fold: 27  Epoch: 3  Training loss = 3.3992  Validation loss = 1.3799  \n",
      "\n",
      "Fold: 27  Epoch: 4  Training loss = 3.3990  Validation loss = 1.3802  \n",
      "\n",
      "Fold: 27  Epoch: 5  Training loss = 3.3989  Validation loss = 1.3802  \n",
      "\n",
      "Fold: 27  Epoch: 6  Training loss = 3.3987  Validation loss = 1.3804  \n",
      "\n",
      "Fold: 27  Epoch: 7  Training loss = 3.3986  Validation loss = 1.3806  \n",
      "\n",
      "Fold: 27  Epoch: 8  Training loss = 3.3985  Validation loss = 1.3805  \n",
      "\n",
      "Fold: 27  Epoch: 9  Training loss = 3.3984  Validation loss = 1.3806  \n",
      "\n",
      "Fold: 27  Epoch: 10  Training loss = 3.3983  Validation loss = 1.3807  \n",
      "\n",
      "Fold: 27  Epoch: 11  Training loss = 3.3982  Validation loss = 1.3808  \n",
      "\n",
      "Check model:  Fold: 27  Optimal epoch: 1  \n",
      "\n",
      "Fold: 28  Epoch: 1  Training loss = 3.3853  Validation loss = 1.7198  \n",
      "\n",
      "Fold: 28  Epoch: 2  Training loss = 3.3851  Validation loss = 1.7200  \n",
      "\n",
      "Fold: 28  Epoch: 3  Training loss = 3.3850  Validation loss = 1.7201  \n",
      "\n",
      "Fold: 28  Epoch: 4  Training loss = 3.3849  Validation loss = 1.7201  \n",
      "\n",
      "Fold: 28  Epoch: 5  Training loss = 3.3848  Validation loss = 1.7202  \n",
      "\n",
      "Fold: 28  Epoch: 6  Training loss = 3.3847  Validation loss = 1.7203  \n",
      "\n",
      "Fold: 28  Epoch: 7  Training loss = 3.3845  Validation loss = 1.7205  \n",
      "\n",
      "Fold: 28  Epoch: 8  Training loss = 3.3843  Validation loss = 1.7208  \n",
      "\n",
      "Fold: 28  Epoch: 9  Training loss = 3.3842  Validation loss = 1.7210  \n",
      "\n",
      "Fold: 28  Epoch: 10  Training loss = 3.3841  Validation loss = 1.7211  \n",
      "\n",
      "Fold: 28  Epoch: 11  Training loss = 3.3841  Validation loss = 1.7211  \n",
      "\n",
      "Fold: 28  Epoch: 12  Training loss = 3.3839  Validation loss = 1.7212  \n",
      "\n",
      "Check model:  Fold: 28  Optimal epoch: 1  \n",
      "\n",
      "Fold: 29  Epoch: 1  Training loss = 3.3961  Validation loss = 2.0158  \n",
      "\n",
      "Fold: 29  Epoch: 2  Training loss = 3.3960  Validation loss = 2.0159  \n",
      "\n",
      "Fold: 29  Epoch: 3  Training loss = 3.3959  Validation loss = 2.0160  \n",
      "\n",
      "Fold: 29  Epoch: 4  Training loss = 3.3957  Validation loss = 2.0161  \n",
      "\n",
      "Fold: 29  Epoch: 5  Training loss = 3.3957  Validation loss = 2.0161  \n",
      "\n",
      "Fold: 29  Epoch: 6  Training loss = 3.3955  Validation loss = 2.0162  \n",
      "\n",
      "Fold: 29  Epoch: 7  Training loss = 3.3955  Validation loss = 2.0163  \n",
      "\n",
      "Fold: 29  Epoch: 8  Training loss = 3.3954  Validation loss = 2.0164  \n",
      "\n",
      "Fold: 29  Epoch: 9  Training loss = 3.3952  Validation loss = 2.0166  \n",
      "\n",
      "Fold: 29  Epoch: 10  Training loss = 3.3951  Validation loss = 2.0167  \n",
      "\n",
      "Fold: 29  Epoch: 11  Training loss = 3.3950  Validation loss = 2.0167  \n",
      "\n",
      "Fold: 29  Epoch: 12  Training loss = 3.3949  Validation loss = 2.0166  \n",
      "\n",
      "Fold: 29  Epoch: 13  Training loss = 3.3948  Validation loss = 2.0167  \n",
      "\n",
      "Check model:  Fold: 29  Optimal epoch: 1  \n",
      "\n",
      "Fold: 30  Epoch: 1  Training loss = 3.3485  Validation loss = 0.6616  \n",
      "\n",
      "Fold: 30  Epoch: 2  Training loss = 3.3484  Validation loss = 0.6616  \n",
      "\n",
      "Fold: 30  Epoch: 3  Training loss = 3.3483  Validation loss = 0.6615  \n",
      "\n",
      "Fold: 30  Epoch: 4  Training loss = 3.3482  Validation loss = 0.6615  \n",
      "\n",
      "Fold: 30  Epoch: 5  Training loss = 3.3481  Validation loss = 0.6615  \n",
      "\n",
      "Fold: 30  Epoch: 6  Training loss = 3.3480  Validation loss = 0.6615  \n",
      "\n",
      "Fold: 30  Epoch: 7  Training loss = 3.3480  Validation loss = 0.6615  \n",
      "\n",
      "Fold: 30  Epoch: 8  Training loss = 3.3478  Validation loss = 0.6615  \n",
      "\n",
      "Fold: 30  Epoch: 9  Training loss = 3.3478  Validation loss = 0.6614  \n",
      "\n",
      "Fold: 30  Epoch: 10  Training loss = 3.3477  Validation loss = 0.6614  \n",
      "\n",
      "Fold: 30  Epoch: 11  Training loss = 3.3477  Validation loss = 0.6614  \n",
      "\n",
      "Fold: 30  Epoch: 12  Training loss = 3.3475  Validation loss = 0.6614  \n",
      "\n",
      "Fold: 30  Epoch: 13  Training loss = 3.3474  Validation loss = 0.6614  \n",
      "\n",
      "Fold: 30  Epoch: 14  Training loss = 3.3473  Validation loss = 0.6613  \n",
      "\n",
      "Fold: 30  Epoch: 15  Training loss = 3.3472  Validation loss = 0.6613  \n",
      "\n",
      "Fold: 30  Epoch: 16  Training loss = 3.3471  Validation loss = 0.6613  \n",
      "\n",
      "Fold: 30  Epoch: 17  Training loss = 3.3470  Validation loss = 0.6613  \n",
      "\n",
      "Fold: 30  Epoch: 18  Training loss = 3.3470  Validation loss = 0.6613  \n",
      "\n",
      "Fold: 30  Epoch: 19  Training loss = 3.3469  Validation loss = 0.6613  \n",
      "\n",
      "Fold: 30  Epoch: 20  Training loss = 3.3468  Validation loss = 0.6613  \n",
      "\n",
      "Fold: 30  Epoch: 21  Training loss = 3.3467  Validation loss = 0.6612  \n",
      "\n",
      "Fold: 30  Epoch: 22  Training loss = 3.3466  Validation loss = 0.6612  \n",
      "\n",
      "Fold: 30  Epoch: 23  Training loss = 3.3465  Validation loss = 0.6612  \n",
      "\n",
      "Fold: 30  Epoch: 24  Training loss = 3.3464  Validation loss = 0.6612  \n",
      "\n",
      "Fold: 30  Epoch: 25  Training loss = 3.3463  Validation loss = 0.6612  \n",
      "\n",
      "Fold: 30  Epoch: 26  Training loss = 3.3462  Validation loss = 0.6612  \n",
      "\n",
      "Fold: 30  Epoch: 27  Training loss = 3.3461  Validation loss = 0.6611  \n",
      "\n",
      "Fold: 30  Epoch: 28  Training loss = 3.3460  Validation loss = 0.6611  \n",
      "\n",
      "Fold: 30  Epoch: 29  Training loss = 3.3460  Validation loss = 0.6611  \n",
      "\n",
      "Fold: 30  Epoch: 30  Training loss = 3.3459  Validation loss = 0.6611  \n",
      "\n",
      "Fold: 30  Epoch: 31  Training loss = 3.3458  Validation loss = 0.6611  \n",
      "\n",
      "Fold: 30  Epoch: 32  Training loss = 3.3457  Validation loss = 0.6611  \n",
      "\n",
      "Fold: 30  Epoch: 33  Training loss = 3.3456  Validation loss = 0.6611  \n",
      "\n",
      "Fold: 30  Epoch: 34  Training loss = 3.3455  Validation loss = 0.6611  \n",
      "\n",
      "Fold: 30  Epoch: 35  Training loss = 3.3455  Validation loss = 0.6611  \n",
      "\n",
      "Fold: 30  Epoch: 36  Training loss = 3.3454  Validation loss = 0.6611  \n",
      "\n",
      "Fold: 30  Epoch: 37  Training loss = 3.3453  Validation loss = 0.6611  \n",
      "\n",
      "Fold: 30  Epoch: 38  Training loss = 3.3452  Validation loss = 0.6610  \n",
      "\n",
      "Fold: 30  Epoch: 39  Training loss = 3.3451  Validation loss = 0.6610  \n",
      "\n",
      "Fold: 30  Epoch: 40  Training loss = 3.3451  Validation loss = 0.6610  \n",
      "\n",
      "Fold: 30  Epoch: 41  Training loss = 3.3449  Validation loss = 0.6610  \n",
      "\n",
      "Fold: 30  Epoch: 42  Training loss = 3.3449  Validation loss = 0.6610  \n",
      "\n",
      "Fold: 30  Epoch: 43  Training loss = 3.3448  Validation loss = 0.6610  \n",
      "\n",
      "Fold: 30  Epoch: 44  Training loss = 3.3446  Validation loss = 0.6609  \n",
      "\n",
      "Fold: 30  Epoch: 45  Training loss = 3.3445  Validation loss = 0.6609  \n",
      "\n",
      "Fold: 30  Epoch: 46  Training loss = 3.3445  Validation loss = 0.6609  \n",
      "\n",
      "Fold: 30  Epoch: 47  Training loss = 3.3443  Validation loss = 0.6609  \n",
      "\n",
      "Fold: 30  Epoch: 48  Training loss = 3.3442  Validation loss = 0.6609  \n",
      "\n",
      "Fold: 30  Epoch: 49  Training loss = 3.3441  Validation loss = 0.6609  \n",
      "\n",
      "Fold: 30  Epoch: 50  Training loss = 3.3440  Validation loss = 0.6609  \n",
      "\n",
      "Fold: 30  Epoch: 51  Training loss = 3.3440  Validation loss = 0.6608  \n",
      "\n",
      "Fold: 30  Epoch: 52  Training loss = 3.3439  Validation loss = 0.6608  \n",
      "\n",
      "Fold: 30  Epoch: 53  Training loss = 3.3438  Validation loss = 0.6608  \n",
      "\n",
      "Fold: 30  Epoch: 54  Training loss = 3.3437  Validation loss = 0.6608  \n",
      "\n",
      "Fold: 30  Epoch: 55  Training loss = 3.3437  Validation loss = 0.6608  \n",
      "\n",
      "Fold: 30  Epoch: 56  Training loss = 3.3436  Validation loss = 0.6608  \n",
      "\n",
      "Fold: 30  Epoch: 57  Training loss = 3.3435  Validation loss = 0.6608  \n",
      "\n",
      "Fold: 30  Epoch: 58  Training loss = 3.3435  Validation loss = 0.6608  \n",
      "\n",
      "Fold: 30  Epoch: 59  Training loss = 3.3434  Validation loss = 0.6607  \n",
      "\n",
      "Fold: 30  Epoch: 60  Training loss = 3.3433  Validation loss = 0.6607  \n",
      "\n",
      "Fold: 30  Epoch: 61  Training loss = 3.3433  Validation loss = 0.6607  \n",
      "\n",
      "Fold: 30  Epoch: 62  Training loss = 3.3432  Validation loss = 0.6607  \n",
      "\n",
      "Fold: 30  Epoch: 63  Training loss = 3.3431  Validation loss = 0.6607  \n",
      "\n",
      "Fold: 30  Epoch: 64  Training loss = 3.3430  Validation loss = 0.6607  \n",
      "\n",
      "Fold: 30  Epoch: 65  Training loss = 3.3430  Validation loss = 0.6606  \n",
      "\n",
      "Fold: 30  Epoch: 66  Training loss = 3.3429  Validation loss = 0.6606  \n",
      "\n",
      "Fold: 30  Epoch: 67  Training loss = 3.3428  Validation loss = 0.6606  \n",
      "\n",
      "Fold: 30  Epoch: 68  Training loss = 3.3428  Validation loss = 0.6606  \n",
      "\n",
      "Fold: 30  Epoch: 69  Training loss = 3.3427  Validation loss = 0.6606  \n",
      "\n",
      "Fold: 30  Epoch: 70  Training loss = 3.3426  Validation loss = 0.6606  \n",
      "\n",
      "Fold: 30  Epoch: 71  Training loss = 3.3425  Validation loss = 0.6606  \n",
      "\n",
      "Fold: 30  Epoch: 72  Training loss = 3.3425  Validation loss = 0.6606  \n",
      "\n",
      "Fold: 30  Epoch: 73  Training loss = 3.3423  Validation loss = 0.6606  \n",
      "\n",
      "Fold: 30  Epoch: 74  Training loss = 3.3422  Validation loss = 0.6606  \n",
      "\n",
      "Fold: 30  Epoch: 75  Training loss = 3.3421  Validation loss = 0.6606  \n",
      "\n",
      "Fold: 30  Epoch: 76  Training loss = 3.3421  Validation loss = 0.6606  \n",
      "\n",
      "Fold: 30  Epoch: 77  Training loss = 3.3420  Validation loss = 0.6606  \n",
      "\n",
      "Fold: 30  Epoch: 78  Training loss = 3.3419  Validation loss = 0.6606  \n",
      "\n",
      "Fold: 30  Epoch: 79  Training loss = 3.3418  Validation loss = 0.6605  \n",
      "\n",
      "Fold: 30  Epoch: 80  Training loss = 3.3416  Validation loss = 0.6605  \n",
      "\n",
      "Fold: 30  Epoch: 81  Training loss = 3.3415  Validation loss = 0.6605  \n",
      "\n",
      "Fold: 30  Epoch: 82  Training loss = 3.3415  Validation loss = 0.6605  \n",
      "\n",
      "Fold: 30  Epoch: 83  Training loss = 3.3413  Validation loss = 0.6605  \n",
      "\n",
      "Fold: 30  Epoch: 84  Training loss = 3.3413  Validation loss = 0.6605  \n",
      "\n",
      "Fold: 30  Epoch: 85  Training loss = 3.3412  Validation loss = 0.6605  \n",
      "\n",
      "Fold: 30  Epoch: 86  Training loss = 3.3411  Validation loss = 0.6605  \n",
      "\n",
      "Fold: 30  Epoch: 87  Training loss = 3.3410  Validation loss = 0.6604  \n",
      "\n",
      "Fold: 30  Epoch: 88  Training loss = 3.3410  Validation loss = 0.6604  \n",
      "\n",
      "Fold: 30  Epoch: 89  Training loss = 3.3408  Validation loss = 0.6604  \n",
      "\n",
      "Fold: 30  Epoch: 90  Training loss = 3.3407  Validation loss = 0.6604  \n",
      "\n",
      "Fold: 30  Epoch: 91  Training loss = 3.3407  Validation loss = 0.6604  \n",
      "\n",
      "Fold: 30  Epoch: 92  Training loss = 3.3406  Validation loss = 0.6604  \n",
      "\n",
      "Fold: 30  Epoch: 93  Training loss = 3.3406  Validation loss = 0.6604  \n",
      "\n",
      "Fold: 30  Epoch: 94  Training loss = 3.3404  Validation loss = 0.6604  \n",
      "\n",
      "Fold: 30  Epoch: 95  Training loss = 3.3403  Validation loss = 0.6604  \n",
      "\n",
      "Fold: 30  Epoch: 96  Training loss = 3.3403  Validation loss = 0.6604  \n",
      "\n",
      "Fold: 30  Epoch: 97  Training loss = 3.3402  Validation loss = 0.6604  \n",
      "\n",
      "Fold: 30  Epoch: 98  Training loss = 3.3401  Validation loss = 0.6604  \n",
      "\n",
      "Fold: 30  Epoch: 99  Training loss = 3.3400  Validation loss = 0.6604  \n",
      "\n",
      "Fold: 30  Epoch: 100  Training loss = 3.3398  Validation loss = 0.6604  \n",
      "\n",
      "Fold: 30  Epoch: 101  Training loss = 3.3397  Validation loss = 0.6603  \n",
      "\n",
      "Fold: 30  Epoch: 102  Training loss = 3.3396  Validation loss = 0.6603  \n",
      "\n",
      "Fold: 30  Epoch: 103  Training loss = 3.3395  Validation loss = 0.6603  \n",
      "\n",
      "Fold: 30  Epoch: 104  Training loss = 3.3394  Validation loss = 0.6603  \n",
      "\n",
      "Fold: 30  Epoch: 105  Training loss = 3.3394  Validation loss = 0.6603  \n",
      "\n",
      "Fold: 30  Epoch: 106  Training loss = 3.3393  Validation loss = 0.6603  \n",
      "\n",
      "Fold: 30  Epoch: 107  Training loss = 3.3392  Validation loss = 0.6603  \n",
      "\n",
      "Fold: 30  Epoch: 108  Training loss = 3.3391  Validation loss = 0.6603  \n",
      "\n",
      "Fold: 30  Epoch: 109  Training loss = 3.3390  Validation loss = 0.6603  \n",
      "\n",
      "Fold: 30  Epoch: 110  Training loss = 3.3389  Validation loss = 0.6603  \n",
      "\n",
      "Fold: 30  Epoch: 111  Training loss = 3.3389  Validation loss = 0.6603  \n",
      "\n",
      "Fold: 30  Epoch: 112  Training loss = 3.3388  Validation loss = 0.6603  \n",
      "\n",
      "Fold: 30  Epoch: 113  Training loss = 3.3387  Validation loss = 0.6603  \n",
      "\n",
      "Fold: 30  Epoch: 114  Training loss = 3.3386  Validation loss = 0.6603  \n",
      "\n",
      "Fold: 30  Epoch: 115  Training loss = 3.3386  Validation loss = 0.6603  \n",
      "\n",
      "Fold: 30  Epoch: 116  Training loss = 3.3385  Validation loss = 0.6602  \n",
      "\n",
      "Fold: 30  Epoch: 117  Training loss = 3.3384  Validation loss = 0.6602  \n",
      "\n",
      "Fold: 30  Epoch: 118  Training loss = 3.3383  Validation loss = 0.6602  \n",
      "\n",
      "Fold: 30  Epoch: 119  Training loss = 3.3382  Validation loss = 0.6602  \n",
      "\n",
      "Fold: 30  Epoch: 120  Training loss = 3.3381  Validation loss = 0.6602  \n",
      "\n",
      "Fold: 30  Epoch: 121  Training loss = 3.3380  Validation loss = 0.6602  \n",
      "\n",
      "Fold: 30  Epoch: 122  Training loss = 3.3380  Validation loss = 0.6602  \n",
      "\n",
      "Fold: 30  Epoch: 123  Training loss = 3.3379  Validation loss = 0.6602  \n",
      "\n",
      "Fold: 30  Epoch: 124  Training loss = 3.3379  Validation loss = 0.6602  \n",
      "\n",
      "Fold: 30  Epoch: 125  Training loss = 3.3377  Validation loss = 0.6602  \n",
      "\n",
      "Fold: 30  Epoch: 126  Training loss = 3.3376  Validation loss = 0.6602  \n",
      "\n",
      "Fold: 30  Epoch: 127  Training loss = 3.3375  Validation loss = 0.6602  \n",
      "\n",
      "Fold: 30  Epoch: 128  Training loss = 3.3374  Validation loss = 0.6601  \n",
      "\n",
      "Fold: 30  Epoch: 129  Training loss = 3.3373  Validation loss = 0.6601  \n",
      "\n",
      "Fold: 30  Epoch: 130  Training loss = 3.3373  Validation loss = 0.6601  \n",
      "\n",
      "Fold: 30  Epoch: 131  Training loss = 3.3372  Validation loss = 0.6601  \n",
      "\n",
      "Fold: 30  Epoch: 132  Training loss = 3.3371  Validation loss = 0.6601  \n",
      "\n",
      "Fold: 30  Epoch: 133  Training loss = 3.3370  Validation loss = 0.6602  \n",
      "\n",
      "Fold: 30  Epoch: 134  Training loss = 3.3369  Validation loss = 0.6601  \n",
      "\n",
      "Fold: 30  Epoch: 135  Training loss = 3.3368  Validation loss = 0.6601  \n",
      "\n",
      "Fold: 30  Epoch: 136  Training loss = 3.3367  Validation loss = 0.6601  \n",
      "\n",
      "Fold: 30  Epoch: 137  Training loss = 3.3366  Validation loss = 0.6601  \n",
      "\n",
      "Fold: 30  Epoch: 138  Training loss = 3.3365  Validation loss = 0.6601  \n",
      "\n",
      "Fold: 30  Epoch: 139  Training loss = 3.3364  Validation loss = 0.6601  \n",
      "\n",
      "Fold: 30  Epoch: 140  Training loss = 3.3364  Validation loss = 0.6600  \n",
      "\n",
      "Fold: 30  Epoch: 141  Training loss = 3.3363  Validation loss = 0.6600  \n",
      "\n",
      "Fold: 30  Epoch: 142  Training loss = 3.3362  Validation loss = 0.6600  \n",
      "\n",
      "Fold: 30  Epoch: 143  Training loss = 3.3361  Validation loss = 0.6600  \n",
      "\n",
      "Fold: 30  Epoch: 144  Training loss = 3.3360  Validation loss = 0.6600  \n",
      "\n",
      "Fold: 30  Epoch: 145  Training loss = 3.3360  Validation loss = 0.6600  \n",
      "\n",
      "Fold: 30  Epoch: 146  Training loss = 3.3359  Validation loss = 0.6601  \n",
      "\n",
      "Fold: 30  Epoch: 147  Training loss = 3.3358  Validation loss = 0.6601  \n",
      "\n",
      "Fold: 30  Epoch: 148  Training loss = 3.3357  Validation loss = 0.6601  \n",
      "\n",
      "Fold: 30  Epoch: 149  Training loss = 3.3357  Validation loss = 0.6601  \n",
      "\n",
      "Fold: 30  Epoch: 150  Training loss = 3.3356  Validation loss = 0.6600  \n",
      "\n",
      "Fold: 30  Epoch: 151  Training loss = 3.3355  Validation loss = 0.6600  \n",
      "\n",
      "Fold: 30  Epoch: 152  Training loss = 3.3354  Validation loss = 0.6600  \n",
      "\n",
      "Fold: 30  Epoch: 153  Training loss = 3.3353  Validation loss = 0.6600  \n",
      "\n",
      "Fold: 30  Epoch: 154  Training loss = 3.3352  Validation loss = 0.6600  \n",
      "\n",
      "Fold: 30  Epoch: 155  Training loss = 3.3351  Validation loss = 0.6600  \n",
      "\n",
      "Fold: 30  Epoch: 156  Training loss = 3.3350  Validation loss = 0.6600  \n",
      "\n",
      "Fold: 30  Epoch: 157  Training loss = 3.3350  Validation loss = 0.6600  \n",
      "\n",
      "Fold: 30  Epoch: 158  Training loss = 3.3349  Validation loss = 0.6600  \n",
      "\n",
      "Fold: 30  Epoch: 159  Training loss = 3.3348  Validation loss = 0.6600  \n",
      "\n",
      "Fold: 30  Epoch: 160  Training loss = 3.3347  Validation loss = 0.6599  \n",
      "\n",
      "Fold: 30  Epoch: 161  Training loss = 3.3346  Validation loss = 0.6599  \n",
      "\n",
      "Fold: 30  Epoch: 162  Training loss = 3.3345  Validation loss = 0.6599  \n",
      "\n",
      "Fold: 30  Epoch: 163  Training loss = 3.3345  Validation loss = 0.6599  \n",
      "\n",
      "Fold: 30  Epoch: 164  Training loss = 3.3343  Validation loss = 0.6599  \n",
      "\n",
      "Fold: 30  Epoch: 165  Training loss = 3.3343  Validation loss = 0.6599  \n",
      "\n",
      "Fold: 30  Epoch: 166  Training loss = 3.3342  Validation loss = 0.6599  \n",
      "\n",
      "Fold: 30  Epoch: 167  Training loss = 3.3341  Validation loss = 0.6599  \n",
      "\n",
      "Fold: 30  Epoch: 168  Training loss = 3.3340  Validation loss = 0.6599  \n",
      "\n",
      "Fold: 30  Epoch: 169  Training loss = 3.3340  Validation loss = 0.6599  \n",
      "\n",
      "Fold: 30  Epoch: 170  Training loss = 3.3339  Validation loss = 0.6599  \n",
      "\n",
      "Fold: 30  Epoch: 171  Training loss = 3.3337  Validation loss = 0.6599  \n",
      "\n",
      "Fold: 30  Epoch: 172  Training loss = 3.3337  Validation loss = 0.6599  \n",
      "\n",
      "Fold: 30  Epoch: 173  Training loss = 3.3336  Validation loss = 0.6599  \n",
      "\n",
      "Fold: 30  Epoch: 174  Training loss = 3.3335  Validation loss = 0.6599  \n",
      "\n",
      "Fold: 30  Epoch: 175  Training loss = 3.3334  Validation loss = 0.6599  \n",
      "\n",
      "Fold: 30  Epoch: 176  Training loss = 3.3333  Validation loss = 0.6599  \n",
      "\n",
      "Fold: 30  Epoch: 177  Training loss = 3.3332  Validation loss = 0.6599  \n",
      "\n",
      "Fold: 30  Epoch: 178  Training loss = 3.3332  Validation loss = 0.6599  \n",
      "\n",
      "Fold: 30  Epoch: 179  Training loss = 3.3331  Validation loss = 0.6599  \n",
      "\n",
      "Fold: 30  Epoch: 180  Training loss = 3.3330  Validation loss = 0.6599  \n",
      "\n",
      "Fold: 30  Epoch: 181  Training loss = 3.3329  Validation loss = 0.6599  \n",
      "\n",
      "Fold: 30  Epoch: 182  Training loss = 3.3329  Validation loss = 0.6599  \n",
      "\n",
      "Fold: 30  Epoch: 183  Training loss = 3.3328  Validation loss = 0.6599  \n",
      "\n",
      "Fold: 30  Epoch: 184  Training loss = 3.3327  Validation loss = 0.6599  \n",
      "\n",
      "Fold: 30  Epoch: 185  Training loss = 3.3326  Validation loss = 0.6599  \n",
      "\n",
      "Fold: 30  Epoch: 186  Training loss = 3.3324  Validation loss = 0.6599  \n",
      "\n",
      "Fold: 30  Epoch: 187  Training loss = 3.3324  Validation loss = 0.6599  \n",
      "\n",
      "Fold: 30  Epoch: 188  Training loss = 3.3323  Validation loss = 0.6599  \n",
      "\n",
      "Fold: 30  Epoch: 189  Training loss = 3.3322  Validation loss = 0.6599  \n",
      "\n",
      "Fold: 30  Epoch: 190  Training loss = 3.3321  Validation loss = 0.6599  \n",
      "\n",
      "Check model:  Fold: 30  Optimal epoch: 184  \n",
      "\n",
      "Fold: 31  Epoch: 1  Training loss = 2.9520  Validation loss = 1.3420  \n",
      "\n",
      "Fold: 31  Epoch: 2  Training loss = 2.9520  Validation loss = 1.3418  \n",
      "\n",
      "Fold: 31  Epoch: 3  Training loss = 2.9519  Validation loss = 1.3419  \n",
      "\n",
      "Fold: 31  Epoch: 4  Training loss = 2.9519  Validation loss = 1.3420  \n",
      "\n",
      "Fold: 31  Epoch: 5  Training loss = 2.9518  Validation loss = 1.3420  \n",
      "\n",
      "Fold: 31  Epoch: 6  Training loss = 2.9518  Validation loss = 1.3422  \n",
      "\n",
      "Fold: 31  Epoch: 7  Training loss = 2.9517  Validation loss = 1.3423  \n",
      "\n",
      "Fold: 31  Epoch: 8  Training loss = 2.9516  Validation loss = 1.3424  \n",
      "\n",
      "Fold: 31  Epoch: 9  Training loss = 2.9516  Validation loss = 1.3424  \n",
      "\n",
      "Fold: 31  Epoch: 10  Training loss = 2.9516  Validation loss = 1.3423  \n",
      "\n",
      "Fold: 31  Epoch: 11  Training loss = 2.9515  Validation loss = 1.3424  \n",
      "\n",
      "Fold: 31  Epoch: 12  Training loss = 2.9515  Validation loss = 1.3424  \n",
      "\n",
      "Check model:  Fold: 31  Optimal epoch: 2  \n",
      "\n",
      "Fold: 32  Epoch: 1  Training loss = 2.2347  Validation loss = 2.4481  \n",
      "\n",
      "Fold: 32  Epoch: 2  Training loss = 2.2347  Validation loss = 2.4480  \n",
      "\n",
      "Fold: 32  Epoch: 3  Training loss = 2.2346  Validation loss = 2.4479  \n",
      "\n",
      "Fold: 32  Epoch: 4  Training loss = 2.2346  Validation loss = 2.4478  \n",
      "\n",
      "Fold: 32  Epoch: 5  Training loss = 2.2346  Validation loss = 2.4478  \n",
      "\n",
      "Fold: 32  Epoch: 6  Training loss = 2.2345  Validation loss = 2.4477  \n",
      "\n",
      "Fold: 32  Epoch: 7  Training loss = 2.2345  Validation loss = 2.4477  \n",
      "\n",
      "Fold: 32  Epoch: 8  Training loss = 2.2344  Validation loss = 2.4476  \n",
      "\n",
      "Fold: 32  Epoch: 9  Training loss = 2.2344  Validation loss = 2.4476  \n",
      "\n",
      "Fold: 32  Epoch: 10  Training loss = 2.2343  Validation loss = 2.4475  \n",
      "\n",
      "Fold: 32  Epoch: 11  Training loss = 2.2343  Validation loss = 2.4474  \n",
      "\n",
      "Fold: 32  Epoch: 12  Training loss = 2.2342  Validation loss = 2.4472  \n",
      "\n",
      "Fold: 32  Epoch: 13  Training loss = 2.2341  Validation loss = 2.4470  \n",
      "\n",
      "Fold: 32  Epoch: 14  Training loss = 2.2340  Validation loss = 2.4468  \n",
      "\n",
      "Fold: 32  Epoch: 15  Training loss = 2.2340  Validation loss = 2.4467  \n",
      "\n",
      "Fold: 32  Epoch: 16  Training loss = 2.2340  Validation loss = 2.4467  \n",
      "\n",
      "Fold: 32  Epoch: 17  Training loss = 2.2339  Validation loss = 2.4467  \n",
      "\n",
      "Fold: 32  Epoch: 18  Training loss = 2.2339  Validation loss = 2.4468  \n",
      "\n",
      "Fold: 32  Epoch: 19  Training loss = 2.2339  Validation loss = 2.4467  \n",
      "\n",
      "Fold: 32  Epoch: 20  Training loss = 2.2338  Validation loss = 2.4466  \n",
      "\n",
      "Fold: 32  Epoch: 21  Training loss = 2.2337  Validation loss = 2.4464  \n",
      "\n",
      "Fold: 32  Epoch: 22  Training loss = 2.2337  Validation loss = 2.4465  \n",
      "\n",
      "Fold: 32  Epoch: 23  Training loss = 2.2336  Validation loss = 2.4463  \n",
      "\n",
      "Fold: 32  Epoch: 24  Training loss = 2.2336  Validation loss = 2.4462  \n",
      "\n",
      "Fold: 32  Epoch: 25  Training loss = 2.2335  Validation loss = 2.4461  \n",
      "\n",
      "Fold: 32  Epoch: 26  Training loss = 2.2335  Validation loss = 2.4461  \n",
      "\n",
      "Fold: 32  Epoch: 27  Training loss = 2.2334  Validation loss = 2.4460  \n",
      "\n",
      "Fold: 32  Epoch: 28  Training loss = 2.2334  Validation loss = 2.4458  \n",
      "\n",
      "Fold: 32  Epoch: 29  Training loss = 2.2333  Validation loss = 2.4458  \n",
      "\n",
      "Fold: 32  Epoch: 30  Training loss = 2.2333  Validation loss = 2.4458  \n",
      "\n",
      "Fold: 32  Epoch: 31  Training loss = 2.2333  Validation loss = 2.4458  \n",
      "\n",
      "Fold: 32  Epoch: 32  Training loss = 2.2333  Validation loss = 2.4459  \n",
      "\n",
      "Fold: 32  Epoch: 33  Training loss = 2.2332  Validation loss = 2.4458  \n",
      "\n",
      "Fold: 32  Epoch: 34  Training loss = 2.2332  Validation loss = 2.4457  \n",
      "\n",
      "Fold: 32  Epoch: 35  Training loss = 2.2331  Validation loss = 2.4456  \n",
      "\n",
      "Fold: 32  Epoch: 36  Training loss = 2.2331  Validation loss = 2.4455  \n",
      "\n",
      "Fold: 32  Epoch: 37  Training loss = 2.2330  Validation loss = 2.4455  \n",
      "\n",
      "Fold: 32  Epoch: 38  Training loss = 2.2330  Validation loss = 2.4454  \n",
      "\n",
      "Fold: 32  Epoch: 39  Training loss = 2.2329  Validation loss = 2.4453  \n",
      "\n",
      "Fold: 32  Epoch: 40  Training loss = 2.2329  Validation loss = 2.4453  \n",
      "\n",
      "Fold: 32  Epoch: 41  Training loss = 2.2328  Validation loss = 2.4453  \n",
      "\n",
      "Fold: 32  Epoch: 42  Training loss = 2.2328  Validation loss = 2.4452  \n",
      "\n",
      "Fold: 32  Epoch: 43  Training loss = 2.2327  Validation loss = 2.4451  \n",
      "\n",
      "Fold: 32  Epoch: 44  Training loss = 2.2327  Validation loss = 2.4451  \n",
      "\n",
      "Fold: 32  Epoch: 45  Training loss = 2.2326  Validation loss = 2.4450  \n",
      "\n",
      "Fold: 32  Epoch: 46  Training loss = 2.2325  Validation loss = 2.4449  \n",
      "\n",
      "Fold: 32  Epoch: 47  Training loss = 2.2325  Validation loss = 2.4448  \n",
      "\n",
      "Fold: 32  Epoch: 48  Training loss = 2.2324  Validation loss = 2.4447  \n",
      "\n",
      "Fold: 32  Epoch: 49  Training loss = 2.2324  Validation loss = 2.4447  \n",
      "\n",
      "Fold: 32  Epoch: 50  Training loss = 2.2323  Validation loss = 2.4447  \n",
      "\n",
      "Fold: 32  Epoch: 51  Training loss = 2.2323  Validation loss = 2.4447  \n",
      "\n",
      "Fold: 32  Epoch: 52  Training loss = 2.2323  Validation loss = 2.4446  \n",
      "\n",
      "Fold: 32  Epoch: 53  Training loss = 2.2322  Validation loss = 2.4445  \n",
      "\n",
      "Fold: 32  Epoch: 54  Training loss = 2.2321  Validation loss = 2.4444  \n",
      "\n",
      "Fold: 32  Epoch: 55  Training loss = 2.2321  Validation loss = 2.4444  \n",
      "\n",
      "Fold: 32  Epoch: 56  Training loss = 2.2320  Validation loss = 2.4443  \n",
      "\n",
      "Fold: 32  Epoch: 57  Training loss = 2.2320  Validation loss = 2.4442  \n",
      "\n",
      "Fold: 32  Epoch: 58  Training loss = 2.2319  Validation loss = 2.4441  \n",
      "\n",
      "Fold: 32  Epoch: 59  Training loss = 2.2319  Validation loss = 2.4440  \n",
      "\n",
      "Fold: 32  Epoch: 60  Training loss = 2.2318  Validation loss = 2.4440  \n",
      "\n",
      "Fold: 32  Epoch: 61  Training loss = 2.2318  Validation loss = 2.4440  \n",
      "\n",
      "Fold: 32  Epoch: 62  Training loss = 2.2318  Validation loss = 2.4439  \n",
      "\n",
      "Fold: 32  Epoch: 63  Training loss = 2.2317  Validation loss = 2.4438  \n",
      "\n",
      "Fold: 32  Epoch: 64  Training loss = 2.2317  Validation loss = 2.4438  \n",
      "\n",
      "Fold: 32  Epoch: 65  Training loss = 2.2316  Validation loss = 2.4437  \n",
      "\n",
      "Fold: 32  Epoch: 66  Training loss = 2.2316  Validation loss = 2.4436  \n",
      "\n",
      "Fold: 32  Epoch: 67  Training loss = 2.2315  Validation loss = 2.4435  \n",
      "\n",
      "Fold: 32  Epoch: 68  Training loss = 2.2315  Validation loss = 2.4435  \n",
      "\n",
      "Fold: 32  Epoch: 69  Training loss = 2.2314  Validation loss = 2.4435  \n",
      "\n",
      "Fold: 32  Epoch: 70  Training loss = 2.2314  Validation loss = 2.4434  \n",
      "\n",
      "Fold: 32  Epoch: 71  Training loss = 2.2313  Validation loss = 2.4433  \n",
      "\n",
      "Fold: 32  Epoch: 72  Training loss = 2.2313  Validation loss = 2.4433  \n",
      "\n",
      "Fold: 32  Epoch: 73  Training loss = 2.2312  Validation loss = 2.4431  \n",
      "\n",
      "Fold: 32  Epoch: 74  Training loss = 2.2312  Validation loss = 2.4431  \n",
      "\n",
      "Fold: 32  Epoch: 75  Training loss = 2.2312  Validation loss = 2.4431  \n",
      "\n",
      "Fold: 32  Epoch: 76  Training loss = 2.2311  Validation loss = 2.4429  \n",
      "\n",
      "Fold: 32  Epoch: 77  Training loss = 2.2311  Validation loss = 2.4431  \n",
      "\n",
      "Fold: 32  Epoch: 78  Training loss = 2.2310  Validation loss = 2.4430  \n",
      "\n",
      "Fold: 32  Epoch: 79  Training loss = 2.2310  Validation loss = 2.4430  \n",
      "\n",
      "Fold: 32  Epoch: 80  Training loss = 2.2310  Validation loss = 2.4429  \n",
      "\n",
      "Fold: 32  Epoch: 81  Training loss = 2.2309  Validation loss = 2.4428  \n",
      "\n",
      "Fold: 32  Epoch: 82  Training loss = 2.2309  Validation loss = 2.4428  \n",
      "\n",
      "Fold: 32  Epoch: 83  Training loss = 2.2308  Validation loss = 2.4427  \n",
      "\n",
      "Fold: 32  Epoch: 84  Training loss = 2.2308  Validation loss = 2.4426  \n",
      "\n",
      "Fold: 32  Epoch: 85  Training loss = 2.2307  Validation loss = 2.4426  \n",
      "\n",
      "Fold: 32  Epoch: 86  Training loss = 2.2307  Validation loss = 2.4426  \n",
      "\n",
      "Fold: 32  Epoch: 87  Training loss = 2.2306  Validation loss = 2.4426  \n",
      "\n",
      "Fold: 32  Epoch: 88  Training loss = 2.2306  Validation loss = 2.4425  \n",
      "\n",
      "Fold: 32  Epoch: 89  Training loss = 2.2305  Validation loss = 2.4424  \n",
      "\n",
      "Fold: 32  Epoch: 90  Training loss = 2.2305  Validation loss = 2.4424  \n",
      "\n",
      "Fold: 32  Epoch: 91  Training loss = 2.2304  Validation loss = 2.4424  \n",
      "\n",
      "Fold: 32  Epoch: 92  Training loss = 2.2304  Validation loss = 2.4425  \n",
      "\n",
      "Fold: 32  Epoch: 93  Training loss = 2.2304  Validation loss = 2.4424  \n",
      "\n",
      "Fold: 32  Epoch: 94  Training loss = 2.2303  Validation loss = 2.4423  \n",
      "\n",
      "Fold: 32  Epoch: 95  Training loss = 2.2303  Validation loss = 2.4423  \n",
      "\n",
      "Fold: 32  Epoch: 96  Training loss = 2.2302  Validation loss = 2.4422  \n",
      "\n",
      "Fold: 32  Epoch: 97  Training loss = 2.2302  Validation loss = 2.4420  \n",
      "\n",
      "Fold: 32  Epoch: 98  Training loss = 2.2301  Validation loss = 2.4422  \n",
      "\n",
      "Fold: 32  Epoch: 99  Training loss = 2.2301  Validation loss = 2.4421  \n",
      "\n",
      "Fold: 32  Epoch: 100  Training loss = 2.2300  Validation loss = 2.4421  \n",
      "\n",
      "Fold: 32  Epoch: 101  Training loss = 2.2300  Validation loss = 2.4421  \n",
      "\n",
      "Fold: 32  Epoch: 102  Training loss = 2.2299  Validation loss = 2.4421  \n",
      "\n",
      "Fold: 32  Epoch: 103  Training loss = 2.2299  Validation loss = 2.4420  \n",
      "\n",
      "Fold: 32  Epoch: 104  Training loss = 2.2298  Validation loss = 2.4420  \n",
      "\n",
      "Fold: 32  Epoch: 105  Training loss = 2.2298  Validation loss = 2.4420  \n",
      "\n",
      "Fold: 32  Epoch: 106  Training loss = 2.2298  Validation loss = 2.4419  \n",
      "\n",
      "Fold: 32  Epoch: 107  Training loss = 2.2297  Validation loss = 2.4418  \n",
      "\n",
      "Fold: 32  Epoch: 108  Training loss = 2.2297  Validation loss = 2.4418  \n",
      "\n",
      "Fold: 32  Epoch: 109  Training loss = 2.2296  Validation loss = 2.4417  \n",
      "\n",
      "Fold: 32  Epoch: 110  Training loss = 2.2296  Validation loss = 2.4416  \n",
      "\n",
      "Fold: 32  Epoch: 111  Training loss = 2.2295  Validation loss = 2.4415  \n",
      "\n",
      "Fold: 32  Epoch: 112  Training loss = 2.2295  Validation loss = 2.4414  \n",
      "\n",
      "Fold: 32  Epoch: 113  Training loss = 2.2294  Validation loss = 2.4414  \n",
      "\n",
      "Fold: 32  Epoch: 114  Training loss = 2.2294  Validation loss = 2.4414  \n",
      "\n",
      "Fold: 32  Epoch: 115  Training loss = 2.2293  Validation loss = 2.4413  \n",
      "\n",
      "Fold: 32  Epoch: 116  Training loss = 2.2293  Validation loss = 2.4411  \n",
      "\n",
      "Fold: 32  Epoch: 117  Training loss = 2.2292  Validation loss = 2.4410  \n",
      "\n",
      "Fold: 32  Epoch: 118  Training loss = 2.2292  Validation loss = 2.4410  \n",
      "\n",
      "Fold: 32  Epoch: 119  Training loss = 2.2291  Validation loss = 2.4409  \n",
      "\n",
      "Fold: 32  Epoch: 120  Training loss = 2.2291  Validation loss = 2.4410  \n",
      "\n",
      "Fold: 32  Epoch: 121  Training loss = 2.2291  Validation loss = 2.4410  \n",
      "\n",
      "Fold: 32  Epoch: 122  Training loss = 2.2290  Validation loss = 2.4409  \n",
      "\n",
      "Fold: 32  Epoch: 123  Training loss = 2.2289  Validation loss = 2.4408  \n",
      "\n",
      "Fold: 32  Epoch: 124  Training loss = 2.2289  Validation loss = 2.4408  \n",
      "\n",
      "Fold: 32  Epoch: 125  Training loss = 2.2289  Validation loss = 2.4407  \n",
      "\n",
      "Fold: 32  Epoch: 126  Training loss = 2.2288  Validation loss = 2.4407  \n",
      "\n",
      "Fold: 32  Epoch: 127  Training loss = 2.2288  Validation loss = 2.4407  \n",
      "\n",
      "Fold: 32  Epoch: 128  Training loss = 2.2287  Validation loss = 2.4407  \n",
      "\n",
      "Fold: 32  Epoch: 129  Training loss = 2.2287  Validation loss = 2.4405  \n",
      "\n",
      "Fold: 32  Epoch: 130  Training loss = 2.2286  Validation loss = 2.4405  \n",
      "\n",
      "Fold: 32  Epoch: 131  Training loss = 2.2286  Validation loss = 2.4404  \n",
      "\n",
      "Fold: 32  Epoch: 132  Training loss = 2.2285  Validation loss = 2.4404  \n",
      "\n",
      "Fold: 32  Epoch: 133  Training loss = 2.2285  Validation loss = 2.4403  \n",
      "\n",
      "Fold: 32  Epoch: 134  Training loss = 2.2284  Validation loss = 2.4402  \n",
      "\n",
      "Fold: 32  Epoch: 135  Training loss = 2.2283  Validation loss = 2.4400  \n",
      "\n",
      "Fold: 32  Epoch: 136  Training loss = 2.2283  Validation loss = 2.4399  \n",
      "\n",
      "Fold: 32  Epoch: 137  Training loss = 2.2282  Validation loss = 2.4399  \n",
      "\n",
      "Fold: 32  Epoch: 138  Training loss = 2.2282  Validation loss = 2.4399  \n",
      "\n",
      "Fold: 32  Epoch: 139  Training loss = 2.2281  Validation loss = 2.4398  \n",
      "\n",
      "Fold: 32  Epoch: 140  Training loss = 2.2280  Validation loss = 2.4397  \n",
      "\n",
      "Fold: 32  Epoch: 141  Training loss = 2.2280  Validation loss = 2.4398  \n",
      "\n",
      "Fold: 32  Epoch: 142  Training loss = 2.2280  Validation loss = 2.4398  \n",
      "\n",
      "Fold: 32  Epoch: 143  Training loss = 2.2279  Validation loss = 2.4398  \n",
      "\n",
      "Fold: 32  Epoch: 144  Training loss = 2.2279  Validation loss = 2.4397  \n",
      "\n",
      "Fold: 32  Epoch: 145  Training loss = 2.2278  Validation loss = 2.4397  \n",
      "\n",
      "Fold: 32  Epoch: 146  Training loss = 2.2278  Validation loss = 2.4397  \n",
      "\n",
      "Fold: 32  Epoch: 147  Training loss = 2.2278  Validation loss = 2.4396  \n",
      "\n",
      "Fold: 32  Epoch: 148  Training loss = 2.2277  Validation loss = 2.4397  \n",
      "\n",
      "Fold: 32  Epoch: 149  Training loss = 2.2277  Validation loss = 2.4397  \n",
      "\n",
      "Fold: 32  Epoch: 150  Training loss = 2.2276  Validation loss = 2.4397  \n",
      "\n",
      "Fold: 32  Epoch: 151  Training loss = 2.2276  Validation loss = 2.4395  \n",
      "\n",
      "Fold: 32  Epoch: 152  Training loss = 2.2276  Validation loss = 2.4395  \n",
      "\n",
      "Fold: 32  Epoch: 153  Training loss = 2.2275  Validation loss = 2.4396  \n",
      "\n",
      "Fold: 32  Epoch: 154  Training loss = 2.2275  Validation loss = 2.4394  \n",
      "\n",
      "Fold: 32  Epoch: 155  Training loss = 2.2274  Validation loss = 2.4395  \n",
      "\n",
      "Fold: 32  Epoch: 156  Training loss = 2.2274  Validation loss = 2.4394  \n",
      "\n",
      "Fold: 32  Epoch: 157  Training loss = 2.2273  Validation loss = 2.4395  \n",
      "\n",
      "Fold: 32  Epoch: 158  Training loss = 2.2273  Validation loss = 2.4395  \n",
      "\n",
      "Fold: 32  Epoch: 159  Training loss = 2.2273  Validation loss = 2.4395  \n",
      "\n",
      "Fold: 32  Epoch: 160  Training loss = 2.2272  Validation loss = 2.4393  \n",
      "\n",
      "Fold: 32  Epoch: 161  Training loss = 2.2272  Validation loss = 2.4395  \n",
      "\n",
      "Fold: 32  Epoch: 162  Training loss = 2.2271  Validation loss = 2.4393  \n",
      "\n",
      "Fold: 32  Epoch: 163  Training loss = 2.2270  Validation loss = 2.4392  \n",
      "\n",
      "Fold: 32  Epoch: 164  Training loss = 2.2270  Validation loss = 2.4391  \n",
      "\n",
      "Fold: 32  Epoch: 165  Training loss = 2.2269  Validation loss = 2.4390  \n",
      "\n",
      "Fold: 32  Epoch: 166  Training loss = 2.2268  Validation loss = 2.4388  \n",
      "\n",
      "Fold: 32  Epoch: 167  Training loss = 2.2268  Validation loss = 2.4387  \n",
      "\n",
      "Fold: 32  Epoch: 168  Training loss = 2.2267  Validation loss = 2.4388  \n",
      "\n",
      "Fold: 32  Epoch: 169  Training loss = 2.2267  Validation loss = 2.4388  \n",
      "\n",
      "Fold: 32  Epoch: 170  Training loss = 2.2266  Validation loss = 2.4387  \n",
      "\n",
      "Fold: 32  Epoch: 171  Training loss = 2.2266  Validation loss = 2.4388  \n",
      "\n",
      "Fold: 32  Epoch: 172  Training loss = 2.2265  Validation loss = 2.4385  \n",
      "\n",
      "Fold: 32  Epoch: 173  Training loss = 2.2264  Validation loss = 2.4385  \n",
      "\n",
      "Fold: 32  Epoch: 174  Training loss = 2.2264  Validation loss = 2.4384  \n",
      "\n",
      "Fold: 32  Epoch: 175  Training loss = 2.2263  Validation loss = 2.4383  \n",
      "\n",
      "Fold: 32  Epoch: 176  Training loss = 2.2263  Validation loss = 2.4382  \n",
      "\n",
      "Fold: 32  Epoch: 177  Training loss = 2.2262  Validation loss = 2.4381  \n",
      "\n",
      "Fold: 32  Epoch: 178  Training loss = 2.2262  Validation loss = 2.4381  \n",
      "\n",
      "Fold: 32  Epoch: 179  Training loss = 2.2261  Validation loss = 2.4380  \n",
      "\n",
      "Fold: 32  Epoch: 180  Training loss = 2.2261  Validation loss = 2.4379  \n",
      "\n",
      "Fold: 32  Epoch: 181  Training loss = 2.2260  Validation loss = 2.4379  \n",
      "\n",
      "Fold: 32  Epoch: 182  Training loss = 2.2260  Validation loss = 2.4379  \n",
      "\n",
      "Fold: 32  Epoch: 183  Training loss = 2.2260  Validation loss = 2.4379  \n",
      "\n",
      "Fold: 32  Epoch: 184  Training loss = 2.2259  Validation loss = 2.4379  \n",
      "\n",
      "Fold: 32  Epoch: 185  Training loss = 2.2259  Validation loss = 2.4377  \n",
      "\n",
      "Fold: 32  Epoch: 186  Training loss = 2.2258  Validation loss = 2.4377  \n",
      "\n",
      "Fold: 32  Epoch: 187  Training loss = 2.2257  Validation loss = 2.4376  \n",
      "\n",
      "Fold: 32  Epoch: 188  Training loss = 2.2257  Validation loss = 2.4375  \n",
      "\n",
      "Fold: 32  Epoch: 189  Training loss = 2.2256  Validation loss = 2.4375  \n",
      "\n",
      "Fold: 32  Epoch: 190  Training loss = 2.2256  Validation loss = 2.4374  \n",
      "\n",
      "Fold: 32  Epoch: 191  Training loss = 2.2255  Validation loss = 2.4374  \n",
      "\n",
      "Fold: 32  Epoch: 192  Training loss = 2.2255  Validation loss = 2.4372  \n",
      "\n",
      "Fold: 32  Epoch: 193  Training loss = 2.2254  Validation loss = 2.4373  \n",
      "\n",
      "Fold: 32  Epoch: 194  Training loss = 2.2254  Validation loss = 2.4372  \n",
      "\n",
      "Fold: 32  Epoch: 195  Training loss = 2.2253  Validation loss = 2.4371  \n",
      "\n",
      "Fold: 32  Epoch: 196  Training loss = 2.2252  Validation loss = 2.4369  \n",
      "\n",
      "Fold: 32  Epoch: 197  Training loss = 2.2252  Validation loss = 2.4367  \n",
      "\n",
      "Fold: 32  Epoch: 198  Training loss = 2.2251  Validation loss = 2.4365  \n",
      "\n",
      "Fold: 32  Epoch: 199  Training loss = 2.2250  Validation loss = 2.4365  \n",
      "\n",
      "Fold: 32  Epoch: 200  Training loss = 2.2250  Validation loss = 2.4364  \n",
      "\n",
      "Fold: 32  Epoch: 201  Training loss = 2.2249  Validation loss = 2.4363  \n",
      "\n",
      "Fold: 32  Epoch: 202  Training loss = 2.2248  Validation loss = 2.4361  \n",
      "\n",
      "Fold: 32  Epoch: 203  Training loss = 2.2248  Validation loss = 2.4361  \n",
      "\n",
      "Fold: 32  Epoch: 204  Training loss = 2.2248  Validation loss = 2.4360  \n",
      "\n",
      "Fold: 32  Epoch: 205  Training loss = 2.2247  Validation loss = 2.4359  \n",
      "\n",
      "Fold: 32  Epoch: 206  Training loss = 2.2247  Validation loss = 2.4360  \n",
      "\n",
      "Fold: 32  Epoch: 207  Training loss = 2.2246  Validation loss = 2.4358  \n",
      "\n",
      "Fold: 32  Epoch: 208  Training loss = 2.2246  Validation loss = 2.4358  \n",
      "\n",
      "Fold: 32  Epoch: 209  Training loss = 2.2245  Validation loss = 2.4357  \n",
      "\n",
      "Fold: 32  Epoch: 210  Training loss = 2.2244  Validation loss = 2.4356  \n",
      "\n",
      "Fold: 32  Epoch: 211  Training loss = 2.2244  Validation loss = 2.4355  \n",
      "\n",
      "Fold: 32  Epoch: 212  Training loss = 2.2243  Validation loss = 2.4353  \n",
      "\n",
      "Fold: 32  Epoch: 213  Training loss = 2.2242  Validation loss = 2.4353  \n",
      "\n",
      "Fold: 32  Epoch: 214  Training loss = 2.2242  Validation loss = 2.4352  \n",
      "\n",
      "Fold: 32  Epoch: 215  Training loss = 2.2241  Validation loss = 2.4351  \n",
      "\n",
      "Fold: 32  Epoch: 216  Training loss = 2.2241  Validation loss = 2.4350  \n",
      "\n",
      "Fold: 32  Epoch: 217  Training loss = 2.2240  Validation loss = 2.4349  \n",
      "\n",
      "Fold: 32  Epoch: 218  Training loss = 2.2240  Validation loss = 2.4349  \n",
      "\n",
      "Fold: 32  Epoch: 219  Training loss = 2.2240  Validation loss = 2.4349  \n",
      "\n",
      "Fold: 32  Epoch: 220  Training loss = 2.2239  Validation loss = 2.4348  \n",
      "\n",
      "Fold: 32  Epoch: 221  Training loss = 2.2238  Validation loss = 2.4347  \n",
      "\n",
      "Fold: 32  Epoch: 222  Training loss = 2.2238  Validation loss = 2.4347  \n",
      "\n",
      "Fold: 32  Epoch: 223  Training loss = 2.2237  Validation loss = 2.4346  \n",
      "\n",
      "Fold: 32  Epoch: 224  Training loss = 2.2236  Validation loss = 2.4344  \n",
      "\n",
      "Fold: 32  Epoch: 225  Training loss = 2.2236  Validation loss = 2.4344  \n",
      "\n",
      "Fold: 32  Epoch: 226  Training loss = 2.2235  Validation loss = 2.4344  \n",
      "\n",
      "Fold: 32  Epoch: 227  Training loss = 2.2235  Validation loss = 2.4344  \n",
      "\n",
      "Fold: 32  Epoch: 228  Training loss = 2.2234  Validation loss = 2.4341  \n",
      "\n",
      "Fold: 32  Epoch: 229  Training loss = 2.2233  Validation loss = 2.4340  \n",
      "\n",
      "Fold: 32  Epoch: 230  Training loss = 2.2233  Validation loss = 2.4339  \n",
      "\n",
      "Fold: 32  Epoch: 231  Training loss = 2.2233  Validation loss = 2.4339  \n",
      "\n",
      "Fold: 32  Epoch: 232  Training loss = 2.2232  Validation loss = 2.4339  \n",
      "\n",
      "Fold: 32  Epoch: 233  Training loss = 2.2232  Validation loss = 2.4338  \n",
      "\n",
      "Fold: 32  Epoch: 234  Training loss = 2.2231  Validation loss = 2.4337  \n",
      "\n",
      "Fold: 32  Epoch: 235  Training loss = 2.2231  Validation loss = 2.4338  \n",
      "\n",
      "Fold: 32  Epoch: 236  Training loss = 2.2230  Validation loss = 2.4334  \n",
      "\n",
      "Fold: 32  Epoch: 237  Training loss = 2.2230  Validation loss = 2.4334  \n",
      "\n",
      "Fold: 32  Epoch: 238  Training loss = 2.2229  Validation loss = 2.4333  \n",
      "\n",
      "Fold: 32  Epoch: 239  Training loss = 2.2229  Validation loss = 2.4333  \n",
      "\n",
      "Fold: 32  Epoch: 240  Training loss = 2.2228  Validation loss = 2.4333  \n",
      "\n",
      "Fold: 32  Epoch: 241  Training loss = 2.2228  Validation loss = 2.4334  \n",
      "\n",
      "Fold: 32  Epoch: 242  Training loss = 2.2228  Validation loss = 2.4334  \n",
      "\n",
      "Fold: 32  Epoch: 243  Training loss = 2.2227  Validation loss = 2.4334  \n",
      "\n",
      "Fold: 32  Epoch: 244  Training loss = 2.2226  Validation loss = 2.4333  \n",
      "\n",
      "Fold: 32  Epoch: 245  Training loss = 2.2226  Validation loss = 2.4332  \n",
      "\n",
      "Fold: 32  Epoch: 246  Training loss = 2.2225  Validation loss = 2.4330  \n",
      "\n",
      "Fold: 32  Epoch: 247  Training loss = 2.2223  Validation loss = 2.4328  \n",
      "\n",
      "Fold: 32  Epoch: 248  Training loss = 2.2223  Validation loss = 2.4327  \n",
      "\n",
      "Fold: 32  Epoch: 249  Training loss = 2.2222  Validation loss = 2.4325  \n",
      "\n",
      "Fold: 32  Epoch: 250  Training loss = 2.2221  Validation loss = 2.4325  \n",
      "\n",
      "Fold: 32  Epoch: 251  Training loss = 2.2221  Validation loss = 2.4325  \n",
      "\n",
      "Fold: 32  Epoch: 252  Training loss = 2.2221  Validation loss = 2.4325  \n",
      "\n",
      "Fold: 32  Epoch: 253  Training loss = 2.2220  Validation loss = 2.4325  \n",
      "\n",
      "Fold: 32  Epoch: 254  Training loss = 2.2220  Validation loss = 2.4325  \n",
      "\n",
      "Fold: 32  Epoch: 255  Training loss = 2.2219  Validation loss = 2.4324  \n",
      "\n",
      "Fold: 32  Epoch: 256  Training loss = 2.2219  Validation loss = 2.4323  \n",
      "\n",
      "Fold: 32  Epoch: 257  Training loss = 2.2218  Validation loss = 2.4322  \n",
      "\n",
      "Fold: 32  Epoch: 258  Training loss = 2.2217  Validation loss = 2.4320  \n",
      "\n",
      "Fold: 32  Epoch: 259  Training loss = 2.2217  Validation loss = 2.4319  \n",
      "\n",
      "Fold: 32  Epoch: 260  Training loss = 2.2216  Validation loss = 2.4318  \n",
      "\n",
      "Fold: 32  Epoch: 261  Training loss = 2.2215  Validation loss = 2.4317  \n",
      "\n",
      "Fold: 32  Epoch: 262  Training loss = 2.2215  Validation loss = 2.4316  \n",
      "\n",
      "Fold: 32  Epoch: 263  Training loss = 2.2214  Validation loss = 2.4314  \n",
      "\n",
      "Fold: 32  Epoch: 264  Training loss = 2.2214  Validation loss = 2.4314  \n",
      "\n",
      "Fold: 32  Epoch: 265  Training loss = 2.2213  Validation loss = 2.4313  \n",
      "\n",
      "Fold: 32  Epoch: 266  Training loss = 2.2212  Validation loss = 2.4311  \n",
      "\n",
      "Fold: 32  Epoch: 267  Training loss = 2.2211  Validation loss = 2.4309  \n",
      "\n",
      "Fold: 32  Epoch: 268  Training loss = 2.2210  Validation loss = 2.4308  \n",
      "\n",
      "Fold: 32  Epoch: 269  Training loss = 2.2210  Validation loss = 2.4307  \n",
      "\n",
      "Fold: 32  Epoch: 270  Training loss = 2.2209  Validation loss = 2.4308  \n",
      "\n",
      "Fold: 32  Epoch: 271  Training loss = 2.2209  Validation loss = 2.4308  \n",
      "\n",
      "Fold: 32  Epoch: 272  Training loss = 2.2209  Validation loss = 2.4309  \n",
      "\n",
      "Fold: 32  Epoch: 273  Training loss = 2.2209  Validation loss = 2.4308  \n",
      "\n",
      "Fold: 32  Epoch: 274  Training loss = 2.2208  Validation loss = 2.4306  \n",
      "\n",
      "Fold: 32  Epoch: 275  Training loss = 2.2207  Validation loss = 2.4304  \n",
      "\n",
      "Fold: 32  Epoch: 276  Training loss = 2.2206  Validation loss = 2.4302  \n",
      "\n",
      "Fold: 32  Epoch: 277  Training loss = 2.2206  Validation loss = 2.4301  \n",
      "\n",
      "Fold: 32  Epoch: 278  Training loss = 2.2205  Validation loss = 2.4300  \n",
      "\n",
      "Fold: 32  Epoch: 279  Training loss = 2.2204  Validation loss = 2.4299  \n",
      "\n",
      "Fold: 32  Epoch: 280  Training loss = 2.2204  Validation loss = 2.4298  \n",
      "\n",
      "Fold: 32  Epoch: 281  Training loss = 2.2204  Validation loss = 2.4298  \n",
      "\n",
      "Fold: 32  Epoch: 282  Training loss = 2.2203  Validation loss = 2.4298  \n",
      "\n",
      "Fold: 32  Epoch: 283  Training loss = 2.2202  Validation loss = 2.4298  \n",
      "\n",
      "Fold: 32  Epoch: 284  Training loss = 2.2202  Validation loss = 2.4298  \n",
      "\n",
      "Fold: 32  Epoch: 285  Training loss = 2.2202  Validation loss = 2.4299  \n",
      "\n",
      "Fold: 32  Epoch: 286  Training loss = 2.2201  Validation loss = 2.4298  \n",
      "\n",
      "Fold: 32  Epoch: 287  Training loss = 2.2201  Validation loss = 2.4299  \n",
      "\n",
      "Fold: 32  Epoch: 288  Training loss = 2.2200  Validation loss = 2.4299  \n",
      "\n",
      "Fold: 32  Epoch: 289  Training loss = 2.2200  Validation loss = 2.4298  \n",
      "\n",
      "Fold: 32  Epoch: 290  Training loss = 2.2199  Validation loss = 2.4297  \n",
      "\n",
      "Fold: 32  Epoch: 291  Training loss = 2.2199  Validation loss = 2.4297  \n",
      "\n",
      "Fold: 32  Epoch: 292  Training loss = 2.2198  Validation loss = 2.4296  \n",
      "\n",
      "Fold: 32  Epoch: 293  Training loss = 2.2198  Validation loss = 2.4296  \n",
      "\n",
      "Fold: 32  Epoch: 294  Training loss = 2.2197  Validation loss = 2.4296  \n",
      "\n",
      "Fold: 32  Epoch: 295  Training loss = 2.2197  Validation loss = 2.4296  \n",
      "\n",
      "Fold: 32  Epoch: 296  Training loss = 2.2196  Validation loss = 2.4295  \n",
      "\n",
      "Fold: 32  Epoch: 297  Training loss = 2.2195  Validation loss = 2.4293  \n",
      "\n",
      "Fold: 32  Epoch: 298  Training loss = 2.2195  Validation loss = 2.4294  \n",
      "\n",
      "Fold: 32  Epoch: 299  Training loss = 2.2195  Validation loss = 2.4294  \n",
      "\n",
      "Fold: 32  Epoch: 300  Training loss = 2.2194  Validation loss = 2.4293  \n",
      "\n",
      "Fold: 32  Epoch: 301  Training loss = 2.2194  Validation loss = 2.4293  \n",
      "\n",
      "Fold: 32  Epoch: 302  Training loss = 2.2193  Validation loss = 2.4291  \n",
      "\n",
      "Fold: 32  Epoch: 303  Training loss = 2.2192  Validation loss = 2.4290  \n",
      "\n",
      "Fold: 32  Epoch: 304  Training loss = 2.2192  Validation loss = 2.4289  \n",
      "\n",
      "Fold: 32  Epoch: 305  Training loss = 2.2191  Validation loss = 2.4286  \n",
      "\n",
      "Fold: 32  Epoch: 306  Training loss = 2.2190  Validation loss = 2.4286  \n",
      "\n",
      "Fold: 32  Epoch: 307  Training loss = 2.2190  Validation loss = 2.4286  \n",
      "\n",
      "Fold: 32  Epoch: 308  Training loss = 2.2189  Validation loss = 2.4285  \n",
      "\n",
      "Fold: 32  Epoch: 309  Training loss = 2.2189  Validation loss = 2.4286  \n",
      "\n",
      "Fold: 32  Epoch: 310  Training loss = 2.2188  Validation loss = 2.4285  \n",
      "\n",
      "Fold: 32  Epoch: 311  Training loss = 2.2188  Validation loss = 2.4285  \n",
      "\n",
      "Fold: 32  Epoch: 312  Training loss = 2.2187  Validation loss = 2.4284  \n",
      "\n",
      "Fold: 32  Epoch: 313  Training loss = 2.2186  Validation loss = 2.4284  \n",
      "\n",
      "Fold: 32  Epoch: 314  Training loss = 2.2186  Validation loss = 2.4284  \n",
      "\n",
      "Fold: 32  Epoch: 315  Training loss = 2.2185  Validation loss = 2.4282  \n",
      "\n",
      "Fold: 32  Epoch: 316  Training loss = 2.2184  Validation loss = 2.4282  \n",
      "\n",
      "Fold: 32  Epoch: 317  Training loss = 2.2183  Validation loss = 2.4280  \n",
      "\n",
      "Fold: 32  Epoch: 318  Training loss = 2.2183  Validation loss = 2.4280  \n",
      "\n",
      "Fold: 32  Epoch: 319  Training loss = 2.2182  Validation loss = 2.4277  \n",
      "\n",
      "Fold: 32  Epoch: 320  Training loss = 2.2181  Validation loss = 2.4276  \n",
      "\n",
      "Fold: 32  Epoch: 321  Training loss = 2.2181  Validation loss = 2.4276  \n",
      "\n",
      "Fold: 32  Epoch: 322  Training loss = 2.2180  Validation loss = 2.4275  \n",
      "\n",
      "Fold: 32  Epoch: 323  Training loss = 2.2179  Validation loss = 2.4274  \n",
      "\n",
      "Fold: 32  Epoch: 324  Training loss = 2.2178  Validation loss = 2.4274  \n",
      "\n",
      "Fold: 32  Epoch: 325  Training loss = 2.2178  Validation loss = 2.4274  \n",
      "\n",
      "Fold: 32  Epoch: 326  Training loss = 2.2177  Validation loss = 2.4272  \n",
      "\n",
      "Fold: 32  Epoch: 327  Training loss = 2.2176  Validation loss = 2.4272  \n",
      "\n",
      "Fold: 32  Epoch: 328  Training loss = 2.2176  Validation loss = 2.4271  \n",
      "\n",
      "Fold: 32  Epoch: 329  Training loss = 2.2175  Validation loss = 2.4271  \n",
      "\n",
      "Fold: 32  Epoch: 330  Training loss = 2.2174  Validation loss = 2.4270  \n",
      "\n",
      "Fold: 32  Epoch: 331  Training loss = 2.2174  Validation loss = 2.4270  \n",
      "\n",
      "Fold: 32  Epoch: 332  Training loss = 2.2173  Validation loss = 2.4269  \n",
      "\n",
      "Fold: 32  Epoch: 333  Training loss = 2.2173  Validation loss = 2.4270  \n",
      "\n",
      "Fold: 32  Epoch: 334  Training loss = 2.2172  Validation loss = 2.4267  \n",
      "\n",
      "Fold: 32  Epoch: 335  Training loss = 2.2171  Validation loss = 2.4265  \n",
      "\n",
      "Fold: 32  Epoch: 336  Training loss = 2.2171  Validation loss = 2.4265  \n",
      "\n",
      "Fold: 32  Epoch: 337  Training loss = 2.2170  Validation loss = 2.4262  \n",
      "\n",
      "Fold: 32  Epoch: 338  Training loss = 2.2170  Validation loss = 2.4264  \n",
      "\n",
      "Fold: 32  Epoch: 339  Training loss = 2.2169  Validation loss = 2.4263  \n",
      "\n",
      "Fold: 32  Epoch: 340  Training loss = 2.2169  Validation loss = 2.4262  \n",
      "\n",
      "Fold: 32  Epoch: 341  Training loss = 2.2169  Validation loss = 2.4263  \n",
      "\n",
      "Fold: 32  Epoch: 342  Training loss = 2.2168  Validation loss = 2.4262  \n",
      "\n",
      "Fold: 32  Epoch: 343  Training loss = 2.2168  Validation loss = 2.4263  \n",
      "\n",
      "Fold: 32  Epoch: 344  Training loss = 2.2167  Validation loss = 2.4261  \n",
      "\n",
      "Fold: 32  Epoch: 345  Training loss = 2.2167  Validation loss = 2.4262  \n",
      "\n",
      "Fold: 32  Epoch: 346  Training loss = 2.2166  Validation loss = 2.4260  \n",
      "\n",
      "Fold: 32  Epoch: 347  Training loss = 2.2165  Validation loss = 2.4260  \n",
      "\n",
      "Fold: 32  Epoch: 348  Training loss = 2.2165  Validation loss = 2.4259  \n",
      "\n",
      "Fold: 32  Epoch: 349  Training loss = 2.2164  Validation loss = 2.4260  \n",
      "\n",
      "Fold: 32  Epoch: 350  Training loss = 2.2164  Validation loss = 2.4259  \n",
      "\n",
      "Fold: 32  Epoch: 351  Training loss = 2.2163  Validation loss = 2.4260  \n",
      "\n",
      "Fold: 32  Epoch: 352  Training loss = 2.2162  Validation loss = 2.4258  \n",
      "\n",
      "Fold: 32  Epoch: 353  Training loss = 2.2162  Validation loss = 2.4259  \n",
      "\n",
      "Fold: 32  Epoch: 354  Training loss = 2.2161  Validation loss = 2.4258  \n",
      "\n",
      "Fold: 32  Epoch: 355  Training loss = 2.2161  Validation loss = 2.4257  \n",
      "\n",
      "Fold: 32  Epoch: 356  Training loss = 2.2160  Validation loss = 2.4256  \n",
      "\n",
      "Fold: 32  Epoch: 357  Training loss = 2.2159  Validation loss = 2.4255  \n",
      "\n",
      "Fold: 32  Epoch: 358  Training loss = 2.2159  Validation loss = 2.4256  \n",
      "\n",
      "Fold: 32  Epoch: 359  Training loss = 2.2158  Validation loss = 2.4255  \n",
      "\n",
      "Fold: 32  Epoch: 360  Training loss = 2.2157  Validation loss = 2.4252  \n",
      "\n",
      "Fold: 32  Epoch: 361  Training loss = 2.2156  Validation loss = 2.4250  \n",
      "\n",
      "Fold: 32  Epoch: 362  Training loss = 2.2155  Validation loss = 2.4250  \n",
      "\n",
      "Fold: 32  Epoch: 363  Training loss = 2.2155  Validation loss = 2.4249  \n",
      "\n",
      "Fold: 32  Epoch: 364  Training loss = 2.2154  Validation loss = 2.4248  \n",
      "\n",
      "Fold: 32  Epoch: 365  Training loss = 2.2153  Validation loss = 2.4245  \n",
      "\n",
      "Fold: 32  Epoch: 366  Training loss = 2.2153  Validation loss = 2.4246  \n",
      "\n",
      "Fold: 32  Epoch: 367  Training loss = 2.2152  Validation loss = 2.4244  \n",
      "\n",
      "Fold: 32  Epoch: 368  Training loss = 2.2151  Validation loss = 2.4242  \n",
      "\n",
      "Fold: 32  Epoch: 369  Training loss = 2.2150  Validation loss = 2.4240  \n",
      "\n",
      "Fold: 32  Epoch: 370  Training loss = 2.2149  Validation loss = 2.4238  \n",
      "\n",
      "Fold: 32  Epoch: 371  Training loss = 2.2149  Validation loss = 2.4238  \n",
      "\n",
      "Fold: 32  Epoch: 372  Training loss = 2.2149  Validation loss = 2.4239  \n",
      "\n",
      "Fold: 32  Epoch: 373  Training loss = 2.2149  Validation loss = 2.4239  \n",
      "\n",
      "Fold: 32  Epoch: 374  Training loss = 2.2148  Validation loss = 2.4237  \n",
      "\n",
      "Fold: 32  Epoch: 375  Training loss = 2.2147  Validation loss = 2.4237  \n",
      "\n",
      "Fold: 32  Epoch: 376  Training loss = 2.2147  Validation loss = 2.4238  \n",
      "\n",
      "Fold: 32  Epoch: 377  Training loss = 2.2147  Validation loss = 2.4238  \n",
      "\n",
      "Fold: 32  Epoch: 378  Training loss = 2.2146  Validation loss = 2.4239  \n",
      "\n",
      "Fold: 32  Epoch: 379  Training loss = 2.2146  Validation loss = 2.4238  \n",
      "\n",
      "Fold: 32  Epoch: 380  Training loss = 2.2145  Validation loss = 2.4235  \n",
      "\n",
      "Fold: 32  Epoch: 381  Training loss = 2.2144  Validation loss = 2.4234  \n",
      "\n",
      "Fold: 32  Epoch: 382  Training loss = 2.2143  Validation loss = 2.4232  \n",
      "\n",
      "Fold: 32  Epoch: 383  Training loss = 2.2143  Validation loss = 2.4234  \n",
      "\n",
      "Fold: 32  Epoch: 384  Training loss = 2.2142  Validation loss = 2.4232  \n",
      "\n",
      "Fold: 32  Epoch: 385  Training loss = 2.2141  Validation loss = 2.4230  \n",
      "\n",
      "Fold: 32  Epoch: 386  Training loss = 2.2141  Validation loss = 2.4230  \n",
      "\n",
      "Fold: 32  Epoch: 387  Training loss = 2.2140  Validation loss = 2.4228  \n",
      "\n",
      "Fold: 32  Epoch: 388  Training loss = 2.2139  Validation loss = 2.4226  \n",
      "\n",
      "Fold: 32  Epoch: 389  Training loss = 2.2139  Validation loss = 2.4227  \n",
      "\n",
      "Fold: 32  Epoch: 390  Training loss = 2.2138  Validation loss = 2.4226  \n",
      "\n",
      "Fold: 32  Epoch: 391  Training loss = 2.2137  Validation loss = 2.4223  \n",
      "\n",
      "Fold: 32  Epoch: 392  Training loss = 2.2137  Validation loss = 2.4224  \n",
      "\n",
      "Fold: 32  Epoch: 393  Training loss = 2.2137  Validation loss = 2.4223  \n",
      "\n",
      "Fold: 32  Epoch: 394  Training loss = 2.2137  Validation loss = 2.4222  \n",
      "\n",
      "Fold: 32  Epoch: 395  Training loss = 2.2135  Validation loss = 2.4219  \n",
      "\n",
      "Fold: 32  Epoch: 396  Training loss = 2.2135  Validation loss = 2.4218  \n",
      "\n",
      "Fold: 32  Epoch: 397  Training loss = 2.2134  Validation loss = 2.4219  \n",
      "\n",
      "Fold: 32  Epoch: 398  Training loss = 2.2134  Validation loss = 2.4218  \n",
      "\n",
      "Fold: 32  Epoch: 399  Training loss = 2.2133  Validation loss = 2.4218  \n",
      "\n",
      "Fold: 32  Epoch: 400  Training loss = 2.2133  Validation loss = 2.4218  \n",
      "\n",
      "Fold: 32  Epoch: 401  Training loss = 2.2132  Validation loss = 2.4216  \n",
      "\n",
      "Fold: 32  Epoch: 402  Training loss = 2.2132  Validation loss = 2.4215  \n",
      "\n",
      "Fold: 32  Epoch: 403  Training loss = 2.2131  Validation loss = 2.4215  \n",
      "\n",
      "Fold: 32  Epoch: 404  Training loss = 2.2131  Validation loss = 2.4215  \n",
      "\n",
      "Fold: 32  Epoch: 405  Training loss = 2.2130  Validation loss = 2.4214  \n",
      "\n",
      "Fold: 32  Epoch: 406  Training loss = 2.2129  Validation loss = 2.4212  \n",
      "\n",
      "Fold: 32  Epoch: 407  Training loss = 2.2129  Validation loss = 2.4211  \n",
      "\n",
      "Fold: 32  Epoch: 408  Training loss = 2.2128  Validation loss = 2.4210  \n",
      "\n",
      "Fold: 32  Epoch: 409  Training loss = 2.2127  Validation loss = 2.4207  \n",
      "\n",
      "Fold: 32  Epoch: 410  Training loss = 2.2127  Validation loss = 2.4206  \n",
      "\n",
      "Fold: 32  Epoch: 411  Training loss = 2.2126  Validation loss = 2.4204  \n",
      "\n",
      "Fold: 32  Epoch: 412  Training loss = 2.2125  Validation loss = 2.4203  \n",
      "\n",
      "Fold: 32  Epoch: 413  Training loss = 2.2125  Validation loss = 2.4202  \n",
      "\n",
      "Fold: 32  Epoch: 414  Training loss = 2.2124  Validation loss = 2.4199  \n",
      "\n",
      "Fold: 32  Epoch: 415  Training loss = 2.2123  Validation loss = 2.4198  \n",
      "\n",
      "Fold: 32  Epoch: 416  Training loss = 2.2123  Validation loss = 2.4197  \n",
      "\n",
      "Fold: 32  Epoch: 417  Training loss = 2.2122  Validation loss = 2.4197  \n",
      "\n",
      "Fold: 32  Epoch: 418  Training loss = 2.2122  Validation loss = 2.4198  \n",
      "\n",
      "Fold: 32  Epoch: 419  Training loss = 2.2122  Validation loss = 2.4199  \n",
      "\n",
      "Fold: 32  Epoch: 420  Training loss = 2.2121  Validation loss = 2.4198  \n",
      "\n",
      "Fold: 32  Epoch: 421  Training loss = 2.2121  Validation loss = 2.4196  \n",
      "\n",
      "Fold: 32  Epoch: 422  Training loss = 2.2120  Validation loss = 2.4195  \n",
      "\n",
      "Fold: 32  Epoch: 423  Training loss = 2.2120  Validation loss = 2.4193  \n",
      "\n",
      "Fold: 32  Epoch: 424  Training loss = 2.2119  Validation loss = 2.4191  \n",
      "\n",
      "Fold: 32  Epoch: 425  Training loss = 2.2119  Validation loss = 2.4192  \n",
      "\n",
      "Fold: 32  Epoch: 426  Training loss = 2.2118  Validation loss = 2.4190  \n",
      "\n",
      "Fold: 32  Epoch: 427  Training loss = 2.2118  Validation loss = 2.4190  \n",
      "\n",
      "Fold: 32  Epoch: 428  Training loss = 2.2117  Validation loss = 2.4190  \n",
      "\n",
      "Fold: 32  Epoch: 429  Training loss = 2.2117  Validation loss = 2.4188  \n",
      "\n",
      "Fold: 32  Epoch: 430  Training loss = 2.2117  Validation loss = 2.4187  \n",
      "\n",
      "Fold: 32  Epoch: 431  Training loss = 2.2116  Validation loss = 2.4187  \n",
      "\n",
      "Fold: 32  Epoch: 432  Training loss = 2.2116  Validation loss = 2.4187  \n",
      "\n",
      "Fold: 32  Epoch: 433  Training loss = 2.2115  Validation loss = 2.4187  \n",
      "\n",
      "Fold: 32  Epoch: 434  Training loss = 2.2115  Validation loss = 2.4187  \n",
      "\n",
      "Fold: 32  Epoch: 435  Training loss = 2.2115  Validation loss = 2.4187  \n",
      "\n",
      "Fold: 32  Epoch: 436  Training loss = 2.2115  Validation loss = 2.4188  \n",
      "\n",
      "Fold: 32  Epoch: 437  Training loss = 2.2115  Validation loss = 2.4190  \n",
      "\n",
      "Check model:  Fold: 32  Optimal epoch: 435  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 2. Train model\n",
    "# ==================================\n",
    "sess = tf.InteractiveSession()  # Launch Graph\n",
    "sess.run(tf.global_variables_initializer())  # Initialise all variables\n",
    "\n",
    "print(\"Start training\", \n",
    "      \"\\nHyperparameters:\",\n",
    "      \"\\nDimension of recurrent unit =\", n_hidden,\n",
    "      \"\\nLearning rate =\", learning_rate,\n",
    "      \"\\nEpochs =\", epochs,\n",
    "      \"\\nBatch size =\", batch_size,\n",
    "      \"\\nEarly stopping epochs =\", early_stop_iters,\n",
    "      \"\\nLearning rate =\", learning_rate)\n",
    "\n",
    "total_batch = int(window_length / batch_size)\n",
    "validation_fold_error = [] # store validation error of each fold\n",
    "optimal_epochs = []\n",
    "\n",
    "# loop through folds\n",
    "for fold in range(1, len(valIndex)):\n",
    "    validx = train_features[valIndex[fold-1]:valIndex[fold]]\n",
    "    validy = train_target[valIndex[fold-1]:valIndex[fold]]\n",
    "    trainx = train_features[(fold-1)*4:valIndex[(fold-1)]]\n",
    "    trainy = train_target[(fold-1)*4:valIndex[(fold-1)]]\n",
    "\n",
    "    loss_list = [] # store validation loss after each epoch for early stopping\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i in range(total_batch):\n",
    "            # Backprop\n",
    "            batch_xs, batch_ys = next_batch(num=batch_size, data=trainx, labels=trainy)\n",
    "            optimizer.run(feed_dict={x:batch_xs, y:batch_ys, lr:learning_rate})\n",
    "\n",
    "        # Loss\n",
    "        loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "        loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "        loss_list.append(loss_valid)\n",
    "\n",
    "        print(\"Fold: {0:d}\".format(fold),\n",
    "              \" Epoch: {0:d}\".format(epoch+1),\n",
    "              \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "              \" Validation loss = {0:.4f}\".format(np.sqrt(loss_valid)),\n",
    "              \" \\n\")\n",
    "\n",
    "        if all(j <= loss_valid for j in loss_list[-early_stop_iters:]) and len(loss_list)>early_stop_iters:\n",
    "            break\n",
    "    \n",
    "    # Load model with lowest validation error for each fold\n",
    "    epoch_hat = np.argmin(loss_list) + 1\n",
    "    optimal_epochs.append(epoch_hat) # store optimal number of epochs for each fold\n",
    "    \n",
    "    # RMSE\n",
    "    loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "    loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "    validation_fold_error.append(np.sqrt(loss_valid))\n",
    "    \n",
    "    print(\"Check model:\",\n",
    "          \" Fold: {0:d}\".format(fold),\n",
    "          \" Optimal epoch: {0:d}\".format(epoch_hat),\n",
    "          \" \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average number of epochs: 378\n",
      "Average validation error: 3.93032\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 3. Optimal epoch choice\n",
    "# ==================================\n",
    "# Pick number of epochs to train model for out-of-sample testing\n",
    "epoch_hat = int(np.mean(optimal_epochs))\n",
    "print(\"\\nAverage number of epochs:\", epoch_hat)\n",
    "# Average validation error\n",
    "print(\"Average validation error:\", np.mean(validation_fold_error))\n",
    "\n",
    "# Save validated model\n",
    "saveModel(sess, \n",
    "          MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + str(epoch_hat) + \"_validated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fixed scheme:\n",
      "Epoch: 1  Training loss = 1.7437  Test loss = 2.9394  \n",
      "\n",
      "Epoch: 2  Training loss = 1.7437  Test loss = 2.9394  \n",
      "\n",
      "Epoch: 3  Training loss = 1.7437  Test loss = 2.9393  \n",
      "\n",
      "Epoch: 4  Training loss = 1.7437  Test loss = 2.9393  \n",
      "\n",
      "Epoch: 5  Training loss = 1.7437  Test loss = 2.9393  \n",
      "\n",
      "Epoch: 6  Training loss = 1.7437  Test loss = 2.9393  \n",
      "\n",
      "Epoch: 7  Training loss = 1.7437  Test loss = 2.9392  \n",
      "\n",
      "Epoch: 8  Training loss = 1.7436  Test loss = 2.9392  \n",
      "\n",
      "Epoch: 9  Training loss = 1.7436  Test loss = 2.9392  \n",
      "\n",
      "Epoch: 10  Training loss = 1.7436  Test loss = 2.9392  \n",
      "\n",
      "Epoch: 11  Training loss = 1.7436  Test loss = 2.9392  \n",
      "\n",
      "Epoch: 12  Training loss = 1.7436  Test loss = 2.9391  \n",
      "\n",
      "Epoch: 13  Training loss = 1.7436  Test loss = 2.9391  \n",
      "\n",
      "Epoch: 14  Training loss = 1.7436  Test loss = 2.9391  \n",
      "\n",
      "Epoch: 15  Training loss = 1.7436  Test loss = 2.9391  \n",
      "\n",
      "Epoch: 16  Training loss = 1.7435  Test loss = 2.9390  \n",
      "\n",
      "Epoch: 17  Training loss = 1.7435  Test loss = 2.9390  \n",
      "\n",
      "Epoch: 18  Training loss = 1.7435  Test loss = 2.9390  \n",
      "\n",
      "Epoch: 19  Training loss = 1.7435  Test loss = 2.9390  \n",
      "\n",
      "Epoch: 20  Training loss = 1.7435  Test loss = 2.9389  \n",
      "\n",
      "Epoch: 21  Training loss = 1.7435  Test loss = 2.9389  \n",
      "\n",
      "Epoch: 22  Training loss = 1.7435  Test loss = 2.9389  \n",
      "\n",
      "Epoch: 23  Training loss = 1.7435  Test loss = 2.9389  \n",
      "\n",
      "Epoch: 24  Training loss = 1.7434  Test loss = 2.9389  \n",
      "\n",
      "Epoch: 25  Training loss = 1.7434  Test loss = 2.9388  \n",
      "\n",
      "Epoch: 26  Training loss = 1.7434  Test loss = 2.9388  \n",
      "\n",
      "Epoch: 27  Training loss = 1.7434  Test loss = 2.9388  \n",
      "\n",
      "Epoch: 28  Training loss = 1.7434  Test loss = 2.9388  \n",
      "\n",
      "Epoch: 29  Training loss = 1.7434  Test loss = 2.9387  \n",
      "\n",
      "Epoch: 30  Training loss = 1.7434  Test loss = 2.9387  \n",
      "\n",
      "Epoch: 31  Training loss = 1.7434  Test loss = 2.9387  \n",
      "\n",
      "Epoch: 32  Training loss = 1.7433  Test loss = 2.9387  \n",
      "\n",
      "Epoch: 33  Training loss = 1.7433  Test loss = 2.9387  \n",
      "\n",
      "Epoch: 34  Training loss = 1.7433  Test loss = 2.9386  \n",
      "\n",
      "Epoch: 35  Training loss = 1.7433  Test loss = 2.9386  \n",
      "\n",
      "Epoch: 36  Training loss = 1.7433  Test loss = 2.9386  \n",
      "\n",
      "Epoch: 37  Training loss = 1.7433  Test loss = 2.9386  \n",
      "\n",
      "Epoch: 38  Training loss = 1.7433  Test loss = 2.9385  \n",
      "\n",
      "Epoch: 39  Training loss = 1.7433  Test loss = 2.9385  \n",
      "\n",
      "Epoch: 40  Training loss = 1.7433  Test loss = 2.9385  \n",
      "\n",
      "Epoch: 41  Training loss = 1.7432  Test loss = 2.9385  \n",
      "\n",
      "Epoch: 42  Training loss = 1.7432  Test loss = 2.9385  \n",
      "\n",
      "Epoch: 43  Training loss = 1.7432  Test loss = 2.9384  \n",
      "\n",
      "Epoch: 44  Training loss = 1.7432  Test loss = 2.9384  \n",
      "\n",
      "Epoch: 45  Training loss = 1.7432  Test loss = 2.9384  \n",
      "\n",
      "Epoch: 46  Training loss = 1.7432  Test loss = 2.9384  \n",
      "\n",
      "Epoch: 47  Training loss = 1.7432  Test loss = 2.9383  \n",
      "\n",
      "Epoch: 48  Training loss = 1.7432  Test loss = 2.9383  \n",
      "\n",
      "Epoch: 49  Training loss = 1.7431  Test loss = 2.9383  \n",
      "\n",
      "Epoch: 50  Training loss = 1.7431  Test loss = 2.9383  \n",
      "\n",
      "Epoch: 51  Training loss = 1.7431  Test loss = 2.9382  \n",
      "\n",
      "Epoch: 52  Training loss = 1.7431  Test loss = 2.9382  \n",
      "\n",
      "Epoch: 53  Training loss = 1.7431  Test loss = 2.9382  \n",
      "\n",
      "Epoch: 54  Training loss = 1.7431  Test loss = 2.9382  \n",
      "\n",
      "Epoch: 55  Training loss = 1.7431  Test loss = 2.9382  \n",
      "\n",
      "Epoch: 56  Training loss = 1.7431  Test loss = 2.9381  \n",
      "\n",
      "Epoch: 57  Training loss = 1.7430  Test loss = 2.9381  \n",
      "\n",
      "Epoch: 58  Training loss = 1.7430  Test loss = 2.9381  \n",
      "\n",
      "Epoch: 59  Training loss = 1.7430  Test loss = 2.9381  \n",
      "\n",
      "Epoch: 60  Training loss = 1.7430  Test loss = 2.9380  \n",
      "\n",
      "Epoch: 61  Training loss = 1.7430  Test loss = 2.9380  \n",
      "\n",
      "Epoch: 62  Training loss = 1.7430  Test loss = 2.9380  \n",
      "\n",
      "Epoch: 63  Training loss = 1.7430  Test loss = 2.9380  \n",
      "\n",
      "Epoch: 64  Training loss = 1.7430  Test loss = 2.9380  \n",
      "\n",
      "Epoch: 65  Training loss = 1.7429  Test loss = 2.9379  \n",
      "\n",
      "Epoch: 66  Training loss = 1.7429  Test loss = 2.9379  \n",
      "\n",
      "Epoch: 67  Training loss = 1.7429  Test loss = 2.9379  \n",
      "\n",
      "Epoch: 68  Training loss = 1.7429  Test loss = 2.9379  \n",
      "\n",
      "Epoch: 69  Training loss = 1.7429  Test loss = 2.9378  \n",
      "\n",
      "Epoch: 70  Training loss = 1.7429  Test loss = 2.9378  \n",
      "\n",
      "Epoch: 71  Training loss = 1.7429  Test loss = 2.9378  \n",
      "\n",
      "Epoch: 72  Training loss = 1.7429  Test loss = 2.9378  \n",
      "\n",
      "Epoch: 73  Training loss = 1.7429  Test loss = 2.9378  \n",
      "\n",
      "Epoch: 74  Training loss = 1.7428  Test loss = 2.9377  \n",
      "\n",
      "Epoch: 75  Training loss = 1.7428  Test loss = 2.9377  \n",
      "\n",
      "Epoch: 76  Training loss = 1.7428  Test loss = 2.9377  \n",
      "\n",
      "Epoch: 77  Training loss = 1.7428  Test loss = 2.9377  \n",
      "\n",
      "Epoch: 78  Training loss = 1.7428  Test loss = 2.9376  \n",
      "\n",
      "Epoch: 79  Training loss = 1.7428  Test loss = 2.9376  \n",
      "\n",
      "Epoch: 80  Training loss = 1.7428  Test loss = 2.9376  \n",
      "\n",
      "Epoch: 81  Training loss = 1.7428  Test loss = 2.9376  \n",
      "\n",
      "Epoch: 82  Training loss = 1.7427  Test loss = 2.9376  \n",
      "\n",
      "Epoch: 83  Training loss = 1.7427  Test loss = 2.9375  \n",
      "\n",
      "Epoch: 84  Training loss = 1.7427  Test loss = 2.9375  \n",
      "\n",
      "Epoch: 85  Training loss = 1.7427  Test loss = 2.9375  \n",
      "\n",
      "Epoch: 86  Training loss = 1.7427  Test loss = 2.9375  \n",
      "\n",
      "Epoch: 87  Training loss = 1.7427  Test loss = 2.9374  \n",
      "\n",
      "Epoch: 88  Training loss = 1.7427  Test loss = 2.9374  \n",
      "\n",
      "Epoch: 89  Training loss = 1.7427  Test loss = 2.9374  \n",
      "\n",
      "Epoch: 90  Training loss = 1.7427  Test loss = 2.9374  \n",
      "\n",
      "Epoch: 91  Training loss = 1.7426  Test loss = 2.9373  \n",
      "\n",
      "Epoch: 92  Training loss = 1.7426  Test loss = 2.9373  \n",
      "\n",
      "Epoch: 93  Training loss = 1.7426  Test loss = 2.9373  \n",
      "\n",
      "Epoch: 94  Training loss = 1.7426  Test loss = 2.9373  \n",
      "\n",
      "Epoch: 95  Training loss = 1.7426  Test loss = 2.9373  \n",
      "\n",
      "Epoch: 96  Training loss = 1.7426  Test loss = 2.9372  \n",
      "\n",
      "Epoch: 97  Training loss = 1.7426  Test loss = 2.9372  \n",
      "\n",
      "Epoch: 98  Training loss = 1.7426  Test loss = 2.9372  \n",
      "\n",
      "Epoch: 99  Training loss = 1.7425  Test loss = 2.9372  \n",
      "\n",
      "Epoch: 100  Training loss = 1.7425  Test loss = 2.9371  \n",
      "\n",
      "Epoch: 101  Training loss = 1.7425  Test loss = 2.9371  \n",
      "\n",
      "Epoch: 102  Training loss = 1.7425  Test loss = 2.9371  \n",
      "\n",
      "Epoch: 103  Training loss = 1.7425  Test loss = 2.9371  \n",
      "\n",
      "Epoch: 104  Training loss = 1.7425  Test loss = 2.9371  \n",
      "\n",
      "Epoch: 105  Training loss = 1.7425  Test loss = 2.9370  \n",
      "\n",
      "Epoch: 106  Training loss = 1.7425  Test loss = 2.9370  \n",
      "\n",
      "Epoch: 107  Training loss = 1.7425  Test loss = 2.9370  \n",
      "\n",
      "Epoch: 108  Training loss = 1.7424  Test loss = 2.9370  \n",
      "\n",
      "Epoch: 109  Training loss = 1.7424  Test loss = 2.9369  \n",
      "\n",
      "Epoch: 110  Training loss = 1.7424  Test loss = 2.9369  \n",
      "\n",
      "Epoch: 111  Training loss = 1.7424  Test loss = 2.9369  \n",
      "\n",
      "Epoch: 112  Training loss = 1.7424  Test loss = 2.9369  \n",
      "\n",
      "Epoch: 113  Training loss = 1.7424  Test loss = 2.9369  \n",
      "\n",
      "Epoch: 114  Training loss = 1.7424  Test loss = 2.9368  \n",
      "\n",
      "Epoch: 115  Training loss = 1.7424  Test loss = 2.9368  \n",
      "\n",
      "Epoch: 116  Training loss = 1.7423  Test loss = 2.9368  \n",
      "\n",
      "Epoch: 117  Training loss = 1.7423  Test loss = 2.9368  \n",
      "\n",
      "Epoch: 118  Training loss = 1.7423  Test loss = 2.9367  \n",
      "\n",
      "Epoch: 119  Training loss = 1.7423  Test loss = 2.9367  \n",
      "\n",
      "Epoch: 120  Training loss = 1.7423  Test loss = 2.9367  \n",
      "\n",
      "Epoch: 121  Training loss = 1.7423  Test loss = 2.9367  \n",
      "\n",
      "Epoch: 122  Training loss = 1.7423  Test loss = 2.9367  \n",
      "\n",
      "Epoch: 123  Training loss = 1.7423  Test loss = 2.9366  \n",
      "\n",
      "Epoch: 124  Training loss = 1.7423  Test loss = 2.9366  \n",
      "\n",
      "Epoch: 125  Training loss = 1.7422  Test loss = 2.9366  \n",
      "\n",
      "Epoch: 126  Training loss = 1.7422  Test loss = 2.9366  \n",
      "\n",
      "Epoch: 127  Training loss = 1.7422  Test loss = 2.9365  \n",
      "\n",
      "Epoch: 128  Training loss = 1.7422  Test loss = 2.9365  \n",
      "\n",
      "Epoch: 129  Training loss = 1.7422  Test loss = 2.9365  \n",
      "\n",
      "Epoch: 130  Training loss = 1.7422  Test loss = 2.9365  \n",
      "\n",
      "Epoch: 131  Training loss = 1.7422  Test loss = 2.9365  \n",
      "\n",
      "Epoch: 132  Training loss = 1.7422  Test loss = 2.9364  \n",
      "\n",
      "Epoch: 133  Training loss = 1.7421  Test loss = 2.9364  \n",
      "\n",
      "Epoch: 134  Training loss = 1.7421  Test loss = 2.9364  \n",
      "\n",
      "Epoch: 135  Training loss = 1.7421  Test loss = 2.9364  \n",
      "\n",
      "Epoch: 136  Training loss = 1.7421  Test loss = 2.9363  \n",
      "\n",
      "Epoch: 137  Training loss = 1.7421  Test loss = 2.9363  \n",
      "\n",
      "Epoch: 138  Training loss = 1.7421  Test loss = 2.9363  \n",
      "\n",
      "Epoch: 139  Training loss = 1.7421  Test loss = 2.9363  \n",
      "\n",
      "Epoch: 140  Training loss = 1.7421  Test loss = 2.9363  \n",
      "\n",
      "Epoch: 141  Training loss = 1.7421  Test loss = 2.9362  \n",
      "\n",
      "Epoch: 142  Training loss = 1.7420  Test loss = 2.9362  \n",
      "\n",
      "Epoch: 143  Training loss = 1.7420  Test loss = 2.9362  \n",
      "\n",
      "Epoch: 144  Training loss = 1.7420  Test loss = 2.9362  \n",
      "\n",
      "Epoch: 145  Training loss = 1.7420  Test loss = 2.9361  \n",
      "\n",
      "Epoch: 146  Training loss = 1.7420  Test loss = 2.9361  \n",
      "\n",
      "Epoch: 147  Training loss = 1.7420  Test loss = 2.9361  \n",
      "\n",
      "Epoch: 148  Training loss = 1.7420  Test loss = 2.9361  \n",
      "\n",
      "Epoch: 149  Training loss = 1.7420  Test loss = 2.9361  \n",
      "\n",
      "Epoch: 150  Training loss = 1.7419  Test loss = 2.9360  \n",
      "\n",
      "Epoch: 151  Training loss = 1.7419  Test loss = 2.9360  \n",
      "\n",
      "Epoch: 152  Training loss = 1.7419  Test loss = 2.9360  \n",
      "\n",
      "Epoch: 153  Training loss = 1.7419  Test loss = 2.9360  \n",
      "\n",
      "Epoch: 154  Training loss = 1.7419  Test loss = 2.9359  \n",
      "\n",
      "Epoch: 155  Training loss = 1.7419  Test loss = 2.9359  \n",
      "\n",
      "Epoch: 156  Training loss = 1.7419  Test loss = 2.9359  \n",
      "\n",
      "Epoch: 157  Training loss = 1.7419  Test loss = 2.9359  \n",
      "\n",
      "Epoch: 158  Training loss = 1.7419  Test loss = 2.9359  \n",
      "\n",
      "Epoch: 159  Training loss = 1.7418  Test loss = 2.9358  \n",
      "\n",
      "Epoch: 160  Training loss = 1.7418  Test loss = 2.9358  \n",
      "\n",
      "Epoch: 161  Training loss = 1.7418  Test loss = 2.9358  \n",
      "\n",
      "Epoch: 162  Training loss = 1.7418  Test loss = 2.9358  \n",
      "\n",
      "Epoch: 163  Training loss = 1.7418  Test loss = 2.9357  \n",
      "\n",
      "Epoch: 164  Training loss = 1.7418  Test loss = 2.9357  \n",
      "\n",
      "Epoch: 165  Training loss = 1.7418  Test loss = 2.9357  \n",
      "\n",
      "Epoch: 166  Training loss = 1.7418  Test loss = 2.9357  \n",
      "\n",
      "Epoch: 167  Training loss = 1.7418  Test loss = 2.9357  \n",
      "\n",
      "Epoch: 168  Training loss = 1.7417  Test loss = 2.9356  \n",
      "\n",
      "Epoch: 169  Training loss = 1.7417  Test loss = 2.9356  \n",
      "\n",
      "Epoch: 170  Training loss = 1.7417  Test loss = 2.9356  \n",
      "\n",
      "Epoch: 171  Training loss = 1.7417  Test loss = 2.9356  \n",
      "\n",
      "Epoch: 172  Training loss = 1.7417  Test loss = 2.9355  \n",
      "\n",
      "Epoch: 173  Training loss = 1.7417  Test loss = 2.9355  \n",
      "\n",
      "Epoch: 174  Training loss = 1.7417  Test loss = 2.9355  \n",
      "\n",
      "Epoch: 175  Training loss = 1.7417  Test loss = 2.9355  \n",
      "\n",
      "Epoch: 176  Training loss = 1.7416  Test loss = 2.9355  \n",
      "\n",
      "Epoch: 177  Training loss = 1.7416  Test loss = 2.9354  \n",
      "\n",
      "Epoch: 178  Training loss = 1.7416  Test loss = 2.9354  \n",
      "\n",
      "Epoch: 179  Training loss = 1.7416  Test loss = 2.9354  \n",
      "\n",
      "Epoch: 180  Training loss = 1.7416  Test loss = 2.9354  \n",
      "\n",
      "Epoch: 181  Training loss = 1.7416  Test loss = 2.9354  \n",
      "\n",
      "Epoch: 182  Training loss = 1.7416  Test loss = 2.9353  \n",
      "\n",
      "Epoch: 183  Training loss = 1.7416  Test loss = 2.9353  \n",
      "\n",
      "Epoch: 184  Training loss = 1.7416  Test loss = 2.9353  \n",
      "\n",
      "Epoch: 185  Training loss = 1.7415  Test loss = 2.9353  \n",
      "\n",
      "Epoch: 186  Training loss = 1.7415  Test loss = 2.9352  \n",
      "\n",
      "Epoch: 187  Training loss = 1.7415  Test loss = 2.9352  \n",
      "\n",
      "Epoch: 188  Training loss = 1.7415  Test loss = 2.9352  \n",
      "\n",
      "Epoch: 189  Training loss = 1.7415  Test loss = 2.9352  \n",
      "\n",
      "Epoch: 190  Training loss = 1.7415  Test loss = 2.9352  \n",
      "\n",
      "Epoch: 191  Training loss = 1.7415  Test loss = 2.9351  \n",
      "\n",
      "Epoch: 192  Training loss = 1.7415  Test loss = 2.9351  \n",
      "\n",
      "Epoch: 193  Training loss = 1.7415  Test loss = 2.9351  \n",
      "\n",
      "Epoch: 194  Training loss = 1.7414  Test loss = 2.9351  \n",
      "\n",
      "Epoch: 195  Training loss = 1.7414  Test loss = 2.9350  \n",
      "\n",
      "Epoch: 196  Training loss = 1.7414  Test loss = 2.9350  \n",
      "\n",
      "Epoch: 197  Training loss = 1.7414  Test loss = 2.9350  \n",
      "\n",
      "Epoch: 198  Training loss = 1.7414  Test loss = 2.9350  \n",
      "\n",
      "Epoch: 199  Training loss = 1.7414  Test loss = 2.9350  \n",
      "\n",
      "Epoch: 200  Training loss = 1.7414  Test loss = 2.9349  \n",
      "\n",
      "Epoch: 201  Training loss = 1.7414  Test loss = 2.9349  \n",
      "\n",
      "Epoch: 202  Training loss = 1.7414  Test loss = 2.9349  \n",
      "\n",
      "Epoch: 203  Training loss = 1.7413  Test loss = 2.9349  \n",
      "\n",
      "Epoch: 204  Training loss = 1.7413  Test loss = 2.9348  \n",
      "\n",
      "Epoch: 205  Training loss = 1.7413  Test loss = 2.9348  \n",
      "\n",
      "Epoch: 206  Training loss = 1.7413  Test loss = 2.9348  \n",
      "\n",
      "Epoch: 207  Training loss = 1.7413  Test loss = 2.9348  \n",
      "\n",
      "Epoch: 208  Training loss = 1.7413  Test loss = 2.9348  \n",
      "\n",
      "Epoch: 209  Training loss = 1.7413  Test loss = 2.9347  \n",
      "\n",
      "Epoch: 210  Training loss = 1.7413  Test loss = 2.9347  \n",
      "\n",
      "Epoch: 211  Training loss = 1.7413  Test loss = 2.9347  \n",
      "\n",
      "Epoch: 212  Training loss = 1.7412  Test loss = 2.9347  \n",
      "\n",
      "Epoch: 213  Training loss = 1.7412  Test loss = 2.9347  \n",
      "\n",
      "Epoch: 214  Training loss = 1.7412  Test loss = 2.9346  \n",
      "\n",
      "Epoch: 215  Training loss = 1.7412  Test loss = 2.9346  \n",
      "\n",
      "Epoch: 216  Training loss = 1.7412  Test loss = 2.9346  \n",
      "\n",
      "Epoch: 217  Training loss = 1.7412  Test loss = 2.9346  \n",
      "\n",
      "Epoch: 218  Training loss = 1.7412  Test loss = 2.9345  \n",
      "\n",
      "Epoch: 219  Training loss = 1.7412  Test loss = 2.9345  \n",
      "\n",
      "Epoch: 220  Training loss = 1.7412  Test loss = 2.9345  \n",
      "\n",
      "Epoch: 221  Training loss = 1.7411  Test loss = 2.9345  \n",
      "\n",
      "Epoch: 222  Training loss = 1.7411  Test loss = 2.9345  \n",
      "\n",
      "Epoch: 223  Training loss = 1.7411  Test loss = 2.9344  \n",
      "\n",
      "Epoch: 224  Training loss = 1.7411  Test loss = 2.9344  \n",
      "\n",
      "Epoch: 225  Training loss = 1.7411  Test loss = 2.9344  \n",
      "\n",
      "Epoch: 226  Training loss = 1.7411  Test loss = 2.9344  \n",
      "\n",
      "Epoch: 227  Training loss = 1.7411  Test loss = 2.9343  \n",
      "\n",
      "Epoch: 228  Training loss = 1.7411  Test loss = 2.9343  \n",
      "\n",
      "Epoch: 229  Training loss = 1.7411  Test loss = 2.9343  \n",
      "\n",
      "Epoch: 230  Training loss = 1.7410  Test loss = 2.9343  \n",
      "\n",
      "Epoch: 231  Training loss = 1.7410  Test loss = 2.9343  \n",
      "\n",
      "Epoch: 232  Training loss = 1.7410  Test loss = 2.9342  \n",
      "\n",
      "Epoch: 233  Training loss = 1.7410  Test loss = 2.9342  \n",
      "\n",
      "Epoch: 234  Training loss = 1.7410  Test loss = 2.9342  \n",
      "\n",
      "Epoch: 235  Training loss = 1.7410  Test loss = 2.9342  \n",
      "\n",
      "Epoch: 236  Training loss = 1.7410  Test loss = 2.9341  \n",
      "\n",
      "Epoch: 237  Training loss = 1.7410  Test loss = 2.9341  \n",
      "\n",
      "Epoch: 238  Training loss = 1.7410  Test loss = 2.9341  \n",
      "\n",
      "Epoch: 239  Training loss = 1.7409  Test loss = 2.9341  \n",
      "\n",
      "Epoch: 240  Training loss = 1.7409  Test loss = 2.9341  \n",
      "\n",
      "Epoch: 241  Training loss = 1.7409  Test loss = 2.9340  \n",
      "\n",
      "Epoch: 242  Training loss = 1.7409  Test loss = 2.9340  \n",
      "\n",
      "Epoch: 243  Training loss = 1.7409  Test loss = 2.9340  \n",
      "\n",
      "Epoch: 244  Training loss = 1.7409  Test loss = 2.9340  \n",
      "\n",
      "Epoch: 245  Training loss = 1.7409  Test loss = 2.9340  \n",
      "\n",
      "Epoch: 246  Training loss = 1.7409  Test loss = 2.9339  \n",
      "\n",
      "Epoch: 247  Training loss = 1.7409  Test loss = 2.9339  \n",
      "\n",
      "Epoch: 248  Training loss = 1.7408  Test loss = 2.9339  \n",
      "\n",
      "Epoch: 249  Training loss = 1.7408  Test loss = 2.9339  \n",
      "\n",
      "Epoch: 250  Training loss = 1.7408  Test loss = 2.9338  \n",
      "\n",
      "Epoch: 251  Training loss = 1.7408  Test loss = 2.9338  \n",
      "\n",
      "Epoch: 252  Training loss = 1.7408  Test loss = 2.9338  \n",
      "\n",
      "Epoch: 253  Training loss = 1.7408  Test loss = 2.9338  \n",
      "\n",
      "Epoch: 254  Training loss = 1.7408  Test loss = 2.9338  \n",
      "\n",
      "Epoch: 255  Training loss = 1.7408  Test loss = 2.9337  \n",
      "\n",
      "Epoch: 256  Training loss = 1.7408  Test loss = 2.9337  \n",
      "\n",
      "Epoch: 257  Training loss = 1.7407  Test loss = 2.9337  \n",
      "\n",
      "Epoch: 258  Training loss = 1.7407  Test loss = 2.9337  \n",
      "\n",
      "Epoch: 259  Training loss = 1.7407  Test loss = 2.9337  \n",
      "\n",
      "Epoch: 260  Training loss = 1.7407  Test loss = 2.9336  \n",
      "\n",
      "Epoch: 261  Training loss = 1.7407  Test loss = 2.9336  \n",
      "\n",
      "Epoch: 262  Training loss = 1.7407  Test loss = 2.9336  \n",
      "\n",
      "Epoch: 263  Training loss = 1.7407  Test loss = 2.9336  \n",
      "\n",
      "Epoch: 264  Training loss = 1.7407  Test loss = 2.9335  \n",
      "\n",
      "Epoch: 265  Training loss = 1.7407  Test loss = 2.9335  \n",
      "\n",
      "Epoch: 266  Training loss = 1.7406  Test loss = 2.9335  \n",
      "\n",
      "Epoch: 267  Training loss = 1.7406  Test loss = 2.9335  \n",
      "\n",
      "Epoch: 268  Training loss = 1.7406  Test loss = 2.9335  \n",
      "\n",
      "Epoch: 269  Training loss = 1.7406  Test loss = 2.9334  \n",
      "\n",
      "Epoch: 270  Training loss = 1.7406  Test loss = 2.9334  \n",
      "\n",
      "Epoch: 271  Training loss = 1.7406  Test loss = 2.9334  \n",
      "\n",
      "Epoch: 272  Training loss = 1.7406  Test loss = 2.9334  \n",
      "\n",
      "Epoch: 273  Training loss = 1.7406  Test loss = 2.9333  \n",
      "\n",
      "Epoch: 274  Training loss = 1.7406  Test loss = 2.9333  \n",
      "\n",
      "Epoch: 275  Training loss = 1.7405  Test loss = 2.9333  \n",
      "\n",
      "Epoch: 276  Training loss = 1.7405  Test loss = 2.9333  \n",
      "\n",
      "Epoch: 277  Training loss = 1.7405  Test loss = 2.9333  \n",
      "\n",
      "Epoch: 278  Training loss = 1.7405  Test loss = 2.9332  \n",
      "\n",
      "Epoch: 279  Training loss = 1.7405  Test loss = 2.9332  \n",
      "\n",
      "Epoch: 280  Training loss = 1.7405  Test loss = 2.9332  \n",
      "\n",
      "Epoch: 281  Training loss = 1.7405  Test loss = 2.9332  \n",
      "\n",
      "Epoch: 282  Training loss = 1.7405  Test loss = 2.9332  \n",
      "\n",
      "Epoch: 283  Training loss = 1.7405  Test loss = 2.9331  \n",
      "\n",
      "Epoch: 284  Training loss = 1.7404  Test loss = 2.9331  \n",
      "\n",
      "Epoch: 285  Training loss = 1.7404  Test loss = 2.9331  \n",
      "\n",
      "Epoch: 286  Training loss = 1.7404  Test loss = 2.9331  \n",
      "\n",
      "Epoch: 287  Training loss = 1.7404  Test loss = 2.9330  \n",
      "\n",
      "Epoch: 288  Training loss = 1.7404  Test loss = 2.9330  \n",
      "\n",
      "Epoch: 289  Training loss = 1.7404  Test loss = 2.9330  \n",
      "\n",
      "Epoch: 290  Training loss = 1.7404  Test loss = 2.9330  \n",
      "\n",
      "Epoch: 291  Training loss = 1.7404  Test loss = 2.9330  \n",
      "\n",
      "Epoch: 292  Training loss = 1.7404  Test loss = 2.9329  \n",
      "\n",
      "Epoch: 293  Training loss = 1.7403  Test loss = 2.9329  \n",
      "\n",
      "Epoch: 294  Training loss = 1.7403  Test loss = 2.9329  \n",
      "\n",
      "Epoch: 295  Training loss = 1.7403  Test loss = 2.9329  \n",
      "\n",
      "Epoch: 296  Training loss = 1.7403  Test loss = 2.9329  \n",
      "\n",
      "Epoch: 297  Training loss = 1.7403  Test loss = 2.9328  \n",
      "\n",
      "Epoch: 298  Training loss = 1.7403  Test loss = 2.9328  \n",
      "\n",
      "Epoch: 299  Training loss = 1.7403  Test loss = 2.9328  \n",
      "\n",
      "Epoch: 300  Training loss = 1.7403  Test loss = 2.9328  \n",
      "\n",
      "Epoch: 301  Training loss = 1.7403  Test loss = 2.9327  \n",
      "\n",
      "Epoch: 302  Training loss = 1.7403  Test loss = 2.9327  \n",
      "\n",
      "Epoch: 303  Training loss = 1.7402  Test loss = 2.9327  \n",
      "\n",
      "Epoch: 304  Training loss = 1.7402  Test loss = 2.9327  \n",
      "\n",
      "Epoch: 305  Training loss = 1.7402  Test loss = 2.9327  \n",
      "\n",
      "Epoch: 306  Training loss = 1.7402  Test loss = 2.9326  \n",
      "\n",
      "Epoch: 307  Training loss = 1.7402  Test loss = 2.9326  \n",
      "\n",
      "Epoch: 308  Training loss = 1.7402  Test loss = 2.9326  \n",
      "\n",
      "Epoch: 309  Training loss = 1.7402  Test loss = 2.9326  \n",
      "\n",
      "Epoch: 310  Training loss = 1.7402  Test loss = 2.9326  \n",
      "\n",
      "Epoch: 311  Training loss = 1.7402  Test loss = 2.9325  \n",
      "\n",
      "Epoch: 312  Training loss = 1.7401  Test loss = 2.9325  \n",
      "\n",
      "Epoch: 313  Training loss = 1.7401  Test loss = 2.9325  \n",
      "\n",
      "Epoch: 314  Training loss = 1.7401  Test loss = 2.9325  \n",
      "\n",
      "Epoch: 315  Training loss = 1.7401  Test loss = 2.9324  \n",
      "\n",
      "Epoch: 316  Training loss = 1.7401  Test loss = 2.9324  \n",
      "\n",
      "Epoch: 317  Training loss = 1.7401  Test loss = 2.9324  \n",
      "\n",
      "Epoch: 318  Training loss = 1.7401  Test loss = 2.9324  \n",
      "\n",
      "Epoch: 319  Training loss = 1.7401  Test loss = 2.9324  \n",
      "\n",
      "Epoch: 320  Training loss = 1.7401  Test loss = 2.9323  \n",
      "\n",
      "Epoch: 321  Training loss = 1.7400  Test loss = 2.9323  \n",
      "\n",
      "Epoch: 322  Training loss = 1.7400  Test loss = 2.9323  \n",
      "\n",
      "Epoch: 323  Training loss = 1.7400  Test loss = 2.9323  \n",
      "\n",
      "Epoch: 324  Training loss = 1.7400  Test loss = 2.9323  \n",
      "\n",
      "Epoch: 325  Training loss = 1.7400  Test loss = 2.9322  \n",
      "\n",
      "Epoch: 326  Training loss = 1.7400  Test loss = 2.9322  \n",
      "\n",
      "Epoch: 327  Training loss = 1.7400  Test loss = 2.9322  \n",
      "\n",
      "Epoch: 328  Training loss = 1.7400  Test loss = 2.9322  \n",
      "\n",
      "Epoch: 329  Training loss = 1.7400  Test loss = 2.9322  \n",
      "\n",
      "Epoch: 330  Training loss = 1.7399  Test loss = 2.9321  \n",
      "\n",
      "Epoch: 331  Training loss = 1.7399  Test loss = 2.9321  \n",
      "\n",
      "Epoch: 332  Training loss = 1.7399  Test loss = 2.9321  \n",
      "\n",
      "Epoch: 333  Training loss = 1.7399  Test loss = 2.9321  \n",
      "\n",
      "Epoch: 334  Training loss = 1.7399  Test loss = 2.9320  \n",
      "\n",
      "Epoch: 335  Training loss = 1.7399  Test loss = 2.9320  \n",
      "\n",
      "Epoch: 336  Training loss = 1.7399  Test loss = 2.9320  \n",
      "\n",
      "Epoch: 337  Training loss = 1.7399  Test loss = 2.9320  \n",
      "\n",
      "Epoch: 338  Training loss = 1.7399  Test loss = 2.9320  \n",
      "\n",
      "Epoch: 339  Training loss = 1.7399  Test loss = 2.9319  \n",
      "\n",
      "Epoch: 340  Training loss = 1.7398  Test loss = 2.9319  \n",
      "\n",
      "Epoch: 341  Training loss = 1.7398  Test loss = 2.9319  \n",
      "\n",
      "Epoch: 342  Training loss = 1.7398  Test loss = 2.9319  \n",
      "\n",
      "Epoch: 343  Training loss = 1.7398  Test loss = 2.9319  \n",
      "\n",
      "Epoch: 344  Training loss = 1.7398  Test loss = 2.9318  \n",
      "\n",
      "Epoch: 345  Training loss = 1.7398  Test loss = 2.9318  \n",
      "\n",
      "Epoch: 346  Training loss = 1.7398  Test loss = 2.9318  \n",
      "\n",
      "Epoch: 347  Training loss = 1.7398  Test loss = 2.9318  \n",
      "\n",
      "Epoch: 348  Training loss = 1.7398  Test loss = 2.9317  \n",
      "\n",
      "Epoch: 349  Training loss = 1.7397  Test loss = 2.9317  \n",
      "\n",
      "Epoch: 350  Training loss = 1.7397  Test loss = 2.9317  \n",
      "\n",
      "Epoch: 351  Training loss = 1.7397  Test loss = 2.9317  \n",
      "\n",
      "Epoch: 352  Training loss = 1.7397  Test loss = 2.9317  \n",
      "\n",
      "Epoch: 353  Training loss = 1.7397  Test loss = 2.9316  \n",
      "\n",
      "Epoch: 354  Training loss = 1.7397  Test loss = 2.9316  \n",
      "\n",
      "Epoch: 355  Training loss = 1.7397  Test loss = 2.9316  \n",
      "\n",
      "Epoch: 356  Training loss = 1.7397  Test loss = 2.9316  \n",
      "\n",
      "Epoch: 357  Training loss = 1.7397  Test loss = 2.9316  \n",
      "\n",
      "Epoch: 358  Training loss = 1.7397  Test loss = 2.9315  \n",
      "\n",
      "Epoch: 359  Training loss = 1.7396  Test loss = 2.9315  \n",
      "\n",
      "Epoch: 360  Training loss = 1.7396  Test loss = 2.9315  \n",
      "\n",
      "Epoch: 361  Training loss = 1.7396  Test loss = 2.9315  \n",
      "\n",
      "Epoch: 362  Training loss = 1.7396  Test loss = 2.9315  \n",
      "\n",
      "Epoch: 363  Training loss = 1.7396  Test loss = 2.9314  \n",
      "\n",
      "Epoch: 364  Training loss = 1.7396  Test loss = 2.9314  \n",
      "\n",
      "Epoch: 365  Training loss = 1.7396  Test loss = 2.9314  \n",
      "\n",
      "Epoch: 366  Training loss = 1.7396  Test loss = 2.9314  \n",
      "\n",
      "Epoch: 367  Training loss = 1.7396  Test loss = 2.9313  \n",
      "\n",
      "Epoch: 368  Training loss = 1.7395  Test loss = 2.9313  \n",
      "\n",
      "Epoch: 369  Training loss = 1.7395  Test loss = 2.9313  \n",
      "\n",
      "Epoch: 370  Training loss = 1.7395  Test loss = 2.9313  \n",
      "\n",
      "Epoch: 371  Training loss = 1.7395  Test loss = 2.9313  \n",
      "\n",
      "Epoch: 372  Training loss = 1.7395  Test loss = 2.9312  \n",
      "\n",
      "Epoch: 373  Training loss = 1.7395  Test loss = 2.9312  \n",
      "\n",
      "Epoch: 374  Training loss = 1.7395  Test loss = 2.9312  \n",
      "\n",
      "Epoch: 375  Training loss = 1.7395  Test loss = 2.9312  \n",
      "\n",
      "Epoch: 376  Training loss = 1.7395  Test loss = 2.9312  \n",
      "\n",
      "Epoch: 377  Training loss = 1.7395  Test loss = 2.9311  \n",
      "\n",
      "Epoch: 378  Training loss = 1.7394  Test loss = 2.9311  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 4. Fixed scheme\n",
    "# ==================================\n",
    "print(\"\\nFixed scheme:\")\n",
    "for epoch in range(epoch_hat):\n",
    "    x_train = train_features[-window_length:]\n",
    "    y_train = train_target[-window_length:]\n",
    "    optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:test_features, y:test_target})\n",
    "    print(\"Epoch: {0:d}\".format(epoch+1),\n",
    "          \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "          \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "          \" \\n\")\n",
    "\n",
    "# Forecasts\n",
    "yhat_test_fixed = pred.eval(feed_dict={x:test_features})\n",
    "yhat_train_fixed = pred.eval(feed_dict={x:x_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc1cf240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train set\n",
    "plt.plot(y_train, 'black')\n",
    "plt.plot(yhat_train_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xce3d2b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: fixed scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_test_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed scheme RMSE: 2.93111356292 \n",
      "Fixed scheme MAE:  2.13594511185\n"
     ]
    }
   ],
   "source": [
    "rmse_fixed = np.sqrt(np.mean((yhat_test_fixed[:,0]-test_target)**2))\n",
    "mae_fixed = np.mean(np.abs((yhat_test_fixed[:,0]-test_target)))\n",
    "print(\"Fixed scheme RMSE:\", rmse_fixed,\n",
    "     \"\\nFixed scheme MAE: \", mae_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Stack training and test set, this makes updating scheme easier to train\n",
    "all_features = np.concatenate((train_features[-window_length:], test_features), axis=0)\n",
    "all_target = np.concatenate((train_target[-window_length:], test_target), axis=0)\n",
    "\n",
    "# Vectors to store loss and forecasts\n",
    "test_loss = np.zeros(len(test_target))\n",
    "yhat_update = np.zeros(len(test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test period = 1  Training loss = 1.7394  Test loss = 4.1999  Model updated 0 times  \n",
      "\n",
      "Test period = 2  Training loss = 1.8082  Test loss = 3.4084  Model updated 0 times  \n",
      "\n",
      "Test period = 3  Training loss = 1.8466  Test loss = 1.7997  Model updated 0 times  \n",
      "\n",
      "Test period = 4  Training loss = 1.8401  Test loss = 0.2779  Model updated 0 times  \n",
      "\n",
      "Test period = 5  Training loss = 1.7417  Test loss = 0.6210  Model updated 1 times  \n",
      "\n",
      "Test period = 6  Training loss = 1.6608  Test loss = 0.2929  Model updated 1 times  \n",
      "\n",
      "Test period = 7  Training loss = 1.6001  Test loss = 0.1400  Model updated 1 times  \n",
      "\n",
      "Test period = 8  Training loss = 1.5957  Test loss = 2.0461  Model updated 1 times  \n",
      "\n",
      "Test period = 9  Training loss = 1.5697  Test loss = 2.1155  Model updated 2 times  \n",
      "\n",
      "Test period = 10  Training loss = 1.5838  Test loss = 0.3294  Model updated 2 times  \n",
      "\n",
      "Test period = 11  Training loss = 1.5802  Test loss = 0.8873  Model updated 2 times  \n",
      "\n",
      "Test period = 12  Training loss = 1.5812  Test loss = 0.7123  Model updated 2 times  \n",
      "\n",
      "Test period = 13  Training loss = 1.5258  Test loss = 1.4424  Model updated 3 times  \n",
      "\n",
      "Test period = 14  Training loss = 1.5337  Test loss = 0.5827  Model updated 3 times  \n",
      "\n",
      "Test period = 15  Training loss = 1.5242  Test loss = 2.4890  Model updated 3 times  \n",
      "\n",
      "Test period = 16  Training loss = 1.5497  Test loss = 4.2640  Model updated 3 times  \n",
      "\n",
      "Test period = 17  Training loss = 1.6172  Test loss = 2.8251  Model updated 4 times  \n",
      "\n",
      "Test period = 18  Training loss = 1.6522  Test loss = 0.3386  Model updated 4 times  \n",
      "\n",
      "Test period = 19  Training loss = 1.6426  Test loss = 0.5665  Model updated 4 times  \n",
      "\n",
      "Test period = 20  Training loss = 1.5433  Test loss = 1.3652  Model updated 4 times  \n",
      "\n",
      "Test period = 21  Training loss = 1.5380  Test loss = 1.8577  Model updated 5 times  \n",
      "\n",
      "Test period = 22  Training loss = 1.5399  Test loss = 3.4280  Model updated 5 times  \n",
      "\n",
      "Test period = 23  Training loss = 1.5975  Test loss = 0.4335  Model updated 5 times  \n",
      "\n",
      "Test period = 24  Training loss = 1.5959  Test loss = 2.1872  Model updated 5 times  \n",
      "\n",
      "Test period = 25  Training loss = 1.6046  Test loss = 0.2356  Model updated 6 times  \n",
      "\n",
      "Test period = 26  Training loss = 1.5995  Test loss = 0.2842  Model updated 6 times  \n",
      "\n",
      "Test period = 27  Training loss = 1.5984  Test loss = 0.9693  Model updated 6 times  \n",
      "\n",
      "Test period = 28  Training loss = 1.6018  Test loss = 1.5061  Model updated 6 times  \n",
      "\n",
      "Test period = 29  Training loss = 1.5925  Test loss = 0.6487  Model updated 7 times  \n",
      "\n",
      "Test period = 30  Training loss = 1.5884  Test loss = 0.9898  Model updated 7 times  \n",
      "\n",
      "Test period = 31  Training loss = 1.5838  Test loss = 2.7826  Model updated 7 times  \n",
      "\n",
      "Test period = 32  Training loss = 1.5658  Test loss = 0.7691  Model updated 7 times  \n",
      "\n",
      "Test period = 33  Training loss = 1.5552  Test loss = 1.2734  Model updated 8 times  \n",
      "\n",
      "Test period = 34  Training loss = 1.5493  Test loss = 0.3696  Model updated 8 times  \n",
      "\n",
      "Test period = 35  Training loss = 1.4923  Test loss = 0.4521  Model updated 8 times  \n",
      "\n",
      "Test period = 36  Training loss = 1.4870  Test loss = 4.9704  Model updated 8 times  \n",
      "\n",
      "Test period = 37  Training loss = 1.5251  Test loss = 0.9949  Model updated 9 times  \n",
      "\n",
      "Test period = 38  Training loss = 1.4469  Test loss = 1.6408  Model updated 9 times  \n",
      "\n",
      "Test period = 39  Training loss = 1.4611  Test loss = 0.6513  Model updated 9 times  \n",
      "\n",
      "Test period = 40  Training loss = 1.4618  Test loss = 1.5364  Model updated 9 times  \n",
      "\n",
      "Test period = 41  Training loss = 1.4591  Test loss = 1.1694  Model updated 10 times  \n",
      "\n",
      "Test period = 42  Training loss = 1.4661  Test loss = 1.8907  Model updated 10 times  \n",
      "\n",
      "Test period = 43  Training loss = 1.4847  Test loss = 3.8684  Model updated 10 times  \n",
      "\n",
      "Test period = 44  Training loss = 1.5598  Test loss = 12.2218  Model updated 10 times  \n",
      "\n",
      "Test period = 45  Training loss = 2.1676  Test loss = 5.6207  Model updated 11 times  \n",
      "\n",
      "Test period = 46  Training loss = 2.2750  Test loss = 0.5300  Model updated 11 times  \n",
      "\n",
      "Test period = 47  Training loss = 2.2759  Test loss = 0.6036  Model updated 11 times  \n",
      "\n",
      "Test period = 48  Training loss = 2.2732  Test loss = 0.2796  Model updated 11 times  \n",
      "\n",
      "Test period = 49  Training loss = 2.2485  Test loss = 1.7136  Model updated 12 times  \n",
      "\n",
      "Test period = 50  Training loss = 2.2572  Test loss = 2.8974  Model updated 12 times  \n",
      "\n",
      "Test period = 51  Training loss = 2.2823  Test loss = 0.7982  Model updated 12 times  \n",
      "\n",
      "Test period = 52  Training loss = 2.2801  Test loss = 0.8515  Model updated 12 times  \n",
      "\n",
      "Test period = 53  Training loss = 2.2639  Test loss = 1.4305  Model updated 13 times  \n",
      "\n",
      "Test period = 54  Training loss = 2.2709  Test loss = 0.9925  Model updated 13 times  \n",
      "\n",
      "Test period = 55  Training loss = 2.2738  Test loss = 1.0439  Model updated 13 times  \n",
      "\n",
      "Test period = 56  Training loss = 2.2751  Test loss = 2.2121  Model updated 13 times  \n",
      "\n",
      "Test period = 57  Training loss = 2.2725  Test loss = 1.4343  Model updated 14 times  \n",
      "\n",
      "Test period = 58  Training loss = 2.2792  Test loss = 2.5960  Model updated 14 times  \n",
      "\n",
      "Test period = 59  Training loss = 2.2998  Test loss = 0.9660  Model updated 14 times  \n",
      "\n",
      "Test period = 60  Training loss = 2.3028  Test loss = 0.1886  Model updated 14 times  \n",
      "\n",
      "Test period = 61  Training loss = 2.2915  Test loss = 1.0703  Model updated 15 times  \n",
      "\n",
      "Test period = 62  Training loss = 2.2944  Test loss = 3.1847  Model updated 15 times  \n",
      "\n",
      "Test period = 63  Training loss = 2.3276  Test loss = 0.7497  Model updated 15 times  \n",
      "\n",
      "Test period = 64  Training loss = 2.3175  Test loss = 0.9016  Model updated 15 times  \n",
      "\n",
      "Test period = 65  Training loss = 2.3008  Test loss = 0.3178  Model updated 16 times  \n",
      "\n",
      "Test period = 66  Training loss = 2.2992  Test loss = 1.4904  Model updated 16 times  \n",
      "\n",
      "Test period = 67  Training loss = 2.2933  Test loss = 1.9006  Model updated 16 times  \n",
      "\n",
      "Test period = 68  Training loss = 2.2984  Test loss = 3.8420  Model updated 16 times  \n",
      "\n",
      "Test period = 69  Training loss = 2.3370  Test loss = 5.5050  Model updated 17 times  \n",
      "\n",
      "Test period = 70  Training loss = 2.4344  Test loss = 0.2268  Model updated 17 times  \n",
      "\n",
      "Test period = 71  Training loss = 2.4333  Test loss = 1.1155  Model updated 17 times  \n",
      "\n",
      "Test period = 72  Training loss = 2.4372  Test loss = 2.8559  Model updated 17 times  \n",
      "\n",
      "Test period = 73  Training loss = 2.4316  Test loss = 2.0844  Model updated 18 times  \n",
      "\n",
      "Test period = 74  Training loss = 2.4354  Test loss = 0.4281  Model updated 18 times  \n",
      "\n",
      "Test period = 75  Training loss = 2.4227  Test loss = 0.0462  Model updated 18 times  \n",
      "\n",
      "Test period = 76  Training loss = 2.4212  Test loss = 1.4840  Model updated 18 times  \n",
      "\n",
      "Test period = 77  Training loss = 2.3744  Test loss = 1.0487  Model updated 19 times  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "retrain_count = 0\n",
    "for t in range(len(test_target)):\n",
    "    x_test = np.reshape(test_features[t], newshape=(1,4,3))\n",
    "    y_test = test_target[t]\n",
    "    test_loss[t] = np.sqrt(sess.run(loss, feed_dict={x:x_test, y:y_test}))\n",
    "    yhat_update[t] = pred.eval(feed_dict={x:x_test})\n",
    "\n",
    "    x_train = all_features[t:(window_length+t)]\n",
    "    y_train = all_target[t:(window_length+t)]\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:x_test, y:y_test})\n",
    "    \n",
    "    print(\"Test period = {0:d}\".format(t+1),\n",
    "      \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "      \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "      \" Model updated {0:d} times\".format(retrain_count),\n",
    "      \" \\n\")\n",
    "\n",
    "    if (t+1)%4==0:\n",
    "        retrain_count += 1\n",
    "        for epoch in range(epoch_hat):\n",
    "            for i in range(total_batch):\n",
    "                optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc5e7f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: updating scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_update, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating scheme RMSE: 2.44579643004 \n",
      "Updating scheme MAE:  1.69149239111\n"
     ]
    }
   ],
   "source": [
    "rmse_update = np.sqrt(np.mean((yhat_update-test_target)**2))\n",
    "mae_update = np.mean(np.abs((yhat_update-test_target)))\n",
    "print(\"Updating scheme RMSE:\", rmse_update,\n",
    "     \"\\nUpdating scheme MAE: \", mae_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + \"yhat_test_fixed.csv\", yhat_test_fixed)\n",
    "np.savetxt(MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + \"yhat_update.csv\", yhat_update)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
