{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Directories\n",
    "MODEL_FOLDER = \"../../../models/lstm/\"\n",
    "MODEL_FILENAME = MODEL_FOLDER + \"4Q/32_units/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: model saver\n",
    "def saveModel(sess, MODEL_FILENAME):\n",
    "    if not os.path.exists(MODEL_FOLDER):\n",
    "        print('Creating path where to save model: ' + MODEL_FOLDER)\n",
    "        os.mkdir(MODEL_FOLDER)\n",
    "\n",
    "    #print('Saving model at: ' + MODEL_FILENAME)\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, MODEL_FILENAME)\n",
    "    #print('Model successfully saved.\\n')\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: model loader\n",
    "def loadModel(sess, MODEL_FILENAME):\n",
    "    if os.path.exists(MODEL_FILENAME + \".index\"):\n",
    "        print('Loading save model from: ' + MODEL_FILENAME)\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, MODEL_FILENAME)\n",
    "        print('Model successfully loaded.\\n')\n",
    "        return True\n",
    "    else:\n",
    "        print('Model file <<' + MODEL_FILENAME + '>> does not exists!')\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Hyperparameters\n",
    "epochs = 500\n",
    "learning_rate = 1e-5\n",
    "batch_size = 5\n",
    "early_stop_iters = 10\n",
    "folds = 32\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 3  # data input\n",
    "n_steps = 4  # timesteps\n",
    "n_hidden = 32 # dimension of recurrent unit\n",
    "\n",
    "# (REPRODUCIBILITY) set random seeds\n",
    "tf.set_random_seed(123)\n",
    "\n",
    "# Define weights and biases\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.truncated_normal([n_hidden, 1], stddev = 1.0 / tf.sqrt(float(n_hidden))),\n",
    "        name='out_weight')\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.zeros([1]),\n",
    "        name='out_bias')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: Build model\n",
    "def RNN(X, weights, biases, n_hidden):\n",
    "\n",
    "    # Define a LSTM cell with tensorflow\n",
    "    lstm_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden, state_is_tuple=True)\n",
    "    outputs, _ = tf.nn.dynamic_rnn(lstm_cell, X, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    out_layer = tf.matmul(outputs[:,-1,:], weights['out']) + biases['out']\n",
    "\n",
    "    return out_layer\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: select batch\n",
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the data...\n",
      "Finished: data loaded. Stats below: \n",
      "Nr of training samples: 193\n",
      "Nr of testing  samples: 77\n",
      "Number of variables: 3\n",
      "Number of lags: 4\n",
      "Window length: 65\n",
      "Number of validation folds: 32\n"
     ]
    }
   ],
   "source": [
    "# =================================\n",
    "# 0. Load dataset\n",
    "# =================================\n",
    "print(\"Loading the data...\")\n",
    "# Training set pre-processing\n",
    "train = pd.read_csv('../../../Data/train.csv')\n",
    "train_4lag_inflation = np.array(train[['inflation.lag4',\n",
    "                                       'inflation.lag5',\n",
    "                                       'inflation.lag6',\n",
    "                                       'inflation.lag7']])\n",
    "train_4lag_unemp = np.array(train[['unemp.lag4',\n",
    "                                   'unemp.lag5',\n",
    "                                   'unemp.lag6',\n",
    "                                   'unemp.lag7']])\n",
    "train_4lag_oil = np.array(train[['oil.lag4',\n",
    "                                 'oil.lag5',\n",
    "                                 'oil.lag6',\n",
    "                                 'oil.lag7']])\n",
    "train_features = np.concatenate((train_4lag_inflation[:,:,np.newaxis], \n",
    "\t                             train_4lag_unemp[:,:,np.newaxis],\n",
    "\t                             train_4lag_oil[:,:,np.newaxis]),\n",
    "\t                             axis=2)\n",
    "train_target = np.array(train['inflation.target'])\n",
    "\n",
    "# Test set pre-processing\n",
    "test = pd.read_csv('../../../Data/test.csv')\n",
    "test_4lag_inflation = np.array(test[['inflation.lag4',\n",
    "                                     'inflation.lag5',\n",
    "                                     'inflation.lag6',\n",
    "                                     'inflation.lag7']])\n",
    "test_4lag_unemp = np.array(test[['unemp.lag4',\n",
    "                                 'unemp.lag5',\n",
    "                                 'unemp.lag6',\n",
    "                                 'unemp.lag7']])\n",
    "test_4lag_oil = np.array(test[['oil.lag4',\n",
    "                               'oil.lag5',\n",
    "                               'oil.lag6',\n",
    "                               'oil.lag7']])\n",
    "test_features = np.concatenate((test_4lag_inflation[:,:,np.newaxis], \n",
    "\t                            test_4lag_unemp[:,:,np.newaxis],\n",
    "\t                            test_4lag_oil[:,:,np.newaxis]),\n",
    "\t                            axis=2)\n",
    "test_target = np.array(test['inflation.target'])\n",
    "\n",
    "(nrTrainSamples, timesteps, variables) = train_features.shape\n",
    "(nrTestSamples, _, _) = test_features.shape\n",
    "\n",
    "# Window length and validation fold index\n",
    "window_length = 65\n",
    "valIndex = np.linspace(start=window_length, stop=nrTrainSamples, \n",
    "                       endpoint=True, num=folds+1, dtype=np.int)\n",
    "\n",
    "print(\"Finished: data loaded. Stats below: \")\n",
    "print(\"Nr of training samples: %d\" % nrTrainSamples)\n",
    "print(\"Nr of testing  samples: %d\" % nrTestSamples)\n",
    "print(\"Number of variables: %d\" % variables)\n",
    "print(\"Number of lags: %d\" % timesteps)\n",
    "print(\"Window length: %d\" % window_length)\n",
    "print(\"Number of validation folds: %d\" % folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 1. Build model\n",
    "# ==================================\n",
    "# tf graph input\n",
    "x = tf.placeholder(\"float\", [None, n_steps, n_input], name='Batch')\n",
    "y = tf.placeholder(\"float\", name='True_labels_of_batch')\n",
    "lr = tf.placeholder(\"float\", name='Learning_rate')\n",
    "\n",
    "# Make predictions with the model\n",
    "pred = RNN(x, weights, biases, n_hidden)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss = tf.reduce_mean(tf.diag_part(tf.square(tf.subtract(x=pred, y=y))))\n",
    "optimizer = tf.train.GradientDescentOptimizer(lr).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training \n",
      "Hyperparameters: \n",
      "Dimension of recurrent unit = 32 \n",
      "Learning rate = 1e-05 \n",
      "Epochs = 500 \n",
      "Batch size = 5 \n",
      "Early stopping epochs = 10 \n",
      "Learning rate = 1e-05\n",
      "Fold: 1  Epoch: 1  Training loss = 3.5247  Validation loss = 3.8758  \n",
      "\n",
      "Fold: 1  Epoch: 2  Training loss = 3.5223  Validation loss = 3.8719  \n",
      "\n",
      "Fold: 1  Epoch: 3  Training loss = 3.5200  Validation loss = 3.8680  \n",
      "\n",
      "Fold: 1  Epoch: 4  Training loss = 3.5173  Validation loss = 3.8636  \n",
      "\n",
      "Fold: 1  Epoch: 5  Training loss = 3.5149  Validation loss = 3.8598  \n",
      "\n",
      "Fold: 1  Epoch: 6  Training loss = 3.5122  Validation loss = 3.8555  \n",
      "\n",
      "Fold: 1  Epoch: 7  Training loss = 3.5094  Validation loss = 3.8509  \n",
      "\n",
      "Fold: 1  Epoch: 8  Training loss = 3.5060  Validation loss = 3.8456  \n",
      "\n",
      "Fold: 1  Epoch: 9  Training loss = 3.5038  Validation loss = 3.8419  \n",
      "\n",
      "Fold: 1  Epoch: 10  Training loss = 3.5020  Validation loss = 3.8390  \n",
      "\n",
      "Fold: 1  Epoch: 11  Training loss = 3.4994  Validation loss = 3.8347  \n",
      "\n",
      "Fold: 1  Epoch: 12  Training loss = 3.4972  Validation loss = 3.8311  \n",
      "\n",
      "Fold: 1  Epoch: 13  Training loss = 3.4943  Validation loss = 3.8264  \n",
      "\n",
      "Fold: 1  Epoch: 14  Training loss = 3.4922  Validation loss = 3.8230  \n",
      "\n",
      "Fold: 1  Epoch: 15  Training loss = 3.4897  Validation loss = 3.8190  \n",
      "\n",
      "Fold: 1  Epoch: 16  Training loss = 3.4878  Validation loss = 3.8157  \n",
      "\n",
      "Fold: 1  Epoch: 17  Training loss = 3.4854  Validation loss = 3.8119  \n",
      "\n",
      "Fold: 1  Epoch: 18  Training loss = 3.4835  Validation loss = 3.8087  \n",
      "\n",
      "Fold: 1  Epoch: 19  Training loss = 3.4809  Validation loss = 3.8043  \n",
      "\n",
      "Fold: 1  Epoch: 20  Training loss = 3.4781  Validation loss = 3.7998  \n",
      "\n",
      "Fold: 1  Epoch: 21  Training loss = 3.4756  Validation loss = 3.7956  \n",
      "\n",
      "Fold: 1  Epoch: 22  Training loss = 3.4731  Validation loss = 3.7915  \n",
      "\n",
      "Fold: 1  Epoch: 23  Training loss = 3.4709  Validation loss = 3.7877  \n",
      "\n",
      "Fold: 1  Epoch: 24  Training loss = 3.4684  Validation loss = 3.7836  \n",
      "\n",
      "Fold: 1  Epoch: 25  Training loss = 3.4659  Validation loss = 3.7795  \n",
      "\n",
      "Fold: 1  Epoch: 26  Training loss = 3.4633  Validation loss = 3.7751  \n",
      "\n",
      "Fold: 1  Epoch: 27  Training loss = 3.4611  Validation loss = 3.7715  \n",
      "\n",
      "Fold: 1  Epoch: 28  Training loss = 3.4584  Validation loss = 3.7669  \n",
      "\n",
      "Fold: 1  Epoch: 29  Training loss = 3.4563  Validation loss = 3.7634  \n",
      "\n",
      "Fold: 1  Epoch: 30  Training loss = 3.4540  Validation loss = 3.7595  \n",
      "\n",
      "Fold: 1  Epoch: 31  Training loss = 3.4520  Validation loss = 3.7562  \n",
      "\n",
      "Fold: 1  Epoch: 32  Training loss = 3.4497  Validation loss = 3.7523  \n",
      "\n",
      "Fold: 1  Epoch: 33  Training loss = 3.4473  Validation loss = 3.7483  \n",
      "\n",
      "Fold: 1  Epoch: 34  Training loss = 3.4452  Validation loss = 3.7449  \n",
      "\n",
      "Fold: 1  Epoch: 35  Training loss = 3.4427  Validation loss = 3.7407  \n",
      "\n",
      "Fold: 1  Epoch: 36  Training loss = 3.4403  Validation loss = 3.7365  \n",
      "\n",
      "Fold: 1  Epoch: 37  Training loss = 3.4379  Validation loss = 3.7324  \n",
      "\n",
      "Fold: 1  Epoch: 38  Training loss = 3.4359  Validation loss = 3.7290  \n",
      "\n",
      "Fold: 1  Epoch: 39  Training loss = 3.4339  Validation loss = 3.7254  \n",
      "\n",
      "Fold: 1  Epoch: 40  Training loss = 3.4315  Validation loss = 3.7213  \n",
      "\n",
      "Fold: 1  Epoch: 41  Training loss = 3.4289  Validation loss = 3.7167  \n",
      "\n",
      "Fold: 1  Epoch: 42  Training loss = 3.4265  Validation loss = 3.7126  \n",
      "\n",
      "Fold: 1  Epoch: 43  Training loss = 3.4245  Validation loss = 3.7092  \n",
      "\n",
      "Fold: 1  Epoch: 44  Training loss = 3.4225  Validation loss = 3.7056  \n",
      "\n",
      "Fold: 1  Epoch: 45  Training loss = 3.4207  Validation loss = 3.7024  \n",
      "\n",
      "Fold: 1  Epoch: 46  Training loss = 3.4185  Validation loss = 3.6987  \n",
      "\n",
      "Fold: 1  Epoch: 47  Training loss = 3.4167  Validation loss = 3.6956  \n",
      "\n",
      "Fold: 1  Epoch: 48  Training loss = 3.4145  Validation loss = 3.6919  \n",
      "\n",
      "Fold: 1  Epoch: 49  Training loss = 3.4129  Validation loss = 3.6890  \n",
      "\n",
      "Fold: 1  Epoch: 50  Training loss = 3.4110  Validation loss = 3.6857  \n",
      "\n",
      "Fold: 1  Epoch: 51  Training loss = 3.4090  Validation loss = 3.6822  \n",
      "\n",
      "Fold: 1  Epoch: 52  Training loss = 3.4065  Validation loss = 3.6780  \n",
      "\n",
      "Fold: 1  Epoch: 53  Training loss = 3.4046  Validation loss = 3.6746  \n",
      "\n",
      "Fold: 1  Epoch: 54  Training loss = 3.4022  Validation loss = 3.6705  \n",
      "\n",
      "Fold: 1  Epoch: 55  Training loss = 3.4004  Validation loss = 3.6672  \n",
      "\n",
      "Fold: 1  Epoch: 56  Training loss = 3.3983  Validation loss = 3.6638  \n",
      "\n",
      "Fold: 1  Epoch: 57  Training loss = 3.3965  Validation loss = 3.6605  \n",
      "\n",
      "Fold: 1  Epoch: 58  Training loss = 3.3939  Validation loss = 3.6560  \n",
      "\n",
      "Fold: 1  Epoch: 59  Training loss = 3.3919  Validation loss = 3.6524  \n",
      "\n",
      "Fold: 1  Epoch: 60  Training loss = 3.3898  Validation loss = 3.6486  \n",
      "\n",
      "Fold: 1  Epoch: 61  Training loss = 3.3877  Validation loss = 3.6449  \n",
      "\n",
      "Fold: 1  Epoch: 62  Training loss = 3.3854  Validation loss = 3.6409  \n",
      "\n",
      "Fold: 1  Epoch: 63  Training loss = 3.3832  Validation loss = 3.6370  \n",
      "\n",
      "Fold: 1  Epoch: 64  Training loss = 3.3812  Validation loss = 3.6337  \n",
      "\n",
      "Fold: 1  Epoch: 65  Training loss = 3.3792  Validation loss = 3.6300  \n",
      "\n",
      "Fold: 1  Epoch: 66  Training loss = 3.3774  Validation loss = 3.6269  \n",
      "\n",
      "Fold: 1  Epoch: 67  Training loss = 3.3757  Validation loss = 3.6237  \n",
      "\n",
      "Fold: 1  Epoch: 68  Training loss = 3.3729  Validation loss = 3.6190  \n",
      "\n",
      "Fold: 1  Epoch: 69  Training loss = 3.3708  Validation loss = 3.6153  \n",
      "\n",
      "Fold: 1  Epoch: 70  Training loss = 3.3686  Validation loss = 3.6115  \n",
      "\n",
      "Fold: 1  Epoch: 71  Training loss = 3.3659  Validation loss = 3.6068  \n",
      "\n",
      "Fold: 1  Epoch: 72  Training loss = 3.3641  Validation loss = 3.6034  \n",
      "\n",
      "Fold: 1  Epoch: 73  Training loss = 3.3621  Validation loss = 3.5996  \n",
      "\n",
      "Fold: 1  Epoch: 74  Training loss = 3.3598  Validation loss = 3.5955  \n",
      "\n",
      "Fold: 1  Epoch: 75  Training loss = 3.3581  Validation loss = 3.5925  \n",
      "\n",
      "Fold: 1  Epoch: 76  Training loss = 3.3560  Validation loss = 3.5887  \n",
      "\n",
      "Fold: 1  Epoch: 77  Training loss = 3.3538  Validation loss = 3.5848  \n",
      "\n",
      "Fold: 1  Epoch: 78  Training loss = 3.3517  Validation loss = 3.5811  \n",
      "\n",
      "Fold: 1  Epoch: 79  Training loss = 3.3496  Validation loss = 3.5773  \n",
      "\n",
      "Fold: 1  Epoch: 80  Training loss = 3.3474  Validation loss = 3.5734  \n",
      "\n",
      "Fold: 1  Epoch: 81  Training loss = 3.3452  Validation loss = 3.5695  \n",
      "\n",
      "Fold: 1  Epoch: 82  Training loss = 3.3430  Validation loss = 3.5654  \n",
      "\n",
      "Fold: 1  Epoch: 83  Training loss = 3.3403  Validation loss = 3.5608  \n",
      "\n",
      "Fold: 1  Epoch: 84  Training loss = 3.3383  Validation loss = 3.5570  \n",
      "\n",
      "Fold: 1  Epoch: 85  Training loss = 3.3357  Validation loss = 3.5524  \n",
      "\n",
      "Fold: 1  Epoch: 86  Training loss = 3.3331  Validation loss = 3.5480  \n",
      "\n",
      "Fold: 1  Epoch: 87  Training loss = 3.3313  Validation loss = 3.5447  \n",
      "\n",
      "Fold: 1  Epoch: 88  Training loss = 3.3291  Validation loss = 3.5407  \n",
      "\n",
      "Fold: 1  Epoch: 89  Training loss = 3.3269  Validation loss = 3.5368  \n",
      "\n",
      "Fold: 1  Epoch: 90  Training loss = 3.3251  Validation loss = 3.5336  \n",
      "\n",
      "Fold: 1  Epoch: 91  Training loss = 3.3230  Validation loss = 3.5298  \n",
      "\n",
      "Fold: 1  Epoch: 92  Training loss = 3.3209  Validation loss = 3.5259  \n",
      "\n",
      "Fold: 1  Epoch: 93  Training loss = 3.3186  Validation loss = 3.5216  \n",
      "\n",
      "Fold: 1  Epoch: 94  Training loss = 3.3163  Validation loss = 3.5173  \n",
      "\n",
      "Fold: 1  Epoch: 95  Training loss = 3.3143  Validation loss = 3.5135  \n",
      "\n",
      "Fold: 1  Epoch: 96  Training loss = 3.3127  Validation loss = 3.5104  \n",
      "\n",
      "Fold: 1  Epoch: 97  Training loss = 3.3106  Validation loss = 3.5067  \n",
      "\n",
      "Fold: 1  Epoch: 98  Training loss = 3.3085  Validation loss = 3.5027  \n",
      "\n",
      "Fold: 1  Epoch: 99  Training loss = 3.3068  Validation loss = 3.4995  \n",
      "\n",
      "Fold: 1  Epoch: 100  Training loss = 3.3047  Validation loss = 3.4956  \n",
      "\n",
      "Fold: 1  Epoch: 101  Training loss = 3.3024  Validation loss = 3.4916  \n",
      "\n",
      "Fold: 1  Epoch: 102  Training loss = 3.3003  Validation loss = 3.4877  \n",
      "\n",
      "Fold: 1  Epoch: 103  Training loss = 3.2984  Validation loss = 3.4843  \n",
      "\n",
      "Fold: 1  Epoch: 104  Training loss = 3.2964  Validation loss = 3.4807  \n",
      "\n",
      "Fold: 1  Epoch: 105  Training loss = 3.2947  Validation loss = 3.4774  \n",
      "\n",
      "Fold: 1  Epoch: 106  Training loss = 3.2929  Validation loss = 3.4740  \n",
      "\n",
      "Fold: 1  Epoch: 107  Training loss = 3.2913  Validation loss = 3.4708  \n",
      "\n",
      "Fold: 1  Epoch: 108  Training loss = 3.2892  Validation loss = 3.4671  \n",
      "\n",
      "Fold: 1  Epoch: 109  Training loss = 3.2873  Validation loss = 3.4635  \n",
      "\n",
      "Fold: 1  Epoch: 110  Training loss = 3.2853  Validation loss = 3.4597  \n",
      "\n",
      "Fold: 1  Epoch: 111  Training loss = 3.2834  Validation loss = 3.4561  \n",
      "\n",
      "Fold: 1  Epoch: 112  Training loss = 3.2813  Validation loss = 3.4523  \n",
      "\n",
      "Fold: 1  Epoch: 113  Training loss = 3.2792  Validation loss = 3.4483  \n",
      "\n",
      "Fold: 1  Epoch: 114  Training loss = 3.2776  Validation loss = 3.4452  \n",
      "\n",
      "Fold: 1  Epoch: 115  Training loss = 3.2756  Validation loss = 3.4414  \n",
      "\n",
      "Fold: 1  Epoch: 116  Training loss = 3.2733  Validation loss = 3.4374  \n",
      "\n",
      "Fold: 1  Epoch: 117  Training loss = 3.2716  Validation loss = 3.4341  \n",
      "\n",
      "Fold: 1  Epoch: 118  Training loss = 3.2696  Validation loss = 3.4304  \n",
      "\n",
      "Fold: 1  Epoch: 119  Training loss = 3.2675  Validation loss = 3.4266  \n",
      "\n",
      "Fold: 1  Epoch: 120  Training loss = 3.2658  Validation loss = 3.4233  \n",
      "\n",
      "Fold: 1  Epoch: 121  Training loss = 3.2635  Validation loss = 3.4192  \n",
      "\n",
      "Fold: 1  Epoch: 122  Training loss = 3.2618  Validation loss = 3.4160  \n",
      "\n",
      "Fold: 1  Epoch: 123  Training loss = 3.2597  Validation loss = 3.4120  \n",
      "\n",
      "Fold: 1  Epoch: 124  Training loss = 3.2572  Validation loss = 3.4074  \n",
      "\n",
      "Fold: 1  Epoch: 125  Training loss = 3.2551  Validation loss = 3.4034  \n",
      "\n",
      "Fold: 1  Epoch: 126  Training loss = 3.2530  Validation loss = 3.3996  \n",
      "\n",
      "Fold: 1  Epoch: 127  Training loss = 3.2500  Validation loss = 3.3940  \n",
      "\n",
      "Fold: 1  Epoch: 128  Training loss = 3.2478  Validation loss = 3.3898  \n",
      "\n",
      "Fold: 1  Epoch: 129  Training loss = 3.2458  Validation loss = 3.3861  \n",
      "\n",
      "Fold: 1  Epoch: 130  Training loss = 3.2434  Validation loss = 3.3816  \n",
      "\n",
      "Fold: 1  Epoch: 131  Training loss = 3.2420  Validation loss = 3.3789  \n",
      "\n",
      "Fold: 1  Epoch: 132  Training loss = 3.2400  Validation loss = 3.3752  \n",
      "\n",
      "Fold: 1  Epoch: 133  Training loss = 3.2381  Validation loss = 3.3716  \n",
      "\n",
      "Fold: 1  Epoch: 134  Training loss = 3.2368  Validation loss = 3.3690  \n",
      "\n",
      "Fold: 1  Epoch: 135  Training loss = 3.2347  Validation loss = 3.3649  \n",
      "\n",
      "Fold: 1  Epoch: 136  Training loss = 3.2325  Validation loss = 3.3608  \n",
      "\n",
      "Fold: 1  Epoch: 137  Training loss = 3.2309  Validation loss = 3.3576  \n",
      "\n",
      "Fold: 1  Epoch: 138  Training loss = 3.2288  Validation loss = 3.3534  \n",
      "\n",
      "Fold: 1  Epoch: 139  Training loss = 3.2273  Validation loss = 3.3506  \n",
      "\n",
      "Fold: 1  Epoch: 140  Training loss = 3.2257  Validation loss = 3.3475  \n",
      "\n",
      "Fold: 1  Epoch: 141  Training loss = 3.2239  Validation loss = 3.3441  \n",
      "\n",
      "Fold: 1  Epoch: 142  Training loss = 3.2226  Validation loss = 3.3416  \n",
      "\n",
      "Fold: 1  Epoch: 143  Training loss = 3.2205  Validation loss = 3.3375  \n",
      "\n",
      "Fold: 1  Epoch: 144  Training loss = 3.2187  Validation loss = 3.3340  \n",
      "\n",
      "Fold: 1  Epoch: 145  Training loss = 3.2167  Validation loss = 3.3301  \n",
      "\n",
      "Fold: 1  Epoch: 146  Training loss = 3.2147  Validation loss = 3.3263  \n",
      "\n",
      "Fold: 1  Epoch: 147  Training loss = 3.2122  Validation loss = 3.3216  \n",
      "\n",
      "Fold: 1  Epoch: 148  Training loss = 3.2101  Validation loss = 3.3175  \n",
      "\n",
      "Fold: 1  Epoch: 149  Training loss = 3.2086  Validation loss = 3.3144  \n",
      "\n",
      "Fold: 1  Epoch: 150  Training loss = 3.2065  Validation loss = 3.3106  \n",
      "\n",
      "Fold: 1  Epoch: 151  Training loss = 3.2047  Validation loss = 3.3071  \n",
      "\n",
      "Fold: 1  Epoch: 152  Training loss = 3.2032  Validation loss = 3.3042  \n",
      "\n",
      "Fold: 1  Epoch: 153  Training loss = 3.2013  Validation loss = 3.3008  \n",
      "\n",
      "Fold: 1  Epoch: 154  Training loss = 3.1996  Validation loss = 3.2974  \n",
      "\n",
      "Fold: 1  Epoch: 155  Training loss = 3.1978  Validation loss = 3.2940  \n",
      "\n",
      "Fold: 1  Epoch: 156  Training loss = 3.1961  Validation loss = 3.2906  \n",
      "\n",
      "Fold: 1  Epoch: 157  Training loss = 3.1939  Validation loss = 3.2865  \n",
      "\n",
      "Fold: 1  Epoch: 158  Training loss = 3.1920  Validation loss = 3.2827  \n",
      "\n",
      "Fold: 1  Epoch: 159  Training loss = 3.1900  Validation loss = 3.2790  \n",
      "\n",
      "Fold: 1  Epoch: 160  Training loss = 3.1882  Validation loss = 3.2756  \n",
      "\n",
      "Fold: 1  Epoch: 161  Training loss = 3.1863  Validation loss = 3.2720  \n",
      "\n",
      "Fold: 1  Epoch: 162  Training loss = 3.1842  Validation loss = 3.2679  \n",
      "\n",
      "Fold: 1  Epoch: 163  Training loss = 3.1828  Validation loss = 3.2651  \n",
      "\n",
      "Fold: 1  Epoch: 164  Training loss = 3.1810  Validation loss = 3.2616  \n",
      "\n",
      "Fold: 1  Epoch: 165  Training loss = 3.1790  Validation loss = 3.2578  \n",
      "\n",
      "Fold: 1  Epoch: 166  Training loss = 3.1763  Validation loss = 3.2528  \n",
      "\n",
      "Fold: 1  Epoch: 167  Training loss = 3.1750  Validation loss = 3.2502  \n",
      "\n",
      "Fold: 1  Epoch: 168  Training loss = 3.1733  Validation loss = 3.2469  \n",
      "\n",
      "Fold: 1  Epoch: 169  Training loss = 3.1715  Validation loss = 3.2432  \n",
      "\n",
      "Fold: 1  Epoch: 170  Training loss = 3.1698  Validation loss = 3.2401  \n",
      "\n",
      "Fold: 1  Epoch: 171  Training loss = 3.1684  Validation loss = 3.2373  \n",
      "\n",
      "Fold: 1  Epoch: 172  Training loss = 3.1667  Validation loss = 3.2338  \n",
      "\n",
      "Fold: 1  Epoch: 173  Training loss = 3.1649  Validation loss = 3.2306  \n",
      "\n",
      "Fold: 1  Epoch: 174  Training loss = 3.1630  Validation loss = 3.2268  \n",
      "\n",
      "Fold: 1  Epoch: 175  Training loss = 3.1612  Validation loss = 3.2234  \n",
      "\n",
      "Fold: 1  Epoch: 176  Training loss = 3.1595  Validation loss = 3.2201  \n",
      "\n",
      "Fold: 1  Epoch: 177  Training loss = 3.1574  Validation loss = 3.2161  \n",
      "\n",
      "Fold: 1  Epoch: 178  Training loss = 3.1558  Validation loss = 3.2129  \n",
      "\n",
      "Fold: 1  Epoch: 179  Training loss = 3.1544  Validation loss = 3.2101  \n",
      "\n",
      "Fold: 1  Epoch: 180  Training loss = 3.1528  Validation loss = 3.2071  \n",
      "\n",
      "Fold: 1  Epoch: 181  Training loss = 3.1508  Validation loss = 3.2032  \n",
      "\n",
      "Fold: 1  Epoch: 182  Training loss = 3.1489  Validation loss = 3.1996  \n",
      "\n",
      "Fold: 1  Epoch: 183  Training loss = 3.1476  Validation loss = 3.1969  \n",
      "\n",
      "Fold: 1  Epoch: 184  Training loss = 3.1457  Validation loss = 3.1932  \n",
      "\n",
      "Fold: 1  Epoch: 185  Training loss = 3.1439  Validation loss = 3.1897  \n",
      "\n",
      "Fold: 1  Epoch: 186  Training loss = 3.1421  Validation loss = 3.1864  \n",
      "\n",
      "Fold: 1  Epoch: 187  Training loss = 3.1406  Validation loss = 3.1833  \n",
      "\n",
      "Fold: 1  Epoch: 188  Training loss = 3.1387  Validation loss = 3.1797  \n",
      "\n",
      "Fold: 1  Epoch: 189  Training loss = 3.1372  Validation loss = 3.1767  \n",
      "\n",
      "Fold: 1  Epoch: 190  Training loss = 3.1357  Validation loss = 3.1738  \n",
      "\n",
      "Fold: 1  Epoch: 191  Training loss = 3.1340  Validation loss = 3.1704  \n",
      "\n",
      "Fold: 1  Epoch: 192  Training loss = 3.1322  Validation loss = 3.1670  \n",
      "\n",
      "Fold: 1  Epoch: 193  Training loss = 3.1304  Validation loss = 3.1636  \n",
      "\n",
      "Fold: 1  Epoch: 194  Training loss = 3.1287  Validation loss = 3.1602  \n",
      "\n",
      "Fold: 1  Epoch: 195  Training loss = 3.1274  Validation loss = 3.1576  \n",
      "\n",
      "Fold: 1  Epoch: 196  Training loss = 3.1251  Validation loss = 3.1533  \n",
      "\n",
      "Fold: 1  Epoch: 197  Training loss = 3.1237  Validation loss = 3.1504  \n",
      "\n",
      "Fold: 1  Epoch: 198  Training loss = 3.1217  Validation loss = 3.1465  \n",
      "\n",
      "Fold: 1  Epoch: 199  Training loss = 3.1203  Validation loss = 3.1438  \n",
      "\n",
      "Fold: 1  Epoch: 200  Training loss = 3.1189  Validation loss = 3.1410  \n",
      "\n",
      "Fold: 1  Epoch: 201  Training loss = 3.1162  Validation loss = 3.1360  \n",
      "\n",
      "Fold: 1  Epoch: 202  Training loss = 3.1143  Validation loss = 3.1323  \n",
      "\n",
      "Fold: 1  Epoch: 203  Training loss = 3.1126  Validation loss = 3.1291  \n",
      "\n",
      "Fold: 1  Epoch: 204  Training loss = 3.1111  Validation loss = 3.1263  \n",
      "\n",
      "Fold: 1  Epoch: 205  Training loss = 3.1094  Validation loss = 3.1229  \n",
      "\n",
      "Fold: 1  Epoch: 206  Training loss = 3.1074  Validation loss = 3.1190  \n",
      "\n",
      "Fold: 1  Epoch: 207  Training loss = 3.1058  Validation loss = 3.1160  \n",
      "\n",
      "Fold: 1  Epoch: 208  Training loss = 3.1036  Validation loss = 3.1119  \n",
      "\n",
      "Fold: 1  Epoch: 209  Training loss = 3.1017  Validation loss = 3.1082  \n",
      "\n",
      "Fold: 1  Epoch: 210  Training loss = 3.1001  Validation loss = 3.1053  \n",
      "\n",
      "Fold: 1  Epoch: 211  Training loss = 3.0994  Validation loss = 3.1038  \n",
      "\n",
      "Fold: 1  Epoch: 212  Training loss = 3.0976  Validation loss = 3.1003  \n",
      "\n",
      "Fold: 1  Epoch: 213  Training loss = 3.0960  Validation loss = 3.0971  \n",
      "\n",
      "Fold: 1  Epoch: 214  Training loss = 3.0948  Validation loss = 3.0949  \n",
      "\n",
      "Fold: 1  Epoch: 215  Training loss = 3.0932  Validation loss = 3.0919  \n",
      "\n",
      "Fold: 1  Epoch: 216  Training loss = 3.0915  Validation loss = 3.0885  \n",
      "\n",
      "Fold: 1  Epoch: 217  Training loss = 3.0900  Validation loss = 3.0855  \n",
      "\n",
      "Fold: 1  Epoch: 218  Training loss = 3.0884  Validation loss = 3.0824  \n",
      "\n",
      "Fold: 1  Epoch: 219  Training loss = 3.0871  Validation loss = 3.0799  \n",
      "\n",
      "Fold: 1  Epoch: 220  Training loss = 3.0860  Validation loss = 3.0778  \n",
      "\n",
      "Fold: 1  Epoch: 221  Training loss = 3.0851  Validation loss = 3.0759  \n",
      "\n",
      "Fold: 1  Epoch: 222  Training loss = 3.0831  Validation loss = 3.0721  \n",
      "\n",
      "Fold: 1  Epoch: 223  Training loss = 3.0816  Validation loss = 3.0690  \n",
      "\n",
      "Fold: 1  Epoch: 224  Training loss = 3.0797  Validation loss = 3.0654  \n",
      "\n",
      "Fold: 1  Epoch: 225  Training loss = 3.0782  Validation loss = 3.0625  \n",
      "\n",
      "Fold: 1  Epoch: 226  Training loss = 3.0768  Validation loss = 3.0597  \n",
      "\n",
      "Fold: 1  Epoch: 227  Training loss = 3.0754  Validation loss = 3.0569  \n",
      "\n",
      "Fold: 1  Epoch: 228  Training loss = 3.0740  Validation loss = 3.0542  \n",
      "\n",
      "Fold: 1  Epoch: 229  Training loss = 3.0728  Validation loss = 3.0520  \n",
      "\n",
      "Fold: 1  Epoch: 230  Training loss = 3.0718  Validation loss = 3.0499  \n",
      "\n",
      "Fold: 1  Epoch: 231  Training loss = 3.0706  Validation loss = 3.0476  \n",
      "\n",
      "Fold: 1  Epoch: 232  Training loss = 3.0690  Validation loss = 3.0444  \n",
      "\n",
      "Fold: 1  Epoch: 233  Training loss = 3.0672  Validation loss = 3.0409  \n",
      "\n",
      "Fold: 1  Epoch: 234  Training loss = 3.0654  Validation loss = 3.0375  \n",
      "\n",
      "Fold: 1  Epoch: 235  Training loss = 3.0639  Validation loss = 3.0346  \n",
      "\n",
      "Fold: 1  Epoch: 236  Training loss = 3.0626  Validation loss = 3.0321  \n",
      "\n",
      "Fold: 1  Epoch: 237  Training loss = 3.0611  Validation loss = 3.0294  \n",
      "\n",
      "Fold: 1  Epoch: 238  Training loss = 3.0599  Validation loss = 3.0269  \n",
      "\n",
      "Fold: 1  Epoch: 239  Training loss = 3.0576  Validation loss = 3.0226  \n",
      "\n",
      "Fold: 1  Epoch: 240  Training loss = 3.0559  Validation loss = 3.0193  \n",
      "\n",
      "Fold: 1  Epoch: 241  Training loss = 3.0547  Validation loss = 3.0170  \n",
      "\n",
      "Fold: 1  Epoch: 242  Training loss = 3.0527  Validation loss = 3.0131  \n",
      "\n",
      "Fold: 1  Epoch: 243  Training loss = 3.0514  Validation loss = 3.0105  \n",
      "\n",
      "Fold: 1  Epoch: 244  Training loss = 3.0493  Validation loss = 3.0067  \n",
      "\n",
      "Fold: 1  Epoch: 245  Training loss = 3.0477  Validation loss = 3.0036  \n",
      "\n",
      "Fold: 1  Epoch: 246  Training loss = 3.0459  Validation loss = 3.0001  \n",
      "\n",
      "Fold: 1  Epoch: 247  Training loss = 3.0446  Validation loss = 2.9975  \n",
      "\n",
      "Fold: 1  Epoch: 248  Training loss = 3.0429  Validation loss = 2.9942  \n",
      "\n",
      "Fold: 1  Epoch: 249  Training loss = 3.0415  Validation loss = 2.9915  \n",
      "\n",
      "Fold: 1  Epoch: 250  Training loss = 3.0400  Validation loss = 2.9886  \n",
      "\n",
      "Fold: 1  Epoch: 251  Training loss = 3.0386  Validation loss = 2.9859  \n",
      "\n",
      "Fold: 1  Epoch: 252  Training loss = 3.0366  Validation loss = 2.9822  \n",
      "\n",
      "Fold: 1  Epoch: 253  Training loss = 3.0348  Validation loss = 2.9788  \n",
      "\n",
      "Fold: 1  Epoch: 254  Training loss = 3.0332  Validation loss = 2.9757  \n",
      "\n",
      "Fold: 1  Epoch: 255  Training loss = 3.0320  Validation loss = 2.9734  \n",
      "\n",
      "Fold: 1  Epoch: 256  Training loss = 3.0303  Validation loss = 2.9701  \n",
      "\n",
      "Fold: 1  Epoch: 257  Training loss = 3.0291  Validation loss = 2.9677  \n",
      "\n",
      "Fold: 1  Epoch: 258  Training loss = 3.0282  Validation loss = 2.9660  \n",
      "\n",
      "Fold: 1  Epoch: 259  Training loss = 3.0270  Validation loss = 2.9635  \n",
      "\n",
      "Fold: 1  Epoch: 260  Training loss = 3.0256  Validation loss = 2.9608  \n",
      "\n",
      "Fold: 1  Epoch: 261  Training loss = 3.0246  Validation loss = 2.9588  \n",
      "\n",
      "Fold: 1  Epoch: 262  Training loss = 3.0233  Validation loss = 2.9561  \n",
      "\n",
      "Fold: 1  Epoch: 263  Training loss = 3.0224  Validation loss = 2.9543  \n",
      "\n",
      "Fold: 1  Epoch: 264  Training loss = 3.0210  Validation loss = 2.9516  \n",
      "\n",
      "Fold: 1  Epoch: 265  Training loss = 3.0202  Validation loss = 2.9499  \n",
      "\n",
      "Fold: 1  Epoch: 266  Training loss = 3.0191  Validation loss = 2.9477  \n",
      "\n",
      "Fold: 1  Epoch: 267  Training loss = 3.0179  Validation loss = 2.9454  \n",
      "\n",
      "Fold: 1  Epoch: 268  Training loss = 3.0168  Validation loss = 2.9434  \n",
      "\n",
      "Fold: 1  Epoch: 269  Training loss = 3.0158  Validation loss = 2.9413  \n",
      "\n",
      "Fold: 1  Epoch: 270  Training loss = 3.0143  Validation loss = 2.9383  \n",
      "\n",
      "Fold: 1  Epoch: 271  Training loss = 3.0131  Validation loss = 2.9358  \n",
      "\n",
      "Fold: 1  Epoch: 272  Training loss = 3.0122  Validation loss = 2.9341  \n",
      "\n",
      "Fold: 1  Epoch: 273  Training loss = 3.0108  Validation loss = 2.9314  \n",
      "\n",
      "Fold: 1  Epoch: 274  Training loss = 3.0094  Validation loss = 2.9286  \n",
      "\n",
      "Fold: 1  Epoch: 275  Training loss = 3.0077  Validation loss = 2.9254  \n",
      "\n",
      "Fold: 1  Epoch: 276  Training loss = 3.0059  Validation loss = 2.9219  \n",
      "\n",
      "Fold: 1  Epoch: 277  Training loss = 3.0045  Validation loss = 2.9192  \n",
      "\n",
      "Fold: 1  Epoch: 278  Training loss = 3.0028  Validation loss = 2.9159  \n",
      "\n",
      "Fold: 1  Epoch: 279  Training loss = 3.0018  Validation loss = 2.9138  \n",
      "\n",
      "Fold: 1  Epoch: 280  Training loss = 3.0007  Validation loss = 2.9118  \n",
      "\n",
      "Fold: 1  Epoch: 281  Training loss = 3.0000  Validation loss = 2.9102  \n",
      "\n",
      "Fold: 1  Epoch: 282  Training loss = 2.9987  Validation loss = 2.9076  \n",
      "\n",
      "Fold: 1  Epoch: 283  Training loss = 2.9974  Validation loss = 2.9050  \n",
      "\n",
      "Fold: 1  Epoch: 284  Training loss = 2.9962  Validation loss = 2.9025  \n",
      "\n",
      "Fold: 1  Epoch: 285  Training loss = 2.9952  Validation loss = 2.9005  \n",
      "\n",
      "Fold: 1  Epoch: 286  Training loss = 2.9936  Validation loss = 2.8975  \n",
      "\n",
      "Fold: 1  Epoch: 287  Training loss = 2.9928  Validation loss = 2.8958  \n",
      "\n",
      "Fold: 1  Epoch: 288  Training loss = 2.9914  Validation loss = 2.8932  \n",
      "\n",
      "Fold: 1  Epoch: 289  Training loss = 2.9901  Validation loss = 2.8907  \n",
      "\n",
      "Fold: 1  Epoch: 290  Training loss = 2.9886  Validation loss = 2.8877  \n",
      "\n",
      "Fold: 1  Epoch: 291  Training loss = 2.9871  Validation loss = 2.8848  \n",
      "\n",
      "Fold: 1  Epoch: 292  Training loss = 2.9861  Validation loss = 2.8827  \n",
      "\n",
      "Fold: 1  Epoch: 293  Training loss = 2.9850  Validation loss = 2.8805  \n",
      "\n",
      "Fold: 1  Epoch: 294  Training loss = 2.9835  Validation loss = 2.8775  \n",
      "\n",
      "Fold: 1  Epoch: 295  Training loss = 2.9824  Validation loss = 2.8752  \n",
      "\n",
      "Fold: 1  Epoch: 296  Training loss = 2.9815  Validation loss = 2.8733  \n",
      "\n",
      "Fold: 1  Epoch: 297  Training loss = 2.9797  Validation loss = 2.8699  \n",
      "\n",
      "Fold: 1  Epoch: 298  Training loss = 2.9784  Validation loss = 2.8675  \n",
      "\n",
      "Fold: 1  Epoch: 299  Training loss = 2.9770  Validation loss = 2.8647  \n",
      "\n",
      "Fold: 1  Epoch: 300  Training loss = 2.9758  Validation loss = 2.8624  \n",
      "\n",
      "Fold: 1  Epoch: 301  Training loss = 2.9749  Validation loss = 2.8604  \n",
      "\n",
      "Fold: 1  Epoch: 302  Training loss = 2.9740  Validation loss = 2.8587  \n",
      "\n",
      "Fold: 1  Epoch: 303  Training loss = 2.9731  Validation loss = 2.8567  \n",
      "\n",
      "Fold: 1  Epoch: 304  Training loss = 2.9719  Validation loss = 2.8543  \n",
      "\n",
      "Fold: 1  Epoch: 305  Training loss = 2.9708  Validation loss = 2.8521  \n",
      "\n",
      "Fold: 1  Epoch: 306  Training loss = 2.9693  Validation loss = 2.8491  \n",
      "\n",
      "Fold: 1  Epoch: 307  Training loss = 2.9681  Validation loss = 2.8467  \n",
      "\n",
      "Fold: 1  Epoch: 308  Training loss = 2.9673  Validation loss = 2.8449  \n",
      "\n",
      "Fold: 1  Epoch: 309  Training loss = 2.9663  Validation loss = 2.8427  \n",
      "\n",
      "Fold: 1  Epoch: 310  Training loss = 2.9649  Validation loss = 2.8400  \n",
      "\n",
      "Fold: 1  Epoch: 311  Training loss = 2.9639  Validation loss = 2.8380  \n",
      "\n",
      "Fold: 1  Epoch: 312  Training loss = 2.9627  Validation loss = 2.8356  \n",
      "\n",
      "Fold: 1  Epoch: 313  Training loss = 2.9615  Validation loss = 2.8330  \n",
      "\n",
      "Fold: 1  Epoch: 314  Training loss = 2.9598  Validation loss = 2.8296  \n",
      "\n",
      "Fold: 1  Epoch: 315  Training loss = 2.9582  Validation loss = 2.8265  \n",
      "\n",
      "Fold: 1  Epoch: 316  Training loss = 2.9567  Validation loss = 2.8234  \n",
      "\n",
      "Fold: 1  Epoch: 317  Training loss = 2.9558  Validation loss = 2.8215  \n",
      "\n",
      "Fold: 1  Epoch: 318  Training loss = 2.9543  Validation loss = 2.8185  \n",
      "\n",
      "Fold: 1  Epoch: 319  Training loss = 2.9530  Validation loss = 2.8158  \n",
      "\n",
      "Fold: 1  Epoch: 320  Training loss = 2.9517  Validation loss = 2.8132  \n",
      "\n",
      "Fold: 1  Epoch: 321  Training loss = 2.9507  Validation loss = 2.8110  \n",
      "\n",
      "Fold: 1  Epoch: 322  Training loss = 2.9494  Validation loss = 2.8083  \n",
      "\n",
      "Fold: 1  Epoch: 323  Training loss = 2.9482  Validation loss = 2.8060  \n",
      "\n",
      "Fold: 1  Epoch: 324  Training loss = 2.9473  Validation loss = 2.8038  \n",
      "\n",
      "Fold: 1  Epoch: 325  Training loss = 2.9461  Validation loss = 2.8015  \n",
      "\n",
      "Fold: 1  Epoch: 326  Training loss = 2.9451  Validation loss = 2.7994  \n",
      "\n",
      "Fold: 1  Epoch: 327  Training loss = 2.9442  Validation loss = 2.7976  \n",
      "\n",
      "Fold: 1  Epoch: 328  Training loss = 2.9432  Validation loss = 2.7953  \n",
      "\n",
      "Fold: 1  Epoch: 329  Training loss = 2.9422  Validation loss = 2.7934  \n",
      "\n",
      "Fold: 1  Epoch: 330  Training loss = 2.9411  Validation loss = 2.7910  \n",
      "\n",
      "Fold: 1  Epoch: 331  Training loss = 2.9401  Validation loss = 2.7888  \n",
      "\n",
      "Fold: 1  Epoch: 332  Training loss = 2.9387  Validation loss = 2.7860  \n",
      "\n",
      "Fold: 1  Epoch: 333  Training loss = 2.9379  Validation loss = 2.7844  \n",
      "\n",
      "Fold: 1  Epoch: 334  Training loss = 2.9371  Validation loss = 2.7825  \n",
      "\n",
      "Fold: 1  Epoch: 335  Training loss = 2.9362  Validation loss = 2.7807  \n",
      "\n",
      "Fold: 1  Epoch: 336  Training loss = 2.9351  Validation loss = 2.7783  \n",
      "\n",
      "Fold: 1  Epoch: 337  Training loss = 2.9339  Validation loss = 2.7760  \n",
      "\n",
      "Fold: 1  Epoch: 338  Training loss = 2.9328  Validation loss = 2.7734  \n",
      "\n",
      "Fold: 1  Epoch: 339  Training loss = 2.9320  Validation loss = 2.7718  \n",
      "\n",
      "Fold: 1  Epoch: 340  Training loss = 2.9310  Validation loss = 2.7696  \n",
      "\n",
      "Fold: 1  Epoch: 341  Training loss = 2.9303  Validation loss = 2.7681  \n",
      "\n",
      "Fold: 1  Epoch: 342  Training loss = 2.9293  Validation loss = 2.7657  \n",
      "\n",
      "Fold: 1  Epoch: 343  Training loss = 2.9282  Validation loss = 2.7634  \n",
      "\n",
      "Fold: 1  Epoch: 344  Training loss = 2.9271  Validation loss = 2.7612  \n",
      "\n",
      "Fold: 1  Epoch: 345  Training loss = 2.9261  Validation loss = 2.7590  \n",
      "\n",
      "Fold: 1  Epoch: 346  Training loss = 2.9253  Validation loss = 2.7571  \n",
      "\n",
      "Fold: 1  Epoch: 347  Training loss = 2.9242  Validation loss = 2.7547  \n",
      "\n",
      "Fold: 1  Epoch: 348  Training loss = 2.9233  Validation loss = 2.7528  \n",
      "\n",
      "Fold: 1  Epoch: 349  Training loss = 2.9221  Validation loss = 2.7503  \n",
      "\n",
      "Fold: 1  Epoch: 350  Training loss = 2.9205  Validation loss = 2.7468  \n",
      "\n",
      "Fold: 1  Epoch: 351  Training loss = 2.9195  Validation loss = 2.7445  \n",
      "\n",
      "Fold: 1  Epoch: 352  Training loss = 2.9188  Validation loss = 2.7429  \n",
      "\n",
      "Fold: 1  Epoch: 353  Training loss = 2.9173  Validation loss = 2.7397  \n",
      "\n",
      "Fold: 1  Epoch: 354  Training loss = 2.9164  Validation loss = 2.7377  \n",
      "\n",
      "Fold: 1  Epoch: 355  Training loss = 2.9154  Validation loss = 2.7356  \n",
      "\n",
      "Fold: 1  Epoch: 356  Training loss = 2.9140  Validation loss = 2.7326  \n",
      "\n",
      "Fold: 1  Epoch: 357  Training loss = 2.9133  Validation loss = 2.7310  \n",
      "\n",
      "Fold: 1  Epoch: 358  Training loss = 2.9122  Validation loss = 2.7287  \n",
      "\n",
      "Fold: 1  Epoch: 359  Training loss = 2.9113  Validation loss = 2.7269  \n",
      "\n",
      "Fold: 1  Epoch: 360  Training loss = 2.9104  Validation loss = 2.7247  \n",
      "\n",
      "Fold: 1  Epoch: 361  Training loss = 2.9093  Validation loss = 2.7224  \n",
      "\n",
      "Fold: 1  Epoch: 362  Training loss = 2.9086  Validation loss = 2.7207  \n",
      "\n",
      "Fold: 1  Epoch: 363  Training loss = 2.9078  Validation loss = 2.7190  \n",
      "\n",
      "Fold: 1  Epoch: 364  Training loss = 2.9071  Validation loss = 2.7175  \n",
      "\n",
      "Fold: 1  Epoch: 365  Training loss = 2.9061  Validation loss = 2.7154  \n",
      "\n",
      "Fold: 1  Epoch: 366  Training loss = 2.9051  Validation loss = 2.7132  \n",
      "\n",
      "Fold: 1  Epoch: 367  Training loss = 2.9043  Validation loss = 2.7113  \n",
      "\n",
      "Fold: 1  Epoch: 368  Training loss = 2.9038  Validation loss = 2.7100  \n",
      "\n",
      "Fold: 1  Epoch: 369  Training loss = 2.9029  Validation loss = 2.7081  \n",
      "\n",
      "Fold: 1  Epoch: 370  Training loss = 2.9022  Validation loss = 2.7065  \n",
      "\n",
      "Fold: 1  Epoch: 371  Training loss = 2.9016  Validation loss = 2.7052  \n",
      "\n",
      "Fold: 1  Epoch: 372  Training loss = 2.9008  Validation loss = 2.7032  \n",
      "\n",
      "Fold: 1  Epoch: 373  Training loss = 2.9001  Validation loss = 2.7017  \n",
      "\n",
      "Fold: 1  Epoch: 374  Training loss = 2.8992  Validation loss = 2.6996  \n",
      "\n",
      "Fold: 1  Epoch: 375  Training loss = 2.8983  Validation loss = 2.6975  \n",
      "\n",
      "Fold: 1  Epoch: 376  Training loss = 2.8974  Validation loss = 2.6956  \n",
      "\n",
      "Fold: 1  Epoch: 377  Training loss = 2.8969  Validation loss = 2.6942  \n",
      "\n",
      "Fold: 1  Epoch: 378  Training loss = 2.8961  Validation loss = 2.6925  \n",
      "\n",
      "Fold: 1  Epoch: 379  Training loss = 2.8954  Validation loss = 2.6909  \n",
      "\n",
      "Fold: 1  Epoch: 380  Training loss = 2.8949  Validation loss = 2.6897  \n",
      "\n",
      "Fold: 1  Epoch: 381  Training loss = 2.8941  Validation loss = 2.6880  \n",
      "\n",
      "Fold: 1  Epoch: 382  Training loss = 2.8927  Validation loss = 2.6851  \n",
      "\n",
      "Fold: 1  Epoch: 383  Training loss = 2.8914  Validation loss = 2.6822  \n",
      "\n",
      "Fold: 1  Epoch: 384  Training loss = 2.8906  Validation loss = 2.6803  \n",
      "\n",
      "Fold: 1  Epoch: 385  Training loss = 2.8895  Validation loss = 2.6778  \n",
      "\n",
      "Fold: 1  Epoch: 386  Training loss = 2.8886  Validation loss = 2.6760  \n",
      "\n",
      "Fold: 1  Epoch: 387  Training loss = 2.8879  Validation loss = 2.6744  \n",
      "\n",
      "Fold: 1  Epoch: 388  Training loss = 2.8872  Validation loss = 2.6727  \n",
      "\n",
      "Fold: 1  Epoch: 389  Training loss = 2.8868  Validation loss = 2.6718  \n",
      "\n",
      "Fold: 1  Epoch: 390  Training loss = 2.8863  Validation loss = 2.6704  \n",
      "\n",
      "Fold: 1  Epoch: 391  Training loss = 2.8851  Validation loss = 2.6678  \n",
      "\n",
      "Fold: 1  Epoch: 392  Training loss = 2.8843  Validation loss = 2.6660  \n",
      "\n",
      "Fold: 1  Epoch: 393  Training loss = 2.8833  Validation loss = 2.6639  \n",
      "\n",
      "Fold: 1  Epoch: 394  Training loss = 2.8827  Validation loss = 2.6623  \n",
      "\n",
      "Fold: 1  Epoch: 395  Training loss = 2.8821  Validation loss = 2.6612  \n",
      "\n",
      "Fold: 1  Epoch: 396  Training loss = 2.8814  Validation loss = 2.6594  \n",
      "\n",
      "Fold: 1  Epoch: 397  Training loss = 2.8807  Validation loss = 2.6577  \n",
      "\n",
      "Fold: 1  Epoch: 398  Training loss = 2.8796  Validation loss = 2.6553  \n",
      "\n",
      "Fold: 1  Epoch: 399  Training loss = 2.8790  Validation loss = 2.6538  \n",
      "\n",
      "Fold: 1  Epoch: 400  Training loss = 2.8778  Validation loss = 2.6510  \n",
      "\n",
      "Fold: 1  Epoch: 401  Training loss = 2.8774  Validation loss = 2.6502  \n",
      "\n",
      "Fold: 1  Epoch: 402  Training loss = 2.8765  Validation loss = 2.6480  \n",
      "\n",
      "Fold: 1  Epoch: 403  Training loss = 2.8761  Validation loss = 2.6471  \n",
      "\n",
      "Fold: 1  Epoch: 404  Training loss = 2.8756  Validation loss = 2.6460  \n",
      "\n",
      "Fold: 1  Epoch: 405  Training loss = 2.8744  Validation loss = 2.6433  \n",
      "\n",
      "Fold: 1  Epoch: 406  Training loss = 2.8737  Validation loss = 2.6415  \n",
      "\n",
      "Fold: 1  Epoch: 407  Training loss = 2.8727  Validation loss = 2.6391  \n",
      "\n",
      "Fold: 1  Epoch: 408  Training loss = 2.8721  Validation loss = 2.6378  \n",
      "\n",
      "Fold: 1  Epoch: 409  Training loss = 2.8710  Validation loss = 2.6352  \n",
      "\n",
      "Fold: 1  Epoch: 410  Training loss = 2.8705  Validation loss = 2.6339  \n",
      "\n",
      "Fold: 1  Epoch: 411  Training loss = 2.8698  Validation loss = 2.6324  \n",
      "\n",
      "Fold: 1  Epoch: 412  Training loss = 2.8692  Validation loss = 2.6308  \n",
      "\n",
      "Fold: 1  Epoch: 413  Training loss = 2.8686  Validation loss = 2.6294  \n",
      "\n",
      "Fold: 1  Epoch: 414  Training loss = 2.8678  Validation loss = 2.6276  \n",
      "\n",
      "Fold: 1  Epoch: 415  Training loss = 2.8674  Validation loss = 2.6265  \n",
      "\n",
      "Fold: 1  Epoch: 416  Training loss = 2.8668  Validation loss = 2.6249  \n",
      "\n",
      "Fold: 1  Epoch: 417  Training loss = 2.8659  Validation loss = 2.6230  \n",
      "\n",
      "Fold: 1  Epoch: 418  Training loss = 2.8650  Validation loss = 2.6209  \n",
      "\n",
      "Fold: 1  Epoch: 419  Training loss = 2.8640  Validation loss = 2.6186  \n",
      "\n",
      "Fold: 1  Epoch: 420  Training loss = 2.8635  Validation loss = 2.6172  \n",
      "\n",
      "Fold: 1  Epoch: 421  Training loss = 2.8627  Validation loss = 2.6155  \n",
      "\n",
      "Fold: 1  Epoch: 422  Training loss = 2.8622  Validation loss = 2.6142  \n",
      "\n",
      "Fold: 1  Epoch: 423  Training loss = 2.8615  Validation loss = 2.6126  \n",
      "\n",
      "Fold: 1  Epoch: 424  Training loss = 2.8609  Validation loss = 2.6113  \n",
      "\n",
      "Fold: 1  Epoch: 425  Training loss = 2.8600  Validation loss = 2.6093  \n",
      "\n",
      "Fold: 1  Epoch: 426  Training loss = 2.8592  Validation loss = 2.6072  \n",
      "\n",
      "Fold: 1  Epoch: 427  Training loss = 2.8587  Validation loss = 2.6061  \n",
      "\n",
      "Fold: 1  Epoch: 428  Training loss = 2.8582  Validation loss = 2.6048  \n",
      "\n",
      "Fold: 1  Epoch: 429  Training loss = 2.8576  Validation loss = 2.6034  \n",
      "\n",
      "Fold: 1  Epoch: 430  Training loss = 2.8566  Validation loss = 2.6011  \n",
      "\n",
      "Fold: 1  Epoch: 431  Training loss = 2.8559  Validation loss = 2.5995  \n",
      "\n",
      "Fold: 1  Epoch: 432  Training loss = 2.8548  Validation loss = 2.5969  \n",
      "\n",
      "Fold: 1  Epoch: 433  Training loss = 2.8543  Validation loss = 2.5956  \n",
      "\n",
      "Fold: 1  Epoch: 434  Training loss = 2.8533  Validation loss = 2.5932  \n",
      "\n",
      "Fold: 1  Epoch: 435  Training loss = 2.8525  Validation loss = 2.5916  \n",
      "\n",
      "Fold: 1  Epoch: 436  Training loss = 2.8515  Validation loss = 2.5892  \n",
      "\n",
      "Fold: 1  Epoch: 437  Training loss = 2.8510  Validation loss = 2.5879  \n",
      "\n",
      "Fold: 1  Epoch: 438  Training loss = 2.8504  Validation loss = 2.5864  \n",
      "\n",
      "Fold: 1  Epoch: 439  Training loss = 2.8497  Validation loss = 2.5848  \n",
      "\n",
      "Fold: 1  Epoch: 440  Training loss = 2.8493  Validation loss = 2.5838  \n",
      "\n",
      "Fold: 1  Epoch: 441  Training loss = 2.8488  Validation loss = 2.5825  \n",
      "\n",
      "Fold: 1  Epoch: 442  Training loss = 2.8479  Validation loss = 2.5805  \n",
      "\n",
      "Fold: 1  Epoch: 443  Training loss = 2.8473  Validation loss = 2.5791  \n",
      "\n",
      "Fold: 1  Epoch: 444  Training loss = 2.8464  Validation loss = 2.5770  \n",
      "\n",
      "Fold: 1  Epoch: 445  Training loss = 2.8460  Validation loss = 2.5760  \n",
      "\n",
      "Fold: 1  Epoch: 446  Training loss = 2.8451  Validation loss = 2.5739  \n",
      "\n",
      "Fold: 1  Epoch: 447  Training loss = 2.8444  Validation loss = 2.5723  \n",
      "\n",
      "Fold: 1  Epoch: 448  Training loss = 2.8438  Validation loss = 2.5709  \n",
      "\n",
      "Fold: 1  Epoch: 449  Training loss = 2.8432  Validation loss = 2.5694  \n",
      "\n",
      "Fold: 1  Epoch: 450  Training loss = 2.8424  Validation loss = 2.5674  \n",
      "\n",
      "Fold: 1  Epoch: 451  Training loss = 2.8417  Validation loss = 2.5656  \n",
      "\n",
      "Fold: 1  Epoch: 452  Training loss = 2.8410  Validation loss = 2.5639  \n",
      "\n",
      "Fold: 1  Epoch: 453  Training loss = 2.8406  Validation loss = 2.5630  \n",
      "\n",
      "Fold: 1  Epoch: 454  Training loss = 2.8399  Validation loss = 2.5614  \n",
      "\n",
      "Fold: 1  Epoch: 455  Training loss = 2.8392  Validation loss = 2.5597  \n",
      "\n",
      "Fold: 1  Epoch: 456  Training loss = 2.8389  Validation loss = 2.5589  \n",
      "\n",
      "Fold: 1  Epoch: 457  Training loss = 2.8380  Validation loss = 2.5567  \n",
      "\n",
      "Fold: 1  Epoch: 458  Training loss = 2.8368  Validation loss = 2.5540  \n",
      "\n",
      "Fold: 1  Epoch: 459  Training loss = 2.8357  Validation loss = 2.5514  \n",
      "\n",
      "Fold: 1  Epoch: 460  Training loss = 2.8348  Validation loss = 2.5493  \n",
      "\n",
      "Fold: 1  Epoch: 461  Training loss = 2.8343  Validation loss = 2.5480  \n",
      "\n",
      "Fold: 1  Epoch: 462  Training loss = 2.8339  Validation loss = 2.5470  \n",
      "\n",
      "Fold: 1  Epoch: 463  Training loss = 2.8329  Validation loss = 2.5447  \n",
      "\n",
      "Fold: 1  Epoch: 464  Training loss = 2.8323  Validation loss = 2.5432  \n",
      "\n",
      "Fold: 1  Epoch: 465  Training loss = 2.8318  Validation loss = 2.5418  \n",
      "\n",
      "Fold: 1  Epoch: 466  Training loss = 2.8308  Validation loss = 2.5396  \n",
      "\n",
      "Fold: 1  Epoch: 467  Training loss = 2.8304  Validation loss = 2.5386  \n",
      "\n",
      "Fold: 1  Epoch: 468  Training loss = 2.8297  Validation loss = 2.5368  \n",
      "\n",
      "Fold: 1  Epoch: 469  Training loss = 2.8291  Validation loss = 2.5353  \n",
      "\n",
      "Fold: 1  Epoch: 470  Training loss = 2.8283  Validation loss = 2.5331  \n",
      "\n",
      "Fold: 1  Epoch: 471  Training loss = 2.8276  Validation loss = 2.5315  \n",
      "\n",
      "Fold: 1  Epoch: 472  Training loss = 2.8272  Validation loss = 2.5303  \n",
      "\n",
      "Fold: 1  Epoch: 473  Training loss = 2.8266  Validation loss = 2.5286  \n",
      "\n",
      "Fold: 1  Epoch: 474  Training loss = 2.8261  Validation loss = 2.5275  \n",
      "\n",
      "Fold: 1  Epoch: 475  Training loss = 2.8256  Validation loss = 2.5261  \n",
      "\n",
      "Fold: 1  Epoch: 476  Training loss = 2.8249  Validation loss = 2.5246  \n",
      "\n",
      "Fold: 1  Epoch: 477  Training loss = 2.8242  Validation loss = 2.5229  \n",
      "\n",
      "Fold: 1  Epoch: 478  Training loss = 2.8234  Validation loss = 2.5207  \n",
      "\n",
      "Fold: 1  Epoch: 479  Training loss = 2.8227  Validation loss = 2.5189  \n",
      "\n",
      "Fold: 1  Epoch: 480  Training loss = 2.8223  Validation loss = 2.5177  \n",
      "\n",
      "Fold: 1  Epoch: 481  Training loss = 2.8216  Validation loss = 2.5160  \n",
      "\n",
      "Fold: 1  Epoch: 482  Training loss = 2.8210  Validation loss = 2.5144  \n",
      "\n",
      "Fold: 1  Epoch: 483  Training loss = 2.8204  Validation loss = 2.5128  \n",
      "\n",
      "Fold: 1  Epoch: 484  Training loss = 2.8195  Validation loss = 2.5105  \n",
      "\n",
      "Fold: 1  Epoch: 485  Training loss = 2.8187  Validation loss = 2.5086  \n",
      "\n",
      "Fold: 1  Epoch: 486  Training loss = 2.8180  Validation loss = 2.5068  \n",
      "\n",
      "Fold: 1  Epoch: 487  Training loss = 2.8173  Validation loss = 2.5051  \n",
      "\n",
      "Fold: 1  Epoch: 488  Training loss = 2.8166  Validation loss = 2.5035  \n",
      "\n",
      "Fold: 1  Epoch: 489  Training loss = 2.8163  Validation loss = 2.5025  \n",
      "\n",
      "Fold: 1  Epoch: 490  Training loss = 2.8159  Validation loss = 2.5015  \n",
      "\n",
      "Fold: 1  Epoch: 491  Training loss = 2.8154  Validation loss = 2.5004  \n",
      "\n",
      "Fold: 1  Epoch: 492  Training loss = 2.8147  Validation loss = 2.4986  \n",
      "\n",
      "Fold: 1  Epoch: 493  Training loss = 2.8139  Validation loss = 2.4967  \n",
      "\n",
      "Fold: 1  Epoch: 494  Training loss = 2.8132  Validation loss = 2.4949  \n",
      "\n",
      "Fold: 1  Epoch: 495  Training loss = 2.8122  Validation loss = 2.4924  \n",
      "\n",
      "Fold: 1  Epoch: 496  Training loss = 2.8113  Validation loss = 2.4904  \n",
      "\n",
      "Fold: 1  Epoch: 497  Training loss = 2.8104  Validation loss = 2.4881  \n",
      "\n",
      "Fold: 1  Epoch: 498  Training loss = 2.8099  Validation loss = 2.4868  \n",
      "\n",
      "Fold: 1  Epoch: 499  Training loss = 2.8096  Validation loss = 2.4860  \n",
      "\n",
      "Fold: 1  Epoch: 500  Training loss = 2.8089  Validation loss = 2.4841  \n",
      "\n",
      "Check model:  Fold: 1  Optimal epoch: 500  \n",
      "\n",
      "Fold: 2  Epoch: 1  Training loss = 2.7333  Validation loss = 2.6751  \n",
      "\n",
      "Fold: 2  Epoch: 2  Training loss = 2.7322  Validation loss = 2.6733  \n",
      "\n",
      "Fold: 2  Epoch: 3  Training loss = 2.7312  Validation loss = 2.6718  \n",
      "\n",
      "Fold: 2  Epoch: 4  Training loss = 2.7302  Validation loss = 2.6700  \n",
      "\n",
      "Fold: 2  Epoch: 5  Training loss = 2.7296  Validation loss = 2.6689  \n",
      "\n",
      "Fold: 2  Epoch: 6  Training loss = 2.7287  Validation loss = 2.6673  \n",
      "\n",
      "Fold: 2  Epoch: 7  Training loss = 2.7279  Validation loss = 2.6659  \n",
      "\n",
      "Fold: 2  Epoch: 8  Training loss = 2.7271  Validation loss = 2.6644  \n",
      "\n",
      "Fold: 2  Epoch: 9  Training loss = 2.7262  Validation loss = 2.6628  \n",
      "\n",
      "Fold: 2  Epoch: 10  Training loss = 2.7255  Validation loss = 2.6614  \n",
      "\n",
      "Fold: 2  Epoch: 11  Training loss = 2.7245  Validation loss = 2.6597  \n",
      "\n",
      "Fold: 2  Epoch: 12  Training loss = 2.7235  Validation loss = 2.6580  \n",
      "\n",
      "Fold: 2  Epoch: 13  Training loss = 2.7229  Validation loss = 2.6569  \n",
      "\n",
      "Fold: 2  Epoch: 14  Training loss = 2.7223  Validation loss = 2.6558  \n",
      "\n",
      "Fold: 2  Epoch: 15  Training loss = 2.7218  Validation loss = 2.6548  \n",
      "\n",
      "Fold: 2  Epoch: 16  Training loss = 2.7213  Validation loss = 2.6538  \n",
      "\n",
      "Fold: 2  Epoch: 17  Training loss = 2.7209  Validation loss = 2.6529  \n",
      "\n",
      "Fold: 2  Epoch: 18  Training loss = 2.7206  Validation loss = 2.6522  \n",
      "\n",
      "Fold: 2  Epoch: 19  Training loss = 2.7200  Validation loss = 2.6509  \n",
      "\n",
      "Fold: 2  Epoch: 20  Training loss = 2.7193  Validation loss = 2.6498  \n",
      "\n",
      "Fold: 2  Epoch: 21  Training loss = 2.7187  Validation loss = 2.6484  \n",
      "\n",
      "Fold: 2  Epoch: 22  Training loss = 2.7181  Validation loss = 2.6475  \n",
      "\n",
      "Fold: 2  Epoch: 23  Training loss = 2.7174  Validation loss = 2.6461  \n",
      "\n",
      "Fold: 2  Epoch: 24  Training loss = 2.7171  Validation loss = 2.6455  \n",
      "\n",
      "Fold: 2  Epoch: 25  Training loss = 2.7166  Validation loss = 2.6445  \n",
      "\n",
      "Fold: 2  Epoch: 26  Training loss = 2.7160  Validation loss = 2.6434  \n",
      "\n",
      "Fold: 2  Epoch: 27  Training loss = 2.7152  Validation loss = 2.6419  \n",
      "\n",
      "Fold: 2  Epoch: 28  Training loss = 2.7147  Validation loss = 2.6410  \n",
      "\n",
      "Fold: 2  Epoch: 29  Training loss = 2.7141  Validation loss = 2.6397  \n",
      "\n",
      "Fold: 2  Epoch: 30  Training loss = 2.7132  Validation loss = 2.6383  \n",
      "\n",
      "Fold: 2  Epoch: 31  Training loss = 2.7126  Validation loss = 2.6372  \n",
      "\n",
      "Fold: 2  Epoch: 32  Training loss = 2.7118  Validation loss = 2.6359  \n",
      "\n",
      "Fold: 2  Epoch: 33  Training loss = 2.7114  Validation loss = 2.6350  \n",
      "\n",
      "Fold: 2  Epoch: 34  Training loss = 2.7106  Validation loss = 2.6336  \n",
      "\n",
      "Fold: 2  Epoch: 35  Training loss = 2.7099  Validation loss = 2.6324  \n",
      "\n",
      "Fold: 2  Epoch: 36  Training loss = 2.7092  Validation loss = 2.6310  \n",
      "\n",
      "Fold: 2  Epoch: 37  Training loss = 2.7086  Validation loss = 2.6299  \n",
      "\n",
      "Fold: 2  Epoch: 38  Training loss = 2.7079  Validation loss = 2.6287  \n",
      "\n",
      "Fold: 2  Epoch: 39  Training loss = 2.7074  Validation loss = 2.6275  \n",
      "\n",
      "Fold: 2  Epoch: 40  Training loss = 2.7068  Validation loss = 2.6262  \n",
      "\n",
      "Fold: 2  Epoch: 41  Training loss = 2.7063  Validation loss = 2.6254  \n",
      "\n",
      "Fold: 2  Epoch: 42  Training loss = 2.7056  Validation loss = 2.6240  \n",
      "\n",
      "Fold: 2  Epoch: 43  Training loss = 2.7052  Validation loss = 2.6230  \n",
      "\n",
      "Fold: 2  Epoch: 44  Training loss = 2.7046  Validation loss = 2.6220  \n",
      "\n",
      "Fold: 2  Epoch: 45  Training loss = 2.7043  Validation loss = 2.6212  \n",
      "\n",
      "Fold: 2  Epoch: 46  Training loss = 2.7040  Validation loss = 2.6205  \n",
      "\n",
      "Fold: 2  Epoch: 47  Training loss = 2.7033  Validation loss = 2.6192  \n",
      "\n",
      "Fold: 2  Epoch: 48  Training loss = 2.7024  Validation loss = 2.6177  \n",
      "\n",
      "Fold: 2  Epoch: 49  Training loss = 2.7021  Validation loss = 2.6170  \n",
      "\n",
      "Fold: 2  Epoch: 50  Training loss = 2.7012  Validation loss = 2.6153  \n",
      "\n",
      "Fold: 2  Epoch: 51  Training loss = 2.7004  Validation loss = 2.6139  \n",
      "\n",
      "Fold: 2  Epoch: 52  Training loss = 2.6996  Validation loss = 2.6123  \n",
      "\n",
      "Fold: 2  Epoch: 53  Training loss = 2.6987  Validation loss = 2.6107  \n",
      "\n",
      "Fold: 2  Epoch: 54  Training loss = 2.6979  Validation loss = 2.6093  \n",
      "\n",
      "Fold: 2  Epoch: 55  Training loss = 2.6969  Validation loss = 2.6075  \n",
      "\n",
      "Fold: 2  Epoch: 56  Training loss = 2.6963  Validation loss = 2.6063  \n",
      "\n",
      "Fold: 2  Epoch: 57  Training loss = 2.6953  Validation loss = 2.6047  \n",
      "\n",
      "Fold: 2  Epoch: 58  Training loss = 2.6947  Validation loss = 2.6035  \n",
      "\n",
      "Fold: 2  Epoch: 59  Training loss = 2.6943  Validation loss = 2.6028  \n",
      "\n",
      "Fold: 2  Epoch: 60  Training loss = 2.6936  Validation loss = 2.6014  \n",
      "\n",
      "Fold: 2  Epoch: 61  Training loss = 2.6933  Validation loss = 2.6010  \n",
      "\n",
      "Fold: 2  Epoch: 62  Training loss = 2.6925  Validation loss = 2.5995  \n",
      "\n",
      "Fold: 2  Epoch: 63  Training loss = 2.6917  Validation loss = 2.5980  \n",
      "\n",
      "Fold: 2  Epoch: 64  Training loss = 2.6911  Validation loss = 2.5969  \n",
      "\n",
      "Fold: 2  Epoch: 65  Training loss = 2.6904  Validation loss = 2.5955  \n",
      "\n",
      "Fold: 2  Epoch: 66  Training loss = 2.6901  Validation loss = 2.5949  \n",
      "\n",
      "Fold: 2  Epoch: 67  Training loss = 2.6894  Validation loss = 2.5935  \n",
      "\n",
      "Fold: 2  Epoch: 68  Training loss = 2.6889  Validation loss = 2.5925  \n",
      "\n",
      "Fold: 2  Epoch: 69  Training loss = 2.6877  Validation loss = 2.5902  \n",
      "\n",
      "Fold: 2  Epoch: 70  Training loss = 2.6870  Validation loss = 2.5888  \n",
      "\n",
      "Fold: 2  Epoch: 71  Training loss = 2.6864  Validation loss = 2.5878  \n",
      "\n",
      "Fold: 2  Epoch: 72  Training loss = 2.6856  Validation loss = 2.5865  \n",
      "\n",
      "Fold: 2  Epoch: 73  Training loss = 2.6848  Validation loss = 2.5851  \n",
      "\n",
      "Fold: 2  Epoch: 74  Training loss = 2.6841  Validation loss = 2.5837  \n",
      "\n",
      "Fold: 2  Epoch: 75  Training loss = 2.6833  Validation loss = 2.5823  \n",
      "\n",
      "Fold: 2  Epoch: 76  Training loss = 2.6826  Validation loss = 2.5809  \n",
      "\n",
      "Fold: 2  Epoch: 77  Training loss = 2.6817  Validation loss = 2.5794  \n",
      "\n",
      "Fold: 2  Epoch: 78  Training loss = 2.6813  Validation loss = 2.5786  \n",
      "\n",
      "Fold: 2  Epoch: 79  Training loss = 2.6810  Validation loss = 2.5779  \n",
      "\n",
      "Fold: 2  Epoch: 80  Training loss = 2.6800  Validation loss = 2.5761  \n",
      "\n",
      "Fold: 2  Epoch: 81  Training loss = 2.6794  Validation loss = 2.5749  \n",
      "\n",
      "Fold: 2  Epoch: 82  Training loss = 2.6787  Validation loss = 2.5735  \n",
      "\n",
      "Fold: 2  Epoch: 83  Training loss = 2.6778  Validation loss = 2.5719  \n",
      "\n",
      "Fold: 2  Epoch: 84  Training loss = 2.6774  Validation loss = 2.5710  \n",
      "\n",
      "Fold: 2  Epoch: 85  Training loss = 2.6767  Validation loss = 2.5697  \n",
      "\n",
      "Fold: 2  Epoch: 86  Training loss = 2.6761  Validation loss = 2.5685  \n",
      "\n",
      "Fold: 2  Epoch: 87  Training loss = 2.6756  Validation loss = 2.5676  \n",
      "\n",
      "Fold: 2  Epoch: 88  Training loss = 2.6751  Validation loss = 2.5665  \n",
      "\n",
      "Fold: 2  Epoch: 89  Training loss = 2.6746  Validation loss = 2.5655  \n",
      "\n",
      "Fold: 2  Epoch: 90  Training loss = 2.6739  Validation loss = 2.5644  \n",
      "\n",
      "Fold: 2  Epoch: 91  Training loss = 2.6736  Validation loss = 2.5637  \n",
      "\n",
      "Fold: 2  Epoch: 92  Training loss = 2.6730  Validation loss = 2.5625  \n",
      "\n",
      "Fold: 2  Epoch: 93  Training loss = 2.6723  Validation loss = 2.5611  \n",
      "\n",
      "Fold: 2  Epoch: 94  Training loss = 2.6719  Validation loss = 2.5602  \n",
      "\n",
      "Fold: 2  Epoch: 95  Training loss = 2.6710  Validation loss = 2.5585  \n",
      "\n",
      "Fold: 2  Epoch: 96  Training loss = 2.6704  Validation loss = 2.5575  \n",
      "\n",
      "Fold: 2  Epoch: 97  Training loss = 2.6698  Validation loss = 2.5562  \n",
      "\n",
      "Fold: 2  Epoch: 98  Training loss = 2.6691  Validation loss = 2.5549  \n",
      "\n",
      "Fold: 2  Epoch: 99  Training loss = 2.6685  Validation loss = 2.5536  \n",
      "\n",
      "Fold: 2  Epoch: 100  Training loss = 2.6679  Validation loss = 2.5525  \n",
      "\n",
      "Fold: 2  Epoch: 101  Training loss = 2.6671  Validation loss = 2.5512  \n",
      "\n",
      "Fold: 2  Epoch: 102  Training loss = 2.6663  Validation loss = 2.5496  \n",
      "\n",
      "Fold: 2  Epoch: 103  Training loss = 2.6659  Validation loss = 2.5487  \n",
      "\n",
      "Fold: 2  Epoch: 104  Training loss = 2.6652  Validation loss = 2.5476  \n",
      "\n",
      "Fold: 2  Epoch: 105  Training loss = 2.6644  Validation loss = 2.5459  \n",
      "\n",
      "Fold: 2  Epoch: 106  Training loss = 2.6637  Validation loss = 2.5446  \n",
      "\n",
      "Fold: 2  Epoch: 107  Training loss = 2.6630  Validation loss = 2.5431  \n",
      "\n",
      "Fold: 2  Epoch: 108  Training loss = 2.6626  Validation loss = 2.5423  \n",
      "\n",
      "Fold: 2  Epoch: 109  Training loss = 2.6622  Validation loss = 2.5414  \n",
      "\n",
      "Fold: 2  Epoch: 110  Training loss = 2.6615  Validation loss = 2.5402  \n",
      "\n",
      "Fold: 2  Epoch: 111  Training loss = 2.6608  Validation loss = 2.5388  \n",
      "\n",
      "Fold: 2  Epoch: 112  Training loss = 2.6603  Validation loss = 2.5378  \n",
      "\n",
      "Fold: 2  Epoch: 113  Training loss = 2.6597  Validation loss = 2.5365  \n",
      "\n",
      "Fold: 2  Epoch: 114  Training loss = 2.6589  Validation loss = 2.5349  \n",
      "\n",
      "Fold: 2  Epoch: 115  Training loss = 2.6581  Validation loss = 2.5333  \n",
      "\n",
      "Fold: 2  Epoch: 116  Training loss = 2.6576  Validation loss = 2.5321  \n",
      "\n",
      "Fold: 2  Epoch: 117  Training loss = 2.6571  Validation loss = 2.5311  \n",
      "\n",
      "Fold: 2  Epoch: 118  Training loss = 2.6565  Validation loss = 2.5300  \n",
      "\n",
      "Fold: 2  Epoch: 119  Training loss = 2.6560  Validation loss = 2.5291  \n",
      "\n",
      "Fold: 2  Epoch: 120  Training loss = 2.6553  Validation loss = 2.5278  \n",
      "\n",
      "Fold: 2  Epoch: 121  Training loss = 2.6548  Validation loss = 2.5268  \n",
      "\n",
      "Fold: 2  Epoch: 122  Training loss = 2.6544  Validation loss = 2.5260  \n",
      "\n",
      "Fold: 2  Epoch: 123  Training loss = 2.6538  Validation loss = 2.5248  \n",
      "\n",
      "Fold: 2  Epoch: 124  Training loss = 2.6531  Validation loss = 2.5233  \n",
      "\n",
      "Fold: 2  Epoch: 125  Training loss = 2.6523  Validation loss = 2.5218  \n",
      "\n",
      "Fold: 2  Epoch: 126  Training loss = 2.6519  Validation loss = 2.5208  \n",
      "\n",
      "Fold: 2  Epoch: 127  Training loss = 2.6511  Validation loss = 2.5193  \n",
      "\n",
      "Fold: 2  Epoch: 128  Training loss = 2.6505  Validation loss = 2.5179  \n",
      "\n",
      "Fold: 2  Epoch: 129  Training loss = 2.6501  Validation loss = 2.5170  \n",
      "\n",
      "Fold: 2  Epoch: 130  Training loss = 2.6494  Validation loss = 2.5156  \n",
      "\n",
      "Fold: 2  Epoch: 131  Training loss = 2.6488  Validation loss = 2.5144  \n",
      "\n",
      "Fold: 2  Epoch: 132  Training loss = 2.6481  Validation loss = 2.5132  \n",
      "\n",
      "Fold: 2  Epoch: 133  Training loss = 2.6478  Validation loss = 2.5125  \n",
      "\n",
      "Fold: 2  Epoch: 134  Training loss = 2.6472  Validation loss = 2.5115  \n",
      "\n",
      "Fold: 2  Epoch: 135  Training loss = 2.6464  Validation loss = 2.5099  \n",
      "\n",
      "Fold: 2  Epoch: 136  Training loss = 2.6459  Validation loss = 2.5091  \n",
      "\n",
      "Fold: 2  Epoch: 137  Training loss = 2.6455  Validation loss = 2.5082  \n",
      "\n",
      "Fold: 2  Epoch: 138  Training loss = 2.6449  Validation loss = 2.5070  \n",
      "\n",
      "Fold: 2  Epoch: 139  Training loss = 2.6445  Validation loss = 2.5061  \n",
      "\n",
      "Fold: 2  Epoch: 140  Training loss = 2.6440  Validation loss = 2.5050  \n",
      "\n",
      "Fold: 2  Epoch: 141  Training loss = 2.6436  Validation loss = 2.5042  \n",
      "\n",
      "Fold: 2  Epoch: 142  Training loss = 2.6432  Validation loss = 2.5033  \n",
      "\n",
      "Fold: 2  Epoch: 143  Training loss = 2.6427  Validation loss = 2.5022  \n",
      "\n",
      "Fold: 2  Epoch: 144  Training loss = 2.6421  Validation loss = 2.5011  \n",
      "\n",
      "Fold: 2  Epoch: 145  Training loss = 2.6418  Validation loss = 2.5006  \n",
      "\n",
      "Fold: 2  Epoch: 146  Training loss = 2.6414  Validation loss = 2.4997  \n",
      "\n",
      "Fold: 2  Epoch: 147  Training loss = 2.6409  Validation loss = 2.4988  \n",
      "\n",
      "Fold: 2  Epoch: 148  Training loss = 2.6405  Validation loss = 2.4980  \n",
      "\n",
      "Fold: 2  Epoch: 149  Training loss = 2.6401  Validation loss = 2.4972  \n",
      "\n",
      "Fold: 2  Epoch: 150  Training loss = 2.6397  Validation loss = 2.4962  \n",
      "\n",
      "Fold: 2  Epoch: 151  Training loss = 2.6393  Validation loss = 2.4954  \n",
      "\n",
      "Fold: 2  Epoch: 152  Training loss = 2.6388  Validation loss = 2.4944  \n",
      "\n",
      "Fold: 2  Epoch: 153  Training loss = 2.6383  Validation loss = 2.4931  \n",
      "\n",
      "Fold: 2  Epoch: 154  Training loss = 2.6380  Validation loss = 2.4924  \n",
      "\n",
      "Fold: 2  Epoch: 155  Training loss = 2.6377  Validation loss = 2.4917  \n",
      "\n",
      "Fold: 2  Epoch: 156  Training loss = 2.6373  Validation loss = 2.4908  \n",
      "\n",
      "Fold: 2  Epoch: 157  Training loss = 2.6370  Validation loss = 2.4902  \n",
      "\n",
      "Fold: 2  Epoch: 158  Training loss = 2.6366  Validation loss = 2.4892  \n",
      "\n",
      "Fold: 2  Epoch: 159  Training loss = 2.6361  Validation loss = 2.4881  \n",
      "\n",
      "Fold: 2  Epoch: 160  Training loss = 2.6355  Validation loss = 2.4870  \n",
      "\n",
      "Fold: 2  Epoch: 161  Training loss = 2.6350  Validation loss = 2.4859  \n",
      "\n",
      "Fold: 2  Epoch: 162  Training loss = 2.6347  Validation loss = 2.4852  \n",
      "\n",
      "Fold: 2  Epoch: 163  Training loss = 2.6343  Validation loss = 2.4842  \n",
      "\n",
      "Fold: 2  Epoch: 164  Training loss = 2.6336  Validation loss = 2.4827  \n",
      "\n",
      "Fold: 2  Epoch: 165  Training loss = 2.6331  Validation loss = 2.4818  \n",
      "\n",
      "Fold: 2  Epoch: 166  Training loss = 2.6325  Validation loss = 2.4807  \n",
      "\n",
      "Fold: 2  Epoch: 167  Training loss = 2.6322  Validation loss = 2.4800  \n",
      "\n",
      "Fold: 2  Epoch: 168  Training loss = 2.6318  Validation loss = 2.4790  \n",
      "\n",
      "Fold: 2  Epoch: 169  Training loss = 2.6313  Validation loss = 2.4780  \n",
      "\n",
      "Fold: 2  Epoch: 170  Training loss = 2.6309  Validation loss = 2.4772  \n",
      "\n",
      "Fold: 2  Epoch: 171  Training loss = 2.6306  Validation loss = 2.4763  \n",
      "\n",
      "Fold: 2  Epoch: 172  Training loss = 2.6298  Validation loss = 2.4748  \n",
      "\n",
      "Fold: 2  Epoch: 173  Training loss = 2.6294  Validation loss = 2.4738  \n",
      "\n",
      "Fold: 2  Epoch: 174  Training loss = 2.6285  Validation loss = 2.4721  \n",
      "\n",
      "Fold: 2  Epoch: 175  Training loss = 2.6280  Validation loss = 2.4709  \n",
      "\n",
      "Fold: 2  Epoch: 176  Training loss = 2.6276  Validation loss = 2.4699  \n",
      "\n",
      "Fold: 2  Epoch: 177  Training loss = 2.6269  Validation loss = 2.4687  \n",
      "\n",
      "Fold: 2  Epoch: 178  Training loss = 2.6266  Validation loss = 2.4678  \n",
      "\n",
      "Fold: 2  Epoch: 179  Training loss = 2.6263  Validation loss = 2.4670  \n",
      "\n",
      "Fold: 2  Epoch: 180  Training loss = 2.6257  Validation loss = 2.4659  \n",
      "\n",
      "Fold: 2  Epoch: 181  Training loss = 2.6254  Validation loss = 2.4652  \n",
      "\n",
      "Fold: 2  Epoch: 182  Training loss = 2.6250  Validation loss = 2.4644  \n",
      "\n",
      "Fold: 2  Epoch: 183  Training loss = 2.6247  Validation loss = 2.4638  \n",
      "\n",
      "Fold: 2  Epoch: 184  Training loss = 2.6240  Validation loss = 2.4624  \n",
      "\n",
      "Fold: 2  Epoch: 185  Training loss = 2.6236  Validation loss = 2.4615  \n",
      "\n",
      "Fold: 2  Epoch: 186  Training loss = 2.6231  Validation loss = 2.4606  \n",
      "\n",
      "Fold: 2  Epoch: 187  Training loss = 2.6226  Validation loss = 2.4597  \n",
      "\n",
      "Fold: 2  Epoch: 188  Training loss = 2.6224  Validation loss = 2.4592  \n",
      "\n",
      "Fold: 2  Epoch: 189  Training loss = 2.6219  Validation loss = 2.4581  \n",
      "\n",
      "Fold: 2  Epoch: 190  Training loss = 2.6214  Validation loss = 2.4570  \n",
      "\n",
      "Fold: 2  Epoch: 191  Training loss = 2.6210  Validation loss = 2.4562  \n",
      "\n",
      "Fold: 2  Epoch: 192  Training loss = 2.6204  Validation loss = 2.4548  \n",
      "\n",
      "Fold: 2  Epoch: 193  Training loss = 2.6201  Validation loss = 2.4542  \n",
      "\n",
      "Fold: 2  Epoch: 194  Training loss = 2.6199  Validation loss = 2.4536  \n",
      "\n",
      "Fold: 2  Epoch: 195  Training loss = 2.6190  Validation loss = 2.4521  \n",
      "\n",
      "Fold: 2  Epoch: 196  Training loss = 2.6186  Validation loss = 2.4512  \n",
      "\n",
      "Fold: 2  Epoch: 197  Training loss = 2.6183  Validation loss = 2.4505  \n",
      "\n",
      "Fold: 2  Epoch: 198  Training loss = 2.6179  Validation loss = 2.4498  \n",
      "\n",
      "Fold: 2  Epoch: 199  Training loss = 2.6173  Validation loss = 2.4484  \n",
      "\n",
      "Fold: 2  Epoch: 200  Training loss = 2.6169  Validation loss = 2.4476  \n",
      "\n",
      "Fold: 2  Epoch: 201  Training loss = 2.6163  Validation loss = 2.4462  \n",
      "\n",
      "Fold: 2  Epoch: 202  Training loss = 2.6158  Validation loss = 2.4449  \n",
      "\n",
      "Fold: 2  Epoch: 203  Training loss = 2.6153  Validation loss = 2.4439  \n",
      "\n",
      "Fold: 2  Epoch: 204  Training loss = 2.6150  Validation loss = 2.4431  \n",
      "\n",
      "Fold: 2  Epoch: 205  Training loss = 2.6148  Validation loss = 2.4426  \n",
      "\n",
      "Fold: 2  Epoch: 206  Training loss = 2.6143  Validation loss = 2.4413  \n",
      "\n",
      "Fold: 2  Epoch: 207  Training loss = 2.6139  Validation loss = 2.4405  \n",
      "\n",
      "Fold: 2  Epoch: 208  Training loss = 2.6133  Validation loss = 2.4393  \n",
      "\n",
      "Fold: 2  Epoch: 209  Training loss = 2.6129  Validation loss = 2.4384  \n",
      "\n",
      "Fold: 2  Epoch: 210  Training loss = 2.6126  Validation loss = 2.4377  \n",
      "\n",
      "Fold: 2  Epoch: 211  Training loss = 2.6121  Validation loss = 2.4367  \n",
      "\n",
      "Fold: 2  Epoch: 212  Training loss = 2.6118  Validation loss = 2.4360  \n",
      "\n",
      "Fold: 2  Epoch: 213  Training loss = 2.6114  Validation loss = 2.4351  \n",
      "\n",
      "Fold: 2  Epoch: 214  Training loss = 2.6109  Validation loss = 2.4342  \n",
      "\n",
      "Fold: 2  Epoch: 215  Training loss = 2.6105  Validation loss = 2.4333  \n",
      "\n",
      "Fold: 2  Epoch: 216  Training loss = 2.6099  Validation loss = 2.4319  \n",
      "\n",
      "Fold: 2  Epoch: 217  Training loss = 2.6093  Validation loss = 2.4306  \n",
      "\n",
      "Fold: 2  Epoch: 218  Training loss = 2.6087  Validation loss = 2.4294  \n",
      "\n",
      "Fold: 2  Epoch: 219  Training loss = 2.6081  Validation loss = 2.4281  \n",
      "\n",
      "Fold: 2  Epoch: 220  Training loss = 2.6079  Validation loss = 2.4275  \n",
      "\n",
      "Fold: 2  Epoch: 221  Training loss = 2.6075  Validation loss = 2.4267  \n",
      "\n",
      "Fold: 2  Epoch: 222  Training loss = 2.6071  Validation loss = 2.4255  \n",
      "\n",
      "Fold: 2  Epoch: 223  Training loss = 2.6066  Validation loss = 2.4245  \n",
      "\n",
      "Fold: 2  Epoch: 224  Training loss = 2.6062  Validation loss = 2.4237  \n",
      "\n",
      "Fold: 2  Epoch: 225  Training loss = 2.6059  Validation loss = 2.4230  \n",
      "\n",
      "Fold: 2  Epoch: 226  Training loss = 2.6057  Validation loss = 2.4224  \n",
      "\n",
      "Fold: 2  Epoch: 227  Training loss = 2.6054  Validation loss = 2.4218  \n",
      "\n",
      "Fold: 2  Epoch: 228  Training loss = 2.6052  Validation loss = 2.4211  \n",
      "\n",
      "Fold: 2  Epoch: 229  Training loss = 2.6048  Validation loss = 2.4202  \n",
      "\n",
      "Fold: 2  Epoch: 230  Training loss = 2.6043  Validation loss = 2.4192  \n",
      "\n",
      "Fold: 2  Epoch: 231  Training loss = 2.6039  Validation loss = 2.4181  \n",
      "\n",
      "Fold: 2  Epoch: 232  Training loss = 2.6033  Validation loss = 2.4169  \n",
      "\n",
      "Fold: 2  Epoch: 233  Training loss = 2.6029  Validation loss = 2.4161  \n",
      "\n",
      "Fold: 2  Epoch: 234  Training loss = 2.6024  Validation loss = 2.4149  \n",
      "\n",
      "Fold: 2  Epoch: 235  Training loss = 2.6022  Validation loss = 2.4143  \n",
      "\n",
      "Fold: 2  Epoch: 236  Training loss = 2.6018  Validation loss = 2.4136  \n",
      "\n",
      "Fold: 2  Epoch: 237  Training loss = 2.6015  Validation loss = 2.4132  \n",
      "\n",
      "Fold: 2  Epoch: 238  Training loss = 2.6010  Validation loss = 2.4120  \n",
      "\n",
      "Fold: 2  Epoch: 239  Training loss = 2.6006  Validation loss = 2.4110  \n",
      "\n",
      "Fold: 2  Epoch: 240  Training loss = 2.6003  Validation loss = 2.4103  \n",
      "\n",
      "Fold: 2  Epoch: 241  Training loss = 2.5999  Validation loss = 2.4095  \n",
      "\n",
      "Fold: 2  Epoch: 242  Training loss = 2.5997  Validation loss = 2.4090  \n",
      "\n",
      "Fold: 2  Epoch: 243  Training loss = 2.5992  Validation loss = 2.4079  \n",
      "\n",
      "Fold: 2  Epoch: 244  Training loss = 2.5986  Validation loss = 2.4068  \n",
      "\n",
      "Fold: 2  Epoch: 245  Training loss = 2.5982  Validation loss = 2.4058  \n",
      "\n",
      "Fold: 2  Epoch: 246  Training loss = 2.5979  Validation loss = 2.4051  \n",
      "\n",
      "Fold: 2  Epoch: 247  Training loss = 2.5972  Validation loss = 2.4036  \n",
      "\n",
      "Fold: 2  Epoch: 248  Training loss = 2.5969  Validation loss = 2.4030  \n",
      "\n",
      "Fold: 2  Epoch: 249  Training loss = 2.5967  Validation loss = 2.4025  \n",
      "\n",
      "Fold: 2  Epoch: 250  Training loss = 2.5963  Validation loss = 2.4014  \n",
      "\n",
      "Fold: 2  Epoch: 251  Training loss = 2.5960  Validation loss = 2.4007  \n",
      "\n",
      "Fold: 2  Epoch: 252  Training loss = 2.5957  Validation loss = 2.3999  \n",
      "\n",
      "Fold: 2  Epoch: 253  Training loss = 2.5953  Validation loss = 2.3989  \n",
      "\n",
      "Fold: 2  Epoch: 254  Training loss = 2.5949  Validation loss = 2.3980  \n",
      "\n",
      "Fold: 2  Epoch: 255  Training loss = 2.5947  Validation loss = 2.3977  \n",
      "\n",
      "Fold: 2  Epoch: 256  Training loss = 2.5943  Validation loss = 2.3967  \n",
      "\n",
      "Fold: 2  Epoch: 257  Training loss = 2.5938  Validation loss = 2.3957  \n",
      "\n",
      "Fold: 2  Epoch: 258  Training loss = 2.5936  Validation loss = 2.3952  \n",
      "\n",
      "Fold: 2  Epoch: 259  Training loss = 2.5935  Validation loss = 2.3947  \n",
      "\n",
      "Fold: 2  Epoch: 260  Training loss = 2.5930  Validation loss = 2.3939  \n",
      "\n",
      "Fold: 2  Epoch: 261  Training loss = 2.5928  Validation loss = 2.3932  \n",
      "\n",
      "Fold: 2  Epoch: 262  Training loss = 2.5922  Validation loss = 2.3920  \n",
      "\n",
      "Fold: 2  Epoch: 263  Training loss = 2.5921  Validation loss = 2.3915  \n",
      "\n",
      "Fold: 2  Epoch: 264  Training loss = 2.5916  Validation loss = 2.3906  \n",
      "\n",
      "Fold: 2  Epoch: 265  Training loss = 2.5913  Validation loss = 2.3900  \n",
      "\n",
      "Fold: 2  Epoch: 266  Training loss = 2.5910  Validation loss = 2.3891  \n",
      "\n",
      "Fold: 2  Epoch: 267  Training loss = 2.5906  Validation loss = 2.3885  \n",
      "\n",
      "Fold: 2  Epoch: 268  Training loss = 2.5902  Validation loss = 2.3873  \n",
      "\n",
      "Fold: 2  Epoch: 269  Training loss = 2.5898  Validation loss = 2.3865  \n",
      "\n",
      "Fold: 2  Epoch: 270  Training loss = 2.5892  Validation loss = 2.3854  \n",
      "\n",
      "Fold: 2  Epoch: 271  Training loss = 2.5891  Validation loss = 2.3850  \n",
      "\n",
      "Fold: 2  Epoch: 272  Training loss = 2.5888  Validation loss = 2.3843  \n",
      "\n",
      "Fold: 2  Epoch: 273  Training loss = 2.5886  Validation loss = 2.3840  \n",
      "\n",
      "Fold: 2  Epoch: 274  Training loss = 2.5883  Validation loss = 2.3833  \n",
      "\n",
      "Fold: 2  Epoch: 275  Training loss = 2.5877  Validation loss = 2.3821  \n",
      "\n",
      "Fold: 2  Epoch: 276  Training loss = 2.5875  Validation loss = 2.3815  \n",
      "\n",
      "Fold: 2  Epoch: 277  Training loss = 2.5874  Validation loss = 2.3812  \n",
      "\n",
      "Fold: 2  Epoch: 278  Training loss = 2.5867  Validation loss = 2.3795  \n",
      "\n",
      "Fold: 2  Epoch: 279  Training loss = 2.5862  Validation loss = 2.3784  \n",
      "\n",
      "Fold: 2  Epoch: 280  Training loss = 2.5858  Validation loss = 2.3775  \n",
      "\n",
      "Fold: 2  Epoch: 281  Training loss = 2.5856  Validation loss = 2.3771  \n",
      "\n",
      "Fold: 2  Epoch: 282  Training loss = 2.5850  Validation loss = 2.3756  \n",
      "\n",
      "Fold: 2  Epoch: 283  Training loss = 2.5847  Validation loss = 2.3750  \n",
      "\n",
      "Fold: 2  Epoch: 284  Training loss = 2.5844  Validation loss = 2.3742  \n",
      "\n",
      "Fold: 2  Epoch: 285  Training loss = 2.5844  Validation loss = 2.3742  \n",
      "\n",
      "Fold: 2  Epoch: 286  Training loss = 2.5840  Validation loss = 2.3734  \n",
      "\n",
      "Fold: 2  Epoch: 287  Training loss = 2.5837  Validation loss = 2.3726  \n",
      "\n",
      "Fold: 2  Epoch: 288  Training loss = 2.5836  Validation loss = 2.3723  \n",
      "\n",
      "Fold: 2  Epoch: 289  Training loss = 2.5834  Validation loss = 2.3716  \n",
      "\n",
      "Fold: 2  Epoch: 290  Training loss = 2.5832  Validation loss = 2.3712  \n",
      "\n",
      "Fold: 2  Epoch: 291  Training loss = 2.5830  Validation loss = 2.3706  \n",
      "\n",
      "Fold: 2  Epoch: 292  Training loss = 2.5824  Validation loss = 2.3694  \n",
      "\n",
      "Fold: 2  Epoch: 293  Training loss = 2.5820  Validation loss = 2.3683  \n",
      "\n",
      "Fold: 2  Epoch: 294  Training loss = 2.5813  Validation loss = 2.3669  \n",
      "\n",
      "Fold: 2  Epoch: 295  Training loss = 2.5808  Validation loss = 2.3658  \n",
      "\n",
      "Fold: 2  Epoch: 296  Training loss = 2.5804  Validation loss = 2.3650  \n",
      "\n",
      "Fold: 2  Epoch: 297  Training loss = 2.5803  Validation loss = 2.3649  \n",
      "\n",
      "Fold: 2  Epoch: 298  Training loss = 2.5802  Validation loss = 2.3647  \n",
      "\n",
      "Fold: 2  Epoch: 299  Training loss = 2.5800  Validation loss = 2.3638  \n",
      "\n",
      "Fold: 2  Epoch: 300  Training loss = 2.5797  Validation loss = 2.3634  \n",
      "\n",
      "Fold: 2  Epoch: 301  Training loss = 2.5793  Validation loss = 2.3625  \n",
      "\n",
      "Fold: 2  Epoch: 302  Training loss = 2.5789  Validation loss = 2.3617  \n",
      "\n",
      "Fold: 2  Epoch: 303  Training loss = 2.5786  Validation loss = 2.3610  \n",
      "\n",
      "Fold: 2  Epoch: 304  Training loss = 2.5782  Validation loss = 2.3599  \n",
      "\n",
      "Fold: 2  Epoch: 305  Training loss = 2.5780  Validation loss = 2.3596  \n",
      "\n",
      "Fold: 2  Epoch: 306  Training loss = 2.5776  Validation loss = 2.3588  \n",
      "\n",
      "Fold: 2  Epoch: 307  Training loss = 2.5775  Validation loss = 2.3586  \n",
      "\n",
      "Fold: 2  Epoch: 308  Training loss = 2.5773  Validation loss = 2.3581  \n",
      "\n",
      "Fold: 2  Epoch: 309  Training loss = 2.5771  Validation loss = 2.3577  \n",
      "\n",
      "Fold: 2  Epoch: 310  Training loss = 2.5766  Validation loss = 2.3566  \n",
      "\n",
      "Fold: 2  Epoch: 311  Training loss = 2.5762  Validation loss = 2.3556  \n",
      "\n",
      "Fold: 2  Epoch: 312  Training loss = 2.5758  Validation loss = 2.3547  \n",
      "\n",
      "Fold: 2  Epoch: 313  Training loss = 2.5755  Validation loss = 2.3541  \n",
      "\n",
      "Fold: 2  Epoch: 314  Training loss = 2.5751  Validation loss = 2.3531  \n",
      "\n",
      "Fold: 2  Epoch: 315  Training loss = 2.5747  Validation loss = 2.3522  \n",
      "\n",
      "Fold: 2  Epoch: 316  Training loss = 2.5743  Validation loss = 2.3511  \n",
      "\n",
      "Fold: 2  Epoch: 317  Training loss = 2.5742  Validation loss = 2.3507  \n",
      "\n",
      "Fold: 2  Epoch: 318  Training loss = 2.5739  Validation loss = 2.3502  \n",
      "\n",
      "Fold: 2  Epoch: 319  Training loss = 2.5735  Validation loss = 2.3492  \n",
      "\n",
      "Fold: 2  Epoch: 320  Training loss = 2.5734  Validation loss = 2.3490  \n",
      "\n",
      "Fold: 2  Epoch: 321  Training loss = 2.5732  Validation loss = 2.3484  \n",
      "\n",
      "Fold: 2  Epoch: 322  Training loss = 2.5730  Validation loss = 2.3478  \n",
      "\n",
      "Fold: 2  Epoch: 323  Training loss = 2.5727  Validation loss = 2.3471  \n",
      "\n",
      "Fold: 2  Epoch: 324  Training loss = 2.5726  Validation loss = 2.3467  \n",
      "\n",
      "Fold: 2  Epoch: 325  Training loss = 2.5723  Validation loss = 2.3462  \n",
      "\n",
      "Fold: 2  Epoch: 326  Training loss = 2.5720  Validation loss = 2.3456  \n",
      "\n",
      "Fold: 2  Epoch: 327  Training loss = 2.5718  Validation loss = 2.3452  \n",
      "\n",
      "Fold: 2  Epoch: 328  Training loss = 2.5718  Validation loss = 2.3451  \n",
      "\n",
      "Fold: 2  Epoch: 329  Training loss = 2.5716  Validation loss = 2.3446  \n",
      "\n",
      "Fold: 2  Epoch: 330  Training loss = 2.5712  Validation loss = 2.3437  \n",
      "\n",
      "Fold: 2  Epoch: 331  Training loss = 2.5710  Validation loss = 2.3433  \n",
      "\n",
      "Fold: 2  Epoch: 332  Training loss = 2.5707  Validation loss = 2.3424  \n",
      "\n",
      "Fold: 2  Epoch: 333  Training loss = 2.5704  Validation loss = 2.3416  \n",
      "\n",
      "Fold: 2  Epoch: 334  Training loss = 2.5698  Validation loss = 2.3402  \n",
      "\n",
      "Fold: 2  Epoch: 335  Training loss = 2.5695  Validation loss = 2.3395  \n",
      "\n",
      "Fold: 2  Epoch: 336  Training loss = 2.5693  Validation loss = 2.3390  \n",
      "\n",
      "Fold: 2  Epoch: 337  Training loss = 2.5692  Validation loss = 2.3386  \n",
      "\n",
      "Fold: 2  Epoch: 338  Training loss = 2.5687  Validation loss = 2.3376  \n",
      "\n",
      "Fold: 2  Epoch: 339  Training loss = 2.5684  Validation loss = 2.3367  \n",
      "\n",
      "Fold: 2  Epoch: 340  Training loss = 2.5681  Validation loss = 2.3362  \n",
      "\n",
      "Fold: 2  Epoch: 341  Training loss = 2.5678  Validation loss = 2.3352  \n",
      "\n",
      "Fold: 2  Epoch: 342  Training loss = 2.5675  Validation loss = 2.3345  \n",
      "\n",
      "Fold: 2  Epoch: 343  Training loss = 2.5671  Validation loss = 2.3336  \n",
      "\n",
      "Fold: 2  Epoch: 344  Training loss = 2.5666  Validation loss = 2.3327  \n",
      "\n",
      "Fold: 2  Epoch: 345  Training loss = 2.5663  Validation loss = 2.3317  \n",
      "\n",
      "Fold: 2  Epoch: 346  Training loss = 2.5657  Validation loss = 2.3302  \n",
      "\n",
      "Fold: 2  Epoch: 347  Training loss = 2.5654  Validation loss = 2.3295  \n",
      "\n",
      "Fold: 2  Epoch: 348  Training loss = 2.5650  Validation loss = 2.3286  \n",
      "\n",
      "Fold: 2  Epoch: 349  Training loss = 2.5644  Validation loss = 2.3274  \n",
      "\n",
      "Fold: 2  Epoch: 350  Training loss = 2.5642  Validation loss = 2.3268  \n",
      "\n",
      "Fold: 2  Epoch: 351  Training loss = 2.5642  Validation loss = 2.3269  \n",
      "\n",
      "Fold: 2  Epoch: 352  Training loss = 2.5641  Validation loss = 2.3264  \n",
      "\n",
      "Fold: 2  Epoch: 353  Training loss = 2.5638  Validation loss = 2.3258  \n",
      "\n",
      "Fold: 2  Epoch: 354  Training loss = 2.5633  Validation loss = 2.3248  \n",
      "\n",
      "Fold: 2  Epoch: 355  Training loss = 2.5630  Validation loss = 2.3241  \n",
      "\n",
      "Fold: 2  Epoch: 356  Training loss = 2.5627  Validation loss = 2.3233  \n",
      "\n",
      "Fold: 2  Epoch: 357  Training loss = 2.5625  Validation loss = 2.3228  \n",
      "\n",
      "Fold: 2  Epoch: 358  Training loss = 2.5622  Validation loss = 2.3220  \n",
      "\n",
      "Fold: 2  Epoch: 359  Training loss = 2.5618  Validation loss = 2.3213  \n",
      "\n",
      "Fold: 2  Epoch: 360  Training loss = 2.5618  Validation loss = 2.3211  \n",
      "\n",
      "Fold: 2  Epoch: 361  Training loss = 2.5616  Validation loss = 2.3206  \n",
      "\n",
      "Fold: 2  Epoch: 362  Training loss = 2.5613  Validation loss = 2.3199  \n",
      "\n",
      "Fold: 2  Epoch: 363  Training loss = 2.5610  Validation loss = 2.3191  \n",
      "\n",
      "Fold: 2  Epoch: 364  Training loss = 2.5608  Validation loss = 2.3186  \n",
      "\n",
      "Fold: 2  Epoch: 365  Training loss = 2.5604  Validation loss = 2.3177  \n",
      "\n",
      "Fold: 2  Epoch: 366  Training loss = 2.5601  Validation loss = 2.3170  \n",
      "\n",
      "Fold: 2  Epoch: 367  Training loss = 2.5599  Validation loss = 2.3165  \n",
      "\n",
      "Fold: 2  Epoch: 368  Training loss = 2.5595  Validation loss = 2.3154  \n",
      "\n",
      "Fold: 2  Epoch: 369  Training loss = 2.5594  Validation loss = 2.3150  \n",
      "\n",
      "Fold: 2  Epoch: 370  Training loss = 2.5591  Validation loss = 2.3142  \n",
      "\n",
      "Fold: 2  Epoch: 371  Training loss = 2.5588  Validation loss = 2.3133  \n",
      "\n",
      "Fold: 2  Epoch: 372  Training loss = 2.5586  Validation loss = 2.3128  \n",
      "\n",
      "Fold: 2  Epoch: 373  Training loss = 2.5582  Validation loss = 2.3117  \n",
      "\n",
      "Fold: 2  Epoch: 374  Training loss = 2.5580  Validation loss = 2.3114  \n",
      "\n",
      "Fold: 2  Epoch: 375  Training loss = 2.5578  Validation loss = 2.3108  \n",
      "\n",
      "Fold: 2  Epoch: 376  Training loss = 2.5575  Validation loss = 2.3101  \n",
      "\n",
      "Fold: 2  Epoch: 377  Training loss = 2.5573  Validation loss = 2.3095  \n",
      "\n",
      "Fold: 2  Epoch: 378  Training loss = 2.5570  Validation loss = 2.3089  \n",
      "\n",
      "Fold: 2  Epoch: 379  Training loss = 2.5569  Validation loss = 2.3086  \n",
      "\n",
      "Fold: 2  Epoch: 380  Training loss = 2.5567  Validation loss = 2.3082  \n",
      "\n",
      "Fold: 2  Epoch: 381  Training loss = 2.5564  Validation loss = 2.3074  \n",
      "\n",
      "Fold: 2  Epoch: 382  Training loss = 2.5561  Validation loss = 2.3068  \n",
      "\n",
      "Fold: 2  Epoch: 383  Training loss = 2.5558  Validation loss = 2.3061  \n",
      "\n",
      "Fold: 2  Epoch: 384  Training loss = 2.5553  Validation loss = 2.3048  \n",
      "\n",
      "Fold: 2  Epoch: 385  Training loss = 2.5551  Validation loss = 2.3044  \n",
      "\n",
      "Fold: 2  Epoch: 386  Training loss = 2.5550  Validation loss = 2.3039  \n",
      "\n",
      "Fold: 2  Epoch: 387  Training loss = 2.5547  Validation loss = 2.3032  \n",
      "\n",
      "Fold: 2  Epoch: 388  Training loss = 2.5544  Validation loss = 2.3022  \n",
      "\n",
      "Fold: 2  Epoch: 389  Training loss = 2.5541  Validation loss = 2.3014  \n",
      "\n",
      "Fold: 2  Epoch: 390  Training loss = 2.5542  Validation loss = 2.3015  \n",
      "\n",
      "Fold: 2  Epoch: 391  Training loss = 2.5538  Validation loss = 2.3006  \n",
      "\n",
      "Fold: 2  Epoch: 392  Training loss = 2.5538  Validation loss = 2.3003  \n",
      "\n",
      "Fold: 2  Epoch: 393  Training loss = 2.5537  Validation loss = 2.3002  \n",
      "\n",
      "Fold: 2  Epoch: 394  Training loss = 2.5534  Validation loss = 2.2995  \n",
      "\n",
      "Fold: 2  Epoch: 395  Training loss = 2.5531  Validation loss = 2.2986  \n",
      "\n",
      "Fold: 2  Epoch: 396  Training loss = 2.5530  Validation loss = 2.2983  \n",
      "\n",
      "Fold: 2  Epoch: 397  Training loss = 2.5527  Validation loss = 2.2976  \n",
      "\n",
      "Fold: 2  Epoch: 398  Training loss = 2.5525  Validation loss = 2.2969  \n",
      "\n",
      "Fold: 2  Epoch: 399  Training loss = 2.5522  Validation loss = 2.2962  \n",
      "\n",
      "Fold: 2  Epoch: 400  Training loss = 2.5518  Validation loss = 2.2951  \n",
      "\n",
      "Fold: 2  Epoch: 401  Training loss = 2.5516  Validation loss = 2.2946  \n",
      "\n",
      "Fold: 2  Epoch: 402  Training loss = 2.5512  Validation loss = 2.2936  \n",
      "\n",
      "Fold: 2  Epoch: 403  Training loss = 2.5511  Validation loss = 2.2933  \n",
      "\n",
      "Fold: 2  Epoch: 404  Training loss = 2.5509  Validation loss = 2.2929  \n",
      "\n",
      "Fold: 2  Epoch: 405  Training loss = 2.5507  Validation loss = 2.2922  \n",
      "\n",
      "Fold: 2  Epoch: 406  Training loss = 2.5504  Validation loss = 2.2913  \n",
      "\n",
      "Fold: 2  Epoch: 407  Training loss = 2.5503  Validation loss = 2.2908  \n",
      "\n",
      "Fold: 2  Epoch: 408  Training loss = 2.5501  Validation loss = 2.2903  \n",
      "\n",
      "Fold: 2  Epoch: 409  Training loss = 2.5499  Validation loss = 2.2899  \n",
      "\n",
      "Fold: 2  Epoch: 410  Training loss = 2.5497  Validation loss = 2.2892  \n",
      "\n",
      "Fold: 2  Epoch: 411  Training loss = 2.5493  Validation loss = 2.2884  \n",
      "\n",
      "Fold: 2  Epoch: 412  Training loss = 2.5490  Validation loss = 2.2876  \n",
      "\n",
      "Fold: 2  Epoch: 413  Training loss = 2.5489  Validation loss = 2.2872  \n",
      "\n",
      "Fold: 2  Epoch: 414  Training loss = 2.5486  Validation loss = 2.2863  \n",
      "\n",
      "Fold: 2  Epoch: 415  Training loss = 2.5483  Validation loss = 2.2854  \n",
      "\n",
      "Fold: 2  Epoch: 416  Training loss = 2.5477  Validation loss = 2.2836  \n",
      "\n",
      "Fold: 2  Epoch: 417  Training loss = 2.5474  Validation loss = 2.2831  \n",
      "\n",
      "Fold: 2  Epoch: 418  Training loss = 2.5473  Validation loss = 2.2827  \n",
      "\n",
      "Fold: 2  Epoch: 419  Training loss = 2.5468  Validation loss = 2.2817  \n",
      "\n",
      "Fold: 2  Epoch: 420  Training loss = 2.5467  Validation loss = 2.2814  \n",
      "\n",
      "Fold: 2  Epoch: 421  Training loss = 2.5466  Validation loss = 2.2809  \n",
      "\n",
      "Fold: 2  Epoch: 422  Training loss = 2.5462  Validation loss = 2.2800  \n",
      "\n",
      "Fold: 2  Epoch: 423  Training loss = 2.5462  Validation loss = 2.2796  \n",
      "\n",
      "Fold: 2  Epoch: 424  Training loss = 2.5459  Validation loss = 2.2788  \n",
      "\n",
      "Fold: 2  Epoch: 425  Training loss = 2.5454  Validation loss = 2.2777  \n",
      "\n",
      "Fold: 2  Epoch: 426  Training loss = 2.5449  Validation loss = 2.2765  \n",
      "\n",
      "Fold: 2  Epoch: 427  Training loss = 2.5449  Validation loss = 2.2762  \n",
      "\n",
      "Fold: 2  Epoch: 428  Training loss = 2.5446  Validation loss = 2.2755  \n",
      "\n",
      "Fold: 2  Epoch: 429  Training loss = 2.5445  Validation loss = 2.2752  \n",
      "\n",
      "Fold: 2  Epoch: 430  Training loss = 2.5444  Validation loss = 2.2748  \n",
      "\n",
      "Fold: 2  Epoch: 431  Training loss = 2.5442  Validation loss = 2.2742  \n",
      "\n",
      "Fold: 2  Epoch: 432  Training loss = 2.5440  Validation loss = 2.2735  \n",
      "\n",
      "Fold: 2  Epoch: 433  Training loss = 2.5438  Validation loss = 2.2732  \n",
      "\n",
      "Fold: 2  Epoch: 434  Training loss = 2.5436  Validation loss = 2.2726  \n",
      "\n",
      "Fold: 2  Epoch: 435  Training loss = 2.5432  Validation loss = 2.2717  \n",
      "\n",
      "Fold: 2  Epoch: 436  Training loss = 2.5432  Validation loss = 2.2716  \n",
      "\n",
      "Fold: 2  Epoch: 437  Training loss = 2.5429  Validation loss = 2.2708  \n",
      "\n",
      "Fold: 2  Epoch: 438  Training loss = 2.5426  Validation loss = 2.2701  \n",
      "\n",
      "Fold: 2  Epoch: 439  Training loss = 2.5424  Validation loss = 2.2695  \n",
      "\n",
      "Fold: 2  Epoch: 440  Training loss = 2.5422  Validation loss = 2.2689  \n",
      "\n",
      "Fold: 2  Epoch: 441  Training loss = 2.5421  Validation loss = 2.2687  \n",
      "\n",
      "Fold: 2  Epoch: 442  Training loss = 2.5420  Validation loss = 2.2682  \n",
      "\n",
      "Fold: 2  Epoch: 443  Training loss = 2.5417  Validation loss = 2.2675  \n",
      "\n",
      "Fold: 2  Epoch: 444  Training loss = 2.5415  Validation loss = 2.2670  \n",
      "\n",
      "Fold: 2  Epoch: 445  Training loss = 2.5412  Validation loss = 2.2660  \n",
      "\n",
      "Fold: 2  Epoch: 446  Training loss = 2.5410  Validation loss = 2.2656  \n",
      "\n",
      "Fold: 2  Epoch: 447  Training loss = 2.5407  Validation loss = 2.2647  \n",
      "\n",
      "Fold: 2  Epoch: 448  Training loss = 2.5404  Validation loss = 2.2639  \n",
      "\n",
      "Fold: 2  Epoch: 449  Training loss = 2.5401  Validation loss = 2.2632  \n",
      "\n",
      "Fold: 2  Epoch: 450  Training loss = 2.5399  Validation loss = 2.2626  \n",
      "\n",
      "Fold: 2  Epoch: 451  Training loss = 2.5398  Validation loss = 2.2623  \n",
      "\n",
      "Fold: 2  Epoch: 452  Training loss = 2.5397  Validation loss = 2.2620  \n",
      "\n",
      "Fold: 2  Epoch: 453  Training loss = 2.5393  Validation loss = 2.2611  \n",
      "\n",
      "Fold: 2  Epoch: 454  Training loss = 2.5392  Validation loss = 2.2609  \n",
      "\n",
      "Fold: 2  Epoch: 455  Training loss = 2.5390  Validation loss = 2.2606  \n",
      "\n",
      "Fold: 2  Epoch: 456  Training loss = 2.5388  Validation loss = 2.2601  \n",
      "\n",
      "Fold: 2  Epoch: 457  Training loss = 2.5385  Validation loss = 2.2593  \n",
      "\n",
      "Fold: 2  Epoch: 458  Training loss = 2.5385  Validation loss = 2.2591  \n",
      "\n",
      "Fold: 2  Epoch: 459  Training loss = 2.5384  Validation loss = 2.2590  \n",
      "\n",
      "Fold: 2  Epoch: 460  Training loss = 2.5383  Validation loss = 2.2587  \n",
      "\n",
      "Fold: 2  Epoch: 461  Training loss = 2.5382  Validation loss = 2.2581  \n",
      "\n",
      "Fold: 2  Epoch: 462  Training loss = 2.5380  Validation loss = 2.2578  \n",
      "\n",
      "Fold: 2  Epoch: 463  Training loss = 2.5378  Validation loss = 2.2570  \n",
      "\n",
      "Fold: 2  Epoch: 464  Training loss = 2.5376  Validation loss = 2.2565  \n",
      "\n",
      "Fold: 2  Epoch: 465  Training loss = 2.5375  Validation loss = 2.2562  \n",
      "\n",
      "Fold: 2  Epoch: 466  Training loss = 2.5373  Validation loss = 2.2555  \n",
      "\n",
      "Fold: 2  Epoch: 467  Training loss = 2.5371  Validation loss = 2.2549  \n",
      "\n",
      "Fold: 2  Epoch: 468  Training loss = 2.5370  Validation loss = 2.2544  \n",
      "\n",
      "Fold: 2  Epoch: 469  Training loss = 2.5367  Validation loss = 2.2538  \n",
      "\n",
      "Fold: 2  Epoch: 470  Training loss = 2.5365  Validation loss = 2.2532  \n",
      "\n",
      "Fold: 2  Epoch: 471  Training loss = 2.5361  Validation loss = 2.2520  \n",
      "\n",
      "Fold: 2  Epoch: 472  Training loss = 2.5359  Validation loss = 2.2514  \n",
      "\n",
      "Fold: 2  Epoch: 473  Training loss = 2.5359  Validation loss = 2.2513  \n",
      "\n",
      "Fold: 2  Epoch: 474  Training loss = 2.5359  Validation loss = 2.2513  \n",
      "\n",
      "Fold: 2  Epoch: 475  Training loss = 2.5357  Validation loss = 2.2509  \n",
      "\n",
      "Fold: 2  Epoch: 476  Training loss = 2.5357  Validation loss = 2.2506  \n",
      "\n",
      "Fold: 2  Epoch: 477  Training loss = 2.5352  Validation loss = 2.2496  \n",
      "\n",
      "Fold: 2  Epoch: 478  Training loss = 2.5349  Validation loss = 2.2485  \n",
      "\n",
      "Fold: 2  Epoch: 479  Training loss = 2.5349  Validation loss = 2.2483  \n",
      "\n",
      "Fold: 2  Epoch: 480  Training loss = 2.5345  Validation loss = 2.2474  \n",
      "\n",
      "Fold: 2  Epoch: 481  Training loss = 2.5345  Validation loss = 2.2473  \n",
      "\n",
      "Fold: 2  Epoch: 482  Training loss = 2.5344  Validation loss = 2.2470  \n",
      "\n",
      "Fold: 2  Epoch: 483  Training loss = 2.5342  Validation loss = 2.2463  \n",
      "\n",
      "Fold: 2  Epoch: 484  Training loss = 2.5341  Validation loss = 2.2460  \n",
      "\n",
      "Fold: 2  Epoch: 485  Training loss = 2.5340  Validation loss = 2.2459  \n",
      "\n",
      "Fold: 2  Epoch: 486  Training loss = 2.5338  Validation loss = 2.2452  \n",
      "\n",
      "Fold: 2  Epoch: 487  Training loss = 2.5337  Validation loss = 2.2450  \n",
      "\n",
      "Fold: 2  Epoch: 488  Training loss = 2.5335  Validation loss = 2.2444  \n",
      "\n",
      "Fold: 2  Epoch: 489  Training loss = 2.5334  Validation loss = 2.2441  \n",
      "\n",
      "Fold: 2  Epoch: 490  Training loss = 2.5331  Validation loss = 2.2431  \n",
      "\n",
      "Fold: 2  Epoch: 491  Training loss = 2.5327  Validation loss = 2.2422  \n",
      "\n",
      "Fold: 2  Epoch: 492  Training loss = 2.5324  Validation loss = 2.2413  \n",
      "\n",
      "Fold: 2  Epoch: 493  Training loss = 2.5323  Validation loss = 2.2411  \n",
      "\n",
      "Fold: 2  Epoch: 494  Training loss = 2.5320  Validation loss = 2.2403  \n",
      "\n",
      "Fold: 2  Epoch: 495  Training loss = 2.5317  Validation loss = 2.2395  \n",
      "\n",
      "Fold: 2  Epoch: 496  Training loss = 2.5314  Validation loss = 2.2386  \n",
      "\n",
      "Fold: 2  Epoch: 497  Training loss = 2.5311  Validation loss = 2.2378  \n",
      "\n",
      "Fold: 2  Epoch: 498  Training loss = 2.5310  Validation loss = 2.2375  \n",
      "\n",
      "Fold: 2  Epoch: 499  Training loss = 2.5305  Validation loss = 2.2363  \n",
      "\n",
      "Fold: 2  Epoch: 500  Training loss = 2.5304  Validation loss = 2.2358  \n",
      "\n",
      "Check model:  Fold: 2  Optimal epoch: 500  \n",
      "\n",
      "Fold: 3  Epoch: 1  Training loss = 1.5016  Validation loss = 3.7243  \n",
      "\n",
      "Fold: 3  Epoch: 2  Training loss = 1.5014  Validation loss = 3.7232  \n",
      "\n",
      "Fold: 3  Epoch: 3  Training loss = 1.5013  Validation loss = 3.7227  \n",
      "\n",
      "Fold: 3  Epoch: 4  Training loss = 1.5012  Validation loss = 3.7223  \n",
      "\n",
      "Fold: 3  Epoch: 5  Training loss = 1.5012  Validation loss = 3.7221  \n",
      "\n",
      "Fold: 3  Epoch: 6  Training loss = 1.5010  Validation loss = 3.7214  \n",
      "\n",
      "Fold: 3  Epoch: 7  Training loss = 1.5010  Validation loss = 3.7212  \n",
      "\n",
      "Fold: 3  Epoch: 8  Training loss = 1.5009  Validation loss = 3.7209  \n",
      "\n",
      "Fold: 3  Epoch: 9  Training loss = 1.5008  Validation loss = 3.7202  \n",
      "\n",
      "Fold: 3  Epoch: 10  Training loss = 1.5007  Validation loss = 3.7198  \n",
      "\n",
      "Fold: 3  Epoch: 11  Training loss = 1.5006  Validation loss = 3.7191  \n",
      "\n",
      "Fold: 3  Epoch: 12  Training loss = 1.5005  Validation loss = 3.7185  \n",
      "\n",
      "Fold: 3  Epoch: 13  Training loss = 1.5005  Validation loss = 3.7189  \n",
      "\n",
      "Fold: 3  Epoch: 14  Training loss = 1.5004  Validation loss = 3.7183  \n",
      "\n",
      "Fold: 3  Epoch: 15  Training loss = 1.5003  Validation loss = 3.7182  \n",
      "\n",
      "Fold: 3  Epoch: 16  Training loss = 1.5003  Validation loss = 3.7181  \n",
      "\n",
      "Fold: 3  Epoch: 17  Training loss = 1.5002  Validation loss = 3.7176  \n",
      "\n",
      "Fold: 3  Epoch: 18  Training loss = 1.5001  Validation loss = 3.7174  \n",
      "\n",
      "Fold: 3  Epoch: 19  Training loss = 1.5000  Validation loss = 3.7166  \n",
      "\n",
      "Fold: 3  Epoch: 20  Training loss = 1.5000  Validation loss = 3.7168  \n",
      "\n",
      "Fold: 3  Epoch: 21  Training loss = 1.4999  Validation loss = 3.7164  \n",
      "\n",
      "Fold: 3  Epoch: 22  Training loss = 1.4999  Validation loss = 3.7162  \n",
      "\n",
      "Fold: 3  Epoch: 23  Training loss = 1.4998  Validation loss = 3.7160  \n",
      "\n",
      "Fold: 3  Epoch: 24  Training loss = 1.4998  Validation loss = 3.7158  \n",
      "\n",
      "Fold: 3  Epoch: 25  Training loss = 1.4997  Validation loss = 3.7153  \n",
      "\n",
      "Fold: 3  Epoch: 26  Training loss = 1.4996  Validation loss = 3.7146  \n",
      "\n",
      "Fold: 3  Epoch: 27  Training loss = 1.4995  Validation loss = 3.7144  \n",
      "\n",
      "Fold: 3  Epoch: 28  Training loss = 1.4994  Validation loss = 3.7141  \n",
      "\n",
      "Fold: 3  Epoch: 29  Training loss = 1.4994  Validation loss = 3.7140  \n",
      "\n",
      "Fold: 3  Epoch: 30  Training loss = 1.4994  Validation loss = 3.7140  \n",
      "\n",
      "Fold: 3  Epoch: 31  Training loss = 1.4994  Validation loss = 3.7138  \n",
      "\n",
      "Fold: 3  Epoch: 32  Training loss = 1.4993  Validation loss = 3.7135  \n",
      "\n",
      "Fold: 3  Epoch: 33  Training loss = 1.4992  Validation loss = 3.7132  \n",
      "\n",
      "Fold: 3  Epoch: 34  Training loss = 1.4990  Validation loss = 3.7122  \n",
      "\n",
      "Fold: 3  Epoch: 35  Training loss = 1.4990  Validation loss = 3.7121  \n",
      "\n",
      "Fold: 3  Epoch: 36  Training loss = 1.4990  Validation loss = 3.7118  \n",
      "\n",
      "Fold: 3  Epoch: 37  Training loss = 1.4988  Validation loss = 3.7112  \n",
      "\n",
      "Fold: 3  Epoch: 38  Training loss = 1.4988  Validation loss = 3.7109  \n",
      "\n",
      "Fold: 3  Epoch: 39  Training loss = 1.4987  Validation loss = 3.7103  \n",
      "\n",
      "Fold: 3  Epoch: 40  Training loss = 1.4985  Validation loss = 3.7095  \n",
      "\n",
      "Fold: 3  Epoch: 41  Training loss = 1.4985  Validation loss = 3.7095  \n",
      "\n",
      "Fold: 3  Epoch: 42  Training loss = 1.4984  Validation loss = 3.7091  \n",
      "\n",
      "Fold: 3  Epoch: 43  Training loss = 1.4984  Validation loss = 3.7087  \n",
      "\n",
      "Fold: 3  Epoch: 44  Training loss = 1.4983  Validation loss = 3.7082  \n",
      "\n",
      "Fold: 3  Epoch: 45  Training loss = 1.4982  Validation loss = 3.7080  \n",
      "\n",
      "Fold: 3  Epoch: 46  Training loss = 1.4982  Validation loss = 3.7076  \n",
      "\n",
      "Fold: 3  Epoch: 47  Training loss = 1.4980  Validation loss = 3.7067  \n",
      "\n",
      "Fold: 3  Epoch: 48  Training loss = 1.4979  Validation loss = 3.7061  \n",
      "\n",
      "Fold: 3  Epoch: 49  Training loss = 1.4978  Validation loss = 3.7058  \n",
      "\n",
      "Fold: 3  Epoch: 50  Training loss = 1.4978  Validation loss = 3.7055  \n",
      "\n",
      "Fold: 3  Epoch: 51  Training loss = 1.4977  Validation loss = 3.7051  \n",
      "\n",
      "Fold: 3  Epoch: 52  Training loss = 1.4976  Validation loss = 3.7049  \n",
      "\n",
      "Fold: 3  Epoch: 53  Training loss = 1.4976  Validation loss = 3.7046  \n",
      "\n",
      "Fold: 3  Epoch: 54  Training loss = 1.4975  Validation loss = 3.7045  \n",
      "\n",
      "Fold: 3  Epoch: 55  Training loss = 1.4975  Validation loss = 3.7042  \n",
      "\n",
      "Fold: 3  Epoch: 56  Training loss = 1.4974  Validation loss = 3.7038  \n",
      "\n",
      "Fold: 3  Epoch: 57  Training loss = 1.4973  Validation loss = 3.7032  \n",
      "\n",
      "Fold: 3  Epoch: 58  Training loss = 1.4971  Validation loss = 3.7022  \n",
      "\n",
      "Fold: 3  Epoch: 59  Training loss = 1.4970  Validation loss = 3.7015  \n",
      "\n",
      "Fold: 3  Epoch: 60  Training loss = 1.4969  Validation loss = 3.7011  \n",
      "\n",
      "Fold: 3  Epoch: 61  Training loss = 1.4968  Validation loss = 3.7006  \n",
      "\n",
      "Fold: 3  Epoch: 62  Training loss = 1.4967  Validation loss = 3.7001  \n",
      "\n",
      "Fold: 3  Epoch: 63  Training loss = 1.4966  Validation loss = 3.6996  \n",
      "\n",
      "Fold: 3  Epoch: 64  Training loss = 1.4966  Validation loss = 3.6996  \n",
      "\n",
      "Fold: 3  Epoch: 65  Training loss = 1.4965  Validation loss = 3.6988  \n",
      "\n",
      "Fold: 3  Epoch: 66  Training loss = 1.4964  Validation loss = 3.6982  \n",
      "\n",
      "Fold: 3  Epoch: 67  Training loss = 1.4963  Validation loss = 3.6977  \n",
      "\n",
      "Fold: 3  Epoch: 68  Training loss = 1.4962  Validation loss = 3.6974  \n",
      "\n",
      "Fold: 3  Epoch: 69  Training loss = 1.4960  Validation loss = 3.6964  \n",
      "\n",
      "Fold: 3  Epoch: 70  Training loss = 1.4960  Validation loss = 3.6960  \n",
      "\n",
      "Fold: 3  Epoch: 71  Training loss = 1.4959  Validation loss = 3.6956  \n",
      "\n",
      "Fold: 3  Epoch: 72  Training loss = 1.4958  Validation loss = 3.6951  \n",
      "\n",
      "Fold: 3  Epoch: 73  Training loss = 1.4958  Validation loss = 3.6950  \n",
      "\n",
      "Fold: 3  Epoch: 74  Training loss = 1.4957  Validation loss = 3.6946  \n",
      "\n",
      "Fold: 3  Epoch: 75  Training loss = 1.4955  Validation loss = 3.6938  \n",
      "\n",
      "Fold: 3  Epoch: 76  Training loss = 1.4955  Validation loss = 3.6938  \n",
      "\n",
      "Fold: 3  Epoch: 77  Training loss = 1.4955  Validation loss = 3.6936  \n",
      "\n",
      "Fold: 3  Epoch: 78  Training loss = 1.4955  Validation loss = 3.6935  \n",
      "\n",
      "Fold: 3  Epoch: 79  Training loss = 1.4954  Validation loss = 3.6932  \n",
      "\n",
      "Fold: 3  Epoch: 80  Training loss = 1.4953  Validation loss = 3.6921  \n",
      "\n",
      "Fold: 3  Epoch: 81  Training loss = 1.4951  Validation loss = 3.6909  \n",
      "\n",
      "Fold: 3  Epoch: 82  Training loss = 1.4950  Validation loss = 3.6907  \n",
      "\n",
      "Fold: 3  Epoch: 83  Training loss = 1.4949  Validation loss = 3.6900  \n",
      "\n",
      "Fold: 3  Epoch: 84  Training loss = 1.4949  Validation loss = 3.6897  \n",
      "\n",
      "Fold: 3  Epoch: 85  Training loss = 1.4948  Validation loss = 3.6892  \n",
      "\n",
      "Fold: 3  Epoch: 86  Training loss = 1.4948  Validation loss = 3.6896  \n",
      "\n",
      "Fold: 3  Epoch: 87  Training loss = 1.4947  Validation loss = 3.6892  \n",
      "\n",
      "Fold: 3  Epoch: 88  Training loss = 1.4946  Validation loss = 3.6884  \n",
      "\n",
      "Fold: 3  Epoch: 89  Training loss = 1.4945  Validation loss = 3.6881  \n",
      "\n",
      "Fold: 3  Epoch: 90  Training loss = 1.4945  Validation loss = 3.6878  \n",
      "\n",
      "Fold: 3  Epoch: 91  Training loss = 1.4945  Validation loss = 3.6879  \n",
      "\n",
      "Fold: 3  Epoch: 92  Training loss = 1.4944  Validation loss = 3.6874  \n",
      "\n",
      "Fold: 3  Epoch: 93  Training loss = 1.4943  Validation loss = 3.6868  \n",
      "\n",
      "Fold: 3  Epoch: 94  Training loss = 1.4942  Validation loss = 3.6863  \n",
      "\n",
      "Fold: 3  Epoch: 95  Training loss = 1.4942  Validation loss = 3.6860  \n",
      "\n",
      "Fold: 3  Epoch: 96  Training loss = 1.4941  Validation loss = 3.6858  \n",
      "\n",
      "Fold: 3  Epoch: 97  Training loss = 1.4940  Validation loss = 3.6851  \n",
      "\n",
      "Fold: 3  Epoch: 98  Training loss = 1.4939  Validation loss = 3.6849  \n",
      "\n",
      "Fold: 3  Epoch: 99  Training loss = 1.4939  Validation loss = 3.6844  \n",
      "\n",
      "Fold: 3  Epoch: 100  Training loss = 1.4937  Validation loss = 3.6838  \n",
      "\n",
      "Fold: 3  Epoch: 101  Training loss = 1.4937  Validation loss = 3.6834  \n",
      "\n",
      "Fold: 3  Epoch: 102  Training loss = 1.4936  Validation loss = 3.6828  \n",
      "\n",
      "Fold: 3  Epoch: 103  Training loss = 1.4934  Validation loss = 3.6817  \n",
      "\n",
      "Fold: 3  Epoch: 104  Training loss = 1.4933  Validation loss = 3.6812  \n",
      "\n",
      "Fold: 3  Epoch: 105  Training loss = 1.4932  Validation loss = 3.6810  \n",
      "\n",
      "Fold: 3  Epoch: 106  Training loss = 1.4931  Validation loss = 3.6805  \n",
      "\n",
      "Fold: 3  Epoch: 107  Training loss = 1.4930  Validation loss = 3.6799  \n",
      "\n",
      "Fold: 3  Epoch: 108  Training loss = 1.4929  Validation loss = 3.6792  \n",
      "\n",
      "Fold: 3  Epoch: 109  Training loss = 1.4929  Validation loss = 3.6793  \n",
      "\n",
      "Fold: 3  Epoch: 110  Training loss = 1.4929  Validation loss = 3.6794  \n",
      "\n",
      "Fold: 3  Epoch: 111  Training loss = 1.4928  Validation loss = 3.6791  \n",
      "\n",
      "Fold: 3  Epoch: 112  Training loss = 1.4927  Validation loss = 3.6780  \n",
      "\n",
      "Fold: 3  Epoch: 113  Training loss = 1.4926  Validation loss = 3.6777  \n",
      "\n",
      "Fold: 3  Epoch: 114  Training loss = 1.4926  Validation loss = 3.6777  \n",
      "\n",
      "Fold: 3  Epoch: 115  Training loss = 1.4925  Validation loss = 3.6772  \n",
      "\n",
      "Fold: 3  Epoch: 116  Training loss = 1.4925  Validation loss = 3.6771  \n",
      "\n",
      "Fold: 3  Epoch: 117  Training loss = 1.4924  Validation loss = 3.6767  \n",
      "\n",
      "Fold: 3  Epoch: 118  Training loss = 1.4923  Validation loss = 3.6760  \n",
      "\n",
      "Fold: 3  Epoch: 119  Training loss = 1.4921  Validation loss = 3.6749  \n",
      "\n",
      "Fold: 3  Epoch: 120  Training loss = 1.4921  Validation loss = 3.6748  \n",
      "\n",
      "Fold: 3  Epoch: 121  Training loss = 1.4921  Validation loss = 3.6748  \n",
      "\n",
      "Fold: 3  Epoch: 122  Training loss = 1.4920  Validation loss = 3.6740  \n",
      "\n",
      "Fold: 3  Epoch: 123  Training loss = 1.4919  Validation loss = 3.6738  \n",
      "\n",
      "Fold: 3  Epoch: 124  Training loss = 1.4919  Validation loss = 3.6739  \n",
      "\n",
      "Fold: 3  Epoch: 125  Training loss = 1.4918  Validation loss = 3.6733  \n",
      "\n",
      "Fold: 3  Epoch: 126  Training loss = 1.4917  Validation loss = 3.6729  \n",
      "\n",
      "Fold: 3  Epoch: 127  Training loss = 1.4917  Validation loss = 3.6729  \n",
      "\n",
      "Fold: 3  Epoch: 128  Training loss = 1.4916  Validation loss = 3.6722  \n",
      "\n",
      "Fold: 3  Epoch: 129  Training loss = 1.4915  Validation loss = 3.6719  \n",
      "\n",
      "Fold: 3  Epoch: 130  Training loss = 1.4915  Validation loss = 3.6714  \n",
      "\n",
      "Fold: 3  Epoch: 131  Training loss = 1.4914  Validation loss = 3.6710  \n",
      "\n",
      "Fold: 3  Epoch: 132  Training loss = 1.4913  Validation loss = 3.6708  \n",
      "\n",
      "Fold: 3  Epoch: 133  Training loss = 1.4912  Validation loss = 3.6703  \n",
      "\n",
      "Fold: 3  Epoch: 134  Training loss = 1.4911  Validation loss = 3.6696  \n",
      "\n",
      "Fold: 3  Epoch: 135  Training loss = 1.4911  Validation loss = 3.6693  \n",
      "\n",
      "Fold: 3  Epoch: 136  Training loss = 1.4911  Validation loss = 3.6693  \n",
      "\n",
      "Fold: 3  Epoch: 137  Training loss = 1.4909  Validation loss = 3.6684  \n",
      "\n",
      "Fold: 3  Epoch: 138  Training loss = 1.4909  Validation loss = 3.6685  \n",
      "\n",
      "Fold: 3  Epoch: 139  Training loss = 1.4909  Validation loss = 3.6686  \n",
      "\n",
      "Fold: 3  Epoch: 140  Training loss = 1.4908  Validation loss = 3.6680  \n",
      "\n",
      "Fold: 3  Epoch: 141  Training loss = 1.4907  Validation loss = 3.6673  \n",
      "\n",
      "Fold: 3  Epoch: 142  Training loss = 1.4907  Validation loss = 3.6671  \n",
      "\n",
      "Fold: 3  Epoch: 143  Training loss = 1.4907  Validation loss = 3.6670  \n",
      "\n",
      "Fold: 3  Epoch: 144  Training loss = 1.4906  Validation loss = 3.6668  \n",
      "\n",
      "Fold: 3  Epoch: 145  Training loss = 1.4905  Validation loss = 3.6660  \n",
      "\n",
      "Fold: 3  Epoch: 146  Training loss = 1.4903  Validation loss = 3.6651  \n",
      "\n",
      "Fold: 3  Epoch: 147  Training loss = 1.4903  Validation loss = 3.6648  \n",
      "\n",
      "Fold: 3  Epoch: 148  Training loss = 1.4902  Validation loss = 3.6640  \n",
      "\n",
      "Fold: 3  Epoch: 149  Training loss = 1.4901  Validation loss = 3.6635  \n",
      "\n",
      "Fold: 3  Epoch: 150  Training loss = 1.4900  Validation loss = 3.6628  \n",
      "\n",
      "Fold: 3  Epoch: 151  Training loss = 1.4899  Validation loss = 3.6624  \n",
      "\n",
      "Fold: 3  Epoch: 152  Training loss = 1.4898  Validation loss = 3.6620  \n",
      "\n",
      "Fold: 3  Epoch: 153  Training loss = 1.4898  Validation loss = 3.6616  \n",
      "\n",
      "Fold: 3  Epoch: 154  Training loss = 1.4897  Validation loss = 3.6613  \n",
      "\n",
      "Fold: 3  Epoch: 155  Training loss = 1.4897  Validation loss = 3.6612  \n",
      "\n",
      "Fold: 3  Epoch: 156  Training loss = 1.4896  Validation loss = 3.6606  \n",
      "\n",
      "Fold: 3  Epoch: 157  Training loss = 1.4897  Validation loss = 3.6610  \n",
      "\n",
      "Fold: 3  Epoch: 158  Training loss = 1.4896  Validation loss = 3.6607  \n",
      "\n",
      "Fold: 3  Epoch: 159  Training loss = 1.4895  Validation loss = 3.6603  \n",
      "\n",
      "Fold: 3  Epoch: 160  Training loss = 1.4894  Validation loss = 3.6598  \n",
      "\n",
      "Fold: 3  Epoch: 161  Training loss = 1.4893  Validation loss = 3.6591  \n",
      "\n",
      "Fold: 3  Epoch: 162  Training loss = 1.4893  Validation loss = 3.6593  \n",
      "\n",
      "Fold: 3  Epoch: 163  Training loss = 1.4892  Validation loss = 3.6587  \n",
      "\n",
      "Fold: 3  Epoch: 164  Training loss = 1.4892  Validation loss = 3.6582  \n",
      "\n",
      "Fold: 3  Epoch: 165  Training loss = 1.4890  Validation loss = 3.6572  \n",
      "\n",
      "Fold: 3  Epoch: 166  Training loss = 1.4890  Validation loss = 3.6572  \n",
      "\n",
      "Fold: 3  Epoch: 167  Training loss = 1.4890  Validation loss = 3.6568  \n",
      "\n",
      "Fold: 3  Epoch: 168  Training loss = 1.4889  Validation loss = 3.6564  \n",
      "\n",
      "Fold: 3  Epoch: 169  Training loss = 1.4888  Validation loss = 3.6557  \n",
      "\n",
      "Fold: 3  Epoch: 170  Training loss = 1.4887  Validation loss = 3.6551  \n",
      "\n",
      "Fold: 3  Epoch: 171  Training loss = 1.4886  Validation loss = 3.6547  \n",
      "\n",
      "Fold: 3  Epoch: 172  Training loss = 1.4886  Validation loss = 3.6544  \n",
      "\n",
      "Fold: 3  Epoch: 173  Training loss = 1.4886  Validation loss = 3.6545  \n",
      "\n",
      "Fold: 3  Epoch: 174  Training loss = 1.4886  Validation loss = 3.6543  \n",
      "\n",
      "Fold: 3  Epoch: 175  Training loss = 1.4886  Validation loss = 3.6544  \n",
      "\n",
      "Fold: 3  Epoch: 176  Training loss = 1.4885  Validation loss = 3.6541  \n",
      "\n",
      "Fold: 3  Epoch: 177  Training loss = 1.4884  Validation loss = 3.6535  \n",
      "\n",
      "Fold: 3  Epoch: 178  Training loss = 1.4883  Validation loss = 3.6529  \n",
      "\n",
      "Fold: 3  Epoch: 179  Training loss = 1.4882  Validation loss = 3.6520  \n",
      "\n",
      "Fold: 3  Epoch: 180  Training loss = 1.4882  Validation loss = 3.6520  \n",
      "\n",
      "Fold: 3  Epoch: 181  Training loss = 1.4882  Validation loss = 3.6518  \n",
      "\n",
      "Fold: 3  Epoch: 182  Training loss = 1.4881  Validation loss = 3.6518  \n",
      "\n",
      "Fold: 3  Epoch: 183  Training loss = 1.4880  Validation loss = 3.6511  \n",
      "\n",
      "Fold: 3  Epoch: 184  Training loss = 1.4880  Validation loss = 3.6507  \n",
      "\n",
      "Fold: 3  Epoch: 185  Training loss = 1.4879  Validation loss = 3.6503  \n",
      "\n",
      "Fold: 3  Epoch: 186  Training loss = 1.4879  Validation loss = 3.6499  \n",
      "\n",
      "Fold: 3  Epoch: 187  Training loss = 1.4878  Validation loss = 3.6494  \n",
      "\n",
      "Fold: 3  Epoch: 188  Training loss = 1.4877  Validation loss = 3.6489  \n",
      "\n",
      "Fold: 3  Epoch: 189  Training loss = 1.4876  Validation loss = 3.6484  \n",
      "\n",
      "Fold: 3  Epoch: 190  Training loss = 1.4876  Validation loss = 3.6481  \n",
      "\n",
      "Fold: 3  Epoch: 191  Training loss = 1.4875  Validation loss = 3.6480  \n",
      "\n",
      "Fold: 3  Epoch: 192  Training loss = 1.4875  Validation loss = 3.6477  \n",
      "\n",
      "Fold: 3  Epoch: 193  Training loss = 1.4874  Validation loss = 3.6475  \n",
      "\n",
      "Fold: 3  Epoch: 194  Training loss = 1.4873  Validation loss = 3.6467  \n",
      "\n",
      "Fold: 3  Epoch: 195  Training loss = 1.4873  Validation loss = 3.6462  \n",
      "\n",
      "Fold: 3  Epoch: 196  Training loss = 1.4872  Validation loss = 3.6457  \n",
      "\n",
      "Fold: 3  Epoch: 197  Training loss = 1.4871  Validation loss = 3.6455  \n",
      "\n",
      "Fold: 3  Epoch: 198  Training loss = 1.4870  Validation loss = 3.6449  \n",
      "\n",
      "Fold: 3  Epoch: 199  Training loss = 1.4870  Validation loss = 3.6446  \n",
      "\n",
      "Fold: 3  Epoch: 200  Training loss = 1.4870  Validation loss = 3.6444  \n",
      "\n",
      "Fold: 3  Epoch: 201  Training loss = 1.4870  Validation loss = 3.6448  \n",
      "\n",
      "Fold: 3  Epoch: 202  Training loss = 1.4869  Validation loss = 3.6445  \n",
      "\n",
      "Fold: 3  Epoch: 203  Training loss = 1.4869  Validation loss = 3.6445  \n",
      "\n",
      "Fold: 3  Epoch: 204  Training loss = 1.4869  Validation loss = 3.6444  \n",
      "\n",
      "Fold: 3  Epoch: 205  Training loss = 1.4868  Validation loss = 3.6437  \n",
      "\n",
      "Fold: 3  Epoch: 206  Training loss = 1.4867  Validation loss = 3.6431  \n",
      "\n",
      "Fold: 3  Epoch: 207  Training loss = 1.4867  Validation loss = 3.6429  \n",
      "\n",
      "Fold: 3  Epoch: 208  Training loss = 1.4866  Validation loss = 3.6425  \n",
      "\n",
      "Fold: 3  Epoch: 209  Training loss = 1.4865  Validation loss = 3.6421  \n",
      "\n",
      "Fold: 3  Epoch: 210  Training loss = 1.4865  Validation loss = 3.6422  \n",
      "\n",
      "Fold: 3  Epoch: 211  Training loss = 1.4865  Validation loss = 3.6419  \n",
      "\n",
      "Fold: 3  Epoch: 212  Training loss = 1.4865  Validation loss = 3.6420  \n",
      "\n",
      "Fold: 3  Epoch: 213  Training loss = 1.4864  Validation loss = 3.6417  \n",
      "\n",
      "Fold: 3  Epoch: 214  Training loss = 1.4864  Validation loss = 3.6414  \n",
      "\n",
      "Fold: 3  Epoch: 215  Training loss = 1.4863  Validation loss = 3.6407  \n",
      "\n",
      "Fold: 3  Epoch: 216  Training loss = 1.4862  Validation loss = 3.6403  \n",
      "\n",
      "Fold: 3  Epoch: 217  Training loss = 1.4861  Validation loss = 3.6396  \n",
      "\n",
      "Fold: 3  Epoch: 218  Training loss = 1.4861  Validation loss = 3.6392  \n",
      "\n",
      "Fold: 3  Epoch: 219  Training loss = 1.4861  Validation loss = 3.6398  \n",
      "\n",
      "Fold: 3  Epoch: 220  Training loss = 1.4861  Validation loss = 3.6396  \n",
      "\n",
      "Fold: 3  Epoch: 221  Training loss = 1.4861  Validation loss = 3.6393  \n",
      "\n",
      "Fold: 3  Epoch: 222  Training loss = 1.4859  Validation loss = 3.6385  \n",
      "\n",
      "Fold: 3  Epoch: 223  Training loss = 1.4859  Validation loss = 3.6381  \n",
      "\n",
      "Fold: 3  Epoch: 224  Training loss = 1.4858  Validation loss = 3.6377  \n",
      "\n",
      "Fold: 3  Epoch: 225  Training loss = 1.4857  Validation loss = 3.6370  \n",
      "\n",
      "Fold: 3  Epoch: 226  Training loss = 1.4857  Validation loss = 3.6365  \n",
      "\n",
      "Fold: 3  Epoch: 227  Training loss = 1.4856  Validation loss = 3.6362  \n",
      "\n",
      "Fold: 3  Epoch: 228  Training loss = 1.4855  Validation loss = 3.6354  \n",
      "\n",
      "Fold: 3  Epoch: 229  Training loss = 1.4855  Validation loss = 3.6354  \n",
      "\n",
      "Fold: 3  Epoch: 230  Training loss = 1.4855  Validation loss = 3.6352  \n",
      "\n",
      "Fold: 3  Epoch: 231  Training loss = 1.4854  Validation loss = 3.6350  \n",
      "\n",
      "Fold: 3  Epoch: 232  Training loss = 1.4853  Validation loss = 3.6341  \n",
      "\n",
      "Fold: 3  Epoch: 233  Training loss = 1.4852  Validation loss = 3.6336  \n",
      "\n",
      "Fold: 3  Epoch: 234  Training loss = 1.4852  Validation loss = 3.6332  \n",
      "\n",
      "Fold: 3  Epoch: 235  Training loss = 1.4852  Validation loss = 3.6330  \n",
      "\n",
      "Fold: 3  Epoch: 236  Training loss = 1.4851  Validation loss = 3.6327  \n",
      "\n",
      "Fold: 3  Epoch: 237  Training loss = 1.4851  Validation loss = 3.6323  \n",
      "\n",
      "Fold: 3  Epoch: 238  Training loss = 1.4850  Validation loss = 3.6319  \n",
      "\n",
      "Fold: 3  Epoch: 239  Training loss = 1.4850  Validation loss = 3.6317  \n",
      "\n",
      "Fold: 3  Epoch: 240  Training loss = 1.4849  Validation loss = 3.6311  \n",
      "\n",
      "Fold: 3  Epoch: 241  Training loss = 1.4849  Validation loss = 3.6316  \n",
      "\n",
      "Fold: 3  Epoch: 242  Training loss = 1.4850  Validation loss = 3.6317  \n",
      "\n",
      "Fold: 3  Epoch: 243  Training loss = 1.4849  Validation loss = 3.6315  \n",
      "\n",
      "Fold: 3  Epoch: 244  Training loss = 1.4848  Validation loss = 3.6310  \n",
      "\n",
      "Fold: 3  Epoch: 245  Training loss = 1.4848  Validation loss = 3.6312  \n",
      "\n",
      "Fold: 3  Epoch: 246  Training loss = 1.4848  Validation loss = 3.6312  \n",
      "\n",
      "Fold: 3  Epoch: 247  Training loss = 1.4848  Validation loss = 3.6309  \n",
      "\n",
      "Fold: 3  Epoch: 248  Training loss = 1.4847  Validation loss = 3.6306  \n",
      "\n",
      "Fold: 3  Epoch: 249  Training loss = 1.4847  Validation loss = 3.6306  \n",
      "\n",
      "Fold: 3  Epoch: 250  Training loss = 1.4847  Validation loss = 3.6302  \n",
      "\n",
      "Fold: 3  Epoch: 251  Training loss = 1.4846  Validation loss = 3.6298  \n",
      "\n",
      "Fold: 3  Epoch: 252  Training loss = 1.4846  Validation loss = 3.6298  \n",
      "\n",
      "Fold: 3  Epoch: 253  Training loss = 1.4846  Validation loss = 3.6297  \n",
      "\n",
      "Fold: 3  Epoch: 254  Training loss = 1.4845  Validation loss = 3.6292  \n",
      "\n",
      "Fold: 3  Epoch: 255  Training loss = 1.4845  Validation loss = 3.6289  \n",
      "\n",
      "Fold: 3  Epoch: 256  Training loss = 1.4845  Validation loss = 3.6289  \n",
      "\n",
      "Fold: 3  Epoch: 257  Training loss = 1.4845  Validation loss = 3.6288  \n",
      "\n",
      "Fold: 3  Epoch: 258  Training loss = 1.4844  Validation loss = 3.6284  \n",
      "\n",
      "Fold: 3  Epoch: 259  Training loss = 1.4844  Validation loss = 3.6282  \n",
      "\n",
      "Fold: 3  Epoch: 260  Training loss = 1.4843  Validation loss = 3.6279  \n",
      "\n",
      "Fold: 3  Epoch: 261  Training loss = 1.4844  Validation loss = 3.6280  \n",
      "\n",
      "Fold: 3  Epoch: 262  Training loss = 1.4843  Validation loss = 3.6276  \n",
      "\n",
      "Fold: 3  Epoch: 263  Training loss = 1.4843  Validation loss = 3.6275  \n",
      "\n",
      "Fold: 3  Epoch: 264  Training loss = 1.4842  Validation loss = 3.6272  \n",
      "\n",
      "Fold: 3  Epoch: 265  Training loss = 1.4842  Validation loss = 3.6266  \n",
      "\n",
      "Fold: 3  Epoch: 266  Training loss = 1.4841  Validation loss = 3.6263  \n",
      "\n",
      "Fold: 3  Epoch: 267  Training loss = 1.4841  Validation loss = 3.6261  \n",
      "\n",
      "Fold: 3  Epoch: 268  Training loss = 1.4840  Validation loss = 3.6256  \n",
      "\n",
      "Fold: 3  Epoch: 269  Training loss = 1.4840  Validation loss = 3.6256  \n",
      "\n",
      "Fold: 3  Epoch: 270  Training loss = 1.4839  Validation loss = 3.6252  \n",
      "\n",
      "Fold: 3  Epoch: 271  Training loss = 1.4839  Validation loss = 3.6251  \n",
      "\n",
      "Fold: 3  Epoch: 272  Training loss = 1.4838  Validation loss = 3.6245  \n",
      "\n",
      "Fold: 3  Epoch: 273  Training loss = 1.4838  Validation loss = 3.6244  \n",
      "\n",
      "Fold: 3  Epoch: 274  Training loss = 1.4838  Validation loss = 3.6240  \n",
      "\n",
      "Fold: 3  Epoch: 275  Training loss = 1.4838  Validation loss = 3.6240  \n",
      "\n",
      "Fold: 3  Epoch: 276  Training loss = 1.4837  Validation loss = 3.6237  \n",
      "\n",
      "Fold: 3  Epoch: 277  Training loss = 1.4836  Validation loss = 3.6231  \n",
      "\n",
      "Fold: 3  Epoch: 278  Training loss = 1.4836  Validation loss = 3.6231  \n",
      "\n",
      "Fold: 3  Epoch: 279  Training loss = 1.4836  Validation loss = 3.6233  \n",
      "\n",
      "Fold: 3  Epoch: 280  Training loss = 1.4836  Validation loss = 3.6230  \n",
      "\n",
      "Fold: 3  Epoch: 281  Training loss = 1.4835  Validation loss = 3.6225  \n",
      "\n",
      "Fold: 3  Epoch: 282  Training loss = 1.4834  Validation loss = 3.6219  \n",
      "\n",
      "Fold: 3  Epoch: 283  Training loss = 1.4834  Validation loss = 3.6217  \n",
      "\n",
      "Fold: 3  Epoch: 284  Training loss = 1.4834  Validation loss = 3.6216  \n",
      "\n",
      "Fold: 3  Epoch: 285  Training loss = 1.4833  Validation loss = 3.6211  \n",
      "\n",
      "Fold: 3  Epoch: 286  Training loss = 1.4833  Validation loss = 3.6208  \n",
      "\n",
      "Fold: 3  Epoch: 287  Training loss = 1.4832  Validation loss = 3.6203  \n",
      "\n",
      "Fold: 3  Epoch: 288  Training loss = 1.4832  Validation loss = 3.6200  \n",
      "\n",
      "Fold: 3  Epoch: 289  Training loss = 1.4832  Validation loss = 3.6201  \n",
      "\n",
      "Fold: 3  Epoch: 290  Training loss = 1.4831  Validation loss = 3.6197  \n",
      "\n",
      "Fold: 3  Epoch: 291  Training loss = 1.4831  Validation loss = 3.6194  \n",
      "\n",
      "Fold: 3  Epoch: 292  Training loss = 1.4830  Validation loss = 3.6187  \n",
      "\n",
      "Fold: 3  Epoch: 293  Training loss = 1.4830  Validation loss = 3.6186  \n",
      "\n",
      "Fold: 3  Epoch: 294  Training loss = 1.4830  Validation loss = 3.6188  \n",
      "\n",
      "Fold: 3  Epoch: 295  Training loss = 1.4829  Validation loss = 3.6181  \n",
      "\n",
      "Fold: 3  Epoch: 296  Training loss = 1.4828  Validation loss = 3.6172  \n",
      "\n",
      "Fold: 3  Epoch: 297  Training loss = 1.4827  Validation loss = 3.6172  \n",
      "\n",
      "Fold: 3  Epoch: 298  Training loss = 1.4827  Validation loss = 3.6167  \n",
      "\n",
      "Fold: 3  Epoch: 299  Training loss = 1.4827  Validation loss = 3.6167  \n",
      "\n",
      "Fold: 3  Epoch: 300  Training loss = 1.4826  Validation loss = 3.6164  \n",
      "\n",
      "Fold: 3  Epoch: 301  Training loss = 1.4825  Validation loss = 3.6154  \n",
      "\n",
      "Fold: 3  Epoch: 302  Training loss = 1.4824  Validation loss = 3.6149  \n",
      "\n",
      "Fold: 3  Epoch: 303  Training loss = 1.4824  Validation loss = 3.6148  \n",
      "\n",
      "Fold: 3  Epoch: 304  Training loss = 1.4823  Validation loss = 3.6141  \n",
      "\n",
      "Fold: 3  Epoch: 305  Training loss = 1.4823  Validation loss = 3.6138  \n",
      "\n",
      "Fold: 3  Epoch: 306  Training loss = 1.4822  Validation loss = 3.6134  \n",
      "\n",
      "Fold: 3  Epoch: 307  Training loss = 1.4822  Validation loss = 3.6129  \n",
      "\n",
      "Fold: 3  Epoch: 308  Training loss = 1.4821  Validation loss = 3.6126  \n",
      "\n",
      "Fold: 3  Epoch: 309  Training loss = 1.4822  Validation loss = 3.6126  \n",
      "\n",
      "Fold: 3  Epoch: 310  Training loss = 1.4821  Validation loss = 3.6125  \n",
      "\n",
      "Fold: 3  Epoch: 311  Training loss = 1.4821  Validation loss = 3.6121  \n",
      "\n",
      "Fold: 3  Epoch: 312  Training loss = 1.4820  Validation loss = 3.6119  \n",
      "\n",
      "Fold: 3  Epoch: 313  Training loss = 1.4820  Validation loss = 3.6118  \n",
      "\n",
      "Fold: 3  Epoch: 314  Training loss = 1.4820  Validation loss = 3.6118  \n",
      "\n",
      "Fold: 3  Epoch: 315  Training loss = 1.4820  Validation loss = 3.6118  \n",
      "\n",
      "Fold: 3  Epoch: 316  Training loss = 1.4820  Validation loss = 3.6115  \n",
      "\n",
      "Fold: 3  Epoch: 317  Training loss = 1.4820  Validation loss = 3.6114  \n",
      "\n",
      "Fold: 3  Epoch: 318  Training loss = 1.4819  Validation loss = 3.6109  \n",
      "\n",
      "Fold: 3  Epoch: 319  Training loss = 1.4819  Validation loss = 3.6105  \n",
      "\n",
      "Fold: 3  Epoch: 320  Training loss = 1.4818  Validation loss = 3.6100  \n",
      "\n",
      "Fold: 3  Epoch: 321  Training loss = 1.4818  Validation loss = 3.6099  \n",
      "\n",
      "Fold: 3  Epoch: 322  Training loss = 1.4817  Validation loss = 3.6092  \n",
      "\n",
      "Fold: 3  Epoch: 323  Training loss = 1.4816  Validation loss = 3.6089  \n",
      "\n",
      "Fold: 3  Epoch: 324  Training loss = 1.4816  Validation loss = 3.6085  \n",
      "\n",
      "Fold: 3  Epoch: 325  Training loss = 1.4815  Validation loss = 3.6079  \n",
      "\n",
      "Fold: 3  Epoch: 326  Training loss = 1.4815  Validation loss = 3.6078  \n",
      "\n",
      "Fold: 3  Epoch: 327  Training loss = 1.4815  Validation loss = 3.6081  \n",
      "\n",
      "Fold: 3  Epoch: 328  Training loss = 1.4814  Validation loss = 3.6078  \n",
      "\n",
      "Fold: 3  Epoch: 329  Training loss = 1.4814  Validation loss = 3.6075  \n",
      "\n",
      "Fold: 3  Epoch: 330  Training loss = 1.4813  Validation loss = 3.6071  \n",
      "\n",
      "Fold: 3  Epoch: 331  Training loss = 1.4813  Validation loss = 3.6068  \n",
      "\n",
      "Fold: 3  Epoch: 332  Training loss = 1.4812  Validation loss = 3.6060  \n",
      "\n",
      "Fold: 3  Epoch: 333  Training loss = 1.4811  Validation loss = 3.6058  \n",
      "\n",
      "Fold: 3  Epoch: 334  Training loss = 1.4811  Validation loss = 3.6055  \n",
      "\n",
      "Fold: 3  Epoch: 335  Training loss = 1.4811  Validation loss = 3.6052  \n",
      "\n",
      "Fold: 3  Epoch: 336  Training loss = 1.4811  Validation loss = 3.6053  \n",
      "\n",
      "Fold: 3  Epoch: 337  Training loss = 1.4811  Validation loss = 3.6051  \n",
      "\n",
      "Fold: 3  Epoch: 338  Training loss = 1.4810  Validation loss = 3.6045  \n",
      "\n",
      "Fold: 3  Epoch: 339  Training loss = 1.4809  Validation loss = 3.6041  \n",
      "\n",
      "Fold: 3  Epoch: 340  Training loss = 1.4809  Validation loss = 3.6038  \n",
      "\n",
      "Fold: 3  Epoch: 341  Training loss = 1.4808  Validation loss = 3.6030  \n",
      "\n",
      "Fold: 3  Epoch: 342  Training loss = 1.4807  Validation loss = 3.6028  \n",
      "\n",
      "Fold: 3  Epoch: 343  Training loss = 1.4807  Validation loss = 3.6023  \n",
      "\n",
      "Fold: 3  Epoch: 344  Training loss = 1.4807  Validation loss = 3.6021  \n",
      "\n",
      "Fold: 3  Epoch: 345  Training loss = 1.4806  Validation loss = 3.6018  \n",
      "\n",
      "Fold: 3  Epoch: 346  Training loss = 1.4806  Validation loss = 3.6015  \n",
      "\n",
      "Fold: 3  Epoch: 347  Training loss = 1.4805  Validation loss = 3.6011  \n",
      "\n",
      "Fold: 3  Epoch: 348  Training loss = 1.4805  Validation loss = 3.6007  \n",
      "\n",
      "Fold: 3  Epoch: 349  Training loss = 1.4804  Validation loss = 3.6003  \n",
      "\n",
      "Fold: 3  Epoch: 350  Training loss = 1.4804  Validation loss = 3.5997  \n",
      "\n",
      "Fold: 3  Epoch: 351  Training loss = 1.4803  Validation loss = 3.5995  \n",
      "\n",
      "Fold: 3  Epoch: 352  Training loss = 1.4803  Validation loss = 3.5994  \n",
      "\n",
      "Fold: 3  Epoch: 353  Training loss = 1.4803  Validation loss = 3.5996  \n",
      "\n",
      "Fold: 3  Epoch: 354  Training loss = 1.4803  Validation loss = 3.5992  \n",
      "\n",
      "Fold: 3  Epoch: 355  Training loss = 1.4802  Validation loss = 3.5984  \n",
      "\n",
      "Fold: 3  Epoch: 356  Training loss = 1.4801  Validation loss = 3.5981  \n",
      "\n",
      "Fold: 3  Epoch: 357  Training loss = 1.4801  Validation loss = 3.5972  \n",
      "\n",
      "Fold: 3  Epoch: 358  Training loss = 1.4800  Validation loss = 3.5968  \n",
      "\n",
      "Fold: 3  Epoch: 359  Training loss = 1.4799  Validation loss = 3.5962  \n",
      "\n",
      "Fold: 3  Epoch: 360  Training loss = 1.4799  Validation loss = 3.5959  \n",
      "\n",
      "Fold: 3  Epoch: 361  Training loss = 1.4799  Validation loss = 3.5959  \n",
      "\n",
      "Fold: 3  Epoch: 362  Training loss = 1.4799  Validation loss = 3.5956  \n",
      "\n",
      "Fold: 3  Epoch: 363  Training loss = 1.4799  Validation loss = 3.5958  \n",
      "\n",
      "Fold: 3  Epoch: 364  Training loss = 1.4798  Validation loss = 3.5954  \n",
      "\n",
      "Fold: 3  Epoch: 365  Training loss = 1.4798  Validation loss = 3.5952  \n",
      "\n",
      "Fold: 3  Epoch: 366  Training loss = 1.4797  Validation loss = 3.5947  \n",
      "\n",
      "Fold: 3  Epoch: 367  Training loss = 1.4797  Validation loss = 3.5942  \n",
      "\n",
      "Fold: 3  Epoch: 368  Training loss = 1.4796  Validation loss = 3.5939  \n",
      "\n",
      "Fold: 3  Epoch: 369  Training loss = 1.4796  Validation loss = 3.5941  \n",
      "\n",
      "Fold: 3  Epoch: 370  Training loss = 1.4796  Validation loss = 3.5942  \n",
      "\n",
      "Fold: 3  Epoch: 371  Training loss = 1.4796  Validation loss = 3.5938  \n",
      "\n",
      "Fold: 3  Epoch: 372  Training loss = 1.4795  Validation loss = 3.5937  \n",
      "\n",
      "Fold: 3  Epoch: 373  Training loss = 1.4795  Validation loss = 3.5939  \n",
      "\n",
      "Fold: 3  Epoch: 374  Training loss = 1.4795  Validation loss = 3.5939  \n",
      "\n",
      "Fold: 3  Epoch: 375  Training loss = 1.4795  Validation loss = 3.5936  \n",
      "\n",
      "Fold: 3  Epoch: 376  Training loss = 1.4795  Validation loss = 3.5935  \n",
      "\n",
      "Fold: 3  Epoch: 377  Training loss = 1.4794  Validation loss = 3.5932  \n",
      "\n",
      "Fold: 3  Epoch: 378  Training loss = 1.4794  Validation loss = 3.5933  \n",
      "\n",
      "Fold: 3  Epoch: 379  Training loss = 1.4794  Validation loss = 3.5930  \n",
      "\n",
      "Fold: 3  Epoch: 380  Training loss = 1.4793  Validation loss = 3.5923  \n",
      "\n",
      "Fold: 3  Epoch: 381  Training loss = 1.4793  Validation loss = 3.5923  \n",
      "\n",
      "Fold: 3  Epoch: 382  Training loss = 1.4793  Validation loss = 3.5923  \n",
      "\n",
      "Fold: 3  Epoch: 383  Training loss = 1.4793  Validation loss = 3.5924  \n",
      "\n",
      "Fold: 3  Epoch: 384  Training loss = 1.4793  Validation loss = 3.5921  \n",
      "\n",
      "Fold: 3  Epoch: 385  Training loss = 1.4793  Validation loss = 3.5921  \n",
      "\n",
      "Fold: 3  Epoch: 386  Training loss = 1.4793  Validation loss = 3.5921  \n",
      "\n",
      "Fold: 3  Epoch: 387  Training loss = 1.4792  Validation loss = 3.5916  \n",
      "\n",
      "Fold: 3  Epoch: 388  Training loss = 1.4791  Validation loss = 3.5911  \n",
      "\n",
      "Fold: 3  Epoch: 389  Training loss = 1.4791  Validation loss = 3.5912  \n",
      "\n",
      "Fold: 3  Epoch: 390  Training loss = 1.4791  Validation loss = 3.5908  \n",
      "\n",
      "Fold: 3  Epoch: 391  Training loss = 1.4791  Validation loss = 3.5906  \n",
      "\n",
      "Fold: 3  Epoch: 392  Training loss = 1.4790  Validation loss = 3.5900  \n",
      "\n",
      "Fold: 3  Epoch: 393  Training loss = 1.4790  Validation loss = 3.5899  \n",
      "\n",
      "Fold: 3  Epoch: 394  Training loss = 1.4790  Validation loss = 3.5898  \n",
      "\n",
      "Fold: 3  Epoch: 395  Training loss = 1.4790  Validation loss = 3.5899  \n",
      "\n",
      "Fold: 3  Epoch: 396  Training loss = 1.4789  Validation loss = 3.5897  \n",
      "\n",
      "Fold: 3  Epoch: 397  Training loss = 1.4789  Validation loss = 3.5897  \n",
      "\n",
      "Fold: 3  Epoch: 398  Training loss = 1.4788  Validation loss = 3.5895  \n",
      "\n",
      "Fold: 3  Epoch: 399  Training loss = 1.4788  Validation loss = 3.5892  \n",
      "\n",
      "Fold: 3  Epoch: 400  Training loss = 1.4787  Validation loss = 3.5886  \n",
      "\n",
      "Fold: 3  Epoch: 401  Training loss = 1.4787  Validation loss = 3.5882  \n",
      "\n",
      "Fold: 3  Epoch: 402  Training loss = 1.4787  Validation loss = 3.5882  \n",
      "\n",
      "Fold: 3  Epoch: 403  Training loss = 1.4786  Validation loss = 3.5879  \n",
      "\n",
      "Fold: 3  Epoch: 404  Training loss = 1.4786  Validation loss = 3.5876  \n",
      "\n",
      "Fold: 3  Epoch: 405  Training loss = 1.4785  Validation loss = 3.5871  \n",
      "\n",
      "Fold: 3  Epoch: 406  Training loss = 1.4785  Validation loss = 3.5870  \n",
      "\n",
      "Fold: 3  Epoch: 407  Training loss = 1.4784  Validation loss = 3.5860  \n",
      "\n",
      "Fold: 3  Epoch: 408  Training loss = 1.4784  Validation loss = 3.5856  \n",
      "\n",
      "Fold: 3  Epoch: 409  Training loss = 1.4783  Validation loss = 3.5853  \n",
      "\n",
      "Fold: 3  Epoch: 410  Training loss = 1.4783  Validation loss = 3.5852  \n",
      "\n",
      "Fold: 3  Epoch: 411  Training loss = 1.4783  Validation loss = 3.5848  \n",
      "\n",
      "Fold: 3  Epoch: 412  Training loss = 1.4782  Validation loss = 3.5839  \n",
      "\n",
      "Fold: 3  Epoch: 413  Training loss = 1.4781  Validation loss = 3.5839  \n",
      "\n",
      "Fold: 3  Epoch: 414  Training loss = 1.4781  Validation loss = 3.5836  \n",
      "\n",
      "Fold: 3  Epoch: 415  Training loss = 1.4780  Validation loss = 3.5829  \n",
      "\n",
      "Fold: 3  Epoch: 416  Training loss = 1.4780  Validation loss = 3.5831  \n",
      "\n",
      "Fold: 3  Epoch: 417  Training loss = 1.4780  Validation loss = 3.5825  \n",
      "\n",
      "Fold: 3  Epoch: 418  Training loss = 1.4780  Validation loss = 3.5826  \n",
      "\n",
      "Fold: 3  Epoch: 419  Training loss = 1.4779  Validation loss = 3.5824  \n",
      "\n",
      "Fold: 3  Epoch: 420  Training loss = 1.4779  Validation loss = 3.5823  \n",
      "\n",
      "Fold: 3  Epoch: 421  Training loss = 1.4778  Validation loss = 3.5816  \n",
      "\n",
      "Fold: 3  Epoch: 422  Training loss = 1.4778  Validation loss = 3.5812  \n",
      "\n",
      "Fold: 3  Epoch: 423  Training loss = 1.4778  Validation loss = 3.5811  \n",
      "\n",
      "Fold: 3  Epoch: 424  Training loss = 1.4777  Validation loss = 3.5805  \n",
      "\n",
      "Fold: 3  Epoch: 425  Training loss = 1.4777  Validation loss = 3.5799  \n",
      "\n",
      "Fold: 3  Epoch: 426  Training loss = 1.4776  Validation loss = 3.5795  \n",
      "\n",
      "Fold: 3  Epoch: 427  Training loss = 1.4776  Validation loss = 3.5794  \n",
      "\n",
      "Fold: 3  Epoch: 428  Training loss = 1.4775  Validation loss = 3.5791  \n",
      "\n",
      "Fold: 3  Epoch: 429  Training loss = 1.4775  Validation loss = 3.5787  \n",
      "\n",
      "Fold: 3  Epoch: 430  Training loss = 1.4775  Validation loss = 3.5785  \n",
      "\n",
      "Fold: 3  Epoch: 431  Training loss = 1.4774  Validation loss = 3.5781  \n",
      "\n",
      "Fold: 3  Epoch: 432  Training loss = 1.4774  Validation loss = 3.5775  \n",
      "\n",
      "Fold: 3  Epoch: 433  Training loss = 1.4773  Validation loss = 3.5773  \n",
      "\n",
      "Fold: 3  Epoch: 434  Training loss = 1.4774  Validation loss = 3.5777  \n",
      "\n",
      "Fold: 3  Epoch: 435  Training loss = 1.4773  Validation loss = 3.5772  \n",
      "\n",
      "Fold: 3  Epoch: 436  Training loss = 1.4773  Validation loss = 3.5769  \n",
      "\n",
      "Fold: 3  Epoch: 437  Training loss = 1.4772  Validation loss = 3.5763  \n",
      "\n",
      "Fold: 3  Epoch: 438  Training loss = 1.4772  Validation loss = 3.5761  \n",
      "\n",
      "Fold: 3  Epoch: 439  Training loss = 1.4772  Validation loss = 3.5758  \n",
      "\n",
      "Fold: 3  Epoch: 440  Training loss = 1.4771  Validation loss = 3.5753  \n",
      "\n",
      "Fold: 3  Epoch: 441  Training loss = 1.4770  Validation loss = 3.5749  \n",
      "\n",
      "Fold: 3  Epoch: 442  Training loss = 1.4770  Validation loss = 3.5745  \n",
      "\n",
      "Fold: 3  Epoch: 443  Training loss = 1.4769  Validation loss = 3.5739  \n",
      "\n",
      "Fold: 3  Epoch: 444  Training loss = 1.4769  Validation loss = 3.5736  \n",
      "\n",
      "Fold: 3  Epoch: 445  Training loss = 1.4769  Validation loss = 3.5732  \n",
      "\n",
      "Fold: 3  Epoch: 446  Training loss = 1.4768  Validation loss = 3.5731  \n",
      "\n",
      "Fold: 3  Epoch: 447  Training loss = 1.4768  Validation loss = 3.5727  \n",
      "\n",
      "Fold: 3  Epoch: 448  Training loss = 1.4768  Validation loss = 3.5726  \n",
      "\n",
      "Fold: 3  Epoch: 449  Training loss = 1.4768  Validation loss = 3.5726  \n",
      "\n",
      "Fold: 3  Epoch: 450  Training loss = 1.4768  Validation loss = 3.5727  \n",
      "\n",
      "Fold: 3  Epoch: 451  Training loss = 1.4767  Validation loss = 3.5721  \n",
      "\n",
      "Fold: 3  Epoch: 452  Training loss = 1.4767  Validation loss = 3.5716  \n",
      "\n",
      "Fold: 3  Epoch: 453  Training loss = 1.4767  Validation loss = 3.5718  \n",
      "\n",
      "Fold: 3  Epoch: 454  Training loss = 1.4767  Validation loss = 3.5715  \n",
      "\n",
      "Fold: 3  Epoch: 455  Training loss = 1.4767  Validation loss = 3.5716  \n",
      "\n",
      "Fold: 3  Epoch: 456  Training loss = 1.4767  Validation loss = 3.5716  \n",
      "\n",
      "Fold: 3  Epoch: 457  Training loss = 1.4766  Validation loss = 3.5709  \n",
      "\n",
      "Fold: 3  Epoch: 458  Training loss = 1.4766  Validation loss = 3.5705  \n",
      "\n",
      "Fold: 3  Epoch: 459  Training loss = 1.4765  Validation loss = 3.5701  \n",
      "\n",
      "Fold: 3  Epoch: 460  Training loss = 1.4765  Validation loss = 3.5701  \n",
      "\n",
      "Fold: 3  Epoch: 461  Training loss = 1.4764  Validation loss = 3.5693  \n",
      "\n",
      "Fold: 3  Epoch: 462  Training loss = 1.4764  Validation loss = 3.5693  \n",
      "\n",
      "Fold: 3  Epoch: 463  Training loss = 1.4764  Validation loss = 3.5692  \n",
      "\n",
      "Fold: 3  Epoch: 464  Training loss = 1.4763  Validation loss = 3.5688  \n",
      "\n",
      "Fold: 3  Epoch: 465  Training loss = 1.4763  Validation loss = 3.5685  \n",
      "\n",
      "Fold: 3  Epoch: 466  Training loss = 1.4763  Validation loss = 3.5683  \n",
      "\n",
      "Fold: 3  Epoch: 467  Training loss = 1.4762  Validation loss = 3.5678  \n",
      "\n",
      "Fold: 3  Epoch: 468  Training loss = 1.4762  Validation loss = 3.5676  \n",
      "\n",
      "Fold: 3  Epoch: 469  Training loss = 1.4762  Validation loss = 3.5670  \n",
      "\n",
      "Fold: 3  Epoch: 470  Training loss = 1.4761  Validation loss = 3.5668  \n",
      "\n",
      "Fold: 3  Epoch: 471  Training loss = 1.4761  Validation loss = 3.5663  \n",
      "\n",
      "Fold: 3  Epoch: 472  Training loss = 1.4761  Validation loss = 3.5662  \n",
      "\n",
      "Fold: 3  Epoch: 473  Training loss = 1.4761  Validation loss = 3.5663  \n",
      "\n",
      "Fold: 3  Epoch: 474  Training loss = 1.4761  Validation loss = 3.5659  \n",
      "\n",
      "Fold: 3  Epoch: 475  Training loss = 1.4760  Validation loss = 3.5659  \n",
      "\n",
      "Fold: 3  Epoch: 476  Training loss = 1.4760  Validation loss = 3.5652  \n",
      "\n",
      "Fold: 3  Epoch: 477  Training loss = 1.4759  Validation loss = 3.5645  \n",
      "\n",
      "Fold: 3  Epoch: 478  Training loss = 1.4759  Validation loss = 3.5641  \n",
      "\n",
      "Fold: 3  Epoch: 479  Training loss = 1.4758  Validation loss = 3.5638  \n",
      "\n",
      "Fold: 3  Epoch: 480  Training loss = 1.4758  Validation loss = 3.5634  \n",
      "\n",
      "Fold: 3  Epoch: 481  Training loss = 1.4758  Validation loss = 3.5632  \n",
      "\n",
      "Fold: 3  Epoch: 482  Training loss = 1.4758  Validation loss = 3.5634  \n",
      "\n",
      "Fold: 3  Epoch: 483  Training loss = 1.4758  Validation loss = 3.5636  \n",
      "\n",
      "Fold: 3  Epoch: 484  Training loss = 1.4757  Validation loss = 3.5635  \n",
      "\n",
      "Fold: 3  Epoch: 485  Training loss = 1.4757  Validation loss = 3.5633  \n",
      "\n",
      "Fold: 3  Epoch: 486  Training loss = 1.4757  Validation loss = 3.5634  \n",
      "\n",
      "Fold: 3  Epoch: 487  Training loss = 1.4757  Validation loss = 3.5631  \n",
      "\n",
      "Fold: 3  Epoch: 488  Training loss = 1.4757  Validation loss = 3.5631  \n",
      "\n",
      "Fold: 3  Epoch: 489  Training loss = 1.4756  Validation loss = 3.5625  \n",
      "\n",
      "Fold: 3  Epoch: 490  Training loss = 1.4756  Validation loss = 3.5622  \n",
      "\n",
      "Fold: 3  Epoch: 491  Training loss = 1.4756  Validation loss = 3.5619  \n",
      "\n",
      "Fold: 3  Epoch: 492  Training loss = 1.4756  Validation loss = 3.5621  \n",
      "\n",
      "Fold: 3  Epoch: 493  Training loss = 1.4755  Validation loss = 3.5621  \n",
      "\n",
      "Fold: 3  Epoch: 494  Training loss = 1.4755  Validation loss = 3.5618  \n",
      "\n",
      "Fold: 3  Epoch: 495  Training loss = 1.4755  Validation loss = 3.5616  \n",
      "\n",
      "Fold: 3  Epoch: 496  Training loss = 1.4754  Validation loss = 3.5615  \n",
      "\n",
      "Fold: 3  Epoch: 497  Training loss = 1.4754  Validation loss = 3.5613  \n",
      "\n",
      "Fold: 3  Epoch: 498  Training loss = 1.4753  Validation loss = 3.5606  \n",
      "\n",
      "Fold: 3  Epoch: 499  Training loss = 1.4753  Validation loss = 3.5603  \n",
      "\n",
      "Fold: 3  Epoch: 500  Training loss = 1.4753  Validation loss = 3.5601  \n",
      "\n",
      "Check model:  Fold: 3  Optimal epoch: 500  \n",
      "\n",
      "Fold: 4  Epoch: 1  Training loss = 1.6134  Validation loss = 4.6874  \n",
      "\n",
      "Fold: 4  Epoch: 2  Training loss = 1.6133  Validation loss = 4.6869  \n",
      "\n",
      "Fold: 4  Epoch: 3  Training loss = 1.6132  Validation loss = 4.6863  \n",
      "\n",
      "Fold: 4  Epoch: 4  Training loss = 1.6130  Validation loss = 4.6855  \n",
      "\n",
      "Fold: 4  Epoch: 5  Training loss = 1.6130  Validation loss = 4.6854  \n",
      "\n",
      "Fold: 4  Epoch: 6  Training loss = 1.6129  Validation loss = 4.6845  \n",
      "\n",
      "Fold: 4  Epoch: 7  Training loss = 1.6127  Validation loss = 4.6836  \n",
      "\n",
      "Fold: 4  Epoch: 8  Training loss = 1.6126  Validation loss = 4.6829  \n",
      "\n",
      "Fold: 4  Epoch: 9  Training loss = 1.6124  Validation loss = 4.6817  \n",
      "\n",
      "Fold: 4  Epoch: 10  Training loss = 1.6123  Validation loss = 4.6807  \n",
      "\n",
      "Fold: 4  Epoch: 11  Training loss = 1.6121  Validation loss = 4.6799  \n",
      "\n",
      "Fold: 4  Epoch: 12  Training loss = 1.6119  Validation loss = 4.6789  \n",
      "\n",
      "Fold: 4  Epoch: 13  Training loss = 1.6118  Validation loss = 4.6778  \n",
      "\n",
      "Fold: 4  Epoch: 14  Training loss = 1.6117  Validation loss = 4.6772  \n",
      "\n",
      "Fold: 4  Epoch: 15  Training loss = 1.6116  Validation loss = 4.6766  \n",
      "\n",
      "Fold: 4  Epoch: 16  Training loss = 1.6115  Validation loss = 4.6763  \n",
      "\n",
      "Fold: 4  Epoch: 17  Training loss = 1.6112  Validation loss = 4.6744  \n",
      "\n",
      "Fold: 4  Epoch: 18  Training loss = 1.6112  Validation loss = 4.6741  \n",
      "\n",
      "Fold: 4  Epoch: 19  Training loss = 1.6110  Validation loss = 4.6730  \n",
      "\n",
      "Fold: 4  Epoch: 20  Training loss = 1.6108  Validation loss = 4.6722  \n",
      "\n",
      "Fold: 4  Epoch: 21  Training loss = 1.6109  Validation loss = 4.6723  \n",
      "\n",
      "Fold: 4  Epoch: 22  Training loss = 1.6106  Validation loss = 4.6710  \n",
      "\n",
      "Fold: 4  Epoch: 23  Training loss = 1.6106  Validation loss = 4.6709  \n",
      "\n",
      "Fold: 4  Epoch: 24  Training loss = 1.6106  Validation loss = 4.6706  \n",
      "\n",
      "Fold: 4  Epoch: 25  Training loss = 1.6106  Validation loss = 4.6707  \n",
      "\n",
      "Fold: 4  Epoch: 26  Training loss = 1.6105  Validation loss = 4.6706  \n",
      "\n",
      "Fold: 4  Epoch: 27  Training loss = 1.6105  Validation loss = 4.6703  \n",
      "\n",
      "Fold: 4  Epoch: 28  Training loss = 1.6103  Validation loss = 4.6690  \n",
      "\n",
      "Fold: 4  Epoch: 29  Training loss = 1.6102  Validation loss = 4.6687  \n",
      "\n",
      "Fold: 4  Epoch: 30  Training loss = 1.6101  Validation loss = 4.6680  \n",
      "\n",
      "Fold: 4  Epoch: 31  Training loss = 1.6100  Validation loss = 4.6677  \n",
      "\n",
      "Fold: 4  Epoch: 32  Training loss = 1.6099  Validation loss = 4.6667  \n",
      "\n",
      "Fold: 4  Epoch: 33  Training loss = 1.6097  Validation loss = 4.6657  \n",
      "\n",
      "Fold: 4  Epoch: 34  Training loss = 1.6096  Validation loss = 4.6649  \n",
      "\n",
      "Fold: 4  Epoch: 35  Training loss = 1.6094  Validation loss = 4.6636  \n",
      "\n",
      "Fold: 4  Epoch: 36  Training loss = 1.6092  Validation loss = 4.6626  \n",
      "\n",
      "Fold: 4  Epoch: 37  Training loss = 1.6091  Validation loss = 4.6621  \n",
      "\n",
      "Fold: 4  Epoch: 38  Training loss = 1.6091  Validation loss = 4.6619  \n",
      "\n",
      "Fold: 4  Epoch: 39  Training loss = 1.6090  Validation loss = 4.6611  \n",
      "\n",
      "Fold: 4  Epoch: 40  Training loss = 1.6089  Validation loss = 4.6604  \n",
      "\n",
      "Fold: 4  Epoch: 41  Training loss = 1.6087  Validation loss = 4.6596  \n",
      "\n",
      "Fold: 4  Epoch: 42  Training loss = 1.6086  Validation loss = 4.6587  \n",
      "\n",
      "Fold: 4  Epoch: 43  Training loss = 1.6085  Validation loss = 4.6579  \n",
      "\n",
      "Fold: 4  Epoch: 44  Training loss = 1.6083  Validation loss = 4.6571  \n",
      "\n",
      "Fold: 4  Epoch: 45  Training loss = 1.6083  Validation loss = 4.6570  \n",
      "\n",
      "Fold: 4  Epoch: 46  Training loss = 1.6081  Validation loss = 4.6559  \n",
      "\n",
      "Fold: 4  Epoch: 47  Training loss = 1.6080  Validation loss = 4.6548  \n",
      "\n",
      "Fold: 4  Epoch: 48  Training loss = 1.6079  Validation loss = 4.6546  \n",
      "\n",
      "Fold: 4  Epoch: 49  Training loss = 1.6079  Validation loss = 4.6546  \n",
      "\n",
      "Fold: 4  Epoch: 50  Training loss = 1.6078  Validation loss = 4.6541  \n",
      "\n",
      "Fold: 4  Epoch: 51  Training loss = 1.6077  Validation loss = 4.6537  \n",
      "\n",
      "Fold: 4  Epoch: 52  Training loss = 1.6077  Validation loss = 4.6536  \n",
      "\n",
      "Fold: 4  Epoch: 53  Training loss = 1.6076  Validation loss = 4.6531  \n",
      "\n",
      "Fold: 4  Epoch: 54  Training loss = 1.6075  Validation loss = 4.6523  \n",
      "\n",
      "Fold: 4  Epoch: 55  Training loss = 1.6074  Validation loss = 4.6521  \n",
      "\n",
      "Fold: 4  Epoch: 56  Training loss = 1.6074  Validation loss = 4.6519  \n",
      "\n",
      "Fold: 4  Epoch: 57  Training loss = 1.6074  Validation loss = 4.6521  \n",
      "\n",
      "Fold: 4  Epoch: 58  Training loss = 1.6072  Validation loss = 4.6511  \n",
      "\n",
      "Fold: 4  Epoch: 59  Training loss = 1.6071  Validation loss = 4.6503  \n",
      "\n",
      "Fold: 4  Epoch: 60  Training loss = 1.6070  Validation loss = 4.6497  \n",
      "\n",
      "Fold: 4  Epoch: 61  Training loss = 1.6069  Validation loss = 4.6492  \n",
      "\n",
      "Fold: 4  Epoch: 62  Training loss = 1.6068  Validation loss = 4.6482  \n",
      "\n",
      "Fold: 4  Epoch: 63  Training loss = 1.6067  Validation loss = 4.6474  \n",
      "\n",
      "Fold: 4  Epoch: 64  Training loss = 1.6066  Validation loss = 4.6468  \n",
      "\n",
      "Fold: 4  Epoch: 65  Training loss = 1.6065  Validation loss = 4.6465  \n",
      "\n",
      "Fold: 4  Epoch: 66  Training loss = 1.6064  Validation loss = 4.6456  \n",
      "\n",
      "Fold: 4  Epoch: 67  Training loss = 1.6063  Validation loss = 4.6448  \n",
      "\n",
      "Fold: 4  Epoch: 68  Training loss = 1.6061  Validation loss = 4.6442  \n",
      "\n",
      "Fold: 4  Epoch: 69  Training loss = 1.6061  Validation loss = 4.6436  \n",
      "\n",
      "Fold: 4  Epoch: 70  Training loss = 1.6060  Validation loss = 4.6432  \n",
      "\n",
      "Fold: 4  Epoch: 71  Training loss = 1.6059  Validation loss = 4.6429  \n",
      "\n",
      "Fold: 4  Epoch: 72  Training loss = 1.6059  Validation loss = 4.6425  \n",
      "\n",
      "Fold: 4  Epoch: 73  Training loss = 1.6057  Validation loss = 4.6416  \n",
      "\n",
      "Fold: 4  Epoch: 74  Training loss = 1.6057  Validation loss = 4.6410  \n",
      "\n",
      "Fold: 4  Epoch: 75  Training loss = 1.6056  Validation loss = 4.6407  \n",
      "\n",
      "Fold: 4  Epoch: 76  Training loss = 1.6055  Validation loss = 4.6401  \n",
      "\n",
      "Fold: 4  Epoch: 77  Training loss = 1.6054  Validation loss = 4.6394  \n",
      "\n",
      "Fold: 4  Epoch: 78  Training loss = 1.6053  Validation loss = 4.6392  \n",
      "\n",
      "Fold: 4  Epoch: 79  Training loss = 1.6053  Validation loss = 4.6392  \n",
      "\n",
      "Fold: 4  Epoch: 80  Training loss = 1.6053  Validation loss = 4.6393  \n",
      "\n",
      "Fold: 4  Epoch: 81  Training loss = 1.6052  Validation loss = 4.6387  \n",
      "\n",
      "Fold: 4  Epoch: 82  Training loss = 1.6051  Validation loss = 4.6381  \n",
      "\n",
      "Fold: 4  Epoch: 83  Training loss = 1.6051  Validation loss = 4.6378  \n",
      "\n",
      "Fold: 4  Epoch: 84  Training loss = 1.6049  Validation loss = 4.6371  \n",
      "\n",
      "Fold: 4  Epoch: 85  Training loss = 1.6049  Validation loss = 4.6367  \n",
      "\n",
      "Fold: 4  Epoch: 86  Training loss = 1.6047  Validation loss = 4.6352  \n",
      "\n",
      "Fold: 4  Epoch: 87  Training loss = 1.6046  Validation loss = 4.6349  \n",
      "\n",
      "Fold: 4  Epoch: 88  Training loss = 1.6045  Validation loss = 4.6341  \n",
      "\n",
      "Fold: 4  Epoch: 89  Training loss = 1.6044  Validation loss = 4.6333  \n",
      "\n",
      "Fold: 4  Epoch: 90  Training loss = 1.6042  Validation loss = 4.6324  \n",
      "\n",
      "Fold: 4  Epoch: 91  Training loss = 1.6041  Validation loss = 4.6320  \n",
      "\n",
      "Fold: 4  Epoch: 92  Training loss = 1.6041  Validation loss = 4.6319  \n",
      "\n",
      "Fold: 4  Epoch: 93  Training loss = 1.6040  Validation loss = 4.6314  \n",
      "\n",
      "Fold: 4  Epoch: 94  Training loss = 1.6040  Validation loss = 4.6312  \n",
      "\n",
      "Fold: 4  Epoch: 95  Training loss = 1.6039  Validation loss = 4.6307  \n",
      "\n",
      "Fold: 4  Epoch: 96  Training loss = 1.6038  Validation loss = 4.6302  \n",
      "\n",
      "Fold: 4  Epoch: 97  Training loss = 1.6037  Validation loss = 4.6294  \n",
      "\n",
      "Fold: 4  Epoch: 98  Training loss = 1.6036  Validation loss = 4.6288  \n",
      "\n",
      "Fold: 4  Epoch: 99  Training loss = 1.6035  Validation loss = 4.6283  \n",
      "\n",
      "Fold: 4  Epoch: 100  Training loss = 1.6035  Validation loss = 4.6279  \n",
      "\n",
      "Fold: 4  Epoch: 101  Training loss = 1.6033  Validation loss = 4.6271  \n",
      "\n",
      "Fold: 4  Epoch: 102  Training loss = 1.6032  Validation loss = 4.6265  \n",
      "\n",
      "Fold: 4  Epoch: 103  Training loss = 1.6031  Validation loss = 4.6256  \n",
      "\n",
      "Fold: 4  Epoch: 104  Training loss = 1.6030  Validation loss = 4.6248  \n",
      "\n",
      "Fold: 4  Epoch: 105  Training loss = 1.6029  Validation loss = 4.6241  \n",
      "\n",
      "Fold: 4  Epoch: 106  Training loss = 1.6027  Validation loss = 4.6231  \n",
      "\n",
      "Fold: 4  Epoch: 107  Training loss = 1.6027  Validation loss = 4.6226  \n",
      "\n",
      "Fold: 4  Epoch: 108  Training loss = 1.6027  Validation loss = 4.6227  \n",
      "\n",
      "Fold: 4  Epoch: 109  Training loss = 1.6026  Validation loss = 4.6225  \n",
      "\n",
      "Fold: 4  Epoch: 110  Training loss = 1.6025  Validation loss = 4.6216  \n",
      "\n",
      "Fold: 4  Epoch: 111  Training loss = 1.6025  Validation loss = 4.6219  \n",
      "\n",
      "Fold: 4  Epoch: 112  Training loss = 1.6024  Validation loss = 4.6211  \n",
      "\n",
      "Fold: 4  Epoch: 113  Training loss = 1.6024  Validation loss = 4.6210  \n",
      "\n",
      "Fold: 4  Epoch: 114  Training loss = 1.6023  Validation loss = 4.6208  \n",
      "\n",
      "Fold: 4  Epoch: 115  Training loss = 1.6022  Validation loss = 4.6200  \n",
      "\n",
      "Fold: 4  Epoch: 116  Training loss = 1.6021  Validation loss = 4.6193  \n",
      "\n",
      "Fold: 4  Epoch: 117  Training loss = 1.6020  Validation loss = 4.6182  \n",
      "\n",
      "Fold: 4  Epoch: 118  Training loss = 1.6019  Validation loss = 4.6176  \n",
      "\n",
      "Fold: 4  Epoch: 119  Training loss = 1.6018  Validation loss = 4.6174  \n",
      "\n",
      "Fold: 4  Epoch: 120  Training loss = 1.6017  Validation loss = 4.6162  \n",
      "\n",
      "Fold: 4  Epoch: 121  Training loss = 1.6017  Validation loss = 4.6164  \n",
      "\n",
      "Fold: 4  Epoch: 122  Training loss = 1.6016  Validation loss = 4.6158  \n",
      "\n",
      "Fold: 4  Epoch: 123  Training loss = 1.6015  Validation loss = 4.6151  \n",
      "\n",
      "Fold: 4  Epoch: 124  Training loss = 1.6013  Validation loss = 4.6138  \n",
      "\n",
      "Fold: 4  Epoch: 125  Training loss = 1.6011  Validation loss = 4.6127  \n",
      "\n",
      "Fold: 4  Epoch: 126  Training loss = 1.6010  Validation loss = 4.6118  \n",
      "\n",
      "Fold: 4  Epoch: 127  Training loss = 1.6010  Validation loss = 4.6120  \n",
      "\n",
      "Fold: 4  Epoch: 128  Training loss = 1.6009  Validation loss = 4.6114  \n",
      "\n",
      "Fold: 4  Epoch: 129  Training loss = 1.6009  Validation loss = 4.6112  \n",
      "\n",
      "Fold: 4  Epoch: 130  Training loss = 1.6008  Validation loss = 4.6109  \n",
      "\n",
      "Fold: 4  Epoch: 131  Training loss = 1.6007  Validation loss = 4.6104  \n",
      "\n",
      "Fold: 4  Epoch: 132  Training loss = 1.6006  Validation loss = 4.6095  \n",
      "\n",
      "Fold: 4  Epoch: 133  Training loss = 1.6006  Validation loss = 4.6093  \n",
      "\n",
      "Fold: 4  Epoch: 134  Training loss = 1.6005  Validation loss = 4.6090  \n",
      "\n",
      "Fold: 4  Epoch: 135  Training loss = 1.6005  Validation loss = 4.6091  \n",
      "\n",
      "Fold: 4  Epoch: 136  Training loss = 1.6005  Validation loss = 4.6088  \n",
      "\n",
      "Fold: 4  Epoch: 137  Training loss = 1.6004  Validation loss = 4.6084  \n",
      "\n",
      "Fold: 4  Epoch: 138  Training loss = 1.6004  Validation loss = 4.6082  \n",
      "\n",
      "Fold: 4  Epoch: 139  Training loss = 1.6004  Validation loss = 4.6083  \n",
      "\n",
      "Fold: 4  Epoch: 140  Training loss = 1.6003  Validation loss = 4.6082  \n",
      "\n",
      "Fold: 4  Epoch: 141  Training loss = 1.6003  Validation loss = 4.6078  \n",
      "\n",
      "Fold: 4  Epoch: 142  Training loss = 1.6002  Validation loss = 4.6071  \n",
      "\n",
      "Fold: 4  Epoch: 143  Training loss = 1.6001  Validation loss = 4.6067  \n",
      "\n",
      "Fold: 4  Epoch: 144  Training loss = 1.6000  Validation loss = 4.6058  \n",
      "\n",
      "Fold: 4  Epoch: 145  Training loss = 1.5999  Validation loss = 4.6053  \n",
      "\n",
      "Fold: 4  Epoch: 146  Training loss = 1.5999  Validation loss = 4.6051  \n",
      "\n",
      "Fold: 4  Epoch: 147  Training loss = 1.5997  Validation loss = 4.6037  \n",
      "\n",
      "Fold: 4  Epoch: 148  Training loss = 1.5996  Validation loss = 4.6032  \n",
      "\n",
      "Fold: 4  Epoch: 149  Training loss = 1.5995  Validation loss = 4.6027  \n",
      "\n",
      "Fold: 4  Epoch: 150  Training loss = 1.5995  Validation loss = 4.6024  \n",
      "\n",
      "Fold: 4  Epoch: 151  Training loss = 1.5993  Validation loss = 4.6011  \n",
      "\n",
      "Fold: 4  Epoch: 152  Training loss = 1.5993  Validation loss = 4.6013  \n",
      "\n",
      "Fold: 4  Epoch: 153  Training loss = 1.5992  Validation loss = 4.6005  \n",
      "\n",
      "Fold: 4  Epoch: 154  Training loss = 1.5991  Validation loss = 4.6001  \n",
      "\n",
      "Fold: 4  Epoch: 155  Training loss = 1.5991  Validation loss = 4.5998  \n",
      "\n",
      "Fold: 4  Epoch: 156  Training loss = 1.5991  Validation loss = 4.5997  \n",
      "\n",
      "Fold: 4  Epoch: 157  Training loss = 1.5990  Validation loss = 4.5994  \n",
      "\n",
      "Fold: 4  Epoch: 158  Training loss = 1.5990  Validation loss = 4.5992  \n",
      "\n",
      "Fold: 4  Epoch: 159  Training loss = 1.5989  Validation loss = 4.5985  \n",
      "\n",
      "Fold: 4  Epoch: 160  Training loss = 1.5988  Validation loss = 4.5978  \n",
      "\n",
      "Fold: 4  Epoch: 161  Training loss = 1.5987  Validation loss = 4.5977  \n",
      "\n",
      "Fold: 4  Epoch: 162  Training loss = 1.5987  Validation loss = 4.5973  \n",
      "\n",
      "Fold: 4  Epoch: 163  Training loss = 1.5987  Validation loss = 4.5974  \n",
      "\n",
      "Fold: 4  Epoch: 164  Training loss = 1.5986  Validation loss = 4.5973  \n",
      "\n",
      "Fold: 4  Epoch: 165  Training loss = 1.5986  Validation loss = 4.5970  \n",
      "\n",
      "Fold: 4  Epoch: 166  Training loss = 1.5985  Validation loss = 4.5965  \n",
      "\n",
      "Fold: 4  Epoch: 167  Training loss = 1.5985  Validation loss = 4.5963  \n",
      "\n",
      "Fold: 4  Epoch: 168  Training loss = 1.5983  Validation loss = 4.5952  \n",
      "\n",
      "Fold: 4  Epoch: 169  Training loss = 1.5983  Validation loss = 4.5950  \n",
      "\n",
      "Fold: 4  Epoch: 170  Training loss = 1.5982  Validation loss = 4.5946  \n",
      "\n",
      "Fold: 4  Epoch: 171  Training loss = 1.5982  Validation loss = 4.5946  \n",
      "\n",
      "Fold: 4  Epoch: 172  Training loss = 1.5981  Validation loss = 4.5939  \n",
      "\n",
      "Fold: 4  Epoch: 173  Training loss = 1.5981  Validation loss = 4.5937  \n",
      "\n",
      "Fold: 4  Epoch: 174  Training loss = 1.5980  Validation loss = 4.5931  \n",
      "\n",
      "Fold: 4  Epoch: 175  Training loss = 1.5979  Validation loss = 4.5922  \n",
      "\n",
      "Fold: 4  Epoch: 176  Training loss = 1.5978  Validation loss = 4.5917  \n",
      "\n",
      "Fold: 4  Epoch: 177  Training loss = 1.5977  Validation loss = 4.5910  \n",
      "\n",
      "Fold: 4  Epoch: 178  Training loss = 1.5976  Validation loss = 4.5903  \n",
      "\n",
      "Fold: 4  Epoch: 179  Training loss = 1.5975  Validation loss = 4.5900  \n",
      "\n",
      "Fold: 4  Epoch: 180  Training loss = 1.5974  Validation loss = 4.5893  \n",
      "\n",
      "Fold: 4  Epoch: 181  Training loss = 1.5974  Validation loss = 4.5889  \n",
      "\n",
      "Fold: 4  Epoch: 182  Training loss = 1.5973  Validation loss = 4.5886  \n",
      "\n",
      "Fold: 4  Epoch: 183  Training loss = 1.5973  Validation loss = 4.5887  \n",
      "\n",
      "Fold: 4  Epoch: 184  Training loss = 1.5972  Validation loss = 4.5882  \n",
      "\n",
      "Fold: 4  Epoch: 185  Training loss = 1.5972  Validation loss = 4.5880  \n",
      "\n",
      "Fold: 4  Epoch: 186  Training loss = 1.5971  Validation loss = 4.5876  \n",
      "\n",
      "Fold: 4  Epoch: 187  Training loss = 1.5970  Validation loss = 4.5871  \n",
      "\n",
      "Fold: 4  Epoch: 188  Training loss = 1.5970  Validation loss = 4.5866  \n",
      "\n",
      "Fold: 4  Epoch: 189  Training loss = 1.5968  Validation loss = 4.5857  \n",
      "\n",
      "Fold: 4  Epoch: 190  Training loss = 1.5967  Validation loss = 4.5850  \n",
      "\n",
      "Fold: 4  Epoch: 191  Training loss = 1.5966  Validation loss = 4.5843  \n",
      "\n",
      "Fold: 4  Epoch: 192  Training loss = 1.5966  Validation loss = 4.5839  \n",
      "\n",
      "Fold: 4  Epoch: 193  Training loss = 1.5965  Validation loss = 4.5832  \n",
      "\n",
      "Fold: 4  Epoch: 194  Training loss = 1.5964  Validation loss = 4.5830  \n",
      "\n",
      "Fold: 4  Epoch: 195  Training loss = 1.5962  Validation loss = 4.5818  \n",
      "\n",
      "Fold: 4  Epoch: 196  Training loss = 1.5961  Validation loss = 4.5809  \n",
      "\n",
      "Fold: 4  Epoch: 197  Training loss = 1.5961  Validation loss = 4.5807  \n",
      "\n",
      "Fold: 4  Epoch: 198  Training loss = 1.5959  Validation loss = 4.5797  \n",
      "\n",
      "Fold: 4  Epoch: 199  Training loss = 1.5959  Validation loss = 4.5795  \n",
      "\n",
      "Fold: 4  Epoch: 200  Training loss = 1.5958  Validation loss = 4.5788  \n",
      "\n",
      "Fold: 4  Epoch: 201  Training loss = 1.5958  Validation loss = 4.5788  \n",
      "\n",
      "Fold: 4  Epoch: 202  Training loss = 1.5957  Validation loss = 4.5781  \n",
      "\n",
      "Fold: 4  Epoch: 203  Training loss = 1.5956  Validation loss = 4.5775  \n",
      "\n",
      "Fold: 4  Epoch: 204  Training loss = 1.5956  Validation loss = 4.5775  \n",
      "\n",
      "Fold: 4  Epoch: 205  Training loss = 1.5955  Validation loss = 4.5767  \n",
      "\n",
      "Fold: 4  Epoch: 206  Training loss = 1.5953  Validation loss = 4.5757  \n",
      "\n",
      "Fold: 4  Epoch: 207  Training loss = 1.5953  Validation loss = 4.5756  \n",
      "\n",
      "Fold: 4  Epoch: 208  Training loss = 1.5952  Validation loss = 4.5750  \n",
      "\n",
      "Fold: 4  Epoch: 209  Training loss = 1.5952  Validation loss = 4.5749  \n",
      "\n",
      "Fold: 4  Epoch: 210  Training loss = 1.5952  Validation loss = 4.5748  \n",
      "\n",
      "Fold: 4  Epoch: 211  Training loss = 1.5952  Validation loss = 4.5748  \n",
      "\n",
      "Fold: 4  Epoch: 212  Training loss = 1.5952  Validation loss = 4.5749  \n",
      "\n",
      "Fold: 4  Epoch: 213  Training loss = 1.5951  Validation loss = 4.5740  \n",
      "\n",
      "Fold: 4  Epoch: 214  Training loss = 1.5950  Validation loss = 4.5734  \n",
      "\n",
      "Fold: 4  Epoch: 215  Training loss = 1.5949  Validation loss = 4.5733  \n",
      "\n",
      "Fold: 4  Epoch: 216  Training loss = 1.5949  Validation loss = 4.5731  \n",
      "\n",
      "Fold: 4  Epoch: 217  Training loss = 1.5948  Validation loss = 4.5726  \n",
      "\n",
      "Fold: 4  Epoch: 218  Training loss = 1.5947  Validation loss = 4.5715  \n",
      "\n",
      "Fold: 4  Epoch: 219  Training loss = 1.5946  Validation loss = 4.5709  \n",
      "\n",
      "Fold: 4  Epoch: 220  Training loss = 1.5946  Validation loss = 4.5708  \n",
      "\n",
      "Fold: 4  Epoch: 221  Training loss = 1.5945  Validation loss = 4.5704  \n",
      "\n",
      "Fold: 4  Epoch: 222  Training loss = 1.5945  Validation loss = 4.5702  \n",
      "\n",
      "Fold: 4  Epoch: 223  Training loss = 1.5944  Validation loss = 4.5696  \n",
      "\n",
      "Fold: 4  Epoch: 224  Training loss = 1.5944  Validation loss = 4.5694  \n",
      "\n",
      "Fold: 4  Epoch: 225  Training loss = 1.5942  Validation loss = 4.5682  \n",
      "\n",
      "Fold: 4  Epoch: 226  Training loss = 1.5942  Validation loss = 4.5681  \n",
      "\n",
      "Fold: 4  Epoch: 227  Training loss = 1.5941  Validation loss = 4.5679  \n",
      "\n",
      "Fold: 4  Epoch: 228  Training loss = 1.5940  Validation loss = 4.5669  \n",
      "\n",
      "Fold: 4  Epoch: 229  Training loss = 1.5940  Validation loss = 4.5665  \n",
      "\n",
      "Fold: 4  Epoch: 230  Training loss = 1.5939  Validation loss = 4.5663  \n",
      "\n",
      "Fold: 4  Epoch: 231  Training loss = 1.5938  Validation loss = 4.5655  \n",
      "\n",
      "Fold: 4  Epoch: 232  Training loss = 1.5937  Validation loss = 4.5645  \n",
      "\n",
      "Fold: 4  Epoch: 233  Training loss = 1.5936  Validation loss = 4.5638  \n",
      "\n",
      "Fold: 4  Epoch: 234  Training loss = 1.5935  Validation loss = 4.5631  \n",
      "\n",
      "Fold: 4  Epoch: 235  Training loss = 1.5935  Validation loss = 4.5631  \n",
      "\n",
      "Fold: 4  Epoch: 236  Training loss = 1.5934  Validation loss = 4.5625  \n",
      "\n",
      "Fold: 4  Epoch: 237  Training loss = 1.5933  Validation loss = 4.5620  \n",
      "\n",
      "Fold: 4  Epoch: 238  Training loss = 1.5933  Validation loss = 4.5616  \n",
      "\n",
      "Fold: 4  Epoch: 239  Training loss = 1.5933  Validation loss = 4.5615  \n",
      "\n",
      "Fold: 4  Epoch: 240  Training loss = 1.5932  Validation loss = 4.5616  \n",
      "\n",
      "Fold: 4  Epoch: 241  Training loss = 1.5932  Validation loss = 4.5615  \n",
      "\n",
      "Fold: 4  Epoch: 242  Training loss = 1.5932  Validation loss = 4.5611  \n",
      "\n",
      "Fold: 4  Epoch: 243  Training loss = 1.5931  Validation loss = 4.5609  \n",
      "\n",
      "Fold: 4  Epoch: 244  Training loss = 1.5931  Validation loss = 4.5608  \n",
      "\n",
      "Fold: 4  Epoch: 245  Training loss = 1.5931  Validation loss = 4.5605  \n",
      "\n",
      "Fold: 4  Epoch: 246  Training loss = 1.5930  Validation loss = 4.5598  \n",
      "\n",
      "Fold: 4  Epoch: 247  Training loss = 1.5929  Validation loss = 4.5595  \n",
      "\n",
      "Fold: 4  Epoch: 248  Training loss = 1.5929  Validation loss = 4.5594  \n",
      "\n",
      "Fold: 4  Epoch: 249  Training loss = 1.5929  Validation loss = 4.5596  \n",
      "\n",
      "Fold: 4  Epoch: 250  Training loss = 1.5928  Validation loss = 4.5592  \n",
      "\n",
      "Fold: 4  Epoch: 251  Training loss = 1.5928  Validation loss = 4.5591  \n",
      "\n",
      "Fold: 4  Epoch: 252  Training loss = 1.5927  Validation loss = 4.5584  \n",
      "\n",
      "Fold: 4  Epoch: 253  Training loss = 1.5927  Validation loss = 4.5580  \n",
      "\n",
      "Fold: 4  Epoch: 254  Training loss = 1.5927  Validation loss = 4.5580  \n",
      "\n",
      "Fold: 4  Epoch: 255  Training loss = 1.5926  Validation loss = 4.5574  \n",
      "\n",
      "Fold: 4  Epoch: 256  Training loss = 1.5925  Validation loss = 4.5567  \n",
      "\n",
      "Fold: 4  Epoch: 257  Training loss = 1.5925  Validation loss = 4.5566  \n",
      "\n",
      "Fold: 4  Epoch: 258  Training loss = 1.5924  Validation loss = 4.5561  \n",
      "\n",
      "Fold: 4  Epoch: 259  Training loss = 1.5923  Validation loss = 4.5554  \n",
      "\n",
      "Fold: 4  Epoch: 260  Training loss = 1.5922  Validation loss = 4.5549  \n",
      "\n",
      "Fold: 4  Epoch: 261  Training loss = 1.5922  Validation loss = 4.5549  \n",
      "\n",
      "Fold: 4  Epoch: 262  Training loss = 1.5921  Validation loss = 4.5542  \n",
      "\n",
      "Fold: 4  Epoch: 263  Training loss = 1.5920  Validation loss = 4.5537  \n",
      "\n",
      "Fold: 4  Epoch: 264  Training loss = 1.5920  Validation loss = 4.5532  \n",
      "\n",
      "Fold: 4  Epoch: 265  Training loss = 1.5919  Validation loss = 4.5530  \n",
      "\n",
      "Fold: 4  Epoch: 266  Training loss = 1.5920  Validation loss = 4.5534  \n",
      "\n",
      "Fold: 4  Epoch: 267  Training loss = 1.5919  Validation loss = 4.5526  \n",
      "\n",
      "Fold: 4  Epoch: 268  Training loss = 1.5918  Validation loss = 4.5522  \n",
      "\n",
      "Fold: 4  Epoch: 269  Training loss = 1.5918  Validation loss = 4.5523  \n",
      "\n",
      "Fold: 4  Epoch: 270  Training loss = 1.5917  Validation loss = 4.5516  \n",
      "\n",
      "Fold: 4  Epoch: 271  Training loss = 1.5916  Validation loss = 4.5512  \n",
      "\n",
      "Fold: 4  Epoch: 272  Training loss = 1.5916  Validation loss = 4.5510  \n",
      "\n",
      "Fold: 4  Epoch: 273  Training loss = 1.5916  Validation loss = 4.5507  \n",
      "\n",
      "Fold: 4  Epoch: 274  Training loss = 1.5914  Validation loss = 4.5496  \n",
      "\n",
      "Fold: 4  Epoch: 275  Training loss = 1.5914  Validation loss = 4.5492  \n",
      "\n",
      "Fold: 4  Epoch: 276  Training loss = 1.5912  Validation loss = 4.5482  \n",
      "\n",
      "Fold: 4  Epoch: 277  Training loss = 1.5912  Validation loss = 4.5478  \n",
      "\n",
      "Fold: 4  Epoch: 278  Training loss = 1.5911  Validation loss = 4.5471  \n",
      "\n",
      "Fold: 4  Epoch: 279  Training loss = 1.5911  Validation loss = 4.5476  \n",
      "\n",
      "Fold: 4  Epoch: 280  Training loss = 1.5911  Validation loss = 4.5478  \n",
      "\n",
      "Fold: 4  Epoch: 281  Training loss = 1.5911  Validation loss = 4.5476  \n",
      "\n",
      "Fold: 4  Epoch: 282  Training loss = 1.5910  Validation loss = 4.5468  \n",
      "\n",
      "Fold: 4  Epoch: 283  Training loss = 1.5909  Validation loss = 4.5466  \n",
      "\n",
      "Fold: 4  Epoch: 284  Training loss = 1.5909  Validation loss = 4.5466  \n",
      "\n",
      "Fold: 4  Epoch: 285  Training loss = 1.5908  Validation loss = 4.5459  \n",
      "\n",
      "Fold: 4  Epoch: 286  Training loss = 1.5908  Validation loss = 4.5459  \n",
      "\n",
      "Fold: 4  Epoch: 287  Training loss = 1.5908  Validation loss = 4.5458  \n",
      "\n",
      "Fold: 4  Epoch: 288  Training loss = 1.5908  Validation loss = 4.5456  \n",
      "\n",
      "Fold: 4  Epoch: 289  Training loss = 1.5907  Validation loss = 4.5457  \n",
      "\n",
      "Fold: 4  Epoch: 290  Training loss = 1.5906  Validation loss = 4.5446  \n",
      "\n",
      "Fold: 4  Epoch: 291  Training loss = 1.5906  Validation loss = 4.5445  \n",
      "\n",
      "Fold: 4  Epoch: 292  Training loss = 1.5905  Validation loss = 4.5440  \n",
      "\n",
      "Fold: 4  Epoch: 293  Training loss = 1.5905  Validation loss = 4.5440  \n",
      "\n",
      "Fold: 4  Epoch: 294  Training loss = 1.5904  Validation loss = 4.5436  \n",
      "\n",
      "Fold: 4  Epoch: 295  Training loss = 1.5904  Validation loss = 4.5438  \n",
      "\n",
      "Fold: 4  Epoch: 296  Training loss = 1.5904  Validation loss = 4.5433  \n",
      "\n",
      "Fold: 4  Epoch: 297  Training loss = 1.5903  Validation loss = 4.5426  \n",
      "\n",
      "Fold: 4  Epoch: 298  Training loss = 1.5902  Validation loss = 4.5427  \n",
      "\n",
      "Fold: 4  Epoch: 299  Training loss = 1.5902  Validation loss = 4.5425  \n",
      "\n",
      "Fold: 4  Epoch: 300  Training loss = 1.5901  Validation loss = 4.5419  \n",
      "\n",
      "Fold: 4  Epoch: 301  Training loss = 1.5901  Validation loss = 4.5416  \n",
      "\n",
      "Fold: 4  Epoch: 302  Training loss = 1.5900  Validation loss = 4.5410  \n",
      "\n",
      "Fold: 4  Epoch: 303  Training loss = 1.5899  Validation loss = 4.5404  \n",
      "\n",
      "Fold: 4  Epoch: 304  Training loss = 1.5898  Validation loss = 4.5397  \n",
      "\n",
      "Fold: 4  Epoch: 305  Training loss = 1.5898  Validation loss = 4.5393  \n",
      "\n",
      "Fold: 4  Epoch: 306  Training loss = 1.5897  Validation loss = 4.5386  \n",
      "\n",
      "Fold: 4  Epoch: 307  Training loss = 1.5897  Validation loss = 4.5385  \n",
      "\n",
      "Fold: 4  Epoch: 308  Training loss = 1.5896  Validation loss = 4.5381  \n",
      "\n",
      "Fold: 4  Epoch: 309  Training loss = 1.5896  Validation loss = 4.5383  \n",
      "\n",
      "Fold: 4  Epoch: 310  Training loss = 1.5896  Validation loss = 4.5380  \n",
      "\n",
      "Fold: 4  Epoch: 311  Training loss = 1.5896  Validation loss = 4.5383  \n",
      "\n",
      "Fold: 4  Epoch: 312  Training loss = 1.5894  Validation loss = 4.5372  \n",
      "\n",
      "Fold: 4  Epoch: 313  Training loss = 1.5893  Validation loss = 4.5360  \n",
      "\n",
      "Fold: 4  Epoch: 314  Training loss = 1.5892  Validation loss = 4.5349  \n",
      "\n",
      "Fold: 4  Epoch: 315  Training loss = 1.5891  Validation loss = 4.5346  \n",
      "\n",
      "Fold: 4  Epoch: 316  Training loss = 1.5891  Validation loss = 4.5341  \n",
      "\n",
      "Fold: 4  Epoch: 317  Training loss = 1.5890  Validation loss = 4.5337  \n",
      "\n",
      "Fold: 4  Epoch: 318  Training loss = 1.5890  Validation loss = 4.5334  \n",
      "\n",
      "Fold: 4  Epoch: 319  Training loss = 1.5889  Validation loss = 4.5325  \n",
      "\n",
      "Fold: 4  Epoch: 320  Training loss = 1.5888  Validation loss = 4.5318  \n",
      "\n",
      "Fold: 4  Epoch: 321  Training loss = 1.5888  Validation loss = 4.5316  \n",
      "\n",
      "Fold: 4  Epoch: 322  Training loss = 1.5887  Validation loss = 4.5310  \n",
      "\n",
      "Fold: 4  Epoch: 323  Training loss = 1.5886  Validation loss = 4.5302  \n",
      "\n",
      "Fold: 4  Epoch: 324  Training loss = 1.5885  Validation loss = 4.5299  \n",
      "\n",
      "Fold: 4  Epoch: 325  Training loss = 1.5885  Validation loss = 4.5299  \n",
      "\n",
      "Fold: 4  Epoch: 326  Training loss = 1.5884  Validation loss = 4.5292  \n",
      "\n",
      "Fold: 4  Epoch: 327  Training loss = 1.5884  Validation loss = 4.5290  \n",
      "\n",
      "Fold: 4  Epoch: 328  Training loss = 1.5883  Validation loss = 4.5282  \n",
      "\n",
      "Fold: 4  Epoch: 329  Training loss = 1.5883  Validation loss = 4.5279  \n",
      "\n",
      "Fold: 4  Epoch: 330  Training loss = 1.5882  Validation loss = 4.5277  \n",
      "\n",
      "Fold: 4  Epoch: 331  Training loss = 1.5882  Validation loss = 4.5277  \n",
      "\n",
      "Fold: 4  Epoch: 332  Training loss = 1.5882  Validation loss = 4.5276  \n",
      "\n",
      "Fold: 4  Epoch: 333  Training loss = 1.5881  Validation loss = 4.5272  \n",
      "\n",
      "Fold: 4  Epoch: 334  Training loss = 1.5881  Validation loss = 4.5265  \n",
      "\n",
      "Fold: 4  Epoch: 335  Training loss = 1.5880  Validation loss = 4.5263  \n",
      "\n",
      "Fold: 4  Epoch: 336  Training loss = 1.5880  Validation loss = 4.5260  \n",
      "\n",
      "Fold: 4  Epoch: 337  Training loss = 1.5879  Validation loss = 4.5253  \n",
      "\n",
      "Fold: 4  Epoch: 338  Training loss = 1.5878  Validation loss = 4.5250  \n",
      "\n",
      "Fold: 4  Epoch: 339  Training loss = 1.5877  Validation loss = 4.5243  \n",
      "\n",
      "Fold: 4  Epoch: 340  Training loss = 1.5877  Validation loss = 4.5236  \n",
      "\n",
      "Fold: 4  Epoch: 341  Training loss = 1.5875  Validation loss = 4.5226  \n",
      "\n",
      "Fold: 4  Epoch: 342  Training loss = 1.5875  Validation loss = 4.5227  \n",
      "\n",
      "Fold: 4  Epoch: 343  Training loss = 1.5875  Validation loss = 4.5223  \n",
      "\n",
      "Fold: 4  Epoch: 344  Training loss = 1.5874  Validation loss = 4.5216  \n",
      "\n",
      "Fold: 4  Epoch: 345  Training loss = 1.5873  Validation loss = 4.5210  \n",
      "\n",
      "Fold: 4  Epoch: 346  Training loss = 1.5872  Validation loss = 4.5201  \n",
      "\n",
      "Fold: 4  Epoch: 347  Training loss = 1.5872  Validation loss = 4.5196  \n",
      "\n",
      "Fold: 4  Epoch: 348  Training loss = 1.5871  Validation loss = 4.5194  \n",
      "\n",
      "Fold: 4  Epoch: 349  Training loss = 1.5871  Validation loss = 4.5189  \n",
      "\n",
      "Fold: 4  Epoch: 350  Training loss = 1.5870  Validation loss = 4.5188  \n",
      "\n",
      "Fold: 4  Epoch: 351  Training loss = 1.5870  Validation loss = 4.5183  \n",
      "\n",
      "Fold: 4  Epoch: 352  Training loss = 1.5869  Validation loss = 4.5178  \n",
      "\n",
      "Fold: 4  Epoch: 353  Training loss = 1.5868  Validation loss = 4.5168  \n",
      "\n",
      "Fold: 4  Epoch: 354  Training loss = 1.5867  Validation loss = 4.5164  \n",
      "\n",
      "Fold: 4  Epoch: 355  Training loss = 1.5867  Validation loss = 4.5160  \n",
      "\n",
      "Fold: 4  Epoch: 356  Training loss = 1.5866  Validation loss = 4.5154  \n",
      "\n",
      "Fold: 4  Epoch: 357  Training loss = 1.5866  Validation loss = 4.5157  \n",
      "\n",
      "Fold: 4  Epoch: 358  Training loss = 1.5866  Validation loss = 4.5153  \n",
      "\n",
      "Fold: 4  Epoch: 359  Training loss = 1.5865  Validation loss = 4.5150  \n",
      "\n",
      "Fold: 4  Epoch: 360  Training loss = 1.5864  Validation loss = 4.5141  \n",
      "\n",
      "Fold: 4  Epoch: 361  Training loss = 1.5864  Validation loss = 4.5139  \n",
      "\n",
      "Fold: 4  Epoch: 362  Training loss = 1.5864  Validation loss = 4.5143  \n",
      "\n",
      "Fold: 4  Epoch: 363  Training loss = 1.5864  Validation loss = 4.5142  \n",
      "\n",
      "Fold: 4  Epoch: 364  Training loss = 1.5863  Validation loss = 4.5143  \n",
      "\n",
      "Fold: 4  Epoch: 365  Training loss = 1.5862  Validation loss = 4.5131  \n",
      "\n",
      "Fold: 4  Epoch: 366  Training loss = 1.5862  Validation loss = 4.5126  \n",
      "\n",
      "Fold: 4  Epoch: 367  Training loss = 1.5861  Validation loss = 4.5126  \n",
      "\n",
      "Fold: 4  Epoch: 368  Training loss = 1.5861  Validation loss = 4.5122  \n",
      "\n",
      "Fold: 4  Epoch: 369  Training loss = 1.5860  Validation loss = 4.5119  \n",
      "\n",
      "Fold: 4  Epoch: 370  Training loss = 1.5859  Validation loss = 4.5113  \n",
      "\n",
      "Fold: 4  Epoch: 371  Training loss = 1.5859  Validation loss = 4.5109  \n",
      "\n",
      "Fold: 4  Epoch: 372  Training loss = 1.5858  Validation loss = 4.5106  \n",
      "\n",
      "Fold: 4  Epoch: 373  Training loss = 1.5858  Validation loss = 4.5101  \n",
      "\n",
      "Fold: 4  Epoch: 374  Training loss = 1.5857  Validation loss = 4.5093  \n",
      "\n",
      "Fold: 4  Epoch: 375  Training loss = 1.5856  Validation loss = 4.5091  \n",
      "\n",
      "Fold: 4  Epoch: 376  Training loss = 1.5856  Validation loss = 4.5090  \n",
      "\n",
      "Fold: 4  Epoch: 377  Training loss = 1.5856  Validation loss = 4.5086  \n",
      "\n",
      "Fold: 4  Epoch: 378  Training loss = 1.5855  Validation loss = 4.5086  \n",
      "\n",
      "Fold: 4  Epoch: 379  Training loss = 1.5855  Validation loss = 4.5082  \n",
      "\n",
      "Fold: 4  Epoch: 380  Training loss = 1.5854  Validation loss = 4.5078  \n",
      "\n",
      "Fold: 4  Epoch: 381  Training loss = 1.5854  Validation loss = 4.5079  \n",
      "\n",
      "Fold: 4  Epoch: 382  Training loss = 1.5853  Validation loss = 4.5074  \n",
      "\n",
      "Fold: 4  Epoch: 383  Training loss = 1.5853  Validation loss = 4.5066  \n",
      "\n",
      "Fold: 4  Epoch: 384  Training loss = 1.5852  Validation loss = 4.5061  \n",
      "\n",
      "Fold: 4  Epoch: 385  Training loss = 1.5852  Validation loss = 4.5060  \n",
      "\n",
      "Fold: 4  Epoch: 386  Training loss = 1.5851  Validation loss = 4.5058  \n",
      "\n",
      "Fold: 4  Epoch: 387  Training loss = 1.5851  Validation loss = 4.5053  \n",
      "\n",
      "Fold: 4  Epoch: 388  Training loss = 1.5850  Validation loss = 4.5046  \n",
      "\n",
      "Fold: 4  Epoch: 389  Training loss = 1.5850  Validation loss = 4.5044  \n",
      "\n",
      "Fold: 4  Epoch: 390  Training loss = 1.5850  Validation loss = 4.5046  \n",
      "\n",
      "Fold: 4  Epoch: 391  Training loss = 1.5849  Validation loss = 4.5042  \n",
      "\n",
      "Fold: 4  Epoch: 392  Training loss = 1.5848  Validation loss = 4.5038  \n",
      "\n",
      "Fold: 4  Epoch: 393  Training loss = 1.5848  Validation loss = 4.5033  \n",
      "\n",
      "Fold: 4  Epoch: 394  Training loss = 1.5847  Validation loss = 4.5023  \n",
      "\n",
      "Fold: 4  Epoch: 395  Training loss = 1.5846  Validation loss = 4.5021  \n",
      "\n",
      "Fold: 4  Epoch: 396  Training loss = 1.5847  Validation loss = 4.5024  \n",
      "\n",
      "Fold: 4  Epoch: 397  Training loss = 1.5846  Validation loss = 4.5016  \n",
      "\n",
      "Fold: 4  Epoch: 398  Training loss = 1.5845  Validation loss = 4.5013  \n",
      "\n",
      "Fold: 4  Epoch: 399  Training loss = 1.5845  Validation loss = 4.5007  \n",
      "\n",
      "Fold: 4  Epoch: 400  Training loss = 1.5844  Validation loss = 4.5002  \n",
      "\n",
      "Fold: 4  Epoch: 401  Training loss = 1.5844  Validation loss = 4.5001  \n",
      "\n",
      "Fold: 4  Epoch: 402  Training loss = 1.5843  Validation loss = 4.4997  \n",
      "\n",
      "Fold: 4  Epoch: 403  Training loss = 1.5843  Validation loss = 4.4994  \n",
      "\n",
      "Fold: 4  Epoch: 404  Training loss = 1.5842  Validation loss = 4.4991  \n",
      "\n",
      "Fold: 4  Epoch: 405  Training loss = 1.5842  Validation loss = 4.4992  \n",
      "\n",
      "Fold: 4  Epoch: 406  Training loss = 1.5841  Validation loss = 4.4985  \n",
      "\n",
      "Fold: 4  Epoch: 407  Training loss = 1.5841  Validation loss = 4.4978  \n",
      "\n",
      "Fold: 4  Epoch: 408  Training loss = 1.5840  Validation loss = 4.4976  \n",
      "\n",
      "Fold: 4  Epoch: 409  Training loss = 1.5841  Validation loss = 4.4980  \n",
      "\n",
      "Fold: 4  Epoch: 410  Training loss = 1.5840  Validation loss = 4.4973  \n",
      "\n",
      "Fold: 4  Epoch: 411  Training loss = 1.5839  Validation loss = 4.4969  \n",
      "\n",
      "Fold: 4  Epoch: 412  Training loss = 1.5839  Validation loss = 4.4966  \n",
      "\n",
      "Fold: 4  Epoch: 413  Training loss = 1.5838  Validation loss = 4.4960  \n",
      "\n",
      "Fold: 4  Epoch: 414  Training loss = 1.5838  Validation loss = 4.4955  \n",
      "\n",
      "Fold: 4  Epoch: 415  Training loss = 1.5837  Validation loss = 4.4952  \n",
      "\n",
      "Fold: 4  Epoch: 416  Training loss = 1.5837  Validation loss = 4.4951  \n",
      "\n",
      "Fold: 4  Epoch: 417  Training loss = 1.5836  Validation loss = 4.4947  \n",
      "\n",
      "Fold: 4  Epoch: 418  Training loss = 1.5835  Validation loss = 4.4940  \n",
      "\n",
      "Fold: 4  Epoch: 419  Training loss = 1.5835  Validation loss = 4.4938  \n",
      "\n",
      "Fold: 4  Epoch: 420  Training loss = 1.5834  Validation loss = 4.4928  \n",
      "\n",
      "Fold: 4  Epoch: 421  Training loss = 1.5834  Validation loss = 4.4927  \n",
      "\n",
      "Fold: 4  Epoch: 422  Training loss = 1.5833  Validation loss = 4.4919  \n",
      "\n",
      "Fold: 4  Epoch: 423  Training loss = 1.5833  Validation loss = 4.4915  \n",
      "\n",
      "Fold: 4  Epoch: 424  Training loss = 1.5832  Validation loss = 4.4915  \n",
      "\n",
      "Fold: 4  Epoch: 425  Training loss = 1.5832  Validation loss = 4.4913  \n",
      "\n",
      "Fold: 4  Epoch: 426  Training loss = 1.5832  Validation loss = 4.4912  \n",
      "\n",
      "Fold: 4  Epoch: 427  Training loss = 1.5832  Validation loss = 4.4915  \n",
      "\n",
      "Fold: 4  Epoch: 428  Training loss = 1.5832  Validation loss = 4.4916  \n",
      "\n",
      "Fold: 4  Epoch: 429  Training loss = 1.5831  Validation loss = 4.4913  \n",
      "\n",
      "Fold: 4  Epoch: 430  Training loss = 1.5831  Validation loss = 4.4912  \n",
      "\n",
      "Fold: 4  Epoch: 431  Training loss = 1.5830  Validation loss = 4.4906  \n",
      "\n",
      "Fold: 4  Epoch: 432  Training loss = 1.5830  Validation loss = 4.4905  \n",
      "\n",
      "Fold: 4  Epoch: 433  Training loss = 1.5829  Validation loss = 4.4895  \n",
      "\n",
      "Fold: 4  Epoch: 434  Training loss = 1.5829  Validation loss = 4.4896  \n",
      "\n",
      "Fold: 4  Epoch: 435  Training loss = 1.5828  Validation loss = 4.4889  \n",
      "\n",
      "Fold: 4  Epoch: 436  Training loss = 1.5828  Validation loss = 4.4886  \n",
      "\n",
      "Fold: 4  Epoch: 437  Training loss = 1.5827  Validation loss = 4.4879  \n",
      "\n",
      "Fold: 4  Epoch: 438  Training loss = 1.5826  Validation loss = 4.4869  \n",
      "\n",
      "Fold: 4  Epoch: 439  Training loss = 1.5825  Validation loss = 4.4868  \n",
      "\n",
      "Fold: 4  Epoch: 440  Training loss = 1.5825  Validation loss = 4.4863  \n",
      "\n",
      "Fold: 4  Epoch: 441  Training loss = 1.5824  Validation loss = 4.4856  \n",
      "\n",
      "Fold: 4  Epoch: 442  Training loss = 1.5824  Validation loss = 4.4851  \n",
      "\n",
      "Fold: 4  Epoch: 443  Training loss = 1.5823  Validation loss = 4.4846  \n",
      "\n",
      "Fold: 4  Epoch: 444  Training loss = 1.5822  Validation loss = 4.4839  \n",
      "\n",
      "Fold: 4  Epoch: 445  Training loss = 1.5822  Validation loss = 4.4839  \n",
      "\n",
      "Fold: 4  Epoch: 446  Training loss = 1.5822  Validation loss = 4.4839  \n",
      "\n",
      "Fold: 4  Epoch: 447  Training loss = 1.5821  Validation loss = 4.4837  \n",
      "\n",
      "Fold: 4  Epoch: 448  Training loss = 1.5821  Validation loss = 4.4832  \n",
      "\n",
      "Fold: 4  Epoch: 449  Training loss = 1.5821  Validation loss = 4.4832  \n",
      "\n",
      "Fold: 4  Epoch: 450  Training loss = 1.5820  Validation loss = 4.4827  \n",
      "\n",
      "Fold: 4  Epoch: 451  Training loss = 1.5820  Validation loss = 4.4824  \n",
      "\n",
      "Fold: 4  Epoch: 452  Training loss = 1.5819  Validation loss = 4.4820  \n",
      "\n",
      "Fold: 4  Epoch: 453  Training loss = 1.5819  Validation loss = 4.4816  \n",
      "\n",
      "Fold: 4  Epoch: 454  Training loss = 1.5819  Validation loss = 4.4813  \n",
      "\n",
      "Fold: 4  Epoch: 455  Training loss = 1.5818  Validation loss = 4.4811  \n",
      "\n",
      "Fold: 4  Epoch: 456  Training loss = 1.5818  Validation loss = 4.4809  \n",
      "\n",
      "Fold: 4  Epoch: 457  Training loss = 1.5817  Validation loss = 4.4797  \n",
      "\n",
      "Fold: 4  Epoch: 458  Training loss = 1.5816  Validation loss = 4.4797  \n",
      "\n",
      "Fold: 4  Epoch: 459  Training loss = 1.5816  Validation loss = 4.4792  \n",
      "\n",
      "Fold: 4  Epoch: 460  Training loss = 1.5816  Validation loss = 4.4793  \n",
      "\n",
      "Fold: 4  Epoch: 461  Training loss = 1.5815  Validation loss = 4.4780  \n",
      "\n",
      "Fold: 4  Epoch: 462  Training loss = 1.5814  Validation loss = 4.4775  \n",
      "\n",
      "Fold: 4  Epoch: 463  Training loss = 1.5813  Validation loss = 4.4769  \n",
      "\n",
      "Fold: 4  Epoch: 464  Training loss = 1.5812  Validation loss = 4.4759  \n",
      "\n",
      "Fold: 4  Epoch: 465  Training loss = 1.5812  Validation loss = 4.4758  \n",
      "\n",
      "Fold: 4  Epoch: 466  Training loss = 1.5812  Validation loss = 4.4756  \n",
      "\n",
      "Fold: 4  Epoch: 467  Training loss = 1.5812  Validation loss = 4.4756  \n",
      "\n",
      "Fold: 4  Epoch: 468  Training loss = 1.5811  Validation loss = 4.4751  \n",
      "\n",
      "Fold: 4  Epoch: 469  Training loss = 1.5811  Validation loss = 4.4748  \n",
      "\n",
      "Fold: 4  Epoch: 470  Training loss = 1.5810  Validation loss = 4.4742  \n",
      "\n",
      "Fold: 4  Epoch: 471  Training loss = 1.5809  Validation loss = 4.4735  \n",
      "\n",
      "Fold: 4  Epoch: 472  Training loss = 1.5809  Validation loss = 4.4733  \n",
      "\n",
      "Fold: 4  Epoch: 473  Training loss = 1.5808  Validation loss = 4.4728  \n",
      "\n",
      "Fold: 4  Epoch: 474  Training loss = 1.5808  Validation loss = 4.4724  \n",
      "\n",
      "Fold: 4  Epoch: 475  Training loss = 1.5807  Validation loss = 4.4722  \n",
      "\n",
      "Fold: 4  Epoch: 476  Training loss = 1.5807  Validation loss = 4.4717  \n",
      "\n",
      "Fold: 4  Epoch: 477  Training loss = 1.5806  Validation loss = 4.4713  \n",
      "\n",
      "Fold: 4  Epoch: 478  Training loss = 1.5806  Validation loss = 4.4712  \n",
      "\n",
      "Fold: 4  Epoch: 479  Training loss = 1.5806  Validation loss = 4.4710  \n",
      "\n",
      "Fold: 4  Epoch: 480  Training loss = 1.5806  Validation loss = 4.4708  \n",
      "\n",
      "Fold: 4  Epoch: 481  Training loss = 1.5805  Validation loss = 4.4700  \n",
      "\n",
      "Fold: 4  Epoch: 482  Training loss = 1.5804  Validation loss = 4.4692  \n",
      "\n",
      "Fold: 4  Epoch: 483  Training loss = 1.5803  Validation loss = 4.4682  \n",
      "\n",
      "Fold: 4  Epoch: 484  Training loss = 1.5802  Validation loss = 4.4675  \n",
      "\n",
      "Fold: 4  Epoch: 485  Training loss = 1.5802  Validation loss = 4.4677  \n",
      "\n",
      "Fold: 4  Epoch: 486  Training loss = 1.5802  Validation loss = 4.4674  \n",
      "\n",
      "Fold: 4  Epoch: 487  Training loss = 1.5802  Validation loss = 4.4672  \n",
      "\n",
      "Fold: 4  Epoch: 488  Training loss = 1.5801  Validation loss = 4.4672  \n",
      "\n",
      "Fold: 4  Epoch: 489  Training loss = 1.5801  Validation loss = 4.4675  \n",
      "\n",
      "Fold: 4  Epoch: 490  Training loss = 1.5801  Validation loss = 4.4680  \n",
      "\n",
      "Fold: 4  Epoch: 491  Training loss = 1.5801  Validation loss = 4.4676  \n",
      "\n",
      "Fold: 4  Epoch: 492  Training loss = 1.5800  Validation loss = 4.4673  \n",
      "\n",
      "Fold: 4  Epoch: 493  Training loss = 1.5800  Validation loss = 4.4672  \n",
      "\n",
      "Fold: 4  Epoch: 494  Training loss = 1.5800  Validation loss = 4.4671  \n",
      "\n",
      "Fold: 4  Epoch: 495  Training loss = 1.5799  Validation loss = 4.4667  \n",
      "\n",
      "Fold: 4  Epoch: 496  Training loss = 1.5799  Validation loss = 4.4665  \n",
      "\n",
      "Fold: 4  Epoch: 497  Training loss = 1.5798  Validation loss = 4.4661  \n",
      "\n",
      "Fold: 4  Epoch: 498  Training loss = 1.5798  Validation loss = 4.4652  \n",
      "\n",
      "Fold: 4  Epoch: 499  Training loss = 1.5797  Validation loss = 4.4646  \n",
      "\n",
      "Fold: 4  Epoch: 500  Training loss = 1.5797  Validation loss = 4.4646  \n",
      "\n",
      "Check model:  Fold: 4  Optimal epoch: 499  \n",
      "\n",
      "Fold: 5  Epoch: 1  Training loss = 1.8869  Validation loss = 4.6974  \n",
      "\n",
      "Fold: 5  Epoch: 2  Training loss = 1.8868  Validation loss = 4.6971  \n",
      "\n",
      "Fold: 5  Epoch: 3  Training loss = 1.8864  Validation loss = 4.6955  \n",
      "\n",
      "Fold: 5  Epoch: 4  Training loss = 1.8861  Validation loss = 4.6945  \n",
      "\n",
      "Fold: 5  Epoch: 5  Training loss = 1.8860  Validation loss = 4.6940  \n",
      "\n",
      "Fold: 5  Epoch: 6  Training loss = 1.8856  Validation loss = 4.6922  \n",
      "\n",
      "Fold: 5  Epoch: 7  Training loss = 1.8852  Validation loss = 4.6909  \n",
      "\n",
      "Fold: 5  Epoch: 8  Training loss = 1.8850  Validation loss = 4.6898  \n",
      "\n",
      "Fold: 5  Epoch: 9  Training loss = 1.8846  Validation loss = 4.6882  \n",
      "\n",
      "Fold: 5  Epoch: 10  Training loss = 1.8842  Validation loss = 4.6869  \n",
      "\n",
      "Fold: 5  Epoch: 11  Training loss = 1.8840  Validation loss = 4.6859  \n",
      "\n",
      "Fold: 5  Epoch: 12  Training loss = 1.8837  Validation loss = 4.6848  \n",
      "\n",
      "Fold: 5  Epoch: 13  Training loss = 1.8834  Validation loss = 4.6835  \n",
      "\n",
      "Fold: 5  Epoch: 14  Training loss = 1.8833  Validation loss = 4.6835  \n",
      "\n",
      "Fold: 5  Epoch: 15  Training loss = 1.8830  Validation loss = 4.6826  \n",
      "\n",
      "Fold: 5  Epoch: 16  Training loss = 1.8826  Validation loss = 4.6811  \n",
      "\n",
      "Fold: 5  Epoch: 17  Training loss = 1.8824  Validation loss = 4.6802  \n",
      "\n",
      "Fold: 5  Epoch: 18  Training loss = 1.8822  Validation loss = 4.6792  \n",
      "\n",
      "Fold: 5  Epoch: 19  Training loss = 1.8819  Validation loss = 4.6780  \n",
      "\n",
      "Fold: 5  Epoch: 20  Training loss = 1.8816  Validation loss = 4.6767  \n",
      "\n",
      "Fold: 5  Epoch: 21  Training loss = 1.8813  Validation loss = 4.6755  \n",
      "\n",
      "Fold: 5  Epoch: 22  Training loss = 1.8811  Validation loss = 4.6743  \n",
      "\n",
      "Fold: 5  Epoch: 23  Training loss = 1.8807  Validation loss = 4.6729  \n",
      "\n",
      "Fold: 5  Epoch: 24  Training loss = 1.8806  Validation loss = 4.6726  \n",
      "\n",
      "Fold: 5  Epoch: 25  Training loss = 1.8802  Validation loss = 4.6714  \n",
      "\n",
      "Fold: 5  Epoch: 26  Training loss = 1.8798  Validation loss = 4.6698  \n",
      "\n",
      "Fold: 5  Epoch: 27  Training loss = 1.8797  Validation loss = 4.6693  \n",
      "\n",
      "Fold: 5  Epoch: 28  Training loss = 1.8796  Validation loss = 4.6689  \n",
      "\n",
      "Fold: 5  Epoch: 29  Training loss = 1.8796  Validation loss = 4.6691  \n",
      "\n",
      "Fold: 5  Epoch: 30  Training loss = 1.8792  Validation loss = 4.6676  \n",
      "\n",
      "Fold: 5  Epoch: 31  Training loss = 1.8791  Validation loss = 4.6671  \n",
      "\n",
      "Fold: 5  Epoch: 32  Training loss = 1.8789  Validation loss = 4.6661  \n",
      "\n",
      "Fold: 5  Epoch: 33  Training loss = 1.8787  Validation loss = 4.6655  \n",
      "\n",
      "Fold: 5  Epoch: 34  Training loss = 1.8786  Validation loss = 4.6650  \n",
      "\n",
      "Fold: 5  Epoch: 35  Training loss = 1.8785  Validation loss = 4.6650  \n",
      "\n",
      "Fold: 5  Epoch: 36  Training loss = 1.8784  Validation loss = 4.6646  \n",
      "\n",
      "Fold: 5  Epoch: 37  Training loss = 1.8781  Validation loss = 4.6636  \n",
      "\n",
      "Fold: 5  Epoch: 38  Training loss = 1.8778  Validation loss = 4.6625  \n",
      "\n",
      "Fold: 5  Epoch: 39  Training loss = 1.8776  Validation loss = 4.6617  \n",
      "\n",
      "Fold: 5  Epoch: 40  Training loss = 1.8774  Validation loss = 4.6607  \n",
      "\n",
      "Fold: 5  Epoch: 41  Training loss = 1.8771  Validation loss = 4.6597  \n",
      "\n",
      "Fold: 5  Epoch: 42  Training loss = 1.8769  Validation loss = 4.6591  \n",
      "\n",
      "Fold: 5  Epoch: 43  Training loss = 1.8767  Validation loss = 4.6584  \n",
      "\n",
      "Fold: 5  Epoch: 44  Training loss = 1.8766  Validation loss = 4.6582  \n",
      "\n",
      "Fold: 5  Epoch: 45  Training loss = 1.8765  Validation loss = 4.6576  \n",
      "\n",
      "Fold: 5  Epoch: 46  Training loss = 1.8762  Validation loss = 4.6565  \n",
      "\n",
      "Fold: 5  Epoch: 47  Training loss = 1.8760  Validation loss = 4.6561  \n",
      "\n",
      "Fold: 5  Epoch: 48  Training loss = 1.8759  Validation loss = 4.6554  \n",
      "\n",
      "Fold: 5  Epoch: 49  Training loss = 1.8757  Validation loss = 4.6547  \n",
      "\n",
      "Fold: 5  Epoch: 50  Training loss = 1.8755  Validation loss = 4.6537  \n",
      "\n",
      "Fold: 5  Epoch: 51  Training loss = 1.8753  Validation loss = 4.6531  \n",
      "\n",
      "Fold: 5  Epoch: 52  Training loss = 1.8750  Validation loss = 4.6520  \n",
      "\n",
      "Fold: 5  Epoch: 53  Training loss = 1.8749  Validation loss = 4.6512  \n",
      "\n",
      "Fold: 5  Epoch: 54  Training loss = 1.8747  Validation loss = 4.6507  \n",
      "\n",
      "Fold: 5  Epoch: 55  Training loss = 1.8744  Validation loss = 4.6493  \n",
      "\n",
      "Fold: 5  Epoch: 56  Training loss = 1.8742  Validation loss = 4.6482  \n",
      "\n",
      "Fold: 5  Epoch: 57  Training loss = 1.8740  Validation loss = 4.6477  \n",
      "\n",
      "Fold: 5  Epoch: 58  Training loss = 1.8738  Validation loss = 4.6463  \n",
      "\n",
      "Fold: 5  Epoch: 59  Training loss = 1.8736  Validation loss = 4.6458  \n",
      "\n",
      "Fold: 5  Epoch: 60  Training loss = 1.8734  Validation loss = 4.6450  \n",
      "\n",
      "Fold: 5  Epoch: 61  Training loss = 1.8731  Validation loss = 4.6433  \n",
      "\n",
      "Fold: 5  Epoch: 62  Training loss = 1.8730  Validation loss = 4.6431  \n",
      "\n",
      "Fold: 5  Epoch: 63  Training loss = 1.8729  Validation loss = 4.6424  \n",
      "\n",
      "Fold: 5  Epoch: 64  Training loss = 1.8728  Validation loss = 4.6422  \n",
      "\n",
      "Fold: 5  Epoch: 65  Training loss = 1.8725  Validation loss = 4.6409  \n",
      "\n",
      "Fold: 5  Epoch: 66  Training loss = 1.8723  Validation loss = 4.6397  \n",
      "\n",
      "Fold: 5  Epoch: 67  Training loss = 1.8722  Validation loss = 4.6391  \n",
      "\n",
      "Fold: 5  Epoch: 68  Training loss = 1.8719  Validation loss = 4.6380  \n",
      "\n",
      "Fold: 5  Epoch: 69  Training loss = 1.8716  Validation loss = 4.6366  \n",
      "\n",
      "Fold: 5  Epoch: 70  Training loss = 1.8713  Validation loss = 4.6356  \n",
      "\n",
      "Fold: 5  Epoch: 71  Training loss = 1.8711  Validation loss = 4.6345  \n",
      "\n",
      "Fold: 5  Epoch: 72  Training loss = 1.8708  Validation loss = 4.6332  \n",
      "\n",
      "Fold: 5  Epoch: 73  Training loss = 1.8705  Validation loss = 4.6315  \n",
      "\n",
      "Fold: 5  Epoch: 74  Training loss = 1.8704  Validation loss = 4.6313  \n",
      "\n",
      "Fold: 5  Epoch: 75  Training loss = 1.8703  Validation loss = 4.6312  \n",
      "\n",
      "Fold: 5  Epoch: 76  Training loss = 1.8701  Validation loss = 4.6306  \n",
      "\n",
      "Fold: 5  Epoch: 77  Training loss = 1.8699  Validation loss = 4.6297  \n",
      "\n",
      "Fold: 5  Epoch: 78  Training loss = 1.8697  Validation loss = 4.6289  \n",
      "\n",
      "Fold: 5  Epoch: 79  Training loss = 1.8694  Validation loss = 4.6278  \n",
      "\n",
      "Fold: 5  Epoch: 80  Training loss = 1.8691  Validation loss = 4.6264  \n",
      "\n",
      "Fold: 5  Epoch: 81  Training loss = 1.8688  Validation loss = 4.6251  \n",
      "\n",
      "Fold: 5  Epoch: 82  Training loss = 1.8685  Validation loss = 4.6243  \n",
      "\n",
      "Fold: 5  Epoch: 83  Training loss = 1.8683  Validation loss = 4.6232  \n",
      "\n",
      "Fold: 5  Epoch: 84  Training loss = 1.8681  Validation loss = 4.6223  \n",
      "\n",
      "Fold: 5  Epoch: 85  Training loss = 1.8679  Validation loss = 4.6215  \n",
      "\n",
      "Fold: 5  Epoch: 86  Training loss = 1.8677  Validation loss = 4.6208  \n",
      "\n",
      "Fold: 5  Epoch: 87  Training loss = 1.8677  Validation loss = 4.6211  \n",
      "\n",
      "Fold: 5  Epoch: 88  Training loss = 1.8676  Validation loss = 4.6209  \n",
      "\n",
      "Fold: 5  Epoch: 89  Training loss = 1.8674  Validation loss = 4.6204  \n",
      "\n",
      "Fold: 5  Epoch: 90  Training loss = 1.8671  Validation loss = 4.6191  \n",
      "\n",
      "Fold: 5  Epoch: 91  Training loss = 1.8669  Validation loss = 4.6179  \n",
      "\n",
      "Fold: 5  Epoch: 92  Training loss = 1.8667  Validation loss = 4.6172  \n",
      "\n",
      "Fold: 5  Epoch: 93  Training loss = 1.8664  Validation loss = 4.6161  \n",
      "\n",
      "Fold: 5  Epoch: 94  Training loss = 1.8664  Validation loss = 4.6160  \n",
      "\n",
      "Fold: 5  Epoch: 95  Training loss = 1.8662  Validation loss = 4.6156  \n",
      "\n",
      "Fold: 5  Epoch: 96  Training loss = 1.8662  Validation loss = 4.6155  \n",
      "\n",
      "Fold: 5  Epoch: 97  Training loss = 1.8659  Validation loss = 4.6143  \n",
      "\n",
      "Fold: 5  Epoch: 98  Training loss = 1.8658  Validation loss = 4.6138  \n",
      "\n",
      "Fold: 5  Epoch: 99  Training loss = 1.8656  Validation loss = 4.6129  \n",
      "\n",
      "Fold: 5  Epoch: 100  Training loss = 1.8654  Validation loss = 4.6122  \n",
      "\n",
      "Fold: 5  Epoch: 101  Training loss = 1.8652  Validation loss = 4.6115  \n",
      "\n",
      "Fold: 5  Epoch: 102  Training loss = 1.8650  Validation loss = 4.6104  \n",
      "\n",
      "Fold: 5  Epoch: 103  Training loss = 1.8648  Validation loss = 4.6097  \n",
      "\n",
      "Fold: 5  Epoch: 104  Training loss = 1.8646  Validation loss = 4.6087  \n",
      "\n",
      "Fold: 5  Epoch: 105  Training loss = 1.8643  Validation loss = 4.6077  \n",
      "\n",
      "Fold: 5  Epoch: 106  Training loss = 1.8641  Validation loss = 4.6066  \n",
      "\n",
      "Fold: 5  Epoch: 107  Training loss = 1.8639  Validation loss = 4.6057  \n",
      "\n",
      "Fold: 5  Epoch: 108  Training loss = 1.8638  Validation loss = 4.6052  \n",
      "\n",
      "Fold: 5  Epoch: 109  Training loss = 1.8635  Validation loss = 4.6041  \n",
      "\n",
      "Fold: 5  Epoch: 110  Training loss = 1.8633  Validation loss = 4.6032  \n",
      "\n",
      "Fold: 5  Epoch: 111  Training loss = 1.8632  Validation loss = 4.6028  \n",
      "\n",
      "Fold: 5  Epoch: 112  Training loss = 1.8630  Validation loss = 4.6022  \n",
      "\n",
      "Fold: 5  Epoch: 113  Training loss = 1.8627  Validation loss = 4.6011  \n",
      "\n",
      "Fold: 5  Epoch: 114  Training loss = 1.8626  Validation loss = 4.6007  \n",
      "\n",
      "Fold: 5  Epoch: 115  Training loss = 1.8625  Validation loss = 4.6004  \n",
      "\n",
      "Fold: 5  Epoch: 116  Training loss = 1.8623  Validation loss = 4.5995  \n",
      "\n",
      "Fold: 5  Epoch: 117  Training loss = 1.8621  Validation loss = 4.5988  \n",
      "\n",
      "Fold: 5  Epoch: 118  Training loss = 1.8619  Validation loss = 4.5980  \n",
      "\n",
      "Fold: 5  Epoch: 119  Training loss = 1.8616  Validation loss = 4.5969  \n",
      "\n",
      "Fold: 5  Epoch: 120  Training loss = 1.8613  Validation loss = 4.5954  \n",
      "\n",
      "Fold: 5  Epoch: 121  Training loss = 1.8611  Validation loss = 4.5946  \n",
      "\n",
      "Fold: 5  Epoch: 122  Training loss = 1.8610  Validation loss = 4.5943  \n",
      "\n",
      "Fold: 5  Epoch: 123  Training loss = 1.8607  Validation loss = 4.5930  \n",
      "\n",
      "Fold: 5  Epoch: 124  Training loss = 1.8604  Validation loss = 4.5918  \n",
      "\n",
      "Fold: 5  Epoch: 125  Training loss = 1.8603  Validation loss = 4.5914  \n",
      "\n",
      "Fold: 5  Epoch: 126  Training loss = 1.8601  Validation loss = 4.5909  \n",
      "\n",
      "Fold: 5  Epoch: 127  Training loss = 1.8600  Validation loss = 4.5905  \n",
      "\n",
      "Fold: 5  Epoch: 128  Training loss = 1.8600  Validation loss = 4.5902  \n",
      "\n",
      "Fold: 5  Epoch: 129  Training loss = 1.8599  Validation loss = 4.5896  \n",
      "\n",
      "Fold: 5  Epoch: 130  Training loss = 1.8597  Validation loss = 4.5889  \n",
      "\n",
      "Fold: 5  Epoch: 131  Training loss = 1.8597  Validation loss = 4.5888  \n",
      "\n",
      "Fold: 5  Epoch: 132  Training loss = 1.8595  Validation loss = 4.5879  \n",
      "\n",
      "Fold: 5  Epoch: 133  Training loss = 1.8593  Validation loss = 4.5870  \n",
      "\n",
      "Fold: 5  Epoch: 134  Training loss = 1.8590  Validation loss = 4.5856  \n",
      "\n",
      "Fold: 5  Epoch: 135  Training loss = 1.8588  Validation loss = 4.5844  \n",
      "\n",
      "Fold: 5  Epoch: 136  Training loss = 1.8587  Validation loss = 4.5845  \n",
      "\n",
      "Fold: 5  Epoch: 137  Training loss = 1.8585  Validation loss = 4.5836  \n",
      "\n",
      "Fold: 5  Epoch: 138  Training loss = 1.8583  Validation loss = 4.5828  \n",
      "\n",
      "Fold: 5  Epoch: 139  Training loss = 1.8580  Validation loss = 4.5814  \n",
      "\n",
      "Fold: 5  Epoch: 140  Training loss = 1.8578  Validation loss = 4.5803  \n",
      "\n",
      "Fold: 5  Epoch: 141  Training loss = 1.8577  Validation loss = 4.5798  \n",
      "\n",
      "Fold: 5  Epoch: 142  Training loss = 1.8575  Validation loss = 4.5792  \n",
      "\n",
      "Fold: 5  Epoch: 143  Training loss = 1.8574  Validation loss = 4.5786  \n",
      "\n",
      "Fold: 5  Epoch: 144  Training loss = 1.8573  Validation loss = 4.5782  \n",
      "\n",
      "Fold: 5  Epoch: 145  Training loss = 1.8572  Validation loss = 4.5778  \n",
      "\n",
      "Fold: 5  Epoch: 146  Training loss = 1.8571  Validation loss = 4.5774  \n",
      "\n",
      "Fold: 5  Epoch: 147  Training loss = 1.8568  Validation loss = 4.5761  \n",
      "\n",
      "Fold: 5  Epoch: 148  Training loss = 1.8566  Validation loss = 4.5749  \n",
      "\n",
      "Fold: 5  Epoch: 149  Training loss = 1.8564  Validation loss = 4.5743  \n",
      "\n",
      "Fold: 5  Epoch: 150  Training loss = 1.8561  Validation loss = 4.5730  \n",
      "\n",
      "Fold: 5  Epoch: 151  Training loss = 1.8558  Validation loss = 4.5716  \n",
      "\n",
      "Fold: 5  Epoch: 152  Training loss = 1.8556  Validation loss = 4.5707  \n",
      "\n",
      "Fold: 5  Epoch: 153  Training loss = 1.8554  Validation loss = 4.5698  \n",
      "\n",
      "Fold: 5  Epoch: 154  Training loss = 1.8552  Validation loss = 4.5687  \n",
      "\n",
      "Fold: 5  Epoch: 155  Training loss = 1.8550  Validation loss = 4.5681  \n",
      "\n",
      "Fold: 5  Epoch: 156  Training loss = 1.8549  Validation loss = 4.5678  \n",
      "\n",
      "Fold: 5  Epoch: 157  Training loss = 1.8548  Validation loss = 4.5670  \n",
      "\n",
      "Fold: 5  Epoch: 158  Training loss = 1.8547  Validation loss = 4.5667  \n",
      "\n",
      "Fold: 5  Epoch: 159  Training loss = 1.8545  Validation loss = 4.5660  \n",
      "\n",
      "Fold: 5  Epoch: 160  Training loss = 1.8542  Validation loss = 4.5644  \n",
      "\n",
      "Fold: 5  Epoch: 161  Training loss = 1.8541  Validation loss = 4.5639  \n",
      "\n",
      "Fold: 5  Epoch: 162  Training loss = 1.8539  Validation loss = 4.5636  \n",
      "\n",
      "Fold: 5  Epoch: 163  Training loss = 1.8537  Validation loss = 4.5623  \n",
      "\n",
      "Fold: 5  Epoch: 164  Training loss = 1.8535  Validation loss = 4.5612  \n",
      "\n",
      "Fold: 5  Epoch: 165  Training loss = 1.8534  Validation loss = 4.5607  \n",
      "\n",
      "Fold: 5  Epoch: 166  Training loss = 1.8534  Validation loss = 4.5606  \n",
      "\n",
      "Fold: 5  Epoch: 167  Training loss = 1.8531  Validation loss = 4.5595  \n",
      "\n",
      "Fold: 5  Epoch: 168  Training loss = 1.8531  Validation loss = 4.5592  \n",
      "\n",
      "Fold: 5  Epoch: 169  Training loss = 1.8529  Validation loss = 4.5587  \n",
      "\n",
      "Fold: 5  Epoch: 170  Training loss = 1.8528  Validation loss = 4.5587  \n",
      "\n",
      "Fold: 5  Epoch: 171  Training loss = 1.8527  Validation loss = 4.5584  \n",
      "\n",
      "Fold: 5  Epoch: 172  Training loss = 1.8526  Validation loss = 4.5580  \n",
      "\n",
      "Fold: 5  Epoch: 173  Training loss = 1.8524  Validation loss = 4.5571  \n",
      "\n",
      "Fold: 5  Epoch: 174  Training loss = 1.8523  Validation loss = 4.5564  \n",
      "\n",
      "Fold: 5  Epoch: 175  Training loss = 1.8521  Validation loss = 4.5555  \n",
      "\n",
      "Fold: 5  Epoch: 176  Training loss = 1.8521  Validation loss = 4.5561  \n",
      "\n",
      "Fold: 5  Epoch: 177  Training loss = 1.8519  Validation loss = 4.5555  \n",
      "\n",
      "Fold: 5  Epoch: 178  Training loss = 1.8519  Validation loss = 4.5555  \n",
      "\n",
      "Fold: 5  Epoch: 179  Training loss = 1.8517  Validation loss = 4.5546  \n",
      "\n",
      "Fold: 5  Epoch: 180  Training loss = 1.8515  Validation loss = 4.5540  \n",
      "\n",
      "Fold: 5  Epoch: 181  Training loss = 1.8514  Validation loss = 4.5533  \n",
      "\n",
      "Fold: 5  Epoch: 182  Training loss = 1.8511  Validation loss = 4.5521  \n",
      "\n",
      "Fold: 5  Epoch: 183  Training loss = 1.8509  Validation loss = 4.5507  \n",
      "\n",
      "Fold: 5  Epoch: 184  Training loss = 1.8507  Validation loss = 4.5504  \n",
      "\n",
      "Fold: 5  Epoch: 185  Training loss = 1.8506  Validation loss = 4.5497  \n",
      "\n",
      "Fold: 5  Epoch: 186  Training loss = 1.8505  Validation loss = 4.5496  \n",
      "\n",
      "Fold: 5  Epoch: 187  Training loss = 1.8504  Validation loss = 4.5491  \n",
      "\n",
      "Fold: 5  Epoch: 188  Training loss = 1.8502  Validation loss = 4.5481  \n",
      "\n",
      "Fold: 5  Epoch: 189  Training loss = 1.8501  Validation loss = 4.5479  \n",
      "\n",
      "Fold: 5  Epoch: 190  Training loss = 1.8499  Validation loss = 4.5471  \n",
      "\n",
      "Fold: 5  Epoch: 191  Training loss = 1.8496  Validation loss = 4.5456  \n",
      "\n",
      "Fold: 5  Epoch: 192  Training loss = 1.8494  Validation loss = 4.5447  \n",
      "\n",
      "Fold: 5  Epoch: 193  Training loss = 1.8493  Validation loss = 4.5440  \n",
      "\n",
      "Fold: 5  Epoch: 194  Training loss = 1.8491  Validation loss = 4.5430  \n",
      "\n",
      "Fold: 5  Epoch: 195  Training loss = 1.8490  Validation loss = 4.5427  \n",
      "\n",
      "Fold: 5  Epoch: 196  Training loss = 1.8488  Validation loss = 4.5412  \n",
      "\n",
      "Fold: 5  Epoch: 197  Training loss = 1.8487  Validation loss = 4.5408  \n",
      "\n",
      "Fold: 5  Epoch: 198  Training loss = 1.8484  Validation loss = 4.5395  \n",
      "\n",
      "Fold: 5  Epoch: 199  Training loss = 1.8483  Validation loss = 4.5392  \n",
      "\n",
      "Fold: 5  Epoch: 200  Training loss = 1.8483  Validation loss = 4.5393  \n",
      "\n",
      "Fold: 5  Epoch: 201  Training loss = 1.8481  Validation loss = 4.5382  \n",
      "\n",
      "Fold: 5  Epoch: 202  Training loss = 1.8480  Validation loss = 4.5376  \n",
      "\n",
      "Fold: 5  Epoch: 203  Training loss = 1.8478  Validation loss = 4.5372  \n",
      "\n",
      "Fold: 5  Epoch: 204  Training loss = 1.8477  Validation loss = 4.5369  \n",
      "\n",
      "Fold: 5  Epoch: 205  Training loss = 1.8475  Validation loss = 4.5358  \n",
      "\n",
      "Fold: 5  Epoch: 206  Training loss = 1.8472  Validation loss = 4.5348  \n",
      "\n",
      "Fold: 5  Epoch: 207  Training loss = 1.8471  Validation loss = 4.5340  \n",
      "\n",
      "Fold: 5  Epoch: 208  Training loss = 1.8471  Validation loss = 4.5341  \n",
      "\n",
      "Fold: 5  Epoch: 209  Training loss = 1.8469  Validation loss = 4.5335  \n",
      "\n",
      "Fold: 5  Epoch: 210  Training loss = 1.8469  Validation loss = 4.5336  \n",
      "\n",
      "Fold: 5  Epoch: 211  Training loss = 1.8467  Validation loss = 4.5325  \n",
      "\n",
      "Fold: 5  Epoch: 212  Training loss = 1.8465  Validation loss = 4.5313  \n",
      "\n",
      "Fold: 5  Epoch: 213  Training loss = 1.8463  Validation loss = 4.5311  \n",
      "\n",
      "Fold: 5  Epoch: 214  Training loss = 1.8462  Validation loss = 4.5306  \n",
      "\n",
      "Fold: 5  Epoch: 215  Training loss = 1.8461  Validation loss = 4.5301  \n",
      "\n",
      "Fold: 5  Epoch: 216  Training loss = 1.8461  Validation loss = 4.5303  \n",
      "\n",
      "Fold: 5  Epoch: 217  Training loss = 1.8459  Validation loss = 4.5291  \n",
      "\n",
      "Fold: 5  Epoch: 218  Training loss = 1.8457  Validation loss = 4.5278  \n",
      "\n",
      "Fold: 5  Epoch: 219  Training loss = 1.8455  Validation loss = 4.5275  \n",
      "\n",
      "Fold: 5  Epoch: 220  Training loss = 1.8454  Validation loss = 4.5269  \n",
      "\n",
      "Fold: 5  Epoch: 221  Training loss = 1.8452  Validation loss = 4.5258  \n",
      "\n",
      "Fold: 5  Epoch: 222  Training loss = 1.8449  Validation loss = 4.5244  \n",
      "\n",
      "Fold: 5  Epoch: 223  Training loss = 1.8447  Validation loss = 4.5232  \n",
      "\n",
      "Fold: 5  Epoch: 224  Training loss = 1.8446  Validation loss = 4.5227  \n",
      "\n",
      "Fold: 5  Epoch: 225  Training loss = 1.8444  Validation loss = 4.5223  \n",
      "\n",
      "Fold: 5  Epoch: 226  Training loss = 1.8443  Validation loss = 4.5211  \n",
      "\n",
      "Fold: 5  Epoch: 227  Training loss = 1.8441  Validation loss = 4.5201  \n",
      "\n",
      "Fold: 5  Epoch: 228  Training loss = 1.8437  Validation loss = 4.5188  \n",
      "\n",
      "Fold: 5  Epoch: 229  Training loss = 1.8437  Validation loss = 4.5187  \n",
      "\n",
      "Fold: 5  Epoch: 230  Training loss = 1.8435  Validation loss = 4.5178  \n",
      "\n",
      "Fold: 5  Epoch: 231  Training loss = 1.8432  Validation loss = 4.5168  \n",
      "\n",
      "Fold: 5  Epoch: 232  Training loss = 1.8431  Validation loss = 4.5159  \n",
      "\n",
      "Fold: 5  Epoch: 233  Training loss = 1.8430  Validation loss = 4.5159  \n",
      "\n",
      "Fold: 5  Epoch: 234  Training loss = 1.8429  Validation loss = 4.5151  \n",
      "\n",
      "Fold: 5  Epoch: 235  Training loss = 1.8428  Validation loss = 4.5145  \n",
      "\n",
      "Fold: 5  Epoch: 236  Training loss = 1.8427  Validation loss = 4.5143  \n",
      "\n",
      "Fold: 5  Epoch: 237  Training loss = 1.8427  Validation loss = 4.5144  \n",
      "\n",
      "Fold: 5  Epoch: 238  Training loss = 1.8425  Validation loss = 4.5137  \n",
      "\n",
      "Fold: 5  Epoch: 239  Training loss = 1.8424  Validation loss = 4.5135  \n",
      "\n",
      "Fold: 5  Epoch: 240  Training loss = 1.8423  Validation loss = 4.5133  \n",
      "\n",
      "Fold: 5  Epoch: 241  Training loss = 1.8421  Validation loss = 4.5122  \n",
      "\n",
      "Fold: 5  Epoch: 242  Training loss = 1.8419  Validation loss = 4.5113  \n",
      "\n",
      "Fold: 5  Epoch: 243  Training loss = 1.8417  Validation loss = 4.5106  \n",
      "\n",
      "Fold: 5  Epoch: 244  Training loss = 1.8418  Validation loss = 4.5116  \n",
      "\n",
      "Fold: 5  Epoch: 245  Training loss = 1.8417  Validation loss = 4.5109  \n",
      "\n",
      "Fold: 5  Epoch: 246  Training loss = 1.8416  Validation loss = 4.5100  \n",
      "\n",
      "Fold: 5  Epoch: 247  Training loss = 1.8414  Validation loss = 4.5092  \n",
      "\n",
      "Fold: 5  Epoch: 248  Training loss = 1.8413  Validation loss = 4.5087  \n",
      "\n",
      "Fold: 5  Epoch: 249  Training loss = 1.8412  Validation loss = 4.5084  \n",
      "\n",
      "Fold: 5  Epoch: 250  Training loss = 1.8410  Validation loss = 4.5076  \n",
      "\n",
      "Fold: 5  Epoch: 251  Training loss = 1.8409  Validation loss = 4.5070  \n",
      "\n",
      "Fold: 5  Epoch: 252  Training loss = 1.8408  Validation loss = 4.5067  \n",
      "\n",
      "Fold: 5  Epoch: 253  Training loss = 1.8405  Validation loss = 4.5053  \n",
      "\n",
      "Fold: 5  Epoch: 254  Training loss = 1.8403  Validation loss = 4.5044  \n",
      "\n",
      "Fold: 5  Epoch: 255  Training loss = 1.8402  Validation loss = 4.5038  \n",
      "\n",
      "Fold: 5  Epoch: 256  Training loss = 1.8401  Validation loss = 4.5032  \n",
      "\n",
      "Fold: 5  Epoch: 257  Training loss = 1.8400  Validation loss = 4.5030  \n",
      "\n",
      "Fold: 5  Epoch: 258  Training loss = 1.8399  Validation loss = 4.5031  \n",
      "\n",
      "Fold: 5  Epoch: 259  Training loss = 1.8398  Validation loss = 4.5023  \n",
      "\n",
      "Fold: 5  Epoch: 260  Training loss = 1.8397  Validation loss = 4.5018  \n",
      "\n",
      "Fold: 5  Epoch: 261  Training loss = 1.8394  Validation loss = 4.5009  \n",
      "\n",
      "Fold: 5  Epoch: 262  Training loss = 1.8394  Validation loss = 4.5012  \n",
      "\n",
      "Fold: 5  Epoch: 263  Training loss = 1.8392  Validation loss = 4.5003  \n",
      "\n",
      "Fold: 5  Epoch: 264  Training loss = 1.8391  Validation loss = 4.4998  \n",
      "\n",
      "Fold: 5  Epoch: 265  Training loss = 1.8389  Validation loss = 4.4991  \n",
      "\n",
      "Fold: 5  Epoch: 266  Training loss = 1.8387  Validation loss = 4.4981  \n",
      "\n",
      "Fold: 5  Epoch: 267  Training loss = 1.8386  Validation loss = 4.4975  \n",
      "\n",
      "Fold: 5  Epoch: 268  Training loss = 1.8384  Validation loss = 4.4964  \n",
      "\n",
      "Fold: 5  Epoch: 269  Training loss = 1.8383  Validation loss = 4.4963  \n",
      "\n",
      "Fold: 5  Epoch: 270  Training loss = 1.8382  Validation loss = 4.4958  \n",
      "\n",
      "Fold: 5  Epoch: 271  Training loss = 1.8381  Validation loss = 4.4960  \n",
      "\n",
      "Fold: 5  Epoch: 272  Training loss = 1.8379  Validation loss = 4.4946  \n",
      "\n",
      "Fold: 5  Epoch: 273  Training loss = 1.8377  Validation loss = 4.4937  \n",
      "\n",
      "Fold: 5  Epoch: 274  Training loss = 1.8376  Validation loss = 4.4926  \n",
      "\n",
      "Fold: 5  Epoch: 275  Training loss = 1.8373  Validation loss = 4.4911  \n",
      "\n",
      "Fold: 5  Epoch: 276  Training loss = 1.8372  Validation loss = 4.4907  \n",
      "\n",
      "Fold: 5  Epoch: 277  Training loss = 1.8370  Validation loss = 4.4898  \n",
      "\n",
      "Fold: 5  Epoch: 278  Training loss = 1.8368  Validation loss = 4.4889  \n",
      "\n",
      "Fold: 5  Epoch: 279  Training loss = 1.8367  Validation loss = 4.4880  \n",
      "\n",
      "Fold: 5  Epoch: 280  Training loss = 1.8366  Validation loss = 4.4878  \n",
      "\n",
      "Fold: 5  Epoch: 281  Training loss = 1.8364  Validation loss = 4.4868  \n",
      "\n",
      "Fold: 5  Epoch: 282  Training loss = 1.8363  Validation loss = 4.4863  \n",
      "\n",
      "Fold: 5  Epoch: 283  Training loss = 1.8362  Validation loss = 4.4862  \n",
      "\n",
      "Fold: 5  Epoch: 284  Training loss = 1.8361  Validation loss = 4.4857  \n",
      "\n",
      "Fold: 5  Epoch: 285  Training loss = 1.8359  Validation loss = 4.4853  \n",
      "\n",
      "Fold: 5  Epoch: 286  Training loss = 1.8358  Validation loss = 4.4844  \n",
      "\n",
      "Fold: 5  Epoch: 287  Training loss = 1.8357  Validation loss = 4.4843  \n",
      "\n",
      "Fold: 5  Epoch: 288  Training loss = 1.8355  Validation loss = 4.4835  \n",
      "\n",
      "Fold: 5  Epoch: 289  Training loss = 1.8353  Validation loss = 4.4825  \n",
      "\n",
      "Fold: 5  Epoch: 290  Training loss = 1.8351  Validation loss = 4.4812  \n",
      "\n",
      "Fold: 5  Epoch: 291  Training loss = 1.8351  Validation loss = 4.4809  \n",
      "\n",
      "Fold: 5  Epoch: 292  Training loss = 1.8349  Validation loss = 4.4798  \n",
      "\n",
      "Fold: 5  Epoch: 293  Training loss = 1.8349  Validation loss = 4.4803  \n",
      "\n",
      "Fold: 5  Epoch: 294  Training loss = 1.8348  Validation loss = 4.4797  \n",
      "\n",
      "Fold: 5  Epoch: 295  Training loss = 1.8347  Validation loss = 4.4788  \n",
      "\n",
      "Fold: 5  Epoch: 296  Training loss = 1.8346  Validation loss = 4.4783  \n",
      "\n",
      "Fold: 5  Epoch: 297  Training loss = 1.8344  Validation loss = 4.4776  \n",
      "\n",
      "Fold: 5  Epoch: 298  Training loss = 1.8342  Validation loss = 4.4765  \n",
      "\n",
      "Fold: 5  Epoch: 299  Training loss = 1.8340  Validation loss = 4.4753  \n",
      "\n",
      "Fold: 5  Epoch: 300  Training loss = 1.8339  Validation loss = 4.4745  \n",
      "\n",
      "Fold: 5  Epoch: 301  Training loss = 1.8337  Validation loss = 4.4736  \n",
      "\n",
      "Fold: 5  Epoch: 302  Training loss = 1.8336  Validation loss = 4.4729  \n",
      "\n",
      "Fold: 5  Epoch: 303  Training loss = 1.8334  Validation loss = 4.4721  \n",
      "\n",
      "Fold: 5  Epoch: 304  Training loss = 1.8334  Validation loss = 4.4721  \n",
      "\n",
      "Fold: 5  Epoch: 305  Training loss = 1.8332  Validation loss = 4.4711  \n",
      "\n",
      "Fold: 5  Epoch: 306  Training loss = 1.8332  Validation loss = 4.4709  \n",
      "\n",
      "Fold: 5  Epoch: 307  Training loss = 1.8330  Validation loss = 4.4696  \n",
      "\n",
      "Fold: 5  Epoch: 308  Training loss = 1.8328  Validation loss = 4.4690  \n",
      "\n",
      "Fold: 5  Epoch: 309  Training loss = 1.8327  Validation loss = 4.4686  \n",
      "\n",
      "Fold: 5  Epoch: 310  Training loss = 1.8325  Validation loss = 4.4678  \n",
      "\n",
      "Fold: 5  Epoch: 311  Training loss = 1.8323  Validation loss = 4.4667  \n",
      "\n",
      "Fold: 5  Epoch: 312  Training loss = 1.8322  Validation loss = 4.4662  \n",
      "\n",
      "Fold: 5  Epoch: 313  Training loss = 1.8322  Validation loss = 4.4661  \n",
      "\n",
      "Fold: 5  Epoch: 314  Training loss = 1.8321  Validation loss = 4.4655  \n",
      "\n",
      "Fold: 5  Epoch: 315  Training loss = 1.8320  Validation loss = 4.4650  \n",
      "\n",
      "Fold: 5  Epoch: 316  Training loss = 1.8319  Validation loss = 4.4645  \n",
      "\n",
      "Fold: 5  Epoch: 317  Training loss = 1.8317  Validation loss = 4.4639  \n",
      "\n",
      "Fold: 5  Epoch: 318  Training loss = 1.8316  Validation loss = 4.4635  \n",
      "\n",
      "Fold: 5  Epoch: 319  Training loss = 1.8316  Validation loss = 4.4636  \n",
      "\n",
      "Fold: 5  Epoch: 320  Training loss = 1.8315  Validation loss = 4.4623  \n",
      "\n",
      "Fold: 5  Epoch: 321  Training loss = 1.8314  Validation loss = 4.4619  \n",
      "\n",
      "Fold: 5  Epoch: 322  Training loss = 1.8313  Validation loss = 4.4620  \n",
      "\n",
      "Fold: 5  Epoch: 323  Training loss = 1.8313  Validation loss = 4.4628  \n",
      "\n",
      "Fold: 5  Epoch: 324  Training loss = 1.8313  Validation loss = 4.4624  \n",
      "\n",
      "Fold: 5  Epoch: 325  Training loss = 1.8311  Validation loss = 4.4619  \n",
      "\n",
      "Fold: 5  Epoch: 326  Training loss = 1.8310  Validation loss = 4.4608  \n",
      "\n",
      "Fold: 5  Epoch: 327  Training loss = 1.8308  Validation loss = 4.4597  \n",
      "\n",
      "Fold: 5  Epoch: 328  Training loss = 1.8306  Validation loss = 4.4586  \n",
      "\n",
      "Fold: 5  Epoch: 329  Training loss = 1.8304  Validation loss = 4.4578  \n",
      "\n",
      "Fold: 5  Epoch: 330  Training loss = 1.8303  Validation loss = 4.4570  \n",
      "\n",
      "Fold: 5  Epoch: 331  Training loss = 1.8302  Validation loss = 4.4563  \n",
      "\n",
      "Fold: 5  Epoch: 332  Training loss = 1.8299  Validation loss = 4.4551  \n",
      "\n",
      "Fold: 5  Epoch: 333  Training loss = 1.8298  Validation loss = 4.4542  \n",
      "\n",
      "Fold: 5  Epoch: 334  Training loss = 1.8295  Validation loss = 4.4530  \n",
      "\n",
      "Fold: 5  Epoch: 335  Training loss = 1.8294  Validation loss = 4.4522  \n",
      "\n",
      "Fold: 5  Epoch: 336  Training loss = 1.8294  Validation loss = 4.4523  \n",
      "\n",
      "Fold: 5  Epoch: 337  Training loss = 1.8291  Validation loss = 4.4514  \n",
      "\n",
      "Fold: 5  Epoch: 338  Training loss = 1.8290  Validation loss = 4.4509  \n",
      "\n",
      "Fold: 5  Epoch: 339  Training loss = 1.8289  Validation loss = 4.4502  \n",
      "\n",
      "Fold: 5  Epoch: 340  Training loss = 1.8287  Validation loss = 4.4494  \n",
      "\n",
      "Fold: 5  Epoch: 341  Training loss = 1.8284  Validation loss = 4.4479  \n",
      "\n",
      "Fold: 5  Epoch: 342  Training loss = 1.8283  Validation loss = 4.4471  \n",
      "\n",
      "Fold: 5  Epoch: 343  Training loss = 1.8283  Validation loss = 4.4470  \n",
      "\n",
      "Fold: 5  Epoch: 344  Training loss = 1.8282  Validation loss = 4.4464  \n",
      "\n",
      "Fold: 5  Epoch: 345  Training loss = 1.8280  Validation loss = 4.4449  \n",
      "\n",
      "Fold: 5  Epoch: 346  Training loss = 1.8278  Validation loss = 4.4442  \n",
      "\n",
      "Fold: 5  Epoch: 347  Training loss = 1.8277  Validation loss = 4.4439  \n",
      "\n",
      "Fold: 5  Epoch: 348  Training loss = 1.8277  Validation loss = 4.4438  \n",
      "\n",
      "Fold: 5  Epoch: 349  Training loss = 1.8276  Validation loss = 4.4441  \n",
      "\n",
      "Fold: 5  Epoch: 350  Training loss = 1.8276  Validation loss = 4.4444  \n",
      "\n",
      "Fold: 5  Epoch: 351  Training loss = 1.8275  Validation loss = 4.4440  \n",
      "\n",
      "Fold: 5  Epoch: 352  Training loss = 1.8273  Validation loss = 4.4430  \n",
      "\n",
      "Fold: 5  Epoch: 353  Training loss = 1.8271  Validation loss = 4.4419  \n",
      "\n",
      "Fold: 5  Epoch: 354  Training loss = 1.8270  Validation loss = 4.4412  \n",
      "\n",
      "Fold: 5  Epoch: 355  Training loss = 1.8270  Validation loss = 4.4410  \n",
      "\n",
      "Fold: 5  Epoch: 356  Training loss = 1.8268  Validation loss = 4.4400  \n",
      "\n",
      "Fold: 5  Epoch: 357  Training loss = 1.8266  Validation loss = 4.4388  \n",
      "\n",
      "Fold: 5  Epoch: 358  Training loss = 1.8264  Validation loss = 4.4381  \n",
      "\n",
      "Fold: 5  Epoch: 359  Training loss = 1.8263  Validation loss = 4.4379  \n",
      "\n",
      "Fold: 5  Epoch: 360  Training loss = 1.8263  Validation loss = 4.4380  \n",
      "\n",
      "Fold: 5  Epoch: 361  Training loss = 1.8262  Validation loss = 4.4374  \n",
      "\n",
      "Fold: 5  Epoch: 362  Training loss = 1.8260  Validation loss = 4.4361  \n",
      "\n",
      "Fold: 5  Epoch: 363  Training loss = 1.8258  Validation loss = 4.4348  \n",
      "\n",
      "Fold: 5  Epoch: 364  Training loss = 1.8257  Validation loss = 4.4340  \n",
      "\n",
      "Fold: 5  Epoch: 365  Training loss = 1.8255  Validation loss = 4.4333  \n",
      "\n",
      "Fold: 5  Epoch: 366  Training loss = 1.8255  Validation loss = 4.4334  \n",
      "\n",
      "Fold: 5  Epoch: 367  Training loss = 1.8254  Validation loss = 4.4330  \n",
      "\n",
      "Fold: 5  Epoch: 368  Training loss = 1.8253  Validation loss = 4.4324  \n",
      "\n",
      "Fold: 5  Epoch: 369  Training loss = 1.8251  Validation loss = 4.4313  \n",
      "\n",
      "Fold: 5  Epoch: 370  Training loss = 1.8250  Validation loss = 4.4311  \n",
      "\n",
      "Fold: 5  Epoch: 371  Training loss = 1.8249  Validation loss = 4.4310  \n",
      "\n",
      "Fold: 5  Epoch: 372  Training loss = 1.8248  Validation loss = 4.4300  \n",
      "\n",
      "Fold: 5  Epoch: 373  Training loss = 1.8248  Validation loss = 4.4305  \n",
      "\n",
      "Fold: 5  Epoch: 374  Training loss = 1.8247  Validation loss = 4.4296  \n",
      "\n",
      "Fold: 5  Epoch: 375  Training loss = 1.8245  Validation loss = 4.4287  \n",
      "\n",
      "Fold: 5  Epoch: 376  Training loss = 1.8244  Validation loss = 4.4284  \n",
      "\n",
      "Fold: 5  Epoch: 377  Training loss = 1.8243  Validation loss = 4.4278  \n",
      "\n",
      "Fold: 5  Epoch: 378  Training loss = 1.8241  Validation loss = 4.4275  \n",
      "\n",
      "Fold: 5  Epoch: 379  Training loss = 1.8240  Validation loss = 4.4266  \n",
      "\n",
      "Fold: 5  Epoch: 380  Training loss = 1.8240  Validation loss = 4.4263  \n",
      "\n",
      "Fold: 5  Epoch: 381  Training loss = 1.8239  Validation loss = 4.4264  \n",
      "\n",
      "Fold: 5  Epoch: 382  Training loss = 1.8237  Validation loss = 4.4254  \n",
      "\n",
      "Fold: 5  Epoch: 383  Training loss = 1.8236  Validation loss = 4.4250  \n",
      "\n",
      "Fold: 5  Epoch: 384  Training loss = 1.8235  Validation loss = 4.4247  \n",
      "\n",
      "Fold: 5  Epoch: 385  Training loss = 1.8234  Validation loss = 4.4240  \n",
      "\n",
      "Fold: 5  Epoch: 386  Training loss = 1.8233  Validation loss = 4.4231  \n",
      "\n",
      "Fold: 5  Epoch: 387  Training loss = 1.8232  Validation loss = 4.4228  \n",
      "\n",
      "Fold: 5  Epoch: 388  Training loss = 1.8231  Validation loss = 4.4224  \n",
      "\n",
      "Fold: 5  Epoch: 389  Training loss = 1.8230  Validation loss = 4.4217  \n",
      "\n",
      "Fold: 5  Epoch: 390  Training loss = 1.8228  Validation loss = 4.4206  \n",
      "\n",
      "Fold: 5  Epoch: 391  Training loss = 1.8228  Validation loss = 4.4209  \n",
      "\n",
      "Fold: 5  Epoch: 392  Training loss = 1.8226  Validation loss = 4.4197  \n",
      "\n",
      "Fold: 5  Epoch: 393  Training loss = 1.8225  Validation loss = 4.4195  \n",
      "\n",
      "Fold: 5  Epoch: 394  Training loss = 1.8224  Validation loss = 4.4191  \n",
      "\n",
      "Fold: 5  Epoch: 395  Training loss = 1.8223  Validation loss = 4.4189  \n",
      "\n",
      "Fold: 5  Epoch: 396  Training loss = 1.8222  Validation loss = 4.4185  \n",
      "\n",
      "Fold: 5  Epoch: 397  Training loss = 1.8221  Validation loss = 4.4179  \n",
      "\n",
      "Fold: 5  Epoch: 398  Training loss = 1.8220  Validation loss = 4.4174  \n",
      "\n",
      "Fold: 5  Epoch: 399  Training loss = 1.8219  Validation loss = 4.4174  \n",
      "\n",
      "Fold: 5  Epoch: 400  Training loss = 1.8219  Validation loss = 4.4171  \n",
      "\n",
      "Fold: 5  Epoch: 401  Training loss = 1.8217  Validation loss = 4.4164  \n",
      "\n",
      "Fold: 5  Epoch: 402  Training loss = 1.8217  Validation loss = 4.4170  \n",
      "\n",
      "Fold: 5  Epoch: 403  Training loss = 1.8217  Validation loss = 4.4173  \n",
      "\n",
      "Fold: 5  Epoch: 404  Training loss = 1.8217  Validation loss = 4.4170  \n",
      "\n",
      "Fold: 5  Epoch: 405  Training loss = 1.8215  Validation loss = 4.4166  \n",
      "\n",
      "Fold: 5  Epoch: 406  Training loss = 1.8214  Validation loss = 4.4156  \n",
      "\n",
      "Fold: 5  Epoch: 407  Training loss = 1.8213  Validation loss = 4.4152  \n",
      "\n",
      "Fold: 5  Epoch: 408  Training loss = 1.8211  Validation loss = 4.4143  \n",
      "\n",
      "Fold: 5  Epoch: 409  Training loss = 1.8210  Validation loss = 4.4138  \n",
      "\n",
      "Fold: 5  Epoch: 410  Training loss = 1.8209  Validation loss = 4.4133  \n",
      "\n",
      "Fold: 5  Epoch: 411  Training loss = 1.8208  Validation loss = 4.4123  \n",
      "\n",
      "Fold: 5  Epoch: 412  Training loss = 1.8207  Validation loss = 4.4117  \n",
      "\n",
      "Fold: 5  Epoch: 413  Training loss = 1.8206  Validation loss = 4.4120  \n",
      "\n",
      "Fold: 5  Epoch: 414  Training loss = 1.8205  Validation loss = 4.4117  \n",
      "\n",
      "Fold: 5  Epoch: 415  Training loss = 1.8205  Validation loss = 4.4121  \n",
      "\n",
      "Fold: 5  Epoch: 416  Training loss = 1.8205  Validation loss = 4.4122  \n",
      "\n",
      "Fold: 5  Epoch: 417  Training loss = 1.8204  Validation loss = 4.4115  \n",
      "\n",
      "Fold: 5  Epoch: 418  Training loss = 1.8203  Validation loss = 4.4112  \n",
      "\n",
      "Fold: 5  Epoch: 419  Training loss = 1.8203  Validation loss = 4.4112  \n",
      "\n",
      "Fold: 5  Epoch: 420  Training loss = 1.8201  Validation loss = 4.4099  \n",
      "\n",
      "Fold: 5  Epoch: 421  Training loss = 1.8200  Validation loss = 4.4091  \n",
      "\n",
      "Fold: 5  Epoch: 422  Training loss = 1.8198  Validation loss = 4.4079  \n",
      "\n",
      "Fold: 5  Epoch: 423  Training loss = 1.8196  Validation loss = 4.4077  \n",
      "\n",
      "Fold: 5  Epoch: 424  Training loss = 1.8196  Validation loss = 4.4075  \n",
      "\n",
      "Fold: 5  Epoch: 425  Training loss = 1.8195  Validation loss = 4.4067  \n",
      "\n",
      "Fold: 5  Epoch: 426  Training loss = 1.8194  Validation loss = 4.4070  \n",
      "\n",
      "Fold: 5  Epoch: 427  Training loss = 1.8194  Validation loss = 4.4068  \n",
      "\n",
      "Fold: 5  Epoch: 428  Training loss = 1.8194  Validation loss = 4.4068  \n",
      "\n",
      "Fold: 5  Epoch: 429  Training loss = 1.8193  Validation loss = 4.4066  \n",
      "\n",
      "Fold: 5  Epoch: 430  Training loss = 1.8192  Validation loss = 4.4062  \n",
      "\n",
      "Fold: 5  Epoch: 431  Training loss = 1.8191  Validation loss = 4.4063  \n",
      "\n",
      "Fold: 5  Epoch: 432  Training loss = 1.8190  Validation loss = 4.4056  \n",
      "\n",
      "Fold: 5  Epoch: 433  Training loss = 1.8189  Validation loss = 4.4049  \n",
      "\n",
      "Fold: 5  Epoch: 434  Training loss = 1.8187  Validation loss = 4.4037  \n",
      "\n",
      "Fold: 5  Epoch: 435  Training loss = 1.8186  Validation loss = 4.4035  \n",
      "\n",
      "Fold: 5  Epoch: 436  Training loss = 1.8185  Validation loss = 4.4030  \n",
      "\n",
      "Fold: 5  Epoch: 437  Training loss = 1.8184  Validation loss = 4.4026  \n",
      "\n",
      "Fold: 5  Epoch: 438  Training loss = 1.8183  Validation loss = 4.4018  \n",
      "\n",
      "Fold: 5  Epoch: 439  Training loss = 1.8182  Validation loss = 4.4012  \n",
      "\n",
      "Fold: 5  Epoch: 440  Training loss = 1.8181  Validation loss = 4.4007  \n",
      "\n",
      "Fold: 5  Epoch: 441  Training loss = 1.8179  Validation loss = 4.3995  \n",
      "\n",
      "Fold: 5  Epoch: 442  Training loss = 1.8178  Validation loss = 4.3992  \n",
      "\n",
      "Fold: 5  Epoch: 443  Training loss = 1.8178  Validation loss = 4.3992  \n",
      "\n",
      "Fold: 5  Epoch: 444  Training loss = 1.8177  Validation loss = 4.3989  \n",
      "\n",
      "Fold: 5  Epoch: 445  Training loss = 1.8176  Validation loss = 4.3991  \n",
      "\n",
      "Fold: 5  Epoch: 446  Training loss = 1.8176  Validation loss = 4.3996  \n",
      "\n",
      "Fold: 5  Epoch: 447  Training loss = 1.8174  Validation loss = 4.3991  \n",
      "\n",
      "Fold: 5  Epoch: 448  Training loss = 1.8173  Validation loss = 4.3985  \n",
      "\n",
      "Fold: 5  Epoch: 449  Training loss = 1.8172  Validation loss = 4.3979  \n",
      "\n",
      "Fold: 5  Epoch: 450  Training loss = 1.8171  Validation loss = 4.3977  \n",
      "\n",
      "Fold: 5  Epoch: 451  Training loss = 1.8171  Validation loss = 4.3974  \n",
      "\n",
      "Fold: 5  Epoch: 452  Training loss = 1.8170  Validation loss = 4.3974  \n",
      "\n",
      "Fold: 5  Epoch: 453  Training loss = 1.8168  Validation loss = 4.3970  \n",
      "\n",
      "Fold: 5  Epoch: 454  Training loss = 1.8167  Validation loss = 4.3965  \n",
      "\n",
      "Fold: 5  Epoch: 455  Training loss = 1.8168  Validation loss = 4.3970  \n",
      "\n",
      "Fold: 5  Epoch: 456  Training loss = 1.8167  Validation loss = 4.3966  \n",
      "\n",
      "Fold: 5  Epoch: 457  Training loss = 1.8165  Validation loss = 4.3956  \n",
      "\n",
      "Fold: 5  Epoch: 458  Training loss = 1.8164  Validation loss = 4.3949  \n",
      "\n",
      "Fold: 5  Epoch: 459  Training loss = 1.8163  Validation loss = 4.3943  \n",
      "\n",
      "Fold: 5  Epoch: 460  Training loss = 1.8161  Validation loss = 4.3929  \n",
      "\n",
      "Fold: 5  Epoch: 461  Training loss = 1.8160  Validation loss = 4.3933  \n",
      "\n",
      "Fold: 5  Epoch: 462  Training loss = 1.8159  Validation loss = 4.3925  \n",
      "\n",
      "Fold: 5  Epoch: 463  Training loss = 1.8158  Validation loss = 4.3922  \n",
      "\n",
      "Fold: 5  Epoch: 464  Training loss = 1.8157  Validation loss = 4.3912  \n",
      "\n",
      "Fold: 5  Epoch: 465  Training loss = 1.8156  Validation loss = 4.3909  \n",
      "\n",
      "Fold: 5  Epoch: 466  Training loss = 1.8155  Validation loss = 4.3898  \n",
      "\n",
      "Fold: 5  Epoch: 467  Training loss = 1.8154  Validation loss = 4.3896  \n",
      "\n",
      "Fold: 5  Epoch: 468  Training loss = 1.8153  Validation loss = 4.3891  \n",
      "\n",
      "Fold: 5  Epoch: 469  Training loss = 1.8152  Validation loss = 4.3888  \n",
      "\n",
      "Fold: 5  Epoch: 470  Training loss = 1.8151  Validation loss = 4.3885  \n",
      "\n",
      "Fold: 5  Epoch: 471  Training loss = 1.8150  Validation loss = 4.3886  \n",
      "\n",
      "Fold: 5  Epoch: 472  Training loss = 1.8149  Validation loss = 4.3878  \n",
      "\n",
      "Fold: 5  Epoch: 473  Training loss = 1.8148  Validation loss = 4.3874  \n",
      "\n",
      "Fold: 5  Epoch: 474  Training loss = 1.8146  Validation loss = 4.3866  \n",
      "\n",
      "Fold: 5  Epoch: 475  Training loss = 1.8145  Validation loss = 4.3858  \n",
      "\n",
      "Fold: 5  Epoch: 476  Training loss = 1.8144  Validation loss = 4.3847  \n",
      "\n",
      "Fold: 5  Epoch: 477  Training loss = 1.8142  Validation loss = 4.3839  \n",
      "\n",
      "Fold: 5  Epoch: 478  Training loss = 1.8141  Validation loss = 4.3832  \n",
      "\n",
      "Fold: 5  Epoch: 479  Training loss = 1.8139  Validation loss = 4.3821  \n",
      "\n",
      "Fold: 5  Epoch: 480  Training loss = 1.8139  Validation loss = 4.3815  \n",
      "\n",
      "Fold: 5  Epoch: 481  Training loss = 1.8137  Validation loss = 4.3810  \n",
      "\n",
      "Fold: 5  Epoch: 482  Training loss = 1.8136  Validation loss = 4.3802  \n",
      "\n",
      "Fold: 5  Epoch: 483  Training loss = 1.8135  Validation loss = 4.3799  \n",
      "\n",
      "Fold: 5  Epoch: 484  Training loss = 1.8134  Validation loss = 4.3795  \n",
      "\n",
      "Fold: 5  Epoch: 485  Training loss = 1.8134  Validation loss = 4.3794  \n",
      "\n",
      "Fold: 5  Epoch: 486  Training loss = 1.8131  Validation loss = 4.3782  \n",
      "\n",
      "Fold: 5  Epoch: 487  Training loss = 1.8130  Validation loss = 4.3778  \n",
      "\n",
      "Fold: 5  Epoch: 488  Training loss = 1.8129  Validation loss = 4.3765  \n",
      "\n",
      "Fold: 5  Epoch: 489  Training loss = 1.8128  Validation loss = 4.3763  \n",
      "\n",
      "Fold: 5  Epoch: 490  Training loss = 1.8128  Validation loss = 4.3763  \n",
      "\n",
      "Fold: 5  Epoch: 491  Training loss = 1.8127  Validation loss = 4.3758  \n",
      "\n",
      "Fold: 5  Epoch: 492  Training loss = 1.8126  Validation loss = 4.3757  \n",
      "\n",
      "Fold: 5  Epoch: 493  Training loss = 1.8124  Validation loss = 4.3741  \n",
      "\n",
      "Fold: 5  Epoch: 494  Training loss = 1.8122  Validation loss = 4.3734  \n",
      "\n",
      "Fold: 5  Epoch: 495  Training loss = 1.8122  Validation loss = 4.3734  \n",
      "\n",
      "Fold: 5  Epoch: 496  Training loss = 1.8121  Validation loss = 4.3727  \n",
      "\n",
      "Fold: 5  Epoch: 497  Training loss = 1.8119  Validation loss = 4.3718  \n",
      "\n",
      "Fold: 5  Epoch: 498  Training loss = 1.8118  Validation loss = 4.3716  \n",
      "\n",
      "Fold: 5  Epoch: 499  Training loss = 1.8117  Validation loss = 4.3711  \n",
      "\n",
      "Fold: 5  Epoch: 500  Training loss = 1.8117  Validation loss = 4.3710  \n",
      "\n",
      "Check model:  Fold: 5  Optimal epoch: 500  \n",
      "\n",
      "Fold: 6  Epoch: 1  Training loss = 2.0752  Validation loss = 2.0014  \n",
      "\n",
      "Fold: 6  Epoch: 2  Training loss = 2.0745  Validation loss = 1.9994  \n",
      "\n",
      "Fold: 6  Epoch: 3  Training loss = 2.0743  Validation loss = 1.9988  \n",
      "\n",
      "Fold: 6  Epoch: 4  Training loss = 2.0738  Validation loss = 1.9972  \n",
      "\n",
      "Fold: 6  Epoch: 5  Training loss = 2.0735  Validation loss = 1.9964  \n",
      "\n",
      "Fold: 6  Epoch: 6  Training loss = 2.0732  Validation loss = 1.9957  \n",
      "\n",
      "Fold: 6  Epoch: 7  Training loss = 2.0726  Validation loss = 1.9942  \n",
      "\n",
      "Fold: 6  Epoch: 8  Training loss = 2.0719  Validation loss = 1.9921  \n",
      "\n",
      "Fold: 6  Epoch: 9  Training loss = 2.0716  Validation loss = 1.9911  \n",
      "\n",
      "Fold: 6  Epoch: 10  Training loss = 2.0711  Validation loss = 1.9897  \n",
      "\n",
      "Fold: 6  Epoch: 11  Training loss = 2.0706  Validation loss = 1.9883  \n",
      "\n",
      "Fold: 6  Epoch: 12  Training loss = 2.0701  Validation loss = 1.9869  \n",
      "\n",
      "Fold: 6  Epoch: 13  Training loss = 2.0698  Validation loss = 1.9858  \n",
      "\n",
      "Fold: 6  Epoch: 14  Training loss = 2.0694  Validation loss = 1.9846  \n",
      "\n",
      "Fold: 6  Epoch: 15  Training loss = 2.0687  Validation loss = 1.9825  \n",
      "\n",
      "Fold: 6  Epoch: 16  Training loss = 2.0680  Validation loss = 1.9803  \n",
      "\n",
      "Fold: 6  Epoch: 17  Training loss = 2.0675  Validation loss = 1.9784  \n",
      "\n",
      "Fold: 6  Epoch: 18  Training loss = 2.0671  Validation loss = 1.9773  \n",
      "\n",
      "Fold: 6  Epoch: 19  Training loss = 2.0667  Validation loss = 1.9760  \n",
      "\n",
      "Fold: 6  Epoch: 20  Training loss = 2.0660  Validation loss = 1.9738  \n",
      "\n",
      "Fold: 6  Epoch: 21  Training loss = 2.0655  Validation loss = 1.9722  \n",
      "\n",
      "Fold: 6  Epoch: 22  Training loss = 2.0650  Validation loss = 1.9706  \n",
      "\n",
      "Fold: 6  Epoch: 23  Training loss = 2.0646  Validation loss = 1.9693  \n",
      "\n",
      "Fold: 6  Epoch: 24  Training loss = 2.0641  Validation loss = 1.9676  \n",
      "\n",
      "Fold: 6  Epoch: 25  Training loss = 2.0635  Validation loss = 1.9660  \n",
      "\n",
      "Fold: 6  Epoch: 26  Training loss = 2.0632  Validation loss = 1.9649  \n",
      "\n",
      "Fold: 6  Epoch: 27  Training loss = 2.0627  Validation loss = 1.9632  \n",
      "\n",
      "Fold: 6  Epoch: 28  Training loss = 2.0623  Validation loss = 1.9620  \n",
      "\n",
      "Fold: 6  Epoch: 29  Training loss = 2.0621  Validation loss = 1.9614  \n",
      "\n",
      "Fold: 6  Epoch: 30  Training loss = 2.0614  Validation loss = 1.9594  \n",
      "\n",
      "Fold: 6  Epoch: 31  Training loss = 2.0610  Validation loss = 1.9579  \n",
      "\n",
      "Fold: 6  Epoch: 32  Training loss = 2.0606  Validation loss = 1.9567  \n",
      "\n",
      "Fold: 6  Epoch: 33  Training loss = 2.0604  Validation loss = 1.9560  \n",
      "\n",
      "Fold: 6  Epoch: 34  Training loss = 2.0597  Validation loss = 1.9538  \n",
      "\n",
      "Fold: 6  Epoch: 35  Training loss = 2.0590  Validation loss = 1.9517  \n",
      "\n",
      "Fold: 6  Epoch: 36  Training loss = 2.0588  Validation loss = 1.9512  \n",
      "\n",
      "Fold: 6  Epoch: 37  Training loss = 2.0584  Validation loss = 1.9498  \n",
      "\n",
      "Fold: 6  Epoch: 38  Training loss = 2.0579  Validation loss = 1.9481  \n",
      "\n",
      "Fold: 6  Epoch: 39  Training loss = 2.0576  Validation loss = 1.9471  \n",
      "\n",
      "Fold: 6  Epoch: 40  Training loss = 2.0573  Validation loss = 1.9463  \n",
      "\n",
      "Fold: 6  Epoch: 41  Training loss = 2.0569  Validation loss = 1.9449  \n",
      "\n",
      "Fold: 6  Epoch: 42  Training loss = 2.0561  Validation loss = 1.9421  \n",
      "\n",
      "Fold: 6  Epoch: 43  Training loss = 2.0553  Validation loss = 1.9392  \n",
      "\n",
      "Fold: 6  Epoch: 44  Training loss = 2.0549  Validation loss = 1.9377  \n",
      "\n",
      "Fold: 6  Epoch: 45  Training loss = 2.0541  Validation loss = 1.9347  \n",
      "\n",
      "Fold: 6  Epoch: 46  Training loss = 2.0538  Validation loss = 1.9337  \n",
      "\n",
      "Fold: 6  Epoch: 47  Training loss = 2.0534  Validation loss = 1.9323  \n",
      "\n",
      "Fold: 6  Epoch: 48  Training loss = 2.0528  Validation loss = 1.9302  \n",
      "\n",
      "Fold: 6  Epoch: 49  Training loss = 2.0522  Validation loss = 1.9281  \n",
      "\n",
      "Fold: 6  Epoch: 50  Training loss = 2.0516  Validation loss = 1.9259  \n",
      "\n",
      "Fold: 6  Epoch: 51  Training loss = 2.0513  Validation loss = 1.9250  \n",
      "\n",
      "Fold: 6  Epoch: 52  Training loss = 2.0510  Validation loss = 1.9240  \n",
      "\n",
      "Fold: 6  Epoch: 53  Training loss = 2.0503  Validation loss = 1.9214  \n",
      "\n",
      "Fold: 6  Epoch: 54  Training loss = 2.0496  Validation loss = 1.9191  \n",
      "\n",
      "Fold: 6  Epoch: 55  Training loss = 2.0489  Validation loss = 1.9164  \n",
      "\n",
      "Fold: 6  Epoch: 56  Training loss = 2.0483  Validation loss = 1.9141  \n",
      "\n",
      "Fold: 6  Epoch: 57  Training loss = 2.0477  Validation loss = 1.9118  \n",
      "\n",
      "Fold: 6  Epoch: 58  Training loss = 2.0472  Validation loss = 1.9099  \n",
      "\n",
      "Fold: 6  Epoch: 59  Training loss = 2.0467  Validation loss = 1.9080  \n",
      "\n",
      "Fold: 6  Epoch: 60  Training loss = 2.0463  Validation loss = 1.9062  \n",
      "\n",
      "Fold: 6  Epoch: 61  Training loss = 2.0457  Validation loss = 1.9043  \n",
      "\n",
      "Fold: 6  Epoch: 62  Training loss = 2.0453  Validation loss = 1.9028  \n",
      "\n",
      "Fold: 6  Epoch: 63  Training loss = 2.0451  Validation loss = 1.9018  \n",
      "\n",
      "Fold: 6  Epoch: 64  Training loss = 2.0447  Validation loss = 1.9003  \n",
      "\n",
      "Fold: 6  Epoch: 65  Training loss = 2.0439  Validation loss = 1.8974  \n",
      "\n",
      "Fold: 6  Epoch: 66  Training loss = 2.0434  Validation loss = 1.8956  \n",
      "\n",
      "Fold: 6  Epoch: 67  Training loss = 2.0429  Validation loss = 1.8938  \n",
      "\n",
      "Fold: 6  Epoch: 68  Training loss = 2.0425  Validation loss = 1.8921  \n",
      "\n",
      "Fold: 6  Epoch: 69  Training loss = 2.0421  Validation loss = 1.8909  \n",
      "\n",
      "Fold: 6  Epoch: 70  Training loss = 2.0419  Validation loss = 1.8902  \n",
      "\n",
      "Fold: 6  Epoch: 71  Training loss = 2.0416  Validation loss = 1.8890  \n",
      "\n",
      "Fold: 6  Epoch: 72  Training loss = 2.0413  Validation loss = 1.8882  \n",
      "\n",
      "Fold: 6  Epoch: 73  Training loss = 2.0411  Validation loss = 1.8872  \n",
      "\n",
      "Fold: 6  Epoch: 74  Training loss = 2.0409  Validation loss = 1.8866  \n",
      "\n",
      "Fold: 6  Epoch: 75  Training loss = 2.0404  Validation loss = 1.8851  \n",
      "\n",
      "Fold: 6  Epoch: 76  Training loss = 2.0403  Validation loss = 1.8848  \n",
      "\n",
      "Fold: 6  Epoch: 77  Training loss = 2.0400  Validation loss = 1.8837  \n",
      "\n",
      "Fold: 6  Epoch: 78  Training loss = 2.0395  Validation loss = 1.8817  \n",
      "\n",
      "Fold: 6  Epoch: 79  Training loss = 2.0390  Validation loss = 1.8803  \n",
      "\n",
      "Fold: 6  Epoch: 80  Training loss = 2.0386  Validation loss = 1.8784  \n",
      "\n",
      "Fold: 6  Epoch: 81  Training loss = 2.0385  Validation loss = 1.8783  \n",
      "\n",
      "Fold: 6  Epoch: 82  Training loss = 2.0385  Validation loss = 1.8783  \n",
      "\n",
      "Fold: 6  Epoch: 83  Training loss = 2.0384  Validation loss = 1.8783  \n",
      "\n",
      "Fold: 6  Epoch: 84  Training loss = 2.0381  Validation loss = 1.8772  \n",
      "\n",
      "Fold: 6  Epoch: 85  Training loss = 2.0376  Validation loss = 1.8753  \n",
      "\n",
      "Fold: 6  Epoch: 86  Training loss = 2.0371  Validation loss = 1.8734  \n",
      "\n",
      "Fold: 6  Epoch: 87  Training loss = 2.0367  Validation loss = 1.8722  \n",
      "\n",
      "Fold: 6  Epoch: 88  Training loss = 2.0365  Validation loss = 1.8717  \n",
      "\n",
      "Fold: 6  Epoch: 89  Training loss = 2.0362  Validation loss = 1.8706  \n",
      "\n",
      "Fold: 6  Epoch: 90  Training loss = 2.0356  Validation loss = 1.8680  \n",
      "\n",
      "Fold: 6  Epoch: 91  Training loss = 2.0351  Validation loss = 1.8660  \n",
      "\n",
      "Fold: 6  Epoch: 92  Training loss = 2.0348  Validation loss = 1.8652  \n",
      "\n",
      "Fold: 6  Epoch: 93  Training loss = 2.0345  Validation loss = 1.8641  \n",
      "\n",
      "Fold: 6  Epoch: 94  Training loss = 2.0342  Validation loss = 1.8632  \n",
      "\n",
      "Fold: 6  Epoch: 95  Training loss = 2.0338  Validation loss = 1.8617  \n",
      "\n",
      "Fold: 6  Epoch: 96  Training loss = 2.0334  Validation loss = 1.8603  \n",
      "\n",
      "Fold: 6  Epoch: 97  Training loss = 2.0330  Validation loss = 1.8587  \n",
      "\n",
      "Fold: 6  Epoch: 98  Training loss = 2.0328  Validation loss = 1.8580  \n",
      "\n",
      "Fold: 6  Epoch: 99  Training loss = 2.0325  Validation loss = 1.8571  \n",
      "\n",
      "Fold: 6  Epoch: 100  Training loss = 2.0321  Validation loss = 1.8552  \n",
      "\n",
      "Fold: 6  Epoch: 101  Training loss = 2.0316  Validation loss = 1.8533  \n",
      "\n",
      "Fold: 6  Epoch: 102  Training loss = 2.0309  Validation loss = 1.8507  \n",
      "\n",
      "Fold: 6  Epoch: 103  Training loss = 2.0304  Validation loss = 1.8484  \n",
      "\n",
      "Fold: 6  Epoch: 104  Training loss = 2.0300  Validation loss = 1.8473  \n",
      "\n",
      "Fold: 6  Epoch: 105  Training loss = 2.0297  Validation loss = 1.8462  \n",
      "\n",
      "Fold: 6  Epoch: 106  Training loss = 2.0293  Validation loss = 1.8442  \n",
      "\n",
      "Fold: 6  Epoch: 107  Training loss = 2.0290  Validation loss = 1.8436  \n",
      "\n",
      "Fold: 6  Epoch: 108  Training loss = 2.0287  Validation loss = 1.8426  \n",
      "\n",
      "Fold: 6  Epoch: 109  Training loss = 2.0284  Validation loss = 1.8413  \n",
      "\n",
      "Fold: 6  Epoch: 110  Training loss = 2.0281  Validation loss = 1.8405  \n",
      "\n",
      "Fold: 6  Epoch: 111  Training loss = 2.0276  Validation loss = 1.8385  \n",
      "\n",
      "Fold: 6  Epoch: 112  Training loss = 2.0274  Validation loss = 1.8379  \n",
      "\n",
      "Fold: 6  Epoch: 113  Training loss = 2.0272  Validation loss = 1.8371  \n",
      "\n",
      "Fold: 6  Epoch: 114  Training loss = 2.0268  Validation loss = 1.8358  \n",
      "\n",
      "Fold: 6  Epoch: 115  Training loss = 2.0265  Validation loss = 1.8347  \n",
      "\n",
      "Fold: 6  Epoch: 116  Training loss = 2.0260  Validation loss = 1.8327  \n",
      "\n",
      "Fold: 6  Epoch: 117  Training loss = 2.0254  Validation loss = 1.8301  \n",
      "\n",
      "Fold: 6  Epoch: 118  Training loss = 2.0250  Validation loss = 1.8281  \n",
      "\n",
      "Fold: 6  Epoch: 119  Training loss = 2.0246  Validation loss = 1.8266  \n",
      "\n",
      "Fold: 6  Epoch: 120  Training loss = 2.0242  Validation loss = 1.8249  \n",
      "\n",
      "Fold: 6  Epoch: 121  Training loss = 2.0238  Validation loss = 1.8238  \n",
      "\n",
      "Fold: 6  Epoch: 122  Training loss = 2.0235  Validation loss = 1.8223  \n",
      "\n",
      "Fold: 6  Epoch: 123  Training loss = 2.0231  Validation loss = 1.8205  \n",
      "\n",
      "Fold: 6  Epoch: 124  Training loss = 2.0229  Validation loss = 1.8196  \n",
      "\n",
      "Fold: 6  Epoch: 125  Training loss = 2.0225  Validation loss = 1.8182  \n",
      "\n",
      "Fold: 6  Epoch: 126  Training loss = 2.0222  Validation loss = 1.8171  \n",
      "\n",
      "Fold: 6  Epoch: 127  Training loss = 2.0220  Validation loss = 1.8166  \n",
      "\n",
      "Fold: 6  Epoch: 128  Training loss = 2.0218  Validation loss = 1.8159  \n",
      "\n",
      "Fold: 6  Epoch: 129  Training loss = 2.0215  Validation loss = 1.8148  \n",
      "\n",
      "Fold: 6  Epoch: 130  Training loss = 2.0211  Validation loss = 1.8136  \n",
      "\n",
      "Fold: 6  Epoch: 131  Training loss = 2.0207  Validation loss = 1.8117  \n",
      "\n",
      "Fold: 6  Epoch: 132  Training loss = 2.0204  Validation loss = 1.8107  \n",
      "\n",
      "Fold: 6  Epoch: 133  Training loss = 2.0201  Validation loss = 1.8098  \n",
      "\n",
      "Fold: 6  Epoch: 134  Training loss = 2.0197  Validation loss = 1.8083  \n",
      "\n",
      "Fold: 6  Epoch: 135  Training loss = 2.0195  Validation loss = 1.8075  \n",
      "\n",
      "Fold: 6  Epoch: 136  Training loss = 2.0192  Validation loss = 1.8063  \n",
      "\n",
      "Fold: 6  Epoch: 137  Training loss = 2.0189  Validation loss = 1.8053  \n",
      "\n",
      "Fold: 6  Epoch: 138  Training loss = 2.0186  Validation loss = 1.8045  \n",
      "\n",
      "Fold: 6  Epoch: 139  Training loss = 2.0181  Validation loss = 1.8022  \n",
      "\n",
      "Fold: 6  Epoch: 140  Training loss = 2.0179  Validation loss = 1.8016  \n",
      "\n",
      "Fold: 6  Epoch: 141  Training loss = 2.0176  Validation loss = 1.8003  \n",
      "\n",
      "Fold: 6  Epoch: 142  Training loss = 2.0174  Validation loss = 1.7996  \n",
      "\n",
      "Fold: 6  Epoch: 143  Training loss = 2.0170  Validation loss = 1.7982  \n",
      "\n",
      "Fold: 6  Epoch: 144  Training loss = 2.0166  Validation loss = 1.7967  \n",
      "\n",
      "Fold: 6  Epoch: 145  Training loss = 2.0164  Validation loss = 1.7960  \n",
      "\n",
      "Fold: 6  Epoch: 146  Training loss = 2.0161  Validation loss = 1.7946  \n",
      "\n",
      "Fold: 6  Epoch: 147  Training loss = 2.0157  Validation loss = 1.7932  \n",
      "\n",
      "Fold: 6  Epoch: 148  Training loss = 2.0155  Validation loss = 1.7923  \n",
      "\n",
      "Fold: 6  Epoch: 149  Training loss = 2.0152  Validation loss = 1.7913  \n",
      "\n",
      "Fold: 6  Epoch: 150  Training loss = 2.0149  Validation loss = 1.7901  \n",
      "\n",
      "Fold: 6  Epoch: 151  Training loss = 2.0145  Validation loss = 1.7886  \n",
      "\n",
      "Fold: 6  Epoch: 152  Training loss = 2.0142  Validation loss = 1.7874  \n",
      "\n",
      "Fold: 6  Epoch: 153  Training loss = 2.0138  Validation loss = 1.7855  \n",
      "\n",
      "Fold: 6  Epoch: 154  Training loss = 2.0134  Validation loss = 1.7840  \n",
      "\n",
      "Fold: 6  Epoch: 155  Training loss = 2.0129  Validation loss = 1.7819  \n",
      "\n",
      "Fold: 6  Epoch: 156  Training loss = 2.0127  Validation loss = 1.7809  \n",
      "\n",
      "Fold: 6  Epoch: 157  Training loss = 2.0122  Validation loss = 1.7791  \n",
      "\n",
      "Fold: 6  Epoch: 158  Training loss = 2.0121  Validation loss = 1.7787  \n",
      "\n",
      "Fold: 6  Epoch: 159  Training loss = 2.0118  Validation loss = 1.7778  \n",
      "\n",
      "Fold: 6  Epoch: 160  Training loss = 2.0116  Validation loss = 1.7771  \n",
      "\n",
      "Fold: 6  Epoch: 161  Training loss = 2.0114  Validation loss = 1.7765  \n",
      "\n",
      "Fold: 6  Epoch: 162  Training loss = 2.0111  Validation loss = 1.7752  \n",
      "\n",
      "Fold: 6  Epoch: 163  Training loss = 2.0107  Validation loss = 1.7733  \n",
      "\n",
      "Fold: 6  Epoch: 164  Training loss = 2.0103  Validation loss = 1.7715  \n",
      "\n",
      "Fold: 6  Epoch: 165  Training loss = 2.0099  Validation loss = 1.7702  \n",
      "\n",
      "Fold: 6  Epoch: 166  Training loss = 2.0096  Validation loss = 1.7692  \n",
      "\n",
      "Fold: 6  Epoch: 167  Training loss = 2.0094  Validation loss = 1.7688  \n",
      "\n",
      "Fold: 6  Epoch: 168  Training loss = 2.0091  Validation loss = 1.7677  \n",
      "\n",
      "Fold: 6  Epoch: 169  Training loss = 2.0088  Validation loss = 1.7665  \n",
      "\n",
      "Fold: 6  Epoch: 170  Training loss = 2.0086  Validation loss = 1.7659  \n",
      "\n",
      "Fold: 6  Epoch: 171  Training loss = 2.0085  Validation loss = 1.7653  \n",
      "\n",
      "Fold: 6  Epoch: 172  Training loss = 2.0082  Validation loss = 1.7644  \n",
      "\n",
      "Fold: 6  Epoch: 173  Training loss = 2.0079  Validation loss = 1.7632  \n",
      "\n",
      "Fold: 6  Epoch: 174  Training loss = 2.0076  Validation loss = 1.7619  \n",
      "\n",
      "Fold: 6  Epoch: 175  Training loss = 2.0073  Validation loss = 1.7610  \n",
      "\n",
      "Fold: 6  Epoch: 176  Training loss = 2.0072  Validation loss = 1.7607  \n",
      "\n",
      "Fold: 6  Epoch: 177  Training loss = 2.0070  Validation loss = 1.7602  \n",
      "\n",
      "Fold: 6  Epoch: 178  Training loss = 2.0068  Validation loss = 1.7593  \n",
      "\n",
      "Fold: 6  Epoch: 179  Training loss = 2.0066  Validation loss = 1.7591  \n",
      "\n",
      "Fold: 6  Epoch: 180  Training loss = 2.0065  Validation loss = 1.7583  \n",
      "\n",
      "Fold: 6  Epoch: 181  Training loss = 2.0063  Validation loss = 1.7579  \n",
      "\n",
      "Fold: 6  Epoch: 182  Training loss = 2.0060  Validation loss = 1.7565  \n",
      "\n",
      "Fold: 6  Epoch: 183  Training loss = 2.0057  Validation loss = 1.7549  \n",
      "\n",
      "Fold: 6  Epoch: 184  Training loss = 2.0054  Validation loss = 1.7539  \n",
      "\n",
      "Fold: 6  Epoch: 185  Training loss = 2.0051  Validation loss = 1.7529  \n",
      "\n",
      "Fold: 6  Epoch: 186  Training loss = 2.0049  Validation loss = 1.7520  \n",
      "\n",
      "Fold: 6  Epoch: 187  Training loss = 2.0047  Validation loss = 1.7512  \n",
      "\n",
      "Fold: 6  Epoch: 188  Training loss = 2.0044  Validation loss = 1.7497  \n",
      "\n",
      "Fold: 6  Epoch: 189  Training loss = 2.0041  Validation loss = 1.7486  \n",
      "\n",
      "Fold: 6  Epoch: 190  Training loss = 2.0037  Validation loss = 1.7468  \n",
      "\n",
      "Fold: 6  Epoch: 191  Training loss = 2.0034  Validation loss = 1.7453  \n",
      "\n",
      "Fold: 6  Epoch: 192  Training loss = 2.0031  Validation loss = 1.7442  \n",
      "\n",
      "Fold: 6  Epoch: 193  Training loss = 2.0027  Validation loss = 1.7425  \n",
      "\n",
      "Fold: 6  Epoch: 194  Training loss = 2.0026  Validation loss = 1.7422  \n",
      "\n",
      "Fold: 6  Epoch: 195  Training loss = 2.0024  Validation loss = 1.7414  \n",
      "\n",
      "Fold: 6  Epoch: 196  Training loss = 2.0022  Validation loss = 1.7405  \n",
      "\n",
      "Fold: 6  Epoch: 197  Training loss = 2.0019  Validation loss = 1.7393  \n",
      "\n",
      "Fold: 6  Epoch: 198  Training loss = 2.0017  Validation loss = 1.7386  \n",
      "\n",
      "Fold: 6  Epoch: 199  Training loss = 2.0016  Validation loss = 1.7387  \n",
      "\n",
      "Fold: 6  Epoch: 200  Training loss = 2.0014  Validation loss = 1.7378  \n",
      "\n",
      "Fold: 6  Epoch: 201  Training loss = 2.0011  Validation loss = 1.7367  \n",
      "\n",
      "Fold: 6  Epoch: 202  Training loss = 2.0010  Validation loss = 1.7366  \n",
      "\n",
      "Fold: 6  Epoch: 203  Training loss = 2.0009  Validation loss = 1.7358  \n",
      "\n",
      "Fold: 6  Epoch: 204  Training loss = 2.0007  Validation loss = 1.7351  \n",
      "\n",
      "Fold: 6  Epoch: 205  Training loss = 2.0002  Validation loss = 1.7333  \n",
      "\n",
      "Fold: 6  Epoch: 206  Training loss = 2.0001  Validation loss = 1.7330  \n",
      "\n",
      "Fold: 6  Epoch: 207  Training loss = 1.9999  Validation loss = 1.7323  \n",
      "\n",
      "Fold: 6  Epoch: 208  Training loss = 1.9997  Validation loss = 1.7315  \n",
      "\n",
      "Fold: 6  Epoch: 209  Training loss = 1.9995  Validation loss = 1.7308  \n",
      "\n",
      "Fold: 6  Epoch: 210  Training loss = 1.9993  Validation loss = 1.7302  \n",
      "\n",
      "Fold: 6  Epoch: 211  Training loss = 1.9991  Validation loss = 1.7296  \n",
      "\n",
      "Fold: 6  Epoch: 212  Training loss = 1.9989  Validation loss = 1.7288  \n",
      "\n",
      "Fold: 6  Epoch: 213  Training loss = 1.9987  Validation loss = 1.7275  \n",
      "\n",
      "Fold: 6  Epoch: 214  Training loss = 1.9985  Validation loss = 1.7270  \n",
      "\n",
      "Fold: 6  Epoch: 215  Training loss = 1.9982  Validation loss = 1.7260  \n",
      "\n",
      "Fold: 6  Epoch: 216  Training loss = 1.9982  Validation loss = 1.7261  \n",
      "\n",
      "Fold: 6  Epoch: 217  Training loss = 1.9981  Validation loss = 1.7257  \n",
      "\n",
      "Fold: 6  Epoch: 218  Training loss = 1.9979  Validation loss = 1.7255  \n",
      "\n",
      "Fold: 6  Epoch: 219  Training loss = 1.9978  Validation loss = 1.7250  \n",
      "\n",
      "Fold: 6  Epoch: 220  Training loss = 1.9975  Validation loss = 1.7237  \n",
      "\n",
      "Fold: 6  Epoch: 221  Training loss = 1.9973  Validation loss = 1.7230  \n",
      "\n",
      "Fold: 6  Epoch: 222  Training loss = 1.9971  Validation loss = 1.7227  \n",
      "\n",
      "Fold: 6  Epoch: 223  Training loss = 1.9969  Validation loss = 1.7217  \n",
      "\n",
      "Fold: 6  Epoch: 224  Training loss = 1.9967  Validation loss = 1.7214  \n",
      "\n",
      "Fold: 6  Epoch: 225  Training loss = 1.9966  Validation loss = 1.7209  \n",
      "\n",
      "Fold: 6  Epoch: 226  Training loss = 1.9964  Validation loss = 1.7202  \n",
      "\n",
      "Fold: 6  Epoch: 227  Training loss = 1.9962  Validation loss = 1.7196  \n",
      "\n",
      "Fold: 6  Epoch: 228  Training loss = 1.9960  Validation loss = 1.7189  \n",
      "\n",
      "Fold: 6  Epoch: 229  Training loss = 1.9956  Validation loss = 1.7171  \n",
      "\n",
      "Fold: 6  Epoch: 230  Training loss = 1.9953  Validation loss = 1.7158  \n",
      "\n",
      "Fold: 6  Epoch: 231  Training loss = 1.9952  Validation loss = 1.7160  \n",
      "\n",
      "Fold: 6  Epoch: 232  Training loss = 1.9951  Validation loss = 1.7159  \n",
      "\n",
      "Fold: 6  Epoch: 233  Training loss = 1.9950  Validation loss = 1.7156  \n",
      "\n",
      "Fold: 6  Epoch: 234  Training loss = 1.9948  Validation loss = 1.7149  \n",
      "\n",
      "Fold: 6  Epoch: 235  Training loss = 1.9948  Validation loss = 1.7148  \n",
      "\n",
      "Fold: 6  Epoch: 236  Training loss = 1.9946  Validation loss = 1.7144  \n",
      "\n",
      "Fold: 6  Epoch: 237  Training loss = 1.9944  Validation loss = 1.7137  \n",
      "\n",
      "Fold: 6  Epoch: 238  Training loss = 1.9942  Validation loss = 1.7127  \n",
      "\n",
      "Fold: 6  Epoch: 239  Training loss = 1.9940  Validation loss = 1.7118  \n",
      "\n",
      "Fold: 6  Epoch: 240  Training loss = 1.9937  Validation loss = 1.7108  \n",
      "\n",
      "Fold: 6  Epoch: 241  Training loss = 1.9936  Validation loss = 1.7103  \n",
      "\n",
      "Fold: 6  Epoch: 242  Training loss = 1.9934  Validation loss = 1.7097  \n",
      "\n",
      "Fold: 6  Epoch: 243  Training loss = 1.9932  Validation loss = 1.7090  \n",
      "\n",
      "Fold: 6  Epoch: 244  Training loss = 1.9929  Validation loss = 1.7079  \n",
      "\n",
      "Fold: 6  Epoch: 245  Training loss = 1.9928  Validation loss = 1.7078  \n",
      "\n",
      "Fold: 6  Epoch: 246  Training loss = 1.9925  Validation loss = 1.7060  \n",
      "\n",
      "Fold: 6  Epoch: 247  Training loss = 1.9923  Validation loss = 1.7058  \n",
      "\n",
      "Fold: 6  Epoch: 248  Training loss = 1.9921  Validation loss = 1.7047  \n",
      "\n",
      "Fold: 6  Epoch: 249  Training loss = 1.9920  Validation loss = 1.7042  \n",
      "\n",
      "Fold: 6  Epoch: 250  Training loss = 1.9917  Validation loss = 1.7032  \n",
      "\n",
      "Fold: 6  Epoch: 251  Training loss = 1.9916  Validation loss = 1.7029  \n",
      "\n",
      "Fold: 6  Epoch: 252  Training loss = 1.9914  Validation loss = 1.7016  \n",
      "\n",
      "Fold: 6  Epoch: 253  Training loss = 1.9911  Validation loss = 1.7008  \n",
      "\n",
      "Fold: 6  Epoch: 254  Training loss = 1.9910  Validation loss = 1.7006  \n",
      "\n",
      "Fold: 6  Epoch: 255  Training loss = 1.9908  Validation loss = 1.7001  \n",
      "\n",
      "Fold: 6  Epoch: 256  Training loss = 1.9907  Validation loss = 1.7001  \n",
      "\n",
      "Fold: 6  Epoch: 257  Training loss = 1.9906  Validation loss = 1.6995  \n",
      "\n",
      "Fold: 6  Epoch: 258  Training loss = 1.9903  Validation loss = 1.6981  \n",
      "\n",
      "Fold: 6  Epoch: 259  Training loss = 1.9901  Validation loss = 1.6974  \n",
      "\n",
      "Fold: 6  Epoch: 260  Training loss = 1.9899  Validation loss = 1.6966  \n",
      "\n",
      "Fold: 6  Epoch: 261  Training loss = 1.9898  Validation loss = 1.6961  \n",
      "\n",
      "Fold: 6  Epoch: 262  Training loss = 1.9896  Validation loss = 1.6959  \n",
      "\n",
      "Fold: 6  Epoch: 263  Training loss = 1.9896  Validation loss = 1.6962  \n",
      "\n",
      "Fold: 6  Epoch: 264  Training loss = 1.9896  Validation loss = 1.6966  \n",
      "\n",
      "Fold: 6  Epoch: 265  Training loss = 1.9894  Validation loss = 1.6958  \n",
      "\n",
      "Fold: 6  Epoch: 266  Training loss = 1.9892  Validation loss = 1.6953  \n",
      "\n",
      "Fold: 6  Epoch: 267  Training loss = 1.9891  Validation loss = 1.6951  \n",
      "\n",
      "Fold: 6  Epoch: 268  Training loss = 1.9889  Validation loss = 1.6944  \n",
      "\n",
      "Fold: 6  Epoch: 269  Training loss = 1.9888  Validation loss = 1.6940  \n",
      "\n",
      "Fold: 6  Epoch: 270  Training loss = 1.9886  Validation loss = 1.6934  \n",
      "\n",
      "Fold: 6  Epoch: 271  Training loss = 1.9884  Validation loss = 1.6929  \n",
      "\n",
      "Fold: 6  Epoch: 272  Training loss = 1.9883  Validation loss = 1.6927  \n",
      "\n",
      "Fold: 6  Epoch: 273  Training loss = 1.9882  Validation loss = 1.6921  \n",
      "\n",
      "Fold: 6  Epoch: 274  Training loss = 1.9880  Validation loss = 1.6917  \n",
      "\n",
      "Fold: 6  Epoch: 275  Training loss = 1.9877  Validation loss = 1.6902  \n",
      "\n",
      "Fold: 6  Epoch: 276  Training loss = 1.9876  Validation loss = 1.6904  \n",
      "\n",
      "Fold: 6  Epoch: 277  Training loss = 1.9876  Validation loss = 1.6905  \n",
      "\n",
      "Fold: 6  Epoch: 278  Training loss = 1.9874  Validation loss = 1.6895  \n",
      "\n",
      "Fold: 6  Epoch: 279  Training loss = 1.9874  Validation loss = 1.6898  \n",
      "\n",
      "Fold: 6  Epoch: 280  Training loss = 1.9872  Validation loss = 1.6887  \n",
      "\n",
      "Fold: 6  Epoch: 281  Training loss = 1.9870  Validation loss = 1.6883  \n",
      "\n",
      "Fold: 6  Epoch: 282  Training loss = 1.9868  Validation loss = 1.6871  \n",
      "\n",
      "Fold: 6  Epoch: 283  Training loss = 1.9865  Validation loss = 1.6858  \n",
      "\n",
      "Fold: 6  Epoch: 284  Training loss = 1.9863  Validation loss = 1.6853  \n",
      "\n",
      "Fold: 6  Epoch: 285  Training loss = 1.9863  Validation loss = 1.6851  \n",
      "\n",
      "Fold: 6  Epoch: 286  Training loss = 1.9862  Validation loss = 1.6848  \n",
      "\n",
      "Fold: 6  Epoch: 287  Training loss = 1.9859  Validation loss = 1.6839  \n",
      "\n",
      "Fold: 6  Epoch: 288  Training loss = 1.9858  Validation loss = 1.6842  \n",
      "\n",
      "Fold: 6  Epoch: 289  Training loss = 1.9856  Validation loss = 1.6833  \n",
      "\n",
      "Fold: 6  Epoch: 290  Training loss = 1.9854  Validation loss = 1.6829  \n",
      "\n",
      "Fold: 6  Epoch: 291  Training loss = 1.9853  Validation loss = 1.6827  \n",
      "\n",
      "Fold: 6  Epoch: 292  Training loss = 1.9852  Validation loss = 1.6824  \n",
      "\n",
      "Fold: 6  Epoch: 293  Training loss = 1.9850  Validation loss = 1.6816  \n",
      "\n",
      "Fold: 6  Epoch: 294  Training loss = 1.9848  Validation loss = 1.6810  \n",
      "\n",
      "Fold: 6  Epoch: 295  Training loss = 1.9847  Validation loss = 1.6808  \n",
      "\n",
      "Fold: 6  Epoch: 296  Training loss = 1.9846  Validation loss = 1.6804  \n",
      "\n",
      "Fold: 6  Epoch: 297  Training loss = 1.9844  Validation loss = 1.6794  \n",
      "\n",
      "Fold: 6  Epoch: 298  Training loss = 1.9841  Validation loss = 1.6782  \n",
      "\n",
      "Fold: 6  Epoch: 299  Training loss = 1.9839  Validation loss = 1.6772  \n",
      "\n",
      "Fold: 6  Epoch: 300  Training loss = 1.9837  Validation loss = 1.6764  \n",
      "\n",
      "Fold: 6  Epoch: 301  Training loss = 1.9836  Validation loss = 1.6762  \n",
      "\n",
      "Fold: 6  Epoch: 302  Training loss = 1.9834  Validation loss = 1.6756  \n",
      "\n",
      "Fold: 6  Epoch: 303  Training loss = 1.9833  Validation loss = 1.6754  \n",
      "\n",
      "Fold: 6  Epoch: 304  Training loss = 1.9831  Validation loss = 1.6745  \n",
      "\n",
      "Fold: 6  Epoch: 305  Training loss = 1.9830  Validation loss = 1.6744  \n",
      "\n",
      "Fold: 6  Epoch: 306  Training loss = 1.9827  Validation loss = 1.6737  \n",
      "\n",
      "Fold: 6  Epoch: 307  Training loss = 1.9826  Validation loss = 1.6737  \n",
      "\n",
      "Fold: 6  Epoch: 308  Training loss = 1.9824  Validation loss = 1.6727  \n",
      "\n",
      "Fold: 6  Epoch: 309  Training loss = 1.9822  Validation loss = 1.6722  \n",
      "\n",
      "Fold: 6  Epoch: 310  Training loss = 1.9821  Validation loss = 1.6717  \n",
      "\n",
      "Fold: 6  Epoch: 311  Training loss = 1.9820  Validation loss = 1.6716  \n",
      "\n",
      "Fold: 6  Epoch: 312  Training loss = 1.9818  Validation loss = 1.6708  \n",
      "\n",
      "Fold: 6  Epoch: 313  Training loss = 1.9816  Validation loss = 1.6699  \n",
      "\n",
      "Fold: 6  Epoch: 314  Training loss = 1.9815  Validation loss = 1.6697  \n",
      "\n",
      "Fold: 6  Epoch: 315  Training loss = 1.9813  Validation loss = 1.6688  \n",
      "\n",
      "Fold: 6  Epoch: 316  Training loss = 1.9811  Validation loss = 1.6685  \n",
      "\n",
      "Fold: 6  Epoch: 317  Training loss = 1.9808  Validation loss = 1.6670  \n",
      "\n",
      "Fold: 6  Epoch: 318  Training loss = 1.9805  Validation loss = 1.6656  \n",
      "\n",
      "Fold: 6  Epoch: 319  Training loss = 1.9803  Validation loss = 1.6643  \n",
      "\n",
      "Fold: 6  Epoch: 320  Training loss = 1.9800  Validation loss = 1.6630  \n",
      "\n",
      "Fold: 6  Epoch: 321  Training loss = 1.9799  Validation loss = 1.6627  \n",
      "\n",
      "Fold: 6  Epoch: 322  Training loss = 1.9796  Validation loss = 1.6614  \n",
      "\n",
      "Fold: 6  Epoch: 323  Training loss = 1.9794  Validation loss = 1.6605  \n",
      "\n",
      "Fold: 6  Epoch: 324  Training loss = 1.9791  Validation loss = 1.6595  \n",
      "\n",
      "Fold: 6  Epoch: 325  Training loss = 1.9789  Validation loss = 1.6584  \n",
      "\n",
      "Fold: 6  Epoch: 326  Training loss = 1.9787  Validation loss = 1.6574  \n",
      "\n",
      "Fold: 6  Epoch: 327  Training loss = 1.9785  Validation loss = 1.6567  \n",
      "\n",
      "Fold: 6  Epoch: 328  Training loss = 1.9783  Validation loss = 1.6561  \n",
      "\n",
      "Fold: 6  Epoch: 329  Training loss = 1.9781  Validation loss = 1.6551  \n",
      "\n",
      "Fold: 6  Epoch: 330  Training loss = 1.9781  Validation loss = 1.6553  \n",
      "\n",
      "Fold: 6  Epoch: 331  Training loss = 1.9781  Validation loss = 1.6560  \n",
      "\n",
      "Fold: 6  Epoch: 332  Training loss = 1.9780  Validation loss = 1.6558  \n",
      "\n",
      "Fold: 6  Epoch: 333  Training loss = 1.9779  Validation loss = 1.6553  \n",
      "\n",
      "Fold: 6  Epoch: 334  Training loss = 1.9777  Validation loss = 1.6553  \n",
      "\n",
      "Fold: 6  Epoch: 335  Training loss = 1.9775  Validation loss = 1.6547  \n",
      "\n",
      "Fold: 6  Epoch: 336  Training loss = 1.9775  Validation loss = 1.6544  \n",
      "\n",
      "Fold: 6  Epoch: 337  Training loss = 1.9773  Validation loss = 1.6539  \n",
      "\n",
      "Fold: 6  Epoch: 338  Training loss = 1.9771  Validation loss = 1.6530  \n",
      "\n",
      "Fold: 6  Epoch: 339  Training loss = 1.9770  Validation loss = 1.6528  \n",
      "\n",
      "Fold: 6  Epoch: 340  Training loss = 1.9769  Validation loss = 1.6523  \n",
      "\n",
      "Fold: 6  Epoch: 341  Training loss = 1.9767  Validation loss = 1.6516  \n",
      "\n",
      "Fold: 6  Epoch: 342  Training loss = 1.9765  Validation loss = 1.6506  \n",
      "\n",
      "Fold: 6  Epoch: 343  Training loss = 1.9763  Validation loss = 1.6504  \n",
      "\n",
      "Fold: 6  Epoch: 344  Training loss = 1.9761  Validation loss = 1.6499  \n",
      "\n",
      "Fold: 6  Epoch: 345  Training loss = 1.9760  Validation loss = 1.6493  \n",
      "\n",
      "Fold: 6  Epoch: 346  Training loss = 1.9758  Validation loss = 1.6484  \n",
      "\n",
      "Fold: 6  Epoch: 347  Training loss = 1.9758  Validation loss = 1.6490  \n",
      "\n",
      "Fold: 6  Epoch: 348  Training loss = 1.9757  Validation loss = 1.6487  \n",
      "\n",
      "Fold: 6  Epoch: 349  Training loss = 1.9756  Validation loss = 1.6487  \n",
      "\n",
      "Fold: 6  Epoch: 350  Training loss = 1.9754  Validation loss = 1.6480  \n",
      "\n",
      "Fold: 6  Epoch: 351  Training loss = 1.9753  Validation loss = 1.6473  \n",
      "\n",
      "Fold: 6  Epoch: 352  Training loss = 1.9752  Validation loss = 1.6472  \n",
      "\n",
      "Fold: 6  Epoch: 353  Training loss = 1.9751  Validation loss = 1.6469  \n",
      "\n",
      "Fold: 6  Epoch: 354  Training loss = 1.9750  Validation loss = 1.6470  \n",
      "\n",
      "Fold: 6  Epoch: 355  Training loss = 1.9747  Validation loss = 1.6457  \n",
      "\n",
      "Fold: 6  Epoch: 356  Training loss = 1.9745  Validation loss = 1.6449  \n",
      "\n",
      "Fold: 6  Epoch: 357  Training loss = 1.9744  Validation loss = 1.6439  \n",
      "\n",
      "Fold: 6  Epoch: 358  Training loss = 1.9742  Validation loss = 1.6434  \n",
      "\n",
      "Fold: 6  Epoch: 359  Training loss = 1.9740  Validation loss = 1.6424  \n",
      "\n",
      "Fold: 6  Epoch: 360  Training loss = 1.9738  Validation loss = 1.6415  \n",
      "\n",
      "Fold: 6  Epoch: 361  Training loss = 1.9737  Validation loss = 1.6412  \n",
      "\n",
      "Fold: 6  Epoch: 362  Training loss = 1.9735  Validation loss = 1.6405  \n",
      "\n",
      "Fold: 6  Epoch: 363  Training loss = 1.9734  Validation loss = 1.6403  \n",
      "\n",
      "Fold: 6  Epoch: 364  Training loss = 1.9734  Validation loss = 1.6404  \n",
      "\n",
      "Fold: 6  Epoch: 365  Training loss = 1.9732  Validation loss = 1.6396  \n",
      "\n",
      "Fold: 6  Epoch: 366  Training loss = 1.9730  Validation loss = 1.6386  \n",
      "\n",
      "Fold: 6  Epoch: 367  Training loss = 1.9729  Validation loss = 1.6381  \n",
      "\n",
      "Fold: 6  Epoch: 368  Training loss = 1.9728  Validation loss = 1.6377  \n",
      "\n",
      "Fold: 6  Epoch: 369  Training loss = 1.9727  Validation loss = 1.6378  \n",
      "\n",
      "Fold: 6  Epoch: 370  Training loss = 1.9725  Validation loss = 1.6373  \n",
      "\n",
      "Fold: 6  Epoch: 371  Training loss = 1.9722  Validation loss = 1.6362  \n",
      "\n",
      "Fold: 6  Epoch: 372  Training loss = 1.9720  Validation loss = 1.6349  \n",
      "\n",
      "Fold: 6  Epoch: 373  Training loss = 1.9717  Validation loss = 1.6333  \n",
      "\n",
      "Fold: 6  Epoch: 374  Training loss = 1.9715  Validation loss = 1.6324  \n",
      "\n",
      "Fold: 6  Epoch: 375  Training loss = 1.9713  Validation loss = 1.6317  \n",
      "\n",
      "Fold: 6  Epoch: 376  Training loss = 1.9711  Validation loss = 1.6311  \n",
      "\n",
      "Fold: 6  Epoch: 377  Training loss = 1.9710  Validation loss = 1.6306  \n",
      "\n",
      "Fold: 6  Epoch: 378  Training loss = 1.9710  Validation loss = 1.6313  \n",
      "\n",
      "Fold: 6  Epoch: 379  Training loss = 1.9709  Validation loss = 1.6307  \n",
      "\n",
      "Fold: 6  Epoch: 380  Training loss = 1.9707  Validation loss = 1.6300  \n",
      "\n",
      "Fold: 6  Epoch: 381  Training loss = 1.9706  Validation loss = 1.6301  \n",
      "\n",
      "Fold: 6  Epoch: 382  Training loss = 1.9705  Validation loss = 1.6292  \n",
      "\n",
      "Fold: 6  Epoch: 383  Training loss = 1.9703  Validation loss = 1.6288  \n",
      "\n",
      "Fold: 6  Epoch: 384  Training loss = 1.9699  Validation loss = 1.6270  \n",
      "\n",
      "Fold: 6  Epoch: 385  Training loss = 1.9698  Validation loss = 1.6263  \n",
      "\n",
      "Fold: 6  Epoch: 386  Training loss = 1.9696  Validation loss = 1.6256  \n",
      "\n",
      "Fold: 6  Epoch: 387  Training loss = 1.9695  Validation loss = 1.6255  \n",
      "\n",
      "Fold: 6  Epoch: 388  Training loss = 1.9694  Validation loss = 1.6248  \n",
      "\n",
      "Fold: 6  Epoch: 389  Training loss = 1.9692  Validation loss = 1.6240  \n",
      "\n",
      "Fold: 6  Epoch: 390  Training loss = 1.9690  Validation loss = 1.6230  \n",
      "\n",
      "Fold: 6  Epoch: 391  Training loss = 1.9688  Validation loss = 1.6223  \n",
      "\n",
      "Fold: 6  Epoch: 392  Training loss = 1.9687  Validation loss = 1.6221  \n",
      "\n",
      "Fold: 6  Epoch: 393  Training loss = 1.9686  Validation loss = 1.6215  \n",
      "\n",
      "Fold: 6  Epoch: 394  Training loss = 1.9685  Validation loss = 1.6215  \n",
      "\n",
      "Fold: 6  Epoch: 395  Training loss = 1.9684  Validation loss = 1.6212  \n",
      "\n",
      "Fold: 6  Epoch: 396  Training loss = 1.9683  Validation loss = 1.6210  \n",
      "\n",
      "Fold: 6  Epoch: 397  Training loss = 1.9683  Validation loss = 1.6217  \n",
      "\n",
      "Fold: 6  Epoch: 398  Training loss = 1.9682  Validation loss = 1.6213  \n",
      "\n",
      "Fold: 6  Epoch: 399  Training loss = 1.9681  Validation loss = 1.6213  \n",
      "\n",
      "Fold: 6  Epoch: 400  Training loss = 1.9679  Validation loss = 1.6202  \n",
      "\n",
      "Fold: 6  Epoch: 401  Training loss = 1.9678  Validation loss = 1.6197  \n",
      "\n",
      "Fold: 6  Epoch: 402  Training loss = 1.9676  Validation loss = 1.6193  \n",
      "\n",
      "Fold: 6  Epoch: 403  Training loss = 1.9676  Validation loss = 1.6191  \n",
      "\n",
      "Fold: 6  Epoch: 404  Training loss = 1.9675  Validation loss = 1.6189  \n",
      "\n",
      "Fold: 6  Epoch: 405  Training loss = 1.9673  Validation loss = 1.6184  \n",
      "\n",
      "Fold: 6  Epoch: 406  Training loss = 1.9672  Validation loss = 1.6180  \n",
      "\n",
      "Fold: 6  Epoch: 407  Training loss = 1.9671  Validation loss = 1.6179  \n",
      "\n",
      "Fold: 6  Epoch: 408  Training loss = 1.9668  Validation loss = 1.6165  \n",
      "\n",
      "Fold: 6  Epoch: 409  Training loss = 1.9666  Validation loss = 1.6150  \n",
      "\n",
      "Fold: 6  Epoch: 410  Training loss = 1.9664  Validation loss = 1.6142  \n",
      "\n",
      "Fold: 6  Epoch: 411  Training loss = 1.9662  Validation loss = 1.6133  \n",
      "\n",
      "Fold: 6  Epoch: 412  Training loss = 1.9660  Validation loss = 1.6122  \n",
      "\n",
      "Fold: 6  Epoch: 413  Training loss = 1.9658  Validation loss = 1.6112  \n",
      "\n",
      "Fold: 6  Epoch: 414  Training loss = 1.9656  Validation loss = 1.6104  \n",
      "\n",
      "Fold: 6  Epoch: 415  Training loss = 1.9654  Validation loss = 1.6092  \n",
      "\n",
      "Fold: 6  Epoch: 416  Training loss = 1.9654  Validation loss = 1.6093  \n",
      "\n",
      "Fold: 6  Epoch: 417  Training loss = 1.9652  Validation loss = 1.6080  \n",
      "\n",
      "Fold: 6  Epoch: 418  Training loss = 1.9651  Validation loss = 1.6079  \n",
      "\n",
      "Fold: 6  Epoch: 419  Training loss = 1.9649  Validation loss = 1.6070  \n",
      "\n",
      "Fold: 6  Epoch: 420  Training loss = 1.9648  Validation loss = 1.6064  \n",
      "\n",
      "Fold: 6  Epoch: 421  Training loss = 1.9646  Validation loss = 1.6057  \n",
      "\n",
      "Fold: 6  Epoch: 422  Training loss = 1.9644  Validation loss = 1.6047  \n",
      "\n",
      "Fold: 6  Epoch: 423  Training loss = 1.9642  Validation loss = 1.6039  \n",
      "\n",
      "Fold: 6  Epoch: 424  Training loss = 1.9641  Validation loss = 1.6031  \n",
      "\n",
      "Fold: 6  Epoch: 425  Training loss = 1.9639  Validation loss = 1.6023  \n",
      "\n",
      "Fold: 6  Epoch: 426  Training loss = 1.9637  Validation loss = 1.6018  \n",
      "\n",
      "Fold: 6  Epoch: 427  Training loss = 1.9636  Validation loss = 1.6018  \n",
      "\n",
      "Fold: 6  Epoch: 428  Training loss = 1.9635  Validation loss = 1.6014  \n",
      "\n",
      "Fold: 6  Epoch: 429  Training loss = 1.9633  Validation loss = 1.6005  \n",
      "\n",
      "Fold: 6  Epoch: 430  Training loss = 1.9633  Validation loss = 1.6005  \n",
      "\n",
      "Fold: 6  Epoch: 431  Training loss = 1.9631  Validation loss = 1.5995  \n",
      "\n",
      "Fold: 6  Epoch: 432  Training loss = 1.9629  Validation loss = 1.5985  \n",
      "\n",
      "Fold: 6  Epoch: 433  Training loss = 1.9628  Validation loss = 1.5986  \n",
      "\n",
      "Fold: 6  Epoch: 434  Training loss = 1.9628  Validation loss = 1.5994  \n",
      "\n",
      "Fold: 6  Epoch: 435  Training loss = 1.9626  Validation loss = 1.5988  \n",
      "\n",
      "Fold: 6  Epoch: 436  Training loss = 1.9624  Validation loss = 1.5978  \n",
      "\n",
      "Fold: 6  Epoch: 437  Training loss = 1.9622  Validation loss = 1.5968  \n",
      "\n",
      "Fold: 6  Epoch: 438  Training loss = 1.9621  Validation loss = 1.5964  \n",
      "\n",
      "Fold: 6  Epoch: 439  Training loss = 1.9619  Validation loss = 1.5957  \n",
      "\n",
      "Fold: 6  Epoch: 440  Training loss = 1.9618  Validation loss = 1.5952  \n",
      "\n",
      "Fold: 6  Epoch: 441  Training loss = 1.9617  Validation loss = 1.5947  \n",
      "\n",
      "Fold: 6  Epoch: 442  Training loss = 1.9614  Validation loss = 1.5931  \n",
      "\n",
      "Fold: 6  Epoch: 443  Training loss = 1.9612  Validation loss = 1.5923  \n",
      "\n",
      "Fold: 6  Epoch: 444  Training loss = 1.9610  Validation loss = 1.5911  \n",
      "\n",
      "Fold: 6  Epoch: 445  Training loss = 1.9609  Validation loss = 1.5910  \n",
      "\n",
      "Fold: 6  Epoch: 446  Training loss = 1.9606  Validation loss = 1.5895  \n",
      "\n",
      "Fold: 6  Epoch: 447  Training loss = 1.9605  Validation loss = 1.5892  \n",
      "\n",
      "Fold: 6  Epoch: 448  Training loss = 1.9604  Validation loss = 1.5887  \n",
      "\n",
      "Fold: 6  Epoch: 449  Training loss = 1.9602  Validation loss = 1.5879  \n",
      "\n",
      "Fold: 6  Epoch: 450  Training loss = 1.9601  Validation loss = 1.5874  \n",
      "\n",
      "Fold: 6  Epoch: 451  Training loss = 1.9600  Validation loss = 1.5875  \n",
      "\n",
      "Fold: 6  Epoch: 452  Training loss = 1.9599  Validation loss = 1.5873  \n",
      "\n",
      "Fold: 6  Epoch: 453  Training loss = 1.9599  Validation loss = 1.5873  \n",
      "\n",
      "Fold: 6  Epoch: 454  Training loss = 1.9596  Validation loss = 1.5862  \n",
      "\n",
      "Fold: 6  Epoch: 455  Training loss = 1.9595  Validation loss = 1.5855  \n",
      "\n",
      "Fold: 6  Epoch: 456  Training loss = 1.9592  Validation loss = 1.5841  \n",
      "\n",
      "Fold: 6  Epoch: 457  Training loss = 1.9591  Validation loss = 1.5836  \n",
      "\n",
      "Fold: 6  Epoch: 458  Training loss = 1.9590  Validation loss = 1.5837  \n",
      "\n",
      "Fold: 6  Epoch: 459  Training loss = 1.9588  Validation loss = 1.5827  \n",
      "\n",
      "Fold: 6  Epoch: 460  Training loss = 1.9586  Validation loss = 1.5817  \n",
      "\n",
      "Fold: 6  Epoch: 461  Training loss = 1.9584  Validation loss = 1.5809  \n",
      "\n",
      "Fold: 6  Epoch: 462  Training loss = 1.9583  Validation loss = 1.5809  \n",
      "\n",
      "Fold: 6  Epoch: 463  Training loss = 1.9582  Validation loss = 1.5796  \n",
      "\n",
      "Fold: 6  Epoch: 464  Training loss = 1.9579  Validation loss = 1.5784  \n",
      "\n",
      "Fold: 6  Epoch: 465  Training loss = 1.9577  Validation loss = 1.5771  \n",
      "\n",
      "Fold: 6  Epoch: 466  Training loss = 1.9577  Validation loss = 1.5773  \n",
      "\n",
      "Fold: 6  Epoch: 467  Training loss = 1.9576  Validation loss = 1.5771  \n",
      "\n",
      "Fold: 6  Epoch: 468  Training loss = 1.9575  Validation loss = 1.5772  \n",
      "\n",
      "Fold: 6  Epoch: 469  Training loss = 1.9574  Validation loss = 1.5768  \n",
      "\n",
      "Fold: 6  Epoch: 470  Training loss = 1.9573  Validation loss = 1.5765  \n",
      "\n",
      "Fold: 6  Epoch: 471  Training loss = 1.9571  Validation loss = 1.5753  \n",
      "\n",
      "Fold: 6  Epoch: 472  Training loss = 1.9569  Validation loss = 1.5745  \n",
      "\n",
      "Fold: 6  Epoch: 473  Training loss = 1.9568  Validation loss = 1.5742  \n",
      "\n",
      "Fold: 6  Epoch: 474  Training loss = 1.9567  Validation loss = 1.5739  \n",
      "\n",
      "Fold: 6  Epoch: 475  Training loss = 1.9566  Validation loss = 1.5730  \n",
      "\n",
      "Fold: 6  Epoch: 476  Training loss = 1.9564  Validation loss = 1.5725  \n",
      "\n",
      "Fold: 6  Epoch: 477  Training loss = 1.9563  Validation loss = 1.5726  \n",
      "\n",
      "Fold: 6  Epoch: 478  Training loss = 1.9562  Validation loss = 1.5718  \n",
      "\n",
      "Fold: 6  Epoch: 479  Training loss = 1.9560  Validation loss = 1.5710  \n",
      "\n",
      "Fold: 6  Epoch: 480  Training loss = 1.9558  Validation loss = 1.5702  \n",
      "\n",
      "Fold: 6  Epoch: 481  Training loss = 1.9557  Validation loss = 1.5694  \n",
      "\n",
      "Fold: 6  Epoch: 482  Training loss = 1.9556  Validation loss = 1.5689  \n",
      "\n",
      "Fold: 6  Epoch: 483  Training loss = 1.9555  Validation loss = 1.5687  \n",
      "\n",
      "Fold: 6  Epoch: 484  Training loss = 1.9554  Validation loss = 1.5690  \n",
      "\n",
      "Fold: 6  Epoch: 485  Training loss = 1.9553  Validation loss = 1.5683  \n",
      "\n",
      "Fold: 6  Epoch: 486  Training loss = 1.9553  Validation loss = 1.5687  \n",
      "\n",
      "Fold: 6  Epoch: 487  Training loss = 1.9552  Validation loss = 1.5686  \n",
      "\n",
      "Fold: 6  Epoch: 488  Training loss = 1.9550  Validation loss = 1.5673  \n",
      "\n",
      "Fold: 6  Epoch: 489  Training loss = 1.9548  Validation loss = 1.5659  \n",
      "\n",
      "Fold: 6  Epoch: 490  Training loss = 1.9548  Validation loss = 1.5660  \n",
      "\n",
      "Fold: 6  Epoch: 491  Training loss = 1.9547  Validation loss = 1.5656  \n",
      "\n",
      "Fold: 6  Epoch: 492  Training loss = 1.9546  Validation loss = 1.5653  \n",
      "\n",
      "Fold: 6  Epoch: 493  Training loss = 1.9544  Validation loss = 1.5647  \n",
      "\n",
      "Fold: 6  Epoch: 494  Training loss = 1.9543  Validation loss = 1.5646  \n",
      "\n",
      "Fold: 6  Epoch: 495  Training loss = 1.9542  Validation loss = 1.5645  \n",
      "\n",
      "Fold: 6  Epoch: 496  Training loss = 1.9541  Validation loss = 1.5641  \n",
      "\n",
      "Fold: 6  Epoch: 497  Training loss = 1.9539  Validation loss = 1.5626  \n",
      "\n",
      "Fold: 6  Epoch: 498  Training loss = 1.9538  Validation loss = 1.5632  \n",
      "\n",
      "Fold: 6  Epoch: 499  Training loss = 1.9537  Validation loss = 1.5629  \n",
      "\n",
      "Fold: 6  Epoch: 500  Training loss = 1.9536  Validation loss = 1.5626  \n",
      "\n",
      "Check model:  Fold: 6  Optimal epoch: 497  \n",
      "\n",
      "Fold: 7  Epoch: 1  Training loss = 1.9427  Validation loss = 1.4707  \n",
      "\n",
      "Fold: 7  Epoch: 2  Training loss = 1.9427  Validation loss = 1.4706  \n",
      "\n",
      "Fold: 7  Epoch: 3  Training loss = 1.9423  Validation loss = 1.4692  \n",
      "\n",
      "Fold: 7  Epoch: 4  Training loss = 1.9420  Validation loss = 1.4678  \n",
      "\n",
      "Fold: 7  Epoch: 5  Training loss = 1.9417  Validation loss = 1.4667  \n",
      "\n",
      "Fold: 7  Epoch: 6  Training loss = 1.9416  Validation loss = 1.4665  \n",
      "\n",
      "Fold: 7  Epoch: 7  Training loss = 1.9415  Validation loss = 1.4665  \n",
      "\n",
      "Fold: 7  Epoch: 8  Training loss = 1.9413  Validation loss = 1.4657  \n",
      "\n",
      "Fold: 7  Epoch: 9  Training loss = 1.9411  Validation loss = 1.4648  \n",
      "\n",
      "Fold: 7  Epoch: 10  Training loss = 1.9408  Validation loss = 1.4634  \n",
      "\n",
      "Fold: 7  Epoch: 11  Training loss = 1.9405  Validation loss = 1.4626  \n",
      "\n",
      "Fold: 7  Epoch: 12  Training loss = 1.9401  Validation loss = 1.4606  \n",
      "\n",
      "Fold: 7  Epoch: 13  Training loss = 1.9399  Validation loss = 1.4598  \n",
      "\n",
      "Fold: 7  Epoch: 14  Training loss = 1.9397  Validation loss = 1.4595  \n",
      "\n",
      "Fold: 7  Epoch: 15  Training loss = 1.9395  Validation loss = 1.4586  \n",
      "\n",
      "Fold: 7  Epoch: 16  Training loss = 1.9392  Validation loss = 1.4576  \n",
      "\n",
      "Fold: 7  Epoch: 17  Training loss = 1.9390  Validation loss = 1.4566  \n",
      "\n",
      "Fold: 7  Epoch: 18  Training loss = 1.9386  Validation loss = 1.4548  \n",
      "\n",
      "Fold: 7  Epoch: 19  Training loss = 1.9384  Validation loss = 1.4546  \n",
      "\n",
      "Fold: 7  Epoch: 20  Training loss = 1.9384  Validation loss = 1.4544  \n",
      "\n",
      "Fold: 7  Epoch: 21  Training loss = 1.9381  Validation loss = 1.4535  \n",
      "\n",
      "Fold: 7  Epoch: 22  Training loss = 1.9380  Validation loss = 1.4531  \n",
      "\n",
      "Fold: 7  Epoch: 23  Training loss = 1.9379  Validation loss = 1.4531  \n",
      "\n",
      "Fold: 7  Epoch: 24  Training loss = 1.9377  Validation loss = 1.4522  \n",
      "\n",
      "Fold: 7  Epoch: 25  Training loss = 1.9375  Validation loss = 1.4517  \n",
      "\n",
      "Fold: 7  Epoch: 26  Training loss = 1.9373  Validation loss = 1.4510  \n",
      "\n",
      "Fold: 7  Epoch: 27  Training loss = 1.9371  Validation loss = 1.4504  \n",
      "\n",
      "Fold: 7  Epoch: 28  Training loss = 1.9370  Validation loss = 1.4499  \n",
      "\n",
      "Fold: 7  Epoch: 29  Training loss = 1.9366  Validation loss = 1.4485  \n",
      "\n",
      "Fold: 7  Epoch: 30  Training loss = 1.9364  Validation loss = 1.4475  \n",
      "\n",
      "Fold: 7  Epoch: 31  Training loss = 1.9359  Validation loss = 1.4459  \n",
      "\n",
      "Fold: 7  Epoch: 32  Training loss = 1.9358  Validation loss = 1.4451  \n",
      "\n",
      "Fold: 7  Epoch: 33  Training loss = 1.9354  Validation loss = 1.4435  \n",
      "\n",
      "Fold: 7  Epoch: 34  Training loss = 1.9350  Validation loss = 1.4419  \n",
      "\n",
      "Fold: 7  Epoch: 35  Training loss = 1.9348  Validation loss = 1.4409  \n",
      "\n",
      "Fold: 7  Epoch: 36  Training loss = 1.9345  Validation loss = 1.4400  \n",
      "\n",
      "Fold: 7  Epoch: 37  Training loss = 1.9343  Validation loss = 1.4389  \n",
      "\n",
      "Fold: 7  Epoch: 38  Training loss = 1.9341  Validation loss = 1.4383  \n",
      "\n",
      "Fold: 7  Epoch: 39  Training loss = 1.9338  Validation loss = 1.4370  \n",
      "\n",
      "Fold: 7  Epoch: 40  Training loss = 1.9336  Validation loss = 1.4362  \n",
      "\n",
      "Fold: 7  Epoch: 41  Training loss = 1.9334  Validation loss = 1.4355  \n",
      "\n",
      "Fold: 7  Epoch: 42  Training loss = 1.9331  Validation loss = 1.4343  \n",
      "\n",
      "Fold: 7  Epoch: 43  Training loss = 1.9327  Validation loss = 1.4325  \n",
      "\n",
      "Fold: 7  Epoch: 44  Training loss = 1.9324  Validation loss = 1.4311  \n",
      "\n",
      "Fold: 7  Epoch: 45  Training loss = 1.9321  Validation loss = 1.4298  \n",
      "\n",
      "Fold: 7  Epoch: 46  Training loss = 1.9319  Validation loss = 1.4290  \n",
      "\n",
      "Fold: 7  Epoch: 47  Training loss = 1.9315  Validation loss = 1.4272  \n",
      "\n",
      "Fold: 7  Epoch: 48  Training loss = 1.9312  Validation loss = 1.4259  \n",
      "\n",
      "Fold: 7  Epoch: 49  Training loss = 1.9309  Validation loss = 1.4246  \n",
      "\n",
      "Fold: 7  Epoch: 50  Training loss = 1.9307  Validation loss = 1.4239  \n",
      "\n",
      "Fold: 7  Epoch: 51  Training loss = 1.9305  Validation loss = 1.4232  \n",
      "\n",
      "Fold: 7  Epoch: 52  Training loss = 1.9301  Validation loss = 1.4215  \n",
      "\n",
      "Fold: 7  Epoch: 53  Training loss = 1.9299  Validation loss = 1.4206  \n",
      "\n",
      "Fold: 7  Epoch: 54  Training loss = 1.9298  Validation loss = 1.4202  \n",
      "\n",
      "Fold: 7  Epoch: 55  Training loss = 1.9297  Validation loss = 1.4197  \n",
      "\n",
      "Fold: 7  Epoch: 56  Training loss = 1.9295  Validation loss = 1.4189  \n",
      "\n",
      "Fold: 7  Epoch: 57  Training loss = 1.9292  Validation loss = 1.4177  \n",
      "\n",
      "Fold: 7  Epoch: 58  Training loss = 1.9290  Validation loss = 1.4166  \n",
      "\n",
      "Fold: 7  Epoch: 59  Training loss = 1.9287  Validation loss = 1.4151  \n",
      "\n",
      "Fold: 7  Epoch: 60  Training loss = 1.9285  Validation loss = 1.4144  \n",
      "\n",
      "Fold: 7  Epoch: 61  Training loss = 1.9282  Validation loss = 1.4133  \n",
      "\n",
      "Fold: 7  Epoch: 62  Training loss = 1.9280  Validation loss = 1.4125  \n",
      "\n",
      "Fold: 7  Epoch: 63  Training loss = 1.9279  Validation loss = 1.4121  \n",
      "\n",
      "Fold: 7  Epoch: 64  Training loss = 1.9279  Validation loss = 1.4123  \n",
      "\n",
      "Fold: 7  Epoch: 65  Training loss = 1.9278  Validation loss = 1.4123  \n",
      "\n",
      "Fold: 7  Epoch: 66  Training loss = 1.9275  Validation loss = 1.4112  \n",
      "\n",
      "Fold: 7  Epoch: 67  Training loss = 1.9273  Validation loss = 1.4106  \n",
      "\n",
      "Fold: 7  Epoch: 68  Training loss = 1.9271  Validation loss = 1.4093  \n",
      "\n",
      "Fold: 7  Epoch: 69  Training loss = 1.9269  Validation loss = 1.4085  \n",
      "\n",
      "Fold: 7  Epoch: 70  Training loss = 1.9266  Validation loss = 1.4074  \n",
      "\n",
      "Fold: 7  Epoch: 71  Training loss = 1.9265  Validation loss = 1.4067  \n",
      "\n",
      "Fold: 7  Epoch: 72  Training loss = 1.9261  Validation loss = 1.4053  \n",
      "\n",
      "Fold: 7  Epoch: 73  Training loss = 1.9260  Validation loss = 1.4046  \n",
      "\n",
      "Fold: 7  Epoch: 74  Training loss = 1.9259  Validation loss = 1.4046  \n",
      "\n",
      "Fold: 7  Epoch: 75  Training loss = 1.9257  Validation loss = 1.4037  \n",
      "\n",
      "Fold: 7  Epoch: 76  Training loss = 1.9254  Validation loss = 1.4024  \n",
      "\n",
      "Fold: 7  Epoch: 77  Training loss = 1.9253  Validation loss = 1.4017  \n",
      "\n",
      "Fold: 7  Epoch: 78  Training loss = 1.9250  Validation loss = 1.4006  \n",
      "\n",
      "Fold: 7  Epoch: 79  Training loss = 1.9245  Validation loss = 1.3982  \n",
      "\n",
      "Fold: 7  Epoch: 80  Training loss = 1.9243  Validation loss = 1.3973  \n",
      "\n",
      "Fold: 7  Epoch: 81  Training loss = 1.9241  Validation loss = 1.3963  \n",
      "\n",
      "Fold: 7  Epoch: 82  Training loss = 1.9238  Validation loss = 1.3954  \n",
      "\n",
      "Fold: 7  Epoch: 83  Training loss = 1.9236  Validation loss = 1.3945  \n",
      "\n",
      "Fold: 7  Epoch: 84  Training loss = 1.9235  Validation loss = 1.3939  \n",
      "\n",
      "Fold: 7  Epoch: 85  Training loss = 1.9232  Validation loss = 1.3927  \n",
      "\n",
      "Fold: 7  Epoch: 86  Training loss = 1.9232  Validation loss = 1.3929  \n",
      "\n",
      "Fold: 7  Epoch: 87  Training loss = 1.9230  Validation loss = 1.3924  \n",
      "\n",
      "Fold: 7  Epoch: 88  Training loss = 1.9227  Validation loss = 1.3912  \n",
      "\n",
      "Fold: 7  Epoch: 89  Training loss = 1.9226  Validation loss = 1.3905  \n",
      "\n",
      "Fold: 7  Epoch: 90  Training loss = 1.9224  Validation loss = 1.3898  \n",
      "\n",
      "Fold: 7  Epoch: 91  Training loss = 1.9222  Validation loss = 1.3890  \n",
      "\n",
      "Fold: 7  Epoch: 92  Training loss = 1.9220  Validation loss = 1.3883  \n",
      "\n",
      "Fold: 7  Epoch: 93  Training loss = 1.9218  Validation loss = 1.3871  \n",
      "\n",
      "Fold: 7  Epoch: 94  Training loss = 1.9216  Validation loss = 1.3867  \n",
      "\n",
      "Fold: 7  Epoch: 95  Training loss = 1.9215  Validation loss = 1.3864  \n",
      "\n",
      "Fold: 7  Epoch: 96  Training loss = 1.9212  Validation loss = 1.3848  \n",
      "\n",
      "Fold: 7  Epoch: 97  Training loss = 1.9210  Validation loss = 1.3838  \n",
      "\n",
      "Fold: 7  Epoch: 98  Training loss = 1.9208  Validation loss = 1.3830  \n",
      "\n",
      "Fold: 7  Epoch: 99  Training loss = 1.9207  Validation loss = 1.3828  \n",
      "\n",
      "Fold: 7  Epoch: 100  Training loss = 1.9205  Validation loss = 1.3819  \n",
      "\n",
      "Fold: 7  Epoch: 101  Training loss = 1.9203  Validation loss = 1.3815  \n",
      "\n",
      "Fold: 7  Epoch: 102  Training loss = 1.9202  Validation loss = 1.3807  \n",
      "\n",
      "Fold: 7  Epoch: 103  Training loss = 1.9200  Validation loss = 1.3798  \n",
      "\n",
      "Fold: 7  Epoch: 104  Training loss = 1.9197  Validation loss = 1.3785  \n",
      "\n",
      "Fold: 7  Epoch: 105  Training loss = 1.9195  Validation loss = 1.3778  \n",
      "\n",
      "Fold: 7  Epoch: 106  Training loss = 1.9193  Validation loss = 1.3768  \n",
      "\n",
      "Fold: 7  Epoch: 107  Training loss = 1.9190  Validation loss = 1.3756  \n",
      "\n",
      "Fold: 7  Epoch: 108  Training loss = 1.9188  Validation loss = 1.3746  \n",
      "\n",
      "Fold: 7  Epoch: 109  Training loss = 1.9185  Validation loss = 1.3735  \n",
      "\n",
      "Fold: 7  Epoch: 110  Training loss = 1.9182  Validation loss = 1.3722  \n",
      "\n",
      "Fold: 7  Epoch: 111  Training loss = 1.9181  Validation loss = 1.3714  \n",
      "\n",
      "Fold: 7  Epoch: 112  Training loss = 1.9180  Validation loss = 1.3711  \n",
      "\n",
      "Fold: 7  Epoch: 113  Training loss = 1.9179  Validation loss = 1.3711  \n",
      "\n",
      "Fold: 7  Epoch: 114  Training loss = 1.9177  Validation loss = 1.3699  \n",
      "\n",
      "Fold: 7  Epoch: 115  Training loss = 1.9175  Validation loss = 1.3692  \n",
      "\n",
      "Fold: 7  Epoch: 116  Training loss = 1.9173  Validation loss = 1.3684  \n",
      "\n",
      "Fold: 7  Epoch: 117  Training loss = 1.9172  Validation loss = 1.3680  \n",
      "\n",
      "Fold: 7  Epoch: 118  Training loss = 1.9170  Validation loss = 1.3672  \n",
      "\n",
      "Fold: 7  Epoch: 119  Training loss = 1.9167  Validation loss = 1.3660  \n",
      "\n",
      "Fold: 7  Epoch: 120  Training loss = 1.9165  Validation loss = 1.3649  \n",
      "\n",
      "Fold: 7  Epoch: 121  Training loss = 1.9163  Validation loss = 1.3641  \n",
      "\n",
      "Fold: 7  Epoch: 122  Training loss = 1.9160  Validation loss = 1.3628  \n",
      "\n",
      "Fold: 7  Epoch: 123  Training loss = 1.9157  Validation loss = 1.3613  \n",
      "\n",
      "Fold: 7  Epoch: 124  Training loss = 1.9156  Validation loss = 1.3608  \n",
      "\n",
      "Fold: 7  Epoch: 125  Training loss = 1.9155  Validation loss = 1.3603  \n",
      "\n",
      "Fold: 7  Epoch: 126  Training loss = 1.9152  Validation loss = 1.3589  \n",
      "\n",
      "Fold: 7  Epoch: 127  Training loss = 1.9149  Validation loss = 1.3575  \n",
      "\n",
      "Fold: 7  Epoch: 128  Training loss = 1.9147  Validation loss = 1.3567  \n",
      "\n",
      "Fold: 7  Epoch: 129  Training loss = 1.9146  Validation loss = 1.3559  \n",
      "\n",
      "Fold: 7  Epoch: 130  Training loss = 1.9144  Validation loss = 1.3555  \n",
      "\n",
      "Fold: 7  Epoch: 131  Training loss = 1.9144  Validation loss = 1.3556  \n",
      "\n",
      "Fold: 7  Epoch: 132  Training loss = 1.9143  Validation loss = 1.3556  \n",
      "\n",
      "Fold: 7  Epoch: 133  Training loss = 1.9141  Validation loss = 1.3545  \n",
      "\n",
      "Fold: 7  Epoch: 134  Training loss = 1.9139  Validation loss = 1.3534  \n",
      "\n",
      "Fold: 7  Epoch: 135  Training loss = 1.9137  Validation loss = 1.3531  \n",
      "\n",
      "Fold: 7  Epoch: 136  Training loss = 1.9135  Validation loss = 1.3518  \n",
      "\n",
      "Fold: 7  Epoch: 137  Training loss = 1.9133  Validation loss = 1.3511  \n",
      "\n",
      "Fold: 7  Epoch: 138  Training loss = 1.9131  Validation loss = 1.3505  \n",
      "\n",
      "Fold: 7  Epoch: 139  Training loss = 1.9129  Validation loss = 1.3493  \n",
      "\n",
      "Fold: 7  Epoch: 140  Training loss = 1.9128  Validation loss = 1.3491  \n",
      "\n",
      "Fold: 7  Epoch: 141  Training loss = 1.9127  Validation loss = 1.3486  \n",
      "\n",
      "Fold: 7  Epoch: 142  Training loss = 1.9125  Validation loss = 1.3480  \n",
      "\n",
      "Fold: 7  Epoch: 143  Training loss = 1.9124  Validation loss = 1.3479  \n",
      "\n",
      "Fold: 7  Epoch: 144  Training loss = 1.9123  Validation loss = 1.3471  \n",
      "\n",
      "Fold: 7  Epoch: 145  Training loss = 1.9121  Validation loss = 1.3465  \n",
      "\n",
      "Fold: 7  Epoch: 146  Training loss = 1.9119  Validation loss = 1.3456  \n",
      "\n",
      "Fold: 7  Epoch: 147  Training loss = 1.9117  Validation loss = 1.3446  \n",
      "\n",
      "Fold: 7  Epoch: 148  Training loss = 1.9115  Validation loss = 1.3434  \n",
      "\n",
      "Fold: 7  Epoch: 149  Training loss = 1.9112  Validation loss = 1.3418  \n",
      "\n",
      "Fold: 7  Epoch: 150  Training loss = 1.9109  Validation loss = 1.3408  \n",
      "\n",
      "Fold: 7  Epoch: 151  Training loss = 1.9107  Validation loss = 1.3396  \n",
      "\n",
      "Fold: 7  Epoch: 152  Training loss = 1.9105  Validation loss = 1.3387  \n",
      "\n",
      "Fold: 7  Epoch: 153  Training loss = 1.9104  Validation loss = 1.3384  \n",
      "\n",
      "Fold: 7  Epoch: 154  Training loss = 1.9102  Validation loss = 1.3374  \n",
      "\n",
      "Fold: 7  Epoch: 155  Training loss = 1.9100  Validation loss = 1.3368  \n",
      "\n",
      "Fold: 7  Epoch: 156  Training loss = 1.9098  Validation loss = 1.3359  \n",
      "\n",
      "Fold: 7  Epoch: 157  Training loss = 1.9097  Validation loss = 1.3357  \n",
      "\n",
      "Fold: 7  Epoch: 158  Training loss = 1.9097  Validation loss = 1.3358  \n",
      "\n",
      "Fold: 7  Epoch: 159  Training loss = 1.9096  Validation loss = 1.3354  \n",
      "\n",
      "Fold: 7  Epoch: 160  Training loss = 1.9094  Validation loss = 1.3347  \n",
      "\n",
      "Fold: 7  Epoch: 161  Training loss = 1.9092  Validation loss = 1.3338  \n",
      "\n",
      "Fold: 7  Epoch: 162  Training loss = 1.9090  Validation loss = 1.3323  \n",
      "\n",
      "Fold: 7  Epoch: 163  Training loss = 1.9087  Validation loss = 1.3310  \n",
      "\n",
      "Fold: 7  Epoch: 164  Training loss = 1.9085  Validation loss = 1.3301  \n",
      "\n",
      "Fold: 7  Epoch: 165  Training loss = 1.9083  Validation loss = 1.3292  \n",
      "\n",
      "Fold: 7  Epoch: 166  Training loss = 1.9081  Validation loss = 1.3283  \n",
      "\n",
      "Fold: 7  Epoch: 167  Training loss = 1.9078  Validation loss = 1.3270  \n",
      "\n",
      "Fold: 7  Epoch: 168  Training loss = 1.9075  Validation loss = 1.3256  \n",
      "\n",
      "Fold: 7  Epoch: 169  Training loss = 1.9074  Validation loss = 1.3249  \n",
      "\n",
      "Fold: 7  Epoch: 170  Training loss = 1.9071  Validation loss = 1.3235  \n",
      "\n",
      "Fold: 7  Epoch: 171  Training loss = 1.9068  Validation loss = 1.3221  \n",
      "\n",
      "Fold: 7  Epoch: 172  Training loss = 1.9066  Validation loss = 1.3212  \n",
      "\n",
      "Fold: 7  Epoch: 173  Training loss = 1.9064  Validation loss = 1.3202  \n",
      "\n",
      "Fold: 7  Epoch: 174  Training loss = 1.9062  Validation loss = 1.3193  \n",
      "\n",
      "Fold: 7  Epoch: 175  Training loss = 1.9061  Validation loss = 1.3186  \n",
      "\n",
      "Fold: 7  Epoch: 176  Training loss = 1.9059  Validation loss = 1.3180  \n",
      "\n",
      "Fold: 7  Epoch: 177  Training loss = 1.9059  Validation loss = 1.3180  \n",
      "\n",
      "Fold: 7  Epoch: 178  Training loss = 1.9059  Validation loss = 1.3183  \n",
      "\n",
      "Fold: 7  Epoch: 179  Training loss = 1.9057  Validation loss = 1.3172  \n",
      "\n",
      "Fold: 7  Epoch: 180  Training loss = 1.9055  Validation loss = 1.3167  \n",
      "\n",
      "Fold: 7  Epoch: 181  Training loss = 1.9054  Validation loss = 1.3159  \n",
      "\n",
      "Fold: 7  Epoch: 182  Training loss = 1.9053  Validation loss = 1.3156  \n",
      "\n",
      "Fold: 7  Epoch: 183  Training loss = 1.9051  Validation loss = 1.3149  \n",
      "\n",
      "Fold: 7  Epoch: 184  Training loss = 1.9049  Validation loss = 1.3140  \n",
      "\n",
      "Fold: 7  Epoch: 185  Training loss = 1.9046  Validation loss = 1.3127  \n",
      "\n",
      "Fold: 7  Epoch: 186  Training loss = 1.9045  Validation loss = 1.3124  \n",
      "\n",
      "Fold: 7  Epoch: 187  Training loss = 1.9044  Validation loss = 1.3122  \n",
      "\n",
      "Fold: 7  Epoch: 188  Training loss = 1.9044  Validation loss = 1.3123  \n",
      "\n",
      "Fold: 7  Epoch: 189  Training loss = 1.9042  Validation loss = 1.3115  \n",
      "\n",
      "Fold: 7  Epoch: 190  Training loss = 1.9041  Validation loss = 1.3110  \n",
      "\n",
      "Fold: 7  Epoch: 191  Training loss = 1.9039  Validation loss = 1.3104  \n",
      "\n",
      "Fold: 7  Epoch: 192  Training loss = 1.9037  Validation loss = 1.3096  \n",
      "\n",
      "Fold: 7  Epoch: 193  Training loss = 1.9036  Validation loss = 1.3092  \n",
      "\n",
      "Fold: 7  Epoch: 194  Training loss = 1.9034  Validation loss = 1.3081  \n",
      "\n",
      "Fold: 7  Epoch: 195  Training loss = 1.9032  Validation loss = 1.3072  \n",
      "\n",
      "Fold: 7  Epoch: 196  Training loss = 1.9031  Validation loss = 1.3068  \n",
      "\n",
      "Fold: 7  Epoch: 197  Training loss = 1.9029  Validation loss = 1.3061  \n",
      "\n",
      "Fold: 7  Epoch: 198  Training loss = 1.9027  Validation loss = 1.3052  \n",
      "\n",
      "Fold: 7  Epoch: 199  Training loss = 1.9025  Validation loss = 1.3044  \n",
      "\n",
      "Fold: 7  Epoch: 200  Training loss = 1.9024  Validation loss = 1.3038  \n",
      "\n",
      "Fold: 7  Epoch: 201  Training loss = 1.9023  Validation loss = 1.3033  \n",
      "\n",
      "Fold: 7  Epoch: 202  Training loss = 1.9021  Validation loss = 1.3026  \n",
      "\n",
      "Fold: 7  Epoch: 203  Training loss = 1.9019  Validation loss = 1.3015  \n",
      "\n",
      "Fold: 7  Epoch: 204  Training loss = 1.9018  Validation loss = 1.3011  \n",
      "\n",
      "Fold: 7  Epoch: 205  Training loss = 1.9016  Validation loss = 1.3003  \n",
      "\n",
      "Fold: 7  Epoch: 206  Training loss = 1.9014  Validation loss = 1.2991  \n",
      "\n",
      "Fold: 7  Epoch: 207  Training loss = 1.9011  Validation loss = 1.2977  \n",
      "\n",
      "Fold: 7  Epoch: 208  Training loss = 1.9011  Validation loss = 1.2977  \n",
      "\n",
      "Fold: 7  Epoch: 209  Training loss = 1.9009  Validation loss = 1.2972  \n",
      "\n",
      "Fold: 7  Epoch: 210  Training loss = 1.9008  Validation loss = 1.2966  \n",
      "\n",
      "Fold: 7  Epoch: 211  Training loss = 1.9005  Validation loss = 1.2949  \n",
      "\n",
      "Fold: 7  Epoch: 212  Training loss = 1.9004  Validation loss = 1.2948  \n",
      "\n",
      "Fold: 7  Epoch: 213  Training loss = 1.9003  Validation loss = 1.2941  \n",
      "\n",
      "Fold: 7  Epoch: 214  Training loss = 1.9001  Validation loss = 1.2933  \n",
      "\n",
      "Fold: 7  Epoch: 215  Training loss = 1.9000  Validation loss = 1.2929  \n",
      "\n",
      "Fold: 7  Epoch: 216  Training loss = 1.8998  Validation loss = 1.2923  \n",
      "\n",
      "Fold: 7  Epoch: 217  Training loss = 1.8998  Validation loss = 1.2923  \n",
      "\n",
      "Fold: 7  Epoch: 218  Training loss = 1.8996  Validation loss = 1.2917  \n",
      "\n",
      "Fold: 7  Epoch: 219  Training loss = 1.8995  Validation loss = 1.2914  \n",
      "\n",
      "Fold: 7  Epoch: 220  Training loss = 1.8994  Validation loss = 1.2910  \n",
      "\n",
      "Fold: 7  Epoch: 221  Training loss = 1.8992  Validation loss = 1.2902  \n",
      "\n",
      "Fold: 7  Epoch: 222  Training loss = 1.8991  Validation loss = 1.2899  \n",
      "\n",
      "Fold: 7  Epoch: 223  Training loss = 1.8989  Validation loss = 1.2889  \n",
      "\n",
      "Fold: 7  Epoch: 224  Training loss = 1.8988  Validation loss = 1.2888  \n",
      "\n",
      "Fold: 7  Epoch: 225  Training loss = 1.8986  Validation loss = 1.2876  \n",
      "\n",
      "Fold: 7  Epoch: 226  Training loss = 1.8983  Validation loss = 1.2864  \n",
      "\n",
      "Fold: 7  Epoch: 227  Training loss = 1.8982  Validation loss = 1.2855  \n",
      "\n",
      "Fold: 7  Epoch: 228  Training loss = 1.8979  Validation loss = 1.2842  \n",
      "\n",
      "Fold: 7  Epoch: 229  Training loss = 1.8977  Validation loss = 1.2830  \n",
      "\n",
      "Fold: 7  Epoch: 230  Training loss = 1.8976  Validation loss = 1.2829  \n",
      "\n",
      "Fold: 7  Epoch: 231  Training loss = 1.8973  Validation loss = 1.2816  \n",
      "\n",
      "Fold: 7  Epoch: 232  Training loss = 1.8972  Validation loss = 1.2811  \n",
      "\n",
      "Fold: 7  Epoch: 233  Training loss = 1.8971  Validation loss = 1.2805  \n",
      "\n",
      "Fold: 7  Epoch: 234  Training loss = 1.8970  Validation loss = 1.2801  \n",
      "\n",
      "Fold: 7  Epoch: 235  Training loss = 1.8969  Validation loss = 1.2797  \n",
      "\n",
      "Fold: 7  Epoch: 236  Training loss = 1.8967  Validation loss = 1.2791  \n",
      "\n",
      "Fold: 7  Epoch: 237  Training loss = 1.8966  Validation loss = 1.2785  \n",
      "\n",
      "Fold: 7  Epoch: 238  Training loss = 1.8964  Validation loss = 1.2773  \n",
      "\n",
      "Fold: 7  Epoch: 239  Training loss = 1.8963  Validation loss = 1.2772  \n",
      "\n",
      "Fold: 7  Epoch: 240  Training loss = 1.8959  Validation loss = 1.2751  \n",
      "\n",
      "Fold: 7  Epoch: 241  Training loss = 1.8959  Validation loss = 1.2748  \n",
      "\n",
      "Fold: 7  Epoch: 242  Training loss = 1.8956  Validation loss = 1.2736  \n",
      "\n",
      "Fold: 7  Epoch: 243  Training loss = 1.8955  Validation loss = 1.2728  \n",
      "\n",
      "Fold: 7  Epoch: 244  Training loss = 1.8953  Validation loss = 1.2720  \n",
      "\n",
      "Fold: 7  Epoch: 245  Training loss = 1.8952  Validation loss = 1.2715  \n",
      "\n",
      "Fold: 7  Epoch: 246  Training loss = 1.8950  Validation loss = 1.2708  \n",
      "\n",
      "Fold: 7  Epoch: 247  Training loss = 1.8949  Validation loss = 1.2701  \n",
      "\n",
      "Fold: 7  Epoch: 248  Training loss = 1.8947  Validation loss = 1.2693  \n",
      "\n",
      "Fold: 7  Epoch: 249  Training loss = 1.8946  Validation loss = 1.2692  \n",
      "\n",
      "Fold: 7  Epoch: 250  Training loss = 1.8944  Validation loss = 1.2684  \n",
      "\n",
      "Fold: 7  Epoch: 251  Training loss = 1.8942  Validation loss = 1.2673  \n",
      "\n",
      "Fold: 7  Epoch: 252  Training loss = 1.8941  Validation loss = 1.2668  \n",
      "\n",
      "Fold: 7  Epoch: 253  Training loss = 1.8940  Validation loss = 1.2665  \n",
      "\n",
      "Fold: 7  Epoch: 254  Training loss = 1.8939  Validation loss = 1.2660  \n",
      "\n",
      "Fold: 7  Epoch: 255  Training loss = 1.8937  Validation loss = 1.2653  \n",
      "\n",
      "Fold: 7  Epoch: 256  Training loss = 1.8937  Validation loss = 1.2654  \n",
      "\n",
      "Fold: 7  Epoch: 257  Training loss = 1.8935  Validation loss = 1.2645  \n",
      "\n",
      "Fold: 7  Epoch: 258  Training loss = 1.8934  Validation loss = 1.2639  \n",
      "\n",
      "Fold: 7  Epoch: 259  Training loss = 1.8932  Validation loss = 1.2627  \n",
      "\n",
      "Fold: 7  Epoch: 260  Training loss = 1.8930  Validation loss = 1.2620  \n",
      "\n",
      "Fold: 7  Epoch: 261  Training loss = 1.8929  Validation loss = 1.2614  \n",
      "\n",
      "Fold: 7  Epoch: 262  Training loss = 1.8928  Validation loss = 1.2613  \n",
      "\n",
      "Fold: 7  Epoch: 263  Training loss = 1.8926  Validation loss = 1.2605  \n",
      "\n",
      "Fold: 7  Epoch: 264  Training loss = 1.8924  Validation loss = 1.2594  \n",
      "\n",
      "Fold: 7  Epoch: 265  Training loss = 1.8923  Validation loss = 1.2589  \n",
      "\n",
      "Fold: 7  Epoch: 266  Training loss = 1.8922  Validation loss = 1.2585  \n",
      "\n",
      "Fold: 7  Epoch: 267  Training loss = 1.8920  Validation loss = 1.2575  \n",
      "\n",
      "Fold: 7  Epoch: 268  Training loss = 1.8919  Validation loss = 1.2574  \n",
      "\n",
      "Fold: 7  Epoch: 269  Training loss = 1.8918  Validation loss = 1.2569  \n",
      "\n",
      "Fold: 7  Epoch: 270  Training loss = 1.8918  Validation loss = 1.2573  \n",
      "\n",
      "Fold: 7  Epoch: 271  Training loss = 1.8916  Validation loss = 1.2565  \n",
      "\n",
      "Fold: 7  Epoch: 272  Training loss = 1.8915  Validation loss = 1.2561  \n",
      "\n",
      "Fold: 7  Epoch: 273  Training loss = 1.8914  Validation loss = 1.2555  \n",
      "\n",
      "Fold: 7  Epoch: 274  Training loss = 1.8913  Validation loss = 1.2552  \n",
      "\n",
      "Fold: 7  Epoch: 275  Training loss = 1.8911  Validation loss = 1.2545  \n",
      "\n",
      "Fold: 7  Epoch: 276  Training loss = 1.8910  Validation loss = 1.2538  \n",
      "\n",
      "Fold: 7  Epoch: 277  Training loss = 1.8908  Validation loss = 1.2527  \n",
      "\n",
      "Fold: 7  Epoch: 278  Training loss = 1.8906  Validation loss = 1.2520  \n",
      "\n",
      "Fold: 7  Epoch: 279  Training loss = 1.8905  Validation loss = 1.2514  \n",
      "\n",
      "Fold: 7  Epoch: 280  Training loss = 1.8904  Validation loss = 1.2506  \n",
      "\n",
      "Fold: 7  Epoch: 281  Training loss = 1.8903  Validation loss = 1.2504  \n",
      "\n",
      "Fold: 7  Epoch: 282  Training loss = 1.8901  Validation loss = 1.2496  \n",
      "\n",
      "Fold: 7  Epoch: 283  Training loss = 1.8899  Validation loss = 1.2485  \n",
      "\n",
      "Fold: 7  Epoch: 284  Training loss = 1.8897  Validation loss = 1.2474  \n",
      "\n",
      "Fold: 7  Epoch: 285  Training loss = 1.8896  Validation loss = 1.2472  \n",
      "\n",
      "Fold: 7  Epoch: 286  Training loss = 1.8895  Validation loss = 1.2468  \n",
      "\n",
      "Fold: 7  Epoch: 287  Training loss = 1.8894  Validation loss = 1.2462  \n",
      "\n",
      "Fold: 7  Epoch: 288  Training loss = 1.8891  Validation loss = 1.2448  \n",
      "\n",
      "Fold: 7  Epoch: 289  Training loss = 1.8889  Validation loss = 1.2436  \n",
      "\n",
      "Fold: 7  Epoch: 290  Training loss = 1.8888  Validation loss = 1.2432  \n",
      "\n",
      "Fold: 7  Epoch: 291  Training loss = 1.8887  Validation loss = 1.2428  \n",
      "\n",
      "Fold: 7  Epoch: 292  Training loss = 1.8886  Validation loss = 1.2424  \n",
      "\n",
      "Fold: 7  Epoch: 293  Training loss = 1.8885  Validation loss = 1.2422  \n",
      "\n",
      "Fold: 7  Epoch: 294  Training loss = 1.8884  Validation loss = 1.2419  \n",
      "\n",
      "Fold: 7  Epoch: 295  Training loss = 1.8883  Validation loss = 1.2417  \n",
      "\n",
      "Fold: 7  Epoch: 296  Training loss = 1.8882  Validation loss = 1.2409  \n",
      "\n",
      "Fold: 7  Epoch: 297  Training loss = 1.8881  Validation loss = 1.2411  \n",
      "\n",
      "Fold: 7  Epoch: 298  Training loss = 1.8880  Validation loss = 1.2403  \n",
      "\n",
      "Fold: 7  Epoch: 299  Training loss = 1.8877  Validation loss = 1.2390  \n",
      "\n",
      "Fold: 7  Epoch: 300  Training loss = 1.8876  Validation loss = 1.2386  \n",
      "\n",
      "Fold: 7  Epoch: 301  Training loss = 1.8875  Validation loss = 1.2381  \n",
      "\n",
      "Fold: 7  Epoch: 302  Training loss = 1.8874  Validation loss = 1.2378  \n",
      "\n",
      "Fold: 7  Epoch: 303  Training loss = 1.8872  Validation loss = 1.2370  \n",
      "\n",
      "Fold: 7  Epoch: 304  Training loss = 1.8870  Validation loss = 1.2360  \n",
      "\n",
      "Fold: 7  Epoch: 305  Training loss = 1.8870  Validation loss = 1.2361  \n",
      "\n",
      "Fold: 7  Epoch: 306  Training loss = 1.8869  Validation loss = 1.2353  \n",
      "\n",
      "Fold: 7  Epoch: 307  Training loss = 1.8868  Validation loss = 1.2350  \n",
      "\n",
      "Fold: 7  Epoch: 308  Training loss = 1.8867  Validation loss = 1.2350  \n",
      "\n",
      "Fold: 7  Epoch: 309  Training loss = 1.8865  Validation loss = 1.2337  \n",
      "\n",
      "Fold: 7  Epoch: 310  Training loss = 1.8864  Validation loss = 1.2337  \n",
      "\n",
      "Fold: 7  Epoch: 311  Training loss = 1.8863  Validation loss = 1.2337  \n",
      "\n",
      "Fold: 7  Epoch: 312  Training loss = 1.8862  Validation loss = 1.2327  \n",
      "\n",
      "Fold: 7  Epoch: 313  Training loss = 1.8860  Validation loss = 1.2319  \n",
      "\n",
      "Fold: 7  Epoch: 314  Training loss = 1.8860  Validation loss = 1.2319  \n",
      "\n",
      "Fold: 7  Epoch: 315  Training loss = 1.8857  Validation loss = 1.2305  \n",
      "\n",
      "Fold: 7  Epoch: 316  Training loss = 1.8856  Validation loss = 1.2299  \n",
      "\n",
      "Fold: 7  Epoch: 317  Training loss = 1.8855  Validation loss = 1.2299  \n",
      "\n",
      "Fold: 7  Epoch: 318  Training loss = 1.8854  Validation loss = 1.2293  \n",
      "\n",
      "Fold: 7  Epoch: 319  Training loss = 1.8852  Validation loss = 1.2284  \n",
      "\n",
      "Fold: 7  Epoch: 320  Training loss = 1.8850  Validation loss = 1.2273  \n",
      "\n",
      "Fold: 7  Epoch: 321  Training loss = 1.8850  Validation loss = 1.2276  \n",
      "\n",
      "Fold: 7  Epoch: 322  Training loss = 1.8849  Validation loss = 1.2268  \n",
      "\n",
      "Fold: 7  Epoch: 323  Training loss = 1.8847  Validation loss = 1.2260  \n",
      "\n",
      "Fold: 7  Epoch: 324  Training loss = 1.8844  Validation loss = 1.2244  \n",
      "\n",
      "Fold: 7  Epoch: 325  Training loss = 1.8842  Validation loss = 1.2233  \n",
      "\n",
      "Fold: 7  Epoch: 326  Training loss = 1.8842  Validation loss = 1.2233  \n",
      "\n",
      "Fold: 7  Epoch: 327  Training loss = 1.8840  Validation loss = 1.2221  \n",
      "\n",
      "Fold: 7  Epoch: 328  Training loss = 1.8839  Validation loss = 1.2218  \n",
      "\n",
      "Fold: 7  Epoch: 329  Training loss = 1.8837  Validation loss = 1.2208  \n",
      "\n",
      "Fold: 7  Epoch: 330  Training loss = 1.8835  Validation loss = 1.2199  \n",
      "\n",
      "Fold: 7  Epoch: 331  Training loss = 1.8834  Validation loss = 1.2193  \n",
      "\n",
      "Fold: 7  Epoch: 332  Training loss = 1.8833  Validation loss = 1.2191  \n",
      "\n",
      "Fold: 7  Epoch: 333  Training loss = 1.8832  Validation loss = 1.2186  \n",
      "\n",
      "Fold: 7  Epoch: 334  Training loss = 1.8831  Validation loss = 1.2184  \n",
      "\n",
      "Fold: 7  Epoch: 335  Training loss = 1.8830  Validation loss = 1.2181  \n",
      "\n",
      "Fold: 7  Epoch: 336  Training loss = 1.8829  Validation loss = 1.2178  \n",
      "\n",
      "Fold: 7  Epoch: 337  Training loss = 1.8828  Validation loss = 1.2173  \n",
      "\n",
      "Fold: 7  Epoch: 338  Training loss = 1.8827  Validation loss = 1.2170  \n",
      "\n",
      "Fold: 7  Epoch: 339  Training loss = 1.8825  Validation loss = 1.2162  \n",
      "\n",
      "Fold: 7  Epoch: 340  Training loss = 1.8823  Validation loss = 1.2155  \n",
      "\n",
      "Fold: 7  Epoch: 341  Training loss = 1.8822  Validation loss = 1.2145  \n",
      "\n",
      "Fold: 7  Epoch: 342  Training loss = 1.8821  Validation loss = 1.2143  \n",
      "\n",
      "Fold: 7  Epoch: 343  Training loss = 1.8819  Validation loss = 1.2130  \n",
      "\n",
      "Fold: 7  Epoch: 344  Training loss = 1.8817  Validation loss = 1.2118  \n",
      "\n",
      "Fold: 7  Epoch: 345  Training loss = 1.8814  Validation loss = 1.2098  \n",
      "\n",
      "Fold: 7  Epoch: 346  Training loss = 1.8813  Validation loss = 1.2099  \n",
      "\n",
      "Fold: 7  Epoch: 347  Training loss = 1.8812  Validation loss = 1.2092  \n",
      "\n",
      "Fold: 7  Epoch: 348  Training loss = 1.8811  Validation loss = 1.2090  \n",
      "\n",
      "Fold: 7  Epoch: 349  Training loss = 1.8810  Validation loss = 1.2084  \n",
      "\n",
      "Fold: 7  Epoch: 350  Training loss = 1.8809  Validation loss = 1.2084  \n",
      "\n",
      "Fold: 7  Epoch: 351  Training loss = 1.8807  Validation loss = 1.2075  \n",
      "\n",
      "Fold: 7  Epoch: 352  Training loss = 1.8806  Validation loss = 1.2069  \n",
      "\n",
      "Fold: 7  Epoch: 353  Training loss = 1.8804  Validation loss = 1.2061  \n",
      "\n",
      "Fold: 7  Epoch: 354  Training loss = 1.8803  Validation loss = 1.2054  \n",
      "\n",
      "Fold: 7  Epoch: 355  Training loss = 1.8801  Validation loss = 1.2040  \n",
      "\n",
      "Fold: 7  Epoch: 356  Training loss = 1.8800  Validation loss = 1.2035  \n",
      "\n",
      "Fold: 7  Epoch: 357  Training loss = 1.8798  Validation loss = 1.2026  \n",
      "\n",
      "Fold: 7  Epoch: 358  Training loss = 1.8797  Validation loss = 1.2021  \n",
      "\n",
      "Fold: 7  Epoch: 359  Training loss = 1.8795  Validation loss = 1.2011  \n",
      "\n",
      "Fold: 7  Epoch: 360  Training loss = 1.8794  Validation loss = 1.2009  \n",
      "\n",
      "Fold: 7  Epoch: 361  Training loss = 1.8793  Validation loss = 1.2002  \n",
      "\n",
      "Fold: 7  Epoch: 362  Training loss = 1.8792  Validation loss = 1.2003  \n",
      "\n",
      "Fold: 7  Epoch: 363  Training loss = 1.8792  Validation loss = 1.2004  \n",
      "\n",
      "Fold: 7  Epoch: 364  Training loss = 1.8792  Validation loss = 1.2007  \n",
      "\n",
      "Fold: 7  Epoch: 365  Training loss = 1.8790  Validation loss = 1.1997  \n",
      "\n",
      "Fold: 7  Epoch: 366  Training loss = 1.8789  Validation loss = 1.1997  \n",
      "\n",
      "Fold: 7  Epoch: 367  Training loss = 1.8788  Validation loss = 1.1989  \n",
      "\n",
      "Fold: 7  Epoch: 368  Training loss = 1.8786  Validation loss = 1.1979  \n",
      "\n",
      "Fold: 7  Epoch: 369  Training loss = 1.8785  Validation loss = 1.1976  \n",
      "\n",
      "Fold: 7  Epoch: 370  Training loss = 1.8784  Validation loss = 1.1969  \n",
      "\n",
      "Fold: 7  Epoch: 371  Training loss = 1.8783  Validation loss = 1.1969  \n",
      "\n",
      "Fold: 7  Epoch: 372  Training loss = 1.8782  Validation loss = 1.1967  \n",
      "\n",
      "Fold: 7  Epoch: 373  Training loss = 1.8781  Validation loss = 1.1964  \n",
      "\n",
      "Fold: 7  Epoch: 374  Training loss = 1.8780  Validation loss = 1.1961  \n",
      "\n",
      "Fold: 7  Epoch: 375  Training loss = 1.8778  Validation loss = 1.1951  \n",
      "\n",
      "Fold: 7  Epoch: 376  Training loss = 1.8778  Validation loss = 1.1947  \n",
      "\n",
      "Fold: 7  Epoch: 377  Training loss = 1.8776  Validation loss = 1.1939  \n",
      "\n",
      "Fold: 7  Epoch: 378  Training loss = 1.8775  Validation loss = 1.1933  \n",
      "\n",
      "Fold: 7  Epoch: 379  Training loss = 1.8773  Validation loss = 1.1926  \n",
      "\n",
      "Fold: 7  Epoch: 380  Training loss = 1.8772  Validation loss = 1.1924  \n",
      "\n",
      "Fold: 7  Epoch: 381  Training loss = 1.8770  Validation loss = 1.1914  \n",
      "\n",
      "Fold: 7  Epoch: 382  Training loss = 1.8769  Validation loss = 1.1906  \n",
      "\n",
      "Fold: 7  Epoch: 383  Training loss = 1.8768  Validation loss = 1.1901  \n",
      "\n",
      "Fold: 7  Epoch: 384  Training loss = 1.8767  Validation loss = 1.1898  \n",
      "\n",
      "Fold: 7  Epoch: 385  Training loss = 1.8766  Validation loss = 1.1899  \n",
      "\n",
      "Fold: 7  Epoch: 386  Training loss = 1.8765  Validation loss = 1.1890  \n",
      "\n",
      "Fold: 7  Epoch: 387  Training loss = 1.8764  Validation loss = 1.1890  \n",
      "\n",
      "Fold: 7  Epoch: 388  Training loss = 1.8763  Validation loss = 1.1883  \n",
      "\n",
      "Fold: 7  Epoch: 389  Training loss = 1.8762  Validation loss = 1.1878  \n",
      "\n",
      "Fold: 7  Epoch: 390  Training loss = 1.8761  Validation loss = 1.1878  \n",
      "\n",
      "Fold: 7  Epoch: 391  Training loss = 1.8760  Validation loss = 1.1876  \n",
      "\n",
      "Fold: 7  Epoch: 392  Training loss = 1.8759  Validation loss = 1.1873  \n",
      "\n",
      "Fold: 7  Epoch: 393  Training loss = 1.8758  Validation loss = 1.1870  \n",
      "\n",
      "Fold: 7  Epoch: 394  Training loss = 1.8757  Validation loss = 1.1862  \n",
      "\n",
      "Fold: 7  Epoch: 395  Training loss = 1.8756  Validation loss = 1.1856  \n",
      "\n",
      "Fold: 7  Epoch: 396  Training loss = 1.8755  Validation loss = 1.1853  \n",
      "\n",
      "Fold: 7  Epoch: 397  Training loss = 1.8754  Validation loss = 1.1851  \n",
      "\n",
      "Fold: 7  Epoch: 398  Training loss = 1.8753  Validation loss = 1.1853  \n",
      "\n",
      "Fold: 7  Epoch: 399  Training loss = 1.8753  Validation loss = 1.1854  \n",
      "\n",
      "Fold: 7  Epoch: 400  Training loss = 1.8752  Validation loss = 1.1851  \n",
      "\n",
      "Fold: 7  Epoch: 401  Training loss = 1.8750  Validation loss = 1.1844  \n",
      "\n",
      "Fold: 7  Epoch: 402  Training loss = 1.8749  Validation loss = 1.1837  \n",
      "\n",
      "Fold: 7  Epoch: 403  Training loss = 1.8748  Validation loss = 1.1831  \n",
      "\n",
      "Fold: 7  Epoch: 404  Training loss = 1.8746  Validation loss = 1.1822  \n",
      "\n",
      "Fold: 7  Epoch: 405  Training loss = 1.8744  Validation loss = 1.1807  \n",
      "\n",
      "Fold: 7  Epoch: 406  Training loss = 1.8742  Validation loss = 1.1801  \n",
      "\n",
      "Fold: 7  Epoch: 407  Training loss = 1.8740  Validation loss = 1.1786  \n",
      "\n",
      "Fold: 7  Epoch: 408  Training loss = 1.8739  Validation loss = 1.1781  \n",
      "\n",
      "Fold: 7  Epoch: 409  Training loss = 1.8738  Validation loss = 1.1779  \n",
      "\n",
      "Fold: 7  Epoch: 410  Training loss = 1.8737  Validation loss = 1.1773  \n",
      "\n",
      "Fold: 7  Epoch: 411  Training loss = 1.8736  Validation loss = 1.1768  \n",
      "\n",
      "Fold: 7  Epoch: 412  Training loss = 1.8734  Validation loss = 1.1760  \n",
      "\n",
      "Fold: 7  Epoch: 413  Training loss = 1.8733  Validation loss = 1.1753  \n",
      "\n",
      "Fold: 7  Epoch: 414  Training loss = 1.8732  Validation loss = 1.1746  \n",
      "\n",
      "Fold: 7  Epoch: 415  Training loss = 1.8731  Validation loss = 1.1744  \n",
      "\n",
      "Fold: 7  Epoch: 416  Training loss = 1.8729  Validation loss = 1.1735  \n",
      "\n",
      "Fold: 7  Epoch: 417  Training loss = 1.8728  Validation loss = 1.1730  \n",
      "\n",
      "Fold: 7  Epoch: 418  Training loss = 1.8727  Validation loss = 1.1726  \n",
      "\n",
      "Fold: 7  Epoch: 419  Training loss = 1.8725  Validation loss = 1.1719  \n",
      "\n",
      "Fold: 7  Epoch: 420  Training loss = 1.8724  Validation loss = 1.1714  \n",
      "\n",
      "Fold: 7  Epoch: 421  Training loss = 1.8723  Validation loss = 1.1708  \n",
      "\n",
      "Fold: 7  Epoch: 422  Training loss = 1.8722  Validation loss = 1.1702  \n",
      "\n",
      "Fold: 7  Epoch: 423  Training loss = 1.8721  Validation loss = 1.1700  \n",
      "\n",
      "Fold: 7  Epoch: 424  Training loss = 1.8719  Validation loss = 1.1690  \n",
      "\n",
      "Fold: 7  Epoch: 425  Training loss = 1.8718  Validation loss = 1.1679  \n",
      "\n",
      "Fold: 7  Epoch: 426  Training loss = 1.8717  Validation loss = 1.1677  \n",
      "\n",
      "Fold: 7  Epoch: 427  Training loss = 1.8716  Validation loss = 1.1672  \n",
      "\n",
      "Fold: 7  Epoch: 428  Training loss = 1.8714  Validation loss = 1.1666  \n",
      "\n",
      "Fold: 7  Epoch: 429  Training loss = 1.8714  Validation loss = 1.1668  \n",
      "\n",
      "Fold: 7  Epoch: 430  Training loss = 1.8714  Validation loss = 1.1670  \n",
      "\n",
      "Fold: 7  Epoch: 431  Training loss = 1.8713  Validation loss = 1.1669  \n",
      "\n",
      "Fold: 7  Epoch: 432  Training loss = 1.8712  Validation loss = 1.1666  \n",
      "\n",
      "Fold: 7  Epoch: 433  Training loss = 1.8711  Validation loss = 1.1664  \n",
      "\n",
      "Fold: 7  Epoch: 434  Training loss = 1.8709  Validation loss = 1.1653  \n",
      "\n",
      "Fold: 7  Epoch: 435  Training loss = 1.8708  Validation loss = 1.1650  \n",
      "\n",
      "Fold: 7  Epoch: 436  Training loss = 1.8707  Validation loss = 1.1646  \n",
      "\n",
      "Fold: 7  Epoch: 437  Training loss = 1.8705  Validation loss = 1.1640  \n",
      "\n",
      "Fold: 7  Epoch: 438  Training loss = 1.8704  Validation loss = 1.1633  \n",
      "\n",
      "Fold: 7  Epoch: 439  Training loss = 1.8703  Validation loss = 1.1629  \n",
      "\n",
      "Fold: 7  Epoch: 440  Training loss = 1.8703  Validation loss = 1.1629  \n",
      "\n",
      "Fold: 7  Epoch: 441  Training loss = 1.8701  Validation loss = 1.1622  \n",
      "\n",
      "Fold: 7  Epoch: 442  Training loss = 1.8699  Validation loss = 1.1609  \n",
      "\n",
      "Fold: 7  Epoch: 443  Training loss = 1.8698  Validation loss = 1.1607  \n",
      "\n",
      "Fold: 7  Epoch: 444  Training loss = 1.8697  Validation loss = 1.1604  \n",
      "\n",
      "Fold: 7  Epoch: 445  Training loss = 1.8696  Validation loss = 1.1597  \n",
      "\n",
      "Fold: 7  Epoch: 446  Training loss = 1.8694  Validation loss = 1.1583  \n",
      "\n",
      "Fold: 7  Epoch: 447  Training loss = 1.8692  Validation loss = 1.1576  \n",
      "\n",
      "Fold: 7  Epoch: 448  Training loss = 1.8692  Validation loss = 1.1574  \n",
      "\n",
      "Fold: 7  Epoch: 449  Training loss = 1.8690  Validation loss = 1.1568  \n",
      "\n",
      "Fold: 7  Epoch: 450  Training loss = 1.8689  Validation loss = 1.1562  \n",
      "\n",
      "Fold: 7  Epoch: 451  Training loss = 1.8689  Validation loss = 1.1563  \n",
      "\n",
      "Fold: 7  Epoch: 452  Training loss = 1.8687  Validation loss = 1.1553  \n",
      "\n",
      "Fold: 7  Epoch: 453  Training loss = 1.8685  Validation loss = 1.1542  \n",
      "\n",
      "Fold: 7  Epoch: 454  Training loss = 1.8684  Validation loss = 1.1537  \n",
      "\n",
      "Fold: 7  Epoch: 455  Training loss = 1.8683  Validation loss = 1.1530  \n",
      "\n",
      "Fold: 7  Epoch: 456  Training loss = 1.8681  Validation loss = 1.1527  \n",
      "\n",
      "Fold: 7  Epoch: 457  Training loss = 1.8681  Validation loss = 1.1527  \n",
      "\n",
      "Fold: 7  Epoch: 458  Training loss = 1.8679  Validation loss = 1.1519  \n",
      "\n",
      "Fold: 7  Epoch: 459  Training loss = 1.8678  Validation loss = 1.1510  \n",
      "\n",
      "Fold: 7  Epoch: 460  Training loss = 1.8677  Validation loss = 1.1505  \n",
      "\n",
      "Fold: 7  Epoch: 461  Training loss = 1.8675  Validation loss = 1.1500  \n",
      "\n",
      "Fold: 7  Epoch: 462  Training loss = 1.8675  Validation loss = 1.1502  \n",
      "\n",
      "Fold: 7  Epoch: 463  Training loss = 1.8673  Validation loss = 1.1493  \n",
      "\n",
      "Fold: 7  Epoch: 464  Training loss = 1.8673  Validation loss = 1.1496  \n",
      "\n",
      "Fold: 7  Epoch: 465  Training loss = 1.8671  Validation loss = 1.1486  \n",
      "\n",
      "Fold: 7  Epoch: 466  Training loss = 1.8670  Validation loss = 1.1486  \n",
      "\n",
      "Fold: 7  Epoch: 467  Training loss = 1.8670  Validation loss = 1.1488  \n",
      "\n",
      "Fold: 7  Epoch: 468  Training loss = 1.8669  Validation loss = 1.1483  \n",
      "\n",
      "Fold: 7  Epoch: 469  Training loss = 1.8667  Validation loss = 1.1476  \n",
      "\n",
      "Fold: 7  Epoch: 470  Training loss = 1.8666  Validation loss = 1.1466  \n",
      "\n",
      "Fold: 7  Epoch: 471  Training loss = 1.8664  Validation loss = 1.1456  \n",
      "\n",
      "Fold: 7  Epoch: 472  Training loss = 1.8662  Validation loss = 1.1445  \n",
      "\n",
      "Fold: 7  Epoch: 473  Training loss = 1.8662  Validation loss = 1.1447  \n",
      "\n",
      "Fold: 7  Epoch: 474  Training loss = 1.8660  Validation loss = 1.1437  \n",
      "\n",
      "Fold: 7  Epoch: 475  Training loss = 1.8658  Validation loss = 1.1428  \n",
      "\n",
      "Fold: 7  Epoch: 476  Training loss = 1.8658  Validation loss = 1.1431  \n",
      "\n",
      "Fold: 7  Epoch: 477  Training loss = 1.8657  Validation loss = 1.1423  \n",
      "\n",
      "Fold: 7  Epoch: 478  Training loss = 1.8655  Validation loss = 1.1418  \n",
      "\n",
      "Fold: 7  Epoch: 479  Training loss = 1.8654  Validation loss = 1.1417  \n",
      "\n",
      "Fold: 7  Epoch: 480  Training loss = 1.8653  Validation loss = 1.1405  \n",
      "\n",
      "Fold: 7  Epoch: 481  Training loss = 1.8652  Validation loss = 1.1403  \n",
      "\n",
      "Fold: 7  Epoch: 482  Training loss = 1.8650  Validation loss = 1.1392  \n",
      "\n",
      "Fold: 7  Epoch: 483  Training loss = 1.8649  Validation loss = 1.1385  \n",
      "\n",
      "Fold: 7  Epoch: 484  Training loss = 1.8648  Validation loss = 1.1380  \n",
      "\n",
      "Fold: 7  Epoch: 485  Training loss = 1.8647  Validation loss = 1.1370  \n",
      "\n",
      "Fold: 7  Epoch: 486  Training loss = 1.8645  Validation loss = 1.1362  \n",
      "\n",
      "Fold: 7  Epoch: 487  Training loss = 1.8644  Validation loss = 1.1360  \n",
      "\n",
      "Fold: 7  Epoch: 488  Training loss = 1.8643  Validation loss = 1.1357  \n",
      "\n",
      "Fold: 7  Epoch: 489  Training loss = 1.8642  Validation loss = 1.1348  \n",
      "\n",
      "Fold: 7  Epoch: 490  Training loss = 1.8641  Validation loss = 1.1345  \n",
      "\n",
      "Fold: 7  Epoch: 491  Training loss = 1.8639  Validation loss = 1.1337  \n",
      "\n",
      "Fold: 7  Epoch: 492  Training loss = 1.8637  Validation loss = 1.1329  \n",
      "\n",
      "Fold: 7  Epoch: 493  Training loss = 1.8636  Validation loss = 1.1320  \n",
      "\n",
      "Fold: 7  Epoch: 494  Training loss = 1.8634  Validation loss = 1.1308  \n",
      "\n",
      "Fold: 7  Epoch: 495  Training loss = 1.8632  Validation loss = 1.1298  \n",
      "\n",
      "Fold: 7  Epoch: 496  Training loss = 1.8631  Validation loss = 1.1291  \n",
      "\n",
      "Fold: 7  Epoch: 497  Training loss = 1.8630  Validation loss = 1.1282  \n",
      "\n",
      "Fold: 7  Epoch: 498  Training loss = 1.8628  Validation loss = 1.1280  \n",
      "\n",
      "Fold: 7  Epoch: 499  Training loss = 1.8628  Validation loss = 1.1280  \n",
      "\n",
      "Fold: 7  Epoch: 500  Training loss = 1.8626  Validation loss = 1.1272  \n",
      "\n",
      "Check model:  Fold: 7  Optimal epoch: 500  \n",
      "\n",
      "Fold: 8  Epoch: 1  Training loss = 1.8300  Validation loss = 5.8853  \n",
      "\n",
      "Fold: 8  Epoch: 2  Training loss = 1.8298  Validation loss = 5.8849  \n",
      "\n",
      "Fold: 8  Epoch: 3  Training loss = 1.8296  Validation loss = 5.8843  \n",
      "\n",
      "Fold: 8  Epoch: 4  Training loss = 1.8296  Validation loss = 5.8850  \n",
      "\n",
      "Fold: 8  Epoch: 5  Training loss = 1.8295  Validation loss = 5.8847  \n",
      "\n",
      "Fold: 8  Epoch: 6  Training loss = 1.8292  Validation loss = 5.8836  \n",
      "\n",
      "Fold: 8  Epoch: 7  Training loss = 1.8291  Validation loss = 5.8836  \n",
      "\n",
      "Fold: 8  Epoch: 8  Training loss = 1.8290  Validation loss = 5.8837  \n",
      "\n",
      "Fold: 8  Epoch: 9  Training loss = 1.8288  Validation loss = 5.8832  \n",
      "\n",
      "Fold: 8  Epoch: 10  Training loss = 1.8288  Validation loss = 5.8839  \n",
      "\n",
      "Fold: 8  Epoch: 11  Training loss = 1.8287  Validation loss = 5.8844  \n",
      "\n",
      "Fold: 8  Epoch: 12  Training loss = 1.8286  Validation loss = 5.8840  \n",
      "\n",
      "Fold: 8  Epoch: 13  Training loss = 1.8285  Validation loss = 5.8837  \n",
      "\n",
      "Fold: 8  Epoch: 14  Training loss = 1.8283  Validation loss = 5.8836  \n",
      "\n",
      "Fold: 8  Epoch: 15  Training loss = 1.8281  Validation loss = 5.8830  \n",
      "\n",
      "Fold: 8  Epoch: 16  Training loss = 1.8280  Validation loss = 5.8826  \n",
      "\n",
      "Fold: 8  Epoch: 17  Training loss = 1.8278  Validation loss = 5.8824  \n",
      "\n",
      "Fold: 8  Epoch: 18  Training loss = 1.8276  Validation loss = 5.8823  \n",
      "\n",
      "Fold: 8  Epoch: 19  Training loss = 1.8275  Validation loss = 5.8823  \n",
      "\n",
      "Fold: 8  Epoch: 20  Training loss = 1.8273  Validation loss = 5.8814  \n",
      "\n",
      "Fold: 8  Epoch: 21  Training loss = 1.8272  Validation loss = 5.8813  \n",
      "\n",
      "Fold: 8  Epoch: 22  Training loss = 1.8270  Validation loss = 5.8808  \n",
      "\n",
      "Fold: 8  Epoch: 23  Training loss = 1.8269  Validation loss = 5.8805  \n",
      "\n",
      "Fold: 8  Epoch: 24  Training loss = 1.8267  Validation loss = 5.8799  \n",
      "\n",
      "Fold: 8  Epoch: 25  Training loss = 1.8266  Validation loss = 5.8798  \n",
      "\n",
      "Fold: 8  Epoch: 26  Training loss = 1.8264  Validation loss = 5.8792  \n",
      "\n",
      "Fold: 8  Epoch: 27  Training loss = 1.8263  Validation loss = 5.8792  \n",
      "\n",
      "Fold: 8  Epoch: 28  Training loss = 1.8261  Validation loss = 5.8785  \n",
      "\n",
      "Fold: 8  Epoch: 29  Training loss = 1.8259  Validation loss = 5.8780  \n",
      "\n",
      "Fold: 8  Epoch: 30  Training loss = 1.8258  Validation loss = 5.8773  \n",
      "\n",
      "Fold: 8  Epoch: 31  Training loss = 1.8258  Validation loss = 5.8776  \n",
      "\n",
      "Fold: 8  Epoch: 32  Training loss = 1.8256  Validation loss = 5.8770  \n",
      "\n",
      "Fold: 8  Epoch: 33  Training loss = 1.8253  Validation loss = 5.8758  \n",
      "\n",
      "Fold: 8  Epoch: 34  Training loss = 1.8251  Validation loss = 5.8755  \n",
      "\n",
      "Fold: 8  Epoch: 35  Training loss = 1.8249  Validation loss = 5.8742  \n",
      "\n",
      "Fold: 8  Epoch: 36  Training loss = 1.8246  Validation loss = 5.8733  \n",
      "\n",
      "Fold: 8  Epoch: 37  Training loss = 1.8246  Validation loss = 5.8736  \n",
      "\n",
      "Fold: 8  Epoch: 38  Training loss = 1.8245  Validation loss = 5.8739  \n",
      "\n",
      "Fold: 8  Epoch: 39  Training loss = 1.8244  Validation loss = 5.8740  \n",
      "\n",
      "Fold: 8  Epoch: 40  Training loss = 1.8243  Validation loss = 5.8741  \n",
      "\n",
      "Fold: 8  Epoch: 41  Training loss = 1.8241  Validation loss = 5.8732  \n",
      "\n",
      "Fold: 8  Epoch: 42  Training loss = 1.8239  Validation loss = 5.8726  \n",
      "\n",
      "Fold: 8  Epoch: 43  Training loss = 1.8238  Validation loss = 5.8726  \n",
      "\n",
      "Fold: 8  Epoch: 44  Training loss = 1.8237  Validation loss = 5.8729  \n",
      "\n",
      "Fold: 8  Epoch: 45  Training loss = 1.8235  Validation loss = 5.8722  \n",
      "\n",
      "Fold: 8  Epoch: 46  Training loss = 1.8234  Validation loss = 5.8717  \n",
      "\n",
      "Fold: 8  Epoch: 47  Training loss = 1.8232  Validation loss = 5.8716  \n",
      "\n",
      "Fold: 8  Epoch: 48  Training loss = 1.8230  Validation loss = 5.8713  \n",
      "\n",
      "Fold: 8  Epoch: 49  Training loss = 1.8229  Validation loss = 5.8709  \n",
      "\n",
      "Fold: 8  Epoch: 50  Training loss = 1.8228  Validation loss = 5.8711  \n",
      "\n",
      "Fold: 8  Epoch: 51  Training loss = 1.8226  Validation loss = 5.8707  \n",
      "\n",
      "Fold: 8  Epoch: 52  Training loss = 1.8223  Validation loss = 5.8695  \n",
      "\n",
      "Fold: 8  Epoch: 53  Training loss = 1.8223  Validation loss = 5.8696  \n",
      "\n",
      "Fold: 8  Epoch: 54  Training loss = 1.8222  Validation loss = 5.8695  \n",
      "\n",
      "Fold: 8  Epoch: 55  Training loss = 1.8221  Validation loss = 5.8695  \n",
      "\n",
      "Fold: 8  Epoch: 56  Training loss = 1.8219  Validation loss = 5.8693  \n",
      "\n",
      "Fold: 8  Epoch: 57  Training loss = 1.8218  Validation loss = 5.8690  \n",
      "\n",
      "Fold: 8  Epoch: 58  Training loss = 1.8216  Validation loss = 5.8687  \n",
      "\n",
      "Fold: 8  Epoch: 59  Training loss = 1.8214  Validation loss = 5.8679  \n",
      "\n",
      "Fold: 8  Epoch: 60  Training loss = 1.8213  Validation loss = 5.8682  \n",
      "\n",
      "Fold: 8  Epoch: 61  Training loss = 1.8211  Validation loss = 5.8676  \n",
      "\n",
      "Fold: 8  Epoch: 62  Training loss = 1.8209  Validation loss = 5.8665  \n",
      "\n",
      "Fold: 8  Epoch: 63  Training loss = 1.8207  Validation loss = 5.8662  \n",
      "\n",
      "Fold: 8  Epoch: 64  Training loss = 1.8206  Validation loss = 5.8660  \n",
      "\n",
      "Fold: 8  Epoch: 65  Training loss = 1.8204  Validation loss = 5.8658  \n",
      "\n",
      "Fold: 8  Epoch: 66  Training loss = 1.8202  Validation loss = 5.8645  \n",
      "\n",
      "Fold: 8  Epoch: 67  Training loss = 1.8201  Validation loss = 5.8644  \n",
      "\n",
      "Fold: 8  Epoch: 68  Training loss = 1.8200  Validation loss = 5.8638  \n",
      "\n",
      "Fold: 8  Epoch: 69  Training loss = 1.8198  Validation loss = 5.8635  \n",
      "\n",
      "Fold: 8  Epoch: 70  Training loss = 1.8196  Validation loss = 5.8629  \n",
      "\n",
      "Fold: 8  Epoch: 71  Training loss = 1.8195  Validation loss = 5.8626  \n",
      "\n",
      "Fold: 8  Epoch: 72  Training loss = 1.8194  Validation loss = 5.8634  \n",
      "\n",
      "Fold: 8  Epoch: 73  Training loss = 1.8194  Validation loss = 5.8637  \n",
      "\n",
      "Fold: 8  Epoch: 74  Training loss = 1.8192  Validation loss = 5.8629  \n",
      "\n",
      "Fold: 8  Epoch: 75  Training loss = 1.8190  Validation loss = 5.8627  \n",
      "\n",
      "Fold: 8  Epoch: 76  Training loss = 1.8188  Validation loss = 5.8617  \n",
      "\n",
      "Fold: 8  Epoch: 77  Training loss = 1.8187  Validation loss = 5.8619  \n",
      "\n",
      "Fold: 8  Epoch: 78  Training loss = 1.8186  Validation loss = 5.8626  \n",
      "\n",
      "Fold: 8  Epoch: 79  Training loss = 1.8184  Validation loss = 5.8618  \n",
      "\n",
      "Fold: 8  Epoch: 80  Training loss = 1.8184  Validation loss = 5.8618  \n",
      "\n",
      "Fold: 8  Epoch: 81  Training loss = 1.8182  Validation loss = 5.8616  \n",
      "\n",
      "Fold: 8  Epoch: 82  Training loss = 1.8181  Validation loss = 5.8619  \n",
      "\n",
      "Fold: 8  Epoch: 83  Training loss = 1.8180  Validation loss = 5.8616  \n",
      "\n",
      "Fold: 8  Epoch: 84  Training loss = 1.8178  Validation loss = 5.8615  \n",
      "\n",
      "Fold: 8  Epoch: 85  Training loss = 1.8176  Validation loss = 5.8606  \n",
      "\n",
      "Fold: 8  Epoch: 86  Training loss = 1.8174  Validation loss = 5.8598  \n",
      "\n",
      "Fold: 8  Epoch: 87  Training loss = 1.8173  Validation loss = 5.8596  \n",
      "\n",
      "Fold: 8  Epoch: 88  Training loss = 1.8172  Validation loss = 5.8594  \n",
      "\n",
      "Fold: 8  Epoch: 89  Training loss = 1.8171  Validation loss = 5.8595  \n",
      "\n",
      "Fold: 8  Epoch: 90  Training loss = 1.8169  Validation loss = 5.8591  \n",
      "\n",
      "Fold: 8  Epoch: 91  Training loss = 1.8168  Validation loss = 5.8587  \n",
      "\n",
      "Fold: 8  Epoch: 92  Training loss = 1.8167  Validation loss = 5.8588  \n",
      "\n",
      "Fold: 8  Epoch: 93  Training loss = 1.8167  Validation loss = 5.8595  \n",
      "\n",
      "Fold: 8  Epoch: 94  Training loss = 1.8165  Validation loss = 5.8594  \n",
      "\n",
      "Fold: 8  Epoch: 95  Training loss = 1.8165  Validation loss = 5.8595  \n",
      "\n",
      "Fold: 8  Epoch: 96  Training loss = 1.8162  Validation loss = 5.8586  \n",
      "\n",
      "Fold: 8  Epoch: 97  Training loss = 1.8160  Validation loss = 5.8577  \n",
      "\n",
      "Fold: 8  Epoch: 98  Training loss = 1.8159  Validation loss = 5.8573  \n",
      "\n",
      "Fold: 8  Epoch: 99  Training loss = 1.8158  Validation loss = 5.8572  \n",
      "\n",
      "Fold: 8  Epoch: 100  Training loss = 1.8157  Validation loss = 5.8566  \n",
      "\n",
      "Fold: 8  Epoch: 101  Training loss = 1.8155  Validation loss = 5.8566  \n",
      "\n",
      "Fold: 8  Epoch: 102  Training loss = 1.8153  Validation loss = 5.8561  \n",
      "\n",
      "Fold: 8  Epoch: 103  Training loss = 1.8152  Validation loss = 5.8557  \n",
      "\n",
      "Fold: 8  Epoch: 104  Training loss = 1.8151  Validation loss = 5.8560  \n",
      "\n",
      "Fold: 8  Epoch: 105  Training loss = 1.8149  Validation loss = 5.8551  \n",
      "\n",
      "Fold: 8  Epoch: 106  Training loss = 1.8147  Validation loss = 5.8551  \n",
      "\n",
      "Fold: 8  Epoch: 107  Training loss = 1.8146  Validation loss = 5.8546  \n",
      "\n",
      "Fold: 8  Epoch: 108  Training loss = 1.8145  Validation loss = 5.8551  \n",
      "\n",
      "Fold: 8  Epoch: 109  Training loss = 1.8144  Validation loss = 5.8547  \n",
      "\n",
      "Fold: 8  Epoch: 110  Training loss = 1.8144  Validation loss = 5.8556  \n",
      "\n",
      "Fold: 8  Epoch: 111  Training loss = 1.8143  Validation loss = 5.8553  \n",
      "\n",
      "Fold: 8  Epoch: 112  Training loss = 1.8141  Validation loss = 5.8552  \n",
      "\n",
      "Fold: 8  Epoch: 113  Training loss = 1.8140  Validation loss = 5.8552  \n",
      "\n",
      "Fold: 8  Epoch: 114  Training loss = 1.8140  Validation loss = 5.8557  \n",
      "\n",
      "Check model:  Fold: 8  Optimal epoch: 107  \n",
      "\n",
      "Fold: 9  Epoch: 1  Training loss = 2.3057  Validation loss = 9.4147  \n",
      "\n",
      "Fold: 9  Epoch: 2  Training loss = 2.3057  Validation loss = 9.4151  \n",
      "\n",
      "Fold: 9  Epoch: 3  Training loss = 2.3054  Validation loss = 9.4141  \n",
      "\n",
      "Fold: 9  Epoch: 4  Training loss = 2.3052  Validation loss = 9.4131  \n",
      "\n",
      "Fold: 9  Epoch: 5  Training loss = 2.3051  Validation loss = 9.4131  \n",
      "\n",
      "Fold: 9  Epoch: 6  Training loss = 2.3048  Validation loss = 9.4118  \n",
      "\n",
      "Fold: 9  Epoch: 7  Training loss = 2.3045  Validation loss = 9.4109  \n",
      "\n",
      "Fold: 9  Epoch: 8  Training loss = 2.3044  Validation loss = 9.4106  \n",
      "\n",
      "Fold: 9  Epoch: 9  Training loss = 2.3041  Validation loss = 9.4094  \n",
      "\n",
      "Fold: 9  Epoch: 10  Training loss = 2.3037  Validation loss = 9.4077  \n",
      "\n",
      "Fold: 9  Epoch: 11  Training loss = 2.3035  Validation loss = 9.4067  \n",
      "\n",
      "Fold: 9  Epoch: 12  Training loss = 2.3030  Validation loss = 9.4043  \n",
      "\n",
      "Fold: 9  Epoch: 13  Training loss = 2.3027  Validation loss = 9.4034  \n",
      "\n",
      "Fold: 9  Epoch: 14  Training loss = 2.3024  Validation loss = 9.4024  \n",
      "\n",
      "Fold: 9  Epoch: 15  Training loss = 2.3022  Validation loss = 9.4017  \n",
      "\n",
      "Fold: 9  Epoch: 16  Training loss = 2.3020  Validation loss = 9.4009  \n",
      "\n",
      "Fold: 9  Epoch: 17  Training loss = 2.3017  Validation loss = 9.3998  \n",
      "\n",
      "Fold: 9  Epoch: 18  Training loss = 2.3015  Validation loss = 9.3988  \n",
      "\n",
      "Fold: 9  Epoch: 19  Training loss = 2.3011  Validation loss = 9.3970  \n",
      "\n",
      "Fold: 9  Epoch: 20  Training loss = 2.3006  Validation loss = 9.3949  \n",
      "\n",
      "Fold: 9  Epoch: 21  Training loss = 2.3003  Validation loss = 9.3938  \n",
      "\n",
      "Fold: 9  Epoch: 22  Training loss = 2.2999  Validation loss = 9.3923  \n",
      "\n",
      "Fold: 9  Epoch: 23  Training loss = 2.2996  Validation loss = 9.3910  \n",
      "\n",
      "Fold: 9  Epoch: 24  Training loss = 2.2992  Validation loss = 9.3894  \n",
      "\n",
      "Fold: 9  Epoch: 25  Training loss = 2.2989  Validation loss = 9.3879  \n",
      "\n",
      "Fold: 9  Epoch: 26  Training loss = 2.2985  Validation loss = 9.3865  \n",
      "\n",
      "Fold: 9  Epoch: 27  Training loss = 2.2982  Validation loss = 9.3852  \n",
      "\n",
      "Fold: 9  Epoch: 28  Training loss = 2.2982  Validation loss = 9.3852  \n",
      "\n",
      "Fold: 9  Epoch: 29  Training loss = 2.2977  Validation loss = 9.3833  \n",
      "\n",
      "Fold: 9  Epoch: 30  Training loss = 2.2973  Validation loss = 9.3813  \n",
      "\n",
      "Fold: 9  Epoch: 31  Training loss = 2.2971  Validation loss = 9.3806  \n",
      "\n",
      "Fold: 9  Epoch: 32  Training loss = 2.2969  Validation loss = 9.3798  \n",
      "\n",
      "Fold: 9  Epoch: 33  Training loss = 2.2966  Validation loss = 9.3787  \n",
      "\n",
      "Fold: 9  Epoch: 34  Training loss = 2.2963  Validation loss = 9.3773  \n",
      "\n",
      "Fold: 9  Epoch: 35  Training loss = 2.2962  Validation loss = 9.3772  \n",
      "\n",
      "Fold: 9  Epoch: 36  Training loss = 2.2959  Validation loss = 9.3757  \n",
      "\n",
      "Fold: 9  Epoch: 37  Training loss = 2.2956  Validation loss = 9.3747  \n",
      "\n",
      "Fold: 9  Epoch: 38  Training loss = 2.2954  Validation loss = 9.3736  \n",
      "\n",
      "Fold: 9  Epoch: 39  Training loss = 2.2951  Validation loss = 9.3725  \n",
      "\n",
      "Fold: 9  Epoch: 40  Training loss = 2.2947  Validation loss = 9.3712  \n",
      "\n",
      "Fold: 9  Epoch: 41  Training loss = 2.2946  Validation loss = 9.3708  \n",
      "\n",
      "Fold: 9  Epoch: 42  Training loss = 2.2943  Validation loss = 9.3693  \n",
      "\n",
      "Fold: 9  Epoch: 43  Training loss = 2.2941  Validation loss = 9.3683  \n",
      "\n",
      "Fold: 9  Epoch: 44  Training loss = 2.2938  Validation loss = 9.3673  \n",
      "\n",
      "Fold: 9  Epoch: 45  Training loss = 2.2935  Validation loss = 9.3658  \n",
      "\n",
      "Fold: 9  Epoch: 46  Training loss = 2.2933  Validation loss = 9.3651  \n",
      "\n",
      "Fold: 9  Epoch: 47  Training loss = 2.2929  Validation loss = 9.3638  \n",
      "\n",
      "Fold: 9  Epoch: 48  Training loss = 2.2927  Validation loss = 9.3632  \n",
      "\n",
      "Fold: 9  Epoch: 49  Training loss = 2.2926  Validation loss = 9.3632  \n",
      "\n",
      "Fold: 9  Epoch: 50  Training loss = 2.2924  Validation loss = 9.3624  \n",
      "\n",
      "Fold: 9  Epoch: 51  Training loss = 2.2921  Validation loss = 9.3609  \n",
      "\n",
      "Fold: 9  Epoch: 52  Training loss = 2.2918  Validation loss = 9.3599  \n",
      "\n",
      "Fold: 9  Epoch: 53  Training loss = 2.2916  Validation loss = 9.3591  \n",
      "\n",
      "Fold: 9  Epoch: 54  Training loss = 2.2911  Validation loss = 9.3569  \n",
      "\n",
      "Fold: 9  Epoch: 55  Training loss = 2.2906  Validation loss = 9.3547  \n",
      "\n",
      "Fold: 9  Epoch: 56  Training loss = 2.2903  Validation loss = 9.3534  \n",
      "\n",
      "Fold: 9  Epoch: 57  Training loss = 2.2899  Validation loss = 9.3517  \n",
      "\n",
      "Fold: 9  Epoch: 58  Training loss = 2.2899  Validation loss = 9.3520  \n",
      "\n",
      "Fold: 9  Epoch: 59  Training loss = 2.2897  Validation loss = 9.3514  \n",
      "\n",
      "Fold: 9  Epoch: 60  Training loss = 2.2895  Validation loss = 9.3504  \n",
      "\n",
      "Fold: 9  Epoch: 61  Training loss = 2.2893  Validation loss = 9.3496  \n",
      "\n",
      "Fold: 9  Epoch: 62  Training loss = 2.2888  Validation loss = 9.3473  \n",
      "\n",
      "Fold: 9  Epoch: 63  Training loss = 2.2885  Validation loss = 9.3459  \n",
      "\n",
      "Fold: 9  Epoch: 64  Training loss = 2.2883  Validation loss = 9.3455  \n",
      "\n",
      "Fold: 9  Epoch: 65  Training loss = 2.2880  Validation loss = 9.3437  \n",
      "\n",
      "Fold: 9  Epoch: 66  Training loss = 2.2878  Validation loss = 9.3431  \n",
      "\n",
      "Fold: 9  Epoch: 67  Training loss = 2.2874  Validation loss = 9.3417  \n",
      "\n",
      "Fold: 9  Epoch: 68  Training loss = 2.2872  Validation loss = 9.3410  \n",
      "\n",
      "Fold: 9  Epoch: 69  Training loss = 2.2870  Validation loss = 9.3404  \n",
      "\n",
      "Fold: 9  Epoch: 70  Training loss = 2.2867  Validation loss = 9.3388  \n",
      "\n",
      "Fold: 9  Epoch: 71  Training loss = 2.2863  Validation loss = 9.3369  \n",
      "\n",
      "Fold: 9  Epoch: 72  Training loss = 2.2859  Validation loss = 9.3349  \n",
      "\n",
      "Fold: 9  Epoch: 73  Training loss = 2.2857  Validation loss = 9.3342  \n",
      "\n",
      "Fold: 9  Epoch: 74  Training loss = 2.2853  Validation loss = 9.3326  \n",
      "\n",
      "Fold: 9  Epoch: 75  Training loss = 2.2850  Validation loss = 9.3312  \n",
      "\n",
      "Fold: 9  Epoch: 76  Training loss = 2.2846  Validation loss = 9.3292  \n",
      "\n",
      "Fold: 9  Epoch: 77  Training loss = 2.2844  Validation loss = 9.3285  \n",
      "\n",
      "Fold: 9  Epoch: 78  Training loss = 2.2842  Validation loss = 9.3275  \n",
      "\n",
      "Fold: 9  Epoch: 79  Training loss = 2.2840  Validation loss = 9.3268  \n",
      "\n",
      "Fold: 9  Epoch: 80  Training loss = 2.2837  Validation loss = 9.3256  \n",
      "\n",
      "Fold: 9  Epoch: 81  Training loss = 2.2833  Validation loss = 9.3240  \n",
      "\n",
      "Fold: 9  Epoch: 82  Training loss = 2.2830  Validation loss = 9.3227  \n",
      "\n",
      "Fold: 9  Epoch: 83  Training loss = 2.2828  Validation loss = 9.3220  \n",
      "\n",
      "Fold: 9  Epoch: 84  Training loss = 2.2828  Validation loss = 9.3220  \n",
      "\n",
      "Fold: 9  Epoch: 85  Training loss = 2.2825  Validation loss = 9.3208  \n",
      "\n",
      "Fold: 9  Epoch: 86  Training loss = 2.2822  Validation loss = 9.3196  \n",
      "\n",
      "Fold: 9  Epoch: 87  Training loss = 2.2822  Validation loss = 9.3197  \n",
      "\n",
      "Fold: 9  Epoch: 88  Training loss = 2.2820  Validation loss = 9.3188  \n",
      "\n",
      "Fold: 9  Epoch: 89  Training loss = 2.2818  Validation loss = 9.3181  \n",
      "\n",
      "Fold: 9  Epoch: 90  Training loss = 2.2816  Validation loss = 9.3175  \n",
      "\n",
      "Fold: 9  Epoch: 91  Training loss = 2.2814  Validation loss = 9.3164  \n",
      "\n",
      "Fold: 9  Epoch: 92  Training loss = 2.2810  Validation loss = 9.3145  \n",
      "\n",
      "Fold: 9  Epoch: 93  Training loss = 2.2805  Validation loss = 9.3124  \n",
      "\n",
      "Fold: 9  Epoch: 94  Training loss = 2.2803  Validation loss = 9.3114  \n",
      "\n",
      "Fold: 9  Epoch: 95  Training loss = 2.2799  Validation loss = 9.3095  \n",
      "\n",
      "Fold: 9  Epoch: 96  Training loss = 2.2795  Validation loss = 9.3077  \n",
      "\n",
      "Fold: 9  Epoch: 97  Training loss = 2.2794  Validation loss = 9.3074  \n",
      "\n",
      "Fold: 9  Epoch: 98  Training loss = 2.2793  Validation loss = 9.3073  \n",
      "\n",
      "Fold: 9  Epoch: 99  Training loss = 2.2791  Validation loss = 9.3064  \n",
      "\n",
      "Fold: 9  Epoch: 100  Training loss = 2.2787  Validation loss = 9.3043  \n",
      "\n",
      "Fold: 9  Epoch: 101  Training loss = 2.2785  Validation loss = 9.3033  \n",
      "\n",
      "Fold: 9  Epoch: 102  Training loss = 2.2784  Validation loss = 9.3032  \n",
      "\n",
      "Fold: 9  Epoch: 103  Training loss = 2.2782  Validation loss = 9.3023  \n",
      "\n",
      "Fold: 9  Epoch: 104  Training loss = 2.2778  Validation loss = 9.3008  \n",
      "\n",
      "Fold: 9  Epoch: 105  Training loss = 2.2778  Validation loss = 9.3007  \n",
      "\n",
      "Fold: 9  Epoch: 106  Training loss = 2.2776  Validation loss = 9.3002  \n",
      "\n",
      "Fold: 9  Epoch: 107  Training loss = 2.2774  Validation loss = 9.2994  \n",
      "\n",
      "Fold: 9  Epoch: 108  Training loss = 2.2773  Validation loss = 9.2986  \n",
      "\n",
      "Fold: 9  Epoch: 109  Training loss = 2.2770  Validation loss = 9.2973  \n",
      "\n",
      "Fold: 9  Epoch: 110  Training loss = 2.2768  Validation loss = 9.2962  \n",
      "\n",
      "Fold: 9  Epoch: 111  Training loss = 2.2765  Validation loss = 9.2951  \n",
      "\n",
      "Fold: 9  Epoch: 112  Training loss = 2.2764  Validation loss = 9.2946  \n",
      "\n",
      "Fold: 9  Epoch: 113  Training loss = 2.2762  Validation loss = 9.2940  \n",
      "\n",
      "Fold: 9  Epoch: 114  Training loss = 2.2760  Validation loss = 9.2931  \n",
      "\n",
      "Fold: 9  Epoch: 115  Training loss = 2.2758  Validation loss = 9.2924  \n",
      "\n",
      "Fold: 9  Epoch: 116  Training loss = 2.2756  Validation loss = 9.2913  \n",
      "\n",
      "Fold: 9  Epoch: 117  Training loss = 2.2750  Validation loss = 9.2885  \n",
      "\n",
      "Fold: 9  Epoch: 118  Training loss = 2.2749  Validation loss = 9.2880  \n",
      "\n",
      "Fold: 9  Epoch: 119  Training loss = 2.2746  Validation loss = 9.2866  \n",
      "\n",
      "Fold: 9  Epoch: 120  Training loss = 2.2742  Validation loss = 9.2847  \n",
      "\n",
      "Fold: 9  Epoch: 121  Training loss = 2.2741  Validation loss = 9.2844  \n",
      "\n",
      "Fold: 9  Epoch: 122  Training loss = 2.2738  Validation loss = 9.2830  \n",
      "\n",
      "Fold: 9  Epoch: 123  Training loss = 2.2736  Validation loss = 9.2819  \n",
      "\n",
      "Fold: 9  Epoch: 124  Training loss = 2.2735  Validation loss = 9.2818  \n",
      "\n",
      "Fold: 9  Epoch: 125  Training loss = 2.2734  Validation loss = 9.2813  \n",
      "\n",
      "Fold: 9  Epoch: 126  Training loss = 2.2732  Validation loss = 9.2806  \n",
      "\n",
      "Fold: 9  Epoch: 127  Training loss = 2.2730  Validation loss = 9.2800  \n",
      "\n",
      "Fold: 9  Epoch: 128  Training loss = 2.2731  Validation loss = 9.2808  \n",
      "\n",
      "Fold: 9  Epoch: 129  Training loss = 2.2730  Validation loss = 9.2804  \n",
      "\n",
      "Fold: 9  Epoch: 130  Training loss = 2.2726  Validation loss = 9.2787  \n",
      "\n",
      "Fold: 9  Epoch: 131  Training loss = 2.2724  Validation loss = 9.2780  \n",
      "\n",
      "Fold: 9  Epoch: 132  Training loss = 2.2722  Validation loss = 9.2772  \n",
      "\n",
      "Fold: 9  Epoch: 133  Training loss = 2.2721  Validation loss = 9.2766  \n",
      "\n",
      "Fold: 9  Epoch: 134  Training loss = 2.2718  Validation loss = 9.2757  \n",
      "\n",
      "Fold: 9  Epoch: 135  Training loss = 2.2714  Validation loss = 9.2735  \n",
      "\n",
      "Fold: 9  Epoch: 136  Training loss = 2.2712  Validation loss = 9.2725  \n",
      "\n",
      "Fold: 9  Epoch: 137  Training loss = 2.2710  Validation loss = 9.2716  \n",
      "\n",
      "Fold: 9  Epoch: 138  Training loss = 2.2705  Validation loss = 9.2691  \n",
      "\n",
      "Fold: 9  Epoch: 139  Training loss = 2.2702  Validation loss = 9.2676  \n",
      "\n",
      "Fold: 9  Epoch: 140  Training loss = 2.2701  Validation loss = 9.2674  \n",
      "\n",
      "Fold: 9  Epoch: 141  Training loss = 2.2698  Validation loss = 9.2655  \n",
      "\n",
      "Fold: 9  Epoch: 142  Training loss = 2.2696  Validation loss = 9.2643  \n",
      "\n",
      "Fold: 9  Epoch: 143  Training loss = 2.2693  Validation loss = 9.2633  \n",
      "\n",
      "Fold: 9  Epoch: 144  Training loss = 2.2691  Validation loss = 9.2627  \n",
      "\n",
      "Fold: 9  Epoch: 145  Training loss = 2.2689  Validation loss = 9.2617  \n",
      "\n",
      "Fold: 9  Epoch: 146  Training loss = 2.2688  Validation loss = 9.2615  \n",
      "\n",
      "Fold: 9  Epoch: 147  Training loss = 2.2686  Validation loss = 9.2609  \n",
      "\n",
      "Fold: 9  Epoch: 148  Training loss = 2.2683  Validation loss = 9.2594  \n",
      "\n",
      "Fold: 9  Epoch: 149  Training loss = 2.2679  Validation loss = 9.2569  \n",
      "\n",
      "Fold: 9  Epoch: 150  Training loss = 2.2677  Validation loss = 9.2563  \n",
      "\n",
      "Fold: 9  Epoch: 151  Training loss = 2.2675  Validation loss = 9.2558  \n",
      "\n",
      "Fold: 9  Epoch: 152  Training loss = 2.2674  Validation loss = 9.2553  \n",
      "\n",
      "Fold: 9  Epoch: 153  Training loss = 2.2673  Validation loss = 9.2545  \n",
      "\n",
      "Fold: 9  Epoch: 154  Training loss = 2.2671  Validation loss = 9.2537  \n",
      "\n",
      "Fold: 9  Epoch: 155  Training loss = 2.2669  Validation loss = 9.2531  \n",
      "\n",
      "Fold: 9  Epoch: 156  Training loss = 2.2665  Validation loss = 9.2505  \n",
      "\n",
      "Fold: 9  Epoch: 157  Training loss = 2.2664  Validation loss = 9.2503  \n",
      "\n",
      "Fold: 9  Epoch: 158  Training loss = 2.2663  Validation loss = 9.2499  \n",
      "\n",
      "Fold: 9  Epoch: 159  Training loss = 2.2660  Validation loss = 9.2485  \n",
      "\n",
      "Fold: 9  Epoch: 160  Training loss = 2.2658  Validation loss = 9.2478  \n",
      "\n",
      "Fold: 9  Epoch: 161  Training loss = 2.2656  Validation loss = 9.2465  \n",
      "\n",
      "Fold: 9  Epoch: 162  Training loss = 2.2655  Validation loss = 9.2459  \n",
      "\n",
      "Fold: 9  Epoch: 163  Training loss = 2.2654  Validation loss = 9.2457  \n",
      "\n",
      "Fold: 9  Epoch: 164  Training loss = 2.2652  Validation loss = 9.2452  \n",
      "\n",
      "Fold: 9  Epoch: 165  Training loss = 2.2651  Validation loss = 9.2451  \n",
      "\n",
      "Fold: 9  Epoch: 166  Training loss = 2.2648  Validation loss = 9.2430  \n",
      "\n",
      "Fold: 9  Epoch: 167  Training loss = 2.2648  Validation loss = 9.2434  \n",
      "\n",
      "Fold: 9  Epoch: 168  Training loss = 2.2645  Validation loss = 9.2423  \n",
      "\n",
      "Fold: 9  Epoch: 169  Training loss = 2.2644  Validation loss = 9.2421  \n",
      "\n",
      "Fold: 9  Epoch: 170  Training loss = 2.2642  Validation loss = 9.2411  \n",
      "\n",
      "Fold: 9  Epoch: 171  Training loss = 2.2642  Validation loss = 9.2414  \n",
      "\n",
      "Fold: 9  Epoch: 172  Training loss = 2.2641  Validation loss = 9.2415  \n",
      "\n",
      "Fold: 9  Epoch: 173  Training loss = 2.2639  Validation loss = 9.2408  \n",
      "\n",
      "Fold: 9  Epoch: 174  Training loss = 2.2634  Validation loss = 9.2381  \n",
      "\n",
      "Fold: 9  Epoch: 175  Training loss = 2.2633  Validation loss = 9.2373  \n",
      "\n",
      "Fold: 9  Epoch: 176  Training loss = 2.2631  Validation loss = 9.2363  \n",
      "\n",
      "Fold: 9  Epoch: 177  Training loss = 2.2629  Validation loss = 9.2356  \n",
      "\n",
      "Fold: 9  Epoch: 178  Training loss = 2.2627  Validation loss = 9.2346  \n",
      "\n",
      "Fold: 9  Epoch: 179  Training loss = 2.2625  Validation loss = 9.2337  \n",
      "\n",
      "Fold: 9  Epoch: 180  Training loss = 2.2623  Validation loss = 9.2326  \n",
      "\n",
      "Fold: 9  Epoch: 181  Training loss = 2.2621  Validation loss = 9.2316  \n",
      "\n",
      "Fold: 9  Epoch: 182  Training loss = 2.2619  Validation loss = 9.2311  \n",
      "\n",
      "Fold: 9  Epoch: 183  Training loss = 2.2617  Validation loss = 9.2302  \n",
      "\n",
      "Fold: 9  Epoch: 184  Training loss = 2.2615  Validation loss = 9.2293  \n",
      "\n",
      "Fold: 9  Epoch: 185  Training loss = 2.2614  Validation loss = 9.2288  \n",
      "\n",
      "Fold: 9  Epoch: 186  Training loss = 2.2612  Validation loss = 9.2281  \n",
      "\n",
      "Fold: 9  Epoch: 187  Training loss = 2.2610  Validation loss = 9.2275  \n",
      "\n",
      "Fold: 9  Epoch: 188  Training loss = 2.2609  Validation loss = 9.2269  \n",
      "\n",
      "Fold: 9  Epoch: 189  Training loss = 2.2607  Validation loss = 9.2264  \n",
      "\n",
      "Fold: 9  Epoch: 190  Training loss = 2.2607  Validation loss = 9.2264  \n",
      "\n",
      "Fold: 9  Epoch: 191  Training loss = 2.2606  Validation loss = 9.2263  \n",
      "\n",
      "Fold: 9  Epoch: 192  Training loss = 2.2604  Validation loss = 9.2258  \n",
      "\n",
      "Fold: 9  Epoch: 193  Training loss = 2.2602  Validation loss = 9.2244  \n",
      "\n",
      "Fold: 9  Epoch: 194  Training loss = 2.2601  Validation loss = 9.2239  \n",
      "\n",
      "Fold: 9  Epoch: 195  Training loss = 2.2598  Validation loss = 9.2230  \n",
      "\n",
      "Fold: 9  Epoch: 196  Training loss = 2.2596  Validation loss = 9.2218  \n",
      "\n",
      "Fold: 9  Epoch: 197  Training loss = 2.2594  Validation loss = 9.2210  \n",
      "\n",
      "Fold: 9  Epoch: 198  Training loss = 2.2593  Validation loss = 9.2208  \n",
      "\n",
      "Fold: 9  Epoch: 199  Training loss = 2.2591  Validation loss = 9.2199  \n",
      "\n",
      "Fold: 9  Epoch: 200  Training loss = 2.2590  Validation loss = 9.2194  \n",
      "\n",
      "Fold: 9  Epoch: 201  Training loss = 2.2588  Validation loss = 9.2185  \n",
      "\n",
      "Fold: 9  Epoch: 202  Training loss = 2.2587  Validation loss = 9.2182  \n",
      "\n",
      "Fold: 9  Epoch: 203  Training loss = 2.2585  Validation loss = 9.2170  \n",
      "\n",
      "Fold: 9  Epoch: 204  Training loss = 2.2583  Validation loss = 9.2166  \n",
      "\n",
      "Fold: 9  Epoch: 205  Training loss = 2.2582  Validation loss = 9.2157  \n",
      "\n",
      "Fold: 9  Epoch: 206  Training loss = 2.2581  Validation loss = 9.2153  \n",
      "\n",
      "Fold: 9  Epoch: 207  Training loss = 2.2578  Validation loss = 9.2133  \n",
      "\n",
      "Fold: 9  Epoch: 208  Training loss = 2.2576  Validation loss = 9.2127  \n",
      "\n",
      "Fold: 9  Epoch: 209  Training loss = 2.2574  Validation loss = 9.2119  \n",
      "\n",
      "Fold: 9  Epoch: 210  Training loss = 2.2574  Validation loss = 9.2125  \n",
      "\n",
      "Fold: 9  Epoch: 211  Training loss = 2.2573  Validation loss = 9.2119  \n",
      "\n",
      "Fold: 9  Epoch: 212  Training loss = 2.2572  Validation loss = 9.2118  \n",
      "\n",
      "Fold: 9  Epoch: 213  Training loss = 2.2570  Validation loss = 9.2111  \n",
      "\n",
      "Fold: 9  Epoch: 214  Training loss = 2.2567  Validation loss = 9.2096  \n",
      "\n",
      "Fold: 9  Epoch: 215  Training loss = 2.2565  Validation loss = 9.2089  \n",
      "\n",
      "Fold: 9  Epoch: 216  Training loss = 2.2562  Validation loss = 9.2070  \n",
      "\n",
      "Fold: 9  Epoch: 217  Training loss = 2.2560  Validation loss = 9.2057  \n",
      "\n",
      "Fold: 9  Epoch: 218  Training loss = 2.2558  Validation loss = 9.2051  \n",
      "\n",
      "Fold: 9  Epoch: 219  Training loss = 2.2557  Validation loss = 9.2046  \n",
      "\n",
      "Fold: 9  Epoch: 220  Training loss = 2.2555  Validation loss = 9.2039  \n",
      "\n",
      "Fold: 9  Epoch: 221  Training loss = 2.2553  Validation loss = 9.2030  \n",
      "\n",
      "Fold: 9  Epoch: 222  Training loss = 2.2552  Validation loss = 9.2027  \n",
      "\n",
      "Fold: 9  Epoch: 223  Training loss = 2.2551  Validation loss = 9.2025  \n",
      "\n",
      "Fold: 9  Epoch: 224  Training loss = 2.2549  Validation loss = 9.2016  \n",
      "\n",
      "Fold: 9  Epoch: 225  Training loss = 2.2547  Validation loss = 9.2006  \n",
      "\n",
      "Fold: 9  Epoch: 226  Training loss = 2.2545  Validation loss = 9.1995  \n",
      "\n",
      "Fold: 9  Epoch: 227  Training loss = 2.2543  Validation loss = 9.1984  \n",
      "\n",
      "Fold: 9  Epoch: 228  Training loss = 2.2539  Validation loss = 9.1964  \n",
      "\n",
      "Fold: 9  Epoch: 229  Training loss = 2.2538  Validation loss = 9.1958  \n",
      "\n",
      "Fold: 9  Epoch: 230  Training loss = 2.2536  Validation loss = 9.1952  \n",
      "\n",
      "Fold: 9  Epoch: 231  Training loss = 2.2535  Validation loss = 9.1951  \n",
      "\n",
      "Fold: 9  Epoch: 232  Training loss = 2.2533  Validation loss = 9.1938  \n",
      "\n",
      "Fold: 9  Epoch: 233  Training loss = 2.2532  Validation loss = 9.1934  \n",
      "\n",
      "Fold: 9  Epoch: 234  Training loss = 2.2531  Validation loss = 9.1933  \n",
      "\n",
      "Fold: 9  Epoch: 235  Training loss = 2.2530  Validation loss = 9.1926  \n",
      "\n",
      "Fold: 9  Epoch: 236  Training loss = 2.2530  Validation loss = 9.1929  \n",
      "\n",
      "Fold: 9  Epoch: 237  Training loss = 2.2528  Validation loss = 9.1922  \n",
      "\n",
      "Fold: 9  Epoch: 238  Training loss = 2.2526  Validation loss = 9.1917  \n",
      "\n",
      "Fold: 9  Epoch: 239  Training loss = 2.2524  Validation loss = 9.1906  \n",
      "\n",
      "Fold: 9  Epoch: 240  Training loss = 2.2523  Validation loss = 9.1902  \n",
      "\n",
      "Fold: 9  Epoch: 241  Training loss = 2.2519  Validation loss = 9.1878  \n",
      "\n",
      "Fold: 9  Epoch: 242  Training loss = 2.2517  Validation loss = 9.1864  \n",
      "\n",
      "Fold: 9  Epoch: 243  Training loss = 2.2514  Validation loss = 9.1848  \n",
      "\n",
      "Fold: 9  Epoch: 244  Training loss = 2.2512  Validation loss = 9.1838  \n",
      "\n",
      "Fold: 9  Epoch: 245  Training loss = 2.2510  Validation loss = 9.1828  \n",
      "\n",
      "Fold: 9  Epoch: 246  Training loss = 2.2508  Validation loss = 9.1816  \n",
      "\n",
      "Fold: 9  Epoch: 247  Training loss = 2.2505  Validation loss = 9.1798  \n",
      "\n",
      "Fold: 9  Epoch: 248  Training loss = 2.2501  Validation loss = 9.1777  \n",
      "\n",
      "Fold: 9  Epoch: 249  Training loss = 2.2501  Validation loss = 9.1779  \n",
      "\n",
      "Fold: 9  Epoch: 250  Training loss = 2.2500  Validation loss = 9.1776  \n",
      "\n",
      "Fold: 9  Epoch: 251  Training loss = 2.2499  Validation loss = 9.1771  \n",
      "\n",
      "Fold: 9  Epoch: 252  Training loss = 2.2497  Validation loss = 9.1763  \n",
      "\n",
      "Fold: 9  Epoch: 253  Training loss = 2.2495  Validation loss = 9.1753  \n",
      "\n",
      "Fold: 9  Epoch: 254  Training loss = 2.2493  Validation loss = 9.1739  \n",
      "\n",
      "Fold: 9  Epoch: 255  Training loss = 2.2492  Validation loss = 9.1738  \n",
      "\n",
      "Fold: 9  Epoch: 256  Training loss = 2.2488  Validation loss = 9.1715  \n",
      "\n",
      "Fold: 9  Epoch: 257  Training loss = 2.2487  Validation loss = 9.1712  \n",
      "\n",
      "Fold: 9  Epoch: 258  Training loss = 2.2485  Validation loss = 9.1705  \n",
      "\n",
      "Fold: 9  Epoch: 259  Training loss = 2.2483  Validation loss = 9.1687  \n",
      "\n",
      "Fold: 9  Epoch: 260  Training loss = 2.2482  Validation loss = 9.1689  \n",
      "\n",
      "Fold: 9  Epoch: 261  Training loss = 2.2481  Validation loss = 9.1678  \n",
      "\n",
      "Fold: 9  Epoch: 262  Training loss = 2.2479  Validation loss = 9.1669  \n",
      "\n",
      "Fold: 9  Epoch: 263  Training loss = 2.2477  Validation loss = 9.1653  \n",
      "\n",
      "Fold: 9  Epoch: 264  Training loss = 2.2474  Validation loss = 9.1638  \n",
      "\n",
      "Fold: 9  Epoch: 265  Training loss = 2.2473  Validation loss = 9.1633  \n",
      "\n",
      "Fold: 9  Epoch: 266  Training loss = 2.2471  Validation loss = 9.1623  \n",
      "\n",
      "Fold: 9  Epoch: 267  Training loss = 2.2469  Validation loss = 9.1609  \n",
      "\n",
      "Fold: 9  Epoch: 268  Training loss = 2.2466  Validation loss = 9.1593  \n",
      "\n",
      "Fold: 9  Epoch: 269  Training loss = 2.2464  Validation loss = 9.1580  \n",
      "\n",
      "Fold: 9  Epoch: 270  Training loss = 2.2462  Validation loss = 9.1568  \n",
      "\n",
      "Fold: 9  Epoch: 271  Training loss = 2.2461  Validation loss = 9.1564  \n",
      "\n",
      "Fold: 9  Epoch: 272  Training loss = 2.2460  Validation loss = 9.1557  \n",
      "\n",
      "Fold: 9  Epoch: 273  Training loss = 2.2457  Validation loss = 9.1545  \n",
      "\n",
      "Fold: 9  Epoch: 274  Training loss = 2.2455  Validation loss = 9.1533  \n",
      "\n",
      "Fold: 9  Epoch: 275  Training loss = 2.2453  Validation loss = 9.1515  \n",
      "\n",
      "Fold: 9  Epoch: 276  Training loss = 2.2452  Validation loss = 9.1512  \n",
      "\n",
      "Fold: 9  Epoch: 277  Training loss = 2.2450  Validation loss = 9.1506  \n",
      "\n",
      "Fold: 9  Epoch: 278  Training loss = 2.2448  Validation loss = 9.1496  \n",
      "\n",
      "Fold: 9  Epoch: 279  Training loss = 2.2447  Validation loss = 9.1491  \n",
      "\n",
      "Fold: 9  Epoch: 280  Training loss = 2.2445  Validation loss = 9.1478  \n",
      "\n",
      "Fold: 9  Epoch: 281  Training loss = 2.2441  Validation loss = 9.1455  \n",
      "\n",
      "Fold: 9  Epoch: 282  Training loss = 2.2439  Validation loss = 9.1443  \n",
      "\n",
      "Fold: 9  Epoch: 283  Training loss = 2.2438  Validation loss = 9.1438  \n",
      "\n",
      "Fold: 9  Epoch: 284  Training loss = 2.2435  Validation loss = 9.1422  \n",
      "\n",
      "Fold: 9  Epoch: 285  Training loss = 2.2433  Validation loss = 9.1409  \n",
      "\n",
      "Fold: 9  Epoch: 286  Training loss = 2.2431  Validation loss = 9.1397  \n",
      "\n",
      "Fold: 9  Epoch: 287  Training loss = 2.2431  Validation loss = 9.1402  \n",
      "\n",
      "Fold: 9  Epoch: 288  Training loss = 2.2430  Validation loss = 9.1399  \n",
      "\n",
      "Fold: 9  Epoch: 289  Training loss = 2.2430  Validation loss = 9.1402  \n",
      "\n",
      "Fold: 9  Epoch: 290  Training loss = 2.2427  Validation loss = 9.1381  \n",
      "\n",
      "Fold: 9  Epoch: 291  Training loss = 2.2427  Validation loss = 9.1388  \n",
      "\n",
      "Fold: 9  Epoch: 292  Training loss = 2.2425  Validation loss = 9.1376  \n",
      "\n",
      "Fold: 9  Epoch: 293  Training loss = 2.2422  Validation loss = 9.1361  \n",
      "\n",
      "Fold: 9  Epoch: 294  Training loss = 2.2420  Validation loss = 9.1348  \n",
      "\n",
      "Fold: 9  Epoch: 295  Training loss = 2.2419  Validation loss = 9.1343  \n",
      "\n",
      "Fold: 9  Epoch: 296  Training loss = 2.2416  Validation loss = 9.1330  \n",
      "\n",
      "Fold: 9  Epoch: 297  Training loss = 2.2415  Validation loss = 9.1323  \n",
      "\n",
      "Fold: 9  Epoch: 298  Training loss = 2.2413  Validation loss = 9.1316  \n",
      "\n",
      "Fold: 9  Epoch: 299  Training loss = 2.2412  Validation loss = 9.1312  \n",
      "\n",
      "Fold: 9  Epoch: 300  Training loss = 2.2411  Validation loss = 9.1310  \n",
      "\n",
      "Fold: 9  Epoch: 301  Training loss = 2.2410  Validation loss = 9.1303  \n",
      "\n",
      "Fold: 9  Epoch: 302  Training loss = 2.2407  Validation loss = 9.1284  \n",
      "\n",
      "Fold: 9  Epoch: 303  Training loss = 2.2404  Validation loss = 9.1265  \n",
      "\n",
      "Fold: 9  Epoch: 304  Training loss = 2.2402  Validation loss = 9.1254  \n",
      "\n",
      "Fold: 9  Epoch: 305  Training loss = 2.2401  Validation loss = 9.1256  \n",
      "\n",
      "Fold: 9  Epoch: 306  Training loss = 2.2399  Validation loss = 9.1245  \n",
      "\n",
      "Fold: 9  Epoch: 307  Training loss = 2.2398  Validation loss = 9.1240  \n",
      "\n",
      "Fold: 9  Epoch: 308  Training loss = 2.2396  Validation loss = 9.1226  \n",
      "\n",
      "Fold: 9  Epoch: 309  Training loss = 2.2394  Validation loss = 9.1214  \n",
      "\n",
      "Fold: 9  Epoch: 310  Training loss = 2.2392  Validation loss = 9.1212  \n",
      "\n",
      "Fold: 9  Epoch: 311  Training loss = 2.2390  Validation loss = 9.1195  \n",
      "\n",
      "Fold: 9  Epoch: 312  Training loss = 2.2390  Validation loss = 9.1199  \n",
      "\n",
      "Fold: 9  Epoch: 313  Training loss = 2.2389  Validation loss = 9.1191  \n",
      "\n",
      "Fold: 9  Epoch: 314  Training loss = 2.2387  Validation loss = 9.1181  \n",
      "\n",
      "Fold: 9  Epoch: 315  Training loss = 2.2385  Validation loss = 9.1173  \n",
      "\n",
      "Fold: 9  Epoch: 316  Training loss = 2.2384  Validation loss = 9.1169  \n",
      "\n",
      "Fold: 9  Epoch: 317  Training loss = 2.2383  Validation loss = 9.1167  \n",
      "\n",
      "Fold: 9  Epoch: 318  Training loss = 2.2382  Validation loss = 9.1163  \n",
      "\n",
      "Fold: 9  Epoch: 319  Training loss = 2.2381  Validation loss = 9.1157  \n",
      "\n",
      "Fold: 9  Epoch: 320  Training loss = 2.2380  Validation loss = 9.1161  \n",
      "\n",
      "Fold: 9  Epoch: 321  Training loss = 2.2379  Validation loss = 9.1153  \n",
      "\n",
      "Fold: 9  Epoch: 322  Training loss = 2.2378  Validation loss = 9.1148  \n",
      "\n",
      "Fold: 9  Epoch: 323  Training loss = 2.2377  Validation loss = 9.1145  \n",
      "\n",
      "Fold: 9  Epoch: 324  Training loss = 2.2374  Validation loss = 9.1128  \n",
      "\n",
      "Fold: 9  Epoch: 325  Training loss = 2.2371  Validation loss = 9.1106  \n",
      "\n",
      "Fold: 9  Epoch: 326  Training loss = 2.2370  Validation loss = 9.1100  \n",
      "\n",
      "Fold: 9  Epoch: 327  Training loss = 2.2369  Validation loss = 9.1099  \n",
      "\n",
      "Fold: 9  Epoch: 328  Training loss = 2.2367  Validation loss = 9.1086  \n",
      "\n",
      "Fold: 9  Epoch: 329  Training loss = 2.2365  Validation loss = 9.1078  \n",
      "\n",
      "Fold: 9  Epoch: 330  Training loss = 2.2365  Validation loss = 9.1080  \n",
      "\n",
      "Fold: 9  Epoch: 331  Training loss = 2.2363  Validation loss = 9.1073  \n",
      "\n",
      "Fold: 9  Epoch: 332  Training loss = 2.2360  Validation loss = 9.1048  \n",
      "\n",
      "Fold: 9  Epoch: 333  Training loss = 2.2359  Validation loss = 9.1038  \n",
      "\n",
      "Fold: 9  Epoch: 334  Training loss = 2.2357  Validation loss = 9.1029  \n",
      "\n",
      "Fold: 9  Epoch: 335  Training loss = 2.2356  Validation loss = 9.1029  \n",
      "\n",
      "Fold: 9  Epoch: 336  Training loss = 2.2355  Validation loss = 9.1020  \n",
      "\n",
      "Fold: 9  Epoch: 337  Training loss = 2.2354  Validation loss = 9.1019  \n",
      "\n",
      "Fold: 9  Epoch: 338  Training loss = 2.2353  Validation loss = 9.1017  \n",
      "\n",
      "Fold: 9  Epoch: 339  Training loss = 2.2352  Validation loss = 9.1010  \n",
      "\n",
      "Fold: 9  Epoch: 340  Training loss = 2.2349  Validation loss = 9.0995  \n",
      "\n",
      "Fold: 9  Epoch: 341  Training loss = 2.2349  Validation loss = 9.0995  \n",
      "\n",
      "Fold: 9  Epoch: 342  Training loss = 2.2346  Validation loss = 9.0977  \n",
      "\n",
      "Fold: 9  Epoch: 343  Training loss = 2.2344  Validation loss = 9.0968  \n",
      "\n",
      "Fold: 9  Epoch: 344  Training loss = 2.2343  Validation loss = 9.0958  \n",
      "\n",
      "Fold: 9  Epoch: 345  Training loss = 2.2341  Validation loss = 9.0946  \n",
      "\n",
      "Fold: 9  Epoch: 346  Training loss = 2.2341  Validation loss = 9.0952  \n",
      "\n",
      "Fold: 9  Epoch: 347  Training loss = 2.2340  Validation loss = 9.0946  \n",
      "\n",
      "Fold: 9  Epoch: 348  Training loss = 2.2339  Validation loss = 9.0951  \n",
      "\n",
      "Fold: 9  Epoch: 349  Training loss = 2.2337  Validation loss = 9.0939  \n",
      "\n",
      "Fold: 9  Epoch: 350  Training loss = 2.2336  Validation loss = 9.0933  \n",
      "\n",
      "Fold: 9  Epoch: 351  Training loss = 2.2334  Validation loss = 9.0927  \n",
      "\n",
      "Fold: 9  Epoch: 352  Training loss = 2.2333  Validation loss = 9.0919  \n",
      "\n",
      "Fold: 9  Epoch: 353  Training loss = 2.2331  Validation loss = 9.0905  \n",
      "\n",
      "Fold: 9  Epoch: 354  Training loss = 2.2329  Validation loss = 9.0893  \n",
      "\n",
      "Fold: 9  Epoch: 355  Training loss = 2.2328  Validation loss = 9.0895  \n",
      "\n",
      "Fold: 9  Epoch: 356  Training loss = 2.2328  Validation loss = 9.0901  \n",
      "\n",
      "Fold: 9  Epoch: 357  Training loss = 2.2328  Validation loss = 9.0905  \n",
      "\n",
      "Fold: 9  Epoch: 358  Training loss = 2.2327  Validation loss = 9.0903  \n",
      "\n",
      "Fold: 9  Epoch: 359  Training loss = 2.2326  Validation loss = 9.0905  \n",
      "\n",
      "Fold: 9  Epoch: 360  Training loss = 2.2326  Validation loss = 9.0904  \n",
      "\n",
      "Fold: 9  Epoch: 361  Training loss = 2.2325  Validation loss = 9.0897  \n",
      "\n",
      "Fold: 9  Epoch: 362  Training loss = 2.2322  Validation loss = 9.0880  \n",
      "\n",
      "Fold: 9  Epoch: 363  Training loss = 2.2321  Validation loss = 9.0872  \n",
      "\n",
      "Fold: 9  Epoch: 364  Training loss = 2.2319  Validation loss = 9.0867  \n",
      "\n",
      "Fold: 9  Epoch: 365  Training loss = 2.2319  Validation loss = 9.0865  \n",
      "\n",
      "Fold: 9  Epoch: 366  Training loss = 2.2316  Validation loss = 9.0852  \n",
      "\n",
      "Fold: 9  Epoch: 367  Training loss = 2.2316  Validation loss = 9.0851  \n",
      "\n",
      "Fold: 9  Epoch: 368  Training loss = 2.2314  Validation loss = 9.0839  \n",
      "\n",
      "Fold: 9  Epoch: 369  Training loss = 2.2312  Validation loss = 9.0828  \n",
      "\n",
      "Fold: 9  Epoch: 370  Training loss = 2.2311  Validation loss = 9.0828  \n",
      "\n",
      "Fold: 9  Epoch: 371  Training loss = 2.2308  Validation loss = 9.0804  \n",
      "\n",
      "Fold: 9  Epoch: 372  Training loss = 2.2309  Validation loss = 9.0817  \n",
      "\n",
      "Fold: 9  Epoch: 373  Training loss = 2.2308  Validation loss = 9.0813  \n",
      "\n",
      "Fold: 9  Epoch: 374  Training loss = 2.2306  Validation loss = 9.0800  \n",
      "\n",
      "Fold: 9  Epoch: 375  Training loss = 2.2304  Validation loss = 9.0786  \n",
      "\n",
      "Fold: 9  Epoch: 376  Training loss = 2.2304  Validation loss = 9.0784  \n",
      "\n",
      "Fold: 9  Epoch: 377  Training loss = 2.2303  Validation loss = 9.0778  \n",
      "\n",
      "Fold: 9  Epoch: 378  Training loss = 2.2301  Validation loss = 9.0770  \n",
      "\n",
      "Fold: 9  Epoch: 379  Training loss = 2.2300  Validation loss = 9.0760  \n",
      "\n",
      "Fold: 9  Epoch: 380  Training loss = 2.2297  Validation loss = 9.0741  \n",
      "\n",
      "Fold: 9  Epoch: 381  Training loss = 2.2295  Validation loss = 9.0726  \n",
      "\n",
      "Fold: 9  Epoch: 382  Training loss = 2.2294  Validation loss = 9.0716  \n",
      "\n",
      "Fold: 9  Epoch: 383  Training loss = 2.2294  Validation loss = 9.0722  \n",
      "\n",
      "Fold: 9  Epoch: 384  Training loss = 2.2292  Validation loss = 9.0710  \n",
      "\n",
      "Fold: 9  Epoch: 385  Training loss = 2.2291  Validation loss = 9.0709  \n",
      "\n",
      "Fold: 9  Epoch: 386  Training loss = 2.2289  Validation loss = 9.0692  \n",
      "\n",
      "Fold: 9  Epoch: 387  Training loss = 2.2289  Validation loss = 9.0693  \n",
      "\n",
      "Fold: 9  Epoch: 388  Training loss = 2.2287  Validation loss = 9.0686  \n",
      "\n",
      "Fold: 9  Epoch: 389  Training loss = 2.2287  Validation loss = 9.0683  \n",
      "\n",
      "Fold: 9  Epoch: 390  Training loss = 2.2285  Validation loss = 9.0676  \n",
      "\n",
      "Fold: 9  Epoch: 391  Training loss = 2.2283  Validation loss = 9.0658  \n",
      "\n",
      "Fold: 9  Epoch: 392  Training loss = 2.2281  Validation loss = 9.0650  \n",
      "\n",
      "Fold: 9  Epoch: 393  Training loss = 2.2280  Validation loss = 9.0643  \n",
      "\n",
      "Fold: 9  Epoch: 394  Training loss = 2.2279  Validation loss = 9.0633  \n",
      "\n",
      "Fold: 9  Epoch: 395  Training loss = 2.2277  Validation loss = 9.0626  \n",
      "\n",
      "Fold: 9  Epoch: 396  Training loss = 2.2277  Validation loss = 9.0630  \n",
      "\n",
      "Fold: 9  Epoch: 397  Training loss = 2.2276  Validation loss = 9.0626  \n",
      "\n",
      "Fold: 9  Epoch: 398  Training loss = 2.2275  Validation loss = 9.0617  \n",
      "\n",
      "Fold: 9  Epoch: 399  Training loss = 2.2274  Validation loss = 9.0614  \n",
      "\n",
      "Fold: 9  Epoch: 400  Training loss = 2.2272  Validation loss = 9.0604  \n",
      "\n",
      "Fold: 9  Epoch: 401  Training loss = 2.2271  Validation loss = 9.0600  \n",
      "\n",
      "Fold: 9  Epoch: 402  Training loss = 2.2271  Validation loss = 9.0605  \n",
      "\n",
      "Fold: 9  Epoch: 403  Training loss = 2.2270  Validation loss = 9.0606  \n",
      "\n",
      "Fold: 9  Epoch: 404  Training loss = 2.2270  Validation loss = 9.0604  \n",
      "\n",
      "Fold: 9  Epoch: 405  Training loss = 2.2269  Validation loss = 9.0607  \n",
      "\n",
      "Fold: 9  Epoch: 406  Training loss = 2.2267  Validation loss = 9.0593  \n",
      "\n",
      "Fold: 9  Epoch: 407  Training loss = 2.2266  Validation loss = 9.0589  \n",
      "\n",
      "Fold: 9  Epoch: 408  Training loss = 2.2264  Validation loss = 9.0575  \n",
      "\n",
      "Fold: 9  Epoch: 409  Training loss = 2.2263  Validation loss = 9.0569  \n",
      "\n",
      "Fold: 9  Epoch: 410  Training loss = 2.2262  Validation loss = 9.0565  \n",
      "\n",
      "Fold: 9  Epoch: 411  Training loss = 2.2260  Validation loss = 9.0550  \n",
      "\n",
      "Fold: 9  Epoch: 412  Training loss = 2.2259  Validation loss = 9.0540  \n",
      "\n",
      "Fold: 9  Epoch: 413  Training loss = 2.2258  Validation loss = 9.0537  \n",
      "\n",
      "Fold: 9  Epoch: 414  Training loss = 2.2256  Validation loss = 9.0528  \n",
      "\n",
      "Fold: 9  Epoch: 415  Training loss = 2.2254  Validation loss = 9.0508  \n",
      "\n",
      "Fold: 9  Epoch: 416  Training loss = 2.2253  Validation loss = 9.0503  \n",
      "\n",
      "Fold: 9  Epoch: 417  Training loss = 2.2251  Validation loss = 9.0495  \n",
      "\n",
      "Fold: 9  Epoch: 418  Training loss = 2.2250  Validation loss = 9.0486  \n",
      "\n",
      "Fold: 9  Epoch: 419  Training loss = 2.2249  Validation loss = 9.0490  \n",
      "\n",
      "Fold: 9  Epoch: 420  Training loss = 2.2248  Validation loss = 9.0481  \n",
      "\n",
      "Fold: 9  Epoch: 421  Training loss = 2.2246  Validation loss = 9.0464  \n",
      "\n",
      "Fold: 9  Epoch: 422  Training loss = 2.2245  Validation loss = 9.0457  \n",
      "\n",
      "Fold: 9  Epoch: 423  Training loss = 2.2244  Validation loss = 9.0451  \n",
      "\n",
      "Fold: 9  Epoch: 424  Training loss = 2.2242  Validation loss = 9.0440  \n",
      "\n",
      "Fold: 9  Epoch: 425  Training loss = 2.2241  Validation loss = 9.0434  \n",
      "\n",
      "Fold: 9  Epoch: 426  Training loss = 2.2240  Validation loss = 9.0431  \n",
      "\n",
      "Fold: 9  Epoch: 427  Training loss = 2.2239  Validation loss = 9.0426  \n",
      "\n",
      "Fold: 9  Epoch: 428  Training loss = 2.2238  Validation loss = 9.0420  \n",
      "\n",
      "Fold: 9  Epoch: 429  Training loss = 2.2236  Validation loss = 9.0406  \n",
      "\n",
      "Fold: 9  Epoch: 430  Training loss = 2.2235  Validation loss = 9.0402  \n",
      "\n",
      "Fold: 9  Epoch: 431  Training loss = 2.2235  Validation loss = 9.0407  \n",
      "\n",
      "Fold: 9  Epoch: 432  Training loss = 2.2233  Validation loss = 9.0397  \n",
      "\n",
      "Fold: 9  Epoch: 433  Training loss = 2.2232  Validation loss = 9.0398  \n",
      "\n",
      "Fold: 9  Epoch: 434  Training loss = 2.2231  Validation loss = 9.0392  \n",
      "\n",
      "Fold: 9  Epoch: 435  Training loss = 2.2229  Validation loss = 9.0378  \n",
      "\n",
      "Fold: 9  Epoch: 436  Training loss = 2.2229  Validation loss = 9.0378  \n",
      "\n",
      "Fold: 9  Epoch: 437  Training loss = 2.2227  Validation loss = 9.0368  \n",
      "\n",
      "Fold: 9  Epoch: 438  Training loss = 2.2226  Validation loss = 9.0360  \n",
      "\n",
      "Fold: 9  Epoch: 439  Training loss = 2.2225  Validation loss = 9.0363  \n",
      "\n",
      "Fold: 9  Epoch: 440  Training loss = 2.2224  Validation loss = 9.0358  \n",
      "\n",
      "Fold: 9  Epoch: 441  Training loss = 2.2223  Validation loss = 9.0350  \n",
      "\n",
      "Fold: 9  Epoch: 442  Training loss = 2.2222  Validation loss = 9.0347  \n",
      "\n",
      "Fold: 9  Epoch: 443  Training loss = 2.2221  Validation loss = 9.0342  \n",
      "\n",
      "Fold: 9  Epoch: 444  Training loss = 2.2219  Validation loss = 9.0334  \n",
      "\n",
      "Fold: 9  Epoch: 445  Training loss = 2.2217  Validation loss = 9.0320  \n",
      "\n",
      "Fold: 9  Epoch: 446  Training loss = 2.2216  Validation loss = 9.0317  \n",
      "\n",
      "Fold: 9  Epoch: 447  Training loss = 2.2215  Validation loss = 9.0316  \n",
      "\n",
      "Fold: 9  Epoch: 448  Training loss = 2.2214  Validation loss = 9.0307  \n",
      "\n",
      "Fold: 9  Epoch: 449  Training loss = 2.2212  Validation loss = 9.0298  \n",
      "\n",
      "Fold: 9  Epoch: 450  Training loss = 2.2212  Validation loss = 9.0299  \n",
      "\n",
      "Fold: 9  Epoch: 451  Training loss = 2.2211  Validation loss = 9.0300  \n",
      "\n",
      "Fold: 9  Epoch: 452  Training loss = 2.2210  Validation loss = 9.0291  \n",
      "\n",
      "Fold: 9  Epoch: 453  Training loss = 2.2209  Validation loss = 9.0289  \n",
      "\n",
      "Fold: 9  Epoch: 454  Training loss = 2.2207  Validation loss = 9.0285  \n",
      "\n",
      "Fold: 9  Epoch: 455  Training loss = 2.2206  Validation loss = 9.0276  \n",
      "\n",
      "Fold: 9  Epoch: 456  Training loss = 2.2205  Validation loss = 9.0272  \n",
      "\n",
      "Fold: 9  Epoch: 457  Training loss = 2.2204  Validation loss = 9.0272  \n",
      "\n",
      "Fold: 9  Epoch: 458  Training loss = 2.2202  Validation loss = 9.0257  \n",
      "\n",
      "Fold: 9  Epoch: 459  Training loss = 2.2200  Validation loss = 9.0244  \n",
      "\n",
      "Fold: 9  Epoch: 460  Training loss = 2.2199  Validation loss = 9.0234  \n",
      "\n",
      "Fold: 9  Epoch: 461  Training loss = 2.2197  Validation loss = 9.0220  \n",
      "\n",
      "Fold: 9  Epoch: 462  Training loss = 2.2196  Validation loss = 9.0220  \n",
      "\n",
      "Fold: 9  Epoch: 463  Training loss = 2.2195  Validation loss = 9.0210  \n",
      "\n",
      "Fold: 9  Epoch: 464  Training loss = 2.2193  Validation loss = 9.0197  \n",
      "\n",
      "Fold: 9  Epoch: 465  Training loss = 2.2192  Validation loss = 9.0188  \n",
      "\n",
      "Fold: 9  Epoch: 466  Training loss = 2.2190  Validation loss = 9.0176  \n",
      "\n",
      "Fold: 9  Epoch: 467  Training loss = 2.2188  Validation loss = 9.0160  \n",
      "\n",
      "Fold: 9  Epoch: 468  Training loss = 2.2187  Validation loss = 9.0157  \n",
      "\n",
      "Fold: 9  Epoch: 469  Training loss = 2.2186  Validation loss = 9.0149  \n",
      "\n",
      "Fold: 9  Epoch: 470  Training loss = 2.2184  Validation loss = 9.0140  \n",
      "\n",
      "Fold: 9  Epoch: 471  Training loss = 2.2182  Validation loss = 9.0121  \n",
      "\n",
      "Fold: 9  Epoch: 472  Training loss = 2.2182  Validation loss = 9.0125  \n",
      "\n",
      "Fold: 9  Epoch: 473  Training loss = 2.2180  Validation loss = 9.0113  \n",
      "\n",
      "Fold: 9  Epoch: 474  Training loss = 2.2179  Validation loss = 9.0100  \n",
      "\n",
      "Fold: 9  Epoch: 475  Training loss = 2.2177  Validation loss = 9.0091  \n",
      "\n",
      "Fold: 9  Epoch: 476  Training loss = 2.2176  Validation loss = 9.0087  \n",
      "\n",
      "Fold: 9  Epoch: 477  Training loss = 2.2175  Validation loss = 9.0081  \n",
      "\n",
      "Fold: 9  Epoch: 478  Training loss = 2.2175  Validation loss = 9.0082  \n",
      "\n",
      "Fold: 9  Epoch: 479  Training loss = 2.2174  Validation loss = 9.0082  \n",
      "\n",
      "Fold: 9  Epoch: 480  Training loss = 2.2173  Validation loss = 9.0083  \n",
      "\n",
      "Fold: 9  Epoch: 481  Training loss = 2.2172  Validation loss = 9.0071  \n",
      "\n",
      "Fold: 9  Epoch: 482  Training loss = 2.2170  Validation loss = 9.0060  \n",
      "\n",
      "Fold: 9  Epoch: 483  Training loss = 2.2170  Validation loss = 9.0068  \n",
      "\n",
      "Fold: 9  Epoch: 484  Training loss = 2.2169  Validation loss = 9.0064  \n",
      "\n",
      "Fold: 9  Epoch: 485  Training loss = 2.2168  Validation loss = 9.0055  \n",
      "\n",
      "Fold: 9  Epoch: 486  Training loss = 2.2167  Validation loss = 9.0055  \n",
      "\n",
      "Fold: 9  Epoch: 487  Training loss = 2.2166  Validation loss = 9.0050  \n",
      "\n",
      "Fold: 9  Epoch: 488  Training loss = 2.2165  Validation loss = 9.0052  \n",
      "\n",
      "Fold: 9  Epoch: 489  Training loss = 2.2165  Validation loss = 9.0055  \n",
      "\n",
      "Fold: 9  Epoch: 490  Training loss = 2.2164  Validation loss = 9.0044  \n",
      "\n",
      "Fold: 9  Epoch: 491  Training loss = 2.2163  Validation loss = 9.0047  \n",
      "\n",
      "Fold: 9  Epoch: 492  Training loss = 2.2162  Validation loss = 9.0036  \n",
      "\n",
      "Fold: 9  Epoch: 493  Training loss = 2.2161  Validation loss = 9.0034  \n",
      "\n",
      "Fold: 9  Epoch: 494  Training loss = 2.2160  Validation loss = 9.0028  \n",
      "\n",
      "Fold: 9  Epoch: 495  Training loss = 2.2159  Validation loss = 9.0034  \n",
      "\n",
      "Fold: 9  Epoch: 496  Training loss = 2.2158  Validation loss = 9.0028  \n",
      "\n",
      "Fold: 9  Epoch: 497  Training loss = 2.2158  Validation loss = 9.0033  \n",
      "\n",
      "Fold: 9  Epoch: 498  Training loss = 2.2158  Validation loss = 9.0039  \n",
      "\n",
      "Fold: 9  Epoch: 499  Training loss = 2.2157  Validation loss = 9.0034  \n",
      "\n",
      "Fold: 9  Epoch: 500  Training loss = 2.2155  Validation loss = 9.0026  \n",
      "\n",
      "Check model:  Fold: 9  Optimal epoch: 500  \n",
      "\n",
      "Fold: 10  Epoch: 1  Training loss = 3.1187  Validation loss = 5.4214  \n",
      "\n",
      "Fold: 10  Epoch: 2  Training loss = 3.1179  Validation loss = 5.4162  \n",
      "\n",
      "Fold: 10  Epoch: 3  Training loss = 3.1179  Validation loss = 5.4155  \n",
      "\n",
      "Fold: 10  Epoch: 4  Training loss = 3.1177  Validation loss = 5.4129  \n",
      "\n",
      "Fold: 10  Epoch: 5  Training loss = 3.1172  Validation loss = 5.4088  \n",
      "\n",
      "Fold: 10  Epoch: 6  Training loss = 3.1168  Validation loss = 5.4055  \n",
      "\n",
      "Fold: 10  Epoch: 7  Training loss = 3.1158  Validation loss = 5.3990  \n",
      "\n",
      "Fold: 10  Epoch: 8  Training loss = 3.1154  Validation loss = 5.3952  \n",
      "\n",
      "Fold: 10  Epoch: 9  Training loss = 3.1146  Validation loss = 5.3901  \n",
      "\n",
      "Fold: 10  Epoch: 10  Training loss = 3.1139  Validation loss = 5.3856  \n",
      "\n",
      "Fold: 10  Epoch: 11  Training loss = 3.1131  Validation loss = 5.3784  \n",
      "\n",
      "Fold: 10  Epoch: 12  Training loss = 3.1122  Validation loss = 5.3711  \n",
      "\n",
      "Fold: 10  Epoch: 13  Training loss = 3.1118  Validation loss = 5.3691  \n",
      "\n",
      "Fold: 10  Epoch: 14  Training loss = 3.1111  Validation loss = 5.3648  \n",
      "\n",
      "Fold: 10  Epoch: 15  Training loss = 3.1105  Validation loss = 5.3603  \n",
      "\n",
      "Fold: 10  Epoch: 16  Training loss = 3.1096  Validation loss = 5.3534  \n",
      "\n",
      "Fold: 10  Epoch: 17  Training loss = 3.1085  Validation loss = 5.3452  \n",
      "\n",
      "Fold: 10  Epoch: 18  Training loss = 3.1079  Validation loss = 5.3419  \n",
      "\n",
      "Fold: 10  Epoch: 19  Training loss = 3.1071  Validation loss = 5.3346  \n",
      "\n",
      "Fold: 10  Epoch: 20  Training loss = 3.1065  Validation loss = 5.3317  \n",
      "\n",
      "Fold: 10  Epoch: 21  Training loss = 3.1056  Validation loss = 5.3251  \n",
      "\n",
      "Fold: 10  Epoch: 22  Training loss = 3.1048  Validation loss = 5.3197  \n",
      "\n",
      "Fold: 10  Epoch: 23  Training loss = 3.1043  Validation loss = 5.3171  \n",
      "\n",
      "Fold: 10  Epoch: 24  Training loss = 3.1036  Validation loss = 5.3130  \n",
      "\n",
      "Fold: 10  Epoch: 25  Training loss = 3.1027  Validation loss = 5.3079  \n",
      "\n",
      "Fold: 10  Epoch: 26  Training loss = 3.1025  Validation loss = 5.3057  \n",
      "\n",
      "Fold: 10  Epoch: 27  Training loss = 3.1016  Validation loss = 5.3013  \n",
      "\n",
      "Fold: 10  Epoch: 28  Training loss = 3.1010  Validation loss = 5.2965  \n",
      "\n",
      "Fold: 10  Epoch: 29  Training loss = 3.1002  Validation loss = 5.2923  \n",
      "\n",
      "Fold: 10  Epoch: 30  Training loss = 3.1001  Validation loss = 5.2911  \n",
      "\n",
      "Fold: 10  Epoch: 31  Training loss = 3.0995  Validation loss = 5.2878  \n",
      "\n",
      "Fold: 10  Epoch: 32  Training loss = 3.0991  Validation loss = 5.2868  \n",
      "\n",
      "Fold: 10  Epoch: 33  Training loss = 3.0988  Validation loss = 5.2847  \n",
      "\n",
      "Fold: 10  Epoch: 34  Training loss = 3.0985  Validation loss = 5.2835  \n",
      "\n",
      "Fold: 10  Epoch: 35  Training loss = 3.0982  Validation loss = 5.2820  \n",
      "\n",
      "Fold: 10  Epoch: 36  Training loss = 3.0974  Validation loss = 5.2784  \n",
      "\n",
      "Fold: 10  Epoch: 37  Training loss = 3.0972  Validation loss = 5.2773  \n",
      "\n",
      "Fold: 10  Epoch: 38  Training loss = 3.0964  Validation loss = 5.2739  \n",
      "\n",
      "Fold: 10  Epoch: 39  Training loss = 3.0962  Validation loss = 5.2733  \n",
      "\n",
      "Fold: 10  Epoch: 40  Training loss = 3.0959  Validation loss = 5.2711  \n",
      "\n",
      "Fold: 10  Epoch: 41  Training loss = 3.0953  Validation loss = 5.2685  \n",
      "\n",
      "Fold: 10  Epoch: 42  Training loss = 3.0947  Validation loss = 5.2658  \n",
      "\n",
      "Fold: 10  Epoch: 43  Training loss = 3.0941  Validation loss = 5.2631  \n",
      "\n",
      "Fold: 10  Epoch: 44  Training loss = 3.0939  Validation loss = 5.2625  \n",
      "\n",
      "Fold: 10  Epoch: 45  Training loss = 3.0935  Validation loss = 5.2611  \n",
      "\n",
      "Fold: 10  Epoch: 46  Training loss = 3.0931  Validation loss = 5.2594  \n",
      "\n",
      "Fold: 10  Epoch: 47  Training loss = 3.0927  Validation loss = 5.2574  \n",
      "\n",
      "Fold: 10  Epoch: 48  Training loss = 3.0922  Validation loss = 5.2548  \n",
      "\n",
      "Fold: 10  Epoch: 49  Training loss = 3.0917  Validation loss = 5.2529  \n",
      "\n",
      "Fold: 10  Epoch: 50  Training loss = 3.0910  Validation loss = 5.2498  \n",
      "\n",
      "Fold: 10  Epoch: 51  Training loss = 3.0902  Validation loss = 5.2463  \n",
      "\n",
      "Fold: 10  Epoch: 52  Training loss = 3.0898  Validation loss = 5.2449  \n",
      "\n",
      "Fold: 10  Epoch: 53  Training loss = 3.0893  Validation loss = 5.2428  \n",
      "\n",
      "Fold: 10  Epoch: 54  Training loss = 3.0889  Validation loss = 5.2412  \n",
      "\n",
      "Fold: 10  Epoch: 55  Training loss = 3.0883  Validation loss = 5.2390  \n",
      "\n",
      "Fold: 10  Epoch: 56  Training loss = 3.0878  Validation loss = 5.2370  \n",
      "\n",
      "Fold: 10  Epoch: 57  Training loss = 3.0873  Validation loss = 5.2350  \n",
      "\n",
      "Fold: 10  Epoch: 58  Training loss = 3.0861  Validation loss = 5.2307  \n",
      "\n",
      "Fold: 10  Epoch: 59  Training loss = 3.0856  Validation loss = 5.2288  \n",
      "\n",
      "Fold: 10  Epoch: 60  Training loss = 3.0852  Validation loss = 5.2274  \n",
      "\n",
      "Fold: 10  Epoch: 61  Training loss = 3.0846  Validation loss = 5.2248  \n",
      "\n",
      "Fold: 10  Epoch: 62  Training loss = 3.0840  Validation loss = 5.2220  \n",
      "\n",
      "Fold: 10  Epoch: 63  Training loss = 3.0838  Validation loss = 5.2213  \n",
      "\n",
      "Fold: 10  Epoch: 64  Training loss = 3.0830  Validation loss = 5.2185  \n",
      "\n",
      "Fold: 10  Epoch: 65  Training loss = 3.0826  Validation loss = 5.2167  \n",
      "\n",
      "Fold: 10  Epoch: 66  Training loss = 3.0825  Validation loss = 5.2163  \n",
      "\n",
      "Fold: 10  Epoch: 67  Training loss = 3.0821  Validation loss = 5.2149  \n",
      "\n",
      "Fold: 10  Epoch: 68  Training loss = 3.0815  Validation loss = 5.2125  \n",
      "\n",
      "Fold: 10  Epoch: 69  Training loss = 3.0810  Validation loss = 5.2104  \n",
      "\n",
      "Fold: 10  Epoch: 70  Training loss = 3.0804  Validation loss = 5.2089  \n",
      "\n",
      "Fold: 10  Epoch: 71  Training loss = 3.0797  Validation loss = 5.2062  \n",
      "\n",
      "Fold: 10  Epoch: 72  Training loss = 3.0794  Validation loss = 5.2053  \n",
      "\n",
      "Fold: 10  Epoch: 73  Training loss = 3.0790  Validation loss = 5.2036  \n",
      "\n",
      "Fold: 10  Epoch: 74  Training loss = 3.0789  Validation loss = 5.2035  \n",
      "\n",
      "Fold: 10  Epoch: 75  Training loss = 3.0788  Validation loss = 5.2032  \n",
      "\n",
      "Fold: 10  Epoch: 76  Training loss = 3.0786  Validation loss = 5.2031  \n",
      "\n",
      "Fold: 10  Epoch: 77  Training loss = 3.0781  Validation loss = 5.2011  \n",
      "\n",
      "Fold: 10  Epoch: 78  Training loss = 3.0776  Validation loss = 5.1990  \n",
      "\n",
      "Fold: 10  Epoch: 79  Training loss = 3.0769  Validation loss = 5.1965  \n",
      "\n",
      "Fold: 10  Epoch: 80  Training loss = 3.0763  Validation loss = 5.1940  \n",
      "\n",
      "Fold: 10  Epoch: 81  Training loss = 3.0760  Validation loss = 5.1932  \n",
      "\n",
      "Fold: 10  Epoch: 82  Training loss = 3.0755  Validation loss = 5.1914  \n",
      "\n",
      "Fold: 10  Epoch: 83  Training loss = 3.0752  Validation loss = 5.1905  \n",
      "\n",
      "Fold: 10  Epoch: 84  Training loss = 3.0746  Validation loss = 5.1883  \n",
      "\n",
      "Fold: 10  Epoch: 85  Training loss = 3.0738  Validation loss = 5.1854  \n",
      "\n",
      "Fold: 10  Epoch: 86  Training loss = 3.0735  Validation loss = 5.1845  \n",
      "\n",
      "Fold: 10  Epoch: 87  Training loss = 3.0732  Validation loss = 5.1831  \n",
      "\n",
      "Fold: 10  Epoch: 88  Training loss = 3.0726  Validation loss = 5.1811  \n",
      "\n",
      "Fold: 10  Epoch: 89  Training loss = 3.0721  Validation loss = 5.1798  \n",
      "\n",
      "Fold: 10  Epoch: 90  Training loss = 3.0717  Validation loss = 5.1784  \n",
      "\n",
      "Fold: 10  Epoch: 91  Training loss = 3.0714  Validation loss = 5.1771  \n",
      "\n",
      "Fold: 10  Epoch: 92  Training loss = 3.0714  Validation loss = 5.1772  \n",
      "\n",
      "Fold: 10  Epoch: 93  Training loss = 3.0708  Validation loss = 5.1749  \n",
      "\n",
      "Fold: 10  Epoch: 94  Training loss = 3.0706  Validation loss = 5.1744  \n",
      "\n",
      "Fold: 10  Epoch: 95  Training loss = 3.0704  Validation loss = 5.1737  \n",
      "\n",
      "Fold: 10  Epoch: 96  Training loss = 3.0701  Validation loss = 5.1727  \n",
      "\n",
      "Fold: 10  Epoch: 97  Training loss = 3.0696  Validation loss = 5.1709  \n",
      "\n",
      "Fold: 10  Epoch: 98  Training loss = 3.0688  Validation loss = 5.1678  \n",
      "\n",
      "Fold: 10  Epoch: 99  Training loss = 3.0682  Validation loss = 5.1654  \n",
      "\n",
      "Fold: 10  Epoch: 100  Training loss = 3.0680  Validation loss = 5.1649  \n",
      "\n",
      "Fold: 10  Epoch: 101  Training loss = 3.0674  Validation loss = 5.1633  \n",
      "\n",
      "Fold: 10  Epoch: 102  Training loss = 3.0667  Validation loss = 5.1611  \n",
      "\n",
      "Fold: 10  Epoch: 103  Training loss = 3.0666  Validation loss = 5.1605  \n",
      "\n",
      "Fold: 10  Epoch: 104  Training loss = 3.0660  Validation loss = 5.1582  \n",
      "\n",
      "Fold: 10  Epoch: 105  Training loss = 3.0656  Validation loss = 5.1569  \n",
      "\n",
      "Fold: 10  Epoch: 106  Training loss = 3.0650  Validation loss = 5.1546  \n",
      "\n",
      "Fold: 10  Epoch: 107  Training loss = 3.0647  Validation loss = 5.1534  \n",
      "\n",
      "Fold: 10  Epoch: 108  Training loss = 3.0645  Validation loss = 5.1530  \n",
      "\n",
      "Fold: 10  Epoch: 109  Training loss = 3.0641  Validation loss = 5.1515  \n",
      "\n",
      "Fold: 10  Epoch: 110  Training loss = 3.0634  Validation loss = 5.1488  \n",
      "\n",
      "Fold: 10  Epoch: 111  Training loss = 3.0632  Validation loss = 5.1482  \n",
      "\n",
      "Fold: 10  Epoch: 112  Training loss = 3.0629  Validation loss = 5.1473  \n",
      "\n",
      "Fold: 10  Epoch: 113  Training loss = 3.0621  Validation loss = 5.1441  \n",
      "\n",
      "Fold: 10  Epoch: 114  Training loss = 3.0616  Validation loss = 5.1422  \n",
      "\n",
      "Fold: 10  Epoch: 115  Training loss = 3.0614  Validation loss = 5.1418  \n",
      "\n",
      "Fold: 10  Epoch: 116  Training loss = 3.0609  Validation loss = 5.1392  \n",
      "\n",
      "Fold: 10  Epoch: 117  Training loss = 3.0608  Validation loss = 5.1392  \n",
      "\n",
      "Fold: 10  Epoch: 118  Training loss = 3.0603  Validation loss = 5.1378  \n",
      "\n",
      "Fold: 10  Epoch: 119  Training loss = 3.0600  Validation loss = 5.1368  \n",
      "\n",
      "Fold: 10  Epoch: 120  Training loss = 3.0600  Validation loss = 5.1367  \n",
      "\n",
      "Fold: 10  Epoch: 121  Training loss = 3.0598  Validation loss = 5.1358  \n",
      "\n",
      "Fold: 10  Epoch: 122  Training loss = 3.0594  Validation loss = 5.1343  \n",
      "\n",
      "Fold: 10  Epoch: 123  Training loss = 3.0586  Validation loss = 5.1312  \n",
      "\n",
      "Fold: 10  Epoch: 124  Training loss = 3.0583  Validation loss = 5.1303  \n",
      "\n",
      "Fold: 10  Epoch: 125  Training loss = 3.0578  Validation loss = 5.1282  \n",
      "\n",
      "Fold: 10  Epoch: 126  Training loss = 3.0575  Validation loss = 5.1276  \n",
      "\n",
      "Fold: 10  Epoch: 127  Training loss = 3.0571  Validation loss = 5.1259  \n",
      "\n",
      "Fold: 10  Epoch: 128  Training loss = 3.0569  Validation loss = 5.1253  \n",
      "\n",
      "Fold: 10  Epoch: 129  Training loss = 3.0564  Validation loss = 5.1235  \n",
      "\n",
      "Fold: 10  Epoch: 130  Training loss = 3.0558  Validation loss = 5.1215  \n",
      "\n",
      "Fold: 10  Epoch: 131  Training loss = 3.0554  Validation loss = 5.1200  \n",
      "\n",
      "Fold: 10  Epoch: 132  Training loss = 3.0550  Validation loss = 5.1187  \n",
      "\n",
      "Fold: 10  Epoch: 133  Training loss = 3.0546  Validation loss = 5.1172  \n",
      "\n",
      "Fold: 10  Epoch: 134  Training loss = 3.0546  Validation loss = 5.1174  \n",
      "\n",
      "Fold: 10  Epoch: 135  Training loss = 3.0543  Validation loss = 5.1162  \n",
      "\n",
      "Fold: 10  Epoch: 136  Training loss = 3.0543  Validation loss = 5.1162  \n",
      "\n",
      "Fold: 10  Epoch: 137  Training loss = 3.0538  Validation loss = 5.1144  \n",
      "\n",
      "Fold: 10  Epoch: 138  Training loss = 3.0535  Validation loss = 5.1134  \n",
      "\n",
      "Fold: 10  Epoch: 139  Training loss = 3.0533  Validation loss = 5.1130  \n",
      "\n",
      "Fold: 10  Epoch: 140  Training loss = 3.0532  Validation loss = 5.1129  \n",
      "\n",
      "Fold: 10  Epoch: 141  Training loss = 3.0529  Validation loss = 5.1115  \n",
      "\n",
      "Fold: 10  Epoch: 142  Training loss = 3.0526  Validation loss = 5.1105  \n",
      "\n",
      "Fold: 10  Epoch: 143  Training loss = 3.0523  Validation loss = 5.1097  \n",
      "\n",
      "Fold: 10  Epoch: 144  Training loss = 3.0518  Validation loss = 5.1078  \n",
      "\n",
      "Fold: 10  Epoch: 145  Training loss = 3.0513  Validation loss = 5.1058  \n",
      "\n",
      "Fold: 10  Epoch: 146  Training loss = 3.0509  Validation loss = 5.1043  \n",
      "\n",
      "Fold: 10  Epoch: 147  Training loss = 3.0506  Validation loss = 5.1030  \n",
      "\n",
      "Fold: 10  Epoch: 148  Training loss = 3.0502  Validation loss = 5.1018  \n",
      "\n",
      "Fold: 10  Epoch: 149  Training loss = 3.0498  Validation loss = 5.1001  \n",
      "\n",
      "Fold: 10  Epoch: 150  Training loss = 3.0496  Validation loss = 5.0993  \n",
      "\n",
      "Fold: 10  Epoch: 151  Training loss = 3.0493  Validation loss = 5.0981  \n",
      "\n",
      "Fold: 10  Epoch: 152  Training loss = 3.0491  Validation loss = 5.0976  \n",
      "\n",
      "Fold: 10  Epoch: 153  Training loss = 3.0487  Validation loss = 5.0961  \n",
      "\n",
      "Fold: 10  Epoch: 154  Training loss = 3.0484  Validation loss = 5.0951  \n",
      "\n",
      "Fold: 10  Epoch: 155  Training loss = 3.0480  Validation loss = 5.0936  \n",
      "\n",
      "Fold: 10  Epoch: 156  Training loss = 3.0473  Validation loss = 5.0916  \n",
      "\n",
      "Fold: 10  Epoch: 157  Training loss = 3.0470  Validation loss = 5.0903  \n",
      "\n",
      "Fold: 10  Epoch: 158  Training loss = 3.0465  Validation loss = 5.0884  \n",
      "\n",
      "Fold: 10  Epoch: 159  Training loss = 3.0463  Validation loss = 5.0873  \n",
      "\n",
      "Fold: 10  Epoch: 160  Training loss = 3.0458  Validation loss = 5.0856  \n",
      "\n",
      "Fold: 10  Epoch: 161  Training loss = 3.0453  Validation loss = 5.0837  \n",
      "\n",
      "Fold: 10  Epoch: 162  Training loss = 3.0451  Validation loss = 5.0830  \n",
      "\n",
      "Fold: 10  Epoch: 163  Training loss = 3.0448  Validation loss = 5.0816  \n",
      "\n",
      "Fold: 10  Epoch: 164  Training loss = 3.0445  Validation loss = 5.0809  \n",
      "\n",
      "Fold: 10  Epoch: 165  Training loss = 3.0442  Validation loss = 5.0799  \n",
      "\n",
      "Fold: 10  Epoch: 166  Training loss = 3.0439  Validation loss = 5.0785  \n",
      "\n",
      "Fold: 10  Epoch: 167  Training loss = 3.0437  Validation loss = 5.0781  \n",
      "\n",
      "Fold: 10  Epoch: 168  Training loss = 3.0435  Validation loss = 5.0774  \n",
      "\n",
      "Fold: 10  Epoch: 169  Training loss = 3.0433  Validation loss = 5.0771  \n",
      "\n",
      "Fold: 10  Epoch: 170  Training loss = 3.0427  Validation loss = 5.0751  \n",
      "\n",
      "Fold: 10  Epoch: 171  Training loss = 3.0425  Validation loss = 5.0746  \n",
      "\n",
      "Fold: 10  Epoch: 172  Training loss = 3.0422  Validation loss = 5.0733  \n",
      "\n",
      "Fold: 10  Epoch: 173  Training loss = 3.0416  Validation loss = 5.0714  \n",
      "\n",
      "Fold: 10  Epoch: 174  Training loss = 3.0415  Validation loss = 5.0709  \n",
      "\n",
      "Fold: 10  Epoch: 175  Training loss = 3.0415  Validation loss = 5.0715  \n",
      "\n",
      "Fold: 10  Epoch: 176  Training loss = 3.0414  Validation loss = 5.0713  \n",
      "\n",
      "Fold: 10  Epoch: 177  Training loss = 3.0411  Validation loss = 5.0698  \n",
      "\n",
      "Fold: 10  Epoch: 178  Training loss = 3.0408  Validation loss = 5.0687  \n",
      "\n",
      "Fold: 10  Epoch: 179  Training loss = 3.0406  Validation loss = 5.0677  \n",
      "\n",
      "Fold: 10  Epoch: 180  Training loss = 3.0404  Validation loss = 5.0669  \n",
      "\n",
      "Fold: 10  Epoch: 181  Training loss = 3.0398  Validation loss = 5.0647  \n",
      "\n",
      "Fold: 10  Epoch: 182  Training loss = 3.0394  Validation loss = 5.0633  \n",
      "\n",
      "Fold: 10  Epoch: 183  Training loss = 3.0391  Validation loss = 5.0623  \n",
      "\n",
      "Fold: 10  Epoch: 184  Training loss = 3.0388  Validation loss = 5.0612  \n",
      "\n",
      "Fold: 10  Epoch: 185  Training loss = 3.0386  Validation loss = 5.0604  \n",
      "\n",
      "Fold: 10  Epoch: 186  Training loss = 3.0385  Validation loss = 5.0599  \n",
      "\n",
      "Fold: 10  Epoch: 187  Training loss = 3.0381  Validation loss = 5.0585  \n",
      "\n",
      "Fold: 10  Epoch: 188  Training loss = 3.0377  Validation loss = 5.0573  \n",
      "\n",
      "Fold: 10  Epoch: 189  Training loss = 3.0374  Validation loss = 5.0559  \n",
      "\n",
      "Fold: 10  Epoch: 190  Training loss = 3.0369  Validation loss = 5.0541  \n",
      "\n",
      "Fold: 10  Epoch: 191  Training loss = 3.0363  Validation loss = 5.0518  \n",
      "\n",
      "Fold: 10  Epoch: 192  Training loss = 3.0359  Validation loss = 5.0501  \n",
      "\n",
      "Fold: 10  Epoch: 193  Training loss = 3.0354  Validation loss = 5.0485  \n",
      "\n",
      "Fold: 10  Epoch: 194  Training loss = 3.0354  Validation loss = 5.0487  \n",
      "\n",
      "Fold: 10  Epoch: 195  Training loss = 3.0351  Validation loss = 5.0475  \n",
      "\n",
      "Fold: 10  Epoch: 196  Training loss = 3.0346  Validation loss = 5.0454  \n",
      "\n",
      "Fold: 10  Epoch: 197  Training loss = 3.0346  Validation loss = 5.0455  \n",
      "\n",
      "Fold: 10  Epoch: 198  Training loss = 3.0341  Validation loss = 5.0433  \n",
      "\n",
      "Fold: 10  Epoch: 199  Training loss = 3.0338  Validation loss = 5.0423  \n",
      "\n",
      "Fold: 10  Epoch: 200  Training loss = 3.0335  Validation loss = 5.0414  \n",
      "\n",
      "Fold: 10  Epoch: 201  Training loss = 3.0334  Validation loss = 5.0412  \n",
      "\n",
      "Fold: 10  Epoch: 202  Training loss = 3.0332  Validation loss = 5.0403  \n",
      "\n",
      "Fold: 10  Epoch: 203  Training loss = 3.0330  Validation loss = 5.0397  \n",
      "\n",
      "Fold: 10  Epoch: 204  Training loss = 3.0327  Validation loss = 5.0387  \n",
      "\n",
      "Fold: 10  Epoch: 205  Training loss = 3.0324  Validation loss = 5.0376  \n",
      "\n",
      "Fold: 10  Epoch: 206  Training loss = 3.0321  Validation loss = 5.0366  \n",
      "\n",
      "Fold: 10  Epoch: 207  Training loss = 3.0316  Validation loss = 5.0342  \n",
      "\n",
      "Fold: 10  Epoch: 208  Training loss = 3.0313  Validation loss = 5.0336  \n",
      "\n",
      "Fold: 10  Epoch: 209  Training loss = 3.0311  Validation loss = 5.0326  \n",
      "\n",
      "Fold: 10  Epoch: 210  Training loss = 3.0306  Validation loss = 5.0307  \n",
      "\n",
      "Fold: 10  Epoch: 211  Training loss = 3.0307  Validation loss = 5.0311  \n",
      "\n",
      "Fold: 10  Epoch: 212  Training loss = 3.0304  Validation loss = 5.0303  \n",
      "\n",
      "Fold: 10  Epoch: 213  Training loss = 3.0298  Validation loss = 5.0278  \n",
      "\n",
      "Fold: 10  Epoch: 214  Training loss = 3.0297  Validation loss = 5.0277  \n",
      "\n",
      "Fold: 10  Epoch: 215  Training loss = 3.0294  Validation loss = 5.0264  \n",
      "\n",
      "Fold: 10  Epoch: 216  Training loss = 3.0291  Validation loss = 5.0254  \n",
      "\n",
      "Fold: 10  Epoch: 217  Training loss = 3.0289  Validation loss = 5.0243  \n",
      "\n",
      "Fold: 10  Epoch: 218  Training loss = 3.0285  Validation loss = 5.0229  \n",
      "\n",
      "Fold: 10  Epoch: 219  Training loss = 3.0281  Validation loss = 5.0212  \n",
      "\n",
      "Fold: 10  Epoch: 220  Training loss = 3.0279  Validation loss = 5.0204  \n",
      "\n",
      "Fold: 10  Epoch: 221  Training loss = 3.0278  Validation loss = 5.0201  \n",
      "\n",
      "Fold: 10  Epoch: 222  Training loss = 3.0275  Validation loss = 5.0190  \n",
      "\n",
      "Fold: 10  Epoch: 223  Training loss = 3.0271  Validation loss = 5.0178  \n",
      "\n",
      "Fold: 10  Epoch: 224  Training loss = 3.0271  Validation loss = 5.0177  \n",
      "\n",
      "Fold: 10  Epoch: 225  Training loss = 3.0267  Validation loss = 5.0161  \n",
      "\n",
      "Fold: 10  Epoch: 226  Training loss = 3.0263  Validation loss = 5.0146  \n",
      "\n",
      "Fold: 10  Epoch: 227  Training loss = 3.0262  Validation loss = 5.0141  \n",
      "\n",
      "Fold: 10  Epoch: 228  Training loss = 3.0260  Validation loss = 5.0132  \n",
      "\n",
      "Fold: 10  Epoch: 229  Training loss = 3.0254  Validation loss = 5.0108  \n",
      "\n",
      "Fold: 10  Epoch: 230  Training loss = 3.0252  Validation loss = 5.0100  \n",
      "\n",
      "Fold: 10  Epoch: 231  Training loss = 3.0249  Validation loss = 5.0091  \n",
      "\n",
      "Fold: 10  Epoch: 232  Training loss = 3.0246  Validation loss = 5.0075  \n",
      "\n",
      "Fold: 10  Epoch: 233  Training loss = 3.0246  Validation loss = 5.0073  \n",
      "\n",
      "Fold: 10  Epoch: 234  Training loss = 3.0245  Validation loss = 5.0072  \n",
      "\n",
      "Fold: 10  Epoch: 235  Training loss = 3.0245  Validation loss = 5.0072  \n",
      "\n",
      "Fold: 10  Epoch: 236  Training loss = 3.0238  Validation loss = 5.0041  \n",
      "\n",
      "Fold: 10  Epoch: 237  Training loss = 3.0234  Validation loss = 5.0026  \n",
      "\n",
      "Fold: 10  Epoch: 238  Training loss = 3.0230  Validation loss = 5.0014  \n",
      "\n",
      "Fold: 10  Epoch: 239  Training loss = 3.0225  Validation loss = 4.9992  \n",
      "\n",
      "Fold: 10  Epoch: 240  Training loss = 3.0222  Validation loss = 4.9980  \n",
      "\n",
      "Fold: 10  Epoch: 241  Training loss = 3.0218  Validation loss = 4.9963  \n",
      "\n",
      "Fold: 10  Epoch: 242  Training loss = 3.0214  Validation loss = 4.9948  \n",
      "\n",
      "Fold: 10  Epoch: 243  Training loss = 3.0212  Validation loss = 4.9938  \n",
      "\n",
      "Fold: 10  Epoch: 244  Training loss = 3.0212  Validation loss = 4.9944  \n",
      "\n",
      "Fold: 10  Epoch: 245  Training loss = 3.0209  Validation loss = 4.9934  \n",
      "\n",
      "Fold: 10  Epoch: 246  Training loss = 3.0208  Validation loss = 4.9928  \n",
      "\n",
      "Fold: 10  Epoch: 247  Training loss = 3.0202  Validation loss = 4.9901  \n",
      "\n",
      "Fold: 10  Epoch: 248  Training loss = 3.0197  Validation loss = 4.9880  \n",
      "\n",
      "Fold: 10  Epoch: 249  Training loss = 3.0194  Validation loss = 4.9867  \n",
      "\n",
      "Fold: 10  Epoch: 250  Training loss = 3.0191  Validation loss = 4.9858  \n",
      "\n",
      "Fold: 10  Epoch: 251  Training loss = 3.0187  Validation loss = 4.9841  \n",
      "\n",
      "Fold: 10  Epoch: 252  Training loss = 3.0183  Validation loss = 4.9823  \n",
      "\n",
      "Fold: 10  Epoch: 253  Training loss = 3.0180  Validation loss = 4.9808  \n",
      "\n",
      "Fold: 10  Epoch: 254  Training loss = 3.0178  Validation loss = 4.9801  \n",
      "\n",
      "Fold: 10  Epoch: 255  Training loss = 3.0174  Validation loss = 4.9785  \n",
      "\n",
      "Fold: 10  Epoch: 256  Training loss = 3.0173  Validation loss = 4.9781  \n",
      "\n",
      "Fold: 10  Epoch: 257  Training loss = 3.0169  Validation loss = 4.9767  \n",
      "\n",
      "Fold: 10  Epoch: 258  Training loss = 3.0167  Validation loss = 4.9761  \n",
      "\n",
      "Fold: 10  Epoch: 259  Training loss = 3.0165  Validation loss = 4.9752  \n",
      "\n",
      "Fold: 10  Epoch: 260  Training loss = 3.0163  Validation loss = 4.9747  \n",
      "\n",
      "Fold: 10  Epoch: 261  Training loss = 3.0162  Validation loss = 4.9744  \n",
      "\n",
      "Fold: 10  Epoch: 262  Training loss = 3.0161  Validation loss = 4.9740  \n",
      "\n",
      "Fold: 10  Epoch: 263  Training loss = 3.0157  Validation loss = 4.9724  \n",
      "\n",
      "Fold: 10  Epoch: 264  Training loss = 3.0152  Validation loss = 4.9702  \n",
      "\n",
      "Fold: 10  Epoch: 265  Training loss = 3.0149  Validation loss = 4.9686  \n",
      "\n",
      "Fold: 10  Epoch: 266  Training loss = 3.0147  Validation loss = 4.9679  \n",
      "\n",
      "Fold: 10  Epoch: 267  Training loss = 3.0144  Validation loss = 4.9663  \n",
      "\n",
      "Fold: 10  Epoch: 268  Training loss = 3.0140  Validation loss = 4.9650  \n",
      "\n",
      "Fold: 10  Epoch: 269  Training loss = 3.0138  Validation loss = 4.9645  \n",
      "\n",
      "Fold: 10  Epoch: 270  Training loss = 3.0137  Validation loss = 4.9643  \n",
      "\n",
      "Fold: 10  Epoch: 271  Training loss = 3.0136  Validation loss = 4.9642  \n",
      "\n",
      "Fold: 10  Epoch: 272  Training loss = 3.0135  Validation loss = 4.9639  \n",
      "\n",
      "Fold: 10  Epoch: 273  Training loss = 3.0132  Validation loss = 4.9626  \n",
      "\n",
      "Fold: 10  Epoch: 274  Training loss = 3.0128  Validation loss = 4.9610  \n",
      "\n",
      "Fold: 10  Epoch: 275  Training loss = 3.0124  Validation loss = 4.9589  \n",
      "\n",
      "Fold: 10  Epoch: 276  Training loss = 3.0121  Validation loss = 4.9579  \n",
      "\n",
      "Fold: 10  Epoch: 277  Training loss = 3.0117  Validation loss = 4.9563  \n",
      "\n",
      "Fold: 10  Epoch: 278  Training loss = 3.0114  Validation loss = 4.9550  \n",
      "\n",
      "Fold: 10  Epoch: 279  Training loss = 3.0110  Validation loss = 4.9534  \n",
      "\n",
      "Fold: 10  Epoch: 280  Training loss = 3.0108  Validation loss = 4.9524  \n",
      "\n",
      "Fold: 10  Epoch: 281  Training loss = 3.0104  Validation loss = 4.9508  \n",
      "\n",
      "Fold: 10  Epoch: 282  Training loss = 3.0101  Validation loss = 4.9492  \n",
      "\n",
      "Fold: 10  Epoch: 283  Training loss = 3.0100  Validation loss = 4.9490  \n",
      "\n",
      "Fold: 10  Epoch: 284  Training loss = 3.0096  Validation loss = 4.9474  \n",
      "\n",
      "Fold: 10  Epoch: 285  Training loss = 3.0092  Validation loss = 4.9453  \n",
      "\n",
      "Fold: 10  Epoch: 286  Training loss = 3.0089  Validation loss = 4.9444  \n",
      "\n",
      "Fold: 10  Epoch: 287  Training loss = 3.0084  Validation loss = 4.9417  \n",
      "\n",
      "Fold: 10  Epoch: 288  Training loss = 3.0081  Validation loss = 4.9406  \n",
      "\n",
      "Fold: 10  Epoch: 289  Training loss = 3.0080  Validation loss = 4.9399  \n",
      "\n",
      "Fold: 10  Epoch: 290  Training loss = 3.0077  Validation loss = 4.9387  \n",
      "\n",
      "Fold: 10  Epoch: 291  Training loss = 3.0077  Validation loss = 4.9387  \n",
      "\n",
      "Fold: 10  Epoch: 292  Training loss = 3.0076  Validation loss = 4.9388  \n",
      "\n",
      "Fold: 10  Epoch: 293  Training loss = 3.0073  Validation loss = 4.9372  \n",
      "\n",
      "Fold: 10  Epoch: 294  Training loss = 3.0070  Validation loss = 4.9354  \n",
      "\n",
      "Fold: 10  Epoch: 295  Training loss = 3.0067  Validation loss = 4.9343  \n",
      "\n",
      "Fold: 10  Epoch: 296  Training loss = 3.0065  Validation loss = 4.9334  \n",
      "\n",
      "Fold: 10  Epoch: 297  Training loss = 3.0063  Validation loss = 4.9328  \n",
      "\n",
      "Fold: 10  Epoch: 298  Training loss = 3.0059  Validation loss = 4.9302  \n",
      "\n",
      "Fold: 10  Epoch: 299  Training loss = 3.0056  Validation loss = 4.9286  \n",
      "\n",
      "Fold: 10  Epoch: 300  Training loss = 3.0052  Validation loss = 4.9266  \n",
      "\n",
      "Fold: 10  Epoch: 301  Training loss = 3.0052  Validation loss = 4.9269  \n",
      "\n",
      "Fold: 10  Epoch: 302  Training loss = 3.0051  Validation loss = 4.9263  \n",
      "\n",
      "Fold: 10  Epoch: 303  Training loss = 3.0049  Validation loss = 4.9254  \n",
      "\n",
      "Fold: 10  Epoch: 304  Training loss = 3.0048  Validation loss = 4.9250  \n",
      "\n",
      "Fold: 10  Epoch: 305  Training loss = 3.0045  Validation loss = 4.9236  \n",
      "\n",
      "Fold: 10  Epoch: 306  Training loss = 3.0043  Validation loss = 4.9225  \n",
      "\n",
      "Fold: 10  Epoch: 307  Training loss = 3.0041  Validation loss = 4.9214  \n",
      "\n",
      "Fold: 10  Epoch: 308  Training loss = 3.0034  Validation loss = 4.9174  \n",
      "\n",
      "Fold: 10  Epoch: 309  Training loss = 3.0033  Validation loss = 4.9164  \n",
      "\n",
      "Fold: 10  Epoch: 310  Training loss = 3.0031  Validation loss = 4.9155  \n",
      "\n",
      "Fold: 10  Epoch: 311  Training loss = 3.0030  Validation loss = 4.9151  \n",
      "\n",
      "Fold: 10  Epoch: 312  Training loss = 3.0028  Validation loss = 4.9136  \n",
      "\n",
      "Fold: 10  Epoch: 313  Training loss = 3.0024  Validation loss = 4.9119  \n",
      "\n",
      "Fold: 10  Epoch: 314  Training loss = 3.0023  Validation loss = 4.9111  \n",
      "\n",
      "Fold: 10  Epoch: 315  Training loss = 3.0020  Validation loss = 4.9106  \n",
      "\n",
      "Fold: 10  Epoch: 316  Training loss = 3.0017  Validation loss = 4.9082  \n",
      "\n",
      "Fold: 10  Epoch: 317  Training loss = 3.0014  Validation loss = 4.9061  \n",
      "\n",
      "Fold: 10  Epoch: 318  Training loss = 3.0011  Validation loss = 4.9043  \n",
      "\n",
      "Fold: 10  Epoch: 319  Training loss = 3.0011  Validation loss = 4.9043  \n",
      "\n",
      "Fold: 10  Epoch: 320  Training loss = 3.0006  Validation loss = 4.9020  \n",
      "\n",
      "Fold: 10  Epoch: 321  Training loss = 3.0003  Validation loss = 4.9000  \n",
      "\n",
      "Fold: 10  Epoch: 322  Training loss = 3.0000  Validation loss = 4.8980  \n",
      "\n",
      "Fold: 10  Epoch: 323  Training loss = 2.9997  Validation loss = 4.8965  \n",
      "\n",
      "Fold: 10  Epoch: 324  Training loss = 2.9994  Validation loss = 4.8941  \n",
      "\n",
      "Fold: 10  Epoch: 325  Training loss = 2.9991  Validation loss = 4.8929  \n",
      "\n",
      "Fold: 10  Epoch: 326  Training loss = 2.9988  Validation loss = 4.8910  \n",
      "\n",
      "Fold: 10  Epoch: 327  Training loss = 2.9985  Validation loss = 4.8891  \n",
      "\n",
      "Fold: 10  Epoch: 328  Training loss = 2.9984  Validation loss = 4.8887  \n",
      "\n",
      "Fold: 10  Epoch: 329  Training loss = 2.9982  Validation loss = 4.8877  \n",
      "\n",
      "Fold: 10  Epoch: 330  Training loss = 2.9979  Validation loss = 4.8853  \n",
      "\n",
      "Fold: 10  Epoch: 331  Training loss = 2.9974  Validation loss = 4.8823  \n",
      "\n",
      "Fold: 10  Epoch: 332  Training loss = 2.9969  Validation loss = 4.8790  \n",
      "\n",
      "Fold: 10  Epoch: 333  Training loss = 2.9968  Validation loss = 4.8787  \n",
      "\n",
      "Fold: 10  Epoch: 334  Training loss = 2.9964  Validation loss = 4.8759  \n",
      "\n",
      "Fold: 10  Epoch: 335  Training loss = 2.9957  Validation loss = 4.8705  \n",
      "\n",
      "Fold: 10  Epoch: 336  Training loss = 2.9954  Validation loss = 4.8693  \n",
      "\n",
      "Fold: 10  Epoch: 337  Training loss = 2.9950  Validation loss = 4.8655  \n",
      "\n",
      "Fold: 10  Epoch: 338  Training loss = 2.9947  Validation loss = 4.8631  \n",
      "\n",
      "Fold: 10  Epoch: 339  Training loss = 2.9945  Validation loss = 4.8624  \n",
      "\n",
      "Fold: 10  Epoch: 340  Training loss = 2.9940  Validation loss = 4.8595  \n",
      "\n",
      "Fold: 10  Epoch: 341  Training loss = 2.9935  Validation loss = 4.8556  \n",
      "\n",
      "Fold: 10  Epoch: 342  Training loss = 2.9931  Validation loss = 4.8541  \n",
      "\n",
      "Fold: 10  Epoch: 343  Training loss = 2.9924  Validation loss = 4.8483  \n",
      "\n",
      "Fold: 10  Epoch: 344  Training loss = 2.9921  Validation loss = 4.8460  \n",
      "\n",
      "Fold: 10  Epoch: 345  Training loss = 2.9915  Validation loss = 4.8411  \n",
      "\n",
      "Fold: 10  Epoch: 346  Training loss = 2.9912  Validation loss = 4.8389  \n",
      "\n",
      "Fold: 10  Epoch: 347  Training loss = 2.9910  Validation loss = 4.8374  \n",
      "\n",
      "Fold: 10  Epoch: 348  Training loss = 2.9907  Validation loss = 4.8358  \n",
      "\n",
      "Fold: 10  Epoch: 349  Training loss = 2.9901  Validation loss = 4.8312  \n",
      "\n",
      "Fold: 10  Epoch: 350  Training loss = 2.9901  Validation loss = 4.8314  \n",
      "\n",
      "Fold: 10  Epoch: 351  Training loss = 2.9900  Validation loss = 4.8312  \n",
      "\n",
      "Fold: 10  Epoch: 352  Training loss = 2.9897  Validation loss = 4.8294  \n",
      "\n",
      "Fold: 10  Epoch: 353  Training loss = 2.9893  Validation loss = 4.8264  \n",
      "\n",
      "Fold: 10  Epoch: 354  Training loss = 2.9888  Validation loss = 4.8223  \n",
      "\n",
      "Fold: 10  Epoch: 355  Training loss = 2.9885  Validation loss = 4.8207  \n",
      "\n",
      "Fold: 10  Epoch: 356  Training loss = 2.9882  Validation loss = 4.8192  \n",
      "\n",
      "Fold: 10  Epoch: 357  Training loss = 2.9880  Validation loss = 4.8177  \n",
      "\n",
      "Fold: 10  Epoch: 358  Training loss = 2.9875  Validation loss = 4.8139  \n",
      "\n",
      "Fold: 10  Epoch: 359  Training loss = 2.9873  Validation loss = 4.8129  \n",
      "\n",
      "Fold: 10  Epoch: 360  Training loss = 2.9869  Validation loss = 4.8101  \n",
      "\n",
      "Fold: 10  Epoch: 361  Training loss = 2.9867  Validation loss = 4.8089  \n",
      "\n",
      "Fold: 10  Epoch: 362  Training loss = 2.9864  Validation loss = 4.8073  \n",
      "\n",
      "Fold: 10  Epoch: 363  Training loss = 2.9861  Validation loss = 4.8056  \n",
      "\n",
      "Fold: 10  Epoch: 364  Training loss = 2.9859  Validation loss = 4.8046  \n",
      "\n",
      "Fold: 10  Epoch: 365  Training loss = 2.9855  Validation loss = 4.8024  \n",
      "\n",
      "Fold: 10  Epoch: 366  Training loss = 2.9852  Validation loss = 4.8001  \n",
      "\n",
      "Fold: 10  Epoch: 367  Training loss = 2.9847  Validation loss = 4.7971  \n",
      "\n",
      "Fold: 10  Epoch: 368  Training loss = 2.9844  Validation loss = 4.7954  \n",
      "\n",
      "Fold: 10  Epoch: 369  Training loss = 2.9841  Validation loss = 4.7932  \n",
      "\n",
      "Fold: 10  Epoch: 370  Training loss = 2.9838  Validation loss = 4.7912  \n",
      "\n",
      "Fold: 10  Epoch: 371  Training loss = 2.9834  Validation loss = 4.7890  \n",
      "\n",
      "Fold: 10  Epoch: 372  Training loss = 2.9833  Validation loss = 4.7879  \n",
      "\n",
      "Fold: 10  Epoch: 373  Training loss = 2.9830  Validation loss = 4.7868  \n",
      "\n",
      "Fold: 10  Epoch: 374  Training loss = 2.9829  Validation loss = 4.7864  \n",
      "\n",
      "Fold: 10  Epoch: 375  Training loss = 2.9828  Validation loss = 4.7864  \n",
      "\n",
      "Fold: 10  Epoch: 376  Training loss = 2.9825  Validation loss = 4.7852  \n",
      "\n",
      "Fold: 10  Epoch: 377  Training loss = 2.9823  Validation loss = 4.7834  \n",
      "\n",
      "Fold: 10  Epoch: 378  Training loss = 2.9821  Validation loss = 4.7827  \n",
      "\n",
      "Fold: 10  Epoch: 379  Training loss = 2.9817  Validation loss = 4.7806  \n",
      "\n",
      "Fold: 10  Epoch: 380  Training loss = 2.9812  Validation loss = 4.7767  \n",
      "\n",
      "Fold: 10  Epoch: 381  Training loss = 2.9809  Validation loss = 4.7751  \n",
      "\n",
      "Fold: 10  Epoch: 382  Training loss = 2.9806  Validation loss = 4.7745  \n",
      "\n",
      "Fold: 10  Epoch: 383  Training loss = 2.9803  Validation loss = 4.7720  \n",
      "\n",
      "Fold: 10  Epoch: 384  Training loss = 2.9798  Validation loss = 4.7679  \n",
      "\n",
      "Fold: 10  Epoch: 385  Training loss = 2.9796  Validation loss = 4.7669  \n",
      "\n",
      "Fold: 10  Epoch: 386  Training loss = 2.9793  Validation loss = 4.7657  \n",
      "\n",
      "Fold: 10  Epoch: 387  Training loss = 2.9790  Validation loss = 4.7637  \n",
      "\n",
      "Fold: 10  Epoch: 388  Training loss = 2.9789  Validation loss = 4.7636  \n",
      "\n",
      "Fold: 10  Epoch: 389  Training loss = 2.9786  Validation loss = 4.7619  \n",
      "\n",
      "Fold: 10  Epoch: 390  Training loss = 2.9785  Validation loss = 4.7621  \n",
      "\n",
      "Fold: 10  Epoch: 391  Training loss = 2.9784  Validation loss = 4.7617  \n",
      "\n",
      "Fold: 10  Epoch: 392  Training loss = 2.9782  Validation loss = 4.7608  \n",
      "\n",
      "Fold: 10  Epoch: 393  Training loss = 2.9776  Validation loss = 4.7563  \n",
      "\n",
      "Fold: 10  Epoch: 394  Training loss = 2.9774  Validation loss = 4.7558  \n",
      "\n",
      "Fold: 10  Epoch: 395  Training loss = 2.9770  Validation loss = 4.7542  \n",
      "\n",
      "Fold: 10  Epoch: 396  Training loss = 2.9770  Validation loss = 4.7542  \n",
      "\n",
      "Fold: 10  Epoch: 397  Training loss = 2.9769  Validation loss = 4.7541  \n",
      "\n",
      "Fold: 10  Epoch: 398  Training loss = 2.9767  Validation loss = 4.7528  \n",
      "\n",
      "Fold: 10  Epoch: 399  Training loss = 2.9766  Validation loss = 4.7526  \n",
      "\n",
      "Fold: 10  Epoch: 400  Training loss = 2.9762  Validation loss = 4.7507  \n",
      "\n",
      "Fold: 10  Epoch: 401  Training loss = 2.9759  Validation loss = 4.7482  \n",
      "\n",
      "Fold: 10  Epoch: 402  Training loss = 2.9758  Validation loss = 4.7478  \n",
      "\n",
      "Fold: 10  Epoch: 403  Training loss = 2.9755  Validation loss = 4.7465  \n",
      "\n",
      "Fold: 10  Epoch: 404  Training loss = 2.9753  Validation loss = 4.7455  \n",
      "\n",
      "Fold: 10  Epoch: 405  Training loss = 2.9750  Validation loss = 4.7442  \n",
      "\n",
      "Fold: 10  Epoch: 406  Training loss = 2.9747  Validation loss = 4.7426  \n",
      "\n",
      "Fold: 10  Epoch: 407  Training loss = 2.9745  Validation loss = 4.7418  \n",
      "\n",
      "Fold: 10  Epoch: 408  Training loss = 2.9743  Validation loss = 4.7403  \n",
      "\n",
      "Fold: 10  Epoch: 409  Training loss = 2.9739  Validation loss = 4.7381  \n",
      "\n",
      "Fold: 10  Epoch: 410  Training loss = 2.9736  Validation loss = 4.7365  \n",
      "\n",
      "Fold: 10  Epoch: 411  Training loss = 2.9732  Validation loss = 4.7347  \n",
      "\n",
      "Fold: 10  Epoch: 412  Training loss = 2.9730  Validation loss = 4.7339  \n",
      "\n",
      "Fold: 10  Epoch: 413  Training loss = 2.9729  Validation loss = 4.7337  \n",
      "\n",
      "Fold: 10  Epoch: 414  Training loss = 2.9727  Validation loss = 4.7334  \n",
      "\n",
      "Fold: 10  Epoch: 415  Training loss = 2.9725  Validation loss = 4.7325  \n",
      "\n",
      "Fold: 10  Epoch: 416  Training loss = 2.9722  Validation loss = 4.7309  \n",
      "\n",
      "Fold: 10  Epoch: 417  Training loss = 2.9722  Validation loss = 4.7312  \n",
      "\n",
      "Fold: 10  Epoch: 418  Training loss = 2.9720  Validation loss = 4.7301  \n",
      "\n",
      "Fold: 10  Epoch: 419  Training loss = 2.9719  Validation loss = 4.7302  \n",
      "\n",
      "Fold: 10  Epoch: 420  Training loss = 2.9718  Validation loss = 4.7301  \n",
      "\n",
      "Fold: 10  Epoch: 421  Training loss = 2.9716  Validation loss = 4.7296  \n",
      "\n",
      "Fold: 10  Epoch: 422  Training loss = 2.9713  Validation loss = 4.7284  \n",
      "\n",
      "Fold: 10  Epoch: 423  Training loss = 2.9711  Validation loss = 4.7270  \n",
      "\n",
      "Fold: 10  Epoch: 424  Training loss = 2.9708  Validation loss = 4.7252  \n",
      "\n",
      "Fold: 10  Epoch: 425  Training loss = 2.9704  Validation loss = 4.7237  \n",
      "\n",
      "Fold: 10  Epoch: 426  Training loss = 2.9702  Validation loss = 4.7226  \n",
      "\n",
      "Fold: 10  Epoch: 427  Training loss = 2.9699  Validation loss = 4.7216  \n",
      "\n",
      "Fold: 10  Epoch: 428  Training loss = 2.9697  Validation loss = 4.7206  \n",
      "\n",
      "Fold: 10  Epoch: 429  Training loss = 2.9694  Validation loss = 4.7192  \n",
      "\n",
      "Fold: 10  Epoch: 430  Training loss = 2.9692  Validation loss = 4.7181  \n",
      "\n",
      "Fold: 10  Epoch: 431  Training loss = 2.9689  Validation loss = 4.7173  \n",
      "\n",
      "Fold: 10  Epoch: 432  Training loss = 2.9686  Validation loss = 4.7158  \n",
      "\n",
      "Fold: 10  Epoch: 433  Training loss = 2.9684  Validation loss = 4.7151  \n",
      "\n",
      "Fold: 10  Epoch: 434  Training loss = 2.9684  Validation loss = 4.7153  \n",
      "\n",
      "Fold: 10  Epoch: 435  Training loss = 2.9683  Validation loss = 4.7147  \n",
      "\n",
      "Fold: 10  Epoch: 436  Training loss = 2.9681  Validation loss = 4.7140  \n",
      "\n",
      "Fold: 10  Epoch: 437  Training loss = 2.9678  Validation loss = 4.7128  \n",
      "\n",
      "Fold: 10  Epoch: 438  Training loss = 2.9677  Validation loss = 4.7123  \n",
      "\n",
      "Fold: 10  Epoch: 439  Training loss = 2.9674  Validation loss = 4.7112  \n",
      "\n",
      "Fold: 10  Epoch: 440  Training loss = 2.9671  Validation loss = 4.7098  \n",
      "\n",
      "Fold: 10  Epoch: 441  Training loss = 2.9667  Validation loss = 4.7077  \n",
      "\n",
      "Fold: 10  Epoch: 442  Training loss = 2.9665  Validation loss = 4.7066  \n",
      "\n",
      "Fold: 10  Epoch: 443  Training loss = 2.9663  Validation loss = 4.7063  \n",
      "\n",
      "Fold: 10  Epoch: 444  Training loss = 2.9663  Validation loss = 4.7065  \n",
      "\n",
      "Fold: 10  Epoch: 445  Training loss = 2.9661  Validation loss = 4.7062  \n",
      "\n",
      "Fold: 10  Epoch: 446  Training loss = 2.9659  Validation loss = 4.7052  \n",
      "\n",
      "Fold: 10  Epoch: 447  Training loss = 2.9657  Validation loss = 4.7052  \n",
      "\n",
      "Fold: 10  Epoch: 448  Training loss = 2.9655  Validation loss = 4.7046  \n",
      "\n",
      "Fold: 10  Epoch: 449  Training loss = 2.9652  Validation loss = 4.7033  \n",
      "\n",
      "Fold: 10  Epoch: 450  Training loss = 2.9650  Validation loss = 4.7021  \n",
      "\n",
      "Fold: 10  Epoch: 451  Training loss = 2.9649  Validation loss = 4.7022  \n",
      "\n",
      "Fold: 10  Epoch: 452  Training loss = 2.9648  Validation loss = 4.7015  \n",
      "\n",
      "Fold: 10  Epoch: 453  Training loss = 2.9647  Validation loss = 4.7024  \n",
      "\n",
      "Fold: 10  Epoch: 454  Training loss = 2.9646  Validation loss = 4.7018  \n",
      "\n",
      "Fold: 10  Epoch: 455  Training loss = 2.9643  Validation loss = 4.7005  \n",
      "\n",
      "Fold: 10  Epoch: 456  Training loss = 2.9641  Validation loss = 4.7001  \n",
      "\n",
      "Fold: 10  Epoch: 457  Training loss = 2.9639  Validation loss = 4.6991  \n",
      "\n",
      "Fold: 10  Epoch: 458  Training loss = 2.9636  Validation loss = 4.6974  \n",
      "\n",
      "Fold: 10  Epoch: 459  Training loss = 2.9635  Validation loss = 4.6981  \n",
      "\n",
      "Fold: 10  Epoch: 460  Training loss = 2.9634  Validation loss = 4.6980  \n",
      "\n",
      "Fold: 10  Epoch: 461  Training loss = 2.9631  Validation loss = 4.6964  \n",
      "\n",
      "Fold: 10  Epoch: 462  Training loss = 2.9628  Validation loss = 4.6951  \n",
      "\n",
      "Fold: 10  Epoch: 463  Training loss = 2.9626  Validation loss = 4.6946  \n",
      "\n",
      "Fold: 10  Epoch: 464  Training loss = 2.9625  Validation loss = 4.6947  \n",
      "\n",
      "Fold: 10  Epoch: 465  Training loss = 2.9623  Validation loss = 4.6938  \n",
      "\n",
      "Fold: 10  Epoch: 466  Training loss = 2.9623  Validation loss = 4.6939  \n",
      "\n",
      "Fold: 10  Epoch: 467  Training loss = 2.9620  Validation loss = 4.6927  \n",
      "\n",
      "Fold: 10  Epoch: 468  Training loss = 2.9618  Validation loss = 4.6918  \n",
      "\n",
      "Fold: 10  Epoch: 469  Training loss = 2.9617  Validation loss = 4.6920  \n",
      "\n",
      "Fold: 10  Epoch: 470  Training loss = 2.9616  Validation loss = 4.6919  \n",
      "\n",
      "Fold: 10  Epoch: 471  Training loss = 2.9615  Validation loss = 4.6916  \n",
      "\n",
      "Fold: 10  Epoch: 472  Training loss = 2.9613  Validation loss = 4.6910  \n",
      "\n",
      "Fold: 10  Epoch: 473  Training loss = 2.9610  Validation loss = 4.6893  \n",
      "\n",
      "Fold: 10  Epoch: 474  Training loss = 2.9608  Validation loss = 4.6890  \n",
      "\n",
      "Fold: 10  Epoch: 475  Training loss = 2.9606  Validation loss = 4.6882  \n",
      "\n",
      "Fold: 10  Epoch: 476  Training loss = 2.9604  Validation loss = 4.6868  \n",
      "\n",
      "Fold: 10  Epoch: 477  Training loss = 2.9601  Validation loss = 4.6854  \n",
      "\n",
      "Fold: 10  Epoch: 478  Training loss = 2.9600  Validation loss = 4.6855  \n",
      "\n",
      "Fold: 10  Epoch: 479  Training loss = 2.9597  Validation loss = 4.6848  \n",
      "\n",
      "Fold: 10  Epoch: 480  Training loss = 2.9595  Validation loss = 4.6835  \n",
      "\n",
      "Fold: 10  Epoch: 481  Training loss = 2.9591  Validation loss = 4.6819  \n",
      "\n",
      "Fold: 10  Epoch: 482  Training loss = 2.9589  Validation loss = 4.6809  \n",
      "\n",
      "Fold: 10  Epoch: 483  Training loss = 2.9588  Validation loss = 4.6805  \n",
      "\n",
      "Fold: 10  Epoch: 484  Training loss = 2.9585  Validation loss = 4.6799  \n",
      "\n",
      "Fold: 10  Epoch: 485  Training loss = 2.9584  Validation loss = 4.6788  \n",
      "\n",
      "Fold: 10  Epoch: 486  Training loss = 2.9580  Validation loss = 4.6773  \n",
      "\n",
      "Fold: 10  Epoch: 487  Training loss = 2.9578  Validation loss = 4.6763  \n",
      "\n",
      "Fold: 10  Epoch: 488  Training loss = 2.9575  Validation loss = 4.6746  \n",
      "\n",
      "Fold: 10  Epoch: 489  Training loss = 2.9573  Validation loss = 4.6741  \n",
      "\n",
      "Fold: 10  Epoch: 490  Training loss = 2.9570  Validation loss = 4.6727  \n",
      "\n",
      "Fold: 10  Epoch: 491  Training loss = 2.9567  Validation loss = 4.6710  \n",
      "\n",
      "Fold: 10  Epoch: 492  Training loss = 2.9566  Validation loss = 4.6711  \n",
      "\n",
      "Fold: 10  Epoch: 493  Training loss = 2.9565  Validation loss = 4.6712  \n",
      "\n",
      "Fold: 10  Epoch: 494  Training loss = 2.9564  Validation loss = 4.6712  \n",
      "\n",
      "Fold: 10  Epoch: 495  Training loss = 2.9562  Validation loss = 4.6707  \n",
      "\n",
      "Fold: 10  Epoch: 496  Training loss = 2.9560  Validation loss = 4.6705  \n",
      "\n",
      "Fold: 10  Epoch: 497  Training loss = 2.9559  Validation loss = 4.6705  \n",
      "\n",
      "Fold: 10  Epoch: 498  Training loss = 2.9556  Validation loss = 4.6692  \n",
      "\n",
      "Fold: 10  Epoch: 499  Training loss = 2.9553  Validation loss = 4.6675  \n",
      "\n",
      "Fold: 10  Epoch: 500  Training loss = 2.9550  Validation loss = 4.6659  \n",
      "\n",
      "Check model:  Fold: 10  Optimal epoch: 500  \n",
      "\n",
      "Fold: 11  Epoch: 1  Training loss = 3.1154  Validation loss = 1.7846  \n",
      "\n",
      "Fold: 11  Epoch: 2  Training loss = 3.1148  Validation loss = 1.7830  \n",
      "\n",
      "Fold: 11  Epoch: 3  Training loss = 3.1143  Validation loss = 1.7817  \n",
      "\n",
      "Fold: 11  Epoch: 4  Training loss = 3.1137  Validation loss = 1.7803  \n",
      "\n",
      "Fold: 11  Epoch: 5  Training loss = 3.1131  Validation loss = 1.7788  \n",
      "\n",
      "Fold: 11  Epoch: 6  Training loss = 3.1125  Validation loss = 1.7772  \n",
      "\n",
      "Fold: 11  Epoch: 7  Training loss = 3.1120  Validation loss = 1.7758  \n",
      "\n",
      "Fold: 11  Epoch: 8  Training loss = 3.1118  Validation loss = 1.7753  \n",
      "\n",
      "Fold: 11  Epoch: 9  Training loss = 3.1113  Validation loss = 1.7741  \n",
      "\n",
      "Fold: 11  Epoch: 10  Training loss = 3.1109  Validation loss = 1.7729  \n",
      "\n",
      "Fold: 11  Epoch: 11  Training loss = 3.1102  Validation loss = 1.7711  \n",
      "\n",
      "Fold: 11  Epoch: 12  Training loss = 3.1096  Validation loss = 1.7697  \n",
      "\n",
      "Fold: 11  Epoch: 13  Training loss = 3.1090  Validation loss = 1.7680  \n",
      "\n",
      "Fold: 11  Epoch: 14  Training loss = 3.1086  Validation loss = 1.7670  \n",
      "\n",
      "Fold: 11  Epoch: 15  Training loss = 3.1084  Validation loss = 1.7668  \n",
      "\n",
      "Fold: 11  Epoch: 16  Training loss = 3.1080  Validation loss = 1.7657  \n",
      "\n",
      "Fold: 11  Epoch: 17  Training loss = 3.1072  Validation loss = 1.7636  \n",
      "\n",
      "Fold: 11  Epoch: 18  Training loss = 3.1064  Validation loss = 1.7614  \n",
      "\n",
      "Fold: 11  Epoch: 19  Training loss = 3.1058  Validation loss = 1.7598  \n",
      "\n",
      "Fold: 11  Epoch: 20  Training loss = 3.1054  Validation loss = 1.7587  \n",
      "\n",
      "Fold: 11  Epoch: 21  Training loss = 3.1047  Validation loss = 1.7568  \n",
      "\n",
      "Fold: 11  Epoch: 22  Training loss = 3.1042  Validation loss = 1.7554  \n",
      "\n",
      "Fold: 11  Epoch: 23  Training loss = 3.1037  Validation loss = 1.7544  \n",
      "\n",
      "Fold: 11  Epoch: 24  Training loss = 3.1027  Validation loss = 1.7513  \n",
      "\n",
      "Fold: 11  Epoch: 25  Training loss = 3.1022  Validation loss = 1.7499  \n",
      "\n",
      "Fold: 11  Epoch: 26  Training loss = 3.1019  Validation loss = 1.7494  \n",
      "\n",
      "Fold: 11  Epoch: 27  Training loss = 3.1017  Validation loss = 1.7493  \n",
      "\n",
      "Fold: 11  Epoch: 28  Training loss = 3.1014  Validation loss = 1.7486  \n",
      "\n",
      "Fold: 11  Epoch: 29  Training loss = 3.1011  Validation loss = 1.7482  \n",
      "\n",
      "Fold: 11  Epoch: 30  Training loss = 3.1007  Validation loss = 1.7473  \n",
      "\n",
      "Fold: 11  Epoch: 31  Training loss = 3.1000  Validation loss = 1.7455  \n",
      "\n",
      "Fold: 11  Epoch: 32  Training loss = 3.0996  Validation loss = 1.7445  \n",
      "\n",
      "Fold: 11  Epoch: 33  Training loss = 3.0993  Validation loss = 1.7439  \n",
      "\n",
      "Fold: 11  Epoch: 34  Training loss = 3.0986  Validation loss = 1.7418  \n",
      "\n",
      "Fold: 11  Epoch: 35  Training loss = 3.0979  Validation loss = 1.7400  \n",
      "\n",
      "Fold: 11  Epoch: 36  Training loss = 3.0976  Validation loss = 1.7397  \n",
      "\n",
      "Fold: 11  Epoch: 37  Training loss = 3.0974  Validation loss = 1.7392  \n",
      "\n",
      "Fold: 11  Epoch: 38  Training loss = 3.0968  Validation loss = 1.7376  \n",
      "\n",
      "Fold: 11  Epoch: 39  Training loss = 3.0964  Validation loss = 1.7365  \n",
      "\n",
      "Fold: 11  Epoch: 40  Training loss = 3.0959  Validation loss = 1.7352  \n",
      "\n",
      "Fold: 11  Epoch: 41  Training loss = 3.0954  Validation loss = 1.7342  \n",
      "\n",
      "Fold: 11  Epoch: 42  Training loss = 3.0949  Validation loss = 1.7327  \n",
      "\n",
      "Fold: 11  Epoch: 43  Training loss = 3.0944  Validation loss = 1.7316  \n",
      "\n",
      "Fold: 11  Epoch: 44  Training loss = 3.0941  Validation loss = 1.7308  \n",
      "\n",
      "Fold: 11  Epoch: 45  Training loss = 3.0938  Validation loss = 1.7304  \n",
      "\n",
      "Fold: 11  Epoch: 46  Training loss = 3.0935  Validation loss = 1.7295  \n",
      "\n",
      "Fold: 11  Epoch: 47  Training loss = 3.0932  Validation loss = 1.7292  \n",
      "\n",
      "Fold: 11  Epoch: 48  Training loss = 3.0925  Validation loss = 1.7270  \n",
      "\n",
      "Fold: 11  Epoch: 49  Training loss = 3.0918  Validation loss = 1.7252  \n",
      "\n",
      "Fold: 11  Epoch: 50  Training loss = 3.0914  Validation loss = 1.7240  \n",
      "\n",
      "Fold: 11  Epoch: 51  Training loss = 3.0906  Validation loss = 1.7217  \n",
      "\n",
      "Fold: 11  Epoch: 52  Training loss = 3.0900  Validation loss = 1.7201  \n",
      "\n",
      "Fold: 11  Epoch: 53  Training loss = 3.0896  Validation loss = 1.7190  \n",
      "\n",
      "Fold: 11  Epoch: 54  Training loss = 3.0892  Validation loss = 1.7182  \n",
      "\n",
      "Fold: 11  Epoch: 55  Training loss = 3.0886  Validation loss = 1.7167  \n",
      "\n",
      "Fold: 11  Epoch: 56  Training loss = 3.0876  Validation loss = 1.7139  \n",
      "\n",
      "Fold: 11  Epoch: 57  Training loss = 3.0871  Validation loss = 1.7126  \n",
      "\n",
      "Fold: 11  Epoch: 58  Training loss = 3.0866  Validation loss = 1.7113  \n",
      "\n",
      "Fold: 11  Epoch: 59  Training loss = 3.0863  Validation loss = 1.7106  \n",
      "\n",
      "Fold: 11  Epoch: 60  Training loss = 3.0860  Validation loss = 1.7100  \n",
      "\n",
      "Fold: 11  Epoch: 61  Training loss = 3.0855  Validation loss = 1.7087  \n",
      "\n",
      "Fold: 11  Epoch: 62  Training loss = 3.0852  Validation loss = 1.7083  \n",
      "\n",
      "Fold: 11  Epoch: 63  Training loss = 3.0847  Validation loss = 1.7074  \n",
      "\n",
      "Fold: 11  Epoch: 64  Training loss = 3.0838  Validation loss = 1.7057  \n",
      "\n",
      "Fold: 11  Epoch: 65  Training loss = 3.0834  Validation loss = 1.7049  \n",
      "\n",
      "Fold: 11  Epoch: 66  Training loss = 3.0826  Validation loss = 1.7027  \n",
      "\n",
      "Fold: 11  Epoch: 67  Training loss = 3.0820  Validation loss = 1.7012  \n",
      "\n",
      "Fold: 11  Epoch: 68  Training loss = 3.0815  Validation loss = 1.7000  \n",
      "\n",
      "Fold: 11  Epoch: 69  Training loss = 3.0807  Validation loss = 1.6978  \n",
      "\n",
      "Fold: 11  Epoch: 70  Training loss = 3.0801  Validation loss = 1.6960  \n",
      "\n",
      "Fold: 11  Epoch: 71  Training loss = 3.0798  Validation loss = 1.6954  \n",
      "\n",
      "Fold: 11  Epoch: 72  Training loss = 3.0788  Validation loss = 1.6924  \n",
      "\n",
      "Fold: 11  Epoch: 73  Training loss = 3.0781  Validation loss = 1.6904  \n",
      "\n",
      "Fold: 11  Epoch: 74  Training loss = 3.0779  Validation loss = 1.6902  \n",
      "\n",
      "Fold: 11  Epoch: 75  Training loss = 3.0773  Validation loss = 1.6885  \n",
      "\n",
      "Fold: 11  Epoch: 76  Training loss = 3.0768  Validation loss = 1.6872  \n",
      "\n",
      "Fold: 11  Epoch: 77  Training loss = 3.0760  Validation loss = 1.6849  \n",
      "\n",
      "Fold: 11  Epoch: 78  Training loss = 3.0756  Validation loss = 1.6839  \n",
      "\n",
      "Fold: 11  Epoch: 79  Training loss = 3.0750  Validation loss = 1.6824  \n",
      "\n",
      "Fold: 11  Epoch: 80  Training loss = 3.0743  Validation loss = 1.6799  \n",
      "\n",
      "Fold: 11  Epoch: 81  Training loss = 3.0740  Validation loss = 1.6794  \n",
      "\n",
      "Fold: 11  Epoch: 82  Training loss = 3.0736  Validation loss = 1.6785  \n",
      "\n",
      "Fold: 11  Epoch: 83  Training loss = 3.0733  Validation loss = 1.6779  \n",
      "\n",
      "Fold: 11  Epoch: 84  Training loss = 3.0723  Validation loss = 1.6751  \n",
      "\n",
      "Fold: 11  Epoch: 85  Training loss = 3.0719  Validation loss = 1.6740  \n",
      "\n",
      "Fold: 11  Epoch: 86  Training loss = 3.0713  Validation loss = 1.6721  \n",
      "\n",
      "Fold: 11  Epoch: 87  Training loss = 3.0708  Validation loss = 1.6711  \n",
      "\n",
      "Fold: 11  Epoch: 88  Training loss = 3.0705  Validation loss = 1.6705  \n",
      "\n",
      "Fold: 11  Epoch: 89  Training loss = 3.0698  Validation loss = 1.6687  \n",
      "\n",
      "Fold: 11  Epoch: 90  Training loss = 3.0691  Validation loss = 1.6668  \n",
      "\n",
      "Fold: 11  Epoch: 91  Training loss = 3.0686  Validation loss = 1.6653  \n",
      "\n",
      "Fold: 11  Epoch: 92  Training loss = 3.0681  Validation loss = 1.6637  \n",
      "\n",
      "Fold: 11  Epoch: 93  Training loss = 3.0675  Validation loss = 1.6624  \n",
      "\n",
      "Fold: 11  Epoch: 94  Training loss = 3.0669  Validation loss = 1.6605  \n",
      "\n",
      "Fold: 11  Epoch: 95  Training loss = 3.0664  Validation loss = 1.6597  \n",
      "\n",
      "Fold: 11  Epoch: 96  Training loss = 3.0660  Validation loss = 1.6589  \n",
      "\n",
      "Fold: 11  Epoch: 97  Training loss = 3.0657  Validation loss = 1.6580  \n",
      "\n",
      "Fold: 11  Epoch: 98  Training loss = 3.0652  Validation loss = 1.6569  \n",
      "\n",
      "Fold: 11  Epoch: 99  Training loss = 3.0647  Validation loss = 1.6556  \n",
      "\n",
      "Fold: 11  Epoch: 100  Training loss = 3.0642  Validation loss = 1.6544  \n",
      "\n",
      "Fold: 11  Epoch: 101  Training loss = 3.0638  Validation loss = 1.6534  \n",
      "\n",
      "Fold: 11  Epoch: 102  Training loss = 3.0632  Validation loss = 1.6518  \n",
      "\n",
      "Fold: 11  Epoch: 103  Training loss = 3.0627  Validation loss = 1.6505  \n",
      "\n",
      "Fold: 11  Epoch: 104  Training loss = 3.0623  Validation loss = 1.6496  \n",
      "\n",
      "Fold: 11  Epoch: 105  Training loss = 3.0619  Validation loss = 1.6485  \n",
      "\n",
      "Fold: 11  Epoch: 106  Training loss = 3.0617  Validation loss = 1.6480  \n",
      "\n",
      "Fold: 11  Epoch: 107  Training loss = 3.0612  Validation loss = 1.6466  \n",
      "\n",
      "Fold: 11  Epoch: 108  Training loss = 3.0608  Validation loss = 1.6456  \n",
      "\n",
      "Fold: 11  Epoch: 109  Training loss = 3.0603  Validation loss = 1.6442  \n",
      "\n",
      "Fold: 11  Epoch: 110  Training loss = 3.0600  Validation loss = 1.6435  \n",
      "\n",
      "Fold: 11  Epoch: 111  Training loss = 3.0597  Validation loss = 1.6429  \n",
      "\n",
      "Fold: 11  Epoch: 112  Training loss = 3.0594  Validation loss = 1.6424  \n",
      "\n",
      "Fold: 11  Epoch: 113  Training loss = 3.0589  Validation loss = 1.6408  \n",
      "\n",
      "Fold: 11  Epoch: 114  Training loss = 3.0583  Validation loss = 1.6391  \n",
      "\n",
      "Fold: 11  Epoch: 115  Training loss = 3.0577  Validation loss = 1.6377  \n",
      "\n",
      "Fold: 11  Epoch: 116  Training loss = 3.0573  Validation loss = 1.6363  \n",
      "\n",
      "Fold: 11  Epoch: 117  Training loss = 3.0569  Validation loss = 1.6354  \n",
      "\n",
      "Fold: 11  Epoch: 118  Training loss = 3.0564  Validation loss = 1.6340  \n",
      "\n",
      "Fold: 11  Epoch: 119  Training loss = 3.0562  Validation loss = 1.6336  \n",
      "\n",
      "Fold: 11  Epoch: 120  Training loss = 3.0559  Validation loss = 1.6329  \n",
      "\n",
      "Fold: 11  Epoch: 121  Training loss = 3.0556  Validation loss = 1.6327  \n",
      "\n",
      "Fold: 11  Epoch: 122  Training loss = 3.0553  Validation loss = 1.6318  \n",
      "\n",
      "Fold: 11  Epoch: 123  Training loss = 3.0551  Validation loss = 1.6313  \n",
      "\n",
      "Fold: 11  Epoch: 124  Training loss = 3.0545  Validation loss = 1.6298  \n",
      "\n",
      "Fold: 11  Epoch: 125  Training loss = 3.0539  Validation loss = 1.6281  \n",
      "\n",
      "Fold: 11  Epoch: 126  Training loss = 3.0536  Validation loss = 1.6273  \n",
      "\n",
      "Fold: 11  Epoch: 127  Training loss = 3.0530  Validation loss = 1.6259  \n",
      "\n",
      "Fold: 11  Epoch: 128  Training loss = 3.0524  Validation loss = 1.6242  \n",
      "\n",
      "Fold: 11  Epoch: 129  Training loss = 3.0521  Validation loss = 1.6237  \n",
      "\n",
      "Fold: 11  Epoch: 130  Training loss = 3.0516  Validation loss = 1.6222  \n",
      "\n",
      "Fold: 11  Epoch: 131  Training loss = 3.0511  Validation loss = 1.6209  \n",
      "\n",
      "Fold: 11  Epoch: 132  Training loss = 3.0506  Validation loss = 1.6196  \n",
      "\n",
      "Fold: 11  Epoch: 133  Training loss = 3.0500  Validation loss = 1.6179  \n",
      "\n",
      "Fold: 11  Epoch: 134  Training loss = 3.0496  Validation loss = 1.6168  \n",
      "\n",
      "Fold: 11  Epoch: 135  Training loss = 3.0489  Validation loss = 1.6153  \n",
      "\n",
      "Fold: 11  Epoch: 136  Training loss = 3.0485  Validation loss = 1.6140  \n",
      "\n",
      "Fold: 11  Epoch: 137  Training loss = 3.0481  Validation loss = 1.6133  \n",
      "\n",
      "Fold: 11  Epoch: 138  Training loss = 3.0476  Validation loss = 1.6122  \n",
      "\n",
      "Fold: 11  Epoch: 139  Training loss = 3.0473  Validation loss = 1.6116  \n",
      "\n",
      "Fold: 11  Epoch: 140  Training loss = 3.0469  Validation loss = 1.6103  \n",
      "\n",
      "Fold: 11  Epoch: 141  Training loss = 3.0465  Validation loss = 1.6091  \n",
      "\n",
      "Fold: 11  Epoch: 142  Training loss = 3.0461  Validation loss = 1.6079  \n",
      "\n",
      "Fold: 11  Epoch: 143  Training loss = 3.0458  Validation loss = 1.6077  \n",
      "\n",
      "Fold: 11  Epoch: 144  Training loss = 3.0457  Validation loss = 1.6078  \n",
      "\n",
      "Fold: 11  Epoch: 145  Training loss = 3.0451  Validation loss = 1.6062  \n",
      "\n",
      "Fold: 11  Epoch: 146  Training loss = 3.0448  Validation loss = 1.6055  \n",
      "\n",
      "Fold: 11  Epoch: 147  Training loss = 3.0445  Validation loss = 1.6050  \n",
      "\n",
      "Fold: 11  Epoch: 148  Training loss = 3.0438  Validation loss = 1.6029  \n",
      "\n",
      "Fold: 11  Epoch: 149  Training loss = 3.0433  Validation loss = 1.6012  \n",
      "\n",
      "Fold: 11  Epoch: 150  Training loss = 3.0430  Validation loss = 1.6008  \n",
      "\n",
      "Fold: 11  Epoch: 151  Training loss = 3.0427  Validation loss = 1.6002  \n",
      "\n",
      "Fold: 11  Epoch: 152  Training loss = 3.0423  Validation loss = 1.5991  \n",
      "\n",
      "Fold: 11  Epoch: 153  Training loss = 3.0418  Validation loss = 1.5979  \n",
      "\n",
      "Fold: 11  Epoch: 154  Training loss = 3.0416  Validation loss = 1.5977  \n",
      "\n",
      "Fold: 11  Epoch: 155  Training loss = 3.0409  Validation loss = 1.5959  \n",
      "\n",
      "Fold: 11  Epoch: 156  Training loss = 3.0403  Validation loss = 1.5939  \n",
      "\n",
      "Fold: 11  Epoch: 157  Training loss = 3.0398  Validation loss = 1.5926  \n",
      "\n",
      "Fold: 11  Epoch: 158  Training loss = 3.0394  Validation loss = 1.5916  \n",
      "\n",
      "Fold: 11  Epoch: 159  Training loss = 3.0391  Validation loss = 1.5910  \n",
      "\n",
      "Fold: 11  Epoch: 160  Training loss = 3.0388  Validation loss = 1.5904  \n",
      "\n",
      "Fold: 11  Epoch: 161  Training loss = 3.0383  Validation loss = 1.5892  \n",
      "\n",
      "Fold: 11  Epoch: 162  Training loss = 3.0378  Validation loss = 1.5878  \n",
      "\n",
      "Fold: 11  Epoch: 163  Training loss = 3.0373  Validation loss = 1.5866  \n",
      "\n",
      "Fold: 11  Epoch: 164  Training loss = 3.0369  Validation loss = 1.5856  \n",
      "\n",
      "Fold: 11  Epoch: 165  Training loss = 3.0366  Validation loss = 1.5850  \n",
      "\n",
      "Fold: 11  Epoch: 166  Training loss = 3.0363  Validation loss = 1.5844  \n",
      "\n",
      "Fold: 11  Epoch: 167  Training loss = 3.0359  Validation loss = 1.5836  \n",
      "\n",
      "Fold: 11  Epoch: 168  Training loss = 3.0354  Validation loss = 1.5824  \n",
      "\n",
      "Fold: 11  Epoch: 169  Training loss = 3.0348  Validation loss = 1.5809  \n",
      "\n",
      "Fold: 11  Epoch: 170  Training loss = 3.0344  Validation loss = 1.5799  \n",
      "\n",
      "Fold: 11  Epoch: 171  Training loss = 3.0340  Validation loss = 1.5789  \n",
      "\n",
      "Fold: 11  Epoch: 172  Training loss = 3.0335  Validation loss = 1.5776  \n",
      "\n",
      "Fold: 11  Epoch: 173  Training loss = 3.0330  Validation loss = 1.5762  \n",
      "\n",
      "Fold: 11  Epoch: 174  Training loss = 3.0326  Validation loss = 1.5756  \n",
      "\n",
      "Fold: 11  Epoch: 175  Training loss = 3.0322  Validation loss = 1.5744  \n",
      "\n",
      "Fold: 11  Epoch: 176  Training loss = 3.0320  Validation loss = 1.5742  \n",
      "\n",
      "Fold: 11  Epoch: 177  Training loss = 3.0315  Validation loss = 1.5728  \n",
      "\n",
      "Fold: 11  Epoch: 178  Training loss = 3.0313  Validation loss = 1.5725  \n",
      "\n",
      "Fold: 11  Epoch: 179  Training loss = 3.0307  Validation loss = 1.5712  \n",
      "\n",
      "Fold: 11  Epoch: 180  Training loss = 3.0305  Validation loss = 1.5709  \n",
      "\n",
      "Fold: 11  Epoch: 181  Training loss = 3.0302  Validation loss = 1.5704  \n",
      "\n",
      "Fold: 11  Epoch: 182  Training loss = 3.0299  Validation loss = 1.5700  \n",
      "\n",
      "Fold: 11  Epoch: 183  Training loss = 3.0294  Validation loss = 1.5686  \n",
      "\n",
      "Fold: 11  Epoch: 184  Training loss = 3.0290  Validation loss = 1.5676  \n",
      "\n",
      "Fold: 11  Epoch: 185  Training loss = 3.0286  Validation loss = 1.5668  \n",
      "\n",
      "Fold: 11  Epoch: 186  Training loss = 3.0280  Validation loss = 1.5653  \n",
      "\n",
      "Fold: 11  Epoch: 187  Training loss = 3.0277  Validation loss = 1.5650  \n",
      "\n",
      "Fold: 11  Epoch: 188  Training loss = 3.0206  Validation loss = 1.5632  \n",
      "\n",
      "Fold: 11  Epoch: 189  Training loss = 3.0196  Validation loss = 1.5615  \n",
      "\n",
      "Fold: 11  Epoch: 190  Training loss = 3.0192  Validation loss = 1.5607  \n",
      "\n",
      "Fold: 11  Epoch: 191  Training loss = 3.0187  Validation loss = 1.5597  \n",
      "\n",
      "Fold: 11  Epoch: 192  Training loss = 3.0182  Validation loss = 1.5585  \n",
      "\n",
      "Fold: 11  Epoch: 193  Training loss = 3.0179  Validation loss = 1.5581  \n",
      "\n",
      "Fold: 11  Epoch: 194  Training loss = 3.0173  Validation loss = 1.5567  \n",
      "\n",
      "Fold: 11  Epoch: 195  Training loss = 3.0169  Validation loss = 1.5560  \n",
      "\n",
      "Fold: 11  Epoch: 196  Training loss = 3.0166  Validation loss = 1.5553  \n",
      "\n",
      "Fold: 11  Epoch: 197  Training loss = 3.0163  Validation loss = 1.5550  \n",
      "\n",
      "Fold: 11  Epoch: 198  Training loss = 3.0159  Validation loss = 1.5541  \n",
      "\n",
      "Fold: 11  Epoch: 199  Training loss = 3.0155  Validation loss = 1.5533  \n",
      "\n",
      "Fold: 11  Epoch: 200  Training loss = 3.0152  Validation loss = 1.5531  \n",
      "\n",
      "Fold: 11  Epoch: 201  Training loss = 3.0147  Validation loss = 1.5519  \n",
      "\n",
      "Fold: 11  Epoch: 202  Training loss = 3.0142  Validation loss = 1.5500  \n",
      "\n",
      "Fold: 11  Epoch: 203  Training loss = 3.0138  Validation loss = 1.5491  \n",
      "\n",
      "Fold: 11  Epoch: 204  Training loss = 3.0135  Validation loss = 1.5483  \n",
      "\n",
      "Fold: 11  Epoch: 205  Training loss = 3.0130  Validation loss = 1.5473  \n",
      "\n",
      "Fold: 11  Epoch: 206  Training loss = 3.0126  Validation loss = 1.5465  \n",
      "\n",
      "Fold: 11  Epoch: 207  Training loss = 3.0122  Validation loss = 1.5454  \n",
      "\n",
      "Fold: 11  Epoch: 208  Training loss = 3.0118  Validation loss = 1.5444  \n",
      "\n",
      "Fold: 11  Epoch: 209  Training loss = 3.0113  Validation loss = 1.5433  \n",
      "\n",
      "Fold: 11  Epoch: 210  Training loss = 3.0111  Validation loss = 1.5430  \n",
      "\n",
      "Fold: 11  Epoch: 211  Training loss = 3.0106  Validation loss = 1.5420  \n",
      "\n",
      "Fold: 11  Epoch: 212  Training loss = 3.0101  Validation loss = 1.5408  \n",
      "\n",
      "Fold: 11  Epoch: 213  Training loss = 3.0098  Validation loss = 1.5400  \n",
      "\n",
      "Fold: 11  Epoch: 214  Training loss = 3.0094  Validation loss = 1.5391  \n",
      "\n",
      "Fold: 11  Epoch: 215  Training loss = 3.0091  Validation loss = 1.5384  \n",
      "\n",
      "Fold: 11  Epoch: 216  Training loss = 3.0086  Validation loss = 1.5370  \n",
      "\n",
      "Fold: 11  Epoch: 217  Training loss = 3.0083  Validation loss = 1.5364  \n",
      "\n",
      "Fold: 11  Epoch: 218  Training loss = 3.0080  Validation loss = 1.5360  \n",
      "\n",
      "Fold: 11  Epoch: 219  Training loss = 3.0078  Validation loss = 1.5362  \n",
      "\n",
      "Fold: 11  Epoch: 220  Training loss = 3.0072  Validation loss = 1.5349  \n",
      "\n",
      "Fold: 11  Epoch: 221  Training loss = 3.0069  Validation loss = 1.5342  \n",
      "\n",
      "Fold: 11  Epoch: 222  Training loss = 3.0065  Validation loss = 1.5336  \n",
      "\n",
      "Fold: 11  Epoch: 223  Training loss = 3.0062  Validation loss = 1.5330  \n",
      "\n",
      "Fold: 11  Epoch: 224  Training loss = 3.0061  Validation loss = 1.5332  \n",
      "\n",
      "Fold: 11  Epoch: 225  Training loss = 3.0057  Validation loss = 1.5324  \n",
      "\n",
      "Fold: 11  Epoch: 226  Training loss = 3.0055  Validation loss = 1.5320  \n",
      "\n",
      "Fold: 11  Epoch: 227  Training loss = 3.0050  Validation loss = 1.5309  \n",
      "\n",
      "Fold: 11  Epoch: 228  Training loss = 3.0047  Validation loss = 1.5305  \n",
      "\n",
      "Fold: 11  Epoch: 229  Training loss = 3.0043  Validation loss = 1.5294  \n",
      "\n",
      "Fold: 11  Epoch: 230  Training loss = 3.0040  Validation loss = 1.5291  \n",
      "\n",
      "Fold: 11  Epoch: 231  Training loss = 3.0037  Validation loss = 1.5287  \n",
      "\n",
      "Fold: 11  Epoch: 232  Training loss = 3.0035  Validation loss = 1.5283  \n",
      "\n",
      "Fold: 11  Epoch: 233  Training loss = 3.0032  Validation loss = 1.5279  \n",
      "\n",
      "Fold: 11  Epoch: 234  Training loss = 3.0028  Validation loss = 1.5273  \n",
      "\n",
      "Fold: 11  Epoch: 235  Training loss = 3.0025  Validation loss = 1.5269  \n",
      "\n",
      "Fold: 11  Epoch: 236  Training loss = 3.0019  Validation loss = 1.5252  \n",
      "\n",
      "Fold: 11  Epoch: 237  Training loss = 3.0015  Validation loss = 1.5244  \n",
      "\n",
      "Fold: 11  Epoch: 238  Training loss = 3.0010  Validation loss = 1.5228  \n",
      "\n",
      "Fold: 11  Epoch: 239  Training loss = 3.0006  Validation loss = 1.5223  \n",
      "\n",
      "Fold: 11  Epoch: 240  Training loss = 3.0003  Validation loss = 1.5217  \n",
      "\n",
      "Fold: 11  Epoch: 241  Training loss = 3.0001  Validation loss = 1.5216  \n",
      "\n",
      "Fold: 11  Epoch: 242  Training loss = 2.9997  Validation loss = 1.5208  \n",
      "\n",
      "Fold: 11  Epoch: 243  Training loss = 2.9994  Validation loss = 1.5204  \n",
      "\n",
      "Fold: 11  Epoch: 244  Training loss = 2.9993  Validation loss = 1.5206  \n",
      "\n",
      "Fold: 11  Epoch: 245  Training loss = 2.9988  Validation loss = 1.5194  \n",
      "\n",
      "Fold: 11  Epoch: 246  Training loss = 2.9985  Validation loss = 1.5188  \n",
      "\n",
      "Fold: 11  Epoch: 247  Training loss = 2.9982  Validation loss = 1.5181  \n",
      "\n",
      "Fold: 11  Epoch: 248  Training loss = 2.9981  Validation loss = 1.5185  \n",
      "\n",
      "Fold: 11  Epoch: 249  Training loss = 2.9979  Validation loss = 1.5183  \n",
      "\n",
      "Fold: 11  Epoch: 250  Training loss = 2.9974  Validation loss = 1.5170  \n",
      "\n",
      "Fold: 11  Epoch: 251  Training loss = 2.9971  Validation loss = 1.5163  \n",
      "\n",
      "Fold: 11  Epoch: 252  Training loss = 2.9965  Validation loss = 1.5149  \n",
      "\n",
      "Fold: 11  Epoch: 253  Training loss = 2.9961  Validation loss = 1.5140  \n",
      "\n",
      "Fold: 11  Epoch: 254  Training loss = 2.9960  Validation loss = 1.5146  \n",
      "\n",
      "Fold: 11  Epoch: 255  Training loss = 2.9956  Validation loss = 1.5136  \n",
      "\n",
      "Fold: 11  Epoch: 256  Training loss = 2.9885  Validation loss = 1.5123  \n",
      "\n",
      "Fold: 11  Epoch: 257  Training loss = 2.9884  Validation loss = 1.5121  \n",
      "\n",
      "Fold: 11  Epoch: 258  Training loss = 2.9880  Validation loss = 1.5114  \n",
      "\n",
      "Fold: 11  Epoch: 259  Training loss = 2.9877  Validation loss = 1.5107  \n",
      "\n",
      "Fold: 11  Epoch: 260  Training loss = 2.9871  Validation loss = 1.5092  \n",
      "\n",
      "Fold: 11  Epoch: 261  Training loss = 2.9870  Validation loss = 1.5094  \n",
      "\n",
      "Fold: 11  Epoch: 262  Training loss = 2.9867  Validation loss = 1.5090  \n",
      "\n",
      "Fold: 11  Epoch: 263  Training loss = 2.9863  Validation loss = 1.5083  \n",
      "\n",
      "Fold: 11  Epoch: 264  Training loss = 2.9862  Validation loss = 1.5089  \n",
      "\n",
      "Fold: 11  Epoch: 265  Training loss = 2.9857  Validation loss = 1.5075  \n",
      "\n",
      "Fold: 11  Epoch: 266  Training loss = 2.9851  Validation loss = 1.5062  \n",
      "\n",
      "Fold: 11  Epoch: 267  Training loss = 2.9848  Validation loss = 1.5056  \n",
      "\n",
      "Fold: 11  Epoch: 268  Training loss = 2.9842  Validation loss = 1.5042  \n",
      "\n",
      "Fold: 11  Epoch: 269  Training loss = 2.9838  Validation loss = 1.5029  \n",
      "\n",
      "Fold: 11  Epoch: 270  Training loss = 2.9833  Validation loss = 1.5018  \n",
      "\n",
      "Fold: 11  Epoch: 271  Training loss = 2.9830  Validation loss = 1.5010  \n",
      "\n",
      "Fold: 11  Epoch: 272  Training loss = 2.9826  Validation loss = 1.5004  \n",
      "\n",
      "Fold: 11  Epoch: 273  Training loss = 2.9823  Validation loss = 1.4998  \n",
      "\n",
      "Fold: 11  Epoch: 274  Training loss = 2.9817  Validation loss = 1.4984  \n",
      "\n",
      "Fold: 11  Epoch: 275  Training loss = 2.9815  Validation loss = 1.4981  \n",
      "\n",
      "Fold: 11  Epoch: 276  Training loss = 2.9811  Validation loss = 1.4971  \n",
      "\n",
      "Fold: 11  Epoch: 277  Training loss = 2.9809  Validation loss = 1.4971  \n",
      "\n",
      "Fold: 11  Epoch: 278  Training loss = 2.9806  Validation loss = 1.4964  \n",
      "\n",
      "Fold: 11  Epoch: 279  Training loss = 2.9801  Validation loss = 1.4951  \n",
      "\n",
      "Fold: 11  Epoch: 280  Training loss = 2.9797  Validation loss = 1.4942  \n",
      "\n",
      "Fold: 11  Epoch: 281  Training loss = 2.9794  Validation loss = 1.4937  \n",
      "\n",
      "Fold: 11  Epoch: 282  Training loss = 2.9788  Validation loss = 1.4920  \n",
      "\n",
      "Fold: 11  Epoch: 283  Training loss = 2.9784  Validation loss = 1.4912  \n",
      "\n",
      "Fold: 11  Epoch: 284  Training loss = 2.9780  Validation loss = 1.4903  \n",
      "\n",
      "Fold: 11  Epoch: 285  Training loss = 2.9778  Validation loss = 1.4904  \n",
      "\n",
      "Fold: 11  Epoch: 286  Training loss = 2.9775  Validation loss = 1.4896  \n",
      "\n",
      "Fold: 11  Epoch: 287  Training loss = 2.9770  Validation loss = 1.4882  \n",
      "\n",
      "Fold: 11  Epoch: 288  Training loss = 2.9764  Validation loss = 1.4872  \n",
      "\n",
      "Fold: 11  Epoch: 289  Training loss = 2.9761  Validation loss = 1.4863  \n",
      "\n",
      "Fold: 11  Epoch: 290  Training loss = 2.9757  Validation loss = 1.4856  \n",
      "\n",
      "Fold: 11  Epoch: 291  Training loss = 2.9753  Validation loss = 1.4846  \n",
      "\n",
      "Fold: 11  Epoch: 292  Training loss = 2.9748  Validation loss = 1.4838  \n",
      "\n",
      "Fold: 11  Epoch: 293  Training loss = 2.9744  Validation loss = 1.4827  \n",
      "\n",
      "Fold: 11  Epoch: 294  Training loss = 2.9741  Validation loss = 1.4821  \n",
      "\n",
      "Fold: 11  Epoch: 295  Training loss = 2.9738  Validation loss = 1.4816  \n",
      "\n",
      "Fold: 11  Epoch: 296  Training loss = 2.9735  Validation loss = 1.4812  \n",
      "\n",
      "Fold: 11  Epoch: 297  Training loss = 2.9732  Validation loss = 1.4803  \n",
      "\n",
      "Fold: 11  Epoch: 298  Training loss = 2.9728  Validation loss = 1.4796  \n",
      "\n",
      "Fold: 11  Epoch: 299  Training loss = 2.9724  Validation loss = 1.4791  \n",
      "\n",
      "Fold: 11  Epoch: 300  Training loss = 2.9722  Validation loss = 1.4787  \n",
      "\n",
      "Fold: 11  Epoch: 301  Training loss = 2.9720  Validation loss = 1.4784  \n",
      "\n",
      "Fold: 11  Epoch: 302  Training loss = 2.9718  Validation loss = 1.4783  \n",
      "\n",
      "Fold: 11  Epoch: 303  Training loss = 2.9715  Validation loss = 1.4778  \n",
      "\n",
      "Fold: 11  Epoch: 304  Training loss = 2.9710  Validation loss = 1.4769  \n",
      "\n",
      "Fold: 11  Epoch: 305  Training loss = 2.9706  Validation loss = 1.4762  \n",
      "\n",
      "Fold: 11  Epoch: 306  Training loss = 2.9702  Validation loss = 1.4754  \n",
      "\n",
      "Fold: 11  Epoch: 307  Training loss = 2.9699  Validation loss = 1.4750  \n",
      "\n",
      "Fold: 11  Epoch: 308  Training loss = 2.9697  Validation loss = 1.4749  \n",
      "\n",
      "Fold: 11  Epoch: 309  Training loss = 2.9692  Validation loss = 1.4736  \n",
      "\n",
      "Fold: 11  Epoch: 310  Training loss = 2.9688  Validation loss = 1.4727  \n",
      "\n",
      "Fold: 11  Epoch: 311  Training loss = 2.9685  Validation loss = 1.4726  \n",
      "\n",
      "Fold: 11  Epoch: 312  Training loss = 2.9681  Validation loss = 1.4720  \n",
      "\n",
      "Fold: 11  Epoch: 313  Training loss = 2.9677  Validation loss = 1.4712  \n",
      "\n",
      "Fold: 11  Epoch: 314  Training loss = 2.9674  Validation loss = 1.4707  \n",
      "\n",
      "Fold: 11  Epoch: 315  Training loss = 2.9670  Validation loss = 1.4702  \n",
      "\n",
      "Fold: 11  Epoch: 316  Training loss = 2.9667  Validation loss = 1.4694  \n",
      "\n",
      "Fold: 11  Epoch: 317  Training loss = 2.9663  Validation loss = 1.4689  \n",
      "\n",
      "Fold: 11  Epoch: 318  Training loss = 2.9660  Validation loss = 1.4684  \n",
      "\n",
      "Fold: 11  Epoch: 319  Training loss = 2.9656  Validation loss = 1.4677  \n",
      "\n",
      "Fold: 11  Epoch: 320  Training loss = 2.9653  Validation loss = 1.4672  \n",
      "\n",
      "Fold: 11  Epoch: 321  Training loss = 2.9651  Validation loss = 1.4671  \n",
      "\n",
      "Fold: 11  Epoch: 322  Training loss = 2.9648  Validation loss = 1.4668  \n",
      "\n",
      "Fold: 11  Epoch: 323  Training loss = 2.9645  Validation loss = 1.4662  \n",
      "\n",
      "Fold: 11  Epoch: 324  Training loss = 2.9642  Validation loss = 1.4655  \n",
      "\n",
      "Fold: 11  Epoch: 325  Training loss = 2.9636  Validation loss = 1.4640  \n",
      "\n",
      "Fold: 11  Epoch: 326  Training loss = 2.9634  Validation loss = 1.4636  \n",
      "\n",
      "Fold: 11  Epoch: 327  Training loss = 2.9632  Validation loss = 1.4636  \n",
      "\n",
      "Fold: 11  Epoch: 328  Training loss = 2.9629  Validation loss = 1.4632  \n",
      "\n",
      "Fold: 11  Epoch: 329  Training loss = 2.9625  Validation loss = 1.4625  \n",
      "\n",
      "Fold: 11  Epoch: 330  Training loss = 2.9621  Validation loss = 1.4616  \n",
      "\n",
      "Fold: 11  Epoch: 331  Training loss = 2.9618  Validation loss = 1.4614  \n",
      "\n",
      "Fold: 11  Epoch: 332  Training loss = 2.9613  Validation loss = 1.4602  \n",
      "\n",
      "Fold: 11  Epoch: 333  Training loss = 2.9609  Validation loss = 1.4596  \n",
      "\n",
      "Fold: 11  Epoch: 334  Training loss = 2.9607  Validation loss = 1.4595  \n",
      "\n",
      "Fold: 11  Epoch: 335  Training loss = 2.9603  Validation loss = 1.4587  \n",
      "\n",
      "Fold: 11  Epoch: 336  Training loss = 2.9601  Validation loss = 1.4581  \n",
      "\n",
      "Fold: 11  Epoch: 337  Training loss = 2.9596  Validation loss = 1.4571  \n",
      "\n",
      "Fold: 11  Epoch: 338  Training loss = 2.9592  Validation loss = 1.4565  \n",
      "\n",
      "Fold: 11  Epoch: 339  Training loss = 2.9588  Validation loss = 1.4558  \n",
      "\n",
      "Fold: 11  Epoch: 340  Training loss = 2.9585  Validation loss = 1.4552  \n",
      "\n",
      "Fold: 11  Epoch: 341  Training loss = 2.9582  Validation loss = 1.4547  \n",
      "\n",
      "Fold: 11  Epoch: 342  Training loss = 2.9579  Validation loss = 1.4545  \n",
      "\n",
      "Fold: 11  Epoch: 343  Training loss = 2.9574  Validation loss = 1.4534  \n",
      "\n",
      "Fold: 11  Epoch: 344  Training loss = 2.9570  Validation loss = 1.4522  \n",
      "\n",
      "Fold: 11  Epoch: 345  Training loss = 2.9565  Validation loss = 1.4513  \n",
      "\n",
      "Fold: 11  Epoch: 346  Training loss = 2.9562  Validation loss = 1.4504  \n",
      "\n",
      "Fold: 11  Epoch: 347  Training loss = 2.9557  Validation loss = 1.4496  \n",
      "\n",
      "Fold: 11  Epoch: 348  Training loss = 2.9554  Validation loss = 1.4492  \n",
      "\n",
      "Fold: 11  Epoch: 349  Training loss = 2.9550  Validation loss = 1.4486  \n",
      "\n",
      "Fold: 11  Epoch: 350  Training loss = 2.9545  Validation loss = 1.4474  \n",
      "\n",
      "Fold: 11  Epoch: 351  Training loss = 2.9542  Validation loss = 1.4472  \n",
      "\n",
      "Fold: 11  Epoch: 352  Training loss = 2.9539  Validation loss = 1.4466  \n",
      "\n",
      "Fold: 11  Epoch: 353  Training loss = 2.9534  Validation loss = 1.4457  \n",
      "\n",
      "Fold: 11  Epoch: 354  Training loss = 2.9532  Validation loss = 1.4455  \n",
      "\n",
      "Fold: 11  Epoch: 355  Training loss = 2.9529  Validation loss = 1.4449  \n",
      "\n",
      "Fold: 11  Epoch: 356  Training loss = 2.9525  Validation loss = 1.4442  \n",
      "\n",
      "Fold: 11  Epoch: 357  Training loss = 2.9522  Validation loss = 1.4441  \n",
      "\n",
      "Fold: 11  Epoch: 358  Training loss = 2.9520  Validation loss = 1.4441  \n",
      "\n",
      "Fold: 11  Epoch: 359  Training loss = 2.9517  Validation loss = 1.4433  \n",
      "\n",
      "Fold: 11  Epoch: 360  Training loss = 2.9512  Validation loss = 1.4423  \n",
      "\n",
      "Fold: 11  Epoch: 361  Training loss = 2.9509  Validation loss = 1.4421  \n",
      "\n",
      "Fold: 11  Epoch: 362  Training loss = 2.9507  Validation loss = 1.4421  \n",
      "\n",
      "Fold: 11  Epoch: 363  Training loss = 2.9504  Validation loss = 1.4416  \n",
      "\n",
      "Fold: 11  Epoch: 364  Training loss = 2.9501  Validation loss = 1.4411  \n",
      "\n",
      "Fold: 11  Epoch: 365  Training loss = 2.9496  Validation loss = 1.4404  \n",
      "\n",
      "Fold: 11  Epoch: 366  Training loss = 2.9493  Validation loss = 1.4400  \n",
      "\n",
      "Fold: 11  Epoch: 367  Training loss = 2.9490  Validation loss = 1.4394  \n",
      "\n",
      "Fold: 11  Epoch: 368  Training loss = 2.9486  Validation loss = 1.4388  \n",
      "\n",
      "Fold: 11  Epoch: 369  Training loss = 2.9484  Validation loss = 1.4388  \n",
      "\n",
      "Fold: 11  Epoch: 370  Training loss = 2.9480  Validation loss = 1.4380  \n",
      "\n",
      "Fold: 11  Epoch: 371  Training loss = 2.9471  Validation loss = 1.4369  \n",
      "\n",
      "Fold: 11  Epoch: 372  Training loss = 2.9429  Validation loss = 1.4359  \n",
      "\n",
      "Fold: 11  Epoch: 373  Training loss = 2.9409  Validation loss = 1.4331  \n",
      "\n",
      "Fold: 11  Epoch: 374  Training loss = 2.9404  Validation loss = 1.4321  \n",
      "\n",
      "Fold: 11  Epoch: 375  Training loss = 2.9400  Validation loss = 1.4315  \n",
      "\n",
      "Fold: 11  Epoch: 376  Training loss = 2.9396  Validation loss = 1.4313  \n",
      "\n",
      "Fold: 11  Epoch: 377  Training loss = 2.9393  Validation loss = 1.4313  \n",
      "\n",
      "Fold: 11  Epoch: 378  Training loss = 2.9390  Validation loss = 1.4310  \n",
      "\n",
      "Fold: 11  Epoch: 379  Training loss = 2.9387  Validation loss = 1.4303  \n",
      "\n",
      "Fold: 11  Epoch: 380  Training loss = 2.9386  Validation loss = 1.4304  \n",
      "\n",
      "Fold: 11  Epoch: 381  Training loss = 2.9383  Validation loss = 1.4304  \n",
      "\n",
      "Fold: 11  Epoch: 382  Training loss = 2.9379  Validation loss = 1.4296  \n",
      "\n",
      "Fold: 11  Epoch: 383  Training loss = 2.9376  Validation loss = 1.4289  \n",
      "\n",
      "Fold: 11  Epoch: 384  Training loss = 2.9373  Validation loss = 1.4287  \n",
      "\n",
      "Fold: 11  Epoch: 385  Training loss = 2.9368  Validation loss = 1.4282  \n",
      "\n",
      "Fold: 11  Epoch: 386  Training loss = 2.9363  Validation loss = 1.4273  \n",
      "\n",
      "Fold: 11  Epoch: 387  Training loss = 2.9359  Validation loss = 1.4260  \n",
      "\n",
      "Fold: 11  Epoch: 388  Training loss = 2.9356  Validation loss = 1.4258  \n",
      "\n",
      "Fold: 11  Epoch: 389  Training loss = 2.9352  Validation loss = 1.4251  \n",
      "\n",
      "Fold: 11  Epoch: 390  Training loss = 2.9349  Validation loss = 1.4245  \n",
      "\n",
      "Fold: 11  Epoch: 391  Training loss = 2.9343  Validation loss = 1.4233  \n",
      "\n",
      "Fold: 11  Epoch: 392  Training loss = 2.9338  Validation loss = 1.4226  \n",
      "\n",
      "Fold: 11  Epoch: 393  Training loss = 2.9335  Validation loss = 1.4223  \n",
      "\n",
      "Fold: 11  Epoch: 394  Training loss = 2.9329  Validation loss = 1.4213  \n",
      "\n",
      "Fold: 11  Epoch: 395  Training loss = 2.9324  Validation loss = 1.4201  \n",
      "\n",
      "Fold: 11  Epoch: 396  Training loss = 2.9321  Validation loss = 1.4198  \n",
      "\n",
      "Fold: 11  Epoch: 397  Training loss = 2.9316  Validation loss = 1.4190  \n",
      "\n",
      "Fold: 11  Epoch: 398  Training loss = 2.9315  Validation loss = 1.4193  \n",
      "\n",
      "Fold: 11  Epoch: 399  Training loss = 2.9311  Validation loss = 1.4186  \n",
      "\n",
      "Fold: 11  Epoch: 400  Training loss = 2.9307  Validation loss = 1.4180  \n",
      "\n",
      "Fold: 11  Epoch: 401  Training loss = 2.9303  Validation loss = 1.4176  \n",
      "\n",
      "Fold: 11  Epoch: 402  Training loss = 2.9301  Validation loss = 1.4179  \n",
      "\n",
      "Fold: 11  Epoch: 403  Training loss = 2.9296  Validation loss = 1.4167  \n",
      "\n",
      "Fold: 11  Epoch: 404  Training loss = 2.9294  Validation loss = 1.4165  \n",
      "\n",
      "Fold: 11  Epoch: 405  Training loss = 2.9290  Validation loss = 1.4161  \n",
      "\n",
      "Fold: 11  Epoch: 406  Training loss = 2.9288  Validation loss = 1.4162  \n",
      "\n",
      "Fold: 11  Epoch: 407  Training loss = 2.9283  Validation loss = 1.4158  \n",
      "\n",
      "Fold: 11  Epoch: 408  Training loss = 2.9279  Validation loss = 1.4148  \n",
      "\n",
      "Fold: 11  Epoch: 409  Training loss = 2.9277  Validation loss = 1.4148  \n",
      "\n",
      "Fold: 11  Epoch: 410  Training loss = 2.9274  Validation loss = 1.4143  \n",
      "\n",
      "Fold: 11  Epoch: 411  Training loss = 2.9270  Validation loss = 1.4138  \n",
      "\n",
      "Fold: 11  Epoch: 412  Training loss = 2.9265  Validation loss = 1.4130  \n",
      "\n",
      "Fold: 11  Epoch: 413  Training loss = 2.9261  Validation loss = 1.4124  \n",
      "\n",
      "Fold: 11  Epoch: 414  Training loss = 2.9258  Validation loss = 1.4117  \n",
      "\n",
      "Fold: 11  Epoch: 415  Training loss = 2.9255  Validation loss = 1.4115  \n",
      "\n",
      "Fold: 11  Epoch: 416  Training loss = 2.9250  Validation loss = 1.4105  \n",
      "\n",
      "Fold: 11  Epoch: 417  Training loss = 2.9247  Validation loss = 1.4100  \n",
      "\n",
      "Fold: 11  Epoch: 418  Training loss = 2.9244  Validation loss = 1.4102  \n",
      "\n",
      "Fold: 11  Epoch: 419  Training loss = 2.9240  Validation loss = 1.4097  \n",
      "\n",
      "Fold: 11  Epoch: 420  Training loss = 2.9237  Validation loss = 1.4099  \n",
      "\n",
      "Fold: 11  Epoch: 421  Training loss = 2.9234  Validation loss = 1.4095  \n",
      "\n",
      "Fold: 11  Epoch: 422  Training loss = 2.9230  Validation loss = 1.4091  \n",
      "\n",
      "Fold: 11  Epoch: 423  Training loss = 2.9226  Validation loss = 1.4089  \n",
      "\n",
      "Fold: 11  Epoch: 424  Training loss = 2.9223  Validation loss = 1.4086  \n",
      "\n",
      "Fold: 11  Epoch: 425  Training loss = 2.9220  Validation loss = 1.4080  \n",
      "\n",
      "Fold: 11  Epoch: 426  Training loss = 2.9216  Validation loss = 1.4073  \n",
      "\n",
      "Fold: 11  Epoch: 427  Training loss = 2.9213  Validation loss = 1.4070  \n",
      "\n",
      "Fold: 11  Epoch: 428  Training loss = 2.9209  Validation loss = 1.4067  \n",
      "\n",
      "Fold: 11  Epoch: 429  Training loss = 2.9205  Validation loss = 1.4062  \n",
      "\n",
      "Fold: 11  Epoch: 430  Training loss = 2.9201  Validation loss = 1.4057  \n",
      "\n",
      "Fold: 11  Epoch: 431  Training loss = 2.9197  Validation loss = 1.4052  \n",
      "\n",
      "Fold: 11  Epoch: 432  Training loss = 2.9195  Validation loss = 1.4052  \n",
      "\n",
      "Fold: 11  Epoch: 433  Training loss = 2.9191  Validation loss = 1.4045  \n",
      "\n",
      "Fold: 11  Epoch: 434  Training loss = 2.9188  Validation loss = 1.4045  \n",
      "\n",
      "Fold: 11  Epoch: 435  Training loss = 2.9184  Validation loss = 1.4041  \n",
      "\n",
      "Fold: 11  Epoch: 436  Training loss = 2.9181  Validation loss = 1.4036  \n",
      "\n",
      "Fold: 11  Epoch: 437  Training loss = 2.9176  Validation loss = 1.4028  \n",
      "\n",
      "Fold: 11  Epoch: 438  Training loss = 2.9173  Validation loss = 1.4027  \n",
      "\n",
      "Fold: 11  Epoch: 439  Training loss = 2.9170  Validation loss = 1.4022  \n",
      "\n",
      "Fold: 11  Epoch: 440  Training loss = 2.9165  Validation loss = 1.4016  \n",
      "\n",
      "Fold: 11  Epoch: 441  Training loss = 2.9161  Validation loss = 1.4009  \n",
      "\n",
      "Fold: 11  Epoch: 442  Training loss = 2.9158  Validation loss = 1.4007  \n",
      "\n",
      "Fold: 11  Epoch: 443  Training loss = 2.9154  Validation loss = 1.4002  \n",
      "\n",
      "Fold: 11  Epoch: 444  Training loss = 2.9151  Validation loss = 1.3997  \n",
      "\n",
      "Fold: 11  Epoch: 445  Training loss = 2.9148  Validation loss = 1.3993  \n",
      "\n",
      "Fold: 11  Epoch: 446  Training loss = 2.9143  Validation loss = 1.3987  \n",
      "\n",
      "Fold: 11  Epoch: 447  Training loss = 2.9138  Validation loss = 1.3983  \n",
      "\n",
      "Fold: 11  Epoch: 448  Training loss = 2.9134  Validation loss = 1.3977  \n",
      "\n",
      "Fold: 11  Epoch: 449  Training loss = 2.9132  Validation loss = 1.3978  \n",
      "\n",
      "Fold: 11  Epoch: 450  Training loss = 2.9129  Validation loss = 1.3976  \n",
      "\n",
      "Fold: 11  Epoch: 451  Training loss = 2.9127  Validation loss = 1.3977  \n",
      "\n",
      "Fold: 11  Epoch: 452  Training loss = 2.9124  Validation loss = 1.3974  \n",
      "\n",
      "Fold: 11  Epoch: 453  Training loss = 2.9119  Validation loss = 1.3966  \n",
      "\n",
      "Fold: 11  Epoch: 454  Training loss = 2.9108  Validation loss = 1.3961  \n",
      "\n",
      "Fold: 11  Epoch: 455  Training loss = 2.9105  Validation loss = 1.3956  \n",
      "\n",
      "Fold: 11  Epoch: 456  Training loss = 2.9101  Validation loss = 1.3949  \n",
      "\n",
      "Fold: 11  Epoch: 457  Training loss = 2.9097  Validation loss = 1.3944  \n",
      "\n",
      "Fold: 11  Epoch: 458  Training loss = 2.9094  Validation loss = 1.3939  \n",
      "\n",
      "Fold: 11  Epoch: 459  Training loss = 2.9088  Validation loss = 1.3934  \n",
      "\n",
      "Fold: 11  Epoch: 460  Training loss = 2.9085  Validation loss = 1.3933  \n",
      "\n",
      "Fold: 11  Epoch: 461  Training loss = 2.9084  Validation loss = 1.3937  \n",
      "\n",
      "Fold: 11  Epoch: 462  Training loss = 2.9080  Validation loss = 1.3930  \n",
      "\n",
      "Fold: 11  Epoch: 463  Training loss = 2.9076  Validation loss = 1.3922  \n",
      "\n",
      "Fold: 11  Epoch: 464  Training loss = 2.9074  Validation loss = 1.3922  \n",
      "\n",
      "Fold: 11  Epoch: 465  Training loss = 2.9070  Validation loss = 1.3918  \n",
      "\n",
      "Fold: 11  Epoch: 466  Training loss = 2.9068  Validation loss = 1.3916  \n",
      "\n",
      "Fold: 11  Epoch: 467  Training loss = 2.9065  Validation loss = 1.3914  \n",
      "\n",
      "Fold: 11  Epoch: 468  Training loss = 2.9063  Validation loss = 1.3911  \n",
      "\n",
      "Fold: 11  Epoch: 469  Training loss = 2.9060  Validation loss = 1.3910  \n",
      "\n",
      "Fold: 11  Epoch: 470  Training loss = 2.9056  Validation loss = 1.3908  \n",
      "\n",
      "Fold: 11  Epoch: 471  Training loss = 2.9054  Validation loss = 1.3907  \n",
      "\n",
      "Fold: 11  Epoch: 472  Training loss = 2.9051  Validation loss = 1.3902  \n",
      "\n",
      "Fold: 11  Epoch: 473  Training loss = 2.9048  Validation loss = 1.3897  \n",
      "\n",
      "Fold: 11  Epoch: 474  Training loss = 2.9046  Validation loss = 1.3897  \n",
      "\n",
      "Fold: 11  Epoch: 475  Training loss = 2.9042  Validation loss = 1.3891  \n",
      "\n",
      "Fold: 11  Epoch: 476  Training loss = 2.9038  Validation loss = 1.3882  \n",
      "\n",
      "Fold: 11  Epoch: 477  Training loss = 2.9034  Validation loss = 1.3878  \n",
      "\n",
      "Fold: 11  Epoch: 478  Training loss = 2.9031  Validation loss = 1.3877  \n",
      "\n",
      "Fold: 11  Epoch: 479  Training loss = 2.9027  Validation loss = 1.3867  \n",
      "\n",
      "Fold: 11  Epoch: 480  Training loss = 2.9024  Validation loss = 1.3863  \n",
      "\n",
      "Fold: 11  Epoch: 481  Training loss = 2.9020  Validation loss = 1.3862  \n",
      "\n",
      "Fold: 11  Epoch: 482  Training loss = 2.9017  Validation loss = 1.3861  \n",
      "\n",
      "Fold: 11  Epoch: 483  Training loss = 2.9010  Validation loss = 1.3857  \n",
      "\n",
      "Fold: 11  Epoch: 484  Training loss = 2.8998  Validation loss = 1.3856  \n",
      "\n",
      "Fold: 11  Epoch: 485  Training loss = 2.8922  Validation loss = 1.3853  \n",
      "\n",
      "Fold: 11  Epoch: 486  Training loss = 2.8914  Validation loss = 1.3849  \n",
      "\n",
      "Fold: 11  Epoch: 487  Training loss = 2.8909  Validation loss = 1.3846  \n",
      "\n",
      "Fold: 11  Epoch: 488  Training loss = 2.8906  Validation loss = 1.3843  \n",
      "\n",
      "Fold: 11  Epoch: 489  Training loss = 2.8902  Validation loss = 1.3840  \n",
      "\n",
      "Fold: 11  Epoch: 490  Training loss = 2.8899  Validation loss = 1.3839  \n",
      "\n",
      "Fold: 11  Epoch: 491  Training loss = 2.8896  Validation loss = 1.3838  \n",
      "\n",
      "Fold: 11  Epoch: 492  Training loss = 2.8891  Validation loss = 1.3830  \n",
      "\n",
      "Fold: 11  Epoch: 493  Training loss = 2.8886  Validation loss = 1.3825  \n",
      "\n",
      "Fold: 11  Epoch: 494  Training loss = 2.8884  Validation loss = 1.3824  \n",
      "\n",
      "Fold: 11  Epoch: 495  Training loss = 2.8879  Validation loss = 1.3819  \n",
      "\n",
      "Fold: 11  Epoch: 496  Training loss = 2.8876  Validation loss = 1.3818  \n",
      "\n",
      "Fold: 11  Epoch: 497  Training loss = 2.8874  Validation loss = 1.3815  \n",
      "\n",
      "Fold: 11  Epoch: 498  Training loss = 2.8869  Validation loss = 1.3807  \n",
      "\n",
      "Fold: 11  Epoch: 499  Training loss = 2.8866  Validation loss = 1.3807  \n",
      "\n",
      "Fold: 11  Epoch: 500  Training loss = 2.8863  Validation loss = 1.3805  \n",
      "\n",
      "Check model:  Fold: 11  Optimal epoch: 500  \n",
      "\n",
      "Fold: 12  Epoch: 1  Training loss = 2.8431  Validation loss = 2.1590  \n",
      "\n",
      "Fold: 12  Epoch: 2  Training loss = 2.8429  Validation loss = 2.1577  \n",
      "\n",
      "Fold: 12  Epoch: 3  Training loss = 2.8424  Validation loss = 2.1556  \n",
      "\n",
      "Fold: 12  Epoch: 4  Training loss = 2.8420  Validation loss = 2.1535  \n",
      "\n",
      "Fold: 12  Epoch: 5  Training loss = 2.8417  Validation loss = 2.1522  \n",
      "\n",
      "Fold: 12  Epoch: 6  Training loss = 2.8414  Validation loss = 2.1511  \n",
      "\n",
      "Fold: 12  Epoch: 7  Training loss = 2.8410  Validation loss = 2.1495  \n",
      "\n",
      "Fold: 12  Epoch: 8  Training loss = 2.8407  Validation loss = 2.1489  \n",
      "\n",
      "Fold: 12  Epoch: 9  Training loss = 2.8404  Validation loss = 2.1473  \n",
      "\n",
      "Fold: 12  Epoch: 10  Training loss = 2.8401  Validation loss = 2.1461  \n",
      "\n",
      "Fold: 12  Epoch: 11  Training loss = 2.8400  Validation loss = 2.1461  \n",
      "\n",
      "Fold: 12  Epoch: 12  Training loss = 2.8397  Validation loss = 2.1460  \n",
      "\n",
      "Fold: 12  Epoch: 13  Training loss = 2.8393  Validation loss = 2.1436  \n",
      "\n",
      "Fold: 12  Epoch: 14  Training loss = 2.8390  Validation loss = 2.1429  \n",
      "\n",
      "Fold: 12  Epoch: 15  Training loss = 2.8387  Validation loss = 2.1426  \n",
      "\n",
      "Fold: 12  Epoch: 16  Training loss = 2.8383  Validation loss = 2.1402  \n",
      "\n",
      "Fold: 12  Epoch: 17  Training loss = 2.8380  Validation loss = 2.1395  \n",
      "\n",
      "Fold: 12  Epoch: 18  Training loss = 2.8377  Validation loss = 2.1385  \n",
      "\n",
      "Fold: 12  Epoch: 19  Training loss = 2.8375  Validation loss = 2.1382  \n",
      "\n",
      "Fold: 12  Epoch: 20  Training loss = 2.8373  Validation loss = 2.1378  \n",
      "\n",
      "Fold: 12  Epoch: 21  Training loss = 2.8371  Validation loss = 2.1382  \n",
      "\n",
      "Fold: 12  Epoch: 22  Training loss = 2.8370  Validation loss = 2.1379  \n",
      "\n",
      "Fold: 12  Epoch: 23  Training loss = 2.8365  Validation loss = 2.1358  \n",
      "\n",
      "Fold: 12  Epoch: 24  Training loss = 2.8362  Validation loss = 2.1354  \n",
      "\n",
      "Fold: 12  Epoch: 25  Training loss = 2.8357  Validation loss = 2.1327  \n",
      "\n",
      "Fold: 12  Epoch: 26  Training loss = 2.8353  Validation loss = 2.1307  \n",
      "\n",
      "Fold: 12  Epoch: 27  Training loss = 2.8351  Validation loss = 2.1303  \n",
      "\n",
      "Fold: 12  Epoch: 28  Training loss = 2.8350  Validation loss = 2.1316  \n",
      "\n",
      "Fold: 12  Epoch: 29  Training loss = 2.8347  Validation loss = 2.1311  \n",
      "\n",
      "Fold: 12  Epoch: 30  Training loss = 2.8342  Validation loss = 2.1287  \n",
      "\n",
      "Fold: 12  Epoch: 31  Training loss = 2.8337  Validation loss = 2.1263  \n",
      "\n",
      "Fold: 12  Epoch: 32  Training loss = 2.8331  Validation loss = 2.1232  \n",
      "\n",
      "Fold: 12  Epoch: 33  Training loss = 2.8327  Validation loss = 2.1208  \n",
      "\n",
      "Fold: 12  Epoch: 34  Training loss = 2.8323  Validation loss = 2.1194  \n",
      "\n",
      "Fold: 12  Epoch: 35  Training loss = 2.8320  Validation loss = 2.1177  \n",
      "\n",
      "Fold: 12  Epoch: 36  Training loss = 2.8315  Validation loss = 2.1150  \n",
      "\n",
      "Fold: 12  Epoch: 37  Training loss = 2.8313  Validation loss = 2.1154  \n",
      "\n",
      "Fold: 12  Epoch: 38  Training loss = 2.8311  Validation loss = 2.1156  \n",
      "\n",
      "Fold: 12  Epoch: 39  Training loss = 2.8308  Validation loss = 2.1143  \n",
      "\n",
      "Fold: 12  Epoch: 40  Training loss = 2.8303  Validation loss = 2.1124  \n",
      "\n",
      "Fold: 12  Epoch: 41  Training loss = 2.8301  Validation loss = 2.1120  \n",
      "\n",
      "Fold: 12  Epoch: 42  Training loss = 2.8297  Validation loss = 2.1103  \n",
      "\n",
      "Fold: 12  Epoch: 43  Training loss = 2.8295  Validation loss = 2.1097  \n",
      "\n",
      "Fold: 12  Epoch: 44  Training loss = 2.8292  Validation loss = 2.1087  \n",
      "\n",
      "Fold: 12  Epoch: 45  Training loss = 2.8287  Validation loss = 2.1064  \n",
      "\n",
      "Fold: 12  Epoch: 46  Training loss = 2.8286  Validation loss = 2.1069  \n",
      "\n",
      "Fold: 12  Epoch: 47  Training loss = 2.8284  Validation loss = 2.1067  \n",
      "\n",
      "Fold: 12  Epoch: 48  Training loss = 2.8281  Validation loss = 2.1052  \n",
      "\n",
      "Fold: 12  Epoch: 49  Training loss = 2.8276  Validation loss = 2.1028  \n",
      "\n",
      "Fold: 12  Epoch: 50  Training loss = 2.8272  Validation loss = 2.1013  \n",
      "\n",
      "Fold: 12  Epoch: 51  Training loss = 2.8266  Validation loss = 2.0976  \n",
      "\n",
      "Fold: 12  Epoch: 52  Training loss = 2.8264  Validation loss = 2.0973  \n",
      "\n",
      "Fold: 12  Epoch: 53  Training loss = 2.8261  Validation loss = 2.0962  \n",
      "\n",
      "Fold: 12  Epoch: 54  Training loss = 2.8256  Validation loss = 2.0942  \n",
      "\n",
      "Fold: 12  Epoch: 55  Training loss = 2.8253  Validation loss = 2.0927  \n",
      "\n",
      "Fold: 12  Epoch: 56  Training loss = 2.8248  Validation loss = 2.0903  \n",
      "\n",
      "Fold: 12  Epoch: 57  Training loss = 2.8245  Validation loss = 2.0894  \n",
      "\n",
      "Fold: 12  Epoch: 58  Training loss = 2.8242  Validation loss = 2.0887  \n",
      "\n",
      "Fold: 12  Epoch: 59  Training loss = 2.8238  Validation loss = 2.0856  \n",
      "\n",
      "Fold: 12  Epoch: 60  Training loss = 2.8235  Validation loss = 2.0853  \n",
      "\n",
      "Fold: 12  Epoch: 61  Training loss = 2.8231  Validation loss = 2.0837  \n",
      "\n",
      "Fold: 12  Epoch: 62  Training loss = 2.8229  Validation loss = 2.0834  \n",
      "\n",
      "Fold: 12  Epoch: 63  Training loss = 2.8226  Validation loss = 2.0826  \n",
      "\n",
      "Fold: 12  Epoch: 64  Training loss = 2.8224  Validation loss = 2.0822  \n",
      "\n",
      "Fold: 12  Epoch: 65  Training loss = 2.8219  Validation loss = 2.0784  \n",
      "\n",
      "Fold: 12  Epoch: 66  Training loss = 2.8214  Validation loss = 2.0758  \n",
      "\n",
      "Fold: 12  Epoch: 67  Training loss = 2.8209  Validation loss = 2.0732  \n",
      "\n",
      "Fold: 12  Epoch: 68  Training loss = 2.8204  Validation loss = 2.0709  \n",
      "\n",
      "Fold: 12  Epoch: 69  Training loss = 2.8203  Validation loss = 2.0725  \n",
      "\n",
      "Fold: 12  Epoch: 70  Training loss = 2.8200  Validation loss = 2.0718  \n",
      "\n",
      "Fold: 12  Epoch: 71  Training loss = 2.8199  Validation loss = 2.0730  \n",
      "\n",
      "Fold: 12  Epoch: 72  Training loss = 2.8198  Validation loss = 2.0739  \n",
      "\n",
      "Fold: 12  Epoch: 73  Training loss = 2.8195  Validation loss = 2.0733  \n",
      "\n",
      "Fold: 12  Epoch: 74  Training loss = 2.8193  Validation loss = 2.0730  \n",
      "\n",
      "Fold: 12  Epoch: 75  Training loss = 2.8192  Validation loss = 2.0731  \n",
      "\n",
      "Fold: 12  Epoch: 76  Training loss = 2.8189  Validation loss = 2.0730  \n",
      "\n",
      "Fold: 12  Epoch: 77  Training loss = 2.8184  Validation loss = 2.0698  \n",
      "\n",
      "Fold: 12  Epoch: 78  Training loss = 2.8180  Validation loss = 2.0680  \n",
      "\n",
      "Fold: 12  Epoch: 79  Training loss = 2.8176  Validation loss = 2.0658  \n",
      "\n",
      "Fold: 12  Epoch: 80  Training loss = 2.8173  Validation loss = 2.0650  \n",
      "\n",
      "Fold: 12  Epoch: 81  Training loss = 2.8170  Validation loss = 2.0648  \n",
      "\n",
      "Fold: 12  Epoch: 82  Training loss = 2.8170  Validation loss = 2.0661  \n",
      "\n",
      "Fold: 12  Epoch: 83  Training loss = 2.8168  Validation loss = 2.0652  \n",
      "\n",
      "Fold: 12  Epoch: 84  Training loss = 2.8166  Validation loss = 2.0650  \n",
      "\n",
      "Fold: 12  Epoch: 85  Training loss = 2.8162  Validation loss = 2.0632  \n",
      "\n",
      "Fold: 12  Epoch: 86  Training loss = 2.8159  Validation loss = 2.0615  \n",
      "\n",
      "Fold: 12  Epoch: 87  Training loss = 2.8156  Validation loss = 2.0607  \n",
      "\n",
      "Fold: 12  Epoch: 88  Training loss = 2.8153  Validation loss = 2.0598  \n",
      "\n",
      "Fold: 12  Epoch: 89  Training loss = 2.8149  Validation loss = 2.0583  \n",
      "\n",
      "Fold: 12  Epoch: 90  Training loss = 2.8146  Validation loss = 2.0574  \n",
      "\n",
      "Fold: 12  Epoch: 91  Training loss = 2.8141  Validation loss = 2.0539  \n",
      "\n",
      "Fold: 12  Epoch: 92  Training loss = 2.8136  Validation loss = 2.0522  \n",
      "\n",
      "Fold: 12  Epoch: 93  Training loss = 2.8134  Validation loss = 2.0525  \n",
      "\n",
      "Fold: 12  Epoch: 94  Training loss = 2.8128  Validation loss = 2.0487  \n",
      "\n",
      "Fold: 12  Epoch: 95  Training loss = 2.8124  Validation loss = 2.0472  \n",
      "\n",
      "Fold: 12  Epoch: 96  Training loss = 2.8121  Validation loss = 2.0467  \n",
      "\n",
      "Fold: 12  Epoch: 97  Training loss = 2.8117  Validation loss = 2.0447  \n",
      "\n",
      "Fold: 12  Epoch: 98  Training loss = 2.8115  Validation loss = 2.0450  \n",
      "\n",
      "Fold: 12  Epoch: 99  Training loss = 2.8112  Validation loss = 2.0431  \n",
      "\n",
      "Fold: 12  Epoch: 100  Training loss = 2.8108  Validation loss = 2.0418  \n",
      "\n",
      "Fold: 12  Epoch: 101  Training loss = 2.8105  Validation loss = 2.0411  \n",
      "\n",
      "Fold: 12  Epoch: 102  Training loss = 2.8102  Validation loss = 2.0404  \n",
      "\n",
      "Fold: 12  Epoch: 103  Training loss = 2.8099  Validation loss = 2.0392  \n",
      "\n",
      "Fold: 12  Epoch: 104  Training loss = 2.8096  Validation loss = 2.0388  \n",
      "\n",
      "Fold: 12  Epoch: 105  Training loss = 2.8092  Validation loss = 2.0364  \n",
      "\n",
      "Fold: 12  Epoch: 106  Training loss = 2.8088  Validation loss = 2.0349  \n",
      "\n",
      "Fold: 12  Epoch: 107  Training loss = 2.8085  Validation loss = 2.0349  \n",
      "\n",
      "Fold: 12  Epoch: 108  Training loss = 2.8084  Validation loss = 2.0354  \n",
      "\n",
      "Fold: 12  Epoch: 109  Training loss = 2.8082  Validation loss = 2.0353  \n",
      "\n",
      "Fold: 12  Epoch: 110  Training loss = 2.8078  Validation loss = 2.0346  \n",
      "\n",
      "Fold: 12  Epoch: 111  Training loss = 2.8074  Validation loss = 2.0321  \n",
      "\n",
      "Fold: 12  Epoch: 112  Training loss = 2.8072  Validation loss = 2.0321  \n",
      "\n",
      "Fold: 12  Epoch: 113  Training loss = 2.8068  Validation loss = 2.0298  \n",
      "\n",
      "Fold: 12  Epoch: 114  Training loss = 2.8065  Validation loss = 2.0292  \n",
      "\n",
      "Fold: 12  Epoch: 115  Training loss = 2.8061  Validation loss = 2.0277  \n",
      "\n",
      "Fold: 12  Epoch: 116  Training loss = 2.8058  Validation loss = 2.0269  \n",
      "\n",
      "Fold: 12  Epoch: 117  Training loss = 2.8053  Validation loss = 2.0239  \n",
      "\n",
      "Fold: 12  Epoch: 118  Training loss = 2.8048  Validation loss = 2.0209  \n",
      "\n",
      "Fold: 12  Epoch: 119  Training loss = 2.8045  Validation loss = 2.0204  \n",
      "\n",
      "Fold: 12  Epoch: 120  Training loss = 2.8042  Validation loss = 2.0199  \n",
      "\n",
      "Fold: 12  Epoch: 121  Training loss = 2.8036  Validation loss = 2.0170  \n",
      "\n",
      "Fold: 12  Epoch: 122  Training loss = 2.8034  Validation loss = 2.0166  \n",
      "\n",
      "Fold: 12  Epoch: 123  Training loss = 2.8031  Validation loss = 2.0159  \n",
      "\n",
      "Fold: 12  Epoch: 124  Training loss = 2.8027  Validation loss = 2.0139  \n",
      "\n",
      "Fold: 12  Epoch: 125  Training loss = 2.8025  Validation loss = 2.0138  \n",
      "\n",
      "Fold: 12  Epoch: 126  Training loss = 2.8020  Validation loss = 2.0111  \n",
      "\n",
      "Fold: 12  Epoch: 127  Training loss = 2.8016  Validation loss = 2.0086  \n",
      "\n",
      "Fold: 12  Epoch: 128  Training loss = 2.8015  Validation loss = 2.0092  \n",
      "\n",
      "Fold: 12  Epoch: 129  Training loss = 2.8011  Validation loss = 2.0084  \n",
      "\n",
      "Fold: 12  Epoch: 130  Training loss = 2.8007  Validation loss = 2.0061  \n",
      "\n",
      "Fold: 12  Epoch: 131  Training loss = 2.8004  Validation loss = 2.0056  \n",
      "\n",
      "Fold: 12  Epoch: 132  Training loss = 2.8003  Validation loss = 2.0071  \n",
      "\n",
      "Fold: 12  Epoch: 133  Training loss = 2.7999  Validation loss = 2.0055  \n",
      "\n",
      "Fold: 12  Epoch: 134  Training loss = 2.7994  Validation loss = 2.0029  \n",
      "\n",
      "Fold: 12  Epoch: 135  Training loss = 2.7991  Validation loss = 2.0010  \n",
      "\n",
      "Fold: 12  Epoch: 136  Training loss = 2.7988  Validation loss = 2.0002  \n",
      "\n",
      "Fold: 12  Epoch: 137  Training loss = 2.7985  Validation loss = 1.9981  \n",
      "\n",
      "Fold: 12  Epoch: 138  Training loss = 2.7981  Validation loss = 1.9972  \n",
      "\n",
      "Fold: 12  Epoch: 139  Training loss = 2.7977  Validation loss = 1.9950  \n",
      "\n",
      "Fold: 12  Epoch: 140  Training loss = 2.7975  Validation loss = 1.9964  \n",
      "\n",
      "Fold: 12  Epoch: 141  Training loss = 2.7972  Validation loss = 1.9959  \n",
      "\n",
      "Fold: 12  Epoch: 142  Training loss = 2.7968  Validation loss = 1.9941  \n",
      "\n",
      "Fold: 12  Epoch: 143  Training loss = 2.7966  Validation loss = 1.9942  \n",
      "\n",
      "Fold: 12  Epoch: 144  Training loss = 2.7961  Validation loss = 1.9911  \n",
      "\n",
      "Fold: 12  Epoch: 145  Training loss = 2.7957  Validation loss = 1.9895  \n",
      "\n",
      "Fold: 12  Epoch: 146  Training loss = 2.7951  Validation loss = 1.9871  \n",
      "\n",
      "Fold: 12  Epoch: 147  Training loss = 2.7948  Validation loss = 1.9851  \n",
      "\n",
      "Fold: 12  Epoch: 148  Training loss = 2.7943  Validation loss = 1.9830  \n",
      "\n",
      "Fold: 12  Epoch: 149  Training loss = 2.7939  Validation loss = 1.9822  \n",
      "\n",
      "Fold: 12  Epoch: 150  Training loss = 2.7934  Validation loss = 1.9796  \n",
      "\n",
      "Fold: 12  Epoch: 151  Training loss = 2.7931  Validation loss = 1.9790  \n",
      "\n",
      "Fold: 12  Epoch: 152  Training loss = 2.7929  Validation loss = 1.9789  \n",
      "\n",
      "Fold: 12  Epoch: 153  Training loss = 2.7925  Validation loss = 1.9774  \n",
      "\n",
      "Fold: 12  Epoch: 154  Training loss = 2.7922  Validation loss = 1.9763  \n",
      "\n",
      "Fold: 12  Epoch: 155  Training loss = 2.7919  Validation loss = 1.9766  \n",
      "\n",
      "Fold: 12  Epoch: 156  Training loss = 2.7916  Validation loss = 1.9754  \n",
      "\n",
      "Fold: 12  Epoch: 157  Training loss = 2.7914  Validation loss = 1.9752  \n",
      "\n",
      "Fold: 12  Epoch: 158  Training loss = 2.7910  Validation loss = 1.9728  \n",
      "\n",
      "Fold: 12  Epoch: 159  Training loss = 2.7905  Validation loss = 1.9700  \n",
      "\n",
      "Fold: 12  Epoch: 160  Training loss = 2.7901  Validation loss = 1.9686  \n",
      "\n",
      "Fold: 12  Epoch: 161  Training loss = 2.7899  Validation loss = 1.9675  \n",
      "\n",
      "Fold: 12  Epoch: 162  Training loss = 2.7898  Validation loss = 1.9696  \n",
      "\n",
      "Fold: 12  Epoch: 163  Training loss = 2.7896  Validation loss = 1.9701  \n",
      "\n",
      "Fold: 12  Epoch: 164  Training loss = 2.7894  Validation loss = 1.9706  \n",
      "\n",
      "Fold: 12  Epoch: 165  Training loss = 2.7892  Validation loss = 1.9705  \n",
      "\n",
      "Fold: 12  Epoch: 166  Training loss = 2.7887  Validation loss = 1.9675  \n",
      "\n",
      "Fold: 12  Epoch: 167  Training loss = 2.7884  Validation loss = 1.9664  \n",
      "\n",
      "Fold: 12  Epoch: 168  Training loss = 2.7881  Validation loss = 1.9665  \n",
      "\n",
      "Fold: 12  Epoch: 169  Training loss = 2.7878  Validation loss = 1.9657  \n",
      "\n",
      "Fold: 12  Epoch: 170  Training loss = 2.7877  Validation loss = 1.9661  \n",
      "\n",
      "Fold: 12  Epoch: 171  Training loss = 2.7874  Validation loss = 1.9673  \n",
      "\n",
      "Fold: 12  Epoch: 172  Training loss = 2.7872  Validation loss = 1.9671  \n",
      "\n",
      "Fold: 12  Epoch: 173  Training loss = 2.7868  Validation loss = 1.9657  \n",
      "\n",
      "Fold: 12  Epoch: 174  Training loss = 2.7867  Validation loss = 1.9672  \n",
      "\n",
      "Fold: 12  Epoch: 175  Training loss = 2.7864  Validation loss = 1.9669  \n",
      "\n",
      "Fold: 12  Epoch: 176  Training loss = 2.7863  Validation loss = 1.9681  \n",
      "\n",
      "Check model:  Fold: 12  Optimal epoch: 169  \n",
      "\n",
      "Fold: 13  Epoch: 1  Training loss = 2.7500  Validation loss = 4.4149  \n",
      "\n",
      "Fold: 13  Epoch: 2  Training loss = 2.7495  Validation loss = 4.4122  \n",
      "\n",
      "Fold: 13  Epoch: 3  Training loss = 2.7490  Validation loss = 4.4103  \n",
      "\n",
      "Fold: 13  Epoch: 4  Training loss = 2.7488  Validation loss = 4.4097  \n",
      "\n",
      "Fold: 13  Epoch: 5  Training loss = 2.7480  Validation loss = 4.4069  \n",
      "\n",
      "Fold: 13  Epoch: 6  Training loss = 2.7474  Validation loss = 4.4036  \n",
      "\n",
      "Fold: 13  Epoch: 7  Training loss = 2.7467  Validation loss = 4.4005  \n",
      "\n",
      "Fold: 13  Epoch: 8  Training loss = 2.7463  Validation loss = 4.3982  \n",
      "\n",
      "Fold: 13  Epoch: 9  Training loss = 2.7457  Validation loss = 4.3959  \n",
      "\n",
      "Fold: 13  Epoch: 10  Training loss = 2.7455  Validation loss = 4.3951  \n",
      "\n",
      "Fold: 13  Epoch: 11  Training loss = 2.7448  Validation loss = 4.3923  \n",
      "\n",
      "Fold: 13  Epoch: 12  Training loss = 2.7441  Validation loss = 4.3895  \n",
      "\n",
      "Fold: 13  Epoch: 13  Training loss = 2.7434  Validation loss = 4.3860  \n",
      "\n",
      "Fold: 13  Epoch: 14  Training loss = 2.7430  Validation loss = 4.3844  \n",
      "\n",
      "Fold: 13  Epoch: 15  Training loss = 2.7426  Validation loss = 4.3822  \n",
      "\n",
      "Fold: 13  Epoch: 16  Training loss = 2.7421  Validation loss = 4.3805  \n",
      "\n",
      "Fold: 13  Epoch: 17  Training loss = 2.7412  Validation loss = 4.3761  \n",
      "\n",
      "Fold: 13  Epoch: 18  Training loss = 2.7406  Validation loss = 4.3735  \n",
      "\n",
      "Fold: 13  Epoch: 19  Training loss = 2.7403  Validation loss = 4.3722  \n",
      "\n",
      "Fold: 13  Epoch: 20  Training loss = 2.7393  Validation loss = 4.3676  \n",
      "\n",
      "Fold: 13  Epoch: 21  Training loss = 2.7387  Validation loss = 4.3650  \n",
      "\n",
      "Fold: 13  Epoch: 22  Training loss = 2.7383  Validation loss = 4.3633  \n",
      "\n",
      "Fold: 13  Epoch: 23  Training loss = 2.7376  Validation loss = 4.3598  \n",
      "\n",
      "Fold: 13  Epoch: 24  Training loss = 2.7370  Validation loss = 4.3568  \n",
      "\n",
      "Fold: 13  Epoch: 25  Training loss = 2.7361  Validation loss = 4.3525  \n",
      "\n",
      "Fold: 13  Epoch: 26  Training loss = 2.7358  Validation loss = 4.3512  \n",
      "\n",
      "Fold: 13  Epoch: 27  Training loss = 2.7352  Validation loss = 4.3481  \n",
      "\n",
      "Fold: 13  Epoch: 28  Training loss = 2.7346  Validation loss = 4.3449  \n",
      "\n",
      "Fold: 13  Epoch: 29  Training loss = 2.7343  Validation loss = 4.3438  \n",
      "\n",
      "Fold: 13  Epoch: 30  Training loss = 2.7336  Validation loss = 4.3403  \n",
      "\n",
      "Fold: 13  Epoch: 31  Training loss = 2.7330  Validation loss = 4.3378  \n",
      "\n",
      "Fold: 13  Epoch: 32  Training loss = 2.7323  Validation loss = 4.3350  \n",
      "\n",
      "Fold: 13  Epoch: 33  Training loss = 2.7319  Validation loss = 4.3336  \n",
      "\n",
      "Fold: 13  Epoch: 34  Training loss = 2.7315  Validation loss = 4.3317  \n",
      "\n",
      "Fold: 13  Epoch: 35  Training loss = 2.7310  Validation loss = 4.3300  \n",
      "\n",
      "Fold: 13  Epoch: 36  Training loss = 2.7301  Validation loss = 4.3253  \n",
      "\n",
      "Fold: 13  Epoch: 37  Training loss = 2.7295  Validation loss = 4.3230  \n",
      "\n",
      "Fold: 13  Epoch: 38  Training loss = 2.7289  Validation loss = 4.3210  \n",
      "\n",
      "Fold: 13  Epoch: 39  Training loss = 2.7286  Validation loss = 4.3195  \n",
      "\n",
      "Fold: 13  Epoch: 40  Training loss = 2.7280  Validation loss = 4.3168  \n",
      "\n",
      "Fold: 13  Epoch: 41  Training loss = 2.7275  Validation loss = 4.3142  \n",
      "\n",
      "Fold: 13  Epoch: 42  Training loss = 2.7269  Validation loss = 4.3121  \n",
      "\n",
      "Fold: 13  Epoch: 43  Training loss = 2.7264  Validation loss = 4.3102  \n",
      "\n",
      "Fold: 13  Epoch: 44  Training loss = 2.7261  Validation loss = 4.3091  \n",
      "\n",
      "Fold: 13  Epoch: 45  Training loss = 2.7258  Validation loss = 4.3079  \n",
      "\n",
      "Fold: 13  Epoch: 46  Training loss = 2.7254  Validation loss = 4.3065  \n",
      "\n",
      "Fold: 13  Epoch: 47  Training loss = 2.7250  Validation loss = 4.3045  \n",
      "\n",
      "Fold: 13  Epoch: 48  Training loss = 2.7243  Validation loss = 4.3018  \n",
      "\n",
      "Fold: 13  Epoch: 49  Training loss = 2.7238  Validation loss = 4.2996  \n",
      "\n",
      "Fold: 13  Epoch: 50  Training loss = 2.7230  Validation loss = 4.2959  \n",
      "\n",
      "Fold: 13  Epoch: 51  Training loss = 2.7224  Validation loss = 4.2933  \n",
      "\n",
      "Fold: 13  Epoch: 52  Training loss = 2.7220  Validation loss = 4.2911  \n",
      "\n",
      "Fold: 13  Epoch: 53  Training loss = 2.7215  Validation loss = 4.2892  \n",
      "\n",
      "Fold: 13  Epoch: 54  Training loss = 2.7214  Validation loss = 4.2892  \n",
      "\n",
      "Fold: 13  Epoch: 55  Training loss = 2.7208  Validation loss = 4.2872  \n",
      "\n",
      "Fold: 13  Epoch: 56  Training loss = 2.7205  Validation loss = 4.2856  \n",
      "\n",
      "Fold: 13  Epoch: 57  Training loss = 2.7199  Validation loss = 4.2824  \n",
      "\n",
      "Fold: 13  Epoch: 58  Training loss = 2.7195  Validation loss = 4.2809  \n",
      "\n",
      "Fold: 13  Epoch: 59  Training loss = 2.7193  Validation loss = 4.2807  \n",
      "\n",
      "Fold: 13  Epoch: 60  Training loss = 2.7188  Validation loss = 4.2791  \n",
      "\n",
      "Fold: 13  Epoch: 61  Training loss = 2.7185  Validation loss = 4.2784  \n",
      "\n",
      "Fold: 13  Epoch: 62  Training loss = 2.7179  Validation loss = 4.2757  \n",
      "\n",
      "Fold: 13  Epoch: 63  Training loss = 2.7176  Validation loss = 4.2745  \n",
      "\n",
      "Fold: 13  Epoch: 64  Training loss = 2.7170  Validation loss = 4.2721  \n",
      "\n",
      "Fold: 13  Epoch: 65  Training loss = 2.7162  Validation loss = 4.2679  \n",
      "\n",
      "Fold: 13  Epoch: 66  Training loss = 2.7159  Validation loss = 4.2669  \n",
      "\n",
      "Fold: 13  Epoch: 67  Training loss = 2.7157  Validation loss = 4.2661  \n",
      "\n",
      "Fold: 13  Epoch: 68  Training loss = 2.7148  Validation loss = 4.2619  \n",
      "\n",
      "Fold: 13  Epoch: 69  Training loss = 2.7143  Validation loss = 4.2589  \n",
      "\n",
      "Fold: 13  Epoch: 70  Training loss = 2.7137  Validation loss = 4.2568  \n",
      "\n",
      "Fold: 13  Epoch: 71  Training loss = 2.7133  Validation loss = 4.2551  \n",
      "\n",
      "Fold: 13  Epoch: 72  Training loss = 2.7129  Validation loss = 4.2535  \n",
      "\n",
      "Fold: 13  Epoch: 73  Training loss = 2.7124  Validation loss = 4.2508  \n",
      "\n",
      "Fold: 13  Epoch: 74  Training loss = 2.7121  Validation loss = 4.2494  \n",
      "\n",
      "Fold: 13  Epoch: 75  Training loss = 2.7120  Validation loss = 4.2494  \n",
      "\n",
      "Fold: 13  Epoch: 76  Training loss = 2.7114  Validation loss = 4.2463  \n",
      "\n",
      "Fold: 13  Epoch: 77  Training loss = 2.7110  Validation loss = 4.2452  \n",
      "\n",
      "Fold: 13  Epoch: 78  Training loss = 2.7104  Validation loss = 4.2423  \n",
      "\n",
      "Fold: 13  Epoch: 79  Training loss = 2.7102  Validation loss = 4.2417  \n",
      "\n",
      "Fold: 13  Epoch: 80  Training loss = 2.7095  Validation loss = 4.2385  \n",
      "\n",
      "Fold: 13  Epoch: 81  Training loss = 2.7085  Validation loss = 4.2327  \n",
      "\n",
      "Fold: 13  Epoch: 82  Training loss = 2.7078  Validation loss = 4.2292  \n",
      "\n",
      "Fold: 13  Epoch: 83  Training loss = 2.7072  Validation loss = 4.2263  \n",
      "\n",
      "Fold: 13  Epoch: 84  Training loss = 2.7067  Validation loss = 4.2238  \n",
      "\n",
      "Fold: 13  Epoch: 85  Training loss = 2.7062  Validation loss = 4.2211  \n",
      "\n",
      "Fold: 13  Epoch: 86  Training loss = 2.7056  Validation loss = 4.2184  \n",
      "\n",
      "Fold: 13  Epoch: 87  Training loss = 2.7051  Validation loss = 4.2155  \n",
      "\n",
      "Fold: 13  Epoch: 88  Training loss = 2.7044  Validation loss = 4.2121  \n",
      "\n",
      "Fold: 13  Epoch: 89  Training loss = 2.7041  Validation loss = 4.2112  \n",
      "\n",
      "Fold: 13  Epoch: 90  Training loss = 2.7034  Validation loss = 4.2076  \n",
      "\n",
      "Fold: 13  Epoch: 91  Training loss = 2.7028  Validation loss = 4.2042  \n",
      "\n",
      "Fold: 13  Epoch: 92  Training loss = 2.7024  Validation loss = 4.2026  \n",
      "\n",
      "Fold: 13  Epoch: 93  Training loss = 2.7020  Validation loss = 4.2007  \n",
      "\n",
      "Fold: 13  Epoch: 94  Training loss = 2.7017  Validation loss = 4.1992  \n",
      "\n",
      "Fold: 13  Epoch: 95  Training loss = 2.7012  Validation loss = 4.1977  \n",
      "\n",
      "Fold: 13  Epoch: 96  Training loss = 2.7008  Validation loss = 4.1962  \n",
      "\n",
      "Fold: 13  Epoch: 97  Training loss = 2.7003  Validation loss = 4.1937  \n",
      "\n",
      "Fold: 13  Epoch: 98  Training loss = 2.6998  Validation loss = 4.1911  \n",
      "\n",
      "Fold: 13  Epoch: 99  Training loss = 2.6993  Validation loss = 4.1889  \n",
      "\n",
      "Fold: 13  Epoch: 100  Training loss = 2.6992  Validation loss = 4.1887  \n",
      "\n",
      "Fold: 13  Epoch: 101  Training loss = 2.6987  Validation loss = 4.1865  \n",
      "\n",
      "Fold: 13  Epoch: 102  Training loss = 2.6984  Validation loss = 4.1851  \n",
      "\n",
      "Fold: 13  Epoch: 103  Training loss = 2.6980  Validation loss = 4.1838  \n",
      "\n",
      "Fold: 13  Epoch: 104  Training loss = 2.6975  Validation loss = 4.1817  \n",
      "\n",
      "Fold: 13  Epoch: 105  Training loss = 2.6971  Validation loss = 4.1809  \n",
      "\n",
      "Fold: 13  Epoch: 106  Training loss = 2.6967  Validation loss = 4.1791  \n",
      "\n",
      "Fold: 13  Epoch: 107  Training loss = 2.6963  Validation loss = 4.1777  \n",
      "\n",
      "Fold: 13  Epoch: 108  Training loss = 2.6959  Validation loss = 4.1763  \n",
      "\n",
      "Fold: 13  Epoch: 109  Training loss = 2.6955  Validation loss = 4.1753  \n",
      "\n",
      "Fold: 13  Epoch: 110  Training loss = 2.6952  Validation loss = 4.1741  \n",
      "\n",
      "Fold: 13  Epoch: 111  Training loss = 2.6945  Validation loss = 4.1706  \n",
      "\n",
      "Fold: 13  Epoch: 112  Training loss = 2.6941  Validation loss = 4.1684  \n",
      "\n",
      "Fold: 13  Epoch: 113  Training loss = 2.6936  Validation loss = 4.1664  \n",
      "\n",
      "Fold: 13  Epoch: 114  Training loss = 2.6932  Validation loss = 4.1649  \n",
      "\n",
      "Fold: 13  Epoch: 115  Training loss = 2.6928  Validation loss = 4.1627  \n",
      "\n",
      "Fold: 13  Epoch: 116  Training loss = 2.6924  Validation loss = 4.1608  \n",
      "\n",
      "Fold: 13  Epoch: 117  Training loss = 2.6919  Validation loss = 4.1588  \n",
      "\n",
      "Fold: 13  Epoch: 118  Training loss = 2.6917  Validation loss = 4.1580  \n",
      "\n",
      "Fold: 13  Epoch: 119  Training loss = 2.6914  Validation loss = 4.1566  \n",
      "\n",
      "Fold: 13  Epoch: 120  Training loss = 2.6909  Validation loss = 4.1548  \n",
      "\n",
      "Fold: 13  Epoch: 121  Training loss = 2.6904  Validation loss = 4.1526  \n",
      "\n",
      "Fold: 13  Epoch: 122  Training loss = 2.6901  Validation loss = 4.1516  \n",
      "\n",
      "Fold: 13  Epoch: 123  Training loss = 2.6899  Validation loss = 4.1513  \n",
      "\n",
      "Fold: 13  Epoch: 124  Training loss = 2.6894  Validation loss = 4.1490  \n",
      "\n",
      "Fold: 13  Epoch: 125  Training loss = 2.6890  Validation loss = 4.1465  \n",
      "\n",
      "Fold: 13  Epoch: 126  Training loss = 2.6886  Validation loss = 4.1450  \n",
      "\n",
      "Fold: 13  Epoch: 127  Training loss = 2.6881  Validation loss = 4.1420  \n",
      "\n",
      "Fold: 13  Epoch: 128  Training loss = 2.6879  Validation loss = 4.1423  \n",
      "\n",
      "Fold: 13  Epoch: 129  Training loss = 2.6873  Validation loss = 4.1391  \n",
      "\n",
      "Fold: 13  Epoch: 130  Training loss = 2.6869  Validation loss = 4.1378  \n",
      "\n",
      "Fold: 13  Epoch: 131  Training loss = 2.6866  Validation loss = 4.1363  \n",
      "\n",
      "Fold: 13  Epoch: 132  Training loss = 2.6864  Validation loss = 4.1360  \n",
      "\n",
      "Fold: 13  Epoch: 133  Training loss = 2.6860  Validation loss = 4.1345  \n",
      "\n",
      "Fold: 13  Epoch: 134  Training loss = 2.6856  Validation loss = 4.1332  \n",
      "\n",
      "Fold: 13  Epoch: 135  Training loss = 2.6853  Validation loss = 4.1320  \n",
      "\n",
      "Fold: 13  Epoch: 136  Training loss = 2.6849  Validation loss = 4.1305  \n",
      "\n",
      "Fold: 13  Epoch: 137  Training loss = 2.6846  Validation loss = 4.1300  \n",
      "\n",
      "Fold: 13  Epoch: 138  Training loss = 2.6843  Validation loss = 4.1291  \n",
      "\n",
      "Fold: 13  Epoch: 139  Training loss = 2.6841  Validation loss = 4.1280  \n",
      "\n",
      "Fold: 13  Epoch: 140  Training loss = 2.6837  Validation loss = 4.1268  \n",
      "\n",
      "Fold: 13  Epoch: 141  Training loss = 2.6835  Validation loss = 4.1260  \n",
      "\n",
      "Fold: 13  Epoch: 142  Training loss = 2.6833  Validation loss = 4.1262  \n",
      "\n",
      "Fold: 13  Epoch: 143  Training loss = 2.6830  Validation loss = 4.1248  \n",
      "\n",
      "Fold: 13  Epoch: 144  Training loss = 2.6828  Validation loss = 4.1244  \n",
      "\n",
      "Fold: 13  Epoch: 145  Training loss = 2.6822  Validation loss = 4.1213  \n",
      "\n",
      "Fold: 13  Epoch: 146  Training loss = 2.6819  Validation loss = 4.1205  \n",
      "\n",
      "Fold: 13  Epoch: 147  Training loss = 2.6816  Validation loss = 4.1190  \n",
      "\n",
      "Fold: 13  Epoch: 148  Training loss = 2.6813  Validation loss = 4.1181  \n",
      "\n",
      "Fold: 13  Epoch: 149  Training loss = 2.6810  Validation loss = 4.1171  \n",
      "\n",
      "Fold: 13  Epoch: 150  Training loss = 2.6804  Validation loss = 4.1133  \n",
      "\n",
      "Fold: 13  Epoch: 151  Training loss = 2.6801  Validation loss = 4.1131  \n",
      "\n",
      "Fold: 13  Epoch: 152  Training loss = 2.6797  Validation loss = 4.1114  \n",
      "\n",
      "Fold: 13  Epoch: 153  Training loss = 2.6794  Validation loss = 4.1107  \n",
      "\n",
      "Fold: 13  Epoch: 154  Training loss = 2.6790  Validation loss = 4.1090  \n",
      "\n",
      "Fold: 13  Epoch: 155  Training loss = 2.6787  Validation loss = 4.1077  \n",
      "\n",
      "Fold: 13  Epoch: 156  Training loss = 2.6781  Validation loss = 4.1049  \n",
      "\n",
      "Fold: 13  Epoch: 157  Training loss = 2.6775  Validation loss = 4.1020  \n",
      "\n",
      "Fold: 13  Epoch: 158  Training loss = 2.6771  Validation loss = 4.1002  \n",
      "\n",
      "Fold: 13  Epoch: 159  Training loss = 2.6767  Validation loss = 4.0979  \n",
      "\n",
      "Fold: 13  Epoch: 160  Training loss = 2.6764  Validation loss = 4.0971  \n",
      "\n",
      "Fold: 13  Epoch: 161  Training loss = 2.6761  Validation loss = 4.0960  \n",
      "\n",
      "Fold: 13  Epoch: 162  Training loss = 2.6759  Validation loss = 4.0956  \n",
      "\n",
      "Fold: 13  Epoch: 163  Training loss = 2.6754  Validation loss = 4.0927  \n",
      "\n",
      "Fold: 13  Epoch: 164  Training loss = 2.6750  Validation loss = 4.0912  \n",
      "\n",
      "Fold: 13  Epoch: 165  Training loss = 2.6747  Validation loss = 4.0908  \n",
      "\n",
      "Fold: 13  Epoch: 166  Training loss = 2.6745  Validation loss = 4.0912  \n",
      "\n",
      "Fold: 13  Epoch: 167  Training loss = 2.6743  Validation loss = 4.0905  \n",
      "\n",
      "Fold: 13  Epoch: 168  Training loss = 2.6738  Validation loss = 4.0891  \n",
      "\n",
      "Fold: 13  Epoch: 169  Training loss = 2.6734  Validation loss = 4.0878  \n",
      "\n",
      "Fold: 13  Epoch: 170  Training loss = 2.6730  Validation loss = 4.0856  \n",
      "\n",
      "Fold: 13  Epoch: 171  Training loss = 2.6723  Validation loss = 4.0818  \n",
      "\n",
      "Fold: 13  Epoch: 172  Training loss = 2.6720  Validation loss = 4.0811  \n",
      "\n",
      "Fold: 13  Epoch: 173  Training loss = 2.6716  Validation loss = 4.0797  \n",
      "\n",
      "Fold: 13  Epoch: 174  Training loss = 2.6712  Validation loss = 4.0778  \n",
      "\n",
      "Fold: 13  Epoch: 175  Training loss = 2.6705  Validation loss = 4.0740  \n",
      "\n",
      "Fold: 13  Epoch: 176  Training loss = 2.6704  Validation loss = 4.0741  \n",
      "\n",
      "Fold: 13  Epoch: 177  Training loss = 2.6701  Validation loss = 4.0736  \n",
      "\n",
      "Fold: 13  Epoch: 178  Training loss = 2.6697  Validation loss = 4.0725  \n",
      "\n",
      "Fold: 13  Epoch: 179  Training loss = 2.6691  Validation loss = 4.0694  \n",
      "\n",
      "Fold: 13  Epoch: 180  Training loss = 2.6689  Validation loss = 4.0691  \n",
      "\n",
      "Fold: 13  Epoch: 181  Training loss = 2.6685  Validation loss = 4.0679  \n",
      "\n",
      "Fold: 13  Epoch: 182  Training loss = 2.6682  Validation loss = 4.0679  \n",
      "\n",
      "Fold: 13  Epoch: 183  Training loss = 2.6679  Validation loss = 4.0665  \n",
      "\n",
      "Fold: 13  Epoch: 184  Training loss = 2.6673  Validation loss = 4.0632  \n",
      "\n",
      "Fold: 13  Epoch: 185  Training loss = 2.6667  Validation loss = 4.0606  \n",
      "\n",
      "Fold: 13  Epoch: 186  Training loss = 2.6665  Validation loss = 4.0610  \n",
      "\n",
      "Fold: 13  Epoch: 187  Training loss = 2.6660  Validation loss = 4.0591  \n",
      "\n",
      "Fold: 13  Epoch: 188  Training loss = 2.6657  Validation loss = 4.0582  \n",
      "\n",
      "Fold: 13  Epoch: 189  Training loss = 2.6653  Validation loss = 4.0563  \n",
      "\n",
      "Fold: 13  Epoch: 190  Training loss = 2.6647  Validation loss = 4.0526  \n",
      "\n",
      "Fold: 13  Epoch: 191  Training loss = 2.6641  Validation loss = 4.0495  \n",
      "\n",
      "Fold: 13  Epoch: 192  Training loss = 2.6639  Validation loss = 4.0494  \n",
      "\n",
      "Fold: 13  Epoch: 193  Training loss = 2.6635  Validation loss = 4.0475  \n",
      "\n",
      "Fold: 13  Epoch: 194  Training loss = 2.6632  Validation loss = 4.0462  \n",
      "\n",
      "Fold: 13  Epoch: 195  Training loss = 2.6629  Validation loss = 4.0458  \n",
      "\n",
      "Fold: 13  Epoch: 196  Training loss = 2.6627  Validation loss = 4.0458  \n",
      "\n",
      "Fold: 13  Epoch: 197  Training loss = 2.6624  Validation loss = 4.0449  \n",
      "\n",
      "Fold: 13  Epoch: 198  Training loss = 2.6620  Validation loss = 4.0427  \n",
      "\n",
      "Fold: 13  Epoch: 199  Training loss = 2.6616  Validation loss = 4.0418  \n",
      "\n",
      "Fold: 13  Epoch: 200  Training loss = 2.6610  Validation loss = 4.0392  \n",
      "\n",
      "Fold: 13  Epoch: 201  Training loss = 2.6606  Validation loss = 4.0363  \n",
      "\n",
      "Fold: 13  Epoch: 202  Training loss = 2.6601  Validation loss = 4.0336  \n",
      "\n",
      "Fold: 13  Epoch: 203  Training loss = 2.6596  Validation loss = 4.0318  \n",
      "\n",
      "Fold: 13  Epoch: 204  Training loss = 2.6592  Validation loss = 4.0311  \n",
      "\n",
      "Fold: 13  Epoch: 205  Training loss = 2.6588  Validation loss = 4.0295  \n",
      "\n",
      "Fold: 13  Epoch: 206  Training loss = 2.6585  Validation loss = 4.0284  \n",
      "\n",
      "Fold: 13  Epoch: 207  Training loss = 2.6582  Validation loss = 4.0282  \n",
      "\n",
      "Fold: 13  Epoch: 208  Training loss = 2.6578  Validation loss = 4.0266  \n",
      "\n",
      "Fold: 13  Epoch: 209  Training loss = 2.6573  Validation loss = 4.0242  \n",
      "\n",
      "Fold: 13  Epoch: 210  Training loss = 2.6569  Validation loss = 4.0243  \n",
      "\n",
      "Fold: 13  Epoch: 211  Training loss = 2.6469  Validation loss = 4.0223  \n",
      "\n",
      "Fold: 13  Epoch: 212  Training loss = 2.6457  Validation loss = 4.0208  \n",
      "\n",
      "Fold: 13  Epoch: 213  Training loss = 2.6453  Validation loss = 4.0192  \n",
      "\n",
      "Fold: 13  Epoch: 214  Training loss = 2.6449  Validation loss = 4.0185  \n",
      "\n",
      "Fold: 13  Epoch: 215  Training loss = 2.6446  Validation loss = 4.0172  \n",
      "\n",
      "Fold: 13  Epoch: 216  Training loss = 2.6442  Validation loss = 4.0158  \n",
      "\n",
      "Fold: 13  Epoch: 217  Training loss = 2.6439  Validation loss = 4.0151  \n",
      "\n",
      "Fold: 13  Epoch: 218  Training loss = 2.6433  Validation loss = 4.0128  \n",
      "\n",
      "Fold: 13  Epoch: 219  Training loss = 2.6430  Validation loss = 4.0120  \n",
      "\n",
      "Fold: 13  Epoch: 220  Training loss = 2.6426  Validation loss = 4.0110  \n",
      "\n",
      "Fold: 13  Epoch: 221  Training loss = 2.6420  Validation loss = 4.0066  \n",
      "\n",
      "Fold: 13  Epoch: 222  Training loss = 2.6419  Validation loss = 4.0077  \n",
      "\n",
      "Fold: 13  Epoch: 223  Training loss = 2.6417  Validation loss = 4.0079  \n",
      "\n",
      "Fold: 13  Epoch: 224  Training loss = 2.6414  Validation loss = 4.0074  \n",
      "\n",
      "Fold: 13  Epoch: 225  Training loss = 2.6409  Validation loss = 4.0059  \n",
      "\n",
      "Fold: 13  Epoch: 226  Training loss = 2.6405  Validation loss = 4.0045  \n",
      "\n",
      "Fold: 13  Epoch: 227  Training loss = 2.6403  Validation loss = 4.0051  \n",
      "\n",
      "Fold: 13  Epoch: 228  Training loss = 2.6399  Validation loss = 4.0042  \n",
      "\n",
      "Fold: 13  Epoch: 229  Training loss = 2.6397  Validation loss = 4.0048  \n",
      "\n",
      "Fold: 13  Epoch: 230  Training loss = 2.6392  Validation loss = 4.0014  \n",
      "\n",
      "Fold: 13  Epoch: 231  Training loss = 2.6389  Validation loss = 4.0013  \n",
      "\n",
      "Fold: 13  Epoch: 232  Training loss = 2.6385  Validation loss = 4.0002  \n",
      "\n",
      "Fold: 13  Epoch: 233  Training loss = 2.6381  Validation loss = 3.9989  \n",
      "\n",
      "Fold: 13  Epoch: 234  Training loss = 2.6374  Validation loss = 3.9951  \n",
      "\n",
      "Fold: 13  Epoch: 235  Training loss = 2.6371  Validation loss = 3.9941  \n",
      "\n",
      "Fold: 13  Epoch: 236  Training loss = 2.6367  Validation loss = 3.9924  \n",
      "\n",
      "Fold: 13  Epoch: 237  Training loss = 2.6362  Validation loss = 3.9906  \n",
      "\n",
      "Fold: 13  Epoch: 238  Training loss = 2.6356  Validation loss = 3.9872  \n",
      "\n",
      "Fold: 13  Epoch: 239  Training loss = 2.6351  Validation loss = 3.9842  \n",
      "\n",
      "Fold: 13  Epoch: 240  Training loss = 2.6346  Validation loss = 3.9819  \n",
      "\n",
      "Fold: 13  Epoch: 241  Training loss = 2.6341  Validation loss = 3.9792  \n",
      "\n",
      "Fold: 13  Epoch: 242  Training loss = 2.6337  Validation loss = 3.9774  \n",
      "\n",
      "Fold: 13  Epoch: 243  Training loss = 2.6332  Validation loss = 3.9744  \n",
      "\n",
      "Fold: 13  Epoch: 244  Training loss = 2.6329  Validation loss = 3.9739  \n",
      "\n",
      "Fold: 13  Epoch: 245  Training loss = 2.6324  Validation loss = 3.9727  \n",
      "\n",
      "Fold: 13  Epoch: 246  Training loss = 2.6318  Validation loss = 3.9701  \n",
      "\n",
      "Fold: 13  Epoch: 247  Training loss = 2.6316  Validation loss = 3.9701  \n",
      "\n",
      "Fold: 13  Epoch: 248  Training loss = 2.6312  Validation loss = 3.9688  \n",
      "\n",
      "Fold: 13  Epoch: 249  Training loss = 2.6309  Validation loss = 3.9673  \n",
      "\n",
      "Fold: 13  Epoch: 250  Training loss = 2.6305  Validation loss = 3.9663  \n",
      "\n",
      "Fold: 13  Epoch: 251  Training loss = 2.6301  Validation loss = 3.9662  \n",
      "\n",
      "Fold: 13  Epoch: 252  Training loss = 2.6299  Validation loss = 3.9664  \n",
      "\n",
      "Fold: 13  Epoch: 253  Training loss = 2.6296  Validation loss = 3.9655  \n",
      "\n",
      "Fold: 13  Epoch: 254  Training loss = 2.6292  Validation loss = 3.9633  \n",
      "\n",
      "Fold: 13  Epoch: 255  Training loss = 2.6287  Validation loss = 3.9613  \n",
      "\n",
      "Fold: 13  Epoch: 256  Training loss = 2.6284  Validation loss = 3.9600  \n",
      "\n",
      "Fold: 13  Epoch: 257  Training loss = 2.6280  Validation loss = 3.9587  \n",
      "\n",
      "Fold: 13  Epoch: 258  Training loss = 2.6278  Validation loss = 3.9581  \n",
      "\n",
      "Fold: 13  Epoch: 259  Training loss = 2.6273  Validation loss = 3.9571  \n",
      "\n",
      "Fold: 13  Epoch: 260  Training loss = 2.6270  Validation loss = 3.9559  \n",
      "\n",
      "Fold: 13  Epoch: 261  Training loss = 2.6266  Validation loss = 3.9534  \n",
      "\n",
      "Fold: 13  Epoch: 262  Training loss = 2.6263  Validation loss = 3.9533  \n",
      "\n",
      "Fold: 13  Epoch: 263  Training loss = 2.6256  Validation loss = 3.9493  \n",
      "\n",
      "Fold: 13  Epoch: 264  Training loss = 2.6253  Validation loss = 3.9471  \n",
      "\n",
      "Fold: 13  Epoch: 265  Training loss = 2.6251  Validation loss = 3.9488  \n",
      "\n",
      "Fold: 13  Epoch: 266  Training loss = 2.6248  Validation loss = 3.9477  \n",
      "\n",
      "Fold: 13  Epoch: 267  Training loss = 2.6245  Validation loss = 3.9467  \n",
      "\n",
      "Fold: 13  Epoch: 268  Training loss = 2.6241  Validation loss = 3.9461  \n",
      "\n",
      "Fold: 13  Epoch: 269  Training loss = 2.6238  Validation loss = 3.9458  \n",
      "\n",
      "Fold: 13  Epoch: 270  Training loss = 2.6234  Validation loss = 3.9442  \n",
      "\n",
      "Fold: 13  Epoch: 271  Training loss = 2.6230  Validation loss = 3.9425  \n",
      "\n",
      "Fold: 13  Epoch: 272  Training loss = 2.6226  Validation loss = 3.9410  \n",
      "\n",
      "Fold: 13  Epoch: 273  Training loss = 2.6221  Validation loss = 3.9378  \n",
      "\n",
      "Fold: 13  Epoch: 274  Training loss = 2.6218  Validation loss = 3.9364  \n",
      "\n",
      "Fold: 13  Epoch: 275  Training loss = 2.6214  Validation loss = 3.9352  \n",
      "\n",
      "Fold: 13  Epoch: 276  Training loss = 2.6209  Validation loss = 3.9332  \n",
      "\n",
      "Fold: 13  Epoch: 277  Training loss = 2.6207  Validation loss = 3.9337  \n",
      "\n",
      "Fold: 13  Epoch: 278  Training loss = 2.6205  Validation loss = 3.9333  \n",
      "\n",
      "Fold: 13  Epoch: 279  Training loss = 2.6201  Validation loss = 3.9321  \n",
      "\n",
      "Fold: 13  Epoch: 280  Training loss = 2.6197  Validation loss = 3.9316  \n",
      "\n",
      "Fold: 13  Epoch: 281  Training loss = 2.6193  Validation loss = 3.9309  \n",
      "\n",
      "Fold: 13  Epoch: 282  Training loss = 2.6189  Validation loss = 3.9299  \n",
      "\n",
      "Fold: 13  Epoch: 283  Training loss = 2.6186  Validation loss = 3.9288  \n",
      "\n",
      "Fold: 13  Epoch: 284  Training loss = 2.6183  Validation loss = 3.9277  \n",
      "\n",
      "Fold: 13  Epoch: 285  Training loss = 2.6179  Validation loss = 3.9263  \n",
      "\n",
      "Fold: 13  Epoch: 286  Training loss = 2.6177  Validation loss = 3.9260  \n",
      "\n",
      "Fold: 13  Epoch: 287  Training loss = 2.6171  Validation loss = 3.9238  \n",
      "\n",
      "Fold: 13  Epoch: 288  Training loss = 2.6167  Validation loss = 3.9218  \n",
      "\n",
      "Fold: 13  Epoch: 289  Training loss = 2.6163  Validation loss = 3.9196  \n",
      "\n",
      "Fold: 13  Epoch: 290  Training loss = 2.6159  Validation loss = 3.9183  \n",
      "\n",
      "Fold: 13  Epoch: 291  Training loss = 2.6155  Validation loss = 3.9167  \n",
      "\n",
      "Fold: 13  Epoch: 292  Training loss = 2.6151  Validation loss = 3.9164  \n",
      "\n",
      "Fold: 13  Epoch: 293  Training loss = 2.6147  Validation loss = 3.9147  \n",
      "\n",
      "Fold: 13  Epoch: 294  Training loss = 2.6143  Validation loss = 3.9130  \n",
      "\n",
      "Fold: 13  Epoch: 295  Training loss = 2.6139  Validation loss = 3.9114  \n",
      "\n",
      "Fold: 13  Epoch: 296  Training loss = 2.6135  Validation loss = 3.9098  \n",
      "\n",
      "Fold: 13  Epoch: 297  Training loss = 2.6131  Validation loss = 3.9088  \n",
      "\n",
      "Fold: 13  Epoch: 298  Training loss = 2.6128  Validation loss = 3.9079  \n",
      "\n",
      "Fold: 13  Epoch: 299  Training loss = 2.6124  Validation loss = 3.9069  \n",
      "\n",
      "Fold: 13  Epoch: 300  Training loss = 2.6119  Validation loss = 3.9045  \n",
      "\n",
      "Fold: 13  Epoch: 301  Training loss = 2.6114  Validation loss = 3.9029  \n",
      "\n",
      "Fold: 13  Epoch: 302  Training loss = 2.6109  Validation loss = 3.9016  \n",
      "\n",
      "Fold: 13  Epoch: 303  Training loss = 2.6106  Validation loss = 3.8994  \n",
      "\n",
      "Fold: 13  Epoch: 304  Training loss = 2.6101  Validation loss = 3.8972  \n",
      "\n",
      "Fold: 13  Epoch: 305  Training loss = 2.6098  Validation loss = 3.8956  \n",
      "\n",
      "Fold: 13  Epoch: 306  Training loss = 2.6093  Validation loss = 3.8943  \n",
      "\n",
      "Fold: 13  Epoch: 307  Training loss = 2.6090  Validation loss = 3.8947  \n",
      "\n",
      "Fold: 13  Epoch: 308  Training loss = 2.6084  Validation loss = 3.8933  \n",
      "\n",
      "Fold: 13  Epoch: 309  Training loss = 2.6082  Validation loss = 3.8933  \n",
      "\n",
      "Fold: 13  Epoch: 310  Training loss = 2.6079  Validation loss = 3.8928  \n",
      "\n",
      "Fold: 13  Epoch: 311  Training loss = 2.6074  Validation loss = 3.8920  \n",
      "\n",
      "Fold: 13  Epoch: 312  Training loss = 2.6070  Validation loss = 3.8909  \n",
      "\n",
      "Fold: 13  Epoch: 313  Training loss = 2.6067  Validation loss = 3.8901  \n",
      "\n",
      "Fold: 13  Epoch: 314  Training loss = 2.6062  Validation loss = 3.8887  \n",
      "\n",
      "Fold: 13  Epoch: 315  Training loss = 2.6058  Validation loss = 3.8864  \n",
      "\n",
      "Fold: 13  Epoch: 316  Training loss = 2.6054  Validation loss = 3.8844  \n",
      "\n",
      "Fold: 13  Epoch: 317  Training loss = 2.6050  Validation loss = 3.8847  \n",
      "\n",
      "Fold: 13  Epoch: 318  Training loss = 2.6046  Validation loss = 3.8831  \n",
      "\n",
      "Fold: 13  Epoch: 319  Training loss = 2.6041  Validation loss = 3.8814  \n",
      "\n",
      "Fold: 13  Epoch: 320  Training loss = 2.6037  Validation loss = 3.8788  \n",
      "\n",
      "Fold: 13  Epoch: 321  Training loss = 2.6033  Validation loss = 3.8788  \n",
      "\n",
      "Fold: 13  Epoch: 322  Training loss = 2.6031  Validation loss = 3.8785  \n",
      "\n",
      "Fold: 13  Epoch: 323  Training loss = 2.6027  Validation loss = 3.8769  \n",
      "\n",
      "Fold: 13  Epoch: 324  Training loss = 2.6024  Validation loss = 3.8763  \n",
      "\n",
      "Fold: 13  Epoch: 325  Training loss = 2.6020  Validation loss = 3.8767  \n",
      "\n",
      "Fold: 13  Epoch: 326  Training loss = 2.6016  Validation loss = 3.8753  \n",
      "\n",
      "Fold: 13  Epoch: 327  Training loss = 2.6011  Validation loss = 3.8735  \n",
      "\n",
      "Fold: 13  Epoch: 328  Training loss = 2.6007  Validation loss = 3.8727  \n",
      "\n",
      "Fold: 13  Epoch: 329  Training loss = 2.6004  Validation loss = 3.8706  \n",
      "\n",
      "Fold: 13  Epoch: 330  Training loss = 2.6000  Validation loss = 3.8697  \n",
      "\n",
      "Fold: 13  Epoch: 331  Training loss = 2.5997  Validation loss = 3.8705  \n",
      "\n",
      "Fold: 13  Epoch: 332  Training loss = 2.5993  Validation loss = 3.8690  \n",
      "\n",
      "Fold: 13  Epoch: 333  Training loss = 2.5990  Validation loss = 3.8696  \n",
      "\n",
      "Fold: 13  Epoch: 334  Training loss = 2.5988  Validation loss = 3.8700  \n",
      "\n",
      "Fold: 13  Epoch: 335  Training loss = 2.5985  Validation loss = 3.8700  \n",
      "\n",
      "Fold: 13  Epoch: 336  Training loss = 2.5981  Validation loss = 3.8687  \n",
      "\n",
      "Fold: 13  Epoch: 337  Training loss = 2.5979  Validation loss = 3.8702  \n",
      "\n",
      "Fold: 13  Epoch: 338  Training loss = 2.5976  Validation loss = 3.8700  \n",
      "\n",
      "Fold: 13  Epoch: 339  Training loss = 2.5973  Validation loss = 3.8702  \n",
      "\n",
      "Fold: 13  Epoch: 340  Training loss = 2.5967  Validation loss = 3.8677  \n",
      "\n",
      "Fold: 13  Epoch: 341  Training loss = 2.5963  Validation loss = 3.8658  \n",
      "\n",
      "Fold: 13  Epoch: 342  Training loss = 2.5957  Validation loss = 3.8627  \n",
      "\n",
      "Fold: 13  Epoch: 343  Training loss = 2.5952  Validation loss = 3.8602  \n",
      "\n",
      "Fold: 13  Epoch: 344  Training loss = 2.5949  Validation loss = 3.8601  \n",
      "\n",
      "Fold: 13  Epoch: 345  Training loss = 2.5946  Validation loss = 3.8595  \n",
      "\n",
      "Fold: 13  Epoch: 346  Training loss = 2.5941  Validation loss = 3.8573  \n",
      "\n",
      "Fold: 13  Epoch: 347  Training loss = 2.5937  Validation loss = 3.8563  \n",
      "\n",
      "Fold: 13  Epoch: 348  Training loss = 2.5934  Validation loss = 3.8562  \n",
      "\n",
      "Fold: 13  Epoch: 349  Training loss = 2.5931  Validation loss = 3.8555  \n",
      "\n",
      "Fold: 13  Epoch: 350  Training loss = 2.5927  Validation loss = 3.8543  \n",
      "\n",
      "Fold: 13  Epoch: 351  Training loss = 2.5921  Validation loss = 3.8509  \n",
      "\n",
      "Fold: 13  Epoch: 352  Training loss = 2.5917  Validation loss = 3.8509  \n",
      "\n",
      "Fold: 13  Epoch: 353  Training loss = 2.5913  Validation loss = 3.8514  \n",
      "\n",
      "Fold: 13  Epoch: 354  Training loss = 2.5910  Validation loss = 3.8500  \n",
      "\n",
      "Fold: 13  Epoch: 355  Training loss = 2.5905  Validation loss = 3.8473  \n",
      "\n",
      "Fold: 13  Epoch: 356  Training loss = 2.5900  Validation loss = 3.8436  \n",
      "\n",
      "Fold: 13  Epoch: 357  Training loss = 2.5896  Validation loss = 3.8429  \n",
      "\n",
      "Fold: 13  Epoch: 358  Training loss = 2.5890  Validation loss = 3.8407  \n",
      "\n",
      "Fold: 13  Epoch: 359  Training loss = 2.5886  Validation loss = 3.8393  \n",
      "\n",
      "Fold: 13  Epoch: 360  Training loss = 2.5881  Validation loss = 3.8364  \n",
      "\n",
      "Fold: 13  Epoch: 361  Training loss = 2.5877  Validation loss = 3.8352  \n",
      "\n",
      "Fold: 13  Epoch: 362  Training loss = 2.5875  Validation loss = 3.8342  \n",
      "\n",
      "Fold: 13  Epoch: 363  Training loss = 2.5871  Validation loss = 3.8339  \n",
      "\n",
      "Fold: 13  Epoch: 364  Training loss = 2.5867  Validation loss = 3.8338  \n",
      "\n",
      "Fold: 13  Epoch: 365  Training loss = 2.5865  Validation loss = 3.8342  \n",
      "\n",
      "Fold: 13  Epoch: 366  Training loss = 2.5861  Validation loss = 3.8327  \n",
      "\n",
      "Fold: 13  Epoch: 367  Training loss = 2.5857  Validation loss = 3.8303  \n",
      "\n",
      "Fold: 13  Epoch: 368  Training loss = 2.5851  Validation loss = 3.8286  \n",
      "\n",
      "Fold: 13  Epoch: 369  Training loss = 2.5849  Validation loss = 3.8294  \n",
      "\n",
      "Fold: 13  Epoch: 370  Training loss = 2.5843  Validation loss = 3.8280  \n",
      "\n",
      "Fold: 13  Epoch: 371  Training loss = 2.5839  Validation loss = 3.8277  \n",
      "\n",
      "Fold: 13  Epoch: 372  Training loss = 2.5835  Validation loss = 3.8264  \n",
      "\n",
      "Fold: 13  Epoch: 373  Training loss = 2.5831  Validation loss = 3.8236  \n",
      "\n",
      "Fold: 13  Epoch: 374  Training loss = 2.5828  Validation loss = 3.8241  \n",
      "\n",
      "Fold: 13  Epoch: 375  Training loss = 2.5823  Validation loss = 3.8202  \n",
      "\n",
      "Fold: 13  Epoch: 376  Training loss = 2.5821  Validation loss = 3.8196  \n",
      "\n",
      "Fold: 13  Epoch: 377  Training loss = 2.5817  Validation loss = 3.8197  \n",
      "\n",
      "Fold: 13  Epoch: 378  Training loss = 2.5815  Validation loss = 3.8192  \n",
      "\n",
      "Fold: 13  Epoch: 379  Training loss = 2.5809  Validation loss = 3.8160  \n",
      "\n",
      "Fold: 13  Epoch: 380  Training loss = 2.5805  Validation loss = 3.8141  \n",
      "\n",
      "Fold: 13  Epoch: 381  Training loss = 2.5800  Validation loss = 3.8119  \n",
      "\n",
      "Fold: 13  Epoch: 382  Training loss = 2.5794  Validation loss = 3.8117  \n",
      "\n",
      "Fold: 13  Epoch: 383  Training loss = 2.5789  Validation loss = 3.8098  \n",
      "\n",
      "Fold: 13  Epoch: 384  Training loss = 2.5786  Validation loss = 3.8075  \n",
      "\n",
      "Fold: 13  Epoch: 385  Training loss = 2.5781  Validation loss = 3.8049  \n",
      "\n",
      "Fold: 13  Epoch: 386  Training loss = 2.5776  Validation loss = 3.8011  \n",
      "\n",
      "Fold: 13  Epoch: 387  Training loss = 2.5771  Validation loss = 3.7989  \n",
      "\n",
      "Fold: 13  Epoch: 388  Training loss = 2.5768  Validation loss = 3.7980  \n",
      "\n",
      "Fold: 13  Epoch: 389  Training loss = 2.5764  Validation loss = 3.7974  \n",
      "\n",
      "Fold: 13  Epoch: 390  Training loss = 2.5760  Validation loss = 3.7960  \n",
      "\n",
      "Fold: 13  Epoch: 391  Training loss = 2.5756  Validation loss = 3.7948  \n",
      "\n",
      "Fold: 13  Epoch: 392  Training loss = 2.5753  Validation loss = 3.7943  \n",
      "\n",
      "Fold: 13  Epoch: 393  Training loss = 2.5751  Validation loss = 3.7943  \n",
      "\n",
      "Fold: 13  Epoch: 394  Training loss = 2.5746  Validation loss = 3.7945  \n",
      "\n",
      "Fold: 13  Epoch: 395  Training loss = 2.5742  Validation loss = 3.7942  \n",
      "\n",
      "Fold: 13  Epoch: 396  Training loss = 2.5738  Validation loss = 3.7927  \n",
      "\n",
      "Fold: 13  Epoch: 397  Training loss = 2.5733  Validation loss = 3.7914  \n",
      "\n",
      "Fold: 13  Epoch: 398  Training loss = 2.5730  Validation loss = 3.7901  \n",
      "\n",
      "Fold: 13  Epoch: 399  Training loss = 2.5727  Validation loss = 3.7899  \n",
      "\n",
      "Fold: 13  Epoch: 400  Training loss = 2.5723  Validation loss = 3.7880  \n",
      "\n",
      "Fold: 13  Epoch: 401  Training loss = 2.5718  Validation loss = 3.7870  \n",
      "\n",
      "Fold: 13  Epoch: 402  Training loss = 2.5712  Validation loss = 3.7848  \n",
      "\n",
      "Fold: 13  Epoch: 403  Training loss = 2.5707  Validation loss = 3.7841  \n",
      "\n",
      "Fold: 13  Epoch: 404  Training loss = 2.5703  Validation loss = 3.7834  \n",
      "\n",
      "Fold: 13  Epoch: 405  Training loss = 2.5699  Validation loss = 3.7838  \n",
      "\n",
      "Fold: 13  Epoch: 406  Training loss = 2.5695  Validation loss = 3.7827  \n",
      "\n",
      "Fold: 13  Epoch: 407  Training loss = 2.5690  Validation loss = 3.7808  \n",
      "\n",
      "Fold: 13  Epoch: 408  Training loss = 2.5688  Validation loss = 3.7806  \n",
      "\n",
      "Fold: 13  Epoch: 409  Training loss = 2.5684  Validation loss = 3.7811  \n",
      "\n",
      "Fold: 13  Epoch: 410  Training loss = 2.5681  Validation loss = 3.7812  \n",
      "\n",
      "Fold: 13  Epoch: 411  Training loss = 2.5678  Validation loss = 3.7797  \n",
      "\n",
      "Fold: 13  Epoch: 412  Training loss = 2.5675  Validation loss = 3.7785  \n",
      "\n",
      "Fold: 13  Epoch: 413  Training loss = 2.5669  Validation loss = 3.7773  \n",
      "\n",
      "Fold: 13  Epoch: 414  Training loss = 2.5666  Validation loss = 3.7767  \n",
      "\n",
      "Fold: 13  Epoch: 415  Training loss = 2.5663  Validation loss = 3.7781  \n",
      "\n",
      "Fold: 13  Epoch: 416  Training loss = 2.5661  Validation loss = 3.7783  \n",
      "\n",
      "Fold: 13  Epoch: 417  Training loss = 2.5658  Validation loss = 3.7771  \n",
      "\n",
      "Fold: 13  Epoch: 418  Training loss = 2.5654  Validation loss = 3.7759  \n",
      "\n",
      "Fold: 13  Epoch: 419  Training loss = 2.5648  Validation loss = 3.7737  \n",
      "\n",
      "Fold: 13  Epoch: 420  Training loss = 2.5643  Validation loss = 3.7730  \n",
      "\n",
      "Fold: 13  Epoch: 421  Training loss = 2.5640  Validation loss = 3.7724  \n",
      "\n",
      "Fold: 13  Epoch: 422  Training loss = 2.5637  Validation loss = 3.7709  \n",
      "\n",
      "Fold: 13  Epoch: 423  Training loss = 2.5634  Validation loss = 3.7699  \n",
      "\n",
      "Fold: 13  Epoch: 424  Training loss = 2.5630  Validation loss = 3.7700  \n",
      "\n",
      "Fold: 13  Epoch: 425  Training loss = 2.5627  Validation loss = 3.7699  \n",
      "\n",
      "Fold: 13  Epoch: 426  Training loss = 2.5623  Validation loss = 3.7679  \n",
      "\n",
      "Fold: 13  Epoch: 427  Training loss = 2.5618  Validation loss = 3.7659  \n",
      "\n",
      "Fold: 13  Epoch: 428  Training loss = 2.5614  Validation loss = 3.7639  \n",
      "\n",
      "Fold: 13  Epoch: 429  Training loss = 2.5610  Validation loss = 3.7610  \n",
      "\n",
      "Fold: 13  Epoch: 430  Training loss = 2.5606  Validation loss = 3.7581  \n",
      "\n",
      "Fold: 13  Epoch: 431  Training loss = 2.5601  Validation loss = 3.7563  \n",
      "\n",
      "Fold: 13  Epoch: 432  Training loss = 2.5597  Validation loss = 3.7554  \n",
      "\n",
      "Fold: 13  Epoch: 433  Training loss = 2.5594  Validation loss = 3.7545  \n",
      "\n",
      "Fold: 13  Epoch: 434  Training loss = 2.5590  Validation loss = 3.7528  \n",
      "\n",
      "Fold: 13  Epoch: 435  Training loss = 2.5586  Validation loss = 3.7522  \n",
      "\n",
      "Fold: 13  Epoch: 436  Training loss = 2.5583  Validation loss = 3.7507  \n",
      "\n",
      "Fold: 13  Epoch: 437  Training loss = 2.5581  Validation loss = 3.7506  \n",
      "\n",
      "Fold: 13  Epoch: 438  Training loss = 2.5578  Validation loss = 3.7500  \n",
      "\n",
      "Fold: 13  Epoch: 439  Training loss = 2.5573  Validation loss = 3.7496  \n",
      "\n",
      "Fold: 13  Epoch: 440  Training loss = 2.5570  Validation loss = 3.7485  \n",
      "\n",
      "Fold: 13  Epoch: 441  Training loss = 2.5566  Validation loss = 3.7473  \n",
      "\n",
      "Fold: 13  Epoch: 442  Training loss = 2.5563  Validation loss = 3.7471  \n",
      "\n",
      "Fold: 13  Epoch: 443  Training loss = 2.5558  Validation loss = 3.7453  \n",
      "\n",
      "Fold: 13  Epoch: 444  Training loss = 2.5555  Validation loss = 3.7443  \n",
      "\n",
      "Fold: 13  Epoch: 445  Training loss = 2.5553  Validation loss = 3.7440  \n",
      "\n",
      "Fold: 13  Epoch: 446  Training loss = 2.5548  Validation loss = 3.7435  \n",
      "\n",
      "Fold: 13  Epoch: 447  Training loss = 2.5544  Validation loss = 3.7419  \n",
      "\n",
      "Fold: 13  Epoch: 448  Training loss = 2.5539  Validation loss = 3.7392  \n",
      "\n",
      "Fold: 13  Epoch: 449  Training loss = 2.5536  Validation loss = 3.7396  \n",
      "\n",
      "Fold: 13  Epoch: 450  Training loss = 2.5533  Validation loss = 3.7416  \n",
      "\n",
      "Fold: 13  Epoch: 451  Training loss = 2.5531  Validation loss = 3.7404  \n",
      "\n",
      "Fold: 13  Epoch: 452  Training loss = 2.5529  Validation loss = 3.7395  \n",
      "\n",
      "Fold: 13  Epoch: 453  Training loss = 2.5525  Validation loss = 3.7378  \n",
      "\n",
      "Fold: 13  Epoch: 454  Training loss = 2.5520  Validation loss = 3.7377  \n",
      "\n",
      "Fold: 13  Epoch: 455  Training loss = 2.5516  Validation loss = 3.7361  \n",
      "\n",
      "Fold: 13  Epoch: 456  Training loss = 2.5513  Validation loss = 3.7344  \n",
      "\n",
      "Fold: 13  Epoch: 457  Training loss = 2.5510  Validation loss = 3.7336  \n",
      "\n",
      "Fold: 13  Epoch: 458  Training loss = 2.5507  Validation loss = 3.7321  \n",
      "\n",
      "Fold: 13  Epoch: 459  Training loss = 2.5505  Validation loss = 3.7323  \n",
      "\n",
      "Fold: 13  Epoch: 460  Training loss = 2.5502  Validation loss = 3.7312  \n",
      "\n",
      "Fold: 13  Epoch: 461  Training loss = 2.5497  Validation loss = 3.7289  \n",
      "\n",
      "Fold: 13  Epoch: 462  Training loss = 2.5492  Validation loss = 3.7276  \n",
      "\n",
      "Fold: 13  Epoch: 463  Training loss = 2.5488  Validation loss = 3.7252  \n",
      "\n",
      "Fold: 13  Epoch: 464  Training loss = 2.5485  Validation loss = 3.7247  \n",
      "\n",
      "Fold: 13  Epoch: 465  Training loss = 2.5481  Validation loss = 3.7228  \n",
      "\n",
      "Fold: 13  Epoch: 466  Training loss = 2.5477  Validation loss = 3.7226  \n",
      "\n",
      "Fold: 13  Epoch: 467  Training loss = 2.5475  Validation loss = 3.7241  \n",
      "\n",
      "Fold: 13  Epoch: 468  Training loss = 2.5473  Validation loss = 3.7220  \n",
      "\n",
      "Fold: 13  Epoch: 469  Training loss = 2.5468  Validation loss = 3.7217  \n",
      "\n",
      "Fold: 13  Epoch: 470  Training loss = 2.5464  Validation loss = 3.7194  \n",
      "\n",
      "Fold: 13  Epoch: 471  Training loss = 2.5459  Validation loss = 3.7183  \n",
      "\n",
      "Fold: 13  Epoch: 472  Training loss = 2.5456  Validation loss = 3.7187  \n",
      "\n",
      "Fold: 13  Epoch: 473  Training loss = 2.5453  Validation loss = 3.7159  \n",
      "\n",
      "Fold: 13  Epoch: 474  Training loss = 2.5449  Validation loss = 3.7131  \n",
      "\n",
      "Fold: 13  Epoch: 475  Training loss = 2.5444  Validation loss = 3.7120  \n",
      "\n",
      "Fold: 13  Epoch: 476  Training loss = 2.5441  Validation loss = 3.7112  \n",
      "\n",
      "Fold: 13  Epoch: 477  Training loss = 2.5437  Validation loss = 3.7103  \n",
      "\n",
      "Fold: 13  Epoch: 478  Training loss = 2.5434  Validation loss = 3.7083  \n",
      "\n",
      "Fold: 13  Epoch: 479  Training loss = 2.5430  Validation loss = 3.7075  \n",
      "\n",
      "Fold: 13  Epoch: 480  Training loss = 2.5425  Validation loss = 3.7060  \n",
      "\n",
      "Fold: 13  Epoch: 481  Training loss = 2.5420  Validation loss = 3.7042  \n",
      "\n",
      "Fold: 13  Epoch: 482  Training loss = 2.5417  Validation loss = 3.7024  \n",
      "\n",
      "Fold: 13  Epoch: 483  Training loss = 2.5412  Validation loss = 3.6991  \n",
      "\n",
      "Fold: 13  Epoch: 484  Training loss = 2.5408  Validation loss = 3.6966  \n",
      "\n",
      "Fold: 13  Epoch: 485  Training loss = 2.5406  Validation loss = 3.6958  \n",
      "\n",
      "Fold: 13  Epoch: 486  Training loss = 2.5403  Validation loss = 3.6955  \n",
      "\n",
      "Fold: 13  Epoch: 487  Training loss = 2.5401  Validation loss = 3.6947  \n",
      "\n",
      "Fold: 13  Epoch: 488  Training loss = 2.5398  Validation loss = 3.6954  \n",
      "\n",
      "Fold: 13  Epoch: 489  Training loss = 2.5395  Validation loss = 3.6948  \n",
      "\n",
      "Fold: 13  Epoch: 490  Training loss = 2.5392  Validation loss = 3.6947  \n",
      "\n",
      "Fold: 13  Epoch: 491  Training loss = 2.5390  Validation loss = 3.6942  \n",
      "\n",
      "Fold: 13  Epoch: 492  Training loss = 2.5385  Validation loss = 3.6937  \n",
      "\n",
      "Fold: 13  Epoch: 493  Training loss = 2.5381  Validation loss = 3.6930  \n",
      "\n",
      "Fold: 13  Epoch: 494  Training loss = 2.5376  Validation loss = 3.6907  \n",
      "\n",
      "Fold: 13  Epoch: 495  Training loss = 2.5372  Validation loss = 3.6885  \n",
      "\n",
      "Fold: 13  Epoch: 496  Training loss = 2.5368  Validation loss = 3.6859  \n",
      "\n",
      "Fold: 13  Epoch: 497  Training loss = 2.5364  Validation loss = 3.6851  \n",
      "\n",
      "Fold: 13  Epoch: 498  Training loss = 2.5359  Validation loss = 3.6842  \n",
      "\n",
      "Fold: 13  Epoch: 499  Training loss = 2.5356  Validation loss = 3.6837  \n",
      "\n",
      "Fold: 13  Epoch: 500  Training loss = 2.5353  Validation loss = 3.6812  \n",
      "\n",
      "Check model:  Fold: 13  Optimal epoch: 500  \n",
      "\n",
      "Fold: 14  Epoch: 1  Training loss = 2.6424  Validation loss = 7.0921  \n",
      "\n",
      "Fold: 14  Epoch: 2  Training loss = 2.6416  Validation loss = 7.0885  \n",
      "\n",
      "Fold: 14  Epoch: 3  Training loss = 2.6412  Validation loss = 7.0872  \n",
      "\n",
      "Fold: 14  Epoch: 4  Training loss = 2.6408  Validation loss = 7.0853  \n",
      "\n",
      "Fold: 14  Epoch: 5  Training loss = 2.6403  Validation loss = 7.0838  \n",
      "\n",
      "Fold: 14  Epoch: 6  Training loss = 2.6398  Validation loss = 7.0815  \n",
      "\n",
      "Fold: 14  Epoch: 7  Training loss = 2.6391  Validation loss = 7.0791  \n",
      "\n",
      "Fold: 14  Epoch: 8  Training loss = 2.6384  Validation loss = 7.0760  \n",
      "\n",
      "Fold: 14  Epoch: 9  Training loss = 2.6374  Validation loss = 7.0713  \n",
      "\n",
      "Fold: 14  Epoch: 10  Training loss = 2.6367  Validation loss = 7.0681  \n",
      "\n",
      "Fold: 14  Epoch: 11  Training loss = 2.6363  Validation loss = 7.0667  \n",
      "\n",
      "Fold: 14  Epoch: 12  Training loss = 2.6355  Validation loss = 7.0632  \n",
      "\n",
      "Fold: 14  Epoch: 13  Training loss = 2.6348  Validation loss = 7.0608  \n",
      "\n",
      "Fold: 14  Epoch: 14  Training loss = 2.6343  Validation loss = 7.0586  \n",
      "\n",
      "Fold: 14  Epoch: 15  Training loss = 2.6335  Validation loss = 7.0558  \n",
      "\n",
      "Fold: 14  Epoch: 16  Training loss = 2.6332  Validation loss = 7.0540  \n",
      "\n",
      "Fold: 14  Epoch: 17  Training loss = 2.6327  Validation loss = 7.0519  \n",
      "\n",
      "Fold: 14  Epoch: 18  Training loss = 2.6322  Validation loss = 7.0505  \n",
      "\n",
      "Fold: 14  Epoch: 19  Training loss = 2.6314  Validation loss = 7.0473  \n",
      "\n",
      "Fold: 14  Epoch: 20  Training loss = 2.6310  Validation loss = 7.0458  \n",
      "\n",
      "Fold: 14  Epoch: 21  Training loss = 2.6307  Validation loss = 7.0447  \n",
      "\n",
      "Fold: 14  Epoch: 22  Training loss = 2.6298  Validation loss = 7.0411  \n",
      "\n",
      "Fold: 14  Epoch: 23  Training loss = 2.6289  Validation loss = 7.0356  \n",
      "\n",
      "Fold: 14  Epoch: 24  Training loss = 2.6283  Validation loss = 7.0333  \n",
      "\n",
      "Fold: 14  Epoch: 25  Training loss = 2.6276  Validation loss = 7.0296  \n",
      "\n",
      "Fold: 14  Epoch: 26  Training loss = 2.6271  Validation loss = 7.0280  \n",
      "\n",
      "Fold: 14  Epoch: 27  Training loss = 2.6269  Validation loss = 7.0281  \n",
      "\n",
      "Fold: 14  Epoch: 28  Training loss = 2.6265  Validation loss = 7.0267  \n",
      "\n",
      "Fold: 14  Epoch: 29  Training loss = 2.6256  Validation loss = 7.0224  \n",
      "\n",
      "Fold: 14  Epoch: 30  Training loss = 2.6254  Validation loss = 7.0228  \n",
      "\n",
      "Fold: 14  Epoch: 31  Training loss = 2.6248  Validation loss = 7.0203  \n",
      "\n",
      "Fold: 14  Epoch: 32  Training loss = 2.6244  Validation loss = 7.0188  \n",
      "\n",
      "Fold: 14  Epoch: 33  Training loss = 2.6241  Validation loss = 7.0188  \n",
      "\n",
      "Fold: 14  Epoch: 34  Training loss = 2.6237  Validation loss = 7.0172  \n",
      "\n",
      "Fold: 14  Epoch: 35  Training loss = 2.6230  Validation loss = 7.0142  \n",
      "\n",
      "Fold: 14  Epoch: 36  Training loss = 2.6222  Validation loss = 7.0104  \n",
      "\n",
      "Fold: 14  Epoch: 37  Training loss = 2.6218  Validation loss = 7.0089  \n",
      "\n",
      "Fold: 14  Epoch: 38  Training loss = 2.6213  Validation loss = 7.0070  \n",
      "\n",
      "Fold: 14  Epoch: 39  Training loss = 2.6210  Validation loss = 7.0058  \n",
      "\n",
      "Fold: 14  Epoch: 40  Training loss = 2.6203  Validation loss = 7.0030  \n",
      "\n",
      "Fold: 14  Epoch: 41  Training loss = 2.6199  Validation loss = 7.0015  \n",
      "\n",
      "Fold: 14  Epoch: 42  Training loss = 2.6193  Validation loss = 6.9989  \n",
      "\n",
      "Fold: 14  Epoch: 43  Training loss = 2.6187  Validation loss = 6.9960  \n",
      "\n",
      "Fold: 14  Epoch: 44  Training loss = 2.6184  Validation loss = 6.9955  \n",
      "\n",
      "Fold: 14  Epoch: 45  Training loss = 2.6178  Validation loss = 6.9927  \n",
      "\n",
      "Fold: 14  Epoch: 46  Training loss = 2.6176  Validation loss = 6.9922  \n",
      "\n",
      "Fold: 14  Epoch: 47  Training loss = 2.6170  Validation loss = 6.9900  \n",
      "\n",
      "Fold: 14  Epoch: 48  Training loss = 2.6169  Validation loss = 6.9905  \n",
      "\n",
      "Fold: 14  Epoch: 49  Training loss = 2.6163  Validation loss = 6.9876  \n",
      "\n",
      "Fold: 14  Epoch: 50  Training loss = 2.6158  Validation loss = 6.9854  \n",
      "\n",
      "Fold: 14  Epoch: 51  Training loss = 2.6153  Validation loss = 6.9838  \n",
      "\n",
      "Fold: 14  Epoch: 52  Training loss = 2.6151  Validation loss = 6.9837  \n",
      "\n",
      "Fold: 14  Epoch: 53  Training loss = 2.6148  Validation loss = 6.9830  \n",
      "\n",
      "Fold: 14  Epoch: 54  Training loss = 2.6143  Validation loss = 6.9811  \n",
      "\n",
      "Fold: 14  Epoch: 55  Training loss = 2.6136  Validation loss = 6.9776  \n",
      "\n",
      "Fold: 14  Epoch: 56  Training loss = 2.6132  Validation loss = 6.9764  \n",
      "\n",
      "Fold: 14  Epoch: 57  Training loss = 2.6126  Validation loss = 6.9735  \n",
      "\n",
      "Fold: 14  Epoch: 58  Training loss = 2.6123  Validation loss = 6.9729  \n",
      "\n",
      "Fold: 14  Epoch: 59  Training loss = 2.6119  Validation loss = 6.9709  \n",
      "\n",
      "Fold: 14  Epoch: 60  Training loss = 2.6115  Validation loss = 6.9693  \n",
      "\n",
      "Fold: 14  Epoch: 61  Training loss = 2.6110  Validation loss = 6.9672  \n",
      "\n",
      "Fold: 14  Epoch: 62  Training loss = 2.6107  Validation loss = 6.9663  \n",
      "\n",
      "Fold: 14  Epoch: 63  Training loss = 2.6100  Validation loss = 6.9627  \n",
      "\n",
      "Fold: 14  Epoch: 64  Training loss = 2.6098  Validation loss = 6.9627  \n",
      "\n",
      "Fold: 14  Epoch: 65  Training loss = 2.6093  Validation loss = 6.9607  \n",
      "\n",
      "Fold: 14  Epoch: 66  Training loss = 2.6087  Validation loss = 6.9582  \n",
      "\n",
      "Fold: 14  Epoch: 67  Training loss = 2.6081  Validation loss = 6.9552  \n",
      "\n",
      "Fold: 14  Epoch: 68  Training loss = 2.6075  Validation loss = 6.9525  \n",
      "\n",
      "Fold: 14  Epoch: 69  Training loss = 2.6069  Validation loss = 6.9501  \n",
      "\n",
      "Fold: 14  Epoch: 70  Training loss = 2.6064  Validation loss = 6.9483  \n",
      "\n",
      "Fold: 14  Epoch: 71  Training loss = 2.6061  Validation loss = 6.9472  \n",
      "\n",
      "Fold: 14  Epoch: 72  Training loss = 2.6057  Validation loss = 6.9456  \n",
      "\n",
      "Fold: 14  Epoch: 73  Training loss = 2.6054  Validation loss = 6.9454  \n",
      "\n",
      "Fold: 14  Epoch: 74  Training loss = 2.6049  Validation loss = 6.9431  \n",
      "\n",
      "Fold: 14  Epoch: 75  Training loss = 2.6042  Validation loss = 6.9404  \n",
      "\n",
      "Fold: 14  Epoch: 76  Training loss = 2.6035  Validation loss = 6.9362  \n",
      "\n",
      "Fold: 14  Epoch: 77  Training loss = 2.6027  Validation loss = 6.9319  \n",
      "\n",
      "Fold: 14  Epoch: 78  Training loss = 2.6021  Validation loss = 6.9297  \n",
      "\n",
      "Fold: 14  Epoch: 79  Training loss = 2.6018  Validation loss = 6.9287  \n",
      "\n",
      "Fold: 14  Epoch: 80  Training loss = 2.6010  Validation loss = 6.9243  \n",
      "\n",
      "Fold: 14  Epoch: 81  Training loss = 2.6001  Validation loss = 6.9193  \n",
      "\n",
      "Fold: 14  Epoch: 82  Training loss = 2.5997  Validation loss = 6.9178  \n",
      "\n",
      "Fold: 14  Epoch: 83  Training loss = 2.5993  Validation loss = 6.9166  \n",
      "\n",
      "Fold: 14  Epoch: 84  Training loss = 2.5986  Validation loss = 6.9128  \n",
      "\n",
      "Fold: 14  Epoch: 85  Training loss = 2.5979  Validation loss = 6.9089  \n",
      "\n",
      "Fold: 14  Epoch: 86  Training loss = 2.5972  Validation loss = 6.9056  \n",
      "\n",
      "Fold: 14  Epoch: 87  Training loss = 2.5969  Validation loss = 6.9043  \n",
      "\n",
      "Fold: 14  Epoch: 88  Training loss = 2.5964  Validation loss = 6.9019  \n",
      "\n",
      "Fold: 14  Epoch: 89  Training loss = 2.5960  Validation loss = 6.9003  \n",
      "\n",
      "Fold: 14  Epoch: 90  Training loss = 2.5957  Validation loss = 6.8997  \n",
      "\n",
      "Fold: 14  Epoch: 91  Training loss = 2.5951  Validation loss = 6.8966  \n",
      "\n",
      "Fold: 14  Epoch: 92  Training loss = 2.5945  Validation loss = 6.8927  \n",
      "\n",
      "Fold: 14  Epoch: 93  Training loss = 2.5940  Validation loss = 6.8899  \n",
      "\n",
      "Fold: 14  Epoch: 94  Training loss = 2.5934  Validation loss = 6.8873  \n",
      "\n",
      "Fold: 14  Epoch: 95  Training loss = 2.5931  Validation loss = 6.8852  \n",
      "\n",
      "Fold: 14  Epoch: 96  Training loss = 2.5927  Validation loss = 6.8842  \n",
      "\n",
      "Fold: 14  Epoch: 97  Training loss = 2.5923  Validation loss = 6.8820  \n",
      "\n",
      "Fold: 14  Epoch: 98  Training loss = 2.5919  Validation loss = 6.8810  \n",
      "\n",
      "Fold: 14  Epoch: 99  Training loss = 2.5915  Validation loss = 6.8793  \n",
      "\n",
      "Fold: 14  Epoch: 100  Training loss = 2.5907  Validation loss = 6.8737  \n",
      "\n",
      "Fold: 14  Epoch: 101  Training loss = 2.5905  Validation loss = 6.8732  \n",
      "\n",
      "Fold: 14  Epoch: 102  Training loss = 2.5902  Validation loss = 6.8727  \n",
      "\n",
      "Fold: 14  Epoch: 103  Training loss = 2.5898  Validation loss = 6.8703  \n",
      "\n",
      "Fold: 14  Epoch: 104  Training loss = 2.5894  Validation loss = 6.8685  \n",
      "\n",
      "Fold: 14  Epoch: 105  Training loss = 2.5888  Validation loss = 6.8657  \n",
      "\n",
      "Fold: 14  Epoch: 106  Training loss = 2.5883  Validation loss = 6.8639  \n",
      "\n",
      "Fold: 14  Epoch: 107  Training loss = 2.5878  Validation loss = 6.8607  \n",
      "\n",
      "Fold: 14  Epoch: 108  Training loss = 2.5872  Validation loss = 6.8574  \n",
      "\n",
      "Fold: 14  Epoch: 109  Training loss = 2.5867  Validation loss = 6.8546  \n",
      "\n",
      "Fold: 14  Epoch: 110  Training loss = 2.5861  Validation loss = 6.8524  \n",
      "\n",
      "Fold: 14  Epoch: 111  Training loss = 2.5856  Validation loss = 6.8488  \n",
      "\n",
      "Fold: 14  Epoch: 112  Training loss = 2.5852  Validation loss = 6.8481  \n",
      "\n",
      "Fold: 14  Epoch: 113  Training loss = 2.5849  Validation loss = 6.8476  \n",
      "\n",
      "Fold: 14  Epoch: 114  Training loss = 2.5847  Validation loss = 6.8471  \n",
      "\n",
      "Fold: 14  Epoch: 115  Training loss = 2.5841  Validation loss = 6.8440  \n",
      "\n",
      "Fold: 14  Epoch: 116  Training loss = 2.5836  Validation loss = 6.8418  \n",
      "\n",
      "Fold: 14  Epoch: 117  Training loss = 2.5832  Validation loss = 6.8401  \n",
      "\n",
      "Fold: 14  Epoch: 118  Training loss = 2.5828  Validation loss = 6.8381  \n",
      "\n",
      "Fold: 14  Epoch: 119  Training loss = 2.5825  Validation loss = 6.8376  \n",
      "\n",
      "Fold: 14  Epoch: 120  Training loss = 2.5821  Validation loss = 6.8371  \n",
      "\n",
      "Fold: 14  Epoch: 121  Training loss = 2.5817  Validation loss = 6.8354  \n",
      "\n",
      "Fold: 14  Epoch: 122  Training loss = 2.5814  Validation loss = 6.8350  \n",
      "\n",
      "Fold: 14  Epoch: 123  Training loss = 2.5810  Validation loss = 6.8330  \n",
      "\n",
      "Fold: 14  Epoch: 124  Training loss = 2.5804  Validation loss = 6.8296  \n",
      "\n",
      "Fold: 14  Epoch: 125  Training loss = 2.5799  Validation loss = 6.8278  \n",
      "\n",
      "Fold: 14  Epoch: 126  Training loss = 2.5759  Validation loss = 6.8274  \n",
      "\n",
      "Fold: 14  Epoch: 127  Training loss = 2.5734  Validation loss = 6.8245  \n",
      "\n",
      "Fold: 14  Epoch: 128  Training loss = 2.5732  Validation loss = 6.8241  \n",
      "\n",
      "Fold: 14  Epoch: 129  Training loss = 2.5730  Validation loss = 6.8236  \n",
      "\n",
      "Fold: 14  Epoch: 130  Training loss = 2.5728  Validation loss = 6.8233  \n",
      "\n",
      "Fold: 14  Epoch: 131  Training loss = 2.5723  Validation loss = 6.8205  \n",
      "\n",
      "Fold: 14  Epoch: 132  Training loss = 2.5722  Validation loss = 6.8210  \n",
      "\n",
      "Fold: 14  Epoch: 133  Training loss = 2.5715  Validation loss = 6.8170  \n",
      "\n",
      "Fold: 14  Epoch: 134  Training loss = 2.5712  Validation loss = 6.8157  \n",
      "\n",
      "Fold: 14  Epoch: 135  Training loss = 2.5707  Validation loss = 6.8121  \n",
      "\n",
      "Fold: 14  Epoch: 136  Training loss = 2.5705  Validation loss = 6.8113  \n",
      "\n",
      "Fold: 14  Epoch: 137  Training loss = 2.5700  Validation loss = 6.8092  \n",
      "\n",
      "Fold: 14  Epoch: 138  Training loss = 2.5698  Validation loss = 6.8086  \n",
      "\n",
      "Fold: 14  Epoch: 139  Training loss = 2.5692  Validation loss = 6.8055  \n",
      "\n",
      "Fold: 14  Epoch: 140  Training loss = 2.5688  Validation loss = 6.8036  \n",
      "\n",
      "Fold: 14  Epoch: 141  Training loss = 2.5685  Validation loss = 6.8020  \n",
      "\n",
      "Fold: 14  Epoch: 142  Training loss = 2.5681  Validation loss = 6.8003  \n",
      "\n",
      "Fold: 14  Epoch: 143  Training loss = 2.5677  Validation loss = 6.7983  \n",
      "\n",
      "Fold: 14  Epoch: 144  Training loss = 2.5674  Validation loss = 6.7974  \n",
      "\n",
      "Fold: 14  Epoch: 145  Training loss = 2.5669  Validation loss = 6.7957  \n",
      "\n",
      "Fold: 14  Epoch: 146  Training loss = 2.5664  Validation loss = 6.7920  \n",
      "\n",
      "Fold: 14  Epoch: 147  Training loss = 2.5661  Validation loss = 6.7916  \n",
      "\n",
      "Fold: 14  Epoch: 148  Training loss = 2.5657  Validation loss = 6.7892  \n",
      "\n",
      "Fold: 14  Epoch: 149  Training loss = 2.5654  Validation loss = 6.7879  \n",
      "\n",
      "Fold: 14  Epoch: 150  Training loss = 2.5649  Validation loss = 6.7856  \n",
      "\n",
      "Fold: 14  Epoch: 151  Training loss = 2.5646  Validation loss = 6.7837  \n",
      "\n",
      "Fold: 14  Epoch: 152  Training loss = 2.5644  Validation loss = 6.7838  \n",
      "\n",
      "Fold: 14  Epoch: 153  Training loss = 2.5640  Validation loss = 6.7821  \n",
      "\n",
      "Fold: 14  Epoch: 154  Training loss = 2.5637  Validation loss = 6.7807  \n",
      "\n",
      "Fold: 14  Epoch: 155  Training loss = 2.5635  Validation loss = 6.7796  \n",
      "\n",
      "Fold: 14  Epoch: 156  Training loss = 2.5630  Validation loss = 6.7772  \n",
      "\n",
      "Fold: 14  Epoch: 157  Training loss = 2.5628  Validation loss = 6.7764  \n",
      "\n",
      "Fold: 14  Epoch: 158  Training loss = 2.5623  Validation loss = 6.7743  \n",
      "\n",
      "Fold: 14  Epoch: 159  Training loss = 2.5620  Validation loss = 6.7733  \n",
      "\n",
      "Fold: 14  Epoch: 160  Training loss = 2.5615  Validation loss = 6.7703  \n",
      "\n",
      "Fold: 14  Epoch: 161  Training loss = 2.5613  Validation loss = 6.7699  \n",
      "\n",
      "Fold: 14  Epoch: 162  Training loss = 2.5611  Validation loss = 6.7697  \n",
      "\n",
      "Fold: 14  Epoch: 163  Training loss = 2.5608  Validation loss = 6.7683  \n",
      "\n",
      "Fold: 14  Epoch: 164  Training loss = 2.5605  Validation loss = 6.7679  \n",
      "\n",
      "Fold: 14  Epoch: 165  Training loss = 2.5603  Validation loss = 6.7675  \n",
      "\n",
      "Fold: 14  Epoch: 166  Training loss = 2.5601  Validation loss = 6.7673  \n",
      "\n",
      "Fold: 14  Epoch: 167  Training loss = 2.5598  Validation loss = 6.7665  \n",
      "\n",
      "Fold: 14  Epoch: 168  Training loss = 2.5596  Validation loss = 6.7646  \n",
      "\n",
      "Fold: 14  Epoch: 169  Training loss = 2.5591  Validation loss = 6.7623  \n",
      "\n",
      "Fold: 14  Epoch: 170  Training loss = 2.5589  Validation loss = 6.7612  \n",
      "\n",
      "Fold: 14  Epoch: 171  Training loss = 2.5587  Validation loss = 6.7605  \n",
      "\n",
      "Fold: 14  Epoch: 172  Training loss = 2.5583  Validation loss = 6.7579  \n",
      "\n",
      "Fold: 14  Epoch: 173  Training loss = 2.5579  Validation loss = 6.7561  \n",
      "\n",
      "Fold: 14  Epoch: 174  Training loss = 2.5576  Validation loss = 6.7560  \n",
      "\n",
      "Fold: 14  Epoch: 175  Training loss = 2.5571  Validation loss = 6.7523  \n",
      "\n",
      "Fold: 14  Epoch: 176  Training loss = 2.5567  Validation loss = 6.7501  \n",
      "\n",
      "Fold: 14  Epoch: 177  Training loss = 2.5565  Validation loss = 6.7501  \n",
      "\n",
      "Fold: 14  Epoch: 178  Training loss = 2.5561  Validation loss = 6.7478  \n",
      "\n",
      "Fold: 14  Epoch: 179  Training loss = 2.5557  Validation loss = 6.7459  \n",
      "\n",
      "Fold: 14  Epoch: 180  Training loss = 2.5553  Validation loss = 6.7442  \n",
      "\n",
      "Fold: 14  Epoch: 181  Training loss = 2.5549  Validation loss = 6.7423  \n",
      "\n",
      "Fold: 14  Epoch: 182  Training loss = 2.5546  Validation loss = 6.7417  \n",
      "\n",
      "Fold: 14  Epoch: 183  Training loss = 2.5542  Validation loss = 6.7395  \n",
      "\n",
      "Fold: 14  Epoch: 184  Training loss = 2.5537  Validation loss = 6.7368  \n",
      "\n",
      "Fold: 14  Epoch: 185  Training loss = 2.5533  Validation loss = 6.7343  \n",
      "\n",
      "Fold: 14  Epoch: 186  Training loss = 2.5530  Validation loss = 6.7339  \n",
      "\n",
      "Fold: 14  Epoch: 187  Training loss = 2.5528  Validation loss = 6.7329  \n",
      "\n",
      "Fold: 14  Epoch: 188  Training loss = 2.5524  Validation loss = 6.7305  \n",
      "\n",
      "Fold: 14  Epoch: 189  Training loss = 2.5522  Validation loss = 6.7313  \n",
      "\n",
      "Fold: 14  Epoch: 190  Training loss = 2.5520  Validation loss = 6.7303  \n",
      "\n",
      "Fold: 14  Epoch: 191  Training loss = 2.5516  Validation loss = 6.7292  \n",
      "\n",
      "Fold: 14  Epoch: 192  Training loss = 2.5514  Validation loss = 6.7291  \n",
      "\n",
      "Fold: 14  Epoch: 193  Training loss = 2.5510  Validation loss = 6.7268  \n",
      "\n",
      "Fold: 14  Epoch: 194  Training loss = 2.5505  Validation loss = 6.7242  \n",
      "\n",
      "Fold: 14  Epoch: 195  Training loss = 2.5503  Validation loss = 6.7238  \n",
      "\n",
      "Fold: 14  Epoch: 196  Training loss = 2.5500  Validation loss = 6.7226  \n",
      "\n",
      "Fold: 14  Epoch: 197  Training loss = 2.5499  Validation loss = 6.7226  \n",
      "\n",
      "Fold: 14  Epoch: 198  Training loss = 2.5496  Validation loss = 6.7219  \n",
      "\n",
      "Fold: 14  Epoch: 199  Training loss = 2.5493  Validation loss = 6.7213  \n",
      "\n",
      "Fold: 14  Epoch: 200  Training loss = 2.5490  Validation loss = 6.7207  \n",
      "\n",
      "Fold: 14  Epoch: 201  Training loss = 2.5488  Validation loss = 6.7209  \n",
      "\n",
      "Fold: 14  Epoch: 202  Training loss = 2.5485  Validation loss = 6.7206  \n",
      "\n",
      "Fold: 14  Epoch: 203  Training loss = 2.5483  Validation loss = 6.7210  \n",
      "\n",
      "Fold: 14  Epoch: 204  Training loss = 2.5480  Validation loss = 6.7196  \n",
      "\n",
      "Fold: 14  Epoch: 205  Training loss = 2.5474  Validation loss = 6.7164  \n",
      "\n",
      "Fold: 14  Epoch: 206  Training loss = 2.5471  Validation loss = 6.7145  \n",
      "\n",
      "Fold: 14  Epoch: 207  Training loss = 2.5468  Validation loss = 6.7128  \n",
      "\n",
      "Fold: 14  Epoch: 208  Training loss = 2.5464  Validation loss = 6.7102  \n",
      "\n",
      "Fold: 14  Epoch: 209  Training loss = 2.5461  Validation loss = 6.7088  \n",
      "\n",
      "Fold: 14  Epoch: 210  Training loss = 2.5461  Validation loss = 6.7097  \n",
      "\n",
      "Fold: 14  Epoch: 211  Training loss = 2.5453  Validation loss = 6.7052  \n",
      "\n",
      "Fold: 14  Epoch: 212  Training loss = 2.5452  Validation loss = 6.7050  \n",
      "\n",
      "Fold: 14  Epoch: 213  Training loss = 2.5447  Validation loss = 6.7015  \n",
      "\n",
      "Fold: 14  Epoch: 214  Training loss = 2.5440  Validation loss = 6.6980  \n",
      "\n",
      "Fold: 14  Epoch: 215  Training loss = 2.5437  Validation loss = 6.6966  \n",
      "\n",
      "Fold: 14  Epoch: 216  Training loss = 2.5434  Validation loss = 6.6958  \n",
      "\n",
      "Fold: 14  Epoch: 217  Training loss = 2.5432  Validation loss = 6.6952  \n",
      "\n",
      "Fold: 14  Epoch: 218  Training loss = 2.5430  Validation loss = 6.6951  \n",
      "\n",
      "Fold: 14  Epoch: 219  Training loss = 2.5425  Validation loss = 6.6921  \n",
      "\n",
      "Fold: 14  Epoch: 220  Training loss = 2.5419  Validation loss = 6.6884  \n",
      "\n",
      "Fold: 14  Epoch: 221  Training loss = 2.5417  Validation loss = 6.6882  \n",
      "\n",
      "Fold: 14  Epoch: 222  Training loss = 2.5414  Validation loss = 6.6866  \n",
      "\n",
      "Fold: 14  Epoch: 223  Training loss = 2.5413  Validation loss = 6.6877  \n",
      "\n",
      "Fold: 14  Epoch: 224  Training loss = 2.5409  Validation loss = 6.6864  \n",
      "\n",
      "Fold: 14  Epoch: 225  Training loss = 2.5407  Validation loss = 6.6859  \n",
      "\n",
      "Fold: 14  Epoch: 226  Training loss = 2.5402  Validation loss = 6.6832  \n",
      "\n",
      "Fold: 14  Epoch: 227  Training loss = 2.5398  Validation loss = 6.6814  \n",
      "\n",
      "Fold: 14  Epoch: 228  Training loss = 2.5394  Validation loss = 6.6798  \n",
      "\n",
      "Fold: 14  Epoch: 229  Training loss = 2.5392  Validation loss = 6.6796  \n",
      "\n",
      "Fold: 14  Epoch: 230  Training loss = 2.5387  Validation loss = 6.6759  \n",
      "\n",
      "Fold: 14  Epoch: 231  Training loss = 2.5385  Validation loss = 6.6753  \n",
      "\n",
      "Fold: 14  Epoch: 232  Training loss = 2.5380  Validation loss = 6.6731  \n",
      "\n",
      "Fold: 14  Epoch: 233  Training loss = 2.5375  Validation loss = 6.6700  \n",
      "\n",
      "Fold: 14  Epoch: 234  Training loss = 2.5372  Validation loss = 6.6698  \n",
      "\n",
      "Fold: 14  Epoch: 235  Training loss = 2.5368  Validation loss = 6.6674  \n",
      "\n",
      "Fold: 14  Epoch: 236  Training loss = 2.5366  Validation loss = 6.6665  \n",
      "\n",
      "Fold: 14  Epoch: 237  Training loss = 2.5363  Validation loss = 6.6651  \n",
      "\n",
      "Fold: 14  Epoch: 238  Training loss = 2.5361  Validation loss = 6.6641  \n",
      "\n",
      "Fold: 14  Epoch: 239  Training loss = 2.5362  Validation loss = 6.6671  \n",
      "\n",
      "Fold: 14  Epoch: 240  Training loss = 2.5357  Validation loss = 6.6645  \n",
      "\n",
      "Fold: 14  Epoch: 241  Training loss = 2.5353  Validation loss = 6.6622  \n",
      "\n",
      "Fold: 14  Epoch: 242  Training loss = 2.5348  Validation loss = 6.6592  \n",
      "\n",
      "Fold: 14  Epoch: 243  Training loss = 2.5345  Validation loss = 6.6580  \n",
      "\n",
      "Fold: 14  Epoch: 244  Training loss = 2.5342  Validation loss = 6.6566  \n",
      "\n",
      "Fold: 14  Epoch: 245  Training loss = 2.5338  Validation loss = 6.6542  \n",
      "\n",
      "Fold: 14  Epoch: 246  Training loss = 2.5334  Validation loss = 6.6520  \n",
      "\n",
      "Fold: 14  Epoch: 247  Training loss = 2.5332  Validation loss = 6.6524  \n",
      "\n",
      "Fold: 14  Epoch: 248  Training loss = 2.5329  Validation loss = 6.6509  \n",
      "\n",
      "Fold: 14  Epoch: 249  Training loss = 2.5326  Validation loss = 6.6504  \n",
      "\n",
      "Fold: 14  Epoch: 250  Training loss = 2.5325  Validation loss = 6.6499  \n",
      "\n",
      "Fold: 14  Epoch: 251  Training loss = 2.5321  Validation loss = 6.6466  \n",
      "\n",
      "Fold: 14  Epoch: 252  Training loss = 2.5316  Validation loss = 6.6432  \n",
      "\n",
      "Fold: 14  Epoch: 253  Training loss = 2.5313  Validation loss = 6.6413  \n",
      "\n",
      "Fold: 14  Epoch: 254  Training loss = 2.5310  Validation loss = 6.6405  \n",
      "\n",
      "Fold: 14  Epoch: 255  Training loss = 2.5309  Validation loss = 6.6409  \n",
      "\n",
      "Fold: 14  Epoch: 256  Training loss = 2.5304  Validation loss = 6.6375  \n",
      "\n",
      "Fold: 14  Epoch: 257  Training loss = 2.5300  Validation loss = 6.6367  \n",
      "\n",
      "Fold: 14  Epoch: 258  Training loss = 2.5298  Validation loss = 6.6359  \n",
      "\n",
      "Fold: 14  Epoch: 259  Training loss = 2.5294  Validation loss = 6.6320  \n",
      "\n",
      "Fold: 14  Epoch: 260  Training loss = 2.5291  Validation loss = 6.6302  \n",
      "\n",
      "Fold: 14  Epoch: 261  Training loss = 2.5289  Validation loss = 6.6304  \n",
      "\n",
      "Fold: 14  Epoch: 262  Training loss = 2.5286  Validation loss = 6.6290  \n",
      "\n",
      "Fold: 14  Epoch: 263  Training loss = 2.5284  Validation loss = 6.6286  \n",
      "\n",
      "Fold: 14  Epoch: 264  Training loss = 2.5281  Validation loss = 6.6279  \n",
      "\n",
      "Fold: 14  Epoch: 265  Training loss = 2.5282  Validation loss = 6.6307  \n",
      "\n",
      "Fold: 14  Epoch: 266  Training loss = 2.5276  Validation loss = 6.6271  \n",
      "\n",
      "Fold: 14  Epoch: 267  Training loss = 2.5273  Validation loss = 6.6243  \n",
      "\n",
      "Fold: 14  Epoch: 268  Training loss = 2.5269  Validation loss = 6.6224  \n",
      "\n",
      "Fold: 14  Epoch: 269  Training loss = 2.5265  Validation loss = 6.6207  \n",
      "\n",
      "Fold: 14  Epoch: 270  Training loss = 2.5263  Validation loss = 6.6206  \n",
      "\n",
      "Fold: 14  Epoch: 271  Training loss = 2.5262  Validation loss = 6.6203  \n",
      "\n",
      "Fold: 14  Epoch: 272  Training loss = 2.5259  Validation loss = 6.6197  \n",
      "\n",
      "Fold: 14  Epoch: 273  Training loss = 2.5256  Validation loss = 6.6187  \n",
      "\n",
      "Fold: 14  Epoch: 274  Training loss = 2.5253  Validation loss = 6.6173  \n",
      "\n",
      "Fold: 14  Epoch: 275  Training loss = 2.5250  Validation loss = 6.6155  \n",
      "\n",
      "Fold: 14  Epoch: 276  Training loss = 2.5249  Validation loss = 6.6149  \n",
      "\n",
      "Fold: 14  Epoch: 277  Training loss = 2.5245  Validation loss = 6.6123  \n",
      "\n",
      "Fold: 14  Epoch: 278  Training loss = 2.5242  Validation loss = 6.6109  \n",
      "\n",
      "Fold: 14  Epoch: 279  Training loss = 2.5238  Validation loss = 6.6091  \n",
      "\n",
      "Fold: 14  Epoch: 280  Training loss = 2.5235  Validation loss = 6.6071  \n",
      "\n",
      "Fold: 14  Epoch: 281  Training loss = 2.5231  Validation loss = 6.6059  \n",
      "\n",
      "Fold: 14  Epoch: 282  Training loss = 2.5226  Validation loss = 6.6028  \n",
      "\n",
      "Fold: 14  Epoch: 283  Training loss = 2.5222  Validation loss = 6.6017  \n",
      "\n",
      "Fold: 14  Epoch: 284  Training loss = 2.5219  Validation loss = 6.6003  \n",
      "\n",
      "Fold: 14  Epoch: 285  Training loss = 2.5218  Validation loss = 6.6011  \n",
      "\n",
      "Fold: 14  Epoch: 286  Training loss = 2.5217  Validation loss = 6.6018  \n",
      "\n",
      "Fold: 14  Epoch: 287  Training loss = 2.5210  Validation loss = 6.5967  \n",
      "\n",
      "Fold: 14  Epoch: 288  Training loss = 2.5208  Validation loss = 6.5966  \n",
      "\n",
      "Fold: 14  Epoch: 289  Training loss = 2.5205  Validation loss = 6.5955  \n",
      "\n",
      "Fold: 14  Epoch: 290  Training loss = 2.5204  Validation loss = 6.5948  \n",
      "\n",
      "Fold: 14  Epoch: 291  Training loss = 2.5200  Validation loss = 6.5919  \n",
      "\n",
      "Fold: 14  Epoch: 292  Training loss = 2.5197  Validation loss = 6.5903  \n",
      "\n",
      "Fold: 14  Epoch: 293  Training loss = 2.5194  Validation loss = 6.5884  \n",
      "\n",
      "Fold: 14  Epoch: 294  Training loss = 2.5190  Validation loss = 6.5853  \n",
      "\n",
      "Fold: 14  Epoch: 295  Training loss = 2.5188  Validation loss = 6.5848  \n",
      "\n",
      "Fold: 14  Epoch: 296  Training loss = 2.5185  Validation loss = 6.5837  \n",
      "\n",
      "Fold: 14  Epoch: 297  Training loss = 2.5183  Validation loss = 6.5836  \n",
      "\n",
      "Fold: 14  Epoch: 298  Training loss = 2.5180  Validation loss = 6.5820  \n",
      "\n",
      "Fold: 14  Epoch: 299  Training loss = 2.5176  Validation loss = 6.5792  \n",
      "\n",
      "Fold: 14  Epoch: 300  Training loss = 2.5172  Validation loss = 6.5760  \n",
      "\n",
      "Fold: 14  Epoch: 301  Training loss = 2.5169  Validation loss = 6.5737  \n",
      "\n",
      "Fold: 14  Epoch: 302  Training loss = 2.5168  Validation loss = 6.5741  \n",
      "\n",
      "Fold: 14  Epoch: 303  Training loss = 2.5165  Validation loss = 6.5737  \n",
      "\n",
      "Fold: 14  Epoch: 304  Training loss = 2.5160  Validation loss = 6.5696  \n",
      "\n",
      "Fold: 14  Epoch: 305  Training loss = 2.5155  Validation loss = 6.5667  \n",
      "\n",
      "Fold: 14  Epoch: 306  Training loss = 2.5154  Validation loss = 6.5666  \n",
      "\n",
      "Fold: 14  Epoch: 307  Training loss = 2.5151  Validation loss = 6.5665  \n",
      "\n",
      "Fold: 14  Epoch: 308  Training loss = 2.5151  Validation loss = 6.5668  \n",
      "\n",
      "Fold: 14  Epoch: 309  Training loss = 2.5148  Validation loss = 6.5651  \n",
      "\n",
      "Fold: 14  Epoch: 310  Training loss = 2.5146  Validation loss = 6.5650  \n",
      "\n",
      "Fold: 14  Epoch: 311  Training loss = 2.5143  Validation loss = 6.5628  \n",
      "\n",
      "Fold: 14  Epoch: 312  Training loss = 2.5140  Validation loss = 6.5612  \n",
      "\n",
      "Fold: 14  Epoch: 313  Training loss = 2.5136  Validation loss = 6.5581  \n",
      "\n",
      "Fold: 14  Epoch: 314  Training loss = 2.5134  Validation loss = 6.5566  \n",
      "\n",
      "Fold: 14  Epoch: 315  Training loss = 2.5132  Validation loss = 6.5550  \n",
      "\n",
      "Fold: 14  Epoch: 316  Training loss = 2.5130  Validation loss = 6.5554  \n",
      "\n",
      "Fold: 14  Epoch: 317  Training loss = 2.5127  Validation loss = 6.5535  \n",
      "\n",
      "Fold: 14  Epoch: 318  Training loss = 2.5124  Validation loss = 6.5518  \n",
      "\n",
      "Fold: 14  Epoch: 319  Training loss = 2.5122  Validation loss = 6.5517  \n",
      "\n",
      "Fold: 14  Epoch: 320  Training loss = 2.5117  Validation loss = 6.5478  \n",
      "\n",
      "Fold: 14  Epoch: 321  Training loss = 2.5115  Validation loss = 6.5480  \n",
      "\n",
      "Fold: 14  Epoch: 322  Training loss = 2.5113  Validation loss = 6.5475  \n",
      "\n",
      "Fold: 14  Epoch: 323  Training loss = 2.5110  Validation loss = 6.5466  \n",
      "\n",
      "Fold: 14  Epoch: 324  Training loss = 2.5106  Validation loss = 6.5448  \n",
      "\n",
      "Fold: 14  Epoch: 325  Training loss = 2.5103  Validation loss = 6.5434  \n",
      "\n",
      "Fold: 14  Epoch: 326  Training loss = 2.5100  Validation loss = 6.5419  \n",
      "\n",
      "Fold: 14  Epoch: 327  Training loss = 2.5098  Validation loss = 6.5407  \n",
      "\n",
      "Fold: 14  Epoch: 328  Training loss = 2.5099  Validation loss = 6.5433  \n",
      "\n",
      "Fold: 14  Epoch: 329  Training loss = 2.5095  Validation loss = 6.5416  \n",
      "\n",
      "Fold: 14  Epoch: 330  Training loss = 2.5092  Validation loss = 6.5415  \n",
      "\n",
      "Fold: 14  Epoch: 331  Training loss = 2.5090  Validation loss = 6.5410  \n",
      "\n",
      "Fold: 14  Epoch: 332  Training loss = 2.5087  Validation loss = 6.5395  \n",
      "\n",
      "Fold: 14  Epoch: 333  Training loss = 2.5085  Validation loss = 6.5387  \n",
      "\n",
      "Fold: 14  Epoch: 334  Training loss = 2.5081  Validation loss = 6.5366  \n",
      "\n",
      "Fold: 14  Epoch: 335  Training loss = 2.5076  Validation loss = 6.5343  \n",
      "\n",
      "Fold: 14  Epoch: 336  Training loss = 2.5069  Validation loss = 6.5321  \n",
      "\n",
      "Fold: 14  Epoch: 337  Training loss = 2.5053  Validation loss = 6.5322  \n",
      "\n",
      "Fold: 14  Epoch: 338  Training loss = 2.5051  Validation loss = 6.5324  \n",
      "\n",
      "Fold: 14  Epoch: 339  Training loss = 2.5048  Validation loss = 6.5302  \n",
      "\n",
      "Fold: 14  Epoch: 340  Training loss = 2.5044  Validation loss = 6.5287  \n",
      "\n",
      "Fold: 14  Epoch: 341  Training loss = 2.5040  Validation loss = 6.5272  \n",
      "\n",
      "Fold: 14  Epoch: 342  Training loss = 2.5037  Validation loss = 6.5258  \n",
      "\n",
      "Fold: 14  Epoch: 343  Training loss = 2.5035  Validation loss = 6.5259  \n",
      "\n",
      "Fold: 14  Epoch: 344  Training loss = 2.5034  Validation loss = 6.5268  \n",
      "\n",
      "Fold: 14  Epoch: 345  Training loss = 2.5028  Validation loss = 6.5220  \n",
      "\n",
      "Fold: 14  Epoch: 346  Training loss = 2.5025  Validation loss = 6.5198  \n",
      "\n",
      "Fold: 14  Epoch: 347  Training loss = 2.5023  Validation loss = 6.5191  \n",
      "\n",
      "Fold: 14  Epoch: 348  Training loss = 2.5022  Validation loss = 6.5179  \n",
      "\n",
      "Fold: 14  Epoch: 349  Training loss = 2.5021  Validation loss = 6.5184  \n",
      "\n",
      "Fold: 14  Epoch: 350  Training loss = 2.5018  Validation loss = 6.5164  \n",
      "\n",
      "Fold: 14  Epoch: 351  Training loss = 2.5014  Validation loss = 6.5141  \n",
      "\n",
      "Fold: 14  Epoch: 352  Training loss = 2.5012  Validation loss = 6.5146  \n",
      "\n",
      "Fold: 14  Epoch: 353  Training loss = 2.5009  Validation loss = 6.5137  \n",
      "\n",
      "Fold: 14  Epoch: 354  Training loss = 2.5006  Validation loss = 6.5113  \n",
      "\n",
      "Fold: 14  Epoch: 355  Training loss = 2.5002  Validation loss = 6.5104  \n",
      "\n",
      "Fold: 14  Epoch: 356  Training loss = 2.4997  Validation loss = 6.5075  \n",
      "\n",
      "Fold: 14  Epoch: 357  Training loss = 2.4994  Validation loss = 6.5046  \n",
      "\n",
      "Fold: 14  Epoch: 358  Training loss = 2.4990  Validation loss = 6.5023  \n",
      "\n",
      "Fold: 14  Epoch: 359  Training loss = 2.4987  Validation loss = 6.5007  \n",
      "\n",
      "Fold: 14  Epoch: 360  Training loss = 2.4983  Validation loss = 6.4975  \n",
      "\n",
      "Fold: 14  Epoch: 361  Training loss = 2.4980  Validation loss = 6.4946  \n",
      "\n",
      "Fold: 14  Epoch: 362  Training loss = 2.4977  Validation loss = 6.4921  \n",
      "\n",
      "Fold: 14  Epoch: 363  Training loss = 2.4976  Validation loss = 6.4933  \n",
      "\n",
      "Fold: 14  Epoch: 364  Training loss = 2.4973  Validation loss = 6.4937  \n",
      "\n",
      "Fold: 14  Epoch: 365  Training loss = 2.4972  Validation loss = 6.4921  \n",
      "\n",
      "Fold: 14  Epoch: 366  Training loss = 2.4970  Validation loss = 6.4905  \n",
      "\n",
      "Fold: 14  Epoch: 367  Training loss = 2.4966  Validation loss = 6.4882  \n",
      "\n",
      "Fold: 14  Epoch: 368  Training loss = 2.4965  Validation loss = 6.4881  \n",
      "\n",
      "Fold: 14  Epoch: 369  Training loss = 2.4962  Validation loss = 6.4862  \n",
      "\n",
      "Fold: 14  Epoch: 370  Training loss = 2.4961  Validation loss = 6.4856  \n",
      "\n",
      "Fold: 14  Epoch: 371  Training loss = 2.4959  Validation loss = 6.4853  \n",
      "\n",
      "Fold: 14  Epoch: 372  Training loss = 2.4957  Validation loss = 6.4865  \n",
      "\n",
      "Fold: 14  Epoch: 373  Training loss = 2.4955  Validation loss = 6.4847  \n",
      "\n",
      "Fold: 14  Epoch: 374  Training loss = 2.4951  Validation loss = 6.4827  \n",
      "\n",
      "Fold: 14  Epoch: 375  Training loss = 2.4949  Validation loss = 6.4823  \n",
      "\n",
      "Fold: 14  Epoch: 376  Training loss = 2.4944  Validation loss = 6.4786  \n",
      "\n",
      "Fold: 14  Epoch: 377  Training loss = 2.4942  Validation loss = 6.4796  \n",
      "\n",
      "Fold: 14  Epoch: 378  Training loss = 2.4940  Validation loss = 6.4786  \n",
      "\n",
      "Fold: 14  Epoch: 379  Training loss = 2.4938  Validation loss = 6.4785  \n",
      "\n",
      "Fold: 14  Epoch: 380  Training loss = 2.4935  Validation loss = 6.4773  \n",
      "\n",
      "Fold: 14  Epoch: 381  Training loss = 2.4933  Validation loss = 6.4767  \n",
      "\n",
      "Fold: 14  Epoch: 382  Training loss = 2.4930  Validation loss = 6.4743  \n",
      "\n",
      "Fold: 14  Epoch: 383  Training loss = 2.4929  Validation loss = 6.4749  \n",
      "\n",
      "Fold: 14  Epoch: 384  Training loss = 2.4927  Validation loss = 6.4746  \n",
      "\n",
      "Fold: 14  Epoch: 385  Training loss = 2.4926  Validation loss = 6.4756  \n",
      "\n",
      "Fold: 14  Epoch: 386  Training loss = 2.4923  Validation loss = 6.4737  \n",
      "\n",
      "Fold: 14  Epoch: 387  Training loss = 2.4920  Validation loss = 6.4721  \n",
      "\n",
      "Fold: 14  Epoch: 388  Training loss = 2.4919  Validation loss = 6.4725  \n",
      "\n",
      "Fold: 14  Epoch: 389  Training loss = 2.4916  Validation loss = 6.4719  \n",
      "\n",
      "Fold: 14  Epoch: 390  Training loss = 2.4912  Validation loss = 6.4677  \n",
      "\n",
      "Fold: 14  Epoch: 391  Training loss = 2.4910  Validation loss = 6.4663  \n",
      "\n",
      "Fold: 14  Epoch: 392  Training loss = 2.4908  Validation loss = 6.4671  \n",
      "\n",
      "Fold: 14  Epoch: 393  Training loss = 2.4906  Validation loss = 6.4655  \n",
      "\n",
      "Fold: 14  Epoch: 394  Training loss = 2.4902  Validation loss = 6.4629  \n",
      "\n",
      "Fold: 14  Epoch: 395  Training loss = 2.4900  Validation loss = 6.4617  \n",
      "\n",
      "Fold: 14  Epoch: 396  Training loss = 2.4899  Validation loss = 6.4611  \n",
      "\n",
      "Fold: 14  Epoch: 397  Training loss = 2.4896  Validation loss = 6.4588  \n",
      "\n",
      "Fold: 14  Epoch: 398  Training loss = 2.4893  Validation loss = 6.4573  \n",
      "\n",
      "Fold: 14  Epoch: 399  Training loss = 2.4891  Validation loss = 6.4563  \n",
      "\n",
      "Fold: 14  Epoch: 400  Training loss = 2.4889  Validation loss = 6.4542  \n",
      "\n",
      "Fold: 14  Epoch: 401  Training loss = 2.4885  Validation loss = 6.4506  \n",
      "\n",
      "Fold: 14  Epoch: 402  Training loss = 2.4883  Validation loss = 6.4493  \n",
      "\n",
      "Fold: 14  Epoch: 403  Training loss = 2.4880  Validation loss = 6.4460  \n",
      "\n",
      "Fold: 14  Epoch: 404  Training loss = 2.4878  Validation loss = 6.4431  \n",
      "\n",
      "Fold: 14  Epoch: 405  Training loss = 2.4876  Validation loss = 6.4429  \n",
      "\n",
      "Fold: 14  Epoch: 406  Training loss = 2.4874  Validation loss = 6.4424  \n",
      "\n",
      "Fold: 14  Epoch: 407  Training loss = 2.4871  Validation loss = 6.4404  \n",
      "\n",
      "Fold: 14  Epoch: 408  Training loss = 2.4867  Validation loss = 6.4390  \n",
      "\n",
      "Fold: 14  Epoch: 409  Training loss = 2.4866  Validation loss = 6.4394  \n",
      "\n",
      "Fold: 14  Epoch: 410  Training loss = 2.4863  Validation loss = 6.4369  \n",
      "\n",
      "Fold: 14  Epoch: 411  Training loss = 2.4860  Validation loss = 6.4361  \n",
      "\n",
      "Fold: 14  Epoch: 412  Training loss = 2.4858  Validation loss = 6.4351  \n",
      "\n",
      "Fold: 14  Epoch: 413  Training loss = 2.4855  Validation loss = 6.4335  \n",
      "\n",
      "Fold: 14  Epoch: 414  Training loss = 2.4853  Validation loss = 6.4322  \n",
      "\n",
      "Fold: 14  Epoch: 415  Training loss = 2.4850  Validation loss = 6.4328  \n",
      "\n",
      "Fold: 14  Epoch: 416  Training loss = 2.4848  Validation loss = 6.4323  \n",
      "\n",
      "Fold: 14  Epoch: 417  Training loss = 2.4845  Validation loss = 6.4297  \n",
      "\n",
      "Fold: 14  Epoch: 418  Training loss = 2.4842  Validation loss = 6.4295  \n",
      "\n",
      "Fold: 14  Epoch: 419  Training loss = 2.4839  Validation loss = 6.4294  \n",
      "\n",
      "Fold: 14  Epoch: 420  Training loss = 2.4835  Validation loss = 6.4263  \n",
      "\n",
      "Fold: 14  Epoch: 421  Training loss = 2.4831  Validation loss = 6.4221  \n",
      "\n",
      "Fold: 14  Epoch: 422  Training loss = 2.4828  Validation loss = 6.4198  \n",
      "\n",
      "Fold: 14  Epoch: 423  Training loss = 2.4824  Validation loss = 6.4179  \n",
      "\n",
      "Fold: 14  Epoch: 424  Training loss = 2.4820  Validation loss = 6.4155  \n",
      "\n",
      "Fold: 14  Epoch: 425  Training loss = 2.4819  Validation loss = 6.4158  \n",
      "\n",
      "Fold: 14  Epoch: 426  Training loss = 2.4816  Validation loss = 6.4142  \n",
      "\n",
      "Fold: 14  Epoch: 427  Training loss = 2.4813  Validation loss = 6.4143  \n",
      "\n",
      "Fold: 14  Epoch: 428  Training loss = 2.4811  Validation loss = 6.4141  \n",
      "\n",
      "Fold: 14  Epoch: 429  Training loss = 2.4808  Validation loss = 6.4123  \n",
      "\n",
      "Fold: 14  Epoch: 430  Training loss = 2.4806  Validation loss = 6.4120  \n",
      "\n",
      "Fold: 14  Epoch: 431  Training loss = 2.4805  Validation loss = 6.4122  \n",
      "\n",
      "Fold: 14  Epoch: 432  Training loss = 2.4803  Validation loss = 6.4114  \n",
      "\n",
      "Fold: 14  Epoch: 433  Training loss = 2.4799  Validation loss = 6.4086  \n",
      "\n",
      "Fold: 14  Epoch: 434  Training loss = 2.4796  Validation loss = 6.4081  \n",
      "\n",
      "Fold: 14  Epoch: 435  Training loss = 2.4794  Validation loss = 6.4076  \n",
      "\n",
      "Fold: 14  Epoch: 436  Training loss = 2.4793  Validation loss = 6.4077  \n",
      "\n",
      "Fold: 14  Epoch: 437  Training loss = 2.4791  Validation loss = 6.4063  \n",
      "\n",
      "Fold: 14  Epoch: 438  Training loss = 2.4790  Validation loss = 6.4067  \n",
      "\n",
      "Fold: 14  Epoch: 439  Training loss = 2.4790  Validation loss = 6.4093  \n",
      "\n",
      "Fold: 14  Epoch: 440  Training loss = 2.4789  Validation loss = 6.4109  \n",
      "\n",
      "Fold: 14  Epoch: 441  Training loss = 2.4786  Validation loss = 6.4087  \n",
      "\n",
      "Fold: 14  Epoch: 442  Training loss = 2.4784  Validation loss = 6.4079  \n",
      "\n",
      "Fold: 14  Epoch: 443  Training loss = 2.4782  Validation loss = 6.4067  \n",
      "\n",
      "Fold: 14  Epoch: 444  Training loss = 2.4778  Validation loss = 6.4050  \n",
      "\n",
      "Fold: 14  Epoch: 445  Training loss = 2.4774  Validation loss = 6.4018  \n",
      "\n",
      "Fold: 14  Epoch: 446  Training loss = 2.4771  Validation loss = 6.4008  \n",
      "\n",
      "Fold: 14  Epoch: 447  Training loss = 2.4770  Validation loss = 6.4026  \n",
      "\n",
      "Fold: 14  Epoch: 448  Training loss = 2.4768  Validation loss = 6.4029  \n",
      "\n",
      "Fold: 14  Epoch: 449  Training loss = 2.4766  Validation loss = 6.4033  \n",
      "\n",
      "Fold: 14  Epoch: 450  Training loss = 2.4765  Validation loss = 6.4035  \n",
      "\n",
      "Fold: 14  Epoch: 451  Training loss = 2.4762  Validation loss = 6.4020  \n",
      "\n",
      "Fold: 14  Epoch: 452  Training loss = 2.4761  Validation loss = 6.4012  \n",
      "\n",
      "Fold: 14  Epoch: 453  Training loss = 2.4759  Validation loss = 6.4010  \n",
      "\n",
      "Fold: 14  Epoch: 454  Training loss = 2.4756  Validation loss = 6.3989  \n",
      "\n",
      "Fold: 14  Epoch: 455  Training loss = 2.4753  Validation loss = 6.3983  \n",
      "\n",
      "Fold: 14  Epoch: 456  Training loss = 2.4751  Validation loss = 6.3960  \n",
      "\n",
      "Fold: 14  Epoch: 457  Training loss = 2.4750  Validation loss = 6.3963  \n",
      "\n",
      "Fold: 14  Epoch: 458  Training loss = 2.4748  Validation loss = 6.3958  \n",
      "\n",
      "Fold: 14  Epoch: 459  Training loss = 2.4746  Validation loss = 6.3950  \n",
      "\n",
      "Fold: 14  Epoch: 460  Training loss = 2.4744  Validation loss = 6.3941  \n",
      "\n",
      "Fold: 14  Epoch: 461  Training loss = 2.4740  Validation loss = 6.3924  \n",
      "\n",
      "Fold: 14  Epoch: 462  Training loss = 2.4738  Validation loss = 6.3923  \n",
      "\n",
      "Fold: 14  Epoch: 463  Training loss = 2.4735  Validation loss = 6.3899  \n",
      "\n",
      "Fold: 14  Epoch: 464  Training loss = 2.4732  Validation loss = 6.3890  \n",
      "\n",
      "Fold: 14  Epoch: 465  Training loss = 2.4729  Validation loss = 6.3866  \n",
      "\n",
      "Fold: 14  Epoch: 466  Training loss = 2.4724  Validation loss = 6.3836  \n",
      "\n",
      "Fold: 14  Epoch: 467  Training loss = 2.4723  Validation loss = 6.3841  \n",
      "\n",
      "Fold: 14  Epoch: 468  Training loss = 2.4721  Validation loss = 6.3840  \n",
      "\n",
      "Fold: 14  Epoch: 469  Training loss = 2.4717  Validation loss = 6.3822  \n",
      "\n",
      "Fold: 14  Epoch: 470  Training loss = 2.4715  Validation loss = 6.3825  \n",
      "\n",
      "Fold: 14  Epoch: 471  Training loss = 2.4713  Validation loss = 6.3814  \n",
      "\n",
      "Fold: 14  Epoch: 472  Training loss = 2.4711  Validation loss = 6.3819  \n",
      "\n",
      "Fold: 14  Epoch: 473  Training loss = 2.4710  Validation loss = 6.3825  \n",
      "\n",
      "Fold: 14  Epoch: 474  Training loss = 2.4706  Validation loss = 6.3788  \n",
      "\n",
      "Fold: 14  Epoch: 475  Training loss = 2.4703  Validation loss = 6.3760  \n",
      "\n",
      "Fold: 14  Epoch: 476  Training loss = 2.4699  Validation loss = 6.3747  \n",
      "\n",
      "Fold: 14  Epoch: 477  Training loss = 2.4697  Validation loss = 6.3744  \n",
      "\n",
      "Fold: 14  Epoch: 478  Training loss = 2.4693  Validation loss = 6.3715  \n",
      "\n",
      "Fold: 14  Epoch: 479  Training loss = 2.4693  Validation loss = 6.3729  \n",
      "\n",
      "Fold: 14  Epoch: 480  Training loss = 2.4689  Validation loss = 6.3697  \n",
      "\n",
      "Fold: 14  Epoch: 481  Training loss = 2.4687  Validation loss = 6.3700  \n",
      "\n",
      "Fold: 14  Epoch: 482  Training loss = 2.4684  Validation loss = 6.3679  \n",
      "\n",
      "Fold: 14  Epoch: 483  Training loss = 2.4682  Validation loss = 6.3661  \n",
      "\n",
      "Fold: 14  Epoch: 484  Training loss = 2.4680  Validation loss = 6.3657  \n",
      "\n",
      "Fold: 14  Epoch: 485  Training loss = 2.4677  Validation loss = 6.3655  \n",
      "\n",
      "Fold: 14  Epoch: 486  Training loss = 2.4676  Validation loss = 6.3652  \n",
      "\n",
      "Fold: 14  Epoch: 487  Training loss = 2.4673  Validation loss = 6.3638  \n",
      "\n",
      "Fold: 14  Epoch: 488  Training loss = 2.4670  Validation loss = 6.3634  \n",
      "\n",
      "Fold: 14  Epoch: 489  Training loss = 2.4668  Validation loss = 6.3621  \n",
      "\n",
      "Fold: 14  Epoch: 490  Training loss = 2.4665  Validation loss = 6.3598  \n",
      "\n",
      "Fold: 14  Epoch: 491  Training loss = 2.4660  Validation loss = 6.3570  \n",
      "\n",
      "Fold: 14  Epoch: 492  Training loss = 2.4657  Validation loss = 6.3547  \n",
      "\n",
      "Fold: 14  Epoch: 493  Training loss = 2.4656  Validation loss = 6.3550  \n",
      "\n",
      "Fold: 14  Epoch: 494  Training loss = 2.4653  Validation loss = 6.3527  \n",
      "\n",
      "Fold: 14  Epoch: 495  Training loss = 2.4653  Validation loss = 6.3548  \n",
      "\n",
      "Fold: 14  Epoch: 496  Training loss = 2.4651  Validation loss = 6.3536  \n",
      "\n",
      "Fold: 14  Epoch: 497  Training loss = 2.4647  Validation loss = 6.3495  \n",
      "\n",
      "Fold: 14  Epoch: 498  Training loss = 2.4646  Validation loss = 6.3501  \n",
      "\n",
      "Fold: 14  Epoch: 499  Training loss = 2.4643  Validation loss = 6.3493  \n",
      "\n",
      "Fold: 14  Epoch: 500  Training loss = 2.4641  Validation loss = 6.3493  \n",
      "\n",
      "Check model:  Fold: 14  Optimal epoch: 499  \n",
      "\n",
      "Fold: 15  Epoch: 1  Training loss = 2.8951  Validation loss = 6.8839  \n",
      "\n",
      "Fold: 15  Epoch: 2  Training loss = 2.8945  Validation loss = 6.8819  \n",
      "\n",
      "Fold: 15  Epoch: 3  Training loss = 2.8938  Validation loss = 6.8794  \n",
      "\n",
      "Fold: 15  Epoch: 4  Training loss = 2.8931  Validation loss = 6.8773  \n",
      "\n",
      "Fold: 15  Epoch: 5  Training loss = 2.8925  Validation loss = 6.8749  \n",
      "\n",
      "Fold: 15  Epoch: 6  Training loss = 2.8912  Validation loss = 6.8702  \n",
      "\n",
      "Fold: 15  Epoch: 7  Training loss = 2.8902  Validation loss = 6.8670  \n",
      "\n",
      "Fold: 15  Epoch: 8  Training loss = 2.8896  Validation loss = 6.8649  \n",
      "\n",
      "Fold: 15  Epoch: 9  Training loss = 2.8887  Validation loss = 6.8617  \n",
      "\n",
      "Fold: 15  Epoch: 10  Training loss = 2.8883  Validation loss = 6.8605  \n",
      "\n",
      "Fold: 15  Epoch: 11  Training loss = 2.8875  Validation loss = 6.8575  \n",
      "\n",
      "Fold: 15  Epoch: 12  Training loss = 2.8868  Validation loss = 6.8554  \n",
      "\n",
      "Fold: 15  Epoch: 13  Training loss = 2.8859  Validation loss = 6.8521  \n",
      "\n",
      "Fold: 15  Epoch: 14  Training loss = 2.8849  Validation loss = 6.8483  \n",
      "\n",
      "Fold: 15  Epoch: 15  Training loss = 2.8843  Validation loss = 6.8463  \n",
      "\n",
      "Fold: 15  Epoch: 16  Training loss = 2.8836  Validation loss = 6.8439  \n",
      "\n",
      "Fold: 15  Epoch: 17  Training loss = 2.8829  Validation loss = 6.8414  \n",
      "\n",
      "Fold: 15  Epoch: 18  Training loss = 2.8817  Validation loss = 6.8371  \n",
      "\n",
      "Fold: 15  Epoch: 19  Training loss = 2.8809  Validation loss = 6.8342  \n",
      "\n",
      "Fold: 15  Epoch: 20  Training loss = 2.8798  Validation loss = 6.8302  \n",
      "\n",
      "Fold: 15  Epoch: 21  Training loss = 2.8793  Validation loss = 6.8285  \n",
      "\n",
      "Fold: 15  Epoch: 22  Training loss = 2.8790  Validation loss = 6.8277  \n",
      "\n",
      "Fold: 15  Epoch: 23  Training loss = 2.8784  Validation loss = 6.8252  \n",
      "\n",
      "Fold: 15  Epoch: 24  Training loss = 2.8774  Validation loss = 6.8214  \n",
      "\n",
      "Fold: 15  Epoch: 25  Training loss = 2.8765  Validation loss = 6.8183  \n",
      "\n",
      "Fold: 15  Epoch: 26  Training loss = 2.8757  Validation loss = 6.8150  \n",
      "\n",
      "Fold: 15  Epoch: 27  Training loss = 2.8748  Validation loss = 6.8121  \n",
      "\n",
      "Fold: 15  Epoch: 28  Training loss = 2.8741  Validation loss = 6.8093  \n",
      "\n",
      "Fold: 15  Epoch: 29  Training loss = 2.8736  Validation loss = 6.8078  \n",
      "\n",
      "Fold: 15  Epoch: 30  Training loss = 2.8728  Validation loss = 6.8048  \n",
      "\n",
      "Fold: 15  Epoch: 31  Training loss = 2.8718  Validation loss = 6.8008  \n",
      "\n",
      "Fold: 15  Epoch: 32  Training loss = 2.8710  Validation loss = 6.7980  \n",
      "\n",
      "Fold: 15  Epoch: 33  Training loss = 2.8705  Validation loss = 6.7961  \n",
      "\n",
      "Fold: 15  Epoch: 34  Training loss = 2.8696  Validation loss = 6.7927  \n",
      "\n",
      "Fold: 15  Epoch: 35  Training loss = 2.8692  Validation loss = 6.7913  \n",
      "\n",
      "Fold: 15  Epoch: 36  Training loss = 2.8685  Validation loss = 6.7883  \n",
      "\n",
      "Fold: 15  Epoch: 37  Training loss = 2.8680  Validation loss = 6.7867  \n",
      "\n",
      "Fold: 15  Epoch: 38  Training loss = 2.8669  Validation loss = 6.7826  \n",
      "\n",
      "Fold: 15  Epoch: 39  Training loss = 2.8656  Validation loss = 6.7772  \n",
      "\n",
      "Fold: 15  Epoch: 40  Training loss = 2.8647  Validation loss = 6.7734  \n",
      "\n",
      "Fold: 15  Epoch: 41  Training loss = 2.8643  Validation loss = 6.7718  \n",
      "\n",
      "Fold: 15  Epoch: 42  Training loss = 2.8638  Validation loss = 6.7702  \n",
      "\n",
      "Fold: 15  Epoch: 43  Training loss = 2.8636  Validation loss = 6.7694  \n",
      "\n",
      "Fold: 15  Epoch: 44  Training loss = 2.8632  Validation loss = 6.7677  \n",
      "\n",
      "Fold: 15  Epoch: 45  Training loss = 2.8625  Validation loss = 6.7649  \n",
      "\n",
      "Fold: 15  Epoch: 46  Training loss = 2.8620  Validation loss = 6.7629  \n",
      "\n",
      "Fold: 15  Epoch: 47  Training loss = 2.8610  Validation loss = 6.7592  \n",
      "\n",
      "Fold: 15  Epoch: 48  Training loss = 2.8605  Validation loss = 6.7572  \n",
      "\n",
      "Fold: 15  Epoch: 49  Training loss = 2.8595  Validation loss = 6.7532  \n",
      "\n",
      "Fold: 15  Epoch: 50  Training loss = 2.8590  Validation loss = 6.7511  \n",
      "\n",
      "Fold: 15  Epoch: 51  Training loss = 2.8585  Validation loss = 6.7495  \n",
      "\n",
      "Fold: 15  Epoch: 52  Training loss = 2.8580  Validation loss = 6.7475  \n",
      "\n",
      "Fold: 15  Epoch: 53  Training loss = 2.8572  Validation loss = 6.7445  \n",
      "\n",
      "Fold: 15  Epoch: 54  Training loss = 2.8565  Validation loss = 6.7420  \n",
      "\n",
      "Fold: 15  Epoch: 55  Training loss = 2.8557  Validation loss = 6.7388  \n",
      "\n",
      "Fold: 15  Epoch: 56  Training loss = 2.8551  Validation loss = 6.7366  \n",
      "\n",
      "Fold: 15  Epoch: 57  Training loss = 2.8541  Validation loss = 6.7319  \n",
      "\n",
      "Fold: 15  Epoch: 58  Training loss = 2.8533  Validation loss = 6.7288  \n",
      "\n",
      "Fold: 15  Epoch: 59  Training loss = 2.8523  Validation loss = 6.7245  \n",
      "\n",
      "Fold: 15  Epoch: 60  Training loss = 2.8517  Validation loss = 6.7225  \n",
      "\n",
      "Fold: 15  Epoch: 61  Training loss = 2.8513  Validation loss = 6.7212  \n",
      "\n",
      "Fold: 15  Epoch: 62  Training loss = 2.8508  Validation loss = 6.7193  \n",
      "\n",
      "Fold: 15  Epoch: 63  Training loss = 2.8508  Validation loss = 6.7198  \n",
      "\n",
      "Fold: 15  Epoch: 64  Training loss = 2.8504  Validation loss = 6.7182  \n",
      "\n",
      "Fold: 15  Epoch: 65  Training loss = 2.8501  Validation loss = 6.7173  \n",
      "\n",
      "Fold: 15  Epoch: 66  Training loss = 2.8497  Validation loss = 6.7160  \n",
      "\n",
      "Fold: 15  Epoch: 67  Training loss = 2.8490  Validation loss = 6.7135  \n",
      "\n",
      "Fold: 15  Epoch: 68  Training loss = 2.8488  Validation loss = 6.7128  \n",
      "\n",
      "Fold: 15  Epoch: 69  Training loss = 2.8482  Validation loss = 6.7105  \n",
      "\n",
      "Fold: 15  Epoch: 70  Training loss = 2.8476  Validation loss = 6.7079  \n",
      "\n",
      "Fold: 15  Epoch: 71  Training loss = 2.8470  Validation loss = 6.7053  \n",
      "\n",
      "Fold: 15  Epoch: 72  Training loss = 2.8468  Validation loss = 6.7051  \n",
      "\n",
      "Fold: 15  Epoch: 73  Training loss = 2.8458  Validation loss = 6.7003  \n",
      "\n",
      "Fold: 15  Epoch: 74  Training loss = 2.8449  Validation loss = 6.6966  \n",
      "\n",
      "Fold: 15  Epoch: 75  Training loss = 2.8447  Validation loss = 6.6960  \n",
      "\n",
      "Fold: 15  Epoch: 76  Training loss = 2.8438  Validation loss = 6.6924  \n",
      "\n",
      "Fold: 15  Epoch: 77  Training loss = 2.8433  Validation loss = 6.6906  \n",
      "\n",
      "Fold: 15  Epoch: 78  Training loss = 2.8430  Validation loss = 6.6897  \n",
      "\n",
      "Fold: 15  Epoch: 79  Training loss = 2.8429  Validation loss = 6.6894  \n",
      "\n",
      "Fold: 15  Epoch: 80  Training loss = 2.8420  Validation loss = 6.6851  \n",
      "\n",
      "Fold: 15  Epoch: 81  Training loss = 2.8413  Validation loss = 6.6825  \n",
      "\n",
      "Fold: 15  Epoch: 82  Training loss = 2.8410  Validation loss = 6.6819  \n",
      "\n",
      "Fold: 15  Epoch: 83  Training loss = 2.8407  Validation loss = 6.6806  \n",
      "\n",
      "Fold: 15  Epoch: 84  Training loss = 2.8399  Validation loss = 6.6777  \n",
      "\n",
      "Fold: 15  Epoch: 85  Training loss = 2.8401  Validation loss = 6.6787  \n",
      "\n",
      "Fold: 15  Epoch: 86  Training loss = 2.8396  Validation loss = 6.6769  \n",
      "\n",
      "Fold: 15  Epoch: 87  Training loss = 2.8390  Validation loss = 6.6746  \n",
      "\n",
      "Fold: 15  Epoch: 88  Training loss = 2.8391  Validation loss = 6.6753  \n",
      "\n",
      "Fold: 15  Epoch: 89  Training loss = 2.8386  Validation loss = 6.6739  \n",
      "\n",
      "Fold: 15  Epoch: 90  Training loss = 2.8381  Validation loss = 6.6717  \n",
      "\n",
      "Fold: 15  Epoch: 91  Training loss = 2.8380  Validation loss = 6.6716  \n",
      "\n",
      "Fold: 15  Epoch: 92  Training loss = 2.8372  Validation loss = 6.6686  \n",
      "\n",
      "Fold: 15  Epoch: 93  Training loss = 2.8368  Validation loss = 6.6675  \n",
      "\n",
      "Fold: 15  Epoch: 94  Training loss = 2.8367  Validation loss = 6.6674  \n",
      "\n",
      "Fold: 15  Epoch: 95  Training loss = 2.8360  Validation loss = 6.6644  \n",
      "\n",
      "Fold: 15  Epoch: 96  Training loss = 2.8357  Validation loss = 6.6638  \n",
      "\n",
      "Fold: 15  Epoch: 97  Training loss = 2.8350  Validation loss = 6.6607  \n",
      "\n",
      "Fold: 15  Epoch: 98  Training loss = 2.8343  Validation loss = 6.6575  \n",
      "\n",
      "Fold: 15  Epoch: 99  Training loss = 2.8334  Validation loss = 6.6535  \n",
      "\n",
      "Fold: 15  Epoch: 100  Training loss = 2.8330  Validation loss = 6.6525  \n",
      "\n",
      "Fold: 15  Epoch: 101  Training loss = 2.8324  Validation loss = 6.6498  \n",
      "\n",
      "Fold: 15  Epoch: 102  Training loss = 2.8322  Validation loss = 6.6490  \n",
      "\n",
      "Fold: 15  Epoch: 103  Training loss = 2.8319  Validation loss = 6.6485  \n",
      "\n",
      "Fold: 15  Epoch: 104  Training loss = 2.8313  Validation loss = 6.6467  \n",
      "\n",
      "Fold: 15  Epoch: 105  Training loss = 2.8310  Validation loss = 6.6456  \n",
      "\n",
      "Fold: 15  Epoch: 106  Training loss = 2.8308  Validation loss = 6.6457  \n",
      "\n",
      "Fold: 15  Epoch: 107  Training loss = 2.8302  Validation loss = 6.6426  \n",
      "\n",
      "Fold: 15  Epoch: 108  Training loss = 2.8298  Validation loss = 6.6408  \n",
      "\n",
      "Fold: 15  Epoch: 109  Training loss = 2.8290  Validation loss = 6.6372  \n",
      "\n",
      "Fold: 15  Epoch: 110  Training loss = 2.8283  Validation loss = 6.6339  \n",
      "\n",
      "Fold: 15  Epoch: 111  Training loss = 2.8280  Validation loss = 6.6333  \n",
      "\n",
      "Fold: 15  Epoch: 112  Training loss = 2.8281  Validation loss = 6.6341  \n",
      "\n",
      "Fold: 15  Epoch: 113  Training loss = 2.8277  Validation loss = 6.6324  \n",
      "\n",
      "Fold: 15  Epoch: 114  Training loss = 2.8272  Validation loss = 6.6306  \n",
      "\n",
      "Fold: 15  Epoch: 115  Training loss = 2.8266  Validation loss = 6.6277  \n",
      "\n",
      "Fold: 15  Epoch: 116  Training loss = 2.8264  Validation loss = 6.6275  \n",
      "\n",
      "Fold: 15  Epoch: 117  Training loss = 2.8259  Validation loss = 6.6257  \n",
      "\n",
      "Fold: 15  Epoch: 118  Training loss = 2.8255  Validation loss = 6.6239  \n",
      "\n",
      "Fold: 15  Epoch: 119  Training loss = 2.8246  Validation loss = 6.6195  \n",
      "\n",
      "Fold: 15  Epoch: 120  Training loss = 2.8242  Validation loss = 6.6184  \n",
      "\n",
      "Fold: 15  Epoch: 121  Training loss = 2.8237  Validation loss = 6.6160  \n",
      "\n",
      "Fold: 15  Epoch: 122  Training loss = 2.8231  Validation loss = 6.6132  \n",
      "\n",
      "Fold: 15  Epoch: 123  Training loss = 2.8231  Validation loss = 6.6142  \n",
      "\n",
      "Fold: 15  Epoch: 124  Training loss = 2.8225  Validation loss = 6.6116  \n",
      "\n",
      "Fold: 15  Epoch: 125  Training loss = 2.8223  Validation loss = 6.6114  \n",
      "\n",
      "Fold: 15  Epoch: 126  Training loss = 2.8216  Validation loss = 6.6083  \n",
      "\n",
      "Fold: 15  Epoch: 127  Training loss = 2.8213  Validation loss = 6.6078  \n",
      "\n",
      "Fold: 15  Epoch: 128  Training loss = 2.8209  Validation loss = 6.6065  \n",
      "\n",
      "Fold: 15  Epoch: 129  Training loss = 2.8207  Validation loss = 6.6057  \n",
      "\n",
      "Fold: 15  Epoch: 130  Training loss = 2.8205  Validation loss = 6.6052  \n",
      "\n",
      "Fold: 15  Epoch: 131  Training loss = 2.8201  Validation loss = 6.6037  \n",
      "\n",
      "Fold: 15  Epoch: 132  Training loss = 2.8195  Validation loss = 6.6011  \n",
      "\n",
      "Fold: 15  Epoch: 133  Training loss = 2.8188  Validation loss = 6.5980  \n",
      "\n",
      "Fold: 15  Epoch: 134  Training loss = 2.8187  Validation loss = 6.5983  \n",
      "\n",
      "Fold: 15  Epoch: 135  Training loss = 2.8185  Validation loss = 6.5980  \n",
      "\n",
      "Fold: 15  Epoch: 136  Training loss = 2.8177  Validation loss = 6.5944  \n",
      "\n",
      "Fold: 15  Epoch: 137  Training loss = 2.8169  Validation loss = 6.5902  \n",
      "\n",
      "Fold: 15  Epoch: 138  Training loss = 2.8162  Validation loss = 6.5863  \n",
      "\n",
      "Fold: 15  Epoch: 139  Training loss = 2.8157  Validation loss = 6.5843  \n",
      "\n",
      "Fold: 15  Epoch: 140  Training loss = 2.8154  Validation loss = 6.5830  \n",
      "\n",
      "Fold: 15  Epoch: 141  Training loss = 2.8148  Validation loss = 6.5803  \n",
      "\n",
      "Fold: 15  Epoch: 142  Training loss = 2.8145  Validation loss = 6.5799  \n",
      "\n",
      "Fold: 15  Epoch: 143  Training loss = 2.8141  Validation loss = 6.5789  \n",
      "\n",
      "Fold: 15  Epoch: 144  Training loss = 2.8136  Validation loss = 6.5767  \n",
      "\n",
      "Fold: 15  Epoch: 145  Training loss = 2.8129  Validation loss = 6.5744  \n",
      "\n",
      "Fold: 15  Epoch: 146  Training loss = 2.8118  Validation loss = 6.5682  \n",
      "\n",
      "Fold: 15  Epoch: 147  Training loss = 2.8112  Validation loss = 6.5658  \n",
      "\n",
      "Fold: 15  Epoch: 148  Training loss = 2.8109  Validation loss = 6.5653  \n",
      "\n",
      "Fold: 15  Epoch: 149  Training loss = 2.8104  Validation loss = 6.5634  \n",
      "\n",
      "Fold: 15  Epoch: 150  Training loss = 2.8102  Validation loss = 6.5638  \n",
      "\n",
      "Fold: 15  Epoch: 151  Training loss = 2.8098  Validation loss = 6.5621  \n",
      "\n",
      "Fold: 15  Epoch: 152  Training loss = 2.8095  Validation loss = 6.5606  \n",
      "\n",
      "Fold: 15  Epoch: 153  Training loss = 2.8092  Validation loss = 6.5594  \n",
      "\n",
      "Fold: 15  Epoch: 154  Training loss = 2.8087  Validation loss = 6.5572  \n",
      "\n",
      "Fold: 15  Epoch: 155  Training loss = 2.8081  Validation loss = 6.5543  \n",
      "\n",
      "Fold: 15  Epoch: 156  Training loss = 2.8073  Validation loss = 6.5502  \n",
      "\n",
      "Fold: 15  Epoch: 157  Training loss = 2.8068  Validation loss = 6.5479  \n",
      "\n",
      "Fold: 15  Epoch: 158  Training loss = 2.8062  Validation loss = 6.5443  \n",
      "\n",
      "Fold: 15  Epoch: 159  Training loss = 2.8062  Validation loss = 6.5446  \n",
      "\n",
      "Fold: 15  Epoch: 160  Training loss = 2.8055  Validation loss = 6.5422  \n",
      "\n",
      "Fold: 15  Epoch: 161  Training loss = 2.8049  Validation loss = 6.5388  \n",
      "\n",
      "Fold: 15  Epoch: 162  Training loss = 2.8045  Validation loss = 6.5380  \n",
      "\n",
      "Fold: 15  Epoch: 163  Training loss = 2.8041  Validation loss = 6.5365  \n",
      "\n",
      "Fold: 15  Epoch: 164  Training loss = 2.8036  Validation loss = 6.5339  \n",
      "\n",
      "Fold: 15  Epoch: 165  Training loss = 2.8034  Validation loss = 6.5335  \n",
      "\n",
      "Fold: 15  Epoch: 166  Training loss = 2.8031  Validation loss = 6.5335  \n",
      "\n",
      "Fold: 15  Epoch: 167  Training loss = 2.8028  Validation loss = 6.5319  \n",
      "\n",
      "Fold: 15  Epoch: 168  Training loss = 2.8022  Validation loss = 6.5289  \n",
      "\n",
      "Fold: 15  Epoch: 169  Training loss = 2.8018  Validation loss = 6.5268  \n",
      "\n",
      "Fold: 15  Epoch: 170  Training loss = 2.8011  Validation loss = 6.5231  \n",
      "\n",
      "Fold: 15  Epoch: 171  Training loss = 2.8006  Validation loss = 6.5218  \n",
      "\n",
      "Fold: 15  Epoch: 172  Training loss = 2.8002  Validation loss = 6.5199  \n",
      "\n",
      "Fold: 15  Epoch: 173  Training loss = 2.7996  Validation loss = 6.5174  \n",
      "\n",
      "Fold: 15  Epoch: 174  Training loss = 2.7994  Validation loss = 6.5168  \n",
      "\n",
      "Fold: 15  Epoch: 175  Training loss = 2.7993  Validation loss = 6.5173  \n",
      "\n",
      "Fold: 15  Epoch: 176  Training loss = 2.7989  Validation loss = 6.5159  \n",
      "\n",
      "Fold: 15  Epoch: 177  Training loss = 2.7984  Validation loss = 6.5129  \n",
      "\n",
      "Fold: 15  Epoch: 178  Training loss = 2.7980  Validation loss = 6.5118  \n",
      "\n",
      "Fold: 15  Epoch: 179  Training loss = 2.7977  Validation loss = 6.5103  \n",
      "\n",
      "Fold: 15  Epoch: 180  Training loss = 2.7971  Validation loss = 6.5080  \n",
      "\n",
      "Fold: 15  Epoch: 181  Training loss = 2.7966  Validation loss = 6.5053  \n",
      "\n",
      "Fold: 15  Epoch: 182  Training loss = 2.7961  Validation loss = 6.5026  \n",
      "\n",
      "Fold: 15  Epoch: 183  Training loss = 2.7956  Validation loss = 6.5011  \n",
      "\n",
      "Fold: 15  Epoch: 184  Training loss = 2.7951  Validation loss = 6.4985  \n",
      "\n",
      "Fold: 15  Epoch: 185  Training loss = 2.7948  Validation loss = 6.4976  \n",
      "\n",
      "Fold: 15  Epoch: 186  Training loss = 2.7943  Validation loss = 6.4959  \n",
      "\n",
      "Fold: 15  Epoch: 187  Training loss = 2.7939  Validation loss = 6.4945  \n",
      "\n",
      "Fold: 15  Epoch: 188  Training loss = 2.7937  Validation loss = 6.4933  \n",
      "\n",
      "Fold: 15  Epoch: 189  Training loss = 2.7936  Validation loss = 6.4947  \n",
      "\n",
      "Fold: 15  Epoch: 190  Training loss = 2.7930  Validation loss = 6.4914  \n",
      "\n",
      "Fold: 15  Epoch: 191  Training loss = 2.7928  Validation loss = 6.4921  \n",
      "\n",
      "Fold: 15  Epoch: 192  Training loss = 2.7925  Validation loss = 6.4912  \n",
      "\n",
      "Fold: 15  Epoch: 193  Training loss = 2.7921  Validation loss = 6.4895  \n",
      "\n",
      "Fold: 15  Epoch: 194  Training loss = 2.7917  Validation loss = 6.4891  \n",
      "\n",
      "Fold: 15  Epoch: 195  Training loss = 2.7916  Validation loss = 6.4899  \n",
      "\n",
      "Fold: 15  Epoch: 196  Training loss = 2.7912  Validation loss = 6.4884  \n",
      "\n",
      "Fold: 15  Epoch: 197  Training loss = 2.7910  Validation loss = 6.4879  \n",
      "\n",
      "Fold: 15  Epoch: 198  Training loss = 2.7904  Validation loss = 6.4850  \n",
      "\n",
      "Fold: 15  Epoch: 199  Training loss = 2.7899  Validation loss = 6.4826  \n",
      "\n",
      "Fold: 15  Epoch: 200  Training loss = 2.7898  Validation loss = 6.4832  \n",
      "\n",
      "Fold: 15  Epoch: 201  Training loss = 2.7895  Validation loss = 6.4824  \n",
      "\n",
      "Fold: 15  Epoch: 202  Training loss = 2.7891  Validation loss = 6.4810  \n",
      "\n",
      "Fold: 15  Epoch: 203  Training loss = 2.7886  Validation loss = 6.4775  \n",
      "\n",
      "Fold: 15  Epoch: 204  Training loss = 2.7884  Validation loss = 6.4776  \n",
      "\n",
      "Fold: 15  Epoch: 205  Training loss = 2.7881  Validation loss = 6.4770  \n",
      "\n",
      "Fold: 15  Epoch: 206  Training loss = 2.7879  Validation loss = 6.4760  \n",
      "\n",
      "Fold: 15  Epoch: 207  Training loss = 2.7878  Validation loss = 6.4776  \n",
      "\n",
      "Fold: 15  Epoch: 208  Training loss = 2.7873  Validation loss = 6.4744  \n",
      "\n",
      "Fold: 15  Epoch: 209  Training loss = 2.7871  Validation loss = 6.4749  \n",
      "\n",
      "Fold: 15  Epoch: 210  Training loss = 2.7869  Validation loss = 6.4746  \n",
      "\n",
      "Fold: 15  Epoch: 211  Training loss = 2.7865  Validation loss = 6.4729  \n",
      "\n",
      "Fold: 15  Epoch: 212  Training loss = 2.7862  Validation loss = 6.4729  \n",
      "\n",
      "Fold: 15  Epoch: 213  Training loss = 2.7860  Validation loss = 6.4715  \n",
      "\n",
      "Fold: 15  Epoch: 214  Training loss = 2.7856  Validation loss = 6.4693  \n",
      "\n",
      "Fold: 15  Epoch: 215  Training loss = 2.7847  Validation loss = 6.4627  \n",
      "\n",
      "Fold: 15  Epoch: 216  Training loss = 2.7842  Validation loss = 6.4612  \n",
      "\n",
      "Fold: 15  Epoch: 217  Training loss = 2.7840  Validation loss = 6.4625  \n",
      "\n",
      "Fold: 15  Epoch: 218  Training loss = 2.7835  Validation loss = 6.4603  \n",
      "\n",
      "Fold: 15  Epoch: 219  Training loss = 2.7834  Validation loss = 6.4606  \n",
      "\n",
      "Fold: 15  Epoch: 220  Training loss = 2.7829  Validation loss = 6.4596  \n",
      "\n",
      "Fold: 15  Epoch: 221  Training loss = 2.7826  Validation loss = 6.4596  \n",
      "\n",
      "Fold: 15  Epoch: 222  Training loss = 2.7821  Validation loss = 6.4566  \n",
      "\n",
      "Fold: 15  Epoch: 223  Training loss = 2.7820  Validation loss = 6.4573  \n",
      "\n",
      "Fold: 15  Epoch: 224  Training loss = 2.7816  Validation loss = 6.4564  \n",
      "\n",
      "Fold: 15  Epoch: 225  Training loss = 2.7812  Validation loss = 6.4558  \n",
      "\n",
      "Fold: 15  Epoch: 226  Training loss = 2.7809  Validation loss = 6.4549  \n",
      "\n",
      "Fold: 15  Epoch: 227  Training loss = 2.7805  Validation loss = 6.4539  \n",
      "\n",
      "Fold: 15  Epoch: 228  Training loss = 2.7801  Validation loss = 6.4522  \n",
      "\n",
      "Fold: 15  Epoch: 229  Training loss = 2.7797  Validation loss = 6.4496  \n",
      "\n",
      "Fold: 15  Epoch: 230  Training loss = 2.7793  Validation loss = 6.4491  \n",
      "\n",
      "Fold: 15  Epoch: 231  Training loss = 2.7789  Validation loss = 6.4469  \n",
      "\n",
      "Fold: 15  Epoch: 232  Training loss = 2.7783  Validation loss = 6.4433  \n",
      "\n",
      "Fold: 15  Epoch: 233  Training loss = 2.7778  Validation loss = 6.4423  \n",
      "\n",
      "Fold: 15  Epoch: 234  Training loss = 2.7774  Validation loss = 6.4408  \n",
      "\n",
      "Fold: 15  Epoch: 235  Training loss = 2.7772  Validation loss = 6.4407  \n",
      "\n",
      "Fold: 15  Epoch: 236  Training loss = 2.7768  Validation loss = 6.4386  \n",
      "\n",
      "Fold: 15  Epoch: 237  Training loss = 2.7768  Validation loss = 6.4405  \n",
      "\n",
      "Fold: 15  Epoch: 238  Training loss = 2.7763  Validation loss = 6.4375  \n",
      "\n",
      "Fold: 15  Epoch: 239  Training loss = 2.7756  Validation loss = 6.4350  \n",
      "\n",
      "Fold: 15  Epoch: 240  Training loss = 2.7752  Validation loss = 6.4337  \n",
      "\n",
      "Fold: 15  Epoch: 241  Training loss = 2.7748  Validation loss = 6.4318  \n",
      "\n",
      "Fold: 15  Epoch: 242  Training loss = 2.7744  Validation loss = 6.4303  \n",
      "\n",
      "Fold: 15  Epoch: 243  Training loss = 2.7740  Validation loss = 6.4284  \n",
      "\n",
      "Fold: 15  Epoch: 244  Training loss = 2.7737  Validation loss = 6.4269  \n",
      "\n",
      "Fold: 15  Epoch: 245  Training loss = 2.7734  Validation loss = 6.4278  \n",
      "\n",
      "Fold: 15  Epoch: 246  Training loss = 2.7730  Validation loss = 6.4271  \n",
      "\n",
      "Fold: 15  Epoch: 247  Training loss = 2.7726  Validation loss = 6.4262  \n",
      "\n",
      "Fold: 15  Epoch: 248  Training loss = 2.7722  Validation loss = 6.4241  \n",
      "\n",
      "Fold: 15  Epoch: 249  Training loss = 2.7720  Validation loss = 6.4242  \n",
      "\n",
      "Fold: 15  Epoch: 250  Training loss = 2.7714  Validation loss = 6.4211  \n",
      "\n",
      "Fold: 15  Epoch: 251  Training loss = 2.7709  Validation loss = 6.4193  \n",
      "\n",
      "Fold: 15  Epoch: 252  Training loss = 2.7707  Validation loss = 6.4183  \n",
      "\n",
      "Fold: 15  Epoch: 253  Training loss = 2.7701  Validation loss = 6.4156  \n",
      "\n",
      "Fold: 15  Epoch: 254  Training loss = 2.7698  Validation loss = 6.4152  \n",
      "\n",
      "Fold: 15  Epoch: 255  Training loss = 2.7695  Validation loss = 6.4131  \n",
      "\n",
      "Fold: 15  Epoch: 256  Training loss = 2.7689  Validation loss = 6.4084  \n",
      "\n",
      "Fold: 15  Epoch: 257  Training loss = 2.7689  Validation loss = 6.4107  \n",
      "\n",
      "Fold: 15  Epoch: 258  Training loss = 2.7685  Validation loss = 6.4081  \n",
      "\n",
      "Fold: 15  Epoch: 259  Training loss = 2.7679  Validation loss = 6.4057  \n",
      "\n",
      "Fold: 15  Epoch: 260  Training loss = 2.7674  Validation loss = 6.4027  \n",
      "\n",
      "Fold: 15  Epoch: 261  Training loss = 2.7671  Validation loss = 6.4021  \n",
      "\n",
      "Fold: 15  Epoch: 262  Training loss = 2.7668  Validation loss = 6.4018  \n",
      "\n",
      "Fold: 15  Epoch: 263  Training loss = 2.7667  Validation loss = 6.4025  \n",
      "\n",
      "Fold: 15  Epoch: 264  Training loss = 2.7665  Validation loss = 6.4028  \n",
      "\n",
      "Fold: 15  Epoch: 265  Training loss = 2.7660  Validation loss = 6.4002  \n",
      "\n",
      "Fold: 15  Epoch: 266  Training loss = 2.7656  Validation loss = 6.3986  \n",
      "\n",
      "Fold: 15  Epoch: 267  Training loss = 2.7653  Validation loss = 6.3971  \n",
      "\n",
      "Fold: 15  Epoch: 268  Training loss = 2.7648  Validation loss = 6.3954  \n",
      "\n",
      "Fold: 15  Epoch: 269  Training loss = 2.7645  Validation loss = 6.3931  \n",
      "\n",
      "Fold: 15  Epoch: 270  Training loss = 2.7639  Validation loss = 6.3903  \n",
      "\n",
      "Fold: 15  Epoch: 271  Training loss = 2.7634  Validation loss = 6.3878  \n",
      "\n",
      "Fold: 15  Epoch: 272  Training loss = 2.7628  Validation loss = 6.3847  \n",
      "\n",
      "Fold: 15  Epoch: 273  Training loss = 2.7626  Validation loss = 6.3837  \n",
      "\n",
      "Fold: 15  Epoch: 274  Training loss = 2.7620  Validation loss = 6.3803  \n",
      "\n",
      "Fold: 15  Epoch: 275  Training loss = 2.7618  Validation loss = 6.3802  \n",
      "\n",
      "Fold: 15  Epoch: 276  Training loss = 2.7614  Validation loss = 6.3774  \n",
      "\n",
      "Fold: 15  Epoch: 277  Training loss = 2.7611  Validation loss = 6.3761  \n",
      "\n",
      "Fold: 15  Epoch: 278  Training loss = 2.7607  Validation loss = 6.3758  \n",
      "\n",
      "Fold: 15  Epoch: 279  Training loss = 2.7603  Validation loss = 6.3743  \n",
      "\n",
      "Fold: 15  Epoch: 280  Training loss = 2.7599  Validation loss = 6.3725  \n",
      "\n",
      "Fold: 15  Epoch: 281  Training loss = 2.7596  Validation loss = 6.3712  \n",
      "\n",
      "Fold: 15  Epoch: 282  Training loss = 2.7594  Validation loss = 6.3699  \n",
      "\n",
      "Fold: 15  Epoch: 283  Training loss = 2.7592  Validation loss = 6.3694  \n",
      "\n",
      "Fold: 15  Epoch: 284  Training loss = 2.7589  Validation loss = 6.3692  \n",
      "\n",
      "Fold: 15  Epoch: 285  Training loss = 2.7587  Validation loss = 6.3697  \n",
      "\n",
      "Fold: 15  Epoch: 286  Training loss = 2.7585  Validation loss = 6.3681  \n",
      "\n",
      "Fold: 15  Epoch: 287  Training loss = 2.7583  Validation loss = 6.3674  \n",
      "\n",
      "Fold: 15  Epoch: 288  Training loss = 2.7580  Validation loss = 6.3663  \n",
      "\n",
      "Fold: 15  Epoch: 289  Training loss = 2.7576  Validation loss = 6.3635  \n",
      "\n",
      "Fold: 15  Epoch: 290  Training loss = 2.7572  Validation loss = 6.3614  \n",
      "\n",
      "Fold: 15  Epoch: 291  Training loss = 2.7567  Validation loss = 6.3603  \n",
      "\n",
      "Fold: 15  Epoch: 292  Training loss = 2.7563  Validation loss = 6.3608  \n",
      "\n",
      "Fold: 15  Epoch: 293  Training loss = 2.7560  Validation loss = 6.3597  \n",
      "\n",
      "Fold: 15  Epoch: 294  Training loss = 2.7558  Validation loss = 6.3590  \n",
      "\n",
      "Fold: 15  Epoch: 295  Training loss = 2.7555  Validation loss = 6.3592  \n",
      "\n",
      "Fold: 15  Epoch: 296  Training loss = 2.7553  Validation loss = 6.3581  \n",
      "\n",
      "Fold: 15  Epoch: 297  Training loss = 2.7549  Validation loss = 6.3569  \n",
      "\n",
      "Fold: 15  Epoch: 298  Training loss = 2.7544  Validation loss = 6.3540  \n",
      "\n",
      "Fold: 15  Epoch: 299  Training loss = 2.7540  Validation loss = 6.3499  \n",
      "\n",
      "Fold: 15  Epoch: 300  Training loss = 2.7536  Validation loss = 6.3480  \n",
      "\n",
      "Fold: 15  Epoch: 301  Training loss = 2.7533  Validation loss = 6.3473  \n",
      "\n",
      "Fold: 15  Epoch: 302  Training loss = 2.7532  Validation loss = 6.3480  \n",
      "\n",
      "Fold: 15  Epoch: 303  Training loss = 2.7528  Validation loss = 6.3472  \n",
      "\n",
      "Fold: 15  Epoch: 304  Training loss = 2.7523  Validation loss = 6.3455  \n",
      "\n",
      "Fold: 15  Epoch: 305  Training loss = 2.7520  Validation loss = 6.3453  \n",
      "\n",
      "Fold: 15  Epoch: 306  Training loss = 2.7517  Validation loss = 6.3442  \n",
      "\n",
      "Fold: 15  Epoch: 307  Training loss = 2.7513  Validation loss = 6.3423  \n",
      "\n",
      "Fold: 15  Epoch: 308  Training loss = 2.7506  Validation loss = 6.3384  \n",
      "\n",
      "Fold: 15  Epoch: 309  Training loss = 2.7502  Validation loss = 6.3386  \n",
      "\n",
      "Fold: 15  Epoch: 310  Training loss = 2.7496  Validation loss = 6.3363  \n",
      "\n",
      "Fold: 15  Epoch: 311  Training loss = 2.7492  Validation loss = 6.3352  \n",
      "\n",
      "Fold: 15  Epoch: 312  Training loss = 2.7486  Validation loss = 6.3317  \n",
      "\n",
      "Fold: 15  Epoch: 313  Training loss = 2.7484  Validation loss = 6.3310  \n",
      "\n",
      "Fold: 15  Epoch: 314  Training loss = 2.7481  Validation loss = 6.3306  \n",
      "\n",
      "Fold: 15  Epoch: 315  Training loss = 2.7476  Validation loss = 6.3275  \n",
      "\n",
      "Fold: 15  Epoch: 316  Training loss = 2.7474  Validation loss = 6.3272  \n",
      "\n",
      "Fold: 15  Epoch: 317  Training loss = 2.7470  Validation loss = 6.3237  \n",
      "\n",
      "Fold: 15  Epoch: 318  Training loss = 2.7467  Validation loss = 6.3240  \n",
      "\n",
      "Fold: 15  Epoch: 319  Training loss = 2.7465  Validation loss = 6.3235  \n",
      "\n",
      "Fold: 15  Epoch: 320  Training loss = 2.7461  Validation loss = 6.3207  \n",
      "\n",
      "Fold: 15  Epoch: 321  Training loss = 2.7456  Validation loss = 6.3170  \n",
      "\n",
      "Fold: 15  Epoch: 322  Training loss = 2.7453  Validation loss = 6.3158  \n",
      "\n",
      "Fold: 15  Epoch: 323  Training loss = 2.7448  Validation loss = 6.3136  \n",
      "\n",
      "Fold: 15  Epoch: 324  Training loss = 2.7446  Validation loss = 6.3130  \n",
      "\n",
      "Fold: 15  Epoch: 325  Training loss = 2.7443  Validation loss = 6.3139  \n",
      "\n",
      "Fold: 15  Epoch: 326  Training loss = 2.7442  Validation loss = 6.3136  \n",
      "\n",
      "Fold: 15  Epoch: 327  Training loss = 2.7439  Validation loss = 6.3114  \n",
      "\n",
      "Fold: 15  Epoch: 328  Training loss = 2.7438  Validation loss = 6.3121  \n",
      "\n",
      "Fold: 15  Epoch: 329  Training loss = 2.7436  Validation loss = 6.3131  \n",
      "\n",
      "Fold: 15  Epoch: 330  Training loss = 2.7433  Validation loss = 6.3138  \n",
      "\n",
      "Fold: 15  Epoch: 331  Training loss = 2.7430  Validation loss = 6.3104  \n",
      "\n",
      "Fold: 15  Epoch: 332  Training loss = 2.7429  Validation loss = 6.3117  \n",
      "\n",
      "Fold: 15  Epoch: 333  Training loss = 2.7424  Validation loss = 6.3072  \n",
      "\n",
      "Fold: 15  Epoch: 334  Training loss = 2.7421  Validation loss = 6.3053  \n",
      "\n",
      "Fold: 15  Epoch: 335  Training loss = 2.7419  Validation loss = 6.3063  \n",
      "\n",
      "Fold: 15  Epoch: 336  Training loss = 2.7415  Validation loss = 6.3045  \n",
      "\n",
      "Fold: 15  Epoch: 337  Training loss = 2.7413  Validation loss = 6.3022  \n",
      "\n",
      "Fold: 15  Epoch: 338  Training loss = 2.7411  Validation loss = 6.2997  \n",
      "\n",
      "Fold: 15  Epoch: 339  Training loss = 2.7408  Validation loss = 6.2975  \n",
      "\n",
      "Fold: 15  Epoch: 340  Training loss = 2.7405  Validation loss = 6.2984  \n",
      "\n",
      "Fold: 15  Epoch: 341  Training loss = 2.7402  Validation loss = 6.2984  \n",
      "\n",
      "Fold: 15  Epoch: 342  Training loss = 2.7398  Validation loss = 6.2966  \n",
      "\n",
      "Fold: 15  Epoch: 343  Training loss = 2.7394  Validation loss = 6.2948  \n",
      "\n",
      "Fold: 15  Epoch: 344  Training loss = 2.7389  Validation loss = 6.2922  \n",
      "\n",
      "Fold: 15  Epoch: 345  Training loss = 2.7386  Validation loss = 6.2909  \n",
      "\n",
      "Fold: 15  Epoch: 346  Training loss = 2.7383  Validation loss = 6.2891  \n",
      "\n",
      "Fold: 15  Epoch: 347  Training loss = 2.7380  Validation loss = 6.2878  \n",
      "\n",
      "Fold: 15  Epoch: 348  Training loss = 2.7376  Validation loss = 6.2874  \n",
      "\n",
      "Fold: 15  Epoch: 349  Training loss = 2.7371  Validation loss = 6.2844  \n",
      "\n",
      "Fold: 15  Epoch: 350  Training loss = 2.7366  Validation loss = 6.2837  \n",
      "\n",
      "Fold: 15  Epoch: 351  Training loss = 2.7361  Validation loss = 6.2792  \n",
      "\n",
      "Fold: 15  Epoch: 352  Training loss = 2.7359  Validation loss = 6.2791  \n",
      "\n",
      "Fold: 15  Epoch: 353  Training loss = 2.7359  Validation loss = 6.2801  \n",
      "\n",
      "Fold: 15  Epoch: 354  Training loss = 2.7357  Validation loss = 6.2797  \n",
      "\n",
      "Fold: 15  Epoch: 355  Training loss = 2.7353  Validation loss = 6.2785  \n",
      "\n",
      "Fold: 15  Epoch: 356  Training loss = 2.7349  Validation loss = 6.2757  \n",
      "\n",
      "Fold: 15  Epoch: 357  Training loss = 2.7347  Validation loss = 6.2760  \n",
      "\n",
      "Fold: 15  Epoch: 358  Training loss = 2.7342  Validation loss = 6.2750  \n",
      "\n",
      "Fold: 15  Epoch: 359  Training loss = 2.7340  Validation loss = 6.2761  \n",
      "\n",
      "Fold: 15  Epoch: 360  Training loss = 2.7337  Validation loss = 6.2751  \n",
      "\n",
      "Fold: 15  Epoch: 361  Training loss = 2.7333  Validation loss = 6.2719  \n",
      "\n",
      "Fold: 15  Epoch: 362  Training loss = 2.7331  Validation loss = 6.2716  \n",
      "\n",
      "Fold: 15  Epoch: 363  Training loss = 2.7330  Validation loss = 6.2720  \n",
      "\n",
      "Fold: 15  Epoch: 364  Training loss = 2.7326  Validation loss = 6.2699  \n",
      "\n",
      "Fold: 15  Epoch: 365  Training loss = 2.7321  Validation loss = 6.2677  \n",
      "\n",
      "Fold: 15  Epoch: 366  Training loss = 2.7317  Validation loss = 6.2656  \n",
      "\n",
      "Fold: 15  Epoch: 367  Training loss = 2.7313  Validation loss = 6.2639  \n",
      "\n",
      "Fold: 15  Epoch: 368  Training loss = 2.7312  Validation loss = 6.2651  \n",
      "\n",
      "Fold: 15  Epoch: 369  Training loss = 2.7309  Validation loss = 6.2648  \n",
      "\n",
      "Fold: 15  Epoch: 370  Training loss = 2.7307  Validation loss = 6.2652  \n",
      "\n",
      "Fold: 15  Epoch: 371  Training loss = 2.7306  Validation loss = 6.2637  \n",
      "\n",
      "Fold: 15  Epoch: 372  Training loss = 2.7303  Validation loss = 6.2639  \n",
      "\n",
      "Fold: 15  Epoch: 373  Training loss = 2.7302  Validation loss = 6.2626  \n",
      "\n",
      "Fold: 15  Epoch: 374  Training loss = 2.7301  Validation loss = 6.2619  \n",
      "\n",
      "Fold: 15  Epoch: 375  Training loss = 2.7300  Validation loss = 6.2614  \n",
      "\n",
      "Fold: 15  Epoch: 376  Training loss = 2.7299  Validation loss = 6.2621  \n",
      "\n",
      "Fold: 15  Epoch: 377  Training loss = 2.7294  Validation loss = 6.2597  \n",
      "\n",
      "Fold: 15  Epoch: 378  Training loss = 2.7293  Validation loss = 6.2577  \n",
      "\n",
      "Fold: 15  Epoch: 379  Training loss = 2.7289  Validation loss = 6.2574  \n",
      "\n",
      "Fold: 15  Epoch: 380  Training loss = 2.7287  Validation loss = 6.2588  \n",
      "\n",
      "Fold: 15  Epoch: 381  Training loss = 2.7286  Validation loss = 6.2599  \n",
      "\n",
      "Fold: 15  Epoch: 382  Training loss = 2.7282  Validation loss = 6.2565  \n",
      "\n",
      "Fold: 15  Epoch: 383  Training loss = 2.7282  Validation loss = 6.2565  \n",
      "\n",
      "Fold: 15  Epoch: 384  Training loss = 2.7280  Validation loss = 6.2567  \n",
      "\n",
      "Fold: 15  Epoch: 385  Training loss = 2.7277  Validation loss = 6.2559  \n",
      "\n",
      "Fold: 15  Epoch: 386  Training loss = 2.7275  Validation loss = 6.2545  \n",
      "\n",
      "Fold: 15  Epoch: 387  Training loss = 2.7272  Validation loss = 6.2535  \n",
      "\n",
      "Fold: 15  Epoch: 388  Training loss = 2.7269  Validation loss = 6.2526  \n",
      "\n",
      "Fold: 15  Epoch: 389  Training loss = 2.7266  Validation loss = 6.2511  \n",
      "\n",
      "Fold: 15  Epoch: 390  Training loss = 2.7267  Validation loss = 6.2530  \n",
      "\n",
      "Fold: 15  Epoch: 391  Training loss = 2.7265  Validation loss = 6.2546  \n",
      "\n",
      "Fold: 15  Epoch: 392  Training loss = 2.7262  Validation loss = 6.2532  \n",
      "\n",
      "Fold: 15  Epoch: 393  Training loss = 2.7260  Validation loss = 6.2518  \n",
      "\n",
      "Fold: 15  Epoch: 394  Training loss = 2.7258  Validation loss = 6.2517  \n",
      "\n",
      "Fold: 15  Epoch: 395  Training loss = 2.7255  Validation loss = 6.2506  \n",
      "\n",
      "Fold: 15  Epoch: 396  Training loss = 2.7252  Validation loss = 6.2503  \n",
      "\n",
      "Fold: 15  Epoch: 397  Training loss = 2.7248  Validation loss = 6.2481  \n",
      "\n",
      "Fold: 15  Epoch: 398  Training loss = 2.7246  Validation loss = 6.2480  \n",
      "\n",
      "Fold: 15  Epoch: 399  Training loss = 2.7244  Validation loss = 6.2458  \n",
      "\n",
      "Fold: 15  Epoch: 400  Training loss = 2.7242  Validation loss = 6.2441  \n",
      "\n",
      "Fold: 15  Epoch: 401  Training loss = 2.7239  Validation loss = 6.2426  \n",
      "\n",
      "Fold: 15  Epoch: 402  Training loss = 2.7234  Validation loss = 6.2372  \n",
      "\n",
      "Fold: 15  Epoch: 403  Training loss = 2.7231  Validation loss = 6.2366  \n",
      "\n",
      "Fold: 15  Epoch: 404  Training loss = 2.7231  Validation loss = 6.2380  \n",
      "\n",
      "Fold: 15  Epoch: 405  Training loss = 2.7229  Validation loss = 6.2382  \n",
      "\n",
      "Fold: 15  Epoch: 406  Training loss = 2.7227  Validation loss = 6.2382  \n",
      "\n",
      "Fold: 15  Epoch: 407  Training loss = 2.7224  Validation loss = 6.2368  \n",
      "\n",
      "Fold: 15  Epoch: 408  Training loss = 2.7224  Validation loss = 6.2379  \n",
      "\n",
      "Fold: 15  Epoch: 409  Training loss = 2.7221  Validation loss = 6.2379  \n",
      "\n",
      "Fold: 15  Epoch: 410  Training loss = 2.7218  Validation loss = 6.2364  \n",
      "\n",
      "Fold: 15  Epoch: 411  Training loss = 2.7215  Validation loss = 6.2341  \n",
      "\n",
      "Fold: 15  Epoch: 412  Training loss = 2.7214  Validation loss = 6.2333  \n",
      "\n",
      "Fold: 15  Epoch: 413  Training loss = 2.7213  Validation loss = 6.2344  \n",
      "\n",
      "Fold: 15  Epoch: 414  Training loss = 2.7213  Validation loss = 6.2371  \n",
      "\n",
      "Fold: 15  Epoch: 415  Training loss = 2.7211  Validation loss = 6.2352  \n",
      "\n",
      "Fold: 15  Epoch: 416  Training loss = 2.7207  Validation loss = 6.2323  \n",
      "\n",
      "Fold: 15  Epoch: 417  Training loss = 2.7205  Validation loss = 6.2297  \n",
      "\n",
      "Fold: 15  Epoch: 418  Training loss = 2.7202  Validation loss = 6.2277  \n",
      "\n",
      "Fold: 15  Epoch: 419  Training loss = 2.7199  Validation loss = 6.2273  \n",
      "\n",
      "Fold: 15  Epoch: 420  Training loss = 2.7196  Validation loss = 6.2257  \n",
      "\n",
      "Fold: 15  Epoch: 421  Training loss = 2.7194  Validation loss = 6.2249  \n",
      "\n",
      "Fold: 15  Epoch: 422  Training loss = 2.7190  Validation loss = 6.2227  \n",
      "\n",
      "Fold: 15  Epoch: 423  Training loss = 2.7189  Validation loss = 6.2240  \n",
      "\n",
      "Fold: 15  Epoch: 424  Training loss = 2.7185  Validation loss = 6.2209  \n",
      "\n",
      "Fold: 15  Epoch: 425  Training loss = 2.7184  Validation loss = 6.2210  \n",
      "\n",
      "Fold: 15  Epoch: 426  Training loss = 2.7182  Validation loss = 6.2197  \n",
      "\n",
      "Fold: 15  Epoch: 427  Training loss = 2.7180  Validation loss = 6.2196  \n",
      "\n",
      "Fold: 15  Epoch: 428  Training loss = 2.7178  Validation loss = 6.2203  \n",
      "\n",
      "Fold: 15  Epoch: 429  Training loss = 2.7177  Validation loss = 6.2208  \n",
      "\n",
      "Fold: 15  Epoch: 430  Training loss = 2.7175  Validation loss = 6.2183  \n",
      "\n",
      "Fold: 15  Epoch: 431  Training loss = 2.7172  Validation loss = 6.2163  \n",
      "\n",
      "Fold: 15  Epoch: 432  Training loss = 2.7169  Validation loss = 6.2144  \n",
      "\n",
      "Fold: 15  Epoch: 433  Training loss = 2.7166  Validation loss = 6.2129  \n",
      "\n",
      "Fold: 15  Epoch: 434  Training loss = 2.7163  Validation loss = 6.2102  \n",
      "\n",
      "Fold: 15  Epoch: 435  Training loss = 2.7161  Validation loss = 6.2098  \n",
      "\n",
      "Fold: 15  Epoch: 436  Training loss = 2.7159  Validation loss = 6.2091  \n",
      "\n",
      "Fold: 15  Epoch: 437  Training loss = 2.7155  Validation loss = 6.2071  \n",
      "\n",
      "Fold: 15  Epoch: 438  Training loss = 2.7154  Validation loss = 6.2047  \n",
      "\n",
      "Fold: 15  Epoch: 439  Training loss = 2.7151  Validation loss = 6.2048  \n",
      "\n",
      "Fold: 15  Epoch: 440  Training loss = 2.7148  Validation loss = 6.2043  \n",
      "\n",
      "Fold: 15  Epoch: 441  Training loss = 2.7147  Validation loss = 6.2044  \n",
      "\n",
      "Fold: 15  Epoch: 442  Training loss = 2.7146  Validation loss = 6.2035  \n",
      "\n",
      "Fold: 15  Epoch: 443  Training loss = 2.7144  Validation loss = 6.2040  \n",
      "\n",
      "Fold: 15  Epoch: 444  Training loss = 2.7142  Validation loss = 6.2026  \n",
      "\n",
      "Fold: 15  Epoch: 445  Training loss = 2.7142  Validation loss = 6.2022  \n",
      "\n",
      "Fold: 15  Epoch: 446  Training loss = 2.7138  Validation loss = 6.1998  \n",
      "\n",
      "Fold: 15  Epoch: 447  Training loss = 2.7138  Validation loss = 6.2018  \n",
      "\n",
      "Fold: 15  Epoch: 448  Training loss = 2.7135  Validation loss = 6.2007  \n",
      "\n",
      "Fold: 15  Epoch: 449  Training loss = 2.7135  Validation loss = 6.2019  \n",
      "\n",
      "Fold: 15  Epoch: 450  Training loss = 2.7134  Validation loss = 6.2028  \n",
      "\n",
      "Fold: 15  Epoch: 451  Training loss = 2.7134  Validation loss = 6.2031  \n",
      "\n",
      "Fold: 15  Epoch: 452  Training loss = 2.7133  Validation loss = 6.2036  \n",
      "\n",
      "Fold: 15  Epoch: 453  Training loss = 2.7131  Validation loss = 6.2023  \n",
      "\n",
      "Fold: 15  Epoch: 454  Training loss = 2.7128  Validation loss = 6.2004  \n",
      "\n",
      "Fold: 15  Epoch: 455  Training loss = 2.7127  Validation loss = 6.2002  \n",
      "\n",
      "Fold: 15  Epoch: 456  Training loss = 2.7126  Validation loss = 6.2000  \n",
      "\n",
      "Fold: 15  Epoch: 457  Training loss = 2.7127  Validation loss = 6.2015  \n",
      "\n",
      "Fold: 15  Epoch: 458  Training loss = 2.7122  Validation loss = 6.1985  \n",
      "\n",
      "Fold: 15  Epoch: 459  Training loss = 2.7121  Validation loss = 6.1972  \n",
      "\n",
      "Fold: 15  Epoch: 460  Training loss = 2.7121  Validation loss = 6.1985  \n",
      "\n",
      "Fold: 15  Epoch: 461  Training loss = 2.7120  Validation loss = 6.1984  \n",
      "\n",
      "Fold: 15  Epoch: 462  Training loss = 2.7116  Validation loss = 6.1958  \n",
      "\n",
      "Fold: 15  Epoch: 463  Training loss = 2.7117  Validation loss = 6.1976  \n",
      "\n",
      "Fold: 15  Epoch: 464  Training loss = 2.7114  Validation loss = 6.1952  \n",
      "\n",
      "Fold: 15  Epoch: 465  Training loss = 2.7113  Validation loss = 6.1952  \n",
      "\n",
      "Fold: 15  Epoch: 466  Training loss = 2.7109  Validation loss = 6.1922  \n",
      "\n",
      "Fold: 15  Epoch: 467  Training loss = 2.7107  Validation loss = 6.1920  \n",
      "\n",
      "Fold: 15  Epoch: 468  Training loss = 2.7105  Validation loss = 6.1909  \n",
      "\n",
      "Fold: 15  Epoch: 469  Training loss = 2.7105  Validation loss = 6.1899  \n",
      "\n",
      "Fold: 15  Epoch: 470  Training loss = 2.7100  Validation loss = 6.1873  \n",
      "\n",
      "Fold: 15  Epoch: 471  Training loss = 2.7098  Validation loss = 6.1864  \n",
      "\n",
      "Fold: 15  Epoch: 472  Training loss = 2.7099  Validation loss = 6.1890  \n",
      "\n",
      "Fold: 15  Epoch: 473  Training loss = 2.7097  Validation loss = 6.1887  \n",
      "\n",
      "Fold: 15  Epoch: 474  Training loss = 2.7096  Validation loss = 6.1883  \n",
      "\n",
      "Fold: 15  Epoch: 475  Training loss = 2.7092  Validation loss = 6.1849  \n",
      "\n",
      "Fold: 15  Epoch: 476  Training loss = 2.7088  Validation loss = 6.1826  \n",
      "\n",
      "Fold: 15  Epoch: 477  Training loss = 2.7087  Validation loss = 6.1820  \n",
      "\n",
      "Fold: 15  Epoch: 478  Training loss = 2.7086  Validation loss = 6.1824  \n",
      "\n",
      "Fold: 15  Epoch: 479  Training loss = 2.7085  Validation loss = 6.1817  \n",
      "\n",
      "Fold: 15  Epoch: 480  Training loss = 2.7085  Validation loss = 6.1823  \n",
      "\n",
      "Fold: 15  Epoch: 481  Training loss = 2.7083  Validation loss = 6.1815  \n",
      "\n",
      "Fold: 15  Epoch: 482  Training loss = 2.7084  Validation loss = 6.1820  \n",
      "\n",
      "Fold: 15  Epoch: 483  Training loss = 2.7081  Validation loss = 6.1821  \n",
      "\n",
      "Fold: 15  Epoch: 484  Training loss = 2.7078  Validation loss = 6.1787  \n",
      "\n",
      "Fold: 15  Epoch: 485  Training loss = 2.7076  Validation loss = 6.1778  \n",
      "\n",
      "Fold: 15  Epoch: 486  Training loss = 2.7073  Validation loss = 6.1758  \n",
      "\n",
      "Fold: 15  Epoch: 487  Training loss = 2.7072  Validation loss = 6.1760  \n",
      "\n",
      "Fold: 15  Epoch: 488  Training loss = 2.7071  Validation loss = 6.1730  \n",
      "\n",
      "Fold: 15  Epoch: 489  Training loss = 2.7068  Validation loss = 6.1708  \n",
      "\n",
      "Fold: 15  Epoch: 490  Training loss = 2.7067  Validation loss = 6.1721  \n",
      "\n",
      "Fold: 15  Epoch: 491  Training loss = 2.7065  Validation loss = 6.1728  \n",
      "\n",
      "Fold: 15  Epoch: 492  Training loss = 2.7063  Validation loss = 6.1724  \n",
      "\n",
      "Fold: 15  Epoch: 493  Training loss = 2.7062  Validation loss = 6.1728  \n",
      "\n",
      "Fold: 15  Epoch: 494  Training loss = 2.7060  Validation loss = 6.1711  \n",
      "\n",
      "Fold: 15  Epoch: 495  Training loss = 2.7058  Validation loss = 6.1702  \n",
      "\n",
      "Fold: 15  Epoch: 496  Training loss = 2.7059  Validation loss = 6.1711  \n",
      "\n",
      "Fold: 15  Epoch: 497  Training loss = 2.7058  Validation loss = 6.1716  \n",
      "\n",
      "Fold: 15  Epoch: 498  Training loss = 2.7056  Validation loss = 6.1707  \n",
      "\n",
      "Fold: 15  Epoch: 499  Training loss = 2.7054  Validation loss = 6.1687  \n",
      "\n",
      "Fold: 15  Epoch: 500  Training loss = 2.7053  Validation loss = 6.1690  \n",
      "\n",
      "Check model:  Fold: 15  Optimal epoch: 499  \n",
      "\n",
      "Fold: 16  Epoch: 1  Training loss = 3.0812  Validation loss = 4.2583  \n",
      "\n",
      "Fold: 16  Epoch: 2  Training loss = 3.0805  Validation loss = 4.2557  \n",
      "\n",
      "Fold: 16  Epoch: 3  Training loss = 3.0800  Validation loss = 4.2537  \n",
      "\n",
      "Fold: 16  Epoch: 4  Training loss = 3.0797  Validation loss = 4.2530  \n",
      "\n",
      "Fold: 16  Epoch: 5  Training loss = 3.0791  Validation loss = 4.2510  \n",
      "\n",
      "Fold: 16  Epoch: 6  Training loss = 3.0792  Validation loss = 4.2509  \n",
      "\n",
      "Fold: 16  Epoch: 7  Training loss = 3.0783  Validation loss = 4.2499  \n",
      "\n",
      "Fold: 16  Epoch: 8  Training loss = 3.0772  Validation loss = 4.2468  \n",
      "\n",
      "Fold: 16  Epoch: 9  Training loss = 3.0765  Validation loss = 4.2449  \n",
      "\n",
      "Fold: 16  Epoch: 10  Training loss = 3.0763  Validation loss = 4.2450  \n",
      "\n",
      "Fold: 16  Epoch: 11  Training loss = 3.0756  Validation loss = 4.2428  \n",
      "\n",
      "Fold: 16  Epoch: 12  Training loss = 3.0742  Validation loss = 4.2394  \n",
      "\n",
      "Fold: 16  Epoch: 13  Training loss = 3.0730  Validation loss = 4.2371  \n",
      "\n",
      "Fold: 16  Epoch: 14  Training loss = 3.0726  Validation loss = 4.2356  \n",
      "\n",
      "Fold: 16  Epoch: 15  Training loss = 3.0723  Validation loss = 4.2337  \n",
      "\n",
      "Fold: 16  Epoch: 16  Training loss = 3.0714  Validation loss = 4.2321  \n",
      "\n",
      "Fold: 16  Epoch: 17  Training loss = 3.0705  Validation loss = 4.2294  \n",
      "\n",
      "Fold: 16  Epoch: 18  Training loss = 3.0699  Validation loss = 4.2275  \n",
      "\n",
      "Fold: 16  Epoch: 19  Training loss = 3.0698  Validation loss = 4.2264  \n",
      "\n",
      "Fold: 16  Epoch: 20  Training loss = 3.0696  Validation loss = 4.2255  \n",
      "\n",
      "Fold: 16  Epoch: 21  Training loss = 3.0692  Validation loss = 4.2240  \n",
      "\n",
      "Fold: 16  Epoch: 22  Training loss = 3.0680  Validation loss = 4.2208  \n",
      "\n",
      "Fold: 16  Epoch: 23  Training loss = 3.0677  Validation loss = 4.2182  \n",
      "\n",
      "Fold: 16  Epoch: 24  Training loss = 3.0667  Validation loss = 4.2151  \n",
      "\n",
      "Fold: 16  Epoch: 25  Training loss = 3.0662  Validation loss = 4.2117  \n",
      "\n",
      "Fold: 16  Epoch: 26  Training loss = 3.0660  Validation loss = 4.2111  \n",
      "\n",
      "Fold: 16  Epoch: 27  Training loss = 3.0652  Validation loss = 4.2081  \n",
      "\n",
      "Fold: 16  Epoch: 28  Training loss = 3.0648  Validation loss = 4.2071  \n",
      "\n",
      "Fold: 16  Epoch: 29  Training loss = 3.0644  Validation loss = 4.2053  \n",
      "\n",
      "Fold: 16  Epoch: 30  Training loss = 3.0650  Validation loss = 4.2070  \n",
      "\n",
      "Fold: 16  Epoch: 31  Training loss = 3.0641  Validation loss = 4.2049  \n",
      "\n",
      "Fold: 16  Epoch: 32  Training loss = 3.0634  Validation loss = 4.2033  \n",
      "\n",
      "Fold: 16  Epoch: 33  Training loss = 3.0629  Validation loss = 4.2019  \n",
      "\n",
      "Fold: 16  Epoch: 34  Training loss = 3.0626  Validation loss = 4.1990  \n",
      "\n",
      "Fold: 16  Epoch: 35  Training loss = 3.0617  Validation loss = 4.1965  \n",
      "\n",
      "Fold: 16  Epoch: 36  Training loss = 3.0610  Validation loss = 4.1948  \n",
      "\n",
      "Fold: 16  Epoch: 37  Training loss = 3.0611  Validation loss = 4.1942  \n",
      "\n",
      "Fold: 16  Epoch: 38  Training loss = 3.0611  Validation loss = 4.1944  \n",
      "\n",
      "Fold: 16  Epoch: 39  Training loss = 3.0612  Validation loss = 4.1947  \n",
      "\n",
      "Fold: 16  Epoch: 40  Training loss = 3.0610  Validation loss = 4.1945  \n",
      "\n",
      "Fold: 16  Epoch: 41  Training loss = 3.0612  Validation loss = 4.1943  \n",
      "\n",
      "Fold: 16  Epoch: 42  Training loss = 3.0607  Validation loss = 4.1933  \n",
      "\n",
      "Fold: 16  Epoch: 43  Training loss = 3.0605  Validation loss = 4.1929  \n",
      "\n",
      "Fold: 16  Epoch: 44  Training loss = 3.0597  Validation loss = 4.1905  \n",
      "\n",
      "Fold: 16  Epoch: 45  Training loss = 3.0593  Validation loss = 4.1894  \n",
      "\n",
      "Fold: 16  Epoch: 46  Training loss = 3.0588  Validation loss = 4.1882  \n",
      "\n",
      "Fold: 16  Epoch: 47  Training loss = 3.0584  Validation loss = 4.1876  \n",
      "\n",
      "Fold: 16  Epoch: 48  Training loss = 3.0571  Validation loss = 4.1851  \n",
      "\n",
      "Fold: 16  Epoch: 49  Training loss = 3.0564  Validation loss = 4.1840  \n",
      "\n",
      "Fold: 16  Epoch: 50  Training loss = 3.0560  Validation loss = 4.1826  \n",
      "\n",
      "Fold: 16  Epoch: 51  Training loss = 3.0554  Validation loss = 4.1800  \n",
      "\n",
      "Fold: 16  Epoch: 52  Training loss = 3.0550  Validation loss = 4.1786  \n",
      "\n",
      "Fold: 16  Epoch: 53  Training loss = 3.0546  Validation loss = 4.1770  \n",
      "\n",
      "Fold: 16  Epoch: 54  Training loss = 3.0541  Validation loss = 4.1755  \n",
      "\n",
      "Fold: 16  Epoch: 55  Training loss = 3.0537  Validation loss = 4.1741  \n",
      "\n",
      "Fold: 16  Epoch: 56  Training loss = 3.0536  Validation loss = 4.1739  \n",
      "\n",
      "Fold: 16  Epoch: 57  Training loss = 3.0531  Validation loss = 4.1719  \n",
      "\n",
      "Fold: 16  Epoch: 58  Training loss = 3.0523  Validation loss = 4.1694  \n",
      "\n",
      "Fold: 16  Epoch: 59  Training loss = 3.0517  Validation loss = 4.1665  \n",
      "\n",
      "Fold: 16  Epoch: 60  Training loss = 3.0510  Validation loss = 4.1644  \n",
      "\n",
      "Fold: 16  Epoch: 61  Training loss = 3.0529  Validation loss = 4.1640  \n",
      "\n",
      "Fold: 16  Epoch: 62  Training loss = 3.0528  Validation loss = 4.1641  \n",
      "\n",
      "Fold: 16  Epoch: 63  Training loss = 3.0525  Validation loss = 4.1635  \n",
      "\n",
      "Fold: 16  Epoch: 64  Training loss = 3.0520  Validation loss = 4.1613  \n",
      "\n",
      "Fold: 16  Epoch: 65  Training loss = 3.0513  Validation loss = 4.1579  \n",
      "\n",
      "Fold: 16  Epoch: 66  Training loss = 3.0504  Validation loss = 4.1551  \n",
      "\n",
      "Fold: 16  Epoch: 67  Training loss = 3.0503  Validation loss = 4.1556  \n",
      "\n",
      "Fold: 16  Epoch: 68  Training loss = 3.0503  Validation loss = 4.1572  \n",
      "\n",
      "Fold: 16  Epoch: 69  Training loss = 3.0497  Validation loss = 4.1545  \n",
      "\n",
      "Fold: 16  Epoch: 70  Training loss = 3.0498  Validation loss = 4.1561  \n",
      "\n",
      "Fold: 16  Epoch: 71  Training loss = 3.0495  Validation loss = 4.1548  \n",
      "\n",
      "Fold: 16  Epoch: 72  Training loss = 3.0495  Validation loss = 4.1555  \n",
      "\n",
      "Fold: 16  Epoch: 73  Training loss = 3.0492  Validation loss = 4.1523  \n",
      "\n",
      "Fold: 16  Epoch: 74  Training loss = 3.0487  Validation loss = 4.1506  \n",
      "\n",
      "Fold: 16  Epoch: 75  Training loss = 3.0479  Validation loss = 4.1470  \n",
      "\n",
      "Fold: 16  Epoch: 76  Training loss = 3.0474  Validation loss = 4.1452  \n",
      "\n",
      "Fold: 16  Epoch: 77  Training loss = 3.0466  Validation loss = 4.1424  \n",
      "\n",
      "Fold: 16  Epoch: 78  Training loss = 3.0462  Validation loss = 4.1413  \n",
      "\n",
      "Fold: 16  Epoch: 79  Training loss = 3.0455  Validation loss = 4.1380  \n",
      "\n",
      "Fold: 16  Epoch: 80  Training loss = 3.0453  Validation loss = 4.1387  \n",
      "\n",
      "Fold: 16  Epoch: 81  Training loss = 3.0449  Validation loss = 4.1365  \n",
      "\n",
      "Fold: 16  Epoch: 82  Training loss = 3.0446  Validation loss = 4.1361  \n",
      "\n",
      "Fold: 16  Epoch: 83  Training loss = 3.0448  Validation loss = 4.1381  \n",
      "\n",
      "Fold: 16  Epoch: 84  Training loss = 3.0446  Validation loss = 4.1368  \n",
      "\n",
      "Fold: 16  Epoch: 85  Training loss = 3.0440  Validation loss = 4.1361  \n",
      "\n",
      "Fold: 16  Epoch: 86  Training loss = 3.0436  Validation loss = 4.1351  \n",
      "\n",
      "Fold: 16  Epoch: 87  Training loss = 3.0431  Validation loss = 4.1314  \n",
      "\n",
      "Fold: 16  Epoch: 88  Training loss = 3.0427  Validation loss = 4.1312  \n",
      "\n",
      "Fold: 16  Epoch: 89  Training loss = 3.0423  Validation loss = 4.1276  \n",
      "\n",
      "Fold: 16  Epoch: 90  Training loss = 3.0417  Validation loss = 4.1258  \n",
      "\n",
      "Fold: 16  Epoch: 91  Training loss = 3.0419  Validation loss = 4.1253  \n",
      "\n",
      "Fold: 16  Epoch: 92  Training loss = 3.0411  Validation loss = 4.1236  \n",
      "\n",
      "Fold: 16  Epoch: 93  Training loss = 3.0408  Validation loss = 4.1223  \n",
      "\n",
      "Fold: 16  Epoch: 94  Training loss = 3.0402  Validation loss = 4.1210  \n",
      "\n",
      "Fold: 16  Epoch: 95  Training loss = 3.0400  Validation loss = 4.1224  \n",
      "\n",
      "Fold: 16  Epoch: 96  Training loss = 3.0391  Validation loss = 4.1171  \n",
      "\n",
      "Fold: 16  Epoch: 97  Training loss = 3.0386  Validation loss = 4.1165  \n",
      "\n",
      "Fold: 16  Epoch: 98  Training loss = 3.0382  Validation loss = 4.1130  \n",
      "\n",
      "Fold: 16  Epoch: 99  Training loss = 3.0379  Validation loss = 4.1131  \n",
      "\n",
      "Fold: 16  Epoch: 100  Training loss = 3.0373  Validation loss = 4.1096  \n",
      "\n",
      "Fold: 16  Epoch: 101  Training loss = 3.0369  Validation loss = 4.1099  \n",
      "\n",
      "Fold: 16  Epoch: 102  Training loss = 3.0367  Validation loss = 4.1103  \n",
      "\n",
      "Fold: 16  Epoch: 103  Training loss = 3.0367  Validation loss = 4.1112  \n",
      "\n",
      "Fold: 16  Epoch: 104  Training loss = 3.0362  Validation loss = 4.1111  \n",
      "\n",
      "Fold: 16  Epoch: 105  Training loss = 3.0354  Validation loss = 4.1080  \n",
      "\n",
      "Fold: 16  Epoch: 106  Training loss = 3.0351  Validation loss = 4.1034  \n",
      "\n",
      "Fold: 16  Epoch: 107  Training loss = 3.0349  Validation loss = 4.1042  \n",
      "\n",
      "Fold: 16  Epoch: 108  Training loss = 3.0347  Validation loss = 4.1036  \n",
      "\n",
      "Fold: 16  Epoch: 109  Training loss = 3.0344  Validation loss = 4.1006  \n",
      "\n",
      "Fold: 16  Epoch: 110  Training loss = 3.0342  Validation loss = 4.1002  \n",
      "\n",
      "Fold: 16  Epoch: 111  Training loss = 3.0339  Validation loss = 4.0986  \n",
      "\n",
      "Fold: 16  Epoch: 112  Training loss = 3.0334  Validation loss = 4.0962  \n",
      "\n",
      "Fold: 16  Epoch: 113  Training loss = 3.0332  Validation loss = 4.0968  \n",
      "\n",
      "Fold: 16  Epoch: 114  Training loss = 3.0332  Validation loss = 4.0962  \n",
      "\n",
      "Fold: 16  Epoch: 115  Training loss = 3.0324  Validation loss = 4.0940  \n",
      "\n",
      "Fold: 16  Epoch: 116  Training loss = 3.0320  Validation loss = 4.0927  \n",
      "\n",
      "Fold: 16  Epoch: 117  Training loss = 3.0318  Validation loss = 4.0920  \n",
      "\n",
      "Fold: 16  Epoch: 118  Training loss = 3.0313  Validation loss = 4.0897  \n",
      "\n",
      "Fold: 16  Epoch: 119  Training loss = 3.0309  Validation loss = 4.0894  \n",
      "\n",
      "Fold: 16  Epoch: 120  Training loss = 3.0309  Validation loss = 4.0916  \n",
      "\n",
      "Fold: 16  Epoch: 121  Training loss = 3.0305  Validation loss = 4.0912  \n",
      "\n",
      "Fold: 16  Epoch: 122  Training loss = 3.0304  Validation loss = 4.0903  \n",
      "\n",
      "Fold: 16  Epoch: 123  Training loss = 3.0303  Validation loss = 4.0892  \n",
      "\n",
      "Fold: 16  Epoch: 124  Training loss = 3.0301  Validation loss = 4.0863  \n",
      "\n",
      "Fold: 16  Epoch: 125  Training loss = 3.0297  Validation loss = 4.0855  \n",
      "\n",
      "Fold: 16  Epoch: 126  Training loss = 3.0293  Validation loss = 4.0854  \n",
      "\n",
      "Fold: 16  Epoch: 127  Training loss = 3.0293  Validation loss = 4.0893  \n",
      "\n",
      "Fold: 16  Epoch: 128  Training loss = 3.0292  Validation loss = 4.0945  \n",
      "\n",
      "Check model:  Fold: 16  Optimal epoch: 126  \n",
      "\n",
      "Fold: 17  Epoch: 1  Training loss = 3.1765  Validation loss = 3.2136  \n",
      "\n",
      "Fold: 17  Epoch: 2  Training loss = 3.1753  Validation loss = 3.2158  \n",
      "\n",
      "Fold: 17  Epoch: 3  Training loss = 3.1746  Validation loss = 3.2169  \n",
      "\n",
      "Fold: 17  Epoch: 4  Training loss = 3.1743  Validation loss = 3.2166  \n",
      "\n",
      "Fold: 17  Epoch: 5  Training loss = 3.1734  Validation loss = 3.2182  \n",
      "\n",
      "Fold: 17  Epoch: 6  Training loss = 3.1727  Validation loss = 3.2194  \n",
      "\n",
      "Fold: 17  Epoch: 7  Training loss = 3.1726  Validation loss = 3.2193  \n",
      "\n",
      "Fold: 17  Epoch: 8  Training loss = 3.1713  Validation loss = 3.2212  \n",
      "\n",
      "Fold: 17  Epoch: 9  Training loss = 3.1702  Validation loss = 3.2231  \n",
      "\n",
      "Fold: 17  Epoch: 10  Training loss = 3.1685  Validation loss = 3.2264  \n",
      "\n",
      "Fold: 17  Epoch: 11  Training loss = 3.1674  Validation loss = 3.2288  \n",
      "\n",
      "Check model:  Fold: 17  Optimal epoch: 1  \n",
      "\n",
      "Fold: 18  Epoch: 1  Training loss = 3.2624  Validation loss = 2.5364  \n",
      "\n",
      "Fold: 18  Epoch: 2  Training loss = 3.2620  Validation loss = 2.5368  \n",
      "\n",
      "Fold: 18  Epoch: 3  Training loss = 3.2611  Validation loss = 2.5403  \n",
      "\n",
      "Fold: 18  Epoch: 4  Training loss = 3.2602  Validation loss = 2.5382  \n",
      "\n",
      "Fold: 18  Epoch: 5  Training loss = 3.2598  Validation loss = 2.5377  \n",
      "\n",
      "Fold: 18  Epoch: 6  Training loss = 3.2593  Validation loss = 2.5360  \n",
      "\n",
      "Fold: 18  Epoch: 7  Training loss = 3.2586  Validation loss = 2.5337  \n",
      "\n",
      "Fold: 18  Epoch: 8  Training loss = 3.2580  Validation loss = 2.5308  \n",
      "\n",
      "Fold: 18  Epoch: 9  Training loss = 3.2575  Validation loss = 2.5271  \n",
      "\n",
      "Fold: 18  Epoch: 10  Training loss = 3.2572  Validation loss = 2.5252  \n",
      "\n",
      "Fold: 18  Epoch: 11  Training loss = 3.2569  Validation loss = 2.5221  \n",
      "\n",
      "Fold: 18  Epoch: 12  Training loss = 3.2562  Validation loss = 2.5228  \n",
      "\n",
      "Fold: 18  Epoch: 13  Training loss = 3.2554  Validation loss = 2.5215  \n",
      "\n",
      "Fold: 18  Epoch: 14  Training loss = 3.2546  Validation loss = 2.5224  \n",
      "\n",
      "Fold: 18  Epoch: 15  Training loss = 3.2541  Validation loss = 2.5219  \n",
      "\n",
      "Fold: 18  Epoch: 16  Training loss = 3.2542  Validation loss = 2.5218  \n",
      "\n",
      "Fold: 18  Epoch: 17  Training loss = 3.2532  Validation loss = 2.5224  \n",
      "\n",
      "Fold: 18  Epoch: 18  Training loss = 3.2532  Validation loss = 2.5218  \n",
      "\n",
      "Fold: 18  Epoch: 19  Training loss = 3.2528  Validation loss = 2.5252  \n",
      "\n",
      "Check model:  Fold: 18  Optimal epoch: 13  \n",
      "\n",
      "Fold: 19  Epoch: 1  Training loss = 3.2523  Validation loss = 1.0131  \n",
      "\n",
      "Fold: 19  Epoch: 2  Training loss = 3.2514  Validation loss = 1.0106  \n",
      "\n",
      "Fold: 19  Epoch: 3  Training loss = 3.2500  Validation loss = 1.0017  \n",
      "\n",
      "Fold: 19  Epoch: 4  Training loss = 3.2491  Validation loss = 1.0017  \n",
      "\n",
      "Fold: 19  Epoch: 5  Training loss = 3.2489  Validation loss = 1.0046  \n",
      "\n",
      "Fold: 19  Epoch: 6  Training loss = 3.2484  Validation loss = 1.0034  \n",
      "\n",
      "Fold: 19  Epoch: 7  Training loss = 3.2474  Validation loss = 0.9994  \n",
      "\n",
      "Fold: 19  Epoch: 8  Training loss = 3.2466  Validation loss = 0.9939  \n",
      "\n",
      "Fold: 19  Epoch: 9  Training loss = 3.2456  Validation loss = 0.9898  \n",
      "\n",
      "Fold: 19  Epoch: 10  Training loss = 3.2448  Validation loss = 0.9865  \n",
      "\n",
      "Fold: 19  Epoch: 11  Training loss = 3.2442  Validation loss = 0.9876  \n",
      "\n",
      "Fold: 19  Epoch: 12  Training loss = 3.2434  Validation loss = 0.9852  \n",
      "\n",
      "Fold: 19  Epoch: 13  Training loss = 3.2430  Validation loss = 0.9860  \n",
      "\n",
      "Fold: 19  Epoch: 14  Training loss = 3.2423  Validation loss = 0.9866  \n",
      "\n",
      "Fold: 19  Epoch: 15  Training loss = 3.2415  Validation loss = 0.9865  \n",
      "\n",
      "Fold: 19  Epoch: 16  Training loss = 3.2408  Validation loss = 0.9808  \n",
      "\n",
      "Fold: 19  Epoch: 17  Training loss = 3.2407  Validation loss = 0.9863  \n",
      "\n",
      "Fold: 19  Epoch: 18  Training loss = 3.2400  Validation loss = 0.9853  \n",
      "\n",
      "Fold: 19  Epoch: 19  Training loss = 3.2395  Validation loss = 0.9844  \n",
      "\n",
      "Fold: 19  Epoch: 20  Training loss = 3.2387  Validation loss = 0.9814  \n",
      "\n",
      "Fold: 19  Epoch: 21  Training loss = 3.2376  Validation loss = 0.9797  \n",
      "\n",
      "Fold: 19  Epoch: 22  Training loss = 3.2372  Validation loss = 0.9825  \n",
      "\n",
      "Fold: 19  Epoch: 23  Training loss = 3.2371  Validation loss = 0.9855  \n",
      "\n",
      "Fold: 19  Epoch: 24  Training loss = 3.2361  Validation loss = 0.9806  \n",
      "\n",
      "Fold: 19  Epoch: 25  Training loss = 3.2353  Validation loss = 0.9786  \n",
      "\n",
      "Fold: 19  Epoch: 26  Training loss = 3.2345  Validation loss = 0.9738  \n",
      "\n",
      "Fold: 19  Epoch: 27  Training loss = 3.2343  Validation loss = 0.9784  \n",
      "\n",
      "Fold: 19  Epoch: 28  Training loss = 3.2343  Validation loss = 0.9827  \n",
      "\n",
      "Fold: 19  Epoch: 29  Training loss = 3.2334  Validation loss = 0.9797  \n",
      "\n",
      "Fold: 19  Epoch: 30  Training loss = 3.2327  Validation loss = 0.9749  \n",
      "\n",
      "Fold: 19  Epoch: 31  Training loss = 3.2321  Validation loss = 0.9733  \n",
      "\n",
      "Fold: 19  Epoch: 32  Training loss = 3.2317  Validation loss = 0.9725  \n",
      "\n",
      "Fold: 19  Epoch: 33  Training loss = 3.2312  Validation loss = 0.9707  \n",
      "\n",
      "Fold: 19  Epoch: 34  Training loss = 3.2307  Validation loss = 0.9689  \n",
      "\n",
      "Fold: 19  Epoch: 35  Training loss = 3.2300  Validation loss = 0.9702  \n",
      "\n",
      "Fold: 19  Epoch: 36  Training loss = 3.2293  Validation loss = 0.9676  \n",
      "\n",
      "Fold: 19  Epoch: 37  Training loss = 3.2286  Validation loss = 0.9714  \n",
      "\n",
      "Fold: 19  Epoch: 38  Training loss = 3.2279  Validation loss = 0.9690  \n",
      "\n",
      "Fold: 19  Epoch: 39  Training loss = 3.2276  Validation loss = 0.9729  \n",
      "\n",
      "Fold: 19  Epoch: 40  Training loss = 3.2271  Validation loss = 0.9723  \n",
      "\n",
      "Fold: 19  Epoch: 41  Training loss = 3.2268  Validation loss = 0.9737  \n",
      "\n",
      "Check model:  Fold: 19  Optimal epoch: 36  \n",
      "\n",
      "Fold: 20  Epoch: 1  Training loss = 3.2107  Validation loss = 1.4029  \n",
      "\n",
      "Fold: 20  Epoch: 2  Training loss = 3.2100  Validation loss = 1.4035  \n",
      "\n",
      "Fold: 20  Epoch: 3  Training loss = 3.2087  Validation loss = 1.4270  \n",
      "\n",
      "Fold: 20  Epoch: 4  Training loss = 3.2078  Validation loss = 1.4318  \n",
      "\n",
      "Fold: 20  Epoch: 5  Training loss = 3.2070  Validation loss = 1.4446  \n",
      "\n",
      "Fold: 20  Epoch: 6  Training loss = 3.2062  Validation loss = 1.4457  \n",
      "\n",
      "Fold: 20  Epoch: 7  Training loss = 3.2052  Validation loss = 1.4610  \n",
      "\n",
      "Fold: 20  Epoch: 8  Training loss = 3.2046  Validation loss = 1.4697  \n",
      "\n",
      "Fold: 20  Epoch: 9  Training loss = 3.2041  Validation loss = 1.4593  \n",
      "\n",
      "Fold: 20  Epoch: 10  Training loss = 3.2030  Validation loss = 1.4707  \n",
      "\n",
      "Fold: 20  Epoch: 11  Training loss = 3.2022  Validation loss = 1.4735  \n",
      "\n",
      "Check model:  Fold: 20  Optimal epoch: 1  \n",
      "\n",
      "Fold: 21  Epoch: 1  Training loss = 3.2134  Validation loss = 2.6602  \n",
      "\n",
      "Fold: 21  Epoch: 2  Training loss = 3.2127  Validation loss = 2.6524  \n",
      "\n",
      "Fold: 21  Epoch: 3  Training loss = 3.2126  Validation loss = 2.6613  \n",
      "\n",
      "Fold: 21  Epoch: 4  Training loss = 3.2120  Validation loss = 2.6672  \n",
      "\n",
      "Fold: 21  Epoch: 5  Training loss = 3.2116  Validation loss = 2.6622  \n",
      "\n",
      "Fold: 21  Epoch: 6  Training loss = 3.2107  Validation loss = 2.6633  \n",
      "\n",
      "Fold: 21  Epoch: 7  Training loss = 3.2097  Validation loss = 2.6567  \n",
      "\n",
      "Fold: 21  Epoch: 8  Training loss = 3.2094  Validation loss = 2.6594  \n",
      "\n",
      "Fold: 21  Epoch: 9  Training loss = 3.2088  Validation loss = 2.6618  \n",
      "\n",
      "Fold: 21  Epoch: 10  Training loss = 3.2082  Validation loss = 2.6585  \n",
      "\n",
      "Fold: 21  Epoch: 11  Training loss = 3.2076  Validation loss = 2.6610  \n",
      "\n",
      "Fold: 21  Epoch: 12  Training loss = 3.2068  Validation loss = 2.6568  \n",
      "\n",
      "Fold: 21  Epoch: 13  Training loss = 3.2063  Validation loss = 2.6560  \n",
      "\n",
      "Fold: 21  Epoch: 14  Training loss = 3.2056  Validation loss = 2.6551  \n",
      "\n",
      "Fold: 21  Epoch: 15  Training loss = 3.2052  Validation loss = 2.6538  \n",
      "\n",
      "Fold: 21  Epoch: 16  Training loss = 3.2043  Validation loss = 2.6570  \n",
      "\n",
      "Fold: 21  Epoch: 17  Training loss = 3.2037  Validation loss = 2.6622  \n",
      "\n",
      "Check model:  Fold: 21  Optimal epoch: 2  \n",
      "\n",
      "Fold: 22  Epoch: 1  Training loss = 3.2467  Validation loss = 1.0888  \n",
      "\n",
      "Fold: 22  Epoch: 2  Training loss = 3.2459  Validation loss = 1.0862  \n",
      "\n",
      "Fold: 22  Epoch: 3  Training loss = 3.2454  Validation loss = 1.0870  \n",
      "\n",
      "Fold: 22  Epoch: 4  Training loss = 3.2447  Validation loss = 1.0856  \n",
      "\n",
      "Fold: 22  Epoch: 5  Training loss = 3.2435  Validation loss = 1.0878  \n",
      "\n",
      "Fold: 22  Epoch: 6  Training loss = 3.2428  Validation loss = 1.0875  \n",
      "\n",
      "Fold: 22  Epoch: 7  Training loss = 3.2417  Validation loss = 1.0888  \n",
      "\n",
      "Fold: 22  Epoch: 8  Training loss = 3.2410  Validation loss = 1.0878  \n",
      "\n",
      "Fold: 22  Epoch: 9  Training loss = 3.2400  Validation loss = 1.0892  \n",
      "\n",
      "Fold: 22  Epoch: 10  Training loss = 3.2389  Validation loss = 1.0884  \n",
      "\n",
      "Fold: 22  Epoch: 11  Training loss = 3.2384  Validation loss = 1.0861  \n",
      "\n",
      "Fold: 22  Epoch: 12  Training loss = 3.2373  Validation loss = 1.0887  \n",
      "\n",
      "Fold: 22  Epoch: 13  Training loss = 3.2364  Validation loss = 1.0884  \n",
      "\n",
      "Fold: 22  Epoch: 14  Training loss = 3.2352  Validation loss = 1.0916  \n",
      "\n",
      "Check model:  Fold: 22  Optimal epoch: 4  \n",
      "\n",
      "Fold: 23  Epoch: 1  Training loss = 3.1567  Validation loss = 0.8819  \n",
      "\n",
      "Fold: 23  Epoch: 2  Training loss = 3.1553  Validation loss = 0.8709  \n",
      "\n",
      "Fold: 23  Epoch: 3  Training loss = 3.1543  Validation loss = 0.8400  \n",
      "\n",
      "Fold: 23  Epoch: 4  Training loss = 3.1534  Validation loss = 0.8514  \n",
      "\n",
      "Fold: 23  Epoch: 5  Training loss = 3.1521  Validation loss = 0.8932  \n",
      "\n",
      "Fold: 23  Epoch: 6  Training loss = 3.1505  Validation loss = 0.9777  \n",
      "\n",
      "Fold: 23  Epoch: 7  Training loss = 3.1488  Validation loss = 0.9623  \n",
      "\n",
      "Fold: 23  Epoch: 8  Training loss = 3.1471  Validation loss = 0.9682  \n",
      "\n",
      "Fold: 23  Epoch: 9  Training loss = 3.1453  Validation loss = 1.0429  \n",
      "\n",
      "Fold: 23  Epoch: 10  Training loss = 3.1450  Validation loss = 0.9494  \n",
      "\n",
      "Fold: 23  Epoch: 11  Training loss = 3.1452  Validation loss = 0.8453  \n",
      "\n",
      "Fold: 23  Epoch: 12  Training loss = 3.1439  Validation loss = 0.8528  \n",
      "\n",
      "Fold: 23  Epoch: 13  Training loss = 3.1423  Validation loss = 0.8887  \n",
      "\n",
      "Fold: 23  Epoch: 14  Training loss = 3.1415  Validation loss = 0.8536  \n",
      "\n",
      "Fold: 23  Epoch: 15  Training loss = 3.1404  Validation loss = 0.8804  \n",
      "\n",
      "Fold: 23  Epoch: 16  Training loss = 3.1397  Validation loss = 0.8667  \n",
      "\n",
      "Fold: 23  Epoch: 17  Training loss = 3.1375  Validation loss = 0.9398  \n",
      "\n",
      "Fold: 23  Epoch: 18  Training loss = 3.1360  Validation loss = 1.0417  \n",
      "\n",
      "Fold: 23  Epoch: 19  Training loss = 3.1349  Validation loss = 0.9924  \n",
      "\n",
      "Fold: 23  Epoch: 20  Training loss = 3.1340  Validation loss = 1.0085  \n",
      "\n",
      "Fold: 23  Epoch: 21  Training loss = 3.1330  Validation loss = 0.9749  \n",
      "\n",
      "Fold: 23  Epoch: 22  Training loss = 3.1338  Validation loss = 0.8887  \n",
      "\n",
      "Fold: 23  Epoch: 23  Training loss = 3.1323  Validation loss = 0.9455  \n",
      "\n",
      "Fold: 23  Epoch: 24  Training loss = 3.1308  Validation loss = 0.9941  \n",
      "\n",
      "Fold: 23  Epoch: 25  Training loss = 3.1298  Validation loss = 0.9975  \n",
      "\n",
      "Fold: 23  Epoch: 26  Training loss = 3.1292  Validation loss = 1.0105  \n",
      "\n",
      "Fold: 23  Epoch: 27  Training loss = 3.1282  Validation loss = 1.0183  \n",
      "\n",
      "Fold: 23  Epoch: 28  Training loss = 3.1271  Validation loss = 0.9955  \n",
      "\n",
      "Fold: 23  Epoch: 29  Training loss = 3.1260  Validation loss = 0.9492  \n",
      "\n",
      "Fold: 23  Epoch: 30  Training loss = 3.1242  Validation loss = 0.9360  \n",
      "\n",
      "Fold: 23  Epoch: 31  Training loss = 3.1232  Validation loss = 0.9783  \n",
      "\n",
      "Fold: 23  Epoch: 32  Training loss = 3.1224  Validation loss = 1.0063  \n",
      "\n",
      "Fold: 23  Epoch: 33  Training loss = 3.1213  Validation loss = 1.0135  \n",
      "\n",
      "Fold: 23  Epoch: 34  Training loss = 3.1205  Validation loss = 1.0495  \n",
      "\n",
      "Check model:  Fold: 23  Optimal epoch: 3  \n",
      "\n",
      "Fold: 24  Epoch: 1  Training loss = 2.9924  Validation loss = 1.6162  \n",
      "\n",
      "Fold: 24  Epoch: 2  Training loss = 2.9898  Validation loss = 1.6128  \n",
      "\n",
      "Fold: 24  Epoch: 3  Training loss = 2.9892  Validation loss = 1.6105  \n",
      "\n",
      "Fold: 24  Epoch: 4  Training loss = 2.9886  Validation loss = 1.6076  \n",
      "\n",
      "Fold: 24  Epoch: 5  Training loss = 2.9861  Validation loss = 1.6084  \n",
      "\n",
      "Fold: 24  Epoch: 6  Training loss = 2.9855  Validation loss = 1.6095  \n",
      "\n",
      "Fold: 24  Epoch: 7  Training loss = 2.9847  Validation loss = 1.6110  \n",
      "\n",
      "Fold: 24  Epoch: 8  Training loss = 2.9829  Validation loss = 1.6053  \n",
      "\n",
      "Fold: 24  Epoch: 9  Training loss = 2.9809  Validation loss = 1.6074  \n",
      "\n",
      "Fold: 24  Epoch: 10  Training loss = 2.9785  Validation loss = 1.6068  \n",
      "\n",
      "Fold: 24  Epoch: 11  Training loss = 2.9771  Validation loss = 1.6063  \n",
      "\n",
      "Fold: 24  Epoch: 12  Training loss = 2.9768  Validation loss = 1.6023  \n",
      "\n",
      "Fold: 24  Epoch: 13  Training loss = 2.9755  Validation loss = 1.6017  \n",
      "\n",
      "Fold: 24  Epoch: 14  Training loss = 2.9747  Validation loss = 1.6020  \n",
      "\n",
      "Fold: 24  Epoch: 15  Training loss = 2.9746  Validation loss = 1.6033  \n",
      "\n",
      "Fold: 24  Epoch: 16  Training loss = 2.9727  Validation loss = 1.5980  \n",
      "\n",
      "Fold: 24  Epoch: 17  Training loss = 2.9710  Validation loss = 1.5973  \n",
      "\n",
      "Fold: 24  Epoch: 18  Training loss = 2.9698  Validation loss = 1.6027  \n",
      "\n",
      "Fold: 24  Epoch: 19  Training loss = 2.9684  Validation loss = 1.6033  \n",
      "\n",
      "Fold: 24  Epoch: 20  Training loss = 2.9676  Validation loss = 1.6013  \n",
      "\n",
      "Fold: 24  Epoch: 21  Training loss = 2.9666  Validation loss = 1.6024  \n",
      "\n",
      "Fold: 24  Epoch: 22  Training loss = 2.9660  Validation loss = 1.6027  \n",
      "\n",
      "Fold: 24  Epoch: 23  Training loss = 2.9637  Validation loss = 1.5963  \n",
      "\n",
      "Fold: 24  Epoch: 24  Training loss = 2.9617  Validation loss = 1.5950  \n",
      "\n",
      "Fold: 24  Epoch: 25  Training loss = 2.9611  Validation loss = 1.5946  \n",
      "\n",
      "Fold: 24  Epoch: 26  Training loss = 2.9598  Validation loss = 1.5938  \n",
      "\n",
      "Fold: 24  Epoch: 27  Training loss = 2.9583  Validation loss = 1.5881  \n",
      "\n",
      "Fold: 24  Epoch: 28  Training loss = 2.9564  Validation loss = 1.5863  \n",
      "\n",
      "Fold: 24  Epoch: 29  Training loss = 2.9551  Validation loss = 1.5881  \n",
      "\n",
      "Fold: 24  Epoch: 30  Training loss = 2.9539  Validation loss = 1.5823  \n",
      "\n",
      "Fold: 24  Epoch: 31  Training loss = 2.9523  Validation loss = 1.5826  \n",
      "\n",
      "Fold: 24  Epoch: 32  Training loss = 2.9515  Validation loss = 1.5861  \n",
      "\n",
      "Fold: 24  Epoch: 33  Training loss = 2.9511  Validation loss = 1.5895  \n",
      "\n",
      "Fold: 24  Epoch: 34  Training loss = 2.9503  Validation loss = 1.5887  \n",
      "\n",
      "Fold: 24  Epoch: 35  Training loss = 2.9474  Validation loss = 1.5816  \n",
      "\n",
      "Fold: 24  Epoch: 36  Training loss = 2.9457  Validation loss = 1.5824  \n",
      "\n",
      "Fold: 24  Epoch: 37  Training loss = 2.9446  Validation loss = 1.5808  \n",
      "\n",
      "Fold: 24  Epoch: 38  Training loss = 2.9433  Validation loss = 1.5758  \n",
      "\n",
      "Fold: 24  Epoch: 39  Training loss = 2.9423  Validation loss = 1.5781  \n",
      "\n",
      "Fold: 24  Epoch: 40  Training loss = 2.9419  Validation loss = 1.5826  \n",
      "\n",
      "Fold: 24  Epoch: 41  Training loss = 2.9405  Validation loss = 1.5803  \n",
      "\n",
      "Fold: 24  Epoch: 42  Training loss = 2.9384  Validation loss = 1.5770  \n",
      "\n",
      "Fold: 24  Epoch: 43  Training loss = 2.9377  Validation loss = 1.5770  \n",
      "\n",
      "Fold: 24  Epoch: 44  Training loss = 2.9368  Validation loss = 1.5768  \n",
      "\n",
      "Fold: 24  Epoch: 45  Training loss = 2.9359  Validation loss = 1.5761  \n",
      "\n",
      "Fold: 24  Epoch: 46  Training loss = 2.9347  Validation loss = 1.5720  \n",
      "\n",
      "Fold: 24  Epoch: 47  Training loss = 2.9329  Validation loss = 1.5656  \n",
      "\n",
      "Fold: 24  Epoch: 48  Training loss = 2.9316  Validation loss = 1.5714  \n",
      "\n",
      "Fold: 24  Epoch: 49  Training loss = 2.9302  Validation loss = 1.5713  \n",
      "\n",
      "Fold: 24  Epoch: 50  Training loss = 2.9283  Validation loss = 1.5672  \n",
      "\n",
      "Fold: 24  Epoch: 51  Training loss = 2.9273  Validation loss = 1.5682  \n",
      "\n",
      "Fold: 24  Epoch: 52  Training loss = 2.9257  Validation loss = 1.5637  \n",
      "\n",
      "Fold: 24  Epoch: 53  Training loss = 2.9261  Validation loss = 1.5710  \n",
      "\n",
      "Fold: 24  Epoch: 54  Training loss = 2.9241  Validation loss = 1.5628  \n",
      "\n",
      "Fold: 24  Epoch: 55  Training loss = 2.9232  Validation loss = 1.5625  \n",
      "\n",
      "Fold: 24  Epoch: 56  Training loss = 2.9225  Validation loss = 1.5646  \n",
      "\n",
      "Fold: 24  Epoch: 57  Training loss = 2.9217  Validation loss = 1.5652  \n",
      "\n",
      "Fold: 24  Epoch: 58  Training loss = 2.9215  Validation loss = 1.5655  \n",
      "\n",
      "Fold: 24  Epoch: 59  Training loss = 2.9197  Validation loss = 1.5603  \n",
      "\n",
      "Fold: 24  Epoch: 60  Training loss = 2.9177  Validation loss = 1.5573  \n",
      "\n",
      "Fold: 24  Epoch: 61  Training loss = 2.9162  Validation loss = 1.5576  \n",
      "\n",
      "Fold: 24  Epoch: 62  Training loss = 2.9150  Validation loss = 1.5584  \n",
      "\n",
      "Fold: 24  Epoch: 63  Training loss = 2.9139  Validation loss = 1.5587  \n",
      "\n",
      "Fold: 24  Epoch: 64  Training loss = 2.9126  Validation loss = 1.5584  \n",
      "\n",
      "Fold: 24  Epoch: 65  Training loss = 2.9115  Validation loss = 1.5550  \n",
      "\n",
      "Fold: 24  Epoch: 66  Training loss = 2.9104  Validation loss = 1.5515  \n",
      "\n",
      "Fold: 24  Epoch: 67  Training loss = 2.9094  Validation loss = 1.5546  \n",
      "\n",
      "Fold: 24  Epoch: 68  Training loss = 2.9087  Validation loss = 1.5523  \n",
      "\n",
      "Fold: 24  Epoch: 69  Training loss = 2.9076  Validation loss = 1.5525  \n",
      "\n",
      "Fold: 24  Epoch: 70  Training loss = 2.9066  Validation loss = 1.5488  \n",
      "\n",
      "Fold: 24  Epoch: 71  Training loss = 2.9056  Validation loss = 1.5502  \n",
      "\n",
      "Fold: 24  Epoch: 72  Training loss = 2.9046  Validation loss = 1.5466  \n",
      "\n",
      "Fold: 24  Epoch: 73  Training loss = 2.9034  Validation loss = 1.5462  \n",
      "\n",
      "Fold: 24  Epoch: 74  Training loss = 2.9024  Validation loss = 1.5417  \n",
      "\n",
      "Fold: 24  Epoch: 75  Training loss = 2.9011  Validation loss = 1.5415  \n",
      "\n",
      "Fold: 24  Epoch: 76  Training loss = 2.9000  Validation loss = 1.5464  \n",
      "\n",
      "Fold: 24  Epoch: 77  Training loss = 2.8990  Validation loss = 1.5468  \n",
      "\n",
      "Fold: 24  Epoch: 78  Training loss = 2.8979  Validation loss = 1.5465  \n",
      "\n",
      "Fold: 24  Epoch: 79  Training loss = 2.8964  Validation loss = 1.5435  \n",
      "\n",
      "Fold: 24  Epoch: 80  Training loss = 2.8957  Validation loss = 1.5474  \n",
      "\n",
      "Fold: 24  Epoch: 81  Training loss = 2.8949  Validation loss = 1.5455  \n",
      "\n",
      "Fold: 24  Epoch: 82  Training loss = 2.8937  Validation loss = 1.5425  \n",
      "\n",
      "Fold: 24  Epoch: 83  Training loss = 2.8920  Validation loss = 1.5410  \n",
      "\n",
      "Fold: 24  Epoch: 84  Training loss = 2.8911  Validation loss = 1.5386  \n",
      "\n",
      "Fold: 24  Epoch: 85  Training loss = 2.8899  Validation loss = 1.5361  \n",
      "\n",
      "Fold: 24  Epoch: 86  Training loss = 2.8887  Validation loss = 1.5368  \n",
      "\n",
      "Fold: 24  Epoch: 87  Training loss = 2.8876  Validation loss = 1.5331  \n",
      "\n",
      "Fold: 24  Epoch: 88  Training loss = 2.8862  Validation loss = 1.5347  \n",
      "\n",
      "Fold: 24  Epoch: 89  Training loss = 2.8858  Validation loss = 1.5375  \n",
      "\n",
      "Fold: 24  Epoch: 90  Training loss = 2.8845  Validation loss = 1.5348  \n",
      "\n",
      "Fold: 24  Epoch: 91  Training loss = 2.8848  Validation loss = 1.5402  \n",
      "\n",
      "Fold: 24  Epoch: 92  Training loss = 2.8838  Validation loss = 1.5381  \n",
      "\n",
      "Fold: 24  Epoch: 93  Training loss = 2.8827  Validation loss = 1.5372  \n",
      "\n",
      "Fold: 24  Epoch: 94  Training loss = 2.8818  Validation loss = 1.5352  \n",
      "\n",
      "Fold: 24  Epoch: 95  Training loss = 2.8817  Validation loss = 1.5373  \n",
      "\n",
      "Fold: 24  Epoch: 96  Training loss = 2.8801  Validation loss = 1.5325  \n",
      "\n",
      "Fold: 24  Epoch: 97  Training loss = 2.8788  Validation loss = 1.5282  \n",
      "\n",
      "Fold: 24  Epoch: 98  Training loss = 2.8782  Validation loss = 1.5343  \n",
      "\n",
      "Fold: 24  Epoch: 99  Training loss = 2.8765  Validation loss = 1.5315  \n",
      "\n",
      "Fold: 24  Epoch: 100  Training loss = 2.8755  Validation loss = 1.5308  \n",
      "\n",
      "Fold: 24  Epoch: 101  Training loss = 2.8745  Validation loss = 1.5296  \n",
      "\n",
      "Fold: 24  Epoch: 102  Training loss = 2.8739  Validation loss = 1.5313  \n",
      "\n",
      "Fold: 24  Epoch: 103  Training loss = 2.8732  Validation loss = 1.5290  \n",
      "\n",
      "Fold: 24  Epoch: 104  Training loss = 2.8725  Validation loss = 1.5240  \n",
      "\n",
      "Fold: 24  Epoch: 105  Training loss = 2.8711  Validation loss = 1.5303  \n",
      "\n",
      "Fold: 24  Epoch: 106  Training loss = 2.8704  Validation loss = 1.5302  \n",
      "\n",
      "Fold: 24  Epoch: 107  Training loss = 2.8695  Validation loss = 1.5269  \n",
      "\n",
      "Fold: 24  Epoch: 108  Training loss = 2.8687  Validation loss = 1.5241  \n",
      "\n",
      "Fold: 24  Epoch: 109  Training loss = 2.8675  Validation loss = 1.5241  \n",
      "\n",
      "Fold: 24  Epoch: 110  Training loss = 2.8665  Validation loss = 1.5207  \n",
      "\n",
      "Fold: 24  Epoch: 111  Training loss = 2.8651  Validation loss = 1.5256  \n",
      "\n",
      "Fold: 24  Epoch: 112  Training loss = 2.8641  Validation loss = 1.5265  \n",
      "\n",
      "Fold: 24  Epoch: 113  Training loss = 2.8633  Validation loss = 1.5198  \n",
      "\n",
      "Fold: 24  Epoch: 114  Training loss = 2.8635  Validation loss = 1.5156  \n",
      "\n",
      "Fold: 24  Epoch: 115  Training loss = 2.8611  Validation loss = 1.5191  \n",
      "\n",
      "Fold: 24  Epoch: 116  Training loss = 2.8609  Validation loss = 1.5171  \n",
      "\n",
      "Fold: 24  Epoch: 117  Training loss = 2.8593  Validation loss = 1.5247  \n",
      "\n",
      "Fold: 24  Epoch: 118  Training loss = 2.8587  Validation loss = 1.5263  \n",
      "\n",
      "Fold: 24  Epoch: 119  Training loss = 2.8573  Validation loss = 1.5222  \n",
      "\n",
      "Fold: 24  Epoch: 120  Training loss = 2.8566  Validation loss = 1.5188  \n",
      "\n",
      "Fold: 24  Epoch: 121  Training loss = 2.8558  Validation loss = 1.5206  \n",
      "\n",
      "Fold: 24  Epoch: 122  Training loss = 2.8548  Validation loss = 1.5218  \n",
      "\n",
      "Fold: 24  Epoch: 123  Training loss = 2.8541  Validation loss = 1.5229  \n",
      "\n",
      "Fold: 24  Epoch: 124  Training loss = 2.8531  Validation loss = 1.5194  \n",
      "\n",
      "Fold: 24  Epoch: 125  Training loss = 2.8526  Validation loss = 1.5192  \n",
      "\n",
      "Fold: 24  Epoch: 126  Training loss = 2.8521  Validation loss = 1.5154  \n",
      "\n",
      "Fold: 24  Epoch: 127  Training loss = 2.8509  Validation loss = 1.5172  \n",
      "\n",
      "Fold: 24  Epoch: 128  Training loss = 2.8503  Validation loss = 1.5151  \n",
      "\n",
      "Fold: 24  Epoch: 129  Training loss = 2.8497  Validation loss = 1.5155  \n",
      "\n",
      "Fold: 24  Epoch: 130  Training loss = 2.8486  Validation loss = 1.5182  \n",
      "\n",
      "Fold: 24  Epoch: 131  Training loss = 2.8477  Validation loss = 1.5149  \n",
      "\n",
      "Fold: 24  Epoch: 132  Training loss = 2.8469  Validation loss = 1.5152  \n",
      "\n",
      "Fold: 24  Epoch: 133  Training loss = 2.8454  Validation loss = 1.5141  \n",
      "\n",
      "Fold: 24  Epoch: 134  Training loss = 2.8437  Validation loss = 1.5147  \n",
      "\n",
      "Fold: 24  Epoch: 135  Training loss = 2.8423  Validation loss = 1.5148  \n",
      "\n",
      "Fold: 24  Epoch: 136  Training loss = 2.8417  Validation loss = 1.5143  \n",
      "\n",
      "Fold: 24  Epoch: 137  Training loss = 2.8405  Validation loss = 1.5135  \n",
      "\n",
      "Fold: 24  Epoch: 138  Training loss = 2.8398  Validation loss = 1.5123  \n",
      "\n",
      "Fold: 24  Epoch: 139  Training loss = 2.8388  Validation loss = 1.5140  \n",
      "\n",
      "Fold: 24  Epoch: 140  Training loss = 2.8376  Validation loss = 1.5173  \n",
      "\n",
      "Check model:  Fold: 24  Optimal epoch: 138  \n",
      "\n",
      "Fold: 25  Epoch: 1  Training loss = 2.8195  Validation loss = 2.4126  \n",
      "\n",
      "Fold: 25  Epoch: 2  Training loss = 2.8175  Validation loss = 2.3508  \n",
      "\n",
      "Fold: 25  Epoch: 3  Training loss = 2.8170  Validation loss = 2.3586  \n",
      "\n",
      "Fold: 25  Epoch: 4  Training loss = 2.8163  Validation loss = 2.3807  \n",
      "\n",
      "Fold: 25  Epoch: 5  Training loss = 2.8154  Validation loss = 2.3813  \n",
      "\n",
      "Fold: 25  Epoch: 6  Training loss = 2.8143  Validation loss = 2.3561  \n",
      "\n",
      "Fold: 25  Epoch: 7  Training loss = 2.8132  Validation loss = 2.3616  \n",
      "\n",
      "Fold: 25  Epoch: 8  Training loss = 2.8119  Validation loss = 2.3467  \n",
      "\n",
      "Fold: 25  Epoch: 9  Training loss = 2.8110  Validation loss = 2.3568  \n",
      "\n",
      "Fold: 25  Epoch: 10  Training loss = 2.8099  Validation loss = 2.1787  \n",
      "\n",
      "Fold: 25  Epoch: 11  Training loss = 2.8082  Validation loss = 2.2662  \n",
      "\n",
      "Fold: 25  Epoch: 12  Training loss = 2.8067  Validation loss = 2.2034  \n",
      "\n",
      "Fold: 25  Epoch: 13  Training loss = 2.8065  Validation loss = 2.1672  \n",
      "\n",
      "Fold: 25  Epoch: 14  Training loss = 2.8053  Validation loss = 2.2155  \n",
      "\n",
      "Fold: 25  Epoch: 15  Training loss = 2.8048  Validation loss = 2.1719  \n",
      "\n",
      "Fold: 25  Epoch: 16  Training loss = 2.8038  Validation loss = 2.2713  \n",
      "\n",
      "Fold: 25  Epoch: 17  Training loss = 2.8022  Validation loss = 2.2297  \n",
      "\n",
      "Fold: 25  Epoch: 18  Training loss = 2.8011  Validation loss = 2.2004  \n",
      "\n",
      "Fold: 25  Epoch: 19  Training loss = 2.8001  Validation loss = 2.2383  \n",
      "\n",
      "Fold: 25  Epoch: 20  Training loss = 2.7996  Validation loss = 2.1851  \n",
      "\n",
      "Fold: 25  Epoch: 21  Training loss = 2.7986  Validation loss = 2.1957  \n",
      "\n",
      "Fold: 25  Epoch: 22  Training loss = 2.7979  Validation loss = 2.2289  \n",
      "\n",
      "Fold: 25  Epoch: 23  Training loss = 2.7972  Validation loss = 2.2416  \n",
      "\n",
      "Fold: 25  Epoch: 24  Training loss = 2.7979  Validation loss = 2.4083  \n",
      "\n",
      "Check model:  Fold: 25  Optimal epoch: 13  \n",
      "\n",
      "Fold: 26  Epoch: 1  Training loss = 2.6309  Validation loss = 2.3460  \n",
      "\n",
      "Fold: 26  Epoch: 2  Training loss = 2.6270  Validation loss = 2.4215  \n",
      "\n",
      "Fold: 26  Epoch: 3  Training loss = 2.6233  Validation loss = 2.5214  \n",
      "\n",
      "Fold: 26  Epoch: 4  Training loss = 2.6223  Validation loss = 2.5380  \n",
      "\n",
      "Fold: 26  Epoch: 5  Training loss = 2.6214  Validation loss = 2.5645  \n",
      "\n",
      "Fold: 26  Epoch: 6  Training loss = 2.6173  Validation loss = 2.5621  \n",
      "\n",
      "Fold: 26  Epoch: 7  Training loss = 2.6137  Validation loss = 2.5573  \n",
      "\n",
      "Fold: 26  Epoch: 8  Training loss = 2.6112  Validation loss = 2.5610  \n",
      "\n",
      "Fold: 26  Epoch: 9  Training loss = 2.6100  Validation loss = 2.4936  \n",
      "\n",
      "Fold: 26  Epoch: 10  Training loss = 2.6095  Validation loss = 2.5261  \n",
      "\n",
      "Fold: 26  Epoch: 11  Training loss = 2.6100  Validation loss = 2.5448  \n",
      "\n",
      "Fold: 26  Epoch: 12  Training loss = 2.6073  Validation loss = 2.5338  \n",
      "\n",
      "Fold: 26  Epoch: 13  Training loss = 2.6054  Validation loss = 2.5356  \n",
      "\n",
      "Fold: 26  Epoch: 14  Training loss = 2.6047  Validation loss = 2.5231  \n",
      "\n",
      "Fold: 26  Epoch: 15  Training loss = 2.6024  Validation loss = 2.5548  \n",
      "\n",
      "Fold: 26  Epoch: 16  Training loss = 2.6019  Validation loss = 2.5643  \n",
      "\n",
      "Check model:  Fold: 26  Optimal epoch: 1  \n",
      "\n",
      "Fold: 27  Epoch: 1  Training loss = 2.6001  Validation loss = 1.6780  \n",
      "\n",
      "Fold: 27  Epoch: 2  Training loss = 2.5976  Validation loss = 1.6526  \n",
      "\n",
      "Fold: 27  Epoch: 3  Training loss = 2.5972  Validation loss = 1.6500  \n",
      "\n",
      "Fold: 27  Epoch: 4  Training loss = 2.5991  Validation loss = 1.6903  \n",
      "\n",
      "Fold: 27  Epoch: 5  Training loss = 2.5966  Validation loss = 1.6317  \n",
      "\n",
      "Fold: 27  Epoch: 6  Training loss = 2.5950  Validation loss = 1.5650  \n",
      "\n",
      "Fold: 27  Epoch: 7  Training loss = 2.5944  Validation loss = 1.5884  \n",
      "\n",
      "Fold: 27  Epoch: 8  Training loss = 2.5944  Validation loss = 1.5997  \n",
      "\n",
      "Fold: 27  Epoch: 9  Training loss = 2.5942  Validation loss = 1.6011  \n",
      "\n",
      "Fold: 27  Epoch: 10  Training loss = 2.5927  Validation loss = 1.5995  \n",
      "\n",
      "Fold: 27  Epoch: 11  Training loss = 2.5922  Validation loss = 1.5846  \n",
      "\n",
      "Fold: 27  Epoch: 12  Training loss = 2.5920  Validation loss = 1.5024  \n",
      "\n",
      "Fold: 27  Epoch: 13  Training loss = 2.5918  Validation loss = 1.5843  \n",
      "\n",
      "Fold: 27  Epoch: 14  Training loss = 2.5912  Validation loss = 1.4646  \n",
      "\n",
      "Fold: 27  Epoch: 15  Training loss = 2.5905  Validation loss = 1.4725  \n",
      "\n",
      "Fold: 27  Epoch: 16  Training loss = 2.5909  Validation loss = 1.2657  \n",
      "\n",
      "Fold: 27  Epoch: 17  Training loss = 2.5884  Validation loss = 1.5607  \n",
      "\n",
      "Fold: 27  Epoch: 18  Training loss = 2.5878  Validation loss = 1.5479  \n",
      "\n",
      "Fold: 27  Epoch: 19  Training loss = 2.5880  Validation loss = 1.5834  \n",
      "\n",
      "Fold: 27  Epoch: 20  Training loss = 2.5869  Validation loss = 1.5994  \n",
      "\n",
      "Check model:  Fold: 27  Optimal epoch: 16  \n",
      "\n",
      "Fold: 28  Epoch: 1  Training loss = 2.4754  Validation loss = 1.8456  \n",
      "\n",
      "Fold: 28  Epoch: 2  Training loss = 2.4763  Validation loss = 1.8618  \n",
      "\n",
      "Fold: 28  Epoch: 3  Training loss = 2.4728  Validation loss = 1.8396  \n",
      "\n",
      "Fold: 28  Epoch: 4  Training loss = 2.4725  Validation loss = 1.8440  \n",
      "\n",
      "Fold: 28  Epoch: 5  Training loss = 2.4715  Validation loss = 1.8437  \n",
      "\n",
      "Fold: 28  Epoch: 6  Training loss = 2.4711  Validation loss = 1.8526  \n",
      "\n",
      "Fold: 28  Epoch: 7  Training loss = 2.4667  Validation loss = 1.8179  \n",
      "\n",
      "Fold: 28  Epoch: 8  Training loss = 2.4648  Validation loss = 1.8102  \n",
      "\n",
      "Fold: 28  Epoch: 9  Training loss = 2.4641  Validation loss = 1.8119  \n",
      "\n",
      "Fold: 28  Epoch: 10  Training loss = 2.4532  Validation loss = 1.7695  \n",
      "\n",
      "Fold: 28  Epoch: 11  Training loss = 2.4502  Validation loss = 1.7828  \n",
      "\n",
      "Fold: 28  Epoch: 12  Training loss = 2.4497  Validation loss = 1.7797  \n",
      "\n",
      "Fold: 28  Epoch: 13  Training loss = 2.4480  Validation loss = 1.7733  \n",
      "\n",
      "Fold: 28  Epoch: 14  Training loss = 2.4566  Validation loss = 1.8019  \n",
      "\n",
      "Fold: 28  Epoch: 15  Training loss = 2.4464  Validation loss = 1.7777  \n",
      "\n",
      "Fold: 28  Epoch: 16  Training loss = 2.4518  Validation loss = 1.7611  \n",
      "\n",
      "Fold: 28  Epoch: 17  Training loss = 2.4526  Validation loss = 1.7596  \n",
      "\n",
      "Fold: 28  Epoch: 18  Training loss = 2.4556  Validation loss = 1.8061  \n",
      "\n",
      "Fold: 28  Epoch: 19  Training loss = 2.4489  Validation loss = 1.7886  \n",
      "\n",
      "Fold: 28  Epoch: 20  Training loss = 2.4551  Validation loss = 1.8146  \n",
      "\n",
      "Check model:  Fold: 28  Optimal epoch: 17  \n",
      "\n",
      "Fold: 29  Epoch: 1  Training loss = 2.4697  Validation loss = 1.7836  \n",
      "\n",
      "Fold: 29  Epoch: 2  Training loss = 2.4659  Validation loss = 1.7740  \n",
      "\n",
      "Fold: 29  Epoch: 3  Training loss = 2.4615  Validation loss = 1.7667  \n",
      "\n",
      "Fold: 29  Epoch: 4  Training loss = 2.4620  Validation loss = 1.7658  \n",
      "\n",
      "Fold: 29  Epoch: 5  Training loss = 2.4600  Validation loss = 1.7601  \n",
      "\n",
      "Fold: 29  Epoch: 6  Training loss = 2.4587  Validation loss = 1.7580  \n",
      "\n",
      "Fold: 29  Epoch: 7  Training loss = 2.4606  Validation loss = 1.7403  \n",
      "\n",
      "Fold: 29  Epoch: 8  Training loss = 2.4516  Validation loss = 1.7427  \n",
      "\n",
      "Fold: 29  Epoch: 9  Training loss = 2.4466  Validation loss = 1.7440  \n",
      "\n",
      "Fold: 29  Epoch: 10  Training loss = 2.4563  Validation loss = 1.7630  \n",
      "\n",
      "Fold: 29  Epoch: 11  Training loss = 2.4527  Validation loss = 1.7530  \n",
      "\n",
      "Fold: 29  Epoch: 12  Training loss = 2.4520  Validation loss = 1.7504  \n",
      "\n",
      "Fold: 29  Epoch: 13  Training loss = 2.4507  Validation loss = 1.7477  \n",
      "\n",
      "Fold: 29  Epoch: 14  Training loss = 2.4498  Validation loss = 1.7493  \n",
      "\n",
      "Fold: 29  Epoch: 15  Training loss = 2.4508  Validation loss = 1.7542  \n",
      "\n",
      "Fold: 29  Epoch: 16  Training loss = 2.4505  Validation loss = 1.7546  \n",
      "\n",
      "Fold: 29  Epoch: 17  Training loss = 2.4467  Validation loss = 1.7444  \n",
      "\n",
      "Fold: 29  Epoch: 18  Training loss = 2.4436  Validation loss = 1.7358  \n",
      "\n",
      "Fold: 29  Epoch: 19  Training loss = 2.4415  Validation loss = 1.7307  \n",
      "\n",
      "Fold: 29  Epoch: 20  Training loss = 2.4409  Validation loss = 1.7280  \n",
      "\n",
      "Fold: 29  Epoch: 21  Training loss = 2.4350  Validation loss = 1.7165  \n",
      "\n",
      "Fold: 29  Epoch: 22  Training loss = 2.4404  Validation loss = 1.7345  \n",
      "\n",
      "Fold: 29  Epoch: 23  Training loss = 2.4395  Validation loss = 1.7342  \n",
      "\n",
      "Fold: 29  Epoch: 24  Training loss = 2.4385  Validation loss = 1.7323  \n",
      "\n",
      "Fold: 29  Epoch: 25  Training loss = 2.4351  Validation loss = 1.7165  \n",
      "\n",
      "Fold: 29  Epoch: 26  Training loss = 2.4341  Validation loss = 1.7176  \n",
      "\n",
      "Fold: 29  Epoch: 27  Training loss = 2.4341  Validation loss = 1.7259  \n",
      "\n",
      "Fold: 29  Epoch: 28  Training loss = 2.4311  Validation loss = 1.7080  \n",
      "\n",
      "Fold: 29  Epoch: 29  Training loss = 2.4300  Validation loss = 1.7056  \n",
      "\n",
      "Fold: 29  Epoch: 30  Training loss = 2.4295  Validation loss = 1.7073  \n",
      "\n",
      "Fold: 29  Epoch: 31  Training loss = 2.4264  Validation loss = 1.6967  \n",
      "\n",
      "Fold: 29  Epoch: 32  Training loss = 2.4243  Validation loss = 1.6957  \n",
      "\n",
      "Fold: 29  Epoch: 33  Training loss = 2.4255  Validation loss = 1.6951  \n",
      "\n",
      "Fold: 29  Epoch: 34  Training loss = 2.4277  Validation loss = 1.6964  \n",
      "\n",
      "Fold: 29  Epoch: 35  Training loss = 2.4239  Validation loss = 1.7107  \n",
      "\n",
      "Fold: 29  Epoch: 36  Training loss = 2.4210  Validation loss = 1.7123  \n",
      "\n",
      "Fold: 29  Epoch: 37  Training loss = 2.4230  Validation loss = 1.7059  \n",
      "\n",
      "Fold: 29  Epoch: 38  Training loss = 2.4193  Validation loss = 1.7028  \n",
      "\n",
      "Fold: 29  Epoch: 39  Training loss = 2.4212  Validation loss = 1.7143  \n",
      "\n",
      "Check model:  Fold: 29  Optimal epoch: 33  \n",
      "\n",
      "Fold: 30  Epoch: 1  Training loss = 2.4303  Validation loss = 0.5934  \n",
      "\n",
      "Fold: 30  Epoch: 2  Training loss = 2.4431  Validation loss = 0.6170  \n",
      "\n",
      "Fold: 30  Epoch: 3  Training loss = 2.4289  Validation loss = 0.5925  \n",
      "\n",
      "Fold: 30  Epoch: 4  Training loss = 2.4374  Validation loss = 0.6092  \n",
      "\n",
      "Fold: 30  Epoch: 5  Training loss = 2.4401  Validation loss = 0.6238  \n",
      "\n",
      "Fold: 30  Epoch: 6  Training loss = 2.4347  Validation loss = 0.6119  \n",
      "\n",
      "Fold: 30  Epoch: 7  Training loss = 2.4287  Validation loss = 0.6007  \n",
      "\n",
      "Fold: 30  Epoch: 8  Training loss = 2.4243  Validation loss = 0.5939  \n",
      "\n",
      "Fold: 30  Epoch: 9  Training loss = 2.4234  Validation loss = 0.5934  \n",
      "\n",
      "Fold: 30  Epoch: 10  Training loss = 2.4219  Validation loss = 0.5935  \n",
      "\n",
      "Fold: 30  Epoch: 11  Training loss = 2.4207  Validation loss = 0.5950  \n",
      "\n",
      "Fold: 30  Epoch: 12  Training loss = 2.4272  Validation loss = 0.5896  \n",
      "\n",
      "Fold: 30  Epoch: 13  Training loss = 2.4248  Validation loss = 0.6047  \n",
      "\n",
      "Fold: 30  Epoch: 14  Training loss = 2.4219  Validation loss = 0.5916  \n",
      "\n",
      "Fold: 30  Epoch: 15  Training loss = 2.4201  Validation loss = 0.6012  \n",
      "\n",
      "Fold: 30  Epoch: 16  Training loss = 2.4162  Validation loss = 0.5973  \n",
      "\n",
      "Fold: 30  Epoch: 17  Training loss = 2.4174  Validation loss = 0.5923  \n",
      "\n",
      "Fold: 30  Epoch: 18  Training loss = 2.4218  Validation loss = 0.6141  \n",
      "\n",
      "Check model:  Fold: 30  Optimal epoch: 12  \n",
      "\n",
      "Fold: 31  Epoch: 1  Training loss = 2.2693  Validation loss = 1.0633  \n",
      "\n",
      "Fold: 31  Epoch: 2  Training loss = 2.2680  Validation loss = 1.0934  \n",
      "\n",
      "Fold: 31  Epoch: 3  Training loss = 2.2593  Validation loss = 1.0017  \n",
      "\n",
      "Fold: 31  Epoch: 4  Training loss = 2.2567  Validation loss = 0.9757  \n",
      "\n",
      "Fold: 31  Epoch: 5  Training loss = 2.2512  Validation loss = 0.9436  \n",
      "\n",
      "Fold: 31  Epoch: 6  Training loss = 2.2510  Validation loss = 0.9444  \n",
      "\n",
      "Fold: 31  Epoch: 7  Training loss = 2.2497  Validation loss = 0.9391  \n",
      "\n",
      "Fold: 31  Epoch: 8  Training loss = 2.2452  Validation loss = 0.8882  \n",
      "\n",
      "Fold: 31  Epoch: 9  Training loss = 2.2446  Validation loss = 0.8974  \n",
      "\n",
      "Fold: 31  Epoch: 10  Training loss = 2.2468  Validation loss = 0.9378  \n",
      "\n",
      "Fold: 31  Epoch: 11  Training loss = 2.2485  Validation loss = 0.9532  \n",
      "\n",
      "Fold: 31  Epoch: 12  Training loss = 2.2464  Validation loss = 0.9499  \n",
      "\n",
      "Fold: 31  Epoch: 13  Training loss = 2.2409  Validation loss = 0.9125  \n",
      "\n",
      "Fold: 31  Epoch: 14  Training loss = 2.2498  Validation loss = 1.0144  \n",
      "\n",
      "Check model:  Fold: 31  Optimal epoch: 8  \n",
      "\n",
      "Fold: 32  Epoch: 1  Training loss = 1.8892  Validation loss = 2.7402  \n",
      "\n",
      "Fold: 32  Epoch: 2  Training loss = 1.8740  Validation loss = 2.4551  \n",
      "\n",
      "Fold: 32  Epoch: 3  Training loss = 1.8672  Validation loss = 2.3291  \n",
      "\n",
      "Fold: 32  Epoch: 4  Training loss = 1.8728  Validation loss = 2.2528  \n",
      "\n",
      "Fold: 32  Epoch: 5  Training loss = 1.8727  Validation loss = 2.2477  \n",
      "\n",
      "Fold: 32  Epoch: 6  Training loss = 1.8617  Validation loss = 2.3340  \n",
      "\n",
      "Fold: 32  Epoch: 7  Training loss = 1.8627  Validation loss = 2.3675  \n",
      "\n",
      "Fold: 32  Epoch: 8  Training loss = 1.8770  Validation loss = 2.6514  \n",
      "\n",
      "Fold: 32  Epoch: 9  Training loss = 1.8707  Validation loss = 2.5539  \n",
      "\n",
      "Fold: 32  Epoch: 10  Training loss = 1.8742  Validation loss = 2.6524  \n",
      "\n",
      "Fold: 32  Epoch: 11  Training loss = 1.8741  Validation loss = 2.6952  \n",
      "\n",
      "Check model:  Fold: 32  Optimal epoch: 5  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 2. Train model\n",
    "# ==================================\n",
    "sess = tf.InteractiveSession()  # Launch Graph\n",
    "sess.run(tf.global_variables_initializer())  # Initialise all variables\n",
    "\n",
    "print(\"Start training\", \n",
    "      \"\\nHyperparameters:\",\n",
    "      \"\\nDimension of recurrent unit =\", n_hidden,\n",
    "      \"\\nLearning rate =\", learning_rate,\n",
    "      \"\\nEpochs =\", epochs,\n",
    "      \"\\nBatch size =\", batch_size,\n",
    "      \"\\nEarly stopping epochs =\", early_stop_iters,\n",
    "      \"\\nLearning rate =\", learning_rate)\n",
    "\n",
    "total_batch = int(window_length / batch_size)\n",
    "validation_fold_error = [] # store validation error of each fold\n",
    "optimal_epochs = []\n",
    "\n",
    "# loop through folds\n",
    "for fold in range(1, len(valIndex)):\n",
    "    validx = train_features[valIndex[fold-1]:valIndex[fold]]\n",
    "    validy = train_target[valIndex[fold-1]:valIndex[fold]]\n",
    "    trainx = train_features[(fold-1)*4:valIndex[(fold-1)]]\n",
    "    trainy = train_target[(fold-1)*4:valIndex[(fold-1)]]\n",
    "\n",
    "    loss_list = [] # store validation loss after each epoch for early stopping\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i in range(total_batch):\n",
    "            # Backprop\n",
    "            batch_xs, batch_ys = next_batch(num=batch_size, data=trainx, labels=trainy)\n",
    "            optimizer.run(feed_dict={x:batch_xs, y:batch_ys, lr:learning_rate})\n",
    "\n",
    "        # Loss\n",
    "        loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "        loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "        loss_list.append(loss_valid)\n",
    "\n",
    "        print(\"Fold: {0:d}\".format(fold),\n",
    "              \" Epoch: {0:d}\".format(epoch+1),\n",
    "              \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "              \" Validation loss = {0:.4f}\".format(np.sqrt(loss_valid)),\n",
    "              \" \\n\")\n",
    "\n",
    "        if all(j <= loss_valid for j in loss_list[-early_stop_iters:]) and len(loss_list)>early_stop_iters:\n",
    "            break\n",
    "    \n",
    "    # Load model with lowest validation error for each fold\n",
    "    epoch_hat = np.argmin(loss_list) + 1\n",
    "    optimal_epochs.append(epoch_hat) # store optimal number of epochs for each fold\n",
    "    \n",
    "    # RMSE\n",
    "    loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "    loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "    validation_fold_error.append(np.sqrt(loss_valid))\n",
    "    \n",
    "    print(\"Check model:\",\n",
    "          \" Fold: {0:d}\".format(fold),\n",
    "          \" Optimal epoch: {0:d}\".format(epoch_hat),\n",
    "          \" \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average number of epochs: 224\n",
      "Average validation error: 2.87246\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 3. Optimal epoch choice\n",
    "# ==================================\n",
    "# Pick number of epochs to train model for out-of-sample testing\n",
    "epoch_hat = int(np.mean(optimal_epochs))\n",
    "print(\"\\nAverage number of epochs:\", epoch_hat)\n",
    "# Average validation error\n",
    "print(\"Average validation error:\", np.mean(validation_fold_error))\n",
    "\n",
    "# Save validated model\n",
    "saveModel(sess, \n",
    "          MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + str(epoch_hat) + \"_validated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fixed scheme:\n",
      "Epoch: 1  Training loss = 1.7323  Test loss = 2.8301  \n",
      "\n",
      "Epoch: 2  Training loss = 1.7277  Test loss = 2.8191  \n",
      "\n",
      "Epoch: 3  Training loss = 1.7234  Test loss = 2.8082  \n",
      "\n",
      "Epoch: 4  Training loss = 1.7195  Test loss = 2.7975  \n",
      "\n",
      "Epoch: 5  Training loss = 1.7158  Test loss = 2.7870  \n",
      "\n",
      "Epoch: 6  Training loss = 1.7123  Test loss = 2.7766  \n",
      "\n",
      "Epoch: 7  Training loss = 1.7089  Test loss = 2.7662  \n",
      "\n",
      "Epoch: 8  Training loss = 1.7056  Test loss = 2.7556  \n",
      "\n",
      "Epoch: 9  Training loss = 1.7022  Test loss = 2.7446  \n",
      "\n",
      "Epoch: 10  Training loss = 1.6986  Test loss = 2.7330  \n",
      "\n",
      "Epoch: 11  Training loss = 1.6949  Test loss = 2.7208  \n",
      "\n",
      "Epoch: 12  Training loss = 1.6911  Test loss = 2.7077  \n",
      "\n",
      "Epoch: 13  Training loss = 1.6874  Test loss = 2.6939  \n",
      "\n",
      "Epoch: 14  Training loss = 1.6839  Test loss = 2.6799  \n",
      "\n",
      "Epoch: 15  Training loss = 1.6810  Test loss = 2.6665  \n",
      "\n",
      "Epoch: 16  Training loss = 1.6787  Test loss = 2.6542  \n",
      "\n",
      "Epoch: 17  Training loss = 1.6770  Test loss = 2.6434  \n",
      "\n",
      "Epoch: 18  Training loss = 1.6756  Test loss = 2.6341  \n",
      "\n",
      "Epoch: 19  Training loss = 1.6746  Test loss = 2.6263  \n",
      "\n",
      "Epoch: 20  Training loss = 1.6738  Test loss = 2.6195  \n",
      "\n",
      "Epoch: 21  Training loss = 1.6731  Test loss = 2.6137  \n",
      "\n",
      "Epoch: 22  Training loss = 1.6726  Test loss = 2.6086  \n",
      "\n",
      "Epoch: 23  Training loss = 1.6721  Test loss = 2.6041  \n",
      "\n",
      "Epoch: 24  Training loss = 1.6717  Test loss = 2.6002  \n",
      "\n",
      "Epoch: 25  Training loss = 1.6713  Test loss = 2.5966  \n",
      "\n",
      "Epoch: 26  Training loss = 1.6709  Test loss = 2.5934  \n",
      "\n",
      "Epoch: 27  Training loss = 1.6706  Test loss = 2.5905  \n",
      "\n",
      "Epoch: 28  Training loss = 1.6703  Test loss = 2.5878  \n",
      "\n",
      "Epoch: 29  Training loss = 1.6700  Test loss = 2.5853  \n",
      "\n",
      "Epoch: 30  Training loss = 1.6697  Test loss = 2.5830  \n",
      "\n",
      "Epoch: 31  Training loss = 1.6694  Test loss = 2.5808  \n",
      "\n",
      "Epoch: 32  Training loss = 1.6691  Test loss = 2.5788  \n",
      "\n",
      "Epoch: 33  Training loss = 1.6689  Test loss = 2.5770  \n",
      "\n",
      "Epoch: 34  Training loss = 1.6686  Test loss = 2.5752  \n",
      "\n",
      "Epoch: 35  Training loss = 1.6684  Test loss = 2.5735  \n",
      "\n",
      "Epoch: 36  Training loss = 1.6681  Test loss = 2.5719  \n",
      "\n",
      "Epoch: 37  Training loss = 1.6679  Test loss = 2.5704  \n",
      "\n",
      "Epoch: 38  Training loss = 1.6677  Test loss = 2.5690  \n",
      "\n",
      "Epoch: 39  Training loss = 1.6674  Test loss = 2.5676  \n",
      "\n",
      "Epoch: 40  Training loss = 1.6672  Test loss = 2.5663  \n",
      "\n",
      "Epoch: 41  Training loss = 1.6670  Test loss = 2.5651  \n",
      "\n",
      "Epoch: 42  Training loss = 1.6668  Test loss = 2.5639  \n",
      "\n",
      "Epoch: 43  Training loss = 1.6666  Test loss = 2.5627  \n",
      "\n",
      "Epoch: 44  Training loss = 1.6663  Test loss = 2.5616  \n",
      "\n",
      "Epoch: 45  Training loss = 1.6661  Test loss = 2.5606  \n",
      "\n",
      "Epoch: 46  Training loss = 1.6659  Test loss = 2.5595  \n",
      "\n",
      "Epoch: 47  Training loss = 1.6657  Test loss = 2.5585  \n",
      "\n",
      "Epoch: 48  Training loss = 1.6655  Test loss = 2.5576  \n",
      "\n",
      "Epoch: 49  Training loss = 1.6653  Test loss = 2.5567  \n",
      "\n",
      "Epoch: 50  Training loss = 1.6651  Test loss = 2.5558  \n",
      "\n",
      "Epoch: 51  Training loss = 1.6649  Test loss = 2.5549  \n",
      "\n",
      "Epoch: 52  Training loss = 1.6647  Test loss = 2.5541  \n",
      "\n",
      "Epoch: 53  Training loss = 1.6645  Test loss = 2.5533  \n",
      "\n",
      "Epoch: 54  Training loss = 1.6643  Test loss = 2.5525  \n",
      "\n",
      "Epoch: 55  Training loss = 1.6641  Test loss = 2.5517  \n",
      "\n",
      "Epoch: 56  Training loss = 1.6639  Test loss = 2.5509  \n",
      "\n",
      "Epoch: 57  Training loss = 1.6637  Test loss = 2.5502  \n",
      "\n",
      "Epoch: 58  Training loss = 1.6635  Test loss = 2.5495  \n",
      "\n",
      "Epoch: 59  Training loss = 1.6633  Test loss = 2.5488  \n",
      "\n",
      "Epoch: 60  Training loss = 1.6631  Test loss = 2.5482  \n",
      "\n",
      "Epoch: 61  Training loss = 1.6629  Test loss = 2.5475  \n",
      "\n",
      "Epoch: 62  Training loss = 1.6627  Test loss = 2.5469  \n",
      "\n",
      "Epoch: 63  Training loss = 1.6625  Test loss = 2.5463  \n",
      "\n",
      "Epoch: 64  Training loss = 1.6624  Test loss = 2.5457  \n",
      "\n",
      "Epoch: 65  Training loss = 1.6622  Test loss = 2.5451  \n",
      "\n",
      "Epoch: 66  Training loss = 1.6620  Test loss = 2.5445  \n",
      "\n",
      "Epoch: 67  Training loss = 1.6618  Test loss = 2.5439  \n",
      "\n",
      "Epoch: 68  Training loss = 1.6616  Test loss = 2.5434  \n",
      "\n",
      "Epoch: 69  Training loss = 1.6614  Test loss = 2.5429  \n",
      "\n",
      "Epoch: 70  Training loss = 1.6612  Test loss = 2.5423  \n",
      "\n",
      "Epoch: 71  Training loss = 1.6610  Test loss = 2.5418  \n",
      "\n",
      "Epoch: 72  Training loss = 1.6609  Test loss = 2.5413  \n",
      "\n",
      "Epoch: 73  Training loss = 1.6607  Test loss = 2.5408  \n",
      "\n",
      "Epoch: 74  Training loss = 1.6605  Test loss = 2.5404  \n",
      "\n",
      "Epoch: 75  Training loss = 1.6603  Test loss = 2.5399  \n",
      "\n",
      "Epoch: 76  Training loss = 1.6601  Test loss = 2.5395  \n",
      "\n",
      "Epoch: 77  Training loss = 1.6599  Test loss = 2.5390  \n",
      "\n",
      "Epoch: 78  Training loss = 1.6598  Test loss = 2.5386  \n",
      "\n",
      "Epoch: 79  Training loss = 1.6596  Test loss = 2.5381  \n",
      "\n",
      "Epoch: 80  Training loss = 1.6594  Test loss = 2.5377  \n",
      "\n",
      "Epoch: 81  Training loss = 1.6592  Test loss = 2.5373  \n",
      "\n",
      "Epoch: 82  Training loss = 1.6590  Test loss = 2.5369  \n",
      "\n",
      "Epoch: 83  Training loss = 1.6589  Test loss = 2.5365  \n",
      "\n",
      "Epoch: 84  Training loss = 1.6587  Test loss = 2.5362  \n",
      "\n",
      "Epoch: 85  Training loss = 1.6585  Test loss = 2.5358  \n",
      "\n",
      "Epoch: 86  Training loss = 1.6583  Test loss = 2.5354  \n",
      "\n",
      "Epoch: 87  Training loss = 1.6582  Test loss = 2.5351  \n",
      "\n",
      "Epoch: 88  Training loss = 1.6580  Test loss = 2.5347  \n",
      "\n",
      "Epoch: 89  Training loss = 1.6578  Test loss = 2.5344  \n",
      "\n",
      "Epoch: 90  Training loss = 1.6576  Test loss = 2.5340  \n",
      "\n",
      "Epoch: 91  Training loss = 1.6575  Test loss = 2.5337  \n",
      "\n",
      "Epoch: 92  Training loss = 1.6573  Test loss = 2.5334  \n",
      "\n",
      "Epoch: 93  Training loss = 1.6571  Test loss = 2.5331  \n",
      "\n",
      "Epoch: 94  Training loss = 1.6569  Test loss = 2.5328  \n",
      "\n",
      "Epoch: 95  Training loss = 1.6568  Test loss = 2.5325  \n",
      "\n",
      "Epoch: 96  Training loss = 1.6566  Test loss = 2.5322  \n",
      "\n",
      "Epoch: 97  Training loss = 1.6564  Test loss = 2.5319  \n",
      "\n",
      "Epoch: 98  Training loss = 1.6563  Test loss = 2.5316  \n",
      "\n",
      "Epoch: 99  Training loss = 1.6561  Test loss = 2.5313  \n",
      "\n",
      "Epoch: 100  Training loss = 1.6559  Test loss = 2.5311  \n",
      "\n",
      "Epoch: 101  Training loss = 1.6557  Test loss = 2.5308  \n",
      "\n",
      "Epoch: 102  Training loss = 1.6556  Test loss = 2.5305  \n",
      "\n",
      "Epoch: 103  Training loss = 1.6554  Test loss = 2.5303  \n",
      "\n",
      "Epoch: 104  Training loss = 1.6552  Test loss = 2.5300  \n",
      "\n",
      "Epoch: 105  Training loss = 1.6551  Test loss = 2.5298  \n",
      "\n",
      "Epoch: 106  Training loss = 1.6549  Test loss = 2.5295  \n",
      "\n",
      "Epoch: 107  Training loss = 1.6547  Test loss = 2.5293  \n",
      "\n",
      "Epoch: 108  Training loss = 1.6546  Test loss = 2.5291  \n",
      "\n",
      "Epoch: 109  Training loss = 1.6544  Test loss = 2.5288  \n",
      "\n",
      "Epoch: 110  Training loss = 1.6542  Test loss = 2.5286  \n",
      "\n",
      "Epoch: 111  Training loss = 1.6541  Test loss = 2.5284  \n",
      "\n",
      "Epoch: 112  Training loss = 1.6539  Test loss = 2.5282  \n",
      "\n",
      "Epoch: 113  Training loss = 1.6537  Test loss = 2.5279  \n",
      "\n",
      "Epoch: 114  Training loss = 1.6536  Test loss = 2.5277  \n",
      "\n",
      "Epoch: 115  Training loss = 1.6534  Test loss = 2.5275  \n",
      "\n",
      "Epoch: 116  Training loss = 1.6532  Test loss = 2.5273  \n",
      "\n",
      "Epoch: 117  Training loss = 1.6531  Test loss = 2.5271  \n",
      "\n",
      "Epoch: 118  Training loss = 1.6529  Test loss = 2.5269  \n",
      "\n",
      "Epoch: 119  Training loss = 1.6527  Test loss = 2.5267  \n",
      "\n",
      "Epoch: 120  Training loss = 1.6526  Test loss = 2.5265  \n",
      "\n",
      "Epoch: 121  Training loss = 1.6524  Test loss = 2.5263  \n",
      "\n",
      "Epoch: 122  Training loss = 1.6523  Test loss = 2.5262  \n",
      "\n",
      "Epoch: 123  Training loss = 1.6521  Test loss = 2.5260  \n",
      "\n",
      "Epoch: 124  Training loss = 1.6519  Test loss = 2.5258  \n",
      "\n",
      "Epoch: 125  Training loss = 1.6518  Test loss = 2.5256  \n",
      "\n",
      "Epoch: 126  Training loss = 1.6516  Test loss = 2.5254  \n",
      "\n",
      "Epoch: 127  Training loss = 1.6514  Test loss = 2.5253  \n",
      "\n",
      "Epoch: 128  Training loss = 1.6513  Test loss = 2.5251  \n",
      "\n",
      "Epoch: 129  Training loss = 1.6511  Test loss = 2.5249  \n",
      "\n",
      "Epoch: 130  Training loss = 1.6510  Test loss = 2.5248  \n",
      "\n",
      "Epoch: 131  Training loss = 1.6508  Test loss = 2.5246  \n",
      "\n",
      "Epoch: 132  Training loss = 1.6507  Test loss = 2.5244  \n",
      "\n",
      "Epoch: 133  Training loss = 1.6505  Test loss = 2.5243  \n",
      "\n",
      "Epoch: 134  Training loss = 1.6503  Test loss = 2.5241  \n",
      "\n",
      "Epoch: 135  Training loss = 1.6502  Test loss = 2.5239  \n",
      "\n",
      "Epoch: 136  Training loss = 1.6500  Test loss = 2.5238  \n",
      "\n",
      "Epoch: 137  Training loss = 1.6499  Test loss = 2.5236  \n",
      "\n",
      "Epoch: 138  Training loss = 1.6497  Test loss = 2.5235  \n",
      "\n",
      "Epoch: 139  Training loss = 1.6496  Test loss = 2.5233  \n",
      "\n",
      "Epoch: 140  Training loss = 1.6494  Test loss = 2.5232  \n",
      "\n",
      "Epoch: 141  Training loss = 1.6492  Test loss = 2.5230  \n",
      "\n",
      "Epoch: 142  Training loss = 1.6491  Test loss = 2.5229  \n",
      "\n",
      "Epoch: 143  Training loss = 1.6489  Test loss = 2.5227  \n",
      "\n",
      "Epoch: 144  Training loss = 1.6488  Test loss = 2.5226  \n",
      "\n",
      "Epoch: 145  Training loss = 1.6486  Test loss = 2.5224  \n",
      "\n",
      "Epoch: 146  Training loss = 1.6485  Test loss = 2.5223  \n",
      "\n",
      "Epoch: 147  Training loss = 1.6483  Test loss = 2.5221  \n",
      "\n",
      "Epoch: 148  Training loss = 1.6482  Test loss = 2.5220  \n",
      "\n",
      "Epoch: 149  Training loss = 1.6480  Test loss = 2.5218  \n",
      "\n",
      "Epoch: 150  Training loss = 1.6479  Test loss = 2.5217  \n",
      "\n",
      "Epoch: 151  Training loss = 1.6477  Test loss = 2.5216  \n",
      "\n",
      "Epoch: 152  Training loss = 1.6476  Test loss = 2.5214  \n",
      "\n",
      "Epoch: 153  Training loss = 1.6474  Test loss = 2.5213  \n",
      "\n",
      "Epoch: 154  Training loss = 1.6473  Test loss = 2.5211  \n",
      "\n",
      "Epoch: 155  Training loss = 1.6471  Test loss = 2.5210  \n",
      "\n",
      "Epoch: 156  Training loss = 1.6470  Test loss = 2.5208  \n",
      "\n",
      "Epoch: 157  Training loss = 1.6468  Test loss = 2.5207  \n",
      "\n",
      "Epoch: 158  Training loss = 1.6467  Test loss = 2.5206  \n",
      "\n",
      "Epoch: 159  Training loss = 1.6465  Test loss = 2.5204  \n",
      "\n",
      "Epoch: 160  Training loss = 1.6464  Test loss = 2.5203  \n",
      "\n",
      "Epoch: 161  Training loss = 1.6462  Test loss = 2.5201  \n",
      "\n",
      "Epoch: 162  Training loss = 1.6461  Test loss = 2.5200  \n",
      "\n",
      "Epoch: 163  Training loss = 1.6459  Test loss = 2.5199  \n",
      "\n",
      "Epoch: 164  Training loss = 1.6458  Test loss = 2.5197  \n",
      "\n",
      "Epoch: 165  Training loss = 1.6456  Test loss = 2.5196  \n",
      "\n",
      "Epoch: 166  Training loss = 1.6455  Test loss = 2.5195  \n",
      "\n",
      "Epoch: 167  Training loss = 1.6454  Test loss = 2.5193  \n",
      "\n",
      "Epoch: 168  Training loss = 1.6452  Test loss = 2.5192  \n",
      "\n",
      "Epoch: 169  Training loss = 1.6451  Test loss = 2.5190  \n",
      "\n",
      "Epoch: 170  Training loss = 1.6449  Test loss = 2.5189  \n",
      "\n",
      "Epoch: 171  Training loss = 1.6448  Test loss = 2.5188  \n",
      "\n",
      "Epoch: 172  Training loss = 1.6446  Test loss = 2.5186  \n",
      "\n",
      "Epoch: 173  Training loss = 1.6445  Test loss = 2.5185  \n",
      "\n",
      "Epoch: 174  Training loss = 1.6444  Test loss = 2.5183  \n",
      "\n",
      "Epoch: 175  Training loss = 1.6442  Test loss = 2.5182  \n",
      "\n",
      "Epoch: 176  Training loss = 1.6441  Test loss = 2.5181  \n",
      "\n",
      "Epoch: 177  Training loss = 1.6439  Test loss = 2.5179  \n",
      "\n",
      "Epoch: 178  Training loss = 1.6438  Test loss = 2.5178  \n",
      "\n",
      "Epoch: 179  Training loss = 1.6437  Test loss = 2.5177  \n",
      "\n",
      "Epoch: 180  Training loss = 1.6435  Test loss = 2.5175  \n",
      "\n",
      "Epoch: 181  Training loss = 1.6434  Test loss = 2.5174  \n",
      "\n",
      "Epoch: 182  Training loss = 1.6432  Test loss = 2.5173  \n",
      "\n",
      "Epoch: 183  Training loss = 1.6431  Test loss = 2.5171  \n",
      "\n",
      "Epoch: 184  Training loss = 1.6430  Test loss = 2.5170  \n",
      "\n",
      "Epoch: 185  Training loss = 1.6428  Test loss = 2.5168  \n",
      "\n",
      "Epoch: 186  Training loss = 1.6427  Test loss = 2.5167  \n",
      "\n",
      "Epoch: 187  Training loss = 1.6426  Test loss = 2.5166  \n",
      "\n",
      "Epoch: 188  Training loss = 1.6424  Test loss = 2.5164  \n",
      "\n",
      "Epoch: 189  Training loss = 1.6423  Test loss = 2.5163  \n",
      "\n",
      "Epoch: 190  Training loss = 1.6422  Test loss = 2.5162  \n",
      "\n",
      "Epoch: 191  Training loss = 1.6420  Test loss = 2.5160  \n",
      "\n",
      "Epoch: 192  Training loss = 1.6419  Test loss = 2.5159  \n",
      "\n",
      "Epoch: 193  Training loss = 1.6418  Test loss = 2.5157  \n",
      "\n",
      "Epoch: 194  Training loss = 1.6416  Test loss = 2.5156  \n",
      "\n",
      "Epoch: 195  Training loss = 1.6415  Test loss = 2.5155  \n",
      "\n",
      "Epoch: 196  Training loss = 1.6414  Test loss = 2.5153  \n",
      "\n",
      "Epoch: 197  Training loss = 1.6412  Test loss = 2.5152  \n",
      "\n",
      "Epoch: 198  Training loss = 1.6411  Test loss = 2.5151  \n",
      "\n",
      "Epoch: 199  Training loss = 1.6410  Test loss = 2.5149  \n",
      "\n",
      "Epoch: 200  Training loss = 1.6408  Test loss = 2.5148  \n",
      "\n",
      "Epoch: 201  Training loss = 1.6407  Test loss = 2.5147  \n",
      "\n",
      "Epoch: 202  Training loss = 1.6406  Test loss = 2.5145  \n",
      "\n",
      "Epoch: 203  Training loss = 1.6404  Test loss = 2.5144  \n",
      "\n",
      "Epoch: 204  Training loss = 1.6403  Test loss = 2.5143  \n",
      "\n",
      "Epoch: 205  Training loss = 1.6402  Test loss = 2.5141  \n",
      "\n",
      "Epoch: 206  Training loss = 1.6401  Test loss = 2.5140  \n",
      "\n",
      "Epoch: 207  Training loss = 1.6399  Test loss = 2.5138  \n",
      "\n",
      "Epoch: 208  Training loss = 1.6398  Test loss = 2.5137  \n",
      "\n",
      "Epoch: 209  Training loss = 1.6397  Test loss = 2.5136  \n",
      "\n",
      "Epoch: 210  Training loss = 1.6395  Test loss = 2.5134  \n",
      "\n",
      "Epoch: 211  Training loss = 1.6394  Test loss = 2.5133  \n",
      "\n",
      "Epoch: 212  Training loss = 1.6393  Test loss = 2.5132  \n",
      "\n",
      "Epoch: 213  Training loss = 1.6392  Test loss = 2.5130  \n",
      "\n",
      "Epoch: 214  Training loss = 1.6390  Test loss = 2.5129  \n",
      "\n",
      "Epoch: 215  Training loss = 1.6389  Test loss = 2.5128  \n",
      "\n",
      "Epoch: 216  Training loss = 1.6388  Test loss = 2.5126  \n",
      "\n",
      "Epoch: 217  Training loss = 1.6387  Test loss = 2.5125  \n",
      "\n",
      "Epoch: 218  Training loss = 1.6385  Test loss = 2.5124  \n",
      "\n",
      "Epoch: 219  Training loss = 1.6384  Test loss = 2.5123  \n",
      "\n",
      "Epoch: 220  Training loss = 1.6383  Test loss = 2.5121  \n",
      "\n",
      "Epoch: 221  Training loss = 1.6382  Test loss = 2.5120  \n",
      "\n",
      "Epoch: 222  Training loss = 1.6381  Test loss = 2.5119  \n",
      "\n",
      "Epoch: 223  Training loss = 1.6379  Test loss = 2.5117  \n",
      "\n",
      "Epoch: 224  Training loss = 1.6378  Test loss = 2.5116  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 4. Fixed scheme\n",
    "# ==================================\n",
    "print(\"\\nFixed scheme:\")\n",
    "for epoch in range(epoch_hat):\n",
    "    x_train = train_features[-window_length:]\n",
    "    y_train = train_target[-window_length:]\n",
    "    optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:test_features, y:test_target})\n",
    "    print(\"Epoch: {0:d}\".format(epoch+1),\n",
    "          \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "          \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "          \" \\n\")\n",
    "\n",
    "# Forecasts\n",
    "yhat_test_fixed = pred.eval(feed_dict={x:test_features})\n",
    "yhat_train_fixed = pred.eval(feed_dict={x:x_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc204860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train set\n",
    "plt.plot(y_train, 'black')\n",
    "plt.plot(yhat_train_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xca12c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: fixed scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_test_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed scheme RMSE: 2.51159687787 \n",
      "Fixed scheme MAE:  1.70187037474\n"
     ]
    }
   ],
   "source": [
    "rmse_fixed = np.sqrt(np.mean((yhat_test_fixed[:,0]-test_target)**2))\n",
    "mae_fixed = np.mean(np.abs((yhat_test_fixed[:,0]-test_target)))\n",
    "print(\"Fixed scheme RMSE:\", rmse_fixed,\n",
    "     \"\\nFixed scheme MAE: \", mae_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Stack training and test set, this makes updating scheme easier to train\n",
    "all_features = np.concatenate((train_features[-window_length:], test_features), axis=0)\n",
    "all_target = np.concatenate((train_target[-window_length:], test_target), axis=0)\n",
    "\n",
    "# Vectors to store loss and forecasts\n",
    "test_loss = np.zeros(len(test_target))\n",
    "yhat_update = np.zeros(len(test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test period = 1  Training loss = 1.6378  Test loss = 3.1596  Model updated 0 times  \n",
      "\n",
      "Test period = 2  Training loss = 1.6829  Test loss = 2.6344  Model updated 0 times  \n",
      "\n",
      "Test period = 3  Training loss = 1.6993  Test loss = 1.0280  Model updated 0 times  \n",
      "\n",
      "Test period = 4  Training loss = 1.6848  Test loss = 0.4683  Model updated 0 times  \n",
      "\n",
      "Test period = 5  Training loss = 1.4852  Test loss = 1.0146  Model updated 1 times  \n",
      "\n",
      "Test period = 6  Training loss = 1.4121  Test loss = 0.2369  Model updated 1 times  \n",
      "\n",
      "Test period = 7  Training loss = 1.3578  Test loss = 0.3868  Model updated 1 times  \n",
      "\n",
      "Test period = 8  Training loss = 1.3520  Test loss = 1.1913  Model updated 1 times  \n",
      "\n",
      "Test period = 9  Training loss = 1.3293  Test loss = 1.8054  Model updated 2 times  \n",
      "\n",
      "Test period = 10  Training loss = 1.3402  Test loss = 0.2383  Model updated 2 times  \n",
      "\n",
      "Test period = 11  Training loss = 1.3174  Test loss = 0.6792  Model updated 2 times  \n",
      "\n",
      "Test period = 12  Training loss = 1.3200  Test loss = 1.3516  Model updated 2 times  \n",
      "\n",
      "Test period = 13  Training loss = 1.3047  Test loss = 0.0454  Model updated 3 times  \n",
      "\n",
      "Test period = 14  Training loss = 1.3040  Test loss = 1.8341  Model updated 3 times  \n",
      "\n",
      "Test period = 15  Training loss = 1.3212  Test loss = 3.5269  Model updated 3 times  \n",
      "\n",
      "Test period = 16  Training loss = 1.3914  Test loss = 5.5115  Model updated 3 times  \n",
      "\n",
      "Test period = 17  Training loss = 1.4993  Test loss = 2.8864  Model updated 4 times  \n",
      "\n",
      "Test period = 18  Training loss = 1.5399  Test loss = 0.1148  Model updated 4 times  \n",
      "\n",
      "Test period = 19  Training loss = 1.5373  Test loss = 0.6717  Model updated 4 times  \n",
      "\n",
      "Test period = 20  Training loss = 1.4535  Test loss = 0.4859  Model updated 4 times  \n",
      "\n",
      "Test period = 21  Training loss = 1.3885  Test loss = 1.6186  Model updated 5 times  \n",
      "\n",
      "Test period = 22  Training loss = 1.3993  Test loss = 3.6278  Model updated 5 times  \n",
      "\n",
      "Test period = 23  Training loss = 1.4654  Test loss = 0.0990  Model updated 5 times  \n",
      "\n",
      "Test period = 24  Training loss = 1.4552  Test loss = 1.0101  Model updated 5 times  \n",
      "\n",
      "Test period = 25  Training loss = 1.4265  Test loss = 0.6265  Model updated 6 times  \n",
      "\n",
      "Test period = 26  Training loss = 1.4278  Test loss = 0.5228  Model updated 6 times  \n",
      "\n",
      "Test period = 27  Training loss = 1.4292  Test loss = 0.4470  Model updated 6 times  \n",
      "\n",
      "Test period = 28  Training loss = 1.4177  Test loss = 1.5920  Model updated 6 times  \n",
      "\n",
      "Test period = 29  Training loss = 1.3731  Test loss = 0.8941  Model updated 7 times  \n",
      "\n",
      "Test period = 30  Training loss = 1.3671  Test loss = 0.0622  Model updated 7 times  \n",
      "\n",
      "Test period = 31  Training loss = 1.3589  Test loss = 3.9681  Model updated 7 times  \n",
      "\n",
      "Test period = 32  Training loss = 1.3934  Test loss = 1.4645  Model updated 7 times  \n",
      "\n",
      "Test period = 33  Training loss = 1.3680  Test loss = 0.2615  Model updated 8 times  \n",
      "\n",
      "Test period = 34  Training loss = 1.3610  Test loss = 1.2286  Model updated 8 times  \n",
      "\n",
      "Test period = 35  Training loss = 1.3152  Test loss = 1.2283  Model updated 8 times  \n",
      "\n",
      "Test period = 36  Training loss = 1.3223  Test loss = 3.8535  Model updated 8 times  \n",
      "\n",
      "Test period = 37  Training loss = 1.3024  Test loss = 1.3981  Model updated 9 times  \n",
      "\n",
      "Test period = 38  Training loss = 1.2485  Test loss = 1.4045  Model updated 9 times  \n",
      "\n",
      "Test period = 39  Training loss = 1.2606  Test loss = 0.1244  Model updated 9 times  \n",
      "\n",
      "Test period = 40  Training loss = 1.2595  Test loss = 2.2527  Model updated 9 times  \n",
      "\n",
      "Test period = 41  Training loss = 1.2554  Test loss = 1.5067  Model updated 10 times  \n",
      "\n",
      "Test period = 42  Training loss = 1.2688  Test loss = 1.8977  Model updated 10 times  \n",
      "\n",
      "Test period = 43  Training loss = 1.2902  Test loss = 3.7591  Model updated 10 times  \n",
      "\n",
      "Test period = 44  Training loss = 1.3716  Test loss = 11.8163  Model updated 10 times  \n",
      "\n",
      "Test period = 45  Training loss = 1.9968  Test loss = 5.5695  Model updated 11 times  \n",
      "\n",
      "Test period = 46  Training loss = 2.1122  Test loss = 0.8317  Model updated 11 times  \n",
      "\n",
      "Test period = 47  Training loss = 2.1134  Test loss = 0.2634  Model updated 11 times  \n",
      "\n",
      "Test period = 48  Training loss = 2.1133  Test loss = 0.0903  Model updated 11 times  \n",
      "\n",
      "Test period = 49  Training loss = 2.0388  Test loss = 2.0211  Model updated 12 times  \n",
      "\n",
      "Test period = 50  Training loss = 2.0521  Test loss = 3.3221  Model updated 12 times  \n",
      "\n",
      "Test period = 51  Training loss = 2.0924  Test loss = 0.9429  Model updated 12 times  \n",
      "\n",
      "Test period = 52  Training loss = 2.0955  Test loss = 0.7333  Model updated 12 times  \n",
      "\n",
      "Test period = 53  Training loss = 2.0513  Test loss = 2.1726  Model updated 13 times  \n",
      "\n",
      "Test period = 54  Training loss = 2.0690  Test loss = 2.1257  Model updated 13 times  \n",
      "\n",
      "Test period = 55  Training loss = 2.0852  Test loss = 0.8481  Model updated 13 times  \n",
      "\n",
      "Test period = 56  Training loss = 2.0865  Test loss = 0.7194  Model updated 13 times  \n",
      "\n",
      "Test period = 57  Training loss = 2.0245  Test loss = 0.7833  Model updated 14 times  \n",
      "\n",
      "Test period = 58  Training loss = 2.0269  Test loss = 0.7729  Model updated 14 times  \n",
      "\n",
      "Test period = 59  Training loss = 2.0284  Test loss = 0.6535  Model updated 14 times  \n",
      "\n",
      "Test period = 60  Training loss = 2.0290  Test loss = 0.0806  Model updated 14 times  \n",
      "\n",
      "Test period = 61  Training loss = 1.9996  Test loss = 1.1971  Model updated 15 times  \n",
      "\n",
      "Test period = 62  Training loss = 2.0017  Test loss = 3.0901  Model updated 15 times  \n",
      "\n",
      "Test period = 63  Training loss = 2.0375  Test loss = 0.2139  Model updated 15 times  \n",
      "\n",
      "Test period = 64  Training loss = 2.0340  Test loss = 1.1468  Model updated 15 times  \n",
      "\n",
      "Test period = 65  Training loss = 2.0138  Test loss = 0.2786  Model updated 16 times  \n",
      "\n",
      "Test period = 66  Training loss = 2.0131  Test loss = 0.0469  Model updated 16 times  \n",
      "\n",
      "Test period = 67  Training loss = 2.0049  Test loss = 0.0250  Model updated 16 times  \n",
      "\n",
      "Test period = 68  Training loss = 2.0016  Test loss = 2.8449  Model updated 16 times  \n",
      "\n",
      "Test period = 69  Training loss = 2.0174  Test loss = 3.5713  Model updated 17 times  \n",
      "\n",
      "Test period = 70  Training loss = 2.0638  Test loss = 0.4132  Model updated 17 times  \n",
      "\n",
      "Test period = 71  Training loss = 2.0607  Test loss = 0.6546  Model updated 17 times  \n",
      "\n",
      "Test period = 72  Training loss = 2.0609  Test loss = 1.8587  Model updated 17 times  \n",
      "\n",
      "Test period = 73  Training loss = 2.0538  Test loss = 2.3942  Model updated 18 times  \n",
      "\n",
      "Test period = 74  Training loss = 2.0736  Test loss = 0.3167  Model updated 18 times  \n",
      "\n",
      "Test period = 75  Training loss = 2.0646  Test loss = 0.2651  Model updated 18 times  \n",
      "\n",
      "Test period = 76  Training loss = 2.0605  Test loss = 1.1125  Model updated 18 times  \n",
      "\n",
      "Test period = 77  Training loss = 2.0246  Test loss = 0.7218  Model updated 19 times  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "retrain_count = 0\n",
    "for t in range(len(test_target)):\n",
    "    x_test = np.reshape(test_features[t], newshape=(1,4,3))\n",
    "    y_test = test_target[t]\n",
    "    test_loss[t] = np.sqrt(sess.run(loss, feed_dict={x:x_test, y:y_test}))\n",
    "    yhat_update[t] = pred.eval(feed_dict={x:x_test})\n",
    "\n",
    "    x_train = all_features[t:(window_length+t)]\n",
    "    y_train = all_target[t:(window_length+t)]\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:x_test, y:y_test})\n",
    "    \n",
    "    print(\"Test period = {0:d}\".format(t+1),\n",
    "      \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "      \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "      \" Model updated {0:d} times\".format(retrain_count),\n",
    "      \" \\n\")\n",
    "\n",
    "    if (t+1)%4==0:\n",
    "        retrain_count += 1\n",
    "        for epoch in range(epoch_hat):\n",
    "            for i in range(total_batch):\n",
    "                optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd2ab9b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: updating scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_update, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating scheme RMSE: 2.3148284842 \n",
      "Updating scheme MAE:  1.53268658115\n"
     ]
    }
   ],
   "source": [
    "rmse_update = np.sqrt(np.mean((yhat_update-test_target)**2))\n",
    "mae_update = np.mean(np.abs((yhat_update-test_target)))\n",
    "print(\"Updating scheme RMSE:\", rmse_update,\n",
    "     \"\\nUpdating scheme MAE: \", mae_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + \"yhat_test_fixed.csv\", yhat_test_fixed)\n",
    "np.savetxt(MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + \"yhat_update.csv\", yhat_update)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
