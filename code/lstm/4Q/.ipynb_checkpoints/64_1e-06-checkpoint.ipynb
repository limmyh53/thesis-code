{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Directories\n",
    "MODEL_FOLDER = \"../../../models/lstm/\"\n",
    "MODEL_FILENAME = MODEL_FOLDER + \"4Q/64_units/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: model saver\n",
    "def saveModel(sess, MODEL_FILENAME):\n",
    "    if not os.path.exists(MODEL_FOLDER):\n",
    "        print('Creating path where to save model: ' + MODEL_FOLDER)\n",
    "        os.mkdir(MODEL_FOLDER)\n",
    "\n",
    "    #print('Saving model at: ' + MODEL_FILENAME)\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, MODEL_FILENAME)\n",
    "    #print('Model successfully saved.\\n')\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: model loader\n",
    "def loadModel(sess, MODEL_FILENAME):\n",
    "    if os.path.exists(MODEL_FILENAME + \".index\"):\n",
    "        print('Loading save model from: ' + MODEL_FILENAME)\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, MODEL_FILENAME)\n",
    "        print('Model successfully loaded.\\n')\n",
    "        return True\n",
    "    else:\n",
    "        print('Model file <<' + MODEL_FILENAME + '>> does not exists!')\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Hyperparameters\n",
    "epochs = 500\n",
    "learning_rate = 1e-6\n",
    "batch_size = 5\n",
    "early_stop_iters = 10\n",
    "folds = 32\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 3  # data input\n",
    "n_steps = 4  # timesteps\n",
    "n_hidden = 64 # dimension of recurrent unit\n",
    "\n",
    "# (REPRODUCIBILITY) set random seeds\n",
    "tf.set_random_seed(123)\n",
    "\n",
    "# Define weights and biases\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.truncated_normal([n_hidden, 1], stddev = 1.0 / tf.sqrt(float(n_hidden))),\n",
    "        name='out_weight')\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.zeros([1]),\n",
    "        name='out_bias')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: Build model\n",
    "def RNN(X, weights, biases, n_hidden):\n",
    "\n",
    "    # Define a LSTM cell with tensorflow\n",
    "    lstm_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden, state_is_tuple=True)\n",
    "    outputs, _ = tf.nn.dynamic_rnn(lstm_cell, X, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    out_layer = tf.matmul(outputs[:,-1,:], weights['out']) + biases['out']\n",
    "\n",
    "    return out_layer\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: select batch\n",
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the data...\n",
      "Finished: data loaded. Stats below: \n",
      "Nr of training samples: 193\n",
      "Nr of testing  samples: 77\n",
      "Number of variables: 3\n",
      "Number of lags: 4\n",
      "Window length: 65\n",
      "Number of validation folds: 32\n"
     ]
    }
   ],
   "source": [
    "# =================================\n",
    "# 0. Load dataset\n",
    "# =================================\n",
    "print(\"Loading the data...\")\n",
    "# Training set pre-processing\n",
    "train = pd.read_csv('../../../Data/train.csv')\n",
    "train_4lag_inflation = np.array(train[['inflation.lag4',\n",
    "                                       'inflation.lag5',\n",
    "                                       'inflation.lag6',\n",
    "                                       'inflation.lag7']])\n",
    "train_4lag_unemp = np.array(train[['unemp.lag4',\n",
    "                                   'unemp.lag5',\n",
    "                                   'unemp.lag6',\n",
    "                                   'unemp.lag7']])\n",
    "train_4lag_oil = np.array(train[['oil.lag4',\n",
    "                                 'oil.lag5',\n",
    "                                 'oil.lag6',\n",
    "                                 'oil.lag7']])\n",
    "train_features = np.concatenate((train_4lag_inflation[:,:,np.newaxis], \n",
    "\t                             train_4lag_unemp[:,:,np.newaxis],\n",
    "\t                             train_4lag_oil[:,:,np.newaxis]),\n",
    "\t                             axis=2)\n",
    "train_target = np.array(train['inflation.target'])\n",
    "\n",
    "# Test set pre-processing\n",
    "test = pd.read_csv('../../../Data/test.csv')\n",
    "test_4lag_inflation = np.array(test[['inflation.lag4',\n",
    "                                     'inflation.lag5',\n",
    "                                     'inflation.lag6',\n",
    "                                     'inflation.lag7']])\n",
    "test_4lag_unemp = np.array(test[['unemp.lag4',\n",
    "                                 'unemp.lag5',\n",
    "                                 'unemp.lag6',\n",
    "                                 'unemp.lag7']])\n",
    "test_4lag_oil = np.array(test[['oil.lag4',\n",
    "                               'oil.lag5',\n",
    "                               'oil.lag6',\n",
    "                               'oil.lag7']])\n",
    "test_features = np.concatenate((test_4lag_inflation[:,:,np.newaxis], \n",
    "\t                            test_4lag_unemp[:,:,np.newaxis],\n",
    "\t                            test_4lag_oil[:,:,np.newaxis]),\n",
    "\t                            axis=2)\n",
    "test_target = np.array(test['inflation.target'])\n",
    "\n",
    "(nrTrainSamples, timesteps, variables) = train_features.shape\n",
    "(nrTestSamples, _, _) = test_features.shape\n",
    "\n",
    "# Window length and validation fold index\n",
    "window_length = 65\n",
    "valIndex = np.linspace(start=window_length, stop=nrTrainSamples, \n",
    "                       endpoint=True, num=folds+1, dtype=np.int)\n",
    "\n",
    "print(\"Finished: data loaded. Stats below: \")\n",
    "print(\"Nr of training samples: %d\" % nrTrainSamples)\n",
    "print(\"Nr of testing  samples: %d\" % nrTestSamples)\n",
    "print(\"Number of variables: %d\" % variables)\n",
    "print(\"Number of lags: %d\" % timesteps)\n",
    "print(\"Window length: %d\" % window_length)\n",
    "print(\"Number of validation folds: %d\" % folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 1. Build model\n",
    "# ==================================\n",
    "# tf graph input\n",
    "x = tf.placeholder(\"float\", [None, n_steps, n_input], name='Batch')\n",
    "y = tf.placeholder(\"float\", name='True_labels_of_batch')\n",
    "lr = tf.placeholder(\"float\", name='Learning_rate')\n",
    "\n",
    "# Make predictions with the model\n",
    "pred = RNN(x, weights, biases, n_hidden)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss = tf.reduce_mean(tf.diag_part(tf.square(tf.subtract(x=pred, y=y))))\n",
    "optimizer = tf.train.GradientDescentOptimizer(lr).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training \n",
      "Hyperparameters: \n",
      "Dimension of recurrent unit = 64 \n",
      "Learning rate = 1e-06 \n",
      "Epochs = 500 \n",
      "Batch size = 5 \n",
      "Early stopping epochs = 10 \n",
      "Learning rate = 1e-06\n",
      "Fold: 1  Epoch: 1  Training loss = 3.2845  Validation loss = 3.5100  \n",
      "\n",
      "Fold: 1  Epoch: 2  Training loss = 3.2842  Validation loss = 3.5096  \n",
      "\n",
      "Fold: 1  Epoch: 3  Training loss = 3.2839  Validation loss = 3.5091  \n",
      "\n",
      "Fold: 1  Epoch: 4  Training loss = 3.2836  Validation loss = 3.5087  \n",
      "\n",
      "Fold: 1  Epoch: 5  Training loss = 3.2834  Validation loss = 3.5082  \n",
      "\n",
      "Fold: 1  Epoch: 6  Training loss = 3.2830  Validation loss = 3.5076  \n",
      "\n",
      "Fold: 1  Epoch: 7  Training loss = 3.2827  Validation loss = 3.5071  \n",
      "\n",
      "Fold: 1  Epoch: 8  Training loss = 3.2825  Validation loss = 3.5067  \n",
      "\n",
      "Fold: 1  Epoch: 9  Training loss = 3.2821  Validation loss = 3.5061  \n",
      "\n",
      "Fold: 1  Epoch: 10  Training loss = 3.2819  Validation loss = 3.5058  \n",
      "\n",
      "Fold: 1  Epoch: 11  Training loss = 3.2816  Validation loss = 3.5053  \n",
      "\n",
      "Fold: 1  Epoch: 12  Training loss = 3.2813  Validation loss = 3.5048  \n",
      "\n",
      "Fold: 1  Epoch: 13  Training loss = 3.2810  Validation loss = 3.5042  \n",
      "\n",
      "Fold: 1  Epoch: 14  Training loss = 3.2807  Validation loss = 3.5037  \n",
      "\n",
      "Fold: 1  Epoch: 15  Training loss = 3.2804  Validation loss = 3.5033  \n",
      "\n",
      "Fold: 1  Epoch: 16  Training loss = 3.2803  Validation loss = 3.5030  \n",
      "\n",
      "Fold: 1  Epoch: 17  Training loss = 3.2800  Validation loss = 3.5026  \n",
      "\n",
      "Fold: 1  Epoch: 18  Training loss = 3.2798  Validation loss = 3.5023  \n",
      "\n",
      "Fold: 1  Epoch: 19  Training loss = 3.2796  Validation loss = 3.5018  \n",
      "\n",
      "Fold: 1  Epoch: 20  Training loss = 3.2793  Validation loss = 3.5013  \n",
      "\n",
      "Fold: 1  Epoch: 21  Training loss = 3.2790  Validation loss = 3.5009  \n",
      "\n",
      "Fold: 1  Epoch: 22  Training loss = 3.2787  Validation loss = 3.5003  \n",
      "\n",
      "Fold: 1  Epoch: 23  Training loss = 3.2784  Validation loss = 3.4999  \n",
      "\n",
      "Fold: 1  Epoch: 24  Training loss = 3.2782  Validation loss = 3.4995  \n",
      "\n",
      "Fold: 1  Epoch: 25  Training loss = 3.2779  Validation loss = 3.4991  \n",
      "\n",
      "Fold: 1  Epoch: 26  Training loss = 3.2777  Validation loss = 3.4987  \n",
      "\n",
      "Fold: 1  Epoch: 27  Training loss = 3.2775  Validation loss = 3.4983  \n",
      "\n",
      "Fold: 1  Epoch: 28  Training loss = 3.2772  Validation loss = 3.4979  \n",
      "\n",
      "Fold: 1  Epoch: 29  Training loss = 3.2770  Validation loss = 3.4975  \n",
      "\n",
      "Fold: 1  Epoch: 30  Training loss = 3.2767  Validation loss = 3.4970  \n",
      "\n",
      "Fold: 1  Epoch: 31  Training loss = 3.2764  Validation loss = 3.4965  \n",
      "\n",
      "Fold: 1  Epoch: 32  Training loss = 3.2762  Validation loss = 3.4961  \n",
      "\n",
      "Fold: 1  Epoch: 33  Training loss = 3.2760  Validation loss = 3.4957  \n",
      "\n",
      "Fold: 1  Epoch: 34  Training loss = 3.2757  Validation loss = 3.4952  \n",
      "\n",
      "Fold: 1  Epoch: 35  Training loss = 3.2754  Validation loss = 3.4947  \n",
      "\n",
      "Fold: 1  Epoch: 36  Training loss = 3.2752  Validation loss = 3.4944  \n",
      "\n",
      "Fold: 1  Epoch: 37  Training loss = 3.2749  Validation loss = 3.4939  \n",
      "\n",
      "Fold: 1  Epoch: 38  Training loss = 3.2747  Validation loss = 3.4935  \n",
      "\n",
      "Fold: 1  Epoch: 39  Training loss = 3.2743  Validation loss = 3.4929  \n",
      "\n",
      "Fold: 1  Epoch: 40  Training loss = 3.2741  Validation loss = 3.4925  \n",
      "\n",
      "Fold: 1  Epoch: 41  Training loss = 3.2738  Validation loss = 3.4920  \n",
      "\n",
      "Fold: 1  Epoch: 42  Training loss = 3.2735  Validation loss = 3.4916  \n",
      "\n",
      "Fold: 1  Epoch: 43  Training loss = 3.2733  Validation loss = 3.4912  \n",
      "\n",
      "Fold: 1  Epoch: 44  Training loss = 3.2730  Validation loss = 3.4907  \n",
      "\n",
      "Fold: 1  Epoch: 45  Training loss = 3.2727  Validation loss = 3.4903  \n",
      "\n",
      "Fold: 1  Epoch: 46  Training loss = 3.2725  Validation loss = 3.4899  \n",
      "\n",
      "Fold: 1  Epoch: 47  Training loss = 3.2723  Validation loss = 3.4895  \n",
      "\n",
      "Fold: 1  Epoch: 48  Training loss = 3.2719  Validation loss = 3.4889  \n",
      "\n",
      "Fold: 1  Epoch: 49  Training loss = 3.2717  Validation loss = 3.4885  \n",
      "\n",
      "Fold: 1  Epoch: 50  Training loss = 3.2714  Validation loss = 3.4880  \n",
      "\n",
      "Fold: 1  Epoch: 51  Training loss = 3.2712  Validation loss = 3.4876  \n",
      "\n",
      "Fold: 1  Epoch: 52  Training loss = 3.2709  Validation loss = 3.4871  \n",
      "\n",
      "Fold: 1  Epoch: 53  Training loss = 3.2706  Validation loss = 3.4866  \n",
      "\n",
      "Fold: 1  Epoch: 54  Training loss = 3.2703  Validation loss = 3.4861  \n",
      "\n",
      "Fold: 1  Epoch: 55  Training loss = 3.2700  Validation loss = 3.4855  \n",
      "\n",
      "Fold: 1  Epoch: 56  Training loss = 3.2697  Validation loss = 3.4850  \n",
      "\n",
      "Fold: 1  Epoch: 57  Training loss = 3.2694  Validation loss = 3.4846  \n",
      "\n",
      "Fold: 1  Epoch: 58  Training loss = 3.2692  Validation loss = 3.4842  \n",
      "\n",
      "Fold: 1  Epoch: 59  Training loss = 3.2689  Validation loss = 3.4837  \n",
      "\n",
      "Fold: 1  Epoch: 60  Training loss = 3.2686  Validation loss = 3.4832  \n",
      "\n",
      "Fold: 1  Epoch: 61  Training loss = 3.2683  Validation loss = 3.4828  \n",
      "\n",
      "Fold: 1  Epoch: 62  Training loss = 3.2681  Validation loss = 3.4824  \n",
      "\n",
      "Fold: 1  Epoch: 63  Training loss = 3.2679  Validation loss = 3.4820  \n",
      "\n",
      "Fold: 1  Epoch: 64  Training loss = 3.2677  Validation loss = 3.4816  \n",
      "\n",
      "Fold: 1  Epoch: 65  Training loss = 3.2674  Validation loss = 3.4812  \n",
      "\n",
      "Fold: 1  Epoch: 66  Training loss = 3.2671  Validation loss = 3.4807  \n",
      "\n",
      "Fold: 1  Epoch: 67  Training loss = 3.2668  Validation loss = 3.4802  \n",
      "\n",
      "Fold: 1  Epoch: 68  Training loss = 3.2666  Validation loss = 3.4798  \n",
      "\n",
      "Fold: 1  Epoch: 69  Training loss = 3.2664  Validation loss = 3.4795  \n",
      "\n",
      "Fold: 1  Epoch: 70  Training loss = 3.2661  Validation loss = 3.4790  \n",
      "\n",
      "Fold: 1  Epoch: 71  Training loss = 3.2659  Validation loss = 3.4785  \n",
      "\n",
      "Fold: 1  Epoch: 72  Training loss = 3.2656  Validation loss = 3.4781  \n",
      "\n",
      "Fold: 1  Epoch: 73  Training loss = 3.2653  Validation loss = 3.4776  \n",
      "\n",
      "Fold: 1  Epoch: 74  Training loss = 3.2650  Validation loss = 3.4770  \n",
      "\n",
      "Fold: 1  Epoch: 75  Training loss = 3.2647  Validation loss = 3.4765  \n",
      "\n",
      "Fold: 1  Epoch: 76  Training loss = 3.2644  Validation loss = 3.4761  \n",
      "\n",
      "Fold: 1  Epoch: 77  Training loss = 3.2642  Validation loss = 3.4757  \n",
      "\n",
      "Fold: 1  Epoch: 78  Training loss = 3.2639  Validation loss = 3.4753  \n",
      "\n",
      "Fold: 1  Epoch: 79  Training loss = 3.2637  Validation loss = 3.4749  \n",
      "\n",
      "Fold: 1  Epoch: 80  Training loss = 3.2635  Validation loss = 3.4744  \n",
      "\n",
      "Fold: 1  Epoch: 81  Training loss = 3.2632  Validation loss = 3.4740  \n",
      "\n",
      "Fold: 1  Epoch: 82  Training loss = 3.2630  Validation loss = 3.4736  \n",
      "\n",
      "Fold: 1  Epoch: 83  Training loss = 3.2627  Validation loss = 3.4732  \n",
      "\n",
      "Fold: 1  Epoch: 84  Training loss = 3.2625  Validation loss = 3.4729  \n",
      "\n",
      "Fold: 1  Epoch: 85  Training loss = 3.2623  Validation loss = 3.4725  \n",
      "\n",
      "Fold: 1  Epoch: 86  Training loss = 3.2621  Validation loss = 3.4721  \n",
      "\n",
      "Fold: 1  Epoch: 87  Training loss = 3.2618  Validation loss = 3.4716  \n",
      "\n",
      "Fold: 1  Epoch: 88  Training loss = 3.2615  Validation loss = 3.4711  \n",
      "\n",
      "Fold: 1  Epoch: 89  Training loss = 3.2613  Validation loss = 3.4707  \n",
      "\n",
      "Fold: 1  Epoch: 90  Training loss = 3.2610  Validation loss = 3.4702  \n",
      "\n",
      "Fold: 1  Epoch: 91  Training loss = 3.2607  Validation loss = 3.4698  \n",
      "\n",
      "Fold: 1  Epoch: 92  Training loss = 3.2606  Validation loss = 3.4695  \n",
      "\n",
      "Fold: 1  Epoch: 93  Training loss = 3.2603  Validation loss = 3.4691  \n",
      "\n",
      "Fold: 1  Epoch: 94  Training loss = 3.2601  Validation loss = 3.4686  \n",
      "\n",
      "Fold: 1  Epoch: 95  Training loss = 3.2599  Validation loss = 3.4682  \n",
      "\n",
      "Fold: 1  Epoch: 96  Training loss = 3.2597  Validation loss = 3.4679  \n",
      "\n",
      "Fold: 1  Epoch: 97  Training loss = 3.2594  Validation loss = 3.4675  \n",
      "\n",
      "Fold: 1  Epoch: 98  Training loss = 3.2592  Validation loss = 3.4671  \n",
      "\n",
      "Fold: 1  Epoch: 99  Training loss = 3.2590  Validation loss = 3.4667  \n",
      "\n",
      "Fold: 1  Epoch: 100  Training loss = 3.2586  Validation loss = 3.4661  \n",
      "\n",
      "Fold: 1  Epoch: 101  Training loss = 3.2584  Validation loss = 3.4657  \n",
      "\n",
      "Fold: 1  Epoch: 102  Training loss = 3.2582  Validation loss = 3.4653  \n",
      "\n",
      "Fold: 1  Epoch: 103  Training loss = 3.2579  Validation loss = 3.4648  \n",
      "\n",
      "Fold: 1  Epoch: 104  Training loss = 3.2576  Validation loss = 3.4644  \n",
      "\n",
      "Fold: 1  Epoch: 105  Training loss = 3.2574  Validation loss = 3.4640  \n",
      "\n",
      "Fold: 1  Epoch: 106  Training loss = 3.2571  Validation loss = 3.4635  \n",
      "\n",
      "Fold: 1  Epoch: 107  Training loss = 3.2569  Validation loss = 3.4632  \n",
      "\n",
      "Fold: 1  Epoch: 108  Training loss = 3.2568  Validation loss = 3.4629  \n",
      "\n",
      "Fold: 1  Epoch: 109  Training loss = 3.2566  Validation loss = 3.4625  \n",
      "\n",
      "Fold: 1  Epoch: 110  Training loss = 3.2563  Validation loss = 3.4621  \n",
      "\n",
      "Fold: 1  Epoch: 111  Training loss = 3.2561  Validation loss = 3.4617  \n",
      "\n",
      "Fold: 1  Epoch: 112  Training loss = 3.2559  Validation loss = 3.4614  \n",
      "\n",
      "Fold: 1  Epoch: 113  Training loss = 3.2556  Validation loss = 3.4609  \n",
      "\n",
      "Fold: 1  Epoch: 114  Training loss = 3.2554  Validation loss = 3.4605  \n",
      "\n",
      "Fold: 1  Epoch: 115  Training loss = 3.2552  Validation loss = 3.4601  \n",
      "\n",
      "Fold: 1  Epoch: 116  Training loss = 3.2550  Validation loss = 3.4598  \n",
      "\n",
      "Fold: 1  Epoch: 117  Training loss = 3.2547  Validation loss = 3.4594  \n",
      "\n",
      "Fold: 1  Epoch: 118  Training loss = 3.2545  Validation loss = 3.4591  \n",
      "\n",
      "Fold: 1  Epoch: 119  Training loss = 3.2543  Validation loss = 3.4586  \n",
      "\n",
      "Fold: 1  Epoch: 120  Training loss = 3.2540  Validation loss = 3.4581  \n",
      "\n",
      "Fold: 1  Epoch: 121  Training loss = 3.2538  Validation loss = 3.4577  \n",
      "\n",
      "Fold: 1  Epoch: 122  Training loss = 3.2535  Validation loss = 3.4572  \n",
      "\n",
      "Fold: 1  Epoch: 123  Training loss = 3.2532  Validation loss = 3.4567  \n",
      "\n",
      "Fold: 1  Epoch: 124  Training loss = 3.2530  Validation loss = 3.4563  \n",
      "\n",
      "Fold: 1  Epoch: 125  Training loss = 3.2528  Validation loss = 3.4559  \n",
      "\n",
      "Fold: 1  Epoch: 126  Training loss = 3.2525  Validation loss = 3.4555  \n",
      "\n",
      "Fold: 1  Epoch: 127  Training loss = 3.2523  Validation loss = 3.4552  \n",
      "\n",
      "Fold: 1  Epoch: 128  Training loss = 3.2522  Validation loss = 3.4548  \n",
      "\n",
      "Fold: 1  Epoch: 129  Training loss = 3.2520  Validation loss = 3.4545  \n",
      "\n",
      "Fold: 1  Epoch: 130  Training loss = 3.2518  Validation loss = 3.4542  \n",
      "\n",
      "Fold: 1  Epoch: 131  Training loss = 3.2515  Validation loss = 3.4537  \n",
      "\n",
      "Fold: 1  Epoch: 132  Training loss = 3.2512  Validation loss = 3.4532  \n",
      "\n",
      "Fold: 1  Epoch: 133  Training loss = 3.2510  Validation loss = 3.4528  \n",
      "\n",
      "Fold: 1  Epoch: 134  Training loss = 3.2508  Validation loss = 3.4524  \n",
      "\n",
      "Fold: 1  Epoch: 135  Training loss = 3.2505  Validation loss = 3.4519  \n",
      "\n",
      "Fold: 1  Epoch: 136  Training loss = 3.2501  Validation loss = 3.4513  \n",
      "\n",
      "Fold: 1  Epoch: 137  Training loss = 3.2499  Validation loss = 3.4510  \n",
      "\n",
      "Fold: 1  Epoch: 138  Training loss = 3.2497  Validation loss = 3.4507  \n",
      "\n",
      "Fold: 1  Epoch: 139  Training loss = 3.2495  Validation loss = 3.4502  \n",
      "\n",
      "Fold: 1  Epoch: 140  Training loss = 3.2491  Validation loss = 3.4497  \n",
      "\n",
      "Fold: 1  Epoch: 141  Training loss = 3.2489  Validation loss = 3.4492  \n",
      "\n",
      "Fold: 1  Epoch: 142  Training loss = 3.2487  Validation loss = 3.4489  \n",
      "\n",
      "Fold: 1  Epoch: 143  Training loss = 3.2485  Validation loss = 3.4485  \n",
      "\n",
      "Fold: 1  Epoch: 144  Training loss = 3.2483  Validation loss = 3.4481  \n",
      "\n",
      "Fold: 1  Epoch: 145  Training loss = 3.2480  Validation loss = 3.4476  \n",
      "\n",
      "Fold: 1  Epoch: 146  Training loss = 3.2478  Validation loss = 3.4473  \n",
      "\n",
      "Fold: 1  Epoch: 147  Training loss = 3.2476  Validation loss = 3.4469  \n",
      "\n",
      "Fold: 1  Epoch: 148  Training loss = 3.2473  Validation loss = 3.4464  \n",
      "\n",
      "Fold: 1  Epoch: 149  Training loss = 3.2471  Validation loss = 3.4461  \n",
      "\n",
      "Fold: 1  Epoch: 150  Training loss = 3.2469  Validation loss = 3.4457  \n",
      "\n",
      "Fold: 1  Epoch: 151  Training loss = 3.2467  Validation loss = 3.4454  \n",
      "\n",
      "Fold: 1  Epoch: 152  Training loss = 3.2465  Validation loss = 3.4450  \n",
      "\n",
      "Fold: 1  Epoch: 153  Training loss = 3.2462  Validation loss = 3.4445  \n",
      "\n",
      "Fold: 1  Epoch: 154  Training loss = 3.2459  Validation loss = 3.4440  \n",
      "\n",
      "Fold: 1  Epoch: 155  Training loss = 3.2458  Validation loss = 3.4438  \n",
      "\n",
      "Fold: 1  Epoch: 156  Training loss = 3.2455  Validation loss = 3.4432  \n",
      "\n",
      "Fold: 1  Epoch: 157  Training loss = 3.2450  Validation loss = 3.4425  \n",
      "\n",
      "Fold: 1  Epoch: 158  Training loss = 3.2449  Validation loss = 3.4422  \n",
      "\n",
      "Fold: 1  Epoch: 159  Training loss = 3.2446  Validation loss = 3.4417  \n",
      "\n",
      "Fold: 1  Epoch: 160  Training loss = 3.2444  Validation loss = 3.4413  \n",
      "\n",
      "Fold: 1  Epoch: 161  Training loss = 3.2441  Validation loss = 3.4408  \n",
      "\n",
      "Fold: 1  Epoch: 162  Training loss = 3.2439  Validation loss = 3.4405  \n",
      "\n",
      "Fold: 1  Epoch: 163  Training loss = 3.2437  Validation loss = 3.4401  \n",
      "\n",
      "Fold: 1  Epoch: 164  Training loss = 3.2434  Validation loss = 3.4397  \n",
      "\n",
      "Fold: 1  Epoch: 165  Training loss = 3.2432  Validation loss = 3.4392  \n",
      "\n",
      "Fold: 1  Epoch: 166  Training loss = 3.2430  Validation loss = 3.4388  \n",
      "\n",
      "Fold: 1  Epoch: 167  Training loss = 3.2427  Validation loss = 3.4385  \n",
      "\n",
      "Fold: 1  Epoch: 168  Training loss = 3.2425  Validation loss = 3.4380  \n",
      "\n",
      "Fold: 1  Epoch: 169  Training loss = 3.2422  Validation loss = 3.4376  \n",
      "\n",
      "Fold: 1  Epoch: 170  Training loss = 3.2419  Validation loss = 3.4371  \n",
      "\n",
      "Fold: 1  Epoch: 171  Training loss = 3.2416  Validation loss = 3.4365  \n",
      "\n",
      "Fold: 1  Epoch: 172  Training loss = 3.2413  Validation loss = 3.4361  \n",
      "\n",
      "Fold: 1  Epoch: 173  Training loss = 3.2411  Validation loss = 3.4357  \n",
      "\n",
      "Fold: 1  Epoch: 174  Training loss = 3.2408  Validation loss = 3.4351  \n",
      "\n",
      "Fold: 1  Epoch: 175  Training loss = 3.2406  Validation loss = 3.4347  \n",
      "\n",
      "Fold: 1  Epoch: 176  Training loss = 3.2403  Validation loss = 3.4343  \n",
      "\n",
      "Fold: 1  Epoch: 177  Training loss = 3.2401  Validation loss = 3.4339  \n",
      "\n",
      "Fold: 1  Epoch: 178  Training loss = 3.2399  Validation loss = 3.4335  \n",
      "\n",
      "Fold: 1  Epoch: 179  Training loss = 3.2396  Validation loss = 3.4330  \n",
      "\n",
      "Fold: 1  Epoch: 180  Training loss = 3.2393  Validation loss = 3.4326  \n",
      "\n",
      "Fold: 1  Epoch: 181  Training loss = 3.2390  Validation loss = 3.4321  \n",
      "\n",
      "Fold: 1  Epoch: 182  Training loss = 3.2388  Validation loss = 3.4316  \n",
      "\n",
      "Fold: 1  Epoch: 183  Training loss = 3.2385  Validation loss = 3.4312  \n",
      "\n",
      "Fold: 1  Epoch: 184  Training loss = 3.2383  Validation loss = 3.4308  \n",
      "\n",
      "Fold: 1  Epoch: 185  Training loss = 3.2381  Validation loss = 3.4304  \n",
      "\n",
      "Fold: 1  Epoch: 186  Training loss = 3.2378  Validation loss = 3.4300  \n",
      "\n",
      "Fold: 1  Epoch: 187  Training loss = 3.2376  Validation loss = 3.4296  \n",
      "\n",
      "Fold: 1  Epoch: 188  Training loss = 3.2373  Validation loss = 3.4291  \n",
      "\n",
      "Fold: 1  Epoch: 189  Training loss = 3.2371  Validation loss = 3.4286  \n",
      "\n",
      "Fold: 1  Epoch: 190  Training loss = 3.2369  Validation loss = 3.4282  \n",
      "\n",
      "Fold: 1  Epoch: 191  Training loss = 3.2367  Validation loss = 3.4279  \n",
      "\n",
      "Fold: 1  Epoch: 192  Training loss = 3.2365  Validation loss = 3.4276  \n",
      "\n",
      "Fold: 1  Epoch: 193  Training loss = 3.2363  Validation loss = 3.4272  \n",
      "\n",
      "Fold: 1  Epoch: 194  Training loss = 3.2361  Validation loss = 3.4269  \n",
      "\n",
      "Fold: 1  Epoch: 195  Training loss = 3.2359  Validation loss = 3.4265  \n",
      "\n",
      "Fold: 1  Epoch: 196  Training loss = 3.2356  Validation loss = 3.4261  \n",
      "\n",
      "Fold: 1  Epoch: 197  Training loss = 3.2354  Validation loss = 3.4257  \n",
      "\n",
      "Fold: 1  Epoch: 198  Training loss = 3.2352  Validation loss = 3.4253  \n",
      "\n",
      "Fold: 1  Epoch: 199  Training loss = 3.2350  Validation loss = 3.4249  \n",
      "\n",
      "Fold: 1  Epoch: 200  Training loss = 3.2348  Validation loss = 3.4246  \n",
      "\n",
      "Fold: 1  Epoch: 201  Training loss = 3.2346  Validation loss = 3.4243  \n",
      "\n",
      "Fold: 1  Epoch: 202  Training loss = 3.2344  Validation loss = 3.4239  \n",
      "\n",
      "Fold: 1  Epoch: 203  Training loss = 3.2341  Validation loss = 3.4234  \n",
      "\n",
      "Fold: 1  Epoch: 204  Training loss = 3.2340  Validation loss = 3.4231  \n",
      "\n",
      "Fold: 1  Epoch: 205  Training loss = 3.2337  Validation loss = 3.4227  \n",
      "\n",
      "Fold: 1  Epoch: 206  Training loss = 3.2335  Validation loss = 3.4223  \n",
      "\n",
      "Fold: 1  Epoch: 207  Training loss = 3.2333  Validation loss = 3.4219  \n",
      "\n",
      "Fold: 1  Epoch: 208  Training loss = 3.2331  Validation loss = 3.4216  \n",
      "\n",
      "Fold: 1  Epoch: 209  Training loss = 3.2329  Validation loss = 3.4212  \n",
      "\n",
      "Fold: 1  Epoch: 210  Training loss = 3.2327  Validation loss = 3.4208  \n",
      "\n",
      "Fold: 1  Epoch: 211  Training loss = 3.2324  Validation loss = 3.4203  \n",
      "\n",
      "Fold: 1  Epoch: 212  Training loss = 3.2322  Validation loss = 3.4199  \n",
      "\n",
      "Fold: 1  Epoch: 213  Training loss = 3.2320  Validation loss = 3.4196  \n",
      "\n",
      "Fold: 1  Epoch: 214  Training loss = 3.2318  Validation loss = 3.4192  \n",
      "\n",
      "Fold: 1  Epoch: 215  Training loss = 3.2316  Validation loss = 3.4189  \n",
      "\n",
      "Fold: 1  Epoch: 216  Training loss = 3.2313  Validation loss = 3.4184  \n",
      "\n",
      "Fold: 1  Epoch: 217  Training loss = 3.2310  Validation loss = 3.4179  \n",
      "\n",
      "Fold: 1  Epoch: 218  Training loss = 3.2308  Validation loss = 3.4174  \n",
      "\n",
      "Fold: 1  Epoch: 219  Training loss = 3.2305  Validation loss = 3.4171  \n",
      "\n",
      "Fold: 1  Epoch: 220  Training loss = 3.2303  Validation loss = 3.4166  \n",
      "\n",
      "Fold: 1  Epoch: 221  Training loss = 3.2301  Validation loss = 3.4163  \n",
      "\n",
      "Fold: 1  Epoch: 222  Training loss = 3.2298  Validation loss = 3.4157  \n",
      "\n",
      "Fold: 1  Epoch: 223  Training loss = 3.2296  Validation loss = 3.4154  \n",
      "\n",
      "Fold: 1  Epoch: 224  Training loss = 3.2293  Validation loss = 3.4149  \n",
      "\n",
      "Fold: 1  Epoch: 225  Training loss = 3.2291  Validation loss = 3.4146  \n",
      "\n",
      "Fold: 1  Epoch: 226  Training loss = 3.2289  Validation loss = 3.4142  \n",
      "\n",
      "Fold: 1  Epoch: 227  Training loss = 3.2287  Validation loss = 3.4138  \n",
      "\n",
      "Fold: 1  Epoch: 228  Training loss = 3.2285  Validation loss = 3.4135  \n",
      "\n",
      "Fold: 1  Epoch: 229  Training loss = 3.2282  Validation loss = 3.4129  \n",
      "\n",
      "Fold: 1  Epoch: 230  Training loss = 3.2280  Validation loss = 3.4126  \n",
      "\n",
      "Fold: 1  Epoch: 231  Training loss = 3.2277  Validation loss = 3.4121  \n",
      "\n",
      "Fold: 1  Epoch: 232  Training loss = 3.2275  Validation loss = 3.4117  \n",
      "\n",
      "Fold: 1  Epoch: 233  Training loss = 3.2273  Validation loss = 3.4113  \n",
      "\n",
      "Fold: 1  Epoch: 234  Training loss = 3.2270  Validation loss = 3.4109  \n",
      "\n",
      "Fold: 1  Epoch: 235  Training loss = 3.2268  Validation loss = 3.4105  \n",
      "\n",
      "Fold: 1  Epoch: 236  Training loss = 3.2266  Validation loss = 3.4101  \n",
      "\n",
      "Fold: 1  Epoch: 237  Training loss = 3.2264  Validation loss = 3.4097  \n",
      "\n",
      "Fold: 1  Epoch: 238  Training loss = 3.2261  Validation loss = 3.4092  \n",
      "\n",
      "Fold: 1  Epoch: 239  Training loss = 3.2258  Validation loss = 3.4087  \n",
      "\n",
      "Fold: 1  Epoch: 240  Training loss = 3.2257  Validation loss = 3.4085  \n",
      "\n",
      "Fold: 1  Epoch: 241  Training loss = 3.2254  Validation loss = 3.4080  \n",
      "\n",
      "Fold: 1  Epoch: 242  Training loss = 3.2253  Validation loss = 3.4078  \n",
      "\n",
      "Fold: 1  Epoch: 243  Training loss = 3.2251  Validation loss = 3.4074  \n",
      "\n",
      "Fold: 1  Epoch: 244  Training loss = 3.2249  Validation loss = 3.4070  \n",
      "\n",
      "Fold: 1  Epoch: 245  Training loss = 3.2247  Validation loss = 3.4066  \n",
      "\n",
      "Fold: 1  Epoch: 246  Training loss = 3.2244  Validation loss = 3.4062  \n",
      "\n",
      "Fold: 1  Epoch: 247  Training loss = 3.2242  Validation loss = 3.4058  \n",
      "\n",
      "Fold: 1  Epoch: 248  Training loss = 3.2240  Validation loss = 3.4054  \n",
      "\n",
      "Fold: 1  Epoch: 249  Training loss = 3.2237  Validation loss = 3.4049  \n",
      "\n",
      "Fold: 1  Epoch: 250  Training loss = 3.2235  Validation loss = 3.4045  \n",
      "\n",
      "Fold: 1  Epoch: 251  Training loss = 3.2232  Validation loss = 3.4041  \n",
      "\n",
      "Fold: 1  Epoch: 252  Training loss = 3.2230  Validation loss = 3.4036  \n",
      "\n",
      "Fold: 1  Epoch: 253  Training loss = 3.2227  Validation loss = 3.4032  \n",
      "\n",
      "Fold: 1  Epoch: 254  Training loss = 3.2224  Validation loss = 3.4027  \n",
      "\n",
      "Fold: 1  Epoch: 255  Training loss = 3.2222  Validation loss = 3.4024  \n",
      "\n",
      "Fold: 1  Epoch: 256  Training loss = 3.2220  Validation loss = 3.4019  \n",
      "\n",
      "Fold: 1  Epoch: 257  Training loss = 3.2217  Validation loss = 3.4015  \n",
      "\n",
      "Fold: 1  Epoch: 258  Training loss = 3.2215  Validation loss = 3.4011  \n",
      "\n",
      "Fold: 1  Epoch: 259  Training loss = 3.2213  Validation loss = 3.4007  \n",
      "\n",
      "Fold: 1  Epoch: 260  Training loss = 3.2211  Validation loss = 3.4003  \n",
      "\n",
      "Fold: 1  Epoch: 261  Training loss = 3.2209  Validation loss = 3.3999  \n",
      "\n",
      "Fold: 1  Epoch: 262  Training loss = 3.2207  Validation loss = 3.3996  \n",
      "\n",
      "Fold: 1  Epoch: 263  Training loss = 3.2204  Validation loss = 3.3991  \n",
      "\n",
      "Fold: 1  Epoch: 264  Training loss = 3.2202  Validation loss = 3.3988  \n",
      "\n",
      "Fold: 1  Epoch: 265  Training loss = 3.2200  Validation loss = 3.3984  \n",
      "\n",
      "Fold: 1  Epoch: 266  Training loss = 3.2198  Validation loss = 3.3980  \n",
      "\n",
      "Fold: 1  Epoch: 267  Training loss = 3.2195  Validation loss = 3.3976  \n",
      "\n",
      "Fold: 1  Epoch: 268  Training loss = 3.2193  Validation loss = 3.3972  \n",
      "\n",
      "Fold: 1  Epoch: 269  Training loss = 3.2191  Validation loss = 3.3969  \n",
      "\n",
      "Fold: 1  Epoch: 270  Training loss = 3.2189  Validation loss = 3.3964  \n",
      "\n",
      "Fold: 1  Epoch: 271  Training loss = 3.2186  Validation loss = 3.3960  \n",
      "\n",
      "Fold: 1  Epoch: 272  Training loss = 3.2185  Validation loss = 3.3957  \n",
      "\n",
      "Fold: 1  Epoch: 273  Training loss = 3.2183  Validation loss = 3.3953  \n",
      "\n",
      "Fold: 1  Epoch: 274  Training loss = 3.2181  Validation loss = 3.3949  \n",
      "\n",
      "Fold: 1  Epoch: 275  Training loss = 3.2179  Validation loss = 3.3946  \n",
      "\n",
      "Fold: 1  Epoch: 276  Training loss = 3.2176  Validation loss = 3.3941  \n",
      "\n",
      "Fold: 1  Epoch: 277  Training loss = 3.2174  Validation loss = 3.3937  \n",
      "\n",
      "Fold: 1  Epoch: 278  Training loss = 3.2171  Validation loss = 3.3932  \n",
      "\n",
      "Fold: 1  Epoch: 279  Training loss = 3.2169  Validation loss = 3.3929  \n",
      "\n",
      "Fold: 1  Epoch: 280  Training loss = 3.2167  Validation loss = 3.3925  \n",
      "\n",
      "Fold: 1  Epoch: 281  Training loss = 3.2165  Validation loss = 3.3921  \n",
      "\n",
      "Fold: 1  Epoch: 282  Training loss = 3.2162  Validation loss = 3.3916  \n",
      "\n",
      "Fold: 1  Epoch: 283  Training loss = 3.2161  Validation loss = 3.3913  \n",
      "\n",
      "Fold: 1  Epoch: 284  Training loss = 3.2159  Validation loss = 3.3910  \n",
      "\n",
      "Fold: 1  Epoch: 285  Training loss = 3.2157  Validation loss = 3.3906  \n",
      "\n",
      "Fold: 1  Epoch: 286  Training loss = 3.2154  Validation loss = 3.3901  \n",
      "\n",
      "Fold: 1  Epoch: 287  Training loss = 3.2152  Validation loss = 3.3897  \n",
      "\n",
      "Fold: 1  Epoch: 288  Training loss = 3.2150  Validation loss = 3.3894  \n",
      "\n",
      "Fold: 1  Epoch: 289  Training loss = 3.2147  Validation loss = 3.3890  \n",
      "\n",
      "Fold: 1  Epoch: 290  Training loss = 3.2145  Validation loss = 3.3886  \n",
      "\n",
      "Fold: 1  Epoch: 291  Training loss = 3.2143  Validation loss = 3.3882  \n",
      "\n",
      "Fold: 1  Epoch: 292  Training loss = 3.2139  Validation loss = 3.3876  \n",
      "\n",
      "Fold: 1  Epoch: 293  Training loss = 3.2137  Validation loss = 3.3871  \n",
      "\n",
      "Fold: 1  Epoch: 294  Training loss = 3.2134  Validation loss = 3.3867  \n",
      "\n",
      "Fold: 1  Epoch: 295  Training loss = 3.2132  Validation loss = 3.3863  \n",
      "\n",
      "Fold: 1  Epoch: 296  Training loss = 3.2130  Validation loss = 3.3859  \n",
      "\n",
      "Fold: 1  Epoch: 297  Training loss = 3.2128  Validation loss = 3.3855  \n",
      "\n",
      "Fold: 1  Epoch: 298  Training loss = 3.2126  Validation loss = 3.3852  \n",
      "\n",
      "Fold: 1  Epoch: 299  Training loss = 3.2123  Validation loss = 3.3847  \n",
      "\n",
      "Fold: 1  Epoch: 300  Training loss = 3.2121  Validation loss = 3.3842  \n",
      "\n",
      "Fold: 1  Epoch: 301  Training loss = 3.2118  Validation loss = 3.3838  \n",
      "\n",
      "Fold: 1  Epoch: 302  Training loss = 3.2116  Validation loss = 3.3834  \n",
      "\n",
      "Fold: 1  Epoch: 303  Training loss = 3.2113  Validation loss = 3.3828  \n",
      "\n",
      "Fold: 1  Epoch: 304  Training loss = 3.2110  Validation loss = 3.3824  \n",
      "\n",
      "Fold: 1  Epoch: 305  Training loss = 3.2108  Validation loss = 3.3820  \n",
      "\n",
      "Fold: 1  Epoch: 306  Training loss = 3.2106  Validation loss = 3.3815  \n",
      "\n",
      "Fold: 1  Epoch: 307  Training loss = 3.2103  Validation loss = 3.3810  \n",
      "\n",
      "Fold: 1  Epoch: 308  Training loss = 3.2100  Validation loss = 3.3806  \n",
      "\n",
      "Fold: 1  Epoch: 309  Training loss = 3.2098  Validation loss = 3.3802  \n",
      "\n",
      "Fold: 1  Epoch: 310  Training loss = 3.2097  Validation loss = 3.3800  \n",
      "\n",
      "Fold: 1  Epoch: 311  Training loss = 3.2094  Validation loss = 3.3794  \n",
      "\n",
      "Fold: 1  Epoch: 312  Training loss = 3.2092  Validation loss = 3.3791  \n",
      "\n",
      "Fold: 1  Epoch: 313  Training loss = 3.2090  Validation loss = 3.3788  \n",
      "\n",
      "Fold: 1  Epoch: 314  Training loss = 3.2089  Validation loss = 3.3785  \n",
      "\n",
      "Fold: 1  Epoch: 315  Training loss = 3.2086  Validation loss = 3.3781  \n",
      "\n",
      "Fold: 1  Epoch: 316  Training loss = 3.2084  Validation loss = 3.3777  \n",
      "\n",
      "Fold: 1  Epoch: 317  Training loss = 3.2082  Validation loss = 3.3774  \n",
      "\n",
      "Fold: 1  Epoch: 318  Training loss = 3.2080  Validation loss = 3.3769  \n",
      "\n",
      "Fold: 1  Epoch: 319  Training loss = 3.2078  Validation loss = 3.3766  \n",
      "\n",
      "Fold: 1  Epoch: 320  Training loss = 3.2076  Validation loss = 3.3762  \n",
      "\n",
      "Fold: 1  Epoch: 321  Training loss = 3.2073  Validation loss = 3.3758  \n",
      "\n",
      "Fold: 1  Epoch: 322  Training loss = 3.2070  Validation loss = 3.3753  \n",
      "\n",
      "Fold: 1  Epoch: 323  Training loss = 3.2068  Validation loss = 3.3749  \n",
      "\n",
      "Fold: 1  Epoch: 324  Training loss = 3.2066  Validation loss = 3.3745  \n",
      "\n",
      "Fold: 1  Epoch: 325  Training loss = 3.2064  Validation loss = 3.3742  \n",
      "\n",
      "Fold: 1  Epoch: 326  Training loss = 3.2062  Validation loss = 3.3738  \n",
      "\n",
      "Fold: 1  Epoch: 327  Training loss = 3.2060  Validation loss = 3.3735  \n",
      "\n",
      "Fold: 1  Epoch: 328  Training loss = 3.2058  Validation loss = 3.3731  \n",
      "\n",
      "Fold: 1  Epoch: 329  Training loss = 3.2056  Validation loss = 3.3726  \n",
      "\n",
      "Fold: 1  Epoch: 330  Training loss = 3.2054  Validation loss = 3.3723  \n",
      "\n",
      "Fold: 1  Epoch: 331  Training loss = 3.2052  Validation loss = 3.3720  \n",
      "\n",
      "Fold: 1  Epoch: 332  Training loss = 3.2050  Validation loss = 3.3716  \n",
      "\n",
      "Fold: 1  Epoch: 333  Training loss = 3.2047  Validation loss = 3.3711  \n",
      "\n",
      "Fold: 1  Epoch: 334  Training loss = 3.2044  Validation loss = 3.3706  \n",
      "\n",
      "Fold: 1  Epoch: 335  Training loss = 3.2042  Validation loss = 3.3702  \n",
      "\n",
      "Fold: 1  Epoch: 336  Training loss = 3.2040  Validation loss = 3.3699  \n",
      "\n",
      "Fold: 1  Epoch: 337  Training loss = 3.2038  Validation loss = 3.3695  \n",
      "\n",
      "Fold: 1  Epoch: 338  Training loss = 3.2036  Validation loss = 3.3691  \n",
      "\n",
      "Fold: 1  Epoch: 339  Training loss = 3.2034  Validation loss = 3.3687  \n",
      "\n",
      "Fold: 1  Epoch: 340  Training loss = 3.2032  Validation loss = 3.3684  \n",
      "\n",
      "Fold: 1  Epoch: 341  Training loss = 3.2029  Validation loss = 3.3679  \n",
      "\n",
      "Fold: 1  Epoch: 342  Training loss = 3.2027  Validation loss = 3.3675  \n",
      "\n",
      "Fold: 1  Epoch: 343  Training loss = 3.2024  Validation loss = 3.3671  \n",
      "\n",
      "Fold: 1  Epoch: 344  Training loss = 3.2022  Validation loss = 3.3666  \n",
      "\n",
      "Fold: 1  Epoch: 345  Training loss = 3.2020  Validation loss = 3.3662  \n",
      "\n",
      "Fold: 1  Epoch: 346  Training loss = 3.2017  Validation loss = 3.3657  \n",
      "\n",
      "Fold: 1  Epoch: 347  Training loss = 3.2015  Validation loss = 3.3653  \n",
      "\n",
      "Fold: 1  Epoch: 348  Training loss = 3.2012  Validation loss = 3.3648  \n",
      "\n",
      "Fold: 1  Epoch: 349  Training loss = 3.2010  Validation loss = 3.3645  \n",
      "\n",
      "Fold: 1  Epoch: 350  Training loss = 3.2008  Validation loss = 3.3641  \n",
      "\n",
      "Fold: 1  Epoch: 351  Training loss = 3.2006  Validation loss = 3.3637  \n",
      "\n",
      "Fold: 1  Epoch: 352  Training loss = 3.2003  Validation loss = 3.3632  \n",
      "\n",
      "Fold: 1  Epoch: 353  Training loss = 3.2001  Validation loss = 3.3629  \n",
      "\n",
      "Fold: 1  Epoch: 354  Training loss = 3.1999  Validation loss = 3.3626  \n",
      "\n",
      "Fold: 1  Epoch: 355  Training loss = 3.1998  Validation loss = 3.3623  \n",
      "\n",
      "Fold: 1  Epoch: 356  Training loss = 3.1996  Validation loss = 3.3619  \n",
      "\n",
      "Fold: 1  Epoch: 357  Training loss = 3.1994  Validation loss = 3.3616  \n",
      "\n",
      "Fold: 1  Epoch: 358  Training loss = 3.1992  Validation loss = 3.3611  \n",
      "\n",
      "Fold: 1  Epoch: 359  Training loss = 3.1989  Validation loss = 3.3607  \n",
      "\n",
      "Fold: 1  Epoch: 360  Training loss = 3.1987  Validation loss = 3.3604  \n",
      "\n",
      "Fold: 1  Epoch: 361  Training loss = 3.1985  Validation loss = 3.3600  \n",
      "\n",
      "Fold: 1  Epoch: 362  Training loss = 3.1983  Validation loss = 3.3597  \n",
      "\n",
      "Fold: 1  Epoch: 363  Training loss = 3.1982  Validation loss = 3.3594  \n",
      "\n",
      "Fold: 1  Epoch: 364  Training loss = 3.1980  Validation loss = 3.3591  \n",
      "\n",
      "Fold: 1  Epoch: 365  Training loss = 3.1977  Validation loss = 3.3586  \n",
      "\n",
      "Fold: 1  Epoch: 366  Training loss = 3.1975  Validation loss = 3.3583  \n",
      "\n",
      "Fold: 1  Epoch: 367  Training loss = 3.1973  Validation loss = 3.3579  \n",
      "\n",
      "Fold: 1  Epoch: 368  Training loss = 3.1971  Validation loss = 3.3574  \n",
      "\n",
      "Fold: 1  Epoch: 369  Training loss = 3.1969  Validation loss = 3.3572  \n",
      "\n",
      "Fold: 1  Epoch: 370  Training loss = 3.1967  Validation loss = 3.3568  \n",
      "\n",
      "Fold: 1  Epoch: 371  Training loss = 3.1965  Validation loss = 3.3564  \n",
      "\n",
      "Fold: 1  Epoch: 372  Training loss = 3.1963  Validation loss = 3.3560  \n",
      "\n",
      "Fold: 1  Epoch: 373  Training loss = 3.1961  Validation loss = 3.3557  \n",
      "\n",
      "Fold: 1  Epoch: 374  Training loss = 3.1959  Validation loss = 3.3552  \n",
      "\n",
      "Fold: 1  Epoch: 375  Training loss = 3.1956  Validation loss = 3.3548  \n",
      "\n",
      "Fold: 1  Epoch: 376  Training loss = 3.1954  Validation loss = 3.3544  \n",
      "\n",
      "Fold: 1  Epoch: 377  Training loss = 3.1952  Validation loss = 3.3540  \n",
      "\n",
      "Fold: 1  Epoch: 378  Training loss = 3.1950  Validation loss = 3.3536  \n",
      "\n",
      "Fold: 1  Epoch: 379  Training loss = 3.1947  Validation loss = 3.3532  \n",
      "\n",
      "Fold: 1  Epoch: 380  Training loss = 3.1945  Validation loss = 3.3528  \n",
      "\n",
      "Fold: 1  Epoch: 381  Training loss = 3.1943  Validation loss = 3.3524  \n",
      "\n",
      "Fold: 1  Epoch: 382  Training loss = 3.1941  Validation loss = 3.3520  \n",
      "\n",
      "Fold: 1  Epoch: 383  Training loss = 3.1938  Validation loss = 3.3514  \n",
      "\n",
      "Fold: 1  Epoch: 384  Training loss = 3.1936  Validation loss = 3.3511  \n",
      "\n",
      "Fold: 1  Epoch: 385  Training loss = 3.1934  Validation loss = 3.3507  \n",
      "\n",
      "Fold: 1  Epoch: 386  Training loss = 3.1932  Validation loss = 3.3504  \n",
      "\n",
      "Fold: 1  Epoch: 387  Training loss = 3.1929  Validation loss = 3.3499  \n",
      "\n",
      "Fold: 1  Epoch: 388  Training loss = 3.1928  Validation loss = 3.3497  \n",
      "\n",
      "Fold: 1  Epoch: 389  Training loss = 3.1926  Validation loss = 3.3492  \n",
      "\n",
      "Fold: 1  Epoch: 390  Training loss = 3.1923  Validation loss = 3.3488  \n",
      "\n",
      "Fold: 1  Epoch: 391  Training loss = 3.1921  Validation loss = 3.3484  \n",
      "\n",
      "Fold: 1  Epoch: 392  Training loss = 3.1919  Validation loss = 3.3480  \n",
      "\n",
      "Fold: 1  Epoch: 393  Training loss = 3.1917  Validation loss = 3.3477  \n",
      "\n",
      "Fold: 1  Epoch: 394  Training loss = 3.1915  Validation loss = 3.3474  \n",
      "\n",
      "Fold: 1  Epoch: 395  Training loss = 3.1913  Validation loss = 3.3470  \n",
      "\n",
      "Fold: 1  Epoch: 396  Training loss = 3.1911  Validation loss = 3.3466  \n",
      "\n",
      "Fold: 1  Epoch: 397  Training loss = 3.1909  Validation loss = 3.3462  \n",
      "\n",
      "Fold: 1  Epoch: 398  Training loss = 3.1907  Validation loss = 3.3459  \n",
      "\n",
      "Fold: 1  Epoch: 399  Training loss = 3.1905  Validation loss = 3.3455  \n",
      "\n",
      "Fold: 1  Epoch: 400  Training loss = 3.1903  Validation loss = 3.3452  \n",
      "\n",
      "Fold: 1  Epoch: 401  Training loss = 3.1901  Validation loss = 3.3448  \n",
      "\n",
      "Fold: 1  Epoch: 402  Training loss = 3.1899  Validation loss = 3.3444  \n",
      "\n",
      "Fold: 1  Epoch: 403  Training loss = 3.1896  Validation loss = 3.3439  \n",
      "\n",
      "Fold: 1  Epoch: 404  Training loss = 3.1894  Validation loss = 3.3435  \n",
      "\n",
      "Fold: 1  Epoch: 405  Training loss = 3.1892  Validation loss = 3.3431  \n",
      "\n",
      "Fold: 1  Epoch: 406  Training loss = 3.1890  Validation loss = 3.3428  \n",
      "\n",
      "Fold: 1  Epoch: 407  Training loss = 3.1888  Validation loss = 3.3424  \n",
      "\n",
      "Fold: 1  Epoch: 408  Training loss = 3.1885  Validation loss = 3.3419  \n",
      "\n",
      "Fold: 1  Epoch: 409  Training loss = 3.1883  Validation loss = 3.3416  \n",
      "\n",
      "Fold: 1  Epoch: 410  Training loss = 3.1881  Validation loss = 3.3412  \n",
      "\n",
      "Fold: 1  Epoch: 411  Training loss = 3.1879  Validation loss = 3.3408  \n",
      "\n",
      "Fold: 1  Epoch: 412  Training loss = 3.1877  Validation loss = 3.3405  \n",
      "\n",
      "Fold: 1  Epoch: 413  Training loss = 3.1875  Validation loss = 3.3400  \n",
      "\n",
      "Fold: 1  Epoch: 414  Training loss = 3.1872  Validation loss = 3.3395  \n",
      "\n",
      "Fold: 1  Epoch: 415  Training loss = 3.1870  Validation loss = 3.3392  \n",
      "\n",
      "Fold: 1  Epoch: 416  Training loss = 3.1868  Validation loss = 3.3388  \n",
      "\n",
      "Fold: 1  Epoch: 417  Training loss = 3.1865  Validation loss = 3.3383  \n",
      "\n",
      "Fold: 1  Epoch: 418  Training loss = 3.1863  Validation loss = 3.3378  \n",
      "\n",
      "Fold: 1  Epoch: 419  Training loss = 3.1860  Validation loss = 3.3374  \n",
      "\n",
      "Fold: 1  Epoch: 420  Training loss = 3.1858  Validation loss = 3.3369  \n",
      "\n",
      "Fold: 1  Epoch: 421  Training loss = 3.1855  Validation loss = 3.3365  \n",
      "\n",
      "Fold: 1  Epoch: 422  Training loss = 3.1854  Validation loss = 3.3362  \n",
      "\n",
      "Fold: 1  Epoch: 423  Training loss = 3.1852  Validation loss = 3.3359  \n",
      "\n",
      "Fold: 1  Epoch: 424  Training loss = 3.1850  Validation loss = 3.3356  \n",
      "\n",
      "Fold: 1  Epoch: 425  Training loss = 3.1848  Validation loss = 3.3352  \n",
      "\n",
      "Fold: 1  Epoch: 426  Training loss = 3.1846  Validation loss = 3.3348  \n",
      "\n",
      "Fold: 1  Epoch: 427  Training loss = 3.1844  Validation loss = 3.3344  \n",
      "\n",
      "Fold: 1  Epoch: 428  Training loss = 3.1842  Validation loss = 3.3340  \n",
      "\n",
      "Fold: 1  Epoch: 429  Training loss = 3.1841  Validation loss = 3.3338  \n",
      "\n",
      "Fold: 1  Epoch: 430  Training loss = 3.1838  Validation loss = 3.3333  \n",
      "\n",
      "Fold: 1  Epoch: 431  Training loss = 3.1836  Validation loss = 3.3330  \n",
      "\n",
      "Fold: 1  Epoch: 432  Training loss = 3.1834  Validation loss = 3.3325  \n",
      "\n",
      "Fold: 1  Epoch: 433  Training loss = 3.1831  Validation loss = 3.3321  \n",
      "\n",
      "Fold: 1  Epoch: 434  Training loss = 3.1829  Validation loss = 3.3317  \n",
      "\n",
      "Fold: 1  Epoch: 435  Training loss = 3.1827  Validation loss = 3.3313  \n",
      "\n",
      "Fold: 1  Epoch: 436  Training loss = 3.1825  Validation loss = 3.3310  \n",
      "\n",
      "Fold: 1  Epoch: 437  Training loss = 3.1823  Validation loss = 3.3307  \n",
      "\n",
      "Fold: 1  Epoch: 438  Training loss = 3.1822  Validation loss = 3.3304  \n",
      "\n",
      "Fold: 1  Epoch: 439  Training loss = 3.1819  Validation loss = 3.3299  \n",
      "\n",
      "Fold: 1  Epoch: 440  Training loss = 3.1818  Validation loss = 3.3296  \n",
      "\n",
      "Fold: 1  Epoch: 441  Training loss = 3.1816  Validation loss = 3.3293  \n",
      "\n",
      "Fold: 1  Epoch: 442  Training loss = 3.1814  Validation loss = 3.3290  \n",
      "\n",
      "Fold: 1  Epoch: 443  Training loss = 3.1812  Validation loss = 3.3286  \n",
      "\n",
      "Fold: 1  Epoch: 444  Training loss = 3.1810  Validation loss = 3.3282  \n",
      "\n",
      "Fold: 1  Epoch: 445  Training loss = 3.1808  Validation loss = 3.3277  \n",
      "\n",
      "Fold: 1  Epoch: 446  Training loss = 3.1805  Validation loss = 3.3273  \n",
      "\n",
      "Fold: 1  Epoch: 447  Training loss = 3.1803  Validation loss = 3.3269  \n",
      "\n",
      "Fold: 1  Epoch: 448  Training loss = 3.1801  Validation loss = 3.3265  \n",
      "\n",
      "Fold: 1  Epoch: 449  Training loss = 3.1799  Validation loss = 3.3262  \n",
      "\n",
      "Fold: 1  Epoch: 450  Training loss = 3.1797  Validation loss = 3.3258  \n",
      "\n",
      "Fold: 1  Epoch: 451  Training loss = 3.1794  Validation loss = 3.3253  \n",
      "\n",
      "Fold: 1  Epoch: 452  Training loss = 3.1792  Validation loss = 3.3250  \n",
      "\n",
      "Fold: 1  Epoch: 453  Training loss = 3.1790  Validation loss = 3.3246  \n",
      "\n",
      "Fold: 1  Epoch: 454  Training loss = 3.1788  Validation loss = 3.3242  \n",
      "\n",
      "Fold: 1  Epoch: 455  Training loss = 3.1785  Validation loss = 3.3237  \n",
      "\n",
      "Fold: 1  Epoch: 456  Training loss = 3.1782  Validation loss = 3.3232  \n",
      "\n",
      "Fold: 1  Epoch: 457  Training loss = 3.1781  Validation loss = 3.3229  \n",
      "\n",
      "Fold: 1  Epoch: 458  Training loss = 3.1779  Validation loss = 3.3225  \n",
      "\n",
      "Fold: 1  Epoch: 459  Training loss = 3.1776  Validation loss = 3.3220  \n",
      "\n",
      "Fold: 1  Epoch: 460  Training loss = 3.1774  Validation loss = 3.3216  \n",
      "\n",
      "Fold: 1  Epoch: 461  Training loss = 3.1771  Validation loss = 3.3212  \n",
      "\n",
      "Fold: 1  Epoch: 462  Training loss = 3.1768  Validation loss = 3.3206  \n",
      "\n",
      "Fold: 1  Epoch: 463  Training loss = 3.1766  Validation loss = 3.3203  \n",
      "\n",
      "Fold: 1  Epoch: 464  Training loss = 3.1764  Validation loss = 3.3198  \n",
      "\n",
      "Fold: 1  Epoch: 465  Training loss = 3.1762  Validation loss = 3.3195  \n",
      "\n",
      "Fold: 1  Epoch: 466  Training loss = 3.1760  Validation loss = 3.3191  \n",
      "\n",
      "Fold: 1  Epoch: 467  Training loss = 3.1758  Validation loss = 3.3188  \n",
      "\n",
      "Fold: 1  Epoch: 468  Training loss = 3.1756  Validation loss = 3.3184  \n",
      "\n",
      "Fold: 1  Epoch: 469  Training loss = 3.1754  Validation loss = 3.3181  \n",
      "\n",
      "Fold: 1  Epoch: 470  Training loss = 3.1753  Validation loss = 3.3178  \n",
      "\n",
      "Fold: 1  Epoch: 471  Training loss = 3.1751  Validation loss = 3.3175  \n",
      "\n",
      "Fold: 1  Epoch: 472  Training loss = 3.1749  Validation loss = 3.3170  \n",
      "\n",
      "Fold: 1  Epoch: 473  Training loss = 3.1746  Validation loss = 3.3166  \n",
      "\n",
      "Fold: 1  Epoch: 474  Training loss = 3.1744  Validation loss = 3.3162  \n",
      "\n",
      "Fold: 1  Epoch: 475  Training loss = 3.1742  Validation loss = 3.3158  \n",
      "\n",
      "Fold: 1  Epoch: 476  Training loss = 3.1740  Validation loss = 3.3154  \n",
      "\n",
      "Fold: 1  Epoch: 477  Training loss = 3.1737  Validation loss = 3.3150  \n",
      "\n",
      "Fold: 1  Epoch: 478  Training loss = 3.1735  Validation loss = 3.3146  \n",
      "\n",
      "Fold: 1  Epoch: 479  Training loss = 3.1734  Validation loss = 3.3142  \n",
      "\n",
      "Fold: 1  Epoch: 480  Training loss = 3.1732  Validation loss = 3.3139  \n",
      "\n",
      "Fold: 1  Epoch: 481  Training loss = 3.1729  Validation loss = 3.3135  \n",
      "\n",
      "Fold: 1  Epoch: 482  Training loss = 3.1727  Validation loss = 3.3131  \n",
      "\n",
      "Fold: 1  Epoch: 483  Training loss = 3.1726  Validation loss = 3.3128  \n",
      "\n",
      "Fold: 1  Epoch: 484  Training loss = 3.1723  Validation loss = 3.3123  \n",
      "\n",
      "Fold: 1  Epoch: 485  Training loss = 3.1721  Validation loss = 3.3119  \n",
      "\n",
      "Fold: 1  Epoch: 486  Training loss = 3.1718  Validation loss = 3.3114  \n",
      "\n",
      "Fold: 1  Epoch: 487  Training loss = 3.1716  Validation loss = 3.3109  \n",
      "\n",
      "Fold: 1  Epoch: 488  Training loss = 3.1714  Validation loss = 3.3106  \n",
      "\n",
      "Fold: 1  Epoch: 489  Training loss = 3.1712  Validation loss = 3.3102  \n",
      "\n",
      "Fold: 1  Epoch: 490  Training loss = 3.1710  Validation loss = 3.3099  \n",
      "\n",
      "Fold: 1  Epoch: 491  Training loss = 3.1708  Validation loss = 3.3095  \n",
      "\n",
      "Fold: 1  Epoch: 492  Training loss = 3.1706  Validation loss = 3.3091  \n",
      "\n",
      "Fold: 1  Epoch: 493  Training loss = 3.1703  Validation loss = 3.3087  \n",
      "\n",
      "Fold: 1  Epoch: 494  Training loss = 3.1701  Validation loss = 3.3083  \n",
      "\n",
      "Fold: 1  Epoch: 495  Training loss = 3.1698  Validation loss = 3.3077  \n",
      "\n",
      "Fold: 1  Epoch: 496  Training loss = 3.1696  Validation loss = 3.3074  \n",
      "\n",
      "Fold: 1  Epoch: 497  Training loss = 3.1694  Validation loss = 3.3069  \n",
      "\n",
      "Fold: 1  Epoch: 498  Training loss = 3.1692  Validation loss = 3.3066  \n",
      "\n",
      "Fold: 1  Epoch: 499  Training loss = 3.1690  Validation loss = 3.3062  \n",
      "\n",
      "Fold: 1  Epoch: 500  Training loss = 3.1688  Validation loss = 3.3059  \n",
      "\n",
      "Check model:  Fold: 1  Epoch: 500  Training loss = 3.1688  Validation loss = 3.3059  \n",
      "\n",
      "Fold: 2  Epoch: 1  Training loss = 3.1120  Validation loss = 3.0964  \n",
      "\n",
      "Fold: 2  Epoch: 2  Training loss = 3.1117  Validation loss = 3.0960  \n",
      "\n",
      "Fold: 2  Epoch: 3  Training loss = 3.1114  Validation loss = 3.0956  \n",
      "\n",
      "Fold: 2  Epoch: 4  Training loss = 3.1112  Validation loss = 3.0953  \n",
      "\n",
      "Fold: 2  Epoch: 5  Training loss = 3.1110  Validation loss = 3.0950  \n",
      "\n",
      "Fold: 2  Epoch: 6  Training loss = 3.1108  Validation loss = 3.0948  \n",
      "\n",
      "Fold: 2  Epoch: 7  Training loss = 3.1106  Validation loss = 3.0945  \n",
      "\n",
      "Fold: 2  Epoch: 8  Training loss = 3.1102  Validation loss = 3.0940  \n",
      "\n",
      "Fold: 2  Epoch: 9  Training loss = 3.1099  Validation loss = 3.0936  \n",
      "\n",
      "Fold: 2  Epoch: 10  Training loss = 3.1097  Validation loss = 3.0932  \n",
      "\n",
      "Fold: 2  Epoch: 11  Training loss = 3.1095  Validation loss = 3.0929  \n",
      "\n",
      "Fold: 2  Epoch: 12  Training loss = 3.1093  Validation loss = 3.0927  \n",
      "\n",
      "Fold: 2  Epoch: 13  Training loss = 3.1091  Validation loss = 3.0924  \n",
      "\n",
      "Fold: 2  Epoch: 14  Training loss = 3.1088  Validation loss = 3.0921  \n",
      "\n",
      "Fold: 2  Epoch: 15  Training loss = 3.1086  Validation loss = 3.0917  \n",
      "\n",
      "Fold: 2  Epoch: 16  Training loss = 3.1083  Validation loss = 3.0913  \n",
      "\n",
      "Fold: 2  Epoch: 17  Training loss = 3.1081  Validation loss = 3.0910  \n",
      "\n",
      "Fold: 2  Epoch: 18  Training loss = 3.1077  Validation loss = 3.0906  \n",
      "\n",
      "Fold: 2  Epoch: 19  Training loss = 3.1075  Validation loss = 3.0902  \n",
      "\n",
      "Fold: 2  Epoch: 20  Training loss = 3.1073  Validation loss = 3.0898  \n",
      "\n",
      "Fold: 2  Epoch: 21  Training loss = 3.1070  Validation loss = 3.0895  \n",
      "\n",
      "Fold: 2  Epoch: 22  Training loss = 3.1069  Validation loss = 3.0892  \n",
      "\n",
      "Fold: 2  Epoch: 23  Training loss = 3.1066  Validation loss = 3.0888  \n",
      "\n",
      "Fold: 2  Epoch: 24  Training loss = 3.1064  Validation loss = 3.0886  \n",
      "\n",
      "Fold: 2  Epoch: 25  Training loss = 3.1061  Validation loss = 3.0882  \n",
      "\n",
      "Fold: 2  Epoch: 26  Training loss = 3.1058  Validation loss = 3.0878  \n",
      "\n",
      "Fold: 2  Epoch: 27  Training loss = 3.1057  Validation loss = 3.0876  \n",
      "\n",
      "Fold: 2  Epoch: 28  Training loss = 3.1055  Validation loss = 3.0873  \n",
      "\n",
      "Fold: 2  Epoch: 29  Training loss = 3.1053  Validation loss = 3.0870  \n",
      "\n",
      "Fold: 2  Epoch: 30  Training loss = 3.1050  Validation loss = 3.0866  \n",
      "\n",
      "Fold: 2  Epoch: 31  Training loss = 3.1048  Validation loss = 3.0863  \n",
      "\n",
      "Fold: 2  Epoch: 32  Training loss = 3.1045  Validation loss = 3.0860  \n",
      "\n",
      "Fold: 2  Epoch: 33  Training loss = 3.1043  Validation loss = 3.0856  \n",
      "\n",
      "Fold: 2  Epoch: 34  Training loss = 3.1041  Validation loss = 3.0854  \n",
      "\n",
      "Fold: 2  Epoch: 35  Training loss = 3.1038  Validation loss = 3.0850  \n",
      "\n",
      "Fold: 2  Epoch: 36  Training loss = 3.1036  Validation loss = 3.0847  \n",
      "\n",
      "Fold: 2  Epoch: 37  Training loss = 3.1033  Validation loss = 3.0843  \n",
      "\n",
      "Fold: 2  Epoch: 38  Training loss = 3.1031  Validation loss = 3.0840  \n",
      "\n",
      "Fold: 2  Epoch: 39  Training loss = 3.1028  Validation loss = 3.0836  \n",
      "\n",
      "Fold: 2  Epoch: 40  Training loss = 3.1026  Validation loss = 3.0833  \n",
      "\n",
      "Fold: 2  Epoch: 41  Training loss = 3.1024  Validation loss = 3.0830  \n",
      "\n",
      "Fold: 2  Epoch: 42  Training loss = 3.1020  Validation loss = 3.0825  \n",
      "\n",
      "Fold: 2  Epoch: 43  Training loss = 3.1018  Validation loss = 3.0821  \n",
      "\n",
      "Fold: 2  Epoch: 44  Training loss = 3.1016  Validation loss = 3.0819  \n",
      "\n",
      "Fold: 2  Epoch: 45  Training loss = 3.1014  Validation loss = 3.0816  \n",
      "\n",
      "Fold: 2  Epoch: 46  Training loss = 3.1011  Validation loss = 3.0812  \n",
      "\n",
      "Fold: 2  Epoch: 47  Training loss = 3.1008  Validation loss = 3.0809  \n",
      "\n",
      "Fold: 2  Epoch: 48  Training loss = 3.1006  Validation loss = 3.0806  \n",
      "\n",
      "Fold: 2  Epoch: 49  Training loss = 3.1005  Validation loss = 3.0803  \n",
      "\n",
      "Fold: 2  Epoch: 50  Training loss = 3.1002  Validation loss = 3.0799  \n",
      "\n",
      "Fold: 2  Epoch: 51  Training loss = 3.0999  Validation loss = 3.0796  \n",
      "\n",
      "Fold: 2  Epoch: 52  Training loss = 3.0996  Validation loss = 3.0792  \n",
      "\n",
      "Fold: 2  Epoch: 53  Training loss = 3.0994  Validation loss = 3.0789  \n",
      "\n",
      "Fold: 2  Epoch: 54  Training loss = 3.0992  Validation loss = 3.0787  \n",
      "\n",
      "Fold: 2  Epoch: 55  Training loss = 3.0990  Validation loss = 3.0783  \n",
      "\n",
      "Fold: 2  Epoch: 56  Training loss = 3.0988  Validation loss = 3.0781  \n",
      "\n",
      "Fold: 2  Epoch: 57  Training loss = 3.0985  Validation loss = 3.0777  \n",
      "\n",
      "Fold: 2  Epoch: 58  Training loss = 3.0983  Validation loss = 3.0774  \n",
      "\n",
      "Fold: 2  Epoch: 59  Training loss = 3.0981  Validation loss = 3.0771  \n",
      "\n",
      "Fold: 2  Epoch: 60  Training loss = 3.0979  Validation loss = 3.0768  \n",
      "\n",
      "Fold: 2  Epoch: 61  Training loss = 3.0978  Validation loss = 3.0766  \n",
      "\n",
      "Fold: 2  Epoch: 62  Training loss = 3.0975  Validation loss = 3.0762  \n",
      "\n",
      "Fold: 2  Epoch: 63  Training loss = 3.0973  Validation loss = 3.0759  \n",
      "\n",
      "Fold: 2  Epoch: 64  Training loss = 3.0970  Validation loss = 3.0755  \n",
      "\n",
      "Fold: 2  Epoch: 65  Training loss = 3.0968  Validation loss = 3.0752  \n",
      "\n",
      "Fold: 2  Epoch: 66  Training loss = 3.0966  Validation loss = 3.0749  \n",
      "\n",
      "Fold: 2  Epoch: 67  Training loss = 3.0964  Validation loss = 3.0746  \n",
      "\n",
      "Fold: 2  Epoch: 68  Training loss = 3.0961  Validation loss = 3.0743  \n",
      "\n",
      "Fold: 2  Epoch: 69  Training loss = 3.0959  Validation loss = 3.0740  \n",
      "\n",
      "Fold: 2  Epoch: 70  Training loss = 3.0957  Validation loss = 3.0737  \n",
      "\n",
      "Fold: 2  Epoch: 71  Training loss = 3.0955  Validation loss = 3.0734  \n",
      "\n",
      "Fold: 2  Epoch: 72  Training loss = 3.0953  Validation loss = 3.0731  \n",
      "\n",
      "Fold: 2  Epoch: 73  Training loss = 3.0950  Validation loss = 3.0727  \n",
      "\n",
      "Fold: 2  Epoch: 74  Training loss = 3.0948  Validation loss = 3.0725  \n",
      "\n",
      "Fold: 2  Epoch: 75  Training loss = 3.0946  Validation loss = 3.0722  \n",
      "\n",
      "Fold: 2  Epoch: 76  Training loss = 3.0944  Validation loss = 3.0719  \n",
      "\n",
      "Fold: 2  Epoch: 77  Training loss = 3.0942  Validation loss = 3.0715  \n",
      "\n",
      "Fold: 2  Epoch: 78  Training loss = 3.0940  Validation loss = 3.0712  \n",
      "\n",
      "Fold: 2  Epoch: 79  Training loss = 3.0936  Validation loss = 3.0708  \n",
      "\n",
      "Fold: 2  Epoch: 80  Training loss = 3.0934  Validation loss = 3.0705  \n",
      "\n",
      "Fold: 2  Epoch: 81  Training loss = 3.0932  Validation loss = 3.0701  \n",
      "\n",
      "Fold: 2  Epoch: 82  Training loss = 3.0929  Validation loss = 3.0698  \n",
      "\n",
      "Fold: 2  Epoch: 83  Training loss = 3.0926  Validation loss = 3.0694  \n",
      "\n",
      "Fold: 2  Epoch: 84  Training loss = 3.0924  Validation loss = 3.0691  \n",
      "\n",
      "Fold: 2  Epoch: 85  Training loss = 3.0922  Validation loss = 3.0687  \n",
      "\n",
      "Fold: 2  Epoch: 86  Training loss = 3.0918  Validation loss = 3.0683  \n",
      "\n",
      "Fold: 2  Epoch: 87  Training loss = 3.0916  Validation loss = 3.0680  \n",
      "\n",
      "Fold: 2  Epoch: 88  Training loss = 3.0914  Validation loss = 3.0677  \n",
      "\n",
      "Fold: 2  Epoch: 89  Training loss = 3.0912  Validation loss = 3.0674  \n",
      "\n",
      "Fold: 2  Epoch: 90  Training loss = 3.0909  Validation loss = 3.0670  \n",
      "\n",
      "Fold: 2  Epoch: 91  Training loss = 3.0907  Validation loss = 3.0667  \n",
      "\n",
      "Fold: 2  Epoch: 92  Training loss = 3.0905  Validation loss = 3.0664  \n",
      "\n",
      "Fold: 2  Epoch: 93  Training loss = 3.0902  Validation loss = 3.0661  \n",
      "\n",
      "Fold: 2  Epoch: 94  Training loss = 3.0900  Validation loss = 3.0657  \n",
      "\n",
      "Fold: 2  Epoch: 95  Training loss = 3.0897  Validation loss = 3.0654  \n",
      "\n",
      "Fold: 2  Epoch: 96  Training loss = 3.0895  Validation loss = 3.0651  \n",
      "\n",
      "Fold: 2  Epoch: 97  Training loss = 3.0893  Validation loss = 3.0647  \n",
      "\n",
      "Fold: 2  Epoch: 98  Training loss = 3.0891  Validation loss = 3.0645  \n",
      "\n",
      "Fold: 2  Epoch: 99  Training loss = 3.0889  Validation loss = 3.0641  \n",
      "\n",
      "Fold: 2  Epoch: 100  Training loss = 3.0886  Validation loss = 3.0638  \n",
      "\n",
      "Fold: 2  Epoch: 101  Training loss = 3.0884  Validation loss = 3.0635  \n",
      "\n",
      "Fold: 2  Epoch: 102  Training loss = 3.0881  Validation loss = 3.0631  \n",
      "\n",
      "Fold: 2  Epoch: 103  Training loss = 3.0879  Validation loss = 3.0628  \n",
      "\n",
      "Fold: 2  Epoch: 104  Training loss = 3.0877  Validation loss = 3.0626  \n",
      "\n",
      "Fold: 2  Epoch: 105  Training loss = 3.0874  Validation loss = 3.0622  \n",
      "\n",
      "Fold: 2  Epoch: 106  Training loss = 3.0872  Validation loss = 3.0619  \n",
      "\n",
      "Fold: 2  Epoch: 107  Training loss = 3.0870  Validation loss = 3.0616  \n",
      "\n",
      "Fold: 2  Epoch: 108  Training loss = 3.0868  Validation loss = 3.0613  \n",
      "\n",
      "Fold: 2  Epoch: 109  Training loss = 3.0866  Validation loss = 3.0610  \n",
      "\n",
      "Fold: 2  Epoch: 110  Training loss = 3.0863  Validation loss = 3.0607  \n",
      "\n",
      "Fold: 2  Epoch: 111  Training loss = 3.0861  Validation loss = 3.0603  \n",
      "\n",
      "Fold: 2  Epoch: 112  Training loss = 3.0859  Validation loss = 3.0601  \n",
      "\n",
      "Fold: 2  Epoch: 113  Training loss = 3.0856  Validation loss = 3.0597  \n",
      "\n",
      "Fold: 2  Epoch: 114  Training loss = 3.0854  Validation loss = 3.0594  \n",
      "\n",
      "Fold: 2  Epoch: 115  Training loss = 3.0852  Validation loss = 3.0591  \n",
      "\n",
      "Fold: 2  Epoch: 116  Training loss = 3.0850  Validation loss = 3.0588  \n",
      "\n",
      "Fold: 2  Epoch: 117  Training loss = 3.0847  Validation loss = 3.0584  \n",
      "\n",
      "Fold: 2  Epoch: 118  Training loss = 3.0844  Validation loss = 3.0581  \n",
      "\n",
      "Fold: 2  Epoch: 119  Training loss = 3.0843  Validation loss = 3.0578  \n",
      "\n",
      "Fold: 2  Epoch: 120  Training loss = 3.0841  Validation loss = 3.0575  \n",
      "\n",
      "Fold: 2  Epoch: 121  Training loss = 3.0839  Validation loss = 3.0573  \n",
      "\n",
      "Fold: 2  Epoch: 122  Training loss = 3.0837  Validation loss = 3.0570  \n",
      "\n",
      "Fold: 2  Epoch: 123  Training loss = 3.0834  Validation loss = 3.0566  \n",
      "\n",
      "Fold: 2  Epoch: 124  Training loss = 3.0832  Validation loss = 3.0563  \n",
      "\n",
      "Fold: 2  Epoch: 125  Training loss = 3.0830  Validation loss = 3.0560  \n",
      "\n",
      "Fold: 2  Epoch: 126  Training loss = 3.0828  Validation loss = 3.0557  \n",
      "\n",
      "Fold: 2  Epoch: 127  Training loss = 3.0825  Validation loss = 3.0553  \n",
      "\n",
      "Fold: 2  Epoch: 128  Training loss = 3.0823  Validation loss = 3.0550  \n",
      "\n",
      "Fold: 2  Epoch: 129  Training loss = 3.0821  Validation loss = 3.0548  \n",
      "\n",
      "Fold: 2  Epoch: 130  Training loss = 3.0818  Validation loss = 3.0544  \n",
      "\n",
      "Fold: 2  Epoch: 131  Training loss = 3.0816  Validation loss = 3.0541  \n",
      "\n",
      "Fold: 2  Epoch: 132  Training loss = 3.0814  Validation loss = 3.0538  \n",
      "\n",
      "Fold: 2  Epoch: 133  Training loss = 3.0812  Validation loss = 3.0535  \n",
      "\n",
      "Fold: 2  Epoch: 134  Training loss = 3.0810  Validation loss = 3.0532  \n",
      "\n",
      "Fold: 2  Epoch: 135  Training loss = 3.0808  Validation loss = 3.0530  \n",
      "\n",
      "Fold: 2  Epoch: 136  Training loss = 3.0806  Validation loss = 3.0526  \n",
      "\n",
      "Fold: 2  Epoch: 137  Training loss = 3.0802  Validation loss = 3.0522  \n",
      "\n",
      "Fold: 2  Epoch: 138  Training loss = 3.0799  Validation loss = 3.0518  \n",
      "\n",
      "Fold: 2  Epoch: 139  Training loss = 3.0797  Validation loss = 3.0515  \n",
      "\n",
      "Fold: 2  Epoch: 140  Training loss = 3.0794  Validation loss = 3.0511  \n",
      "\n",
      "Fold: 2  Epoch: 141  Training loss = 3.0793  Validation loss = 3.0509  \n",
      "\n",
      "Fold: 2  Epoch: 142  Training loss = 3.0790  Validation loss = 3.0505  \n",
      "\n",
      "Fold: 2  Epoch: 143  Training loss = 3.0789  Validation loss = 3.0503  \n",
      "\n",
      "Fold: 2  Epoch: 144  Training loss = 3.0787  Validation loss = 3.0500  \n",
      "\n",
      "Fold: 2  Epoch: 145  Training loss = 3.0785  Validation loss = 3.0498  \n",
      "\n",
      "Fold: 2  Epoch: 146  Training loss = 3.0783  Validation loss = 3.0494  \n",
      "\n",
      "Fold: 2  Epoch: 147  Training loss = 3.0781  Validation loss = 3.0491  \n",
      "\n",
      "Fold: 2  Epoch: 148  Training loss = 3.0779  Validation loss = 3.0488  \n",
      "\n",
      "Fold: 2  Epoch: 149  Training loss = 3.0777  Validation loss = 3.0485  \n",
      "\n",
      "Fold: 2  Epoch: 150  Training loss = 3.0774  Validation loss = 3.0482  \n",
      "\n",
      "Fold: 2  Epoch: 151  Training loss = 3.0772  Validation loss = 3.0479  \n",
      "\n",
      "Fold: 2  Epoch: 152  Training loss = 3.0771  Validation loss = 3.0476  \n",
      "\n",
      "Fold: 2  Epoch: 153  Training loss = 3.0768  Validation loss = 3.0473  \n",
      "\n",
      "Fold: 2  Epoch: 154  Training loss = 3.0766  Validation loss = 3.0470  \n",
      "\n",
      "Fold: 2  Epoch: 155  Training loss = 3.0764  Validation loss = 3.0467  \n",
      "\n",
      "Fold: 2  Epoch: 156  Training loss = 3.0762  Validation loss = 3.0464  \n",
      "\n",
      "Fold: 2  Epoch: 157  Training loss = 3.0760  Validation loss = 3.0461  \n",
      "\n",
      "Fold: 2  Epoch: 158  Training loss = 3.0758  Validation loss = 3.0458  \n",
      "\n",
      "Fold: 2  Epoch: 159  Training loss = 3.0756  Validation loss = 3.0455  \n",
      "\n",
      "Fold: 2  Epoch: 160  Training loss = 3.0754  Validation loss = 3.0452  \n",
      "\n",
      "Fold: 2  Epoch: 161  Training loss = 3.0752  Validation loss = 3.0448  \n",
      "\n",
      "Fold: 2  Epoch: 162  Training loss = 3.0749  Validation loss = 3.0445  \n",
      "\n",
      "Fold: 2  Epoch: 163  Training loss = 3.0747  Validation loss = 3.0442  \n",
      "\n",
      "Fold: 2  Epoch: 164  Training loss = 3.0744  Validation loss = 3.0439  \n",
      "\n",
      "Fold: 2  Epoch: 165  Training loss = 3.0742  Validation loss = 3.0436  \n",
      "\n",
      "Fold: 2  Epoch: 166  Training loss = 3.0740  Validation loss = 3.0433  \n",
      "\n",
      "Fold: 2  Epoch: 167  Training loss = 3.0738  Validation loss = 3.0430  \n",
      "\n",
      "Fold: 2  Epoch: 168  Training loss = 3.0736  Validation loss = 3.0426  \n",
      "\n",
      "Fold: 2  Epoch: 169  Training loss = 3.0733  Validation loss = 3.0423  \n",
      "\n",
      "Fold: 2  Epoch: 170  Training loss = 3.0731  Validation loss = 3.0420  \n",
      "\n",
      "Fold: 2  Epoch: 171  Training loss = 3.0730  Validation loss = 3.0417  \n",
      "\n",
      "Fold: 2  Epoch: 172  Training loss = 3.0727  Validation loss = 3.0414  \n",
      "\n",
      "Fold: 2  Epoch: 173  Training loss = 3.0725  Validation loss = 3.0411  \n",
      "\n",
      "Fold: 2  Epoch: 174  Training loss = 3.0724  Validation loss = 3.0409  \n",
      "\n",
      "Fold: 2  Epoch: 175  Training loss = 3.0721  Validation loss = 3.0405  \n",
      "\n",
      "Fold: 2  Epoch: 176  Training loss = 3.0718  Validation loss = 3.0402  \n",
      "\n",
      "Fold: 2  Epoch: 177  Training loss = 3.0717  Validation loss = 3.0399  \n",
      "\n",
      "Fold: 2  Epoch: 178  Training loss = 3.0714  Validation loss = 3.0396  \n",
      "\n",
      "Fold: 2  Epoch: 179  Training loss = 3.0712  Validation loss = 3.0393  \n",
      "\n",
      "Fold: 2  Epoch: 180  Training loss = 3.0710  Validation loss = 3.0390  \n",
      "\n",
      "Fold: 2  Epoch: 181  Training loss = 3.0708  Validation loss = 3.0387  \n",
      "\n",
      "Fold: 2  Epoch: 182  Training loss = 3.0706  Validation loss = 3.0384  \n",
      "\n",
      "Fold: 2  Epoch: 183  Training loss = 3.0704  Validation loss = 3.0381  \n",
      "\n",
      "Fold: 2  Epoch: 184  Training loss = 3.0702  Validation loss = 3.0378  \n",
      "\n",
      "Fold: 2  Epoch: 185  Training loss = 3.0699  Validation loss = 3.0374  \n",
      "\n",
      "Fold: 2  Epoch: 186  Training loss = 3.0697  Validation loss = 3.0371  \n",
      "\n",
      "Fold: 2  Epoch: 187  Training loss = 3.0694  Validation loss = 3.0368  \n",
      "\n",
      "Fold: 2  Epoch: 188  Training loss = 3.0692  Validation loss = 3.0365  \n",
      "\n",
      "Fold: 2  Epoch: 189  Training loss = 3.0691  Validation loss = 3.0363  \n",
      "\n",
      "Fold: 2  Epoch: 190  Training loss = 3.0689  Validation loss = 3.0360  \n",
      "\n",
      "Fold: 2  Epoch: 191  Training loss = 3.0687  Validation loss = 3.0356  \n",
      "\n",
      "Fold: 2  Epoch: 192  Training loss = 3.0684  Validation loss = 3.0354  \n",
      "\n",
      "Fold: 2  Epoch: 193  Training loss = 3.0683  Validation loss = 3.0351  \n",
      "\n",
      "Fold: 2  Epoch: 194  Training loss = 3.0681  Validation loss = 3.0349  \n",
      "\n",
      "Fold: 2  Epoch: 195  Training loss = 3.0679  Validation loss = 3.0346  \n",
      "\n",
      "Fold: 2  Epoch: 196  Training loss = 3.0677  Validation loss = 3.0343  \n",
      "\n",
      "Fold: 2  Epoch: 197  Training loss = 3.0674  Validation loss = 3.0340  \n",
      "\n",
      "Fold: 2  Epoch: 198  Training loss = 3.0671  Validation loss = 3.0336  \n",
      "\n",
      "Fold: 2  Epoch: 199  Training loss = 3.0670  Validation loss = 3.0333  \n",
      "\n",
      "Fold: 2  Epoch: 200  Training loss = 3.0668  Validation loss = 3.0331  \n",
      "\n",
      "Fold: 2  Epoch: 201  Training loss = 3.0667  Validation loss = 3.0329  \n",
      "\n",
      "Fold: 2  Epoch: 202  Training loss = 3.0664  Validation loss = 3.0325  \n",
      "\n",
      "Fold: 2  Epoch: 203  Training loss = 3.0663  Validation loss = 3.0323  \n",
      "\n",
      "Fold: 2  Epoch: 204  Training loss = 3.0661  Validation loss = 3.0320  \n",
      "\n",
      "Fold: 2  Epoch: 205  Training loss = 3.0659  Validation loss = 3.0317  \n",
      "\n",
      "Fold: 2  Epoch: 206  Training loss = 3.0657  Validation loss = 3.0314  \n",
      "\n",
      "Fold: 2  Epoch: 207  Training loss = 3.0655  Validation loss = 3.0311  \n",
      "\n",
      "Fold: 2  Epoch: 208  Training loss = 3.0652  Validation loss = 3.0308  \n",
      "\n",
      "Fold: 2  Epoch: 209  Training loss = 3.0649  Validation loss = 3.0304  \n",
      "\n",
      "Fold: 2  Epoch: 210  Training loss = 3.0648  Validation loss = 3.0301  \n",
      "\n",
      "Fold: 2  Epoch: 211  Training loss = 3.0645  Validation loss = 3.0298  \n",
      "\n",
      "Fold: 2  Epoch: 212  Training loss = 3.0643  Validation loss = 3.0295  \n",
      "\n",
      "Fold: 2  Epoch: 213  Training loss = 3.0641  Validation loss = 3.0292  \n",
      "\n",
      "Fold: 2  Epoch: 214  Training loss = 3.0639  Validation loss = 3.0289  \n",
      "\n",
      "Fold: 2  Epoch: 215  Training loss = 3.0637  Validation loss = 3.0286  \n",
      "\n",
      "Fold: 2  Epoch: 216  Training loss = 3.0634  Validation loss = 3.0282  \n",
      "\n",
      "Fold: 2  Epoch: 217  Training loss = 3.0632  Validation loss = 3.0279  \n",
      "\n",
      "Fold: 2  Epoch: 218  Training loss = 3.0630  Validation loss = 3.0276  \n",
      "\n",
      "Fold: 2  Epoch: 219  Training loss = 3.0627  Validation loss = 3.0272  \n",
      "\n",
      "Fold: 2  Epoch: 220  Training loss = 3.0625  Validation loss = 3.0269  \n",
      "\n",
      "Fold: 2  Epoch: 221  Training loss = 3.0623  Validation loss = 3.0267  \n",
      "\n",
      "Fold: 2  Epoch: 222  Training loss = 3.0621  Validation loss = 3.0263  \n",
      "\n",
      "Fold: 2  Epoch: 223  Training loss = 3.0618  Validation loss = 3.0260  \n",
      "\n",
      "Fold: 2  Epoch: 224  Training loss = 3.0616  Validation loss = 3.0257  \n",
      "\n",
      "Fold: 2  Epoch: 225  Training loss = 3.0615  Validation loss = 3.0254  \n",
      "\n",
      "Fold: 2  Epoch: 226  Training loss = 3.0612  Validation loss = 3.0250  \n",
      "\n",
      "Fold: 2  Epoch: 227  Training loss = 3.0610  Validation loss = 3.0246  \n",
      "\n",
      "Fold: 2  Epoch: 228  Training loss = 3.0607  Validation loss = 3.0243  \n",
      "\n",
      "Fold: 2  Epoch: 229  Training loss = 3.0605  Validation loss = 3.0240  \n",
      "\n",
      "Fold: 2  Epoch: 230  Training loss = 3.0603  Validation loss = 3.0236  \n",
      "\n",
      "Fold: 2  Epoch: 231  Training loss = 3.0601  Validation loss = 3.0234  \n",
      "\n",
      "Fold: 2  Epoch: 232  Training loss = 3.0599  Validation loss = 3.0231  \n",
      "\n",
      "Fold: 2  Epoch: 233  Training loss = 3.0597  Validation loss = 3.0228  \n",
      "\n",
      "Fold: 2  Epoch: 234  Training loss = 3.0596  Validation loss = 3.0226  \n",
      "\n",
      "Fold: 2  Epoch: 235  Training loss = 3.0593  Validation loss = 3.0222  \n",
      "\n",
      "Fold: 2  Epoch: 236  Training loss = 3.0591  Validation loss = 3.0219  \n",
      "\n",
      "Fold: 2  Epoch: 237  Training loss = 3.0589  Validation loss = 3.0216  \n",
      "\n",
      "Fold: 2  Epoch: 238  Training loss = 3.0587  Validation loss = 3.0213  \n",
      "\n",
      "Fold: 2  Epoch: 239  Training loss = 3.0584  Validation loss = 3.0209  \n",
      "\n",
      "Fold: 2  Epoch: 240  Training loss = 3.0581  Validation loss = 3.0205  \n",
      "\n",
      "Fold: 2  Epoch: 241  Training loss = 3.0579  Validation loss = 3.0202  \n",
      "\n",
      "Fold: 2  Epoch: 242  Training loss = 3.0578  Validation loss = 3.0200  \n",
      "\n",
      "Fold: 2  Epoch: 243  Training loss = 3.0576  Validation loss = 3.0197  \n",
      "\n",
      "Fold: 2  Epoch: 244  Training loss = 3.0573  Validation loss = 3.0193  \n",
      "\n",
      "Fold: 2  Epoch: 245  Training loss = 3.0571  Validation loss = 3.0190  \n",
      "\n",
      "Fold: 2  Epoch: 246  Training loss = 3.0569  Validation loss = 3.0187  \n",
      "\n",
      "Fold: 2  Epoch: 247  Training loss = 3.0566  Validation loss = 3.0183  \n",
      "\n",
      "Fold: 2  Epoch: 248  Training loss = 3.0564  Validation loss = 3.0180  \n",
      "\n",
      "Fold: 2  Epoch: 249  Training loss = 3.0562  Validation loss = 3.0177  \n",
      "\n",
      "Fold: 2  Epoch: 250  Training loss = 3.0560  Validation loss = 3.0174  \n",
      "\n",
      "Fold: 2  Epoch: 251  Training loss = 3.0558  Validation loss = 3.0171  \n",
      "\n",
      "Fold: 2  Epoch: 252  Training loss = 3.0556  Validation loss = 3.0168  \n",
      "\n",
      "Fold: 2  Epoch: 253  Training loss = 3.0552  Validation loss = 3.0164  \n",
      "\n",
      "Fold: 2  Epoch: 254  Training loss = 3.0550  Validation loss = 3.0160  \n",
      "\n",
      "Fold: 2  Epoch: 255  Training loss = 3.0547  Validation loss = 3.0157  \n",
      "\n",
      "Fold: 2  Epoch: 256  Training loss = 3.0545  Validation loss = 3.0154  \n",
      "\n",
      "Fold: 2  Epoch: 257  Training loss = 3.0543  Validation loss = 3.0151  \n",
      "\n",
      "Fold: 2  Epoch: 258  Training loss = 3.0542  Validation loss = 3.0149  \n",
      "\n",
      "Fold: 2  Epoch: 259  Training loss = 3.0540  Validation loss = 3.0146  \n",
      "\n",
      "Fold: 2  Epoch: 260  Training loss = 3.0538  Validation loss = 3.0143  \n",
      "\n",
      "Fold: 2  Epoch: 261  Training loss = 3.0536  Validation loss = 3.0140  \n",
      "\n",
      "Fold: 2  Epoch: 262  Training loss = 3.0533  Validation loss = 3.0137  \n",
      "\n",
      "Fold: 2  Epoch: 263  Training loss = 3.0531  Validation loss = 3.0133  \n",
      "\n",
      "Fold: 2  Epoch: 264  Training loss = 3.0529  Validation loss = 3.0130  \n",
      "\n",
      "Fold: 2  Epoch: 265  Training loss = 3.0527  Validation loss = 3.0128  \n",
      "\n",
      "Fold: 2  Epoch: 266  Training loss = 3.0525  Validation loss = 3.0124  \n",
      "\n",
      "Fold: 2  Epoch: 267  Training loss = 3.0522  Validation loss = 3.0121  \n",
      "\n",
      "Fold: 2  Epoch: 268  Training loss = 3.0519  Validation loss = 3.0118  \n",
      "\n",
      "Fold: 2  Epoch: 269  Training loss = 3.0517  Validation loss = 3.0114  \n",
      "\n",
      "Fold: 2  Epoch: 270  Training loss = 3.0515  Validation loss = 3.0111  \n",
      "\n",
      "Fold: 2  Epoch: 271  Training loss = 3.0513  Validation loss = 3.0109  \n",
      "\n",
      "Fold: 2  Epoch: 272  Training loss = 3.0511  Validation loss = 3.0106  \n",
      "\n",
      "Fold: 2  Epoch: 273  Training loss = 3.0510  Validation loss = 3.0104  \n",
      "\n",
      "Fold: 2  Epoch: 274  Training loss = 3.0508  Validation loss = 3.0101  \n",
      "\n",
      "Fold: 2  Epoch: 275  Training loss = 3.0506  Validation loss = 3.0098  \n",
      "\n",
      "Fold: 2  Epoch: 276  Training loss = 3.0505  Validation loss = 3.0096  \n",
      "\n",
      "Fold: 2  Epoch: 277  Training loss = 3.0502  Validation loss = 3.0093  \n",
      "\n",
      "Fold: 2  Epoch: 278  Training loss = 3.0499  Validation loss = 3.0089  \n",
      "\n",
      "Fold: 2  Epoch: 279  Training loss = 3.0497  Validation loss = 3.0086  \n",
      "\n",
      "Fold: 2  Epoch: 280  Training loss = 3.0494  Validation loss = 3.0082  \n",
      "\n",
      "Fold: 2  Epoch: 281  Training loss = 3.0492  Validation loss = 3.0079  \n",
      "\n",
      "Fold: 2  Epoch: 282  Training loss = 3.0490  Validation loss = 3.0076  \n",
      "\n",
      "Fold: 2  Epoch: 283  Training loss = 3.0488  Validation loss = 3.0073  \n",
      "\n",
      "Fold: 2  Epoch: 284  Training loss = 3.0485  Validation loss = 3.0069  \n",
      "\n",
      "Fold: 2  Epoch: 285  Training loss = 3.0483  Validation loss = 3.0066  \n",
      "\n",
      "Fold: 2  Epoch: 286  Training loss = 3.0481  Validation loss = 3.0064  \n",
      "\n",
      "Fold: 2  Epoch: 287  Training loss = 3.0479  Validation loss = 3.0061  \n",
      "\n",
      "Fold: 2  Epoch: 288  Training loss = 3.0477  Validation loss = 3.0057  \n",
      "\n",
      "Fold: 2  Epoch: 289  Training loss = 3.0475  Validation loss = 3.0055  \n",
      "\n",
      "Fold: 2  Epoch: 290  Training loss = 3.0473  Validation loss = 3.0052  \n",
      "\n",
      "Fold: 2  Epoch: 291  Training loss = 3.0472  Validation loss = 3.0049  \n",
      "\n",
      "Fold: 2  Epoch: 292  Training loss = 3.0470  Validation loss = 3.0047  \n",
      "\n",
      "Fold: 2  Epoch: 293  Training loss = 3.0467  Validation loss = 3.0043  \n",
      "\n",
      "Fold: 2  Epoch: 294  Training loss = 3.0466  Validation loss = 3.0041  \n",
      "\n",
      "Fold: 2  Epoch: 295  Training loss = 3.0464  Validation loss = 3.0038  \n",
      "\n",
      "Fold: 2  Epoch: 296  Training loss = 3.0462  Validation loss = 3.0035  \n",
      "\n",
      "Fold: 2  Epoch: 297  Training loss = 3.0460  Validation loss = 3.0033  \n",
      "\n",
      "Fold: 2  Epoch: 298  Training loss = 3.0458  Validation loss = 3.0029  \n",
      "\n",
      "Fold: 2  Epoch: 299  Training loss = 3.0456  Validation loss = 3.0027  \n",
      "\n",
      "Fold: 2  Epoch: 300  Training loss = 3.0454  Validation loss = 3.0024  \n",
      "\n",
      "Fold: 2  Epoch: 301  Training loss = 3.0452  Validation loss = 3.0021  \n",
      "\n",
      "Fold: 2  Epoch: 302  Training loss = 3.0450  Validation loss = 3.0019  \n",
      "\n",
      "Fold: 2  Epoch: 303  Training loss = 3.0448  Validation loss = 3.0016  \n",
      "\n",
      "Fold: 2  Epoch: 304  Training loss = 3.0446  Validation loss = 3.0012  \n",
      "\n",
      "Fold: 2  Epoch: 305  Training loss = 3.0443  Validation loss = 3.0008  \n",
      "\n",
      "Fold: 2  Epoch: 306  Training loss = 3.0441  Validation loss = 3.0005  \n",
      "\n",
      "Fold: 2  Epoch: 307  Training loss = 3.0439  Validation loss = 3.0003  \n",
      "\n",
      "Fold: 2  Epoch: 308  Training loss = 3.0437  Validation loss = 3.0000  \n",
      "\n",
      "Fold: 2  Epoch: 309  Training loss = 3.0435  Validation loss = 2.9997  \n",
      "\n",
      "Fold: 2  Epoch: 310  Training loss = 3.0434  Validation loss = 2.9995  \n",
      "\n",
      "Fold: 2  Epoch: 311  Training loss = 3.0432  Validation loss = 2.9992  \n",
      "\n",
      "Fold: 2  Epoch: 312  Training loss = 3.0430  Validation loss = 2.9988  \n",
      "\n",
      "Fold: 2  Epoch: 313  Training loss = 3.0427  Validation loss = 2.9985  \n",
      "\n",
      "Fold: 2  Epoch: 314  Training loss = 3.0425  Validation loss = 2.9983  \n",
      "\n",
      "Fold: 2  Epoch: 315  Training loss = 3.0423  Validation loss = 2.9980  \n",
      "\n",
      "Fold: 2  Epoch: 316  Training loss = 3.0422  Validation loss = 2.9977  \n",
      "\n",
      "Fold: 2  Epoch: 317  Training loss = 3.0419  Validation loss = 2.9974  \n",
      "\n",
      "Fold: 2  Epoch: 318  Training loss = 3.0417  Validation loss = 2.9970  \n",
      "\n",
      "Fold: 2  Epoch: 319  Training loss = 3.0415  Validation loss = 2.9967  \n",
      "\n",
      "Fold: 2  Epoch: 320  Training loss = 3.0413  Validation loss = 2.9964  \n",
      "\n",
      "Fold: 2  Epoch: 321  Training loss = 3.0410  Validation loss = 2.9960  \n",
      "\n",
      "Fold: 2  Epoch: 322  Training loss = 3.0408  Validation loss = 2.9958  \n",
      "\n",
      "Fold: 2  Epoch: 323  Training loss = 3.0406  Validation loss = 2.9954  \n",
      "\n",
      "Fold: 2  Epoch: 324  Training loss = 3.0404  Validation loss = 2.9952  \n",
      "\n",
      "Fold: 2  Epoch: 325  Training loss = 3.0402  Validation loss = 2.9949  \n",
      "\n",
      "Fold: 2  Epoch: 326  Training loss = 3.0400  Validation loss = 2.9945  \n",
      "\n",
      "Fold: 2  Epoch: 327  Training loss = 3.0398  Validation loss = 2.9942  \n",
      "\n",
      "Fold: 2  Epoch: 328  Training loss = 3.0396  Validation loss = 2.9939  \n",
      "\n",
      "Fold: 2  Epoch: 329  Training loss = 3.0394  Validation loss = 2.9937  \n",
      "\n",
      "Fold: 2  Epoch: 330  Training loss = 3.0392  Validation loss = 2.9934  \n",
      "\n",
      "Fold: 2  Epoch: 331  Training loss = 3.0389  Validation loss = 2.9930  \n",
      "\n",
      "Fold: 2  Epoch: 332  Training loss = 3.0386  Validation loss = 2.9926  \n",
      "\n",
      "Fold: 2  Epoch: 333  Training loss = 3.0384  Validation loss = 2.9924  \n",
      "\n",
      "Fold: 2  Epoch: 334  Training loss = 3.0382  Validation loss = 2.9920  \n",
      "\n",
      "Fold: 2  Epoch: 335  Training loss = 3.0379  Validation loss = 2.9916  \n",
      "\n",
      "Fold: 2  Epoch: 336  Training loss = 3.0377  Validation loss = 2.9913  \n",
      "\n",
      "Fold: 2  Epoch: 337  Training loss = 3.0375  Validation loss = 2.9910  \n",
      "\n",
      "Fold: 2  Epoch: 338  Training loss = 3.0373  Validation loss = 2.9907  \n",
      "\n",
      "Fold: 2  Epoch: 339  Training loss = 3.0370  Validation loss = 2.9904  \n",
      "\n",
      "Fold: 2  Epoch: 340  Training loss = 3.0369  Validation loss = 2.9901  \n",
      "\n",
      "Fold: 2  Epoch: 341  Training loss = 3.0365  Validation loss = 2.9896  \n",
      "\n",
      "Fold: 2  Epoch: 342  Training loss = 3.0362  Validation loss = 2.9892  \n",
      "\n",
      "Fold: 2  Epoch: 343  Training loss = 3.0360  Validation loss = 2.9889  \n",
      "\n",
      "Fold: 2  Epoch: 344  Training loss = 3.0359  Validation loss = 2.9887  \n",
      "\n",
      "Fold: 2  Epoch: 345  Training loss = 3.0356  Validation loss = 2.9883  \n",
      "\n",
      "Fold: 2  Epoch: 346  Training loss = 3.0354  Validation loss = 2.9880  \n",
      "\n",
      "Fold: 2  Epoch: 347  Training loss = 3.0352  Validation loss = 2.9877  \n",
      "\n",
      "Fold: 2  Epoch: 348  Training loss = 3.0350  Validation loss = 2.9874  \n",
      "\n",
      "Fold: 2  Epoch: 349  Training loss = 3.0348  Validation loss = 2.9871  \n",
      "\n",
      "Fold: 2  Epoch: 350  Training loss = 3.0346  Validation loss = 2.9868  \n",
      "\n",
      "Fold: 2  Epoch: 351  Training loss = 3.0344  Validation loss = 2.9866  \n",
      "\n",
      "Fold: 2  Epoch: 352  Training loss = 3.0342  Validation loss = 2.9863  \n",
      "\n",
      "Fold: 2  Epoch: 353  Training loss = 3.0340  Validation loss = 2.9860  \n",
      "\n",
      "Fold: 2  Epoch: 354  Training loss = 3.0338  Validation loss = 2.9857  \n",
      "\n",
      "Fold: 2  Epoch: 355  Training loss = 3.0336  Validation loss = 2.9854  \n",
      "\n",
      "Fold: 2  Epoch: 356  Training loss = 3.0334  Validation loss = 2.9852  \n",
      "\n",
      "Fold: 2  Epoch: 357  Training loss = 3.0333  Validation loss = 2.9849  \n",
      "\n",
      "Fold: 2  Epoch: 358  Training loss = 3.0330  Validation loss = 2.9845  \n",
      "\n",
      "Fold: 2  Epoch: 359  Training loss = 3.0328  Validation loss = 2.9842  \n",
      "\n",
      "Fold: 2  Epoch: 360  Training loss = 3.0326  Validation loss = 2.9839  \n",
      "\n",
      "Fold: 2  Epoch: 361  Training loss = 3.0324  Validation loss = 2.9836  \n",
      "\n",
      "Fold: 2  Epoch: 362  Training loss = 3.0322  Validation loss = 2.9832  \n",
      "\n",
      "Fold: 2  Epoch: 363  Training loss = 3.0319  Validation loss = 2.9829  \n",
      "\n",
      "Fold: 2  Epoch: 364  Training loss = 3.0318  Validation loss = 2.9826  \n",
      "\n",
      "Fold: 2  Epoch: 365  Training loss = 3.0315  Validation loss = 2.9823  \n",
      "\n",
      "Fold: 2  Epoch: 366  Training loss = 3.0313  Validation loss = 2.9820  \n",
      "\n",
      "Fold: 2  Epoch: 367  Training loss = 3.0311  Validation loss = 2.9818  \n",
      "\n",
      "Fold: 2  Epoch: 368  Training loss = 3.0310  Validation loss = 2.9815  \n",
      "\n",
      "Fold: 2  Epoch: 369  Training loss = 3.0308  Validation loss = 2.9813  \n",
      "\n",
      "Fold: 2  Epoch: 370  Training loss = 3.0306  Validation loss = 2.9809  \n",
      "\n",
      "Fold: 2  Epoch: 371  Training loss = 3.0305  Validation loss = 2.9808  \n",
      "\n",
      "Fold: 2  Epoch: 372  Training loss = 3.0303  Validation loss = 2.9805  \n",
      "\n",
      "Fold: 2  Epoch: 373  Training loss = 3.0301  Validation loss = 2.9802  \n",
      "\n",
      "Fold: 2  Epoch: 374  Training loss = 3.0299  Validation loss = 2.9800  \n",
      "\n",
      "Fold: 2  Epoch: 375  Training loss = 3.0297  Validation loss = 2.9797  \n",
      "\n",
      "Fold: 2  Epoch: 376  Training loss = 3.0295  Validation loss = 2.9793  \n",
      "\n",
      "Fold: 2  Epoch: 377  Training loss = 3.0294  Validation loss = 2.9791  \n",
      "\n",
      "Fold: 2  Epoch: 378  Training loss = 3.0292  Validation loss = 2.9789  \n",
      "\n",
      "Fold: 2  Epoch: 379  Training loss = 3.0290  Validation loss = 2.9786  \n",
      "\n",
      "Fold: 2  Epoch: 380  Training loss = 3.0288  Validation loss = 2.9783  \n",
      "\n",
      "Fold: 2  Epoch: 381  Training loss = 3.0286  Validation loss = 2.9780  \n",
      "\n",
      "Fold: 2  Epoch: 382  Training loss = 3.0284  Validation loss = 2.9777  \n",
      "\n",
      "Fold: 2  Epoch: 383  Training loss = 3.0282  Validation loss = 2.9774  \n",
      "\n",
      "Fold: 2  Epoch: 384  Training loss = 3.0280  Validation loss = 2.9770  \n",
      "\n",
      "Fold: 2  Epoch: 385  Training loss = 3.0277  Validation loss = 2.9766  \n",
      "\n",
      "Fold: 2  Epoch: 386  Training loss = 3.0275  Validation loss = 2.9764  \n",
      "\n",
      "Fold: 2  Epoch: 387  Training loss = 3.0273  Validation loss = 2.9761  \n",
      "\n",
      "Fold: 2  Epoch: 388  Training loss = 3.0271  Validation loss = 2.9758  \n",
      "\n",
      "Fold: 2  Epoch: 389  Training loss = 3.0269  Validation loss = 2.9755  \n",
      "\n",
      "Fold: 2  Epoch: 390  Training loss = 3.0267  Validation loss = 2.9752  \n",
      "\n",
      "Fold: 2  Epoch: 391  Training loss = 3.0265  Validation loss = 2.9750  \n",
      "\n",
      "Fold: 2  Epoch: 392  Training loss = 3.0263  Validation loss = 2.9746  \n",
      "\n",
      "Fold: 2  Epoch: 393  Training loss = 3.0260  Validation loss = 2.9743  \n",
      "\n",
      "Fold: 2  Epoch: 394  Training loss = 3.0258  Validation loss = 2.9739  \n",
      "\n",
      "Fold: 2  Epoch: 395  Training loss = 3.0256  Validation loss = 2.9737  \n",
      "\n",
      "Fold: 2  Epoch: 396  Training loss = 3.0254  Validation loss = 2.9734  \n",
      "\n",
      "Fold: 2  Epoch: 397  Training loss = 3.0252  Validation loss = 2.9730  \n",
      "\n",
      "Fold: 2  Epoch: 398  Training loss = 3.0249  Validation loss = 2.9727  \n",
      "\n",
      "Fold: 2  Epoch: 399  Training loss = 3.0248  Validation loss = 2.9724  \n",
      "\n",
      "Fold: 2  Epoch: 400  Training loss = 3.0246  Validation loss = 2.9721  \n",
      "\n",
      "Fold: 2  Epoch: 401  Training loss = 3.0244  Validation loss = 2.9719  \n",
      "\n",
      "Fold: 2  Epoch: 402  Training loss = 3.0242  Validation loss = 2.9717  \n",
      "\n",
      "Fold: 2  Epoch: 403  Training loss = 3.0239  Validation loss = 2.9712  \n",
      "\n",
      "Fold: 2  Epoch: 404  Training loss = 3.0237  Validation loss = 2.9709  \n",
      "\n",
      "Fold: 2  Epoch: 405  Training loss = 3.0235  Validation loss = 2.9707  \n",
      "\n",
      "Fold: 2  Epoch: 406  Training loss = 3.0233  Validation loss = 2.9704  \n",
      "\n",
      "Fold: 2  Epoch: 407  Training loss = 3.0231  Validation loss = 2.9700  \n",
      "\n",
      "Fold: 2  Epoch: 408  Training loss = 3.0230  Validation loss = 2.9698  \n",
      "\n",
      "Fold: 2  Epoch: 409  Training loss = 3.0227  Validation loss = 2.9695  \n",
      "\n",
      "Fold: 2  Epoch: 410  Training loss = 3.0225  Validation loss = 2.9692  \n",
      "\n",
      "Fold: 2  Epoch: 411  Training loss = 3.0223  Validation loss = 2.9688  \n",
      "\n",
      "Fold: 2  Epoch: 412  Training loss = 3.0221  Validation loss = 2.9686  \n",
      "\n",
      "Fold: 2  Epoch: 413  Training loss = 3.0219  Validation loss = 2.9683  \n",
      "\n",
      "Fold: 2  Epoch: 414  Training loss = 3.0216  Validation loss = 2.9679  \n",
      "\n",
      "Fold: 2  Epoch: 415  Training loss = 3.0215  Validation loss = 2.9677  \n",
      "\n",
      "Fold: 2  Epoch: 416  Training loss = 3.0212  Validation loss = 2.9673  \n",
      "\n",
      "Fold: 2  Epoch: 417  Training loss = 3.0210  Validation loss = 2.9670  \n",
      "\n",
      "Fold: 2  Epoch: 418  Training loss = 3.0208  Validation loss = 2.9667  \n",
      "\n",
      "Fold: 2  Epoch: 419  Training loss = 3.0206  Validation loss = 2.9664  \n",
      "\n",
      "Fold: 2  Epoch: 420  Training loss = 3.0204  Validation loss = 2.9661  \n",
      "\n",
      "Fold: 2  Epoch: 421  Training loss = 3.0202  Validation loss = 2.9659  \n",
      "\n",
      "Fold: 2  Epoch: 422  Training loss = 3.0200  Validation loss = 2.9656  \n",
      "\n",
      "Fold: 2  Epoch: 423  Training loss = 3.0198  Validation loss = 2.9653  \n",
      "\n",
      "Fold: 2  Epoch: 424  Training loss = 3.0196  Validation loss = 2.9650  \n",
      "\n",
      "Fold: 2  Epoch: 425  Training loss = 3.0194  Validation loss = 2.9647  \n",
      "\n",
      "Fold: 2  Epoch: 426  Training loss = 3.0192  Validation loss = 2.9644  \n",
      "\n",
      "Fold: 2  Epoch: 427  Training loss = 3.0190  Validation loss = 2.9641  \n",
      "\n",
      "Fold: 2  Epoch: 428  Training loss = 3.0188  Validation loss = 2.9639  \n",
      "\n",
      "Fold: 2  Epoch: 429  Training loss = 3.0186  Validation loss = 2.9635  \n",
      "\n",
      "Fold: 2  Epoch: 430  Training loss = 3.0184  Validation loss = 2.9632  \n",
      "\n",
      "Fold: 2  Epoch: 431  Training loss = 3.0183  Validation loss = 2.9630  \n",
      "\n",
      "Fold: 2  Epoch: 432  Training loss = 3.0181  Validation loss = 2.9628  \n",
      "\n",
      "Fold: 2  Epoch: 433  Training loss = 3.0179  Validation loss = 2.9625  \n",
      "\n",
      "Fold: 2  Epoch: 434  Training loss = 3.0178  Validation loss = 2.9623  \n",
      "\n",
      "Fold: 2  Epoch: 435  Training loss = 3.0177  Validation loss = 2.9621  \n",
      "\n",
      "Fold: 2  Epoch: 436  Training loss = 3.0175  Validation loss = 2.9618  \n",
      "\n",
      "Fold: 2  Epoch: 437  Training loss = 3.0172  Validation loss = 2.9615  \n",
      "\n",
      "Fold: 2  Epoch: 438  Training loss = 3.0171  Validation loss = 2.9612  \n",
      "\n",
      "Fold: 2  Epoch: 439  Training loss = 3.0168  Validation loss = 2.9609  \n",
      "\n",
      "Fold: 2  Epoch: 440  Training loss = 3.0167  Validation loss = 2.9607  \n",
      "\n",
      "Fold: 2  Epoch: 441  Training loss = 3.0164  Validation loss = 2.9603  \n",
      "\n",
      "Fold: 2  Epoch: 442  Training loss = 3.0163  Validation loss = 2.9600  \n",
      "\n",
      "Fold: 2  Epoch: 443  Training loss = 3.0161  Validation loss = 2.9598  \n",
      "\n",
      "Fold: 2  Epoch: 444  Training loss = 3.0159  Validation loss = 2.9596  \n",
      "\n",
      "Fold: 2  Epoch: 445  Training loss = 3.0157  Validation loss = 2.9593  \n",
      "\n",
      "Fold: 2  Epoch: 446  Training loss = 3.0156  Validation loss = 2.9590  \n",
      "\n",
      "Fold: 2  Epoch: 447  Training loss = 3.0154  Validation loss = 2.9587  \n",
      "\n",
      "Fold: 2  Epoch: 448  Training loss = 3.0152  Validation loss = 2.9585  \n",
      "\n",
      "Fold: 2  Epoch: 449  Training loss = 3.0150  Validation loss = 2.9582  \n",
      "\n",
      "Fold: 2  Epoch: 450  Training loss = 3.0149  Validation loss = 2.9580  \n",
      "\n",
      "Fold: 2  Epoch: 451  Training loss = 3.0147  Validation loss = 2.9577  \n",
      "\n",
      "Fold: 2  Epoch: 452  Training loss = 3.0144  Validation loss = 2.9574  \n",
      "\n",
      "Fold: 2  Epoch: 453  Training loss = 3.0142  Validation loss = 2.9571  \n",
      "\n",
      "Fold: 2  Epoch: 454  Training loss = 3.0140  Validation loss = 2.9568  \n",
      "\n",
      "Fold: 2  Epoch: 455  Training loss = 3.0138  Validation loss = 2.9565  \n",
      "\n",
      "Fold: 2  Epoch: 456  Training loss = 3.0136  Validation loss = 2.9561  \n",
      "\n",
      "Fold: 2  Epoch: 457  Training loss = 3.0134  Validation loss = 2.9559  \n",
      "\n",
      "Fold: 2  Epoch: 458  Training loss = 3.0132  Validation loss = 2.9556  \n",
      "\n",
      "Fold: 2  Epoch: 459  Training loss = 3.0129  Validation loss = 2.9552  \n",
      "\n",
      "Fold: 2  Epoch: 460  Training loss = 3.0127  Validation loss = 2.9550  \n",
      "\n",
      "Fold: 2  Epoch: 461  Training loss = 3.0126  Validation loss = 2.9548  \n",
      "\n",
      "Fold: 2  Epoch: 462  Training loss = 3.0125  Validation loss = 2.9546  \n",
      "\n",
      "Fold: 2  Epoch: 463  Training loss = 3.0123  Validation loss = 2.9543  \n",
      "\n",
      "Fold: 2  Epoch: 464  Training loss = 3.0121  Validation loss = 2.9540  \n",
      "\n",
      "Fold: 2  Epoch: 465  Training loss = 3.0119  Validation loss = 2.9537  \n",
      "\n",
      "Fold: 2  Epoch: 466  Training loss = 3.0117  Validation loss = 2.9535  \n",
      "\n",
      "Fold: 2  Epoch: 467  Training loss = 3.0115  Validation loss = 2.9531  \n",
      "\n",
      "Fold: 2  Epoch: 468  Training loss = 3.0112  Validation loss = 2.9528  \n",
      "\n",
      "Fold: 2  Epoch: 469  Training loss = 3.0111  Validation loss = 2.9525  \n",
      "\n",
      "Fold: 2  Epoch: 470  Training loss = 3.0109  Validation loss = 2.9522  \n",
      "\n",
      "Fold: 2  Epoch: 471  Training loss = 3.0107  Validation loss = 2.9519  \n",
      "\n",
      "Fold: 2  Epoch: 472  Training loss = 3.0105  Validation loss = 2.9516  \n",
      "\n",
      "Fold: 2  Epoch: 473  Training loss = 3.0102  Validation loss = 2.9513  \n",
      "\n",
      "Fold: 2  Epoch: 474  Training loss = 3.0100  Validation loss = 2.9510  \n",
      "\n",
      "Fold: 2  Epoch: 475  Training loss = 3.0098  Validation loss = 2.9507  \n",
      "\n",
      "Fold: 2  Epoch: 476  Training loss = 3.0096  Validation loss = 2.9504  \n",
      "\n",
      "Fold: 2  Epoch: 477  Training loss = 3.0094  Validation loss = 2.9501  \n",
      "\n",
      "Fold: 2  Epoch: 478  Training loss = 3.0092  Validation loss = 2.9499  \n",
      "\n",
      "Fold: 2  Epoch: 479  Training loss = 3.0090  Validation loss = 2.9496  \n",
      "\n",
      "Fold: 2  Epoch: 480  Training loss = 3.0089  Validation loss = 2.9493  \n",
      "\n",
      "Fold: 2  Epoch: 481  Training loss = 3.0086  Validation loss = 2.9489  \n",
      "\n",
      "Fold: 2  Epoch: 482  Training loss = 3.0083  Validation loss = 2.9485  \n",
      "\n",
      "Fold: 2  Epoch: 483  Training loss = 3.0082  Validation loss = 2.9483  \n",
      "\n",
      "Fold: 2  Epoch: 484  Training loss = 3.0080  Validation loss = 2.9481  \n",
      "\n",
      "Fold: 2  Epoch: 485  Training loss = 3.0078  Validation loss = 2.9478  \n",
      "\n",
      "Fold: 2  Epoch: 486  Training loss = 3.0076  Validation loss = 2.9475  \n",
      "\n",
      "Fold: 2  Epoch: 487  Training loss = 3.0075  Validation loss = 2.9472  \n",
      "\n",
      "Fold: 2  Epoch: 488  Training loss = 3.0073  Validation loss = 2.9470  \n",
      "\n",
      "Fold: 2  Epoch: 489  Training loss = 3.0071  Validation loss = 2.9467  \n",
      "\n",
      "Fold: 2  Epoch: 490  Training loss = 3.0070  Validation loss = 2.9464  \n",
      "\n",
      "Fold: 2  Epoch: 491  Training loss = 3.0067  Validation loss = 2.9461  \n",
      "\n",
      "Fold: 2  Epoch: 492  Training loss = 3.0065  Validation loss = 2.9459  \n",
      "\n",
      "Fold: 2  Epoch: 493  Training loss = 3.0063  Validation loss = 2.9456  \n",
      "\n",
      "Fold: 2  Epoch: 494  Training loss = 3.0061  Validation loss = 2.9453  \n",
      "\n",
      "Fold: 2  Epoch: 495  Training loss = 3.0060  Validation loss = 2.9450  \n",
      "\n",
      "Fold: 2  Epoch: 496  Training loss = 3.0057  Validation loss = 2.9447  \n",
      "\n",
      "Fold: 2  Epoch: 497  Training loss = 3.0054  Validation loss = 2.9443  \n",
      "\n",
      "Fold: 2  Epoch: 498  Training loss = 3.0052  Validation loss = 2.9439  \n",
      "\n",
      "Fold: 2  Epoch: 499  Training loss = 3.0049  Validation loss = 2.9436  \n",
      "\n",
      "Fold: 2  Epoch: 500  Training loss = 3.0047  Validation loss = 2.9433  \n",
      "\n",
      "Check model:  Fold: 2  Epoch: 500  Training loss = 3.0047  Validation loss = 2.9433  \n",
      "\n",
      "Fold: 3  Epoch: 1  Training loss = 2.0014  Validation loss = 4.2135  \n",
      "\n",
      "Fold: 3  Epoch: 2  Training loss = 2.0012  Validation loss = 4.2132  \n",
      "\n",
      "Fold: 3  Epoch: 3  Training loss = 2.0010  Validation loss = 4.2129  \n",
      "\n",
      "Fold: 3  Epoch: 4  Training loss = 2.0008  Validation loss = 4.2127  \n",
      "\n",
      "Fold: 3  Epoch: 5  Training loss = 2.0006  Validation loss = 4.2124  \n",
      "\n",
      "Fold: 3  Epoch: 6  Training loss = 2.0004  Validation loss = 4.2122  \n",
      "\n",
      "Fold: 3  Epoch: 7  Training loss = 2.0002  Validation loss = 4.2118  \n",
      "\n",
      "Fold: 3  Epoch: 8  Training loss = 1.9999  Validation loss = 4.2115  \n",
      "\n",
      "Fold: 3  Epoch: 9  Training loss = 1.9997  Validation loss = 4.2112  \n",
      "\n",
      "Fold: 3  Epoch: 10  Training loss = 1.9995  Validation loss = 4.2109  \n",
      "\n",
      "Fold: 3  Epoch: 11  Training loss = 1.9994  Validation loss = 4.2107  \n",
      "\n",
      "Fold: 3  Epoch: 12  Training loss = 1.9991  Validation loss = 4.2104  \n",
      "\n",
      "Fold: 3  Epoch: 13  Training loss = 1.9989  Validation loss = 4.2100  \n",
      "\n",
      "Fold: 3  Epoch: 14  Training loss = 1.9987  Validation loss = 4.2098  \n",
      "\n",
      "Fold: 3  Epoch: 15  Training loss = 1.9985  Validation loss = 4.2095  \n",
      "\n",
      "Fold: 3  Epoch: 16  Training loss = 1.9983  Validation loss = 4.2093  \n",
      "\n",
      "Fold: 3  Epoch: 17  Training loss = 1.9982  Validation loss = 4.2091  \n",
      "\n",
      "Fold: 3  Epoch: 18  Training loss = 1.9980  Validation loss = 4.2088  \n",
      "\n",
      "Fold: 3  Epoch: 19  Training loss = 1.9978  Validation loss = 4.2086  \n",
      "\n",
      "Fold: 3  Epoch: 20  Training loss = 1.9976  Validation loss = 4.2083  \n",
      "\n",
      "Fold: 3  Epoch: 21  Training loss = 1.9974  Validation loss = 4.2081  \n",
      "\n",
      "Fold: 3  Epoch: 22  Training loss = 1.9972  Validation loss = 4.2078  \n",
      "\n",
      "Fold: 3  Epoch: 23  Training loss = 1.9970  Validation loss = 4.2075  \n",
      "\n",
      "Fold: 3  Epoch: 24  Training loss = 1.9968  Validation loss = 4.2073  \n",
      "\n",
      "Fold: 3  Epoch: 25  Training loss = 1.9966  Validation loss = 4.2070  \n",
      "\n",
      "Fold: 3  Epoch: 26  Training loss = 1.9964  Validation loss = 4.2068  \n",
      "\n",
      "Fold: 3  Epoch: 27  Training loss = 1.9963  Validation loss = 4.2066  \n",
      "\n",
      "Fold: 3  Epoch: 28  Training loss = 1.9961  Validation loss = 4.2063  \n",
      "\n",
      "Fold: 3  Epoch: 29  Training loss = 1.9959  Validation loss = 4.2061  \n",
      "\n",
      "Fold: 3  Epoch: 30  Training loss = 1.9957  Validation loss = 4.2058  \n",
      "\n",
      "Fold: 3  Epoch: 31  Training loss = 1.9955  Validation loss = 4.2056  \n",
      "\n",
      "Fold: 3  Epoch: 32  Training loss = 1.9954  Validation loss = 4.2054  \n",
      "\n",
      "Fold: 3  Epoch: 33  Training loss = 1.9952  Validation loss = 4.2051  \n",
      "\n",
      "Fold: 3  Epoch: 34  Training loss = 1.9950  Validation loss = 4.2049  \n",
      "\n",
      "Fold: 3  Epoch: 35  Training loss = 1.9948  Validation loss = 4.2046  \n",
      "\n",
      "Fold: 3  Epoch: 36  Training loss = 1.9946  Validation loss = 4.2043  \n",
      "\n",
      "Fold: 3  Epoch: 37  Training loss = 1.9944  Validation loss = 4.2040  \n",
      "\n",
      "Fold: 3  Epoch: 38  Training loss = 1.9942  Validation loss = 4.2038  \n",
      "\n",
      "Fold: 3  Epoch: 39  Training loss = 1.9940  Validation loss = 4.2035  \n",
      "\n",
      "Fold: 3  Epoch: 40  Training loss = 1.9938  Validation loss = 4.2033  \n",
      "\n",
      "Fold: 3  Epoch: 41  Training loss = 1.9936  Validation loss = 4.2029  \n",
      "\n",
      "Fold: 3  Epoch: 42  Training loss = 1.9933  Validation loss = 4.2026  \n",
      "\n",
      "Fold: 3  Epoch: 43  Training loss = 1.9931  Validation loss = 4.2023  \n",
      "\n",
      "Fold: 3  Epoch: 44  Training loss = 1.9929  Validation loss = 4.2021  \n",
      "\n",
      "Fold: 3  Epoch: 45  Training loss = 1.9927  Validation loss = 4.2018  \n",
      "\n",
      "Fold: 3  Epoch: 46  Training loss = 1.9925  Validation loss = 4.2015  \n",
      "\n",
      "Fold: 3  Epoch: 47  Training loss = 1.9923  Validation loss = 4.2012  \n",
      "\n",
      "Fold: 3  Epoch: 48  Training loss = 1.9921  Validation loss = 4.2010  \n",
      "\n",
      "Fold: 3  Epoch: 49  Training loss = 1.9919  Validation loss = 4.2007  \n",
      "\n",
      "Fold: 3  Epoch: 50  Training loss = 1.9917  Validation loss = 4.2004  \n",
      "\n",
      "Fold: 3  Epoch: 51  Training loss = 1.9915  Validation loss = 4.2001  \n",
      "\n",
      "Fold: 3  Epoch: 52  Training loss = 1.9913  Validation loss = 4.1998  \n",
      "\n",
      "Fold: 3  Epoch: 53  Training loss = 1.9910  Validation loss = 4.1995  \n",
      "\n",
      "Fold: 3  Epoch: 54  Training loss = 1.9909  Validation loss = 4.1993  \n",
      "\n",
      "Fold: 3  Epoch: 55  Training loss = 1.9907  Validation loss = 4.1990  \n",
      "\n",
      "Fold: 3  Epoch: 56  Training loss = 1.9905  Validation loss = 4.1987  \n",
      "\n",
      "Fold: 3  Epoch: 57  Training loss = 1.9903  Validation loss = 4.1985  \n",
      "\n",
      "Fold: 3  Epoch: 58  Training loss = 1.9901  Validation loss = 4.1982  \n",
      "\n",
      "Fold: 3  Epoch: 59  Training loss = 1.9899  Validation loss = 4.1979  \n",
      "\n",
      "Fold: 3  Epoch: 60  Training loss = 1.9897  Validation loss = 4.1977  \n",
      "\n",
      "Fold: 3  Epoch: 61  Training loss = 1.9895  Validation loss = 4.1975  \n",
      "\n",
      "Fold: 3  Epoch: 62  Training loss = 1.9893  Validation loss = 4.1972  \n",
      "\n",
      "Fold: 3  Epoch: 63  Training loss = 1.9891  Validation loss = 4.1969  \n",
      "\n",
      "Fold: 3  Epoch: 64  Training loss = 1.9890  Validation loss = 4.1967  \n",
      "\n",
      "Fold: 3  Epoch: 65  Training loss = 1.9887  Validation loss = 4.1964  \n",
      "\n",
      "Fold: 3  Epoch: 66  Training loss = 1.9885  Validation loss = 4.1961  \n",
      "\n",
      "Fold: 3  Epoch: 67  Training loss = 1.9883  Validation loss = 4.1959  \n",
      "\n",
      "Fold: 3  Epoch: 68  Training loss = 1.9881  Validation loss = 4.1956  \n",
      "\n",
      "Fold: 3  Epoch: 69  Training loss = 1.9879  Validation loss = 4.1953  \n",
      "\n",
      "Fold: 3  Epoch: 70  Training loss = 1.9878  Validation loss = 4.1951  \n",
      "\n",
      "Fold: 3  Epoch: 71  Training loss = 1.9876  Validation loss = 4.1949  \n",
      "\n",
      "Fold: 3  Epoch: 72  Training loss = 1.9874  Validation loss = 4.1946  \n",
      "\n",
      "Fold: 3  Epoch: 73  Training loss = 1.9872  Validation loss = 4.1943  \n",
      "\n",
      "Fold: 3  Epoch: 74  Training loss = 1.9870  Validation loss = 4.1941  \n",
      "\n",
      "Fold: 3  Epoch: 75  Training loss = 1.9869  Validation loss = 4.1938  \n",
      "\n",
      "Fold: 3  Epoch: 76  Training loss = 1.9867  Validation loss = 4.1936  \n",
      "\n",
      "Fold: 3  Epoch: 77  Training loss = 1.9864  Validation loss = 4.1933  \n",
      "\n",
      "Fold: 3  Epoch: 78  Training loss = 1.9862  Validation loss = 4.1930  \n",
      "\n",
      "Fold: 3  Epoch: 79  Training loss = 1.9860  Validation loss = 4.1927  \n",
      "\n",
      "Fold: 3  Epoch: 80  Training loss = 1.9858  Validation loss = 4.1924  \n",
      "\n",
      "Fold: 3  Epoch: 81  Training loss = 1.9856  Validation loss = 4.1922  \n",
      "\n",
      "Fold: 3  Epoch: 82  Training loss = 1.9855  Validation loss = 4.1919  \n",
      "\n",
      "Fold: 3  Epoch: 83  Training loss = 1.9852  Validation loss = 4.1916  \n",
      "\n",
      "Fold: 3  Epoch: 84  Training loss = 1.9850  Validation loss = 4.1914  \n",
      "\n",
      "Fold: 3  Epoch: 85  Training loss = 1.9848  Validation loss = 4.1911  \n",
      "\n",
      "Fold: 3  Epoch: 86  Training loss = 1.9847  Validation loss = 4.1909  \n",
      "\n",
      "Fold: 3  Epoch: 87  Training loss = 1.9845  Validation loss = 4.1907  \n",
      "\n",
      "Fold: 3  Epoch: 88  Training loss = 1.9842  Validation loss = 4.1903  \n",
      "\n",
      "Fold: 3  Epoch: 89  Training loss = 1.9840  Validation loss = 4.1900  \n",
      "\n",
      "Fold: 3  Epoch: 90  Training loss = 1.9839  Validation loss = 4.1898  \n",
      "\n",
      "Fold: 3  Epoch: 91  Training loss = 1.9836  Validation loss = 4.1895  \n",
      "\n",
      "Fold: 3  Epoch: 92  Training loss = 1.9835  Validation loss = 4.1893  \n",
      "\n",
      "Fold: 3  Epoch: 93  Training loss = 1.9833  Validation loss = 4.1890  \n",
      "\n",
      "Fold: 3  Epoch: 94  Training loss = 1.9831  Validation loss = 4.1888  \n",
      "\n",
      "Fold: 3  Epoch: 95  Training loss = 1.9829  Validation loss = 4.1885  \n",
      "\n",
      "Fold: 3  Epoch: 96  Training loss = 1.9827  Validation loss = 4.1882  \n",
      "\n",
      "Fold: 3  Epoch: 97  Training loss = 1.9825  Validation loss = 4.1879  \n",
      "\n",
      "Fold: 3  Epoch: 98  Training loss = 1.9823  Validation loss = 4.1877  \n",
      "\n",
      "Fold: 3  Epoch: 99  Training loss = 1.9821  Validation loss = 4.1874  \n",
      "\n",
      "Fold: 3  Epoch: 100  Training loss = 1.9819  Validation loss = 4.1872  \n",
      "\n",
      "Fold: 3  Epoch: 101  Training loss = 1.9818  Validation loss = 4.1870  \n",
      "\n",
      "Fold: 3  Epoch: 102  Training loss = 1.9816  Validation loss = 4.1867  \n",
      "\n",
      "Fold: 3  Epoch: 103  Training loss = 1.9814  Validation loss = 4.1864  \n",
      "\n",
      "Fold: 3  Epoch: 104  Training loss = 1.9812  Validation loss = 4.1862  \n",
      "\n",
      "Fold: 3  Epoch: 105  Training loss = 1.9810  Validation loss = 4.1859  \n",
      "\n",
      "Fold: 3  Epoch: 106  Training loss = 1.9808  Validation loss = 4.1857  \n",
      "\n",
      "Fold: 3  Epoch: 107  Training loss = 1.9806  Validation loss = 4.1854  \n",
      "\n",
      "Fold: 3  Epoch: 108  Training loss = 1.9804  Validation loss = 4.1851  \n",
      "\n",
      "Fold: 3  Epoch: 109  Training loss = 1.9802  Validation loss = 4.1848  \n",
      "\n",
      "Fold: 3  Epoch: 110  Training loss = 1.9800  Validation loss = 4.1845  \n",
      "\n",
      "Fold: 3  Epoch: 111  Training loss = 1.9798  Validation loss = 4.1843  \n",
      "\n",
      "Fold: 3  Epoch: 112  Training loss = 1.9796  Validation loss = 4.1839  \n",
      "\n",
      "Fold: 3  Epoch: 113  Training loss = 1.9794  Validation loss = 4.1837  \n",
      "\n",
      "Fold: 3  Epoch: 114  Training loss = 1.9792  Validation loss = 4.1834  \n",
      "\n",
      "Fold: 3  Epoch: 115  Training loss = 1.9790  Validation loss = 4.1832  \n",
      "\n",
      "Fold: 3  Epoch: 116  Training loss = 1.9788  Validation loss = 4.1829  \n",
      "\n",
      "Fold: 3  Epoch: 117  Training loss = 1.9786  Validation loss = 4.1826  \n",
      "\n",
      "Fold: 3  Epoch: 118  Training loss = 1.9784  Validation loss = 4.1824  \n",
      "\n",
      "Fold: 3  Epoch: 119  Training loss = 1.9782  Validation loss = 4.1821  \n",
      "\n",
      "Fold: 3  Epoch: 120  Training loss = 1.9780  Validation loss = 4.1818  \n",
      "\n",
      "Fold: 3  Epoch: 121  Training loss = 1.9778  Validation loss = 4.1815  \n",
      "\n",
      "Fold: 3  Epoch: 122  Training loss = 1.9776  Validation loss = 4.1813  \n",
      "\n",
      "Fold: 3  Epoch: 123  Training loss = 1.9774  Validation loss = 4.1810  \n",
      "\n",
      "Fold: 3  Epoch: 124  Training loss = 1.9772  Validation loss = 4.1807  \n",
      "\n",
      "Fold: 3  Epoch: 125  Training loss = 1.9770  Validation loss = 4.1805  \n",
      "\n",
      "Fold: 3  Epoch: 126  Training loss = 1.9768  Validation loss = 4.1802  \n",
      "\n",
      "Fold: 3  Epoch: 127  Training loss = 1.9766  Validation loss = 4.1800  \n",
      "\n",
      "Fold: 3  Epoch: 128  Training loss = 1.9764  Validation loss = 4.1797  \n",
      "\n",
      "Fold: 3  Epoch: 129  Training loss = 1.9762  Validation loss = 4.1795  \n",
      "\n",
      "Fold: 3  Epoch: 130  Training loss = 1.9761  Validation loss = 4.1793  \n",
      "\n",
      "Fold: 3  Epoch: 131  Training loss = 1.9759  Validation loss = 4.1790  \n",
      "\n",
      "Fold: 3  Epoch: 132  Training loss = 1.9757  Validation loss = 4.1787  \n",
      "\n",
      "Fold: 3  Epoch: 133  Training loss = 1.9755  Validation loss = 4.1784  \n",
      "\n",
      "Fold: 3  Epoch: 134  Training loss = 1.9753  Validation loss = 4.1782  \n",
      "\n",
      "Fold: 3  Epoch: 135  Training loss = 1.9751  Validation loss = 4.1779  \n",
      "\n",
      "Fold: 3  Epoch: 136  Training loss = 1.9749  Validation loss = 4.1776  \n",
      "\n",
      "Fold: 3  Epoch: 137  Training loss = 1.9747  Validation loss = 4.1773  \n",
      "\n",
      "Fold: 3  Epoch: 138  Training loss = 1.9744  Validation loss = 4.1770  \n",
      "\n",
      "Fold: 3  Epoch: 139  Training loss = 1.9742  Validation loss = 4.1767  \n",
      "\n",
      "Fold: 3  Epoch: 140  Training loss = 1.9740  Validation loss = 4.1764  \n",
      "\n",
      "Fold: 3  Epoch: 141  Training loss = 1.9738  Validation loss = 4.1761  \n",
      "\n",
      "Fold: 3  Epoch: 142  Training loss = 1.9736  Validation loss = 4.1758  \n",
      "\n",
      "Fold: 3  Epoch: 143  Training loss = 1.9734  Validation loss = 4.1756  \n",
      "\n",
      "Fold: 3  Epoch: 144  Training loss = 1.9732  Validation loss = 4.1753  \n",
      "\n",
      "Fold: 3  Epoch: 145  Training loss = 1.9730  Validation loss = 4.1751  \n",
      "\n",
      "Fold: 3  Epoch: 146  Training loss = 1.9728  Validation loss = 4.1748  \n",
      "\n",
      "Fold: 3  Epoch: 147  Training loss = 1.9726  Validation loss = 4.1745  \n",
      "\n",
      "Fold: 3  Epoch: 148  Training loss = 1.9724  Validation loss = 4.1742  \n",
      "\n",
      "Fold: 3  Epoch: 149  Training loss = 1.9723  Validation loss = 4.1740  \n",
      "\n",
      "Fold: 3  Epoch: 150  Training loss = 1.9721  Validation loss = 4.1738  \n",
      "\n",
      "Fold: 3  Epoch: 151  Training loss = 1.9719  Validation loss = 4.1735  \n",
      "\n",
      "Fold: 3  Epoch: 152  Training loss = 1.9717  Validation loss = 4.1733  \n",
      "\n",
      "Fold: 3  Epoch: 153  Training loss = 1.9716  Validation loss = 4.1731  \n",
      "\n",
      "Fold: 3  Epoch: 154  Training loss = 1.9714  Validation loss = 4.1728  \n",
      "\n",
      "Fold: 3  Epoch: 155  Training loss = 1.9712  Validation loss = 4.1726  \n",
      "\n",
      "Fold: 3  Epoch: 156  Training loss = 1.9710  Validation loss = 4.1723  \n",
      "\n",
      "Fold: 3  Epoch: 157  Training loss = 1.9708  Validation loss = 4.1721  \n",
      "\n",
      "Fold: 3  Epoch: 158  Training loss = 1.9706  Validation loss = 4.1718  \n",
      "\n",
      "Fold: 3  Epoch: 159  Training loss = 1.9705  Validation loss = 4.1716  \n",
      "\n",
      "Fold: 3  Epoch: 160  Training loss = 1.9703  Validation loss = 4.1713  \n",
      "\n",
      "Fold: 3  Epoch: 161  Training loss = 1.9701  Validation loss = 4.1711  \n",
      "\n",
      "Fold: 3  Epoch: 162  Training loss = 1.9699  Validation loss = 4.1708  \n",
      "\n",
      "Fold: 3  Epoch: 163  Training loss = 1.9698  Validation loss = 4.1706  \n",
      "\n",
      "Fold: 3  Epoch: 164  Training loss = 1.9696  Validation loss = 4.1704  \n",
      "\n",
      "Fold: 3  Epoch: 165  Training loss = 1.9695  Validation loss = 4.1702  \n",
      "\n",
      "Fold: 3  Epoch: 166  Training loss = 1.9693  Validation loss = 4.1699  \n",
      "\n",
      "Fold: 3  Epoch: 167  Training loss = 1.9691  Validation loss = 4.1696  \n",
      "\n",
      "Fold: 3  Epoch: 168  Training loss = 1.9689  Validation loss = 4.1694  \n",
      "\n",
      "Fold: 3  Epoch: 169  Training loss = 1.9687  Validation loss = 4.1692  \n",
      "\n",
      "Fold: 3  Epoch: 170  Training loss = 1.9685  Validation loss = 4.1689  \n",
      "\n",
      "Fold: 3  Epoch: 171  Training loss = 1.9683  Validation loss = 4.1686  \n",
      "\n",
      "Fold: 3  Epoch: 172  Training loss = 1.9681  Validation loss = 4.1684  \n",
      "\n",
      "Fold: 3  Epoch: 173  Training loss = 1.9679  Validation loss = 4.1681  \n",
      "\n",
      "Fold: 3  Epoch: 174  Training loss = 1.9677  Validation loss = 4.1678  \n",
      "\n",
      "Fold: 3  Epoch: 175  Training loss = 1.9675  Validation loss = 4.1675  \n",
      "\n",
      "Fold: 3  Epoch: 176  Training loss = 1.9673  Validation loss = 4.1672  \n",
      "\n",
      "Fold: 3  Epoch: 177  Training loss = 1.9671  Validation loss = 4.1670  \n",
      "\n",
      "Fold: 3  Epoch: 178  Training loss = 1.9669  Validation loss = 4.1667  \n",
      "\n",
      "Fold: 3  Epoch: 179  Training loss = 1.9667  Validation loss = 4.1664  \n",
      "\n",
      "Fold: 3  Epoch: 180  Training loss = 1.9666  Validation loss = 4.1662  \n",
      "\n",
      "Fold: 3  Epoch: 181  Training loss = 1.9664  Validation loss = 4.1659  \n",
      "\n",
      "Fold: 3  Epoch: 182  Training loss = 1.9662  Validation loss = 4.1657  \n",
      "\n",
      "Fold: 3  Epoch: 183  Training loss = 1.9660  Validation loss = 4.1655  \n",
      "\n",
      "Fold: 3  Epoch: 184  Training loss = 1.9658  Validation loss = 4.1651  \n",
      "\n",
      "Fold: 3  Epoch: 185  Training loss = 1.9656  Validation loss = 4.1648  \n",
      "\n",
      "Fold: 3  Epoch: 186  Training loss = 1.9653  Validation loss = 4.1645  \n",
      "\n",
      "Fold: 3  Epoch: 187  Training loss = 1.9652  Validation loss = 4.1643  \n",
      "\n",
      "Fold: 3  Epoch: 188  Training loss = 1.9650  Validation loss = 4.1640  \n",
      "\n",
      "Fold: 3  Epoch: 189  Training loss = 1.9648  Validation loss = 4.1638  \n",
      "\n",
      "Fold: 3  Epoch: 190  Training loss = 1.9646  Validation loss = 4.1635  \n",
      "\n",
      "Fold: 3  Epoch: 191  Training loss = 1.9644  Validation loss = 4.1632  \n",
      "\n",
      "Fold: 3  Epoch: 192  Training loss = 1.9642  Validation loss = 4.1629  \n",
      "\n",
      "Fold: 3  Epoch: 193  Training loss = 1.9640  Validation loss = 4.1627  \n",
      "\n",
      "Fold: 3  Epoch: 194  Training loss = 1.9638  Validation loss = 4.1625  \n",
      "\n",
      "Fold: 3  Epoch: 195  Training loss = 1.9636  Validation loss = 4.1622  \n",
      "\n",
      "Fold: 3  Epoch: 196  Training loss = 1.9634  Validation loss = 4.1619  \n",
      "\n",
      "Fold: 3  Epoch: 197  Training loss = 1.9632  Validation loss = 4.1616  \n",
      "\n",
      "Fold: 3  Epoch: 198  Training loss = 1.9630  Validation loss = 4.1614  \n",
      "\n",
      "Fold: 3  Epoch: 199  Training loss = 1.9629  Validation loss = 4.1611  \n",
      "\n",
      "Fold: 3  Epoch: 200  Training loss = 1.9626  Validation loss = 4.1608  \n",
      "\n",
      "Fold: 3  Epoch: 201  Training loss = 1.9625  Validation loss = 4.1606  \n",
      "\n",
      "Fold: 3  Epoch: 202  Training loss = 1.9623  Validation loss = 4.1603  \n",
      "\n",
      "Fold: 3  Epoch: 203  Training loss = 1.9621  Validation loss = 4.1601  \n",
      "\n",
      "Fold: 3  Epoch: 204  Training loss = 1.9619  Validation loss = 4.1598  \n",
      "\n",
      "Fold: 3  Epoch: 205  Training loss = 1.9617  Validation loss = 4.1596  \n",
      "\n",
      "Fold: 3  Epoch: 206  Training loss = 1.9616  Validation loss = 4.1593  \n",
      "\n",
      "Fold: 3  Epoch: 207  Training loss = 1.9614  Validation loss = 4.1591  \n",
      "\n",
      "Fold: 3  Epoch: 208  Training loss = 1.9612  Validation loss = 4.1588  \n",
      "\n",
      "Fold: 3  Epoch: 209  Training loss = 1.9610  Validation loss = 4.1585  \n",
      "\n",
      "Fold: 3  Epoch: 210  Training loss = 1.9608  Validation loss = 4.1583  \n",
      "\n",
      "Fold: 3  Epoch: 211  Training loss = 1.9606  Validation loss = 4.1580  \n",
      "\n",
      "Fold: 3  Epoch: 212  Training loss = 1.9605  Validation loss = 4.1578  \n",
      "\n",
      "Fold: 3  Epoch: 213  Training loss = 1.9603  Validation loss = 4.1575  \n",
      "\n",
      "Fold: 3  Epoch: 214  Training loss = 1.9601  Validation loss = 4.1572  \n",
      "\n",
      "Fold: 3  Epoch: 215  Training loss = 1.9599  Validation loss = 4.1570  \n",
      "\n",
      "Fold: 3  Epoch: 216  Training loss = 1.9597  Validation loss = 4.1566  \n",
      "\n",
      "Fold: 3  Epoch: 217  Training loss = 1.9595  Validation loss = 4.1564  \n",
      "\n",
      "Fold: 3  Epoch: 218  Training loss = 1.9593  Validation loss = 4.1561  \n",
      "\n",
      "Fold: 3  Epoch: 219  Training loss = 1.9591  Validation loss = 4.1558  \n",
      "\n",
      "Fold: 3  Epoch: 220  Training loss = 1.9589  Validation loss = 4.1556  \n",
      "\n",
      "Fold: 3  Epoch: 221  Training loss = 1.9587  Validation loss = 4.1553  \n",
      "\n",
      "Fold: 3  Epoch: 222  Training loss = 1.9585  Validation loss = 4.1551  \n",
      "\n",
      "Fold: 3  Epoch: 223  Training loss = 1.9583  Validation loss = 4.1548  \n",
      "\n",
      "Fold: 3  Epoch: 224  Training loss = 1.9581  Validation loss = 4.1546  \n",
      "\n",
      "Fold: 3  Epoch: 225  Training loss = 1.9579  Validation loss = 4.1543  \n",
      "\n",
      "Fold: 3  Epoch: 226  Training loss = 1.9577  Validation loss = 4.1540  \n",
      "\n",
      "Fold: 3  Epoch: 227  Training loss = 1.9576  Validation loss = 4.1538  \n",
      "\n",
      "Fold: 3  Epoch: 228  Training loss = 1.9574  Validation loss = 4.1536  \n",
      "\n",
      "Fold: 3  Epoch: 229  Training loss = 1.9572  Validation loss = 4.1533  \n",
      "\n",
      "Fold: 3  Epoch: 230  Training loss = 1.9571  Validation loss = 4.1531  \n",
      "\n",
      "Fold: 3  Epoch: 231  Training loss = 1.9569  Validation loss = 4.1529  \n",
      "\n",
      "Fold: 3  Epoch: 232  Training loss = 1.9567  Validation loss = 4.1526  \n",
      "\n",
      "Fold: 3  Epoch: 233  Training loss = 1.9565  Validation loss = 4.1524  \n",
      "\n",
      "Fold: 3  Epoch: 234  Training loss = 1.9564  Validation loss = 4.1522  \n",
      "\n",
      "Fold: 3  Epoch: 235  Training loss = 1.9562  Validation loss = 4.1520  \n",
      "\n",
      "Fold: 3  Epoch: 236  Training loss = 1.9560  Validation loss = 4.1517  \n",
      "\n",
      "Fold: 3  Epoch: 237  Training loss = 1.9558  Validation loss = 4.1515  \n",
      "\n",
      "Fold: 3  Epoch: 238  Training loss = 1.9556  Validation loss = 4.1511  \n",
      "\n",
      "Fold: 3  Epoch: 239  Training loss = 1.9554  Validation loss = 4.1508  \n",
      "\n",
      "Fold: 3  Epoch: 240  Training loss = 1.9552  Validation loss = 4.1506  \n",
      "\n",
      "Fold: 3  Epoch: 241  Training loss = 1.9551  Validation loss = 4.1504  \n",
      "\n",
      "Fold: 3  Epoch: 242  Training loss = 1.9549  Validation loss = 4.1502  \n",
      "\n",
      "Fold: 3  Epoch: 243  Training loss = 1.9547  Validation loss = 4.1499  \n",
      "\n",
      "Fold: 3  Epoch: 244  Training loss = 1.9545  Validation loss = 4.1496  \n",
      "\n",
      "Fold: 3  Epoch: 245  Training loss = 1.9543  Validation loss = 4.1494  \n",
      "\n",
      "Fold: 3  Epoch: 246  Training loss = 1.9541  Validation loss = 4.1492  \n",
      "\n",
      "Fold: 3  Epoch: 247  Training loss = 1.9540  Validation loss = 4.1489  \n",
      "\n",
      "Fold: 3  Epoch: 248  Training loss = 1.9537  Validation loss = 4.1486  \n",
      "\n",
      "Fold: 3  Epoch: 249  Training loss = 1.9536  Validation loss = 4.1484  \n",
      "\n",
      "Fold: 3  Epoch: 250  Training loss = 1.9534  Validation loss = 4.1481  \n",
      "\n",
      "Fold: 3  Epoch: 251  Training loss = 1.9532  Validation loss = 4.1479  \n",
      "\n",
      "Fold: 3  Epoch: 252  Training loss = 1.9530  Validation loss = 4.1476  \n",
      "\n",
      "Fold: 3  Epoch: 253  Training loss = 1.9528  Validation loss = 4.1473  \n",
      "\n",
      "Fold: 3  Epoch: 254  Training loss = 1.9526  Validation loss = 4.1470  \n",
      "\n",
      "Fold: 3  Epoch: 255  Training loss = 1.9524  Validation loss = 4.1468  \n",
      "\n",
      "Fold: 3  Epoch: 256  Training loss = 1.9523  Validation loss = 4.1466  \n",
      "\n",
      "Fold: 3  Epoch: 257  Training loss = 1.9521  Validation loss = 4.1463  \n",
      "\n",
      "Fold: 3  Epoch: 258  Training loss = 1.9519  Validation loss = 4.1461  \n",
      "\n",
      "Fold: 3  Epoch: 259  Training loss = 1.9517  Validation loss = 4.1458  \n",
      "\n",
      "Fold: 3  Epoch: 260  Training loss = 1.9516  Validation loss = 4.1456  \n",
      "\n",
      "Fold: 3  Epoch: 261  Training loss = 1.9514  Validation loss = 4.1453  \n",
      "\n",
      "Fold: 3  Epoch: 262  Training loss = 1.9512  Validation loss = 4.1451  \n",
      "\n",
      "Fold: 3  Epoch: 263  Training loss = 1.9510  Validation loss = 4.1449  \n",
      "\n",
      "Fold: 3  Epoch: 264  Training loss = 1.9509  Validation loss = 4.1447  \n",
      "\n",
      "Fold: 3  Epoch: 265  Training loss = 1.9507  Validation loss = 4.1444  \n",
      "\n",
      "Fold: 3  Epoch: 266  Training loss = 1.9505  Validation loss = 4.1442  \n",
      "\n",
      "Fold: 3  Epoch: 267  Training loss = 1.9503  Validation loss = 4.1439  \n",
      "\n",
      "Fold: 3  Epoch: 268  Training loss = 1.9501  Validation loss = 4.1437  \n",
      "\n",
      "Fold: 3  Epoch: 269  Training loss = 1.9500  Validation loss = 4.1434  \n",
      "\n",
      "Fold: 3  Epoch: 270  Training loss = 1.9498  Validation loss = 4.1432  \n",
      "\n",
      "Fold: 3  Epoch: 271  Training loss = 1.9496  Validation loss = 4.1430  \n",
      "\n",
      "Fold: 3  Epoch: 272  Training loss = 1.9494  Validation loss = 4.1427  \n",
      "\n",
      "Fold: 3  Epoch: 273  Training loss = 1.9492  Validation loss = 4.1424  \n",
      "\n",
      "Fold: 3  Epoch: 274  Training loss = 1.9491  Validation loss = 4.1422  \n",
      "\n",
      "Fold: 3  Epoch: 275  Training loss = 1.9489  Validation loss = 4.1420  \n",
      "\n",
      "Fold: 3  Epoch: 276  Training loss = 1.9488  Validation loss = 4.1418  \n",
      "\n",
      "Fold: 3  Epoch: 277  Training loss = 1.9486  Validation loss = 4.1415  \n",
      "\n",
      "Fold: 3  Epoch: 278  Training loss = 1.9484  Validation loss = 4.1413  \n",
      "\n",
      "Fold: 3  Epoch: 279  Training loss = 1.9483  Validation loss = 4.1411  \n",
      "\n",
      "Fold: 3  Epoch: 280  Training loss = 1.9481  Validation loss = 4.1408  \n",
      "\n",
      "Fold: 3  Epoch: 281  Training loss = 1.9479  Validation loss = 4.1406  \n",
      "\n",
      "Fold: 3  Epoch: 282  Training loss = 1.9478  Validation loss = 4.1404  \n",
      "\n",
      "Fold: 3  Epoch: 283  Training loss = 1.9476  Validation loss = 4.1401  \n",
      "\n",
      "Fold: 3  Epoch: 284  Training loss = 1.9473  Validation loss = 4.1397  \n",
      "\n",
      "Fold: 3  Epoch: 285  Training loss = 1.9472  Validation loss = 4.1395  \n",
      "\n",
      "Fold: 3  Epoch: 286  Training loss = 1.9471  Validation loss = 4.1394  \n",
      "\n",
      "Fold: 3  Epoch: 287  Training loss = 1.9469  Validation loss = 4.1391  \n",
      "\n",
      "Fold: 3  Epoch: 288  Training loss = 1.9467  Validation loss = 4.1389  \n",
      "\n",
      "Fold: 3  Epoch: 289  Training loss = 1.9465  Validation loss = 4.1386  \n",
      "\n",
      "Fold: 3  Epoch: 290  Training loss = 1.9463  Validation loss = 4.1383  \n",
      "\n",
      "Fold: 3  Epoch: 291  Training loss = 1.9462  Validation loss = 4.1381  \n",
      "\n",
      "Fold: 3  Epoch: 292  Training loss = 1.9460  Validation loss = 4.1378  \n",
      "\n",
      "Fold: 3  Epoch: 293  Training loss = 1.9458  Validation loss = 4.1376  \n",
      "\n",
      "Fold: 3  Epoch: 294  Training loss = 1.9456  Validation loss = 4.1373  \n",
      "\n",
      "Fold: 3  Epoch: 295  Training loss = 1.9454  Validation loss = 4.1370  \n",
      "\n",
      "Fold: 3  Epoch: 296  Training loss = 1.9452  Validation loss = 4.1368  \n",
      "\n",
      "Fold: 3  Epoch: 297  Training loss = 1.9451  Validation loss = 4.1366  \n",
      "\n",
      "Fold: 3  Epoch: 298  Training loss = 1.9449  Validation loss = 4.1363  \n",
      "\n",
      "Fold: 3  Epoch: 299  Training loss = 1.9447  Validation loss = 4.1361  \n",
      "\n",
      "Fold: 3  Epoch: 300  Training loss = 1.9445  Validation loss = 4.1358  \n",
      "\n",
      "Fold: 3  Epoch: 301  Training loss = 1.9443  Validation loss = 4.1356  \n",
      "\n",
      "Fold: 3  Epoch: 302  Training loss = 1.9442  Validation loss = 4.1353  \n",
      "\n",
      "Fold: 3  Epoch: 303  Training loss = 1.9440  Validation loss = 4.1352  \n",
      "\n",
      "Fold: 3  Epoch: 304  Training loss = 1.9439  Validation loss = 4.1349  \n",
      "\n",
      "Fold: 3  Epoch: 305  Training loss = 1.9437  Validation loss = 4.1347  \n",
      "\n",
      "Fold: 3  Epoch: 306  Training loss = 1.9435  Validation loss = 4.1344  \n",
      "\n",
      "Fold: 3  Epoch: 307  Training loss = 1.9433  Validation loss = 4.1342  \n",
      "\n",
      "Fold: 3  Epoch: 308  Training loss = 1.9431  Validation loss = 4.1339  \n",
      "\n",
      "Fold: 3  Epoch: 309  Training loss = 1.9430  Validation loss = 4.1337  \n",
      "\n",
      "Fold: 3  Epoch: 310  Training loss = 1.9428  Validation loss = 4.1335  \n",
      "\n",
      "Fold: 3  Epoch: 311  Training loss = 1.9427  Validation loss = 4.1333  \n",
      "\n",
      "Fold: 3  Epoch: 312  Training loss = 1.9425  Validation loss = 4.1330  \n",
      "\n",
      "Fold: 3  Epoch: 313  Training loss = 1.9423  Validation loss = 4.1328  \n",
      "\n",
      "Fold: 3  Epoch: 314  Training loss = 1.9421  Validation loss = 4.1325  \n",
      "\n",
      "Fold: 3  Epoch: 315  Training loss = 1.9420  Validation loss = 4.1323  \n",
      "\n",
      "Fold: 3  Epoch: 316  Training loss = 1.9418  Validation loss = 4.1321  \n",
      "\n",
      "Fold: 3  Epoch: 317  Training loss = 1.9417  Validation loss = 4.1319  \n",
      "\n",
      "Fold: 3  Epoch: 318  Training loss = 1.9414  Validation loss = 4.1315  \n",
      "\n",
      "Fold: 3  Epoch: 319  Training loss = 1.9413  Validation loss = 4.1313  \n",
      "\n",
      "Fold: 3  Epoch: 320  Training loss = 1.9411  Validation loss = 4.1311  \n",
      "\n",
      "Fold: 3  Epoch: 321  Training loss = 1.9409  Validation loss = 4.1308  \n",
      "\n",
      "Fold: 3  Epoch: 322  Training loss = 1.9408  Validation loss = 4.1307  \n",
      "\n",
      "Fold: 3  Epoch: 323  Training loss = 1.9406  Validation loss = 4.1304  \n",
      "\n",
      "Fold: 3  Epoch: 324  Training loss = 1.9404  Validation loss = 4.1302  \n",
      "\n",
      "Fold: 3  Epoch: 325  Training loss = 1.9402  Validation loss = 4.1299  \n",
      "\n",
      "Fold: 3  Epoch: 326  Training loss = 1.9400  Validation loss = 4.1296  \n",
      "\n",
      "Fold: 3  Epoch: 327  Training loss = 1.9398  Validation loss = 4.1293  \n",
      "\n",
      "Fold: 3  Epoch: 328  Training loss = 1.9396  Validation loss = 4.1290  \n",
      "\n",
      "Fold: 3  Epoch: 329  Training loss = 1.9395  Validation loss = 4.1288  \n",
      "\n",
      "Fold: 3  Epoch: 330  Training loss = 1.9393  Validation loss = 4.1286  \n",
      "\n",
      "Fold: 3  Epoch: 331  Training loss = 1.9391  Validation loss = 4.1283  \n",
      "\n",
      "Fold: 3  Epoch: 332  Training loss = 1.9389  Validation loss = 4.1281  \n",
      "\n",
      "Fold: 3  Epoch: 333  Training loss = 1.9388  Validation loss = 4.1278  \n",
      "\n",
      "Fold: 3  Epoch: 334  Training loss = 1.9386  Validation loss = 4.1276  \n",
      "\n",
      "Fold: 3  Epoch: 335  Training loss = 1.9383  Validation loss = 4.1273  \n",
      "\n",
      "Fold: 3  Epoch: 336  Training loss = 1.9382  Validation loss = 4.1270  \n",
      "\n",
      "Fold: 3  Epoch: 337  Training loss = 1.9380  Validation loss = 4.1268  \n",
      "\n",
      "Fold: 3  Epoch: 338  Training loss = 1.9379  Validation loss = 4.1266  \n",
      "\n",
      "Fold: 3  Epoch: 339  Training loss = 1.9377  Validation loss = 4.1263  \n",
      "\n",
      "Fold: 3  Epoch: 340  Training loss = 1.9375  Validation loss = 4.1262  \n",
      "\n",
      "Fold: 3  Epoch: 341  Training loss = 1.9374  Validation loss = 4.1260  \n",
      "\n",
      "Fold: 3  Epoch: 342  Training loss = 1.9372  Validation loss = 4.1257  \n",
      "\n",
      "Fold: 3  Epoch: 343  Training loss = 1.9370  Validation loss = 4.1255  \n",
      "\n",
      "Fold: 3  Epoch: 344  Training loss = 1.9369  Validation loss = 4.1252  \n",
      "\n",
      "Fold: 3  Epoch: 345  Training loss = 1.9367  Validation loss = 4.1250  \n",
      "\n",
      "Fold: 3  Epoch: 346  Training loss = 1.9365  Validation loss = 4.1247  \n",
      "\n",
      "Fold: 3  Epoch: 347  Training loss = 1.9363  Validation loss = 4.1245  \n",
      "\n",
      "Fold: 3  Epoch: 348  Training loss = 1.9361  Validation loss = 4.1242  \n",
      "\n",
      "Fold: 3  Epoch: 349  Training loss = 1.9359  Validation loss = 4.1239  \n",
      "\n",
      "Fold: 3  Epoch: 350  Training loss = 1.9357  Validation loss = 4.1236  \n",
      "\n",
      "Fold: 3  Epoch: 351  Training loss = 1.9355  Validation loss = 4.1234  \n",
      "\n",
      "Fold: 3  Epoch: 352  Training loss = 1.9354  Validation loss = 4.1231  \n",
      "\n",
      "Fold: 3  Epoch: 353  Training loss = 1.9352  Validation loss = 4.1228  \n",
      "\n",
      "Fold: 3  Epoch: 354  Training loss = 1.9350  Validation loss = 4.1226  \n",
      "\n",
      "Fold: 3  Epoch: 355  Training loss = 1.9349  Validation loss = 4.1224  \n",
      "\n",
      "Fold: 3  Epoch: 356  Training loss = 1.9347  Validation loss = 4.1221  \n",
      "\n",
      "Fold: 3  Epoch: 357  Training loss = 1.9345  Validation loss = 4.1218  \n",
      "\n",
      "Fold: 3  Epoch: 358  Training loss = 1.9343  Validation loss = 4.1215  \n",
      "\n",
      "Fold: 3  Epoch: 359  Training loss = 1.9342  Validation loss = 4.1214  \n",
      "\n",
      "Fold: 3  Epoch: 360  Training loss = 1.9340  Validation loss = 4.1212  \n",
      "\n",
      "Fold: 3  Epoch: 361  Training loss = 1.9338  Validation loss = 4.1209  \n",
      "\n",
      "Fold: 3  Epoch: 362  Training loss = 1.9336  Validation loss = 4.1207  \n",
      "\n",
      "Fold: 3  Epoch: 363  Training loss = 1.9335  Validation loss = 4.1205  \n",
      "\n",
      "Fold: 3  Epoch: 364  Training loss = 1.9333  Validation loss = 4.1203  \n",
      "\n",
      "Fold: 3  Epoch: 365  Training loss = 1.9332  Validation loss = 4.1200  \n",
      "\n",
      "Fold: 3  Epoch: 366  Training loss = 1.9330  Validation loss = 4.1197  \n",
      "\n",
      "Fold: 3  Epoch: 367  Training loss = 1.9328  Validation loss = 4.1194  \n",
      "\n",
      "Fold: 3  Epoch: 368  Training loss = 1.9326  Validation loss = 4.1192  \n",
      "\n",
      "Fold: 3  Epoch: 369  Training loss = 1.9325  Validation loss = 4.1191  \n",
      "\n",
      "Fold: 3  Epoch: 370  Training loss = 1.9323  Validation loss = 4.1188  \n",
      "\n",
      "Fold: 3  Epoch: 371  Training loss = 1.9322  Validation loss = 4.1186  \n",
      "\n",
      "Fold: 3  Epoch: 372  Training loss = 1.9320  Validation loss = 4.1183  \n",
      "\n",
      "Fold: 3  Epoch: 373  Training loss = 1.9318  Validation loss = 4.1181  \n",
      "\n",
      "Fold: 3  Epoch: 374  Training loss = 1.9316  Validation loss = 4.1178  \n",
      "\n",
      "Fold: 3  Epoch: 375  Training loss = 1.9314  Validation loss = 4.1176  \n",
      "\n",
      "Fold: 3  Epoch: 376  Training loss = 1.9313  Validation loss = 4.1173  \n",
      "\n",
      "Fold: 3  Epoch: 377  Training loss = 1.9311  Validation loss = 4.1170  \n",
      "\n",
      "Fold: 3  Epoch: 378  Training loss = 1.9309  Validation loss = 4.1168  \n",
      "\n",
      "Fold: 3  Epoch: 379  Training loss = 1.9308  Validation loss = 4.1166  \n",
      "\n",
      "Fold: 3  Epoch: 380  Training loss = 1.9306  Validation loss = 4.1164  \n",
      "\n",
      "Fold: 3  Epoch: 381  Training loss = 1.9304  Validation loss = 4.1161  \n",
      "\n",
      "Fold: 3  Epoch: 382  Training loss = 1.9302  Validation loss = 4.1159  \n",
      "\n",
      "Fold: 3  Epoch: 383  Training loss = 1.9300  Validation loss = 4.1156  \n",
      "\n",
      "Fold: 3  Epoch: 384  Training loss = 1.9298  Validation loss = 4.1153  \n",
      "\n",
      "Fold: 3  Epoch: 385  Training loss = 1.9297  Validation loss = 4.1151  \n",
      "\n",
      "Fold: 3  Epoch: 386  Training loss = 1.9295  Validation loss = 4.1149  \n",
      "\n",
      "Fold: 3  Epoch: 387  Training loss = 1.9293  Validation loss = 4.1146  \n",
      "\n",
      "Fold: 3  Epoch: 388  Training loss = 1.9292  Validation loss = 4.1144  \n",
      "\n",
      "Fold: 3  Epoch: 389  Training loss = 1.9290  Validation loss = 4.1141  \n",
      "\n",
      "Fold: 3  Epoch: 390  Training loss = 1.9288  Validation loss = 4.1138  \n",
      "\n",
      "Fold: 3  Epoch: 391  Training loss = 1.9286  Validation loss = 4.1136  \n",
      "\n",
      "Fold: 3  Epoch: 392  Training loss = 1.9284  Validation loss = 4.1134  \n",
      "\n",
      "Fold: 3  Epoch: 393  Training loss = 1.9283  Validation loss = 4.1132  \n",
      "\n",
      "Fold: 3  Epoch: 394  Training loss = 1.9281  Validation loss = 4.1130  \n",
      "\n",
      "Fold: 3  Epoch: 395  Training loss = 1.9280  Validation loss = 4.1127  \n",
      "\n",
      "Fold: 3  Epoch: 396  Training loss = 1.9278  Validation loss = 4.1125  \n",
      "\n",
      "Fold: 3  Epoch: 397  Training loss = 1.9276  Validation loss = 4.1122  \n",
      "\n",
      "Fold: 3  Epoch: 398  Training loss = 1.9275  Validation loss = 4.1120  \n",
      "\n",
      "Fold: 3  Epoch: 399  Training loss = 1.9273  Validation loss = 4.1117  \n",
      "\n",
      "Fold: 3  Epoch: 400  Training loss = 1.9271  Validation loss = 4.1115  \n",
      "\n",
      "Fold: 3  Epoch: 401  Training loss = 1.9268  Validation loss = 4.1111  \n",
      "\n",
      "Fold: 3  Epoch: 402  Training loss = 1.9267  Validation loss = 4.1109  \n",
      "\n",
      "Fold: 3  Epoch: 403  Training loss = 1.9265  Validation loss = 4.1107  \n",
      "\n",
      "Fold: 3  Epoch: 404  Training loss = 1.9263  Validation loss = 4.1104  \n",
      "\n",
      "Fold: 3  Epoch: 405  Training loss = 1.9262  Validation loss = 4.1102  \n",
      "\n",
      "Fold: 3  Epoch: 406  Training loss = 1.9260  Validation loss = 4.1099  \n",
      "\n",
      "Fold: 3  Epoch: 407  Training loss = 1.9258  Validation loss = 4.1097  \n",
      "\n",
      "Fold: 3  Epoch: 408  Training loss = 1.9256  Validation loss = 4.1094  \n",
      "\n",
      "Fold: 3  Epoch: 409  Training loss = 1.9254  Validation loss = 4.1091  \n",
      "\n",
      "Fold: 3  Epoch: 410  Training loss = 1.9252  Validation loss = 4.1089  \n",
      "\n",
      "Fold: 3  Epoch: 411  Training loss = 1.9250  Validation loss = 4.1086  \n",
      "\n",
      "Fold: 3  Epoch: 412  Training loss = 1.9249  Validation loss = 4.1084  \n",
      "\n",
      "Fold: 3  Epoch: 413  Training loss = 1.9246  Validation loss = 4.1081  \n",
      "\n",
      "Fold: 3  Epoch: 414  Training loss = 1.9245  Validation loss = 4.1078  \n",
      "\n",
      "Fold: 3  Epoch: 415  Training loss = 1.9243  Validation loss = 4.1076  \n",
      "\n",
      "Fold: 3  Epoch: 416  Training loss = 1.9241  Validation loss = 4.1073  \n",
      "\n",
      "Fold: 3  Epoch: 417  Training loss = 1.9240  Validation loss = 4.1071  \n",
      "\n",
      "Fold: 3  Epoch: 418  Training loss = 1.9238  Validation loss = 4.1069  \n",
      "\n",
      "Fold: 3  Epoch: 419  Training loss = 1.9236  Validation loss = 4.1067  \n",
      "\n",
      "Fold: 3  Epoch: 420  Training loss = 1.9235  Validation loss = 4.1065  \n",
      "\n",
      "Fold: 3  Epoch: 421  Training loss = 1.9233  Validation loss = 4.1062  \n",
      "\n",
      "Fold: 3  Epoch: 422  Training loss = 1.9232  Validation loss = 4.1060  \n",
      "\n",
      "Fold: 3  Epoch: 423  Training loss = 1.9230  Validation loss = 4.1058  \n",
      "\n",
      "Fold: 3  Epoch: 424  Training loss = 1.9228  Validation loss = 4.1056  \n",
      "\n",
      "Fold: 3  Epoch: 425  Training loss = 1.9227  Validation loss = 4.1053  \n",
      "\n",
      "Fold: 3  Epoch: 426  Training loss = 1.9225  Validation loss = 4.1051  \n",
      "\n",
      "Fold: 3  Epoch: 427  Training loss = 1.9223  Validation loss = 4.1048  \n",
      "\n",
      "Fold: 3  Epoch: 428  Training loss = 1.9221  Validation loss = 4.1046  \n",
      "\n",
      "Fold: 3  Epoch: 429  Training loss = 1.9219  Validation loss = 4.1043  \n",
      "\n",
      "Fold: 3  Epoch: 430  Training loss = 1.9218  Validation loss = 4.1040  \n",
      "\n",
      "Fold: 3  Epoch: 431  Training loss = 1.9216  Validation loss = 4.1038  \n",
      "\n",
      "Fold: 3  Epoch: 432  Training loss = 1.9214  Validation loss = 4.1036  \n",
      "\n",
      "Fold: 3  Epoch: 433  Training loss = 1.9212  Validation loss = 4.1033  \n",
      "\n",
      "Fold: 3  Epoch: 434  Training loss = 1.9211  Validation loss = 4.1032  \n",
      "\n",
      "Fold: 3  Epoch: 435  Training loss = 1.9209  Validation loss = 4.1029  \n",
      "\n",
      "Fold: 3  Epoch: 436  Training loss = 1.9208  Validation loss = 4.1027  \n",
      "\n",
      "Fold: 3  Epoch: 437  Training loss = 1.9207  Validation loss = 4.1026  \n",
      "\n",
      "Fold: 3  Epoch: 438  Training loss = 1.9205  Validation loss = 4.1023  \n",
      "\n",
      "Fold: 3  Epoch: 439  Training loss = 1.9203  Validation loss = 4.1020  \n",
      "\n",
      "Fold: 3  Epoch: 440  Training loss = 1.9201  Validation loss = 4.1018  \n",
      "\n",
      "Fold: 3  Epoch: 441  Training loss = 1.9200  Validation loss = 4.1016  \n",
      "\n",
      "Fold: 3  Epoch: 442  Training loss = 1.9199  Validation loss = 4.1014  \n",
      "\n",
      "Fold: 3  Epoch: 443  Training loss = 1.9197  Validation loss = 4.1011  \n",
      "\n",
      "Fold: 3  Epoch: 444  Training loss = 1.9195  Validation loss = 4.1008  \n",
      "\n",
      "Fold: 3  Epoch: 445  Training loss = 1.9193  Validation loss = 4.1006  \n",
      "\n",
      "Fold: 3  Epoch: 446  Training loss = 1.9192  Validation loss = 4.1004  \n",
      "\n",
      "Fold: 3  Epoch: 447  Training loss = 1.9190  Validation loss = 4.1002  \n",
      "\n",
      "Fold: 3  Epoch: 448  Training loss = 1.9189  Validation loss = 4.1000  \n",
      "\n",
      "Fold: 3  Epoch: 449  Training loss = 1.9187  Validation loss = 4.0998  \n",
      "\n",
      "Fold: 3  Epoch: 450  Training loss = 1.9186  Validation loss = 4.0996  \n",
      "\n",
      "Fold: 3  Epoch: 451  Training loss = 1.9184  Validation loss = 4.0993  \n",
      "\n",
      "Fold: 3  Epoch: 452  Training loss = 1.9182  Validation loss = 4.0991  \n",
      "\n",
      "Fold: 3  Epoch: 453  Training loss = 1.9180  Validation loss = 4.0988  \n",
      "\n",
      "Fold: 3  Epoch: 454  Training loss = 1.9179  Validation loss = 4.0986  \n",
      "\n",
      "Fold: 3  Epoch: 455  Training loss = 1.9177  Validation loss = 4.0983  \n",
      "\n",
      "Fold: 3  Epoch: 456  Training loss = 1.9175  Validation loss = 4.0981  \n",
      "\n",
      "Fold: 3  Epoch: 457  Training loss = 1.9174  Validation loss = 4.0978  \n",
      "\n",
      "Fold: 3  Epoch: 458  Training loss = 1.9172  Validation loss = 4.0976  \n",
      "\n",
      "Fold: 3  Epoch: 459  Training loss = 1.9170  Validation loss = 4.0973  \n",
      "\n",
      "Fold: 3  Epoch: 460  Training loss = 1.9168  Validation loss = 4.0971  \n",
      "\n",
      "Fold: 3  Epoch: 461  Training loss = 1.9166  Validation loss = 4.0968  \n",
      "\n",
      "Fold: 3  Epoch: 462  Training loss = 1.9165  Validation loss = 4.0967  \n",
      "\n",
      "Fold: 3  Epoch: 463  Training loss = 1.9164  Validation loss = 4.0964  \n",
      "\n",
      "Fold: 3  Epoch: 464  Training loss = 1.9162  Validation loss = 4.0963  \n",
      "\n",
      "Fold: 3  Epoch: 465  Training loss = 1.9161  Validation loss = 4.0960  \n",
      "\n",
      "Fold: 3  Epoch: 466  Training loss = 1.9159  Validation loss = 4.0958  \n",
      "\n",
      "Fold: 3  Epoch: 467  Training loss = 1.9158  Validation loss = 4.0956  \n",
      "\n",
      "Fold: 3  Epoch: 468  Training loss = 1.9156  Validation loss = 4.0953  \n",
      "\n",
      "Fold: 3  Epoch: 469  Training loss = 1.9154  Validation loss = 4.0951  \n",
      "\n",
      "Fold: 3  Epoch: 470  Training loss = 1.9152  Validation loss = 4.0948  \n",
      "\n",
      "Fold: 3  Epoch: 471  Training loss = 1.9150  Validation loss = 4.0946  \n",
      "\n",
      "Fold: 3  Epoch: 472  Training loss = 1.9149  Validation loss = 4.0944  \n",
      "\n",
      "Fold: 3  Epoch: 473  Training loss = 1.9147  Validation loss = 4.0941  \n",
      "\n",
      "Fold: 3  Epoch: 474  Training loss = 1.9146  Validation loss = 4.0940  \n",
      "\n",
      "Fold: 3  Epoch: 475  Training loss = 1.9144  Validation loss = 4.0938  \n",
      "\n",
      "Fold: 3  Epoch: 476  Training loss = 1.9143  Validation loss = 4.0935  \n",
      "\n",
      "Fold: 3  Epoch: 477  Training loss = 1.9141  Validation loss = 4.0933  \n",
      "\n",
      "Fold: 3  Epoch: 478  Training loss = 1.9140  Validation loss = 4.0931  \n",
      "\n",
      "Fold: 3  Epoch: 479  Training loss = 1.9138  Validation loss = 4.0928  \n",
      "\n",
      "Fold: 3  Epoch: 480  Training loss = 1.9137  Validation loss = 4.0926  \n",
      "\n",
      "Fold: 3  Epoch: 481  Training loss = 1.9135  Validation loss = 4.0924  \n",
      "\n",
      "Fold: 3  Epoch: 482  Training loss = 1.9134  Validation loss = 4.0922  \n",
      "\n",
      "Fold: 3  Epoch: 483  Training loss = 1.9132  Validation loss = 4.0919  \n",
      "\n",
      "Fold: 3  Epoch: 484  Training loss = 1.9131  Validation loss = 4.0918  \n",
      "\n",
      "Fold: 3  Epoch: 485  Training loss = 1.9130  Validation loss = 4.0916  \n",
      "\n",
      "Fold: 3  Epoch: 486  Training loss = 1.9128  Validation loss = 4.0914  \n",
      "\n",
      "Fold: 3  Epoch: 487  Training loss = 1.9127  Validation loss = 4.0912  \n",
      "\n",
      "Fold: 3  Epoch: 488  Training loss = 1.9124  Validation loss = 4.0909  \n",
      "\n",
      "Fold: 3  Epoch: 489  Training loss = 1.9123  Validation loss = 4.0907  \n",
      "\n",
      "Fold: 3  Epoch: 490  Training loss = 1.9121  Validation loss = 4.0904  \n",
      "\n",
      "Fold: 3  Epoch: 491  Training loss = 1.9120  Validation loss = 4.0902  \n",
      "\n",
      "Fold: 3  Epoch: 492  Training loss = 1.9118  Validation loss = 4.0900  \n",
      "\n",
      "Fold: 3  Epoch: 493  Training loss = 1.9117  Validation loss = 4.0897  \n",
      "\n",
      "Fold: 3  Epoch: 494  Training loss = 1.9115  Validation loss = 4.0896  \n",
      "\n",
      "Fold: 3  Epoch: 495  Training loss = 1.9113  Validation loss = 4.0893  \n",
      "\n",
      "Fold: 3  Epoch: 496  Training loss = 1.9112  Validation loss = 4.0891  \n",
      "\n",
      "Fold: 3  Epoch: 497  Training loss = 1.9110  Validation loss = 4.0888  \n",
      "\n",
      "Fold: 3  Epoch: 498  Training loss = 1.9108  Validation loss = 4.0885  \n",
      "\n",
      "Fold: 3  Epoch: 499  Training loss = 1.9106  Validation loss = 4.0883  \n",
      "\n",
      "Fold: 3  Epoch: 500  Training loss = 1.9105  Validation loss = 4.0881  \n",
      "\n",
      "Check model:  Fold: 3  Epoch: 500  Training loss = 1.9105  Validation loss = 4.0881  \n",
      "\n",
      "Fold: 4  Epoch: 1  Training loss = 2.0148  Validation loss = 5.3230  \n",
      "\n",
      "Fold: 4  Epoch: 2  Training loss = 2.0146  Validation loss = 5.3227  \n",
      "\n",
      "Fold: 4  Epoch: 3  Training loss = 2.0144  Validation loss = 5.3224  \n",
      "\n",
      "Fold: 4  Epoch: 4  Training loss = 2.0142  Validation loss = 5.3221  \n",
      "\n",
      "Fold: 4  Epoch: 5  Training loss = 2.0141  Validation loss = 5.3219  \n",
      "\n",
      "Fold: 4  Epoch: 6  Training loss = 2.0139  Validation loss = 5.3215  \n",
      "\n",
      "Fold: 4  Epoch: 7  Training loss = 2.0137  Validation loss = 5.3213  \n",
      "\n",
      "Fold: 4  Epoch: 8  Training loss = 2.0135  Validation loss = 5.3210  \n",
      "\n",
      "Fold: 4  Epoch: 9  Training loss = 2.0133  Validation loss = 5.3207  \n",
      "\n",
      "Fold: 4  Epoch: 10  Training loss = 2.0131  Validation loss = 5.3203  \n",
      "\n",
      "Fold: 4  Epoch: 11  Training loss = 2.0129  Validation loss = 5.3200  \n",
      "\n",
      "Fold: 4  Epoch: 12  Training loss = 2.0127  Validation loss = 5.3197  \n",
      "\n",
      "Fold: 4  Epoch: 13  Training loss = 2.0126  Validation loss = 5.3194  \n",
      "\n",
      "Fold: 4  Epoch: 14  Training loss = 2.0124  Validation loss = 5.3191  \n",
      "\n",
      "Fold: 4  Epoch: 15  Training loss = 2.0122  Validation loss = 5.3188  \n",
      "\n",
      "Fold: 4  Epoch: 16  Training loss = 2.0120  Validation loss = 5.3185  \n",
      "\n",
      "Fold: 4  Epoch: 17  Training loss = 2.0118  Validation loss = 5.3182  \n",
      "\n",
      "Fold: 4  Epoch: 18  Training loss = 2.0116  Validation loss = 5.3178  \n",
      "\n",
      "Fold: 4  Epoch: 19  Training loss = 2.0115  Validation loss = 5.3175  \n",
      "\n",
      "Fold: 4  Epoch: 20  Training loss = 2.0113  Validation loss = 5.3173  \n",
      "\n",
      "Fold: 4  Epoch: 21  Training loss = 2.0111  Validation loss = 5.3169  \n",
      "\n",
      "Fold: 4  Epoch: 22  Training loss = 2.0109  Validation loss = 5.3167  \n",
      "\n",
      "Fold: 4  Epoch: 23  Training loss = 2.0108  Validation loss = 5.3164  \n",
      "\n",
      "Fold: 4  Epoch: 24  Training loss = 2.0105  Validation loss = 5.3161  \n",
      "\n",
      "Fold: 4  Epoch: 25  Training loss = 2.0103  Validation loss = 5.3157  \n",
      "\n",
      "Fold: 4  Epoch: 26  Training loss = 2.0102  Validation loss = 5.3154  \n",
      "\n",
      "Fold: 4  Epoch: 27  Training loss = 2.0100  Validation loss = 5.3152  \n",
      "\n",
      "Fold: 4  Epoch: 28  Training loss = 2.0098  Validation loss = 5.3147  \n",
      "\n",
      "Fold: 4  Epoch: 29  Training loss = 2.0096  Validation loss = 5.3145  \n",
      "\n",
      "Fold: 4  Epoch: 30  Training loss = 2.0094  Validation loss = 5.3142  \n",
      "\n",
      "Fold: 4  Epoch: 31  Training loss = 2.0093  Validation loss = 5.3139  \n",
      "\n",
      "Fold: 4  Epoch: 32  Training loss = 2.0091  Validation loss = 5.3136  \n",
      "\n",
      "Fold: 4  Epoch: 33  Training loss = 2.0089  Validation loss = 5.3133  \n",
      "\n",
      "Fold: 4  Epoch: 34  Training loss = 2.0088  Validation loss = 5.3131  \n",
      "\n",
      "Fold: 4  Epoch: 35  Training loss = 2.0086  Validation loss = 5.3128  \n",
      "\n",
      "Fold: 4  Epoch: 36  Training loss = 2.0084  Validation loss = 5.3125  \n",
      "\n",
      "Fold: 4  Epoch: 37  Training loss = 2.0082  Validation loss = 5.3123  \n",
      "\n",
      "Fold: 4  Epoch: 38  Training loss = 2.0081  Validation loss = 5.3119  \n",
      "\n",
      "Fold: 4  Epoch: 39  Training loss = 2.0079  Validation loss = 5.3116  \n",
      "\n",
      "Fold: 4  Epoch: 40  Training loss = 2.0077  Validation loss = 5.3113  \n",
      "\n",
      "Fold: 4  Epoch: 41  Training loss = 2.0075  Validation loss = 5.3110  \n",
      "\n",
      "Fold: 4  Epoch: 42  Training loss = 2.0074  Validation loss = 5.3108  \n",
      "\n",
      "Fold: 4  Epoch: 43  Training loss = 2.0072  Validation loss = 5.3105  \n",
      "\n",
      "Fold: 4  Epoch: 44  Training loss = 2.0071  Validation loss = 5.3102  \n",
      "\n",
      "Fold: 4  Epoch: 45  Training loss = 2.0069  Validation loss = 5.3100  \n",
      "\n",
      "Fold: 4  Epoch: 46  Training loss = 2.0067  Validation loss = 5.3097  \n",
      "\n",
      "Fold: 4  Epoch: 47  Training loss = 2.0065  Validation loss = 5.3094  \n",
      "\n",
      "Fold: 4  Epoch: 48  Training loss = 2.0064  Validation loss = 5.3091  \n",
      "\n",
      "Fold: 4  Epoch: 49  Training loss = 2.0062  Validation loss = 5.3087  \n",
      "\n",
      "Fold: 4  Epoch: 50  Training loss = 2.0059  Validation loss = 5.3084  \n",
      "\n",
      "Fold: 4  Epoch: 51  Training loss = 2.0058  Validation loss = 5.3081  \n",
      "\n",
      "Fold: 4  Epoch: 52  Training loss = 2.0056  Validation loss = 5.3079  \n",
      "\n",
      "Fold: 4  Epoch: 53  Training loss = 2.0055  Validation loss = 5.3077  \n",
      "\n",
      "Fold: 4  Epoch: 54  Training loss = 2.0053  Validation loss = 5.3074  \n",
      "\n",
      "Fold: 4  Epoch: 55  Training loss = 2.0051  Validation loss = 5.3070  \n",
      "\n",
      "Fold: 4  Epoch: 56  Training loss = 2.0049  Validation loss = 5.3067  \n",
      "\n",
      "Fold: 4  Epoch: 57  Training loss = 2.0047  Validation loss = 5.3063  \n",
      "\n",
      "Fold: 4  Epoch: 58  Training loss = 2.0045  Validation loss = 5.3060  \n",
      "\n",
      "Fold: 4  Epoch: 59  Training loss = 2.0044  Validation loss = 5.3057  \n",
      "\n",
      "Fold: 4  Epoch: 60  Training loss = 2.0042  Validation loss = 5.3055  \n",
      "\n",
      "Fold: 4  Epoch: 61  Training loss = 2.0040  Validation loss = 5.3052  \n",
      "\n",
      "Fold: 4  Epoch: 62  Training loss = 2.0039  Validation loss = 5.3050  \n",
      "\n",
      "Fold: 4  Epoch: 63  Training loss = 2.0037  Validation loss = 5.3047  \n",
      "\n",
      "Fold: 4  Epoch: 64  Training loss = 2.0036  Validation loss = 5.3044  \n",
      "\n",
      "Fold: 4  Epoch: 65  Training loss = 2.0034  Validation loss = 5.3041  \n",
      "\n",
      "Fold: 4  Epoch: 66  Training loss = 2.0032  Validation loss = 5.3037  \n",
      "\n",
      "Fold: 4  Epoch: 67  Training loss = 2.0030  Validation loss = 5.3035  \n",
      "\n",
      "Fold: 4  Epoch: 68  Training loss = 2.0028  Validation loss = 5.3032  \n",
      "\n",
      "Fold: 4  Epoch: 69  Training loss = 2.0027  Validation loss = 5.3029  \n",
      "\n",
      "Fold: 4  Epoch: 70  Training loss = 2.0025  Validation loss = 5.3026  \n",
      "\n",
      "Fold: 4  Epoch: 71  Training loss = 2.0022  Validation loss = 5.3022  \n",
      "\n",
      "Fold: 4  Epoch: 72  Training loss = 2.0021  Validation loss = 5.3020  \n",
      "\n",
      "Fold: 4  Epoch: 73  Training loss = 2.0019  Validation loss = 5.3016  \n",
      "\n",
      "Fold: 4  Epoch: 74  Training loss = 2.0017  Validation loss = 5.3013  \n",
      "\n",
      "Fold: 4  Epoch: 75  Training loss = 2.0015  Validation loss = 5.3010  \n",
      "\n",
      "Fold: 4  Epoch: 76  Training loss = 2.0013  Validation loss = 5.3007  \n",
      "\n",
      "Fold: 4  Epoch: 77  Training loss = 2.0012  Validation loss = 5.3005  \n",
      "\n",
      "Fold: 4  Epoch: 78  Training loss = 2.0010  Validation loss = 5.3002  \n",
      "\n",
      "Fold: 4  Epoch: 79  Training loss = 2.0009  Validation loss = 5.3000  \n",
      "\n",
      "Fold: 4  Epoch: 80  Training loss = 2.0007  Validation loss = 5.2997  \n",
      "\n",
      "Fold: 4  Epoch: 81  Training loss = 2.0005  Validation loss = 5.2993  \n",
      "\n",
      "Fold: 4  Epoch: 82  Training loss = 2.0003  Validation loss = 5.2990  \n",
      "\n",
      "Fold: 4  Epoch: 83  Training loss = 2.0002  Validation loss = 5.2988  \n",
      "\n",
      "Fold: 4  Epoch: 84  Training loss = 1.9999  Validation loss = 5.2984  \n",
      "\n",
      "Fold: 4  Epoch: 85  Training loss = 1.9998  Validation loss = 5.2981  \n",
      "\n",
      "Fold: 4  Epoch: 86  Training loss = 1.9996  Validation loss = 5.2978  \n",
      "\n",
      "Fold: 4  Epoch: 87  Training loss = 1.9994  Validation loss = 5.2975  \n",
      "\n",
      "Fold: 4  Epoch: 88  Training loss = 1.9992  Validation loss = 5.2972  \n",
      "\n",
      "Fold: 4  Epoch: 89  Training loss = 1.9991  Validation loss = 5.2969  \n",
      "\n",
      "Fold: 4  Epoch: 90  Training loss = 1.9989  Validation loss = 5.2966  \n",
      "\n",
      "Fold: 4  Epoch: 91  Training loss = 1.9987  Validation loss = 5.2962  \n",
      "\n",
      "Fold: 4  Epoch: 92  Training loss = 1.9985  Validation loss = 5.2959  \n",
      "\n",
      "Fold: 4  Epoch: 93  Training loss = 1.9983  Validation loss = 5.2956  \n",
      "\n",
      "Fold: 4  Epoch: 94  Training loss = 1.9981  Validation loss = 5.2953  \n",
      "\n",
      "Fold: 4  Epoch: 95  Training loss = 1.9979  Validation loss = 5.2950  \n",
      "\n",
      "Fold: 4  Epoch: 96  Training loss = 1.9978  Validation loss = 5.2947  \n",
      "\n",
      "Fold: 4  Epoch: 97  Training loss = 1.9976  Validation loss = 5.2944  \n",
      "\n",
      "Fold: 4  Epoch: 98  Training loss = 1.9974  Validation loss = 5.2941  \n",
      "\n",
      "Fold: 4  Epoch: 99  Training loss = 1.9973  Validation loss = 5.2939  \n",
      "\n",
      "Fold: 4  Epoch: 100  Training loss = 1.9971  Validation loss = 5.2936  \n",
      "\n",
      "Fold: 4  Epoch: 101  Training loss = 1.9969  Validation loss = 5.2932  \n",
      "\n",
      "Fold: 4  Epoch: 102  Training loss = 1.9967  Validation loss = 5.2930  \n",
      "\n",
      "Fold: 4  Epoch: 103  Training loss = 1.9965  Validation loss = 5.2926  \n",
      "\n",
      "Fold: 4  Epoch: 104  Training loss = 1.9964  Validation loss = 5.2925  \n",
      "\n",
      "Fold: 4  Epoch: 105  Training loss = 1.9963  Validation loss = 5.2922  \n",
      "\n",
      "Fold: 4  Epoch: 106  Training loss = 1.9961  Validation loss = 5.2919  \n",
      "\n",
      "Fold: 4  Epoch: 107  Training loss = 1.9959  Validation loss = 5.2916  \n",
      "\n",
      "Fold: 4  Epoch: 108  Training loss = 1.9957  Validation loss = 5.2914  \n",
      "\n",
      "Fold: 4  Epoch: 109  Training loss = 1.9956  Validation loss = 5.2911  \n",
      "\n",
      "Fold: 4  Epoch: 110  Training loss = 1.9954  Validation loss = 5.2908  \n",
      "\n",
      "Fold: 4  Epoch: 111  Training loss = 1.9952  Validation loss = 5.2905  \n",
      "\n",
      "Fold: 4  Epoch: 112  Training loss = 1.9950  Validation loss = 5.2901  \n",
      "\n",
      "Fold: 4  Epoch: 113  Training loss = 1.9948  Validation loss = 5.2898  \n",
      "\n",
      "Fold: 4  Epoch: 114  Training loss = 1.9946  Validation loss = 5.2895  \n",
      "\n",
      "Fold: 4  Epoch: 115  Training loss = 1.9945  Validation loss = 5.2893  \n",
      "\n",
      "Fold: 4  Epoch: 116  Training loss = 1.9943  Validation loss = 5.2890  \n",
      "\n",
      "Fold: 4  Epoch: 117  Training loss = 1.9941  Validation loss = 5.2887  \n",
      "\n",
      "Fold: 4  Epoch: 118  Training loss = 1.9940  Validation loss = 5.2884  \n",
      "\n",
      "Fold: 4  Epoch: 119  Training loss = 1.9938  Validation loss = 5.2881  \n",
      "\n",
      "Fold: 4  Epoch: 120  Training loss = 1.9936  Validation loss = 5.2878  \n",
      "\n",
      "Fold: 4  Epoch: 121  Training loss = 1.9935  Validation loss = 5.2876  \n",
      "\n",
      "Fold: 4  Epoch: 122  Training loss = 1.9933  Validation loss = 5.2873  \n",
      "\n",
      "Fold: 4  Epoch: 123  Training loss = 1.9931  Validation loss = 5.2870  \n",
      "\n",
      "Fold: 4  Epoch: 124  Training loss = 1.9930  Validation loss = 5.2868  \n",
      "\n",
      "Fold: 4  Epoch: 125  Training loss = 1.9928  Validation loss = 5.2865  \n",
      "\n",
      "Fold: 4  Epoch: 126  Training loss = 1.9926  Validation loss = 5.2863  \n",
      "\n",
      "Fold: 4  Epoch: 127  Training loss = 1.9925  Validation loss = 5.2860  \n",
      "\n",
      "Fold: 4  Epoch: 128  Training loss = 1.9923  Validation loss = 5.2857  \n",
      "\n",
      "Fold: 4  Epoch: 129  Training loss = 1.9922  Validation loss = 5.2854  \n",
      "\n",
      "Fold: 4  Epoch: 130  Training loss = 1.9920  Validation loss = 5.2852  \n",
      "\n",
      "Fold: 4  Epoch: 131  Training loss = 1.9919  Validation loss = 5.2849  \n",
      "\n",
      "Fold: 4  Epoch: 132  Training loss = 1.9917  Validation loss = 5.2846  \n",
      "\n",
      "Fold: 4  Epoch: 133  Training loss = 1.9916  Validation loss = 5.2844  \n",
      "\n",
      "Fold: 4  Epoch: 134  Training loss = 1.9914  Validation loss = 5.2841  \n",
      "\n",
      "Fold: 4  Epoch: 135  Training loss = 1.9912  Validation loss = 5.2838  \n",
      "\n",
      "Fold: 4  Epoch: 136  Training loss = 1.9910  Validation loss = 5.2835  \n",
      "\n",
      "Fold: 4  Epoch: 137  Training loss = 1.9908  Validation loss = 5.2831  \n",
      "\n",
      "Fold: 4  Epoch: 138  Training loss = 1.9906  Validation loss = 5.2828  \n",
      "\n",
      "Fold: 4  Epoch: 139  Training loss = 1.9905  Validation loss = 5.2825  \n",
      "\n",
      "Fold: 4  Epoch: 140  Training loss = 1.9903  Validation loss = 5.2822  \n",
      "\n",
      "Fold: 4  Epoch: 141  Training loss = 1.9901  Validation loss = 5.2819  \n",
      "\n",
      "Fold: 4  Epoch: 142  Training loss = 1.9900  Validation loss = 5.2817  \n",
      "\n",
      "Fold: 4  Epoch: 143  Training loss = 1.9898  Validation loss = 5.2815  \n",
      "\n",
      "Fold: 4  Epoch: 144  Training loss = 1.9897  Validation loss = 5.2812  \n",
      "\n",
      "Fold: 4  Epoch: 145  Training loss = 1.9895  Validation loss = 5.2809  \n",
      "\n",
      "Fold: 4  Epoch: 146  Training loss = 1.9893  Validation loss = 5.2807  \n",
      "\n",
      "Fold: 4  Epoch: 147  Training loss = 1.9892  Validation loss = 5.2805  \n",
      "\n",
      "Fold: 4  Epoch: 148  Training loss = 1.9891  Validation loss = 5.2802  \n",
      "\n",
      "Fold: 4  Epoch: 149  Training loss = 1.9889  Validation loss = 5.2799  \n",
      "\n",
      "Fold: 4  Epoch: 150  Training loss = 1.9888  Validation loss = 5.2798  \n",
      "\n",
      "Fold: 4  Epoch: 151  Training loss = 1.9886  Validation loss = 5.2794  \n",
      "\n",
      "Fold: 4  Epoch: 152  Training loss = 1.9884  Validation loss = 5.2791  \n",
      "\n",
      "Fold: 4  Epoch: 153  Training loss = 1.9882  Validation loss = 5.2788  \n",
      "\n",
      "Fold: 4  Epoch: 154  Training loss = 1.9881  Validation loss = 5.2786  \n",
      "\n",
      "Fold: 4  Epoch: 155  Training loss = 1.9879  Validation loss = 5.2783  \n",
      "\n",
      "Fold: 4  Epoch: 156  Training loss = 1.9877  Validation loss = 5.2780  \n",
      "\n",
      "Fold: 4  Epoch: 157  Training loss = 1.9876  Validation loss = 5.2778  \n",
      "\n",
      "Fold: 4  Epoch: 158  Training loss = 1.9874  Validation loss = 5.2775  \n",
      "\n",
      "Fold: 4  Epoch: 159  Training loss = 1.9873  Validation loss = 5.2772  \n",
      "\n",
      "Fold: 4  Epoch: 160  Training loss = 1.9871  Validation loss = 5.2769  \n",
      "\n",
      "Fold: 4  Epoch: 161  Training loss = 1.9869  Validation loss = 5.2765  \n",
      "\n",
      "Fold: 4  Epoch: 162  Training loss = 1.9867  Validation loss = 5.2763  \n",
      "\n",
      "Fold: 4  Epoch: 163  Training loss = 1.9865  Validation loss = 5.2760  \n",
      "\n",
      "Fold: 4  Epoch: 164  Training loss = 1.9864  Validation loss = 5.2757  \n",
      "\n",
      "Fold: 4  Epoch: 165  Training loss = 1.9862  Validation loss = 5.2754  \n",
      "\n",
      "Fold: 4  Epoch: 166  Training loss = 1.9860  Validation loss = 5.2751  \n",
      "\n",
      "Fold: 4  Epoch: 167  Training loss = 1.9858  Validation loss = 5.2748  \n",
      "\n",
      "Fold: 4  Epoch: 168  Training loss = 1.9856  Validation loss = 5.2745  \n",
      "\n",
      "Fold: 4  Epoch: 169  Training loss = 1.9854  Validation loss = 5.2742  \n",
      "\n",
      "Fold: 4  Epoch: 170  Training loss = 1.9853  Validation loss = 5.2739  \n",
      "\n",
      "Fold: 4  Epoch: 171  Training loss = 1.9851  Validation loss = 5.2736  \n",
      "\n",
      "Fold: 4  Epoch: 172  Training loss = 1.9849  Validation loss = 5.2733  \n",
      "\n",
      "Fold: 4  Epoch: 173  Training loss = 1.9848  Validation loss = 5.2730  \n",
      "\n",
      "Fold: 4  Epoch: 174  Training loss = 1.9846  Validation loss = 5.2728  \n",
      "\n",
      "Fold: 4  Epoch: 175  Training loss = 1.9845  Validation loss = 5.2725  \n",
      "\n",
      "Fold: 4  Epoch: 176  Training loss = 1.9843  Validation loss = 5.2722  \n",
      "\n",
      "Fold: 4  Epoch: 177  Training loss = 1.9841  Validation loss = 5.2719  \n",
      "\n",
      "Fold: 4  Epoch: 178  Training loss = 1.9839  Validation loss = 5.2716  \n",
      "\n",
      "Fold: 4  Epoch: 179  Training loss = 1.9838  Validation loss = 5.2714  \n",
      "\n",
      "Fold: 4  Epoch: 180  Training loss = 1.9836  Validation loss = 5.2711  \n",
      "\n",
      "Fold: 4  Epoch: 181  Training loss = 1.9835  Validation loss = 5.2708  \n",
      "\n",
      "Fold: 4  Epoch: 182  Training loss = 1.9833  Validation loss = 5.2706  \n",
      "\n",
      "Fold: 4  Epoch: 183  Training loss = 1.9832  Validation loss = 5.2703  \n",
      "\n",
      "Fold: 4  Epoch: 184  Training loss = 1.9830  Validation loss = 5.2700  \n",
      "\n",
      "Fold: 4  Epoch: 185  Training loss = 1.9829  Validation loss = 5.2698  \n",
      "\n",
      "Fold: 4  Epoch: 186  Training loss = 1.9827  Validation loss = 5.2695  \n",
      "\n",
      "Fold: 4  Epoch: 187  Training loss = 1.9825  Validation loss = 5.2692  \n",
      "\n",
      "Fold: 4  Epoch: 188  Training loss = 1.9824  Validation loss = 5.2689  \n",
      "\n",
      "Fold: 4  Epoch: 189  Training loss = 1.9822  Validation loss = 5.2686  \n",
      "\n",
      "Fold: 4  Epoch: 190  Training loss = 1.9820  Validation loss = 5.2684  \n",
      "\n",
      "Fold: 4  Epoch: 191  Training loss = 1.9818  Validation loss = 5.2680  \n",
      "\n",
      "Fold: 4  Epoch: 192  Training loss = 1.9816  Validation loss = 5.2676  \n",
      "\n",
      "Fold: 4  Epoch: 193  Training loss = 1.9814  Validation loss = 5.2673  \n",
      "\n",
      "Fold: 4  Epoch: 194  Training loss = 1.9813  Validation loss = 5.2671  \n",
      "\n",
      "Fold: 4  Epoch: 195  Training loss = 1.9811  Validation loss = 5.2668  \n",
      "\n",
      "Fold: 4  Epoch: 196  Training loss = 1.9809  Validation loss = 5.2665  \n",
      "\n",
      "Fold: 4  Epoch: 197  Training loss = 1.9807  Validation loss = 5.2661  \n",
      "\n",
      "Fold: 4  Epoch: 198  Training loss = 1.9805  Validation loss = 5.2657  \n",
      "\n",
      "Fold: 4  Epoch: 199  Training loss = 1.9804  Validation loss = 5.2654  \n",
      "\n",
      "Fold: 4  Epoch: 200  Training loss = 1.9802  Validation loss = 5.2651  \n",
      "\n",
      "Fold: 4  Epoch: 201  Training loss = 1.9800  Validation loss = 5.2648  \n",
      "\n",
      "Fold: 4  Epoch: 202  Training loss = 1.9799  Validation loss = 5.2646  \n",
      "\n",
      "Fold: 4  Epoch: 203  Training loss = 1.9797  Validation loss = 5.2644  \n",
      "\n",
      "Fold: 4  Epoch: 204  Training loss = 1.9796  Validation loss = 5.2641  \n",
      "\n",
      "Fold: 4  Epoch: 205  Training loss = 1.9794  Validation loss = 5.2638  \n",
      "\n",
      "Fold: 4  Epoch: 206  Training loss = 1.9793  Validation loss = 5.2636  \n",
      "\n",
      "Fold: 4  Epoch: 207  Training loss = 1.9791  Validation loss = 5.2633  \n",
      "\n",
      "Fold: 4  Epoch: 208  Training loss = 1.9789  Validation loss = 5.2631  \n",
      "\n",
      "Fold: 4  Epoch: 209  Training loss = 1.9788  Validation loss = 5.2628  \n",
      "\n",
      "Fold: 4  Epoch: 210  Training loss = 1.9786  Validation loss = 5.2625  \n",
      "\n",
      "Fold: 4  Epoch: 211  Training loss = 1.9784  Validation loss = 5.2621  \n",
      "\n",
      "Fold: 4  Epoch: 212  Training loss = 1.9783  Validation loss = 5.2619  \n",
      "\n",
      "Fold: 4  Epoch: 213  Training loss = 1.9781  Validation loss = 5.2616  \n",
      "\n",
      "Fold: 4  Epoch: 214  Training loss = 1.9780  Validation loss = 5.2614  \n",
      "\n",
      "Fold: 4  Epoch: 215  Training loss = 1.9778  Validation loss = 5.2612  \n",
      "\n",
      "Fold: 4  Epoch: 216  Training loss = 1.9776  Validation loss = 5.2608  \n",
      "\n",
      "Fold: 4  Epoch: 217  Training loss = 1.9775  Validation loss = 5.2605  \n",
      "\n",
      "Fold: 4  Epoch: 218  Training loss = 1.9773  Validation loss = 5.2602  \n",
      "\n",
      "Fold: 4  Epoch: 219  Training loss = 1.9771  Validation loss = 5.2600  \n",
      "\n",
      "Fold: 4  Epoch: 220  Training loss = 1.9770  Validation loss = 5.2597  \n",
      "\n",
      "Fold: 4  Epoch: 221  Training loss = 1.9769  Validation loss = 5.2595  \n",
      "\n",
      "Fold: 4  Epoch: 222  Training loss = 1.9767  Validation loss = 5.2592  \n",
      "\n",
      "Fold: 4  Epoch: 223  Training loss = 1.9765  Validation loss = 5.2589  \n",
      "\n",
      "Fold: 4  Epoch: 224  Training loss = 1.9763  Validation loss = 5.2586  \n",
      "\n",
      "Fold: 4  Epoch: 225  Training loss = 1.9761  Validation loss = 5.2583  \n",
      "\n",
      "Fold: 4  Epoch: 226  Training loss = 1.9759  Validation loss = 5.2579  \n",
      "\n",
      "Fold: 4  Epoch: 227  Training loss = 1.9758  Validation loss = 5.2577  \n",
      "\n",
      "Fold: 4  Epoch: 228  Training loss = 1.9757  Validation loss = 5.2574  \n",
      "\n",
      "Fold: 4  Epoch: 229  Training loss = 1.9755  Validation loss = 5.2571  \n",
      "\n",
      "Fold: 4  Epoch: 230  Training loss = 1.9754  Validation loss = 5.2569  \n",
      "\n",
      "Fold: 4  Epoch: 231  Training loss = 1.9752  Validation loss = 5.2566  \n",
      "\n",
      "Fold: 4  Epoch: 232  Training loss = 1.9750  Validation loss = 5.2564  \n",
      "\n",
      "Fold: 4  Epoch: 233  Training loss = 1.9749  Validation loss = 5.2561  \n",
      "\n",
      "Fold: 4  Epoch: 234  Training loss = 1.9746  Validation loss = 5.2557  \n",
      "\n",
      "Fold: 4  Epoch: 235  Training loss = 1.9744  Validation loss = 5.2553  \n",
      "\n",
      "Fold: 4  Epoch: 236  Training loss = 1.9743  Validation loss = 5.2550  \n",
      "\n",
      "Fold: 4  Epoch: 237  Training loss = 1.9741  Validation loss = 5.2547  \n",
      "\n",
      "Fold: 4  Epoch: 238  Training loss = 1.9739  Validation loss = 5.2544  \n",
      "\n",
      "Fold: 4  Epoch: 239  Training loss = 1.9738  Validation loss = 5.2541  \n",
      "\n",
      "Fold: 4  Epoch: 240  Training loss = 1.9736  Validation loss = 5.2539  \n",
      "\n",
      "Fold: 4  Epoch: 241  Training loss = 1.9735  Validation loss = 5.2536  \n",
      "\n",
      "Fold: 4  Epoch: 242  Training loss = 1.9733  Validation loss = 5.2534  \n",
      "\n",
      "Fold: 4  Epoch: 243  Training loss = 1.9731  Validation loss = 5.2531  \n",
      "\n",
      "Fold: 4  Epoch: 244  Training loss = 1.9730  Validation loss = 5.2528  \n",
      "\n",
      "Fold: 4  Epoch: 245  Training loss = 1.9728  Validation loss = 5.2524  \n",
      "\n",
      "Fold: 4  Epoch: 246  Training loss = 1.9726  Validation loss = 5.2520  \n",
      "\n",
      "Fold: 4  Epoch: 247  Training loss = 1.9724  Validation loss = 5.2517  \n",
      "\n",
      "Fold: 4  Epoch: 248  Training loss = 1.9722  Validation loss = 5.2514  \n",
      "\n",
      "Fold: 4  Epoch: 249  Training loss = 1.9720  Validation loss = 5.2511  \n",
      "\n",
      "Fold: 4  Epoch: 250  Training loss = 1.9719  Validation loss = 5.2508  \n",
      "\n",
      "Fold: 4  Epoch: 251  Training loss = 1.9717  Validation loss = 5.2506  \n",
      "\n",
      "Fold: 4  Epoch: 252  Training loss = 1.9716  Validation loss = 5.2503  \n",
      "\n",
      "Fold: 4  Epoch: 253  Training loss = 1.9714  Validation loss = 5.2500  \n",
      "\n",
      "Fold: 4  Epoch: 254  Training loss = 1.9713  Validation loss = 5.2498  \n",
      "\n",
      "Fold: 4  Epoch: 255  Training loss = 1.9711  Validation loss = 5.2494  \n",
      "\n",
      "Fold: 4  Epoch: 256  Training loss = 1.9709  Validation loss = 5.2491  \n",
      "\n",
      "Fold: 4  Epoch: 257  Training loss = 1.9707  Validation loss = 5.2488  \n",
      "\n",
      "Fold: 4  Epoch: 258  Training loss = 1.9706  Validation loss = 5.2485  \n",
      "\n",
      "Fold: 4  Epoch: 259  Training loss = 1.9704  Validation loss = 5.2483  \n",
      "\n",
      "Fold: 4  Epoch: 260  Training loss = 1.9702  Validation loss = 5.2479  \n",
      "\n",
      "Fold: 4  Epoch: 261  Training loss = 1.9700  Validation loss = 5.2476  \n",
      "\n",
      "Fold: 4  Epoch: 262  Training loss = 1.9698  Validation loss = 5.2473  \n",
      "\n",
      "Fold: 4  Epoch: 263  Training loss = 1.9697  Validation loss = 5.2470  \n",
      "\n",
      "Fold: 4  Epoch: 264  Training loss = 1.9695  Validation loss = 5.2467  \n",
      "\n",
      "Fold: 4  Epoch: 265  Training loss = 1.9693  Validation loss = 5.2464  \n",
      "\n",
      "Fold: 4  Epoch: 266  Training loss = 1.9691  Validation loss = 5.2461  \n",
      "\n",
      "Fold: 4  Epoch: 267  Training loss = 1.9690  Validation loss = 5.2458  \n",
      "\n",
      "Fold: 4  Epoch: 268  Training loss = 1.9688  Validation loss = 5.2455  \n",
      "\n",
      "Fold: 4  Epoch: 269  Training loss = 1.9687  Validation loss = 5.2453  \n",
      "\n",
      "Fold: 4  Epoch: 270  Training loss = 1.9685  Validation loss = 5.2450  \n",
      "\n",
      "Fold: 4  Epoch: 271  Training loss = 1.9684  Validation loss = 5.2448  \n",
      "\n",
      "Fold: 4  Epoch: 272  Training loss = 1.9682  Validation loss = 5.2444  \n",
      "\n",
      "Fold: 4  Epoch: 273  Training loss = 1.9680  Validation loss = 5.2441  \n",
      "\n",
      "Fold: 4  Epoch: 274  Training loss = 1.9679  Validation loss = 5.2439  \n",
      "\n",
      "Fold: 4  Epoch: 275  Training loss = 1.9677  Validation loss = 5.2436  \n",
      "\n",
      "Fold: 4  Epoch: 276  Training loss = 1.9675  Validation loss = 5.2433  \n",
      "\n",
      "Fold: 4  Epoch: 277  Training loss = 1.9674  Validation loss = 5.2431  \n",
      "\n",
      "Fold: 4  Epoch: 278  Training loss = 1.9673  Validation loss = 5.2429  \n",
      "\n",
      "Fold: 4  Epoch: 279  Training loss = 1.9672  Validation loss = 5.2427  \n",
      "\n",
      "Fold: 4  Epoch: 280  Training loss = 1.9670  Validation loss = 5.2424  \n",
      "\n",
      "Fold: 4  Epoch: 281  Training loss = 1.9668  Validation loss = 5.2420  \n",
      "\n",
      "Fold: 4  Epoch: 282  Training loss = 1.9666  Validation loss = 5.2417  \n",
      "\n",
      "Fold: 4  Epoch: 283  Training loss = 1.9665  Validation loss = 5.2415  \n",
      "\n",
      "Fold: 4  Epoch: 284  Training loss = 1.9663  Validation loss = 5.2411  \n",
      "\n",
      "Fold: 4  Epoch: 285  Training loss = 1.9661  Validation loss = 5.2408  \n",
      "\n",
      "Fold: 4  Epoch: 286  Training loss = 1.9659  Validation loss = 5.2405  \n",
      "\n",
      "Fold: 4  Epoch: 287  Training loss = 1.9658  Validation loss = 5.2402  \n",
      "\n",
      "Fold: 4  Epoch: 288  Training loss = 1.9656  Validation loss = 5.2399  \n",
      "\n",
      "Fold: 4  Epoch: 289  Training loss = 1.9654  Validation loss = 5.2395  \n",
      "\n",
      "Fold: 4  Epoch: 290  Training loss = 1.9653  Validation loss = 5.2393  \n",
      "\n",
      "Fold: 4  Epoch: 291  Training loss = 1.9651  Validation loss = 5.2390  \n",
      "\n",
      "Fold: 4  Epoch: 292  Training loss = 1.9649  Validation loss = 5.2387  \n",
      "\n",
      "Fold: 4  Epoch: 293  Training loss = 1.9648  Validation loss = 5.2384  \n",
      "\n",
      "Fold: 4  Epoch: 294  Training loss = 1.9646  Validation loss = 5.2382  \n",
      "\n",
      "Fold: 4  Epoch: 295  Training loss = 1.9644  Validation loss = 5.2378  \n",
      "\n",
      "Fold: 4  Epoch: 296  Training loss = 1.9643  Validation loss = 5.2376  \n",
      "\n",
      "Fold: 4  Epoch: 297  Training loss = 1.9641  Validation loss = 5.2372  \n",
      "\n",
      "Fold: 4  Epoch: 298  Training loss = 1.9639  Validation loss = 5.2370  \n",
      "\n",
      "Fold: 4  Epoch: 299  Training loss = 1.9638  Validation loss = 5.2367  \n",
      "\n",
      "Fold: 4  Epoch: 300  Training loss = 1.9636  Validation loss = 5.2364  \n",
      "\n",
      "Fold: 4  Epoch: 301  Training loss = 1.9634  Validation loss = 5.2361  \n",
      "\n",
      "Fold: 4  Epoch: 302  Training loss = 1.9633  Validation loss = 5.2359  \n",
      "\n",
      "Fold: 4  Epoch: 303  Training loss = 1.9631  Validation loss = 5.2356  \n",
      "\n",
      "Fold: 4  Epoch: 304  Training loss = 1.9629  Validation loss = 5.2353  \n",
      "\n",
      "Fold: 4  Epoch: 305  Training loss = 1.9628  Validation loss = 5.2350  \n",
      "\n",
      "Fold: 4  Epoch: 306  Training loss = 1.9626  Validation loss = 5.2347  \n",
      "\n",
      "Fold: 4  Epoch: 307  Training loss = 1.9625  Validation loss = 5.2345  \n",
      "\n",
      "Fold: 4  Epoch: 308  Training loss = 1.9624  Validation loss = 5.2343  \n",
      "\n",
      "Fold: 4  Epoch: 309  Training loss = 1.9622  Validation loss = 5.2341  \n",
      "\n",
      "Fold: 4  Epoch: 310  Training loss = 1.9621  Validation loss = 5.2339  \n",
      "\n",
      "Fold: 4  Epoch: 311  Training loss = 1.9619  Validation loss = 5.2336  \n",
      "\n",
      "Fold: 4  Epoch: 312  Training loss = 1.9618  Validation loss = 5.2333  \n",
      "\n",
      "Fold: 4  Epoch: 313  Training loss = 1.9616  Validation loss = 5.2330  \n",
      "\n",
      "Fold: 4  Epoch: 314  Training loss = 1.9614  Validation loss = 5.2327  \n",
      "\n",
      "Fold: 4  Epoch: 315  Training loss = 1.9613  Validation loss = 5.2326  \n",
      "\n",
      "Fold: 4  Epoch: 316  Training loss = 1.9611  Validation loss = 5.2323  \n",
      "\n",
      "Fold: 4  Epoch: 317  Training loss = 1.9610  Validation loss = 5.2321  \n",
      "\n",
      "Fold: 4  Epoch: 318  Training loss = 1.9609  Validation loss = 5.2318  \n",
      "\n",
      "Fold: 4  Epoch: 319  Training loss = 1.9607  Validation loss = 5.2315  \n",
      "\n",
      "Fold: 4  Epoch: 320  Training loss = 1.9606  Validation loss = 5.2313  \n",
      "\n",
      "Fold: 4  Epoch: 321  Training loss = 1.9604  Validation loss = 5.2310  \n",
      "\n",
      "Fold: 4  Epoch: 322  Training loss = 1.9602  Validation loss = 5.2307  \n",
      "\n",
      "Fold: 4  Epoch: 323  Training loss = 1.9600  Validation loss = 5.2303  \n",
      "\n",
      "Fold: 4  Epoch: 324  Training loss = 1.9598  Validation loss = 5.2300  \n",
      "\n",
      "Fold: 4  Epoch: 325  Training loss = 1.9597  Validation loss = 5.2297  \n",
      "\n",
      "Fold: 4  Epoch: 326  Training loss = 1.9595  Validation loss = 5.2294  \n",
      "\n",
      "Fold: 4  Epoch: 327  Training loss = 1.9593  Validation loss = 5.2291  \n",
      "\n",
      "Fold: 4  Epoch: 328  Training loss = 1.9591  Validation loss = 5.2288  \n",
      "\n",
      "Fold: 4  Epoch: 329  Training loss = 1.9590  Validation loss = 5.2285  \n",
      "\n",
      "Fold: 4  Epoch: 330  Training loss = 1.9588  Validation loss = 5.2283  \n",
      "\n",
      "Fold: 4  Epoch: 331  Training loss = 1.9587  Validation loss = 5.2279  \n",
      "\n",
      "Fold: 4  Epoch: 332  Training loss = 1.9585  Validation loss = 5.2277  \n",
      "\n",
      "Fold: 4  Epoch: 333  Training loss = 1.9583  Validation loss = 5.2274  \n",
      "\n",
      "Fold: 4  Epoch: 334  Training loss = 1.9582  Validation loss = 5.2271  \n",
      "\n",
      "Fold: 4  Epoch: 335  Training loss = 1.9580  Validation loss = 5.2269  \n",
      "\n",
      "Fold: 4  Epoch: 336  Training loss = 1.9579  Validation loss = 5.2267  \n",
      "\n",
      "Fold: 4  Epoch: 337  Training loss = 1.9577  Validation loss = 5.2264  \n",
      "\n",
      "Fold: 4  Epoch: 338  Training loss = 1.9576  Validation loss = 5.2261  \n",
      "\n",
      "Fold: 4  Epoch: 339  Training loss = 1.9574  Validation loss = 5.2258  \n",
      "\n",
      "Fold: 4  Epoch: 340  Training loss = 1.9573  Validation loss = 5.2256  \n",
      "\n",
      "Fold: 4  Epoch: 341  Training loss = 1.9571  Validation loss = 5.2253  \n",
      "\n",
      "Fold: 4  Epoch: 342  Training loss = 1.9569  Validation loss = 5.2250  \n",
      "\n",
      "Fold: 4  Epoch: 343  Training loss = 1.9568  Validation loss = 5.2248  \n",
      "\n",
      "Fold: 4  Epoch: 344  Training loss = 1.9566  Validation loss = 5.2245  \n",
      "\n",
      "Fold: 4  Epoch: 345  Training loss = 1.9565  Validation loss = 5.2243  \n",
      "\n",
      "Fold: 4  Epoch: 346  Training loss = 1.9564  Validation loss = 5.2240  \n",
      "\n",
      "Fold: 4  Epoch: 347  Training loss = 1.9562  Validation loss = 5.2238  \n",
      "\n",
      "Fold: 4  Epoch: 348  Training loss = 1.9560  Validation loss = 5.2235  \n",
      "\n",
      "Fold: 4  Epoch: 349  Training loss = 1.9559  Validation loss = 5.2232  \n",
      "\n",
      "Fold: 4  Epoch: 350  Training loss = 1.9557  Validation loss = 5.2230  \n",
      "\n",
      "Fold: 4  Epoch: 351  Training loss = 1.9556  Validation loss = 5.2227  \n",
      "\n",
      "Fold: 4  Epoch: 352  Training loss = 1.9554  Validation loss = 5.2224  \n",
      "\n",
      "Fold: 4  Epoch: 353  Training loss = 1.9552  Validation loss = 5.2221  \n",
      "\n",
      "Fold: 4  Epoch: 354  Training loss = 1.9550  Validation loss = 5.2218  \n",
      "\n",
      "Fold: 4  Epoch: 355  Training loss = 1.9549  Validation loss = 5.2216  \n",
      "\n",
      "Fold: 4  Epoch: 356  Training loss = 1.9547  Validation loss = 5.2212  \n",
      "\n",
      "Fold: 4  Epoch: 357  Training loss = 1.9546  Validation loss = 5.2210  \n",
      "\n",
      "Fold: 4  Epoch: 358  Training loss = 1.9544  Validation loss = 5.2207  \n",
      "\n",
      "Fold: 4  Epoch: 359  Training loss = 1.9543  Validation loss = 5.2204  \n",
      "\n",
      "Fold: 4  Epoch: 360  Training loss = 1.9541  Validation loss = 5.2202  \n",
      "\n",
      "Fold: 4  Epoch: 361  Training loss = 1.9539  Validation loss = 5.2199  \n",
      "\n",
      "Fold: 4  Epoch: 362  Training loss = 1.9538  Validation loss = 5.2195  \n",
      "\n",
      "Fold: 4  Epoch: 363  Training loss = 1.9536  Validation loss = 5.2193  \n",
      "\n",
      "Fold: 4  Epoch: 364  Training loss = 1.9534  Validation loss = 5.2189  \n",
      "\n",
      "Fold: 4  Epoch: 365  Training loss = 1.9532  Validation loss = 5.2187  \n",
      "\n",
      "Fold: 4  Epoch: 366  Training loss = 1.9531  Validation loss = 5.2184  \n",
      "\n",
      "Fold: 4  Epoch: 367  Training loss = 1.9530  Validation loss = 5.2182  \n",
      "\n",
      "Fold: 4  Epoch: 368  Training loss = 1.9528  Validation loss = 5.2178  \n",
      "\n",
      "Fold: 4  Epoch: 369  Training loss = 1.9526  Validation loss = 5.2176  \n",
      "\n",
      "Fold: 4  Epoch: 370  Training loss = 1.9525  Validation loss = 5.2173  \n",
      "\n",
      "Fold: 4  Epoch: 371  Training loss = 1.9523  Validation loss = 5.2170  \n",
      "\n",
      "Fold: 4  Epoch: 372  Training loss = 1.9522  Validation loss = 5.2168  \n",
      "\n",
      "Fold: 4  Epoch: 373  Training loss = 1.9520  Validation loss = 5.2164  \n",
      "\n",
      "Fold: 4  Epoch: 374  Training loss = 1.9518  Validation loss = 5.2161  \n",
      "\n",
      "Fold: 4  Epoch: 375  Training loss = 1.9516  Validation loss = 5.2157  \n",
      "\n",
      "Fold: 4  Epoch: 376  Training loss = 1.9514  Validation loss = 5.2154  \n",
      "\n",
      "Fold: 4  Epoch: 377  Training loss = 1.9513  Validation loss = 5.2152  \n",
      "\n",
      "Fold: 4  Epoch: 378  Training loss = 1.9512  Validation loss = 5.2149  \n",
      "\n",
      "Fold: 4  Epoch: 379  Training loss = 1.9510  Validation loss = 5.2147  \n",
      "\n",
      "Fold: 4  Epoch: 380  Training loss = 1.9508  Validation loss = 5.2143  \n",
      "\n",
      "Fold: 4  Epoch: 381  Training loss = 1.9506  Validation loss = 5.2140  \n",
      "\n",
      "Fold: 4  Epoch: 382  Training loss = 1.9505  Validation loss = 5.2138  \n",
      "\n",
      "Fold: 4  Epoch: 383  Training loss = 1.9504  Validation loss = 5.2135  \n",
      "\n",
      "Fold: 4  Epoch: 384  Training loss = 1.9502  Validation loss = 5.2132  \n",
      "\n",
      "Fold: 4  Epoch: 385  Training loss = 1.9501  Validation loss = 5.2130  \n",
      "\n",
      "Fold: 4  Epoch: 386  Training loss = 1.9499  Validation loss = 5.2127  \n",
      "\n",
      "Fold: 4  Epoch: 387  Training loss = 1.9498  Validation loss = 5.2124  \n",
      "\n",
      "Fold: 4  Epoch: 388  Training loss = 1.9496  Validation loss = 5.2121  \n",
      "\n",
      "Fold: 4  Epoch: 389  Training loss = 1.9495  Validation loss = 5.2119  \n",
      "\n",
      "Fold: 4  Epoch: 390  Training loss = 1.9493  Validation loss = 5.2116  \n",
      "\n",
      "Fold: 4  Epoch: 391  Training loss = 1.9491  Validation loss = 5.2113  \n",
      "\n",
      "Fold: 4  Epoch: 392  Training loss = 1.9490  Validation loss = 5.2111  \n",
      "\n",
      "Fold: 4  Epoch: 393  Training loss = 1.9489  Validation loss = 5.2109  \n",
      "\n",
      "Fold: 4  Epoch: 394  Training loss = 1.9487  Validation loss = 5.2106  \n",
      "\n",
      "Fold: 4  Epoch: 395  Training loss = 1.9486  Validation loss = 5.2104  \n",
      "\n",
      "Fold: 4  Epoch: 396  Training loss = 1.9484  Validation loss = 5.2100  \n",
      "\n",
      "Fold: 4  Epoch: 397  Training loss = 1.9483  Validation loss = 5.2098  \n",
      "\n",
      "Fold: 4  Epoch: 398  Training loss = 1.9481  Validation loss = 5.2095  \n",
      "\n",
      "Fold: 4  Epoch: 399  Training loss = 1.9479  Validation loss = 5.2092  \n",
      "\n",
      "Fold: 4  Epoch: 400  Training loss = 1.9478  Validation loss = 5.2090  \n",
      "\n",
      "Fold: 4  Epoch: 401  Training loss = 1.9476  Validation loss = 5.2087  \n",
      "\n",
      "Fold: 4  Epoch: 402  Training loss = 1.9475  Validation loss = 5.2084  \n",
      "\n",
      "Fold: 4  Epoch: 403  Training loss = 1.9473  Validation loss = 5.2081  \n",
      "\n",
      "Fold: 4  Epoch: 404  Training loss = 1.9471  Validation loss = 5.2078  \n",
      "\n",
      "Fold: 4  Epoch: 405  Training loss = 1.9470  Validation loss = 5.2075  \n",
      "\n",
      "Fold: 4  Epoch: 406  Training loss = 1.9469  Validation loss = 5.2073  \n",
      "\n",
      "Fold: 4  Epoch: 407  Training loss = 1.9467  Validation loss = 5.2070  \n",
      "\n",
      "Fold: 4  Epoch: 408  Training loss = 1.9465  Validation loss = 5.2067  \n",
      "\n",
      "Fold: 4  Epoch: 409  Training loss = 1.9464  Validation loss = 5.2064  \n",
      "\n",
      "Fold: 4  Epoch: 410  Training loss = 1.9462  Validation loss = 5.2061  \n",
      "\n",
      "Fold: 4  Epoch: 411  Training loss = 1.9460  Validation loss = 5.2057  \n",
      "\n",
      "Fold: 4  Epoch: 412  Training loss = 1.9458  Validation loss = 5.2054  \n",
      "\n",
      "Fold: 4  Epoch: 413  Training loss = 1.9457  Validation loss = 5.2051  \n",
      "\n",
      "Fold: 4  Epoch: 414  Training loss = 1.9455  Validation loss = 5.2048  \n",
      "\n",
      "Fold: 4  Epoch: 415  Training loss = 1.9453  Validation loss = 5.2046  \n",
      "\n",
      "Fold: 4  Epoch: 416  Training loss = 1.9452  Validation loss = 5.2043  \n",
      "\n",
      "Fold: 4  Epoch: 417  Training loss = 1.9450  Validation loss = 5.2040  \n",
      "\n",
      "Fold: 4  Epoch: 418  Training loss = 1.9449  Validation loss = 5.2038  \n",
      "\n",
      "Fold: 4  Epoch: 419  Training loss = 1.9448  Validation loss = 5.2036  \n",
      "\n",
      "Fold: 4  Epoch: 420  Training loss = 1.9446  Validation loss = 5.2033  \n",
      "\n",
      "Fold: 4  Epoch: 421  Training loss = 1.9444  Validation loss = 5.2029  \n",
      "\n",
      "Fold: 4  Epoch: 422  Training loss = 1.9443  Validation loss = 5.2027  \n",
      "\n",
      "Fold: 4  Epoch: 423  Training loss = 1.9441  Validation loss = 5.2024  \n",
      "\n",
      "Fold: 4  Epoch: 424  Training loss = 1.9440  Validation loss = 5.2021  \n",
      "\n",
      "Fold: 4  Epoch: 425  Training loss = 1.9438  Validation loss = 5.2019  \n",
      "\n",
      "Fold: 4  Epoch: 426  Training loss = 1.9436  Validation loss = 5.2015  \n",
      "\n",
      "Fold: 4  Epoch: 427  Training loss = 1.9434  Validation loss = 5.2012  \n",
      "\n",
      "Fold: 4  Epoch: 428  Training loss = 1.9433  Validation loss = 5.2009  \n",
      "\n",
      "Fold: 4  Epoch: 429  Training loss = 1.9432  Validation loss = 5.2007  \n",
      "\n",
      "Fold: 4  Epoch: 430  Training loss = 1.9430  Validation loss = 5.2004  \n",
      "\n",
      "Fold: 4  Epoch: 431  Training loss = 1.9429  Validation loss = 5.2003  \n",
      "\n",
      "Fold: 4  Epoch: 432  Training loss = 1.9428  Validation loss = 5.2000  \n",
      "\n",
      "Fold: 4  Epoch: 433  Training loss = 1.9426  Validation loss = 5.1997  \n",
      "\n",
      "Fold: 4  Epoch: 434  Training loss = 1.9424  Validation loss = 5.1994  \n",
      "\n",
      "Fold: 4  Epoch: 435  Training loss = 1.9423  Validation loss = 5.1991  \n",
      "\n",
      "Fold: 4  Epoch: 436  Training loss = 1.9421  Validation loss = 5.1988  \n",
      "\n",
      "Fold: 4  Epoch: 437  Training loss = 1.9420  Validation loss = 5.1986  \n",
      "\n",
      "Fold: 4  Epoch: 438  Training loss = 1.9418  Validation loss = 5.1983  \n",
      "\n",
      "Fold: 4  Epoch: 439  Training loss = 1.9417  Validation loss = 5.1981  \n",
      "\n",
      "Fold: 4  Epoch: 440  Training loss = 1.9415  Validation loss = 5.1978  \n",
      "\n",
      "Fold: 4  Epoch: 441  Training loss = 1.9414  Validation loss = 5.1975  \n",
      "\n",
      "Fold: 4  Epoch: 442  Training loss = 1.9412  Validation loss = 5.1973  \n",
      "\n",
      "Fold: 4  Epoch: 443  Training loss = 1.9411  Validation loss = 5.1971  \n",
      "\n",
      "Fold: 4  Epoch: 444  Training loss = 1.9409  Validation loss = 5.1968  \n",
      "\n",
      "Fold: 4  Epoch: 445  Training loss = 1.9408  Validation loss = 5.1966  \n",
      "\n",
      "Fold: 4  Epoch: 446  Training loss = 1.9407  Validation loss = 5.1963  \n",
      "\n",
      "Fold: 4  Epoch: 447  Training loss = 1.9405  Validation loss = 5.1961  \n",
      "\n",
      "Fold: 4  Epoch: 448  Training loss = 1.9404  Validation loss = 5.1959  \n",
      "\n",
      "Fold: 4  Epoch: 449  Training loss = 1.9403  Validation loss = 5.1956  \n",
      "\n",
      "Fold: 4  Epoch: 450  Training loss = 1.9401  Validation loss = 5.1953  \n",
      "\n",
      "Fold: 4  Epoch: 451  Training loss = 1.9400  Validation loss = 5.1951  \n",
      "\n",
      "Fold: 4  Epoch: 452  Training loss = 1.9398  Validation loss = 5.1947  \n",
      "\n",
      "Fold: 4  Epoch: 453  Training loss = 1.9396  Validation loss = 5.1945  \n",
      "\n",
      "Fold: 4  Epoch: 454  Training loss = 1.9395  Validation loss = 5.1942  \n",
      "\n",
      "Fold: 4  Epoch: 455  Training loss = 1.9393  Validation loss = 5.1939  \n",
      "\n",
      "Fold: 4  Epoch: 456  Training loss = 1.9392  Validation loss = 5.1937  \n",
      "\n",
      "Fold: 4  Epoch: 457  Training loss = 1.9391  Validation loss = 5.1935  \n",
      "\n",
      "Fold: 4  Epoch: 458  Training loss = 1.9390  Validation loss = 5.1933  \n",
      "\n",
      "Fold: 4  Epoch: 459  Training loss = 1.9388  Validation loss = 5.1929  \n",
      "\n",
      "Fold: 4  Epoch: 460  Training loss = 1.9387  Validation loss = 5.1927  \n",
      "\n",
      "Fold: 4  Epoch: 461  Training loss = 1.9385  Validation loss = 5.1925  \n",
      "\n",
      "Fold: 4  Epoch: 462  Training loss = 1.9384  Validation loss = 5.1923  \n",
      "\n",
      "Fold: 4  Epoch: 463  Training loss = 1.9383  Validation loss = 5.1920  \n",
      "\n",
      "Fold: 4  Epoch: 464  Training loss = 1.9381  Validation loss = 5.1917  \n",
      "\n",
      "Fold: 4  Epoch: 465  Training loss = 1.9379  Validation loss = 5.1914  \n",
      "\n",
      "Fold: 4  Epoch: 466  Training loss = 1.9377  Validation loss = 5.1911  \n",
      "\n",
      "Fold: 4  Epoch: 467  Training loss = 1.9376  Validation loss = 5.1908  \n",
      "\n",
      "Fold: 4  Epoch: 468  Training loss = 1.9374  Validation loss = 5.1905  \n",
      "\n",
      "Fold: 4  Epoch: 469  Training loss = 1.9373  Validation loss = 5.1903  \n",
      "\n",
      "Fold: 4  Epoch: 470  Training loss = 1.9371  Validation loss = 5.1900  \n",
      "\n",
      "Fold: 4  Epoch: 471  Training loss = 1.9369  Validation loss = 5.1897  \n",
      "\n",
      "Fold: 4  Epoch: 472  Training loss = 1.9368  Validation loss = 5.1894  \n",
      "\n",
      "Fold: 4  Epoch: 473  Training loss = 1.9367  Validation loss = 5.1892  \n",
      "\n",
      "Fold: 4  Epoch: 474  Training loss = 1.9365  Validation loss = 5.1889  \n",
      "\n",
      "Fold: 4  Epoch: 475  Training loss = 1.9364  Validation loss = 5.1886  \n",
      "\n",
      "Fold: 4  Epoch: 476  Training loss = 1.9362  Validation loss = 5.1884  \n",
      "\n",
      "Fold: 4  Epoch: 477  Training loss = 1.9361  Validation loss = 5.1881  \n",
      "\n",
      "Fold: 4  Epoch: 478  Training loss = 1.9359  Validation loss = 5.1878  \n",
      "\n",
      "Fold: 4  Epoch: 479  Training loss = 1.9358  Validation loss = 5.1875  \n",
      "\n",
      "Fold: 4  Epoch: 480  Training loss = 1.9356  Validation loss = 5.1872  \n",
      "\n",
      "Fold: 4  Epoch: 481  Training loss = 1.9354  Validation loss = 5.1869  \n",
      "\n",
      "Fold: 4  Epoch: 482  Training loss = 1.9353  Validation loss = 5.1867  \n",
      "\n",
      "Fold: 4  Epoch: 483  Training loss = 1.9352  Validation loss = 5.1864  \n",
      "\n",
      "Fold: 4  Epoch: 484  Training loss = 1.9350  Validation loss = 5.1861  \n",
      "\n",
      "Fold: 4  Epoch: 485  Training loss = 1.9349  Validation loss = 5.1859  \n",
      "\n",
      "Fold: 4  Epoch: 486  Training loss = 1.9347  Validation loss = 5.1857  \n",
      "\n",
      "Fold: 4  Epoch: 487  Training loss = 1.9346  Validation loss = 5.1854  \n",
      "\n",
      "Fold: 4  Epoch: 488  Training loss = 1.9344  Validation loss = 5.1851  \n",
      "\n",
      "Fold: 4  Epoch: 489  Training loss = 1.9343  Validation loss = 5.1848  \n",
      "\n",
      "Fold: 4  Epoch: 490  Training loss = 1.9341  Validation loss = 5.1846  \n",
      "\n",
      "Fold: 4  Epoch: 491  Training loss = 1.9340  Validation loss = 5.1844  \n",
      "\n",
      "Fold: 4  Epoch: 492  Training loss = 1.9338  Validation loss = 5.1841  \n",
      "\n",
      "Fold: 4  Epoch: 493  Training loss = 1.9337  Validation loss = 5.1839  \n",
      "\n",
      "Fold: 4  Epoch: 494  Training loss = 1.9335  Validation loss = 5.1835  \n",
      "\n",
      "Fold: 4  Epoch: 495  Training loss = 1.9334  Validation loss = 5.1832  \n",
      "\n",
      "Fold: 4  Epoch: 496  Training loss = 1.9332  Validation loss = 5.1830  \n",
      "\n",
      "Fold: 4  Epoch: 497  Training loss = 1.9331  Validation loss = 5.1828  \n",
      "\n",
      "Fold: 4  Epoch: 498  Training loss = 1.9329  Validation loss = 5.1825  \n",
      "\n",
      "Fold: 4  Epoch: 499  Training loss = 1.9328  Validation loss = 5.1822  \n",
      "\n",
      "Fold: 4  Epoch: 500  Training loss = 1.9327  Validation loss = 5.1821  \n",
      "\n",
      "Check model:  Fold: 4  Epoch: 500  Training loss = 1.9327  Validation loss = 5.1821  \n",
      "\n",
      "Fold: 5  Epoch: 1  Training loss = 2.2926  Validation loss = 4.9120  \n",
      "\n",
      "Fold: 5  Epoch: 2  Training loss = 2.2924  Validation loss = 4.9116  \n",
      "\n",
      "Fold: 5  Epoch: 3  Training loss = 2.2922  Validation loss = 4.9113  \n",
      "\n",
      "Fold: 5  Epoch: 4  Training loss = 2.2920  Validation loss = 4.9110  \n",
      "\n",
      "Fold: 5  Epoch: 5  Training loss = 2.2918  Validation loss = 4.9106  \n",
      "\n",
      "Fold: 5  Epoch: 6  Training loss = 2.2916  Validation loss = 4.9103  \n",
      "\n",
      "Fold: 5  Epoch: 7  Training loss = 2.2913  Validation loss = 4.9100  \n",
      "\n",
      "Fold: 5  Epoch: 8  Training loss = 2.2911  Validation loss = 4.9096  \n",
      "\n",
      "Fold: 5  Epoch: 9  Training loss = 2.2908  Validation loss = 4.9092  \n",
      "\n",
      "Fold: 5  Epoch: 10  Training loss = 2.2906  Validation loss = 4.9089  \n",
      "\n",
      "Fold: 5  Epoch: 11  Training loss = 2.2904  Validation loss = 4.9086  \n",
      "\n",
      "Fold: 5  Epoch: 12  Training loss = 2.2902  Validation loss = 4.9082  \n",
      "\n",
      "Fold: 5  Epoch: 13  Training loss = 2.2900  Validation loss = 4.9079  \n",
      "\n",
      "Fold: 5  Epoch: 14  Training loss = 2.2898  Validation loss = 4.9076  \n",
      "\n",
      "Fold: 5  Epoch: 15  Training loss = 2.2896  Validation loss = 4.9072  \n",
      "\n",
      "Fold: 5  Epoch: 16  Training loss = 2.2893  Validation loss = 4.9069  \n",
      "\n",
      "Fold: 5  Epoch: 17  Training loss = 2.2892  Validation loss = 4.9066  \n",
      "\n",
      "Fold: 5  Epoch: 18  Training loss = 2.2890  Validation loss = 4.9063  \n",
      "\n",
      "Fold: 5  Epoch: 19  Training loss = 2.2888  Validation loss = 4.9060  \n",
      "\n",
      "Fold: 5  Epoch: 20  Training loss = 2.2885  Validation loss = 4.9057  \n",
      "\n",
      "Fold: 5  Epoch: 21  Training loss = 2.2883  Validation loss = 4.9054  \n",
      "\n",
      "Fold: 5  Epoch: 22  Training loss = 2.2881  Validation loss = 4.9051  \n",
      "\n",
      "Fold: 5  Epoch: 23  Training loss = 2.2880  Validation loss = 4.9050  \n",
      "\n",
      "Fold: 5  Epoch: 24  Training loss = 2.2878  Validation loss = 4.9046  \n",
      "\n",
      "Fold: 5  Epoch: 25  Training loss = 2.2876  Validation loss = 4.9043  \n",
      "\n",
      "Fold: 5  Epoch: 26  Training loss = 2.2874  Validation loss = 4.9040  \n",
      "\n",
      "Fold: 5  Epoch: 27  Training loss = 2.2871  Validation loss = 4.9035  \n",
      "\n",
      "Fold: 5  Epoch: 28  Training loss = 2.2869  Validation loss = 4.9032  \n",
      "\n",
      "Fold: 5  Epoch: 29  Training loss = 2.2867  Validation loss = 4.9029  \n",
      "\n",
      "Fold: 5  Epoch: 30  Training loss = 2.2865  Validation loss = 4.9027  \n",
      "\n",
      "Fold: 5  Epoch: 31  Training loss = 2.2863  Validation loss = 4.9024  \n",
      "\n",
      "Fold: 5  Epoch: 32  Training loss = 2.2861  Validation loss = 4.9021  \n",
      "\n",
      "Fold: 5  Epoch: 33  Training loss = 2.2859  Validation loss = 4.9017  \n",
      "\n",
      "Fold: 5  Epoch: 34  Training loss = 2.2856  Validation loss = 4.9014  \n",
      "\n",
      "Fold: 5  Epoch: 35  Training loss = 2.2854  Validation loss = 4.9010  \n",
      "\n",
      "Fold: 5  Epoch: 36  Training loss = 2.2852  Validation loss = 4.9006  \n",
      "\n",
      "Fold: 5  Epoch: 37  Training loss = 2.2849  Validation loss = 4.9003  \n",
      "\n",
      "Fold: 5  Epoch: 38  Training loss = 2.2847  Validation loss = 4.8999  \n",
      "\n",
      "Fold: 5  Epoch: 39  Training loss = 2.2845  Validation loss = 4.8996  \n",
      "\n",
      "Fold: 5  Epoch: 40  Training loss = 2.2843  Validation loss = 4.8993  \n",
      "\n",
      "Fold: 5  Epoch: 41  Training loss = 2.2841  Validation loss = 4.8990  \n",
      "\n",
      "Fold: 5  Epoch: 42  Training loss = 2.2839  Validation loss = 4.8987  \n",
      "\n",
      "Fold: 5  Epoch: 43  Training loss = 2.2837  Validation loss = 4.8984  \n",
      "\n",
      "Fold: 5  Epoch: 44  Training loss = 2.2835  Validation loss = 4.8980  \n",
      "\n",
      "Fold: 5  Epoch: 45  Training loss = 2.2833  Validation loss = 4.8978  \n",
      "\n",
      "Fold: 5  Epoch: 46  Training loss = 2.2831  Validation loss = 4.8975  \n",
      "\n",
      "Fold: 5  Epoch: 47  Training loss = 2.2829  Validation loss = 4.8972  \n",
      "\n",
      "Fold: 5  Epoch: 48  Training loss = 2.2827  Validation loss = 4.8968  \n",
      "\n",
      "Fold: 5  Epoch: 49  Training loss = 2.2825  Validation loss = 4.8965  \n",
      "\n",
      "Fold: 5  Epoch: 50  Training loss = 2.2823  Validation loss = 4.8962  \n",
      "\n",
      "Fold: 5  Epoch: 51  Training loss = 2.2821  Validation loss = 4.8960  \n",
      "\n",
      "Fold: 5  Epoch: 52  Training loss = 2.2820  Validation loss = 4.8958  \n",
      "\n",
      "Fold: 5  Epoch: 53  Training loss = 2.2818  Validation loss = 4.8954  \n",
      "\n",
      "Fold: 5  Epoch: 54  Training loss = 2.2816  Validation loss = 4.8952  \n",
      "\n",
      "Fold: 5  Epoch: 55  Training loss = 2.2814  Validation loss = 4.8949  \n",
      "\n",
      "Fold: 5  Epoch: 56  Training loss = 2.2812  Validation loss = 4.8946  \n",
      "\n",
      "Fold: 5  Epoch: 57  Training loss = 2.2811  Validation loss = 4.8944  \n",
      "\n",
      "Fold: 5  Epoch: 58  Training loss = 2.2808  Validation loss = 4.8940  \n",
      "\n",
      "Fold: 5  Epoch: 59  Training loss = 2.2806  Validation loss = 4.8937  \n",
      "\n",
      "Fold: 5  Epoch: 60  Training loss = 2.2804  Validation loss = 4.8934  \n",
      "\n",
      "Fold: 5  Epoch: 61  Training loss = 2.2802  Validation loss = 4.8930  \n",
      "\n",
      "Fold: 5  Epoch: 62  Training loss = 2.2800  Validation loss = 4.8926  \n",
      "\n",
      "Fold: 5  Epoch: 63  Training loss = 2.2798  Validation loss = 4.8924  \n",
      "\n",
      "Fold: 5  Epoch: 64  Training loss = 2.2796  Validation loss = 4.8921  \n",
      "\n",
      "Fold: 5  Epoch: 65  Training loss = 2.2794  Validation loss = 4.8917  \n",
      "\n",
      "Fold: 5  Epoch: 66  Training loss = 2.2792  Validation loss = 4.8915  \n",
      "\n",
      "Fold: 5  Epoch: 67  Training loss = 2.2790  Validation loss = 4.8912  \n",
      "\n",
      "Fold: 5  Epoch: 68  Training loss = 2.2788  Validation loss = 4.8908  \n",
      "\n",
      "Fold: 5  Epoch: 69  Training loss = 2.2786  Validation loss = 4.8906  \n",
      "\n",
      "Fold: 5  Epoch: 70  Training loss = 2.2785  Validation loss = 4.8904  \n",
      "\n",
      "Fold: 5  Epoch: 71  Training loss = 2.2783  Validation loss = 4.8901  \n",
      "\n",
      "Fold: 5  Epoch: 72  Training loss = 2.2781  Validation loss = 4.8898  \n",
      "\n",
      "Fold: 5  Epoch: 73  Training loss = 2.2779  Validation loss = 4.8896  \n",
      "\n",
      "Fold: 5  Epoch: 74  Training loss = 2.2777  Validation loss = 4.8892  \n",
      "\n",
      "Fold: 5  Epoch: 75  Training loss = 2.2774  Validation loss = 4.8888  \n",
      "\n",
      "Fold: 5  Epoch: 76  Training loss = 2.2772  Validation loss = 4.8885  \n",
      "\n",
      "Fold: 5  Epoch: 77  Training loss = 2.2771  Validation loss = 4.8883  \n",
      "\n",
      "Fold: 5  Epoch: 78  Training loss = 2.2769  Validation loss = 4.8880  \n",
      "\n",
      "Fold: 5  Epoch: 79  Training loss = 2.2767  Validation loss = 4.8877  \n",
      "\n",
      "Fold: 5  Epoch: 80  Training loss = 2.2765  Validation loss = 4.8874  \n",
      "\n",
      "Fold: 5  Epoch: 81  Training loss = 2.2763  Validation loss = 4.8871  \n",
      "\n",
      "Fold: 5  Epoch: 82  Training loss = 2.2761  Validation loss = 4.8868  \n",
      "\n",
      "Fold: 5  Epoch: 83  Training loss = 2.2759  Validation loss = 4.8865  \n",
      "\n",
      "Fold: 5  Epoch: 84  Training loss = 2.2757  Validation loss = 4.8861  \n",
      "\n",
      "Fold: 5  Epoch: 85  Training loss = 2.2755  Validation loss = 4.8859  \n",
      "\n",
      "Fold: 5  Epoch: 86  Training loss = 2.2753  Validation loss = 4.8856  \n",
      "\n",
      "Fold: 5  Epoch: 87  Training loss = 2.2751  Validation loss = 4.8852  \n",
      "\n",
      "Fold: 5  Epoch: 88  Training loss = 2.2749  Validation loss = 4.8850  \n",
      "\n",
      "Fold: 5  Epoch: 89  Training loss = 2.2747  Validation loss = 4.8847  \n",
      "\n",
      "Fold: 5  Epoch: 90  Training loss = 2.2745  Validation loss = 4.8843  \n",
      "\n",
      "Fold: 5  Epoch: 91  Training loss = 2.2742  Validation loss = 4.8839  \n",
      "\n",
      "Fold: 5  Epoch: 92  Training loss = 2.2740  Validation loss = 4.8836  \n",
      "\n",
      "Fold: 5  Epoch: 93  Training loss = 2.2739  Validation loss = 4.8833  \n",
      "\n",
      "Fold: 5  Epoch: 94  Training loss = 2.2737  Validation loss = 4.8830  \n",
      "\n",
      "Fold: 5  Epoch: 95  Training loss = 2.2734  Validation loss = 4.8826  \n",
      "\n",
      "Fold: 5  Epoch: 96  Training loss = 2.2732  Validation loss = 4.8822  \n",
      "\n",
      "Fold: 5  Epoch: 97  Training loss = 2.2729  Validation loss = 4.8818  \n",
      "\n",
      "Fold: 5  Epoch: 98  Training loss = 2.2727  Validation loss = 4.8815  \n",
      "\n",
      "Fold: 5  Epoch: 99  Training loss = 2.2725  Validation loss = 4.8812  \n",
      "\n",
      "Fold: 5  Epoch: 100  Training loss = 2.2723  Validation loss = 4.8809  \n",
      "\n",
      "Fold: 5  Epoch: 101  Training loss = 2.2721  Validation loss = 4.8806  \n",
      "\n",
      "Fold: 5  Epoch: 102  Training loss = 2.2720  Validation loss = 4.8803  \n",
      "\n",
      "Fold: 5  Epoch: 103  Training loss = 2.2717  Validation loss = 4.8800  \n",
      "\n",
      "Fold: 5  Epoch: 104  Training loss = 2.2716  Validation loss = 4.8798  \n",
      "\n",
      "Fold: 5  Epoch: 105  Training loss = 2.2714  Validation loss = 4.8795  \n",
      "\n",
      "Fold: 5  Epoch: 106  Training loss = 2.2712  Validation loss = 4.8791  \n",
      "\n",
      "Fold: 5  Epoch: 107  Training loss = 2.2710  Validation loss = 4.8789  \n",
      "\n",
      "Fold: 5  Epoch: 108  Training loss = 2.2708  Validation loss = 4.8785  \n",
      "\n",
      "Fold: 5  Epoch: 109  Training loss = 2.2706  Validation loss = 4.8783  \n",
      "\n",
      "Fold: 5  Epoch: 110  Training loss = 2.2704  Validation loss = 4.8779  \n",
      "\n",
      "Fold: 5  Epoch: 111  Training loss = 2.2702  Validation loss = 4.8776  \n",
      "\n",
      "Fold: 5  Epoch: 112  Training loss = 2.2699  Validation loss = 4.8771  \n",
      "\n",
      "Fold: 5  Epoch: 113  Training loss = 2.2697  Validation loss = 4.8769  \n",
      "\n",
      "Fold: 5  Epoch: 114  Training loss = 2.2695  Validation loss = 4.8765  \n",
      "\n",
      "Fold: 5  Epoch: 115  Training loss = 2.2693  Validation loss = 4.8762  \n",
      "\n",
      "Fold: 5  Epoch: 116  Training loss = 2.2690  Validation loss = 4.8758  \n",
      "\n",
      "Fold: 5  Epoch: 117  Training loss = 2.2689  Validation loss = 4.8755  \n",
      "\n",
      "Fold: 5  Epoch: 118  Training loss = 2.2687  Validation loss = 4.8753  \n",
      "\n",
      "Fold: 5  Epoch: 119  Training loss = 2.2685  Validation loss = 4.8750  \n",
      "\n",
      "Fold: 5  Epoch: 120  Training loss = 2.2682  Validation loss = 4.8745  \n",
      "\n",
      "Fold: 5  Epoch: 121  Training loss = 2.2680  Validation loss = 4.8741  \n",
      "\n",
      "Fold: 5  Epoch: 122  Training loss = 2.2678  Validation loss = 4.8738  \n",
      "\n",
      "Fold: 5  Epoch: 123  Training loss = 2.2676  Validation loss = 4.8734  \n",
      "\n",
      "Fold: 5  Epoch: 124  Training loss = 2.2673  Validation loss = 4.8731  \n",
      "\n",
      "Fold: 5  Epoch: 125  Training loss = 2.2672  Validation loss = 4.8728  \n",
      "\n",
      "Fold: 5  Epoch: 126  Training loss = 2.2670  Validation loss = 4.8725  \n",
      "\n",
      "Fold: 5  Epoch: 127  Training loss = 2.2668  Validation loss = 4.8722  \n",
      "\n",
      "Fold: 5  Epoch: 128  Training loss = 2.2666  Validation loss = 4.8719  \n",
      "\n",
      "Fold: 5  Epoch: 129  Training loss = 2.2663  Validation loss = 4.8715  \n",
      "\n",
      "Fold: 5  Epoch: 130  Training loss = 2.2661  Validation loss = 4.8712  \n",
      "\n",
      "Fold: 5  Epoch: 131  Training loss = 2.2659  Validation loss = 4.8708  \n",
      "\n",
      "Fold: 5  Epoch: 132  Training loss = 2.2656  Validation loss = 4.8703  \n",
      "\n",
      "Fold: 5  Epoch: 133  Training loss = 2.2654  Validation loss = 4.8701  \n",
      "\n",
      "Fold: 5  Epoch: 134  Training loss = 2.2652  Validation loss = 4.8698  \n",
      "\n",
      "Fold: 5  Epoch: 135  Training loss = 2.2650  Validation loss = 4.8695  \n",
      "\n",
      "Fold: 5  Epoch: 136  Training loss = 2.2648  Validation loss = 4.8692  \n",
      "\n",
      "Fold: 5  Epoch: 137  Training loss = 2.2646  Validation loss = 4.8689  \n",
      "\n",
      "Fold: 5  Epoch: 138  Training loss = 2.2645  Validation loss = 4.8686  \n",
      "\n",
      "Fold: 5  Epoch: 139  Training loss = 2.2643  Validation loss = 4.8684  \n",
      "\n",
      "Fold: 5  Epoch: 140  Training loss = 2.2641  Validation loss = 4.8681  \n",
      "\n",
      "Fold: 5  Epoch: 141  Training loss = 2.2639  Validation loss = 4.8679  \n",
      "\n",
      "Fold: 5  Epoch: 142  Training loss = 2.2637  Validation loss = 4.8676  \n",
      "\n",
      "Fold: 5  Epoch: 143  Training loss = 2.2636  Validation loss = 4.8674  \n",
      "\n",
      "Fold: 5  Epoch: 144  Training loss = 2.2634  Validation loss = 4.8671  \n",
      "\n",
      "Fold: 5  Epoch: 145  Training loss = 2.2631  Validation loss = 4.8667  \n",
      "\n",
      "Fold: 5  Epoch: 146  Training loss = 2.2630  Validation loss = 4.8664  \n",
      "\n",
      "Fold: 5  Epoch: 147  Training loss = 2.2628  Validation loss = 4.8661  \n",
      "\n",
      "Fold: 5  Epoch: 148  Training loss = 2.2626  Validation loss = 4.8659  \n",
      "\n",
      "Fold: 5  Epoch: 149  Training loss = 2.2624  Validation loss = 4.8656  \n",
      "\n",
      "Fold: 5  Epoch: 150  Training loss = 2.2622  Validation loss = 4.8652  \n",
      "\n",
      "Fold: 5  Epoch: 151  Training loss = 2.2621  Validation loss = 4.8650  \n",
      "\n",
      "Fold: 5  Epoch: 152  Training loss = 2.2618  Validation loss = 4.8646  \n",
      "\n",
      "Fold: 5  Epoch: 153  Training loss = 2.2617  Validation loss = 4.8644  \n",
      "\n",
      "Fold: 5  Epoch: 154  Training loss = 2.2615  Validation loss = 4.8641  \n",
      "\n",
      "Fold: 5  Epoch: 155  Training loss = 2.2613  Validation loss = 4.8638  \n",
      "\n",
      "Fold: 5  Epoch: 156  Training loss = 2.2611  Validation loss = 4.8635  \n",
      "\n",
      "Fold: 5  Epoch: 157  Training loss = 2.2609  Validation loss = 4.8633  \n",
      "\n",
      "Fold: 5  Epoch: 158  Training loss = 2.2608  Validation loss = 4.8630  \n",
      "\n",
      "Fold: 5  Epoch: 159  Training loss = 2.2606  Validation loss = 4.8627  \n",
      "\n",
      "Fold: 5  Epoch: 160  Training loss = 2.2604  Validation loss = 4.8625  \n",
      "\n",
      "Fold: 5  Epoch: 161  Training loss = 2.2602  Validation loss = 4.8622  \n",
      "\n",
      "Fold: 5  Epoch: 162  Training loss = 2.2601  Validation loss = 4.8620  \n",
      "\n",
      "Fold: 5  Epoch: 163  Training loss = 2.2598  Validation loss = 4.8616  \n",
      "\n",
      "Fold: 5  Epoch: 164  Training loss = 2.2596  Validation loss = 4.8613  \n",
      "\n",
      "Fold: 5  Epoch: 165  Training loss = 2.2595  Validation loss = 4.8610  \n",
      "\n",
      "Fold: 5  Epoch: 166  Training loss = 2.2592  Validation loss = 4.8606  \n",
      "\n",
      "Fold: 5  Epoch: 167  Training loss = 2.2590  Validation loss = 4.8603  \n",
      "\n",
      "Fold: 5  Epoch: 168  Training loss = 2.2588  Validation loss = 4.8600  \n",
      "\n",
      "Fold: 5  Epoch: 169  Training loss = 2.2586  Validation loss = 4.8597  \n",
      "\n",
      "Fold: 5  Epoch: 170  Training loss = 2.2584  Validation loss = 4.8594  \n",
      "\n",
      "Fold: 5  Epoch: 171  Training loss = 2.2583  Validation loss = 4.8591  \n",
      "\n",
      "Fold: 5  Epoch: 172  Training loss = 2.2581  Validation loss = 4.8590  \n",
      "\n",
      "Fold: 5  Epoch: 173  Training loss = 2.2579  Validation loss = 4.8586  \n",
      "\n",
      "Fold: 5  Epoch: 174  Training loss = 2.2578  Validation loss = 4.8585  \n",
      "\n",
      "Fold: 5  Epoch: 175  Training loss = 2.2576  Validation loss = 4.8582  \n",
      "\n",
      "Fold: 5  Epoch: 176  Training loss = 2.2575  Validation loss = 4.8579  \n",
      "\n",
      "Fold: 5  Epoch: 177  Training loss = 2.2573  Validation loss = 4.8577  \n",
      "\n",
      "Fold: 5  Epoch: 178  Training loss = 2.2570  Validation loss = 4.8573  \n",
      "\n",
      "Fold: 5  Epoch: 179  Training loss = 2.2568  Validation loss = 4.8569  \n",
      "\n",
      "Fold: 5  Epoch: 180  Training loss = 2.2567  Validation loss = 4.8567  \n",
      "\n",
      "Fold: 5  Epoch: 181  Training loss = 2.2565  Validation loss = 4.8565  \n",
      "\n",
      "Fold: 5  Epoch: 182  Training loss = 2.2563  Validation loss = 4.8561  \n",
      "\n",
      "Fold: 5  Epoch: 183  Training loss = 2.2561  Validation loss = 4.8558  \n",
      "\n",
      "Fold: 5  Epoch: 184  Training loss = 2.2559  Validation loss = 4.8555  \n",
      "\n",
      "Fold: 5  Epoch: 185  Training loss = 2.2557  Validation loss = 4.8551  \n",
      "\n",
      "Fold: 5  Epoch: 186  Training loss = 2.2555  Validation loss = 4.8548  \n",
      "\n",
      "Fold: 5  Epoch: 187  Training loss = 2.2553  Validation loss = 4.8546  \n",
      "\n",
      "Fold: 5  Epoch: 188  Training loss = 2.2550  Validation loss = 4.8541  \n",
      "\n",
      "Fold: 5  Epoch: 189  Training loss = 2.2548  Validation loss = 4.8538  \n",
      "\n",
      "Fold: 5  Epoch: 190  Training loss = 2.2546  Validation loss = 4.8535  \n",
      "\n",
      "Fold: 5  Epoch: 191  Training loss = 2.2544  Validation loss = 4.8532  \n",
      "\n",
      "Fold: 5  Epoch: 192  Training loss = 2.2542  Validation loss = 4.8528  \n",
      "\n",
      "Fold: 5  Epoch: 193  Training loss = 2.2540  Validation loss = 4.8525  \n",
      "\n",
      "Fold: 5  Epoch: 194  Training loss = 2.2537  Validation loss = 4.8521  \n",
      "\n",
      "Fold: 5  Epoch: 195  Training loss = 2.2536  Validation loss = 4.8518  \n",
      "\n",
      "Fold: 5  Epoch: 196  Training loss = 2.2534  Validation loss = 4.8515  \n",
      "\n",
      "Fold: 5  Epoch: 197  Training loss = 2.2532  Validation loss = 4.8512  \n",
      "\n",
      "Fold: 5  Epoch: 198  Training loss = 2.2530  Validation loss = 4.8509  \n",
      "\n",
      "Fold: 5  Epoch: 199  Training loss = 2.2527  Validation loss = 4.8505  \n",
      "\n",
      "Fold: 5  Epoch: 200  Training loss = 2.2525  Validation loss = 4.8501  \n",
      "\n",
      "Fold: 5  Epoch: 201  Training loss = 2.2524  Validation loss = 4.8499  \n",
      "\n",
      "Fold: 5  Epoch: 202  Training loss = 2.2522  Validation loss = 4.8496  \n",
      "\n",
      "Fold: 5  Epoch: 203  Training loss = 2.2519  Validation loss = 4.8492  \n",
      "\n",
      "Fold: 5  Epoch: 204  Training loss = 2.2518  Validation loss = 4.8489  \n",
      "\n",
      "Fold: 5  Epoch: 205  Training loss = 2.2516  Validation loss = 4.8486  \n",
      "\n",
      "Fold: 5  Epoch: 206  Training loss = 2.2514  Validation loss = 4.8484  \n",
      "\n",
      "Fold: 5  Epoch: 207  Training loss = 2.2513  Validation loss = 4.8482  \n",
      "\n",
      "Fold: 5  Epoch: 208  Training loss = 2.2511  Validation loss = 4.8479  \n",
      "\n",
      "Fold: 5  Epoch: 209  Training loss = 2.2509  Validation loss = 4.8476  \n",
      "\n",
      "Fold: 5  Epoch: 210  Training loss = 2.2506  Validation loss = 4.8472  \n",
      "\n",
      "Fold: 5  Epoch: 211  Training loss = 2.2505  Validation loss = 4.8469  \n",
      "\n",
      "Fold: 5  Epoch: 212  Training loss = 2.2502  Validation loss = 4.8465  \n",
      "\n",
      "Fold: 5  Epoch: 213  Training loss = 2.2500  Validation loss = 4.8462  \n",
      "\n",
      "Fold: 5  Epoch: 214  Training loss = 2.2498  Validation loss = 4.8459  \n",
      "\n",
      "Fold: 5  Epoch: 215  Training loss = 2.2496  Validation loss = 4.8455  \n",
      "\n",
      "Fold: 5  Epoch: 216  Training loss = 2.2494  Validation loss = 4.8452  \n",
      "\n",
      "Fold: 5  Epoch: 217  Training loss = 2.2493  Validation loss = 4.8449  \n",
      "\n",
      "Fold: 5  Epoch: 218  Training loss = 2.2491  Validation loss = 4.8446  \n",
      "\n",
      "Fold: 5  Epoch: 219  Training loss = 2.2489  Validation loss = 4.8445  \n",
      "\n",
      "Fold: 5  Epoch: 220  Training loss = 2.2488  Validation loss = 4.8442  \n",
      "\n",
      "Fold: 5  Epoch: 221  Training loss = 2.2486  Validation loss = 4.8439  \n",
      "\n",
      "Fold: 5  Epoch: 222  Training loss = 2.2484  Validation loss = 4.8436  \n",
      "\n",
      "Fold: 5  Epoch: 223  Training loss = 2.2482  Validation loss = 4.8434  \n",
      "\n",
      "Fold: 5  Epoch: 224  Training loss = 2.2480  Validation loss = 4.8430  \n",
      "\n",
      "Fold: 5  Epoch: 225  Training loss = 2.2478  Validation loss = 4.8428  \n",
      "\n",
      "Fold: 5  Epoch: 226  Training loss = 2.2476  Validation loss = 4.8425  \n",
      "\n",
      "Fold: 5  Epoch: 227  Training loss = 2.2475  Validation loss = 4.8422  \n",
      "\n",
      "Fold: 5  Epoch: 228  Training loss = 2.2472  Validation loss = 4.8418  \n",
      "\n",
      "Fold: 5  Epoch: 229  Training loss = 2.2470  Validation loss = 4.8414  \n",
      "\n",
      "Fold: 5  Epoch: 230  Training loss = 2.2468  Validation loss = 4.8411  \n",
      "\n",
      "Fold: 5  Epoch: 231  Training loss = 2.2466  Validation loss = 4.8409  \n",
      "\n",
      "Fold: 5  Epoch: 232  Training loss = 2.2464  Validation loss = 4.8406  \n",
      "\n",
      "Fold: 5  Epoch: 233  Training loss = 2.2462  Validation loss = 4.8403  \n",
      "\n",
      "Fold: 5  Epoch: 234  Training loss = 2.2461  Validation loss = 4.8402  \n",
      "\n",
      "Fold: 5  Epoch: 235  Training loss = 2.2459  Validation loss = 4.8399  \n",
      "\n",
      "Fold: 5  Epoch: 236  Training loss = 2.2457  Validation loss = 4.8396  \n",
      "\n",
      "Fold: 5  Epoch: 237  Training loss = 2.2456  Validation loss = 4.8393  \n",
      "\n",
      "Fold: 5  Epoch: 238  Training loss = 2.2454  Validation loss = 4.8391  \n",
      "\n",
      "Fold: 5  Epoch: 239  Training loss = 2.2452  Validation loss = 4.8388  \n",
      "\n",
      "Fold: 5  Epoch: 240  Training loss = 2.2450  Validation loss = 4.8384  \n",
      "\n",
      "Fold: 5  Epoch: 241  Training loss = 2.2448  Validation loss = 4.8381  \n",
      "\n",
      "Fold: 5  Epoch: 242  Training loss = 2.2446  Validation loss = 4.8378  \n",
      "\n",
      "Fold: 5  Epoch: 243  Training loss = 2.2445  Validation loss = 4.8376  \n",
      "\n",
      "Fold: 5  Epoch: 244  Training loss = 2.2443  Validation loss = 4.8373  \n",
      "\n",
      "Fold: 5  Epoch: 245  Training loss = 2.2440  Validation loss = 4.8369  \n",
      "\n",
      "Fold: 5  Epoch: 246  Training loss = 2.2438  Validation loss = 4.8366  \n",
      "\n",
      "Fold: 5  Epoch: 247  Training loss = 2.2436  Validation loss = 4.8362  \n",
      "\n",
      "Fold: 5  Epoch: 248  Training loss = 2.2434  Validation loss = 4.8359  \n",
      "\n",
      "Fold: 5  Epoch: 249  Training loss = 2.2432  Validation loss = 4.8355  \n",
      "\n",
      "Fold: 5  Epoch: 250  Training loss = 2.2430  Validation loss = 4.8353  \n",
      "\n",
      "Fold: 5  Epoch: 251  Training loss = 2.2428  Validation loss = 4.8350  \n",
      "\n",
      "Fold: 5  Epoch: 252  Training loss = 2.2426  Validation loss = 4.8346  \n",
      "\n",
      "Fold: 5  Epoch: 253  Training loss = 2.2424  Validation loss = 4.8343  \n",
      "\n",
      "Fold: 5  Epoch: 254  Training loss = 2.2422  Validation loss = 4.8340  \n",
      "\n",
      "Fold: 5  Epoch: 255  Training loss = 2.2420  Validation loss = 4.8337  \n",
      "\n",
      "Fold: 5  Epoch: 256  Training loss = 2.2418  Validation loss = 4.8334  \n",
      "\n",
      "Fold: 5  Epoch: 257  Training loss = 2.2416  Validation loss = 4.8331  \n",
      "\n",
      "Fold: 5  Epoch: 258  Training loss = 2.2414  Validation loss = 4.8327  \n",
      "\n",
      "Fold: 5  Epoch: 259  Training loss = 2.2412  Validation loss = 4.8324  \n",
      "\n",
      "Fold: 5  Epoch: 260  Training loss = 2.2410  Validation loss = 4.8321  \n",
      "\n",
      "Fold: 5  Epoch: 261  Training loss = 2.2408  Validation loss = 4.8319  \n",
      "\n",
      "Fold: 5  Epoch: 262  Training loss = 2.2406  Validation loss = 4.8316  \n",
      "\n",
      "Fold: 5  Epoch: 263  Training loss = 2.2404  Validation loss = 4.8312  \n",
      "\n",
      "Fold: 5  Epoch: 264  Training loss = 2.2402  Validation loss = 4.8309  \n",
      "\n",
      "Fold: 5  Epoch: 265  Training loss = 2.2400  Validation loss = 4.8305  \n",
      "\n",
      "Fold: 5  Epoch: 266  Training loss = 2.2398  Validation loss = 4.8303  \n",
      "\n",
      "Fold: 5  Epoch: 267  Training loss = 2.2396  Validation loss = 4.8300  \n",
      "\n",
      "Fold: 5  Epoch: 268  Training loss = 2.2395  Validation loss = 4.8297  \n",
      "\n",
      "Fold: 5  Epoch: 269  Training loss = 2.2392  Validation loss = 4.8294  \n",
      "\n",
      "Fold: 5  Epoch: 270  Training loss = 2.2390  Validation loss = 4.8291  \n",
      "\n",
      "Fold: 5  Epoch: 271  Training loss = 2.2389  Validation loss = 4.8289  \n",
      "\n",
      "Fold: 5  Epoch: 272  Training loss = 2.2387  Validation loss = 4.8287  \n",
      "\n",
      "Fold: 5  Epoch: 273  Training loss = 2.2386  Validation loss = 4.8284  \n",
      "\n",
      "Fold: 5  Epoch: 274  Training loss = 2.2384  Validation loss = 4.8281  \n",
      "\n",
      "Fold: 5  Epoch: 275  Training loss = 2.2382  Validation loss = 4.8279  \n",
      "\n",
      "Fold: 5  Epoch: 276  Training loss = 2.2381  Validation loss = 4.8276  \n",
      "\n",
      "Fold: 5  Epoch: 277  Training loss = 2.2379  Validation loss = 4.8273  \n",
      "\n",
      "Fold: 5  Epoch: 278  Training loss = 2.2377  Validation loss = 4.8271  \n",
      "\n",
      "Fold: 5  Epoch: 279  Training loss = 2.2375  Validation loss = 4.8268  \n",
      "\n",
      "Fold: 5  Epoch: 280  Training loss = 2.2374  Validation loss = 4.8266  \n",
      "\n",
      "Fold: 5  Epoch: 281  Training loss = 2.2372  Validation loss = 4.8263  \n",
      "\n",
      "Fold: 5  Epoch: 282  Training loss = 2.2370  Validation loss = 4.8260  \n",
      "\n",
      "Fold: 5  Epoch: 283  Training loss = 2.2369  Validation loss = 4.8258  \n",
      "\n",
      "Fold: 5  Epoch: 284  Training loss = 2.2367  Validation loss = 4.8255  \n",
      "\n",
      "Fold: 5  Epoch: 285  Training loss = 2.2365  Validation loss = 4.8251  \n",
      "\n",
      "Fold: 5  Epoch: 286  Training loss = 2.2363  Validation loss = 4.8248  \n",
      "\n",
      "Fold: 5  Epoch: 287  Training loss = 2.2361  Validation loss = 4.8244  \n",
      "\n",
      "Fold: 5  Epoch: 288  Training loss = 2.2359  Validation loss = 4.8241  \n",
      "\n",
      "Fold: 5  Epoch: 289  Training loss = 2.2357  Validation loss = 4.8237  \n",
      "\n",
      "Fold: 5  Epoch: 290  Training loss = 2.2355  Validation loss = 4.8234  \n",
      "\n",
      "Fold: 5  Epoch: 291  Training loss = 2.2353  Validation loss = 4.8232  \n",
      "\n",
      "Fold: 5  Epoch: 292  Training loss = 2.2351  Validation loss = 4.8228  \n",
      "\n",
      "Fold: 5  Epoch: 293  Training loss = 2.2349  Validation loss = 4.8226  \n",
      "\n",
      "Fold: 5  Epoch: 294  Training loss = 2.2348  Validation loss = 4.8223  \n",
      "\n",
      "Fold: 5  Epoch: 295  Training loss = 2.2346  Validation loss = 4.8221  \n",
      "\n",
      "Fold: 5  Epoch: 296  Training loss = 2.2345  Validation loss = 4.8219  \n",
      "\n",
      "Fold: 5  Epoch: 297  Training loss = 2.2343  Validation loss = 4.8216  \n",
      "\n",
      "Fold: 5  Epoch: 298  Training loss = 2.2341  Validation loss = 4.8213  \n",
      "\n",
      "Fold: 5  Epoch: 299  Training loss = 2.2340  Validation loss = 4.8211  \n",
      "\n",
      "Fold: 5  Epoch: 300  Training loss = 2.2338  Validation loss = 4.8208  \n",
      "\n",
      "Fold: 5  Epoch: 301  Training loss = 2.2336  Validation loss = 4.8205  \n",
      "\n",
      "Fold: 5  Epoch: 302  Training loss = 2.2335  Validation loss = 4.8203  \n",
      "\n",
      "Fold: 5  Epoch: 303  Training loss = 2.2332  Validation loss = 4.8199  \n",
      "\n",
      "Fold: 5  Epoch: 304  Training loss = 2.2330  Validation loss = 4.8196  \n",
      "\n",
      "Fold: 5  Epoch: 305  Training loss = 2.2329  Validation loss = 4.8193  \n",
      "\n",
      "Fold: 5  Epoch: 306  Training loss = 2.2326  Validation loss = 4.8189  \n",
      "\n",
      "Fold: 5  Epoch: 307  Training loss = 2.2325  Validation loss = 4.8188  \n",
      "\n",
      "Fold: 5  Epoch: 308  Training loss = 2.2323  Validation loss = 4.8184  \n",
      "\n",
      "Fold: 5  Epoch: 309  Training loss = 2.2320  Validation loss = 4.8180  \n",
      "\n",
      "Fold: 5  Epoch: 310  Training loss = 2.2319  Validation loss = 4.8177  \n",
      "\n",
      "Fold: 5  Epoch: 311  Training loss = 2.2317  Validation loss = 4.8173  \n",
      "\n",
      "Fold: 5  Epoch: 312  Training loss = 2.2315  Validation loss = 4.8170  \n",
      "\n",
      "Fold: 5  Epoch: 313  Training loss = 2.2312  Validation loss = 4.8166  \n",
      "\n",
      "Fold: 5  Epoch: 314  Training loss = 2.2311  Validation loss = 4.8164  \n",
      "\n",
      "Fold: 5  Epoch: 315  Training loss = 2.2309  Validation loss = 4.8161  \n",
      "\n",
      "Fold: 5  Epoch: 316  Training loss = 2.2307  Validation loss = 4.8157  \n",
      "\n",
      "Fold: 5  Epoch: 317  Training loss = 2.2305  Validation loss = 4.8153  \n",
      "\n",
      "Fold: 5  Epoch: 318  Training loss = 2.2302  Validation loss = 4.8149  \n",
      "\n",
      "Fold: 5  Epoch: 319  Training loss = 2.2301  Validation loss = 4.8146  \n",
      "\n",
      "Fold: 5  Epoch: 320  Training loss = 2.2299  Validation loss = 4.8143  \n",
      "\n",
      "Fold: 5  Epoch: 321  Training loss = 2.2297  Validation loss = 4.8140  \n",
      "\n",
      "Fold: 5  Epoch: 322  Training loss = 2.2295  Validation loss = 4.8137  \n",
      "\n",
      "Fold: 5  Epoch: 323  Training loss = 2.2293  Validation loss = 4.8134  \n",
      "\n",
      "Fold: 5  Epoch: 324  Training loss = 2.2291  Validation loss = 4.8130  \n",
      "\n",
      "Fold: 5  Epoch: 325  Training loss = 2.2289  Validation loss = 4.8128  \n",
      "\n",
      "Fold: 5  Epoch: 326  Training loss = 2.2287  Validation loss = 4.8125  \n",
      "\n",
      "Fold: 5  Epoch: 327  Training loss = 2.2285  Validation loss = 4.8122  \n",
      "\n",
      "Fold: 5  Epoch: 328  Training loss = 2.2283  Validation loss = 4.8119  \n",
      "\n",
      "Fold: 5  Epoch: 329  Training loss = 2.2282  Validation loss = 4.8117  \n",
      "\n",
      "Fold: 5  Epoch: 330  Training loss = 2.2280  Validation loss = 4.8114  \n",
      "\n",
      "Fold: 5  Epoch: 331  Training loss = 2.2279  Validation loss = 4.8112  \n",
      "\n",
      "Fold: 5  Epoch: 332  Training loss = 2.2277  Validation loss = 4.8109  \n",
      "\n",
      "Fold: 5  Epoch: 333  Training loss = 2.2276  Validation loss = 4.8107  \n",
      "\n",
      "Fold: 5  Epoch: 334  Training loss = 2.2274  Validation loss = 4.8105  \n",
      "\n",
      "Fold: 5  Epoch: 335  Training loss = 2.2272  Validation loss = 4.8102  \n",
      "\n",
      "Fold: 5  Epoch: 336  Training loss = 2.2270  Validation loss = 4.8098  \n",
      "\n",
      "Fold: 5  Epoch: 337  Training loss = 2.2268  Validation loss = 4.8095  \n",
      "\n",
      "Fold: 5  Epoch: 338  Training loss = 2.2266  Validation loss = 4.8092  \n",
      "\n",
      "Fold: 5  Epoch: 339  Training loss = 2.2265  Validation loss = 4.8090  \n",
      "\n",
      "Fold: 5  Epoch: 340  Training loss = 2.2263  Validation loss = 4.8087  \n",
      "\n",
      "Fold: 5  Epoch: 341  Training loss = 2.2261  Validation loss = 4.8084  \n",
      "\n",
      "Fold: 5  Epoch: 342  Training loss = 2.2259  Validation loss = 4.8081  \n",
      "\n",
      "Fold: 5  Epoch: 343  Training loss = 2.2258  Validation loss = 4.8078  \n",
      "\n",
      "Fold: 5  Epoch: 344  Training loss = 2.2256  Validation loss = 4.8074  \n",
      "\n",
      "Fold: 5  Epoch: 345  Training loss = 2.2253  Validation loss = 4.8071  \n",
      "\n",
      "Fold: 5  Epoch: 346  Training loss = 2.2252  Validation loss = 4.8069  \n",
      "\n",
      "Fold: 5  Epoch: 347  Training loss = 2.2250  Validation loss = 4.8066  \n",
      "\n",
      "Fold: 5  Epoch: 348  Training loss = 2.2249  Validation loss = 4.8064  \n",
      "\n",
      "Fold: 5  Epoch: 349  Training loss = 2.2247  Validation loss = 4.8061  \n",
      "\n",
      "Fold: 5  Epoch: 350  Training loss = 2.2246  Validation loss = 4.8059  \n",
      "\n",
      "Fold: 5  Epoch: 351  Training loss = 2.2244  Validation loss = 4.8056  \n",
      "\n",
      "Fold: 5  Epoch: 352  Training loss = 2.2242  Validation loss = 4.8054  \n",
      "\n",
      "Fold: 5  Epoch: 353  Training loss = 2.2240  Validation loss = 4.8051  \n",
      "\n",
      "Fold: 5  Epoch: 354  Training loss = 2.2238  Validation loss = 4.8047  \n",
      "\n",
      "Fold: 5  Epoch: 355  Training loss = 2.2236  Validation loss = 4.8044  \n",
      "\n",
      "Fold: 5  Epoch: 356  Training loss = 2.2234  Validation loss = 4.8040  \n",
      "\n",
      "Fold: 5  Epoch: 357  Training loss = 2.2232  Validation loss = 4.8038  \n",
      "\n",
      "Fold: 5  Epoch: 358  Training loss = 2.2231  Validation loss = 4.8035  \n",
      "\n",
      "Fold: 5  Epoch: 359  Training loss = 2.2229  Validation loss = 4.8033  \n",
      "\n",
      "Fold: 5  Epoch: 360  Training loss = 2.2228  Validation loss = 4.8031  \n",
      "\n",
      "Fold: 5  Epoch: 361  Training loss = 2.2226  Validation loss = 4.8027  \n",
      "\n",
      "Fold: 5  Epoch: 362  Training loss = 2.2224  Validation loss = 4.8024  \n",
      "\n",
      "Fold: 5  Epoch: 363  Training loss = 2.2222  Validation loss = 4.8022  \n",
      "\n",
      "Fold: 5  Epoch: 364  Training loss = 2.2221  Validation loss = 4.8020  \n",
      "\n",
      "Fold: 5  Epoch: 365  Training loss = 2.2219  Validation loss = 4.8017  \n",
      "\n",
      "Fold: 5  Epoch: 366  Training loss = 2.2217  Validation loss = 4.8013  \n",
      "\n",
      "Fold: 5  Epoch: 367  Training loss = 2.2215  Validation loss = 4.8011  \n",
      "\n",
      "Fold: 5  Epoch: 368  Training loss = 2.2214  Validation loss = 4.8008  \n",
      "\n",
      "Fold: 5  Epoch: 369  Training loss = 2.2212  Validation loss = 4.8007  \n",
      "\n",
      "Fold: 5  Epoch: 370  Training loss = 2.2210  Validation loss = 4.8004  \n",
      "\n",
      "Fold: 5  Epoch: 371  Training loss = 2.2209  Validation loss = 4.8001  \n",
      "\n",
      "Fold: 5  Epoch: 372  Training loss = 2.2207  Validation loss = 4.7998  \n",
      "\n",
      "Fold: 5  Epoch: 373  Training loss = 2.2205  Validation loss = 4.7994  \n",
      "\n",
      "Fold: 5  Epoch: 374  Training loss = 2.2203  Validation loss = 4.7992  \n",
      "\n",
      "Fold: 5  Epoch: 375  Training loss = 2.2201  Validation loss = 4.7987  \n",
      "\n",
      "Fold: 5  Epoch: 376  Training loss = 2.2199  Validation loss = 4.7984  \n",
      "\n",
      "Fold: 5  Epoch: 377  Training loss = 2.2196  Validation loss = 4.7980  \n",
      "\n",
      "Fold: 5  Epoch: 378  Training loss = 2.2195  Validation loss = 4.7977  \n",
      "\n",
      "Fold: 5  Epoch: 379  Training loss = 2.2193  Validation loss = 4.7974  \n",
      "\n",
      "Fold: 5  Epoch: 380  Training loss = 2.2191  Validation loss = 4.7972  \n",
      "\n",
      "Fold: 5  Epoch: 381  Training loss = 2.2190  Validation loss = 4.7970  \n",
      "\n",
      "Fold: 5  Epoch: 382  Training loss = 2.2188  Validation loss = 4.7967  \n",
      "\n",
      "Fold: 5  Epoch: 383  Training loss = 2.2185  Validation loss = 4.7962  \n",
      "\n",
      "Fold: 5  Epoch: 384  Training loss = 2.2183  Validation loss = 4.7959  \n",
      "\n",
      "Fold: 5  Epoch: 385  Training loss = 2.2182  Validation loss = 4.7957  \n",
      "\n",
      "Fold: 5  Epoch: 386  Training loss = 2.2181  Validation loss = 4.7954  \n",
      "\n",
      "Fold: 5  Epoch: 387  Training loss = 2.2179  Validation loss = 4.7952  \n",
      "\n",
      "Fold: 5  Epoch: 388  Training loss = 2.2177  Validation loss = 4.7949  \n",
      "\n",
      "Fold: 5  Epoch: 389  Training loss = 2.2175  Validation loss = 4.7944  \n",
      "\n",
      "Fold: 5  Epoch: 390  Training loss = 2.2173  Validation loss = 4.7942  \n",
      "\n",
      "Fold: 5  Epoch: 391  Training loss = 2.2171  Validation loss = 4.7939  \n",
      "\n",
      "Fold: 5  Epoch: 392  Training loss = 2.2169  Validation loss = 4.7936  \n",
      "\n",
      "Fold: 5  Epoch: 393  Training loss = 2.2167  Validation loss = 4.7933  \n",
      "\n",
      "Fold: 5  Epoch: 394  Training loss = 2.2165  Validation loss = 4.7930  \n",
      "\n",
      "Fold: 5  Epoch: 395  Training loss = 2.2163  Validation loss = 4.7926  \n",
      "\n",
      "Fold: 5  Epoch: 396  Training loss = 2.2161  Validation loss = 4.7923  \n",
      "\n",
      "Fold: 5  Epoch: 397  Training loss = 2.2159  Validation loss = 4.7919  \n",
      "\n",
      "Fold: 5  Epoch: 398  Training loss = 2.2157  Validation loss = 4.7916  \n",
      "\n",
      "Fold: 5  Epoch: 399  Training loss = 2.2156  Validation loss = 4.7914  \n",
      "\n",
      "Fold: 5  Epoch: 400  Training loss = 2.2154  Validation loss = 4.7911  \n",
      "\n",
      "Fold: 5  Epoch: 401  Training loss = 2.2152  Validation loss = 4.7908  \n",
      "\n",
      "Fold: 5  Epoch: 402  Training loss = 2.2150  Validation loss = 4.7905  \n",
      "\n",
      "Fold: 5  Epoch: 403  Training loss = 2.2148  Validation loss = 4.7902  \n",
      "\n",
      "Fold: 5  Epoch: 404  Training loss = 2.2146  Validation loss = 4.7899  \n",
      "\n",
      "Fold: 5  Epoch: 405  Training loss = 2.2144  Validation loss = 4.7896  \n",
      "\n",
      "Fold: 5  Epoch: 406  Training loss = 2.2142  Validation loss = 4.7892  \n",
      "\n",
      "Fold: 5  Epoch: 407  Training loss = 2.2141  Validation loss = 4.7890  \n",
      "\n",
      "Fold: 5  Epoch: 408  Training loss = 2.2139  Validation loss = 4.7888  \n",
      "\n",
      "Fold: 5  Epoch: 409  Training loss = 2.2137  Validation loss = 4.7884  \n",
      "\n",
      "Fold: 5  Epoch: 410  Training loss = 2.2135  Validation loss = 4.7881  \n",
      "\n",
      "Fold: 5  Epoch: 411  Training loss = 2.2134  Validation loss = 4.7879  \n",
      "\n",
      "Fold: 5  Epoch: 412  Training loss = 2.2133  Validation loss = 4.7877  \n",
      "\n",
      "Fold: 5  Epoch: 413  Training loss = 2.2131  Validation loss = 4.7875  \n",
      "\n",
      "Fold: 5  Epoch: 414  Training loss = 2.2130  Validation loss = 4.7872  \n",
      "\n",
      "Fold: 5  Epoch: 415  Training loss = 2.2128  Validation loss = 4.7870  \n",
      "\n",
      "Fold: 5  Epoch: 416  Training loss = 2.2126  Validation loss = 4.7866  \n",
      "\n",
      "Fold: 5  Epoch: 417  Training loss = 2.2124  Validation loss = 4.7863  \n",
      "\n",
      "Fold: 5  Epoch: 418  Training loss = 2.2122  Validation loss = 4.7860  \n",
      "\n",
      "Fold: 5  Epoch: 419  Training loss = 2.2121  Validation loss = 4.7857  \n",
      "\n",
      "Fold: 5  Epoch: 420  Training loss = 2.2119  Validation loss = 4.7854  \n",
      "\n",
      "Fold: 5  Epoch: 421  Training loss = 2.2117  Validation loss = 4.7850  \n",
      "\n",
      "Fold: 5  Epoch: 422  Training loss = 2.2115  Validation loss = 4.7847  \n",
      "\n",
      "Fold: 5  Epoch: 423  Training loss = 2.2113  Validation loss = 4.7845  \n",
      "\n",
      "Fold: 5  Epoch: 424  Training loss = 2.2111  Validation loss = 4.7842  \n",
      "\n",
      "Fold: 5  Epoch: 425  Training loss = 2.2110  Validation loss = 4.7840  \n",
      "\n",
      "Fold: 5  Epoch: 426  Training loss = 2.2109  Validation loss = 4.7838  \n",
      "\n",
      "Fold: 5  Epoch: 427  Training loss = 2.2107  Validation loss = 4.7836  \n",
      "\n",
      "Fold: 5  Epoch: 428  Training loss = 2.2106  Validation loss = 4.7833  \n",
      "\n",
      "Fold: 5  Epoch: 429  Training loss = 2.2104  Validation loss = 4.7830  \n",
      "\n",
      "Fold: 5  Epoch: 430  Training loss = 2.2102  Validation loss = 4.7827  \n",
      "\n",
      "Fold: 5  Epoch: 431  Training loss = 2.2100  Validation loss = 4.7824  \n",
      "\n",
      "Fold: 5  Epoch: 432  Training loss = 2.2099  Validation loss = 4.7821  \n",
      "\n",
      "Fold: 5  Epoch: 433  Training loss = 2.2097  Validation loss = 4.7819  \n",
      "\n",
      "Fold: 5  Epoch: 434  Training loss = 2.2095  Validation loss = 4.7816  \n",
      "\n",
      "Fold: 5  Epoch: 435  Training loss = 2.2093  Validation loss = 4.7813  \n",
      "\n",
      "Fold: 5  Epoch: 436  Training loss = 2.2091  Validation loss = 4.7809  \n",
      "\n",
      "Fold: 5  Epoch: 437  Training loss = 2.2090  Validation loss = 4.7806  \n",
      "\n",
      "Fold: 5  Epoch: 438  Training loss = 2.2088  Validation loss = 4.7804  \n",
      "\n",
      "Fold: 5  Epoch: 439  Training loss = 2.2086  Validation loss = 4.7800  \n",
      "\n",
      "Fold: 5  Epoch: 440  Training loss = 2.2084  Validation loss = 4.7798  \n",
      "\n",
      "Fold: 5  Epoch: 441  Training loss = 2.2083  Validation loss = 4.7795  \n",
      "\n",
      "Fold: 5  Epoch: 442  Training loss = 2.2081  Validation loss = 4.7792  \n",
      "\n",
      "Fold: 5  Epoch: 443  Training loss = 2.2078  Validation loss = 4.7788  \n",
      "\n",
      "Fold: 5  Epoch: 444  Training loss = 2.2077  Validation loss = 4.7786  \n",
      "\n",
      "Fold: 5  Epoch: 445  Training loss = 2.2075  Validation loss = 4.7783  \n",
      "\n",
      "Fold: 5  Epoch: 446  Training loss = 2.2074  Validation loss = 4.7780  \n",
      "\n",
      "Fold: 5  Epoch: 447  Training loss = 2.2072  Validation loss = 4.7778  \n",
      "\n",
      "Fold: 5  Epoch: 448  Training loss = 2.2070  Validation loss = 4.7775  \n",
      "\n",
      "Fold: 5  Epoch: 449  Training loss = 2.2068  Validation loss = 4.7772  \n",
      "\n",
      "Fold: 5  Epoch: 450  Training loss = 2.2066  Validation loss = 4.7768  \n",
      "\n",
      "Fold: 5  Epoch: 451  Training loss = 2.2064  Validation loss = 4.7766  \n",
      "\n",
      "Fold: 5  Epoch: 452  Training loss = 2.2062  Validation loss = 4.7762  \n",
      "\n",
      "Fold: 5  Epoch: 453  Training loss = 2.2060  Validation loss = 4.7759  \n",
      "\n",
      "Fold: 5  Epoch: 454  Training loss = 2.2058  Validation loss = 4.7756  \n",
      "\n",
      "Fold: 5  Epoch: 455  Training loss = 2.2057  Validation loss = 4.7753  \n",
      "\n",
      "Fold: 5  Epoch: 456  Training loss = 2.2054  Validation loss = 4.7750  \n",
      "\n",
      "Fold: 5  Epoch: 457  Training loss = 2.2053  Validation loss = 4.7747  \n",
      "\n",
      "Fold: 5  Epoch: 458  Training loss = 2.2051  Validation loss = 4.7744  \n",
      "\n",
      "Fold: 5  Epoch: 459  Training loss = 2.2049  Validation loss = 4.7741  \n",
      "\n",
      "Fold: 5  Epoch: 460  Training loss = 2.2047  Validation loss = 4.7739  \n",
      "\n",
      "Fold: 5  Epoch: 461  Training loss = 2.2046  Validation loss = 4.7736  \n",
      "\n",
      "Fold: 5  Epoch: 462  Training loss = 2.2044  Validation loss = 4.7734  \n",
      "\n",
      "Fold: 5  Epoch: 463  Training loss = 2.2042  Validation loss = 4.7730  \n",
      "\n",
      "Fold: 5  Epoch: 464  Training loss = 2.2040  Validation loss = 4.7727  \n",
      "\n",
      "Fold: 5  Epoch: 465  Training loss = 2.2039  Validation loss = 4.7724  \n",
      "\n",
      "Fold: 5  Epoch: 466  Training loss = 2.2037  Validation loss = 4.7722  \n",
      "\n",
      "Fold: 5  Epoch: 467  Training loss = 2.2035  Validation loss = 4.7720  \n",
      "\n",
      "Fold: 5  Epoch: 468  Training loss = 2.2034  Validation loss = 4.7717  \n",
      "\n",
      "Fold: 5  Epoch: 469  Training loss = 2.2032  Validation loss = 4.7714  \n",
      "\n",
      "Fold: 5  Epoch: 470  Training loss = 2.2030  Validation loss = 4.7712  \n",
      "\n",
      "Fold: 5  Epoch: 471  Training loss = 2.2029  Validation loss = 4.7709  \n",
      "\n",
      "Fold: 5  Epoch: 472  Training loss = 2.2027  Validation loss = 4.7707  \n",
      "\n",
      "Fold: 5  Epoch: 473  Training loss = 2.2026  Validation loss = 4.7704  \n",
      "\n",
      "Fold: 5  Epoch: 474  Training loss = 2.2024  Validation loss = 4.7701  \n",
      "\n",
      "Fold: 5  Epoch: 475  Training loss = 2.2022  Validation loss = 4.7699  \n",
      "\n",
      "Fold: 5  Epoch: 476  Training loss = 2.2020  Validation loss = 4.7696  \n",
      "\n",
      "Fold: 5  Epoch: 477  Training loss = 2.2019  Validation loss = 4.7693  \n",
      "\n",
      "Fold: 5  Epoch: 478  Training loss = 2.2017  Validation loss = 4.7690  \n",
      "\n",
      "Fold: 5  Epoch: 479  Training loss = 2.2015  Validation loss = 4.7687  \n",
      "\n",
      "Fold: 5  Epoch: 480  Training loss = 2.2013  Validation loss = 4.7684  \n",
      "\n",
      "Fold: 5  Epoch: 481  Training loss = 2.2011  Validation loss = 4.7681  \n",
      "\n",
      "Fold: 5  Epoch: 482  Training loss = 2.2009  Validation loss = 4.7678  \n",
      "\n",
      "Fold: 5  Epoch: 483  Training loss = 2.2007  Validation loss = 4.7674  \n",
      "\n",
      "Fold: 5  Epoch: 484  Training loss = 2.2005  Validation loss = 4.7671  \n",
      "\n",
      "Fold: 5  Epoch: 485  Training loss = 2.2003  Validation loss = 4.7668  \n",
      "\n",
      "Fold: 5  Epoch: 486  Training loss = 2.2002  Validation loss = 4.7666  \n",
      "\n",
      "Fold: 5  Epoch: 487  Training loss = 2.2001  Validation loss = 4.7664  \n",
      "\n",
      "Fold: 5  Epoch: 488  Training loss = 2.1999  Validation loss = 4.7660  \n",
      "\n",
      "Fold: 5  Epoch: 489  Training loss = 2.1997  Validation loss = 4.7658  \n",
      "\n",
      "Fold: 5  Epoch: 490  Training loss = 2.1996  Validation loss = 4.7655  \n",
      "\n",
      "Fold: 5  Epoch: 491  Training loss = 2.1994  Validation loss = 4.7652  \n",
      "\n",
      "Fold: 5  Epoch: 492  Training loss = 2.1992  Validation loss = 4.7649  \n",
      "\n",
      "Fold: 5  Epoch: 493  Training loss = 2.1990  Validation loss = 4.7645  \n",
      "\n",
      "Fold: 5  Epoch: 494  Training loss = 2.1988  Validation loss = 4.7642  \n",
      "\n",
      "Fold: 5  Epoch: 495  Training loss = 2.1986  Validation loss = 4.7638  \n",
      "\n",
      "Fold: 5  Epoch: 496  Training loss = 2.1984  Validation loss = 4.7635  \n",
      "\n",
      "Fold: 5  Epoch: 497  Training loss = 2.1982  Validation loss = 4.7633  \n",
      "\n",
      "Fold: 5  Epoch: 498  Training loss = 2.1980  Validation loss = 4.7630  \n",
      "\n",
      "Fold: 5  Epoch: 499  Training loss = 2.1978  Validation loss = 4.7627  \n",
      "\n",
      "Fold: 5  Epoch: 500  Training loss = 2.1977  Validation loss = 4.7625  \n",
      "\n",
      "Check model:  Fold: 5  Epoch: 500  Training loss = 2.1977  Validation loss = 4.7625  \n",
      "\n",
      "Fold: 6  Epoch: 1  Training loss = 2.4846  Validation loss = 2.7003  \n",
      "\n",
      "Fold: 6  Epoch: 2  Training loss = 2.4845  Validation loss = 2.7000  \n",
      "\n",
      "Fold: 6  Epoch: 3  Training loss = 2.4842  Validation loss = 2.6996  \n",
      "\n",
      "Fold: 6  Epoch: 4  Training loss = 2.4840  Validation loss = 2.6991  \n",
      "\n",
      "Fold: 6  Epoch: 5  Training loss = 2.4837  Validation loss = 2.6987  \n",
      "\n",
      "Fold: 6  Epoch: 6  Training loss = 2.4834  Validation loss = 2.6981  \n",
      "\n",
      "Fold: 6  Epoch: 7  Training loss = 2.4832  Validation loss = 2.6977  \n",
      "\n",
      "Fold: 6  Epoch: 8  Training loss = 2.4830  Validation loss = 2.6974  \n",
      "\n",
      "Fold: 6  Epoch: 9  Training loss = 2.4828  Validation loss = 2.6969  \n",
      "\n",
      "Fold: 6  Epoch: 10  Training loss = 2.4825  Validation loss = 2.6965  \n",
      "\n",
      "Fold: 6  Epoch: 11  Training loss = 2.4822  Validation loss = 2.6960  \n",
      "\n",
      "Fold: 6  Epoch: 12  Training loss = 2.4821  Validation loss = 2.6958  \n",
      "\n",
      "Fold: 6  Epoch: 13  Training loss = 2.4819  Validation loss = 2.6953  \n",
      "\n",
      "Fold: 6  Epoch: 14  Training loss = 2.4816  Validation loss = 2.6948  \n",
      "\n",
      "Fold: 6  Epoch: 15  Training loss = 2.4813  Validation loss = 2.6943  \n",
      "\n",
      "Fold: 6  Epoch: 16  Training loss = 2.4810  Validation loss = 2.6938  \n",
      "\n",
      "Fold: 6  Epoch: 17  Training loss = 2.4808  Validation loss = 2.6934  \n",
      "\n",
      "Fold: 6  Epoch: 18  Training loss = 2.4805  Validation loss = 2.6928  \n",
      "\n",
      "Fold: 6  Epoch: 19  Training loss = 2.4802  Validation loss = 2.6922  \n",
      "\n",
      "Fold: 6  Epoch: 20  Training loss = 2.4800  Validation loss = 2.6918  \n",
      "\n",
      "Fold: 6  Epoch: 21  Training loss = 2.4797  Validation loss = 2.6913  \n",
      "\n",
      "Fold: 6  Epoch: 22  Training loss = 2.4794  Validation loss = 2.6908  \n",
      "\n",
      "Fold: 6  Epoch: 23  Training loss = 2.4792  Validation loss = 2.6903  \n",
      "\n",
      "Fold: 6  Epoch: 24  Training loss = 2.4789  Validation loss = 2.6898  \n",
      "\n",
      "Fold: 6  Epoch: 25  Training loss = 2.4786  Validation loss = 2.6894  \n",
      "\n",
      "Fold: 6  Epoch: 26  Training loss = 2.4784  Validation loss = 2.6890  \n",
      "\n",
      "Fold: 6  Epoch: 27  Training loss = 2.4782  Validation loss = 2.6885  \n",
      "\n",
      "Fold: 6  Epoch: 28  Training loss = 2.4780  Validation loss = 2.6882  \n",
      "\n",
      "Fold: 6  Epoch: 29  Training loss = 2.4777  Validation loss = 2.6877  \n",
      "\n",
      "Fold: 6  Epoch: 30  Training loss = 2.4775  Validation loss = 2.6873  \n",
      "\n",
      "Fold: 6  Epoch: 31  Training loss = 2.4772  Validation loss = 2.6868  \n",
      "\n",
      "Fold: 6  Epoch: 32  Training loss = 2.4769  Validation loss = 2.6863  \n",
      "\n",
      "Fold: 6  Epoch: 33  Training loss = 2.4767  Validation loss = 2.6858  \n",
      "\n",
      "Fold: 6  Epoch: 34  Training loss = 2.4765  Validation loss = 2.6854  \n",
      "\n",
      "Fold: 6  Epoch: 35  Training loss = 2.4761  Validation loss = 2.6848  \n",
      "\n",
      "Fold: 6  Epoch: 36  Training loss = 2.4759  Validation loss = 2.6843  \n",
      "\n",
      "Fold: 6  Epoch: 37  Training loss = 2.4756  Validation loss = 2.6839  \n",
      "\n",
      "Fold: 6  Epoch: 38  Training loss = 2.4753  Validation loss = 2.6834  \n",
      "\n",
      "Fold: 6  Epoch: 39  Training loss = 2.4751  Validation loss = 2.6829  \n",
      "\n",
      "Fold: 6  Epoch: 40  Training loss = 2.4749  Validation loss = 2.6825  \n",
      "\n",
      "Fold: 6  Epoch: 41  Training loss = 2.4746  Validation loss = 2.6821  \n",
      "\n",
      "Fold: 6  Epoch: 42  Training loss = 2.4743  Validation loss = 2.6815  \n",
      "\n",
      "Fold: 6  Epoch: 43  Training loss = 2.4740  Validation loss = 2.6809  \n",
      "\n",
      "Fold: 6  Epoch: 44  Training loss = 2.4737  Validation loss = 2.6804  \n",
      "\n",
      "Fold: 6  Epoch: 45  Training loss = 2.4735  Validation loss = 2.6800  \n",
      "\n",
      "Fold: 6  Epoch: 46  Training loss = 2.4733  Validation loss = 2.6795  \n",
      "\n",
      "Fold: 6  Epoch: 47  Training loss = 2.4730  Validation loss = 2.6790  \n",
      "\n",
      "Fold: 6  Epoch: 48  Training loss = 2.4728  Validation loss = 2.6788  \n",
      "\n",
      "Fold: 6  Epoch: 49  Training loss = 2.4726  Validation loss = 2.6784  \n",
      "\n",
      "Fold: 6  Epoch: 50  Training loss = 2.4724  Validation loss = 2.6779  \n",
      "\n",
      "Fold: 6  Epoch: 51  Training loss = 2.4721  Validation loss = 2.6774  \n",
      "\n",
      "Fold: 6  Epoch: 52  Training loss = 2.4718  Validation loss = 2.6770  \n",
      "\n",
      "Fold: 6  Epoch: 53  Training loss = 2.4717  Validation loss = 2.6767  \n",
      "\n",
      "Fold: 6  Epoch: 54  Training loss = 2.4714  Validation loss = 2.6762  \n",
      "\n",
      "Fold: 6  Epoch: 55  Training loss = 2.4712  Validation loss = 2.6759  \n",
      "\n",
      "Fold: 6  Epoch: 56  Training loss = 2.4710  Validation loss = 2.6754  \n",
      "\n",
      "Fold: 6  Epoch: 57  Training loss = 2.4707  Validation loss = 2.6749  \n",
      "\n",
      "Fold: 6  Epoch: 58  Training loss = 2.4704  Validation loss = 2.6744  \n",
      "\n",
      "Fold: 6  Epoch: 59  Training loss = 2.4702  Validation loss = 2.6741  \n",
      "\n",
      "Fold: 6  Epoch: 60  Training loss = 2.4700  Validation loss = 2.6736  \n",
      "\n",
      "Fold: 6  Epoch: 61  Training loss = 2.4698  Validation loss = 2.6732  \n",
      "\n",
      "Fold: 6  Epoch: 62  Training loss = 2.4695  Validation loss = 2.6727  \n",
      "\n",
      "Fold: 6  Epoch: 63  Training loss = 2.4693  Validation loss = 2.6723  \n",
      "\n",
      "Fold: 6  Epoch: 64  Training loss = 2.4690  Validation loss = 2.6718  \n",
      "\n",
      "Fold: 6  Epoch: 65  Training loss = 2.4688  Validation loss = 2.6714  \n",
      "\n",
      "Fold: 6  Epoch: 66  Training loss = 2.4686  Validation loss = 2.6710  \n",
      "\n",
      "Fold: 6  Epoch: 67  Training loss = 2.4683  Validation loss = 2.6705  \n",
      "\n",
      "Fold: 6  Epoch: 68  Training loss = 2.4681  Validation loss = 2.6701  \n",
      "\n",
      "Fold: 6  Epoch: 69  Training loss = 2.4678  Validation loss = 2.6696  \n",
      "\n",
      "Fold: 6  Epoch: 70  Training loss = 2.4676  Validation loss = 2.6693  \n",
      "\n",
      "Fold: 6  Epoch: 71  Training loss = 2.4674  Validation loss = 2.6689  \n",
      "\n",
      "Fold: 6  Epoch: 72  Training loss = 2.4672  Validation loss = 2.6685  \n",
      "\n",
      "Fold: 6  Epoch: 73  Training loss = 2.4669  Validation loss = 2.6679  \n",
      "\n",
      "Fold: 6  Epoch: 74  Training loss = 2.4667  Validation loss = 2.6675  \n",
      "\n",
      "Fold: 6  Epoch: 75  Training loss = 2.4665  Validation loss = 2.6672  \n",
      "\n",
      "Fold: 6  Epoch: 76  Training loss = 2.4663  Validation loss = 2.6667  \n",
      "\n",
      "Fold: 6  Epoch: 77  Training loss = 2.4660  Validation loss = 2.6663  \n",
      "\n",
      "Fold: 6  Epoch: 78  Training loss = 2.4658  Validation loss = 2.6660  \n",
      "\n",
      "Fold: 6  Epoch: 79  Training loss = 2.4656  Validation loss = 2.6656  \n",
      "\n",
      "Fold: 6  Epoch: 80  Training loss = 2.4654  Validation loss = 2.6652  \n",
      "\n",
      "Fold: 6  Epoch: 81  Training loss = 2.4652  Validation loss = 2.6647  \n",
      "\n",
      "Fold: 6  Epoch: 82  Training loss = 2.4649  Validation loss = 2.6643  \n",
      "\n",
      "Fold: 6  Epoch: 83  Training loss = 2.4647  Validation loss = 2.6639  \n",
      "\n",
      "Fold: 6  Epoch: 84  Training loss = 2.4645  Validation loss = 2.6635  \n",
      "\n",
      "Fold: 6  Epoch: 85  Training loss = 2.4642  Validation loss = 2.6631  \n",
      "\n",
      "Fold: 6  Epoch: 86  Training loss = 2.4640  Validation loss = 2.6627  \n",
      "\n",
      "Fold: 6  Epoch: 87  Training loss = 2.4637  Validation loss = 2.6621  \n",
      "\n",
      "Fold: 6  Epoch: 88  Training loss = 2.4635  Validation loss = 2.6618  \n",
      "\n",
      "Fold: 6  Epoch: 89  Training loss = 2.4632  Validation loss = 2.6612  \n",
      "\n",
      "Fold: 6  Epoch: 90  Training loss = 2.4630  Validation loss = 2.6608  \n",
      "\n",
      "Fold: 6  Epoch: 91  Training loss = 2.4628  Validation loss = 2.6603  \n",
      "\n",
      "Fold: 6  Epoch: 92  Training loss = 2.4626  Validation loss = 2.6600  \n",
      "\n",
      "Fold: 6  Epoch: 93  Training loss = 2.4623  Validation loss = 2.6595  \n",
      "\n",
      "Fold: 6  Epoch: 94  Training loss = 2.4621  Validation loss = 2.6592  \n",
      "\n",
      "Fold: 6  Epoch: 95  Training loss = 2.4618  Validation loss = 2.6586  \n",
      "\n",
      "Fold: 6  Epoch: 96  Training loss = 2.4616  Validation loss = 2.6582  \n",
      "\n",
      "Fold: 6  Epoch: 97  Training loss = 2.4614  Validation loss = 2.6578  \n",
      "\n",
      "Fold: 6  Epoch: 98  Training loss = 2.4612  Validation loss = 2.6574  \n",
      "\n",
      "Fold: 6  Epoch: 99  Training loss = 2.4608  Validation loss = 2.6568  \n",
      "\n",
      "Fold: 6  Epoch: 100  Training loss = 2.4606  Validation loss = 2.6564  \n",
      "\n",
      "Fold: 6  Epoch: 101  Training loss = 2.4604  Validation loss = 2.6561  \n",
      "\n",
      "Fold: 6  Epoch: 102  Training loss = 2.4602  Validation loss = 2.6556  \n",
      "\n",
      "Fold: 6  Epoch: 103  Training loss = 2.4599  Validation loss = 2.6550  \n",
      "\n",
      "Fold: 6  Epoch: 104  Training loss = 2.4597  Validation loss = 2.6546  \n",
      "\n",
      "Fold: 6  Epoch: 105  Training loss = 2.4595  Validation loss = 2.6542  \n",
      "\n",
      "Fold: 6  Epoch: 106  Training loss = 2.4592  Validation loss = 2.6538  \n",
      "\n",
      "Fold: 6  Epoch: 107  Training loss = 2.4590  Validation loss = 2.6533  \n",
      "\n",
      "Fold: 6  Epoch: 108  Training loss = 2.4587  Validation loss = 2.6528  \n",
      "\n",
      "Fold: 6  Epoch: 109  Training loss = 2.4585  Validation loss = 2.6524  \n",
      "\n",
      "Fold: 6  Epoch: 110  Training loss = 2.4582  Validation loss = 2.6519  \n",
      "\n",
      "Fold: 6  Epoch: 111  Training loss = 2.4580  Validation loss = 2.6515  \n",
      "\n",
      "Fold: 6  Epoch: 112  Training loss = 2.4578  Validation loss = 2.6511  \n",
      "\n",
      "Fold: 6  Epoch: 113  Training loss = 2.4575  Validation loss = 2.6506  \n",
      "\n",
      "Fold: 6  Epoch: 114  Training loss = 2.4574  Validation loss = 2.6503  \n",
      "\n",
      "Fold: 6  Epoch: 115  Training loss = 2.4571  Validation loss = 2.6498  \n",
      "\n",
      "Fold: 6  Epoch: 116  Training loss = 2.4569  Validation loss = 2.6494  \n",
      "\n",
      "Fold: 6  Epoch: 117  Training loss = 2.4567  Validation loss = 2.6491  \n",
      "\n",
      "Fold: 6  Epoch: 118  Training loss = 2.4564  Validation loss = 2.6485  \n",
      "\n",
      "Fold: 6  Epoch: 119  Training loss = 2.4562  Validation loss = 2.6481  \n",
      "\n",
      "Fold: 6  Epoch: 120  Training loss = 2.4559  Validation loss = 2.6477  \n",
      "\n",
      "Fold: 6  Epoch: 121  Training loss = 2.4557  Validation loss = 2.6473  \n",
      "\n",
      "Fold: 6  Epoch: 122  Training loss = 2.4555  Validation loss = 2.6469  \n",
      "\n",
      "Fold: 6  Epoch: 123  Training loss = 2.4552  Validation loss = 2.6464  \n",
      "\n",
      "Fold: 6  Epoch: 124  Training loss = 2.4550  Validation loss = 2.6460  \n",
      "\n",
      "Fold: 6  Epoch: 125  Training loss = 2.4548  Validation loss = 2.6456  \n",
      "\n",
      "Fold: 6  Epoch: 126  Training loss = 2.4546  Validation loss = 2.6453  \n",
      "\n",
      "Fold: 6  Epoch: 127  Training loss = 2.4544  Validation loss = 2.6450  \n",
      "\n",
      "Fold: 6  Epoch: 128  Training loss = 2.4542  Validation loss = 2.6446  \n",
      "\n",
      "Fold: 6  Epoch: 129  Training loss = 2.4539  Validation loss = 2.6441  \n",
      "\n",
      "Fold: 6  Epoch: 130  Training loss = 2.4537  Validation loss = 2.6437  \n",
      "\n",
      "Fold: 6  Epoch: 131  Training loss = 2.4534  Validation loss = 2.6431  \n",
      "\n",
      "Fold: 6  Epoch: 132  Training loss = 2.4532  Validation loss = 2.6427  \n",
      "\n",
      "Fold: 6  Epoch: 133  Training loss = 2.4529  Validation loss = 2.6421  \n",
      "\n",
      "Fold: 6  Epoch: 134  Training loss = 2.4527  Validation loss = 2.6417  \n",
      "\n",
      "Fold: 6  Epoch: 135  Training loss = 2.4524  Validation loss = 2.6413  \n",
      "\n",
      "Fold: 6  Epoch: 136  Training loss = 2.4522  Validation loss = 2.6409  \n",
      "\n",
      "Fold: 6  Epoch: 137  Training loss = 2.4520  Validation loss = 2.6405  \n",
      "\n",
      "Fold: 6  Epoch: 138  Training loss = 2.4518  Validation loss = 2.6402  \n",
      "\n",
      "Fold: 6  Epoch: 139  Training loss = 2.4516  Validation loss = 2.6398  \n",
      "\n",
      "Fold: 6  Epoch: 140  Training loss = 2.4514  Validation loss = 2.6394  \n",
      "\n",
      "Fold: 6  Epoch: 141  Training loss = 2.4511  Validation loss = 2.6389  \n",
      "\n",
      "Fold: 6  Epoch: 142  Training loss = 2.4509  Validation loss = 2.6385  \n",
      "\n",
      "Fold: 6  Epoch: 143  Training loss = 2.4506  Validation loss = 2.6380  \n",
      "\n",
      "Fold: 6  Epoch: 144  Training loss = 2.4504  Validation loss = 2.6376  \n",
      "\n",
      "Fold: 6  Epoch: 145  Training loss = 2.4502  Validation loss = 2.6372  \n",
      "\n",
      "Fold: 6  Epoch: 146  Training loss = 2.4500  Validation loss = 2.6367  \n",
      "\n",
      "Fold: 6  Epoch: 147  Training loss = 2.4498  Validation loss = 2.6363  \n",
      "\n",
      "Fold: 6  Epoch: 148  Training loss = 2.4496  Validation loss = 2.6359  \n",
      "\n",
      "Fold: 6  Epoch: 149  Training loss = 2.4493  Validation loss = 2.6355  \n",
      "\n",
      "Fold: 6  Epoch: 150  Training loss = 2.4490  Validation loss = 2.6349  \n",
      "\n",
      "Fold: 6  Epoch: 151  Training loss = 2.4488  Validation loss = 2.6344  \n",
      "\n",
      "Fold: 6  Epoch: 152  Training loss = 2.4485  Validation loss = 2.6340  \n",
      "\n",
      "Fold: 6  Epoch: 153  Training loss = 2.4483  Validation loss = 2.6335  \n",
      "\n",
      "Fold: 6  Epoch: 154  Training loss = 2.4481  Validation loss = 2.6331  \n",
      "\n",
      "Fold: 6  Epoch: 155  Training loss = 2.4479  Validation loss = 2.6328  \n",
      "\n",
      "Fold: 6  Epoch: 156  Training loss = 2.4476  Validation loss = 2.6321  \n",
      "\n",
      "Fold: 6  Epoch: 157  Training loss = 2.4474  Validation loss = 2.6318  \n",
      "\n",
      "Fold: 6  Epoch: 158  Training loss = 2.4471  Validation loss = 2.6314  \n",
      "\n",
      "Fold: 6  Epoch: 159  Training loss = 2.4468  Validation loss = 2.6307  \n",
      "\n",
      "Fold: 6  Epoch: 160  Training loss = 2.4465  Validation loss = 2.6302  \n",
      "\n",
      "Fold: 6  Epoch: 161  Training loss = 2.4463  Validation loss = 2.6298  \n",
      "\n",
      "Fold: 6  Epoch: 162  Training loss = 2.4462  Validation loss = 2.6295  \n",
      "\n",
      "Fold: 6  Epoch: 163  Training loss = 2.4459  Validation loss = 2.6291  \n",
      "\n",
      "Fold: 6  Epoch: 164  Training loss = 2.4457  Validation loss = 2.6286  \n",
      "\n",
      "Fold: 6  Epoch: 165  Training loss = 2.4454  Validation loss = 2.6282  \n",
      "\n",
      "Fold: 6  Epoch: 166  Training loss = 2.4452  Validation loss = 2.6277  \n",
      "\n",
      "Fold: 6  Epoch: 167  Training loss = 2.4450  Validation loss = 2.6273  \n",
      "\n",
      "Fold: 6  Epoch: 168  Training loss = 2.4448  Validation loss = 2.6269  \n",
      "\n",
      "Fold: 6  Epoch: 169  Training loss = 2.4445  Validation loss = 2.6265  \n",
      "\n",
      "Fold: 6  Epoch: 170  Training loss = 2.4444  Validation loss = 2.6262  \n",
      "\n",
      "Fold: 6  Epoch: 171  Training loss = 2.4441  Validation loss = 2.6257  \n",
      "\n",
      "Fold: 6  Epoch: 172  Training loss = 2.4439  Validation loss = 2.6252  \n",
      "\n",
      "Fold: 6  Epoch: 173  Training loss = 2.4436  Validation loss = 2.6246  \n",
      "\n",
      "Fold: 6  Epoch: 174  Training loss = 2.4434  Validation loss = 2.6242  \n",
      "\n",
      "Fold: 6  Epoch: 175  Training loss = 2.4431  Validation loss = 2.6237  \n",
      "\n",
      "Fold: 6  Epoch: 176  Training loss = 2.4429  Validation loss = 2.6234  \n",
      "\n",
      "Fold: 6  Epoch: 177  Training loss = 2.4426  Validation loss = 2.6228  \n",
      "\n",
      "Fold: 6  Epoch: 178  Training loss = 2.4424  Validation loss = 2.6224  \n",
      "\n",
      "Fold: 6  Epoch: 179  Training loss = 2.4422  Validation loss = 2.6220  \n",
      "\n",
      "Fold: 6  Epoch: 180  Training loss = 2.4419  Validation loss = 2.6215  \n",
      "\n",
      "Fold: 6  Epoch: 181  Training loss = 2.4417  Validation loss = 2.6211  \n",
      "\n",
      "Fold: 6  Epoch: 182  Training loss = 2.4414  Validation loss = 2.6206  \n",
      "\n",
      "Fold: 6  Epoch: 183  Training loss = 2.4412  Validation loss = 2.6202  \n",
      "\n",
      "Fold: 6  Epoch: 184  Training loss = 2.4410  Validation loss = 2.6198  \n",
      "\n",
      "Fold: 6  Epoch: 185  Training loss = 2.4407  Validation loss = 2.6193  \n",
      "\n",
      "Fold: 6  Epoch: 186  Training loss = 2.4405  Validation loss = 2.6189  \n",
      "\n",
      "Fold: 6  Epoch: 187  Training loss = 2.4403  Validation loss = 2.6185  \n",
      "\n",
      "Fold: 6  Epoch: 188  Training loss = 2.4401  Validation loss = 2.6181  \n",
      "\n",
      "Fold: 6  Epoch: 189  Training loss = 2.4398  Validation loss = 2.6177  \n",
      "\n",
      "Fold: 6  Epoch: 190  Training loss = 2.4396  Validation loss = 2.6172  \n",
      "\n",
      "Fold: 6  Epoch: 191  Training loss = 2.4394  Validation loss = 2.6169  \n",
      "\n",
      "Fold: 6  Epoch: 192  Training loss = 2.4392  Validation loss = 2.6164  \n",
      "\n",
      "Fold: 6  Epoch: 193  Training loss = 2.4390  Validation loss = 2.6160  \n",
      "\n",
      "Fold: 6  Epoch: 194  Training loss = 2.4387  Validation loss = 2.6155  \n",
      "\n",
      "Fold: 6  Epoch: 195  Training loss = 2.4384  Validation loss = 2.6150  \n",
      "\n",
      "Fold: 6  Epoch: 196  Training loss = 2.4382  Validation loss = 2.6146  \n",
      "\n",
      "Fold: 6  Epoch: 197  Training loss = 2.4380  Validation loss = 2.6141  \n",
      "\n",
      "Fold: 6  Epoch: 198  Training loss = 2.4378  Validation loss = 2.6137  \n",
      "\n",
      "Fold: 6  Epoch: 199  Training loss = 2.4375  Validation loss = 2.6133  \n",
      "\n",
      "Fold: 6  Epoch: 200  Training loss = 2.4373  Validation loss = 2.6129  \n",
      "\n",
      "Fold: 6  Epoch: 201  Training loss = 2.4371  Validation loss = 2.6125  \n",
      "\n",
      "Fold: 6  Epoch: 202  Training loss = 2.4368  Validation loss = 2.6120  \n",
      "\n",
      "Fold: 6  Epoch: 203  Training loss = 2.4366  Validation loss = 2.6116  \n",
      "\n",
      "Fold: 6  Epoch: 204  Training loss = 2.4364  Validation loss = 2.6112  \n",
      "\n",
      "Fold: 6  Epoch: 205  Training loss = 2.4362  Validation loss = 2.6109  \n",
      "\n",
      "Fold: 6  Epoch: 206  Training loss = 2.4360  Validation loss = 2.6104  \n",
      "\n",
      "Fold: 6  Epoch: 207  Training loss = 2.4357  Validation loss = 2.6100  \n",
      "\n",
      "Fold: 6  Epoch: 208  Training loss = 2.4355  Validation loss = 2.6096  \n",
      "\n",
      "Fold: 6  Epoch: 209  Training loss = 2.4354  Validation loss = 2.6093  \n",
      "\n",
      "Fold: 6  Epoch: 210  Training loss = 2.4352  Validation loss = 2.6089  \n",
      "\n",
      "Fold: 6  Epoch: 211  Training loss = 2.4349  Validation loss = 2.6085  \n",
      "\n",
      "Fold: 6  Epoch: 212  Training loss = 2.4347  Validation loss = 2.6081  \n",
      "\n",
      "Fold: 6  Epoch: 213  Training loss = 2.4345  Validation loss = 2.6077  \n",
      "\n",
      "Fold: 6  Epoch: 214  Training loss = 2.4343  Validation loss = 2.6073  \n",
      "\n",
      "Fold: 6  Epoch: 215  Training loss = 2.4341  Validation loss = 2.6069  \n",
      "\n",
      "Fold: 6  Epoch: 216  Training loss = 2.4339  Validation loss = 2.6065  \n",
      "\n",
      "Fold: 6  Epoch: 217  Training loss = 2.4336  Validation loss = 2.6061  \n",
      "\n",
      "Fold: 6  Epoch: 218  Training loss = 2.4334  Validation loss = 2.6057  \n",
      "\n",
      "Fold: 6  Epoch: 219  Training loss = 2.4333  Validation loss = 2.6054  \n",
      "\n",
      "Fold: 6  Epoch: 220  Training loss = 2.4330  Validation loss = 2.6050  \n",
      "\n",
      "Fold: 6  Epoch: 221  Training loss = 2.4328  Validation loss = 2.6044  \n",
      "\n",
      "Fold: 6  Epoch: 222  Training loss = 2.4326  Validation loss = 2.6041  \n",
      "\n",
      "Fold: 6  Epoch: 223  Training loss = 2.4323  Validation loss = 2.6036  \n",
      "\n",
      "Fold: 6  Epoch: 224  Training loss = 2.4321  Validation loss = 2.6032  \n",
      "\n",
      "Fold: 6  Epoch: 225  Training loss = 2.4319  Validation loss = 2.6028  \n",
      "\n",
      "Fold: 6  Epoch: 226  Training loss = 2.4317  Validation loss = 2.6023  \n",
      "\n",
      "Fold: 6  Epoch: 227  Training loss = 2.4314  Validation loss = 2.6019  \n",
      "\n",
      "Fold: 6  Epoch: 228  Training loss = 2.4312  Validation loss = 2.6014  \n",
      "\n",
      "Fold: 6  Epoch: 229  Training loss = 2.4310  Validation loss = 2.6010  \n",
      "\n",
      "Fold: 6  Epoch: 230  Training loss = 2.4308  Validation loss = 2.6006  \n",
      "\n",
      "Fold: 6  Epoch: 231  Training loss = 2.4306  Validation loss = 2.6002  \n",
      "\n",
      "Fold: 6  Epoch: 232  Training loss = 2.4304  Validation loss = 2.5999  \n",
      "\n",
      "Fold: 6  Epoch: 233  Training loss = 2.4302  Validation loss = 2.5995  \n",
      "\n",
      "Fold: 6  Epoch: 234  Training loss = 2.4299  Validation loss = 2.5990  \n",
      "\n",
      "Fold: 6  Epoch: 235  Training loss = 2.4297  Validation loss = 2.5986  \n",
      "\n",
      "Fold: 6  Epoch: 236  Training loss = 2.4295  Validation loss = 2.5983  \n",
      "\n",
      "Fold: 6  Epoch: 237  Training loss = 2.4294  Validation loss = 2.5980  \n",
      "\n",
      "Fold: 6  Epoch: 238  Training loss = 2.4292  Validation loss = 2.5976  \n",
      "\n",
      "Fold: 6  Epoch: 239  Training loss = 2.4289  Validation loss = 2.5971  \n",
      "\n",
      "Fold: 6  Epoch: 240  Training loss = 2.4286  Validation loss = 2.5966  \n",
      "\n",
      "Fold: 6  Epoch: 241  Training loss = 2.4284  Validation loss = 2.5962  \n",
      "\n",
      "Fold: 6  Epoch: 242  Training loss = 2.4282  Validation loss = 2.5958  \n",
      "\n",
      "Fold: 6  Epoch: 243  Training loss = 2.4280  Validation loss = 2.5955  \n",
      "\n",
      "Fold: 6  Epoch: 244  Training loss = 2.4278  Validation loss = 2.5950  \n",
      "\n",
      "Fold: 6  Epoch: 245  Training loss = 2.4276  Validation loss = 2.5946  \n",
      "\n",
      "Fold: 6  Epoch: 246  Training loss = 2.4273  Validation loss = 2.5942  \n",
      "\n",
      "Fold: 6  Epoch: 247  Training loss = 2.4272  Validation loss = 2.5939  \n",
      "\n",
      "Fold: 6  Epoch: 248  Training loss = 2.4270  Validation loss = 2.5935  \n",
      "\n",
      "Fold: 6  Epoch: 249  Training loss = 2.4267  Validation loss = 2.5930  \n",
      "\n",
      "Fold: 6  Epoch: 250  Training loss = 2.4265  Validation loss = 2.5925  \n",
      "\n",
      "Fold: 6  Epoch: 251  Training loss = 2.4262  Validation loss = 2.5920  \n",
      "\n",
      "Fold: 6  Epoch: 252  Training loss = 2.4260  Validation loss = 2.5916  \n",
      "\n",
      "Fold: 6  Epoch: 253  Training loss = 2.4257  Validation loss = 2.5911  \n",
      "\n",
      "Fold: 6  Epoch: 254  Training loss = 2.4255  Validation loss = 2.5907  \n",
      "\n",
      "Fold: 6  Epoch: 255  Training loss = 2.4253  Validation loss = 2.5903  \n",
      "\n",
      "Fold: 6  Epoch: 256  Training loss = 2.4251  Validation loss = 2.5900  \n",
      "\n",
      "Fold: 6  Epoch: 257  Training loss = 2.4249  Validation loss = 2.5897  \n",
      "\n",
      "Fold: 6  Epoch: 258  Training loss = 2.4247  Validation loss = 2.5891  \n",
      "\n",
      "Fold: 6  Epoch: 259  Training loss = 2.4245  Validation loss = 2.5888  \n",
      "\n",
      "Fold: 6  Epoch: 260  Training loss = 2.4242  Validation loss = 2.5883  \n",
      "\n",
      "Fold: 6  Epoch: 261  Training loss = 2.4240  Validation loss = 2.5879  \n",
      "\n",
      "Fold: 6  Epoch: 262  Training loss = 2.4238  Validation loss = 2.5876  \n",
      "\n",
      "Fold: 6  Epoch: 263  Training loss = 2.4237  Validation loss = 2.5873  \n",
      "\n",
      "Fold: 6  Epoch: 264  Training loss = 2.4234  Validation loss = 2.5868  \n",
      "\n",
      "Fold: 6  Epoch: 265  Training loss = 2.4232  Validation loss = 2.5865  \n",
      "\n",
      "Fold: 6  Epoch: 266  Training loss = 2.4230  Validation loss = 2.5860  \n",
      "\n",
      "Fold: 6  Epoch: 267  Training loss = 2.4227  Validation loss = 2.5855  \n",
      "\n",
      "Fold: 6  Epoch: 268  Training loss = 2.4226  Validation loss = 2.5852  \n",
      "\n",
      "Fold: 6  Epoch: 269  Training loss = 2.4224  Validation loss = 2.5848  \n",
      "\n",
      "Fold: 6  Epoch: 270  Training loss = 2.4221  Validation loss = 2.5844  \n",
      "\n",
      "Fold: 6  Epoch: 271  Training loss = 2.4219  Validation loss = 2.5839  \n",
      "\n",
      "Fold: 6  Epoch: 272  Training loss = 2.4217  Validation loss = 2.5835  \n",
      "\n",
      "Fold: 6  Epoch: 273  Training loss = 2.4214  Validation loss = 2.5829  \n",
      "\n",
      "Fold: 6  Epoch: 274  Training loss = 2.4212  Validation loss = 2.5825  \n",
      "\n",
      "Fold: 6  Epoch: 275  Training loss = 2.4209  Validation loss = 2.5821  \n",
      "\n",
      "Fold: 6  Epoch: 276  Training loss = 2.4207  Validation loss = 2.5817  \n",
      "\n",
      "Fold: 6  Epoch: 277  Training loss = 2.4205  Validation loss = 2.5813  \n",
      "\n",
      "Fold: 6  Epoch: 278  Training loss = 2.4203  Validation loss = 2.5810  \n",
      "\n",
      "Fold: 6  Epoch: 279  Training loss = 2.4202  Validation loss = 2.5807  \n",
      "\n",
      "Fold: 6  Epoch: 280  Training loss = 2.4199  Validation loss = 2.5803  \n",
      "\n",
      "Fold: 6  Epoch: 281  Training loss = 2.4197  Validation loss = 2.5799  \n",
      "\n",
      "Fold: 6  Epoch: 282  Training loss = 2.4195  Validation loss = 2.5794  \n",
      "\n",
      "Fold: 6  Epoch: 283  Training loss = 2.4192  Validation loss = 2.5788  \n",
      "\n",
      "Fold: 6  Epoch: 284  Training loss = 2.4190  Validation loss = 2.5785  \n",
      "\n",
      "Fold: 6  Epoch: 285  Training loss = 2.4187  Validation loss = 2.5779  \n",
      "\n",
      "Fold: 6  Epoch: 286  Training loss = 2.4186  Validation loss = 2.5777  \n",
      "\n",
      "Fold: 6  Epoch: 287  Training loss = 2.4184  Validation loss = 2.5773  \n",
      "\n",
      "Fold: 6  Epoch: 288  Training loss = 2.4182  Validation loss = 2.5769  \n",
      "\n",
      "Fold: 6  Epoch: 289  Training loss = 2.4179  Validation loss = 2.5764  \n",
      "\n",
      "Fold: 6  Epoch: 290  Training loss = 2.4177  Validation loss = 2.5761  \n",
      "\n",
      "Fold: 6  Epoch: 291  Training loss = 2.4175  Validation loss = 2.5755  \n",
      "\n",
      "Fold: 6  Epoch: 292  Training loss = 2.4173  Validation loss = 2.5752  \n",
      "\n",
      "Fold: 6  Epoch: 293  Training loss = 2.4170  Validation loss = 2.5748  \n",
      "\n",
      "Fold: 6  Epoch: 294  Training loss = 2.4168  Validation loss = 2.5743  \n",
      "\n",
      "Fold: 6  Epoch: 295  Training loss = 2.4166  Validation loss = 2.5739  \n",
      "\n",
      "Fold: 6  Epoch: 296  Training loss = 2.4164  Validation loss = 2.5735  \n",
      "\n",
      "Fold: 6  Epoch: 297  Training loss = 2.4162  Validation loss = 2.5732  \n",
      "\n",
      "Fold: 6  Epoch: 298  Training loss = 2.4160  Validation loss = 2.5729  \n",
      "\n",
      "Fold: 6  Epoch: 299  Training loss = 2.4158  Validation loss = 2.5724  \n",
      "\n",
      "Fold: 6  Epoch: 300  Training loss = 2.4156  Validation loss = 2.5720  \n",
      "\n",
      "Fold: 6  Epoch: 301  Training loss = 2.4154  Validation loss = 2.5717  \n",
      "\n",
      "Fold: 6  Epoch: 302  Training loss = 2.4152  Validation loss = 2.5712  \n",
      "\n",
      "Fold: 6  Epoch: 303  Training loss = 2.4150  Validation loss = 2.5708  \n",
      "\n",
      "Fold: 6  Epoch: 304  Training loss = 2.4147  Validation loss = 2.5704  \n",
      "\n",
      "Fold: 6  Epoch: 305  Training loss = 2.4145  Validation loss = 2.5699  \n",
      "\n",
      "Fold: 6  Epoch: 306  Training loss = 2.4143  Validation loss = 2.5695  \n",
      "\n",
      "Fold: 6  Epoch: 307  Training loss = 2.4141  Validation loss = 2.5692  \n",
      "\n",
      "Fold: 6  Epoch: 308  Training loss = 2.4139  Validation loss = 2.5688  \n",
      "\n",
      "Fold: 6  Epoch: 309  Training loss = 2.4136  Validation loss = 2.5683  \n",
      "\n",
      "Fold: 6  Epoch: 310  Training loss = 2.4134  Validation loss = 2.5679  \n",
      "\n",
      "Fold: 6  Epoch: 311  Training loss = 2.4133  Validation loss = 2.5676  \n",
      "\n",
      "Fold: 6  Epoch: 312  Training loss = 2.4130  Validation loss = 2.5672  \n",
      "\n",
      "Fold: 6  Epoch: 313  Training loss = 2.4128  Validation loss = 2.5668  \n",
      "\n",
      "Fold: 6  Epoch: 314  Training loss = 2.4126  Validation loss = 2.5664  \n",
      "\n",
      "Fold: 6  Epoch: 315  Training loss = 2.4123  Validation loss = 2.5659  \n",
      "\n",
      "Fold: 6  Epoch: 316  Training loss = 2.4121  Validation loss = 2.5655  \n",
      "\n",
      "Fold: 6  Epoch: 317  Training loss = 2.4120  Validation loss = 2.5652  \n",
      "\n",
      "Fold: 6  Epoch: 318  Training loss = 2.4117  Validation loss = 2.5648  \n",
      "\n",
      "Fold: 6  Epoch: 319  Training loss = 2.4115  Validation loss = 2.5644  \n",
      "\n",
      "Fold: 6  Epoch: 320  Training loss = 2.4113  Validation loss = 2.5640  \n",
      "\n",
      "Fold: 6  Epoch: 321  Training loss = 2.4111  Validation loss = 2.5636  \n",
      "\n",
      "Fold: 6  Epoch: 322  Training loss = 2.4110  Validation loss = 2.5633  \n",
      "\n",
      "Fold: 6  Epoch: 323  Training loss = 2.4107  Validation loss = 2.5629  \n",
      "\n",
      "Fold: 6  Epoch: 324  Training loss = 2.4105  Validation loss = 2.5625  \n",
      "\n",
      "Fold: 6  Epoch: 325  Training loss = 2.4103  Validation loss = 2.5620  \n",
      "\n",
      "Fold: 6  Epoch: 326  Training loss = 2.4102  Validation loss = 2.5619  \n",
      "\n",
      "Fold: 6  Epoch: 327  Training loss = 2.4100  Validation loss = 2.5615  \n",
      "\n",
      "Fold: 6  Epoch: 328  Training loss = 2.4098  Validation loss = 2.5610  \n",
      "\n",
      "Fold: 6  Epoch: 329  Training loss = 2.4095  Validation loss = 2.5606  \n",
      "\n",
      "Fold: 6  Epoch: 330  Training loss = 2.4093  Validation loss = 2.5602  \n",
      "\n",
      "Fold: 6  Epoch: 331  Training loss = 2.4091  Validation loss = 2.5598  \n",
      "\n",
      "Fold: 6  Epoch: 332  Training loss = 2.4089  Validation loss = 2.5594  \n",
      "\n",
      "Fold: 6  Epoch: 333  Training loss = 2.4086  Validation loss = 2.5589  \n",
      "\n",
      "Fold: 6  Epoch: 334  Training loss = 2.4084  Validation loss = 2.5584  \n",
      "\n",
      "Fold: 6  Epoch: 335  Training loss = 2.4081  Validation loss = 2.5580  \n",
      "\n",
      "Fold: 6  Epoch: 336  Training loss = 2.4080  Validation loss = 2.5576  \n",
      "\n",
      "Fold: 6  Epoch: 337  Training loss = 2.4078  Validation loss = 2.5573  \n",
      "\n",
      "Fold: 6  Epoch: 338  Training loss = 2.4075  Validation loss = 2.5568  \n",
      "\n",
      "Fold: 6  Epoch: 339  Training loss = 2.4073  Validation loss = 2.5564  \n",
      "\n",
      "Fold: 6  Epoch: 340  Training loss = 2.4071  Validation loss = 2.5561  \n",
      "\n",
      "Fold: 6  Epoch: 341  Training loss = 2.4069  Validation loss = 2.5555  \n",
      "\n",
      "Fold: 6  Epoch: 342  Training loss = 2.4067  Validation loss = 2.5553  \n",
      "\n",
      "Fold: 6  Epoch: 343  Training loss = 2.4065  Validation loss = 2.5549  \n",
      "\n",
      "Fold: 6  Epoch: 344  Training loss = 2.4063  Validation loss = 2.5545  \n",
      "\n",
      "Fold: 6  Epoch: 345  Training loss = 2.4061  Validation loss = 2.5542  \n",
      "\n",
      "Fold: 6  Epoch: 346  Training loss = 2.4059  Validation loss = 2.5539  \n",
      "\n",
      "Fold: 6  Epoch: 347  Training loss = 2.4057  Validation loss = 2.5534  \n",
      "\n",
      "Fold: 6  Epoch: 348  Training loss = 2.4055  Validation loss = 2.5531  \n",
      "\n",
      "Fold: 6  Epoch: 349  Training loss = 2.4053  Validation loss = 2.5527  \n",
      "\n",
      "Fold: 6  Epoch: 350  Training loss = 2.4052  Validation loss = 2.5524  \n",
      "\n",
      "Fold: 6  Epoch: 351  Training loss = 2.4049  Validation loss = 2.5518  \n",
      "\n",
      "Fold: 6  Epoch: 352  Training loss = 2.4047  Validation loss = 2.5514  \n",
      "\n",
      "Fold: 6  Epoch: 353  Training loss = 2.4044  Validation loss = 2.5510  \n",
      "\n",
      "Fold: 6  Epoch: 354  Training loss = 2.4042  Validation loss = 2.5505  \n",
      "\n",
      "Fold: 6  Epoch: 355  Training loss = 2.4040  Validation loss = 2.5502  \n",
      "\n",
      "Fold: 6  Epoch: 356  Training loss = 2.4038  Validation loss = 2.5499  \n",
      "\n",
      "Fold: 6  Epoch: 357  Training loss = 2.4036  Validation loss = 2.5494  \n",
      "\n",
      "Fold: 6  Epoch: 358  Training loss = 2.4034  Validation loss = 2.5490  \n",
      "\n",
      "Fold: 6  Epoch: 359  Training loss = 2.4032  Validation loss = 2.5486  \n",
      "\n",
      "Fold: 6  Epoch: 360  Training loss = 2.4029  Validation loss = 2.5482  \n",
      "\n",
      "Fold: 6  Epoch: 361  Training loss = 2.4028  Validation loss = 2.5479  \n",
      "\n",
      "Fold: 6  Epoch: 362  Training loss = 2.4025  Validation loss = 2.5474  \n",
      "\n",
      "Fold: 6  Epoch: 363  Training loss = 2.4024  Validation loss = 2.5471  \n",
      "\n",
      "Fold: 6  Epoch: 364  Training loss = 2.4021  Validation loss = 2.5467  \n",
      "\n",
      "Fold: 6  Epoch: 365  Training loss = 2.4020  Validation loss = 2.5464  \n",
      "\n",
      "Fold: 6  Epoch: 366  Training loss = 2.4018  Validation loss = 2.5460  \n",
      "\n",
      "Fold: 6  Epoch: 367  Training loss = 2.4016  Validation loss = 2.5456  \n",
      "\n",
      "Fold: 6  Epoch: 368  Training loss = 2.4014  Validation loss = 2.5452  \n",
      "\n",
      "Fold: 6  Epoch: 369  Training loss = 2.4012  Validation loss = 2.5448  \n",
      "\n",
      "Fold: 6  Epoch: 370  Training loss = 2.4009  Validation loss = 2.5443  \n",
      "\n",
      "Fold: 6  Epoch: 371  Training loss = 2.4008  Validation loss = 2.5441  \n",
      "\n",
      "Fold: 6  Epoch: 372  Training loss = 2.4007  Validation loss = 2.5438  \n",
      "\n",
      "Fold: 6  Epoch: 373  Training loss = 2.4004  Validation loss = 2.5434  \n",
      "\n",
      "Fold: 6  Epoch: 374  Training loss = 2.4002  Validation loss = 2.5430  \n",
      "\n",
      "Fold: 6  Epoch: 375  Training loss = 2.4000  Validation loss = 2.5425  \n",
      "\n",
      "Fold: 6  Epoch: 376  Training loss = 2.3998  Validation loss = 2.5422  \n",
      "\n",
      "Fold: 6  Epoch: 377  Training loss = 2.3996  Validation loss = 2.5418  \n",
      "\n",
      "Fold: 6  Epoch: 378  Training loss = 2.3994  Validation loss = 2.5413  \n",
      "\n",
      "Fold: 6  Epoch: 379  Training loss = 2.3991  Validation loss = 2.5409  \n",
      "\n",
      "Fold: 6  Epoch: 380  Training loss = 2.3989  Validation loss = 2.5405  \n",
      "\n",
      "Fold: 6  Epoch: 381  Training loss = 2.3987  Validation loss = 2.5401  \n",
      "\n",
      "Fold: 6  Epoch: 382  Training loss = 2.3985  Validation loss = 2.5397  \n",
      "\n",
      "Fold: 6  Epoch: 383  Training loss = 2.3983  Validation loss = 2.5393  \n",
      "\n",
      "Fold: 6  Epoch: 384  Training loss = 2.3980  Validation loss = 2.5388  \n",
      "\n",
      "Fold: 6  Epoch: 385  Training loss = 2.3978  Validation loss = 2.5383  \n",
      "\n",
      "Fold: 6  Epoch: 386  Training loss = 2.3975  Validation loss = 2.5377  \n",
      "\n",
      "Fold: 6  Epoch: 387  Training loss = 2.3973  Validation loss = 2.5373  \n",
      "\n",
      "Fold: 6  Epoch: 388  Training loss = 2.3971  Validation loss = 2.5369  \n",
      "\n",
      "Fold: 6  Epoch: 389  Training loss = 2.3969  Validation loss = 2.5366  \n",
      "\n",
      "Fold: 6  Epoch: 390  Training loss = 2.3966  Validation loss = 2.5361  \n",
      "\n",
      "Fold: 6  Epoch: 391  Training loss = 2.3965  Validation loss = 2.5358  \n",
      "\n",
      "Fold: 6  Epoch: 392  Training loss = 2.3962  Validation loss = 2.5353  \n",
      "\n",
      "Fold: 6  Epoch: 393  Training loss = 2.3960  Validation loss = 2.5348  \n",
      "\n",
      "Fold: 6  Epoch: 394  Training loss = 2.3957  Validation loss = 2.5344  \n",
      "\n",
      "Fold: 6  Epoch: 395  Training loss = 2.3956  Validation loss = 2.5341  \n",
      "\n",
      "Fold: 6  Epoch: 396  Training loss = 2.3954  Validation loss = 2.5338  \n",
      "\n",
      "Fold: 6  Epoch: 397  Training loss = 2.3952  Validation loss = 2.5335  \n",
      "\n",
      "Fold: 6  Epoch: 398  Training loss = 2.3951  Validation loss = 2.5331  \n",
      "\n",
      "Fold: 6  Epoch: 399  Training loss = 2.3948  Validation loss = 2.5327  \n",
      "\n",
      "Fold: 6  Epoch: 400  Training loss = 2.3947  Validation loss = 2.5323  \n",
      "\n",
      "Fold: 6  Epoch: 401  Training loss = 2.3944  Validation loss = 2.5319  \n",
      "\n",
      "Fold: 6  Epoch: 402  Training loss = 2.3942  Validation loss = 2.5315  \n",
      "\n",
      "Fold: 6  Epoch: 403  Training loss = 2.3940  Validation loss = 2.5311  \n",
      "\n",
      "Fold: 6  Epoch: 404  Training loss = 2.3937  Validation loss = 2.5306  \n",
      "\n",
      "Fold: 6  Epoch: 405  Training loss = 2.3935  Validation loss = 2.5302  \n",
      "\n",
      "Fold: 6  Epoch: 406  Training loss = 2.3933  Validation loss = 2.5297  \n",
      "\n",
      "Fold: 6  Epoch: 407  Training loss = 2.3931  Validation loss = 2.5294  \n",
      "\n",
      "Fold: 6  Epoch: 408  Training loss = 2.3930  Validation loss = 2.5291  \n",
      "\n",
      "Fold: 6  Epoch: 409  Training loss = 2.3927  Validation loss = 2.5286  \n",
      "\n",
      "Fold: 6  Epoch: 410  Training loss = 2.3925  Validation loss = 2.5282  \n",
      "\n",
      "Fold: 6  Epoch: 411  Training loss = 2.3923  Validation loss = 2.5278  \n",
      "\n",
      "Fold: 6  Epoch: 412  Training loss = 2.3921  Validation loss = 2.5275  \n",
      "\n",
      "Fold: 6  Epoch: 413  Training loss = 2.3920  Validation loss = 2.5272  \n",
      "\n",
      "Fold: 6  Epoch: 414  Training loss = 2.3918  Validation loss = 2.5269  \n",
      "\n",
      "Fold: 6  Epoch: 415  Training loss = 2.3915  Validation loss = 2.5264  \n",
      "\n",
      "Fold: 6  Epoch: 416  Training loss = 2.3914  Validation loss = 2.5261  \n",
      "\n",
      "Fold: 6  Epoch: 417  Training loss = 2.3911  Validation loss = 2.5256  \n",
      "\n",
      "Fold: 6  Epoch: 418  Training loss = 2.3909  Validation loss = 2.5251  \n",
      "\n",
      "Fold: 6  Epoch: 419  Training loss = 2.3907  Validation loss = 2.5248  \n",
      "\n",
      "Fold: 6  Epoch: 420  Training loss = 2.3905  Validation loss = 2.5243  \n",
      "\n",
      "Fold: 6  Epoch: 421  Training loss = 2.3903  Validation loss = 2.5240  \n",
      "\n",
      "Fold: 6  Epoch: 422  Training loss = 2.3901  Validation loss = 2.5236  \n",
      "\n",
      "Fold: 6  Epoch: 423  Training loss = 2.3899  Validation loss = 2.5231  \n",
      "\n",
      "Fold: 6  Epoch: 424  Training loss = 2.3897  Validation loss = 2.5227  \n",
      "\n",
      "Fold: 6  Epoch: 425  Training loss = 2.3895  Validation loss = 2.5224  \n",
      "\n",
      "Fold: 6  Epoch: 426  Training loss = 2.3892  Validation loss = 2.5220  \n",
      "\n",
      "Fold: 6  Epoch: 427  Training loss = 2.3890  Validation loss = 2.5215  \n",
      "\n",
      "Fold: 6  Epoch: 428  Training loss = 2.3889  Validation loss = 2.5212  \n",
      "\n",
      "Fold: 6  Epoch: 429  Training loss = 2.3886  Validation loss = 2.5208  \n",
      "\n",
      "Fold: 6  Epoch: 430  Training loss = 2.3884  Validation loss = 2.5204  \n",
      "\n",
      "Fold: 6  Epoch: 431  Training loss = 2.3882  Validation loss = 2.5199  \n",
      "\n",
      "Fold: 6  Epoch: 432  Training loss = 2.3880  Validation loss = 2.5195  \n",
      "\n",
      "Fold: 6  Epoch: 433  Training loss = 2.3878  Validation loss = 2.5191  \n",
      "\n",
      "Fold: 6  Epoch: 434  Training loss = 2.3875  Validation loss = 2.5186  \n",
      "\n",
      "Fold: 6  Epoch: 435  Training loss = 2.3873  Validation loss = 2.5182  \n",
      "\n",
      "Fold: 6  Epoch: 436  Training loss = 2.3871  Validation loss = 2.5178  \n",
      "\n",
      "Fold: 6  Epoch: 437  Training loss = 2.3869  Validation loss = 2.5174  \n",
      "\n",
      "Fold: 6  Epoch: 438  Training loss = 2.3867  Validation loss = 2.5170  \n",
      "\n",
      "Fold: 6  Epoch: 439  Training loss = 2.3865  Validation loss = 2.5166  \n",
      "\n",
      "Fold: 6  Epoch: 440  Training loss = 2.3863  Validation loss = 2.5163  \n",
      "\n",
      "Fold: 6  Epoch: 441  Training loss = 2.3861  Validation loss = 2.5159  \n",
      "\n",
      "Fold: 6  Epoch: 442  Training loss = 2.3859  Validation loss = 2.5155  \n",
      "\n",
      "Fold: 6  Epoch: 443  Training loss = 2.3857  Validation loss = 2.5151  \n",
      "\n",
      "Fold: 6  Epoch: 444  Training loss = 2.3855  Validation loss = 2.5147  \n",
      "\n",
      "Fold: 6  Epoch: 445  Training loss = 2.3853  Validation loss = 2.5144  \n",
      "\n",
      "Fold: 6  Epoch: 446  Training loss = 2.3851  Validation loss = 2.5140  \n",
      "\n",
      "Fold: 6  Epoch: 447  Training loss = 2.3849  Validation loss = 2.5136  \n",
      "\n",
      "Fold: 6  Epoch: 448  Training loss = 2.3848  Validation loss = 2.5134  \n",
      "\n",
      "Fold: 6  Epoch: 449  Training loss = 2.3846  Validation loss = 2.5130  \n",
      "\n",
      "Fold: 6  Epoch: 450  Training loss = 2.3844  Validation loss = 2.5127  \n",
      "\n",
      "Fold: 6  Epoch: 451  Training loss = 2.3842  Validation loss = 2.5123  \n",
      "\n",
      "Fold: 6  Epoch: 452  Training loss = 2.3841  Validation loss = 2.5120  \n",
      "\n",
      "Fold: 6  Epoch: 453  Training loss = 2.3838  Validation loss = 2.5116  \n",
      "\n",
      "Fold: 6  Epoch: 454  Training loss = 2.3836  Validation loss = 2.5112  \n",
      "\n",
      "Fold: 6  Epoch: 455  Training loss = 2.3834  Validation loss = 2.5107  \n",
      "\n",
      "Fold: 6  Epoch: 456  Training loss = 2.3832  Validation loss = 2.5103  \n",
      "\n",
      "Fold: 6  Epoch: 457  Training loss = 2.3830  Validation loss = 2.5099  \n",
      "\n",
      "Fold: 6  Epoch: 458  Training loss = 2.3828  Validation loss = 2.5096  \n",
      "\n",
      "Fold: 6  Epoch: 459  Training loss = 2.3826  Validation loss = 2.5093  \n",
      "\n",
      "Fold: 6  Epoch: 460  Training loss = 2.3824  Validation loss = 2.5089  \n",
      "\n",
      "Fold: 6  Epoch: 461  Training loss = 2.3822  Validation loss = 2.5085  \n",
      "\n",
      "Fold: 6  Epoch: 462  Training loss = 2.3821  Validation loss = 2.5082  \n",
      "\n",
      "Fold: 6  Epoch: 463  Training loss = 2.3818  Validation loss = 2.5077  \n",
      "\n",
      "Fold: 6  Epoch: 464  Training loss = 2.3816  Validation loss = 2.5072  \n",
      "\n",
      "Fold: 6  Epoch: 465  Training loss = 2.3813  Validation loss = 2.5067  \n",
      "\n",
      "Fold: 6  Epoch: 466  Training loss = 2.3810  Validation loss = 2.5062  \n",
      "\n",
      "Fold: 6  Epoch: 467  Training loss = 2.3809  Validation loss = 2.5059  \n",
      "\n",
      "Fold: 6  Epoch: 468  Training loss = 2.3806  Validation loss = 2.5054  \n",
      "\n",
      "Fold: 6  Epoch: 469  Training loss = 2.3804  Validation loss = 2.5050  \n",
      "\n",
      "Fold: 6  Epoch: 470  Training loss = 2.3802  Validation loss = 2.5046  \n",
      "\n",
      "Fold: 6  Epoch: 471  Training loss = 2.3800  Validation loss = 2.5042  \n",
      "\n",
      "Fold: 6  Epoch: 472  Training loss = 2.3798  Validation loss = 2.5038  \n",
      "\n",
      "Fold: 6  Epoch: 473  Training loss = 2.3796  Validation loss = 2.5035  \n",
      "\n",
      "Fold: 6  Epoch: 474  Training loss = 2.3794  Validation loss = 2.5031  \n",
      "\n",
      "Fold: 6  Epoch: 475  Training loss = 2.3792  Validation loss = 2.5027  \n",
      "\n",
      "Fold: 6  Epoch: 476  Training loss = 2.3790  Validation loss = 2.5023  \n",
      "\n",
      "Fold: 6  Epoch: 477  Training loss = 2.3789  Validation loss = 2.5020  \n",
      "\n",
      "Fold: 6  Epoch: 478  Training loss = 2.3787  Validation loss = 2.5018  \n",
      "\n",
      "Fold: 6  Epoch: 479  Training loss = 2.3784  Validation loss = 2.5012  \n",
      "\n",
      "Fold: 6  Epoch: 480  Training loss = 2.3782  Validation loss = 2.5008  \n",
      "\n",
      "Fold: 6  Epoch: 481  Training loss = 2.3780  Validation loss = 2.5004  \n",
      "\n",
      "Fold: 6  Epoch: 482  Training loss = 2.3778  Validation loss = 2.5000  \n",
      "\n",
      "Fold: 6  Epoch: 483  Training loss = 2.3776  Validation loss = 2.4996  \n",
      "\n",
      "Fold: 6  Epoch: 484  Training loss = 2.3775  Validation loss = 2.4994  \n",
      "\n",
      "Fold: 6  Epoch: 485  Training loss = 2.3773  Validation loss = 2.4990  \n",
      "\n",
      "Fold: 6  Epoch: 486  Training loss = 2.3771  Validation loss = 2.4987  \n",
      "\n",
      "Fold: 6  Epoch: 487  Training loss = 2.3769  Validation loss = 2.4982  \n",
      "\n",
      "Fold: 6  Epoch: 488  Training loss = 2.3767  Validation loss = 2.4978  \n",
      "\n",
      "Fold: 6  Epoch: 489  Training loss = 2.3764  Validation loss = 2.4973  \n",
      "\n",
      "Fold: 6  Epoch: 490  Training loss = 2.3763  Validation loss = 2.4970  \n",
      "\n",
      "Fold: 6  Epoch: 491  Training loss = 2.3761  Validation loss = 2.4966  \n",
      "\n",
      "Fold: 6  Epoch: 492  Training loss = 2.3759  Validation loss = 2.4962  \n",
      "\n",
      "Fold: 6  Epoch: 493  Training loss = 2.3757  Validation loss = 2.4959  \n",
      "\n",
      "Fold: 6  Epoch: 494  Training loss = 2.3754  Validation loss = 2.4953  \n",
      "\n",
      "Fold: 6  Epoch: 495  Training loss = 2.3752  Validation loss = 2.4949  \n",
      "\n",
      "Fold: 6  Epoch: 496  Training loss = 2.3750  Validation loss = 2.4945  \n",
      "\n",
      "Fold: 6  Epoch: 497  Training loss = 2.3747  Validation loss = 2.4940  \n",
      "\n",
      "Fold: 6  Epoch: 498  Training loss = 2.3745  Validation loss = 2.4937  \n",
      "\n",
      "Fold: 6  Epoch: 499  Training loss = 2.3744  Validation loss = 2.4934  \n",
      "\n",
      "Fold: 6  Epoch: 500  Training loss = 2.3741  Validation loss = 2.4929  \n",
      "\n",
      "Check model:  Fold: 6  Epoch: 500  Training loss = 2.3741  Validation loss = 2.4929  \n",
      "\n",
      "Fold: 7  Epoch: 1  Training loss = 2.4280  Validation loss = 2.1229  \n",
      "\n",
      "Fold: 7  Epoch: 2  Training loss = 2.4278  Validation loss = 2.1225  \n",
      "\n",
      "Fold: 7  Epoch: 3  Training loss = 2.4275  Validation loss = 2.1221  \n",
      "\n",
      "Fold: 7  Epoch: 4  Training loss = 2.4272  Validation loss = 2.1217  \n",
      "\n",
      "Fold: 7  Epoch: 5  Training loss = 2.4270  Validation loss = 2.1213  \n",
      "\n",
      "Fold: 7  Epoch: 6  Training loss = 2.4267  Validation loss = 2.1209  \n",
      "\n",
      "Fold: 7  Epoch: 7  Training loss = 2.4265  Validation loss = 2.1204  \n",
      "\n",
      "Fold: 7  Epoch: 8  Training loss = 2.4262  Validation loss = 2.1200  \n",
      "\n",
      "Fold: 7  Epoch: 9  Training loss = 2.4259  Validation loss = 2.1195  \n",
      "\n",
      "Fold: 7  Epoch: 10  Training loss = 2.4256  Validation loss = 2.1190  \n",
      "\n",
      "Fold: 7  Epoch: 11  Training loss = 2.4254  Validation loss = 2.1186  \n",
      "\n",
      "Fold: 7  Epoch: 12  Training loss = 2.4251  Validation loss = 2.1182  \n",
      "\n",
      "Fold: 7  Epoch: 13  Training loss = 2.4248  Validation loss = 2.1177  \n",
      "\n",
      "Fold: 7  Epoch: 14  Training loss = 2.4246  Validation loss = 2.1172  \n",
      "\n",
      "Fold: 7  Epoch: 15  Training loss = 2.4243  Validation loss = 2.1168  \n",
      "\n",
      "Fold: 7  Epoch: 16  Training loss = 2.4241  Validation loss = 2.1164  \n",
      "\n",
      "Fold: 7  Epoch: 17  Training loss = 2.4238  Validation loss = 2.1160  \n",
      "\n",
      "Fold: 7  Epoch: 18  Training loss = 2.4235  Validation loss = 2.1155  \n",
      "\n",
      "Fold: 7  Epoch: 19  Training loss = 2.4234  Validation loss = 2.1153  \n",
      "\n",
      "Fold: 7  Epoch: 20  Training loss = 2.4231  Validation loss = 2.1148  \n",
      "\n",
      "Fold: 7  Epoch: 21  Training loss = 2.4228  Validation loss = 2.1144  \n",
      "\n",
      "Fold: 7  Epoch: 22  Training loss = 2.4226  Validation loss = 2.1140  \n",
      "\n",
      "Fold: 7  Epoch: 23  Training loss = 2.4224  Validation loss = 2.1136  \n",
      "\n",
      "Fold: 7  Epoch: 24  Training loss = 2.4221  Validation loss = 2.1132  \n",
      "\n",
      "Fold: 7  Epoch: 25  Training loss = 2.4218  Validation loss = 2.1126  \n",
      "\n",
      "Fold: 7  Epoch: 26  Training loss = 2.4216  Validation loss = 2.1124  \n",
      "\n",
      "Fold: 7  Epoch: 27  Training loss = 2.4214  Validation loss = 2.1120  \n",
      "\n",
      "Fold: 7  Epoch: 28  Training loss = 2.4211  Validation loss = 2.1115  \n",
      "\n",
      "Fold: 7  Epoch: 29  Training loss = 2.4208  Validation loss = 2.1110  \n",
      "\n",
      "Fold: 7  Epoch: 30  Training loss = 2.4205  Validation loss = 2.1106  \n",
      "\n",
      "Fold: 7  Epoch: 31  Training loss = 2.4203  Validation loss = 2.1102  \n",
      "\n",
      "Fold: 7  Epoch: 32  Training loss = 2.4200  Validation loss = 2.1098  \n",
      "\n",
      "Fold: 7  Epoch: 33  Training loss = 2.4198  Validation loss = 2.1094  \n",
      "\n",
      "Fold: 7  Epoch: 34  Training loss = 2.4195  Validation loss = 2.1090  \n",
      "\n",
      "Fold: 7  Epoch: 35  Training loss = 2.4193  Validation loss = 2.1085  \n",
      "\n",
      "Fold: 7  Epoch: 36  Training loss = 2.4190  Validation loss = 2.1080  \n",
      "\n",
      "Fold: 7  Epoch: 37  Training loss = 2.4187  Validation loss = 2.1076  \n",
      "\n",
      "Fold: 7  Epoch: 38  Training loss = 2.4184  Validation loss = 2.1072  \n",
      "\n",
      "Fold: 7  Epoch: 39  Training loss = 2.4182  Validation loss = 2.1068  \n",
      "\n",
      "Fold: 7  Epoch: 40  Training loss = 2.4180  Validation loss = 2.1065  \n",
      "\n",
      "Fold: 7  Epoch: 41  Training loss = 2.4178  Validation loss = 2.1061  \n",
      "\n",
      "Fold: 7  Epoch: 42  Training loss = 2.4176  Validation loss = 2.1058  \n",
      "\n",
      "Fold: 7  Epoch: 43  Training loss = 2.4173  Validation loss = 2.1054  \n",
      "\n",
      "Fold: 7  Epoch: 44  Training loss = 2.4171  Validation loss = 2.1050  \n",
      "\n",
      "Fold: 7  Epoch: 45  Training loss = 2.4168  Validation loss = 2.1045  \n",
      "\n",
      "Fold: 7  Epoch: 46  Training loss = 2.4165  Validation loss = 2.1040  \n",
      "\n",
      "Fold: 7  Epoch: 47  Training loss = 2.4162  Validation loss = 2.1034  \n",
      "\n",
      "Fold: 7  Epoch: 48  Training loss = 2.4160  Validation loss = 2.1032  \n",
      "\n",
      "Fold: 7  Epoch: 49  Training loss = 2.4157  Validation loss = 2.1027  \n",
      "\n",
      "Fold: 7  Epoch: 50  Training loss = 2.4155  Validation loss = 2.1022  \n",
      "\n",
      "Fold: 7  Epoch: 51  Training loss = 2.4152  Validation loss = 2.1017  \n",
      "\n",
      "Fold: 7  Epoch: 52  Training loss = 2.4149  Validation loss = 2.1013  \n",
      "\n",
      "Fold: 7  Epoch: 53  Training loss = 2.4147  Validation loss = 2.1009  \n",
      "\n",
      "Fold: 7  Epoch: 54  Training loss = 2.4144  Validation loss = 2.1005  \n",
      "\n",
      "Fold: 7  Epoch: 55  Training loss = 2.4142  Validation loss = 2.1001  \n",
      "\n",
      "Fold: 7  Epoch: 56  Training loss = 2.4139  Validation loss = 2.0997  \n",
      "\n",
      "Fold: 7  Epoch: 57  Training loss = 2.4136  Validation loss = 2.0993  \n",
      "\n",
      "Fold: 7  Epoch: 58  Training loss = 2.4133  Validation loss = 2.0987  \n",
      "\n",
      "Fold: 7  Epoch: 59  Training loss = 2.4130  Validation loss = 2.0982  \n",
      "\n",
      "Fold: 7  Epoch: 60  Training loss = 2.4127  Validation loss = 2.0977  \n",
      "\n",
      "Fold: 7  Epoch: 61  Training loss = 2.4125  Validation loss = 2.0973  \n",
      "\n",
      "Fold: 7  Epoch: 62  Training loss = 2.4123  Validation loss = 2.0970  \n",
      "\n",
      "Fold: 7  Epoch: 63  Training loss = 2.4121  Validation loss = 2.0966  \n",
      "\n",
      "Fold: 7  Epoch: 64  Training loss = 2.4118  Validation loss = 2.0962  \n",
      "\n",
      "Fold: 7  Epoch: 65  Training loss = 2.4116  Validation loss = 2.0958  \n",
      "\n",
      "Fold: 7  Epoch: 66  Training loss = 2.4114  Validation loss = 2.0955  \n",
      "\n",
      "Fold: 7  Epoch: 67  Training loss = 2.4111  Validation loss = 2.0949  \n",
      "\n",
      "Fold: 7  Epoch: 68  Training loss = 2.4109  Validation loss = 2.0946  \n",
      "\n",
      "Fold: 7  Epoch: 69  Training loss = 2.4106  Validation loss = 2.0943  \n",
      "\n",
      "Fold: 7  Epoch: 70  Training loss = 2.4103  Validation loss = 2.0937  \n",
      "\n",
      "Fold: 7  Epoch: 71  Training loss = 2.4101  Validation loss = 2.0934  \n",
      "\n",
      "Fold: 7  Epoch: 72  Training loss = 2.4098  Validation loss = 2.0930  \n",
      "\n",
      "Fold: 7  Epoch: 73  Training loss = 2.4096  Validation loss = 2.0925  \n",
      "\n",
      "Fold: 7  Epoch: 74  Training loss = 2.4093  Validation loss = 2.0921  \n",
      "\n",
      "Fold: 7  Epoch: 75  Training loss = 2.4090  Validation loss = 2.0916  \n",
      "\n",
      "Fold: 7  Epoch: 76  Training loss = 2.4088  Validation loss = 2.0912  \n",
      "\n",
      "Fold: 7  Epoch: 77  Training loss = 2.4085  Validation loss = 2.0907  \n",
      "\n",
      "Fold: 7  Epoch: 78  Training loss = 2.4082  Validation loss = 2.0904  \n",
      "\n",
      "Fold: 7  Epoch: 79  Training loss = 2.4080  Validation loss = 2.0900  \n",
      "\n",
      "Fold: 7  Epoch: 80  Training loss = 2.4077  Validation loss = 2.0895  \n",
      "\n",
      "Fold: 7  Epoch: 81  Training loss = 2.4075  Validation loss = 2.0891  \n",
      "\n",
      "Fold: 7  Epoch: 82  Training loss = 2.4072  Validation loss = 2.0887  \n",
      "\n",
      "Fold: 7  Epoch: 83  Training loss = 2.4069  Validation loss = 2.0882  \n",
      "\n",
      "Fold: 7  Epoch: 84  Training loss = 2.4067  Validation loss = 2.0878  \n",
      "\n",
      "Fold: 7  Epoch: 85  Training loss = 2.4065  Validation loss = 2.0875  \n",
      "\n",
      "Fold: 7  Epoch: 86  Training loss = 2.4062  Validation loss = 2.0870  \n",
      "\n",
      "Fold: 7  Epoch: 87  Training loss = 2.4059  Validation loss = 2.0865  \n",
      "\n",
      "Fold: 7  Epoch: 88  Training loss = 2.4057  Validation loss = 2.0862  \n",
      "\n",
      "Fold: 7  Epoch: 89  Training loss = 2.4055  Validation loss = 2.0858  \n",
      "\n",
      "Fold: 7  Epoch: 90  Training loss = 2.4052  Validation loss = 2.0853  \n",
      "\n",
      "Fold: 7  Epoch: 91  Training loss = 2.4049  Validation loss = 2.0849  \n",
      "\n",
      "Fold: 7  Epoch: 92  Training loss = 2.4046  Validation loss = 2.0844  \n",
      "\n",
      "Fold: 7  Epoch: 93  Training loss = 2.4044  Validation loss = 2.0840  \n",
      "\n",
      "Fold: 7  Epoch: 94  Training loss = 2.4041  Validation loss = 2.0836  \n",
      "\n",
      "Fold: 7  Epoch: 95  Training loss = 2.4039  Validation loss = 2.0832  \n",
      "\n",
      "Fold: 7  Epoch: 96  Training loss = 2.4037  Validation loss = 2.0828  \n",
      "\n",
      "Fold: 7  Epoch: 97  Training loss = 2.4034  Validation loss = 2.0824  \n",
      "\n",
      "Fold: 7  Epoch: 98  Training loss = 2.4032  Validation loss = 2.0820  \n",
      "\n",
      "Fold: 7  Epoch: 99  Training loss = 2.4029  Validation loss = 2.0815  \n",
      "\n",
      "Fold: 7  Epoch: 100  Training loss = 2.4027  Validation loss = 2.0812  \n",
      "\n",
      "Fold: 7  Epoch: 101  Training loss = 2.4025  Validation loss = 2.0808  \n",
      "\n",
      "Fold: 7  Epoch: 102  Training loss = 2.4022  Validation loss = 2.0804  \n",
      "\n",
      "Fold: 7  Epoch: 103  Training loss = 2.4020  Validation loss = 2.0800  \n",
      "\n",
      "Fold: 7  Epoch: 104  Training loss = 2.4018  Validation loss = 2.0796  \n",
      "\n",
      "Fold: 7  Epoch: 105  Training loss = 2.4016  Validation loss = 2.0793  \n",
      "\n",
      "Fold: 7  Epoch: 106  Training loss = 2.4014  Validation loss = 2.0789  \n",
      "\n",
      "Fold: 7  Epoch: 107  Training loss = 2.4010  Validation loss = 2.0784  \n",
      "\n",
      "Fold: 7  Epoch: 108  Training loss = 2.4008  Validation loss = 2.0781  \n",
      "\n",
      "Fold: 7  Epoch: 109  Training loss = 2.4006  Validation loss = 2.0777  \n",
      "\n",
      "Fold: 7  Epoch: 110  Training loss = 2.4003  Validation loss = 2.0772  \n",
      "\n",
      "Fold: 7  Epoch: 111  Training loss = 2.4000  Validation loss = 2.0767  \n",
      "\n",
      "Fold: 7  Epoch: 112  Training loss = 2.3999  Validation loss = 2.0765  \n",
      "\n",
      "Fold: 7  Epoch: 113  Training loss = 2.3997  Validation loss = 2.0762  \n",
      "\n",
      "Fold: 7  Epoch: 114  Training loss = 2.3994  Validation loss = 2.0758  \n",
      "\n",
      "Fold: 7  Epoch: 115  Training loss = 2.3991  Validation loss = 2.0753  \n",
      "\n",
      "Fold: 7  Epoch: 116  Training loss = 2.3989  Validation loss = 2.0749  \n",
      "\n",
      "Fold: 7  Epoch: 117  Training loss = 2.3986  Validation loss = 2.0745  \n",
      "\n",
      "Fold: 7  Epoch: 118  Training loss = 2.3984  Validation loss = 2.0741  \n",
      "\n",
      "Fold: 7  Epoch: 119  Training loss = 2.3981  Validation loss = 2.0737  \n",
      "\n",
      "Fold: 7  Epoch: 120  Training loss = 2.3979  Validation loss = 2.0732  \n",
      "\n",
      "Fold: 7  Epoch: 121  Training loss = 2.3976  Validation loss = 2.0728  \n",
      "\n",
      "Fold: 7  Epoch: 122  Training loss = 2.3973  Validation loss = 2.0723  \n",
      "\n",
      "Fold: 7  Epoch: 123  Training loss = 2.3970  Validation loss = 2.0719  \n",
      "\n",
      "Fold: 7  Epoch: 124  Training loss = 2.3968  Validation loss = 2.0714  \n",
      "\n",
      "Fold: 7  Epoch: 125  Training loss = 2.3966  Validation loss = 2.0711  \n",
      "\n",
      "Fold: 7  Epoch: 126  Training loss = 2.3963  Validation loss = 2.0706  \n",
      "\n",
      "Fold: 7  Epoch: 127  Training loss = 2.3960  Validation loss = 2.0701  \n",
      "\n",
      "Fold: 7  Epoch: 128  Training loss = 2.3957  Validation loss = 2.0696  \n",
      "\n",
      "Fold: 7  Epoch: 129  Training loss = 2.3954  Validation loss = 2.0692  \n",
      "\n",
      "Fold: 7  Epoch: 130  Training loss = 2.3952  Validation loss = 2.0688  \n",
      "\n",
      "Fold: 7  Epoch: 131  Training loss = 2.3949  Validation loss = 2.0683  \n",
      "\n",
      "Fold: 7  Epoch: 132  Training loss = 2.3946  Validation loss = 2.0679  \n",
      "\n",
      "Fold: 7  Epoch: 133  Training loss = 2.3944  Validation loss = 2.0675  \n",
      "\n",
      "Fold: 7  Epoch: 134  Training loss = 2.3941  Validation loss = 2.0670  \n",
      "\n",
      "Fold: 7  Epoch: 135  Training loss = 2.3938  Validation loss = 2.0665  \n",
      "\n",
      "Fold: 7  Epoch: 136  Training loss = 2.3936  Validation loss = 2.0661  \n",
      "\n",
      "Fold: 7  Epoch: 137  Training loss = 2.3933  Validation loss = 2.0657  \n",
      "\n",
      "Fold: 7  Epoch: 138  Training loss = 2.3930  Validation loss = 2.0653  \n",
      "\n",
      "Fold: 7  Epoch: 139  Training loss = 2.3928  Validation loss = 2.0649  \n",
      "\n",
      "Fold: 7  Epoch: 140  Training loss = 2.3926  Validation loss = 2.0645  \n",
      "\n",
      "Fold: 7  Epoch: 141  Training loss = 2.3923  Validation loss = 2.0641  \n",
      "\n",
      "Fold: 7  Epoch: 142  Training loss = 2.3921  Validation loss = 2.0638  \n",
      "\n",
      "Fold: 7  Epoch: 143  Training loss = 2.3918  Validation loss = 2.0633  \n",
      "\n",
      "Fold: 7  Epoch: 144  Training loss = 2.3916  Validation loss = 2.0629  \n",
      "\n",
      "Fold: 7  Epoch: 145  Training loss = 2.3914  Validation loss = 2.0626  \n",
      "\n",
      "Fold: 7  Epoch: 146  Training loss = 2.3912  Validation loss = 2.0622  \n",
      "\n",
      "Fold: 7  Epoch: 147  Training loss = 2.3909  Validation loss = 2.0618  \n",
      "\n",
      "Fold: 7  Epoch: 148  Training loss = 2.3906  Validation loss = 2.0613  \n",
      "\n",
      "Fold: 7  Epoch: 149  Training loss = 2.3904  Validation loss = 2.0609  \n",
      "\n",
      "Fold: 7  Epoch: 150  Training loss = 2.3902  Validation loss = 2.0606  \n",
      "\n",
      "Fold: 7  Epoch: 151  Training loss = 2.3899  Validation loss = 2.0601  \n",
      "\n",
      "Fold: 7  Epoch: 152  Training loss = 2.3897  Validation loss = 2.0598  \n",
      "\n",
      "Fold: 7  Epoch: 153  Training loss = 2.3894  Validation loss = 2.0593  \n",
      "\n",
      "Fold: 7  Epoch: 154  Training loss = 2.3891  Validation loss = 2.0589  \n",
      "\n",
      "Fold: 7  Epoch: 155  Training loss = 2.3889  Validation loss = 2.0584  \n",
      "\n",
      "Fold: 7  Epoch: 156  Training loss = 2.3886  Validation loss = 2.0580  \n",
      "\n",
      "Fold: 7  Epoch: 157  Training loss = 2.3883  Validation loss = 2.0575  \n",
      "\n",
      "Fold: 7  Epoch: 158  Training loss = 2.3881  Validation loss = 2.0571  \n",
      "\n",
      "Fold: 7  Epoch: 159  Training loss = 2.3879  Validation loss = 2.0568  \n",
      "\n",
      "Fold: 7  Epoch: 160  Training loss = 2.3876  Validation loss = 2.0563  \n",
      "\n",
      "Fold: 7  Epoch: 161  Training loss = 2.3874  Validation loss = 2.0559  \n",
      "\n",
      "Fold: 7  Epoch: 162  Training loss = 2.3872  Validation loss = 2.0556  \n",
      "\n",
      "Fold: 7  Epoch: 163  Training loss = 2.3870  Validation loss = 2.0553  \n",
      "\n",
      "Fold: 7  Epoch: 164  Training loss = 2.3868  Validation loss = 2.0549  \n",
      "\n",
      "Fold: 7  Epoch: 165  Training loss = 2.3865  Validation loss = 2.0546  \n",
      "\n",
      "Fold: 7  Epoch: 166  Training loss = 2.3863  Validation loss = 2.0543  \n",
      "\n",
      "Fold: 7  Epoch: 167  Training loss = 2.3861  Validation loss = 2.0538  \n",
      "\n",
      "Fold: 7  Epoch: 168  Training loss = 2.3858  Validation loss = 2.0534  \n",
      "\n",
      "Fold: 7  Epoch: 169  Training loss = 2.3855  Validation loss = 2.0529  \n",
      "\n",
      "Fold: 7  Epoch: 170  Training loss = 2.3853  Validation loss = 2.0525  \n",
      "\n",
      "Fold: 7  Epoch: 171  Training loss = 2.3850  Validation loss = 2.0521  \n",
      "\n",
      "Fold: 7  Epoch: 172  Training loss = 2.3848  Validation loss = 2.0518  \n",
      "\n",
      "Fold: 7  Epoch: 173  Training loss = 2.3846  Validation loss = 2.0514  \n",
      "\n",
      "Fold: 7  Epoch: 174  Training loss = 2.3844  Validation loss = 2.0510  \n",
      "\n",
      "Fold: 7  Epoch: 175  Training loss = 2.3842  Validation loss = 2.0507  \n",
      "\n",
      "Fold: 7  Epoch: 176  Training loss = 2.3839  Validation loss = 2.0502  \n",
      "\n",
      "Fold: 7  Epoch: 177  Training loss = 2.3836  Validation loss = 2.0497  \n",
      "\n",
      "Fold: 7  Epoch: 178  Training loss = 2.3834  Validation loss = 2.0493  \n",
      "\n",
      "Fold: 7  Epoch: 179  Training loss = 2.3831  Validation loss = 2.0488  \n",
      "\n",
      "Fold: 7  Epoch: 180  Training loss = 2.3828  Validation loss = 2.0483  \n",
      "\n",
      "Fold: 7  Epoch: 181  Training loss = 2.3825  Validation loss = 2.0478  \n",
      "\n",
      "Fold: 7  Epoch: 182  Training loss = 2.3823  Validation loss = 2.0474  \n",
      "\n",
      "Fold: 7  Epoch: 183  Training loss = 2.3820  Validation loss = 2.0470  \n",
      "\n",
      "Fold: 7  Epoch: 184  Training loss = 2.3818  Validation loss = 2.0466  \n",
      "\n",
      "Fold: 7  Epoch: 185  Training loss = 2.3816  Validation loss = 2.0462  \n",
      "\n",
      "Fold: 7  Epoch: 186  Training loss = 2.3813  Validation loss = 2.0458  \n",
      "\n",
      "Fold: 7  Epoch: 187  Training loss = 2.3810  Validation loss = 2.0453  \n",
      "\n",
      "Fold: 7  Epoch: 188  Training loss = 2.3807  Validation loss = 2.0448  \n",
      "\n",
      "Fold: 7  Epoch: 189  Training loss = 2.3805  Validation loss = 2.0444  \n",
      "\n",
      "Fold: 7  Epoch: 190  Training loss = 2.3802  Validation loss = 2.0440  \n",
      "\n",
      "Fold: 7  Epoch: 191  Training loss = 2.3800  Validation loss = 2.0437  \n",
      "\n",
      "Fold: 7  Epoch: 192  Training loss = 2.3797  Validation loss = 2.0432  \n",
      "\n",
      "Fold: 7  Epoch: 193  Training loss = 2.3795  Validation loss = 2.0428  \n",
      "\n",
      "Fold: 7  Epoch: 194  Training loss = 2.3792  Validation loss = 2.0424  \n",
      "\n",
      "Fold: 7  Epoch: 195  Training loss = 2.3790  Validation loss = 2.0420  \n",
      "\n",
      "Fold: 7  Epoch: 196  Training loss = 2.3788  Validation loss = 2.0416  \n",
      "\n",
      "Fold: 7  Epoch: 197  Training loss = 2.3785  Validation loss = 2.0412  \n",
      "\n",
      "Fold: 7  Epoch: 198  Training loss = 2.3783  Validation loss = 2.0409  \n",
      "\n",
      "Fold: 7  Epoch: 199  Training loss = 2.3780  Validation loss = 2.0405  \n",
      "\n",
      "Fold: 7  Epoch: 200  Training loss = 2.3778  Validation loss = 2.0400  \n",
      "\n",
      "Fold: 7  Epoch: 201  Training loss = 2.3775  Validation loss = 2.0395  \n",
      "\n",
      "Fold: 7  Epoch: 202  Training loss = 2.3773  Validation loss = 2.0392  \n",
      "\n",
      "Fold: 7  Epoch: 203  Training loss = 2.3770  Validation loss = 2.0387  \n",
      "\n",
      "Fold: 7  Epoch: 204  Training loss = 2.3768  Validation loss = 2.0384  \n",
      "\n",
      "Fold: 7  Epoch: 205  Training loss = 2.3766  Validation loss = 2.0380  \n",
      "\n",
      "Fold: 7  Epoch: 206  Training loss = 2.3763  Validation loss = 2.0376  \n",
      "\n",
      "Fold: 7  Epoch: 207  Training loss = 2.3760  Validation loss = 2.0371  \n",
      "\n",
      "Fold: 7  Epoch: 208  Training loss = 2.3758  Validation loss = 2.0367  \n",
      "\n",
      "Fold: 7  Epoch: 209  Training loss = 2.3756  Validation loss = 2.0364  \n",
      "\n",
      "Fold: 7  Epoch: 210  Training loss = 2.3753  Validation loss = 2.0360  \n",
      "\n",
      "Fold: 7  Epoch: 211  Training loss = 2.3750  Validation loss = 2.0354  \n",
      "\n",
      "Fold: 7  Epoch: 212  Training loss = 2.3748  Validation loss = 2.0350  \n",
      "\n",
      "Fold: 7  Epoch: 213  Training loss = 2.3746  Validation loss = 2.0347  \n",
      "\n",
      "Fold: 7  Epoch: 214  Training loss = 2.3743  Validation loss = 2.0342  \n",
      "\n",
      "Fold: 7  Epoch: 215  Training loss = 2.3740  Validation loss = 2.0338  \n",
      "\n",
      "Fold: 7  Epoch: 216  Training loss = 2.3739  Validation loss = 2.0335  \n",
      "\n",
      "Fold: 7  Epoch: 217  Training loss = 2.3737  Validation loss = 2.0332  \n",
      "\n",
      "Fold: 7  Epoch: 218  Training loss = 2.3735  Validation loss = 2.0329  \n",
      "\n",
      "Fold: 7  Epoch: 219  Training loss = 2.3732  Validation loss = 2.0324  \n",
      "\n",
      "Fold: 7  Epoch: 220  Training loss = 2.3729  Validation loss = 2.0319  \n",
      "\n",
      "Fold: 7  Epoch: 221  Training loss = 2.3726  Validation loss = 2.0315  \n",
      "\n",
      "Fold: 7  Epoch: 222  Training loss = 2.3724  Validation loss = 2.0311  \n",
      "\n",
      "Fold: 7  Epoch: 223  Training loss = 2.3722  Validation loss = 2.0307  \n",
      "\n",
      "Fold: 7  Epoch: 224  Training loss = 2.3719  Validation loss = 2.0303  \n",
      "\n",
      "Fold: 7  Epoch: 225  Training loss = 2.3717  Validation loss = 2.0299  \n",
      "\n",
      "Fold: 7  Epoch: 226  Training loss = 2.3714  Validation loss = 2.0295  \n",
      "\n",
      "Fold: 7  Epoch: 227  Training loss = 2.3713  Validation loss = 2.0292  \n",
      "\n",
      "Fold: 7  Epoch: 228  Training loss = 2.3710  Validation loss = 2.0287  \n",
      "\n",
      "Fold: 7  Epoch: 229  Training loss = 2.3708  Validation loss = 2.0283  \n",
      "\n",
      "Fold: 7  Epoch: 230  Training loss = 2.3705  Validation loss = 2.0278  \n",
      "\n",
      "Fold: 7  Epoch: 231  Training loss = 2.3702  Validation loss = 2.0274  \n",
      "\n",
      "Fold: 7  Epoch: 232  Training loss = 2.3699  Validation loss = 2.0269  \n",
      "\n",
      "Fold: 7  Epoch: 233  Training loss = 2.3697  Validation loss = 2.0265  \n",
      "\n",
      "Fold: 7  Epoch: 234  Training loss = 2.3694  Validation loss = 2.0261  \n",
      "\n",
      "Fold: 7  Epoch: 235  Training loss = 2.3692  Validation loss = 2.0258  \n",
      "\n",
      "Fold: 7  Epoch: 236  Training loss = 2.3690  Validation loss = 2.0253  \n",
      "\n",
      "Fold: 7  Epoch: 237  Training loss = 2.3688  Validation loss = 2.0249  \n",
      "\n",
      "Fold: 7  Epoch: 238  Training loss = 2.3686  Validation loss = 2.0246  \n",
      "\n",
      "Fold: 7  Epoch: 239  Training loss = 2.3684  Validation loss = 2.0242  \n",
      "\n",
      "Fold: 7  Epoch: 240  Training loss = 2.3681  Validation loss = 2.0237  \n",
      "\n",
      "Fold: 7  Epoch: 241  Training loss = 2.3678  Validation loss = 2.0233  \n",
      "\n",
      "Fold: 7  Epoch: 242  Training loss = 2.3676  Validation loss = 2.0229  \n",
      "\n",
      "Fold: 7  Epoch: 243  Training loss = 2.3674  Validation loss = 2.0227  \n",
      "\n",
      "Fold: 7  Epoch: 244  Training loss = 2.3672  Validation loss = 2.0223  \n",
      "\n",
      "Fold: 7  Epoch: 245  Training loss = 2.3669  Validation loss = 2.0219  \n",
      "\n",
      "Fold: 7  Epoch: 246  Training loss = 2.3667  Validation loss = 2.0216  \n",
      "\n",
      "Fold: 7  Epoch: 247  Training loss = 2.3665  Validation loss = 2.0212  \n",
      "\n",
      "Fold: 7  Epoch: 248  Training loss = 2.3663  Validation loss = 2.0207  \n",
      "\n",
      "Fold: 7  Epoch: 249  Training loss = 2.3660  Validation loss = 2.0203  \n",
      "\n",
      "Fold: 7  Epoch: 250  Training loss = 2.3657  Validation loss = 2.0198  \n",
      "\n",
      "Fold: 7  Epoch: 251  Training loss = 2.3655  Validation loss = 2.0194  \n",
      "\n",
      "Fold: 7  Epoch: 252  Training loss = 2.3652  Validation loss = 2.0189  \n",
      "\n",
      "Fold: 7  Epoch: 253  Training loss = 2.3649  Validation loss = 2.0185  \n",
      "\n",
      "Fold: 7  Epoch: 254  Training loss = 2.3646  Validation loss = 2.0179  \n",
      "\n",
      "Fold: 7  Epoch: 255  Training loss = 2.3643  Validation loss = 2.0174  \n",
      "\n",
      "Fold: 7  Epoch: 256  Training loss = 2.3642  Validation loss = 2.0171  \n",
      "\n",
      "Fold: 7  Epoch: 257  Training loss = 2.3640  Validation loss = 2.0168  \n",
      "\n",
      "Fold: 7  Epoch: 258  Training loss = 2.3638  Validation loss = 2.0165  \n",
      "\n",
      "Fold: 7  Epoch: 259  Training loss = 2.3635  Validation loss = 2.0160  \n",
      "\n",
      "Fold: 7  Epoch: 260  Training loss = 2.3633  Validation loss = 2.0156  \n",
      "\n",
      "Fold: 7  Epoch: 261  Training loss = 2.3631  Validation loss = 2.0152  \n",
      "\n",
      "Fold: 7  Epoch: 262  Training loss = 2.3628  Validation loss = 2.0148  \n",
      "\n",
      "Fold: 7  Epoch: 263  Training loss = 2.3625  Validation loss = 2.0143  \n",
      "\n",
      "Fold: 7  Epoch: 264  Training loss = 2.3622  Validation loss = 2.0138  \n",
      "\n",
      "Fold: 7  Epoch: 265  Training loss = 2.3620  Validation loss = 2.0134  \n",
      "\n",
      "Fold: 7  Epoch: 266  Training loss = 2.3617  Validation loss = 2.0129  \n",
      "\n",
      "Fold: 7  Epoch: 267  Training loss = 2.3614  Validation loss = 2.0124  \n",
      "\n",
      "Fold: 7  Epoch: 268  Training loss = 2.3612  Validation loss = 2.0120  \n",
      "\n",
      "Fold: 7  Epoch: 269  Training loss = 2.3610  Validation loss = 2.0117  \n",
      "\n",
      "Fold: 7  Epoch: 270  Training loss = 2.3608  Validation loss = 2.0114  \n",
      "\n",
      "Fold: 7  Epoch: 271  Training loss = 2.3605  Validation loss = 2.0109  \n",
      "\n",
      "Fold: 7  Epoch: 272  Training loss = 2.3602  Validation loss = 2.0105  \n",
      "\n",
      "Fold: 7  Epoch: 273  Training loss = 2.3600  Validation loss = 2.0101  \n",
      "\n",
      "Fold: 7  Epoch: 274  Training loss = 2.3599  Validation loss = 2.0099  \n",
      "\n",
      "Fold: 7  Epoch: 275  Training loss = 2.3596  Validation loss = 2.0095  \n",
      "\n",
      "Fold: 7  Epoch: 276  Training loss = 2.3594  Validation loss = 2.0092  \n",
      "\n",
      "Fold: 7  Epoch: 277  Training loss = 2.3592  Validation loss = 2.0087  \n",
      "\n",
      "Fold: 7  Epoch: 278  Training loss = 2.3589  Validation loss = 2.0083  \n",
      "\n",
      "Fold: 7  Epoch: 279  Training loss = 2.3587  Validation loss = 2.0078  \n",
      "\n",
      "Fold: 7  Epoch: 280  Training loss = 2.3584  Validation loss = 2.0074  \n",
      "\n",
      "Fold: 7  Epoch: 281  Training loss = 2.3581  Validation loss = 2.0069  \n",
      "\n",
      "Fold: 7  Epoch: 282  Training loss = 2.3579  Validation loss = 2.0066  \n",
      "\n",
      "Fold: 7  Epoch: 283  Training loss = 2.3577  Validation loss = 2.0062  \n",
      "\n",
      "Fold: 7  Epoch: 284  Training loss = 2.3574  Validation loss = 2.0058  \n",
      "\n",
      "Fold: 7  Epoch: 285  Training loss = 2.3572  Validation loss = 2.0054  \n",
      "\n",
      "Fold: 7  Epoch: 286  Training loss = 2.3570  Validation loss = 2.0050  \n",
      "\n",
      "Fold: 7  Epoch: 287  Training loss = 2.3567  Validation loss = 2.0046  \n",
      "\n",
      "Fold: 7  Epoch: 288  Training loss = 2.3565  Validation loss = 2.0041  \n",
      "\n",
      "Fold: 7  Epoch: 289  Training loss = 2.3562  Validation loss = 2.0037  \n",
      "\n",
      "Fold: 7  Epoch: 290  Training loss = 2.3559  Validation loss = 2.0032  \n",
      "\n",
      "Fold: 7  Epoch: 291  Training loss = 2.3557  Validation loss = 2.0029  \n",
      "\n",
      "Fold: 7  Epoch: 292  Training loss = 2.3555  Validation loss = 2.0025  \n",
      "\n",
      "Fold: 7  Epoch: 293  Training loss = 2.3553  Validation loss = 2.0021  \n",
      "\n",
      "Fold: 7  Epoch: 294  Training loss = 2.3551  Validation loss = 2.0018  \n",
      "\n",
      "Fold: 7  Epoch: 295  Training loss = 2.3549  Validation loss = 2.0015  \n",
      "\n",
      "Fold: 7  Epoch: 296  Training loss = 2.3547  Validation loss = 2.0010  \n",
      "\n",
      "Fold: 7  Epoch: 297  Training loss = 2.3545  Validation loss = 2.0007  \n",
      "\n",
      "Fold: 7  Epoch: 298  Training loss = 2.3543  Validation loss = 2.0004  \n",
      "\n",
      "Fold: 7  Epoch: 299  Training loss = 2.3540  Validation loss = 1.9999  \n",
      "\n",
      "Fold: 7  Epoch: 300  Training loss = 2.3537  Validation loss = 1.9995  \n",
      "\n",
      "Fold: 7  Epoch: 301  Training loss = 2.3534  Validation loss = 1.9990  \n",
      "\n",
      "Fold: 7  Epoch: 302  Training loss = 2.3532  Validation loss = 1.9986  \n",
      "\n",
      "Fold: 7  Epoch: 303  Training loss = 2.3530  Validation loss = 1.9983  \n",
      "\n",
      "Fold: 7  Epoch: 304  Training loss = 2.3528  Validation loss = 1.9978  \n",
      "\n",
      "Fold: 7  Epoch: 305  Training loss = 2.3525  Validation loss = 1.9973  \n",
      "\n",
      "Fold: 7  Epoch: 306  Training loss = 2.3523  Validation loss = 1.9969  \n",
      "\n",
      "Fold: 7  Epoch: 307  Training loss = 2.3520  Validation loss = 1.9966  \n",
      "\n",
      "Fold: 7  Epoch: 308  Training loss = 2.3518  Validation loss = 1.9962  \n",
      "\n",
      "Fold: 7  Epoch: 309  Training loss = 2.3516  Validation loss = 1.9959  \n",
      "\n",
      "Fold: 7  Epoch: 310  Training loss = 2.3514  Validation loss = 1.9955  \n",
      "\n",
      "Fold: 7  Epoch: 311  Training loss = 2.3511  Validation loss = 1.9950  \n",
      "\n",
      "Fold: 7  Epoch: 312  Training loss = 2.3508  Validation loss = 1.9945  \n",
      "\n",
      "Fold: 7  Epoch: 313  Training loss = 2.3506  Validation loss = 1.9941  \n",
      "\n",
      "Fold: 7  Epoch: 314  Training loss = 2.3503  Validation loss = 1.9936  \n",
      "\n",
      "Fold: 7  Epoch: 315  Training loss = 2.3501  Validation loss = 1.9932  \n",
      "\n",
      "Fold: 7  Epoch: 316  Training loss = 2.3498  Validation loss = 1.9928  \n",
      "\n",
      "Fold: 7  Epoch: 317  Training loss = 2.3496  Validation loss = 1.9924  \n",
      "\n",
      "Fold: 7  Epoch: 318  Training loss = 2.3492  Validation loss = 1.9918  \n",
      "\n",
      "Fold: 7  Epoch: 319  Training loss = 2.3489  Validation loss = 1.9913  \n",
      "\n",
      "Fold: 7  Epoch: 320  Training loss = 2.3488  Validation loss = 1.9911  \n",
      "\n",
      "Fold: 7  Epoch: 321  Training loss = 2.3485  Validation loss = 1.9907  \n",
      "\n",
      "Fold: 7  Epoch: 322  Training loss = 2.3484  Validation loss = 1.9904  \n",
      "\n",
      "Fold: 7  Epoch: 323  Training loss = 2.3482  Validation loss = 1.9900  \n",
      "\n",
      "Fold: 7  Epoch: 324  Training loss = 2.3479  Validation loss = 1.9896  \n",
      "\n",
      "Fold: 7  Epoch: 325  Training loss = 2.3477  Validation loss = 1.9893  \n",
      "\n",
      "Fold: 7  Epoch: 326  Training loss = 2.3475  Validation loss = 1.9890  \n",
      "\n",
      "Fold: 7  Epoch: 327  Training loss = 2.3473  Validation loss = 1.9886  \n",
      "\n",
      "Fold: 7  Epoch: 328  Training loss = 2.3471  Validation loss = 1.9882  \n",
      "\n",
      "Fold: 7  Epoch: 329  Training loss = 2.3469  Validation loss = 1.9878  \n",
      "\n",
      "Fold: 7  Epoch: 330  Training loss = 2.3467  Validation loss = 1.9875  \n",
      "\n",
      "Fold: 7  Epoch: 331  Training loss = 2.3465  Validation loss = 1.9871  \n",
      "\n",
      "Fold: 7  Epoch: 332  Training loss = 2.3463  Validation loss = 1.9868  \n",
      "\n",
      "Fold: 7  Epoch: 333  Training loss = 2.3461  Validation loss = 1.9865  \n",
      "\n",
      "Fold: 7  Epoch: 334  Training loss = 2.3459  Validation loss = 1.9861  \n",
      "\n",
      "Fold: 7  Epoch: 335  Training loss = 2.3456  Validation loss = 1.9856  \n",
      "\n",
      "Fold: 7  Epoch: 336  Training loss = 2.3452  Validation loss = 1.9851  \n",
      "\n",
      "Fold: 7  Epoch: 337  Training loss = 2.3450  Validation loss = 1.9847  \n",
      "\n",
      "Fold: 7  Epoch: 338  Training loss = 2.3448  Validation loss = 1.9842  \n",
      "\n",
      "Fold: 7  Epoch: 339  Training loss = 2.3445  Validation loss = 1.9838  \n",
      "\n",
      "Fold: 7  Epoch: 340  Training loss = 2.3442  Validation loss = 1.9834  \n",
      "\n",
      "Fold: 7  Epoch: 341  Training loss = 2.3439  Validation loss = 1.9829  \n",
      "\n",
      "Fold: 7  Epoch: 342  Training loss = 2.3437  Validation loss = 1.9824  \n",
      "\n",
      "Fold: 7  Epoch: 343  Training loss = 2.3434  Validation loss = 1.9820  \n",
      "\n",
      "Fold: 7  Epoch: 344  Training loss = 2.3432  Validation loss = 1.9816  \n",
      "\n",
      "Fold: 7  Epoch: 345  Training loss = 2.3429  Validation loss = 1.9812  \n",
      "\n",
      "Fold: 7  Epoch: 346  Training loss = 2.3427  Validation loss = 1.9808  \n",
      "\n",
      "Fold: 7  Epoch: 347  Training loss = 2.3425  Validation loss = 1.9804  \n",
      "\n",
      "Fold: 7  Epoch: 348  Training loss = 2.3422  Validation loss = 1.9800  \n",
      "\n",
      "Fold: 7  Epoch: 349  Training loss = 2.3420  Validation loss = 1.9796  \n",
      "\n",
      "Fold: 7  Epoch: 350  Training loss = 2.3419  Validation loss = 1.9793  \n",
      "\n",
      "Fold: 7  Epoch: 351  Training loss = 2.3416  Validation loss = 1.9790  \n",
      "\n",
      "Fold: 7  Epoch: 352  Training loss = 2.3414  Validation loss = 1.9786  \n",
      "\n",
      "Fold: 7  Epoch: 353  Training loss = 2.3412  Validation loss = 1.9782  \n",
      "\n",
      "Fold: 7  Epoch: 354  Training loss = 2.3409  Validation loss = 1.9778  \n",
      "\n",
      "Fold: 7  Epoch: 355  Training loss = 2.3408  Validation loss = 1.9775  \n",
      "\n",
      "Fold: 7  Epoch: 356  Training loss = 2.3405  Validation loss = 1.9771  \n",
      "\n",
      "Fold: 7  Epoch: 357  Training loss = 2.3402  Validation loss = 1.9765  \n",
      "\n",
      "Fold: 7  Epoch: 358  Training loss = 2.3400  Validation loss = 1.9762  \n",
      "\n",
      "Fold: 7  Epoch: 359  Training loss = 2.3397  Validation loss = 1.9757  \n",
      "\n",
      "Fold: 7  Epoch: 360  Training loss = 2.3395  Validation loss = 1.9753  \n",
      "\n",
      "Fold: 7  Epoch: 361  Training loss = 2.3392  Validation loss = 1.9748  \n",
      "\n",
      "Fold: 7  Epoch: 362  Training loss = 2.3389  Validation loss = 1.9744  \n",
      "\n",
      "Fold: 7  Epoch: 363  Training loss = 2.3388  Validation loss = 1.9741  \n",
      "\n",
      "Fold: 7  Epoch: 364  Training loss = 2.3386  Validation loss = 1.9738  \n",
      "\n",
      "Fold: 7  Epoch: 365  Training loss = 2.3383  Validation loss = 1.9733  \n",
      "\n",
      "Fold: 7  Epoch: 366  Training loss = 2.3381  Validation loss = 1.9729  \n",
      "\n",
      "Fold: 7  Epoch: 367  Training loss = 2.3378  Validation loss = 1.9725  \n",
      "\n",
      "Fold: 7  Epoch: 368  Training loss = 2.3376  Validation loss = 1.9720  \n",
      "\n",
      "Fold: 7  Epoch: 369  Training loss = 2.3374  Validation loss = 1.9718  \n",
      "\n",
      "Fold: 7  Epoch: 370  Training loss = 2.3371  Validation loss = 1.9712  \n",
      "\n",
      "Fold: 7  Epoch: 371  Training loss = 2.3369  Validation loss = 1.9708  \n",
      "\n",
      "Fold: 7  Epoch: 372  Training loss = 2.3367  Validation loss = 1.9705  \n",
      "\n",
      "Fold: 7  Epoch: 373  Training loss = 2.3365  Validation loss = 1.9701  \n",
      "\n",
      "Fold: 7  Epoch: 374  Training loss = 2.3362  Validation loss = 1.9697  \n",
      "\n",
      "Fold: 7  Epoch: 375  Training loss = 2.3360  Validation loss = 1.9694  \n",
      "\n",
      "Fold: 7  Epoch: 376  Training loss = 2.3357  Validation loss = 1.9689  \n",
      "\n",
      "Fold: 7  Epoch: 377  Training loss = 2.3355  Validation loss = 1.9684  \n",
      "\n",
      "Fold: 7  Epoch: 378  Training loss = 2.3353  Validation loss = 1.9681  \n",
      "\n",
      "Fold: 7  Epoch: 379  Training loss = 2.3351  Validation loss = 1.9677  \n",
      "\n",
      "Fold: 7  Epoch: 380  Training loss = 2.3348  Validation loss = 1.9673  \n",
      "\n",
      "Fold: 7  Epoch: 381  Training loss = 2.3346  Validation loss = 1.9669  \n",
      "\n",
      "Fold: 7  Epoch: 382  Training loss = 2.3343  Validation loss = 1.9663  \n",
      "\n",
      "Fold: 7  Epoch: 383  Training loss = 2.3340  Validation loss = 1.9659  \n",
      "\n",
      "Fold: 7  Epoch: 384  Training loss = 2.3338  Validation loss = 1.9656  \n",
      "\n",
      "Fold: 7  Epoch: 385  Training loss = 2.3336  Validation loss = 1.9652  \n",
      "\n",
      "Fold: 7  Epoch: 386  Training loss = 2.3333  Validation loss = 1.9647  \n",
      "\n",
      "Fold: 7  Epoch: 387  Training loss = 2.3331  Validation loss = 1.9643  \n",
      "\n",
      "Fold: 7  Epoch: 388  Training loss = 2.3329  Validation loss = 1.9639  \n",
      "\n",
      "Fold: 7  Epoch: 389  Training loss = 2.3327  Validation loss = 1.9636  \n",
      "\n",
      "Fold: 7  Epoch: 390  Training loss = 2.3324  Validation loss = 1.9632  \n",
      "\n",
      "Fold: 7  Epoch: 391  Training loss = 2.3322  Validation loss = 1.9629  \n",
      "\n",
      "Fold: 7  Epoch: 392  Training loss = 2.3321  Validation loss = 1.9626  \n",
      "\n",
      "Fold: 7  Epoch: 393  Training loss = 2.3319  Validation loss = 1.9622  \n",
      "\n",
      "Fold: 7  Epoch: 394  Training loss = 2.3316  Validation loss = 1.9618  \n",
      "\n",
      "Fold: 7  Epoch: 395  Training loss = 2.3313  Validation loss = 1.9613  \n",
      "\n",
      "Fold: 7  Epoch: 396  Training loss = 2.3310  Validation loss = 1.9608  \n",
      "\n",
      "Fold: 7  Epoch: 397  Training loss = 2.3309  Validation loss = 1.9605  \n",
      "\n",
      "Fold: 7  Epoch: 398  Training loss = 2.3306  Validation loss = 1.9602  \n",
      "\n",
      "Fold: 7  Epoch: 399  Training loss = 2.3304  Validation loss = 1.9598  \n",
      "\n",
      "Fold: 7  Epoch: 400  Training loss = 2.3302  Validation loss = 1.9594  \n",
      "\n",
      "Fold: 7  Epoch: 401  Training loss = 2.3300  Validation loss = 1.9591  \n",
      "\n",
      "Fold: 7  Epoch: 402  Training loss = 2.3298  Validation loss = 1.9587  \n",
      "\n",
      "Fold: 7  Epoch: 403  Training loss = 2.3296  Validation loss = 1.9583  \n",
      "\n",
      "Fold: 7  Epoch: 404  Training loss = 2.3294  Validation loss = 1.9580  \n",
      "\n",
      "Fold: 7  Epoch: 405  Training loss = 2.3291  Validation loss = 1.9575  \n",
      "\n",
      "Fold: 7  Epoch: 406  Training loss = 2.3289  Validation loss = 1.9571  \n",
      "\n",
      "Fold: 7  Epoch: 407  Training loss = 2.3287  Validation loss = 1.9568  \n",
      "\n",
      "Fold: 7  Epoch: 408  Training loss = 2.3285  Validation loss = 1.9564  \n",
      "\n",
      "Fold: 7  Epoch: 409  Training loss = 2.3282  Validation loss = 1.9559  \n",
      "\n",
      "Fold: 7  Epoch: 410  Training loss = 2.3279  Validation loss = 1.9554  \n",
      "\n",
      "Fold: 7  Epoch: 411  Training loss = 2.3276  Validation loss = 1.9550  \n",
      "\n",
      "Fold: 7  Epoch: 412  Training loss = 2.3275  Validation loss = 1.9547  \n",
      "\n",
      "Fold: 7  Epoch: 413  Training loss = 2.3273  Validation loss = 1.9543  \n",
      "\n",
      "Fold: 7  Epoch: 414  Training loss = 2.3270  Validation loss = 1.9539  \n",
      "\n",
      "Fold: 7  Epoch: 415  Training loss = 2.3268  Validation loss = 1.9535  \n",
      "\n",
      "Fold: 7  Epoch: 416  Training loss = 2.3266  Validation loss = 1.9532  \n",
      "\n",
      "Fold: 7  Epoch: 417  Training loss = 2.3264  Validation loss = 1.9528  \n",
      "\n",
      "Fold: 7  Epoch: 418  Training loss = 2.3261  Validation loss = 1.9524  \n",
      "\n",
      "Fold: 7  Epoch: 419  Training loss = 2.3259  Validation loss = 1.9521  \n",
      "\n",
      "Fold: 7  Epoch: 420  Training loss = 2.3257  Validation loss = 1.9517  \n",
      "\n",
      "Fold: 7  Epoch: 421  Training loss = 2.3254  Validation loss = 1.9513  \n",
      "\n",
      "Fold: 7  Epoch: 422  Training loss = 2.3252  Validation loss = 1.9508  \n",
      "\n",
      "Fold: 7  Epoch: 423  Training loss = 2.3249  Validation loss = 1.9503  \n",
      "\n",
      "Fold: 7  Epoch: 424  Training loss = 2.3247  Validation loss = 1.9499  \n",
      "\n",
      "Fold: 7  Epoch: 425  Training loss = 2.3245  Validation loss = 1.9495  \n",
      "\n",
      "Fold: 7  Epoch: 426  Training loss = 2.3242  Validation loss = 1.9492  \n",
      "\n",
      "Fold: 7  Epoch: 427  Training loss = 2.3240  Validation loss = 1.9487  \n",
      "\n",
      "Fold: 7  Epoch: 428  Training loss = 2.3238  Validation loss = 1.9484  \n",
      "\n",
      "Fold: 7  Epoch: 429  Training loss = 2.3235  Validation loss = 1.9479  \n",
      "\n",
      "Fold: 7  Epoch: 430  Training loss = 2.3233  Validation loss = 1.9477  \n",
      "\n",
      "Fold: 7  Epoch: 431  Training loss = 2.3232  Validation loss = 1.9474  \n",
      "\n",
      "Fold: 7  Epoch: 432  Training loss = 2.3229  Validation loss = 1.9469  \n",
      "\n",
      "Fold: 7  Epoch: 433  Training loss = 2.3227  Validation loss = 1.9465  \n",
      "\n",
      "Fold: 7  Epoch: 434  Training loss = 2.3224  Validation loss = 1.9460  \n",
      "\n",
      "Fold: 7  Epoch: 435  Training loss = 2.3222  Validation loss = 1.9456  \n",
      "\n",
      "Fold: 7  Epoch: 436  Training loss = 2.3220  Validation loss = 1.9453  \n",
      "\n",
      "Fold: 7  Epoch: 437  Training loss = 2.3218  Validation loss = 1.9451  \n",
      "\n",
      "Fold: 7  Epoch: 438  Training loss = 2.3216  Validation loss = 1.9447  \n",
      "\n",
      "Fold: 7  Epoch: 439  Training loss = 2.3214  Validation loss = 1.9444  \n",
      "\n",
      "Fold: 7  Epoch: 440  Training loss = 2.3212  Validation loss = 1.9441  \n",
      "\n",
      "Fold: 7  Epoch: 441  Training loss = 2.3210  Validation loss = 1.9437  \n",
      "\n",
      "Fold: 7  Epoch: 442  Training loss = 2.3208  Validation loss = 1.9433  \n",
      "\n",
      "Fold: 7  Epoch: 443  Training loss = 2.3206  Validation loss = 1.9429  \n",
      "\n",
      "Fold: 7  Epoch: 444  Training loss = 2.3203  Validation loss = 1.9425  \n",
      "\n",
      "Fold: 7  Epoch: 445  Training loss = 2.3202  Validation loss = 1.9423  \n",
      "\n",
      "Fold: 7  Epoch: 446  Training loss = 2.3200  Validation loss = 1.9419  \n",
      "\n",
      "Fold: 7  Epoch: 447  Training loss = 2.3198  Validation loss = 1.9415  \n",
      "\n",
      "Fold: 7  Epoch: 448  Training loss = 2.3195  Validation loss = 1.9411  \n",
      "\n",
      "Fold: 7  Epoch: 449  Training loss = 2.3193  Validation loss = 1.9407  \n",
      "\n",
      "Fold: 7  Epoch: 450  Training loss = 2.3190  Validation loss = 1.9403  \n",
      "\n",
      "Fold: 7  Epoch: 451  Training loss = 2.3189  Validation loss = 1.9401  \n",
      "\n",
      "Fold: 7  Epoch: 452  Training loss = 2.3186  Validation loss = 1.9397  \n",
      "\n",
      "Fold: 7  Epoch: 453  Training loss = 2.3185  Validation loss = 1.9394  \n",
      "\n",
      "Fold: 7  Epoch: 454  Training loss = 2.3182  Validation loss = 1.9389  \n",
      "\n",
      "Fold: 7  Epoch: 455  Training loss = 2.3180  Validation loss = 1.9386  \n",
      "\n",
      "Fold: 7  Epoch: 456  Training loss = 2.3179  Validation loss = 1.9384  \n",
      "\n",
      "Fold: 7  Epoch: 457  Training loss = 2.3176  Validation loss = 1.9380  \n",
      "\n",
      "Fold: 7  Epoch: 458  Training loss = 2.3175  Validation loss = 1.9377  \n",
      "\n",
      "Fold: 7  Epoch: 459  Training loss = 2.3172  Validation loss = 1.9373  \n",
      "\n",
      "Fold: 7  Epoch: 460  Training loss = 2.3171  Validation loss = 1.9371  \n",
      "\n",
      "Fold: 7  Epoch: 461  Training loss = 2.3169  Validation loss = 1.9367  \n",
      "\n",
      "Fold: 7  Epoch: 462  Training loss = 2.3167  Validation loss = 1.9364  \n",
      "\n",
      "Fold: 7  Epoch: 463  Training loss = 2.3165  Validation loss = 1.9360  \n",
      "\n",
      "Fold: 7  Epoch: 464  Training loss = 2.3163  Validation loss = 1.9357  \n",
      "\n",
      "Fold: 7  Epoch: 465  Training loss = 2.3161  Validation loss = 1.9354  \n",
      "\n",
      "Fold: 7  Epoch: 466  Training loss = 2.3159  Validation loss = 1.9351  \n",
      "\n",
      "Fold: 7  Epoch: 467  Training loss = 2.3157  Validation loss = 1.9348  \n",
      "\n",
      "Fold: 7  Epoch: 468  Training loss = 2.3154  Validation loss = 1.9343  \n",
      "\n",
      "Fold: 7  Epoch: 469  Training loss = 2.3152  Validation loss = 1.9338  \n",
      "\n",
      "Fold: 7  Epoch: 470  Training loss = 2.3150  Validation loss = 1.9334  \n",
      "\n",
      "Fold: 7  Epoch: 471  Training loss = 2.3147  Validation loss = 1.9331  \n",
      "\n",
      "Fold: 7  Epoch: 472  Training loss = 2.3145  Validation loss = 1.9327  \n",
      "\n",
      "Fold: 7  Epoch: 473  Training loss = 2.3144  Validation loss = 1.9325  \n",
      "\n",
      "Fold: 7  Epoch: 474  Training loss = 2.3142  Validation loss = 1.9321  \n",
      "\n",
      "Fold: 7  Epoch: 475  Training loss = 2.3139  Validation loss = 1.9317  \n",
      "\n",
      "Fold: 7  Epoch: 476  Training loss = 2.3138  Validation loss = 1.9314  \n",
      "\n",
      "Fold: 7  Epoch: 477  Training loss = 2.3136  Validation loss = 1.9311  \n",
      "\n",
      "Fold: 7  Epoch: 478  Training loss = 2.3134  Validation loss = 1.9307  \n",
      "\n",
      "Fold: 7  Epoch: 479  Training loss = 2.3132  Validation loss = 1.9304  \n",
      "\n",
      "Fold: 7  Epoch: 480  Training loss = 2.3129  Validation loss = 1.9300  \n",
      "\n",
      "Fold: 7  Epoch: 481  Training loss = 2.3127  Validation loss = 1.9296  \n",
      "\n",
      "Fold: 7  Epoch: 482  Training loss = 2.3125  Validation loss = 1.9292  \n",
      "\n",
      "Fold: 7  Epoch: 483  Training loss = 2.3123  Validation loss = 1.9288  \n",
      "\n",
      "Fold: 7  Epoch: 484  Training loss = 2.3121  Validation loss = 1.9285  \n",
      "\n",
      "Fold: 7  Epoch: 485  Training loss = 2.3119  Validation loss = 1.9282  \n",
      "\n",
      "Fold: 7  Epoch: 486  Training loss = 2.3116  Validation loss = 1.9277  \n",
      "\n",
      "Fold: 7  Epoch: 487  Training loss = 2.3115  Validation loss = 1.9274  \n",
      "\n",
      "Fold: 7  Epoch: 488  Training loss = 2.3112  Validation loss = 1.9269  \n",
      "\n",
      "Fold: 7  Epoch: 489  Training loss = 2.3110  Validation loss = 1.9266  \n",
      "\n",
      "Fold: 7  Epoch: 490  Training loss = 2.3108  Validation loss = 1.9262  \n",
      "\n",
      "Fold: 7  Epoch: 491  Training loss = 2.3106  Validation loss = 1.9259  \n",
      "\n",
      "Fold: 7  Epoch: 492  Training loss = 2.3104  Validation loss = 1.9256  \n",
      "\n",
      "Fold: 7  Epoch: 493  Training loss = 2.3102  Validation loss = 1.9253  \n",
      "\n",
      "Fold: 7  Epoch: 494  Training loss = 2.3100  Validation loss = 1.9249  \n",
      "\n",
      "Fold: 7  Epoch: 495  Training loss = 2.3098  Validation loss = 1.9245  \n",
      "\n",
      "Fold: 7  Epoch: 496  Training loss = 2.3096  Validation loss = 1.9242  \n",
      "\n",
      "Fold: 7  Epoch: 497  Training loss = 2.3093  Validation loss = 1.9238  \n",
      "\n",
      "Fold: 7  Epoch: 498  Training loss = 2.3091  Validation loss = 1.9233  \n",
      "\n",
      "Fold: 7  Epoch: 499  Training loss = 2.3089  Validation loss = 1.9230  \n",
      "\n",
      "Fold: 7  Epoch: 500  Training loss = 2.3086  Validation loss = 1.9225  \n",
      "\n",
      "Check model:  Fold: 7  Epoch: 500  Training loss = 2.3086  Validation loss = 1.9225  \n",
      "\n",
      "Fold: 8  Epoch: 1  Training loss = 2.3056  Validation loss = 7.1380  \n",
      "\n",
      "Fold: 8  Epoch: 2  Training loss = 2.3054  Validation loss = 7.1377  \n",
      "\n",
      "Fold: 8  Epoch: 3  Training loss = 2.3051  Validation loss = 7.1372  \n",
      "\n",
      "Fold: 8  Epoch: 4  Training loss = 2.3049  Validation loss = 7.1369  \n",
      "\n",
      "Fold: 8  Epoch: 5  Training loss = 2.3046  Validation loss = 7.1364  \n",
      "\n",
      "Fold: 8  Epoch: 6  Training loss = 2.3044  Validation loss = 7.1361  \n",
      "\n",
      "Fold: 8  Epoch: 7  Training loss = 2.3042  Validation loss = 7.1358  \n",
      "\n",
      "Fold: 8  Epoch: 8  Training loss = 2.3039  Validation loss = 7.1352  \n",
      "\n",
      "Fold: 8  Epoch: 9  Training loss = 2.3037  Validation loss = 7.1350  \n",
      "\n",
      "Fold: 8  Epoch: 10  Training loss = 2.3035  Validation loss = 7.1346  \n",
      "\n",
      "Fold: 8  Epoch: 11  Training loss = 2.3032  Validation loss = 7.1342  \n",
      "\n",
      "Fold: 8  Epoch: 12  Training loss = 2.3030  Validation loss = 7.1338  \n",
      "\n",
      "Fold: 8  Epoch: 13  Training loss = 2.3027  Validation loss = 7.1333  \n",
      "\n",
      "Fold: 8  Epoch: 14  Training loss = 2.3024  Validation loss = 7.1329  \n",
      "\n",
      "Fold: 8  Epoch: 15  Training loss = 2.3022  Validation loss = 7.1325  \n",
      "\n",
      "Fold: 8  Epoch: 16  Training loss = 2.3020  Validation loss = 7.1321  \n",
      "\n",
      "Fold: 8  Epoch: 17  Training loss = 2.3017  Validation loss = 7.1317  \n",
      "\n",
      "Fold: 8  Epoch: 18  Training loss = 2.3015  Validation loss = 7.1313  \n",
      "\n",
      "Fold: 8  Epoch: 19  Training loss = 2.3013  Validation loss = 7.1310  \n",
      "\n",
      "Fold: 8  Epoch: 20  Training loss = 2.3010  Validation loss = 7.1306  \n",
      "\n",
      "Fold: 8  Epoch: 21  Training loss = 2.3009  Validation loss = 7.1304  \n",
      "\n",
      "Fold: 8  Epoch: 22  Training loss = 2.3006  Validation loss = 7.1299  \n",
      "\n",
      "Fold: 8  Epoch: 23  Training loss = 2.3003  Validation loss = 7.1295  \n",
      "\n",
      "Fold: 8  Epoch: 24  Training loss = 2.3000  Validation loss = 7.1290  \n",
      "\n",
      "Fold: 8  Epoch: 25  Training loss = 2.2998  Validation loss = 7.1287  \n",
      "\n",
      "Fold: 8  Epoch: 26  Training loss = 2.2996  Validation loss = 7.1284  \n",
      "\n",
      "Fold: 8  Epoch: 27  Training loss = 2.2994  Validation loss = 7.1280  \n",
      "\n",
      "Fold: 8  Epoch: 28  Training loss = 2.2991  Validation loss = 7.1275  \n",
      "\n",
      "Fold: 8  Epoch: 29  Training loss = 2.2988  Validation loss = 7.1271  \n",
      "\n",
      "Fold: 8  Epoch: 30  Training loss = 2.2985  Validation loss = 7.1266  \n",
      "\n",
      "Fold: 8  Epoch: 31  Training loss = 2.2983  Validation loss = 7.1262  \n",
      "\n",
      "Fold: 8  Epoch: 32  Training loss = 2.2981  Validation loss = 7.1259  \n",
      "\n",
      "Fold: 8  Epoch: 33  Training loss = 2.2978  Validation loss = 7.1254  \n",
      "\n",
      "Fold: 8  Epoch: 34  Training loss = 2.2975  Validation loss = 7.1250  \n",
      "\n",
      "Fold: 8  Epoch: 35  Training loss = 2.2973  Validation loss = 7.1246  \n",
      "\n",
      "Fold: 8  Epoch: 36  Training loss = 2.2970  Validation loss = 7.1243  \n",
      "\n",
      "Fold: 8  Epoch: 37  Training loss = 2.2967  Validation loss = 7.1238  \n",
      "\n",
      "Fold: 8  Epoch: 38  Training loss = 2.2965  Validation loss = 7.1234  \n",
      "\n",
      "Fold: 8  Epoch: 39  Training loss = 2.2962  Validation loss = 7.1229  \n",
      "\n",
      "Fold: 8  Epoch: 40  Training loss = 2.2959  Validation loss = 7.1225  \n",
      "\n",
      "Fold: 8  Epoch: 41  Training loss = 2.2956  Validation loss = 7.1220  \n",
      "\n",
      "Fold: 8  Epoch: 42  Training loss = 2.2954  Validation loss = 7.1216  \n",
      "\n",
      "Fold: 8  Epoch: 43  Training loss = 2.2951  Validation loss = 7.1212  \n",
      "\n",
      "Fold: 8  Epoch: 44  Training loss = 2.2949  Validation loss = 7.1208  \n",
      "\n",
      "Fold: 8  Epoch: 45  Training loss = 2.2947  Validation loss = 7.1205  \n",
      "\n",
      "Fold: 8  Epoch: 46  Training loss = 2.2944  Validation loss = 7.1200  \n",
      "\n",
      "Fold: 8  Epoch: 47  Training loss = 2.2941  Validation loss = 7.1195  \n",
      "\n",
      "Fold: 8  Epoch: 48  Training loss = 2.2938  Validation loss = 7.1191  \n",
      "\n",
      "Fold: 8  Epoch: 49  Training loss = 2.2936  Validation loss = 7.1187  \n",
      "\n",
      "Fold: 8  Epoch: 50  Training loss = 2.2934  Validation loss = 7.1183  \n",
      "\n",
      "Fold: 8  Epoch: 51  Training loss = 2.2931  Validation loss = 7.1180  \n",
      "\n",
      "Fold: 8  Epoch: 52  Training loss = 2.2928  Validation loss = 7.1175  \n",
      "\n",
      "Fold: 8  Epoch: 53  Training loss = 2.2926  Validation loss = 7.1171  \n",
      "\n",
      "Fold: 8  Epoch: 54  Training loss = 2.2923  Validation loss = 7.1167  \n",
      "\n",
      "Fold: 8  Epoch: 55  Training loss = 2.2920  Validation loss = 7.1162  \n",
      "\n",
      "Fold: 8  Epoch: 56  Training loss = 2.2918  Validation loss = 7.1158  \n",
      "\n",
      "Fold: 8  Epoch: 57  Training loss = 2.2915  Validation loss = 7.1154  \n",
      "\n",
      "Fold: 8  Epoch: 58  Training loss = 2.2913  Validation loss = 7.1150  \n",
      "\n",
      "Fold: 8  Epoch: 59  Training loss = 2.2911  Validation loss = 7.1146  \n",
      "\n",
      "Fold: 8  Epoch: 60  Training loss = 2.2908  Validation loss = 7.1143  \n",
      "\n",
      "Fold: 8  Epoch: 61  Training loss = 2.2906  Validation loss = 7.1139  \n",
      "\n",
      "Fold: 8  Epoch: 62  Training loss = 2.2904  Validation loss = 7.1136  \n",
      "\n",
      "Fold: 8  Epoch: 63  Training loss = 2.2901  Validation loss = 7.1131  \n",
      "\n",
      "Fold: 8  Epoch: 64  Training loss = 2.2899  Validation loss = 7.1127  \n",
      "\n",
      "Fold: 8  Epoch: 65  Training loss = 2.2896  Validation loss = 7.1123  \n",
      "\n",
      "Fold: 8  Epoch: 66  Training loss = 2.2894  Validation loss = 7.1119  \n",
      "\n",
      "Fold: 8  Epoch: 67  Training loss = 2.2891  Validation loss = 7.1115  \n",
      "\n",
      "Fold: 8  Epoch: 68  Training loss = 2.2889  Validation loss = 7.1111  \n",
      "\n",
      "Fold: 8  Epoch: 69  Training loss = 2.2887  Validation loss = 7.1107  \n",
      "\n",
      "Fold: 8  Epoch: 70  Training loss = 2.2884  Validation loss = 7.1103  \n",
      "\n",
      "Fold: 8  Epoch: 71  Training loss = 2.2881  Validation loss = 7.1099  \n",
      "\n",
      "Fold: 8  Epoch: 72  Training loss = 2.2879  Validation loss = 7.1095  \n",
      "\n",
      "Fold: 8  Epoch: 73  Training loss = 2.2877  Validation loss = 7.1092  \n",
      "\n",
      "Fold: 8  Epoch: 74  Training loss = 2.2874  Validation loss = 7.1087  \n",
      "\n",
      "Fold: 8  Epoch: 75  Training loss = 2.2872  Validation loss = 7.1083  \n",
      "\n",
      "Fold: 8  Epoch: 76  Training loss = 2.2869  Validation loss = 7.1079  \n",
      "\n",
      "Fold: 8  Epoch: 77  Training loss = 2.2867  Validation loss = 7.1076  \n",
      "\n",
      "Fold: 8  Epoch: 78  Training loss = 2.2865  Validation loss = 7.1073  \n",
      "\n",
      "Fold: 8  Epoch: 79  Training loss = 2.2863  Validation loss = 7.1069  \n",
      "\n",
      "Fold: 8  Epoch: 80  Training loss = 2.2860  Validation loss = 7.1065  \n",
      "\n",
      "Fold: 8  Epoch: 81  Training loss = 2.2858  Validation loss = 7.1061  \n",
      "\n",
      "Fold: 8  Epoch: 82  Training loss = 2.2855  Validation loss = 7.1057  \n",
      "\n",
      "Fold: 8  Epoch: 83  Training loss = 2.2853  Validation loss = 7.1053  \n",
      "\n",
      "Fold: 8  Epoch: 84  Training loss = 2.2850  Validation loss = 7.1049  \n",
      "\n",
      "Fold: 8  Epoch: 85  Training loss = 2.2848  Validation loss = 7.1046  \n",
      "\n",
      "Fold: 8  Epoch: 86  Training loss = 2.2846  Validation loss = 7.1042  \n",
      "\n",
      "Fold: 8  Epoch: 87  Training loss = 2.2843  Validation loss = 7.1038  \n",
      "\n",
      "Fold: 8  Epoch: 88  Training loss = 2.2841  Validation loss = 7.1034  \n",
      "\n",
      "Fold: 8  Epoch: 89  Training loss = 2.2839  Validation loss = 7.1032  \n",
      "\n",
      "Fold: 8  Epoch: 90  Training loss = 2.2837  Validation loss = 7.1028  \n",
      "\n",
      "Fold: 8  Epoch: 91  Training loss = 2.2835  Validation loss = 7.1024  \n",
      "\n",
      "Fold: 8  Epoch: 92  Training loss = 2.2833  Validation loss = 7.1021  \n",
      "\n",
      "Fold: 8  Epoch: 93  Training loss = 2.2830  Validation loss = 7.1017  \n",
      "\n",
      "Fold: 8  Epoch: 94  Training loss = 2.2828  Validation loss = 7.1013  \n",
      "\n",
      "Fold: 8  Epoch: 95  Training loss = 2.2826  Validation loss = 7.1010  \n",
      "\n",
      "Fold: 8  Epoch: 96  Training loss = 2.2823  Validation loss = 7.1006  \n",
      "\n",
      "Fold: 8  Epoch: 97  Training loss = 2.2821  Validation loss = 7.1002  \n",
      "\n",
      "Fold: 8  Epoch: 98  Training loss = 2.2819  Validation loss = 7.0999  \n",
      "\n",
      "Fold: 8  Epoch: 99  Training loss = 2.2817  Validation loss = 7.0995  \n",
      "\n",
      "Fold: 8  Epoch: 100  Training loss = 2.2814  Validation loss = 7.0990  \n",
      "\n",
      "Fold: 8  Epoch: 101  Training loss = 2.2811  Validation loss = 7.0986  \n",
      "\n",
      "Fold: 8  Epoch: 102  Training loss = 2.2809  Validation loss = 7.0982  \n",
      "\n",
      "Fold: 8  Epoch: 103  Training loss = 2.2806  Validation loss = 7.0978  \n",
      "\n",
      "Fold: 8  Epoch: 104  Training loss = 2.2803  Validation loss = 7.0973  \n",
      "\n",
      "Fold: 8  Epoch: 105  Training loss = 2.2801  Validation loss = 7.0970  \n",
      "\n",
      "Fold: 8  Epoch: 106  Training loss = 2.2799  Validation loss = 7.0967  \n",
      "\n",
      "Fold: 8  Epoch: 107  Training loss = 2.2797  Validation loss = 7.0963  \n",
      "\n",
      "Fold: 8  Epoch: 108  Training loss = 2.2794  Validation loss = 7.0959  \n",
      "\n",
      "Fold: 8  Epoch: 109  Training loss = 2.2791  Validation loss = 7.0955  \n",
      "\n",
      "Fold: 8  Epoch: 110  Training loss = 2.2789  Validation loss = 7.0951  \n",
      "\n",
      "Fold: 8  Epoch: 111  Training loss = 2.2787  Validation loss = 7.0948  \n",
      "\n",
      "Fold: 8  Epoch: 112  Training loss = 2.2785  Validation loss = 7.0944  \n",
      "\n",
      "Fold: 8  Epoch: 113  Training loss = 2.2783  Validation loss = 7.0941  \n",
      "\n",
      "Fold: 8  Epoch: 114  Training loss = 2.2780  Validation loss = 7.0936  \n",
      "\n",
      "Fold: 8  Epoch: 115  Training loss = 2.2777  Validation loss = 7.0932  \n",
      "\n",
      "Fold: 8  Epoch: 116  Training loss = 2.2775  Validation loss = 7.0928  \n",
      "\n",
      "Fold: 8  Epoch: 117  Training loss = 2.2773  Validation loss = 7.0925  \n",
      "\n",
      "Fold: 8  Epoch: 118  Training loss = 2.2771  Validation loss = 7.0921  \n",
      "\n",
      "Fold: 8  Epoch: 119  Training loss = 2.2768  Validation loss = 7.0916  \n",
      "\n",
      "Fold: 8  Epoch: 120  Training loss = 2.2766  Validation loss = 7.0913  \n",
      "\n",
      "Fold: 8  Epoch: 121  Training loss = 2.2763  Validation loss = 7.0909  \n",
      "\n",
      "Fold: 8  Epoch: 122  Training loss = 2.2761  Validation loss = 7.0905  \n",
      "\n",
      "Fold: 8  Epoch: 123  Training loss = 2.2758  Validation loss = 7.0901  \n",
      "\n",
      "Fold: 8  Epoch: 124  Training loss = 2.2756  Validation loss = 7.0897  \n",
      "\n",
      "Fold: 8  Epoch: 125  Training loss = 2.2754  Validation loss = 7.0893  \n",
      "\n",
      "Fold: 8  Epoch: 126  Training loss = 2.2752  Validation loss = 7.0890  \n",
      "\n",
      "Fold: 8  Epoch: 127  Training loss = 2.2749  Validation loss = 7.0886  \n",
      "\n",
      "Fold: 8  Epoch: 128  Training loss = 2.2747  Validation loss = 7.0882  \n",
      "\n",
      "Fold: 8  Epoch: 129  Training loss = 2.2744  Validation loss = 7.0878  \n",
      "\n",
      "Fold: 8  Epoch: 130  Training loss = 2.2742  Validation loss = 7.0874  \n",
      "\n",
      "Fold: 8  Epoch: 131  Training loss = 2.2740  Validation loss = 7.0871  \n",
      "\n",
      "Fold: 8  Epoch: 132  Training loss = 2.2737  Validation loss = 7.0866  \n",
      "\n",
      "Fold: 8  Epoch: 133  Training loss = 2.2735  Validation loss = 7.0863  \n",
      "\n",
      "Fold: 8  Epoch: 134  Training loss = 2.2733  Validation loss = 7.0860  \n",
      "\n",
      "Fold: 8  Epoch: 135  Training loss = 2.2731  Validation loss = 7.0856  \n",
      "\n",
      "Fold: 8  Epoch: 136  Training loss = 2.2729  Validation loss = 7.0853  \n",
      "\n",
      "Fold: 8  Epoch: 137  Training loss = 2.2726  Validation loss = 7.0848  \n",
      "\n",
      "Fold: 8  Epoch: 138  Training loss = 2.2723  Validation loss = 7.0844  \n",
      "\n",
      "Fold: 8  Epoch: 139  Training loss = 2.2721  Validation loss = 7.0840  \n",
      "\n",
      "Fold: 8  Epoch: 140  Training loss = 2.2719  Validation loss = 7.0837  \n",
      "\n",
      "Fold: 8  Epoch: 141  Training loss = 2.2717  Validation loss = 7.0833  \n",
      "\n",
      "Fold: 8  Epoch: 142  Training loss = 2.2714  Validation loss = 7.0830  \n",
      "\n",
      "Fold: 8  Epoch: 143  Training loss = 2.2712  Validation loss = 7.0826  \n",
      "\n",
      "Fold: 8  Epoch: 144  Training loss = 2.2710  Validation loss = 7.0822  \n",
      "\n",
      "Fold: 8  Epoch: 145  Training loss = 2.2708  Validation loss = 7.0819  \n",
      "\n",
      "Fold: 8  Epoch: 146  Training loss = 2.2706  Validation loss = 7.0815  \n",
      "\n",
      "Fold: 8  Epoch: 147  Training loss = 2.2704  Validation loss = 7.0812  \n",
      "\n",
      "Fold: 8  Epoch: 148  Training loss = 2.2701  Validation loss = 7.0809  \n",
      "\n",
      "Fold: 8  Epoch: 149  Training loss = 2.2698  Validation loss = 7.0804  \n",
      "\n",
      "Fold: 8  Epoch: 150  Training loss = 2.2696  Validation loss = 7.0800  \n",
      "\n",
      "Fold: 8  Epoch: 151  Training loss = 2.2693  Validation loss = 7.0796  \n",
      "\n",
      "Fold: 8  Epoch: 152  Training loss = 2.2691  Validation loss = 7.0792  \n",
      "\n",
      "Fold: 8  Epoch: 153  Training loss = 2.2688  Validation loss = 7.0787  \n",
      "\n",
      "Fold: 8  Epoch: 154  Training loss = 2.2686  Validation loss = 7.0784  \n",
      "\n",
      "Fold: 8  Epoch: 155  Training loss = 2.2683  Validation loss = 7.0779  \n",
      "\n",
      "Fold: 8  Epoch: 156  Training loss = 2.2681  Validation loss = 7.0776  \n",
      "\n",
      "Fold: 8  Epoch: 157  Training loss = 2.2679  Validation loss = 7.0773  \n",
      "\n",
      "Fold: 8  Epoch: 158  Training loss = 2.2677  Validation loss = 7.0768  \n",
      "\n",
      "Fold: 8  Epoch: 159  Training loss = 2.2675  Validation loss = 7.0765  \n",
      "\n",
      "Fold: 8  Epoch: 160  Training loss = 2.2672  Validation loss = 7.0762  \n",
      "\n",
      "Fold: 8  Epoch: 161  Training loss = 2.2670  Validation loss = 7.0758  \n",
      "\n",
      "Fold: 8  Epoch: 162  Training loss = 2.2667  Validation loss = 7.0754  \n",
      "\n",
      "Fold: 8  Epoch: 163  Training loss = 2.2665  Validation loss = 7.0750  \n",
      "\n",
      "Fold: 8  Epoch: 164  Training loss = 2.2662  Validation loss = 7.0745  \n",
      "\n",
      "Fold: 8  Epoch: 165  Training loss = 2.2660  Validation loss = 7.0742  \n",
      "\n",
      "Fold: 8  Epoch: 166  Training loss = 2.2658  Validation loss = 7.0738  \n",
      "\n",
      "Fold: 8  Epoch: 167  Training loss = 2.2656  Validation loss = 7.0735  \n",
      "\n",
      "Fold: 8  Epoch: 168  Training loss = 2.2654  Validation loss = 7.0732  \n",
      "\n",
      "Fold: 8  Epoch: 169  Training loss = 2.2652  Validation loss = 7.0728  \n",
      "\n",
      "Fold: 8  Epoch: 170  Training loss = 2.2650  Validation loss = 7.0725  \n",
      "\n",
      "Fold: 8  Epoch: 171  Training loss = 2.2647  Validation loss = 7.0721  \n",
      "\n",
      "Fold: 8  Epoch: 172  Training loss = 2.2645  Validation loss = 7.0717  \n",
      "\n",
      "Fold: 8  Epoch: 173  Training loss = 2.2643  Validation loss = 7.0714  \n",
      "\n",
      "Fold: 8  Epoch: 174  Training loss = 2.2641  Validation loss = 7.0710  \n",
      "\n",
      "Fold: 8  Epoch: 175  Training loss = 2.2638  Validation loss = 7.0707  \n",
      "\n",
      "Fold: 8  Epoch: 176  Training loss = 2.2636  Validation loss = 7.0703  \n",
      "\n",
      "Fold: 8  Epoch: 177  Training loss = 2.2634  Validation loss = 7.0700  \n",
      "\n",
      "Fold: 8  Epoch: 178  Training loss = 2.2632  Validation loss = 7.0696  \n",
      "\n",
      "Fold: 8  Epoch: 179  Training loss = 2.2630  Validation loss = 7.0693  \n",
      "\n",
      "Fold: 8  Epoch: 180  Training loss = 2.2627  Validation loss = 7.0688  \n",
      "\n",
      "Fold: 8  Epoch: 181  Training loss = 2.2625  Validation loss = 7.0685  \n",
      "\n",
      "Fold: 8  Epoch: 182  Training loss = 2.2622  Validation loss = 7.0681  \n",
      "\n",
      "Fold: 8  Epoch: 183  Training loss = 2.2620  Validation loss = 7.0676  \n",
      "\n",
      "Fold: 8  Epoch: 184  Training loss = 2.2617  Validation loss = 7.0672  \n",
      "\n",
      "Fold: 8  Epoch: 185  Training loss = 2.2615  Validation loss = 7.0668  \n",
      "\n",
      "Fold: 8  Epoch: 186  Training loss = 2.2612  Validation loss = 7.0664  \n",
      "\n",
      "Fold: 8  Epoch: 187  Training loss = 2.2610  Validation loss = 7.0661  \n",
      "\n",
      "Fold: 8  Epoch: 188  Training loss = 2.2608  Validation loss = 7.0658  \n",
      "\n",
      "Fold: 8  Epoch: 189  Training loss = 2.2606  Validation loss = 7.0654  \n",
      "\n",
      "Fold: 8  Epoch: 190  Training loss = 2.2603  Validation loss = 7.0650  \n",
      "\n",
      "Fold: 8  Epoch: 191  Training loss = 2.2601  Validation loss = 7.0646  \n",
      "\n",
      "Fold: 8  Epoch: 192  Training loss = 2.2599  Validation loss = 7.0643  \n",
      "\n",
      "Fold: 8  Epoch: 193  Training loss = 2.2597  Validation loss = 7.0640  \n",
      "\n",
      "Fold: 8  Epoch: 194  Training loss = 2.2595  Validation loss = 7.0637  \n",
      "\n",
      "Fold: 8  Epoch: 195  Training loss = 2.2593  Validation loss = 7.0633  \n",
      "\n",
      "Fold: 8  Epoch: 196  Training loss = 2.2591  Validation loss = 7.0629  \n",
      "\n",
      "Fold: 8  Epoch: 197  Training loss = 2.2588  Validation loss = 7.0625  \n",
      "\n",
      "Fold: 8  Epoch: 198  Training loss = 2.2586  Validation loss = 7.0622  \n",
      "\n",
      "Fold: 8  Epoch: 199  Training loss = 2.2585  Validation loss = 7.0619  \n",
      "\n",
      "Fold: 8  Epoch: 200  Training loss = 2.2582  Validation loss = 7.0615  \n",
      "\n",
      "Fold: 8  Epoch: 201  Training loss = 2.2581  Validation loss = 7.0613  \n",
      "\n",
      "Fold: 8  Epoch: 202  Training loss = 2.2578  Validation loss = 7.0609  \n",
      "\n",
      "Fold: 8  Epoch: 203  Training loss = 2.2575  Validation loss = 7.0604  \n",
      "\n",
      "Fold: 8  Epoch: 204  Training loss = 2.2574  Validation loss = 7.0602  \n",
      "\n",
      "Fold: 8  Epoch: 205  Training loss = 2.2571  Validation loss = 7.0597  \n",
      "\n",
      "Fold: 8  Epoch: 206  Training loss = 2.2568  Validation loss = 7.0593  \n",
      "\n",
      "Fold: 8  Epoch: 207  Training loss = 2.2567  Validation loss = 7.0590  \n",
      "\n",
      "Fold: 8  Epoch: 208  Training loss = 2.2565  Validation loss = 7.0587  \n",
      "\n",
      "Fold: 8  Epoch: 209  Training loss = 2.2563  Validation loss = 7.0584  \n",
      "\n",
      "Fold: 8  Epoch: 210  Training loss = 2.2561  Validation loss = 7.0580  \n",
      "\n",
      "Fold: 8  Epoch: 211  Training loss = 2.2558  Validation loss = 7.0577  \n",
      "\n",
      "Fold: 8  Epoch: 212  Training loss = 2.2556  Validation loss = 7.0573  \n",
      "\n",
      "Fold: 8  Epoch: 213  Training loss = 2.2554  Validation loss = 7.0569  \n",
      "\n",
      "Fold: 8  Epoch: 214  Training loss = 2.2552  Validation loss = 7.0566  \n",
      "\n",
      "Fold: 8  Epoch: 215  Training loss = 2.2551  Validation loss = 7.0563  \n",
      "\n",
      "Fold: 8  Epoch: 216  Training loss = 2.2549  Validation loss = 7.0560  \n",
      "\n",
      "Fold: 8  Epoch: 217  Training loss = 2.2546  Validation loss = 7.0556  \n",
      "\n",
      "Fold: 8  Epoch: 218  Training loss = 2.2543  Validation loss = 7.0552  \n",
      "\n",
      "Fold: 8  Epoch: 219  Training loss = 2.2541  Validation loss = 7.0548  \n",
      "\n",
      "Fold: 8  Epoch: 220  Training loss = 2.2539  Validation loss = 7.0545  \n",
      "\n",
      "Fold: 8  Epoch: 221  Training loss = 2.2537  Validation loss = 7.0541  \n",
      "\n",
      "Fold: 8  Epoch: 222  Training loss = 2.2534  Validation loss = 7.0537  \n",
      "\n",
      "Fold: 8  Epoch: 223  Training loss = 2.2532  Validation loss = 7.0534  \n",
      "\n",
      "Fold: 8  Epoch: 224  Training loss = 2.2530  Validation loss = 7.0530  \n",
      "\n",
      "Fold: 8  Epoch: 225  Training loss = 2.2528  Validation loss = 7.0526  \n",
      "\n",
      "Fold: 8  Epoch: 226  Training loss = 2.2526  Validation loss = 7.0524  \n",
      "\n",
      "Fold: 8  Epoch: 227  Training loss = 2.2524  Validation loss = 7.0520  \n",
      "\n",
      "Fold: 8  Epoch: 228  Training loss = 2.2522  Validation loss = 7.0517  \n",
      "\n",
      "Fold: 8  Epoch: 229  Training loss = 2.2520  Validation loss = 7.0513  \n",
      "\n",
      "Fold: 8  Epoch: 230  Training loss = 2.2518  Validation loss = 7.0509  \n",
      "\n",
      "Fold: 8  Epoch: 231  Training loss = 2.2516  Validation loss = 7.0506  \n",
      "\n",
      "Fold: 8  Epoch: 232  Training loss = 2.2514  Validation loss = 7.0503  \n",
      "\n",
      "Fold: 8  Epoch: 233  Training loss = 2.2512  Validation loss = 7.0500  \n",
      "\n",
      "Fold: 8  Epoch: 234  Training loss = 2.2510  Validation loss = 7.0496  \n",
      "\n",
      "Fold: 8  Epoch: 235  Training loss = 2.2507  Validation loss = 7.0492  \n",
      "\n",
      "Fold: 8  Epoch: 236  Training loss = 2.2505  Validation loss = 7.0489  \n",
      "\n",
      "Fold: 8  Epoch: 237  Training loss = 2.2503  Validation loss = 7.0485  \n",
      "\n",
      "Fold: 8  Epoch: 238  Training loss = 2.2501  Validation loss = 7.0482  \n",
      "\n",
      "Fold: 8  Epoch: 239  Training loss = 2.2499  Validation loss = 7.0478  \n",
      "\n",
      "Fold: 8  Epoch: 240  Training loss = 2.2497  Validation loss = 7.0475  \n",
      "\n",
      "Fold: 8  Epoch: 241  Training loss = 2.2494  Validation loss = 7.0471  \n",
      "\n",
      "Fold: 8  Epoch: 242  Training loss = 2.2492  Validation loss = 7.0467  \n",
      "\n",
      "Fold: 8  Epoch: 243  Training loss = 2.2490  Validation loss = 7.0464  \n",
      "\n",
      "Fold: 8  Epoch: 244  Training loss = 2.2488  Validation loss = 7.0461  \n",
      "\n",
      "Fold: 8  Epoch: 245  Training loss = 2.2486  Validation loss = 7.0457  \n",
      "\n",
      "Fold: 8  Epoch: 246  Training loss = 2.2484  Validation loss = 7.0453  \n",
      "\n",
      "Fold: 8  Epoch: 247  Training loss = 2.2481  Validation loss = 7.0449  \n",
      "\n",
      "Fold: 8  Epoch: 248  Training loss = 2.2479  Validation loss = 7.0445  \n",
      "\n",
      "Fold: 8  Epoch: 249  Training loss = 2.2476  Validation loss = 7.0441  \n",
      "\n",
      "Fold: 8  Epoch: 250  Training loss = 2.2475  Validation loss = 7.0439  \n",
      "\n",
      "Fold: 8  Epoch: 251  Training loss = 2.2473  Validation loss = 7.0435  \n",
      "\n",
      "Fold: 8  Epoch: 252  Training loss = 2.2470  Validation loss = 7.0431  \n",
      "\n",
      "Fold: 8  Epoch: 253  Training loss = 2.2467  Validation loss = 7.0426  \n",
      "\n",
      "Fold: 8  Epoch: 254  Training loss = 2.2465  Validation loss = 7.0423  \n",
      "\n",
      "Fold: 8  Epoch: 255  Training loss = 2.2463  Validation loss = 7.0419  \n",
      "\n",
      "Fold: 8  Epoch: 256  Training loss = 2.2461  Validation loss = 7.0416  \n",
      "\n",
      "Fold: 8  Epoch: 257  Training loss = 2.2459  Validation loss = 7.0413  \n",
      "\n",
      "Fold: 8  Epoch: 258  Training loss = 2.2458  Validation loss = 7.0410  \n",
      "\n",
      "Fold: 8  Epoch: 259  Training loss = 2.2456  Validation loss = 7.0407  \n",
      "\n",
      "Fold: 8  Epoch: 260  Training loss = 2.2453  Validation loss = 7.0403  \n",
      "\n",
      "Fold: 8  Epoch: 261  Training loss = 2.2451  Validation loss = 7.0399  \n",
      "\n",
      "Fold: 8  Epoch: 262  Training loss = 2.2449  Validation loss = 7.0396  \n",
      "\n",
      "Fold: 8  Epoch: 263  Training loss = 2.2447  Validation loss = 7.0392  \n",
      "\n",
      "Fold: 8  Epoch: 264  Training loss = 2.2444  Validation loss = 7.0388  \n",
      "\n",
      "Fold: 8  Epoch: 265  Training loss = 2.2442  Validation loss = 7.0385  \n",
      "\n",
      "Fold: 8  Epoch: 266  Training loss = 2.2440  Validation loss = 7.0381  \n",
      "\n",
      "Fold: 8  Epoch: 267  Training loss = 2.2438  Validation loss = 7.0377  \n",
      "\n",
      "Fold: 8  Epoch: 268  Training loss = 2.2435  Validation loss = 7.0373  \n",
      "\n",
      "Fold: 8  Epoch: 269  Training loss = 2.2433  Validation loss = 7.0370  \n",
      "\n",
      "Fold: 8  Epoch: 270  Training loss = 2.2431  Validation loss = 7.0366  \n",
      "\n",
      "Fold: 8  Epoch: 271  Training loss = 2.2428  Validation loss = 7.0362  \n",
      "\n",
      "Fold: 8  Epoch: 272  Training loss = 2.2427  Validation loss = 7.0360  \n",
      "\n",
      "Fold: 8  Epoch: 273  Training loss = 2.2424  Validation loss = 7.0356  \n",
      "\n",
      "Fold: 8  Epoch: 274  Training loss = 2.2422  Validation loss = 7.0352  \n",
      "\n",
      "Fold: 8  Epoch: 275  Training loss = 2.2420  Validation loss = 7.0348  \n",
      "\n",
      "Fold: 8  Epoch: 276  Training loss = 2.2418  Validation loss = 7.0346  \n",
      "\n",
      "Fold: 8  Epoch: 277  Training loss = 2.2415  Validation loss = 7.0341  \n",
      "\n",
      "Fold: 8  Epoch: 278  Training loss = 2.2413  Validation loss = 7.0338  \n",
      "\n",
      "Fold: 8  Epoch: 279  Training loss = 2.2411  Validation loss = 7.0334  \n",
      "\n",
      "Fold: 8  Epoch: 280  Training loss = 2.2409  Validation loss = 7.0330  \n",
      "\n",
      "Fold: 8  Epoch: 281  Training loss = 2.2407  Validation loss = 7.0327  \n",
      "\n",
      "Fold: 8  Epoch: 282  Training loss = 2.2404  Validation loss = 7.0323  \n",
      "\n",
      "Fold: 8  Epoch: 283  Training loss = 2.2402  Validation loss = 7.0319  \n",
      "\n",
      "Fold: 8  Epoch: 284  Training loss = 2.2399  Validation loss = 7.0315  \n",
      "\n",
      "Fold: 8  Epoch: 285  Training loss = 2.2397  Validation loss = 7.0312  \n",
      "\n",
      "Fold: 8  Epoch: 286  Training loss = 2.2395  Validation loss = 7.0308  \n",
      "\n",
      "Fold: 8  Epoch: 287  Training loss = 2.2393  Validation loss = 7.0304  \n",
      "\n",
      "Fold: 8  Epoch: 288  Training loss = 2.2391  Validation loss = 7.0301  \n",
      "\n",
      "Fold: 8  Epoch: 289  Training loss = 2.2389  Validation loss = 7.0298  \n",
      "\n",
      "Fold: 8  Epoch: 290  Training loss = 2.2387  Validation loss = 7.0294  \n",
      "\n",
      "Fold: 8  Epoch: 291  Training loss = 2.2384  Validation loss = 7.0290  \n",
      "\n",
      "Fold: 8  Epoch: 292  Training loss = 2.2382  Validation loss = 7.0286  \n",
      "\n",
      "Fold: 8  Epoch: 293  Training loss = 2.2380  Validation loss = 7.0283  \n",
      "\n",
      "Fold: 8  Epoch: 294  Training loss = 2.2378  Validation loss = 7.0279  \n",
      "\n",
      "Fold: 8  Epoch: 295  Training loss = 2.2376  Validation loss = 7.0276  \n",
      "\n",
      "Fold: 8  Epoch: 296  Training loss = 2.2374  Validation loss = 7.0273  \n",
      "\n",
      "Fold: 8  Epoch: 297  Training loss = 2.2372  Validation loss = 7.0269  \n",
      "\n",
      "Fold: 8  Epoch: 298  Training loss = 2.2369  Validation loss = 7.0265  \n",
      "\n",
      "Fold: 8  Epoch: 299  Training loss = 2.2367  Validation loss = 7.0261  \n",
      "\n",
      "Fold: 8  Epoch: 300  Training loss = 2.2365  Validation loss = 7.0257  \n",
      "\n",
      "Fold: 8  Epoch: 301  Training loss = 2.2363  Validation loss = 7.0254  \n",
      "\n",
      "Fold: 8  Epoch: 302  Training loss = 2.2361  Validation loss = 7.0251  \n",
      "\n",
      "Fold: 8  Epoch: 303  Training loss = 2.2358  Validation loss = 7.0247  \n",
      "\n",
      "Fold: 8  Epoch: 304  Training loss = 2.2356  Validation loss = 7.0243  \n",
      "\n",
      "Fold: 8  Epoch: 305  Training loss = 2.2354  Validation loss = 7.0240  \n",
      "\n",
      "Fold: 8  Epoch: 306  Training loss = 2.2353  Validation loss = 7.0237  \n",
      "\n",
      "Fold: 8  Epoch: 307  Training loss = 2.2350  Validation loss = 7.0233  \n",
      "\n",
      "Fold: 8  Epoch: 308  Training loss = 2.2348  Validation loss = 7.0230  \n",
      "\n",
      "Fold: 8  Epoch: 309  Training loss = 2.2346  Validation loss = 7.0226  \n",
      "\n",
      "Fold: 8  Epoch: 310  Training loss = 2.2343  Validation loss = 7.0222  \n",
      "\n",
      "Fold: 8  Epoch: 311  Training loss = 2.2341  Validation loss = 7.0218  \n",
      "\n",
      "Fold: 8  Epoch: 312  Training loss = 2.2339  Validation loss = 7.0215  \n",
      "\n",
      "Fold: 8  Epoch: 313  Training loss = 2.2337  Validation loss = 7.0211  \n",
      "\n",
      "Fold: 8  Epoch: 314  Training loss = 2.2335  Validation loss = 7.0207  \n",
      "\n",
      "Fold: 8  Epoch: 315  Training loss = 2.2333  Validation loss = 7.0204  \n",
      "\n",
      "Fold: 8  Epoch: 316  Training loss = 2.2330  Validation loss = 7.0200  \n",
      "\n",
      "Fold: 8  Epoch: 317  Training loss = 2.2328  Validation loss = 7.0197  \n",
      "\n",
      "Fold: 8  Epoch: 318  Training loss = 2.2326  Validation loss = 7.0193  \n",
      "\n",
      "Fold: 8  Epoch: 319  Training loss = 2.2324  Validation loss = 7.0190  \n",
      "\n",
      "Fold: 8  Epoch: 320  Training loss = 2.2322  Validation loss = 7.0186  \n",
      "\n",
      "Fold: 8  Epoch: 321  Training loss = 2.2320  Validation loss = 7.0183  \n",
      "\n",
      "Fold: 8  Epoch: 322  Training loss = 2.2318  Validation loss = 7.0179  \n",
      "\n",
      "Fold: 8  Epoch: 323  Training loss = 2.2316  Validation loss = 7.0176  \n",
      "\n",
      "Fold: 8  Epoch: 324  Training loss = 2.2313  Validation loss = 7.0171  \n",
      "\n",
      "Fold: 8  Epoch: 325  Training loss = 2.2311  Validation loss = 7.0168  \n",
      "\n",
      "Fold: 8  Epoch: 326  Training loss = 2.2308  Validation loss = 7.0164  \n",
      "\n",
      "Fold: 8  Epoch: 327  Training loss = 2.2306  Validation loss = 7.0160  \n",
      "\n",
      "Fold: 8  Epoch: 328  Training loss = 2.2304  Validation loss = 7.0157  \n",
      "\n",
      "Fold: 8  Epoch: 329  Training loss = 2.2302  Validation loss = 7.0153  \n",
      "\n",
      "Fold: 8  Epoch: 330  Training loss = 2.2300  Validation loss = 7.0150  \n",
      "\n",
      "Fold: 8  Epoch: 331  Training loss = 2.2298  Validation loss = 7.0146  \n",
      "\n",
      "Fold: 8  Epoch: 332  Training loss = 2.2296  Validation loss = 7.0143  \n",
      "\n",
      "Fold: 8  Epoch: 333  Training loss = 2.2294  Validation loss = 7.0140  \n",
      "\n",
      "Fold: 8  Epoch: 334  Training loss = 2.2292  Validation loss = 7.0136  \n",
      "\n",
      "Fold: 8  Epoch: 335  Training loss = 2.2289  Validation loss = 7.0132  \n",
      "\n",
      "Fold: 8  Epoch: 336  Training loss = 2.2287  Validation loss = 7.0129  \n",
      "\n",
      "Fold: 8  Epoch: 337  Training loss = 2.2285  Validation loss = 7.0125  \n",
      "\n",
      "Fold: 8  Epoch: 338  Training loss = 2.2283  Validation loss = 7.0121  \n",
      "\n",
      "Fold: 8  Epoch: 339  Training loss = 2.2280  Validation loss = 7.0117  \n",
      "\n",
      "Fold: 8  Epoch: 340  Training loss = 2.2278  Validation loss = 7.0113  \n",
      "\n",
      "Fold: 8  Epoch: 341  Training loss = 2.2276  Validation loss = 7.0110  \n",
      "\n",
      "Fold: 8  Epoch: 342  Training loss = 2.2274  Validation loss = 7.0107  \n",
      "\n",
      "Fold: 8  Epoch: 343  Training loss = 2.2272  Validation loss = 7.0103  \n",
      "\n",
      "Fold: 8  Epoch: 344  Training loss = 2.2270  Validation loss = 7.0100  \n",
      "\n",
      "Fold: 8  Epoch: 345  Training loss = 2.2268  Validation loss = 7.0096  \n",
      "\n",
      "Fold: 8  Epoch: 346  Training loss = 2.2266  Validation loss = 7.0093  \n",
      "\n",
      "Fold: 8  Epoch: 347  Training loss = 2.2263  Validation loss = 7.0089  \n",
      "\n",
      "Fold: 8  Epoch: 348  Training loss = 2.2261  Validation loss = 7.0086  \n",
      "\n",
      "Fold: 8  Epoch: 349  Training loss = 2.2259  Validation loss = 7.0082  \n",
      "\n",
      "Fold: 8  Epoch: 350  Training loss = 2.2257  Validation loss = 7.0079  \n",
      "\n",
      "Fold: 8  Epoch: 351  Training loss = 2.2255  Validation loss = 7.0075  \n",
      "\n",
      "Fold: 8  Epoch: 352  Training loss = 2.2253  Validation loss = 7.0071  \n",
      "\n",
      "Fold: 8  Epoch: 353  Training loss = 2.2250  Validation loss = 7.0067  \n",
      "\n",
      "Fold: 8  Epoch: 354  Training loss = 2.2248  Validation loss = 7.0064  \n",
      "\n",
      "Fold: 8  Epoch: 355  Training loss = 2.2245  Validation loss = 7.0059  \n",
      "\n",
      "Fold: 8  Epoch: 356  Training loss = 2.2243  Validation loss = 7.0055  \n",
      "\n",
      "Fold: 8  Epoch: 357  Training loss = 2.2240  Validation loss = 7.0051  \n",
      "\n",
      "Fold: 8  Epoch: 358  Training loss = 2.2239  Validation loss = 7.0048  \n",
      "\n",
      "Fold: 8  Epoch: 359  Training loss = 2.2237  Validation loss = 7.0044  \n",
      "\n",
      "Fold: 8  Epoch: 360  Training loss = 2.2234  Validation loss = 7.0041  \n",
      "\n",
      "Fold: 8  Epoch: 361  Training loss = 2.2233  Validation loss = 7.0037  \n",
      "\n",
      "Fold: 8  Epoch: 362  Training loss = 2.2231  Validation loss = 7.0034  \n",
      "\n",
      "Fold: 8  Epoch: 363  Training loss = 2.2229  Validation loss = 7.0031  \n",
      "\n",
      "Fold: 8  Epoch: 364  Training loss = 2.2227  Validation loss = 7.0027  \n",
      "\n",
      "Fold: 8  Epoch: 365  Training loss = 2.2225  Validation loss = 7.0025  \n",
      "\n",
      "Fold: 8  Epoch: 366  Training loss = 2.2223  Validation loss = 7.0021  \n",
      "\n",
      "Fold: 8  Epoch: 367  Training loss = 2.2221  Validation loss = 7.0017  \n",
      "\n",
      "Fold: 8  Epoch: 368  Training loss = 2.2219  Validation loss = 7.0014  \n",
      "\n",
      "Fold: 8  Epoch: 369  Training loss = 2.2217  Validation loss = 7.0011  \n",
      "\n",
      "Fold: 8  Epoch: 370  Training loss = 2.2214  Validation loss = 7.0007  \n",
      "\n",
      "Fold: 8  Epoch: 371  Training loss = 2.2212  Validation loss = 7.0003  \n",
      "\n",
      "Fold: 8  Epoch: 372  Training loss = 2.2210  Validation loss = 6.9999  \n",
      "\n",
      "Fold: 8  Epoch: 373  Training loss = 2.2207  Validation loss = 6.9995  \n",
      "\n",
      "Fold: 8  Epoch: 374  Training loss = 2.2205  Validation loss = 6.9992  \n",
      "\n",
      "Fold: 8  Epoch: 375  Training loss = 2.2203  Validation loss = 6.9989  \n",
      "\n",
      "Fold: 8  Epoch: 376  Training loss = 2.2201  Validation loss = 6.9984  \n",
      "\n",
      "Fold: 8  Epoch: 377  Training loss = 2.2199  Validation loss = 6.9981  \n",
      "\n",
      "Fold: 8  Epoch: 378  Training loss = 2.2196  Validation loss = 6.9977  \n",
      "\n",
      "Fold: 8  Epoch: 379  Training loss = 2.2195  Validation loss = 6.9974  \n",
      "\n",
      "Fold: 8  Epoch: 380  Training loss = 2.2192  Validation loss = 6.9970  \n",
      "\n",
      "Fold: 8  Epoch: 381  Training loss = 2.2190  Validation loss = 6.9966  \n",
      "\n",
      "Fold: 8  Epoch: 382  Training loss = 2.2188  Validation loss = 6.9963  \n",
      "\n",
      "Fold: 8  Epoch: 383  Training loss = 2.2185  Validation loss = 6.9959  \n",
      "\n",
      "Fold: 8  Epoch: 384  Training loss = 2.2183  Validation loss = 6.9955  \n",
      "\n",
      "Fold: 8  Epoch: 385  Training loss = 2.2181  Validation loss = 6.9951  \n",
      "\n",
      "Fold: 8  Epoch: 386  Training loss = 2.2179  Validation loss = 6.9947  \n",
      "\n",
      "Fold: 8  Epoch: 387  Training loss = 2.2176  Validation loss = 6.9943  \n",
      "\n",
      "Fold: 8  Epoch: 388  Training loss = 2.2174  Validation loss = 6.9939  \n",
      "\n",
      "Fold: 8  Epoch: 389  Training loss = 2.2172  Validation loss = 6.9936  \n",
      "\n",
      "Fold: 8  Epoch: 390  Training loss = 2.2170  Validation loss = 6.9932  \n",
      "\n",
      "Fold: 8  Epoch: 391  Training loss = 2.2167  Validation loss = 6.9928  \n",
      "\n",
      "Fold: 8  Epoch: 392  Training loss = 2.2165  Validation loss = 6.9924  \n",
      "\n",
      "Fold: 8  Epoch: 393  Training loss = 2.2163  Validation loss = 6.9920  \n",
      "\n",
      "Fold: 8  Epoch: 394  Training loss = 2.2161  Validation loss = 6.9917  \n",
      "\n",
      "Fold: 8  Epoch: 395  Training loss = 2.2158  Validation loss = 6.9912  \n",
      "\n",
      "Fold: 8  Epoch: 396  Training loss = 2.2156  Validation loss = 6.9908  \n",
      "\n",
      "Fold: 8  Epoch: 397  Training loss = 2.2153  Validation loss = 6.9904  \n",
      "\n",
      "Fold: 8  Epoch: 398  Training loss = 2.2151  Validation loss = 6.9901  \n",
      "\n",
      "Fold: 8  Epoch: 399  Training loss = 2.2148  Validation loss = 6.9896  \n",
      "\n",
      "Fold: 8  Epoch: 400  Training loss = 2.2147  Validation loss = 6.9893  \n",
      "\n",
      "Fold: 8  Epoch: 401  Training loss = 2.2145  Validation loss = 6.9890  \n",
      "\n",
      "Fold: 8  Epoch: 402  Training loss = 2.2142  Validation loss = 6.9885  \n",
      "\n",
      "Fold: 8  Epoch: 403  Training loss = 2.2140  Validation loss = 6.9882  \n",
      "\n",
      "Fold: 8  Epoch: 404  Training loss = 2.2137  Validation loss = 6.9878  \n",
      "\n",
      "Fold: 8  Epoch: 405  Training loss = 2.2135  Validation loss = 6.9874  \n",
      "\n",
      "Fold: 8  Epoch: 406  Training loss = 2.2133  Validation loss = 6.9871  \n",
      "\n",
      "Fold: 8  Epoch: 407  Training loss = 2.2131  Validation loss = 6.9867  \n",
      "\n",
      "Fold: 8  Epoch: 408  Training loss = 2.2129  Validation loss = 6.9863  \n",
      "\n",
      "Fold: 8  Epoch: 409  Training loss = 2.2126  Validation loss = 6.9859  \n",
      "\n",
      "Fold: 8  Epoch: 410  Training loss = 2.2124  Validation loss = 6.9855  \n",
      "\n",
      "Fold: 8  Epoch: 411  Training loss = 2.2122  Validation loss = 6.9852  \n",
      "\n",
      "Fold: 8  Epoch: 412  Training loss = 2.2120  Validation loss = 6.9849  \n",
      "\n",
      "Fold: 8  Epoch: 413  Training loss = 2.2118  Validation loss = 6.9845  \n",
      "\n",
      "Fold: 8  Epoch: 414  Training loss = 2.2116  Validation loss = 6.9842  \n",
      "\n",
      "Fold: 8  Epoch: 415  Training loss = 2.2114  Validation loss = 6.9838  \n",
      "\n",
      "Fold: 8  Epoch: 416  Training loss = 2.2112  Validation loss = 6.9834  \n",
      "\n",
      "Fold: 8  Epoch: 417  Training loss = 2.2109  Validation loss = 6.9830  \n",
      "\n",
      "Fold: 8  Epoch: 418  Training loss = 2.2107  Validation loss = 6.9825  \n",
      "\n",
      "Fold: 8  Epoch: 419  Training loss = 2.2105  Validation loss = 6.9822  \n",
      "\n",
      "Fold: 8  Epoch: 420  Training loss = 2.2103  Validation loss = 6.9819  \n",
      "\n",
      "Fold: 8  Epoch: 421  Training loss = 2.2100  Validation loss = 6.9815  \n",
      "\n",
      "Fold: 8  Epoch: 422  Training loss = 2.2098  Validation loss = 6.9811  \n",
      "\n",
      "Fold: 8  Epoch: 423  Training loss = 2.2096  Validation loss = 6.9807  \n",
      "\n",
      "Fold: 8  Epoch: 424  Training loss = 2.2095  Validation loss = 6.9805  \n",
      "\n",
      "Fold: 8  Epoch: 425  Training loss = 2.2092  Validation loss = 6.9801  \n",
      "\n",
      "Fold: 8  Epoch: 426  Training loss = 2.2091  Validation loss = 6.9799  \n",
      "\n",
      "Fold: 8  Epoch: 427  Training loss = 2.2089  Validation loss = 6.9795  \n",
      "\n",
      "Fold: 8  Epoch: 428  Training loss = 2.2086  Validation loss = 6.9791  \n",
      "\n",
      "Fold: 8  Epoch: 429  Training loss = 2.2084  Validation loss = 6.9787  \n",
      "\n",
      "Fold: 8  Epoch: 430  Training loss = 2.2082  Validation loss = 6.9783  \n",
      "\n",
      "Fold: 8  Epoch: 431  Training loss = 2.2079  Validation loss = 6.9779  \n",
      "\n",
      "Fold: 8  Epoch: 432  Training loss = 2.2077  Validation loss = 6.9776  \n",
      "\n",
      "Fold: 8  Epoch: 433  Training loss = 2.2075  Validation loss = 6.9773  \n",
      "\n",
      "Fold: 8  Epoch: 434  Training loss = 2.2073  Validation loss = 6.9769  \n",
      "\n",
      "Fold: 8  Epoch: 435  Training loss = 2.2071  Validation loss = 6.9766  \n",
      "\n",
      "Fold: 8  Epoch: 436  Training loss = 2.2069  Validation loss = 6.9762  \n",
      "\n",
      "Fold: 8  Epoch: 437  Training loss = 2.2067  Validation loss = 6.9758  \n",
      "\n",
      "Fold: 8  Epoch: 438  Training loss = 2.2065  Validation loss = 6.9755  \n",
      "\n",
      "Fold: 8  Epoch: 439  Training loss = 2.2063  Validation loss = 6.9752  \n",
      "\n",
      "Fold: 8  Epoch: 440  Training loss = 2.2061  Validation loss = 6.9749  \n",
      "\n",
      "Fold: 8  Epoch: 441  Training loss = 2.2059  Validation loss = 6.9745  \n",
      "\n",
      "Fold: 8  Epoch: 442  Training loss = 2.2057  Validation loss = 6.9742  \n",
      "\n",
      "Fold: 8  Epoch: 443  Training loss = 2.2054  Validation loss = 6.9737  \n",
      "\n",
      "Fold: 8  Epoch: 444  Training loss = 2.2052  Validation loss = 6.9733  \n",
      "\n",
      "Fold: 8  Epoch: 445  Training loss = 2.2050  Validation loss = 6.9731  \n",
      "\n",
      "Fold: 8  Epoch: 446  Training loss = 2.2048  Validation loss = 6.9726  \n",
      "\n",
      "Fold: 8  Epoch: 447  Training loss = 2.2046  Validation loss = 6.9722  \n",
      "\n",
      "Fold: 8  Epoch: 448  Training loss = 2.2044  Validation loss = 6.9719  \n",
      "\n",
      "Fold: 8  Epoch: 449  Training loss = 2.2042  Validation loss = 6.9717  \n",
      "\n",
      "Fold: 8  Epoch: 450  Training loss = 2.2040  Validation loss = 6.9712  \n",
      "\n",
      "Fold: 8  Epoch: 451  Training loss = 2.2037  Validation loss = 6.9708  \n",
      "\n",
      "Fold: 8  Epoch: 452  Training loss = 2.2035  Validation loss = 6.9704  \n",
      "\n",
      "Fold: 8  Epoch: 453  Training loss = 2.2033  Validation loss = 6.9701  \n",
      "\n",
      "Fold: 8  Epoch: 454  Training loss = 2.2031  Validation loss = 6.9698  \n",
      "\n",
      "Fold: 8  Epoch: 455  Training loss = 2.2029  Validation loss = 6.9695  \n",
      "\n",
      "Fold: 8  Epoch: 456  Training loss = 2.2027  Validation loss = 6.9692  \n",
      "\n",
      "Fold: 8  Epoch: 457  Training loss = 2.2025  Validation loss = 6.9689  \n",
      "\n",
      "Fold: 8  Epoch: 458  Training loss = 2.2023  Validation loss = 6.9685  \n",
      "\n",
      "Fold: 8  Epoch: 459  Training loss = 2.2020  Validation loss = 6.9680  \n",
      "\n",
      "Fold: 8  Epoch: 460  Training loss = 2.2018  Validation loss = 6.9677  \n",
      "\n",
      "Fold: 8  Epoch: 461  Training loss = 2.2016  Validation loss = 6.9673  \n",
      "\n",
      "Fold: 8  Epoch: 462  Training loss = 2.2014  Validation loss = 6.9669  \n",
      "\n",
      "Fold: 8  Epoch: 463  Training loss = 2.2011  Validation loss = 6.9666  \n",
      "\n",
      "Fold: 8  Epoch: 464  Training loss = 2.2009  Validation loss = 6.9662  \n",
      "\n",
      "Fold: 8  Epoch: 465  Training loss = 2.2007  Validation loss = 6.9658  \n",
      "\n",
      "Fold: 8  Epoch: 466  Training loss = 2.2005  Validation loss = 6.9655  \n",
      "\n",
      "Fold: 8  Epoch: 467  Training loss = 2.2003  Validation loss = 6.9651  \n",
      "\n",
      "Fold: 8  Epoch: 468  Training loss = 2.2002  Validation loss = 6.9649  \n",
      "\n",
      "Fold: 8  Epoch: 469  Training loss = 2.2000  Validation loss = 6.9646  \n",
      "\n",
      "Fold: 8  Epoch: 470  Training loss = 2.1998  Validation loss = 6.9642  \n",
      "\n",
      "Fold: 8  Epoch: 471  Training loss = 2.1996  Validation loss = 6.9638  \n",
      "\n",
      "Fold: 8  Epoch: 472  Training loss = 2.1993  Validation loss = 6.9634  \n",
      "\n",
      "Fold: 8  Epoch: 473  Training loss = 2.1991  Validation loss = 6.9630  \n",
      "\n",
      "Fold: 8  Epoch: 474  Training loss = 2.1989  Validation loss = 6.9627  \n",
      "\n",
      "Fold: 8  Epoch: 475  Training loss = 2.1987  Validation loss = 6.9624  \n",
      "\n",
      "Fold: 8  Epoch: 476  Training loss = 2.1986  Validation loss = 6.9621  \n",
      "\n",
      "Fold: 8  Epoch: 477  Training loss = 2.1984  Validation loss = 6.9618  \n",
      "\n",
      "Fold: 8  Epoch: 478  Training loss = 2.1981  Validation loss = 6.9613  \n",
      "\n",
      "Fold: 8  Epoch: 479  Training loss = 2.1979  Validation loss = 6.9610  \n",
      "\n",
      "Fold: 8  Epoch: 480  Training loss = 2.1977  Validation loss = 6.9607  \n",
      "\n",
      "Fold: 8  Epoch: 481  Training loss = 2.1976  Validation loss = 6.9604  \n",
      "\n",
      "Fold: 8  Epoch: 482  Training loss = 2.1973  Validation loss = 6.9600  \n",
      "\n",
      "Fold: 8  Epoch: 483  Training loss = 2.1971  Validation loss = 6.9597  \n",
      "\n",
      "Fold: 8  Epoch: 484  Training loss = 2.1969  Validation loss = 6.9593  \n",
      "\n",
      "Fold: 8  Epoch: 485  Training loss = 2.1967  Validation loss = 6.9589  \n",
      "\n",
      "Fold: 8  Epoch: 486  Training loss = 2.1965  Validation loss = 6.9586  \n",
      "\n",
      "Fold: 8  Epoch: 487  Training loss = 2.1963  Validation loss = 6.9582  \n",
      "\n",
      "Fold: 8  Epoch: 488  Training loss = 2.1961  Validation loss = 6.9579  \n",
      "\n",
      "Fold: 8  Epoch: 489  Training loss = 2.1960  Validation loss = 6.9577  \n",
      "\n",
      "Fold: 8  Epoch: 490  Training loss = 2.1958  Validation loss = 6.9574  \n",
      "\n",
      "Fold: 8  Epoch: 491  Training loss = 2.1956  Validation loss = 6.9570  \n",
      "\n",
      "Fold: 8  Epoch: 492  Training loss = 2.1954  Validation loss = 6.9567  \n",
      "\n",
      "Fold: 8  Epoch: 493  Training loss = 2.1952  Validation loss = 6.9564  \n",
      "\n",
      "Fold: 8  Epoch: 494  Training loss = 2.1950  Validation loss = 6.9561  \n",
      "\n",
      "Fold: 8  Epoch: 495  Training loss = 2.1949  Validation loss = 6.9558  \n",
      "\n",
      "Fold: 8  Epoch: 496  Training loss = 2.1947  Validation loss = 6.9554  \n",
      "\n",
      "Fold: 8  Epoch: 497  Training loss = 2.1944  Validation loss = 6.9550  \n",
      "\n",
      "Fold: 8  Epoch: 498  Training loss = 2.1942  Validation loss = 6.9546  \n",
      "\n",
      "Fold: 8  Epoch: 499  Training loss = 2.1939  Validation loss = 6.9542  \n",
      "\n",
      "Fold: 8  Epoch: 500  Training loss = 2.1937  Validation loss = 6.9539  \n",
      "\n",
      "Check model:  Fold: 8  Epoch: 500  Training loss = 2.1937  Validation loss = 6.9539  \n",
      "\n",
      "Fold: 9  Epoch: 1  Training loss = 2.7330  Validation loss = 10.4225  \n",
      "\n",
      "Fold: 9  Epoch: 2  Training loss = 2.7327  Validation loss = 10.4219  \n",
      "\n",
      "Fold: 9  Epoch: 3  Training loss = 2.7324  Validation loss = 10.4214  \n",
      "\n",
      "Fold: 9  Epoch: 4  Training loss = 2.7322  Validation loss = 10.4211  \n",
      "\n",
      "Fold: 9  Epoch: 5  Training loss = 2.7321  Validation loss = 10.4208  \n",
      "\n",
      "Fold: 9  Epoch: 6  Training loss = 2.7318  Validation loss = 10.4203  \n",
      "\n",
      "Fold: 9  Epoch: 7  Training loss = 2.7316  Validation loss = 10.4199  \n",
      "\n",
      "Fold: 9  Epoch: 8  Training loss = 2.7314  Validation loss = 10.4195  \n",
      "\n",
      "Fold: 9  Epoch: 9  Training loss = 2.7310  Validation loss = 10.4189  \n",
      "\n",
      "Fold: 9  Epoch: 10  Training loss = 2.7307  Validation loss = 10.4183  \n",
      "\n",
      "Fold: 9  Epoch: 11  Training loss = 2.7304  Validation loss = 10.4177  \n",
      "\n",
      "Fold: 9  Epoch: 12  Training loss = 2.7301  Validation loss = 10.4171  \n",
      "\n",
      "Fold: 9  Epoch: 13  Training loss = 2.7298  Validation loss = 10.4167  \n",
      "\n",
      "Fold: 9  Epoch: 14  Training loss = 2.7295  Validation loss = 10.4162  \n",
      "\n",
      "Fold: 9  Epoch: 15  Training loss = 2.7293  Validation loss = 10.4158  \n",
      "\n",
      "Fold: 9  Epoch: 16  Training loss = 2.7290  Validation loss = 10.4152  \n",
      "\n",
      "Fold: 9  Epoch: 17  Training loss = 2.7288  Validation loss = 10.4148  \n",
      "\n",
      "Fold: 9  Epoch: 18  Training loss = 2.7285  Validation loss = 10.4143  \n",
      "\n",
      "Fold: 9  Epoch: 19  Training loss = 2.7283  Validation loss = 10.4138  \n",
      "\n",
      "Fold: 9  Epoch: 20  Training loss = 2.7280  Validation loss = 10.4134  \n",
      "\n",
      "Fold: 9  Epoch: 21  Training loss = 2.7278  Validation loss = 10.4129  \n",
      "\n",
      "Fold: 9  Epoch: 22  Training loss = 2.7275  Validation loss = 10.4125  \n",
      "\n",
      "Fold: 9  Epoch: 23  Training loss = 2.7273  Validation loss = 10.4121  \n",
      "\n",
      "Fold: 9  Epoch: 24  Training loss = 2.7271  Validation loss = 10.4117  \n",
      "\n",
      "Fold: 9  Epoch: 25  Training loss = 2.7268  Validation loss = 10.4112  \n",
      "\n",
      "Fold: 9  Epoch: 26  Training loss = 2.7266  Validation loss = 10.4108  \n",
      "\n",
      "Fold: 9  Epoch: 27  Training loss = 2.7263  Validation loss = 10.4102  \n",
      "\n",
      "Fold: 9  Epoch: 28  Training loss = 2.7260  Validation loss = 10.4097  \n",
      "\n",
      "Fold: 9  Epoch: 29  Training loss = 2.7258  Validation loss = 10.4094  \n",
      "\n",
      "Fold: 9  Epoch: 30  Training loss = 2.7256  Validation loss = 10.4090  \n",
      "\n",
      "Fold: 9  Epoch: 31  Training loss = 2.7253  Validation loss = 10.4084  \n",
      "\n",
      "Fold: 9  Epoch: 32  Training loss = 2.7250  Validation loss = 10.4079  \n",
      "\n",
      "Fold: 9  Epoch: 33  Training loss = 2.7247  Validation loss = 10.4073  \n",
      "\n",
      "Fold: 9  Epoch: 34  Training loss = 2.7245  Validation loss = 10.4069  \n",
      "\n",
      "Fold: 9  Epoch: 35  Training loss = 2.7243  Validation loss = 10.4065  \n",
      "\n",
      "Fold: 9  Epoch: 36  Training loss = 2.7241  Validation loss = 10.4061  \n",
      "\n",
      "Fold: 9  Epoch: 37  Training loss = 2.7238  Validation loss = 10.4056  \n",
      "\n",
      "Fold: 9  Epoch: 38  Training loss = 2.7235  Validation loss = 10.4051  \n",
      "\n",
      "Fold: 9  Epoch: 39  Training loss = 2.7232  Validation loss = 10.4046  \n",
      "\n",
      "Fold: 9  Epoch: 40  Training loss = 2.7229  Validation loss = 10.4041  \n",
      "\n",
      "Fold: 9  Epoch: 41  Training loss = 2.7227  Validation loss = 10.4036  \n",
      "\n",
      "Fold: 9  Epoch: 42  Training loss = 2.7224  Validation loss = 10.4031  \n",
      "\n",
      "Fold: 9  Epoch: 43  Training loss = 2.7222  Validation loss = 10.4027  \n",
      "\n",
      "Fold: 9  Epoch: 44  Training loss = 2.7219  Validation loss = 10.4023  \n",
      "\n",
      "Fold: 9  Epoch: 45  Training loss = 2.7217  Validation loss = 10.4019  \n",
      "\n",
      "Fold: 9  Epoch: 46  Training loss = 2.7214  Validation loss = 10.4013  \n",
      "\n",
      "Fold: 9  Epoch: 47  Training loss = 2.7212  Validation loss = 10.4009  \n",
      "\n",
      "Fold: 9  Epoch: 48  Training loss = 2.7209  Validation loss = 10.4004  \n",
      "\n",
      "Fold: 9  Epoch: 49  Training loss = 2.7207  Validation loss = 10.4001  \n",
      "\n",
      "Fold: 9  Epoch: 50  Training loss = 2.7204  Validation loss = 10.3995  \n",
      "\n",
      "Fold: 9  Epoch: 51  Training loss = 2.7203  Validation loss = 10.3992  \n",
      "\n",
      "Fold: 9  Epoch: 52  Training loss = 2.7200  Validation loss = 10.3987  \n",
      "\n",
      "Fold: 9  Epoch: 53  Training loss = 2.7198  Validation loss = 10.3983  \n",
      "\n",
      "Fold: 9  Epoch: 54  Training loss = 2.7196  Validation loss = 10.3980  \n",
      "\n",
      "Fold: 9  Epoch: 55  Training loss = 2.7194  Validation loss = 10.3977  \n",
      "\n",
      "Fold: 9  Epoch: 56  Training loss = 2.7192  Validation loss = 10.3972  \n",
      "\n",
      "Fold: 9  Epoch: 57  Training loss = 2.7189  Validation loss = 10.3967  \n",
      "\n",
      "Fold: 9  Epoch: 58  Training loss = 2.7187  Validation loss = 10.3963  \n",
      "\n",
      "Fold: 9  Epoch: 59  Training loss = 2.7184  Validation loss = 10.3958  \n",
      "\n",
      "Fold: 9  Epoch: 60  Training loss = 2.7182  Validation loss = 10.3953  \n",
      "\n",
      "Fold: 9  Epoch: 61  Training loss = 2.7179  Validation loss = 10.3949  \n",
      "\n",
      "Fold: 9  Epoch: 62  Training loss = 2.7177  Validation loss = 10.3944  \n",
      "\n",
      "Fold: 9  Epoch: 63  Training loss = 2.7174  Validation loss = 10.3940  \n",
      "\n",
      "Fold: 9  Epoch: 64  Training loss = 2.7171  Validation loss = 10.3935  \n",
      "\n",
      "Fold: 9  Epoch: 65  Training loss = 2.7169  Validation loss = 10.3930  \n",
      "\n",
      "Fold: 9  Epoch: 66  Training loss = 2.7166  Validation loss = 10.3926  \n",
      "\n",
      "Fold: 9  Epoch: 67  Training loss = 2.7163  Validation loss = 10.3919  \n",
      "\n",
      "Fold: 9  Epoch: 68  Training loss = 2.7161  Validation loss = 10.3915  \n",
      "\n",
      "Fold: 9  Epoch: 69  Training loss = 2.7157  Validation loss = 10.3908  \n",
      "\n",
      "Fold: 9  Epoch: 70  Training loss = 2.7154  Validation loss = 10.3903  \n",
      "\n",
      "Fold: 9  Epoch: 71  Training loss = 2.7152  Validation loss = 10.3899  \n",
      "\n",
      "Fold: 9  Epoch: 72  Training loss = 2.7149  Validation loss = 10.3894  \n",
      "\n",
      "Fold: 9  Epoch: 73  Training loss = 2.7146  Validation loss = 10.3889  \n",
      "\n",
      "Fold: 9  Epoch: 74  Training loss = 2.7144  Validation loss = 10.3885  \n",
      "\n",
      "Fold: 9  Epoch: 75  Training loss = 2.7141  Validation loss = 10.3880  \n",
      "\n",
      "Fold: 9  Epoch: 76  Training loss = 2.7139  Validation loss = 10.3876  \n",
      "\n",
      "Fold: 9  Epoch: 77  Training loss = 2.7137  Validation loss = 10.3872  \n",
      "\n",
      "Fold: 9  Epoch: 78  Training loss = 2.7134  Validation loss = 10.3867  \n",
      "\n",
      "Fold: 9  Epoch: 79  Training loss = 2.7132  Validation loss = 10.3862  \n",
      "\n",
      "Fold: 9  Epoch: 80  Training loss = 2.7129  Validation loss = 10.3857  \n",
      "\n",
      "Fold: 9  Epoch: 81  Training loss = 2.7127  Validation loss = 10.3853  \n",
      "\n",
      "Fold: 9  Epoch: 82  Training loss = 2.7124  Validation loss = 10.3847  \n",
      "\n",
      "Fold: 9  Epoch: 83  Training loss = 2.7121  Validation loss = 10.3843  \n",
      "\n",
      "Fold: 9  Epoch: 84  Training loss = 2.7118  Validation loss = 10.3837  \n",
      "\n",
      "Fold: 9  Epoch: 85  Training loss = 2.7115  Validation loss = 10.3832  \n",
      "\n",
      "Fold: 9  Epoch: 86  Training loss = 2.7113  Validation loss = 10.3828  \n",
      "\n",
      "Fold: 9  Epoch: 87  Training loss = 2.7110  Validation loss = 10.3823  \n",
      "\n",
      "Fold: 9  Epoch: 88  Training loss = 2.7109  Validation loss = 10.3820  \n",
      "\n",
      "Fold: 9  Epoch: 89  Training loss = 2.7107  Validation loss = 10.3816  \n",
      "\n",
      "Fold: 9  Epoch: 90  Training loss = 2.7105  Validation loss = 10.3812  \n",
      "\n",
      "Fold: 9  Epoch: 91  Training loss = 2.7103  Validation loss = 10.3809  \n",
      "\n",
      "Fold: 9  Epoch: 92  Training loss = 2.7100  Validation loss = 10.3804  \n",
      "\n",
      "Fold: 9  Epoch: 93  Training loss = 2.7098  Validation loss = 10.3799  \n",
      "\n",
      "Fold: 9  Epoch: 94  Training loss = 2.7095  Validation loss = 10.3794  \n",
      "\n",
      "Fold: 9  Epoch: 95  Training loss = 2.7091  Validation loss = 10.3787  \n",
      "\n",
      "Fold: 9  Epoch: 96  Training loss = 2.7089  Validation loss = 10.3783  \n",
      "\n",
      "Fold: 9  Epoch: 97  Training loss = 2.7087  Validation loss = 10.3779  \n",
      "\n",
      "Fold: 9  Epoch: 98  Training loss = 2.7084  Validation loss = 10.3774  \n",
      "\n",
      "Fold: 9  Epoch: 99  Training loss = 2.7082  Validation loss = 10.3770  \n",
      "\n",
      "Fold: 9  Epoch: 100  Training loss = 2.7079  Validation loss = 10.3765  \n",
      "\n",
      "Fold: 9  Epoch: 101  Training loss = 2.7076  Validation loss = 10.3760  \n",
      "\n",
      "Fold: 9  Epoch: 102  Training loss = 2.7074  Validation loss = 10.3755  \n",
      "\n",
      "Fold: 9  Epoch: 103  Training loss = 2.7070  Validation loss = 10.3749  \n",
      "\n",
      "Fold: 9  Epoch: 104  Training loss = 2.7068  Validation loss = 10.3744  \n",
      "\n",
      "Fold: 9  Epoch: 105  Training loss = 2.7065  Validation loss = 10.3740  \n",
      "\n",
      "Fold: 9  Epoch: 106  Training loss = 2.7063  Validation loss = 10.3735  \n",
      "\n",
      "Fold: 9  Epoch: 107  Training loss = 2.7059  Validation loss = 10.3729  \n",
      "\n",
      "Fold: 9  Epoch: 108  Training loss = 2.7057  Validation loss = 10.3724  \n",
      "\n",
      "Fold: 9  Epoch: 109  Training loss = 2.7055  Validation loss = 10.3720  \n",
      "\n",
      "Fold: 9  Epoch: 110  Training loss = 2.7052  Validation loss = 10.3715  \n",
      "\n",
      "Fold: 9  Epoch: 111  Training loss = 2.7049  Validation loss = 10.3710  \n",
      "\n",
      "Fold: 9  Epoch: 112  Training loss = 2.7047  Validation loss = 10.3706  \n",
      "\n",
      "Fold: 9  Epoch: 113  Training loss = 2.7043  Validation loss = 10.3699  \n",
      "\n",
      "Fold: 9  Epoch: 114  Training loss = 2.7040  Validation loss = 10.3693  \n",
      "\n",
      "Fold: 9  Epoch: 115  Training loss = 2.7037  Validation loss = 10.3688  \n",
      "\n",
      "Fold: 9  Epoch: 116  Training loss = 2.7035  Validation loss = 10.3683  \n",
      "\n",
      "Fold: 9  Epoch: 117  Training loss = 2.7031  Validation loss = 10.3677  \n",
      "\n",
      "Fold: 9  Epoch: 118  Training loss = 2.7029  Validation loss = 10.3672  \n",
      "\n",
      "Fold: 9  Epoch: 119  Training loss = 2.7027  Validation loss = 10.3669  \n",
      "\n",
      "Fold: 9  Epoch: 120  Training loss = 2.7025  Validation loss = 10.3665  \n",
      "\n",
      "Fold: 9  Epoch: 121  Training loss = 2.7022  Validation loss = 10.3660  \n",
      "\n",
      "Fold: 9  Epoch: 122  Training loss = 2.7020  Validation loss = 10.3656  \n",
      "\n",
      "Fold: 9  Epoch: 123  Training loss = 2.7017  Validation loss = 10.3651  \n",
      "\n",
      "Fold: 9  Epoch: 124  Training loss = 2.7015  Validation loss = 10.3647  \n",
      "\n",
      "Fold: 9  Epoch: 125  Training loss = 2.7013  Validation loss = 10.3643  \n",
      "\n",
      "Fold: 9  Epoch: 126  Training loss = 2.7010  Validation loss = 10.3638  \n",
      "\n",
      "Fold: 9  Epoch: 127  Training loss = 2.7007  Validation loss = 10.3633  \n",
      "\n",
      "Fold: 9  Epoch: 128  Training loss = 2.7005  Validation loss = 10.3629  \n",
      "\n",
      "Fold: 9  Epoch: 129  Training loss = 2.7003  Validation loss = 10.3624  \n",
      "\n",
      "Fold: 9  Epoch: 130  Training loss = 2.7000  Validation loss = 10.3620  \n",
      "\n",
      "Fold: 9  Epoch: 131  Training loss = 2.6999  Validation loss = 10.3617  \n",
      "\n",
      "Fold: 9  Epoch: 132  Training loss = 2.6997  Validation loss = 10.3614  \n",
      "\n",
      "Fold: 9  Epoch: 133  Training loss = 2.6995  Validation loss = 10.3609  \n",
      "\n",
      "Fold: 9  Epoch: 134  Training loss = 2.6991  Validation loss = 10.3603  \n",
      "\n",
      "Fold: 9  Epoch: 135  Training loss = 2.6989  Validation loss = 10.3598  \n",
      "\n",
      "Fold: 9  Epoch: 136  Training loss = 2.6986  Validation loss = 10.3594  \n",
      "\n",
      "Fold: 9  Epoch: 137  Training loss = 2.6984  Validation loss = 10.3590  \n",
      "\n",
      "Fold: 9  Epoch: 138  Training loss = 2.6982  Validation loss = 10.3586  \n",
      "\n",
      "Fold: 9  Epoch: 139  Training loss = 2.6979  Validation loss = 10.3580  \n",
      "\n",
      "Fold: 9  Epoch: 140  Training loss = 2.6977  Validation loss = 10.3576  \n",
      "\n",
      "Fold: 9  Epoch: 141  Training loss = 2.6974  Validation loss = 10.3571  \n",
      "\n",
      "Fold: 9  Epoch: 142  Training loss = 2.6972  Validation loss = 10.3567  \n",
      "\n",
      "Fold: 9  Epoch: 143  Training loss = 2.6970  Validation loss = 10.3563  \n",
      "\n",
      "Fold: 9  Epoch: 144  Training loss = 2.6967  Validation loss = 10.3557  \n",
      "\n",
      "Fold: 9  Epoch: 145  Training loss = 2.6965  Validation loss = 10.3554  \n",
      "\n",
      "Fold: 9  Epoch: 146  Training loss = 2.6963  Validation loss = 10.3550  \n",
      "\n",
      "Fold: 9  Epoch: 147  Training loss = 2.6960  Validation loss = 10.3545  \n",
      "\n",
      "Fold: 9  Epoch: 148  Training loss = 2.6958  Validation loss = 10.3540  \n",
      "\n",
      "Fold: 9  Epoch: 149  Training loss = 2.6955  Validation loss = 10.3536  \n",
      "\n",
      "Fold: 9  Epoch: 150  Training loss = 2.6953  Validation loss = 10.3532  \n",
      "\n",
      "Fold: 9  Epoch: 151  Training loss = 2.6950  Validation loss = 10.3527  \n",
      "\n",
      "Fold: 9  Epoch: 152  Training loss = 2.6948  Validation loss = 10.3522  \n",
      "\n",
      "Fold: 9  Epoch: 153  Training loss = 2.6945  Validation loss = 10.3518  \n",
      "\n",
      "Fold: 9  Epoch: 154  Training loss = 2.6943  Validation loss = 10.3513  \n",
      "\n",
      "Fold: 9  Epoch: 155  Training loss = 2.6941  Validation loss = 10.3509  \n",
      "\n",
      "Fold: 9  Epoch: 156  Training loss = 2.6939  Validation loss = 10.3505  \n",
      "\n",
      "Fold: 9  Epoch: 157  Training loss = 2.6937  Validation loss = 10.3502  \n",
      "\n",
      "Fold: 9  Epoch: 158  Training loss = 2.6934  Validation loss = 10.3497  \n",
      "\n",
      "Fold: 9  Epoch: 159  Training loss = 2.6932  Validation loss = 10.3492  \n",
      "\n",
      "Fold: 9  Epoch: 160  Training loss = 2.6929  Validation loss = 10.3487  \n",
      "\n",
      "Fold: 9  Epoch: 161  Training loss = 2.6926  Validation loss = 10.3482  \n",
      "\n",
      "Fold: 9  Epoch: 162  Training loss = 2.6924  Validation loss = 10.3478  \n",
      "\n",
      "Fold: 9  Epoch: 163  Training loss = 2.6921  Validation loss = 10.3472  \n",
      "\n",
      "Fold: 9  Epoch: 164  Training loss = 2.6919  Validation loss = 10.3468  \n",
      "\n",
      "Fold: 9  Epoch: 165  Training loss = 2.6916  Validation loss = 10.3463  \n",
      "\n",
      "Fold: 9  Epoch: 166  Training loss = 2.6914  Validation loss = 10.3459  \n",
      "\n",
      "Fold: 9  Epoch: 167  Training loss = 2.6912  Validation loss = 10.3455  \n",
      "\n",
      "Fold: 9  Epoch: 168  Training loss = 2.6910  Validation loss = 10.3452  \n",
      "\n",
      "Fold: 9  Epoch: 169  Training loss = 2.6907  Validation loss = 10.3447  \n",
      "\n",
      "Fold: 9  Epoch: 170  Training loss = 2.6904  Validation loss = 10.3441  \n",
      "\n",
      "Fold: 9  Epoch: 171  Training loss = 2.6902  Validation loss = 10.3437  \n",
      "\n",
      "Fold: 9  Epoch: 172  Training loss = 2.6899  Validation loss = 10.3432  \n",
      "\n",
      "Fold: 9  Epoch: 173  Training loss = 2.6897  Validation loss = 10.3427  \n",
      "\n",
      "Fold: 9  Epoch: 174  Training loss = 2.6894  Validation loss = 10.3422  \n",
      "\n",
      "Fold: 9  Epoch: 175  Training loss = 2.6891  Validation loss = 10.3417  \n",
      "\n",
      "Fold: 9  Epoch: 176  Training loss = 2.6889  Validation loss = 10.3412  \n",
      "\n",
      "Fold: 9  Epoch: 177  Training loss = 2.6886  Validation loss = 10.3407  \n",
      "\n",
      "Fold: 9  Epoch: 178  Training loss = 2.6884  Validation loss = 10.3403  \n",
      "\n",
      "Fold: 9  Epoch: 179  Training loss = 2.6882  Validation loss = 10.3399  \n",
      "\n",
      "Fold: 9  Epoch: 180  Training loss = 2.6879  Validation loss = 10.3395  \n",
      "\n",
      "Fold: 9  Epoch: 181  Training loss = 2.6876  Validation loss = 10.3389  \n",
      "\n",
      "Fold: 9  Epoch: 182  Training loss = 2.6875  Validation loss = 10.3386  \n",
      "\n",
      "Fold: 9  Epoch: 183  Training loss = 2.6872  Validation loss = 10.3381  \n",
      "\n",
      "Fold: 9  Epoch: 184  Training loss = 2.6870  Validation loss = 10.3377  \n",
      "\n",
      "Fold: 9  Epoch: 185  Training loss = 2.6867  Validation loss = 10.3372  \n",
      "\n",
      "Fold: 9  Epoch: 186  Training loss = 2.6864  Validation loss = 10.3367  \n",
      "\n",
      "Fold: 9  Epoch: 187  Training loss = 2.6862  Validation loss = 10.3362  \n",
      "\n",
      "Fold: 9  Epoch: 188  Training loss = 2.6860  Validation loss = 10.3359  \n",
      "\n",
      "Fold: 9  Epoch: 189  Training loss = 2.6858  Validation loss = 10.3354  \n",
      "\n",
      "Fold: 9  Epoch: 190  Training loss = 2.6855  Validation loss = 10.3350  \n",
      "\n",
      "Fold: 9  Epoch: 191  Training loss = 2.6853  Validation loss = 10.3345  \n",
      "\n",
      "Fold: 9  Epoch: 192  Training loss = 2.6851  Validation loss = 10.3342  \n",
      "\n",
      "Fold: 9  Epoch: 193  Training loss = 2.6849  Validation loss = 10.3337  \n",
      "\n",
      "Fold: 9  Epoch: 194  Training loss = 2.6846  Validation loss = 10.3332  \n",
      "\n",
      "Fold: 9  Epoch: 195  Training loss = 2.6843  Validation loss = 10.3327  \n",
      "\n",
      "Fold: 9  Epoch: 196  Training loss = 2.6841  Validation loss = 10.3323  \n",
      "\n",
      "Fold: 9  Epoch: 197  Training loss = 2.6839  Validation loss = 10.3319  \n",
      "\n",
      "Fold: 9  Epoch: 198  Training loss = 2.6837  Validation loss = 10.3315  \n",
      "\n",
      "Fold: 9  Epoch: 199  Training loss = 2.6834  Validation loss = 10.3310  \n",
      "\n",
      "Fold: 9  Epoch: 200  Training loss = 2.6832  Validation loss = 10.3306  \n",
      "\n",
      "Fold: 9  Epoch: 201  Training loss = 2.6830  Validation loss = 10.3301  \n",
      "\n",
      "Fold: 9  Epoch: 202  Training loss = 2.6828  Validation loss = 10.3298  \n",
      "\n",
      "Fold: 9  Epoch: 203  Training loss = 2.6825  Validation loss = 10.3292  \n",
      "\n",
      "Fold: 9  Epoch: 204  Training loss = 2.6823  Validation loss = 10.3289  \n",
      "\n",
      "Fold: 9  Epoch: 205  Training loss = 2.6820  Validation loss = 10.3284  \n",
      "\n",
      "Fold: 9  Epoch: 206  Training loss = 2.6818  Validation loss = 10.3281  \n",
      "\n",
      "Fold: 9  Epoch: 207  Training loss = 2.6816  Validation loss = 10.3276  \n",
      "\n",
      "Fold: 9  Epoch: 208  Training loss = 2.6815  Validation loss = 10.3273  \n",
      "\n",
      "Fold: 9  Epoch: 209  Training loss = 2.6812  Validation loss = 10.3269  \n",
      "\n",
      "Fold: 9  Epoch: 210  Training loss = 2.6810  Validation loss = 10.3264  \n",
      "\n",
      "Fold: 9  Epoch: 211  Training loss = 2.6808  Validation loss = 10.3261  \n",
      "\n",
      "Fold: 9  Epoch: 212  Training loss = 2.6806  Validation loss = 10.3257  \n",
      "\n",
      "Fold: 9  Epoch: 213  Training loss = 2.6803  Validation loss = 10.3252  \n",
      "\n",
      "Fold: 9  Epoch: 214  Training loss = 2.6802  Validation loss = 10.3251  \n",
      "\n",
      "Fold: 9  Epoch: 215  Training loss = 2.6801  Validation loss = 10.3247  \n",
      "\n",
      "Fold: 9  Epoch: 216  Training loss = 2.6799  Validation loss = 10.3243  \n",
      "\n",
      "Fold: 9  Epoch: 217  Training loss = 2.6796  Validation loss = 10.3239  \n",
      "\n",
      "Fold: 9  Epoch: 218  Training loss = 2.6793  Validation loss = 10.3233  \n",
      "\n",
      "Fold: 9  Epoch: 219  Training loss = 2.6791  Validation loss = 10.3229  \n",
      "\n",
      "Fold: 9  Epoch: 220  Training loss = 2.6789  Validation loss = 10.3225  \n",
      "\n",
      "Fold: 9  Epoch: 221  Training loss = 2.6787  Validation loss = 10.3221  \n",
      "\n",
      "Fold: 9  Epoch: 222  Training loss = 2.6785  Validation loss = 10.3217  \n",
      "\n",
      "Fold: 9  Epoch: 223  Training loss = 2.6782  Validation loss = 10.3212  \n",
      "\n",
      "Fold: 9  Epoch: 224  Training loss = 2.6779  Validation loss = 10.3207  \n",
      "\n",
      "Fold: 9  Epoch: 225  Training loss = 2.6777  Validation loss = 10.3203  \n",
      "\n",
      "Fold: 9  Epoch: 226  Training loss = 2.6775  Validation loss = 10.3200  \n",
      "\n",
      "Fold: 9  Epoch: 227  Training loss = 2.6773  Validation loss = 10.3195  \n",
      "\n",
      "Fold: 9  Epoch: 228  Training loss = 2.6770  Validation loss = 10.3191  \n",
      "\n",
      "Fold: 9  Epoch: 229  Training loss = 2.6769  Validation loss = 10.3187  \n",
      "\n",
      "Fold: 9  Epoch: 230  Training loss = 2.6766  Validation loss = 10.3182  \n",
      "\n",
      "Fold: 9  Epoch: 231  Training loss = 2.6764  Validation loss = 10.3178  \n",
      "\n",
      "Fold: 9  Epoch: 232  Training loss = 2.6762  Validation loss = 10.3174  \n",
      "\n",
      "Fold: 9  Epoch: 233  Training loss = 2.6759  Validation loss = 10.3170  \n",
      "\n",
      "Fold: 9  Epoch: 234  Training loss = 2.6757  Validation loss = 10.3166  \n",
      "\n",
      "Fold: 9  Epoch: 235  Training loss = 2.6755  Validation loss = 10.3161  \n",
      "\n",
      "Fold: 9  Epoch: 236  Training loss = 2.6753  Validation loss = 10.3157  \n",
      "\n",
      "Fold: 9  Epoch: 237  Training loss = 2.6751  Validation loss = 10.3153  \n",
      "\n",
      "Fold: 9  Epoch: 238  Training loss = 2.6748  Validation loss = 10.3149  \n",
      "\n",
      "Fold: 9  Epoch: 239  Training loss = 2.6746  Validation loss = 10.3145  \n",
      "\n",
      "Fold: 9  Epoch: 240  Training loss = 2.6745  Validation loss = 10.3142  \n",
      "\n",
      "Fold: 9  Epoch: 241  Training loss = 2.6743  Validation loss = 10.3139  \n",
      "\n",
      "Fold: 9  Epoch: 242  Training loss = 2.6740  Validation loss = 10.3134  \n",
      "\n",
      "Fold: 9  Epoch: 243  Training loss = 2.6738  Validation loss = 10.3129  \n",
      "\n",
      "Fold: 9  Epoch: 244  Training loss = 2.6735  Validation loss = 10.3124  \n",
      "\n",
      "Fold: 9  Epoch: 245  Training loss = 2.6733  Validation loss = 10.3119  \n",
      "\n",
      "Fold: 9  Epoch: 246  Training loss = 2.6731  Validation loss = 10.3116  \n",
      "\n",
      "Fold: 9  Epoch: 247  Training loss = 2.6729  Validation loss = 10.3112  \n",
      "\n",
      "Fold: 9  Epoch: 248  Training loss = 2.6727  Validation loss = 10.3108  \n",
      "\n",
      "Fold: 9  Epoch: 249  Training loss = 2.6724  Validation loss = 10.3103  \n",
      "\n",
      "Fold: 9  Epoch: 250  Training loss = 2.6721  Validation loss = 10.3098  \n",
      "\n",
      "Fold: 9  Epoch: 251  Training loss = 2.6719  Validation loss = 10.3094  \n",
      "\n",
      "Fold: 9  Epoch: 252  Training loss = 2.6716  Validation loss = 10.3089  \n",
      "\n",
      "Fold: 9  Epoch: 253  Training loss = 2.6714  Validation loss = 10.3084  \n",
      "\n",
      "Fold: 9  Epoch: 254  Training loss = 2.6712  Validation loss = 10.3080  \n",
      "\n",
      "Fold: 9  Epoch: 255  Training loss = 2.6710  Validation loss = 10.3076  \n",
      "\n",
      "Fold: 9  Epoch: 256  Training loss = 2.6707  Validation loss = 10.3071  \n",
      "\n",
      "Fold: 9  Epoch: 257  Training loss = 2.6705  Validation loss = 10.3068  \n",
      "\n",
      "Fold: 9  Epoch: 258  Training loss = 2.6702  Validation loss = 10.3062  \n",
      "\n",
      "Fold: 9  Epoch: 259  Training loss = 2.6700  Validation loss = 10.3058  \n",
      "\n",
      "Fold: 9  Epoch: 260  Training loss = 2.6698  Validation loss = 10.3054  \n",
      "\n",
      "Fold: 9  Epoch: 261  Training loss = 2.6696  Validation loss = 10.3051  \n",
      "\n",
      "Fold: 9  Epoch: 262  Training loss = 2.6695  Validation loss = 10.3048  \n",
      "\n",
      "Fold: 9  Epoch: 263  Training loss = 2.6693  Validation loss = 10.3044  \n",
      "\n",
      "Fold: 9  Epoch: 264  Training loss = 2.6690  Validation loss = 10.3039  \n",
      "\n",
      "Fold: 9  Epoch: 265  Training loss = 2.6687  Validation loss = 10.3033  \n",
      "\n",
      "Fold: 9  Epoch: 266  Training loss = 2.6685  Validation loss = 10.3029  \n",
      "\n",
      "Fold: 9  Epoch: 267  Training loss = 2.6682  Validation loss = 10.3025  \n",
      "\n",
      "Fold: 9  Epoch: 268  Training loss = 2.6680  Validation loss = 10.3020  \n",
      "\n",
      "Fold: 9  Epoch: 269  Training loss = 2.6677  Validation loss = 10.3015  \n",
      "\n",
      "Fold: 9  Epoch: 270  Training loss = 2.6675  Validation loss = 10.3011  \n",
      "\n",
      "Fold: 9  Epoch: 271  Training loss = 2.6673  Validation loss = 10.3006  \n",
      "\n",
      "Fold: 9  Epoch: 272  Training loss = 2.6670  Validation loss = 10.3002  \n",
      "\n",
      "Fold: 9  Epoch: 273  Training loss = 2.6668  Validation loss = 10.2998  \n",
      "\n",
      "Fold: 9  Epoch: 274  Training loss = 2.6665  Validation loss = 10.2992  \n",
      "\n",
      "Fold: 9  Epoch: 275  Training loss = 2.6663  Validation loss = 10.2988  \n",
      "\n",
      "Fold: 9  Epoch: 276  Training loss = 2.6660  Validation loss = 10.2983  \n",
      "\n",
      "Fold: 9  Epoch: 277  Training loss = 2.6658  Validation loss = 10.2979  \n",
      "\n",
      "Fold: 9  Epoch: 278  Training loss = 2.6656  Validation loss = 10.2975  \n",
      "\n",
      "Fold: 9  Epoch: 279  Training loss = 2.6654  Validation loss = 10.2971  \n",
      "\n",
      "Fold: 9  Epoch: 280  Training loss = 2.6652  Validation loss = 10.2967  \n",
      "\n",
      "Fold: 9  Epoch: 281  Training loss = 2.6650  Validation loss = 10.2963  \n",
      "\n",
      "Fold: 9  Epoch: 282  Training loss = 2.6647  Validation loss = 10.2959  \n",
      "\n",
      "Fold: 9  Epoch: 283  Training loss = 2.6645  Validation loss = 10.2954  \n",
      "\n",
      "Fold: 9  Epoch: 284  Training loss = 2.6642  Validation loss = 10.2949  \n",
      "\n",
      "Fold: 9  Epoch: 285  Training loss = 2.6641  Validation loss = 10.2946  \n",
      "\n",
      "Fold: 9  Epoch: 286  Training loss = 2.6638  Validation loss = 10.2941  \n",
      "\n",
      "Fold: 9  Epoch: 287  Training loss = 2.6636  Validation loss = 10.2936  \n",
      "\n",
      "Fold: 9  Epoch: 288  Training loss = 2.6633  Validation loss = 10.2932  \n",
      "\n",
      "Fold: 9  Epoch: 289  Training loss = 2.6631  Validation loss = 10.2927  \n",
      "\n",
      "Fold: 9  Epoch: 290  Training loss = 2.6628  Validation loss = 10.2921  \n",
      "\n",
      "Fold: 9  Epoch: 291  Training loss = 2.6625  Validation loss = 10.2916  \n",
      "\n",
      "Fold: 9  Epoch: 292  Training loss = 2.6624  Validation loss = 10.2913  \n",
      "\n",
      "Fold: 9  Epoch: 293  Training loss = 2.6621  Validation loss = 10.2909  \n",
      "\n",
      "Fold: 9  Epoch: 294  Training loss = 2.6620  Validation loss = 10.2906  \n",
      "\n",
      "Fold: 9  Epoch: 295  Training loss = 2.6616  Validation loss = 10.2899  \n",
      "\n",
      "Fold: 9  Epoch: 296  Training loss = 2.6614  Validation loss = 10.2896  \n",
      "\n",
      "Fold: 9  Epoch: 297  Training loss = 2.6612  Validation loss = 10.2892  \n",
      "\n",
      "Fold: 9  Epoch: 298  Training loss = 2.6609  Validation loss = 10.2886  \n",
      "\n",
      "Fold: 9  Epoch: 299  Training loss = 2.6607  Validation loss = 10.2881  \n",
      "\n",
      "Fold: 9  Epoch: 300  Training loss = 2.6605  Validation loss = 10.2877  \n",
      "\n",
      "Fold: 9  Epoch: 301  Training loss = 2.6602  Validation loss = 10.2873  \n",
      "\n",
      "Fold: 9  Epoch: 302  Training loss = 2.6601  Validation loss = 10.2870  \n",
      "\n",
      "Fold: 9  Epoch: 303  Training loss = 2.6598  Validation loss = 10.2865  \n",
      "\n",
      "Fold: 9  Epoch: 304  Training loss = 2.6596  Validation loss = 10.2861  \n",
      "\n",
      "Fold: 9  Epoch: 305  Training loss = 2.6594  Validation loss = 10.2856  \n",
      "\n",
      "Fold: 9  Epoch: 306  Training loss = 2.6591  Validation loss = 10.2851  \n",
      "\n",
      "Fold: 9  Epoch: 307  Training loss = 2.6589  Validation loss = 10.2848  \n",
      "\n",
      "Fold: 9  Epoch: 308  Training loss = 2.6587  Validation loss = 10.2844  \n",
      "\n",
      "Fold: 9  Epoch: 309  Training loss = 2.6584  Validation loss = 10.2838  \n",
      "\n",
      "Fold: 9  Epoch: 310  Training loss = 2.6582  Validation loss = 10.2834  \n",
      "\n",
      "Fold: 9  Epoch: 311  Training loss = 2.6580  Validation loss = 10.2830  \n",
      "\n",
      "Fold: 9  Epoch: 312  Training loss = 2.6577  Validation loss = 10.2824  \n",
      "\n",
      "Fold: 9  Epoch: 313  Training loss = 2.6575  Validation loss = 10.2821  \n",
      "\n",
      "Fold: 9  Epoch: 314  Training loss = 2.6572  Validation loss = 10.2815  \n",
      "\n",
      "Fold: 9  Epoch: 315  Training loss = 2.6569  Validation loss = 10.2810  \n",
      "\n",
      "Fold: 9  Epoch: 316  Training loss = 2.6567  Validation loss = 10.2805  \n",
      "\n",
      "Fold: 9  Epoch: 317  Training loss = 2.6565  Validation loss = 10.2801  \n",
      "\n",
      "Fold: 9  Epoch: 318  Training loss = 2.6562  Validation loss = 10.2796  \n",
      "\n",
      "Fold: 9  Epoch: 319  Training loss = 2.6560  Validation loss = 10.2793  \n",
      "\n",
      "Fold: 9  Epoch: 320  Training loss = 2.6558  Validation loss = 10.2788  \n",
      "\n",
      "Fold: 9  Epoch: 321  Training loss = 2.6556  Validation loss = 10.2785  \n",
      "\n",
      "Fold: 9  Epoch: 322  Training loss = 2.6554  Validation loss = 10.2782  \n",
      "\n",
      "Fold: 9  Epoch: 323  Training loss = 2.6553  Validation loss = 10.2778  \n",
      "\n",
      "Fold: 9  Epoch: 324  Training loss = 2.6550  Validation loss = 10.2773  \n",
      "\n",
      "Fold: 9  Epoch: 325  Training loss = 2.6547  Validation loss = 10.2768  \n",
      "\n",
      "Fold: 9  Epoch: 326  Training loss = 2.6544  Validation loss = 10.2762  \n",
      "\n",
      "Fold: 9  Epoch: 327  Training loss = 2.6542  Validation loss = 10.2759  \n",
      "\n",
      "Fold: 9  Epoch: 328  Training loss = 2.6540  Validation loss = 10.2754  \n",
      "\n",
      "Fold: 9  Epoch: 329  Training loss = 2.6537  Validation loss = 10.2749  \n",
      "\n",
      "Fold: 9  Epoch: 330  Training loss = 2.6534  Validation loss = 10.2744  \n",
      "\n",
      "Fold: 9  Epoch: 331  Training loss = 2.6532  Validation loss = 10.2739  \n",
      "\n",
      "Fold: 9  Epoch: 332  Training loss = 2.6530  Validation loss = 10.2735  \n",
      "\n",
      "Fold: 9  Epoch: 333  Training loss = 2.6528  Validation loss = 10.2731  \n",
      "\n",
      "Fold: 9  Epoch: 334  Training loss = 2.6526  Validation loss = 10.2727  \n",
      "\n",
      "Fold: 9  Epoch: 335  Training loss = 2.6524  Validation loss = 10.2723  \n",
      "\n",
      "Fold: 9  Epoch: 336  Training loss = 2.6522  Validation loss = 10.2719  \n",
      "\n",
      "Fold: 9  Epoch: 337  Training loss = 2.6518  Validation loss = 10.2713  \n",
      "\n",
      "Fold: 9  Epoch: 338  Training loss = 2.6516  Validation loss = 10.2708  \n",
      "\n",
      "Fold: 9  Epoch: 339  Training loss = 2.6514  Validation loss = 10.2704  \n",
      "\n",
      "Fold: 9  Epoch: 340  Training loss = 2.6512  Validation loss = 10.2700  \n",
      "\n",
      "Fold: 9  Epoch: 341  Training loss = 2.6509  Validation loss = 10.2696  \n",
      "\n",
      "Fold: 9  Epoch: 342  Training loss = 2.6507  Validation loss = 10.2691  \n",
      "\n",
      "Fold: 9  Epoch: 343  Training loss = 2.6505  Validation loss = 10.2688  \n",
      "\n",
      "Fold: 9  Epoch: 344  Training loss = 2.6502  Validation loss = 10.2682  \n",
      "\n",
      "Fold: 9  Epoch: 345  Training loss = 2.6499  Validation loss = 10.2676  \n",
      "\n",
      "Fold: 9  Epoch: 346  Training loss = 2.6497  Validation loss = 10.2671  \n",
      "\n",
      "Fold: 9  Epoch: 347  Training loss = 2.6495  Validation loss = 10.2668  \n",
      "\n",
      "Fold: 9  Epoch: 348  Training loss = 2.6492  Validation loss = 10.2663  \n",
      "\n",
      "Fold: 9  Epoch: 349  Training loss = 2.6490  Validation loss = 10.2659  \n",
      "\n",
      "Fold: 9  Epoch: 350  Training loss = 2.6488  Validation loss = 10.2656  \n",
      "\n",
      "Fold: 9  Epoch: 351  Training loss = 2.6486  Validation loss = 10.2651  \n",
      "\n",
      "Fold: 9  Epoch: 352  Training loss = 2.6485  Validation loss = 10.2648  \n",
      "\n",
      "Fold: 9  Epoch: 353  Training loss = 2.6482  Validation loss = 10.2643  \n",
      "\n",
      "Fold: 9  Epoch: 354  Training loss = 2.6480  Validation loss = 10.2640  \n",
      "\n",
      "Fold: 9  Epoch: 355  Training loss = 2.6478  Validation loss = 10.2636  \n",
      "\n",
      "Fold: 9  Epoch: 356  Training loss = 2.6476  Validation loss = 10.2632  \n",
      "\n",
      "Fold: 9  Epoch: 357  Training loss = 2.6474  Validation loss = 10.2628  \n",
      "\n",
      "Fold: 9  Epoch: 358  Training loss = 2.6472  Validation loss = 10.2624  \n",
      "\n",
      "Fold: 9  Epoch: 359  Training loss = 2.6470  Validation loss = 10.2619  \n",
      "\n",
      "Fold: 9  Epoch: 360  Training loss = 2.6466  Validation loss = 10.2613  \n",
      "\n",
      "Fold: 9  Epoch: 361  Training loss = 2.6465  Validation loss = 10.2610  \n",
      "\n",
      "Fold: 9  Epoch: 362  Training loss = 2.6462  Validation loss = 10.2605  \n",
      "\n",
      "Fold: 9  Epoch: 363  Training loss = 2.6459  Validation loss = 10.2600  \n",
      "\n",
      "Fold: 9  Epoch: 364  Training loss = 2.6457  Validation loss = 10.2595  \n",
      "\n",
      "Fold: 9  Epoch: 365  Training loss = 2.6454  Validation loss = 10.2590  \n",
      "\n",
      "Fold: 9  Epoch: 366  Training loss = 2.6452  Validation loss = 10.2585  \n",
      "\n",
      "Fold: 9  Epoch: 367  Training loss = 2.6450  Validation loss = 10.2582  \n",
      "\n",
      "Fold: 9  Epoch: 368  Training loss = 2.6448  Validation loss = 10.2578  \n",
      "\n",
      "Fold: 9  Epoch: 369  Training loss = 2.6445  Validation loss = 10.2573  \n",
      "\n",
      "Fold: 9  Epoch: 370  Training loss = 2.6443  Validation loss = 10.2568  \n",
      "\n",
      "Fold: 9  Epoch: 371  Training loss = 2.6441  Validation loss = 10.2564  \n",
      "\n",
      "Fold: 9  Epoch: 372  Training loss = 2.6438  Validation loss = 10.2559  \n",
      "\n",
      "Fold: 9  Epoch: 373  Training loss = 2.6436  Validation loss = 10.2555  \n",
      "\n",
      "Fold: 9  Epoch: 374  Training loss = 2.6434  Validation loss = 10.2551  \n",
      "\n",
      "Fold: 9  Epoch: 375  Training loss = 2.6432  Validation loss = 10.2548  \n",
      "\n",
      "Fold: 9  Epoch: 376  Training loss = 2.6430  Validation loss = 10.2543  \n",
      "\n",
      "Fold: 9  Epoch: 377  Training loss = 2.6427  Validation loss = 10.2538  \n",
      "\n",
      "Fold: 9  Epoch: 378  Training loss = 2.6425  Validation loss = 10.2534  \n",
      "\n",
      "Fold: 9  Epoch: 379  Training loss = 2.6423  Validation loss = 10.2530  \n",
      "\n",
      "Fold: 9  Epoch: 380  Training loss = 2.6421  Validation loss = 10.2525  \n",
      "\n",
      "Fold: 9  Epoch: 381  Training loss = 2.6418  Validation loss = 10.2521  \n",
      "\n",
      "Fold: 9  Epoch: 382  Training loss = 2.6416  Validation loss = 10.2517  \n",
      "\n",
      "Fold: 9  Epoch: 383  Training loss = 2.6415  Validation loss = 10.2514  \n",
      "\n",
      "Fold: 9  Epoch: 384  Training loss = 2.6412  Validation loss = 10.2510  \n",
      "\n",
      "Fold: 9  Epoch: 385  Training loss = 2.6410  Validation loss = 10.2505  \n",
      "\n",
      "Fold: 9  Epoch: 386  Training loss = 2.6408  Validation loss = 10.2501  \n",
      "\n",
      "Fold: 9  Epoch: 387  Training loss = 2.6405  Validation loss = 10.2496  \n",
      "\n",
      "Fold: 9  Epoch: 388  Training loss = 2.6403  Validation loss = 10.2491  \n",
      "\n",
      "Fold: 9  Epoch: 389  Training loss = 2.6401  Validation loss = 10.2488  \n",
      "\n",
      "Fold: 9  Epoch: 390  Training loss = 2.6399  Validation loss = 10.2483  \n",
      "\n",
      "Fold: 9  Epoch: 391  Training loss = 2.6397  Validation loss = 10.2479  \n",
      "\n",
      "Fold: 9  Epoch: 392  Training loss = 2.6394  Validation loss = 10.2475  \n",
      "\n",
      "Fold: 9  Epoch: 393  Training loss = 2.6393  Validation loss = 10.2472  \n",
      "\n",
      "Fold: 9  Epoch: 394  Training loss = 2.6390  Validation loss = 10.2467  \n",
      "\n",
      "Fold: 9  Epoch: 395  Training loss = 2.6388  Validation loss = 10.2462  \n",
      "\n",
      "Fold: 9  Epoch: 396  Training loss = 2.6386  Validation loss = 10.2458  \n",
      "\n",
      "Fold: 9  Epoch: 397  Training loss = 2.6383  Validation loss = 10.2452  \n",
      "\n",
      "Fold: 9  Epoch: 398  Training loss = 2.6380  Validation loss = 10.2447  \n",
      "\n",
      "Fold: 9  Epoch: 399  Training loss = 2.6378  Validation loss = 10.2443  \n",
      "\n",
      "Fold: 9  Epoch: 400  Training loss = 2.6376  Validation loss = 10.2439  \n",
      "\n",
      "Fold: 9  Epoch: 401  Training loss = 2.6373  Validation loss = 10.2434  \n",
      "\n",
      "Fold: 9  Epoch: 402  Training loss = 2.6371  Validation loss = 10.2430  \n",
      "\n",
      "Fold: 9  Epoch: 403  Training loss = 2.6368  Validation loss = 10.2424  \n",
      "\n",
      "Fold: 9  Epoch: 404  Training loss = 2.6365  Validation loss = 10.2418  \n",
      "\n",
      "Fold: 9  Epoch: 405  Training loss = 2.6363  Validation loss = 10.2413  \n",
      "\n",
      "Fold: 9  Epoch: 406  Training loss = 2.6361  Validation loss = 10.2409  \n",
      "\n",
      "Fold: 9  Epoch: 407  Training loss = 2.6358  Validation loss = 10.2405  \n",
      "\n",
      "Fold: 9  Epoch: 408  Training loss = 2.6356  Validation loss = 10.2401  \n",
      "\n",
      "Fold: 9  Epoch: 409  Training loss = 2.6353  Validation loss = 10.2395  \n",
      "\n",
      "Fold: 9  Epoch: 410  Training loss = 2.6351  Validation loss = 10.2390  \n",
      "\n",
      "Fold: 9  Epoch: 411  Training loss = 2.6348  Validation loss = 10.2385  \n",
      "\n",
      "Fold: 9  Epoch: 412  Training loss = 2.6345  Validation loss = 10.2380  \n",
      "\n",
      "Fold: 9  Epoch: 413  Training loss = 2.6344  Validation loss = 10.2376  \n",
      "\n",
      "Fold: 9  Epoch: 414  Training loss = 2.6342  Validation loss = 10.2373  \n",
      "\n",
      "Fold: 9  Epoch: 415  Training loss = 2.6340  Validation loss = 10.2369  \n",
      "\n",
      "Fold: 9  Epoch: 416  Training loss = 2.6337  Validation loss = 10.2364  \n",
      "\n",
      "Fold: 9  Epoch: 417  Training loss = 2.6336  Validation loss = 10.2362  \n",
      "\n",
      "Fold: 9  Epoch: 418  Training loss = 2.6334  Validation loss = 10.2358  \n",
      "\n",
      "Fold: 9  Epoch: 419  Training loss = 2.6332  Validation loss = 10.2353  \n",
      "\n",
      "Fold: 9  Epoch: 420  Training loss = 2.6330  Validation loss = 10.2350  \n",
      "\n",
      "Fold: 9  Epoch: 421  Training loss = 2.6328  Validation loss = 10.2346  \n",
      "\n",
      "Fold: 9  Epoch: 422  Training loss = 2.6326  Validation loss = 10.2342  \n",
      "\n",
      "Fold: 9  Epoch: 423  Training loss = 2.6324  Validation loss = 10.2338  \n",
      "\n",
      "Fold: 9  Epoch: 424  Training loss = 2.6322  Validation loss = 10.2334  \n",
      "\n",
      "Fold: 9  Epoch: 425  Training loss = 2.6320  Validation loss = 10.2331  \n",
      "\n",
      "Fold: 9  Epoch: 426  Training loss = 2.6318  Validation loss = 10.2328  \n",
      "\n",
      "Fold: 9  Epoch: 427  Training loss = 2.6316  Validation loss = 10.2323  \n",
      "\n",
      "Fold: 9  Epoch: 428  Training loss = 2.6314  Validation loss = 10.2319  \n",
      "\n",
      "Fold: 9  Epoch: 429  Training loss = 2.6311  Validation loss = 10.2313  \n",
      "\n",
      "Fold: 9  Epoch: 430  Training loss = 2.6309  Validation loss = 10.2309  \n",
      "\n",
      "Fold: 9  Epoch: 431  Training loss = 2.6306  Validation loss = 10.2303  \n",
      "\n",
      "Fold: 9  Epoch: 432  Training loss = 2.6304  Validation loss = 10.2300  \n",
      "\n",
      "Fold: 9  Epoch: 433  Training loss = 2.6301  Validation loss = 10.2295  \n",
      "\n",
      "Fold: 9  Epoch: 434  Training loss = 2.6299  Validation loss = 10.2290  \n",
      "\n",
      "Fold: 9  Epoch: 435  Training loss = 2.6298  Validation loss = 10.2287  \n",
      "\n",
      "Fold: 9  Epoch: 436  Training loss = 2.6295  Validation loss = 10.2283  \n",
      "\n",
      "Fold: 9  Epoch: 437  Training loss = 2.6293  Validation loss = 10.2279  \n",
      "\n",
      "Fold: 9  Epoch: 438  Training loss = 2.6290  Validation loss = 10.2273  \n",
      "\n",
      "Fold: 9  Epoch: 439  Training loss = 2.6288  Validation loss = 10.2269  \n",
      "\n",
      "Fold: 9  Epoch: 440  Training loss = 2.6286  Validation loss = 10.2265  \n",
      "\n",
      "Fold: 9  Epoch: 441  Training loss = 2.6284  Validation loss = 10.2261  \n",
      "\n",
      "Fold: 9  Epoch: 442  Training loss = 2.6282  Validation loss = 10.2257  \n",
      "\n",
      "Fold: 9  Epoch: 443  Training loss = 2.6280  Validation loss = 10.2254  \n",
      "\n",
      "Fold: 9  Epoch: 444  Training loss = 2.6278  Validation loss = 10.2250  \n",
      "\n",
      "Fold: 9  Epoch: 445  Training loss = 2.6276  Validation loss = 10.2245  \n",
      "\n",
      "Fold: 9  Epoch: 446  Training loss = 2.6274  Validation loss = 10.2242  \n",
      "\n",
      "Fold: 9  Epoch: 447  Training loss = 2.6272  Validation loss = 10.2237  \n",
      "\n",
      "Fold: 9  Epoch: 448  Training loss = 2.6269  Validation loss = 10.2232  \n",
      "\n",
      "Fold: 9  Epoch: 449  Training loss = 2.6267  Validation loss = 10.2227  \n",
      "\n",
      "Fold: 9  Epoch: 450  Training loss = 2.6265  Validation loss = 10.2224  \n",
      "\n",
      "Fold: 9  Epoch: 451  Training loss = 2.6263  Validation loss = 10.2221  \n",
      "\n",
      "Fold: 9  Epoch: 452  Training loss = 2.6261  Validation loss = 10.2216  \n",
      "\n",
      "Fold: 9  Epoch: 453  Training loss = 2.6259  Validation loss = 10.2212  \n",
      "\n",
      "Fold: 9  Epoch: 454  Training loss = 2.6257  Validation loss = 10.2207  \n",
      "\n",
      "Fold: 9  Epoch: 455  Training loss = 2.6253  Validation loss = 10.2200  \n",
      "\n",
      "Fold: 9  Epoch: 456  Training loss = 2.6251  Validation loss = 10.2197  \n",
      "\n",
      "Fold: 9  Epoch: 457  Training loss = 2.6249  Validation loss = 10.2192  \n",
      "\n",
      "Fold: 9  Epoch: 458  Training loss = 2.6247  Validation loss = 10.2188  \n",
      "\n",
      "Fold: 9  Epoch: 459  Training loss = 2.6245  Validation loss = 10.2184  \n",
      "\n",
      "Fold: 9  Epoch: 460  Training loss = 2.6243  Validation loss = 10.2181  \n",
      "\n",
      "Fold: 9  Epoch: 461  Training loss = 2.6240  Validation loss = 10.2176  \n",
      "\n",
      "Fold: 9  Epoch: 462  Training loss = 2.6238  Validation loss = 10.2172  \n",
      "\n",
      "Fold: 9  Epoch: 463  Training loss = 2.6236  Validation loss = 10.2167  \n",
      "\n",
      "Fold: 9  Epoch: 464  Training loss = 2.6234  Validation loss = 10.2164  \n",
      "\n",
      "Fold: 9  Epoch: 465  Training loss = 2.6232  Validation loss = 10.2159  \n",
      "\n",
      "Fold: 9  Epoch: 466  Training loss = 2.6230  Validation loss = 10.2155  \n",
      "\n",
      "Fold: 9  Epoch: 467  Training loss = 2.6228  Validation loss = 10.2151  \n",
      "\n",
      "Fold: 9  Epoch: 468  Training loss = 2.6225  Validation loss = 10.2146  \n",
      "\n",
      "Fold: 9  Epoch: 469  Training loss = 2.6223  Validation loss = 10.2142  \n",
      "\n",
      "Fold: 9  Epoch: 470  Training loss = 2.6221  Validation loss = 10.2138  \n",
      "\n",
      "Fold: 9  Epoch: 471  Training loss = 2.6219  Validation loss = 10.2134  \n",
      "\n",
      "Fold: 9  Epoch: 472  Training loss = 2.6216  Validation loss = 10.2129  \n",
      "\n",
      "Fold: 9  Epoch: 473  Training loss = 2.6214  Validation loss = 10.2125  \n",
      "\n",
      "Fold: 9  Epoch: 474  Training loss = 2.6212  Validation loss = 10.2121  \n",
      "\n",
      "Fold: 9  Epoch: 475  Training loss = 2.6210  Validation loss = 10.2116  \n",
      "\n",
      "Fold: 9  Epoch: 476  Training loss = 2.6208  Validation loss = 10.2113  \n",
      "\n",
      "Fold: 9  Epoch: 477  Training loss = 2.6206  Validation loss = 10.2108  \n",
      "\n",
      "Fold: 9  Epoch: 478  Training loss = 2.6204  Validation loss = 10.2105  \n",
      "\n",
      "Fold: 9  Epoch: 479  Training loss = 2.6202  Validation loss = 10.2100  \n",
      "\n",
      "Fold: 9  Epoch: 480  Training loss = 2.6200  Validation loss = 10.2097  \n",
      "\n",
      "Fold: 9  Epoch: 481  Training loss = 2.6199  Validation loss = 10.2094  \n",
      "\n",
      "Fold: 9  Epoch: 482  Training loss = 2.6196  Validation loss = 10.2089  \n",
      "\n",
      "Fold: 9  Epoch: 483  Training loss = 2.6193  Validation loss = 10.2083  \n",
      "\n",
      "Fold: 9  Epoch: 484  Training loss = 2.6190  Validation loss = 10.2078  \n",
      "\n",
      "Fold: 9  Epoch: 485  Training loss = 2.6189  Validation loss = 10.2075  \n",
      "\n",
      "Fold: 9  Epoch: 486  Training loss = 2.6186  Validation loss = 10.2070  \n",
      "\n",
      "Fold: 9  Epoch: 487  Training loss = 2.6185  Validation loss = 10.2067  \n",
      "\n",
      "Fold: 9  Epoch: 488  Training loss = 2.6182  Validation loss = 10.2062  \n",
      "\n",
      "Fold: 9  Epoch: 489  Training loss = 2.6180  Validation loss = 10.2058  \n",
      "\n",
      "Fold: 9  Epoch: 490  Training loss = 2.6178  Validation loss = 10.2054  \n",
      "\n",
      "Fold: 9  Epoch: 491  Training loss = 2.6176  Validation loss = 10.2050  \n",
      "\n",
      "Fold: 9  Epoch: 492  Training loss = 2.6174  Validation loss = 10.2047  \n",
      "\n",
      "Fold: 9  Epoch: 493  Training loss = 2.6172  Validation loss = 10.2042  \n",
      "\n",
      "Fold: 9  Epoch: 494  Training loss = 2.6171  Validation loss = 10.2039  \n",
      "\n",
      "Fold: 9  Epoch: 495  Training loss = 2.6169  Validation loss = 10.2035  \n",
      "\n",
      "Fold: 9  Epoch: 496  Training loss = 2.6167  Validation loss = 10.2031  \n",
      "\n",
      "Fold: 9  Epoch: 497  Training loss = 2.6164  Validation loss = 10.2026  \n",
      "\n",
      "Fold: 9  Epoch: 498  Training loss = 2.6162  Validation loss = 10.2022  \n",
      "\n",
      "Fold: 9  Epoch: 499  Training loss = 2.6160  Validation loss = 10.2018  \n",
      "\n",
      "Fold: 9  Epoch: 500  Training loss = 2.6158  Validation loss = 10.2015  \n",
      "\n",
      "Check model:  Fold: 9  Epoch: 500  Training loss = 2.6158  Validation loss = 10.2015  \n",
      "\n",
      "Fold: 10  Epoch: 1  Training loss = 3.6120  Validation loss = 5.8473  \n",
      "\n",
      "Fold: 10  Epoch: 2  Training loss = 3.6116  Validation loss = 5.8469  \n",
      "\n",
      "Fold: 10  Epoch: 3  Training loss = 3.6114  Validation loss = 5.8465  \n",
      "\n",
      "Fold: 10  Epoch: 4  Training loss = 3.6110  Validation loss = 5.8461  \n",
      "\n",
      "Fold: 10  Epoch: 5  Training loss = 3.6108  Validation loss = 5.8457  \n",
      "\n",
      "Fold: 10  Epoch: 6  Training loss = 3.6106  Validation loss = 5.8454  \n",
      "\n",
      "Fold: 10  Epoch: 7  Training loss = 3.6102  Validation loss = 5.8449  \n",
      "\n",
      "Fold: 10  Epoch: 8  Training loss = 3.6099  Validation loss = 5.8445  \n",
      "\n",
      "Fold: 10  Epoch: 9  Training loss = 3.6095  Validation loss = 5.8440  \n",
      "\n",
      "Fold: 10  Epoch: 10  Training loss = 3.6092  Validation loss = 5.8436  \n",
      "\n",
      "Fold: 10  Epoch: 11  Training loss = 3.6089  Validation loss = 5.8431  \n",
      "\n",
      "Fold: 10  Epoch: 12  Training loss = 3.6086  Validation loss = 5.8428  \n",
      "\n",
      "Fold: 10  Epoch: 13  Training loss = 3.6083  Validation loss = 5.8424  \n",
      "\n",
      "Fold: 10  Epoch: 14  Training loss = 3.6080  Validation loss = 5.8420  \n",
      "\n",
      "Fold: 10  Epoch: 15  Training loss = 3.6076  Validation loss = 5.8415  \n",
      "\n",
      "Fold: 10  Epoch: 16  Training loss = 3.6074  Validation loss = 5.8410  \n",
      "\n",
      "Fold: 10  Epoch: 17  Training loss = 3.6070  Validation loss = 5.8405  \n",
      "\n",
      "Fold: 10  Epoch: 18  Training loss = 3.6066  Validation loss = 5.8400  \n",
      "\n",
      "Fold: 10  Epoch: 19  Training loss = 3.6063  Validation loss = 5.8396  \n",
      "\n",
      "Fold: 10  Epoch: 20  Training loss = 3.6059  Validation loss = 5.8391  \n",
      "\n",
      "Fold: 10  Epoch: 21  Training loss = 3.6056  Validation loss = 5.8387  \n",
      "\n",
      "Fold: 10  Epoch: 22  Training loss = 3.6053  Validation loss = 5.8382  \n",
      "\n",
      "Fold: 10  Epoch: 23  Training loss = 3.6050  Validation loss = 5.8379  \n",
      "\n",
      "Fold: 10  Epoch: 24  Training loss = 3.6046  Validation loss = 5.8372  \n",
      "\n",
      "Fold: 10  Epoch: 25  Training loss = 3.6042  Validation loss = 5.8367  \n",
      "\n",
      "Fold: 10  Epoch: 26  Training loss = 3.6040  Validation loss = 5.8364  \n",
      "\n",
      "Fold: 10  Epoch: 27  Training loss = 3.6036  Validation loss = 5.8359  \n",
      "\n",
      "Fold: 10  Epoch: 28  Training loss = 3.6033  Validation loss = 5.8353  \n",
      "\n",
      "Fold: 10  Epoch: 29  Training loss = 3.6031  Validation loss = 5.8350  \n",
      "\n",
      "Fold: 10  Epoch: 30  Training loss = 3.6028  Validation loss = 5.8347  \n",
      "\n",
      "Fold: 10  Epoch: 31  Training loss = 3.6026  Validation loss = 5.8344  \n",
      "\n",
      "Fold: 10  Epoch: 32  Training loss = 3.6023  Validation loss = 5.8340  \n",
      "\n",
      "Fold: 10  Epoch: 33  Training loss = 3.6020  Validation loss = 5.8335  \n",
      "\n",
      "Fold: 10  Epoch: 34  Training loss = 3.6017  Validation loss = 5.8331  \n",
      "\n",
      "Fold: 10  Epoch: 35  Training loss = 3.6015  Validation loss = 5.8328  \n",
      "\n",
      "Fold: 10  Epoch: 36  Training loss = 3.6011  Validation loss = 5.8323  \n",
      "\n",
      "Fold: 10  Epoch: 37  Training loss = 3.6009  Validation loss = 5.8320  \n",
      "\n",
      "Fold: 10  Epoch: 38  Training loss = 3.6006  Validation loss = 5.8316  \n",
      "\n",
      "Fold: 10  Epoch: 39  Training loss = 3.6002  Validation loss = 5.8311  \n",
      "\n",
      "Fold: 10  Epoch: 40  Training loss = 3.5999  Validation loss = 5.8307  \n",
      "\n",
      "Fold: 10  Epoch: 41  Training loss = 3.5996  Validation loss = 5.8303  \n",
      "\n",
      "Fold: 10  Epoch: 42  Training loss = 3.5994  Validation loss = 5.8300  \n",
      "\n",
      "Fold: 10  Epoch: 43  Training loss = 3.5991  Validation loss = 5.8295  \n",
      "\n",
      "Fold: 10  Epoch: 44  Training loss = 3.5988  Validation loss = 5.8291  \n",
      "\n",
      "Fold: 10  Epoch: 45  Training loss = 3.5984  Validation loss = 5.8286  \n",
      "\n",
      "Fold: 10  Epoch: 46  Training loss = 3.5980  Validation loss = 5.8281  \n",
      "\n",
      "Fold: 10  Epoch: 47  Training loss = 3.5977  Validation loss = 5.8276  \n",
      "\n",
      "Fold: 10  Epoch: 48  Training loss = 3.5973  Validation loss = 5.8272  \n",
      "\n",
      "Fold: 10  Epoch: 49  Training loss = 3.5970  Validation loss = 5.8267  \n",
      "\n",
      "Fold: 10  Epoch: 50  Training loss = 3.5967  Validation loss = 5.8263  \n",
      "\n",
      "Fold: 10  Epoch: 51  Training loss = 3.5963  Validation loss = 5.8257  \n",
      "\n",
      "Fold: 10  Epoch: 52  Training loss = 3.5960  Validation loss = 5.8252  \n",
      "\n",
      "Fold: 10  Epoch: 53  Training loss = 3.5956  Validation loss = 5.8248  \n",
      "\n",
      "Fold: 10  Epoch: 54  Training loss = 3.5953  Validation loss = 5.8243  \n",
      "\n",
      "Fold: 10  Epoch: 55  Training loss = 3.5950  Validation loss = 5.8239  \n",
      "\n",
      "Fold: 10  Epoch: 56  Training loss = 3.5946  Validation loss = 5.8233  \n",
      "\n",
      "Fold: 10  Epoch: 57  Training loss = 3.5943  Validation loss = 5.8229  \n",
      "\n",
      "Fold: 10  Epoch: 58  Training loss = 3.5940  Validation loss = 5.8224  \n",
      "\n",
      "Fold: 10  Epoch: 59  Training loss = 3.5938  Validation loss = 5.8220  \n",
      "\n",
      "Fold: 10  Epoch: 60  Training loss = 3.5934  Validation loss = 5.8215  \n",
      "\n",
      "Fold: 10  Epoch: 61  Training loss = 3.5931  Validation loss = 5.8211  \n",
      "\n",
      "Fold: 10  Epoch: 62  Training loss = 3.5928  Validation loss = 5.8206  \n",
      "\n",
      "Fold: 10  Epoch: 63  Training loss = 3.5925  Validation loss = 5.8202  \n",
      "\n",
      "Fold: 10  Epoch: 64  Training loss = 3.5922  Validation loss = 5.8197  \n",
      "\n",
      "Fold: 10  Epoch: 65  Training loss = 3.5919  Validation loss = 5.8193  \n",
      "\n",
      "Fold: 10  Epoch: 66  Training loss = 3.5916  Validation loss = 5.8187  \n",
      "\n",
      "Fold: 10  Epoch: 67  Training loss = 3.5913  Validation loss = 5.8184  \n",
      "\n",
      "Fold: 10  Epoch: 68  Training loss = 3.5910  Validation loss = 5.8179  \n",
      "\n",
      "Fold: 10  Epoch: 69  Training loss = 3.5906  Validation loss = 5.8173  \n",
      "\n",
      "Fold: 10  Epoch: 70  Training loss = 3.5903  Validation loss = 5.8169  \n",
      "\n",
      "Fold: 10  Epoch: 71  Training loss = 3.5898  Validation loss = 5.8162  \n",
      "\n",
      "Fold: 10  Epoch: 72  Training loss = 3.5895  Validation loss = 5.8158  \n",
      "\n",
      "Fold: 10  Epoch: 73  Training loss = 3.5893  Validation loss = 5.8155  \n",
      "\n",
      "Fold: 10  Epoch: 74  Training loss = 3.5889  Validation loss = 5.8149  \n",
      "\n",
      "Fold: 10  Epoch: 75  Training loss = 3.5886  Validation loss = 5.8144  \n",
      "\n",
      "Fold: 10  Epoch: 76  Training loss = 3.5882  Validation loss = 5.8139  \n",
      "\n",
      "Fold: 10  Epoch: 77  Training loss = 3.5879  Validation loss = 5.8134  \n",
      "\n",
      "Fold: 10  Epoch: 78  Training loss = 3.5876  Validation loss = 5.8130  \n",
      "\n",
      "Fold: 10  Epoch: 79  Training loss = 3.5874  Validation loss = 5.8127  \n",
      "\n",
      "Fold: 10  Epoch: 80  Training loss = 3.5872  Validation loss = 5.8124  \n",
      "\n",
      "Fold: 10  Epoch: 81  Training loss = 3.5869  Validation loss = 5.8120  \n",
      "\n",
      "Fold: 10  Epoch: 82  Training loss = 3.5866  Validation loss = 5.8115  \n",
      "\n",
      "Fold: 10  Epoch: 83  Training loss = 3.5863  Validation loss = 5.8110  \n",
      "\n",
      "Fold: 10  Epoch: 84  Training loss = 3.5860  Validation loss = 5.8106  \n",
      "\n",
      "Fold: 10  Epoch: 85  Training loss = 3.5857  Validation loss = 5.8101  \n",
      "\n",
      "Fold: 10  Epoch: 86  Training loss = 3.5853  Validation loss = 5.8096  \n",
      "\n",
      "Fold: 10  Epoch: 87  Training loss = 3.5850  Validation loss = 5.8092  \n",
      "\n",
      "Fold: 10  Epoch: 88  Training loss = 3.5847  Validation loss = 5.8088  \n",
      "\n",
      "Fold: 10  Epoch: 89  Training loss = 3.5844  Validation loss = 5.8084  \n",
      "\n",
      "Fold: 10  Epoch: 90  Training loss = 3.5841  Validation loss = 5.8080  \n",
      "\n",
      "Fold: 10  Epoch: 91  Training loss = 3.5839  Validation loss = 5.8077  \n",
      "\n",
      "Fold: 10  Epoch: 92  Training loss = 3.5835  Validation loss = 5.8071  \n",
      "\n",
      "Fold: 10  Epoch: 93  Training loss = 3.5831  Validation loss = 5.8067  \n",
      "\n",
      "Fold: 10  Epoch: 94  Training loss = 3.5827  Validation loss = 5.8061  \n",
      "\n",
      "Fold: 10  Epoch: 95  Training loss = 3.5824  Validation loss = 5.8056  \n",
      "\n",
      "Fold: 10  Epoch: 96  Training loss = 3.5821  Validation loss = 5.8052  \n",
      "\n",
      "Fold: 10  Epoch: 97  Training loss = 3.5816  Validation loss = 5.8046  \n",
      "\n",
      "Fold: 10  Epoch: 98  Training loss = 3.5813  Validation loss = 5.8042  \n",
      "\n",
      "Fold: 10  Epoch: 99  Training loss = 3.5809  Validation loss = 5.8036  \n",
      "\n",
      "Fold: 10  Epoch: 100  Training loss = 3.5805  Validation loss = 5.8031  \n",
      "\n",
      "Fold: 10  Epoch: 101  Training loss = 3.5802  Validation loss = 5.8026  \n",
      "\n",
      "Fold: 10  Epoch: 102  Training loss = 3.5799  Validation loss = 5.8021  \n",
      "\n",
      "Fold: 10  Epoch: 103  Training loss = 3.5796  Validation loss = 5.8017  \n",
      "\n",
      "Fold: 10  Epoch: 104  Training loss = 3.5794  Validation loss = 5.8014  \n",
      "\n",
      "Fold: 10  Epoch: 105  Training loss = 3.5791  Validation loss = 5.8010  \n",
      "\n",
      "Fold: 10  Epoch: 106  Training loss = 3.5789  Validation loss = 5.8007  \n",
      "\n",
      "Fold: 10  Epoch: 107  Training loss = 3.5785  Validation loss = 5.8001  \n",
      "\n",
      "Fold: 10  Epoch: 108  Training loss = 3.5780  Validation loss = 5.7995  \n",
      "\n",
      "Fold: 10  Epoch: 109  Training loss = 3.5778  Validation loss = 5.7991  \n",
      "\n",
      "Fold: 10  Epoch: 110  Training loss = 3.5775  Validation loss = 5.7987  \n",
      "\n",
      "Fold: 10  Epoch: 111  Training loss = 3.5771  Validation loss = 5.7982  \n",
      "\n",
      "Fold: 10  Epoch: 112  Training loss = 3.5768  Validation loss = 5.7978  \n",
      "\n",
      "Fold: 10  Epoch: 113  Training loss = 3.5766  Validation loss = 5.7974  \n",
      "\n",
      "Fold: 10  Epoch: 114  Training loss = 3.5763  Validation loss = 5.7970  \n",
      "\n",
      "Fold: 10  Epoch: 115  Training loss = 3.5759  Validation loss = 5.7964  \n",
      "\n",
      "Fold: 10  Epoch: 116  Training loss = 3.5756  Validation loss = 5.7960  \n",
      "\n",
      "Fold: 10  Epoch: 117  Training loss = 3.5753  Validation loss = 5.7956  \n",
      "\n",
      "Fold: 10  Epoch: 118  Training loss = 3.5750  Validation loss = 5.7952  \n",
      "\n",
      "Fold: 10  Epoch: 119  Training loss = 3.5747  Validation loss = 5.7947  \n",
      "\n",
      "Fold: 10  Epoch: 120  Training loss = 3.5744  Validation loss = 5.7942  \n",
      "\n",
      "Fold: 10  Epoch: 121  Training loss = 3.5741  Validation loss = 5.7939  \n",
      "\n",
      "Fold: 10  Epoch: 122  Training loss = 3.5737  Validation loss = 5.7932  \n",
      "\n",
      "Fold: 10  Epoch: 123  Training loss = 3.5733  Validation loss = 5.7927  \n",
      "\n",
      "Fold: 10  Epoch: 124  Training loss = 3.5731  Validation loss = 5.7924  \n",
      "\n",
      "Fold: 10  Epoch: 125  Training loss = 3.5727  Validation loss = 5.7918  \n",
      "\n",
      "Fold: 10  Epoch: 126  Training loss = 3.5723  Validation loss = 5.7912  \n",
      "\n",
      "Fold: 10  Epoch: 127  Training loss = 3.5720  Validation loss = 5.7907  \n",
      "\n",
      "Fold: 10  Epoch: 128  Training loss = 3.5716  Validation loss = 5.7901  \n",
      "\n",
      "Fold: 10  Epoch: 129  Training loss = 3.5713  Validation loss = 5.7896  \n",
      "\n",
      "Fold: 10  Epoch: 130  Training loss = 3.5709  Validation loss = 5.7890  \n",
      "\n",
      "Fold: 10  Epoch: 131  Training loss = 3.5706  Validation loss = 5.7885  \n",
      "\n",
      "Fold: 10  Epoch: 132  Training loss = 3.5703  Validation loss = 5.7881  \n",
      "\n",
      "Fold: 10  Epoch: 133  Training loss = 3.5701  Validation loss = 5.7877  \n",
      "\n",
      "Fold: 10  Epoch: 134  Training loss = 3.5698  Validation loss = 5.7874  \n",
      "\n",
      "Fold: 10  Epoch: 135  Training loss = 3.5695  Validation loss = 5.7870  \n",
      "\n",
      "Fold: 10  Epoch: 136  Training loss = 3.5692  Validation loss = 5.7865  \n",
      "\n",
      "Fold: 10  Epoch: 137  Training loss = 3.5689  Validation loss = 5.7862  \n",
      "\n",
      "Fold: 10  Epoch: 138  Training loss = 3.5686  Validation loss = 5.7857  \n",
      "\n",
      "Fold: 10  Epoch: 139  Training loss = 3.5682  Validation loss = 5.7850  \n",
      "\n",
      "Fold: 10  Epoch: 140  Training loss = 3.5678  Validation loss = 5.7844  \n",
      "\n",
      "Fold: 10  Epoch: 141  Training loss = 3.5674  Validation loss = 5.7837  \n",
      "\n",
      "Fold: 10  Epoch: 142  Training loss = 3.5671  Validation loss = 5.7833  \n",
      "\n",
      "Fold: 10  Epoch: 143  Training loss = 3.5668  Validation loss = 5.7828  \n",
      "\n",
      "Fold: 10  Epoch: 144  Training loss = 3.5665  Validation loss = 5.7825  \n",
      "\n",
      "Fold: 10  Epoch: 145  Training loss = 3.5662  Validation loss = 5.7821  \n",
      "\n",
      "Fold: 10  Epoch: 146  Training loss = 3.5659  Validation loss = 5.7816  \n",
      "\n",
      "Fold: 10  Epoch: 147  Training loss = 3.5655  Validation loss = 5.7812  \n",
      "\n",
      "Fold: 10  Epoch: 148  Training loss = 3.5652  Validation loss = 5.7806  \n",
      "\n",
      "Fold: 10  Epoch: 149  Training loss = 3.5649  Validation loss = 5.7803  \n",
      "\n",
      "Fold: 10  Epoch: 150  Training loss = 3.5646  Validation loss = 5.7798  \n",
      "\n",
      "Fold: 10  Epoch: 151  Training loss = 3.5642  Validation loss = 5.7793  \n",
      "\n",
      "Fold: 10  Epoch: 152  Training loss = 3.5640  Validation loss = 5.7788  \n",
      "\n",
      "Fold: 10  Epoch: 153  Training loss = 3.5637  Validation loss = 5.7784  \n",
      "\n",
      "Fold: 10  Epoch: 154  Training loss = 3.5634  Validation loss = 5.7780  \n",
      "\n",
      "Fold: 10  Epoch: 155  Training loss = 3.5631  Validation loss = 5.7775  \n",
      "\n",
      "Fold: 10  Epoch: 156  Training loss = 3.5628  Validation loss = 5.7770  \n",
      "\n",
      "Fold: 10  Epoch: 157  Training loss = 3.5623  Validation loss = 5.7763  \n",
      "\n",
      "Fold: 10  Epoch: 158  Training loss = 3.5619  Validation loss = 5.7758  \n",
      "\n",
      "Fold: 10  Epoch: 159  Training loss = 3.5615  Validation loss = 5.7752  \n",
      "\n",
      "Fold: 10  Epoch: 160  Training loss = 3.5613  Validation loss = 5.7749  \n",
      "\n",
      "Fold: 10  Epoch: 161  Training loss = 3.5610  Validation loss = 5.7744  \n",
      "\n",
      "Fold: 10  Epoch: 162  Training loss = 3.5607  Validation loss = 5.7741  \n",
      "\n",
      "Fold: 10  Epoch: 163  Training loss = 3.5605  Validation loss = 5.7737  \n",
      "\n",
      "Fold: 10  Epoch: 164  Training loss = 3.5601  Validation loss = 5.7733  \n",
      "\n",
      "Fold: 10  Epoch: 165  Training loss = 3.5598  Validation loss = 5.7728  \n",
      "\n",
      "Fold: 10  Epoch: 166  Training loss = 3.5594  Validation loss = 5.7722  \n",
      "\n",
      "Fold: 10  Epoch: 167  Training loss = 3.5590  Validation loss = 5.7717  \n",
      "\n",
      "Fold: 10  Epoch: 168  Training loss = 3.5587  Validation loss = 5.7712  \n",
      "\n",
      "Fold: 10  Epoch: 169  Training loss = 3.5584  Validation loss = 5.7707  \n",
      "\n",
      "Fold: 10  Epoch: 170  Training loss = 3.5582  Validation loss = 5.7704  \n",
      "\n",
      "Fold: 10  Epoch: 171  Training loss = 3.5578  Validation loss = 5.7698  \n",
      "\n",
      "Fold: 10  Epoch: 172  Training loss = 3.5575  Validation loss = 5.7695  \n",
      "\n",
      "Fold: 10  Epoch: 173  Training loss = 3.5573  Validation loss = 5.7692  \n",
      "\n",
      "Fold: 10  Epoch: 174  Training loss = 3.5569  Validation loss = 5.7687  \n",
      "\n",
      "Fold: 10  Epoch: 175  Training loss = 3.5566  Validation loss = 5.7683  \n",
      "\n",
      "Fold: 10  Epoch: 176  Training loss = 3.5563  Validation loss = 5.7677  \n",
      "\n",
      "Fold: 10  Epoch: 177  Training loss = 3.5560  Validation loss = 5.7674  \n",
      "\n",
      "Fold: 10  Epoch: 178  Training loss = 3.5557  Validation loss = 5.7668  \n",
      "\n",
      "Fold: 10  Epoch: 179  Training loss = 3.5554  Validation loss = 5.7665  \n",
      "\n",
      "Fold: 10  Epoch: 180  Training loss = 3.5552  Validation loss = 5.7661  \n",
      "\n",
      "Fold: 10  Epoch: 181  Training loss = 3.5549  Validation loss = 5.7657  \n",
      "\n",
      "Fold: 10  Epoch: 182  Training loss = 3.5546  Validation loss = 5.7653  \n",
      "\n",
      "Fold: 10  Epoch: 183  Training loss = 3.5543  Validation loss = 5.7649  \n",
      "\n",
      "Fold: 10  Epoch: 184  Training loss = 3.5541  Validation loss = 5.7645  \n",
      "\n",
      "Fold: 10  Epoch: 185  Training loss = 3.5537  Validation loss = 5.7640  \n",
      "\n",
      "Fold: 10  Epoch: 186  Training loss = 3.5534  Validation loss = 5.7635  \n",
      "\n",
      "Fold: 10  Epoch: 187  Training loss = 3.5531  Validation loss = 5.7631  \n",
      "\n",
      "Fold: 10  Epoch: 188  Training loss = 3.5528  Validation loss = 5.7627  \n",
      "\n",
      "Fold: 10  Epoch: 189  Training loss = 3.5525  Validation loss = 5.7620  \n",
      "\n",
      "Fold: 10  Epoch: 190  Training loss = 3.5521  Validation loss = 5.7614  \n",
      "\n",
      "Fold: 10  Epoch: 191  Training loss = 3.5517  Validation loss = 5.7609  \n",
      "\n",
      "Fold: 10  Epoch: 192  Training loss = 3.5514  Validation loss = 5.7603  \n",
      "\n",
      "Fold: 10  Epoch: 193  Training loss = 3.5510  Validation loss = 5.7598  \n",
      "\n",
      "Fold: 10  Epoch: 194  Training loss = 3.5507  Validation loss = 5.7594  \n",
      "\n",
      "Fold: 10  Epoch: 195  Training loss = 3.5505  Validation loss = 5.7590  \n",
      "\n",
      "Fold: 10  Epoch: 196  Training loss = 3.5503  Validation loss = 5.7587  \n",
      "\n",
      "Fold: 10  Epoch: 197  Training loss = 3.5501  Validation loss = 5.7584  \n",
      "\n",
      "Fold: 10  Epoch: 198  Training loss = 3.5498  Validation loss = 5.7580  \n",
      "\n",
      "Fold: 10  Epoch: 199  Training loss = 3.5496  Validation loss = 5.7577  \n",
      "\n",
      "Fold: 10  Epoch: 200  Training loss = 3.5494  Validation loss = 5.7574  \n",
      "\n",
      "Fold: 10  Epoch: 201  Training loss = 3.5490  Validation loss = 5.7569  \n",
      "\n",
      "Fold: 10  Epoch: 202  Training loss = 3.5487  Validation loss = 5.7565  \n",
      "\n",
      "Fold: 10  Epoch: 203  Training loss = 3.5485  Validation loss = 5.7561  \n",
      "\n",
      "Fold: 10  Epoch: 204  Training loss = 3.5481  Validation loss = 5.7555  \n",
      "\n",
      "Fold: 10  Epoch: 205  Training loss = 3.5479  Validation loss = 5.7552  \n",
      "\n",
      "Fold: 10  Epoch: 206  Training loss = 3.5475  Validation loss = 5.7548  \n",
      "\n",
      "Fold: 10  Epoch: 207  Training loss = 3.5472  Validation loss = 5.7543  \n",
      "\n",
      "Fold: 10  Epoch: 208  Training loss = 3.5470  Validation loss = 5.7540  \n",
      "\n",
      "Fold: 10  Epoch: 209  Training loss = 3.5466  Validation loss = 5.7535  \n",
      "\n",
      "Fold: 10  Epoch: 210  Training loss = 3.5463  Validation loss = 5.7530  \n",
      "\n",
      "Fold: 10  Epoch: 211  Training loss = 3.5459  Validation loss = 5.7524  \n",
      "\n",
      "Fold: 10  Epoch: 212  Training loss = 3.5456  Validation loss = 5.7521  \n",
      "\n",
      "Fold: 10  Epoch: 213  Training loss = 3.5454  Validation loss = 5.7518  \n",
      "\n",
      "Fold: 10  Epoch: 214  Training loss = 3.5451  Validation loss = 5.7513  \n",
      "\n",
      "Fold: 10  Epoch: 215  Training loss = 3.5448  Validation loss = 5.7508  \n",
      "\n",
      "Fold: 10  Epoch: 216  Training loss = 3.5446  Validation loss = 5.7504  \n",
      "\n",
      "Fold: 10  Epoch: 217  Training loss = 3.5443  Validation loss = 5.7501  \n",
      "\n",
      "Fold: 10  Epoch: 218  Training loss = 3.5441  Validation loss = 5.7498  \n",
      "\n",
      "Fold: 10  Epoch: 219  Training loss = 3.5437  Validation loss = 5.7494  \n",
      "\n",
      "Fold: 10  Epoch: 220  Training loss = 3.5435  Validation loss = 5.7490  \n",
      "\n",
      "Fold: 10  Epoch: 221  Training loss = 3.5432  Validation loss = 5.7486  \n",
      "\n",
      "Fold: 10  Epoch: 222  Training loss = 3.5428  Validation loss = 5.7481  \n",
      "\n",
      "Fold: 10  Epoch: 223  Training loss = 3.5426  Validation loss = 5.7478  \n",
      "\n",
      "Fold: 10  Epoch: 224  Training loss = 3.5423  Validation loss = 5.7474  \n",
      "\n",
      "Fold: 10  Epoch: 225  Training loss = 3.5419  Validation loss = 5.7468  \n",
      "\n",
      "Fold: 10  Epoch: 226  Training loss = 3.5416  Validation loss = 5.7462  \n",
      "\n",
      "Fold: 10  Epoch: 227  Training loss = 3.5412  Validation loss = 5.7457  \n",
      "\n",
      "Fold: 10  Epoch: 228  Training loss = 3.5410  Validation loss = 5.7453  \n",
      "\n",
      "Fold: 10  Epoch: 229  Training loss = 3.5407  Validation loss = 5.7450  \n",
      "\n",
      "Fold: 10  Epoch: 230  Training loss = 3.5405  Validation loss = 5.7447  \n",
      "\n",
      "Fold: 10  Epoch: 231  Training loss = 3.5402  Validation loss = 5.7443  \n",
      "\n",
      "Fold: 10  Epoch: 232  Training loss = 3.5399  Validation loss = 5.7438  \n",
      "\n",
      "Fold: 10  Epoch: 233  Training loss = 3.5396  Validation loss = 5.7434  \n",
      "\n",
      "Fold: 10  Epoch: 234  Training loss = 3.5393  Validation loss = 5.7429  \n",
      "\n",
      "Fold: 10  Epoch: 235  Training loss = 3.5390  Validation loss = 5.7426  \n",
      "\n",
      "Fold: 10  Epoch: 236  Training loss = 3.5387  Validation loss = 5.7421  \n",
      "\n",
      "Fold: 10  Epoch: 237  Training loss = 3.5384  Validation loss = 5.7417  \n",
      "\n",
      "Fold: 10  Epoch: 238  Training loss = 3.5381  Validation loss = 5.7413  \n",
      "\n",
      "Fold: 10  Epoch: 239  Training loss = 3.5378  Validation loss = 5.7407  \n",
      "\n",
      "Fold: 10  Epoch: 240  Training loss = 3.5374  Validation loss = 5.7401  \n",
      "\n",
      "Fold: 10  Epoch: 241  Training loss = 3.5370  Validation loss = 5.7396  \n",
      "\n",
      "Fold: 10  Epoch: 242  Training loss = 3.5368  Validation loss = 5.7394  \n",
      "\n",
      "Fold: 10  Epoch: 243  Training loss = 3.5365  Validation loss = 5.7388  \n",
      "\n",
      "Fold: 10  Epoch: 244  Training loss = 3.5362  Validation loss = 5.7384  \n",
      "\n",
      "Fold: 10  Epoch: 245  Training loss = 3.5359  Validation loss = 5.7379  \n",
      "\n",
      "Fold: 10  Epoch: 246  Training loss = 3.5356  Validation loss = 5.7375  \n",
      "\n",
      "Fold: 10  Epoch: 247  Training loss = 3.5353  Validation loss = 5.7371  \n",
      "\n",
      "Fold: 10  Epoch: 248  Training loss = 3.5350  Validation loss = 5.7367  \n",
      "\n",
      "Fold: 10  Epoch: 249  Training loss = 3.5347  Validation loss = 5.7363  \n",
      "\n",
      "Fold: 10  Epoch: 250  Training loss = 3.5343  Validation loss = 5.7358  \n",
      "\n",
      "Fold: 10  Epoch: 251  Training loss = 3.5341  Validation loss = 5.7354  \n",
      "\n",
      "Fold: 10  Epoch: 252  Training loss = 3.5338  Validation loss = 5.7350  \n",
      "\n",
      "Fold: 10  Epoch: 253  Training loss = 3.5336  Validation loss = 5.7346  \n",
      "\n",
      "Fold: 10  Epoch: 254  Training loss = 3.5333  Validation loss = 5.7342  \n",
      "\n",
      "Fold: 10  Epoch: 255  Training loss = 3.5330  Validation loss = 5.7338  \n",
      "\n",
      "Fold: 10  Epoch: 256  Training loss = 3.5327  Validation loss = 5.7333  \n",
      "\n",
      "Fold: 10  Epoch: 257  Training loss = 3.5324  Validation loss = 5.7329  \n",
      "\n",
      "Fold: 10  Epoch: 258  Training loss = 3.5323  Validation loss = 5.7327  \n",
      "\n",
      "Fold: 10  Epoch: 259  Training loss = 3.5320  Validation loss = 5.7323  \n",
      "\n",
      "Fold: 10  Epoch: 260  Training loss = 3.5317  Validation loss = 5.7319  \n",
      "\n",
      "Fold: 10  Epoch: 261  Training loss = 3.5314  Validation loss = 5.7315  \n",
      "\n",
      "Fold: 10  Epoch: 262  Training loss = 3.5312  Validation loss = 5.7312  \n",
      "\n",
      "Fold: 10  Epoch: 263  Training loss = 3.5307  Validation loss = 5.7305  \n",
      "\n",
      "Fold: 10  Epoch: 264  Training loss = 3.5304  Validation loss = 5.7301  \n",
      "\n",
      "Fold: 10  Epoch: 265  Training loss = 3.5301  Validation loss = 5.7296  \n",
      "\n",
      "Fold: 10  Epoch: 266  Training loss = 3.5298  Validation loss = 5.7292  \n",
      "\n",
      "Fold: 10  Epoch: 267  Training loss = 3.5294  Validation loss = 5.7287  \n",
      "\n",
      "Fold: 10  Epoch: 268  Training loss = 3.5292  Validation loss = 5.7283  \n",
      "\n",
      "Fold: 10  Epoch: 269  Training loss = 3.5289  Validation loss = 5.7280  \n",
      "\n",
      "Fold: 10  Epoch: 270  Training loss = 3.5287  Validation loss = 5.7277  \n",
      "\n",
      "Fold: 10  Epoch: 271  Training loss = 3.5284  Validation loss = 5.7274  \n",
      "\n",
      "Fold: 10  Epoch: 272  Training loss = 3.5281  Validation loss = 5.7268  \n",
      "\n",
      "Fold: 10  Epoch: 273  Training loss = 3.5279  Validation loss = 5.7266  \n",
      "\n",
      "Fold: 10  Epoch: 274  Training loss = 3.5276  Validation loss = 5.7261  \n",
      "\n",
      "Fold: 10  Epoch: 275  Training loss = 3.5273  Validation loss = 5.7255  \n",
      "\n",
      "Fold: 10  Epoch: 276  Training loss = 3.5270  Validation loss = 5.7252  \n",
      "\n",
      "Fold: 10  Epoch: 277  Training loss = 3.5266  Validation loss = 5.7247  \n",
      "\n",
      "Fold: 10  Epoch: 278  Training loss = 3.5263  Validation loss = 5.7242  \n",
      "\n",
      "Fold: 10  Epoch: 279  Training loss = 3.5260  Validation loss = 5.7237  \n",
      "\n",
      "Fold: 10  Epoch: 280  Training loss = 3.5257  Validation loss = 5.7234  \n",
      "\n",
      "Fold: 10  Epoch: 281  Training loss = 3.5255  Validation loss = 5.7229  \n",
      "\n",
      "Fold: 10  Epoch: 282  Training loss = 3.5251  Validation loss = 5.7223  \n",
      "\n",
      "Fold: 10  Epoch: 283  Training loss = 3.5248  Validation loss = 5.7219  \n",
      "\n",
      "Fold: 10  Epoch: 284  Training loss = 3.5246  Validation loss = 5.7216  \n",
      "\n",
      "Fold: 10  Epoch: 285  Training loss = 3.5243  Validation loss = 5.7212  \n",
      "\n",
      "Fold: 10  Epoch: 286  Training loss = 3.5240  Validation loss = 5.7208  \n",
      "\n",
      "Fold: 10  Epoch: 287  Training loss = 3.5238  Validation loss = 5.7205  \n",
      "\n",
      "Fold: 10  Epoch: 288  Training loss = 3.5235  Validation loss = 5.7200  \n",
      "\n",
      "Fold: 10  Epoch: 289  Training loss = 3.5232  Validation loss = 5.7196  \n",
      "\n",
      "Fold: 10  Epoch: 290  Training loss = 3.5229  Validation loss = 5.7192  \n",
      "\n",
      "Fold: 10  Epoch: 291  Training loss = 3.5225  Validation loss = 5.7187  \n",
      "\n",
      "Fold: 10  Epoch: 292  Training loss = 3.5222  Validation loss = 5.7182  \n",
      "\n",
      "Fold: 10  Epoch: 293  Training loss = 3.5218  Validation loss = 5.7177  \n",
      "\n",
      "Fold: 10  Epoch: 294  Training loss = 3.5215  Validation loss = 5.7171  \n",
      "\n",
      "Fold: 10  Epoch: 295  Training loss = 3.5211  Validation loss = 5.7166  \n",
      "\n",
      "Fold: 10  Epoch: 296  Training loss = 3.5209  Validation loss = 5.7162  \n",
      "\n",
      "Fold: 10  Epoch: 297  Training loss = 3.5207  Validation loss = 5.7159  \n",
      "\n",
      "Fold: 10  Epoch: 298  Training loss = 3.5203  Validation loss = 5.7153  \n",
      "\n",
      "Fold: 10  Epoch: 299  Training loss = 3.5200  Validation loss = 5.7149  \n",
      "\n",
      "Fold: 10  Epoch: 300  Training loss = 3.5198  Validation loss = 5.7144  \n",
      "\n",
      "Fold: 10  Epoch: 301  Training loss = 3.5194  Validation loss = 5.7138  \n",
      "\n",
      "Fold: 10  Epoch: 302  Training loss = 3.5191  Validation loss = 5.7133  \n",
      "\n",
      "Fold: 10  Epoch: 303  Training loss = 3.5188  Validation loss = 5.7128  \n",
      "\n",
      "Fold: 10  Epoch: 304  Training loss = 3.5186  Validation loss = 5.7124  \n",
      "\n",
      "Fold: 10  Epoch: 305  Training loss = 3.5182  Validation loss = 5.7118  \n",
      "\n",
      "Fold: 10  Epoch: 306  Training loss = 3.5179  Validation loss = 5.7113  \n",
      "\n",
      "Fold: 10  Epoch: 307  Training loss = 3.5176  Validation loss = 5.7109  \n",
      "\n",
      "Fold: 10  Epoch: 308  Training loss = 3.5174  Validation loss = 5.7106  \n",
      "\n",
      "Fold: 10  Epoch: 309  Training loss = 3.5170  Validation loss = 5.7101  \n",
      "\n",
      "Fold: 10  Epoch: 310  Training loss = 3.5168  Validation loss = 5.7098  \n",
      "\n",
      "Fold: 10  Epoch: 311  Training loss = 3.5165  Validation loss = 5.7093  \n",
      "\n",
      "Fold: 10  Epoch: 312  Training loss = 3.5162  Validation loss = 5.7089  \n",
      "\n",
      "Fold: 10  Epoch: 313  Training loss = 3.5159  Validation loss = 5.7085  \n",
      "\n",
      "Fold: 10  Epoch: 314  Training loss = 3.5156  Validation loss = 5.7081  \n",
      "\n",
      "Fold: 10  Epoch: 315  Training loss = 3.5153  Validation loss = 5.7076  \n",
      "\n",
      "Fold: 10  Epoch: 316  Training loss = 3.5149  Validation loss = 5.7071  \n",
      "\n",
      "Fold: 10  Epoch: 317  Training loss = 3.5147  Validation loss = 5.7068  \n",
      "\n",
      "Fold: 10  Epoch: 318  Training loss = 3.5144  Validation loss = 5.7063  \n",
      "\n",
      "Fold: 10  Epoch: 319  Training loss = 3.5142  Validation loss = 5.7060  \n",
      "\n",
      "Fold: 10  Epoch: 320  Training loss = 3.5139  Validation loss = 5.7057  \n",
      "\n",
      "Fold: 10  Epoch: 321  Training loss = 3.5136  Validation loss = 5.7053  \n",
      "\n",
      "Fold: 10  Epoch: 322  Training loss = 3.5133  Validation loss = 5.7049  \n",
      "\n",
      "Fold: 10  Epoch: 323  Training loss = 3.5131  Validation loss = 5.7045  \n",
      "\n",
      "Fold: 10  Epoch: 324  Training loss = 3.5128  Validation loss = 5.7041  \n",
      "\n",
      "Fold: 10  Epoch: 325  Training loss = 3.5126  Validation loss = 5.7037  \n",
      "\n",
      "Fold: 10  Epoch: 326  Training loss = 3.5122  Validation loss = 5.7033  \n",
      "\n",
      "Fold: 10  Epoch: 327  Training loss = 3.5120  Validation loss = 5.7029  \n",
      "\n",
      "Fold: 10  Epoch: 328  Training loss = 3.5117  Validation loss = 5.7024  \n",
      "\n",
      "Fold: 10  Epoch: 329  Training loss = 3.5115  Validation loss = 5.7020  \n",
      "\n",
      "Fold: 10  Epoch: 330  Training loss = 3.5111  Validation loss = 5.7014  \n",
      "\n",
      "Fold: 10  Epoch: 331  Training loss = 3.5108  Validation loss = 5.7009  \n",
      "\n",
      "Fold: 10  Epoch: 332  Training loss = 3.5104  Validation loss = 5.7005  \n",
      "\n",
      "Fold: 10  Epoch: 333  Training loss = 3.5101  Validation loss = 5.7000  \n",
      "\n",
      "Fold: 10  Epoch: 334  Training loss = 3.5098  Validation loss = 5.6995  \n",
      "\n",
      "Fold: 10  Epoch: 335  Training loss = 3.5096  Validation loss = 5.6992  \n",
      "\n",
      "Fold: 10  Epoch: 336  Training loss = 3.5093  Validation loss = 5.6989  \n",
      "\n",
      "Fold: 10  Epoch: 337  Training loss = 3.5091  Validation loss = 5.6986  \n",
      "\n",
      "Fold: 10  Epoch: 338  Training loss = 3.5087  Validation loss = 5.6981  \n",
      "\n",
      "Fold: 10  Epoch: 339  Training loss = 3.5085  Validation loss = 5.6978  \n",
      "\n",
      "Fold: 10  Epoch: 340  Training loss = 3.5082  Validation loss = 5.6973  \n",
      "\n",
      "Fold: 10  Epoch: 341  Training loss = 3.5080  Validation loss = 5.6969  \n",
      "\n",
      "Fold: 10  Epoch: 342  Training loss = 3.5076  Validation loss = 5.6963  \n",
      "\n",
      "Fold: 10  Epoch: 343  Training loss = 3.5073  Validation loss = 5.6959  \n",
      "\n",
      "Fold: 10  Epoch: 344  Training loss = 3.5070  Validation loss = 5.6955  \n",
      "\n",
      "Fold: 10  Epoch: 345  Training loss = 3.5067  Validation loss = 5.6950  \n",
      "\n",
      "Fold: 10  Epoch: 346  Training loss = 3.5064  Validation loss = 5.6946  \n",
      "\n",
      "Fold: 10  Epoch: 347  Training loss = 3.5060  Validation loss = 5.6941  \n",
      "\n",
      "Fold: 10  Epoch: 348  Training loss = 3.5057  Validation loss = 5.6936  \n",
      "\n",
      "Fold: 10  Epoch: 349  Training loss = 3.5054  Validation loss = 5.6932  \n",
      "\n",
      "Fold: 10  Epoch: 350  Training loss = 3.5051  Validation loss = 5.6927  \n",
      "\n",
      "Fold: 10  Epoch: 351  Training loss = 3.5048  Validation loss = 5.6922  \n",
      "\n",
      "Fold: 10  Epoch: 352  Training loss = 3.5045  Validation loss = 5.6919  \n",
      "\n",
      "Fold: 10  Epoch: 353  Training loss = 3.5043  Validation loss = 5.6915  \n",
      "\n",
      "Fold: 10  Epoch: 354  Training loss = 3.5040  Validation loss = 5.6910  \n",
      "\n",
      "Fold: 10  Epoch: 355  Training loss = 3.5037  Validation loss = 5.6905  \n",
      "\n",
      "Fold: 10  Epoch: 356  Training loss = 3.5034  Validation loss = 5.6901  \n",
      "\n",
      "Fold: 10  Epoch: 357  Training loss = 3.5031  Validation loss = 5.6897  \n",
      "\n",
      "Fold: 10  Epoch: 358  Training loss = 3.5028  Validation loss = 5.6892  \n",
      "\n",
      "Fold: 10  Epoch: 359  Training loss = 3.5025  Validation loss = 5.6887  \n",
      "\n",
      "Fold: 10  Epoch: 360  Training loss = 3.5021  Validation loss = 5.6882  \n",
      "\n",
      "Fold: 10  Epoch: 361  Training loss = 3.5018  Validation loss = 5.6878  \n",
      "\n",
      "Fold: 10  Epoch: 362  Training loss = 3.5015  Validation loss = 5.6874  \n",
      "\n",
      "Fold: 10  Epoch: 363  Training loss = 3.5013  Validation loss = 5.6870  \n",
      "\n",
      "Fold: 10  Epoch: 364  Training loss = 3.5009  Validation loss = 5.6865  \n",
      "\n",
      "Fold: 10  Epoch: 365  Training loss = 3.5006  Validation loss = 5.6861  \n",
      "\n",
      "Fold: 10  Epoch: 366  Training loss = 3.5003  Validation loss = 5.6857  \n",
      "\n",
      "Fold: 10  Epoch: 367  Training loss = 3.5001  Validation loss = 5.6854  \n",
      "\n",
      "Fold: 10  Epoch: 368  Training loss = 3.4999  Validation loss = 5.6851  \n",
      "\n",
      "Fold: 10  Epoch: 369  Training loss = 3.4995  Validation loss = 5.6845  \n",
      "\n",
      "Fold: 10  Epoch: 370  Training loss = 3.4992  Validation loss = 5.6841  \n",
      "\n",
      "Fold: 10  Epoch: 371  Training loss = 3.4988  Validation loss = 5.6836  \n",
      "\n",
      "Fold: 10  Epoch: 372  Training loss = 3.4984  Validation loss = 5.6831  \n",
      "\n",
      "Fold: 10  Epoch: 373  Training loss = 3.4982  Validation loss = 5.6828  \n",
      "\n",
      "Fold: 10  Epoch: 374  Training loss = 3.4979  Validation loss = 5.6823  \n",
      "\n",
      "Fold: 10  Epoch: 375  Training loss = 3.4977  Validation loss = 5.6820  \n",
      "\n",
      "Fold: 10  Epoch: 376  Training loss = 3.4975  Validation loss = 5.6817  \n",
      "\n",
      "Fold: 10  Epoch: 377  Training loss = 3.4974  Validation loss = 5.6815  \n",
      "\n",
      "Fold: 10  Epoch: 378  Training loss = 3.4971  Validation loss = 5.6811  \n",
      "\n",
      "Fold: 10  Epoch: 379  Training loss = 3.4968  Validation loss = 5.6806  \n",
      "\n",
      "Fold: 10  Epoch: 380  Training loss = 3.4965  Validation loss = 5.6802  \n",
      "\n",
      "Fold: 10  Epoch: 381  Training loss = 3.4962  Validation loss = 5.6797  \n",
      "\n",
      "Fold: 10  Epoch: 382  Training loss = 3.4960  Validation loss = 5.6795  \n",
      "\n",
      "Fold: 10  Epoch: 383  Training loss = 3.4957  Validation loss = 5.6791  \n",
      "\n",
      "Fold: 10  Epoch: 384  Training loss = 3.4955  Validation loss = 5.6788  \n",
      "\n",
      "Fold: 10  Epoch: 385  Training loss = 3.4953  Validation loss = 5.6784  \n",
      "\n",
      "Fold: 10  Epoch: 386  Training loss = 3.4950  Validation loss = 5.6780  \n",
      "\n",
      "Fold: 10  Epoch: 387  Training loss = 3.4947  Validation loss = 5.6776  \n",
      "\n",
      "Fold: 10  Epoch: 388  Training loss = 3.4945  Validation loss = 5.6772  \n",
      "\n",
      "Fold: 10  Epoch: 389  Training loss = 3.4942  Validation loss = 5.6768  \n",
      "\n",
      "Fold: 10  Epoch: 390  Training loss = 3.4939  Validation loss = 5.6763  \n",
      "\n",
      "Fold: 10  Epoch: 391  Training loss = 3.4936  Validation loss = 5.6759  \n",
      "\n",
      "Fold: 10  Epoch: 392  Training loss = 3.4934  Validation loss = 5.6757  \n",
      "\n",
      "Fold: 10  Epoch: 393  Training loss = 3.4932  Validation loss = 5.6753  \n",
      "\n",
      "Fold: 10  Epoch: 394  Training loss = 3.4929  Validation loss = 5.6750  \n",
      "\n",
      "Fold: 10  Epoch: 395  Training loss = 3.4927  Validation loss = 5.6747  \n",
      "\n",
      "Fold: 10  Epoch: 396  Training loss = 3.4924  Validation loss = 5.6743  \n",
      "\n",
      "Fold: 10  Epoch: 397  Training loss = 3.4922  Validation loss = 5.6740  \n",
      "\n",
      "Fold: 10  Epoch: 398  Training loss = 3.4919  Validation loss = 5.6735  \n",
      "\n",
      "Fold: 10  Epoch: 399  Training loss = 3.4916  Validation loss = 5.6731  \n",
      "\n",
      "Fold: 10  Epoch: 400  Training loss = 3.4914  Validation loss = 5.6728  \n",
      "\n",
      "Fold: 10  Epoch: 401  Training loss = 3.4911  Validation loss = 5.6723  \n",
      "\n",
      "Fold: 10  Epoch: 402  Training loss = 3.4909  Validation loss = 5.6721  \n",
      "\n",
      "Fold: 10  Epoch: 403  Training loss = 3.4906  Validation loss = 5.6717  \n",
      "\n",
      "Fold: 10  Epoch: 404  Training loss = 3.4902  Validation loss = 5.6712  \n",
      "\n",
      "Fold: 10  Epoch: 405  Training loss = 3.4899  Validation loss = 5.6708  \n",
      "\n",
      "Fold: 10  Epoch: 406  Training loss = 3.4897  Validation loss = 5.6705  \n",
      "\n",
      "Fold: 10  Epoch: 407  Training loss = 3.4895  Validation loss = 5.6701  \n",
      "\n",
      "Fold: 10  Epoch: 408  Training loss = 3.4891  Validation loss = 5.6697  \n",
      "\n",
      "Fold: 10  Epoch: 409  Training loss = 3.4889  Validation loss = 5.6694  \n",
      "\n",
      "Fold: 10  Epoch: 410  Training loss = 3.4886  Validation loss = 5.6690  \n",
      "\n",
      "Fold: 10  Epoch: 411  Training loss = 3.4883  Validation loss = 5.6685  \n",
      "\n",
      "Fold: 10  Epoch: 412  Training loss = 3.4881  Validation loss = 5.6681  \n",
      "\n",
      "Fold: 10  Epoch: 413  Training loss = 3.4878  Validation loss = 5.6677  \n",
      "\n",
      "Fold: 10  Epoch: 414  Training loss = 3.4875  Validation loss = 5.6673  \n",
      "\n",
      "Fold: 10  Epoch: 415  Training loss = 3.4873  Validation loss = 5.6669  \n",
      "\n",
      "Fold: 10  Epoch: 416  Training loss = 3.4869  Validation loss = 5.6664  \n",
      "\n",
      "Fold: 10  Epoch: 417  Training loss = 3.4867  Validation loss = 5.6660  \n",
      "\n",
      "Fold: 10  Epoch: 418  Training loss = 3.4864  Validation loss = 5.6657  \n",
      "\n",
      "Fold: 10  Epoch: 419  Training loss = 3.4862  Validation loss = 5.6654  \n",
      "\n",
      "Fold: 10  Epoch: 420  Training loss = 3.4860  Validation loss = 5.6650  \n",
      "\n",
      "Fold: 10  Epoch: 421  Training loss = 3.4857  Validation loss = 5.6647  \n",
      "\n",
      "Fold: 10  Epoch: 422  Training loss = 3.4855  Validation loss = 5.6643  \n",
      "\n",
      "Fold: 10  Epoch: 423  Training loss = 3.4851  Validation loss = 5.6639  \n",
      "\n",
      "Fold: 10  Epoch: 424  Training loss = 3.4849  Validation loss = 5.6636  \n",
      "\n",
      "Fold: 10  Epoch: 425  Training loss = 3.4847  Validation loss = 5.6633  \n",
      "\n",
      "Fold: 10  Epoch: 426  Training loss = 3.4843  Validation loss = 5.6627  \n",
      "\n",
      "Fold: 10  Epoch: 427  Training loss = 3.4841  Validation loss = 5.6624  \n",
      "\n",
      "Fold: 10  Epoch: 428  Training loss = 3.4840  Validation loss = 5.6621  \n",
      "\n",
      "Fold: 10  Epoch: 429  Training loss = 3.4838  Validation loss = 5.6618  \n",
      "\n",
      "Fold: 10  Epoch: 430  Training loss = 3.4835  Validation loss = 5.6614  \n",
      "\n",
      "Fold: 10  Epoch: 431  Training loss = 3.4832  Validation loss = 5.6610  \n",
      "\n",
      "Fold: 10  Epoch: 432  Training loss = 3.4830  Validation loss = 5.6605  \n",
      "\n",
      "Fold: 10  Epoch: 433  Training loss = 3.4827  Validation loss = 5.6601  \n",
      "\n",
      "Fold: 10  Epoch: 434  Training loss = 3.4824  Validation loss = 5.6597  \n",
      "\n",
      "Fold: 10  Epoch: 435  Training loss = 3.4821  Validation loss = 5.6593  \n",
      "\n",
      "Fold: 10  Epoch: 436  Training loss = 3.4818  Validation loss = 5.6589  \n",
      "\n",
      "Fold: 10  Epoch: 437  Training loss = 3.4816  Validation loss = 5.6585  \n",
      "\n",
      "Fold: 10  Epoch: 438  Training loss = 3.4813  Validation loss = 5.6581  \n",
      "\n",
      "Fold: 10  Epoch: 439  Training loss = 3.4811  Validation loss = 5.6577  \n",
      "\n",
      "Fold: 10  Epoch: 440  Training loss = 3.4808  Validation loss = 5.6573  \n",
      "\n",
      "Fold: 10  Epoch: 441  Training loss = 3.4806  Validation loss = 5.6569  \n",
      "\n",
      "Fold: 10  Epoch: 442  Training loss = 3.4803  Validation loss = 5.6566  \n",
      "\n",
      "Fold: 10  Epoch: 443  Training loss = 3.4801  Validation loss = 5.6563  \n",
      "\n",
      "Fold: 10  Epoch: 444  Training loss = 3.4799  Validation loss = 5.6559  \n",
      "\n",
      "Fold: 10  Epoch: 445  Training loss = 3.4795  Validation loss = 5.6555  \n",
      "\n",
      "Fold: 10  Epoch: 446  Training loss = 3.4792  Validation loss = 5.6550  \n",
      "\n",
      "Fold: 10  Epoch: 447  Training loss = 3.4789  Validation loss = 5.6546  \n",
      "\n",
      "Fold: 10  Epoch: 448  Training loss = 3.4787  Validation loss = 5.6542  \n",
      "\n",
      "Fold: 10  Epoch: 449  Training loss = 3.4782  Validation loss = 5.6535  \n",
      "\n",
      "Fold: 10  Epoch: 450  Training loss = 3.4779  Validation loss = 5.6531  \n",
      "\n",
      "Fold: 10  Epoch: 451  Training loss = 3.4777  Validation loss = 5.6528  \n",
      "\n",
      "Fold: 10  Epoch: 452  Training loss = 3.4775  Validation loss = 5.6525  \n",
      "\n",
      "Fold: 10  Epoch: 453  Training loss = 3.4772  Validation loss = 5.6521  \n",
      "\n",
      "Fold: 10  Epoch: 454  Training loss = 3.4770  Validation loss = 5.6518  \n",
      "\n",
      "Fold: 10  Epoch: 455  Training loss = 3.4768  Validation loss = 5.6515  \n",
      "\n",
      "Fold: 10  Epoch: 456  Training loss = 3.4765  Validation loss = 5.6511  \n",
      "\n",
      "Fold: 10  Epoch: 457  Training loss = 3.4762  Validation loss = 5.6507  \n",
      "\n",
      "Fold: 10  Epoch: 458  Training loss = 3.4759  Validation loss = 5.6502  \n",
      "\n",
      "Fold: 10  Epoch: 459  Training loss = 3.4757  Validation loss = 5.6498  \n",
      "\n",
      "Fold: 10  Epoch: 460  Training loss = 3.4754  Validation loss = 5.6494  \n",
      "\n",
      "Fold: 10  Epoch: 461  Training loss = 3.4752  Validation loss = 5.6492  \n",
      "\n",
      "Fold: 10  Epoch: 462  Training loss = 3.4750  Validation loss = 5.6489  \n",
      "\n",
      "Fold: 10  Epoch: 463  Training loss = 3.4747  Validation loss = 5.6485  \n",
      "\n",
      "Fold: 10  Epoch: 464  Training loss = 3.4744  Validation loss = 5.6481  \n",
      "\n",
      "Fold: 10  Epoch: 465  Training loss = 3.4741  Validation loss = 5.6476  \n",
      "\n",
      "Fold: 10  Epoch: 466  Training loss = 3.4738  Validation loss = 5.6472  \n",
      "\n",
      "Fold: 10  Epoch: 467  Training loss = 3.4735  Validation loss = 5.6467  \n",
      "\n",
      "Fold: 10  Epoch: 468  Training loss = 3.4732  Validation loss = 5.6464  \n",
      "\n",
      "Fold: 10  Epoch: 469  Training loss = 3.4729  Validation loss = 5.6459  \n",
      "\n",
      "Fold: 10  Epoch: 470  Training loss = 3.4726  Validation loss = 5.6454  \n",
      "\n",
      "Fold: 10  Epoch: 471  Training loss = 3.4723  Validation loss = 5.6449  \n",
      "\n",
      "Fold: 10  Epoch: 472  Training loss = 3.4720  Validation loss = 5.6445  \n",
      "\n",
      "Fold: 10  Epoch: 473  Training loss = 3.4717  Validation loss = 5.6441  \n",
      "\n",
      "Fold: 10  Epoch: 474  Training loss = 3.4714  Validation loss = 5.6435  \n",
      "\n",
      "Fold: 10  Epoch: 475  Training loss = 3.4712  Validation loss = 5.6432  \n",
      "\n",
      "Fold: 10  Epoch: 476  Training loss = 3.4709  Validation loss = 5.6428  \n",
      "\n",
      "Fold: 10  Epoch: 477  Training loss = 3.4706  Validation loss = 5.6424  \n",
      "\n",
      "Fold: 10  Epoch: 478  Training loss = 3.4704  Validation loss = 5.6421  \n",
      "\n",
      "Fold: 10  Epoch: 479  Training loss = 3.4700  Validation loss = 5.6416  \n",
      "\n",
      "Fold: 10  Epoch: 480  Training loss = 3.4698  Validation loss = 5.6412  \n",
      "\n",
      "Fold: 10  Epoch: 481  Training loss = 3.4694  Validation loss = 5.6407  \n",
      "\n",
      "Fold: 10  Epoch: 482  Training loss = 3.4692  Validation loss = 5.6404  \n",
      "\n",
      "Fold: 10  Epoch: 483  Training loss = 3.4689  Validation loss = 5.6399  \n",
      "\n",
      "Fold: 10  Epoch: 484  Training loss = 3.4686  Validation loss = 5.6395  \n",
      "\n",
      "Fold: 10  Epoch: 485  Training loss = 3.4683  Validation loss = 5.6390  \n",
      "\n",
      "Fold: 10  Epoch: 486  Training loss = 3.4680  Validation loss = 5.6385  \n",
      "\n",
      "Fold: 10  Epoch: 487  Training loss = 3.4677  Validation loss = 5.6381  \n",
      "\n",
      "Fold: 10  Epoch: 488  Training loss = 3.4674  Validation loss = 5.6376  \n",
      "\n",
      "Fold: 10  Epoch: 489  Training loss = 3.4672  Validation loss = 5.6373  \n",
      "\n",
      "Fold: 10  Epoch: 490  Training loss = 3.4669  Validation loss = 5.6369  \n",
      "\n",
      "Fold: 10  Epoch: 491  Training loss = 3.4667  Validation loss = 5.6365  \n",
      "\n",
      "Fold: 10  Epoch: 492  Training loss = 3.4664  Validation loss = 5.6361  \n",
      "\n",
      "Fold: 10  Epoch: 493  Training loss = 3.4661  Validation loss = 5.6356  \n",
      "\n",
      "Fold: 10  Epoch: 494  Training loss = 3.4658  Validation loss = 5.6352  \n",
      "\n",
      "Fold: 10  Epoch: 495  Training loss = 3.4655  Validation loss = 5.6348  \n",
      "\n",
      "Fold: 10  Epoch: 496  Training loss = 3.4653  Validation loss = 5.6345  \n",
      "\n",
      "Fold: 10  Epoch: 497  Training loss = 3.4651  Validation loss = 5.6342  \n",
      "\n",
      "Fold: 10  Epoch: 498  Training loss = 3.4649  Validation loss = 5.6338  \n",
      "\n",
      "Fold: 10  Epoch: 499  Training loss = 3.4645  Validation loss = 5.6334  \n",
      "\n",
      "Fold: 10  Epoch: 500  Training loss = 3.4643  Validation loss = 5.6330  \n",
      "\n",
      "Check model:  Fold: 10  Epoch: 500  Training loss = 3.4643  Validation loss = 5.6330  \n",
      "\n",
      "Fold: 11  Epoch: 1  Training loss = 3.7203  Validation loss = 2.9685  \n",
      "\n",
      "Fold: 11  Epoch: 2  Training loss = 3.7199  Validation loss = 2.9678  \n",
      "\n",
      "Fold: 11  Epoch: 3  Training loss = 3.7195  Validation loss = 2.9672  \n",
      "\n",
      "Fold: 11  Epoch: 4  Training loss = 3.7191  Validation loss = 2.9664  \n",
      "\n",
      "Fold: 11  Epoch: 5  Training loss = 3.7187  Validation loss = 2.9657  \n",
      "\n",
      "Fold: 11  Epoch: 6  Training loss = 3.7183  Validation loss = 2.9651  \n",
      "\n",
      "Fold: 11  Epoch: 7  Training loss = 3.7180  Validation loss = 2.9645  \n",
      "\n",
      "Fold: 11  Epoch: 8  Training loss = 3.7177  Validation loss = 2.9639  \n",
      "\n",
      "Fold: 11  Epoch: 9  Training loss = 3.7174  Validation loss = 2.9635  \n",
      "\n",
      "Fold: 11  Epoch: 10  Training loss = 3.7171  Validation loss = 2.9629  \n",
      "\n",
      "Fold: 11  Epoch: 11  Training loss = 3.7167  Validation loss = 2.9622  \n",
      "\n",
      "Fold: 11  Epoch: 12  Training loss = 3.7163  Validation loss = 2.9616  \n",
      "\n",
      "Fold: 11  Epoch: 13  Training loss = 3.7160  Validation loss = 2.9610  \n",
      "\n",
      "Fold: 11  Epoch: 14  Training loss = 3.7156  Validation loss = 2.9604  \n",
      "\n",
      "Fold: 11  Epoch: 15  Training loss = 3.7153  Validation loss = 2.9598  \n",
      "\n",
      "Fold: 11  Epoch: 16  Training loss = 3.7149  Validation loss = 2.9591  \n",
      "\n",
      "Fold: 11  Epoch: 17  Training loss = 3.7146  Validation loss = 2.9585  \n",
      "\n",
      "Fold: 11  Epoch: 18  Training loss = 3.7142  Validation loss = 2.9579  \n",
      "\n",
      "Fold: 11  Epoch: 19  Training loss = 3.7139  Validation loss = 2.9574  \n",
      "\n",
      "Fold: 11  Epoch: 20  Training loss = 3.7136  Validation loss = 2.9567  \n",
      "\n",
      "Fold: 11  Epoch: 21  Training loss = 3.7131  Validation loss = 2.9560  \n",
      "\n",
      "Fold: 11  Epoch: 22  Training loss = 3.7127  Validation loss = 2.9553  \n",
      "\n",
      "Fold: 11  Epoch: 23  Training loss = 3.7123  Validation loss = 2.9546  \n",
      "\n",
      "Fold: 11  Epoch: 24  Training loss = 3.7119  Validation loss = 2.9539  \n",
      "\n",
      "Fold: 11  Epoch: 25  Training loss = 3.7116  Validation loss = 2.9533  \n",
      "\n",
      "Fold: 11  Epoch: 26  Training loss = 3.7113  Validation loss = 2.9528  \n",
      "\n",
      "Fold: 11  Epoch: 27  Training loss = 3.7109  Validation loss = 2.9521  \n",
      "\n",
      "Fold: 11  Epoch: 28  Training loss = 3.7106  Validation loss = 2.9515  \n",
      "\n",
      "Fold: 11  Epoch: 29  Training loss = 3.7102  Validation loss = 2.9509  \n",
      "\n",
      "Fold: 11  Epoch: 30  Training loss = 3.7099  Validation loss = 2.9503  \n",
      "\n",
      "Fold: 11  Epoch: 31  Training loss = 3.7095  Validation loss = 2.9496  \n",
      "\n",
      "Fold: 11  Epoch: 32  Training loss = 3.7090  Validation loss = 2.9487  \n",
      "\n",
      "Fold: 11  Epoch: 33  Training loss = 3.7086  Validation loss = 2.9481  \n",
      "\n",
      "Fold: 11  Epoch: 34  Training loss = 3.7083  Validation loss = 2.9475  \n",
      "\n",
      "Fold: 11  Epoch: 35  Training loss = 3.7079  Validation loss = 2.9468  \n",
      "\n",
      "Fold: 11  Epoch: 36  Training loss = 3.7075  Validation loss = 2.9461  \n",
      "\n",
      "Fold: 11  Epoch: 37  Training loss = 3.7071  Validation loss = 2.9455  \n",
      "\n",
      "Fold: 11  Epoch: 38  Training loss = 3.7068  Validation loss = 2.9448  \n",
      "\n",
      "Fold: 11  Epoch: 39  Training loss = 3.7064  Validation loss = 2.9442  \n",
      "\n",
      "Fold: 11  Epoch: 40  Training loss = 3.7061  Validation loss = 2.9436  \n",
      "\n",
      "Fold: 11  Epoch: 41  Training loss = 3.7057  Validation loss = 2.9429  \n",
      "\n",
      "Fold: 11  Epoch: 42  Training loss = 3.7053  Validation loss = 2.9423  \n",
      "\n",
      "Fold: 11  Epoch: 43  Training loss = 3.7050  Validation loss = 2.9416  \n",
      "\n",
      "Fold: 11  Epoch: 44  Training loss = 3.7045  Validation loss = 2.9409  \n",
      "\n",
      "Fold: 11  Epoch: 45  Training loss = 3.7042  Validation loss = 2.9403  \n",
      "\n",
      "Fold: 11  Epoch: 46  Training loss = 3.7038  Validation loss = 2.9396  \n",
      "\n",
      "Fold: 11  Epoch: 47  Training loss = 3.7034  Validation loss = 2.9390  \n",
      "\n",
      "Fold: 11  Epoch: 48  Training loss = 3.7031  Validation loss = 2.9384  \n",
      "\n",
      "Fold: 11  Epoch: 49  Training loss = 3.7028  Validation loss = 2.9378  \n",
      "\n",
      "Fold: 11  Epoch: 50  Training loss = 3.7024  Validation loss = 2.9372  \n",
      "\n",
      "Fold: 11  Epoch: 51  Training loss = 3.7020  Validation loss = 2.9364  \n",
      "\n",
      "Fold: 11  Epoch: 52  Training loss = 3.7017  Validation loss = 2.9358  \n",
      "\n",
      "Fold: 11  Epoch: 53  Training loss = 3.7013  Validation loss = 2.9351  \n",
      "\n",
      "Fold: 11  Epoch: 54  Training loss = 3.7008  Validation loss = 2.9343  \n",
      "\n",
      "Fold: 11  Epoch: 55  Training loss = 3.7005  Validation loss = 2.9337  \n",
      "\n",
      "Fold: 11  Epoch: 56  Training loss = 3.7001  Validation loss = 2.9331  \n",
      "\n",
      "Fold: 11  Epoch: 57  Training loss = 3.6998  Validation loss = 2.9325  \n",
      "\n",
      "Fold: 11  Epoch: 58  Training loss = 3.6995  Validation loss = 2.9319  \n",
      "\n",
      "Fold: 11  Epoch: 59  Training loss = 3.6991  Validation loss = 2.9313  \n",
      "\n",
      "Fold: 11  Epoch: 60  Training loss = 3.6988  Validation loss = 2.9307  \n",
      "\n",
      "Fold: 11  Epoch: 61  Training loss = 3.6983  Validation loss = 2.9299  \n",
      "\n",
      "Fold: 11  Epoch: 62  Training loss = 3.6980  Validation loss = 2.9293  \n",
      "\n",
      "Fold: 11  Epoch: 63  Training loss = 3.6977  Validation loss = 2.9288  \n",
      "\n",
      "Fold: 11  Epoch: 64  Training loss = 3.6973  Validation loss = 2.9281  \n",
      "\n",
      "Fold: 11  Epoch: 65  Training loss = 3.6968  Validation loss = 2.9273  \n",
      "\n",
      "Fold: 11  Epoch: 66  Training loss = 3.6965  Validation loss = 2.9267  \n",
      "\n",
      "Fold: 11  Epoch: 67  Training loss = 3.6962  Validation loss = 2.9262  \n",
      "\n",
      "Fold: 11  Epoch: 68  Training loss = 3.6959  Validation loss = 2.9256  \n",
      "\n",
      "Fold: 11  Epoch: 69  Training loss = 3.6956  Validation loss = 2.9251  \n",
      "\n",
      "Fold: 11  Epoch: 70  Training loss = 3.6953  Validation loss = 2.9245  \n",
      "\n",
      "Fold: 11  Epoch: 71  Training loss = 3.6948  Validation loss = 2.9238  \n",
      "\n",
      "Fold: 11  Epoch: 72  Training loss = 3.6945  Validation loss = 2.9232  \n",
      "\n",
      "Fold: 11  Epoch: 73  Training loss = 3.6941  Validation loss = 2.9225  \n",
      "\n",
      "Fold: 11  Epoch: 74  Training loss = 3.6938  Validation loss = 2.9219  \n",
      "\n",
      "Fold: 11  Epoch: 75  Training loss = 3.6934  Validation loss = 2.9211  \n",
      "\n",
      "Fold: 11  Epoch: 76  Training loss = 3.6930  Validation loss = 2.9204  \n",
      "\n",
      "Fold: 11  Epoch: 77  Training loss = 3.6926  Validation loss = 2.9197  \n",
      "\n",
      "Fold: 11  Epoch: 78  Training loss = 3.6922  Validation loss = 2.9191  \n",
      "\n",
      "Fold: 11  Epoch: 79  Training loss = 3.6919  Validation loss = 2.9185  \n",
      "\n",
      "Fold: 11  Epoch: 80  Training loss = 3.6915  Validation loss = 2.9179  \n",
      "\n",
      "Fold: 11  Epoch: 81  Training loss = 3.6911  Validation loss = 2.9172  \n",
      "\n",
      "Fold: 11  Epoch: 82  Training loss = 3.6908  Validation loss = 2.9166  \n",
      "\n",
      "Fold: 11  Epoch: 83  Training loss = 3.6904  Validation loss = 2.9159  \n",
      "\n",
      "Fold: 11  Epoch: 84  Training loss = 3.6901  Validation loss = 2.9154  \n",
      "\n",
      "Fold: 11  Epoch: 85  Training loss = 3.6898  Validation loss = 2.9148  \n",
      "\n",
      "Fold: 11  Epoch: 86  Training loss = 3.6895  Validation loss = 2.9144  \n",
      "\n",
      "Fold: 11  Epoch: 87  Training loss = 3.6891  Validation loss = 2.9136  \n",
      "\n",
      "Fold: 11  Epoch: 88  Training loss = 3.6888  Validation loss = 2.9131  \n",
      "\n",
      "Fold: 11  Epoch: 89  Training loss = 3.6886  Validation loss = 2.9127  \n",
      "\n",
      "Fold: 11  Epoch: 90  Training loss = 3.6883  Validation loss = 2.9121  \n",
      "\n",
      "Fold: 11  Epoch: 91  Training loss = 3.6879  Validation loss = 2.9115  \n",
      "\n",
      "Fold: 11  Epoch: 92  Training loss = 3.6875  Validation loss = 2.9108  \n",
      "\n",
      "Fold: 11  Epoch: 93  Training loss = 3.6872  Validation loss = 2.9103  \n",
      "\n",
      "Fold: 11  Epoch: 94  Training loss = 3.6869  Validation loss = 2.9096  \n",
      "\n",
      "Fold: 11  Epoch: 95  Training loss = 3.6865  Validation loss = 2.9091  \n",
      "\n",
      "Fold: 11  Epoch: 96  Training loss = 3.6862  Validation loss = 2.9084  \n",
      "\n",
      "Fold: 11  Epoch: 97  Training loss = 3.6858  Validation loss = 2.9077  \n",
      "\n",
      "Fold: 11  Epoch: 98  Training loss = 3.6855  Validation loss = 2.9072  \n",
      "\n",
      "Fold: 11  Epoch: 99  Training loss = 3.6851  Validation loss = 2.9064  \n",
      "\n",
      "Fold: 11  Epoch: 100  Training loss = 3.6846  Validation loss = 2.9056  \n",
      "\n",
      "Fold: 11  Epoch: 101  Training loss = 3.6843  Validation loss = 2.9050  \n",
      "\n",
      "Fold: 11  Epoch: 102  Training loss = 3.6840  Validation loss = 2.9046  \n",
      "\n",
      "Fold: 11  Epoch: 103  Training loss = 3.6838  Validation loss = 2.9041  \n",
      "\n",
      "Fold: 11  Epoch: 104  Training loss = 3.6835  Validation loss = 2.9037  \n",
      "\n",
      "Fold: 11  Epoch: 105  Training loss = 3.6832  Validation loss = 2.9031  \n",
      "\n",
      "Fold: 11  Epoch: 106  Training loss = 3.6829  Validation loss = 2.9026  \n",
      "\n",
      "Fold: 11  Epoch: 107  Training loss = 3.6827  Validation loss = 2.9021  \n",
      "\n",
      "Fold: 11  Epoch: 108  Training loss = 3.6822  Validation loss = 2.9013  \n",
      "\n",
      "Fold: 11  Epoch: 109  Training loss = 3.6818  Validation loss = 2.9006  \n",
      "\n",
      "Fold: 11  Epoch: 110  Training loss = 3.6816  Validation loss = 2.9002  \n",
      "\n",
      "Fold: 11  Epoch: 111  Training loss = 3.6813  Validation loss = 2.8997  \n",
      "\n",
      "Fold: 11  Epoch: 112  Training loss = 3.6810  Validation loss = 2.8991  \n",
      "\n",
      "Fold: 11  Epoch: 113  Training loss = 3.6806  Validation loss = 2.8985  \n",
      "\n",
      "Fold: 11  Epoch: 114  Training loss = 3.6804  Validation loss = 2.8981  \n",
      "\n",
      "Fold: 11  Epoch: 115  Training loss = 3.6801  Validation loss = 2.8975  \n",
      "\n",
      "Fold: 11  Epoch: 116  Training loss = 3.6797  Validation loss = 2.8968  \n",
      "\n",
      "Fold: 11  Epoch: 117  Training loss = 3.6794  Validation loss = 2.8962  \n",
      "\n",
      "Fold: 11  Epoch: 118  Training loss = 3.6790  Validation loss = 2.8955  \n",
      "\n",
      "Fold: 11  Epoch: 119  Training loss = 3.6787  Validation loss = 2.8949  \n",
      "\n",
      "Fold: 11  Epoch: 120  Training loss = 3.6783  Validation loss = 2.8943  \n",
      "\n",
      "Fold: 11  Epoch: 121  Training loss = 3.6779  Validation loss = 2.8936  \n",
      "\n",
      "Fold: 11  Epoch: 122  Training loss = 3.6776  Validation loss = 2.8931  \n",
      "\n",
      "Fold: 11  Epoch: 123  Training loss = 3.6772  Validation loss = 2.8924  \n",
      "\n",
      "Fold: 11  Epoch: 124  Training loss = 3.6769  Validation loss = 2.8919  \n",
      "\n",
      "Fold: 11  Epoch: 125  Training loss = 3.6766  Validation loss = 2.8913  \n",
      "\n",
      "Fold: 11  Epoch: 126  Training loss = 3.6762  Validation loss = 2.8905  \n",
      "\n",
      "Fold: 11  Epoch: 127  Training loss = 3.6758  Validation loss = 2.8898  \n",
      "\n",
      "Fold: 11  Epoch: 128  Training loss = 3.6754  Validation loss = 2.8892  \n",
      "\n",
      "Fold: 11  Epoch: 129  Training loss = 3.6751  Validation loss = 2.8886  \n",
      "\n",
      "Fold: 11  Epoch: 130  Training loss = 3.6748  Validation loss = 2.8881  \n",
      "\n",
      "Fold: 11  Epoch: 131  Training loss = 3.6744  Validation loss = 2.8874  \n",
      "\n",
      "Fold: 11  Epoch: 132  Training loss = 3.6740  Validation loss = 2.8867  \n",
      "\n",
      "Fold: 11  Epoch: 133  Training loss = 3.6737  Validation loss = 2.8860  \n",
      "\n",
      "Fold: 11  Epoch: 134  Training loss = 3.6732  Validation loss = 2.8853  \n",
      "\n",
      "Fold: 11  Epoch: 135  Training loss = 3.6728  Validation loss = 2.8845  \n",
      "\n",
      "Fold: 11  Epoch: 136  Training loss = 3.6724  Validation loss = 2.8837  \n",
      "\n",
      "Fold: 11  Epoch: 137  Training loss = 3.6720  Validation loss = 2.8830  \n",
      "\n",
      "Fold: 11  Epoch: 138  Training loss = 3.6717  Validation loss = 2.8825  \n",
      "\n",
      "Fold: 11  Epoch: 139  Training loss = 3.6714  Validation loss = 2.8820  \n",
      "\n",
      "Fold: 11  Epoch: 140  Training loss = 3.6710  Validation loss = 2.8813  \n",
      "\n",
      "Fold: 11  Epoch: 141  Training loss = 3.6706  Validation loss = 2.8806  \n",
      "\n",
      "Fold: 11  Epoch: 142  Training loss = 3.6703  Validation loss = 2.8799  \n",
      "\n",
      "Fold: 11  Epoch: 143  Training loss = 3.6700  Validation loss = 2.8795  \n",
      "\n",
      "Fold: 11  Epoch: 144  Training loss = 3.6696  Validation loss = 2.8788  \n",
      "\n",
      "Fold: 11  Epoch: 145  Training loss = 3.6693  Validation loss = 2.8783  \n",
      "\n",
      "Fold: 11  Epoch: 146  Training loss = 3.6691  Validation loss = 2.8778  \n",
      "\n",
      "Fold: 11  Epoch: 147  Training loss = 3.6688  Validation loss = 2.8773  \n",
      "\n",
      "Fold: 11  Epoch: 148  Training loss = 3.6683  Validation loss = 2.8765  \n",
      "\n",
      "Fold: 11  Epoch: 149  Training loss = 3.6681  Validation loss = 2.8761  \n",
      "\n",
      "Fold: 11  Epoch: 150  Training loss = 3.6678  Validation loss = 2.8756  \n",
      "\n",
      "Fold: 11  Epoch: 151  Training loss = 3.6675  Validation loss = 2.8750  \n",
      "\n",
      "Fold: 11  Epoch: 152  Training loss = 3.6672  Validation loss = 2.8744  \n",
      "\n",
      "Fold: 11  Epoch: 153  Training loss = 3.6668  Validation loss = 2.8738  \n",
      "\n",
      "Fold: 11  Epoch: 154  Training loss = 3.6665  Validation loss = 2.8734  \n",
      "\n",
      "Fold: 11  Epoch: 155  Training loss = 3.6661  Validation loss = 2.8727  \n",
      "\n",
      "Fold: 11  Epoch: 156  Training loss = 3.6657  Validation loss = 2.8720  \n",
      "\n",
      "Fold: 11  Epoch: 157  Training loss = 3.6651  Validation loss = 2.8714  \n",
      "\n",
      "Fold: 11  Epoch: 158  Training loss = 3.6635  Validation loss = 2.8708  \n",
      "\n",
      "Fold: 11  Epoch: 159  Training loss = 3.6626  Validation loss = 2.8701  \n",
      "\n",
      "Fold: 11  Epoch: 160  Training loss = 3.6621  Validation loss = 2.8694  \n",
      "\n",
      "Fold: 11  Epoch: 161  Training loss = 3.6616  Validation loss = 2.8686  \n",
      "\n",
      "Fold: 11  Epoch: 162  Training loss = 3.6612  Validation loss = 2.8680  \n",
      "\n",
      "Fold: 11  Epoch: 163  Training loss = 3.6608  Validation loss = 2.8672  \n",
      "\n",
      "Fold: 11  Epoch: 164  Training loss = 3.6606  Validation loss = 2.8668  \n",
      "\n",
      "Fold: 11  Epoch: 165  Training loss = 3.6602  Validation loss = 2.8661  \n",
      "\n",
      "Fold: 11  Epoch: 166  Training loss = 3.6599  Validation loss = 2.8656  \n",
      "\n",
      "Fold: 11  Epoch: 167  Training loss = 3.6595  Validation loss = 2.8649  \n",
      "\n",
      "Fold: 11  Epoch: 168  Training loss = 3.6592  Validation loss = 2.8643  \n",
      "\n",
      "Fold: 11  Epoch: 169  Training loss = 3.6589  Validation loss = 2.8637  \n",
      "\n",
      "Fold: 11  Epoch: 170  Training loss = 3.6586  Validation loss = 2.8633  \n",
      "\n",
      "Fold: 11  Epoch: 171  Training loss = 3.6583  Validation loss = 2.8628  \n",
      "\n",
      "Fold: 11  Epoch: 172  Training loss = 3.6580  Validation loss = 2.8622  \n",
      "\n",
      "Fold: 11  Epoch: 173  Training loss = 3.6578  Validation loss = 2.8617  \n",
      "\n",
      "Fold: 11  Epoch: 174  Training loss = 3.6574  Validation loss = 2.8611  \n",
      "\n",
      "Fold: 11  Epoch: 175  Training loss = 3.6570  Validation loss = 2.8603  \n",
      "\n",
      "Fold: 11  Epoch: 176  Training loss = 3.6566  Validation loss = 2.8596  \n",
      "\n",
      "Fold: 11  Epoch: 177  Training loss = 3.6562  Validation loss = 2.8589  \n",
      "\n",
      "Fold: 11  Epoch: 178  Training loss = 3.6559  Validation loss = 2.8583  \n",
      "\n",
      "Fold: 11  Epoch: 179  Training loss = 3.6555  Validation loss = 2.8576  \n",
      "\n",
      "Fold: 11  Epoch: 180  Training loss = 3.6552  Validation loss = 2.8571  \n",
      "\n",
      "Fold: 11  Epoch: 181  Training loss = 3.6548  Validation loss = 2.8565  \n",
      "\n",
      "Fold: 11  Epoch: 182  Training loss = 3.6546  Validation loss = 2.8560  \n",
      "\n",
      "Fold: 11  Epoch: 183  Training loss = 3.6543  Validation loss = 2.8554  \n",
      "\n",
      "Fold: 11  Epoch: 184  Training loss = 3.6539  Validation loss = 2.8548  \n",
      "\n",
      "Fold: 11  Epoch: 185  Training loss = 3.6536  Validation loss = 2.8543  \n",
      "\n",
      "Fold: 11  Epoch: 186  Training loss = 3.6533  Validation loss = 2.8538  \n",
      "\n",
      "Fold: 11  Epoch: 187  Training loss = 3.6531  Validation loss = 2.8533  \n",
      "\n",
      "Fold: 11  Epoch: 188  Training loss = 3.6528  Validation loss = 2.8528  \n",
      "\n",
      "Fold: 11  Epoch: 189  Training loss = 3.6524  Validation loss = 2.8520  \n",
      "\n",
      "Fold: 11  Epoch: 190  Training loss = 3.6520  Validation loss = 2.8513  \n",
      "\n",
      "Fold: 11  Epoch: 191  Training loss = 3.6516  Validation loss = 2.8506  \n",
      "\n",
      "Fold: 11  Epoch: 192  Training loss = 3.6513  Validation loss = 2.8501  \n",
      "\n",
      "Fold: 11  Epoch: 193  Training loss = 3.6510  Validation loss = 2.8494  \n",
      "\n",
      "Fold: 11  Epoch: 194  Training loss = 3.6505  Validation loss = 2.8487  \n",
      "\n",
      "Fold: 11  Epoch: 195  Training loss = 3.6503  Validation loss = 2.8481  \n",
      "\n",
      "Fold: 11  Epoch: 196  Training loss = 3.6500  Validation loss = 2.8476  \n",
      "\n",
      "Fold: 11  Epoch: 197  Training loss = 3.6496  Validation loss = 2.8470  \n",
      "\n",
      "Fold: 11  Epoch: 198  Training loss = 3.6494  Validation loss = 2.8465  \n",
      "\n",
      "Fold: 11  Epoch: 199  Training loss = 3.6492  Validation loss = 2.8461  \n",
      "\n",
      "Fold: 11  Epoch: 200  Training loss = 3.6489  Validation loss = 2.8456  \n",
      "\n",
      "Fold: 11  Epoch: 201  Training loss = 3.6486  Validation loss = 2.8450  \n",
      "\n",
      "Fold: 11  Epoch: 202  Training loss = 3.6482  Validation loss = 2.8444  \n",
      "\n",
      "Fold: 11  Epoch: 203  Training loss = 3.6480  Validation loss = 2.8439  \n",
      "\n",
      "Fold: 11  Epoch: 204  Training loss = 3.6476  Validation loss = 2.8432  \n",
      "\n",
      "Fold: 11  Epoch: 205  Training loss = 3.6473  Validation loss = 2.8427  \n",
      "\n",
      "Fold: 11  Epoch: 206  Training loss = 3.6469  Validation loss = 2.8421  \n",
      "\n",
      "Fold: 11  Epoch: 207  Training loss = 3.6465  Validation loss = 2.8413  \n",
      "\n",
      "Fold: 11  Epoch: 208  Training loss = 3.6461  Validation loss = 2.8405  \n",
      "\n",
      "Fold: 11  Epoch: 209  Training loss = 3.6458  Validation loss = 2.8400  \n",
      "\n",
      "Fold: 11  Epoch: 210  Training loss = 3.6454  Validation loss = 2.8394  \n",
      "\n",
      "Fold: 11  Epoch: 211  Training loss = 3.6451  Validation loss = 2.8388  \n",
      "\n",
      "Fold: 11  Epoch: 212  Training loss = 3.6447  Validation loss = 2.8380  \n",
      "\n",
      "Fold: 11  Epoch: 213  Training loss = 3.6444  Validation loss = 2.8374  \n",
      "\n",
      "Fold: 11  Epoch: 214  Training loss = 3.6440  Validation loss = 2.8368  \n",
      "\n",
      "Fold: 11  Epoch: 215  Training loss = 3.6438  Validation loss = 2.8363  \n",
      "\n",
      "Fold: 11  Epoch: 216  Training loss = 3.6435  Validation loss = 2.8358  \n",
      "\n",
      "Fold: 11  Epoch: 217  Training loss = 3.6433  Validation loss = 2.8354  \n",
      "\n",
      "Fold: 11  Epoch: 218  Training loss = 3.6429  Validation loss = 2.8348  \n",
      "\n",
      "Fold: 11  Epoch: 219  Training loss = 3.6426  Validation loss = 2.8341  \n",
      "\n",
      "Fold: 11  Epoch: 220  Training loss = 3.6423  Validation loss = 2.8336  \n",
      "\n",
      "Fold: 11  Epoch: 221  Training loss = 3.6419  Validation loss = 2.8329  \n",
      "\n",
      "Fold: 11  Epoch: 222  Training loss = 3.6416  Validation loss = 2.8323  \n",
      "\n",
      "Fold: 11  Epoch: 223  Training loss = 3.6412  Validation loss = 2.8316  \n",
      "\n",
      "Fold: 11  Epoch: 224  Training loss = 3.6409  Validation loss = 2.8309  \n",
      "\n",
      "Fold: 11  Epoch: 225  Training loss = 3.6406  Validation loss = 2.8304  \n",
      "\n",
      "Fold: 11  Epoch: 226  Training loss = 3.6403  Validation loss = 2.8299  \n",
      "\n",
      "Fold: 11  Epoch: 227  Training loss = 3.6400  Validation loss = 2.8293  \n",
      "\n",
      "Fold: 11  Epoch: 228  Training loss = 3.6397  Validation loss = 2.8288  \n",
      "\n",
      "Fold: 11  Epoch: 229  Training loss = 3.6393  Validation loss = 2.8282  \n",
      "\n",
      "Fold: 11  Epoch: 230  Training loss = 3.6390  Validation loss = 2.8276  \n",
      "\n",
      "Fold: 11  Epoch: 231  Training loss = 3.6387  Validation loss = 2.8270  \n",
      "\n",
      "Fold: 11  Epoch: 232  Training loss = 3.6383  Validation loss = 2.8263  \n",
      "\n",
      "Fold: 11  Epoch: 233  Training loss = 3.6379  Validation loss = 2.8256  \n",
      "\n",
      "Fold: 11  Epoch: 234  Training loss = 3.6377  Validation loss = 2.8253  \n",
      "\n",
      "Fold: 11  Epoch: 235  Training loss = 3.6375  Validation loss = 2.8248  \n",
      "\n",
      "Fold: 11  Epoch: 236  Training loss = 3.6372  Validation loss = 2.8243  \n",
      "\n",
      "Fold: 11  Epoch: 237  Training loss = 3.6369  Validation loss = 2.8237  \n",
      "\n",
      "Fold: 11  Epoch: 238  Training loss = 3.6366  Validation loss = 2.8232  \n",
      "\n",
      "Fold: 11  Epoch: 239  Training loss = 3.6364  Validation loss = 2.8227  \n",
      "\n",
      "Fold: 11  Epoch: 240  Training loss = 3.6361  Validation loss = 2.8223  \n",
      "\n",
      "Fold: 11  Epoch: 241  Training loss = 3.6358  Validation loss = 2.8217  \n",
      "\n",
      "Fold: 11  Epoch: 242  Training loss = 3.6354  Validation loss = 2.8210  \n",
      "\n",
      "Fold: 11  Epoch: 243  Training loss = 3.6350  Validation loss = 2.8203  \n",
      "\n",
      "Fold: 11  Epoch: 244  Training loss = 3.6347  Validation loss = 2.8197  \n",
      "\n",
      "Fold: 11  Epoch: 245  Training loss = 3.6344  Validation loss = 2.8191  \n",
      "\n",
      "Fold: 11  Epoch: 246  Training loss = 3.6340  Validation loss = 2.8184  \n",
      "\n",
      "Fold: 11  Epoch: 247  Training loss = 3.6337  Validation loss = 2.8178  \n",
      "\n",
      "Fold: 11  Epoch: 248  Training loss = 3.6332  Validation loss = 2.8170  \n",
      "\n",
      "Fold: 11  Epoch: 249  Training loss = 3.6329  Validation loss = 2.8164  \n",
      "\n",
      "Fold: 11  Epoch: 250  Training loss = 3.6327  Validation loss = 2.8160  \n",
      "\n",
      "Fold: 11  Epoch: 251  Training loss = 3.6324  Validation loss = 2.8155  \n",
      "\n",
      "Fold: 11  Epoch: 252  Training loss = 3.6322  Validation loss = 2.8150  \n",
      "\n",
      "Fold: 11  Epoch: 253  Training loss = 3.6317  Validation loss = 2.8143  \n",
      "\n",
      "Fold: 11  Epoch: 254  Training loss = 3.6314  Validation loss = 2.8136  \n",
      "\n",
      "Fold: 11  Epoch: 255  Training loss = 3.6309  Validation loss = 2.8127  \n",
      "\n",
      "Fold: 11  Epoch: 256  Training loss = 3.6305  Validation loss = 2.8120  \n",
      "\n",
      "Fold: 11  Epoch: 257  Training loss = 3.6301  Validation loss = 2.8113  \n",
      "\n",
      "Fold: 11  Epoch: 258  Training loss = 3.6298  Validation loss = 2.8107  \n",
      "\n",
      "Fold: 11  Epoch: 259  Training loss = 3.6295  Validation loss = 2.8102  \n",
      "\n",
      "Fold: 11  Epoch: 260  Training loss = 3.6292  Validation loss = 2.8097  \n",
      "\n",
      "Fold: 11  Epoch: 261  Training loss = 3.6290  Validation loss = 2.8092  \n",
      "\n",
      "Fold: 11  Epoch: 262  Training loss = 3.6287  Validation loss = 2.8087  \n",
      "\n",
      "Fold: 11  Epoch: 263  Training loss = 3.6285  Validation loss = 2.8083  \n",
      "\n",
      "Fold: 11  Epoch: 264  Training loss = 3.6282  Validation loss = 2.8078  \n",
      "\n",
      "Fold: 11  Epoch: 265  Training loss = 3.6278  Validation loss = 2.8071  \n",
      "\n",
      "Fold: 11  Epoch: 266  Training loss = 3.6275  Validation loss = 2.8065  \n",
      "\n",
      "Fold: 11  Epoch: 267  Training loss = 3.6272  Validation loss = 2.8059  \n",
      "\n",
      "Fold: 11  Epoch: 268  Training loss = 3.6269  Validation loss = 2.8053  \n",
      "\n",
      "Fold: 11  Epoch: 269  Training loss = 3.6266  Validation loss = 2.8047  \n",
      "\n",
      "Fold: 11  Epoch: 270  Training loss = 3.6264  Validation loss = 2.8044  \n",
      "\n",
      "Fold: 11  Epoch: 271  Training loss = 3.6260  Validation loss = 2.8037  \n",
      "\n",
      "Fold: 11  Epoch: 272  Training loss = 3.6257  Validation loss = 2.8031  \n",
      "\n",
      "Fold: 11  Epoch: 273  Training loss = 3.6254  Validation loss = 2.8025  \n",
      "\n",
      "Fold: 11  Epoch: 274  Training loss = 3.6250  Validation loss = 2.8019  \n",
      "\n",
      "Fold: 11  Epoch: 275  Training loss = 3.6247  Validation loss = 2.8012  \n",
      "\n",
      "Fold: 11  Epoch: 276  Training loss = 3.6243  Validation loss = 2.8005  \n",
      "\n",
      "Fold: 11  Epoch: 277  Training loss = 3.6239  Validation loss = 2.7999  \n",
      "\n",
      "Fold: 11  Epoch: 278  Training loss = 3.6236  Validation loss = 2.7992  \n",
      "\n",
      "Fold: 11  Epoch: 279  Training loss = 3.6232  Validation loss = 2.7985  \n",
      "\n",
      "Fold: 11  Epoch: 280  Training loss = 3.6228  Validation loss = 2.7979  \n",
      "\n",
      "Fold: 11  Epoch: 281  Training loss = 3.6226  Validation loss = 2.7974  \n",
      "\n",
      "Fold: 11  Epoch: 282  Training loss = 3.6223  Validation loss = 2.7968  \n",
      "\n",
      "Fold: 11  Epoch: 283  Training loss = 3.6219  Validation loss = 2.7961  \n",
      "\n",
      "Fold: 11  Epoch: 284  Training loss = 3.6216  Validation loss = 2.7956  \n",
      "\n",
      "Fold: 11  Epoch: 285  Training loss = 3.6212  Validation loss = 2.7949  \n",
      "\n",
      "Fold: 11  Epoch: 286  Training loss = 3.6209  Validation loss = 2.7944  \n",
      "\n",
      "Fold: 11  Epoch: 287  Training loss = 3.6206  Validation loss = 2.7938  \n",
      "\n",
      "Fold: 11  Epoch: 288  Training loss = 3.6203  Validation loss = 2.7932  \n",
      "\n",
      "Fold: 11  Epoch: 289  Training loss = 3.6200  Validation loss = 2.7926  \n",
      "\n",
      "Fold: 11  Epoch: 290  Training loss = 3.6196  Validation loss = 2.7920  \n",
      "\n",
      "Fold: 11  Epoch: 291  Training loss = 3.6193  Validation loss = 2.7913  \n",
      "\n",
      "Fold: 11  Epoch: 292  Training loss = 3.6190  Validation loss = 2.7907  \n",
      "\n",
      "Fold: 11  Epoch: 293  Training loss = 3.6187  Validation loss = 2.7902  \n",
      "\n",
      "Fold: 11  Epoch: 294  Training loss = 3.6184  Validation loss = 2.7896  \n",
      "\n",
      "Fold: 11  Epoch: 295  Training loss = 3.6181  Validation loss = 2.7890  \n",
      "\n",
      "Fold: 11  Epoch: 296  Training loss = 3.6178  Validation loss = 2.7885  \n",
      "\n",
      "Fold: 11  Epoch: 297  Training loss = 3.6174  Validation loss = 2.7879  \n",
      "\n",
      "Fold: 11  Epoch: 298  Training loss = 3.6172  Validation loss = 2.7873  \n",
      "\n",
      "Fold: 11  Epoch: 299  Training loss = 3.6168  Validation loss = 2.7867  \n",
      "\n",
      "Fold: 11  Epoch: 300  Training loss = 3.6166  Validation loss = 2.7862  \n",
      "\n",
      "Fold: 11  Epoch: 301  Training loss = 3.6162  Validation loss = 2.7856  \n",
      "\n",
      "Fold: 11  Epoch: 302  Training loss = 3.6159  Validation loss = 2.7850  \n",
      "\n",
      "Fold: 11  Epoch: 303  Training loss = 3.6155  Validation loss = 2.7843  \n",
      "\n",
      "Fold: 11  Epoch: 304  Training loss = 3.6151  Validation loss = 2.7836  \n",
      "\n",
      "Fold: 11  Epoch: 305  Training loss = 3.6148  Validation loss = 2.7829  \n",
      "\n",
      "Fold: 11  Epoch: 306  Training loss = 3.6143  Validation loss = 2.7821  \n",
      "\n",
      "Fold: 11  Epoch: 307  Training loss = 3.6140  Validation loss = 2.7815  \n",
      "\n",
      "Fold: 11  Epoch: 308  Training loss = 3.6136  Validation loss = 2.7809  \n",
      "\n",
      "Fold: 11  Epoch: 309  Training loss = 3.6133  Validation loss = 2.7803  \n",
      "\n",
      "Fold: 11  Epoch: 310  Training loss = 3.6130  Validation loss = 2.7797  \n",
      "\n",
      "Fold: 11  Epoch: 311  Training loss = 3.6126  Validation loss = 2.7790  \n",
      "\n",
      "Fold: 11  Epoch: 312  Training loss = 3.6123  Validation loss = 2.7784  \n",
      "\n",
      "Fold: 11  Epoch: 313  Training loss = 3.6120  Validation loss = 2.7779  \n",
      "\n",
      "Fold: 11  Epoch: 314  Training loss = 3.6117  Validation loss = 2.7773  \n",
      "\n",
      "Fold: 11  Epoch: 315  Training loss = 3.6113  Validation loss = 2.7766  \n",
      "\n",
      "Fold: 11  Epoch: 316  Training loss = 3.6109  Validation loss = 2.7759  \n",
      "\n",
      "Fold: 11  Epoch: 317  Training loss = 3.6107  Validation loss = 2.7754  \n",
      "\n",
      "Fold: 11  Epoch: 318  Training loss = 3.6104  Validation loss = 2.7749  \n",
      "\n",
      "Fold: 11  Epoch: 319  Training loss = 3.6101  Validation loss = 2.7744  \n",
      "\n",
      "Fold: 11  Epoch: 320  Training loss = 3.6098  Validation loss = 2.7738  \n",
      "\n",
      "Fold: 11  Epoch: 321  Training loss = 3.6095  Validation loss = 2.7733  \n",
      "\n",
      "Fold: 11  Epoch: 322  Training loss = 3.6092  Validation loss = 2.7727  \n",
      "\n",
      "Fold: 11  Epoch: 323  Training loss = 3.6090  Validation loss = 2.7723  \n",
      "\n",
      "Fold: 11  Epoch: 324  Training loss = 3.6086  Validation loss = 2.7716  \n",
      "\n",
      "Fold: 11  Epoch: 325  Training loss = 3.6084  Validation loss = 2.7711  \n",
      "\n",
      "Fold: 11  Epoch: 326  Training loss = 3.6081  Validation loss = 2.7706  \n",
      "\n",
      "Fold: 11  Epoch: 327  Training loss = 3.6077  Validation loss = 2.7699  \n",
      "\n",
      "Fold: 11  Epoch: 328  Training loss = 3.6075  Validation loss = 2.7696  \n",
      "\n",
      "Fold: 11  Epoch: 329  Training loss = 3.6073  Validation loss = 2.7691  \n",
      "\n",
      "Fold: 11  Epoch: 330  Training loss = 3.6070  Validation loss = 2.7686  \n",
      "\n",
      "Fold: 11  Epoch: 331  Training loss = 3.6066  Validation loss = 2.7679  \n",
      "\n",
      "Fold: 11  Epoch: 332  Training loss = 3.6063  Validation loss = 2.7672  \n",
      "\n",
      "Fold: 11  Epoch: 333  Training loss = 3.6060  Validation loss = 2.7667  \n",
      "\n",
      "Fold: 11  Epoch: 334  Training loss = 3.6056  Validation loss = 2.7660  \n",
      "\n",
      "Fold: 11  Epoch: 335  Training loss = 3.6052  Validation loss = 2.7653  \n",
      "\n",
      "Fold: 11  Epoch: 336  Training loss = 3.6049  Validation loss = 2.7647  \n",
      "\n",
      "Fold: 11  Epoch: 337  Training loss = 3.6046  Validation loss = 2.7640  \n",
      "\n",
      "Fold: 11  Epoch: 338  Training loss = 3.6042  Validation loss = 2.7634  \n",
      "\n",
      "Fold: 11  Epoch: 339  Training loss = 3.6039  Validation loss = 2.7629  \n",
      "\n",
      "Fold: 11  Epoch: 340  Training loss = 3.6036  Validation loss = 2.7622  \n",
      "\n",
      "Fold: 11  Epoch: 341  Training loss = 3.6033  Validation loss = 2.7616  \n",
      "\n",
      "Fold: 11  Epoch: 342  Training loss = 3.6029  Validation loss = 2.7610  \n",
      "\n",
      "Fold: 11  Epoch: 343  Training loss = 3.6027  Validation loss = 2.7605  \n",
      "\n",
      "Fold: 11  Epoch: 344  Training loss = 3.6024  Validation loss = 2.7600  \n",
      "\n",
      "Fold: 11  Epoch: 345  Training loss = 3.6021  Validation loss = 2.7594  \n",
      "\n",
      "Fold: 11  Epoch: 346  Training loss = 3.6018  Validation loss = 2.7589  \n",
      "\n",
      "Fold: 11  Epoch: 347  Training loss = 3.6015  Validation loss = 2.7583  \n",
      "\n",
      "Fold: 11  Epoch: 348  Training loss = 3.6011  Validation loss = 2.7576  \n",
      "\n",
      "Fold: 11  Epoch: 349  Training loss = 3.6008  Validation loss = 2.7570  \n",
      "\n",
      "Fold: 11  Epoch: 350  Training loss = 3.6005  Validation loss = 2.7565  \n",
      "\n",
      "Fold: 11  Epoch: 351  Training loss = 3.6001  Validation loss = 2.7558  \n",
      "\n",
      "Fold: 11  Epoch: 352  Training loss = 3.5998  Validation loss = 2.7551  \n",
      "\n",
      "Fold: 11  Epoch: 353  Training loss = 3.5996  Validation loss = 2.7547  \n",
      "\n",
      "Fold: 11  Epoch: 354  Training loss = 3.5993  Validation loss = 2.7543  \n",
      "\n",
      "Fold: 11  Epoch: 355  Training loss = 3.5990  Validation loss = 2.7537  \n",
      "\n",
      "Fold: 11  Epoch: 356  Training loss = 3.5987  Validation loss = 2.7531  \n",
      "\n",
      "Fold: 11  Epoch: 357  Training loss = 3.5983  Validation loss = 2.7523  \n",
      "\n",
      "Fold: 11  Epoch: 358  Training loss = 3.5980  Validation loss = 2.7518  \n",
      "\n",
      "Fold: 11  Epoch: 359  Training loss = 3.5976  Validation loss = 2.7511  \n",
      "\n",
      "Fold: 11  Epoch: 360  Training loss = 3.5972  Validation loss = 2.7504  \n",
      "\n",
      "Fold: 11  Epoch: 361  Training loss = 3.5969  Validation loss = 2.7498  \n",
      "\n",
      "Fold: 11  Epoch: 362  Training loss = 3.5966  Validation loss = 2.7492  \n",
      "\n",
      "Fold: 11  Epoch: 363  Training loss = 3.5963  Validation loss = 2.7487  \n",
      "\n",
      "Fold: 11  Epoch: 364  Training loss = 3.5960  Validation loss = 2.7480  \n",
      "\n",
      "Fold: 11  Epoch: 365  Training loss = 3.5956  Validation loss = 2.7474  \n",
      "\n",
      "Fold: 11  Epoch: 366  Training loss = 3.5953  Validation loss = 2.7468  \n",
      "\n",
      "Fold: 11  Epoch: 367  Training loss = 3.5950  Validation loss = 2.7462  \n",
      "\n",
      "Fold: 11  Epoch: 368  Training loss = 3.5947  Validation loss = 2.7457  \n",
      "\n",
      "Fold: 11  Epoch: 369  Training loss = 3.5944  Validation loss = 2.7451  \n",
      "\n",
      "Fold: 11  Epoch: 370  Training loss = 3.5940  Validation loss = 2.7444  \n",
      "\n",
      "Fold: 11  Epoch: 371  Training loss = 3.5938  Validation loss = 2.7440  \n",
      "\n",
      "Fold: 11  Epoch: 372  Training loss = 3.5934  Validation loss = 2.7433  \n",
      "\n",
      "Fold: 11  Epoch: 373  Training loss = 3.5931  Validation loss = 2.7428  \n",
      "\n",
      "Fold: 11  Epoch: 374  Training loss = 3.5928  Validation loss = 2.7422  \n",
      "\n",
      "Fold: 11  Epoch: 375  Training loss = 3.5926  Validation loss = 2.7417  \n",
      "\n",
      "Fold: 11  Epoch: 376  Training loss = 3.5921  Validation loss = 2.7409  \n",
      "\n",
      "Fold: 11  Epoch: 377  Training loss = 3.5918  Validation loss = 2.7402  \n",
      "\n",
      "Fold: 11  Epoch: 378  Training loss = 3.5915  Validation loss = 2.7397  \n",
      "\n",
      "Fold: 11  Epoch: 379  Training loss = 3.5912  Validation loss = 2.7391  \n",
      "\n",
      "Fold: 11  Epoch: 380  Training loss = 3.5908  Validation loss = 2.7384  \n",
      "\n",
      "Fold: 11  Epoch: 381  Training loss = 3.5904  Validation loss = 2.7376  \n",
      "\n",
      "Fold: 11  Epoch: 382  Training loss = 3.5901  Validation loss = 2.7370  \n",
      "\n",
      "Fold: 11  Epoch: 383  Training loss = 3.5897  Validation loss = 2.7364  \n",
      "\n",
      "Fold: 11  Epoch: 384  Training loss = 3.5893  Validation loss = 2.7356  \n",
      "\n",
      "Fold: 11  Epoch: 385  Training loss = 3.5890  Validation loss = 2.7349  \n",
      "\n",
      "Fold: 11  Epoch: 386  Training loss = 3.5887  Validation loss = 2.7344  \n",
      "\n",
      "Fold: 11  Epoch: 387  Training loss = 3.5884  Validation loss = 2.7339  \n",
      "\n",
      "Fold: 11  Epoch: 388  Training loss = 3.5880  Validation loss = 2.7331  \n",
      "\n",
      "Fold: 11  Epoch: 389  Training loss = 3.5876  Validation loss = 2.7324  \n",
      "\n",
      "Fold: 11  Epoch: 390  Training loss = 3.5873  Validation loss = 2.7319  \n",
      "\n",
      "Fold: 11  Epoch: 391  Training loss = 3.5870  Validation loss = 2.7313  \n",
      "\n",
      "Fold: 11  Epoch: 392  Training loss = 3.5868  Validation loss = 2.7309  \n",
      "\n",
      "Fold: 11  Epoch: 393  Training loss = 3.5864  Validation loss = 2.7301  \n",
      "\n",
      "Fold: 11  Epoch: 394  Training loss = 3.5859  Validation loss = 2.7292  \n",
      "\n",
      "Fold: 11  Epoch: 395  Training loss = 3.5857  Validation loss = 2.7289  \n",
      "\n",
      "Fold: 11  Epoch: 396  Training loss = 3.5855  Validation loss = 2.7284  \n",
      "\n",
      "Fold: 11  Epoch: 397  Training loss = 3.5852  Validation loss = 2.7278  \n",
      "\n",
      "Fold: 11  Epoch: 398  Training loss = 3.5849  Validation loss = 2.7273  \n",
      "\n",
      "Fold: 11  Epoch: 399  Training loss = 3.5845  Validation loss = 2.7265  \n",
      "\n",
      "Fold: 11  Epoch: 400  Training loss = 3.5842  Validation loss = 2.7260  \n",
      "\n",
      "Fold: 11  Epoch: 401  Training loss = 3.5839  Validation loss = 2.7255  \n",
      "\n",
      "Fold: 11  Epoch: 402  Training loss = 3.5835  Validation loss = 2.7247  \n",
      "\n",
      "Fold: 11  Epoch: 403  Training loss = 3.5832  Validation loss = 2.7241  \n",
      "\n",
      "Fold: 11  Epoch: 404  Training loss = 3.5829  Validation loss = 2.7235  \n",
      "\n",
      "Fold: 11  Epoch: 405  Training loss = 3.5825  Validation loss = 2.7228  \n",
      "\n",
      "Fold: 11  Epoch: 406  Training loss = 3.5823  Validation loss = 2.7224  \n",
      "\n",
      "Fold: 11  Epoch: 407  Training loss = 3.5820  Validation loss = 2.7219  \n",
      "\n",
      "Fold: 11  Epoch: 408  Training loss = 3.5818  Validation loss = 2.7214  \n",
      "\n",
      "Fold: 11  Epoch: 409  Training loss = 3.5814  Validation loss = 2.7207  \n",
      "\n",
      "Fold: 11  Epoch: 410  Training loss = 3.5811  Validation loss = 2.7200  \n",
      "\n",
      "Fold: 11  Epoch: 411  Training loss = 3.5808  Validation loss = 2.7195  \n",
      "\n",
      "Fold: 11  Epoch: 412  Training loss = 3.5804  Validation loss = 2.7188  \n",
      "\n",
      "Fold: 11  Epoch: 413  Training loss = 3.5801  Validation loss = 2.7183  \n",
      "\n",
      "Fold: 11  Epoch: 414  Training loss = 3.5799  Validation loss = 2.7178  \n",
      "\n",
      "Fold: 11  Epoch: 415  Training loss = 3.5795  Validation loss = 2.7170  \n",
      "\n",
      "Fold: 11  Epoch: 416  Training loss = 3.5791  Validation loss = 2.7164  \n",
      "\n",
      "Fold: 11  Epoch: 417  Training loss = 3.5788  Validation loss = 2.7158  \n",
      "\n",
      "Fold: 11  Epoch: 418  Training loss = 3.5785  Validation loss = 2.7152  \n",
      "\n",
      "Fold: 11  Epoch: 419  Training loss = 3.5782  Validation loss = 2.7147  \n",
      "\n",
      "Fold: 11  Epoch: 420  Training loss = 3.5779  Validation loss = 2.7140  \n",
      "\n",
      "Fold: 11  Epoch: 421  Training loss = 3.5775  Validation loss = 2.7133  \n",
      "\n",
      "Fold: 11  Epoch: 422  Training loss = 3.5772  Validation loss = 2.7128  \n",
      "\n",
      "Fold: 11  Epoch: 423  Training loss = 3.5768  Validation loss = 2.7120  \n",
      "\n",
      "Fold: 11  Epoch: 424  Training loss = 3.5767  Validation loss = 2.7117  \n",
      "\n",
      "Fold: 11  Epoch: 425  Training loss = 3.5764  Validation loss = 2.7112  \n",
      "\n",
      "Fold: 11  Epoch: 426  Training loss = 3.5760  Validation loss = 2.7105  \n",
      "\n",
      "Fold: 11  Epoch: 427  Training loss = 3.5757  Validation loss = 2.7099  \n",
      "\n",
      "Fold: 11  Epoch: 428  Training loss = 3.5754  Validation loss = 2.7093  \n",
      "\n",
      "Fold: 11  Epoch: 429  Training loss = 3.5750  Validation loss = 2.7086  \n",
      "\n",
      "Fold: 11  Epoch: 430  Training loss = 3.5748  Validation loss = 2.7082  \n",
      "\n",
      "Fold: 11  Epoch: 431  Training loss = 3.5743  Validation loss = 2.7073  \n",
      "\n",
      "Fold: 11  Epoch: 432  Training loss = 3.5740  Validation loss = 2.7068  \n",
      "\n",
      "Fold: 11  Epoch: 433  Training loss = 3.5738  Validation loss = 2.7063  \n",
      "\n",
      "Fold: 11  Epoch: 434  Training loss = 3.5735  Validation loss = 2.7058  \n",
      "\n",
      "Fold: 11  Epoch: 435  Training loss = 3.5732  Validation loss = 2.7052  \n",
      "\n",
      "Fold: 11  Epoch: 436  Training loss = 3.5729  Validation loss = 2.7047  \n",
      "\n",
      "Fold: 11  Epoch: 437  Training loss = 3.5727  Validation loss = 2.7042  \n",
      "\n",
      "Fold: 11  Epoch: 438  Training loss = 3.5724  Validation loss = 2.7036  \n",
      "\n",
      "Fold: 11  Epoch: 439  Training loss = 3.5721  Validation loss = 2.7031  \n",
      "\n",
      "Fold: 11  Epoch: 440  Training loss = 3.5717  Validation loss = 2.7024  \n",
      "\n",
      "Fold: 11  Epoch: 441  Training loss = 3.5715  Validation loss = 2.7019  \n",
      "\n",
      "Fold: 11  Epoch: 442  Training loss = 3.5712  Validation loss = 2.7015  \n",
      "\n",
      "Fold: 11  Epoch: 443  Training loss = 3.5709  Validation loss = 2.7009  \n",
      "\n",
      "Fold: 11  Epoch: 444  Training loss = 3.5706  Validation loss = 2.7003  \n",
      "\n",
      "Fold: 11  Epoch: 445  Training loss = 3.5703  Validation loss = 2.6998  \n",
      "\n",
      "Fold: 11  Epoch: 446  Training loss = 3.5700  Validation loss = 2.6991  \n",
      "\n",
      "Fold: 11  Epoch: 447  Training loss = 3.5696  Validation loss = 2.6984  \n",
      "\n",
      "Fold: 11  Epoch: 448  Training loss = 3.5693  Validation loss = 2.6979  \n",
      "\n",
      "Fold: 11  Epoch: 449  Training loss = 3.5690  Validation loss = 2.6973  \n",
      "\n",
      "Fold: 11  Epoch: 450  Training loss = 3.5687  Validation loss = 2.6967  \n",
      "\n",
      "Fold: 11  Epoch: 451  Training loss = 3.5683  Validation loss = 2.6960  \n",
      "\n",
      "Fold: 11  Epoch: 452  Training loss = 3.5680  Validation loss = 2.6954  \n",
      "\n",
      "Fold: 11  Epoch: 453  Training loss = 3.5677  Validation loss = 2.6948  \n",
      "\n",
      "Fold: 11  Epoch: 454  Training loss = 3.5673  Validation loss = 2.6942  \n",
      "\n",
      "Fold: 11  Epoch: 455  Training loss = 3.5670  Validation loss = 2.6936  \n",
      "\n",
      "Fold: 11  Epoch: 456  Training loss = 3.5667  Validation loss = 2.6930  \n",
      "\n",
      "Fold: 11  Epoch: 457  Training loss = 3.5664  Validation loss = 2.6924  \n",
      "\n",
      "Fold: 11  Epoch: 458  Training loss = 3.5662  Validation loss = 2.6921  \n",
      "\n",
      "Fold: 11  Epoch: 459  Training loss = 3.5659  Validation loss = 2.6916  \n",
      "\n",
      "Fold: 11  Epoch: 460  Training loss = 3.5656  Validation loss = 2.6910  \n",
      "\n",
      "Fold: 11  Epoch: 461  Training loss = 3.5654  Validation loss = 2.6906  \n",
      "\n",
      "Fold: 11  Epoch: 462  Training loss = 3.5650  Validation loss = 2.6899  \n",
      "\n",
      "Fold: 11  Epoch: 463  Training loss = 3.5646  Validation loss = 2.6891  \n",
      "\n",
      "Fold: 11  Epoch: 464  Training loss = 3.5644  Validation loss = 2.6886  \n",
      "\n",
      "Fold: 11  Epoch: 465  Training loss = 3.5641  Validation loss = 2.6880  \n",
      "\n",
      "Fold: 11  Epoch: 466  Training loss = 3.5638  Validation loss = 2.6875  \n",
      "\n",
      "Fold: 11  Epoch: 467  Training loss = 3.5635  Validation loss = 2.6869  \n",
      "\n",
      "Fold: 11  Epoch: 468  Training loss = 3.5633  Validation loss = 2.6866  \n",
      "\n",
      "Fold: 11  Epoch: 469  Training loss = 3.5630  Validation loss = 2.6861  \n",
      "\n",
      "Fold: 11  Epoch: 470  Training loss = 3.5627  Validation loss = 2.6855  \n",
      "\n",
      "Fold: 11  Epoch: 471  Training loss = 3.5625  Validation loss = 2.6850  \n",
      "\n",
      "Fold: 11  Epoch: 472  Training loss = 3.5622  Validation loss = 2.6845  \n",
      "\n",
      "Fold: 11  Epoch: 473  Training loss = 3.5619  Validation loss = 2.6838  \n",
      "\n",
      "Fold: 11  Epoch: 474  Training loss = 3.5616  Validation loss = 2.6834  \n",
      "\n",
      "Fold: 11  Epoch: 475  Training loss = 3.5614  Validation loss = 2.6829  \n",
      "\n",
      "Fold: 11  Epoch: 476  Training loss = 3.5611  Validation loss = 2.6823  \n",
      "\n",
      "Fold: 11  Epoch: 477  Training loss = 3.5608  Validation loss = 2.6819  \n",
      "\n",
      "Fold: 11  Epoch: 478  Training loss = 3.5606  Validation loss = 2.6814  \n",
      "\n",
      "Fold: 11  Epoch: 479  Training loss = 3.5603  Validation loss = 2.6810  \n",
      "\n",
      "Fold: 11  Epoch: 480  Training loss = 3.5600  Validation loss = 2.6802  \n",
      "\n",
      "Fold: 11  Epoch: 481  Training loss = 3.5597  Validation loss = 2.6797  \n",
      "\n",
      "Fold: 11  Epoch: 482  Training loss = 3.5595  Validation loss = 2.6793  \n",
      "\n",
      "Fold: 11  Epoch: 483  Training loss = 3.5592  Validation loss = 2.6788  \n",
      "\n",
      "Fold: 11  Epoch: 484  Training loss = 3.5590  Validation loss = 2.6784  \n",
      "\n",
      "Fold: 11  Epoch: 485  Training loss = 3.5587  Validation loss = 2.6779  \n",
      "\n",
      "Fold: 11  Epoch: 486  Training loss = 3.5584  Validation loss = 2.6773  \n",
      "\n",
      "Fold: 11  Epoch: 487  Training loss = 3.5581  Validation loss = 2.6768  \n",
      "\n",
      "Fold: 11  Epoch: 488  Training loss = 3.5579  Validation loss = 2.6763  \n",
      "\n",
      "Fold: 11  Epoch: 489  Training loss = 3.5576  Validation loss = 2.6757  \n",
      "\n",
      "Fold: 11  Epoch: 490  Training loss = 3.5573  Validation loss = 2.6751  \n",
      "\n",
      "Fold: 11  Epoch: 491  Training loss = 3.5571  Validation loss = 2.6747  \n",
      "\n",
      "Fold: 11  Epoch: 492  Training loss = 3.5568  Validation loss = 2.6743  \n",
      "\n",
      "Fold: 11  Epoch: 493  Training loss = 3.5566  Validation loss = 2.6738  \n",
      "\n",
      "Fold: 11  Epoch: 494  Training loss = 3.5563  Validation loss = 2.6733  \n",
      "\n",
      "Fold: 11  Epoch: 495  Training loss = 3.5560  Validation loss = 2.6727  \n",
      "\n",
      "Fold: 11  Epoch: 496  Training loss = 3.5557  Validation loss = 2.6721  \n",
      "\n",
      "Fold: 11  Epoch: 497  Training loss = 3.5554  Validation loss = 2.6716  \n",
      "\n",
      "Fold: 11  Epoch: 498  Training loss = 3.5552  Validation loss = 2.6712  \n",
      "\n",
      "Fold: 11  Epoch: 499  Training loss = 3.5549  Validation loss = 2.6707  \n",
      "\n",
      "Fold: 11  Epoch: 500  Training loss = 3.5546  Validation loss = 2.6701  \n",
      "\n",
      "Check model:  Fold: 11  Epoch: 500  Training loss = 3.5546  Validation loss = 2.6701  \n",
      "\n",
      "Fold: 12  Epoch: 1  Training loss = 3.6026  Validation loss = 4.0093  \n",
      "\n",
      "Fold: 12  Epoch: 2  Training loss = 3.6022  Validation loss = 4.0085  \n",
      "\n",
      "Fold: 12  Epoch: 3  Training loss = 3.6018  Validation loss = 4.0078  \n",
      "\n",
      "Fold: 12  Epoch: 4  Training loss = 3.6014  Validation loss = 4.0070  \n",
      "\n",
      "Fold: 12  Epoch: 5  Training loss = 3.6011  Validation loss = 4.0064  \n",
      "\n",
      "Fold: 12  Epoch: 6  Training loss = 3.6007  Validation loss = 4.0055  \n",
      "\n",
      "Fold: 12  Epoch: 7  Training loss = 3.6003  Validation loss = 4.0048  \n",
      "\n",
      "Fold: 12  Epoch: 8  Training loss = 3.5998  Validation loss = 4.0040  \n",
      "\n",
      "Fold: 12  Epoch: 9  Training loss = 3.5994  Validation loss = 4.0031  \n",
      "\n",
      "Fold: 12  Epoch: 10  Training loss = 3.5991  Validation loss = 4.0025  \n",
      "\n",
      "Fold: 12  Epoch: 11  Training loss = 3.5988  Validation loss = 4.0019  \n",
      "\n",
      "Fold: 12  Epoch: 12  Training loss = 3.5983  Validation loss = 4.0009  \n",
      "\n",
      "Fold: 12  Epoch: 13  Training loss = 3.5979  Validation loss = 4.0002  \n",
      "\n",
      "Fold: 12  Epoch: 14  Training loss = 3.5976  Validation loss = 3.9996  \n",
      "\n",
      "Fold: 12  Epoch: 15  Training loss = 3.5972  Validation loss = 3.9988  \n",
      "\n",
      "Fold: 12  Epoch: 16  Training loss = 3.5968  Validation loss = 3.9981  \n",
      "\n",
      "Fold: 12  Epoch: 17  Training loss = 3.5965  Validation loss = 3.9976  \n",
      "\n",
      "Fold: 12  Epoch: 18  Training loss = 3.5961  Validation loss = 3.9968  \n",
      "\n",
      "Fold: 12  Epoch: 19  Training loss = 3.5958  Validation loss = 3.9962  \n",
      "\n",
      "Fold: 12  Epoch: 20  Training loss = 3.5955  Validation loss = 3.9956  \n",
      "\n",
      "Fold: 12  Epoch: 21  Training loss = 3.5952  Validation loss = 3.9949  \n",
      "\n",
      "Fold: 12  Epoch: 22  Training loss = 3.5949  Validation loss = 3.9943  \n",
      "\n",
      "Fold: 12  Epoch: 23  Training loss = 3.5946  Validation loss = 3.9938  \n",
      "\n",
      "Fold: 12  Epoch: 24  Training loss = 3.5943  Validation loss = 3.9932  \n",
      "\n",
      "Fold: 12  Epoch: 25  Training loss = 3.5939  Validation loss = 3.9925  \n",
      "\n",
      "Fold: 12  Epoch: 26  Training loss = 3.5935  Validation loss = 3.9917  \n",
      "\n",
      "Fold: 12  Epoch: 27  Training loss = 3.5930  Validation loss = 3.9907  \n",
      "\n",
      "Fold: 12  Epoch: 28  Training loss = 3.5928  Validation loss = 3.9901  \n",
      "\n",
      "Fold: 12  Epoch: 29  Training loss = 3.5925  Validation loss = 3.9896  \n",
      "\n",
      "Fold: 12  Epoch: 30  Training loss = 3.5922  Validation loss = 3.9890  \n",
      "\n",
      "Fold: 12  Epoch: 31  Training loss = 3.5919  Validation loss = 3.9884  \n",
      "\n",
      "Fold: 12  Epoch: 32  Training loss = 3.5916  Validation loss = 3.9878  \n",
      "\n",
      "Fold: 12  Epoch: 33  Training loss = 3.5912  Validation loss = 3.9870  \n",
      "\n",
      "Fold: 12  Epoch: 34  Training loss = 3.5908  Validation loss = 3.9863  \n",
      "\n",
      "Fold: 12  Epoch: 35  Training loss = 3.5905  Validation loss = 3.9857  \n",
      "\n",
      "Fold: 12  Epoch: 36  Training loss = 3.5902  Validation loss = 3.9850  \n",
      "\n",
      "Fold: 12  Epoch: 37  Training loss = 3.5898  Validation loss = 3.9844  \n",
      "\n",
      "Fold: 12  Epoch: 38  Training loss = 3.5895  Validation loss = 3.9838  \n",
      "\n",
      "Fold: 12  Epoch: 39  Training loss = 3.5893  Validation loss = 3.9833  \n",
      "\n",
      "Fold: 12  Epoch: 40  Training loss = 3.5889  Validation loss = 3.9827  \n",
      "\n",
      "Fold: 12  Epoch: 41  Training loss = 3.5885  Validation loss = 3.9819  \n",
      "\n",
      "Fold: 12  Epoch: 42  Training loss = 3.5881  Validation loss = 3.9811  \n",
      "\n",
      "Fold: 12  Epoch: 43  Training loss = 3.5878  Validation loss = 3.9804  \n",
      "\n",
      "Fold: 12  Epoch: 44  Training loss = 3.5875  Validation loss = 3.9798  \n",
      "\n",
      "Fold: 12  Epoch: 45  Training loss = 3.5871  Validation loss = 3.9790  \n",
      "\n",
      "Fold: 12  Epoch: 46  Training loss = 3.5867  Validation loss = 3.9783  \n",
      "\n",
      "Fold: 12  Epoch: 47  Training loss = 3.5863  Validation loss = 3.9775  \n",
      "\n",
      "Fold: 12  Epoch: 48  Training loss = 3.5858  Validation loss = 3.9765  \n",
      "\n",
      "Fold: 12  Epoch: 49  Training loss = 3.5854  Validation loss = 3.9758  \n",
      "\n",
      "Fold: 12  Epoch: 50  Training loss = 3.5851  Validation loss = 3.9751  \n",
      "\n",
      "Fold: 12  Epoch: 51  Training loss = 3.5849  Validation loss = 3.9747  \n",
      "\n",
      "Fold: 12  Epoch: 52  Training loss = 3.5845  Validation loss = 3.9740  \n",
      "\n",
      "Fold: 12  Epoch: 53  Training loss = 3.5842  Validation loss = 3.9734  \n",
      "\n",
      "Fold: 12  Epoch: 54  Training loss = 3.5838  Validation loss = 3.9727  \n",
      "\n",
      "Fold: 12  Epoch: 55  Training loss = 3.5835  Validation loss = 3.9721  \n",
      "\n",
      "Fold: 12  Epoch: 56  Training loss = 3.5831  Validation loss = 3.9712  \n",
      "\n",
      "Fold: 12  Epoch: 57  Training loss = 3.5827  Validation loss = 3.9704  \n",
      "\n",
      "Fold: 12  Epoch: 58  Training loss = 3.5824  Validation loss = 3.9698  \n",
      "\n",
      "Fold: 12  Epoch: 59  Training loss = 3.5820  Validation loss = 3.9690  \n",
      "\n",
      "Fold: 12  Epoch: 60  Training loss = 3.5817  Validation loss = 3.9685  \n",
      "\n",
      "Fold: 12  Epoch: 61  Training loss = 3.5814  Validation loss = 3.9679  \n",
      "\n",
      "Fold: 12  Epoch: 62  Training loss = 3.5812  Validation loss = 3.9674  \n",
      "\n",
      "Fold: 12  Epoch: 63  Training loss = 3.5807  Validation loss = 3.9665  \n",
      "\n",
      "Fold: 12  Epoch: 64  Training loss = 3.5803  Validation loss = 3.9658  \n",
      "\n",
      "Fold: 12  Epoch: 65  Training loss = 3.5800  Validation loss = 3.9651  \n",
      "\n",
      "Fold: 12  Epoch: 66  Training loss = 3.5797  Validation loss = 3.9645  \n",
      "\n",
      "Fold: 12  Epoch: 67  Training loss = 3.5792  Validation loss = 3.9636  \n",
      "\n",
      "Fold: 12  Epoch: 68  Training loss = 3.5790  Validation loss = 3.9631  \n",
      "\n",
      "Fold: 12  Epoch: 69  Training loss = 3.5785  Validation loss = 3.9622  \n",
      "\n",
      "Fold: 12  Epoch: 70  Training loss = 3.5782  Validation loss = 3.9615  \n",
      "\n",
      "Fold: 12  Epoch: 71  Training loss = 3.5777  Validation loss = 3.9607  \n",
      "\n",
      "Fold: 12  Epoch: 72  Training loss = 3.5774  Validation loss = 3.9599  \n",
      "\n",
      "Fold: 12  Epoch: 73  Training loss = 3.5770  Validation loss = 3.9592  \n",
      "\n",
      "Fold: 12  Epoch: 74  Training loss = 3.5766  Validation loss = 3.9584  \n",
      "\n",
      "Fold: 12  Epoch: 75  Training loss = 3.5762  Validation loss = 3.9577  \n",
      "\n",
      "Fold: 12  Epoch: 76  Training loss = 3.5760  Validation loss = 3.9572  \n",
      "\n",
      "Fold: 12  Epoch: 77  Training loss = 3.5755  Validation loss = 3.9563  \n",
      "\n",
      "Fold: 12  Epoch: 78  Training loss = 3.5751  Validation loss = 3.9555  \n",
      "\n",
      "Fold: 12  Epoch: 79  Training loss = 3.5748  Validation loss = 3.9548  \n",
      "\n",
      "Fold: 12  Epoch: 80  Training loss = 3.5745  Validation loss = 3.9541  \n",
      "\n",
      "Fold: 12  Epoch: 81  Training loss = 3.5741  Validation loss = 3.9535  \n",
      "\n",
      "Fold: 12  Epoch: 82  Training loss = 3.5737  Validation loss = 3.9526  \n",
      "\n",
      "Fold: 12  Epoch: 83  Training loss = 3.5733  Validation loss = 3.9517  \n",
      "\n",
      "Fold: 12  Epoch: 84  Training loss = 3.5729  Validation loss = 3.9511  \n",
      "\n",
      "Fold: 12  Epoch: 85  Training loss = 3.5727  Validation loss = 3.9506  \n",
      "\n",
      "Fold: 12  Epoch: 86  Training loss = 3.5724  Validation loss = 3.9500  \n",
      "\n",
      "Fold: 12  Epoch: 87  Training loss = 3.5720  Validation loss = 3.9493  \n",
      "\n",
      "Fold: 12  Epoch: 88  Training loss = 3.5716  Validation loss = 3.9485  \n",
      "\n",
      "Fold: 12  Epoch: 89  Training loss = 3.5713  Validation loss = 3.9478  \n",
      "\n",
      "Fold: 12  Epoch: 90  Training loss = 3.5710  Validation loss = 3.9471  \n",
      "\n",
      "Fold: 12  Epoch: 91  Training loss = 3.5705  Validation loss = 3.9463  \n",
      "\n",
      "Fold: 12  Epoch: 92  Training loss = 3.5703  Validation loss = 3.9457  \n",
      "\n",
      "Fold: 12  Epoch: 93  Training loss = 3.5699  Validation loss = 3.9449  \n",
      "\n",
      "Fold: 12  Epoch: 94  Training loss = 3.5694  Validation loss = 3.9441  \n",
      "\n",
      "Fold: 12  Epoch: 95  Training loss = 3.5690  Validation loss = 3.9433  \n",
      "\n",
      "Fold: 12  Epoch: 96  Training loss = 3.5687  Validation loss = 3.9426  \n",
      "\n",
      "Fold: 12  Epoch: 97  Training loss = 3.5683  Validation loss = 3.9419  \n",
      "\n",
      "Fold: 12  Epoch: 98  Training loss = 3.5679  Validation loss = 3.9410  \n",
      "\n",
      "Fold: 12  Epoch: 99  Training loss = 3.5675  Validation loss = 3.9403  \n",
      "\n",
      "Fold: 12  Epoch: 100  Training loss = 3.5672  Validation loss = 3.9396  \n",
      "\n",
      "Fold: 12  Epoch: 101  Training loss = 3.5668  Validation loss = 3.9389  \n",
      "\n",
      "Fold: 12  Epoch: 102  Training loss = 3.5664  Validation loss = 3.9380  \n",
      "\n",
      "Fold: 12  Epoch: 103  Training loss = 3.5660  Validation loss = 3.9372  \n",
      "\n",
      "Fold: 12  Epoch: 104  Training loss = 3.5656  Validation loss = 3.9364  \n",
      "\n",
      "Fold: 12  Epoch: 105  Training loss = 3.5652  Validation loss = 3.9357  \n",
      "\n",
      "Fold: 12  Epoch: 106  Training loss = 3.5648  Validation loss = 3.9349  \n",
      "\n",
      "Fold: 12  Epoch: 107  Training loss = 3.5645  Validation loss = 3.9342  \n",
      "\n",
      "Fold: 12  Epoch: 108  Training loss = 3.5642  Validation loss = 3.9336  \n",
      "\n",
      "Fold: 12  Epoch: 109  Training loss = 3.5637  Validation loss = 3.9327  \n",
      "\n",
      "Fold: 12  Epoch: 110  Training loss = 3.5633  Validation loss = 3.9319  \n",
      "\n",
      "Fold: 12  Epoch: 111  Training loss = 3.5630  Validation loss = 3.9313  \n",
      "\n",
      "Fold: 12  Epoch: 112  Training loss = 3.5626  Validation loss = 3.9306  \n",
      "\n",
      "Fold: 12  Epoch: 113  Training loss = 3.5622  Validation loss = 3.9298  \n",
      "\n",
      "Fold: 12  Epoch: 114  Training loss = 3.5618  Validation loss = 3.9290  \n",
      "\n",
      "Fold: 12  Epoch: 115  Training loss = 3.5615  Validation loss = 3.9283  \n",
      "\n",
      "Fold: 12  Epoch: 116  Training loss = 3.5612  Validation loss = 3.9277  \n",
      "\n",
      "Fold: 12  Epoch: 117  Training loss = 3.5608  Validation loss = 3.9270  \n",
      "\n",
      "Fold: 12  Epoch: 118  Training loss = 3.5604  Validation loss = 3.9262  \n",
      "\n",
      "Fold: 12  Epoch: 119  Training loss = 3.5601  Validation loss = 3.9257  \n",
      "\n",
      "Fold: 12  Epoch: 120  Training loss = 3.5599  Validation loss = 3.9252  \n",
      "\n",
      "Fold: 12  Epoch: 121  Training loss = 3.5595  Validation loss = 3.9245  \n",
      "\n",
      "Fold: 12  Epoch: 122  Training loss = 3.5591  Validation loss = 3.9237  \n",
      "\n",
      "Fold: 12  Epoch: 123  Training loss = 3.5587  Validation loss = 3.9228  \n",
      "\n",
      "Fold: 12  Epoch: 124  Training loss = 3.5583  Validation loss = 3.9219  \n",
      "\n",
      "Fold: 12  Epoch: 125  Training loss = 3.5579  Validation loss = 3.9213  \n",
      "\n",
      "Fold: 12  Epoch: 126  Training loss = 3.5574  Validation loss = 3.9203  \n",
      "\n",
      "Fold: 12  Epoch: 127  Training loss = 3.5570  Validation loss = 3.9194  \n",
      "\n",
      "Fold: 12  Epoch: 128  Training loss = 3.5566  Validation loss = 3.9187  \n",
      "\n",
      "Fold: 12  Epoch: 129  Training loss = 3.5562  Validation loss = 3.9179  \n",
      "\n",
      "Fold: 12  Epoch: 130  Training loss = 3.5559  Validation loss = 3.9172  \n",
      "\n",
      "Fold: 12  Epoch: 131  Training loss = 3.5556  Validation loss = 3.9166  \n",
      "\n",
      "Fold: 12  Epoch: 132  Training loss = 3.5551  Validation loss = 3.9157  \n",
      "\n",
      "Fold: 12  Epoch: 133  Training loss = 3.5548  Validation loss = 3.9150  \n",
      "\n",
      "Fold: 12  Epoch: 134  Training loss = 3.5544  Validation loss = 3.9143  \n",
      "\n",
      "Fold: 12  Epoch: 135  Training loss = 3.5541  Validation loss = 3.9137  \n",
      "\n",
      "Fold: 12  Epoch: 136  Training loss = 3.5537  Validation loss = 3.9129  \n",
      "\n",
      "Fold: 12  Epoch: 137  Training loss = 3.5533  Validation loss = 3.9121  \n",
      "\n",
      "Fold: 12  Epoch: 138  Training loss = 3.5529  Validation loss = 3.9112  \n",
      "\n",
      "Fold: 12  Epoch: 139  Training loss = 3.5525  Validation loss = 3.9104  \n",
      "\n",
      "Fold: 12  Epoch: 140  Training loss = 3.5522  Validation loss = 3.9098  \n",
      "\n",
      "Fold: 12  Epoch: 141  Training loss = 3.5518  Validation loss = 3.9090  \n",
      "\n",
      "Fold: 12  Epoch: 142  Training loss = 3.5514  Validation loss = 3.9083  \n",
      "\n",
      "Fold: 12  Epoch: 143  Training loss = 3.5510  Validation loss = 3.9075  \n",
      "\n",
      "Fold: 12  Epoch: 144  Training loss = 3.5507  Validation loss = 3.9068  \n",
      "\n",
      "Fold: 12  Epoch: 145  Training loss = 3.5503  Validation loss = 3.9061  \n",
      "\n",
      "Fold: 12  Epoch: 146  Training loss = 3.5500  Validation loss = 3.9055  \n",
      "\n",
      "Fold: 12  Epoch: 147  Training loss = 3.5496  Validation loss = 3.9047  \n",
      "\n",
      "Fold: 12  Epoch: 148  Training loss = 3.5493  Validation loss = 3.9041  \n",
      "\n",
      "Fold: 12  Epoch: 149  Training loss = 3.5490  Validation loss = 3.9035  \n",
      "\n",
      "Fold: 12  Epoch: 150  Training loss = 3.5486  Validation loss = 3.9027  \n",
      "\n",
      "Fold: 12  Epoch: 151  Training loss = 3.5482  Validation loss = 3.9019  \n",
      "\n",
      "Fold: 12  Epoch: 152  Training loss = 3.5478  Validation loss = 3.9011  \n",
      "\n",
      "Fold: 12  Epoch: 153  Training loss = 3.5475  Validation loss = 3.9005  \n",
      "\n",
      "Fold: 12  Epoch: 154  Training loss = 3.5471  Validation loss = 3.8997  \n",
      "\n",
      "Fold: 12  Epoch: 155  Training loss = 3.5468  Validation loss = 3.8990  \n",
      "\n",
      "Fold: 12  Epoch: 156  Training loss = 3.5464  Validation loss = 3.8982  \n",
      "\n",
      "Fold: 12  Epoch: 157  Training loss = 3.5459  Validation loss = 3.8972  \n",
      "\n",
      "Fold: 12  Epoch: 158  Training loss = 3.5455  Validation loss = 3.8965  \n",
      "\n",
      "Fold: 12  Epoch: 159  Training loss = 3.5452  Validation loss = 3.8958  \n",
      "\n",
      "Fold: 12  Epoch: 160  Training loss = 3.5449  Validation loss = 3.8953  \n",
      "\n",
      "Fold: 12  Epoch: 161  Training loss = 3.5447  Validation loss = 3.8948  \n",
      "\n",
      "Fold: 12  Epoch: 162  Training loss = 3.5444  Validation loss = 3.8941  \n",
      "\n",
      "Fold: 12  Epoch: 163  Training loss = 3.5441  Validation loss = 3.8936  \n",
      "\n",
      "Fold: 12  Epoch: 164  Training loss = 3.5439  Validation loss = 3.8932  \n",
      "\n",
      "Fold: 12  Epoch: 165  Training loss = 3.5435  Validation loss = 3.8924  \n",
      "\n",
      "Fold: 12  Epoch: 166  Training loss = 3.5432  Validation loss = 3.8917  \n",
      "\n",
      "Fold: 12  Epoch: 167  Training loss = 3.5428  Validation loss = 3.8909  \n",
      "\n",
      "Fold: 12  Epoch: 168  Training loss = 3.5424  Validation loss = 3.8902  \n",
      "\n",
      "Fold: 12  Epoch: 169  Training loss = 3.5421  Validation loss = 3.8896  \n",
      "\n",
      "Fold: 12  Epoch: 170  Training loss = 3.5417  Validation loss = 3.8888  \n",
      "\n",
      "Fold: 12  Epoch: 171  Training loss = 3.5414  Validation loss = 3.8883  \n",
      "\n",
      "Fold: 12  Epoch: 172  Training loss = 3.5411  Validation loss = 3.8876  \n",
      "\n",
      "Fold: 12  Epoch: 173  Training loss = 3.5407  Validation loss = 3.8869  \n",
      "\n",
      "Fold: 12  Epoch: 174  Training loss = 3.5404  Validation loss = 3.8862  \n",
      "\n",
      "Fold: 12  Epoch: 175  Training loss = 3.5402  Validation loss = 3.8858  \n",
      "\n",
      "Fold: 12  Epoch: 176  Training loss = 3.5399  Validation loss = 3.8851  \n",
      "\n",
      "Fold: 12  Epoch: 177  Training loss = 3.5396  Validation loss = 3.8845  \n",
      "\n",
      "Fold: 12  Epoch: 178  Training loss = 3.5392  Validation loss = 3.8839  \n",
      "\n",
      "Fold: 12  Epoch: 179  Training loss = 3.5389  Validation loss = 3.8832  \n",
      "\n",
      "Fold: 12  Epoch: 180  Training loss = 3.5386  Validation loss = 3.8825  \n",
      "\n",
      "Fold: 12  Epoch: 181  Training loss = 3.5382  Validation loss = 3.8817  \n",
      "\n",
      "Fold: 12  Epoch: 182  Training loss = 3.5379  Validation loss = 3.8810  \n",
      "\n",
      "Fold: 12  Epoch: 183  Training loss = 3.5375  Validation loss = 3.8804  \n",
      "\n",
      "Fold: 12  Epoch: 184  Training loss = 3.5372  Validation loss = 3.8798  \n",
      "\n",
      "Fold: 12  Epoch: 185  Training loss = 3.5370  Validation loss = 3.8793  \n",
      "\n",
      "Fold: 12  Epoch: 186  Training loss = 3.5366  Validation loss = 3.8786  \n",
      "\n",
      "Fold: 12  Epoch: 187  Training loss = 3.5362  Validation loss = 3.8778  \n",
      "\n",
      "Fold: 12  Epoch: 188  Training loss = 3.5359  Validation loss = 3.8771  \n",
      "\n",
      "Fold: 12  Epoch: 189  Training loss = 3.5356  Validation loss = 3.8765  \n",
      "\n",
      "Fold: 12  Epoch: 190  Training loss = 3.5352  Validation loss = 3.8758  \n",
      "\n",
      "Fold: 12  Epoch: 191  Training loss = 3.5349  Validation loss = 3.8752  \n",
      "\n",
      "Fold: 12  Epoch: 192  Training loss = 3.5345  Validation loss = 3.8744  \n",
      "\n",
      "Fold: 12  Epoch: 193  Training loss = 3.5342  Validation loss = 3.8737  \n",
      "\n",
      "Fold: 12  Epoch: 194  Training loss = 3.5339  Validation loss = 3.8731  \n",
      "\n",
      "Fold: 12  Epoch: 195  Training loss = 3.5336  Validation loss = 3.8725  \n",
      "\n",
      "Fold: 12  Epoch: 196  Training loss = 3.5332  Validation loss = 3.8718  \n",
      "\n",
      "Fold: 12  Epoch: 197  Training loss = 3.5328  Validation loss = 3.8710  \n",
      "\n",
      "Fold: 12  Epoch: 198  Training loss = 3.5325  Validation loss = 3.8703  \n",
      "\n",
      "Fold: 12  Epoch: 199  Training loss = 3.5322  Validation loss = 3.8696  \n",
      "\n",
      "Fold: 12  Epoch: 200  Training loss = 3.5318  Validation loss = 3.8689  \n",
      "\n",
      "Fold: 12  Epoch: 201  Training loss = 3.5314  Validation loss = 3.8681  \n",
      "\n",
      "Fold: 12  Epoch: 202  Training loss = 3.5310  Validation loss = 3.8674  \n",
      "\n",
      "Fold: 12  Epoch: 203  Training loss = 3.5308  Validation loss = 3.8668  \n",
      "\n",
      "Fold: 12  Epoch: 204  Training loss = 3.5304  Validation loss = 3.8662  \n",
      "\n",
      "Fold: 12  Epoch: 205  Training loss = 3.5300  Validation loss = 3.8653  \n",
      "\n",
      "Fold: 12  Epoch: 206  Training loss = 3.5296  Validation loss = 3.8646  \n",
      "\n",
      "Fold: 12  Epoch: 207  Training loss = 3.5292  Validation loss = 3.8637  \n",
      "\n",
      "Fold: 12  Epoch: 208  Training loss = 3.5288  Validation loss = 3.8630  \n",
      "\n",
      "Fold: 12  Epoch: 209  Training loss = 3.5284  Validation loss = 3.8622  \n",
      "\n",
      "Fold: 12  Epoch: 210  Training loss = 3.5282  Validation loss = 3.8617  \n",
      "\n",
      "Fold: 12  Epoch: 211  Training loss = 3.5278  Validation loss = 3.8609  \n",
      "\n",
      "Fold: 12  Epoch: 212  Training loss = 3.5274  Validation loss = 3.8603  \n",
      "\n",
      "Fold: 12  Epoch: 213  Training loss = 3.5271  Validation loss = 3.8597  \n",
      "\n",
      "Fold: 12  Epoch: 214  Training loss = 3.5267  Validation loss = 3.8590  \n",
      "\n",
      "Fold: 12  Epoch: 215  Training loss = 3.5263  Validation loss = 3.8582  \n",
      "\n",
      "Fold: 12  Epoch: 216  Training loss = 3.5260  Validation loss = 3.8576  \n",
      "\n",
      "Fold: 12  Epoch: 217  Training loss = 3.5249  Validation loss = 3.8568  \n",
      "\n",
      "Fold: 12  Epoch: 218  Training loss = 3.5232  Validation loss = 3.8563  \n",
      "\n",
      "Fold: 12  Epoch: 219  Training loss = 3.5203  Validation loss = 3.8556  \n",
      "\n",
      "Fold: 12  Epoch: 220  Training loss = 3.5126  Validation loss = 3.8551  \n",
      "\n",
      "Fold: 12  Epoch: 221  Training loss = 3.5120  Validation loss = 3.8545  \n",
      "\n",
      "Fold: 12  Epoch: 222  Training loss = 3.5117  Validation loss = 3.8540  \n",
      "\n",
      "Fold: 12  Epoch: 223  Training loss = 3.5113  Validation loss = 3.8532  \n",
      "\n",
      "Fold: 12  Epoch: 224  Training loss = 3.5109  Validation loss = 3.8525  \n",
      "\n",
      "Fold: 12  Epoch: 225  Training loss = 3.5106  Validation loss = 3.8519  \n",
      "\n",
      "Fold: 12  Epoch: 226  Training loss = 3.5102  Validation loss = 3.8513  \n",
      "\n",
      "Fold: 12  Epoch: 227  Training loss = 3.5099  Validation loss = 3.8506  \n",
      "\n",
      "Fold: 12  Epoch: 228  Training loss = 3.5095  Validation loss = 3.8498  \n",
      "\n",
      "Fold: 12  Epoch: 229  Training loss = 3.5092  Validation loss = 3.8492  \n",
      "\n",
      "Fold: 12  Epoch: 230  Training loss = 3.5089  Validation loss = 3.8485  \n",
      "\n",
      "Fold: 12  Epoch: 231  Training loss = 3.5086  Validation loss = 3.8479  \n",
      "\n",
      "Fold: 12  Epoch: 232  Training loss = 3.5082  Validation loss = 3.8472  \n",
      "\n",
      "Fold: 12  Epoch: 233  Training loss = 3.5079  Validation loss = 3.8467  \n",
      "\n",
      "Fold: 12  Epoch: 234  Training loss = 3.5075  Validation loss = 3.8457  \n",
      "\n",
      "Fold: 12  Epoch: 235  Training loss = 3.5071  Validation loss = 3.8451  \n",
      "\n",
      "Fold: 12  Epoch: 236  Training loss = 3.5068  Validation loss = 3.8444  \n",
      "\n",
      "Fold: 12  Epoch: 237  Training loss = 3.5065  Validation loss = 3.8437  \n",
      "\n",
      "Fold: 12  Epoch: 238  Training loss = 3.5062  Validation loss = 3.8432  \n",
      "\n",
      "Fold: 12  Epoch: 239  Training loss = 3.5059  Validation loss = 3.8426  \n",
      "\n",
      "Fold: 12  Epoch: 240  Training loss = 3.5057  Validation loss = 3.8422  \n",
      "\n",
      "Fold: 12  Epoch: 241  Training loss = 3.5053  Validation loss = 3.8414  \n",
      "\n",
      "Fold: 12  Epoch: 242  Training loss = 3.5050  Validation loss = 3.8407  \n",
      "\n",
      "Fold: 12  Epoch: 243  Training loss = 3.5046  Validation loss = 3.8400  \n",
      "\n",
      "Fold: 12  Epoch: 244  Training loss = 3.5043  Validation loss = 3.8394  \n",
      "\n",
      "Fold: 12  Epoch: 245  Training loss = 3.5040  Validation loss = 3.8388  \n",
      "\n",
      "Fold: 12  Epoch: 246  Training loss = 3.5037  Validation loss = 3.8380  \n",
      "\n",
      "Fold: 12  Epoch: 247  Training loss = 3.5033  Validation loss = 3.8373  \n",
      "\n",
      "Fold: 12  Epoch: 248  Training loss = 3.5029  Validation loss = 3.8364  \n",
      "\n",
      "Fold: 12  Epoch: 249  Training loss = 3.5024  Validation loss = 3.8355  \n",
      "\n",
      "Fold: 12  Epoch: 250  Training loss = 3.5020  Validation loss = 3.8347  \n",
      "\n",
      "Fold: 12  Epoch: 251  Training loss = 3.5018  Validation loss = 3.8342  \n",
      "\n",
      "Fold: 12  Epoch: 252  Training loss = 3.5014  Validation loss = 3.8335  \n",
      "\n",
      "Fold: 12  Epoch: 253  Training loss = 3.5010  Validation loss = 3.8327  \n",
      "\n",
      "Fold: 12  Epoch: 254  Training loss = 3.5006  Validation loss = 3.8319  \n",
      "\n",
      "Fold: 12  Epoch: 255  Training loss = 3.5003  Validation loss = 3.8313  \n",
      "\n",
      "Fold: 12  Epoch: 256  Training loss = 3.5000  Validation loss = 3.8306  \n",
      "\n",
      "Fold: 12  Epoch: 257  Training loss = 3.4997  Validation loss = 3.8300  \n",
      "\n",
      "Fold: 12  Epoch: 258  Training loss = 3.4992  Validation loss = 3.8290  \n",
      "\n",
      "Fold: 12  Epoch: 259  Training loss = 3.4989  Validation loss = 3.8284  \n",
      "\n",
      "Fold: 12  Epoch: 260  Training loss = 3.4986  Validation loss = 3.8278  \n",
      "\n",
      "Fold: 12  Epoch: 261  Training loss = 3.4983  Validation loss = 3.8272  \n",
      "\n",
      "Fold: 12  Epoch: 262  Training loss = 3.4979  Validation loss = 3.8263  \n",
      "\n",
      "Fold: 12  Epoch: 263  Training loss = 3.4976  Validation loss = 3.8257  \n",
      "\n",
      "Fold: 12  Epoch: 264  Training loss = 3.4973  Validation loss = 3.8251  \n",
      "\n",
      "Fold: 12  Epoch: 265  Training loss = 3.4971  Validation loss = 3.8246  \n",
      "\n",
      "Fold: 12  Epoch: 266  Training loss = 3.4967  Validation loss = 3.8239  \n",
      "\n",
      "Fold: 12  Epoch: 267  Training loss = 3.4963  Validation loss = 3.8230  \n",
      "\n",
      "Fold: 12  Epoch: 268  Training loss = 3.4960  Validation loss = 3.8224  \n",
      "\n",
      "Fold: 12  Epoch: 269  Training loss = 3.4957  Validation loss = 3.8217  \n",
      "\n",
      "Fold: 12  Epoch: 270  Training loss = 3.4953  Validation loss = 3.8210  \n",
      "\n",
      "Fold: 12  Epoch: 271  Training loss = 3.4949  Validation loss = 3.8202  \n",
      "\n",
      "Fold: 12  Epoch: 272  Training loss = 3.4946  Validation loss = 3.8195  \n",
      "\n",
      "Fold: 12  Epoch: 273  Training loss = 3.4943  Validation loss = 3.8189  \n",
      "\n",
      "Fold: 12  Epoch: 274  Training loss = 3.4939  Validation loss = 3.8182  \n",
      "\n",
      "Fold: 12  Epoch: 275  Training loss = 3.4935  Validation loss = 3.8173  \n",
      "\n",
      "Fold: 12  Epoch: 276  Training loss = 3.4932  Validation loss = 3.8166  \n",
      "\n",
      "Fold: 12  Epoch: 277  Training loss = 3.4929  Validation loss = 3.8160  \n",
      "\n",
      "Fold: 12  Epoch: 278  Training loss = 3.4926  Validation loss = 3.8155  \n",
      "\n",
      "Fold: 12  Epoch: 279  Training loss = 3.4923  Validation loss = 3.8149  \n",
      "\n",
      "Fold: 12  Epoch: 280  Training loss = 3.4920  Validation loss = 3.8142  \n",
      "\n",
      "Fold: 12  Epoch: 281  Training loss = 3.4917  Validation loss = 3.8137  \n",
      "\n",
      "Fold: 12  Epoch: 282  Training loss = 3.4915  Validation loss = 3.8132  \n",
      "\n",
      "Fold: 12  Epoch: 283  Training loss = 3.4912  Validation loss = 3.8126  \n",
      "\n",
      "Fold: 12  Epoch: 284  Training loss = 3.4909  Validation loss = 3.8120  \n",
      "\n",
      "Fold: 12  Epoch: 285  Training loss = 3.4905  Validation loss = 3.8113  \n",
      "\n",
      "Fold: 12  Epoch: 286  Training loss = 3.4903  Validation loss = 3.8107  \n",
      "\n",
      "Fold: 12  Epoch: 287  Training loss = 3.4899  Validation loss = 3.8100  \n",
      "\n",
      "Fold: 12  Epoch: 288  Training loss = 3.4896  Validation loss = 3.8093  \n",
      "\n",
      "Fold: 12  Epoch: 289  Training loss = 3.4893  Validation loss = 3.8089  \n",
      "\n",
      "Fold: 12  Epoch: 290  Training loss = 3.4890  Validation loss = 3.8083  \n",
      "\n",
      "Fold: 12  Epoch: 291  Training loss = 3.4888  Validation loss = 3.8077  \n",
      "\n",
      "Fold: 12  Epoch: 292  Training loss = 3.4885  Validation loss = 3.8071  \n",
      "\n",
      "Fold: 12  Epoch: 293  Training loss = 3.4882  Validation loss = 3.8065  \n",
      "\n",
      "Fold: 12  Epoch: 294  Training loss = 3.4877  Validation loss = 3.8056  \n",
      "\n",
      "Fold: 12  Epoch: 295  Training loss = 3.4873  Validation loss = 3.8048  \n",
      "\n",
      "Fold: 12  Epoch: 296  Training loss = 3.4870  Validation loss = 3.8042  \n",
      "\n",
      "Fold: 12  Epoch: 297  Training loss = 3.4867  Validation loss = 3.8035  \n",
      "\n",
      "Fold: 12  Epoch: 298  Training loss = 3.4864  Validation loss = 3.8029  \n",
      "\n",
      "Fold: 12  Epoch: 299  Training loss = 3.4862  Validation loss = 3.8024  \n",
      "\n",
      "Fold: 12  Epoch: 300  Training loss = 3.4858  Validation loss = 3.8017  \n",
      "\n",
      "Fold: 12  Epoch: 301  Training loss = 3.4855  Validation loss = 3.8011  \n",
      "\n",
      "Fold: 12  Epoch: 302  Training loss = 3.4853  Validation loss = 3.8006  \n",
      "\n",
      "Fold: 12  Epoch: 303  Training loss = 3.4851  Validation loss = 3.8002  \n",
      "\n",
      "Fold: 12  Epoch: 304  Training loss = 3.4849  Validation loss = 3.7998  \n",
      "\n",
      "Fold: 12  Epoch: 305  Training loss = 3.4846  Validation loss = 3.7993  \n",
      "\n",
      "Fold: 12  Epoch: 306  Training loss = 3.4843  Validation loss = 3.7986  \n",
      "\n",
      "Fold: 12  Epoch: 307  Training loss = 3.4839  Validation loss = 3.7978  \n",
      "\n",
      "Fold: 12  Epoch: 308  Training loss = 3.4835  Validation loss = 3.7969  \n",
      "\n",
      "Fold: 12  Epoch: 309  Training loss = 3.4832  Validation loss = 3.7963  \n",
      "\n",
      "Fold: 12  Epoch: 310  Training loss = 3.4829  Validation loss = 3.7957  \n",
      "\n",
      "Fold: 12  Epoch: 311  Training loss = 3.4826  Validation loss = 3.7952  \n",
      "\n",
      "Fold: 12  Epoch: 312  Training loss = 3.4823  Validation loss = 3.7944  \n",
      "\n",
      "Fold: 12  Epoch: 313  Training loss = 3.4818  Validation loss = 3.7935  \n",
      "\n",
      "Fold: 12  Epoch: 314  Training loss = 3.4816  Validation loss = 3.7929  \n",
      "\n",
      "Fold: 12  Epoch: 315  Training loss = 3.4814  Validation loss = 3.7925  \n",
      "\n",
      "Fold: 12  Epoch: 316  Training loss = 3.4811  Validation loss = 3.7920  \n",
      "\n",
      "Fold: 12  Epoch: 317  Training loss = 3.4808  Validation loss = 3.7913  \n",
      "\n",
      "Fold: 12  Epoch: 318  Training loss = 3.4805  Validation loss = 3.7907  \n",
      "\n",
      "Fold: 12  Epoch: 319  Training loss = 3.4801  Validation loss = 3.7900  \n",
      "\n",
      "Fold: 12  Epoch: 320  Training loss = 3.4798  Validation loss = 3.7893  \n",
      "\n",
      "Fold: 12  Epoch: 321  Training loss = 3.4794  Validation loss = 3.7886  \n",
      "\n",
      "Fold: 12  Epoch: 322  Training loss = 3.4791  Validation loss = 3.7878  \n",
      "\n",
      "Fold: 12  Epoch: 323  Training loss = 3.4788  Validation loss = 3.7872  \n",
      "\n",
      "Fold: 12  Epoch: 324  Training loss = 3.4784  Validation loss = 3.7865  \n",
      "\n",
      "Fold: 12  Epoch: 325  Training loss = 3.4781  Validation loss = 3.7858  \n",
      "\n",
      "Fold: 12  Epoch: 326  Training loss = 3.4778  Validation loss = 3.7851  \n",
      "\n",
      "Fold: 12  Epoch: 327  Training loss = 3.4774  Validation loss = 3.7844  \n",
      "\n",
      "Fold: 12  Epoch: 328  Training loss = 3.4771  Validation loss = 3.7837  \n",
      "\n",
      "Fold: 12  Epoch: 329  Training loss = 3.4767  Validation loss = 3.7830  \n",
      "\n",
      "Fold: 12  Epoch: 330  Training loss = 3.4764  Validation loss = 3.7822  \n",
      "\n",
      "Fold: 12  Epoch: 331  Training loss = 3.4761  Validation loss = 3.7816  \n",
      "\n",
      "Fold: 12  Epoch: 332  Training loss = 3.4759  Validation loss = 3.7812  \n",
      "\n",
      "Fold: 12  Epoch: 333  Training loss = 3.4755  Validation loss = 3.7804  \n",
      "\n",
      "Fold: 12  Epoch: 334  Training loss = 3.4751  Validation loss = 3.7795  \n",
      "\n",
      "Fold: 12  Epoch: 335  Training loss = 3.4748  Validation loss = 3.7790  \n",
      "\n",
      "Fold: 12  Epoch: 336  Training loss = 3.4746  Validation loss = 3.7785  \n",
      "\n",
      "Fold: 12  Epoch: 337  Training loss = 3.4742  Validation loss = 3.7778  \n",
      "\n",
      "Fold: 12  Epoch: 338  Training loss = 3.4739  Validation loss = 3.7772  \n",
      "\n",
      "Fold: 12  Epoch: 339  Training loss = 3.4736  Validation loss = 3.7765  \n",
      "\n",
      "Fold: 12  Epoch: 340  Training loss = 3.4734  Validation loss = 3.7760  \n",
      "\n",
      "Fold: 12  Epoch: 341  Training loss = 3.4730  Validation loss = 3.7753  \n",
      "\n",
      "Fold: 12  Epoch: 342  Training loss = 3.4727  Validation loss = 3.7746  \n",
      "\n",
      "Fold: 12  Epoch: 343  Training loss = 3.4724  Validation loss = 3.7739  \n",
      "\n",
      "Fold: 12  Epoch: 344  Training loss = 3.4721  Validation loss = 3.7733  \n",
      "\n",
      "Fold: 12  Epoch: 345  Training loss = 3.4719  Validation loss = 3.7729  \n",
      "\n",
      "Fold: 12  Epoch: 346  Training loss = 3.4714  Validation loss = 3.7719  \n",
      "\n",
      "Fold: 12  Epoch: 347  Training loss = 3.4710  Validation loss = 3.7711  \n",
      "\n",
      "Fold: 12  Epoch: 348  Training loss = 3.4706  Validation loss = 3.7702  \n",
      "\n",
      "Fold: 12  Epoch: 349  Training loss = 3.4704  Validation loss = 3.7698  \n",
      "\n",
      "Fold: 12  Epoch: 350  Training loss = 3.4700  Validation loss = 3.7690  \n",
      "\n",
      "Fold: 12  Epoch: 351  Training loss = 3.4697  Validation loss = 3.7684  \n",
      "\n",
      "Fold: 12  Epoch: 352  Training loss = 3.4694  Validation loss = 3.7678  \n",
      "\n",
      "Fold: 12  Epoch: 353  Training loss = 3.4690  Validation loss = 3.7670  \n",
      "\n",
      "Fold: 12  Epoch: 354  Training loss = 3.4686  Validation loss = 3.7663  \n",
      "\n",
      "Fold: 12  Epoch: 355  Training loss = 3.4682  Validation loss = 3.7655  \n",
      "\n",
      "Fold: 12  Epoch: 356  Training loss = 3.4678  Validation loss = 3.7649  \n",
      "\n",
      "Fold: 12  Epoch: 357  Training loss = 3.4670  Validation loss = 3.7642  \n",
      "\n",
      "Fold: 12  Epoch: 358  Training loss = 3.4661  Validation loss = 3.7636  \n",
      "\n",
      "Fold: 12  Epoch: 359  Training loss = 3.4646  Validation loss = 3.7630  \n",
      "\n",
      "Fold: 12  Epoch: 360  Training loss = 3.4626  Validation loss = 3.7622  \n",
      "\n",
      "Fold: 12  Epoch: 361  Training loss = 3.4623  Validation loss = 3.7616  \n",
      "\n",
      "Fold: 12  Epoch: 362  Training loss = 3.4619  Validation loss = 3.7609  \n",
      "\n",
      "Fold: 12  Epoch: 363  Training loss = 3.4616  Validation loss = 3.7604  \n",
      "\n",
      "Fold: 12  Epoch: 364  Training loss = 3.4614  Validation loss = 3.7599  \n",
      "\n",
      "Fold: 12  Epoch: 365  Training loss = 3.4610  Validation loss = 3.7591  \n",
      "\n",
      "Fold: 12  Epoch: 366  Training loss = 3.4607  Validation loss = 3.7585  \n",
      "\n",
      "Fold: 12  Epoch: 367  Training loss = 3.4603  Validation loss = 3.7577  \n",
      "\n",
      "Fold: 12  Epoch: 368  Training loss = 3.4600  Validation loss = 3.7570  \n",
      "\n",
      "Fold: 12  Epoch: 369  Training loss = 3.4596  Validation loss = 3.7562  \n",
      "\n",
      "Fold: 12  Epoch: 370  Training loss = 3.4593  Validation loss = 3.7556  \n",
      "\n",
      "Fold: 12  Epoch: 371  Training loss = 3.4589  Validation loss = 3.7547  \n",
      "\n",
      "Fold: 12  Epoch: 372  Training loss = 3.4585  Validation loss = 3.7540  \n",
      "\n",
      "Fold: 12  Epoch: 373  Training loss = 3.4582  Validation loss = 3.7534  \n",
      "\n",
      "Fold: 12  Epoch: 374  Training loss = 3.4580  Validation loss = 3.7529  \n",
      "\n",
      "Fold: 12  Epoch: 375  Training loss = 3.4576  Validation loss = 3.7522  \n",
      "\n",
      "Fold: 12  Epoch: 376  Training loss = 3.4574  Validation loss = 3.7516  \n",
      "\n",
      "Fold: 12  Epoch: 377  Training loss = 3.4570  Validation loss = 3.7508  \n",
      "\n",
      "Fold: 12  Epoch: 378  Training loss = 3.4567  Validation loss = 3.7502  \n",
      "\n",
      "Fold: 12  Epoch: 379  Training loss = 3.4564  Validation loss = 3.7497  \n",
      "\n",
      "Fold: 12  Epoch: 380  Training loss = 3.4562  Validation loss = 3.7491  \n",
      "\n",
      "Fold: 12  Epoch: 381  Training loss = 3.4558  Validation loss = 3.7483  \n",
      "\n",
      "Fold: 12  Epoch: 382  Training loss = 3.4554  Validation loss = 3.7476  \n",
      "\n",
      "Fold: 12  Epoch: 383  Training loss = 3.4552  Validation loss = 3.7470  \n",
      "\n",
      "Fold: 12  Epoch: 384  Training loss = 3.4549  Validation loss = 3.7464  \n",
      "\n",
      "Fold: 12  Epoch: 385  Training loss = 3.4544  Validation loss = 3.7455  \n",
      "\n",
      "Fold: 12  Epoch: 386  Training loss = 3.4541  Validation loss = 3.7448  \n",
      "\n",
      "Fold: 12  Epoch: 387  Training loss = 3.4538  Validation loss = 3.7442  \n",
      "\n",
      "Fold: 12  Epoch: 388  Training loss = 3.4535  Validation loss = 3.7435  \n",
      "\n",
      "Fold: 12  Epoch: 389  Training loss = 3.4532  Validation loss = 3.7429  \n",
      "\n",
      "Fold: 12  Epoch: 390  Training loss = 3.4530  Validation loss = 3.7425  \n",
      "\n",
      "Fold: 12  Epoch: 391  Training loss = 3.4527  Validation loss = 3.7418  \n",
      "\n",
      "Fold: 12  Epoch: 392  Training loss = 3.4525  Validation loss = 3.7414  \n",
      "\n",
      "Fold: 12  Epoch: 393  Training loss = 3.4522  Validation loss = 3.7408  \n",
      "\n",
      "Fold: 12  Epoch: 394  Training loss = 3.4518  Validation loss = 3.7401  \n",
      "\n",
      "Fold: 12  Epoch: 395  Training loss = 3.4515  Validation loss = 3.7394  \n",
      "\n",
      "Fold: 12  Epoch: 396  Training loss = 3.4513  Validation loss = 3.7389  \n",
      "\n",
      "Fold: 12  Epoch: 397  Training loss = 3.4510  Validation loss = 3.7383  \n",
      "\n",
      "Fold: 12  Epoch: 398  Training loss = 3.4508  Validation loss = 3.7378  \n",
      "\n",
      "Fold: 12  Epoch: 399  Training loss = 3.4505  Validation loss = 3.7372  \n",
      "\n",
      "Fold: 12  Epoch: 400  Training loss = 3.4502  Validation loss = 3.7366  \n",
      "\n",
      "Fold: 12  Epoch: 401  Training loss = 3.4499  Validation loss = 3.7359  \n",
      "\n",
      "Fold: 12  Epoch: 402  Training loss = 3.4496  Validation loss = 3.7353  \n",
      "\n",
      "Fold: 12  Epoch: 403  Training loss = 3.4494  Validation loss = 3.7349  \n",
      "\n",
      "Fold: 12  Epoch: 404  Training loss = 3.4491  Validation loss = 3.7342  \n",
      "\n",
      "Fold: 12  Epoch: 405  Training loss = 3.4487  Validation loss = 3.7335  \n",
      "\n",
      "Fold: 12  Epoch: 406  Training loss = 3.4485  Validation loss = 3.7330  \n",
      "\n",
      "Fold: 12  Epoch: 407  Training loss = 3.4483  Validation loss = 3.7326  \n",
      "\n",
      "Fold: 12  Epoch: 408  Training loss = 3.4479  Validation loss = 3.7318  \n",
      "\n",
      "Fold: 12  Epoch: 409  Training loss = 3.4476  Validation loss = 3.7311  \n",
      "\n",
      "Fold: 12  Epoch: 410  Training loss = 3.4473  Validation loss = 3.7305  \n",
      "\n",
      "Fold: 12  Epoch: 411  Training loss = 3.4470  Validation loss = 3.7300  \n",
      "\n",
      "Fold: 12  Epoch: 412  Training loss = 3.4466  Validation loss = 3.7291  \n",
      "\n",
      "Fold: 12  Epoch: 413  Training loss = 3.4463  Validation loss = 3.7284  \n",
      "\n",
      "Fold: 12  Epoch: 414  Training loss = 3.4459  Validation loss = 3.7276  \n",
      "\n",
      "Fold: 12  Epoch: 415  Training loss = 3.4456  Validation loss = 3.7270  \n",
      "\n",
      "Fold: 12  Epoch: 416  Training loss = 3.4453  Validation loss = 3.7263  \n",
      "\n",
      "Fold: 12  Epoch: 417  Training loss = 3.4451  Validation loss = 3.7258  \n",
      "\n",
      "Fold: 12  Epoch: 418  Training loss = 3.4447  Validation loss = 3.7250  \n",
      "\n",
      "Fold: 12  Epoch: 419  Training loss = 3.4443  Validation loss = 3.7243  \n",
      "\n",
      "Fold: 12  Epoch: 420  Training loss = 3.4441  Validation loss = 3.7238  \n",
      "\n",
      "Fold: 12  Epoch: 421  Training loss = 3.4438  Validation loss = 3.7231  \n",
      "\n",
      "Fold: 12  Epoch: 422  Training loss = 3.4434  Validation loss = 3.7224  \n",
      "\n",
      "Fold: 12  Epoch: 423  Training loss = 3.4432  Validation loss = 3.7218  \n",
      "\n",
      "Fold: 12  Epoch: 424  Training loss = 3.4429  Validation loss = 3.7212  \n",
      "\n",
      "Fold: 12  Epoch: 425  Training loss = 3.4426  Validation loss = 3.7205  \n",
      "\n",
      "Fold: 12  Epoch: 426  Training loss = 3.4421  Validation loss = 3.7196  \n",
      "\n",
      "Fold: 12  Epoch: 427  Training loss = 3.4418  Validation loss = 3.7188  \n",
      "\n",
      "Fold: 12  Epoch: 428  Training loss = 3.4415  Validation loss = 3.7183  \n",
      "\n",
      "Fold: 12  Epoch: 429  Training loss = 3.4412  Validation loss = 3.7177  \n",
      "\n",
      "Fold: 12  Epoch: 430  Training loss = 3.4409  Validation loss = 3.7170  \n",
      "\n",
      "Fold: 12  Epoch: 431  Training loss = 3.4406  Validation loss = 3.7165  \n",
      "\n",
      "Fold: 12  Epoch: 432  Training loss = 3.4403  Validation loss = 3.7157  \n",
      "\n",
      "Fold: 12  Epoch: 433  Training loss = 3.4400  Validation loss = 3.7152  \n",
      "\n",
      "Fold: 12  Epoch: 434  Training loss = 3.4398  Validation loss = 3.7147  \n",
      "\n",
      "Fold: 12  Epoch: 435  Training loss = 3.4396  Validation loss = 3.7142  \n",
      "\n",
      "Fold: 12  Epoch: 436  Training loss = 3.4392  Validation loss = 3.7135  \n",
      "\n",
      "Fold: 12  Epoch: 437  Training loss = 3.4389  Validation loss = 3.7128  \n",
      "\n",
      "Fold: 12  Epoch: 438  Training loss = 3.4387  Validation loss = 3.7123  \n",
      "\n",
      "Fold: 12  Epoch: 439  Training loss = 3.4384  Validation loss = 3.7118  \n",
      "\n",
      "Fold: 12  Epoch: 440  Training loss = 3.4382  Validation loss = 3.7112  \n",
      "\n",
      "Fold: 12  Epoch: 441  Training loss = 3.4378  Validation loss = 3.7106  \n",
      "\n",
      "Fold: 12  Epoch: 442  Training loss = 3.4375  Validation loss = 3.7098  \n",
      "\n",
      "Fold: 12  Epoch: 443  Training loss = 3.4372  Validation loss = 3.7092  \n",
      "\n",
      "Fold: 12  Epoch: 444  Training loss = 3.4368  Validation loss = 3.7084  \n",
      "\n",
      "Fold: 12  Epoch: 445  Training loss = 3.4365  Validation loss = 3.7077  \n",
      "\n",
      "Fold: 12  Epoch: 446  Training loss = 3.4361  Validation loss = 3.7068  \n",
      "\n",
      "Fold: 12  Epoch: 447  Training loss = 3.4357  Validation loss = 3.7061  \n",
      "\n",
      "Fold: 12  Epoch: 448  Training loss = 3.4354  Validation loss = 3.7053  \n",
      "\n",
      "Fold: 12  Epoch: 449  Training loss = 3.4350  Validation loss = 3.7046  \n",
      "\n",
      "Fold: 12  Epoch: 450  Training loss = 3.4349  Validation loss = 3.7042  \n",
      "\n",
      "Fold: 12  Epoch: 451  Training loss = 3.4346  Validation loss = 3.7037  \n",
      "\n",
      "Fold: 12  Epoch: 452  Training loss = 3.4342  Validation loss = 3.7027  \n",
      "\n",
      "Fold: 12  Epoch: 453  Training loss = 3.4339  Validation loss = 3.7023  \n",
      "\n",
      "Fold: 12  Epoch: 454  Training loss = 3.4336  Validation loss = 3.7014  \n",
      "\n",
      "Fold: 12  Epoch: 455  Training loss = 3.4333  Validation loss = 3.7009  \n",
      "\n",
      "Fold: 12  Epoch: 456  Training loss = 3.4329  Validation loss = 3.7001  \n",
      "\n",
      "Fold: 12  Epoch: 457  Training loss = 3.4326  Validation loss = 3.6994  \n",
      "\n",
      "Fold: 12  Epoch: 458  Training loss = 3.4322  Validation loss = 3.6986  \n",
      "\n",
      "Fold: 12  Epoch: 459  Training loss = 3.4318  Validation loss = 3.6978  \n",
      "\n",
      "Fold: 12  Epoch: 460  Training loss = 3.4315  Validation loss = 3.6971  \n",
      "\n",
      "Fold: 12  Epoch: 461  Training loss = 3.4312  Validation loss = 3.6964  \n",
      "\n",
      "Fold: 12  Epoch: 462  Training loss = 3.4308  Validation loss = 3.6957  \n",
      "\n",
      "Fold: 12  Epoch: 463  Training loss = 3.4306  Validation loss = 3.6952  \n",
      "\n",
      "Fold: 12  Epoch: 464  Training loss = 3.4302  Validation loss = 3.6943  \n",
      "\n",
      "Fold: 12  Epoch: 465  Training loss = 3.4300  Validation loss = 3.6939  \n",
      "\n",
      "Fold: 12  Epoch: 466  Training loss = 3.4297  Validation loss = 3.6933  \n",
      "\n",
      "Fold: 12  Epoch: 467  Training loss = 3.4294  Validation loss = 3.6925  \n",
      "\n",
      "Fold: 12  Epoch: 468  Training loss = 3.4290  Validation loss = 3.6918  \n",
      "\n",
      "Fold: 12  Epoch: 469  Training loss = 3.4288  Validation loss = 3.6913  \n",
      "\n",
      "Fold: 12  Epoch: 470  Training loss = 3.4286  Validation loss = 3.6909  \n",
      "\n",
      "Fold: 12  Epoch: 471  Training loss = 3.4283  Validation loss = 3.6902  \n",
      "\n",
      "Fold: 12  Epoch: 472  Training loss = 3.4279  Validation loss = 3.6895  \n",
      "\n",
      "Fold: 12  Epoch: 473  Training loss = 3.4277  Validation loss = 3.6890  \n",
      "\n",
      "Fold: 12  Epoch: 474  Training loss = 3.4275  Validation loss = 3.6886  \n",
      "\n",
      "Fold: 12  Epoch: 475  Training loss = 3.4272  Validation loss = 3.6878  \n",
      "\n",
      "Fold: 12  Epoch: 476  Training loss = 3.4268  Validation loss = 3.6870  \n",
      "\n",
      "Fold: 12  Epoch: 477  Training loss = 3.4264  Validation loss = 3.6863  \n",
      "\n",
      "Fold: 12  Epoch: 478  Training loss = 3.4261  Validation loss = 3.6856  \n",
      "\n",
      "Fold: 12  Epoch: 479  Training loss = 3.4258  Validation loss = 3.6849  \n",
      "\n",
      "Fold: 12  Epoch: 480  Training loss = 3.4255  Validation loss = 3.6843  \n",
      "\n",
      "Fold: 12  Epoch: 481  Training loss = 3.4253  Validation loss = 3.6838  \n",
      "\n",
      "Fold: 12  Epoch: 482  Training loss = 3.4249  Validation loss = 3.6830  \n",
      "\n",
      "Fold: 12  Epoch: 483  Training loss = 3.4246  Validation loss = 3.6823  \n",
      "\n",
      "Fold: 12  Epoch: 484  Training loss = 3.4243  Validation loss = 3.6818  \n",
      "\n",
      "Fold: 12  Epoch: 485  Training loss = 3.4240  Validation loss = 3.6812  \n",
      "\n",
      "Fold: 12  Epoch: 486  Training loss = 3.4236  Validation loss = 3.6803  \n",
      "\n",
      "Fold: 12  Epoch: 487  Training loss = 3.4233  Validation loss = 3.6795  \n",
      "\n",
      "Fold: 12  Epoch: 488  Training loss = 3.4229  Validation loss = 3.6789  \n",
      "\n",
      "Fold: 12  Epoch: 489  Training loss = 3.4226  Validation loss = 3.6781  \n",
      "\n",
      "Fold: 12  Epoch: 490  Training loss = 3.4222  Validation loss = 3.6772  \n",
      "\n",
      "Fold: 12  Epoch: 491  Training loss = 3.4219  Validation loss = 3.6765  \n",
      "\n",
      "Fold: 12  Epoch: 492  Training loss = 3.4216  Validation loss = 3.6760  \n",
      "\n",
      "Fold: 12  Epoch: 493  Training loss = 3.4213  Validation loss = 3.6754  \n",
      "\n",
      "Fold: 12  Epoch: 494  Training loss = 3.4210  Validation loss = 3.6748  \n",
      "\n",
      "Fold: 12  Epoch: 495  Training loss = 3.4207  Validation loss = 3.6740  \n",
      "\n",
      "Fold: 12  Epoch: 496  Training loss = 3.4204  Validation loss = 3.6734  \n",
      "\n",
      "Fold: 12  Epoch: 497  Training loss = 3.4201  Validation loss = 3.6729  \n",
      "\n",
      "Fold: 12  Epoch: 498  Training loss = 3.4198  Validation loss = 3.6721  \n",
      "\n",
      "Fold: 12  Epoch: 499  Training loss = 3.4196  Validation loss = 3.6716  \n",
      "\n",
      "Fold: 12  Epoch: 500  Training loss = 3.4192  Validation loss = 3.6708  \n",
      "\n",
      "Check model:  Fold: 12  Epoch: 500  Training loss = 3.4192  Validation loss = 3.6708  \n",
      "\n",
      "Fold: 13  Epoch: 1  Training loss = 3.5126  Validation loss = 6.0654  \n",
      "\n",
      "Fold: 13  Epoch: 2  Training loss = 3.5121  Validation loss = 6.0646  \n",
      "\n",
      "Fold: 13  Epoch: 3  Training loss = 3.5118  Validation loss = 6.0641  \n",
      "\n",
      "Fold: 13  Epoch: 4  Training loss = 3.5113  Validation loss = 6.0631  \n",
      "\n",
      "Fold: 13  Epoch: 5  Training loss = 3.5109  Validation loss = 6.0624  \n",
      "\n",
      "Fold: 13  Epoch: 6  Training loss = 3.5105  Validation loss = 6.0616  \n",
      "\n",
      "Fold: 13  Epoch: 7  Training loss = 3.5100  Validation loss = 6.0607  \n",
      "\n",
      "Fold: 13  Epoch: 8  Training loss = 3.5096  Validation loss = 6.0599  \n",
      "\n",
      "Fold: 13  Epoch: 9  Training loss = 3.5092  Validation loss = 6.0591  \n",
      "\n",
      "Fold: 13  Epoch: 10  Training loss = 3.5088  Validation loss = 6.0584  \n",
      "\n",
      "Fold: 13  Epoch: 11  Training loss = 3.5084  Validation loss = 6.0577  \n",
      "\n",
      "Fold: 13  Epoch: 12  Training loss = 3.5080  Validation loss = 6.0569  \n",
      "\n",
      "Fold: 13  Epoch: 13  Training loss = 3.5076  Validation loss = 6.0561  \n",
      "\n",
      "Fold: 13  Epoch: 14  Training loss = 3.5073  Validation loss = 6.0555  \n",
      "\n",
      "Fold: 13  Epoch: 15  Training loss = 3.5069  Validation loss = 6.0548  \n",
      "\n",
      "Fold: 13  Epoch: 16  Training loss = 3.5065  Validation loss = 6.0541  \n",
      "\n",
      "Fold: 13  Epoch: 17  Training loss = 3.5061  Validation loss = 6.0534  \n",
      "\n",
      "Fold: 13  Epoch: 18  Training loss = 3.5057  Validation loss = 6.0526  \n",
      "\n",
      "Fold: 13  Epoch: 19  Training loss = 3.5054  Validation loss = 6.0520  \n",
      "\n",
      "Fold: 13  Epoch: 20  Training loss = 3.5050  Validation loss = 6.0512  \n",
      "\n",
      "Fold: 13  Epoch: 21  Training loss = 3.5045  Validation loss = 6.0504  \n",
      "\n",
      "Fold: 13  Epoch: 22  Training loss = 3.5041  Validation loss = 6.0496  \n",
      "\n",
      "Fold: 13  Epoch: 23  Training loss = 3.5037  Validation loss = 6.0489  \n",
      "\n",
      "Fold: 13  Epoch: 24  Training loss = 3.5033  Validation loss = 6.0482  \n",
      "\n",
      "Fold: 13  Epoch: 25  Training loss = 3.5030  Validation loss = 6.0475  \n",
      "\n",
      "Fold: 13  Epoch: 26  Training loss = 3.5027  Validation loss = 6.0469  \n",
      "\n",
      "Fold: 13  Epoch: 27  Training loss = 3.5024  Validation loss = 6.0464  \n",
      "\n",
      "Fold: 13  Epoch: 28  Training loss = 3.5020  Validation loss = 6.0455  \n",
      "\n",
      "Fold: 13  Epoch: 29  Training loss = 3.5016  Validation loss = 6.0447  \n",
      "\n",
      "Fold: 13  Epoch: 30  Training loss = 3.5011  Validation loss = 6.0439  \n",
      "\n",
      "Fold: 13  Epoch: 31  Training loss = 3.5006  Validation loss = 6.0430  \n",
      "\n",
      "Fold: 13  Epoch: 32  Training loss = 3.5003  Validation loss = 6.0423  \n",
      "\n",
      "Fold: 13  Epoch: 33  Training loss = 3.4998  Validation loss = 6.0415  \n",
      "\n",
      "Fold: 13  Epoch: 34  Training loss = 3.4994  Validation loss = 6.0408  \n",
      "\n",
      "Fold: 13  Epoch: 35  Training loss = 3.4990  Validation loss = 6.0399  \n",
      "\n",
      "Fold: 13  Epoch: 36  Training loss = 3.4986  Validation loss = 6.0393  \n",
      "\n",
      "Fold: 13  Epoch: 37  Training loss = 3.4981  Validation loss = 6.0383  \n",
      "\n",
      "Fold: 13  Epoch: 38  Training loss = 3.4976  Validation loss = 6.0374  \n",
      "\n",
      "Fold: 13  Epoch: 39  Training loss = 3.4972  Validation loss = 6.0367  \n",
      "\n",
      "Fold: 13  Epoch: 40  Training loss = 3.4968  Validation loss = 6.0360  \n",
      "\n",
      "Fold: 13  Epoch: 41  Training loss = 3.4964  Validation loss = 6.0351  \n",
      "\n",
      "Fold: 13  Epoch: 42  Training loss = 3.4959  Validation loss = 6.0342  \n",
      "\n",
      "Fold: 13  Epoch: 43  Training loss = 3.4956  Validation loss = 6.0337  \n",
      "\n",
      "Fold: 13  Epoch: 44  Training loss = 3.4951  Validation loss = 6.0328  \n",
      "\n",
      "Fold: 13  Epoch: 45  Training loss = 3.4948  Validation loss = 6.0321  \n",
      "\n",
      "Fold: 13  Epoch: 46  Training loss = 3.4944  Validation loss = 6.0314  \n",
      "\n",
      "Fold: 13  Epoch: 47  Training loss = 3.4940  Validation loss = 6.0306  \n",
      "\n",
      "Fold: 13  Epoch: 48  Training loss = 3.4937  Validation loss = 6.0301  \n",
      "\n",
      "Fold: 13  Epoch: 49  Training loss = 3.4932  Validation loss = 6.0291  \n",
      "\n",
      "Fold: 13  Epoch: 50  Training loss = 3.4928  Validation loss = 6.0284  \n",
      "\n",
      "Fold: 13  Epoch: 51  Training loss = 3.4924  Validation loss = 6.0276  \n",
      "\n",
      "Fold: 13  Epoch: 52  Training loss = 3.4920  Validation loss = 6.0268  \n",
      "\n",
      "Fold: 13  Epoch: 53  Training loss = 3.4916  Validation loss = 6.0260  \n",
      "\n",
      "Fold: 13  Epoch: 54  Training loss = 3.4913  Validation loss = 6.0254  \n",
      "\n",
      "Fold: 13  Epoch: 55  Training loss = 3.4908  Validation loss = 6.0246  \n",
      "\n",
      "Fold: 13  Epoch: 56  Training loss = 3.4905  Validation loss = 6.0238  \n",
      "\n",
      "Fold: 13  Epoch: 57  Training loss = 3.4901  Validation loss = 6.0231  \n",
      "\n",
      "Fold: 13  Epoch: 58  Training loss = 3.4898  Validation loss = 6.0224  \n",
      "\n",
      "Fold: 13  Epoch: 59  Training loss = 3.4895  Validation loss = 6.0218  \n",
      "\n",
      "Fold: 13  Epoch: 60  Training loss = 3.4891  Validation loss = 6.0211  \n",
      "\n",
      "Fold: 13  Epoch: 61  Training loss = 3.4888  Validation loss = 6.0205  \n",
      "\n",
      "Fold: 13  Epoch: 62  Training loss = 3.4884  Validation loss = 6.0198  \n",
      "\n",
      "Fold: 13  Epoch: 63  Training loss = 3.4882  Validation loss = 6.0193  \n",
      "\n",
      "Fold: 13  Epoch: 64  Training loss = 3.4878  Validation loss = 6.0185  \n",
      "\n",
      "Fold: 13  Epoch: 65  Training loss = 3.4873  Validation loss = 6.0177  \n",
      "\n",
      "Fold: 13  Epoch: 66  Training loss = 3.4869  Validation loss = 6.0168  \n",
      "\n",
      "Fold: 13  Epoch: 67  Training loss = 3.4866  Validation loss = 6.0162  \n",
      "\n",
      "Fold: 13  Epoch: 68  Training loss = 3.4863  Validation loss = 6.0156  \n",
      "\n",
      "Fold: 13  Epoch: 69  Training loss = 3.4859  Validation loss = 6.0150  \n",
      "\n",
      "Fold: 13  Epoch: 70  Training loss = 3.4856  Validation loss = 6.0145  \n",
      "\n",
      "Fold: 13  Epoch: 71  Training loss = 3.4852  Validation loss = 6.0137  \n",
      "\n",
      "Fold: 13  Epoch: 72  Training loss = 3.4849  Validation loss = 6.0131  \n",
      "\n",
      "Fold: 13  Epoch: 73  Training loss = 3.4845  Validation loss = 6.0123  \n",
      "\n",
      "Fold: 13  Epoch: 74  Training loss = 3.4841  Validation loss = 6.0117  \n",
      "\n",
      "Fold: 13  Epoch: 75  Training loss = 3.4837  Validation loss = 6.0109  \n",
      "\n",
      "Fold: 13  Epoch: 76  Training loss = 3.4833  Validation loss = 6.0101  \n",
      "\n",
      "Fold: 13  Epoch: 77  Training loss = 3.4828  Validation loss = 6.0092  \n",
      "\n",
      "Fold: 13  Epoch: 78  Training loss = 3.4823  Validation loss = 6.0082  \n",
      "\n",
      "Fold: 13  Epoch: 79  Training loss = 3.4819  Validation loss = 6.0074  \n",
      "\n",
      "Fold: 13  Epoch: 80  Training loss = 3.4814  Validation loss = 6.0064  \n",
      "\n",
      "Fold: 13  Epoch: 81  Training loss = 3.4811  Validation loss = 6.0058  \n",
      "\n",
      "Fold: 13  Epoch: 82  Training loss = 3.4807  Validation loss = 6.0051  \n",
      "\n",
      "Fold: 13  Epoch: 83  Training loss = 3.4802  Validation loss = 6.0042  \n",
      "\n",
      "Fold: 13  Epoch: 84  Training loss = 3.4799  Validation loss = 6.0036  \n",
      "\n",
      "Fold: 13  Epoch: 85  Training loss = 3.4794  Validation loss = 6.0027  \n",
      "\n",
      "Fold: 13  Epoch: 86  Training loss = 3.4791  Validation loss = 6.0022  \n",
      "\n",
      "Fold: 13  Epoch: 87  Training loss = 3.4786  Validation loss = 6.0012  \n",
      "\n",
      "Fold: 13  Epoch: 88  Training loss = 3.4782  Validation loss = 6.0004  \n",
      "\n",
      "Fold: 13  Epoch: 89  Training loss = 3.4777  Validation loss = 5.9995  \n",
      "\n",
      "Fold: 13  Epoch: 90  Training loss = 3.4773  Validation loss = 5.9987  \n",
      "\n",
      "Fold: 13  Epoch: 91  Training loss = 3.4769  Validation loss = 5.9980  \n",
      "\n",
      "Fold: 13  Epoch: 92  Training loss = 3.4765  Validation loss = 5.9972  \n",
      "\n",
      "Fold: 13  Epoch: 93  Training loss = 3.4761  Validation loss = 5.9964  \n",
      "\n",
      "Fold: 13  Epoch: 94  Training loss = 3.4757  Validation loss = 5.9956  \n",
      "\n",
      "Fold: 13  Epoch: 95  Training loss = 3.4753  Validation loss = 5.9950  \n",
      "\n",
      "Fold: 13  Epoch: 96  Training loss = 3.4748  Validation loss = 5.9941  \n",
      "\n",
      "Fold: 13  Epoch: 97  Training loss = 3.4744  Validation loss = 5.9933  \n",
      "\n",
      "Fold: 13  Epoch: 98  Training loss = 3.4741  Validation loss = 5.9927  \n",
      "\n",
      "Fold: 13  Epoch: 99  Training loss = 3.4737  Validation loss = 5.9921  \n",
      "\n",
      "Fold: 13  Epoch: 100  Training loss = 3.4734  Validation loss = 5.9915  \n",
      "\n",
      "Fold: 13  Epoch: 101  Training loss = 3.4730  Validation loss = 5.9907  \n",
      "\n",
      "Fold: 13  Epoch: 102  Training loss = 3.4726  Validation loss = 5.9899  \n",
      "\n",
      "Fold: 13  Epoch: 103  Training loss = 3.4721  Validation loss = 5.9891  \n",
      "\n",
      "Fold: 13  Epoch: 104  Training loss = 3.4717  Validation loss = 5.9883  \n",
      "\n",
      "Fold: 13  Epoch: 105  Training loss = 3.4713  Validation loss = 5.9875  \n",
      "\n",
      "Fold: 13  Epoch: 106  Training loss = 3.4711  Validation loss = 5.9870  \n",
      "\n",
      "Fold: 13  Epoch: 107  Training loss = 3.4707  Validation loss = 5.9863  \n",
      "\n",
      "Fold: 13  Epoch: 108  Training loss = 3.4703  Validation loss = 5.9856  \n",
      "\n",
      "Fold: 13  Epoch: 109  Training loss = 3.4699  Validation loss = 5.9849  \n",
      "\n",
      "Fold: 13  Epoch: 110  Training loss = 3.4694  Validation loss = 5.9839  \n",
      "\n",
      "Fold: 13  Epoch: 111  Training loss = 3.4690  Validation loss = 5.9833  \n",
      "\n",
      "Fold: 13  Epoch: 112  Training loss = 3.4687  Validation loss = 5.9826  \n",
      "\n",
      "Fold: 13  Epoch: 113  Training loss = 3.4683  Validation loss = 5.9819  \n",
      "\n",
      "Fold: 13  Epoch: 114  Training loss = 3.4679  Validation loss = 5.9812  \n",
      "\n",
      "Fold: 13  Epoch: 115  Training loss = 3.4676  Validation loss = 5.9805  \n",
      "\n",
      "Fold: 13  Epoch: 116  Training loss = 3.4671  Validation loss = 5.9797  \n",
      "\n",
      "Fold: 13  Epoch: 117  Training loss = 3.4666  Validation loss = 5.9787  \n",
      "\n",
      "Fold: 13  Epoch: 118  Training loss = 3.4661  Validation loss = 5.9778  \n",
      "\n",
      "Fold: 13  Epoch: 119  Training loss = 3.4658  Validation loss = 5.9772  \n",
      "\n",
      "Fold: 13  Epoch: 120  Training loss = 3.4654  Validation loss = 5.9764  \n",
      "\n",
      "Fold: 13  Epoch: 121  Training loss = 3.4650  Validation loss = 5.9757  \n",
      "\n",
      "Fold: 13  Epoch: 122  Training loss = 3.4647  Validation loss = 5.9752  \n",
      "\n",
      "Fold: 13  Epoch: 123  Training loss = 3.4643  Validation loss = 5.9744  \n",
      "\n",
      "Fold: 13  Epoch: 124  Training loss = 3.4638  Validation loss = 5.9735  \n",
      "\n",
      "Fold: 13  Epoch: 125  Training loss = 3.4635  Validation loss = 5.9729  \n",
      "\n",
      "Fold: 13  Epoch: 126  Training loss = 3.4631  Validation loss = 5.9721  \n",
      "\n",
      "Fold: 13  Epoch: 127  Training loss = 3.4626  Validation loss = 5.9712  \n",
      "\n",
      "Fold: 13  Epoch: 128  Training loss = 3.4622  Validation loss = 5.9704  \n",
      "\n",
      "Fold: 13  Epoch: 129  Training loss = 3.4618  Validation loss = 5.9697  \n",
      "\n",
      "Fold: 13  Epoch: 130  Training loss = 3.4614  Validation loss = 5.9689  \n",
      "\n",
      "Fold: 13  Epoch: 131  Training loss = 3.4610  Validation loss = 5.9682  \n",
      "\n",
      "Fold: 13  Epoch: 132  Training loss = 3.4605  Validation loss = 5.9671  \n",
      "\n",
      "Fold: 13  Epoch: 133  Training loss = 3.4601  Validation loss = 5.9664  \n",
      "\n",
      "Fold: 13  Epoch: 134  Training loss = 3.4597  Validation loss = 5.9657  \n",
      "\n",
      "Fold: 13  Epoch: 135  Training loss = 3.4592  Validation loss = 5.9647  \n",
      "\n",
      "Fold: 13  Epoch: 136  Training loss = 3.4589  Validation loss = 5.9642  \n",
      "\n",
      "Fold: 13  Epoch: 137  Training loss = 3.4583  Validation loss = 5.9631  \n",
      "\n",
      "Fold: 13  Epoch: 138  Training loss = 3.4580  Validation loss = 5.9625  \n",
      "\n",
      "Fold: 13  Epoch: 139  Training loss = 3.4576  Validation loss = 5.9618  \n",
      "\n",
      "Fold: 13  Epoch: 140  Training loss = 3.4571  Validation loss = 5.9609  \n",
      "\n",
      "Fold: 13  Epoch: 141  Training loss = 3.4568  Validation loss = 5.9603  \n",
      "\n",
      "Fold: 13  Epoch: 142  Training loss = 3.4564  Validation loss = 5.9595  \n",
      "\n",
      "Fold: 13  Epoch: 143  Training loss = 3.4560  Validation loss = 5.9587  \n",
      "\n",
      "Fold: 13  Epoch: 144  Training loss = 3.4556  Validation loss = 5.9579  \n",
      "\n",
      "Fold: 13  Epoch: 145  Training loss = 3.4552  Validation loss = 5.9573  \n",
      "\n",
      "Fold: 13  Epoch: 146  Training loss = 3.4549  Validation loss = 5.9565  \n",
      "\n",
      "Fold: 13  Epoch: 147  Training loss = 3.4545  Validation loss = 5.9558  \n",
      "\n",
      "Fold: 13  Epoch: 148  Training loss = 3.4542  Validation loss = 5.9552  \n",
      "\n",
      "Fold: 13  Epoch: 149  Training loss = 3.4538  Validation loss = 5.9545  \n",
      "\n",
      "Fold: 13  Epoch: 150  Training loss = 3.4533  Validation loss = 5.9536  \n",
      "\n",
      "Fold: 13  Epoch: 151  Training loss = 3.4530  Validation loss = 5.9530  \n",
      "\n",
      "Fold: 13  Epoch: 152  Training loss = 3.4525  Validation loss = 5.9521  \n",
      "\n",
      "Fold: 13  Epoch: 153  Training loss = 3.4521  Validation loss = 5.9514  \n",
      "\n",
      "Fold: 13  Epoch: 154  Training loss = 3.4518  Validation loss = 5.9508  \n",
      "\n",
      "Fold: 13  Epoch: 155  Training loss = 3.4515  Validation loss = 5.9501  \n",
      "\n",
      "Fold: 13  Epoch: 156  Training loss = 3.4511  Validation loss = 5.9495  \n",
      "\n",
      "Fold: 13  Epoch: 157  Training loss = 3.4508  Validation loss = 5.9489  \n",
      "\n",
      "Fold: 13  Epoch: 158  Training loss = 3.4504  Validation loss = 5.9480  \n",
      "\n",
      "Fold: 13  Epoch: 159  Training loss = 3.4499  Validation loss = 5.9471  \n",
      "\n",
      "Fold: 13  Epoch: 160  Training loss = 3.4495  Validation loss = 5.9465  \n",
      "\n",
      "Fold: 13  Epoch: 161  Training loss = 3.4492  Validation loss = 5.9458  \n",
      "\n",
      "Fold: 13  Epoch: 162  Training loss = 3.4488  Validation loss = 5.9452  \n",
      "\n",
      "Fold: 13  Epoch: 163  Training loss = 3.4484  Validation loss = 5.9445  \n",
      "\n",
      "Fold: 13  Epoch: 164  Training loss = 3.4481  Validation loss = 5.9437  \n",
      "\n",
      "Fold: 13  Epoch: 165  Training loss = 3.4477  Validation loss = 5.9430  \n",
      "\n",
      "Fold: 13  Epoch: 166  Training loss = 3.4472  Validation loss = 5.9422  \n",
      "\n",
      "Fold: 13  Epoch: 167  Training loss = 3.4469  Validation loss = 5.9416  \n",
      "\n",
      "Fold: 13  Epoch: 168  Training loss = 3.4466  Validation loss = 5.9410  \n",
      "\n",
      "Fold: 13  Epoch: 169  Training loss = 3.4463  Validation loss = 5.9403  \n",
      "\n",
      "Fold: 13  Epoch: 170  Training loss = 3.4458  Validation loss = 5.9395  \n",
      "\n",
      "Fold: 13  Epoch: 171  Training loss = 3.4455  Validation loss = 5.9389  \n",
      "\n",
      "Fold: 13  Epoch: 172  Training loss = 3.4451  Validation loss = 5.9381  \n",
      "\n",
      "Fold: 13  Epoch: 173  Training loss = 3.4446  Validation loss = 5.9373  \n",
      "\n",
      "Fold: 13  Epoch: 174  Training loss = 3.4443  Validation loss = 5.9366  \n",
      "\n",
      "Fold: 13  Epoch: 175  Training loss = 3.4439  Validation loss = 5.9359  \n",
      "\n",
      "Fold: 13  Epoch: 176  Training loss = 3.4435  Validation loss = 5.9352  \n",
      "\n",
      "Fold: 13  Epoch: 177  Training loss = 3.4433  Validation loss = 5.9348  \n",
      "\n",
      "Fold: 13  Epoch: 178  Training loss = 3.4429  Validation loss = 5.9340  \n",
      "\n",
      "Fold: 13  Epoch: 179  Training loss = 3.4424  Validation loss = 5.9331  \n",
      "\n",
      "Fold: 13  Epoch: 180  Training loss = 3.4419  Validation loss = 5.9322  \n",
      "\n",
      "Fold: 13  Epoch: 181  Training loss = 3.4417  Validation loss = 5.9317  \n",
      "\n",
      "Fold: 13  Epoch: 182  Training loss = 3.4412  Validation loss = 5.9308  \n",
      "\n",
      "Fold: 13  Epoch: 183  Training loss = 3.4408  Validation loss = 5.9301  \n",
      "\n",
      "Fold: 13  Epoch: 184  Training loss = 3.4405  Validation loss = 5.9295  \n",
      "\n",
      "Fold: 13  Epoch: 185  Training loss = 3.4400  Validation loss = 5.9286  \n",
      "\n",
      "Fold: 13  Epoch: 186  Training loss = 3.4397  Validation loss = 5.9280  \n",
      "\n",
      "Fold: 13  Epoch: 187  Training loss = 3.4394  Validation loss = 5.9273  \n",
      "\n",
      "Fold: 13  Epoch: 188  Training loss = 3.4390  Validation loss = 5.9266  \n",
      "\n",
      "Fold: 13  Epoch: 189  Training loss = 3.4386  Validation loss = 5.9258  \n",
      "\n",
      "Fold: 13  Epoch: 190  Training loss = 3.4383  Validation loss = 5.9252  \n",
      "\n",
      "Fold: 13  Epoch: 191  Training loss = 3.4379  Validation loss = 5.9244  \n",
      "\n",
      "Fold: 13  Epoch: 192  Training loss = 3.4375  Validation loss = 5.9235  \n",
      "\n",
      "Fold: 13  Epoch: 193  Training loss = 3.4370  Validation loss = 5.9227  \n",
      "\n",
      "Fold: 13  Epoch: 194  Training loss = 3.4365  Validation loss = 5.9217  \n",
      "\n",
      "Fold: 13  Epoch: 195  Training loss = 3.4361  Validation loss = 5.9210  \n",
      "\n",
      "Fold: 13  Epoch: 196  Training loss = 3.4358  Validation loss = 5.9202  \n",
      "\n",
      "Fold: 13  Epoch: 197  Training loss = 3.4353  Validation loss = 5.9193  \n",
      "\n",
      "Fold: 13  Epoch: 198  Training loss = 3.4349  Validation loss = 5.9186  \n",
      "\n",
      "Fold: 13  Epoch: 199  Training loss = 3.4345  Validation loss = 5.9179  \n",
      "\n",
      "Fold: 13  Epoch: 200  Training loss = 3.4341  Validation loss = 5.9170  \n",
      "\n",
      "Fold: 13  Epoch: 201  Training loss = 3.4337  Validation loss = 5.9162  \n",
      "\n",
      "Fold: 13  Epoch: 202  Training loss = 3.4334  Validation loss = 5.9155  \n",
      "\n",
      "Fold: 13  Epoch: 203  Training loss = 3.4329  Validation loss = 5.9147  \n",
      "\n",
      "Fold: 13  Epoch: 204  Training loss = 3.4325  Validation loss = 5.9139  \n",
      "\n",
      "Fold: 13  Epoch: 205  Training loss = 3.4322  Validation loss = 5.9132  \n",
      "\n",
      "Fold: 13  Epoch: 206  Training loss = 3.4319  Validation loss = 5.9126  \n",
      "\n",
      "Fold: 13  Epoch: 207  Training loss = 3.4314  Validation loss = 5.9117  \n",
      "\n",
      "Fold: 13  Epoch: 208  Training loss = 3.4310  Validation loss = 5.9109  \n",
      "\n",
      "Fold: 13  Epoch: 209  Training loss = 3.4306  Validation loss = 5.9102  \n",
      "\n",
      "Fold: 13  Epoch: 210  Training loss = 3.4303  Validation loss = 5.9095  \n",
      "\n",
      "Fold: 13  Epoch: 211  Training loss = 3.4298  Validation loss = 5.9086  \n",
      "\n",
      "Fold: 13  Epoch: 212  Training loss = 3.4294  Validation loss = 5.9079  \n",
      "\n",
      "Fold: 13  Epoch: 213  Training loss = 3.4291  Validation loss = 5.9072  \n",
      "\n",
      "Fold: 13  Epoch: 214  Training loss = 3.4287  Validation loss = 5.9065  \n",
      "\n",
      "Fold: 13  Epoch: 215  Training loss = 3.4284  Validation loss = 5.9059  \n",
      "\n",
      "Fold: 13  Epoch: 216  Training loss = 3.4279  Validation loss = 5.9049  \n",
      "\n",
      "Fold: 13  Epoch: 217  Training loss = 3.4275  Validation loss = 5.9041  \n",
      "\n",
      "Fold: 13  Epoch: 218  Training loss = 3.4272  Validation loss = 5.9035  \n",
      "\n",
      "Fold: 13  Epoch: 219  Training loss = 3.4268  Validation loss = 5.9028  \n",
      "\n",
      "Fold: 13  Epoch: 220  Training loss = 3.4265  Validation loss = 5.9021  \n",
      "\n",
      "Fold: 13  Epoch: 221  Training loss = 3.4261  Validation loss = 5.9013  \n",
      "\n",
      "Fold: 13  Epoch: 222  Training loss = 3.4258  Validation loss = 5.9007  \n",
      "\n",
      "Fold: 13  Epoch: 223  Training loss = 3.4255  Validation loss = 5.9000  \n",
      "\n",
      "Fold: 13  Epoch: 224  Training loss = 3.4251  Validation loss = 5.8993  \n",
      "\n",
      "Fold: 13  Epoch: 225  Training loss = 3.4248  Validation loss = 5.8986  \n",
      "\n",
      "Fold: 13  Epoch: 226  Training loss = 3.4244  Validation loss = 5.8980  \n",
      "\n",
      "Fold: 13  Epoch: 227  Training loss = 3.4241  Validation loss = 5.8974  \n",
      "\n",
      "Fold: 13  Epoch: 228  Training loss = 3.4238  Validation loss = 5.8968  \n",
      "\n",
      "Fold: 13  Epoch: 229  Training loss = 3.4235  Validation loss = 5.8962  \n",
      "\n",
      "Fold: 13  Epoch: 230  Training loss = 3.4232  Validation loss = 5.8956  \n",
      "\n",
      "Fold: 13  Epoch: 231  Training loss = 3.4227  Validation loss = 5.8948  \n",
      "\n",
      "Fold: 13  Epoch: 232  Training loss = 3.4224  Validation loss = 5.8940  \n",
      "\n",
      "Fold: 13  Epoch: 233  Training loss = 3.4220  Validation loss = 5.8932  \n",
      "\n",
      "Fold: 13  Epoch: 234  Training loss = 3.4216  Validation loss = 5.8926  \n",
      "\n",
      "Fold: 13  Epoch: 235  Training loss = 3.4213  Validation loss = 5.8918  \n",
      "\n",
      "Fold: 13  Epoch: 236  Training loss = 3.4209  Validation loss = 5.8911  \n",
      "\n",
      "Fold: 13  Epoch: 237  Training loss = 3.4205  Validation loss = 5.8904  \n",
      "\n",
      "Fold: 13  Epoch: 238  Training loss = 3.4202  Validation loss = 5.8898  \n",
      "\n",
      "Fold: 13  Epoch: 239  Training loss = 3.4198  Validation loss = 5.8891  \n",
      "\n",
      "Fold: 13  Epoch: 240  Training loss = 3.4194  Validation loss = 5.8883  \n",
      "\n",
      "Fold: 13  Epoch: 241  Training loss = 3.4190  Validation loss = 5.8875  \n",
      "\n",
      "Fold: 13  Epoch: 242  Training loss = 3.4186  Validation loss = 5.8869  \n",
      "\n",
      "Fold: 13  Epoch: 243  Training loss = 3.4183  Validation loss = 5.8862  \n",
      "\n",
      "Fold: 13  Epoch: 244  Training loss = 3.4179  Validation loss = 5.8855  \n",
      "\n",
      "Fold: 13  Epoch: 245  Training loss = 3.4175  Validation loss = 5.8847  \n",
      "\n",
      "Fold: 13  Epoch: 246  Training loss = 3.4171  Validation loss = 5.8839  \n",
      "\n",
      "Fold: 13  Epoch: 247  Training loss = 3.4168  Validation loss = 5.8831  \n",
      "\n",
      "Fold: 13  Epoch: 248  Training loss = 3.4163  Validation loss = 5.8824  \n",
      "\n",
      "Fold: 13  Epoch: 249  Training loss = 3.4159  Validation loss = 5.8815  \n",
      "\n",
      "Fold: 13  Epoch: 250  Training loss = 3.4156  Validation loss = 5.8810  \n",
      "\n",
      "Fold: 13  Epoch: 251  Training loss = 3.4153  Validation loss = 5.8805  \n",
      "\n",
      "Fold: 13  Epoch: 252  Training loss = 3.4150  Validation loss = 5.8798  \n",
      "\n",
      "Fold: 13  Epoch: 253  Training loss = 3.4145  Validation loss = 5.8789  \n",
      "\n",
      "Fold: 13  Epoch: 254  Training loss = 3.4141  Validation loss = 5.8781  \n",
      "\n",
      "Fold: 13  Epoch: 255  Training loss = 3.4138  Validation loss = 5.8774  \n",
      "\n",
      "Fold: 13  Epoch: 256  Training loss = 3.4134  Validation loss = 5.8768  \n",
      "\n",
      "Fold: 13  Epoch: 257  Training loss = 3.4131  Validation loss = 5.8761  \n",
      "\n",
      "Fold: 13  Epoch: 258  Training loss = 3.4127  Validation loss = 5.8753  \n",
      "\n",
      "Fold: 13  Epoch: 259  Training loss = 3.4122  Validation loss = 5.8744  \n",
      "\n",
      "Fold: 13  Epoch: 260  Training loss = 3.4119  Validation loss = 5.8738  \n",
      "\n",
      "Fold: 13  Epoch: 261  Training loss = 3.4116  Validation loss = 5.8731  \n",
      "\n",
      "Fold: 13  Epoch: 262  Training loss = 3.4112  Validation loss = 5.8723  \n",
      "\n",
      "Fold: 13  Epoch: 263  Training loss = 3.4108  Validation loss = 5.8717  \n",
      "\n",
      "Fold: 13  Epoch: 264  Training loss = 3.4105  Validation loss = 5.8710  \n",
      "\n",
      "Fold: 13  Epoch: 265  Training loss = 3.4101  Validation loss = 5.8703  \n",
      "\n",
      "Fold: 13  Epoch: 266  Training loss = 3.4099  Validation loss = 5.8698  \n",
      "\n",
      "Fold: 13  Epoch: 267  Training loss = 3.4095  Validation loss = 5.8689  \n",
      "\n",
      "Fold: 13  Epoch: 268  Training loss = 3.4092  Validation loss = 5.8683  \n",
      "\n",
      "Fold: 13  Epoch: 269  Training loss = 3.4089  Validation loss = 5.8677  \n",
      "\n",
      "Fold: 13  Epoch: 270  Training loss = 3.4085  Validation loss = 5.8670  \n",
      "\n",
      "Fold: 13  Epoch: 271  Training loss = 3.4083  Validation loss = 5.8666  \n",
      "\n",
      "Fold: 13  Epoch: 272  Training loss = 3.4079  Validation loss = 5.8659  \n",
      "\n",
      "Fold: 13  Epoch: 273  Training loss = 3.4075  Validation loss = 5.8651  \n",
      "\n",
      "Fold: 13  Epoch: 274  Training loss = 3.4073  Validation loss = 5.8646  \n",
      "\n",
      "Fold: 13  Epoch: 275  Training loss = 3.4070  Validation loss = 5.8641  \n",
      "\n",
      "Fold: 13  Epoch: 276  Training loss = 3.4066  Validation loss = 5.8634  \n",
      "\n",
      "Fold: 13  Epoch: 277  Training loss = 3.4063  Validation loss = 5.8627  \n",
      "\n",
      "Fold: 13  Epoch: 278  Training loss = 3.4060  Validation loss = 5.8620  \n",
      "\n",
      "Fold: 13  Epoch: 279  Training loss = 3.4055  Validation loss = 5.8611  \n",
      "\n",
      "Fold: 13  Epoch: 280  Training loss = 3.4052  Validation loss = 5.8604  \n",
      "\n",
      "Fold: 13  Epoch: 281  Training loss = 3.4048  Validation loss = 5.8596  \n",
      "\n",
      "Fold: 13  Epoch: 282  Training loss = 3.4044  Validation loss = 5.8589  \n",
      "\n",
      "Fold: 13  Epoch: 283  Training loss = 3.4040  Validation loss = 5.8580  \n",
      "\n",
      "Fold: 13  Epoch: 284  Training loss = 3.4036  Validation loss = 5.8573  \n",
      "\n",
      "Fold: 13  Epoch: 285  Training loss = 3.4034  Validation loss = 5.8568  \n",
      "\n",
      "Fold: 13  Epoch: 286  Training loss = 3.4030  Validation loss = 5.8560  \n",
      "\n",
      "Fold: 13  Epoch: 287  Training loss = 3.4026  Validation loss = 5.8552  \n",
      "\n",
      "Fold: 13  Epoch: 288  Training loss = 3.4021  Validation loss = 5.8543  \n",
      "\n",
      "Fold: 13  Epoch: 289  Training loss = 3.4018  Validation loss = 5.8536  \n",
      "\n",
      "Fold: 13  Epoch: 290  Training loss = 3.4014  Validation loss = 5.8528  \n",
      "\n",
      "Fold: 13  Epoch: 291  Training loss = 3.4011  Validation loss = 5.8521  \n",
      "\n",
      "Fold: 13  Epoch: 292  Training loss = 3.4006  Validation loss = 5.8513  \n",
      "\n",
      "Fold: 13  Epoch: 293  Training loss = 3.4002  Validation loss = 5.8505  \n",
      "\n",
      "Fold: 13  Epoch: 294  Training loss = 3.3999  Validation loss = 5.8500  \n",
      "\n",
      "Fold: 13  Epoch: 295  Training loss = 3.3997  Validation loss = 5.8495  \n",
      "\n",
      "Fold: 13  Epoch: 296  Training loss = 3.3994  Validation loss = 5.8489  \n",
      "\n",
      "Fold: 13  Epoch: 297  Training loss = 3.3991  Validation loss = 5.8483  \n",
      "\n",
      "Fold: 13  Epoch: 298  Training loss = 3.3986  Validation loss = 5.8474  \n",
      "\n",
      "Fold: 13  Epoch: 299  Training loss = 3.3982  Validation loss = 5.8466  \n",
      "\n",
      "Fold: 13  Epoch: 300  Training loss = 3.3979  Validation loss = 5.8459  \n",
      "\n",
      "Fold: 13  Epoch: 301  Training loss = 3.3974  Validation loss = 5.8451  \n",
      "\n",
      "Fold: 13  Epoch: 302  Training loss = 3.3971  Validation loss = 5.8444  \n",
      "\n",
      "Fold: 13  Epoch: 303  Training loss = 3.3968  Validation loss = 5.8438  \n",
      "\n",
      "Fold: 13  Epoch: 304  Training loss = 3.3965  Validation loss = 5.8432  \n",
      "\n",
      "Fold: 13  Epoch: 305  Training loss = 3.3962  Validation loss = 5.8425  \n",
      "\n",
      "Fold: 13  Epoch: 306  Training loss = 3.3958  Validation loss = 5.8418  \n",
      "\n",
      "Fold: 13  Epoch: 307  Training loss = 3.3955  Validation loss = 5.8411  \n",
      "\n",
      "Fold: 13  Epoch: 308  Training loss = 3.3951  Validation loss = 5.8403  \n",
      "\n",
      "Fold: 13  Epoch: 309  Training loss = 3.3946  Validation loss = 5.8394  \n",
      "\n",
      "Fold: 13  Epoch: 310  Training loss = 3.3943  Validation loss = 5.8388  \n",
      "\n",
      "Fold: 13  Epoch: 311  Training loss = 3.3938  Validation loss = 5.8379  \n",
      "\n",
      "Fold: 13  Epoch: 312  Training loss = 3.3933  Validation loss = 5.8370  \n",
      "\n",
      "Fold: 13  Epoch: 313  Training loss = 3.3930  Validation loss = 5.8363  \n",
      "\n",
      "Fold: 13  Epoch: 314  Training loss = 3.3926  Validation loss = 5.8356  \n",
      "\n",
      "Fold: 13  Epoch: 315  Training loss = 3.3923  Validation loss = 5.8350  \n",
      "\n",
      "Fold: 13  Epoch: 316  Training loss = 3.3919  Validation loss = 5.8342  \n",
      "\n",
      "Fold: 13  Epoch: 317  Training loss = 3.3915  Validation loss = 5.8334  \n",
      "\n",
      "Fold: 13  Epoch: 318  Training loss = 3.3912  Validation loss = 5.8329  \n",
      "\n",
      "Fold: 13  Epoch: 319  Training loss = 3.3909  Validation loss = 5.8322  \n",
      "\n",
      "Fold: 13  Epoch: 320  Training loss = 3.3906  Validation loss = 5.8317  \n",
      "\n",
      "Fold: 13  Epoch: 321  Training loss = 3.3903  Validation loss = 5.8311  \n",
      "\n",
      "Fold: 13  Epoch: 322  Training loss = 3.3899  Validation loss = 5.8303  \n",
      "\n",
      "Fold: 13  Epoch: 323  Training loss = 3.3896  Validation loss = 5.8296  \n",
      "\n",
      "Fold: 13  Epoch: 324  Training loss = 3.3891  Validation loss = 5.8287  \n",
      "\n",
      "Fold: 13  Epoch: 325  Training loss = 3.3887  Validation loss = 5.8279  \n",
      "\n",
      "Fold: 13  Epoch: 326  Training loss = 3.3883  Validation loss = 5.8271  \n",
      "\n",
      "Fold: 13  Epoch: 327  Training loss = 3.3879  Validation loss = 5.8264  \n",
      "\n",
      "Fold: 13  Epoch: 328  Training loss = 3.3875  Validation loss = 5.8256  \n",
      "\n",
      "Fold: 13  Epoch: 329  Training loss = 3.3871  Validation loss = 5.8249  \n",
      "\n",
      "Fold: 13  Epoch: 330  Training loss = 3.3867  Validation loss = 5.8241  \n",
      "\n",
      "Fold: 13  Epoch: 331  Training loss = 3.3864  Validation loss = 5.8234  \n",
      "\n",
      "Fold: 13  Epoch: 332  Training loss = 3.3861  Validation loss = 5.8228  \n",
      "\n",
      "Fold: 13  Epoch: 333  Training loss = 3.3857  Validation loss = 5.8220  \n",
      "\n",
      "Fold: 13  Epoch: 334  Training loss = 3.3853  Validation loss = 5.8213  \n",
      "\n",
      "Fold: 13  Epoch: 335  Training loss = 3.3851  Validation loss = 5.8208  \n",
      "\n",
      "Fold: 13  Epoch: 336  Training loss = 3.3848  Validation loss = 5.8202  \n",
      "\n",
      "Fold: 13  Epoch: 337  Training loss = 3.3844  Validation loss = 5.8194  \n",
      "\n",
      "Fold: 13  Epoch: 338  Training loss = 3.3840  Validation loss = 5.8187  \n",
      "\n",
      "Fold: 13  Epoch: 339  Training loss = 3.3837  Validation loss = 5.8181  \n",
      "\n",
      "Fold: 13  Epoch: 340  Training loss = 3.3834  Validation loss = 5.8174  \n",
      "\n",
      "Fold: 13  Epoch: 341  Training loss = 3.3829  Validation loss = 5.8165  \n",
      "\n",
      "Fold: 13  Epoch: 342  Training loss = 3.3825  Validation loss = 5.8157  \n",
      "\n",
      "Fold: 13  Epoch: 343  Training loss = 3.3823  Validation loss = 5.8152  \n",
      "\n",
      "Fold: 13  Epoch: 344  Training loss = 3.3820  Validation loss = 5.8145  \n",
      "\n",
      "Fold: 13  Epoch: 345  Training loss = 3.3816  Validation loss = 5.8137  \n",
      "\n",
      "Fold: 13  Epoch: 346  Training loss = 3.3812  Validation loss = 5.8129  \n",
      "\n",
      "Fold: 13  Epoch: 347  Training loss = 3.3809  Validation loss = 5.8123  \n",
      "\n",
      "Fold: 13  Epoch: 348  Training loss = 3.3807  Validation loss = 5.8118  \n",
      "\n",
      "Fold: 13  Epoch: 349  Training loss = 3.3803  Validation loss = 5.8111  \n",
      "\n",
      "Fold: 13  Epoch: 350  Training loss = 3.3799  Validation loss = 5.8103  \n",
      "\n",
      "Fold: 13  Epoch: 351  Training loss = 3.3795  Validation loss = 5.8094  \n",
      "\n",
      "Fold: 13  Epoch: 352  Training loss = 3.3791  Validation loss = 5.8087  \n",
      "\n",
      "Fold: 13  Epoch: 353  Training loss = 3.3788  Validation loss = 5.8080  \n",
      "\n",
      "Fold: 13  Epoch: 354  Training loss = 3.3785  Validation loss = 5.8074  \n",
      "\n",
      "Fold: 13  Epoch: 355  Training loss = 3.3781  Validation loss = 5.8066  \n",
      "\n",
      "Fold: 13  Epoch: 356  Training loss = 3.3777  Validation loss = 5.8058  \n",
      "\n",
      "Fold: 13  Epoch: 357  Training loss = 3.3773  Validation loss = 5.8051  \n",
      "\n",
      "Fold: 13  Epoch: 358  Training loss = 3.3770  Validation loss = 5.8044  \n",
      "\n",
      "Fold: 13  Epoch: 359  Training loss = 3.3767  Validation loss = 5.8038  \n",
      "\n",
      "Fold: 13  Epoch: 360  Training loss = 3.3763  Validation loss = 5.8030  \n",
      "\n",
      "Fold: 13  Epoch: 361  Training loss = 3.3760  Validation loss = 5.8025  \n",
      "\n",
      "Fold: 13  Epoch: 362  Training loss = 3.3757  Validation loss = 5.8018  \n",
      "\n",
      "Fold: 13  Epoch: 363  Training loss = 3.3754  Validation loss = 5.8011  \n",
      "\n",
      "Fold: 13  Epoch: 364  Training loss = 3.3751  Validation loss = 5.8004  \n",
      "\n",
      "Fold: 13  Epoch: 365  Training loss = 3.3747  Validation loss = 5.7998  \n",
      "\n",
      "Fold: 13  Epoch: 366  Training loss = 3.3744  Validation loss = 5.7991  \n",
      "\n",
      "Fold: 13  Epoch: 367  Training loss = 3.3740  Validation loss = 5.7983  \n",
      "\n",
      "Fold: 13  Epoch: 368  Training loss = 3.3737  Validation loss = 5.7977  \n",
      "\n",
      "Fold: 13  Epoch: 369  Training loss = 3.3733  Validation loss = 5.7969  \n",
      "\n",
      "Fold: 13  Epoch: 370  Training loss = 3.3730  Validation loss = 5.7962  \n",
      "\n",
      "Fold: 13  Epoch: 371  Training loss = 3.3726  Validation loss = 5.7956  \n",
      "\n",
      "Fold: 13  Epoch: 372  Training loss = 3.3723  Validation loss = 5.7950  \n",
      "\n",
      "Fold: 13  Epoch: 373  Training loss = 3.3721  Validation loss = 5.7945  \n",
      "\n",
      "Fold: 13  Epoch: 374  Training loss = 3.3718  Validation loss = 5.7939  \n",
      "\n",
      "Fold: 13  Epoch: 375  Training loss = 3.3714  Validation loss = 5.7930  \n",
      "\n",
      "Fold: 13  Epoch: 376  Training loss = 3.3711  Validation loss = 5.7924  \n",
      "\n",
      "Fold: 13  Epoch: 377  Training loss = 3.3706  Validation loss = 5.7915  \n",
      "\n",
      "Fold: 13  Epoch: 378  Training loss = 3.3703  Validation loss = 5.7909  \n",
      "\n",
      "Fold: 13  Epoch: 379  Training loss = 3.3699  Validation loss = 5.7900  \n",
      "\n",
      "Fold: 13  Epoch: 380  Training loss = 3.3696  Validation loss = 5.7894  \n",
      "\n",
      "Fold: 13  Epoch: 381  Training loss = 3.3694  Validation loss = 5.7890  \n",
      "\n",
      "Fold: 13  Epoch: 382  Training loss = 3.3690  Validation loss = 5.7883  \n",
      "\n",
      "Fold: 13  Epoch: 383  Training loss = 3.3686  Validation loss = 5.7874  \n",
      "\n",
      "Fold: 13  Epoch: 384  Training loss = 3.3683  Validation loss = 5.7868  \n",
      "\n",
      "Fold: 13  Epoch: 385  Training loss = 3.3678  Validation loss = 5.7859  \n",
      "\n",
      "Fold: 13  Epoch: 386  Training loss = 3.3675  Validation loss = 5.7853  \n",
      "\n",
      "Fold: 13  Epoch: 387  Training loss = 3.3671  Validation loss = 5.7845  \n",
      "\n",
      "Fold: 13  Epoch: 388  Training loss = 3.3667  Validation loss = 5.7837  \n",
      "\n",
      "Fold: 13  Epoch: 389  Training loss = 3.3664  Validation loss = 5.7832  \n",
      "\n",
      "Fold: 13  Epoch: 390  Training loss = 3.3661  Validation loss = 5.7825  \n",
      "\n",
      "Fold: 13  Epoch: 391  Training loss = 3.3659  Validation loss = 5.7821  \n",
      "\n",
      "Fold: 13  Epoch: 392  Training loss = 3.3655  Validation loss = 5.7812  \n",
      "\n",
      "Fold: 13  Epoch: 393  Training loss = 3.3650  Validation loss = 5.7804  \n",
      "\n",
      "Fold: 13  Epoch: 394  Training loss = 3.3647  Validation loss = 5.7796  \n",
      "\n",
      "Fold: 13  Epoch: 395  Training loss = 3.3645  Validation loss = 5.7792  \n",
      "\n",
      "Fold: 13  Epoch: 396  Training loss = 3.3641  Validation loss = 5.7786  \n",
      "\n",
      "Fold: 13  Epoch: 397  Training loss = 3.3637  Validation loss = 5.7777  \n",
      "\n",
      "Fold: 13  Epoch: 398  Training loss = 3.3634  Validation loss = 5.7770  \n",
      "\n",
      "Fold: 13  Epoch: 399  Training loss = 3.3631  Validation loss = 5.7764  \n",
      "\n",
      "Fold: 13  Epoch: 400  Training loss = 3.3627  Validation loss = 5.7756  \n",
      "\n",
      "Fold: 13  Epoch: 401  Training loss = 3.3623  Validation loss = 5.7749  \n",
      "\n",
      "Fold: 13  Epoch: 402  Training loss = 3.3620  Validation loss = 5.7743  \n",
      "\n",
      "Fold: 13  Epoch: 403  Training loss = 3.3617  Validation loss = 5.7736  \n",
      "\n",
      "Fold: 13  Epoch: 404  Training loss = 3.3613  Validation loss = 5.7729  \n",
      "\n",
      "Fold: 13  Epoch: 405  Training loss = 3.3610  Validation loss = 5.7721  \n",
      "\n",
      "Fold: 13  Epoch: 406  Training loss = 3.3607  Validation loss = 5.7716  \n",
      "\n",
      "Fold: 13  Epoch: 407  Training loss = 3.3604  Validation loss = 5.7709  \n",
      "\n",
      "Fold: 13  Epoch: 408  Training loss = 3.3601  Validation loss = 5.7703  \n",
      "\n",
      "Fold: 13  Epoch: 409  Training loss = 3.3598  Validation loss = 5.7697  \n",
      "\n",
      "Fold: 13  Epoch: 410  Training loss = 3.3594  Validation loss = 5.7689  \n",
      "\n",
      "Fold: 13  Epoch: 411  Training loss = 3.3591  Validation loss = 5.7682  \n",
      "\n",
      "Fold: 13  Epoch: 412  Training loss = 3.3587  Validation loss = 5.7675  \n",
      "\n",
      "Fold: 13  Epoch: 413  Training loss = 3.3583  Validation loss = 5.7668  \n",
      "\n",
      "Fold: 13  Epoch: 414  Training loss = 3.3580  Validation loss = 5.7660  \n",
      "\n",
      "Fold: 13  Epoch: 415  Training loss = 3.3576  Validation loss = 5.7652  \n",
      "\n",
      "Fold: 13  Epoch: 416  Training loss = 3.3574  Validation loss = 5.7647  \n",
      "\n",
      "Fold: 13  Epoch: 417  Training loss = 3.3570  Validation loss = 5.7639  \n",
      "\n",
      "Fold: 13  Epoch: 418  Training loss = 3.3567  Validation loss = 5.7632  \n",
      "\n",
      "Fold: 13  Epoch: 419  Training loss = 3.3563  Validation loss = 5.7625  \n",
      "\n",
      "Fold: 13  Epoch: 420  Training loss = 3.3559  Validation loss = 5.7617  \n",
      "\n",
      "Fold: 13  Epoch: 421  Training loss = 3.3556  Validation loss = 5.7611  \n",
      "\n",
      "Fold: 13  Epoch: 422  Training loss = 3.3553  Validation loss = 5.7603  \n",
      "\n",
      "Fold: 13  Epoch: 423  Training loss = 3.3549  Validation loss = 5.7597  \n",
      "\n",
      "Fold: 13  Epoch: 424  Training loss = 3.3546  Validation loss = 5.7589  \n",
      "\n",
      "Fold: 13  Epoch: 425  Training loss = 3.3543  Validation loss = 5.7585  \n",
      "\n",
      "Fold: 13  Epoch: 426  Training loss = 3.3539  Validation loss = 5.7577  \n",
      "\n",
      "Fold: 13  Epoch: 427  Training loss = 3.3536  Validation loss = 5.7570  \n",
      "\n",
      "Fold: 13  Epoch: 428  Training loss = 3.3532  Validation loss = 5.7563  \n",
      "\n",
      "Fold: 13  Epoch: 429  Training loss = 3.3529  Validation loss = 5.7555  \n",
      "\n",
      "Fold: 13  Epoch: 430  Training loss = 3.3526  Validation loss = 5.7549  \n",
      "\n",
      "Fold: 13  Epoch: 431  Training loss = 3.3523  Validation loss = 5.7543  \n",
      "\n",
      "Fold: 13  Epoch: 432  Training loss = 3.3519  Validation loss = 5.7535  \n",
      "\n",
      "Fold: 13  Epoch: 433  Training loss = 3.3515  Validation loss = 5.7529  \n",
      "\n",
      "Fold: 13  Epoch: 434  Training loss = 3.3513  Validation loss = 5.7524  \n",
      "\n",
      "Fold: 13  Epoch: 435  Training loss = 3.3510  Validation loss = 5.7517  \n",
      "\n",
      "Fold: 13  Epoch: 436  Training loss = 3.3507  Validation loss = 5.7509  \n",
      "\n",
      "Fold: 13  Epoch: 437  Training loss = 3.3502  Validation loss = 5.7500  \n",
      "\n",
      "Fold: 13  Epoch: 438  Training loss = 3.3500  Validation loss = 5.7496  \n",
      "\n",
      "Fold: 13  Epoch: 439  Training loss = 3.3496  Validation loss = 5.7488  \n",
      "\n",
      "Fold: 13  Epoch: 440  Training loss = 3.3493  Validation loss = 5.7482  \n",
      "\n",
      "Fold: 13  Epoch: 441  Training loss = 3.3490  Validation loss = 5.7476  \n",
      "\n",
      "Fold: 13  Epoch: 442  Training loss = 3.3487  Validation loss = 5.7468  \n",
      "\n",
      "Fold: 13  Epoch: 443  Training loss = 3.3483  Validation loss = 5.7461  \n",
      "\n",
      "Fold: 13  Epoch: 444  Training loss = 3.3479  Validation loss = 5.7453  \n",
      "\n",
      "Fold: 13  Epoch: 445  Training loss = 3.3477  Validation loss = 5.7447  \n",
      "\n",
      "Fold: 13  Epoch: 446  Training loss = 3.3473  Validation loss = 5.7440  \n",
      "\n",
      "Fold: 13  Epoch: 447  Training loss = 3.3470  Validation loss = 5.7433  \n",
      "\n",
      "Fold: 13  Epoch: 448  Training loss = 3.3467  Validation loss = 5.7427  \n",
      "\n",
      "Fold: 13  Epoch: 449  Training loss = 3.3464  Validation loss = 5.7421  \n",
      "\n",
      "Fold: 13  Epoch: 450  Training loss = 3.3462  Validation loss = 5.7417  \n",
      "\n",
      "Fold: 13  Epoch: 451  Training loss = 3.3459  Validation loss = 5.7412  \n",
      "\n",
      "Fold: 13  Epoch: 452  Training loss = 3.3456  Validation loss = 5.7405  \n",
      "\n",
      "Fold: 13  Epoch: 453  Training loss = 3.3452  Validation loss = 5.7397  \n",
      "\n",
      "Fold: 13  Epoch: 454  Training loss = 3.3448  Validation loss = 5.7389  \n",
      "\n",
      "Fold: 13  Epoch: 455  Training loss = 3.3446  Validation loss = 5.7384  \n",
      "\n",
      "Fold: 13  Epoch: 456  Training loss = 3.3444  Validation loss = 5.7380  \n",
      "\n",
      "Fold: 13  Epoch: 457  Training loss = 3.3441  Validation loss = 5.7375  \n",
      "\n",
      "Fold: 13  Epoch: 458  Training loss = 3.3439  Validation loss = 5.7369  \n",
      "\n",
      "Fold: 13  Epoch: 459  Training loss = 3.3435  Validation loss = 5.7361  \n",
      "\n",
      "Fold: 13  Epoch: 460  Training loss = 3.3432  Validation loss = 5.7356  \n",
      "\n",
      "Fold: 13  Epoch: 461  Training loss = 3.3429  Validation loss = 5.7350  \n",
      "\n",
      "Fold: 13  Epoch: 462  Training loss = 3.3426  Validation loss = 5.7344  \n",
      "\n",
      "Fold: 13  Epoch: 463  Training loss = 3.3422  Validation loss = 5.7336  \n",
      "\n",
      "Fold: 13  Epoch: 464  Training loss = 3.3419  Validation loss = 5.7330  \n",
      "\n",
      "Fold: 13  Epoch: 465  Training loss = 3.3417  Validation loss = 5.7325  \n",
      "\n",
      "Fold: 13  Epoch: 466  Training loss = 3.3414  Validation loss = 5.7319  \n",
      "\n",
      "Fold: 13  Epoch: 467  Training loss = 3.3410  Validation loss = 5.7312  \n",
      "\n",
      "Fold: 13  Epoch: 468  Training loss = 3.3408  Validation loss = 5.7306  \n",
      "\n",
      "Fold: 13  Epoch: 469  Training loss = 3.3404  Validation loss = 5.7298  \n",
      "\n",
      "Fold: 13  Epoch: 470  Training loss = 3.3401  Validation loss = 5.7292  \n",
      "\n",
      "Fold: 13  Epoch: 471  Training loss = 3.3397  Validation loss = 5.7284  \n",
      "\n",
      "Fold: 13  Epoch: 472  Training loss = 3.3393  Validation loss = 5.7277  \n",
      "\n",
      "Fold: 13  Epoch: 473  Training loss = 3.3390  Validation loss = 5.7271  \n",
      "\n",
      "Fold: 13  Epoch: 474  Training loss = 3.3387  Validation loss = 5.7263  \n",
      "\n",
      "Fold: 13  Epoch: 475  Training loss = 3.3382  Validation loss = 5.7254  \n",
      "\n",
      "Fold: 13  Epoch: 476  Training loss = 3.3378  Validation loss = 5.7246  \n",
      "\n",
      "Fold: 13  Epoch: 477  Training loss = 3.3375  Validation loss = 5.7239  \n",
      "\n",
      "Fold: 13  Epoch: 478  Training loss = 3.3371  Validation loss = 5.7230  \n",
      "\n",
      "Fold: 13  Epoch: 479  Training loss = 3.3368  Validation loss = 5.7224  \n",
      "\n",
      "Fold: 13  Epoch: 480  Training loss = 3.3364  Validation loss = 5.7217  \n",
      "\n",
      "Fold: 13  Epoch: 481  Training loss = 3.3360  Validation loss = 5.7209  \n",
      "\n",
      "Fold: 13  Epoch: 482  Training loss = 3.3356  Validation loss = 5.7201  \n",
      "\n",
      "Fold: 13  Epoch: 483  Training loss = 3.3353  Validation loss = 5.7194  \n",
      "\n",
      "Fold: 13  Epoch: 484  Training loss = 3.3350  Validation loss = 5.7189  \n",
      "\n",
      "Fold: 13  Epoch: 485  Training loss = 3.3347  Validation loss = 5.7183  \n",
      "\n",
      "Fold: 13  Epoch: 486  Training loss = 3.3343  Validation loss = 5.7176  \n",
      "\n",
      "Fold: 13  Epoch: 487  Training loss = 3.3341  Validation loss = 5.7170  \n",
      "\n",
      "Fold: 13  Epoch: 488  Training loss = 3.3338  Validation loss = 5.7164  \n",
      "\n",
      "Fold: 13  Epoch: 489  Training loss = 3.3335  Validation loss = 5.7159  \n",
      "\n",
      "Fold: 13  Epoch: 490  Training loss = 3.3331  Validation loss = 5.7151  \n",
      "\n",
      "Fold: 13  Epoch: 491  Training loss = 3.3327  Validation loss = 5.7142  \n",
      "\n",
      "Fold: 13  Epoch: 492  Training loss = 3.3324  Validation loss = 5.7136  \n",
      "\n",
      "Fold: 13  Epoch: 493  Training loss = 3.3320  Validation loss = 5.7128  \n",
      "\n",
      "Fold: 13  Epoch: 494  Training loss = 3.3317  Validation loss = 5.7121  \n",
      "\n",
      "Fold: 13  Epoch: 495  Training loss = 3.3312  Validation loss = 5.7112  \n",
      "\n",
      "Fold: 13  Epoch: 496  Training loss = 3.3309  Validation loss = 5.7105  \n",
      "\n",
      "Fold: 13  Epoch: 497  Training loss = 3.3305  Validation loss = 5.7097  \n",
      "\n",
      "Fold: 13  Epoch: 498  Training loss = 3.3301  Validation loss = 5.7089  \n",
      "\n",
      "Fold: 13  Epoch: 499  Training loss = 3.3298  Validation loss = 5.7083  \n",
      "\n",
      "Fold: 13  Epoch: 500  Training loss = 3.3296  Validation loss = 5.7078  \n",
      "\n",
      "Check model:  Fold: 13  Epoch: 500  Training loss = 3.3296  Validation loss = 5.7078  \n",
      "\n",
      "Fold: 14  Epoch: 1  Training loss = 3.5999  Validation loss = 9.2528  \n",
      "\n",
      "Fold: 14  Epoch: 2  Training loss = 3.5994  Validation loss = 9.2519  \n",
      "\n",
      "Fold: 14  Epoch: 3  Training loss = 3.5990  Validation loss = 9.2511  \n",
      "\n",
      "Fold: 14  Epoch: 4  Training loss = 3.5986  Validation loss = 9.2505  \n",
      "\n",
      "Fold: 14  Epoch: 5  Training loss = 3.5982  Validation loss = 9.2495  \n",
      "\n",
      "Fold: 14  Epoch: 6  Training loss = 3.5977  Validation loss = 9.2486  \n",
      "\n",
      "Fold: 14  Epoch: 7  Training loss = 3.5970  Validation loss = 9.2474  \n",
      "\n",
      "Fold: 14  Epoch: 8  Training loss = 3.5966  Validation loss = 9.2465  \n",
      "\n",
      "Fold: 14  Epoch: 9  Training loss = 3.5960  Validation loss = 9.2454  \n",
      "\n",
      "Fold: 14  Epoch: 10  Training loss = 3.5955  Validation loss = 9.2444  \n",
      "\n",
      "Fold: 14  Epoch: 11  Training loss = 3.5950  Validation loss = 9.2434  \n",
      "\n",
      "Fold: 14  Epoch: 12  Training loss = 3.5945  Validation loss = 9.2424  \n",
      "\n",
      "Fold: 14  Epoch: 13  Training loss = 3.5940  Validation loss = 9.2416  \n",
      "\n",
      "Fold: 14  Epoch: 14  Training loss = 3.5936  Validation loss = 9.2407  \n",
      "\n",
      "Fold: 14  Epoch: 15  Training loss = 3.5931  Validation loss = 9.2397  \n",
      "\n",
      "Fold: 14  Epoch: 16  Training loss = 3.5927  Validation loss = 9.2390  \n",
      "\n",
      "Fold: 14  Epoch: 17  Training loss = 3.5923  Validation loss = 9.2383  \n",
      "\n",
      "Fold: 14  Epoch: 18  Training loss = 3.5918  Validation loss = 9.2374  \n",
      "\n",
      "Fold: 14  Epoch: 19  Training loss = 3.5912  Validation loss = 9.2362  \n",
      "\n",
      "Fold: 14  Epoch: 20  Training loss = 3.5907  Validation loss = 9.2353  \n",
      "\n",
      "Fold: 14  Epoch: 21  Training loss = 3.5903  Validation loss = 9.2345  \n",
      "\n",
      "Fold: 14  Epoch: 22  Training loss = 3.5898  Validation loss = 9.2335  \n",
      "\n",
      "Fold: 14  Epoch: 23  Training loss = 3.5892  Validation loss = 9.2323  \n",
      "\n",
      "Fold: 14  Epoch: 24  Training loss = 3.5888  Validation loss = 9.2315  \n",
      "\n",
      "Fold: 14  Epoch: 25  Training loss = 3.5883  Validation loss = 9.2306  \n",
      "\n",
      "Fold: 14  Epoch: 26  Training loss = 3.5878  Validation loss = 9.2297  \n",
      "\n",
      "Fold: 14  Epoch: 27  Training loss = 3.5872  Validation loss = 9.2286  \n",
      "\n",
      "Fold: 14  Epoch: 28  Training loss = 3.5868  Validation loss = 9.2277  \n",
      "\n",
      "Fold: 14  Epoch: 29  Training loss = 3.5862  Validation loss = 9.2266  \n",
      "\n",
      "Fold: 14  Epoch: 30  Training loss = 3.5856  Validation loss = 9.2255  \n",
      "\n",
      "Fold: 14  Epoch: 31  Training loss = 3.5851  Validation loss = 9.2245  \n",
      "\n",
      "Fold: 14  Epoch: 32  Training loss = 3.5845  Validation loss = 9.2234  \n",
      "\n",
      "Fold: 14  Epoch: 33  Training loss = 3.5840  Validation loss = 9.2224  \n",
      "\n",
      "Fold: 14  Epoch: 34  Training loss = 3.5837  Validation loss = 9.2219  \n",
      "\n",
      "Fold: 14  Epoch: 35  Training loss = 3.5832  Validation loss = 9.2208  \n",
      "\n",
      "Fold: 14  Epoch: 36  Training loss = 3.5825  Validation loss = 9.2194  \n",
      "\n",
      "Fold: 14  Epoch: 37  Training loss = 3.5819  Validation loss = 9.2184  \n",
      "\n",
      "Fold: 14  Epoch: 38  Training loss = 3.5815  Validation loss = 9.2176  \n",
      "\n",
      "Fold: 14  Epoch: 39  Training loss = 3.5811  Validation loss = 9.2168  \n",
      "\n",
      "Fold: 14  Epoch: 40  Training loss = 3.5805  Validation loss = 9.2157  \n",
      "\n",
      "Fold: 14  Epoch: 41  Training loss = 3.5801  Validation loss = 9.2148  \n",
      "\n",
      "Fold: 14  Epoch: 42  Training loss = 3.5796  Validation loss = 9.2138  \n",
      "\n",
      "Fold: 14  Epoch: 43  Training loss = 3.5790  Validation loss = 9.2128  \n",
      "\n",
      "Fold: 14  Epoch: 44  Training loss = 3.5785  Validation loss = 9.2117  \n",
      "\n",
      "Fold: 14  Epoch: 45  Training loss = 3.5781  Validation loss = 9.2109  \n",
      "\n",
      "Fold: 14  Epoch: 46  Training loss = 3.5776  Validation loss = 9.2101  \n",
      "\n",
      "Fold: 14  Epoch: 47  Training loss = 3.5772  Validation loss = 9.2093  \n",
      "\n",
      "Fold: 14  Epoch: 48  Training loss = 3.5768  Validation loss = 9.2085  \n",
      "\n",
      "Fold: 14  Epoch: 49  Training loss = 3.5764  Validation loss = 9.2077  \n",
      "\n",
      "Fold: 14  Epoch: 50  Training loss = 3.5758  Validation loss = 9.2065  \n",
      "\n",
      "Fold: 14  Epoch: 51  Training loss = 3.5753  Validation loss = 9.2056  \n",
      "\n",
      "Fold: 14  Epoch: 52  Training loss = 3.5747  Validation loss = 9.2043  \n",
      "\n",
      "Fold: 14  Epoch: 53  Training loss = 3.5743  Validation loss = 9.2036  \n",
      "\n",
      "Fold: 14  Epoch: 54  Training loss = 3.5738  Validation loss = 9.2028  \n",
      "\n",
      "Fold: 14  Epoch: 55  Training loss = 3.5733  Validation loss = 9.2017  \n",
      "\n",
      "Fold: 14  Epoch: 56  Training loss = 3.5728  Validation loss = 9.2007  \n",
      "\n",
      "Fold: 14  Epoch: 57  Training loss = 3.5722  Validation loss = 9.1997  \n",
      "\n",
      "Fold: 14  Epoch: 58  Training loss = 3.5719  Validation loss = 9.1990  \n",
      "\n",
      "Fold: 14  Epoch: 59  Training loss = 3.5713  Validation loss = 9.1979  \n",
      "\n",
      "Fold: 14  Epoch: 60  Training loss = 3.5709  Validation loss = 9.1970  \n",
      "\n",
      "Fold: 14  Epoch: 61  Training loss = 3.5704  Validation loss = 9.1960  \n",
      "\n",
      "Fold: 14  Epoch: 62  Training loss = 3.5699  Validation loss = 9.1951  \n",
      "\n",
      "Fold: 14  Epoch: 63  Training loss = 3.5695  Validation loss = 9.1944  \n",
      "\n",
      "Fold: 14  Epoch: 64  Training loss = 3.5689  Validation loss = 9.1933  \n",
      "\n",
      "Fold: 14  Epoch: 65  Training loss = 3.5685  Validation loss = 9.1925  \n",
      "\n",
      "Fold: 14  Epoch: 66  Training loss = 3.5680  Validation loss = 9.1915  \n",
      "\n",
      "Fold: 14  Epoch: 67  Training loss = 3.5676  Validation loss = 9.1907  \n",
      "\n",
      "Fold: 14  Epoch: 68  Training loss = 3.5672  Validation loss = 9.1899  \n",
      "\n",
      "Fold: 14  Epoch: 69  Training loss = 3.5667  Validation loss = 9.1890  \n",
      "\n",
      "Fold: 14  Epoch: 70  Training loss = 3.5663  Validation loss = 9.1882  \n",
      "\n",
      "Fold: 14  Epoch: 71  Training loss = 3.5657  Validation loss = 9.1871  \n",
      "\n",
      "Fold: 14  Epoch: 72  Training loss = 3.5652  Validation loss = 9.1860  \n",
      "\n",
      "Fold: 14  Epoch: 73  Training loss = 3.5647  Validation loss = 9.1852  \n",
      "\n",
      "Fold: 14  Epoch: 74  Training loss = 3.5643  Validation loss = 9.1844  \n",
      "\n",
      "Fold: 14  Epoch: 75  Training loss = 3.5639  Validation loss = 9.1835  \n",
      "\n",
      "Fold: 14  Epoch: 76  Training loss = 3.5634  Validation loss = 9.1826  \n",
      "\n",
      "Fold: 14  Epoch: 77  Training loss = 3.5630  Validation loss = 9.1818  \n",
      "\n",
      "Fold: 14  Epoch: 78  Training loss = 3.5624  Validation loss = 9.1807  \n",
      "\n",
      "Fold: 14  Epoch: 79  Training loss = 3.5621  Validation loss = 9.1801  \n",
      "\n",
      "Fold: 14  Epoch: 80  Training loss = 3.5615  Validation loss = 9.1790  \n",
      "\n",
      "Fold: 14  Epoch: 81  Training loss = 3.5611  Validation loss = 9.1781  \n",
      "\n",
      "Fold: 14  Epoch: 82  Training loss = 3.5605  Validation loss = 9.1770  \n",
      "\n",
      "Fold: 14  Epoch: 83  Training loss = 3.5601  Validation loss = 9.1763  \n",
      "\n",
      "Fold: 14  Epoch: 84  Training loss = 3.5597  Validation loss = 9.1753  \n",
      "\n",
      "Fold: 14  Epoch: 85  Training loss = 3.5593  Validation loss = 9.1746  \n",
      "\n",
      "Fold: 14  Epoch: 86  Training loss = 3.5587  Validation loss = 9.1735  \n",
      "\n",
      "Fold: 14  Epoch: 87  Training loss = 3.5582  Validation loss = 9.1724  \n",
      "\n",
      "Fold: 14  Epoch: 88  Training loss = 3.5577  Validation loss = 9.1715  \n",
      "\n",
      "Fold: 14  Epoch: 89  Training loss = 3.5572  Validation loss = 9.1706  \n",
      "\n",
      "Fold: 14  Epoch: 90  Training loss = 3.5568  Validation loss = 9.1699  \n",
      "\n",
      "Fold: 14  Epoch: 91  Training loss = 3.5562  Validation loss = 9.1687  \n",
      "\n",
      "Fold: 14  Epoch: 92  Training loss = 3.5558  Validation loss = 9.1678  \n",
      "\n",
      "Fold: 14  Epoch: 93  Training loss = 3.5552  Validation loss = 9.1667  \n",
      "\n",
      "Fold: 14  Epoch: 94  Training loss = 3.5547  Validation loss = 9.1658  \n",
      "\n",
      "Fold: 14  Epoch: 95  Training loss = 3.5541  Validation loss = 9.1646  \n",
      "\n",
      "Fold: 14  Epoch: 96  Training loss = 3.5536  Validation loss = 9.1635  \n",
      "\n",
      "Fold: 14  Epoch: 97  Training loss = 3.5530  Validation loss = 9.1625  \n",
      "\n",
      "Fold: 14  Epoch: 98  Training loss = 3.5526  Validation loss = 9.1616  \n",
      "\n",
      "Fold: 14  Epoch: 99  Training loss = 3.5520  Validation loss = 9.1605  \n",
      "\n",
      "Fold: 14  Epoch: 100  Training loss = 3.5516  Validation loss = 9.1597  \n",
      "\n",
      "Fold: 14  Epoch: 101  Training loss = 3.5511  Validation loss = 9.1587  \n",
      "\n",
      "Fold: 14  Epoch: 102  Training loss = 3.5507  Validation loss = 9.1580  \n",
      "\n",
      "Fold: 14  Epoch: 103  Training loss = 3.5502  Validation loss = 9.1571  \n",
      "\n",
      "Fold: 14  Epoch: 104  Training loss = 3.5499  Validation loss = 9.1563  \n",
      "\n",
      "Fold: 14  Epoch: 105  Training loss = 3.5494  Validation loss = 9.1554  \n",
      "\n",
      "Fold: 14  Epoch: 106  Training loss = 3.5490  Validation loss = 9.1545  \n",
      "\n",
      "Fold: 14  Epoch: 107  Training loss = 3.5486  Validation loss = 9.1538  \n",
      "\n",
      "Fold: 14  Epoch: 108  Training loss = 3.5481  Validation loss = 9.1528  \n",
      "\n",
      "Fold: 14  Epoch: 109  Training loss = 3.5475  Validation loss = 9.1516  \n",
      "\n",
      "Fold: 14  Epoch: 110  Training loss = 3.5471  Validation loss = 9.1510  \n",
      "\n",
      "Fold: 14  Epoch: 111  Training loss = 3.5467  Validation loss = 9.1501  \n",
      "\n",
      "Fold: 14  Epoch: 112  Training loss = 3.5462  Validation loss = 9.1492  \n",
      "\n",
      "Fold: 14  Epoch: 113  Training loss = 3.5457  Validation loss = 9.1482  \n",
      "\n",
      "Fold: 14  Epoch: 114  Training loss = 3.5451  Validation loss = 9.1471  \n",
      "\n",
      "Fold: 14  Epoch: 115  Training loss = 3.5448  Validation loss = 9.1463  \n",
      "\n",
      "Fold: 14  Epoch: 116  Training loss = 3.5443  Validation loss = 9.1455  \n",
      "\n",
      "Fold: 14  Epoch: 117  Training loss = 3.5440  Validation loss = 9.1449  \n",
      "\n",
      "Fold: 14  Epoch: 118  Training loss = 3.5434  Validation loss = 9.1436  \n",
      "\n",
      "Fold: 14  Epoch: 119  Training loss = 3.5429  Validation loss = 9.1428  \n",
      "\n",
      "Fold: 14  Epoch: 120  Training loss = 3.5425  Validation loss = 9.1420  \n",
      "\n",
      "Fold: 14  Epoch: 121  Training loss = 3.5421  Validation loss = 9.1412  \n",
      "\n",
      "Fold: 14  Epoch: 122  Training loss = 3.5416  Validation loss = 9.1402  \n",
      "\n",
      "Fold: 14  Epoch: 123  Training loss = 3.5412  Validation loss = 9.1394  \n",
      "\n",
      "Fold: 14  Epoch: 124  Training loss = 3.5407  Validation loss = 9.1384  \n",
      "\n",
      "Fold: 14  Epoch: 125  Training loss = 3.5403  Validation loss = 9.1375  \n",
      "\n",
      "Fold: 14  Epoch: 126  Training loss = 3.5398  Validation loss = 9.1367  \n",
      "\n",
      "Fold: 14  Epoch: 127  Training loss = 3.5394  Validation loss = 9.1358  \n",
      "\n",
      "Fold: 14  Epoch: 128  Training loss = 3.5388  Validation loss = 9.1348  \n",
      "\n",
      "Fold: 14  Epoch: 129  Training loss = 3.5383  Validation loss = 9.1337  \n",
      "\n",
      "Fold: 14  Epoch: 130  Training loss = 3.5378  Validation loss = 9.1328  \n",
      "\n",
      "Fold: 14  Epoch: 131  Training loss = 3.5375  Validation loss = 9.1321  \n",
      "\n",
      "Fold: 14  Epoch: 132  Training loss = 3.5370  Validation loss = 9.1312  \n",
      "\n",
      "Fold: 14  Epoch: 133  Training loss = 3.5366  Validation loss = 9.1304  \n",
      "\n",
      "Fold: 14  Epoch: 134  Training loss = 3.5360  Validation loss = 9.1293  \n",
      "\n",
      "Fold: 14  Epoch: 135  Training loss = 3.5355  Validation loss = 9.1281  \n",
      "\n",
      "Fold: 14  Epoch: 136  Training loss = 3.5351  Validation loss = 9.1275  \n",
      "\n",
      "Fold: 14  Epoch: 137  Training loss = 3.5348  Validation loss = 9.1269  \n",
      "\n",
      "Fold: 14  Epoch: 138  Training loss = 3.5344  Validation loss = 9.1260  \n",
      "\n",
      "Fold: 14  Epoch: 139  Training loss = 3.5340  Validation loss = 9.1252  \n",
      "\n",
      "Fold: 14  Epoch: 140  Training loss = 3.5336  Validation loss = 9.1245  \n",
      "\n",
      "Fold: 14  Epoch: 141  Training loss = 3.5331  Validation loss = 9.1236  \n",
      "\n",
      "Fold: 14  Epoch: 142  Training loss = 3.5326  Validation loss = 9.1226  \n",
      "\n",
      "Fold: 14  Epoch: 143  Training loss = 3.5321  Validation loss = 9.1216  \n",
      "\n",
      "Fold: 14  Epoch: 144  Training loss = 3.5317  Validation loss = 9.1207  \n",
      "\n",
      "Fold: 14  Epoch: 145  Training loss = 3.5312  Validation loss = 9.1198  \n",
      "\n",
      "Fold: 14  Epoch: 146  Training loss = 3.5305  Validation loss = 9.1185  \n",
      "\n",
      "Fold: 14  Epoch: 147  Training loss = 3.5301  Validation loss = 9.1176  \n",
      "\n",
      "Fold: 14  Epoch: 148  Training loss = 3.5297  Validation loss = 9.1168  \n",
      "\n",
      "Fold: 14  Epoch: 149  Training loss = 3.5293  Validation loss = 9.1161  \n",
      "\n",
      "Fold: 14  Epoch: 150  Training loss = 3.5289  Validation loss = 9.1152  \n",
      "\n",
      "Fold: 14  Epoch: 151  Training loss = 3.5285  Validation loss = 9.1145  \n",
      "\n",
      "Fold: 14  Epoch: 152  Training loss = 3.5280  Validation loss = 9.1135  \n",
      "\n",
      "Fold: 14  Epoch: 153  Training loss = 3.5276  Validation loss = 9.1127  \n",
      "\n",
      "Fold: 14  Epoch: 154  Training loss = 3.5271  Validation loss = 9.1117  \n",
      "\n",
      "Fold: 14  Epoch: 155  Training loss = 3.5267  Validation loss = 9.1109  \n",
      "\n",
      "Fold: 14  Epoch: 156  Training loss = 3.5262  Validation loss = 9.1100  \n",
      "\n",
      "Fold: 14  Epoch: 157  Training loss = 3.5258  Validation loss = 9.1092  \n",
      "\n",
      "Fold: 14  Epoch: 158  Training loss = 3.5255  Validation loss = 9.1085  \n",
      "\n",
      "Fold: 14  Epoch: 159  Training loss = 3.5251  Validation loss = 9.1078  \n",
      "\n",
      "Fold: 14  Epoch: 160  Training loss = 3.5247  Validation loss = 9.1070  \n",
      "\n",
      "Fold: 14  Epoch: 161  Training loss = 3.5243  Validation loss = 9.1061  \n",
      "\n",
      "Fold: 14  Epoch: 162  Training loss = 3.5238  Validation loss = 9.1052  \n",
      "\n",
      "Fold: 14  Epoch: 163  Training loss = 3.5234  Validation loss = 9.1045  \n",
      "\n",
      "Fold: 14  Epoch: 164  Training loss = 3.5228  Validation loss = 9.1033  \n",
      "\n",
      "Fold: 14  Epoch: 165  Training loss = 3.5224  Validation loss = 9.1025  \n",
      "\n",
      "Fold: 14  Epoch: 166  Training loss = 3.5220  Validation loss = 9.1017  \n",
      "\n",
      "Fold: 14  Epoch: 167  Training loss = 3.5215  Validation loss = 9.1008  \n",
      "\n",
      "Fold: 14  Epoch: 168  Training loss = 3.5209  Validation loss = 9.0997  \n",
      "\n",
      "Fold: 14  Epoch: 169  Training loss = 3.5205  Validation loss = 9.0988  \n",
      "\n",
      "Fold: 14  Epoch: 170  Training loss = 3.5201  Validation loss = 9.0980  \n",
      "\n",
      "Fold: 14  Epoch: 171  Training loss = 3.5198  Validation loss = 9.0973  \n",
      "\n",
      "Fold: 14  Epoch: 172  Training loss = 3.5193  Validation loss = 9.0964  \n",
      "\n",
      "Fold: 14  Epoch: 173  Training loss = 3.5189  Validation loss = 9.0957  \n",
      "\n",
      "Fold: 14  Epoch: 174  Training loss = 3.5185  Validation loss = 9.0949  \n",
      "\n",
      "Fold: 14  Epoch: 175  Training loss = 3.5182  Validation loss = 9.0942  \n",
      "\n",
      "Fold: 14  Epoch: 176  Training loss = 3.5176  Validation loss = 9.0931  \n",
      "\n",
      "Fold: 14  Epoch: 177  Training loss = 3.5172  Validation loss = 9.0923  \n",
      "\n",
      "Fold: 14  Epoch: 178  Training loss = 3.5168  Validation loss = 9.0915  \n",
      "\n",
      "Fold: 14  Epoch: 179  Training loss = 3.5164  Validation loss = 9.0908  \n",
      "\n",
      "Fold: 14  Epoch: 180  Training loss = 3.5160  Validation loss = 9.0900  \n",
      "\n",
      "Fold: 14  Epoch: 181  Training loss = 3.5155  Validation loss = 9.0889  \n",
      "\n",
      "Fold: 14  Epoch: 182  Training loss = 3.5150  Validation loss = 9.0879  \n",
      "\n",
      "Fold: 14  Epoch: 183  Training loss = 3.5145  Validation loss = 9.0868  \n",
      "\n",
      "Fold: 14  Epoch: 184  Training loss = 3.5139  Validation loss = 9.0857  \n",
      "\n",
      "Fold: 14  Epoch: 185  Training loss = 3.5135  Validation loss = 9.0850  \n",
      "\n",
      "Fold: 14  Epoch: 186  Training loss = 3.5129  Validation loss = 9.0838  \n",
      "\n",
      "Fold: 14  Epoch: 187  Training loss = 3.5124  Validation loss = 9.0828  \n",
      "\n",
      "Fold: 14  Epoch: 188  Training loss = 3.5119  Validation loss = 9.0819  \n",
      "\n",
      "Fold: 14  Epoch: 189  Training loss = 3.5114  Validation loss = 9.0809  \n",
      "\n",
      "Fold: 14  Epoch: 190  Training loss = 3.5110  Validation loss = 9.0801  \n",
      "\n",
      "Fold: 14  Epoch: 191  Training loss = 3.5106  Validation loss = 9.0793  \n",
      "\n",
      "Fold: 14  Epoch: 192  Training loss = 3.5102  Validation loss = 9.0786  \n",
      "\n",
      "Fold: 14  Epoch: 193  Training loss = 3.5097  Validation loss = 9.0775  \n",
      "\n",
      "Fold: 14  Epoch: 194  Training loss = 3.5092  Validation loss = 9.0766  \n",
      "\n",
      "Fold: 14  Epoch: 195  Training loss = 3.5087  Validation loss = 9.0756  \n",
      "\n",
      "Fold: 14  Epoch: 196  Training loss = 3.5083  Validation loss = 9.0749  \n",
      "\n",
      "Fold: 14  Epoch: 197  Training loss = 3.5079  Validation loss = 9.0739  \n",
      "\n",
      "Fold: 14  Epoch: 198  Training loss = 3.5074  Validation loss = 9.0731  \n",
      "\n",
      "Fold: 14  Epoch: 199  Training loss = 3.5070  Validation loss = 9.0723  \n",
      "\n",
      "Fold: 14  Epoch: 200  Training loss = 3.5065  Validation loss = 9.0712  \n",
      "\n",
      "Fold: 14  Epoch: 201  Training loss = 3.5060  Validation loss = 9.0703  \n",
      "\n",
      "Fold: 14  Epoch: 202  Training loss = 3.5056  Validation loss = 9.0694  \n",
      "\n",
      "Fold: 14  Epoch: 203  Training loss = 3.5051  Validation loss = 9.0684  \n",
      "\n",
      "Fold: 14  Epoch: 204  Training loss = 3.5047  Validation loss = 9.0677  \n",
      "\n",
      "Fold: 14  Epoch: 205  Training loss = 3.5041  Validation loss = 9.0666  \n",
      "\n",
      "Fold: 14  Epoch: 206  Training loss = 3.5038  Validation loss = 9.0660  \n",
      "\n",
      "Fold: 14  Epoch: 207  Training loss = 3.5033  Validation loss = 9.0651  \n",
      "\n",
      "Fold: 14  Epoch: 208  Training loss = 3.5028  Validation loss = 9.0641  \n",
      "\n",
      "Fold: 14  Epoch: 209  Training loss = 3.5024  Validation loss = 9.0633  \n",
      "\n",
      "Fold: 14  Epoch: 210  Training loss = 3.5018  Validation loss = 9.0624  \n",
      "\n",
      "Fold: 14  Epoch: 211  Training loss = 3.5013  Validation loss = 9.0614  \n",
      "\n",
      "Fold: 14  Epoch: 212  Training loss = 3.5006  Validation loss = 9.0603  \n",
      "\n",
      "Fold: 14  Epoch: 213  Training loss = 3.5001  Validation loss = 9.0594  \n",
      "\n",
      "Fold: 14  Epoch: 214  Training loss = 3.4993  Validation loss = 9.0582  \n",
      "\n",
      "Fold: 14  Epoch: 215  Training loss = 3.4988  Validation loss = 9.0574  \n",
      "\n",
      "Fold: 14  Epoch: 216  Training loss = 3.4978  Validation loss = 9.0564  \n",
      "\n",
      "Fold: 14  Epoch: 217  Training loss = 3.4971  Validation loss = 9.0554  \n",
      "\n",
      "Fold: 14  Epoch: 218  Training loss = 3.4967  Validation loss = 9.0547  \n",
      "\n",
      "Fold: 14  Epoch: 219  Training loss = 3.4961  Validation loss = 9.0542  \n",
      "\n",
      "Fold: 14  Epoch: 220  Training loss = 3.4956  Validation loss = 9.0533  \n",
      "\n",
      "Fold: 14  Epoch: 221  Training loss = 3.4950  Validation loss = 9.0523  \n",
      "\n",
      "Fold: 14  Epoch: 222  Training loss = 3.4945  Validation loss = 9.0515  \n",
      "\n",
      "Fold: 14  Epoch: 223  Training loss = 3.4941  Validation loss = 9.0507  \n",
      "\n",
      "Fold: 14  Epoch: 224  Training loss = 3.4936  Validation loss = 9.0499  \n",
      "\n",
      "Fold: 14  Epoch: 225  Training loss = 3.4932  Validation loss = 9.0491  \n",
      "\n",
      "Fold: 14  Epoch: 226  Training loss = 3.4929  Validation loss = 9.0484  \n",
      "\n",
      "Fold: 14  Epoch: 227  Training loss = 3.4924  Validation loss = 9.0475  \n",
      "\n",
      "Fold: 14  Epoch: 228  Training loss = 3.4919  Validation loss = 9.0465  \n",
      "\n",
      "Fold: 14  Epoch: 229  Training loss = 3.4914  Validation loss = 9.0455  \n",
      "\n",
      "Fold: 14  Epoch: 230  Training loss = 3.4909  Validation loss = 9.0446  \n",
      "\n",
      "Fold: 14  Epoch: 231  Training loss = 3.4905  Validation loss = 9.0438  \n",
      "\n",
      "Fold: 14  Epoch: 232  Training loss = 3.4902  Validation loss = 9.0431  \n",
      "\n",
      "Fold: 14  Epoch: 233  Training loss = 3.4897  Validation loss = 9.0422  \n",
      "\n",
      "Fold: 14  Epoch: 234  Training loss = 3.4892  Validation loss = 9.0412  \n",
      "\n",
      "Fold: 14  Epoch: 235  Training loss = 3.4888  Validation loss = 9.0403  \n",
      "\n",
      "Fold: 14  Epoch: 236  Training loss = 3.4883  Validation loss = 9.0394  \n",
      "\n",
      "Fold: 14  Epoch: 237  Training loss = 3.4879  Validation loss = 9.0387  \n",
      "\n",
      "Fold: 14  Epoch: 238  Training loss = 3.4876  Validation loss = 9.0380  \n",
      "\n",
      "Fold: 14  Epoch: 239  Training loss = 3.4872  Validation loss = 9.0372  \n",
      "\n",
      "Fold: 14  Epoch: 240  Training loss = 3.4867  Validation loss = 9.0363  \n",
      "\n",
      "Fold: 14  Epoch: 241  Training loss = 3.4862  Validation loss = 9.0352  \n",
      "\n",
      "Fold: 14  Epoch: 242  Training loss = 3.4857  Validation loss = 9.0342  \n",
      "\n",
      "Fold: 14  Epoch: 243  Training loss = 3.4852  Validation loss = 9.0333  \n",
      "\n",
      "Fold: 14  Epoch: 244  Training loss = 3.4848  Validation loss = 9.0323  \n",
      "\n",
      "Fold: 14  Epoch: 245  Training loss = 3.4841  Validation loss = 9.0311  \n",
      "\n",
      "Fold: 14  Epoch: 246  Training loss = 3.4838  Validation loss = 9.0304  \n",
      "\n",
      "Fold: 14  Epoch: 247  Training loss = 3.4834  Validation loss = 9.0295  \n",
      "\n",
      "Fold: 14  Epoch: 248  Training loss = 3.4827  Validation loss = 9.0283  \n",
      "\n",
      "Fold: 14  Epoch: 249  Training loss = 3.4823  Validation loss = 9.0275  \n",
      "\n",
      "Fold: 14  Epoch: 250  Training loss = 3.4820  Validation loss = 9.0268  \n",
      "\n",
      "Fold: 14  Epoch: 251  Training loss = 3.4816  Validation loss = 9.0259  \n",
      "\n",
      "Fold: 14  Epoch: 252  Training loss = 3.4811  Validation loss = 9.0251  \n",
      "\n",
      "Fold: 14  Epoch: 253  Training loss = 3.4807  Validation loss = 9.0242  \n",
      "\n",
      "Fold: 14  Epoch: 254  Training loss = 3.4802  Validation loss = 9.0233  \n",
      "\n",
      "Fold: 14  Epoch: 255  Training loss = 3.4798  Validation loss = 9.0224  \n",
      "\n",
      "Fold: 14  Epoch: 256  Training loss = 3.4793  Validation loss = 9.0215  \n",
      "\n",
      "Fold: 14  Epoch: 257  Training loss = 3.4789  Validation loss = 9.0206  \n",
      "\n",
      "Fold: 14  Epoch: 258  Training loss = 3.4784  Validation loss = 9.0197  \n",
      "\n",
      "Fold: 14  Epoch: 259  Training loss = 3.4778  Validation loss = 9.0185  \n",
      "\n",
      "Fold: 14  Epoch: 260  Training loss = 3.4774  Validation loss = 9.0175  \n",
      "\n",
      "Fold: 14  Epoch: 261  Training loss = 3.4768  Validation loss = 9.0165  \n",
      "\n",
      "Fold: 14  Epoch: 262  Training loss = 3.4763  Validation loss = 9.0154  \n",
      "\n",
      "Fold: 14  Epoch: 263  Training loss = 3.4757  Validation loss = 9.0142  \n",
      "\n",
      "Fold: 14  Epoch: 264  Training loss = 3.4752  Validation loss = 9.0132  \n",
      "\n",
      "Fold: 14  Epoch: 265  Training loss = 3.4748  Validation loss = 9.0123  \n",
      "\n",
      "Fold: 14  Epoch: 266  Training loss = 3.4743  Validation loss = 9.0115  \n",
      "\n",
      "Fold: 14  Epoch: 267  Training loss = 3.4739  Validation loss = 9.0106  \n",
      "\n",
      "Fold: 14  Epoch: 268  Training loss = 3.4733  Validation loss = 9.0094  \n",
      "\n",
      "Fold: 14  Epoch: 269  Training loss = 3.4730  Validation loss = 9.0088  \n",
      "\n",
      "Fold: 14  Epoch: 270  Training loss = 3.4726  Validation loss = 9.0080  \n",
      "\n",
      "Fold: 14  Epoch: 271  Training loss = 3.4722  Validation loss = 9.0072  \n",
      "\n",
      "Fold: 14  Epoch: 272  Training loss = 3.4718  Validation loss = 9.0064  \n",
      "\n",
      "Fold: 14  Epoch: 273  Training loss = 3.4712  Validation loss = 9.0052  \n",
      "\n",
      "Fold: 14  Epoch: 274  Training loss = 3.4706  Validation loss = 9.0039  \n",
      "\n",
      "Fold: 14  Epoch: 275  Training loss = 3.4700  Validation loss = 9.0029  \n",
      "\n",
      "Fold: 14  Epoch: 276  Training loss = 3.4696  Validation loss = 9.0020  \n",
      "\n",
      "Fold: 14  Epoch: 277  Training loss = 3.4691  Validation loss = 9.0010  \n",
      "\n",
      "Fold: 14  Epoch: 278  Training loss = 3.4687  Validation loss = 9.0001  \n",
      "\n",
      "Fold: 14  Epoch: 279  Training loss = 3.4682  Validation loss = 8.9992  \n",
      "\n",
      "Fold: 14  Epoch: 280  Training loss = 3.4677  Validation loss = 8.9983  \n",
      "\n",
      "Fold: 14  Epoch: 281  Training loss = 3.4674  Validation loss = 8.9975  \n",
      "\n",
      "Fold: 14  Epoch: 282  Training loss = 3.4669  Validation loss = 8.9966  \n",
      "\n",
      "Fold: 14  Epoch: 283  Training loss = 3.4665  Validation loss = 8.9957  \n",
      "\n",
      "Fold: 14  Epoch: 284  Training loss = 3.4660  Validation loss = 8.9948  \n",
      "\n",
      "Fold: 14  Epoch: 285  Training loss = 3.4656  Validation loss = 8.9939  \n",
      "\n",
      "Fold: 14  Epoch: 286  Training loss = 3.4651  Validation loss = 8.9930  \n",
      "\n",
      "Fold: 14  Epoch: 287  Training loss = 3.4647  Validation loss = 8.9921  \n",
      "\n",
      "Fold: 14  Epoch: 288  Training loss = 3.4643  Validation loss = 8.9913  \n",
      "\n",
      "Fold: 14  Epoch: 289  Training loss = 3.4638  Validation loss = 8.9904  \n",
      "\n",
      "Fold: 14  Epoch: 290  Training loss = 3.4634  Validation loss = 8.9894  \n",
      "\n",
      "Fold: 14  Epoch: 291  Training loss = 3.4630  Validation loss = 8.9887  \n",
      "\n",
      "Fold: 14  Epoch: 292  Training loss = 3.4625  Validation loss = 8.9877  \n",
      "\n",
      "Fold: 14  Epoch: 293  Training loss = 3.4621  Validation loss = 8.9868  \n",
      "\n",
      "Fold: 14  Epoch: 294  Training loss = 3.4616  Validation loss = 8.9858  \n",
      "\n",
      "Fold: 14  Epoch: 295  Training loss = 3.4612  Validation loss = 8.9850  \n",
      "\n",
      "Fold: 14  Epoch: 296  Training loss = 3.4607  Validation loss = 8.9840  \n",
      "\n",
      "Fold: 14  Epoch: 297  Training loss = 3.4601  Validation loss = 8.9828  \n",
      "\n",
      "Fold: 14  Epoch: 298  Training loss = 3.4596  Validation loss = 8.9817  \n",
      "\n",
      "Fold: 14  Epoch: 299  Training loss = 3.4591  Validation loss = 8.9808  \n",
      "\n",
      "Fold: 14  Epoch: 300  Training loss = 3.4587  Validation loss = 8.9800  \n",
      "\n",
      "Fold: 14  Epoch: 301  Training loss = 3.4582  Validation loss = 8.9789  \n",
      "\n",
      "Fold: 14  Epoch: 302  Training loss = 3.4577  Validation loss = 8.9780  \n",
      "\n",
      "Fold: 14  Epoch: 303  Training loss = 3.4573  Validation loss = 8.9771  \n",
      "\n",
      "Fold: 14  Epoch: 304  Training loss = 3.4568  Validation loss = 8.9760  \n",
      "\n",
      "Fold: 14  Epoch: 305  Training loss = 3.4563  Validation loss = 8.9750  \n",
      "\n",
      "Fold: 14  Epoch: 306  Training loss = 3.4558  Validation loss = 8.9741  \n",
      "\n",
      "Fold: 14  Epoch: 307  Training loss = 3.4554  Validation loss = 8.9732  \n",
      "\n",
      "Fold: 14  Epoch: 308  Training loss = 3.4549  Validation loss = 8.9722  \n",
      "\n",
      "Fold: 14  Epoch: 309  Training loss = 3.4544  Validation loss = 8.9713  \n",
      "\n",
      "Fold: 14  Epoch: 310  Training loss = 3.4540  Validation loss = 8.9705  \n",
      "\n",
      "Fold: 14  Epoch: 311  Training loss = 3.4536  Validation loss = 8.9696  \n",
      "\n",
      "Fold: 14  Epoch: 312  Training loss = 3.4531  Validation loss = 8.9687  \n",
      "\n",
      "Fold: 14  Epoch: 313  Training loss = 3.4526  Validation loss = 8.9676  \n",
      "\n",
      "Fold: 14  Epoch: 314  Training loss = 3.4522  Validation loss = 8.9669  \n",
      "\n",
      "Fold: 14  Epoch: 315  Training loss = 3.4518  Validation loss = 8.9659  \n",
      "\n",
      "Fold: 14  Epoch: 316  Training loss = 3.4515  Validation loss = 8.9653  \n",
      "\n",
      "Fold: 14  Epoch: 317  Training loss = 3.4511  Validation loss = 8.9646  \n",
      "\n",
      "Fold: 14  Epoch: 318  Training loss = 3.4506  Validation loss = 8.9636  \n",
      "\n",
      "Fold: 14  Epoch: 319  Training loss = 3.4502  Validation loss = 8.9627  \n",
      "\n",
      "Fold: 14  Epoch: 320  Training loss = 3.4497  Validation loss = 8.9617  \n",
      "\n",
      "Fold: 14  Epoch: 321  Training loss = 3.4491  Validation loss = 8.9605  \n",
      "\n",
      "Fold: 14  Epoch: 322  Training loss = 3.4487  Validation loss = 8.9596  \n",
      "\n",
      "Fold: 14  Epoch: 323  Training loss = 3.4482  Validation loss = 8.9586  \n",
      "\n",
      "Fold: 14  Epoch: 324  Training loss = 3.4478  Validation loss = 8.9577  \n",
      "\n",
      "Fold: 14  Epoch: 325  Training loss = 3.4474  Validation loss = 8.9570  \n",
      "\n",
      "Fold: 14  Epoch: 326  Training loss = 3.4469  Validation loss = 8.9560  \n",
      "\n",
      "Fold: 14  Epoch: 327  Training loss = 3.4465  Validation loss = 8.9552  \n",
      "\n",
      "Fold: 14  Epoch: 328  Training loss = 3.4461  Validation loss = 8.9543  \n",
      "\n",
      "Fold: 14  Epoch: 329  Training loss = 3.4456  Validation loss = 8.9533  \n",
      "\n",
      "Fold: 14  Epoch: 330  Training loss = 3.4452  Validation loss = 8.9526  \n",
      "\n",
      "Fold: 14  Epoch: 331  Training loss = 3.4448  Validation loss = 8.9517  \n",
      "\n",
      "Fold: 14  Epoch: 332  Training loss = 3.4444  Validation loss = 8.9509  \n",
      "\n",
      "Fold: 14  Epoch: 333  Training loss = 3.4440  Validation loss = 8.9500  \n",
      "\n",
      "Fold: 14  Epoch: 334  Training loss = 3.4435  Validation loss = 8.9491  \n",
      "\n",
      "Fold: 14  Epoch: 335  Training loss = 3.4431  Validation loss = 8.9483  \n",
      "\n",
      "Fold: 14  Epoch: 336  Training loss = 3.4427  Validation loss = 8.9474  \n",
      "\n",
      "Fold: 14  Epoch: 337  Training loss = 3.4422  Validation loss = 8.9465  \n",
      "\n",
      "Fold: 14  Epoch: 338  Training loss = 3.4418  Validation loss = 8.9456  \n",
      "\n",
      "Fold: 14  Epoch: 339  Training loss = 3.4415  Validation loss = 8.9449  \n",
      "\n",
      "Fold: 14  Epoch: 340  Training loss = 3.4411  Validation loss = 8.9441  \n",
      "\n",
      "Fold: 14  Epoch: 341  Training loss = 3.4406  Validation loss = 8.9432  \n",
      "\n",
      "Fold: 14  Epoch: 342  Training loss = 3.4401  Validation loss = 8.9422  \n",
      "\n",
      "Fold: 14  Epoch: 343  Training loss = 3.4398  Validation loss = 8.9415  \n",
      "\n",
      "Fold: 14  Epoch: 344  Training loss = 3.4392  Validation loss = 8.9403  \n",
      "\n",
      "Fold: 14  Epoch: 345  Training loss = 3.4389  Validation loss = 8.9396  \n",
      "\n",
      "Fold: 14  Epoch: 346  Training loss = 3.4384  Validation loss = 8.9386  \n",
      "\n",
      "Fold: 14  Epoch: 347  Training loss = 3.4379  Validation loss = 8.9377  \n",
      "\n",
      "Fold: 14  Epoch: 348  Training loss = 3.4375  Validation loss = 8.9368  \n",
      "\n",
      "Fold: 14  Epoch: 349  Training loss = 3.4371  Validation loss = 8.9361  \n",
      "\n",
      "Fold: 14  Epoch: 350  Training loss = 3.4368  Validation loss = 8.9354  \n",
      "\n",
      "Fold: 14  Epoch: 351  Training loss = 3.4363  Validation loss = 8.9344  \n",
      "\n",
      "Fold: 14  Epoch: 352  Training loss = 3.4358  Validation loss = 8.9334  \n",
      "\n",
      "Fold: 14  Epoch: 353  Training loss = 3.4353  Validation loss = 8.9324  \n",
      "\n",
      "Fold: 14  Epoch: 354  Training loss = 3.4348  Validation loss = 8.9313  \n",
      "\n",
      "Fold: 14  Epoch: 355  Training loss = 3.4343  Validation loss = 8.9303  \n",
      "\n",
      "Fold: 14  Epoch: 356  Training loss = 3.4340  Validation loss = 8.9296  \n",
      "\n",
      "Fold: 14  Epoch: 357  Training loss = 3.4335  Validation loss = 8.9287  \n",
      "\n",
      "Fold: 14  Epoch: 358  Training loss = 3.4331  Validation loss = 8.9278  \n",
      "\n",
      "Fold: 14  Epoch: 359  Training loss = 3.4326  Validation loss = 8.9268  \n",
      "\n",
      "Fold: 14  Epoch: 360  Training loss = 3.4321  Validation loss = 8.9259  \n",
      "\n",
      "Fold: 14  Epoch: 361  Training loss = 3.4316  Validation loss = 8.9248  \n",
      "\n",
      "Fold: 14  Epoch: 362  Training loss = 3.4313  Validation loss = 8.9241  \n",
      "\n",
      "Fold: 14  Epoch: 363  Training loss = 3.4308  Validation loss = 8.9233  \n",
      "\n",
      "Fold: 14  Epoch: 364  Training loss = 3.4305  Validation loss = 8.9225  \n",
      "\n",
      "Fold: 14  Epoch: 365  Training loss = 3.4301  Validation loss = 8.9217  \n",
      "\n",
      "Fold: 14  Epoch: 366  Training loss = 3.4297  Validation loss = 8.9209  \n",
      "\n",
      "Fold: 14  Epoch: 367  Training loss = 3.4292  Validation loss = 8.9200  \n",
      "\n",
      "Fold: 14  Epoch: 368  Training loss = 3.4287  Validation loss = 8.9189  \n",
      "\n",
      "Fold: 14  Epoch: 369  Training loss = 3.4282  Validation loss = 8.9178  \n",
      "\n",
      "Fold: 14  Epoch: 370  Training loss = 3.4278  Validation loss = 8.9169  \n",
      "\n",
      "Fold: 14  Epoch: 371  Training loss = 3.4272  Validation loss = 8.9158  \n",
      "\n",
      "Fold: 14  Epoch: 372  Training loss = 3.4269  Validation loss = 8.9153  \n",
      "\n",
      "Fold: 14  Epoch: 373  Training loss = 3.4265  Validation loss = 8.9144  \n",
      "\n",
      "Fold: 14  Epoch: 374  Training loss = 3.4262  Validation loss = 8.9137  \n",
      "\n",
      "Fold: 14  Epoch: 375  Training loss = 3.4258  Validation loss = 8.9129  \n",
      "\n",
      "Fold: 14  Epoch: 376  Training loss = 3.4253  Validation loss = 8.9120  \n",
      "\n",
      "Fold: 14  Epoch: 377  Training loss = 3.4250  Validation loss = 8.9112  \n",
      "\n",
      "Fold: 14  Epoch: 378  Training loss = 3.4245  Validation loss = 8.9102  \n",
      "\n",
      "Fold: 14  Epoch: 379  Training loss = 3.4241  Validation loss = 8.9093  \n",
      "\n",
      "Fold: 14  Epoch: 380  Training loss = 3.4236  Validation loss = 8.9083  \n",
      "\n",
      "Fold: 14  Epoch: 381  Training loss = 3.4231  Validation loss = 8.9073  \n",
      "\n",
      "Fold: 14  Epoch: 382  Training loss = 3.4227  Validation loss = 8.9065  \n",
      "\n",
      "Fold: 14  Epoch: 383  Training loss = 3.4224  Validation loss = 8.9058  \n",
      "\n",
      "Fold: 14  Epoch: 384  Training loss = 3.4219  Validation loss = 8.9050  \n",
      "\n",
      "Fold: 14  Epoch: 385  Training loss = 3.4214  Validation loss = 8.9039  \n",
      "\n",
      "Fold: 14  Epoch: 386  Training loss = 3.4211  Validation loss = 8.9032  \n",
      "\n",
      "Fold: 14  Epoch: 387  Training loss = 3.4207  Validation loss = 8.9023  \n",
      "\n",
      "Fold: 14  Epoch: 388  Training loss = 3.4203  Validation loss = 8.9017  \n",
      "\n",
      "Fold: 14  Epoch: 389  Training loss = 3.4199  Validation loss = 8.9008  \n",
      "\n",
      "Fold: 14  Epoch: 390  Training loss = 3.4195  Validation loss = 8.8999  \n",
      "\n",
      "Fold: 14  Epoch: 391  Training loss = 3.4191  Validation loss = 8.8991  \n",
      "\n",
      "Fold: 14  Epoch: 392  Training loss = 3.4187  Validation loss = 8.8983  \n",
      "\n",
      "Fold: 14  Epoch: 393  Training loss = 3.4182  Validation loss = 8.8972  \n",
      "\n",
      "Fold: 14  Epoch: 394  Training loss = 3.4178  Validation loss = 8.8965  \n",
      "\n",
      "Fold: 14  Epoch: 395  Training loss = 3.4173  Validation loss = 8.8955  \n",
      "\n",
      "Fold: 14  Epoch: 396  Training loss = 3.4168  Validation loss = 8.8945  \n",
      "\n",
      "Fold: 14  Epoch: 397  Training loss = 3.4164  Validation loss = 8.8936  \n",
      "\n",
      "Fold: 14  Epoch: 398  Training loss = 3.4160  Validation loss = 8.8928  \n",
      "\n",
      "Fold: 14  Epoch: 399  Training loss = 3.4155  Validation loss = 8.8917  \n",
      "\n",
      "Fold: 14  Epoch: 400  Training loss = 3.4150  Validation loss = 8.8906  \n",
      "\n",
      "Fold: 14  Epoch: 401  Training loss = 3.4145  Validation loss = 8.8897  \n",
      "\n",
      "Fold: 14  Epoch: 402  Training loss = 3.4141  Validation loss = 8.8889  \n",
      "\n",
      "Fold: 14  Epoch: 403  Training loss = 3.4136  Validation loss = 8.8878  \n",
      "\n",
      "Fold: 14  Epoch: 404  Training loss = 3.4132  Validation loss = 8.8870  \n",
      "\n",
      "Fold: 14  Epoch: 405  Training loss = 3.4128  Validation loss = 8.8861  \n",
      "\n",
      "Fold: 14  Epoch: 406  Training loss = 3.4123  Validation loss = 8.8851  \n",
      "\n",
      "Fold: 14  Epoch: 407  Training loss = 3.4118  Validation loss = 8.8841  \n",
      "\n",
      "Fold: 14  Epoch: 408  Training loss = 3.4113  Validation loss = 8.8831  \n",
      "\n",
      "Fold: 14  Epoch: 409  Training loss = 3.4110  Validation loss = 8.8826  \n",
      "\n",
      "Fold: 14  Epoch: 410  Training loss = 3.4106  Validation loss = 8.8816  \n",
      "\n",
      "Fold: 14  Epoch: 411  Training loss = 3.4102  Validation loss = 8.8808  \n",
      "\n",
      "Fold: 14  Epoch: 412  Training loss = 3.4097  Validation loss = 8.8798  \n",
      "\n",
      "Fold: 14  Epoch: 413  Training loss = 3.4093  Validation loss = 8.8790  \n",
      "\n",
      "Fold: 14  Epoch: 414  Training loss = 3.4090  Validation loss = 8.8783  \n",
      "\n",
      "Fold: 14  Epoch: 415  Training loss = 3.4086  Validation loss = 8.8775  \n",
      "\n",
      "Fold: 14  Epoch: 416  Training loss = 3.4082  Validation loss = 8.8767  \n",
      "\n",
      "Fold: 14  Epoch: 417  Training loss = 3.4078  Validation loss = 8.8759  \n",
      "\n",
      "Fold: 14  Epoch: 418  Training loss = 3.4074  Validation loss = 8.8751  \n",
      "\n",
      "Fold: 14  Epoch: 419  Training loss = 3.4070  Validation loss = 8.8742  \n",
      "\n",
      "Fold: 14  Epoch: 420  Training loss = 3.4066  Validation loss = 8.8734  \n",
      "\n",
      "Fold: 14  Epoch: 421  Training loss = 3.4062  Validation loss = 8.8726  \n",
      "\n",
      "Fold: 14  Epoch: 422  Training loss = 3.4057  Validation loss = 8.8717  \n",
      "\n",
      "Fold: 14  Epoch: 423  Training loss = 3.4054  Validation loss = 8.8710  \n",
      "\n",
      "Fold: 14  Epoch: 424  Training loss = 3.4049  Validation loss = 8.8701  \n",
      "\n",
      "Fold: 14  Epoch: 425  Training loss = 3.4045  Validation loss = 8.8693  \n",
      "\n",
      "Fold: 14  Epoch: 426  Training loss = 3.4041  Validation loss = 8.8684  \n",
      "\n",
      "Fold: 14  Epoch: 427  Training loss = 3.4035  Validation loss = 8.8673  \n",
      "\n",
      "Fold: 14  Epoch: 428  Training loss = 3.4031  Validation loss = 8.8666  \n",
      "\n",
      "Fold: 14  Epoch: 429  Training loss = 3.4026  Validation loss = 8.8656  \n",
      "\n",
      "Fold: 14  Epoch: 430  Training loss = 3.4020  Validation loss = 8.8645  \n",
      "\n",
      "Fold: 14  Epoch: 431  Training loss = 3.4017  Validation loss = 8.8640  \n",
      "\n",
      "Fold: 14  Epoch: 432  Training loss = 3.4009  Validation loss = 8.8629  \n",
      "\n",
      "Fold: 14  Epoch: 433  Training loss = 3.3997  Validation loss = 8.8618  \n",
      "\n",
      "Fold: 14  Epoch: 434  Training loss = 3.3982  Validation loss = 8.8605  \n",
      "\n",
      "Fold: 14  Epoch: 435  Training loss = 3.3975  Validation loss = 8.8596  \n",
      "\n",
      "Fold: 14  Epoch: 436  Training loss = 3.3969  Validation loss = 8.8588  \n",
      "\n",
      "Fold: 14  Epoch: 437  Training loss = 3.3966  Validation loss = 8.8582  \n",
      "\n",
      "Fold: 14  Epoch: 438  Training loss = 3.3961  Validation loss = 8.8572  \n",
      "\n",
      "Fold: 14  Epoch: 439  Training loss = 3.3956  Validation loss = 8.8565  \n",
      "\n",
      "Fold: 14  Epoch: 440  Training loss = 3.3951  Validation loss = 8.8555  \n",
      "\n",
      "Fold: 14  Epoch: 441  Training loss = 3.3946  Validation loss = 8.8546  \n",
      "\n",
      "Fold: 14  Epoch: 442  Training loss = 3.3941  Validation loss = 8.8535  \n",
      "\n",
      "Fold: 14  Epoch: 443  Training loss = 3.3936  Validation loss = 8.8526  \n",
      "\n",
      "Fold: 14  Epoch: 444  Training loss = 3.3932  Validation loss = 8.8516  \n",
      "\n",
      "Fold: 14  Epoch: 445  Training loss = 3.3927  Validation loss = 8.8507  \n",
      "\n",
      "Fold: 14  Epoch: 446  Training loss = 3.3922  Validation loss = 8.8498  \n",
      "\n",
      "Fold: 14  Epoch: 447  Training loss = 3.3919  Validation loss = 8.8490  \n",
      "\n",
      "Fold: 14  Epoch: 448  Training loss = 3.3915  Validation loss = 8.8482  \n",
      "\n",
      "Fold: 14  Epoch: 449  Training loss = 3.3912  Validation loss = 8.8477  \n",
      "\n",
      "Fold: 14  Epoch: 450  Training loss = 3.3909  Validation loss = 8.8470  \n",
      "\n",
      "Fold: 14  Epoch: 451  Training loss = 3.3905  Validation loss = 8.8462  \n",
      "\n",
      "Fold: 14  Epoch: 452  Training loss = 3.3899  Validation loss = 8.8450  \n",
      "\n",
      "Fold: 14  Epoch: 453  Training loss = 3.3895  Validation loss = 8.8441  \n",
      "\n",
      "Fold: 14  Epoch: 454  Training loss = 3.3889  Validation loss = 8.8430  \n",
      "\n",
      "Fold: 14  Epoch: 455  Training loss = 3.3884  Validation loss = 8.8418  \n",
      "\n",
      "Fold: 14  Epoch: 456  Training loss = 3.3879  Validation loss = 8.8409  \n",
      "\n",
      "Fold: 14  Epoch: 457  Training loss = 3.3875  Validation loss = 8.8400  \n",
      "\n",
      "Fold: 14  Epoch: 458  Training loss = 3.3872  Validation loss = 8.8393  \n",
      "\n",
      "Fold: 14  Epoch: 459  Training loss = 3.3868  Validation loss = 8.8384  \n",
      "\n",
      "Fold: 14  Epoch: 460  Training loss = 3.3862  Validation loss = 8.8373  \n",
      "\n",
      "Fold: 14  Epoch: 461  Training loss = 3.3859  Validation loss = 8.8366  \n",
      "\n",
      "Fold: 14  Epoch: 462  Training loss = 3.3855  Validation loss = 8.8357  \n",
      "\n",
      "Fold: 14  Epoch: 463  Training loss = 3.3851  Validation loss = 8.8349  \n",
      "\n",
      "Fold: 14  Epoch: 464  Training loss = 3.3845  Validation loss = 8.8337  \n",
      "\n",
      "Fold: 14  Epoch: 465  Training loss = 3.3841  Validation loss = 8.8328  \n",
      "\n",
      "Fold: 14  Epoch: 466  Training loss = 3.3836  Validation loss = 8.8318  \n",
      "\n",
      "Fold: 14  Epoch: 467  Training loss = 3.3832  Validation loss = 8.8311  \n",
      "\n",
      "Fold: 14  Epoch: 468  Training loss = 3.3828  Validation loss = 8.8301  \n",
      "\n",
      "Fold: 14  Epoch: 469  Training loss = 3.3824  Validation loss = 8.8292  \n",
      "\n",
      "Fold: 14  Epoch: 470  Training loss = 3.3819  Validation loss = 8.8283  \n",
      "\n",
      "Fold: 14  Epoch: 471  Training loss = 3.3814  Validation loss = 8.8271  \n",
      "\n",
      "Fold: 14  Epoch: 472  Training loss = 3.3809  Validation loss = 8.8263  \n",
      "\n",
      "Fold: 14  Epoch: 473  Training loss = 3.3805  Validation loss = 8.8253  \n",
      "\n",
      "Fold: 14  Epoch: 474  Training loss = 3.3801  Validation loss = 8.8245  \n",
      "\n",
      "Fold: 14  Epoch: 475  Training loss = 3.3797  Validation loss = 8.8236  \n",
      "\n",
      "Fold: 14  Epoch: 476  Training loss = 3.3793  Validation loss = 8.8229  \n",
      "\n",
      "Fold: 14  Epoch: 477  Training loss = 3.3789  Validation loss = 8.8220  \n",
      "\n",
      "Fold: 14  Epoch: 478  Training loss = 3.3786  Validation loss = 8.8213  \n",
      "\n",
      "Fold: 14  Epoch: 479  Training loss = 3.3781  Validation loss = 8.8202  \n",
      "\n",
      "Fold: 14  Epoch: 480  Training loss = 3.3775  Validation loss = 8.8191  \n",
      "\n",
      "Fold: 14  Epoch: 481  Training loss = 3.3772  Validation loss = 8.8184  \n",
      "\n",
      "Fold: 14  Epoch: 482  Training loss = 3.3769  Validation loss = 8.8177  \n",
      "\n",
      "Fold: 14  Epoch: 483  Training loss = 3.3764  Validation loss = 8.8167  \n",
      "\n",
      "Fold: 14  Epoch: 484  Training loss = 3.3759  Validation loss = 8.8157  \n",
      "\n",
      "Fold: 14  Epoch: 485  Training loss = 3.3755  Validation loss = 8.8149  \n",
      "\n",
      "Fold: 14  Epoch: 486  Training loss = 3.3751  Validation loss = 8.8140  \n",
      "\n",
      "Fold: 14  Epoch: 487  Training loss = 3.3748  Validation loss = 8.8133  \n",
      "\n",
      "Fold: 14  Epoch: 488  Training loss = 3.3743  Validation loss = 8.8123  \n",
      "\n",
      "Fold: 14  Epoch: 489  Training loss = 3.3739  Validation loss = 8.8114  \n",
      "\n",
      "Fold: 14  Epoch: 490  Training loss = 3.3734  Validation loss = 8.8104  \n",
      "\n",
      "Fold: 14  Epoch: 491  Training loss = 3.3730  Validation loss = 8.8096  \n",
      "\n",
      "Fold: 14  Epoch: 492  Training loss = 3.3727  Validation loss = 8.8088  \n",
      "\n",
      "Fold: 14  Epoch: 493  Training loss = 3.3722  Validation loss = 8.8079  \n",
      "\n",
      "Fold: 14  Epoch: 494  Training loss = 3.3718  Validation loss = 8.8070  \n",
      "\n",
      "Fold: 14  Epoch: 495  Training loss = 3.3714  Validation loss = 8.8063  \n",
      "\n",
      "Fold: 14  Epoch: 496  Training loss = 3.3710  Validation loss = 8.8054  \n",
      "\n",
      "Fold: 14  Epoch: 497  Training loss = 3.3707  Validation loss = 8.8047  \n",
      "\n",
      "Fold: 14  Epoch: 498  Training loss = 3.3703  Validation loss = 8.8039  \n",
      "\n",
      "Fold: 14  Epoch: 499  Training loss = 3.3700  Validation loss = 8.8033  \n",
      "\n",
      "Fold: 14  Epoch: 500  Training loss = 3.3695  Validation loss = 8.8022  \n",
      "\n",
      "Check model:  Fold: 14  Epoch: 500  Training loss = 3.3695  Validation loss = 8.8022  \n",
      "\n",
      "Fold: 15  Epoch: 1  Training loss = 3.9920  Validation loss = 9.3918  \n",
      "\n",
      "Fold: 15  Epoch: 2  Training loss = 3.9915  Validation loss = 9.3909  \n",
      "\n",
      "Fold: 15  Epoch: 3  Training loss = 3.9908  Validation loss = 9.3897  \n",
      "\n",
      "Fold: 15  Epoch: 4  Training loss = 3.9901  Validation loss = 9.3886  \n",
      "\n",
      "Fold: 15  Epoch: 5  Training loss = 3.9895  Validation loss = 9.3876  \n",
      "\n",
      "Fold: 15  Epoch: 6  Training loss = 3.9889  Validation loss = 9.3866  \n",
      "\n",
      "Fold: 15  Epoch: 7  Training loss = 3.9880  Validation loss = 9.3851  \n",
      "\n",
      "Fold: 15  Epoch: 8  Training loss = 3.9873  Validation loss = 9.3839  \n",
      "\n",
      "Fold: 15  Epoch: 9  Training loss = 3.9866  Validation loss = 9.3828  \n",
      "\n",
      "Fold: 15  Epoch: 10  Training loss = 3.9860  Validation loss = 9.3817  \n",
      "\n",
      "Fold: 15  Epoch: 11  Training loss = 3.9852  Validation loss = 9.3804  \n",
      "\n",
      "Fold: 15  Epoch: 12  Training loss = 3.9844  Validation loss = 9.3792  \n",
      "\n",
      "Fold: 15  Epoch: 13  Training loss = 3.9839  Validation loss = 9.3783  \n",
      "\n",
      "Fold: 15  Epoch: 14  Training loss = 3.9833  Validation loss = 9.3772  \n",
      "\n",
      "Fold: 15  Epoch: 15  Training loss = 3.9827  Validation loss = 9.3762  \n",
      "\n",
      "Fold: 15  Epoch: 16  Training loss = 3.9818  Validation loss = 9.3749  \n",
      "\n",
      "Fold: 15  Epoch: 17  Training loss = 3.9810  Validation loss = 9.3735  \n",
      "\n",
      "Fold: 15  Epoch: 18  Training loss = 3.9804  Validation loss = 9.3726  \n",
      "\n",
      "Fold: 15  Epoch: 19  Training loss = 3.9798  Validation loss = 9.3714  \n",
      "\n",
      "Fold: 15  Epoch: 20  Training loss = 3.9790  Validation loss = 9.3702  \n",
      "\n",
      "Fold: 15  Epoch: 21  Training loss = 3.9785  Validation loss = 9.3693  \n",
      "\n",
      "Fold: 15  Epoch: 22  Training loss = 3.9779  Validation loss = 9.3683  \n",
      "\n",
      "Fold: 15  Epoch: 23  Training loss = 3.9772  Validation loss = 9.3672  \n",
      "\n",
      "Fold: 15  Epoch: 24  Training loss = 3.9766  Validation loss = 9.3660  \n",
      "\n",
      "Fold: 15  Epoch: 25  Training loss = 3.9761  Validation loss = 9.3652  \n",
      "\n",
      "Fold: 15  Epoch: 26  Training loss = 3.9754  Validation loss = 9.3640  \n",
      "\n",
      "Fold: 15  Epoch: 27  Training loss = 3.9746  Validation loss = 9.3628  \n",
      "\n",
      "Fold: 15  Epoch: 28  Training loss = 3.9740  Validation loss = 9.3618  \n",
      "\n",
      "Fold: 15  Epoch: 29  Training loss = 3.9732  Validation loss = 9.3605  \n",
      "\n",
      "Fold: 15  Epoch: 30  Training loss = 3.9725  Validation loss = 9.3594  \n",
      "\n",
      "Fold: 15  Epoch: 31  Training loss = 3.9719  Validation loss = 9.3584  \n",
      "\n",
      "Fold: 15  Epoch: 32  Training loss = 3.9713  Validation loss = 9.3573  \n",
      "\n",
      "Fold: 15  Epoch: 33  Training loss = 3.9708  Validation loss = 9.3565  \n",
      "\n",
      "Fold: 15  Epoch: 34  Training loss = 3.9701  Validation loss = 9.3553  \n",
      "\n",
      "Fold: 15  Epoch: 35  Training loss = 3.9694  Validation loss = 9.3542  \n",
      "\n",
      "Fold: 15  Epoch: 36  Training loss = 3.9687  Validation loss = 9.3529  \n",
      "\n",
      "Fold: 15  Epoch: 37  Training loss = 3.9681  Validation loss = 9.3518  \n",
      "\n",
      "Fold: 15  Epoch: 38  Training loss = 3.9676  Validation loss = 9.3511  \n",
      "\n",
      "Fold: 15  Epoch: 39  Training loss = 3.9670  Validation loss = 9.3501  \n",
      "\n",
      "Fold: 15  Epoch: 40  Training loss = 3.9663  Validation loss = 9.3488  \n",
      "\n",
      "Fold: 15  Epoch: 41  Training loss = 3.9656  Validation loss = 9.3478  \n",
      "\n",
      "Fold: 15  Epoch: 42  Training loss = 3.9649  Validation loss = 9.3466  \n",
      "\n",
      "Fold: 15  Epoch: 43  Training loss = 3.9643  Validation loss = 9.3455  \n",
      "\n",
      "Fold: 15  Epoch: 44  Training loss = 3.9637  Validation loss = 9.3445  \n",
      "\n",
      "Fold: 15  Epoch: 45  Training loss = 3.9630  Validation loss = 9.3434  \n",
      "\n",
      "Fold: 15  Epoch: 46  Training loss = 3.9625  Validation loss = 9.3425  \n",
      "\n",
      "Fold: 15  Epoch: 47  Training loss = 3.9619  Validation loss = 9.3416  \n",
      "\n",
      "Fold: 15  Epoch: 48  Training loss = 3.9612  Validation loss = 9.3404  \n",
      "\n",
      "Fold: 15  Epoch: 49  Training loss = 3.9604  Validation loss = 9.3391  \n",
      "\n",
      "Fold: 15  Epoch: 50  Training loss = 3.9598  Validation loss = 9.3380  \n",
      "\n",
      "Fold: 15  Epoch: 51  Training loss = 3.9592  Validation loss = 9.3371  \n",
      "\n",
      "Fold: 15  Epoch: 52  Training loss = 3.9584  Validation loss = 9.3357  \n",
      "\n",
      "Fold: 15  Epoch: 53  Training loss = 3.9578  Validation loss = 9.3348  \n",
      "\n",
      "Fold: 15  Epoch: 54  Training loss = 3.9572  Validation loss = 9.3337  \n",
      "\n",
      "Fold: 15  Epoch: 55  Training loss = 3.9567  Validation loss = 9.3329  \n",
      "\n",
      "Fold: 15  Epoch: 56  Training loss = 3.9562  Validation loss = 9.3320  \n",
      "\n",
      "Fold: 15  Epoch: 57  Training loss = 3.9556  Validation loss = 9.3310  \n",
      "\n",
      "Fold: 15  Epoch: 58  Training loss = 3.9550  Validation loss = 9.3300  \n",
      "\n",
      "Fold: 15  Epoch: 59  Training loss = 3.9544  Validation loss = 9.3289  \n",
      "\n",
      "Fold: 15  Epoch: 60  Training loss = 3.9536  Validation loss = 9.3277  \n",
      "\n",
      "Fold: 15  Epoch: 61  Training loss = 3.9529  Validation loss = 9.3265  \n",
      "\n",
      "Fold: 15  Epoch: 62  Training loss = 3.9520  Validation loss = 9.3250  \n",
      "\n",
      "Fold: 15  Epoch: 63  Training loss = 3.9514  Validation loss = 9.3239  \n",
      "\n",
      "Fold: 15  Epoch: 64  Training loss = 3.9508  Validation loss = 9.3230  \n",
      "\n",
      "Fold: 15  Epoch: 65  Training loss = 3.9502  Validation loss = 9.3220  \n",
      "\n",
      "Fold: 15  Epoch: 66  Training loss = 3.9496  Validation loss = 9.3209  \n",
      "\n",
      "Fold: 15  Epoch: 67  Training loss = 3.9491  Validation loss = 9.3202  \n",
      "\n",
      "Fold: 15  Epoch: 68  Training loss = 3.9485  Validation loss = 9.3191  \n",
      "\n",
      "Fold: 15  Epoch: 69  Training loss = 3.9479  Validation loss = 9.3182  \n",
      "\n",
      "Fold: 15  Epoch: 70  Training loss = 3.9473  Validation loss = 9.3172  \n",
      "\n",
      "Fold: 15  Epoch: 71  Training loss = 3.9465  Validation loss = 9.3158  \n",
      "\n",
      "Fold: 15  Epoch: 72  Training loss = 3.9458  Validation loss = 9.3145  \n",
      "\n",
      "Fold: 15  Epoch: 73  Training loss = 3.9450  Validation loss = 9.3133  \n",
      "\n",
      "Fold: 15  Epoch: 74  Training loss = 3.9445  Validation loss = 9.3123  \n",
      "\n",
      "Fold: 15  Epoch: 75  Training loss = 3.9439  Validation loss = 9.3114  \n",
      "\n",
      "Fold: 15  Epoch: 76  Training loss = 3.9432  Validation loss = 9.3102  \n",
      "\n",
      "Fold: 15  Epoch: 77  Training loss = 3.9425  Validation loss = 9.3090  \n",
      "\n",
      "Fold: 15  Epoch: 78  Training loss = 3.9416  Validation loss = 9.3075  \n",
      "\n",
      "Fold: 15  Epoch: 79  Training loss = 3.9408  Validation loss = 9.3061  \n",
      "\n",
      "Fold: 15  Epoch: 80  Training loss = 3.9401  Validation loss = 9.3049  \n",
      "\n",
      "Fold: 15  Epoch: 81  Training loss = 3.9394  Validation loss = 9.3038  \n",
      "\n",
      "Fold: 15  Epoch: 82  Training loss = 3.9385  Validation loss = 9.3022  \n",
      "\n",
      "Fold: 15  Epoch: 83  Training loss = 3.9378  Validation loss = 9.3010  \n",
      "\n",
      "Fold: 15  Epoch: 84  Training loss = 3.9372  Validation loss = 9.3001  \n",
      "\n",
      "Fold: 15  Epoch: 85  Training loss = 3.9367  Validation loss = 9.2992  \n",
      "\n",
      "Fold: 15  Epoch: 86  Training loss = 3.9362  Validation loss = 9.2984  \n",
      "\n",
      "Fold: 15  Epoch: 87  Training loss = 3.9354  Validation loss = 9.2970  \n",
      "\n",
      "Fold: 15  Epoch: 88  Training loss = 3.9348  Validation loss = 9.2960  \n",
      "\n",
      "Fold: 15  Epoch: 89  Training loss = 3.9342  Validation loss = 9.2949  \n",
      "\n",
      "Fold: 15  Epoch: 90  Training loss = 3.9334  Validation loss = 9.2937  \n",
      "\n",
      "Fold: 15  Epoch: 91  Training loss = 3.9327  Validation loss = 9.2924  \n",
      "\n",
      "Fold: 15  Epoch: 92  Training loss = 3.9318  Validation loss = 9.2910  \n",
      "\n",
      "Fold: 15  Epoch: 93  Training loss = 3.9312  Validation loss = 9.2899  \n",
      "\n",
      "Fold: 15  Epoch: 94  Training loss = 3.9308  Validation loss = 9.2892  \n",
      "\n",
      "Fold: 15  Epoch: 95  Training loss = 3.9302  Validation loss = 9.2882  \n",
      "\n",
      "Fold: 15  Epoch: 96  Training loss = 3.9296  Validation loss = 9.2872  \n",
      "\n",
      "Fold: 15  Epoch: 97  Training loss = 3.9289  Validation loss = 9.2860  \n",
      "\n",
      "Fold: 15  Epoch: 98  Training loss = 3.9284  Validation loss = 9.2852  \n",
      "\n",
      "Fold: 15  Epoch: 99  Training loss = 3.9279  Validation loss = 9.2842  \n",
      "\n",
      "Fold: 15  Epoch: 100  Training loss = 3.9273  Validation loss = 9.2833  \n",
      "\n",
      "Fold: 15  Epoch: 101  Training loss = 3.9266  Validation loss = 9.2821  \n",
      "\n",
      "Fold: 15  Epoch: 102  Training loss = 3.9260  Validation loss = 9.2812  \n",
      "\n",
      "Fold: 15  Epoch: 103  Training loss = 3.9254  Validation loss = 9.2802  \n",
      "\n",
      "Fold: 15  Epoch: 104  Training loss = 3.9248  Validation loss = 9.2791  \n",
      "\n",
      "Fold: 15  Epoch: 105  Training loss = 3.9243  Validation loss = 9.2783  \n",
      "\n",
      "Fold: 15  Epoch: 106  Training loss = 3.9235  Validation loss = 9.2769  \n",
      "\n",
      "Fold: 15  Epoch: 107  Training loss = 3.9228  Validation loss = 9.2758  \n",
      "\n",
      "Fold: 15  Epoch: 108  Training loss = 3.9222  Validation loss = 9.2746  \n",
      "\n",
      "Fold: 15  Epoch: 109  Training loss = 3.9216  Validation loss = 9.2736  \n",
      "\n",
      "Fold: 15  Epoch: 110  Training loss = 3.9209  Validation loss = 9.2725  \n",
      "\n",
      "Fold: 15  Epoch: 111  Training loss = 3.9204  Validation loss = 9.2716  \n",
      "\n",
      "Fold: 15  Epoch: 112  Training loss = 3.9196  Validation loss = 9.2703  \n",
      "\n",
      "Fold: 15  Epoch: 113  Training loss = 3.9190  Validation loss = 9.2693  \n",
      "\n",
      "Fold: 15  Epoch: 114  Training loss = 3.9184  Validation loss = 9.2683  \n",
      "\n",
      "Fold: 15  Epoch: 115  Training loss = 3.9178  Validation loss = 9.2672  \n",
      "\n",
      "Fold: 15  Epoch: 116  Training loss = 3.9171  Validation loss = 9.2660  \n",
      "\n",
      "Fold: 15  Epoch: 117  Training loss = 3.9165  Validation loss = 9.2650  \n",
      "\n",
      "Fold: 15  Epoch: 118  Training loss = 3.9158  Validation loss = 9.2638  \n",
      "\n",
      "Fold: 15  Epoch: 119  Training loss = 3.9153  Validation loss = 9.2630  \n",
      "\n",
      "Fold: 15  Epoch: 120  Training loss = 3.9148  Validation loss = 9.2620  \n",
      "\n",
      "Fold: 15  Epoch: 121  Training loss = 3.9141  Validation loss = 9.2609  \n",
      "\n",
      "Fold: 15  Epoch: 122  Training loss = 3.9135  Validation loss = 9.2600  \n",
      "\n",
      "Fold: 15  Epoch: 123  Training loss = 3.9128  Validation loss = 9.2587  \n",
      "\n",
      "Fold: 15  Epoch: 124  Training loss = 3.9122  Validation loss = 9.2577  \n",
      "\n",
      "Fold: 15  Epoch: 125  Training loss = 3.9116  Validation loss = 9.2567  \n",
      "\n",
      "Fold: 15  Epoch: 126  Training loss = 3.9109  Validation loss = 9.2554  \n",
      "\n",
      "Fold: 15  Epoch: 127  Training loss = 3.9101  Validation loss = 9.2542  \n",
      "\n",
      "Fold: 15  Epoch: 128  Training loss = 3.9096  Validation loss = 9.2533  \n",
      "\n",
      "Fold: 15  Epoch: 129  Training loss = 3.9090  Validation loss = 9.2522  \n",
      "\n",
      "Fold: 15  Epoch: 130  Training loss = 3.9083  Validation loss = 9.2511  \n",
      "\n",
      "Fold: 15  Epoch: 131  Training loss = 3.9076  Validation loss = 9.2498  \n",
      "\n",
      "Fold: 15  Epoch: 132  Training loss = 3.9069  Validation loss = 9.2487  \n",
      "\n",
      "Fold: 15  Epoch: 133  Training loss = 3.9063  Validation loss = 9.2476  \n",
      "\n",
      "Fold: 15  Epoch: 134  Training loss = 3.9055  Validation loss = 9.2464  \n",
      "\n",
      "Fold: 15  Epoch: 135  Training loss = 3.9050  Validation loss = 9.2454  \n",
      "\n",
      "Fold: 15  Epoch: 136  Training loss = 3.9044  Validation loss = 9.2444  \n",
      "\n",
      "Fold: 15  Epoch: 137  Training loss = 3.9039  Validation loss = 9.2436  \n",
      "\n",
      "Fold: 15  Epoch: 138  Training loss = 3.9032  Validation loss = 9.2423  \n",
      "\n",
      "Fold: 15  Epoch: 139  Training loss = 3.9024  Validation loss = 9.2411  \n",
      "\n",
      "Fold: 15  Epoch: 140  Training loss = 3.9018  Validation loss = 9.2400  \n",
      "\n",
      "Fold: 15  Epoch: 141  Training loss = 3.9012  Validation loss = 9.2390  \n",
      "\n",
      "Fold: 15  Epoch: 142  Training loss = 3.9006  Validation loss = 9.2379  \n",
      "\n",
      "Fold: 15  Epoch: 143  Training loss = 3.8998  Validation loss = 9.2366  \n",
      "\n",
      "Fold: 15  Epoch: 144  Training loss = 3.8993  Validation loss = 9.2358  \n",
      "\n",
      "Fold: 15  Epoch: 145  Training loss = 3.8989  Validation loss = 9.2351  \n",
      "\n",
      "Fold: 15  Epoch: 146  Training loss = 3.8984  Validation loss = 9.2342  \n",
      "\n",
      "Fold: 15  Epoch: 147  Training loss = 3.8977  Validation loss = 9.2331  \n",
      "\n",
      "Fold: 15  Epoch: 148  Training loss = 3.8973  Validation loss = 9.2323  \n",
      "\n",
      "Fold: 15  Epoch: 149  Training loss = 3.8968  Validation loss = 9.2314  \n",
      "\n",
      "Fold: 15  Epoch: 150  Training loss = 3.8962  Validation loss = 9.2304  \n",
      "\n",
      "Fold: 15  Epoch: 151  Training loss = 3.8954  Validation loss = 9.2291  \n",
      "\n",
      "Fold: 15  Epoch: 152  Training loss = 3.8949  Validation loss = 9.2282  \n",
      "\n",
      "Fold: 15  Epoch: 153  Training loss = 3.8943  Validation loss = 9.2272  \n",
      "\n",
      "Fold: 15  Epoch: 154  Training loss = 3.8936  Validation loss = 9.2261  \n",
      "\n",
      "Fold: 15  Epoch: 155  Training loss = 3.8931  Validation loss = 9.2251  \n",
      "\n",
      "Fold: 15  Epoch: 156  Training loss = 3.8924  Validation loss = 9.2240  \n",
      "\n",
      "Fold: 15  Epoch: 157  Training loss = 3.8920  Validation loss = 9.2233  \n",
      "\n",
      "Fold: 15  Epoch: 158  Training loss = 3.8912  Validation loss = 9.2220  \n",
      "\n",
      "Fold: 15  Epoch: 159  Training loss = 3.8907  Validation loss = 9.2210  \n",
      "\n",
      "Fold: 15  Epoch: 160  Training loss = 3.8900  Validation loss = 9.2199  \n",
      "\n",
      "Fold: 15  Epoch: 161  Training loss = 3.8896  Validation loss = 9.2192  \n",
      "\n",
      "Fold: 15  Epoch: 162  Training loss = 3.8889  Validation loss = 9.2180  \n",
      "\n",
      "Fold: 15  Epoch: 163  Training loss = 3.8884  Validation loss = 9.2170  \n",
      "\n",
      "Fold: 15  Epoch: 164  Training loss = 3.8880  Validation loss = 9.2164  \n",
      "\n",
      "Fold: 15  Epoch: 165  Training loss = 3.8875  Validation loss = 9.2155  \n",
      "\n",
      "Fold: 15  Epoch: 166  Training loss = 3.8869  Validation loss = 9.2146  \n",
      "\n",
      "Fold: 15  Epoch: 167  Training loss = 3.8864  Validation loss = 9.2137  \n",
      "\n",
      "Fold: 15  Epoch: 168  Training loss = 3.8858  Validation loss = 9.2127  \n",
      "\n",
      "Fold: 15  Epoch: 169  Training loss = 3.8853  Validation loss = 9.2118  \n",
      "\n",
      "Fold: 15  Epoch: 170  Training loss = 3.8848  Validation loss = 9.2109  \n",
      "\n",
      "Fold: 15  Epoch: 171  Training loss = 3.8840  Validation loss = 9.2096  \n",
      "\n",
      "Fold: 15  Epoch: 172  Training loss = 3.8835  Validation loss = 9.2086  \n",
      "\n",
      "Fold: 15  Epoch: 173  Training loss = 3.8826  Validation loss = 9.2072  \n",
      "\n",
      "Fold: 15  Epoch: 174  Training loss = 3.8819  Validation loss = 9.2060  \n",
      "\n",
      "Fold: 15  Epoch: 175  Training loss = 3.8813  Validation loss = 9.2049  \n",
      "\n",
      "Fold: 15  Epoch: 176  Training loss = 3.8806  Validation loss = 9.2038  \n",
      "\n",
      "Fold: 15  Epoch: 177  Training loss = 3.8801  Validation loss = 9.2028  \n",
      "\n",
      "Fold: 15  Epoch: 178  Training loss = 3.8793  Validation loss = 9.2015  \n",
      "\n",
      "Fold: 15  Epoch: 179  Training loss = 3.8787  Validation loss = 9.2005  \n",
      "\n",
      "Fold: 15  Epoch: 180  Training loss = 3.8781  Validation loss = 9.1995  \n",
      "\n",
      "Fold: 15  Epoch: 181  Training loss = 3.8776  Validation loss = 9.1986  \n",
      "\n",
      "Fold: 15  Epoch: 182  Training loss = 3.8770  Validation loss = 9.1976  \n",
      "\n",
      "Fold: 15  Epoch: 183  Training loss = 3.8765  Validation loss = 9.1967  \n",
      "\n",
      "Fold: 15  Epoch: 184  Training loss = 3.8760  Validation loss = 9.1958  \n",
      "\n",
      "Fold: 15  Epoch: 185  Training loss = 3.8755  Validation loss = 9.1950  \n",
      "\n",
      "Fold: 15  Epoch: 186  Training loss = 3.8748  Validation loss = 9.1938  \n",
      "\n",
      "Fold: 15  Epoch: 187  Training loss = 3.8743  Validation loss = 9.1929  \n",
      "\n",
      "Fold: 15  Epoch: 188  Training loss = 3.8738  Validation loss = 9.1921  \n",
      "\n",
      "Fold: 15  Epoch: 189  Training loss = 3.8732  Validation loss = 9.1910  \n",
      "\n",
      "Fold: 15  Epoch: 190  Training loss = 3.8726  Validation loss = 9.1900  \n",
      "\n",
      "Fold: 15  Epoch: 191  Training loss = 3.8720  Validation loss = 9.1890  \n",
      "\n",
      "Fold: 15  Epoch: 192  Training loss = 3.8716  Validation loss = 9.1882  \n",
      "\n",
      "Fold: 15  Epoch: 193  Training loss = 3.8709  Validation loss = 9.1870  \n",
      "\n",
      "Fold: 15  Epoch: 194  Training loss = 3.8702  Validation loss = 9.1859  \n",
      "\n",
      "Fold: 15  Epoch: 195  Training loss = 3.8696  Validation loss = 9.1848  \n",
      "\n",
      "Fold: 15  Epoch: 196  Training loss = 3.8688  Validation loss = 9.1835  \n",
      "\n",
      "Fold: 15  Epoch: 197  Training loss = 3.8683  Validation loss = 9.1826  \n",
      "\n",
      "Fold: 15  Epoch: 198  Training loss = 3.8678  Validation loss = 9.1817  \n",
      "\n",
      "Fold: 15  Epoch: 199  Training loss = 3.8672  Validation loss = 9.1807  \n",
      "\n",
      "Fold: 15  Epoch: 200  Training loss = 3.8666  Validation loss = 9.1796  \n",
      "\n",
      "Fold: 15  Epoch: 201  Training loss = 3.8660  Validation loss = 9.1786  \n",
      "\n",
      "Fold: 15  Epoch: 202  Training loss = 3.8653  Validation loss = 9.1774  \n",
      "\n",
      "Fold: 15  Epoch: 203  Training loss = 3.8648  Validation loss = 9.1765  \n",
      "\n",
      "Fold: 15  Epoch: 204  Training loss = 3.8644  Validation loss = 9.1757  \n",
      "\n",
      "Fold: 15  Epoch: 205  Training loss = 3.8638  Validation loss = 9.1748  \n",
      "\n",
      "Fold: 15  Epoch: 206  Training loss = 3.8633  Validation loss = 9.1739  \n",
      "\n",
      "Fold: 15  Epoch: 207  Training loss = 3.8627  Validation loss = 9.1728  \n",
      "\n",
      "Fold: 15  Epoch: 208  Training loss = 3.8619  Validation loss = 9.1715  \n",
      "\n",
      "Fold: 15  Epoch: 209  Training loss = 3.8614  Validation loss = 9.1706  \n",
      "\n",
      "Fold: 15  Epoch: 210  Training loss = 3.8608  Validation loss = 9.1696  \n",
      "\n",
      "Fold: 15  Epoch: 211  Training loss = 3.8600  Validation loss = 9.1683  \n",
      "\n",
      "Fold: 15  Epoch: 212  Training loss = 3.8593  Validation loss = 9.1671  \n",
      "\n",
      "Fold: 15  Epoch: 213  Training loss = 3.8589  Validation loss = 9.1663  \n",
      "\n",
      "Fold: 15  Epoch: 214  Training loss = 3.8580  Validation loss = 9.1648  \n",
      "\n",
      "Fold: 15  Epoch: 215  Training loss = 3.8576  Validation loss = 9.1641  \n",
      "\n",
      "Fold: 15  Epoch: 216  Training loss = 3.8573  Validation loss = 9.1635  \n",
      "\n",
      "Fold: 15  Epoch: 217  Training loss = 3.8567  Validation loss = 9.1625  \n",
      "\n",
      "Fold: 15  Epoch: 218  Training loss = 3.8561  Validation loss = 9.1615  \n",
      "\n",
      "Fold: 15  Epoch: 219  Training loss = 3.8556  Validation loss = 9.1606  \n",
      "\n",
      "Fold: 15  Epoch: 220  Training loss = 3.8550  Validation loss = 9.1596  \n",
      "\n",
      "Fold: 15  Epoch: 221  Training loss = 3.8544  Validation loss = 9.1586  \n",
      "\n",
      "Fold: 15  Epoch: 222  Training loss = 3.8537  Validation loss = 9.1573  \n",
      "\n",
      "Fold: 15  Epoch: 223  Training loss = 3.8531  Validation loss = 9.1563  \n",
      "\n",
      "Fold: 15  Epoch: 224  Training loss = 3.8525  Validation loss = 9.1552  \n",
      "\n",
      "Fold: 15  Epoch: 225  Training loss = 3.8520  Validation loss = 9.1544  \n",
      "\n",
      "Fold: 15  Epoch: 226  Training loss = 3.8516  Validation loss = 9.1537  \n",
      "\n",
      "Fold: 15  Epoch: 227  Training loss = 3.8510  Validation loss = 9.1527  \n",
      "\n",
      "Fold: 15  Epoch: 228  Training loss = 3.8505  Validation loss = 9.1518  \n",
      "\n",
      "Fold: 15  Epoch: 229  Training loss = 3.8497  Validation loss = 9.1504  \n",
      "\n",
      "Fold: 15  Epoch: 230  Training loss = 3.8491  Validation loss = 9.1493  \n",
      "\n",
      "Fold: 15  Epoch: 231  Training loss = 3.8484  Validation loss = 9.1482  \n",
      "\n",
      "Fold: 15  Epoch: 232  Training loss = 3.8477  Validation loss = 9.1469  \n",
      "\n",
      "Fold: 15  Epoch: 233  Training loss = 3.8470  Validation loss = 9.1457  \n",
      "\n",
      "Fold: 15  Epoch: 234  Training loss = 3.8465  Validation loss = 9.1448  \n",
      "\n",
      "Fold: 15  Epoch: 235  Training loss = 3.8460  Validation loss = 9.1440  \n",
      "\n",
      "Fold: 15  Epoch: 236  Training loss = 3.8453  Validation loss = 9.1428  \n",
      "\n",
      "Fold: 15  Epoch: 237  Training loss = 3.8448  Validation loss = 9.1418  \n",
      "\n",
      "Fold: 15  Epoch: 238  Training loss = 3.8442  Validation loss = 9.1408  \n",
      "\n",
      "Fold: 15  Epoch: 239  Training loss = 3.8438  Validation loss = 9.1401  \n",
      "\n",
      "Fold: 15  Epoch: 240  Training loss = 3.8431  Validation loss = 9.1389  \n",
      "\n",
      "Fold: 15  Epoch: 241  Training loss = 3.8425  Validation loss = 9.1379  \n",
      "\n",
      "Fold: 15  Epoch: 242  Training loss = 3.8420  Validation loss = 9.1370  \n",
      "\n",
      "Fold: 15  Epoch: 243  Training loss = 3.8412  Validation loss = 9.1356  \n",
      "\n",
      "Fold: 15  Epoch: 244  Training loss = 3.8406  Validation loss = 9.1345  \n",
      "\n",
      "Fold: 15  Epoch: 245  Training loss = 3.8400  Validation loss = 9.1335  \n",
      "\n",
      "Fold: 15  Epoch: 246  Training loss = 3.8395  Validation loss = 9.1325  \n",
      "\n",
      "Fold: 15  Epoch: 247  Training loss = 3.8389  Validation loss = 9.1315  \n",
      "\n",
      "Fold: 15  Epoch: 248  Training loss = 3.8384  Validation loss = 9.1307  \n",
      "\n",
      "Fold: 15  Epoch: 249  Training loss = 3.8378  Validation loss = 9.1296  \n",
      "\n",
      "Fold: 15  Epoch: 250  Training loss = 3.8372  Validation loss = 9.1286  \n",
      "\n",
      "Fold: 15  Epoch: 251  Training loss = 3.8366  Validation loss = 9.1276  \n",
      "\n",
      "Fold: 15  Epoch: 252  Training loss = 3.8361  Validation loss = 9.1267  \n",
      "\n",
      "Fold: 15  Epoch: 253  Training loss = 3.8356  Validation loss = 9.1258  \n",
      "\n",
      "Fold: 15  Epoch: 254  Training loss = 3.8349  Validation loss = 9.1246  \n",
      "\n",
      "Fold: 15  Epoch: 255  Training loss = 3.8343  Validation loss = 9.1235  \n",
      "\n",
      "Fold: 15  Epoch: 256  Training loss = 3.8338  Validation loss = 9.1226  \n",
      "\n",
      "Fold: 15  Epoch: 257  Training loss = 3.8332  Validation loss = 9.1216  \n",
      "\n",
      "Fold: 15  Epoch: 258  Training loss = 3.8326  Validation loss = 9.1207  \n",
      "\n",
      "Fold: 15  Epoch: 259  Training loss = 3.8320  Validation loss = 9.1196  \n",
      "\n",
      "Fold: 15  Epoch: 260  Training loss = 3.8314  Validation loss = 9.1185  \n",
      "\n",
      "Fold: 15  Epoch: 261  Training loss = 3.8307  Validation loss = 9.1173  \n",
      "\n",
      "Fold: 15  Epoch: 262  Training loss = 3.8302  Validation loss = 9.1164  \n",
      "\n",
      "Fold: 15  Epoch: 263  Training loss = 3.8296  Validation loss = 9.1154  \n",
      "\n",
      "Fold: 15  Epoch: 264  Training loss = 3.8289  Validation loss = 9.1143  \n",
      "\n",
      "Fold: 15  Epoch: 265  Training loss = 3.8284  Validation loss = 9.1133  \n",
      "\n",
      "Fold: 15  Epoch: 266  Training loss = 3.8279  Validation loss = 9.1124  \n",
      "\n",
      "Fold: 15  Epoch: 267  Training loss = 3.8276  Validation loss = 9.1119  \n",
      "\n",
      "Fold: 15  Epoch: 268  Training loss = 3.8271  Validation loss = 9.1111  \n",
      "\n",
      "Fold: 15  Epoch: 269  Training loss = 3.8266  Validation loss = 9.1101  \n",
      "\n",
      "Fold: 15  Epoch: 270  Training loss = 3.8260  Validation loss = 9.1091  \n",
      "\n",
      "Fold: 15  Epoch: 271  Training loss = 3.8254  Validation loss = 9.1080  \n",
      "\n",
      "Fold: 15  Epoch: 272  Training loss = 3.8248  Validation loss = 9.1071  \n",
      "\n",
      "Fold: 15  Epoch: 273  Training loss = 3.8242  Validation loss = 9.1059  \n",
      "\n",
      "Fold: 15  Epoch: 274  Training loss = 3.8237  Validation loss = 9.1051  \n",
      "\n",
      "Fold: 15  Epoch: 275  Training loss = 3.8231  Validation loss = 9.1040  \n",
      "\n",
      "Fold: 15  Epoch: 276  Training loss = 3.8226  Validation loss = 9.1031  \n",
      "\n",
      "Fold: 15  Epoch: 277  Training loss = 3.8220  Validation loss = 9.1021  \n",
      "\n",
      "Fold: 15  Epoch: 278  Training loss = 3.8214  Validation loss = 9.1010  \n",
      "\n",
      "Fold: 15  Epoch: 279  Training loss = 3.8206  Validation loss = 9.0997  \n",
      "\n",
      "Fold: 15  Epoch: 280  Training loss = 3.8200  Validation loss = 9.0986  \n",
      "\n",
      "Fold: 15  Epoch: 281  Training loss = 3.8194  Validation loss = 9.0976  \n",
      "\n",
      "Fold: 15  Epoch: 282  Training loss = 3.8190  Validation loss = 9.0968  \n",
      "\n",
      "Fold: 15  Epoch: 283  Training loss = 3.8184  Validation loss = 9.0958  \n",
      "\n",
      "Fold: 15  Epoch: 284  Training loss = 3.8178  Validation loss = 9.0947  \n",
      "\n",
      "Fold: 15  Epoch: 285  Training loss = 3.8173  Validation loss = 9.0938  \n",
      "\n",
      "Fold: 15  Epoch: 286  Training loss = 3.8166  Validation loss = 9.0927  \n",
      "\n",
      "Fold: 15  Epoch: 287  Training loss = 3.8160  Validation loss = 9.0916  \n",
      "\n",
      "Fold: 15  Epoch: 288  Training loss = 3.8154  Validation loss = 9.0905  \n",
      "\n",
      "Fold: 15  Epoch: 289  Training loss = 3.8148  Validation loss = 9.0894  \n",
      "\n",
      "Fold: 15  Epoch: 290  Training loss = 3.8143  Validation loss = 9.0885  \n",
      "\n",
      "Fold: 15  Epoch: 291  Training loss = 3.8137  Validation loss = 9.0875  \n",
      "\n",
      "Fold: 15  Epoch: 292  Training loss = 3.8132  Validation loss = 9.0866  \n",
      "\n",
      "Fold: 15  Epoch: 293  Training loss = 3.8129  Validation loss = 9.0860  \n",
      "\n",
      "Fold: 15  Epoch: 294  Training loss = 3.8122  Validation loss = 9.0848  \n",
      "\n",
      "Fold: 15  Epoch: 295  Training loss = 3.8116  Validation loss = 9.0837  \n",
      "\n",
      "Fold: 15  Epoch: 296  Training loss = 3.8110  Validation loss = 9.0828  \n",
      "\n",
      "Fold: 15  Epoch: 297  Training loss = 3.8105  Validation loss = 9.0819  \n",
      "\n",
      "Fold: 15  Epoch: 298  Training loss = 3.8100  Validation loss = 9.0809  \n",
      "\n",
      "Fold: 15  Epoch: 299  Training loss = 3.8093  Validation loss = 9.0798  \n",
      "\n",
      "Fold: 15  Epoch: 300  Training loss = 3.8088  Validation loss = 9.0789  \n",
      "\n",
      "Fold: 15  Epoch: 301  Training loss = 3.8082  Validation loss = 9.0778  \n",
      "\n",
      "Fold: 15  Epoch: 302  Training loss = 3.8077  Validation loss = 9.0768  \n",
      "\n",
      "Fold: 15  Epoch: 303  Training loss = 3.8072  Validation loss = 9.0760  \n",
      "\n",
      "Fold: 15  Epoch: 304  Training loss = 3.8066  Validation loss = 9.0749  \n",
      "\n",
      "Fold: 15  Epoch: 305  Training loss = 3.8060  Validation loss = 9.0739  \n",
      "\n",
      "Fold: 15  Epoch: 306  Training loss = 3.8054  Validation loss = 9.0728  \n",
      "\n",
      "Fold: 15  Epoch: 307  Training loss = 3.8048  Validation loss = 9.0719  \n",
      "\n",
      "Fold: 15  Epoch: 308  Training loss = 3.8043  Validation loss = 9.0709  \n",
      "\n",
      "Fold: 15  Epoch: 309  Training loss = 3.8039  Validation loss = 9.0702  \n",
      "\n",
      "Fold: 15  Epoch: 310  Training loss = 3.8034  Validation loss = 9.0693  \n",
      "\n",
      "Fold: 15  Epoch: 311  Training loss = 3.8028  Validation loss = 9.0682  \n",
      "\n",
      "Fold: 15  Epoch: 312  Training loss = 3.8022  Validation loss = 9.0672  \n",
      "\n",
      "Fold: 15  Epoch: 313  Training loss = 3.8016  Validation loss = 9.0662  \n",
      "\n",
      "Fold: 15  Epoch: 314  Training loss = 3.8010  Validation loss = 9.0651  \n",
      "\n",
      "Fold: 15  Epoch: 315  Training loss = 3.8004  Validation loss = 9.0640  \n",
      "\n",
      "Fold: 15  Epoch: 316  Training loss = 3.7997  Validation loss = 9.0627  \n",
      "\n",
      "Fold: 15  Epoch: 317  Training loss = 3.7992  Validation loss = 9.0619  \n",
      "\n",
      "Fold: 15  Epoch: 318  Training loss = 3.7988  Validation loss = 9.0612  \n",
      "\n",
      "Fold: 15  Epoch: 319  Training loss = 3.7983  Validation loss = 9.0602  \n",
      "\n",
      "Fold: 15  Epoch: 320  Training loss = 3.7976  Validation loss = 9.0589  \n",
      "\n",
      "Fold: 15  Epoch: 321  Training loss = 3.7971  Validation loss = 9.0581  \n",
      "\n",
      "Fold: 15  Epoch: 322  Training loss = 3.7965  Validation loss = 9.0570  \n",
      "\n",
      "Fold: 15  Epoch: 323  Training loss = 3.7955  Validation loss = 9.0553  \n",
      "\n",
      "Fold: 15  Epoch: 324  Training loss = 3.7950  Validation loss = 9.0544  \n",
      "\n",
      "Fold: 15  Epoch: 325  Training loss = 3.7944  Validation loss = 9.0534  \n",
      "\n",
      "Fold: 15  Epoch: 326  Training loss = 3.7939  Validation loss = 9.0524  \n",
      "\n",
      "Fold: 15  Epoch: 327  Training loss = 3.7935  Validation loss = 9.0518  \n",
      "\n",
      "Fold: 15  Epoch: 328  Training loss = 3.7929  Validation loss = 9.0506  \n",
      "\n",
      "Fold: 15  Epoch: 329  Training loss = 3.7923  Validation loss = 9.0497  \n",
      "\n",
      "Fold: 15  Epoch: 330  Training loss = 3.7917  Validation loss = 9.0486  \n",
      "\n",
      "Fold: 15  Epoch: 331  Training loss = 3.7912  Validation loss = 9.0476  \n",
      "\n",
      "Fold: 15  Epoch: 332  Training loss = 3.7906  Validation loss = 9.0467  \n",
      "\n",
      "Fold: 15  Epoch: 333  Training loss = 3.7901  Validation loss = 9.0456  \n",
      "\n",
      "Fold: 15  Epoch: 334  Training loss = 3.7895  Validation loss = 9.0447  \n",
      "\n",
      "Fold: 15  Epoch: 335  Training loss = 3.7889  Validation loss = 9.0437  \n",
      "\n",
      "Fold: 15  Epoch: 336  Training loss = 3.7884  Validation loss = 9.0428  \n",
      "\n",
      "Fold: 15  Epoch: 337  Training loss = 3.7879  Validation loss = 9.0418  \n",
      "\n",
      "Fold: 15  Epoch: 338  Training loss = 3.7874  Validation loss = 9.0409  \n",
      "\n",
      "Fold: 15  Epoch: 339  Training loss = 3.7868  Validation loss = 9.0399  \n",
      "\n",
      "Fold: 15  Epoch: 340  Training loss = 3.7863  Validation loss = 9.0390  \n",
      "\n",
      "Fold: 15  Epoch: 341  Training loss = 3.7857  Validation loss = 9.0379  \n",
      "\n",
      "Fold: 15  Epoch: 342  Training loss = 3.7849  Validation loss = 9.0366  \n",
      "\n",
      "Fold: 15  Epoch: 343  Training loss = 3.7842  Validation loss = 9.0353  \n",
      "\n",
      "Fold: 15  Epoch: 344  Training loss = 3.7835  Validation loss = 9.0341  \n",
      "\n",
      "Fold: 15  Epoch: 345  Training loss = 3.7828  Validation loss = 9.0329  \n",
      "\n",
      "Fold: 15  Epoch: 346  Training loss = 3.7822  Validation loss = 9.0317  \n",
      "\n",
      "Fold: 15  Epoch: 347  Training loss = 3.7817  Validation loss = 9.0309  \n",
      "\n",
      "Fold: 15  Epoch: 348  Training loss = 3.7811  Validation loss = 9.0298  \n",
      "\n",
      "Fold: 15  Epoch: 349  Training loss = 3.7804  Validation loss = 9.0285  \n",
      "\n",
      "Fold: 15  Epoch: 350  Training loss = 3.7799  Validation loss = 9.0275  \n",
      "\n",
      "Fold: 15  Epoch: 351  Training loss = 3.7794  Validation loss = 9.0267  \n",
      "\n",
      "Fold: 15  Epoch: 352  Training loss = 3.7788  Validation loss = 9.0257  \n",
      "\n",
      "Fold: 15  Epoch: 353  Training loss = 3.7784  Validation loss = 9.0249  \n",
      "\n",
      "Fold: 15  Epoch: 354  Training loss = 3.7777  Validation loss = 9.0237  \n",
      "\n",
      "Fold: 15  Epoch: 355  Training loss = 3.7772  Validation loss = 9.0228  \n",
      "\n",
      "Fold: 15  Epoch: 356  Training loss = 3.7766  Validation loss = 9.0216  \n",
      "\n",
      "Fold: 15  Epoch: 357  Training loss = 3.7760  Validation loss = 9.0206  \n",
      "\n",
      "Fold: 15  Epoch: 358  Training loss = 3.7754  Validation loss = 9.0196  \n",
      "\n",
      "Fold: 15  Epoch: 359  Training loss = 3.7750  Validation loss = 9.0188  \n",
      "\n",
      "Fold: 15  Epoch: 360  Training loss = 3.7744  Validation loss = 9.0179  \n",
      "\n",
      "Fold: 15  Epoch: 361  Training loss = 3.7738  Validation loss = 9.0167  \n",
      "\n",
      "Fold: 15  Epoch: 362  Training loss = 3.7733  Validation loss = 9.0158  \n",
      "\n",
      "Fold: 15  Epoch: 363  Training loss = 3.7729  Validation loss = 9.0151  \n",
      "\n",
      "Fold: 15  Epoch: 364  Training loss = 3.7724  Validation loss = 9.0142  \n",
      "\n",
      "Fold: 15  Epoch: 365  Training loss = 3.7717  Validation loss = 9.0131  \n",
      "\n",
      "Fold: 15  Epoch: 366  Training loss = 3.7710  Validation loss = 9.0118  \n",
      "\n",
      "Fold: 15  Epoch: 367  Training loss = 3.7704  Validation loss = 9.0108  \n",
      "\n",
      "Fold: 15  Epoch: 368  Training loss = 3.7698  Validation loss = 9.0097  \n",
      "\n",
      "Fold: 15  Epoch: 369  Training loss = 3.7693  Validation loss = 9.0088  \n",
      "\n",
      "Fold: 15  Epoch: 370  Training loss = 3.7688  Validation loss = 9.0079  \n",
      "\n",
      "Fold: 15  Epoch: 371  Training loss = 3.7684  Validation loss = 9.0071  \n",
      "\n",
      "Fold: 15  Epoch: 372  Training loss = 3.7678  Validation loss = 9.0061  \n",
      "\n",
      "Fold: 15  Epoch: 373  Training loss = 3.7673  Validation loss = 9.0052  \n",
      "\n",
      "Fold: 15  Epoch: 374  Training loss = 3.7667  Validation loss = 9.0041  \n",
      "\n",
      "Fold: 15  Epoch: 375  Training loss = 3.7661  Validation loss = 9.0031  \n",
      "\n",
      "Fold: 15  Epoch: 376  Training loss = 3.7655  Validation loss = 9.0021  \n",
      "\n",
      "Fold: 15  Epoch: 377  Training loss = 3.7651  Validation loss = 9.0013  \n",
      "\n",
      "Fold: 15  Epoch: 378  Training loss = 3.7645  Validation loss = 9.0002  \n",
      "\n",
      "Fold: 15  Epoch: 379  Training loss = 3.7640  Validation loss = 8.9993  \n",
      "\n",
      "Fold: 15  Epoch: 380  Training loss = 3.7635  Validation loss = 8.9984  \n",
      "\n",
      "Fold: 15  Epoch: 381  Training loss = 3.7631  Validation loss = 8.9976  \n",
      "\n",
      "Fold: 15  Epoch: 382  Training loss = 3.7624  Validation loss = 8.9963  \n",
      "\n",
      "Fold: 15  Epoch: 383  Training loss = 3.7618  Validation loss = 8.9954  \n",
      "\n",
      "Fold: 15  Epoch: 384  Training loss = 3.7612  Validation loss = 8.9942  \n",
      "\n",
      "Fold: 15  Epoch: 385  Training loss = 3.7606  Validation loss = 8.9931  \n",
      "\n",
      "Fold: 15  Epoch: 386  Training loss = 3.7600  Validation loss = 8.9921  \n",
      "\n",
      "Fold: 15  Epoch: 387  Training loss = 3.7593  Validation loss = 8.9909  \n",
      "\n",
      "Fold: 15  Epoch: 388  Training loss = 3.7587  Validation loss = 8.9898  \n",
      "\n",
      "Fold: 15  Epoch: 389  Training loss = 3.7582  Validation loss = 8.9888  \n",
      "\n",
      "Fold: 15  Epoch: 390  Training loss = 3.7577  Validation loss = 8.9879  \n",
      "\n",
      "Fold: 15  Epoch: 391  Training loss = 3.7571  Validation loss = 8.9870  \n",
      "\n",
      "Fold: 15  Epoch: 392  Training loss = 3.7564  Validation loss = 8.9857  \n",
      "\n",
      "Fold: 15  Epoch: 393  Training loss = 3.7559  Validation loss = 8.9848  \n",
      "\n",
      "Fold: 15  Epoch: 394  Training loss = 3.7555  Validation loss = 8.9841  \n",
      "\n",
      "Fold: 15  Epoch: 395  Training loss = 3.7549  Validation loss = 8.9829  \n",
      "\n",
      "Fold: 15  Epoch: 396  Training loss = 3.7542  Validation loss = 8.9817  \n",
      "\n",
      "Fold: 15  Epoch: 397  Training loss = 3.7538  Validation loss = 8.9809  \n",
      "\n",
      "Fold: 15  Epoch: 398  Training loss = 3.7531  Validation loss = 8.9797  \n",
      "\n",
      "Fold: 15  Epoch: 399  Training loss = 3.7525  Validation loss = 8.9786  \n",
      "\n",
      "Fold: 15  Epoch: 400  Training loss = 3.7520  Validation loss = 8.9778  \n",
      "\n",
      "Fold: 15  Epoch: 401  Training loss = 3.7515  Validation loss = 8.9769  \n",
      "\n",
      "Fold: 15  Epoch: 402  Training loss = 3.7510  Validation loss = 8.9759  \n",
      "\n",
      "Fold: 15  Epoch: 403  Training loss = 3.7504  Validation loss = 8.9749  \n",
      "\n",
      "Fold: 15  Epoch: 404  Training loss = 3.7499  Validation loss = 8.9739  \n",
      "\n",
      "Fold: 15  Epoch: 405  Training loss = 3.7492  Validation loss = 8.9728  \n",
      "\n",
      "Fold: 15  Epoch: 406  Training loss = 3.7487  Validation loss = 8.9718  \n",
      "\n",
      "Fold: 15  Epoch: 407  Training loss = 3.7482  Validation loss = 8.9710  \n",
      "\n",
      "Fold: 15  Epoch: 408  Training loss = 3.7476  Validation loss = 8.9699  \n",
      "\n",
      "Fold: 15  Epoch: 409  Training loss = 3.7472  Validation loss = 8.9692  \n",
      "\n",
      "Fold: 15  Epoch: 410  Training loss = 3.7467  Validation loss = 8.9683  \n",
      "\n",
      "Fold: 15  Epoch: 411  Training loss = 3.7461  Validation loss = 8.9672  \n",
      "\n",
      "Fold: 15  Epoch: 412  Training loss = 3.7456  Validation loss = 8.9662  \n",
      "\n",
      "Fold: 15  Epoch: 413  Training loss = 3.7451  Validation loss = 8.9654  \n",
      "\n",
      "Fold: 15  Epoch: 414  Training loss = 3.7446  Validation loss = 8.9644  \n",
      "\n",
      "Fold: 15  Epoch: 415  Training loss = 3.7441  Validation loss = 8.9636  \n",
      "\n",
      "Fold: 15  Epoch: 416  Training loss = 3.7436  Validation loss = 8.9626  \n",
      "\n",
      "Fold: 15  Epoch: 417  Training loss = 3.7429  Validation loss = 8.9615  \n",
      "\n",
      "Fold: 15  Epoch: 418  Training loss = 3.7424  Validation loss = 8.9606  \n",
      "\n",
      "Fold: 15  Epoch: 419  Training loss = 3.7419  Validation loss = 8.9596  \n",
      "\n",
      "Fold: 15  Epoch: 420  Training loss = 3.7414  Validation loss = 8.9588  \n",
      "\n",
      "Fold: 15  Epoch: 421  Training loss = 3.7410  Validation loss = 8.9580  \n",
      "\n",
      "Fold: 15  Epoch: 422  Training loss = 3.7405  Validation loss = 8.9570  \n",
      "\n",
      "Fold: 15  Epoch: 423  Training loss = 3.7400  Validation loss = 8.9563  \n",
      "\n",
      "Fold: 15  Epoch: 424  Training loss = 3.7394  Validation loss = 8.9553  \n",
      "\n",
      "Fold: 15  Epoch: 425  Training loss = 3.7390  Validation loss = 8.9544  \n",
      "\n",
      "Fold: 15  Epoch: 426  Training loss = 3.7383  Validation loss = 8.9532  \n",
      "\n",
      "Fold: 15  Epoch: 427  Training loss = 3.7376  Validation loss = 8.9520  \n",
      "\n",
      "Fold: 15  Epoch: 428  Training loss = 3.7370  Validation loss = 8.9508  \n",
      "\n",
      "Fold: 15  Epoch: 429  Training loss = 3.7363  Validation loss = 8.9497  \n",
      "\n",
      "Fold: 15  Epoch: 430  Training loss = 3.7358  Validation loss = 8.9488  \n",
      "\n",
      "Fold: 15  Epoch: 431  Training loss = 3.7354  Validation loss = 8.9479  \n",
      "\n",
      "Fold: 15  Epoch: 432  Training loss = 3.7348  Validation loss = 8.9470  \n",
      "\n",
      "Fold: 15  Epoch: 433  Training loss = 3.7344  Validation loss = 8.9462  \n",
      "\n",
      "Fold: 15  Epoch: 434  Training loss = 3.7336  Validation loss = 8.9450  \n",
      "\n",
      "Fold: 15  Epoch: 435  Training loss = 3.7331  Validation loss = 8.9443  \n",
      "\n",
      "Fold: 15  Epoch: 436  Training loss = 3.7326  Validation loss = 8.9434  \n",
      "\n",
      "Fold: 15  Epoch: 437  Training loss = 3.7320  Validation loss = 8.9425  \n",
      "\n",
      "Fold: 15  Epoch: 438  Training loss = 3.7316  Validation loss = 8.9417  \n",
      "\n",
      "Fold: 15  Epoch: 439  Training loss = 3.7309  Validation loss = 8.9407  \n",
      "\n",
      "Fold: 15  Epoch: 440  Training loss = 3.7304  Validation loss = 8.9399  \n",
      "\n",
      "Fold: 15  Epoch: 441  Training loss = 3.7299  Validation loss = 8.9391  \n",
      "\n",
      "Fold: 15  Epoch: 442  Training loss = 3.7294  Validation loss = 8.9383  \n",
      "\n",
      "Fold: 15  Epoch: 443  Training loss = 3.7286  Validation loss = 8.9372  \n",
      "\n",
      "Fold: 15  Epoch: 444  Training loss = 3.7275  Validation loss = 8.9361  \n",
      "\n",
      "Fold: 15  Epoch: 445  Training loss = 3.7265  Validation loss = 8.9353  \n",
      "\n",
      "Fold: 15  Epoch: 446  Training loss = 3.7259  Validation loss = 8.9344  \n",
      "\n",
      "Fold: 15  Epoch: 447  Training loss = 3.7253  Validation loss = 8.9333  \n",
      "\n",
      "Fold: 15  Epoch: 448  Training loss = 3.7246  Validation loss = 8.9321  \n",
      "\n",
      "Fold: 15  Epoch: 449  Training loss = 3.7242  Validation loss = 8.9314  \n",
      "\n",
      "Fold: 15  Epoch: 450  Training loss = 3.7235  Validation loss = 8.9302  \n",
      "\n",
      "Fold: 15  Epoch: 451  Training loss = 3.7229  Validation loss = 8.9292  \n",
      "\n",
      "Fold: 15  Epoch: 452  Training loss = 3.7225  Validation loss = 8.9284  \n",
      "\n",
      "Fold: 15  Epoch: 453  Training loss = 3.7219  Validation loss = 8.9275  \n",
      "\n",
      "Fold: 15  Epoch: 454  Training loss = 3.7212  Validation loss = 8.9262  \n",
      "\n",
      "Fold: 15  Epoch: 455  Training loss = 3.7207  Validation loss = 8.9252  \n",
      "\n",
      "Fold: 15  Epoch: 456  Training loss = 3.7202  Validation loss = 8.9244  \n",
      "\n",
      "Fold: 15  Epoch: 457  Training loss = 3.7197  Validation loss = 8.9234  \n",
      "\n",
      "Fold: 15  Epoch: 458  Training loss = 3.7191  Validation loss = 8.9224  \n",
      "\n",
      "Fold: 15  Epoch: 459  Training loss = 3.7185  Validation loss = 8.9213  \n",
      "\n",
      "Fold: 15  Epoch: 460  Training loss = 3.7181  Validation loss = 8.9206  \n",
      "\n",
      "Fold: 15  Epoch: 461  Training loss = 3.7175  Validation loss = 8.9195  \n",
      "\n",
      "Fold: 15  Epoch: 462  Training loss = 3.7168  Validation loss = 8.9182  \n",
      "\n",
      "Fold: 15  Epoch: 463  Training loss = 3.7163  Validation loss = 8.9174  \n",
      "\n",
      "Fold: 15  Epoch: 464  Training loss = 3.7158  Validation loss = 8.9165  \n",
      "\n",
      "Fold: 15  Epoch: 465  Training loss = 3.7153  Validation loss = 8.9156  \n",
      "\n",
      "Fold: 15  Epoch: 466  Training loss = 3.7149  Validation loss = 8.9148  \n",
      "\n",
      "Fold: 15  Epoch: 467  Training loss = 3.7143  Validation loss = 8.9137  \n",
      "\n",
      "Fold: 15  Epoch: 468  Training loss = 3.7139  Validation loss = 8.9130  \n",
      "\n",
      "Fold: 15  Epoch: 469  Training loss = 3.7134  Validation loss = 8.9121  \n",
      "\n",
      "Fold: 15  Epoch: 470  Training loss = 3.7129  Validation loss = 8.9111  \n",
      "\n",
      "Fold: 15  Epoch: 471  Training loss = 3.7122  Validation loss = 8.9099  \n",
      "\n",
      "Fold: 15  Epoch: 472  Training loss = 3.7118  Validation loss = 8.9092  \n",
      "\n",
      "Fold: 15  Epoch: 473  Training loss = 3.7115  Validation loss = 8.9087  \n",
      "\n",
      "Fold: 15  Epoch: 474  Training loss = 3.7109  Validation loss = 8.9074  \n",
      "\n",
      "Fold: 15  Epoch: 475  Training loss = 3.7102  Validation loss = 8.9062  \n",
      "\n",
      "Fold: 15  Epoch: 476  Training loss = 3.7097  Validation loss = 8.9053  \n",
      "\n",
      "Fold: 15  Epoch: 477  Training loss = 3.7091  Validation loss = 8.9043  \n",
      "\n",
      "Fold: 15  Epoch: 478  Training loss = 3.7086  Validation loss = 8.9032  \n",
      "\n",
      "Fold: 15  Epoch: 479  Training loss = 3.7081  Validation loss = 8.9024  \n",
      "\n",
      "Fold: 15  Epoch: 480  Training loss = 3.7075  Validation loss = 8.9014  \n",
      "\n",
      "Fold: 15  Epoch: 481  Training loss = 3.7069  Validation loss = 8.9002  \n",
      "\n",
      "Fold: 15  Epoch: 482  Training loss = 3.7064  Validation loss = 8.8993  \n",
      "\n",
      "Fold: 15  Epoch: 483  Training loss = 3.7059  Validation loss = 8.8983  \n",
      "\n",
      "Fold: 15  Epoch: 484  Training loss = 3.7054  Validation loss = 8.8974  \n",
      "\n",
      "Fold: 15  Epoch: 485  Training loss = 3.7047  Validation loss = 8.8962  \n",
      "\n",
      "Fold: 15  Epoch: 486  Training loss = 3.7041  Validation loss = 8.8951  \n",
      "\n",
      "Fold: 15  Epoch: 487  Training loss = 3.7036  Validation loss = 8.8941  \n",
      "\n",
      "Fold: 15  Epoch: 488  Training loss = 3.7030  Validation loss = 8.8931  \n",
      "\n",
      "Fold: 15  Epoch: 489  Training loss = 3.7024  Validation loss = 8.8920  \n",
      "\n",
      "Fold: 15  Epoch: 490  Training loss = 3.7019  Validation loss = 8.8911  \n",
      "\n",
      "Fold: 15  Epoch: 491  Training loss = 3.7015  Validation loss = 8.8903  \n",
      "\n",
      "Fold: 15  Epoch: 492  Training loss = 3.7009  Validation loss = 8.8891  \n",
      "\n",
      "Fold: 15  Epoch: 493  Training loss = 3.7004  Validation loss = 8.8882  \n",
      "\n",
      "Fold: 15  Epoch: 494  Training loss = 3.6999  Validation loss = 8.8874  \n",
      "\n",
      "Fold: 15  Epoch: 495  Training loss = 3.6992  Validation loss = 8.8860  \n",
      "\n",
      "Fold: 15  Epoch: 496  Training loss = 3.6987  Validation loss = 8.8852  \n",
      "\n",
      "Fold: 15  Epoch: 497  Training loss = 3.6981  Validation loss = 8.8841  \n",
      "\n",
      "Fold: 15  Epoch: 498  Training loss = 3.6976  Validation loss = 8.8831  \n",
      "\n",
      "Fold: 15  Epoch: 499  Training loss = 3.6971  Validation loss = 8.8822  \n",
      "\n",
      "Fold: 15  Epoch: 500  Training loss = 3.6965  Validation loss = 8.8812  \n",
      "\n",
      "Check model:  Fold: 15  Epoch: 500  Training loss = 3.6965  Validation loss = 8.8812  \n",
      "\n",
      "Fold: 16  Epoch: 1  Training loss = 4.2673  Validation loss = 6.4622  \n",
      "\n",
      "Fold: 16  Epoch: 2  Training loss = 4.2665  Validation loss = 6.4613  \n",
      "\n",
      "Fold: 16  Epoch: 3  Training loss = 4.2656  Validation loss = 6.4604  \n",
      "\n",
      "Fold: 16  Epoch: 4  Training loss = 4.2648  Validation loss = 6.4595  \n",
      "\n",
      "Fold: 16  Epoch: 5  Training loss = 4.2640  Validation loss = 6.4583  \n",
      "\n",
      "Fold: 16  Epoch: 6  Training loss = 4.2632  Validation loss = 6.4572  \n",
      "\n",
      "Fold: 16  Epoch: 7  Training loss = 4.2623  Validation loss = 6.4563  \n",
      "\n",
      "Fold: 16  Epoch: 8  Training loss = 4.2616  Validation loss = 6.4553  \n",
      "\n",
      "Fold: 16  Epoch: 9  Training loss = 4.2606  Validation loss = 6.4542  \n",
      "\n",
      "Fold: 16  Epoch: 10  Training loss = 4.2597  Validation loss = 6.4531  \n",
      "\n",
      "Fold: 16  Epoch: 11  Training loss = 4.2587  Validation loss = 6.4518  \n",
      "\n",
      "Fold: 16  Epoch: 12  Training loss = 4.2577  Validation loss = 6.4508  \n",
      "\n",
      "Fold: 16  Epoch: 13  Training loss = 4.2567  Validation loss = 6.4496  \n",
      "\n",
      "Fold: 16  Epoch: 14  Training loss = 4.2560  Validation loss = 6.4488  \n",
      "\n",
      "Fold: 16  Epoch: 15  Training loss = 4.2550  Validation loss = 6.4476  \n",
      "\n",
      "Fold: 16  Epoch: 16  Training loss = 4.2541  Validation loss = 6.4464  \n",
      "\n",
      "Fold: 16  Epoch: 17  Training loss = 4.2531  Validation loss = 6.4452  \n",
      "\n",
      "Fold: 16  Epoch: 18  Training loss = 4.2521  Validation loss = 6.4437  \n",
      "\n",
      "Fold: 16  Epoch: 19  Training loss = 4.2513  Validation loss = 6.4428  \n",
      "\n",
      "Fold: 16  Epoch: 20  Training loss = 4.2502  Validation loss = 6.4413  \n",
      "\n",
      "Fold: 16  Epoch: 21  Training loss = 4.2493  Validation loss = 6.4404  \n",
      "\n",
      "Fold: 16  Epoch: 22  Training loss = 4.2486  Validation loss = 6.4394  \n",
      "\n",
      "Fold: 16  Epoch: 23  Training loss = 4.2478  Validation loss = 6.4383  \n",
      "\n",
      "Fold: 16  Epoch: 24  Training loss = 4.2468  Validation loss = 6.4373  \n",
      "\n",
      "Fold: 16  Epoch: 25  Training loss = 4.2464  Validation loss = 6.4367  \n",
      "\n",
      "Fold: 16  Epoch: 26  Training loss = 4.2456  Validation loss = 6.4356  \n",
      "\n",
      "Fold: 16  Epoch: 27  Training loss = 4.2448  Validation loss = 6.4348  \n",
      "\n",
      "Fold: 16  Epoch: 28  Training loss = 4.2438  Validation loss = 6.4335  \n",
      "\n",
      "Fold: 16  Epoch: 29  Training loss = 4.2426  Validation loss = 6.4321  \n",
      "\n",
      "Fold: 16  Epoch: 30  Training loss = 4.2418  Validation loss = 6.4311  \n",
      "\n",
      "Fold: 16  Epoch: 31  Training loss = 4.2410  Validation loss = 6.4304  \n",
      "\n",
      "Fold: 16  Epoch: 32  Training loss = 4.2403  Validation loss = 6.4296  \n",
      "\n",
      "Fold: 16  Epoch: 33  Training loss = 4.2395  Validation loss = 6.4286  \n",
      "\n",
      "Fold: 16  Epoch: 34  Training loss = 4.2386  Validation loss = 6.4276  \n",
      "\n",
      "Fold: 16  Epoch: 35  Training loss = 4.2375  Validation loss = 6.4262  \n",
      "\n",
      "Fold: 16  Epoch: 36  Training loss = 4.2366  Validation loss = 6.4254  \n",
      "\n",
      "Fold: 16  Epoch: 37  Training loss = 4.2359  Validation loss = 6.4246  \n",
      "\n",
      "Fold: 16  Epoch: 38  Training loss = 4.2351  Validation loss = 6.4237  \n",
      "\n",
      "Fold: 16  Epoch: 39  Training loss = 4.2344  Validation loss = 6.4228  \n",
      "\n",
      "Fold: 16  Epoch: 40  Training loss = 4.2338  Validation loss = 6.4221  \n",
      "\n",
      "Fold: 16  Epoch: 41  Training loss = 4.2333  Validation loss = 6.4214  \n",
      "\n",
      "Fold: 16  Epoch: 42  Training loss = 4.2324  Validation loss = 6.4203  \n",
      "\n",
      "Fold: 16  Epoch: 43  Training loss = 4.2314  Validation loss = 6.4191  \n",
      "\n",
      "Fold: 16  Epoch: 44  Training loss = 4.2304  Validation loss = 6.4179  \n",
      "\n",
      "Fold: 16  Epoch: 45  Training loss = 4.2297  Validation loss = 6.4170  \n",
      "\n",
      "Fold: 16  Epoch: 46  Training loss = 4.2292  Validation loss = 6.4164  \n",
      "\n",
      "Fold: 16  Epoch: 47  Training loss = 4.2286  Validation loss = 6.4158  \n",
      "\n",
      "Fold: 16  Epoch: 48  Training loss = 4.2278  Validation loss = 6.4149  \n",
      "\n",
      "Fold: 16  Epoch: 49  Training loss = 4.2271  Validation loss = 6.4141  \n",
      "\n",
      "Fold: 16  Epoch: 50  Training loss = 4.2262  Validation loss = 6.4131  \n",
      "\n",
      "Fold: 16  Epoch: 51  Training loss = 4.2255  Validation loss = 6.4123  \n",
      "\n",
      "Fold: 16  Epoch: 52  Training loss = 4.2247  Validation loss = 6.4114  \n",
      "\n",
      "Fold: 16  Epoch: 53  Training loss = 4.2239  Validation loss = 6.4105  \n",
      "\n",
      "Fold: 16  Epoch: 54  Training loss = 4.2231  Validation loss = 6.4094  \n",
      "\n",
      "Fold: 16  Epoch: 55  Training loss = 4.2222  Validation loss = 6.4085  \n",
      "\n",
      "Fold: 16  Epoch: 56  Training loss = 4.2214  Validation loss = 6.4074  \n",
      "\n",
      "Fold: 16  Epoch: 57  Training loss = 4.2206  Validation loss = 6.4064  \n",
      "\n",
      "Fold: 16  Epoch: 58  Training loss = 4.2196  Validation loss = 6.4054  \n",
      "\n",
      "Fold: 16  Epoch: 59  Training loss = 4.2191  Validation loss = 6.4048  \n",
      "\n",
      "Fold: 16  Epoch: 60  Training loss = 4.2183  Validation loss = 6.4038  \n",
      "\n",
      "Fold: 16  Epoch: 61  Training loss = 4.2176  Validation loss = 6.4030  \n",
      "\n",
      "Fold: 16  Epoch: 62  Training loss = 4.2171  Validation loss = 6.4024  \n",
      "\n",
      "Fold: 16  Epoch: 63  Training loss = 4.2162  Validation loss = 6.4012  \n",
      "\n",
      "Fold: 16  Epoch: 64  Training loss = 4.2156  Validation loss = 6.4004  \n",
      "\n",
      "Fold: 16  Epoch: 65  Training loss = 4.2148  Validation loss = 6.3995  \n",
      "\n",
      "Fold: 16  Epoch: 66  Training loss = 4.2139  Validation loss = 6.3984  \n",
      "\n",
      "Fold: 16  Epoch: 67  Training loss = 4.2130  Validation loss = 6.3974  \n",
      "\n",
      "Fold: 16  Epoch: 68  Training loss = 4.2121  Validation loss = 6.3965  \n",
      "\n",
      "Fold: 16  Epoch: 69  Training loss = 4.2112  Validation loss = 6.3954  \n",
      "\n",
      "Fold: 16  Epoch: 70  Training loss = 4.2104  Validation loss = 6.3946  \n",
      "\n",
      "Fold: 16  Epoch: 71  Training loss = 4.2098  Validation loss = 6.3939  \n",
      "\n",
      "Fold: 16  Epoch: 72  Training loss = 4.2088  Validation loss = 6.3926  \n",
      "\n",
      "Fold: 16  Epoch: 73  Training loss = 4.2081  Validation loss = 6.3917  \n",
      "\n",
      "Fold: 16  Epoch: 74  Training loss = 4.2075  Validation loss = 6.3908  \n",
      "\n",
      "Fold: 16  Epoch: 75  Training loss = 4.2070  Validation loss = 6.3902  \n",
      "\n",
      "Fold: 16  Epoch: 76  Training loss = 4.2062  Validation loss = 6.3891  \n",
      "\n",
      "Fold: 16  Epoch: 77  Training loss = 4.2055  Validation loss = 6.3883  \n",
      "\n",
      "Fold: 16  Epoch: 78  Training loss = 4.2049  Validation loss = 6.3875  \n",
      "\n",
      "Fold: 16  Epoch: 79  Training loss = 4.2040  Validation loss = 6.3865  \n",
      "\n",
      "Fold: 16  Epoch: 80  Training loss = 4.2034  Validation loss = 6.3858  \n",
      "\n",
      "Fold: 16  Epoch: 81  Training loss = 4.2026  Validation loss = 6.3849  \n",
      "\n",
      "Fold: 16  Epoch: 82  Training loss = 4.2017  Validation loss = 6.3839  \n",
      "\n",
      "Fold: 16  Epoch: 83  Training loss = 4.2010  Validation loss = 6.3831  \n",
      "\n",
      "Fold: 16  Epoch: 84  Training loss = 4.2004  Validation loss = 6.3824  \n",
      "\n",
      "Fold: 16  Epoch: 85  Training loss = 4.1995  Validation loss = 6.3814  \n",
      "\n",
      "Fold: 16  Epoch: 86  Training loss = 4.1989  Validation loss = 6.3806  \n",
      "\n",
      "Fold: 16  Epoch: 87  Training loss = 4.1981  Validation loss = 6.3798  \n",
      "\n",
      "Fold: 16  Epoch: 88  Training loss = 4.1974  Validation loss = 6.3788  \n",
      "\n",
      "Fold: 16  Epoch: 89  Training loss = 4.1966  Validation loss = 6.3778  \n",
      "\n",
      "Fold: 16  Epoch: 90  Training loss = 4.1956  Validation loss = 6.3767  \n",
      "\n",
      "Fold: 16  Epoch: 91  Training loss = 4.1947  Validation loss = 6.3756  \n",
      "\n",
      "Fold: 16  Epoch: 92  Training loss = 4.1939  Validation loss = 6.3746  \n",
      "\n",
      "Fold: 16  Epoch: 93  Training loss = 4.1933  Validation loss = 6.3738  \n",
      "\n",
      "Fold: 16  Epoch: 94  Training loss = 4.1925  Validation loss = 6.3730  \n",
      "\n",
      "Fold: 16  Epoch: 95  Training loss = 4.1919  Validation loss = 6.3723  \n",
      "\n",
      "Fold: 16  Epoch: 96  Training loss = 4.1911  Validation loss = 6.3714  \n",
      "\n",
      "Fold: 16  Epoch: 97  Training loss = 4.1904  Validation loss = 6.3703  \n",
      "\n",
      "Fold: 16  Epoch: 98  Training loss = 4.1896  Validation loss = 6.3695  \n",
      "\n",
      "Fold: 16  Epoch: 99  Training loss = 4.1890  Validation loss = 6.3687  \n",
      "\n",
      "Fold: 16  Epoch: 100  Training loss = 4.1882  Validation loss = 6.3680  \n",
      "\n",
      "Fold: 16  Epoch: 101  Training loss = 4.1875  Validation loss = 6.3673  \n",
      "\n",
      "Fold: 16  Epoch: 102  Training loss = 4.1865  Validation loss = 6.3660  \n",
      "\n",
      "Fold: 16  Epoch: 103  Training loss = 4.1860  Validation loss = 6.3654  \n",
      "\n",
      "Fold: 16  Epoch: 104  Training loss = 4.1851  Validation loss = 6.3644  \n",
      "\n",
      "Fold: 16  Epoch: 105  Training loss = 4.1843  Validation loss = 6.3635  \n",
      "\n",
      "Fold: 16  Epoch: 106  Training loss = 4.1837  Validation loss = 6.3627  \n",
      "\n",
      "Fold: 16  Epoch: 107  Training loss = 4.1830  Validation loss = 6.3619  \n",
      "\n",
      "Fold: 16  Epoch: 108  Training loss = 4.1823  Validation loss = 6.3612  \n",
      "\n",
      "Fold: 16  Epoch: 109  Training loss = 4.1816  Validation loss = 6.3604  \n",
      "\n",
      "Fold: 16  Epoch: 110  Training loss = 4.1810  Validation loss = 6.3596  \n",
      "\n",
      "Fold: 16  Epoch: 111  Training loss = 4.1803  Validation loss = 6.3588  \n",
      "\n",
      "Fold: 16  Epoch: 112  Training loss = 4.1796  Validation loss = 6.3579  \n",
      "\n",
      "Fold: 16  Epoch: 113  Training loss = 4.1788  Validation loss = 6.3571  \n",
      "\n",
      "Fold: 16  Epoch: 114  Training loss = 4.1780  Validation loss = 6.3562  \n",
      "\n",
      "Fold: 16  Epoch: 115  Training loss = 4.1772  Validation loss = 6.3552  \n",
      "\n",
      "Fold: 16  Epoch: 116  Training loss = 4.1764  Validation loss = 6.3541  \n",
      "\n",
      "Fold: 16  Epoch: 117  Training loss = 4.1755  Validation loss = 6.3531  \n",
      "\n",
      "Fold: 16  Epoch: 118  Training loss = 4.1749  Validation loss = 6.3523  \n",
      "\n",
      "Fold: 16  Epoch: 119  Training loss = 4.1741  Validation loss = 6.3515  \n",
      "\n",
      "Fold: 16  Epoch: 120  Training loss = 4.1733  Validation loss = 6.3505  \n",
      "\n",
      "Fold: 16  Epoch: 121  Training loss = 4.1724  Validation loss = 6.3495  \n",
      "\n",
      "Fold: 16  Epoch: 122  Training loss = 4.1718  Validation loss = 6.3489  \n",
      "\n",
      "Fold: 16  Epoch: 123  Training loss = 4.1712  Validation loss = 6.3481  \n",
      "\n",
      "Fold: 16  Epoch: 124  Training loss = 4.1704  Validation loss = 6.3472  \n",
      "\n",
      "Fold: 16  Epoch: 125  Training loss = 4.1697  Validation loss = 6.3464  \n",
      "\n",
      "Fold: 16  Epoch: 126  Training loss = 4.1690  Validation loss = 6.3457  \n",
      "\n",
      "Fold: 16  Epoch: 127  Training loss = 4.1681  Validation loss = 6.3447  \n",
      "\n",
      "Fold: 16  Epoch: 128  Training loss = 4.1672  Validation loss = 6.3437  \n",
      "\n",
      "Fold: 16  Epoch: 129  Training loss = 4.1668  Validation loss = 6.3431  \n",
      "\n",
      "Fold: 16  Epoch: 130  Training loss = 4.1662  Validation loss = 6.3426  \n",
      "\n",
      "Fold: 16  Epoch: 131  Training loss = 4.1655  Validation loss = 6.3418  \n",
      "\n",
      "Fold: 16  Epoch: 132  Training loss = 4.1648  Validation loss = 6.3410  \n",
      "\n",
      "Fold: 16  Epoch: 133  Training loss = 4.1639  Validation loss = 6.3399  \n",
      "\n",
      "Fold: 16  Epoch: 134  Training loss = 4.1633  Validation loss = 6.3391  \n",
      "\n",
      "Fold: 16  Epoch: 135  Training loss = 4.1625  Validation loss = 6.3382  \n",
      "\n",
      "Fold: 16  Epoch: 136  Training loss = 4.1615  Validation loss = 6.3370  \n",
      "\n",
      "Fold: 16  Epoch: 137  Training loss = 4.1606  Validation loss = 6.3359  \n",
      "\n",
      "Fold: 16  Epoch: 138  Training loss = 4.1598  Validation loss = 6.3351  \n",
      "\n",
      "Fold: 16  Epoch: 139  Training loss = 4.1592  Validation loss = 6.3343  \n",
      "\n",
      "Fold: 16  Epoch: 140  Training loss = 4.1582  Validation loss = 6.3331  \n",
      "\n",
      "Fold: 16  Epoch: 141  Training loss = 4.1576  Validation loss = 6.3323  \n",
      "\n",
      "Fold: 16  Epoch: 142  Training loss = 4.1570  Validation loss = 6.3317  \n",
      "\n",
      "Fold: 16  Epoch: 143  Training loss = 4.1565  Validation loss = 6.3311  \n",
      "\n",
      "Fold: 16  Epoch: 144  Training loss = 4.1559  Validation loss = 6.3304  \n",
      "\n",
      "Fold: 16  Epoch: 145  Training loss = 4.1552  Validation loss = 6.3295  \n",
      "\n",
      "Fold: 16  Epoch: 146  Training loss = 4.1546  Validation loss = 6.3286  \n",
      "\n",
      "Fold: 16  Epoch: 147  Training loss = 4.1538  Validation loss = 6.3277  \n",
      "\n",
      "Fold: 16  Epoch: 148  Training loss = 4.1529  Validation loss = 6.3267  \n",
      "\n",
      "Fold: 16  Epoch: 149  Training loss = 4.1525  Validation loss = 6.3260  \n",
      "\n",
      "Fold: 16  Epoch: 150  Training loss = 4.1519  Validation loss = 6.3253  \n",
      "\n",
      "Fold: 16  Epoch: 151  Training loss = 4.1510  Validation loss = 6.3242  \n",
      "\n",
      "Fold: 16  Epoch: 152  Training loss = 4.1504  Validation loss = 6.3236  \n",
      "\n",
      "Fold: 16  Epoch: 153  Training loss = 4.1496  Validation loss = 6.3226  \n",
      "\n",
      "Fold: 16  Epoch: 154  Training loss = 4.1490  Validation loss = 6.3220  \n",
      "\n",
      "Fold: 16  Epoch: 155  Training loss = 4.1482  Validation loss = 6.3210  \n",
      "\n",
      "Fold: 16  Epoch: 156  Training loss = 4.1474  Validation loss = 6.3201  \n",
      "\n",
      "Fold: 16  Epoch: 157  Training loss = 4.1463  Validation loss = 6.3189  \n",
      "\n",
      "Fold: 16  Epoch: 158  Training loss = 4.1457  Validation loss = 6.3183  \n",
      "\n",
      "Fold: 16  Epoch: 159  Training loss = 4.1451  Validation loss = 6.3176  \n",
      "\n",
      "Fold: 16  Epoch: 160  Training loss = 4.1445  Validation loss = 6.3167  \n",
      "\n",
      "Fold: 16  Epoch: 161  Training loss = 4.1439  Validation loss = 6.3158  \n",
      "\n",
      "Fold: 16  Epoch: 162  Training loss = 4.1432  Validation loss = 6.3150  \n",
      "\n",
      "Fold: 16  Epoch: 163  Training loss = 4.1427  Validation loss = 6.3144  \n",
      "\n",
      "Fold: 16  Epoch: 164  Training loss = 4.1421  Validation loss = 6.3136  \n",
      "\n",
      "Fold: 16  Epoch: 165  Training loss = 4.1416  Validation loss = 6.3129  \n",
      "\n",
      "Fold: 16  Epoch: 166  Training loss = 4.1408  Validation loss = 6.3122  \n",
      "\n",
      "Fold: 16  Epoch: 167  Training loss = 4.1400  Validation loss = 6.3112  \n",
      "\n",
      "Fold: 16  Epoch: 168  Training loss = 4.1394  Validation loss = 6.3105  \n",
      "\n",
      "Fold: 16  Epoch: 169  Training loss = 4.1386  Validation loss = 6.3095  \n",
      "\n",
      "Fold: 16  Epoch: 170  Training loss = 4.1379  Validation loss = 6.3086  \n",
      "\n",
      "Fold: 16  Epoch: 171  Training loss = 4.1373  Validation loss = 6.3079  \n",
      "\n",
      "Fold: 16  Epoch: 172  Training loss = 4.1364  Validation loss = 6.3069  \n",
      "\n",
      "Fold: 16  Epoch: 173  Training loss = 4.1356  Validation loss = 6.3059  \n",
      "\n",
      "Fold: 16  Epoch: 174  Training loss = 4.1349  Validation loss = 6.3050  \n",
      "\n",
      "Fold: 16  Epoch: 175  Training loss = 4.1341  Validation loss = 6.3041  \n",
      "\n",
      "Fold: 16  Epoch: 176  Training loss = 4.1336  Validation loss = 6.3032  \n",
      "\n",
      "Fold: 16  Epoch: 177  Training loss = 4.1328  Validation loss = 6.3024  \n",
      "\n",
      "Fold: 16  Epoch: 178  Training loss = 4.1321  Validation loss = 6.3015  \n",
      "\n",
      "Fold: 16  Epoch: 179  Training loss = 4.1314  Validation loss = 6.3006  \n",
      "\n",
      "Fold: 16  Epoch: 180  Training loss = 4.1308  Validation loss = 6.3000  \n",
      "\n",
      "Fold: 16  Epoch: 181  Training loss = 4.1300  Validation loss = 6.2991  \n",
      "\n",
      "Fold: 16  Epoch: 182  Training loss = 4.1293  Validation loss = 6.2983  \n",
      "\n",
      "Fold: 16  Epoch: 183  Training loss = 4.1285  Validation loss = 6.2974  \n",
      "\n",
      "Fold: 16  Epoch: 184  Training loss = 4.1276  Validation loss = 6.2963  \n",
      "\n",
      "Fold: 16  Epoch: 185  Training loss = 4.1269  Validation loss = 6.2955  \n",
      "\n",
      "Fold: 16  Epoch: 186  Training loss = 4.1263  Validation loss = 6.2947  \n",
      "\n",
      "Fold: 16  Epoch: 187  Training loss = 4.1255  Validation loss = 6.2938  \n",
      "\n",
      "Fold: 16  Epoch: 188  Training loss = 4.1246  Validation loss = 6.2926  \n",
      "\n",
      "Fold: 16  Epoch: 189  Training loss = 4.1237  Validation loss = 6.2915  \n",
      "\n",
      "Fold: 16  Epoch: 190  Training loss = 4.1232  Validation loss = 6.2908  \n",
      "\n",
      "Fold: 16  Epoch: 191  Training loss = 4.1224  Validation loss = 6.2897  \n",
      "\n",
      "Fold: 16  Epoch: 192  Training loss = 4.1218  Validation loss = 6.2891  \n",
      "\n",
      "Fold: 16  Epoch: 193  Training loss = 4.1211  Validation loss = 6.2883  \n",
      "\n",
      "Fold: 16  Epoch: 194  Training loss = 4.1206  Validation loss = 6.2876  \n",
      "\n",
      "Fold: 16  Epoch: 195  Training loss = 4.1201  Validation loss = 6.2869  \n",
      "\n",
      "Fold: 16  Epoch: 196  Training loss = 4.1193  Validation loss = 6.2860  \n",
      "\n",
      "Fold: 16  Epoch: 197  Training loss = 4.1187  Validation loss = 6.2855  \n",
      "\n",
      "Fold: 16  Epoch: 198  Training loss = 4.1179  Validation loss = 6.2845  \n",
      "\n",
      "Fold: 16  Epoch: 199  Training loss = 4.1173  Validation loss = 6.2838  \n",
      "\n",
      "Fold: 16  Epoch: 200  Training loss = 4.1167  Validation loss = 6.2829  \n",
      "\n",
      "Fold: 16  Epoch: 201  Training loss = 4.1159  Validation loss = 6.2821  \n",
      "\n",
      "Fold: 16  Epoch: 202  Training loss = 4.1152  Validation loss = 6.2813  \n",
      "\n",
      "Fold: 16  Epoch: 203  Training loss = 4.1143  Validation loss = 6.2803  \n",
      "\n",
      "Fold: 16  Epoch: 204  Training loss = 4.1135  Validation loss = 6.2793  \n",
      "\n",
      "Fold: 16  Epoch: 205  Training loss = 4.1128  Validation loss = 6.2786  \n",
      "\n",
      "Fold: 16  Epoch: 206  Training loss = 4.1121  Validation loss = 6.2777  \n",
      "\n",
      "Fold: 16  Epoch: 207  Training loss = 4.1113  Validation loss = 6.2769  \n",
      "\n",
      "Fold: 16  Epoch: 208  Training loss = 4.1105  Validation loss = 6.2759  \n",
      "\n",
      "Fold: 16  Epoch: 209  Training loss = 4.1101  Validation loss = 6.2753  \n",
      "\n",
      "Fold: 16  Epoch: 210  Training loss = 4.1093  Validation loss = 6.2744  \n",
      "\n",
      "Fold: 16  Epoch: 211  Training loss = 4.1085  Validation loss = 6.2735  \n",
      "\n",
      "Fold: 16  Epoch: 212  Training loss = 4.1076  Validation loss = 6.2724  \n",
      "\n",
      "Fold: 16  Epoch: 213  Training loss = 4.1070  Validation loss = 6.2717  \n",
      "\n",
      "Fold: 16  Epoch: 214  Training loss = 4.1063  Validation loss = 6.2708  \n",
      "\n",
      "Fold: 16  Epoch: 215  Training loss = 4.1057  Validation loss = 6.2700  \n",
      "\n",
      "Fold: 16  Epoch: 216  Training loss = 4.1052  Validation loss = 6.2695  \n",
      "\n",
      "Fold: 16  Epoch: 217  Training loss = 4.1046  Validation loss = 6.2687  \n",
      "\n",
      "Fold: 16  Epoch: 218  Training loss = 4.1039  Validation loss = 6.2679  \n",
      "\n",
      "Fold: 16  Epoch: 219  Training loss = 4.1033  Validation loss = 6.2670  \n",
      "\n",
      "Fold: 16  Epoch: 220  Training loss = 4.1025  Validation loss = 6.2661  \n",
      "\n",
      "Fold: 16  Epoch: 221  Training loss = 4.1015  Validation loss = 6.2649  \n",
      "\n",
      "Fold: 16  Epoch: 222  Training loss = 4.1009  Validation loss = 6.2642  \n",
      "\n",
      "Fold: 16  Epoch: 223  Training loss = 4.1000  Validation loss = 6.2630  \n",
      "\n",
      "Fold: 16  Epoch: 224  Training loss = 4.0992  Validation loss = 6.2621  \n",
      "\n",
      "Fold: 16  Epoch: 225  Training loss = 4.0988  Validation loss = 6.2615  \n",
      "\n",
      "Fold: 16  Epoch: 226  Training loss = 4.0981  Validation loss = 6.2608  \n",
      "\n",
      "Fold: 16  Epoch: 227  Training loss = 4.0974  Validation loss = 6.2599  \n",
      "\n",
      "Fold: 16  Epoch: 228  Training loss = 4.0967  Validation loss = 6.2590  \n",
      "\n",
      "Fold: 16  Epoch: 229  Training loss = 4.0958  Validation loss = 6.2580  \n",
      "\n",
      "Fold: 16  Epoch: 230  Training loss = 4.0953  Validation loss = 6.2574  \n",
      "\n",
      "Fold: 16  Epoch: 231  Training loss = 4.0945  Validation loss = 6.2566  \n",
      "\n",
      "Fold: 16  Epoch: 232  Training loss = 4.0939  Validation loss = 6.2560  \n",
      "\n",
      "Fold: 16  Epoch: 233  Training loss = 4.0932  Validation loss = 6.2552  \n",
      "\n",
      "Fold: 16  Epoch: 234  Training loss = 4.0924  Validation loss = 6.2541  \n",
      "\n",
      "Fold: 16  Epoch: 235  Training loss = 4.0918  Validation loss = 6.2534  \n",
      "\n",
      "Fold: 16  Epoch: 236  Training loss = 4.0910  Validation loss = 6.2524  \n",
      "\n",
      "Fold: 16  Epoch: 237  Training loss = 4.0902  Validation loss = 6.2516  \n",
      "\n",
      "Fold: 16  Epoch: 238  Training loss = 4.0895  Validation loss = 6.2508  \n",
      "\n",
      "Fold: 16  Epoch: 239  Training loss = 4.0890  Validation loss = 6.2502  \n",
      "\n",
      "Fold: 16  Epoch: 240  Training loss = 4.0884  Validation loss = 6.2494  \n",
      "\n",
      "Fold: 16  Epoch: 241  Training loss = 4.0875  Validation loss = 6.2482  \n",
      "\n",
      "Fold: 16  Epoch: 242  Training loss = 4.0866  Validation loss = 6.2475  \n",
      "\n",
      "Fold: 16  Epoch: 243  Training loss = 4.0861  Validation loss = 6.2467  \n",
      "\n",
      "Fold: 16  Epoch: 244  Training loss = 4.0854  Validation loss = 6.2461  \n",
      "\n",
      "Fold: 16  Epoch: 245  Training loss = 4.0848  Validation loss = 6.2452  \n",
      "\n",
      "Fold: 16  Epoch: 246  Training loss = 4.0840  Validation loss = 6.2443  \n",
      "\n",
      "Fold: 16  Epoch: 247  Training loss = 4.0830  Validation loss = 6.2433  \n",
      "\n",
      "Fold: 16  Epoch: 248  Training loss = 4.0822  Validation loss = 6.2423  \n",
      "\n",
      "Fold: 16  Epoch: 249  Training loss = 4.0815  Validation loss = 6.2414  \n",
      "\n",
      "Fold: 16  Epoch: 250  Training loss = 4.0808  Validation loss = 6.2405  \n",
      "\n",
      "Fold: 16  Epoch: 251  Training loss = 4.0800  Validation loss = 6.2396  \n",
      "\n",
      "Fold: 16  Epoch: 252  Training loss = 4.0794  Validation loss = 6.2390  \n",
      "\n",
      "Fold: 16  Epoch: 253  Training loss = 4.0788  Validation loss = 6.2384  \n",
      "\n",
      "Fold: 16  Epoch: 254  Training loss = 4.0782  Validation loss = 6.2375  \n",
      "\n",
      "Fold: 16  Epoch: 255  Training loss = 4.0776  Validation loss = 6.2368  \n",
      "\n",
      "Fold: 16  Epoch: 256  Training loss = 4.0768  Validation loss = 6.2357  \n",
      "\n",
      "Fold: 16  Epoch: 257  Training loss = 4.0760  Validation loss = 6.2349  \n",
      "\n",
      "Fold: 16  Epoch: 258  Training loss = 4.0753  Validation loss = 6.2341  \n",
      "\n",
      "Fold: 16  Epoch: 259  Training loss = 4.0745  Validation loss = 6.2331  \n",
      "\n",
      "Fold: 16  Epoch: 260  Training loss = 4.0740  Validation loss = 6.2326  \n",
      "\n",
      "Fold: 16  Epoch: 261  Training loss = 4.0732  Validation loss = 6.2316  \n",
      "\n",
      "Fold: 16  Epoch: 262  Training loss = 4.0727  Validation loss = 6.2310  \n",
      "\n",
      "Fold: 16  Epoch: 263  Training loss = 4.0718  Validation loss = 6.2299  \n",
      "\n",
      "Fold: 16  Epoch: 264  Training loss = 4.0709  Validation loss = 6.2290  \n",
      "\n",
      "Fold: 16  Epoch: 265  Training loss = 4.0704  Validation loss = 6.2283  \n",
      "\n",
      "Fold: 16  Epoch: 266  Training loss = 4.0698  Validation loss = 6.2277  \n",
      "\n",
      "Fold: 16  Epoch: 267  Training loss = 4.0692  Validation loss = 6.2269  \n",
      "\n",
      "Fold: 16  Epoch: 268  Training loss = 4.0683  Validation loss = 6.2258  \n",
      "\n",
      "Fold: 16  Epoch: 269  Training loss = 4.0676  Validation loss = 6.2251  \n",
      "\n",
      "Fold: 16  Epoch: 270  Training loss = 4.0670  Validation loss = 6.2244  \n",
      "\n",
      "Fold: 16  Epoch: 271  Training loss = 4.0663  Validation loss = 6.2234  \n",
      "\n",
      "Fold: 16  Epoch: 272  Training loss = 4.0656  Validation loss = 6.2227  \n",
      "\n",
      "Fold: 16  Epoch: 273  Training loss = 4.0649  Validation loss = 6.2218  \n",
      "\n",
      "Fold: 16  Epoch: 274  Training loss = 4.0641  Validation loss = 6.2208  \n",
      "\n",
      "Fold: 16  Epoch: 275  Training loss = 4.0635  Validation loss = 6.2200  \n",
      "\n",
      "Fold: 16  Epoch: 276  Training loss = 4.0628  Validation loss = 6.2191  \n",
      "\n",
      "Fold: 16  Epoch: 277  Training loss = 4.0623  Validation loss = 6.2185  \n",
      "\n",
      "Fold: 16  Epoch: 278  Training loss = 4.0617  Validation loss = 6.2177  \n",
      "\n",
      "Fold: 16  Epoch: 279  Training loss = 4.0611  Validation loss = 6.2170  \n",
      "\n",
      "Fold: 16  Epoch: 280  Training loss = 4.0605  Validation loss = 6.2162  \n",
      "\n",
      "Fold: 16  Epoch: 281  Training loss = 4.0598  Validation loss = 6.2152  \n",
      "\n",
      "Fold: 16  Epoch: 282  Training loss = 4.0590  Validation loss = 6.2142  \n",
      "\n",
      "Fold: 16  Epoch: 283  Training loss = 4.0582  Validation loss = 6.2133  \n",
      "\n",
      "Fold: 16  Epoch: 284  Training loss = 4.0575  Validation loss = 6.2124  \n",
      "\n",
      "Fold: 16  Epoch: 285  Training loss = 4.0567  Validation loss = 6.2116  \n",
      "\n",
      "Fold: 16  Epoch: 286  Training loss = 4.0561  Validation loss = 6.2108  \n",
      "\n",
      "Fold: 16  Epoch: 287  Training loss = 4.0554  Validation loss = 6.2100  \n",
      "\n",
      "Fold: 16  Epoch: 288  Training loss = 4.0548  Validation loss = 6.2094  \n",
      "\n",
      "Fold: 16  Epoch: 289  Training loss = 4.0538  Validation loss = 6.2083  \n",
      "\n",
      "Fold: 16  Epoch: 290  Training loss = 4.0532  Validation loss = 6.2076  \n",
      "\n",
      "Fold: 16  Epoch: 291  Training loss = 4.0527  Validation loss = 6.2069  \n",
      "\n",
      "Fold: 16  Epoch: 292  Training loss = 4.0522  Validation loss = 6.2062  \n",
      "\n",
      "Fold: 16  Epoch: 293  Training loss = 4.0515  Validation loss = 6.2056  \n",
      "\n",
      "Fold: 16  Epoch: 294  Training loss = 4.0511  Validation loss = 6.2050  \n",
      "\n",
      "Fold: 16  Epoch: 295  Training loss = 4.0505  Validation loss = 6.2042  \n",
      "\n",
      "Fold: 16  Epoch: 296  Training loss = 4.0498  Validation loss = 6.2033  \n",
      "\n",
      "Fold: 16  Epoch: 297  Training loss = 4.0489  Validation loss = 6.2023  \n",
      "\n",
      "Fold: 16  Epoch: 298  Training loss = 4.0482  Validation loss = 6.2015  \n",
      "\n",
      "Fold: 16  Epoch: 299  Training loss = 4.0475  Validation loss = 6.2006  \n",
      "\n",
      "Fold: 16  Epoch: 300  Training loss = 4.0468  Validation loss = 6.1996  \n",
      "\n",
      "Fold: 16  Epoch: 301  Training loss = 4.0463  Validation loss = 6.1990  \n",
      "\n",
      "Fold: 16  Epoch: 302  Training loss = 4.0455  Validation loss = 6.1980  \n",
      "\n",
      "Fold: 16  Epoch: 303  Training loss = 4.0448  Validation loss = 6.1971  \n",
      "\n",
      "Fold: 16  Epoch: 304  Training loss = 4.0442  Validation loss = 6.1963  \n",
      "\n",
      "Fold: 16  Epoch: 305  Training loss = 4.0433  Validation loss = 6.1952  \n",
      "\n",
      "Fold: 16  Epoch: 306  Training loss = 4.0426  Validation loss = 6.1943  \n",
      "\n",
      "Fold: 16  Epoch: 307  Training loss = 4.0417  Validation loss = 6.1935  \n",
      "\n",
      "Fold: 16  Epoch: 308  Training loss = 4.0413  Validation loss = 6.1929  \n",
      "\n",
      "Fold: 16  Epoch: 309  Training loss = 4.0407  Validation loss = 6.1921  \n",
      "\n",
      "Fold: 16  Epoch: 310  Training loss = 4.0399  Validation loss = 6.1911  \n",
      "\n",
      "Fold: 16  Epoch: 311  Training loss = 4.0391  Validation loss = 6.1901  \n",
      "\n",
      "Fold: 16  Epoch: 312  Training loss = 4.0387  Validation loss = 6.1897  \n",
      "\n",
      "Fold: 16  Epoch: 313  Training loss = 4.0381  Validation loss = 6.1889  \n",
      "\n",
      "Fold: 16  Epoch: 314  Training loss = 4.0376  Validation loss = 6.1882  \n",
      "\n",
      "Fold: 16  Epoch: 315  Training loss = 4.0370  Validation loss = 6.1874  \n",
      "\n",
      "Fold: 16  Epoch: 316  Training loss = 4.0363  Validation loss = 6.1865  \n",
      "\n",
      "Fold: 16  Epoch: 317  Training loss = 4.0357  Validation loss = 6.1857  \n",
      "\n",
      "Fold: 16  Epoch: 318  Training loss = 4.0350  Validation loss = 6.1848  \n",
      "\n",
      "Fold: 16  Epoch: 319  Training loss = 4.0347  Validation loss = 6.1844  \n",
      "\n",
      "Fold: 16  Epoch: 320  Training loss = 4.0340  Validation loss = 6.1835  \n",
      "\n",
      "Fold: 16  Epoch: 321  Training loss = 4.0333  Validation loss = 6.1827  \n",
      "\n",
      "Fold: 16  Epoch: 322  Training loss = 4.0326  Validation loss = 6.1819  \n",
      "\n",
      "Fold: 16  Epoch: 323  Training loss = 4.0318  Validation loss = 6.1809  \n",
      "\n",
      "Fold: 16  Epoch: 324  Training loss = 4.0311  Validation loss = 6.1800  \n",
      "\n",
      "Fold: 16  Epoch: 325  Training loss = 4.0305  Validation loss = 6.1793  \n",
      "\n",
      "Fold: 16  Epoch: 326  Training loss = 4.0299  Validation loss = 6.1787  \n",
      "\n",
      "Fold: 16  Epoch: 327  Training loss = 4.0292  Validation loss = 6.1777  \n",
      "\n",
      "Fold: 16  Epoch: 328  Training loss = 4.0283  Validation loss = 6.1767  \n",
      "\n",
      "Fold: 16  Epoch: 329  Training loss = 4.0278  Validation loss = 6.1760  \n",
      "\n",
      "Fold: 16  Epoch: 330  Training loss = 4.0271  Validation loss = 6.1752  \n",
      "\n",
      "Fold: 16  Epoch: 331  Training loss = 4.0265  Validation loss = 6.1745  \n",
      "\n",
      "Fold: 16  Epoch: 332  Training loss = 4.0260  Validation loss = 6.1737  \n",
      "\n",
      "Fold: 16  Epoch: 333  Training loss = 4.0253  Validation loss = 6.1728  \n",
      "\n",
      "Fold: 16  Epoch: 334  Training loss = 4.0247  Validation loss = 6.1722  \n",
      "\n",
      "Fold: 16  Epoch: 335  Training loss = 4.0242  Validation loss = 6.1716  \n",
      "\n",
      "Fold: 16  Epoch: 336  Training loss = 4.0236  Validation loss = 6.1708  \n",
      "\n",
      "Fold: 16  Epoch: 337  Training loss = 4.0230  Validation loss = 6.1702  \n",
      "\n",
      "Fold: 16  Epoch: 338  Training loss = 4.0223  Validation loss = 6.1693  \n",
      "\n",
      "Fold: 16  Epoch: 339  Training loss = 4.0216  Validation loss = 6.1685  \n",
      "\n",
      "Fold: 16  Epoch: 340  Training loss = 4.0207  Validation loss = 6.1675  \n",
      "\n",
      "Fold: 16  Epoch: 341  Training loss = 4.0198  Validation loss = 6.1664  \n",
      "\n",
      "Fold: 16  Epoch: 342  Training loss = 4.0191  Validation loss = 6.1655  \n",
      "\n",
      "Fold: 16  Epoch: 343  Training loss = 4.0184  Validation loss = 6.1647  \n",
      "\n",
      "Fold: 16  Epoch: 344  Training loss = 4.0176  Validation loss = 6.1639  \n",
      "\n",
      "Fold: 16  Epoch: 345  Training loss = 4.0171  Validation loss = 6.1633  \n",
      "\n",
      "Fold: 16  Epoch: 346  Training loss = 4.0163  Validation loss = 6.1623  \n",
      "\n",
      "Fold: 16  Epoch: 347  Training loss = 4.0155  Validation loss = 6.1614  \n",
      "\n",
      "Fold: 16  Epoch: 348  Training loss = 4.0150  Validation loss = 6.1607  \n",
      "\n",
      "Fold: 16  Epoch: 349  Training loss = 4.0143  Validation loss = 6.1599  \n",
      "\n",
      "Fold: 16  Epoch: 350  Training loss = 4.0137  Validation loss = 6.1591  \n",
      "\n",
      "Fold: 16  Epoch: 351  Training loss = 4.0132  Validation loss = 6.1585  \n",
      "\n",
      "Fold: 16  Epoch: 352  Training loss = 4.0123  Validation loss = 6.1575  \n",
      "\n",
      "Fold: 16  Epoch: 353  Training loss = 4.0115  Validation loss = 6.1565  \n",
      "\n",
      "Fold: 16  Epoch: 354  Training loss = 4.0109  Validation loss = 6.1558  \n",
      "\n",
      "Fold: 16  Epoch: 355  Training loss = 4.0101  Validation loss = 6.1548  \n",
      "\n",
      "Fold: 16  Epoch: 356  Training loss = 4.0094  Validation loss = 6.1540  \n",
      "\n",
      "Fold: 16  Epoch: 357  Training loss = 4.0087  Validation loss = 6.1531  \n",
      "\n",
      "Fold: 16  Epoch: 358  Training loss = 4.0081  Validation loss = 6.1523  \n",
      "\n",
      "Fold: 16  Epoch: 359  Training loss = 4.0074  Validation loss = 6.1515  \n",
      "\n",
      "Fold: 16  Epoch: 360  Training loss = 4.0066  Validation loss = 6.1506  \n",
      "\n",
      "Fold: 16  Epoch: 361  Training loss = 4.0060  Validation loss = 6.1498  \n",
      "\n",
      "Fold: 16  Epoch: 362  Training loss = 4.0055  Validation loss = 6.1493  \n",
      "\n",
      "Fold: 16  Epoch: 363  Training loss = 4.0048  Validation loss = 6.1484  \n",
      "\n",
      "Fold: 16  Epoch: 364  Training loss = 4.0045  Validation loss = 6.1480  \n",
      "\n",
      "Fold: 16  Epoch: 365  Training loss = 4.0039  Validation loss = 6.1472  \n",
      "\n",
      "Fold: 16  Epoch: 366  Training loss = 4.0033  Validation loss = 6.1465  \n",
      "\n",
      "Fold: 16  Epoch: 367  Training loss = 4.0026  Validation loss = 6.1456  \n",
      "\n",
      "Fold: 16  Epoch: 368  Training loss = 4.0021  Validation loss = 6.1449  \n",
      "\n",
      "Fold: 16  Epoch: 369  Training loss = 4.0015  Validation loss = 6.1441  \n",
      "\n",
      "Fold: 16  Epoch: 370  Training loss = 4.0008  Validation loss = 6.1433  \n",
      "\n",
      "Fold: 16  Epoch: 371  Training loss = 4.0001  Validation loss = 6.1425  \n",
      "\n",
      "Fold: 16  Epoch: 372  Training loss = 3.9995  Validation loss = 6.1417  \n",
      "\n",
      "Fold: 16  Epoch: 373  Training loss = 3.9988  Validation loss = 6.1407  \n",
      "\n",
      "Fold: 16  Epoch: 374  Training loss = 3.9981  Validation loss = 6.1398  \n",
      "\n",
      "Fold: 16  Epoch: 375  Training loss = 3.9975  Validation loss = 6.1390  \n",
      "\n",
      "Fold: 16  Epoch: 376  Training loss = 3.9969  Validation loss = 6.1383  \n",
      "\n",
      "Fold: 16  Epoch: 377  Training loss = 3.9964  Validation loss = 6.1378  \n",
      "\n",
      "Fold: 16  Epoch: 378  Training loss = 3.9957  Validation loss = 6.1369  \n",
      "\n",
      "Fold: 16  Epoch: 379  Training loss = 3.9951  Validation loss = 6.1361  \n",
      "\n",
      "Fold: 16  Epoch: 380  Training loss = 3.9945  Validation loss = 6.1354  \n",
      "\n",
      "Fold: 16  Epoch: 381  Training loss = 3.9938  Validation loss = 6.1347  \n",
      "\n",
      "Fold: 16  Epoch: 382  Training loss = 3.9929  Validation loss = 6.1336  \n",
      "\n",
      "Fold: 16  Epoch: 383  Training loss = 3.9924  Validation loss = 6.1330  \n",
      "\n",
      "Fold: 16  Epoch: 384  Training loss = 3.9918  Validation loss = 6.1322  \n",
      "\n",
      "Fold: 16  Epoch: 385  Training loss = 3.9914  Validation loss = 6.1316  \n",
      "\n",
      "Fold: 16  Epoch: 386  Training loss = 3.9909  Validation loss = 6.1311  \n",
      "\n",
      "Fold: 16  Epoch: 387  Training loss = 3.9904  Validation loss = 6.1305  \n",
      "\n",
      "Fold: 16  Epoch: 388  Training loss = 3.9898  Validation loss = 6.1297  \n",
      "\n",
      "Fold: 16  Epoch: 389  Training loss = 3.9891  Validation loss = 6.1289  \n",
      "\n",
      "Fold: 16  Epoch: 390  Training loss = 3.9884  Validation loss = 6.1281  \n",
      "\n",
      "Fold: 16  Epoch: 391  Training loss = 3.9878  Validation loss = 6.1273  \n",
      "\n",
      "Fold: 16  Epoch: 392  Training loss = 3.9872  Validation loss = 6.1264  \n",
      "\n",
      "Fold: 16  Epoch: 393  Training loss = 3.9864  Validation loss = 6.1255  \n",
      "\n",
      "Fold: 16  Epoch: 394  Training loss = 3.9860  Validation loss = 6.1250  \n",
      "\n",
      "Fold: 16  Epoch: 395  Training loss = 3.9852  Validation loss = 6.1240  \n",
      "\n",
      "Fold: 16  Epoch: 396  Training loss = 3.9845  Validation loss = 6.1233  \n",
      "\n",
      "Fold: 16  Epoch: 397  Training loss = 3.9838  Validation loss = 6.1225  \n",
      "\n",
      "Fold: 16  Epoch: 398  Training loss = 3.9832  Validation loss = 6.1217  \n",
      "\n",
      "Fold: 16  Epoch: 399  Training loss = 3.9825  Validation loss = 6.1208  \n",
      "\n",
      "Fold: 16  Epoch: 400  Training loss = 3.9818  Validation loss = 6.1199  \n",
      "\n",
      "Fold: 16  Epoch: 401  Training loss = 3.9809  Validation loss = 6.1187  \n",
      "\n",
      "Fold: 16  Epoch: 402  Training loss = 3.9803  Validation loss = 6.1180  \n",
      "\n",
      "Fold: 16  Epoch: 403  Training loss = 3.9799  Validation loss = 6.1175  \n",
      "\n",
      "Fold: 16  Epoch: 404  Training loss = 3.9791  Validation loss = 6.1165  \n",
      "\n",
      "Fold: 16  Epoch: 405  Training loss = 3.9785  Validation loss = 6.1157  \n",
      "\n",
      "Fold: 16  Epoch: 406  Training loss = 3.9778  Validation loss = 6.1148  \n",
      "\n",
      "Fold: 16  Epoch: 407  Training loss = 3.9769  Validation loss = 6.1137  \n",
      "\n",
      "Fold: 16  Epoch: 408  Training loss = 3.9764  Validation loss = 6.1130  \n",
      "\n",
      "Fold: 16  Epoch: 409  Training loss = 3.9757  Validation loss = 6.1122  \n",
      "\n",
      "Fold: 16  Epoch: 410  Training loss = 3.9750  Validation loss = 6.1112  \n",
      "\n",
      "Fold: 16  Epoch: 411  Training loss = 3.9743  Validation loss = 6.1104  \n",
      "\n",
      "Fold: 16  Epoch: 412  Training loss = 3.9739  Validation loss = 6.1097  \n",
      "\n",
      "Fold: 16  Epoch: 413  Training loss = 3.9730  Validation loss = 6.1088  \n",
      "\n",
      "Fold: 16  Epoch: 414  Training loss = 3.9725  Validation loss = 6.1080  \n",
      "\n",
      "Fold: 16  Epoch: 415  Training loss = 3.9720  Validation loss = 6.1075  \n",
      "\n",
      "Fold: 16  Epoch: 416  Training loss = 3.9712  Validation loss = 6.1064  \n",
      "\n",
      "Fold: 16  Epoch: 417  Training loss = 3.9707  Validation loss = 6.1057  \n",
      "\n",
      "Fold: 16  Epoch: 418  Training loss = 3.9701  Validation loss = 6.1050  \n",
      "\n",
      "Fold: 16  Epoch: 419  Training loss = 3.9692  Validation loss = 6.1040  \n",
      "\n",
      "Fold: 16  Epoch: 420  Training loss = 3.9688  Validation loss = 6.1035  \n",
      "\n",
      "Fold: 16  Epoch: 421  Training loss = 3.9681  Validation loss = 6.1027  \n",
      "\n",
      "Fold: 16  Epoch: 422  Training loss = 3.9675  Validation loss = 6.1019  \n",
      "\n",
      "Fold: 16  Epoch: 423  Training loss = 3.9667  Validation loss = 6.1009  \n",
      "\n",
      "Fold: 16  Epoch: 424  Training loss = 3.9660  Validation loss = 6.1001  \n",
      "\n",
      "Fold: 16  Epoch: 425  Training loss = 3.9655  Validation loss = 6.0993  \n",
      "\n",
      "Fold: 16  Epoch: 426  Training loss = 3.9650  Validation loss = 6.0988  \n",
      "\n",
      "Fold: 16  Epoch: 427  Training loss = 3.9644  Validation loss = 6.0981  \n",
      "\n",
      "Fold: 16  Epoch: 428  Training loss = 3.9639  Validation loss = 6.0972  \n",
      "\n",
      "Fold: 16  Epoch: 429  Training loss = 3.9631  Validation loss = 6.0963  \n",
      "\n",
      "Fold: 16  Epoch: 430  Training loss = 3.9625  Validation loss = 6.0957  \n",
      "\n",
      "Fold: 16  Epoch: 431  Training loss = 3.9620  Validation loss = 6.0950  \n",
      "\n",
      "Fold: 16  Epoch: 432  Training loss = 3.9614  Validation loss = 6.0942  \n",
      "\n",
      "Fold: 16  Epoch: 433  Training loss = 3.9608  Validation loss = 6.0934  \n",
      "\n",
      "Fold: 16  Epoch: 434  Training loss = 3.9602  Validation loss = 6.0926  \n",
      "\n",
      "Fold: 16  Epoch: 435  Training loss = 3.9595  Validation loss = 6.0917  \n",
      "\n",
      "Fold: 16  Epoch: 436  Training loss = 3.9588  Validation loss = 6.0907  \n",
      "\n",
      "Fold: 16  Epoch: 437  Training loss = 3.9583  Validation loss = 6.0899  \n",
      "\n",
      "Fold: 16  Epoch: 438  Training loss = 3.9576  Validation loss = 6.0891  \n",
      "\n",
      "Fold: 16  Epoch: 439  Training loss = 3.9570  Validation loss = 6.0884  \n",
      "\n",
      "Fold: 16  Epoch: 440  Training loss = 3.9565  Validation loss = 6.0877  \n",
      "\n",
      "Fold: 16  Epoch: 441  Training loss = 3.9557  Validation loss = 6.0867  \n",
      "\n",
      "Fold: 16  Epoch: 442  Training loss = 3.9550  Validation loss = 6.0858  \n",
      "\n",
      "Fold: 16  Epoch: 443  Training loss = 3.9545  Validation loss = 6.0851  \n",
      "\n",
      "Fold: 16  Epoch: 444  Training loss = 3.9538  Validation loss = 6.0842  \n",
      "\n",
      "Fold: 16  Epoch: 445  Training loss = 3.9533  Validation loss = 6.0835  \n",
      "\n",
      "Fold: 16  Epoch: 446  Training loss = 3.9526  Validation loss = 6.0826  \n",
      "\n",
      "Fold: 16  Epoch: 447  Training loss = 3.9520  Validation loss = 6.0819  \n",
      "\n",
      "Fold: 16  Epoch: 448  Training loss = 3.9510  Validation loss = 6.0808  \n",
      "\n",
      "Fold: 16  Epoch: 449  Training loss = 3.9503  Validation loss = 6.0799  \n",
      "\n",
      "Fold: 16  Epoch: 450  Training loss = 3.9497  Validation loss = 6.0792  \n",
      "\n",
      "Fold: 16  Epoch: 451  Training loss = 3.9492  Validation loss = 6.0786  \n",
      "\n",
      "Fold: 16  Epoch: 452  Training loss = 3.9486  Validation loss = 6.0778  \n",
      "\n",
      "Fold: 16  Epoch: 453  Training loss = 3.9482  Validation loss = 6.0774  \n",
      "\n",
      "Fold: 16  Epoch: 454  Training loss = 3.9477  Validation loss = 6.0767  \n",
      "\n",
      "Fold: 16  Epoch: 455  Training loss = 3.9469  Validation loss = 6.0758  \n",
      "\n",
      "Fold: 16  Epoch: 456  Training loss = 3.9464  Validation loss = 6.0751  \n",
      "\n",
      "Fold: 16  Epoch: 457  Training loss = 3.9457  Validation loss = 6.0743  \n",
      "\n",
      "Fold: 16  Epoch: 458  Training loss = 3.9452  Validation loss = 6.0736  \n",
      "\n",
      "Fold: 16  Epoch: 459  Training loss = 3.9446  Validation loss = 6.0727  \n",
      "\n",
      "Fold: 16  Epoch: 460  Training loss = 3.9440  Validation loss = 6.0720  \n",
      "\n",
      "Fold: 16  Epoch: 461  Training loss = 3.9434  Validation loss = 6.0711  \n",
      "\n",
      "Fold: 16  Epoch: 462  Training loss = 3.9426  Validation loss = 6.0701  \n",
      "\n",
      "Fold: 16  Epoch: 463  Training loss = 3.9420  Validation loss = 6.0693  \n",
      "\n",
      "Fold: 16  Epoch: 464  Training loss = 3.9415  Validation loss = 6.0686  \n",
      "\n",
      "Fold: 16  Epoch: 465  Training loss = 3.9409  Validation loss = 6.0677  \n",
      "\n",
      "Fold: 16  Epoch: 466  Training loss = 3.9402  Validation loss = 6.0666  \n",
      "\n",
      "Fold: 16  Epoch: 467  Training loss = 3.9396  Validation loss = 6.0659  \n",
      "\n",
      "Fold: 16  Epoch: 468  Training loss = 3.9390  Validation loss = 6.0649  \n",
      "\n",
      "Fold: 16  Epoch: 469  Training loss = 3.9383  Validation loss = 6.0640  \n",
      "\n",
      "Fold: 16  Epoch: 470  Training loss = 3.9379  Validation loss = 6.0635  \n",
      "\n",
      "Fold: 16  Epoch: 471  Training loss = 3.9371  Validation loss = 6.0624  \n",
      "\n",
      "Fold: 16  Epoch: 472  Training loss = 3.9366  Validation loss = 6.0618  \n",
      "\n",
      "Fold: 16  Epoch: 473  Training loss = 3.9360  Validation loss = 6.0611  \n",
      "\n",
      "Fold: 16  Epoch: 474  Training loss = 3.9353  Validation loss = 6.0602  \n",
      "\n",
      "Fold: 16  Epoch: 475  Training loss = 3.9347  Validation loss = 6.0594  \n",
      "\n",
      "Fold: 16  Epoch: 476  Training loss = 3.9343  Validation loss = 6.0585  \n",
      "\n",
      "Fold: 16  Epoch: 477  Training loss = 3.9336  Validation loss = 6.0577  \n",
      "\n",
      "Fold: 16  Epoch: 478  Training loss = 3.9330  Validation loss = 6.0569  \n",
      "\n",
      "Fold: 16  Epoch: 479  Training loss = 3.9324  Validation loss = 6.0561  \n",
      "\n",
      "Fold: 16  Epoch: 480  Training loss = 3.9317  Validation loss = 6.0552  \n",
      "\n",
      "Fold: 16  Epoch: 481  Training loss = 3.9312  Validation loss = 6.0546  \n",
      "\n",
      "Fold: 16  Epoch: 482  Training loss = 3.9305  Validation loss = 6.0538  \n",
      "\n",
      "Fold: 16  Epoch: 483  Training loss = 3.9298  Validation loss = 6.0528  \n",
      "\n",
      "Fold: 16  Epoch: 484  Training loss = 3.9293  Validation loss = 6.0519  \n",
      "\n",
      "Fold: 16  Epoch: 485  Training loss = 3.9287  Validation loss = 6.0512  \n",
      "\n",
      "Fold: 16  Epoch: 486  Training loss = 3.9280  Validation loss = 6.0500  \n",
      "\n",
      "Fold: 16  Epoch: 487  Training loss = 3.9274  Validation loss = 6.0494  \n",
      "\n",
      "Fold: 16  Epoch: 488  Training loss = 3.9268  Validation loss = 6.0485  \n",
      "\n",
      "Fold: 16  Epoch: 489  Training loss = 3.9260  Validation loss = 6.0475  \n",
      "\n",
      "Fold: 16  Epoch: 490  Training loss = 3.9255  Validation loss = 6.0470  \n",
      "\n",
      "Fold: 16  Epoch: 491  Training loss = 3.9248  Validation loss = 6.0461  \n",
      "\n",
      "Fold: 16  Epoch: 492  Training loss = 3.9242  Validation loss = 6.0454  \n",
      "\n",
      "Fold: 16  Epoch: 493  Training loss = 3.9238  Validation loss = 6.0447  \n",
      "\n",
      "Fold: 16  Epoch: 494  Training loss = 3.9230  Validation loss = 6.0437  \n",
      "\n",
      "Fold: 16  Epoch: 495  Training loss = 3.9224  Validation loss = 6.0431  \n",
      "\n",
      "Fold: 16  Epoch: 496  Training loss = 3.9220  Validation loss = 6.0426  \n",
      "\n",
      "Fold: 16  Epoch: 497  Training loss = 3.9214  Validation loss = 6.0417  \n",
      "\n",
      "Fold: 16  Epoch: 498  Training loss = 3.9209  Validation loss = 6.0410  \n",
      "\n",
      "Fold: 16  Epoch: 499  Training loss = 3.9201  Validation loss = 6.0401  \n",
      "\n",
      "Fold: 16  Epoch: 500  Training loss = 3.9195  Validation loss = 6.0391  \n",
      "\n",
      "Check model:  Fold: 16  Epoch: 500  Training loss = 3.9195  Validation loss = 6.0391  \n",
      "\n",
      "Fold: 17  Epoch: 1  Training loss = 4.1660  Validation loss = 3.1315  \n",
      "\n",
      "Fold: 17  Epoch: 2  Training loss = 4.1652  Validation loss = 3.1316  \n",
      "\n",
      "Fold: 17  Epoch: 3  Training loss = 4.1644  Validation loss = 3.1318  \n",
      "\n",
      "Fold: 17  Epoch: 4  Training loss = 4.1635  Validation loss = 3.1320  \n",
      "\n",
      "Fold: 17  Epoch: 5  Training loss = 4.1626  Validation loss = 3.1322  \n",
      "\n",
      "Fold: 17  Epoch: 6  Training loss = 4.1618  Validation loss = 3.1324  \n",
      "\n",
      "Fold: 17  Epoch: 7  Training loss = 4.1611  Validation loss = 3.1326  \n",
      "\n",
      "Fold: 17  Epoch: 8  Training loss = 4.1603  Validation loss = 3.1327  \n",
      "\n",
      "Fold: 17  Epoch: 9  Training loss = 4.1597  Validation loss = 3.1329  \n",
      "\n",
      "Fold: 17  Epoch: 10  Training loss = 4.1588  Validation loss = 3.1331  \n",
      "\n",
      "Fold: 17  Epoch: 11  Training loss = 4.1582  Validation loss = 3.1333  \n",
      "\n",
      "Check model:  Fold: 17  Epoch: 1  Training loss = 4.1582  Validation loss = 3.1333  \n",
      "\n",
      "Fold: 18  Epoch: 1  Training loss = 4.2265  Validation loss = 2.0841  \n",
      "\n",
      "Fold: 18  Epoch: 2  Training loss = 4.2259  Validation loss = 2.0841  \n",
      "\n",
      "Fold: 18  Epoch: 3  Training loss = 4.2252  Validation loss = 2.0840  \n",
      "\n",
      "Fold: 18  Epoch: 4  Training loss = 4.2246  Validation loss = 2.0840  \n",
      "\n",
      "Fold: 18  Epoch: 5  Training loss = 4.2239  Validation loss = 2.0840  \n",
      "\n",
      "Fold: 18  Epoch: 6  Training loss = 4.2229  Validation loss = 2.0839  \n",
      "\n",
      "Fold: 18  Epoch: 7  Training loss = 4.2222  Validation loss = 2.0839  \n",
      "\n",
      "Fold: 18  Epoch: 8  Training loss = 4.2214  Validation loss = 2.0838  \n",
      "\n",
      "Fold: 18  Epoch: 9  Training loss = 4.2206  Validation loss = 2.0838  \n",
      "\n",
      "Fold: 18  Epoch: 10  Training loss = 4.2198  Validation loss = 2.0837  \n",
      "\n",
      "Fold: 18  Epoch: 11  Training loss = 4.2192  Validation loss = 2.0837  \n",
      "\n",
      "Fold: 18  Epoch: 12  Training loss = 4.2185  Validation loss = 2.0836  \n",
      "\n",
      "Fold: 18  Epoch: 13  Training loss = 4.2178  Validation loss = 2.0836  \n",
      "\n",
      "Fold: 18  Epoch: 14  Training loss = 4.2170  Validation loss = 2.0836  \n",
      "\n",
      "Fold: 18  Epoch: 15  Training loss = 4.2161  Validation loss = 2.0836  \n",
      "\n",
      "Fold: 18  Epoch: 16  Training loss = 4.2154  Validation loss = 2.0836  \n",
      "\n",
      "Fold: 18  Epoch: 17  Training loss = 4.2147  Validation loss = 2.0835  \n",
      "\n",
      "Fold: 18  Epoch: 18  Training loss = 4.2141  Validation loss = 2.0835  \n",
      "\n",
      "Fold: 18  Epoch: 19  Training loss = 4.2135  Validation loss = 2.0835  \n",
      "\n",
      "Fold: 18  Epoch: 20  Training loss = 4.2129  Validation loss = 2.0834  \n",
      "\n",
      "Fold: 18  Epoch: 21  Training loss = 4.2121  Validation loss = 2.0834  \n",
      "\n",
      "Fold: 18  Epoch: 22  Training loss = 4.2115  Validation loss = 2.0833  \n",
      "\n",
      "Fold: 18  Epoch: 23  Training loss = 4.2109  Validation loss = 2.0833  \n",
      "\n",
      "Fold: 18  Epoch: 24  Training loss = 4.2100  Validation loss = 2.0833  \n",
      "\n",
      "Fold: 18  Epoch: 25  Training loss = 4.2094  Validation loss = 2.0832  \n",
      "\n",
      "Fold: 18  Epoch: 26  Training loss = 4.2087  Validation loss = 2.0832  \n",
      "\n",
      "Fold: 18  Epoch: 27  Training loss = 4.2077  Validation loss = 2.0831  \n",
      "\n",
      "Fold: 18  Epoch: 28  Training loss = 4.2069  Validation loss = 2.0831  \n",
      "\n",
      "Fold: 18  Epoch: 29  Training loss = 4.2060  Validation loss = 2.0831  \n",
      "\n",
      "Fold: 18  Epoch: 30  Training loss = 4.2051  Validation loss = 2.0831  \n",
      "\n",
      "Fold: 18  Epoch: 31  Training loss = 4.2043  Validation loss = 2.0830  \n",
      "\n",
      "Fold: 18  Epoch: 32  Training loss = 4.2036  Validation loss = 2.0829  \n",
      "\n",
      "Fold: 18  Epoch: 33  Training loss = 4.2029  Validation loss = 2.0829  \n",
      "\n",
      "Fold: 18  Epoch: 34  Training loss = 4.2021  Validation loss = 2.0828  \n",
      "\n",
      "Fold: 18  Epoch: 35  Training loss = 4.2015  Validation loss = 2.0828  \n",
      "\n",
      "Fold: 18  Epoch: 36  Training loss = 4.2005  Validation loss = 2.0828  \n",
      "\n",
      "Fold: 18  Epoch: 37  Training loss = 4.1998  Validation loss = 2.0827  \n",
      "\n",
      "Fold: 18  Epoch: 38  Training loss = 4.1991  Validation loss = 2.0827  \n",
      "\n",
      "Fold: 18  Epoch: 39  Training loss = 4.1984  Validation loss = 2.0827  \n",
      "\n",
      "Fold: 18  Epoch: 40  Training loss = 4.1978  Validation loss = 2.0826  \n",
      "\n",
      "Fold: 18  Epoch: 41  Training loss = 4.1971  Validation loss = 2.0826  \n",
      "\n",
      "Fold: 18  Epoch: 42  Training loss = 4.1964  Validation loss = 2.0825  \n",
      "\n",
      "Fold: 18  Epoch: 43  Training loss = 4.1956  Validation loss = 2.0825  \n",
      "\n",
      "Fold: 18  Epoch: 44  Training loss = 4.1948  Validation loss = 2.0825  \n",
      "\n",
      "Fold: 18  Epoch: 45  Training loss = 4.1943  Validation loss = 2.0825  \n",
      "\n",
      "Fold: 18  Epoch: 46  Training loss = 4.1932  Validation loss = 2.0825  \n",
      "\n",
      "Fold: 18  Epoch: 47  Training loss = 4.1924  Validation loss = 2.0824  \n",
      "\n",
      "Fold: 18  Epoch: 48  Training loss = 4.1914  Validation loss = 2.0824  \n",
      "\n",
      "Fold: 18  Epoch: 49  Training loss = 4.1908  Validation loss = 2.0824  \n",
      "\n",
      "Fold: 18  Epoch: 50  Training loss = 4.1902  Validation loss = 2.0824  \n",
      "\n",
      "Fold: 18  Epoch: 51  Training loss = 4.1894  Validation loss = 2.0823  \n",
      "\n",
      "Fold: 18  Epoch: 52  Training loss = 4.1886  Validation loss = 2.0823  \n",
      "\n",
      "Fold: 18  Epoch: 53  Training loss = 4.1878  Validation loss = 2.0823  \n",
      "\n",
      "Fold: 18  Epoch: 54  Training loss = 4.1870  Validation loss = 2.0823  \n",
      "\n",
      "Fold: 18  Epoch: 55  Training loss = 4.1861  Validation loss = 2.0822  \n",
      "\n",
      "Fold: 18  Epoch: 56  Training loss = 4.1850  Validation loss = 2.0822  \n",
      "\n",
      "Fold: 18  Epoch: 57  Training loss = 4.1841  Validation loss = 2.0822  \n",
      "\n",
      "Fold: 18  Epoch: 58  Training loss = 4.1833  Validation loss = 2.0822  \n",
      "\n",
      "Fold: 18  Epoch: 59  Training loss = 4.1825  Validation loss = 2.0822  \n",
      "\n",
      "Fold: 18  Epoch: 60  Training loss = 4.1817  Validation loss = 2.0821  \n",
      "\n",
      "Fold: 18  Epoch: 61  Training loss = 4.1807  Validation loss = 2.0821  \n",
      "\n",
      "Fold: 18  Epoch: 62  Training loss = 4.1796  Validation loss = 2.0821  \n",
      "\n",
      "Fold: 18  Epoch: 63  Training loss = 4.1789  Validation loss = 2.0821  \n",
      "\n",
      "Fold: 18  Epoch: 64  Training loss = 4.1777  Validation loss = 2.0820  \n",
      "\n",
      "Fold: 18  Epoch: 65  Training loss = 4.1768  Validation loss = 2.0820  \n",
      "\n",
      "Fold: 18  Epoch: 66  Training loss = 4.1758  Validation loss = 2.0820  \n",
      "\n",
      "Fold: 18  Epoch: 67  Training loss = 4.1750  Validation loss = 2.0820  \n",
      "\n",
      "Fold: 18  Epoch: 68  Training loss = 4.1739  Validation loss = 2.0820  \n",
      "\n",
      "Fold: 18  Epoch: 69  Training loss = 4.1729  Validation loss = 2.0819  \n",
      "\n",
      "Fold: 18  Epoch: 70  Training loss = 4.1722  Validation loss = 2.0819  \n",
      "\n",
      "Fold: 18  Epoch: 71  Training loss = 4.1713  Validation loss = 2.0819  \n",
      "\n",
      "Fold: 18  Epoch: 72  Training loss = 4.1705  Validation loss = 2.0819  \n",
      "\n",
      "Fold: 18  Epoch: 73  Training loss = 4.1700  Validation loss = 2.0818  \n",
      "\n",
      "Fold: 18  Epoch: 74  Training loss = 4.1693  Validation loss = 2.0818  \n",
      "\n",
      "Fold: 18  Epoch: 75  Training loss = 4.1686  Validation loss = 2.0818  \n",
      "\n",
      "Fold: 18  Epoch: 76  Training loss = 4.1679  Validation loss = 2.0817  \n",
      "\n",
      "Fold: 18  Epoch: 77  Training loss = 4.1671  Validation loss = 2.0817  \n",
      "\n",
      "Fold: 18  Epoch: 78  Training loss = 4.1662  Validation loss = 2.0817  \n",
      "\n",
      "Fold: 18  Epoch: 79  Training loss = 4.1652  Validation loss = 2.0817  \n",
      "\n",
      "Fold: 18  Epoch: 80  Training loss = 4.1643  Validation loss = 2.0817  \n",
      "\n",
      "Fold: 18  Epoch: 81  Training loss = 4.1637  Validation loss = 2.0816  \n",
      "\n",
      "Fold: 18  Epoch: 82  Training loss = 4.1632  Validation loss = 2.0816  \n",
      "\n",
      "Fold: 18  Epoch: 83  Training loss = 4.1624  Validation loss = 2.0816  \n",
      "\n",
      "Fold: 18  Epoch: 84  Training loss = 4.1617  Validation loss = 2.0816  \n",
      "\n",
      "Fold: 18  Epoch: 85  Training loss = 4.1610  Validation loss = 2.0815  \n",
      "\n",
      "Fold: 18  Epoch: 86  Training loss = 4.1603  Validation loss = 2.0815  \n",
      "\n",
      "Fold: 18  Epoch: 87  Training loss = 4.1595  Validation loss = 2.0815  \n",
      "\n",
      "Fold: 18  Epoch: 88  Training loss = 4.1589  Validation loss = 2.0815  \n",
      "\n",
      "Fold: 18  Epoch: 89  Training loss = 4.1583  Validation loss = 2.0815  \n",
      "\n",
      "Fold: 18  Epoch: 90  Training loss = 4.1575  Validation loss = 2.0814  \n",
      "\n",
      "Fold: 18  Epoch: 91  Training loss = 4.1568  Validation loss = 2.0814  \n",
      "\n",
      "Fold: 18  Epoch: 92  Training loss = 4.1562  Validation loss = 2.0814  \n",
      "\n",
      "Fold: 18  Epoch: 93  Training loss = 4.1553  Validation loss = 2.0814  \n",
      "\n",
      "Fold: 18  Epoch: 94  Training loss = 4.1546  Validation loss = 2.0814  \n",
      "\n",
      "Fold: 18  Epoch: 95  Training loss = 4.1538  Validation loss = 2.0814  \n",
      "\n",
      "Fold: 18  Epoch: 96  Training loss = 4.1530  Validation loss = 2.0814  \n",
      "\n",
      "Fold: 18  Epoch: 97  Training loss = 4.1520  Validation loss = 2.0814  \n",
      "\n",
      "Fold: 18  Epoch: 98  Training loss = 4.1512  Validation loss = 2.0814  \n",
      "\n",
      "Fold: 18  Epoch: 99  Training loss = 4.1505  Validation loss = 2.0814  \n",
      "\n",
      "Fold: 18  Epoch: 100  Training loss = 4.1499  Validation loss = 2.0814  \n",
      "\n",
      "Fold: 18  Epoch: 101  Training loss = 4.1490  Validation loss = 2.0814  \n",
      "\n",
      "Fold: 18  Epoch: 102  Training loss = 4.1482  Validation loss = 2.0814  \n",
      "\n",
      "Fold: 18  Epoch: 103  Training loss = 4.1476  Validation loss = 2.0814  \n",
      "\n",
      "Fold: 18  Epoch: 104  Training loss = 4.1470  Validation loss = 2.0814  \n",
      "\n",
      "Fold: 18  Epoch: 105  Training loss = 4.1463  Validation loss = 2.0813  \n",
      "\n",
      "Fold: 18  Epoch: 106  Training loss = 4.1454  Validation loss = 2.0813  \n",
      "\n",
      "Fold: 18  Epoch: 107  Training loss = 4.1446  Validation loss = 2.0813  \n",
      "\n",
      "Fold: 18  Epoch: 108  Training loss = 4.1438  Validation loss = 2.0813  \n",
      "\n",
      "Fold: 18  Epoch: 109  Training loss = 4.1429  Validation loss = 2.0813  \n",
      "\n",
      "Fold: 18  Epoch: 110  Training loss = 4.1422  Validation loss = 2.0813  \n",
      "\n",
      "Fold: 18  Epoch: 111  Training loss = 4.1411  Validation loss = 2.0813  \n",
      "\n",
      "Fold: 18  Epoch: 112  Training loss = 4.1405  Validation loss = 2.0813  \n",
      "\n",
      "Fold: 18  Epoch: 113  Training loss = 4.1397  Validation loss = 2.0813  \n",
      "\n",
      "Fold: 18  Epoch: 114  Training loss = 4.1389  Validation loss = 2.0813  \n",
      "\n",
      "Fold: 18  Epoch: 115  Training loss = 4.1382  Validation loss = 2.0813  \n",
      "\n",
      "Fold: 18  Epoch: 116  Training loss = 4.1374  Validation loss = 2.0813  \n",
      "\n",
      "Check model:  Fold: 18  Epoch: 112  Training loss = 4.1374  Validation loss = 2.0813  \n",
      "\n",
      "Fold: 19  Epoch: 1  Training loss = 4.1475  Validation loss = 1.1272  \n",
      "\n",
      "Fold: 19  Epoch: 2  Training loss = 4.1468  Validation loss = 1.1268  \n",
      "\n",
      "Fold: 19  Epoch: 3  Training loss = 4.1461  Validation loss = 1.1263  \n",
      "\n",
      "Fold: 19  Epoch: 4  Training loss = 4.1456  Validation loss = 1.1259  \n",
      "\n",
      "Fold: 19  Epoch: 5  Training loss = 4.1448  Validation loss = 1.1253  \n",
      "\n",
      "Fold: 19  Epoch: 6  Training loss = 4.1440  Validation loss = 1.1247  \n",
      "\n",
      "Fold: 19  Epoch: 7  Training loss = 4.1433  Validation loss = 1.1243  \n",
      "\n",
      "Fold: 19  Epoch: 8  Training loss = 4.1426  Validation loss = 1.1237  \n",
      "\n",
      "Fold: 19  Epoch: 9  Training loss = 4.1419  Validation loss = 1.1232  \n",
      "\n",
      "Fold: 19  Epoch: 10  Training loss = 4.1411  Validation loss = 1.1227  \n",
      "\n",
      "Fold: 19  Epoch: 11  Training loss = 4.1403  Validation loss = 1.1221  \n",
      "\n",
      "Fold: 19  Epoch: 12  Training loss = 4.1395  Validation loss = 1.1214  \n",
      "\n",
      "Fold: 19  Epoch: 13  Training loss = 4.1388  Validation loss = 1.1209  \n",
      "\n",
      "Fold: 19  Epoch: 14  Training loss = 4.1381  Validation loss = 1.1204  \n",
      "\n",
      "Fold: 19  Epoch: 15  Training loss = 4.1374  Validation loss = 1.1199  \n",
      "\n",
      "Fold: 19  Epoch: 16  Training loss = 4.1367  Validation loss = 1.1194  \n",
      "\n",
      "Fold: 19  Epoch: 17  Training loss = 4.1359  Validation loss = 1.1188  \n",
      "\n",
      "Fold: 19  Epoch: 18  Training loss = 4.1350  Validation loss = 1.1183  \n",
      "\n",
      "Fold: 19  Epoch: 19  Training loss = 4.1343  Validation loss = 1.1178  \n",
      "\n",
      "Fold: 19  Epoch: 20  Training loss = 4.1336  Validation loss = 1.1173  \n",
      "\n",
      "Fold: 19  Epoch: 21  Training loss = 4.1329  Validation loss = 1.1168  \n",
      "\n",
      "Fold: 19  Epoch: 22  Training loss = 4.1323  Validation loss = 1.1164  \n",
      "\n",
      "Fold: 19  Epoch: 23  Training loss = 4.1316  Validation loss = 1.1160  \n",
      "\n",
      "Fold: 19  Epoch: 24  Training loss = 4.1309  Validation loss = 1.1155  \n",
      "\n",
      "Fold: 19  Epoch: 25  Training loss = 4.1300  Validation loss = 1.1148  \n",
      "\n",
      "Fold: 19  Epoch: 26  Training loss = 4.1293  Validation loss = 1.1143  \n",
      "\n",
      "Fold: 19  Epoch: 27  Training loss = 4.1286  Validation loss = 1.1138  \n",
      "\n",
      "Fold: 19  Epoch: 28  Training loss = 4.1280  Validation loss = 1.1134  \n",
      "\n",
      "Fold: 19  Epoch: 29  Training loss = 4.1273  Validation loss = 1.1128  \n",
      "\n",
      "Fold: 19  Epoch: 30  Training loss = 4.1265  Validation loss = 1.1122  \n",
      "\n",
      "Fold: 19  Epoch: 31  Training loss = 4.1259  Validation loss = 1.1117  \n",
      "\n",
      "Fold: 19  Epoch: 32  Training loss = 4.1249  Validation loss = 1.1110  \n",
      "\n",
      "Fold: 19  Epoch: 33  Training loss = 4.1242  Validation loss = 1.1105  \n",
      "\n",
      "Fold: 19  Epoch: 34  Training loss = 4.1236  Validation loss = 1.1101  \n",
      "\n",
      "Fold: 19  Epoch: 35  Training loss = 4.1229  Validation loss = 1.1096  \n",
      "\n",
      "Fold: 19  Epoch: 36  Training loss = 4.1220  Validation loss = 1.1090  \n",
      "\n",
      "Fold: 19  Epoch: 37  Training loss = 4.1213  Validation loss = 1.1086  \n",
      "\n",
      "Fold: 19  Epoch: 38  Training loss = 4.1206  Validation loss = 1.1081  \n",
      "\n",
      "Fold: 19  Epoch: 39  Training loss = 4.1199  Validation loss = 1.1076  \n",
      "\n",
      "Fold: 19  Epoch: 40  Training loss = 4.1191  Validation loss = 1.1071  \n",
      "\n",
      "Fold: 19  Epoch: 41  Training loss = 4.1183  Validation loss = 1.1065  \n",
      "\n",
      "Fold: 19  Epoch: 42  Training loss = 4.1175  Validation loss = 1.1059  \n",
      "\n",
      "Fold: 19  Epoch: 43  Training loss = 4.1170  Validation loss = 1.1056  \n",
      "\n",
      "Fold: 19  Epoch: 44  Training loss = 4.1165  Validation loss = 1.1052  \n",
      "\n",
      "Fold: 19  Epoch: 45  Training loss = 4.1159  Validation loss = 1.1048  \n",
      "\n",
      "Fold: 19  Epoch: 46  Training loss = 4.1150  Validation loss = 1.1042  \n",
      "\n",
      "Fold: 19  Epoch: 47  Training loss = 4.1143  Validation loss = 1.1038  \n",
      "\n",
      "Fold: 19  Epoch: 48  Training loss = 4.1137  Validation loss = 1.1033  \n",
      "\n",
      "Fold: 19  Epoch: 49  Training loss = 4.1129  Validation loss = 1.1028  \n",
      "\n",
      "Fold: 19  Epoch: 50  Training loss = 4.1122  Validation loss = 1.1023  \n",
      "\n",
      "Fold: 19  Epoch: 51  Training loss = 4.1112  Validation loss = 1.1016  \n",
      "\n",
      "Fold: 19  Epoch: 52  Training loss = 4.1105  Validation loss = 1.1011  \n",
      "\n",
      "Fold: 19  Epoch: 53  Training loss = 4.1096  Validation loss = 1.1005  \n",
      "\n",
      "Fold: 19  Epoch: 54  Training loss = 4.1089  Validation loss = 1.1001  \n",
      "\n",
      "Fold: 19  Epoch: 55  Training loss = 4.1083  Validation loss = 1.0997  \n",
      "\n",
      "Fold: 19  Epoch: 56  Training loss = 4.1076  Validation loss = 1.0992  \n",
      "\n",
      "Fold: 19  Epoch: 57  Training loss = 4.1070  Validation loss = 1.0988  \n",
      "\n",
      "Fold: 19  Epoch: 58  Training loss = 4.1063  Validation loss = 1.0984  \n",
      "\n",
      "Fold: 19  Epoch: 59  Training loss = 4.1057  Validation loss = 1.0980  \n",
      "\n",
      "Fold: 19  Epoch: 60  Training loss = 4.1046  Validation loss = 1.0973  \n",
      "\n",
      "Fold: 19  Epoch: 61  Training loss = 4.1039  Validation loss = 1.0968  \n",
      "\n",
      "Fold: 19  Epoch: 62  Training loss = 4.1031  Validation loss = 1.0964  \n",
      "\n",
      "Fold: 19  Epoch: 63  Training loss = 4.1024  Validation loss = 1.0959  \n",
      "\n",
      "Fold: 19  Epoch: 64  Training loss = 4.1017  Validation loss = 1.0953  \n",
      "\n",
      "Fold: 19  Epoch: 65  Training loss = 4.1008  Validation loss = 1.0947  \n",
      "\n",
      "Fold: 19  Epoch: 66  Training loss = 4.1001  Validation loss = 1.0941  \n",
      "\n",
      "Fold: 19  Epoch: 67  Training loss = 4.0996  Validation loss = 1.0937  \n",
      "\n",
      "Fold: 19  Epoch: 68  Training loss = 4.0988  Validation loss = 1.0932  \n",
      "\n",
      "Fold: 19  Epoch: 69  Training loss = 4.0981  Validation loss = 1.0928  \n",
      "\n",
      "Fold: 19  Epoch: 70  Training loss = 4.0973  Validation loss = 1.0923  \n",
      "\n",
      "Fold: 19  Epoch: 71  Training loss = 4.0965  Validation loss = 1.0918  \n",
      "\n",
      "Fold: 19  Epoch: 72  Training loss = 4.0959  Validation loss = 1.0914  \n",
      "\n",
      "Fold: 19  Epoch: 73  Training loss = 4.0949  Validation loss = 1.0907  \n",
      "\n",
      "Fold: 19  Epoch: 74  Training loss = 4.0942  Validation loss = 1.0902  \n",
      "\n",
      "Fold: 19  Epoch: 75  Training loss = 4.0935  Validation loss = 1.0897  \n",
      "\n",
      "Fold: 19  Epoch: 76  Training loss = 4.0926  Validation loss = 1.0891  \n",
      "\n",
      "Fold: 19  Epoch: 77  Training loss = 4.0920  Validation loss = 1.0887  \n",
      "\n",
      "Fold: 19  Epoch: 78  Training loss = 4.0912  Validation loss = 1.0882  \n",
      "\n",
      "Fold: 19  Epoch: 79  Training loss = 4.0904  Validation loss = 1.0878  \n",
      "\n",
      "Fold: 19  Epoch: 80  Training loss = 4.0901  Validation loss = 1.0875  \n",
      "\n",
      "Fold: 19  Epoch: 81  Training loss = 4.0893  Validation loss = 1.0870  \n",
      "\n",
      "Fold: 19  Epoch: 82  Training loss = 4.0886  Validation loss = 1.0865  \n",
      "\n",
      "Fold: 19  Epoch: 83  Training loss = 4.0881  Validation loss = 1.0861  \n",
      "\n",
      "Fold: 19  Epoch: 84  Training loss = 4.0871  Validation loss = 1.0854  \n",
      "\n",
      "Fold: 19  Epoch: 85  Training loss = 4.0865  Validation loss = 1.0851  \n",
      "\n",
      "Fold: 19  Epoch: 86  Training loss = 4.0859  Validation loss = 1.0847  \n",
      "\n",
      "Fold: 19  Epoch: 87  Training loss = 4.0851  Validation loss = 1.0843  \n",
      "\n",
      "Fold: 19  Epoch: 88  Training loss = 4.0845  Validation loss = 1.0839  \n",
      "\n",
      "Fold: 19  Epoch: 89  Training loss = 4.0839  Validation loss = 1.0835  \n",
      "\n",
      "Fold: 19  Epoch: 90  Training loss = 4.0830  Validation loss = 1.0829  \n",
      "\n",
      "Fold: 19  Epoch: 91  Training loss = 4.0823  Validation loss = 1.0825  \n",
      "\n",
      "Fold: 19  Epoch: 92  Training loss = 4.0816  Validation loss = 1.0820  \n",
      "\n",
      "Fold: 19  Epoch: 93  Training loss = 4.0809  Validation loss = 1.0816  \n",
      "\n",
      "Fold: 19  Epoch: 94  Training loss = 4.0803  Validation loss = 1.0812  \n",
      "\n",
      "Fold: 19  Epoch: 95  Training loss = 4.0794  Validation loss = 1.0806  \n",
      "\n",
      "Fold: 19  Epoch: 96  Training loss = 4.0788  Validation loss = 1.0802  \n",
      "\n",
      "Fold: 19  Epoch: 97  Training loss = 4.0782  Validation loss = 1.0799  \n",
      "\n",
      "Fold: 19  Epoch: 98  Training loss = 4.0774  Validation loss = 1.0794  \n",
      "\n",
      "Fold: 19  Epoch: 99  Training loss = 4.0769  Validation loss = 1.0790  \n",
      "\n",
      "Fold: 19  Epoch: 100  Training loss = 4.0764  Validation loss = 1.0786  \n",
      "\n",
      "Fold: 19  Epoch: 101  Training loss = 4.0758  Validation loss = 1.0782  \n",
      "\n",
      "Fold: 19  Epoch: 102  Training loss = 4.0752  Validation loss = 1.0778  \n",
      "\n",
      "Fold: 19  Epoch: 103  Training loss = 4.0745  Validation loss = 1.0774  \n",
      "\n",
      "Fold: 19  Epoch: 104  Training loss = 4.0738  Validation loss = 1.0769  \n",
      "\n",
      "Fold: 19  Epoch: 105  Training loss = 4.0730  Validation loss = 1.0764  \n",
      "\n",
      "Fold: 19  Epoch: 106  Training loss = 4.0723  Validation loss = 1.0760  \n",
      "\n",
      "Fold: 19  Epoch: 107  Training loss = 4.0714  Validation loss = 1.0755  \n",
      "\n",
      "Fold: 19  Epoch: 108  Training loss = 4.0709  Validation loss = 1.0751  \n",
      "\n",
      "Fold: 19  Epoch: 109  Training loss = 4.0701  Validation loss = 1.0746  \n",
      "\n",
      "Fold: 19  Epoch: 110  Training loss = 4.0694  Validation loss = 1.0741  \n",
      "\n",
      "Fold: 19  Epoch: 111  Training loss = 4.0683  Validation loss = 1.0735  \n",
      "\n",
      "Fold: 19  Epoch: 112  Training loss = 4.0674  Validation loss = 1.0730  \n",
      "\n",
      "Fold: 19  Epoch: 113  Training loss = 4.0669  Validation loss = 1.0726  \n",
      "\n",
      "Fold: 19  Epoch: 114  Training loss = 4.0661  Validation loss = 1.0721  \n",
      "\n",
      "Fold: 19  Epoch: 115  Training loss = 4.0654  Validation loss = 1.0716  \n",
      "\n",
      "Fold: 19  Epoch: 116  Training loss = 4.0649  Validation loss = 1.0712  \n",
      "\n",
      "Fold: 19  Epoch: 117  Training loss = 4.0640  Validation loss = 1.0706  \n",
      "\n",
      "Fold: 19  Epoch: 118  Training loss = 4.0632  Validation loss = 1.0701  \n",
      "\n",
      "Fold: 19  Epoch: 119  Training loss = 4.0624  Validation loss = 1.0697  \n",
      "\n",
      "Fold: 19  Epoch: 120  Training loss = 4.0616  Validation loss = 1.0692  \n",
      "\n",
      "Fold: 19  Epoch: 121  Training loss = 4.0610  Validation loss = 1.0688  \n",
      "\n",
      "Fold: 19  Epoch: 122  Training loss = 4.0600  Validation loss = 1.0683  \n",
      "\n",
      "Fold: 19  Epoch: 123  Training loss = 4.0594  Validation loss = 1.0678  \n",
      "\n",
      "Fold: 19  Epoch: 124  Training loss = 4.0584  Validation loss = 1.0673  \n",
      "\n",
      "Fold: 19  Epoch: 125  Training loss = 4.0576  Validation loss = 1.0668  \n",
      "\n",
      "Fold: 19  Epoch: 126  Training loss = 4.0569  Validation loss = 1.0663  \n",
      "\n",
      "Fold: 19  Epoch: 127  Training loss = 4.0563  Validation loss = 1.0660  \n",
      "\n",
      "Fold: 19  Epoch: 128  Training loss = 4.0556  Validation loss = 1.0656  \n",
      "\n",
      "Fold: 19  Epoch: 129  Training loss = 4.0551  Validation loss = 1.0653  \n",
      "\n",
      "Fold: 19  Epoch: 130  Training loss = 4.0545  Validation loss = 1.0649  \n",
      "\n",
      "Fold: 19  Epoch: 131  Training loss = 4.0538  Validation loss = 1.0645  \n",
      "\n",
      "Fold: 19  Epoch: 132  Training loss = 4.0530  Validation loss = 1.0640  \n",
      "\n",
      "Fold: 19  Epoch: 133  Training loss = 4.0523  Validation loss = 1.0636  \n",
      "\n",
      "Fold: 19  Epoch: 134  Training loss = 4.0517  Validation loss = 1.0632  \n",
      "\n",
      "Fold: 19  Epoch: 135  Training loss = 4.0510  Validation loss = 1.0628  \n",
      "\n",
      "Fold: 19  Epoch: 136  Training loss = 4.0503  Validation loss = 1.0624  \n",
      "\n",
      "Fold: 19  Epoch: 137  Training loss = 4.0495  Validation loss = 1.0619  \n",
      "\n",
      "Fold: 19  Epoch: 138  Training loss = 4.0487  Validation loss = 1.0615  \n",
      "\n",
      "Fold: 19  Epoch: 139  Training loss = 4.0480  Validation loss = 1.0610  \n",
      "\n",
      "Fold: 19  Epoch: 140  Training loss = 4.0474  Validation loss = 1.0607  \n",
      "\n",
      "Fold: 19  Epoch: 141  Training loss = 4.0466  Validation loss = 1.0603  \n",
      "\n",
      "Fold: 19  Epoch: 142  Training loss = 4.0460  Validation loss = 1.0599  \n",
      "\n",
      "Fold: 19  Epoch: 143  Training loss = 4.0453  Validation loss = 1.0595  \n",
      "\n",
      "Fold: 19  Epoch: 144  Training loss = 4.0447  Validation loss = 1.0591  \n",
      "\n",
      "Fold: 19  Epoch: 145  Training loss = 4.0439  Validation loss = 1.0586  \n",
      "\n",
      "Fold: 19  Epoch: 146  Training loss = 4.0434  Validation loss = 1.0582  \n",
      "\n",
      "Fold: 19  Epoch: 147  Training loss = 4.0427  Validation loss = 1.0578  \n",
      "\n",
      "Fold: 19  Epoch: 148  Training loss = 4.0420  Validation loss = 1.0574  \n",
      "\n",
      "Fold: 19  Epoch: 149  Training loss = 4.0413  Validation loss = 1.0570  \n",
      "\n",
      "Fold: 19  Epoch: 150  Training loss = 4.0405  Validation loss = 1.0565  \n",
      "\n",
      "Fold: 19  Epoch: 151  Training loss = 4.0400  Validation loss = 1.0562  \n",
      "\n",
      "Fold: 19  Epoch: 152  Training loss = 4.0391  Validation loss = 1.0557  \n",
      "\n",
      "Fold: 19  Epoch: 153  Training loss = 4.0382  Validation loss = 1.0551  \n",
      "\n",
      "Fold: 19  Epoch: 154  Training loss = 4.0373  Validation loss = 1.0546  \n",
      "\n",
      "Fold: 19  Epoch: 155  Training loss = 4.0366  Validation loss = 1.0541  \n",
      "\n",
      "Fold: 19  Epoch: 156  Training loss = 4.0358  Validation loss = 1.0536  \n",
      "\n",
      "Fold: 19  Epoch: 157  Training loss = 4.0353  Validation loss = 1.0533  \n",
      "\n",
      "Fold: 19  Epoch: 158  Training loss = 4.0345  Validation loss = 1.0528  \n",
      "\n",
      "Fold: 19  Epoch: 159  Training loss = 4.0337  Validation loss = 1.0523  \n",
      "\n",
      "Fold: 19  Epoch: 160  Training loss = 4.0330  Validation loss = 1.0519  \n",
      "\n",
      "Fold: 19  Epoch: 161  Training loss = 4.0323  Validation loss = 1.0515  \n",
      "\n",
      "Fold: 19  Epoch: 162  Training loss = 4.0316  Validation loss = 1.0511  \n",
      "\n",
      "Fold: 19  Epoch: 163  Training loss = 4.0307  Validation loss = 1.0506  \n",
      "\n",
      "Fold: 19  Epoch: 164  Training loss = 4.0300  Validation loss = 1.0502  \n",
      "\n",
      "Fold: 19  Epoch: 165  Training loss = 4.0294  Validation loss = 1.0499  \n",
      "\n",
      "Fold: 19  Epoch: 166  Training loss = 4.0286  Validation loss = 1.0494  \n",
      "\n",
      "Fold: 19  Epoch: 167  Training loss = 4.0280  Validation loss = 1.0491  \n",
      "\n",
      "Fold: 19  Epoch: 168  Training loss = 4.0274  Validation loss = 1.0487  \n",
      "\n",
      "Fold: 19  Epoch: 169  Training loss = 4.0267  Validation loss = 1.0483  \n",
      "\n",
      "Fold: 19  Epoch: 170  Training loss = 4.0259  Validation loss = 1.0479  \n",
      "\n",
      "Fold: 19  Epoch: 171  Training loss = 4.0252  Validation loss = 1.0475  \n",
      "\n",
      "Fold: 19  Epoch: 172  Training loss = 4.0246  Validation loss = 1.0472  \n",
      "\n",
      "Fold: 19  Epoch: 173  Training loss = 4.0240  Validation loss = 1.0469  \n",
      "\n",
      "Fold: 19  Epoch: 174  Training loss = 4.0233  Validation loss = 1.0465  \n",
      "\n",
      "Fold: 19  Epoch: 175  Training loss = 4.0223  Validation loss = 1.0459  \n",
      "\n",
      "Fold: 19  Epoch: 176  Training loss = 4.0218  Validation loss = 1.0457  \n",
      "\n",
      "Fold: 19  Epoch: 177  Training loss = 4.0213  Validation loss = 1.0454  \n",
      "\n",
      "Fold: 19  Epoch: 178  Training loss = 4.0205  Validation loss = 1.0450  \n",
      "\n",
      "Fold: 19  Epoch: 179  Training loss = 4.0197  Validation loss = 1.0446  \n",
      "\n",
      "Fold: 19  Epoch: 180  Training loss = 4.0190  Validation loss = 1.0441  \n",
      "\n",
      "Fold: 19  Epoch: 181  Training loss = 4.0181  Validation loss = 1.0436  \n",
      "\n",
      "Fold: 19  Epoch: 182  Training loss = 4.0175  Validation loss = 1.0433  \n",
      "\n",
      "Fold: 19  Epoch: 183  Training loss = 4.0168  Validation loss = 1.0430  \n",
      "\n",
      "Fold: 19  Epoch: 184  Training loss = 4.0164  Validation loss = 1.0428  \n",
      "\n",
      "Fold: 19  Epoch: 185  Training loss = 4.0157  Validation loss = 1.0424  \n",
      "\n",
      "Fold: 19  Epoch: 186  Training loss = 4.0152  Validation loss = 1.0422  \n",
      "\n",
      "Fold: 19  Epoch: 187  Training loss = 4.0146  Validation loss = 1.0418  \n",
      "\n",
      "Fold: 19  Epoch: 188  Training loss = 4.0137  Validation loss = 1.0413  \n",
      "\n",
      "Fold: 19  Epoch: 189  Training loss = 4.0130  Validation loss = 1.0408  \n",
      "\n",
      "Fold: 19  Epoch: 190  Training loss = 4.0123  Validation loss = 1.0404  \n",
      "\n",
      "Fold: 19  Epoch: 191  Training loss = 4.0116  Validation loss = 1.0400  \n",
      "\n",
      "Fold: 19  Epoch: 192  Training loss = 4.0111  Validation loss = 1.0397  \n",
      "\n",
      "Fold: 19  Epoch: 193  Training loss = 4.0106  Validation loss = 1.0394  \n",
      "\n",
      "Fold: 19  Epoch: 194  Training loss = 4.0100  Validation loss = 1.0391  \n",
      "\n",
      "Fold: 19  Epoch: 195  Training loss = 4.0094  Validation loss = 1.0387  \n",
      "\n",
      "Fold: 19  Epoch: 196  Training loss = 4.0088  Validation loss = 1.0384  \n",
      "\n",
      "Fold: 19  Epoch: 197  Training loss = 4.0081  Validation loss = 1.0380  \n",
      "\n",
      "Fold: 19  Epoch: 198  Training loss = 4.0076  Validation loss = 1.0376  \n",
      "\n",
      "Fold: 19  Epoch: 199  Training loss = 4.0068  Validation loss = 1.0372  \n",
      "\n",
      "Fold: 19  Epoch: 200  Training loss = 4.0061  Validation loss = 1.0368  \n",
      "\n",
      "Fold: 19  Epoch: 201  Training loss = 4.0054  Validation loss = 1.0365  \n",
      "\n",
      "Fold: 19  Epoch: 202  Training loss = 4.0048  Validation loss = 1.0361  \n",
      "\n",
      "Fold: 19  Epoch: 203  Training loss = 4.0041  Validation loss = 1.0358  \n",
      "\n",
      "Fold: 19  Epoch: 204  Training loss = 4.0033  Validation loss = 1.0354  \n",
      "\n",
      "Fold: 19  Epoch: 205  Training loss = 4.0028  Validation loss = 1.0350  \n",
      "\n",
      "Fold: 19  Epoch: 206  Training loss = 4.0020  Validation loss = 1.0347  \n",
      "\n",
      "Fold: 19  Epoch: 207  Training loss = 4.0014  Validation loss = 1.0343  \n",
      "\n",
      "Fold: 19  Epoch: 208  Training loss = 4.0009  Validation loss = 1.0340  \n",
      "\n",
      "Fold: 19  Epoch: 209  Training loss = 4.0002  Validation loss = 1.0337  \n",
      "\n",
      "Fold: 19  Epoch: 210  Training loss = 3.9996  Validation loss = 1.0334  \n",
      "\n",
      "Fold: 19  Epoch: 211  Training loss = 3.9990  Validation loss = 1.0331  \n",
      "\n",
      "Fold: 19  Epoch: 212  Training loss = 3.9982  Validation loss = 1.0327  \n",
      "\n",
      "Fold: 19  Epoch: 213  Training loss = 3.9975  Validation loss = 1.0323  \n",
      "\n",
      "Fold: 19  Epoch: 214  Training loss = 3.9968  Validation loss = 1.0318  \n",
      "\n",
      "Fold: 19  Epoch: 215  Training loss = 3.9962  Validation loss = 1.0315  \n",
      "\n",
      "Fold: 19  Epoch: 216  Training loss = 3.9956  Validation loss = 1.0312  \n",
      "\n",
      "Fold: 19  Epoch: 217  Training loss = 3.9950  Validation loss = 1.0309  \n",
      "\n",
      "Fold: 19  Epoch: 218  Training loss = 3.9944  Validation loss = 1.0306  \n",
      "\n",
      "Fold: 19  Epoch: 219  Training loss = 3.9939  Validation loss = 1.0302  \n",
      "\n",
      "Fold: 19  Epoch: 220  Training loss = 3.9933  Validation loss = 1.0300  \n",
      "\n",
      "Fold: 19  Epoch: 221  Training loss = 3.9927  Validation loss = 1.0296  \n",
      "\n",
      "Fold: 19  Epoch: 222  Training loss = 3.9919  Validation loss = 1.0291  \n",
      "\n",
      "Fold: 19  Epoch: 223  Training loss = 3.9913  Validation loss = 1.0288  \n",
      "\n",
      "Fold: 19  Epoch: 224  Training loss = 3.9908  Validation loss = 1.0284  \n",
      "\n",
      "Fold: 19  Epoch: 225  Training loss = 3.9900  Validation loss = 1.0279  \n",
      "\n",
      "Fold: 19  Epoch: 226  Training loss = 3.9894  Validation loss = 1.0276  \n",
      "\n",
      "Fold: 19  Epoch: 227  Training loss = 3.9887  Validation loss = 1.0272  \n",
      "\n",
      "Fold: 19  Epoch: 228  Training loss = 3.9880  Validation loss = 1.0268  \n",
      "\n",
      "Fold: 19  Epoch: 229  Training loss = 3.9873  Validation loss = 1.0264  \n",
      "\n",
      "Fold: 19  Epoch: 230  Training loss = 3.9867  Validation loss = 1.0260  \n",
      "\n",
      "Fold: 19  Epoch: 231  Training loss = 3.9861  Validation loss = 1.0256  \n",
      "\n",
      "Fold: 19  Epoch: 232  Training loss = 3.9852  Validation loss = 1.0252  \n",
      "\n",
      "Fold: 19  Epoch: 233  Training loss = 3.9848  Validation loss = 1.0249  \n",
      "\n",
      "Fold: 19  Epoch: 234  Training loss = 3.9837  Validation loss = 1.0243  \n",
      "\n",
      "Fold: 19  Epoch: 235  Training loss = 3.9829  Validation loss = 1.0240  \n",
      "\n",
      "Fold: 19  Epoch: 236  Training loss = 3.9823  Validation loss = 1.0236  \n",
      "\n",
      "Fold: 19  Epoch: 237  Training loss = 3.9815  Validation loss = 1.0232  \n",
      "\n",
      "Fold: 19  Epoch: 238  Training loss = 3.9808  Validation loss = 1.0229  \n",
      "\n",
      "Fold: 19  Epoch: 239  Training loss = 3.9802  Validation loss = 1.0226  \n",
      "\n",
      "Fold: 19  Epoch: 240  Training loss = 3.9797  Validation loss = 1.0223  \n",
      "\n",
      "Fold: 19  Epoch: 241  Training loss = 3.9788  Validation loss = 1.0219  \n",
      "\n",
      "Fold: 19  Epoch: 242  Training loss = 3.9781  Validation loss = 1.0216  \n",
      "\n",
      "Fold: 19  Epoch: 243  Training loss = 3.9775  Validation loss = 1.0212  \n",
      "\n",
      "Fold: 19  Epoch: 244  Training loss = 3.9768  Validation loss = 1.0209  \n",
      "\n",
      "Fold: 19  Epoch: 245  Training loss = 3.9762  Validation loss = 1.0206  \n",
      "\n",
      "Fold: 19  Epoch: 246  Training loss = 3.9755  Validation loss = 1.0202  \n",
      "\n",
      "Fold: 19  Epoch: 247  Training loss = 3.9750  Validation loss = 1.0199  \n",
      "\n",
      "Fold: 19  Epoch: 248  Training loss = 3.9744  Validation loss = 1.0195  \n",
      "\n",
      "Fold: 19  Epoch: 249  Training loss = 3.9736  Validation loss = 1.0191  \n",
      "\n",
      "Fold: 19  Epoch: 250  Training loss = 3.9729  Validation loss = 1.0187  \n",
      "\n",
      "Fold: 19  Epoch: 251  Training loss = 3.9724  Validation loss = 1.0184  \n",
      "\n",
      "Fold: 19  Epoch: 252  Training loss = 3.9717  Validation loss = 1.0181  \n",
      "\n",
      "Fold: 19  Epoch: 253  Training loss = 3.9712  Validation loss = 1.0178  \n",
      "\n",
      "Fold: 19  Epoch: 254  Training loss = 3.9708  Validation loss = 1.0175  \n",
      "\n",
      "Fold: 19  Epoch: 255  Training loss = 3.9702  Validation loss = 1.0173  \n",
      "\n",
      "Fold: 19  Epoch: 256  Training loss = 3.9697  Validation loss = 1.0171  \n",
      "\n",
      "Fold: 19  Epoch: 257  Training loss = 3.9688  Validation loss = 1.0166  \n",
      "\n",
      "Fold: 19  Epoch: 258  Training loss = 3.9681  Validation loss = 1.0163  \n",
      "\n",
      "Fold: 19  Epoch: 259  Training loss = 3.9672  Validation loss = 1.0159  \n",
      "\n",
      "Fold: 19  Epoch: 260  Training loss = 3.9665  Validation loss = 1.0155  \n",
      "\n",
      "Fold: 19  Epoch: 261  Training loss = 3.9658  Validation loss = 1.0152  \n",
      "\n",
      "Fold: 19  Epoch: 262  Training loss = 3.9654  Validation loss = 1.0149  \n",
      "\n",
      "Fold: 19  Epoch: 263  Training loss = 3.9647  Validation loss = 1.0146  \n",
      "\n",
      "Fold: 19  Epoch: 264  Training loss = 3.9641  Validation loss = 1.0143  \n",
      "\n",
      "Fold: 19  Epoch: 265  Training loss = 3.9633  Validation loss = 1.0139  \n",
      "\n",
      "Fold: 19  Epoch: 266  Training loss = 3.9627  Validation loss = 1.0135  \n",
      "\n",
      "Fold: 19  Epoch: 267  Training loss = 3.9619  Validation loss = 1.0131  \n",
      "\n",
      "Fold: 19  Epoch: 268  Training loss = 3.9611  Validation loss = 1.0128  \n",
      "\n",
      "Fold: 19  Epoch: 269  Training loss = 3.9605  Validation loss = 1.0125  \n",
      "\n",
      "Fold: 19  Epoch: 270  Training loss = 3.9600  Validation loss = 1.0123  \n",
      "\n",
      "Fold: 19  Epoch: 271  Training loss = 3.9595  Validation loss = 1.0120  \n",
      "\n",
      "Fold: 19  Epoch: 272  Training loss = 3.9587  Validation loss = 1.0117  \n",
      "\n",
      "Fold: 19  Epoch: 273  Training loss = 3.9579  Validation loss = 1.0112  \n",
      "\n",
      "Fold: 19  Epoch: 274  Training loss = 3.9571  Validation loss = 1.0108  \n",
      "\n",
      "Fold: 19  Epoch: 275  Training loss = 3.9566  Validation loss = 1.0105  \n",
      "\n",
      "Fold: 19  Epoch: 276  Training loss = 3.9560  Validation loss = 1.0102  \n",
      "\n",
      "Fold: 19  Epoch: 277  Training loss = 3.9554  Validation loss = 1.0100  \n",
      "\n",
      "Fold: 19  Epoch: 278  Training loss = 3.9547  Validation loss = 1.0097  \n",
      "\n",
      "Fold: 19  Epoch: 279  Training loss = 3.9541  Validation loss = 1.0094  \n",
      "\n",
      "Fold: 19  Epoch: 280  Training loss = 3.9536  Validation loss = 1.0091  \n",
      "\n",
      "Fold: 19  Epoch: 281  Training loss = 3.9529  Validation loss = 1.0088  \n",
      "\n",
      "Fold: 19  Epoch: 282  Training loss = 3.9521  Validation loss = 1.0084  \n",
      "\n",
      "Fold: 19  Epoch: 283  Training loss = 3.9515  Validation loss = 1.0081  \n",
      "\n",
      "Fold: 19  Epoch: 284  Training loss = 3.9511  Validation loss = 1.0079  \n",
      "\n",
      "Fold: 19  Epoch: 285  Training loss = 3.9502  Validation loss = 1.0075  \n",
      "\n",
      "Fold: 19  Epoch: 286  Training loss = 3.9494  Validation loss = 1.0071  \n",
      "\n",
      "Fold: 19  Epoch: 287  Training loss = 3.9489  Validation loss = 1.0069  \n",
      "\n",
      "Fold: 19  Epoch: 288  Training loss = 3.9482  Validation loss = 1.0066  \n",
      "\n",
      "Fold: 19  Epoch: 289  Training loss = 3.9477  Validation loss = 1.0063  \n",
      "\n",
      "Fold: 19  Epoch: 290  Training loss = 3.9467  Validation loss = 1.0059  \n",
      "\n",
      "Fold: 19  Epoch: 291  Training loss = 3.9462  Validation loss = 1.0057  \n",
      "\n",
      "Fold: 19  Epoch: 292  Training loss = 3.9454  Validation loss = 1.0053  \n",
      "\n",
      "Fold: 19  Epoch: 293  Training loss = 3.9446  Validation loss = 1.0050  \n",
      "\n",
      "Fold: 19  Epoch: 294  Training loss = 3.9439  Validation loss = 1.0047  \n",
      "\n",
      "Fold: 19  Epoch: 295  Training loss = 3.9432  Validation loss = 1.0044  \n",
      "\n",
      "Fold: 19  Epoch: 296  Training loss = 3.9425  Validation loss = 1.0041  \n",
      "\n",
      "Fold: 19  Epoch: 297  Training loss = 3.9418  Validation loss = 1.0038  \n",
      "\n",
      "Fold: 19  Epoch: 298  Training loss = 3.9412  Validation loss = 1.0035  \n",
      "\n",
      "Fold: 19  Epoch: 299  Training loss = 3.9406  Validation loss = 1.0032  \n",
      "\n",
      "Fold: 19  Epoch: 300  Training loss = 3.9401  Validation loss = 1.0029  \n",
      "\n",
      "Fold: 19  Epoch: 301  Training loss = 3.9395  Validation loss = 1.0027  \n",
      "\n",
      "Fold: 19  Epoch: 302  Training loss = 3.9389  Validation loss = 1.0024  \n",
      "\n",
      "Fold: 19  Epoch: 303  Training loss = 3.9385  Validation loss = 1.0022  \n",
      "\n",
      "Fold: 19  Epoch: 304  Training loss = 3.9380  Validation loss = 1.0019  \n",
      "\n",
      "Fold: 19  Epoch: 305  Training loss = 3.9373  Validation loss = 1.0015  \n",
      "\n",
      "Fold: 19  Epoch: 306  Training loss = 3.9363  Validation loss = 1.0011  \n",
      "\n",
      "Fold: 19  Epoch: 307  Training loss = 3.9355  Validation loss = 1.0008  \n",
      "\n",
      "Fold: 19  Epoch: 308  Training loss = 3.9348  Validation loss = 1.0005  \n",
      "\n",
      "Fold: 19  Epoch: 309  Training loss = 3.9341  Validation loss = 1.0002  \n",
      "\n",
      "Fold: 19  Epoch: 310  Training loss = 3.9336  Validation loss = 0.9999  \n",
      "\n",
      "Fold: 19  Epoch: 311  Training loss = 3.9330  Validation loss = 0.9996  \n",
      "\n",
      "Fold: 19  Epoch: 312  Training loss = 3.9325  Validation loss = 0.9993  \n",
      "\n",
      "Fold: 19  Epoch: 313  Training loss = 3.9318  Validation loss = 0.9990  \n",
      "\n",
      "Fold: 19  Epoch: 314  Training loss = 3.9311  Validation loss = 0.9987  \n",
      "\n",
      "Fold: 19  Epoch: 315  Training loss = 3.9301  Validation loss = 0.9982  \n",
      "\n",
      "Fold: 19  Epoch: 316  Training loss = 3.9295  Validation loss = 0.9979  \n",
      "\n",
      "Fold: 19  Epoch: 317  Training loss = 3.9289  Validation loss = 0.9976  \n",
      "\n",
      "Fold: 19  Epoch: 318  Training loss = 3.9283  Validation loss = 0.9974  \n",
      "\n",
      "Fold: 19  Epoch: 319  Training loss = 3.9276  Validation loss = 0.9972  \n",
      "\n",
      "Fold: 19  Epoch: 320  Training loss = 3.9271  Validation loss = 0.9970  \n",
      "\n",
      "Fold: 19  Epoch: 321  Training loss = 3.9265  Validation loss = 0.9967  \n",
      "\n",
      "Fold: 19  Epoch: 322  Training loss = 3.9259  Validation loss = 0.9964  \n",
      "\n",
      "Fold: 19  Epoch: 323  Training loss = 3.9253  Validation loss = 0.9962  \n",
      "\n",
      "Fold: 19  Epoch: 324  Training loss = 3.9245  Validation loss = 0.9959  \n",
      "\n",
      "Fold: 19  Epoch: 325  Training loss = 3.9239  Validation loss = 0.9956  \n",
      "\n",
      "Fold: 19  Epoch: 326  Training loss = 3.9233  Validation loss = 0.9954  \n",
      "\n",
      "Fold: 19  Epoch: 327  Training loss = 3.9227  Validation loss = 0.9952  \n",
      "\n",
      "Fold: 19  Epoch: 328  Training loss = 3.9221  Validation loss = 0.9949  \n",
      "\n",
      "Fold: 19  Epoch: 329  Training loss = 3.9215  Validation loss = 0.9946  \n",
      "\n",
      "Fold: 19  Epoch: 330  Training loss = 3.9206  Validation loss = 0.9943  \n",
      "\n",
      "Fold: 19  Epoch: 331  Training loss = 3.9199  Validation loss = 0.9940  \n",
      "\n",
      "Fold: 19  Epoch: 332  Training loss = 3.9192  Validation loss = 0.9937  \n",
      "\n",
      "Fold: 19  Epoch: 333  Training loss = 3.9186  Validation loss = 0.9934  \n",
      "\n",
      "Fold: 19  Epoch: 334  Training loss = 3.9181  Validation loss = 0.9931  \n",
      "\n",
      "Fold: 19  Epoch: 335  Training loss = 3.9173  Validation loss = 0.9928  \n",
      "\n",
      "Fold: 19  Epoch: 336  Training loss = 3.9165  Validation loss = 0.9925  \n",
      "\n",
      "Fold: 19  Epoch: 337  Training loss = 3.9159  Validation loss = 0.9923  \n",
      "\n",
      "Fold: 19  Epoch: 338  Training loss = 3.9153  Validation loss = 0.9920  \n",
      "\n",
      "Fold: 19  Epoch: 339  Training loss = 3.9146  Validation loss = 0.9917  \n",
      "\n",
      "Fold: 19  Epoch: 340  Training loss = 3.9139  Validation loss = 0.9914  \n",
      "\n",
      "Fold: 19  Epoch: 341  Training loss = 3.9134  Validation loss = 0.9912  \n",
      "\n",
      "Fold: 19  Epoch: 342  Training loss = 3.9129  Validation loss = 0.9909  \n",
      "\n",
      "Fold: 19  Epoch: 343  Training loss = 3.9123  Validation loss = 0.9906  \n",
      "\n",
      "Fold: 19  Epoch: 344  Training loss = 3.9119  Validation loss = 0.9904  \n",
      "\n",
      "Fold: 19  Epoch: 345  Training loss = 3.9111  Validation loss = 0.9901  \n",
      "\n",
      "Fold: 19  Epoch: 346  Training loss = 3.9106  Validation loss = 0.9898  \n",
      "\n",
      "Fold: 19  Epoch: 347  Training loss = 3.9097  Validation loss = 0.9894  \n",
      "\n",
      "Fold: 19  Epoch: 348  Training loss = 3.9089  Validation loss = 0.9891  \n",
      "\n",
      "Fold: 19  Epoch: 349  Training loss = 3.9085  Validation loss = 0.9889  \n",
      "\n",
      "Fold: 19  Epoch: 350  Training loss = 3.9078  Validation loss = 0.9886  \n",
      "\n",
      "Fold: 19  Epoch: 351  Training loss = 3.9073  Validation loss = 0.9885  \n",
      "\n",
      "Fold: 19  Epoch: 352  Training loss = 3.9066  Validation loss = 0.9882  \n",
      "\n",
      "Fold: 19  Epoch: 353  Training loss = 3.9060  Validation loss = 0.9879  \n",
      "\n",
      "Fold: 19  Epoch: 354  Training loss = 3.9053  Validation loss = 0.9877  \n",
      "\n",
      "Fold: 19  Epoch: 355  Training loss = 3.9047  Validation loss = 0.9874  \n",
      "\n",
      "Fold: 19  Epoch: 356  Training loss = 3.9043  Validation loss = 0.9872  \n",
      "\n",
      "Fold: 19  Epoch: 357  Training loss = 3.9035  Validation loss = 0.9869  \n",
      "\n",
      "Fold: 19  Epoch: 358  Training loss = 3.9028  Validation loss = 0.9866  \n",
      "\n",
      "Fold: 19  Epoch: 359  Training loss = 3.9020  Validation loss = 0.9863  \n",
      "\n",
      "Fold: 19  Epoch: 360  Training loss = 3.9013  Validation loss = 0.9861  \n",
      "\n",
      "Fold: 19  Epoch: 361  Training loss = 3.9005  Validation loss = 0.9858  \n",
      "\n",
      "Fold: 19  Epoch: 362  Training loss = 3.8998  Validation loss = 0.9855  \n",
      "\n",
      "Fold: 19  Epoch: 363  Training loss = 3.8990  Validation loss = 0.9851  \n",
      "\n",
      "Fold: 19  Epoch: 364  Training loss = 3.8984  Validation loss = 0.9848  \n",
      "\n",
      "Fold: 19  Epoch: 365  Training loss = 3.8977  Validation loss = 0.9846  \n",
      "\n",
      "Fold: 19  Epoch: 366  Training loss = 3.8971  Validation loss = 0.9843  \n",
      "\n",
      "Fold: 19  Epoch: 367  Training loss = 3.8964  Validation loss = 0.9840  \n",
      "\n",
      "Fold: 19  Epoch: 368  Training loss = 3.8959  Validation loss = 0.9838  \n",
      "\n",
      "Fold: 19  Epoch: 369  Training loss = 3.8952  Validation loss = 0.9835  \n",
      "\n",
      "Fold: 19  Epoch: 370  Training loss = 3.8944  Validation loss = 0.9832  \n",
      "\n",
      "Fold: 19  Epoch: 371  Training loss = 3.8937  Validation loss = 0.9828  \n",
      "\n",
      "Fold: 19  Epoch: 372  Training loss = 3.8930  Validation loss = 0.9825  \n",
      "\n",
      "Fold: 19  Epoch: 373  Training loss = 3.8923  Validation loss = 0.9823  \n",
      "\n",
      "Fold: 19  Epoch: 374  Training loss = 3.8916  Validation loss = 0.9821  \n",
      "\n",
      "Fold: 19  Epoch: 375  Training loss = 3.8909  Validation loss = 0.9818  \n",
      "\n",
      "Fold: 19  Epoch: 376  Training loss = 3.8901  Validation loss = 0.9815  \n",
      "\n",
      "Fold: 19  Epoch: 377  Training loss = 3.8897  Validation loss = 0.9813  \n",
      "\n",
      "Fold: 19  Epoch: 378  Training loss = 3.8889  Validation loss = 0.9811  \n",
      "\n",
      "Fold: 19  Epoch: 379  Training loss = 3.8881  Validation loss = 0.9808  \n",
      "\n",
      "Fold: 19  Epoch: 380  Training loss = 3.8875  Validation loss = 0.9806  \n",
      "\n",
      "Fold: 19  Epoch: 381  Training loss = 3.8869  Validation loss = 0.9804  \n",
      "\n",
      "Fold: 19  Epoch: 382  Training loss = 3.8863  Validation loss = 0.9802  \n",
      "\n",
      "Fold: 19  Epoch: 383  Training loss = 3.8859  Validation loss = 0.9801  \n",
      "\n",
      "Fold: 19  Epoch: 384  Training loss = 3.8854  Validation loss = 0.9799  \n",
      "\n",
      "Fold: 19  Epoch: 385  Training loss = 3.8849  Validation loss = 0.9797  \n",
      "\n",
      "Fold: 19  Epoch: 386  Training loss = 3.8844  Validation loss = 0.9795  \n",
      "\n",
      "Fold: 19  Epoch: 387  Training loss = 3.8839  Validation loss = 0.9793  \n",
      "\n",
      "Fold: 19  Epoch: 388  Training loss = 3.8834  Validation loss = 0.9791  \n",
      "\n",
      "Fold: 19  Epoch: 389  Training loss = 3.8827  Validation loss = 0.9789  \n",
      "\n",
      "Fold: 19  Epoch: 390  Training loss = 3.8823  Validation loss = 0.9787  \n",
      "\n",
      "Fold: 19  Epoch: 391  Training loss = 3.8816  Validation loss = 0.9785  \n",
      "\n",
      "Fold: 19  Epoch: 392  Training loss = 3.8810  Validation loss = 0.9783  \n",
      "\n",
      "Fold: 19  Epoch: 393  Training loss = 3.8805  Validation loss = 0.9780  \n",
      "\n",
      "Fold: 19  Epoch: 394  Training loss = 3.8797  Validation loss = 0.9777  \n",
      "\n",
      "Fold: 19  Epoch: 395  Training loss = 3.8789  Validation loss = 0.9774  \n",
      "\n",
      "Fold: 19  Epoch: 396  Training loss = 3.8785  Validation loss = 0.9773  \n",
      "\n",
      "Fold: 19  Epoch: 397  Training loss = 3.8779  Validation loss = 0.9770  \n",
      "\n",
      "Fold: 19  Epoch: 398  Training loss = 3.8774  Validation loss = 0.9769  \n",
      "\n",
      "Fold: 19  Epoch: 399  Training loss = 3.8769  Validation loss = 0.9767  \n",
      "\n",
      "Fold: 19  Epoch: 400  Training loss = 3.8761  Validation loss = 0.9765  \n",
      "\n",
      "Fold: 19  Epoch: 401  Training loss = 3.8754  Validation loss = 0.9763  \n",
      "\n",
      "Fold: 19  Epoch: 402  Training loss = 3.8747  Validation loss = 0.9760  \n",
      "\n",
      "Fold: 19  Epoch: 403  Training loss = 3.8741  Validation loss = 0.9758  \n",
      "\n",
      "Fold: 19  Epoch: 404  Training loss = 3.8734  Validation loss = 0.9755  \n",
      "\n",
      "Fold: 19  Epoch: 405  Training loss = 3.8728  Validation loss = 0.9754  \n",
      "\n",
      "Fold: 19  Epoch: 406  Training loss = 3.8723  Validation loss = 0.9752  \n",
      "\n",
      "Fold: 19  Epoch: 407  Training loss = 3.8718  Validation loss = 0.9750  \n",
      "\n",
      "Fold: 19  Epoch: 408  Training loss = 3.8711  Validation loss = 0.9748  \n",
      "\n",
      "Fold: 19  Epoch: 409  Training loss = 3.8706  Validation loss = 0.9747  \n",
      "\n",
      "Fold: 19  Epoch: 410  Training loss = 3.8700  Validation loss = 0.9745  \n",
      "\n",
      "Fold: 19  Epoch: 411  Training loss = 3.8695  Validation loss = 0.9742  \n",
      "\n",
      "Fold: 19  Epoch: 412  Training loss = 3.8687  Validation loss = 0.9740  \n",
      "\n",
      "Fold: 19  Epoch: 413  Training loss = 3.8681  Validation loss = 0.9736  \n",
      "\n",
      "Fold: 19  Epoch: 414  Training loss = 3.8675  Validation loss = 0.9734  \n",
      "\n",
      "Fold: 19  Epoch: 415  Training loss = 3.8668  Validation loss = 0.9732  \n",
      "\n",
      "Fold: 19  Epoch: 416  Training loss = 3.8662  Validation loss = 0.9730  \n",
      "\n",
      "Fold: 19  Epoch: 417  Training loss = 3.8658  Validation loss = 0.9729  \n",
      "\n",
      "Fold: 19  Epoch: 418  Training loss = 3.8652  Validation loss = 0.9727  \n",
      "\n",
      "Fold: 19  Epoch: 419  Training loss = 3.8646  Validation loss = 0.9724  \n",
      "\n",
      "Fold: 19  Epoch: 420  Training loss = 3.8640  Validation loss = 0.9722  \n",
      "\n",
      "Fold: 19  Epoch: 421  Training loss = 3.8634  Validation loss = 0.9720  \n",
      "\n",
      "Fold: 19  Epoch: 422  Training loss = 3.8629  Validation loss = 0.9718  \n",
      "\n",
      "Fold: 19  Epoch: 423  Training loss = 3.8623  Validation loss = 0.9716  \n",
      "\n",
      "Fold: 19  Epoch: 424  Training loss = 3.8618  Validation loss = 0.9714  \n",
      "\n",
      "Fold: 19  Epoch: 425  Training loss = 3.8611  Validation loss = 0.9711  \n",
      "\n",
      "Fold: 19  Epoch: 426  Training loss = 3.8606  Validation loss = 0.9709  \n",
      "\n",
      "Fold: 19  Epoch: 427  Training loss = 3.8601  Validation loss = 0.9707  \n",
      "\n",
      "Fold: 19  Epoch: 428  Training loss = 3.8595  Validation loss = 0.9705  \n",
      "\n",
      "Fold: 19  Epoch: 429  Training loss = 3.8588  Validation loss = 0.9703  \n",
      "\n",
      "Fold: 19  Epoch: 430  Training loss = 3.8582  Validation loss = 0.9702  \n",
      "\n",
      "Fold: 19  Epoch: 431  Training loss = 3.8575  Validation loss = 0.9699  \n",
      "\n",
      "Fold: 19  Epoch: 432  Training loss = 3.8568  Validation loss = 0.9697  \n",
      "\n",
      "Fold: 19  Epoch: 433  Training loss = 3.8562  Validation loss = 0.9694  \n",
      "\n",
      "Fold: 19  Epoch: 434  Training loss = 3.8558  Validation loss = 0.9693  \n",
      "\n",
      "Fold: 19  Epoch: 435  Training loss = 3.8552  Validation loss = 0.9691  \n",
      "\n",
      "Fold: 19  Epoch: 436  Training loss = 3.8549  Validation loss = 0.9690  \n",
      "\n",
      "Fold: 19  Epoch: 437  Training loss = 3.8544  Validation loss = 0.9689  \n",
      "\n",
      "Fold: 19  Epoch: 438  Training loss = 3.8536  Validation loss = 0.9687  \n",
      "\n",
      "Fold: 19  Epoch: 439  Training loss = 3.8529  Validation loss = 0.9685  \n",
      "\n",
      "Fold: 19  Epoch: 440  Training loss = 3.8524  Validation loss = 0.9683  \n",
      "\n",
      "Fold: 19  Epoch: 441  Training loss = 3.8518  Validation loss = 0.9681  \n",
      "\n",
      "Fold: 19  Epoch: 442  Training loss = 3.8513  Validation loss = 0.9679  \n",
      "\n",
      "Fold: 19  Epoch: 443  Training loss = 3.8507  Validation loss = 0.9678  \n",
      "\n",
      "Fold: 19  Epoch: 444  Training loss = 3.8502  Validation loss = 0.9676  \n",
      "\n",
      "Fold: 19  Epoch: 445  Training loss = 3.8499  Validation loss = 0.9675  \n",
      "\n",
      "Fold: 19  Epoch: 446  Training loss = 3.8491  Validation loss = 0.9673  \n",
      "\n",
      "Fold: 19  Epoch: 447  Training loss = 3.8486  Validation loss = 0.9671  \n",
      "\n",
      "Fold: 19  Epoch: 448  Training loss = 3.8480  Validation loss = 0.9669  \n",
      "\n",
      "Fold: 19  Epoch: 449  Training loss = 3.8477  Validation loss = 0.9668  \n",
      "\n",
      "Fold: 19  Epoch: 450  Training loss = 3.8473  Validation loss = 0.9667  \n",
      "\n",
      "Fold: 19  Epoch: 451  Training loss = 3.8467  Validation loss = 0.9665  \n",
      "\n",
      "Fold: 19  Epoch: 452  Training loss = 3.8461  Validation loss = 0.9662  \n",
      "\n",
      "Fold: 19  Epoch: 453  Training loss = 3.8455  Validation loss = 0.9661  \n",
      "\n",
      "Fold: 19  Epoch: 454  Training loss = 3.8451  Validation loss = 0.9659  \n",
      "\n",
      "Fold: 19  Epoch: 455  Training loss = 3.8446  Validation loss = 0.9657  \n",
      "\n",
      "Fold: 19  Epoch: 456  Training loss = 3.8441  Validation loss = 0.9655  \n",
      "\n",
      "Fold: 19  Epoch: 457  Training loss = 3.8435  Validation loss = 0.9654  \n",
      "\n",
      "Fold: 19  Epoch: 458  Training loss = 3.8427  Validation loss = 0.9651  \n",
      "\n",
      "Fold: 19  Epoch: 459  Training loss = 3.8424  Validation loss = 0.9651  \n",
      "\n",
      "Fold: 19  Epoch: 460  Training loss = 3.8419  Validation loss = 0.9649  \n",
      "\n",
      "Fold: 19  Epoch: 461  Training loss = 3.8414  Validation loss = 0.9647  \n",
      "\n",
      "Fold: 19  Epoch: 462  Training loss = 3.8407  Validation loss = 0.9646  \n",
      "\n",
      "Fold: 19  Epoch: 463  Training loss = 3.8401  Validation loss = 0.9644  \n",
      "\n",
      "Fold: 19  Epoch: 464  Training loss = 3.8394  Validation loss = 0.9642  \n",
      "\n",
      "Fold: 19  Epoch: 465  Training loss = 3.8388  Validation loss = 0.9640  \n",
      "\n",
      "Fold: 19  Epoch: 466  Training loss = 3.8383  Validation loss = 0.9639  \n",
      "\n",
      "Fold: 19  Epoch: 467  Training loss = 3.8374  Validation loss = 0.9636  \n",
      "\n",
      "Fold: 19  Epoch: 468  Training loss = 3.8368  Validation loss = 0.9635  \n",
      "\n",
      "Fold: 19  Epoch: 469  Training loss = 3.8363  Validation loss = 0.9634  \n",
      "\n",
      "Fold: 19  Epoch: 470  Training loss = 3.8356  Validation loss = 0.9632  \n",
      "\n",
      "Fold: 19  Epoch: 471  Training loss = 3.8349  Validation loss = 0.9630  \n",
      "\n",
      "Fold: 19  Epoch: 472  Training loss = 3.8341  Validation loss = 0.9628  \n",
      "\n",
      "Fold: 19  Epoch: 473  Training loss = 3.8335  Validation loss = 0.9627  \n",
      "\n",
      "Fold: 19  Epoch: 474  Training loss = 3.8330  Validation loss = 0.9625  \n",
      "\n",
      "Fold: 19  Epoch: 475  Training loss = 3.8326  Validation loss = 0.9624  \n",
      "\n",
      "Fold: 19  Epoch: 476  Training loss = 3.8321  Validation loss = 0.9623  \n",
      "\n",
      "Fold: 19  Epoch: 477  Training loss = 3.8316  Validation loss = 0.9622  \n",
      "\n",
      "Fold: 19  Epoch: 478  Training loss = 3.8310  Validation loss = 0.9620  \n",
      "\n",
      "Fold: 19  Epoch: 479  Training loss = 3.8304  Validation loss = 0.9619  \n",
      "\n",
      "Fold: 19  Epoch: 480  Training loss = 3.8297  Validation loss = 0.9617  \n",
      "\n",
      "Fold: 19  Epoch: 481  Training loss = 3.8292  Validation loss = 0.9615  \n",
      "\n",
      "Fold: 19  Epoch: 482  Training loss = 3.8285  Validation loss = 0.9613  \n",
      "\n",
      "Fold: 19  Epoch: 483  Training loss = 3.8280  Validation loss = 0.9612  \n",
      "\n",
      "Fold: 19  Epoch: 484  Training loss = 3.8277  Validation loss = 0.9612  \n",
      "\n",
      "Fold: 19  Epoch: 485  Training loss = 3.8270  Validation loss = 0.9610  \n",
      "\n",
      "Fold: 19  Epoch: 486  Training loss = 3.8263  Validation loss = 0.9608  \n",
      "\n",
      "Fold: 19  Epoch: 487  Training loss = 3.8258  Validation loss = 0.9607  \n",
      "\n",
      "Fold: 19  Epoch: 488  Training loss = 3.8252  Validation loss = 0.9605  \n",
      "\n",
      "Fold: 19  Epoch: 489  Training loss = 3.8245  Validation loss = 0.9604  \n",
      "\n",
      "Fold: 19  Epoch: 490  Training loss = 3.8240  Validation loss = 0.9603  \n",
      "\n",
      "Fold: 19  Epoch: 491  Training loss = 3.8234  Validation loss = 0.9601  \n",
      "\n",
      "Fold: 19  Epoch: 492  Training loss = 3.8227  Validation loss = 0.9599  \n",
      "\n",
      "Fold: 19  Epoch: 493  Training loss = 3.8220  Validation loss = 0.9597  \n",
      "\n",
      "Fold: 19  Epoch: 494  Training loss = 3.8217  Validation loss = 0.9596  \n",
      "\n",
      "Fold: 19  Epoch: 495  Training loss = 3.8211  Validation loss = 0.9594  \n",
      "\n",
      "Fold: 19  Epoch: 496  Training loss = 3.8204  Validation loss = 0.9592  \n",
      "\n",
      "Fold: 19  Epoch: 497  Training loss = 3.8197  Validation loss = 0.9591  \n",
      "\n",
      "Fold: 19  Epoch: 498  Training loss = 3.8191  Validation loss = 0.9589  \n",
      "\n",
      "Fold: 19  Epoch: 499  Training loss = 3.8186  Validation loss = 0.9587  \n",
      "\n",
      "Fold: 19  Epoch: 500  Training loss = 3.8176  Validation loss = 0.9585  \n",
      "\n",
      "Check model:  Fold: 19  Epoch: 500  Training loss = 3.8176  Validation loss = 0.9585  \n",
      "\n",
      "Fold: 20  Epoch: 1  Training loss = 3.8211  Validation loss = 1.6041  \n",
      "\n",
      "Fold: 20  Epoch: 2  Training loss = 3.8206  Validation loss = 1.6050  \n",
      "\n",
      "Fold: 20  Epoch: 3  Training loss = 3.8200  Validation loss = 1.6059  \n",
      "\n",
      "Fold: 20  Epoch: 4  Training loss = 3.8195  Validation loss = 1.6068  \n",
      "\n",
      "Fold: 20  Epoch: 5  Training loss = 3.8189  Validation loss = 1.6077  \n",
      "\n",
      "Fold: 20  Epoch: 6  Training loss = 3.8181  Validation loss = 1.6091  \n",
      "\n",
      "Fold: 20  Epoch: 7  Training loss = 3.8174  Validation loss = 1.6103  \n",
      "\n",
      "Fold: 20  Epoch: 8  Training loss = 3.8169  Validation loss = 1.6110  \n",
      "\n",
      "Fold: 20  Epoch: 9  Training loss = 3.8162  Validation loss = 1.6122  \n",
      "\n",
      "Fold: 20  Epoch: 10  Training loss = 3.8156  Validation loss = 1.6132  \n",
      "\n",
      "Fold: 20  Epoch: 11  Training loss = 3.8149  Validation loss = 1.6146  \n",
      "\n",
      "Check model:  Fold: 20  Epoch: 1  Training loss = 3.8149  Validation loss = 1.6146  \n",
      "\n",
      "Fold: 21  Epoch: 1  Training loss = 3.8309  Validation loss = 2.4680  \n",
      "\n",
      "Fold: 21  Epoch: 2  Training loss = 3.8303  Validation loss = 2.4686  \n",
      "\n",
      "Fold: 21  Epoch: 3  Training loss = 3.8298  Validation loss = 2.4690  \n",
      "\n",
      "Fold: 21  Epoch: 4  Training loss = 3.8293  Validation loss = 2.4695  \n",
      "\n",
      "Fold: 21  Epoch: 5  Training loss = 3.8288  Validation loss = 2.4699  \n",
      "\n",
      "Fold: 21  Epoch: 6  Training loss = 3.8284  Validation loss = 2.4704  \n",
      "\n",
      "Fold: 21  Epoch: 7  Training loss = 3.8281  Validation loss = 2.4708  \n",
      "\n",
      "Fold: 21  Epoch: 8  Training loss = 3.8276  Validation loss = 2.4712  \n",
      "\n",
      "Fold: 21  Epoch: 9  Training loss = 3.8272  Validation loss = 2.4716  \n",
      "\n",
      "Fold: 21  Epoch: 10  Training loss = 3.8266  Validation loss = 2.4722  \n",
      "\n",
      "Fold: 21  Epoch: 11  Training loss = 3.8262  Validation loss = 2.4726  \n",
      "\n",
      "Check model:  Fold: 21  Epoch: 1  Training loss = 3.8262  Validation loss = 2.4726  \n",
      "\n",
      "Fold: 22  Epoch: 1  Training loss = 3.8601  Validation loss = 1.4524  \n",
      "\n",
      "Fold: 22  Epoch: 2  Training loss = 3.8596  Validation loss = 1.4523  \n",
      "\n",
      "Fold: 22  Epoch: 3  Training loss = 3.8590  Validation loss = 1.4522  \n",
      "\n",
      "Fold: 22  Epoch: 4  Training loss = 3.8587  Validation loss = 1.4522  \n",
      "\n",
      "Fold: 22  Epoch: 5  Training loss = 3.8582  Validation loss = 1.4521  \n",
      "\n",
      "Fold: 22  Epoch: 6  Training loss = 3.8575  Validation loss = 1.4521  \n",
      "\n",
      "Fold: 22  Epoch: 7  Training loss = 3.8571  Validation loss = 1.4521  \n",
      "\n",
      "Fold: 22  Epoch: 8  Training loss = 3.8566  Validation loss = 1.4520  \n",
      "\n",
      "Fold: 22  Epoch: 9  Training loss = 3.8565  Validation loss = 1.4520  \n",
      "\n",
      "Fold: 22  Epoch: 10  Training loss = 3.8561  Validation loss = 1.4519  \n",
      "\n",
      "Fold: 22  Epoch: 11  Training loss = 3.8557  Validation loss = 1.4518  \n",
      "\n",
      "Fold: 22  Epoch: 12  Training loss = 3.8553  Validation loss = 1.4518  \n",
      "\n",
      "Fold: 22  Epoch: 13  Training loss = 3.8549  Validation loss = 1.4517  \n",
      "\n",
      "Fold: 22  Epoch: 14  Training loss = 3.8545  Validation loss = 1.4517  \n",
      "\n",
      "Fold: 22  Epoch: 15  Training loss = 3.8542  Validation loss = 1.4517  \n",
      "\n",
      "Fold: 22  Epoch: 16  Training loss = 3.8538  Validation loss = 1.4516  \n",
      "\n",
      "Fold: 22  Epoch: 17  Training loss = 3.8534  Validation loss = 1.4516  \n",
      "\n",
      "Fold: 22  Epoch: 18  Training loss = 3.8530  Validation loss = 1.4516  \n",
      "\n",
      "Fold: 22  Epoch: 19  Training loss = 3.8525  Validation loss = 1.4515  \n",
      "\n",
      "Fold: 22  Epoch: 20  Training loss = 3.8520  Validation loss = 1.4515  \n",
      "\n",
      "Fold: 22  Epoch: 21  Training loss = 3.8516  Validation loss = 1.4514  \n",
      "\n",
      "Fold: 22  Epoch: 22  Training loss = 3.8512  Validation loss = 1.4514  \n",
      "\n",
      "Fold: 22  Epoch: 23  Training loss = 3.8507  Validation loss = 1.4513  \n",
      "\n",
      "Fold: 22  Epoch: 24  Training loss = 3.8505  Validation loss = 1.4512  \n",
      "\n",
      "Fold: 22  Epoch: 25  Training loss = 3.8499  Validation loss = 1.4512  \n",
      "\n",
      "Fold: 22  Epoch: 26  Training loss = 3.8495  Validation loss = 1.4511  \n",
      "\n",
      "Fold: 22  Epoch: 27  Training loss = 3.8490  Validation loss = 1.4511  \n",
      "\n",
      "Fold: 22  Epoch: 28  Training loss = 3.8484  Validation loss = 1.4510  \n",
      "\n",
      "Fold: 22  Epoch: 29  Training loss = 3.8481  Validation loss = 1.4509  \n",
      "\n",
      "Fold: 22  Epoch: 30  Training loss = 3.8477  Validation loss = 1.4509  \n",
      "\n",
      "Fold: 22  Epoch: 31  Training loss = 3.8475  Validation loss = 1.4508  \n",
      "\n",
      "Fold: 22  Epoch: 32  Training loss = 3.8473  Validation loss = 1.4508  \n",
      "\n",
      "Fold: 22  Epoch: 33  Training loss = 3.8469  Validation loss = 1.4507  \n",
      "\n",
      "Fold: 22  Epoch: 34  Training loss = 3.8464  Validation loss = 1.4506  \n",
      "\n",
      "Fold: 22  Epoch: 35  Training loss = 3.8460  Validation loss = 1.4506  \n",
      "\n",
      "Fold: 22  Epoch: 36  Training loss = 3.8455  Validation loss = 1.4506  \n",
      "\n",
      "Fold: 22  Epoch: 37  Training loss = 3.8451  Validation loss = 1.4505  \n",
      "\n",
      "Fold: 22  Epoch: 38  Training loss = 3.8446  Validation loss = 1.4504  \n",
      "\n",
      "Fold: 22  Epoch: 39  Training loss = 3.8442  Validation loss = 1.4503  \n",
      "\n",
      "Fold: 22  Epoch: 40  Training loss = 3.8437  Validation loss = 1.4502  \n",
      "\n",
      "Fold: 22  Epoch: 41  Training loss = 3.8433  Validation loss = 1.4501  \n",
      "\n",
      "Fold: 22  Epoch: 42  Training loss = 3.8429  Validation loss = 1.4501  \n",
      "\n",
      "Fold: 22  Epoch: 43  Training loss = 3.8423  Validation loss = 1.4500  \n",
      "\n",
      "Fold: 22  Epoch: 44  Training loss = 3.8419  Validation loss = 1.4500  \n",
      "\n",
      "Fold: 22  Epoch: 45  Training loss = 3.8415  Validation loss = 1.4499  \n",
      "\n",
      "Fold: 22  Epoch: 46  Training loss = 3.8411  Validation loss = 1.4499  \n",
      "\n",
      "Fold: 22  Epoch: 47  Training loss = 3.8408  Validation loss = 1.4499  \n",
      "\n",
      "Fold: 22  Epoch: 48  Training loss = 3.8402  Validation loss = 1.4498  \n",
      "\n",
      "Fold: 22  Epoch: 49  Training loss = 3.8397  Validation loss = 1.4496  \n",
      "\n",
      "Fold: 22  Epoch: 50  Training loss = 3.8392  Validation loss = 1.4496  \n",
      "\n",
      "Fold: 22  Epoch: 51  Training loss = 3.8388  Validation loss = 1.4495  \n",
      "\n",
      "Fold: 22  Epoch: 52  Training loss = 3.8382  Validation loss = 1.4494  \n",
      "\n",
      "Fold: 22  Epoch: 53  Training loss = 3.8379  Validation loss = 1.4494  \n",
      "\n",
      "Fold: 22  Epoch: 54  Training loss = 3.8375  Validation loss = 1.4493  \n",
      "\n",
      "Fold: 22  Epoch: 55  Training loss = 3.8370  Validation loss = 1.4492  \n",
      "\n",
      "Fold: 22  Epoch: 56  Training loss = 3.8366  Validation loss = 1.4492  \n",
      "\n",
      "Fold: 22  Epoch: 57  Training loss = 3.8362  Validation loss = 1.4492  \n",
      "\n",
      "Fold: 22  Epoch: 58  Training loss = 3.8358  Validation loss = 1.4491  \n",
      "\n",
      "Fold: 22  Epoch: 59  Training loss = 3.8355  Validation loss = 1.4492  \n",
      "\n",
      "Fold: 22  Epoch: 60  Training loss = 3.8349  Validation loss = 1.4491  \n",
      "\n",
      "Fold: 22  Epoch: 61  Training loss = 3.8345  Validation loss = 1.4491  \n",
      "\n",
      "Fold: 22  Epoch: 62  Training loss = 3.8341  Validation loss = 1.4491  \n",
      "\n",
      "Fold: 22  Epoch: 63  Training loss = 3.8336  Validation loss = 1.4491  \n",
      "\n",
      "Fold: 22  Epoch: 64  Training loss = 3.8333  Validation loss = 1.4491  \n",
      "\n",
      "Fold: 22  Epoch: 65  Training loss = 3.8328  Validation loss = 1.4491  \n",
      "\n",
      "Fold: 22  Epoch: 66  Training loss = 3.8323  Validation loss = 1.4490  \n",
      "\n",
      "Fold: 22  Epoch: 67  Training loss = 3.8319  Validation loss = 1.4490  \n",
      "\n",
      "Fold: 22  Epoch: 68  Training loss = 3.8314  Validation loss = 1.4491  \n",
      "\n",
      "Fold: 22  Epoch: 69  Training loss = 3.8309  Validation loss = 1.4491  \n",
      "\n",
      "Fold: 22  Epoch: 70  Training loss = 3.8304  Validation loss = 1.4490  \n",
      "\n",
      "Fold: 22  Epoch: 71  Training loss = 3.8299  Validation loss = 1.4490  \n",
      "\n",
      "Fold: 22  Epoch: 72  Training loss = 3.8297  Validation loss = 1.4490  \n",
      "\n",
      "Fold: 22  Epoch: 73  Training loss = 3.8291  Validation loss = 1.4490  \n",
      "\n",
      "Fold: 22  Epoch: 74  Training loss = 3.8289  Validation loss = 1.4489  \n",
      "\n",
      "Fold: 22  Epoch: 75  Training loss = 3.8285  Validation loss = 1.4488  \n",
      "\n",
      "Fold: 22  Epoch: 76  Training loss = 3.8282  Validation loss = 1.4488  \n",
      "\n",
      "Fold: 22  Epoch: 77  Training loss = 3.8279  Validation loss = 1.4488  \n",
      "\n",
      "Fold: 22  Epoch: 78  Training loss = 3.8274  Validation loss = 1.4488  \n",
      "\n",
      "Fold: 22  Epoch: 79  Training loss = 3.8271  Validation loss = 1.4487  \n",
      "\n",
      "Fold: 22  Epoch: 80  Training loss = 3.8268  Validation loss = 1.4487  \n",
      "\n",
      "Fold: 22  Epoch: 81  Training loss = 3.8263  Validation loss = 1.4486  \n",
      "\n",
      "Fold: 22  Epoch: 82  Training loss = 3.8259  Validation loss = 1.4485  \n",
      "\n",
      "Fold: 22  Epoch: 83  Training loss = 3.8255  Validation loss = 1.4485  \n",
      "\n",
      "Fold: 22  Epoch: 84  Training loss = 3.8252  Validation loss = 1.4484  \n",
      "\n",
      "Fold: 22  Epoch: 85  Training loss = 3.8249  Validation loss = 1.4484  \n",
      "\n",
      "Fold: 22  Epoch: 86  Training loss = 3.8246  Validation loss = 1.4483  \n",
      "\n",
      "Fold: 22  Epoch: 87  Training loss = 3.8243  Validation loss = 1.4483  \n",
      "\n",
      "Fold: 22  Epoch: 88  Training loss = 3.8239  Validation loss = 1.4482  \n",
      "\n",
      "Fold: 22  Epoch: 89  Training loss = 3.8236  Validation loss = 1.4482  \n",
      "\n",
      "Fold: 22  Epoch: 90  Training loss = 3.8232  Validation loss = 1.4482  \n",
      "\n",
      "Fold: 22  Epoch: 91  Training loss = 3.8230  Validation loss = 1.4481  \n",
      "\n",
      "Fold: 22  Epoch: 92  Training loss = 3.8226  Validation loss = 1.4481  \n",
      "\n",
      "Fold: 22  Epoch: 93  Training loss = 3.8222  Validation loss = 1.4481  \n",
      "\n",
      "Fold: 22  Epoch: 94  Training loss = 3.8220  Validation loss = 1.4481  \n",
      "\n",
      "Fold: 22  Epoch: 95  Training loss = 3.8216  Validation loss = 1.4481  \n",
      "\n",
      "Fold: 22  Epoch: 96  Training loss = 3.8212  Validation loss = 1.4481  \n",
      "\n",
      "Fold: 22  Epoch: 97  Training loss = 3.8209  Validation loss = 1.4481  \n",
      "\n",
      "Fold: 22  Epoch: 98  Training loss = 3.8206  Validation loss = 1.4480  \n",
      "\n",
      "Fold: 22  Epoch: 99  Training loss = 3.8202  Validation loss = 1.4481  \n",
      "\n",
      "Fold: 22  Epoch: 100  Training loss = 3.8200  Validation loss = 1.4481  \n",
      "\n",
      "Fold: 22  Epoch: 101  Training loss = 3.8196  Validation loss = 1.4480  \n",
      "\n",
      "Fold: 22  Epoch: 102  Training loss = 3.8191  Validation loss = 1.4480  \n",
      "\n",
      "Fold: 22  Epoch: 103  Training loss = 3.8186  Validation loss = 1.4479  \n",
      "\n",
      "Fold: 22  Epoch: 104  Training loss = 3.8182  Validation loss = 1.4479  \n",
      "\n",
      "Fold: 22  Epoch: 105  Training loss = 3.8177  Validation loss = 1.4478  \n",
      "\n",
      "Fold: 22  Epoch: 106  Training loss = 3.8173  Validation loss = 1.4478  \n",
      "\n",
      "Fold: 22  Epoch: 107  Training loss = 3.8170  Validation loss = 1.4477  \n",
      "\n",
      "Fold: 22  Epoch: 108  Training loss = 3.8167  Validation loss = 1.4476  \n",
      "\n",
      "Fold: 22  Epoch: 109  Training loss = 3.8163  Validation loss = 1.4476  \n",
      "\n",
      "Fold: 22  Epoch: 110  Training loss = 3.8160  Validation loss = 1.4477  \n",
      "\n",
      "Fold: 22  Epoch: 111  Training loss = 3.8155  Validation loss = 1.4477  \n",
      "\n",
      "Fold: 22  Epoch: 112  Training loss = 3.8151  Validation loss = 1.4477  \n",
      "\n",
      "Fold: 22  Epoch: 113  Training loss = 3.8148  Validation loss = 1.4477  \n",
      "\n",
      "Fold: 22  Epoch: 114  Training loss = 3.8144  Validation loss = 1.4477  \n",
      "\n",
      "Fold: 22  Epoch: 115  Training loss = 3.8140  Validation loss = 1.4476  \n",
      "\n",
      "Fold: 22  Epoch: 116  Training loss = 3.8137  Validation loss = 1.4476  \n",
      "\n",
      "Fold: 22  Epoch: 117  Training loss = 3.8133  Validation loss = 1.4475  \n",
      "\n",
      "Fold: 22  Epoch: 118  Training loss = 3.8128  Validation loss = 1.4474  \n",
      "\n",
      "Fold: 22  Epoch: 119  Training loss = 3.8122  Validation loss = 1.4474  \n",
      "\n",
      "Fold: 22  Epoch: 120  Training loss = 3.8118  Validation loss = 1.4473  \n",
      "\n",
      "Fold: 22  Epoch: 121  Training loss = 3.8114  Validation loss = 1.4474  \n",
      "\n",
      "Fold: 22  Epoch: 122  Training loss = 3.8109  Validation loss = 1.4473  \n",
      "\n",
      "Fold: 22  Epoch: 123  Training loss = 3.8104  Validation loss = 1.4473  \n",
      "\n",
      "Fold: 22  Epoch: 124  Training loss = 3.8100  Validation loss = 1.4473  \n",
      "\n",
      "Fold: 22  Epoch: 125  Training loss = 3.8098  Validation loss = 1.4472  \n",
      "\n",
      "Fold: 22  Epoch: 126  Training loss = 3.8094  Validation loss = 1.4471  \n",
      "\n",
      "Fold: 22  Epoch: 127  Training loss = 3.8090  Validation loss = 1.4471  \n",
      "\n",
      "Fold: 22  Epoch: 128  Training loss = 3.8087  Validation loss = 1.4470  \n",
      "\n",
      "Fold: 22  Epoch: 129  Training loss = 3.8083  Validation loss = 1.4469  \n",
      "\n",
      "Fold: 22  Epoch: 130  Training loss = 3.8080  Validation loss = 1.4469  \n",
      "\n",
      "Fold: 22  Epoch: 131  Training loss = 3.8077  Validation loss = 1.4469  \n",
      "\n",
      "Fold: 22  Epoch: 132  Training loss = 3.8073  Validation loss = 1.4469  \n",
      "\n",
      "Fold: 22  Epoch: 133  Training loss = 3.8069  Validation loss = 1.4469  \n",
      "\n",
      "Fold: 22  Epoch: 134  Training loss = 3.8066  Validation loss = 1.4469  \n",
      "\n",
      "Fold: 22  Epoch: 135  Training loss = 3.8065  Validation loss = 1.4470  \n",
      "\n",
      "Fold: 22  Epoch: 136  Training loss = 3.8062  Validation loss = 1.4469  \n",
      "\n",
      "Fold: 22  Epoch: 137  Training loss = 3.8060  Validation loss = 1.4469  \n",
      "\n",
      "Fold: 22  Epoch: 138  Training loss = 3.8056  Validation loss = 1.4468  \n",
      "\n",
      "Fold: 22  Epoch: 139  Training loss = 3.8053  Validation loss = 1.4468  \n",
      "\n",
      "Fold: 22  Epoch: 140  Training loss = 3.8049  Validation loss = 1.4467  \n",
      "\n",
      "Fold: 22  Epoch: 141  Training loss = 3.8046  Validation loss = 1.4467  \n",
      "\n",
      "Fold: 22  Epoch: 142  Training loss = 3.8044  Validation loss = 1.4467  \n",
      "\n",
      "Fold: 22  Epoch: 143  Training loss = 3.8039  Validation loss = 1.4467  \n",
      "\n",
      "Fold: 22  Epoch: 144  Training loss = 3.8036  Validation loss = 1.4466  \n",
      "\n",
      "Fold: 22  Epoch: 145  Training loss = 3.8032  Validation loss = 1.4465  \n",
      "\n",
      "Fold: 22  Epoch: 146  Training loss = 3.8029  Validation loss = 1.4465  \n",
      "\n",
      "Fold: 22  Epoch: 147  Training loss = 3.8024  Validation loss = 1.4465  \n",
      "\n",
      "Fold: 22  Epoch: 148  Training loss = 3.8021  Validation loss = 1.4464  \n",
      "\n",
      "Fold: 22  Epoch: 149  Training loss = 3.8019  Validation loss = 1.4463  \n",
      "\n",
      "Fold: 22  Epoch: 150  Training loss = 3.8016  Validation loss = 1.4463  \n",
      "\n",
      "Fold: 22  Epoch: 151  Training loss = 3.8012  Validation loss = 1.4462  \n",
      "\n",
      "Fold: 22  Epoch: 152  Training loss = 3.8007  Validation loss = 1.4462  \n",
      "\n",
      "Fold: 22  Epoch: 153  Training loss = 3.8002  Validation loss = 1.4461  \n",
      "\n",
      "Fold: 22  Epoch: 154  Training loss = 3.7999  Validation loss = 1.4460  \n",
      "\n",
      "Fold: 22  Epoch: 155  Training loss = 3.7995  Validation loss = 1.4461  \n",
      "\n",
      "Fold: 22  Epoch: 156  Training loss = 3.7992  Validation loss = 1.4461  \n",
      "\n",
      "Fold: 22  Epoch: 157  Training loss = 3.7988  Validation loss = 1.4460  \n",
      "\n",
      "Fold: 22  Epoch: 158  Training loss = 3.7984  Validation loss = 1.4460  \n",
      "\n",
      "Fold: 22  Epoch: 159  Training loss = 3.7979  Validation loss = 1.4460  \n",
      "\n",
      "Fold: 22  Epoch: 160  Training loss = 3.7977  Validation loss = 1.4459  \n",
      "\n",
      "Fold: 22  Epoch: 161  Training loss = 3.7974  Validation loss = 1.4459  \n",
      "\n",
      "Fold: 22  Epoch: 162  Training loss = 3.7970  Validation loss = 1.4458  \n",
      "\n",
      "Fold: 22  Epoch: 163  Training loss = 3.7967  Validation loss = 1.4457  \n",
      "\n",
      "Fold: 22  Epoch: 164  Training loss = 3.7962  Validation loss = 1.4457  \n",
      "\n",
      "Fold: 22  Epoch: 165  Training loss = 3.7960  Validation loss = 1.4456  \n",
      "\n",
      "Fold: 22  Epoch: 166  Training loss = 3.7956  Validation loss = 1.4455  \n",
      "\n",
      "Fold: 22  Epoch: 167  Training loss = 3.7953  Validation loss = 1.4455  \n",
      "\n",
      "Fold: 22  Epoch: 168  Training loss = 3.7950  Validation loss = 1.4454  \n",
      "\n",
      "Fold: 22  Epoch: 169  Training loss = 3.7948  Validation loss = 1.4454  \n",
      "\n",
      "Fold: 22  Epoch: 170  Training loss = 3.7945  Validation loss = 1.4454  \n",
      "\n",
      "Fold: 22  Epoch: 171  Training loss = 3.7942  Validation loss = 1.4453  \n",
      "\n",
      "Fold: 22  Epoch: 172  Training loss = 3.7939  Validation loss = 1.4453  \n",
      "\n",
      "Fold: 22  Epoch: 173  Training loss = 3.7935  Validation loss = 1.4453  \n",
      "\n",
      "Fold: 22  Epoch: 174  Training loss = 3.7932  Validation loss = 1.4454  \n",
      "\n",
      "Fold: 22  Epoch: 175  Training loss = 3.7929  Validation loss = 1.4453  \n",
      "\n",
      "Fold: 22  Epoch: 176  Training loss = 3.7925  Validation loss = 1.4453  \n",
      "\n",
      "Fold: 22  Epoch: 177  Training loss = 3.7922  Validation loss = 1.4453  \n",
      "\n",
      "Fold: 22  Epoch: 178  Training loss = 3.7919  Validation loss = 1.4452  \n",
      "\n",
      "Fold: 22  Epoch: 179  Training loss = 3.7914  Validation loss = 1.4452  \n",
      "\n",
      "Fold: 22  Epoch: 180  Training loss = 3.7912  Validation loss = 1.4452  \n",
      "\n",
      "Fold: 22  Epoch: 181  Training loss = 3.7908  Validation loss = 1.4452  \n",
      "\n",
      "Fold: 22  Epoch: 182  Training loss = 3.7906  Validation loss = 1.4452  \n",
      "\n",
      "Fold: 22  Epoch: 183  Training loss = 3.7902  Validation loss = 1.4452  \n",
      "\n",
      "Fold: 22  Epoch: 184  Training loss = 3.7897  Validation loss = 1.4452  \n",
      "\n",
      "Fold: 22  Epoch: 185  Training loss = 3.7894  Validation loss = 1.4452  \n",
      "\n",
      "Fold: 22  Epoch: 186  Training loss = 3.7892  Validation loss = 1.4451  \n",
      "\n",
      "Fold: 22  Epoch: 187  Training loss = 3.7887  Validation loss = 1.4451  \n",
      "\n",
      "Fold: 22  Epoch: 188  Training loss = 3.7885  Validation loss = 1.4451  \n",
      "\n",
      "Fold: 22  Epoch: 189  Training loss = 3.7881  Validation loss = 1.4451  \n",
      "\n",
      "Fold: 22  Epoch: 190  Training loss = 3.7878  Validation loss = 1.4451  \n",
      "\n",
      "Fold: 22  Epoch: 191  Training loss = 3.7874  Validation loss = 1.4451  \n",
      "\n",
      "Fold: 22  Epoch: 192  Training loss = 3.7871  Validation loss = 1.4452  \n",
      "\n",
      "Fold: 22  Epoch: 193  Training loss = 3.7868  Validation loss = 1.4451  \n",
      "\n",
      "Fold: 22  Epoch: 194  Training loss = 3.7863  Validation loss = 1.4451  \n",
      "\n",
      "Fold: 22  Epoch: 195  Training loss = 3.7859  Validation loss = 1.4450  \n",
      "\n",
      "Fold: 22  Epoch: 196  Training loss = 3.7855  Validation loss = 1.4451  \n",
      "\n",
      "Fold: 22  Epoch: 197  Training loss = 3.7852  Validation loss = 1.4451  \n",
      "\n",
      "Fold: 22  Epoch: 198  Training loss = 3.7847  Validation loss = 1.4451  \n",
      "\n",
      "Fold: 22  Epoch: 199  Training loss = 3.7843  Validation loss = 1.4451  \n",
      "\n",
      "Fold: 22  Epoch: 200  Training loss = 3.7839  Validation loss = 1.4451  \n",
      "\n",
      "Fold: 22  Epoch: 201  Training loss = 3.7837  Validation loss = 1.4451  \n",
      "\n",
      "Fold: 22  Epoch: 202  Training loss = 3.7833  Validation loss = 1.4451  \n",
      "\n",
      "Fold: 22  Epoch: 203  Training loss = 3.7830  Validation loss = 1.4451  \n",
      "\n",
      "Check model:  Fold: 22  Epoch: 195  Training loss = 3.7830  Validation loss = 1.4451  \n",
      "\n",
      "Fold: 23  Epoch: 1  Training loss = 3.7802  Validation loss = 0.9210  \n",
      "\n",
      "Fold: 23  Epoch: 2  Training loss = 3.7801  Validation loss = 0.9211  \n",
      "\n",
      "Fold: 23  Epoch: 3  Training loss = 3.7796  Validation loss = 0.9215  \n",
      "\n",
      "Fold: 23  Epoch: 4  Training loss = 3.7793  Validation loss = 0.9217  \n",
      "\n",
      "Fold: 23  Epoch: 5  Training loss = 3.7791  Validation loss = 0.9219  \n",
      "\n",
      "Fold: 23  Epoch: 6  Training loss = 3.7787  Validation loss = 0.9221  \n",
      "\n",
      "Fold: 23  Epoch: 7  Training loss = 3.7783  Validation loss = 0.9224  \n",
      "\n",
      "Fold: 23  Epoch: 8  Training loss = 3.7779  Validation loss = 0.9225  \n",
      "\n",
      "Fold: 23  Epoch: 9  Training loss = 3.7775  Validation loss = 0.9227  \n",
      "\n",
      "Fold: 23  Epoch: 10  Training loss = 3.7771  Validation loss = 0.9230  \n",
      "\n",
      "Fold: 23  Epoch: 11  Training loss = 3.7770  Validation loss = 0.9230  \n",
      "\n",
      "Check model:  Fold: 23  Epoch: 1  Training loss = 3.7770  Validation loss = 0.9230  \n",
      "\n",
      "Fold: 24  Epoch: 1  Training loss = 3.7339  Validation loss = 2.1277  \n",
      "\n",
      "Fold: 24  Epoch: 2  Training loss = 3.7335  Validation loss = 2.1273  \n",
      "\n",
      "Fold: 24  Epoch: 3  Training loss = 3.7330  Validation loss = 2.1270  \n",
      "\n",
      "Fold: 24  Epoch: 4  Training loss = 3.7326  Validation loss = 2.1266  \n",
      "\n",
      "Fold: 24  Epoch: 5  Training loss = 3.7323  Validation loss = 2.1264  \n",
      "\n",
      "Fold: 24  Epoch: 6  Training loss = 3.7319  Validation loss = 2.1261  \n",
      "\n",
      "Fold: 24  Epoch: 7  Training loss = 3.7312  Validation loss = 2.1256  \n",
      "\n",
      "Fold: 24  Epoch: 8  Training loss = 3.7307  Validation loss = 2.1252  \n",
      "\n",
      "Fold: 24  Epoch: 9  Training loss = 3.7302  Validation loss = 2.1248  \n",
      "\n",
      "Fold: 24  Epoch: 10  Training loss = 3.7298  Validation loss = 2.1244  \n",
      "\n",
      "Fold: 24  Epoch: 11  Training loss = 3.7291  Validation loss = 2.1240  \n",
      "\n",
      "Fold: 24  Epoch: 12  Training loss = 3.7286  Validation loss = 2.1236  \n",
      "\n",
      "Fold: 24  Epoch: 13  Training loss = 3.7283  Validation loss = 2.1233  \n",
      "\n",
      "Fold: 24  Epoch: 14  Training loss = 3.7279  Validation loss = 2.1231  \n",
      "\n",
      "Fold: 24  Epoch: 15  Training loss = 3.7274  Validation loss = 2.1228  \n",
      "\n",
      "Fold: 24  Epoch: 16  Training loss = 3.7269  Validation loss = 2.1226  \n",
      "\n",
      "Fold: 24  Epoch: 17  Training loss = 3.7266  Validation loss = 2.1222  \n",
      "\n",
      "Fold: 24  Epoch: 18  Training loss = 3.7260  Validation loss = 2.1219  \n",
      "\n",
      "Fold: 24  Epoch: 19  Training loss = 3.7256  Validation loss = 2.1217  \n",
      "\n",
      "Fold: 24  Epoch: 20  Training loss = 3.7251  Validation loss = 2.1213  \n",
      "\n",
      "Fold: 24  Epoch: 21  Training loss = 3.7247  Validation loss = 2.1210  \n",
      "\n",
      "Fold: 24  Epoch: 22  Training loss = 3.7241  Validation loss = 2.1207  \n",
      "\n",
      "Fold: 24  Epoch: 23  Training loss = 3.7238  Validation loss = 2.1203  \n",
      "\n",
      "Fold: 24  Epoch: 24  Training loss = 3.7233  Validation loss = 2.1200  \n",
      "\n",
      "Fold: 24  Epoch: 25  Training loss = 3.7230  Validation loss = 2.1198  \n",
      "\n",
      "Fold: 24  Epoch: 26  Training loss = 3.7225  Validation loss = 2.1195  \n",
      "\n",
      "Fold: 24  Epoch: 27  Training loss = 3.7220  Validation loss = 2.1192  \n",
      "\n",
      "Fold: 24  Epoch: 28  Training loss = 3.7214  Validation loss = 2.1187  \n",
      "\n",
      "Fold: 24  Epoch: 29  Training loss = 3.7207  Validation loss = 2.1183  \n",
      "\n",
      "Fold: 24  Epoch: 30  Training loss = 3.7203  Validation loss = 2.1180  \n",
      "\n",
      "Fold: 24  Epoch: 31  Training loss = 3.7198  Validation loss = 2.1175  \n",
      "\n",
      "Fold: 24  Epoch: 32  Training loss = 3.7193  Validation loss = 2.1172  \n",
      "\n",
      "Fold: 24  Epoch: 33  Training loss = 3.7188  Validation loss = 2.1169  \n",
      "\n",
      "Fold: 24  Epoch: 34  Training loss = 3.7184  Validation loss = 2.1167  \n",
      "\n",
      "Fold: 24  Epoch: 35  Training loss = 3.7180  Validation loss = 2.1164  \n",
      "\n",
      "Fold: 24  Epoch: 36  Training loss = 3.7175  Validation loss = 2.1160  \n",
      "\n",
      "Fold: 24  Epoch: 37  Training loss = 3.7170  Validation loss = 2.1158  \n",
      "\n",
      "Fold: 24  Epoch: 38  Training loss = 3.7165  Validation loss = 2.1156  \n",
      "\n",
      "Fold: 24  Epoch: 39  Training loss = 3.7161  Validation loss = 2.1153  \n",
      "\n",
      "Fold: 24  Epoch: 40  Training loss = 3.7157  Validation loss = 2.1150  \n",
      "\n",
      "Fold: 24  Epoch: 41  Training loss = 3.7154  Validation loss = 2.1148  \n",
      "\n",
      "Fold: 24  Epoch: 42  Training loss = 3.7150  Validation loss = 2.1147  \n",
      "\n",
      "Fold: 24  Epoch: 43  Training loss = 3.7145  Validation loss = 2.1144  \n",
      "\n",
      "Fold: 24  Epoch: 44  Training loss = 3.7141  Validation loss = 2.1141  \n",
      "\n",
      "Fold: 24  Epoch: 45  Training loss = 3.7136  Validation loss = 2.1138  \n",
      "\n",
      "Fold: 24  Epoch: 46  Training loss = 3.7129  Validation loss = 2.1135  \n",
      "\n",
      "Fold: 24  Epoch: 47  Training loss = 3.7126  Validation loss = 2.1132  \n",
      "\n",
      "Fold: 24  Epoch: 48  Training loss = 3.7120  Validation loss = 2.1130  \n",
      "\n",
      "Fold: 24  Epoch: 49  Training loss = 3.7116  Validation loss = 2.1127  \n",
      "\n",
      "Fold: 24  Epoch: 50  Training loss = 3.7110  Validation loss = 2.1123  \n",
      "\n",
      "Fold: 24  Epoch: 51  Training loss = 3.7107  Validation loss = 2.1120  \n",
      "\n",
      "Fold: 24  Epoch: 52  Training loss = 3.7102  Validation loss = 2.1118  \n",
      "\n",
      "Fold: 24  Epoch: 53  Training loss = 3.7098  Validation loss = 2.1115  \n",
      "\n",
      "Fold: 24  Epoch: 54  Training loss = 3.7092  Validation loss = 2.1111  \n",
      "\n",
      "Fold: 24  Epoch: 55  Training loss = 3.7087  Validation loss = 2.1108  \n",
      "\n",
      "Fold: 24  Epoch: 56  Training loss = 3.7082  Validation loss = 2.1105  \n",
      "\n",
      "Fold: 24  Epoch: 57  Training loss = 3.7076  Validation loss = 2.1099  \n",
      "\n",
      "Fold: 24  Epoch: 58  Training loss = 3.7071  Validation loss = 2.1097  \n",
      "\n",
      "Fold: 24  Epoch: 59  Training loss = 3.7065  Validation loss = 2.1094  \n",
      "\n",
      "Fold: 24  Epoch: 60  Training loss = 3.7061  Validation loss = 2.1094  \n",
      "\n",
      "Fold: 24  Epoch: 61  Training loss = 3.7057  Validation loss = 2.1090  \n",
      "\n",
      "Fold: 24  Epoch: 62  Training loss = 3.7052  Validation loss = 2.1087  \n",
      "\n",
      "Fold: 24  Epoch: 63  Training loss = 3.7046  Validation loss = 2.1084  \n",
      "\n",
      "Fold: 24  Epoch: 64  Training loss = 3.7042  Validation loss = 2.1083  \n",
      "\n",
      "Fold: 24  Epoch: 65  Training loss = 3.7036  Validation loss = 2.1077  \n",
      "\n",
      "Fold: 24  Epoch: 66  Training loss = 3.7031  Validation loss = 2.1073  \n",
      "\n",
      "Fold: 24  Epoch: 67  Training loss = 3.7028  Validation loss = 2.1071  \n",
      "\n",
      "Fold: 24  Epoch: 68  Training loss = 3.7024  Validation loss = 2.1068  \n",
      "\n",
      "Fold: 24  Epoch: 69  Training loss = 3.7020  Validation loss = 2.1065  \n",
      "\n",
      "Fold: 24  Epoch: 70  Training loss = 3.7015  Validation loss = 2.1062  \n",
      "\n",
      "Fold: 24  Epoch: 71  Training loss = 3.7011  Validation loss = 2.1057  \n",
      "\n",
      "Fold: 24  Epoch: 72  Training loss = 3.7006  Validation loss = 2.1054  \n",
      "\n",
      "Fold: 24  Epoch: 73  Training loss = 3.7000  Validation loss = 2.1050  \n",
      "\n",
      "Fold: 24  Epoch: 74  Training loss = 3.6997  Validation loss = 2.1049  \n",
      "\n",
      "Fold: 24  Epoch: 75  Training loss = 3.6992  Validation loss = 2.1045  \n",
      "\n",
      "Fold: 24  Epoch: 76  Training loss = 3.6989  Validation loss = 2.1042  \n",
      "\n",
      "Fold: 24  Epoch: 77  Training loss = 3.6985  Validation loss = 2.1040  \n",
      "\n",
      "Fold: 24  Epoch: 78  Training loss = 3.6980  Validation loss = 2.1038  \n",
      "\n",
      "Fold: 24  Epoch: 79  Training loss = 3.6976  Validation loss = 2.1034  \n",
      "\n",
      "Fold: 24  Epoch: 80  Training loss = 3.6971  Validation loss = 2.1029  \n",
      "\n",
      "Fold: 24  Epoch: 81  Training loss = 3.6968  Validation loss = 2.1027  \n",
      "\n",
      "Fold: 24  Epoch: 82  Training loss = 3.6961  Validation loss = 2.1022  \n",
      "\n",
      "Fold: 24  Epoch: 83  Training loss = 3.6956  Validation loss = 2.1019  \n",
      "\n",
      "Fold: 24  Epoch: 84  Training loss = 3.6951  Validation loss = 2.1013  \n",
      "\n",
      "Fold: 24  Epoch: 85  Training loss = 3.6945  Validation loss = 2.1009  \n",
      "\n",
      "Fold: 24  Epoch: 86  Training loss = 3.6941  Validation loss = 2.1006  \n",
      "\n",
      "Fold: 24  Epoch: 87  Training loss = 3.6937  Validation loss = 2.1004  \n",
      "\n",
      "Fold: 24  Epoch: 88  Training loss = 3.6933  Validation loss = 2.1001  \n",
      "\n",
      "Fold: 24  Epoch: 89  Training loss = 3.6930  Validation loss = 2.0999  \n",
      "\n",
      "Fold: 24  Epoch: 90  Training loss = 3.6926  Validation loss = 2.0997  \n",
      "\n",
      "Fold: 24  Epoch: 91  Training loss = 3.6919  Validation loss = 2.0991  \n",
      "\n",
      "Fold: 24  Epoch: 92  Training loss = 3.6914  Validation loss = 2.0987  \n",
      "\n",
      "Fold: 24  Epoch: 93  Training loss = 3.6908  Validation loss = 2.0984  \n",
      "\n",
      "Fold: 24  Epoch: 94  Training loss = 3.6904  Validation loss = 2.0979  \n",
      "\n",
      "Fold: 24  Epoch: 95  Training loss = 3.6900  Validation loss = 2.0976  \n",
      "\n",
      "Fold: 24  Epoch: 96  Training loss = 3.6896  Validation loss = 2.0974  \n",
      "\n",
      "Fold: 24  Epoch: 97  Training loss = 3.6893  Validation loss = 2.0972  \n",
      "\n",
      "Fold: 24  Epoch: 98  Training loss = 3.6889  Validation loss = 2.0969  \n",
      "\n",
      "Fold: 24  Epoch: 99  Training loss = 3.6887  Validation loss = 2.0967  \n",
      "\n",
      "Fold: 24  Epoch: 100  Training loss = 3.6883  Validation loss = 2.0967  \n",
      "\n",
      "Fold: 24  Epoch: 101  Training loss = 3.6877  Validation loss = 2.0962  \n",
      "\n",
      "Fold: 24  Epoch: 102  Training loss = 3.6871  Validation loss = 2.0960  \n",
      "\n",
      "Fold: 24  Epoch: 103  Training loss = 3.6867  Validation loss = 2.0956  \n",
      "\n",
      "Fold: 24  Epoch: 104  Training loss = 3.6862  Validation loss = 2.0952  \n",
      "\n",
      "Fold: 24  Epoch: 105  Training loss = 3.6858  Validation loss = 2.0949  \n",
      "\n",
      "Fold: 24  Epoch: 106  Training loss = 3.6854  Validation loss = 2.0946  \n",
      "\n",
      "Fold: 24  Epoch: 107  Training loss = 3.6852  Validation loss = 2.0944  \n",
      "\n",
      "Fold: 24  Epoch: 108  Training loss = 3.6848  Validation loss = 2.0942  \n",
      "\n",
      "Fold: 24  Epoch: 109  Training loss = 3.6845  Validation loss = 2.0939  \n",
      "\n",
      "Fold: 24  Epoch: 110  Training loss = 3.6841  Validation loss = 2.0934  \n",
      "\n",
      "Fold: 24  Epoch: 111  Training loss = 3.6838  Validation loss = 2.0932  \n",
      "\n",
      "Fold: 24  Epoch: 112  Training loss = 3.6835  Validation loss = 2.0928  \n",
      "\n",
      "Fold: 24  Epoch: 113  Training loss = 3.6830  Validation loss = 2.0926  \n",
      "\n",
      "Fold: 24  Epoch: 114  Training loss = 3.6826  Validation loss = 2.0923  \n",
      "\n",
      "Fold: 24  Epoch: 115  Training loss = 3.6820  Validation loss = 2.0919  \n",
      "\n",
      "Fold: 24  Epoch: 116  Training loss = 3.6818  Validation loss = 2.0916  \n",
      "\n",
      "Fold: 24  Epoch: 117  Training loss = 3.6813  Validation loss = 2.0912  \n",
      "\n",
      "Fold: 24  Epoch: 118  Training loss = 3.6809  Validation loss = 2.0910  \n",
      "\n",
      "Fold: 24  Epoch: 119  Training loss = 3.6805  Validation loss = 2.0908  \n",
      "\n",
      "Fold: 24  Epoch: 120  Training loss = 3.6800  Validation loss = 2.0904  \n",
      "\n",
      "Fold: 24  Epoch: 121  Training loss = 3.6795  Validation loss = 2.0900  \n",
      "\n",
      "Fold: 24  Epoch: 122  Training loss = 3.6791  Validation loss = 2.0897  \n",
      "\n",
      "Fold: 24  Epoch: 123  Training loss = 3.6788  Validation loss = 2.0894  \n",
      "\n",
      "Fold: 24  Epoch: 124  Training loss = 3.6784  Validation loss = 2.0891  \n",
      "\n",
      "Fold: 24  Epoch: 125  Training loss = 3.6781  Validation loss = 2.0889  \n",
      "\n",
      "Fold: 24  Epoch: 126  Training loss = 3.6774  Validation loss = 2.0884  \n",
      "\n",
      "Fold: 24  Epoch: 127  Training loss = 3.6770  Validation loss = 2.0881  \n",
      "\n",
      "Fold: 24  Epoch: 128  Training loss = 3.6767  Validation loss = 2.0879  \n",
      "\n",
      "Fold: 24  Epoch: 129  Training loss = 3.6762  Validation loss = 2.0875  \n",
      "\n",
      "Fold: 24  Epoch: 130  Training loss = 3.6756  Validation loss = 2.0871  \n",
      "\n",
      "Fold: 24  Epoch: 131  Training loss = 3.6751  Validation loss = 2.0867  \n",
      "\n",
      "Fold: 24  Epoch: 132  Training loss = 3.6747  Validation loss = 2.0863  \n",
      "\n",
      "Fold: 24  Epoch: 133  Training loss = 3.6743  Validation loss = 2.0860  \n",
      "\n",
      "Fold: 24  Epoch: 134  Training loss = 3.6738  Validation loss = 2.0857  \n",
      "\n",
      "Fold: 24  Epoch: 135  Training loss = 3.6734  Validation loss = 2.0855  \n",
      "\n",
      "Fold: 24  Epoch: 136  Training loss = 3.6731  Validation loss = 2.0854  \n",
      "\n",
      "Fold: 24  Epoch: 137  Training loss = 3.6726  Validation loss = 2.0850  \n",
      "\n",
      "Fold: 24  Epoch: 138  Training loss = 3.6721  Validation loss = 2.0848  \n",
      "\n",
      "Fold: 24  Epoch: 139  Training loss = 3.6718  Validation loss = 2.0845  \n",
      "\n",
      "Fold: 24  Epoch: 140  Training loss = 3.6713  Validation loss = 2.0842  \n",
      "\n",
      "Fold: 24  Epoch: 141  Training loss = 3.6709  Validation loss = 2.0840  \n",
      "\n",
      "Fold: 24  Epoch: 142  Training loss = 3.6704  Validation loss = 2.0837  \n",
      "\n",
      "Fold: 24  Epoch: 143  Training loss = 3.6701  Validation loss = 2.0833  \n",
      "\n",
      "Fold: 24  Epoch: 144  Training loss = 3.6697  Validation loss = 2.0830  \n",
      "\n",
      "Fold: 24  Epoch: 145  Training loss = 3.6693  Validation loss = 2.0826  \n",
      "\n",
      "Fold: 24  Epoch: 146  Training loss = 3.6690  Validation loss = 2.0823  \n",
      "\n",
      "Fold: 24  Epoch: 147  Training loss = 3.6685  Validation loss = 2.0821  \n",
      "\n",
      "Fold: 24  Epoch: 148  Training loss = 3.6681  Validation loss = 2.0819  \n",
      "\n",
      "Fold: 24  Epoch: 149  Training loss = 3.6678  Validation loss = 2.0816  \n",
      "\n",
      "Fold: 24  Epoch: 150  Training loss = 3.6673  Validation loss = 2.0813  \n",
      "\n",
      "Fold: 24  Epoch: 151  Training loss = 3.6670  Validation loss = 2.0810  \n",
      "\n",
      "Fold: 24  Epoch: 152  Training loss = 3.6666  Validation loss = 2.0807  \n",
      "\n",
      "Fold: 24  Epoch: 153  Training loss = 3.6662  Validation loss = 2.0802  \n",
      "\n",
      "Fold: 24  Epoch: 154  Training loss = 3.6657  Validation loss = 2.0798  \n",
      "\n",
      "Fold: 24  Epoch: 155  Training loss = 3.6653  Validation loss = 2.0795  \n",
      "\n",
      "Fold: 24  Epoch: 156  Training loss = 3.6648  Validation loss = 2.0790  \n",
      "\n",
      "Fold: 24  Epoch: 157  Training loss = 3.6646  Validation loss = 2.0789  \n",
      "\n",
      "Fold: 24  Epoch: 158  Training loss = 3.6644  Validation loss = 2.0788  \n",
      "\n",
      "Fold: 24  Epoch: 159  Training loss = 3.6641  Validation loss = 2.0784  \n",
      "\n",
      "Fold: 24  Epoch: 160  Training loss = 3.6636  Validation loss = 2.0782  \n",
      "\n",
      "Fold: 24  Epoch: 161  Training loss = 3.6632  Validation loss = 2.0779  \n",
      "\n",
      "Fold: 24  Epoch: 162  Training loss = 3.6627  Validation loss = 2.0775  \n",
      "\n",
      "Fold: 24  Epoch: 163  Training loss = 3.6623  Validation loss = 2.0773  \n",
      "\n",
      "Fold: 24  Epoch: 164  Training loss = 3.6618  Validation loss = 2.0769  \n",
      "\n",
      "Fold: 24  Epoch: 165  Training loss = 3.6613  Validation loss = 2.0767  \n",
      "\n",
      "Fold: 24  Epoch: 166  Training loss = 3.6608  Validation loss = 2.0763  \n",
      "\n",
      "Fold: 24  Epoch: 167  Training loss = 3.6604  Validation loss = 2.0760  \n",
      "\n",
      "Fold: 24  Epoch: 168  Training loss = 3.6602  Validation loss = 2.0758  \n",
      "\n",
      "Fold: 24  Epoch: 169  Training loss = 3.6599  Validation loss = 2.0757  \n",
      "\n",
      "Fold: 24  Epoch: 170  Training loss = 3.6596  Validation loss = 2.0756  \n",
      "\n",
      "Fold: 24  Epoch: 171  Training loss = 3.6594  Validation loss = 2.0754  \n",
      "\n",
      "Fold: 24  Epoch: 172  Training loss = 3.6591  Validation loss = 2.0753  \n",
      "\n",
      "Fold: 24  Epoch: 173  Training loss = 3.6586  Validation loss = 2.0749  \n",
      "\n",
      "Fold: 24  Epoch: 174  Training loss = 3.6583  Validation loss = 2.0746  \n",
      "\n",
      "Fold: 24  Epoch: 175  Training loss = 3.6580  Validation loss = 2.0741  \n",
      "\n",
      "Fold: 24  Epoch: 176  Training loss = 3.6576  Validation loss = 2.0738  \n",
      "\n",
      "Fold: 24  Epoch: 177  Training loss = 3.6571  Validation loss = 2.0734  \n",
      "\n",
      "Fold: 24  Epoch: 178  Training loss = 3.6567  Validation loss = 2.0729  \n",
      "\n",
      "Fold: 24  Epoch: 179  Training loss = 3.6565  Validation loss = 2.0725  \n",
      "\n",
      "Fold: 24  Epoch: 180  Training loss = 3.6560  Validation loss = 2.0722  \n",
      "\n",
      "Fold: 24  Epoch: 181  Training loss = 3.6555  Validation loss = 2.0720  \n",
      "\n",
      "Fold: 24  Epoch: 182  Training loss = 3.6551  Validation loss = 2.0717  \n",
      "\n",
      "Fold: 24  Epoch: 183  Training loss = 3.6545  Validation loss = 2.0713  \n",
      "\n",
      "Fold: 24  Epoch: 184  Training loss = 3.6541  Validation loss = 2.0708  \n",
      "\n",
      "Fold: 24  Epoch: 185  Training loss = 3.6537  Validation loss = 2.0707  \n",
      "\n",
      "Fold: 24  Epoch: 186  Training loss = 3.6532  Validation loss = 2.0705  \n",
      "\n",
      "Fold: 24  Epoch: 187  Training loss = 3.6529  Validation loss = 2.0704  \n",
      "\n",
      "Fold: 24  Epoch: 188  Training loss = 3.6526  Validation loss = 2.0700  \n",
      "\n",
      "Fold: 24  Epoch: 189  Training loss = 3.6521  Validation loss = 2.0697  \n",
      "\n",
      "Fold: 24  Epoch: 190  Training loss = 3.6516  Validation loss = 2.0693  \n",
      "\n",
      "Fold: 24  Epoch: 191  Training loss = 3.6512  Validation loss = 2.0690  \n",
      "\n",
      "Fold: 24  Epoch: 192  Training loss = 3.6508  Validation loss = 2.0688  \n",
      "\n",
      "Fold: 24  Epoch: 193  Training loss = 3.6504  Validation loss = 2.0685  \n",
      "\n",
      "Fold: 24  Epoch: 194  Training loss = 3.6500  Validation loss = 2.0681  \n",
      "\n",
      "Fold: 24  Epoch: 195  Training loss = 3.6497  Validation loss = 2.0679  \n",
      "\n",
      "Fold: 24  Epoch: 196  Training loss = 3.6494  Validation loss = 2.0679  \n",
      "\n",
      "Fold: 24  Epoch: 197  Training loss = 3.6492  Validation loss = 2.0679  \n",
      "\n",
      "Fold: 24  Epoch: 198  Training loss = 3.6487  Validation loss = 2.0676  \n",
      "\n",
      "Fold: 24  Epoch: 199  Training loss = 3.6483  Validation loss = 2.0673  \n",
      "\n",
      "Fold: 24  Epoch: 200  Training loss = 3.6476  Validation loss = 2.0668  \n",
      "\n",
      "Fold: 24  Epoch: 201  Training loss = 3.6474  Validation loss = 2.0667  \n",
      "\n",
      "Fold: 24  Epoch: 202  Training loss = 3.6470  Validation loss = 2.0664  \n",
      "\n",
      "Fold: 24  Epoch: 203  Training loss = 3.6466  Validation loss = 2.0662  \n",
      "\n",
      "Fold: 24  Epoch: 204  Training loss = 3.6461  Validation loss = 2.0658  \n",
      "\n",
      "Fold: 24  Epoch: 205  Training loss = 3.6457  Validation loss = 2.0656  \n",
      "\n",
      "Fold: 24  Epoch: 206  Training loss = 3.6454  Validation loss = 2.0654  \n",
      "\n",
      "Fold: 24  Epoch: 207  Training loss = 3.6449  Validation loss = 2.0650  \n",
      "\n",
      "Fold: 24  Epoch: 208  Training loss = 3.6446  Validation loss = 2.0649  \n",
      "\n",
      "Fold: 24  Epoch: 209  Training loss = 3.6441  Validation loss = 2.0646  \n",
      "\n",
      "Fold: 24  Epoch: 210  Training loss = 3.6437  Validation loss = 2.0643  \n",
      "\n",
      "Fold: 24  Epoch: 211  Training loss = 3.6434  Validation loss = 2.0640  \n",
      "\n",
      "Fold: 24  Epoch: 212  Training loss = 3.6431  Validation loss = 2.0638  \n",
      "\n",
      "Fold: 24  Epoch: 213  Training loss = 3.6427  Validation loss = 2.0635  \n",
      "\n",
      "Fold: 24  Epoch: 214  Training loss = 3.6422  Validation loss = 2.0631  \n",
      "\n",
      "Fold: 24  Epoch: 215  Training loss = 3.6417  Validation loss = 2.0628  \n",
      "\n",
      "Fold: 24  Epoch: 216  Training loss = 3.6414  Validation loss = 2.0625  \n",
      "\n",
      "Fold: 24  Epoch: 217  Training loss = 3.6409  Validation loss = 2.0621  \n",
      "\n",
      "Fold: 24  Epoch: 218  Training loss = 3.6405  Validation loss = 2.0617  \n",
      "\n",
      "Fold: 24  Epoch: 219  Training loss = 3.6401  Validation loss = 2.0615  \n",
      "\n",
      "Fold: 24  Epoch: 220  Training loss = 3.6396  Validation loss = 2.0610  \n",
      "\n",
      "Fold: 24  Epoch: 221  Training loss = 3.6393  Validation loss = 2.0608  \n",
      "\n",
      "Fold: 24  Epoch: 222  Training loss = 3.6388  Validation loss = 2.0605  \n",
      "\n",
      "Fold: 24  Epoch: 223  Training loss = 3.6384  Validation loss = 2.0603  \n",
      "\n",
      "Fold: 24  Epoch: 224  Training loss = 3.6379  Validation loss = 2.0600  \n",
      "\n",
      "Fold: 24  Epoch: 225  Training loss = 3.6374  Validation loss = 2.0597  \n",
      "\n",
      "Fold: 24  Epoch: 226  Training loss = 3.6370  Validation loss = 2.0595  \n",
      "\n",
      "Fold: 24  Epoch: 227  Training loss = 3.6367  Validation loss = 2.0594  \n",
      "\n",
      "Fold: 24  Epoch: 228  Training loss = 3.6364  Validation loss = 2.0593  \n",
      "\n",
      "Fold: 24  Epoch: 229  Training loss = 3.6358  Validation loss = 2.0590  \n",
      "\n",
      "Fold: 24  Epoch: 230  Training loss = 3.6353  Validation loss = 2.0586  \n",
      "\n",
      "Fold: 24  Epoch: 231  Training loss = 3.6346  Validation loss = 2.0580  \n",
      "\n",
      "Fold: 24  Epoch: 232  Training loss = 3.6341  Validation loss = 2.0576  \n",
      "\n",
      "Fold: 24  Epoch: 233  Training loss = 3.6335  Validation loss = 2.0572  \n",
      "\n",
      "Fold: 24  Epoch: 234  Training loss = 3.6331  Validation loss = 2.0569  \n",
      "\n",
      "Fold: 24  Epoch: 235  Training loss = 3.6325  Validation loss = 2.0566  \n",
      "\n",
      "Fold: 24  Epoch: 236  Training loss = 3.6321  Validation loss = 2.0564  \n",
      "\n",
      "Fold: 24  Epoch: 237  Training loss = 3.6318  Validation loss = 2.0560  \n",
      "\n",
      "Fold: 24  Epoch: 238  Training loss = 3.6315  Validation loss = 2.0559  \n",
      "\n",
      "Fold: 24  Epoch: 239  Training loss = 3.6313  Validation loss = 2.0558  \n",
      "\n",
      "Fold: 24  Epoch: 240  Training loss = 3.6309  Validation loss = 2.0555  \n",
      "\n",
      "Fold: 24  Epoch: 241  Training loss = 3.6305  Validation loss = 2.0552  \n",
      "\n",
      "Fold: 24  Epoch: 242  Training loss = 3.6301  Validation loss = 2.0549  \n",
      "\n",
      "Fold: 24  Epoch: 243  Training loss = 3.6296  Validation loss = 2.0547  \n",
      "\n",
      "Fold: 24  Epoch: 244  Training loss = 3.6292  Validation loss = 2.0545  \n",
      "\n",
      "Fold: 24  Epoch: 245  Training loss = 3.6289  Validation loss = 2.0544  \n",
      "\n",
      "Fold: 24  Epoch: 246  Training loss = 3.6286  Validation loss = 2.0542  \n",
      "\n",
      "Fold: 24  Epoch: 247  Training loss = 3.6282  Validation loss = 2.0540  \n",
      "\n",
      "Fold: 24  Epoch: 248  Training loss = 3.6277  Validation loss = 2.0536  \n",
      "\n",
      "Fold: 24  Epoch: 249  Training loss = 3.6272  Validation loss = 2.0533  \n",
      "\n",
      "Fold: 24  Epoch: 250  Training loss = 3.6269  Validation loss = 2.0531  \n",
      "\n",
      "Fold: 24  Epoch: 251  Training loss = 3.6265  Validation loss = 2.0529  \n",
      "\n",
      "Fold: 24  Epoch: 252  Training loss = 3.6262  Validation loss = 2.0528  \n",
      "\n",
      "Fold: 24  Epoch: 253  Training loss = 3.6258  Validation loss = 2.0526  \n",
      "\n",
      "Fold: 24  Epoch: 254  Training loss = 3.6258  Validation loss = 2.0527  \n",
      "\n",
      "Fold: 24  Epoch: 255  Training loss = 3.6256  Validation loss = 2.0525  \n",
      "\n",
      "Fold: 24  Epoch: 256  Training loss = 3.6253  Validation loss = 2.0520  \n",
      "\n",
      "Fold: 24  Epoch: 257  Training loss = 3.6248  Validation loss = 2.0518  \n",
      "\n",
      "Fold: 24  Epoch: 258  Training loss = 3.6243  Validation loss = 2.0514  \n",
      "\n",
      "Fold: 24  Epoch: 259  Training loss = 3.6237  Validation loss = 2.0511  \n",
      "\n",
      "Fold: 24  Epoch: 260  Training loss = 3.6233  Validation loss = 2.0508  \n",
      "\n",
      "Fold: 24  Epoch: 261  Training loss = 3.6228  Validation loss = 2.0505  \n",
      "\n",
      "Fold: 24  Epoch: 262  Training loss = 3.6224  Validation loss = 2.0502  \n",
      "\n",
      "Fold: 24  Epoch: 263  Training loss = 3.6219  Validation loss = 2.0499  \n",
      "\n",
      "Fold: 24  Epoch: 264  Training loss = 3.6216  Validation loss = 2.0498  \n",
      "\n",
      "Fold: 24  Epoch: 265  Training loss = 3.6211  Validation loss = 2.0497  \n",
      "\n",
      "Fold: 24  Epoch: 266  Training loss = 3.6207  Validation loss = 2.0496  \n",
      "\n",
      "Fold: 24  Epoch: 267  Training loss = 3.6203  Validation loss = 2.0493  \n",
      "\n",
      "Fold: 24  Epoch: 268  Training loss = 3.6201  Validation loss = 2.0491  \n",
      "\n",
      "Fold: 24  Epoch: 269  Training loss = 3.6195  Validation loss = 2.0488  \n",
      "\n",
      "Fold: 24  Epoch: 270  Training loss = 3.6192  Validation loss = 2.0486  \n",
      "\n",
      "Fold: 24  Epoch: 271  Training loss = 3.6187  Validation loss = 2.0482  \n",
      "\n",
      "Fold: 24  Epoch: 272  Training loss = 3.6185  Validation loss = 2.0481  \n",
      "\n",
      "Fold: 24  Epoch: 273  Training loss = 3.6181  Validation loss = 2.0479  \n",
      "\n",
      "Fold: 24  Epoch: 274  Training loss = 3.6178  Validation loss = 2.0477  \n",
      "\n",
      "Fold: 24  Epoch: 275  Training loss = 3.6175  Validation loss = 2.0474  \n",
      "\n",
      "Fold: 24  Epoch: 276  Training loss = 3.6171  Validation loss = 2.0471  \n",
      "\n",
      "Fold: 24  Epoch: 277  Training loss = 3.6166  Validation loss = 2.0468  \n",
      "\n",
      "Fold: 24  Epoch: 278  Training loss = 3.6163  Validation loss = 2.0465  \n",
      "\n",
      "Fold: 24  Epoch: 279  Training loss = 3.6159  Validation loss = 2.0462  \n",
      "\n",
      "Fold: 24  Epoch: 280  Training loss = 3.6156  Validation loss = 2.0458  \n",
      "\n",
      "Fold: 24  Epoch: 281  Training loss = 3.6152  Validation loss = 2.0456  \n",
      "\n",
      "Fold: 24  Epoch: 282  Training loss = 3.6149  Validation loss = 2.0452  \n",
      "\n",
      "Fold: 24  Epoch: 283  Training loss = 3.6145  Validation loss = 2.0448  \n",
      "\n",
      "Fold: 24  Epoch: 284  Training loss = 3.6142  Validation loss = 2.0447  \n",
      "\n",
      "Fold: 24  Epoch: 285  Training loss = 3.6136  Validation loss = 2.0445  \n",
      "\n",
      "Fold: 24  Epoch: 286  Training loss = 3.6133  Validation loss = 2.0443  \n",
      "\n",
      "Fold: 24  Epoch: 287  Training loss = 3.6129  Validation loss = 2.0441  \n",
      "\n",
      "Fold: 24  Epoch: 288  Training loss = 3.6125  Validation loss = 2.0438  \n",
      "\n",
      "Fold: 24  Epoch: 289  Training loss = 3.6121  Validation loss = 2.0436  \n",
      "\n",
      "Fold: 24  Epoch: 290  Training loss = 3.6116  Validation loss = 2.0432  \n",
      "\n",
      "Fold: 24  Epoch: 291  Training loss = 3.6115  Validation loss = 2.0430  \n",
      "\n",
      "Fold: 24  Epoch: 292  Training loss = 3.6111  Validation loss = 2.0427  \n",
      "\n",
      "Fold: 24  Epoch: 293  Training loss = 3.6106  Validation loss = 2.0424  \n",
      "\n",
      "Fold: 24  Epoch: 294  Training loss = 3.6104  Validation loss = 2.0422  \n",
      "\n",
      "Fold: 24  Epoch: 295  Training loss = 3.6099  Validation loss = 2.0419  \n",
      "\n",
      "Fold: 24  Epoch: 296  Training loss = 3.6097  Validation loss = 2.0417  \n",
      "\n",
      "Fold: 24  Epoch: 297  Training loss = 3.6095  Validation loss = 2.0416  \n",
      "\n",
      "Fold: 24  Epoch: 298  Training loss = 3.6091  Validation loss = 2.0414  \n",
      "\n",
      "Fold: 24  Epoch: 299  Training loss = 3.6088  Validation loss = 2.0413  \n",
      "\n",
      "Fold: 24  Epoch: 300  Training loss = 3.6085  Validation loss = 2.0410  \n",
      "\n",
      "Fold: 24  Epoch: 301  Training loss = 3.6082  Validation loss = 2.0407  \n",
      "\n",
      "Fold: 24  Epoch: 302  Training loss = 3.6079  Validation loss = 2.0404  \n",
      "\n",
      "Fold: 24  Epoch: 303  Training loss = 3.6076  Validation loss = 2.0403  \n",
      "\n",
      "Fold: 24  Epoch: 304  Training loss = 3.6070  Validation loss = 2.0401  \n",
      "\n",
      "Fold: 24  Epoch: 305  Training loss = 3.6065  Validation loss = 2.0398  \n",
      "\n",
      "Fold: 24  Epoch: 306  Training loss = 3.6062  Validation loss = 2.0395  \n",
      "\n",
      "Fold: 24  Epoch: 307  Training loss = 3.6060  Validation loss = 2.0394  \n",
      "\n",
      "Fold: 24  Epoch: 308  Training loss = 3.6056  Validation loss = 2.0392  \n",
      "\n",
      "Fold: 24  Epoch: 309  Training loss = 3.6054  Validation loss = 2.0391  \n",
      "\n",
      "Fold: 24  Epoch: 310  Training loss = 3.6050  Validation loss = 2.0387  \n",
      "\n",
      "Fold: 24  Epoch: 311  Training loss = 3.6045  Validation loss = 2.0385  \n",
      "\n",
      "Fold: 24  Epoch: 312  Training loss = 3.6040  Validation loss = 2.0383  \n",
      "\n",
      "Fold: 24  Epoch: 313  Training loss = 3.6035  Validation loss = 2.0382  \n",
      "\n",
      "Fold: 24  Epoch: 314  Training loss = 3.6030  Validation loss = 2.0381  \n",
      "\n",
      "Fold: 24  Epoch: 315  Training loss = 3.6025  Validation loss = 2.0378  \n",
      "\n",
      "Fold: 24  Epoch: 316  Training loss = 3.6022  Validation loss = 2.0376  \n",
      "\n",
      "Fold: 24  Epoch: 317  Training loss = 3.6017  Validation loss = 2.0374  \n",
      "\n",
      "Fold: 24  Epoch: 318  Training loss = 3.6013  Validation loss = 2.0369  \n",
      "\n",
      "Fold: 24  Epoch: 319  Training loss = 3.6008  Validation loss = 2.0364  \n",
      "\n",
      "Fold: 24  Epoch: 320  Training loss = 3.6004  Validation loss = 2.0362  \n",
      "\n",
      "Fold: 24  Epoch: 321  Training loss = 3.6000  Validation loss = 2.0360  \n",
      "\n",
      "Fold: 24  Epoch: 322  Training loss = 3.5996  Validation loss = 2.0358  \n",
      "\n",
      "Fold: 24  Epoch: 323  Training loss = 3.5992  Validation loss = 2.0355  \n",
      "\n",
      "Fold: 24  Epoch: 324  Training loss = 3.5989  Validation loss = 2.0352  \n",
      "\n",
      "Fold: 24  Epoch: 325  Training loss = 3.5986  Validation loss = 2.0349  \n",
      "\n",
      "Fold: 24  Epoch: 326  Training loss = 3.5982  Validation loss = 2.0347  \n",
      "\n",
      "Fold: 24  Epoch: 327  Training loss = 3.5978  Validation loss = 2.0346  \n",
      "\n",
      "Fold: 24  Epoch: 328  Training loss = 3.5974  Validation loss = 2.0343  \n",
      "\n",
      "Fold: 24  Epoch: 329  Training loss = 3.5968  Validation loss = 2.0340  \n",
      "\n",
      "Fold: 24  Epoch: 330  Training loss = 3.5965  Validation loss = 2.0336  \n",
      "\n",
      "Fold: 24  Epoch: 331  Training loss = 3.5960  Validation loss = 2.0334  \n",
      "\n",
      "Fold: 24  Epoch: 332  Training loss = 3.5956  Validation loss = 2.0333  \n",
      "\n",
      "Fold: 24  Epoch: 333  Training loss = 3.5952  Validation loss = 2.0331  \n",
      "\n",
      "Fold: 24  Epoch: 334  Training loss = 3.5948  Validation loss = 2.0328  \n",
      "\n",
      "Fold: 24  Epoch: 335  Training loss = 3.5944  Validation loss = 2.0323  \n",
      "\n",
      "Fold: 24  Epoch: 336  Training loss = 3.5939  Validation loss = 2.0321  \n",
      "\n",
      "Fold: 24  Epoch: 337  Training loss = 3.5936  Validation loss = 2.0318  \n",
      "\n",
      "Fold: 24  Epoch: 338  Training loss = 3.5931  Validation loss = 2.0315  \n",
      "\n",
      "Fold: 24  Epoch: 339  Training loss = 3.5929  Validation loss = 2.0314  \n",
      "\n",
      "Fold: 24  Epoch: 340  Training loss = 3.5925  Validation loss = 2.0312  \n",
      "\n",
      "Fold: 24  Epoch: 341  Training loss = 3.5922  Validation loss = 2.0310  \n",
      "\n",
      "Fold: 24  Epoch: 342  Training loss = 3.5918  Validation loss = 2.0308  \n",
      "\n",
      "Fold: 24  Epoch: 343  Training loss = 3.5915  Validation loss = 2.0308  \n",
      "\n",
      "Fold: 24  Epoch: 344  Training loss = 3.5911  Validation loss = 2.0306  \n",
      "\n",
      "Fold: 24  Epoch: 345  Training loss = 3.5908  Validation loss = 2.0304  \n",
      "\n",
      "Fold: 24  Epoch: 346  Training loss = 3.5904  Validation loss = 2.0303  \n",
      "\n",
      "Fold: 24  Epoch: 347  Training loss = 3.5900  Validation loss = 2.0298  \n",
      "\n",
      "Fold: 24  Epoch: 348  Training loss = 3.5897  Validation loss = 2.0297  \n",
      "\n",
      "Fold: 24  Epoch: 349  Training loss = 3.5893  Validation loss = 2.0292  \n",
      "\n",
      "Fold: 24  Epoch: 350  Training loss = 3.5890  Validation loss = 2.0290  \n",
      "\n",
      "Fold: 24  Epoch: 351  Training loss = 3.5886  Validation loss = 2.0287  \n",
      "\n",
      "Fold: 24  Epoch: 352  Training loss = 3.5884  Validation loss = 2.0284  \n",
      "\n",
      "Fold: 24  Epoch: 353  Training loss = 3.5879  Validation loss = 2.0279  \n",
      "\n",
      "Fold: 24  Epoch: 354  Training loss = 3.5875  Validation loss = 2.0277  \n",
      "\n",
      "Fold: 24  Epoch: 355  Training loss = 3.5871  Validation loss = 2.0275  \n",
      "\n",
      "Fold: 24  Epoch: 356  Training loss = 3.5869  Validation loss = 2.0273  \n",
      "\n",
      "Fold: 24  Epoch: 357  Training loss = 3.5865  Validation loss = 2.0270  \n",
      "\n",
      "Fold: 24  Epoch: 358  Training loss = 3.5860  Validation loss = 2.0267  \n",
      "\n",
      "Fold: 24  Epoch: 359  Training loss = 3.5855  Validation loss = 2.0264  \n",
      "\n",
      "Fold: 24  Epoch: 360  Training loss = 3.5853  Validation loss = 2.0263  \n",
      "\n",
      "Fold: 24  Epoch: 361  Training loss = 3.5851  Validation loss = 2.0260  \n",
      "\n",
      "Fold: 24  Epoch: 362  Training loss = 3.5847  Validation loss = 2.0258  \n",
      "\n",
      "Fold: 24  Epoch: 363  Training loss = 3.5843  Validation loss = 2.0257  \n",
      "\n",
      "Fold: 24  Epoch: 364  Training loss = 3.5838  Validation loss = 2.0253  \n",
      "\n",
      "Fold: 24  Epoch: 365  Training loss = 3.5834  Validation loss = 2.0248  \n",
      "\n",
      "Fold: 24  Epoch: 366  Training loss = 3.5830  Validation loss = 2.0245  \n",
      "\n",
      "Fold: 24  Epoch: 367  Training loss = 3.5828  Validation loss = 2.0244  \n",
      "\n",
      "Fold: 24  Epoch: 368  Training loss = 3.5823  Validation loss = 2.0241  \n",
      "\n",
      "Fold: 24  Epoch: 369  Training loss = 3.5821  Validation loss = 2.0240  \n",
      "\n",
      "Fold: 24  Epoch: 370  Training loss = 3.5817  Validation loss = 2.0237  \n",
      "\n",
      "Fold: 24  Epoch: 371  Training loss = 3.5814  Validation loss = 2.0234  \n",
      "\n",
      "Fold: 24  Epoch: 372  Training loss = 3.5809  Validation loss = 2.0230  \n",
      "\n",
      "Fold: 24  Epoch: 373  Training loss = 3.5806  Validation loss = 2.0227  \n",
      "\n",
      "Fold: 24  Epoch: 374  Training loss = 3.5805  Validation loss = 2.0225  \n",
      "\n",
      "Fold: 24  Epoch: 375  Training loss = 3.5804  Validation loss = 2.0224  \n",
      "\n",
      "Fold: 24  Epoch: 376  Training loss = 3.5800  Validation loss = 2.0221  \n",
      "\n",
      "Fold: 24  Epoch: 377  Training loss = 3.5796  Validation loss = 2.0217  \n",
      "\n",
      "Fold: 24  Epoch: 378  Training loss = 3.5793  Validation loss = 2.0216  \n",
      "\n",
      "Fold: 24  Epoch: 379  Training loss = 3.5790  Validation loss = 2.0216  \n",
      "\n",
      "Fold: 24  Epoch: 380  Training loss = 3.5788  Validation loss = 2.0215  \n",
      "\n",
      "Fold: 24  Epoch: 381  Training loss = 3.5783  Validation loss = 2.0212  \n",
      "\n",
      "Fold: 24  Epoch: 382  Training loss = 3.5781  Validation loss = 2.0211  \n",
      "\n",
      "Fold: 24  Epoch: 383  Training loss = 3.5778  Validation loss = 2.0209  \n",
      "\n",
      "Fold: 24  Epoch: 384  Training loss = 3.5773  Validation loss = 2.0206  \n",
      "\n",
      "Fold: 24  Epoch: 385  Training loss = 3.5768  Validation loss = 2.0203  \n",
      "\n",
      "Fold: 24  Epoch: 386  Training loss = 3.5766  Validation loss = 2.0201  \n",
      "\n",
      "Fold: 24  Epoch: 387  Training loss = 3.5762  Validation loss = 2.0198  \n",
      "\n",
      "Fold: 24  Epoch: 388  Training loss = 3.5757  Validation loss = 2.0196  \n",
      "\n",
      "Fold: 24  Epoch: 389  Training loss = 3.5755  Validation loss = 2.0197  \n",
      "\n",
      "Fold: 24  Epoch: 390  Training loss = 3.5750  Validation loss = 2.0193  \n",
      "\n",
      "Fold: 24  Epoch: 391  Training loss = 3.5746  Validation loss = 2.0191  \n",
      "\n",
      "Fold: 24  Epoch: 392  Training loss = 3.5741  Validation loss = 2.0189  \n",
      "\n",
      "Fold: 24  Epoch: 393  Training loss = 3.5736  Validation loss = 2.0185  \n",
      "\n",
      "Fold: 24  Epoch: 394  Training loss = 3.5734  Validation loss = 2.0182  \n",
      "\n",
      "Fold: 24  Epoch: 395  Training loss = 3.5730  Validation loss = 2.0181  \n",
      "\n",
      "Fold: 24  Epoch: 396  Training loss = 3.5728  Validation loss = 2.0180  \n",
      "\n",
      "Fold: 24  Epoch: 397  Training loss = 3.5723  Validation loss = 2.0177  \n",
      "\n",
      "Fold: 24  Epoch: 398  Training loss = 3.5721  Validation loss = 2.0173  \n",
      "\n",
      "Fold: 24  Epoch: 399  Training loss = 3.5716  Validation loss = 2.0169  \n",
      "\n",
      "Fold: 24  Epoch: 400  Training loss = 3.5714  Validation loss = 2.0167  \n",
      "\n",
      "Fold: 24  Epoch: 401  Training loss = 3.5712  Validation loss = 2.0165  \n",
      "\n",
      "Fold: 24  Epoch: 402  Training loss = 3.5710  Validation loss = 2.0163  \n",
      "\n",
      "Fold: 24  Epoch: 403  Training loss = 3.5706  Validation loss = 2.0161  \n",
      "\n",
      "Fold: 24  Epoch: 404  Training loss = 3.5701  Validation loss = 2.0158  \n",
      "\n",
      "Fold: 24  Epoch: 405  Training loss = 3.5697  Validation loss = 2.0155  \n",
      "\n",
      "Fold: 24  Epoch: 406  Training loss = 3.5694  Validation loss = 2.0152  \n",
      "\n",
      "Fold: 24  Epoch: 407  Training loss = 3.5690  Validation loss = 2.0149  \n",
      "\n",
      "Fold: 24  Epoch: 408  Training loss = 3.5687  Validation loss = 2.0148  \n",
      "\n",
      "Fold: 24  Epoch: 409  Training loss = 3.5684  Validation loss = 2.0146  \n",
      "\n",
      "Fold: 24  Epoch: 410  Training loss = 3.5680  Validation loss = 2.0144  \n",
      "\n",
      "Fold: 24  Epoch: 411  Training loss = 3.5677  Validation loss = 2.0143  \n",
      "\n",
      "Fold: 24  Epoch: 412  Training loss = 3.5673  Validation loss = 2.0140  \n",
      "\n",
      "Fold: 24  Epoch: 413  Training loss = 3.5669  Validation loss = 2.0138  \n",
      "\n",
      "Fold: 24  Epoch: 414  Training loss = 3.5666  Validation loss = 2.0136  \n",
      "\n",
      "Fold: 24  Epoch: 415  Training loss = 3.5662  Validation loss = 2.0132  \n",
      "\n",
      "Fold: 24  Epoch: 416  Training loss = 3.5659  Validation loss = 2.0129  \n",
      "\n",
      "Fold: 24  Epoch: 417  Training loss = 3.5656  Validation loss = 2.0126  \n",
      "\n",
      "Fold: 24  Epoch: 418  Training loss = 3.5653  Validation loss = 2.0125  \n",
      "\n",
      "Fold: 24  Epoch: 419  Training loss = 3.5650  Validation loss = 2.0122  \n",
      "\n",
      "Fold: 24  Epoch: 420  Training loss = 3.5645  Validation loss = 2.0119  \n",
      "\n",
      "Fold: 24  Epoch: 421  Training loss = 3.5641  Validation loss = 2.0117  \n",
      "\n",
      "Fold: 24  Epoch: 422  Training loss = 3.5639  Validation loss = 2.0116  \n",
      "\n",
      "Fold: 24  Epoch: 423  Training loss = 3.5634  Validation loss = 2.0112  \n",
      "\n",
      "Fold: 24  Epoch: 424  Training loss = 3.5631  Validation loss = 2.0111  \n",
      "\n",
      "Fold: 24  Epoch: 425  Training loss = 3.5628  Validation loss = 2.0110  \n",
      "\n",
      "Fold: 24  Epoch: 426  Training loss = 3.5624  Validation loss = 2.0108  \n",
      "\n",
      "Fold: 24  Epoch: 427  Training loss = 3.5620  Validation loss = 2.0105  \n",
      "\n",
      "Fold: 24  Epoch: 428  Training loss = 3.5614  Validation loss = 2.0102  \n",
      "\n",
      "Fold: 24  Epoch: 429  Training loss = 3.5611  Validation loss = 2.0099  \n",
      "\n",
      "Fold: 24  Epoch: 430  Training loss = 3.5607  Validation loss = 2.0097  \n",
      "\n",
      "Fold: 24  Epoch: 431  Training loss = 3.5605  Validation loss = 2.0096  \n",
      "\n",
      "Fold: 24  Epoch: 432  Training loss = 3.5603  Validation loss = 2.0095  \n",
      "\n",
      "Fold: 24  Epoch: 433  Training loss = 3.5598  Validation loss = 2.0092  \n",
      "\n",
      "Fold: 24  Epoch: 434  Training loss = 3.5596  Validation loss = 2.0093  \n",
      "\n",
      "Fold: 24  Epoch: 435  Training loss = 3.5594  Validation loss = 2.0093  \n",
      "\n",
      "Fold: 24  Epoch: 436  Training loss = 3.5589  Validation loss = 2.0091  \n",
      "\n",
      "Fold: 24  Epoch: 437  Training loss = 3.5586  Validation loss = 2.0088  \n",
      "\n",
      "Fold: 24  Epoch: 438  Training loss = 3.5583  Validation loss = 2.0087  \n",
      "\n",
      "Fold: 24  Epoch: 439  Training loss = 3.5580  Validation loss = 2.0087  \n",
      "\n",
      "Fold: 24  Epoch: 440  Training loss = 3.5576  Validation loss = 2.0085  \n",
      "\n",
      "Fold: 24  Epoch: 441  Training loss = 3.5572  Validation loss = 2.0083  \n",
      "\n",
      "Fold: 24  Epoch: 442  Training loss = 3.5569  Validation loss = 2.0081  \n",
      "\n",
      "Fold: 24  Epoch: 443  Training loss = 3.5567  Validation loss = 2.0082  \n",
      "\n",
      "Fold: 24  Epoch: 444  Training loss = 3.5563  Validation loss = 2.0081  \n",
      "\n",
      "Fold: 24  Epoch: 445  Training loss = 3.5561  Validation loss = 2.0077  \n",
      "\n",
      "Fold: 24  Epoch: 446  Training loss = 3.5558  Validation loss = 2.0074  \n",
      "\n",
      "Fold: 24  Epoch: 447  Training loss = 3.5555  Validation loss = 2.0072  \n",
      "\n",
      "Fold: 24  Epoch: 448  Training loss = 3.5552  Validation loss = 2.0071  \n",
      "\n",
      "Fold: 24  Epoch: 449  Training loss = 3.5549  Validation loss = 2.0068  \n",
      "\n",
      "Fold: 24  Epoch: 450  Training loss = 3.5546  Validation loss = 2.0066  \n",
      "\n",
      "Fold: 24  Epoch: 451  Training loss = 3.5543  Validation loss = 2.0063  \n",
      "\n",
      "Fold: 24  Epoch: 452  Training loss = 3.5540  Validation loss = 2.0064  \n",
      "\n",
      "Fold: 24  Epoch: 453  Training loss = 3.5537  Validation loss = 2.0062  \n",
      "\n",
      "Fold: 24  Epoch: 454  Training loss = 3.5534  Validation loss = 2.0059  \n",
      "\n",
      "Fold: 24  Epoch: 455  Training loss = 3.5531  Validation loss = 2.0057  \n",
      "\n",
      "Fold: 24  Epoch: 456  Training loss = 3.5528  Validation loss = 2.0054  \n",
      "\n",
      "Fold: 24  Epoch: 457  Training loss = 3.5525  Validation loss = 2.0052  \n",
      "\n",
      "Fold: 24  Epoch: 458  Training loss = 3.5523  Validation loss = 2.0049  \n",
      "\n",
      "Fold: 24  Epoch: 459  Training loss = 3.5519  Validation loss = 2.0045  \n",
      "\n",
      "Fold: 24  Epoch: 460  Training loss = 3.5515  Validation loss = 2.0042  \n",
      "\n",
      "Fold: 24  Epoch: 461  Training loss = 3.5512  Validation loss = 2.0039  \n",
      "\n",
      "Fold: 24  Epoch: 462  Training loss = 3.5507  Validation loss = 2.0035  \n",
      "\n",
      "Fold: 24  Epoch: 463  Training loss = 3.5505  Validation loss = 2.0033  \n",
      "\n",
      "Fold: 24  Epoch: 464  Training loss = 3.5501  Validation loss = 2.0032  \n",
      "\n",
      "Fold: 24  Epoch: 465  Training loss = 3.5496  Validation loss = 2.0028  \n",
      "\n",
      "Fold: 24  Epoch: 466  Training loss = 3.5493  Validation loss = 2.0024  \n",
      "\n",
      "Fold: 24  Epoch: 467  Training loss = 3.5489  Validation loss = 2.0022  \n",
      "\n",
      "Fold: 24  Epoch: 468  Training loss = 3.5487  Validation loss = 2.0019  \n",
      "\n",
      "Fold: 24  Epoch: 469  Training loss = 3.5483  Validation loss = 2.0019  \n",
      "\n",
      "Fold: 24  Epoch: 470  Training loss = 3.5479  Validation loss = 2.0016  \n",
      "\n",
      "Fold: 24  Epoch: 471  Training loss = 3.5477  Validation loss = 2.0012  \n",
      "\n",
      "Fold: 24  Epoch: 472  Training loss = 3.5472  Validation loss = 2.0010  \n",
      "\n",
      "Fold: 24  Epoch: 473  Training loss = 3.5470  Validation loss = 2.0009  \n",
      "\n",
      "Fold: 24  Epoch: 474  Training loss = 3.5466  Validation loss = 2.0006  \n",
      "\n",
      "Fold: 24  Epoch: 475  Training loss = 3.5462  Validation loss = 2.0002  \n",
      "\n",
      "Fold: 24  Epoch: 476  Training loss = 3.5457  Validation loss = 1.9999  \n",
      "\n",
      "Fold: 24  Epoch: 477  Training loss = 3.5454  Validation loss = 1.9997  \n",
      "\n",
      "Fold: 24  Epoch: 478  Training loss = 3.5451  Validation loss = 1.9996  \n",
      "\n",
      "Fold: 24  Epoch: 479  Training loss = 3.5446  Validation loss = 1.9994  \n",
      "\n",
      "Fold: 24  Epoch: 480  Training loss = 3.5444  Validation loss = 1.9991  \n",
      "\n",
      "Fold: 24  Epoch: 481  Training loss = 3.5441  Validation loss = 1.9991  \n",
      "\n",
      "Fold: 24  Epoch: 482  Training loss = 3.5439  Validation loss = 1.9990  \n",
      "\n",
      "Fold: 24  Epoch: 483  Training loss = 3.5436  Validation loss = 1.9988  \n",
      "\n",
      "Fold: 24  Epoch: 484  Training loss = 3.5433  Validation loss = 1.9986  \n",
      "\n",
      "Fold: 24  Epoch: 485  Training loss = 3.5430  Validation loss = 1.9983  \n",
      "\n",
      "Fold: 24  Epoch: 486  Training loss = 3.5427  Validation loss = 1.9981  \n",
      "\n",
      "Fold: 24  Epoch: 487  Training loss = 3.5422  Validation loss = 1.9977  \n",
      "\n",
      "Fold: 24  Epoch: 488  Training loss = 3.5420  Validation loss = 1.9977  \n",
      "\n",
      "Fold: 24  Epoch: 489  Training loss = 3.5417  Validation loss = 1.9974  \n",
      "\n",
      "Fold: 24  Epoch: 490  Training loss = 3.5411  Validation loss = 1.9971  \n",
      "\n",
      "Fold: 24  Epoch: 491  Training loss = 3.5407  Validation loss = 1.9968  \n",
      "\n",
      "Fold: 24  Epoch: 492  Training loss = 3.5404  Validation loss = 1.9965  \n",
      "\n",
      "Fold: 24  Epoch: 493  Training loss = 3.5401  Validation loss = 1.9964  \n",
      "\n",
      "Fold: 24  Epoch: 494  Training loss = 3.5396  Validation loss = 1.9963  \n",
      "\n",
      "Fold: 24  Epoch: 495  Training loss = 3.5393  Validation loss = 1.9961  \n",
      "\n",
      "Fold: 24  Epoch: 496  Training loss = 3.5391  Validation loss = 1.9961  \n",
      "\n",
      "Fold: 24  Epoch: 497  Training loss = 3.5388  Validation loss = 1.9958  \n",
      "\n",
      "Fold: 24  Epoch: 498  Training loss = 3.5385  Validation loss = 1.9957  \n",
      "\n",
      "Fold: 24  Epoch: 499  Training loss = 3.5382  Validation loss = 1.9956  \n",
      "\n",
      "Fold: 24  Epoch: 500  Training loss = 3.5378  Validation loss = 1.9954  \n",
      "\n",
      "Check model:  Fold: 24  Epoch: 500  Training loss = 3.5378  Validation loss = 1.9954  \n",
      "\n",
      "Fold: 25  Epoch: 1  Training loss = 3.5210  Validation loss = 2.4249  \n",
      "\n",
      "Fold: 25  Epoch: 2  Training loss = 3.5207  Validation loss = 2.4241  \n",
      "\n",
      "Fold: 25  Epoch: 3  Training loss = 3.5202  Validation loss = 2.4232  \n",
      "\n",
      "Fold: 25  Epoch: 4  Training loss = 3.5199  Validation loss = 2.4227  \n",
      "\n",
      "Fold: 25  Epoch: 5  Training loss = 3.5196  Validation loss = 2.4220  \n",
      "\n",
      "Fold: 25  Epoch: 6  Training loss = 3.5193  Validation loss = 2.4214  \n",
      "\n",
      "Fold: 25  Epoch: 7  Training loss = 3.5190  Validation loss = 2.4208  \n",
      "\n",
      "Fold: 25  Epoch: 8  Training loss = 3.5188  Validation loss = 2.4205  \n",
      "\n",
      "Fold: 25  Epoch: 9  Training loss = 3.5183  Validation loss = 2.4194  \n",
      "\n",
      "Fold: 25  Epoch: 10  Training loss = 3.5180  Validation loss = 2.4190  \n",
      "\n",
      "Fold: 25  Epoch: 11  Training loss = 3.5177  Validation loss = 2.4184  \n",
      "\n",
      "Fold: 25  Epoch: 12  Training loss = 3.5174  Validation loss = 2.4176  \n",
      "\n",
      "Fold: 25  Epoch: 13  Training loss = 3.5169  Validation loss = 2.4167  \n",
      "\n",
      "Fold: 25  Epoch: 14  Training loss = 3.5165  Validation loss = 2.4157  \n",
      "\n",
      "Fold: 25  Epoch: 15  Training loss = 3.5161  Validation loss = 2.4149  \n",
      "\n",
      "Fold: 25  Epoch: 16  Training loss = 3.5158  Validation loss = 2.4145  \n",
      "\n",
      "Fold: 25  Epoch: 17  Training loss = 3.5154  Validation loss = 2.4135  \n",
      "\n",
      "Fold: 25  Epoch: 18  Training loss = 3.5151  Validation loss = 2.4130  \n",
      "\n",
      "Fold: 25  Epoch: 19  Training loss = 3.5149  Validation loss = 2.4128  \n",
      "\n",
      "Fold: 25  Epoch: 20  Training loss = 3.5147  Validation loss = 2.4123  \n",
      "\n",
      "Fold: 25  Epoch: 21  Training loss = 3.5144  Validation loss = 2.4117  \n",
      "\n",
      "Fold: 25  Epoch: 22  Training loss = 3.5141  Validation loss = 2.4112  \n",
      "\n",
      "Fold: 25  Epoch: 23  Training loss = 3.5139  Validation loss = 2.4109  \n",
      "\n",
      "Fold: 25  Epoch: 24  Training loss = 3.5136  Validation loss = 2.4102  \n",
      "\n",
      "Fold: 25  Epoch: 25  Training loss = 3.5132  Validation loss = 2.4096  \n",
      "\n",
      "Fold: 25  Epoch: 26  Training loss = 3.5129  Validation loss = 2.4088  \n",
      "\n",
      "Fold: 25  Epoch: 27  Training loss = 3.5125  Validation loss = 2.4078  \n",
      "\n",
      "Fold: 25  Epoch: 28  Training loss = 3.5120  Validation loss = 2.4069  \n",
      "\n",
      "Fold: 25  Epoch: 29  Training loss = 3.5116  Validation loss = 2.4059  \n",
      "\n",
      "Fold: 25  Epoch: 30  Training loss = 3.5113  Validation loss = 2.4054  \n",
      "\n",
      "Fold: 25  Epoch: 31  Training loss = 3.5110  Validation loss = 2.4050  \n",
      "\n",
      "Fold: 25  Epoch: 32  Training loss = 3.5108  Validation loss = 2.4045  \n",
      "\n",
      "Fold: 25  Epoch: 33  Training loss = 3.5105  Validation loss = 2.4039  \n",
      "\n",
      "Fold: 25  Epoch: 34  Training loss = 3.5101  Validation loss = 2.4032  \n",
      "\n",
      "Fold: 25  Epoch: 35  Training loss = 3.5098  Validation loss = 2.4026  \n",
      "\n",
      "Fold: 25  Epoch: 36  Training loss = 3.5095  Validation loss = 2.4019  \n",
      "\n",
      "Fold: 25  Epoch: 37  Training loss = 3.5093  Validation loss = 2.4014  \n",
      "\n",
      "Fold: 25  Epoch: 38  Training loss = 3.5090  Validation loss = 2.4009  \n",
      "\n",
      "Fold: 25  Epoch: 39  Training loss = 3.5088  Validation loss = 2.4005  \n",
      "\n",
      "Fold: 25  Epoch: 40  Training loss = 3.5082  Validation loss = 2.3994  \n",
      "\n",
      "Fold: 25  Epoch: 41  Training loss = 3.5080  Validation loss = 2.3990  \n",
      "\n",
      "Fold: 25  Epoch: 42  Training loss = 3.5078  Validation loss = 2.3988  \n",
      "\n",
      "Fold: 25  Epoch: 43  Training loss = 3.5076  Validation loss = 2.3984  \n",
      "\n",
      "Fold: 25  Epoch: 44  Training loss = 3.5074  Validation loss = 2.3978  \n",
      "\n",
      "Fold: 25  Epoch: 45  Training loss = 3.5070  Validation loss = 2.3971  \n",
      "\n",
      "Fold: 25  Epoch: 46  Training loss = 3.5068  Validation loss = 2.3965  \n",
      "\n",
      "Fold: 25  Epoch: 47  Training loss = 3.5065  Validation loss = 2.3958  \n",
      "\n",
      "Fold: 25  Epoch: 48  Training loss = 3.5063  Validation loss = 2.3954  \n",
      "\n",
      "Fold: 25  Epoch: 49  Training loss = 3.5060  Validation loss = 2.3949  \n",
      "\n",
      "Fold: 25  Epoch: 50  Training loss = 3.5056  Validation loss = 2.3941  \n",
      "\n",
      "Fold: 25  Epoch: 51  Training loss = 3.5053  Validation loss = 2.3935  \n",
      "\n",
      "Fold: 25  Epoch: 52  Training loss = 3.5049  Validation loss = 2.3927  \n",
      "\n",
      "Fold: 25  Epoch: 53  Training loss = 3.5046  Validation loss = 2.3920  \n",
      "\n",
      "Fold: 25  Epoch: 54  Training loss = 3.5042  Validation loss = 2.3913  \n",
      "\n",
      "Fold: 25  Epoch: 55  Training loss = 3.5039  Validation loss = 2.3907  \n",
      "\n",
      "Fold: 25  Epoch: 56  Training loss = 3.5036  Validation loss = 2.3899  \n",
      "\n",
      "Fold: 25  Epoch: 57  Training loss = 3.5030  Validation loss = 2.3887  \n",
      "\n",
      "Fold: 25  Epoch: 58  Training loss = 3.5029  Validation loss = 2.3884  \n",
      "\n",
      "Fold: 25  Epoch: 59  Training loss = 3.5027  Validation loss = 2.3880  \n",
      "\n",
      "Fold: 25  Epoch: 60  Training loss = 3.5025  Validation loss = 2.3878  \n",
      "\n",
      "Fold: 25  Epoch: 61  Training loss = 3.5023  Validation loss = 2.3874  \n",
      "\n",
      "Fold: 25  Epoch: 62  Training loss = 3.5020  Validation loss = 2.3870  \n",
      "\n",
      "Fold: 25  Epoch: 63  Training loss = 3.5016  Validation loss = 2.3862  \n",
      "\n",
      "Fold: 25  Epoch: 64  Training loss = 3.5014  Validation loss = 2.3859  \n",
      "\n",
      "Fold: 25  Epoch: 65  Training loss = 3.5010  Validation loss = 2.3849  \n",
      "\n",
      "Fold: 25  Epoch: 66  Training loss = 3.5008  Validation loss = 2.3844  \n",
      "\n",
      "Fold: 25  Epoch: 67  Training loss = 3.5004  Validation loss = 2.3835  \n",
      "\n",
      "Fold: 25  Epoch: 68  Training loss = 3.4999  Validation loss = 2.3825  \n",
      "\n",
      "Fold: 25  Epoch: 69  Training loss = 3.4995  Validation loss = 2.3816  \n",
      "\n",
      "Fold: 25  Epoch: 70  Training loss = 3.4991  Validation loss = 2.3808  \n",
      "\n",
      "Fold: 25  Epoch: 71  Training loss = 3.4986  Validation loss = 2.3799  \n",
      "\n",
      "Fold: 25  Epoch: 72  Training loss = 3.4982  Validation loss = 2.3791  \n",
      "\n",
      "Fold: 25  Epoch: 73  Training loss = 3.4979  Validation loss = 2.3786  \n",
      "\n",
      "Fold: 25  Epoch: 74  Training loss = 3.4975  Validation loss = 2.3777  \n",
      "\n",
      "Fold: 25  Epoch: 75  Training loss = 3.4973  Validation loss = 2.3774  \n",
      "\n",
      "Fold: 25  Epoch: 76  Training loss = 3.4970  Validation loss = 2.3768  \n",
      "\n",
      "Fold: 25  Epoch: 77  Training loss = 3.4967  Validation loss = 2.3762  \n",
      "\n",
      "Fold: 25  Epoch: 78  Training loss = 3.4964  Validation loss = 2.3756  \n",
      "\n",
      "Fold: 25  Epoch: 79  Training loss = 3.4960  Validation loss = 2.3748  \n",
      "\n",
      "Fold: 25  Epoch: 80  Training loss = 3.4958  Validation loss = 2.3743  \n",
      "\n",
      "Fold: 25  Epoch: 81  Training loss = 3.4955  Validation loss = 2.3736  \n",
      "\n",
      "Fold: 25  Epoch: 82  Training loss = 3.4952  Validation loss = 2.3731  \n",
      "\n",
      "Fold: 25  Epoch: 83  Training loss = 3.4949  Validation loss = 2.3726  \n",
      "\n",
      "Fold: 25  Epoch: 84  Training loss = 3.4945  Validation loss = 2.3718  \n",
      "\n",
      "Fold: 25  Epoch: 85  Training loss = 3.4943  Validation loss = 2.3714  \n",
      "\n",
      "Fold: 25  Epoch: 86  Training loss = 3.4940  Validation loss = 2.3707  \n",
      "\n",
      "Fold: 25  Epoch: 87  Training loss = 3.4938  Validation loss = 2.3703  \n",
      "\n",
      "Fold: 25  Epoch: 88  Training loss = 3.4936  Validation loss = 2.3697  \n",
      "\n",
      "Fold: 25  Epoch: 89  Training loss = 3.4932  Validation loss = 2.3690  \n",
      "\n",
      "Fold: 25  Epoch: 90  Training loss = 3.4929  Validation loss = 2.3683  \n",
      "\n",
      "Fold: 25  Epoch: 91  Training loss = 3.4927  Validation loss = 2.3677  \n",
      "\n",
      "Fold: 25  Epoch: 92  Training loss = 3.4922  Validation loss = 2.3669  \n",
      "\n",
      "Fold: 25  Epoch: 93  Training loss = 3.4919  Validation loss = 2.3659  \n",
      "\n",
      "Fold: 25  Epoch: 94  Training loss = 3.4917  Validation loss = 2.3656  \n",
      "\n",
      "Fold: 25  Epoch: 95  Training loss = 3.4912  Validation loss = 2.3647  \n",
      "\n",
      "Fold: 25  Epoch: 96  Training loss = 3.4911  Validation loss = 2.3644  \n",
      "\n",
      "Fold: 25  Epoch: 97  Training loss = 3.4907  Validation loss = 2.3638  \n",
      "\n",
      "Fold: 25  Epoch: 98  Training loss = 3.4904  Validation loss = 2.3634  \n",
      "\n",
      "Fold: 25  Epoch: 99  Training loss = 3.4901  Validation loss = 2.3626  \n",
      "\n",
      "Fold: 25  Epoch: 100  Training loss = 3.4898  Validation loss = 2.3621  \n",
      "\n",
      "Fold: 25  Epoch: 101  Training loss = 3.4894  Validation loss = 2.3611  \n",
      "\n",
      "Fold: 25  Epoch: 102  Training loss = 3.4891  Validation loss = 2.3603  \n",
      "\n",
      "Fold: 25  Epoch: 103  Training loss = 3.4889  Validation loss = 2.3597  \n",
      "\n",
      "Fold: 25  Epoch: 104  Training loss = 3.4885  Validation loss = 2.3588  \n",
      "\n",
      "Fold: 25  Epoch: 105  Training loss = 3.4882  Validation loss = 2.3582  \n",
      "\n",
      "Fold: 25  Epoch: 106  Training loss = 3.4879  Validation loss = 2.3577  \n",
      "\n",
      "Fold: 25  Epoch: 107  Training loss = 3.4875  Validation loss = 2.3570  \n",
      "\n",
      "Fold: 25  Epoch: 108  Training loss = 3.4870  Validation loss = 2.3558  \n",
      "\n",
      "Fold: 25  Epoch: 109  Training loss = 3.4867  Validation loss = 2.3551  \n",
      "\n",
      "Fold: 25  Epoch: 110  Training loss = 3.4863  Validation loss = 2.3544  \n",
      "\n",
      "Fold: 25  Epoch: 111  Training loss = 3.4860  Validation loss = 2.3539  \n",
      "\n",
      "Fold: 25  Epoch: 112  Training loss = 3.4855  Validation loss = 2.3528  \n",
      "\n",
      "Fold: 25  Epoch: 113  Training loss = 3.4852  Validation loss = 2.3521  \n",
      "\n",
      "Fold: 25  Epoch: 114  Training loss = 3.4848  Validation loss = 2.3512  \n",
      "\n",
      "Fold: 25  Epoch: 115  Training loss = 3.4846  Validation loss = 2.3506  \n",
      "\n",
      "Fold: 25  Epoch: 116  Training loss = 3.4842  Validation loss = 2.3496  \n",
      "\n",
      "Fold: 25  Epoch: 117  Training loss = 3.4838  Validation loss = 2.3487  \n",
      "\n",
      "Fold: 25  Epoch: 118  Training loss = 3.4835  Validation loss = 2.3482  \n",
      "\n",
      "Fold: 25  Epoch: 119  Training loss = 3.4833  Validation loss = 2.3475  \n",
      "\n",
      "Fold: 25  Epoch: 120  Training loss = 3.4829  Validation loss = 2.3466  \n",
      "\n",
      "Fold: 25  Epoch: 121  Training loss = 3.4826  Validation loss = 2.3459  \n",
      "\n",
      "Fold: 25  Epoch: 122  Training loss = 3.4823  Validation loss = 2.3454  \n",
      "\n",
      "Fold: 25  Epoch: 123  Training loss = 3.4819  Validation loss = 2.3445  \n",
      "\n",
      "Fold: 25  Epoch: 124  Training loss = 3.4816  Validation loss = 2.3441  \n",
      "\n",
      "Fold: 25  Epoch: 125  Training loss = 3.4813  Validation loss = 2.3435  \n",
      "\n",
      "Fold: 25  Epoch: 126  Training loss = 3.4810  Validation loss = 2.3428  \n",
      "\n",
      "Fold: 25  Epoch: 127  Training loss = 3.4806  Validation loss = 2.3419  \n",
      "\n",
      "Fold: 25  Epoch: 128  Training loss = 3.4804  Validation loss = 2.3415  \n",
      "\n",
      "Fold: 25  Epoch: 129  Training loss = 3.4802  Validation loss = 2.3407  \n",
      "\n",
      "Fold: 25  Epoch: 130  Training loss = 3.4797  Validation loss = 2.3398  \n",
      "\n",
      "Fold: 25  Epoch: 131  Training loss = 3.4794  Validation loss = 2.3393  \n",
      "\n",
      "Fold: 25  Epoch: 132  Training loss = 3.4792  Validation loss = 2.3387  \n",
      "\n",
      "Fold: 25  Epoch: 133  Training loss = 3.4788  Validation loss = 2.3377  \n",
      "\n",
      "Fold: 25  Epoch: 134  Training loss = 3.4787  Validation loss = 2.3373  \n",
      "\n",
      "Fold: 25  Epoch: 135  Training loss = 3.4784  Validation loss = 2.3369  \n",
      "\n",
      "Fold: 25  Epoch: 136  Training loss = 3.4779  Validation loss = 2.3358  \n",
      "\n",
      "Fold: 25  Epoch: 137  Training loss = 3.4776  Validation loss = 2.3353  \n",
      "\n",
      "Fold: 25  Epoch: 138  Training loss = 3.4774  Validation loss = 2.3349  \n",
      "\n",
      "Fold: 25  Epoch: 139  Training loss = 3.4771  Validation loss = 2.3342  \n",
      "\n",
      "Fold: 25  Epoch: 140  Training loss = 3.4769  Validation loss = 2.3337  \n",
      "\n",
      "Fold: 25  Epoch: 141  Training loss = 3.4764  Validation loss = 2.3328  \n",
      "\n",
      "Fold: 25  Epoch: 142  Training loss = 3.4763  Validation loss = 2.3326  \n",
      "\n",
      "Fold: 25  Epoch: 143  Training loss = 3.4759  Validation loss = 2.3317  \n",
      "\n",
      "Fold: 25  Epoch: 144  Training loss = 3.4755  Validation loss = 2.3310  \n",
      "\n",
      "Fold: 25  Epoch: 145  Training loss = 3.4753  Validation loss = 2.3304  \n",
      "\n",
      "Fold: 25  Epoch: 146  Training loss = 3.4751  Validation loss = 2.3298  \n",
      "\n",
      "Fold: 25  Epoch: 147  Training loss = 3.4748  Validation loss = 2.3292  \n",
      "\n",
      "Fold: 25  Epoch: 148  Training loss = 3.4745  Validation loss = 2.3286  \n",
      "\n",
      "Fold: 25  Epoch: 149  Training loss = 3.4741  Validation loss = 2.3278  \n",
      "\n",
      "Fold: 25  Epoch: 150  Training loss = 3.4737  Validation loss = 2.3267  \n",
      "\n",
      "Fold: 25  Epoch: 151  Training loss = 3.4735  Validation loss = 2.3263  \n",
      "\n",
      "Fold: 25  Epoch: 152  Training loss = 3.4733  Validation loss = 2.3260  \n",
      "\n",
      "Fold: 25  Epoch: 153  Training loss = 3.4730  Validation loss = 2.3254  \n",
      "\n",
      "Fold: 25  Epoch: 154  Training loss = 3.4728  Validation loss = 2.3249  \n",
      "\n",
      "Fold: 25  Epoch: 155  Training loss = 3.4725  Validation loss = 2.3244  \n",
      "\n",
      "Fold: 25  Epoch: 156  Training loss = 3.4721  Validation loss = 2.3238  \n",
      "\n",
      "Fold: 25  Epoch: 157  Training loss = 3.4718  Validation loss = 2.3232  \n",
      "\n",
      "Fold: 25  Epoch: 158  Training loss = 3.4715  Validation loss = 2.3225  \n",
      "\n",
      "Fold: 25  Epoch: 159  Training loss = 3.4714  Validation loss = 2.3221  \n",
      "\n",
      "Fold: 25  Epoch: 160  Training loss = 3.4710  Validation loss = 2.3214  \n",
      "\n",
      "Fold: 25  Epoch: 161  Training loss = 3.4706  Validation loss = 2.3203  \n",
      "\n",
      "Fold: 25  Epoch: 162  Training loss = 3.4702  Validation loss = 2.3193  \n",
      "\n",
      "Fold: 25  Epoch: 163  Training loss = 3.4699  Validation loss = 2.3184  \n",
      "\n",
      "Fold: 25  Epoch: 164  Training loss = 3.4696  Validation loss = 2.3178  \n",
      "\n",
      "Fold: 25  Epoch: 165  Training loss = 3.4693  Validation loss = 2.3173  \n",
      "\n",
      "Fold: 25  Epoch: 166  Training loss = 3.4688  Validation loss = 2.3162  \n",
      "\n",
      "Fold: 25  Epoch: 167  Training loss = 3.4686  Validation loss = 2.3158  \n",
      "\n",
      "Fold: 25  Epoch: 168  Training loss = 3.4684  Validation loss = 2.3154  \n",
      "\n",
      "Fold: 25  Epoch: 169  Training loss = 3.4681  Validation loss = 2.3149  \n",
      "\n",
      "Fold: 25  Epoch: 170  Training loss = 3.4678  Validation loss = 2.3142  \n",
      "\n",
      "Fold: 25  Epoch: 171  Training loss = 3.4677  Validation loss = 2.3140  \n",
      "\n",
      "Fold: 25  Epoch: 172  Training loss = 3.4675  Validation loss = 2.3133  \n",
      "\n",
      "Fold: 25  Epoch: 173  Training loss = 3.4672  Validation loss = 2.3128  \n",
      "\n",
      "Fold: 25  Epoch: 174  Training loss = 3.4669  Validation loss = 2.3121  \n",
      "\n",
      "Fold: 25  Epoch: 175  Training loss = 3.4665  Validation loss = 2.3113  \n",
      "\n",
      "Fold: 25  Epoch: 176  Training loss = 3.4662  Validation loss = 2.3106  \n",
      "\n",
      "Fold: 25  Epoch: 177  Training loss = 3.4659  Validation loss = 2.3098  \n",
      "\n",
      "Fold: 25  Epoch: 178  Training loss = 3.4656  Validation loss = 2.3088  \n",
      "\n",
      "Fold: 25  Epoch: 179  Training loss = 3.4652  Validation loss = 2.3080  \n",
      "\n",
      "Fold: 25  Epoch: 180  Training loss = 3.4649  Validation loss = 2.3073  \n",
      "\n",
      "Fold: 25  Epoch: 181  Training loss = 3.4647  Validation loss = 2.3070  \n",
      "\n",
      "Fold: 25  Epoch: 182  Training loss = 3.4645  Validation loss = 2.3064  \n",
      "\n",
      "Fold: 25  Epoch: 183  Training loss = 3.4641  Validation loss = 2.3055  \n",
      "\n",
      "Fold: 25  Epoch: 184  Training loss = 3.4639  Validation loss = 2.3051  \n",
      "\n",
      "Fold: 25  Epoch: 185  Training loss = 3.4636  Validation loss = 2.3045  \n",
      "\n",
      "Fold: 25  Epoch: 186  Training loss = 3.4633  Validation loss = 2.3039  \n",
      "\n",
      "Fold: 25  Epoch: 187  Training loss = 3.4630  Validation loss = 2.3033  \n",
      "\n",
      "Fold: 25  Epoch: 188  Training loss = 3.4627  Validation loss = 2.3026  \n",
      "\n",
      "Fold: 25  Epoch: 189  Training loss = 3.4625  Validation loss = 2.3021  \n",
      "\n",
      "Fold: 25  Epoch: 190  Training loss = 3.4621  Validation loss = 2.3007  \n",
      "\n",
      "Fold: 25  Epoch: 191  Training loss = 3.4618  Validation loss = 2.3001  \n",
      "\n",
      "Fold: 25  Epoch: 192  Training loss = 3.4615  Validation loss = 2.2994  \n",
      "\n",
      "Fold: 25  Epoch: 193  Training loss = 3.4612  Validation loss = 2.2986  \n",
      "\n",
      "Fold: 25  Epoch: 194  Training loss = 3.4609  Validation loss = 2.2980  \n",
      "\n",
      "Fold: 25  Epoch: 195  Training loss = 3.4605  Validation loss = 2.2973  \n",
      "\n",
      "Fold: 25  Epoch: 196  Training loss = 3.4601  Validation loss = 2.2963  \n",
      "\n",
      "Fold: 25  Epoch: 197  Training loss = 3.4598  Validation loss = 2.2957  \n",
      "\n",
      "Fold: 25  Epoch: 198  Training loss = 3.4595  Validation loss = 2.2951  \n",
      "\n",
      "Fold: 25  Epoch: 199  Training loss = 3.4593  Validation loss = 2.2946  \n",
      "\n",
      "Fold: 25  Epoch: 200  Training loss = 3.4589  Validation loss = 2.2939  \n",
      "\n",
      "Fold: 25  Epoch: 201  Training loss = 3.4584  Validation loss = 2.2927  \n",
      "\n",
      "Fold: 25  Epoch: 202  Training loss = 3.4583  Validation loss = 2.2925  \n",
      "\n",
      "Fold: 25  Epoch: 203  Training loss = 3.4580  Validation loss = 2.2919  \n",
      "\n",
      "Fold: 25  Epoch: 204  Training loss = 3.4576  Validation loss = 2.2910  \n",
      "\n",
      "Fold: 25  Epoch: 205  Training loss = 3.4574  Validation loss = 2.2905  \n",
      "\n",
      "Fold: 25  Epoch: 206  Training loss = 3.4572  Validation loss = 2.2903  \n",
      "\n",
      "Fold: 25  Epoch: 207  Training loss = 3.4569  Validation loss = 2.2896  \n",
      "\n",
      "Fold: 25  Epoch: 208  Training loss = 3.4567  Validation loss = 2.2893  \n",
      "\n",
      "Fold: 25  Epoch: 209  Training loss = 3.4563  Validation loss = 2.2884  \n",
      "\n",
      "Fold: 25  Epoch: 210  Training loss = 3.4560  Validation loss = 2.2879  \n",
      "\n",
      "Fold: 25  Epoch: 211  Training loss = 3.4559  Validation loss = 2.2878  \n",
      "\n",
      "Fold: 25  Epoch: 212  Training loss = 3.4557  Validation loss = 2.2875  \n",
      "\n",
      "Fold: 25  Epoch: 213  Training loss = 3.4553  Validation loss = 2.2867  \n",
      "\n",
      "Fold: 25  Epoch: 214  Training loss = 3.4550  Validation loss = 2.2862  \n",
      "\n",
      "Fold: 25  Epoch: 215  Training loss = 3.4548  Validation loss = 2.2857  \n",
      "\n",
      "Fold: 25  Epoch: 216  Training loss = 3.4546  Validation loss = 2.2853  \n",
      "\n",
      "Fold: 25  Epoch: 217  Training loss = 3.4541  Validation loss = 2.2844  \n",
      "\n",
      "Fold: 25  Epoch: 218  Training loss = 3.4538  Validation loss = 2.2837  \n",
      "\n",
      "Fold: 25  Epoch: 219  Training loss = 3.4536  Validation loss = 2.2832  \n",
      "\n",
      "Fold: 25  Epoch: 220  Training loss = 3.4533  Validation loss = 2.2824  \n",
      "\n",
      "Fold: 25  Epoch: 221  Training loss = 3.4530  Validation loss = 2.2819  \n",
      "\n",
      "Fold: 25  Epoch: 222  Training loss = 3.4526  Validation loss = 2.2809  \n",
      "\n",
      "Fold: 25  Epoch: 223  Training loss = 3.4524  Validation loss = 2.2805  \n",
      "\n",
      "Fold: 25  Epoch: 224  Training loss = 3.4521  Validation loss = 2.2800  \n",
      "\n",
      "Fold: 25  Epoch: 225  Training loss = 3.4519  Validation loss = 2.2794  \n",
      "\n",
      "Fold: 25  Epoch: 226  Training loss = 3.4517  Validation loss = 2.2791  \n",
      "\n",
      "Fold: 25  Epoch: 227  Training loss = 3.4513  Validation loss = 2.2783  \n",
      "\n",
      "Fold: 25  Epoch: 228  Training loss = 3.4511  Validation loss = 2.2778  \n",
      "\n",
      "Fold: 25  Epoch: 229  Training loss = 3.4508  Validation loss = 2.2772  \n",
      "\n",
      "Fold: 25  Epoch: 230  Training loss = 3.4506  Validation loss = 2.2764  \n",
      "\n",
      "Fold: 25  Epoch: 231  Training loss = 3.4501  Validation loss = 2.2757  \n",
      "\n",
      "Fold: 25  Epoch: 232  Training loss = 3.4497  Validation loss = 2.2748  \n",
      "\n",
      "Fold: 25  Epoch: 233  Training loss = 3.4496  Validation loss = 2.2746  \n",
      "\n",
      "Fold: 25  Epoch: 234  Training loss = 3.4493  Validation loss = 2.2741  \n",
      "\n",
      "Fold: 25  Epoch: 235  Training loss = 3.4491  Validation loss = 2.2739  \n",
      "\n",
      "Fold: 25  Epoch: 236  Training loss = 3.4490  Validation loss = 2.2737  \n",
      "\n",
      "Fold: 25  Epoch: 237  Training loss = 3.4487  Validation loss = 2.2732  \n",
      "\n",
      "Fold: 25  Epoch: 238  Training loss = 3.4483  Validation loss = 2.2725  \n",
      "\n",
      "Fold: 25  Epoch: 239  Training loss = 3.4481  Validation loss = 2.2720  \n",
      "\n",
      "Fold: 25  Epoch: 240  Training loss = 3.4479  Validation loss = 2.2715  \n",
      "\n",
      "Fold: 25  Epoch: 241  Training loss = 3.4477  Validation loss = 2.2714  \n",
      "\n",
      "Fold: 25  Epoch: 242  Training loss = 3.4474  Validation loss = 2.2708  \n",
      "\n",
      "Fold: 25  Epoch: 243  Training loss = 3.4471  Validation loss = 2.2702  \n",
      "\n",
      "Fold: 25  Epoch: 244  Training loss = 3.4469  Validation loss = 2.2699  \n",
      "\n",
      "Fold: 25  Epoch: 245  Training loss = 3.4467  Validation loss = 2.2693  \n",
      "\n",
      "Fold: 25  Epoch: 246  Training loss = 3.4466  Validation loss = 2.2690  \n",
      "\n",
      "Fold: 25  Epoch: 247  Training loss = 3.4463  Validation loss = 2.2684  \n",
      "\n",
      "Fold: 25  Epoch: 248  Training loss = 3.4460  Validation loss = 2.2680  \n",
      "\n",
      "Fold: 25  Epoch: 249  Training loss = 3.4459  Validation loss = 2.2677  \n",
      "\n",
      "Fold: 25  Epoch: 250  Training loss = 3.4457  Validation loss = 2.2672  \n",
      "\n",
      "Fold: 25  Epoch: 251  Training loss = 3.4453  Validation loss = 2.2664  \n",
      "\n",
      "Fold: 25  Epoch: 252  Training loss = 3.4451  Validation loss = 2.2660  \n",
      "\n",
      "Fold: 25  Epoch: 253  Training loss = 3.4447  Validation loss = 2.2653  \n",
      "\n",
      "Fold: 25  Epoch: 254  Training loss = 3.4444  Validation loss = 2.2646  \n",
      "\n",
      "Fold: 25  Epoch: 255  Training loss = 3.4441  Validation loss = 2.2639  \n",
      "\n",
      "Fold: 25  Epoch: 256  Training loss = 3.4438  Validation loss = 2.2634  \n",
      "\n",
      "Fold: 25  Epoch: 257  Training loss = 3.4437  Validation loss = 2.2631  \n",
      "\n",
      "Fold: 25  Epoch: 258  Training loss = 3.4434  Validation loss = 2.2624  \n",
      "\n",
      "Fold: 25  Epoch: 259  Training loss = 3.4431  Validation loss = 2.2618  \n",
      "\n",
      "Fold: 25  Epoch: 260  Training loss = 3.4427  Validation loss = 2.2609  \n",
      "\n",
      "Fold: 25  Epoch: 261  Training loss = 3.4423  Validation loss = 2.2601  \n",
      "\n",
      "Fold: 25  Epoch: 262  Training loss = 3.4419  Validation loss = 2.2593  \n",
      "\n",
      "Fold: 25  Epoch: 263  Training loss = 3.4416  Validation loss = 2.2587  \n",
      "\n",
      "Fold: 25  Epoch: 264  Training loss = 3.4414  Validation loss = 2.2583  \n",
      "\n",
      "Fold: 25  Epoch: 265  Training loss = 3.4410  Validation loss = 2.2574  \n",
      "\n",
      "Fold: 25  Epoch: 266  Training loss = 3.4407  Validation loss = 2.2568  \n",
      "\n",
      "Fold: 25  Epoch: 267  Training loss = 3.4405  Validation loss = 2.2565  \n",
      "\n",
      "Fold: 25  Epoch: 268  Training loss = 3.4403  Validation loss = 2.2559  \n",
      "\n",
      "Fold: 25  Epoch: 269  Training loss = 3.4400  Validation loss = 2.2553  \n",
      "\n",
      "Fold: 25  Epoch: 270  Training loss = 3.4397  Validation loss = 2.2549  \n",
      "\n",
      "Fold: 25  Epoch: 271  Training loss = 3.4395  Validation loss = 2.2544  \n",
      "\n",
      "Fold: 25  Epoch: 272  Training loss = 3.4392  Validation loss = 2.2536  \n",
      "\n",
      "Fold: 25  Epoch: 273  Training loss = 3.4389  Validation loss = 2.2531  \n",
      "\n",
      "Fold: 25  Epoch: 274  Training loss = 3.4387  Validation loss = 2.2526  \n",
      "\n",
      "Fold: 25  Epoch: 275  Training loss = 3.4385  Validation loss = 2.2523  \n",
      "\n",
      "Fold: 25  Epoch: 276  Training loss = 3.4383  Validation loss = 2.2517  \n",
      "\n",
      "Fold: 25  Epoch: 277  Training loss = 3.4381  Validation loss = 2.2516  \n",
      "\n",
      "Fold: 25  Epoch: 278  Training loss = 3.4379  Validation loss = 2.2511  \n",
      "\n",
      "Fold: 25  Epoch: 279  Training loss = 3.4377  Validation loss = 2.2507  \n",
      "\n",
      "Fold: 25  Epoch: 280  Training loss = 3.4373  Validation loss = 2.2501  \n",
      "\n",
      "Fold: 25  Epoch: 281  Training loss = 3.4370  Validation loss = 2.2497  \n",
      "\n",
      "Fold: 25  Epoch: 282  Training loss = 3.4368  Validation loss = 2.2493  \n",
      "\n",
      "Fold: 25  Epoch: 283  Training loss = 3.4367  Validation loss = 2.2491  \n",
      "\n",
      "Fold: 25  Epoch: 284  Training loss = 3.4366  Validation loss = 2.2488  \n",
      "\n",
      "Fold: 25  Epoch: 285  Training loss = 3.4362  Validation loss = 2.2482  \n",
      "\n",
      "Fold: 25  Epoch: 286  Training loss = 3.4359  Validation loss = 2.2476  \n",
      "\n",
      "Fold: 25  Epoch: 287  Training loss = 3.4356  Validation loss = 2.2470  \n",
      "\n",
      "Fold: 25  Epoch: 288  Training loss = 3.4353  Validation loss = 2.2463  \n",
      "\n",
      "Fold: 25  Epoch: 289  Training loss = 3.4351  Validation loss = 2.2458  \n",
      "\n",
      "Fold: 25  Epoch: 290  Training loss = 3.4347  Validation loss = 2.2451  \n",
      "\n",
      "Fold: 25  Epoch: 291  Training loss = 3.4344  Validation loss = 2.2446  \n",
      "\n",
      "Fold: 25  Epoch: 292  Training loss = 3.4342  Validation loss = 2.2442  \n",
      "\n",
      "Fold: 25  Epoch: 293  Training loss = 3.4339  Validation loss = 2.2437  \n",
      "\n",
      "Fold: 25  Epoch: 294  Training loss = 3.4336  Validation loss = 2.2431  \n",
      "\n",
      "Fold: 25  Epoch: 295  Training loss = 3.4329  Validation loss = 2.2420  \n",
      "\n",
      "Fold: 25  Epoch: 296  Training loss = 3.4324  Validation loss = 2.2412  \n",
      "\n",
      "Fold: 25  Epoch: 297  Training loss = 3.4315  Validation loss = 2.2398  \n",
      "\n",
      "Fold: 25  Epoch: 298  Training loss = 3.4309  Validation loss = 2.2392  \n",
      "\n",
      "Fold: 25  Epoch: 299  Training loss = 3.4304  Validation loss = 2.2382  \n",
      "\n",
      "Fold: 25  Epoch: 300  Training loss = 3.4302  Validation loss = 2.2379  \n",
      "\n",
      "Fold: 25  Epoch: 301  Training loss = 3.4299  Validation loss = 2.2375  \n",
      "\n",
      "Fold: 25  Epoch: 302  Training loss = 3.4296  Validation loss = 2.2369  \n",
      "\n",
      "Fold: 25  Epoch: 303  Training loss = 3.4294  Validation loss = 2.2363  \n",
      "\n",
      "Fold: 25  Epoch: 304  Training loss = 3.4292  Validation loss = 2.2359  \n",
      "\n",
      "Fold: 25  Epoch: 305  Training loss = 3.4290  Validation loss = 2.2356  \n",
      "\n",
      "Fold: 25  Epoch: 306  Training loss = 3.4287  Validation loss = 2.2350  \n",
      "\n",
      "Fold: 25  Epoch: 307  Training loss = 3.4285  Validation loss = 2.2346  \n",
      "\n",
      "Fold: 25  Epoch: 308  Training loss = 3.4282  Validation loss = 2.2341  \n",
      "\n",
      "Fold: 25  Epoch: 309  Training loss = 3.4279  Validation loss = 2.2335  \n",
      "\n",
      "Fold: 25  Epoch: 310  Training loss = 3.4277  Validation loss = 2.2331  \n",
      "\n",
      "Fold: 25  Epoch: 311  Training loss = 3.4272  Validation loss = 2.2322  \n",
      "\n",
      "Fold: 25  Epoch: 312  Training loss = 3.4270  Validation loss = 2.2317  \n",
      "\n",
      "Fold: 25  Epoch: 313  Training loss = 3.4267  Validation loss = 2.2311  \n",
      "\n",
      "Fold: 25  Epoch: 314  Training loss = 3.4264  Validation loss = 2.2306  \n",
      "\n",
      "Fold: 25  Epoch: 315  Training loss = 3.4262  Validation loss = 2.2303  \n",
      "\n",
      "Fold: 25  Epoch: 316  Training loss = 3.4259  Validation loss = 2.2298  \n",
      "\n",
      "Fold: 25  Epoch: 317  Training loss = 3.4258  Validation loss = 2.2296  \n",
      "\n",
      "Fold: 25  Epoch: 318  Training loss = 3.4256  Validation loss = 2.2290  \n",
      "\n",
      "Fold: 25  Epoch: 319  Training loss = 3.4253  Validation loss = 2.2286  \n",
      "\n",
      "Fold: 25  Epoch: 320  Training loss = 3.4251  Validation loss = 2.2281  \n",
      "\n",
      "Fold: 25  Epoch: 321  Training loss = 3.4248  Validation loss = 2.2277  \n",
      "\n",
      "Fold: 25  Epoch: 322  Training loss = 3.4245  Validation loss = 2.2271  \n",
      "\n",
      "Fold: 25  Epoch: 323  Training loss = 3.4242  Validation loss = 2.2264  \n",
      "\n",
      "Fold: 25  Epoch: 324  Training loss = 3.4239  Validation loss = 2.2259  \n",
      "\n",
      "Fold: 25  Epoch: 325  Training loss = 3.4238  Validation loss = 2.2258  \n",
      "\n",
      "Fold: 25  Epoch: 326  Training loss = 3.4236  Validation loss = 2.2253  \n",
      "\n",
      "Fold: 25  Epoch: 327  Training loss = 3.4234  Validation loss = 2.2251  \n",
      "\n",
      "Fold: 25  Epoch: 328  Training loss = 3.4232  Validation loss = 2.2247  \n",
      "\n",
      "Fold: 25  Epoch: 329  Training loss = 3.4230  Validation loss = 2.2245  \n",
      "\n",
      "Fold: 25  Epoch: 330  Training loss = 3.4227  Validation loss = 2.2240  \n",
      "\n",
      "Fold: 25  Epoch: 331  Training loss = 3.4225  Validation loss = 2.2236  \n",
      "\n",
      "Fold: 25  Epoch: 332  Training loss = 3.4224  Validation loss = 2.2234  \n",
      "\n",
      "Fold: 25  Epoch: 333  Training loss = 3.4220  Validation loss = 2.2227  \n",
      "\n",
      "Fold: 25  Epoch: 334  Training loss = 3.4218  Validation loss = 2.2222  \n",
      "\n",
      "Fold: 25  Epoch: 335  Training loss = 3.4216  Validation loss = 2.2216  \n",
      "\n",
      "Fold: 25  Epoch: 336  Training loss = 3.4212  Validation loss = 2.2208  \n",
      "\n",
      "Fold: 25  Epoch: 337  Training loss = 3.4210  Validation loss = 2.2206  \n",
      "\n",
      "Fold: 25  Epoch: 338  Training loss = 3.4209  Validation loss = 2.2203  \n",
      "\n",
      "Fold: 25  Epoch: 339  Training loss = 3.4206  Validation loss = 2.2198  \n",
      "\n",
      "Fold: 25  Epoch: 340  Training loss = 3.4203  Validation loss = 2.2193  \n",
      "\n",
      "Fold: 25  Epoch: 341  Training loss = 3.4201  Validation loss = 2.2190  \n",
      "\n",
      "Fold: 25  Epoch: 342  Training loss = 3.4200  Validation loss = 2.2187  \n",
      "\n",
      "Fold: 25  Epoch: 343  Training loss = 3.4195  Validation loss = 2.2179  \n",
      "\n",
      "Fold: 25  Epoch: 344  Training loss = 3.4193  Validation loss = 2.2175  \n",
      "\n",
      "Fold: 25  Epoch: 345  Training loss = 3.4191  Validation loss = 2.2172  \n",
      "\n",
      "Fold: 25  Epoch: 346  Training loss = 3.4188  Validation loss = 2.2167  \n",
      "\n",
      "Fold: 25  Epoch: 347  Training loss = 3.4186  Validation loss = 2.2162  \n",
      "\n",
      "Fold: 25  Epoch: 348  Training loss = 3.4183  Validation loss = 2.2157  \n",
      "\n",
      "Fold: 25  Epoch: 349  Training loss = 3.4181  Validation loss = 2.2153  \n",
      "\n",
      "Fold: 25  Epoch: 350  Training loss = 3.4178  Validation loss = 2.2147  \n",
      "\n",
      "Fold: 25  Epoch: 351  Training loss = 3.4176  Validation loss = 2.2144  \n",
      "\n",
      "Fold: 25  Epoch: 352  Training loss = 3.4175  Validation loss = 2.2143  \n",
      "\n",
      "Fold: 25  Epoch: 353  Training loss = 3.4173  Validation loss = 2.2138  \n",
      "\n",
      "Fold: 25  Epoch: 354  Training loss = 3.4169  Validation loss = 2.2132  \n",
      "\n",
      "Fold: 25  Epoch: 355  Training loss = 3.4166  Validation loss = 2.2125  \n",
      "\n",
      "Fold: 25  Epoch: 356  Training loss = 3.4163  Validation loss = 2.2119  \n",
      "\n",
      "Fold: 25  Epoch: 357  Training loss = 3.4160  Validation loss = 2.2116  \n",
      "\n",
      "Fold: 25  Epoch: 358  Training loss = 3.4158  Validation loss = 2.2111  \n",
      "\n",
      "Fold: 25  Epoch: 359  Training loss = 3.4155  Validation loss = 2.2107  \n",
      "\n",
      "Fold: 25  Epoch: 360  Training loss = 3.4154  Validation loss = 2.2105  \n",
      "\n",
      "Fold: 25  Epoch: 361  Training loss = 3.4151  Validation loss = 2.2101  \n",
      "\n",
      "Fold: 25  Epoch: 362  Training loss = 3.4148  Validation loss = 2.2095  \n",
      "\n",
      "Fold: 25  Epoch: 363  Training loss = 3.4146  Validation loss = 2.2092  \n",
      "\n",
      "Fold: 25  Epoch: 364  Training loss = 3.4145  Validation loss = 2.2092  \n",
      "\n",
      "Fold: 25  Epoch: 365  Training loss = 3.4143  Validation loss = 2.2090  \n",
      "\n",
      "Fold: 25  Epoch: 366  Training loss = 3.4140  Validation loss = 2.2085  \n",
      "\n",
      "Fold: 25  Epoch: 367  Training loss = 3.4139  Validation loss = 2.2084  \n",
      "\n",
      "Fold: 25  Epoch: 368  Training loss = 3.4135  Validation loss = 2.2075  \n",
      "\n",
      "Fold: 25  Epoch: 369  Training loss = 3.4134  Validation loss = 2.2072  \n",
      "\n",
      "Fold: 25  Epoch: 370  Training loss = 3.4132  Validation loss = 2.2068  \n",
      "\n",
      "Fold: 25  Epoch: 371  Training loss = 3.4131  Validation loss = 2.2066  \n",
      "\n",
      "Fold: 25  Epoch: 372  Training loss = 3.4128  Validation loss = 2.2062  \n",
      "\n",
      "Fold: 25  Epoch: 373  Training loss = 3.4127  Validation loss = 2.2059  \n",
      "\n",
      "Fold: 25  Epoch: 374  Training loss = 3.4124  Validation loss = 2.2055  \n",
      "\n",
      "Fold: 25  Epoch: 375  Training loss = 3.4122  Validation loss = 2.2051  \n",
      "\n",
      "Fold: 25  Epoch: 376  Training loss = 3.4118  Validation loss = 2.2046  \n",
      "\n",
      "Fold: 25  Epoch: 377  Training loss = 3.4116  Validation loss = 2.2043  \n",
      "\n",
      "Fold: 25  Epoch: 378  Training loss = 3.4114  Validation loss = 2.2040  \n",
      "\n",
      "Fold: 25  Epoch: 379  Training loss = 3.4113  Validation loss = 2.2036  \n",
      "\n",
      "Fold: 25  Epoch: 380  Training loss = 3.4110  Validation loss = 2.2031  \n",
      "\n",
      "Fold: 25  Epoch: 381  Training loss = 3.4109  Validation loss = 2.2028  \n",
      "\n",
      "Fold: 25  Epoch: 382  Training loss = 3.4106  Validation loss = 2.2024  \n",
      "\n",
      "Fold: 25  Epoch: 383  Training loss = 3.4103  Validation loss = 2.2015  \n",
      "\n",
      "Fold: 25  Epoch: 384  Training loss = 3.4098  Validation loss = 2.2008  \n",
      "\n",
      "Fold: 25  Epoch: 385  Training loss = 3.4096  Validation loss = 2.2003  \n",
      "\n",
      "Fold: 25  Epoch: 386  Training loss = 3.4094  Validation loss = 2.2001  \n",
      "\n",
      "Fold: 25  Epoch: 387  Training loss = 3.4092  Validation loss = 2.1997  \n",
      "\n",
      "Fold: 25  Epoch: 388  Training loss = 3.4089  Validation loss = 2.1991  \n",
      "\n",
      "Fold: 25  Epoch: 389  Training loss = 3.4087  Validation loss = 2.1988  \n",
      "\n",
      "Fold: 25  Epoch: 390  Training loss = 3.4085  Validation loss = 2.1984  \n",
      "\n",
      "Fold: 25  Epoch: 391  Training loss = 3.4081  Validation loss = 2.1977  \n",
      "\n",
      "Fold: 25  Epoch: 392  Training loss = 3.4079  Validation loss = 2.1973  \n",
      "\n",
      "Fold: 25  Epoch: 393  Training loss = 3.4077  Validation loss = 2.1968  \n",
      "\n",
      "Fold: 25  Epoch: 394  Training loss = 3.4075  Validation loss = 2.1965  \n",
      "\n",
      "Fold: 25  Epoch: 395  Training loss = 3.4073  Validation loss = 2.1960  \n",
      "\n",
      "Fold: 25  Epoch: 396  Training loss = 3.4071  Validation loss = 2.1958  \n",
      "\n",
      "Fold: 25  Epoch: 397  Training loss = 3.4068  Validation loss = 2.1953  \n",
      "\n",
      "Fold: 25  Epoch: 398  Training loss = 3.4066  Validation loss = 2.1948  \n",
      "\n",
      "Fold: 25  Epoch: 399  Training loss = 3.4065  Validation loss = 2.1946  \n",
      "\n",
      "Fold: 25  Epoch: 400  Training loss = 3.4063  Validation loss = 2.1943  \n",
      "\n",
      "Fold: 25  Epoch: 401  Training loss = 3.4060  Validation loss = 2.1939  \n",
      "\n",
      "Fold: 25  Epoch: 402  Training loss = 3.4058  Validation loss = 2.1934  \n",
      "\n",
      "Fold: 25  Epoch: 403  Training loss = 3.4054  Validation loss = 2.1928  \n",
      "\n",
      "Fold: 25  Epoch: 404  Training loss = 3.4053  Validation loss = 2.1927  \n",
      "\n",
      "Fold: 25  Epoch: 405  Training loss = 3.4051  Validation loss = 2.1921  \n",
      "\n",
      "Fold: 25  Epoch: 406  Training loss = 3.4048  Validation loss = 2.1917  \n",
      "\n",
      "Fold: 25  Epoch: 407  Training loss = 3.4046  Validation loss = 2.1913  \n",
      "\n",
      "Fold: 25  Epoch: 408  Training loss = 3.4044  Validation loss = 2.1909  \n",
      "\n",
      "Fold: 25  Epoch: 409  Training loss = 3.4041  Validation loss = 2.1905  \n",
      "\n",
      "Fold: 25  Epoch: 410  Training loss = 3.4040  Validation loss = 2.1904  \n",
      "\n",
      "Fold: 25  Epoch: 411  Training loss = 3.4037  Validation loss = 2.1898  \n",
      "\n",
      "Fold: 25  Epoch: 412  Training loss = 3.4036  Validation loss = 2.1897  \n",
      "\n",
      "Fold: 25  Epoch: 413  Training loss = 3.4034  Validation loss = 2.1892  \n",
      "\n",
      "Fold: 25  Epoch: 414  Training loss = 3.4030  Validation loss = 2.1887  \n",
      "\n",
      "Fold: 25  Epoch: 415  Training loss = 3.4028  Validation loss = 2.1883  \n",
      "\n",
      "Fold: 25  Epoch: 416  Training loss = 3.4025  Validation loss = 2.1876  \n",
      "\n",
      "Fold: 25  Epoch: 417  Training loss = 3.4022  Validation loss = 2.1872  \n",
      "\n",
      "Fold: 25  Epoch: 418  Training loss = 3.4020  Validation loss = 2.1868  \n",
      "\n",
      "Fold: 25  Epoch: 419  Training loss = 3.4018  Validation loss = 2.1865  \n",
      "\n",
      "Fold: 25  Epoch: 420  Training loss = 3.4016  Validation loss = 2.1861  \n",
      "\n",
      "Fold: 25  Epoch: 421  Training loss = 3.4014  Validation loss = 2.1860  \n",
      "\n",
      "Fold: 25  Epoch: 422  Training loss = 3.4012  Validation loss = 2.1856  \n",
      "\n",
      "Fold: 25  Epoch: 423  Training loss = 3.4010  Validation loss = 2.1852  \n",
      "\n",
      "Fold: 25  Epoch: 424  Training loss = 3.4007  Validation loss = 2.1847  \n",
      "\n",
      "Fold: 25  Epoch: 425  Training loss = 3.4004  Validation loss = 2.1842  \n",
      "\n",
      "Fold: 25  Epoch: 426  Training loss = 3.4002  Validation loss = 2.1837  \n",
      "\n",
      "Fold: 25  Epoch: 427  Training loss = 3.3999  Validation loss = 2.1832  \n",
      "\n",
      "Fold: 25  Epoch: 428  Training loss = 3.3997  Validation loss = 2.1827  \n",
      "\n",
      "Fold: 25  Epoch: 429  Training loss = 3.3995  Validation loss = 2.1824  \n",
      "\n",
      "Fold: 25  Epoch: 430  Training loss = 3.3992  Validation loss = 2.1819  \n",
      "\n",
      "Fold: 25  Epoch: 431  Training loss = 3.3990  Validation loss = 2.1816  \n",
      "\n",
      "Fold: 25  Epoch: 432  Training loss = 3.3987  Validation loss = 2.1811  \n",
      "\n",
      "Fold: 25  Epoch: 433  Training loss = 3.3985  Validation loss = 2.1808  \n",
      "\n",
      "Fold: 25  Epoch: 434  Training loss = 3.3981  Validation loss = 2.1800  \n",
      "\n",
      "Fold: 25  Epoch: 435  Training loss = 3.3978  Validation loss = 2.1793  \n",
      "\n",
      "Fold: 25  Epoch: 436  Training loss = 3.3975  Validation loss = 2.1788  \n",
      "\n",
      "Fold: 25  Epoch: 437  Training loss = 3.3972  Validation loss = 2.1784  \n",
      "\n",
      "Fold: 25  Epoch: 438  Training loss = 3.3969  Validation loss = 2.1779  \n",
      "\n",
      "Fold: 25  Epoch: 439  Training loss = 3.3967  Validation loss = 2.1775  \n",
      "\n",
      "Fold: 25  Epoch: 440  Training loss = 3.3964  Validation loss = 2.1771  \n",
      "\n",
      "Fold: 25  Epoch: 441  Training loss = 3.3962  Validation loss = 2.1767  \n",
      "\n",
      "Fold: 25  Epoch: 442  Training loss = 3.3959  Validation loss = 2.1762  \n",
      "\n",
      "Fold: 25  Epoch: 443  Training loss = 3.3957  Validation loss = 2.1759  \n",
      "\n",
      "Fold: 25  Epoch: 444  Training loss = 3.3954  Validation loss = 2.1754  \n",
      "\n",
      "Fold: 25  Epoch: 445  Training loss = 3.3951  Validation loss = 2.1748  \n",
      "\n",
      "Fold: 25  Epoch: 446  Training loss = 3.3949  Validation loss = 2.1746  \n",
      "\n",
      "Fold: 25  Epoch: 447  Training loss = 3.3947  Validation loss = 2.1741  \n",
      "\n",
      "Fold: 25  Epoch: 448  Training loss = 3.3944  Validation loss = 2.1736  \n",
      "\n",
      "Fold: 25  Epoch: 449  Training loss = 3.3942  Validation loss = 2.1735  \n",
      "\n",
      "Fold: 25  Epoch: 450  Training loss = 3.3939  Validation loss = 2.1731  \n",
      "\n",
      "Fold: 25  Epoch: 451  Training loss = 3.3937  Validation loss = 2.1727  \n",
      "\n",
      "Fold: 25  Epoch: 452  Training loss = 3.3935  Validation loss = 2.1723  \n",
      "\n",
      "Fold: 25  Epoch: 453  Training loss = 3.3932  Validation loss = 2.1720  \n",
      "\n",
      "Fold: 25  Epoch: 454  Training loss = 3.3930  Validation loss = 2.1716  \n",
      "\n",
      "Fold: 25  Epoch: 455  Training loss = 3.3929  Validation loss = 2.1715  \n",
      "\n",
      "Fold: 25  Epoch: 456  Training loss = 3.3926  Validation loss = 2.1708  \n",
      "\n",
      "Fold: 25  Epoch: 457  Training loss = 3.3923  Validation loss = 2.1703  \n",
      "\n",
      "Fold: 25  Epoch: 458  Training loss = 3.3921  Validation loss = 2.1700  \n",
      "\n",
      "Fold: 25  Epoch: 459  Training loss = 3.3919  Validation loss = 2.1694  \n",
      "\n",
      "Fold: 25  Epoch: 460  Training loss = 3.3916  Validation loss = 2.1688  \n",
      "\n",
      "Fold: 25  Epoch: 461  Training loss = 3.3913  Validation loss = 2.1683  \n",
      "\n",
      "Fold: 25  Epoch: 462  Training loss = 3.3911  Validation loss = 2.1678  \n",
      "\n",
      "Fold: 25  Epoch: 463  Training loss = 3.3908  Validation loss = 2.1673  \n",
      "\n",
      "Fold: 25  Epoch: 464  Training loss = 3.3904  Validation loss = 2.1666  \n",
      "\n",
      "Fold: 25  Epoch: 465  Training loss = 3.3901  Validation loss = 2.1661  \n",
      "\n",
      "Fold: 25  Epoch: 466  Training loss = 3.3899  Validation loss = 2.1659  \n",
      "\n",
      "Fold: 25  Epoch: 467  Training loss = 3.3898  Validation loss = 2.1659  \n",
      "\n",
      "Fold: 25  Epoch: 468  Training loss = 3.3896  Validation loss = 2.1655  \n",
      "\n",
      "Fold: 25  Epoch: 469  Training loss = 3.3894  Validation loss = 2.1650  \n",
      "\n",
      "Fold: 25  Epoch: 470  Training loss = 3.3892  Validation loss = 2.1648  \n",
      "\n",
      "Fold: 25  Epoch: 471  Training loss = 3.3891  Validation loss = 2.1646  \n",
      "\n",
      "Fold: 25  Epoch: 472  Training loss = 3.3890  Validation loss = 2.1645  \n",
      "\n",
      "Fold: 25  Epoch: 473  Training loss = 3.3888  Validation loss = 2.1643  \n",
      "\n",
      "Fold: 25  Epoch: 474  Training loss = 3.3887  Validation loss = 2.1642  \n",
      "\n",
      "Fold: 25  Epoch: 475  Training loss = 3.3884  Validation loss = 2.1636  \n",
      "\n",
      "Fold: 25  Epoch: 476  Training loss = 3.3882  Validation loss = 2.1635  \n",
      "\n",
      "Fold: 25  Epoch: 477  Training loss = 3.3880  Validation loss = 2.1633  \n",
      "\n",
      "Fold: 25  Epoch: 478  Training loss = 3.3878  Validation loss = 2.1627  \n",
      "\n",
      "Fold: 25  Epoch: 479  Training loss = 3.3875  Validation loss = 2.1625  \n",
      "\n",
      "Fold: 25  Epoch: 480  Training loss = 3.3874  Validation loss = 2.1623  \n",
      "\n",
      "Fold: 25  Epoch: 481  Training loss = 3.3874  Validation loss = 2.1622  \n",
      "\n",
      "Fold: 25  Epoch: 482  Training loss = 3.3872  Validation loss = 2.1620  \n",
      "\n",
      "Fold: 25  Epoch: 483  Training loss = 3.3871  Validation loss = 2.1618  \n",
      "\n",
      "Fold: 25  Epoch: 484  Training loss = 3.3870  Validation loss = 2.1617  \n",
      "\n",
      "Fold: 25  Epoch: 485  Training loss = 3.3868  Validation loss = 2.1614  \n",
      "\n",
      "Fold: 25  Epoch: 486  Training loss = 3.3867  Validation loss = 2.1612  \n",
      "\n",
      "Fold: 25  Epoch: 487  Training loss = 3.3865  Validation loss = 2.1609  \n",
      "\n",
      "Fold: 25  Epoch: 488  Training loss = 3.3864  Validation loss = 2.1607  \n",
      "\n",
      "Fold: 25  Epoch: 489  Training loss = 3.3861  Validation loss = 2.1604  \n",
      "\n",
      "Fold: 25  Epoch: 490  Training loss = 3.3858  Validation loss = 2.1598  \n",
      "\n",
      "Fold: 25  Epoch: 491  Training loss = 3.3856  Validation loss = 2.1595  \n",
      "\n",
      "Fold: 25  Epoch: 492  Training loss = 3.3855  Validation loss = 2.1594  \n",
      "\n",
      "Fold: 25  Epoch: 493  Training loss = 3.3853  Validation loss = 2.1589  \n",
      "\n",
      "Fold: 25  Epoch: 494  Training loss = 3.3850  Validation loss = 2.1583  \n",
      "\n",
      "Fold: 25  Epoch: 495  Training loss = 3.3848  Validation loss = 2.1579  \n",
      "\n",
      "Fold: 25  Epoch: 496  Training loss = 3.3846  Validation loss = 2.1575  \n",
      "\n",
      "Fold: 25  Epoch: 497  Training loss = 3.3844  Validation loss = 2.1571  \n",
      "\n",
      "Fold: 25  Epoch: 498  Training loss = 3.3842  Validation loss = 2.1566  \n",
      "\n",
      "Fold: 25  Epoch: 499  Training loss = 3.3838  Validation loss = 2.1560  \n",
      "\n",
      "Fold: 25  Epoch: 500  Training loss = 3.3836  Validation loss = 2.1555  \n",
      "\n",
      "Check model:  Fold: 25  Epoch: 500  Training loss = 3.3836  Validation loss = 2.1555  \n",
      "\n",
      "Fold: 26  Epoch: 1  Training loss = 3.1227  Validation loss = 2.6640  \n",
      "\n",
      "Fold: 26  Epoch: 2  Training loss = 3.1224  Validation loss = 2.6651  \n",
      "\n",
      "Fold: 26  Epoch: 3  Training loss = 3.1222  Validation loss = 2.6661  \n",
      "\n",
      "Fold: 26  Epoch: 4  Training loss = 3.1220  Validation loss = 2.6667  \n",
      "\n",
      "Fold: 26  Epoch: 5  Training loss = 3.1219  Validation loss = 2.6670  \n",
      "\n",
      "Fold: 26  Epoch: 6  Training loss = 3.1218  Validation loss = 2.6674  \n",
      "\n",
      "Fold: 26  Epoch: 7  Training loss = 3.1217  Validation loss = 2.6678  \n",
      "\n",
      "Fold: 26  Epoch: 8  Training loss = 3.1215  Validation loss = 2.6685  \n",
      "\n",
      "Fold: 26  Epoch: 9  Training loss = 3.1213  Validation loss = 2.6692  \n",
      "\n",
      "Fold: 26  Epoch: 10  Training loss = 3.1212  Validation loss = 2.6697  \n",
      "\n",
      "Fold: 26  Epoch: 11  Training loss = 3.1211  Validation loss = 2.6693  \n",
      "\n",
      "Fold: 26  Epoch: 12  Training loss = 3.1210  Validation loss = 2.6697  \n",
      "\n",
      "Fold: 26  Epoch: 13  Training loss = 3.1208  Validation loss = 2.6699  \n",
      "\n",
      "Check model:  Fold: 26  Epoch: 1  Training loss = 3.1208  Validation loss = 2.6699  \n",
      "\n",
      "Fold: 27  Epoch: 1  Training loss = 3.0631  Validation loss = 2.1459  \n",
      "\n",
      "Fold: 27  Epoch: 2  Training loss = 3.0630  Validation loss = 2.1461  \n",
      "\n",
      "Fold: 27  Epoch: 3  Training loss = 3.0630  Validation loss = 2.1459  \n",
      "\n",
      "Fold: 27  Epoch: 4  Training loss = 3.0628  Validation loss = 2.1460  \n",
      "\n",
      "Fold: 27  Epoch: 5  Training loss = 3.0627  Validation loss = 2.1459  \n",
      "\n",
      "Fold: 27  Epoch: 6  Training loss = 3.0626  Validation loss = 2.1459  \n",
      "\n",
      "Fold: 27  Epoch: 7  Training loss = 3.0625  Validation loss = 2.1460  \n",
      "\n",
      "Fold: 27  Epoch: 8  Training loss = 3.0624  Validation loss = 2.1461  \n",
      "\n",
      "Fold: 27  Epoch: 9  Training loss = 3.0623  Validation loss = 2.1461  \n",
      "\n",
      "Fold: 27  Epoch: 10  Training loss = 3.0622  Validation loss = 2.1461  \n",
      "\n",
      "Fold: 27  Epoch: 11  Training loss = 3.0621  Validation loss = 2.1461  \n",
      "\n",
      "Check model:  Fold: 27  Epoch: 5  Training loss = 3.0621  Validation loss = 2.1461  \n",
      "\n",
      "Fold: 28  Epoch: 1  Training loss = 3.0617  Validation loss = 2.3579  \n",
      "\n",
      "Fold: 28  Epoch: 2  Training loss = 3.0616  Validation loss = 2.3579  \n",
      "\n",
      "Fold: 28  Epoch: 3  Training loss = 3.0615  Validation loss = 2.3579  \n",
      "\n",
      "Fold: 28  Epoch: 4  Training loss = 3.0615  Validation loss = 2.3579  \n",
      "\n",
      "Fold: 28  Epoch: 5  Training loss = 3.0613  Validation loss = 2.3582  \n",
      "\n",
      "Fold: 28  Epoch: 6  Training loss = 3.0612  Validation loss = 2.3582  \n",
      "\n",
      "Fold: 28  Epoch: 7  Training loss = 3.0609  Validation loss = 2.3586  \n",
      "\n",
      "Fold: 28  Epoch: 8  Training loss = 3.0608  Validation loss = 2.3584  \n",
      "\n",
      "Fold: 28  Epoch: 9  Training loss = 3.0607  Validation loss = 2.3586  \n",
      "\n",
      "Fold: 28  Epoch: 10  Training loss = 3.0605  Validation loss = 2.3588  \n",
      "\n",
      "Fold: 28  Epoch: 11  Training loss = 3.0604  Validation loss = 2.3586  \n",
      "\n",
      "Fold: 28  Epoch: 12  Training loss = 3.0603  Validation loss = 2.3585  \n",
      "\n",
      "Fold: 28  Epoch: 13  Training loss = 3.0601  Validation loss = 2.3587  \n",
      "\n",
      "Fold: 28  Epoch: 14  Training loss = 3.0600  Validation loss = 2.3585  \n",
      "\n",
      "Fold: 28  Epoch: 15  Training loss = 3.0598  Validation loss = 2.3586  \n",
      "\n",
      "Fold: 28  Epoch: 16  Training loss = 3.0597  Validation loss = 2.3589  \n",
      "\n",
      "Check model:  Fold: 28  Epoch: 2  Training loss = 3.0597  Validation loss = 2.3589  \n",
      "\n",
      "Fold: 29  Epoch: 1  Training loss = 3.1071  Validation loss = 2.7534  \n",
      "\n",
      "Fold: 29  Epoch: 2  Training loss = 3.1070  Validation loss = 2.7532  \n",
      "\n",
      "Fold: 29  Epoch: 3  Training loss = 3.1068  Validation loss = 2.7534  \n",
      "\n",
      "Fold: 29  Epoch: 4  Training loss = 3.1067  Validation loss = 2.7536  \n",
      "\n",
      "Fold: 29  Epoch: 5  Training loss = 3.1066  Validation loss = 2.7534  \n",
      "\n",
      "Fold: 29  Epoch: 6  Training loss = 3.1065  Validation loss = 2.7534  \n",
      "\n",
      "Fold: 29  Epoch: 7  Training loss = 3.1064  Validation loss = 2.7532  \n",
      "\n",
      "Fold: 29  Epoch: 8  Training loss = 3.1063  Validation loss = 2.7531  \n",
      "\n",
      "Fold: 29  Epoch: 9  Training loss = 3.1061  Validation loss = 2.7531  \n",
      "\n",
      "Fold: 29  Epoch: 10  Training loss = 3.1060  Validation loss = 2.7531  \n",
      "\n",
      "Fold: 29  Epoch: 11  Training loss = 3.1059  Validation loss = 2.7531  \n",
      "\n",
      "Fold: 29  Epoch: 12  Training loss = 3.1058  Validation loss = 2.7528  \n",
      "\n",
      "Fold: 29  Epoch: 13  Training loss = 3.1057  Validation loss = 2.7530  \n",
      "\n",
      "Fold: 29  Epoch: 14  Training loss = 3.1055  Validation loss = 2.7529  \n",
      "\n",
      "Fold: 29  Epoch: 15  Training loss = 3.1053  Validation loss = 2.7532  \n",
      "\n",
      "Fold: 29  Epoch: 16  Training loss = 3.1052  Validation loss = 2.7531  \n",
      "\n",
      "Fold: 29  Epoch: 17  Training loss = 3.1051  Validation loss = 2.7533  \n",
      "\n",
      "Check model:  Fold: 29  Epoch: 12  Training loss = 3.1051  Validation loss = 2.7533  \n",
      "\n",
      "Fold: 30  Epoch: 1  Training loss = 3.1519  Validation loss = 1.2012  \n",
      "\n",
      "Fold: 30  Epoch: 2  Training loss = 3.1518  Validation loss = 1.2012  \n",
      "\n",
      "Fold: 30  Epoch: 3  Training loss = 3.1517  Validation loss = 1.2009  \n",
      "\n",
      "Fold: 30  Epoch: 4  Training loss = 3.1515  Validation loss = 1.2005  \n",
      "\n",
      "Fold: 30  Epoch: 5  Training loss = 3.1513  Validation loss = 1.2007  \n",
      "\n",
      "Fold: 30  Epoch: 6  Training loss = 3.1512  Validation loss = 1.2004  \n",
      "\n",
      "Fold: 30  Epoch: 7  Training loss = 3.1510  Validation loss = 1.2007  \n",
      "\n",
      "Fold: 30  Epoch: 8  Training loss = 3.1509  Validation loss = 1.2006  \n",
      "\n",
      "Fold: 30  Epoch: 9  Training loss = 3.1508  Validation loss = 1.2006  \n",
      "\n",
      "Fold: 30  Epoch: 10  Training loss = 3.1506  Validation loss = 1.2006  \n",
      "\n",
      "Fold: 30  Epoch: 11  Training loss = 3.1505  Validation loss = 1.2008  \n",
      "\n",
      "Fold: 30  Epoch: 12  Training loss = 3.1504  Validation loss = 1.2008  \n",
      "\n",
      "Fold: 30  Epoch: 13  Training loss = 3.1502  Validation loss = 1.2008  \n",
      "\n",
      "Check model:  Fold: 30  Epoch: 6  Training loss = 3.1502  Validation loss = 1.2008  \n",
      "\n",
      "Fold: 31  Epoch: 1  Training loss = 2.9290  Validation loss = 2.3049  \n",
      "\n",
      "Fold: 31  Epoch: 2  Training loss = 2.9289  Validation loss = 2.3049  \n",
      "\n",
      "Fold: 31  Epoch: 3  Training loss = 2.9288  Validation loss = 2.3048  \n",
      "\n",
      "Fold: 31  Epoch: 4  Training loss = 2.9286  Validation loss = 2.3041  \n",
      "\n",
      "Fold: 31  Epoch: 5  Training loss = 2.9285  Validation loss = 2.3041  \n",
      "\n",
      "Fold: 31  Epoch: 6  Training loss = 2.9283  Validation loss = 2.3033  \n",
      "\n",
      "Fold: 31  Epoch: 7  Training loss = 2.9282  Validation loss = 2.3031  \n",
      "\n",
      "Fold: 31  Epoch: 8  Training loss = 2.9280  Validation loss = 2.3024  \n",
      "\n",
      "Fold: 31  Epoch: 9  Training loss = 2.9279  Validation loss = 2.3024  \n",
      "\n",
      "Fold: 31  Epoch: 10  Training loss = 2.9276  Validation loss = 2.3015  \n",
      "\n",
      "Fold: 31  Epoch: 11  Training loss = 2.9275  Validation loss = 2.3011  \n",
      "\n",
      "Fold: 31  Epoch: 12  Training loss = 2.9273  Validation loss = 2.3001  \n",
      "\n",
      "Fold: 31  Epoch: 13  Training loss = 2.9271  Validation loss = 2.2998  \n",
      "\n",
      "Fold: 31  Epoch: 14  Training loss = 2.9270  Validation loss = 2.2995  \n",
      "\n",
      "Fold: 31  Epoch: 15  Training loss = 2.9269  Validation loss = 2.2995  \n",
      "\n",
      "Fold: 31  Epoch: 16  Training loss = 2.9267  Validation loss = 2.2992  \n",
      "\n",
      "Fold: 31  Epoch: 17  Training loss = 2.9265  Validation loss = 2.2990  \n",
      "\n",
      "Fold: 31  Epoch: 18  Training loss = 2.9264  Validation loss = 2.2982  \n",
      "\n",
      "Fold: 31  Epoch: 19  Training loss = 2.9263  Validation loss = 2.2981  \n",
      "\n",
      "Fold: 31  Epoch: 20  Training loss = 2.9261  Validation loss = 2.2976  \n",
      "\n",
      "Fold: 31  Epoch: 21  Training loss = 2.9259  Validation loss = 2.2973  \n",
      "\n",
      "Fold: 31  Epoch: 22  Training loss = 2.9257  Validation loss = 2.2967  \n",
      "\n",
      "Fold: 31  Epoch: 23  Training loss = 2.9256  Validation loss = 2.2959  \n",
      "\n",
      "Fold: 31  Epoch: 24  Training loss = 2.9253  Validation loss = 2.2949  \n",
      "\n",
      "Fold: 31  Epoch: 25  Training loss = 2.9252  Validation loss = 2.2944  \n",
      "\n",
      "Fold: 31  Epoch: 26  Training loss = 2.9251  Validation loss = 2.2945  \n",
      "\n",
      "Fold: 31  Epoch: 27  Training loss = 2.9250  Validation loss = 2.2945  \n",
      "\n",
      "Fold: 31  Epoch: 28  Training loss = 2.9249  Validation loss = 2.2946  \n",
      "\n",
      "Fold: 31  Epoch: 29  Training loss = 2.9248  Validation loss = 2.2945  \n",
      "\n",
      "Fold: 31  Epoch: 30  Training loss = 2.9246  Validation loss = 2.2946  \n",
      "\n",
      "Fold: 31  Epoch: 31  Training loss = 2.9245  Validation loss = 2.2946  \n",
      "\n",
      "Fold: 31  Epoch: 32  Training loss = 2.9244  Validation loss = 2.2940  \n",
      "\n",
      "Fold: 31  Epoch: 33  Training loss = 2.9242  Validation loss = 2.2938  \n",
      "\n",
      "Fold: 31  Epoch: 34  Training loss = 2.9241  Validation loss = 2.2937  \n",
      "\n",
      "Fold: 31  Epoch: 35  Training loss = 2.9239  Validation loss = 2.2932  \n",
      "\n",
      "Fold: 31  Epoch: 36  Training loss = 2.9238  Validation loss = 2.2930  \n",
      "\n",
      "Fold: 31  Epoch: 37  Training loss = 2.9237  Validation loss = 2.2931  \n",
      "\n",
      "Fold: 31  Epoch: 38  Training loss = 2.9235  Validation loss = 2.2925  \n",
      "\n",
      "Fold: 31  Epoch: 39  Training loss = 2.9234  Validation loss = 2.2923  \n",
      "\n",
      "Fold: 31  Epoch: 40  Training loss = 2.9232  Validation loss = 2.2922  \n",
      "\n",
      "Fold: 31  Epoch: 41  Training loss = 2.9231  Validation loss = 2.2920  \n",
      "\n",
      "Fold: 31  Epoch: 42  Training loss = 2.9229  Validation loss = 2.2914  \n",
      "\n",
      "Fold: 31  Epoch: 43  Training loss = 2.9228  Validation loss = 2.2909  \n",
      "\n",
      "Fold: 31  Epoch: 44  Training loss = 2.9226  Validation loss = 2.2905  \n",
      "\n",
      "Fold: 31  Epoch: 45  Training loss = 2.9225  Validation loss = 2.2907  \n",
      "\n",
      "Fold: 31  Epoch: 46  Training loss = 2.9224  Validation loss = 2.2906  \n",
      "\n",
      "Fold: 31  Epoch: 47  Training loss = 2.9223  Validation loss = 2.2907  \n",
      "\n",
      "Fold: 31  Epoch: 48  Training loss = 2.9221  Validation loss = 2.2900  \n",
      "\n",
      "Fold: 31  Epoch: 49  Training loss = 2.9220  Validation loss = 2.2900  \n",
      "\n",
      "Fold: 31  Epoch: 50  Training loss = 2.9218  Validation loss = 2.2892  \n",
      "\n",
      "Fold: 31  Epoch: 51  Training loss = 2.9217  Validation loss = 2.2889  \n",
      "\n",
      "Fold: 31  Epoch: 52  Training loss = 2.9215  Validation loss = 2.2888  \n",
      "\n",
      "Fold: 31  Epoch: 53  Training loss = 2.9214  Validation loss = 2.2886  \n",
      "\n",
      "Fold: 31  Epoch: 54  Training loss = 2.9213  Validation loss = 2.2883  \n",
      "\n",
      "Fold: 31  Epoch: 55  Training loss = 2.9211  Validation loss = 2.2879  \n",
      "\n",
      "Fold: 31  Epoch: 56  Training loss = 2.9210  Validation loss = 2.2877  \n",
      "\n",
      "Fold: 31  Epoch: 57  Training loss = 2.9208  Validation loss = 2.2879  \n",
      "\n",
      "Fold: 31  Epoch: 58  Training loss = 2.9207  Validation loss = 2.2875  \n",
      "\n",
      "Fold: 31  Epoch: 59  Training loss = 2.9206  Validation loss = 2.2873  \n",
      "\n",
      "Fold: 31  Epoch: 60  Training loss = 2.9203  Validation loss = 2.2860  \n",
      "\n",
      "Fold: 31  Epoch: 61  Training loss = 2.9202  Validation loss = 2.2857  \n",
      "\n",
      "Fold: 31  Epoch: 62  Training loss = 2.9200  Validation loss = 2.2845  \n",
      "\n",
      "Fold: 31  Epoch: 63  Training loss = 2.9199  Validation loss = 2.2846  \n",
      "\n",
      "Fold: 31  Epoch: 64  Training loss = 2.9197  Validation loss = 2.2837  \n",
      "\n",
      "Fold: 31  Epoch: 65  Training loss = 2.9196  Validation loss = 2.2840  \n",
      "\n",
      "Fold: 31  Epoch: 66  Training loss = 2.9194  Validation loss = 2.2834  \n",
      "\n",
      "Fold: 31  Epoch: 67  Training loss = 2.9193  Validation loss = 2.2829  \n",
      "\n",
      "Fold: 31  Epoch: 68  Training loss = 2.9191  Validation loss = 2.2824  \n",
      "\n",
      "Fold: 31  Epoch: 69  Training loss = 2.9190  Validation loss = 2.2824  \n",
      "\n",
      "Fold: 31  Epoch: 70  Training loss = 2.9188  Validation loss = 2.2820  \n",
      "\n",
      "Fold: 31  Epoch: 71  Training loss = 2.9187  Validation loss = 2.2817  \n",
      "\n",
      "Fold: 31  Epoch: 72  Training loss = 2.9185  Validation loss = 2.2814  \n",
      "\n",
      "Fold: 31  Epoch: 73  Training loss = 2.9183  Validation loss = 2.2807  \n",
      "\n",
      "Fold: 31  Epoch: 74  Training loss = 2.9182  Validation loss = 2.2802  \n",
      "\n",
      "Fold: 31  Epoch: 75  Training loss = 2.9180  Validation loss = 2.2798  \n",
      "\n",
      "Fold: 31  Epoch: 76  Training loss = 2.9179  Validation loss = 2.2798  \n",
      "\n",
      "Fold: 31  Epoch: 77  Training loss = 2.9177  Validation loss = 2.2792  \n",
      "\n",
      "Fold: 31  Epoch: 78  Training loss = 2.9176  Validation loss = 2.2785  \n",
      "\n",
      "Fold: 31  Epoch: 79  Training loss = 2.9175  Validation loss = 2.2790  \n",
      "\n",
      "Fold: 31  Epoch: 80  Training loss = 2.9173  Validation loss = 2.2789  \n",
      "\n",
      "Fold: 31  Epoch: 81  Training loss = 2.9172  Validation loss = 2.2783  \n",
      "\n",
      "Fold: 31  Epoch: 82  Training loss = 2.9170  Validation loss = 2.2780  \n",
      "\n",
      "Fold: 31  Epoch: 83  Training loss = 2.9169  Validation loss = 2.2774  \n",
      "\n",
      "Fold: 31  Epoch: 84  Training loss = 2.9168  Validation loss = 2.2771  \n",
      "\n",
      "Fold: 31  Epoch: 85  Training loss = 2.9166  Validation loss = 2.2767  \n",
      "\n",
      "Fold: 31  Epoch: 86  Training loss = 2.9164  Validation loss = 2.2764  \n",
      "\n",
      "Fold: 31  Epoch: 87  Training loss = 2.9163  Validation loss = 2.2762  \n",
      "\n",
      "Fold: 31  Epoch: 88  Training loss = 2.9161  Validation loss = 2.2757  \n",
      "\n",
      "Fold: 31  Epoch: 89  Training loss = 2.9160  Validation loss = 2.2757  \n",
      "\n",
      "Fold: 31  Epoch: 90  Training loss = 2.9159  Validation loss = 2.2756  \n",
      "\n",
      "Fold: 31  Epoch: 91  Training loss = 2.9157  Validation loss = 2.2755  \n",
      "\n",
      "Fold: 31  Epoch: 92  Training loss = 2.9155  Validation loss = 2.2748  \n",
      "\n",
      "Fold: 31  Epoch: 93  Training loss = 2.9154  Validation loss = 2.2741  \n",
      "\n",
      "Fold: 31  Epoch: 94  Training loss = 2.9153  Validation loss = 2.2742  \n",
      "\n",
      "Fold: 31  Epoch: 95  Training loss = 2.9151  Validation loss = 2.2740  \n",
      "\n",
      "Fold: 31  Epoch: 96  Training loss = 2.9149  Validation loss = 2.2735  \n",
      "\n",
      "Fold: 31  Epoch: 97  Training loss = 2.9148  Validation loss = 2.2726  \n",
      "\n",
      "Fold: 31  Epoch: 98  Training loss = 2.9146  Validation loss = 2.2724  \n",
      "\n",
      "Fold: 31  Epoch: 99  Training loss = 2.9145  Validation loss = 2.2724  \n",
      "\n",
      "Fold: 31  Epoch: 100  Training loss = 2.9144  Validation loss = 2.2728  \n",
      "\n",
      "Fold: 31  Epoch: 101  Training loss = 2.9143  Validation loss = 2.2726  \n",
      "\n",
      "Fold: 31  Epoch: 102  Training loss = 2.9141  Validation loss = 2.2722  \n",
      "\n",
      "Fold: 31  Epoch: 103  Training loss = 2.9140  Validation loss = 2.2725  \n",
      "\n",
      "Fold: 31  Epoch: 104  Training loss = 2.9139  Validation loss = 2.2720  \n",
      "\n",
      "Fold: 31  Epoch: 105  Training loss = 2.9137  Validation loss = 2.2713  \n",
      "\n",
      "Fold: 31  Epoch: 106  Training loss = 2.9136  Validation loss = 2.2711  \n",
      "\n",
      "Fold: 31  Epoch: 107  Training loss = 2.9134  Validation loss = 2.2711  \n",
      "\n",
      "Fold: 31  Epoch: 108  Training loss = 2.9133  Validation loss = 2.2709  \n",
      "\n",
      "Fold: 31  Epoch: 109  Training loss = 2.9131  Validation loss = 2.2704  \n",
      "\n",
      "Fold: 31  Epoch: 110  Training loss = 2.9130  Validation loss = 2.2704  \n",
      "\n",
      "Fold: 31  Epoch: 111  Training loss = 2.9129  Validation loss = 2.2698  \n",
      "\n",
      "Fold: 31  Epoch: 112  Training loss = 2.9127  Validation loss = 2.2697  \n",
      "\n",
      "Fold: 31  Epoch: 113  Training loss = 2.9125  Validation loss = 2.2694  \n",
      "\n",
      "Fold: 31  Epoch: 114  Training loss = 2.9124  Validation loss = 2.2690  \n",
      "\n",
      "Fold: 31  Epoch: 115  Training loss = 2.9122  Validation loss = 2.2689  \n",
      "\n",
      "Fold: 31  Epoch: 116  Training loss = 2.9121  Validation loss = 2.2686  \n",
      "\n",
      "Fold: 31  Epoch: 117  Training loss = 2.9119  Validation loss = 2.2685  \n",
      "\n",
      "Fold: 31  Epoch: 118  Training loss = 2.9118  Validation loss = 2.2679  \n",
      "\n",
      "Fold: 31  Epoch: 119  Training loss = 2.9117  Validation loss = 2.2678  \n",
      "\n",
      "Fold: 31  Epoch: 120  Training loss = 2.9116  Validation loss = 2.2676  \n",
      "\n",
      "Fold: 31  Epoch: 121  Training loss = 2.9114  Validation loss = 2.2675  \n",
      "\n",
      "Fold: 31  Epoch: 122  Training loss = 2.9112  Validation loss = 2.2667  \n",
      "\n",
      "Fold: 31  Epoch: 123  Training loss = 2.9111  Validation loss = 2.2667  \n",
      "\n",
      "Fold: 31  Epoch: 124  Training loss = 2.9110  Validation loss = 2.2664  \n",
      "\n",
      "Fold: 31  Epoch: 125  Training loss = 2.9108  Validation loss = 2.2660  \n",
      "\n",
      "Fold: 31  Epoch: 126  Training loss = 2.9107  Validation loss = 2.2660  \n",
      "\n",
      "Fold: 31  Epoch: 127  Training loss = 2.9105  Validation loss = 2.2657  \n",
      "\n",
      "Fold: 31  Epoch: 128  Training loss = 2.9104  Validation loss = 2.2661  \n",
      "\n",
      "Fold: 31  Epoch: 129  Training loss = 2.9103  Validation loss = 2.2660  \n",
      "\n",
      "Fold: 31  Epoch: 130  Training loss = 2.9102  Validation loss = 2.2657  \n",
      "\n",
      "Fold: 31  Epoch: 131  Training loss = 2.9101  Validation loss = 2.2656  \n",
      "\n",
      "Fold: 31  Epoch: 132  Training loss = 2.9100  Validation loss = 2.2657  \n",
      "\n",
      "Fold: 31  Epoch: 133  Training loss = 2.9098  Validation loss = 2.2655  \n",
      "\n",
      "Fold: 31  Epoch: 134  Training loss = 2.9097  Validation loss = 2.2655  \n",
      "\n",
      "Fold: 31  Epoch: 135  Training loss = 2.9096  Validation loss = 2.2653  \n",
      "\n",
      "Fold: 31  Epoch: 136  Training loss = 2.9094  Validation loss = 2.2650  \n",
      "\n",
      "Fold: 31  Epoch: 137  Training loss = 2.9093  Validation loss = 2.2644  \n",
      "\n",
      "Fold: 31  Epoch: 138  Training loss = 2.9091  Validation loss = 2.2644  \n",
      "\n",
      "Fold: 31  Epoch: 139  Training loss = 2.9090  Validation loss = 2.2643  \n",
      "\n",
      "Fold: 31  Epoch: 140  Training loss = 2.9088  Validation loss = 2.2638  \n",
      "\n",
      "Fold: 31  Epoch: 141  Training loss = 2.9087  Validation loss = 2.2638  \n",
      "\n",
      "Fold: 31  Epoch: 142  Training loss = 2.9086  Validation loss = 2.2636  \n",
      "\n",
      "Fold: 31  Epoch: 143  Training loss = 2.9084  Validation loss = 2.2634  \n",
      "\n",
      "Fold: 31  Epoch: 144  Training loss = 2.9083  Validation loss = 2.2636  \n",
      "\n",
      "Fold: 31  Epoch: 145  Training loss = 2.9081  Validation loss = 2.2629  \n",
      "\n",
      "Fold: 31  Epoch: 146  Training loss = 2.9079  Validation loss = 2.2623  \n",
      "\n",
      "Fold: 31  Epoch: 147  Training loss = 2.9078  Validation loss = 2.2622  \n",
      "\n",
      "Fold: 31  Epoch: 148  Training loss = 2.9077  Validation loss = 2.2623  \n",
      "\n",
      "Fold: 31  Epoch: 149  Training loss = 2.9076  Validation loss = 2.2616  \n",
      "\n",
      "Fold: 31  Epoch: 150  Training loss = 2.9075  Validation loss = 2.2616  \n",
      "\n",
      "Fold: 31  Epoch: 151  Training loss = 2.9074  Validation loss = 2.2612  \n",
      "\n",
      "Fold: 31  Epoch: 152  Training loss = 2.9072  Validation loss = 2.2609  \n",
      "\n",
      "Fold: 31  Epoch: 153  Training loss = 2.9071  Validation loss = 2.2603  \n",
      "\n",
      "Fold: 31  Epoch: 154  Training loss = 2.9069  Validation loss = 2.2600  \n",
      "\n",
      "Fold: 31  Epoch: 155  Training loss = 2.9068  Validation loss = 2.2594  \n",
      "\n",
      "Fold: 31  Epoch: 156  Training loss = 2.9066  Validation loss = 2.2593  \n",
      "\n",
      "Fold: 31  Epoch: 157  Training loss = 2.9065  Validation loss = 2.2588  \n",
      "\n",
      "Fold: 31  Epoch: 158  Training loss = 2.9063  Validation loss = 2.2585  \n",
      "\n",
      "Fold: 31  Epoch: 159  Training loss = 2.9063  Validation loss = 2.2585  \n",
      "\n",
      "Fold: 31  Epoch: 160  Training loss = 2.9061  Validation loss = 2.2580  \n",
      "\n",
      "Fold: 31  Epoch: 161  Training loss = 2.9059  Validation loss = 2.2572  \n",
      "\n",
      "Fold: 31  Epoch: 162  Training loss = 2.9058  Validation loss = 2.2569  \n",
      "\n",
      "Fold: 31  Epoch: 163  Training loss = 2.9057  Validation loss = 2.2569  \n",
      "\n",
      "Fold: 31  Epoch: 164  Training loss = 2.9056  Validation loss = 2.2566  \n",
      "\n",
      "Fold: 31  Epoch: 165  Training loss = 2.9054  Validation loss = 2.2562  \n",
      "\n",
      "Fold: 31  Epoch: 166  Training loss = 2.9053  Validation loss = 2.2553  \n",
      "\n",
      "Fold: 31  Epoch: 167  Training loss = 2.9051  Validation loss = 2.2545  \n",
      "\n",
      "Fold: 31  Epoch: 168  Training loss = 2.9049  Validation loss = 2.2537  \n",
      "\n",
      "Fold: 31  Epoch: 169  Training loss = 2.9048  Validation loss = 2.2535  \n",
      "\n",
      "Fold: 31  Epoch: 170  Training loss = 2.9047  Validation loss = 2.2533  \n",
      "\n",
      "Fold: 31  Epoch: 171  Training loss = 2.9045  Validation loss = 2.2524  \n",
      "\n",
      "Fold: 31  Epoch: 172  Training loss = 2.9043  Validation loss = 2.2521  \n",
      "\n",
      "Fold: 31  Epoch: 173  Training loss = 2.9042  Validation loss = 2.2518  \n",
      "\n",
      "Fold: 31  Epoch: 174  Training loss = 2.9040  Validation loss = 2.2512  \n",
      "\n",
      "Fold: 31  Epoch: 175  Training loss = 2.9038  Validation loss = 2.2507  \n",
      "\n",
      "Fold: 31  Epoch: 176  Training loss = 2.9037  Validation loss = 2.2502  \n",
      "\n",
      "Fold: 31  Epoch: 177  Training loss = 2.9035  Validation loss = 2.2497  \n",
      "\n",
      "Fold: 31  Epoch: 178  Training loss = 2.9034  Validation loss = 2.2494  \n",
      "\n",
      "Fold: 31  Epoch: 179  Training loss = 2.9033  Validation loss = 2.2490  \n",
      "\n",
      "Fold: 31  Epoch: 180  Training loss = 2.9032  Validation loss = 2.2489  \n",
      "\n",
      "Fold: 31  Epoch: 181  Training loss = 2.9030  Validation loss = 2.2486  \n",
      "\n",
      "Fold: 31  Epoch: 182  Training loss = 2.9029  Validation loss = 2.2482  \n",
      "\n",
      "Fold: 31  Epoch: 183  Training loss = 2.9027  Validation loss = 2.2474  \n",
      "\n",
      "Fold: 31  Epoch: 184  Training loss = 2.9026  Validation loss = 2.2473  \n",
      "\n",
      "Fold: 31  Epoch: 185  Training loss = 2.9025  Validation loss = 2.2475  \n",
      "\n",
      "Fold: 31  Epoch: 186  Training loss = 2.9023  Validation loss = 2.2469  \n",
      "\n",
      "Fold: 31  Epoch: 187  Training loss = 2.9021  Validation loss = 2.2462  \n",
      "\n",
      "Fold: 31  Epoch: 188  Training loss = 2.9020  Validation loss = 2.2460  \n",
      "\n",
      "Fold: 31  Epoch: 189  Training loss = 2.9019  Validation loss = 2.2460  \n",
      "\n",
      "Fold: 31  Epoch: 190  Training loss = 2.9017  Validation loss = 2.2453  \n",
      "\n",
      "Fold: 31  Epoch: 191  Training loss = 2.9016  Validation loss = 2.2450  \n",
      "\n",
      "Fold: 31  Epoch: 192  Training loss = 2.9014  Validation loss = 2.2442  \n",
      "\n",
      "Fold: 31  Epoch: 193  Training loss = 2.9012  Validation loss = 2.2440  \n",
      "\n",
      "Fold: 31  Epoch: 194  Training loss = 2.9011  Validation loss = 2.2436  \n",
      "\n",
      "Fold: 31  Epoch: 195  Training loss = 2.9009  Validation loss = 2.2433  \n",
      "\n",
      "Fold: 31  Epoch: 196  Training loss = 2.9008  Validation loss = 2.2431  \n",
      "\n",
      "Fold: 31  Epoch: 197  Training loss = 2.9007  Validation loss = 2.2430  \n",
      "\n",
      "Fold: 31  Epoch: 198  Training loss = 2.9005  Validation loss = 2.2425  \n",
      "\n",
      "Fold: 31  Epoch: 199  Training loss = 2.9004  Validation loss = 2.2427  \n",
      "\n",
      "Fold: 31  Epoch: 200  Training loss = 2.9003  Validation loss = 2.2426  \n",
      "\n",
      "Fold: 31  Epoch: 201  Training loss = 2.9002  Validation loss = 2.2423  \n",
      "\n",
      "Fold: 31  Epoch: 202  Training loss = 2.9001  Validation loss = 2.2422  \n",
      "\n",
      "Fold: 31  Epoch: 203  Training loss = 2.8999  Validation loss = 2.2423  \n",
      "\n",
      "Fold: 31  Epoch: 204  Training loss = 2.8998  Validation loss = 2.2418  \n",
      "\n",
      "Fold: 31  Epoch: 205  Training loss = 2.8996  Validation loss = 2.2411  \n",
      "\n",
      "Fold: 31  Epoch: 206  Training loss = 2.8994  Validation loss = 2.2404  \n",
      "\n",
      "Fold: 31  Epoch: 207  Training loss = 2.8993  Validation loss = 2.2407  \n",
      "\n",
      "Fold: 31  Epoch: 208  Training loss = 2.8992  Validation loss = 2.2402  \n",
      "\n",
      "Fold: 31  Epoch: 209  Training loss = 2.8991  Validation loss = 2.2404  \n",
      "\n",
      "Fold: 31  Epoch: 210  Training loss = 2.8989  Validation loss = 2.2396  \n",
      "\n",
      "Fold: 31  Epoch: 211  Training loss = 2.8988  Validation loss = 2.2390  \n",
      "\n",
      "Fold: 31  Epoch: 212  Training loss = 2.8987  Validation loss = 2.2391  \n",
      "\n",
      "Fold: 31  Epoch: 213  Training loss = 2.8985  Validation loss = 2.2386  \n",
      "\n",
      "Fold: 31  Epoch: 214  Training loss = 2.8984  Validation loss = 2.2382  \n",
      "\n",
      "Fold: 31  Epoch: 215  Training loss = 2.8982  Validation loss = 2.2379  \n",
      "\n",
      "Fold: 31  Epoch: 216  Training loss = 2.8981  Validation loss = 2.2377  \n",
      "\n",
      "Fold: 31  Epoch: 217  Training loss = 2.8980  Validation loss = 2.2375  \n",
      "\n",
      "Fold: 31  Epoch: 218  Training loss = 2.8978  Validation loss = 2.2368  \n",
      "\n",
      "Fold: 31  Epoch: 219  Training loss = 2.8977  Validation loss = 2.2368  \n",
      "\n",
      "Fold: 31  Epoch: 220  Training loss = 2.8975  Validation loss = 2.2364  \n",
      "\n",
      "Fold: 31  Epoch: 221  Training loss = 2.8974  Validation loss = 2.2357  \n",
      "\n",
      "Fold: 31  Epoch: 222  Training loss = 2.8972  Validation loss = 2.2353  \n",
      "\n",
      "Fold: 31  Epoch: 223  Training loss = 2.8970  Validation loss = 2.2348  \n",
      "\n",
      "Fold: 31  Epoch: 224  Training loss = 2.8969  Validation loss = 2.2347  \n",
      "\n",
      "Fold: 31  Epoch: 225  Training loss = 2.8967  Validation loss = 2.2341  \n",
      "\n",
      "Fold: 31  Epoch: 226  Training loss = 2.8966  Validation loss = 2.2340  \n",
      "\n",
      "Fold: 31  Epoch: 227  Training loss = 2.8965  Validation loss = 2.2339  \n",
      "\n",
      "Fold: 31  Epoch: 228  Training loss = 2.8963  Validation loss = 2.2335  \n",
      "\n",
      "Fold: 31  Epoch: 229  Training loss = 2.8962  Validation loss = 2.2336  \n",
      "\n",
      "Fold: 31  Epoch: 230  Training loss = 2.8961  Validation loss = 2.2335  \n",
      "\n",
      "Fold: 31  Epoch: 231  Training loss = 2.8959  Validation loss = 2.2329  \n",
      "\n",
      "Fold: 31  Epoch: 232  Training loss = 2.8958  Validation loss = 2.2320  \n",
      "\n",
      "Fold: 31  Epoch: 233  Training loss = 2.8956  Validation loss = 2.2317  \n",
      "\n",
      "Fold: 31  Epoch: 234  Training loss = 2.8955  Validation loss = 2.2313  \n",
      "\n",
      "Fold: 31  Epoch: 235  Training loss = 2.8954  Validation loss = 2.2308  \n",
      "\n",
      "Fold: 31  Epoch: 236  Training loss = 2.8952  Validation loss = 2.2304  \n",
      "\n",
      "Fold: 31  Epoch: 237  Training loss = 2.8951  Validation loss = 2.2306  \n",
      "\n",
      "Fold: 31  Epoch: 238  Training loss = 2.8950  Validation loss = 2.2305  \n",
      "\n",
      "Fold: 31  Epoch: 239  Training loss = 2.8949  Validation loss = 2.2303  \n",
      "\n",
      "Fold: 31  Epoch: 240  Training loss = 2.8947  Validation loss = 2.2297  \n",
      "\n",
      "Fold: 31  Epoch: 241  Training loss = 2.8945  Validation loss = 2.2296  \n",
      "\n",
      "Fold: 31  Epoch: 242  Training loss = 2.8944  Validation loss = 2.2290  \n",
      "\n",
      "Fold: 31  Epoch: 243  Training loss = 2.8943  Validation loss = 2.2288  \n",
      "\n",
      "Fold: 31  Epoch: 244  Training loss = 2.8941  Validation loss = 2.2285  \n",
      "\n",
      "Fold: 31  Epoch: 245  Training loss = 2.8939  Validation loss = 2.2278  \n",
      "\n",
      "Fold: 31  Epoch: 246  Training loss = 2.8938  Validation loss = 2.2274  \n",
      "\n",
      "Fold: 31  Epoch: 247  Training loss = 2.8937  Validation loss = 2.2272  \n",
      "\n",
      "Fold: 31  Epoch: 248  Training loss = 2.8935  Validation loss = 2.2268  \n",
      "\n",
      "Fold: 31  Epoch: 249  Training loss = 2.8935  Validation loss = 2.2270  \n",
      "\n",
      "Fold: 31  Epoch: 250  Training loss = 2.8933  Validation loss = 2.2261  \n",
      "\n",
      "Fold: 31  Epoch: 251  Training loss = 2.8932  Validation loss = 2.2264  \n",
      "\n",
      "Fold: 31  Epoch: 252  Training loss = 2.8930  Validation loss = 2.2260  \n",
      "\n",
      "Fold: 31  Epoch: 253  Training loss = 2.8929  Validation loss = 2.2257  \n",
      "\n",
      "Fold: 31  Epoch: 254  Training loss = 2.8927  Validation loss = 2.2252  \n",
      "\n",
      "Fold: 31  Epoch: 255  Training loss = 2.8926  Validation loss = 2.2249  \n",
      "\n",
      "Fold: 31  Epoch: 256  Training loss = 2.8925  Validation loss = 2.2244  \n",
      "\n",
      "Fold: 31  Epoch: 257  Training loss = 2.8923  Validation loss = 2.2236  \n",
      "\n",
      "Fold: 31  Epoch: 258  Training loss = 2.8921  Validation loss = 2.2237  \n",
      "\n",
      "Fold: 31  Epoch: 259  Training loss = 2.8920  Validation loss = 2.2233  \n",
      "\n",
      "Fold: 31  Epoch: 260  Training loss = 2.8918  Validation loss = 2.2228  \n",
      "\n",
      "Fold: 31  Epoch: 261  Training loss = 2.8917  Validation loss = 2.2226  \n",
      "\n",
      "Fold: 31  Epoch: 262  Training loss = 2.8916  Validation loss = 2.2225  \n",
      "\n",
      "Fold: 31  Epoch: 263  Training loss = 2.8914  Validation loss = 2.2222  \n",
      "\n",
      "Fold: 31  Epoch: 264  Training loss = 2.8913  Validation loss = 2.2221  \n",
      "\n",
      "Fold: 31  Epoch: 265  Training loss = 2.8912  Validation loss = 2.2219  \n",
      "\n",
      "Fold: 31  Epoch: 266  Training loss = 2.8911  Validation loss = 2.2220  \n",
      "\n",
      "Fold: 31  Epoch: 267  Training loss = 2.8909  Validation loss = 2.2216  \n",
      "\n",
      "Fold: 31  Epoch: 268  Training loss = 2.8908  Validation loss = 2.2212  \n",
      "\n",
      "Fold: 31  Epoch: 269  Training loss = 2.8906  Validation loss = 2.2203  \n",
      "\n",
      "Fold: 31  Epoch: 270  Training loss = 2.8905  Validation loss = 2.2202  \n",
      "\n",
      "Fold: 31  Epoch: 271  Training loss = 2.8903  Validation loss = 2.2200  \n",
      "\n",
      "Fold: 31  Epoch: 272  Training loss = 2.8902  Validation loss = 2.2200  \n",
      "\n",
      "Fold: 31  Epoch: 273  Training loss = 2.8900  Validation loss = 2.2192  \n",
      "\n",
      "Fold: 31  Epoch: 274  Training loss = 2.8898  Validation loss = 2.2186  \n",
      "\n",
      "Fold: 31  Epoch: 275  Training loss = 2.8897  Validation loss = 2.2186  \n",
      "\n",
      "Fold: 31  Epoch: 276  Training loss = 2.8896  Validation loss = 2.2187  \n",
      "\n",
      "Fold: 31  Epoch: 277  Training loss = 2.8894  Validation loss = 2.2184  \n",
      "\n",
      "Fold: 31  Epoch: 278  Training loss = 2.8893  Validation loss = 2.2179  \n",
      "\n",
      "Fold: 31  Epoch: 279  Training loss = 2.8892  Validation loss = 2.2179  \n",
      "\n",
      "Fold: 31  Epoch: 280  Training loss = 2.8890  Validation loss = 2.2178  \n",
      "\n",
      "Fold: 31  Epoch: 281  Training loss = 2.8889  Validation loss = 2.2180  \n",
      "\n",
      "Fold: 31  Epoch: 282  Training loss = 2.8887  Validation loss = 2.2175  \n",
      "\n",
      "Fold: 31  Epoch: 283  Training loss = 2.8886  Validation loss = 2.2173  \n",
      "\n",
      "Fold: 31  Epoch: 284  Training loss = 2.8885  Validation loss = 2.2174  \n",
      "\n",
      "Fold: 31  Epoch: 285  Training loss = 2.8884  Validation loss = 2.2171  \n",
      "\n",
      "Fold: 31  Epoch: 286  Training loss = 2.8882  Validation loss = 2.2165  \n",
      "\n",
      "Fold: 31  Epoch: 287  Training loss = 2.8881  Validation loss = 2.2168  \n",
      "\n",
      "Fold: 31  Epoch: 288  Training loss = 2.8880  Validation loss = 2.2169  \n",
      "\n",
      "Fold: 31  Epoch: 289  Training loss = 2.8879  Validation loss = 2.2165  \n",
      "\n",
      "Fold: 31  Epoch: 290  Training loss = 2.8878  Validation loss = 2.2165  \n",
      "\n",
      "Fold: 31  Epoch: 291  Training loss = 2.8877  Validation loss = 2.2165  \n",
      "\n",
      "Fold: 31  Epoch: 292  Training loss = 2.8875  Validation loss = 2.2159  \n",
      "\n",
      "Fold: 31  Epoch: 293  Training loss = 2.8874  Validation loss = 2.2157  \n",
      "\n",
      "Fold: 31  Epoch: 294  Training loss = 2.8872  Validation loss = 2.2153  \n",
      "\n",
      "Fold: 31  Epoch: 295  Training loss = 2.8871  Validation loss = 2.2150  \n",
      "\n",
      "Fold: 31  Epoch: 296  Training loss = 2.8869  Validation loss = 2.2142  \n",
      "\n",
      "Fold: 31  Epoch: 297  Training loss = 2.8868  Validation loss = 2.2142  \n",
      "\n",
      "Fold: 31  Epoch: 298  Training loss = 2.8867  Validation loss = 2.2142  \n",
      "\n",
      "Fold: 31  Epoch: 299  Training loss = 2.8865  Validation loss = 2.2138  \n",
      "\n",
      "Fold: 31  Epoch: 300  Training loss = 2.8864  Validation loss = 2.2134  \n",
      "\n",
      "Fold: 31  Epoch: 301  Training loss = 2.8863  Validation loss = 2.2127  \n",
      "\n",
      "Fold: 31  Epoch: 302  Training loss = 2.8861  Validation loss = 2.2122  \n",
      "\n",
      "Fold: 31  Epoch: 303  Training loss = 2.8859  Validation loss = 2.2113  \n",
      "\n",
      "Fold: 31  Epoch: 304  Training loss = 2.8858  Validation loss = 2.2110  \n",
      "\n",
      "Fold: 31  Epoch: 305  Training loss = 2.8857  Validation loss = 2.2115  \n",
      "\n",
      "Fold: 31  Epoch: 306  Training loss = 2.8856  Validation loss = 2.2109  \n",
      "\n",
      "Fold: 31  Epoch: 307  Training loss = 2.8854  Validation loss = 2.2105  \n",
      "\n",
      "Fold: 31  Epoch: 308  Training loss = 2.8853  Validation loss = 2.2102  \n",
      "\n",
      "Fold: 31  Epoch: 309  Training loss = 2.8852  Validation loss = 2.2099  \n",
      "\n",
      "Fold: 31  Epoch: 310  Training loss = 2.8851  Validation loss = 2.2096  \n",
      "\n",
      "Fold: 31  Epoch: 311  Training loss = 2.8849  Validation loss = 2.2095  \n",
      "\n",
      "Fold: 31  Epoch: 312  Training loss = 2.8848  Validation loss = 2.2090  \n",
      "\n",
      "Fold: 31  Epoch: 313  Training loss = 2.8846  Validation loss = 2.2086  \n",
      "\n",
      "Fold: 31  Epoch: 314  Training loss = 2.8845  Validation loss = 2.2083  \n",
      "\n",
      "Fold: 31  Epoch: 315  Training loss = 2.8843  Validation loss = 2.2077  \n",
      "\n",
      "Fold: 31  Epoch: 316  Training loss = 2.8841  Validation loss = 2.2069  \n",
      "\n",
      "Fold: 31  Epoch: 317  Training loss = 2.8840  Validation loss = 2.2071  \n",
      "\n",
      "Fold: 31  Epoch: 318  Training loss = 2.8838  Validation loss = 2.2067  \n",
      "\n",
      "Fold: 31  Epoch: 319  Training loss = 2.8837  Validation loss = 2.2069  \n",
      "\n",
      "Fold: 31  Epoch: 320  Training loss = 2.8835  Validation loss = 2.2060  \n",
      "\n",
      "Fold: 31  Epoch: 321  Training loss = 2.8834  Validation loss = 2.2058  \n",
      "\n",
      "Fold: 31  Epoch: 322  Training loss = 2.8832  Validation loss = 2.2054  \n",
      "\n",
      "Fold: 31  Epoch: 323  Training loss = 2.8831  Validation loss = 2.2053  \n",
      "\n",
      "Fold: 31  Epoch: 324  Training loss = 2.8830  Validation loss = 2.2048  \n",
      "\n",
      "Fold: 31  Epoch: 325  Training loss = 2.8829  Validation loss = 2.2047  \n",
      "\n",
      "Fold: 31  Epoch: 326  Training loss = 2.8827  Validation loss = 2.2042  \n",
      "\n",
      "Fold: 31  Epoch: 327  Training loss = 2.8826  Validation loss = 2.2042  \n",
      "\n",
      "Fold: 31  Epoch: 328  Training loss = 2.8825  Validation loss = 2.2045  \n",
      "\n",
      "Fold: 31  Epoch: 329  Training loss = 2.8824  Validation loss = 2.2040  \n",
      "\n",
      "Fold: 31  Epoch: 330  Training loss = 2.8822  Validation loss = 2.2034  \n",
      "\n",
      "Fold: 31  Epoch: 331  Training loss = 2.8821  Validation loss = 2.2033  \n",
      "\n",
      "Fold: 31  Epoch: 332  Training loss = 2.8819  Validation loss = 2.2031  \n",
      "\n",
      "Fold: 31  Epoch: 333  Training loss = 2.8818  Validation loss = 2.2029  \n",
      "\n",
      "Fold: 31  Epoch: 334  Training loss = 2.8817  Validation loss = 2.2030  \n",
      "\n",
      "Fold: 31  Epoch: 335  Training loss = 2.8815  Validation loss = 2.2026  \n",
      "\n",
      "Fold: 31  Epoch: 336  Training loss = 2.8814  Validation loss = 2.2024  \n",
      "\n",
      "Fold: 31  Epoch: 337  Training loss = 2.8812  Validation loss = 2.2016  \n",
      "\n",
      "Fold: 31  Epoch: 338  Training loss = 2.8810  Validation loss = 2.2012  \n",
      "\n",
      "Fold: 31  Epoch: 339  Training loss = 2.8808  Validation loss = 2.2005  \n",
      "\n",
      "Fold: 31  Epoch: 340  Training loss = 2.8807  Validation loss = 2.1999  \n",
      "\n",
      "Fold: 31  Epoch: 341  Training loss = 2.8805  Validation loss = 2.1993  \n",
      "\n",
      "Fold: 31  Epoch: 342  Training loss = 2.8803  Validation loss = 2.1985  \n",
      "\n",
      "Fold: 31  Epoch: 343  Training loss = 2.8802  Validation loss = 2.1982  \n",
      "\n",
      "Fold: 31  Epoch: 344  Training loss = 2.8800  Validation loss = 2.1976  \n",
      "\n",
      "Fold: 31  Epoch: 345  Training loss = 2.8799  Validation loss = 2.1976  \n",
      "\n",
      "Fold: 31  Epoch: 346  Training loss = 2.8797  Validation loss = 2.1971  \n",
      "\n",
      "Fold: 31  Epoch: 347  Training loss = 2.8795  Validation loss = 2.1966  \n",
      "\n",
      "Fold: 31  Epoch: 348  Training loss = 2.8794  Validation loss = 2.1967  \n",
      "\n",
      "Fold: 31  Epoch: 349  Training loss = 2.8793  Validation loss = 2.1961  \n",
      "\n",
      "Fold: 31  Epoch: 350  Training loss = 2.8791  Validation loss = 2.1954  \n",
      "\n",
      "Fold: 31  Epoch: 351  Training loss = 2.8789  Validation loss = 2.1951  \n",
      "\n",
      "Fold: 31  Epoch: 352  Training loss = 2.8787  Validation loss = 2.1941  \n",
      "\n",
      "Fold: 31  Epoch: 353  Training loss = 2.8785  Validation loss = 2.1936  \n",
      "\n",
      "Fold: 31  Epoch: 354  Training loss = 2.8784  Validation loss = 2.1933  \n",
      "\n",
      "Fold: 31  Epoch: 355  Training loss = 2.8783  Validation loss = 2.1927  \n",
      "\n",
      "Fold: 31  Epoch: 356  Training loss = 2.8781  Validation loss = 2.1921  \n",
      "\n",
      "Fold: 31  Epoch: 357  Training loss = 2.8780  Validation loss = 2.1918  \n",
      "\n",
      "Fold: 31  Epoch: 358  Training loss = 2.8779  Validation loss = 2.1921  \n",
      "\n",
      "Fold: 31  Epoch: 359  Training loss = 2.8777  Validation loss = 2.1917  \n",
      "\n",
      "Fold: 31  Epoch: 360  Training loss = 2.8775  Validation loss = 2.1913  \n",
      "\n",
      "Fold: 31  Epoch: 361  Training loss = 2.8773  Validation loss = 2.1910  \n",
      "\n",
      "Fold: 31  Epoch: 362  Training loss = 2.8772  Validation loss = 2.1904  \n",
      "\n",
      "Fold: 31  Epoch: 363  Training loss = 2.8770  Validation loss = 2.1901  \n",
      "\n",
      "Fold: 31  Epoch: 364  Training loss = 2.8769  Validation loss = 2.1896  \n",
      "\n",
      "Fold: 31  Epoch: 365  Training loss = 2.8767  Validation loss = 2.1893  \n",
      "\n",
      "Fold: 31  Epoch: 366  Training loss = 2.8766  Validation loss = 2.1890  \n",
      "\n",
      "Fold: 31  Epoch: 367  Training loss = 2.8764  Validation loss = 2.1888  \n",
      "\n",
      "Fold: 31  Epoch: 368  Training loss = 2.8763  Validation loss = 2.1886  \n",
      "\n",
      "Fold: 31  Epoch: 369  Training loss = 2.8760  Validation loss = 2.1875  \n",
      "\n",
      "Fold: 31  Epoch: 370  Training loss = 2.8759  Validation loss = 2.1872  \n",
      "\n",
      "Fold: 31  Epoch: 371  Training loss = 2.8758  Validation loss = 2.1868  \n",
      "\n",
      "Fold: 31  Epoch: 372  Training loss = 2.8756  Validation loss = 2.1862  \n",
      "\n",
      "Fold: 31  Epoch: 373  Training loss = 2.8753  Validation loss = 2.1853  \n",
      "\n",
      "Fold: 31  Epoch: 374  Training loss = 2.8752  Validation loss = 2.1854  \n",
      "\n",
      "Fold: 31  Epoch: 375  Training loss = 2.8751  Validation loss = 2.1852  \n",
      "\n",
      "Fold: 31  Epoch: 376  Training loss = 2.8750  Validation loss = 2.1848  \n",
      "\n",
      "Fold: 31  Epoch: 377  Training loss = 2.8748  Validation loss = 2.1844  \n",
      "\n",
      "Fold: 31  Epoch: 378  Training loss = 2.8746  Validation loss = 2.1835  \n",
      "\n",
      "Fold: 31  Epoch: 379  Training loss = 2.8744  Validation loss = 2.1826  \n",
      "\n",
      "Fold: 31  Epoch: 380  Training loss = 2.8741  Validation loss = 2.1816  \n",
      "\n",
      "Fold: 31  Epoch: 381  Training loss = 2.8739  Validation loss = 2.1810  \n",
      "\n",
      "Fold: 31  Epoch: 382  Training loss = 2.8737  Validation loss = 2.1804  \n",
      "\n",
      "Fold: 31  Epoch: 383  Training loss = 2.8735  Validation loss = 2.1792  \n",
      "\n",
      "Fold: 31  Epoch: 384  Training loss = 2.8734  Validation loss = 2.1795  \n",
      "\n",
      "Fold: 31  Epoch: 385  Training loss = 2.8732  Validation loss = 2.1788  \n",
      "\n",
      "Fold: 31  Epoch: 386  Training loss = 2.8730  Validation loss = 2.1783  \n",
      "\n",
      "Fold: 31  Epoch: 387  Training loss = 2.8729  Validation loss = 2.1783  \n",
      "\n",
      "Fold: 31  Epoch: 388  Training loss = 2.8728  Validation loss = 2.1785  \n",
      "\n",
      "Fold: 31  Epoch: 389  Training loss = 2.8725  Validation loss = 2.1775  \n",
      "\n",
      "Fold: 31  Epoch: 390  Training loss = 2.8722  Validation loss = 2.1762  \n",
      "\n",
      "Fold: 31  Epoch: 391  Training loss = 2.8720  Validation loss = 2.1758  \n",
      "\n",
      "Fold: 31  Epoch: 392  Training loss = 2.8718  Validation loss = 2.1750  \n",
      "\n",
      "Fold: 31  Epoch: 393  Training loss = 2.8715  Validation loss = 2.1744  \n",
      "\n",
      "Fold: 31  Epoch: 394  Training loss = 2.8712  Validation loss = 2.1733  \n",
      "\n",
      "Fold: 31  Epoch: 395  Training loss = 2.8707  Validation loss = 2.1721  \n",
      "\n",
      "Fold: 31  Epoch: 396  Training loss = 2.8701  Validation loss = 2.1703  \n",
      "\n",
      "Fold: 31  Epoch: 397  Training loss = 2.8699  Validation loss = 2.1699  \n",
      "\n",
      "Fold: 31  Epoch: 398  Training loss = 2.8690  Validation loss = 2.1676  \n",
      "\n",
      "Fold: 31  Epoch: 399  Training loss = 2.8688  Validation loss = 2.1674  \n",
      "\n",
      "Fold: 31  Epoch: 400  Training loss = 2.8686  Validation loss = 2.1671  \n",
      "\n",
      "Fold: 31  Epoch: 401  Training loss = 2.8682  Validation loss = 2.1660  \n",
      "\n",
      "Fold: 31  Epoch: 402  Training loss = 2.8676  Validation loss = 2.1650  \n",
      "\n",
      "Fold: 31  Epoch: 403  Training loss = 2.8670  Validation loss = 2.1637  \n",
      "\n",
      "Fold: 31  Epoch: 404  Training loss = 2.8662  Validation loss = 2.1620  \n",
      "\n",
      "Fold: 31  Epoch: 405  Training loss = 2.8657  Validation loss = 2.1608  \n",
      "\n",
      "Fold: 31  Epoch: 406  Training loss = 2.8646  Validation loss = 2.1579  \n",
      "\n",
      "Fold: 31  Epoch: 407  Training loss = 2.8641  Validation loss = 2.1568  \n",
      "\n",
      "Fold: 31  Epoch: 408  Training loss = 2.8636  Validation loss = 2.1555  \n",
      "\n",
      "Fold: 31  Epoch: 409  Training loss = 2.8631  Validation loss = 2.1537  \n",
      "\n",
      "Fold: 31  Epoch: 410  Training loss = 2.8626  Validation loss = 2.1516  \n",
      "\n",
      "Fold: 31  Epoch: 411  Training loss = 2.8622  Validation loss = 2.1505  \n",
      "\n",
      "Fold: 31  Epoch: 412  Training loss = 2.8622  Validation loss = 2.1506  \n",
      "\n",
      "Fold: 31  Epoch: 413  Training loss = 2.8619  Validation loss = 2.1499  \n",
      "\n",
      "Fold: 31  Epoch: 414  Training loss = 2.8617  Validation loss = 2.1492  \n",
      "\n",
      "Fold: 31  Epoch: 415  Training loss = 2.8615  Validation loss = 2.1490  \n",
      "\n",
      "Fold: 31  Epoch: 416  Training loss = 2.8613  Validation loss = 2.1481  \n",
      "\n",
      "Fold: 31  Epoch: 417  Training loss = 2.8609  Validation loss = 2.1464  \n",
      "\n",
      "Fold: 31  Epoch: 418  Training loss = 2.8605  Validation loss = 2.1441  \n",
      "\n",
      "Fold: 31  Epoch: 419  Training loss = 2.8601  Validation loss = 2.1424  \n",
      "\n",
      "Fold: 31  Epoch: 420  Training loss = 2.8599  Validation loss = 2.1419  \n",
      "\n",
      "Fold: 31  Epoch: 421  Training loss = 2.8598  Validation loss = 2.1418  \n",
      "\n",
      "Fold: 31  Epoch: 422  Training loss = 2.8596  Validation loss = 2.1414  \n",
      "\n",
      "Fold: 31  Epoch: 423  Training loss = 2.8595  Validation loss = 2.1410  \n",
      "\n",
      "Fold: 31  Epoch: 424  Training loss = 2.8593  Validation loss = 2.1407  \n",
      "\n",
      "Fold: 31  Epoch: 425  Training loss = 2.8590  Validation loss = 2.1392  \n",
      "\n",
      "Fold: 31  Epoch: 426  Training loss = 2.8589  Validation loss = 2.1389  \n",
      "\n",
      "Fold: 31  Epoch: 427  Training loss = 2.8587  Validation loss = 2.1379  \n",
      "\n",
      "Fold: 31  Epoch: 428  Training loss = 2.8584  Validation loss = 2.1364  \n",
      "\n",
      "Fold: 31  Epoch: 429  Training loss = 2.8581  Validation loss = 2.1354  \n",
      "\n",
      "Fold: 31  Epoch: 430  Training loss = 2.8579  Validation loss = 2.1340  \n",
      "\n",
      "Fold: 31  Epoch: 431  Training loss = 2.8576  Validation loss = 2.1325  \n",
      "\n",
      "Fold: 31  Epoch: 432  Training loss = 2.8574  Validation loss = 2.1316  \n",
      "\n",
      "Fold: 31  Epoch: 433  Training loss = 2.8572  Validation loss = 2.1304  \n",
      "\n",
      "Fold: 31  Epoch: 434  Training loss = 2.8571  Validation loss = 2.1305  \n",
      "\n",
      "Fold: 31  Epoch: 435  Training loss = 2.8569  Validation loss = 2.1300  \n",
      "\n",
      "Fold: 31  Epoch: 436  Training loss = 2.8567  Validation loss = 2.1291  \n",
      "\n",
      "Fold: 31  Epoch: 437  Training loss = 2.8566  Validation loss = 2.1285  \n",
      "\n",
      "Fold: 31  Epoch: 438  Training loss = 2.8564  Validation loss = 2.1281  \n",
      "\n",
      "Fold: 31  Epoch: 439  Training loss = 2.8563  Validation loss = 2.1276  \n",
      "\n",
      "Fold: 31  Epoch: 440  Training loss = 2.8562  Validation loss = 2.1276  \n",
      "\n",
      "Fold: 31  Epoch: 441  Training loss = 2.8561  Validation loss = 2.1278  \n",
      "\n",
      "Fold: 31  Epoch: 442  Training loss = 2.8559  Validation loss = 2.1267  \n",
      "\n",
      "Fold: 31  Epoch: 443  Training loss = 2.8558  Validation loss = 2.1263  \n",
      "\n",
      "Fold: 31  Epoch: 444  Training loss = 2.8555  Validation loss = 2.1246  \n",
      "\n",
      "Fold: 31  Epoch: 445  Training loss = 2.8553  Validation loss = 2.1237  \n",
      "\n",
      "Fold: 31  Epoch: 446  Training loss = 2.8551  Validation loss = 2.1224  \n",
      "\n",
      "Fold: 31  Epoch: 447  Training loss = 2.8549  Validation loss = 2.1208  \n",
      "\n",
      "Fold: 31  Epoch: 448  Training loss = 2.8549  Validation loss = 2.1214  \n",
      "\n",
      "Fold: 31  Epoch: 449  Training loss = 2.8547  Validation loss = 2.1207  \n",
      "\n",
      "Fold: 31  Epoch: 450  Training loss = 2.8545  Validation loss = 2.1195  \n",
      "\n",
      "Fold: 31  Epoch: 451  Training loss = 2.8543  Validation loss = 2.1194  \n",
      "\n",
      "Fold: 31  Epoch: 452  Training loss = 2.8542  Validation loss = 2.1198  \n",
      "\n",
      "Fold: 31  Epoch: 453  Training loss = 2.8541  Validation loss = 2.1191  \n",
      "\n",
      "Fold: 31  Epoch: 454  Training loss = 2.8540  Validation loss = 2.1187  \n",
      "\n",
      "Fold: 31  Epoch: 455  Training loss = 2.8538  Validation loss = 2.1182  \n",
      "\n",
      "Fold: 31  Epoch: 456  Training loss = 2.8536  Validation loss = 2.1180  \n",
      "\n",
      "Fold: 31  Epoch: 457  Training loss = 2.8534  Validation loss = 2.1171  \n",
      "\n",
      "Fold: 31  Epoch: 458  Training loss = 2.8533  Validation loss = 2.1157  \n",
      "\n",
      "Fold: 31  Epoch: 459  Training loss = 2.8531  Validation loss = 2.1140  \n",
      "\n",
      "Fold: 31  Epoch: 460  Training loss = 2.8529  Validation loss = 2.1133  \n",
      "\n",
      "Fold: 31  Epoch: 461  Training loss = 2.8527  Validation loss = 2.1123  \n",
      "\n",
      "Fold: 31  Epoch: 462  Training loss = 2.8526  Validation loss = 2.1124  \n",
      "\n",
      "Fold: 31  Epoch: 463  Training loss = 2.8525  Validation loss = 2.1119  \n",
      "\n",
      "Fold: 31  Epoch: 464  Training loss = 2.8523  Validation loss = 2.1108  \n",
      "\n",
      "Fold: 31  Epoch: 465  Training loss = 2.8522  Validation loss = 2.1112  \n",
      "\n",
      "Fold: 31  Epoch: 466  Training loss = 2.8521  Validation loss = 2.1113  \n",
      "\n",
      "Fold: 31  Epoch: 467  Training loss = 2.8519  Validation loss = 2.1096  \n",
      "\n",
      "Fold: 31  Epoch: 468  Training loss = 2.8518  Validation loss = 2.1095  \n",
      "\n",
      "Fold: 31  Epoch: 469  Training loss = 2.8516  Validation loss = 2.1088  \n",
      "\n",
      "Fold: 31  Epoch: 470  Training loss = 2.8515  Validation loss = 2.1078  \n",
      "\n",
      "Fold: 31  Epoch: 471  Training loss = 2.8513  Validation loss = 2.1072  \n",
      "\n",
      "Fold: 31  Epoch: 472  Training loss = 2.8511  Validation loss = 2.1062  \n",
      "\n",
      "Fold: 31  Epoch: 473  Training loss = 2.8510  Validation loss = 2.1056  \n",
      "\n",
      "Fold: 31  Epoch: 474  Training loss = 2.8509  Validation loss = 2.1054  \n",
      "\n",
      "Fold: 31  Epoch: 475  Training loss = 2.8507  Validation loss = 2.1050  \n",
      "\n",
      "Fold: 31  Epoch: 476  Training loss = 2.8506  Validation loss = 2.1038  \n",
      "\n",
      "Fold: 31  Epoch: 477  Training loss = 2.8504  Validation loss = 2.1028  \n",
      "\n",
      "Fold: 31  Epoch: 478  Training loss = 2.8503  Validation loss = 2.1020  \n",
      "\n",
      "Fold: 31  Epoch: 479  Training loss = 2.8500  Validation loss = 2.1001  \n",
      "\n",
      "Fold: 31  Epoch: 480  Training loss = 2.8499  Validation loss = 2.1001  \n",
      "\n",
      "Fold: 31  Epoch: 481  Training loss = 2.8498  Validation loss = 2.1010  \n",
      "\n",
      "Fold: 31  Epoch: 482  Training loss = 2.8497  Validation loss = 2.1012  \n",
      "\n",
      "Fold: 31  Epoch: 483  Training loss = 2.8495  Validation loss = 2.0994  \n",
      "\n",
      "Fold: 31  Epoch: 484  Training loss = 2.8494  Validation loss = 2.0992  \n",
      "\n",
      "Fold: 31  Epoch: 485  Training loss = 2.8492  Validation loss = 2.0985  \n",
      "\n",
      "Fold: 31  Epoch: 486  Training loss = 2.8491  Validation loss = 2.0982  \n",
      "\n",
      "Fold: 31  Epoch: 487  Training loss = 2.8490  Validation loss = 2.0986  \n",
      "\n",
      "Fold: 31  Epoch: 488  Training loss = 2.8489  Validation loss = 2.0979  \n",
      "\n",
      "Fold: 31  Epoch: 489  Training loss = 2.8487  Validation loss = 2.0971  \n",
      "\n",
      "Fold: 31  Epoch: 490  Training loss = 2.8486  Validation loss = 2.0966  \n",
      "\n",
      "Fold: 31  Epoch: 491  Training loss = 2.8485  Validation loss = 2.0965  \n",
      "\n",
      "Fold: 31  Epoch: 492  Training loss = 2.8483  Validation loss = 2.0954  \n",
      "\n",
      "Fold: 31  Epoch: 493  Training loss = 2.8482  Validation loss = 2.0944  \n",
      "\n",
      "Fold: 31  Epoch: 494  Training loss = 2.8480  Validation loss = 2.0941  \n",
      "\n",
      "Fold: 31  Epoch: 495  Training loss = 2.8479  Validation loss = 2.0935  \n",
      "\n",
      "Fold: 31  Epoch: 496  Training loss = 2.8478  Validation loss = 2.0935  \n",
      "\n",
      "Fold: 31  Epoch: 497  Training loss = 2.8477  Validation loss = 2.0940  \n",
      "\n",
      "Fold: 31  Epoch: 498  Training loss = 2.8476  Validation loss = 2.0941  \n",
      "\n",
      "Fold: 31  Epoch: 499  Training loss = 2.8474  Validation loss = 2.0935  \n",
      "\n",
      "Fold: 31  Epoch: 500  Training loss = 2.8473  Validation loss = 2.0932  \n",
      "\n",
      "Check model:  Fold: 31  Epoch: 500  Training loss = 2.8473  Validation loss = 2.0932  \n",
      "\n",
      "Fold: 32  Epoch: 1  Training loss = 2.3436  Validation loss = 3.3088  \n",
      "\n",
      "Fold: 32  Epoch: 2  Training loss = 2.3432  Validation loss = 3.3078  \n",
      "\n",
      "Fold: 32  Epoch: 3  Training loss = 2.3429  Validation loss = 3.3067  \n",
      "\n",
      "Fold: 32  Epoch: 4  Training loss = 2.3425  Validation loss = 3.3059  \n",
      "\n",
      "Fold: 32  Epoch: 5  Training loss = 2.3423  Validation loss = 3.3054  \n",
      "\n",
      "Fold: 32  Epoch: 6  Training loss = 2.3419  Validation loss = 3.3047  \n",
      "\n",
      "Fold: 32  Epoch: 7  Training loss = 2.3416  Validation loss = 3.3040  \n",
      "\n",
      "Fold: 32  Epoch: 8  Training loss = 2.3413  Validation loss = 3.3033  \n",
      "\n",
      "Fold: 32  Epoch: 9  Training loss = 2.3411  Validation loss = 3.3032  \n",
      "\n",
      "Fold: 32  Epoch: 10  Training loss = 2.3409  Validation loss = 3.3027  \n",
      "\n",
      "Fold: 32  Epoch: 11  Training loss = 2.3406  Validation loss = 3.3021  \n",
      "\n",
      "Fold: 32  Epoch: 12  Training loss = 2.3402  Validation loss = 3.3010  \n",
      "\n",
      "Fold: 32  Epoch: 13  Training loss = 2.3399  Validation loss = 3.3000  \n",
      "\n",
      "Fold: 32  Epoch: 14  Training loss = 2.3395  Validation loss = 3.2992  \n",
      "\n",
      "Fold: 32  Epoch: 15  Training loss = 2.3392  Validation loss = 3.2984  \n",
      "\n",
      "Fold: 32  Epoch: 16  Training loss = 2.3389  Validation loss = 3.2980  \n",
      "\n",
      "Fold: 32  Epoch: 17  Training loss = 2.3386  Validation loss = 3.2974  \n",
      "\n",
      "Fold: 32  Epoch: 18  Training loss = 2.3384  Validation loss = 3.2969  \n",
      "\n",
      "Fold: 32  Epoch: 19  Training loss = 2.3382  Validation loss = 3.2967  \n",
      "\n",
      "Fold: 32  Epoch: 20  Training loss = 2.3380  Validation loss = 3.2967  \n",
      "\n",
      "Fold: 32  Epoch: 21  Training loss = 2.3378  Validation loss = 3.2963  \n",
      "\n",
      "Fold: 32  Epoch: 22  Training loss = 2.3375  Validation loss = 3.2959  \n",
      "\n",
      "Fold: 32  Epoch: 23  Training loss = 2.3372  Validation loss = 3.2951  \n",
      "\n",
      "Fold: 32  Epoch: 24  Training loss = 2.3368  Validation loss = 3.2940  \n",
      "\n",
      "Fold: 32  Epoch: 25  Training loss = 2.3365  Validation loss = 3.2935  \n",
      "\n",
      "Fold: 32  Epoch: 26  Training loss = 2.3362  Validation loss = 3.2923  \n",
      "\n",
      "Fold: 32  Epoch: 27  Training loss = 2.3360  Validation loss = 3.2924  \n",
      "\n",
      "Fold: 32  Epoch: 28  Training loss = 2.3358  Validation loss = 3.2921  \n",
      "\n",
      "Fold: 32  Epoch: 29  Training loss = 2.3355  Validation loss = 3.2914  \n",
      "\n",
      "Fold: 32  Epoch: 30  Training loss = 2.3353  Validation loss = 3.2911  \n",
      "\n",
      "Fold: 32  Epoch: 31  Training loss = 2.3349  Validation loss = 3.2901  \n",
      "\n",
      "Fold: 32  Epoch: 32  Training loss = 2.3345  Validation loss = 3.2888  \n",
      "\n",
      "Fold: 32  Epoch: 33  Training loss = 2.3342  Validation loss = 3.2886  \n",
      "\n",
      "Fold: 32  Epoch: 34  Training loss = 2.3339  Validation loss = 3.2877  \n",
      "\n",
      "Fold: 32  Epoch: 35  Training loss = 2.3336  Validation loss = 3.2872  \n",
      "\n",
      "Fold: 32  Epoch: 36  Training loss = 2.3333  Validation loss = 3.2864  \n",
      "\n",
      "Fold: 32  Epoch: 37  Training loss = 2.3331  Validation loss = 3.2857  \n",
      "\n",
      "Fold: 32  Epoch: 38  Training loss = 2.3330  Validation loss = 3.2857  \n",
      "\n",
      "Fold: 32  Epoch: 39  Training loss = 2.3327  Validation loss = 3.2856  \n",
      "\n",
      "Fold: 32  Epoch: 40  Training loss = 2.3325  Validation loss = 3.2850  \n",
      "\n",
      "Fold: 32  Epoch: 41  Training loss = 2.3322  Validation loss = 3.2844  \n",
      "\n",
      "Fold: 32  Epoch: 42  Training loss = 2.3318  Validation loss = 3.2831  \n",
      "\n",
      "Fold: 32  Epoch: 43  Training loss = 2.3316  Validation loss = 3.2828  \n",
      "\n",
      "Fold: 32  Epoch: 44  Training loss = 2.3315  Validation loss = 3.2824  \n",
      "\n",
      "Fold: 32  Epoch: 45  Training loss = 2.3313  Validation loss = 3.2821  \n",
      "\n",
      "Fold: 32  Epoch: 46  Training loss = 2.3309  Validation loss = 3.2811  \n",
      "\n",
      "Fold: 32  Epoch: 47  Training loss = 2.3307  Validation loss = 3.2808  \n",
      "\n",
      "Fold: 32  Epoch: 48  Training loss = 2.3304  Validation loss = 3.2799  \n",
      "\n",
      "Fold: 32  Epoch: 49  Training loss = 2.3301  Validation loss = 3.2797  \n",
      "\n",
      "Fold: 32  Epoch: 50  Training loss = 2.3298  Validation loss = 3.2784  \n",
      "\n",
      "Fold: 32  Epoch: 51  Training loss = 2.3294  Validation loss = 3.2775  \n",
      "\n",
      "Fold: 32  Epoch: 52  Training loss = 2.3290  Validation loss = 3.2763  \n",
      "\n",
      "Fold: 32  Epoch: 53  Training loss = 2.3287  Validation loss = 3.2754  \n",
      "\n",
      "Fold: 32  Epoch: 54  Training loss = 2.3284  Validation loss = 3.2743  \n",
      "\n",
      "Fold: 32  Epoch: 55  Training loss = 2.3281  Validation loss = 3.2736  \n",
      "\n",
      "Fold: 32  Epoch: 56  Training loss = 2.3277  Validation loss = 3.2726  \n",
      "\n",
      "Fold: 32  Epoch: 57  Training loss = 2.3274  Validation loss = 3.2719  \n",
      "\n",
      "Fold: 32  Epoch: 58  Training loss = 2.3273  Validation loss = 3.2715  \n",
      "\n",
      "Fold: 32  Epoch: 59  Training loss = 2.3272  Validation loss = 3.2721  \n",
      "\n",
      "Fold: 32  Epoch: 60  Training loss = 2.3269  Validation loss = 3.2714  \n",
      "\n",
      "Fold: 32  Epoch: 61  Training loss = 2.3267  Validation loss = 3.2708  \n",
      "\n",
      "Fold: 32  Epoch: 62  Training loss = 2.3266  Validation loss = 3.2706  \n",
      "\n",
      "Fold: 32  Epoch: 63  Training loss = 2.3264  Validation loss = 3.2703  \n",
      "\n",
      "Fold: 32  Epoch: 64  Training loss = 2.3261  Validation loss = 3.2696  \n",
      "\n",
      "Fold: 32  Epoch: 65  Training loss = 2.3259  Validation loss = 3.2691  \n",
      "\n",
      "Fold: 32  Epoch: 66  Training loss = 2.3256  Validation loss = 3.2683  \n",
      "\n",
      "Fold: 32  Epoch: 67  Training loss = 2.3254  Validation loss = 3.2681  \n",
      "\n",
      "Fold: 32  Epoch: 68  Training loss = 2.3250  Validation loss = 3.2670  \n",
      "\n",
      "Fold: 32  Epoch: 69  Training loss = 2.3248  Validation loss = 3.2662  \n",
      "\n",
      "Fold: 32  Epoch: 70  Training loss = 2.3245  Validation loss = 3.2656  \n",
      "\n",
      "Fold: 32  Epoch: 71  Training loss = 2.3242  Validation loss = 3.2650  \n",
      "\n",
      "Fold: 32  Epoch: 72  Training loss = 2.3240  Validation loss = 3.2645  \n",
      "\n",
      "Fold: 32  Epoch: 73  Training loss = 2.3238  Validation loss = 3.2637  \n",
      "\n",
      "Fold: 32  Epoch: 74  Training loss = 2.3237  Validation loss = 3.2636  \n",
      "\n",
      "Fold: 32  Epoch: 75  Training loss = 2.3235  Validation loss = 3.2633  \n",
      "\n",
      "Fold: 32  Epoch: 76  Training loss = 2.3233  Validation loss = 3.2632  \n",
      "\n",
      "Fold: 32  Epoch: 77  Training loss = 2.3230  Validation loss = 3.2622  \n",
      "\n",
      "Fold: 32  Epoch: 78  Training loss = 2.3229  Validation loss = 3.2620  \n",
      "\n",
      "Fold: 32  Epoch: 79  Training loss = 2.3225  Validation loss = 3.2608  \n",
      "\n",
      "Fold: 32  Epoch: 80  Training loss = 2.3222  Validation loss = 3.2598  \n",
      "\n",
      "Fold: 32  Epoch: 81  Training loss = 2.3219  Validation loss = 3.2592  \n",
      "\n",
      "Fold: 32  Epoch: 82  Training loss = 2.3216  Validation loss = 3.2583  \n",
      "\n",
      "Fold: 32  Epoch: 83  Training loss = 2.3213  Validation loss = 3.2575  \n",
      "\n",
      "Fold: 32  Epoch: 84  Training loss = 2.3212  Validation loss = 3.2575  \n",
      "\n",
      "Fold: 32  Epoch: 85  Training loss = 2.3211  Validation loss = 3.2574  \n",
      "\n",
      "Fold: 32  Epoch: 86  Training loss = 2.3207  Validation loss = 3.2562  \n",
      "\n",
      "Fold: 32  Epoch: 87  Training loss = 2.3205  Validation loss = 3.2554  \n",
      "\n",
      "Fold: 32  Epoch: 88  Training loss = 2.3202  Validation loss = 3.2547  \n",
      "\n",
      "Fold: 32  Epoch: 89  Training loss = 2.3199  Validation loss = 3.2537  \n",
      "\n",
      "Fold: 32  Epoch: 90  Training loss = 2.3197  Validation loss = 3.2530  \n",
      "\n",
      "Fold: 32  Epoch: 91  Training loss = 2.3195  Validation loss = 3.2529  \n",
      "\n",
      "Fold: 32  Epoch: 92  Training loss = 2.3194  Validation loss = 3.2531  \n",
      "\n",
      "Fold: 32  Epoch: 93  Training loss = 2.3192  Validation loss = 3.2526  \n",
      "\n",
      "Fold: 32  Epoch: 94  Training loss = 2.3190  Validation loss = 3.2519  \n",
      "\n",
      "Fold: 32  Epoch: 95  Training loss = 2.3188  Validation loss = 3.2519  \n",
      "\n",
      "Fold: 32  Epoch: 96  Training loss = 2.3186  Validation loss = 3.2513  \n",
      "\n",
      "Fold: 32  Epoch: 97  Training loss = 2.3185  Validation loss = 3.2514  \n",
      "\n",
      "Fold: 32  Epoch: 98  Training loss = 2.3182  Validation loss = 3.2506  \n",
      "\n",
      "Fold: 32  Epoch: 99  Training loss = 2.3180  Validation loss = 3.2507  \n",
      "\n",
      "Fold: 32  Epoch: 100  Training loss = 2.3177  Validation loss = 3.2494  \n",
      "\n",
      "Fold: 32  Epoch: 101  Training loss = 2.3176  Validation loss = 3.2493  \n",
      "\n",
      "Fold: 32  Epoch: 102  Training loss = 2.3173  Validation loss = 3.2483  \n",
      "\n",
      "Fold: 32  Epoch: 103  Training loss = 2.3171  Validation loss = 3.2481  \n",
      "\n",
      "Fold: 32  Epoch: 104  Training loss = 2.3168  Validation loss = 3.2472  \n",
      "\n",
      "Fold: 32  Epoch: 105  Training loss = 2.3163  Validation loss = 3.2456  \n",
      "\n",
      "Fold: 32  Epoch: 106  Training loss = 2.3162  Validation loss = 3.2448  \n",
      "\n",
      "Fold: 32  Epoch: 107  Training loss = 2.3160  Validation loss = 3.2445  \n",
      "\n",
      "Fold: 32  Epoch: 108  Training loss = 2.3157  Validation loss = 3.2434  \n",
      "\n",
      "Fold: 32  Epoch: 109  Training loss = 2.3155  Validation loss = 3.2435  \n",
      "\n",
      "Fold: 32  Epoch: 110  Training loss = 2.3152  Validation loss = 3.2424  \n",
      "\n",
      "Fold: 32  Epoch: 111  Training loss = 2.3149  Validation loss = 3.2415  \n",
      "\n",
      "Fold: 32  Epoch: 112  Training loss = 2.3147  Validation loss = 3.2407  \n",
      "\n",
      "Fold: 32  Epoch: 113  Training loss = 2.3144  Validation loss = 3.2395  \n",
      "\n",
      "Fold: 32  Epoch: 114  Training loss = 2.3143  Validation loss = 3.2401  \n",
      "\n",
      "Fold: 32  Epoch: 115  Training loss = 2.3141  Validation loss = 3.2397  \n",
      "\n",
      "Fold: 32  Epoch: 116  Training loss = 2.3140  Validation loss = 3.2401  \n",
      "\n",
      "Fold: 32  Epoch: 117  Training loss = 2.3137  Validation loss = 3.2392  \n",
      "\n",
      "Fold: 32  Epoch: 118  Training loss = 2.3135  Validation loss = 3.2398  \n",
      "\n",
      "Fold: 32  Epoch: 119  Training loss = 2.3133  Validation loss = 3.2394  \n",
      "\n",
      "Fold: 32  Epoch: 120  Training loss = 2.3131  Validation loss = 3.2390  \n",
      "\n",
      "Fold: 32  Epoch: 121  Training loss = 2.3128  Validation loss = 3.2376  \n",
      "\n",
      "Fold: 32  Epoch: 122  Training loss = 2.3126  Validation loss = 3.2376  \n",
      "\n",
      "Fold: 32  Epoch: 123  Training loss = 2.3124  Validation loss = 3.2369  \n",
      "\n",
      "Fold: 32  Epoch: 124  Training loss = 2.3121  Validation loss = 3.2358  \n",
      "\n",
      "Fold: 32  Epoch: 125  Training loss = 2.3119  Validation loss = 3.2356  \n",
      "\n",
      "Fold: 32  Epoch: 126  Training loss = 2.3116  Validation loss = 3.2348  \n",
      "\n",
      "Fold: 32  Epoch: 127  Training loss = 2.3114  Validation loss = 3.2343  \n",
      "\n",
      "Fold: 32  Epoch: 128  Training loss = 2.3112  Validation loss = 3.2340  \n",
      "\n",
      "Fold: 32  Epoch: 129  Training loss = 2.3109  Validation loss = 3.2332  \n",
      "\n",
      "Fold: 32  Epoch: 130  Training loss = 2.3107  Validation loss = 3.2329  \n",
      "\n",
      "Fold: 32  Epoch: 131  Training loss = 2.3104  Validation loss = 3.2321  \n",
      "\n",
      "Fold: 32  Epoch: 132  Training loss = 2.3101  Validation loss = 3.2313  \n",
      "\n",
      "Fold: 32  Epoch: 133  Training loss = 2.3100  Validation loss = 3.2315  \n",
      "\n",
      "Fold: 32  Epoch: 134  Training loss = 2.3099  Validation loss = 3.2314  \n",
      "\n",
      "Fold: 32  Epoch: 135  Training loss = 2.3096  Validation loss = 3.2304  \n",
      "\n",
      "Fold: 32  Epoch: 136  Training loss = 2.3094  Validation loss = 3.2297  \n",
      "\n",
      "Fold: 32  Epoch: 137  Training loss = 2.3092  Validation loss = 3.2294  \n",
      "\n",
      "Fold: 32  Epoch: 138  Training loss = 2.3090  Validation loss = 3.2288  \n",
      "\n",
      "Fold: 32  Epoch: 139  Training loss = 2.3088  Validation loss = 3.2282  \n",
      "\n",
      "Fold: 32  Epoch: 140  Training loss = 2.3087  Validation loss = 3.2285  \n",
      "\n",
      "Fold: 32  Epoch: 141  Training loss = 2.3084  Validation loss = 3.2275  \n",
      "\n",
      "Fold: 32  Epoch: 142  Training loss = 2.3083  Validation loss = 3.2276  \n",
      "\n",
      "Fold: 32  Epoch: 143  Training loss = 2.3081  Validation loss = 3.2274  \n",
      "\n",
      "Fold: 32  Epoch: 144  Training loss = 2.3078  Validation loss = 3.2264  \n",
      "\n",
      "Fold: 32  Epoch: 145  Training loss = 2.3077  Validation loss = 3.2264  \n",
      "\n",
      "Fold: 32  Epoch: 146  Training loss = 2.3075  Validation loss = 3.2265  \n",
      "\n",
      "Fold: 32  Epoch: 147  Training loss = 2.3073  Validation loss = 3.2260  \n",
      "\n",
      "Fold: 32  Epoch: 148  Training loss = 2.3071  Validation loss = 3.2259  \n",
      "\n",
      "Fold: 32  Epoch: 149  Training loss = 2.3068  Validation loss = 3.2248  \n",
      "\n",
      "Fold: 32  Epoch: 150  Training loss = 2.3066  Validation loss = 3.2243  \n",
      "\n",
      "Fold: 32  Epoch: 151  Training loss = 2.3064  Validation loss = 3.2240  \n",
      "\n",
      "Fold: 32  Epoch: 152  Training loss = 2.3062  Validation loss = 3.2240  \n",
      "\n",
      "Fold: 32  Epoch: 153  Training loss = 2.3059  Validation loss = 3.2232  \n",
      "\n",
      "Fold: 32  Epoch: 154  Training loss = 2.3057  Validation loss = 3.2229  \n",
      "\n",
      "Fold: 32  Epoch: 155  Training loss = 2.3054  Validation loss = 3.2218  \n",
      "\n",
      "Fold: 32  Epoch: 156  Training loss = 2.3051  Validation loss = 3.2209  \n",
      "\n",
      "Fold: 32  Epoch: 157  Training loss = 2.3049  Validation loss = 3.2211  \n",
      "\n",
      "Fold: 32  Epoch: 158  Training loss = 2.3049  Validation loss = 3.2212  \n",
      "\n",
      "Fold: 32  Epoch: 159  Training loss = 2.3044  Validation loss = 3.2203  \n",
      "\n",
      "Fold: 32  Epoch: 160  Training loss = 2.3041  Validation loss = 3.2197  \n",
      "\n",
      "Fold: 32  Epoch: 161  Training loss = 2.3038  Validation loss = 3.2194  \n",
      "\n",
      "Fold: 32  Epoch: 162  Training loss = 2.3035  Validation loss = 3.2185  \n",
      "\n",
      "Fold: 32  Epoch: 163  Training loss = 2.3032  Validation loss = 3.2180  \n",
      "\n",
      "Fold: 32  Epoch: 164  Training loss = 2.3030  Validation loss = 3.2183  \n",
      "\n",
      "Fold: 32  Epoch: 165  Training loss = 2.3027  Validation loss = 3.2180  \n",
      "\n",
      "Fold: 32  Epoch: 166  Training loss = 2.3024  Validation loss = 3.2173  \n",
      "\n",
      "Fold: 32  Epoch: 167  Training loss = 2.3016  Validation loss = 3.2166  \n",
      "\n",
      "Fold: 32  Epoch: 168  Training loss = 2.3014  Validation loss = 3.2165  \n",
      "\n",
      "Fold: 32  Epoch: 169  Training loss = 2.3008  Validation loss = 3.2165  \n",
      "\n",
      "Fold: 32  Epoch: 170  Training loss = 2.3005  Validation loss = 3.2149  \n",
      "\n",
      "Fold: 32  Epoch: 171  Training loss = 2.2998  Validation loss = 3.2141  \n",
      "\n",
      "Fold: 32  Epoch: 172  Training loss = 2.2990  Validation loss = 3.2126  \n",
      "\n",
      "Fold: 32  Epoch: 173  Training loss = 2.2979  Validation loss = 3.2114  \n",
      "\n",
      "Fold: 32  Epoch: 174  Training loss = 2.2973  Validation loss = 3.2105  \n",
      "\n",
      "Fold: 32  Epoch: 175  Training loss = 2.2967  Validation loss = 3.2093  \n",
      "\n",
      "Fold: 32  Epoch: 176  Training loss = 2.2961  Validation loss = 3.2091  \n",
      "\n",
      "Fold: 32  Epoch: 177  Training loss = 2.2958  Validation loss = 3.2090  \n",
      "\n",
      "Fold: 32  Epoch: 178  Training loss = 2.2947  Validation loss = 3.2079  \n",
      "\n",
      "Fold: 32  Epoch: 179  Training loss = 2.2935  Validation loss = 3.2060  \n",
      "\n",
      "Fold: 32  Epoch: 180  Training loss = 2.2933  Validation loss = 3.2056  \n",
      "\n",
      "Fold: 32  Epoch: 181  Training loss = 2.2927  Validation loss = 3.2044  \n",
      "\n",
      "Fold: 32  Epoch: 182  Training loss = 2.2920  Validation loss = 3.2040  \n",
      "\n",
      "Fold: 32  Epoch: 183  Training loss = 2.2913  Validation loss = 3.2027  \n",
      "\n",
      "Fold: 32  Epoch: 184  Training loss = 2.2910  Validation loss = 3.2026  \n",
      "\n",
      "Fold: 32  Epoch: 185  Training loss = 2.2903  Validation loss = 3.2016  \n",
      "\n",
      "Fold: 32  Epoch: 186  Training loss = 2.2898  Validation loss = 3.2010  \n",
      "\n",
      "Fold: 32  Epoch: 187  Training loss = 2.2894  Validation loss = 3.1998  \n",
      "\n",
      "Fold: 32  Epoch: 188  Training loss = 2.2889  Validation loss = 3.1980  \n",
      "\n",
      "Fold: 32  Epoch: 189  Training loss = 2.2886  Validation loss = 3.1979  \n",
      "\n",
      "Fold: 32  Epoch: 190  Training loss = 2.2882  Validation loss = 3.1963  \n",
      "\n",
      "Fold: 32  Epoch: 191  Training loss = 2.2879  Validation loss = 3.1956  \n",
      "\n",
      "Fold: 32  Epoch: 192  Training loss = 2.2875  Validation loss = 3.1943  \n",
      "\n",
      "Fold: 32  Epoch: 193  Training loss = 2.2873  Validation loss = 3.1946  \n",
      "\n",
      "Fold: 32  Epoch: 194  Training loss = 2.2873  Validation loss = 3.1960  \n",
      "\n",
      "Fold: 32  Epoch: 195  Training loss = 2.2869  Validation loss = 3.1949  \n",
      "\n",
      "Fold: 32  Epoch: 196  Training loss = 2.2869  Validation loss = 3.1957  \n",
      "\n",
      "Fold: 32  Epoch: 197  Training loss = 2.2866  Validation loss = 3.1948  \n",
      "\n",
      "Fold: 32  Epoch: 198  Training loss = 2.2865  Validation loss = 3.1950  \n",
      "\n",
      "Fold: 32  Epoch: 199  Training loss = 2.2862  Validation loss = 3.1946  \n",
      "\n",
      "Fold: 32  Epoch: 200  Training loss = 2.2859  Validation loss = 3.1944  \n",
      "\n",
      "Fold: 32  Epoch: 201  Training loss = 2.2856  Validation loss = 3.1939  \n",
      "\n",
      "Fold: 32  Epoch: 202  Training loss = 2.2852  Validation loss = 3.1930  \n",
      "\n",
      "Fold: 32  Epoch: 203  Training loss = 2.2849  Validation loss = 3.1919  \n",
      "\n",
      "Fold: 32  Epoch: 204  Training loss = 2.2846  Validation loss = 3.1914  \n",
      "\n",
      "Fold: 32  Epoch: 205  Training loss = 2.2844  Validation loss = 3.1908  \n",
      "\n",
      "Fold: 32  Epoch: 206  Training loss = 2.2842  Validation loss = 3.1907  \n",
      "\n",
      "Fold: 32  Epoch: 207  Training loss = 2.2839  Validation loss = 3.1902  \n",
      "\n",
      "Fold: 32  Epoch: 208  Training loss = 2.2839  Validation loss = 3.1915  \n",
      "\n",
      "Fold: 32  Epoch: 209  Training loss = 2.2838  Validation loss = 3.1926  \n",
      "\n",
      "Fold: 32  Epoch: 210  Training loss = 2.2834  Validation loss = 3.1913  \n",
      "\n",
      "Fold: 32  Epoch: 211  Training loss = 2.2831  Validation loss = 3.1904  \n",
      "\n",
      "Fold: 32  Epoch: 212  Training loss = 2.2829  Validation loss = 3.1905  \n",
      "\n",
      "Fold: 32  Epoch: 213  Training loss = 2.2826  Validation loss = 3.1890  \n",
      "\n",
      "Fold: 32  Epoch: 214  Training loss = 2.2824  Validation loss = 3.1884  \n",
      "\n",
      "Fold: 32  Epoch: 215  Training loss = 2.2820  Validation loss = 3.1866  \n",
      "\n",
      "Fold: 32  Epoch: 216  Training loss = 2.2817  Validation loss = 3.1862  \n",
      "\n",
      "Fold: 32  Epoch: 217  Training loss = 2.2815  Validation loss = 3.1855  \n",
      "\n",
      "Fold: 32  Epoch: 218  Training loss = 2.2812  Validation loss = 3.1841  \n",
      "\n",
      "Fold: 32  Epoch: 219  Training loss = 2.2810  Validation loss = 3.1835  \n",
      "\n",
      "Fold: 32  Epoch: 220  Training loss = 2.2809  Validation loss = 3.1843  \n",
      "\n",
      "Fold: 32  Epoch: 221  Training loss = 2.2806  Validation loss = 3.1832  \n",
      "\n",
      "Fold: 32  Epoch: 222  Training loss = 2.2805  Validation loss = 3.1833  \n",
      "\n",
      "Fold: 32  Epoch: 223  Training loss = 2.2803  Validation loss = 3.1824  \n",
      "\n",
      "Fold: 32  Epoch: 224  Training loss = 2.2801  Validation loss = 3.1823  \n",
      "\n",
      "Fold: 32  Epoch: 225  Training loss = 2.2799  Validation loss = 3.1824  \n",
      "\n",
      "Fold: 32  Epoch: 226  Training loss = 2.2798  Validation loss = 3.1821  \n",
      "\n",
      "Fold: 32  Epoch: 227  Training loss = 2.2796  Validation loss = 3.1821  \n",
      "\n",
      "Fold: 32  Epoch: 228  Training loss = 2.2794  Validation loss = 3.1819  \n",
      "\n",
      "Fold: 32  Epoch: 229  Training loss = 2.2792  Validation loss = 3.1819  \n",
      "\n",
      "Fold: 32  Epoch: 230  Training loss = 2.2790  Validation loss = 3.1812  \n",
      "\n",
      "Fold: 32  Epoch: 231  Training loss = 2.2787  Validation loss = 3.1805  \n",
      "\n",
      "Fold: 32  Epoch: 232  Training loss = 2.2784  Validation loss = 3.1796  \n",
      "\n",
      "Fold: 32  Epoch: 233  Training loss = 2.2783  Validation loss = 3.1796  \n",
      "\n",
      "Fold: 32  Epoch: 234  Training loss = 2.2781  Validation loss = 3.1784  \n",
      "\n",
      "Fold: 32  Epoch: 235  Training loss = 2.2778  Validation loss = 3.1778  \n",
      "\n",
      "Fold: 32  Epoch: 236  Training loss = 2.2777  Validation loss = 3.1783  \n",
      "\n",
      "Fold: 32  Epoch: 237  Training loss = 2.2776  Validation loss = 3.1785  \n",
      "\n",
      "Fold: 32  Epoch: 238  Training loss = 2.2773  Validation loss = 3.1775  \n",
      "\n",
      "Fold: 32  Epoch: 239  Training loss = 2.2771  Validation loss = 3.1766  \n",
      "\n",
      "Fold: 32  Epoch: 240  Training loss = 2.2769  Validation loss = 3.1754  \n",
      "\n",
      "Fold: 32  Epoch: 241  Training loss = 2.2768  Validation loss = 3.1753  \n",
      "\n",
      "Fold: 32  Epoch: 242  Training loss = 2.2766  Validation loss = 3.1743  \n",
      "\n",
      "Fold: 32  Epoch: 243  Training loss = 2.2764  Validation loss = 3.1735  \n",
      "\n",
      "Fold: 32  Epoch: 244  Training loss = 2.2762  Validation loss = 3.1732  \n",
      "\n",
      "Fold: 32  Epoch: 245  Training loss = 2.2761  Validation loss = 3.1733  \n",
      "\n",
      "Fold: 32  Epoch: 246  Training loss = 2.2759  Validation loss = 3.1723  \n",
      "\n",
      "Fold: 32  Epoch: 247  Training loss = 2.2758  Validation loss = 3.1712  \n",
      "\n",
      "Fold: 32  Epoch: 248  Training loss = 2.2755  Validation loss = 3.1700  \n",
      "\n",
      "Fold: 32  Epoch: 249  Training loss = 2.2753  Validation loss = 3.1686  \n",
      "\n",
      "Fold: 32  Epoch: 250  Training loss = 2.2753  Validation loss = 3.1691  \n",
      "\n",
      "Fold: 32  Epoch: 251  Training loss = 2.2751  Validation loss = 3.1680  \n",
      "\n",
      "Fold: 32  Epoch: 252  Training loss = 2.2748  Validation loss = 3.1671  \n",
      "\n",
      "Fold: 32  Epoch: 253  Training loss = 2.2747  Validation loss = 3.1676  \n",
      "\n",
      "Fold: 32  Epoch: 254  Training loss = 2.2746  Validation loss = 3.1676  \n",
      "\n",
      "Fold: 32  Epoch: 255  Training loss = 2.2745  Validation loss = 3.1684  \n",
      "\n",
      "Fold: 32  Epoch: 256  Training loss = 2.2744  Validation loss = 3.1683  \n",
      "\n",
      "Fold: 32  Epoch: 257  Training loss = 2.2742  Validation loss = 3.1671  \n",
      "\n",
      "Fold: 32  Epoch: 258  Training loss = 2.2740  Validation loss = 3.1680  \n",
      "\n",
      "Fold: 32  Epoch: 259  Training loss = 2.2738  Validation loss = 3.1668  \n",
      "\n",
      "Fold: 32  Epoch: 260  Training loss = 2.2736  Validation loss = 3.1672  \n",
      "\n",
      "Fold: 32  Epoch: 261  Training loss = 2.2735  Validation loss = 3.1667  \n",
      "\n",
      "Fold: 32  Epoch: 262  Training loss = 2.2732  Validation loss = 3.1657  \n",
      "\n",
      "Fold: 32  Epoch: 263  Training loss = 2.2730  Validation loss = 3.1647  \n",
      "\n",
      "Fold: 32  Epoch: 264  Training loss = 2.2727  Validation loss = 3.1621  \n",
      "\n",
      "Fold: 32  Epoch: 265  Training loss = 2.2725  Validation loss = 3.1611  \n",
      "\n",
      "Fold: 32  Epoch: 266  Training loss = 2.2724  Validation loss = 3.1611  \n",
      "\n",
      "Fold: 32  Epoch: 267  Training loss = 2.2721  Validation loss = 3.1602  \n",
      "\n",
      "Fold: 32  Epoch: 268  Training loss = 2.2719  Validation loss = 3.1596  \n",
      "\n",
      "Fold: 32  Epoch: 269  Training loss = 2.2718  Validation loss = 3.1591  \n",
      "\n",
      "Fold: 32  Epoch: 270  Training loss = 2.2716  Validation loss = 3.1592  \n",
      "\n",
      "Fold: 32  Epoch: 271  Training loss = 2.2715  Validation loss = 3.1586  \n",
      "\n",
      "Fold: 32  Epoch: 272  Training loss = 2.2713  Validation loss = 3.1582  \n",
      "\n",
      "Fold: 32  Epoch: 273  Training loss = 2.2712  Validation loss = 3.1587  \n",
      "\n",
      "Fold: 32  Epoch: 274  Training loss = 2.2711  Validation loss = 3.1594  \n",
      "\n",
      "Fold: 32  Epoch: 275  Training loss = 2.2709  Validation loss = 3.1584  \n",
      "\n",
      "Fold: 32  Epoch: 276  Training loss = 2.2707  Validation loss = 3.1577  \n",
      "\n",
      "Fold: 32  Epoch: 277  Training loss = 2.2705  Validation loss = 3.1569  \n",
      "\n",
      "Fold: 32  Epoch: 278  Training loss = 2.2702  Validation loss = 3.1565  \n",
      "\n",
      "Fold: 32  Epoch: 279  Training loss = 2.2701  Validation loss = 3.1557  \n",
      "\n",
      "Fold: 32  Epoch: 280  Training loss = 2.2699  Validation loss = 3.1547  \n",
      "\n",
      "Fold: 32  Epoch: 281  Training loss = 2.2697  Validation loss = 3.1533  \n",
      "\n",
      "Fold: 32  Epoch: 282  Training loss = 2.2695  Validation loss = 3.1522  \n",
      "\n",
      "Fold: 32  Epoch: 283  Training loss = 2.2693  Validation loss = 3.1514  \n",
      "\n",
      "Fold: 32  Epoch: 284  Training loss = 2.2691  Validation loss = 3.1507  \n",
      "\n",
      "Fold: 32  Epoch: 285  Training loss = 2.2690  Validation loss = 3.1502  \n",
      "\n",
      "Fold: 32  Epoch: 286  Training loss = 2.2689  Validation loss = 3.1513  \n",
      "\n",
      "Fold: 32  Epoch: 287  Training loss = 2.2688  Validation loss = 3.1511  \n",
      "\n",
      "Fold: 32  Epoch: 288  Training loss = 2.2686  Validation loss = 3.1513  \n",
      "\n",
      "Fold: 32  Epoch: 289  Training loss = 2.2684  Validation loss = 3.1504  \n",
      "\n",
      "Fold: 32  Epoch: 290  Training loss = 2.2682  Validation loss = 3.1503  \n",
      "\n",
      "Fold: 32  Epoch: 291  Training loss = 2.2681  Validation loss = 3.1501  \n",
      "\n",
      "Fold: 32  Epoch: 292  Training loss = 2.2679  Validation loss = 3.1497  \n",
      "\n",
      "Fold: 32  Epoch: 293  Training loss = 2.2676  Validation loss = 3.1481  \n",
      "\n",
      "Fold: 32  Epoch: 294  Training loss = 2.2674  Validation loss = 3.1478  \n",
      "\n",
      "Fold: 32  Epoch: 295  Training loss = 2.2673  Validation loss = 3.1479  \n",
      "\n",
      "Fold: 32  Epoch: 296  Training loss = 2.2672  Validation loss = 3.1482  \n",
      "\n",
      "Fold: 32  Epoch: 297  Training loss = 2.2670  Validation loss = 3.1487  \n",
      "\n",
      "Fold: 32  Epoch: 298  Training loss = 2.2668  Validation loss = 3.1486  \n",
      "\n",
      "Fold: 32  Epoch: 299  Training loss = 2.2666  Validation loss = 3.1478  \n",
      "\n",
      "Fold: 32  Epoch: 300  Training loss = 2.2665  Validation loss = 3.1490  \n",
      "\n",
      "Fold: 32  Epoch: 301  Training loss = 2.2663  Validation loss = 3.1484  \n",
      "\n",
      "Fold: 32  Epoch: 302  Training loss = 2.2662  Validation loss = 3.1484  \n",
      "\n",
      "Fold: 32  Epoch: 303  Training loss = 2.2660  Validation loss = 3.1485  \n",
      "\n",
      "Fold: 32  Epoch: 304  Training loss = 2.2659  Validation loss = 3.1475  \n",
      "\n",
      "Fold: 32  Epoch: 305  Training loss = 2.2658  Validation loss = 3.1480  \n",
      "\n",
      "Fold: 32  Epoch: 306  Training loss = 2.2656  Validation loss = 3.1477  \n",
      "\n",
      "Fold: 32  Epoch: 307  Training loss = 2.2654  Validation loss = 3.1466  \n",
      "\n",
      "Fold: 32  Epoch: 308  Training loss = 2.2653  Validation loss = 3.1461  \n",
      "\n",
      "Fold: 32  Epoch: 309  Training loss = 2.2651  Validation loss = 3.1462  \n",
      "\n",
      "Fold: 32  Epoch: 310  Training loss = 2.2650  Validation loss = 3.1471  \n",
      "\n",
      "Fold: 32  Epoch: 311  Training loss = 2.2649  Validation loss = 3.1469  \n",
      "\n",
      "Fold: 32  Epoch: 312  Training loss = 2.2647  Validation loss = 3.1465  \n",
      "\n",
      "Fold: 32  Epoch: 313  Training loss = 2.2645  Validation loss = 3.1457  \n",
      "\n",
      "Fold: 32  Epoch: 314  Training loss = 2.2643  Validation loss = 3.1439  \n",
      "\n",
      "Fold: 32  Epoch: 315  Training loss = 2.2640  Validation loss = 3.1423  \n",
      "\n",
      "Fold: 32  Epoch: 316  Training loss = 2.2638  Validation loss = 3.1409  \n",
      "\n",
      "Fold: 32  Epoch: 317  Training loss = 2.2636  Validation loss = 3.1394  \n",
      "\n",
      "Fold: 32  Epoch: 318  Training loss = 2.2634  Validation loss = 3.1388  \n",
      "\n",
      "Fold: 32  Epoch: 319  Training loss = 2.2633  Validation loss = 3.1392  \n",
      "\n",
      "Fold: 32  Epoch: 320  Training loss = 2.2632  Validation loss = 3.1384  \n",
      "\n",
      "Fold: 32  Epoch: 321  Training loss = 2.2630  Validation loss = 3.1384  \n",
      "\n",
      "Fold: 32  Epoch: 322  Training loss = 2.2628  Validation loss = 3.1370  \n",
      "\n",
      "Fold: 32  Epoch: 323  Training loss = 2.2626  Validation loss = 3.1355  \n",
      "\n",
      "Fold: 32  Epoch: 324  Training loss = 2.2625  Validation loss = 3.1364  \n",
      "\n",
      "Fold: 32  Epoch: 325  Training loss = 2.2624  Validation loss = 3.1367  \n",
      "\n",
      "Fold: 32  Epoch: 326  Training loss = 2.2623  Validation loss = 3.1371  \n",
      "\n",
      "Fold: 32  Epoch: 327  Training loss = 2.2621  Validation loss = 3.1365  \n",
      "\n",
      "Fold: 32  Epoch: 328  Training loss = 2.2619  Validation loss = 3.1361  \n",
      "\n",
      "Fold: 32  Epoch: 329  Training loss = 2.2617  Validation loss = 3.1353  \n",
      "\n",
      "Fold: 32  Epoch: 330  Training loss = 2.2615  Validation loss = 3.1335  \n",
      "\n",
      "Fold: 32  Epoch: 331  Training loss = 2.2613  Validation loss = 3.1320  \n",
      "\n",
      "Fold: 32  Epoch: 332  Training loss = 2.2611  Validation loss = 3.1311  \n",
      "\n",
      "Fold: 32  Epoch: 333  Training loss = 2.2609  Validation loss = 3.1301  \n",
      "\n",
      "Fold: 32  Epoch: 334  Training loss = 2.2608  Validation loss = 3.1308  \n",
      "\n",
      "Fold: 32  Epoch: 335  Training loss = 2.2606  Validation loss = 3.1302  \n",
      "\n",
      "Fold: 32  Epoch: 336  Training loss = 2.2606  Validation loss = 3.1310  \n",
      "\n",
      "Fold: 32  Epoch: 337  Training loss = 2.2604  Validation loss = 3.1307  \n",
      "\n",
      "Fold: 32  Epoch: 338  Training loss = 2.2603  Validation loss = 3.1313  \n",
      "\n",
      "Fold: 32  Epoch: 339  Training loss = 2.2600  Validation loss = 3.1311  \n",
      "\n",
      "Fold: 32  Epoch: 340  Training loss = 2.2599  Validation loss = 3.1313  \n",
      "\n",
      "Fold: 32  Epoch: 341  Training loss = 2.2597  Validation loss = 3.1299  \n",
      "\n",
      "Fold: 32  Epoch: 342  Training loss = 2.2595  Validation loss = 3.1298  \n",
      "\n",
      "Fold: 32  Epoch: 343  Training loss = 2.2594  Validation loss = 3.1299  \n",
      "\n",
      "Fold: 32  Epoch: 344  Training loss = 2.2592  Validation loss = 3.1303  \n",
      "\n",
      "Fold: 32  Epoch: 345  Training loss = 2.2590  Validation loss = 3.1289  \n",
      "\n",
      "Fold: 32  Epoch: 346  Training loss = 2.2589  Validation loss = 3.1293  \n",
      "\n",
      "Fold: 32  Epoch: 347  Training loss = 2.2587  Validation loss = 3.1297  \n",
      "\n",
      "Fold: 32  Epoch: 348  Training loss = 2.2585  Validation loss = 3.1299  \n",
      "\n",
      "Fold: 32  Epoch: 349  Training loss = 2.2583  Validation loss = 3.1293  \n",
      "\n",
      "Fold: 32  Epoch: 350  Training loss = 2.2582  Validation loss = 3.1284  \n",
      "\n",
      "Fold: 32  Epoch: 351  Training loss = 2.2580  Validation loss = 3.1281  \n",
      "\n",
      "Fold: 32  Epoch: 352  Training loss = 2.2579  Validation loss = 3.1279  \n",
      "\n",
      "Fold: 32  Epoch: 353  Training loss = 2.2577  Validation loss = 3.1272  \n",
      "\n",
      "Fold: 32  Epoch: 354  Training loss = 2.2574  Validation loss = 3.1258  \n",
      "\n",
      "Fold: 32  Epoch: 355  Training loss = 2.2574  Validation loss = 3.1271  \n",
      "\n",
      "Fold: 32  Epoch: 356  Training loss = 2.2572  Validation loss = 3.1280  \n",
      "\n",
      "Fold: 32  Epoch: 357  Training loss = 2.2570  Validation loss = 3.1268  \n",
      "\n",
      "Fold: 32  Epoch: 358  Training loss = 2.2568  Validation loss = 3.1256  \n",
      "\n",
      "Fold: 32  Epoch: 359  Training loss = 2.2565  Validation loss = 3.1231  \n",
      "\n",
      "Fold: 32  Epoch: 360  Training loss = 2.2564  Validation loss = 3.1242  \n",
      "\n",
      "Fold: 32  Epoch: 361  Training loss = 2.2563  Validation loss = 3.1245  \n",
      "\n",
      "Fold: 32  Epoch: 362  Training loss = 2.2561  Validation loss = 3.1242  \n",
      "\n",
      "Fold: 32  Epoch: 363  Training loss = 2.2559  Validation loss = 3.1246  \n",
      "\n",
      "Fold: 32  Epoch: 364  Training loss = 2.2557  Validation loss = 3.1240  \n",
      "\n",
      "Fold: 32  Epoch: 365  Training loss = 2.2555  Validation loss = 3.1240  \n",
      "\n",
      "Fold: 32  Epoch: 366  Training loss = 2.2554  Validation loss = 3.1238  \n",
      "\n",
      "Fold: 32  Epoch: 367  Training loss = 2.2552  Validation loss = 3.1219  \n",
      "\n",
      "Fold: 32  Epoch: 368  Training loss = 2.2551  Validation loss = 3.1223  \n",
      "\n",
      "Fold: 32  Epoch: 369  Training loss = 2.2550  Validation loss = 3.1225  \n",
      "\n",
      "Fold: 32  Epoch: 370  Training loss = 2.2548  Validation loss = 3.1218  \n",
      "\n",
      "Fold: 32  Epoch: 371  Training loss = 2.2547  Validation loss = 3.1213  \n",
      "\n",
      "Fold: 32  Epoch: 372  Training loss = 2.2545  Validation loss = 3.1214  \n",
      "\n",
      "Fold: 32  Epoch: 373  Training loss = 2.2544  Validation loss = 3.1223  \n",
      "\n",
      "Fold: 32  Epoch: 374  Training loss = 2.2543  Validation loss = 3.1225  \n",
      "\n",
      "Fold: 32  Epoch: 375  Training loss = 2.2541  Validation loss = 3.1216  \n",
      "\n",
      "Fold: 32  Epoch: 376  Training loss = 2.2538  Validation loss = 3.1209  \n",
      "\n",
      "Fold: 32  Epoch: 377  Training loss = 2.2537  Validation loss = 3.1214  \n",
      "\n",
      "Fold: 32  Epoch: 378  Training loss = 2.2536  Validation loss = 3.1238  \n",
      "\n",
      "Check model:  Fold: 32  Epoch: 376  Training loss = 2.2536  Validation loss = 3.1238  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 2. Train model\n",
    "# ==================================\n",
    "sess = tf.InteractiveSession()  # Launch Graph\n",
    "sess.run(tf.global_variables_initializer())  # Initialise all variables\n",
    "\n",
    "print(\"Start training\", \n",
    "      \"\\nHyperparameters:\",\n",
    "      \"\\nDimension of recurrent unit =\", n_hidden,\n",
    "      \"\\nLearning rate =\", learning_rate,\n",
    "      \"\\nEpochs =\", epochs,\n",
    "      \"\\nBatch size =\", batch_size,\n",
    "      \"\\nEarly stopping epochs =\", early_stop_iters,\n",
    "      \"\\nLearning rate =\", learning_rate)\n",
    "\n",
    "total_batch = int(window_length / batch_size)\n",
    "validation_fold_error = [] # store validation error of each fold\n",
    "optimal_epochs = []\n",
    "\n",
    "# loop through folds\n",
    "for fold in range(1, len(valIndex)):\n",
    "    validx = train_features[valIndex[fold-1]:valIndex[fold]]\n",
    "    validy = train_target[valIndex[fold-1]:valIndex[fold]]\n",
    "    trainx = train_features[(fold-1)*4:valIndex[(fold-1)]]\n",
    "    trainy = train_target[(fold-1)*4:valIndex[(fold-1)]]\n",
    "\n",
    "    loss_list = [] # store validation loss after each epoch for early stopping\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i in range(total_batch):\n",
    "            # Backprop\n",
    "            batch_xs, batch_ys = next_batch(num=batch_size, data=trainx, labels=trainy)\n",
    "            optimizer.run(feed_dict={x:batch_xs, y:batch_ys, lr:learning_rate})\n",
    "\n",
    "        # Loss\n",
    "        loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "        loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "        loss_list.append(loss_valid)\n",
    "\n",
    "        print(\"Fold: {0:d}\".format(fold),\n",
    "              \" Epoch: {0:d}\".format(epoch+1),\n",
    "              \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "              \" Validation loss = {0:.4f}\".format(np.sqrt(loss_valid)),\n",
    "              \" \\n\")\n",
    "\n",
    "        if all(j <= loss_valid for j in loss_list[-early_stop_iters:]) and len(loss_list)>early_stop_iters:\n",
    "            break\n",
    "    \n",
    "    # Load model with lowest validation error for each fold\n",
    "    epoch_hat = np.argmin(loss_list) + 1\n",
    "    optimal_epochs.append(epoch_hat) # store optimal number of epochs for each fold\n",
    "    \n",
    "    # RMSE\n",
    "    loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "    loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "    validation_fold_error.append(np.sqrt(loss_valid))\n",
    "    \n",
    "    print(\"Check model:\",\n",
    "          \" Fold: {0:d}\".format(fold),\n",
    "          \" Epoch: {0:d}\".format(epoch_hat),\n",
    "          \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "          \" Validation loss = {0:.4f}\".format(np.sqrt(loss_valid)),\n",
    "          \" \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average number of epochs: 334\n",
      "Average validation error: 3.63695\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 3. Optimal epoch choice\n",
    "# ==================================\n",
    "# Pick number of epochs to train model for out-of-sample testing\n",
    "epoch_hat = int(np.mean(optimal_epochs))\n",
    "print(\"\\nAverage number of epochs:\", epoch_hat)\n",
    "# Average validation error\n",
    "print(\"Average validation error:\", np.mean(validation_fold_error))\n",
    "\n",
    "# Save validated model\n",
    "saveModel(sess, \n",
    "          MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + str(epoch_hat) + \"_validated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fixed scheme:\n",
      "Epoch: 1  Training loss = 2.0519  Test loss = 3.1893  \n",
      "\n",
      "Epoch: 2  Training loss = 2.0519  Test loss = 3.1891  \n",
      "\n",
      "Epoch: 3  Training loss = 2.0518  Test loss = 3.1889  \n",
      "\n",
      "Epoch: 4  Training loss = 2.0518  Test loss = 3.1887  \n",
      "\n",
      "Epoch: 5  Training loss = 2.0517  Test loss = 3.1885  \n",
      "\n",
      "Epoch: 6  Training loss = 2.0516  Test loss = 3.1883  \n",
      "\n",
      "Epoch: 7  Training loss = 2.0516  Test loss = 3.1881  \n",
      "\n",
      "Epoch: 8  Training loss = 2.0515  Test loss = 3.1879  \n",
      "\n",
      "Epoch: 9  Training loss = 2.0514  Test loss = 3.1878  \n",
      "\n",
      "Epoch: 10  Training loss = 2.0514  Test loss = 3.1876  \n",
      "\n",
      "Epoch: 11  Training loss = 2.0513  Test loss = 3.1874  \n",
      "\n",
      "Epoch: 12  Training loss = 2.0513  Test loss = 3.1872  \n",
      "\n",
      "Epoch: 13  Training loss = 2.0512  Test loss = 3.1870  \n",
      "\n",
      "Epoch: 14  Training loss = 2.0511  Test loss = 3.1868  \n",
      "\n",
      "Epoch: 15  Training loss = 2.0511  Test loss = 3.1866  \n",
      "\n",
      "Epoch: 16  Training loss = 2.0510  Test loss = 3.1864  \n",
      "\n",
      "Epoch: 17  Training loss = 2.0510  Test loss = 3.1862  \n",
      "\n",
      "Epoch: 18  Training loss = 2.0509  Test loss = 3.1860  \n",
      "\n",
      "Epoch: 19  Training loss = 2.0508  Test loss = 3.1858  \n",
      "\n",
      "Epoch: 20  Training loss = 2.0508  Test loss = 3.1856  \n",
      "\n",
      "Epoch: 21  Training loss = 2.0507  Test loss = 3.1854  \n",
      "\n",
      "Epoch: 22  Training loss = 2.0507  Test loss = 3.1853  \n",
      "\n",
      "Epoch: 23  Training loss = 2.0506  Test loss = 3.1851  \n",
      "\n",
      "Epoch: 24  Training loss = 2.0505  Test loss = 3.1849  \n",
      "\n",
      "Epoch: 25  Training loss = 2.0505  Test loss = 3.1847  \n",
      "\n",
      "Epoch: 26  Training loss = 2.0504  Test loss = 3.1845  \n",
      "\n",
      "Epoch: 27  Training loss = 2.0503  Test loss = 3.1843  \n",
      "\n",
      "Epoch: 28  Training loss = 2.0503  Test loss = 3.1841  \n",
      "\n",
      "Epoch: 29  Training loss = 2.0502  Test loss = 3.1839  \n",
      "\n",
      "Epoch: 30  Training loss = 2.0502  Test loss = 3.1837  \n",
      "\n",
      "Epoch: 31  Training loss = 2.0501  Test loss = 3.1835  \n",
      "\n",
      "Epoch: 32  Training loss = 2.0500  Test loss = 3.1833  \n",
      "\n",
      "Epoch: 33  Training loss = 2.0500  Test loss = 3.1831  \n",
      "\n",
      "Epoch: 34  Training loss = 2.0499  Test loss = 3.1829  \n",
      "\n",
      "Epoch: 35  Training loss = 2.0499  Test loss = 3.1828  \n",
      "\n",
      "Epoch: 36  Training loss = 2.0498  Test loss = 3.1826  \n",
      "\n",
      "Epoch: 37  Training loss = 2.0497  Test loss = 3.1824  \n",
      "\n",
      "Epoch: 38  Training loss = 2.0497  Test loss = 3.1822  \n",
      "\n",
      "Epoch: 39  Training loss = 2.0496  Test loss = 3.1820  \n",
      "\n",
      "Epoch: 40  Training loss = 2.0495  Test loss = 3.1818  \n",
      "\n",
      "Epoch: 41  Training loss = 2.0495  Test loss = 3.1816  \n",
      "\n",
      "Epoch: 42  Training loss = 2.0494  Test loss = 3.1814  \n",
      "\n",
      "Epoch: 43  Training loss = 2.0494  Test loss = 3.1812  \n",
      "\n",
      "Epoch: 44  Training loss = 2.0493  Test loss = 3.1810  \n",
      "\n",
      "Epoch: 45  Training loss = 2.0492  Test loss = 3.1808  \n",
      "\n",
      "Epoch: 46  Training loss = 2.0492  Test loss = 3.1806  \n",
      "\n",
      "Epoch: 47  Training loss = 2.0491  Test loss = 3.1804  \n",
      "\n",
      "Epoch: 48  Training loss = 2.0491  Test loss = 3.1802  \n",
      "\n",
      "Epoch: 49  Training loss = 2.0490  Test loss = 3.1801  \n",
      "\n",
      "Epoch: 50  Training loss = 2.0489  Test loss = 3.1799  \n",
      "\n",
      "Epoch: 51  Training loss = 2.0489  Test loss = 3.1797  \n",
      "\n",
      "Epoch: 52  Training loss = 2.0488  Test loss = 3.1795  \n",
      "\n",
      "Epoch: 53  Training loss = 2.0487  Test loss = 3.1793  \n",
      "\n",
      "Epoch: 54  Training loss = 2.0487  Test loss = 3.1791  \n",
      "\n",
      "Epoch: 55  Training loss = 2.0486  Test loss = 3.1789  \n",
      "\n",
      "Epoch: 56  Training loss = 2.0486  Test loss = 3.1787  \n",
      "\n",
      "Epoch: 57  Training loss = 2.0485  Test loss = 3.1785  \n",
      "\n",
      "Epoch: 58  Training loss = 2.0484  Test loss = 3.1783  \n",
      "\n",
      "Epoch: 59  Training loss = 2.0484  Test loss = 3.1781  \n",
      "\n",
      "Epoch: 60  Training loss = 2.0483  Test loss = 3.1779  \n",
      "\n",
      "Epoch: 61  Training loss = 2.0482  Test loss = 3.1777  \n",
      "\n",
      "Epoch: 62  Training loss = 2.0482  Test loss = 3.1775  \n",
      "\n",
      "Epoch: 63  Training loss = 2.0481  Test loss = 3.1773  \n",
      "\n",
      "Epoch: 64  Training loss = 2.0481  Test loss = 3.1771  \n",
      "\n",
      "Epoch: 65  Training loss = 2.0480  Test loss = 3.1770  \n",
      "\n",
      "Epoch: 66  Training loss = 2.0479  Test loss = 3.1768  \n",
      "\n",
      "Epoch: 67  Training loss = 2.0479  Test loss = 3.1766  \n",
      "\n",
      "Epoch: 68  Training loss = 2.0478  Test loss = 3.1764  \n",
      "\n",
      "Epoch: 69  Training loss = 2.0478  Test loss = 3.1762  \n",
      "\n",
      "Epoch: 70  Training loss = 2.0477  Test loss = 3.1760  \n",
      "\n",
      "Epoch: 71  Training loss = 2.0476  Test loss = 3.1758  \n",
      "\n",
      "Epoch: 72  Training loss = 2.0476  Test loss = 3.1756  \n",
      "\n",
      "Epoch: 73  Training loss = 2.0475  Test loss = 3.1754  \n",
      "\n",
      "Epoch: 74  Training loss = 2.0474  Test loss = 3.1752  \n",
      "\n",
      "Epoch: 75  Training loss = 2.0474  Test loss = 3.1750  \n",
      "\n",
      "Epoch: 76  Training loss = 2.0473  Test loss = 3.1748  \n",
      "\n",
      "Epoch: 77  Training loss = 2.0473  Test loss = 3.1746  \n",
      "\n",
      "Epoch: 78  Training loss = 2.0472  Test loss = 3.1744  \n",
      "\n",
      "Epoch: 79  Training loss = 2.0471  Test loss = 3.1742  \n",
      "\n",
      "Epoch: 80  Training loss = 2.0471  Test loss = 3.1740  \n",
      "\n",
      "Epoch: 81  Training loss = 2.0470  Test loss = 3.1738  \n",
      "\n",
      "Epoch: 82  Training loss = 2.0469  Test loss = 3.1737  \n",
      "\n",
      "Epoch: 83  Training loss = 2.0469  Test loss = 3.1735  \n",
      "\n",
      "Epoch: 84  Training loss = 2.0468  Test loss = 3.1733  \n",
      "\n",
      "Epoch: 85  Training loss = 2.0468  Test loss = 3.1731  \n",
      "\n",
      "Epoch: 86  Training loss = 2.0467  Test loss = 3.1729  \n",
      "\n",
      "Epoch: 87  Training loss = 2.0466  Test loss = 3.1727  \n",
      "\n",
      "Epoch: 88  Training loss = 2.0466  Test loss = 3.1725  \n",
      "\n",
      "Epoch: 89  Training loss = 2.0465  Test loss = 3.1723  \n",
      "\n",
      "Epoch: 90  Training loss = 2.0464  Test loss = 3.1721  \n",
      "\n",
      "Epoch: 91  Training loss = 2.0464  Test loss = 3.1719  \n",
      "\n",
      "Epoch: 92  Training loss = 2.0463  Test loss = 3.1717  \n",
      "\n",
      "Epoch: 93  Training loss = 2.0463  Test loss = 3.1715  \n",
      "\n",
      "Epoch: 94  Training loss = 2.0462  Test loss = 3.1713  \n",
      "\n",
      "Epoch: 95  Training loss = 2.0461  Test loss = 3.1711  \n",
      "\n",
      "Epoch: 96  Training loss = 2.0461  Test loss = 3.1709  \n",
      "\n",
      "Epoch: 97  Training loss = 2.0460  Test loss = 3.1707  \n",
      "\n",
      "Epoch: 98  Training loss = 2.0459  Test loss = 3.1705  \n",
      "\n",
      "Epoch: 99  Training loss = 2.0459  Test loss = 3.1703  \n",
      "\n",
      "Epoch: 100  Training loss = 2.0458  Test loss = 3.1701  \n",
      "\n",
      "Epoch: 101  Training loss = 2.0458  Test loss = 3.1699  \n",
      "\n",
      "Epoch: 102  Training loss = 2.0457  Test loss = 3.1697  \n",
      "\n",
      "Epoch: 103  Training loss = 2.0456  Test loss = 3.1696  \n",
      "\n",
      "Epoch: 104  Training loss = 2.0456  Test loss = 3.1694  \n",
      "\n",
      "Epoch: 105  Training loss = 2.0455  Test loss = 3.1692  \n",
      "\n",
      "Epoch: 106  Training loss = 2.0454  Test loss = 3.1690  \n",
      "\n",
      "Epoch: 107  Training loss = 2.0454  Test loss = 3.1688  \n",
      "\n",
      "Epoch: 108  Training loss = 2.0453  Test loss = 3.1686  \n",
      "\n",
      "Epoch: 109  Training loss = 2.0452  Test loss = 3.1684  \n",
      "\n",
      "Epoch: 110  Training loss = 2.0452  Test loss = 3.1682  \n",
      "\n",
      "Epoch: 111  Training loss = 2.0451  Test loss = 3.1680  \n",
      "\n",
      "Epoch: 112  Training loss = 2.0451  Test loss = 3.1678  \n",
      "\n",
      "Epoch: 113  Training loss = 2.0450  Test loss = 3.1676  \n",
      "\n",
      "Epoch: 114  Training loss = 2.0449  Test loss = 3.1674  \n",
      "\n",
      "Epoch: 115  Training loss = 2.0449  Test loss = 3.1672  \n",
      "\n",
      "Epoch: 116  Training loss = 2.0448  Test loss = 3.1670  \n",
      "\n",
      "Epoch: 117  Training loss = 2.0447  Test loss = 3.1668  \n",
      "\n",
      "Epoch: 118  Training loss = 2.0447  Test loss = 3.1666  \n",
      "\n",
      "Epoch: 119  Training loss = 2.0446  Test loss = 3.1664  \n",
      "\n",
      "Epoch: 120  Training loss = 2.0446  Test loss = 3.1662  \n",
      "\n",
      "Epoch: 121  Training loss = 2.0445  Test loss = 3.1660  \n",
      "\n",
      "Epoch: 122  Training loss = 2.0444  Test loss = 3.1658  \n",
      "\n",
      "Epoch: 123  Training loss = 2.0444  Test loss = 3.1656  \n",
      "\n",
      "Epoch: 124  Training loss = 2.0443  Test loss = 3.1654  \n",
      "\n",
      "Epoch: 125  Training loss = 2.0442  Test loss = 3.1652  \n",
      "\n",
      "Epoch: 126  Training loss = 2.0442  Test loss = 3.1650  \n",
      "\n",
      "Epoch: 127  Training loss = 2.0441  Test loss = 3.1648  \n",
      "\n",
      "Epoch: 128  Training loss = 2.0440  Test loss = 3.1647  \n",
      "\n",
      "Epoch: 129  Training loss = 2.0440  Test loss = 3.1645  \n",
      "\n",
      "Epoch: 130  Training loss = 2.0439  Test loss = 3.1643  \n",
      "\n",
      "Epoch: 131  Training loss = 2.0439  Test loss = 3.1641  \n",
      "\n",
      "Epoch: 132  Training loss = 2.0438  Test loss = 3.1639  \n",
      "\n",
      "Epoch: 133  Training loss = 2.0437  Test loss = 3.1637  \n",
      "\n",
      "Epoch: 134  Training loss = 2.0437  Test loss = 3.1635  \n",
      "\n",
      "Epoch: 135  Training loss = 2.0436  Test loss = 3.1633  \n",
      "\n",
      "Epoch: 136  Training loss = 2.0435  Test loss = 3.1631  \n",
      "\n",
      "Epoch: 137  Training loss = 2.0435  Test loss = 3.1629  \n",
      "\n",
      "Epoch: 138  Training loss = 2.0434  Test loss = 3.1627  \n",
      "\n",
      "Epoch: 139  Training loss = 2.0434  Test loss = 3.1625  \n",
      "\n",
      "Epoch: 140  Training loss = 2.0433  Test loss = 3.1623  \n",
      "\n",
      "Epoch: 141  Training loss = 2.0432  Test loss = 3.1621  \n",
      "\n",
      "Epoch: 142  Training loss = 2.0432  Test loss = 3.1619  \n",
      "\n",
      "Epoch: 143  Training loss = 2.0431  Test loss = 3.1617  \n",
      "\n",
      "Epoch: 144  Training loss = 2.0430  Test loss = 3.1615  \n",
      "\n",
      "Epoch: 145  Training loss = 2.0430  Test loss = 3.1613  \n",
      "\n",
      "Epoch: 146  Training loss = 2.0429  Test loss = 3.1611  \n",
      "\n",
      "Epoch: 147  Training loss = 2.0428  Test loss = 3.1609  \n",
      "\n",
      "Epoch: 148  Training loss = 2.0428  Test loss = 3.1607  \n",
      "\n",
      "Epoch: 149  Training loss = 2.0427  Test loss = 3.1605  \n",
      "\n",
      "Epoch: 150  Training loss = 2.0426  Test loss = 3.1603  \n",
      "\n",
      "Epoch: 151  Training loss = 2.0426  Test loss = 3.1601  \n",
      "\n",
      "Epoch: 152  Training loss = 2.0425  Test loss = 3.1599  \n",
      "\n",
      "Epoch: 153  Training loss = 2.0425  Test loss = 3.1597  \n",
      "\n",
      "Epoch: 154  Training loss = 2.0424  Test loss = 3.1595  \n",
      "\n",
      "Epoch: 155  Training loss = 2.0423  Test loss = 3.1593  \n",
      "\n",
      "Epoch: 156  Training loss = 2.0423  Test loss = 3.1591  \n",
      "\n",
      "Epoch: 157  Training loss = 2.0422  Test loss = 3.1589  \n",
      "\n",
      "Epoch: 158  Training loss = 2.0421  Test loss = 3.1587  \n",
      "\n",
      "Epoch: 159  Training loss = 2.0421  Test loss = 3.1585  \n",
      "\n",
      "Epoch: 160  Training loss = 2.0420  Test loss = 3.1583  \n",
      "\n",
      "Epoch: 161  Training loss = 2.0419  Test loss = 3.1581  \n",
      "\n",
      "Epoch: 162  Training loss = 2.0419  Test loss = 3.1579  \n",
      "\n",
      "Epoch: 163  Training loss = 2.0418  Test loss = 3.1577  \n",
      "\n",
      "Epoch: 164  Training loss = 2.0418  Test loss = 3.1575  \n",
      "\n",
      "Epoch: 165  Training loss = 2.0417  Test loss = 3.1573  \n",
      "\n",
      "Epoch: 166  Training loss = 2.0416  Test loss = 3.1571  \n",
      "\n",
      "Epoch: 167  Training loss = 2.0416  Test loss = 3.1569  \n",
      "\n",
      "Epoch: 168  Training loss = 2.0415  Test loss = 3.1568  \n",
      "\n",
      "Epoch: 169  Training loss = 2.0414  Test loss = 3.1566  \n",
      "\n",
      "Epoch: 170  Training loss = 2.0414  Test loss = 3.1564  \n",
      "\n",
      "Epoch: 171  Training loss = 2.0413  Test loss = 3.1562  \n",
      "\n",
      "Epoch: 172  Training loss = 2.0412  Test loss = 3.1560  \n",
      "\n",
      "Epoch: 173  Training loss = 2.0412  Test loss = 3.1558  \n",
      "\n",
      "Epoch: 174  Training loss = 2.0411  Test loss = 3.1556  \n",
      "\n",
      "Epoch: 175  Training loss = 2.0410  Test loss = 3.1554  \n",
      "\n",
      "Epoch: 176  Training loss = 2.0410  Test loss = 3.1552  \n",
      "\n",
      "Epoch: 177  Training loss = 2.0409  Test loss = 3.1550  \n",
      "\n",
      "Epoch: 178  Training loss = 2.0408  Test loss = 3.1548  \n",
      "\n",
      "Epoch: 179  Training loss = 2.0408  Test loss = 3.1546  \n",
      "\n",
      "Epoch: 180  Training loss = 2.0407  Test loss = 3.1544  \n",
      "\n",
      "Epoch: 181  Training loss = 2.0407  Test loss = 3.1542  \n",
      "\n",
      "Epoch: 182  Training loss = 2.0406  Test loss = 3.1540  \n",
      "\n",
      "Epoch: 183  Training loss = 2.0405  Test loss = 3.1538  \n",
      "\n",
      "Epoch: 184  Training loss = 2.0405  Test loss = 3.1536  \n",
      "\n",
      "Epoch: 185  Training loss = 2.0404  Test loss = 3.1534  \n",
      "\n",
      "Epoch: 186  Training loss = 2.0403  Test loss = 3.1532  \n",
      "\n",
      "Epoch: 187  Training loss = 2.0403  Test loss = 3.1530  \n",
      "\n",
      "Epoch: 188  Training loss = 2.0402  Test loss = 3.1528  \n",
      "\n",
      "Epoch: 189  Training loss = 2.0401  Test loss = 3.1526  \n",
      "\n",
      "Epoch: 190  Training loss = 2.0401  Test loss = 3.1524  \n",
      "\n",
      "Epoch: 191  Training loss = 2.0400  Test loss = 3.1522  \n",
      "\n",
      "Epoch: 192  Training loss = 2.0399  Test loss = 3.1520  \n",
      "\n",
      "Epoch: 193  Training loss = 2.0399  Test loss = 3.1518  \n",
      "\n",
      "Epoch: 194  Training loss = 2.0398  Test loss = 3.1516  \n",
      "\n",
      "Epoch: 195  Training loss = 2.0397  Test loss = 3.1514  \n",
      "\n",
      "Epoch: 196  Training loss = 2.0397  Test loss = 3.1512  \n",
      "\n",
      "Epoch: 197  Training loss = 2.0396  Test loss = 3.1510  \n",
      "\n",
      "Epoch: 198  Training loss = 2.0396  Test loss = 3.1508  \n",
      "\n",
      "Epoch: 199  Training loss = 2.0395  Test loss = 3.1506  \n",
      "\n",
      "Epoch: 200  Training loss = 2.0394  Test loss = 3.1504  \n",
      "\n",
      "Epoch: 201  Training loss = 2.0394  Test loss = 3.1502  \n",
      "\n",
      "Epoch: 202  Training loss = 2.0393  Test loss = 3.1500  \n",
      "\n",
      "Epoch: 203  Training loss = 2.0392  Test loss = 3.1498  \n",
      "\n",
      "Epoch: 204  Training loss = 2.0392  Test loss = 3.1496  \n",
      "\n",
      "Epoch: 205  Training loss = 2.0391  Test loss = 3.1494  \n",
      "\n",
      "Epoch: 206  Training loss = 2.0390  Test loss = 3.1492  \n",
      "\n",
      "Epoch: 207  Training loss = 2.0390  Test loss = 3.1490  \n",
      "\n",
      "Epoch: 208  Training loss = 2.0389  Test loss = 3.1488  \n",
      "\n",
      "Epoch: 209  Training loss = 2.0388  Test loss = 3.1486  \n",
      "\n",
      "Epoch: 210  Training loss = 2.0388  Test loss = 3.1484  \n",
      "\n",
      "Epoch: 211  Training loss = 2.0387  Test loss = 3.1482  \n",
      "\n",
      "Epoch: 212  Training loss = 2.0386  Test loss = 3.1480  \n",
      "\n",
      "Epoch: 213  Training loss = 2.0386  Test loss = 3.1478  \n",
      "\n",
      "Epoch: 214  Training loss = 2.0385  Test loss = 3.1476  \n",
      "\n",
      "Epoch: 215  Training loss = 2.0384  Test loss = 3.1474  \n",
      "\n",
      "Epoch: 216  Training loss = 2.0384  Test loss = 3.1472  \n",
      "\n",
      "Epoch: 217  Training loss = 2.0383  Test loss = 3.1470  \n",
      "\n",
      "Epoch: 218  Training loss = 2.0382  Test loss = 3.1468  \n",
      "\n",
      "Epoch: 219  Training loss = 2.0382  Test loss = 3.1466  \n",
      "\n",
      "Epoch: 220  Training loss = 2.0381  Test loss = 3.1464  \n",
      "\n",
      "Epoch: 221  Training loss = 2.0380  Test loss = 3.1462  \n",
      "\n",
      "Epoch: 222  Training loss = 2.0380  Test loss = 3.1460  \n",
      "\n",
      "Epoch: 223  Training loss = 2.0379  Test loss = 3.1458  \n",
      "\n",
      "Epoch: 224  Training loss = 2.0379  Test loss = 3.1456  \n",
      "\n",
      "Epoch: 225  Training loss = 2.0378  Test loss = 3.1454  \n",
      "\n",
      "Epoch: 226  Training loss = 2.0377  Test loss = 3.1452  \n",
      "\n",
      "Epoch: 227  Training loss = 2.0377  Test loss = 3.1450  \n",
      "\n",
      "Epoch: 228  Training loss = 2.0376  Test loss = 3.1448  \n",
      "\n",
      "Epoch: 229  Training loss = 2.0375  Test loss = 3.1446  \n",
      "\n",
      "Epoch: 230  Training loss = 2.0375  Test loss = 3.1444  \n",
      "\n",
      "Epoch: 231  Training loss = 2.0374  Test loss = 3.1442  \n",
      "\n",
      "Epoch: 232  Training loss = 2.0373  Test loss = 3.1440  \n",
      "\n",
      "Epoch: 233  Training loss = 2.0373  Test loss = 3.1438  \n",
      "\n",
      "Epoch: 234  Training loss = 2.0372  Test loss = 3.1436  \n",
      "\n",
      "Epoch: 235  Training loss = 2.0371  Test loss = 3.1434  \n",
      "\n",
      "Epoch: 236  Training loss = 2.0371  Test loss = 3.1432  \n",
      "\n",
      "Epoch: 237  Training loss = 2.0370  Test loss = 3.1430  \n",
      "\n",
      "Epoch: 238  Training loss = 2.0369  Test loss = 3.1428  \n",
      "\n",
      "Epoch: 239  Training loss = 2.0369  Test loss = 3.1426  \n",
      "\n",
      "Epoch: 240  Training loss = 2.0368  Test loss = 3.1424  \n",
      "\n",
      "Epoch: 241  Training loss = 2.0367  Test loss = 3.1422  \n",
      "\n",
      "Epoch: 242  Training loss = 2.0367  Test loss = 3.1420  \n",
      "\n",
      "Epoch: 243  Training loss = 2.0366  Test loss = 3.1418  \n",
      "\n",
      "Epoch: 244  Training loss = 2.0365  Test loss = 3.1416  \n",
      "\n",
      "Epoch: 245  Training loss = 2.0365  Test loss = 3.1414  \n",
      "\n",
      "Epoch: 246  Training loss = 2.0364  Test loss = 3.1412  \n",
      "\n",
      "Epoch: 247  Training loss = 2.0363  Test loss = 3.1410  \n",
      "\n",
      "Epoch: 248  Training loss = 2.0363  Test loss = 3.1408  \n",
      "\n",
      "Epoch: 249  Training loss = 2.0362  Test loss = 3.1405  \n",
      "\n",
      "Epoch: 250  Training loss = 2.0361  Test loss = 3.1403  \n",
      "\n",
      "Epoch: 251  Training loss = 2.0361  Test loss = 3.1401  \n",
      "\n",
      "Epoch: 252  Training loss = 2.0360  Test loss = 3.1399  \n",
      "\n",
      "Epoch: 253  Training loss = 2.0359  Test loss = 3.1397  \n",
      "\n",
      "Epoch: 254  Training loss = 2.0359  Test loss = 3.1395  \n",
      "\n",
      "Epoch: 255  Training loss = 2.0358  Test loss = 3.1393  \n",
      "\n",
      "Epoch: 256  Training loss = 2.0357  Test loss = 3.1391  \n",
      "\n",
      "Epoch: 257  Training loss = 2.0357  Test loss = 3.1389  \n",
      "\n",
      "Epoch: 258  Training loss = 2.0356  Test loss = 3.1387  \n",
      "\n",
      "Epoch: 259  Training loss = 2.0355  Test loss = 3.1385  \n",
      "\n",
      "Epoch: 260  Training loss = 2.0355  Test loss = 3.1383  \n",
      "\n",
      "Epoch: 261  Training loss = 2.0354  Test loss = 3.1381  \n",
      "\n",
      "Epoch: 262  Training loss = 2.0353  Test loss = 3.1379  \n",
      "\n",
      "Epoch: 263  Training loss = 2.0353  Test loss = 3.1377  \n",
      "\n",
      "Epoch: 264  Training loss = 2.0352  Test loss = 3.1375  \n",
      "\n",
      "Epoch: 265  Training loss = 2.0351  Test loss = 3.1373  \n",
      "\n",
      "Epoch: 266  Training loss = 2.0351  Test loss = 3.1371  \n",
      "\n",
      "Epoch: 267  Training loss = 2.0350  Test loss = 3.1369  \n",
      "\n",
      "Epoch: 268  Training loss = 2.0349  Test loss = 3.1367  \n",
      "\n",
      "Epoch: 269  Training loss = 2.0349  Test loss = 3.1365  \n",
      "\n",
      "Epoch: 270  Training loss = 2.0348  Test loss = 3.1363  \n",
      "\n",
      "Epoch: 271  Training loss = 2.0347  Test loss = 3.1361  \n",
      "\n",
      "Epoch: 272  Training loss = 2.0347  Test loss = 3.1359  \n",
      "\n",
      "Epoch: 273  Training loss = 2.0346  Test loss = 3.1357  \n",
      "\n",
      "Epoch: 274  Training loss = 2.0345  Test loss = 3.1355  \n",
      "\n",
      "Epoch: 275  Training loss = 2.0345  Test loss = 3.1353  \n",
      "\n",
      "Epoch: 276  Training loss = 2.0344  Test loss = 3.1351  \n",
      "\n",
      "Epoch: 277  Training loss = 2.0343  Test loss = 3.1349  \n",
      "\n",
      "Epoch: 278  Training loss = 2.0343  Test loss = 3.1347  \n",
      "\n",
      "Epoch: 279  Training loss = 2.0342  Test loss = 3.1345  \n",
      "\n",
      "Epoch: 280  Training loss = 2.0341  Test loss = 3.1343  \n",
      "\n",
      "Epoch: 281  Training loss = 2.0341  Test loss = 3.1341  \n",
      "\n",
      "Epoch: 282  Training loss = 2.0340  Test loss = 3.1339  \n",
      "\n",
      "Epoch: 283  Training loss = 2.0339  Test loss = 3.1337  \n",
      "\n",
      "Epoch: 284  Training loss = 2.0339  Test loss = 3.1335  \n",
      "\n",
      "Epoch: 285  Training loss = 2.0338  Test loss = 3.1333  \n",
      "\n",
      "Epoch: 286  Training loss = 2.0337  Test loss = 3.1331  \n",
      "\n",
      "Epoch: 287  Training loss = 2.0336  Test loss = 3.1329  \n",
      "\n",
      "Epoch: 288  Training loss = 2.0336  Test loss = 3.1327  \n",
      "\n",
      "Epoch: 289  Training loss = 2.0335  Test loss = 3.1325  \n",
      "\n",
      "Epoch: 290  Training loss = 2.0334  Test loss = 3.1323  \n",
      "\n",
      "Epoch: 291  Training loss = 2.0334  Test loss = 3.1321  \n",
      "\n",
      "Epoch: 292  Training loss = 2.0333  Test loss = 3.1319  \n",
      "\n",
      "Epoch: 293  Training loss = 2.0332  Test loss = 3.1317  \n",
      "\n",
      "Epoch: 294  Training loss = 2.0332  Test loss = 3.1315  \n",
      "\n",
      "Epoch: 295  Training loss = 2.0331  Test loss = 3.1313  \n",
      "\n",
      "Epoch: 296  Training loss = 2.0330  Test loss = 3.1311  \n",
      "\n",
      "Epoch: 297  Training loss = 2.0330  Test loss = 3.1309  \n",
      "\n",
      "Epoch: 298  Training loss = 2.0329  Test loss = 3.1306  \n",
      "\n",
      "Epoch: 299  Training loss = 2.0328  Test loss = 3.1304  \n",
      "\n",
      "Epoch: 300  Training loss = 2.0328  Test loss = 3.1302  \n",
      "\n",
      "Epoch: 301  Training loss = 2.0327  Test loss = 3.1300  \n",
      "\n",
      "Epoch: 302  Training loss = 2.0326  Test loss = 3.1298  \n",
      "\n",
      "Epoch: 303  Training loss = 2.0326  Test loss = 3.1296  \n",
      "\n",
      "Epoch: 304  Training loss = 2.0325  Test loss = 3.1294  \n",
      "\n",
      "Epoch: 305  Training loss = 2.0324  Test loss = 3.1292  \n",
      "\n",
      "Epoch: 306  Training loss = 2.0324  Test loss = 3.1290  \n",
      "\n",
      "Epoch: 307  Training loss = 2.0323  Test loss = 3.1288  \n",
      "\n",
      "Epoch: 308  Training loss = 2.0322  Test loss = 3.1286  \n",
      "\n",
      "Epoch: 309  Training loss = 2.0322  Test loss = 3.1284  \n",
      "\n",
      "Epoch: 310  Training loss = 2.0321  Test loss = 3.1282  \n",
      "\n",
      "Epoch: 311  Training loss = 2.0320  Test loss = 3.1280  \n",
      "\n",
      "Epoch: 312  Training loss = 2.0319  Test loss = 3.1278  \n",
      "\n",
      "Epoch: 313  Training loss = 2.0319  Test loss = 3.1276  \n",
      "\n",
      "Epoch: 314  Training loss = 2.0318  Test loss = 3.1274  \n",
      "\n",
      "Epoch: 315  Training loss = 2.0317  Test loss = 3.1272  \n",
      "\n",
      "Epoch: 316  Training loss = 2.0317  Test loss = 3.1270  \n",
      "\n",
      "Epoch: 317  Training loss = 2.0316  Test loss = 3.1268  \n",
      "\n",
      "Epoch: 318  Training loss = 2.0315  Test loss = 3.1266  \n",
      "\n",
      "Epoch: 319  Training loss = 2.0315  Test loss = 3.1264  \n",
      "\n",
      "Epoch: 320  Training loss = 2.0314  Test loss = 3.1262  \n",
      "\n",
      "Epoch: 321  Training loss = 2.0313  Test loss = 3.1260  \n",
      "\n",
      "Epoch: 322  Training loss = 2.0313  Test loss = 3.1258  \n",
      "\n",
      "Epoch: 323  Training loss = 2.0312  Test loss = 3.1256  \n",
      "\n",
      "Epoch: 324  Training loss = 2.0311  Test loss = 3.1254  \n",
      "\n",
      "Epoch: 325  Training loss = 2.0311  Test loss = 3.1252  \n",
      "\n",
      "Epoch: 326  Training loss = 2.0310  Test loss = 3.1250  \n",
      "\n",
      "Epoch: 327  Training loss = 2.0309  Test loss = 3.1248  \n",
      "\n",
      "Epoch: 328  Training loss = 2.0309  Test loss = 3.1246  \n",
      "\n",
      "Epoch: 329  Training loss = 2.0308  Test loss = 3.1244  \n",
      "\n",
      "Epoch: 330  Training loss = 2.0307  Test loss = 3.1242  \n",
      "\n",
      "Epoch: 331  Training loss = 2.0306  Test loss = 3.1240  \n",
      "\n",
      "Epoch: 332  Training loss = 2.0306  Test loss = 3.1238  \n",
      "\n",
      "Epoch: 333  Training loss = 2.0305  Test loss = 3.1236  \n",
      "\n",
      "Epoch: 334  Training loss = 2.0304  Test loss = 3.1234  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 4. Fixed scheme\n",
    "# ==================================\n",
    "print(\"\\nFixed scheme:\")\n",
    "for epoch in range(epoch_hat):\n",
    "    x_train = train_features[-window_length:]\n",
    "    y_train = train_target[-window_length:]\n",
    "    optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:test_features, y:test_target})\n",
    "    print(\"Epoch: {0:d}\".format(epoch+1),\n",
    "          \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "          \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "          \" \\n\")\n",
    "\n",
    "# Forecasts\n",
    "yhat_test_fixed = pred.eval(feed_dict={x:test_features})\n",
    "yhat_train_fixed = pred.eval(feed_dict={x:x_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWWFc7GZmhfkagQFF9e8lDxQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x47b4668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train set\n",
    "plt.plot(y_train, 'black')\n",
    "plt.plot(yhat_train_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n9GNDD9O8XwwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc6eda20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: fixed scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_test_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed scheme RMSE: 3.12335244295 \n",
      "Fixed scheme MAE:  2.34853065497\n"
     ]
    }
   ],
   "source": [
    "rmse_fixed = np.sqrt(np.mean((yhat_test_fixed[:,0]-test_target)**2))\n",
    "mae_fixed = np.mean(np.abs((yhat_test_fixed[:,0]-test_target)))\n",
    "print(\"Fixed scheme RMSE:\", rmse_fixed,\n",
    "     \"\\nFixed scheme MAE: \", mae_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Stack training and test set, this makes updating scheme easier to train\n",
    "all_features = np.concatenate((train_features[-window_length:], test_features), axis=0)\n",
    "all_target = np.concatenate((train_target[-window_length:], test_target), axis=0)\n",
    "\n",
    "# Vectors to store loss and forecasts\n",
    "test_loss = np.zeros(len(test_target))\n",
    "yhat_update = np.zeros(len(test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test period = 1  Training loss = 2.0304  Test loss = 4.5866  Model updated 0 times  \n",
      "\n",
      "Test period = 2  Training loss = 2.1078  Test loss = 3.5391  Model updated 0 times  \n",
      "\n",
      "Test period = 3  Training loss = 2.1294  Test loss = 1.6230  Model updated 0 times  \n",
      "\n",
      "Test period = 4  Training loss = 2.1227  Test loss = 0.4467  Model updated 0 times  \n",
      "\n",
      "Test period = 5  Training loss = 1.8687  Test loss = 0.1912  Model updated 1 times  \n",
      "\n",
      "Test period = 6  Training loss = 1.7582  Test loss = 0.6000  Model updated 1 times  \n",
      "\n",
      "Test period = 7  Training loss = 1.7269  Test loss = 1.4053  Model updated 1 times  \n",
      "\n",
      "Test period = 8  Training loss = 1.7277  Test loss = 2.2734  Model updated 1 times  \n",
      "\n",
      "Test period = 9  Training loss = 1.6851  Test loss = 2.8887  Model updated 2 times  \n",
      "\n",
      "Test period = 10  Training loss = 1.7116  Test loss = 1.1276  Model updated 2 times  \n",
      "\n",
      "Test period = 11  Training loss = 1.7106  Test loss = 1.2210  Model updated 2 times  \n",
      "\n",
      "Test period = 12  Training loss = 1.7131  Test loss = 1.3753  Model updated 2 times  \n",
      "\n",
      "Test period = 13  Training loss = 1.6697  Test loss = 0.3028  Model updated 3 times  \n",
      "\n",
      "Test period = 14  Training loss = 1.6665  Test loss = 1.2146  Model updated 3 times  \n",
      "\n",
      "Test period = 15  Training loss = 1.6539  Test loss = 3.0551  Model updated 3 times  \n",
      "\n",
      "Test period = 16  Training loss = 1.6838  Test loss = 4.6269  Model updated 3 times  \n",
      "\n",
      "Test period = 17  Training loss = 1.7191  Test loss = 3.0493  Model updated 4 times  \n",
      "\n",
      "Test period = 18  Training loss = 1.7581  Test loss = 0.4439  Model updated 4 times  \n",
      "\n",
      "Test period = 19  Training loss = 1.7548  Test loss = 0.3752  Model updated 4 times  \n",
      "\n",
      "Test period = 20  Training loss = 1.6755  Test loss = 1.5900  Model updated 4 times  \n",
      "\n",
      "Test period = 21  Training loss = 1.6226  Test loss = 2.6138  Model updated 5 times  \n",
      "\n",
      "Test period = 22  Training loss = 1.6300  Test loss = 2.8503  Model updated 5 times  \n",
      "\n",
      "Test period = 23  Training loss = 1.6677  Test loss = 0.4827  Model updated 5 times  \n",
      "\n",
      "Test period = 24  Training loss = 1.6674  Test loss = 2.2668  Model updated 5 times  \n",
      "\n",
      "Test period = 25  Training loss = 1.6447  Test loss = 0.1587  Model updated 6 times  \n",
      "\n",
      "Test period = 26  Training loss = 1.6381  Test loss = 0.6169  Model updated 6 times  \n",
      "\n",
      "Test period = 27  Training loss = 1.6391  Test loss = 1.4755  Model updated 6 times  \n",
      "\n",
      "Test period = 28  Training loss = 1.6484  Test loss = 1.3654  Model updated 6 times  \n",
      "\n",
      "Test period = 29  Training loss = 1.6141  Test loss = 0.7204  Model updated 7 times  \n",
      "\n",
      "Test period = 30  Training loss = 1.6110  Test loss = 1.1375  Model updated 7 times  \n",
      "\n",
      "Test period = 31  Training loss = 1.6133  Test loss = 2.7592  Model updated 7 times  \n",
      "\n",
      "Test period = 32  Training loss = 1.5944  Test loss = 0.9138  Model updated 7 times  \n",
      "\n",
      "Test period = 33  Training loss = 1.5658  Test loss = 0.9387  Model updated 8 times  \n",
      "\n",
      "Test period = 34  Training loss = 1.5554  Test loss = 0.7040  Model updated 8 times  \n",
      "\n",
      "Test period = 35  Training loss = 1.5048  Test loss = 0.7039  Model updated 8 times  \n",
      "\n",
      "Test period = 36  Training loss = 1.4977  Test loss = 5.3761  Model updated 8 times  \n",
      "\n",
      "Test period = 37  Training loss = 1.5545  Test loss = 0.8811  Model updated 9 times  \n",
      "\n",
      "Test period = 38  Training loss = 1.4760  Test loss = 1.8284  Model updated 9 times  \n",
      "\n",
      "Test period = 39  Training loss = 1.4933  Test loss = 0.6207  Model updated 9 times  \n",
      "\n",
      "Test period = 40  Training loss = 1.4934  Test loss = 1.5132  Model updated 9 times  \n",
      "\n",
      "Test period = 41  Training loss = 1.4738  Test loss = 1.4540  Model updated 10 times  \n",
      "\n",
      "Test period = 42  Training loss = 1.4845  Test loss = 2.2802  Model updated 10 times  \n",
      "\n",
      "Test period = 43  Training loss = 1.5112  Test loss = 3.7702  Model updated 10 times  \n",
      "\n",
      "Test period = 44  Training loss = 1.5800  Test loss = 12.1103  Model updated 10 times  \n",
      "\n",
      "Test period = 45  Training loss = 2.1640  Test loss = 5.5040  Model updated 11 times  \n",
      "\n",
      "Test period = 46  Training loss = 2.2661  Test loss = 0.5600  Model updated 11 times  \n",
      "\n",
      "Test period = 47  Training loss = 2.2672  Test loss = 0.8052  Model updated 11 times  \n",
      "\n",
      "Test period = 48  Training loss = 2.2657  Test loss = 0.3905  Model updated 11 times  \n",
      "\n",
      "Test period = 49  Training loss = 2.2278  Test loss = 1.3985  Model updated 12 times  \n",
      "\n",
      "Test period = 50  Training loss = 2.2331  Test loss = 2.6673  Model updated 12 times  \n",
      "\n",
      "Test period = 51  Training loss = 2.2532  Test loss = 1.4919  Model updated 12 times  \n",
      "\n",
      "Test period = 52  Training loss = 2.2545  Test loss = 0.6968  Model updated 12 times  \n",
      "\n",
      "Test period = 53  Training loss = 2.2166  Test loss = 1.6457  Model updated 13 times  \n",
      "\n",
      "Test period = 54  Training loss = 2.2257  Test loss = 1.7923  Model updated 13 times  \n",
      "\n",
      "Test period = 55  Training loss = 2.2321  Test loss = 0.7993  Model updated 13 times  \n",
      "\n",
      "Test period = 56  Training loss = 2.2312  Test loss = 2.3796  Model updated 13 times  \n",
      "\n",
      "Test period = 57  Training loss = 2.2339  Test loss = 1.5955  Model updated 14 times  \n",
      "\n",
      "Test period = 58  Training loss = 2.2424  Test loss = 2.4314  Model updated 14 times  \n",
      "\n",
      "Test period = 59  Training loss = 2.2595  Test loss = 0.5516  Model updated 14 times  \n",
      "\n",
      "Test period = 60  Training loss = 2.2606  Test loss = 0.2249  Model updated 14 times  \n",
      "\n",
      "Test period = 61  Training loss = 2.2425  Test loss = 0.5652  Model updated 15 times  \n",
      "\n",
      "Test period = 62  Training loss = 2.2432  Test loss = 3.0137  Model updated 15 times  \n",
      "\n",
      "Test period = 63  Training loss = 2.2737  Test loss = 0.7550  Model updated 15 times  \n",
      "\n",
      "Test period = 64  Training loss = 2.2655  Test loss = 0.7706  Model updated 15 times  \n",
      "\n",
      "Test period = 65  Training loss = 2.2472  Test loss = 0.1271  Model updated 16 times  \n",
      "\n",
      "Test period = 66  Training loss = 2.2469  Test loss = 1.4431  Model updated 16 times  \n",
      "\n",
      "Test period = 67  Training loss = 2.2458  Test loss = 1.7102  Model updated 16 times  \n",
      "\n",
      "Test period = 68  Training loss = 2.2486  Test loss = 3.3576  Model updated 16 times  \n",
      "\n",
      "Test period = 69  Training loss = 2.2724  Test loss = 5.5848  Model updated 17 times  \n",
      "\n",
      "Test period = 70  Training loss = 2.3753  Test loss = 0.1042  Model updated 17 times  \n",
      "\n",
      "Test period = 71  Training loss = 2.3732  Test loss = 1.1206  Model updated 17 times  \n",
      "\n",
      "Test period = 72  Training loss = 2.3767  Test loss = 3.1306  Model updated 17 times  \n",
      "\n",
      "Test period = 73  Training loss = 2.3807  Test loss = 1.6734  Model updated 18 times  \n",
      "\n",
      "Test period = 74  Training loss = 2.3831  Test loss = 0.1412  Model updated 18 times  \n",
      "\n",
      "Test period = 75  Training loss = 2.3687  Test loss = 0.6060  Model updated 18 times  \n",
      "\n",
      "Test period = 76  Training loss = 2.3670  Test loss = 0.8257  Model updated 18 times  \n",
      "\n",
      "Test period = 77  Training loss = 2.3378  Test loss = 1.8915  Model updated 19 times  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "retrain_count = 0\n",
    "for t in range(len(test_target)):\n",
    "    x_test = np.reshape(test_features[t], newshape=(1,4,3))\n",
    "    y_test = test_target[t]\n",
    "    test_loss[t] = np.sqrt(sess.run(loss, feed_dict={x:x_test, y:y_test}))\n",
    "    yhat_update[t] = pred.eval(feed_dict={x:x_test})\n",
    "\n",
    "    x_train = all_features[t:(window_length+t)]\n",
    "    y_train = all_target[t:(window_length+t)]\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:x_test, y:y_test})\n",
    "    \n",
    "    print(\"Test period = {0:d}\".format(t+1),\n",
    "      \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "      \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "      \" Model updated {0:d} times\".format(retrain_count),\n",
    "      \" \\n\")\n",
    "\n",
    "    if (t+1)%4==0:\n",
    "        retrain_count += 1\n",
    "        for epoch in range(epoch_hat):\n",
    "            for i in range(total_batch):\n",
    "                optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzsnXd4k+X6x79P2qQtLaWtpSCz0DJblpQhQxEEQRAVFFGG\nIrKOIuBBjoh41N9xHBAVnIACDmQ6EFAQFOEAApYyLKuU0bJKS6GTDprcvz+evGnSJmnSJE2T3p/r\n6gV9x5Mnb5Pve7/3egQRgWEYhvEeVO6eAMMwDONcWNgZhmG8DBZ2hmEYL4OFnWEYxstgYWcYhvEy\nWNgZhmG8DBZ2hmEYL4OFnWEYxstgYWcYhvEyfN3xouHh4RQZGemOl2YYhvFYDh48eI2I6lZ0nFuE\nPTIyEvHx8e54aYZhGI9FCJFiy3HsimEYhvEyWNgZhmG8DBZ2hmEYL4OFnWEYxstgYWcYhvEyWNgZ\nhmG8DBZ2hmEYL4OFnWGcRHZ2Nr788kt3T4NhWNgZxlksXLgQTz31FC5evOjuqTA1HKcIuxAiRAix\nXghxUghxQghxpzPGZWoWR48exeTJk6HVat09lUqxadMmAEBBQYGbZ8LUdJxlsS8EsIWIWgPoAOCE\nk8ZlahAbNmzA4sWLkZJiU9V0teLKlSv466+/AAC3bt1y82yYmo7Dwi6EqAPgLgBfAAARFRNRlqPj\nMjWPq1evAgDOnz/v3olUgs2bNxv+z8LOuBtnWOzNAGQAWC6EOCSE+FwIEeiEcZkaRnp6OgDg3Llz\nbp6J/ShuGICFnXE/zhB2XwB3APiUiDoByAfwUtmDhBAThRDxQoj4jIwMJ7ws4214qsVeWFiIbdu2\nISoqCgALO+N+nCHsFwFcJKL9+t/XQwq9CUS0hIjiiCiubt0K2wkzNRBF2D3NYt+xYwdu3ryJYcOG\nAWBhZ9yPw8JORGkALgghWuk39QNw3NFxmZqHp1rsGzduRGBgIAYMGAAAKC4udvOMmJqOsxbamApg\npRBCA+AsgHFOGpepIRQXFyMrS8bcPcliJyJs2rQJ/fv3R1BQEAC22Bn345R0RyI6rHeztCeih4jo\nhjPGZWoOSuC0UaNGuHz5MgoLC908I9s4evQoLly4gAceeABqtRoACzvjfrjylKkWKG6Ybt26AQBS\nU1PdOR2bUbJh7r//fhZ2ptrgWcK+dSvw73+7exaMC1AsdkXYPcUds3HjRnTt2hX169eHRqMBwMLO\nuB/PEvY//gDeeAM4eNDdM2GcTFmL3RMCqFevXsWBAwcwZMgQADBY7Bw8ZdyNZwn7Sy8B4eHAzJkA\nkbtnwzgRRdg7duwItVrtERb7xo0bQUTlhJ0tdsbdeJaw16kDvP66tNw3bnT3bBgnkp6ejlq1aiE4\nOBhNmzb1CIv922+/RXR0NDp27AiAhZ2pPniWsAPAhAlA69bAiy8C/AXyGq5evYp69eoBACIjI6u9\nxX7x4kX88ccfGD16NIQQAFjYmeqD5wm7Wg3MmwckJQFLlrh7NoyTMBb2Zs2aVXthX7VqFYgIo0aN\nMmzj4ClTXfA8YQeAIUOAe+4BXnsNyM5292wYJ5Ceno6IiAgAUtgzMjKQn5/v1jmdO3cOL774IoqK\nisrtW7lyJbp164bo6GjDNg6eMtUFzxR2IYB33wUyM4G33nL3bBgnUNYVA7g/M2b9+vV499138d57\n75lsT0xMxJEjR0ysdYBdMUz1wTOFHQDuuAN4/HHg448BtpA8Gq1Wi4yMDBNXDOB+YVfcQf/5z39M\nlrtbuXIlfHx88Nhjj5kc7+PjA4CFnXE/nivsAPDII0B+PrB/f8XHMtWWzMxM6HQ6gytGsdjd7Wc/\nf/48GjVqBJ1Oh5kzZwIAdDodvv32WwwYMMAwXwUhBNRqNQs743Y8W9j79AFUKuC339w9E8YBlKpT\nxWKvV68e/P39XS7saWlp+Pjjj0EWaiLOnTuHrl274qWXXsKaNWvwxx9/YPfu3UhNTS3nhlHwJGG/\nceMGvvjiC+h0OndPhXEyni3soaHSJcPC7tEoxUmKsAshEBkZ6XJXzCuvvILnnnsOycnJ5fYREc6f\nP4/IyEjMmjULkZGRmDp1Kr788ksEBgbioYceMjumRqPxCGHPzc3Ffffdh2eeecawVivjPXi2sANA\nv37Avn1AXp67Z8JUEkXYjV0brk55zMjIwDfffAMAOH36tNk5FRYWolmzZggICMB7772HxMRELFu2\nDA899BACA82v/qhWq6t9VkxBQQEeeOABg6CfPHnSzTNinI13CHtJCfC//7l7JkwlKeuKAeByi33x\n4sWGNMakpKRy+5XXVvz9Dz30EPr37w8AGD16tMVxq7srpri4GI8++ih27dqFL7/8Er6+vjh16pS7\np8U4Gc8X9p49AY3GO90x584By5fLQqyPPwYWLgR+/NHds7KZXbt2YejQoSgpKbF63NWrV+Hr64vQ\n0FDDtmbNmuHGjRvIdkGdQnFxMT7++GMMGDAAderUMWuxK08LSoaOEAKff/453njjDYPAm6M6C7tW\nq8XYsWOxefNmfPrppxg7diyioqJY2L0QZ62g5D5q1QJ69Kiewn7xInD0KHD//fadt28fsGAB8P33\ngLnA1okTsq1CNWf9+vXYuHEjUlNT0bx5c4vHXb16FREREYbSfMA0l71Dhw5OndfatWuRlpaG5cuX\n49VXXzUr7IrF3rRpU8O2Jk2aYO7cuVbHrs7CvmbNGqxZswbvvPMOJk2aBABo1aoVu2K8EKdZ7EII\nHyHEISHEJmeNaTP33gscPgxcu1blL22Vd96RVbK2WERaLfDDD/IJ5M47ge3bgVmzpIhfugSkpwPJ\nyfLp5MMPKzWd69evY8eOHZU6tzIkJiYCAM6ePWv1uPT0dBM3DFBqKTvbz05EeP/999G6dWsMGDAA\nLVq0sOiKCQ8PNyx3ZyvVOXi6YcMG1K9fHy+++KJhW6tWrZCcnAytVlv+hH37pAFx6FAVzpJxBs50\nxUwDcMKJ49lOv37y3yoULZv4+2/ZXvj99y0fU1AAfPYZ0KYNMGwYcOUKsGgRcOEC8Pbb8ovVoAFQ\nty4QFQU88QSwYgVww/7VBxcsWIABAwaYLZF3BYqwVyTOxlWnCq4S9j179iAhIQHTpk2DSqVCy5Yt\nkZqaWm4pvnPnzhnmYA/VNXh669YtbNmyBYMHD4ZKVfq1b926NYqLi83HMxYskEbJqFHAzZtVN1nG\nYZwi7EKIRgAGA/jcGePZTVwcEBzscndMVlaWQawqhEgKuxDAl18CGRnlj/nlF6BpU2DKFCAkBFi7\nVjY3mzoVsGQpTpsmv2RffGH3/I8cOYKSkhLDotFOZ+1aYNIkQKtFeno6MvTvuSKL3Zywh4WFISgo\nyOkB1IULFyI0NBRjxowBALRo0QJEVG6OSqqjvVRXV8zu3buRk5Nj6B2v0KpVKwAo72dPTwc2bAB6\n95ZPjbNmVdVUGSfgLIv9AwCzALin0sHXF7j7bpcL++zZs9GlSxfcsMVavnJFWtX/+AdQWAh88onp\n/owM4MkngXr1ZH/5/fuBRx+V78UaHTsCd90FfPSRzAayA+Wm5HRh1+mAV14BHntMBnr37ze5AVoT\ndiIyaQCmIIRwespjSkoKvv/+e0ycONGQrtiiRQsAppkxOp0OKSkplbbYq6Owb9q0CRqNBvfee6/J\ndovC/vXXsi32Z58BM2bI4P3PP1fVdBkHcVjYhRBDAKQTkdX16oQQE4UQ8UKI+Axz1quj9OsnfdAu\nWgSZiLBhwwYUFhZi3bp1FZ/w99/y30ceAR54APjoIyQdOYIVK1bI7dOmAVlZwKpV8qZkFDiskOnT\ngZQU4KefbD4lNzcXKSkpAJws7Hl5wPDhwJtvAmPGAD4+wObNBmHv0KGDZWHPyUH+Tz+hqKionMUO\nOD/lcfPmzdDpdHjmmWcM2xRhNw6gXrlyBcXFxV5lsW/atAn33HNPuZhBeHg4wsLCTAOoRMDSpTIp\noW1b2WivXTtg3DhpyTPVHmdY7D0BDBVCnAewGkBfIcQ3ZQ8ioiVEFEdEcXXr1nXCy5ZB8bO7yGo/\ndOgQrly5ApVKha+//rriExSLNTZWLuV37Rp2jh+PcePGIXPFCinor7wi99vL0KFAZCTwwQc2n3L8\n+HHD/20W9sxMuYC4JS5dksHen36SqZhffinF4OefkZiYiPDwcHTv3t2y1b1gAYIeegiPAGaFXbHY\nLZX8G5OVlYVZs2ZhwIABFn3cyvtu3LixYVtISAjq1q1rIuxlUx3toToGT5OSkpCUlFTODaPQqlUr\nU4t9zx7pW58wQf7u7w98+61skf3MM7wspQfgsLAT0WwiakREkQBGAvidiCxXcLiKmBjp1nCRsG/a\ntAlCCEybNg27d+82K1Y3b94sLU9PTATq15drtPbuDV1cHO5JSEAoAP8ZM6QF9NJLlZuMjw/w3HOy\nKMvGjAVj14hNriQAmD8fGDhQuorMMWkScOaMjBU8/7x86hg8GDh8GGkHDyImJgZRUVHIzMw0n4/+\nyy8AgCUAmpgZvlmzZsjLyzMUMJnj1q1bWLRoEaKiojB//nxs27YNaWlpcqfi3iooAADk5ORAo9HA\nz8/PZIyymTFli5PsoToGTzdv3gwAGDx4sNn9rVu3NhX2pUuB2rXltVOIjQX++1+5JOWXX7pyuowT\n8PwCJQUhgL59XZYZs2nTJnTv3h3Tp08HAEM5ujFPPfUUOnToIC3Dv/8utcaFwN8DBiCaCDsA+Gdl\nAcuWydTFyjJ+PBAYKC1lGzAWdpstdkXQn3++vD//55+BzZvlGrQDBpRu14tH02PHEBsba8hfL3cj\nvHYNiI9Hyt13wxfAHR98IFM+jWjXrh0A4G/FrVWG5ORkxMTEYNq0aejUqZMhxzwnJ0dalTNmAOvX\nA199ZdgeHBxcbpyWLVuatdiNc9htpTq6YjZt2oSYmBiLTyCtWrVCWlqavPlmZQHr1snsq7JtE6ZO\nBXr1Al54AdC3gWCqJ04VdiL6g4jMP+9VBe3aAZcvA7m5Th02LS0Nf/31F4YMGYImTZqgT58++Oqr\nr0xcBDt37sS6detw8+ZNrFu9Gjh+XM5Hz+fXryNFCHQA8IFajSKjfZUiJET6tFetAmxIX0xMTERM\nTAwAG4U9Lw+Ij5dN1v7+G1i8uHRfcbEUzVat5JfdmJgYlDRsiH5FRYiNjTWISTk/+/btABH+6tIF\nUwEEHTwolzw0on379gBkNo85li1bhnPnzmHTpk3Ytm0bevXqBUAv7Nu3A3/+CQQEAO+9B+h0yM7O\nNivsLVq0wOXLl5Gn7zd0/vx51K9fHwEBARVfpzJUN2HPzs7Grl27LLphgDIB1FWr5BOO4oYxRqUC\nPv9cZmWV/bsz1QrvsdgBmecNABWk19nLz/psAOXLMWbMGCQnJ2O/vg+8VqvFtGnT0KRJE7Rq1Qrb\nliyRXw69xU5E+HHTJqzu0gVp3bvjlVu3sHPnTscn1ru3FFkzBTZlSUxMRJcuXeDn52ebK+bPP6UF\n/fbbMn4xd25pAdiiRfI133+//FOHELjUoQPuBdCuZUvLFvuvvwKhoUj098dXAHSPPgq8+ipg1Gmw\nbt26uP3223H06FGzU0xISEBMTAwGDx4MIYRBtLOzsuSTRKNGwKefyrlu2oScnBzUqVOn3DhKAFVx\no1U2hx1wTNiLi4uxb98+m2IKtrJ161aUlJTYLuxLl8rMqzvusHSw/DutW+dR7S0qzfXr7p5BpfBO\nYT9zxqnDbtq0CY0bNza4Bh555BH4+/sbgqjLli3DkSNHMG/ePIwfPx63FL+3XtgPHTqEixcvot6U\nKQj+7TfA39/g93QIvQWOY8esHpaZmYm0tDTExsYiJCTENot9507py+/RQ7p7cnKQ/fzz+O+MGaA3\n3pAul0GDzJ4aHxGBIADts7IQEhKC0NBQU4udSAZl770XV69dw23h4VAtXiwLsZ54wuATB2RWjTmL\nnYhw8OBB3GEkQIqw++/dKwOAL70ki2uaNAEWLLDqigFKM2MMOeyffAJ06iSLxWzEkeDp119/jTvv\nvBMLFiyo1Pnm2LRpE8LCwtC9e3eLx0RFRcHHxwe5O3bImM0zz1jP0nrxRaBDB5nK66qaiOrArl0y\nRuaBbY1Z2CugsLAQv/76K4YMGWLoZRIcHIwHH3wQq1evRkZGBubMmYNevXphxIgRGD16NNopXwq9\n8G7YsAEqlQpDhgxBrVq10LdvX2zevNlxy6xVK/l4XIGwH9Pvt1vYO3eWhVIxMcBzz6H2qlXo+sEH\nKMnNxflp0yyeuqW4GIUAau/aBQBo3ry5qbAfOyZdZvfdV1qcFBoq4w7JyTJnWk+HDh1w/PjxcgHJ\nixcv4tq1a+jcubNhm2KNt16zRt4kxo+XdQHTpwO7dqFRWppZYVcWpD59+jRKSkpwITUV4y5fBp59\nVraqmDDB5kwQRyx25SnuxRdfxOrVqys1hjFarRY///wzBg0aBF8r9REajQbNmzdH1y1bpIvPSvdK\nAIBaLV0yV696d+HSkiXy775nj7tnYjfeJewhIUBYmFOFfefOncjPzy/3KDt27Fhcv34dAwcOxLVr\n17Bw4UIIIXD77bfj3nr1kOLjA53eR7thwwb07NkT4eHhAGR2wpkzZ8z2KLELf38gOrpCYVcCpzEx\nMQgNDa1Y2AsKgAMHZH69wmuvIVejwT0APvX3R6cRI7DVQipkwsmTOBoeLoOrkNktJsKunDdggKEB\nGADp8hk0SOZN691F7du3x61bt8oV0Bw8KMsmylrsfQDcnpwsrXV/f7lj/HggOBiPX7pkVtgDAwPR\noEEDJCUl4dLFi3hTq0X/nTulwL33npzv8uXWr5kek6yYkydl7reNawXs3r0b999/P+666y48+eST\n+MNSNpKNHDhwAJmZmVbdMApDIyIQd+WKFGoz7qpyxMXJIOrSpaU1G1VNfr50B7qi3UF2tmzCBwAW\nYjyVoco6aRJRlf907tyZXEaXLkT33uu04Z577jkKCAigmzdvmmy/desWRUREEAAaP368yb6shg3p\nB4C2b99O58+fJwA0f/58w35l24IFCxyaW1paGqX17EnUsqXV46ZMmUJ16tQhnU5HAwcOpC5dulgf\neMcOIoBo40bTcSIiKDEigs4dPUrt27cnlUpV7j2UlJSQv78/fde3rxzj1CmaNWsWaTQa0mq18qAB\nA4jatCEioujoaBo5cmTpAIcPEwlB9K9/ERFRYmIiAaCvv/7a5HXmzp1LKpWK8vPzDdt0Oh3tACg7\nKIiooMD0Pc2cSbcAmjN6tNm33KdPH+p155106YEHiABKfeABIq1W/tx9N1FwMFFqqvXrRkRTp06l\nkJAQ+cvIkfIa/PvfFZ53+fJlw2fi+vXr1LZtW6pTpw79/fffFZ5riQ8//JAA0KVLl6wfqNPR6caN\nKQ2gkuxs218gPZ1IpSJ65ZVKz9Eh5s+X13fGDOePvXSpHLtBA6JOnRweLj8/n2bMmEFCCNqwYUOl\nxwEQTzZorPcJ+8iRRM2aOWUonU5HkZGR9MADD5jdP2vWLAoJCaG0tLTSjYWFpPPxoXl+fjR69Gha\ntGgRAaCkpCSTc2NiYqhv374OzW/WrFn0BkA6laq8kBnRu3dv6tmzJxERjRw5klq0aGF94Ndfl+J6\n44ZhU35+Pgkh6PXXXyciory8PBo2bBgBoH379hmOS0pKIgC0bt48+fF6/3367LPPCABduHCB6OZN\nIn9/ounTiYiodu3aNG3aNNPXHzNGHnPhAt26dYs0Gg3NnDnT5JDBgwdTTExM6QatlujTT4kA+u6u\nu8q/p9RUKgZoV1yc2bc84ZlnaIW/PxFAbwJ02vjvdeYMUa1aRPfdR6TTWb10L7zwAgUGBhJdukTk\n6yvfR61a8ncrrFu3zuRapqSkUIMGDahRo0aUl5dn9VxLPP/88xQUFES6CuZM27YRAfQcQGfPnrXv\nRfr2JWrdulLzcwitligqSt5YVCqiAwdsO+/WLduO69lTGh8zZxJpNLafZ4Y//viDoqKiCABNmTKF\ncnJyKj2WrcLuXa4YQPrZU1Nln4sKSE1NxSeffIJvv/0WW7duRXx8PM6dO4fs7GwQEY4fP47z589b\nfJT9z3/+gzNnzphWTZ46BaHVIrRXL3z33XdYuXIl2rRpY8i8UBg8eDB27dolU/MqSWJiIo4BEDqd\nxdbARITExETE6gO51nzs+fn5Mmd8504ZHAsJMXpbp0BEaNu2LQDpvlixYgXCw8Px73//22ROABB5\nzz2yY+XmzYbMmLNnz8qAVGEhcN99KCgoQG5ubrk+MXjjDdl/5rXX4Ovri5iYGJkZs3cv8NprwJYt\nOB4fX+qG2bFDugamTEG8RoMtTcqXOxVFRGANgK5Hj8p2tGUYm5KCJwsLsb1zZ7wiBBobj9G8uSzO\n2bpVxgGuX5d99pVcfiP/u8HHvnixzCrasEF+Fl991ew1V9izZw/8/f3RqVMnALL3+6JFi3Dx4kWL\nefwVcfr0aURHR5v0uS8HEfDyyyisVw9LUAlXwfDh0uVkVNlcJWzfLl2uH30kCxMnTKj4O795syy8\nio+3ftzp09Kv/tRT8ntQXGxb6+0yaLVaTJ06FX369AER4ffff8cnn3yC2rVr2z2W3dii/s7+canF\nvmyZtBRPn67w0PHjxxMAsz8+Pj4UFBREAOjixYu2v/433xABdHjlSsNY/9K7FYzZuXMnAaD169fb\n8+5MiIyMpFj51SRaudLsMZcuXSIA9OGHHxIR0ezZs8nX19esFTd//nyq5etLuoAAojJW9Er9+0lM\nTDTZPm/ePAJAu3fvJiKiN954g4QQ0sp88UUiX1+6rHcJLF++XD42+/kR5ecbXFKff/55+YnPmCEt\nsWPH6F/DhtFGPz/5PvU/hQCltmhBNHCg3Na4MdE331C7mBh6+OGHyw2Xnp5OzQDKCg+XFtjSpaU7\n9Y/dKwBq26YNNWrUqPx8FJeM0RwMP99+azhs7ty55AeQrl49osGDS9+LEERHjpj5C0ni4uLo7rvv\nNtmmuKG+NRrfHqKjo2nEiBHWD/rhByKAsj/4gADQBx98YN+LXL4s35v+Sa7KeOghorp1iQoLib7/\nXv4d3nnH8vHp6UQREfK4SZOsjz1njvzsXbpEdPSo1e+XNTZt2kQAaPLkyZV+6ioLaqwrZudO+ba2\nbKnw0I4dO9I999xDJ0+epD179tCGDRto2bJl9O6779LLL79MkyZNonesfVjM8dJLRGo16QoLqWXL\nlgSA9u7dW+6wW7duUUhICI0bN86+8fUorpHaGg3dAqiojKtCYevWrQSAduzYQURE//3vfwmA2Q/a\n1KlT6U5FrL77zmTfnDlzyMfHh4qKiky25+XlUUREhMGtNGLECIqKipI7r14l6taNCKC3AXp1zhyi\nmBhDDGT//v0EgDaW8eUTEVFGhvRrN2tGJSoV5QKUO2sWUUYG7Xv9dXoXoLzmzYluu43o7beli4eI\nevToQf369Ss3XHJyMgGgVR9/LF0qyhd83ToilYpye/UiX/2NuFevXuYv+oUL0ve/YAHR2rVEe/cS\nde9OFBZGpHfHvfHGGzRKuYZbt8rzMjOJQkNlbMEMeXl55OPjQy+//HK57QDozTffND8fKxQXF5OP\njw/NmTPH8kElJfLv0aoV6YqLKSQkhCZPnmz3a1Hv3kTt2tl/XlmOHyd6+mkpwtZITZXCa2wwDRsm\n3V7mDDqdjmj4cHlD79GDKCTEsuuypISoUSOiQYPk70VFRGo10axZdr+dmTNnkp+fHxVYcZPaS80V\n9osX5dv6+GOrhxUUFJCvry/Nnj3bua8/eDBRbCwRES1dupR69OhBJSUlZg8dOXIk1atXr2IfqBkS\nEhIM1sBxgC537Wr2uPfee48AULr+y7J48WKLTyGPPfYYvaSIUpkv17Bhw6hVq1ZWX2PHjh3Utm1b\nevDBB0t3FhYSTZxIBNAJxWLSB5J/+uknAkD79+83/ybnzSPy8aGLQ4ZQPYC26oXy9ddfJyGEWV/l\noEGDzAaHDx48SADohx9+kF/e2bNLLe4uXaggI4OEEASAxowZY34+5jh+XD6BPPwwkU5Hb7/9Nu0D\nSNuypbTySy+SRYPj999/JwC0efPmcvsiIiLomWeesX0+ek6dOkUAaMWKFZYOkOIFEK1ZQ0RE3bp1\no3vuucfu16IPPiAlUF5pLlyQT10A0bPPWj927lz5lGAcD7h0iahOHaJ77pF/X2P0T9H0zjvyZgsQ\nWXpS1scblGtCREQdOsgnQzuJi4uju8zFexzAVmH3Ph/77bfLNLcKUh4TExNRUlJiki7nFBITDa0E\nnnnmGezZswc+Pj5mD+3duzeuXr2KS5cu2f0ySrfGSZMmIcnXF8LCupWJiYmIiIiA0lEzRO83N+dn\nz8jIwF0ALtSuLVdsMuLEiRNo06aN2deYPHkybr/9drz88stISkoy+PMBAH5+wOLFeLdVKzRX2jXf\ndx8AGJp7mevsCEB2xbx+Hf4rVuAqYKhAPXjwIFq2bGnWVxkcHGy24ZgSywgODpaFV2+9JfvIDB8O\nbN4M//BwQ28Yu5p/tWkjYwI//ACsWYPGV66gG4CiCRNkjYHCP/4hffXPPy+reT/+WPaw2bgRyevX\now6AO++8Ux579ar0zb/0Ej4nQlol0neVYquysR3k5gL/+pcsntu9W66SpG/2Va7Lo60MGyb//e47\n+88FZJHToEGl/y5ebLl6/NYtmUM/aBBgXB3coIFsSbFjB9C+PbBmjYzTXLwo6xF69JCfp379pEbo\n+weVY8UKGVsaOrR0W4cOdqc8ZmdnIyEhAX369LHrPKdhi/o7+8elFjsRUdu2RMZWoxmUTA27swCs\nkZ0t7/Y2Pjr/73//IwC0adMmu1/K2DWyPiaGSgAqMeNe6dq1q0n2za+//koA6H//+1+5YzvExFAO\nQF8FBZlsLy4urvDpRkmtA0CrVq0qt//pp5+m+267TVp3+ieUkSNHUnBwcDn3jjkaNmxIo/Wpio0a\nNaInnnjC7HETJkyg+vXrl9u+YcMGAkDx8fEWX6N///4EgJYtW1bhfEy4dYuoa1ei226js23bUjZA\n186dK3+AdgHlAAAgAElEQVTczz8TBQWVPimU/QkOJmrYsPR3X18igP4bFmbbPH79lWj8eKJFi+jL\nF18kAVBGRoZ0U/3yi8xEql9fjv3UU0RXrpic/tZbbxGAymVtdO9OdMcdJpu0Wq1ZN6QJBQVEd90l\n3R3bt0uffUAAkZm/b3FxMe2ePp3MpeISkfxcrV0rv/+AdDN17UoUGEiUnFx63MyZ8tqWdflkZcnX\nnjLFdPuCBWafYq2xefNmAkC///67zefYAmqsxQ7IzJgKrJyEhASEhoZWqjWrRZRCIRsbfCktCiz1\nQrHG8ePHER0dDY1Gg3r9+sEHQOL69SbH6HQ6HNN3WVSwZrHXu3IFtQFsLtMqNzk5GSUlJYaMGHM8\n88wzaNSoEQCYWux6mjdvjq2Zmbg5YQIgBFJTU7Fu3TpMmDABGhu6XCqtBdLT03Hx4kWLT1p16tSp\n2GK3gGLd2v2Z8PWVBUy5uWh2/DiWA7ilFEcZM2gQkJMjC2quXgVOn4Z2716MDQjA+u7dgbFjgXvu\nAd59V1rTOTk41bw5xl+/Dq21/j5nzwIPPyy7bK5aBTz/PMbOn490IXDbQw/Jor1Bg2TfnI4dZVbQ\n8uWyrbQRyudx79699r1/QC4ok5AAGPUE+uqrr9CjRw/LC6hrtbKR3a5dshWwYk1Pny77vx8+bHL4\nmjVrUPjBB8gLDzffzkII+fRx9Ki8DlqtLLRbsKC0Kh2Q17mkRFr1xkyfLjO2jBZiASCfAAC7rPY/\n/vgDGo3GaisHV+K9wn72rEkaWlmUPiNWU8HsxXhxDRuoU6cOIiMjKyXsxq6Rdo89BgA4WeZROCUl\nBfn5+TYJu06nw8N68dgFIN4oJezECblGuSVXDAD4+/tj3rx56Nixo6H3ijFKyqPS6/yjjz4CEWGq\njV0C27dvjxMnTmCfPlXRkrAHBwejoKCgXFm/LcKuvL8oYxGwlbZtgbffRrGfHz4CLPdkF0J2nIyI\nAKKjcSwwEF8XFKDgH/8APvxQLkn3z3/KBUwCAnD8scdwG4Dct94qP1ZRkVyspW1bYNs26eK5fh04\ndw7z2rbFvrAwiJISYPJk2fv++nX5b7duZqfWv39/hIWFYbmNVbYmmHHHLFu2DADMrzim08kUxfXr\npfA+/njpvlmzZIuJl182OSVzyRL0A7AuNFS60yzh4wOMHCm/j4mJwMSJpvvbtZPuFWN3zFdfSTfM\nK6+Ub4DWoYP8105h79atW6U6hDoFW8x6Z/+43BXz4Yfy0enyZbO7i4qKSKPR0MLRo+WxzqCkREbc\nb7vNNGhWAUOHDqU2+ipMWykqKiJfX9/SLIqiIrolBC0JDzc5TglOGj8OZ2RkEABatGiRybF5r71G\nBND+O+8kIQS99tprhn3/93//ZzGTxlb27dtnyIDJzc2lOnXq0KOPPmrz+atWrSIANGLECAJAN4yK\np4xZuHAhAaBr166ZbH/77bcJQLkKYmPy8/Npiw3ZVNb4ZskSAkDJxo/+Vvjkk08IAJ05c8bs/l9/\n/ZV+BKg4KEi6ChRKSmSmB0A0erRMGjCiadOmFt1V1pg6dSppNJpy188mOneWWVCFhXT+11/pPoCe\n8PGhZhERpVXHRPL7MW6cnLulqlylqvSPP4guXSLdww8TAXQYoNuEsC8F2RyKe+XECRkAr1VLprNa\nSHSg228nGjvW+pg6HdHRo5R94wapVCqaO3euY3M0A2psVgyR9GUCRGb8yESlGSUZLVvK4yx8qezi\nrbfkWGVK3yvilVdeIZVKZVdK1LFjxwgwLbO/Vq8e/WgkKGlpadS3b18SQlCWkSAUFxcTAHrjjTdK\nB/zqKyKAVgP07TffUJs2bWiwkoNNRE888QQ1bdrUrvdVlvT0dAJACxcuNPjjK/S/GnH8+HECQBqN\npjSd0gzLly83Gzuxlr/vTL799lsCQCdOnLDp+FGjRlH9+vUtzuv06dPUUfG5KyKo0xE995zc9v77\n5c4pKCgod3O2lcOHD5u98dvE22/LOQlhEju4BFDyzJlExcW2iTqRjAs0aiSrS4ODSevnR/8C6P9e\nfZUA2J+GXJYrV0inUlFi//6kjYmROfHWqoPvu09mx5QhMzNT/ufaNRnXAyizbVtqBdBvv/3m2BzN\nULOF/dQp+dYspHp9/vnnFGMctLKhl4dVDh6UwZgRIyosOS/L2rVrCQAdPHjQ5nPWr19fLhCYO2gQ\nnQbo/fffpx9++IHCw8PJ39+fPvvss3LnBwYG0gsvvCB/+flnIl9fun7HHaQBaNu2bTR27FiTNMxO\nnTrRwEqkexmj0+koMDCQpk6dStHR0dStWze7zr916xb5+fkZrHZLfPfddwSADh8+bLL92WefpTBb\ng5AOoLQGOHr0qE3HN23alIYPH25xf1FREQkh6Fjr1jK4mplJ9N//ys+t8jcsg1LYtLISRTVERJ07\nd6YOHTrYfxNMTyf6xz9I9+qrND0sjP7ZrRvl/fgj7VaEvkULg/jRq69WPJ5SbNi3L300fToJISg9\nPZ169epFrVu3dvgmndG1KxFAOiFKaw4sMWuWDPAaBfqPHDlCQgja8frr8iakVhM9+yzl+/tTIUBF\nr75qcrwzqDJhB9AYwA4AxwEcAzCtonNcLuxFRbKAwcKj0JQpU+hTjYZ0Gg1RXJzsLWOH+8SEmzdl\nT4kGDeSXzk6UfOPly5fbfI5Z18hrr5EWoHq1axMA6tSpEx07dszs+Q0bNqSnn35a3pBq1SLq2JF+\n/OorAkBHjhwxWNSpqamk1WopICCAZjih0VK7du0oNDSUANAa4zxhG+ncuXOF1tr27dsJAO3cudNk\n+5gxYygyMtLu17QXJfvGlhv1xYsXCfqbsTUaN25Ms4cMkZZw797ya/vYYxY/sz/88AMBoAO29k8p\nw8cff2w2gygzM5M++ugji3UZCsrfYPXq1UREdP+gQTQ+IoJ0MTFy7nPn2mYA6XTSTaLTUc+ePQ31\nCUuXLrVe/2Aje6dNIwJoRcOGFR+8cqWcu1H18Iply2guQCUAaaOiiPTXa2CnTrQ9PFwe3769LNRz\nErYKuzOCpyUA/klEbQF0B/CsEMJy+kRVoNEAjRtbzIw59tdfGKXTQQwfDkybJiP5u3dX7rVeegk4\ncUIGXsLC7D49KioKAQEBFpd/M8fx48fRtGlTBBqvSRkTAxWARnl5ePnll7Fv3z6LWSyhoaFyFaWZ\nM2XvjF9+wZX8fABy1aK4uDgAwF9//YWUlBQUFBRYzYixlebNm+PGjRto0qQJhinBNjvooA9iGfdg\nL4sSHC3bg8fSIhvORq1WA4BNPdmVFbh69Ohh9bjIyEjszs4GRoyQC5j36SOzSFTmv74Wc9ht5Ikn\nnoC/vz+++OILw7aCggI88MADeO655/D7779bPX/FihWoU6cOHnzwQQDA8EcewRfp6Ti8YoXsKfP6\n62YX8jhz5gy6dOmCM8r3VgigTRvcyMrCn3/+ifv09Q+PPvooAgICsGLFikq9P4W/27TBnQCevnSp\n4hbaSgDVKNGh8YoVeAPAKgBvDhsGdO6M3NxcbDt6FH9Mnizb/h49KvPuqxiHhZ2IrhBRgv7/uQBO\nAGjo6LiVYenSpejVqxe2b99uMeWxpKQELY4cQe2SEmDSJJkmFhRUuZXXf/tNLhP3/PNA//6VmrOP\njw9iY2Ptyow5ceJEeaHVL+qx7YMP8Oabb1pNIQwJCUHD8+dlMcesWUD9+ob0xvDwcHTs2BG+vr74\n66+/bMqIsRUlM2bq1KlWF36wRO/evREYGGhV2JXFNsqmPFa1sFvMijEiLS0NQMXplc2aNZNLC86f\nL2/GP/wgC78skJSUhLp16xoyoOwlJCQEw4cPx7fffouCggJotVqMHj0af/75J4QQ2G3FCMrJycF3\n332Hxx9/HP76lM+hQ4fCx8cH3/34oyzospCJtnv3bsTHxxsWJVf47bffoNPpMHDgQADybzxs2DCs\nWrUKhYWFlXqPAJCVnY19AEiIim8SLVtKg1ExwDZvRt9du7A+MBBbnngCby5ahLNnz2LPnj3QarWy\nMOnhh2V208qVVjP0XIFT0x2FEJEAOgHY78xxbeHWrVt47bXXsGfPHvTv3x9bz5yB1sxd+MSJExh3\n6xayb78duOsuuRL7o4/KNRztbdj/3ntyXc133nFo7u3bt8eRI0cU15ZVtFotTp48WV5oo6MBtRqh\nly9XOEZISAgeO3NGLvs1aRIAWXUaGhoKtVoNf39/tGvXDvHx8YYKV2cI+1133YUWLVrgmbJ5wjYy\nduxYXLhwAaGhoRaPsWSxW1rI2tnYY7ErKafm1mE1plmzZrh06RKKIiKkuFcg2KdPn660ta7w9NNP\nIzs7G99//z3++c9/4vvvv8eCBQvQsWNHq8K+du1aFBQU4KmnnjJsCw8Px913343vlYUrLJCamgoA\nWL16tUlHyy1btqBOnTroZpSm+eSTTyIrKwsbN26s5DuU19/X1xf3338/vvrqK2i1WssHq9XSeDpy\nRK7yNXo0TtaqheVdu+K/8+bB19cXL7zwAv744w+o1erSKuJRo+RTihMX67AFpwm7ECIIwHcAphNR\nuV60QoiJQoh4IUR8hlJa7kQ2btyIy5cvY82aNXjrrbew58oV+Ny4gbdnzzYRzDMbNqAngMKxY0st\nhyeflKXWP/xg+wveuCEXZH78cZmX7AAdOnQwrEtaESkpKSgsLCwvtGq1XCqvgtWUAKCjVoteOTly\nBRy9Oyc9Pd3QdgAAunTpYhD2evXqIawSbqayPPTQQ0hKSqq0JalSqayKOmDdFVORgDoDe4U9ICAA\nflasb0AKOxEZhK8inCHsffr0QbNmzTBt2jQsXLgQ06ZNw4wZM9CrVy/s37/f4vtbsWIF2rRpg65d\nu5psHzZsGE6cOGF4AjRHamoqQkJCULt2bYPVTkTYsmUL+vfvb/KU17dvXzRq1Mghd0yWfk3ecePG\n4dKlS/JJ3xodOsg1YYcNA1QqjPT1RZNWrdCwYUPMnTsXGzZswOeff46uXbuiVq1a8pxHH5UFbCtX\nVnqelcEpwi6EUEOK+koiMntbJqIlRBRHRHF1y/QhcQaffPIJmjRpguHDh2P27NmY8dFHAIC177yD\nr4wKEULXrUMRgPAZM0pP7t0biIy0zx3z44+yek3fZ8MR2usr22zxsytfDLM+75gYm4T9kVOnkCWE\n7KGhJyMjw6QvelxcHLKysvDLL784xVqvKgICAuDr6+t2V4ytwm7LTa6ZvifKOaOqTkvk5eXh8uXL\nZovE7EGlUmHcuHHIzMzEsGHDDAts9+rVC/n5+WY/q6dPn8aePXvw1FNPlSv8e/jhhwHAqtWekpKC\nli1bYubMmdiwYQMOHDiAY8eO4dKlSwY3jIKPjw/GjBmDrVu34sqVK5V6jzdu3EBoaCiGDBliW2FW\n+/bAtWtAYiJylizBkZwcw3q506dPR4sWLZCZmWnaH0apklUqYasIh4VdyL/gFwBOENF7jk/Jfk6d\nOoXffvsNkyZNMjTcCtUHAIe2bYtnn31WBkdu3kSnY8ews25d+Bg3nlKpZJnx9u2yaZAtrFsnbwb6\n13EEe1oLWHWNdOwoA8FXr1oeIDERHc6exSIi6IKCDJvNWeyA9AN7krALIRAcHOy24KkS23CXsCcn\nJwOofODUmBkzZuCzzz7DN998Y/he9ezZEwDMumPW6Ev0R40aVW5fgwYNcOedd1oV9tTUVDRp0gTT\np09HeHg45syZgy1btgCAIXBqzLhx46DVag0VrvaiXH8/Pz+MGjUKP/74o0wqsITyFPKf/+CUfiEW\npUrZz88PixYtgkqlwqCy7Q5GjQIuXZKtE6oIZ1jsPQGMAdBXCHFY/3O/E8a1mc8++wxqtRrjx48v\n3ai/4C88+CD8/f0xcuRIFH/8MYK1Wpzs3bv8IGPHygDHN99U/ILXr8sS7hEjLAaC7CEsLAyNGjWy\nSdhPnDiBevXqmXdJKB+oTZssD/DWWyj288MHAHJzcw2bMzIyTIQ9JibGEPxyRkZMVVK2X0xxcTEK\nCwurXfDUVmFv0KAB1Gq1TcLuaEaMMUFBQZg0aZJJWXzDhg3RrFkzs8K+fv169OjRAw0bms+dGDZs\nGBISEpCSklJun+JqatKkCWrXro3Zs2dj+/bteP/99xEbG2voQ2RMixYtcO+992Lx4sXW/eMWML7+\nTz31FIqKirB69WrLJ/ToIZ+IZ8823EAVix0ABg4ciOvXrxtufgYeeEAmaFShO8YZWTG7iUgQUXsi\n6qj/+dkZk7OF/Px8LF++HMOHDzdt/xocDISHo861a/jq008x6dAhaGbNwi4AIcYtORWiooBevaQ7\npqIgpuKGGTHCae+jQ4cONlvsFoW2fXugaVPgp5/M709KAtaswcm+fXEDMFgnOp0O165dM3HFqNVq\ndOzYEYBzAqdVSVmLXbmBeaorxsfHB02aNDH02bGGIuzGguNsevXqhd27d5vErpKTk3HkyBE88sgj\nFs/rrTeozLlxMjMzUVBQYGidPGXKFDRo0ACXL18u54YxZsqUKbhw4QI2b95s9/swvv6dOnVC+/bt\nrbtjhJB9eYQwpGQqmV4KZuM4tWpJv/z69bLJWBXg8U3AVq9ejezsbPzjH/8ovzMqCvjf/3D/K69g\nAoD/ArgXwB2W0uXGjJHrN1bk6167VvaCdmIvd6XJVVFRkcVjiMhqX3QIIftIb9tmPsPngw8AjQYX\n9XEBJSvj+vXr0Ol0KBv7UNwxni7stjQAcxauEHbAKOWxApKSktCgQQMEGbnZnE2vXr1w9erV0nxz\nAN/pm38NHz7c4nnKU4Ry8zFGCQw30bs4AgIC8Kp+ndjBgwdbHHPo0KFo0KABPv30Uzvfhen1F0Jg\n3Lhx+OuvvwzuTmskJyejQYMGpUHSihg1CsjOluvkVgEeLexEhE8++QSxsbHo1atX+QOioqRQ37yJ\nki1bsLpjR/gFBaF169bmBxw2TEawrT2OZWZKX7yT3DAK7du3R0lJCU5aWDADAK5cuYKcnBzrrpEH\nHwQKCuQcjcnPl26mESMQoM+bVoRdyVIqu6j0c889h3nz5uH222+3/w25kbKumJok7M7IiKkI5btm\n7I5Zv349unTpYhBmc4SFhSEsLMyssCvuGePzJ06ciPj4eKuLVfj6+mLChAnYunWrXCzdDpTgqYJy\nU9q6dWuF5yYnJ9v3VNS3r1x0u4rcMR4t7H/99RcSEhIwZcoU8+13J0+WLVCPHoXmvvuwdetW/P77\n75aLY8LDZaHR6tWW3TE//iij2050wwClmTHW3DE25ZTfdRdQp45cgceY1atlSufEiQYxUVwxSnFS\nWYu9ZcuWePHFF53b2rgKcKfFbmvwlIjsFvaMjAzk5eVZPa4qhL1169YICwszCHtKSgri4+OtumEU\nWrRoYfBPG1PWYgekFW2tGE1hwoQJUKlUWLx4sa1vAYWFhSgqKjK5/o0bN0aLFi0qrKwFZJWsXcLu\n6ytbCW/aJFeKcjEeLexvvvkmgoKCMHr0aPMH9O4tFy3Q35UjIiIM7gWLPP44kJIiFyMwx9q18kmg\nUycHZl6eli1bws/Pz6qw21QFqlYD998PbNxoml61ZIn0D/boYbBSKrLYPZXqYLFXFDxVesbbmluv\nZMZY87NnZWUhIyPD5cKuUqnQs2dPg7Db4oZRiI6OtuiKCQgIwG233Wb3fBo2bIihQ4di2bJlNlei\nKp/9sjfWvn37YufOnSgpKbF4bl5eHtLS0uzv2z96NFBcLCu+XYzHCvuGDRvw008/Ye7cuc79wj74\noCzXNueOuXZNthFwshsGkI+UMTExVnPZjx49irCwMNQvs/JNOYYOBTIyAH0vEhw+LFeSmTQJEKLc\nYhuKsLuivsAdeIKP3ZKwWMKWlEdFMB3NYbeFXr164dSpU8jIyMD69evRsWNHm4SuRYsWuHDhQjkB\nTk1NRdOmTSv9dDhlyhRcu3YN68usImYJa8Kem5uLgwcPWjxXiS3YHaDu3Ll0tSsX45HCnpeXh6lT\npyI2NhYzjAuNnEFwMDB4sLTMy6ZQrVsntzmhKMkcSmsBSyQkJNi26tOgQfLRT8mOWbJELvCtf7IJ\nDg6GEMLw4VZcMZWxlqojwcHBKC4uNgSiFeu9OlWe2ivsSj8Za8KuPNFVhbArKX3r1q3Dn3/+aZMb\nBpDCTkTl/OEpKSlW/fMV0a9fP0RHR9scRLV0/RV/vjV3TKWFXQjTBbhdiEcK++uvv44LFy5g8eLF\nhi+SUxk5EkhLA3buLN124YJcNqtLF1kI5AI6depkWNOzLMXFxUhMTLS4JJwJderIDoAbNpQGTR99\n1NB9UqVSITg42OBjz8jIQFhYmGuupRso2wjMGyz2iIgI1KpVy6qw79u3D7Vr10arVq1snG3liYuL\ng5+fH1577TUAsEvYgfKZMUoOe2VRqVSYPHky9u7da7VtgYLy2S9bDxIREYF27dpZFXYlRlCpJRSr\nCI8T9iNHjuD999/HhAkTKmx3WmkGD5YFBYo7pqREpisVF8uotouCiUqTI6WdqzHHjx9HcXGxbcIO\nSJfSyZPAG2/IoKm+2ZdCaGioicXuLW4YoHy/mJycHKhUKttT0xxACAFfX1+nC7sQApGRkVZ97Hv3\n7kX37t0NVaKuxM/PD126dEFGRgZiYmJsvpkoVq6xsBcWFuLq1asOCTsA3H+/rIs0Xq/XEtauf9++\nfbF7926LqcfJyckIDw+vkifAyuJRwq7T6TB58mSEhYXhHQc7KlqlVi0pjOvXSzH/v/+TfbA//RRw\nYWCqY8eO0Gg0OHDgQLl9CQkJAKRVbxMPPCD/nT/fEDQ1JiQkxMTH7i2BU8C8xa64n6oCtVpdYfDU\nXmEHrKc85uTk4O+//3adsWMGJe3RVmsdkAbFbbfdZiLsyhOqUpxUWaKjo6HRaJCoLCpvhYqEvbCw\n0LBwelnszohxAx4l7EuXLsW+ffuwYMECp3QbtMrIkbKD4yuvAP/5j+wAaSn7xkn4+fmhY8eOZi32\nQ4cOISgoyPYPVNOm0mVEJFdpLyNqISEhJumO3m6xV4UbRkGtVjvdYgdKhd1ce+cDBw5Ap9NVqbAP\nGTIEAQEBePzxx+06r2zKo7kc9sqgVqvRunVrh4X9rrvugkqlsuiOsTuH3Q14lLAXFRVh8ODBltMb\nncmAATJNcv582etc3y3S1XTr1g3x8fHlel8kJCSgU6dOUFlYNccsI0fKYPCYMeV2GbtiyvaJ8XQU\nES9rsVcV9gi7PY/zzZo1Q05OjtlGVXv37oUQwqRnuavp2bMncnNz7fbpt2jRwsRiN5fDXlliYmJw\nzIYOpzdu3IC/v7+hH5IxISEh6Ny5s1lhLyoqwoULF6q1fx3wMGF//vnnsXHjxqp5pNZoZFqjRgOs\nWSN97lVA165dkZ+fb/Lh1Gq1OHz4sO1uGIWZM2VOvpmnG8UVo9VqkZmZ6ZWumOpusVsSFksoXUDN\nNeDau3cvYmNjq9zvWxl/fnR0NC5cuICCggIAUtiFEBabh9lDbGwsUlJSTBrcmaOi4rC+ffti3759\nyNcvGamgPDGxxe5kqrQKcv58IDHRZVkw5jAXQE1KSsLNmzdtD5wq+PhYXG1HEXZLfWI8GXe7YjQa\njU3Cbu+CI3369EFoaCjWrVtnsl2n0+HPP/+sUjeMIyiZMUrKY2pqKurXr1/hgiO2EBsbCwAV9nux\nRdhLSkrK3UTNdXWsjnicsFcptWu7NFhqjujoaISFhZkEUA8dOgQA9gu7FUJCQgyLMgDeU3UKeI4r\nxl5hV6vVePjhh/HTTz+ZZGwcP34cOTk5HifsijtGKU5yBjH6tX8r8rNXdP179uwJtVpdzh3Dws5U\nCiEEunbtamKxJyQkwM/Pz3Lzskqg5O8qXy5vstj9/Pzg5+fnVleMLVkxlVki8NFHH0VOTg5+/fVX\nw7a9e/cCgMcIe9mUR0eLk4xp1qwZAgICHBb2wMBAdO/evZywnzlzBsHBwdW+mI+FvRrSrVs3HDt2\nzNDwKSEhAe3bt3dqAZHyofZGYQek1a5Y7NnZ2VXqe3aVxQ7ICsuy7pi9e/eibt261T6gpxASEoLw\n8HCcPn3aZIENZ6BSqWwKoJbt7GiOvn37IiEhwSRYrWTEVPfGeCzs1ZBu3bpBp9MhPj4eRIRDhw45\n1Q0DlAp7UlISAO9yxQAygJqTk4OSkhLcvHnTK1wxytgPPfQQNmzYYHDH7N27Fz179qz2YmOMkvKY\nkZGBoqIipwk7IN0xjlrsgCx40ul0GDhwoCEe4AmpjoDzFrMeKIQ4JYRIFkK85IwxazJKB8r9+/fj\n/PnzyMrKsj8jpgLKCnt1f7S0F6URWFWunqTgSmEHTN0xGRkZOH36tMe4YRSUlEcl1dFZPnZABlCv\nXLmC69evm91va8vkrl27Yv369UhKSkKnTp2wcuVKnD9/3iOejJyxmLUPgI8BDALQFsDjQgjPWiSz\nmhEeHo6oqCgcOHDAUHHqbIvd2Md+2223We5R76EorXursk+MQkVZMfb2Yi+LsTvmzz//BOA5/nWF\n6OhoXLx40bCwjLMtdgAW3TE3b95ESUmJTdd/+PDhOHz4MGJiYjB69GiUlJTUGIu9K4BkIjpLRMUA\nVgN40Anj1mi6deuG/fv349ChQ/Dx8THkMDsL5UPtbcVJCorF7g5hryh4qvRir6ywazQagztmx44d\nUKvVNi1IUZ1QMmN26HuTO1PYlZRHS+4Ye6t+mzZtip07d+Lll19GrVq1qrQIrLI4Q9gbArhg9PtF\n/TbGAbp164ZLly5h48aNiImJsauQxRaMP9TeKuzustgrcsVUpp1AWRR3zJIlS9C5c2enfz5cjSLs\nv/32GwIDAysMZNpDo0aNEBwcbNFit9TZ0RpqtRpvvvkm8vLyDE8E1ZkqC54KISYKIeKFEPHKwg6M\nZRSr4OjRo073rwMynUtxv3hb4BQoDZ56q7D369cPISEhuHnzpse5YYDSlMeUlBSHFtgwhxDCagDV\nkeLKO4wAAA/JSURBVOvvKQFqZwj7JQCNjX5vpN9mAhEtIaI4IorzRgvR2SidHgHn+9cB+QFVPtje\n+PdQXDFKymN1EnZlTo4Iu+KOATzPvw7IG6/yuXOmG0YhNjYWiYmJZhumOePGWt1xhrD/BaCFEKKZ\nEEIDYCSAn5wwbo1G6fQIuEbYgdIPtrda7FqtFmlpaQCqV/DUWcIyefJktGvXzrDqj6ehuGNcJeyZ\nmZmG1cGMYWG3ASIqAfAcgK0ATgBYS0QVt1djKqR79+5QqVTo0KGDS8b3dosdKO31XZ2Cp5Xp7GiO\nbt264ejRox6bqupKYbfWWqAyPnZPwyk+diL6mYhaElEUEb3pjDEZ4OWXX8aWLVtQu3Ztl4yvfLC9\nWdgvXLgAIQSCqqg7J1A1PnZvwNUWO2A+5dFZN9bqDFeeVmPq1auH/v37u2x8b3fFAFLYa9eubV8f\newdhYbcNRdiVhbqdSUREBMLDw81a7FlZWQgMDPSaNX7NwcJeg6kprpiqdMMAtgm7n5+fx6UoOpsH\nH3wQixcvdknw11pmjCPFYZ4CC3sNRnHFeLPFfvny5SoXdluCp94uLLbg5+eHiRMnumzx7djYWBw7\ndqxcZkxNuP4s7DWYDh06IDo62mODb9ZQxFyr1VZLi93bhaU6EBMTg5ycHEMAXcGWzo6eDgt7DeaJ\nJ57A6dOnXWYxuRNjMXeHsFeUFcPC7nostRaoCdefhZ3xStwt7DqdDjqdzuz+miAs1QEWdobxMnx9\nfVGrVi0A7hF2ABbdMTVBWKoDoaGhaNiwIQs7w3gTSgDVHcFTgIW9OqC0FlDQ6XTIzs72+uvPws54\nLYqgVyeL3dFe7Ix9xMbG4vjx49BqtQCA3Nxc6HQ6Dp4yjKfibmE3F0AtLCxEcXExC3sVERsbi8LC\nQpw5cwZAzSkOY2FnvBbFFVPVpePWLPaaIizVhbIB1Jpy/VnYGa/F3RY7C7v7adu2LYQQLOwM4y24\nK3jKwl59qFWrFqKioljYGcZbcJfFbi0rpqYIS3XCODOmJrTsBVjYGS/G3a4Yc8FTFvaqJzY2FklJ\nSSgqKqox15+FnfFa2BXDAFLYtVotTp48abj+Vf2ZqGpY2BmvZcCAARg1ahQaNGhQpa/Lwl69MM6M\nycrKQnBwsFf2RzLGIWEXQswXQpwUQhwVQvwghOBPK1NtaNeuHb755hv4+vpW6etWJOzci71qadmy\nJdRqNRITE2tEZ0fAcYt9G4BYImoPIAnAbMenxDCeTUXBU7bWqxa1Wo3WrVsbLPaacP0dEnYi+lW/\nmDUA7APQyPEpMYxnU5HFXhOEpboRGxuLv//+u8Zcf2f62J8G8IsTx2MYj6SirBhvXkS5uhIbG4uU\nlBSkpqaysAOAEGK7ECLRzM+DRsfMAVACYKWVcSYKIeKFEPEZGRnOmT3DVEPYYq9+KAHU8+fP14jr\nX2FUiYjutbZfCPEUgCEA+lHZxQVNx1kCYAkAxMXFWTyOYTydioQ9MjKyimfEKMIOeH9xEuB4VsxA\nALMADCWim86ZEsN4Nhw8rX5ERkYiMDAQQM1INXXUx/4RgNoAtgkhDgshPnPCnBjGo7FksXMvdveh\nUqkQExMDoGYIu0MJvkQU7ayJMIy3YCl4yr3Y3UtsbCwOHDhQI64/V54yjJOxZLFz1al7UfzsNeH6\ns7AzjJNhYa+edOvWDQDQtGlTN8/E9VRtrTXD1AAsBU+zs7MBsLC7ix49euDs2bNo1qyZu6ficthi\nZxgnwxZ79aUmiDrAws4wTkelUkGlUpULnrKwM1UFCzvDuAC1Wm3RFePtvcAZ98PCzjAuwJyw5+bm\nAgBq167tjikxNQgWdoZxAdaEPSgoyB1TYmoQLOwM4wI0Go1ZYQ8MDIRKxV87xrXwJ4xhXIBarS4X\nPM3NzWU3DFMlsLAzjAuw5IphYWeqAhZ2hnEBLOyMO2FhZxgXwMLOuBMWdoZxAZaCpyzsTFXAws4w\nLoAtdsadsLAzjAvgrBjGnbCwM4wLYIudcSdOEXYhxD+FECSECHfGeAzj6ZQV9pKSEhQUFLCwM1WC\nw8IuhGgMYACAVMenwzDeQdngaV5eHgDuE8NUDc6w2N8HMAsAOWEshvEKylrs3ACMqUocEnYhxIMA\nLhHRESfNh2G8grLBUxZ2piqpcGk8IcR2APXN7JoD4GVIN0yFCCEmApgIAE2aNLFjigzjebDFzriT\nCoWdiO41t10I0Q5AMwBHhBAA0AhAghCiKxGlmRlnCYAlABAXF8duG8arYWFn3EmlF7Mmor8BRCi/\nCyHOA4gjomtOmBfDeDQs7Iw74Tx2hnEBZbNiWNiZqqTSFntZiCjSWWMxjKfDwVPGnbDFzjAugF0x\njDthYWcYF2BO2FUqFQICAtw4K6amwMLOMC5ArVajpKQERDIBTOkTo88gYxiXwsLOMC5Ao9EAkD1i\nAG4AxlQtLOwM4wLUajUAGNwxLOxMVcLCzjAuQBF2JTOGhZ2pSljYGcYFsMXOuBMWdoZxASzsjDth\nYWcYF6AET1nYGXfAws4wLoAtdsadsLAzjAvg4CnjTljYGcYFGFvsRUVFuHXrFgs7U2WwsDOMCzAW\ndu4Tw1Q1LOwM4wKMg6cs7ExVw8LOMC6ALXbGnbCwM4wLMA6esrAzVY3TFtpgGKYUY4tdaQTGws5U\nFQ5b7EKIqUKIk0KIY0KIec6YFMN4OuyKYdyJQxa7EOIeAA8C6EBERUKIiIrOYZiaAAs7404ctdin\nAHiHiIoAgIjSHZ8Sw3g+nBXDuBNHhb0lgN5CiP1CiJ1CiC7OmBTDeDpssTPupEJXjBBiO4D6ZnbN\n0Z8fBqA7gC4A1gohmpOyHpjpOBMBTASAJk2aODJnhqn2lM2K0Wg0BiueYVxNhcJORPda2ieEmALg\ne72QHxBC6ACEA8gwM84SAEsAIC4urpzwM4w3UdZiZ2udqUocdcX8COAeABBCtASgAXDN0UkxjKfD\nws64E0fz2JcBWCaESARQDOBJc24YhqlplA2esrAzVYlDwk5ExQBGO2kuDOM1sMXOuBNuKcAwLqBs\n8JSFnalKWNgZxgX4+PgAYIudcQ8s7AzjAoQQUKvVLOyMW2BhZxgXodFoWNgZt8DCzjAuQq1Wo7i4\nGHl5eSzsTJXCws4wLkKtViM7Oxs6nY6FnalSWNgZxkWo1Wpcv34dAPeJYaoWFnaGcRFqtRo3btwA\nwMLOVC0s7AzjIjQaDVvsjFtgYWcYF8GuGMZdsLAzjItQq9XIzMwEwMLOVC0s7AzjItRqNS9kzbgF\nFnaGcRFKvxiAhZ2pWljYGcZFsLAz7oKFnWFchPFSeEFBQW6cCVPTYGFnGBehWOy1atUydHtkmKqA\nhZ1hXIQi7OyGYaoah4RdCNFRCLFPCHFYCBEvhOjqrIkxjKfDws64C0ct9nkAXieijgBe1f/OMAxY\n2Bn34aiwE4Bg/f/rALjs4HgM4zUowVMWdqaqcWgxawDTAWwVQrwLeZPo4fiUGMY7YIudcRcVCrsQ\nYjuA+mZ2zQHQD8AMIvpOCDECwBcA7rUwzkQAEwGgSZMmlZ4ww3gKLOyMu6hQ2InIrFADgBDiKwDT\n9L+uA/C5lXGWAFgCAHFxcWTfNBnG82BhZ9yFoz72ywDu1v+/L4DTDo7HMF4DCzvjLhz1sU8AsFAI\n4QugEHpXC8MwHDxl3IdDwk5EuwF0dtJcGMarYIudcRdcecowLoKFnXEXLOwM4yJY2Bl3wcLOMC6C\nhZ1xFyzsDOMiWNgZd8HCzjAugrNiGHfBws4wLoKFnXEXLOwM4yIGDRqEOXPmICoqyt1TYWoYgqjq\nq/vj4uIoPj6+yl+XYRjGkxFCHCSiuIqOY4udYRjGy2BhZxiG8TJY2BmGYbwMFnaGYRgvg4WdYRjG\ny2BhZxiG8TJY2BmGYbwMFnaGYRgvwy0FSkKIDAAplTw9HMA1J07H2fD8HIPn5xg8P8epznNsSkR1\nKzrILcLuCEKIeFsqr9wFz88xeH6OwfNzHE+YY0WwK4ZhGMbLYGFnGIbxMjxR2Je4ewIVwPNzDJ6f\nY/D8HMcT5mgVj/OxMwzDMNbxRIudYRiGsYJHCbsQYqAQ4pQQIlkI8VI1mM8yIUS6ECLRaFuYEGKb\nEOK0/t9QN86vsRBihxDiuBDimBBiWnWaoxDCXwhxQAjx/+2bTYiVVRjHf3+cjJrC6QsZmmCMRJlF\njgamJFFGoRKuWiQtXAhtXCQE0RAELd1ULsSNUZuwyL5kFn1NrVpM+THW1DR94IAj6ogkQkFk/V2c\nc+nlIuHVxTn38vzgcM95zl38eJ97n/u+z/ve49nvlRxfJmky5/ldSYtL+DU8F0k6Jmm8Nj9Jc5K+\nlzQl6XCOVZHf7DIg6aCknyTNSFpfi5+kFfm4tcZFSbtq8bseuqawS1oE7AU2AyPANkkjZa14C9jU\nFnsRmLC9HJjI61JcAp63PQKsA3bmY1aL41/ARturgFFgk6R1wG7gNdv3Ab8DOwr5tXgOmGmsa/N7\n1PZo4xG9WvILsAf4xPZKYBXpOFbhZ3s2H7dR4AHgT+DDWvyuC9tdMYD1wKeN9RgwVoHXMDDdWM8C\ng3k+CMyWdmy4fQw8XqMjcDNwFHiQ9OeQvivlvYDXEOnLvREYB1SZ3xxwZ1usivwCS4AT5Ht5tfm1\nOT0BfF2rX6eja87YgbuBk431fI7VxlLbp/P8DLC0pEwLScPAamCSihxzm2MKWAA+B34DLti+lN9S\nOs+vAy8A/+b1HdTlZ+AzSUckPZtjteR3GXAOeDO3svZL6q/Ir8nTwIE8r9GvI7qpsHcdTj/5xR87\nknQL8D6wy/bF5l5pR9v/OF0KDwFrgZWlXNqR9CSwYPtIaZf/YYPtNaQW5U5JDzc3C+e3D1gD7LO9\nGviDtrZG6c8fQL5HshV4r32vBr9roZsK+yngnsZ6KMdq46ykQYD8ulBSRtINpKL+tu0PcrgqRwDb\nF4CvSK2NAUl9eatknh8CtkqaA94htWP2UI8ftk/l1wVSf3gt9eR3Hpi3PZnXB0mFvha/FpuBo7bP\n5nVtfh3TTYX9W2B5fiJhMenS6VBhpytxCNie59tJfe0iSBLwBjBj+9XGVhWOku6SNJDnN5H6/zOk\nAv9UaT/bY7aHbA+TPm9f2n6mFj9J/ZJubc1JfeJpKsmv7TPASUkrcugx4Ecq8Wuwjf/aMFCfX+eU\nbvJ3eINjC/AzqQ/7UgU+B4DTwN+ks5MdpB7sBPAL8AVwe0G/DaTLyO+AqTy21OII3A8cy37TwMs5\nfi/wDfAr6fL4xgpy/QgwXpNf9jiexw+t70Qt+c0uo8DhnOOPgNsq8+sHzgNLGrFq/K51xD9PgyAI\neoxuasUEQRAEV0EU9iAIgh4jCnsQBEGPEYU9CIKgx4jCHgRB0GNEYQ+CIOgxorAHQRD0GFHYgyAI\neozLwHjiZg31yIEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd69ebe0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: updating scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_update, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating scheme RMSE: 2.50451434543 \n",
      "Updating scheme MAE:  1.78224002686\n"
     ]
    }
   ],
   "source": [
    "rmse_update = np.sqrt(np.mean((yhat_update-test_target)**2))\n",
    "mae_update = np.mean(np.abs((yhat_update-test_target)))\n",
    "print(\"Updating scheme RMSE:\", rmse_update,\n",
    "     \"\\nUpdating scheme MAE: \", mae_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + \"yhat_test_fixed.csv\", yhat_test_fixed)\n",
    "np.savetxt(MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + \"yhat_update.csv\", yhat_update)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
