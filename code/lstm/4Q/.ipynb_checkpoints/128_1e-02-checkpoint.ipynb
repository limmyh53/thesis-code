{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Directories\n",
    "MODEL_FOLDER = \"../../../models/lstm/\"\n",
    "MODEL_FILENAME = MODEL_FOLDER + \"4Q/128_units/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: model saver\n",
    "def saveModel(sess, MODEL_FILENAME):\n",
    "    if not os.path.exists(MODEL_FOLDER):\n",
    "        print('Creating path where to save model: ' + MODEL_FOLDER)\n",
    "        os.mkdir(MODEL_FOLDER)\n",
    "\n",
    "    #print('Saving model at: ' + MODEL_FILENAME)\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, MODEL_FILENAME)\n",
    "    #print('Model successfully saved.\\n')\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: model loader\n",
    "def loadModel(sess, MODEL_FILENAME):\n",
    "    if os.path.exists(MODEL_FILENAME + \".index\"):\n",
    "        print('Loading save model from: ' + MODEL_FILENAME)\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, MODEL_FILENAME)\n",
    "        print('Model successfully loaded.\\n')\n",
    "        return True\n",
    "    else:\n",
    "        print('Model file <<' + MODEL_FILENAME + '>> does not exists!')\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Hyperparameters\n",
    "epochs = 500\n",
    "learning_rate = 1e-2\n",
    "batch_size = 5\n",
    "early_stop_iters = 10\n",
    "folds = 32\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 3  # data input\n",
    "n_steps = 4  # timesteps\n",
    "n_hidden = 128 # dimension of recurrent unit\n",
    "\n",
    "# (REPRODUCIBILITY) set random seeds\n",
    "tf.set_random_seed(123)\n",
    "\n",
    "# Define weights and biases\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.truncated_normal([n_hidden, 1], stddev = 1.0 / tf.sqrt(float(n_hidden))),\n",
    "        name='out_weight')\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.zeros([1]),\n",
    "        name='out_bias')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: Build model\n",
    "def RNN(X, weights, biases, n_hidden):\n",
    "\n",
    "    # Define a LSTM cell with tensorflow\n",
    "    lstm_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden, state_is_tuple=True)\n",
    "    outputs, _ = tf.nn.dynamic_rnn(lstm_cell, X, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    out_layer = tf.matmul(outputs[:,-1,:], weights['out']) + biases['out']\n",
    "\n",
    "    return out_layer\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: select batch\n",
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the data...\n",
      "Finished: data loaded. Stats below: \n",
      "Nr of training samples: 193\n",
      "Nr of testing  samples: 77\n",
      "Number of variables: 3\n",
      "Number of lags: 4\n",
      "Window length: 65\n",
      "Number of validation folds: 32\n"
     ]
    }
   ],
   "source": [
    "# =================================\n",
    "# 0. Load dataset\n",
    "# =================================\n",
    "print(\"Loading the data...\")\n",
    "# Training set pre-processing\n",
    "train = pd.read_csv('../../../Data/train.csv')\n",
    "train_4lag_inflation = np.array(train[['inflation.lag4',\n",
    "                                       'inflation.lag5',\n",
    "                                       'inflation.lag6',\n",
    "                                       'inflation.lag7']])\n",
    "train_4lag_unemp = np.array(train[['unemp.lag4',\n",
    "                                   'unemp.lag5',\n",
    "                                   'unemp.lag6',\n",
    "                                   'unemp.lag7']])\n",
    "train_4lag_oil = np.array(train[['oil.lag4',\n",
    "                                 'oil.lag5',\n",
    "                                 'oil.lag6',\n",
    "                                 'oil.lag7']])\n",
    "train_features = np.concatenate((train_4lag_inflation[:,:,np.newaxis], \n",
    "\t                             train_4lag_unemp[:,:,np.newaxis],\n",
    "\t                             train_4lag_oil[:,:,np.newaxis]),\n",
    "\t                             axis=2)\n",
    "train_target = np.array(train['inflation.target'])\n",
    "\n",
    "# Test set pre-processing\n",
    "test = pd.read_csv('../../../Data/test.csv')\n",
    "test_4lag_inflation = np.array(test[['inflation.lag4',\n",
    "                                     'inflation.lag5',\n",
    "                                     'inflation.lag6',\n",
    "                                     'inflation.lag7']])\n",
    "test_4lag_unemp = np.array(test[['unemp.lag4',\n",
    "                                 'unemp.lag5',\n",
    "                                 'unemp.lag6',\n",
    "                                 'unemp.lag7']])\n",
    "test_4lag_oil = np.array(test[['oil.lag4',\n",
    "                               'oil.lag5',\n",
    "                               'oil.lag6',\n",
    "                               'oil.lag7']])\n",
    "test_features = np.concatenate((test_4lag_inflation[:,:,np.newaxis], \n",
    "\t                            test_4lag_unemp[:,:,np.newaxis],\n",
    "\t                            test_4lag_oil[:,:,np.newaxis]),\n",
    "\t                            axis=2)\n",
    "test_target = np.array(test['inflation.target'])\n",
    "\n",
    "(nrTrainSamples, timesteps, variables) = train_features.shape\n",
    "(nrTestSamples, _, _) = test_features.shape\n",
    "\n",
    "# Window length and validation fold index\n",
    "window_length = 65\n",
    "valIndex = np.linspace(start=window_length, stop=nrTrainSamples, \n",
    "                       endpoint=True, num=folds+1, dtype=np.int)\n",
    "\n",
    "print(\"Finished: data loaded. Stats below: \")\n",
    "print(\"Nr of training samples: %d\" % nrTrainSamples)\n",
    "print(\"Nr of testing  samples: %d\" % nrTestSamples)\n",
    "print(\"Number of variables: %d\" % variables)\n",
    "print(\"Number of lags: %d\" % timesteps)\n",
    "print(\"Window length: %d\" % window_length)\n",
    "print(\"Number of validation folds: %d\" % folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 1. Build model\n",
    "# ==================================\n",
    "# tf graph input\n",
    "x = tf.placeholder(\"float\", [None, n_steps, n_input], name='Batch')\n",
    "y = tf.placeholder(\"float\", name='True_labels_of_batch')\n",
    "lr = tf.placeholder(\"float\", name='Learning_rate')\n",
    "\n",
    "# Make predictions with the model\n",
    "pred = RNN(x, weights, biases, n_hidden)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss = tf.reduce_mean(tf.diag_part(tf.square(tf.subtract(x=pred, y=y))))\n",
    "optimizer = tf.train.GradientDescentOptimizer(lr).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training \n",
      "Hyperparameters: \n",
      "Dimension of recurrent unit = 128 \n",
      "Learning rate = 0.01 \n",
      "Epochs = 500 \n",
      "Batch size = 5 \n",
      "Early stopping epochs = 10 \n",
      "Learning rate = 0.01\n",
      "Fold: 1  Epoch: 1  Training loss = 2.5798  Validation loss = 1.4007  \n",
      "\n",
      "Fold: 1  Epoch: 2  Training loss = 2.5064  Validation loss = 1.5324  \n",
      "\n",
      "Fold: 1  Epoch: 3  Training loss = 2.4367  Validation loss = 1.5599  \n",
      "\n",
      "Fold: 1  Epoch: 4  Training loss = 2.5100  Validation loss = 2.1621  \n",
      "\n",
      "Fold: 1  Epoch: 5  Training loss = 2.6366  Validation loss = 0.5161  \n",
      "\n",
      "Fold: 1  Epoch: 6  Training loss = 2.4041  Validation loss = 1.6017  \n",
      "\n",
      "Fold: 1  Epoch: 7  Training loss = 2.4079  Validation loss = 2.2012  \n",
      "\n",
      "Fold: 1  Epoch: 8  Training loss = 2.3186  Validation loss = 1.9050  \n",
      "\n",
      "Fold: 1  Epoch: 9  Training loss = 2.3587  Validation loss = 2.1122  \n",
      "\n",
      "Fold: 1  Epoch: 10  Training loss = 2.3846  Validation loss = 2.0954  \n",
      "\n",
      "Fold: 1  Epoch: 11  Training loss = 2.6936  Validation loss = 0.5181  \n",
      "\n",
      "Fold: 1  Epoch: 12  Training loss = 2.2977  Validation loss = 1.9927  \n",
      "\n",
      "Fold: 1  Epoch: 13  Training loss = 2.3228  Validation loss = 1.2721  \n",
      "\n",
      "Fold: 1  Epoch: 14  Training loss = 2.2252  Validation loss = 1.7266  \n",
      "\n",
      "Fold: 1  Epoch: 15  Training loss = 2.1868  Validation loss = 2.0979  \n",
      "\n",
      "Fold: 1  Epoch: 16  Training loss = 2.2714  Validation loss = 2.2881  \n",
      "\n",
      "Check model:  Fold: 1  Optimal epoch: 5  \n",
      "\n",
      "Fold: 2  Epoch: 1  Training loss = 2.2020  Validation loss = 2.0633  \n",
      "\n",
      "Fold: 2  Epoch: 2  Training loss = 2.1951  Validation loss = 2.2215  \n",
      "\n",
      "Fold: 2  Epoch: 3  Training loss = 2.4299  Validation loss = 1.9841  \n",
      "\n",
      "Fold: 2  Epoch: 4  Training loss = 2.1851  Validation loss = 2.3548  \n",
      "\n",
      "Fold: 2  Epoch: 5  Training loss = 2.1051  Validation loss = 2.2175  \n",
      "\n",
      "Fold: 2  Epoch: 6  Training loss = 2.1460  Validation loss = 2.0688  \n",
      "\n",
      "Fold: 2  Epoch: 7  Training loss = 2.7118  Validation loss = 2.0598  \n",
      "\n",
      "Fold: 2  Epoch: 8  Training loss = 2.0911  Validation loss = 2.3895  \n",
      "\n",
      "Fold: 2  Epoch: 9  Training loss = 2.1965  Validation loss = 2.0648  \n",
      "\n",
      "Fold: 2  Epoch: 10  Training loss = 2.1252  Validation loss = 2.2501  \n",
      "\n",
      "Fold: 2  Epoch: 11  Training loss = 2.0766  Validation loss = 2.1151  \n",
      "\n",
      "Fold: 2  Epoch: 12  Training loss = 2.0425  Validation loss = 1.8181  \n",
      "\n",
      "Fold: 2  Epoch: 13  Training loss = 2.0658  Validation loss = 2.1082  \n",
      "\n",
      "Fold: 2  Epoch: 14  Training loss = 1.9841  Validation loss = 2.1919  \n",
      "\n",
      "Fold: 2  Epoch: 15  Training loss = 2.0107  Validation loss = 1.8387  \n",
      "\n",
      "Fold: 2  Epoch: 16  Training loss = 2.0583  Validation loss = 2.0427  \n",
      "\n",
      "Fold: 2  Epoch: 17  Training loss = 2.0308  Validation loss = 2.0225  \n",
      "\n",
      "Fold: 2  Epoch: 18  Training loss = 2.2856  Validation loss = 2.3390  \n",
      "\n",
      "Check model:  Fold: 2  Optimal epoch: 12  \n",
      "\n",
      "Fold: 3  Epoch: 1  Training loss = 1.3686  Validation loss = 3.3490  \n",
      "\n",
      "Fold: 3  Epoch: 2  Training loss = 1.3757  Validation loss = 3.1702  \n",
      "\n",
      "Fold: 3  Epoch: 3  Training loss = 1.2919  Validation loss = 3.1503  \n",
      "\n",
      "Fold: 3  Epoch: 4  Training loss = 1.3330  Validation loss = 2.9467  \n",
      "\n",
      "Fold: 3  Epoch: 5  Training loss = 1.3126  Validation loss = 2.9162  \n",
      "\n",
      "Fold: 3  Epoch: 6  Training loss = 1.3705  Validation loss = 2.4484  \n",
      "\n",
      "Fold: 3  Epoch: 7  Training loss = 1.3627  Validation loss = 2.5396  \n",
      "\n",
      "Fold: 3  Epoch: 8  Training loss = 1.2937  Validation loss = 2.5227  \n",
      "\n",
      "Fold: 3  Epoch: 9  Training loss = 1.2565  Validation loss = 2.8511  \n",
      "\n",
      "Fold: 3  Epoch: 10  Training loss = 1.2584  Validation loss = 2.5263  \n",
      "\n",
      "Fold: 3  Epoch: 11  Training loss = 1.3073  Validation loss = 3.0349  \n",
      "\n",
      "Fold: 3  Epoch: 12  Training loss = 1.2183  Validation loss = 2.6349  \n",
      "\n",
      "Fold: 3  Epoch: 13  Training loss = 1.2372  Validation loss = 2.9400  \n",
      "\n",
      "Fold: 3  Epoch: 14  Training loss = 1.2183  Validation loss = 2.8207  \n",
      "\n",
      "Fold: 3  Epoch: 15  Training loss = 1.2059  Validation loss = 3.0492  \n",
      "\n",
      "Check model:  Fold: 3  Optimal epoch: 6  \n",
      "\n",
      "Fold: 4  Epoch: 1  Training loss = 1.3967  Validation loss = 3.8980  \n",
      "\n",
      "Fold: 4  Epoch: 2  Training loss = 1.3304  Validation loss = 3.5043  \n",
      "\n",
      "Fold: 4  Epoch: 3  Training loss = 1.3667  Validation loss = 3.5121  \n",
      "\n",
      "Fold: 4  Epoch: 4  Training loss = 1.2806  Validation loss = 2.9422  \n",
      "\n",
      "Fold: 4  Epoch: 5  Training loss = 1.2617  Validation loss = 3.1368  \n",
      "\n",
      "Fold: 4  Epoch: 6  Training loss = 1.2743  Validation loss = 2.6644  \n",
      "\n",
      "Fold: 4  Epoch: 7  Training loss = 1.2484  Validation loss = 2.7737  \n",
      "\n",
      "Fold: 4  Epoch: 8  Training loss = 1.3397  Validation loss = 3.4434  \n",
      "\n",
      "Fold: 4  Epoch: 9  Training loss = 1.2161  Validation loss = 2.7274  \n",
      "\n",
      "Fold: 4  Epoch: 10  Training loss = 1.1852  Validation loss = 2.6037  \n",
      "\n",
      "Fold: 4  Epoch: 11  Training loss = 1.1891  Validation loss = 2.3315  \n",
      "\n",
      "Fold: 4  Epoch: 12  Training loss = 1.2439  Validation loss = 2.3285  \n",
      "\n",
      "Fold: 4  Epoch: 13  Training loss = 1.1792  Validation loss = 2.7705  \n",
      "\n",
      "Fold: 4  Epoch: 14  Training loss = 1.3244  Validation loss = 1.8729  \n",
      "\n",
      "Fold: 4  Epoch: 15  Training loss = 1.2430  Validation loss = 2.4758  \n",
      "\n",
      "Fold: 4  Epoch: 16  Training loss = 1.1432  Validation loss = 2.9750  \n",
      "\n",
      "Fold: 4  Epoch: 17  Training loss = 1.1205  Validation loss = 2.6099  \n",
      "\n",
      "Fold: 4  Epoch: 18  Training loss = 1.2170  Validation loss = 2.8002  \n",
      "\n",
      "Fold: 4  Epoch: 19  Training loss = 1.1372  Validation loss = 2.8900  \n",
      "\n",
      "Fold: 4  Epoch: 20  Training loss = 1.1582  Validation loss = 2.5907  \n",
      "\n",
      "Fold: 4  Epoch: 21  Training loss = 1.0913  Validation loss = 2.8431  \n",
      "\n",
      "Fold: 4  Epoch: 22  Training loss = 1.0995  Validation loss = 2.4785  \n",
      "\n",
      "Fold: 4  Epoch: 23  Training loss = 1.0746  Validation loss = 2.7839  \n",
      "\n",
      "Fold: 4  Epoch: 24  Training loss = 1.1296  Validation loss = 3.3279  \n",
      "\n",
      "Check model:  Fold: 4  Optimal epoch: 14  \n",
      "\n",
      "Fold: 5  Epoch: 1  Training loss = 1.1084  Validation loss = 2.4399  \n",
      "\n",
      "Fold: 5  Epoch: 2  Training loss = 1.0941  Validation loss = 3.1065  \n",
      "\n",
      "Fold: 5  Epoch: 3  Training loss = 1.0744  Validation loss = 2.6514  \n",
      "\n",
      "Fold: 5  Epoch: 4  Training loss = 1.0887  Validation loss = 2.9946  \n",
      "\n",
      "Fold: 5  Epoch: 5  Training loss = 1.0503  Validation loss = 2.5786  \n",
      "\n",
      "Fold: 5  Epoch: 6  Training loss = 1.0802  Validation loss = 2.9226  \n",
      "\n",
      "Fold: 5  Epoch: 7  Training loss = 1.1086  Validation loss = 2.9396  \n",
      "\n",
      "Fold: 5  Epoch: 8  Training loss = 1.0230  Validation loss = 2.4203  \n",
      "\n",
      "Fold: 5  Epoch: 9  Training loss = 1.0197  Validation loss = 2.4441  \n",
      "\n",
      "Fold: 5  Epoch: 10  Training loss = 1.0170  Validation loss = 2.7712  \n",
      "\n",
      "Fold: 5  Epoch: 11  Training loss = 1.0973  Validation loss = 2.7605  \n",
      "\n",
      "Fold: 5  Epoch: 12  Training loss = 1.0076  Validation loss = 2.6290  \n",
      "\n",
      "Fold: 5  Epoch: 13  Training loss = 1.0695  Validation loss = 2.9536  \n",
      "\n",
      "Fold: 5  Epoch: 14  Training loss = 0.9921  Validation loss = 2.5576  \n",
      "\n",
      "Fold: 5  Epoch: 15  Training loss = 0.9695  Validation loss = 2.5106  \n",
      "\n",
      "Fold: 5  Epoch: 16  Training loss = 0.9710  Validation loss = 2.4649  \n",
      "\n",
      "Fold: 5  Epoch: 17  Training loss = 0.9889  Validation loss = 2.7673  \n",
      "\n",
      "Fold: 5  Epoch: 18  Training loss = 0.9522  Validation loss = 2.6739  \n",
      "\n",
      "Fold: 5  Epoch: 19  Training loss = 0.9554  Validation loss = 2.7181  \n",
      "\n",
      "Fold: 5  Epoch: 20  Training loss = 1.0582  Validation loss = 2.8218  \n",
      "\n",
      "Fold: 5  Epoch: 21  Training loss = 0.9464  Validation loss = 2.7208  \n",
      "\n",
      "Fold: 5  Epoch: 22  Training loss = 0.9608  Validation loss = 2.7388  \n",
      "\n",
      "Fold: 5  Epoch: 23  Training loss = 0.9373  Validation loss = 2.7484  \n",
      "\n",
      "Fold: 5  Epoch: 24  Training loss = 0.9436  Validation loss = 2.7363  \n",
      "\n",
      "Fold: 5  Epoch: 25  Training loss = 0.9700  Validation loss = 2.6512  \n",
      "\n",
      "Fold: 5  Epoch: 26  Training loss = 0.9865  Validation loss = 2.6433  \n",
      "\n",
      "Fold: 5  Epoch: 27  Training loss = 0.9605  Validation loss = 2.5552  \n",
      "\n",
      "Fold: 5  Epoch: 28  Training loss = 0.9193  Validation loss = 2.7015  \n",
      "\n",
      "Fold: 5  Epoch: 29  Training loss = 0.9171  Validation loss = 2.5433  \n",
      "\n",
      "Fold: 5  Epoch: 30  Training loss = 0.9439  Validation loss = 2.5477  \n",
      "\n",
      "Fold: 5  Epoch: 31  Training loss = 0.9307  Validation loss = 2.5654  \n",
      "\n",
      "Fold: 5  Epoch: 32  Training loss = 0.9323  Validation loss = 2.6583  \n",
      "\n",
      "Fold: 5  Epoch: 33  Training loss = 0.9655  Validation loss = 2.8932  \n",
      "\n",
      "Check model:  Fold: 5  Optimal epoch: 8  \n",
      "\n",
      "Fold: 6  Epoch: 1  Training loss = 1.1122  Validation loss = 1.6377  \n",
      "\n",
      "Fold: 6  Epoch: 2  Training loss = 1.0035  Validation loss = 1.5936  \n",
      "\n",
      "Fold: 6  Epoch: 3  Training loss = 0.9810  Validation loss = 1.2215  \n",
      "\n",
      "Fold: 6  Epoch: 4  Training loss = 0.9726  Validation loss = 1.4375  \n",
      "\n",
      "Fold: 6  Epoch: 5  Training loss = 0.9899  Validation loss = 1.6073  \n",
      "\n",
      "Fold: 6  Epoch: 6  Training loss = 0.9641  Validation loss = 1.2903  \n",
      "\n",
      "Fold: 6  Epoch: 7  Training loss = 0.9456  Validation loss = 1.4757  \n",
      "\n",
      "Fold: 6  Epoch: 8  Training loss = 0.9012  Validation loss = 1.3492  \n",
      "\n",
      "Fold: 6  Epoch: 9  Training loss = 0.9392  Validation loss = 1.6149  \n",
      "\n",
      "Fold: 6  Epoch: 10  Training loss = 0.9228  Validation loss = 1.3264  \n",
      "\n",
      "Fold: 6  Epoch: 11  Training loss = 0.8772  Validation loss = 1.3548  \n",
      "\n",
      "Fold: 6  Epoch: 12  Training loss = 0.9448  Validation loss = 1.0952  \n",
      "\n",
      "Fold: 6  Epoch: 13  Training loss = 0.8734  Validation loss = 1.4005  \n",
      "\n",
      "Fold: 6  Epoch: 14  Training loss = 0.8885  Validation loss = 1.3404  \n",
      "\n",
      "Fold: 6  Epoch: 15  Training loss = 0.9756  Validation loss = 1.2290  \n",
      "\n",
      "Fold: 6  Epoch: 16  Training loss = 0.9077  Validation loss = 1.6965  \n",
      "\n",
      "Check model:  Fold: 6  Optimal epoch: 12  \n",
      "\n",
      "Fold: 7  Epoch: 1  Training loss = 0.8992  Validation loss = 2.4066  \n",
      "\n",
      "Fold: 7  Epoch: 2  Training loss = 0.9664  Validation loss = 2.6074  \n",
      "\n",
      "Fold: 7  Epoch: 3  Training loss = 1.0821  Validation loss = 2.4916  \n",
      "\n",
      "Fold: 7  Epoch: 4  Training loss = 0.9484  Validation loss = 2.2791  \n",
      "\n",
      "Fold: 7  Epoch: 5  Training loss = 0.9236  Validation loss = 2.3099  \n",
      "\n",
      "Fold: 7  Epoch: 6  Training loss = 0.9446  Validation loss = 2.4187  \n",
      "\n",
      "Fold: 7  Epoch: 7  Training loss = 0.9001  Validation loss = 2.3312  \n",
      "\n",
      "Fold: 7  Epoch: 8  Training loss = 0.9276  Validation loss = 2.4655  \n",
      "\n",
      "Fold: 7  Epoch: 9  Training loss = 0.8940  Validation loss = 2.5014  \n",
      "\n",
      "Fold: 7  Epoch: 10  Training loss = 0.9320  Validation loss = 2.5946  \n",
      "\n",
      "Fold: 7  Epoch: 11  Training loss = 0.8845  Validation loss = 2.5297  \n",
      "\n",
      "Fold: 7  Epoch: 12  Training loss = 0.9532  Validation loss = 2.6240  \n",
      "\n",
      "Check model:  Fold: 7  Optimal epoch: 4  \n",
      "\n",
      "Fold: 8  Epoch: 1  Training loss = 1.0069  Validation loss = 7.2127  \n",
      "\n",
      "Fold: 8  Epoch: 2  Training loss = 1.0122  Validation loss = 6.9537  \n",
      "\n",
      "Fold: 8  Epoch: 3  Training loss = 1.0272  Validation loss = 7.1444  \n",
      "\n",
      "Fold: 8  Epoch: 4  Training loss = 0.9689  Validation loss = 6.9862  \n",
      "\n",
      "Fold: 8  Epoch: 5  Training loss = 0.9532  Validation loss = 6.8264  \n",
      "\n",
      "Fold: 8  Epoch: 6  Training loss = 0.9504  Validation loss = 6.9665  \n",
      "\n",
      "Fold: 8  Epoch: 7  Training loss = 0.9627  Validation loss = 7.1084  \n",
      "\n",
      "Fold: 8  Epoch: 8  Training loss = 1.0526  Validation loss = 6.5181  \n",
      "\n",
      "Fold: 8  Epoch: 9  Training loss = 0.9885  Validation loss = 6.8895  \n",
      "\n",
      "Fold: 8  Epoch: 10  Training loss = 0.9387  Validation loss = 6.8782  \n",
      "\n",
      "Fold: 8  Epoch: 11  Training loss = 0.9095  Validation loss = 7.2102  \n",
      "\n",
      "Check model:  Fold: 8  Optimal epoch: 8  \n",
      "\n",
      "Fold: 9  Epoch: 1  Training loss = 1.8718  Validation loss = 7.6596  \n",
      "\n",
      "Fold: 9  Epoch: 2  Training loss = 1.8091  Validation loss = 7.8022  \n",
      "\n",
      "Fold: 9  Epoch: 3  Training loss = 1.7980  Validation loss = 7.4974  \n",
      "\n",
      "Fold: 9  Epoch: 4  Training loss = 2.0557  Validation loss = 6.0944  \n",
      "\n",
      "Fold: 9  Epoch: 5  Training loss = 1.7840  Validation loss = 7.7648  \n",
      "\n",
      "Fold: 9  Epoch: 6  Training loss = 1.6916  Validation loss = 7.3011  \n",
      "\n",
      "Fold: 9  Epoch: 7  Training loss = 1.8140  Validation loss = 6.7728  \n",
      "\n",
      "Fold: 9  Epoch: 8  Training loss = 1.6115  Validation loss = 7.0950  \n",
      "\n",
      "Fold: 9  Epoch: 9  Training loss = 1.7312  Validation loss = 7.4178  \n",
      "\n",
      "Fold: 9  Epoch: 10  Training loss = 1.5731  Validation loss = 6.6583  \n",
      "\n",
      "Fold: 9  Epoch: 11  Training loss = 1.5512  Validation loss = 6.9163  \n",
      "\n",
      "Fold: 9  Epoch: 12  Training loss = 1.5619  Validation loss = 6.9954  \n",
      "\n",
      "Fold: 9  Epoch: 13  Training loss = 1.5254  Validation loss = 6.6419  \n",
      "\n",
      "Fold: 9  Epoch: 14  Training loss = 1.6160  Validation loss = 7.0709  \n",
      "\n",
      "Fold: 9  Epoch: 15  Training loss = 1.6789  Validation loss = 7.4656  \n",
      "\n",
      "Check model:  Fold: 9  Optimal epoch: 4  \n",
      "\n",
      "Fold: 10  Epoch: 1  Training loss = 2.0289  Validation loss = 3.9757  \n",
      "\n",
      "Fold: 10  Epoch: 2  Training loss = 2.0108  Validation loss = 4.1360  \n",
      "\n",
      "Fold: 10  Epoch: 3  Training loss = 2.4326  Validation loss = 4.7933  \n",
      "\n",
      "Fold: 10  Epoch: 4  Training loss = 1.9856  Validation loss = 4.2660  \n",
      "\n",
      "Fold: 10  Epoch: 5  Training loss = 2.6668  Validation loss = 3.5633  \n",
      "\n",
      "Fold: 10  Epoch: 6  Training loss = 1.9552  Validation loss = 3.8188  \n",
      "\n",
      "Fold: 10  Epoch: 7  Training loss = 1.8806  Validation loss = 3.5552  \n",
      "\n",
      "Fold: 10  Epoch: 8  Training loss = 1.8141  Validation loss = 3.7176  \n",
      "\n",
      "Fold: 10  Epoch: 9  Training loss = 1.9534  Validation loss = 3.7275  \n",
      "\n",
      "Fold: 10  Epoch: 10  Training loss = 2.3485  Validation loss = 2.5942  \n",
      "\n",
      "Fold: 10  Epoch: 11  Training loss = 1.6846  Validation loss = 3.5077  \n",
      "\n",
      "Fold: 10  Epoch: 12  Training loss = 1.7772  Validation loss = 2.6739  \n",
      "\n",
      "Fold: 10  Epoch: 13  Training loss = 2.1079  Validation loss = 2.8864  \n",
      "\n",
      "Fold: 10  Epoch: 14  Training loss = 2.0576  Validation loss = 2.3734  \n",
      "\n",
      "Fold: 10  Epoch: 15  Training loss = 1.7313  Validation loss = 2.6657  \n",
      "\n",
      "Fold: 10  Epoch: 16  Training loss = 1.6785  Validation loss = 2.3890  \n",
      "\n",
      "Fold: 10  Epoch: 17  Training loss = 1.4774  Validation loss = 2.3676  \n",
      "\n",
      "Fold: 10  Epoch: 18  Training loss = 1.5893  Validation loss = 2.4785  \n",
      "\n",
      "Fold: 10  Epoch: 19  Training loss = 1.4954  Validation loss = 2.7047  \n",
      "\n",
      "Fold: 10  Epoch: 20  Training loss = 1.5398  Validation loss = 3.3401  \n",
      "\n",
      "Fold: 10  Epoch: 21  Training loss = 1.4691  Validation loss = 2.1372  \n",
      "\n",
      "Fold: 10  Epoch: 22  Training loss = 1.9882  Validation loss = 1.7758  \n",
      "\n",
      "Fold: 10  Epoch: 23  Training loss = 1.5667  Validation loss = 2.2930  \n",
      "\n",
      "Fold: 10  Epoch: 24  Training loss = 1.4039  Validation loss = 2.8628  \n",
      "\n",
      "Fold: 10  Epoch: 25  Training loss = 1.4417  Validation loss = 2.2889  \n",
      "\n",
      "Fold: 10  Epoch: 26  Training loss = 1.4259  Validation loss = 2.7679  \n",
      "\n",
      "Fold: 10  Epoch: 27  Training loss = 1.3705  Validation loss = 2.8301  \n",
      "\n",
      "Fold: 10  Epoch: 28  Training loss = 1.3573  Validation loss = 2.5551  \n",
      "\n",
      "Fold: 10  Epoch: 29  Training loss = 1.4258  Validation loss = 2.2233  \n",
      "\n",
      "Fold: 10  Epoch: 30  Training loss = 1.9572  Validation loss = 2.2287  \n",
      "\n",
      "Fold: 10  Epoch: 31  Training loss = 1.4403  Validation loss = 2.7705  \n",
      "\n",
      "Fold: 10  Epoch: 32  Training loss = 1.6925  Validation loss = 2.6368  \n",
      "\n",
      "Fold: 10  Epoch: 33  Training loss = 1.3411  Validation loss = 2.4665  \n",
      "\n",
      "Fold: 10  Epoch: 34  Training loss = 1.3020  Validation loss = 2.5202  \n",
      "\n",
      "Fold: 10  Epoch: 35  Training loss = 1.2938  Validation loss = 2.7096  \n",
      "\n",
      "Fold: 10  Epoch: 36  Training loss = 1.2797  Validation loss = 2.9039  \n",
      "\n",
      "Check model:  Fold: 10  Optimal epoch: 22  \n",
      "\n",
      "Fold: 11  Epoch: 1  Training loss = 1.4251  Validation loss = 2.7772  \n",
      "\n",
      "Fold: 11  Epoch: 2  Training loss = 1.2979  Validation loss = 3.0525  \n",
      "\n",
      "Fold: 11  Epoch: 3  Training loss = 1.2665  Validation loss = 3.0792  \n",
      "\n",
      "Fold: 11  Epoch: 4  Training loss = 1.2738  Validation loss = 3.2591  \n",
      "\n",
      "Fold: 11  Epoch: 5  Training loss = 1.2945  Validation loss = 4.0109  \n",
      "\n",
      "Fold: 11  Epoch: 6  Training loss = 1.1771  Validation loss = 3.9315  \n",
      "\n",
      "Fold: 11  Epoch: 7  Training loss = 1.5834  Validation loss = 3.6288  \n",
      "\n",
      "Fold: 11  Epoch: 8  Training loss = 1.1714  Validation loss = 3.4010  \n",
      "\n",
      "Fold: 11  Epoch: 9  Training loss = 1.4122  Validation loss = 4.0465  \n",
      "\n",
      "Fold: 11  Epoch: 10  Training loss = 1.3061  Validation loss = 3.5833  \n",
      "\n",
      "Fold: 11  Epoch: 11  Training loss = 1.3862  Validation loss = 4.5653  \n",
      "\n",
      "Check model:  Fold: 11  Optimal epoch: 1  \n",
      "\n",
      "Fold: 12  Epoch: 1  Training loss = 1.2736  Validation loss = 2.2962  \n",
      "\n",
      "Fold: 12  Epoch: 2  Training loss = 1.4119  Validation loss = 2.6549  \n",
      "\n",
      "Fold: 12  Epoch: 3  Training loss = 1.7918  Validation loss = 2.1213  \n",
      "\n",
      "Fold: 12  Epoch: 4  Training loss = 1.2154  Validation loss = 2.3693  \n",
      "\n",
      "Fold: 12  Epoch: 5  Training loss = 1.2803  Validation loss = 2.4609  \n",
      "\n",
      "Fold: 12  Epoch: 6  Training loss = 1.3113  Validation loss = 2.3246  \n",
      "\n",
      "Fold: 12  Epoch: 7  Training loss = 1.3331  Validation loss = 2.6588  \n",
      "\n",
      "Fold: 12  Epoch: 8  Training loss = 1.2220  Validation loss = 2.0221  \n",
      "\n",
      "Fold: 12  Epoch: 9  Training loss = 1.2412  Validation loss = 2.2093  \n",
      "\n",
      "Fold: 12  Epoch: 10  Training loss = 1.2288  Validation loss = 2.9833  \n",
      "\n",
      "Fold: 12  Epoch: 11  Training loss = 1.3416  Validation loss = 1.9306  \n",
      "\n",
      "Fold: 12  Epoch: 12  Training loss = 1.1420  Validation loss = 2.2948  \n",
      "\n",
      "Fold: 12  Epoch: 13  Training loss = 1.1534  Validation loss = 2.5696  \n",
      "\n",
      "Fold: 12  Epoch: 14  Training loss = 1.2591  Validation loss = 1.8096  \n",
      "\n",
      "Fold: 12  Epoch: 15  Training loss = 1.1795  Validation loss = 2.1582  \n",
      "\n",
      "Fold: 12  Epoch: 16  Training loss = 1.1596  Validation loss = 2.4018  \n",
      "\n",
      "Fold: 12  Epoch: 17  Training loss = 1.2876  Validation loss = 2.2404  \n",
      "\n",
      "Fold: 12  Epoch: 18  Training loss = 1.1785  Validation loss = 3.0170  \n",
      "\n",
      "Check model:  Fold: 12  Optimal epoch: 14  \n",
      "\n",
      "Fold: 13  Epoch: 1  Training loss = 1.1889  Validation loss = 4.1749  \n",
      "\n",
      "Fold: 13  Epoch: 2  Training loss = 1.1808  Validation loss = 4.3528  \n",
      "\n",
      "Fold: 13  Epoch: 3  Training loss = 1.3731  Validation loss = 4.5677  \n",
      "\n",
      "Fold: 13  Epoch: 4  Training loss = 1.1320  Validation loss = 3.9052  \n",
      "\n",
      "Fold: 13  Epoch: 5  Training loss = 1.0867  Validation loss = 3.9990  \n",
      "\n",
      "Fold: 13  Epoch: 6  Training loss = 1.1009  Validation loss = 4.5745  \n",
      "\n",
      "Fold: 13  Epoch: 7  Training loss = 1.1847  Validation loss = 3.9136  \n",
      "\n",
      "Fold: 13  Epoch: 8  Training loss = 1.3458  Validation loss = 4.1517  \n",
      "\n",
      "Fold: 13  Epoch: 9  Training loss = 1.1982  Validation loss = 4.4116  \n",
      "\n",
      "Fold: 13  Epoch: 10  Training loss = 1.0646  Validation loss = 3.8109  \n",
      "\n",
      "Fold: 13  Epoch: 11  Training loss = 1.1629  Validation loss = 3.5494  \n",
      "\n",
      "Fold: 13  Epoch: 12  Training loss = 1.0412  Validation loss = 3.5895  \n",
      "\n",
      "Fold: 13  Epoch: 13  Training loss = 1.0533  Validation loss = 4.3975  \n",
      "\n",
      "Fold: 13  Epoch: 14  Training loss = 0.9783  Validation loss = 4.1985  \n",
      "\n",
      "Fold: 13  Epoch: 15  Training loss = 1.0450  Validation loss = 4.4130  \n",
      "\n",
      "Fold: 13  Epoch: 16  Training loss = 1.1727  Validation loss = 3.5494  \n",
      "\n",
      "Fold: 13  Epoch: 17  Training loss = 0.9727  Validation loss = 4.1649  \n",
      "\n",
      "Fold: 13  Epoch: 18  Training loss = 1.0010  Validation loss = 4.2139  \n",
      "\n",
      "Fold: 13  Epoch: 19  Training loss = 1.0765  Validation loss = 4.3170  \n",
      "\n",
      "Fold: 13  Epoch: 20  Training loss = 1.3663  Validation loss = 3.3142  \n",
      "\n",
      "Fold: 13  Epoch: 21  Training loss = 0.9878  Validation loss = 3.4841  \n",
      "\n",
      "Fold: 13  Epoch: 22  Training loss = 1.0430  Validation loss = 3.3107  \n",
      "\n",
      "Fold: 13  Epoch: 23  Training loss = 0.8790  Validation loss = 4.1354  \n",
      "\n",
      "Fold: 13  Epoch: 24  Training loss = 0.9023  Validation loss = 3.8368  \n",
      "\n",
      "Fold: 13  Epoch: 25  Training loss = 0.9959  Validation loss = 4.3556  \n",
      "\n",
      "Check model:  Fold: 13  Optimal epoch: 22  \n",
      "\n",
      "Fold: 14  Epoch: 1  Training loss = 1.4025  Validation loss = 3.9583  \n",
      "\n",
      "Fold: 14  Epoch: 2  Training loss = 1.2887  Validation loss = 4.6059  \n",
      "\n",
      "Fold: 14  Epoch: 3  Training loss = 1.1278  Validation loss = 5.1832  \n",
      "\n",
      "Fold: 14  Epoch: 4  Training loss = 1.3050  Validation loss = 4.2483  \n",
      "\n",
      "Fold: 14  Epoch: 5  Training loss = 1.1897  Validation loss = 4.3601  \n",
      "\n",
      "Fold: 14  Epoch: 6  Training loss = 1.1034  Validation loss = 4.9837  \n",
      "\n",
      "Fold: 14  Epoch: 7  Training loss = 1.4009  Validation loss = 5.8481  \n",
      "\n",
      "Fold: 14  Epoch: 8  Training loss = 1.1619  Validation loss = 4.7167  \n",
      "\n",
      "Fold: 14  Epoch: 9  Training loss = 1.1318  Validation loss = 4.9134  \n",
      "\n",
      "Fold: 14  Epoch: 10  Training loss = 1.1180  Validation loss = 4.3524  \n",
      "\n",
      "Fold: 14  Epoch: 11  Training loss = 1.1224  Validation loss = 5.1629  \n",
      "\n",
      "Fold: 14  Epoch: 12  Training loss = 1.0271  Validation loss = 4.7776  \n",
      "\n",
      "Fold: 14  Epoch: 13  Training loss = 1.0249  Validation loss = 4.0169  \n",
      "\n",
      "Fold: 14  Epoch: 14  Training loss = 1.2814  Validation loss = 5.7712  \n",
      "\n",
      "Fold: 14  Epoch: 15  Training loss = 1.3369  Validation loss = 4.1108  \n",
      "\n",
      "Fold: 14  Epoch: 16  Training loss = 0.9932  Validation loss = 4.8835  \n",
      "\n",
      "Fold: 14  Epoch: 17  Training loss = 0.9842  Validation loss = 4.2018  \n",
      "\n",
      "Fold: 14  Epoch: 18  Training loss = 1.0742  Validation loss = 4.4064  \n",
      "\n",
      "Fold: 14  Epoch: 19  Training loss = 1.0053  Validation loss = 5.2193  \n",
      "\n",
      "Fold: 14  Epoch: 20  Training loss = 1.0350  Validation loss = 5.3394  \n",
      "\n",
      "Fold: 14  Epoch: 21  Training loss = 0.9049  Validation loss = 5.1327  \n",
      "\n",
      "Fold: 14  Epoch: 22  Training loss = 0.8227  Validation loss = 4.8227  \n",
      "\n",
      "Fold: 14  Epoch: 23  Training loss = 0.9548  Validation loss = 4.5584  \n",
      "\n",
      "Fold: 14  Epoch: 24  Training loss = 1.0549  Validation loss = 4.2573  \n",
      "\n",
      "Fold: 14  Epoch: 25  Training loss = 0.8455  Validation loss = 4.1112  \n",
      "\n",
      "Fold: 14  Epoch: 26  Training loss = 0.8567  Validation loss = 4.5931  \n",
      "\n",
      "Fold: 14  Epoch: 27  Training loss = 1.0272  Validation loss = 3.9656  \n",
      "\n",
      "Fold: 14  Epoch: 28  Training loss = 0.8085  Validation loss = 4.6042  \n",
      "\n",
      "Fold: 14  Epoch: 29  Training loss = 0.8212  Validation loss = 4.8026  \n",
      "\n",
      "Fold: 14  Epoch: 30  Training loss = 0.9752  Validation loss = 4.5886  \n",
      "\n",
      "Fold: 14  Epoch: 31  Training loss = 0.9069  Validation loss = 4.7556  \n",
      "\n",
      "Fold: 14  Epoch: 32  Training loss = 0.8368  Validation loss = 4.7965  \n",
      "\n",
      "Fold: 14  Epoch: 33  Training loss = 1.2104  Validation loss = 3.6833  \n",
      "\n",
      "Fold: 14  Epoch: 34  Training loss = 1.0423  Validation loss = 5.7482  \n",
      "\n",
      "Check model:  Fold: 14  Optimal epoch: 33  \n",
      "\n",
      "Fold: 15  Epoch: 1  Training loss = 1.4854  Validation loss = 4.9557  \n",
      "\n",
      "Fold: 15  Epoch: 2  Training loss = 1.7103  Validation loss = 7.0933  \n",
      "\n",
      "Fold: 15  Epoch: 3  Training loss = 1.1751  Validation loss = 5.7621  \n",
      "\n",
      "Fold: 15  Epoch: 4  Training loss = 1.3433  Validation loss = 5.4829  \n",
      "\n",
      "Fold: 15  Epoch: 5  Training loss = 1.1766  Validation loss = 6.2769  \n",
      "\n",
      "Fold: 15  Epoch: 6  Training loss = 1.3098  Validation loss = 5.0228  \n",
      "\n",
      "Fold: 15  Epoch: 7  Training loss = 0.9525  Validation loss = 5.9798  \n",
      "\n",
      "Fold: 15  Epoch: 8  Training loss = 0.8959  Validation loss = 6.0367  \n",
      "\n",
      "Fold: 15  Epoch: 9  Training loss = 1.9000  Validation loss = 4.5524  \n",
      "\n",
      "Fold: 15  Epoch: 10  Training loss = 1.3482  Validation loss = 7.3033  \n",
      "\n",
      "Fold: 15  Epoch: 11  Training loss = 0.9243  Validation loss = 5.4029  \n",
      "\n",
      "Fold: 15  Epoch: 12  Training loss = 0.9968  Validation loss = 5.6342  \n",
      "\n",
      "Fold: 15  Epoch: 13  Training loss = 1.1129  Validation loss = 6.8517  \n",
      "\n",
      "Fold: 15  Epoch: 14  Training loss = 1.3167  Validation loss = 6.3389  \n",
      "\n",
      "Fold: 15  Epoch: 15  Training loss = 1.1416  Validation loss = 5.9447  \n",
      "\n",
      "Fold: 15  Epoch: 16  Training loss = 0.9004  Validation loss = 6.0029  \n",
      "\n",
      "Fold: 15  Epoch: 17  Training loss = 0.8192  Validation loss = 6.4047  \n",
      "\n",
      "Fold: 15  Epoch: 18  Training loss = 0.7640  Validation loss = 6.0690  \n",
      "\n",
      "Fold: 15  Epoch: 19  Training loss = 0.7386  Validation loss = 6.1376  \n",
      "\n",
      "Fold: 15  Epoch: 20  Training loss = 0.8025  Validation loss = 5.9680  \n",
      "\n",
      "Fold: 15  Epoch: 21  Training loss = 0.8427  Validation loss = 6.0864  \n",
      "\n",
      "Fold: 15  Epoch: 22  Training loss = 0.7058  Validation loss = 5.8979  \n",
      "\n",
      "Fold: 15  Epoch: 23  Training loss = 1.0354  Validation loss = 6.4723  \n",
      "\n",
      "Check model:  Fold: 15  Optimal epoch: 9  \n",
      "\n",
      "Fold: 16  Epoch: 1  Training loss = 1.5500  Validation loss = 4.3338  \n",
      "\n",
      "Fold: 16  Epoch: 2  Training loss = 1.5550  Validation loss = 4.3569  \n",
      "\n",
      "Fold: 16  Epoch: 3  Training loss = 1.2561  Validation loss = 5.5053  \n",
      "\n",
      "Fold: 16  Epoch: 4  Training loss = 1.3991  Validation loss = 4.5585  \n",
      "\n",
      "Fold: 16  Epoch: 5  Training loss = 1.2908  Validation loss = 5.2154  \n",
      "\n",
      "Fold: 16  Epoch: 6  Training loss = 1.2954  Validation loss = 4.5592  \n",
      "\n",
      "Fold: 16  Epoch: 7  Training loss = 1.6858  Validation loss = 5.7795  \n",
      "\n",
      "Fold: 16  Epoch: 8  Training loss = 1.3289  Validation loss = 4.3644  \n",
      "\n",
      "Fold: 16  Epoch: 9  Training loss = 1.2167  Validation loss = 4.9574  \n",
      "\n",
      "Fold: 16  Epoch: 10  Training loss = 1.6689  Validation loss = 4.9990  \n",
      "\n",
      "Fold: 16  Epoch: 11  Training loss = 1.4225  Validation loss = 5.9266  \n",
      "\n",
      "Check model:  Fold: 16  Optimal epoch: 1  \n",
      "\n",
      "Fold: 17  Epoch: 1  Training loss = 1.9307  Validation loss = 4.1926  \n",
      "\n",
      "Fold: 17  Epoch: 2  Training loss = 1.5370  Validation loss = 3.7938  \n",
      "\n",
      "Fold: 17  Epoch: 3  Training loss = 1.4164  Validation loss = 3.6555  \n",
      "\n",
      "Fold: 17  Epoch: 4  Training loss = 1.3356  Validation loss = 3.8127  \n",
      "\n",
      "Fold: 17  Epoch: 5  Training loss = 1.3099  Validation loss = 3.7702  \n",
      "\n",
      "Fold: 17  Epoch: 6  Training loss = 1.4133  Validation loss = 3.9622  \n",
      "\n",
      "Fold: 17  Epoch: 7  Training loss = 1.9279  Validation loss = 4.6143  \n",
      "\n",
      "Fold: 17  Epoch: 8  Training loss = 1.4439  Validation loss = 4.2159  \n",
      "\n",
      "Fold: 17  Epoch: 9  Training loss = 1.9446  Validation loss = 4.5771  \n",
      "\n",
      "Fold: 17  Epoch: 10  Training loss = 1.3811  Validation loss = 4.0626  \n",
      "\n",
      "Fold: 17  Epoch: 11  Training loss = 1.4239  Validation loss = 4.3071  \n",
      "\n",
      "Fold: 17  Epoch: 12  Training loss = 1.2085  Validation loss = 4.4790  \n",
      "\n",
      "Fold: 17  Epoch: 13  Training loss = 1.1000  Validation loss = 4.1170  \n",
      "\n",
      "Fold: 17  Epoch: 14  Training loss = 1.0197  Validation loss = 3.5858  \n",
      "\n",
      "Fold: 17  Epoch: 15  Training loss = 0.9866  Validation loss = 4.2454  \n",
      "\n",
      "Fold: 17  Epoch: 16  Training loss = 0.9999  Validation loss = 4.2537  \n",
      "\n",
      "Fold: 17  Epoch: 17  Training loss = 0.9619  Validation loss = 4.4162  \n",
      "\n",
      "Fold: 17  Epoch: 18  Training loss = 0.9802  Validation loss = 4.2156  \n",
      "\n",
      "Fold: 17  Epoch: 19  Training loss = 0.9406  Validation loss = 4.2357  \n",
      "\n",
      "Fold: 17  Epoch: 20  Training loss = 1.0411  Validation loss = 4.4905  \n",
      "\n",
      "Check model:  Fold: 17  Optimal epoch: 14  \n",
      "\n",
      "Fold: 18  Epoch: 1  Training loss = 1.3079  Validation loss = 2.7022  \n",
      "\n",
      "Fold: 18  Epoch: 2  Training loss = 1.1581  Validation loss = 3.0450  \n",
      "\n",
      "Fold: 18  Epoch: 3  Training loss = 1.5183  Validation loss = 2.8129  \n",
      "\n",
      "Fold: 18  Epoch: 4  Training loss = 1.0279  Validation loss = 2.7596  \n",
      "\n",
      "Fold: 18  Epoch: 5  Training loss = 1.0000  Validation loss = 2.7818  \n",
      "\n",
      "Fold: 18  Epoch: 6  Training loss = 0.9943  Validation loss = 2.5273  \n",
      "\n",
      "Fold: 18  Epoch: 7  Training loss = 1.0466  Validation loss = 2.7984  \n",
      "\n",
      "Fold: 18  Epoch: 8  Training loss = 1.0530  Validation loss = 2.4780  \n",
      "\n",
      "Fold: 18  Epoch: 9  Training loss = 1.0984  Validation loss = 2.7445  \n",
      "\n",
      "Fold: 18  Epoch: 10  Training loss = 0.8914  Validation loss = 2.5281  \n",
      "\n",
      "Fold: 18  Epoch: 11  Training loss = 0.9834  Validation loss = 2.3500  \n",
      "\n",
      "Fold: 18  Epoch: 12  Training loss = 1.0274  Validation loss = 2.6177  \n",
      "\n",
      "Fold: 18  Epoch: 13  Training loss = 0.9442  Validation loss = 2.5798  \n",
      "\n",
      "Fold: 18  Epoch: 14  Training loss = 0.9674  Validation loss = 2.4552  \n",
      "\n",
      "Fold: 18  Epoch: 15  Training loss = 0.8094  Validation loss = 2.6611  \n",
      "\n",
      "Fold: 18  Epoch: 16  Training loss = 0.7995  Validation loss = 2.4680  \n",
      "\n",
      "Fold: 18  Epoch: 17  Training loss = 0.7786  Validation loss = 2.7817  \n",
      "\n",
      "Check model:  Fold: 18  Optimal epoch: 11  \n",
      "\n",
      "Fold: 19  Epoch: 1  Training loss = 0.8964  Validation loss = 1.1688  \n",
      "\n",
      "Fold: 19  Epoch: 2  Training loss = 0.8936  Validation loss = 1.3323  \n",
      "\n",
      "Fold: 19  Epoch: 3  Training loss = 0.8095  Validation loss = 1.2426  \n",
      "\n",
      "Fold: 19  Epoch: 4  Training loss = 0.9548  Validation loss = 1.5458  \n",
      "\n",
      "Fold: 19  Epoch: 5  Training loss = 0.8146  Validation loss = 1.1142  \n",
      "\n",
      "Fold: 19  Epoch: 6  Training loss = 0.7036  Validation loss = 1.2294  \n",
      "\n",
      "Fold: 19  Epoch: 7  Training loss = 0.8954  Validation loss = 1.1066  \n",
      "\n",
      "Fold: 19  Epoch: 8  Training loss = 0.6082  Validation loss = 0.8784  \n",
      "\n",
      "Fold: 19  Epoch: 9  Training loss = 0.6116  Validation loss = 0.8926  \n",
      "\n",
      "Fold: 19  Epoch: 10  Training loss = 0.5868  Validation loss = 0.8271  \n",
      "\n",
      "Fold: 19  Epoch: 11  Training loss = 0.8157  Validation loss = 0.7413  \n",
      "\n",
      "Fold: 19  Epoch: 12  Training loss = 0.6770  Validation loss = 0.8207  \n",
      "\n",
      "Fold: 19  Epoch: 13  Training loss = 0.5708  Validation loss = 0.8122  \n",
      "\n",
      "Fold: 19  Epoch: 14  Training loss = 0.5482  Validation loss = 0.7304  \n",
      "\n",
      "Fold: 19  Epoch: 15  Training loss = 0.5796  Validation loss = 0.7941  \n",
      "\n",
      "Fold: 19  Epoch: 16  Training loss = 0.6180  Validation loss = 0.6484  \n",
      "\n",
      "Fold: 19  Epoch: 17  Training loss = 0.9828  Validation loss = 0.8305  \n",
      "\n",
      "Fold: 19  Epoch: 18  Training loss = 0.6284  Validation loss = 0.8231  \n",
      "\n",
      "Fold: 19  Epoch: 19  Training loss = 0.5157  Validation loss = 0.7545  \n",
      "\n",
      "Fold: 19  Epoch: 20  Training loss = 0.6900  Validation loss = 0.8105  \n",
      "\n",
      "Fold: 19  Epoch: 21  Training loss = 0.6413  Validation loss = 0.7534  \n",
      "\n",
      "Fold: 19  Epoch: 22  Training loss = 0.5960  Validation loss = 0.7295  \n",
      "\n",
      "Fold: 19  Epoch: 23  Training loss = 0.5146  Validation loss = 0.7202  \n",
      "\n",
      "Fold: 19  Epoch: 24  Training loss = 0.5146  Validation loss = 0.6321  \n",
      "\n",
      "Fold: 19  Epoch: 25  Training loss = 0.6716  Validation loss = 0.9331  \n",
      "\n",
      "Check model:  Fold: 19  Optimal epoch: 24  \n",
      "\n",
      "Fold: 20  Epoch: 1  Training loss = 0.6305  Validation loss = 4.6673  \n",
      "\n",
      "Fold: 20  Epoch: 2  Training loss = 0.5363  Validation loss = 4.8217  \n",
      "\n",
      "Fold: 20  Epoch: 3  Training loss = 0.5717  Validation loss = 4.4521  \n",
      "\n",
      "Fold: 20  Epoch: 4  Training loss = 0.4657  Validation loss = 4.5816  \n",
      "\n",
      "Fold: 20  Epoch: 5  Training loss = 0.5380  Validation loss = 4.7423  \n",
      "\n",
      "Fold: 20  Epoch: 6  Training loss = 0.5059  Validation loss = 4.6866  \n",
      "\n",
      "Fold: 20  Epoch: 7  Training loss = 0.5901  Validation loss = 4.3598  \n",
      "\n",
      "Fold: 20  Epoch: 8  Training loss = 0.6219  Validation loss = 4.1976  \n",
      "\n",
      "Fold: 20  Epoch: 9  Training loss = 0.7081  Validation loss = 4.0025  \n",
      "\n",
      "Fold: 20  Epoch: 10  Training loss = 0.5053  Validation loss = 4.5734  \n",
      "\n",
      "Fold: 20  Epoch: 11  Training loss = 0.5095  Validation loss = 4.4765  \n",
      "\n",
      "Fold: 20  Epoch: 12  Training loss = 0.5162  Validation loss = 4.4875  \n",
      "\n",
      "Fold: 20  Epoch: 13  Training loss = 0.4692  Validation loss = 4.4960  \n",
      "\n",
      "Fold: 20  Epoch: 14  Training loss = 0.4744  Validation loss = 4.6146  \n",
      "\n",
      "Fold: 20  Epoch: 15  Training loss = 0.4125  Validation loss = 4.4188  \n",
      "\n",
      "Fold: 20  Epoch: 16  Training loss = 0.4976  Validation loss = 4.1772  \n",
      "\n",
      "Fold: 20  Epoch: 17  Training loss = 0.4705  Validation loss = 4.2692  \n",
      "\n",
      "Fold: 20  Epoch: 18  Training loss = 0.4851  Validation loss = 4.6307  \n",
      "\n",
      "Check model:  Fold: 20  Optimal epoch: 9  \n",
      "\n",
      "Fold: 21  Epoch: 1  Training loss = 1.9274  Validation loss = 5.0036  \n",
      "\n",
      "Fold: 21  Epoch: 2  Training loss = 1.3044  Validation loss = 4.2237  \n",
      "\n",
      "Fold: 21  Epoch: 3  Training loss = 0.9062  Validation loss = 3.7988  \n",
      "\n",
      "Fold: 21  Epoch: 4  Training loss = 1.1592  Validation loss = 3.6008  \n",
      "\n",
      "Fold: 21  Epoch: 5  Training loss = 0.8577  Validation loss = 3.7420  \n",
      "\n",
      "Fold: 21  Epoch: 6  Training loss = 0.6732  Validation loss = 4.1425  \n",
      "\n",
      "Fold: 21  Epoch: 7  Training loss = 0.7212  Validation loss = 4.1350  \n",
      "\n",
      "Fold: 21  Epoch: 8  Training loss = 0.6224  Validation loss = 4.0449  \n",
      "\n",
      "Fold: 21  Epoch: 9  Training loss = 0.5956  Validation loss = 3.8967  \n",
      "\n",
      "Fold: 21  Epoch: 10  Training loss = 0.6392  Validation loss = 3.8932  \n",
      "\n",
      "Fold: 21  Epoch: 11  Training loss = 0.5194  Validation loss = 3.9052  \n",
      "\n",
      "Fold: 21  Epoch: 12  Training loss = 0.4891  Validation loss = 3.9591  \n",
      "\n",
      "Fold: 21  Epoch: 13  Training loss = 0.4698  Validation loss = 3.8903  \n",
      "\n",
      "Fold: 21  Epoch: 14  Training loss = 0.5260  Validation loss = 3.9535  \n",
      "\n",
      "Fold: 21  Epoch: 15  Training loss = 0.5152  Validation loss = 3.8734  \n",
      "\n",
      "Fold: 21  Epoch: 16  Training loss = 0.5827  Validation loss = 3.8354  \n",
      "\n",
      "Fold: 21  Epoch: 17  Training loss = 0.4590  Validation loss = 3.7982  \n",
      "\n",
      "Fold: 21  Epoch: 18  Training loss = 0.4363  Validation loss = 3.8484  \n",
      "\n",
      "Fold: 21  Epoch: 19  Training loss = 0.4691  Validation loss = 3.7078  \n",
      "\n",
      "Fold: 21  Epoch: 20  Training loss = 0.5039  Validation loss = 3.7032  \n",
      "\n",
      "Fold: 21  Epoch: 21  Training loss = 0.4903  Validation loss = 3.6781  \n",
      "\n",
      "Fold: 21  Epoch: 22  Training loss = 0.4711  Validation loss = 3.7337  \n",
      "\n",
      "Fold: 21  Epoch: 23  Training loss = 0.4763  Validation loss = 3.7641  \n",
      "\n",
      "Fold: 21  Epoch: 24  Training loss = 0.4484  Validation loss = 3.7946  \n",
      "\n",
      "Fold: 21  Epoch: 25  Training loss = 0.4117  Validation loss = 3.7064  \n",
      "\n",
      "Fold: 21  Epoch: 26  Training loss = 0.4290  Validation loss = 3.7590  \n",
      "\n",
      "Fold: 21  Epoch: 27  Training loss = 0.6116  Validation loss = 3.8192  \n",
      "\n",
      "Fold: 21  Epoch: 28  Training loss = 0.5100  Validation loss = 3.8215  \n",
      "\n",
      "Check model:  Fold: 21  Optimal epoch: 4  \n",
      "\n",
      "Fold: 22  Epoch: 1  Training loss = 0.8918  Validation loss = 1.2032  \n",
      "\n",
      "Fold: 22  Epoch: 2  Training loss = 0.9197  Validation loss = 1.2650  \n",
      "\n",
      "Fold: 22  Epoch: 3  Training loss = 0.8432  Validation loss = 1.3972  \n",
      "\n",
      "Fold: 22  Epoch: 4  Training loss = 0.8021  Validation loss = 1.3041  \n",
      "\n",
      "Fold: 22  Epoch: 5  Training loss = 0.7895  Validation loss = 1.3420  \n",
      "\n",
      "Fold: 22  Epoch: 6  Training loss = 0.8359  Validation loss = 0.9689  \n",
      "\n",
      "Fold: 22  Epoch: 7  Training loss = 0.7765  Validation loss = 1.3112  \n",
      "\n",
      "Fold: 22  Epoch: 8  Training loss = 0.6954  Validation loss = 0.9184  \n",
      "\n",
      "Fold: 22  Epoch: 9  Training loss = 0.5622  Validation loss = 0.8126  \n",
      "\n",
      "Fold: 22  Epoch: 10  Training loss = 0.5229  Validation loss = 1.1214  \n",
      "\n",
      "Fold: 22  Epoch: 11  Training loss = 0.6369  Validation loss = 0.9858  \n",
      "\n",
      "Fold: 22  Epoch: 12  Training loss = 0.5565  Validation loss = 1.1654  \n",
      "\n",
      "Fold: 22  Epoch: 13  Training loss = 0.4599  Validation loss = 1.3262  \n",
      "\n",
      "Fold: 22  Epoch: 14  Training loss = 0.5145  Validation loss = 1.5016  \n",
      "\n",
      "Check model:  Fold: 22  Optimal epoch: 9  \n",
      "\n",
      "Fold: 23  Epoch: 1  Training loss = 0.5906  Validation loss = 3.0203  \n",
      "\n",
      "Fold: 23  Epoch: 2  Training loss = 0.5671  Validation loss = 3.2133  \n",
      "\n",
      "Fold: 23  Epoch: 3  Training loss = 0.5722  Validation loss = 2.6055  \n",
      "\n",
      "Fold: 23  Epoch: 4  Training loss = 0.4933  Validation loss = 2.9432  \n",
      "\n",
      "Fold: 23  Epoch: 5  Training loss = 0.5630  Validation loss = 3.3543  \n",
      "\n",
      "Fold: 23  Epoch: 6  Training loss = 0.4555  Validation loss = 3.0263  \n",
      "\n",
      "Fold: 23  Epoch: 7  Training loss = 0.4918  Validation loss = 2.5234  \n",
      "\n",
      "Fold: 23  Epoch: 8  Training loss = 0.5177  Validation loss = 2.4523  \n",
      "\n",
      "Fold: 23  Epoch: 9  Training loss = 0.4441  Validation loss = 2.7980  \n",
      "\n",
      "Fold: 23  Epoch: 10  Training loss = 0.5177  Validation loss = 2.8377  \n",
      "\n",
      "Fold: 23  Epoch: 11  Training loss = 0.4227  Validation loss = 2.8719  \n",
      "\n",
      "Fold: 23  Epoch: 12  Training loss = 0.4007  Validation loss = 2.9746  \n",
      "\n",
      "Fold: 23  Epoch: 13  Training loss = 0.4527  Validation loss = 2.7409  \n",
      "\n",
      "Fold: 23  Epoch: 14  Training loss = 0.5272  Validation loss = 3.2151  \n",
      "\n",
      "Fold: 23  Epoch: 15  Training loss = 0.3967  Validation loss = 2.8233  \n",
      "\n",
      "Fold: 23  Epoch: 16  Training loss = 0.4007  Validation loss = 3.0896  \n",
      "\n",
      "Fold: 23  Epoch: 17  Training loss = 0.4761  Validation loss = 2.6271  \n",
      "\n",
      "Fold: 23  Epoch: 18  Training loss = 0.4167  Validation loss = 2.8239  \n",
      "\n",
      "Fold: 23  Epoch: 19  Training loss = 0.3537  Validation loss = 2.6836  \n",
      "\n",
      "Fold: 23  Epoch: 20  Training loss = 0.3984  Validation loss = 2.4262  \n",
      "\n",
      "Fold: 23  Epoch: 21  Training loss = 0.3134  Validation loss = 2.5725  \n",
      "\n",
      "Fold: 23  Epoch: 22  Training loss = 0.3031  Validation loss = 2.5502  \n",
      "\n",
      "Fold: 23  Epoch: 23  Training loss = 0.2899  Validation loss = 2.7399  \n",
      "\n",
      "Fold: 23  Epoch: 24  Training loss = 0.3426  Validation loss = 2.6332  \n",
      "\n",
      "Fold: 23  Epoch: 25  Training loss = 0.3290  Validation loss = 2.4625  \n",
      "\n",
      "Fold: 23  Epoch: 26  Training loss = 0.3315  Validation loss = 2.6281  \n",
      "\n",
      "Fold: 23  Epoch: 27  Training loss = 0.3582  Validation loss = 2.6537  \n",
      "\n",
      "Fold: 23  Epoch: 28  Training loss = 0.3253  Validation loss = 2.5019  \n",
      "\n",
      "Fold: 23  Epoch: 29  Training loss = 0.3416  Validation loss = 2.4194  \n",
      "\n",
      "Fold: 23  Epoch: 30  Training loss = 0.3677  Validation loss = 2.6940  \n",
      "\n",
      "Fold: 23  Epoch: 31  Training loss = 0.4479  Validation loss = 2.8304  \n",
      "\n",
      "Check model:  Fold: 23  Optimal epoch: 29  \n",
      "\n",
      "Fold: 24  Epoch: 1  Training loss = 1.1435  Validation loss = 1.7180  \n",
      "\n",
      "Fold: 24  Epoch: 2  Training loss = 1.3450  Validation loss = 1.7559  \n",
      "\n",
      "Fold: 24  Epoch: 3  Training loss = 1.1109  Validation loss = 1.6062  \n",
      "\n",
      "Fold: 24  Epoch: 4  Training loss = 0.9956  Validation loss = 1.3510  \n",
      "\n",
      "Fold: 24  Epoch: 5  Training loss = 1.0117  Validation loss = 1.4116  \n",
      "\n",
      "Fold: 24  Epoch: 6  Training loss = 1.1000  Validation loss = 1.6223  \n",
      "\n",
      "Fold: 24  Epoch: 7  Training loss = 0.8881  Validation loss = 1.4755  \n",
      "\n",
      "Fold: 24  Epoch: 8  Training loss = 0.8912  Validation loss = 1.7097  \n",
      "\n",
      "Fold: 24  Epoch: 9  Training loss = 1.1169  Validation loss = 2.0785  \n",
      "\n",
      "Fold: 24  Epoch: 10  Training loss = 0.8556  Validation loss = 1.6114  \n",
      "\n",
      "Fold: 24  Epoch: 11  Training loss = 0.8574  Validation loss = 1.6787  \n",
      "\n",
      "Fold: 24  Epoch: 12  Training loss = 0.8908  Validation loss = 2.3969  \n",
      "\n",
      "Check model:  Fold: 24  Optimal epoch: 4  \n",
      "\n",
      "Fold: 25  Epoch: 1  Training loss = 0.8693  Validation loss = 3.4036  \n",
      "\n",
      "Fold: 25  Epoch: 2  Training loss = 0.8465  Validation loss = 3.1592  \n",
      "\n",
      "Fold: 25  Epoch: 3  Training loss = 0.9065  Validation loss = 3.0895  \n",
      "\n",
      "Fold: 25  Epoch: 4  Training loss = 0.7135  Validation loss = 3.0977  \n",
      "\n",
      "Fold: 25  Epoch: 5  Training loss = 0.8007  Validation loss = 3.3030  \n",
      "\n",
      "Fold: 25  Epoch: 6  Training loss = 0.9039  Validation loss = 3.2107  \n",
      "\n",
      "Fold: 25  Epoch: 7  Training loss = 0.7658  Validation loss = 2.8184  \n",
      "\n",
      "Fold: 25  Epoch: 8  Training loss = 0.7651  Validation loss = 3.3029  \n",
      "\n",
      "Fold: 25  Epoch: 9  Training loss = 0.7748  Validation loss = 2.9541  \n",
      "\n",
      "Fold: 25  Epoch: 10  Training loss = 0.6910  Validation loss = 2.7589  \n",
      "\n",
      "Fold: 25  Epoch: 11  Training loss = 0.7659  Validation loss = 2.9443  \n",
      "\n",
      "Fold: 25  Epoch: 12  Training loss = 0.7726  Validation loss = 2.8368  \n",
      "\n",
      "Fold: 25  Epoch: 13  Training loss = 0.7095  Validation loss = 2.9316  \n",
      "\n",
      "Fold: 25  Epoch: 14  Training loss = 0.8913  Validation loss = 2.9694  \n",
      "\n",
      "Fold: 25  Epoch: 15  Training loss = 0.6769  Validation loss = 2.9619  \n",
      "\n",
      "Fold: 25  Epoch: 16  Training loss = 0.7266  Validation loss = 3.1444  \n",
      "\n",
      "Fold: 25  Epoch: 17  Training loss = 0.6732  Validation loss = 2.9574  \n",
      "\n",
      "Fold: 25  Epoch: 18  Training loss = 0.7486  Validation loss = 2.9736  \n",
      "\n",
      "Fold: 25  Epoch: 19  Training loss = 0.6269  Validation loss = 2.8544  \n",
      "\n",
      "Fold: 25  Epoch: 20  Training loss = 0.6449  Validation loss = 2.6291  \n",
      "\n",
      "Fold: 25  Epoch: 21  Training loss = 0.5976  Validation loss = 2.6284  \n",
      "\n",
      "Fold: 25  Epoch: 22  Training loss = 0.6710  Validation loss = 2.5745  \n",
      "\n",
      "Fold: 25  Epoch: 23  Training loss = 0.6470  Validation loss = 2.5144  \n",
      "\n",
      "Fold: 25  Epoch: 24  Training loss = 0.6227  Validation loss = 2.4602  \n",
      "\n",
      "Fold: 25  Epoch: 25  Training loss = 0.6191  Validation loss = 2.4828  \n",
      "\n",
      "Fold: 25  Epoch: 26  Training loss = 0.6034  Validation loss = 2.6250  \n",
      "\n",
      "Fold: 25  Epoch: 27  Training loss = 0.5813  Validation loss = 2.7504  \n",
      "\n",
      "Fold: 25  Epoch: 28  Training loss = 0.6436  Validation loss = 2.7252  \n",
      "\n",
      "Fold: 25  Epoch: 29  Training loss = 0.5977  Validation loss = 2.5138  \n",
      "\n",
      "Fold: 25  Epoch: 30  Training loss = 0.5577  Validation loss = 2.5322  \n",
      "\n",
      "Fold: 25  Epoch: 31  Training loss = 0.6028  Validation loss = 2.7025  \n",
      "\n",
      "Fold: 25  Epoch: 32  Training loss = 0.6123  Validation loss = 2.8176  \n",
      "\n",
      "Check model:  Fold: 25  Optimal epoch: 24  \n",
      "\n",
      "Fold: 26  Epoch: 1  Training loss = 0.8319  Validation loss = 2.9580  \n",
      "\n",
      "Fold: 26  Epoch: 2  Training loss = 0.8034  Validation loss = 2.5341  \n",
      "\n",
      "Fold: 26  Epoch: 3  Training loss = 0.7227  Validation loss = 2.7675  \n",
      "\n",
      "Fold: 26  Epoch: 4  Training loss = 0.6292  Validation loss = 2.8382  \n",
      "\n",
      "Fold: 26  Epoch: 5  Training loss = 1.0681  Validation loss = 4.3643  \n",
      "\n",
      "Fold: 26  Epoch: 6  Training loss = 0.6257  Validation loss = 2.1797  \n",
      "\n",
      "Fold: 26  Epoch: 7  Training loss = 0.5416  Validation loss = 2.9931  \n",
      "\n",
      "Fold: 26  Epoch: 8  Training loss = 0.5113  Validation loss = 2.5671  \n",
      "\n",
      "Fold: 26  Epoch: 9  Training loss = 0.8249  Validation loss = 2.1363  \n",
      "\n",
      "Fold: 26  Epoch: 10  Training loss = 0.4775  Validation loss = 2.9240  \n",
      "\n",
      "Fold: 26  Epoch: 11  Training loss = 0.4578  Validation loss = 3.1573  \n",
      "\n",
      "Fold: 26  Epoch: 12  Training loss = 0.4252  Validation loss = 2.7372  \n",
      "\n",
      "Fold: 26  Epoch: 13  Training loss = 0.7191  Validation loss = 2.6329  \n",
      "\n",
      "Fold: 26  Epoch: 14  Training loss = 0.4789  Validation loss = 2.5074  \n",
      "\n",
      "Fold: 26  Epoch: 15  Training loss = 0.4601  Validation loss = 3.1970  \n",
      "\n",
      "Check model:  Fold: 26  Optimal epoch: 9  \n",
      "\n",
      "Fold: 27  Epoch: 1  Training loss = 0.7683  Validation loss = 2.1732  \n",
      "\n",
      "Fold: 27  Epoch: 2  Training loss = 0.8360  Validation loss = 2.3765  \n",
      "\n",
      "Fold: 27  Epoch: 3  Training loss = 0.6801  Validation loss = 1.7513  \n",
      "\n",
      "Fold: 27  Epoch: 4  Training loss = 0.6820  Validation loss = 1.4011  \n",
      "\n",
      "Fold: 27  Epoch: 5  Training loss = 0.6045  Validation loss = 1.6792  \n",
      "\n",
      "Fold: 27  Epoch: 6  Training loss = 0.6211  Validation loss = 2.1450  \n",
      "\n",
      "Fold: 27  Epoch: 7  Training loss = 0.6348  Validation loss = 2.1385  \n",
      "\n",
      "Fold: 27  Epoch: 8  Training loss = 0.7693  Validation loss = 2.5084  \n",
      "\n",
      "Fold: 27  Epoch: 9  Training loss = 0.5782  Validation loss = 1.9376  \n",
      "\n",
      "Fold: 27  Epoch: 10  Training loss = 0.6806  Validation loss = 2.5411  \n",
      "\n",
      "Fold: 27  Epoch: 11  Training loss = 0.6124  Validation loss = 1.9891  \n",
      "\n",
      "Fold: 27  Epoch: 12  Training loss = 0.4934  Validation loss = 2.3191  \n",
      "\n",
      "Fold: 27  Epoch: 13  Training loss = 0.5756  Validation loss = 2.0104  \n",
      "\n",
      "Fold: 27  Epoch: 14  Training loss = 0.6415  Validation loss = 2.6137  \n",
      "\n",
      "Check model:  Fold: 27  Optimal epoch: 4  \n",
      "\n",
      "Fold: 28  Epoch: 1  Training loss = 0.7797  Validation loss = 2.8721  \n",
      "\n",
      "Fold: 28  Epoch: 2  Training loss = 0.6083  Validation loss = 3.1047  \n",
      "\n",
      "Fold: 28  Epoch: 3  Training loss = 0.7030  Validation loss = 2.9991  \n",
      "\n",
      "Fold: 28  Epoch: 4  Training loss = 0.7226  Validation loss = 3.4232  \n",
      "\n",
      "Fold: 28  Epoch: 5  Training loss = 0.5827  Validation loss = 3.1218  \n",
      "\n",
      "Fold: 28  Epoch: 6  Training loss = 0.5983  Validation loss = 3.2539  \n",
      "\n",
      "Fold: 28  Epoch: 7  Training loss = 0.6504  Validation loss = 3.0026  \n",
      "\n",
      "Fold: 28  Epoch: 8  Training loss = 0.5443  Validation loss = 3.1964  \n",
      "\n",
      "Fold: 28  Epoch: 9  Training loss = 0.5565  Validation loss = 3.3830  \n",
      "\n",
      "Fold: 28  Epoch: 10  Training loss = 0.4966  Validation loss = 3.3313  \n",
      "\n",
      "Fold: 28  Epoch: 11  Training loss = 0.5462  Validation loss = 3.1539  \n",
      "\n",
      "Fold: 28  Epoch: 12  Training loss = 0.5389  Validation loss = 3.3178  \n",
      "\n",
      "Fold: 28  Epoch: 13  Training loss = 0.5362  Validation loss = 3.3392  \n",
      "\n",
      "Fold: 28  Epoch: 14  Training loss = 0.5001  Validation loss = 3.2688  \n",
      "\n",
      "Fold: 28  Epoch: 15  Training loss = 0.7337  Validation loss = 2.9774  \n",
      "\n",
      "Fold: 28  Epoch: 16  Training loss = 0.5102  Validation loss = 3.1217  \n",
      "\n",
      "Fold: 28  Epoch: 17  Training loss = 0.5964  Validation loss = 3.4302  \n",
      "\n",
      "Check model:  Fold: 28  Optimal epoch: 1  \n",
      "\n",
      "Fold: 29  Epoch: 1  Training loss = 0.9443  Validation loss = 2.4308  \n",
      "\n",
      "Fold: 29  Epoch: 2  Training loss = 0.8862  Validation loss = 2.7045  \n",
      "\n",
      "Fold: 29  Epoch: 3  Training loss = 0.8289  Validation loss = 2.1606  \n",
      "\n",
      "Fold: 29  Epoch: 4  Training loss = 0.8187  Validation loss = 2.4881  \n",
      "\n",
      "Fold: 29  Epoch: 5  Training loss = 0.7055  Validation loss = 2.4476  \n",
      "\n",
      "Fold: 29  Epoch: 6  Training loss = 0.6704  Validation loss = 2.4353  \n",
      "\n",
      "Fold: 29  Epoch: 7  Training loss = 0.7115  Validation loss = 1.7858  \n",
      "\n",
      "Fold: 29  Epoch: 8  Training loss = 1.0369  Validation loss = 2.2961  \n",
      "\n",
      "Fold: 29  Epoch: 9  Training loss = 0.7208  Validation loss = 2.8530  \n",
      "\n",
      "Fold: 29  Epoch: 10  Training loss = 0.5996  Validation loss = 2.0011  \n",
      "\n",
      "Fold: 29  Epoch: 11  Training loss = 0.7357  Validation loss = 1.7565  \n",
      "\n",
      "Fold: 29  Epoch: 12  Training loss = 0.6681  Validation loss = 1.6788  \n",
      "\n",
      "Fold: 29  Epoch: 13  Training loss = 0.6041  Validation loss = 1.7861  \n",
      "\n",
      "Fold: 29  Epoch: 14  Training loss = 0.5074  Validation loss = 1.8011  \n",
      "\n",
      "Fold: 29  Epoch: 15  Training loss = 0.4523  Validation loss = 2.0037  \n",
      "\n",
      "Fold: 29  Epoch: 16  Training loss = 0.4705  Validation loss = 1.8330  \n",
      "\n",
      "Fold: 29  Epoch: 17  Training loss = 0.4931  Validation loss = 2.3875  \n",
      "\n",
      "Fold: 29  Epoch: 18  Training loss = 0.4652  Validation loss = 1.9737  \n",
      "\n",
      "Fold: 29  Epoch: 19  Training loss = 0.4232  Validation loss = 1.9694  \n",
      "\n",
      "Fold: 29  Epoch: 20  Training loss = 0.5496  Validation loss = 2.2724  \n",
      "\n",
      "Fold: 29  Epoch: 21  Training loss = 0.5391  Validation loss = 2.5054  \n",
      "\n",
      "Check model:  Fold: 29  Optimal epoch: 12  \n",
      "\n",
      "Fold: 30  Epoch: 1  Training loss = 0.8012  Validation loss = 1.1994  \n",
      "\n",
      "Fold: 30  Epoch: 2  Training loss = 0.7980  Validation loss = 0.7636  \n",
      "\n",
      "Fold: 30  Epoch: 3  Training loss = 0.6387  Validation loss = 0.9348  \n",
      "\n",
      "Fold: 30  Epoch: 4  Training loss = 0.5792  Validation loss = 0.7746  \n",
      "\n",
      "Fold: 30  Epoch: 5  Training loss = 0.7307  Validation loss = 0.7561  \n",
      "\n",
      "Fold: 30  Epoch: 6  Training loss = 0.5225  Validation loss = 0.6956  \n",
      "\n",
      "Fold: 30  Epoch: 7  Training loss = 0.4913  Validation loss = 0.7691  \n",
      "\n",
      "Fold: 30  Epoch: 8  Training loss = 0.5237  Validation loss = 0.5735  \n",
      "\n",
      "Fold: 30  Epoch: 9  Training loss = 0.4721  Validation loss = 0.5698  \n",
      "\n",
      "Fold: 30  Epoch: 10  Training loss = 0.5535  Validation loss = 0.6265  \n",
      "\n",
      "Fold: 30  Epoch: 11  Training loss = 0.5471  Validation loss = 0.6759  \n",
      "\n",
      "Fold: 30  Epoch: 12  Training loss = 0.5122  Validation loss = 0.7456  \n",
      "\n",
      "Fold: 30  Epoch: 13  Training loss = 0.4632  Validation loss = 0.6662  \n",
      "\n",
      "Fold: 30  Epoch: 14  Training loss = 0.5714  Validation loss = 1.1095  \n",
      "\n",
      "Check model:  Fold: 30  Optimal epoch: 9  \n",
      "\n",
      "Fold: 31  Epoch: 1  Training loss = 0.4880  Validation loss = 0.7090  \n",
      "\n",
      "Fold: 31  Epoch: 2  Training loss = 0.5725  Validation loss = 0.9159  \n",
      "\n",
      "Fold: 31  Epoch: 3  Training loss = 0.4193  Validation loss = 0.4877  \n",
      "\n",
      "Fold: 31  Epoch: 4  Training loss = 0.4554  Validation loss = 0.7139  \n",
      "\n",
      "Fold: 31  Epoch: 5  Training loss = 0.4480  Validation loss = 0.8055  \n",
      "\n",
      "Fold: 31  Epoch: 6  Training loss = 0.3886  Validation loss = 0.3980  \n",
      "\n",
      "Fold: 31  Epoch: 7  Training loss = 0.3691  Validation loss = 0.5284  \n",
      "\n",
      "Fold: 31  Epoch: 8  Training loss = 0.3962  Validation loss = 0.5080  \n",
      "\n",
      "Fold: 31  Epoch: 9  Training loss = 0.3421  Validation loss = 0.4516  \n",
      "\n",
      "Fold: 31  Epoch: 10  Training loss = 0.4067  Validation loss = 0.5335  \n",
      "\n",
      "Fold: 31  Epoch: 11  Training loss = 0.3336  Validation loss = 0.5571  \n",
      "\n",
      "Fold: 31  Epoch: 12  Training loss = 0.3841  Validation loss = 0.4479  \n",
      "\n",
      "Fold: 31  Epoch: 13  Training loss = 0.3557  Validation loss = 0.3844  \n",
      "\n",
      "Fold: 31  Epoch: 14  Training loss = 0.3162  Validation loss = 0.5079  \n",
      "\n",
      "Fold: 31  Epoch: 15  Training loss = 0.3863  Validation loss = 0.6855  \n",
      "\n",
      "Check model:  Fold: 31  Optimal epoch: 13  \n",
      "\n",
      "Fold: 32  Epoch: 1  Training loss = 0.5190  Validation loss = 2.8194  \n",
      "\n",
      "Fold: 32  Epoch: 2  Training loss = 0.3671  Validation loss = 3.0249  \n",
      "\n",
      "Fold: 32  Epoch: 3  Training loss = 0.4251  Validation loss = 3.0975  \n",
      "\n",
      "Fold: 32  Epoch: 4  Training loss = 0.4177  Validation loss = 2.6240  \n",
      "\n",
      "Fold: 32  Epoch: 5  Training loss = 0.3170  Validation loss = 2.8411  \n",
      "\n",
      "Fold: 32  Epoch: 6  Training loss = 0.3433  Validation loss = 3.0213  \n",
      "\n",
      "Fold: 32  Epoch: 7  Training loss = 0.3481  Validation loss = 2.9817  \n",
      "\n",
      "Fold: 32  Epoch: 8  Training loss = 0.4048  Validation loss = 3.1518  \n",
      "\n",
      "Fold: 32  Epoch: 9  Training loss = 0.4629  Validation loss = 2.9331  \n",
      "\n",
      "Fold: 32  Epoch: 10  Training loss = 0.3339  Validation loss = 2.8820  \n",
      "\n",
      "Fold: 32  Epoch: 11  Training loss = 0.3389  Validation loss = 2.9104  \n",
      "\n",
      "Fold: 32  Epoch: 12  Training loss = 0.3289  Validation loss = 3.0207  \n",
      "\n",
      "Fold: 32  Epoch: 13  Training loss = 0.4081  Validation loss = 2.7278  \n",
      "\n",
      "Fold: 32  Epoch: 14  Training loss = 0.3291  Validation loss = 2.9338  \n",
      "\n",
      "Fold: 32  Epoch: 15  Training loss = 0.3826  Validation loss = 3.0435  \n",
      "\n",
      "Fold: 32  Epoch: 16  Training loss = 0.3227  Validation loss = 3.0477  \n",
      "\n",
      "Fold: 32  Epoch: 17  Training loss = 0.3468  Validation loss = 2.9465  \n",
      "\n",
      "Fold: 32  Epoch: 18  Training loss = 0.2833  Validation loss = 2.8971  \n",
      "\n",
      "Fold: 32  Epoch: 19  Training loss = 0.3109  Validation loss = 2.7213  \n",
      "\n",
      "Fold: 32  Epoch: 20  Training loss = 0.4129  Validation loss = 2.5339  \n",
      "\n",
      "Fold: 32  Epoch: 21  Training loss = 0.3470  Validation loss = 2.9294  \n",
      "\n",
      "Fold: 32  Epoch: 22  Training loss = 0.3828  Validation loss = 2.8971  \n",
      "\n",
      "Fold: 32  Epoch: 23  Training loss = 0.3802  Validation loss = 2.9271  \n",
      "\n",
      "Fold: 32  Epoch: 24  Training loss = 0.3865  Validation loss = 3.0340  \n",
      "\n",
      "Fold: 32  Epoch: 25  Training loss = 0.4250  Validation loss = 2.8527  \n",
      "\n",
      "Fold: 32  Epoch: 26  Training loss = 0.2806  Validation loss = 2.8679  \n",
      "\n",
      "Fold: 32  Epoch: 27  Training loss = 0.2981  Validation loss = 2.9819  \n",
      "\n",
      "Fold: 32  Epoch: 28  Training loss = 0.3150  Validation loss = 2.9892  \n",
      "\n",
      "Fold: 32  Epoch: 29  Training loss = 0.2913  Validation loss = 2.8403  \n",
      "\n",
      "Fold: 32  Epoch: 30  Training loss = 0.2787  Validation loss = 2.8478  \n",
      "\n",
      "Fold: 32  Epoch: 31  Training loss = 0.2975  Validation loss = 2.7800  \n",
      "\n",
      "Fold: 32  Epoch: 32  Training loss = 0.2700  Validation loss = 2.8601  \n",
      "\n",
      "Fold: 32  Epoch: 33  Training loss = 0.3277  Validation loss = 2.8871  \n",
      "\n",
      "Fold: 32  Epoch: 34  Training loss = 0.3181  Validation loss = 2.5372  \n",
      "\n",
      "Fold: 32  Epoch: 35  Training loss = 0.5344  Validation loss = 2.4577  \n",
      "\n",
      "Fold: 32  Epoch: 36  Training loss = 0.2808  Validation loss = 2.7808  \n",
      "\n",
      "Fold: 32  Epoch: 37  Training loss = 0.2941  Validation loss = 2.8832  \n",
      "\n",
      "Fold: 32  Epoch: 38  Training loss = 0.2646  Validation loss = 2.7704  \n",
      "\n",
      "Fold: 32  Epoch: 39  Training loss = 0.2788  Validation loss = 2.6868  \n",
      "\n",
      "Fold: 32  Epoch: 40  Training loss = 0.3633  Validation loss = 3.0402  \n",
      "\n",
      "Check model:  Fold: 32  Optimal epoch: 35  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 2. Train model\n",
    "# ==================================\n",
    "sess = tf.InteractiveSession()  # Launch Graph\n",
    "sess.run(tf.global_variables_initializer())  # Initialise all variables\n",
    "\n",
    "print(\"Start training\", \n",
    "      \"\\nHyperparameters:\",\n",
    "      \"\\nDimension of recurrent unit =\", n_hidden,\n",
    "      \"\\nLearning rate =\", learning_rate,\n",
    "      \"\\nEpochs =\", epochs,\n",
    "      \"\\nBatch size =\", batch_size,\n",
    "      \"\\nEarly stopping epochs =\", early_stop_iters,\n",
    "      \"\\nLearning rate =\", learning_rate)\n",
    "\n",
    "total_batch = int(window_length / batch_size)\n",
    "validation_fold_error = [] # store validation error of each fold\n",
    "optimal_epochs = []\n",
    "\n",
    "# loop through folds\n",
    "for fold in range(1, len(valIndex)):\n",
    "    validx = train_features[valIndex[fold-1]:valIndex[fold]]\n",
    "    validy = train_target[valIndex[fold-1]:valIndex[fold]]\n",
    "    trainx = train_features[(fold-1)*4:valIndex[(fold-1)]]\n",
    "    trainy = train_target[(fold-1)*4:valIndex[(fold-1)]]\n",
    "\n",
    "    loss_list = [] # store validation loss after each epoch for early stopping\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i in range(total_batch):\n",
    "            # Backprop\n",
    "            batch_xs, batch_ys = next_batch(num=batch_size, data=trainx, labels=trainy)\n",
    "            optimizer.run(feed_dict={x:batch_xs, y:batch_ys, lr:learning_rate})\n",
    "\n",
    "        # Loss\n",
    "        loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "        loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "        loss_list.append(loss_valid)\n",
    "\n",
    "        print(\"Fold: {0:d}\".format(fold),\n",
    "              \" Epoch: {0:d}\".format(epoch+1),\n",
    "              \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "              \" Validation loss = {0:.4f}\".format(np.sqrt(loss_valid)),\n",
    "              \" \\n\")\n",
    "\n",
    "        if all(j <= loss_valid for j in loss_list[-early_stop_iters:]) and len(loss_list)>early_stop_iters:\n",
    "            break\n",
    "    \n",
    "    # Load model with lowest validation error for each fold\n",
    "    epoch_hat = np.argmin(loss_list) + 1\n",
    "    optimal_epochs.append(epoch_hat) # store optimal number of epochs for each fold\n",
    "    \n",
    "    # RMSE\n",
    "    loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "    loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "    validation_fold_error.append(np.sqrt(loss_valid))\n",
    "    \n",
    "    print(\"Check model:\",\n",
    "          \" Fold: {0:d}\".format(fold),\n",
    "          \" Optimal epoch: {0:d}\".format(epoch_hat),\n",
    "          \" \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average number of epochs: 12\n",
      "Average validation error: 3.39587\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 3. Optimal epoch choice\n",
    "# ==================================\n",
    "# Pick number of epochs to train model for out-of-sample testing\n",
    "epoch_hat = int(np.mean(optimal_epochs))\n",
    "print(\"\\nAverage number of epochs:\", epoch_hat)\n",
    "# Average validation error\n",
    "print(\"Average validation error:\", np.mean(validation_fold_error))\n",
    "\n",
    "# Save validated model\n",
    "saveModel(sess, \n",
    "          MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + str(epoch_hat) + \"_validated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fixed scheme:\n",
      "Epoch: 1  Training loss = 0.6782  Test loss = 3.6298  \n",
      "\n",
      "Epoch: 2  Training loss = 0.6433  Test loss = 3.6019  \n",
      "\n",
      "Epoch: 3  Training loss = 0.6168  Test loss = 3.5726  \n",
      "\n",
      "Epoch: 4  Training loss = 0.5946  Test loss = 3.5503  \n",
      "\n",
      "Epoch: 5  Training loss = 0.5754  Test loss = 3.5314  \n",
      "\n",
      "Epoch: 6  Training loss = 0.5585  Test loss = 3.5150  \n",
      "\n",
      "Epoch: 7  Training loss = 0.5434  Test loss = 3.5008  \n",
      "\n",
      "Epoch: 8  Training loss = 0.5298  Test loss = 3.4884  \n",
      "\n",
      "Epoch: 9  Training loss = 0.5174  Test loss = 3.4774  \n",
      "\n",
      "Epoch: 10  Training loss = 0.5060  Test loss = 3.4675  \n",
      "\n",
      "Epoch: 11  Training loss = 0.4954  Test loss = 3.4585  \n",
      "\n",
      "Epoch: 12  Training loss = 0.4855  Test loss = 3.4502  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 4. Fixed scheme\n",
    "# ==================================\n",
    "print(\"\\nFixed scheme:\")\n",
    "for epoch in range(epoch_hat):\n",
    "    x_train = train_features[-window_length:]\n",
    "    y_train = train_target[-window_length:]\n",
    "    optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:test_features, y:test_target})\n",
    "    print(\"Epoch: {0:d}\".format(epoch+1),\n",
    "          \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "          \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "          \" \\n\")\n",
    "\n",
    "# Forecasts\n",
    "yhat_test_fixed = pred.eval(feed_dict={x:test_features})\n",
    "yhat_train_fixed = pred.eval(feed_dict={x:x_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc0a7080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train set\n",
    "plt.plot(y_train, 'black')\n",
    "plt.plot(yhat_train_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD9CAYAAAC1DKAUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzsnXlc1HX+x1+fAYZbQTxQwQNFQFBRUTTNo1Kzsq201i7z\nKDt1u7a2+rW6tbuV7paVrmZpmUe2lpWb5llpaB4oooIHIKgcAoKA3Md8fn+8v9+Z7wxzMgMzwOf5\nePgY+M535vthnO/n9XmfH8Y5h0AgEAjaHypnD0AgEAgEzkEIgEAgELRThAAIBAJBO0UIgEAgELRT\nhAAIBAJBO0UIgEAgELRTbBIAxthaxlgBY+yM4lgnxtgexlia9Bho4rWPSeekMcYes3fgAoFAILAP\nWy2ALwDcbnDsLwD2cc7DAeyTfteDMdYJwCIA8QBGAlhkSigEAoFA0DLYJACc8wMAig0O/wHAOunn\ndQDuMfLSKQD2cM6LOefXAexBYyERCAQCQQviiBhAN855nvTzVQDdjJzTE8AVxe/Z0jGBQCAQOAl3\nR74Z55wzxuzqLcEYmw9gPgD4+voOj4yMdMjYBAKBoD1w/Pjxa5zzLtac6wgByGeMdeec5zHGugMo\nMHJODoAJit9DAPxq7M0456sBrAaAuLg4npiY6IAhCgQCQfuAMXbJ2nMd4QLaBkDO6nkMwA9GztkF\nYDJjLFAK/k6WjgkEAoHASdiaBvoVgN8BRDDGshlj8wC8C2ASYywNwG3S72CMxTHGPgMAznkxgLcB\nHJP+vSUdEwgEAoGTYK7cDlq4gAQCgcA2GGPHOedx1pwrKoEFAoGgnSIEQCAQCNopQgAEAoGgnSIE\nQCAQCNopQgAEgtbG0aPA4cPOHoWgDeDQSmCBQNACPPssUFkJpKQ4eySCVo4QAIGgNVFfD5w+DdTW\nAmVlQIcOzh6RoBUjXEACQWsiLQ2oqQE4B44fd/ZoBK0cIQCuSG4uUFHh7FEIXJHkZN3PR486bxyC\nNoEQAFdk3Djg8cedPQqBK5KcDLi7A717A0eOOHs0glaOEABXo6EByMwEtmwBcnKcPRqBq3HqFBAV\nBYwdKywAgd0IAXA1iooAjYaEYPVqZ49G4GokJwNDhgAjR9ICQSwSBHYgBMDVyM+nR19fEoDaWueO\nR+A6FBXRhC8LAAAcO+bcMQlaNUIAXA1ZABYsAK5eBbZude54BK7DqVP0OHgwEBsLeHiIOIDALoQA\nuBqyAMyaBfTrB6xYof/8jRvAH/4AREcDt94KPPww8NJLwJkzLT9WU5w+DVy+7OxRtD3kDKAhQwAv\nL3oUcQCBHQgBcDVkAejeHXjmGSAhQXfjV1YCd90FbN8O9O8PVFdTS4Bly4B333XemA25917gxRed\nPYq2x6lTQNeuQLdu9PvIkeQC0micOy5Bq0UIgKuRnw+o1UDHjsCcOYC3N1kBNTU0sf72G7BhA/DD\nD8DBg0BGBhAfT+4iV6CyErh4ETh71tkjaXvIAWCZkSPJIjx/3nljErRqhAC4Gvn5tMJjDAgMBB56\nCNi4EbjvPmD3bmDNGmDmTP3XBAe7jgCkpVGVano6ZTIJHEN9PfX+MRQAQLiBBE1GCICrcfWqzsQH\ndI2/duwAli8nq8AQVxIAeTVaWwtcueLcsbQlLlwgK3DwYN2xiAjA318EggVNxm4BYIxFMMZOKv6V\nMcaeNzhnAmOsVHHOX+29bptFtgBkhg4FXn4ZWLWKxMAYwcGUIugKKaPnzul+vnDBeeNoaygDwDIq\nFTBihLAABE3G7m6gnPPzAGIBgDHmBiAHwHdGTv2Nc36Xvddr8+TnA8OG6R9butT8a4KD6bGgAAgJ\naZ5xWcv584CfH1BeTgIwebJzx9NWOHWK0j4jI/WPx8fT96O6mjKDBAIbcLQL6FYAGZzzSw5+3/aB\nRkOTuDyhW4t8viu4gc6fB266iUQgLc3Zo2md7N8P7N2rfyw5mVpAqNX6x0eOpPjAyZMtNz5Bm8HR\nAjATwFcmnhvNGEtmjP3EGIt28HXbBsXFFDhVuoCswVUEgHMSgMhIYMAA4QJqKo8/Dtx5p75v3zAD\nSEYEggV24DABYIypAdwNYIuRp08A6M05HwLgYwDfm3mf+YyxRMZYYmFhoaOG1zqQawBaqwDk5pLr\nJyJCCEBTuXiRMqjq64Hp0+n/9No1+myVAWCZHj2Anj1FIFjQJBxpAUwFcIJznm/4BOe8jHNeLv28\nA4AHY6yzsTfhnK/mnMdxzuO6dOniwOG1ApoqAPL5zhYAOQMoMhIIDweyslwjMN2a2L2bHjdvBq5f\nB+6/X7fxizELAKA4wO+/t8z4BG0KRwrAgzDh/mGMBTPGmPTzSOm6RQ68dtugqQLg6Uk1A84WADkD\nSLYANBpa0QqsZ9cu6vU/YwbVfCQk6PaGMCUAY8ZQC/G8vJYbp6BN4BABYIz5ApgEYKvi2FOMsaek\nX2cAOMMYSwbwEYCZnHPuiGu3KZoqAIBr1ALIGUA9epAAAMINZAt1dcC+fcCUKVQIOHMmpQBnZ9N3\nomtX468bO5YeDx5subEK2gQO2RSec14BIMjg2CrFz8sBLHfEtdo0+fmU6hcYaPtrXUUAIiJo8goP\np2NCAKzn8GFq7TBliu7YO+/QZ2huUTB0KLUMSUggy0EgsBKHCIDAQVy9Sqs88pbZRnCw8zNBzp0j\ndwRAIta5s0gFtYXduwE3N+CWW3TH3N2p75M5PDwoG0hYAAIbEa0gXIn8fNtrAGScbQFUVVEL6IgI\n3TGRCWQbu3ZRQDcgwPbXjh0LJCVRFpZAYCVCAFwJwzYQthAcDFRUOG8CkJvACQFoGteuAYmJ+u4f\nWxgzhmpInG0FCloVQgBcCXsFAHCeFSBnAClbFYSH62oDBObZu5cEtKkCMHo0uQ6FG0hgA0IAXAXO\nqQ1EaxUAuQZADv4Cukyg9PSWH09rY9cuipvExTXt9QEBQEwMBYIFAisRAuAqXL9OaYCtWQB69QJ8\nfHTHRCqodXBOAeDbbqMgcFMZM4YKwsQ+DAIrEQLgKthTAwA4XwDOnWvcqbJ/f3psbgGYMwf4v/9r\n3ms4kJycHOTm5uoOpKSQq6yp7h+ZsWMpjdSV9ocWuDRCAFwFewUgKIhWj84QALkJnDIADJA1EBLS\nvKmg1dXApk20a1orgHOOqVOnYv78+bqDu3bRo70CIKfgCjeQwEqEALgK9gqAmxvVEDhDAPLydE3g\nDGmGTKDFixdj5cqV9EtiIvUbysqiVbSLc+rUKZw+fRolJSW6g/v2Uatne/dy6N2bqrBFIFhgJUIA\nXAV54m5qHYD8WmcIgLEMIJlmEIC1a9fiiy++oF9++033xKFDDr1Oc7Bp0yYAQK2ySd7Zs1TNay+M\nkRtIWAACKxEC4Crk51PVZ1PaQMg4SwDkDCBjFkB4OO1zUOSY3n8ajQZ5eXm4cOECOOc02fXvT7th\nufjKV6PR4KuvqF+iVgBqa6mATo6X2MuYMbQXs9iPWWAFQgBchfx8cuGo7PgvcaYF4OtLfekNkTOB\nHBQHKCwsRH19PUpKSlCYn0+T/sSJ1ArBxS2AhIQEXLlyBd7e3qipqaGDWVnUNdWRAgC4vBgKXAMh\nAK6CPUVgMsHB9D4ajWPGZC3KJnCGODgVNCcnR/tz9s6dQGkpcPPNtA3liRNAZaVDrtMcbNq0CT4+\nPpgyZYrOApBrJBwlAEOGkBgLN5DACoQAuAqOEoD6enK5tCTp6foFYEr69qUAdTMIQLW8b+7YsbTy\nra+noLALUltbiy1btuAPf/gDOnXq1FgA+vVzzIXc3amfkNghTGAFQgBcBUcJANCybiDOgZwcIDTU\n+PMeHiQCDnIBKQXA+8QJynrp04daIQAu6/rYvXs3iouL8fDDD8PT01NfAPz9AUfufhcTQ4HllrYE\nBa0OIQCuAOetVwCuX6dc/B49TJ/Tr5/DdgbLycmBSqXCgPBwhGZl0eqfMaqDiIx02TjAxo0bERQU\nhMmTJ0OtVusLQP/+TWsBboqBA6kxYHa2495T0CYRAuAKlJZSNkhrFAB5RW4sACzTt6/DBCA3Nxfd\nunXD+L590bmqivz/MjfdRALgYivf8vJy/PDDD3jggQfg4eGhLwAZGY7z/8tERdFjaqpj31dgHUVF\nrWYfDCEAroBcBGZPDYDy9S0pAHLxlTkBCAujuERpqd2Xy8nJQc+ePTHRwwMA0CC7fgCKAxQXu1zv\noR9++AFVVVV46KGHAEAnAPX1tJevo/z/MgMH0uPZs017/d69wOuvA99+SymqYvdW23j1VWDyZGeP\nwiocJgCMsSzG2GnG2EnGWKNIHCM+YoylM8ZOMcaGOerarR57q4Bl/P1pa0BnWADmXEBhYfSYmemA\ny5EADC0vRymALH9/3ZM33USPLhYHWL9+PXr16oWbpPGp1WrU19dDc+kSNQB0tAXQuTPFFJpqAbz1\nFm1FOWMGVRcHBwPvvuvYMbZlUlKAS5fIqndxHG0BTOScx3LOjfW0nQogXPo3H8BKB1+79SJP2PYK\nAGMtXwtgiwA4wA0kC0Do5cs4BOBCRobuyYgIoFMnx8UBrl4FliyhoOorrzTpLdLT07F7927MmTMH\nKqnGQ61WAwDq5QpqRwsAQG6gploAly4BDzxAm8usWEGf61//Su3KBZaRN0dqBa1JWtIF9AcAX3Li\nMIAAxlj3Fry+6+IoCwBoeQHIzaUVp6en6XP69qVHOwWgqqoK169fR1hAAHwzM5EA4ILS3cMYWQH2\nWgBJScA991BvnldfpWKt775r0lutXLkSbm5uePLJJ7XHZAFokCuom0MABg4kC8BW9019PYl6eDgw\nYgTwzDPAJ5+QpbJunePH2da4fl1X9d4KgvCOFAAOYDdj7DhjbL6R53sCUNanZ0vHBPn5lCsfFGT/\neznDAjC3+gdos5LAQLtdQHIL5SEVFQCAk35+OC9PojJjxlBh2rVr9PuxYzSRjRtHhWLW8PDD1GPo\nxRdpFf3nP1Ow1kSRWWlpKW7cuNHoeEVFBdauXYsZM2age3fdWkcWAJ6RQS0sujfDOigqiiYjeXFh\nLbm5tJ9A797673XzzcDq1SIeYAnl5ketoB2HIwVgLOd8GMjV8yxjbFxT3oQxNp8xlsgYSywsLHTg\n8FyY/Hzy2drTBkLGGQJgLgAsExZmtwUg1wD0y8sDPDxwIzJS3wIAdHGAvXuBF14ARo2iMZ47R7tt\nPfmkThyMce2abtJfsoRSS2NiaOIz4VKZPn06Ro8ejaqqKr3jmzZtQklJCZ599lm9456StcQyMigA\n7Ij/d0OaGgi+dIkee/XSP/7EEzS5/fqr3UNr07RXAeCc50iPBQC+AzDS4JQcAMpqoRDpmOH7rOac\nx3HO47o4sjjGlXFEDYBMcDCZoC0VgMrNbVEBGAMg5MABYPhw9ImKamwBxMVRNezDDwPLltGEf/Ys\nZQb96U/AmjXUnmLbNuMXOXyYHmUhAUgAAJMbrSQlJSElJQWvv/669hjnHMuXL8eQIUMwRu7PIyFb\nAG6Zmc3j/gF0AmBrIFgWAKUFAFBAOCAA+PRT+8fWlpHTP3182o8LiDHmyxjzl38GMBmA4d2yDcAs\nKRtoFIBSznmeI67f6nG0AAAtE7Crq6OxW3IBARQHkBufNYX8fAz697+RAMDN3R1YsgQDBgxAdnY2\nKiSXEAC68aZMoQkwIQH4z3+Ajh1p8vrgAyA5mT6j114zfp1Dh0hAlHvz9utHMQ4jAlBUVITi4mIE\nBwdj2bJl2Cu1p0hISMCpU6fw3HPPgRkUeanVajAA7pcuNZ8AdO8OdOhguwVw+TI9GloA3t7Ao49S\naqg5C6q9k55OVfF9+7YrC6AbgATGWDKAowC2c853MsaeYow9JZ2zA8BFAOkAPgXwjIOu3fppDgFo\nCTfQ1avkGrHWAqitbVpmxJYtQEQEIpOSsNTdHezsWeDmmxEhtZ9OMyy6+d//gNOndZ0xlURH0xaS\nqanGx3LoEPXmV+xt/J/Vq1EcHGxUAGQX1EcffYTIyEjMnj0bxcXFWL58OQICArS5/0rUajV6AFDV\n1Di+BkCGMV0g2BYuXaKgvuLvX79+PTZv3kxuoNpaYP16Bw+2DZGWRqIeEtJ+LADO+UXO+RDpXzTn\n/B/S8VWc81XSz5xz/iznvB/nfBDnvGW7dl2/Tpkczz5LHRPlDUWawsmT9H6OQM66MNVLx1ZaUgCs\nKQKTsScV9PXXgdBQvDx5Mj7t2xfMzw8AMEDqNNooDmCprcKkSfQoN5OTqauj1EeF+yc9PR0LFy7E\nobIyowIgu6BiY2OxYcMG5Ofn46GHHsLWrVsxb948+CgmUhm1Wg3ttN9cFgBAwdumCIDk/tFoNHj1\n1Vcxa9YsvPLKK8CgQRRTsTcYzLnLVWs7DLkxYmhou7IAXBfOgYceolXNffdRKlteHrBoEU2+xti4\nkVaQxjhzhrJKHnzQMePLzqZxyKmS9mKNAFy54pCqXKtqAGSaKgCc02c0ZQoSb9xAT4XYhEsdSBsJ\ngCUGD6ag+549+seTk4GqKj0BeOutt9DQ0EACkJ0NKLdylK7t7u6Ovn37Yvjw4Vi8eDF27dqFhoYG\nPP3000Yvr1aroZ32m1MABg4k69KW7rCXLwO9e6Ourg6zZ8/GkiVL0LdvX1y5cgXXr18H5s+ngLo9\nqbazZ9P9+NxzwPHjbSezqKSE3GP9+5MA5OcD8r4PLkrbF4ALF4CvviIR+O03uhk++YS+6D/+2Pj8\npCTgkUeAqVMb72Kl0QBPPUUT9q5d9OW1Fzk1Up4g7UV2JZkSAM7JNXLPPfbfeNb0AZLp1YuyXYwI\nwHfffYcEU/3r5WZzISHaIjAZHx8fhIaGNg4EW0KlAm67jSwA5Wfw++/0KAlAamoqNmzYgLCwMCQ3\nNNBzKSl6b3XhwgX069cP7u7uAIBXX30VU6dOxaxZs9BPdu8cPQqcOqV9jSwAGnd3x1l+xrA1E4hz\n4NIl1HbvjmnTpmH9+vX4+9//jhUrVgCg/YzxwAMUW1i9umljungR2LCBYhSffUaxliFDyM3X2pEz\ngMLDdfs7u3gxWNsXgJ076fHtt6lzpFoNTJtGE9LHHzc+/+9/p5YKBQWUQaKcINasoZXPsmUUWHzn\nHfvHJwuAoywAT0/KuTf1xUtJIQvg119NZ8JYS24utXvu3NnyuR4eNNkZ1AJwzvHkk09i0aJFxl8n\niQzv0QO5ubnoYWBtDBgwwHYLACA30NWr+m6dQ4dojNLNu3jxYvj5+WHVqlW6jAYDN9D58+e1rigA\ncHd3x44dO/D555/TgVWrqFX11KkkZNAJQFVwMAWcmwu5KZy1AlBUBFRW4quDB7Fnzx589tlneOON\nNzBkyBAAkgD4+gLTp1OcxZQFbY4PP6Salz176PNfuZLusUcecUirEKcix6JkCwBweTdQ2xeAn36i\nXO4+fXTH3N2Bp58Gfv5Z30d6+jSwdSvlj//jH5TxsHYtPZefT+0Axo8HFi4k83Xr1qaX28tkZtIN\n4ciV4ODBptsh7NtHjyEh9PfU1TU6ZefOnThtygWmJCeHVnLW5rEbSQW9cuUKCgsLTa/ipUBaqZ8f\namtr9SwAAIiIiMD58+dpf2BbuO02elS6gQ4d0q7+T548iS1btuCFF17A2LFjcQVAjVqtJwAajQZp\naWnaYLQSxjlVET/9NAWVc3NpxQuqA+gPoMJRgX9T9O5N2TvWxgGkDKAfT5/GwoULMW/ePABA9+7d\nERQURAIAALffTu6OY8dsG09JCS2iHnyQ3IYBAWRR79xJ96SpzKzWgnJzH/l+dvFAcNsWgKoqYP9+\n+sIa8vjjtFpevlx37O23afX//PPASy8Bt9xCk/2FC/R7RQWt6BijnHIvL+C99+wb48WL9GVx5Erw\njjvIn23sy7dvH31BV66kv+uTT/Se5pzjwQcfxD/+8Q/L17G2CEzGiAAkSjt45eTkGK2mlS2AXElk\nDAVgwIABKC0thc1Fg6Gh1ONGFoDsbJoAJQF48803ERgYiBdeeAHe3t7oHx6OLD8/PQG4cuUKampq\n9CwAALTSf+ghKiR76imqLbj5ZmqoVlMDtYcH+gG40dwCoFLZ1hNIqgG42NCARx55RHuYMYYhQ4Yg\nOTmZDtx2G90Du3fbNp7Vq+keevFF/eM9ewIvvwx8/bWuDqM1kpZG3ytvb50LSFgATuTXX+lmnDq1\n8XOdO9NK5MsvKSCakgJ88w1N+IGBdPN8+SVN8pMnU2D4L38hawKgIOL8+eTPzMrSe+tXX30V26x1\nr2RmOs79I3PnnfT400/6x+vrSRBvvZXOueUWYPFivcBmRkYGbbhuzYRqbRGYTN++ZPYrWiokKrZw\nNOrKyckBGMMlqbDNmAVg8rWWmDQJOHCAAnUK///hw4fx448/4s9//jMCAgIAADExMRQHOH1a6xaU\nrZZGAjBnDk1m771HdQju7pR0kJMDrFkD7/JydABQ2hKFjrZkAkkC4B4WhmHD9Jv1Dh48GGfOnEFD\nQwM13BsxguJg1lJbC3z0EX33JJeSHn/+MyUwvPRS6w0Ky5v7AICfH1k4QgCcyM6dpMbjTHSlWLCA\nViRffEEuHx8fcv/I9OxJZrtcsKOo9ARAqxaVCli6VHsoLS0NS5YswYsvvgiNNalumZmNAsDZ2dnG\nV8PWMnAgxTi2b9c/npgIlJXRTcgY8K9/UVBcEcs4LgW2iwwD4Mawpg+QEvnvVAhmYmIiOnToAAA4\nJ3fHNLxG167IlnraGIsBALA9EAyQAFRW0uR/6BB9V4YMwbvvvosuXbpgwYIF2lNjYmJwsKyM/ORS\nkZ0sOnouoGvXaCHx4ovkYpNTUm+5hYLv77wDX+nvv25N7MReBg4ky6a83OKp5ampqAAw9ZFHGhWv\nDR48GFVVVciQu69OmUL7DhtkRZlkyxb6v3zpJePP+/mRBX7oELlWWyNpafp7Y7eCWoC2LQA//QRM\nnEireGMMG0YBuvfeAzZvJr++YUO2e++lLKJt2xq/T0gI8Nhj5NeUsm6++uorALSS/slwBW5IZSW9\nTmEB1NTUYNiwYXjuueds+lP1YIxW+Hv36qehyXnvt9xCj0OHArNmUVBbmpTkFblFAbhxg/7Z6gIC\ntG4gzjkSExNxzz33wM3NzbgAZGcDPXtq+wB1N2ic1rt3b6jVaqstgOzsbLz++uv44YcfgAkTdAHJ\nQ4doVevhgbS0NIwfPx5+Ur0BQAJwWl6ZSvGRCxcuwN/fH92UrpxvvyVLa9Ys/QszRtZWdjaCli0D\nAFwPDLRqzHYhB4KNfbYG5B0+jMsAHjRSvKYXCAbIKtZodDElc3AO/PvfNJYpU0yfN2cOtd149dVW\n0UtfD2UKqEwrqAVouwKQkUGKbMz/r2TBAqoL8PY2vTqZOVN3IxkiB1JnzABPSsKmTZswZswY9OjR\nAx999JHRl1y8eBHl5eW6lbBCAHbs2IHCwkJ8++23qDTRfdIq7riDrJsDB3TH9u0DYmP1s3b+/nea\nBJcsAWCDANhSBCZjIABZWVm4fv06xowZg7CwMNMWQEgIcnNz0bVrV20fHRk3NzeEh4cj1YKb48KF\nC5g3bx7CwsLwzjvv4OOPP6Z0xlGjKKPlxAmt///69eta149MTExMo0ygCxcuYMCAAfqr5a++Ijfh\n4MGNB3HrrcBNN8EzMRENAK4pBKbZsKEnUF1GBq536GA0qD1w4ECoVCpdHCA+nuJl1sQB9u+n9OoX\nXzSfMODmRlZpRga5zpqKRmObG+nLL5u834MWZQqoTGiosACchpz+acz/r2T6dFLtl18mv76thIeT\nBXDuHDB8OF47fx7PTJuGZ555Brt37240qZ0/fx7R0dF49NFHjaaArl+/Hh4eHqioqMCPxuoUrOWW\nWyjIvWMH/V5ZSavcW2/VPy8khFxkhw5Bo9Hg+PHjUKlUqKqqMi9AthSByXTuTGmEkgDIYhMXF4fI\nyEjTAiBZAIb+f5lhw4bh2LFjJjOBFi1ahMjISGzatAnz58/HqFGjqKgJIDfQ6dO0alcIQKDB6jw8\nPBwlHh4o9/HRCoBhCihyckhwZ840Xo3MGMUCAFwGUN0Svu5+/SgF10Ig+MKFC+hcWQlfWTAM8PLy\nQkREhM4C8PCg79KuXZYn288+I8v64Yctj3fKFLLMlMkZtjJ3ri7Lyxo2bbKvMwCgnwIqExJC7kIX\nLgZruwLw00/05bdUaalWUzbM4sVNv9bs2UB6On6Ni8MfATy4eDGe69ULnp6eWK74ItfX1+Oxxx5D\ndXU1fvjhBxQePUpPSCvj4uJi/Pjjj3j66afRo0cPrTupSfj4kPtLjgMcPEhmtaEAAOQKS0lB+pkz\nuHHjBkaOpEauZq0AW4rAZBijv1USvsTERKjVasTExCAyMhJpaWkUZJSpqiKfuyQAhv5/mfj4eOTn\n5+Oy3MhMQUNDAz744ANMnjwZWVlZWL58Ofr3768TAOVEMXo0qqurUV1d3cgC8PDwQGRkJDK8vYEz\nZ1BdXY1Lly7pr5b/+1+aDGfONP0ZTJqEhnHjcAzQbQzfnLi7U/dTgwI2Q7asW4euAPrcfLPJcwYP\nHqwTAIDcQJcuWd4APSuLAr/e3taNefJksgKsjS8o+f13qvZPtKHTTGYmfc9Mxex27rSc7adMAZVp\nBamgbVMAqquBX36xvPqXYcxy/xgLaDp0wKO5uXj21lvBgoLQ8fvv8eCDD+KLL75AqdR2YenSpThy\n5Ag++OADuLu748y2bTRRd+0KAPjvf/+Luro6PPbYY/jjH/+IHTt2oKQpN4HMnXfSzZmWRv5/Dw9K\nRzRk2DCgvh4XpcylKZKf1qwAyC4gI5NyQUGB9m9uhCIVNDExEYMHD4ZarUZERARqampwSW5HrLyG\nBQsgPj4eAHDkyJFGz52RRO2RRx7R+uoDAwN1AjByJLkyBgwAOnfWft6GFgBAbqATtbVASgoy0tLA\nOde3ADZvpriKEReKFsbAd+7Eg2i6AHz00Ud45ZVXUG9tIdaIEVQFb6TmA6BYTMKmTQCAjsZcVxJD\nhgxBVlaW7v9W9udbygbKz9d+x61i6FB6PHnS+tcAJL4vv0w/l5VRjMoSGo2uS62plhmffUYZgKaq\n1QG6x0INn/2bAAAgAElEQVRC9EVOCICT+O03cnlYKwAOueRvyMnJwaTHH6fy9rNnsWDBAlRUVODz\nzz/HqVOnsGjRIjzwwAN4/vnnMXPmTJSfPo2GXr204rN+/XoMHDgQQ4cOxcyZM1FbW4vvv/++6YO6\n4w563LGD/P+jRlG2hSHDhwMAyn79FV5eXrhZEgmLFkCHDkbfb9KkSejfvz++M7aNoiQAmoYGHD9+\nHHFS2+VIKb1Wzw0kWRm1Xbvi2rVrJgVg8ODB8PLyMioAcouJsWPHao8FBgaitLSUsrQ8PMgt8+c/\nA4BWGEwJwO83bgDl5bgi9cLRCsDFi9TywYoeUe7e3oBK1SQB0Gg0ePvtt7F06VI89NBD1r3HvffS\navqXX4w+nZSUhAY5HmW4D4CCwZI4aIsEw8JoxWspDlBQYFu3W1kAkpKsfw1A2UOHDpHlC+isVHNc\nvaoLOJtKfZZbq7/0kmkrQW4Cp8RULYALpbm2TQHYuZP83xMmtNglN23aBF9fX0ybNo0CxmlpGDZo\nEMaMGYOPP/4Ys2bNQqdOnbR9VV544QWENjQgS5r8MzIycOjQITz66KNgjGHEiBEICwuzzw0UFkYB\nyY0bKchpzP0DUJV0QAA8U1IQGxurXSlbFAAjE3JpaSlOnTqFyspK3HfffZg1a5a+FdO3L1BZiayj\nR1FaWmqVABRKgV9TAqBWqzFs2DCjAnDw4EH06NEDvRUTW2BgIDjnupXsSy9RYSCgHauhCwjQDwTf\nkOoGtAKweTM9/vGPRsdobMxNEYCTJ0/i2rVrmDx5MrZs2YLp06ejWmoxYZJJkyj2YiK9ctOmTQhz\nc6NfDPcBUCALgJ4baMoUEhZTf0t1Na3GbbEAunUjy9KUACxZQq47Zf1NbS2t0qOjgf/7Pzpmzcpb\n2X7CnAB07EgC//XXxs+R20ArkQXAcBzvvENJAibG19DQgIt2bp5kLW1TAH76iVo2GGnF2xzU1tbi\nm2++wT333ANfX18SgPp6ICMDCxcuxMWLF5GcnIzVq1ejs5SBMzQ2Fv3d3PDblSuor6/Hhg0bwBjD\nw1KgjDGGmTNnYt++fSiwZ3OXO+6gkn3OTQfGGAMfOhQ9CwoQFxeHICkV9pq5jT9MFIHJk8OmTZuw\naNEibNq0CYMGDcIhuTWFFO9IlypwZQEICgpC586d9QVAukGuSKsuUzEAgNxAx48fR52BmyMhIQFj\nx47Vy9SRV/fXjbT0tmQByJ50lpKC7t27w9/fnw5s3kx5/mYmUCVNFYDd0mr7iy++wKpVq7B9+3ZM\nmzZNf1McQ7y9yR343Xe0368B+/fvx9iQEMrCMRPTCQkJQWBgoC4TCCB/fUWF6dYj8p7EtlY9Dx1q\neg/nzz4ji3b4cF2yx6pVtApfulRnxVhjAShFxNR9VlBAld2xsdSuwlBw5RRQQwvA15eKSpUWgEZD\nGU6nT1OiRp7+nlj79u3D8OHDMWHChEZbjDYHbU8AqqqoP83dd7fYJXfv3o3i4mI8KJv/iiZc9957\nLwYNGoRnn30WdyvHVFwMv4YGJJeX47vvvsP69esxYcIEhCp6Aj344INoaGjAN9980+SxaSQ3WIVK\nRf5uExT36YMYjQYjYmO1AmDRAjAyISdJq7aRI0di8eLF+P3336FWq3H//fdTcZskAIVHjsDLywsD\nFVknjTKBcnIAf39cllblpiwAgASgurpab3V6+fJlXLlypdGWjE0VgD59+qDexwfX/fww8Px5zOja\nlSbUlBS6oc0Ffw1oqgDs2bMHgwcPRvfu3fHkk09i3bp1+Pnnn/Hkk0+af+H06TSRGbRx1mg0SElJ\nQYSPD03+ZlqSMMYaB4InTqTXmIoDyJNqUwTg3Dm6n5Xk5dFq+9lnaYV9xx1UoPnWW2Th3n67TsQc\nYQHU1lJH2u7dqZbh0iWqaFYiB4CNJZwYpoImJtL3+tlnaRF1221AYSHOnj2Lu+66C7fddhtKSkqw\nZMkSeJmqX3IgzdiK0El4e1tXnGIDs2bNwtmzZxEQEKD917FjR+3PW7duRVBQECZPnkwvkNtFnD0L\nj3vvRVJSEtxkE1tG+uJVdeuG559/Hrm5uXjjjTf0TomJiUFMTAy++uorPPNM0zZQy+zZE10AHNBo\nEHX5sq5FsQGpXl64GcBNAQFQq9Xw9/c3KQDv/+tfeD43FyojE3JSUhK6deumLdgaMWIENm7ciNGj\nR+Ptt9/Gkr/9DQBQnZqK2NhYeHh4aF8bGRlJBVoyihRQwLIAABQIHi7FNA5Kk53S/w+YFwBzLiCV\nSoXo6GhsLinBY2lp+Cg5Wdc9VKUC7r/f5PgMUavVqLExPbCiogIJCQlYuHCh9tijjz6KXbt24YCy\n3sMYU6eSW3TrVr3K+MzMTFRVVSGkocEq62Xw4MFYu3YtNBoNVCqVrpbCRHxBawHY4gICKDFBbr2h\nXLjs30+Ps2eTK+jpp8mlIle2M0YFm507Wy8AnTvTCt6YAMjHunalFftdd1HXgDlzdGnjxmoAZAyL\nwbZuJcF8+23aZ3nqVBTHxWFcdjZq/fzw3nvvYeHChS0y+QNt0QJwMFevXsX69etRXV2NyspKpKam\nYvv27Vi5ciXefPNNLFiwAL/88gsefvhh3WTm70+TgpR73WjyB7QCMO6xx5CbmwsvLy9Mnz690Wkz\nZ85EQkICrjSxojApJQV3Ange5JYxxQGpVUCYNAEGBQWZFIC1770HVUODUXdBUlISYmNj9Y6NGjUK\nc+fOxQcffICzWVng3btj4qVL+EdVFXVbPXoUqKtDZGQkCgsLUSxnY0hVwLm5ufD09ESnTp1Mjr93\n797o2rWrXhzg4MGD8PX11fquZZpqAQAkyq/k5aErgB8feYQqyU+fJheLDavcplgABw4cQG1trW6h\nIREVFYUrV66YdwP5+5O/futWvSDkGammoVNZmdkAsMyQIUNQUVGBTOXKOSJCt5m8IfZYAEBjN9D+\n/fS3xMaSi/eLLyjtc8UKOiZjbRuGrCyauAMCjAuAPH5ZwJYsIZfXY49Ra+t163Sp1sb29AgJ0QkA\n5/T5T5xIrqEJE4AffoDflSs46eaGvAcfxCuDBsHLiJuuuRACYAF5FfnZZ5/h4MGDSElJQW5uLioq\nKlBTU4OCggKkpaXhX//6l/4LLXVhlG6gaQsXIjAwENOnT9f2xFEyU3IrfG0q+GSBpKQk/O7mhq6j\nR2PDhg0mi6V+Sk9HpUoFlZR6Z0oA6uvr4SnFBqoMJsmamhqkpKRgqHzzKnj33Xfh5+eH5557Dvmz\nZ6OIc4w7exaYN4+qSufP1waCtX19FBZAjx49GvWnUcIYw6hRo/QEICEhAaNHj9Zu1iJjSQB8fX31\nLBMlMTExKC8vRwUA/sAD1PqhuJj6/9hAUwRg9+7d8PLyamTRmNwb2ZDp02kyUrRxPnPmDFQA1IWF\nVgmALKZ6cYCePWmlbywttakWQO/eNEkaBoIPHKB9PeT/U8ao7Ybh7ms9e1oXA5CbMXbpYp0AREWR\ny+mnn6hr8OzZ1BCyf3/jMcfQULIuqqupGjstjXYmlMiNicEdnKO2d2/4fPEFubQ6dSLXUAsIgd0C\nwBgLZYz9whhLZYylMMb+ZOScCYyxUsbYSenfX+29bkuRkJAALy8vo5OaWq1Gly5d0L9//8YTRlQU\n+TBNpY1dvAgEBcG/Z0+cOHEC/zFR+t6vXz/ExMRgXxPdWklJSRg4cCDmzZuHCxcu6HXflKmvr0dS\ncjLygoO1K67OnTsbDQLn5+dD9vwnGzyfmpqK+vp6o59Vly5d8M9//pP81SkpGAng3NGjdENMngzs\n26edyM6dO0df/rw8ozuBmSI+Ph7nz5/H9evXUVpaitOnTzfy/wOWXUDG3D8yMTEx2p+1RWDe3lRQ\naANNFYBx48bB26CgSh6HxYZ406bRxKnIBjpz5gziQ0LArHQBRUdHQ6VS6ccBevak1a2xXejy82nF\nbm0RmAxjZAUoBaCwkCZRU80dlVhjAdTXkyD26UMCYCwIbCgAAMUb6uqoeCwjg3YGlF1ThihrAbZu\npb/rD3/QPr1jxw7sA1C+dSvFGnbvplbzclC+mXGEBVAP4CXO+UAAowA8yxgzVk/+G+c8Vvr3lgOu\n2yIcPHgQ8fHxjXrQWCQqikxFU19CRRvoPn36GF39y4waNQpHjx61fdMTkAAMHToU06dPh6enJzZs\n2NDonHPnzqGyshK1gwZR8U1Dg0kLIC8vTysA+2Xfp+JaAIwKAADMnz8fw4YNw7Zt2+Dj44PI6Gha\nOU2dCly5gj4eHlCr1SQABQVAfT2u+/jgyJEjGDRokMW/VY4DHDt2DIcPH4ZGo2m0WgYAb29vqNVq\nkxaAKfcPoBMANzc39LWjjbenp6dNApCdnY3U1NRG7h8A6N+/PxhjlgUgMJD82N9+q3UDnTlzBjfL\nE78VFoCPjw/Cw8P1BUBOBjC24raiBuDEiRPGFzhDh9JWmnJmlxznGD/e7PsdOHAAyUVFJBjm4iw5\nObr9uK21AGTc3WmlHhZG8QpTGWrKVNCtW6ndiKKh4fbt29GrVy/6Xnl7U8rukiX2t6awErsFgHOe\nxzk/If18A8BZADb0B3BdKioqcOLECaOrSItY2o7Phn0ARo4cieLiYl0rXiu5evUqrl69itjYWAQE\nBGDatGnYvHlzowpS2SroOGECFdBduGBWAHoCaADwk4F/NikpCX5+fiYDzW5ubto6iKFDh+pcM6NH\nAwDcExMRHh5OAiBNJpt/+w0ajQZ/lgq1zDFixAgwxnDkyBEcPHgQKpVKKwpKGGP61cAKjDWCU9K9\ne3cEBgYiLCzMpJvIGmy1APZIabPGBMDb2xu9evWyriPq9OkUtDx9GrW1tTh37hyGyh1wrRAAgBYk\ne/fu1dVRyNaZMQGwUAWs0Wgwc+ZM3HfffY17Tw0dShO4nBl24AC5WaQgvykWLlyIj+UiRHN78ip7\ncXXtaloA1GoKdjcF2QLYv58WVwr3T01NDfbs2YM777zTrHuzOXFoDIAx1gfAUACNK3KA0YyxZMbY\nT4yxaEdet7k4evQoGhoajK4iLWJOABoaKPhkpQCYa3VgjpOSP19ekT/88MMoKCjAXrkttERiYiL8\n/PwQLFcOHz+OoKAglJaWNhILWQDKvLzw+7FjernKSUlJGDJkCGWHmGDUqFFYsWIFXlNu/xcbSzfZ\n4cOIjIyklaw0mazbuxdPPPGEVavtDh06ICoqCkeOHEFCQgJiY2N1efoGmBKAkpISsxYAYwyTJ0/G\nBDuLDG0VgN27dyM4OFjPBaVE3hrTIvfcQ26ITZuQduEC6uvrESm7Z6ysYViwYAFu3LiBTz/9lA5Y\nEgAzFsD27duRlpaGsrKyxpXj8qY08kJj/35aLJixxtPS0pCcnIxLsv/cnBtIrgGQXUDXrjV22RYU\nkDg0dYKWP5tVq+jx3nu1T+3fvx8VFRW4U97AyQk4TAAYY34AvgXwPOe8zODpEwB6c86HAPgYgMn+\nBoyx+YyxRMZYos3b/DmYhIQEMMYwWlqh2kSXLmQiGhOA3Fwya60UgIEDB8LHxwdH5eZxViK7ZOSs\nnKlTpyIwMFDPDZSXl4e9e/di2LBhUA0cSCl0J05oawGKDfqj5ObmkguoZ0/U1tZqx6TRaJCcnGzS\n/aPkmWee0f/Se3rSqu7336nhWkYGGqTGbvkeHvg/ubLTCuLj43H48GEcOXLErOVmzgIwJwAAsHnz\nZqxevdrqMRnDFgHQaDTYs2cPJk+ebHKlaPXeyF27kpvhvffQd/x4rAHQPyODunX6+lo1nuHDh2Pi\nxIlYtmwZ/Q2dO1NLDWOrbQsuoPfffx+hoaHo06cPPv/8c/0nBwygFX9SEvnHT52y6P6Ra2aCpGB1\nrbmK2sxMSt8NDaX7taGhcQO6ggI0dOmCq8biG9bg40Of7dWrtNBR3PPbt2+Hl5cXJsqtK5yAQwSA\nMeYBmvw3cs4b1Ztzzss45+XSzzsAeDDGjG6HxDlfzTmP45zHdWmJLfPMcPDgQcTExJh1CZiEMdOZ\nQLLpaSxtzAju7u6Ii4uz2QJISkpC3759teP39PTEAw88gO+++w7Xr1/H0qVLMWDAAGRmZuKpp54i\nv+aQIcCJE9qKZcNAcH5ODgaqVPCV+uDL+ecZGRkoLy+3SgCMMmoUcPw4Bvbvj/r6eqT98gvqADzw\n3HONNoExR3x8PIqKilBZWWnWcmuqC8hR2FIHkJSUhKKiIqPuH5kBAwbgxo0b1k1UX38NfPopLnbr\nhnsB+B0/bjyH3Qwvv/wycnJyKDtNpSK/tqEFUF9Pq2oTLqCkpCT8+uuvWLhwIebMmYOff/5Zvxmg\nmxu1TEhKokZsnFsUgC1btmDUqFF47t13AQAnzLVUz8qiFbparcvpN1x0FhTgXFERhg4darnlhgkK\nPD0BAHWKQlDOObZv345bbrkFPi3UscAYjsgCYgDWADjLOX/fxDnB0nlgjI2UrmvFnoPOo6GhAYcO\nHWqa/1/GkgDYEESMj49HUlKSTcVDcgBYySOPPILKykr0798fr7zyCsaPH48zZ87oqpiHDQOSkhAk\nrYIN4wB37d2L3hoN1HPnYvDgwVoBsBQAtsjo0UB1NWKlFW7yjh24yhhe+ctfbHqbUaNGaX+21QJo\naGhAWVmZRQvAEdhiAcj+/9vM9Li3OhMIoJz3xx/HXyMjMTYigjZiN1MjYoypU6di4MCBWLp0KVkd\nirTLPXv2YMeOHTT5c27SAvjggw/g6+uLxx9/HI899hgAYN26dfonSd9H/PorWYpSUZix7VYzMjKQ\nlJSE+++/H2Nuvx3lKhXSfv7ZtFWkjMPJAmCYCZSfj7yGBly9ehUbN260/MEYIUO6Z99X1E5cuHAB\nGRkZTnX/AI6xAMYAeBTALYo0zzsYY08xxp6SzpkB4AxjLBnARwBm8qaktDiIgoICi7ttyW2Em+T/\nl4mKopvAMJ3y4kWyEKz0uQIUCK6trdXPvjBDWVkZ0tPTG03IN910E6Kjo9GpUyf8+OOP+PHHHxGu\nXP0NGwaUlaGHtNrRE4C1a3FnVha+7dMHmDED48aNw6FDh1BXV4ekpCS4u7vrtXawCWniDpNuwKCa\nGqBnT60rylqio6Ph4+ODPn36mE0dNSYAclDT1QRg//79GDRokP7WkwbIAmDt1pgAfcejYmKoDsPG\njCbGGF5++WWcPn2aBEoSgM8//xxTpkzBrFmz0CD3uTFiAeTm5mLz5s2YN28eAgIC0Lt3b9xyyy34\n/PPP9Sf3oUOprfPGjTROLy+8/PLLiI+Pb/T5bdmyBQAwY8YMMMZQHxwM7+Jibf+kRmRmkv8fMG4B\ncA4UFOCqNJ7333+/SZl4u2pr8Stj+Mv69dpsJ3mzp1YvAJzzBM4545wPVqR57uCcr+Kcr5LOWc45\nj+acD+Gcj+Kcm+gc1fwUFxcjIiICffr0wbvvvouyMsNwBSG3EbbbAgAaWwGZmXTDSKahNdgaCJYL\ndQwFQKVSITExEefOnTP+5ZMyLLpKwTOtABw5Ajz9NH5Tq/GTZIaPGzcOlZWVOH78OJKSkhAdHQ1P\nG/4mPUJDgZ494ZWUhJ49e6K3SoVgC9kexnB3d8fs2bMxZ84cs+cFBgaipKREb7Ix1wbC0dgiAHl5\neRaD4CEhIfD29rbOAgBQVVWF9PR0k0Fla3jooYfQvXt3LF26lGJCly5h7ty56NGjB4qKipAu9x0y\nIlwrVqxAfX29XluLOXPmICsrC/uVOfXy9zc/X+v+SUhIQGJiIj744AO999yyZQtGjhyJXtLCqkNU\nFPp6eDQ6DwD1+MnJaWwBKAXgxg2gpgbZtbXo0KEDUlNTscvS3gcGFBcX4283buDA4sUYMGAAZs+e\njZKSEmzfvh0xMTF6XWqdQburBP7www9RUlKCmJgYvPbaa+jduzcWL17cSAgOHjxIE5E9/0HmBMBK\n/79MSEgIgoODrQ4EyxlAhm0ZANrez2h7CoDa6Xp4IHDLFjwE0PaH2dnAffeB9+iB6fX1CJZym+V9\nA/bv32/U3WQzo0YBhw9jyZIl6OvpCQ95dWYjK1aswF//ar7WUG4Jrfx/t9QGwpHYUgdQVFRktg0G\nQMIeHh5utQCcPXsWnHO7BMDT0xMLFy7E3r178d3Ro1BXV+P+22/H71Kr7LPyRG4gAJWVlVi1ahXu\nuecevZThe++9Fx06dNAPBsfE6Kp+pQKwdKn+5K233tLGDC5evIgTJ07gfkU/JlVoKMK9vbFr167G\ne0ZfvkwrfHMCIFmjWVVVmDlzJrp374733zfq5TbJWenej4uLw4YNG5CXl4e5c+fit99+c/rqH2hn\nAlBaWooPP/wQ9957L37++WccO3YM48ePx9/+9jdMmTJFL6UxISEBY8aMsS8/t1cvygJQCkB5OVUz\n2igAjDHEx8dbbQEkJSWhS5cuZlsoG0WtBmbNgtvhw9gIYN6yZbQ6v34dxWvWoFCj0QZlu3XrhoiI\nCHz99dcoKCiwXwBGjwYyM/HQyJFwr6qybbtJGzFWDdySAmCLBVBUVGSVK8zqVFDoegDZIwAA8NRT\nT8HPzw/fSJP+hvfeQ2hoKIYNG4bs48fpJAMX0Jdffoni4mK88MILesd9fHwwc+ZMfPPNNzph9vSk\nRYm7OzB6NEpKSlBUVIQFCxYAgNaCULp/tISEwL+iAj5qNT788EP9gStTQOXrdOhgXAAqK9G9e3cs\nWLAAe/bs0W2IYwUp0lacAwcOxIgRI/Dmm2/iu+++Q319vRCAlmb58uUoLS3Vdt2Mi4vD999/j2++\n+QZHjhzBrFmzoNFotG2E7fL/A5QdERGhLwB//Sv1jpk3z+a3GzlyJC5cuGA0e8UQeUXeJAH77DOw\nGzdwS5cuWD1+PG20sXMnLksTozIrZ9y4cfYHgGXkAK7cV0euomwGjAmAK7qAqqqqUFVVZbUAZGZm\nWvW+Z86cgVqtRn9Le2ZbICAgAO+//z7GST2r1NIEOmXKFFRlZYGr1bSZigTnHP/5z38wbNgwo/fX\nnDlzUFVVhf/+97+6g488Qj13fH21xZATJ07EokWLsG3bNmzbtg1btmzBiBEj0EdpNUotLp6dMQPr\n1q1DnrL3vrFEDMNqYEkACkC9sZ588kn4+PgYdymZIDU1FT4+Plq31Ouvv46RI0eic+fOTUsvdzDt\nRgDKy8vxwQcf4I477tC2C5aZPn06li5dim+++QavvfaayTbCTUKZCXT0KHUQfPppamhlI8pWB+ao\nra012ZTNajw8cC04GDsCAqjd7rhx2htIKQDjFWl5Q4YMafr1AApAe3joBEBYANo6DGsFwNrdpM6c\nOYOoqKhGjfKawhNPPIEn35K6u0iZQFOmTEFnzlHVoYNeEVViYiJOnz6NJ554wujiJD4+HlFRUfjy\nyy91B19+GZCKzmT3T//+/fHCCy8gOjoa8+fPx/Hjx/XcPwC035+F06ejrq4O//73v3XPZWaSVaH8\njhn2AzIQgE6dOmHOnDnYuHGj1XUBqampiIqK0hZHenh4YOfOnfj9998d8tnbS7sRgFWrVqGoqAhv\nvvmm0edffPFFPP3001iyZAkWLVoEPz8/q/rPWCQqivyNJSW07WBwME2oTSAuLg6MMYtxgJSUFNTV\n1dm9IjdsByELgNKtNE7yy/br189sPyOr8PamYhnZdeAkAXClOgD587dWAADrUkHPnDljt/tHD/k7\nIRWDjR49Gj3c3FBoMMmvWbMG3t7eurRjAxhjmDRpEo4fP24y1ROAthXHypUrkS91HNVz/wBaCzIE\nFLBeuXKlrq4lK4tctMpYmAULAAD+9Kc/oa6uzmTzRkNSU1MbZcYFBgbabXk5inYhAFVVVfjXv/6F\n2267TS9PXAljDB999BGmTp2KtLQ0o22Em4QcCH7iCeob/5//6JnEttCxY0dERkZajAM4yiUTFBSk\nVwgmC0BwcLD2WGhoKCIiInDTTTfZdS0tSrPY1viFDZhyAbm7u9O2ns2MWq2GRqNBg4WWv7YIgLw/\nsSUBKC0txZUrVxwrAL6+9L2WLAC1Wo1+fn64KO0zAVDw96uvvsKMGTPQ0cw9EBMTg8rKSv2iMIn0\n9HR0795d+3908803409/+hPuueeexplSikZsr732GqqqqrBs2TI6ZqwXlxEBqPX1RR10n394eDim\nTZuG1atXGxUoJaWlpcjJyWl6anQL0C4E4NNPP0V+fr7J1b+Mu7s7vv76a0ydOlVbmGI3sgB88w3t\nAKRoBdsURo4ciSNHjpjNR05KSoKvr6/dq4zOnTvrWQC5ubno1KlTo1TP/fv3Y/ny5XZdS4ss0EFB\ntrcQtgFTFkBgYGCLNOaSu8tacgPJn7+lLCCAFgjdunWzKAByYNKhAgA06sHfjTFkSemmAPDtt9+i\nrKwM8yzEv6KjqVWYHKhWkp6e3uh7vWzZssZ9hAD6Dnl6AtIkPH36dHz88ccU68nK0gWAZbp21RWv\nAUB+Pqr8/KS30gnwzJkzkZ+fb9ESlzOA5L/HFWnzAlBcXIx3330XN998s9ZdYQ5/f3/s2LFDuzm7\n3fTvT2Zmx46N9xJtAvHx8SgsLDS6OpI5efKkxaZs1hAUFITi4mKt2OTl5Rlty9CtWzf73T8ysgXQ\njO4fgDJOPDw8GglAS7h/ANsFwNqCuIiICIvFYC0iAJzDr6IC+YA2d37NmjXo16+fxftQXjHL41Ri\nTABMwhiNSappeeONN1BWVoaV779PvXmMWQB1dYDc5bSgADekNg1yaxQAuP322+Hu7o5t27aZvbyc\neiosACfBOce8efNw7do1m/N3HYZaDbz5JrB+vV4f8KZiqSCsrq4OJ06caBTobgpBQUFoaGjQVsjm\n5eXZnlZqK717U5ykGTOAAOMtoS11AnUk1gqALUFgwLpU0DNnzsDPz0+bmeIwevbUNYQrLQWrq0N9\np07YvXs30tPTsX//fsydO9eihRUQEICQkJBGAlBRUYG8vDyT7caNotgYJjY2FnfddRe2yQsxQwvA\nsLUhwr4AABlpSURBVBagoAAlHh7w8PCAn2QJAGQ9jhs3zioB8PLy0s9McjHatACsXLkS33//Pd55\n5x3ExcU5byCLFtFuTA5g0KBB8PLyMikAp06dQmVlpX0VzBLypCOvQk1ZAA6FMRLLt99u3uugcTsI\nazqBOgrZjWaNBeDj42P1JuEDBgxAYWGh2VTh48ePIyYmxm4LsRE9etAubg0N2q0ge8TG4ueff8Yn\nn3wClUpltWs1Ojq6kQtIzm6yybVpsDPYG2+8gQB5hW/MAgB0mUAFBbimUiEoKKiRaN19991ISUkx\nm3GVmpqKyMhI00WXLkCbFYBTp07hxRdfxO23396o4KQ14+Hhgfj4eG0TNkPkFFZHBGVlAbh27Ro4\n5y0jAADthyr3gm9GjAmAK7qAbOmHZCkT6MaNGzhy5EjztCDu2ZMm/4ICrQBEjBuH8vJyfPjhh5g6\ndapVW3sCJADnzp3TC5IrU0BtGlNOjtavP2rUKEyRguUmBaCwkDqZFhUhH8atr2nSgu5///ufyUsb\nywByNdqkAFRUVGDmzJkIDAzEunXrHL/ScTITJkxAUlKStnBJycGDBxEaGopQeSciO5D9nkVFRSgq\nKkJdXV3LCEALERAQ4PIuIGvaQCixJAD79+9HfX292c6iTUa5MYy0ih4yeTLc3NxQV1dnMfirJCYm\nBtXV1XorbDkF1GYXUE0N7d8rMbp7d1QDKDLM8lMKQFERwDly6+uNCkBYWBiio6NNuoHKy8tx6dIl\nIQDO4Pnnn8e5c+ewfv16dDWzHV1rZeLEidBoNEatgEOHDjksJVPpAjJWA9DaUVoAnPMWdQHJAmCp\nFsBWC6Bv375wd3c3GQjes2cPvL29HZe2q0QpAJIF4BcWhjFjxqBLly42tT4wlgmUnp6OoKAg26w0\n5Z68AFBdjZiMDKQCOK7ccB7QFwBJwC5XV5v8/O+++27s37/fqLtNzgASAtDCFBcXY9euXXj11Veb\nZ5XjAsTHx8PLywu//vqr3vHLly8jOzvbIf5/wLgAtCULQCkAFRUVqK+vb/UuIA8PD4SFhZm0APbu\n3Yubb77Z6piCTSiLwfLzKZ7TuTPWrFmD3bt3a/9mazCWCWRTBpCM4XaV77wD3+xs/AW6vbC1eHsD\nfn56ApBVWWlWABoaGrBz585Gz7WGDCAAcH4tsoPp1KkTkpOT9aL2bQ0vLy+MHj0av/zyi95x2f/v\nKAEICAiASqXCtWvXkCtld7Q1AZBbQsvuNFd0Adm6J8Lw4cOxZ88e1NTU6NVs5OTkIDU11WKr7CbT\nrRulPOfkUD59586Am1uT6lH8/PzQp08fPQHIyMiw3XJRWgCpqVSF/8gjyDx8GP5yxbkSuRhMEoD0\nsjJEmPj8R44cia5du2Lbtm2NKptTU1Ph4eFhm7vKCbQ5CwCgm9jDw8PZw2hWJk6ciOTkZL09ew8d\nOgRfX18MlvZDtReVSoXAwMA2bQFoNBrcuHGjRdtAANYJgEajQXFxsc0C8Nhjj+HatWv44Ycf9I7v\n3bsXgPmdxezCzY1SeGUXkJkNbKxBmQlUU1ODy5cv2y4mwcE0rsuXgfnzAX9/4P33MXz48MYWAKDr\nByS5sHLq6/VqAJSoVCrcdddd+Omnnxr9P6ampiIiIsIl+v2Yo00KQHtg4sSJ4JzrbZ5x8OBBxMfH\nO/RLJ1cD5+XloWPHjk7dv9TRKKuBW7IRHGCdAJSVlUGj0dgsAJMmTULv3r3x2Wef6R3fu3cvunTp\n4rAFglHkrBsLm8FbQ0xMDM6fP4+6ujpkZWVBo9HYLgBublR/88knwMGDwPvvA126IC4uDpcvX0ah\n4R7ACguAu7ujBOZrMO6++26Ulpbit99+0zveGjKAACEArZYRI0bA29tbGwcoLy9HcnKyw9w/MnJD\nuNzc3Da1+gf0BaClXUDW1AHY0gZCiUqlwty5c7Fnzx5kSm2POefYu3cvbr311ubNipOLwfLzTW4G\nby3R0dGoq6tDenp60zKAlGMqKgJuuQWYNQsAtIWSxw3dQAoBqAsIAId5Abjtttvg5eWllw1UWVmJ\nzMxMIQCC5sPT0xNjxozRxgGOHDkCjUbj8OwOWQBarAagBTFmAbiSC8jWNhBK5syZA5VKhbVr1wKg\nYOrVq1cxadKkJozWBnr0cKgLCKBMoCbVAMj07g14eZEVIBV0DZPqTEwKQH4+qqX2JuY+f19fX0ya\nNAmff/451qxZA41Gg/Pnz4Nz7tI9gGQcIgCMsdsZY+cZY+mMsb8Yed6TMfa19PwRxlgfR1y3vTNx\n4kScPn0ahYWFOHjwIBhjJrudNhW5I2iLtIFoYVzdBWSPAISGhuL222/H2rVrUV9fTxu3oxn9/zI9\ne1Lr8/JyuwUgKioKjDGkpKQgPT0d/v7+6CKnatrCP/8J7NtHfbkkOnbsiPDw8MZxgK5dab/gjAxU\nSO5OS5//hx9+iNjYWDz++OMYP348vv32WwCunwEEOEAAGGNuAFYAmApgIIAHGWOGf/k8ANc55/0B\nfADgPXuvK4C2mvPAgQM4dOgQoqOjHb6CVcYA2rIFILuAzLUpdiTW1AHYIwAAbdSSm5uLnTt3Yu/e\nvRgwYIDj+/8Yoqz0tdMF5O3tjX79+mkFoF+/fk3r1NqvH2DEMo6LizNuAQBAWhpKpVRZS59/3759\n8euvv2Lt2rU4e/Ys/vGPf8Dd3d1lev6bwxEWwEgA6Zzzi5zzWgCbARj2PP4DgHXSz98AuJW1RM/d\nNk5cXBx8fX2xb98+/P777w73/wP05a+urkZ1dXWbFoDr16+jQ4cOLda3xRoLwNZGcIbceeed6Nat\nG1asWIH9+/e3TF2MUgDstAAAXSZQRkaGwyfU4cOH48qVKyhQ7gImC0B9PYqlZAprrEKVSoU5c+bg\n3LlzeOKJJzB37lyb6h6chSMEoCeAK4rfs6VjRs/hnNcDKAVg9FvNGJvPGEtkjCU2itAL9PDw8MDY\nsWOxYcMGlJWVNZsAyLQ1AfDz84Obm5vWAmgp9w9gvQuIMdZkq87DwwNz5szBzp07UVFR0fz+f0B/\nEx8HVOHHxMQgLS0NmZmZDhcAuUGknhWgcDEVSp+9LVl1nTt3xurVq/HJJ584bJzNicsFgTnnqznn\ncZzzuCb5+9oZEydOxI0bNwA4pgGcIUoBaGsxAGVL6JZsBAdYLwABAQF2WSVy/x2VSoUJEyY0+X2s\nphksgIaGBtTV1Tm8qEreMc+UAOQ1NJisAWgrOCJhPAeAsvNYiHTM2DnZjDF3AB0BFEFgN/JN3a1b\nN4SFhTn8/duyBQBATwBc0QJoqvtHpn///pg6dSpqampaRuA6dKB2CuXlDrEAlJk0jrYAOnTogIiI\nCP1AsEIAsmtr7f78XR1HWADHAIQzxvoyxtQAZgIwbJG3DYDcCHwGgJ+5uT0NBVYzfPhwdOjQAWPH\njm2WrQyVK6C2LACu6gJyxAS0detW/Pjjj3a/j9X07ElC4IB+QxEREVoLqDmCqsOHD9e3AHx9ASn7\n51JVlRAAS0g+/ecA7AJwFsB/OecpjLG3GGN3S6etARDEGEsH8CKARqmigqbh7u6OnTt34t///nez\nvL98A/j6+sLf379ZruFMnOUCcnNzg5ubW4sIgJeXF7ybcX/lRvTo4RD3D0D1LuHh4fD09GwWF2Rc\nXByys7ORL7V+AKC1Ai6Wl7d5AXBIzwDO+Q4AOwyO/VXxczWA+x1xLUFjRsv76DYDchVqW/P/ywQG\nBiIjI6PFXUAAWQGWBKA1FBM14qWX9Prv28tNN92EwMDAZqlgVlYE33HHHXSwSxfg0iWklZRgpBAA\nQXtGrVbD39+/Tbp/ABKA/Px8VFZWOkUAzNUBFBcX29wGwiWwoe+/NaxYsQL19fUOfU+ZoUOHgjGG\nxMREPQHgfn4obAcWgMtlAQlcj9DQ0GYJMLsCgYGB2iyqlnQBAeYtgNraWty4caPNT0DW4OXl1Wzt\n3f39/REREaEfB4iJQZ20s1pb//yFBSCwyP/+97826f8H9It8XMkFZG8RmMB64uLisG/fPt2Bd97B\nheRkYPjwNp8GKiwAgUXCwsKa1oOlFeCqAmBvGwiB9cTFxSEvL0+76RHc3HCtrAxA2//8hQAI2jXK\nSd+VXEBCAFoOYxXB7eXzFwIgaNe4ugXQKoPArYzY2FioVCq9gjAhAAJBO8CZFoCnp6eIAbgAvr6+\nGDhwoBAAgaC94eoWQFufgFyFESNG4NixY5AbFBQVFcHb27tlC+icgBAAQbtGnvS9vLzg5YDWBbZg\nSQDUajV8fX1bdEztlbi4OBQWFuLKFWps7KgqbFdHCICgXePv7w83N7cWd/8A5gvB5AlIbJvRMsiB\nYNkNdO3aNSEAAkFbR+6339LuH8CyBdAeJiBXYfDgwXB3d9cKQFFRUZuvAQCEAAgECAwMdEkBEBlA\nLYeXlxcGDRqkJwDtQYCFAAjaPVFRUYiQSv9bEmEBuBZxcXFITEwE57zdfP6iFYSg3fPtt986xddu\nqRVEe5iAXIm4uDh8+umn2u6w7eHzFwIgaPd4eHg45bqm6gDa0wrUlZADwXv37oVGo2kXn79wAQkE\nTsKUBVBeXo66urp2MQG5EjExMfD09MTOnTsBtI8aDCEAAoGTMCUAog2Ec1Cr1RgyZAh+/vlnAEIA\nBAJBM2KqDkBUATuPuLg47f4Q7eHztysGwBhbCmAagFoAGQDmcM5LjJyXBeAGgAYA9ZzzOHuuKxC0\nBWQLgHOuF4QWAuA85DgAAFEHYAV7AMRwzgcDuADgNTPnTuScx4rJXyAg1Go1OOdoaGjQOy4awTkP\npQC0h8/fLgHgnO/mnMubdR4GEGL/kASC9oFarQaARnEAYQE4j6ioKHh7e8PNzQ0dO3Z09nCaHUfG\nAOYC+MnEcxzAbsbYccbYfAdeUyBotVgSABEEbnnc3d0xdOhQdOrUqV30YbIYA2CM7QUQbOSpNzjn\nP0jnvAGgHsBGE28zlnOewxjrCmAPY+wc5/yAievNBzAfAHr16mXFnyAQtE48PT0BGBcAf39/p9Un\ntHeeeuoppKSkOHsYLYJFAeCc32buecbYbAB3AbiVy820G79HjvRYwBj7DsBIAEYFgHO+GsBqAIiL\nizP6fgJBW8CcBSDcP87j0UcfdfYQWgy7XECMsdsBvALgbs55pYlzfBlj/vLPACYDOGPPdQWCtoAQ\nAIGzsTcGsByAP8itc5IxtgoAGGM9GGM7pHO6AUhgjCUDOApgO+d8p53XFQhaPbIAGNYCXL9+3Snd\nSQXtD7vqADjn/U0czwVwh/TzRQBD7LmOQNAWMWUBlJaWIjQ01BlDErQzRCWwQOAkzAlAe0hBFDgf\nIQACgZMwJQAlJSVCAAQtghAAgcBJGBOAuro6VFVVOWWPYkH7QwiAQOAkjAlAaWkpAAgLQNAiCAEQ\nCJyEsUKwkhLqpSgsAEFLIARAIHASwgIQOBshAAKBkzBWByAEQNCSCAEQCJyEMQtAuIAELYkQAIHA\nSQgXkMDZCAEQCJyEEACBsxECIBA4CXMuoA4dOjhlTIL2hRAAgcBJmLIA/Pz84O5uV5sugcAqhAAI\nBE7ClAAI94+gpRACIBA4CZVKBXd390YCIDKABC2FEACBwImo1Wq9OgDRCE7QkggBEAiciFqtFi4g\ngdMQAiAQOBFjAiBcQIKWQgiAQOBEDAVAuIAELYkQAIHAiSgFgHMuXECCFsUuAWCMLWaM5Ugbwp9k\njN1h4rzbGWPnGWP/3979xchV1mEc/z50O1vdkrYIYqGNVG1KeiELbCpENIKFQENoNEZLjMGEpF5A\nAonEQEhMvNSIyAUhqYjeGCCiSFMJUJDE6EXbLbS40NZWrGHLny0iYiyru/jzYt7Rk8n+K2dy3tM5\nzyeZ7PkznfNkT9tn33fOmT0i6fYyxzTrJ8UCmJycZGpqylNAVple3G1yd0R8f7adkhYB9wJXAuPA\nHknbI+KlHhzb7JQ2ODj4vwLo3AXsEYBVpYopoA3AkYh4OSL+DTwEbK7guGa1VxwB+HOArGq9KICb\nJb0g6QFJK2bYfy7wSmF9PG0za7zifQCdAvAUkFVl3gKQ9LSksRkem4H7gI8Dw8BrwF1lA0naKmlU\n0ujx48fLvpxZrRVHAJ4CsqrN+x5ARGxcyAtJ+hGwY4Zdx4DVhfVVadtsx9sGbAMYGRmJhRzb7FTV\narU4ceIE4Ckgq17Zq4BWFla/AIzN8LQ9wFpJayS1gC3A9jLHNesXM70H4Ckgq0rZq4C+J2kYCOAo\n8A0ASecA90fEpoiYlnQz8CSwCHggIl4seVyzvuApIMupVAFExNdm2f4qsKmw/jjweJljmfWj7hHA\naaedxtKlSzOnsqbwncBmGXUXwLJly5CUOZU1hQvALKPuG8E8/WNVcgGYZdR9H4ALwKrkAjDLqHsK\nyFcAWZVcAGYZdV8F5BGAVckFYJZRpwD8UdCWgwvALKNWqwXA9PS0p4Csci4As4w6BTA5OekRgFXO\nBWCWUacA3nrrLSLCBWCVcgGYZTQ4OAhA55NvPQVkVXIBmGXUGQFMTEwA/hwgq5YLwCyj7gLwCMCq\n5AIwy6hTAJ0pII8ArEouALOMPAVkObkAzDLqHgF4Csiq5AIwy8hTQJaTC8Aso+IUUKvVYsmSJZkT\nWZO4AMwyKt4H4Okfq5oLwCyj4gjA0z9WtVK/E1jSw8C6tLoceDsihmd43lHgH8B7wHREjJQ5rlm/\n6BTAu+++6wKwypX9pfBf6SxLugv4+xxPvzwi3ixzPLN+0ykA8BVAVr1SBdCh9m+x/jJwRS9ez6wp\nigXgEYBVrVfvAXwGeCMiDs+yP4CnJO2VtHWuF5K0VdKopNHOpXFm/coFYDnNOwKQ9DTwkRl23RkR\nj6Xl64EH53iZyyLimKQPAzslHYyI3870xIjYBmwDGBkZifnymZ3KPAVkOc1bABGxca79kgaALwIX\nz/Eax9LXCUmPAhuAGQvArEk8ArCcejEFtBE4GBHjM+2UNCTp9M4ycBUw1oPjmp3yXACWUy8KYAtd\n0z+SzpH0eFo9G/idpP3AbuDXEfFED45rdsrzFJDlVPoqoIj4+gzbXgU2peWXgQvKHsesH0li8eLF\nTE1NeQRglfOdwGaZdUYBLgCrmgvALLNOAXgKyKrmAjDLzCMAy8UFYJaZC8BycQGYZeYCsFxcAGaZ\ntVothoaGGBjoyUdzmS2YC8Ass8HBQf/0b1m4AMwya7VavgLIsnABmGXWarU8ArAsPOloltltt92W\nO4I1lAvALLPNmzfnjmAN5SkgM7OGcgGYmTWUC8DMrKFcAGZmDeUCMDNrKBeAmVlDuQDMzBrKBWBm\n1lCKiNwZZiXpOPCX9/nHzwTe7GGcXnO+cpyvHOcrp875PhoRZy3kibUugDIkjUbESO4cs3G+cpyv\nHOcrp+75FspTQGZmDeUCMDNrqH4ugG25A8zD+cpxvnKcr5y651uQvn0PwMzM5tbPIwAzM5tD3xWA\npKslHZJ0RNLtufMASHpA0oSkscK2MyTtlHQ4fV2RKdtqSc9KeknSi5JuqVm+JZJ2S9qf8n0nbV8j\naVc6zw9LauXIV8i5SNLzknbUNN9RSX+QtE/SaNpWi3OcsiyX9Iikg5IOSLq0LvkkrUvft87jHUm3\n1iVfGX1VAJIWAfcC1wDrgeslrc+bCoCfAld3bbsdeCYi1gLPpPUcpoFvRsR64BLgpvQ9q0u+fwFX\nRMQFwDBwtaRLgO8Cd0fEJ4C/ATdmytdxC3CgsF63fACXR8Rw4fLFupxjgHuAJyLifOAC2t/LWuSL\niEPp+zYMXAycAB6tS75SIqJvHsClwJOF9TuAO3LnSlnOA8YK64eAlWl5JXAod8aU5THgyjrmAz4I\nPAd8ivZNOAMznfcMuVbR/g/gCmAHoDrlSxmOAmd2bavFOQaWAX8mvSdZt3xdma4Cfl/XfCf76KsR\nAHAu8EphfTxtq6OzI+K1tPw6cHbOMACSzgMuBHZRo3xpemUfMAHsBP4EvB0R0+kpuc/zD4FvAf9J\n6x+iXvkAAnhK0l5JW9O2upzjNcBx4CdpGu1+SUM1yle0BXgwLdcx30nptwI4JUX7R4isl2NJWgr8\nArg1It4p7sudLyLei/bwexWwATg/V5Zukq4FJiJib+4s87gsIi6iPT16k6TPFndmPscDwEXAfRFx\nIfBPuqZTcv8dBEjv41wH/Lx7Xx3yvR/9VgDHgNWF9VVpWx29IWklQPo6kSuIpMW0//P/WUT8sm75\nOiLibeBZ2lMqyyUNpF05z/OngeskHQUeoj0NdA/1yQdARBxLXydoz19voD7neBwYj4hdaf0R2oVQ\nl3wd1wDPRcQbab1u+U5avxXAHmBtugKjRXu4tj1zptlsB25IyzfQnnuvnCQBPwYORMQPCrvqku8s\nScvT8gdovz9xgHYRfCl3voi4IyJWRcR5tP++/SYivlqXfACShiSd3lmmPY89Rk3OcUS8DrwiaV3a\n9HngJWqSr+B6/j/9A/XLd/JyvwnR6wewCfgj7XniO3PnSZkeBF4Dpmj/tHMj7XniZ4DDwNPAGZmy\nXUZ76PoCsC89NtUo3yeB51O+MeDbafvHgN3AEdpD8sEanOfPATvqli9l2Z8eL3b+XdTlHKcsw8Bo\nOs+/AlbULN8Q8FdgWWFbbfK934fvBDYza6h+mwIyM7MFcgGYmTWUC8DMrKFcAGZmDeUCMDNrKBeA\nmVlDuQDMzBrKBWBm1lD/BR8D1kJPX2MqAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc6edf60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: fixed scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_test_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed scheme RMSE: 3.45015275288 \n",
      "Fixed scheme MAE:  2.49553909099\n"
     ]
    }
   ],
   "source": [
    "rmse_fixed = np.sqrt(np.mean((yhat_test_fixed[:,0]-test_target)**2))\n",
    "mae_fixed = np.mean(np.abs((yhat_test_fixed[:,0]-test_target)))\n",
    "print(\"Fixed scheme RMSE:\", rmse_fixed,\n",
    "     \"\\nFixed scheme MAE: \", mae_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Stack training and test set, this makes updating scheme easier to train\n",
    "all_features = np.concatenate((train_features[-window_length:], test_features), axis=0)\n",
    "all_target = np.concatenate((train_target[-window_length:], test_target), axis=0)\n",
    "\n",
    "# Vectors to store loss and forecasts\n",
    "test_loss = np.zeros(len(test_target))\n",
    "yhat_update = np.zeros(len(test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test period = 1  Training loss = 0.4855  Test loss = 2.3705  Model updated 0 times  \n",
      "\n",
      "Test period = 2  Training loss = 0.5676  Test loss = 3.1541  Model updated 0 times  \n",
      "\n",
      "Test period = 3  Training loss = 0.6892  Test loss = 2.5060  Model updated 0 times  \n",
      "\n",
      "Test period = 4  Training loss = 0.7560  Test loss = 1.8272  Model updated 0 times  \n",
      "\n",
      "Test period = 5  Training loss = 0.3643  Test loss = 3.0164  Model updated 1 times  \n",
      "\n",
      "Test period = 6  Training loss = 0.5221  Test loss = 1.1301  Model updated 1 times  \n",
      "\n",
      "Test period = 7  Training loss = 0.5405  Test loss = 1.7787  Model updated 1 times  \n",
      "\n",
      "Test period = 8  Training loss = 0.5838  Test loss = 0.5728  Model updated 1 times  \n",
      "\n",
      "Test period = 9  Training loss = 0.2776  Test loss = 0.8806  Model updated 2 times  \n",
      "\n",
      "Test period = 10  Training loss = 0.2983  Test loss = 2.3464  Model updated 2 times  \n",
      "\n",
      "Test period = 11  Training loss = 0.4164  Test loss = 2.2751  Model updated 2 times  \n",
      "\n",
      "Test period = 12  Training loss = 0.5030  Test loss = 0.5484  Model updated 2 times  \n",
      "\n",
      "Test period = 13  Training loss = 0.2397  Test loss = 3.4528  Model updated 3 times  \n",
      "\n",
      "Test period = 14  Training loss = 0.4908  Test loss = 3.8414  Model updated 3 times  \n",
      "\n",
      "Test period = 15  Training loss = 0.6840  Test loss = 5.5369  Model updated 3 times  \n",
      "\n",
      "Test period = 16  Training loss = 0.9692  Test loss = 7.3598  Model updated 3 times  \n",
      "\n",
      "Test period = 17  Training loss = 0.3555  Test loss = 1.7762  Model updated 4 times  \n",
      "\n",
      "Test period = 18  Training loss = 0.4183  Test loss = 1.7495  Model updated 4 times  \n",
      "\n",
      "Test period = 19  Training loss = 0.4712  Test loss = 1.0582  Model updated 4 times  \n",
      "\n",
      "Test period = 20  Training loss = 0.4887  Test loss = 1.2508  Model updated 4 times  \n",
      "\n",
      "Test period = 21  Training loss = 0.3089  Test loss = 0.5529  Model updated 5 times  \n",
      "\n",
      "Test period = 22  Training loss = 0.3164  Test loss = 3.9423  Model updated 5 times  \n",
      "\n",
      "Test period = 23  Training loss = 0.5824  Test loss = 0.2962  Model updated 5 times  \n",
      "\n",
      "Test period = 24  Training loss = 0.5834  Test loss = 2.6850  Model updated 5 times  \n",
      "\n",
      "Test period = 25  Training loss = 0.4491  Test loss = 1.4732  Model updated 6 times  \n",
      "\n",
      "Test period = 26  Training loss = 0.4849  Test loss = 0.4988  Model updated 6 times  \n",
      "\n",
      "Test period = 27  Training loss = 0.4887  Test loss = 0.3541  Model updated 6 times  \n",
      "\n",
      "Test period = 28  Training loss = 0.4907  Test loss = 1.7641  Model updated 6 times  \n",
      "\n",
      "Test period = 29  Training loss = 0.3379  Test loss = 0.7348  Model updated 7 times  \n",
      "\n",
      "Test period = 30  Training loss = 0.3481  Test loss = 0.5972  Model updated 7 times  \n",
      "\n",
      "Test period = 31  Training loss = 0.3529  Test loss = 3.7089  Model updated 7 times  \n",
      "\n",
      "Test period = 32  Training loss = 0.5795  Test loss = 1.2811  Model updated 7 times  \n",
      "\n",
      "Test period = 33  Training loss = 0.3681  Test loss = 1.0981  Model updated 8 times  \n",
      "\n",
      "Test period = 34  Training loss = 0.3919  Test loss = 1.0605  Model updated 8 times  \n",
      "\n",
      "Test period = 35  Training loss = 0.4117  Test loss = 1.8973  Model updated 8 times  \n",
      "\n",
      "Test period = 36  Training loss = 0.4729  Test loss = 5.2255  Model updated 8 times  \n",
      "\n",
      "Test period = 37  Training loss = 0.7696  Test loss = 1.2720  Model updated 9 times  \n",
      "\n",
      "Test period = 38  Training loss = 0.7856  Test loss = 0.7820  Model updated 9 times  \n",
      "\n",
      "Test period = 39  Training loss = 0.7910  Test loss = 1.4141  Model updated 9 times  \n",
      "\n",
      "Test period = 40  Training loss = 0.8101  Test loss = 3.5374  Model updated 9 times  \n",
      "\n",
      "Test period = 41  Training loss = 0.5999  Test loss = 1.0410  Model updated 10 times  \n",
      "\n",
      "Test period = 42  Training loss = 0.6116  Test loss = 0.7798  Model updated 10 times  \n",
      "\n",
      "Test period = 43  Training loss = 0.6189  Test loss = 2.4640  Model updated 10 times  \n",
      "\n",
      "Test period = 44  Training loss = 0.6902  Test loss = 15.7147  Model updated 10 times  \n",
      "\n",
      "Test period = 45  Training loss = 2.0395  Test loss = 7.2989  Model updated 11 times  \n",
      "\n",
      "Test period = 46  Training loss = 2.2314  Test loss = 1.9801  Model updated 11 times  \n",
      "\n",
      "Test period = 47  Training loss = 2.2448  Test loss = 3.2872  Model updated 11 times  \n",
      "\n",
      "Test period = 48  Training loss = 2.2809  Test loss = 2.3472  Model updated 11 times  \n",
      "\n",
      "Test period = 49  Training loss = 0.9410  Test loss = 4.5501  Model updated 12 times  \n",
      "\n",
      "Test period = 50  Training loss = 1.0947  Test loss = 2.8893  Model updated 12 times  \n",
      "\n",
      "Test period = 51  Training loss = 1.1494  Test loss = 4.2809  Model updated 12 times  \n",
      "\n",
      "Test period = 52  Training loss = 1.2657  Test loss = 0.3978  Model updated 12 times  \n",
      "\n",
      "Test period = 53  Training loss = 0.7946  Test loss = 0.3619  Model updated 13 times  \n",
      "\n",
      "Test period = 54  Training loss = 0.7953  Test loss = 2.3336  Model updated 13 times  \n",
      "\n",
      "Test period = 55  Training loss = 0.8461  Test loss = 0.4450  Model updated 13 times  \n",
      "\n",
      "Test period = 56  Training loss = 0.8478  Test loss = 0.2798  Model updated 13 times  \n",
      "\n",
      "Test period = 57  Training loss = 0.7201  Test loss = 3.4975  Model updated 14 times  \n",
      "\n",
      "Test period = 58  Training loss = 0.8403  Test loss = 5.1012  Model updated 14 times  \n",
      "\n",
      "Test period = 59  Training loss = 1.0491  Test loss = 0.1573  Model updated 14 times  \n",
      "\n",
      "Test period = 60  Training loss = 1.0479  Test loss = 0.5405  Model updated 14 times  \n",
      "\n",
      "Test period = 61  Training loss = 0.7025  Test loss = 0.8514  Model updated 15 times  \n",
      "\n",
      "Test period = 62  Training loss = 0.7100  Test loss = 3.4329  Model updated 15 times  \n",
      "\n",
      "Test period = 63  Training loss = 0.8263  Test loss = 0.8370  Model updated 15 times  \n",
      "\n",
      "Test period = 64  Training loss = 0.8297  Test loss = 0.2849  Model updated 15 times  \n",
      "\n",
      "Test period = 65  Training loss = 0.6319  Test loss = 0.3571  Model updated 16 times  \n",
      "\n",
      "Test period = 66  Training loss = 0.6249  Test loss = 2.1502  Model updated 16 times  \n",
      "\n",
      "Test period = 67  Training loss = 0.6763  Test loss = 3.6365  Model updated 16 times  \n",
      "\n",
      "Test period = 68  Training loss = 0.8114  Test loss = 4.0844  Model updated 16 times  \n",
      "\n",
      "Test period = 69  Training loss = 0.7815  Test loss = 5.6730  Model updated 17 times  \n",
      "\n",
      "Test period = 70  Training loss = 1.0514  Test loss = 0.0366  Model updated 17 times  \n",
      "\n",
      "Test period = 71  Training loss = 1.0511  Test loss = 1.3808  Model updated 17 times  \n",
      "\n",
      "Test period = 72  Training loss = 1.0649  Test loss = 2.4983  Model updated 17 times  \n",
      "\n",
      "Test period = 73  Training loss = 0.6997  Test loss = 2.5757  Model updated 18 times  \n",
      "\n",
      "Test period = 74  Training loss = 0.7690  Test loss = 2.1998  Model updated 18 times  \n",
      "\n",
      "Test period = 75  Training loss = 0.8159  Test loss = 1.6802  Model updated 18 times  \n",
      "\n",
      "Test period = 76  Training loss = 0.8420  Test loss = 1.5864  Model updated 18 times  \n",
      "\n",
      "Test period = 77  Training loss = 0.5963  Test loss = 1.1917  Model updated 19 times  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "retrain_count = 0\n",
    "for t in range(len(test_target)):\n",
    "    x_test = np.reshape(test_features[t], newshape=(1,4,3))\n",
    "    y_test = test_target[t]\n",
    "    test_loss[t] = np.sqrt(sess.run(loss, feed_dict={x:x_test, y:y_test}))\n",
    "    yhat_update[t] = pred.eval(feed_dict={x:x_test})\n",
    "\n",
    "    x_train = all_features[t:(window_length+t)]\n",
    "    y_train = all_target[t:(window_length+t)]\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:x_test, y:y_test})\n",
    "    \n",
    "    print(\"Test period = {0:d}\".format(t+1),\n",
    "      \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "      \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "      \" Model updated {0:d} times\".format(retrain_count),\n",
    "      \" \\n\")\n",
    "\n",
    "    if (t+1)%4==0:\n",
    "        retrain_count += 1\n",
    "        for epoch in range(epoch_hat):\n",
    "            for i in range(total_batch):\n",
    "                optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd617ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: updating scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_update, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating scheme RMSE: 3.20913229555 \n",
      "Updating scheme MAE:  2.29625791948\n"
     ]
    }
   ],
   "source": [
    "rmse_update = np.sqrt(np.mean((yhat_update-test_target)**2))\n",
    "mae_update = np.mean(np.abs((yhat_update-test_target)))\n",
    "print(\"Updating scheme RMSE:\", rmse_update,\n",
    "     \"\\nUpdating scheme MAE: \", mae_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + \"yhat_test_fixed.csv\", yhat_test_fixed)\n",
    "np.savetxt(MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + \"yhat_update.csv\", yhat_update)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
