{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Directories\n",
    "MODEL_FOLDER = \"../../../models/lstm/\"\n",
    "MODEL_FILENAME = MODEL_FOLDER + \"4Q/64_units/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: model saver\n",
    "def saveModel(sess, MODEL_FILENAME):\n",
    "    if not os.path.exists(MODEL_FOLDER):\n",
    "        print('Creating path where to save model: ' + MODEL_FOLDER)\n",
    "        os.mkdir(MODEL_FOLDER)\n",
    "\n",
    "    #print('Saving model at: ' + MODEL_FILENAME)\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, MODEL_FILENAME)\n",
    "    #print('Model successfully saved.\\n')\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: model loader\n",
    "def loadModel(sess, MODEL_FILENAME):\n",
    "    if os.path.exists(MODEL_FILENAME + \".index\"):\n",
    "        print('Loading save model from: ' + MODEL_FILENAME)\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, MODEL_FILENAME)\n",
    "        print('Model successfully loaded.\\n')\n",
    "        return True\n",
    "    else:\n",
    "        print('Model file <<' + MODEL_FILENAME + '>> does not exists!')\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Hyperparameters\n",
    "epochs = 500\n",
    "learning_rate = 1e-3\n",
    "batch_size = 5\n",
    "early_stop_iters = 10\n",
    "folds = 32\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 3  # data input\n",
    "n_steps = 4  # timesteps\n",
    "n_hidden = 64 # dimension of recurrent unit\n",
    "\n",
    "# (REPRODUCIBILITY) set random seeds\n",
    "tf.set_random_seed(123)\n",
    "\n",
    "# Define weights and biases\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.truncated_normal([n_hidden, 1], stddev = 1.0 / tf.sqrt(float(n_hidden))),\n",
    "        name='out_weight')\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.zeros([1]),\n",
    "        name='out_bias')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: Build model\n",
    "def RNN(X, weights, biases, n_hidden):\n",
    "\n",
    "    # Define a LSTM cell with tensorflow\n",
    "    lstm_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden, state_is_tuple=True)\n",
    "    outputs, _ = tf.nn.dynamic_rnn(lstm_cell, X, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    out_layer = tf.matmul(outputs[:,-1,:], weights['out']) + biases['out']\n",
    "\n",
    "    return out_layer\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: select batch\n",
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the data...\n",
      "Finished: data loaded. Stats below: \n",
      "Nr of training samples: 193\n",
      "Nr of testing  samples: 77\n",
      "Number of variables: 3\n",
      "Number of lags: 4\n",
      "Window length: 65\n",
      "Number of validation folds: 32\n"
     ]
    }
   ],
   "source": [
    "# =================================\n",
    "# 0. Load dataset\n",
    "# =================================\n",
    "print(\"Loading the data...\")\n",
    "# Training set pre-processing\n",
    "train = pd.read_csv('../../../Data/train.csv')\n",
    "train_4lag_inflation = np.array(train[['inflation.lag4',\n",
    "                                       'inflation.lag5',\n",
    "                                       'inflation.lag6',\n",
    "                                       'inflation.lag7']])\n",
    "train_4lag_unemp = np.array(train[['unemp.lag4',\n",
    "                                   'unemp.lag5',\n",
    "                                   'unemp.lag6',\n",
    "                                   'unemp.lag7']])\n",
    "train_4lag_oil = np.array(train[['oil.lag4',\n",
    "                                 'oil.lag5',\n",
    "                                 'oil.lag6',\n",
    "                                 'oil.lag7']])\n",
    "train_features = np.concatenate((train_4lag_inflation[:,:,np.newaxis], \n",
    "\t                             train_4lag_unemp[:,:,np.newaxis],\n",
    "\t                             train_4lag_oil[:,:,np.newaxis]),\n",
    "\t                             axis=2)\n",
    "train_target = np.array(train['inflation.target'])\n",
    "\n",
    "# Test set pre-processing\n",
    "test = pd.read_csv('../../../Data/test.csv')\n",
    "test_4lag_inflation = np.array(test[['inflation.lag4',\n",
    "                                     'inflation.lag5',\n",
    "                                     'inflation.lag6',\n",
    "                                     'inflation.lag7']])\n",
    "test_4lag_unemp = np.array(test[['unemp.lag4',\n",
    "                                 'unemp.lag5',\n",
    "                                 'unemp.lag6',\n",
    "                                 'unemp.lag7']])\n",
    "test_4lag_oil = np.array(test[['oil.lag4',\n",
    "                               'oil.lag5',\n",
    "                               'oil.lag6',\n",
    "                               'oil.lag7']])\n",
    "test_features = np.concatenate((test_4lag_inflation[:,:,np.newaxis], \n",
    "\t                            test_4lag_unemp[:,:,np.newaxis],\n",
    "\t                            test_4lag_oil[:,:,np.newaxis]),\n",
    "\t                            axis=2)\n",
    "test_target = np.array(test['inflation.target'])\n",
    "\n",
    "(nrTrainSamples, timesteps, variables) = train_features.shape\n",
    "(nrTestSamples, _, _) = test_features.shape\n",
    "\n",
    "# Window length and validation fold index\n",
    "window_length = 65\n",
    "valIndex = np.linspace(start=window_length, stop=nrTrainSamples, \n",
    "                       endpoint=True, num=folds+1, dtype=np.int)\n",
    "\n",
    "print(\"Finished: data loaded. Stats below: \")\n",
    "print(\"Nr of training samples: %d\" % nrTrainSamples)\n",
    "print(\"Nr of testing  samples: %d\" % nrTestSamples)\n",
    "print(\"Number of variables: %d\" % variables)\n",
    "print(\"Number of lags: %d\" % timesteps)\n",
    "print(\"Window length: %d\" % window_length)\n",
    "print(\"Number of validation folds: %d\" % folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 1. Build model\n",
    "# ==================================\n",
    "# tf graph input\n",
    "x = tf.placeholder(\"float\", [None, n_steps, n_input], name='Batch')\n",
    "y = tf.placeholder(\"float\", name='True_labels_of_batch')\n",
    "lr = tf.placeholder(\"float\", name='Learning_rate')\n",
    "\n",
    "# Make predictions with the model\n",
    "pred = RNN(x, weights, biases, n_hidden)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss = tf.reduce_mean(tf.diag_part(tf.square(tf.subtract(x=pred, y=y))))\n",
    "optimizer = tf.train.GradientDescentOptimizer(lr).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training \n",
      "Hyperparameters: \n",
      "Dimension of recurrent unit = 64 \n",
      "Learning rate = 0.001 \n",
      "Epochs = 500 \n",
      "Batch size = 5 \n",
      "Early stopping epochs = 10 \n",
      "Learning rate = 0.001\n",
      "Fold: 1  Epoch: 1  Training loss = 3.0892  Validation loss = 3.1544  \n",
      "\n",
      "Fold: 1  Epoch: 2  Training loss = 2.9413  Validation loss = 2.8549  \n",
      "\n",
      "Fold: 1  Epoch: 3  Training loss = 2.8246  Validation loss = 2.5602  \n",
      "\n",
      "Fold: 1  Epoch: 4  Training loss = 2.7672  Validation loss = 2.3929  \n",
      "\n",
      "Fold: 1  Epoch: 5  Training loss = 2.7291  Validation loss = 2.2742  \n",
      "\n",
      "Fold: 1  Epoch: 6  Training loss = 2.6758  Validation loss = 2.0653  \n",
      "\n",
      "Fold: 1  Epoch: 7  Training loss = 2.6632  Validation loss = 2.0273  \n",
      "\n",
      "Fold: 1  Epoch: 8  Training loss = 2.6389  Validation loss = 1.9127  \n",
      "\n",
      "Fold: 1  Epoch: 9  Training loss = 2.6294  Validation loss = 1.8797  \n",
      "\n",
      "Fold: 1  Epoch: 10  Training loss = 2.6078  Validation loss = 1.7916  \n",
      "\n",
      "Fold: 1  Epoch: 11  Training loss = 2.6203  Validation loss = 1.9096  \n",
      "\n",
      "Fold: 1  Epoch: 12  Training loss = 2.6185  Validation loss = 1.9066  \n",
      "\n",
      "Fold: 1  Epoch: 13  Training loss = 2.6141  Validation loss = 1.9074  \n",
      "\n",
      "Fold: 1  Epoch: 14  Training loss = 2.6059  Validation loss = 1.8248  \n",
      "\n",
      "Fold: 1  Epoch: 15  Training loss = 2.5877  Validation loss = 1.6922  \n",
      "\n",
      "Fold: 1  Epoch: 16  Training loss = 2.5724  Validation loss = 1.5936  \n",
      "\n",
      "Fold: 1  Epoch: 17  Training loss = 2.5650  Validation loss = 1.6465  \n",
      "\n",
      "Fold: 1  Epoch: 18  Training loss = 2.5661  Validation loss = 1.6924  \n",
      "\n",
      "Fold: 1  Epoch: 19  Training loss = 2.5605  Validation loss = 1.7042  \n",
      "\n",
      "Fold: 1  Epoch: 20  Training loss = 2.5525  Validation loss = 1.6745  \n",
      "\n",
      "Fold: 1  Epoch: 21  Training loss = 2.5532  Validation loss = 1.7152  \n",
      "\n",
      "Fold: 1  Epoch: 22  Training loss = 2.5508  Validation loss = 1.7436  \n",
      "\n",
      "Fold: 1  Epoch: 23  Training loss = 2.5410  Validation loss = 1.6437  \n",
      "\n",
      "Fold: 1  Epoch: 24  Training loss = 2.5332  Validation loss = 1.6033  \n",
      "\n",
      "Fold: 1  Epoch: 25  Training loss = 2.5317  Validation loss = 1.6462  \n",
      "\n",
      "Fold: 1  Epoch: 26  Training loss = 2.5300  Validation loss = 1.6721  \n",
      "\n",
      "Fold: 1  Epoch: 27  Training loss = 2.5241  Validation loss = 1.6778  \n",
      "\n",
      "Fold: 1  Epoch: 28  Training loss = 2.5179  Validation loss = 1.6965  \n",
      "\n",
      "Fold: 1  Epoch: 29  Training loss = 2.5144  Validation loss = 1.7262  \n",
      "\n",
      "Fold: 1  Epoch: 30  Training loss = 2.5029  Validation loss = 1.6716  \n",
      "\n",
      "Fold: 1  Epoch: 31  Training loss = 2.5080  Validation loss = 1.7924  \n",
      "\n",
      "Check model:  Fold: 1  Epoch: 16  Training loss = 2.5080  Validation loss = 1.7924  \n",
      "\n",
      "Fold: 2  Epoch: 1  Training loss = 2.4327  Validation loss = 2.2570  \n",
      "\n",
      "Fold: 2  Epoch: 2  Training loss = 2.4259  Validation loss = 2.2352  \n",
      "\n",
      "Fold: 2  Epoch: 3  Training loss = 2.4197  Validation loss = 2.2009  \n",
      "\n",
      "Fold: 2  Epoch: 4  Training loss = 2.4165  Validation loss = 2.1494  \n",
      "\n",
      "Fold: 2  Epoch: 5  Training loss = 2.4125  Validation loss = 2.1902  \n",
      "\n",
      "Fold: 2  Epoch: 6  Training loss = 2.4178  Validation loss = 2.2631  \n",
      "\n",
      "Fold: 2  Epoch: 7  Training loss = 2.4197  Validation loss = 2.2770  \n",
      "\n",
      "Fold: 2  Epoch: 8  Training loss = 2.4223  Validation loss = 2.3100  \n",
      "\n",
      "Fold: 2  Epoch: 9  Training loss = 2.4034  Validation loss = 2.1728  \n",
      "\n",
      "Fold: 2  Epoch: 10  Training loss = 2.3996  Validation loss = 2.1510  \n",
      "\n",
      "Fold: 2  Epoch: 11  Training loss = 2.3994  Validation loss = 2.0921  \n",
      "\n",
      "Fold: 2  Epoch: 12  Training loss = 2.3934  Validation loss = 2.1761  \n",
      "\n",
      "Fold: 2  Epoch: 13  Training loss = 2.3917  Validation loss = 2.2031  \n",
      "\n",
      "Fold: 2  Epoch: 14  Training loss = 2.3976  Validation loss = 2.2350  \n",
      "\n",
      "Fold: 2  Epoch: 15  Training loss = 2.3907  Validation loss = 2.2081  \n",
      "\n",
      "Fold: 2  Epoch: 16  Training loss = 2.3841  Validation loss = 2.1433  \n",
      "\n",
      "Fold: 2  Epoch: 17  Training loss = 2.3773  Validation loss = 2.1154  \n",
      "\n",
      "Fold: 2  Epoch: 18  Training loss = 2.3722  Validation loss = 2.1385  \n",
      "\n",
      "Fold: 2  Epoch: 19  Training loss = 2.3684  Validation loss = 2.1379  \n",
      "\n",
      "Fold: 2  Epoch: 20  Training loss = 2.3627  Validation loss = 2.1530  \n",
      "\n",
      "Fold: 2  Epoch: 21  Training loss = 2.3611  Validation loss = 2.1284  \n",
      "\n",
      "Fold: 2  Epoch: 22  Training loss = 2.3582  Validation loss = 2.1256  \n",
      "\n",
      "Fold: 2  Epoch: 23  Training loss = 2.3534  Validation loss = 2.1004  \n",
      "\n",
      "Fold: 2  Epoch: 24  Training loss = 2.3404  Validation loss = 2.1905  \n",
      "\n",
      "Fold: 2  Epoch: 25  Training loss = 2.3387  Validation loss = 2.2726  \n",
      "\n",
      "Check model:  Fold: 2  Epoch: 11  Training loss = 2.3387  Validation loss = 2.2726  \n",
      "\n",
      "Fold: 3  Epoch: 1  Training loss = 1.5357  Validation loss = 3.6410  \n",
      "\n",
      "Fold: 3  Epoch: 2  Training loss = 1.5247  Validation loss = 3.6087  \n",
      "\n",
      "Fold: 3  Epoch: 3  Training loss = 1.5171  Validation loss = 3.6738  \n",
      "\n",
      "Fold: 3  Epoch: 4  Training loss = 1.5065  Validation loss = 3.5884  \n",
      "\n",
      "Fold: 3  Epoch: 5  Training loss = 1.5012  Validation loss = 3.5430  \n",
      "\n",
      "Fold: 3  Epoch: 6  Training loss = 1.4983  Validation loss = 3.5068  \n",
      "\n",
      "Fold: 3  Epoch: 7  Training loss = 1.4923  Validation loss = 3.5642  \n",
      "\n",
      "Fold: 3  Epoch: 8  Training loss = 1.4871  Validation loss = 3.4433  \n",
      "\n",
      "Fold: 3  Epoch: 9  Training loss = 1.4817  Validation loss = 3.4912  \n",
      "\n",
      "Fold: 3  Epoch: 10  Training loss = 1.4782  Validation loss = 3.3919  \n",
      "\n",
      "Fold: 3  Epoch: 11  Training loss = 1.4737  Validation loss = 3.3812  \n",
      "\n",
      "Fold: 3  Epoch: 12  Training loss = 1.4713  Validation loss = 3.3538  \n",
      "\n",
      "Fold: 3  Epoch: 13  Training loss = 1.4681  Validation loss = 3.4097  \n",
      "\n",
      "Fold: 3  Epoch: 14  Training loss = 1.4669  Validation loss = 3.3581  \n",
      "\n",
      "Fold: 3  Epoch: 15  Training loss = 1.4678  Validation loss = 3.2780  \n",
      "\n",
      "Fold: 3  Epoch: 16  Training loss = 1.4615  Validation loss = 3.2846  \n",
      "\n",
      "Fold: 3  Epoch: 17  Training loss = 1.4601  Validation loss = 3.2822  \n",
      "\n",
      "Fold: 3  Epoch: 18  Training loss = 1.4565  Validation loss = 3.2928  \n",
      "\n",
      "Fold: 3  Epoch: 19  Training loss = 1.4544  Validation loss = 3.3236  \n",
      "\n",
      "Fold: 3  Epoch: 20  Training loss = 1.4519  Validation loss = 3.3519  \n",
      "\n",
      "Fold: 3  Epoch: 21  Training loss = 1.4541  Validation loss = 3.4395  \n",
      "\n",
      "Check model:  Fold: 3  Epoch: 15  Training loss = 1.4541  Validation loss = 3.4395  \n",
      "\n",
      "Fold: 4  Epoch: 1  Training loss = 1.5676  Validation loss = 4.5152  \n",
      "\n",
      "Fold: 4  Epoch: 2  Training loss = 1.5665  Validation loss = 4.5290  \n",
      "\n",
      "Fold: 4  Epoch: 3  Training loss = 1.5507  Validation loss = 4.4152  \n",
      "\n",
      "Fold: 4  Epoch: 4  Training loss = 1.5462  Validation loss = 4.3748  \n",
      "\n",
      "Fold: 4  Epoch: 5  Training loss = 1.5418  Validation loss = 4.3905  \n",
      "\n",
      "Fold: 4  Epoch: 6  Training loss = 1.5376  Validation loss = 4.3624  \n",
      "\n",
      "Fold: 4  Epoch: 7  Training loss = 1.5285  Validation loss = 4.2477  \n",
      "\n",
      "Fold: 4  Epoch: 8  Training loss = 1.5250  Validation loss = 4.2930  \n",
      "\n",
      "Fold: 4  Epoch: 9  Training loss = 1.5171  Validation loss = 4.2507  \n",
      "\n",
      "Fold: 4  Epoch: 10  Training loss = 1.5137  Validation loss = 4.1469  \n",
      "\n",
      "Fold: 4  Epoch: 11  Training loss = 1.5099  Validation loss = 4.1841  \n",
      "\n",
      "Fold: 4  Epoch: 12  Training loss = 1.5059  Validation loss = 4.1776  \n",
      "\n",
      "Fold: 4  Epoch: 13  Training loss = 1.5113  Validation loss = 4.2966  \n",
      "\n",
      "Fold: 4  Epoch: 14  Training loss = 1.5051  Validation loss = 4.2485  \n",
      "\n",
      "Fold: 4  Epoch: 15  Training loss = 1.4945  Validation loss = 4.0682  \n",
      "\n",
      "Fold: 4  Epoch: 16  Training loss = 1.4918  Validation loss = 4.0875  \n",
      "\n",
      "Fold: 4  Epoch: 17  Training loss = 1.4878  Validation loss = 4.0296  \n",
      "\n",
      "Fold: 4  Epoch: 18  Training loss = 1.4874  Validation loss = 3.9737  \n",
      "\n",
      "Fold: 4  Epoch: 19  Training loss = 1.4847  Validation loss = 3.9732  \n",
      "\n",
      "Fold: 4  Epoch: 20  Training loss = 1.4806  Validation loss = 3.9702  \n",
      "\n",
      "Fold: 4  Epoch: 21  Training loss = 1.4782  Validation loss = 3.9800  \n",
      "\n",
      "Fold: 4  Epoch: 22  Training loss = 1.4747  Validation loss = 3.9546  \n",
      "\n",
      "Fold: 4  Epoch: 23  Training loss = 1.4736  Validation loss = 4.0163  \n",
      "\n",
      "Fold: 4  Epoch: 24  Training loss = 1.4708  Validation loss = 4.0043  \n",
      "\n",
      "Fold: 4  Epoch: 25  Training loss = 1.4667  Validation loss = 3.9620  \n",
      "\n",
      "Fold: 4  Epoch: 26  Training loss = 1.4678  Validation loss = 4.0435  \n",
      "\n",
      "Check model:  Fold: 4  Epoch: 22  Training loss = 1.4678  Validation loss = 4.0435  \n",
      "\n",
      "Fold: 5  Epoch: 1  Training loss = 1.6877  Validation loss = 4.0466  \n",
      "\n",
      "Fold: 5  Epoch: 2  Training loss = 1.6762  Validation loss = 4.0217  \n",
      "\n",
      "Fold: 5  Epoch: 3  Training loss = 1.6718  Validation loss = 4.0436  \n",
      "\n",
      "Fold: 5  Epoch: 4  Training loss = 1.6661  Validation loss = 4.0255  \n",
      "\n",
      "Fold: 5  Epoch: 5  Training loss = 1.6533  Validation loss = 3.9647  \n",
      "\n",
      "Fold: 5  Epoch: 6  Training loss = 1.6391  Validation loss = 3.8917  \n",
      "\n",
      "Fold: 5  Epoch: 7  Training loss = 1.6380  Validation loss = 3.9170  \n",
      "\n",
      "Fold: 5  Epoch: 8  Training loss = 1.6172  Validation loss = 3.7933  \n",
      "\n",
      "Fold: 5  Epoch: 9  Training loss = 1.6074  Validation loss = 3.7354  \n",
      "\n",
      "Fold: 5  Epoch: 10  Training loss = 1.5967  Validation loss = 3.7097  \n",
      "\n",
      "Fold: 5  Epoch: 11  Training loss = 1.5684  Validation loss = 3.4590  \n",
      "\n",
      "Fold: 5  Epoch: 12  Training loss = 1.5560  Validation loss = 3.5388  \n",
      "\n",
      "Fold: 5  Epoch: 13  Training loss = 1.5438  Validation loss = 3.5203  \n",
      "\n",
      "Fold: 5  Epoch: 14  Training loss = 1.5290  Validation loss = 3.4086  \n",
      "\n",
      "Fold: 5  Epoch: 15  Training loss = 1.5179  Validation loss = 3.3962  \n",
      "\n",
      "Fold: 5  Epoch: 16  Training loss = 1.5114  Validation loss = 3.4259  \n",
      "\n",
      "Fold: 5  Epoch: 17  Training loss = 1.5052  Validation loss = 3.3758  \n",
      "\n",
      "Fold: 5  Epoch: 18  Training loss = 1.4959  Validation loss = 3.3668  \n",
      "\n",
      "Fold: 5  Epoch: 19  Training loss = 1.4861  Validation loss = 3.3506  \n",
      "\n",
      "Fold: 5  Epoch: 20  Training loss = 1.4774  Validation loss = 3.3269  \n",
      "\n",
      "Fold: 5  Epoch: 21  Training loss = 1.4709  Validation loss = 3.3258  \n",
      "\n",
      "Fold: 5  Epoch: 22  Training loss = 1.4661  Validation loss = 3.3465  \n",
      "\n",
      "Fold: 5  Epoch: 23  Training loss = 1.4502  Validation loss = 3.2546  \n",
      "\n",
      "Fold: 5  Epoch: 24  Training loss = 1.4521  Validation loss = 3.2768  \n",
      "\n",
      "Fold: 5  Epoch: 25  Training loss = 1.4475  Validation loss = 3.2905  \n",
      "\n",
      "Fold: 5  Epoch: 26  Training loss = 1.4361  Validation loss = 3.1975  \n",
      "\n",
      "Fold: 5  Epoch: 27  Training loss = 1.4280  Validation loss = 3.1278  \n",
      "\n",
      "Fold: 5  Epoch: 28  Training loss = 1.4185  Validation loss = 2.9870  \n",
      "\n",
      "Fold: 5  Epoch: 29  Training loss = 1.4087  Validation loss = 2.9577  \n",
      "\n",
      "Fold: 5  Epoch: 30  Training loss = 1.4013  Validation loss = 3.0524  \n",
      "\n",
      "Fold: 5  Epoch: 31  Training loss = 1.3930  Validation loss = 2.9920  \n",
      "\n",
      "Fold: 5  Epoch: 32  Training loss = 1.3926  Validation loss = 3.0856  \n",
      "\n",
      "Fold: 5  Epoch: 33  Training loss = 1.3821  Validation loss = 3.0417  \n",
      "\n",
      "Fold: 5  Epoch: 34  Training loss = 1.3772  Validation loss = 2.9573  \n",
      "\n",
      "Fold: 5  Epoch: 35  Training loss = 1.3714  Validation loss = 2.9283  \n",
      "\n",
      "Fold: 5  Epoch: 36  Training loss = 1.3614  Validation loss = 2.9266  \n",
      "\n",
      "Fold: 5  Epoch: 37  Training loss = 1.3544  Validation loss = 2.9268  \n",
      "\n",
      "Fold: 5  Epoch: 38  Training loss = 1.3473  Validation loss = 2.8766  \n",
      "\n",
      "Fold: 5  Epoch: 39  Training loss = 1.3400  Validation loss = 2.8640  \n",
      "\n",
      "Fold: 5  Epoch: 40  Training loss = 1.3408  Validation loss = 2.7810  \n",
      "\n",
      "Fold: 5  Epoch: 41  Training loss = 1.3273  Validation loss = 2.7826  \n",
      "\n",
      "Fold: 5  Epoch: 42  Training loss = 1.3221  Validation loss = 2.7605  \n",
      "\n",
      "Fold: 5  Epoch: 43  Training loss = 1.3142  Validation loss = 2.7317  \n",
      "\n",
      "Fold: 5  Epoch: 44  Training loss = 1.3088  Validation loss = 2.7440  \n",
      "\n",
      "Fold: 5  Epoch: 45  Training loss = 1.3029  Validation loss = 2.8073  \n",
      "\n",
      "Fold: 5  Epoch: 46  Training loss = 1.2956  Validation loss = 2.7790  \n",
      "\n",
      "Fold: 5  Epoch: 47  Training loss = 1.2917  Validation loss = 2.7177  \n",
      "\n",
      "Fold: 5  Epoch: 48  Training loss = 1.2885  Validation loss = 2.6605  \n",
      "\n",
      "Fold: 5  Epoch: 49  Training loss = 1.2810  Validation loss = 2.6194  \n",
      "\n",
      "Fold: 5  Epoch: 50  Training loss = 1.2745  Validation loss = 2.6473  \n",
      "\n",
      "Fold: 5  Epoch: 51  Training loss = 1.2705  Validation loss = 2.6834  \n",
      "\n",
      "Fold: 5  Epoch: 52  Training loss = 1.2657  Validation loss = 2.6994  \n",
      "\n",
      "Fold: 5  Epoch: 53  Training loss = 1.2586  Validation loss = 2.5881  \n",
      "\n",
      "Fold: 5  Epoch: 54  Training loss = 1.2586  Validation loss = 2.6525  \n",
      "\n",
      "Fold: 5  Epoch: 55  Training loss = 1.2503  Validation loss = 2.5716  \n",
      "\n",
      "Fold: 5  Epoch: 56  Training loss = 1.2468  Validation loss = 2.4971  \n",
      "\n",
      "Fold: 5  Epoch: 57  Training loss = 1.2447  Validation loss = 2.4602  \n",
      "\n",
      "Fold: 5  Epoch: 58  Training loss = 1.2380  Validation loss = 2.4468  \n",
      "\n",
      "Fold: 5  Epoch: 59  Training loss = 1.2337  Validation loss = 2.5089  \n",
      "\n",
      "Fold: 5  Epoch: 60  Training loss = 1.2287  Validation loss = 2.4399  \n",
      "\n",
      "Fold: 5  Epoch: 61  Training loss = 1.2238  Validation loss = 2.4385  \n",
      "\n",
      "Fold: 5  Epoch: 62  Training loss = 1.2214  Validation loss = 2.4510  \n",
      "\n",
      "Fold: 5  Epoch: 63  Training loss = 1.2298  Validation loss = 2.5674  \n",
      "\n",
      "Fold: 5  Epoch: 64  Training loss = 1.2141  Validation loss = 2.4277  \n",
      "\n",
      "Fold: 5  Epoch: 65  Training loss = 1.2110  Validation loss = 2.3681  \n",
      "\n",
      "Fold: 5  Epoch: 66  Training loss = 1.2130  Validation loss = 2.3046  \n",
      "\n",
      "Fold: 5  Epoch: 67  Training loss = 1.2067  Validation loss = 2.3420  \n",
      "\n",
      "Fold: 5  Epoch: 68  Training loss = 1.2060  Validation loss = 2.4084  \n",
      "\n",
      "Fold: 5  Epoch: 69  Training loss = 1.2040  Validation loss = 2.3742  \n",
      "\n",
      "Fold: 5  Epoch: 70  Training loss = 1.2052  Validation loss = 2.2797  \n",
      "\n",
      "Fold: 5  Epoch: 71  Training loss = 1.2011  Validation loss = 2.2792  \n",
      "\n",
      "Fold: 5  Epoch: 72  Training loss = 1.1984  Validation loss = 2.2630  \n",
      "\n",
      "Fold: 5  Epoch: 73  Training loss = 1.1985  Validation loss = 2.2507  \n",
      "\n",
      "Fold: 5  Epoch: 74  Training loss = 1.1888  Validation loss = 2.3088  \n",
      "\n",
      "Fold: 5  Epoch: 75  Training loss = 1.1873  Validation loss = 2.2703  \n",
      "\n",
      "Fold: 5  Epoch: 76  Training loss = 1.1845  Validation loss = 2.3860  \n",
      "\n",
      "Fold: 5  Epoch: 77  Training loss = 1.1808  Validation loss = 2.4312  \n",
      "\n",
      "Check model:  Fold: 5  Epoch: 73  Training loss = 1.1808  Validation loss = 2.4312  \n",
      "\n",
      "Fold: 6  Epoch: 1  Training loss = 1.2618  Validation loss = 1.1122  \n",
      "\n",
      "Fold: 6  Epoch: 2  Training loss = 1.2377  Validation loss = 1.2201  \n",
      "\n",
      "Fold: 6  Epoch: 3  Training loss = 1.2319  Validation loss = 1.2773  \n",
      "\n",
      "Fold: 6  Epoch: 4  Training loss = 1.2297  Validation loss = 1.3587  \n",
      "\n",
      "Fold: 6  Epoch: 5  Training loss = 1.2087  Validation loss = 1.2885  \n",
      "\n",
      "Fold: 6  Epoch: 6  Training loss = 1.1961  Validation loss = 1.2424  \n",
      "\n",
      "Fold: 6  Epoch: 7  Training loss = 1.1966  Validation loss = 1.3248  \n",
      "\n",
      "Fold: 6  Epoch: 8  Training loss = 1.1879  Validation loss = 1.1619  \n",
      "\n",
      "Fold: 6  Epoch: 9  Training loss = 1.1823  Validation loss = 1.1765  \n",
      "\n",
      "Fold: 6  Epoch: 10  Training loss = 1.1796  Validation loss = 1.1292  \n",
      "\n",
      "Fold: 6  Epoch: 11  Training loss = 1.1786  Validation loss = 1.1387  \n",
      "\n",
      "Fold: 6  Epoch: 12  Training loss = 1.1772  Validation loss = 1.1871  \n",
      "\n",
      "Fold: 6  Epoch: 13  Training loss = 1.1725  Validation loss = 1.1768  \n",
      "\n",
      "Fold: 6  Epoch: 14  Training loss = 1.1840  Validation loss = 1.0932  \n",
      "\n",
      "Fold: 6  Epoch: 15  Training loss = 1.1660  Validation loss = 1.1988  \n",
      "\n",
      "Fold: 6  Epoch: 16  Training loss = 1.1683  Validation loss = 1.2280  \n",
      "\n",
      "Fold: 6  Epoch: 17  Training loss = 1.1563  Validation loss = 1.2809  \n",
      "\n",
      "Check model:  Fold: 6  Epoch: 14  Training loss = 1.1563  Validation loss = 1.2809  \n",
      "\n",
      "Fold: 7  Epoch: 1  Training loss = 1.1744  Validation loss = 1.7577  \n",
      "\n",
      "Fold: 7  Epoch: 2  Training loss = 1.1786  Validation loss = 1.7915  \n",
      "\n",
      "Fold: 7  Epoch: 3  Training loss = 1.1775  Validation loss = 1.7962  \n",
      "\n",
      "Fold: 7  Epoch: 4  Training loss = 1.1722  Validation loss = 1.7936  \n",
      "\n",
      "Fold: 7  Epoch: 5  Training loss = 1.1620  Validation loss = 1.7321  \n",
      "\n",
      "Fold: 7  Epoch: 6  Training loss = 1.1567  Validation loss = 1.7437  \n",
      "\n",
      "Fold: 7  Epoch: 7  Training loss = 1.1581  Validation loss = 1.7756  \n",
      "\n",
      "Fold: 7  Epoch: 8  Training loss = 1.1525  Validation loss = 1.7326  \n",
      "\n",
      "Fold: 7  Epoch: 9  Training loss = 1.1522  Validation loss = 1.7851  \n",
      "\n",
      "Fold: 7  Epoch: 10  Training loss = 1.1777  Validation loss = 1.8418  \n",
      "\n",
      "Fold: 7  Epoch: 11  Training loss = 1.1471  Validation loss = 1.8135  \n",
      "\n",
      "Fold: 7  Epoch: 12  Training loss = 1.1652  Validation loss = 1.8703  \n",
      "\n",
      "Check model:  Fold: 7  Epoch: 5  Training loss = 1.1652  Validation loss = 1.8703  \n",
      "\n",
      "Fold: 8  Epoch: 1  Training loss = 1.1596  Validation loss = 6.5903  \n",
      "\n",
      "Fold: 8  Epoch: 2  Training loss = 1.1535  Validation loss = 6.6146  \n",
      "\n",
      "Fold: 8  Epoch: 3  Training loss = 1.1424  Validation loss = 6.5441  \n",
      "\n",
      "Fold: 8  Epoch: 4  Training loss = 1.1424  Validation loss = 6.5907  \n",
      "\n",
      "Fold: 8  Epoch: 5  Training loss = 1.1495  Validation loss = 6.6768  \n",
      "\n",
      "Fold: 8  Epoch: 6  Training loss = 1.1485  Validation loss = 6.6673  \n",
      "\n",
      "Fold: 8  Epoch: 7  Training loss = 1.1368  Validation loss = 6.5675  \n",
      "\n",
      "Fold: 8  Epoch: 8  Training loss = 1.1368  Validation loss = 6.5619  \n",
      "\n",
      "Fold: 8  Epoch: 9  Training loss = 1.1324  Validation loss = 6.5603  \n",
      "\n",
      "Fold: 8  Epoch: 10  Training loss = 1.1354  Validation loss = 6.4694  \n",
      "\n",
      "Fold: 8  Epoch: 11  Training loss = 1.1302  Validation loss = 6.6545  \n",
      "\n",
      "Fold: 8  Epoch: 12  Training loss = 1.1223  Validation loss = 6.6255  \n",
      "\n",
      "Fold: 8  Epoch: 13  Training loss = 1.1715  Validation loss = 6.8235  \n",
      "\n",
      "Check model:  Fold: 8  Epoch: 10  Training loss = 1.1715  Validation loss = 6.8235  \n",
      "\n",
      "Fold: 9  Epoch: 1  Training loss = 1.9708  Validation loss = 8.1238  \n",
      "\n",
      "Fold: 9  Epoch: 2  Training loss = 1.8769  Validation loss = 7.5365  \n",
      "\n",
      "Fold: 9  Epoch: 3  Training loss = 1.8502  Validation loss = 7.4997  \n",
      "\n",
      "Fold: 9  Epoch: 4  Training loss = 1.8244  Validation loss = 7.5333  \n",
      "\n",
      "Fold: 9  Epoch: 5  Training loss = 1.8391  Validation loss = 7.7315  \n",
      "\n",
      "Fold: 9  Epoch: 6  Training loss = 1.8196  Validation loss = 6.9747  \n",
      "\n",
      "Fold: 9  Epoch: 7  Training loss = 1.7058  Validation loss = 7.2763  \n",
      "\n",
      "Fold: 9  Epoch: 8  Training loss = 1.6863  Validation loss = 7.5084  \n",
      "\n",
      "Fold: 9  Epoch: 9  Training loss = 1.6692  Validation loss = 7.5475  \n",
      "\n",
      "Fold: 9  Epoch: 10  Training loss = 1.6667  Validation loss = 7.4831  \n",
      "\n",
      "Fold: 9  Epoch: 11  Training loss = 1.6691  Validation loss = 7.3459  \n",
      "\n",
      "Fold: 9  Epoch: 12  Training loss = 1.6480  Validation loss = 7.6663  \n",
      "\n",
      "Fold: 9  Epoch: 13  Training loss = 1.6420  Validation loss = 7.6539  \n",
      "\n",
      "Fold: 9  Epoch: 14  Training loss = 1.6309  Validation loss = 7.4668  \n",
      "\n",
      "Fold: 9  Epoch: 15  Training loss = 1.6406  Validation loss = 7.4652  \n",
      "\n",
      "Fold: 9  Epoch: 16  Training loss = 1.6237  Validation loss = 7.5959  \n",
      "\n",
      "Fold: 9  Epoch: 17  Training loss = 1.6178  Validation loss = 7.5724  \n",
      "\n",
      "Fold: 9  Epoch: 18  Training loss = 1.6274  Validation loss = 7.4804  \n",
      "\n",
      "Fold: 9  Epoch: 19  Training loss = 1.6199  Validation loss = 7.4311  \n",
      "\n",
      "Fold: 9  Epoch: 20  Training loss = 1.6093  Validation loss = 7.4802  \n",
      "\n",
      "Fold: 9  Epoch: 21  Training loss = 1.5987  Validation loss = 7.5192  \n",
      "\n",
      "Fold: 9  Epoch: 22  Training loss = 1.5981  Validation loss = 7.4997  \n",
      "\n",
      "Fold: 9  Epoch: 23  Training loss = 1.5995  Validation loss = 7.5868  \n",
      "\n",
      "Fold: 9  Epoch: 24  Training loss = 1.6191  Validation loss = 7.6481  \n",
      "\n",
      "Check model:  Fold: 9  Epoch: 6  Training loss = 1.6191  Validation loss = 7.6481  \n",
      "\n",
      "Fold: 10  Epoch: 1  Training loss = 2.3597  Validation loss = 5.9998  \n",
      "\n",
      "Fold: 10  Epoch: 2  Training loss = 2.3080  Validation loss = 5.2152  \n",
      "\n",
      "Fold: 10  Epoch: 3  Training loss = 2.2606  Validation loss = 5.4966  \n",
      "\n",
      "Fold: 10  Epoch: 4  Training loss = 2.2468  Validation loss = 5.2694  \n",
      "\n",
      "Fold: 10  Epoch: 5  Training loss = 2.2571  Validation loss = 5.5125  \n",
      "\n",
      "Fold: 10  Epoch: 6  Training loss = 2.2337  Validation loss = 5.2370  \n",
      "\n",
      "Fold: 10  Epoch: 7  Training loss = 2.2031  Validation loss = 5.3390  \n",
      "\n",
      "Fold: 10  Epoch: 8  Training loss = 2.1933  Validation loss = 5.4891  \n",
      "\n",
      "Fold: 10  Epoch: 9  Training loss = 2.1701  Validation loss = 5.0964  \n",
      "\n",
      "Fold: 10  Epoch: 10  Training loss = 2.1670  Validation loss = 4.9155  \n",
      "\n",
      "Fold: 10  Epoch: 11  Training loss = 2.1619  Validation loss = 5.4036  \n",
      "\n",
      "Fold: 10  Epoch: 12  Training loss = 2.1323  Validation loss = 5.4498  \n",
      "\n",
      "Fold: 10  Epoch: 13  Training loss = 2.1026  Validation loss = 4.9507  \n",
      "\n",
      "Fold: 10  Epoch: 14  Training loss = 2.1342  Validation loss = 4.8588  \n",
      "\n",
      "Fold: 10  Epoch: 15  Training loss = 2.1041  Validation loss = 5.0719  \n",
      "\n",
      "Fold: 10  Epoch: 16  Training loss = 2.1117  Validation loss = 4.9321  \n",
      "\n",
      "Fold: 10  Epoch: 17  Training loss = 2.0695  Validation loss = 4.9684  \n",
      "\n",
      "Fold: 10  Epoch: 18  Training loss = 2.1083  Validation loss = 4.6598  \n",
      "\n",
      "Fold: 10  Epoch: 19  Training loss = 2.0759  Validation loss = 4.8388  \n",
      "\n",
      "Fold: 10  Epoch: 20  Training loss = 2.2161  Validation loss = 4.7705  \n",
      "\n",
      "Fold: 10  Epoch: 21  Training loss = 2.1380  Validation loss = 4.6722  \n",
      "\n",
      "Fold: 10  Epoch: 22  Training loss = 2.0865  Validation loss = 4.4113  \n",
      "\n",
      "Fold: 10  Epoch: 23  Training loss = 2.0621  Validation loss = 4.6083  \n",
      "\n",
      "Fold: 10  Epoch: 24  Training loss = 2.1576  Validation loss = 4.9135  \n",
      "\n",
      "Fold: 10  Epoch: 25  Training loss = 2.0261  Validation loss = 4.4898  \n",
      "\n",
      "Fold: 10  Epoch: 26  Training loss = 2.0251  Validation loss = 4.4770  \n",
      "\n",
      "Fold: 10  Epoch: 27  Training loss = 2.0181  Validation loss = 4.4597  \n",
      "\n",
      "Fold: 10  Epoch: 28  Training loss = 2.0168  Validation loss = 4.4644  \n",
      "\n",
      "Fold: 10  Epoch: 29  Training loss = 2.0016  Validation loss = 4.4258  \n",
      "\n",
      "Fold: 10  Epoch: 30  Training loss = 2.0434  Validation loss = 4.5141  \n",
      "\n",
      "Fold: 10  Epoch: 31  Training loss = 2.0047  Validation loss = 4.4736  \n",
      "\n",
      "Fold: 10  Epoch: 32  Training loss = 1.9973  Validation loss = 4.3106  \n",
      "\n",
      "Fold: 10  Epoch: 33  Training loss = 1.9935  Validation loss = 4.3421  \n",
      "\n",
      "Fold: 10  Epoch: 34  Training loss = 1.9807  Validation loss = 4.4606  \n",
      "\n",
      "Fold: 10  Epoch: 35  Training loss = 2.0138  Validation loss = 4.5021  \n",
      "\n",
      "Fold: 10  Epoch: 36  Training loss = 1.9790  Validation loss = 4.2486  \n",
      "\n",
      "Fold: 10  Epoch: 37  Training loss = 1.9695  Validation loss = 4.1494  \n",
      "\n",
      "Fold: 10  Epoch: 38  Training loss = 1.9888  Validation loss = 4.2539  \n",
      "\n",
      "Fold: 10  Epoch: 39  Training loss = 1.9845  Validation loss = 4.0671  \n",
      "\n",
      "Fold: 10  Epoch: 40  Training loss = 1.9737  Validation loss = 4.2940  \n",
      "\n",
      "Fold: 10  Epoch: 41  Training loss = 1.9612  Validation loss = 4.1028  \n",
      "\n",
      "Fold: 10  Epoch: 42  Training loss = 1.9529  Validation loss = 4.2099  \n",
      "\n",
      "Fold: 10  Epoch: 43  Training loss = 1.9474  Validation loss = 4.1986  \n",
      "\n",
      "Fold: 10  Epoch: 44  Training loss = 1.9468  Validation loss = 3.9196  \n",
      "\n",
      "Fold: 10  Epoch: 45  Training loss = 1.9499  Validation loss = 3.7395  \n",
      "\n",
      "Fold: 10  Epoch: 46  Training loss = 1.9398  Validation loss = 3.7385  \n",
      "\n",
      "Fold: 10  Epoch: 47  Training loss = 1.9477  Validation loss = 3.7015  \n",
      "\n",
      "Fold: 10  Epoch: 48  Training loss = 1.9397  Validation loss = 3.6710  \n",
      "\n",
      "Fold: 10  Epoch: 49  Training loss = 1.9235  Validation loss = 3.6474  \n",
      "\n",
      "Fold: 10  Epoch: 50  Training loss = 1.9223  Validation loss = 3.6103  \n",
      "\n",
      "Fold: 10  Epoch: 51  Training loss = 1.9601  Validation loss = 3.7036  \n",
      "\n",
      "Fold: 10  Epoch: 52  Training loss = 1.9195  Validation loss = 3.7270  \n",
      "\n",
      "Fold: 10  Epoch: 53  Training loss = 1.9166  Validation loss = 3.7491  \n",
      "\n",
      "Fold: 10  Epoch: 54  Training loss = 1.9549  Validation loss = 3.7267  \n",
      "\n",
      "Fold: 10  Epoch: 55  Training loss = 1.9783  Validation loss = 3.7611  \n",
      "\n",
      "Check model:  Fold: 10  Epoch: 50  Training loss = 1.9783  Validation loss = 3.7611  \n",
      "\n",
      "Fold: 11  Epoch: 1  Training loss = 2.0170  Validation loss = 2.8994  \n",
      "\n",
      "Fold: 11  Epoch: 2  Training loss = 1.9437  Validation loss = 3.1127  \n",
      "\n",
      "Fold: 11  Epoch: 3  Training loss = 1.9069  Validation loss = 3.1536  \n",
      "\n",
      "Fold: 11  Epoch: 4  Training loss = 1.8790  Validation loss = 3.3141  \n",
      "\n",
      "Fold: 11  Epoch: 5  Training loss = 1.8931  Validation loss = 3.0681  \n",
      "\n",
      "Fold: 11  Epoch: 6  Training loss = 1.8612  Validation loss = 3.4330  \n",
      "\n",
      "Fold: 11  Epoch: 7  Training loss = 1.8369  Validation loss = 3.3128  \n",
      "\n",
      "Fold: 11  Epoch: 8  Training loss = 1.8179  Validation loss = 2.8319  \n",
      "\n",
      "Fold: 11  Epoch: 9  Training loss = 1.8255  Validation loss = 3.3901  \n",
      "\n",
      "Fold: 11  Epoch: 10  Training loss = 1.8151  Validation loss = 3.2220  \n",
      "\n",
      "Fold: 11  Epoch: 11  Training loss = 1.7976  Validation loss = 3.2351  \n",
      "\n",
      "Fold: 11  Epoch: 12  Training loss = 1.7943  Validation loss = 3.0215  \n",
      "\n",
      "Fold: 11  Epoch: 13  Training loss = 1.7893  Validation loss = 3.2497  \n",
      "\n",
      "Fold: 11  Epoch: 14  Training loss = 1.7915  Validation loss = 3.3246  \n",
      "\n",
      "Fold: 11  Epoch: 15  Training loss = 1.8189  Validation loss = 3.3112  \n",
      "\n",
      "Fold: 11  Epoch: 16  Training loss = 1.7526  Validation loss = 3.1227  \n",
      "\n",
      "Fold: 11  Epoch: 17  Training loss = 1.7448  Validation loss = 3.3521  \n",
      "\n",
      "Fold: 11  Epoch: 18  Training loss = 1.7440  Validation loss = 3.4690  \n",
      "\n",
      "Check model:  Fold: 11  Epoch: 8  Training loss = 1.7440  Validation loss = 3.4690  \n",
      "\n",
      "Fold: 12  Epoch: 1  Training loss = 1.9112  Validation loss = 1.8222  \n",
      "\n",
      "Fold: 12  Epoch: 2  Training loss = 2.1097  Validation loss = 1.3421  \n",
      "\n",
      "Fold: 12  Epoch: 3  Training loss = 2.0666  Validation loss = 0.8983  \n",
      "\n",
      "Fold: 12  Epoch: 4  Training loss = 2.0495  Validation loss = 0.9023  \n",
      "\n",
      "Fold: 12  Epoch: 5  Training loss = 2.0346  Validation loss = 0.9260  \n",
      "\n",
      "Fold: 12  Epoch: 6  Training loss = 2.0267  Validation loss = 0.9765  \n",
      "\n",
      "Fold: 12  Epoch: 7  Training loss = 2.0300  Validation loss = 1.1498  \n",
      "\n",
      "Fold: 12  Epoch: 8  Training loss = 2.0338  Validation loss = 1.0758  \n",
      "\n",
      "Fold: 12  Epoch: 9  Training loss = 2.0053  Validation loss = 1.0650  \n",
      "\n",
      "Fold: 12  Epoch: 10  Training loss = 1.9788  Validation loss = 0.8266  \n",
      "\n",
      "Fold: 12  Epoch: 11  Training loss = 1.9704  Validation loss = 0.9346  \n",
      "\n",
      "Fold: 12  Epoch: 12  Training loss = 1.9633  Validation loss = 0.7840  \n",
      "\n",
      "Fold: 12  Epoch: 13  Training loss = 1.9431  Validation loss = 0.7753  \n",
      "\n",
      "Fold: 12  Epoch: 14  Training loss = 1.9489  Validation loss = 0.7702  \n",
      "\n",
      "Fold: 12  Epoch: 15  Training loss = 1.9331  Validation loss = 0.7803  \n",
      "\n",
      "Fold: 12  Epoch: 16  Training loss = 2.0009  Validation loss = 1.1559  \n",
      "\n",
      "Check model:  Fold: 12  Epoch: 14  Training loss = 2.0009  Validation loss = 1.1559  \n",
      "\n",
      "Fold: 13  Epoch: 1  Training loss = 1.8983  Validation loss = 2.9540  \n",
      "\n",
      "Fold: 13  Epoch: 2  Training loss = 1.8713  Validation loss = 3.0821  \n",
      "\n",
      "Fold: 13  Epoch: 3  Training loss = 1.9195  Validation loss = 2.7922  \n",
      "\n",
      "Fold: 13  Epoch: 4  Training loss = 1.8565  Validation loss = 3.1427  \n",
      "\n",
      "Fold: 13  Epoch: 5  Training loss = 1.8493  Validation loss = 2.9293  \n",
      "\n",
      "Fold: 13  Epoch: 6  Training loss = 1.8454  Validation loss = 3.0699  \n",
      "\n",
      "Fold: 13  Epoch: 7  Training loss = 1.8490  Validation loss = 3.1618  \n",
      "\n",
      "Fold: 13  Epoch: 8  Training loss = 1.8388  Validation loss = 3.0267  \n",
      "\n",
      "Fold: 13  Epoch: 9  Training loss = 1.8139  Validation loss = 2.8001  \n",
      "\n",
      "Fold: 13  Epoch: 10  Training loss = 1.8183  Validation loss = 3.0929  \n",
      "\n",
      "Fold: 13  Epoch: 11  Training loss = 1.8489  Validation loss = 3.3225  \n",
      "\n",
      "Check model:  Fold: 13  Epoch: 3  Training loss = 1.8489  Validation loss = 3.3225  \n",
      "\n",
      "Fold: 14  Epoch: 1  Training loss = 1.9313  Validation loss = 5.9605  \n",
      "\n",
      "Fold: 14  Epoch: 2  Training loss = 1.9446  Validation loss = 5.7297  \n",
      "\n",
      "Fold: 14  Epoch: 3  Training loss = 1.9207  Validation loss = 5.7244  \n",
      "\n",
      "Fold: 14  Epoch: 4  Training loss = 1.8962  Validation loss = 5.8823  \n",
      "\n",
      "Fold: 14  Epoch: 5  Training loss = 1.8943  Validation loss = 5.9412  \n",
      "\n",
      "Fold: 14  Epoch: 6  Training loss = 1.9012  Validation loss = 5.5283  \n",
      "\n",
      "Fold: 14  Epoch: 7  Training loss = 1.8734  Validation loss = 5.7996  \n",
      "\n",
      "Fold: 14  Epoch: 8  Training loss = 1.8808  Validation loss = 6.0058  \n",
      "\n",
      "Fold: 14  Epoch: 9  Training loss = 1.8785  Validation loss = 5.5432  \n",
      "\n",
      "Fold: 14  Epoch: 10  Training loss = 1.8544  Validation loss = 5.6066  \n",
      "\n",
      "Fold: 14  Epoch: 11  Training loss = 1.8510  Validation loss = 5.5884  \n",
      "\n",
      "Fold: 14  Epoch: 12  Training loss = 1.8595  Validation loss = 6.1381  \n",
      "\n",
      "Check model:  Fold: 14  Epoch: 6  Training loss = 1.8595  Validation loss = 6.1381  \n",
      "\n",
      "Fold: 15  Epoch: 1  Training loss = 2.2690  Validation loss = 6.0694  \n",
      "\n",
      "Fold: 15  Epoch: 2  Training loss = 2.2621  Validation loss = 6.2216  \n",
      "\n",
      "Fold: 15  Epoch: 3  Training loss = 2.2643  Validation loss = 6.3818  \n",
      "\n",
      "Fold: 15  Epoch: 4  Training loss = 2.2513  Validation loss = 6.5468  \n",
      "\n",
      "Fold: 15  Epoch: 5  Training loss = 2.2148  Validation loss = 6.0403  \n",
      "\n",
      "Fold: 15  Epoch: 6  Training loss = 2.1831  Validation loss = 5.9983  \n",
      "\n",
      "Fold: 15  Epoch: 7  Training loss = 2.1649  Validation loss = 5.8660  \n",
      "\n",
      "Fold: 15  Epoch: 8  Training loss = 2.2041  Validation loss = 6.1689  \n",
      "\n",
      "Fold: 15  Epoch: 9  Training loss = 2.1778  Validation loss = 5.7621  \n",
      "\n",
      "Fold: 15  Epoch: 10  Training loss = 2.1547  Validation loss = 6.1754  \n",
      "\n",
      "Fold: 15  Epoch: 11  Training loss = 2.1390  Validation loss = 6.0049  \n",
      "\n",
      "Fold: 15  Epoch: 12  Training loss = 2.1793  Validation loss = 5.3231  \n",
      "\n",
      "Fold: 15  Epoch: 13  Training loss = 2.0958  Validation loss = 5.8877  \n",
      "\n",
      "Fold: 15  Epoch: 14  Training loss = 2.0962  Validation loss = 5.7555  \n",
      "\n",
      "Fold: 15  Epoch: 15  Training loss = 2.2059  Validation loss = 5.1976  \n",
      "\n",
      "Fold: 15  Epoch: 16  Training loss = 2.1765  Validation loss = 5.1050  \n",
      "\n",
      "Fold: 15  Epoch: 17  Training loss = 2.0925  Validation loss = 6.2435  \n",
      "\n",
      "Check model:  Fold: 15  Epoch: 16  Training loss = 2.0925  Validation loss = 6.2435  \n",
      "\n",
      "Fold: 16  Epoch: 1  Training loss = 2.4635  Validation loss = 5.2043  \n",
      "\n",
      "Fold: 16  Epoch: 2  Training loss = 2.4289  Validation loss = 5.2051  \n",
      "\n",
      "Fold: 16  Epoch: 3  Training loss = 2.3641  Validation loss = 5.0504  \n",
      "\n",
      "Fold: 16  Epoch: 4  Training loss = 2.3436  Validation loss = 5.2826  \n",
      "\n",
      "Fold: 16  Epoch: 5  Training loss = 2.4300  Validation loss = 3.4324  \n",
      "\n",
      "Fold: 16  Epoch: 6  Training loss = 2.3560  Validation loss = 4.1857  \n",
      "\n",
      "Fold: 16  Epoch: 7  Training loss = 2.3450  Validation loss = 4.2089  \n",
      "\n",
      "Fold: 16  Epoch: 8  Training loss = 2.3161  Validation loss = 4.7361  \n",
      "\n",
      "Fold: 16  Epoch: 9  Training loss = 2.3265  Validation loss = 5.0791  \n",
      "\n",
      "Fold: 16  Epoch: 10  Training loss = 2.4021  Validation loss = 4.9369  \n",
      "\n",
      "Fold: 16  Epoch: 11  Training loss = 2.2519  Validation loss = 3.9781  \n",
      "\n",
      "Fold: 16  Epoch: 12  Training loss = 2.2108  Validation loss = 4.1703  \n",
      "\n",
      "Fold: 16  Epoch: 13  Training loss = 2.1208  Validation loss = 4.3880  \n",
      "\n",
      "Fold: 16  Epoch: 14  Training loss = 2.1666  Validation loss = 3.5620  \n",
      "\n",
      "Fold: 16  Epoch: 15  Training loss = 2.0952  Validation loss = 4.2335  \n",
      "\n",
      "Fold: 16  Epoch: 16  Training loss = 2.1240  Validation loss = 4.1145  \n",
      "\n",
      "Fold: 16  Epoch: 17  Training loss = 2.1365  Validation loss = 3.9255  \n",
      "\n",
      "Fold: 16  Epoch: 18  Training loss = 2.0480  Validation loss = 4.2123  \n",
      "\n",
      "Fold: 16  Epoch: 19  Training loss = 2.2008  Validation loss = 4.0757  \n",
      "\n",
      "Fold: 16  Epoch: 20  Training loss = 2.0504  Validation loss = 4.7286  \n",
      "\n",
      "Check model:  Fold: 16  Epoch: 5  Training loss = 2.0504  Validation loss = 4.7286  \n",
      "\n",
      "Fold: 17  Epoch: 1  Training loss = 2.1864  Validation loss = 4.4869  \n",
      "\n",
      "Fold: 17  Epoch: 2  Training loss = 2.1271  Validation loss = 4.8499  \n",
      "\n",
      "Fold: 17  Epoch: 3  Training loss = 2.3054  Validation loss = 4.9747  \n",
      "\n",
      "Fold: 17  Epoch: 4  Training loss = 2.0897  Validation loss = 4.9623  \n",
      "\n",
      "Fold: 17  Epoch: 5  Training loss = 2.1598  Validation loss = 5.0555  \n",
      "\n",
      "Fold: 17  Epoch: 6  Training loss = 2.0955  Validation loss = 5.1516  \n",
      "\n",
      "Fold: 17  Epoch: 7  Training loss = 2.1151  Validation loss = 5.1412  \n",
      "\n",
      "Fold: 17  Epoch: 8  Training loss = 2.1085  Validation loss = 5.3528  \n",
      "\n",
      "Fold: 17  Epoch: 9  Training loss = 2.2072  Validation loss = 4.9393  \n",
      "\n",
      "Fold: 17  Epoch: 10  Training loss = 2.3896  Validation loss = 5.0074  \n",
      "\n",
      "Fold: 17  Epoch: 11  Training loss = 1.9669  Validation loss = 5.2646  \n",
      "\n",
      "Fold: 17  Epoch: 12  Training loss = 2.1492  Validation loss = 5.1816  \n",
      "\n",
      "Fold: 17  Epoch: 13  Training loss = 2.0282  Validation loss = 5.3633  \n",
      "\n",
      "Check model:  Fold: 17  Epoch: 1  Training loss = 2.0282  Validation loss = 5.3633  \n",
      "\n",
      "Fold: 18  Epoch: 1  Training loss = 2.3053  Validation loss = 3.8648  \n",
      "\n",
      "Fold: 18  Epoch: 2  Training loss = 2.1982  Validation loss = 3.0374  \n",
      "\n",
      "Fold: 18  Epoch: 3  Training loss = 2.1628  Validation loss = 3.0525  \n",
      "\n",
      "Fold: 18  Epoch: 4  Training loss = 2.0729  Validation loss = 2.2566  \n",
      "\n",
      "Fold: 18  Epoch: 5  Training loss = 2.0152  Validation loss = 2.1968  \n",
      "\n",
      "Fold: 18  Epoch: 6  Training loss = 2.0241  Validation loss = 2.1031  \n",
      "\n",
      "Fold: 18  Epoch: 7  Training loss = 1.9920  Validation loss = 2.0850  \n",
      "\n",
      "Fold: 18  Epoch: 8  Training loss = 2.0750  Validation loss = 2.0500  \n",
      "\n",
      "Fold: 18  Epoch: 9  Training loss = 2.0259  Validation loss = 2.0963  \n",
      "\n",
      "Fold: 18  Epoch: 10  Training loss = 1.9413  Validation loss = 1.9449  \n",
      "\n",
      "Fold: 18  Epoch: 11  Training loss = 1.9393  Validation loss = 1.9892  \n",
      "\n",
      "Fold: 18  Epoch: 12  Training loss = 2.1961  Validation loss = 1.9941  \n",
      "\n",
      "Fold: 18  Epoch: 13  Training loss = 1.8673  Validation loss = 1.9573  \n",
      "\n",
      "Fold: 18  Epoch: 14  Training loss = 1.9086  Validation loss = 1.9769  \n",
      "\n",
      "Fold: 18  Epoch: 15  Training loss = 2.1580  Validation loss = 1.9559  \n",
      "\n",
      "Fold: 18  Epoch: 16  Training loss = 1.8703  Validation loss = 2.0872  \n",
      "\n",
      "Fold: 18  Epoch: 17  Training loss = 2.0603  Validation loss = 2.0740  \n",
      "\n",
      "Fold: 18  Epoch: 18  Training loss = 1.8247  Validation loss = 1.9511  \n",
      "\n",
      "Fold: 18  Epoch: 19  Training loss = 1.8037  Validation loss = 1.8631  \n",
      "\n",
      "Fold: 18  Epoch: 20  Training loss = 2.0258  Validation loss = 1.9221  \n",
      "\n",
      "Fold: 18  Epoch: 21  Training loss = 1.9322  Validation loss = 1.9780  \n",
      "\n",
      "Fold: 18  Epoch: 22  Training loss = 1.8798  Validation loss = 2.0568  \n",
      "\n",
      "Fold: 18  Epoch: 23  Training loss = 1.7632  Validation loss = 2.0906  \n",
      "\n",
      "Check model:  Fold: 18  Epoch: 19  Training loss = 1.7632  Validation loss = 2.0906  \n",
      "\n",
      "Fold: 19  Epoch: 1  Training loss = 1.6912  Validation loss = 2.6186  \n",
      "\n",
      "Fold: 19  Epoch: 2  Training loss = 2.0428  Validation loss = 1.8897  \n",
      "\n",
      "Fold: 19  Epoch: 3  Training loss = 1.7456  Validation loss = 2.5252  \n",
      "\n",
      "Fold: 19  Epoch: 4  Training loss = 1.7053  Validation loss = 2.2599  \n",
      "\n",
      "Fold: 19  Epoch: 5  Training loss = 1.6583  Validation loss = 2.3907  \n",
      "\n",
      "Fold: 19  Epoch: 6  Training loss = 1.6237  Validation loss = 2.2826  \n",
      "\n",
      "Fold: 19  Epoch: 7  Training loss = 1.6053  Validation loss = 1.9958  \n",
      "\n",
      "Fold: 19  Epoch: 8  Training loss = 1.5680  Validation loss = 2.2355  \n",
      "\n",
      "Fold: 19  Epoch: 9  Training loss = 1.6044  Validation loss = 2.6386  \n",
      "\n",
      "Fold: 19  Epoch: 10  Training loss = 1.5404  Validation loss = 2.3894  \n",
      "\n",
      "Fold: 19  Epoch: 11  Training loss = 1.5567  Validation loss = 2.2050  \n",
      "\n",
      "Fold: 19  Epoch: 12  Training loss = 1.5238  Validation loss = 2.1408  \n",
      "\n",
      "Fold: 19  Epoch: 13  Training loss = 1.5931  Validation loss = 2.0887  \n",
      "\n",
      "Fold: 19  Epoch: 14  Training loss = 1.5237  Validation loss = 2.3935  \n",
      "\n",
      "Fold: 19  Epoch: 15  Training loss = 1.5291  Validation loss = 2.7405  \n",
      "\n",
      "Check model:  Fold: 19  Epoch: 2  Training loss = 1.5291  Validation loss = 2.7405  \n",
      "\n",
      "Fold: 20  Epoch: 1  Training loss = 1.5800  Validation loss = 3.1974  \n",
      "\n",
      "Fold: 20  Epoch: 2  Training loss = 1.6244  Validation loss = 3.4566  \n",
      "\n",
      "Fold: 20  Epoch: 3  Training loss = 1.6218  Validation loss = 2.8802  \n",
      "\n",
      "Fold: 20  Epoch: 4  Training loss = 1.5001  Validation loss = 3.0197  \n",
      "\n",
      "Fold: 20  Epoch: 5  Training loss = 1.6736  Validation loss = 3.2666  \n",
      "\n",
      "Fold: 20  Epoch: 6  Training loss = 1.4859  Validation loss = 2.9192  \n",
      "\n",
      "Fold: 20  Epoch: 7  Training loss = 1.4807  Validation loss = 3.2188  \n",
      "\n",
      "Fold: 20  Epoch: 8  Training loss = 1.5100  Validation loss = 2.7911  \n",
      "\n",
      "Fold: 20  Epoch: 9  Training loss = 1.5141  Validation loss = 2.8138  \n",
      "\n",
      "Fold: 20  Epoch: 10  Training loss = 1.4004  Validation loss = 3.0387  \n",
      "\n",
      "Fold: 20  Epoch: 11  Training loss = 1.4401  Validation loss = 3.1755  \n",
      "\n",
      "Fold: 20  Epoch: 12  Training loss = 1.3877  Validation loss = 2.9769  \n",
      "\n",
      "Fold: 20  Epoch: 13  Training loss = 1.4825  Validation loss = 2.6649  \n",
      "\n",
      "Fold: 20  Epoch: 14  Training loss = 1.4840  Validation loss = 2.6849  \n",
      "\n",
      "Fold: 20  Epoch: 15  Training loss = 1.3612  Validation loss = 3.0502  \n",
      "\n",
      "Fold: 20  Epoch: 16  Training loss = 1.4026  Validation loss = 3.3863  \n",
      "\n",
      "Check model:  Fold: 20  Epoch: 13  Training loss = 1.4026  Validation loss = 3.3863  \n",
      "\n",
      "Fold: 21  Epoch: 1  Training loss = 1.5427  Validation loss = 4.1002  \n",
      "\n",
      "Fold: 21  Epoch: 2  Training loss = 1.4988  Validation loss = 3.5996  \n",
      "\n",
      "Fold: 21  Epoch: 3  Training loss = 1.4497  Validation loss = 3.4524  \n",
      "\n",
      "Fold: 21  Epoch: 4  Training loss = 1.6650  Validation loss = 3.2834  \n",
      "\n",
      "Fold: 21  Epoch: 5  Training loss = 1.3699  Validation loss = 3.4319  \n",
      "\n",
      "Fold: 21  Epoch: 6  Training loss = 1.4037  Validation loss = 3.5278  \n",
      "\n",
      "Fold: 21  Epoch: 7  Training loss = 1.4512  Validation loss = 3.4990  \n",
      "\n",
      "Fold: 21  Epoch: 8  Training loss = 1.3491  Validation loss = 3.5278  \n",
      "\n",
      "Fold: 21  Epoch: 9  Training loss = 1.4047  Validation loss = 3.4370  \n",
      "\n",
      "Fold: 21  Epoch: 10  Training loss = 1.3369  Validation loss = 3.2375  \n",
      "\n",
      "Fold: 21  Epoch: 11  Training loss = 1.5533  Validation loss = 3.5410  \n",
      "\n",
      "Fold: 21  Epoch: 12  Training loss = 1.3007  Validation loss = 3.2947  \n",
      "\n",
      "Fold: 21  Epoch: 13  Training loss = 1.3555  Validation loss = 3.3678  \n",
      "\n",
      "Fold: 21  Epoch: 14  Training loss = 1.3317  Validation loss = 3.5138  \n",
      "\n",
      "Fold: 21  Epoch: 15  Training loss = 1.3517  Validation loss = 3.4598  \n",
      "\n",
      "Fold: 21  Epoch: 16  Training loss = 1.4552  Validation loss = 3.3473  \n",
      "\n",
      "Fold: 21  Epoch: 17  Training loss = 1.6695  Validation loss = 3.5692  \n",
      "\n",
      "Check model:  Fold: 21  Epoch: 10  Training loss = 1.6695  Validation loss = 3.5692  \n",
      "\n",
      "Fold: 22  Epoch: 1  Training loss = 1.4907  Validation loss = 1.0792  \n",
      "\n",
      "Fold: 22  Epoch: 2  Training loss = 1.4134  Validation loss = 1.4877  \n",
      "\n",
      "Fold: 22  Epoch: 3  Training loss = 1.4322  Validation loss = 1.4043  \n",
      "\n",
      "Fold: 22  Epoch: 4  Training loss = 1.4807  Validation loss = 1.6660  \n",
      "\n",
      "Fold: 22  Epoch: 5  Training loss = 1.4063  Validation loss = 1.1202  \n",
      "\n",
      "Fold: 22  Epoch: 6  Training loss = 1.4002  Validation loss = 0.9445  \n",
      "\n",
      "Fold: 22  Epoch: 7  Training loss = 1.3330  Validation loss = 0.8949  \n",
      "\n",
      "Fold: 22  Epoch: 8  Training loss = 1.3066  Validation loss = 0.7696  \n",
      "\n",
      "Fold: 22  Epoch: 9  Training loss = 1.3108  Validation loss = 0.8617  \n",
      "\n",
      "Fold: 22  Epoch: 10  Training loss = 1.3027  Validation loss = 0.6689  \n",
      "\n",
      "Fold: 22  Epoch: 11  Training loss = 1.4211  Validation loss = 0.5918  \n",
      "\n",
      "Fold: 22  Epoch: 12  Training loss = 1.2908  Validation loss = 0.8383  \n",
      "\n",
      "Fold: 22  Epoch: 13  Training loss = 1.2998  Validation loss = 0.6194  \n",
      "\n",
      "Fold: 22  Epoch: 14  Training loss = 1.3322  Validation loss = 0.8269  \n",
      "\n",
      "Fold: 22  Epoch: 15  Training loss = 1.3844  Validation loss = 0.5042  \n",
      "\n",
      "Fold: 22  Epoch: 16  Training loss = 1.2478  Validation loss = 0.9648  \n",
      "\n",
      "Check model:  Fold: 22  Epoch: 15  Training loss = 1.2478  Validation loss = 0.9648  \n",
      "\n",
      "Fold: 23  Epoch: 1  Training loss = 1.1754  Validation loss = 3.7333  \n",
      "\n",
      "Fold: 23  Epoch: 2  Training loss = 1.2210  Validation loss = 3.6912  \n",
      "\n",
      "Fold: 23  Epoch: 3  Training loss = 1.1975  Validation loss = 3.4826  \n",
      "\n",
      "Fold: 23  Epoch: 4  Training loss = 1.1765  Validation loss = 3.4442  \n",
      "\n",
      "Fold: 23  Epoch: 5  Training loss = 1.1825  Validation loss = 3.0790  \n",
      "\n",
      "Fold: 23  Epoch: 6  Training loss = 1.1596  Validation loss = 3.0249  \n",
      "\n",
      "Fold: 23  Epoch: 7  Training loss = 1.1637  Validation loss = 3.4089  \n",
      "\n",
      "Fold: 23  Epoch: 8  Training loss = 1.1369  Validation loss = 3.3466  \n",
      "\n",
      "Fold: 23  Epoch: 9  Training loss = 1.1399  Validation loss = 3.0439  \n",
      "\n",
      "Fold: 23  Epoch: 10  Training loss = 1.1365  Validation loss = 2.8675  \n",
      "\n",
      "Fold: 23  Epoch: 11  Training loss = 1.1214  Validation loss = 2.8693  \n",
      "\n",
      "Fold: 23  Epoch: 12  Training loss = 1.1400  Validation loss = 3.4861  \n",
      "\n",
      "Check model:  Fold: 23  Epoch: 10  Training loss = 1.1400  Validation loss = 3.4861  \n",
      "\n",
      "Fold: 24  Epoch: 1  Training loss = 1.3188  Validation loss = 1.7197  \n",
      "\n",
      "Fold: 24  Epoch: 2  Training loss = 1.4077  Validation loss = 1.9333  \n",
      "\n",
      "Fold: 24  Epoch: 3  Training loss = 1.3455  Validation loss = 1.7784  \n",
      "\n",
      "Fold: 24  Epoch: 4  Training loss = 1.3739  Validation loss = 1.7135  \n",
      "\n",
      "Fold: 24  Epoch: 5  Training loss = 1.2707  Validation loss = 1.7189  \n",
      "\n",
      "Fold: 24  Epoch: 6  Training loss = 1.5375  Validation loss = 1.9361  \n",
      "\n",
      "Fold: 24  Epoch: 7  Training loss = 1.3411  Validation loss = 1.9732  \n",
      "\n",
      "Fold: 24  Epoch: 8  Training loss = 1.2579  Validation loss = 2.0172  \n",
      "\n",
      "Fold: 24  Epoch: 9  Training loss = 1.5944  Validation loss = 2.0768  \n",
      "\n",
      "Fold: 24  Epoch: 10  Training loss = 1.4337  Validation loss = 1.9425  \n",
      "\n",
      "Fold: 24  Epoch: 11  Training loss = 1.6533  Validation loss = 2.2110  \n",
      "\n",
      "Check model:  Fold: 24  Epoch: 4  Training loss = 1.6533  Validation loss = 2.2110  \n",
      "\n",
      "Fold: 25  Epoch: 1  Training loss = 1.2400  Validation loss = 2.3985  \n",
      "\n",
      "Fold: 25  Epoch: 2  Training loss = 1.2222  Validation loss = 2.0932  \n",
      "\n",
      "Fold: 25  Epoch: 3  Training loss = 1.3471  Validation loss = 2.1999  \n",
      "\n",
      "Fold: 25  Epoch: 4  Training loss = 1.1574  Validation loss = 2.2680  \n",
      "\n",
      "Fold: 25  Epoch: 5  Training loss = 1.2870  Validation loss = 2.5151  \n",
      "\n",
      "Fold: 25  Epoch: 6  Training loss = 1.3911  Validation loss = 1.9477  \n",
      "\n",
      "Fold: 25  Epoch: 7  Training loss = 1.4142  Validation loss = 2.7254  \n",
      "\n",
      "Fold: 25  Epoch: 8  Training loss = 1.0640  Validation loss = 2.3050  \n",
      "\n",
      "Fold: 25  Epoch: 9  Training loss = 1.0985  Validation loss = 2.2492  \n",
      "\n",
      "Fold: 25  Epoch: 10  Training loss = 1.0510  Validation loss = 2.3316  \n",
      "\n",
      "Fold: 25  Epoch: 11  Training loss = 1.2757  Validation loss = 2.7419  \n",
      "\n",
      "Check model:  Fold: 25  Epoch: 6  Training loss = 1.2757  Validation loss = 2.7419  \n",
      "\n",
      "Fold: 26  Epoch: 1  Training loss = 1.1269  Validation loss = 3.7051  \n",
      "\n",
      "Fold: 26  Epoch: 2  Training loss = 1.0808  Validation loss = 3.8939  \n",
      "\n",
      "Fold: 26  Epoch: 3  Training loss = 1.2224  Validation loss = 4.2044  \n",
      "\n",
      "Fold: 26  Epoch: 4  Training loss = 1.2008  Validation loss = 4.0300  \n",
      "\n",
      "Fold: 26  Epoch: 5  Training loss = 1.2822  Validation loss = 4.9525  \n",
      "\n",
      "Fold: 26  Epoch: 6  Training loss = 1.1732  Validation loss = 4.0877  \n",
      "\n",
      "Fold: 26  Epoch: 7  Training loss = 1.0975  Validation loss = 3.9286  \n",
      "\n",
      "Fold: 26  Epoch: 8  Training loss = 1.0745  Validation loss = 4.1913  \n",
      "\n",
      "Fold: 26  Epoch: 9  Training loss = 1.0314  Validation loss = 3.8812  \n",
      "\n",
      "Fold: 26  Epoch: 10  Training loss = 1.0525  Validation loss = 3.4902  \n",
      "\n",
      "Fold: 26  Epoch: 11  Training loss = 1.0134  Validation loss = 3.5117  \n",
      "\n",
      "Fold: 26  Epoch: 12  Training loss = 1.0466  Validation loss = 3.6547  \n",
      "\n",
      "Fold: 26  Epoch: 13  Training loss = 1.1650  Validation loss = 2.9213  \n",
      "\n",
      "Fold: 26  Epoch: 14  Training loss = 0.9997  Validation loss = 3.3490  \n",
      "\n",
      "Fold: 26  Epoch: 15  Training loss = 1.2185  Validation loss = 5.0078  \n",
      "\n",
      "Check model:  Fold: 26  Epoch: 13  Training loss = 1.2185  Validation loss = 5.0078  \n",
      "\n",
      "Fold: 27  Epoch: 1  Training loss = 1.2281  Validation loss = 1.7483  \n",
      "\n",
      "Fold: 27  Epoch: 2  Training loss = 1.3997  Validation loss = 1.6125  \n",
      "\n",
      "Fold: 27  Epoch: 3  Training loss = 1.2635  Validation loss = 1.6664  \n",
      "\n",
      "Fold: 27  Epoch: 4  Training loss = 1.2052  Validation loss = 2.2239  \n",
      "\n",
      "Fold: 27  Epoch: 5  Training loss = 1.1012  Validation loss = 1.7803  \n",
      "\n",
      "Fold: 27  Epoch: 6  Training loss = 1.0906  Validation loss = 1.5818  \n",
      "\n",
      "Fold: 27  Epoch: 7  Training loss = 1.0251  Validation loss = 1.4437  \n",
      "\n",
      "Fold: 27  Epoch: 8  Training loss = 0.9996  Validation loss = 1.5643  \n",
      "\n",
      "Fold: 27  Epoch: 9  Training loss = 0.9767  Validation loss = 1.6353  \n",
      "\n",
      "Fold: 27  Epoch: 10  Training loss = 1.0198  Validation loss = 1.8642  \n",
      "\n",
      "Fold: 27  Epoch: 11  Training loss = 0.9903  Validation loss = 1.6453  \n",
      "\n",
      "Fold: 27  Epoch: 12  Training loss = 0.9661  Validation loss = 1.5607  \n",
      "\n",
      "Fold: 27  Epoch: 13  Training loss = 0.9641  Validation loss = 1.7015  \n",
      "\n",
      "Fold: 27  Epoch: 14  Training loss = 1.1138  Validation loss = 1.6008  \n",
      "\n",
      "Fold: 27  Epoch: 15  Training loss = 0.9247  Validation loss = 1.3669  \n",
      "\n",
      "Fold: 27  Epoch: 16  Training loss = 0.9187  Validation loss = 1.5832  \n",
      "\n",
      "Fold: 27  Epoch: 17  Training loss = 0.9023  Validation loss = 1.8284  \n",
      "\n",
      "Fold: 27  Epoch: 18  Training loss = 0.9179  Validation loss = 1.8175  \n",
      "\n",
      "Fold: 27  Epoch: 19  Training loss = 0.9885  Validation loss = 1.1688  \n",
      "\n",
      "Fold: 27  Epoch: 20  Training loss = 1.0315  Validation loss = 1.3479  \n",
      "\n",
      "Fold: 27  Epoch: 21  Training loss = 1.0843  Validation loss = 1.4765  \n",
      "\n",
      "Fold: 27  Epoch: 22  Training loss = 0.9410  Validation loss = 1.2956  \n",
      "\n",
      "Fold: 27  Epoch: 23  Training loss = 0.9709  Validation loss = 1.7828  \n",
      "\n",
      "Fold: 27  Epoch: 24  Training loss = 0.8858  Validation loss = 1.6961  \n",
      "\n",
      "Fold: 27  Epoch: 25  Training loss = 0.8716  Validation loss = 1.7806  \n",
      "\n",
      "Fold: 27  Epoch: 26  Training loss = 0.7747  Validation loss = 1.3887  \n",
      "\n",
      "Fold: 27  Epoch: 27  Training loss = 0.7969  Validation loss = 1.2791  \n",
      "\n",
      "Fold: 27  Epoch: 28  Training loss = 0.7671  Validation loss = 1.3932  \n",
      "\n",
      "Fold: 27  Epoch: 29  Training loss = 0.7977  Validation loss = 1.3129  \n",
      "\n",
      "Fold: 27  Epoch: 30  Training loss = 0.8423  Validation loss = 1.8143  \n",
      "\n",
      "Check model:  Fold: 27  Epoch: 19  Training loss = 0.8423  Validation loss = 1.8143  \n",
      "\n",
      "Fold: 28  Epoch: 1  Training loss = 0.9104  Validation loss = 1.7406  \n",
      "\n",
      "Fold: 28  Epoch: 2  Training loss = 0.7999  Validation loss = 2.0024  \n",
      "\n",
      "Fold: 28  Epoch: 3  Training loss = 0.8382  Validation loss = 1.8939  \n",
      "\n",
      "Fold: 28  Epoch: 4  Training loss = 0.7726  Validation loss = 1.8891  \n",
      "\n",
      "Fold: 28  Epoch: 5  Training loss = 0.7669  Validation loss = 2.0168  \n",
      "\n",
      "Fold: 28  Epoch: 6  Training loss = 0.8298  Validation loss = 1.9012  \n",
      "\n",
      "Fold: 28  Epoch: 7  Training loss = 0.8788  Validation loss = 1.6329  \n",
      "\n",
      "Fold: 28  Epoch: 8  Training loss = 0.8020  Validation loss = 1.6694  \n",
      "\n",
      "Fold: 28  Epoch: 9  Training loss = 0.7628  Validation loss = 1.7356  \n",
      "\n",
      "Fold: 28  Epoch: 10  Training loss = 0.7345  Validation loss = 1.7044  \n",
      "\n",
      "Fold: 28  Epoch: 11  Training loss = 0.7431  Validation loss = 1.7868  \n",
      "\n",
      "Fold: 28  Epoch: 12  Training loss = 0.7825  Validation loss = 1.6069  \n",
      "\n",
      "Fold: 28  Epoch: 13  Training loss = 0.7427  Validation loss = 1.6651  \n",
      "\n",
      "Fold: 28  Epoch: 14  Training loss = 0.8337  Validation loss = 1.4560  \n",
      "\n",
      "Fold: 28  Epoch: 15  Training loss = 0.7651  Validation loss = 1.7570  \n",
      "\n",
      "Fold: 28  Epoch: 16  Training loss = 0.7406  Validation loss = 1.7509  \n",
      "\n",
      "Fold: 28  Epoch: 17  Training loss = 0.7245  Validation loss = 1.5809  \n",
      "\n",
      "Fold: 28  Epoch: 18  Training loss = 0.7300  Validation loss = 1.6593  \n",
      "\n",
      "Fold: 28  Epoch: 19  Training loss = 0.8425  Validation loss = 1.4915  \n",
      "\n",
      "Fold: 28  Epoch: 20  Training loss = 0.7009  Validation loss = 1.6495  \n",
      "\n",
      "Fold: 28  Epoch: 21  Training loss = 0.7369  Validation loss = 1.6495  \n",
      "\n",
      "Fold: 28  Epoch: 22  Training loss = 0.6803  Validation loss = 1.5894  \n",
      "\n",
      "Fold: 28  Epoch: 23  Training loss = 0.7169  Validation loss = 1.5330  \n",
      "\n",
      "Fold: 28  Epoch: 24  Training loss = 0.7445  Validation loss = 1.4555  \n",
      "\n",
      "Fold: 28  Epoch: 25  Training loss = 0.7147  Validation loss = 1.6235  \n",
      "\n",
      "Fold: 28  Epoch: 26  Training loss = 0.7045  Validation loss = 1.7380  \n",
      "\n",
      "Check model:  Fold: 28  Epoch: 24  Training loss = 0.7045  Validation loss = 1.7380  \n",
      "\n",
      "Fold: 29  Epoch: 1  Training loss = 0.7859  Validation loss = 1.5754  \n",
      "\n",
      "Fold: 29  Epoch: 2  Training loss = 0.8015  Validation loss = 1.6022  \n",
      "\n",
      "Fold: 29  Epoch: 3  Training loss = 0.7507  Validation loss = 1.6522  \n",
      "\n",
      "Fold: 29  Epoch: 4  Training loss = 0.7459  Validation loss = 1.6374  \n",
      "\n",
      "Fold: 29  Epoch: 5  Training loss = 0.7889  Validation loss = 1.8436  \n",
      "\n",
      "Fold: 29  Epoch: 6  Training loss = 0.7741  Validation loss = 1.6509  \n",
      "\n",
      "Fold: 29  Epoch: 7  Training loss = 0.7148  Validation loss = 1.5800  \n",
      "\n",
      "Fold: 29  Epoch: 8  Training loss = 0.7428  Validation loss = 1.3813  \n",
      "\n",
      "Fold: 29  Epoch: 9  Training loss = 0.7037  Validation loss = 1.4440  \n",
      "\n",
      "Fold: 29  Epoch: 10  Training loss = 0.7108  Validation loss = 1.5135  \n",
      "\n",
      "Fold: 29  Epoch: 11  Training loss = 0.6942  Validation loss = 1.6213  \n",
      "\n",
      "Fold: 29  Epoch: 12  Training loss = 0.6969  Validation loss = 1.7457  \n",
      "\n",
      "Fold: 29  Epoch: 13  Training loss = 0.6691  Validation loss = 1.8263  \n",
      "\n",
      "Fold: 29  Epoch: 14  Training loss = 0.6664  Validation loss = 1.7274  \n",
      "\n",
      "Fold: 29  Epoch: 15  Training loss = 0.8133  Validation loss = 1.6376  \n",
      "\n",
      "Fold: 29  Epoch: 16  Training loss = 0.6562  Validation loss = 1.5298  \n",
      "\n",
      "Fold: 29  Epoch: 17  Training loss = 0.7002  Validation loss = 1.7704  \n",
      "\n",
      "Fold: 29  Epoch: 18  Training loss = 0.6808  Validation loss = 1.5687  \n",
      "\n",
      "Fold: 29  Epoch: 19  Training loss = 0.6363  Validation loss = 1.6243  \n",
      "\n",
      "Fold: 29  Epoch: 20  Training loss = 0.7467  Validation loss = 1.6413  \n",
      "\n",
      "Fold: 29  Epoch: 21  Training loss = 0.6674  Validation loss = 1.5923  \n",
      "\n",
      "Fold: 29  Epoch: 22  Training loss = 0.6348  Validation loss = 1.5081  \n",
      "\n",
      "Fold: 29  Epoch: 23  Training loss = 0.6108  Validation loss = 1.6621  \n",
      "\n",
      "Fold: 29  Epoch: 24  Training loss = 0.6681  Validation loss = 1.7355  \n",
      "\n",
      "Fold: 29  Epoch: 25  Training loss = 0.6435  Validation loss = 1.6256  \n",
      "\n",
      "Fold: 29  Epoch: 26  Training loss = 0.6266  Validation loss = 1.7881  \n",
      "\n",
      "Check model:  Fold: 29  Epoch: 8  Training loss = 0.6266  Validation loss = 1.7881  \n",
      "\n",
      "Fold: 30  Epoch: 1  Training loss = 0.8850  Validation loss = 1.0033  \n",
      "\n",
      "Fold: 30  Epoch: 2  Training loss = 0.6845  Validation loss = 1.2341  \n",
      "\n",
      "Fold: 30  Epoch: 3  Training loss = 0.6886  Validation loss = 1.2633  \n",
      "\n",
      "Fold: 30  Epoch: 4  Training loss = 0.6793  Validation loss = 1.1391  \n",
      "\n",
      "Fold: 30  Epoch: 5  Training loss = 0.6856  Validation loss = 1.0260  \n",
      "\n",
      "Fold: 30  Epoch: 6  Training loss = 0.6618  Validation loss = 1.1663  \n",
      "\n",
      "Fold: 30  Epoch: 7  Training loss = 0.7524  Validation loss = 1.2982  \n",
      "\n",
      "Fold: 30  Epoch: 8  Training loss = 0.6769  Validation loss = 1.1853  \n",
      "\n",
      "Fold: 30  Epoch: 9  Training loss = 0.6880  Validation loss = 1.0933  \n",
      "\n",
      "Fold: 30  Epoch: 10  Training loss = 0.7028  Validation loss = 1.0884  \n",
      "\n",
      "Fold: 30  Epoch: 11  Training loss = 0.6786  Validation loss = 1.1135  \n",
      "\n",
      "Fold: 30  Epoch: 12  Training loss = 0.7505  Validation loss = 0.9648  \n",
      "\n",
      "Fold: 30  Epoch: 13  Training loss = 0.7036  Validation loss = 0.9880  \n",
      "\n",
      "Fold: 30  Epoch: 14  Training loss = 0.7386  Validation loss = 1.1809  \n",
      "\n",
      "Fold: 30  Epoch: 15  Training loss = 0.6397  Validation loss = 1.1494  \n",
      "\n",
      "Fold: 30  Epoch: 16  Training loss = 0.6369  Validation loss = 1.1381  \n",
      "\n",
      "Fold: 30  Epoch: 17  Training loss = 0.7621  Validation loss = 1.1968  \n",
      "\n",
      "Check model:  Fold: 30  Epoch: 12  Training loss = 0.7621  Validation loss = 1.1968  \n",
      "\n",
      "Fold: 31  Epoch: 1  Training loss = 0.6742  Validation loss = 0.2731  \n",
      "\n",
      "Fold: 31  Epoch: 2  Training loss = 0.7542  Validation loss = 0.8337  \n",
      "\n",
      "Fold: 31  Epoch: 3  Training loss = 0.6956  Validation loss = 0.4795  \n",
      "\n",
      "Fold: 31  Epoch: 4  Training loss = 0.7417  Validation loss = 0.4458  \n",
      "\n",
      "Fold: 31  Epoch: 5  Training loss = 0.6405  Validation loss = 0.4292  \n",
      "\n",
      "Fold: 31  Epoch: 6  Training loss = 0.6543  Validation loss = 0.3988  \n",
      "\n",
      "Fold: 31  Epoch: 7  Training loss = 0.6531  Validation loss = 0.8327  \n",
      "\n",
      "Fold: 31  Epoch: 8  Training loss = 0.6612  Validation loss = 0.4059  \n",
      "\n",
      "Fold: 31  Epoch: 9  Training loss = 0.6636  Validation loss = 0.8764  \n",
      "\n",
      "Fold: 31  Epoch: 10  Training loss = 0.6137  Validation loss = 0.5171  \n",
      "\n",
      "Fold: 31  Epoch: 11  Training loss = 0.6522  Validation loss = 0.4543  \n",
      "\n",
      "Fold: 31  Epoch: 12  Training loss = 0.6739  Validation loss = 0.9070  \n",
      "\n",
      "Check model:  Fold: 31  Epoch: 1  Training loss = 0.6739  Validation loss = 0.9070  \n",
      "\n",
      "Fold: 32  Epoch: 1  Training loss = 0.6230  Validation loss = 1.9697  \n",
      "\n",
      "Fold: 32  Epoch: 2  Training loss = 0.7915  Validation loss = 3.4920  \n",
      "\n",
      "Fold: 32  Epoch: 3  Training loss = 0.7278  Validation loss = 2.0625  \n",
      "\n",
      "Fold: 32  Epoch: 4  Training loss = 0.6163  Validation loss = 1.8537  \n",
      "\n",
      "Fold: 32  Epoch: 5  Training loss = 0.7795  Validation loss = 2.4622  \n",
      "\n",
      "Fold: 32  Epoch: 6  Training loss = 0.6219  Validation loss = 1.7609  \n",
      "\n",
      "Fold: 32  Epoch: 7  Training loss = 0.6364  Validation loss = 1.7506  \n",
      "\n",
      "Fold: 32  Epoch: 8  Training loss = 0.6659  Validation loss = 1.7918  \n",
      "\n",
      "Fold: 32  Epoch: 9  Training loss = 0.6026  Validation loss = 1.9777  \n",
      "\n",
      "Fold: 32  Epoch: 10  Training loss = 0.6247  Validation loss = 2.0597  \n",
      "\n",
      "Fold: 32  Epoch: 11  Training loss = 0.6336  Validation loss = 1.8292  \n",
      "\n",
      "Fold: 32  Epoch: 12  Training loss = 0.6049  Validation loss = 2.0190  \n",
      "\n",
      "Fold: 32  Epoch: 13  Training loss = 0.5830  Validation loss = 1.9647  \n",
      "\n",
      "Fold: 32  Epoch: 14  Training loss = 0.6243  Validation loss = 1.7818  \n",
      "\n",
      "Fold: 32  Epoch: 15  Training loss = 0.5771  Validation loss = 1.8834  \n",
      "\n",
      "Fold: 32  Epoch: 16  Training loss = 0.6643  Validation loss = 1.6702  \n",
      "\n",
      "Fold: 32  Epoch: 17  Training loss = 0.5733  Validation loss = 1.9931  \n",
      "\n",
      "Fold: 32  Epoch: 18  Training loss = 0.5719  Validation loss = 2.1059  \n",
      "\n",
      "Check model:  Fold: 32  Epoch: 16  Training loss = 0.5719  Validation loss = 2.1059  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 2. Train model\n",
    "# ==================================\n",
    "sess = tf.InteractiveSession()  # Launch Graph\n",
    "sess.run(tf.global_variables_initializer())  # Initialise all variables\n",
    "\n",
    "print(\"Start training\", \n",
    "      \"\\nHyperparameters:\",\n",
    "      \"\\nDimension of recurrent unit =\", n_hidden,\n",
    "      \"\\nLearning rate =\", learning_rate,\n",
    "      \"\\nEpochs =\", epochs,\n",
    "      \"\\nBatch size =\", batch_size,\n",
    "      \"\\nEarly stopping epochs =\", early_stop_iters,\n",
    "      \"\\nLearning rate =\", learning_rate)\n",
    "\n",
    "total_batch = int(window_length / batch_size)\n",
    "validation_fold_error = [] # store validation error of each fold\n",
    "optimal_epochs = []\n",
    "\n",
    "# loop through folds\n",
    "for fold in range(1, len(valIndex)):\n",
    "    validx = train_features[valIndex[fold-1]:valIndex[fold]]\n",
    "    validy = train_target[valIndex[fold-1]:valIndex[fold]]\n",
    "    trainx = train_features[(fold-1)*4:valIndex[(fold-1)]]\n",
    "    trainy = train_target[(fold-1)*4:valIndex[(fold-1)]]\n",
    "\n",
    "    loss_list = [] # store validation loss after each epoch for early stopping\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i in range(total_batch):\n",
    "            # Backprop\n",
    "            batch_xs, batch_ys = next_batch(num=batch_size, data=trainx, labels=trainy)\n",
    "            optimizer.run(feed_dict={x:batch_xs, y:batch_ys, lr:learning_rate})\n",
    "\n",
    "        # Loss\n",
    "        loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "        loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "        loss_list.append(loss_valid)\n",
    "\n",
    "        print(\"Fold: {0:d}\".format(fold),\n",
    "              \" Epoch: {0:d}\".format(epoch+1),\n",
    "              \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "              \" Validation loss = {0:.4f}\".format(np.sqrt(loss_valid)),\n",
    "              \" \\n\")\n",
    "\n",
    "        if all(j <= loss_valid for j in loss_list[-early_stop_iters:]) and len(loss_list)>early_stop_iters:\n",
    "            break\n",
    "    \n",
    "    # Load model with lowest validation error for each fold\n",
    "    epoch_hat = np.argmin(loss_list) + 1\n",
    "    optimal_epochs.append(epoch_hat) # store optimal number of epochs for each fold\n",
    "    \n",
    "    # RMSE\n",
    "    loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "    loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "    validation_fold_error.append(np.sqrt(loss_valid))\n",
    "    \n",
    "    print(\"Check model:\",\n",
    "          \" Fold: {0:d}\".format(fold),\n",
    "          \" Epoch: {0:d}\".format(epoch_hat),\n",
    "          \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "          \" Validation loss = {0:.4f}\".format(np.sqrt(loss_valid)),\n",
    "          \" \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average number of epochs: 13\n",
      "Average validation error: 3.17287\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 3. Optimal epoch choice\n",
    "# ==================================\n",
    "# Pick number of epochs to train model for out-of-sample testing\n",
    "epoch_hat = int(np.mean(optimal_epochs))\n",
    "print(\"\\nAverage number of epochs:\", epoch_hat)\n",
    "# Average validation error\n",
    "print(\"Average validation error:\", np.mean(validation_fold_error))\n",
    "\n",
    "# Save validated model\n",
    "saveModel(sess, \n",
    "          MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + str(epoch_hat) + \"_validated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fixed scheme:\n",
      "Epoch: 1  Training loss = 0.7001  Test loss = 3.5030  \n",
      "\n",
      "Epoch: 2  Training loss = 0.6894  Test loss = 3.4652  \n",
      "\n",
      "Epoch: 3  Training loss = 0.6841  Test loss = 3.4473  \n",
      "\n",
      "Epoch: 4  Training loss = 0.6802  Test loss = 3.4390  \n",
      "\n",
      "Epoch: 5  Training loss = 0.6767  Test loss = 3.4349  \n",
      "\n",
      "Epoch: 6  Training loss = 0.6733  Test loss = 3.4326  \n",
      "\n",
      "Epoch: 7  Training loss = 0.6701  Test loss = 3.4310  \n",
      "\n",
      "Epoch: 8  Training loss = 0.6670  Test loss = 3.4297  \n",
      "\n",
      "Epoch: 9  Training loss = 0.6640  Test loss = 3.4284  \n",
      "\n",
      "Epoch: 10  Training loss = 0.6611  Test loss = 3.4272  \n",
      "\n",
      "Epoch: 11  Training loss = 0.6583  Test loss = 3.4259  \n",
      "\n",
      "Epoch: 12  Training loss = 0.6557  Test loss = 3.4246  \n",
      "\n",
      "Epoch: 13  Training loss = 0.6531  Test loss = 3.4232  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 4. Fixed scheme\n",
    "# ==================================\n",
    "print(\"\\nFixed scheme:\")\n",
    "for epoch in range(epoch_hat):\n",
    "    x_train = train_features[-window_length:]\n",
    "    y_train = train_target[-window_length:]\n",
    "    optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:test_features, y:test_target})\n",
    "    print(\"Epoch: {0:d}\".format(epoch+1),\n",
    "          \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "          \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "          \" \\n\")\n",
    "\n",
    "# Forecasts\n",
    "yhat_test_fixed = pred.eval(feed_dict={x:test_features})\n",
    "yhat_train_fixed = pred.eval(feed_dict={x:x_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n3cwsM/8HIVqwDo0Aq8sAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f17034300d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train set\n",
    "plt.plot(y_train, 'black')\n",
    "plt.plot(yhat_train_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzMwaygVgZtZQLgAzs4ZyAZiZNdR/AQIMiSSmH/5lAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f17005e83d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: fixed scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_test_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed scheme RMSE: 3.42320380207 \n",
      "Fixed scheme MAE:  2.27100635993\n"
     ]
    }
   ],
   "source": [
    "rmse_fixed = np.sqrt(np.mean((yhat_test_fixed[:,0]-test_target)**2))\n",
    "mae_fixed = np.mean(np.abs((yhat_test_fixed[:,0]-test_target)))\n",
    "print(\"Fixed scheme RMSE:\", rmse_fixed,\n",
    "     \"\\nFixed scheme MAE: \", mae_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Stack training and test set, this makes updating scheme easier to train\n",
    "all_features = np.concatenate((train_features[-window_length:], test_features), axis=0)\n",
    "all_target = np.concatenate((train_target[-window_length:], test_target), axis=0)\n",
    "\n",
    "# Vectors to store loss and forecasts\n",
    "test_loss = np.zeros(len(test_target))\n",
    "yhat_update = np.zeros(len(test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test period = 1  Training loss = 0.6531  Test loss = 2.5268  Model updated 0 times  \n",
      "\n",
      "Test period = 2  Training loss = 0.7239  Test loss = 3.5734  Model updated 0 times  \n",
      "\n",
      "Test period = 3  Training loss = 0.8483  Test loss = 2.2157  Model updated 0 times  \n",
      "\n",
      "Test period = 4  Training loss = 0.8913  Test loss = 0.6311  Model updated 0 times  \n",
      "\n",
      "Test period = 5  Training loss = 0.6169  Test loss = 1.5647  Model updated 1 times  \n",
      "\n",
      "Test period = 6  Training loss = 0.6456  Test loss = 0.7411  Model updated 1 times  \n",
      "\n",
      "Test period = 7  Training loss = 0.6517  Test loss = 1.6847  Model updated 1 times  \n",
      "\n",
      "Test period = 8  Training loss = 0.6843  Test loss = 0.9711  Model updated 1 times  \n",
      "\n",
      "Test period = 9  Training loss = 0.6142  Test loss = 1.7141  Model updated 2 times  \n",
      "\n",
      "Test period = 10  Training loss = 0.6500  Test loss = 1.2646  Model updated 2 times  \n",
      "\n",
      "Test period = 11  Training loss = 0.6684  Test loss = 1.1029  Model updated 2 times  \n",
      "\n",
      "Test period = 12  Training loss = 0.6823  Test loss = 4.4883  Model updated 2 times  \n",
      "\n",
      "Test period = 13  Training loss = 0.8025  Test loss = 3.2900  Model updated 3 times  \n",
      "\n",
      "Test period = 14  Training loss = 0.8999  Test loss = 4.6973  Model updated 3 times  \n",
      "\n",
      "Test period = 15  Training loss = 1.0720  Test loss = 6.7042  Model updated 3 times  \n",
      "\n",
      "Test period = 16  Training loss = 1.3567  Test loss = 7.2777  Model updated 3 times  \n",
      "\n",
      "Test period = 17  Training loss = 0.9652  Test loss = 0.5042  Model updated 4 times  \n",
      "\n",
      "Test period = 18  Training loss = 0.9668  Test loss = 0.2375  Model updated 4 times  \n",
      "\n",
      "Test period = 19  Training loss = 0.9655  Test loss = 0.6439  Model updated 4 times  \n",
      "\n",
      "Test period = 20  Training loss = 0.9448  Test loss = 0.2615  Model updated 4 times  \n",
      "\n",
      "Test period = 21  Training loss = 0.6673  Test loss = 1.6563  Model updated 5 times  \n",
      "\n",
      "Test period = 22  Training loss = 0.6980  Test loss = 3.1289  Model updated 5 times  \n",
      "\n",
      "Test period = 23  Training loss = 0.7943  Test loss = 0.9993  Model updated 5 times  \n",
      "\n",
      "Test period = 24  Training loss = 0.8034  Test loss = 0.9369  Model updated 5 times  \n",
      "\n",
      "Test period = 25  Training loss = 0.6556  Test loss = 0.0270  Model updated 6 times  \n",
      "\n",
      "Test period = 26  Training loss = 0.6501  Test loss = 0.1969  Model updated 6 times  \n",
      "\n",
      "Test period = 27  Training loss = 0.6503  Test loss = 2.5471  Model updated 6 times  \n",
      "\n",
      "Test period = 28  Training loss = 0.7187  Test loss = 2.1869  Model updated 6 times  \n",
      "\n",
      "Test period = 29  Training loss = 0.6700  Test loss = 0.1795  Model updated 7 times  \n",
      "\n",
      "Test period = 30  Training loss = 0.6691  Test loss = 0.1373  Model updated 7 times  \n",
      "\n",
      "Test period = 31  Training loss = 0.6689  Test loss = 4.7108  Model updated 7 times  \n",
      "\n",
      "Test period = 32  Training loss = 0.8833  Test loss = 2.5355  Model updated 7 times  \n",
      "\n",
      "Test period = 33  Training loss = 0.6712  Test loss = 0.9209  Model updated 8 times  \n",
      "\n",
      "Test period = 34  Training loss = 0.6808  Test loss = 0.4818  Model updated 8 times  \n",
      "\n",
      "Test period = 35  Training loss = 0.6818  Test loss = 1.1445  Model updated 8 times  \n",
      "\n",
      "Test period = 36  Training loss = 0.6963  Test loss = 2.7544  Model updated 8 times  \n",
      "\n",
      "Test period = 37  Training loss = 0.6868  Test loss = 1.8714  Model updated 9 times  \n",
      "\n",
      "Test period = 38  Training loss = 0.6835  Test loss = 1.1990  Model updated 9 times  \n",
      "\n",
      "Test period = 39  Training loss = 0.6992  Test loss = 0.4342  Model updated 9 times  \n",
      "\n",
      "Test period = 40  Training loss = 0.7008  Test loss = 4.5976  Model updated 9 times  \n",
      "\n",
      "Test period = 41  Training loss = 0.8551  Test loss = 1.3623  Model updated 10 times  \n",
      "\n",
      "Test period = 42  Training loss = 0.8700  Test loss = 1.4135  Model updated 10 times  \n",
      "\n",
      "Test period = 43  Training loss = 0.8874  Test loss = 3.6495  Model updated 10 times  \n",
      "\n",
      "Test period = 44  Training loss = 0.9929  Test loss = 14.3817  Model updated 10 times  \n",
      "\n",
      "Test period = 45  Training loss = 1.9802  Test loss = 6.2919  Model updated 11 times  \n",
      "\n",
      "Test period = 46  Training loss = 2.1279  Test loss = 1.1291  Model updated 11 times  \n",
      "\n",
      "Test period = 47  Training loss = 2.1319  Test loss = 0.3137  Model updated 11 times  \n",
      "\n",
      "Test period = 48  Training loss = 2.1317  Test loss = 0.1687  Model updated 11 times  \n",
      "\n",
      "Test period = 49  Training loss = 1.4688  Test loss = 0.9622  Model updated 12 times  \n",
      "\n",
      "Test period = 50  Training loss = 1.4735  Test loss = 3.1888  Model updated 12 times  \n",
      "\n",
      "Test period = 51  Training loss = 1.5251  Test loss = 2.5391  Model updated 12 times  \n",
      "\n",
      "Test period = 52  Training loss = 1.5573  Test loss = 1.1233  Model updated 12 times  \n",
      "\n",
      "Test period = 53  Training loss = 1.3724  Test loss = 0.7583  Model updated 13 times  \n",
      "\n",
      "Test period = 54  Training loss = 1.3706  Test loss = 1.9063  Model updated 13 times  \n",
      "\n",
      "Test period = 55  Training loss = 1.3908  Test loss = 0.2373  Model updated 13 times  \n",
      "\n",
      "Test period = 56  Training loss = 1.3911  Test loss = 0.8336  Model updated 13 times  \n",
      "\n",
      "Test period = 57  Training loss = 1.2498  Test loss = 0.8968  Model updated 14 times  \n",
      "\n",
      "Test period = 58  Training loss = 1.2546  Test loss = 1.3369  Model updated 14 times  \n",
      "\n",
      "Test period = 59  Training loss = 1.2633  Test loss = 2.9456  Model updated 14 times  \n",
      "\n",
      "Test period = 60  Training loss = 1.3147  Test loss = 2.6059  Model updated 14 times  \n",
      "\n",
      "Test period = 61  Training loss = 1.2551  Test loss = 2.0532  Model updated 15 times  \n",
      "\n",
      "Test period = 62  Training loss = 1.2793  Test loss = 3.7828  Model updated 15 times  \n",
      "\n",
      "Test period = 63  Training loss = 1.3599  Test loss = 1.3486  Model updated 15 times  \n",
      "\n",
      "Test period = 64  Training loss = 1.3701  Test loss = 1.2352  Model updated 15 times  \n",
      "\n",
      "Test period = 65  Training loss = 1.2039  Test loss = 0.4591  Model updated 16 times  \n",
      "\n",
      "Test period = 66  Training loss = 1.1962  Test loss = 0.0314  Model updated 16 times  \n",
      "\n",
      "Test period = 67  Training loss = 1.1913  Test loss = 1.4702  Model updated 16 times  \n",
      "\n",
      "Test period = 68  Training loss = 1.2052  Test loss = 2.0290  Model updated 16 times  \n",
      "\n",
      "Test period = 69  Training loss = 1.1474  Test loss = 4.6970  Model updated 17 times  \n",
      "\n",
      "Test period = 70  Training loss = 1.2866  Test loss = 0.6635  Model updated 17 times  \n",
      "\n",
      "Test period = 71  Training loss = 1.2874  Test loss = 0.6978  Model updated 17 times  \n",
      "\n",
      "Test period = 72  Training loss = 1.2902  Test loss = 1.6085  Model updated 17 times  \n",
      "\n",
      "Test period = 73  Training loss = 1.1485  Test loss = 1.9633  Model updated 18 times  \n",
      "\n",
      "Test period = 74  Training loss = 1.1740  Test loss = 1.6978  Model updated 18 times  \n",
      "\n",
      "Test period = 75  Training loss = 1.1912  Test loss = 1.6621  Model updated 18 times  \n",
      "\n",
      "Test period = 76  Training loss = 1.2022  Test loss = 0.4783  Model updated 18 times  \n",
      "\n",
      "Test period = 77  Training loss = 1.0900  Test loss = 1.2092  Model updated 19 times  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "retrain_count = 0\n",
    "for t in range(len(test_target)):\n",
    "    x_test = np.reshape(test_features[t], newshape=(1,4,3))\n",
    "    y_test = test_target[t]\n",
    "    test_loss[t] = np.sqrt(sess.run(loss, feed_dict={x:x_test, y:y_test}))\n",
    "    yhat_update[t] = pred.eval(feed_dict={x:x_test})\n",
    "\n",
    "    x_train = all_features[t:(window_length+t)]\n",
    "    y_train = all_target[t:(window_length+t)]\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:x_test, y:y_test})\n",
    "    \n",
    "    print(\"Test period = {0:d}\".format(t+1),\n",
    "      \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "      \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "      \" Model updated {0:d} times\".format(retrain_count),\n",
    "      \" \\n\")\n",
    "\n",
    "    if (t+1)%4==0:\n",
    "        retrain_count += 1\n",
    "        for epoch in range(epoch_hat):\n",
    "            for i in range(total_batch):\n",
    "                optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1qf+C/cYcdJqrMmIAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f17005a3a50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: updating scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_update, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating scheme RMSE: 2.90836453291 \n",
      "Updating scheme MAE:  1.99834568653\n"
     ]
    }
   ],
   "source": [
    "rmse_update = np.sqrt(np.mean((yhat_update-test_target)**2))\n",
    "mae_update = np.mean(np.abs((yhat_update-test_target)))\n",
    "print(\"Updating scheme RMSE:\", rmse_update,\n",
    "     \"\\nUpdating scheme MAE: \", mae_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
