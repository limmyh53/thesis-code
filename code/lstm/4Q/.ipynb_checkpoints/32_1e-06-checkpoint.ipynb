{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Directories\n",
    "MODEL_FOLDER = \"../../../models/lstm/\"\n",
    "MODEL_FILENAME = MODEL_FOLDER + \"4Q/32_units/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: model saver\n",
    "def saveModel(sess, MODEL_FILENAME):\n",
    "    if not os.path.exists(MODEL_FOLDER):\n",
    "        print('Creating path where to save model: ' + MODEL_FOLDER)\n",
    "        os.mkdir(MODEL_FOLDER)\n",
    "\n",
    "    #print('Saving model at: ' + MODEL_FILENAME)\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, MODEL_FILENAME)\n",
    "    #print('Model successfully saved.\\n')\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: model loader\n",
    "def loadModel(sess, MODEL_FILENAME):\n",
    "    if os.path.exists(MODEL_FILENAME + \".index\"):\n",
    "        print('Loading save model from: ' + MODEL_FILENAME)\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, MODEL_FILENAME)\n",
    "        print('Model successfully loaded.\\n')\n",
    "        return True\n",
    "    else:\n",
    "        print('Model file <<' + MODEL_FILENAME + '>> does not exists!')\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Hyperparameters\n",
    "epochs = 500\n",
    "learning_rate = 1e-6\n",
    "batch_size = 5\n",
    "early_stop_iters = 10\n",
    "folds = 32\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 3  # data input\n",
    "n_steps = 4  # timesteps\n",
    "n_hidden = 32 # dimension of recurrent unit\n",
    "\n",
    "# (REPRODUCIBILITY) set random seeds\n",
    "tf.set_random_seed(123)\n",
    "\n",
    "# Define weights and biases\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.truncated_normal([n_hidden, 1], stddev = 1.0 / tf.sqrt(float(n_hidden))),\n",
    "        name='out_weight')\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.zeros([1]),\n",
    "        name='out_bias')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: Build model\n",
    "def RNN(X, weights, biases, n_hidden):\n",
    "\n",
    "    # Define a LSTM cell with tensorflow\n",
    "    lstm_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden, state_is_tuple=True)\n",
    "    outputs, _ = tf.nn.dynamic_rnn(lstm_cell, X, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    out_layer = tf.matmul(outputs[:,-1,:], weights['out']) + biases['out']\n",
    "\n",
    "    return out_layer\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: select batch\n",
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the data...\n",
      "Finished: data loaded. Stats below: \n",
      "Nr of training samples: 193\n",
      "Nr of testing  samples: 77\n",
      "Number of variables: 3\n",
      "Number of lags: 4\n",
      "Window length: 65\n",
      "Number of validation folds: 32\n"
     ]
    }
   ],
   "source": [
    "# =================================\n",
    "# 0. Load dataset\n",
    "# =================================\n",
    "print(\"Loading the data...\")\n",
    "# Training set pre-processing\n",
    "train = pd.read_csv('../../../Data/train.csv')\n",
    "train_4lag_inflation = np.array(train[['inflation.lag4',\n",
    "                                       'inflation.lag5',\n",
    "                                       'inflation.lag6',\n",
    "                                       'inflation.lag7']])\n",
    "train_4lag_unemp = np.array(train[['unemp.lag4',\n",
    "                                   'unemp.lag5',\n",
    "                                   'unemp.lag6',\n",
    "                                   'unemp.lag7']])\n",
    "train_4lag_oil = np.array(train[['oil.lag4',\n",
    "                                 'oil.lag5',\n",
    "                                 'oil.lag6',\n",
    "                                 'oil.lag7']])\n",
    "train_features = np.concatenate((train_4lag_inflation[:,:,np.newaxis], \n",
    "\t                             train_4lag_unemp[:,:,np.newaxis],\n",
    "\t                             train_4lag_oil[:,:,np.newaxis]),\n",
    "\t                             axis=2)\n",
    "train_target = np.array(train['inflation.target'])\n",
    "\n",
    "# Test set pre-processing\n",
    "test = pd.read_csv('../../../Data/test.csv')\n",
    "test_4lag_inflation = np.array(test[['inflation.lag4',\n",
    "                                     'inflation.lag5',\n",
    "                                     'inflation.lag6',\n",
    "                                     'inflation.lag7']])\n",
    "test_4lag_unemp = np.array(test[['unemp.lag4',\n",
    "                                 'unemp.lag5',\n",
    "                                 'unemp.lag6',\n",
    "                                 'unemp.lag7']])\n",
    "test_4lag_oil = np.array(test[['oil.lag4',\n",
    "                               'oil.lag5',\n",
    "                               'oil.lag6',\n",
    "                               'oil.lag7']])\n",
    "test_features = np.concatenate((test_4lag_inflation[:,:,np.newaxis], \n",
    "\t                            test_4lag_unemp[:,:,np.newaxis],\n",
    "\t                            test_4lag_oil[:,:,np.newaxis]),\n",
    "\t                            axis=2)\n",
    "test_target = np.array(test['inflation.target'])\n",
    "\n",
    "(nrTrainSamples, timesteps, variables) = train_features.shape\n",
    "(nrTestSamples, _, _) = test_features.shape\n",
    "\n",
    "# Window length and validation fold index\n",
    "window_length = 65\n",
    "valIndex = np.linspace(start=window_length, stop=nrTrainSamples, \n",
    "                       endpoint=True, num=folds+1, dtype=np.int)\n",
    "\n",
    "print(\"Finished: data loaded. Stats below: \")\n",
    "print(\"Nr of training samples: %d\" % nrTrainSamples)\n",
    "print(\"Nr of testing  samples: %d\" % nrTestSamples)\n",
    "print(\"Number of variables: %d\" % variables)\n",
    "print(\"Number of lags: %d\" % timesteps)\n",
    "print(\"Window length: %d\" % window_length)\n",
    "print(\"Number of validation folds: %d\" % folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 1. Build model\n",
    "# ==================================\n",
    "# tf graph input\n",
    "x = tf.placeholder(\"float\", [None, n_steps, n_input], name='Batch')\n",
    "y = tf.placeholder(\"float\", name='True_labels_of_batch')\n",
    "lr = tf.placeholder(\"float\", name='Learning_rate')\n",
    "\n",
    "# Make predictions with the model\n",
    "pred = RNN(x, weights, biases, n_hidden)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss = tf.reduce_mean(tf.diag_part(tf.square(tf.subtract(x=pred, y=y))))\n",
    "optimizer = tf.train.GradientDescentOptimizer(lr).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training \n",
      "Hyperparameters: \n",
      "Dimension of recurrent unit = 32 \n",
      "Learning rate = 1e-06 \n",
      "Epochs = 500 \n",
      "Batch size = 5 \n",
      "Early stopping epochs = 10 \n",
      "Learning rate = 1e-06\n",
      "Fold: 1  Epoch: 1  Training loss = 3.5270  Validation loss = 3.8795  \n",
      "\n",
      "Fold: 1  Epoch: 2  Training loss = 3.5268  Validation loss = 3.8791  \n",
      "\n",
      "Fold: 1  Epoch: 3  Training loss = 3.5265  Validation loss = 3.8786  \n",
      "\n",
      "Fold: 1  Epoch: 4  Training loss = 3.5262  Validation loss = 3.8782  \n",
      "\n",
      "Fold: 1  Epoch: 5  Training loss = 3.5260  Validation loss = 3.8778  \n",
      "\n",
      "Fold: 1  Epoch: 6  Training loss = 3.5257  Validation loss = 3.8774  \n",
      "\n",
      "Fold: 1  Epoch: 7  Training loss = 3.5255  Validation loss = 3.8770  \n",
      "\n",
      "Fold: 1  Epoch: 8  Training loss = 3.5252  Validation loss = 3.8765  \n",
      "\n",
      "Fold: 1  Epoch: 9  Training loss = 3.5250  Validation loss = 3.8762  \n",
      "\n",
      "Fold: 1  Epoch: 10  Training loss = 3.5247  Validation loss = 3.8757  \n",
      "\n",
      "Fold: 1  Epoch: 11  Training loss = 3.5244  Validation loss = 3.8753  \n",
      "\n",
      "Fold: 1  Epoch: 12  Training loss = 3.5242  Validation loss = 3.8749  \n",
      "\n",
      "Fold: 1  Epoch: 13  Training loss = 3.5239  Validation loss = 3.8745  \n",
      "\n",
      "Fold: 1  Epoch: 14  Training loss = 3.5236  Validation loss = 3.8741  \n",
      "\n",
      "Fold: 1  Epoch: 15  Training loss = 3.5234  Validation loss = 3.8737  \n",
      "\n",
      "Fold: 1  Epoch: 16  Training loss = 3.5231  Validation loss = 3.8732  \n",
      "\n",
      "Fold: 1  Epoch: 17  Training loss = 3.5228  Validation loss = 3.8728  \n",
      "\n",
      "Fold: 1  Epoch: 18  Training loss = 3.5226  Validation loss = 3.8724  \n",
      "\n",
      "Fold: 1  Epoch: 19  Training loss = 3.5224  Validation loss = 3.8721  \n",
      "\n",
      "Fold: 1  Epoch: 20  Training loss = 3.5222  Validation loss = 3.8717  \n",
      "\n",
      "Fold: 1  Epoch: 21  Training loss = 3.5219  Validation loss = 3.8712  \n",
      "\n",
      "Fold: 1  Epoch: 22  Training loss = 3.5217  Validation loss = 3.8708  \n",
      "\n",
      "Fold: 1  Epoch: 23  Training loss = 3.5214  Validation loss = 3.8705  \n",
      "\n",
      "Fold: 1  Epoch: 24  Training loss = 3.5211  Validation loss = 3.8700  \n",
      "\n",
      "Fold: 1  Epoch: 25  Training loss = 3.5209  Validation loss = 3.8697  \n",
      "\n",
      "Fold: 1  Epoch: 26  Training loss = 3.5206  Validation loss = 3.8692  \n",
      "\n",
      "Fold: 1  Epoch: 27  Training loss = 3.5204  Validation loss = 3.8688  \n",
      "\n",
      "Fold: 1  Epoch: 28  Training loss = 3.5201  Validation loss = 3.8684  \n",
      "\n",
      "Fold: 1  Epoch: 29  Training loss = 3.5198  Validation loss = 3.8679  \n",
      "\n",
      "Fold: 1  Epoch: 30  Training loss = 3.5195  Validation loss = 3.8675  \n",
      "\n",
      "Fold: 1  Epoch: 31  Training loss = 3.5192  Validation loss = 3.8669  \n",
      "\n",
      "Fold: 1  Epoch: 32  Training loss = 3.5189  Validation loss = 3.8664  \n",
      "\n",
      "Fold: 1  Epoch: 33  Training loss = 3.5186  Validation loss = 3.8659  \n",
      "\n",
      "Fold: 1  Epoch: 34  Training loss = 3.5183  Validation loss = 3.8655  \n",
      "\n",
      "Fold: 1  Epoch: 35  Training loss = 3.5180  Validation loss = 3.8651  \n",
      "\n",
      "Fold: 1  Epoch: 36  Training loss = 3.5178  Validation loss = 3.8647  \n",
      "\n",
      "Fold: 1  Epoch: 37  Training loss = 3.5176  Validation loss = 3.8643  \n",
      "\n",
      "Fold: 1  Epoch: 38  Training loss = 3.5173  Validation loss = 3.8639  \n",
      "\n",
      "Fold: 1  Epoch: 39  Training loss = 3.5171  Validation loss = 3.8635  \n",
      "\n",
      "Fold: 1  Epoch: 40  Training loss = 3.5169  Validation loss = 3.8632  \n",
      "\n",
      "Fold: 1  Epoch: 41  Training loss = 3.5167  Validation loss = 3.8629  \n",
      "\n",
      "Fold: 1  Epoch: 42  Training loss = 3.5164  Validation loss = 3.8625  \n",
      "\n",
      "Fold: 1  Epoch: 43  Training loss = 3.5162  Validation loss = 3.8621  \n",
      "\n",
      "Fold: 1  Epoch: 44  Training loss = 3.5159  Validation loss = 3.8617  \n",
      "\n",
      "Fold: 1  Epoch: 45  Training loss = 3.5157  Validation loss = 3.8613  \n",
      "\n",
      "Fold: 1  Epoch: 46  Training loss = 3.5155  Validation loss = 3.8609  \n",
      "\n",
      "Fold: 1  Epoch: 47  Training loss = 3.5152  Validation loss = 3.8606  \n",
      "\n",
      "Fold: 1  Epoch: 48  Training loss = 3.5150  Validation loss = 3.8602  \n",
      "\n",
      "Fold: 1  Epoch: 49  Training loss = 3.5148  Validation loss = 3.8598  \n",
      "\n",
      "Fold: 1  Epoch: 50  Training loss = 3.5146  Validation loss = 3.8594  \n",
      "\n",
      "Fold: 1  Epoch: 51  Training loss = 3.5143  Validation loss = 3.8590  \n",
      "\n",
      "Fold: 1  Epoch: 52  Training loss = 3.5141  Validation loss = 3.8587  \n",
      "\n",
      "Fold: 1  Epoch: 53  Training loss = 3.5139  Validation loss = 3.8583  \n",
      "\n",
      "Fold: 1  Epoch: 54  Training loss = 3.5136  Validation loss = 3.8579  \n",
      "\n",
      "Fold: 1  Epoch: 55  Training loss = 3.5134  Validation loss = 3.8575  \n",
      "\n",
      "Fold: 1  Epoch: 56  Training loss = 3.5131  Validation loss = 3.8571  \n",
      "\n",
      "Fold: 1  Epoch: 57  Training loss = 3.5128  Validation loss = 3.8567  \n",
      "\n",
      "Fold: 1  Epoch: 58  Training loss = 3.5126  Validation loss = 3.8563  \n",
      "\n",
      "Fold: 1  Epoch: 59  Training loss = 3.5123  Validation loss = 3.8558  \n",
      "\n",
      "Fold: 1  Epoch: 60  Training loss = 3.5121  Validation loss = 3.8555  \n",
      "\n",
      "Fold: 1  Epoch: 61  Training loss = 3.5118  Validation loss = 3.8550  \n",
      "\n",
      "Fold: 1  Epoch: 62  Training loss = 3.5116  Validation loss = 3.8547  \n",
      "\n",
      "Fold: 1  Epoch: 63  Training loss = 3.5114  Validation loss = 3.8543  \n",
      "\n",
      "Fold: 1  Epoch: 64  Training loss = 3.5112  Validation loss = 3.8539  \n",
      "\n",
      "Fold: 1  Epoch: 65  Training loss = 3.5109  Validation loss = 3.8536  \n",
      "\n",
      "Fold: 1  Epoch: 66  Training loss = 3.5107  Validation loss = 3.8531  \n",
      "\n",
      "Fold: 1  Epoch: 67  Training loss = 3.5104  Validation loss = 3.8526  \n",
      "\n",
      "Fold: 1  Epoch: 68  Training loss = 3.5101  Validation loss = 3.8522  \n",
      "\n",
      "Fold: 1  Epoch: 69  Training loss = 3.5099  Validation loss = 3.8519  \n",
      "\n",
      "Fold: 1  Epoch: 70  Training loss = 3.5097  Validation loss = 3.8516  \n",
      "\n",
      "Fold: 1  Epoch: 71  Training loss = 3.5095  Validation loss = 3.8512  \n",
      "\n",
      "Fold: 1  Epoch: 72  Training loss = 3.5093  Validation loss = 3.8508  \n",
      "\n",
      "Fold: 1  Epoch: 73  Training loss = 3.5090  Validation loss = 3.8504  \n",
      "\n",
      "Fold: 1  Epoch: 74  Training loss = 3.5087  Validation loss = 3.8499  \n",
      "\n",
      "Fold: 1  Epoch: 75  Training loss = 3.5084  Validation loss = 3.8495  \n",
      "\n",
      "Fold: 1  Epoch: 76  Training loss = 3.5082  Validation loss = 3.8491  \n",
      "\n",
      "Fold: 1  Epoch: 77  Training loss = 3.5079  Validation loss = 3.8486  \n",
      "\n",
      "Fold: 1  Epoch: 78  Training loss = 3.5076  Validation loss = 3.8482  \n",
      "\n",
      "Fold: 1  Epoch: 79  Training loss = 3.5073  Validation loss = 3.8477  \n",
      "\n",
      "Fold: 1  Epoch: 80  Training loss = 3.5071  Validation loss = 3.8473  \n",
      "\n",
      "Fold: 1  Epoch: 81  Training loss = 3.5068  Validation loss = 3.8469  \n",
      "\n",
      "Fold: 1  Epoch: 82  Training loss = 3.5066  Validation loss = 3.8465  \n",
      "\n",
      "Fold: 1  Epoch: 83  Training loss = 3.5064  Validation loss = 3.8461  \n",
      "\n",
      "Fold: 1  Epoch: 84  Training loss = 3.5061  Validation loss = 3.8457  \n",
      "\n",
      "Fold: 1  Epoch: 85  Training loss = 3.5058  Validation loss = 3.8453  \n",
      "\n",
      "Fold: 1  Epoch: 86  Training loss = 3.5056  Validation loss = 3.8450  \n",
      "\n",
      "Fold: 1  Epoch: 87  Training loss = 3.5053  Validation loss = 3.8445  \n",
      "\n",
      "Fold: 1  Epoch: 88  Training loss = 3.5051  Validation loss = 3.8441  \n",
      "\n",
      "Fold: 1  Epoch: 89  Training loss = 3.5049  Validation loss = 3.8438  \n",
      "\n",
      "Fold: 1  Epoch: 90  Training loss = 3.5047  Validation loss = 3.8434  \n",
      "\n",
      "Fold: 1  Epoch: 91  Training loss = 3.5045  Validation loss = 3.8431  \n",
      "\n",
      "Fold: 1  Epoch: 92  Training loss = 3.5042  Validation loss = 3.8427  \n",
      "\n",
      "Fold: 1  Epoch: 93  Training loss = 3.5039  Validation loss = 3.8422  \n",
      "\n",
      "Fold: 1  Epoch: 94  Training loss = 3.5036  Validation loss = 3.8417  \n",
      "\n",
      "Fold: 1  Epoch: 95  Training loss = 3.5034  Validation loss = 3.8413  \n",
      "\n",
      "Fold: 1  Epoch: 96  Training loss = 3.5032  Validation loss = 3.8410  \n",
      "\n",
      "Fold: 1  Epoch: 97  Training loss = 3.5029  Validation loss = 3.8406  \n",
      "\n",
      "Fold: 1  Epoch: 98  Training loss = 3.5027  Validation loss = 3.8402  \n",
      "\n",
      "Fold: 1  Epoch: 99  Training loss = 3.5024  Validation loss = 3.8398  \n",
      "\n",
      "Fold: 1  Epoch: 100  Training loss = 3.5022  Validation loss = 3.8395  \n",
      "\n",
      "Fold: 1  Epoch: 101  Training loss = 3.5019  Validation loss = 3.8389  \n",
      "\n",
      "Fold: 1  Epoch: 102  Training loss = 3.5017  Validation loss = 3.8385  \n",
      "\n",
      "Fold: 1  Epoch: 103  Training loss = 3.5014  Validation loss = 3.8381  \n",
      "\n",
      "Fold: 1  Epoch: 104  Training loss = 3.5012  Validation loss = 3.8377  \n",
      "\n",
      "Fold: 1  Epoch: 105  Training loss = 3.5009  Validation loss = 3.8373  \n",
      "\n",
      "Fold: 1  Epoch: 106  Training loss = 3.5006  Validation loss = 3.8368  \n",
      "\n",
      "Fold: 1  Epoch: 107  Training loss = 3.5004  Validation loss = 3.8364  \n",
      "\n",
      "Fold: 1  Epoch: 108  Training loss = 3.5002  Validation loss = 3.8361  \n",
      "\n",
      "Fold: 1  Epoch: 109  Training loss = 3.5000  Validation loss = 3.8357  \n",
      "\n",
      "Fold: 1  Epoch: 110  Training loss = 3.4998  Validation loss = 3.8354  \n",
      "\n",
      "Fold: 1  Epoch: 111  Training loss = 3.4995  Validation loss = 3.8350  \n",
      "\n",
      "Fold: 1  Epoch: 112  Training loss = 3.4994  Validation loss = 3.8347  \n",
      "\n",
      "Fold: 1  Epoch: 113  Training loss = 3.4990  Validation loss = 3.8342  \n",
      "\n",
      "Fold: 1  Epoch: 114  Training loss = 3.4988  Validation loss = 3.8339  \n",
      "\n",
      "Fold: 1  Epoch: 115  Training loss = 3.4986  Validation loss = 3.8335  \n",
      "\n",
      "Fold: 1  Epoch: 116  Training loss = 3.4984  Validation loss = 3.8331  \n",
      "\n",
      "Fold: 1  Epoch: 117  Training loss = 3.4981  Validation loss = 3.8327  \n",
      "\n",
      "Fold: 1  Epoch: 118  Training loss = 3.4978  Validation loss = 3.8323  \n",
      "\n",
      "Fold: 1  Epoch: 119  Training loss = 3.4976  Validation loss = 3.8319  \n",
      "\n",
      "Fold: 1  Epoch: 120  Training loss = 3.4974  Validation loss = 3.8315  \n",
      "\n",
      "Fold: 1  Epoch: 121  Training loss = 3.4971  Validation loss = 3.8311  \n",
      "\n",
      "Fold: 1  Epoch: 122  Training loss = 3.4968  Validation loss = 3.8307  \n",
      "\n",
      "Fold: 1  Epoch: 123  Training loss = 3.4966  Validation loss = 3.8302  \n",
      "\n",
      "Fold: 1  Epoch: 124  Training loss = 3.4964  Validation loss = 3.8299  \n",
      "\n",
      "Fold: 1  Epoch: 125  Training loss = 3.4961  Validation loss = 3.8294  \n",
      "\n",
      "Fold: 1  Epoch: 126  Training loss = 3.4958  Validation loss = 3.8290  \n",
      "\n",
      "Fold: 1  Epoch: 127  Training loss = 3.4955  Validation loss = 3.8286  \n",
      "\n",
      "Fold: 1  Epoch: 128  Training loss = 3.4953  Validation loss = 3.8282  \n",
      "\n",
      "Fold: 1  Epoch: 129  Training loss = 3.4951  Validation loss = 3.8278  \n",
      "\n",
      "Fold: 1  Epoch: 130  Training loss = 3.4948  Validation loss = 3.8273  \n",
      "\n",
      "Fold: 1  Epoch: 131  Training loss = 3.4945  Validation loss = 3.8269  \n",
      "\n",
      "Fold: 1  Epoch: 132  Training loss = 3.4943  Validation loss = 3.8265  \n",
      "\n",
      "Fold: 1  Epoch: 133  Training loss = 3.4941  Validation loss = 3.8262  \n",
      "\n",
      "Fold: 1  Epoch: 134  Training loss = 3.4938  Validation loss = 3.8257  \n",
      "\n",
      "Fold: 1  Epoch: 135  Training loss = 3.4935  Validation loss = 3.8253  \n",
      "\n",
      "Fold: 1  Epoch: 136  Training loss = 3.4933  Validation loss = 3.8249  \n",
      "\n",
      "Fold: 1  Epoch: 137  Training loss = 3.4930  Validation loss = 3.8245  \n",
      "\n",
      "Fold: 1  Epoch: 138  Training loss = 3.4928  Validation loss = 3.8241  \n",
      "\n",
      "Fold: 1  Epoch: 139  Training loss = 3.4926  Validation loss = 3.8237  \n",
      "\n",
      "Fold: 1  Epoch: 140  Training loss = 3.4924  Validation loss = 3.8234  \n",
      "\n",
      "Fold: 1  Epoch: 141  Training loss = 3.4921  Validation loss = 3.8230  \n",
      "\n",
      "Fold: 1  Epoch: 142  Training loss = 3.4919  Validation loss = 3.8225  \n",
      "\n",
      "Fold: 1  Epoch: 143  Training loss = 3.4916  Validation loss = 3.8221  \n",
      "\n",
      "Fold: 1  Epoch: 144  Training loss = 3.4914  Validation loss = 3.8218  \n",
      "\n",
      "Fold: 1  Epoch: 145  Training loss = 3.4911  Validation loss = 3.8213  \n",
      "\n",
      "Fold: 1  Epoch: 146  Training loss = 3.4909  Validation loss = 3.8209  \n",
      "\n",
      "Fold: 1  Epoch: 147  Training loss = 3.4906  Validation loss = 3.8205  \n",
      "\n",
      "Fold: 1  Epoch: 148  Training loss = 3.4904  Validation loss = 3.8201  \n",
      "\n",
      "Fold: 1  Epoch: 149  Training loss = 3.4901  Validation loss = 3.8197  \n",
      "\n",
      "Fold: 1  Epoch: 150  Training loss = 3.4899  Validation loss = 3.8193  \n",
      "\n",
      "Fold: 1  Epoch: 151  Training loss = 3.4896  Validation loss = 3.8189  \n",
      "\n",
      "Fold: 1  Epoch: 152  Training loss = 3.4894  Validation loss = 3.8185  \n",
      "\n",
      "Fold: 1  Epoch: 153  Training loss = 3.4891  Validation loss = 3.8180  \n",
      "\n",
      "Fold: 1  Epoch: 154  Training loss = 3.4888  Validation loss = 3.8175  \n",
      "\n",
      "Fold: 1  Epoch: 155  Training loss = 3.4886  Validation loss = 3.8172  \n",
      "\n",
      "Fold: 1  Epoch: 156  Training loss = 3.4884  Validation loss = 3.8168  \n",
      "\n",
      "Fold: 1  Epoch: 157  Training loss = 3.4882  Validation loss = 3.8165  \n",
      "\n",
      "Fold: 1  Epoch: 158  Training loss = 3.4880  Validation loss = 3.8162  \n",
      "\n",
      "Fold: 1  Epoch: 159  Training loss = 3.4878  Validation loss = 3.8157  \n",
      "\n",
      "Fold: 1  Epoch: 160  Training loss = 3.4875  Validation loss = 3.8153  \n",
      "\n",
      "Fold: 1  Epoch: 161  Training loss = 3.4872  Validation loss = 3.8148  \n",
      "\n",
      "Fold: 1  Epoch: 162  Training loss = 3.4869  Validation loss = 3.8144  \n",
      "\n",
      "Fold: 1  Epoch: 163  Training loss = 3.4867  Validation loss = 3.8141  \n",
      "\n",
      "Fold: 1  Epoch: 164  Training loss = 3.4865  Validation loss = 3.8137  \n",
      "\n",
      "Fold: 1  Epoch: 165  Training loss = 3.4863  Validation loss = 3.8133  \n",
      "\n",
      "Fold: 1  Epoch: 166  Training loss = 3.4859  Validation loss = 3.8128  \n",
      "\n",
      "Fold: 1  Epoch: 167  Training loss = 3.4857  Validation loss = 3.8124  \n",
      "\n",
      "Fold: 1  Epoch: 168  Training loss = 3.4855  Validation loss = 3.8121  \n",
      "\n",
      "Fold: 1  Epoch: 169  Training loss = 3.4853  Validation loss = 3.8117  \n",
      "\n",
      "Fold: 1  Epoch: 170  Training loss = 3.4850  Validation loss = 3.8113  \n",
      "\n",
      "Fold: 1  Epoch: 171  Training loss = 3.4848  Validation loss = 3.8110  \n",
      "\n",
      "Fold: 1  Epoch: 172  Training loss = 3.4846  Validation loss = 3.8106  \n",
      "\n",
      "Fold: 1  Epoch: 173  Training loss = 3.4843  Validation loss = 3.8101  \n",
      "\n",
      "Fold: 1  Epoch: 174  Training loss = 3.4841  Validation loss = 3.8097  \n",
      "\n",
      "Fold: 1  Epoch: 175  Training loss = 3.4839  Validation loss = 3.8094  \n",
      "\n",
      "Fold: 1  Epoch: 176  Training loss = 3.4836  Validation loss = 3.8090  \n",
      "\n",
      "Fold: 1  Epoch: 177  Training loss = 3.4834  Validation loss = 3.8087  \n",
      "\n",
      "Fold: 1  Epoch: 178  Training loss = 3.4832  Validation loss = 3.8083  \n",
      "\n",
      "Fold: 1  Epoch: 179  Training loss = 3.4830  Validation loss = 3.8079  \n",
      "\n",
      "Fold: 1  Epoch: 180  Training loss = 3.4827  Validation loss = 3.8075  \n",
      "\n",
      "Fold: 1  Epoch: 181  Training loss = 3.4824  Validation loss = 3.8070  \n",
      "\n",
      "Fold: 1  Epoch: 182  Training loss = 3.4822  Validation loss = 3.8067  \n",
      "\n",
      "Fold: 1  Epoch: 183  Training loss = 3.4819  Validation loss = 3.8062  \n",
      "\n",
      "Fold: 1  Epoch: 184  Training loss = 3.4817  Validation loss = 3.8058  \n",
      "\n",
      "Fold: 1  Epoch: 185  Training loss = 3.4815  Validation loss = 3.8055  \n",
      "\n",
      "Fold: 1  Epoch: 186  Training loss = 3.4813  Validation loss = 3.8051  \n",
      "\n",
      "Fold: 1  Epoch: 187  Training loss = 3.4811  Validation loss = 3.8048  \n",
      "\n",
      "Fold: 1  Epoch: 188  Training loss = 3.4808  Validation loss = 3.8044  \n",
      "\n",
      "Fold: 1  Epoch: 189  Training loss = 3.4805  Validation loss = 3.8039  \n",
      "\n",
      "Fold: 1  Epoch: 190  Training loss = 3.4803  Validation loss = 3.8036  \n",
      "\n",
      "Fold: 1  Epoch: 191  Training loss = 3.4800  Validation loss = 3.8031  \n",
      "\n",
      "Fold: 1  Epoch: 192  Training loss = 3.4798  Validation loss = 3.8026  \n",
      "\n",
      "Fold: 1  Epoch: 193  Training loss = 3.4795  Validation loss = 3.8023  \n",
      "\n",
      "Fold: 1  Epoch: 194  Training loss = 3.4793  Validation loss = 3.8019  \n",
      "\n",
      "Fold: 1  Epoch: 195  Training loss = 3.4791  Validation loss = 3.8016  \n",
      "\n",
      "Fold: 1  Epoch: 196  Training loss = 3.4789  Validation loss = 3.8012  \n",
      "\n",
      "Fold: 1  Epoch: 197  Training loss = 3.4787  Validation loss = 3.8009  \n",
      "\n",
      "Fold: 1  Epoch: 198  Training loss = 3.4785  Validation loss = 3.8005  \n",
      "\n",
      "Fold: 1  Epoch: 199  Training loss = 3.4782  Validation loss = 3.8001  \n",
      "\n",
      "Fold: 1  Epoch: 200  Training loss = 3.4779  Validation loss = 3.7997  \n",
      "\n",
      "Fold: 1  Epoch: 201  Training loss = 3.4777  Validation loss = 3.7992  \n",
      "\n",
      "Fold: 1  Epoch: 202  Training loss = 3.4775  Validation loss = 3.7989  \n",
      "\n",
      "Fold: 1  Epoch: 203  Training loss = 3.4773  Validation loss = 3.7985  \n",
      "\n",
      "Fold: 1  Epoch: 204  Training loss = 3.4771  Validation loss = 3.7982  \n",
      "\n",
      "Fold: 1  Epoch: 205  Training loss = 3.4768  Validation loss = 3.7978  \n",
      "\n",
      "Fold: 1  Epoch: 206  Training loss = 3.4766  Validation loss = 3.7975  \n",
      "\n",
      "Fold: 1  Epoch: 207  Training loss = 3.4764  Validation loss = 3.7971  \n",
      "\n",
      "Fold: 1  Epoch: 208  Training loss = 3.4761  Validation loss = 3.7966  \n",
      "\n",
      "Fold: 1  Epoch: 209  Training loss = 3.4759  Validation loss = 3.7963  \n",
      "\n",
      "Fold: 1  Epoch: 210  Training loss = 3.4757  Validation loss = 3.7959  \n",
      "\n",
      "Fold: 1  Epoch: 211  Training loss = 3.4755  Validation loss = 3.7956  \n",
      "\n",
      "Fold: 1  Epoch: 212  Training loss = 3.4753  Validation loss = 3.7953  \n",
      "\n",
      "Fold: 1  Epoch: 213  Training loss = 3.4751  Validation loss = 3.7949  \n",
      "\n",
      "Fold: 1  Epoch: 214  Training loss = 3.4748  Validation loss = 3.7945  \n",
      "\n",
      "Fold: 1  Epoch: 215  Training loss = 3.4746  Validation loss = 3.7941  \n",
      "\n",
      "Fold: 1  Epoch: 216  Training loss = 3.4744  Validation loss = 3.7938  \n",
      "\n",
      "Fold: 1  Epoch: 217  Training loss = 3.4742  Validation loss = 3.7935  \n",
      "\n",
      "Fold: 1  Epoch: 218  Training loss = 3.4740  Validation loss = 3.7931  \n",
      "\n",
      "Fold: 1  Epoch: 219  Training loss = 3.4738  Validation loss = 3.7927  \n",
      "\n",
      "Fold: 1  Epoch: 220  Training loss = 3.4736  Validation loss = 3.7924  \n",
      "\n",
      "Fold: 1  Epoch: 221  Training loss = 3.4734  Validation loss = 3.7920  \n",
      "\n",
      "Fold: 1  Epoch: 222  Training loss = 3.4731  Validation loss = 3.7915  \n",
      "\n",
      "Fold: 1  Epoch: 223  Training loss = 3.4729  Validation loss = 3.7912  \n",
      "\n",
      "Fold: 1  Epoch: 224  Training loss = 3.4727  Validation loss = 3.7908  \n",
      "\n",
      "Fold: 1  Epoch: 225  Training loss = 3.4724  Validation loss = 3.7904  \n",
      "\n",
      "Fold: 1  Epoch: 226  Training loss = 3.4721  Validation loss = 3.7900  \n",
      "\n",
      "Fold: 1  Epoch: 227  Training loss = 3.4718  Validation loss = 3.7895  \n",
      "\n",
      "Fold: 1  Epoch: 228  Training loss = 3.4716  Validation loss = 3.7892  \n",
      "\n",
      "Fold: 1  Epoch: 229  Training loss = 3.4714  Validation loss = 3.7887  \n",
      "\n",
      "Fold: 1  Epoch: 230  Training loss = 3.4712  Validation loss = 3.7884  \n",
      "\n",
      "Fold: 1  Epoch: 231  Training loss = 3.4710  Validation loss = 3.7880  \n",
      "\n",
      "Fold: 1  Epoch: 232  Training loss = 3.4707  Validation loss = 3.7877  \n",
      "\n",
      "Fold: 1  Epoch: 233  Training loss = 3.4704  Validation loss = 3.7871  \n",
      "\n",
      "Fold: 1  Epoch: 234  Training loss = 3.4701  Validation loss = 3.7866  \n",
      "\n",
      "Fold: 1  Epoch: 235  Training loss = 3.4699  Validation loss = 3.7862  \n",
      "\n",
      "Fold: 1  Epoch: 236  Training loss = 3.4696  Validation loss = 3.7858  \n",
      "\n",
      "Fold: 1  Epoch: 237  Training loss = 3.4694  Validation loss = 3.7855  \n",
      "\n",
      "Fold: 1  Epoch: 238  Training loss = 3.4691  Validation loss = 3.7850  \n",
      "\n",
      "Fold: 1  Epoch: 239  Training loss = 3.4688  Validation loss = 3.7846  \n",
      "\n",
      "Fold: 1  Epoch: 240  Training loss = 3.4686  Validation loss = 3.7842  \n",
      "\n",
      "Fold: 1  Epoch: 241  Training loss = 3.4684  Validation loss = 3.7838  \n",
      "\n",
      "Fold: 1  Epoch: 242  Training loss = 3.4681  Validation loss = 3.7834  \n",
      "\n",
      "Fold: 1  Epoch: 243  Training loss = 3.4679  Validation loss = 3.7829  \n",
      "\n",
      "Fold: 1  Epoch: 244  Training loss = 3.4677  Validation loss = 3.7826  \n",
      "\n",
      "Fold: 1  Epoch: 245  Training loss = 3.4674  Validation loss = 3.7822  \n",
      "\n",
      "Fold: 1  Epoch: 246  Training loss = 3.4672  Validation loss = 3.7818  \n",
      "\n",
      "Fold: 1  Epoch: 247  Training loss = 3.4670  Validation loss = 3.7814  \n",
      "\n",
      "Fold: 1  Epoch: 248  Training loss = 3.4667  Validation loss = 3.7810  \n",
      "\n",
      "Fold: 1  Epoch: 249  Training loss = 3.4665  Validation loss = 3.7807  \n",
      "\n",
      "Fold: 1  Epoch: 250  Training loss = 3.4663  Validation loss = 3.7804  \n",
      "\n",
      "Fold: 1  Epoch: 251  Training loss = 3.4661  Validation loss = 3.7800  \n",
      "\n",
      "Fold: 1  Epoch: 252  Training loss = 3.4658  Validation loss = 3.7796  \n",
      "\n",
      "Fold: 1  Epoch: 253  Training loss = 3.4656  Validation loss = 3.7792  \n",
      "\n",
      "Fold: 1  Epoch: 254  Training loss = 3.4654  Validation loss = 3.7788  \n",
      "\n",
      "Fold: 1  Epoch: 255  Training loss = 3.4651  Validation loss = 3.7784  \n",
      "\n",
      "Fold: 1  Epoch: 256  Training loss = 3.4649  Validation loss = 3.7780  \n",
      "\n",
      "Fold: 1  Epoch: 257  Training loss = 3.4647  Validation loss = 3.7777  \n",
      "\n",
      "Fold: 1  Epoch: 258  Training loss = 3.4644  Validation loss = 3.7772  \n",
      "\n",
      "Fold: 1  Epoch: 259  Training loss = 3.4642  Validation loss = 3.7768  \n",
      "\n",
      "Fold: 1  Epoch: 260  Training loss = 3.4640  Validation loss = 3.7765  \n",
      "\n",
      "Fold: 1  Epoch: 261  Training loss = 3.4637  Validation loss = 3.7761  \n",
      "\n",
      "Fold: 1  Epoch: 262  Training loss = 3.4636  Validation loss = 3.7758  \n",
      "\n",
      "Fold: 1  Epoch: 263  Training loss = 3.4633  Validation loss = 3.7754  \n",
      "\n",
      "Fold: 1  Epoch: 264  Training loss = 3.4631  Validation loss = 3.7749  \n",
      "\n",
      "Fold: 1  Epoch: 265  Training loss = 3.4629  Validation loss = 3.7746  \n",
      "\n",
      "Fold: 1  Epoch: 266  Training loss = 3.4626  Validation loss = 3.7742  \n",
      "\n",
      "Fold: 1  Epoch: 267  Training loss = 3.4624  Validation loss = 3.7738  \n",
      "\n",
      "Fold: 1  Epoch: 268  Training loss = 3.4622  Validation loss = 3.7734  \n",
      "\n",
      "Fold: 1  Epoch: 269  Training loss = 3.4619  Validation loss = 3.7730  \n",
      "\n",
      "Fold: 1  Epoch: 270  Training loss = 3.4616  Validation loss = 3.7726  \n",
      "\n",
      "Fold: 1  Epoch: 271  Training loss = 3.4614  Validation loss = 3.7722  \n",
      "\n",
      "Fold: 1  Epoch: 272  Training loss = 3.4612  Validation loss = 3.7718  \n",
      "\n",
      "Fold: 1  Epoch: 273  Training loss = 3.4610  Validation loss = 3.7715  \n",
      "\n",
      "Fold: 1  Epoch: 274  Training loss = 3.4608  Validation loss = 3.7711  \n",
      "\n",
      "Fold: 1  Epoch: 275  Training loss = 3.4605  Validation loss = 3.7707  \n",
      "\n",
      "Fold: 1  Epoch: 276  Training loss = 3.4604  Validation loss = 3.7704  \n",
      "\n",
      "Fold: 1  Epoch: 277  Training loss = 3.4601  Validation loss = 3.7700  \n",
      "\n",
      "Fold: 1  Epoch: 278  Training loss = 3.4599  Validation loss = 3.7695  \n",
      "\n",
      "Fold: 1  Epoch: 279  Training loss = 3.4597  Validation loss = 3.7692  \n",
      "\n",
      "Fold: 1  Epoch: 280  Training loss = 3.4594  Validation loss = 3.7688  \n",
      "\n",
      "Fold: 1  Epoch: 281  Training loss = 3.4592  Validation loss = 3.7685  \n",
      "\n",
      "Fold: 1  Epoch: 282  Training loss = 3.4589  Validation loss = 3.7680  \n",
      "\n",
      "Fold: 1  Epoch: 283  Training loss = 3.4586  Validation loss = 3.7676  \n",
      "\n",
      "Fold: 1  Epoch: 284  Training loss = 3.4584  Validation loss = 3.7672  \n",
      "\n",
      "Fold: 1  Epoch: 285  Training loss = 3.4582  Validation loss = 3.7668  \n",
      "\n",
      "Fold: 1  Epoch: 286  Training loss = 3.4579  Validation loss = 3.7664  \n",
      "\n",
      "Fold: 1  Epoch: 287  Training loss = 3.4577  Validation loss = 3.7660  \n",
      "\n",
      "Fold: 1  Epoch: 288  Training loss = 3.4575  Validation loss = 3.7656  \n",
      "\n",
      "Fold: 1  Epoch: 289  Training loss = 3.4572  Validation loss = 3.7652  \n",
      "\n",
      "Fold: 1  Epoch: 290  Training loss = 3.4570  Validation loss = 3.7648  \n",
      "\n",
      "Fold: 1  Epoch: 291  Training loss = 3.4568  Validation loss = 3.7644  \n",
      "\n",
      "Fold: 1  Epoch: 292  Training loss = 3.4565  Validation loss = 3.7640  \n",
      "\n",
      "Fold: 1  Epoch: 293  Training loss = 3.4563  Validation loss = 3.7637  \n",
      "\n",
      "Fold: 1  Epoch: 294  Training loss = 3.4561  Validation loss = 3.7634  \n",
      "\n",
      "Fold: 1  Epoch: 295  Training loss = 3.4559  Validation loss = 3.7629  \n",
      "\n",
      "Fold: 1  Epoch: 296  Training loss = 3.4557  Validation loss = 3.7626  \n",
      "\n",
      "Fold: 1  Epoch: 297  Training loss = 3.4555  Validation loss = 3.7623  \n",
      "\n",
      "Fold: 1  Epoch: 298  Training loss = 3.4552  Validation loss = 3.7618  \n",
      "\n",
      "Fold: 1  Epoch: 299  Training loss = 3.4550  Validation loss = 3.7614  \n",
      "\n",
      "Fold: 1  Epoch: 300  Training loss = 3.4547  Validation loss = 3.7610  \n",
      "\n",
      "Fold: 1  Epoch: 301  Training loss = 3.4545  Validation loss = 3.7606  \n",
      "\n",
      "Fold: 1  Epoch: 302  Training loss = 3.4542  Validation loss = 3.7602  \n",
      "\n",
      "Fold: 1  Epoch: 303  Training loss = 3.4540  Validation loss = 3.7598  \n",
      "\n",
      "Fold: 1  Epoch: 304  Training loss = 3.4537  Validation loss = 3.7594  \n",
      "\n",
      "Fold: 1  Epoch: 305  Training loss = 3.4535  Validation loss = 3.7590  \n",
      "\n",
      "Fold: 1  Epoch: 306  Training loss = 3.4532  Validation loss = 3.7585  \n",
      "\n",
      "Fold: 1  Epoch: 307  Training loss = 3.4531  Validation loss = 3.7582  \n",
      "\n",
      "Fold: 1  Epoch: 308  Training loss = 3.4528  Validation loss = 3.7577  \n",
      "\n",
      "Fold: 1  Epoch: 309  Training loss = 3.4526  Validation loss = 3.7574  \n",
      "\n",
      "Fold: 1  Epoch: 310  Training loss = 3.4524  Validation loss = 3.7571  \n",
      "\n",
      "Fold: 1  Epoch: 311  Training loss = 3.4522  Validation loss = 3.7567  \n",
      "\n",
      "Fold: 1  Epoch: 312  Training loss = 3.4519  Validation loss = 3.7563  \n",
      "\n",
      "Fold: 1  Epoch: 313  Training loss = 3.4517  Validation loss = 3.7560  \n",
      "\n",
      "Fold: 1  Epoch: 314  Training loss = 3.4515  Validation loss = 3.7555  \n",
      "\n",
      "Fold: 1  Epoch: 315  Training loss = 3.4512  Validation loss = 3.7550  \n",
      "\n",
      "Fold: 1  Epoch: 316  Training loss = 3.4509  Validation loss = 3.7546  \n",
      "\n",
      "Fold: 1  Epoch: 317  Training loss = 3.4507  Validation loss = 3.7543  \n",
      "\n",
      "Fold: 1  Epoch: 318  Training loss = 3.4505  Validation loss = 3.7539  \n",
      "\n",
      "Fold: 1  Epoch: 319  Training loss = 3.4503  Validation loss = 3.7535  \n",
      "\n",
      "Fold: 1  Epoch: 320  Training loss = 3.4500  Validation loss = 3.7531  \n",
      "\n",
      "Fold: 1  Epoch: 321  Training loss = 3.4498  Validation loss = 3.7528  \n",
      "\n",
      "Fold: 1  Epoch: 322  Training loss = 3.4496  Validation loss = 3.7524  \n",
      "\n",
      "Fold: 1  Epoch: 323  Training loss = 3.4494  Validation loss = 3.7521  \n",
      "\n",
      "Fold: 1  Epoch: 324  Training loss = 3.4492  Validation loss = 3.7517  \n",
      "\n",
      "Fold: 1  Epoch: 325  Training loss = 3.4489  Validation loss = 3.7512  \n",
      "\n",
      "Fold: 1  Epoch: 326  Training loss = 3.4487  Validation loss = 3.7509  \n",
      "\n",
      "Fold: 1  Epoch: 327  Training loss = 3.4485  Validation loss = 3.7505  \n",
      "\n",
      "Fold: 1  Epoch: 328  Training loss = 3.4483  Validation loss = 3.7502  \n",
      "\n",
      "Fold: 1  Epoch: 329  Training loss = 3.4481  Validation loss = 3.7498  \n",
      "\n",
      "Fold: 1  Epoch: 330  Training loss = 3.4478  Validation loss = 3.7494  \n",
      "\n",
      "Fold: 1  Epoch: 331  Training loss = 3.4476  Validation loss = 3.7490  \n",
      "\n",
      "Fold: 1  Epoch: 332  Training loss = 3.4473  Validation loss = 3.7486  \n",
      "\n",
      "Fold: 1  Epoch: 333  Training loss = 3.4471  Validation loss = 3.7482  \n",
      "\n",
      "Fold: 1  Epoch: 334  Training loss = 3.4469  Validation loss = 3.7478  \n",
      "\n",
      "Fold: 1  Epoch: 335  Training loss = 3.4467  Validation loss = 3.7475  \n",
      "\n",
      "Fold: 1  Epoch: 336  Training loss = 3.4464  Validation loss = 3.7471  \n",
      "\n",
      "Fold: 1  Epoch: 337  Training loss = 3.4462  Validation loss = 3.7467  \n",
      "\n",
      "Fold: 1  Epoch: 338  Training loss = 3.4459  Validation loss = 3.7463  \n",
      "\n",
      "Fold: 1  Epoch: 339  Training loss = 3.4458  Validation loss = 3.7460  \n",
      "\n",
      "Fold: 1  Epoch: 340  Training loss = 3.4455  Validation loss = 3.7456  \n",
      "\n",
      "Fold: 1  Epoch: 341  Training loss = 3.4453  Validation loss = 3.7452  \n",
      "\n",
      "Fold: 1  Epoch: 342  Training loss = 3.4451  Validation loss = 3.7449  \n",
      "\n",
      "Fold: 1  Epoch: 343  Training loss = 3.4449  Validation loss = 3.7445  \n",
      "\n",
      "Fold: 1  Epoch: 344  Training loss = 3.4446  Validation loss = 3.7441  \n",
      "\n",
      "Fold: 1  Epoch: 345  Training loss = 3.4444  Validation loss = 3.7437  \n",
      "\n",
      "Fold: 1  Epoch: 346  Training loss = 3.4441  Validation loss = 3.7433  \n",
      "\n",
      "Fold: 1  Epoch: 347  Training loss = 3.4439  Validation loss = 3.7428  \n",
      "\n",
      "Fold: 1  Epoch: 348  Training loss = 3.4437  Validation loss = 3.7425  \n",
      "\n",
      "Fold: 1  Epoch: 349  Training loss = 3.4434  Validation loss = 3.7421  \n",
      "\n",
      "Fold: 1  Epoch: 350  Training loss = 3.4432  Validation loss = 3.7417  \n",
      "\n",
      "Fold: 1  Epoch: 351  Training loss = 3.4430  Validation loss = 3.7414  \n",
      "\n",
      "Fold: 1  Epoch: 352  Training loss = 3.4428  Validation loss = 3.7410  \n",
      "\n",
      "Fold: 1  Epoch: 353  Training loss = 3.4425  Validation loss = 3.7405  \n",
      "\n",
      "Fold: 1  Epoch: 354  Training loss = 3.4423  Validation loss = 3.7402  \n",
      "\n",
      "Fold: 1  Epoch: 355  Training loss = 3.4421  Validation loss = 3.7399  \n",
      "\n",
      "Fold: 1  Epoch: 356  Training loss = 3.4420  Validation loss = 3.7396  \n",
      "\n",
      "Fold: 1  Epoch: 357  Training loss = 3.4417  Validation loss = 3.7391  \n",
      "\n",
      "Fold: 1  Epoch: 358  Training loss = 3.4415  Validation loss = 3.7388  \n",
      "\n",
      "Fold: 1  Epoch: 359  Training loss = 3.4413  Validation loss = 3.7384  \n",
      "\n",
      "Fold: 1  Epoch: 360  Training loss = 3.4411  Validation loss = 3.7380  \n",
      "\n",
      "Fold: 1  Epoch: 361  Training loss = 3.4408  Validation loss = 3.7376  \n",
      "\n",
      "Fold: 1  Epoch: 362  Training loss = 3.4406  Validation loss = 3.7372  \n",
      "\n",
      "Fold: 1  Epoch: 363  Training loss = 3.4404  Validation loss = 3.7369  \n",
      "\n",
      "Fold: 1  Epoch: 364  Training loss = 3.4401  Validation loss = 3.7364  \n",
      "\n",
      "Fold: 1  Epoch: 365  Training loss = 3.4398  Validation loss = 3.7360  \n",
      "\n",
      "Fold: 1  Epoch: 366  Training loss = 3.4396  Validation loss = 3.7355  \n",
      "\n",
      "Fold: 1  Epoch: 367  Training loss = 3.4394  Validation loss = 3.7352  \n",
      "\n",
      "Fold: 1  Epoch: 368  Training loss = 3.4391  Validation loss = 3.7347  \n",
      "\n",
      "Fold: 1  Epoch: 369  Training loss = 3.4388  Validation loss = 3.7343  \n",
      "\n",
      "Fold: 1  Epoch: 370  Training loss = 3.4386  Validation loss = 3.7339  \n",
      "\n",
      "Fold: 1  Epoch: 371  Training loss = 3.4384  Validation loss = 3.7335  \n",
      "\n",
      "Fold: 1  Epoch: 372  Training loss = 3.4382  Validation loss = 3.7331  \n",
      "\n",
      "Fold: 1  Epoch: 373  Training loss = 3.4380  Validation loss = 3.7328  \n",
      "\n",
      "Fold: 1  Epoch: 374  Training loss = 3.4377  Validation loss = 3.7324  \n",
      "\n",
      "Fold: 1  Epoch: 375  Training loss = 3.4375  Validation loss = 3.7319  \n",
      "\n",
      "Fold: 1  Epoch: 376  Training loss = 3.4372  Validation loss = 3.7315  \n",
      "\n",
      "Fold: 1  Epoch: 377  Training loss = 3.4370  Validation loss = 3.7311  \n",
      "\n",
      "Fold: 1  Epoch: 378  Training loss = 3.4367  Validation loss = 3.7307  \n",
      "\n",
      "Fold: 1  Epoch: 379  Training loss = 3.4365  Validation loss = 3.7303  \n",
      "\n",
      "Fold: 1  Epoch: 380  Training loss = 3.4363  Validation loss = 3.7299  \n",
      "\n",
      "Fold: 1  Epoch: 381  Training loss = 3.4361  Validation loss = 3.7295  \n",
      "\n",
      "Fold: 1  Epoch: 382  Training loss = 3.4358  Validation loss = 3.7291  \n",
      "\n",
      "Fold: 1  Epoch: 383  Training loss = 3.4356  Validation loss = 3.7287  \n",
      "\n",
      "Fold: 1  Epoch: 384  Training loss = 3.4353  Validation loss = 3.7283  \n",
      "\n",
      "Fold: 1  Epoch: 385  Training loss = 3.4351  Validation loss = 3.7280  \n",
      "\n",
      "Fold: 1  Epoch: 386  Training loss = 3.4349  Validation loss = 3.7276  \n",
      "\n",
      "Fold: 1  Epoch: 387  Training loss = 3.4347  Validation loss = 3.7272  \n",
      "\n",
      "Fold: 1  Epoch: 388  Training loss = 3.4345  Validation loss = 3.7268  \n",
      "\n",
      "Fold: 1  Epoch: 389  Training loss = 3.4343  Validation loss = 3.7265  \n",
      "\n",
      "Fold: 1  Epoch: 390  Training loss = 3.4341  Validation loss = 3.7261  \n",
      "\n",
      "Fold: 1  Epoch: 391  Training loss = 3.4338  Validation loss = 3.7256  \n",
      "\n",
      "Fold: 1  Epoch: 392  Training loss = 3.4335  Validation loss = 3.7252  \n",
      "\n",
      "Fold: 1  Epoch: 393  Training loss = 3.4332  Validation loss = 3.7248  \n",
      "\n",
      "Fold: 1  Epoch: 394  Training loss = 3.4331  Validation loss = 3.7244  \n",
      "\n",
      "Fold: 1  Epoch: 395  Training loss = 3.4328  Validation loss = 3.7240  \n",
      "\n",
      "Fold: 1  Epoch: 396  Training loss = 3.4326  Validation loss = 3.7237  \n",
      "\n",
      "Fold: 1  Epoch: 397  Training loss = 3.4324  Validation loss = 3.7233  \n",
      "\n",
      "Fold: 1  Epoch: 398  Training loss = 3.4321  Validation loss = 3.7228  \n",
      "\n",
      "Fold: 1  Epoch: 399  Training loss = 3.4319  Validation loss = 3.7225  \n",
      "\n",
      "Fold: 1  Epoch: 400  Training loss = 3.4317  Validation loss = 3.7221  \n",
      "\n",
      "Fold: 1  Epoch: 401  Training loss = 3.4315  Validation loss = 3.7218  \n",
      "\n",
      "Fold: 1  Epoch: 402  Training loss = 3.4313  Validation loss = 3.7214  \n",
      "\n",
      "Fold: 1  Epoch: 403  Training loss = 3.4311  Validation loss = 3.7210  \n",
      "\n",
      "Fold: 1  Epoch: 404  Training loss = 3.4309  Validation loss = 3.7207  \n",
      "\n",
      "Fold: 1  Epoch: 405  Training loss = 3.4307  Validation loss = 3.7204  \n",
      "\n",
      "Fold: 1  Epoch: 406  Training loss = 3.4305  Validation loss = 3.7201  \n",
      "\n",
      "Fold: 1  Epoch: 407  Training loss = 3.4302  Validation loss = 3.7196  \n",
      "\n",
      "Fold: 1  Epoch: 408  Training loss = 3.4300  Validation loss = 3.7192  \n",
      "\n",
      "Fold: 1  Epoch: 409  Training loss = 3.4297  Validation loss = 3.7188  \n",
      "\n",
      "Fold: 1  Epoch: 410  Training loss = 3.4295  Validation loss = 3.7184  \n",
      "\n",
      "Fold: 1  Epoch: 411  Training loss = 3.4293  Validation loss = 3.7180  \n",
      "\n",
      "Fold: 1  Epoch: 412  Training loss = 3.4291  Validation loss = 3.7176  \n",
      "\n",
      "Fold: 1  Epoch: 413  Training loss = 3.4288  Validation loss = 3.7172  \n",
      "\n",
      "Fold: 1  Epoch: 414  Training loss = 3.4286  Validation loss = 3.7169  \n",
      "\n",
      "Fold: 1  Epoch: 415  Training loss = 3.4283  Validation loss = 3.7164  \n",
      "\n",
      "Fold: 1  Epoch: 416  Training loss = 3.4281  Validation loss = 3.7161  \n",
      "\n",
      "Fold: 1  Epoch: 417  Training loss = 3.4279  Validation loss = 3.7157  \n",
      "\n",
      "Fold: 1  Epoch: 418  Training loss = 3.4277  Validation loss = 3.7153  \n",
      "\n",
      "Fold: 1  Epoch: 419  Training loss = 3.4274  Validation loss = 3.7149  \n",
      "\n",
      "Fold: 1  Epoch: 420  Training loss = 3.4273  Validation loss = 3.7146  \n",
      "\n",
      "Fold: 1  Epoch: 421  Training loss = 3.4270  Validation loss = 3.7142  \n",
      "\n",
      "Fold: 1  Epoch: 422  Training loss = 3.4268  Validation loss = 3.7139  \n",
      "\n",
      "Fold: 1  Epoch: 423  Training loss = 3.4266  Validation loss = 3.7135  \n",
      "\n",
      "Fold: 1  Epoch: 424  Training loss = 3.4264  Validation loss = 3.7131  \n",
      "\n",
      "Fold: 1  Epoch: 425  Training loss = 3.4261  Validation loss = 3.7126  \n",
      "\n",
      "Fold: 1  Epoch: 426  Training loss = 3.4259  Validation loss = 3.7122  \n",
      "\n",
      "Fold: 1  Epoch: 427  Training loss = 3.4257  Validation loss = 3.7119  \n",
      "\n",
      "Fold: 1  Epoch: 428  Training loss = 3.4254  Validation loss = 3.7114  \n",
      "\n",
      "Fold: 1  Epoch: 429  Training loss = 3.4252  Validation loss = 3.7110  \n",
      "\n",
      "Fold: 1  Epoch: 430  Training loss = 3.4250  Validation loss = 3.7107  \n",
      "\n",
      "Fold: 1  Epoch: 431  Training loss = 3.4247  Validation loss = 3.7103  \n",
      "\n",
      "Fold: 1  Epoch: 432  Training loss = 3.4245  Validation loss = 3.7099  \n",
      "\n",
      "Fold: 1  Epoch: 433  Training loss = 3.4243  Validation loss = 3.7095  \n",
      "\n",
      "Fold: 1  Epoch: 434  Training loss = 3.4241  Validation loss = 3.7092  \n",
      "\n",
      "Fold: 1  Epoch: 435  Training loss = 3.4238  Validation loss = 3.7087  \n",
      "\n",
      "Fold: 1  Epoch: 436  Training loss = 3.4235  Validation loss = 3.7083  \n",
      "\n",
      "Fold: 1  Epoch: 437  Training loss = 3.4233  Validation loss = 3.7079  \n",
      "\n",
      "Fold: 1  Epoch: 438  Training loss = 3.4231  Validation loss = 3.7076  \n",
      "\n",
      "Fold: 1  Epoch: 439  Training loss = 3.4229  Validation loss = 3.7071  \n",
      "\n",
      "Fold: 1  Epoch: 440  Training loss = 3.4226  Validation loss = 3.7067  \n",
      "\n",
      "Fold: 1  Epoch: 441  Training loss = 3.4224  Validation loss = 3.7063  \n",
      "\n",
      "Fold: 1  Epoch: 442  Training loss = 3.4221  Validation loss = 3.7059  \n",
      "\n",
      "Fold: 1  Epoch: 443  Training loss = 3.4219  Validation loss = 3.7054  \n",
      "\n",
      "Fold: 1  Epoch: 444  Training loss = 3.4217  Validation loss = 3.7051  \n",
      "\n",
      "Fold: 1  Epoch: 445  Training loss = 3.4214  Validation loss = 3.7047  \n",
      "\n",
      "Fold: 1  Epoch: 446  Training loss = 3.4212  Validation loss = 3.7043  \n",
      "\n",
      "Fold: 1  Epoch: 447  Training loss = 3.4210  Validation loss = 3.7039  \n",
      "\n",
      "Fold: 1  Epoch: 448  Training loss = 3.4208  Validation loss = 3.7035  \n",
      "\n",
      "Fold: 1  Epoch: 449  Training loss = 3.4206  Validation loss = 3.7032  \n",
      "\n",
      "Fold: 1  Epoch: 450  Training loss = 3.4203  Validation loss = 3.7028  \n",
      "\n",
      "Fold: 1  Epoch: 451  Training loss = 3.4201  Validation loss = 3.7024  \n",
      "\n",
      "Fold: 1  Epoch: 452  Training loss = 3.4199  Validation loss = 3.7020  \n",
      "\n",
      "Fold: 1  Epoch: 453  Training loss = 3.4197  Validation loss = 3.7017  \n",
      "\n",
      "Fold: 1  Epoch: 454  Training loss = 3.4195  Validation loss = 3.7013  \n",
      "\n",
      "Fold: 1  Epoch: 455  Training loss = 3.4193  Validation loss = 3.7010  \n",
      "\n",
      "Fold: 1  Epoch: 456  Training loss = 3.4190  Validation loss = 3.7005  \n",
      "\n",
      "Fold: 1  Epoch: 457  Training loss = 3.4187  Validation loss = 3.7000  \n",
      "\n",
      "Fold: 1  Epoch: 458  Training loss = 3.4185  Validation loss = 3.6996  \n",
      "\n",
      "Fold: 1  Epoch: 459  Training loss = 3.4183  Validation loss = 3.6993  \n",
      "\n",
      "Fold: 1  Epoch: 460  Training loss = 3.4181  Validation loss = 3.6989  \n",
      "\n",
      "Fold: 1  Epoch: 461  Training loss = 3.4178  Validation loss = 3.6985  \n",
      "\n",
      "Fold: 1  Epoch: 462  Training loss = 3.4176  Validation loss = 3.6981  \n",
      "\n",
      "Fold: 1  Epoch: 463  Training loss = 3.4174  Validation loss = 3.6977  \n",
      "\n",
      "Fold: 1  Epoch: 464  Training loss = 3.4171  Validation loss = 3.6973  \n",
      "\n",
      "Fold: 1  Epoch: 465  Training loss = 3.4169  Validation loss = 3.6969  \n",
      "\n",
      "Fold: 1  Epoch: 466  Training loss = 3.4167  Validation loss = 3.6966  \n",
      "\n",
      "Fold: 1  Epoch: 467  Training loss = 3.4164  Validation loss = 3.6962  \n",
      "\n",
      "Fold: 1  Epoch: 468  Training loss = 3.4162  Validation loss = 3.6958  \n",
      "\n",
      "Fold: 1  Epoch: 469  Training loss = 3.4160  Validation loss = 3.6954  \n",
      "\n",
      "Fold: 1  Epoch: 470  Training loss = 3.4158  Validation loss = 3.6951  \n",
      "\n",
      "Fold: 1  Epoch: 471  Training loss = 3.4156  Validation loss = 3.6947  \n",
      "\n",
      "Fold: 1  Epoch: 472  Training loss = 3.4153  Validation loss = 3.6942  \n",
      "\n",
      "Fold: 1  Epoch: 473  Training loss = 3.4151  Validation loss = 3.6939  \n",
      "\n",
      "Fold: 1  Epoch: 474  Training loss = 3.4149  Validation loss = 3.6935  \n",
      "\n",
      "Fold: 1  Epoch: 475  Training loss = 3.4147  Validation loss = 3.6931  \n",
      "\n",
      "Fold: 1  Epoch: 476  Training loss = 3.4145  Validation loss = 3.6927  \n",
      "\n",
      "Fold: 1  Epoch: 477  Training loss = 3.4142  Validation loss = 3.6923  \n",
      "\n",
      "Fold: 1  Epoch: 478  Training loss = 3.4140  Validation loss = 3.6919  \n",
      "\n",
      "Fold: 1  Epoch: 479  Training loss = 3.4138  Validation loss = 3.6915  \n",
      "\n",
      "Fold: 1  Epoch: 480  Training loss = 3.4135  Validation loss = 3.6911  \n",
      "\n",
      "Fold: 1  Epoch: 481  Training loss = 3.4133  Validation loss = 3.6907  \n",
      "\n",
      "Fold: 1  Epoch: 482  Training loss = 3.4130  Validation loss = 3.6903  \n",
      "\n",
      "Fold: 1  Epoch: 483  Training loss = 3.4128  Validation loss = 3.6898  \n",
      "\n",
      "Fold: 1  Epoch: 484  Training loss = 3.4125  Validation loss = 3.6894  \n",
      "\n",
      "Fold: 1  Epoch: 485  Training loss = 3.4123  Validation loss = 3.6890  \n",
      "\n",
      "Fold: 1  Epoch: 486  Training loss = 3.4121  Validation loss = 3.6886  \n",
      "\n",
      "Fold: 1  Epoch: 487  Training loss = 3.4119  Validation loss = 3.6883  \n",
      "\n",
      "Fold: 1  Epoch: 488  Training loss = 3.4117  Validation loss = 3.6879  \n",
      "\n",
      "Fold: 1  Epoch: 489  Training loss = 3.4115  Validation loss = 3.6876  \n",
      "\n",
      "Fold: 1  Epoch: 490  Training loss = 3.4113  Validation loss = 3.6872  \n",
      "\n",
      "Fold: 1  Epoch: 491  Training loss = 3.4111  Validation loss = 3.6869  \n",
      "\n",
      "Fold: 1  Epoch: 492  Training loss = 3.4109  Validation loss = 3.6865  \n",
      "\n",
      "Fold: 1  Epoch: 493  Training loss = 3.4106  Validation loss = 3.6861  \n",
      "\n",
      "Fold: 1  Epoch: 494  Training loss = 3.4104  Validation loss = 3.6857  \n",
      "\n",
      "Fold: 1  Epoch: 495  Training loss = 3.4102  Validation loss = 3.6853  \n",
      "\n",
      "Fold: 1  Epoch: 496  Training loss = 3.4099  Validation loss = 3.6849  \n",
      "\n",
      "Fold: 1  Epoch: 497  Training loss = 3.4097  Validation loss = 3.6845  \n",
      "\n",
      "Fold: 1  Epoch: 498  Training loss = 3.4095  Validation loss = 3.6841  \n",
      "\n",
      "Fold: 1  Epoch: 499  Training loss = 3.4093  Validation loss = 3.6838  \n",
      "\n",
      "Fold: 1  Epoch: 500  Training loss = 3.4090  Validation loss = 3.6833  \n",
      "\n",
      "Check model:  Fold: 1  Optimal epoch: 500  \n",
      "\n",
      "Fold: 2  Epoch: 1  Training loss = 3.3783  Validation loss = 3.6038  \n",
      "\n",
      "Fold: 2  Epoch: 2  Training loss = 3.3780  Validation loss = 3.6035  \n",
      "\n",
      "Fold: 2  Epoch: 3  Training loss = 3.3778  Validation loss = 3.6031  \n",
      "\n",
      "Fold: 2  Epoch: 4  Training loss = 3.3775  Validation loss = 3.6027  \n",
      "\n",
      "Fold: 2  Epoch: 5  Training loss = 3.3773  Validation loss = 3.6023  \n",
      "\n",
      "Fold: 2  Epoch: 6  Training loss = 3.3770  Validation loss = 3.6019  \n",
      "\n",
      "Fold: 2  Epoch: 7  Training loss = 3.3767  Validation loss = 3.6016  \n",
      "\n",
      "Fold: 2  Epoch: 8  Training loss = 3.3765  Validation loss = 3.6012  \n",
      "\n",
      "Fold: 2  Epoch: 9  Training loss = 3.3762  Validation loss = 3.6009  \n",
      "\n",
      "Fold: 2  Epoch: 10  Training loss = 3.3760  Validation loss = 3.6005  \n",
      "\n",
      "Fold: 2  Epoch: 11  Training loss = 3.3758  Validation loss = 3.6002  \n",
      "\n",
      "Fold: 2  Epoch: 12  Training loss = 3.3755  Validation loss = 3.5998  \n",
      "\n",
      "Fold: 2  Epoch: 13  Training loss = 3.3753  Validation loss = 3.5995  \n",
      "\n",
      "Fold: 2  Epoch: 14  Training loss = 3.3751  Validation loss = 3.5992  \n",
      "\n",
      "Fold: 2  Epoch: 15  Training loss = 3.3747  Validation loss = 3.5987  \n",
      "\n",
      "Fold: 2  Epoch: 16  Training loss = 3.3746  Validation loss = 3.5985  \n",
      "\n",
      "Fold: 2  Epoch: 17  Training loss = 3.3743  Validation loss = 3.5981  \n",
      "\n",
      "Fold: 2  Epoch: 18  Training loss = 3.3740  Validation loss = 3.5977  \n",
      "\n",
      "Fold: 2  Epoch: 19  Training loss = 3.3738  Validation loss = 3.5973  \n",
      "\n",
      "Fold: 2  Epoch: 20  Training loss = 3.3735  Validation loss = 3.5970  \n",
      "\n",
      "Fold: 2  Epoch: 21  Training loss = 3.3733  Validation loss = 3.5967  \n",
      "\n",
      "Fold: 2  Epoch: 22  Training loss = 3.3731  Validation loss = 3.5964  \n",
      "\n",
      "Fold: 2  Epoch: 23  Training loss = 3.3729  Validation loss = 3.5961  \n",
      "\n",
      "Fold: 2  Epoch: 24  Training loss = 3.3727  Validation loss = 3.5957  \n",
      "\n",
      "Fold: 2  Epoch: 25  Training loss = 3.3724  Validation loss = 3.5953  \n",
      "\n",
      "Fold: 2  Epoch: 26  Training loss = 3.3721  Validation loss = 3.5949  \n",
      "\n",
      "Fold: 2  Epoch: 27  Training loss = 3.3718  Validation loss = 3.5945  \n",
      "\n",
      "Fold: 2  Epoch: 28  Training loss = 3.3716  Validation loss = 3.5942  \n",
      "\n",
      "Fold: 2  Epoch: 29  Training loss = 3.3713  Validation loss = 3.5938  \n",
      "\n",
      "Fold: 2  Epoch: 30  Training loss = 3.3711  Validation loss = 3.5935  \n",
      "\n",
      "Fold: 2  Epoch: 31  Training loss = 3.3709  Validation loss = 3.5931  \n",
      "\n",
      "Fold: 2  Epoch: 32  Training loss = 3.3706  Validation loss = 3.5928  \n",
      "\n",
      "Fold: 2  Epoch: 33  Training loss = 3.3703  Validation loss = 3.5923  \n",
      "\n",
      "Fold: 2  Epoch: 34  Training loss = 3.3700  Validation loss = 3.5919  \n",
      "\n",
      "Fold: 2  Epoch: 35  Training loss = 3.3697  Validation loss = 3.5915  \n",
      "\n",
      "Fold: 2  Epoch: 36  Training loss = 3.3695  Validation loss = 3.5912  \n",
      "\n",
      "Fold: 2  Epoch: 37  Training loss = 3.3692  Validation loss = 3.5908  \n",
      "\n",
      "Fold: 2  Epoch: 38  Training loss = 3.3690  Validation loss = 3.5904  \n",
      "\n",
      "Fold: 2  Epoch: 39  Training loss = 3.3688  Validation loss = 3.5901  \n",
      "\n",
      "Fold: 2  Epoch: 40  Training loss = 3.3685  Validation loss = 3.5897  \n",
      "\n",
      "Fold: 2  Epoch: 41  Training loss = 3.3683  Validation loss = 3.5894  \n",
      "\n",
      "Fold: 2  Epoch: 42  Training loss = 3.3680  Validation loss = 3.5891  \n",
      "\n",
      "Fold: 2  Epoch: 43  Training loss = 3.3678  Validation loss = 3.5887  \n",
      "\n",
      "Fold: 2  Epoch: 44  Training loss = 3.3676  Validation loss = 3.5884  \n",
      "\n",
      "Fold: 2  Epoch: 45  Training loss = 3.3673  Validation loss = 3.5880  \n",
      "\n",
      "Fold: 2  Epoch: 46  Training loss = 3.3670  Validation loss = 3.5876  \n",
      "\n",
      "Fold: 2  Epoch: 47  Training loss = 3.3668  Validation loss = 3.5872  \n",
      "\n",
      "Fold: 2  Epoch: 48  Training loss = 3.3665  Validation loss = 3.5869  \n",
      "\n",
      "Fold: 2  Epoch: 49  Training loss = 3.3663  Validation loss = 3.5865  \n",
      "\n",
      "Fold: 2  Epoch: 50  Training loss = 3.3660  Validation loss = 3.5861  \n",
      "\n",
      "Fold: 2  Epoch: 51  Training loss = 3.3657  Validation loss = 3.5858  \n",
      "\n",
      "Fold: 2  Epoch: 52  Training loss = 3.3655  Validation loss = 3.5854  \n",
      "\n",
      "Fold: 2  Epoch: 53  Training loss = 3.3652  Validation loss = 3.5850  \n",
      "\n",
      "Fold: 2  Epoch: 54  Training loss = 3.3649  Validation loss = 3.5846  \n",
      "\n",
      "Fold: 2  Epoch: 55  Training loss = 3.3648  Validation loss = 3.5844  \n",
      "\n",
      "Fold: 2  Epoch: 56  Training loss = 3.3645  Validation loss = 3.5840  \n",
      "\n",
      "Fold: 2  Epoch: 57  Training loss = 3.3642  Validation loss = 3.5836  \n",
      "\n",
      "Fold: 2  Epoch: 58  Training loss = 3.3639  Validation loss = 3.5832  \n",
      "\n",
      "Fold: 2  Epoch: 59  Training loss = 3.3637  Validation loss = 3.5829  \n",
      "\n",
      "Fold: 2  Epoch: 60  Training loss = 3.3634  Validation loss = 3.5825  \n",
      "\n",
      "Fold: 2  Epoch: 61  Training loss = 3.3632  Validation loss = 3.5822  \n",
      "\n",
      "Fold: 2  Epoch: 62  Training loss = 3.3629  Validation loss = 3.5817  \n",
      "\n",
      "Fold: 2  Epoch: 63  Training loss = 3.3627  Validation loss = 3.5814  \n",
      "\n",
      "Fold: 2  Epoch: 64  Training loss = 3.3624  Validation loss = 3.5810  \n",
      "\n",
      "Fold: 2  Epoch: 65  Training loss = 3.3622  Validation loss = 3.5807  \n",
      "\n",
      "Fold: 2  Epoch: 66  Training loss = 3.3620  Validation loss = 3.5803  \n",
      "\n",
      "Fold: 2  Epoch: 67  Training loss = 3.3617  Validation loss = 3.5800  \n",
      "\n",
      "Fold: 2  Epoch: 68  Training loss = 3.3614  Validation loss = 3.5795  \n",
      "\n",
      "Fold: 2  Epoch: 69  Training loss = 3.3611  Validation loss = 3.5791  \n",
      "\n",
      "Fold: 2  Epoch: 70  Training loss = 3.3608  Validation loss = 3.5787  \n",
      "\n",
      "Fold: 2  Epoch: 71  Training loss = 3.3605  Validation loss = 3.5783  \n",
      "\n",
      "Fold: 2  Epoch: 72  Training loss = 3.3603  Validation loss = 3.5780  \n",
      "\n",
      "Fold: 2  Epoch: 73  Training loss = 3.3601  Validation loss = 3.5777  \n",
      "\n",
      "Fold: 2  Epoch: 74  Training loss = 3.3598  Validation loss = 3.5773  \n",
      "\n",
      "Fold: 2  Epoch: 75  Training loss = 3.3596  Validation loss = 3.5770  \n",
      "\n",
      "Fold: 2  Epoch: 76  Training loss = 3.3594  Validation loss = 3.5767  \n",
      "\n",
      "Fold: 2  Epoch: 77  Training loss = 3.3591  Validation loss = 3.5763  \n",
      "\n",
      "Fold: 2  Epoch: 78  Training loss = 3.3589  Validation loss = 3.5760  \n",
      "\n",
      "Fold: 2  Epoch: 79  Training loss = 3.3587  Validation loss = 3.5757  \n",
      "\n",
      "Fold: 2  Epoch: 80  Training loss = 3.3584  Validation loss = 3.5752  \n",
      "\n",
      "Fold: 2  Epoch: 81  Training loss = 3.3582  Validation loss = 3.5749  \n",
      "\n",
      "Fold: 2  Epoch: 82  Training loss = 3.3579  Validation loss = 3.5745  \n",
      "\n",
      "Fold: 2  Epoch: 83  Training loss = 3.3577  Validation loss = 3.5742  \n",
      "\n",
      "Fold: 2  Epoch: 84  Training loss = 3.3574  Validation loss = 3.5739  \n",
      "\n",
      "Fold: 2  Epoch: 85  Training loss = 3.3572  Validation loss = 3.5736  \n",
      "\n",
      "Fold: 2  Epoch: 86  Training loss = 3.3569  Validation loss = 3.5732  \n",
      "\n",
      "Fold: 2  Epoch: 87  Training loss = 3.3567  Validation loss = 3.5728  \n",
      "\n",
      "Fold: 2  Epoch: 88  Training loss = 3.3564  Validation loss = 3.5724  \n",
      "\n",
      "Fold: 2  Epoch: 89  Training loss = 3.3562  Validation loss = 3.5721  \n",
      "\n",
      "Fold: 2  Epoch: 90  Training loss = 3.3559  Validation loss = 3.5718  \n",
      "\n",
      "Fold: 2  Epoch: 91  Training loss = 3.3556  Validation loss = 3.5713  \n",
      "\n",
      "Fold: 2  Epoch: 92  Training loss = 3.3554  Validation loss = 3.5710  \n",
      "\n",
      "Fold: 2  Epoch: 93  Training loss = 3.3552  Validation loss = 3.5707  \n",
      "\n",
      "Fold: 2  Epoch: 94  Training loss = 3.3549  Validation loss = 3.5703  \n",
      "\n",
      "Fold: 2  Epoch: 95  Training loss = 3.3547  Validation loss = 3.5700  \n",
      "\n",
      "Fold: 2  Epoch: 96  Training loss = 3.3545  Validation loss = 3.5697  \n",
      "\n",
      "Fold: 2  Epoch: 97  Training loss = 3.3543  Validation loss = 3.5694  \n",
      "\n",
      "Fold: 2  Epoch: 98  Training loss = 3.3540  Validation loss = 3.5689  \n",
      "\n",
      "Fold: 2  Epoch: 99  Training loss = 3.3537  Validation loss = 3.5686  \n",
      "\n",
      "Fold: 2  Epoch: 100  Training loss = 3.3535  Validation loss = 3.5682  \n",
      "\n",
      "Fold: 2  Epoch: 101  Training loss = 3.3532  Validation loss = 3.5678  \n",
      "\n",
      "Fold: 2  Epoch: 102  Training loss = 3.3529  Validation loss = 3.5674  \n",
      "\n",
      "Fold: 2  Epoch: 103  Training loss = 3.3527  Validation loss = 3.5670  \n",
      "\n",
      "Fold: 2  Epoch: 104  Training loss = 3.3525  Validation loss = 3.5667  \n",
      "\n",
      "Fold: 2  Epoch: 105  Training loss = 3.3522  Validation loss = 3.5664  \n",
      "\n",
      "Fold: 2  Epoch: 106  Training loss = 3.3520  Validation loss = 3.5661  \n",
      "\n",
      "Fold: 2  Epoch: 107  Training loss = 3.3518  Validation loss = 3.5657  \n",
      "\n",
      "Fold: 2  Epoch: 108  Training loss = 3.3515  Validation loss = 3.5653  \n",
      "\n",
      "Fold: 2  Epoch: 109  Training loss = 3.3513  Validation loss = 3.5650  \n",
      "\n",
      "Fold: 2  Epoch: 110  Training loss = 3.3511  Validation loss = 3.5647  \n",
      "\n",
      "Fold: 2  Epoch: 111  Training loss = 3.3509  Validation loss = 3.5643  \n",
      "\n",
      "Fold: 2  Epoch: 112  Training loss = 3.3506  Validation loss = 3.5640  \n",
      "\n",
      "Fold: 2  Epoch: 113  Training loss = 3.3503  Validation loss = 3.5636  \n",
      "\n",
      "Fold: 2  Epoch: 114  Training loss = 3.3500  Validation loss = 3.5632  \n",
      "\n",
      "Fold: 2  Epoch: 115  Training loss = 3.3497  Validation loss = 3.5627  \n",
      "\n",
      "Fold: 2  Epoch: 116  Training loss = 3.3495  Validation loss = 3.5624  \n",
      "\n",
      "Fold: 2  Epoch: 117  Training loss = 3.3493  Validation loss = 3.5620  \n",
      "\n",
      "Fold: 2  Epoch: 118  Training loss = 3.3490  Validation loss = 3.5616  \n",
      "\n",
      "Fold: 2  Epoch: 119  Training loss = 3.3488  Validation loss = 3.5613  \n",
      "\n",
      "Fold: 2  Epoch: 120  Training loss = 3.3485  Validation loss = 3.5609  \n",
      "\n",
      "Fold: 2  Epoch: 121  Training loss = 3.3482  Validation loss = 3.5605  \n",
      "\n",
      "Fold: 2  Epoch: 122  Training loss = 3.3480  Validation loss = 3.5601  \n",
      "\n",
      "Fold: 2  Epoch: 123  Training loss = 3.3477  Validation loss = 3.5597  \n",
      "\n",
      "Fold: 2  Epoch: 124  Training loss = 3.3474  Validation loss = 3.5593  \n",
      "\n",
      "Fold: 2  Epoch: 125  Training loss = 3.3472  Validation loss = 3.5590  \n",
      "\n",
      "Fold: 2  Epoch: 126  Training loss = 3.3469  Validation loss = 3.5586  \n",
      "\n",
      "Fold: 2  Epoch: 127  Training loss = 3.3467  Validation loss = 3.5582  \n",
      "\n",
      "Fold: 2  Epoch: 128  Training loss = 3.3464  Validation loss = 3.5579  \n",
      "\n",
      "Fold: 2  Epoch: 129  Training loss = 3.3462  Validation loss = 3.5575  \n",
      "\n",
      "Fold: 2  Epoch: 130  Training loss = 3.3459  Validation loss = 3.5571  \n",
      "\n",
      "Fold: 2  Epoch: 131  Training loss = 3.3457  Validation loss = 3.5567  \n",
      "\n",
      "Fold: 2  Epoch: 132  Training loss = 3.3454  Validation loss = 3.5564  \n",
      "\n",
      "Fold: 2  Epoch: 133  Training loss = 3.3451  Validation loss = 3.5560  \n",
      "\n",
      "Fold: 2  Epoch: 134  Training loss = 3.3448  Validation loss = 3.5555  \n",
      "\n",
      "Fold: 2  Epoch: 135  Training loss = 3.3446  Validation loss = 3.5552  \n",
      "\n",
      "Fold: 2  Epoch: 136  Training loss = 3.3443  Validation loss = 3.5548  \n",
      "\n",
      "Fold: 2  Epoch: 137  Training loss = 3.3441  Validation loss = 3.5545  \n",
      "\n",
      "Fold: 2  Epoch: 138  Training loss = 3.3439  Validation loss = 3.5542  \n",
      "\n",
      "Fold: 2  Epoch: 139  Training loss = 3.3436  Validation loss = 3.5538  \n",
      "\n",
      "Fold: 2  Epoch: 140  Training loss = 3.3434  Validation loss = 3.5535  \n",
      "\n",
      "Fold: 2  Epoch: 141  Training loss = 3.3432  Validation loss = 3.5531  \n",
      "\n",
      "Fold: 2  Epoch: 142  Training loss = 3.3429  Validation loss = 3.5528  \n",
      "\n",
      "Fold: 2  Epoch: 143  Training loss = 3.3427  Validation loss = 3.5524  \n",
      "\n",
      "Fold: 2  Epoch: 144  Training loss = 3.3424  Validation loss = 3.5520  \n",
      "\n",
      "Fold: 2  Epoch: 145  Training loss = 3.3421  Validation loss = 3.5516  \n",
      "\n",
      "Fold: 2  Epoch: 146  Training loss = 3.3419  Validation loss = 3.5512  \n",
      "\n",
      "Fold: 2  Epoch: 147  Training loss = 3.3416  Validation loss = 3.5509  \n",
      "\n",
      "Fold: 2  Epoch: 148  Training loss = 3.3414  Validation loss = 3.5505  \n",
      "\n",
      "Fold: 2  Epoch: 149  Training loss = 3.3411  Validation loss = 3.5502  \n",
      "\n",
      "Fold: 2  Epoch: 150  Training loss = 3.3409  Validation loss = 3.5498  \n",
      "\n",
      "Fold: 2  Epoch: 151  Training loss = 3.3407  Validation loss = 3.5495  \n",
      "\n",
      "Fold: 2  Epoch: 152  Training loss = 3.3405  Validation loss = 3.5492  \n",
      "\n",
      "Fold: 2  Epoch: 153  Training loss = 3.3402  Validation loss = 3.5488  \n",
      "\n",
      "Fold: 2  Epoch: 154  Training loss = 3.3400  Validation loss = 3.5485  \n",
      "\n",
      "Fold: 2  Epoch: 155  Training loss = 3.3397  Validation loss = 3.5481  \n",
      "\n",
      "Fold: 2  Epoch: 156  Training loss = 3.3395  Validation loss = 3.5477  \n",
      "\n",
      "Fold: 2  Epoch: 157  Training loss = 3.3392  Validation loss = 3.5474  \n",
      "\n",
      "Fold: 2  Epoch: 158  Training loss = 3.3390  Validation loss = 3.5470  \n",
      "\n",
      "Fold: 2  Epoch: 159  Training loss = 3.3387  Validation loss = 3.5466  \n",
      "\n",
      "Fold: 2  Epoch: 160  Training loss = 3.3385  Validation loss = 3.5463  \n",
      "\n",
      "Fold: 2  Epoch: 161  Training loss = 3.3383  Validation loss = 3.5460  \n",
      "\n",
      "Fold: 2  Epoch: 162  Training loss = 3.3380  Validation loss = 3.5456  \n",
      "\n",
      "Fold: 2  Epoch: 163  Training loss = 3.3377  Validation loss = 3.5452  \n",
      "\n",
      "Fold: 2  Epoch: 164  Training loss = 3.3375  Validation loss = 3.5449  \n",
      "\n",
      "Fold: 2  Epoch: 165  Training loss = 3.3373  Validation loss = 3.5445  \n",
      "\n",
      "Fold: 2  Epoch: 166  Training loss = 3.3370  Validation loss = 3.5441  \n",
      "\n",
      "Fold: 2  Epoch: 167  Training loss = 3.3367  Validation loss = 3.5437  \n",
      "\n",
      "Fold: 2  Epoch: 168  Training loss = 3.3365  Validation loss = 3.5434  \n",
      "\n",
      "Fold: 2  Epoch: 169  Training loss = 3.3363  Validation loss = 3.5431  \n",
      "\n",
      "Fold: 2  Epoch: 170  Training loss = 3.3361  Validation loss = 3.5428  \n",
      "\n",
      "Fold: 2  Epoch: 171  Training loss = 3.3358  Validation loss = 3.5424  \n",
      "\n",
      "Fold: 2  Epoch: 172  Training loss = 3.3356  Validation loss = 3.5420  \n",
      "\n",
      "Fold: 2  Epoch: 173  Training loss = 3.3353  Validation loss = 3.5416  \n",
      "\n",
      "Fold: 2  Epoch: 174  Training loss = 3.3350  Validation loss = 3.5412  \n",
      "\n",
      "Fold: 2  Epoch: 175  Training loss = 3.3348  Validation loss = 3.5408  \n",
      "\n",
      "Fold: 2  Epoch: 176  Training loss = 3.3345  Validation loss = 3.5405  \n",
      "\n",
      "Fold: 2  Epoch: 177  Training loss = 3.3343  Validation loss = 3.5402  \n",
      "\n",
      "Fold: 2  Epoch: 178  Training loss = 3.3340  Validation loss = 3.5398  \n",
      "\n",
      "Fold: 2  Epoch: 179  Training loss = 3.3338  Validation loss = 3.5394  \n",
      "\n",
      "Fold: 2  Epoch: 180  Training loss = 3.3335  Validation loss = 3.5390  \n",
      "\n",
      "Fold: 2  Epoch: 181  Training loss = 3.3332  Validation loss = 3.5385  \n",
      "\n",
      "Fold: 2  Epoch: 182  Training loss = 3.3330  Validation loss = 3.5382  \n",
      "\n",
      "Fold: 2  Epoch: 183  Training loss = 3.3327  Validation loss = 3.5378  \n",
      "\n",
      "Fold: 2  Epoch: 184  Training loss = 3.3325  Validation loss = 3.5375  \n",
      "\n",
      "Fold: 2  Epoch: 185  Training loss = 3.3322  Validation loss = 3.5371  \n",
      "\n",
      "Fold: 2  Epoch: 186  Training loss = 3.3320  Validation loss = 3.5368  \n",
      "\n",
      "Fold: 2  Epoch: 187  Training loss = 3.3318  Validation loss = 3.5364  \n",
      "\n",
      "Fold: 2  Epoch: 188  Training loss = 3.3315  Validation loss = 3.5361  \n",
      "\n",
      "Fold: 2  Epoch: 189  Training loss = 3.3312  Validation loss = 3.5357  \n",
      "\n",
      "Fold: 2  Epoch: 190  Training loss = 3.3310  Validation loss = 3.5353  \n",
      "\n",
      "Fold: 2  Epoch: 191  Training loss = 3.3307  Validation loss = 3.5350  \n",
      "\n",
      "Fold: 2  Epoch: 192  Training loss = 3.3305  Validation loss = 3.5346  \n",
      "\n",
      "Fold: 2  Epoch: 193  Training loss = 3.3302  Validation loss = 3.5342  \n",
      "\n",
      "Fold: 2  Epoch: 194  Training loss = 3.3300  Validation loss = 3.5339  \n",
      "\n",
      "Fold: 2  Epoch: 195  Training loss = 3.3297  Validation loss = 3.5336  \n",
      "\n",
      "Fold: 2  Epoch: 196  Training loss = 3.3295  Validation loss = 3.5332  \n",
      "\n",
      "Fold: 2  Epoch: 197  Training loss = 3.3292  Validation loss = 3.5329  \n",
      "\n",
      "Fold: 2  Epoch: 198  Training loss = 3.3290  Validation loss = 3.5325  \n",
      "\n",
      "Fold: 2  Epoch: 199  Training loss = 3.3287  Validation loss = 3.5321  \n",
      "\n",
      "Fold: 2  Epoch: 200  Training loss = 3.3285  Validation loss = 3.5318  \n",
      "\n",
      "Fold: 2  Epoch: 201  Training loss = 3.3283  Validation loss = 3.5314  \n",
      "\n",
      "Fold: 2  Epoch: 202  Training loss = 3.3280  Validation loss = 3.5311  \n",
      "\n",
      "Fold: 2  Epoch: 203  Training loss = 3.3278  Validation loss = 3.5308  \n",
      "\n",
      "Fold: 2  Epoch: 204  Training loss = 3.3276  Validation loss = 3.5304  \n",
      "\n",
      "Fold: 2  Epoch: 205  Training loss = 3.3273  Validation loss = 3.5300  \n",
      "\n",
      "Fold: 2  Epoch: 206  Training loss = 3.3270  Validation loss = 3.5297  \n",
      "\n",
      "Fold: 2  Epoch: 207  Training loss = 3.3268  Validation loss = 3.5293  \n",
      "\n",
      "Fold: 2  Epoch: 208  Training loss = 3.3266  Validation loss = 3.5289  \n",
      "\n",
      "Fold: 2  Epoch: 209  Training loss = 3.3264  Validation loss = 3.5287  \n",
      "\n",
      "Fold: 2  Epoch: 210  Training loss = 3.3261  Validation loss = 3.5283  \n",
      "\n",
      "Fold: 2  Epoch: 211  Training loss = 3.3259  Validation loss = 3.5280  \n",
      "\n",
      "Fold: 2  Epoch: 212  Training loss = 3.3256  Validation loss = 3.5276  \n",
      "\n",
      "Fold: 2  Epoch: 213  Training loss = 3.3254  Validation loss = 3.5272  \n",
      "\n",
      "Fold: 2  Epoch: 214  Training loss = 3.3251  Validation loss = 3.5268  \n",
      "\n",
      "Fold: 2  Epoch: 215  Training loss = 3.3248  Validation loss = 3.5264  \n",
      "\n",
      "Fold: 2  Epoch: 216  Training loss = 3.3246  Validation loss = 3.5261  \n",
      "\n",
      "Fold: 2  Epoch: 217  Training loss = 3.3244  Validation loss = 3.5257  \n",
      "\n",
      "Fold: 2  Epoch: 218  Training loss = 3.3241  Validation loss = 3.5254  \n",
      "\n",
      "Fold: 2  Epoch: 219  Training loss = 3.3239  Validation loss = 3.5250  \n",
      "\n",
      "Fold: 2  Epoch: 220  Training loss = 3.3236  Validation loss = 3.5247  \n",
      "\n",
      "Fold: 2  Epoch: 221  Training loss = 3.3234  Validation loss = 3.5244  \n",
      "\n",
      "Fold: 2  Epoch: 222  Training loss = 3.3231  Validation loss = 3.5240  \n",
      "\n",
      "Fold: 2  Epoch: 223  Training loss = 3.3229  Validation loss = 3.5236  \n",
      "\n",
      "Fold: 2  Epoch: 224  Training loss = 3.3226  Validation loss = 3.5233  \n",
      "\n",
      "Fold: 2  Epoch: 225  Training loss = 3.3223  Validation loss = 3.5229  \n",
      "\n",
      "Fold: 2  Epoch: 226  Training loss = 3.3221  Validation loss = 3.5225  \n",
      "\n",
      "Fold: 2  Epoch: 227  Training loss = 3.3218  Validation loss = 3.5221  \n",
      "\n",
      "Fold: 2  Epoch: 228  Training loss = 3.3216  Validation loss = 3.5218  \n",
      "\n",
      "Fold: 2  Epoch: 229  Training loss = 3.3214  Validation loss = 3.5215  \n",
      "\n",
      "Fold: 2  Epoch: 230  Training loss = 3.3212  Validation loss = 3.5211  \n",
      "\n",
      "Fold: 2  Epoch: 231  Training loss = 3.3209  Validation loss = 3.5208  \n",
      "\n",
      "Fold: 2  Epoch: 232  Training loss = 3.3206  Validation loss = 3.5204  \n",
      "\n",
      "Fold: 2  Epoch: 233  Training loss = 3.3205  Validation loss = 3.5201  \n",
      "\n",
      "Fold: 2  Epoch: 234  Training loss = 3.3202  Validation loss = 3.5197  \n",
      "\n",
      "Fold: 2  Epoch: 235  Training loss = 3.3200  Validation loss = 3.5194  \n",
      "\n",
      "Fold: 2  Epoch: 236  Training loss = 3.3198  Validation loss = 3.5191  \n",
      "\n",
      "Fold: 2  Epoch: 237  Training loss = 3.3195  Validation loss = 3.5187  \n",
      "\n",
      "Fold: 2  Epoch: 238  Training loss = 3.3192  Validation loss = 3.5183  \n",
      "\n",
      "Fold: 2  Epoch: 239  Training loss = 3.3189  Validation loss = 3.5179  \n",
      "\n",
      "Fold: 2  Epoch: 240  Training loss = 3.3187  Validation loss = 3.5176  \n",
      "\n",
      "Fold: 2  Epoch: 241  Training loss = 3.3185  Validation loss = 3.5172  \n",
      "\n",
      "Fold: 2  Epoch: 242  Training loss = 3.3182  Validation loss = 3.5168  \n",
      "\n",
      "Fold: 2  Epoch: 243  Training loss = 3.3180  Validation loss = 3.5164  \n",
      "\n",
      "Fold: 2  Epoch: 244  Training loss = 3.3177  Validation loss = 3.5161  \n",
      "\n",
      "Fold: 2  Epoch: 245  Training loss = 3.3175  Validation loss = 3.5157  \n",
      "\n",
      "Fold: 2  Epoch: 246  Training loss = 3.3172  Validation loss = 3.5153  \n",
      "\n",
      "Fold: 2  Epoch: 247  Training loss = 3.3170  Validation loss = 3.5150  \n",
      "\n",
      "Fold: 2  Epoch: 248  Training loss = 3.3168  Validation loss = 3.5147  \n",
      "\n",
      "Fold: 2  Epoch: 249  Training loss = 3.3165  Validation loss = 3.5143  \n",
      "\n",
      "Fold: 2  Epoch: 250  Training loss = 3.3163  Validation loss = 3.5140  \n",
      "\n",
      "Fold: 2  Epoch: 251  Training loss = 3.3160  Validation loss = 3.5136  \n",
      "\n",
      "Fold: 2  Epoch: 252  Training loss = 3.3158  Validation loss = 3.5133  \n",
      "\n",
      "Fold: 2  Epoch: 253  Training loss = 3.3156  Validation loss = 3.5129  \n",
      "\n",
      "Fold: 2  Epoch: 254  Training loss = 3.3154  Validation loss = 3.5126  \n",
      "\n",
      "Fold: 2  Epoch: 255  Training loss = 3.3151  Validation loss = 3.5122  \n",
      "\n",
      "Fold: 2  Epoch: 256  Training loss = 3.3148  Validation loss = 3.5118  \n",
      "\n",
      "Fold: 2  Epoch: 257  Training loss = 3.3146  Validation loss = 3.5115  \n",
      "\n",
      "Fold: 2  Epoch: 258  Training loss = 3.3143  Validation loss = 3.5111  \n",
      "\n",
      "Fold: 2  Epoch: 259  Training loss = 3.3141  Validation loss = 3.5107  \n",
      "\n",
      "Fold: 2  Epoch: 260  Training loss = 3.3139  Validation loss = 3.5104  \n",
      "\n",
      "Fold: 2  Epoch: 261  Training loss = 3.3137  Validation loss = 3.5101  \n",
      "\n",
      "Fold: 2  Epoch: 262  Training loss = 3.3135  Validation loss = 3.5098  \n",
      "\n",
      "Fold: 2  Epoch: 263  Training loss = 3.3133  Validation loss = 3.5094  \n",
      "\n",
      "Fold: 2  Epoch: 264  Training loss = 3.3131  Validation loss = 3.5091  \n",
      "\n",
      "Fold: 2  Epoch: 265  Training loss = 3.3128  Validation loss = 3.5088  \n",
      "\n",
      "Fold: 2  Epoch: 266  Training loss = 3.3126  Validation loss = 3.5085  \n",
      "\n",
      "Fold: 2  Epoch: 267  Training loss = 3.3123  Validation loss = 3.5081  \n",
      "\n",
      "Fold: 2  Epoch: 268  Training loss = 3.3121  Validation loss = 3.5077  \n",
      "\n",
      "Fold: 2  Epoch: 269  Training loss = 3.3117  Validation loss = 3.5072  \n",
      "\n",
      "Fold: 2  Epoch: 270  Training loss = 3.3114  Validation loss = 3.5068  \n",
      "\n",
      "Fold: 2  Epoch: 271  Training loss = 3.3112  Validation loss = 3.5064  \n",
      "\n",
      "Fold: 2  Epoch: 272  Training loss = 3.3110  Validation loss = 3.5061  \n",
      "\n",
      "Fold: 2  Epoch: 273  Training loss = 3.3107  Validation loss = 3.5058  \n",
      "\n",
      "Fold: 2  Epoch: 274  Training loss = 3.3105  Validation loss = 3.5054  \n",
      "\n",
      "Fold: 2  Epoch: 275  Training loss = 3.3102  Validation loss = 3.5051  \n",
      "\n",
      "Fold: 2  Epoch: 276  Training loss = 3.3100  Validation loss = 3.5047  \n",
      "\n",
      "Fold: 2  Epoch: 277  Training loss = 3.3098  Validation loss = 3.5044  \n",
      "\n",
      "Fold: 2  Epoch: 278  Training loss = 3.3095  Validation loss = 3.5041  \n",
      "\n",
      "Fold: 2  Epoch: 279  Training loss = 3.3093  Validation loss = 3.5037  \n",
      "\n",
      "Fold: 2  Epoch: 280  Training loss = 3.3091  Validation loss = 3.5034  \n",
      "\n",
      "Fold: 2  Epoch: 281  Training loss = 3.3088  Validation loss = 3.5030  \n",
      "\n",
      "Fold: 2  Epoch: 282  Training loss = 3.3086  Validation loss = 3.5026  \n",
      "\n",
      "Fold: 2  Epoch: 283  Training loss = 3.3083  Validation loss = 3.5023  \n",
      "\n",
      "Fold: 2  Epoch: 284  Training loss = 3.3080  Validation loss = 3.5019  \n",
      "\n",
      "Fold: 2  Epoch: 285  Training loss = 3.3079  Validation loss = 3.5016  \n",
      "\n",
      "Fold: 2  Epoch: 286  Training loss = 3.3076  Validation loss = 3.5012  \n",
      "\n",
      "Fold: 2  Epoch: 287  Training loss = 3.3074  Validation loss = 3.5008  \n",
      "\n",
      "Fold: 2  Epoch: 288  Training loss = 3.3071  Validation loss = 3.5005  \n",
      "\n",
      "Fold: 2  Epoch: 289  Training loss = 3.3069  Validation loss = 3.5001  \n",
      "\n",
      "Fold: 2  Epoch: 290  Training loss = 3.3066  Validation loss = 3.4997  \n",
      "\n",
      "Fold: 2  Epoch: 291  Training loss = 3.3065  Validation loss = 3.4994  \n",
      "\n",
      "Fold: 2  Epoch: 292  Training loss = 3.3063  Validation loss = 3.4991  \n",
      "\n",
      "Fold: 2  Epoch: 293  Training loss = 3.3060  Validation loss = 3.4988  \n",
      "\n",
      "Fold: 2  Epoch: 294  Training loss = 3.3058  Validation loss = 3.4984  \n",
      "\n",
      "Fold: 2  Epoch: 295  Training loss = 3.3055  Validation loss = 3.4981  \n",
      "\n",
      "Fold: 2  Epoch: 296  Training loss = 3.3053  Validation loss = 3.4977  \n",
      "\n",
      "Fold: 2  Epoch: 297  Training loss = 3.3050  Validation loss = 3.4973  \n",
      "\n",
      "Fold: 2  Epoch: 298  Training loss = 3.3047  Validation loss = 3.4969  \n",
      "\n",
      "Fold: 2  Epoch: 299  Training loss = 3.3044  Validation loss = 3.4965  \n",
      "\n",
      "Fold: 2  Epoch: 300  Training loss = 3.3042  Validation loss = 3.4962  \n",
      "\n",
      "Fold: 2  Epoch: 301  Training loss = 3.3040  Validation loss = 3.4959  \n",
      "\n",
      "Fold: 2  Epoch: 302  Training loss = 3.3038  Validation loss = 3.4956  \n",
      "\n",
      "Fold: 2  Epoch: 303  Training loss = 3.3036  Validation loss = 3.4952  \n",
      "\n",
      "Fold: 2  Epoch: 304  Training loss = 3.3033  Validation loss = 3.4949  \n",
      "\n",
      "Fold: 2  Epoch: 305  Training loss = 3.3031  Validation loss = 3.4945  \n",
      "\n",
      "Fold: 2  Epoch: 306  Training loss = 3.3029  Validation loss = 3.4942  \n",
      "\n",
      "Fold: 2  Epoch: 307  Training loss = 3.3026  Validation loss = 3.4938  \n",
      "\n",
      "Fold: 2  Epoch: 308  Training loss = 3.3024  Validation loss = 3.4935  \n",
      "\n",
      "Fold: 2  Epoch: 309  Training loss = 3.3021  Validation loss = 3.4931  \n",
      "\n",
      "Fold: 2  Epoch: 310  Training loss = 3.3018  Validation loss = 3.4927  \n",
      "\n",
      "Fold: 2  Epoch: 311  Training loss = 3.3016  Validation loss = 3.4923  \n",
      "\n",
      "Fold: 2  Epoch: 312  Training loss = 3.3014  Validation loss = 3.4920  \n",
      "\n",
      "Fold: 2  Epoch: 313  Training loss = 3.3011  Validation loss = 3.4916  \n",
      "\n",
      "Fold: 2  Epoch: 314  Training loss = 3.3010  Validation loss = 3.4914  \n",
      "\n",
      "Fold: 2  Epoch: 315  Training loss = 3.3007  Validation loss = 3.4910  \n",
      "\n",
      "Fold: 2  Epoch: 316  Training loss = 3.3005  Validation loss = 3.4907  \n",
      "\n",
      "Fold: 2  Epoch: 317  Training loss = 3.3002  Validation loss = 3.4903  \n",
      "\n",
      "Fold: 2  Epoch: 318  Training loss = 3.3000  Validation loss = 3.4899  \n",
      "\n",
      "Fold: 2  Epoch: 319  Training loss = 3.2998  Validation loss = 3.4896  \n",
      "\n",
      "Fold: 2  Epoch: 320  Training loss = 3.2995  Validation loss = 3.4892  \n",
      "\n",
      "Fold: 2  Epoch: 321  Training loss = 3.2993  Validation loss = 3.4889  \n",
      "\n",
      "Fold: 2  Epoch: 322  Training loss = 3.2991  Validation loss = 3.4886  \n",
      "\n",
      "Fold: 2  Epoch: 323  Training loss = 3.2988  Validation loss = 3.4882  \n",
      "\n",
      "Fold: 2  Epoch: 324  Training loss = 3.2986  Validation loss = 3.4879  \n",
      "\n",
      "Fold: 2  Epoch: 325  Training loss = 3.2984  Validation loss = 3.4875  \n",
      "\n",
      "Fold: 2  Epoch: 326  Training loss = 3.2981  Validation loss = 3.4871  \n",
      "\n",
      "Fold: 2  Epoch: 327  Training loss = 3.2979  Validation loss = 3.4868  \n",
      "\n",
      "Fold: 2  Epoch: 328  Training loss = 3.2976  Validation loss = 3.4864  \n",
      "\n",
      "Fold: 2  Epoch: 329  Training loss = 3.2974  Validation loss = 3.4860  \n",
      "\n",
      "Fold: 2  Epoch: 330  Training loss = 3.2971  Validation loss = 3.4857  \n",
      "\n",
      "Fold: 2  Epoch: 331  Training loss = 3.2969  Validation loss = 3.4854  \n",
      "\n",
      "Fold: 2  Epoch: 332  Training loss = 3.2966  Validation loss = 3.4850  \n",
      "\n",
      "Fold: 2  Epoch: 333  Training loss = 3.2964  Validation loss = 3.4847  \n",
      "\n",
      "Fold: 2  Epoch: 334  Training loss = 3.2962  Validation loss = 3.4843  \n",
      "\n",
      "Fold: 2  Epoch: 335  Training loss = 3.2959  Validation loss = 3.4839  \n",
      "\n",
      "Fold: 2  Epoch: 336  Training loss = 3.2957  Validation loss = 3.4836  \n",
      "\n",
      "Fold: 2  Epoch: 337  Training loss = 3.2954  Validation loss = 3.4832  \n",
      "\n",
      "Fold: 2  Epoch: 338  Training loss = 3.2952  Validation loss = 3.4829  \n",
      "\n",
      "Fold: 2  Epoch: 339  Training loss = 3.2950  Validation loss = 3.4825  \n",
      "\n",
      "Fold: 2  Epoch: 340  Training loss = 3.2948  Validation loss = 3.4822  \n",
      "\n",
      "Fold: 2  Epoch: 341  Training loss = 3.2945  Validation loss = 3.4819  \n",
      "\n",
      "Fold: 2  Epoch: 342  Training loss = 3.2943  Validation loss = 3.4815  \n",
      "\n",
      "Fold: 2  Epoch: 343  Training loss = 3.2941  Validation loss = 3.4812  \n",
      "\n",
      "Fold: 2  Epoch: 344  Training loss = 3.2939  Validation loss = 3.4809  \n",
      "\n",
      "Fold: 2  Epoch: 345  Training loss = 3.2936  Validation loss = 3.4805  \n",
      "\n",
      "Fold: 2  Epoch: 346  Training loss = 3.2933  Validation loss = 3.4801  \n",
      "\n",
      "Fold: 2  Epoch: 347  Training loss = 3.2931  Validation loss = 3.4798  \n",
      "\n",
      "Fold: 2  Epoch: 348  Training loss = 3.2928  Validation loss = 3.4794  \n",
      "\n",
      "Fold: 2  Epoch: 349  Training loss = 3.2926  Validation loss = 3.4791  \n",
      "\n",
      "Fold: 2  Epoch: 350  Training loss = 3.2924  Validation loss = 3.4787  \n",
      "\n",
      "Fold: 2  Epoch: 351  Training loss = 3.2921  Validation loss = 3.4783  \n",
      "\n",
      "Fold: 2  Epoch: 352  Training loss = 3.2919  Validation loss = 3.4780  \n",
      "\n",
      "Fold: 2  Epoch: 353  Training loss = 3.2917  Validation loss = 3.4777  \n",
      "\n",
      "Fold: 2  Epoch: 354  Training loss = 3.2914  Validation loss = 3.4773  \n",
      "\n",
      "Fold: 2  Epoch: 355  Training loss = 3.2912  Validation loss = 3.4769  \n",
      "\n",
      "Fold: 2  Epoch: 356  Training loss = 3.2909  Validation loss = 3.4766  \n",
      "\n",
      "Fold: 2  Epoch: 357  Training loss = 3.2907  Validation loss = 3.4762  \n",
      "\n",
      "Fold: 2  Epoch: 358  Training loss = 3.2905  Validation loss = 3.4759  \n",
      "\n",
      "Fold: 2  Epoch: 359  Training loss = 3.2903  Validation loss = 3.4756  \n",
      "\n",
      "Fold: 2  Epoch: 360  Training loss = 3.2901  Validation loss = 3.4753  \n",
      "\n",
      "Fold: 2  Epoch: 361  Training loss = 3.2899  Validation loss = 3.4750  \n",
      "\n",
      "Fold: 2  Epoch: 362  Training loss = 3.2896  Validation loss = 3.4746  \n",
      "\n",
      "Fold: 2  Epoch: 363  Training loss = 3.2894  Validation loss = 3.4743  \n",
      "\n",
      "Fold: 2  Epoch: 364  Training loss = 3.2892  Validation loss = 3.4739  \n",
      "\n",
      "Fold: 2  Epoch: 365  Training loss = 3.2889  Validation loss = 3.4736  \n",
      "\n",
      "Fold: 2  Epoch: 366  Training loss = 3.2887  Validation loss = 3.4732  \n",
      "\n",
      "Fold: 2  Epoch: 367  Training loss = 3.2884  Validation loss = 3.4728  \n",
      "\n",
      "Fold: 2  Epoch: 368  Training loss = 3.2882  Validation loss = 3.4725  \n",
      "\n",
      "Fold: 2  Epoch: 369  Training loss = 3.2880  Validation loss = 3.4722  \n",
      "\n",
      "Fold: 2  Epoch: 370  Training loss = 3.2878  Validation loss = 3.4718  \n",
      "\n",
      "Fold: 2  Epoch: 371  Training loss = 3.2875  Validation loss = 3.4714  \n",
      "\n",
      "Fold: 2  Epoch: 372  Training loss = 3.2873  Validation loss = 3.4711  \n",
      "\n",
      "Fold: 2  Epoch: 373  Training loss = 3.2870  Validation loss = 3.4707  \n",
      "\n",
      "Fold: 2  Epoch: 374  Training loss = 3.2868  Validation loss = 3.4704  \n",
      "\n",
      "Fold: 2  Epoch: 375  Training loss = 3.2866  Validation loss = 3.4700  \n",
      "\n",
      "Fold: 2  Epoch: 376  Training loss = 3.2863  Validation loss = 3.4697  \n",
      "\n",
      "Fold: 2  Epoch: 377  Training loss = 3.2861  Validation loss = 3.4693  \n",
      "\n",
      "Fold: 2  Epoch: 378  Training loss = 3.2859  Validation loss = 3.4689  \n",
      "\n",
      "Fold: 2  Epoch: 379  Training loss = 3.2856  Validation loss = 3.4685  \n",
      "\n",
      "Fold: 2  Epoch: 380  Training loss = 3.2853  Validation loss = 3.4681  \n",
      "\n",
      "Fold: 2  Epoch: 381  Training loss = 3.2851  Validation loss = 3.4677  \n",
      "\n",
      "Fold: 2  Epoch: 382  Training loss = 3.2848  Validation loss = 3.4673  \n",
      "\n",
      "Fold: 2  Epoch: 383  Training loss = 3.2845  Validation loss = 3.4669  \n",
      "\n",
      "Fold: 2  Epoch: 384  Training loss = 3.2843  Validation loss = 3.4666  \n",
      "\n",
      "Fold: 2  Epoch: 385  Training loss = 3.2840  Validation loss = 3.4662  \n",
      "\n",
      "Fold: 2  Epoch: 386  Training loss = 3.2838  Validation loss = 3.4659  \n",
      "\n",
      "Fold: 2  Epoch: 387  Training loss = 3.2836  Validation loss = 3.4655  \n",
      "\n",
      "Fold: 2  Epoch: 388  Training loss = 3.2833  Validation loss = 3.4651  \n",
      "\n",
      "Fold: 2  Epoch: 389  Training loss = 3.2831  Validation loss = 3.4648  \n",
      "\n",
      "Fold: 2  Epoch: 390  Training loss = 3.2829  Validation loss = 3.4645  \n",
      "\n",
      "Fold: 2  Epoch: 391  Training loss = 3.2827  Validation loss = 3.4641  \n",
      "\n",
      "Fold: 2  Epoch: 392  Training loss = 3.2824  Validation loss = 3.4637  \n",
      "\n",
      "Fold: 2  Epoch: 393  Training loss = 3.2821  Validation loss = 3.4634  \n",
      "\n",
      "Fold: 2  Epoch: 394  Training loss = 3.2820  Validation loss = 3.4631  \n",
      "\n",
      "Fold: 2  Epoch: 395  Training loss = 3.2818  Validation loss = 3.4628  \n",
      "\n",
      "Fold: 2  Epoch: 396  Training loss = 3.2815  Validation loss = 3.4624  \n",
      "\n",
      "Fold: 2  Epoch: 397  Training loss = 3.2813  Validation loss = 3.4621  \n",
      "\n",
      "Fold: 2  Epoch: 398  Training loss = 3.2810  Validation loss = 3.4617  \n",
      "\n",
      "Fold: 2  Epoch: 399  Training loss = 3.2808  Validation loss = 3.4614  \n",
      "\n",
      "Fold: 2  Epoch: 400  Training loss = 3.2806  Validation loss = 3.4611  \n",
      "\n",
      "Fold: 2  Epoch: 401  Training loss = 3.2804  Validation loss = 3.4607  \n",
      "\n",
      "Fold: 2  Epoch: 402  Training loss = 3.2801  Validation loss = 3.4603  \n",
      "\n",
      "Fold: 2  Epoch: 403  Training loss = 3.2798  Validation loss = 3.4599  \n",
      "\n",
      "Fold: 2  Epoch: 404  Training loss = 3.2795  Validation loss = 3.4596  \n",
      "\n",
      "Fold: 2  Epoch: 405  Training loss = 3.2792  Validation loss = 3.4592  \n",
      "\n",
      "Fold: 2  Epoch: 406  Training loss = 3.2789  Validation loss = 3.4587  \n",
      "\n",
      "Fold: 2  Epoch: 407  Training loss = 3.2787  Validation loss = 3.4583  \n",
      "\n",
      "Fold: 2  Epoch: 408  Training loss = 3.2785  Validation loss = 3.4580  \n",
      "\n",
      "Fold: 2  Epoch: 409  Training loss = 3.2782  Validation loss = 3.4576  \n",
      "\n",
      "Fold: 2  Epoch: 410  Training loss = 3.2780  Validation loss = 3.4572  \n",
      "\n",
      "Fold: 2  Epoch: 411  Training loss = 3.2777  Validation loss = 3.4569  \n",
      "\n",
      "Fold: 2  Epoch: 412  Training loss = 3.2775  Validation loss = 3.4565  \n",
      "\n",
      "Fold: 2  Epoch: 413  Training loss = 3.2772  Validation loss = 3.4561  \n",
      "\n",
      "Fold: 2  Epoch: 414  Training loss = 3.2770  Validation loss = 3.4558  \n",
      "\n",
      "Fold: 2  Epoch: 415  Training loss = 3.2768  Validation loss = 3.4554  \n",
      "\n",
      "Fold: 2  Epoch: 416  Training loss = 3.2765  Validation loss = 3.4550  \n",
      "\n",
      "Fold: 2  Epoch: 417  Training loss = 3.2762  Validation loss = 3.4546  \n",
      "\n",
      "Fold: 2  Epoch: 418  Training loss = 3.2761  Validation loss = 3.4543  \n",
      "\n",
      "Fold: 2  Epoch: 419  Training loss = 3.2758  Validation loss = 3.4539  \n",
      "\n",
      "Fold: 2  Epoch: 420  Training loss = 3.2756  Validation loss = 3.4536  \n",
      "\n",
      "Fold: 2  Epoch: 421  Training loss = 3.2753  Validation loss = 3.4532  \n",
      "\n",
      "Fold: 2  Epoch: 422  Training loss = 3.2751  Validation loss = 3.4529  \n",
      "\n",
      "Fold: 2  Epoch: 423  Training loss = 3.2749  Validation loss = 3.4526  \n",
      "\n",
      "Fold: 2  Epoch: 424  Training loss = 3.2747  Validation loss = 3.4523  \n",
      "\n",
      "Fold: 2  Epoch: 425  Training loss = 3.2745  Validation loss = 3.4519  \n",
      "\n",
      "Fold: 2  Epoch: 426  Training loss = 3.2742  Validation loss = 3.4516  \n",
      "\n",
      "Fold: 2  Epoch: 427  Training loss = 3.2740  Validation loss = 3.4512  \n",
      "\n",
      "Fold: 2  Epoch: 428  Training loss = 3.2738  Validation loss = 3.4508  \n",
      "\n",
      "Fold: 2  Epoch: 429  Training loss = 3.2735  Validation loss = 3.4505  \n",
      "\n",
      "Fold: 2  Epoch: 430  Training loss = 3.2733  Validation loss = 3.4501  \n",
      "\n",
      "Fold: 2  Epoch: 431  Training loss = 3.2731  Validation loss = 3.4498  \n",
      "\n",
      "Fold: 2  Epoch: 432  Training loss = 3.2728  Validation loss = 3.4495  \n",
      "\n",
      "Fold: 2  Epoch: 433  Training loss = 3.2726  Validation loss = 3.4491  \n",
      "\n",
      "Fold: 2  Epoch: 434  Training loss = 3.2724  Validation loss = 3.4488  \n",
      "\n",
      "Fold: 2  Epoch: 435  Training loss = 3.2722  Validation loss = 3.4485  \n",
      "\n",
      "Fold: 2  Epoch: 436  Training loss = 3.2720  Validation loss = 3.4482  \n",
      "\n",
      "Fold: 2  Epoch: 437  Training loss = 3.2718  Validation loss = 3.4479  \n",
      "\n",
      "Fold: 2  Epoch: 438  Training loss = 3.2716  Validation loss = 3.4475  \n",
      "\n",
      "Fold: 2  Epoch: 439  Training loss = 3.2713  Validation loss = 3.4472  \n",
      "\n",
      "Fold: 2  Epoch: 440  Training loss = 3.2711  Validation loss = 3.4469  \n",
      "\n",
      "Fold: 2  Epoch: 441  Training loss = 3.2709  Validation loss = 3.4465  \n",
      "\n",
      "Fold: 2  Epoch: 442  Training loss = 3.2706  Validation loss = 3.4461  \n",
      "\n",
      "Fold: 2  Epoch: 443  Training loss = 3.2704  Validation loss = 3.4458  \n",
      "\n",
      "Fold: 2  Epoch: 444  Training loss = 3.2701  Validation loss = 3.4454  \n",
      "\n",
      "Fold: 2  Epoch: 445  Training loss = 3.2699  Validation loss = 3.4451  \n",
      "\n",
      "Fold: 2  Epoch: 446  Training loss = 3.2696  Validation loss = 3.4446  \n",
      "\n",
      "Fold: 2  Epoch: 447  Training loss = 3.2694  Validation loss = 3.4443  \n",
      "\n",
      "Fold: 2  Epoch: 448  Training loss = 3.2691  Validation loss = 3.4440  \n",
      "\n",
      "Fold: 2  Epoch: 449  Training loss = 3.2689  Validation loss = 3.4436  \n",
      "\n",
      "Fold: 2  Epoch: 450  Training loss = 3.2686  Validation loss = 3.4432  \n",
      "\n",
      "Fold: 2  Epoch: 451  Training loss = 3.2684  Validation loss = 3.4428  \n",
      "\n",
      "Fold: 2  Epoch: 452  Training loss = 3.2681  Validation loss = 3.4424  \n",
      "\n",
      "Fold: 2  Epoch: 453  Training loss = 3.2678  Validation loss = 3.4420  \n",
      "\n",
      "Fold: 2  Epoch: 454  Training loss = 3.2676  Validation loss = 3.4417  \n",
      "\n",
      "Fold: 2  Epoch: 455  Training loss = 3.2674  Validation loss = 3.4413  \n",
      "\n",
      "Fold: 2  Epoch: 456  Training loss = 3.2671  Validation loss = 3.4409  \n",
      "\n",
      "Fold: 2  Epoch: 457  Training loss = 3.2669  Validation loss = 3.4406  \n",
      "\n",
      "Fold: 2  Epoch: 458  Training loss = 3.2667  Validation loss = 3.4403  \n",
      "\n",
      "Fold: 2  Epoch: 459  Training loss = 3.2664  Validation loss = 3.4400  \n",
      "\n",
      "Fold: 2  Epoch: 460  Training loss = 3.2661  Validation loss = 3.4395  \n",
      "\n",
      "Fold: 2  Epoch: 461  Training loss = 3.2660  Validation loss = 3.4392  \n",
      "\n",
      "Fold: 2  Epoch: 462  Training loss = 3.2657  Validation loss = 3.4389  \n",
      "\n",
      "Fold: 2  Epoch: 463  Training loss = 3.2655  Validation loss = 3.4386  \n",
      "\n",
      "Fold: 2  Epoch: 464  Training loss = 3.2653  Validation loss = 3.4382  \n",
      "\n",
      "Fold: 2  Epoch: 465  Training loss = 3.2651  Validation loss = 3.4380  \n",
      "\n",
      "Fold: 2  Epoch: 466  Training loss = 3.2648  Validation loss = 3.4375  \n",
      "\n",
      "Fold: 2  Epoch: 467  Training loss = 3.2645  Validation loss = 3.4371  \n",
      "\n",
      "Fold: 2  Epoch: 468  Training loss = 3.2643  Validation loss = 3.4368  \n",
      "\n",
      "Fold: 2  Epoch: 469  Training loss = 3.2641  Validation loss = 3.4364  \n",
      "\n",
      "Fold: 2  Epoch: 470  Training loss = 3.2638  Validation loss = 3.4360  \n",
      "\n",
      "Fold: 2  Epoch: 471  Training loss = 3.2636  Validation loss = 3.4357  \n",
      "\n",
      "Fold: 2  Epoch: 472  Training loss = 3.2634  Validation loss = 3.4355  \n",
      "\n",
      "Fold: 2  Epoch: 473  Training loss = 3.2632  Validation loss = 3.4351  \n",
      "\n",
      "Fold: 2  Epoch: 474  Training loss = 3.2629  Validation loss = 3.4347  \n",
      "\n",
      "Fold: 2  Epoch: 475  Training loss = 3.2626  Validation loss = 3.4343  \n",
      "\n",
      "Fold: 2  Epoch: 476  Training loss = 3.2624  Validation loss = 3.4339  \n",
      "\n",
      "Fold: 2  Epoch: 477  Training loss = 3.2621  Validation loss = 3.4336  \n",
      "\n",
      "Fold: 2  Epoch: 478  Training loss = 3.2619  Validation loss = 3.4332  \n",
      "\n",
      "Fold: 2  Epoch: 479  Training loss = 3.2616  Validation loss = 3.4329  \n",
      "\n",
      "Fold: 2  Epoch: 480  Training loss = 3.2614  Validation loss = 3.4325  \n",
      "\n",
      "Fold: 2  Epoch: 481  Training loss = 3.2612  Validation loss = 3.4322  \n",
      "\n",
      "Fold: 2  Epoch: 482  Training loss = 3.2609  Validation loss = 3.4317  \n",
      "\n",
      "Fold: 2  Epoch: 483  Training loss = 3.2606  Validation loss = 3.4313  \n",
      "\n",
      "Fold: 2  Epoch: 484  Training loss = 3.2604  Validation loss = 3.4310  \n",
      "\n",
      "Fold: 2  Epoch: 485  Training loss = 3.2602  Validation loss = 3.4306  \n",
      "\n",
      "Fold: 2  Epoch: 486  Training loss = 3.2600  Validation loss = 3.4303  \n",
      "\n",
      "Fold: 2  Epoch: 487  Training loss = 3.2597  Validation loss = 3.4300  \n",
      "\n",
      "Fold: 2  Epoch: 488  Training loss = 3.2595  Validation loss = 3.4296  \n",
      "\n",
      "Fold: 2  Epoch: 489  Training loss = 3.2593  Validation loss = 3.4293  \n",
      "\n",
      "Fold: 2  Epoch: 490  Training loss = 3.2590  Validation loss = 3.4289  \n",
      "\n",
      "Fold: 2  Epoch: 491  Training loss = 3.2588  Validation loss = 3.4286  \n",
      "\n",
      "Fold: 2  Epoch: 492  Training loss = 3.2586  Validation loss = 3.4282  \n",
      "\n",
      "Fold: 2  Epoch: 493  Training loss = 3.2583  Validation loss = 3.4278  \n",
      "\n",
      "Fold: 2  Epoch: 494  Training loss = 3.2580  Validation loss = 3.4274  \n",
      "\n",
      "Fold: 2  Epoch: 495  Training loss = 3.2578  Validation loss = 3.4270  \n",
      "\n",
      "Fold: 2  Epoch: 496  Training loss = 3.2575  Validation loss = 3.4266  \n",
      "\n",
      "Fold: 2  Epoch: 497  Training loss = 3.2573  Validation loss = 3.4263  \n",
      "\n",
      "Fold: 2  Epoch: 498  Training loss = 3.2570  Validation loss = 3.4260  \n",
      "\n",
      "Fold: 2  Epoch: 499  Training loss = 3.2568  Validation loss = 3.4257  \n",
      "\n",
      "Fold: 2  Epoch: 500  Training loss = 3.2566  Validation loss = 3.4253  \n",
      "\n",
      "Check model:  Fold: 2  Optimal epoch: 500  \n",
      "\n",
      "Fold: 3  Epoch: 1  Training loss = 2.3309  Validation loss = 4.9690  \n",
      "\n",
      "Fold: 3  Epoch: 2  Training loss = 2.3306  Validation loss = 4.9686  \n",
      "\n",
      "Fold: 3  Epoch: 3  Training loss = 2.3304  Validation loss = 4.9684  \n",
      "\n",
      "Fold: 3  Epoch: 4  Training loss = 2.3301  Validation loss = 4.9681  \n",
      "\n",
      "Fold: 3  Epoch: 5  Training loss = 2.3297  Validation loss = 4.9677  \n",
      "\n",
      "Fold: 3  Epoch: 6  Training loss = 2.3295  Validation loss = 4.9674  \n",
      "\n",
      "Fold: 3  Epoch: 7  Training loss = 2.3292  Validation loss = 4.9672  \n",
      "\n",
      "Fold: 3  Epoch: 8  Training loss = 2.3290  Validation loss = 4.9669  \n",
      "\n",
      "Fold: 3  Epoch: 9  Training loss = 2.3287  Validation loss = 4.9666  \n",
      "\n",
      "Fold: 3  Epoch: 10  Training loss = 2.3284  Validation loss = 4.9663  \n",
      "\n",
      "Fold: 3  Epoch: 11  Training loss = 2.3281  Validation loss = 4.9660  \n",
      "\n",
      "Fold: 3  Epoch: 12  Training loss = 2.3279  Validation loss = 4.9657  \n",
      "\n",
      "Fold: 3  Epoch: 13  Training loss = 2.3276  Validation loss = 4.9655  \n",
      "\n",
      "Fold: 3  Epoch: 14  Training loss = 2.3274  Validation loss = 4.9652  \n",
      "\n",
      "Fold: 3  Epoch: 15  Training loss = 2.3271  Validation loss = 4.9650  \n",
      "\n",
      "Fold: 3  Epoch: 16  Training loss = 2.3269  Validation loss = 4.9647  \n",
      "\n",
      "Fold: 3  Epoch: 17  Training loss = 2.3266  Validation loss = 4.9644  \n",
      "\n",
      "Fold: 3  Epoch: 18  Training loss = 2.3263  Validation loss = 4.9641  \n",
      "\n",
      "Fold: 3  Epoch: 19  Training loss = 2.3260  Validation loss = 4.9638  \n",
      "\n",
      "Fold: 3  Epoch: 20  Training loss = 2.3257  Validation loss = 4.9635  \n",
      "\n",
      "Fold: 3  Epoch: 21  Training loss = 2.3254  Validation loss = 4.9632  \n",
      "\n",
      "Fold: 3  Epoch: 22  Training loss = 2.3251  Validation loss = 4.9629  \n",
      "\n",
      "Fold: 3  Epoch: 23  Training loss = 2.3248  Validation loss = 4.9626  \n",
      "\n",
      "Fold: 3  Epoch: 24  Training loss = 2.3245  Validation loss = 4.9623  \n",
      "\n",
      "Fold: 3  Epoch: 25  Training loss = 2.3243  Validation loss = 4.9620  \n",
      "\n",
      "Fold: 3  Epoch: 26  Training loss = 2.3240  Validation loss = 4.9617  \n",
      "\n",
      "Fold: 3  Epoch: 27  Training loss = 2.3237  Validation loss = 4.9615  \n",
      "\n",
      "Fold: 3  Epoch: 28  Training loss = 2.3234  Validation loss = 4.9612  \n",
      "\n",
      "Fold: 3  Epoch: 29  Training loss = 2.3232  Validation loss = 4.9609  \n",
      "\n",
      "Fold: 3  Epoch: 30  Training loss = 2.3229  Validation loss = 4.9606  \n",
      "\n",
      "Fold: 3  Epoch: 31  Training loss = 2.3226  Validation loss = 4.9603  \n",
      "\n",
      "Fold: 3  Epoch: 32  Training loss = 2.3224  Validation loss = 4.9600  \n",
      "\n",
      "Fold: 3  Epoch: 33  Training loss = 2.3221  Validation loss = 4.9597  \n",
      "\n",
      "Fold: 3  Epoch: 34  Training loss = 2.3218  Validation loss = 4.9594  \n",
      "\n",
      "Fold: 3  Epoch: 35  Training loss = 2.3215  Validation loss = 4.9592  \n",
      "\n",
      "Fold: 3  Epoch: 36  Training loss = 2.3212  Validation loss = 4.9589  \n",
      "\n",
      "Fold: 3  Epoch: 37  Training loss = 2.3210  Validation loss = 4.9586  \n",
      "\n",
      "Fold: 3  Epoch: 38  Training loss = 2.3207  Validation loss = 4.9583  \n",
      "\n",
      "Fold: 3  Epoch: 39  Training loss = 2.3204  Validation loss = 4.9581  \n",
      "\n",
      "Fold: 3  Epoch: 40  Training loss = 2.3202  Validation loss = 4.9578  \n",
      "\n",
      "Fold: 3  Epoch: 41  Training loss = 2.3200  Validation loss = 4.9576  \n",
      "\n",
      "Fold: 3  Epoch: 42  Training loss = 2.3198  Validation loss = 4.9574  \n",
      "\n",
      "Fold: 3  Epoch: 43  Training loss = 2.3195  Validation loss = 4.9571  \n",
      "\n",
      "Fold: 3  Epoch: 44  Training loss = 2.3191  Validation loss = 4.9567  \n",
      "\n",
      "Fold: 3  Epoch: 45  Training loss = 2.3189  Validation loss = 4.9564  \n",
      "\n",
      "Fold: 3  Epoch: 46  Training loss = 2.3186  Validation loss = 4.9561  \n",
      "\n",
      "Fold: 3  Epoch: 47  Training loss = 2.3183  Validation loss = 4.9558  \n",
      "\n",
      "Fold: 3  Epoch: 48  Training loss = 2.3180  Validation loss = 4.9554  \n",
      "\n",
      "Fold: 3  Epoch: 49  Training loss = 2.3177  Validation loss = 4.9552  \n",
      "\n",
      "Fold: 3  Epoch: 50  Training loss = 2.3174  Validation loss = 4.9549  \n",
      "\n",
      "Fold: 3  Epoch: 51  Training loss = 2.3172  Validation loss = 4.9546  \n",
      "\n",
      "Fold: 3  Epoch: 52  Training loss = 2.3169  Validation loss = 4.9543  \n",
      "\n",
      "Fold: 3  Epoch: 53  Training loss = 2.3166  Validation loss = 4.9540  \n",
      "\n",
      "Fold: 3  Epoch: 54  Training loss = 2.3163  Validation loss = 4.9537  \n",
      "\n",
      "Fold: 3  Epoch: 55  Training loss = 2.3161  Validation loss = 4.9534  \n",
      "\n",
      "Fold: 3  Epoch: 56  Training loss = 2.3158  Validation loss = 4.9532  \n",
      "\n",
      "Fold: 3  Epoch: 57  Training loss = 2.3156  Validation loss = 4.9530  \n",
      "\n",
      "Fold: 3  Epoch: 58  Training loss = 2.3153  Validation loss = 4.9526  \n",
      "\n",
      "Fold: 3  Epoch: 59  Training loss = 2.3151  Validation loss = 4.9524  \n",
      "\n",
      "Fold: 3  Epoch: 60  Training loss = 2.3148  Validation loss = 4.9521  \n",
      "\n",
      "Fold: 3  Epoch: 61  Training loss = 2.3145  Validation loss = 4.9518  \n",
      "\n",
      "Fold: 3  Epoch: 62  Training loss = 2.3143  Validation loss = 4.9516  \n",
      "\n",
      "Fold: 3  Epoch: 63  Training loss = 2.3140  Validation loss = 4.9514  \n",
      "\n",
      "Fold: 3  Epoch: 64  Training loss = 2.3138  Validation loss = 4.9511  \n",
      "\n",
      "Fold: 3  Epoch: 65  Training loss = 2.3135  Validation loss = 4.9508  \n",
      "\n",
      "Fold: 3  Epoch: 66  Training loss = 2.3132  Validation loss = 4.9505  \n",
      "\n",
      "Fold: 3  Epoch: 67  Training loss = 2.3128  Validation loss = 4.9501  \n",
      "\n",
      "Fold: 3  Epoch: 68  Training loss = 2.3126  Validation loss = 4.9499  \n",
      "\n",
      "Fold: 3  Epoch: 69  Training loss = 2.3124  Validation loss = 4.9496  \n",
      "\n",
      "Fold: 3  Epoch: 70  Training loss = 2.3121  Validation loss = 4.9493  \n",
      "\n",
      "Fold: 3  Epoch: 71  Training loss = 2.3119  Validation loss = 4.9491  \n",
      "\n",
      "Fold: 3  Epoch: 72  Training loss = 2.3115  Validation loss = 4.9488  \n",
      "\n",
      "Fold: 3  Epoch: 73  Training loss = 2.3113  Validation loss = 4.9485  \n",
      "\n",
      "Fold: 3  Epoch: 74  Training loss = 2.3110  Validation loss = 4.9482  \n",
      "\n",
      "Fold: 3  Epoch: 75  Training loss = 2.3107  Validation loss = 4.9479  \n",
      "\n",
      "Fold: 3  Epoch: 76  Training loss = 2.3104  Validation loss = 4.9476  \n",
      "\n",
      "Fold: 3  Epoch: 77  Training loss = 2.3102  Validation loss = 4.9474  \n",
      "\n",
      "Fold: 3  Epoch: 78  Training loss = 2.3099  Validation loss = 4.9471  \n",
      "\n",
      "Fold: 3  Epoch: 79  Training loss = 2.3097  Validation loss = 4.9468  \n",
      "\n",
      "Fold: 3  Epoch: 80  Training loss = 2.3094  Validation loss = 4.9465  \n",
      "\n",
      "Fold: 3  Epoch: 81  Training loss = 2.3091  Validation loss = 4.9462  \n",
      "\n",
      "Fold: 3  Epoch: 82  Training loss = 2.3088  Validation loss = 4.9459  \n",
      "\n",
      "Fold: 3  Epoch: 83  Training loss = 2.3085  Validation loss = 4.9456  \n",
      "\n",
      "Fold: 3  Epoch: 84  Training loss = 2.3082  Validation loss = 4.9453  \n",
      "\n",
      "Fold: 3  Epoch: 85  Training loss = 2.3079  Validation loss = 4.9450  \n",
      "\n",
      "Fold: 3  Epoch: 86  Training loss = 2.3077  Validation loss = 4.9448  \n",
      "\n",
      "Fold: 3  Epoch: 87  Training loss = 2.3074  Validation loss = 4.9445  \n",
      "\n",
      "Fold: 3  Epoch: 88  Training loss = 2.3072  Validation loss = 4.9442  \n",
      "\n",
      "Fold: 3  Epoch: 89  Training loss = 2.3069  Validation loss = 4.9439  \n",
      "\n",
      "Fold: 3  Epoch: 90  Training loss = 2.3066  Validation loss = 4.9436  \n",
      "\n",
      "Fold: 3  Epoch: 91  Training loss = 2.3064  Validation loss = 4.9434  \n",
      "\n",
      "Fold: 3  Epoch: 92  Training loss = 2.3061  Validation loss = 4.9431  \n",
      "\n",
      "Fold: 3  Epoch: 93  Training loss = 2.3059  Validation loss = 4.9429  \n",
      "\n",
      "Fold: 3  Epoch: 94  Training loss = 2.3056  Validation loss = 4.9426  \n",
      "\n",
      "Fold: 3  Epoch: 95  Training loss = 2.3053  Validation loss = 4.9423  \n",
      "\n",
      "Fold: 3  Epoch: 96  Training loss = 2.3051  Validation loss = 4.9420  \n",
      "\n",
      "Fold: 3  Epoch: 97  Training loss = 2.3048  Validation loss = 4.9417  \n",
      "\n",
      "Fold: 3  Epoch: 98  Training loss = 2.3045  Validation loss = 4.9414  \n",
      "\n",
      "Fold: 3  Epoch: 99  Training loss = 2.3042  Validation loss = 4.9411  \n",
      "\n",
      "Fold: 3  Epoch: 100  Training loss = 2.3040  Validation loss = 4.9409  \n",
      "\n",
      "Fold: 3  Epoch: 101  Training loss = 2.3037  Validation loss = 4.9405  \n",
      "\n",
      "Fold: 3  Epoch: 102  Training loss = 2.3034  Validation loss = 4.9402  \n",
      "\n",
      "Fold: 3  Epoch: 103  Training loss = 2.3031  Validation loss = 4.9400  \n",
      "\n",
      "Fold: 3  Epoch: 104  Training loss = 2.3029  Validation loss = 4.9397  \n",
      "\n",
      "Fold: 3  Epoch: 105  Training loss = 2.3026  Validation loss = 4.9395  \n",
      "\n",
      "Fold: 3  Epoch: 106  Training loss = 2.3024  Validation loss = 4.9392  \n",
      "\n",
      "Fold: 3  Epoch: 107  Training loss = 2.3021  Validation loss = 4.9389  \n",
      "\n",
      "Fold: 3  Epoch: 108  Training loss = 2.3019  Validation loss = 4.9387  \n",
      "\n",
      "Fold: 3  Epoch: 109  Training loss = 2.3016  Validation loss = 4.9384  \n",
      "\n",
      "Fold: 3  Epoch: 110  Training loss = 2.3013  Validation loss = 4.9381  \n",
      "\n",
      "Fold: 3  Epoch: 111  Training loss = 2.3010  Validation loss = 4.9378  \n",
      "\n",
      "Fold: 3  Epoch: 112  Training loss = 2.3008  Validation loss = 4.9375  \n",
      "\n",
      "Fold: 3  Epoch: 113  Training loss = 2.3005  Validation loss = 4.9372  \n",
      "\n",
      "Fold: 3  Epoch: 114  Training loss = 2.3003  Validation loss = 4.9370  \n",
      "\n",
      "Fold: 3  Epoch: 115  Training loss = 2.3000  Validation loss = 4.9367  \n",
      "\n",
      "Fold: 3  Epoch: 116  Training loss = 2.2997  Validation loss = 4.9364  \n",
      "\n",
      "Fold: 3  Epoch: 117  Training loss = 2.2995  Validation loss = 4.9361  \n",
      "\n",
      "Fold: 3  Epoch: 118  Training loss = 2.2992  Validation loss = 4.9358  \n",
      "\n",
      "Fold: 3  Epoch: 119  Training loss = 2.2989  Validation loss = 4.9356  \n",
      "\n",
      "Fold: 3  Epoch: 120  Training loss = 2.2987  Validation loss = 4.9353  \n",
      "\n",
      "Fold: 3  Epoch: 121  Training loss = 2.2985  Validation loss = 4.9351  \n",
      "\n",
      "Fold: 3  Epoch: 122  Training loss = 2.2982  Validation loss = 4.9348  \n",
      "\n",
      "Fold: 3  Epoch: 123  Training loss = 2.2979  Validation loss = 4.9345  \n",
      "\n",
      "Fold: 3  Epoch: 124  Training loss = 2.2976  Validation loss = 4.9342  \n",
      "\n",
      "Fold: 3  Epoch: 125  Training loss = 2.2974  Validation loss = 4.9339  \n",
      "\n",
      "Fold: 3  Epoch: 126  Training loss = 2.2971  Validation loss = 4.9336  \n",
      "\n",
      "Fold: 3  Epoch: 127  Training loss = 2.2968  Validation loss = 4.9333  \n",
      "\n",
      "Fold: 3  Epoch: 128  Training loss = 2.2965  Validation loss = 4.9330  \n",
      "\n",
      "Fold: 3  Epoch: 129  Training loss = 2.2963  Validation loss = 4.9327  \n",
      "\n",
      "Fold: 3  Epoch: 130  Training loss = 2.2960  Validation loss = 4.9324  \n",
      "\n",
      "Fold: 3  Epoch: 131  Training loss = 2.2957  Validation loss = 4.9322  \n",
      "\n",
      "Fold: 3  Epoch: 132  Training loss = 2.2954  Validation loss = 4.9318  \n",
      "\n",
      "Fold: 3  Epoch: 133  Training loss = 2.2952  Validation loss = 4.9316  \n",
      "\n",
      "Fold: 3  Epoch: 134  Training loss = 2.2949  Validation loss = 4.9313  \n",
      "\n",
      "Fold: 3  Epoch: 135  Training loss = 2.2947  Validation loss = 4.9311  \n",
      "\n",
      "Fold: 3  Epoch: 136  Training loss = 2.2944  Validation loss = 4.9308  \n",
      "\n",
      "Fold: 3  Epoch: 137  Training loss = 2.2942  Validation loss = 4.9305  \n",
      "\n",
      "Fold: 3  Epoch: 138  Training loss = 2.2939  Validation loss = 4.9303  \n",
      "\n",
      "Fold: 3  Epoch: 139  Training loss = 2.2937  Validation loss = 4.9300  \n",
      "\n",
      "Fold: 3  Epoch: 140  Training loss = 2.2935  Validation loss = 4.9298  \n",
      "\n",
      "Fold: 3  Epoch: 141  Training loss = 2.2932  Validation loss = 4.9295  \n",
      "\n",
      "Fold: 3  Epoch: 142  Training loss = 2.2930  Validation loss = 4.9292  \n",
      "\n",
      "Fold: 3  Epoch: 143  Training loss = 2.2927  Validation loss = 4.9289  \n",
      "\n",
      "Fold: 3  Epoch: 144  Training loss = 2.2924  Validation loss = 4.9287  \n",
      "\n",
      "Fold: 3  Epoch: 145  Training loss = 2.2921  Validation loss = 4.9284  \n",
      "\n",
      "Fold: 3  Epoch: 146  Training loss = 2.2918  Validation loss = 4.9281  \n",
      "\n",
      "Fold: 3  Epoch: 147  Training loss = 2.2915  Validation loss = 4.9278  \n",
      "\n",
      "Fold: 3  Epoch: 148  Training loss = 2.2913  Validation loss = 4.9275  \n",
      "\n",
      "Fold: 3  Epoch: 149  Training loss = 2.2910  Validation loss = 4.9272  \n",
      "\n",
      "Fold: 3  Epoch: 150  Training loss = 2.2907  Validation loss = 4.9269  \n",
      "\n",
      "Fold: 3  Epoch: 151  Training loss = 2.2905  Validation loss = 4.9266  \n",
      "\n",
      "Fold: 3  Epoch: 152  Training loss = 2.2902  Validation loss = 4.9264  \n",
      "\n",
      "Fold: 3  Epoch: 153  Training loss = 2.2900  Validation loss = 4.9261  \n",
      "\n",
      "Fold: 3  Epoch: 154  Training loss = 2.2897  Validation loss = 4.9258  \n",
      "\n",
      "Fold: 3  Epoch: 155  Training loss = 2.2895  Validation loss = 4.9255  \n",
      "\n",
      "Fold: 3  Epoch: 156  Training loss = 2.2892  Validation loss = 4.9252  \n",
      "\n",
      "Fold: 3  Epoch: 157  Training loss = 2.2889  Validation loss = 4.9249  \n",
      "\n",
      "Fold: 3  Epoch: 158  Training loss = 2.2886  Validation loss = 4.9247  \n",
      "\n",
      "Fold: 3  Epoch: 159  Training loss = 2.2884  Validation loss = 4.9244  \n",
      "\n",
      "Fold: 3  Epoch: 160  Training loss = 2.2881  Validation loss = 4.9241  \n",
      "\n",
      "Fold: 3  Epoch: 161  Training loss = 2.2879  Validation loss = 4.9239  \n",
      "\n",
      "Fold: 3  Epoch: 162  Training loss = 2.2875  Validation loss = 4.9235  \n",
      "\n",
      "Fold: 3  Epoch: 163  Training loss = 2.2873  Validation loss = 4.9232  \n",
      "\n",
      "Fold: 3  Epoch: 164  Training loss = 2.2870  Validation loss = 4.9230  \n",
      "\n",
      "Fold: 3  Epoch: 165  Training loss = 2.2868  Validation loss = 4.9227  \n",
      "\n",
      "Fold: 3  Epoch: 166  Training loss = 2.2865  Validation loss = 4.9224  \n",
      "\n",
      "Fold: 3  Epoch: 167  Training loss = 2.2862  Validation loss = 4.9221  \n",
      "\n",
      "Fold: 3  Epoch: 168  Training loss = 2.2860  Validation loss = 4.9219  \n",
      "\n",
      "Fold: 3  Epoch: 169  Training loss = 2.2857  Validation loss = 4.9216  \n",
      "\n",
      "Fold: 3  Epoch: 170  Training loss = 2.2855  Validation loss = 4.9213  \n",
      "\n",
      "Fold: 3  Epoch: 171  Training loss = 2.2852  Validation loss = 4.9211  \n",
      "\n",
      "Fold: 3  Epoch: 172  Training loss = 2.2849  Validation loss = 4.9207  \n",
      "\n",
      "Fold: 3  Epoch: 173  Training loss = 2.2846  Validation loss = 4.9204  \n",
      "\n",
      "Fold: 3  Epoch: 174  Training loss = 2.2843  Validation loss = 4.9201  \n",
      "\n",
      "Fold: 3  Epoch: 175  Training loss = 2.2840  Validation loss = 4.9198  \n",
      "\n",
      "Fold: 3  Epoch: 176  Training loss = 2.2838  Validation loss = 4.9195  \n",
      "\n",
      "Fold: 3  Epoch: 177  Training loss = 2.2835  Validation loss = 4.9192  \n",
      "\n",
      "Fold: 3  Epoch: 178  Training loss = 2.2832  Validation loss = 4.9189  \n",
      "\n",
      "Fold: 3  Epoch: 179  Training loss = 2.2830  Validation loss = 4.9187  \n",
      "\n",
      "Fold: 3  Epoch: 180  Training loss = 2.2827  Validation loss = 4.9184  \n",
      "\n",
      "Fold: 3  Epoch: 181  Training loss = 2.2824  Validation loss = 4.9181  \n",
      "\n",
      "Fold: 3  Epoch: 182  Training loss = 2.2822  Validation loss = 4.9179  \n",
      "\n",
      "Fold: 3  Epoch: 183  Training loss = 2.2819  Validation loss = 4.9176  \n",
      "\n",
      "Fold: 3  Epoch: 184  Training loss = 2.2817  Validation loss = 4.9173  \n",
      "\n",
      "Fold: 3  Epoch: 185  Training loss = 2.2814  Validation loss = 4.9171  \n",
      "\n",
      "Fold: 3  Epoch: 186  Training loss = 2.2811  Validation loss = 4.9167  \n",
      "\n",
      "Fold: 3  Epoch: 187  Training loss = 2.2809  Validation loss = 4.9164  \n",
      "\n",
      "Fold: 3  Epoch: 188  Training loss = 2.2806  Validation loss = 4.9162  \n",
      "\n",
      "Fold: 3  Epoch: 189  Training loss = 2.2803  Validation loss = 4.9159  \n",
      "\n",
      "Fold: 3  Epoch: 190  Training loss = 2.2801  Validation loss = 4.9156  \n",
      "\n",
      "Fold: 3  Epoch: 191  Training loss = 2.2798  Validation loss = 4.9153  \n",
      "\n",
      "Fold: 3  Epoch: 192  Training loss = 2.2795  Validation loss = 4.9150  \n",
      "\n",
      "Fold: 3  Epoch: 193  Training loss = 2.2793  Validation loss = 4.9148  \n",
      "\n",
      "Fold: 3  Epoch: 194  Training loss = 2.2790  Validation loss = 4.9145  \n",
      "\n",
      "Fold: 3  Epoch: 195  Training loss = 2.2787  Validation loss = 4.9142  \n",
      "\n",
      "Fold: 3  Epoch: 196  Training loss = 2.2785  Validation loss = 4.9139  \n",
      "\n",
      "Fold: 3  Epoch: 197  Training loss = 2.2782  Validation loss = 4.9137  \n",
      "\n",
      "Fold: 3  Epoch: 198  Training loss = 2.2780  Validation loss = 4.9134  \n",
      "\n",
      "Fold: 3  Epoch: 199  Training loss = 2.2777  Validation loss = 4.9131  \n",
      "\n",
      "Fold: 3  Epoch: 200  Training loss = 2.2775  Validation loss = 4.9129  \n",
      "\n",
      "Fold: 3  Epoch: 201  Training loss = 2.2772  Validation loss = 4.9126  \n",
      "\n",
      "Fold: 3  Epoch: 202  Training loss = 2.2770  Validation loss = 4.9123  \n",
      "\n",
      "Fold: 3  Epoch: 203  Training loss = 2.2767  Validation loss = 4.9120  \n",
      "\n",
      "Fold: 3  Epoch: 204  Training loss = 2.2764  Validation loss = 4.9117  \n",
      "\n",
      "Fold: 3  Epoch: 205  Training loss = 2.2761  Validation loss = 4.9114  \n",
      "\n",
      "Fold: 3  Epoch: 206  Training loss = 2.2758  Validation loss = 4.9111  \n",
      "\n",
      "Fold: 3  Epoch: 207  Training loss = 2.2756  Validation loss = 4.9108  \n",
      "\n",
      "Fold: 3  Epoch: 208  Training loss = 2.2753  Validation loss = 4.9105  \n",
      "\n",
      "Fold: 3  Epoch: 209  Training loss = 2.2750  Validation loss = 4.9102  \n",
      "\n",
      "Fold: 3  Epoch: 210  Training loss = 2.2747  Validation loss = 4.9098  \n",
      "\n",
      "Fold: 3  Epoch: 211  Training loss = 2.2744  Validation loss = 4.9095  \n",
      "\n",
      "Fold: 3  Epoch: 212  Training loss = 2.2741  Validation loss = 4.9092  \n",
      "\n",
      "Fold: 3  Epoch: 213  Training loss = 2.2739  Validation loss = 4.9090  \n",
      "\n",
      "Fold: 3  Epoch: 214  Training loss = 2.2736  Validation loss = 4.9087  \n",
      "\n",
      "Fold: 3  Epoch: 215  Training loss = 2.2733  Validation loss = 4.9084  \n",
      "\n",
      "Fold: 3  Epoch: 216  Training loss = 2.2730  Validation loss = 4.9081  \n",
      "\n",
      "Fold: 3  Epoch: 217  Training loss = 2.2728  Validation loss = 4.9078  \n",
      "\n",
      "Fold: 3  Epoch: 218  Training loss = 2.2726  Validation loss = 4.9075  \n",
      "\n",
      "Fold: 3  Epoch: 219  Training loss = 2.2723  Validation loss = 4.9072  \n",
      "\n",
      "Fold: 3  Epoch: 220  Training loss = 2.2721  Validation loss = 4.9070  \n",
      "\n",
      "Fold: 3  Epoch: 221  Training loss = 2.2718  Validation loss = 4.9067  \n",
      "\n",
      "Fold: 3  Epoch: 222  Training loss = 2.2715  Validation loss = 4.9065  \n",
      "\n",
      "Fold: 3  Epoch: 223  Training loss = 2.2713  Validation loss = 4.9062  \n",
      "\n",
      "Fold: 3  Epoch: 224  Training loss = 2.2710  Validation loss = 4.9059  \n",
      "\n",
      "Fold: 3  Epoch: 225  Training loss = 2.2708  Validation loss = 4.9057  \n",
      "\n",
      "Fold: 3  Epoch: 226  Training loss = 2.2705  Validation loss = 4.9054  \n",
      "\n",
      "Fold: 3  Epoch: 227  Training loss = 2.2702  Validation loss = 4.9051  \n",
      "\n",
      "Fold: 3  Epoch: 228  Training loss = 2.2700  Validation loss = 4.9049  \n",
      "\n",
      "Fold: 3  Epoch: 229  Training loss = 2.2697  Validation loss = 4.9046  \n",
      "\n",
      "Fold: 3  Epoch: 230  Training loss = 2.2695  Validation loss = 4.9043  \n",
      "\n",
      "Fold: 3  Epoch: 231  Training loss = 2.2692  Validation loss = 4.9039  \n",
      "\n",
      "Fold: 3  Epoch: 232  Training loss = 2.2689  Validation loss = 4.9037  \n",
      "\n",
      "Fold: 3  Epoch: 233  Training loss = 2.2687  Validation loss = 4.9035  \n",
      "\n",
      "Fold: 3  Epoch: 234  Training loss = 2.2685  Validation loss = 4.9032  \n",
      "\n",
      "Fold: 3  Epoch: 235  Training loss = 2.2682  Validation loss = 4.9029  \n",
      "\n",
      "Fold: 3  Epoch: 236  Training loss = 2.2679  Validation loss = 4.9026  \n",
      "\n",
      "Fold: 3  Epoch: 237  Training loss = 2.2676  Validation loss = 4.9023  \n",
      "\n",
      "Fold: 3  Epoch: 238  Training loss = 2.2674  Validation loss = 4.9021  \n",
      "\n",
      "Fold: 3  Epoch: 239  Training loss = 2.2671  Validation loss = 4.9017  \n",
      "\n",
      "Fold: 3  Epoch: 240  Training loss = 2.2668  Validation loss = 4.9015  \n",
      "\n",
      "Fold: 3  Epoch: 241  Training loss = 2.2666  Validation loss = 4.9012  \n",
      "\n",
      "Fold: 3  Epoch: 242  Training loss = 2.2664  Validation loss = 4.9009  \n",
      "\n",
      "Fold: 3  Epoch: 243  Training loss = 2.2661  Validation loss = 4.9007  \n",
      "\n",
      "Fold: 3  Epoch: 244  Training loss = 2.2658  Validation loss = 4.9004  \n",
      "\n",
      "Fold: 3  Epoch: 245  Training loss = 2.2656  Validation loss = 4.9001  \n",
      "\n",
      "Fold: 3  Epoch: 246  Training loss = 2.2653  Validation loss = 4.8998  \n",
      "\n",
      "Fold: 3  Epoch: 247  Training loss = 2.2650  Validation loss = 4.8995  \n",
      "\n",
      "Fold: 3  Epoch: 248  Training loss = 2.2647  Validation loss = 4.8992  \n",
      "\n",
      "Fold: 3  Epoch: 249  Training loss = 2.2645  Validation loss = 4.8989  \n",
      "\n",
      "Fold: 3  Epoch: 250  Training loss = 2.2642  Validation loss = 4.8986  \n",
      "\n",
      "Fold: 3  Epoch: 251  Training loss = 2.2639  Validation loss = 4.8983  \n",
      "\n",
      "Fold: 3  Epoch: 252  Training loss = 2.2637  Validation loss = 4.8981  \n",
      "\n",
      "Fold: 3  Epoch: 253  Training loss = 2.2634  Validation loss = 4.8977  \n",
      "\n",
      "Fold: 3  Epoch: 254  Training loss = 2.2632  Validation loss = 4.8975  \n",
      "\n",
      "Fold: 3  Epoch: 255  Training loss = 2.2629  Validation loss = 4.8972  \n",
      "\n",
      "Fold: 3  Epoch: 256  Training loss = 2.2626  Validation loss = 4.8969  \n",
      "\n",
      "Fold: 3  Epoch: 257  Training loss = 2.2623  Validation loss = 4.8966  \n",
      "\n",
      "Fold: 3  Epoch: 258  Training loss = 2.2620  Validation loss = 4.8962  \n",
      "\n",
      "Fold: 3  Epoch: 259  Training loss = 2.2617  Validation loss = 4.8959  \n",
      "\n",
      "Fold: 3  Epoch: 260  Training loss = 2.2614  Validation loss = 4.8956  \n",
      "\n",
      "Fold: 3  Epoch: 261  Training loss = 2.2611  Validation loss = 4.8953  \n",
      "\n",
      "Fold: 3  Epoch: 262  Training loss = 2.2609  Validation loss = 4.8950  \n",
      "\n",
      "Fold: 3  Epoch: 263  Training loss = 2.2606  Validation loss = 4.8947  \n",
      "\n",
      "Fold: 3  Epoch: 264  Training loss = 2.2604  Validation loss = 4.8945  \n",
      "\n",
      "Fold: 3  Epoch: 265  Training loss = 2.2601  Validation loss = 4.8941  \n",
      "\n",
      "Fold: 3  Epoch: 266  Training loss = 2.2598  Validation loss = 4.8938  \n",
      "\n",
      "Fold: 3  Epoch: 267  Training loss = 2.2595  Validation loss = 4.8936  \n",
      "\n",
      "Fold: 3  Epoch: 268  Training loss = 2.2593  Validation loss = 4.8933  \n",
      "\n",
      "Fold: 3  Epoch: 269  Training loss = 2.2590  Validation loss = 4.8930  \n",
      "\n",
      "Fold: 3  Epoch: 270  Training loss = 2.2588  Validation loss = 4.8928  \n",
      "\n",
      "Fold: 3  Epoch: 271  Training loss = 2.2585  Validation loss = 4.8925  \n",
      "\n",
      "Fold: 3  Epoch: 272  Training loss = 2.2583  Validation loss = 4.8922  \n",
      "\n",
      "Fold: 3  Epoch: 273  Training loss = 2.2580  Validation loss = 4.8919  \n",
      "\n",
      "Fold: 3  Epoch: 274  Training loss = 2.2578  Validation loss = 4.8917  \n",
      "\n",
      "Fold: 3  Epoch: 275  Training loss = 2.2575  Validation loss = 4.8914  \n",
      "\n",
      "Fold: 3  Epoch: 276  Training loss = 2.2573  Validation loss = 4.8911  \n",
      "\n",
      "Fold: 3  Epoch: 277  Training loss = 2.2570  Validation loss = 4.8909  \n",
      "\n",
      "Fold: 3  Epoch: 278  Training loss = 2.2567  Validation loss = 4.8906  \n",
      "\n",
      "Fold: 3  Epoch: 279  Training loss = 2.2564  Validation loss = 4.8902  \n",
      "\n",
      "Fold: 3  Epoch: 280  Training loss = 2.2561  Validation loss = 4.8899  \n",
      "\n",
      "Fold: 3  Epoch: 281  Training loss = 2.2559  Validation loss = 4.8896  \n",
      "\n",
      "Fold: 3  Epoch: 282  Training loss = 2.2556  Validation loss = 4.8894  \n",
      "\n",
      "Fold: 3  Epoch: 283  Training loss = 2.2553  Validation loss = 4.8891  \n",
      "\n",
      "Fold: 3  Epoch: 284  Training loss = 2.2551  Validation loss = 4.8888  \n",
      "\n",
      "Fold: 3  Epoch: 285  Training loss = 2.2548  Validation loss = 4.8885  \n",
      "\n",
      "Fold: 3  Epoch: 286  Training loss = 2.2546  Validation loss = 4.8883  \n",
      "\n",
      "Fold: 3  Epoch: 287  Training loss = 2.2543  Validation loss = 4.8879  \n",
      "\n",
      "Fold: 3  Epoch: 288  Training loss = 2.2541  Validation loss = 4.8877  \n",
      "\n",
      "Fold: 3  Epoch: 289  Training loss = 2.2538  Validation loss = 4.8874  \n",
      "\n",
      "Fold: 3  Epoch: 290  Training loss = 2.2535  Validation loss = 4.8871  \n",
      "\n",
      "Fold: 3  Epoch: 291  Training loss = 2.2533  Validation loss = 4.8869  \n",
      "\n",
      "Fold: 3  Epoch: 292  Training loss = 2.2530  Validation loss = 4.8866  \n",
      "\n",
      "Fold: 3  Epoch: 293  Training loss = 2.2527  Validation loss = 4.8863  \n",
      "\n",
      "Fold: 3  Epoch: 294  Training loss = 2.2525  Validation loss = 4.8860  \n",
      "\n",
      "Fold: 3  Epoch: 295  Training loss = 2.2522  Validation loss = 4.8857  \n",
      "\n",
      "Fold: 3  Epoch: 296  Training loss = 2.2520  Validation loss = 4.8854  \n",
      "\n",
      "Fold: 3  Epoch: 297  Training loss = 2.2517  Validation loss = 4.8852  \n",
      "\n",
      "Fold: 3  Epoch: 298  Training loss = 2.2515  Validation loss = 4.8849  \n",
      "\n",
      "Fold: 3  Epoch: 299  Training loss = 2.2512  Validation loss = 4.8846  \n",
      "\n",
      "Fold: 3  Epoch: 300  Training loss = 2.2509  Validation loss = 4.8843  \n",
      "\n",
      "Fold: 3  Epoch: 301  Training loss = 2.2507  Validation loss = 4.8840  \n",
      "\n",
      "Fold: 3  Epoch: 302  Training loss = 2.2504  Validation loss = 4.8837  \n",
      "\n",
      "Fold: 3  Epoch: 303  Training loss = 2.2501  Validation loss = 4.8834  \n",
      "\n",
      "Fold: 3  Epoch: 304  Training loss = 2.2499  Validation loss = 4.8831  \n",
      "\n",
      "Fold: 3  Epoch: 305  Training loss = 2.2496  Validation loss = 4.8828  \n",
      "\n",
      "Fold: 3  Epoch: 306  Training loss = 2.2493  Validation loss = 4.8825  \n",
      "\n",
      "Fold: 3  Epoch: 307  Training loss = 2.2490  Validation loss = 4.8823  \n",
      "\n",
      "Fold: 3  Epoch: 308  Training loss = 2.2488  Validation loss = 4.8820  \n",
      "\n",
      "Fold: 3  Epoch: 309  Training loss = 2.2485  Validation loss = 4.8817  \n",
      "\n",
      "Fold: 3  Epoch: 310  Training loss = 2.2482  Validation loss = 4.8813  \n",
      "\n",
      "Fold: 3  Epoch: 311  Training loss = 2.2479  Validation loss = 4.8810  \n",
      "\n",
      "Fold: 3  Epoch: 312  Training loss = 2.2476  Validation loss = 4.8807  \n",
      "\n",
      "Fold: 3  Epoch: 313  Training loss = 2.2474  Validation loss = 4.8805  \n",
      "\n",
      "Fold: 3  Epoch: 314  Training loss = 2.2471  Validation loss = 4.8802  \n",
      "\n",
      "Fold: 3  Epoch: 315  Training loss = 2.2469  Validation loss = 4.8799  \n",
      "\n",
      "Fold: 3  Epoch: 316  Training loss = 2.2466  Validation loss = 4.8796  \n",
      "\n",
      "Fold: 3  Epoch: 317  Training loss = 2.2463  Validation loss = 4.8793  \n",
      "\n",
      "Fold: 3  Epoch: 318  Training loss = 2.2461  Validation loss = 4.8791  \n",
      "\n",
      "Fold: 3  Epoch: 319  Training loss = 2.2458  Validation loss = 4.8788  \n",
      "\n",
      "Fold: 3  Epoch: 320  Training loss = 2.2455  Validation loss = 4.8785  \n",
      "\n",
      "Fold: 3  Epoch: 321  Training loss = 2.2453  Validation loss = 4.8782  \n",
      "\n",
      "Fold: 3  Epoch: 322  Training loss = 2.2451  Validation loss = 4.8779  \n",
      "\n",
      "Fold: 3  Epoch: 323  Training loss = 2.2448  Validation loss = 4.8777  \n",
      "\n",
      "Fold: 3  Epoch: 324  Training loss = 2.2446  Validation loss = 4.8774  \n",
      "\n",
      "Fold: 3  Epoch: 325  Training loss = 2.2443  Validation loss = 4.8772  \n",
      "\n",
      "Fold: 3  Epoch: 326  Training loss = 2.2441  Validation loss = 4.8768  \n",
      "\n",
      "Fold: 3  Epoch: 327  Training loss = 2.2438  Validation loss = 4.8766  \n",
      "\n",
      "Fold: 3  Epoch: 328  Training loss = 2.2435  Validation loss = 4.8763  \n",
      "\n",
      "Fold: 3  Epoch: 329  Training loss = 2.2433  Validation loss = 4.8760  \n",
      "\n",
      "Fold: 3  Epoch: 330  Training loss = 2.2430  Validation loss = 4.8757  \n",
      "\n",
      "Fold: 3  Epoch: 331  Training loss = 2.2428  Validation loss = 4.8754  \n",
      "\n",
      "Fold: 3  Epoch: 332  Training loss = 2.2425  Validation loss = 4.8751  \n",
      "\n",
      "Fold: 3  Epoch: 333  Training loss = 2.2422  Validation loss = 4.8748  \n",
      "\n",
      "Fold: 3  Epoch: 334  Training loss = 2.2420  Validation loss = 4.8746  \n",
      "\n",
      "Fold: 3  Epoch: 335  Training loss = 2.2417  Validation loss = 4.8743  \n",
      "\n",
      "Fold: 3  Epoch: 336  Training loss = 2.2415  Validation loss = 4.8741  \n",
      "\n",
      "Fold: 3  Epoch: 337  Training loss = 2.2413  Validation loss = 4.8738  \n",
      "\n",
      "Fold: 3  Epoch: 338  Training loss = 2.2410  Validation loss = 4.8735  \n",
      "\n",
      "Fold: 3  Epoch: 339  Training loss = 2.2407  Validation loss = 4.8732  \n",
      "\n",
      "Fold: 3  Epoch: 340  Training loss = 2.2405  Validation loss = 4.8730  \n",
      "\n",
      "Fold: 3  Epoch: 341  Training loss = 2.2402  Validation loss = 4.8727  \n",
      "\n",
      "Fold: 3  Epoch: 342  Training loss = 2.2400  Validation loss = 4.8724  \n",
      "\n",
      "Fold: 3  Epoch: 343  Training loss = 2.2397  Validation loss = 4.8721  \n",
      "\n",
      "Fold: 3  Epoch: 344  Training loss = 2.2394  Validation loss = 4.8718  \n",
      "\n",
      "Fold: 3  Epoch: 345  Training loss = 2.2392  Validation loss = 4.8715  \n",
      "\n",
      "Fold: 3  Epoch: 346  Training loss = 2.2389  Validation loss = 4.8712  \n",
      "\n",
      "Fold: 3  Epoch: 347  Training loss = 2.2387  Validation loss = 4.8710  \n",
      "\n",
      "Fold: 3  Epoch: 348  Training loss = 2.2384  Validation loss = 4.8707  \n",
      "\n",
      "Fold: 3  Epoch: 349  Training loss = 2.2382  Validation loss = 4.8705  \n",
      "\n",
      "Fold: 3  Epoch: 350  Training loss = 2.2379  Validation loss = 4.8702  \n",
      "\n",
      "Fold: 3  Epoch: 351  Training loss = 2.2377  Validation loss = 4.8699  \n",
      "\n",
      "Fold: 3  Epoch: 352  Training loss = 2.2374  Validation loss = 4.8696  \n",
      "\n",
      "Fold: 3  Epoch: 353  Training loss = 2.2372  Validation loss = 4.8693  \n",
      "\n",
      "Fold: 3  Epoch: 354  Training loss = 2.2369  Validation loss = 4.8691  \n",
      "\n",
      "Fold: 3  Epoch: 355  Training loss = 2.2367  Validation loss = 4.8688  \n",
      "\n",
      "Fold: 3  Epoch: 356  Training loss = 2.2365  Validation loss = 4.8686  \n",
      "\n",
      "Fold: 3  Epoch: 357  Training loss = 2.2362  Validation loss = 4.8683  \n",
      "\n",
      "Fold: 3  Epoch: 358  Training loss = 2.2359  Validation loss = 4.8680  \n",
      "\n",
      "Fold: 3  Epoch: 359  Training loss = 2.2357  Validation loss = 4.8677  \n",
      "\n",
      "Fold: 3  Epoch: 360  Training loss = 2.2354  Validation loss = 4.8674  \n",
      "\n",
      "Fold: 3  Epoch: 361  Training loss = 2.2351  Validation loss = 4.8671  \n",
      "\n",
      "Fold: 3  Epoch: 362  Training loss = 2.2349  Validation loss = 4.8668  \n",
      "\n",
      "Fold: 3  Epoch: 363  Training loss = 2.2346  Validation loss = 4.8665  \n",
      "\n",
      "Fold: 3  Epoch: 364  Training loss = 2.2344  Validation loss = 4.8662  \n",
      "\n",
      "Fold: 3  Epoch: 365  Training loss = 2.2341  Validation loss = 4.8659  \n",
      "\n",
      "Fold: 3  Epoch: 366  Training loss = 2.2338  Validation loss = 4.8656  \n",
      "\n",
      "Fold: 3  Epoch: 367  Training loss = 2.2335  Validation loss = 4.8652  \n",
      "\n",
      "Fold: 3  Epoch: 368  Training loss = 2.2332  Validation loss = 4.8649  \n",
      "\n",
      "Fold: 3  Epoch: 369  Training loss = 2.2329  Validation loss = 4.8646  \n",
      "\n",
      "Fold: 3  Epoch: 370  Training loss = 2.2326  Validation loss = 4.8643  \n",
      "\n",
      "Fold: 3  Epoch: 371  Training loss = 2.2324  Validation loss = 4.8641  \n",
      "\n",
      "Fold: 3  Epoch: 372  Training loss = 2.2321  Validation loss = 4.8637  \n",
      "\n",
      "Fold: 3  Epoch: 373  Training loss = 2.2319  Validation loss = 4.8635  \n",
      "\n",
      "Fold: 3  Epoch: 374  Training loss = 2.2316  Validation loss = 4.8632  \n",
      "\n",
      "Fold: 3  Epoch: 375  Training loss = 2.2314  Validation loss = 4.8629  \n",
      "\n",
      "Fold: 3  Epoch: 376  Training loss = 2.2311  Validation loss = 4.8627  \n",
      "\n",
      "Fold: 3  Epoch: 377  Training loss = 2.2309  Validation loss = 4.8624  \n",
      "\n",
      "Fold: 3  Epoch: 378  Training loss = 2.2307  Validation loss = 4.8622  \n",
      "\n",
      "Fold: 3  Epoch: 379  Training loss = 2.2304  Validation loss = 4.8619  \n",
      "\n",
      "Fold: 3  Epoch: 380  Training loss = 2.2302  Validation loss = 4.8616  \n",
      "\n",
      "Fold: 3  Epoch: 381  Training loss = 2.2299  Validation loss = 4.8613  \n",
      "\n",
      "Fold: 3  Epoch: 382  Training loss = 2.2297  Validation loss = 4.8610  \n",
      "\n",
      "Fold: 3  Epoch: 383  Training loss = 2.2294  Validation loss = 4.8608  \n",
      "\n",
      "Fold: 3  Epoch: 384  Training loss = 2.2292  Validation loss = 4.8605  \n",
      "\n",
      "Fold: 3  Epoch: 385  Training loss = 2.2289  Validation loss = 4.8602  \n",
      "\n",
      "Fold: 3  Epoch: 386  Training loss = 2.2286  Validation loss = 4.8599  \n",
      "\n",
      "Fold: 3  Epoch: 387  Training loss = 2.2284  Validation loss = 4.8596  \n",
      "\n",
      "Fold: 3  Epoch: 388  Training loss = 2.2281  Validation loss = 4.8593  \n",
      "\n",
      "Fold: 3  Epoch: 389  Training loss = 2.2278  Validation loss = 4.8590  \n",
      "\n",
      "Fold: 3  Epoch: 390  Training loss = 2.2276  Validation loss = 4.8588  \n",
      "\n",
      "Fold: 3  Epoch: 391  Training loss = 2.2274  Validation loss = 4.8585  \n",
      "\n",
      "Fold: 3  Epoch: 392  Training loss = 2.2271  Validation loss = 4.8582  \n",
      "\n",
      "Fold: 3  Epoch: 393  Training loss = 2.2268  Validation loss = 4.8579  \n",
      "\n",
      "Fold: 3  Epoch: 394  Training loss = 2.2266  Validation loss = 4.8576  \n",
      "\n",
      "Fold: 3  Epoch: 395  Training loss = 2.2262  Validation loss = 4.8573  \n",
      "\n",
      "Fold: 3  Epoch: 396  Training loss = 2.2260  Validation loss = 4.8570  \n",
      "\n",
      "Fold: 3  Epoch: 397  Training loss = 2.2257  Validation loss = 4.8567  \n",
      "\n",
      "Fold: 3  Epoch: 398  Training loss = 2.2255  Validation loss = 4.8565  \n",
      "\n",
      "Fold: 3  Epoch: 399  Training loss = 2.2253  Validation loss = 4.8562  \n",
      "\n",
      "Fold: 3  Epoch: 400  Training loss = 2.2250  Validation loss = 4.8559  \n",
      "\n",
      "Fold: 3  Epoch: 401  Training loss = 2.2248  Validation loss = 4.8557  \n",
      "\n",
      "Fold: 3  Epoch: 402  Training loss = 2.2245  Validation loss = 4.8553  \n",
      "\n",
      "Fold: 3  Epoch: 403  Training loss = 2.2242  Validation loss = 4.8550  \n",
      "\n",
      "Fold: 3  Epoch: 404  Training loss = 2.2239  Validation loss = 4.8547  \n",
      "\n",
      "Fold: 3  Epoch: 405  Training loss = 2.2236  Validation loss = 4.8544  \n",
      "\n",
      "Fold: 3  Epoch: 406  Training loss = 2.2234  Validation loss = 4.8541  \n",
      "\n",
      "Fold: 3  Epoch: 407  Training loss = 2.2232  Validation loss = 4.8539  \n",
      "\n",
      "Fold: 3  Epoch: 408  Training loss = 2.2229  Validation loss = 4.8536  \n",
      "\n",
      "Fold: 3  Epoch: 409  Training loss = 2.2226  Validation loss = 4.8533  \n",
      "\n",
      "Fold: 3  Epoch: 410  Training loss = 2.2224  Validation loss = 4.8530  \n",
      "\n",
      "Fold: 3  Epoch: 411  Training loss = 2.2221  Validation loss = 4.8528  \n",
      "\n",
      "Fold: 3  Epoch: 412  Training loss = 2.2219  Validation loss = 4.8525  \n",
      "\n",
      "Fold: 3  Epoch: 413  Training loss = 2.2216  Validation loss = 4.8522  \n",
      "\n",
      "Fold: 3  Epoch: 414  Training loss = 2.2213  Validation loss = 4.8519  \n",
      "\n",
      "Fold: 3  Epoch: 415  Training loss = 2.2210  Validation loss = 4.8516  \n",
      "\n",
      "Fold: 3  Epoch: 416  Training loss = 2.2208  Validation loss = 4.8513  \n",
      "\n",
      "Fold: 3  Epoch: 417  Training loss = 2.2206  Validation loss = 4.8510  \n",
      "\n",
      "Fold: 3  Epoch: 418  Training loss = 2.2203  Validation loss = 4.8507  \n",
      "\n",
      "Fold: 3  Epoch: 419  Training loss = 2.2200  Validation loss = 4.8504  \n",
      "\n",
      "Fold: 3  Epoch: 420  Training loss = 2.2197  Validation loss = 4.8501  \n",
      "\n",
      "Fold: 3  Epoch: 421  Training loss = 2.2195  Validation loss = 4.8498  \n",
      "\n",
      "Fold: 3  Epoch: 422  Training loss = 2.2193  Validation loss = 4.8496  \n",
      "\n",
      "Fold: 3  Epoch: 423  Training loss = 2.2190  Validation loss = 4.8493  \n",
      "\n",
      "Fold: 3  Epoch: 424  Training loss = 2.2188  Validation loss = 4.8491  \n",
      "\n",
      "Fold: 3  Epoch: 425  Training loss = 2.2185  Validation loss = 4.8488  \n",
      "\n",
      "Fold: 3  Epoch: 426  Training loss = 2.2183  Validation loss = 4.8485  \n",
      "\n",
      "Fold: 3  Epoch: 427  Training loss = 2.2180  Validation loss = 4.8482  \n",
      "\n",
      "Fold: 3  Epoch: 428  Training loss = 2.2178  Validation loss = 4.8480  \n",
      "\n",
      "Fold: 3  Epoch: 429  Training loss = 2.2175  Validation loss = 4.8477  \n",
      "\n",
      "Fold: 3  Epoch: 430  Training loss = 2.2173  Validation loss = 4.8474  \n",
      "\n",
      "Fold: 3  Epoch: 431  Training loss = 2.2170  Validation loss = 4.8471  \n",
      "\n",
      "Fold: 3  Epoch: 432  Training loss = 2.2167  Validation loss = 4.8468  \n",
      "\n",
      "Fold: 3  Epoch: 433  Training loss = 2.2165  Validation loss = 4.8466  \n",
      "\n",
      "Fold: 3  Epoch: 434  Training loss = 2.2162  Validation loss = 4.8463  \n",
      "\n",
      "Fold: 3  Epoch: 435  Training loss = 2.2160  Validation loss = 4.8460  \n",
      "\n",
      "Fold: 3  Epoch: 436  Training loss = 2.2158  Validation loss = 4.8458  \n",
      "\n",
      "Fold: 3  Epoch: 437  Training loss = 2.2156  Validation loss = 4.8456  \n",
      "\n",
      "Fold: 3  Epoch: 438  Training loss = 2.2153  Validation loss = 4.8453  \n",
      "\n",
      "Fold: 3  Epoch: 439  Training loss = 2.2151  Validation loss = 4.8450  \n",
      "\n",
      "Fold: 3  Epoch: 440  Training loss = 2.2148  Validation loss = 4.8447  \n",
      "\n",
      "Fold: 3  Epoch: 441  Training loss = 2.2145  Validation loss = 4.8444  \n",
      "\n",
      "Fold: 3  Epoch: 442  Training loss = 2.2143  Validation loss = 4.8441  \n",
      "\n",
      "Fold: 3  Epoch: 443  Training loss = 2.2140  Validation loss = 4.8438  \n",
      "\n",
      "Fold: 3  Epoch: 444  Training loss = 2.2137  Validation loss = 4.8435  \n",
      "\n",
      "Fold: 3  Epoch: 445  Training loss = 2.2135  Validation loss = 4.8432  \n",
      "\n",
      "Fold: 3  Epoch: 446  Training loss = 2.2132  Validation loss = 4.8429  \n",
      "\n",
      "Fold: 3  Epoch: 447  Training loss = 2.2129  Validation loss = 4.8426  \n",
      "\n",
      "Fold: 3  Epoch: 448  Training loss = 2.2126  Validation loss = 4.8423  \n",
      "\n",
      "Fold: 3  Epoch: 449  Training loss = 2.2124  Validation loss = 4.8420  \n",
      "\n",
      "Fold: 3  Epoch: 450  Training loss = 2.2121  Validation loss = 4.8417  \n",
      "\n",
      "Fold: 3  Epoch: 451  Training loss = 2.2119  Validation loss = 4.8415  \n",
      "\n",
      "Fold: 3  Epoch: 452  Training loss = 2.2116  Validation loss = 4.8412  \n",
      "\n",
      "Fold: 3  Epoch: 453  Training loss = 2.2114  Validation loss = 4.8409  \n",
      "\n",
      "Fold: 3  Epoch: 454  Training loss = 2.2111  Validation loss = 4.8406  \n",
      "\n",
      "Fold: 3  Epoch: 455  Training loss = 2.2109  Validation loss = 4.8403  \n",
      "\n",
      "Fold: 3  Epoch: 456  Training loss = 2.2106  Validation loss = 4.8401  \n",
      "\n",
      "Fold: 3  Epoch: 457  Training loss = 2.2104  Validation loss = 4.8398  \n",
      "\n",
      "Fold: 3  Epoch: 458  Training loss = 2.2101  Validation loss = 4.8395  \n",
      "\n",
      "Fold: 3  Epoch: 459  Training loss = 2.2099  Validation loss = 4.8393  \n",
      "\n",
      "Fold: 3  Epoch: 460  Training loss = 2.2097  Validation loss = 4.8390  \n",
      "\n",
      "Fold: 3  Epoch: 461  Training loss = 2.2094  Validation loss = 4.8388  \n",
      "\n",
      "Fold: 3  Epoch: 462  Training loss = 2.2092  Validation loss = 4.8385  \n",
      "\n",
      "Fold: 3  Epoch: 463  Training loss = 2.2089  Validation loss = 4.8382  \n",
      "\n",
      "Fold: 3  Epoch: 464  Training loss = 2.2086  Validation loss = 4.8379  \n",
      "\n",
      "Fold: 3  Epoch: 465  Training loss = 2.2084  Validation loss = 4.8376  \n",
      "\n",
      "Fold: 3  Epoch: 466  Training loss = 2.2081  Validation loss = 4.8373  \n",
      "\n",
      "Fold: 3  Epoch: 467  Training loss = 2.2078  Validation loss = 4.8370  \n",
      "\n",
      "Fold: 3  Epoch: 468  Training loss = 2.2076  Validation loss = 4.8367  \n",
      "\n",
      "Fold: 3  Epoch: 469  Training loss = 2.2073  Validation loss = 4.8365  \n",
      "\n",
      "Fold: 3  Epoch: 470  Training loss = 2.2070  Validation loss = 4.8361  \n",
      "\n",
      "Fold: 3  Epoch: 471  Training loss = 2.2068  Validation loss = 4.8359  \n",
      "\n",
      "Fold: 3  Epoch: 472  Training loss = 2.2066  Validation loss = 4.8356  \n",
      "\n",
      "Fold: 3  Epoch: 473  Training loss = 2.2063  Validation loss = 4.8353  \n",
      "\n",
      "Fold: 3  Epoch: 474  Training loss = 2.2061  Validation loss = 4.8350  \n",
      "\n",
      "Fold: 3  Epoch: 475  Training loss = 2.2058  Validation loss = 4.8348  \n",
      "\n",
      "Fold: 3  Epoch: 476  Training loss = 2.2056  Validation loss = 4.8345  \n",
      "\n",
      "Fold: 3  Epoch: 477  Training loss = 2.2053  Validation loss = 4.8342  \n",
      "\n",
      "Fold: 3  Epoch: 478  Training loss = 2.2051  Validation loss = 4.8339  \n",
      "\n",
      "Fold: 3  Epoch: 479  Training loss = 2.2049  Validation loss = 4.8337  \n",
      "\n",
      "Fold: 3  Epoch: 480  Training loss = 2.2046  Validation loss = 4.8334  \n",
      "\n",
      "Fold: 3  Epoch: 481  Training loss = 2.2044  Validation loss = 4.8331  \n",
      "\n",
      "Fold: 3  Epoch: 482  Training loss = 2.2042  Validation loss = 4.8329  \n",
      "\n",
      "Fold: 3  Epoch: 483  Training loss = 2.2039  Validation loss = 4.8326  \n",
      "\n",
      "Fold: 3  Epoch: 484  Training loss = 2.2036  Validation loss = 4.8323  \n",
      "\n",
      "Fold: 3  Epoch: 485  Training loss = 2.2034  Validation loss = 4.8321  \n",
      "\n",
      "Fold: 3  Epoch: 486  Training loss = 2.2031  Validation loss = 4.8318  \n",
      "\n",
      "Fold: 3  Epoch: 487  Training loss = 2.2029  Validation loss = 4.8316  \n",
      "\n",
      "Fold: 3  Epoch: 488  Training loss = 2.2027  Validation loss = 4.8313  \n",
      "\n",
      "Fold: 3  Epoch: 489  Training loss = 2.2025  Validation loss = 4.8310  \n",
      "\n",
      "Fold: 3  Epoch: 490  Training loss = 2.2022  Validation loss = 4.8307  \n",
      "\n",
      "Fold: 3  Epoch: 491  Training loss = 2.2019  Validation loss = 4.8304  \n",
      "\n",
      "Fold: 3  Epoch: 492  Training loss = 2.2016  Validation loss = 4.8301  \n",
      "\n",
      "Fold: 3  Epoch: 493  Training loss = 2.2014  Validation loss = 4.8298  \n",
      "\n",
      "Fold: 3  Epoch: 494  Training loss = 2.2012  Validation loss = 4.8296  \n",
      "\n",
      "Fold: 3  Epoch: 495  Training loss = 2.2010  Validation loss = 4.8294  \n",
      "\n",
      "Fold: 3  Epoch: 496  Training loss = 2.2007  Validation loss = 4.8290  \n",
      "\n",
      "Fold: 3  Epoch: 497  Training loss = 2.2004  Validation loss = 4.8288  \n",
      "\n",
      "Fold: 3  Epoch: 498  Training loss = 2.2002  Validation loss = 4.8285  \n",
      "\n",
      "Fold: 3  Epoch: 499  Training loss = 2.2000  Validation loss = 4.8282  \n",
      "\n",
      "Fold: 3  Epoch: 500  Training loss = 2.1997  Validation loss = 4.8280  \n",
      "\n",
      "Check model:  Fold: 3  Optimal epoch: 500  \n",
      "\n",
      "Fold: 4  Epoch: 1  Training loss = 2.3531  Validation loss = 5.9767  \n",
      "\n",
      "Fold: 4  Epoch: 2  Training loss = 2.3529  Validation loss = 5.9764  \n",
      "\n",
      "Fold: 4  Epoch: 3  Training loss = 2.3526  Validation loss = 5.9760  \n",
      "\n",
      "Fold: 4  Epoch: 4  Training loss = 2.3523  Validation loss = 5.9757  \n",
      "\n",
      "Fold: 4  Epoch: 5  Training loss = 2.3521  Validation loss = 5.9754  \n",
      "\n",
      "Fold: 4  Epoch: 6  Training loss = 2.3519  Validation loss = 5.9751  \n",
      "\n",
      "Fold: 4  Epoch: 7  Training loss = 2.3516  Validation loss = 5.9748  \n",
      "\n",
      "Fold: 4  Epoch: 8  Training loss = 2.3513  Validation loss = 5.9744  \n",
      "\n",
      "Fold: 4  Epoch: 9  Training loss = 2.3510  Validation loss = 5.9740  \n",
      "\n",
      "Fold: 4  Epoch: 10  Training loss = 2.3507  Validation loss = 5.9737  \n",
      "\n",
      "Fold: 4  Epoch: 11  Training loss = 2.3505  Validation loss = 5.9734  \n",
      "\n",
      "Fold: 4  Epoch: 12  Training loss = 2.3502  Validation loss = 5.9730  \n",
      "\n",
      "Fold: 4  Epoch: 13  Training loss = 2.3500  Validation loss = 5.9727  \n",
      "\n",
      "Fold: 4  Epoch: 14  Training loss = 2.3497  Validation loss = 5.9724  \n",
      "\n",
      "Fold: 4  Epoch: 15  Training loss = 2.3495  Validation loss = 5.9721  \n",
      "\n",
      "Fold: 4  Epoch: 16  Training loss = 2.3492  Validation loss = 5.9718  \n",
      "\n",
      "Fold: 4  Epoch: 17  Training loss = 2.3490  Validation loss = 5.9714  \n",
      "\n",
      "Fold: 4  Epoch: 18  Training loss = 2.3487  Validation loss = 5.9711  \n",
      "\n",
      "Fold: 4  Epoch: 19  Training loss = 2.3484  Validation loss = 5.9707  \n",
      "\n",
      "Fold: 4  Epoch: 20  Training loss = 2.3482  Validation loss = 5.9704  \n",
      "\n",
      "Fold: 4  Epoch: 21  Training loss = 2.3479  Validation loss = 5.9700  \n",
      "\n",
      "Fold: 4  Epoch: 22  Training loss = 2.3476  Validation loss = 5.9697  \n",
      "\n",
      "Fold: 4  Epoch: 23  Training loss = 2.3474  Validation loss = 5.9694  \n",
      "\n",
      "Fold: 4  Epoch: 24  Training loss = 2.3471  Validation loss = 5.9691  \n",
      "\n",
      "Fold: 4  Epoch: 25  Training loss = 2.3468  Validation loss = 5.9686  \n",
      "\n",
      "Fold: 4  Epoch: 26  Training loss = 2.3465  Validation loss = 5.9683  \n",
      "\n",
      "Fold: 4  Epoch: 27  Training loss = 2.3463  Validation loss = 5.9680  \n",
      "\n",
      "Fold: 4  Epoch: 28  Training loss = 2.3460  Validation loss = 5.9676  \n",
      "\n",
      "Fold: 4  Epoch: 29  Training loss = 2.3457  Validation loss = 5.9673  \n",
      "\n",
      "Fold: 4  Epoch: 30  Training loss = 2.3455  Validation loss = 5.9669  \n",
      "\n",
      "Fold: 4  Epoch: 31  Training loss = 2.3452  Validation loss = 5.9666  \n",
      "\n",
      "Fold: 4  Epoch: 32  Training loss = 2.3449  Validation loss = 5.9663  \n",
      "\n",
      "Fold: 4  Epoch: 33  Training loss = 2.3447  Validation loss = 5.9660  \n",
      "\n",
      "Fold: 4  Epoch: 34  Training loss = 2.3444  Validation loss = 5.9656  \n",
      "\n",
      "Fold: 4  Epoch: 35  Training loss = 2.3442  Validation loss = 5.9653  \n",
      "\n",
      "Fold: 4  Epoch: 36  Training loss = 2.3440  Validation loss = 5.9650  \n",
      "\n",
      "Fold: 4  Epoch: 37  Training loss = 2.3437  Validation loss = 5.9646  \n",
      "\n",
      "Fold: 4  Epoch: 38  Training loss = 2.3434  Validation loss = 5.9643  \n",
      "\n",
      "Fold: 4  Epoch: 39  Training loss = 2.3431  Validation loss = 5.9640  \n",
      "\n",
      "Fold: 4  Epoch: 40  Training loss = 2.3429  Validation loss = 5.9636  \n",
      "\n",
      "Fold: 4  Epoch: 41  Training loss = 2.3426  Validation loss = 5.9633  \n",
      "\n",
      "Fold: 4  Epoch: 42  Training loss = 2.3423  Validation loss = 5.9629  \n",
      "\n",
      "Fold: 4  Epoch: 43  Training loss = 2.3420  Validation loss = 5.9626  \n",
      "\n",
      "Fold: 4  Epoch: 44  Training loss = 2.3418  Validation loss = 5.9623  \n",
      "\n",
      "Fold: 4  Epoch: 45  Training loss = 2.3416  Validation loss = 5.9620  \n",
      "\n",
      "Fold: 4  Epoch: 46  Training loss = 2.3413  Validation loss = 5.9616  \n",
      "\n",
      "Fold: 4  Epoch: 47  Training loss = 2.3410  Validation loss = 5.9613  \n",
      "\n",
      "Fold: 4  Epoch: 48  Training loss = 2.3408  Validation loss = 5.9611  \n",
      "\n",
      "Fold: 4  Epoch: 49  Training loss = 2.3405  Validation loss = 5.9607  \n",
      "\n",
      "Fold: 4  Epoch: 50  Training loss = 2.3403  Validation loss = 5.9604  \n",
      "\n",
      "Fold: 4  Epoch: 51  Training loss = 2.3401  Validation loss = 5.9601  \n",
      "\n",
      "Fold: 4  Epoch: 52  Training loss = 2.3398  Validation loss = 5.9598  \n",
      "\n",
      "Fold: 4  Epoch: 53  Training loss = 2.3395  Validation loss = 5.9594  \n",
      "\n",
      "Fold: 4  Epoch: 54  Training loss = 2.3393  Validation loss = 5.9591  \n",
      "\n",
      "Fold: 4  Epoch: 55  Training loss = 2.3391  Validation loss = 5.9589  \n",
      "\n",
      "Fold: 4  Epoch: 56  Training loss = 2.3388  Validation loss = 5.9585  \n",
      "\n",
      "Fold: 4  Epoch: 57  Training loss = 2.3386  Validation loss = 5.9582  \n",
      "\n",
      "Fold: 4  Epoch: 58  Training loss = 2.3383  Validation loss = 5.9578  \n",
      "\n",
      "Fold: 4  Epoch: 59  Training loss = 2.3380  Validation loss = 5.9575  \n",
      "\n",
      "Fold: 4  Epoch: 60  Training loss = 2.3378  Validation loss = 5.9572  \n",
      "\n",
      "Fold: 4  Epoch: 61  Training loss = 2.3376  Validation loss = 5.9569  \n",
      "\n",
      "Fold: 4  Epoch: 62  Training loss = 2.3373  Validation loss = 5.9566  \n",
      "\n",
      "Fold: 4  Epoch: 63  Training loss = 2.3371  Validation loss = 5.9563  \n",
      "\n",
      "Fold: 4  Epoch: 64  Training loss = 2.3368  Validation loss = 5.9560  \n",
      "\n",
      "Fold: 4  Epoch: 65  Training loss = 2.3365  Validation loss = 5.9556  \n",
      "\n",
      "Fold: 4  Epoch: 66  Training loss = 2.3363  Validation loss = 5.9553  \n",
      "\n",
      "Fold: 4  Epoch: 67  Training loss = 2.3360  Validation loss = 5.9550  \n",
      "\n",
      "Fold: 4  Epoch: 68  Training loss = 2.3358  Validation loss = 5.9547  \n",
      "\n",
      "Fold: 4  Epoch: 69  Training loss = 2.3356  Validation loss = 5.9544  \n",
      "\n",
      "Fold: 4  Epoch: 70  Training loss = 2.3353  Validation loss = 5.9540  \n",
      "\n",
      "Fold: 4  Epoch: 71  Training loss = 2.3350  Validation loss = 5.9537  \n",
      "\n",
      "Fold: 4  Epoch: 72  Training loss = 2.3348  Validation loss = 5.9535  \n",
      "\n",
      "Fold: 4  Epoch: 73  Training loss = 2.3345  Validation loss = 5.9531  \n",
      "\n",
      "Fold: 4  Epoch: 74  Training loss = 2.3343  Validation loss = 5.9528  \n",
      "\n",
      "Fold: 4  Epoch: 75  Training loss = 2.3340  Validation loss = 5.9524  \n",
      "\n",
      "Fold: 4  Epoch: 76  Training loss = 2.3337  Validation loss = 5.9521  \n",
      "\n",
      "Fold: 4  Epoch: 77  Training loss = 2.3335  Validation loss = 5.9518  \n",
      "\n",
      "Fold: 4  Epoch: 78  Training loss = 2.3332  Validation loss = 5.9514  \n",
      "\n",
      "Fold: 4  Epoch: 79  Training loss = 2.3329  Validation loss = 5.9511  \n",
      "\n",
      "Fold: 4  Epoch: 80  Training loss = 2.3327  Validation loss = 5.9508  \n",
      "\n",
      "Fold: 4  Epoch: 81  Training loss = 2.3325  Validation loss = 5.9505  \n",
      "\n",
      "Fold: 4  Epoch: 82  Training loss = 2.3322  Validation loss = 5.9502  \n",
      "\n",
      "Fold: 4  Epoch: 83  Training loss = 2.3320  Validation loss = 5.9499  \n",
      "\n",
      "Fold: 4  Epoch: 84  Training loss = 2.3317  Validation loss = 5.9496  \n",
      "\n",
      "Fold: 4  Epoch: 85  Training loss = 2.3314  Validation loss = 5.9492  \n",
      "\n",
      "Fold: 4  Epoch: 86  Training loss = 2.3312  Validation loss = 5.9489  \n",
      "\n",
      "Fold: 4  Epoch: 87  Training loss = 2.3309  Validation loss = 5.9485  \n",
      "\n",
      "Fold: 4  Epoch: 88  Training loss = 2.3307  Validation loss = 5.9482  \n",
      "\n",
      "Fold: 4  Epoch: 89  Training loss = 2.3304  Validation loss = 5.9479  \n",
      "\n",
      "Fold: 4  Epoch: 90  Training loss = 2.3301  Validation loss = 5.9475  \n",
      "\n",
      "Fold: 4  Epoch: 91  Training loss = 2.3299  Validation loss = 5.9472  \n",
      "\n",
      "Fold: 4  Epoch: 92  Training loss = 2.3297  Validation loss = 5.9470  \n",
      "\n",
      "Fold: 4  Epoch: 93  Training loss = 2.3294  Validation loss = 5.9467  \n",
      "\n",
      "Fold: 4  Epoch: 94  Training loss = 2.3292  Validation loss = 5.9464  \n",
      "\n",
      "Fold: 4  Epoch: 95  Training loss = 2.3289  Validation loss = 5.9460  \n",
      "\n",
      "Fold: 4  Epoch: 96  Training loss = 2.3287  Validation loss = 5.9457  \n",
      "\n",
      "Fold: 4  Epoch: 97  Training loss = 2.3284  Validation loss = 5.9454  \n",
      "\n",
      "Fold: 4  Epoch: 98  Training loss = 2.3282  Validation loss = 5.9452  \n",
      "\n",
      "Fold: 4  Epoch: 99  Training loss = 2.3280  Validation loss = 5.9448  \n",
      "\n",
      "Fold: 4  Epoch: 100  Training loss = 2.3277  Validation loss = 5.9446  \n",
      "\n",
      "Fold: 4  Epoch: 101  Training loss = 2.3274  Validation loss = 5.9442  \n",
      "\n",
      "Fold: 4  Epoch: 102  Training loss = 2.3271  Validation loss = 5.9438  \n",
      "\n",
      "Fold: 4  Epoch: 103  Training loss = 2.3269  Validation loss = 5.9436  \n",
      "\n",
      "Fold: 4  Epoch: 104  Training loss = 2.3266  Validation loss = 5.9432  \n",
      "\n",
      "Fold: 4  Epoch: 105  Training loss = 2.3264  Validation loss = 5.9429  \n",
      "\n",
      "Fold: 4  Epoch: 106  Training loss = 2.3261  Validation loss = 5.9425  \n",
      "\n",
      "Fold: 4  Epoch: 107  Training loss = 2.3258  Validation loss = 5.9422  \n",
      "\n",
      "Fold: 4  Epoch: 108  Training loss = 2.3256  Validation loss = 5.9419  \n",
      "\n",
      "Fold: 4  Epoch: 109  Training loss = 2.3253  Validation loss = 5.9415  \n",
      "\n",
      "Fold: 4  Epoch: 110  Training loss = 2.3251  Validation loss = 5.9412  \n",
      "\n",
      "Fold: 4  Epoch: 111  Training loss = 2.3248  Validation loss = 5.9409  \n",
      "\n",
      "Fold: 4  Epoch: 112  Training loss = 2.3246  Validation loss = 5.9406  \n",
      "\n",
      "Fold: 4  Epoch: 113  Training loss = 2.3243  Validation loss = 5.9403  \n",
      "\n",
      "Fold: 4  Epoch: 114  Training loss = 2.3241  Validation loss = 5.9399  \n",
      "\n",
      "Fold: 4  Epoch: 115  Training loss = 2.3238  Validation loss = 5.9396  \n",
      "\n",
      "Fold: 4  Epoch: 116  Training loss = 2.3236  Validation loss = 5.9393  \n",
      "\n",
      "Fold: 4  Epoch: 117  Training loss = 2.3233  Validation loss = 5.9390  \n",
      "\n",
      "Fold: 4  Epoch: 118  Training loss = 2.3231  Validation loss = 5.9387  \n",
      "\n",
      "Fold: 4  Epoch: 119  Training loss = 2.3229  Validation loss = 5.9384  \n",
      "\n",
      "Fold: 4  Epoch: 120  Training loss = 2.3227  Validation loss = 5.9382  \n",
      "\n",
      "Fold: 4  Epoch: 121  Training loss = 2.3224  Validation loss = 5.9379  \n",
      "\n",
      "Fold: 4  Epoch: 122  Training loss = 2.3221  Validation loss = 5.9375  \n",
      "\n",
      "Fold: 4  Epoch: 123  Training loss = 2.3219  Validation loss = 5.9372  \n",
      "\n",
      "Fold: 4  Epoch: 124  Training loss = 2.3217  Validation loss = 5.9370  \n",
      "\n",
      "Fold: 4  Epoch: 125  Training loss = 2.3214  Validation loss = 5.9366  \n",
      "\n",
      "Fold: 4  Epoch: 126  Training loss = 2.3212  Validation loss = 5.9364  \n",
      "\n",
      "Fold: 4  Epoch: 127  Training loss = 2.3210  Validation loss = 5.9361  \n",
      "\n",
      "Fold: 4  Epoch: 128  Training loss = 2.3207  Validation loss = 5.9357  \n",
      "\n",
      "Fold: 4  Epoch: 129  Training loss = 2.3205  Validation loss = 5.9354  \n",
      "\n",
      "Fold: 4  Epoch: 130  Training loss = 2.3202  Validation loss = 5.9351  \n",
      "\n",
      "Fold: 4  Epoch: 131  Training loss = 2.3200  Validation loss = 5.9348  \n",
      "\n",
      "Fold: 4  Epoch: 132  Training loss = 2.3198  Validation loss = 5.9345  \n",
      "\n",
      "Fold: 4  Epoch: 133  Training loss = 2.3195  Validation loss = 5.9342  \n",
      "\n",
      "Fold: 4  Epoch: 134  Training loss = 2.3193  Validation loss = 5.9339  \n",
      "\n",
      "Fold: 4  Epoch: 135  Training loss = 2.3190  Validation loss = 5.9335  \n",
      "\n",
      "Fold: 4  Epoch: 136  Training loss = 2.3187  Validation loss = 5.9332  \n",
      "\n",
      "Fold: 4  Epoch: 137  Training loss = 2.3185  Validation loss = 5.9329  \n",
      "\n",
      "Fold: 4  Epoch: 138  Training loss = 2.3183  Validation loss = 5.9326  \n",
      "\n",
      "Fold: 4  Epoch: 139  Training loss = 2.3180  Validation loss = 5.9323  \n",
      "\n",
      "Fold: 4  Epoch: 140  Training loss = 2.3177  Validation loss = 5.9319  \n",
      "\n",
      "Fold: 4  Epoch: 141  Training loss = 2.3174  Validation loss = 5.9316  \n",
      "\n",
      "Fold: 4  Epoch: 142  Training loss = 2.3172  Validation loss = 5.9313  \n",
      "\n",
      "Fold: 4  Epoch: 143  Training loss = 2.3170  Validation loss = 5.9310  \n",
      "\n",
      "Fold: 4  Epoch: 144  Training loss = 2.3168  Validation loss = 5.9307  \n",
      "\n",
      "Fold: 4  Epoch: 145  Training loss = 2.3166  Validation loss = 5.9305  \n",
      "\n",
      "Fold: 4  Epoch: 146  Training loss = 2.3163  Validation loss = 5.9302  \n",
      "\n",
      "Fold: 4  Epoch: 147  Training loss = 2.3161  Validation loss = 5.9299  \n",
      "\n",
      "Fold: 4  Epoch: 148  Training loss = 2.3159  Validation loss = 5.9296  \n",
      "\n",
      "Fold: 4  Epoch: 149  Training loss = 2.3156  Validation loss = 5.9293  \n",
      "\n",
      "Fold: 4  Epoch: 150  Training loss = 2.3153  Validation loss = 5.9289  \n",
      "\n",
      "Fold: 4  Epoch: 151  Training loss = 2.3150  Validation loss = 5.9286  \n",
      "\n",
      "Fold: 4  Epoch: 152  Training loss = 2.3148  Validation loss = 5.9282  \n",
      "\n",
      "Fold: 4  Epoch: 153  Training loss = 2.3145  Validation loss = 5.9279  \n",
      "\n",
      "Fold: 4  Epoch: 154  Training loss = 2.3143  Validation loss = 5.9276  \n",
      "\n",
      "Fold: 4  Epoch: 155  Training loss = 2.3140  Validation loss = 5.9273  \n",
      "\n",
      "Fold: 4  Epoch: 156  Training loss = 2.3138  Validation loss = 5.9270  \n",
      "\n",
      "Fold: 4  Epoch: 157  Training loss = 2.3135  Validation loss = 5.9266  \n",
      "\n",
      "Fold: 4  Epoch: 158  Training loss = 2.3133  Validation loss = 5.9263  \n",
      "\n",
      "Fold: 4  Epoch: 159  Training loss = 2.3130  Validation loss = 5.9259  \n",
      "\n",
      "Fold: 4  Epoch: 160  Training loss = 2.3127  Validation loss = 5.9256  \n",
      "\n",
      "Fold: 4  Epoch: 161  Training loss = 2.3125  Validation loss = 5.9253  \n",
      "\n",
      "Fold: 4  Epoch: 162  Training loss = 2.3123  Validation loss = 5.9251  \n",
      "\n",
      "Fold: 4  Epoch: 163  Training loss = 2.3121  Validation loss = 5.9248  \n",
      "\n",
      "Fold: 4  Epoch: 164  Training loss = 2.3118  Validation loss = 5.9245  \n",
      "\n",
      "Fold: 4  Epoch: 165  Training loss = 2.3115  Validation loss = 5.9241  \n",
      "\n",
      "Fold: 4  Epoch: 166  Training loss = 2.3113  Validation loss = 5.9238  \n",
      "\n",
      "Fold: 4  Epoch: 167  Training loss = 2.3111  Validation loss = 5.9235  \n",
      "\n",
      "Fold: 4  Epoch: 168  Training loss = 2.3109  Validation loss = 5.9232  \n",
      "\n",
      "Fold: 4  Epoch: 169  Training loss = 2.3106  Validation loss = 5.9229  \n",
      "\n",
      "Fold: 4  Epoch: 170  Training loss = 2.3104  Validation loss = 5.9227  \n",
      "\n",
      "Fold: 4  Epoch: 171  Training loss = 2.3102  Validation loss = 5.9224  \n",
      "\n",
      "Fold: 4  Epoch: 172  Training loss = 2.3100  Validation loss = 5.9221  \n",
      "\n",
      "Fold: 4  Epoch: 173  Training loss = 2.3097  Validation loss = 5.9218  \n",
      "\n",
      "Fold: 4  Epoch: 174  Training loss = 2.3095  Validation loss = 5.9215  \n",
      "\n",
      "Fold: 4  Epoch: 175  Training loss = 2.3093  Validation loss = 5.9213  \n",
      "\n",
      "Fold: 4  Epoch: 176  Training loss = 2.3091  Validation loss = 5.9210  \n",
      "\n",
      "Fold: 4  Epoch: 177  Training loss = 2.3088  Validation loss = 5.9207  \n",
      "\n",
      "Fold: 4  Epoch: 178  Training loss = 2.3086  Validation loss = 5.9204  \n",
      "\n",
      "Fold: 4  Epoch: 179  Training loss = 2.3083  Validation loss = 5.9200  \n",
      "\n",
      "Fold: 4  Epoch: 180  Training loss = 2.3081  Validation loss = 5.9197  \n",
      "\n",
      "Fold: 4  Epoch: 181  Training loss = 2.3078  Validation loss = 5.9194  \n",
      "\n",
      "Fold: 4  Epoch: 182  Training loss = 2.3076  Validation loss = 5.9191  \n",
      "\n",
      "Fold: 4  Epoch: 183  Training loss = 2.3072  Validation loss = 5.9187  \n",
      "\n",
      "Fold: 4  Epoch: 184  Training loss = 2.3070  Validation loss = 5.9183  \n",
      "\n",
      "Fold: 4  Epoch: 185  Training loss = 2.3067  Validation loss = 5.9180  \n",
      "\n",
      "Fold: 4  Epoch: 186  Training loss = 2.3065  Validation loss = 5.9178  \n",
      "\n",
      "Fold: 4  Epoch: 187  Training loss = 2.3063  Validation loss = 5.9175  \n",
      "\n",
      "Fold: 4  Epoch: 188  Training loss = 2.3060  Validation loss = 5.9172  \n",
      "\n",
      "Fold: 4  Epoch: 189  Training loss = 2.3058  Validation loss = 5.9168  \n",
      "\n",
      "Fold: 4  Epoch: 190  Training loss = 2.3056  Validation loss = 5.9166  \n",
      "\n",
      "Fold: 4  Epoch: 191  Training loss = 2.3053  Validation loss = 5.9163  \n",
      "\n",
      "Fold: 4  Epoch: 192  Training loss = 2.3051  Validation loss = 5.9159  \n",
      "\n",
      "Fold: 4  Epoch: 193  Training loss = 2.3048  Validation loss = 5.9156  \n",
      "\n",
      "Fold: 4  Epoch: 194  Training loss = 2.3046  Validation loss = 5.9154  \n",
      "\n",
      "Fold: 4  Epoch: 195  Training loss = 2.3044  Validation loss = 5.9151  \n",
      "\n",
      "Fold: 4  Epoch: 196  Training loss = 2.3040  Validation loss = 5.9147  \n",
      "\n",
      "Fold: 4  Epoch: 197  Training loss = 2.3038  Validation loss = 5.9144  \n",
      "\n",
      "Fold: 4  Epoch: 198  Training loss = 2.3036  Validation loss = 5.9141  \n",
      "\n",
      "Fold: 4  Epoch: 199  Training loss = 2.3033  Validation loss = 5.9138  \n",
      "\n",
      "Fold: 4  Epoch: 200  Training loss = 2.3031  Validation loss = 5.9135  \n",
      "\n",
      "Fold: 4  Epoch: 201  Training loss = 2.3029  Validation loss = 5.9132  \n",
      "\n",
      "Fold: 4  Epoch: 202  Training loss = 2.3027  Validation loss = 5.9129  \n",
      "\n",
      "Fold: 4  Epoch: 203  Training loss = 2.3024  Validation loss = 5.9127  \n",
      "\n",
      "Fold: 4  Epoch: 204  Training loss = 2.3022  Validation loss = 5.9124  \n",
      "\n",
      "Fold: 4  Epoch: 205  Training loss = 2.3020  Validation loss = 5.9121  \n",
      "\n",
      "Fold: 4  Epoch: 206  Training loss = 2.3018  Validation loss = 5.9118  \n",
      "\n",
      "Fold: 4  Epoch: 207  Training loss = 2.3015  Validation loss = 5.9115  \n",
      "\n",
      "Fold: 4  Epoch: 208  Training loss = 2.3013  Validation loss = 5.9112  \n",
      "\n",
      "Fold: 4  Epoch: 209  Training loss = 2.3010  Validation loss = 5.9108  \n",
      "\n",
      "Fold: 4  Epoch: 210  Training loss = 2.3008  Validation loss = 5.9105  \n",
      "\n",
      "Fold: 4  Epoch: 211  Training loss = 2.3005  Validation loss = 5.9102  \n",
      "\n",
      "Fold: 4  Epoch: 212  Training loss = 2.3002  Validation loss = 5.9098  \n",
      "\n",
      "Fold: 4  Epoch: 213  Training loss = 2.3000  Validation loss = 5.9095  \n",
      "\n",
      "Fold: 4  Epoch: 214  Training loss = 2.2998  Validation loss = 5.9092  \n",
      "\n",
      "Fold: 4  Epoch: 215  Training loss = 2.2995  Validation loss = 5.9089  \n",
      "\n",
      "Fold: 4  Epoch: 216  Training loss = 2.2993  Validation loss = 5.9086  \n",
      "\n",
      "Fold: 4  Epoch: 217  Training loss = 2.2991  Validation loss = 5.9083  \n",
      "\n",
      "Fold: 4  Epoch: 218  Training loss = 2.2988  Validation loss = 5.9080  \n",
      "\n",
      "Fold: 4  Epoch: 219  Training loss = 2.2986  Validation loss = 5.9077  \n",
      "\n",
      "Fold: 4  Epoch: 220  Training loss = 2.2983  Validation loss = 5.9074  \n",
      "\n",
      "Fold: 4  Epoch: 221  Training loss = 2.2981  Validation loss = 5.9071  \n",
      "\n",
      "Fold: 4  Epoch: 222  Training loss = 2.2978  Validation loss = 5.9068  \n",
      "\n",
      "Fold: 4  Epoch: 223  Training loss = 2.2976  Validation loss = 5.9066  \n",
      "\n",
      "Fold: 4  Epoch: 224  Training loss = 2.2974  Validation loss = 5.9063  \n",
      "\n",
      "Fold: 4  Epoch: 225  Training loss = 2.2972  Validation loss = 5.9060  \n",
      "\n",
      "Fold: 4  Epoch: 226  Training loss = 2.2970  Validation loss = 5.9057  \n",
      "\n",
      "Fold: 4  Epoch: 227  Training loss = 2.2967  Validation loss = 5.9054  \n",
      "\n",
      "Fold: 4  Epoch: 228  Training loss = 2.2965  Validation loss = 5.9052  \n",
      "\n",
      "Fold: 4  Epoch: 229  Training loss = 2.2963  Validation loss = 5.9049  \n",
      "\n",
      "Fold: 4  Epoch: 230  Training loss = 2.2961  Validation loss = 5.9046  \n",
      "\n",
      "Fold: 4  Epoch: 231  Training loss = 2.2959  Validation loss = 5.9044  \n",
      "\n",
      "Fold: 4  Epoch: 232  Training loss = 2.2956  Validation loss = 5.9040  \n",
      "\n",
      "Fold: 4  Epoch: 233  Training loss = 2.2953  Validation loss = 5.9037  \n",
      "\n",
      "Fold: 4  Epoch: 234  Training loss = 2.2951  Validation loss = 5.9034  \n",
      "\n",
      "Fold: 4  Epoch: 235  Training loss = 2.2948  Validation loss = 5.9030  \n",
      "\n",
      "Fold: 4  Epoch: 236  Training loss = 2.2946  Validation loss = 5.9027  \n",
      "\n",
      "Fold: 4  Epoch: 237  Training loss = 2.2944  Validation loss = 5.9025  \n",
      "\n",
      "Fold: 4  Epoch: 238  Training loss = 2.2942  Validation loss = 5.9021  \n",
      "\n",
      "Fold: 4  Epoch: 239  Training loss = 2.2939  Validation loss = 5.9019  \n",
      "\n",
      "Fold: 4  Epoch: 240  Training loss = 2.2937  Validation loss = 5.9016  \n",
      "\n",
      "Fold: 4  Epoch: 241  Training loss = 2.2935  Validation loss = 5.9013  \n",
      "\n",
      "Fold: 4  Epoch: 242  Training loss = 2.2932  Validation loss = 5.9010  \n",
      "\n",
      "Fold: 4  Epoch: 243  Training loss = 2.2930  Validation loss = 5.9007  \n",
      "\n",
      "Fold: 4  Epoch: 244  Training loss = 2.2928  Validation loss = 5.9004  \n",
      "\n",
      "Fold: 4  Epoch: 245  Training loss = 2.2925  Validation loss = 5.9000  \n",
      "\n",
      "Fold: 4  Epoch: 246  Training loss = 2.2923  Validation loss = 5.8998  \n",
      "\n",
      "Fold: 4  Epoch: 247  Training loss = 2.2921  Validation loss = 5.8995  \n",
      "\n",
      "Fold: 4  Epoch: 248  Training loss = 2.2919  Validation loss = 5.8993  \n",
      "\n",
      "Fold: 4  Epoch: 249  Training loss = 2.2916  Validation loss = 5.8989  \n",
      "\n",
      "Fold: 4  Epoch: 250  Training loss = 2.2914  Validation loss = 5.8987  \n",
      "\n",
      "Fold: 4  Epoch: 251  Training loss = 2.2912  Validation loss = 5.8984  \n",
      "\n",
      "Fold: 4  Epoch: 252  Training loss = 2.2910  Validation loss = 5.8981  \n",
      "\n",
      "Fold: 4  Epoch: 253  Training loss = 2.2908  Validation loss = 5.8978  \n",
      "\n",
      "Fold: 4  Epoch: 254  Training loss = 2.2905  Validation loss = 5.8975  \n",
      "\n",
      "Fold: 4  Epoch: 255  Training loss = 2.2902  Validation loss = 5.8972  \n",
      "\n",
      "Fold: 4  Epoch: 256  Training loss = 2.2900  Validation loss = 5.8969  \n",
      "\n",
      "Fold: 4  Epoch: 257  Training loss = 2.2898  Validation loss = 5.8967  \n",
      "\n",
      "Fold: 4  Epoch: 258  Training loss = 2.2896  Validation loss = 5.8964  \n",
      "\n",
      "Fold: 4  Epoch: 259  Training loss = 2.2894  Validation loss = 5.8961  \n",
      "\n",
      "Fold: 4  Epoch: 260  Training loss = 2.2891  Validation loss = 5.8958  \n",
      "\n",
      "Fold: 4  Epoch: 261  Training loss = 2.2889  Validation loss = 5.8955  \n",
      "\n",
      "Fold: 4  Epoch: 262  Training loss = 2.2887  Validation loss = 5.8952  \n",
      "\n",
      "Fold: 4  Epoch: 263  Training loss = 2.2885  Validation loss = 5.8950  \n",
      "\n",
      "Fold: 4  Epoch: 264  Training loss = 2.2883  Validation loss = 5.8947  \n",
      "\n",
      "Fold: 4  Epoch: 265  Training loss = 2.2880  Validation loss = 5.8944  \n",
      "\n",
      "Fold: 4  Epoch: 266  Training loss = 2.2878  Validation loss = 5.8941  \n",
      "\n",
      "Fold: 4  Epoch: 267  Training loss = 2.2876  Validation loss = 5.8938  \n",
      "\n",
      "Fold: 4  Epoch: 268  Training loss = 2.2873  Validation loss = 5.8935  \n",
      "\n",
      "Fold: 4  Epoch: 269  Training loss = 2.2871  Validation loss = 5.8932  \n",
      "\n",
      "Fold: 4  Epoch: 270  Training loss = 2.2869  Validation loss = 5.8929  \n",
      "\n",
      "Fold: 4  Epoch: 271  Training loss = 2.2866  Validation loss = 5.8927  \n",
      "\n",
      "Fold: 4  Epoch: 272  Training loss = 2.2864  Validation loss = 5.8924  \n",
      "\n",
      "Fold: 4  Epoch: 273  Training loss = 2.2862  Validation loss = 5.8921  \n",
      "\n",
      "Fold: 4  Epoch: 274  Training loss = 2.2859  Validation loss = 5.8918  \n",
      "\n",
      "Fold: 4  Epoch: 275  Training loss = 2.2857  Validation loss = 5.8915  \n",
      "\n",
      "Fold: 4  Epoch: 276  Training loss = 2.2855  Validation loss = 5.8912  \n",
      "\n",
      "Fold: 4  Epoch: 277  Training loss = 2.2853  Validation loss = 5.8910  \n",
      "\n",
      "Fold: 4  Epoch: 278  Training loss = 2.2851  Validation loss = 5.8907  \n",
      "\n",
      "Fold: 4  Epoch: 279  Training loss = 2.2849  Validation loss = 5.8904  \n",
      "\n",
      "Fold: 4  Epoch: 280  Training loss = 2.2846  Validation loss = 5.8901  \n",
      "\n",
      "Fold: 4  Epoch: 281  Training loss = 2.2844  Validation loss = 5.8899  \n",
      "\n",
      "Fold: 4  Epoch: 282  Training loss = 2.2842  Validation loss = 5.8896  \n",
      "\n",
      "Fold: 4  Epoch: 283  Training loss = 2.2840  Validation loss = 5.8893  \n",
      "\n",
      "Fold: 4  Epoch: 284  Training loss = 2.2837  Validation loss = 5.8890  \n",
      "\n",
      "Fold: 4  Epoch: 285  Training loss = 2.2835  Validation loss = 5.8886  \n",
      "\n",
      "Fold: 4  Epoch: 286  Training loss = 2.2833  Validation loss = 5.8884  \n",
      "\n",
      "Fold: 4  Epoch: 287  Training loss = 2.2831  Validation loss = 5.8881  \n",
      "\n",
      "Fold: 4  Epoch: 288  Training loss = 2.2828  Validation loss = 5.8878  \n",
      "\n",
      "Fold: 4  Epoch: 289  Training loss = 2.2825  Validation loss = 5.8874  \n",
      "\n",
      "Fold: 4  Epoch: 290  Training loss = 2.2823  Validation loss = 5.8871  \n",
      "\n",
      "Fold: 4  Epoch: 291  Training loss = 2.2820  Validation loss = 5.8868  \n",
      "\n",
      "Fold: 4  Epoch: 292  Training loss = 2.2818  Validation loss = 5.8865  \n",
      "\n",
      "Fold: 4  Epoch: 293  Training loss = 2.2815  Validation loss = 5.8861  \n",
      "\n",
      "Fold: 4  Epoch: 294  Training loss = 2.2813  Validation loss = 5.8858  \n",
      "\n",
      "Fold: 4  Epoch: 295  Training loss = 2.2810  Validation loss = 5.8855  \n",
      "\n",
      "Fold: 4  Epoch: 296  Training loss = 2.2808  Validation loss = 5.8852  \n",
      "\n",
      "Fold: 4  Epoch: 297  Training loss = 2.2806  Validation loss = 5.8850  \n",
      "\n",
      "Fold: 4  Epoch: 298  Training loss = 2.2803  Validation loss = 5.8846  \n",
      "\n",
      "Fold: 4  Epoch: 299  Training loss = 2.2801  Validation loss = 5.8843  \n",
      "\n",
      "Fold: 4  Epoch: 300  Training loss = 2.2799  Validation loss = 5.8840  \n",
      "\n",
      "Fold: 4  Epoch: 301  Training loss = 2.2796  Validation loss = 5.8836  \n",
      "\n",
      "Fold: 4  Epoch: 302  Training loss = 2.2793  Validation loss = 5.8833  \n",
      "\n",
      "Fold: 4  Epoch: 303  Training loss = 2.2791  Validation loss = 5.8830  \n",
      "\n",
      "Fold: 4  Epoch: 304  Training loss = 2.2789  Validation loss = 5.8827  \n",
      "\n",
      "Fold: 4  Epoch: 305  Training loss = 2.2787  Validation loss = 5.8825  \n",
      "\n",
      "Fold: 4  Epoch: 306  Training loss = 2.2785  Validation loss = 5.8822  \n",
      "\n",
      "Fold: 4  Epoch: 307  Training loss = 2.2782  Validation loss = 5.8819  \n",
      "\n",
      "Fold: 4  Epoch: 308  Training loss = 2.2780  Validation loss = 5.8816  \n",
      "\n",
      "Fold: 4  Epoch: 309  Training loss = 2.2778  Validation loss = 5.8813  \n",
      "\n",
      "Fold: 4  Epoch: 310  Training loss = 2.2776  Validation loss = 5.8811  \n",
      "\n",
      "Fold: 4  Epoch: 311  Training loss = 2.2773  Validation loss = 5.8808  \n",
      "\n",
      "Fold: 4  Epoch: 312  Training loss = 2.2771  Validation loss = 5.8805  \n",
      "\n",
      "Fold: 4  Epoch: 313  Training loss = 2.2768  Validation loss = 5.8801  \n",
      "\n",
      "Fold: 4  Epoch: 314  Training loss = 2.2766  Validation loss = 5.8799  \n",
      "\n",
      "Fold: 4  Epoch: 315  Training loss = 2.2764  Validation loss = 5.8796  \n",
      "\n",
      "Fold: 4  Epoch: 316  Training loss = 2.2762  Validation loss = 5.8793  \n",
      "\n",
      "Fold: 4  Epoch: 317  Training loss = 2.2759  Validation loss = 5.8789  \n",
      "\n",
      "Fold: 4  Epoch: 318  Training loss = 2.2757  Validation loss = 5.8787  \n",
      "\n",
      "Fold: 4  Epoch: 319  Training loss = 2.2755  Validation loss = 5.8785  \n",
      "\n",
      "Fold: 4  Epoch: 320  Training loss = 2.2753  Validation loss = 5.8782  \n",
      "\n",
      "Fold: 4  Epoch: 321  Training loss = 2.2751  Validation loss = 5.8779  \n",
      "\n",
      "Fold: 4  Epoch: 322  Training loss = 2.2749  Validation loss = 5.8776  \n",
      "\n",
      "Fold: 4  Epoch: 323  Training loss = 2.2746  Validation loss = 5.8774  \n",
      "\n",
      "Fold: 4  Epoch: 324  Training loss = 2.2744  Validation loss = 5.8771  \n",
      "\n",
      "Fold: 4  Epoch: 325  Training loss = 2.2742  Validation loss = 5.8768  \n",
      "\n",
      "Fold: 4  Epoch: 326  Training loss = 2.2740  Validation loss = 5.8765  \n",
      "\n",
      "Fold: 4  Epoch: 327  Training loss = 2.2737  Validation loss = 5.8763  \n",
      "\n",
      "Fold: 4  Epoch: 328  Training loss = 2.2735  Validation loss = 5.8760  \n",
      "\n",
      "Fold: 4  Epoch: 329  Training loss = 2.2733  Validation loss = 5.8756  \n",
      "\n",
      "Fold: 4  Epoch: 330  Training loss = 2.2731  Validation loss = 5.8754  \n",
      "\n",
      "Fold: 4  Epoch: 331  Training loss = 2.2729  Validation loss = 5.8752  \n",
      "\n",
      "Fold: 4  Epoch: 332  Training loss = 2.2727  Validation loss = 5.8749  \n",
      "\n",
      "Fold: 4  Epoch: 333  Training loss = 2.2725  Validation loss = 5.8746  \n",
      "\n",
      "Fold: 4  Epoch: 334  Training loss = 2.2723  Validation loss = 5.8744  \n",
      "\n",
      "Fold: 4  Epoch: 335  Training loss = 2.2721  Validation loss = 5.8741  \n",
      "\n",
      "Fold: 4  Epoch: 336  Training loss = 2.2718  Validation loss = 5.8738  \n",
      "\n",
      "Fold: 4  Epoch: 337  Training loss = 2.2716  Validation loss = 5.8735  \n",
      "\n",
      "Fold: 4  Epoch: 338  Training loss = 2.2714  Validation loss = 5.8733  \n",
      "\n",
      "Fold: 4  Epoch: 339  Training loss = 2.2712  Validation loss = 5.8730  \n",
      "\n",
      "Fold: 4  Epoch: 340  Training loss = 2.2709  Validation loss = 5.8727  \n",
      "\n",
      "Fold: 4  Epoch: 341  Training loss = 2.2707  Validation loss = 5.8724  \n",
      "\n",
      "Fold: 4  Epoch: 342  Training loss = 2.2705  Validation loss = 5.8721  \n",
      "\n",
      "Fold: 4  Epoch: 343  Training loss = 2.2703  Validation loss = 5.8718  \n",
      "\n",
      "Fold: 4  Epoch: 344  Training loss = 2.2701  Validation loss = 5.8715  \n",
      "\n",
      "Fold: 4  Epoch: 345  Training loss = 2.2698  Validation loss = 5.8712  \n",
      "\n",
      "Fold: 4  Epoch: 346  Training loss = 2.2696  Validation loss = 5.8710  \n",
      "\n",
      "Fold: 4  Epoch: 347  Training loss = 2.2694  Validation loss = 5.8707  \n",
      "\n",
      "Fold: 4  Epoch: 348  Training loss = 2.2692  Validation loss = 5.8704  \n",
      "\n",
      "Fold: 4  Epoch: 349  Training loss = 2.2690  Validation loss = 5.8701  \n",
      "\n",
      "Fold: 4  Epoch: 350  Training loss = 2.2687  Validation loss = 5.8698  \n",
      "\n",
      "Fold: 4  Epoch: 351  Training loss = 2.2685  Validation loss = 5.8696  \n",
      "\n",
      "Fold: 4  Epoch: 352  Training loss = 2.2683  Validation loss = 5.8693  \n",
      "\n",
      "Fold: 4  Epoch: 353  Training loss = 2.2681  Validation loss = 5.8690  \n",
      "\n",
      "Fold: 4  Epoch: 354  Training loss = 2.2679  Validation loss = 5.8688  \n",
      "\n",
      "Fold: 4  Epoch: 355  Training loss = 2.2676  Validation loss = 5.8684  \n",
      "\n",
      "Fold: 4  Epoch: 356  Training loss = 2.2674  Validation loss = 5.8681  \n",
      "\n",
      "Fold: 4  Epoch: 357  Training loss = 2.2672  Validation loss = 5.8678  \n",
      "\n",
      "Fold: 4  Epoch: 358  Training loss = 2.2669  Validation loss = 5.8674  \n",
      "\n",
      "Fold: 4  Epoch: 359  Training loss = 2.2666  Validation loss = 5.8672  \n",
      "\n",
      "Fold: 4  Epoch: 360  Training loss = 2.2664  Validation loss = 5.8668  \n",
      "\n",
      "Fold: 4  Epoch: 361  Training loss = 2.2662  Validation loss = 5.8665  \n",
      "\n",
      "Fold: 4  Epoch: 362  Training loss = 2.2659  Validation loss = 5.8663  \n",
      "\n",
      "Fold: 4  Epoch: 363  Training loss = 2.2657  Validation loss = 5.8660  \n",
      "\n",
      "Fold: 4  Epoch: 364  Training loss = 2.2655  Validation loss = 5.8657  \n",
      "\n",
      "Fold: 4  Epoch: 365  Training loss = 2.2653  Validation loss = 5.8655  \n",
      "\n",
      "Fold: 4  Epoch: 366  Training loss = 2.2651  Validation loss = 5.8652  \n",
      "\n",
      "Fold: 4  Epoch: 367  Training loss = 2.2649  Validation loss = 5.8649  \n",
      "\n",
      "Fold: 4  Epoch: 368  Training loss = 2.2647  Validation loss = 5.8647  \n",
      "\n",
      "Fold: 4  Epoch: 369  Training loss = 2.2645  Validation loss = 5.8644  \n",
      "\n",
      "Fold: 4  Epoch: 370  Training loss = 2.2643  Validation loss = 5.8641  \n",
      "\n",
      "Fold: 4  Epoch: 371  Training loss = 2.2641  Validation loss = 5.8638  \n",
      "\n",
      "Fold: 4  Epoch: 372  Training loss = 2.2638  Validation loss = 5.8636  \n",
      "\n",
      "Fold: 4  Epoch: 373  Training loss = 2.2636  Validation loss = 5.8633  \n",
      "\n",
      "Fold: 4  Epoch: 374  Training loss = 2.2635  Validation loss = 5.8631  \n",
      "\n",
      "Fold: 4  Epoch: 375  Training loss = 2.2632  Validation loss = 5.8628  \n",
      "\n",
      "Fold: 4  Epoch: 376  Training loss = 2.2630  Validation loss = 5.8625  \n",
      "\n",
      "Fold: 4  Epoch: 377  Training loss = 2.2628  Validation loss = 5.8622  \n",
      "\n",
      "Fold: 4  Epoch: 378  Training loss = 2.2626  Validation loss = 5.8619  \n",
      "\n",
      "Fold: 4  Epoch: 379  Training loss = 2.2624  Validation loss = 5.8617  \n",
      "\n",
      "Fold: 4  Epoch: 380  Training loss = 2.2622  Validation loss = 5.8615  \n",
      "\n",
      "Fold: 4  Epoch: 381  Training loss = 2.2619  Validation loss = 5.8612  \n",
      "\n",
      "Fold: 4  Epoch: 382  Training loss = 2.2617  Validation loss = 5.8608  \n",
      "\n",
      "Fold: 4  Epoch: 383  Training loss = 2.2614  Validation loss = 5.8605  \n",
      "\n",
      "Fold: 4  Epoch: 384  Training loss = 2.2612  Validation loss = 5.8603  \n",
      "\n",
      "Fold: 4  Epoch: 385  Training loss = 2.2610  Validation loss = 5.8600  \n",
      "\n",
      "Fold: 4  Epoch: 386  Training loss = 2.2608  Validation loss = 5.8597  \n",
      "\n",
      "Fold: 4  Epoch: 387  Training loss = 2.2606  Validation loss = 5.8594  \n",
      "\n",
      "Fold: 4  Epoch: 388  Training loss = 2.2603  Validation loss = 5.8592  \n",
      "\n",
      "Fold: 4  Epoch: 389  Training loss = 2.2601  Validation loss = 5.8588  \n",
      "\n",
      "Fold: 4  Epoch: 390  Training loss = 2.2598  Validation loss = 5.8585  \n",
      "\n",
      "Fold: 4  Epoch: 391  Training loss = 2.2596  Validation loss = 5.8582  \n",
      "\n",
      "Fold: 4  Epoch: 392  Training loss = 2.2593  Validation loss = 5.8579  \n",
      "\n",
      "Fold: 4  Epoch: 393  Training loss = 2.2592  Validation loss = 5.8577  \n",
      "\n",
      "Fold: 4  Epoch: 394  Training loss = 2.2590  Validation loss = 5.8574  \n",
      "\n",
      "Fold: 4  Epoch: 395  Training loss = 2.2588  Validation loss = 5.8572  \n",
      "\n",
      "Fold: 4  Epoch: 396  Training loss = 2.2585  Validation loss = 5.8569  \n",
      "\n",
      "Fold: 4  Epoch: 397  Training loss = 2.2583  Validation loss = 5.8565  \n",
      "\n",
      "Fold: 4  Epoch: 398  Training loss = 2.2580  Validation loss = 5.8562  \n",
      "\n",
      "Fold: 4  Epoch: 399  Training loss = 2.2578  Validation loss = 5.8559  \n",
      "\n",
      "Fold: 4  Epoch: 400  Training loss = 2.2576  Validation loss = 5.8556  \n",
      "\n",
      "Fold: 4  Epoch: 401  Training loss = 2.2574  Validation loss = 5.8553  \n",
      "\n",
      "Fold: 4  Epoch: 402  Training loss = 2.2571  Validation loss = 5.8550  \n",
      "\n",
      "Fold: 4  Epoch: 403  Training loss = 2.2569  Validation loss = 5.8547  \n",
      "\n",
      "Fold: 4  Epoch: 404  Training loss = 2.2567  Validation loss = 5.8544  \n",
      "\n",
      "Fold: 4  Epoch: 405  Training loss = 2.2564  Validation loss = 5.8542  \n",
      "\n",
      "Fold: 4  Epoch: 406  Training loss = 2.2562  Validation loss = 5.8538  \n",
      "\n",
      "Fold: 4  Epoch: 407  Training loss = 2.2560  Validation loss = 5.8536  \n",
      "\n",
      "Fold: 4  Epoch: 408  Training loss = 2.2558  Validation loss = 5.8533  \n",
      "\n",
      "Fold: 4  Epoch: 409  Training loss = 2.2556  Validation loss = 5.8530  \n",
      "\n",
      "Fold: 4  Epoch: 410  Training loss = 2.2553  Validation loss = 5.8528  \n",
      "\n",
      "Fold: 4  Epoch: 411  Training loss = 2.2551  Validation loss = 5.8525  \n",
      "\n",
      "Fold: 4  Epoch: 412  Training loss = 2.2550  Validation loss = 5.8523  \n",
      "\n",
      "Fold: 4  Epoch: 413  Training loss = 2.2547  Validation loss = 5.8519  \n",
      "\n",
      "Fold: 4  Epoch: 414  Training loss = 2.2545  Validation loss = 5.8517  \n",
      "\n",
      "Fold: 4  Epoch: 415  Training loss = 2.2543  Validation loss = 5.8514  \n",
      "\n",
      "Fold: 4  Epoch: 416  Training loss = 2.2541  Validation loss = 5.8512  \n",
      "\n",
      "Fold: 4  Epoch: 417  Training loss = 2.2538  Validation loss = 5.8508  \n",
      "\n",
      "Fold: 4  Epoch: 418  Training loss = 2.2536  Validation loss = 5.8505  \n",
      "\n",
      "Fold: 4  Epoch: 419  Training loss = 2.2534  Validation loss = 5.8502  \n",
      "\n",
      "Fold: 4  Epoch: 420  Training loss = 2.2531  Validation loss = 5.8499  \n",
      "\n",
      "Fold: 4  Epoch: 421  Training loss = 2.2530  Validation loss = 5.8497  \n",
      "\n",
      "Fold: 4  Epoch: 422  Training loss = 2.2528  Validation loss = 5.8494  \n",
      "\n",
      "Fold: 4  Epoch: 423  Training loss = 2.2525  Validation loss = 5.8491  \n",
      "\n",
      "Fold: 4  Epoch: 424  Training loss = 2.2523  Validation loss = 5.8489  \n",
      "\n",
      "Fold: 4  Epoch: 425  Training loss = 2.2521  Validation loss = 5.8486  \n",
      "\n",
      "Fold: 4  Epoch: 426  Training loss = 2.2518  Validation loss = 5.8482  \n",
      "\n",
      "Fold: 4  Epoch: 427  Training loss = 2.2516  Validation loss = 5.8480  \n",
      "\n",
      "Fold: 4  Epoch: 428  Training loss = 2.2514  Validation loss = 5.8477  \n",
      "\n",
      "Fold: 4  Epoch: 429  Training loss = 2.2512  Validation loss = 5.8475  \n",
      "\n",
      "Fold: 4  Epoch: 430  Training loss = 2.2510  Validation loss = 5.8472  \n",
      "\n",
      "Fold: 4  Epoch: 431  Training loss = 2.2508  Validation loss = 5.8469  \n",
      "\n",
      "Fold: 4  Epoch: 432  Training loss = 2.2506  Validation loss = 5.8466  \n",
      "\n",
      "Fold: 4  Epoch: 433  Training loss = 2.2503  Validation loss = 5.8463  \n",
      "\n",
      "Fold: 4  Epoch: 434  Training loss = 2.2502  Validation loss = 5.8461  \n",
      "\n",
      "Fold: 4  Epoch: 435  Training loss = 2.2499  Validation loss = 5.8458  \n",
      "\n",
      "Fold: 4  Epoch: 436  Training loss = 2.2497  Validation loss = 5.8455  \n",
      "\n",
      "Fold: 4  Epoch: 437  Training loss = 2.2496  Validation loss = 5.8453  \n",
      "\n",
      "Fold: 4  Epoch: 438  Training loss = 2.2493  Validation loss = 5.8450  \n",
      "\n",
      "Fold: 4  Epoch: 439  Training loss = 2.2492  Validation loss = 5.8448  \n",
      "\n",
      "Fold: 4  Epoch: 440  Training loss = 2.2490  Validation loss = 5.8445  \n",
      "\n",
      "Fold: 4  Epoch: 441  Training loss = 2.2487  Validation loss = 5.8441  \n",
      "\n",
      "Fold: 4  Epoch: 442  Training loss = 2.2485  Validation loss = 5.8439  \n",
      "\n",
      "Fold: 4  Epoch: 443  Training loss = 2.2483  Validation loss = 5.8436  \n",
      "\n",
      "Fold: 4  Epoch: 444  Training loss = 2.2480  Validation loss = 5.8433  \n",
      "\n",
      "Fold: 4  Epoch: 445  Training loss = 2.2478  Validation loss = 5.8430  \n",
      "\n",
      "Fold: 4  Epoch: 446  Training loss = 2.2476  Validation loss = 5.8427  \n",
      "\n",
      "Fold: 4  Epoch: 447  Training loss = 2.2474  Validation loss = 5.8424  \n",
      "\n",
      "Fold: 4  Epoch: 448  Training loss = 2.2472  Validation loss = 5.8422  \n",
      "\n",
      "Fold: 4  Epoch: 449  Training loss = 2.2470  Validation loss = 5.8419  \n",
      "\n",
      "Fold: 4  Epoch: 450  Training loss = 2.2468  Validation loss = 5.8417  \n",
      "\n",
      "Fold: 4  Epoch: 451  Training loss = 2.2466  Validation loss = 5.8414  \n",
      "\n",
      "Fold: 4  Epoch: 452  Training loss = 2.2464  Validation loss = 5.8411  \n",
      "\n",
      "Fold: 4  Epoch: 453  Training loss = 2.2461  Validation loss = 5.8408  \n",
      "\n",
      "Fold: 4  Epoch: 454  Training loss = 2.2459  Validation loss = 5.8405  \n",
      "\n",
      "Fold: 4  Epoch: 455  Training loss = 2.2457  Validation loss = 5.8403  \n",
      "\n",
      "Fold: 4  Epoch: 456  Training loss = 2.2455  Validation loss = 5.8400  \n",
      "\n",
      "Fold: 4  Epoch: 457  Training loss = 2.2453  Validation loss = 5.8397  \n",
      "\n",
      "Fold: 4  Epoch: 458  Training loss = 2.2451  Validation loss = 5.8394  \n",
      "\n",
      "Fold: 4  Epoch: 459  Training loss = 2.2449  Validation loss = 5.8392  \n",
      "\n",
      "Fold: 4  Epoch: 460  Training loss = 2.2446  Validation loss = 5.8389  \n",
      "\n",
      "Fold: 4  Epoch: 461  Training loss = 2.2444  Validation loss = 5.8386  \n",
      "\n",
      "Fold: 4  Epoch: 462  Training loss = 2.2442  Validation loss = 5.8384  \n",
      "\n",
      "Fold: 4  Epoch: 463  Training loss = 2.2440  Validation loss = 5.8381  \n",
      "\n",
      "Fold: 4  Epoch: 464  Training loss = 2.2438  Validation loss = 5.8378  \n",
      "\n",
      "Fold: 4  Epoch: 465  Training loss = 2.2436  Validation loss = 5.8376  \n",
      "\n",
      "Fold: 4  Epoch: 466  Training loss = 2.2434  Validation loss = 5.8373  \n",
      "\n",
      "Fold: 4  Epoch: 467  Training loss = 2.2432  Validation loss = 5.8370  \n",
      "\n",
      "Fold: 4  Epoch: 468  Training loss = 2.2429  Validation loss = 5.8367  \n",
      "\n",
      "Fold: 4  Epoch: 469  Training loss = 2.2428  Validation loss = 5.8365  \n",
      "\n",
      "Fold: 4  Epoch: 470  Training loss = 2.2426  Validation loss = 5.8362  \n",
      "\n",
      "Fold: 4  Epoch: 471  Training loss = 2.2424  Validation loss = 5.8360  \n",
      "\n",
      "Fold: 4  Epoch: 472  Training loss = 2.2422  Validation loss = 5.8358  \n",
      "\n",
      "Fold: 4  Epoch: 473  Training loss = 2.2419  Validation loss = 5.8354  \n",
      "\n",
      "Fold: 4  Epoch: 474  Training loss = 2.2417  Validation loss = 5.8352  \n",
      "\n",
      "Fold: 4  Epoch: 475  Training loss = 2.2415  Validation loss = 5.8349  \n",
      "\n",
      "Fold: 4  Epoch: 476  Training loss = 2.2413  Validation loss = 5.8347  \n",
      "\n",
      "Fold: 4  Epoch: 477  Training loss = 2.2411  Validation loss = 5.8344  \n",
      "\n",
      "Fold: 4  Epoch: 478  Training loss = 2.2409  Validation loss = 5.8342  \n",
      "\n",
      "Fold: 4  Epoch: 479  Training loss = 2.2407  Validation loss = 5.8339  \n",
      "\n",
      "Fold: 4  Epoch: 480  Training loss = 2.2405  Validation loss = 5.8336  \n",
      "\n",
      "Fold: 4  Epoch: 481  Training loss = 2.2403  Validation loss = 5.8333  \n",
      "\n",
      "Fold: 4  Epoch: 482  Training loss = 2.2401  Validation loss = 5.8331  \n",
      "\n",
      "Fold: 4  Epoch: 483  Training loss = 2.2399  Validation loss = 5.8328  \n",
      "\n",
      "Fold: 4  Epoch: 484  Training loss = 2.2396  Validation loss = 5.8325  \n",
      "\n",
      "Fold: 4  Epoch: 485  Training loss = 2.2394  Validation loss = 5.8323  \n",
      "\n",
      "Fold: 4  Epoch: 486  Training loss = 2.2392  Validation loss = 5.8320  \n",
      "\n",
      "Fold: 4  Epoch: 487  Training loss = 2.2390  Validation loss = 5.8317  \n",
      "\n",
      "Fold: 4  Epoch: 488  Training loss = 2.2388  Validation loss = 5.8314  \n",
      "\n",
      "Fold: 4  Epoch: 489  Training loss = 2.2386  Validation loss = 5.8311  \n",
      "\n",
      "Fold: 4  Epoch: 490  Training loss = 2.2384  Validation loss = 5.8309  \n",
      "\n",
      "Fold: 4  Epoch: 491  Training loss = 2.2382  Validation loss = 5.8306  \n",
      "\n",
      "Fold: 4  Epoch: 492  Training loss = 2.2379  Validation loss = 5.8303  \n",
      "\n",
      "Fold: 4  Epoch: 493  Training loss = 2.2377  Validation loss = 5.8300  \n",
      "\n",
      "Fold: 4  Epoch: 494  Training loss = 2.2375  Validation loss = 5.8298  \n",
      "\n",
      "Fold: 4  Epoch: 495  Training loss = 2.2373  Validation loss = 5.8295  \n",
      "\n",
      "Fold: 4  Epoch: 496  Training loss = 2.2371  Validation loss = 5.8293  \n",
      "\n",
      "Fold: 4  Epoch: 497  Training loss = 2.2370  Validation loss = 5.8291  \n",
      "\n",
      "Fold: 4  Epoch: 498  Training loss = 2.2368  Validation loss = 5.8289  \n",
      "\n",
      "Fold: 4  Epoch: 499  Training loss = 2.2366  Validation loss = 5.8286  \n",
      "\n",
      "Fold: 4  Epoch: 500  Training loss = 2.2364  Validation loss = 5.8283  \n",
      "\n",
      "Check model:  Fold: 4  Optimal epoch: 500  \n",
      "\n",
      "Fold: 5  Epoch: 1  Training loss = 2.6350  Validation loss = 5.7222  \n",
      "\n",
      "Fold: 5  Epoch: 2  Training loss = 2.6347  Validation loss = 5.7219  \n",
      "\n",
      "Fold: 5  Epoch: 3  Training loss = 2.6345  Validation loss = 5.7215  \n",
      "\n",
      "Fold: 5  Epoch: 4  Training loss = 2.6342  Validation loss = 5.7212  \n",
      "\n",
      "Fold: 5  Epoch: 5  Training loss = 2.6340  Validation loss = 5.7209  \n",
      "\n",
      "Fold: 5  Epoch: 6  Training loss = 2.6337  Validation loss = 5.7206  \n",
      "\n",
      "Fold: 5  Epoch: 7  Training loss = 2.6335  Validation loss = 5.7204  \n",
      "\n",
      "Fold: 5  Epoch: 8  Training loss = 2.6333  Validation loss = 5.7201  \n",
      "\n",
      "Fold: 5  Epoch: 9  Training loss = 2.6330  Validation loss = 5.7197  \n",
      "\n",
      "Fold: 5  Epoch: 10  Training loss = 2.6327  Validation loss = 5.7194  \n",
      "\n",
      "Fold: 5  Epoch: 11  Training loss = 2.6324  Validation loss = 5.7190  \n",
      "\n",
      "Fold: 5  Epoch: 12  Training loss = 2.6322  Validation loss = 5.7188  \n",
      "\n",
      "Fold: 5  Epoch: 13  Training loss = 2.6320  Validation loss = 5.7185  \n",
      "\n",
      "Fold: 5  Epoch: 14  Training loss = 2.6317  Validation loss = 5.7181  \n",
      "\n",
      "Fold: 5  Epoch: 15  Training loss = 2.6315  Validation loss = 5.7179  \n",
      "\n",
      "Fold: 5  Epoch: 16  Training loss = 2.6312  Validation loss = 5.7175  \n",
      "\n",
      "Fold: 5  Epoch: 17  Training loss = 2.6310  Validation loss = 5.7172  \n",
      "\n",
      "Fold: 5  Epoch: 18  Training loss = 2.6307  Validation loss = 5.7169  \n",
      "\n",
      "Fold: 5  Epoch: 19  Training loss = 2.6305  Validation loss = 5.7166  \n",
      "\n",
      "Fold: 5  Epoch: 20  Training loss = 2.6302  Validation loss = 5.7162  \n",
      "\n",
      "Fold: 5  Epoch: 21  Training loss = 2.6299  Validation loss = 5.7159  \n",
      "\n",
      "Fold: 5  Epoch: 22  Training loss = 2.6296  Validation loss = 5.7155  \n",
      "\n",
      "Fold: 5  Epoch: 23  Training loss = 2.6294  Validation loss = 5.7152  \n",
      "\n",
      "Fold: 5  Epoch: 24  Training loss = 2.6291  Validation loss = 5.7149  \n",
      "\n",
      "Fold: 5  Epoch: 25  Training loss = 2.6289  Validation loss = 5.7146  \n",
      "\n",
      "Fold: 5  Epoch: 26  Training loss = 2.6287  Validation loss = 5.7143  \n",
      "\n",
      "Fold: 5  Epoch: 27  Training loss = 2.6284  Validation loss = 5.7140  \n",
      "\n",
      "Fold: 5  Epoch: 28  Training loss = 2.6281  Validation loss = 5.7137  \n",
      "\n",
      "Fold: 5  Epoch: 29  Training loss = 2.6279  Validation loss = 5.7134  \n",
      "\n",
      "Fold: 5  Epoch: 30  Training loss = 2.6276  Validation loss = 5.7131  \n",
      "\n",
      "Fold: 5  Epoch: 31  Training loss = 2.6273  Validation loss = 5.7127  \n",
      "\n",
      "Fold: 5  Epoch: 32  Training loss = 2.6271  Validation loss = 5.7125  \n",
      "\n",
      "Fold: 5  Epoch: 33  Training loss = 2.6269  Validation loss = 5.7121  \n",
      "\n",
      "Fold: 5  Epoch: 34  Training loss = 2.6266  Validation loss = 5.7118  \n",
      "\n",
      "Fold: 5  Epoch: 35  Training loss = 2.6263  Validation loss = 5.7114  \n",
      "\n",
      "Fold: 5  Epoch: 36  Training loss = 2.6261  Validation loss = 5.7111  \n",
      "\n",
      "Fold: 5  Epoch: 37  Training loss = 2.6259  Validation loss = 5.7109  \n",
      "\n",
      "Fold: 5  Epoch: 38  Training loss = 2.6256  Validation loss = 5.7105  \n",
      "\n",
      "Fold: 5  Epoch: 39  Training loss = 2.6253  Validation loss = 5.7102  \n",
      "\n",
      "Fold: 5  Epoch: 40  Training loss = 2.6251  Validation loss = 5.7099  \n",
      "\n",
      "Fold: 5  Epoch: 41  Training loss = 2.6249  Validation loss = 5.7096  \n",
      "\n",
      "Fold: 5  Epoch: 42  Training loss = 2.6246  Validation loss = 5.7093  \n",
      "\n",
      "Fold: 5  Epoch: 43  Training loss = 2.6244  Validation loss = 5.7090  \n",
      "\n",
      "Fold: 5  Epoch: 44  Training loss = 2.6241  Validation loss = 5.7087  \n",
      "\n",
      "Fold: 5  Epoch: 45  Training loss = 2.6238  Validation loss = 5.7082  \n",
      "\n",
      "Fold: 5  Epoch: 46  Training loss = 2.6235  Validation loss = 5.7079  \n",
      "\n",
      "Fold: 5  Epoch: 47  Training loss = 2.6233  Validation loss = 5.7076  \n",
      "\n",
      "Fold: 5  Epoch: 48  Training loss = 2.6230  Validation loss = 5.7073  \n",
      "\n",
      "Fold: 5  Epoch: 49  Training loss = 2.6228  Validation loss = 5.7070  \n",
      "\n",
      "Fold: 5  Epoch: 50  Training loss = 2.6225  Validation loss = 5.7067  \n",
      "\n",
      "Fold: 5  Epoch: 51  Training loss = 2.6223  Validation loss = 5.7064  \n",
      "\n",
      "Fold: 5  Epoch: 52  Training loss = 2.6220  Validation loss = 5.7060  \n",
      "\n",
      "Fold: 5  Epoch: 53  Training loss = 2.6217  Validation loss = 5.7057  \n",
      "\n",
      "Fold: 5  Epoch: 54  Training loss = 2.6215  Validation loss = 5.7055  \n",
      "\n",
      "Fold: 5  Epoch: 55  Training loss = 2.6212  Validation loss = 5.7051  \n",
      "\n",
      "Fold: 5  Epoch: 56  Training loss = 2.6210  Validation loss = 5.7049  \n",
      "\n",
      "Fold: 5  Epoch: 57  Training loss = 2.6207  Validation loss = 5.7045  \n",
      "\n",
      "Fold: 5  Epoch: 58  Training loss = 2.6205  Validation loss = 5.7043  \n",
      "\n",
      "Fold: 5  Epoch: 59  Training loss = 2.6203  Validation loss = 5.7040  \n",
      "\n",
      "Fold: 5  Epoch: 60  Training loss = 2.6200  Validation loss = 5.7036  \n",
      "\n",
      "Fold: 5  Epoch: 61  Training loss = 2.6198  Validation loss = 5.7033  \n",
      "\n",
      "Fold: 5  Epoch: 62  Training loss = 2.6196  Validation loss = 5.7031  \n",
      "\n",
      "Fold: 5  Epoch: 63  Training loss = 2.6194  Validation loss = 5.7028  \n",
      "\n",
      "Fold: 5  Epoch: 64  Training loss = 2.6191  Validation loss = 5.7025  \n",
      "\n",
      "Fold: 5  Epoch: 65  Training loss = 2.6189  Validation loss = 5.7022  \n",
      "\n",
      "Fold: 5  Epoch: 66  Training loss = 2.6186  Validation loss = 5.7019  \n",
      "\n",
      "Fold: 5  Epoch: 67  Training loss = 2.6184  Validation loss = 5.7016  \n",
      "\n",
      "Fold: 5  Epoch: 68  Training loss = 2.6182  Validation loss = 5.7013  \n",
      "\n",
      "Fold: 5  Epoch: 69  Training loss = 2.6179  Validation loss = 5.7010  \n",
      "\n",
      "Fold: 5  Epoch: 70  Training loss = 2.6177  Validation loss = 5.7008  \n",
      "\n",
      "Fold: 5  Epoch: 71  Training loss = 2.6175  Validation loss = 5.7005  \n",
      "\n",
      "Fold: 5  Epoch: 72  Training loss = 2.6172  Validation loss = 5.7002  \n",
      "\n",
      "Fold: 5  Epoch: 73  Training loss = 2.6169  Validation loss = 5.6998  \n",
      "\n",
      "Fold: 5  Epoch: 74  Training loss = 2.6167  Validation loss = 5.6995  \n",
      "\n",
      "Fold: 5  Epoch: 75  Training loss = 2.6165  Validation loss = 5.6993  \n",
      "\n",
      "Fold: 5  Epoch: 76  Training loss = 2.6163  Validation loss = 5.6990  \n",
      "\n",
      "Fold: 5  Epoch: 77  Training loss = 2.6160  Validation loss = 5.6987  \n",
      "\n",
      "Fold: 5  Epoch: 78  Training loss = 2.6158  Validation loss = 5.6984  \n",
      "\n",
      "Fold: 5  Epoch: 79  Training loss = 2.6156  Validation loss = 5.6981  \n",
      "\n",
      "Fold: 5  Epoch: 80  Training loss = 2.6154  Validation loss = 5.6979  \n",
      "\n",
      "Fold: 5  Epoch: 81  Training loss = 2.6152  Validation loss = 5.6977  \n",
      "\n",
      "Fold: 5  Epoch: 82  Training loss = 2.6149  Validation loss = 5.6974  \n",
      "\n",
      "Fold: 5  Epoch: 83  Training loss = 2.6146  Validation loss = 5.6970  \n",
      "\n",
      "Fold: 5  Epoch: 84  Training loss = 2.6144  Validation loss = 5.6967  \n",
      "\n",
      "Fold: 5  Epoch: 85  Training loss = 2.6142  Validation loss = 5.6965  \n",
      "\n",
      "Fold: 5  Epoch: 86  Training loss = 2.6140  Validation loss = 5.6962  \n",
      "\n",
      "Fold: 5  Epoch: 87  Training loss = 2.6137  Validation loss = 5.6959  \n",
      "\n",
      "Fold: 5  Epoch: 88  Training loss = 2.6135  Validation loss = 5.6956  \n",
      "\n",
      "Fold: 5  Epoch: 89  Training loss = 2.6133  Validation loss = 5.6953  \n",
      "\n",
      "Fold: 5  Epoch: 90  Training loss = 2.6130  Validation loss = 5.6950  \n",
      "\n",
      "Fold: 5  Epoch: 91  Training loss = 2.6128  Validation loss = 5.6947  \n",
      "\n",
      "Fold: 5  Epoch: 92  Training loss = 2.6126  Validation loss = 5.6944  \n",
      "\n",
      "Fold: 5  Epoch: 93  Training loss = 2.6123  Validation loss = 5.6941  \n",
      "\n",
      "Fold: 5  Epoch: 94  Training loss = 2.6121  Validation loss = 5.6939  \n",
      "\n",
      "Fold: 5  Epoch: 95  Training loss = 2.6118  Validation loss = 5.6935  \n",
      "\n",
      "Fold: 5  Epoch: 96  Training loss = 2.6116  Validation loss = 5.6933  \n",
      "\n",
      "Fold: 5  Epoch: 97  Training loss = 2.6114  Validation loss = 5.6931  \n",
      "\n",
      "Fold: 5  Epoch: 98  Training loss = 2.6112  Validation loss = 5.6928  \n",
      "\n",
      "Fold: 5  Epoch: 99  Training loss = 2.6109  Validation loss = 5.6924  \n",
      "\n",
      "Fold: 5  Epoch: 100  Training loss = 2.6106  Validation loss = 5.6920  \n",
      "\n",
      "Fold: 5  Epoch: 101  Training loss = 2.6104  Validation loss = 5.6917  \n",
      "\n",
      "Fold: 5  Epoch: 102  Training loss = 2.6102  Validation loss = 5.6915  \n",
      "\n",
      "Fold: 5  Epoch: 103  Training loss = 2.6100  Validation loss = 5.6912  \n",
      "\n",
      "Fold: 5  Epoch: 104  Training loss = 2.6097  Validation loss = 5.6910  \n",
      "\n",
      "Fold: 5  Epoch: 105  Training loss = 2.6095  Validation loss = 5.6907  \n",
      "\n",
      "Fold: 5  Epoch: 106  Training loss = 2.6092  Validation loss = 5.6903  \n",
      "\n",
      "Fold: 5  Epoch: 107  Training loss = 2.6090  Validation loss = 5.6900  \n",
      "\n",
      "Fold: 5  Epoch: 108  Training loss = 2.6087  Validation loss = 5.6897  \n",
      "\n",
      "Fold: 5  Epoch: 109  Training loss = 2.6085  Validation loss = 5.6894  \n",
      "\n",
      "Fold: 5  Epoch: 110  Training loss = 2.6083  Validation loss = 5.6891  \n",
      "\n",
      "Fold: 5  Epoch: 111  Training loss = 2.6080  Validation loss = 5.6888  \n",
      "\n",
      "Fold: 5  Epoch: 112  Training loss = 2.6078  Validation loss = 5.6885  \n",
      "\n",
      "Fold: 5  Epoch: 113  Training loss = 2.6075  Validation loss = 5.6882  \n",
      "\n",
      "Fold: 5  Epoch: 114  Training loss = 2.6073  Validation loss = 5.6879  \n",
      "\n",
      "Fold: 5  Epoch: 115  Training loss = 2.6070  Validation loss = 5.6876  \n",
      "\n",
      "Fold: 5  Epoch: 116  Training loss = 2.6068  Validation loss = 5.6873  \n",
      "\n",
      "Fold: 5  Epoch: 117  Training loss = 2.6065  Validation loss = 5.6870  \n",
      "\n",
      "Fold: 5  Epoch: 118  Training loss = 2.6063  Validation loss = 5.6867  \n",
      "\n",
      "Fold: 5  Epoch: 119  Training loss = 2.6060  Validation loss = 5.6863  \n",
      "\n",
      "Fold: 5  Epoch: 120  Training loss = 2.6059  Validation loss = 5.6862  \n",
      "\n",
      "Fold: 5  Epoch: 121  Training loss = 2.6056  Validation loss = 5.6858  \n",
      "\n",
      "Fold: 5  Epoch: 122  Training loss = 2.6054  Validation loss = 5.6855  \n",
      "\n",
      "Fold: 5  Epoch: 123  Training loss = 2.6052  Validation loss = 5.6853  \n",
      "\n",
      "Fold: 5  Epoch: 124  Training loss = 2.6050  Validation loss = 5.6850  \n",
      "\n",
      "Fold: 5  Epoch: 125  Training loss = 2.6047  Validation loss = 5.6847  \n",
      "\n",
      "Fold: 5  Epoch: 126  Training loss = 2.6045  Validation loss = 5.6844  \n",
      "\n",
      "Fold: 5  Epoch: 127  Training loss = 2.6042  Validation loss = 5.6841  \n",
      "\n",
      "Fold: 5  Epoch: 128  Training loss = 2.6040  Validation loss = 5.6838  \n",
      "\n",
      "Fold: 5  Epoch: 129  Training loss = 2.6037  Validation loss = 5.6835  \n",
      "\n",
      "Fold: 5  Epoch: 130  Training loss = 2.6035  Validation loss = 5.6832  \n",
      "\n",
      "Fold: 5  Epoch: 131  Training loss = 2.6033  Validation loss = 5.6829  \n",
      "\n",
      "Fold: 5  Epoch: 132  Training loss = 2.6031  Validation loss = 5.6826  \n",
      "\n",
      "Fold: 5  Epoch: 133  Training loss = 2.6028  Validation loss = 5.6823  \n",
      "\n",
      "Fold: 5  Epoch: 134  Training loss = 2.6025  Validation loss = 5.6820  \n",
      "\n",
      "Fold: 5  Epoch: 135  Training loss = 2.6022  Validation loss = 5.6816  \n",
      "\n",
      "Fold: 5  Epoch: 136  Training loss = 2.6021  Validation loss = 5.6814  \n",
      "\n",
      "Fold: 5  Epoch: 137  Training loss = 2.6018  Validation loss = 5.6810  \n",
      "\n",
      "Fold: 5  Epoch: 138  Training loss = 2.6015  Validation loss = 5.6806  \n",
      "\n",
      "Fold: 5  Epoch: 139  Training loss = 2.6012  Validation loss = 5.6803  \n",
      "\n",
      "Fold: 5  Epoch: 140  Training loss = 2.6010  Validation loss = 5.6800  \n",
      "\n",
      "Fold: 5  Epoch: 141  Training loss = 2.6008  Validation loss = 5.6797  \n",
      "\n",
      "Fold: 5  Epoch: 142  Training loss = 2.6005  Validation loss = 5.6794  \n",
      "\n",
      "Fold: 5  Epoch: 143  Training loss = 2.6003  Validation loss = 5.6792  \n",
      "\n",
      "Fold: 5  Epoch: 144  Training loss = 2.6001  Validation loss = 5.6789  \n",
      "\n",
      "Fold: 5  Epoch: 145  Training loss = 2.5998  Validation loss = 5.6786  \n",
      "\n",
      "Fold: 5  Epoch: 146  Training loss = 2.5996  Validation loss = 5.6784  \n",
      "\n",
      "Fold: 5  Epoch: 147  Training loss = 2.5994  Validation loss = 5.6781  \n",
      "\n",
      "Fold: 5  Epoch: 148  Training loss = 2.5992  Validation loss = 5.6778  \n",
      "\n",
      "Fold: 5  Epoch: 149  Training loss = 2.5989  Validation loss = 5.6775  \n",
      "\n",
      "Fold: 5  Epoch: 150  Training loss = 2.5987  Validation loss = 5.6773  \n",
      "\n",
      "Fold: 5  Epoch: 151  Training loss = 2.5985  Validation loss = 5.6770  \n",
      "\n",
      "Fold: 5  Epoch: 152  Training loss = 2.5982  Validation loss = 5.6767  \n",
      "\n",
      "Fold: 5  Epoch: 153  Training loss = 2.5980  Validation loss = 5.6764  \n",
      "\n",
      "Fold: 5  Epoch: 154  Training loss = 2.5978  Validation loss = 5.6760  \n",
      "\n",
      "Fold: 5  Epoch: 155  Training loss = 2.5975  Validation loss = 5.6758  \n",
      "\n",
      "Fold: 5  Epoch: 156  Training loss = 2.5973  Validation loss = 5.6755  \n",
      "\n",
      "Fold: 5  Epoch: 157  Training loss = 2.5971  Validation loss = 5.6752  \n",
      "\n",
      "Fold: 5  Epoch: 158  Training loss = 2.5969  Validation loss = 5.6750  \n",
      "\n",
      "Fold: 5  Epoch: 159  Training loss = 2.5966  Validation loss = 5.6747  \n",
      "\n",
      "Fold: 5  Epoch: 160  Training loss = 2.5964  Validation loss = 5.6744  \n",
      "\n",
      "Fold: 5  Epoch: 161  Training loss = 2.5962  Validation loss = 5.6741  \n",
      "\n",
      "Fold: 5  Epoch: 162  Training loss = 2.5959  Validation loss = 5.6738  \n",
      "\n",
      "Fold: 5  Epoch: 163  Training loss = 2.5957  Validation loss = 5.6735  \n",
      "\n",
      "Fold: 5  Epoch: 164  Training loss = 2.5954  Validation loss = 5.6732  \n",
      "\n",
      "Fold: 5  Epoch: 165  Training loss = 2.5952  Validation loss = 5.6729  \n",
      "\n",
      "Fold: 5  Epoch: 166  Training loss = 2.5950  Validation loss = 5.6726  \n",
      "\n",
      "Fold: 5  Epoch: 167  Training loss = 2.5947  Validation loss = 5.6722  \n",
      "\n",
      "Fold: 5  Epoch: 168  Training loss = 2.5945  Validation loss = 5.6720  \n",
      "\n",
      "Fold: 5  Epoch: 169  Training loss = 2.5942  Validation loss = 5.6716  \n",
      "\n",
      "Fold: 5  Epoch: 170  Training loss = 2.5940  Validation loss = 5.6713  \n",
      "\n",
      "Fold: 5  Epoch: 171  Training loss = 2.5938  Validation loss = 5.6711  \n",
      "\n",
      "Fold: 5  Epoch: 172  Training loss = 2.5935  Validation loss = 5.6708  \n",
      "\n",
      "Fold: 5  Epoch: 173  Training loss = 2.5933  Validation loss = 5.6705  \n",
      "\n",
      "Fold: 5  Epoch: 174  Training loss = 2.5931  Validation loss = 5.6702  \n",
      "\n",
      "Fold: 5  Epoch: 175  Training loss = 2.5928  Validation loss = 5.6698  \n",
      "\n",
      "Fold: 5  Epoch: 176  Training loss = 2.5926  Validation loss = 5.6695  \n",
      "\n",
      "Fold: 5  Epoch: 177  Training loss = 2.5923  Validation loss = 5.6692  \n",
      "\n",
      "Fold: 5  Epoch: 178  Training loss = 2.5920  Validation loss = 5.6688  \n",
      "\n",
      "Fold: 5  Epoch: 179  Training loss = 2.5918  Validation loss = 5.6685  \n",
      "\n",
      "Fold: 5  Epoch: 180  Training loss = 2.5915  Validation loss = 5.6682  \n",
      "\n",
      "Fold: 5  Epoch: 181  Training loss = 2.5913  Validation loss = 5.6678  \n",
      "\n",
      "Fold: 5  Epoch: 182  Training loss = 2.5910  Validation loss = 5.6675  \n",
      "\n",
      "Fold: 5  Epoch: 183  Training loss = 2.5908  Validation loss = 5.6673  \n",
      "\n",
      "Fold: 5  Epoch: 184  Training loss = 2.5906  Validation loss = 5.6670  \n",
      "\n",
      "Fold: 5  Epoch: 185  Training loss = 2.5903  Validation loss = 5.6667  \n",
      "\n",
      "Fold: 5  Epoch: 186  Training loss = 2.5901  Validation loss = 5.6664  \n",
      "\n",
      "Fold: 5  Epoch: 187  Training loss = 2.5899  Validation loss = 5.6661  \n",
      "\n",
      "Fold: 5  Epoch: 188  Training loss = 2.5897  Validation loss = 5.6658  \n",
      "\n",
      "Fold: 5  Epoch: 189  Training loss = 2.5894  Validation loss = 5.6655  \n",
      "\n",
      "Fold: 5  Epoch: 190  Training loss = 2.5892  Validation loss = 5.6652  \n",
      "\n",
      "Fold: 5  Epoch: 191  Training loss = 2.5889  Validation loss = 5.6648  \n",
      "\n",
      "Fold: 5  Epoch: 192  Training loss = 2.5886  Validation loss = 5.6645  \n",
      "\n",
      "Fold: 5  Epoch: 193  Training loss = 2.5884  Validation loss = 5.6642  \n",
      "\n",
      "Fold: 5  Epoch: 194  Training loss = 2.5882  Validation loss = 5.6639  \n",
      "\n",
      "Fold: 5  Epoch: 195  Training loss = 2.5880  Validation loss = 5.6637  \n",
      "\n",
      "Fold: 5  Epoch: 196  Training loss = 2.5877  Validation loss = 5.6633  \n",
      "\n",
      "Fold: 5  Epoch: 197  Training loss = 2.5875  Validation loss = 5.6631  \n",
      "\n",
      "Fold: 5  Epoch: 198  Training loss = 2.5873  Validation loss = 5.6628  \n",
      "\n",
      "Fold: 5  Epoch: 199  Training loss = 2.5871  Validation loss = 5.6625  \n",
      "\n",
      "Fold: 5  Epoch: 200  Training loss = 2.5868  Validation loss = 5.6622  \n",
      "\n",
      "Fold: 5  Epoch: 201  Training loss = 2.5866  Validation loss = 5.6619  \n",
      "\n",
      "Fold: 5  Epoch: 202  Training loss = 2.5864  Validation loss = 5.6616  \n",
      "\n",
      "Fold: 5  Epoch: 203  Training loss = 2.5862  Validation loss = 5.6614  \n",
      "\n",
      "Fold: 5  Epoch: 204  Training loss = 2.5860  Validation loss = 5.6611  \n",
      "\n",
      "Fold: 5  Epoch: 205  Training loss = 2.5858  Validation loss = 5.6608  \n",
      "\n",
      "Fold: 5  Epoch: 206  Training loss = 2.5855  Validation loss = 5.6606  \n",
      "\n",
      "Fold: 5  Epoch: 207  Training loss = 2.5853  Validation loss = 5.6603  \n",
      "\n",
      "Fold: 5  Epoch: 208  Training loss = 2.5851  Validation loss = 5.6600  \n",
      "\n",
      "Fold: 5  Epoch: 209  Training loss = 2.5849  Validation loss = 5.6597  \n",
      "\n",
      "Fold: 5  Epoch: 210  Training loss = 2.5846  Validation loss = 5.6594  \n",
      "\n",
      "Fold: 5  Epoch: 211  Training loss = 2.5844  Validation loss = 5.6591  \n",
      "\n",
      "Fold: 5  Epoch: 212  Training loss = 2.5841  Validation loss = 5.6588  \n",
      "\n",
      "Fold: 5  Epoch: 213  Training loss = 2.5839  Validation loss = 5.6585  \n",
      "\n",
      "Fold: 5  Epoch: 214  Training loss = 2.5837  Validation loss = 5.6583  \n",
      "\n",
      "Fold: 5  Epoch: 215  Training loss = 2.5835  Validation loss = 5.6580  \n",
      "\n",
      "Fold: 5  Epoch: 216  Training loss = 2.5832  Validation loss = 5.6577  \n",
      "\n",
      "Fold: 5  Epoch: 217  Training loss = 2.5830  Validation loss = 5.6574  \n",
      "\n",
      "Fold: 5  Epoch: 218  Training loss = 2.5828  Validation loss = 5.6571  \n",
      "\n",
      "Fold: 5  Epoch: 219  Training loss = 2.5826  Validation loss = 5.6569  \n",
      "\n",
      "Fold: 5  Epoch: 220  Training loss = 2.5824  Validation loss = 5.6566  \n",
      "\n",
      "Fold: 5  Epoch: 221  Training loss = 2.5821  Validation loss = 5.6563  \n",
      "\n",
      "Fold: 5  Epoch: 222  Training loss = 2.5819  Validation loss = 5.6560  \n",
      "\n",
      "Fold: 5  Epoch: 223  Training loss = 2.5817  Validation loss = 5.6557  \n",
      "\n",
      "Fold: 5  Epoch: 224  Training loss = 2.5814  Validation loss = 5.6554  \n",
      "\n",
      "Fold: 5  Epoch: 225  Training loss = 2.5812  Validation loss = 5.6551  \n",
      "\n",
      "Fold: 5  Epoch: 226  Training loss = 2.5810  Validation loss = 5.6548  \n",
      "\n",
      "Fold: 5  Epoch: 227  Training loss = 2.5807  Validation loss = 5.6545  \n",
      "\n",
      "Fold: 5  Epoch: 228  Training loss = 2.5806  Validation loss = 5.6543  \n",
      "\n",
      "Fold: 5  Epoch: 229  Training loss = 2.5804  Validation loss = 5.6541  \n",
      "\n",
      "Fold: 5  Epoch: 230  Training loss = 2.5802  Validation loss = 5.6539  \n",
      "\n",
      "Fold: 5  Epoch: 231  Training loss = 2.5800  Validation loss = 5.6536  \n",
      "\n",
      "Fold: 5  Epoch: 232  Training loss = 2.5797  Validation loss = 5.6533  \n",
      "\n",
      "Fold: 5  Epoch: 233  Training loss = 2.5795  Validation loss = 5.6530  \n",
      "\n",
      "Fold: 5  Epoch: 234  Training loss = 2.5793  Validation loss = 5.6527  \n",
      "\n",
      "Fold: 5  Epoch: 235  Training loss = 2.5790  Validation loss = 5.6524  \n",
      "\n",
      "Fold: 5  Epoch: 236  Training loss = 2.5788  Validation loss = 5.6521  \n",
      "\n",
      "Fold: 5  Epoch: 237  Training loss = 2.5786  Validation loss = 5.6518  \n",
      "\n",
      "Fold: 5  Epoch: 238  Training loss = 2.5783  Validation loss = 5.6515  \n",
      "\n",
      "Fold: 5  Epoch: 239  Training loss = 2.5781  Validation loss = 5.6512  \n",
      "\n",
      "Fold: 5  Epoch: 240  Training loss = 2.5778  Validation loss = 5.6509  \n",
      "\n",
      "Fold: 5  Epoch: 241  Training loss = 2.5776  Validation loss = 5.6506  \n",
      "\n",
      "Fold: 5  Epoch: 242  Training loss = 2.5774  Validation loss = 5.6503  \n",
      "\n",
      "Fold: 5  Epoch: 243  Training loss = 2.5771  Validation loss = 5.6500  \n",
      "\n",
      "Fold: 5  Epoch: 244  Training loss = 2.5769  Validation loss = 5.6497  \n",
      "\n",
      "Fold: 5  Epoch: 245  Training loss = 2.5767  Validation loss = 5.6495  \n",
      "\n",
      "Fold: 5  Epoch: 246  Training loss = 2.5765  Validation loss = 5.6492  \n",
      "\n",
      "Fold: 5  Epoch: 247  Training loss = 2.5763  Validation loss = 5.6489  \n",
      "\n",
      "Fold: 5  Epoch: 248  Training loss = 2.5761  Validation loss = 5.6487  \n",
      "\n",
      "Fold: 5  Epoch: 249  Training loss = 2.5759  Validation loss = 5.6484  \n",
      "\n",
      "Fold: 5  Epoch: 250  Training loss = 2.5757  Validation loss = 5.6482  \n",
      "\n",
      "Fold: 5  Epoch: 251  Training loss = 2.5754  Validation loss = 5.6479  \n",
      "\n",
      "Fold: 5  Epoch: 252  Training loss = 2.5752  Validation loss = 5.6476  \n",
      "\n",
      "Fold: 5  Epoch: 253  Training loss = 2.5751  Validation loss = 5.6474  \n",
      "\n",
      "Fold: 5  Epoch: 254  Training loss = 2.5748  Validation loss = 5.6471  \n",
      "\n",
      "Fold: 5  Epoch: 255  Training loss = 2.5746  Validation loss = 5.6469  \n",
      "\n",
      "Fold: 5  Epoch: 256  Training loss = 2.5744  Validation loss = 5.6465  \n",
      "\n",
      "Fold: 5  Epoch: 257  Training loss = 2.5742  Validation loss = 5.6463  \n",
      "\n",
      "Fold: 5  Epoch: 258  Training loss = 2.5739  Validation loss = 5.6460  \n",
      "\n",
      "Fold: 5  Epoch: 259  Training loss = 2.5737  Validation loss = 5.6457  \n",
      "\n",
      "Fold: 5  Epoch: 260  Training loss = 2.5735  Validation loss = 5.6455  \n",
      "\n",
      "Fold: 5  Epoch: 261  Training loss = 2.5732  Validation loss = 5.6451  \n",
      "\n",
      "Fold: 5  Epoch: 262  Training loss = 2.5730  Validation loss = 5.6449  \n",
      "\n",
      "Fold: 5  Epoch: 263  Training loss = 2.5728  Validation loss = 5.6446  \n",
      "\n",
      "Fold: 5  Epoch: 264  Training loss = 2.5726  Validation loss = 5.6444  \n",
      "\n",
      "Fold: 5  Epoch: 265  Training loss = 2.5724  Validation loss = 5.6442  \n",
      "\n",
      "Fold: 5  Epoch: 266  Training loss = 2.5722  Validation loss = 5.6439  \n",
      "\n",
      "Fold: 5  Epoch: 267  Training loss = 2.5720  Validation loss = 5.6436  \n",
      "\n",
      "Fold: 5  Epoch: 268  Training loss = 2.5718  Validation loss = 5.6434  \n",
      "\n",
      "Fold: 5  Epoch: 269  Training loss = 2.5715  Validation loss = 5.6431  \n",
      "\n",
      "Fold: 5  Epoch: 270  Training loss = 2.5713  Validation loss = 5.6428  \n",
      "\n",
      "Fold: 5  Epoch: 271  Training loss = 2.5710  Validation loss = 5.6424  \n",
      "\n",
      "Fold: 5  Epoch: 272  Training loss = 2.5708  Validation loss = 5.6421  \n",
      "\n",
      "Fold: 5  Epoch: 273  Training loss = 2.5706  Validation loss = 5.6418  \n",
      "\n",
      "Fold: 5  Epoch: 274  Training loss = 2.5703  Validation loss = 5.6416  \n",
      "\n",
      "Fold: 5  Epoch: 275  Training loss = 2.5701  Validation loss = 5.6413  \n",
      "\n",
      "Fold: 5  Epoch: 276  Training loss = 2.5699  Validation loss = 5.6410  \n",
      "\n",
      "Fold: 5  Epoch: 277  Training loss = 2.5697  Validation loss = 5.6407  \n",
      "\n",
      "Fold: 5  Epoch: 278  Training loss = 2.5694  Validation loss = 5.6404  \n",
      "\n",
      "Fold: 5  Epoch: 279  Training loss = 2.5692  Validation loss = 5.6401  \n",
      "\n",
      "Fold: 5  Epoch: 280  Training loss = 2.5690  Validation loss = 5.6398  \n",
      "\n",
      "Fold: 5  Epoch: 281  Training loss = 2.5688  Validation loss = 5.6396  \n",
      "\n",
      "Fold: 5  Epoch: 282  Training loss = 2.5685  Validation loss = 5.6393  \n",
      "\n",
      "Fold: 5  Epoch: 283  Training loss = 2.5683  Validation loss = 5.6390  \n",
      "\n",
      "Fold: 5  Epoch: 284  Training loss = 2.5681  Validation loss = 5.6387  \n",
      "\n",
      "Fold: 5  Epoch: 285  Training loss = 2.5678  Validation loss = 5.6384  \n",
      "\n",
      "Fold: 5  Epoch: 286  Training loss = 2.5676  Validation loss = 5.6381  \n",
      "\n",
      "Fold: 5  Epoch: 287  Training loss = 2.5674  Validation loss = 5.6378  \n",
      "\n",
      "Fold: 5  Epoch: 288  Training loss = 2.5672  Validation loss = 5.6376  \n",
      "\n",
      "Fold: 5  Epoch: 289  Training loss = 2.5670  Validation loss = 5.6373  \n",
      "\n",
      "Fold: 5  Epoch: 290  Training loss = 2.5667  Validation loss = 5.6370  \n",
      "\n",
      "Fold: 5  Epoch: 291  Training loss = 2.5666  Validation loss = 5.6368  \n",
      "\n",
      "Fold: 5  Epoch: 292  Training loss = 2.5664  Validation loss = 5.6365  \n",
      "\n",
      "Fold: 5  Epoch: 293  Training loss = 2.5661  Validation loss = 5.6362  \n",
      "\n",
      "Fold: 5  Epoch: 294  Training loss = 2.5659  Validation loss = 5.6359  \n",
      "\n",
      "Fold: 5  Epoch: 295  Training loss = 2.5656  Validation loss = 5.6356  \n",
      "\n",
      "Fold: 5  Epoch: 296  Training loss = 2.5654  Validation loss = 5.6354  \n",
      "\n",
      "Fold: 5  Epoch: 297  Training loss = 2.5652  Validation loss = 5.6351  \n",
      "\n",
      "Fold: 5  Epoch: 298  Training loss = 2.5650  Validation loss = 5.6348  \n",
      "\n",
      "Fold: 5  Epoch: 299  Training loss = 2.5648  Validation loss = 5.6345  \n",
      "\n",
      "Fold: 5  Epoch: 300  Training loss = 2.5645  Validation loss = 5.6342  \n",
      "\n",
      "Fold: 5  Epoch: 301  Training loss = 2.5643  Validation loss = 5.6340  \n",
      "\n",
      "Fold: 5  Epoch: 302  Training loss = 2.5641  Validation loss = 5.6336  \n",
      "\n",
      "Fold: 5  Epoch: 303  Training loss = 2.5639  Validation loss = 5.6334  \n",
      "\n",
      "Fold: 5  Epoch: 304  Training loss = 2.5637  Validation loss = 5.6332  \n",
      "\n",
      "Fold: 5  Epoch: 305  Training loss = 2.5634  Validation loss = 5.6329  \n",
      "\n",
      "Fold: 5  Epoch: 306  Training loss = 2.5632  Validation loss = 5.6326  \n",
      "\n",
      "Fold: 5  Epoch: 307  Training loss = 2.5630  Validation loss = 5.6324  \n",
      "\n",
      "Fold: 5  Epoch: 308  Training loss = 2.5628  Validation loss = 5.6321  \n",
      "\n",
      "Fold: 5  Epoch: 309  Training loss = 2.5626  Validation loss = 5.6318  \n",
      "\n",
      "Fold: 5  Epoch: 310  Training loss = 2.5624  Validation loss = 5.6316  \n",
      "\n",
      "Fold: 5  Epoch: 311  Training loss = 2.5622  Validation loss = 5.6313  \n",
      "\n",
      "Fold: 5  Epoch: 312  Training loss = 2.5620  Validation loss = 5.6311  \n",
      "\n",
      "Fold: 5  Epoch: 313  Training loss = 2.5618  Validation loss = 5.6308  \n",
      "\n",
      "Fold: 5  Epoch: 314  Training loss = 2.5615  Validation loss = 5.6305  \n",
      "\n",
      "Fold: 5  Epoch: 315  Training loss = 2.5613  Validation loss = 5.6302  \n",
      "\n",
      "Fold: 5  Epoch: 316  Training loss = 2.5611  Validation loss = 5.6300  \n",
      "\n",
      "Fold: 5  Epoch: 317  Training loss = 2.5609  Validation loss = 5.6298  \n",
      "\n",
      "Fold: 5  Epoch: 318  Training loss = 2.5607  Validation loss = 5.6294  \n",
      "\n",
      "Fold: 5  Epoch: 319  Training loss = 2.5604  Validation loss = 5.6291  \n",
      "\n",
      "Fold: 5  Epoch: 320  Training loss = 2.5602  Validation loss = 5.6288  \n",
      "\n",
      "Fold: 5  Epoch: 321  Training loss = 2.5600  Validation loss = 5.6286  \n",
      "\n",
      "Fold: 5  Epoch: 322  Training loss = 2.5598  Validation loss = 5.6283  \n",
      "\n",
      "Fold: 5  Epoch: 323  Training loss = 2.5595  Validation loss = 5.6280  \n",
      "\n",
      "Fold: 5  Epoch: 324  Training loss = 2.5593  Validation loss = 5.6277  \n",
      "\n",
      "Fold: 5  Epoch: 325  Training loss = 2.5591  Validation loss = 5.6275  \n",
      "\n",
      "Fold: 5  Epoch: 326  Training loss = 2.5589  Validation loss = 5.6272  \n",
      "\n",
      "Fold: 5  Epoch: 327  Training loss = 2.5587  Validation loss = 5.6269  \n",
      "\n",
      "Fold: 5  Epoch: 328  Training loss = 2.5585  Validation loss = 5.6266  \n",
      "\n",
      "Fold: 5  Epoch: 329  Training loss = 2.5583  Validation loss = 5.6265  \n",
      "\n",
      "Fold: 5  Epoch: 330  Training loss = 2.5581  Validation loss = 5.6263  \n",
      "\n",
      "Fold: 5  Epoch: 331  Training loss = 2.5579  Validation loss = 5.6260  \n",
      "\n",
      "Fold: 5  Epoch: 332  Training loss = 2.5577  Validation loss = 5.6257  \n",
      "\n",
      "Fold: 5  Epoch: 333  Training loss = 2.5575  Validation loss = 5.6254  \n",
      "\n",
      "Fold: 5  Epoch: 334  Training loss = 2.5572  Validation loss = 5.6251  \n",
      "\n",
      "Fold: 5  Epoch: 335  Training loss = 2.5570  Validation loss = 5.6248  \n",
      "\n",
      "Fold: 5  Epoch: 336  Training loss = 2.5568  Validation loss = 5.6246  \n",
      "\n",
      "Fold: 5  Epoch: 337  Training loss = 2.5566  Validation loss = 5.6242  \n",
      "\n",
      "Fold: 5  Epoch: 338  Training loss = 2.5563  Validation loss = 5.6239  \n",
      "\n",
      "Fold: 5  Epoch: 339  Training loss = 2.5561  Validation loss = 5.6237  \n",
      "\n",
      "Fold: 5  Epoch: 340  Training loss = 2.5559  Validation loss = 5.6234  \n",
      "\n",
      "Fold: 5  Epoch: 341  Training loss = 2.5557  Validation loss = 5.6232  \n",
      "\n",
      "Fold: 5  Epoch: 342  Training loss = 2.5555  Validation loss = 5.6229  \n",
      "\n",
      "Fold: 5  Epoch: 343  Training loss = 2.5553  Validation loss = 5.6226  \n",
      "\n",
      "Fold: 5  Epoch: 344  Training loss = 2.5551  Validation loss = 5.6223  \n",
      "\n",
      "Fold: 5  Epoch: 345  Training loss = 2.5548  Validation loss = 5.6220  \n",
      "\n",
      "Fold: 5  Epoch: 346  Training loss = 2.5546  Validation loss = 5.6217  \n",
      "\n",
      "Fold: 5  Epoch: 347  Training loss = 2.5544  Validation loss = 5.6215  \n",
      "\n",
      "Fold: 5  Epoch: 348  Training loss = 2.5542  Validation loss = 5.6212  \n",
      "\n",
      "Fold: 5  Epoch: 349  Training loss = 2.5539  Validation loss = 5.6209  \n",
      "\n",
      "Fold: 5  Epoch: 350  Training loss = 2.5537  Validation loss = 5.6206  \n",
      "\n",
      "Fold: 5  Epoch: 351  Training loss = 2.5535  Validation loss = 5.6203  \n",
      "\n",
      "Fold: 5  Epoch: 352  Training loss = 2.5532  Validation loss = 5.6200  \n",
      "\n",
      "Fold: 5  Epoch: 353  Training loss = 2.5530  Validation loss = 5.6197  \n",
      "\n",
      "Fold: 5  Epoch: 354  Training loss = 2.5528  Validation loss = 5.6195  \n",
      "\n",
      "Fold: 5  Epoch: 355  Training loss = 2.5526  Validation loss = 5.6192  \n",
      "\n",
      "Fold: 5  Epoch: 356  Training loss = 2.5524  Validation loss = 5.6189  \n",
      "\n",
      "Fold: 5  Epoch: 357  Training loss = 2.5522  Validation loss = 5.6187  \n",
      "\n",
      "Fold: 5  Epoch: 358  Training loss = 2.5520  Validation loss = 5.6184  \n",
      "\n",
      "Fold: 5  Epoch: 359  Training loss = 2.5518  Validation loss = 5.6181  \n",
      "\n",
      "Fold: 5  Epoch: 360  Training loss = 2.5515  Validation loss = 5.6178  \n",
      "\n",
      "Fold: 5  Epoch: 361  Training loss = 2.5513  Validation loss = 5.6175  \n",
      "\n",
      "Fold: 5  Epoch: 362  Training loss = 2.5510  Validation loss = 5.6172  \n",
      "\n",
      "Fold: 5  Epoch: 363  Training loss = 2.5508  Validation loss = 5.6169  \n",
      "\n",
      "Fold: 5  Epoch: 364  Training loss = 2.5506  Validation loss = 5.6167  \n",
      "\n",
      "Fold: 5  Epoch: 365  Training loss = 2.5504  Validation loss = 5.6164  \n",
      "\n",
      "Fold: 5  Epoch: 366  Training loss = 2.5502  Validation loss = 5.6162  \n",
      "\n",
      "Fold: 5  Epoch: 367  Training loss = 2.5500  Validation loss = 5.6159  \n",
      "\n",
      "Fold: 5  Epoch: 368  Training loss = 2.5498  Validation loss = 5.6156  \n",
      "\n",
      "Fold: 5  Epoch: 369  Training loss = 2.5496  Validation loss = 5.6154  \n",
      "\n",
      "Fold: 5  Epoch: 370  Training loss = 2.5493  Validation loss = 5.6151  \n",
      "\n",
      "Fold: 5  Epoch: 371  Training loss = 2.5491  Validation loss = 5.6148  \n",
      "\n",
      "Fold: 5  Epoch: 372  Training loss = 2.5489  Validation loss = 5.6145  \n",
      "\n",
      "Fold: 5  Epoch: 373  Training loss = 2.5487  Validation loss = 5.6142  \n",
      "\n",
      "Fold: 5  Epoch: 374  Training loss = 2.5485  Validation loss = 5.6140  \n",
      "\n",
      "Fold: 5  Epoch: 375  Training loss = 2.5483  Validation loss = 5.6137  \n",
      "\n",
      "Fold: 5  Epoch: 376  Training loss = 2.5481  Validation loss = 5.6134  \n",
      "\n",
      "Fold: 5  Epoch: 377  Training loss = 2.5479  Validation loss = 5.6132  \n",
      "\n",
      "Fold: 5  Epoch: 378  Training loss = 2.5476  Validation loss = 5.6129  \n",
      "\n",
      "Fold: 5  Epoch: 379  Training loss = 2.5474  Validation loss = 5.6126  \n",
      "\n",
      "Fold: 5  Epoch: 380  Training loss = 2.5472  Validation loss = 5.6123  \n",
      "\n",
      "Fold: 5  Epoch: 381  Training loss = 2.5469  Validation loss = 5.6120  \n",
      "\n",
      "Fold: 5  Epoch: 382  Training loss = 2.5468  Validation loss = 5.6118  \n",
      "\n",
      "Fold: 5  Epoch: 383  Training loss = 2.5465  Validation loss = 5.6115  \n",
      "\n",
      "Fold: 5  Epoch: 384  Training loss = 2.5463  Validation loss = 5.6113  \n",
      "\n",
      "Fold: 5  Epoch: 385  Training loss = 2.5462  Validation loss = 5.6111  \n",
      "\n",
      "Fold: 5  Epoch: 386  Training loss = 2.5459  Validation loss = 5.6108  \n",
      "\n",
      "Fold: 5  Epoch: 387  Training loss = 2.5457  Validation loss = 5.6105  \n",
      "\n",
      "Fold: 5  Epoch: 388  Training loss = 2.5455  Validation loss = 5.6102  \n",
      "\n",
      "Fold: 5  Epoch: 389  Training loss = 2.5453  Validation loss = 5.6100  \n",
      "\n",
      "Fold: 5  Epoch: 390  Training loss = 2.5450  Validation loss = 5.6097  \n",
      "\n",
      "Fold: 5  Epoch: 391  Training loss = 2.5448  Validation loss = 5.6095  \n",
      "\n",
      "Fold: 5  Epoch: 392  Training loss = 2.5446  Validation loss = 5.6092  \n",
      "\n",
      "Fold: 5  Epoch: 393  Training loss = 2.5445  Validation loss = 5.6090  \n",
      "\n",
      "Fold: 5  Epoch: 394  Training loss = 2.5442  Validation loss = 5.6087  \n",
      "\n",
      "Fold: 5  Epoch: 395  Training loss = 2.5440  Validation loss = 5.6084  \n",
      "\n",
      "Fold: 5  Epoch: 396  Training loss = 2.5438  Validation loss = 5.6082  \n",
      "\n",
      "Fold: 5  Epoch: 397  Training loss = 2.5436  Validation loss = 5.6079  \n",
      "\n",
      "Fold: 5  Epoch: 398  Training loss = 2.5434  Validation loss = 5.6077  \n",
      "\n",
      "Fold: 5  Epoch: 399  Training loss = 2.5432  Validation loss = 5.6074  \n",
      "\n",
      "Fold: 5  Epoch: 400  Training loss = 2.5430  Validation loss = 5.6071  \n",
      "\n",
      "Fold: 5  Epoch: 401  Training loss = 2.5427  Validation loss = 5.6068  \n",
      "\n",
      "Fold: 5  Epoch: 402  Training loss = 2.5425  Validation loss = 5.6065  \n",
      "\n",
      "Fold: 5  Epoch: 403  Training loss = 2.5423  Validation loss = 5.6063  \n",
      "\n",
      "Fold: 5  Epoch: 404  Training loss = 2.5421  Validation loss = 5.6060  \n",
      "\n",
      "Fold: 5  Epoch: 405  Training loss = 2.5419  Validation loss = 5.6058  \n",
      "\n",
      "Fold: 5  Epoch: 406  Training loss = 2.5417  Validation loss = 5.6055  \n",
      "\n",
      "Fold: 5  Epoch: 407  Training loss = 2.5416  Validation loss = 5.6053  \n",
      "\n",
      "Fold: 5  Epoch: 408  Training loss = 2.5414  Validation loss = 5.6051  \n",
      "\n",
      "Fold: 5  Epoch: 409  Training loss = 2.5412  Validation loss = 5.6049  \n",
      "\n",
      "Fold: 5  Epoch: 410  Training loss = 2.5410  Validation loss = 5.6047  \n",
      "\n",
      "Fold: 5  Epoch: 411  Training loss = 2.5408  Validation loss = 5.6044  \n",
      "\n",
      "Fold: 5  Epoch: 412  Training loss = 2.5405  Validation loss = 5.6041  \n",
      "\n",
      "Fold: 5  Epoch: 413  Training loss = 2.5404  Validation loss = 5.6039  \n",
      "\n",
      "Fold: 5  Epoch: 414  Training loss = 2.5401  Validation loss = 5.6035  \n",
      "\n",
      "Fold: 5  Epoch: 415  Training loss = 2.5399  Validation loss = 5.6033  \n",
      "\n",
      "Fold: 5  Epoch: 416  Training loss = 2.5397  Validation loss = 5.6030  \n",
      "\n",
      "Fold: 5  Epoch: 417  Training loss = 2.5395  Validation loss = 5.6027  \n",
      "\n",
      "Fold: 5  Epoch: 418  Training loss = 2.5393  Validation loss = 5.6024  \n",
      "\n",
      "Fold: 5  Epoch: 419  Training loss = 2.5390  Validation loss = 5.6021  \n",
      "\n",
      "Fold: 5  Epoch: 420  Training loss = 2.5388  Validation loss = 5.6019  \n",
      "\n",
      "Fold: 5  Epoch: 421  Training loss = 2.5385  Validation loss = 5.6015  \n",
      "\n",
      "Fold: 5  Epoch: 422  Training loss = 2.5383  Validation loss = 5.6012  \n",
      "\n",
      "Fold: 5  Epoch: 423  Training loss = 2.5381  Validation loss = 5.6009  \n",
      "\n",
      "Fold: 5  Epoch: 424  Training loss = 2.5379  Validation loss = 5.6007  \n",
      "\n",
      "Fold: 5  Epoch: 425  Training loss = 2.5377  Validation loss = 5.6004  \n",
      "\n",
      "Fold: 5  Epoch: 426  Training loss = 2.5375  Validation loss = 5.6002  \n",
      "\n",
      "Fold: 5  Epoch: 427  Training loss = 2.5372  Validation loss = 5.5999  \n",
      "\n",
      "Fold: 5  Epoch: 428  Training loss = 2.5370  Validation loss = 5.5996  \n",
      "\n",
      "Fold: 5  Epoch: 429  Training loss = 2.5368  Validation loss = 5.5994  \n",
      "\n",
      "Fold: 5  Epoch: 430  Training loss = 2.5367  Validation loss = 5.5991  \n",
      "\n",
      "Fold: 5  Epoch: 431  Training loss = 2.5364  Validation loss = 5.5989  \n",
      "\n",
      "Fold: 5  Epoch: 432  Training loss = 2.5362  Validation loss = 5.5986  \n",
      "\n",
      "Fold: 5  Epoch: 433  Training loss = 2.5360  Validation loss = 5.5983  \n",
      "\n",
      "Fold: 5  Epoch: 434  Training loss = 2.5358  Validation loss = 5.5980  \n",
      "\n",
      "Fold: 5  Epoch: 435  Training loss = 2.5356  Validation loss = 5.5978  \n",
      "\n",
      "Fold: 5  Epoch: 436  Training loss = 2.5354  Validation loss = 5.5975  \n",
      "\n",
      "Fold: 5  Epoch: 437  Training loss = 2.5352  Validation loss = 5.5973  \n",
      "\n",
      "Fold: 5  Epoch: 438  Training loss = 2.5350  Validation loss = 5.5970  \n",
      "\n",
      "Fold: 5  Epoch: 439  Training loss = 2.5348  Validation loss = 5.5968  \n",
      "\n",
      "Fold: 5  Epoch: 440  Training loss = 2.5346  Validation loss = 5.5965  \n",
      "\n",
      "Fold: 5  Epoch: 441  Training loss = 2.5344  Validation loss = 5.5962  \n",
      "\n",
      "Fold: 5  Epoch: 442  Training loss = 2.5342  Validation loss = 5.5960  \n",
      "\n",
      "Fold: 5  Epoch: 443  Training loss = 2.5340  Validation loss = 5.5958  \n",
      "\n",
      "Fold: 5  Epoch: 444  Training loss = 2.5338  Validation loss = 5.5955  \n",
      "\n",
      "Fold: 5  Epoch: 445  Training loss = 2.5336  Validation loss = 5.5953  \n",
      "\n",
      "Fold: 5  Epoch: 446  Training loss = 2.5334  Validation loss = 5.5950  \n",
      "\n",
      "Fold: 5  Epoch: 447  Training loss = 2.5332  Validation loss = 5.5948  \n",
      "\n",
      "Fold: 5  Epoch: 448  Training loss = 2.5330  Validation loss = 5.5946  \n",
      "\n",
      "Fold: 5  Epoch: 449  Training loss = 2.5328  Validation loss = 5.5943  \n",
      "\n",
      "Fold: 5  Epoch: 450  Training loss = 2.5326  Validation loss = 5.5941  \n",
      "\n",
      "Fold: 5  Epoch: 451  Training loss = 2.5324  Validation loss = 5.5938  \n",
      "\n",
      "Fold: 5  Epoch: 452  Training loss = 2.5321  Validation loss = 5.5935  \n",
      "\n",
      "Fold: 5  Epoch: 453  Training loss = 2.5319  Validation loss = 5.5931  \n",
      "\n",
      "Fold: 5  Epoch: 454  Training loss = 2.5317  Validation loss = 5.5929  \n",
      "\n",
      "Fold: 5  Epoch: 455  Training loss = 2.5315  Validation loss = 5.5926  \n",
      "\n",
      "Fold: 5  Epoch: 456  Training loss = 2.5312  Validation loss = 5.5923  \n",
      "\n",
      "Fold: 5  Epoch: 457  Training loss = 2.5310  Validation loss = 5.5920  \n",
      "\n",
      "Fold: 5  Epoch: 458  Training loss = 2.5308  Validation loss = 5.5917  \n",
      "\n",
      "Fold: 5  Epoch: 459  Training loss = 2.5306  Validation loss = 5.5915  \n",
      "\n",
      "Fold: 5  Epoch: 460  Training loss = 2.5303  Validation loss = 5.5912  \n",
      "\n",
      "Fold: 5  Epoch: 461  Training loss = 2.5301  Validation loss = 5.5909  \n",
      "\n",
      "Fold: 5  Epoch: 462  Training loss = 2.5299  Validation loss = 5.5907  \n",
      "\n",
      "Fold: 5  Epoch: 463  Training loss = 2.5297  Validation loss = 5.5904  \n",
      "\n",
      "Fold: 5  Epoch: 464  Training loss = 2.5295  Validation loss = 5.5901  \n",
      "\n",
      "Fold: 5  Epoch: 465  Training loss = 2.5293  Validation loss = 5.5898  \n",
      "\n",
      "Fold: 5  Epoch: 466  Training loss = 2.5291  Validation loss = 5.5896  \n",
      "\n",
      "Fold: 5  Epoch: 467  Training loss = 2.5289  Validation loss = 5.5893  \n",
      "\n",
      "Fold: 5  Epoch: 468  Training loss = 2.5287  Validation loss = 5.5891  \n",
      "\n",
      "Fold: 5  Epoch: 469  Training loss = 2.5285  Validation loss = 5.5888  \n",
      "\n",
      "Fold: 5  Epoch: 470  Training loss = 2.5283  Validation loss = 5.5886  \n",
      "\n",
      "Fold: 5  Epoch: 471  Training loss = 2.5281  Validation loss = 5.5884  \n",
      "\n",
      "Fold: 5  Epoch: 472  Training loss = 2.5279  Validation loss = 5.5881  \n",
      "\n",
      "Fold: 5  Epoch: 473  Training loss = 2.5277  Validation loss = 5.5878  \n",
      "\n",
      "Fold: 5  Epoch: 474  Training loss = 2.5275  Validation loss = 5.5875  \n",
      "\n",
      "Fold: 5  Epoch: 475  Training loss = 2.5272  Validation loss = 5.5872  \n",
      "\n",
      "Fold: 5  Epoch: 476  Training loss = 2.5270  Validation loss = 5.5870  \n",
      "\n",
      "Fold: 5  Epoch: 477  Training loss = 2.5268  Validation loss = 5.5867  \n",
      "\n",
      "Fold: 5  Epoch: 478  Training loss = 2.5266  Validation loss = 5.5865  \n",
      "\n",
      "Fold: 5  Epoch: 479  Training loss = 2.5264  Validation loss = 5.5862  \n",
      "\n",
      "Fold: 5  Epoch: 480  Training loss = 2.5262  Validation loss = 5.5859  \n",
      "\n",
      "Fold: 5  Epoch: 481  Training loss = 2.5260  Validation loss = 5.5857  \n",
      "\n",
      "Fold: 5  Epoch: 482  Training loss = 2.5257  Validation loss = 5.5854  \n",
      "\n",
      "Fold: 5  Epoch: 483  Training loss = 2.5255  Validation loss = 5.5851  \n",
      "\n",
      "Fold: 5  Epoch: 484  Training loss = 2.5253  Validation loss = 5.5848  \n",
      "\n",
      "Fold: 5  Epoch: 485  Training loss = 2.5251  Validation loss = 5.5846  \n",
      "\n",
      "Fold: 5  Epoch: 486  Training loss = 2.5249  Validation loss = 5.5842  \n",
      "\n",
      "Fold: 5  Epoch: 487  Training loss = 2.5247  Validation loss = 5.5840  \n",
      "\n",
      "Fold: 5  Epoch: 488  Training loss = 2.5244  Validation loss = 5.5837  \n",
      "\n",
      "Fold: 5  Epoch: 489  Training loss = 2.5242  Validation loss = 5.5834  \n",
      "\n",
      "Fold: 5  Epoch: 490  Training loss = 2.5240  Validation loss = 5.5832  \n",
      "\n",
      "Fold: 5  Epoch: 491  Training loss = 2.5238  Validation loss = 5.5830  \n",
      "\n",
      "Fold: 5  Epoch: 492  Training loss = 2.5237  Validation loss = 5.5827  \n",
      "\n",
      "Fold: 5  Epoch: 493  Training loss = 2.5235  Validation loss = 5.5825  \n",
      "\n",
      "Fold: 5  Epoch: 494  Training loss = 2.5233  Validation loss = 5.5823  \n",
      "\n",
      "Fold: 5  Epoch: 495  Training loss = 2.5231  Validation loss = 5.5820  \n",
      "\n",
      "Fold: 5  Epoch: 496  Training loss = 2.5229  Validation loss = 5.5818  \n",
      "\n",
      "Fold: 5  Epoch: 497  Training loss = 2.5227  Validation loss = 5.5816  \n",
      "\n",
      "Fold: 5  Epoch: 498  Training loss = 2.5225  Validation loss = 5.5812  \n",
      "\n",
      "Fold: 5  Epoch: 499  Training loss = 2.5223  Validation loss = 5.5810  \n",
      "\n",
      "Fold: 5  Epoch: 500  Training loss = 2.5221  Validation loss = 5.5807  \n",
      "\n",
      "Check model:  Fold: 5  Optimal epoch: 500  \n",
      "\n",
      "Fold: 6  Epoch: 1  Training loss = 2.8729  Validation loss = 3.3093  \n",
      "\n",
      "Fold: 6  Epoch: 2  Training loss = 2.8726  Validation loss = 3.3090  \n",
      "\n",
      "Fold: 6  Epoch: 3  Training loss = 2.8724  Validation loss = 3.3086  \n",
      "\n",
      "Fold: 6  Epoch: 4  Training loss = 2.8721  Validation loss = 3.3082  \n",
      "\n",
      "Fold: 6  Epoch: 5  Training loss = 2.8719  Validation loss = 3.3080  \n",
      "\n",
      "Fold: 6  Epoch: 6  Training loss = 2.8717  Validation loss = 3.3077  \n",
      "\n",
      "Fold: 6  Epoch: 7  Training loss = 2.8714  Validation loss = 3.3073  \n",
      "\n",
      "Fold: 6  Epoch: 8  Training loss = 2.8712  Validation loss = 3.3070  \n",
      "\n",
      "Fold: 6  Epoch: 9  Training loss = 2.8709  Validation loss = 3.3066  \n",
      "\n",
      "Fold: 6  Epoch: 10  Training loss = 2.8707  Validation loss = 3.3063  \n",
      "\n",
      "Fold: 6  Epoch: 11  Training loss = 2.8704  Validation loss = 3.3059  \n",
      "\n",
      "Fold: 6  Epoch: 12  Training loss = 2.8702  Validation loss = 3.3056  \n",
      "\n",
      "Fold: 6  Epoch: 13  Training loss = 2.8700  Validation loss = 3.3053  \n",
      "\n",
      "Fold: 6  Epoch: 14  Training loss = 2.8697  Validation loss = 3.3050  \n",
      "\n",
      "Fold: 6  Epoch: 15  Training loss = 2.8695  Validation loss = 3.3047  \n",
      "\n",
      "Fold: 6  Epoch: 16  Training loss = 2.8693  Validation loss = 3.3044  \n",
      "\n",
      "Fold: 6  Epoch: 17  Training loss = 2.8690  Validation loss = 3.3041  \n",
      "\n",
      "Fold: 6  Epoch: 18  Training loss = 2.8688  Validation loss = 3.3037  \n",
      "\n",
      "Fold: 6  Epoch: 19  Training loss = 2.8685  Validation loss = 3.3033  \n",
      "\n",
      "Fold: 6  Epoch: 20  Training loss = 2.8682  Validation loss = 3.3029  \n",
      "\n",
      "Fold: 6  Epoch: 21  Training loss = 2.8679  Validation loss = 3.3025  \n",
      "\n",
      "Fold: 6  Epoch: 22  Training loss = 2.8677  Validation loss = 3.3021  \n",
      "\n",
      "Fold: 6  Epoch: 23  Training loss = 2.8674  Validation loss = 3.3018  \n",
      "\n",
      "Fold: 6  Epoch: 24  Training loss = 2.8672  Validation loss = 3.3015  \n",
      "\n",
      "Fold: 6  Epoch: 25  Training loss = 2.8669  Validation loss = 3.3011  \n",
      "\n",
      "Fold: 6  Epoch: 26  Training loss = 2.8667  Validation loss = 3.3008  \n",
      "\n",
      "Fold: 6  Epoch: 27  Training loss = 2.8664  Validation loss = 3.3004  \n",
      "\n",
      "Fold: 6  Epoch: 28  Training loss = 2.8661  Validation loss = 3.3000  \n",
      "\n",
      "Fold: 6  Epoch: 29  Training loss = 2.8658  Validation loss = 3.2996  \n",
      "\n",
      "Fold: 6  Epoch: 30  Training loss = 2.8656  Validation loss = 3.2992  \n",
      "\n",
      "Fold: 6  Epoch: 31  Training loss = 2.8653  Validation loss = 3.2988  \n",
      "\n",
      "Fold: 6  Epoch: 32  Training loss = 2.8650  Validation loss = 3.2985  \n",
      "\n",
      "Fold: 6  Epoch: 33  Training loss = 2.8648  Validation loss = 3.2982  \n",
      "\n",
      "Fold: 6  Epoch: 34  Training loss = 2.8646  Validation loss = 3.2979  \n",
      "\n",
      "Fold: 6  Epoch: 35  Training loss = 2.8643  Validation loss = 3.2976  \n",
      "\n",
      "Fold: 6  Epoch: 36  Training loss = 2.8641  Validation loss = 3.2972  \n",
      "\n",
      "Fold: 6  Epoch: 37  Training loss = 2.8638  Validation loss = 3.2968  \n",
      "\n",
      "Fold: 6  Epoch: 38  Training loss = 2.8636  Validation loss = 3.2965  \n",
      "\n",
      "Fold: 6  Epoch: 39  Training loss = 2.8633  Validation loss = 3.2962  \n",
      "\n",
      "Fold: 6  Epoch: 40  Training loss = 2.8631  Validation loss = 3.2957  \n",
      "\n",
      "Fold: 6  Epoch: 41  Training loss = 2.8628  Validation loss = 3.2954  \n",
      "\n",
      "Fold: 6  Epoch: 42  Training loss = 2.8626  Validation loss = 3.2951  \n",
      "\n",
      "Fold: 6  Epoch: 43  Training loss = 2.8623  Validation loss = 3.2948  \n",
      "\n",
      "Fold: 6  Epoch: 44  Training loss = 2.8621  Validation loss = 3.2944  \n",
      "\n",
      "Fold: 6  Epoch: 45  Training loss = 2.8618  Validation loss = 3.2941  \n",
      "\n",
      "Fold: 6  Epoch: 46  Training loss = 2.8616  Validation loss = 3.2937  \n",
      "\n",
      "Fold: 6  Epoch: 47  Training loss = 2.8613  Validation loss = 3.2933  \n",
      "\n",
      "Fold: 6  Epoch: 48  Training loss = 2.8610  Validation loss = 3.2929  \n",
      "\n",
      "Fold: 6  Epoch: 49  Training loss = 2.8608  Validation loss = 3.2926  \n",
      "\n",
      "Fold: 6  Epoch: 50  Training loss = 2.8605  Validation loss = 3.2922  \n",
      "\n",
      "Fold: 6  Epoch: 51  Training loss = 2.8602  Validation loss = 3.2919  \n",
      "\n",
      "Fold: 6  Epoch: 52  Training loss = 2.8600  Validation loss = 3.2915  \n",
      "\n",
      "Fold: 6  Epoch: 53  Training loss = 2.8597  Validation loss = 3.2912  \n",
      "\n",
      "Fold: 6  Epoch: 54  Training loss = 2.8595  Validation loss = 3.2908  \n",
      "\n",
      "Fold: 6  Epoch: 55  Training loss = 2.8592  Validation loss = 3.2905  \n",
      "\n",
      "Fold: 6  Epoch: 56  Training loss = 2.8590  Validation loss = 3.2901  \n",
      "\n",
      "Fold: 6  Epoch: 57  Training loss = 2.8587  Validation loss = 3.2897  \n",
      "\n",
      "Fold: 6  Epoch: 58  Training loss = 2.8585  Validation loss = 3.2894  \n",
      "\n",
      "Fold: 6  Epoch: 59  Training loss = 2.8582  Validation loss = 3.2891  \n",
      "\n",
      "Fold: 6  Epoch: 60  Training loss = 2.8579  Validation loss = 3.2887  \n",
      "\n",
      "Fold: 6  Epoch: 61  Training loss = 2.8577  Validation loss = 3.2884  \n",
      "\n",
      "Fold: 6  Epoch: 62  Training loss = 2.8574  Validation loss = 3.2880  \n",
      "\n",
      "Fold: 6  Epoch: 63  Training loss = 2.8572  Validation loss = 3.2877  \n",
      "\n",
      "Fold: 6  Epoch: 64  Training loss = 2.8569  Validation loss = 3.2873  \n",
      "\n",
      "Fold: 6  Epoch: 65  Training loss = 2.8567  Validation loss = 3.2870  \n",
      "\n",
      "Fold: 6  Epoch: 66  Training loss = 2.8564  Validation loss = 3.2866  \n",
      "\n",
      "Fold: 6  Epoch: 67  Training loss = 2.8562  Validation loss = 3.2863  \n",
      "\n",
      "Fold: 6  Epoch: 68  Training loss = 2.8560  Validation loss = 3.2860  \n",
      "\n",
      "Fold: 6  Epoch: 69  Training loss = 2.8557  Validation loss = 3.2857  \n",
      "\n",
      "Fold: 6  Epoch: 70  Training loss = 2.8554  Validation loss = 3.2853  \n",
      "\n",
      "Fold: 6  Epoch: 71  Training loss = 2.8552  Validation loss = 3.2850  \n",
      "\n",
      "Fold: 6  Epoch: 72  Training loss = 2.8549  Validation loss = 3.2846  \n",
      "\n",
      "Fold: 6  Epoch: 73  Training loss = 2.8547  Validation loss = 3.2843  \n",
      "\n",
      "Fold: 6  Epoch: 74  Training loss = 2.8545  Validation loss = 3.2840  \n",
      "\n",
      "Fold: 6  Epoch: 75  Training loss = 2.8543  Validation loss = 3.2837  \n",
      "\n",
      "Fold: 6  Epoch: 76  Training loss = 2.8540  Validation loss = 3.2834  \n",
      "\n",
      "Fold: 6  Epoch: 77  Training loss = 2.8538  Validation loss = 3.2830  \n",
      "\n",
      "Fold: 6  Epoch: 78  Training loss = 2.8536  Validation loss = 3.2827  \n",
      "\n",
      "Fold: 6  Epoch: 79  Training loss = 2.8533  Validation loss = 3.2824  \n",
      "\n",
      "Fold: 6  Epoch: 80  Training loss = 2.8531  Validation loss = 3.2821  \n",
      "\n",
      "Fold: 6  Epoch: 81  Training loss = 2.8528  Validation loss = 3.2817  \n",
      "\n",
      "Fold: 6  Epoch: 82  Training loss = 2.8526  Validation loss = 3.2814  \n",
      "\n",
      "Fold: 6  Epoch: 83  Training loss = 2.8524  Validation loss = 3.2811  \n",
      "\n",
      "Fold: 6  Epoch: 84  Training loss = 2.8522  Validation loss = 3.2808  \n",
      "\n",
      "Fold: 6  Epoch: 85  Training loss = 2.8519  Validation loss = 3.2804  \n",
      "\n",
      "Fold: 6  Epoch: 86  Training loss = 2.8516  Validation loss = 3.2801  \n",
      "\n",
      "Fold: 6  Epoch: 87  Training loss = 2.8514  Validation loss = 3.2798  \n",
      "\n",
      "Fold: 6  Epoch: 88  Training loss = 2.8512  Validation loss = 3.2795  \n",
      "\n",
      "Fold: 6  Epoch: 89  Training loss = 2.8509  Validation loss = 3.2791  \n",
      "\n",
      "Fold: 6  Epoch: 90  Training loss = 2.8507  Validation loss = 3.2788  \n",
      "\n",
      "Fold: 6  Epoch: 91  Training loss = 2.8505  Validation loss = 3.2785  \n",
      "\n",
      "Fold: 6  Epoch: 92  Training loss = 2.8502  Validation loss = 3.2782  \n",
      "\n",
      "Fold: 6  Epoch: 93  Training loss = 2.8500  Validation loss = 3.2779  \n",
      "\n",
      "Fold: 6  Epoch: 94  Training loss = 2.8498  Validation loss = 3.2775  \n",
      "\n",
      "Fold: 6  Epoch: 95  Training loss = 2.8495  Validation loss = 3.2771  \n",
      "\n",
      "Fold: 6  Epoch: 96  Training loss = 2.8492  Validation loss = 3.2768  \n",
      "\n",
      "Fold: 6  Epoch: 97  Training loss = 2.8490  Validation loss = 3.2765  \n",
      "\n",
      "Fold: 6  Epoch: 98  Training loss = 2.8487  Validation loss = 3.2760  \n",
      "\n",
      "Fold: 6  Epoch: 99  Training loss = 2.8484  Validation loss = 3.2757  \n",
      "\n",
      "Fold: 6  Epoch: 100  Training loss = 2.8482  Validation loss = 3.2753  \n",
      "\n",
      "Fold: 6  Epoch: 101  Training loss = 2.8480  Validation loss = 3.2750  \n",
      "\n",
      "Fold: 6  Epoch: 102  Training loss = 2.8477  Validation loss = 3.2747  \n",
      "\n",
      "Fold: 6  Epoch: 103  Training loss = 2.8475  Validation loss = 3.2744  \n",
      "\n",
      "Fold: 6  Epoch: 104  Training loss = 2.8473  Validation loss = 3.2741  \n",
      "\n",
      "Fold: 6  Epoch: 105  Training loss = 2.8470  Validation loss = 3.2738  \n",
      "\n",
      "Fold: 6  Epoch: 106  Training loss = 2.8468  Validation loss = 3.2734  \n",
      "\n",
      "Fold: 6  Epoch: 107  Training loss = 2.8465  Validation loss = 3.2731  \n",
      "\n",
      "Fold: 6  Epoch: 108  Training loss = 2.8463  Validation loss = 3.2728  \n",
      "\n",
      "Fold: 6  Epoch: 109  Training loss = 2.8460  Validation loss = 3.2724  \n",
      "\n",
      "Fold: 6  Epoch: 110  Training loss = 2.8458  Validation loss = 3.2721  \n",
      "\n",
      "Fold: 6  Epoch: 111  Training loss = 2.8455  Validation loss = 3.2716  \n",
      "\n",
      "Fold: 6  Epoch: 112  Training loss = 2.8453  Validation loss = 3.2713  \n",
      "\n",
      "Fold: 6  Epoch: 113  Training loss = 2.8450  Validation loss = 3.2709  \n",
      "\n",
      "Fold: 6  Epoch: 114  Training loss = 2.8448  Validation loss = 3.2706  \n",
      "\n",
      "Fold: 6  Epoch: 115  Training loss = 2.8445  Validation loss = 3.2703  \n",
      "\n",
      "Fold: 6  Epoch: 116  Training loss = 2.8443  Validation loss = 3.2700  \n",
      "\n",
      "Fold: 6  Epoch: 117  Training loss = 2.8441  Validation loss = 3.2696  \n",
      "\n",
      "Fold: 6  Epoch: 118  Training loss = 2.8439  Validation loss = 3.2694  \n",
      "\n",
      "Fold: 6  Epoch: 119  Training loss = 2.8437  Validation loss = 3.2691  \n",
      "\n",
      "Fold: 6  Epoch: 120  Training loss = 2.8434  Validation loss = 3.2688  \n",
      "\n",
      "Fold: 6  Epoch: 121  Training loss = 2.8431  Validation loss = 3.2684  \n",
      "\n",
      "Fold: 6  Epoch: 122  Training loss = 2.8429  Validation loss = 3.2681  \n",
      "\n",
      "Fold: 6  Epoch: 123  Training loss = 2.8427  Validation loss = 3.2678  \n",
      "\n",
      "Fold: 6  Epoch: 124  Training loss = 2.8424  Validation loss = 3.2674  \n",
      "\n",
      "Fold: 6  Epoch: 125  Training loss = 2.8422  Validation loss = 3.2670  \n",
      "\n",
      "Fold: 6  Epoch: 126  Training loss = 2.8419  Validation loss = 3.2667  \n",
      "\n",
      "Fold: 6  Epoch: 127  Training loss = 2.8417  Validation loss = 3.2664  \n",
      "\n",
      "Fold: 6  Epoch: 128  Training loss = 2.8415  Validation loss = 3.2661  \n",
      "\n",
      "Fold: 6  Epoch: 129  Training loss = 2.8412  Validation loss = 3.2658  \n",
      "\n",
      "Fold: 6  Epoch: 130  Training loss = 2.8410  Validation loss = 3.2654  \n",
      "\n",
      "Fold: 6  Epoch: 131  Training loss = 2.8408  Validation loss = 3.2651  \n",
      "\n",
      "Fold: 6  Epoch: 132  Training loss = 2.8405  Validation loss = 3.2648  \n",
      "\n",
      "Fold: 6  Epoch: 133  Training loss = 2.8403  Validation loss = 3.2644  \n",
      "\n",
      "Fold: 6  Epoch: 134  Training loss = 2.8400  Validation loss = 3.2641  \n",
      "\n",
      "Fold: 6  Epoch: 135  Training loss = 2.8398  Validation loss = 3.2637  \n",
      "\n",
      "Fold: 6  Epoch: 136  Training loss = 2.8395  Validation loss = 3.2634  \n",
      "\n",
      "Fold: 6  Epoch: 137  Training loss = 2.8393  Validation loss = 3.2630  \n",
      "\n",
      "Fold: 6  Epoch: 138  Training loss = 2.8390  Validation loss = 3.2627  \n",
      "\n",
      "Fold: 6  Epoch: 139  Training loss = 2.8387  Validation loss = 3.2623  \n",
      "\n",
      "Fold: 6  Epoch: 140  Training loss = 2.8385  Validation loss = 3.2620  \n",
      "\n",
      "Fold: 6  Epoch: 141  Training loss = 2.8383  Validation loss = 3.2616  \n",
      "\n",
      "Fold: 6  Epoch: 142  Training loss = 2.8380  Validation loss = 3.2613  \n",
      "\n",
      "Fold: 6  Epoch: 143  Training loss = 2.8378  Validation loss = 3.2610  \n",
      "\n",
      "Fold: 6  Epoch: 144  Training loss = 2.8376  Validation loss = 3.2607  \n",
      "\n",
      "Fold: 6  Epoch: 145  Training loss = 2.8374  Validation loss = 3.2604  \n",
      "\n",
      "Fold: 6  Epoch: 146  Training loss = 2.8371  Validation loss = 3.2600  \n",
      "\n",
      "Fold: 6  Epoch: 147  Training loss = 2.8369  Validation loss = 3.2597  \n",
      "\n",
      "Fold: 6  Epoch: 148  Training loss = 2.8366  Validation loss = 3.2594  \n",
      "\n",
      "Fold: 6  Epoch: 149  Training loss = 2.8363  Validation loss = 3.2590  \n",
      "\n",
      "Fold: 6  Epoch: 150  Training loss = 2.8361  Validation loss = 3.2587  \n",
      "\n",
      "Fold: 6  Epoch: 151  Training loss = 2.8358  Validation loss = 3.2583  \n",
      "\n",
      "Fold: 6  Epoch: 152  Training loss = 2.8357  Validation loss = 3.2580  \n",
      "\n",
      "Fold: 6  Epoch: 153  Training loss = 2.8354  Validation loss = 3.2577  \n",
      "\n",
      "Fold: 6  Epoch: 154  Training loss = 2.8352  Validation loss = 3.2574  \n",
      "\n",
      "Fold: 6  Epoch: 155  Training loss = 2.8350  Validation loss = 3.2571  \n",
      "\n",
      "Fold: 6  Epoch: 156  Training loss = 2.8348  Validation loss = 3.2568  \n",
      "\n",
      "Fold: 6  Epoch: 157  Training loss = 2.8345  Validation loss = 3.2565  \n",
      "\n",
      "Fold: 6  Epoch: 158  Training loss = 2.8343  Validation loss = 3.2561  \n",
      "\n",
      "Fold: 6  Epoch: 159  Training loss = 2.8340  Validation loss = 3.2558  \n",
      "\n",
      "Fold: 6  Epoch: 160  Training loss = 2.8338  Validation loss = 3.2554  \n",
      "\n",
      "Fold: 6  Epoch: 161  Training loss = 2.8335  Validation loss = 3.2551  \n",
      "\n",
      "Fold: 6  Epoch: 162  Training loss = 2.8333  Validation loss = 3.2548  \n",
      "\n",
      "Fold: 6  Epoch: 163  Training loss = 2.8331  Validation loss = 3.2545  \n",
      "\n",
      "Fold: 6  Epoch: 164  Training loss = 2.8328  Validation loss = 3.2541  \n",
      "\n",
      "Fold: 6  Epoch: 165  Training loss = 2.8326  Validation loss = 3.2538  \n",
      "\n",
      "Fold: 6  Epoch: 166  Training loss = 2.8324  Validation loss = 3.2535  \n",
      "\n",
      "Fold: 6  Epoch: 167  Training loss = 2.8321  Validation loss = 3.2531  \n",
      "\n",
      "Fold: 6  Epoch: 168  Training loss = 2.8318  Validation loss = 3.2527  \n",
      "\n",
      "Fold: 6  Epoch: 169  Training loss = 2.8316  Validation loss = 3.2525  \n",
      "\n",
      "Fold: 6  Epoch: 170  Training loss = 2.8314  Validation loss = 3.2522  \n",
      "\n",
      "Fold: 6  Epoch: 171  Training loss = 2.8312  Validation loss = 3.2518  \n",
      "\n",
      "Fold: 6  Epoch: 172  Training loss = 2.8309  Validation loss = 3.2515  \n",
      "\n",
      "Fold: 6  Epoch: 173  Training loss = 2.8307  Validation loss = 3.2512  \n",
      "\n",
      "Fold: 6  Epoch: 174  Training loss = 2.8305  Validation loss = 3.2509  \n",
      "\n",
      "Fold: 6  Epoch: 175  Training loss = 2.8302  Validation loss = 3.2505  \n",
      "\n",
      "Fold: 6  Epoch: 176  Training loss = 2.8300  Validation loss = 3.2502  \n",
      "\n",
      "Fold: 6  Epoch: 177  Training loss = 2.8298  Validation loss = 3.2499  \n",
      "\n",
      "Fold: 6  Epoch: 178  Training loss = 2.8296  Validation loss = 3.2496  \n",
      "\n",
      "Fold: 6  Epoch: 179  Training loss = 2.8294  Validation loss = 3.2493  \n",
      "\n",
      "Fold: 6  Epoch: 180  Training loss = 2.8291  Validation loss = 3.2490  \n",
      "\n",
      "Fold: 6  Epoch: 181  Training loss = 2.8289  Validation loss = 3.2486  \n",
      "\n",
      "Fold: 6  Epoch: 182  Training loss = 2.8286  Validation loss = 3.2482  \n",
      "\n",
      "Fold: 6  Epoch: 183  Training loss = 2.8284  Validation loss = 3.2479  \n",
      "\n",
      "Fold: 6  Epoch: 184  Training loss = 2.8282  Validation loss = 3.2476  \n",
      "\n",
      "Fold: 6  Epoch: 185  Training loss = 2.8279  Validation loss = 3.2473  \n",
      "\n",
      "Fold: 6  Epoch: 186  Training loss = 2.8277  Validation loss = 3.2470  \n",
      "\n",
      "Fold: 6  Epoch: 187  Training loss = 2.8275  Validation loss = 3.2466  \n",
      "\n",
      "Fold: 6  Epoch: 188  Training loss = 2.8272  Validation loss = 3.2462  \n",
      "\n",
      "Fold: 6  Epoch: 189  Training loss = 2.8270  Validation loss = 3.2459  \n",
      "\n",
      "Fold: 6  Epoch: 190  Training loss = 2.8268  Validation loss = 3.2456  \n",
      "\n",
      "Fold: 6  Epoch: 191  Training loss = 2.8265  Validation loss = 3.2453  \n",
      "\n",
      "Fold: 6  Epoch: 192  Training loss = 2.8263  Validation loss = 3.2450  \n",
      "\n",
      "Fold: 6  Epoch: 193  Training loss = 2.8261  Validation loss = 3.2447  \n",
      "\n",
      "Fold: 6  Epoch: 194  Training loss = 2.8259  Validation loss = 3.2443  \n",
      "\n",
      "Fold: 6  Epoch: 195  Training loss = 2.8256  Validation loss = 3.2440  \n",
      "\n",
      "Fold: 6  Epoch: 196  Training loss = 2.8253  Validation loss = 3.2435  \n",
      "\n",
      "Fold: 6  Epoch: 197  Training loss = 2.8251  Validation loss = 3.2433  \n",
      "\n",
      "Fold: 6  Epoch: 198  Training loss = 2.8249  Validation loss = 3.2430  \n",
      "\n",
      "Fold: 6  Epoch: 199  Training loss = 2.8247  Validation loss = 3.2427  \n",
      "\n",
      "Fold: 6  Epoch: 200  Training loss = 2.8244  Validation loss = 3.2423  \n",
      "\n",
      "Fold: 6  Epoch: 201  Training loss = 2.8242  Validation loss = 3.2419  \n",
      "\n",
      "Fold: 6  Epoch: 202  Training loss = 2.8240  Validation loss = 3.2417  \n",
      "\n",
      "Fold: 6  Epoch: 203  Training loss = 2.8237  Validation loss = 3.2413  \n",
      "\n",
      "Fold: 6  Epoch: 204  Training loss = 2.8235  Validation loss = 3.2411  \n",
      "\n",
      "Fold: 6  Epoch: 205  Training loss = 2.8233  Validation loss = 3.2408  \n",
      "\n",
      "Fold: 6  Epoch: 206  Training loss = 2.8231  Validation loss = 3.2404  \n",
      "\n",
      "Fold: 6  Epoch: 207  Training loss = 2.8229  Validation loss = 3.2402  \n",
      "\n",
      "Fold: 6  Epoch: 208  Training loss = 2.8226  Validation loss = 3.2398  \n",
      "\n",
      "Fold: 6  Epoch: 209  Training loss = 2.8225  Validation loss = 3.2396  \n",
      "\n",
      "Fold: 6  Epoch: 210  Training loss = 2.8222  Validation loss = 3.2393  \n",
      "\n",
      "Fold: 6  Epoch: 211  Training loss = 2.8220  Validation loss = 3.2390  \n",
      "\n",
      "Fold: 6  Epoch: 212  Training loss = 2.8218  Validation loss = 3.2388  \n",
      "\n",
      "Fold: 6  Epoch: 213  Training loss = 2.8216  Validation loss = 3.2384  \n",
      "\n",
      "Fold: 6  Epoch: 214  Training loss = 2.8214  Validation loss = 3.2381  \n",
      "\n",
      "Fold: 6  Epoch: 215  Training loss = 2.8211  Validation loss = 3.2378  \n",
      "\n",
      "Fold: 6  Epoch: 216  Training loss = 2.8209  Validation loss = 3.2374  \n",
      "\n",
      "Fold: 6  Epoch: 217  Training loss = 2.8207  Validation loss = 3.2371  \n",
      "\n",
      "Fold: 6  Epoch: 218  Training loss = 2.8204  Validation loss = 3.2368  \n",
      "\n",
      "Fold: 6  Epoch: 219  Training loss = 2.8202  Validation loss = 3.2365  \n",
      "\n",
      "Fold: 6  Epoch: 220  Training loss = 2.8200  Validation loss = 3.2363  \n",
      "\n",
      "Fold: 6  Epoch: 221  Training loss = 2.8198  Validation loss = 3.2359  \n",
      "\n",
      "Fold: 6  Epoch: 222  Training loss = 2.8196  Validation loss = 3.2356  \n",
      "\n",
      "Fold: 6  Epoch: 223  Training loss = 2.8193  Validation loss = 3.2353  \n",
      "\n",
      "Fold: 6  Epoch: 224  Training loss = 2.8191  Validation loss = 3.2349  \n",
      "\n",
      "Fold: 6  Epoch: 225  Training loss = 2.8189  Validation loss = 3.2347  \n",
      "\n",
      "Fold: 6  Epoch: 226  Training loss = 2.8187  Validation loss = 3.2344  \n",
      "\n",
      "Fold: 6  Epoch: 227  Training loss = 2.8184  Validation loss = 3.2340  \n",
      "\n",
      "Fold: 6  Epoch: 228  Training loss = 2.8182  Validation loss = 3.2337  \n",
      "\n",
      "Fold: 6  Epoch: 229  Training loss = 2.8180  Validation loss = 3.2334  \n",
      "\n",
      "Fold: 6  Epoch: 230  Training loss = 2.8177  Validation loss = 3.2331  \n",
      "\n",
      "Fold: 6  Epoch: 231  Training loss = 2.8175  Validation loss = 3.2327  \n",
      "\n",
      "Fold: 6  Epoch: 232  Training loss = 2.8172  Validation loss = 3.2324  \n",
      "\n",
      "Fold: 6  Epoch: 233  Training loss = 2.8170  Validation loss = 3.2320  \n",
      "\n",
      "Fold: 6  Epoch: 234  Training loss = 2.8168  Validation loss = 3.2317  \n",
      "\n",
      "Fold: 6  Epoch: 235  Training loss = 2.8166  Validation loss = 3.2314  \n",
      "\n",
      "Fold: 6  Epoch: 236  Training loss = 2.8163  Validation loss = 3.2310  \n",
      "\n",
      "Fold: 6  Epoch: 237  Training loss = 2.8161  Validation loss = 3.2307  \n",
      "\n",
      "Fold: 6  Epoch: 238  Training loss = 2.8159  Validation loss = 3.2304  \n",
      "\n",
      "Fold: 6  Epoch: 239  Training loss = 2.8156  Validation loss = 3.2301  \n",
      "\n",
      "Fold: 6  Epoch: 240  Training loss = 2.8154  Validation loss = 3.2297  \n",
      "\n",
      "Fold: 6  Epoch: 241  Training loss = 2.8151  Validation loss = 3.2293  \n",
      "\n",
      "Fold: 6  Epoch: 242  Training loss = 2.8149  Validation loss = 3.2290  \n",
      "\n",
      "Fold: 6  Epoch: 243  Training loss = 2.8146  Validation loss = 3.2287  \n",
      "\n",
      "Fold: 6  Epoch: 244  Training loss = 2.8144  Validation loss = 3.2283  \n",
      "\n",
      "Fold: 6  Epoch: 245  Training loss = 2.8142  Validation loss = 3.2280  \n",
      "\n",
      "Fold: 6  Epoch: 246  Training loss = 2.8139  Validation loss = 3.2277  \n",
      "\n",
      "Fold: 6  Epoch: 247  Training loss = 2.8137  Validation loss = 3.2273  \n",
      "\n",
      "Fold: 6  Epoch: 248  Training loss = 2.8135  Validation loss = 3.2270  \n",
      "\n",
      "Fold: 6  Epoch: 249  Training loss = 2.8133  Validation loss = 3.2268  \n",
      "\n",
      "Fold: 6  Epoch: 250  Training loss = 2.8131  Validation loss = 3.2265  \n",
      "\n",
      "Fold: 6  Epoch: 251  Training loss = 2.8128  Validation loss = 3.2261  \n",
      "\n",
      "Fold: 6  Epoch: 252  Training loss = 2.8126  Validation loss = 3.2258  \n",
      "\n",
      "Fold: 6  Epoch: 253  Training loss = 2.8123  Validation loss = 3.2254  \n",
      "\n",
      "Fold: 6  Epoch: 254  Training loss = 2.8121  Validation loss = 3.2250  \n",
      "\n",
      "Fold: 6  Epoch: 255  Training loss = 2.8118  Validation loss = 3.2246  \n",
      "\n",
      "Fold: 6  Epoch: 256  Training loss = 2.8116  Validation loss = 3.2244  \n",
      "\n",
      "Fold: 6  Epoch: 257  Training loss = 2.8114  Validation loss = 3.2240  \n",
      "\n",
      "Fold: 6  Epoch: 258  Training loss = 2.8112  Validation loss = 3.2238  \n",
      "\n",
      "Fold: 6  Epoch: 259  Training loss = 2.8110  Validation loss = 3.2234  \n",
      "\n",
      "Fold: 6  Epoch: 260  Training loss = 2.8107  Validation loss = 3.2231  \n",
      "\n",
      "Fold: 6  Epoch: 261  Training loss = 2.8105  Validation loss = 3.2228  \n",
      "\n",
      "Fold: 6  Epoch: 262  Training loss = 2.8102  Validation loss = 3.2224  \n",
      "\n",
      "Fold: 6  Epoch: 263  Training loss = 2.8100  Validation loss = 3.2221  \n",
      "\n",
      "Fold: 6  Epoch: 264  Training loss = 2.8098  Validation loss = 3.2218  \n",
      "\n",
      "Fold: 6  Epoch: 265  Training loss = 2.8096  Validation loss = 3.2215  \n",
      "\n",
      "Fold: 6  Epoch: 266  Training loss = 2.8094  Validation loss = 3.2212  \n",
      "\n",
      "Fold: 6  Epoch: 267  Training loss = 2.8091  Validation loss = 3.2208  \n",
      "\n",
      "Fold: 6  Epoch: 268  Training loss = 2.8089  Validation loss = 3.2205  \n",
      "\n",
      "Fold: 6  Epoch: 269  Training loss = 2.8087  Validation loss = 3.2202  \n",
      "\n",
      "Fold: 6  Epoch: 270  Training loss = 2.8084  Validation loss = 3.2199  \n",
      "\n",
      "Fold: 6  Epoch: 271  Training loss = 2.8082  Validation loss = 3.2196  \n",
      "\n",
      "Fold: 6  Epoch: 272  Training loss = 2.8080  Validation loss = 3.2193  \n",
      "\n",
      "Fold: 6  Epoch: 273  Training loss = 2.8077  Validation loss = 3.2189  \n",
      "\n",
      "Fold: 6  Epoch: 274  Training loss = 2.8075  Validation loss = 3.2186  \n",
      "\n",
      "Fold: 6  Epoch: 275  Training loss = 2.8073  Validation loss = 3.2183  \n",
      "\n",
      "Fold: 6  Epoch: 276  Training loss = 2.8070  Validation loss = 3.2180  \n",
      "\n",
      "Fold: 6  Epoch: 277  Training loss = 2.8068  Validation loss = 3.2177  \n",
      "\n",
      "Fold: 6  Epoch: 278  Training loss = 2.8066  Validation loss = 3.2173  \n",
      "\n",
      "Fold: 6  Epoch: 279  Training loss = 2.8063  Validation loss = 3.2169  \n",
      "\n",
      "Fold: 6  Epoch: 280  Training loss = 2.8061  Validation loss = 3.2166  \n",
      "\n",
      "Fold: 6  Epoch: 281  Training loss = 2.8059  Validation loss = 3.2163  \n",
      "\n",
      "Fold: 6  Epoch: 282  Training loss = 2.8057  Validation loss = 3.2160  \n",
      "\n",
      "Fold: 6  Epoch: 283  Training loss = 2.8055  Validation loss = 3.2157  \n",
      "\n",
      "Fold: 6  Epoch: 284  Training loss = 2.8053  Validation loss = 3.2154  \n",
      "\n",
      "Fold: 6  Epoch: 285  Training loss = 2.8051  Validation loss = 3.2151  \n",
      "\n",
      "Fold: 6  Epoch: 286  Training loss = 2.8048  Validation loss = 3.2148  \n",
      "\n",
      "Fold: 6  Epoch: 287  Training loss = 2.8046  Validation loss = 3.2145  \n",
      "\n",
      "Fold: 6  Epoch: 288  Training loss = 2.8044  Validation loss = 3.2142  \n",
      "\n",
      "Fold: 6  Epoch: 289  Training loss = 2.8042  Validation loss = 3.2139  \n",
      "\n",
      "Fold: 6  Epoch: 290  Training loss = 2.8040  Validation loss = 3.2136  \n",
      "\n",
      "Fold: 6  Epoch: 291  Training loss = 2.8038  Validation loss = 3.2133  \n",
      "\n",
      "Fold: 6  Epoch: 292  Training loss = 2.8036  Validation loss = 3.2130  \n",
      "\n",
      "Fold: 6  Epoch: 293  Training loss = 2.8033  Validation loss = 3.2127  \n",
      "\n",
      "Fold: 6  Epoch: 294  Training loss = 2.8031  Validation loss = 3.2124  \n",
      "\n",
      "Fold: 6  Epoch: 295  Training loss = 2.8029  Validation loss = 3.2121  \n",
      "\n",
      "Fold: 6  Epoch: 296  Training loss = 2.8027  Validation loss = 3.2118  \n",
      "\n",
      "Fold: 6  Epoch: 297  Training loss = 2.8025  Validation loss = 3.2115  \n",
      "\n",
      "Fold: 6  Epoch: 298  Training loss = 2.8023  Validation loss = 3.2112  \n",
      "\n",
      "Fold: 6  Epoch: 299  Training loss = 2.8020  Validation loss = 3.2108  \n",
      "\n",
      "Fold: 6  Epoch: 300  Training loss = 2.8018  Validation loss = 3.2105  \n",
      "\n",
      "Fold: 6  Epoch: 301  Training loss = 2.8016  Validation loss = 3.2102  \n",
      "\n",
      "Fold: 6  Epoch: 302  Training loss = 2.8014  Validation loss = 3.2099  \n",
      "\n",
      "Fold: 6  Epoch: 303  Training loss = 2.8012  Validation loss = 3.2096  \n",
      "\n",
      "Fold: 6  Epoch: 304  Training loss = 2.8010  Validation loss = 3.2093  \n",
      "\n",
      "Fold: 6  Epoch: 305  Training loss = 2.8007  Validation loss = 3.2089  \n",
      "\n",
      "Fold: 6  Epoch: 306  Training loss = 2.8004  Validation loss = 3.2086  \n",
      "\n",
      "Fold: 6  Epoch: 307  Training loss = 2.8002  Validation loss = 3.2083  \n",
      "\n",
      "Fold: 6  Epoch: 308  Training loss = 2.8000  Validation loss = 3.2080  \n",
      "\n",
      "Fold: 6  Epoch: 309  Training loss = 2.7997  Validation loss = 3.2076  \n",
      "\n",
      "Fold: 6  Epoch: 310  Training loss = 2.7995  Validation loss = 3.2074  \n",
      "\n",
      "Fold: 6  Epoch: 311  Training loss = 2.7994  Validation loss = 3.2071  \n",
      "\n",
      "Fold: 6  Epoch: 312  Training loss = 2.7991  Validation loss = 3.2068  \n",
      "\n",
      "Fold: 6  Epoch: 313  Training loss = 2.7989  Validation loss = 3.2065  \n",
      "\n",
      "Fold: 6  Epoch: 314  Training loss = 2.7987  Validation loss = 3.2062  \n",
      "\n",
      "Fold: 6  Epoch: 315  Training loss = 2.7985  Validation loss = 3.2059  \n",
      "\n",
      "Fold: 6  Epoch: 316  Training loss = 2.7982  Validation loss = 3.2055  \n",
      "\n",
      "Fold: 6  Epoch: 317  Training loss = 2.7980  Validation loss = 3.2052  \n",
      "\n",
      "Fold: 6  Epoch: 318  Training loss = 2.7977  Validation loss = 3.2049  \n",
      "\n",
      "Fold: 6  Epoch: 319  Training loss = 2.7975  Validation loss = 3.2046  \n",
      "\n",
      "Fold: 6  Epoch: 320  Training loss = 2.7973  Validation loss = 3.2043  \n",
      "\n",
      "Fold: 6  Epoch: 321  Training loss = 2.7972  Validation loss = 3.2040  \n",
      "\n",
      "Fold: 6  Epoch: 322  Training loss = 2.7969  Validation loss = 3.2037  \n",
      "\n",
      "Fold: 6  Epoch: 323  Training loss = 2.7967  Validation loss = 3.2034  \n",
      "\n",
      "Fold: 6  Epoch: 324  Training loss = 2.7965  Validation loss = 3.2031  \n",
      "\n",
      "Fold: 6  Epoch: 325  Training loss = 2.7963  Validation loss = 3.2028  \n",
      "\n",
      "Fold: 6  Epoch: 326  Training loss = 2.7960  Validation loss = 3.2024  \n",
      "\n",
      "Fold: 6  Epoch: 327  Training loss = 2.7958  Validation loss = 3.2021  \n",
      "\n",
      "Fold: 6  Epoch: 328  Training loss = 2.7956  Validation loss = 3.2018  \n",
      "\n",
      "Fold: 6  Epoch: 329  Training loss = 2.7953  Validation loss = 3.2015  \n",
      "\n",
      "Fold: 6  Epoch: 330  Training loss = 2.7951  Validation loss = 3.2012  \n",
      "\n",
      "Fold: 6  Epoch: 331  Training loss = 2.7949  Validation loss = 3.2009  \n",
      "\n",
      "Fold: 6  Epoch: 332  Training loss = 2.7947  Validation loss = 3.2005  \n",
      "\n",
      "Fold: 6  Epoch: 333  Training loss = 2.7945  Validation loss = 3.2003  \n",
      "\n",
      "Fold: 6  Epoch: 334  Training loss = 2.7943  Validation loss = 3.2000  \n",
      "\n",
      "Fold: 6  Epoch: 335  Training loss = 2.7941  Validation loss = 3.1997  \n",
      "\n",
      "Fold: 6  Epoch: 336  Training loss = 2.7939  Validation loss = 3.1993  \n",
      "\n",
      "Fold: 6  Epoch: 337  Training loss = 2.7937  Validation loss = 3.1991  \n",
      "\n",
      "Fold: 6  Epoch: 338  Training loss = 2.7935  Validation loss = 3.1988  \n",
      "\n",
      "Fold: 6  Epoch: 339  Training loss = 2.7933  Validation loss = 3.1985  \n",
      "\n",
      "Fold: 6  Epoch: 340  Training loss = 2.7930  Validation loss = 3.1982  \n",
      "\n",
      "Fold: 6  Epoch: 341  Training loss = 2.7928  Validation loss = 3.1979  \n",
      "\n",
      "Fold: 6  Epoch: 342  Training loss = 2.7926  Validation loss = 3.1976  \n",
      "\n",
      "Fold: 6  Epoch: 343  Training loss = 2.7924  Validation loss = 3.1974  \n",
      "\n",
      "Fold: 6  Epoch: 344  Training loss = 2.7923  Validation loss = 3.1972  \n",
      "\n",
      "Fold: 6  Epoch: 345  Training loss = 2.7921  Validation loss = 3.1969  \n",
      "\n",
      "Fold: 6  Epoch: 346  Training loss = 2.7918  Validation loss = 3.1965  \n",
      "\n",
      "Fold: 6  Epoch: 347  Training loss = 2.7916  Validation loss = 3.1962  \n",
      "\n",
      "Fold: 6  Epoch: 348  Training loss = 2.7914  Validation loss = 3.1958  \n",
      "\n",
      "Fold: 6  Epoch: 349  Training loss = 2.7911  Validation loss = 3.1955  \n",
      "\n",
      "Fold: 6  Epoch: 350  Training loss = 2.7909  Validation loss = 3.1952  \n",
      "\n",
      "Fold: 6  Epoch: 351  Training loss = 2.7906  Validation loss = 3.1948  \n",
      "\n",
      "Fold: 6  Epoch: 352  Training loss = 2.7904  Validation loss = 3.1944  \n",
      "\n",
      "Fold: 6  Epoch: 353  Training loss = 2.7902  Validation loss = 3.1942  \n",
      "\n",
      "Fold: 6  Epoch: 354  Training loss = 2.7899  Validation loss = 3.1938  \n",
      "\n",
      "Fold: 6  Epoch: 355  Training loss = 2.7897  Validation loss = 3.1935  \n",
      "\n",
      "Fold: 6  Epoch: 356  Training loss = 2.7895  Validation loss = 3.1932  \n",
      "\n",
      "Fold: 6  Epoch: 357  Training loss = 2.7893  Validation loss = 3.1929  \n",
      "\n",
      "Fold: 6  Epoch: 358  Training loss = 2.7890  Validation loss = 3.1925  \n",
      "\n",
      "Fold: 6  Epoch: 359  Training loss = 2.7888  Validation loss = 3.1922  \n",
      "\n",
      "Fold: 6  Epoch: 360  Training loss = 2.7886  Validation loss = 3.1919  \n",
      "\n",
      "Fold: 6  Epoch: 361  Training loss = 2.7884  Validation loss = 3.1916  \n",
      "\n",
      "Fold: 6  Epoch: 362  Training loss = 2.7881  Validation loss = 3.1912  \n",
      "\n",
      "Fold: 6  Epoch: 363  Training loss = 2.7879  Validation loss = 3.1910  \n",
      "\n",
      "Fold: 6  Epoch: 364  Training loss = 2.7877  Validation loss = 3.1907  \n",
      "\n",
      "Fold: 6  Epoch: 365  Training loss = 2.7874  Validation loss = 3.1903  \n",
      "\n",
      "Fold: 6  Epoch: 366  Training loss = 2.7872  Validation loss = 3.1899  \n",
      "\n",
      "Fold: 6  Epoch: 367  Training loss = 2.7870  Validation loss = 3.1897  \n",
      "\n",
      "Fold: 6  Epoch: 368  Training loss = 2.7868  Validation loss = 3.1894  \n",
      "\n",
      "Fold: 6  Epoch: 369  Training loss = 2.7866  Validation loss = 3.1891  \n",
      "\n",
      "Fold: 6  Epoch: 370  Training loss = 2.7864  Validation loss = 3.1888  \n",
      "\n",
      "Fold: 6  Epoch: 371  Training loss = 2.7862  Validation loss = 3.1885  \n",
      "\n",
      "Fold: 6  Epoch: 372  Training loss = 2.7860  Validation loss = 3.1882  \n",
      "\n",
      "Fold: 6  Epoch: 373  Training loss = 2.7857  Validation loss = 3.1879  \n",
      "\n",
      "Fold: 6  Epoch: 374  Training loss = 2.7855  Validation loss = 3.1875  \n",
      "\n",
      "Fold: 6  Epoch: 375  Training loss = 2.7853  Validation loss = 3.1872  \n",
      "\n",
      "Fold: 6  Epoch: 376  Training loss = 2.7850  Validation loss = 3.1868  \n",
      "\n",
      "Fold: 6  Epoch: 377  Training loss = 2.7848  Validation loss = 3.1865  \n",
      "\n",
      "Fold: 6  Epoch: 378  Training loss = 2.7845  Validation loss = 3.1861  \n",
      "\n",
      "Fold: 6  Epoch: 379  Training loss = 2.7843  Validation loss = 3.1858  \n",
      "\n",
      "Fold: 6  Epoch: 380  Training loss = 2.7840  Validation loss = 3.1854  \n",
      "\n",
      "Fold: 6  Epoch: 381  Training loss = 2.7838  Validation loss = 3.1851  \n",
      "\n",
      "Fold: 6  Epoch: 382  Training loss = 2.7836  Validation loss = 3.1848  \n",
      "\n",
      "Fold: 6  Epoch: 383  Training loss = 2.7834  Validation loss = 3.1845  \n",
      "\n",
      "Fold: 6  Epoch: 384  Training loss = 2.7831  Validation loss = 3.1841  \n",
      "\n",
      "Fold: 6  Epoch: 385  Training loss = 2.7829  Validation loss = 3.1838  \n",
      "\n",
      "Fold: 6  Epoch: 386  Training loss = 2.7826  Validation loss = 3.1834  \n",
      "\n",
      "Fold: 6  Epoch: 387  Training loss = 2.7824  Validation loss = 3.1831  \n",
      "\n",
      "Fold: 6  Epoch: 388  Training loss = 2.7821  Validation loss = 3.1827  \n",
      "\n",
      "Fold: 6  Epoch: 389  Training loss = 2.7819  Validation loss = 3.1824  \n",
      "\n",
      "Fold: 6  Epoch: 390  Training loss = 2.7817  Validation loss = 3.1821  \n",
      "\n",
      "Fold: 6  Epoch: 391  Training loss = 2.7815  Validation loss = 3.1818  \n",
      "\n",
      "Fold: 6  Epoch: 392  Training loss = 2.7812  Validation loss = 3.1814  \n",
      "\n",
      "Fold: 6  Epoch: 393  Training loss = 2.7810  Validation loss = 3.1811  \n",
      "\n",
      "Fold: 6  Epoch: 394  Training loss = 2.7808  Validation loss = 3.1808  \n",
      "\n",
      "Fold: 6  Epoch: 395  Training loss = 2.7806  Validation loss = 3.1805  \n",
      "\n",
      "Fold: 6  Epoch: 396  Training loss = 2.7804  Validation loss = 3.1802  \n",
      "\n",
      "Fold: 6  Epoch: 397  Training loss = 2.7801  Validation loss = 3.1798  \n",
      "\n",
      "Fold: 6  Epoch: 398  Training loss = 2.7799  Validation loss = 3.1795  \n",
      "\n",
      "Fold: 6  Epoch: 399  Training loss = 2.7797  Validation loss = 3.1793  \n",
      "\n",
      "Fold: 6  Epoch: 400  Training loss = 2.7795  Validation loss = 3.1790  \n",
      "\n",
      "Fold: 6  Epoch: 401  Training loss = 2.7793  Validation loss = 3.1787  \n",
      "\n",
      "Fold: 6  Epoch: 402  Training loss = 2.7791  Validation loss = 3.1784  \n",
      "\n",
      "Fold: 6  Epoch: 403  Training loss = 2.7788  Validation loss = 3.1780  \n",
      "\n",
      "Fold: 6  Epoch: 404  Training loss = 2.7786  Validation loss = 3.1776  \n",
      "\n",
      "Fold: 6  Epoch: 405  Training loss = 2.7784  Validation loss = 3.1773  \n",
      "\n",
      "Fold: 6  Epoch: 406  Training loss = 2.7781  Validation loss = 3.1769  \n",
      "\n",
      "Fold: 6  Epoch: 407  Training loss = 2.7779  Validation loss = 3.1766  \n",
      "\n",
      "Fold: 6  Epoch: 408  Training loss = 2.7776  Validation loss = 3.1762  \n",
      "\n",
      "Fold: 6  Epoch: 409  Training loss = 2.7774  Validation loss = 3.1759  \n",
      "\n",
      "Fold: 6  Epoch: 410  Training loss = 2.7771  Validation loss = 3.1755  \n",
      "\n",
      "Fold: 6  Epoch: 411  Training loss = 2.7769  Validation loss = 3.1752  \n",
      "\n",
      "Fold: 6  Epoch: 412  Training loss = 2.7766  Validation loss = 3.1747  \n",
      "\n",
      "Fold: 6  Epoch: 413  Training loss = 2.7764  Validation loss = 3.1745  \n",
      "\n",
      "Fold: 6  Epoch: 414  Training loss = 2.7762  Validation loss = 3.1742  \n",
      "\n",
      "Fold: 6  Epoch: 415  Training loss = 2.7760  Validation loss = 3.1739  \n",
      "\n",
      "Fold: 6  Epoch: 416  Training loss = 2.7758  Validation loss = 3.1736  \n",
      "\n",
      "Fold: 6  Epoch: 417  Training loss = 2.7756  Validation loss = 3.1733  \n",
      "\n",
      "Fold: 6  Epoch: 418  Training loss = 2.7753  Validation loss = 3.1730  \n",
      "\n",
      "Fold: 6  Epoch: 419  Training loss = 2.7752  Validation loss = 3.1727  \n",
      "\n",
      "Fold: 6  Epoch: 420  Training loss = 2.7749  Validation loss = 3.1724  \n",
      "\n",
      "Fold: 6  Epoch: 421  Training loss = 2.7748  Validation loss = 3.1722  \n",
      "\n",
      "Fold: 6  Epoch: 422  Training loss = 2.7746  Validation loss = 3.1719  \n",
      "\n",
      "Fold: 6  Epoch: 423  Training loss = 2.7743  Validation loss = 3.1716  \n",
      "\n",
      "Fold: 6  Epoch: 424  Training loss = 2.7741  Validation loss = 3.1713  \n",
      "\n",
      "Fold: 6  Epoch: 425  Training loss = 2.7739  Validation loss = 3.1709  \n",
      "\n",
      "Fold: 6  Epoch: 426  Training loss = 2.7736  Validation loss = 3.1706  \n",
      "\n",
      "Fold: 6  Epoch: 427  Training loss = 2.7735  Validation loss = 3.1703  \n",
      "\n",
      "Fold: 6  Epoch: 428  Training loss = 2.7732  Validation loss = 3.1700  \n",
      "\n",
      "Fold: 6  Epoch: 429  Training loss = 2.7730  Validation loss = 3.1696  \n",
      "\n",
      "Fold: 6  Epoch: 430  Training loss = 2.7728  Validation loss = 3.1693  \n",
      "\n",
      "Fold: 6  Epoch: 431  Training loss = 2.7725  Validation loss = 3.1690  \n",
      "\n",
      "Fold: 6  Epoch: 432  Training loss = 2.7723  Validation loss = 3.1687  \n",
      "\n",
      "Fold: 6  Epoch: 433  Training loss = 2.7721  Validation loss = 3.1684  \n",
      "\n",
      "Fold: 6  Epoch: 434  Training loss = 2.7719  Validation loss = 3.1681  \n",
      "\n",
      "Fold: 6  Epoch: 435  Training loss = 2.7717  Validation loss = 3.1678  \n",
      "\n",
      "Fold: 6  Epoch: 436  Training loss = 2.7715  Validation loss = 3.1676  \n",
      "\n",
      "Fold: 6  Epoch: 437  Training loss = 2.7713  Validation loss = 3.1673  \n",
      "\n",
      "Fold: 6  Epoch: 438  Training loss = 2.7711  Validation loss = 3.1669  \n",
      "\n",
      "Fold: 6  Epoch: 439  Training loss = 2.7709  Validation loss = 3.1667  \n",
      "\n",
      "Fold: 6  Epoch: 440  Training loss = 2.7707  Validation loss = 3.1664  \n",
      "\n",
      "Fold: 6  Epoch: 441  Training loss = 2.7705  Validation loss = 3.1661  \n",
      "\n",
      "Fold: 6  Epoch: 442  Training loss = 2.7703  Validation loss = 3.1658  \n",
      "\n",
      "Fold: 6  Epoch: 443  Training loss = 2.7701  Validation loss = 3.1655  \n",
      "\n",
      "Fold: 6  Epoch: 444  Training loss = 2.7699  Validation loss = 3.1652  \n",
      "\n",
      "Fold: 6  Epoch: 445  Training loss = 2.7697  Validation loss = 3.1650  \n",
      "\n",
      "Fold: 6  Epoch: 446  Training loss = 2.7695  Validation loss = 3.1646  \n",
      "\n",
      "Fold: 6  Epoch: 447  Training loss = 2.7693  Validation loss = 3.1643  \n",
      "\n",
      "Fold: 6  Epoch: 448  Training loss = 2.7690  Validation loss = 3.1640  \n",
      "\n",
      "Fold: 6  Epoch: 449  Training loss = 2.7688  Validation loss = 3.1636  \n",
      "\n",
      "Fold: 6  Epoch: 450  Training loss = 2.7685  Validation loss = 3.1632  \n",
      "\n",
      "Fold: 6  Epoch: 451  Training loss = 2.7683  Validation loss = 3.1629  \n",
      "\n",
      "Fold: 6  Epoch: 452  Training loss = 2.7681  Validation loss = 3.1626  \n",
      "\n",
      "Fold: 6  Epoch: 453  Training loss = 2.7679  Validation loss = 3.1624  \n",
      "\n",
      "Fold: 6  Epoch: 454  Training loss = 2.7677  Validation loss = 3.1620  \n",
      "\n",
      "Fold: 6  Epoch: 455  Training loss = 2.7675  Validation loss = 3.1617  \n",
      "\n",
      "Fold: 6  Epoch: 456  Training loss = 2.7673  Validation loss = 3.1614  \n",
      "\n",
      "Fold: 6  Epoch: 457  Training loss = 2.7671  Validation loss = 3.1611  \n",
      "\n",
      "Fold: 6  Epoch: 458  Training loss = 2.7669  Validation loss = 3.1609  \n",
      "\n",
      "Fold: 6  Epoch: 459  Training loss = 2.7667  Validation loss = 3.1606  \n",
      "\n",
      "Fold: 6  Epoch: 460  Training loss = 2.7664  Validation loss = 3.1602  \n",
      "\n",
      "Fold: 6  Epoch: 461  Training loss = 2.7662  Validation loss = 3.1599  \n",
      "\n",
      "Fold: 6  Epoch: 462  Training loss = 2.7660  Validation loss = 3.1596  \n",
      "\n",
      "Fold: 6  Epoch: 463  Training loss = 2.7657  Validation loss = 3.1592  \n",
      "\n",
      "Fold: 6  Epoch: 464  Training loss = 2.7655  Validation loss = 3.1588  \n",
      "\n",
      "Fold: 6  Epoch: 465  Training loss = 2.7653  Validation loss = 3.1585  \n",
      "\n",
      "Fold: 6  Epoch: 466  Training loss = 2.7650  Validation loss = 3.1582  \n",
      "\n",
      "Fold: 6  Epoch: 467  Training loss = 2.7648  Validation loss = 3.1579  \n",
      "\n",
      "Fold: 6  Epoch: 468  Training loss = 2.7646  Validation loss = 3.1576  \n",
      "\n",
      "Fold: 6  Epoch: 469  Training loss = 2.7644  Validation loss = 3.1573  \n",
      "\n",
      "Fold: 6  Epoch: 470  Training loss = 2.7642  Validation loss = 3.1569  \n",
      "\n",
      "Fold: 6  Epoch: 471  Training loss = 2.7640  Validation loss = 3.1567  \n",
      "\n",
      "Fold: 6  Epoch: 472  Training loss = 2.7638  Validation loss = 3.1564  \n",
      "\n",
      "Fold: 6  Epoch: 473  Training loss = 2.7636  Validation loss = 3.1561  \n",
      "\n",
      "Fold: 6  Epoch: 474  Training loss = 2.7634  Validation loss = 3.1558  \n",
      "\n",
      "Fold: 6  Epoch: 475  Training loss = 2.7631  Validation loss = 3.1555  \n",
      "\n",
      "Fold: 6  Epoch: 476  Training loss = 2.7629  Validation loss = 3.1552  \n",
      "\n",
      "Fold: 6  Epoch: 477  Training loss = 2.7627  Validation loss = 3.1549  \n",
      "\n",
      "Fold: 6  Epoch: 478  Training loss = 2.7625  Validation loss = 3.1546  \n",
      "\n",
      "Fold: 6  Epoch: 479  Training loss = 2.7623  Validation loss = 3.1543  \n",
      "\n",
      "Fold: 6  Epoch: 480  Training loss = 2.7621  Validation loss = 3.1540  \n",
      "\n",
      "Fold: 6  Epoch: 481  Training loss = 2.7618  Validation loss = 3.1536  \n",
      "\n",
      "Fold: 6  Epoch: 482  Training loss = 2.7616  Validation loss = 3.1533  \n",
      "\n",
      "Fold: 6  Epoch: 483  Training loss = 2.7614  Validation loss = 3.1531  \n",
      "\n",
      "Fold: 6  Epoch: 484  Training loss = 2.7612  Validation loss = 3.1527  \n",
      "\n",
      "Fold: 6  Epoch: 485  Training loss = 2.7610  Validation loss = 3.1525  \n",
      "\n",
      "Fold: 6  Epoch: 486  Training loss = 2.7608  Validation loss = 3.1522  \n",
      "\n",
      "Fold: 6  Epoch: 487  Training loss = 2.7606  Validation loss = 3.1519  \n",
      "\n",
      "Fold: 6  Epoch: 488  Training loss = 2.7604  Validation loss = 3.1516  \n",
      "\n",
      "Fold: 6  Epoch: 489  Training loss = 2.7602  Validation loss = 3.1513  \n",
      "\n",
      "Fold: 6  Epoch: 490  Training loss = 2.7600  Validation loss = 3.1510  \n",
      "\n",
      "Fold: 6  Epoch: 491  Training loss = 2.7598  Validation loss = 3.1507  \n",
      "\n",
      "Fold: 6  Epoch: 492  Training loss = 2.7596  Validation loss = 3.1505  \n",
      "\n",
      "Fold: 6  Epoch: 493  Training loss = 2.7594  Validation loss = 3.1502  \n",
      "\n",
      "Fold: 6  Epoch: 494  Training loss = 2.7592  Validation loss = 3.1499  \n",
      "\n",
      "Fold: 6  Epoch: 495  Training loss = 2.7590  Validation loss = 3.1496  \n",
      "\n",
      "Fold: 6  Epoch: 496  Training loss = 2.7588  Validation loss = 3.1493  \n",
      "\n",
      "Fold: 6  Epoch: 497  Training loss = 2.7586  Validation loss = 3.1491  \n",
      "\n",
      "Fold: 6  Epoch: 498  Training loss = 2.7584  Validation loss = 3.1488  \n",
      "\n",
      "Fold: 6  Epoch: 499  Training loss = 2.7582  Validation loss = 3.1485  \n",
      "\n",
      "Fold: 6  Epoch: 500  Training loss = 2.7580  Validation loss = 3.1482  \n",
      "\n",
      "Check model:  Fold: 6  Optimal epoch: 500  \n",
      "\n",
      "Fold: 7  Epoch: 1  Training loss = 2.8570  Validation loss = 3.1215  \n",
      "\n",
      "Fold: 7  Epoch: 2  Training loss = 2.8567  Validation loss = 3.1211  \n",
      "\n",
      "Fold: 7  Epoch: 3  Training loss = 2.8565  Validation loss = 3.1208  \n",
      "\n",
      "Fold: 7  Epoch: 4  Training loss = 2.8562  Validation loss = 3.1205  \n",
      "\n",
      "Fold: 7  Epoch: 5  Training loss = 2.8560  Validation loss = 3.1201  \n",
      "\n",
      "Fold: 7  Epoch: 6  Training loss = 2.8557  Validation loss = 3.1197  \n",
      "\n",
      "Fold: 7  Epoch: 7  Training loss = 2.8555  Validation loss = 3.1193  \n",
      "\n",
      "Fold: 7  Epoch: 8  Training loss = 2.8553  Validation loss = 3.1190  \n",
      "\n",
      "Fold: 7  Epoch: 9  Training loss = 2.8551  Validation loss = 3.1188  \n",
      "\n",
      "Fold: 7  Epoch: 10  Training loss = 2.8548  Validation loss = 3.1184  \n",
      "\n",
      "Fold: 7  Epoch: 11  Training loss = 2.8545  Validation loss = 3.1180  \n",
      "\n",
      "Fold: 7  Epoch: 12  Training loss = 2.8542  Validation loss = 3.1175  \n",
      "\n",
      "Fold: 7  Epoch: 13  Training loss = 2.8540  Validation loss = 3.1172  \n",
      "\n",
      "Fold: 7  Epoch: 14  Training loss = 2.8537  Validation loss = 3.1169  \n",
      "\n",
      "Fold: 7  Epoch: 15  Training loss = 2.8535  Validation loss = 3.1164  \n",
      "\n",
      "Fold: 7  Epoch: 16  Training loss = 2.8532  Validation loss = 3.1161  \n",
      "\n",
      "Fold: 7  Epoch: 17  Training loss = 2.8530  Validation loss = 3.1157  \n",
      "\n",
      "Fold: 7  Epoch: 18  Training loss = 2.8527  Validation loss = 3.1153  \n",
      "\n",
      "Fold: 7  Epoch: 19  Training loss = 2.8525  Validation loss = 3.1150  \n",
      "\n",
      "Fold: 7  Epoch: 20  Training loss = 2.8522  Validation loss = 3.1146  \n",
      "\n",
      "Fold: 7  Epoch: 21  Training loss = 2.8519  Validation loss = 3.1142  \n",
      "\n",
      "Fold: 7  Epoch: 22  Training loss = 2.8517  Validation loss = 3.1138  \n",
      "\n",
      "Fold: 7  Epoch: 23  Training loss = 2.8514  Validation loss = 3.1134  \n",
      "\n",
      "Fold: 7  Epoch: 24  Training loss = 2.8511  Validation loss = 3.1130  \n",
      "\n",
      "Fold: 7  Epoch: 25  Training loss = 2.8509  Validation loss = 3.1127  \n",
      "\n",
      "Fold: 7  Epoch: 26  Training loss = 2.8506  Validation loss = 3.1123  \n",
      "\n",
      "Fold: 7  Epoch: 27  Training loss = 2.8504  Validation loss = 3.1120  \n",
      "\n",
      "Fold: 7  Epoch: 28  Training loss = 2.8501  Validation loss = 3.1116  \n",
      "\n",
      "Fold: 7  Epoch: 29  Training loss = 2.8499  Validation loss = 3.1112  \n",
      "\n",
      "Fold: 7  Epoch: 30  Training loss = 2.8496  Validation loss = 3.1108  \n",
      "\n",
      "Fold: 7  Epoch: 31  Training loss = 2.8493  Validation loss = 3.1104  \n",
      "\n",
      "Fold: 7  Epoch: 32  Training loss = 2.8491  Validation loss = 3.1101  \n",
      "\n",
      "Fold: 7  Epoch: 33  Training loss = 2.8489  Validation loss = 3.1098  \n",
      "\n",
      "Fold: 7  Epoch: 34  Training loss = 2.8487  Validation loss = 3.1095  \n",
      "\n",
      "Fold: 7  Epoch: 35  Training loss = 2.8484  Validation loss = 3.1092  \n",
      "\n",
      "Fold: 7  Epoch: 36  Training loss = 2.8482  Validation loss = 3.1088  \n",
      "\n",
      "Fold: 7  Epoch: 37  Training loss = 2.8479  Validation loss = 3.1083  \n",
      "\n",
      "Fold: 7  Epoch: 38  Training loss = 2.8476  Validation loss = 3.1079  \n",
      "\n",
      "Fold: 7  Epoch: 39  Training loss = 2.8473  Validation loss = 3.1076  \n",
      "\n",
      "Fold: 7  Epoch: 40  Training loss = 2.8471  Validation loss = 3.1072  \n",
      "\n",
      "Fold: 7  Epoch: 41  Training loss = 2.8469  Validation loss = 3.1069  \n",
      "\n",
      "Fold: 7  Epoch: 42  Training loss = 2.8467  Validation loss = 3.1066  \n",
      "\n",
      "Fold: 7  Epoch: 43  Training loss = 2.8464  Validation loss = 3.1062  \n",
      "\n",
      "Fold: 7  Epoch: 44  Training loss = 2.8461  Validation loss = 3.1059  \n",
      "\n",
      "Fold: 7  Epoch: 45  Training loss = 2.8459  Validation loss = 3.1055  \n",
      "\n",
      "Fold: 7  Epoch: 46  Training loss = 2.8457  Validation loss = 3.1052  \n",
      "\n",
      "Fold: 7  Epoch: 47  Training loss = 2.8454  Validation loss = 3.1047  \n",
      "\n",
      "Fold: 7  Epoch: 48  Training loss = 2.8451  Validation loss = 3.1044  \n",
      "\n",
      "Fold: 7  Epoch: 49  Training loss = 2.8448  Validation loss = 3.1040  \n",
      "\n",
      "Fold: 7  Epoch: 50  Training loss = 2.8446  Validation loss = 3.1037  \n",
      "\n",
      "Fold: 7  Epoch: 51  Training loss = 2.8443  Validation loss = 3.1033  \n",
      "\n",
      "Fold: 7  Epoch: 52  Training loss = 2.8441  Validation loss = 3.1029  \n",
      "\n",
      "Fold: 7  Epoch: 53  Training loss = 2.8438  Validation loss = 3.1025  \n",
      "\n",
      "Fold: 7  Epoch: 54  Training loss = 2.8435  Validation loss = 3.1021  \n",
      "\n",
      "Fold: 7  Epoch: 55  Training loss = 2.8433  Validation loss = 3.1018  \n",
      "\n",
      "Fold: 7  Epoch: 56  Training loss = 2.8430  Validation loss = 3.1014  \n",
      "\n",
      "Fold: 7  Epoch: 57  Training loss = 2.8428  Validation loss = 3.1011  \n",
      "\n",
      "Fold: 7  Epoch: 58  Training loss = 2.8425  Validation loss = 3.1007  \n",
      "\n",
      "Fold: 7  Epoch: 59  Training loss = 2.8423  Validation loss = 3.1003  \n",
      "\n",
      "Fold: 7  Epoch: 60  Training loss = 2.8421  Validation loss = 3.1000  \n",
      "\n",
      "Fold: 7  Epoch: 61  Training loss = 2.8418  Validation loss = 3.0996  \n",
      "\n",
      "Fold: 7  Epoch: 62  Training loss = 2.8415  Validation loss = 3.0993  \n",
      "\n",
      "Fold: 7  Epoch: 63  Training loss = 2.8412  Validation loss = 3.0988  \n",
      "\n",
      "Fold: 7  Epoch: 64  Training loss = 2.8410  Validation loss = 3.0984  \n",
      "\n",
      "Fold: 7  Epoch: 65  Training loss = 2.8408  Validation loss = 3.0981  \n",
      "\n",
      "Fold: 7  Epoch: 66  Training loss = 2.8404  Validation loss = 3.0976  \n",
      "\n",
      "Fold: 7  Epoch: 67  Training loss = 2.8403  Validation loss = 3.0974  \n",
      "\n",
      "Fold: 7  Epoch: 68  Training loss = 2.8400  Validation loss = 3.0970  \n",
      "\n",
      "Fold: 7  Epoch: 69  Training loss = 2.8398  Validation loss = 3.0966  \n",
      "\n",
      "Fold: 7  Epoch: 70  Training loss = 2.8395  Validation loss = 3.0963  \n",
      "\n",
      "Fold: 7  Epoch: 71  Training loss = 2.8393  Validation loss = 3.0959  \n",
      "\n",
      "Fold: 7  Epoch: 72  Training loss = 2.8390  Validation loss = 3.0955  \n",
      "\n",
      "Fold: 7  Epoch: 73  Training loss = 2.8387  Validation loss = 3.0951  \n",
      "\n",
      "Fold: 7  Epoch: 74  Training loss = 2.8385  Validation loss = 3.0949  \n",
      "\n",
      "Fold: 7  Epoch: 75  Training loss = 2.8383  Validation loss = 3.0945  \n",
      "\n",
      "Fold: 7  Epoch: 76  Training loss = 2.8380  Validation loss = 3.0941  \n",
      "\n",
      "Fold: 7  Epoch: 77  Training loss = 2.8378  Validation loss = 3.0937  \n",
      "\n",
      "Fold: 7  Epoch: 78  Training loss = 2.8375  Validation loss = 3.0934  \n",
      "\n",
      "Fold: 7  Epoch: 79  Training loss = 2.8372  Validation loss = 3.0930  \n",
      "\n",
      "Fold: 7  Epoch: 80  Training loss = 2.8370  Validation loss = 3.0926  \n",
      "\n",
      "Fold: 7  Epoch: 81  Training loss = 2.8368  Validation loss = 3.0922  \n",
      "\n",
      "Fold: 7  Epoch: 82  Training loss = 2.8365  Validation loss = 3.0919  \n",
      "\n",
      "Fold: 7  Epoch: 83  Training loss = 2.8363  Validation loss = 3.0915  \n",
      "\n",
      "Fold: 7  Epoch: 84  Training loss = 2.8360  Validation loss = 3.0911  \n",
      "\n",
      "Fold: 7  Epoch: 85  Training loss = 2.8358  Validation loss = 3.0908  \n",
      "\n",
      "Fold: 7  Epoch: 86  Training loss = 2.8356  Validation loss = 3.0905  \n",
      "\n",
      "Fold: 7  Epoch: 87  Training loss = 2.8354  Validation loss = 3.0902  \n",
      "\n",
      "Fold: 7  Epoch: 88  Training loss = 2.8352  Validation loss = 3.0899  \n",
      "\n",
      "Fold: 7  Epoch: 89  Training loss = 2.8349  Validation loss = 3.0896  \n",
      "\n",
      "Fold: 7  Epoch: 90  Training loss = 2.8347  Validation loss = 3.0892  \n",
      "\n",
      "Fold: 7  Epoch: 91  Training loss = 2.8344  Validation loss = 3.0887  \n",
      "\n",
      "Fold: 7  Epoch: 92  Training loss = 2.8341  Validation loss = 3.0884  \n",
      "\n",
      "Fold: 7  Epoch: 93  Training loss = 2.8339  Validation loss = 3.0880  \n",
      "\n",
      "Fold: 7  Epoch: 94  Training loss = 2.8336  Validation loss = 3.0877  \n",
      "\n",
      "Fold: 7  Epoch: 95  Training loss = 2.8334  Validation loss = 3.0874  \n",
      "\n",
      "Fold: 7  Epoch: 96  Training loss = 2.8332  Validation loss = 3.0870  \n",
      "\n",
      "Fold: 7  Epoch: 97  Training loss = 2.8329  Validation loss = 3.0867  \n",
      "\n",
      "Fold: 7  Epoch: 98  Training loss = 2.8327  Validation loss = 3.0863  \n",
      "\n",
      "Fold: 7  Epoch: 99  Training loss = 2.8324  Validation loss = 3.0860  \n",
      "\n",
      "Fold: 7  Epoch: 100  Training loss = 2.8321  Validation loss = 3.0856  \n",
      "\n",
      "Fold: 7  Epoch: 101  Training loss = 2.8319  Validation loss = 3.0852  \n",
      "\n",
      "Fold: 7  Epoch: 102  Training loss = 2.8317  Validation loss = 3.0849  \n",
      "\n",
      "Fold: 7  Epoch: 103  Training loss = 2.8314  Validation loss = 3.0846  \n",
      "\n",
      "Fold: 7  Epoch: 104  Training loss = 2.8312  Validation loss = 3.0842  \n",
      "\n",
      "Fold: 7  Epoch: 105  Training loss = 2.8310  Validation loss = 3.0839  \n",
      "\n",
      "Fold: 7  Epoch: 106  Training loss = 2.8307  Validation loss = 3.0836  \n",
      "\n",
      "Fold: 7  Epoch: 107  Training loss = 2.8305  Validation loss = 3.0833  \n",
      "\n",
      "Fold: 7  Epoch: 108  Training loss = 2.8303  Validation loss = 3.0829  \n",
      "\n",
      "Fold: 7  Epoch: 109  Training loss = 2.8300  Validation loss = 3.0825  \n",
      "\n",
      "Fold: 7  Epoch: 110  Training loss = 2.8298  Validation loss = 3.0822  \n",
      "\n",
      "Fold: 7  Epoch: 111  Training loss = 2.8296  Validation loss = 3.0818  \n",
      "\n",
      "Fold: 7  Epoch: 112  Training loss = 2.8293  Validation loss = 3.0815  \n",
      "\n",
      "Fold: 7  Epoch: 113  Training loss = 2.8291  Validation loss = 3.0812  \n",
      "\n",
      "Fold: 7  Epoch: 114  Training loss = 2.8289  Validation loss = 3.0809  \n",
      "\n",
      "Fold: 7  Epoch: 115  Training loss = 2.8286  Validation loss = 3.0805  \n",
      "\n",
      "Fold: 7  Epoch: 116  Training loss = 2.8284  Validation loss = 3.0801  \n",
      "\n",
      "Fold: 7  Epoch: 117  Training loss = 2.8281  Validation loss = 3.0797  \n",
      "\n",
      "Fold: 7  Epoch: 118  Training loss = 2.8279  Validation loss = 3.0794  \n",
      "\n",
      "Fold: 7  Epoch: 119  Training loss = 2.8276  Validation loss = 3.0790  \n",
      "\n",
      "Fold: 7  Epoch: 120  Training loss = 2.8273  Validation loss = 3.0786  \n",
      "\n",
      "Fold: 7  Epoch: 121  Training loss = 2.8271  Validation loss = 3.0783  \n",
      "\n",
      "Fold: 7  Epoch: 122  Training loss = 2.8269  Validation loss = 3.0779  \n",
      "\n",
      "Fold: 7  Epoch: 123  Training loss = 2.8266  Validation loss = 3.0776  \n",
      "\n",
      "Fold: 7  Epoch: 124  Training loss = 2.8263  Validation loss = 3.0771  \n",
      "\n",
      "Fold: 7  Epoch: 125  Training loss = 2.8261  Validation loss = 3.0768  \n",
      "\n",
      "Fold: 7  Epoch: 126  Training loss = 2.8259  Validation loss = 3.0765  \n",
      "\n",
      "Fold: 7  Epoch: 127  Training loss = 2.8255  Validation loss = 3.0760  \n",
      "\n",
      "Fold: 7  Epoch: 128  Training loss = 2.8253  Validation loss = 3.0756  \n",
      "\n",
      "Fold: 7  Epoch: 129  Training loss = 2.8251  Validation loss = 3.0753  \n",
      "\n",
      "Fold: 7  Epoch: 130  Training loss = 2.8249  Validation loss = 3.0750  \n",
      "\n",
      "Fold: 7  Epoch: 131  Training loss = 2.8246  Validation loss = 3.0746  \n",
      "\n",
      "Fold: 7  Epoch: 132  Training loss = 2.8243  Validation loss = 3.0742  \n",
      "\n",
      "Fold: 7  Epoch: 133  Training loss = 2.8240  Validation loss = 3.0738  \n",
      "\n",
      "Fold: 7  Epoch: 134  Training loss = 2.8238  Validation loss = 3.0735  \n",
      "\n",
      "Fold: 7  Epoch: 135  Training loss = 2.8235  Validation loss = 3.0731  \n",
      "\n",
      "Fold: 7  Epoch: 136  Training loss = 2.8233  Validation loss = 3.0727  \n",
      "\n",
      "Fold: 7  Epoch: 137  Training loss = 2.8230  Validation loss = 3.0723  \n",
      "\n",
      "Fold: 7  Epoch: 138  Training loss = 2.8228  Validation loss = 3.0720  \n",
      "\n",
      "Fold: 7  Epoch: 139  Training loss = 2.8226  Validation loss = 3.0717  \n",
      "\n",
      "Fold: 7  Epoch: 140  Training loss = 2.8224  Validation loss = 3.0713  \n",
      "\n",
      "Fold: 7  Epoch: 141  Training loss = 2.8221  Validation loss = 3.0709  \n",
      "\n",
      "Fold: 7  Epoch: 142  Training loss = 2.8219  Validation loss = 3.0705  \n",
      "\n",
      "Fold: 7  Epoch: 143  Training loss = 2.8217  Validation loss = 3.0703  \n",
      "\n",
      "Fold: 7  Epoch: 144  Training loss = 2.8214  Validation loss = 3.0699  \n",
      "\n",
      "Fold: 7  Epoch: 145  Training loss = 2.8212  Validation loss = 3.0696  \n",
      "\n",
      "Fold: 7  Epoch: 146  Training loss = 2.8209  Validation loss = 3.0692  \n",
      "\n",
      "Fold: 7  Epoch: 147  Training loss = 2.8207  Validation loss = 3.0689  \n",
      "\n",
      "Fold: 7  Epoch: 148  Training loss = 2.8204  Validation loss = 3.0685  \n",
      "\n",
      "Fold: 7  Epoch: 149  Training loss = 2.8202  Validation loss = 3.0681  \n",
      "\n",
      "Fold: 7  Epoch: 150  Training loss = 2.8199  Validation loss = 3.0677  \n",
      "\n",
      "Fold: 7  Epoch: 151  Training loss = 2.8197  Validation loss = 3.0674  \n",
      "\n",
      "Fold: 7  Epoch: 152  Training loss = 2.8195  Validation loss = 3.0671  \n",
      "\n",
      "Fold: 7  Epoch: 153  Training loss = 2.8193  Validation loss = 3.0668  \n",
      "\n",
      "Fold: 7  Epoch: 154  Training loss = 2.8190  Validation loss = 3.0664  \n",
      "\n",
      "Fold: 7  Epoch: 155  Training loss = 2.8188  Validation loss = 3.0661  \n",
      "\n",
      "Fold: 7  Epoch: 156  Training loss = 2.8186  Validation loss = 3.0658  \n",
      "\n",
      "Fold: 7  Epoch: 157  Training loss = 2.8183  Validation loss = 3.0654  \n",
      "\n",
      "Fold: 7  Epoch: 158  Training loss = 2.8181  Validation loss = 3.0650  \n",
      "\n",
      "Fold: 7  Epoch: 159  Training loss = 2.8179  Validation loss = 3.0647  \n",
      "\n",
      "Fold: 7  Epoch: 160  Training loss = 2.8176  Validation loss = 3.0644  \n",
      "\n",
      "Fold: 7  Epoch: 161  Training loss = 2.8174  Validation loss = 3.0641  \n",
      "\n",
      "Fold: 7  Epoch: 162  Training loss = 2.8172  Validation loss = 3.0638  \n",
      "\n",
      "Fold: 7  Epoch: 163  Training loss = 2.8169  Validation loss = 3.0634  \n",
      "\n",
      "Fold: 7  Epoch: 164  Training loss = 2.8167  Validation loss = 3.0630  \n",
      "\n",
      "Fold: 7  Epoch: 165  Training loss = 2.8164  Validation loss = 3.0627  \n",
      "\n",
      "Fold: 7  Epoch: 166  Training loss = 2.8162  Validation loss = 3.0623  \n",
      "\n",
      "Fold: 7  Epoch: 167  Training loss = 2.8160  Validation loss = 3.0620  \n",
      "\n",
      "Fold: 7  Epoch: 168  Training loss = 2.8157  Validation loss = 3.0617  \n",
      "\n",
      "Fold: 7  Epoch: 169  Training loss = 2.8155  Validation loss = 3.0614  \n",
      "\n",
      "Fold: 7  Epoch: 170  Training loss = 2.8153  Validation loss = 3.0610  \n",
      "\n",
      "Fold: 7  Epoch: 171  Training loss = 2.8150  Validation loss = 3.0607  \n",
      "\n",
      "Fold: 7  Epoch: 172  Training loss = 2.8148  Validation loss = 3.0603  \n",
      "\n",
      "Fold: 7  Epoch: 173  Training loss = 2.8145  Validation loss = 3.0598  \n",
      "\n",
      "Fold: 7  Epoch: 174  Training loss = 2.8143  Validation loss = 3.0595  \n",
      "\n",
      "Fold: 7  Epoch: 175  Training loss = 2.8141  Validation loss = 3.0592  \n",
      "\n",
      "Fold: 7  Epoch: 176  Training loss = 2.8138  Validation loss = 3.0589  \n",
      "\n",
      "Fold: 7  Epoch: 177  Training loss = 2.8136  Validation loss = 3.0585  \n",
      "\n",
      "Fold: 7  Epoch: 178  Training loss = 2.8133  Validation loss = 3.0581  \n",
      "\n",
      "Fold: 7  Epoch: 179  Training loss = 2.8131  Validation loss = 3.0577  \n",
      "\n",
      "Fold: 7  Epoch: 180  Training loss = 2.8128  Validation loss = 3.0574  \n",
      "\n",
      "Fold: 7  Epoch: 181  Training loss = 2.8126  Validation loss = 3.0571  \n",
      "\n",
      "Fold: 7  Epoch: 182  Training loss = 2.8124  Validation loss = 3.0567  \n",
      "\n",
      "Fold: 7  Epoch: 183  Training loss = 2.8121  Validation loss = 3.0563  \n",
      "\n",
      "Fold: 7  Epoch: 184  Training loss = 2.8119  Validation loss = 3.0560  \n",
      "\n",
      "Fold: 7  Epoch: 185  Training loss = 2.8116  Validation loss = 3.0556  \n",
      "\n",
      "Fold: 7  Epoch: 186  Training loss = 2.8113  Validation loss = 3.0552  \n",
      "\n",
      "Fold: 7  Epoch: 187  Training loss = 2.8111  Validation loss = 3.0548  \n",
      "\n",
      "Fold: 7  Epoch: 188  Training loss = 2.8108  Validation loss = 3.0545  \n",
      "\n",
      "Fold: 7  Epoch: 189  Training loss = 2.8106  Validation loss = 3.0541  \n",
      "\n",
      "Fold: 7  Epoch: 190  Training loss = 2.8103  Validation loss = 3.0537  \n",
      "\n",
      "Fold: 7  Epoch: 191  Training loss = 2.8101  Validation loss = 3.0534  \n",
      "\n",
      "Fold: 7  Epoch: 192  Training loss = 2.8098  Validation loss = 3.0530  \n",
      "\n",
      "Fold: 7  Epoch: 193  Training loss = 2.8096  Validation loss = 3.0527  \n",
      "\n",
      "Fold: 7  Epoch: 194  Training loss = 2.8093  Validation loss = 3.0522  \n",
      "\n",
      "Fold: 7  Epoch: 195  Training loss = 2.8091  Validation loss = 3.0518  \n",
      "\n",
      "Fold: 7  Epoch: 196  Training loss = 2.8089  Validation loss = 3.0516  \n",
      "\n",
      "Fold: 7  Epoch: 197  Training loss = 2.8086  Validation loss = 3.0512  \n",
      "\n",
      "Fold: 7  Epoch: 198  Training loss = 2.8084  Validation loss = 3.0508  \n",
      "\n",
      "Fold: 7  Epoch: 199  Training loss = 2.8082  Validation loss = 3.0505  \n",
      "\n",
      "Fold: 7  Epoch: 200  Training loss = 2.8079  Validation loss = 3.0502  \n",
      "\n",
      "Fold: 7  Epoch: 201  Training loss = 2.8077  Validation loss = 3.0498  \n",
      "\n",
      "Fold: 7  Epoch: 202  Training loss = 2.8075  Validation loss = 3.0495  \n",
      "\n",
      "Fold: 7  Epoch: 203  Training loss = 2.8073  Validation loss = 3.0492  \n",
      "\n",
      "Fold: 7  Epoch: 204  Training loss = 2.8070  Validation loss = 3.0489  \n",
      "\n",
      "Fold: 7  Epoch: 205  Training loss = 2.8067  Validation loss = 3.0484  \n",
      "\n",
      "Fold: 7  Epoch: 206  Training loss = 2.8065  Validation loss = 3.0481  \n",
      "\n",
      "Fold: 7  Epoch: 207  Training loss = 2.8063  Validation loss = 3.0477  \n",
      "\n",
      "Fold: 7  Epoch: 208  Training loss = 2.8060  Validation loss = 3.0474  \n",
      "\n",
      "Fold: 7  Epoch: 209  Training loss = 2.8058  Validation loss = 3.0470  \n",
      "\n",
      "Fold: 7  Epoch: 210  Training loss = 2.8055  Validation loss = 3.0467  \n",
      "\n",
      "Fold: 7  Epoch: 211  Training loss = 2.8053  Validation loss = 3.0464  \n",
      "\n",
      "Fold: 7  Epoch: 212  Training loss = 2.8051  Validation loss = 3.0460  \n",
      "\n",
      "Fold: 7  Epoch: 213  Training loss = 2.8048  Validation loss = 3.0456  \n",
      "\n",
      "Fold: 7  Epoch: 214  Training loss = 2.8045  Validation loss = 3.0452  \n",
      "\n",
      "Fold: 7  Epoch: 215  Training loss = 2.8043  Validation loss = 3.0448  \n",
      "\n",
      "Fold: 7  Epoch: 216  Training loss = 2.8041  Validation loss = 3.0445  \n",
      "\n",
      "Fold: 7  Epoch: 217  Training loss = 2.8038  Validation loss = 3.0442  \n",
      "\n",
      "Fold: 7  Epoch: 218  Training loss = 2.8036  Validation loss = 3.0438  \n",
      "\n",
      "Fold: 7  Epoch: 219  Training loss = 2.8033  Validation loss = 3.0434  \n",
      "\n",
      "Fold: 7  Epoch: 220  Training loss = 2.8031  Validation loss = 3.0430  \n",
      "\n",
      "Fold: 7  Epoch: 221  Training loss = 2.8029  Validation loss = 3.0427  \n",
      "\n",
      "Fold: 7  Epoch: 222  Training loss = 2.8026  Validation loss = 3.0424  \n",
      "\n",
      "Fold: 7  Epoch: 223  Training loss = 2.8024  Validation loss = 3.0420  \n",
      "\n",
      "Fold: 7  Epoch: 224  Training loss = 2.8021  Validation loss = 3.0416  \n",
      "\n",
      "Fold: 7  Epoch: 225  Training loss = 2.8019  Validation loss = 3.0411  \n",
      "\n",
      "Fold: 7  Epoch: 226  Training loss = 2.8016  Validation loss = 3.0408  \n",
      "\n",
      "Fold: 7  Epoch: 227  Training loss = 2.8014  Validation loss = 3.0404  \n",
      "\n",
      "Fold: 7  Epoch: 228  Training loss = 2.8012  Validation loss = 3.0401  \n",
      "\n",
      "Fold: 7  Epoch: 229  Training loss = 2.8009  Validation loss = 3.0396  \n",
      "\n",
      "Fold: 7  Epoch: 230  Training loss = 2.8007  Validation loss = 3.0394  \n",
      "\n",
      "Fold: 7  Epoch: 231  Training loss = 2.8004  Validation loss = 3.0390  \n",
      "\n",
      "Fold: 7  Epoch: 232  Training loss = 2.8002  Validation loss = 3.0387  \n",
      "\n",
      "Fold: 7  Epoch: 233  Training loss = 2.8001  Validation loss = 3.0384  \n",
      "\n",
      "Fold: 7  Epoch: 234  Training loss = 2.7998  Validation loss = 3.0380  \n",
      "\n",
      "Fold: 7  Epoch: 235  Training loss = 2.7996  Validation loss = 3.0376  \n",
      "\n",
      "Fold: 7  Epoch: 236  Training loss = 2.7993  Validation loss = 3.0373  \n",
      "\n",
      "Fold: 7  Epoch: 237  Training loss = 2.7991  Validation loss = 3.0370  \n",
      "\n",
      "Fold: 7  Epoch: 238  Training loss = 2.7988  Validation loss = 3.0366  \n",
      "\n",
      "Fold: 7  Epoch: 239  Training loss = 2.7986  Validation loss = 3.0363  \n",
      "\n",
      "Fold: 7  Epoch: 240  Training loss = 2.7984  Validation loss = 3.0359  \n",
      "\n",
      "Fold: 7  Epoch: 241  Training loss = 2.7981  Validation loss = 3.0355  \n",
      "\n",
      "Fold: 7  Epoch: 242  Training loss = 2.7979  Validation loss = 3.0352  \n",
      "\n",
      "Fold: 7  Epoch: 243  Training loss = 2.7977  Validation loss = 3.0349  \n",
      "\n",
      "Fold: 7  Epoch: 244  Training loss = 2.7975  Validation loss = 3.0347  \n",
      "\n",
      "Fold: 7  Epoch: 245  Training loss = 2.7972  Validation loss = 3.0343  \n",
      "\n",
      "Fold: 7  Epoch: 246  Training loss = 2.7970  Validation loss = 3.0339  \n",
      "\n",
      "Fold: 7  Epoch: 247  Training loss = 2.7967  Validation loss = 3.0335  \n",
      "\n",
      "Fold: 7  Epoch: 248  Training loss = 2.7965  Validation loss = 3.0332  \n",
      "\n",
      "Fold: 7  Epoch: 249  Training loss = 2.7963  Validation loss = 3.0329  \n",
      "\n",
      "Fold: 7  Epoch: 250  Training loss = 2.7960  Validation loss = 3.0325  \n",
      "\n",
      "Fold: 7  Epoch: 251  Training loss = 2.7958  Validation loss = 3.0322  \n",
      "\n",
      "Fold: 7  Epoch: 252  Training loss = 2.7956  Validation loss = 3.0319  \n",
      "\n",
      "Fold: 7  Epoch: 253  Training loss = 2.7954  Validation loss = 3.0315  \n",
      "\n",
      "Fold: 7  Epoch: 254  Training loss = 2.7951  Validation loss = 3.0312  \n",
      "\n",
      "Fold: 7  Epoch: 255  Training loss = 2.7949  Validation loss = 3.0308  \n",
      "\n",
      "Fold: 7  Epoch: 256  Training loss = 2.7947  Validation loss = 3.0305  \n",
      "\n",
      "Fold: 7  Epoch: 257  Training loss = 2.7945  Validation loss = 3.0302  \n",
      "\n",
      "Fold: 7  Epoch: 258  Training loss = 2.7943  Validation loss = 3.0299  \n",
      "\n",
      "Fold: 7  Epoch: 259  Training loss = 2.7941  Validation loss = 3.0296  \n",
      "\n",
      "Fold: 7  Epoch: 260  Training loss = 2.7938  Validation loss = 3.0293  \n",
      "\n",
      "Fold: 7  Epoch: 261  Training loss = 2.7936  Validation loss = 3.0289  \n",
      "\n",
      "Fold: 7  Epoch: 262  Training loss = 2.7933  Validation loss = 3.0286  \n",
      "\n",
      "Fold: 7  Epoch: 263  Training loss = 2.7931  Validation loss = 3.0282  \n",
      "\n",
      "Fold: 7  Epoch: 264  Training loss = 2.7928  Validation loss = 3.0278  \n",
      "\n",
      "Fold: 7  Epoch: 265  Training loss = 2.7926  Validation loss = 3.0275  \n",
      "\n",
      "Fold: 7  Epoch: 266  Training loss = 2.7924  Validation loss = 3.0271  \n",
      "\n",
      "Fold: 7  Epoch: 267  Training loss = 2.7921  Validation loss = 3.0267  \n",
      "\n",
      "Fold: 7  Epoch: 268  Training loss = 2.7919  Validation loss = 3.0264  \n",
      "\n",
      "Fold: 7  Epoch: 269  Training loss = 2.7916  Validation loss = 3.0260  \n",
      "\n",
      "Fold: 7  Epoch: 270  Training loss = 2.7914  Validation loss = 3.0256  \n",
      "\n",
      "Fold: 7  Epoch: 271  Training loss = 2.7912  Validation loss = 3.0253  \n",
      "\n",
      "Fold: 7  Epoch: 272  Training loss = 2.7910  Validation loss = 3.0250  \n",
      "\n",
      "Fold: 7  Epoch: 273  Training loss = 2.7907  Validation loss = 3.0247  \n",
      "\n",
      "Fold: 7  Epoch: 274  Training loss = 2.7905  Validation loss = 3.0243  \n",
      "\n",
      "Fold: 7  Epoch: 275  Training loss = 2.7903  Validation loss = 3.0241  \n",
      "\n",
      "Fold: 7  Epoch: 276  Training loss = 2.7902  Validation loss = 3.0239  \n",
      "\n",
      "Fold: 7  Epoch: 277  Training loss = 2.7899  Validation loss = 3.0235  \n",
      "\n",
      "Fold: 7  Epoch: 278  Training loss = 2.7897  Validation loss = 3.0232  \n",
      "\n",
      "Fold: 7  Epoch: 279  Training loss = 2.7894  Validation loss = 3.0229  \n",
      "\n",
      "Fold: 7  Epoch: 280  Training loss = 2.7893  Validation loss = 3.0226  \n",
      "\n",
      "Fold: 7  Epoch: 281  Training loss = 2.7890  Validation loss = 3.0223  \n",
      "\n",
      "Fold: 7  Epoch: 282  Training loss = 2.7888  Validation loss = 3.0219  \n",
      "\n",
      "Fold: 7  Epoch: 283  Training loss = 2.7886  Validation loss = 3.0216  \n",
      "\n",
      "Fold: 7  Epoch: 284  Training loss = 2.7884  Validation loss = 3.0214  \n",
      "\n",
      "Fold: 7  Epoch: 285  Training loss = 2.7881  Validation loss = 3.0210  \n",
      "\n",
      "Fold: 7  Epoch: 286  Training loss = 2.7879  Validation loss = 3.0207  \n",
      "\n",
      "Fold: 7  Epoch: 287  Training loss = 2.7877  Validation loss = 3.0203  \n",
      "\n",
      "Fold: 7  Epoch: 288  Training loss = 2.7875  Validation loss = 3.0200  \n",
      "\n",
      "Fold: 7  Epoch: 289  Training loss = 2.7873  Validation loss = 3.0196  \n",
      "\n",
      "Fold: 7  Epoch: 290  Training loss = 2.7870  Validation loss = 3.0192  \n",
      "\n",
      "Fold: 7  Epoch: 291  Training loss = 2.7868  Validation loss = 3.0189  \n",
      "\n",
      "Fold: 7  Epoch: 292  Training loss = 2.7866  Validation loss = 3.0186  \n",
      "\n",
      "Fold: 7  Epoch: 293  Training loss = 2.7863  Validation loss = 3.0183  \n",
      "\n",
      "Fold: 7  Epoch: 294  Training loss = 2.7861  Validation loss = 3.0180  \n",
      "\n",
      "Fold: 7  Epoch: 295  Training loss = 2.7859  Validation loss = 3.0177  \n",
      "\n",
      "Fold: 7  Epoch: 296  Training loss = 2.7857  Validation loss = 3.0173  \n",
      "\n",
      "Fold: 7  Epoch: 297  Training loss = 2.7855  Validation loss = 3.0171  \n",
      "\n",
      "Fold: 7  Epoch: 298  Training loss = 2.7853  Validation loss = 3.0168  \n",
      "\n",
      "Fold: 7  Epoch: 299  Training loss = 2.7850  Validation loss = 3.0164  \n",
      "\n",
      "Fold: 7  Epoch: 300  Training loss = 2.7848  Validation loss = 3.0161  \n",
      "\n",
      "Fold: 7  Epoch: 301  Training loss = 2.7845  Validation loss = 3.0156  \n",
      "\n",
      "Fold: 7  Epoch: 302  Training loss = 2.7843  Validation loss = 3.0154  \n",
      "\n",
      "Fold: 7  Epoch: 303  Training loss = 2.7841  Validation loss = 3.0150  \n",
      "\n",
      "Fold: 7  Epoch: 304  Training loss = 2.7838  Validation loss = 3.0146  \n",
      "\n",
      "Fold: 7  Epoch: 305  Training loss = 2.7836  Validation loss = 3.0143  \n",
      "\n",
      "Fold: 7  Epoch: 306  Training loss = 2.7834  Validation loss = 3.0140  \n",
      "\n",
      "Fold: 7  Epoch: 307  Training loss = 2.7831  Validation loss = 3.0136  \n",
      "\n",
      "Fold: 7  Epoch: 308  Training loss = 2.7829  Validation loss = 3.0132  \n",
      "\n",
      "Fold: 7  Epoch: 309  Training loss = 2.7827  Validation loss = 3.0129  \n",
      "\n",
      "Fold: 7  Epoch: 310  Training loss = 2.7825  Validation loss = 3.0126  \n",
      "\n",
      "Fold: 7  Epoch: 311  Training loss = 2.7823  Validation loss = 3.0123  \n",
      "\n",
      "Fold: 7  Epoch: 312  Training loss = 2.7820  Validation loss = 3.0119  \n",
      "\n",
      "Fold: 7  Epoch: 313  Training loss = 2.7818  Validation loss = 3.0116  \n",
      "\n",
      "Fold: 7  Epoch: 314  Training loss = 2.7816  Validation loss = 3.0113  \n",
      "\n",
      "Fold: 7  Epoch: 315  Training loss = 2.7814  Validation loss = 3.0110  \n",
      "\n",
      "Fold: 7  Epoch: 316  Training loss = 2.7811  Validation loss = 3.0107  \n",
      "\n",
      "Fold: 7  Epoch: 317  Training loss = 2.7809  Validation loss = 3.0103  \n",
      "\n",
      "Fold: 7  Epoch: 318  Training loss = 2.7807  Validation loss = 3.0100  \n",
      "\n",
      "Fold: 7  Epoch: 319  Training loss = 2.7805  Validation loss = 3.0097  \n",
      "\n",
      "Fold: 7  Epoch: 320  Training loss = 2.7803  Validation loss = 3.0094  \n",
      "\n",
      "Fold: 7  Epoch: 321  Training loss = 2.7800  Validation loss = 3.0090  \n",
      "\n",
      "Fold: 7  Epoch: 322  Training loss = 2.7798  Validation loss = 3.0087  \n",
      "\n",
      "Fold: 7  Epoch: 323  Training loss = 2.7796  Validation loss = 3.0083  \n",
      "\n",
      "Fold: 7  Epoch: 324  Training loss = 2.7793  Validation loss = 3.0080  \n",
      "\n",
      "Fold: 7  Epoch: 325  Training loss = 2.7791  Validation loss = 3.0076  \n",
      "\n",
      "Fold: 7  Epoch: 326  Training loss = 2.7789  Validation loss = 3.0073  \n",
      "\n",
      "Fold: 7  Epoch: 327  Training loss = 2.7786  Validation loss = 3.0070  \n",
      "\n",
      "Fold: 7  Epoch: 328  Training loss = 2.7784  Validation loss = 3.0067  \n",
      "\n",
      "Fold: 7  Epoch: 329  Training loss = 2.7782  Validation loss = 3.0063  \n",
      "\n",
      "Fold: 7  Epoch: 330  Training loss = 2.7779  Validation loss = 3.0059  \n",
      "\n",
      "Fold: 7  Epoch: 331  Training loss = 2.7777  Validation loss = 3.0056  \n",
      "\n",
      "Fold: 7  Epoch: 332  Training loss = 2.7775  Validation loss = 3.0053  \n",
      "\n",
      "Fold: 7  Epoch: 333  Training loss = 2.7772  Validation loss = 3.0049  \n",
      "\n",
      "Fold: 7  Epoch: 334  Training loss = 2.7770  Validation loss = 3.0046  \n",
      "\n",
      "Fold: 7  Epoch: 335  Training loss = 2.7768  Validation loss = 3.0043  \n",
      "\n",
      "Fold: 7  Epoch: 336  Training loss = 2.7766  Validation loss = 3.0040  \n",
      "\n",
      "Fold: 7  Epoch: 337  Training loss = 2.7764  Validation loss = 3.0037  \n",
      "\n",
      "Fold: 7  Epoch: 338  Training loss = 2.7762  Validation loss = 3.0033  \n",
      "\n",
      "Fold: 7  Epoch: 339  Training loss = 2.7759  Validation loss = 3.0030  \n",
      "\n",
      "Fold: 7  Epoch: 340  Training loss = 2.7757  Validation loss = 3.0027  \n",
      "\n",
      "Fold: 7  Epoch: 341  Training loss = 2.7755  Validation loss = 3.0023  \n",
      "\n",
      "Fold: 7  Epoch: 342  Training loss = 2.7753  Validation loss = 3.0020  \n",
      "\n",
      "Fold: 7  Epoch: 343  Training loss = 2.7751  Validation loss = 3.0017  \n",
      "\n",
      "Fold: 7  Epoch: 344  Training loss = 2.7748  Validation loss = 3.0014  \n",
      "\n",
      "Fold: 7  Epoch: 345  Training loss = 2.7746  Validation loss = 3.0010  \n",
      "\n",
      "Fold: 7  Epoch: 346  Training loss = 2.7743  Validation loss = 3.0007  \n",
      "\n",
      "Fold: 7  Epoch: 347  Training loss = 2.7741  Validation loss = 3.0003  \n",
      "\n",
      "Fold: 7  Epoch: 348  Training loss = 2.7739  Validation loss = 2.9999  \n",
      "\n",
      "Fold: 7  Epoch: 349  Training loss = 2.7736  Validation loss = 2.9995  \n",
      "\n",
      "Fold: 7  Epoch: 350  Training loss = 2.7734  Validation loss = 2.9992  \n",
      "\n",
      "Fold: 7  Epoch: 351  Training loss = 2.7732  Validation loss = 2.9989  \n",
      "\n",
      "Fold: 7  Epoch: 352  Training loss = 2.7729  Validation loss = 2.9985  \n",
      "\n",
      "Fold: 7  Epoch: 353  Training loss = 2.7728  Validation loss = 2.9983  \n",
      "\n",
      "Fold: 7  Epoch: 354  Training loss = 2.7725  Validation loss = 2.9979  \n",
      "\n",
      "Fold: 7  Epoch: 355  Training loss = 2.7723  Validation loss = 2.9975  \n",
      "\n",
      "Fold: 7  Epoch: 356  Training loss = 2.7720  Validation loss = 2.9971  \n",
      "\n",
      "Fold: 7  Epoch: 357  Training loss = 2.7718  Validation loss = 2.9968  \n",
      "\n",
      "Fold: 7  Epoch: 358  Training loss = 2.7715  Validation loss = 2.9964  \n",
      "\n",
      "Fold: 7  Epoch: 359  Training loss = 2.7713  Validation loss = 2.9960  \n",
      "\n",
      "Fold: 7  Epoch: 360  Training loss = 2.7711  Validation loss = 2.9958  \n",
      "\n",
      "Fold: 7  Epoch: 361  Training loss = 2.7708  Validation loss = 2.9954  \n",
      "\n",
      "Fold: 7  Epoch: 362  Training loss = 2.7706  Validation loss = 2.9951  \n",
      "\n",
      "Fold: 7  Epoch: 363  Training loss = 2.7703  Validation loss = 2.9946  \n",
      "\n",
      "Fold: 7  Epoch: 364  Training loss = 2.7701  Validation loss = 2.9944  \n",
      "\n",
      "Fold: 7  Epoch: 365  Training loss = 2.7699  Validation loss = 2.9941  \n",
      "\n",
      "Fold: 7  Epoch: 366  Training loss = 2.7697  Validation loss = 2.9938  \n",
      "\n",
      "Fold: 7  Epoch: 367  Training loss = 2.7695  Validation loss = 2.9935  \n",
      "\n",
      "Fold: 7  Epoch: 368  Training loss = 2.7693  Validation loss = 2.9931  \n",
      "\n",
      "Fold: 7  Epoch: 369  Training loss = 2.7691  Validation loss = 2.9928  \n",
      "\n",
      "Fold: 7  Epoch: 370  Training loss = 2.7689  Validation loss = 2.9926  \n",
      "\n",
      "Fold: 7  Epoch: 371  Training loss = 2.7687  Validation loss = 2.9922  \n",
      "\n",
      "Fold: 7  Epoch: 372  Training loss = 2.7685  Validation loss = 2.9919  \n",
      "\n",
      "Fold: 7  Epoch: 373  Training loss = 2.7682  Validation loss = 2.9915  \n",
      "\n",
      "Fold: 7  Epoch: 374  Training loss = 2.7679  Validation loss = 2.9911  \n",
      "\n",
      "Fold: 7  Epoch: 375  Training loss = 2.7677  Validation loss = 2.9907  \n",
      "\n",
      "Fold: 7  Epoch: 376  Training loss = 2.7675  Validation loss = 2.9904  \n",
      "\n",
      "Fold: 7  Epoch: 377  Training loss = 2.7672  Validation loss = 2.9901  \n",
      "\n",
      "Fold: 7  Epoch: 378  Training loss = 2.7670  Validation loss = 2.9897  \n",
      "\n",
      "Fold: 7  Epoch: 379  Training loss = 2.7667  Validation loss = 2.9893  \n",
      "\n",
      "Fold: 7  Epoch: 380  Training loss = 2.7665  Validation loss = 2.9890  \n",
      "\n",
      "Fold: 7  Epoch: 381  Training loss = 2.7663  Validation loss = 2.9887  \n",
      "\n",
      "Fold: 7  Epoch: 382  Training loss = 2.7660  Validation loss = 2.9883  \n",
      "\n",
      "Fold: 7  Epoch: 383  Training loss = 2.7658  Validation loss = 2.9878  \n",
      "\n",
      "Fold: 7  Epoch: 384  Training loss = 2.7655  Validation loss = 2.9875  \n",
      "\n",
      "Fold: 7  Epoch: 385  Training loss = 2.7653  Validation loss = 2.9872  \n",
      "\n",
      "Fold: 7  Epoch: 386  Training loss = 2.7650  Validation loss = 2.9867  \n",
      "\n",
      "Fold: 7  Epoch: 387  Training loss = 2.7648  Validation loss = 2.9864  \n",
      "\n",
      "Fold: 7  Epoch: 388  Training loss = 2.7646  Validation loss = 2.9860  \n",
      "\n",
      "Fold: 7  Epoch: 389  Training loss = 2.7643  Validation loss = 2.9856  \n",
      "\n",
      "Fold: 7  Epoch: 390  Training loss = 2.7641  Validation loss = 2.9852  \n",
      "\n",
      "Fold: 7  Epoch: 391  Training loss = 2.7639  Validation loss = 2.9849  \n",
      "\n",
      "Fold: 7  Epoch: 392  Training loss = 2.7637  Validation loss = 2.9846  \n",
      "\n",
      "Fold: 7  Epoch: 393  Training loss = 2.7634  Validation loss = 2.9842  \n",
      "\n",
      "Fold: 7  Epoch: 394  Training loss = 2.7632  Validation loss = 2.9839  \n",
      "\n",
      "Fold: 7  Epoch: 395  Training loss = 2.7630  Validation loss = 2.9836  \n",
      "\n",
      "Fold: 7  Epoch: 396  Training loss = 2.7628  Validation loss = 2.9833  \n",
      "\n",
      "Fold: 7  Epoch: 397  Training loss = 2.7625  Validation loss = 2.9829  \n",
      "\n",
      "Fold: 7  Epoch: 398  Training loss = 2.7623  Validation loss = 2.9826  \n",
      "\n",
      "Fold: 7  Epoch: 399  Training loss = 2.7621  Validation loss = 2.9822  \n",
      "\n",
      "Fold: 7  Epoch: 400  Training loss = 2.7619  Validation loss = 2.9819  \n",
      "\n",
      "Fold: 7  Epoch: 401  Training loss = 2.7616  Validation loss = 2.9815  \n",
      "\n",
      "Fold: 7  Epoch: 402  Training loss = 2.7614  Validation loss = 2.9812  \n",
      "\n",
      "Fold: 7  Epoch: 403  Training loss = 2.7612  Validation loss = 2.9808  \n",
      "\n",
      "Fold: 7  Epoch: 404  Training loss = 2.7610  Validation loss = 2.9805  \n",
      "\n",
      "Fold: 7  Epoch: 405  Training loss = 2.7607  Validation loss = 2.9802  \n",
      "\n",
      "Fold: 7  Epoch: 406  Training loss = 2.7606  Validation loss = 2.9799  \n",
      "\n",
      "Fold: 7  Epoch: 407  Training loss = 2.7603  Validation loss = 2.9795  \n",
      "\n",
      "Fold: 7  Epoch: 408  Training loss = 2.7601  Validation loss = 2.9791  \n",
      "\n",
      "Fold: 7  Epoch: 409  Training loss = 2.7599  Validation loss = 2.9788  \n",
      "\n",
      "Fold: 7  Epoch: 410  Training loss = 2.7596  Validation loss = 2.9785  \n",
      "\n",
      "Fold: 7  Epoch: 411  Training loss = 2.7594  Validation loss = 2.9781  \n",
      "\n",
      "Fold: 7  Epoch: 412  Training loss = 2.7592  Validation loss = 2.9777  \n",
      "\n",
      "Fold: 7  Epoch: 413  Training loss = 2.7590  Validation loss = 2.9774  \n",
      "\n",
      "Fold: 7  Epoch: 414  Training loss = 2.7588  Validation loss = 2.9771  \n",
      "\n",
      "Fold: 7  Epoch: 415  Training loss = 2.7586  Validation loss = 2.9768  \n",
      "\n",
      "Fold: 7  Epoch: 416  Training loss = 2.7583  Validation loss = 2.9764  \n",
      "\n",
      "Fold: 7  Epoch: 417  Training loss = 2.7581  Validation loss = 2.9762  \n",
      "\n",
      "Fold: 7  Epoch: 418  Training loss = 2.7579  Validation loss = 2.9757  \n",
      "\n",
      "Fold: 7  Epoch: 419  Training loss = 2.7577  Validation loss = 2.9755  \n",
      "\n",
      "Fold: 7  Epoch: 420  Training loss = 2.7575  Validation loss = 2.9752  \n",
      "\n",
      "Fold: 7  Epoch: 421  Training loss = 2.7573  Validation loss = 2.9748  \n",
      "\n",
      "Fold: 7  Epoch: 422  Training loss = 2.7570  Validation loss = 2.9745  \n",
      "\n",
      "Fold: 7  Epoch: 423  Training loss = 2.7568  Validation loss = 2.9741  \n",
      "\n",
      "Fold: 7  Epoch: 424  Training loss = 2.7566  Validation loss = 2.9739  \n",
      "\n",
      "Fold: 7  Epoch: 425  Training loss = 2.7564  Validation loss = 2.9735  \n",
      "\n",
      "Fold: 7  Epoch: 426  Training loss = 2.7562  Validation loss = 2.9732  \n",
      "\n",
      "Fold: 7  Epoch: 427  Training loss = 2.7559  Validation loss = 2.9729  \n",
      "\n",
      "Fold: 7  Epoch: 428  Training loss = 2.7557  Validation loss = 2.9726  \n",
      "\n",
      "Fold: 7  Epoch: 429  Training loss = 2.7555  Validation loss = 2.9723  \n",
      "\n",
      "Fold: 7  Epoch: 430  Training loss = 2.7553  Validation loss = 2.9720  \n",
      "\n",
      "Fold: 7  Epoch: 431  Training loss = 2.7551  Validation loss = 2.9716  \n",
      "\n",
      "Fold: 7  Epoch: 432  Training loss = 2.7549  Validation loss = 2.9713  \n",
      "\n",
      "Fold: 7  Epoch: 433  Training loss = 2.7546  Validation loss = 2.9709  \n",
      "\n",
      "Fold: 7  Epoch: 434  Training loss = 2.7544  Validation loss = 2.9706  \n",
      "\n",
      "Fold: 7  Epoch: 435  Training loss = 2.7542  Validation loss = 2.9702  \n",
      "\n",
      "Fold: 7  Epoch: 436  Training loss = 2.7539  Validation loss = 2.9698  \n",
      "\n",
      "Fold: 7  Epoch: 437  Training loss = 2.7537  Validation loss = 2.9695  \n",
      "\n",
      "Fold: 7  Epoch: 438  Training loss = 2.7535  Validation loss = 2.9692  \n",
      "\n",
      "Fold: 7  Epoch: 439  Training loss = 2.7533  Validation loss = 2.9688  \n",
      "\n",
      "Fold: 7  Epoch: 440  Training loss = 2.7531  Validation loss = 2.9686  \n",
      "\n",
      "Fold: 7  Epoch: 441  Training loss = 2.7529  Validation loss = 2.9683  \n",
      "\n",
      "Fold: 7  Epoch: 442  Training loss = 2.7527  Validation loss = 2.9680  \n",
      "\n",
      "Fold: 7  Epoch: 443  Training loss = 2.7524  Validation loss = 2.9676  \n",
      "\n",
      "Fold: 7  Epoch: 444  Training loss = 2.7522  Validation loss = 2.9673  \n",
      "\n",
      "Fold: 7  Epoch: 445  Training loss = 2.7520  Validation loss = 2.9669  \n",
      "\n",
      "Fold: 7  Epoch: 446  Training loss = 2.7517  Validation loss = 2.9665  \n",
      "\n",
      "Fold: 7  Epoch: 447  Training loss = 2.7515  Validation loss = 2.9661  \n",
      "\n",
      "Fold: 7  Epoch: 448  Training loss = 2.7512  Validation loss = 2.9658  \n",
      "\n",
      "Fold: 7  Epoch: 449  Training loss = 2.7510  Validation loss = 2.9655  \n",
      "\n",
      "Fold: 7  Epoch: 450  Training loss = 2.7509  Validation loss = 2.9652  \n",
      "\n",
      "Fold: 7  Epoch: 451  Training loss = 2.7507  Validation loss = 2.9649  \n",
      "\n",
      "Fold: 7  Epoch: 452  Training loss = 2.7505  Validation loss = 2.9646  \n",
      "\n",
      "Fold: 7  Epoch: 453  Training loss = 2.7502  Validation loss = 2.9642  \n",
      "\n",
      "Fold: 7  Epoch: 454  Training loss = 2.7500  Validation loss = 2.9639  \n",
      "\n",
      "Fold: 7  Epoch: 455  Training loss = 2.7498  Validation loss = 2.9635  \n",
      "\n",
      "Fold: 7  Epoch: 456  Training loss = 2.7496  Validation loss = 2.9632  \n",
      "\n",
      "Fold: 7  Epoch: 457  Training loss = 2.7493  Validation loss = 2.9629  \n",
      "\n",
      "Fold: 7  Epoch: 458  Training loss = 2.7491  Validation loss = 2.9625  \n",
      "\n",
      "Fold: 7  Epoch: 459  Training loss = 2.7489  Validation loss = 2.9622  \n",
      "\n",
      "Fold: 7  Epoch: 460  Training loss = 2.7487  Validation loss = 2.9619  \n",
      "\n",
      "Fold: 7  Epoch: 461  Training loss = 2.7485  Validation loss = 2.9616  \n",
      "\n",
      "Fold: 7  Epoch: 462  Training loss = 2.7482  Validation loss = 2.9612  \n",
      "\n",
      "Fold: 7  Epoch: 463  Training loss = 2.7480  Validation loss = 2.9608  \n",
      "\n",
      "Fold: 7  Epoch: 464  Training loss = 2.7477  Validation loss = 2.9604  \n",
      "\n",
      "Fold: 7  Epoch: 465  Training loss = 2.7476  Validation loss = 2.9601  \n",
      "\n",
      "Fold: 7  Epoch: 466  Training loss = 2.7473  Validation loss = 2.9598  \n",
      "\n",
      "Fold: 7  Epoch: 467  Training loss = 2.7471  Validation loss = 2.9595  \n",
      "\n",
      "Fold: 7  Epoch: 468  Training loss = 2.7470  Validation loss = 2.9592  \n",
      "\n",
      "Fold: 7  Epoch: 469  Training loss = 2.7467  Validation loss = 2.9589  \n",
      "\n",
      "Fold: 7  Epoch: 470  Training loss = 2.7465  Validation loss = 2.9585  \n",
      "\n",
      "Fold: 7  Epoch: 471  Training loss = 2.7463  Validation loss = 2.9582  \n",
      "\n",
      "Fold: 7  Epoch: 472  Training loss = 2.7461  Validation loss = 2.9579  \n",
      "\n",
      "Fold: 7  Epoch: 473  Training loss = 2.7459  Validation loss = 2.9575  \n",
      "\n",
      "Fold: 7  Epoch: 474  Training loss = 2.7456  Validation loss = 2.9572  \n",
      "\n",
      "Fold: 7  Epoch: 475  Training loss = 2.7453  Validation loss = 2.9567  \n",
      "\n",
      "Fold: 7  Epoch: 476  Training loss = 2.7451  Validation loss = 2.9564  \n",
      "\n",
      "Fold: 7  Epoch: 477  Training loss = 2.7449  Validation loss = 2.9560  \n",
      "\n",
      "Fold: 7  Epoch: 478  Training loss = 2.7447  Validation loss = 2.9557  \n",
      "\n",
      "Fold: 7  Epoch: 479  Training loss = 2.7444  Validation loss = 2.9553  \n",
      "\n",
      "Fold: 7  Epoch: 480  Training loss = 2.7442  Validation loss = 2.9549  \n",
      "\n",
      "Fold: 7  Epoch: 481  Training loss = 2.7440  Validation loss = 2.9546  \n",
      "\n",
      "Fold: 7  Epoch: 482  Training loss = 2.7437  Validation loss = 2.9543  \n",
      "\n",
      "Fold: 7  Epoch: 483  Training loss = 2.7436  Validation loss = 2.9540  \n",
      "\n",
      "Fold: 7  Epoch: 484  Training loss = 2.7433  Validation loss = 2.9537  \n",
      "\n",
      "Fold: 7  Epoch: 485  Training loss = 2.7431  Validation loss = 2.9533  \n",
      "\n",
      "Fold: 7  Epoch: 486  Training loss = 2.7429  Validation loss = 2.9530  \n",
      "\n",
      "Fold: 7  Epoch: 487  Training loss = 2.7426  Validation loss = 2.9526  \n",
      "\n",
      "Fold: 7  Epoch: 488  Training loss = 2.7424  Validation loss = 2.9523  \n",
      "\n",
      "Fold: 7  Epoch: 489  Training loss = 2.7422  Validation loss = 2.9520  \n",
      "\n",
      "Fold: 7  Epoch: 490  Training loss = 2.7420  Validation loss = 2.9516  \n",
      "\n",
      "Fold: 7  Epoch: 491  Training loss = 2.7417  Validation loss = 2.9512  \n",
      "\n",
      "Fold: 7  Epoch: 492  Training loss = 2.7415  Validation loss = 2.9509  \n",
      "\n",
      "Fold: 7  Epoch: 493  Training loss = 2.7414  Validation loss = 2.9507  \n",
      "\n",
      "Fold: 7  Epoch: 494  Training loss = 2.7411  Validation loss = 2.9503  \n",
      "\n",
      "Fold: 7  Epoch: 495  Training loss = 2.7409  Validation loss = 2.9499  \n",
      "\n",
      "Fold: 7  Epoch: 496  Training loss = 2.7407  Validation loss = 2.9495  \n",
      "\n",
      "Fold: 7  Epoch: 497  Training loss = 2.7405  Validation loss = 2.9492  \n",
      "\n",
      "Fold: 7  Epoch: 498  Training loss = 2.7403  Validation loss = 2.9489  \n",
      "\n",
      "Fold: 7  Epoch: 499  Training loss = 2.7401  Validation loss = 2.9486  \n",
      "\n",
      "Fold: 7  Epoch: 500  Training loss = 2.7399  Validation loss = 2.9483  \n",
      "\n",
      "Check model:  Fold: 7  Optimal epoch: 500  \n",
      "\n",
      "Fold: 8  Epoch: 1  Training loss = 2.7841  Validation loss = 7.7320  \n",
      "\n",
      "Fold: 8  Epoch: 2  Training loss = 2.7839  Validation loss = 7.7317  \n",
      "\n",
      "Fold: 8  Epoch: 3  Training loss = 2.7836  Validation loss = 7.7314  \n",
      "\n",
      "Fold: 8  Epoch: 4  Training loss = 2.7834  Validation loss = 7.7311  \n",
      "\n",
      "Fold: 8  Epoch: 5  Training loss = 2.7831  Validation loss = 7.7307  \n",
      "\n",
      "Fold: 8  Epoch: 6  Training loss = 2.7829  Validation loss = 7.7304  \n",
      "\n",
      "Fold: 8  Epoch: 7  Training loss = 2.7827  Validation loss = 7.7301  \n",
      "\n",
      "Fold: 8  Epoch: 8  Training loss = 2.7824  Validation loss = 7.7297  \n",
      "\n",
      "Fold: 8  Epoch: 9  Training loss = 2.7821  Validation loss = 7.7294  \n",
      "\n",
      "Fold: 8  Epoch: 10  Training loss = 2.7819  Validation loss = 7.7290  \n",
      "\n",
      "Fold: 8  Epoch: 11  Training loss = 2.7816  Validation loss = 7.7287  \n",
      "\n",
      "Fold: 8  Epoch: 12  Training loss = 2.7814  Validation loss = 7.7284  \n",
      "\n",
      "Fold: 8  Epoch: 13  Training loss = 2.7811  Validation loss = 7.7280  \n",
      "\n",
      "Fold: 8  Epoch: 14  Training loss = 2.7809  Validation loss = 7.7277  \n",
      "\n",
      "Fold: 8  Epoch: 15  Training loss = 2.7806  Validation loss = 7.7274  \n",
      "\n",
      "Fold: 8  Epoch: 16  Training loss = 2.7804  Validation loss = 7.7271  \n",
      "\n",
      "Fold: 8  Epoch: 17  Training loss = 2.7802  Validation loss = 7.7268  \n",
      "\n",
      "Fold: 8  Epoch: 18  Training loss = 2.7799  Validation loss = 7.7265  \n",
      "\n",
      "Fold: 8  Epoch: 19  Training loss = 2.7798  Validation loss = 7.7262  \n",
      "\n",
      "Fold: 8  Epoch: 20  Training loss = 2.7795  Validation loss = 7.7259  \n",
      "\n",
      "Fold: 8  Epoch: 21  Training loss = 2.7792  Validation loss = 7.7255  \n",
      "\n",
      "Fold: 8  Epoch: 22  Training loss = 2.7790  Validation loss = 7.7252  \n",
      "\n",
      "Fold: 8  Epoch: 23  Training loss = 2.7788  Validation loss = 7.7250  \n",
      "\n",
      "Fold: 8  Epoch: 24  Training loss = 2.7786  Validation loss = 7.7247  \n",
      "\n",
      "Fold: 8  Epoch: 25  Training loss = 2.7784  Validation loss = 7.7244  \n",
      "\n",
      "Fold: 8  Epoch: 26  Training loss = 2.7782  Validation loss = 7.7241  \n",
      "\n",
      "Fold: 8  Epoch: 27  Training loss = 2.7779  Validation loss = 7.7238  \n",
      "\n",
      "Fold: 8  Epoch: 28  Training loss = 2.7777  Validation loss = 7.7235  \n",
      "\n",
      "Fold: 8  Epoch: 29  Training loss = 2.7774  Validation loss = 7.7231  \n",
      "\n",
      "Fold: 8  Epoch: 30  Training loss = 2.7772  Validation loss = 7.7228  \n",
      "\n",
      "Fold: 8  Epoch: 31  Training loss = 2.7770  Validation loss = 7.7225  \n",
      "\n",
      "Fold: 8  Epoch: 32  Training loss = 2.7767  Validation loss = 7.7222  \n",
      "\n",
      "Fold: 8  Epoch: 33  Training loss = 2.7765  Validation loss = 7.7219  \n",
      "\n",
      "Fold: 8  Epoch: 34  Training loss = 2.7762  Validation loss = 7.7215  \n",
      "\n",
      "Fold: 8  Epoch: 35  Training loss = 2.7759  Validation loss = 7.7212  \n",
      "\n",
      "Fold: 8  Epoch: 36  Training loss = 2.7757  Validation loss = 7.7209  \n",
      "\n",
      "Fold: 8  Epoch: 37  Training loss = 2.7755  Validation loss = 7.7206  \n",
      "\n",
      "Fold: 8  Epoch: 38  Training loss = 2.7753  Validation loss = 7.7203  \n",
      "\n",
      "Fold: 8  Epoch: 39  Training loss = 2.7750  Validation loss = 7.7199  \n",
      "\n",
      "Fold: 8  Epoch: 40  Training loss = 2.7747  Validation loss = 7.7196  \n",
      "\n",
      "Fold: 8  Epoch: 41  Training loss = 2.7745  Validation loss = 7.7193  \n",
      "\n",
      "Fold: 8  Epoch: 42  Training loss = 2.7743  Validation loss = 7.7190  \n",
      "\n",
      "Fold: 8  Epoch: 43  Training loss = 2.7740  Validation loss = 7.7186  \n",
      "\n",
      "Fold: 8  Epoch: 44  Training loss = 2.7737  Validation loss = 7.7183  \n",
      "\n",
      "Fold: 8  Epoch: 45  Training loss = 2.7735  Validation loss = 7.7180  \n",
      "\n",
      "Fold: 8  Epoch: 46  Training loss = 2.7733  Validation loss = 7.7177  \n",
      "\n",
      "Fold: 8  Epoch: 47  Training loss = 2.7730  Validation loss = 7.7173  \n",
      "\n",
      "Fold: 8  Epoch: 48  Training loss = 2.7728  Validation loss = 7.7170  \n",
      "\n",
      "Fold: 8  Epoch: 49  Training loss = 2.7726  Validation loss = 7.7168  \n",
      "\n",
      "Fold: 8  Epoch: 50  Training loss = 2.7724  Validation loss = 7.7165  \n",
      "\n",
      "Fold: 8  Epoch: 51  Training loss = 2.7722  Validation loss = 7.7162  \n",
      "\n",
      "Fold: 8  Epoch: 52  Training loss = 2.7719  Validation loss = 7.7159  \n",
      "\n",
      "Fold: 8  Epoch: 53  Training loss = 2.7717  Validation loss = 7.7155  \n",
      "\n",
      "Fold: 8  Epoch: 54  Training loss = 2.7715  Validation loss = 7.7153  \n",
      "\n",
      "Fold: 8  Epoch: 55  Training loss = 2.7713  Validation loss = 7.7150  \n",
      "\n",
      "Fold: 8  Epoch: 56  Training loss = 2.7710  Validation loss = 7.7146  \n",
      "\n",
      "Fold: 8  Epoch: 57  Training loss = 2.7708  Validation loss = 7.7143  \n",
      "\n",
      "Fold: 8  Epoch: 58  Training loss = 2.7705  Validation loss = 7.7140  \n",
      "\n",
      "Fold: 8  Epoch: 59  Training loss = 2.7703  Validation loss = 7.7137  \n",
      "\n",
      "Fold: 8  Epoch: 60  Training loss = 2.7700  Validation loss = 7.7134  \n",
      "\n",
      "Fold: 8  Epoch: 61  Training loss = 2.7698  Validation loss = 7.7131  \n",
      "\n",
      "Fold: 8  Epoch: 62  Training loss = 2.7696  Validation loss = 7.7127  \n",
      "\n",
      "Fold: 8  Epoch: 63  Training loss = 2.7693  Validation loss = 7.7124  \n",
      "\n",
      "Fold: 8  Epoch: 64  Training loss = 2.7690  Validation loss = 7.7120  \n",
      "\n",
      "Fold: 8  Epoch: 65  Training loss = 2.7688  Validation loss = 7.7117  \n",
      "\n",
      "Fold: 8  Epoch: 66  Training loss = 2.7686  Validation loss = 7.7114  \n",
      "\n",
      "Fold: 8  Epoch: 67  Training loss = 2.7683  Validation loss = 7.7111  \n",
      "\n",
      "Fold: 8  Epoch: 68  Training loss = 2.7681  Validation loss = 7.7108  \n",
      "\n",
      "Fold: 8  Epoch: 69  Training loss = 2.7678  Validation loss = 7.7104  \n",
      "\n",
      "Fold: 8  Epoch: 70  Training loss = 2.7676  Validation loss = 7.7101  \n",
      "\n",
      "Fold: 8  Epoch: 71  Training loss = 2.7673  Validation loss = 7.7097  \n",
      "\n",
      "Fold: 8  Epoch: 72  Training loss = 2.7670  Validation loss = 7.7094  \n",
      "\n",
      "Fold: 8  Epoch: 73  Training loss = 2.7667  Validation loss = 7.7090  \n",
      "\n",
      "Fold: 8  Epoch: 74  Training loss = 2.7665  Validation loss = 7.7087  \n",
      "\n",
      "Fold: 8  Epoch: 75  Training loss = 2.7662  Validation loss = 7.7084  \n",
      "\n",
      "Fold: 8  Epoch: 76  Training loss = 2.7660  Validation loss = 7.7080  \n",
      "\n",
      "Fold: 8  Epoch: 77  Training loss = 2.7657  Validation loss = 7.7076  \n",
      "\n",
      "Fold: 8  Epoch: 78  Training loss = 2.7654  Validation loss = 7.7073  \n",
      "\n",
      "Fold: 8  Epoch: 79  Training loss = 2.7652  Validation loss = 7.7070  \n",
      "\n",
      "Fold: 8  Epoch: 80  Training loss = 2.7650  Validation loss = 7.7067  \n",
      "\n",
      "Fold: 8  Epoch: 81  Training loss = 2.7648  Validation loss = 7.7064  \n",
      "\n",
      "Fold: 8  Epoch: 82  Training loss = 2.7645  Validation loss = 7.7061  \n",
      "\n",
      "Fold: 8  Epoch: 83  Training loss = 2.7642  Validation loss = 7.7057  \n",
      "\n",
      "Fold: 8  Epoch: 84  Training loss = 2.7640  Validation loss = 7.7054  \n",
      "\n",
      "Fold: 8  Epoch: 85  Training loss = 2.7637  Validation loss = 7.7050  \n",
      "\n",
      "Fold: 8  Epoch: 86  Training loss = 2.7634  Validation loss = 7.7047  \n",
      "\n",
      "Fold: 8  Epoch: 87  Training loss = 2.7632  Validation loss = 7.7043  \n",
      "\n",
      "Fold: 8  Epoch: 88  Training loss = 2.7629  Validation loss = 7.7040  \n",
      "\n",
      "Fold: 8  Epoch: 89  Training loss = 2.7626  Validation loss = 7.7036  \n",
      "\n",
      "Fold: 8  Epoch: 90  Training loss = 2.7624  Validation loss = 7.7033  \n",
      "\n",
      "Fold: 8  Epoch: 91  Training loss = 2.7621  Validation loss = 7.7030  \n",
      "\n",
      "Fold: 8  Epoch: 92  Training loss = 2.7619  Validation loss = 7.7027  \n",
      "\n",
      "Fold: 8  Epoch: 93  Training loss = 2.7616  Validation loss = 7.7024  \n",
      "\n",
      "Fold: 8  Epoch: 94  Training loss = 2.7614  Validation loss = 7.7020  \n",
      "\n",
      "Fold: 8  Epoch: 95  Training loss = 2.7612  Validation loss = 7.7018  \n",
      "\n",
      "Fold: 8  Epoch: 96  Training loss = 2.7610  Validation loss = 7.7015  \n",
      "\n",
      "Fold: 8  Epoch: 97  Training loss = 2.7607  Validation loss = 7.7012  \n",
      "\n",
      "Fold: 8  Epoch: 98  Training loss = 2.7605  Validation loss = 7.7008  \n",
      "\n",
      "Fold: 8  Epoch: 99  Training loss = 2.7603  Validation loss = 7.7005  \n",
      "\n",
      "Fold: 8  Epoch: 100  Training loss = 2.7600  Validation loss = 7.7001  \n",
      "\n",
      "Fold: 8  Epoch: 101  Training loss = 2.7597  Validation loss = 7.6998  \n",
      "\n",
      "Fold: 8  Epoch: 102  Training loss = 2.7594  Validation loss = 7.6994  \n",
      "\n",
      "Fold: 8  Epoch: 103  Training loss = 2.7592  Validation loss = 7.6991  \n",
      "\n",
      "Fold: 8  Epoch: 104  Training loss = 2.7590  Validation loss = 7.6988  \n",
      "\n",
      "Fold: 8  Epoch: 105  Training loss = 2.7587  Validation loss = 7.6984  \n",
      "\n",
      "Fold: 8  Epoch: 106  Training loss = 2.7584  Validation loss = 7.6981  \n",
      "\n",
      "Fold: 8  Epoch: 107  Training loss = 2.7582  Validation loss = 7.6978  \n",
      "\n",
      "Fold: 8  Epoch: 108  Training loss = 2.7580  Validation loss = 7.6974  \n",
      "\n",
      "Fold: 8  Epoch: 109  Training loss = 2.7577  Validation loss = 7.6971  \n",
      "\n",
      "Fold: 8  Epoch: 110  Training loss = 2.7575  Validation loss = 7.6968  \n",
      "\n",
      "Fold: 8  Epoch: 111  Training loss = 2.7572  Validation loss = 7.6964  \n",
      "\n",
      "Fold: 8  Epoch: 112  Training loss = 2.7569  Validation loss = 7.6961  \n",
      "\n",
      "Fold: 8  Epoch: 113  Training loss = 2.7567  Validation loss = 7.6957  \n",
      "\n",
      "Fold: 8  Epoch: 114  Training loss = 2.7564  Validation loss = 7.6954  \n",
      "\n",
      "Fold: 8  Epoch: 115  Training loss = 2.7562  Validation loss = 7.6951  \n",
      "\n",
      "Fold: 8  Epoch: 116  Training loss = 2.7560  Validation loss = 7.6948  \n",
      "\n",
      "Fold: 8  Epoch: 117  Training loss = 2.7558  Validation loss = 7.6945  \n",
      "\n",
      "Fold: 8  Epoch: 118  Training loss = 2.7555  Validation loss = 7.6942  \n",
      "\n",
      "Fold: 8  Epoch: 119  Training loss = 2.7552  Validation loss = 7.6938  \n",
      "\n",
      "Fold: 8  Epoch: 120  Training loss = 2.7550  Validation loss = 7.6935  \n",
      "\n",
      "Fold: 8  Epoch: 121  Training loss = 2.7547  Validation loss = 7.6932  \n",
      "\n",
      "Fold: 8  Epoch: 122  Training loss = 2.7545  Validation loss = 7.6929  \n",
      "\n",
      "Fold: 8  Epoch: 123  Training loss = 2.7543  Validation loss = 7.6926  \n",
      "\n",
      "Fold: 8  Epoch: 124  Training loss = 2.7541  Validation loss = 7.6923  \n",
      "\n",
      "Fold: 8  Epoch: 125  Training loss = 2.7539  Validation loss = 7.6920  \n",
      "\n",
      "Fold: 8  Epoch: 126  Training loss = 2.7536  Validation loss = 7.6917  \n",
      "\n",
      "Fold: 8  Epoch: 127  Training loss = 2.7534  Validation loss = 7.6914  \n",
      "\n",
      "Fold: 8  Epoch: 128  Training loss = 2.7532  Validation loss = 7.6911  \n",
      "\n",
      "Fold: 8  Epoch: 129  Training loss = 2.7529  Validation loss = 7.6908  \n",
      "\n",
      "Fold: 8  Epoch: 130  Training loss = 2.7527  Validation loss = 7.6904  \n",
      "\n",
      "Fold: 8  Epoch: 131  Training loss = 2.7525  Validation loss = 7.6902  \n",
      "\n",
      "Fold: 8  Epoch: 132  Training loss = 2.7522  Validation loss = 7.6899  \n",
      "\n",
      "Fold: 8  Epoch: 133  Training loss = 2.7520  Validation loss = 7.6895  \n",
      "\n",
      "Fold: 8  Epoch: 134  Training loss = 2.7518  Validation loss = 7.6892  \n",
      "\n",
      "Fold: 8  Epoch: 135  Training loss = 2.7515  Validation loss = 7.6889  \n",
      "\n",
      "Fold: 8  Epoch: 136  Training loss = 2.7513  Validation loss = 7.6886  \n",
      "\n",
      "Fold: 8  Epoch: 137  Training loss = 2.7510  Validation loss = 7.6883  \n",
      "\n",
      "Fold: 8  Epoch: 138  Training loss = 2.7508  Validation loss = 7.6879  \n",
      "\n",
      "Fold: 8  Epoch: 139  Training loss = 2.7505  Validation loss = 7.6876  \n",
      "\n",
      "Fold: 8  Epoch: 140  Training loss = 2.7503  Validation loss = 7.6873  \n",
      "\n",
      "Fold: 8  Epoch: 141  Training loss = 2.7501  Validation loss = 7.6870  \n",
      "\n",
      "Fold: 8  Epoch: 142  Training loss = 2.7498  Validation loss = 7.6866  \n",
      "\n",
      "Fold: 8  Epoch: 143  Training loss = 2.7496  Validation loss = 7.6863  \n",
      "\n",
      "Fold: 8  Epoch: 144  Training loss = 2.7493  Validation loss = 7.6859  \n",
      "\n",
      "Fold: 8  Epoch: 145  Training loss = 2.7491  Validation loss = 7.6856  \n",
      "\n",
      "Fold: 8  Epoch: 146  Training loss = 2.7489  Validation loss = 7.6854  \n",
      "\n",
      "Fold: 8  Epoch: 147  Training loss = 2.7486  Validation loss = 7.6850  \n",
      "\n",
      "Fold: 8  Epoch: 148  Training loss = 2.7484  Validation loss = 7.6847  \n",
      "\n",
      "Fold: 8  Epoch: 149  Training loss = 2.7482  Validation loss = 7.6844  \n",
      "\n",
      "Fold: 8  Epoch: 150  Training loss = 2.7479  Validation loss = 7.6841  \n",
      "\n",
      "Fold: 8  Epoch: 151  Training loss = 2.7477  Validation loss = 7.6837  \n",
      "\n",
      "Fold: 8  Epoch: 152  Training loss = 2.7474  Validation loss = 7.6834  \n",
      "\n",
      "Fold: 8  Epoch: 153  Training loss = 2.7472  Validation loss = 7.6831  \n",
      "\n",
      "Fold: 8  Epoch: 154  Training loss = 2.7469  Validation loss = 7.6827  \n",
      "\n",
      "Fold: 8  Epoch: 155  Training loss = 2.7467  Validation loss = 7.6824  \n",
      "\n",
      "Fold: 8  Epoch: 156  Training loss = 2.7465  Validation loss = 7.6822  \n",
      "\n",
      "Fold: 8  Epoch: 157  Training loss = 2.7463  Validation loss = 7.6819  \n",
      "\n",
      "Fold: 8  Epoch: 158  Training loss = 2.7461  Validation loss = 7.6816  \n",
      "\n",
      "Fold: 8  Epoch: 159  Training loss = 2.7458  Validation loss = 7.6813  \n",
      "\n",
      "Fold: 8  Epoch: 160  Training loss = 2.7456  Validation loss = 7.6810  \n",
      "\n",
      "Fold: 8  Epoch: 161  Training loss = 2.7454  Validation loss = 7.6807  \n",
      "\n",
      "Fold: 8  Epoch: 162  Training loss = 2.7452  Validation loss = 7.6804  \n",
      "\n",
      "Fold: 8  Epoch: 163  Training loss = 2.7449  Validation loss = 7.6801  \n",
      "\n",
      "Fold: 8  Epoch: 164  Training loss = 2.7447  Validation loss = 7.6797  \n",
      "\n",
      "Fold: 8  Epoch: 165  Training loss = 2.7444  Validation loss = 7.6794  \n",
      "\n",
      "Fold: 8  Epoch: 166  Training loss = 2.7442  Validation loss = 7.6791  \n",
      "\n",
      "Fold: 8  Epoch: 167  Training loss = 2.7440  Validation loss = 7.6788  \n",
      "\n",
      "Fold: 8  Epoch: 168  Training loss = 2.7438  Validation loss = 7.6785  \n",
      "\n",
      "Fold: 8  Epoch: 169  Training loss = 2.7435  Validation loss = 7.6781  \n",
      "\n",
      "Fold: 8  Epoch: 170  Training loss = 2.7432  Validation loss = 7.6778  \n",
      "\n",
      "Fold: 8  Epoch: 171  Training loss = 2.7429  Validation loss = 7.6774  \n",
      "\n",
      "Fold: 8  Epoch: 172  Training loss = 2.7427  Validation loss = 7.6771  \n",
      "\n",
      "Fold: 8  Epoch: 173  Training loss = 2.7424  Validation loss = 7.6768  \n",
      "\n",
      "Fold: 8  Epoch: 174  Training loss = 2.7422  Validation loss = 7.6765  \n",
      "\n",
      "Fold: 8  Epoch: 175  Training loss = 2.7420  Validation loss = 7.6762  \n",
      "\n",
      "Fold: 8  Epoch: 176  Training loss = 2.7417  Validation loss = 7.6758  \n",
      "\n",
      "Fold: 8  Epoch: 177  Training loss = 2.7415  Validation loss = 7.6755  \n",
      "\n",
      "Fold: 8  Epoch: 178  Training loss = 2.7413  Validation loss = 7.6752  \n",
      "\n",
      "Fold: 8  Epoch: 179  Training loss = 2.7410  Validation loss = 7.6749  \n",
      "\n",
      "Fold: 8  Epoch: 180  Training loss = 2.7408  Validation loss = 7.6745  \n",
      "\n",
      "Fold: 8  Epoch: 181  Training loss = 2.7405  Validation loss = 7.6742  \n",
      "\n",
      "Fold: 8  Epoch: 182  Training loss = 2.7403  Validation loss = 7.6739  \n",
      "\n",
      "Fold: 8  Epoch: 183  Training loss = 2.7401  Validation loss = 7.6736  \n",
      "\n",
      "Fold: 8  Epoch: 184  Training loss = 2.7398  Validation loss = 7.6733  \n",
      "\n",
      "Fold: 8  Epoch: 185  Training loss = 2.7396  Validation loss = 7.6730  \n",
      "\n",
      "Fold: 8  Epoch: 186  Training loss = 2.7394  Validation loss = 7.6727  \n",
      "\n",
      "Fold: 8  Epoch: 187  Training loss = 2.7392  Validation loss = 7.6725  \n",
      "\n",
      "Fold: 8  Epoch: 188  Training loss = 2.7390  Validation loss = 7.6722  \n",
      "\n",
      "Fold: 8  Epoch: 189  Training loss = 2.7388  Validation loss = 7.6719  \n",
      "\n",
      "Fold: 8  Epoch: 190  Training loss = 2.7386  Validation loss = 7.6716  \n",
      "\n",
      "Fold: 8  Epoch: 191  Training loss = 2.7383  Validation loss = 7.6713  \n",
      "\n",
      "Fold: 8  Epoch: 192  Training loss = 2.7380  Validation loss = 7.6709  \n",
      "\n",
      "Fold: 8  Epoch: 193  Training loss = 2.7377  Validation loss = 7.6705  \n",
      "\n",
      "Fold: 8  Epoch: 194  Training loss = 2.7376  Validation loss = 7.6703  \n",
      "\n",
      "Fold: 8  Epoch: 195  Training loss = 2.7373  Validation loss = 7.6700  \n",
      "\n",
      "Fold: 8  Epoch: 196  Training loss = 2.7371  Validation loss = 7.6697  \n",
      "\n",
      "Fold: 8  Epoch: 197  Training loss = 2.7368  Validation loss = 7.6694  \n",
      "\n",
      "Fold: 8  Epoch: 198  Training loss = 2.7366  Validation loss = 7.6690  \n",
      "\n",
      "Fold: 8  Epoch: 199  Training loss = 2.7364  Validation loss = 7.6687  \n",
      "\n",
      "Fold: 8  Epoch: 200  Training loss = 2.7361  Validation loss = 7.6684  \n",
      "\n",
      "Fold: 8  Epoch: 201  Training loss = 2.7359  Validation loss = 7.6681  \n",
      "\n",
      "Fold: 8  Epoch: 202  Training loss = 2.7356  Validation loss = 7.6678  \n",
      "\n",
      "Fold: 8  Epoch: 203  Training loss = 2.7354  Validation loss = 7.6675  \n",
      "\n",
      "Fold: 8  Epoch: 204  Training loss = 2.7351  Validation loss = 7.6671  \n",
      "\n",
      "Fold: 8  Epoch: 205  Training loss = 2.7349  Validation loss = 7.6668  \n",
      "\n",
      "Fold: 8  Epoch: 206  Training loss = 2.7346  Validation loss = 7.6665  \n",
      "\n",
      "Fold: 8  Epoch: 207  Training loss = 2.7344  Validation loss = 7.6662  \n",
      "\n",
      "Fold: 8  Epoch: 208  Training loss = 2.7342  Validation loss = 7.6659  \n",
      "\n",
      "Fold: 8  Epoch: 209  Training loss = 2.7340  Validation loss = 7.6656  \n",
      "\n",
      "Fold: 8  Epoch: 210  Training loss = 2.7337  Validation loss = 7.6653  \n",
      "\n",
      "Fold: 8  Epoch: 211  Training loss = 2.7334  Validation loss = 7.6649  \n",
      "\n",
      "Fold: 8  Epoch: 212  Training loss = 2.7332  Validation loss = 7.6646  \n",
      "\n",
      "Fold: 8  Epoch: 213  Training loss = 2.7330  Validation loss = 7.6643  \n",
      "\n",
      "Fold: 8  Epoch: 214  Training loss = 2.7327  Validation loss = 7.6640  \n",
      "\n",
      "Fold: 8  Epoch: 215  Training loss = 2.7325  Validation loss = 7.6637  \n",
      "\n",
      "Fold: 8  Epoch: 216  Training loss = 2.7322  Validation loss = 7.6634  \n",
      "\n",
      "Fold: 8  Epoch: 217  Training loss = 2.7320  Validation loss = 7.6630  \n",
      "\n",
      "Fold: 8  Epoch: 218  Training loss = 2.7317  Validation loss = 7.6627  \n",
      "\n",
      "Fold: 8  Epoch: 219  Training loss = 2.7315  Validation loss = 7.6624  \n",
      "\n",
      "Fold: 8  Epoch: 220  Training loss = 2.7313  Validation loss = 7.6621  \n",
      "\n",
      "Fold: 8  Epoch: 221  Training loss = 2.7311  Validation loss = 7.6618  \n",
      "\n",
      "Fold: 8  Epoch: 222  Training loss = 2.7308  Validation loss = 7.6615  \n",
      "\n",
      "Fold: 8  Epoch: 223  Training loss = 2.7306  Validation loss = 7.6611  \n",
      "\n",
      "Fold: 8  Epoch: 224  Training loss = 2.7303  Validation loss = 7.6608  \n",
      "\n",
      "Fold: 8  Epoch: 225  Training loss = 2.7301  Validation loss = 7.6605  \n",
      "\n",
      "Fold: 8  Epoch: 226  Training loss = 2.7299  Validation loss = 7.6602  \n",
      "\n",
      "Fold: 8  Epoch: 227  Training loss = 2.7297  Validation loss = 7.6600  \n",
      "\n",
      "Fold: 8  Epoch: 228  Training loss = 2.7295  Validation loss = 7.6597  \n",
      "\n",
      "Fold: 8  Epoch: 229  Training loss = 2.7292  Validation loss = 7.6594  \n",
      "\n",
      "Fold: 8  Epoch: 230  Training loss = 2.7290  Validation loss = 7.6591  \n",
      "\n",
      "Fold: 8  Epoch: 231  Training loss = 2.7288  Validation loss = 7.6588  \n",
      "\n",
      "Fold: 8  Epoch: 232  Training loss = 2.7286  Validation loss = 7.6585  \n",
      "\n",
      "Fold: 8  Epoch: 233  Training loss = 2.7284  Validation loss = 7.6582  \n",
      "\n",
      "Fold: 8  Epoch: 234  Training loss = 2.7282  Validation loss = 7.6579  \n",
      "\n",
      "Fold: 8  Epoch: 235  Training loss = 2.7279  Validation loss = 7.6576  \n",
      "\n",
      "Fold: 8  Epoch: 236  Training loss = 2.7277  Validation loss = 7.6574  \n",
      "\n",
      "Fold: 8  Epoch: 237  Training loss = 2.7275  Validation loss = 7.6571  \n",
      "\n",
      "Fold: 8  Epoch: 238  Training loss = 2.7273  Validation loss = 7.6568  \n",
      "\n",
      "Fold: 8  Epoch: 239  Training loss = 2.7271  Validation loss = 7.6566  \n",
      "\n",
      "Fold: 8  Epoch: 240  Training loss = 2.7269  Validation loss = 7.6563  \n",
      "\n",
      "Fold: 8  Epoch: 241  Training loss = 2.7267  Validation loss = 7.6560  \n",
      "\n",
      "Fold: 8  Epoch: 242  Training loss = 2.7265  Validation loss = 7.6557  \n",
      "\n",
      "Fold: 8  Epoch: 243  Training loss = 2.7263  Validation loss = 7.6554  \n",
      "\n",
      "Fold: 8  Epoch: 244  Training loss = 2.7260  Validation loss = 7.6551  \n",
      "\n",
      "Fold: 8  Epoch: 245  Training loss = 2.7258  Validation loss = 7.6548  \n",
      "\n",
      "Fold: 8  Epoch: 246  Training loss = 2.7256  Validation loss = 7.6545  \n",
      "\n",
      "Fold: 8  Epoch: 247  Training loss = 2.7254  Validation loss = 7.6542  \n",
      "\n",
      "Fold: 8  Epoch: 248  Training loss = 2.7251  Validation loss = 7.6539  \n",
      "\n",
      "Fold: 8  Epoch: 249  Training loss = 2.7249  Validation loss = 7.6536  \n",
      "\n",
      "Fold: 8  Epoch: 250  Training loss = 2.7246  Validation loss = 7.6532  \n",
      "\n",
      "Fold: 8  Epoch: 251  Training loss = 2.7244  Validation loss = 7.6529  \n",
      "\n",
      "Fold: 8  Epoch: 252  Training loss = 2.7241  Validation loss = 7.6526  \n",
      "\n",
      "Fold: 8  Epoch: 253  Training loss = 2.7239  Validation loss = 7.6523  \n",
      "\n",
      "Fold: 8  Epoch: 254  Training loss = 2.7237  Validation loss = 7.6520  \n",
      "\n",
      "Fold: 8  Epoch: 255  Training loss = 2.7234  Validation loss = 7.6517  \n",
      "\n",
      "Fold: 8  Epoch: 256  Training loss = 2.7232  Validation loss = 7.6513  \n",
      "\n",
      "Fold: 8  Epoch: 257  Training loss = 2.7229  Validation loss = 7.6510  \n",
      "\n",
      "Fold: 8  Epoch: 258  Training loss = 2.7227  Validation loss = 7.6507  \n",
      "\n",
      "Fold: 8  Epoch: 259  Training loss = 2.7225  Validation loss = 7.6504  \n",
      "\n",
      "Fold: 8  Epoch: 260  Training loss = 2.7223  Validation loss = 7.6501  \n",
      "\n",
      "Fold: 8  Epoch: 261  Training loss = 2.7221  Validation loss = 7.6498  \n",
      "\n",
      "Fold: 8  Epoch: 262  Training loss = 2.7219  Validation loss = 7.6495  \n",
      "\n",
      "Fold: 8  Epoch: 263  Training loss = 2.7216  Validation loss = 7.6492  \n",
      "\n",
      "Fold: 8  Epoch: 264  Training loss = 2.7214  Validation loss = 7.6489  \n",
      "\n",
      "Fold: 8  Epoch: 265  Training loss = 2.7211  Validation loss = 7.6486  \n",
      "\n",
      "Fold: 8  Epoch: 266  Training loss = 2.7209  Validation loss = 7.6482  \n",
      "\n",
      "Fold: 8  Epoch: 267  Training loss = 2.7206  Validation loss = 7.6479  \n",
      "\n",
      "Fold: 8  Epoch: 268  Training loss = 2.7204  Validation loss = 7.6476  \n",
      "\n",
      "Fold: 8  Epoch: 269  Training loss = 2.7202  Validation loss = 7.6473  \n",
      "\n",
      "Fold: 8  Epoch: 270  Training loss = 2.7200  Validation loss = 7.6470  \n",
      "\n",
      "Fold: 8  Epoch: 271  Training loss = 2.7198  Validation loss = 7.6467  \n",
      "\n",
      "Fold: 8  Epoch: 272  Training loss = 2.7196  Validation loss = 7.6464  \n",
      "\n",
      "Fold: 8  Epoch: 273  Training loss = 2.7193  Validation loss = 7.6460  \n",
      "\n",
      "Fold: 8  Epoch: 274  Training loss = 2.7190  Validation loss = 7.6457  \n",
      "\n",
      "Fold: 8  Epoch: 275  Training loss = 2.7188  Validation loss = 7.6454  \n",
      "\n",
      "Fold: 8  Epoch: 276  Training loss = 2.7185  Validation loss = 7.6451  \n",
      "\n",
      "Fold: 8  Epoch: 277  Training loss = 2.7183  Validation loss = 7.6448  \n",
      "\n",
      "Fold: 8  Epoch: 278  Training loss = 2.7181  Validation loss = 7.6445  \n",
      "\n",
      "Fold: 8  Epoch: 279  Training loss = 2.7178  Validation loss = 7.6441  \n",
      "\n",
      "Fold: 8  Epoch: 280  Training loss = 2.7176  Validation loss = 7.6438  \n",
      "\n",
      "Fold: 8  Epoch: 281  Training loss = 2.7174  Validation loss = 7.6435  \n",
      "\n",
      "Fold: 8  Epoch: 282  Training loss = 2.7172  Validation loss = 7.6433  \n",
      "\n",
      "Fold: 8  Epoch: 283  Training loss = 2.7170  Validation loss = 7.6430  \n",
      "\n",
      "Fold: 8  Epoch: 284  Training loss = 2.7167  Validation loss = 7.6427  \n",
      "\n",
      "Fold: 8  Epoch: 285  Training loss = 2.7166  Validation loss = 7.6424  \n",
      "\n",
      "Fold: 8  Epoch: 286  Training loss = 2.7163  Validation loss = 7.6421  \n",
      "\n",
      "Fold: 8  Epoch: 287  Training loss = 2.7161  Validation loss = 7.6418  \n",
      "\n",
      "Fold: 8  Epoch: 288  Training loss = 2.7158  Validation loss = 7.6414  \n",
      "\n",
      "Fold: 8  Epoch: 289  Training loss = 2.7156  Validation loss = 7.6412  \n",
      "\n",
      "Fold: 8  Epoch: 290  Training loss = 2.7154  Validation loss = 7.6408  \n",
      "\n",
      "Fold: 8  Epoch: 291  Training loss = 2.7151  Validation loss = 7.6405  \n",
      "\n",
      "Fold: 8  Epoch: 292  Training loss = 2.7149  Validation loss = 7.6402  \n",
      "\n",
      "Fold: 8  Epoch: 293  Training loss = 2.7146  Validation loss = 7.6399  \n",
      "\n",
      "Fold: 8  Epoch: 294  Training loss = 2.7143  Validation loss = 7.6395  \n",
      "\n",
      "Fold: 8  Epoch: 295  Training loss = 2.7141  Validation loss = 7.6392  \n",
      "\n",
      "Fold: 8  Epoch: 296  Training loss = 2.7139  Validation loss = 7.6389  \n",
      "\n",
      "Fold: 8  Epoch: 297  Training loss = 2.7136  Validation loss = 7.6386  \n",
      "\n",
      "Fold: 8  Epoch: 298  Training loss = 2.7134  Validation loss = 7.6383  \n",
      "\n",
      "Fold: 8  Epoch: 299  Training loss = 2.7133  Validation loss = 7.6381  \n",
      "\n",
      "Fold: 8  Epoch: 300  Training loss = 2.7131  Validation loss = 7.6378  \n",
      "\n",
      "Fold: 8  Epoch: 301  Training loss = 2.7128  Validation loss = 7.6375  \n",
      "\n",
      "Fold: 8  Epoch: 302  Training loss = 2.7125  Validation loss = 7.6371  \n",
      "\n",
      "Fold: 8  Epoch: 303  Training loss = 2.7123  Validation loss = 7.6368  \n",
      "\n",
      "Fold: 8  Epoch: 304  Training loss = 2.7121  Validation loss = 7.6365  \n",
      "\n",
      "Fold: 8  Epoch: 305  Training loss = 2.7118  Validation loss = 7.6362  \n",
      "\n",
      "Fold: 8  Epoch: 306  Training loss = 2.7116  Validation loss = 7.6359  \n",
      "\n",
      "Fold: 8  Epoch: 307  Training loss = 2.7114  Validation loss = 7.6356  \n",
      "\n",
      "Fold: 8  Epoch: 308  Training loss = 2.7112  Validation loss = 7.6353  \n",
      "\n",
      "Fold: 8  Epoch: 309  Training loss = 2.7109  Validation loss = 7.6350  \n",
      "\n",
      "Fold: 8  Epoch: 310  Training loss = 2.7107  Validation loss = 7.6347  \n",
      "\n",
      "Fold: 8  Epoch: 311  Training loss = 2.7105  Validation loss = 7.6345  \n",
      "\n",
      "Fold: 8  Epoch: 312  Training loss = 2.7103  Validation loss = 7.6342  \n",
      "\n",
      "Fold: 8  Epoch: 313  Training loss = 2.7101  Validation loss = 7.6339  \n",
      "\n",
      "Fold: 8  Epoch: 314  Training loss = 2.7098  Validation loss = 7.6336  \n",
      "\n",
      "Fold: 8  Epoch: 315  Training loss = 2.7096  Validation loss = 7.6333  \n",
      "\n",
      "Fold: 8  Epoch: 316  Training loss = 2.7094  Validation loss = 7.6329  \n",
      "\n",
      "Fold: 8  Epoch: 317  Training loss = 2.7091  Validation loss = 7.6326  \n",
      "\n",
      "Fold: 8  Epoch: 318  Training loss = 2.7089  Validation loss = 7.6324  \n",
      "\n",
      "Fold: 8  Epoch: 319  Training loss = 2.7087  Validation loss = 7.6321  \n",
      "\n",
      "Fold: 8  Epoch: 320  Training loss = 2.7085  Validation loss = 7.6318  \n",
      "\n",
      "Fold: 8  Epoch: 321  Training loss = 2.7083  Validation loss = 7.6315  \n",
      "\n",
      "Fold: 8  Epoch: 322  Training loss = 2.7080  Validation loss = 7.6312  \n",
      "\n",
      "Fold: 8  Epoch: 323  Training loss = 2.7078  Validation loss = 7.6309  \n",
      "\n",
      "Fold: 8  Epoch: 324  Training loss = 2.7075  Validation loss = 7.6305  \n",
      "\n",
      "Fold: 8  Epoch: 325  Training loss = 2.7073  Validation loss = 7.6302  \n",
      "\n",
      "Fold: 8  Epoch: 326  Training loss = 2.7071  Validation loss = 7.6299  \n",
      "\n",
      "Fold: 8  Epoch: 327  Training loss = 2.7069  Validation loss = 7.6297  \n",
      "\n",
      "Fold: 8  Epoch: 328  Training loss = 2.7066  Validation loss = 7.6293  \n",
      "\n",
      "Fold: 8  Epoch: 329  Training loss = 2.7064  Validation loss = 7.6290  \n",
      "\n",
      "Fold: 8  Epoch: 330  Training loss = 2.7062  Validation loss = 7.6287  \n",
      "\n",
      "Fold: 8  Epoch: 331  Training loss = 2.7059  Validation loss = 7.6284  \n",
      "\n",
      "Fold: 8  Epoch: 332  Training loss = 2.7057  Validation loss = 7.6281  \n",
      "\n",
      "Fold: 8  Epoch: 333  Training loss = 2.7055  Validation loss = 7.6278  \n",
      "\n",
      "Fold: 8  Epoch: 334  Training loss = 2.7052  Validation loss = 7.6275  \n",
      "\n",
      "Fold: 8  Epoch: 335  Training loss = 2.7050  Validation loss = 7.6272  \n",
      "\n",
      "Fold: 8  Epoch: 336  Training loss = 2.7048  Validation loss = 7.6269  \n",
      "\n",
      "Fold: 8  Epoch: 337  Training loss = 2.7045  Validation loss = 7.6266  \n",
      "\n",
      "Fold: 8  Epoch: 338  Training loss = 2.7043  Validation loss = 7.6263  \n",
      "\n",
      "Fold: 8  Epoch: 339  Training loss = 2.7041  Validation loss = 7.6260  \n",
      "\n",
      "Fold: 8  Epoch: 340  Training loss = 2.7038  Validation loss = 7.6256  \n",
      "\n",
      "Fold: 8  Epoch: 341  Training loss = 2.7036  Validation loss = 7.6253  \n",
      "\n",
      "Fold: 8  Epoch: 342  Training loss = 2.7033  Validation loss = 7.6249  \n",
      "\n",
      "Fold: 8  Epoch: 343  Training loss = 2.7031  Validation loss = 7.6246  \n",
      "\n",
      "Fold: 8  Epoch: 344  Training loss = 2.7028  Validation loss = 7.6243  \n",
      "\n",
      "Fold: 8  Epoch: 345  Training loss = 2.7027  Validation loss = 7.6240  \n",
      "\n",
      "Fold: 8  Epoch: 346  Training loss = 2.7025  Validation loss = 7.6238  \n",
      "\n",
      "Fold: 8  Epoch: 347  Training loss = 2.7023  Validation loss = 7.6235  \n",
      "\n",
      "Fold: 8  Epoch: 348  Training loss = 2.7020  Validation loss = 7.6232  \n",
      "\n",
      "Fold: 8  Epoch: 349  Training loss = 2.7018  Validation loss = 7.6229  \n",
      "\n",
      "Fold: 8  Epoch: 350  Training loss = 2.7016  Validation loss = 7.6227  \n",
      "\n",
      "Fold: 8  Epoch: 351  Training loss = 2.7014  Validation loss = 7.6224  \n",
      "\n",
      "Fold: 8  Epoch: 352  Training loss = 2.7012  Validation loss = 7.6221  \n",
      "\n",
      "Fold: 8  Epoch: 353  Training loss = 2.7009  Validation loss = 7.6218  \n",
      "\n",
      "Fold: 8  Epoch: 354  Training loss = 2.7007  Validation loss = 7.6214  \n",
      "\n",
      "Fold: 8  Epoch: 355  Training loss = 2.7004  Validation loss = 7.6211  \n",
      "\n",
      "Fold: 8  Epoch: 356  Training loss = 2.7002  Validation loss = 7.6208  \n",
      "\n",
      "Fold: 8  Epoch: 357  Training loss = 2.7000  Validation loss = 7.6206  \n",
      "\n",
      "Fold: 8  Epoch: 358  Training loss = 2.6997  Validation loss = 7.6202  \n",
      "\n",
      "Fold: 8  Epoch: 359  Training loss = 2.6995  Validation loss = 7.6199  \n",
      "\n",
      "Fold: 8  Epoch: 360  Training loss = 2.6992  Validation loss = 7.6196  \n",
      "\n",
      "Fold: 8  Epoch: 361  Training loss = 2.6990  Validation loss = 7.6192  \n",
      "\n",
      "Fold: 8  Epoch: 362  Training loss = 2.6987  Validation loss = 7.6189  \n",
      "\n",
      "Fold: 8  Epoch: 363  Training loss = 2.6985  Validation loss = 7.6186  \n",
      "\n",
      "Fold: 8  Epoch: 364  Training loss = 2.6983  Validation loss = 7.6183  \n",
      "\n",
      "Fold: 8  Epoch: 365  Training loss = 2.6980  Validation loss = 7.6180  \n",
      "\n",
      "Fold: 8  Epoch: 366  Training loss = 2.6978  Validation loss = 7.6176  \n",
      "\n",
      "Fold: 8  Epoch: 367  Training loss = 2.6976  Validation loss = 7.6173  \n",
      "\n",
      "Fold: 8  Epoch: 368  Training loss = 2.6974  Validation loss = 7.6170  \n",
      "\n",
      "Fold: 8  Epoch: 369  Training loss = 2.6971  Validation loss = 7.6167  \n",
      "\n",
      "Fold: 8  Epoch: 370  Training loss = 2.6969  Validation loss = 7.6164  \n",
      "\n",
      "Fold: 8  Epoch: 371  Training loss = 2.6966  Validation loss = 7.6160  \n",
      "\n",
      "Fold: 8  Epoch: 372  Training loss = 2.6964  Validation loss = 7.6158  \n",
      "\n",
      "Fold: 8  Epoch: 373  Training loss = 2.6961  Validation loss = 7.6154  \n",
      "\n",
      "Fold: 8  Epoch: 374  Training loss = 2.6959  Validation loss = 7.6151  \n",
      "\n",
      "Fold: 8  Epoch: 375  Training loss = 2.6957  Validation loss = 7.6148  \n",
      "\n",
      "Fold: 8  Epoch: 376  Training loss = 2.6955  Validation loss = 7.6146  \n",
      "\n",
      "Fold: 8  Epoch: 377  Training loss = 2.6952  Validation loss = 7.6142  \n",
      "\n",
      "Fold: 8  Epoch: 378  Training loss = 2.6949  Validation loss = 7.6138  \n",
      "\n",
      "Fold: 8  Epoch: 379  Training loss = 2.6947  Validation loss = 7.6135  \n",
      "\n",
      "Fold: 8  Epoch: 380  Training loss = 2.6945  Validation loss = 7.6132  \n",
      "\n",
      "Fold: 8  Epoch: 381  Training loss = 2.6942  Validation loss = 7.6129  \n",
      "\n",
      "Fold: 8  Epoch: 382  Training loss = 2.6940  Validation loss = 7.6126  \n",
      "\n",
      "Fold: 8  Epoch: 383  Training loss = 2.6938  Validation loss = 7.6123  \n",
      "\n",
      "Fold: 8  Epoch: 384  Training loss = 2.6935  Validation loss = 7.6120  \n",
      "\n",
      "Fold: 8  Epoch: 385  Training loss = 2.6933  Validation loss = 7.6117  \n",
      "\n",
      "Fold: 8  Epoch: 386  Training loss = 2.6931  Validation loss = 7.6114  \n",
      "\n",
      "Fold: 8  Epoch: 387  Training loss = 2.6928  Validation loss = 7.6111  \n",
      "\n",
      "Fold: 8  Epoch: 388  Training loss = 2.6926  Validation loss = 7.6108  \n",
      "\n",
      "Fold: 8  Epoch: 389  Training loss = 2.6924  Validation loss = 7.6104  \n",
      "\n",
      "Fold: 8  Epoch: 390  Training loss = 2.6922  Validation loss = 7.6102  \n",
      "\n",
      "Fold: 8  Epoch: 391  Training loss = 2.6919  Validation loss = 7.6099  \n",
      "\n",
      "Fold: 8  Epoch: 392  Training loss = 2.6916  Validation loss = 7.6095  \n",
      "\n",
      "Fold: 8  Epoch: 393  Training loss = 2.6914  Validation loss = 7.6092  \n",
      "\n",
      "Fold: 8  Epoch: 394  Training loss = 2.6912  Validation loss = 7.6089  \n",
      "\n",
      "Fold: 8  Epoch: 395  Training loss = 2.6910  Validation loss = 7.6086  \n",
      "\n",
      "Fold: 8  Epoch: 396  Training loss = 2.6907  Validation loss = 7.6083  \n",
      "\n",
      "Fold: 8  Epoch: 397  Training loss = 2.6906  Validation loss = 7.6081  \n",
      "\n",
      "Fold: 8  Epoch: 398  Training loss = 2.6903  Validation loss = 7.6078  \n",
      "\n",
      "Fold: 8  Epoch: 399  Training loss = 2.6901  Validation loss = 7.6075  \n",
      "\n",
      "Fold: 8  Epoch: 400  Training loss = 2.6899  Validation loss = 7.6072  \n",
      "\n",
      "Fold: 8  Epoch: 401  Training loss = 2.6897  Validation loss = 7.6069  \n",
      "\n",
      "Fold: 8  Epoch: 402  Training loss = 2.6894  Validation loss = 7.6065  \n",
      "\n",
      "Fold: 8  Epoch: 403  Training loss = 2.6892  Validation loss = 7.6062  \n",
      "\n",
      "Fold: 8  Epoch: 404  Training loss = 2.6889  Validation loss = 7.6059  \n",
      "\n",
      "Fold: 8  Epoch: 405  Training loss = 2.6887  Validation loss = 7.6055  \n",
      "\n",
      "Fold: 8  Epoch: 406  Training loss = 2.6885  Validation loss = 7.6052  \n",
      "\n",
      "Fold: 8  Epoch: 407  Training loss = 2.6883  Validation loss = 7.6050  \n",
      "\n",
      "Fold: 8  Epoch: 408  Training loss = 2.6880  Validation loss = 7.6047  \n",
      "\n",
      "Fold: 8  Epoch: 409  Training loss = 2.6878  Validation loss = 7.6044  \n",
      "\n",
      "Fold: 8  Epoch: 410  Training loss = 2.6876  Validation loss = 7.6040  \n",
      "\n",
      "Fold: 8  Epoch: 411  Training loss = 2.6873  Validation loss = 7.6037  \n",
      "\n",
      "Fold: 8  Epoch: 412  Training loss = 2.6871  Validation loss = 7.6034  \n",
      "\n",
      "Fold: 8  Epoch: 413  Training loss = 2.6869  Validation loss = 7.6031  \n",
      "\n",
      "Fold: 8  Epoch: 414  Training loss = 2.6867  Validation loss = 7.6029  \n",
      "\n",
      "Fold: 8  Epoch: 415  Training loss = 2.6865  Validation loss = 7.6026  \n",
      "\n",
      "Fold: 8  Epoch: 416  Training loss = 2.6862  Validation loss = 7.6022  \n",
      "\n",
      "Fold: 8  Epoch: 417  Training loss = 2.6859  Validation loss = 7.6019  \n",
      "\n",
      "Fold: 8  Epoch: 418  Training loss = 2.6857  Validation loss = 7.6016  \n",
      "\n",
      "Fold: 8  Epoch: 419  Training loss = 2.6855  Validation loss = 7.6013  \n",
      "\n",
      "Fold: 8  Epoch: 420  Training loss = 2.6852  Validation loss = 7.6009  \n",
      "\n",
      "Fold: 8  Epoch: 421  Training loss = 2.6850  Validation loss = 7.6006  \n",
      "\n",
      "Fold: 8  Epoch: 422  Training loss = 2.6848  Validation loss = 7.6003  \n",
      "\n",
      "Fold: 8  Epoch: 423  Training loss = 2.6846  Validation loss = 7.6000  \n",
      "\n",
      "Fold: 8  Epoch: 424  Training loss = 2.6843  Validation loss = 7.5997  \n",
      "\n",
      "Fold: 8  Epoch: 425  Training loss = 2.6840  Validation loss = 7.5994  \n",
      "\n",
      "Fold: 8  Epoch: 426  Training loss = 2.6838  Validation loss = 7.5991  \n",
      "\n",
      "Fold: 8  Epoch: 427  Training loss = 2.6836  Validation loss = 7.5988  \n",
      "\n",
      "Fold: 8  Epoch: 428  Training loss = 2.6833  Validation loss = 7.5984  \n",
      "\n",
      "Fold: 8  Epoch: 429  Training loss = 2.6831  Validation loss = 7.5981  \n",
      "\n",
      "Fold: 8  Epoch: 430  Training loss = 2.6829  Validation loss = 7.5978  \n",
      "\n",
      "Fold: 8  Epoch: 431  Training loss = 2.6827  Validation loss = 7.5975  \n",
      "\n",
      "Fold: 8  Epoch: 432  Training loss = 2.6825  Validation loss = 7.5973  \n",
      "\n",
      "Fold: 8  Epoch: 433  Training loss = 2.6822  Validation loss = 7.5970  \n",
      "\n",
      "Fold: 8  Epoch: 434  Training loss = 2.6821  Validation loss = 7.5967  \n",
      "\n",
      "Fold: 8  Epoch: 435  Training loss = 2.6818  Validation loss = 7.5964  \n",
      "\n",
      "Fold: 8  Epoch: 436  Training loss = 2.6816  Validation loss = 7.5962  \n",
      "\n",
      "Fold: 8  Epoch: 437  Training loss = 2.6814  Validation loss = 7.5958  \n",
      "\n",
      "Fold: 8  Epoch: 438  Training loss = 2.6812  Validation loss = 7.5955  \n",
      "\n",
      "Fold: 8  Epoch: 439  Training loss = 2.6810  Validation loss = 7.5953  \n",
      "\n",
      "Fold: 8  Epoch: 440  Training loss = 2.6808  Validation loss = 7.5950  \n",
      "\n",
      "Fold: 8  Epoch: 441  Training loss = 2.6805  Validation loss = 7.5947  \n",
      "\n",
      "Fold: 8  Epoch: 442  Training loss = 2.6803  Validation loss = 7.5944  \n",
      "\n",
      "Fold: 8  Epoch: 443  Training loss = 2.6801  Validation loss = 7.5941  \n",
      "\n",
      "Fold: 8  Epoch: 444  Training loss = 2.6799  Validation loss = 7.5938  \n",
      "\n",
      "Fold: 8  Epoch: 445  Training loss = 2.6797  Validation loss = 7.5936  \n",
      "\n",
      "Fold: 8  Epoch: 446  Training loss = 2.6794  Validation loss = 7.5932  \n",
      "\n",
      "Fold: 8  Epoch: 447  Training loss = 2.6792  Validation loss = 7.5929  \n",
      "\n",
      "Fold: 8  Epoch: 448  Training loss = 2.6789  Validation loss = 7.5926  \n",
      "\n",
      "Fold: 8  Epoch: 449  Training loss = 2.6787  Validation loss = 7.5923  \n",
      "\n",
      "Fold: 8  Epoch: 450  Training loss = 2.6785  Validation loss = 7.5921  \n",
      "\n",
      "Fold: 8  Epoch: 451  Training loss = 2.6782  Validation loss = 7.5917  \n",
      "\n",
      "Fold: 8  Epoch: 452  Training loss = 2.6780  Validation loss = 7.5914  \n",
      "\n",
      "Fold: 8  Epoch: 453  Training loss = 2.6778  Validation loss = 7.5912  \n",
      "\n",
      "Fold: 8  Epoch: 454  Training loss = 2.6776  Validation loss = 7.5909  \n",
      "\n",
      "Fold: 8  Epoch: 455  Training loss = 2.6774  Validation loss = 7.5906  \n",
      "\n",
      "Fold: 8  Epoch: 456  Training loss = 2.6771  Validation loss = 7.5903  \n",
      "\n",
      "Fold: 8  Epoch: 457  Training loss = 2.6769  Validation loss = 7.5900  \n",
      "\n",
      "Fold: 8  Epoch: 458  Training loss = 2.6767  Validation loss = 7.5897  \n",
      "\n",
      "Fold: 8  Epoch: 459  Training loss = 2.6765  Validation loss = 7.5894  \n",
      "\n",
      "Fold: 8  Epoch: 460  Training loss = 2.6762  Validation loss = 7.5891  \n",
      "\n",
      "Fold: 8  Epoch: 461  Training loss = 2.6760  Validation loss = 7.5887  \n",
      "\n",
      "Fold: 8  Epoch: 462  Training loss = 2.6758  Validation loss = 7.5885  \n",
      "\n",
      "Fold: 8  Epoch: 463  Training loss = 2.6755  Validation loss = 7.5882  \n",
      "\n",
      "Fold: 8  Epoch: 464  Training loss = 2.6753  Validation loss = 7.5879  \n",
      "\n",
      "Fold: 8  Epoch: 465  Training loss = 2.6752  Validation loss = 7.5877  \n",
      "\n",
      "Fold: 8  Epoch: 466  Training loss = 2.6750  Validation loss = 7.5874  \n",
      "\n",
      "Fold: 8  Epoch: 467  Training loss = 2.6747  Validation loss = 7.5871  \n",
      "\n",
      "Fold: 8  Epoch: 468  Training loss = 2.6745  Validation loss = 7.5868  \n",
      "\n",
      "Fold: 8  Epoch: 469  Training loss = 2.6743  Validation loss = 7.5865  \n",
      "\n",
      "Fold: 8  Epoch: 470  Training loss = 2.6740  Validation loss = 7.5861  \n",
      "\n",
      "Fold: 8  Epoch: 471  Training loss = 2.6738  Validation loss = 7.5858  \n",
      "\n",
      "Fold: 8  Epoch: 472  Training loss = 2.6736  Validation loss = 7.5855  \n",
      "\n",
      "Fold: 8  Epoch: 473  Training loss = 2.6733  Validation loss = 7.5852  \n",
      "\n",
      "Fold: 8  Epoch: 474  Training loss = 2.6731  Validation loss = 7.5849  \n",
      "\n",
      "Fold: 8  Epoch: 475  Training loss = 2.6729  Validation loss = 7.5845  \n",
      "\n",
      "Fold: 8  Epoch: 476  Training loss = 2.6726  Validation loss = 7.5842  \n",
      "\n",
      "Fold: 8  Epoch: 477  Training loss = 2.6724  Validation loss = 7.5840  \n",
      "\n",
      "Fold: 8  Epoch: 478  Training loss = 2.6722  Validation loss = 7.5837  \n",
      "\n",
      "Fold: 8  Epoch: 479  Training loss = 2.6719  Validation loss = 7.5833  \n",
      "\n",
      "Fold: 8  Epoch: 480  Training loss = 2.6717  Validation loss = 7.5830  \n",
      "\n",
      "Fold: 8  Epoch: 481  Training loss = 2.6715  Validation loss = 7.5827  \n",
      "\n",
      "Fold: 8  Epoch: 482  Training loss = 2.6713  Validation loss = 7.5825  \n",
      "\n",
      "Fold: 8  Epoch: 483  Training loss = 2.6710  Validation loss = 7.5821  \n",
      "\n",
      "Fold: 8  Epoch: 484  Training loss = 2.6708  Validation loss = 7.5818  \n",
      "\n",
      "Fold: 8  Epoch: 485  Training loss = 2.6706  Validation loss = 7.5815  \n",
      "\n",
      "Fold: 8  Epoch: 486  Training loss = 2.6703  Validation loss = 7.5812  \n",
      "\n",
      "Fold: 8  Epoch: 487  Training loss = 2.6701  Validation loss = 7.5808  \n",
      "\n",
      "Fold: 8  Epoch: 488  Training loss = 2.6698  Validation loss = 7.5805  \n",
      "\n",
      "Fold: 8  Epoch: 489  Training loss = 2.6696  Validation loss = 7.5802  \n",
      "\n",
      "Fold: 8  Epoch: 490  Training loss = 2.6694  Validation loss = 7.5799  \n",
      "\n",
      "Fold: 8  Epoch: 491  Training loss = 2.6691  Validation loss = 7.5796  \n",
      "\n",
      "Fold: 8  Epoch: 492  Training loss = 2.6690  Validation loss = 7.5794  \n",
      "\n",
      "Fold: 8  Epoch: 493  Training loss = 2.6688  Validation loss = 7.5791  \n",
      "\n",
      "Fold: 8  Epoch: 494  Training loss = 2.6686  Validation loss = 7.5788  \n",
      "\n",
      "Fold: 8  Epoch: 495  Training loss = 2.6684  Validation loss = 7.5785  \n",
      "\n",
      "Fold: 8  Epoch: 496  Training loss = 2.6682  Validation loss = 7.5783  \n",
      "\n",
      "Fold: 8  Epoch: 497  Training loss = 2.6679  Validation loss = 7.5779  \n",
      "\n",
      "Fold: 8  Epoch: 498  Training loss = 2.6677  Validation loss = 7.5776  \n",
      "\n",
      "Fold: 8  Epoch: 499  Training loss = 2.6674  Validation loss = 7.5773  \n",
      "\n",
      "Fold: 8  Epoch: 500  Training loss = 2.6672  Validation loss = 7.5770  \n",
      "\n",
      "Check model:  Fold: 8  Optimal epoch: 500  \n",
      "\n",
      "Fold: 9  Epoch: 1  Training loss = 3.1963  Validation loss = 11.2287  \n",
      "\n",
      "Fold: 9  Epoch: 2  Training loss = 3.1961  Validation loss = 11.2283  \n",
      "\n",
      "Fold: 9  Epoch: 3  Training loss = 3.1958  Validation loss = 11.2279  \n",
      "\n",
      "Fold: 9  Epoch: 4  Training loss = 3.1955  Validation loss = 11.2275  \n",
      "\n",
      "Fold: 9  Epoch: 5  Training loss = 3.1952  Validation loss = 11.2271  \n",
      "\n",
      "Fold: 9  Epoch: 6  Training loss = 3.1951  Validation loss = 11.2268  \n",
      "\n",
      "Fold: 9  Epoch: 7  Training loss = 3.1948  Validation loss = 11.2265  \n",
      "\n",
      "Fold: 9  Epoch: 8  Training loss = 3.1946  Validation loss = 11.2262  \n",
      "\n",
      "Fold: 9  Epoch: 9  Training loss = 3.1943  Validation loss = 11.2258  \n",
      "\n",
      "Fold: 9  Epoch: 10  Training loss = 3.1940  Validation loss = 11.2254  \n",
      "\n",
      "Fold: 9  Epoch: 11  Training loss = 3.1938  Validation loss = 11.2250  \n",
      "\n",
      "Fold: 9  Epoch: 12  Training loss = 3.1936  Validation loss = 11.2247  \n",
      "\n",
      "Fold: 9  Epoch: 13  Training loss = 3.1933  Validation loss = 11.2244  \n",
      "\n",
      "Fold: 9  Epoch: 14  Training loss = 3.1931  Validation loss = 11.2240  \n",
      "\n",
      "Fold: 9  Epoch: 15  Training loss = 3.1928  Validation loss = 11.2236  \n",
      "\n",
      "Fold: 9  Epoch: 16  Training loss = 3.1926  Validation loss = 11.2233  \n",
      "\n",
      "Fold: 9  Epoch: 17  Training loss = 3.1923  Validation loss = 11.2229  \n",
      "\n",
      "Fold: 9  Epoch: 18  Training loss = 3.1920  Validation loss = 11.2225  \n",
      "\n",
      "Fold: 9  Epoch: 19  Training loss = 3.1918  Validation loss = 11.2220  \n",
      "\n",
      "Fold: 9  Epoch: 20  Training loss = 3.1915  Validation loss = 11.2217  \n",
      "\n",
      "Fold: 9  Epoch: 21  Training loss = 3.1913  Validation loss = 11.2213  \n",
      "\n",
      "Fold: 9  Epoch: 22  Training loss = 3.1911  Validation loss = 11.2210  \n",
      "\n",
      "Fold: 9  Epoch: 23  Training loss = 3.1909  Validation loss = 11.2207  \n",
      "\n",
      "Fold: 9  Epoch: 24  Training loss = 3.1907  Validation loss = 11.2204  \n",
      "\n",
      "Fold: 9  Epoch: 25  Training loss = 3.1903  Validation loss = 11.2199  \n",
      "\n",
      "Fold: 9  Epoch: 26  Training loss = 3.1901  Validation loss = 11.2196  \n",
      "\n",
      "Fold: 9  Epoch: 27  Training loss = 3.1898  Validation loss = 11.2192  \n",
      "\n",
      "Fold: 9  Epoch: 28  Training loss = 3.1896  Validation loss = 11.2189  \n",
      "\n",
      "Fold: 9  Epoch: 29  Training loss = 3.1893  Validation loss = 11.2184  \n",
      "\n",
      "Fold: 9  Epoch: 30  Training loss = 3.1891  Validation loss = 11.2181  \n",
      "\n",
      "Fold: 9  Epoch: 31  Training loss = 3.1888  Validation loss = 11.2178  \n",
      "\n",
      "Fold: 9  Epoch: 32  Training loss = 3.1885  Validation loss = 11.2173  \n",
      "\n",
      "Fold: 9  Epoch: 33  Training loss = 3.1883  Validation loss = 11.2169  \n",
      "\n",
      "Fold: 9  Epoch: 34  Training loss = 3.1880  Validation loss = 11.2165  \n",
      "\n",
      "Fold: 9  Epoch: 35  Training loss = 3.1878  Validation loss = 11.2162  \n",
      "\n",
      "Fold: 9  Epoch: 36  Training loss = 3.1875  Validation loss = 11.2159  \n",
      "\n",
      "Fold: 9  Epoch: 37  Training loss = 3.1873  Validation loss = 11.2155  \n",
      "\n",
      "Fold: 9  Epoch: 38  Training loss = 3.1870  Validation loss = 11.2151  \n",
      "\n",
      "Fold: 9  Epoch: 39  Training loss = 3.1868  Validation loss = 11.2147  \n",
      "\n",
      "Fold: 9  Epoch: 40  Training loss = 3.1865  Validation loss = 11.2143  \n",
      "\n",
      "Fold: 9  Epoch: 41  Training loss = 3.1863  Validation loss = 11.2140  \n",
      "\n",
      "Fold: 9  Epoch: 42  Training loss = 3.1860  Validation loss = 11.2136  \n",
      "\n",
      "Fold: 9  Epoch: 43  Training loss = 3.1858  Validation loss = 11.2133  \n",
      "\n",
      "Fold: 9  Epoch: 44  Training loss = 3.1855  Validation loss = 11.2129  \n",
      "\n",
      "Fold: 9  Epoch: 45  Training loss = 3.1853  Validation loss = 11.2126  \n",
      "\n",
      "Fold: 9  Epoch: 46  Training loss = 3.1850  Validation loss = 11.2122  \n",
      "\n",
      "Fold: 9  Epoch: 47  Training loss = 3.1848  Validation loss = 11.2119  \n",
      "\n",
      "Fold: 9  Epoch: 48  Training loss = 3.1845  Validation loss = 11.2115  \n",
      "\n",
      "Fold: 9  Epoch: 49  Training loss = 3.1842  Validation loss = 11.2110  \n",
      "\n",
      "Fold: 9  Epoch: 50  Training loss = 3.1839  Validation loss = 11.2105  \n",
      "\n",
      "Fold: 9  Epoch: 51  Training loss = 3.1836  Validation loss = 11.2102  \n",
      "\n",
      "Fold: 9  Epoch: 52  Training loss = 3.1834  Validation loss = 11.2098  \n",
      "\n",
      "Fold: 9  Epoch: 53  Training loss = 3.1831  Validation loss = 11.2094  \n",
      "\n",
      "Fold: 9  Epoch: 54  Training loss = 3.1829  Validation loss = 11.2091  \n",
      "\n",
      "Fold: 9  Epoch: 55  Training loss = 3.1826  Validation loss = 11.2087  \n",
      "\n",
      "Fold: 9  Epoch: 56  Training loss = 3.1824  Validation loss = 11.2083  \n",
      "\n",
      "Fold: 9  Epoch: 57  Training loss = 3.1821  Validation loss = 11.2080  \n",
      "\n",
      "Fold: 9  Epoch: 58  Training loss = 3.1819  Validation loss = 11.2076  \n",
      "\n",
      "Fold: 9  Epoch: 59  Training loss = 3.1817  Validation loss = 11.2074  \n",
      "\n",
      "Fold: 9  Epoch: 60  Training loss = 3.1815  Validation loss = 11.2070  \n",
      "\n",
      "Fold: 9  Epoch: 61  Training loss = 3.1812  Validation loss = 11.2066  \n",
      "\n",
      "Fold: 9  Epoch: 62  Training loss = 3.1810  Validation loss = 11.2063  \n",
      "\n",
      "Fold: 9  Epoch: 63  Training loss = 3.1807  Validation loss = 11.2059  \n",
      "\n",
      "Fold: 9  Epoch: 64  Training loss = 3.1805  Validation loss = 11.2056  \n",
      "\n",
      "Fold: 9  Epoch: 65  Training loss = 3.1803  Validation loss = 11.2053  \n",
      "\n",
      "Fold: 9  Epoch: 66  Training loss = 3.1801  Validation loss = 11.2050  \n",
      "\n",
      "Fold: 9  Epoch: 67  Training loss = 3.1798  Validation loss = 11.2045  \n",
      "\n",
      "Fold: 9  Epoch: 68  Training loss = 3.1795  Validation loss = 11.2042  \n",
      "\n",
      "Fold: 9  Epoch: 69  Training loss = 3.1793  Validation loss = 11.2038  \n",
      "\n",
      "Fold: 9  Epoch: 70  Training loss = 3.1790  Validation loss = 11.2035  \n",
      "\n",
      "Fold: 9  Epoch: 71  Training loss = 3.1788  Validation loss = 11.2031  \n",
      "\n",
      "Fold: 9  Epoch: 72  Training loss = 3.1785  Validation loss = 11.2027  \n",
      "\n",
      "Fold: 9  Epoch: 73  Training loss = 3.1782  Validation loss = 11.2023  \n",
      "\n",
      "Fold: 9  Epoch: 74  Training loss = 3.1780  Validation loss = 11.2019  \n",
      "\n",
      "Fold: 9  Epoch: 75  Training loss = 3.1777  Validation loss = 11.2015  \n",
      "\n",
      "Fold: 9  Epoch: 76  Training loss = 3.1775  Validation loss = 11.2012  \n",
      "\n",
      "Fold: 9  Epoch: 77  Training loss = 3.1773  Validation loss = 11.2009  \n",
      "\n",
      "Fold: 9  Epoch: 78  Training loss = 3.1770  Validation loss = 11.2005  \n",
      "\n",
      "Fold: 9  Epoch: 79  Training loss = 3.1767  Validation loss = 11.2002  \n",
      "\n",
      "Fold: 9  Epoch: 80  Training loss = 3.1765  Validation loss = 11.1998  \n",
      "\n",
      "Fold: 9  Epoch: 81  Training loss = 3.1762  Validation loss = 11.1994  \n",
      "\n",
      "Fold: 9  Epoch: 82  Training loss = 3.1760  Validation loss = 11.1991  \n",
      "\n",
      "Fold: 9  Epoch: 83  Training loss = 3.1757  Validation loss = 11.1986  \n",
      "\n",
      "Fold: 9  Epoch: 84  Training loss = 3.1755  Validation loss = 11.1983  \n",
      "\n",
      "Fold: 9  Epoch: 85  Training loss = 3.1752  Validation loss = 11.1979  \n",
      "\n",
      "Fold: 9  Epoch: 86  Training loss = 3.1749  Validation loss = 11.1975  \n",
      "\n",
      "Fold: 9  Epoch: 87  Training loss = 3.1746  Validation loss = 11.1971  \n",
      "\n",
      "Fold: 9  Epoch: 88  Training loss = 3.1744  Validation loss = 11.1967  \n",
      "\n",
      "Fold: 9  Epoch: 89  Training loss = 3.1741  Validation loss = 11.1963  \n",
      "\n",
      "Fold: 9  Epoch: 90  Training loss = 3.1739  Validation loss = 11.1959  \n",
      "\n",
      "Fold: 9  Epoch: 91  Training loss = 3.1736  Validation loss = 11.1955  \n",
      "\n",
      "Fold: 9  Epoch: 92  Training loss = 3.1734  Validation loss = 11.1952  \n",
      "\n",
      "Fold: 9  Epoch: 93  Training loss = 3.1731  Validation loss = 11.1948  \n",
      "\n",
      "Fold: 9  Epoch: 94  Training loss = 3.1729  Validation loss = 11.1945  \n",
      "\n",
      "Fold: 9  Epoch: 95  Training loss = 3.1726  Validation loss = 11.1941  \n",
      "\n",
      "Fold: 9  Epoch: 96  Training loss = 3.1723  Validation loss = 11.1937  \n",
      "\n",
      "Fold: 9  Epoch: 97  Training loss = 3.1721  Validation loss = 11.1934  \n",
      "\n",
      "Fold: 9  Epoch: 98  Training loss = 3.1719  Validation loss = 11.1930  \n",
      "\n",
      "Fold: 9  Epoch: 99  Training loss = 3.1716  Validation loss = 11.1926  \n",
      "\n",
      "Fold: 9  Epoch: 100  Training loss = 3.1714  Validation loss = 11.1923  \n",
      "\n",
      "Fold: 9  Epoch: 101  Training loss = 3.1711  Validation loss = 11.1919  \n",
      "\n",
      "Fold: 9  Epoch: 102  Training loss = 3.1708  Validation loss = 11.1915  \n",
      "\n",
      "Fold: 9  Epoch: 103  Training loss = 3.1706  Validation loss = 11.1912  \n",
      "\n",
      "Fold: 9  Epoch: 104  Training loss = 3.1704  Validation loss = 11.1908  \n",
      "\n",
      "Fold: 9  Epoch: 105  Training loss = 3.1701  Validation loss = 11.1904  \n",
      "\n",
      "Fold: 9  Epoch: 106  Training loss = 3.1699  Validation loss = 11.1901  \n",
      "\n",
      "Fold: 9  Epoch: 107  Training loss = 3.1697  Validation loss = 11.1898  \n",
      "\n",
      "Fold: 9  Epoch: 108  Training loss = 3.1694  Validation loss = 11.1894  \n",
      "\n",
      "Fold: 9  Epoch: 109  Training loss = 3.1691  Validation loss = 11.1891  \n",
      "\n",
      "Fold: 9  Epoch: 110  Training loss = 3.1689  Validation loss = 11.1886  \n",
      "\n",
      "Fold: 9  Epoch: 111  Training loss = 3.1686  Validation loss = 11.1883  \n",
      "\n",
      "Fold: 9  Epoch: 112  Training loss = 3.1684  Validation loss = 11.1879  \n",
      "\n",
      "Fold: 9  Epoch: 113  Training loss = 3.1681  Validation loss = 11.1875  \n",
      "\n",
      "Fold: 9  Epoch: 114  Training loss = 3.1678  Validation loss = 11.1870  \n",
      "\n",
      "Fold: 9  Epoch: 115  Training loss = 3.1676  Validation loss = 11.1867  \n",
      "\n",
      "Fold: 9  Epoch: 116  Training loss = 3.1674  Validation loss = 11.1864  \n",
      "\n",
      "Fold: 9  Epoch: 117  Training loss = 3.1670  Validation loss = 11.1860  \n",
      "\n",
      "Fold: 9  Epoch: 118  Training loss = 3.1668  Validation loss = 11.1855  \n",
      "\n",
      "Fold: 9  Epoch: 119  Training loss = 3.1665  Validation loss = 11.1852  \n",
      "\n",
      "Fold: 9  Epoch: 120  Training loss = 3.1663  Validation loss = 11.1848  \n",
      "\n",
      "Fold: 9  Epoch: 121  Training loss = 3.1660  Validation loss = 11.1844  \n",
      "\n",
      "Fold: 9  Epoch: 122  Training loss = 3.1657  Validation loss = 11.1839  \n",
      "\n",
      "Fold: 9  Epoch: 123  Training loss = 3.1654  Validation loss = 11.1835  \n",
      "\n",
      "Fold: 9  Epoch: 124  Training loss = 3.1651  Validation loss = 11.1831  \n",
      "\n",
      "Fold: 9  Epoch: 125  Training loss = 3.1648  Validation loss = 11.1827  \n",
      "\n",
      "Fold: 9  Epoch: 126  Training loss = 3.1646  Validation loss = 11.1823  \n",
      "\n",
      "Fold: 9  Epoch: 127  Training loss = 3.1643  Validation loss = 11.1820  \n",
      "\n",
      "Fold: 9  Epoch: 128  Training loss = 3.1641  Validation loss = 11.1816  \n",
      "\n",
      "Fold: 9  Epoch: 129  Training loss = 3.1639  Validation loss = 11.1813  \n",
      "\n",
      "Fold: 9  Epoch: 130  Training loss = 3.1636  Validation loss = 11.1809  \n",
      "\n",
      "Fold: 9  Epoch: 131  Training loss = 3.1634  Validation loss = 11.1807  \n",
      "\n",
      "Fold: 9  Epoch: 132  Training loss = 3.1632  Validation loss = 11.1803  \n",
      "\n",
      "Fold: 9  Epoch: 133  Training loss = 3.1630  Validation loss = 11.1800  \n",
      "\n",
      "Fold: 9  Epoch: 134  Training loss = 3.1627  Validation loss = 11.1796  \n",
      "\n",
      "Fold: 9  Epoch: 135  Training loss = 3.1625  Validation loss = 11.1793  \n",
      "\n",
      "Fold: 9  Epoch: 136  Training loss = 3.1623  Validation loss = 11.1790  \n",
      "\n",
      "Fold: 9  Epoch: 137  Training loss = 3.1622  Validation loss = 11.1788  \n",
      "\n",
      "Fold: 9  Epoch: 138  Training loss = 3.1619  Validation loss = 11.1784  \n",
      "\n",
      "Fold: 9  Epoch: 139  Training loss = 3.1617  Validation loss = 11.1780  \n",
      "\n",
      "Fold: 9  Epoch: 140  Training loss = 3.1614  Validation loss = 11.1776  \n",
      "\n",
      "Fold: 9  Epoch: 141  Training loss = 3.1612  Validation loss = 11.1773  \n",
      "\n",
      "Fold: 9  Epoch: 142  Training loss = 3.1609  Validation loss = 11.1770  \n",
      "\n",
      "Fold: 9  Epoch: 143  Training loss = 3.1607  Validation loss = 11.1766  \n",
      "\n",
      "Fold: 9  Epoch: 144  Training loss = 3.1604  Validation loss = 11.1761  \n",
      "\n",
      "Fold: 9  Epoch: 145  Training loss = 3.1602  Validation loss = 11.1758  \n",
      "\n",
      "Fold: 9  Epoch: 146  Training loss = 3.1599  Validation loss = 11.1755  \n",
      "\n",
      "Fold: 9  Epoch: 147  Training loss = 3.1597  Validation loss = 11.1751  \n",
      "\n",
      "Fold: 9  Epoch: 148  Training loss = 3.1594  Validation loss = 11.1747  \n",
      "\n",
      "Fold: 9  Epoch: 149  Training loss = 3.1591  Validation loss = 11.1743  \n",
      "\n",
      "Fold: 9  Epoch: 150  Training loss = 3.1589  Validation loss = 11.1739  \n",
      "\n",
      "Fold: 9  Epoch: 151  Training loss = 3.1586  Validation loss = 11.1736  \n",
      "\n",
      "Fold: 9  Epoch: 152  Training loss = 3.1584  Validation loss = 11.1732  \n",
      "\n",
      "Fold: 9  Epoch: 153  Training loss = 3.1581  Validation loss = 11.1729  \n",
      "\n",
      "Fold: 9  Epoch: 154  Training loss = 3.1579  Validation loss = 11.1725  \n",
      "\n",
      "Fold: 9  Epoch: 155  Training loss = 3.1576  Validation loss = 11.1721  \n",
      "\n",
      "Fold: 9  Epoch: 156  Training loss = 3.1574  Validation loss = 11.1718  \n",
      "\n",
      "Fold: 9  Epoch: 157  Training loss = 3.1572  Validation loss = 11.1715  \n",
      "\n",
      "Fold: 9  Epoch: 158  Training loss = 3.1569  Validation loss = 11.1711  \n",
      "\n",
      "Fold: 9  Epoch: 159  Training loss = 3.1567  Validation loss = 11.1708  \n",
      "\n",
      "Fold: 9  Epoch: 160  Training loss = 3.1564  Validation loss = 11.1704  \n",
      "\n",
      "Fold: 9  Epoch: 161  Training loss = 3.1562  Validation loss = 11.1700  \n",
      "\n",
      "Fold: 9  Epoch: 162  Training loss = 3.1558  Validation loss = 11.1695  \n",
      "\n",
      "Fold: 9  Epoch: 163  Training loss = 3.1556  Validation loss = 11.1692  \n",
      "\n",
      "Fold: 9  Epoch: 164  Training loss = 3.1554  Validation loss = 11.1689  \n",
      "\n",
      "Fold: 9  Epoch: 165  Training loss = 3.1551  Validation loss = 11.1684  \n",
      "\n",
      "Fold: 9  Epoch: 166  Training loss = 3.1549  Validation loss = 11.1681  \n",
      "\n",
      "Fold: 9  Epoch: 167  Training loss = 3.1547  Validation loss = 11.1678  \n",
      "\n",
      "Fold: 9  Epoch: 168  Training loss = 3.1544  Validation loss = 11.1675  \n",
      "\n",
      "Fold: 9  Epoch: 169  Training loss = 3.1542  Validation loss = 11.1671  \n",
      "\n",
      "Fold: 9  Epoch: 170  Training loss = 3.1539  Validation loss = 11.1667  \n",
      "\n",
      "Fold: 9  Epoch: 171  Training loss = 3.1536  Validation loss = 11.1663  \n",
      "\n",
      "Fold: 9  Epoch: 172  Training loss = 3.1534  Validation loss = 11.1659  \n",
      "\n",
      "Fold: 9  Epoch: 173  Training loss = 3.1531  Validation loss = 11.1655  \n",
      "\n",
      "Fold: 9  Epoch: 174  Training loss = 3.1528  Validation loss = 11.1651  \n",
      "\n",
      "Fold: 9  Epoch: 175  Training loss = 3.1526  Validation loss = 11.1647  \n",
      "\n",
      "Fold: 9  Epoch: 176  Training loss = 3.1523  Validation loss = 11.1643  \n",
      "\n",
      "Fold: 9  Epoch: 177  Training loss = 3.1521  Validation loss = 11.1639  \n",
      "\n",
      "Fold: 9  Epoch: 178  Training loss = 3.1517  Validation loss = 11.1635  \n",
      "\n",
      "Fold: 9  Epoch: 179  Training loss = 3.1515  Validation loss = 11.1632  \n",
      "\n",
      "Fold: 9  Epoch: 180  Training loss = 3.1513  Validation loss = 11.1628  \n",
      "\n",
      "Fold: 9  Epoch: 181  Training loss = 3.1511  Validation loss = 11.1625  \n",
      "\n",
      "Fold: 9  Epoch: 182  Training loss = 3.1508  Validation loss = 11.1621  \n",
      "\n",
      "Fold: 9  Epoch: 183  Training loss = 3.1505  Validation loss = 11.1617  \n",
      "\n",
      "Fold: 9  Epoch: 184  Training loss = 3.1503  Validation loss = 11.1613  \n",
      "\n",
      "Fold: 9  Epoch: 185  Training loss = 3.1500  Validation loss = 11.1609  \n",
      "\n",
      "Fold: 9  Epoch: 186  Training loss = 3.1497  Validation loss = 11.1605  \n",
      "\n",
      "Fold: 9  Epoch: 187  Training loss = 3.1495  Validation loss = 11.1601  \n",
      "\n",
      "Fold: 9  Epoch: 188  Training loss = 3.1492  Validation loss = 11.1597  \n",
      "\n",
      "Fold: 9  Epoch: 189  Training loss = 3.1490  Validation loss = 11.1594  \n",
      "\n",
      "Fold: 9  Epoch: 190  Training loss = 3.1487  Validation loss = 11.1589  \n",
      "\n",
      "Fold: 9  Epoch: 191  Training loss = 3.1484  Validation loss = 11.1586  \n",
      "\n",
      "Fold: 9  Epoch: 192  Training loss = 3.1481  Validation loss = 11.1581  \n",
      "\n",
      "Fold: 9  Epoch: 193  Training loss = 3.1479  Validation loss = 11.1579  \n",
      "\n",
      "Fold: 9  Epoch: 194  Training loss = 3.1476  Validation loss = 11.1574  \n",
      "\n",
      "Fold: 9  Epoch: 195  Training loss = 3.1474  Validation loss = 11.1571  \n",
      "\n",
      "Fold: 9  Epoch: 196  Training loss = 3.1472  Validation loss = 11.1567  \n",
      "\n",
      "Fold: 9  Epoch: 197  Training loss = 3.1469  Validation loss = 11.1564  \n",
      "\n",
      "Fold: 9  Epoch: 198  Training loss = 3.1467  Validation loss = 11.1560  \n",
      "\n",
      "Fold: 9  Epoch: 199  Training loss = 3.1464  Validation loss = 11.1556  \n",
      "\n",
      "Fold: 9  Epoch: 200  Training loss = 3.1461  Validation loss = 11.1552  \n",
      "\n",
      "Fold: 9  Epoch: 201  Training loss = 3.1459  Validation loss = 11.1548  \n",
      "\n",
      "Fold: 9  Epoch: 202  Training loss = 3.1456  Validation loss = 11.1544  \n",
      "\n",
      "Fold: 9  Epoch: 203  Training loss = 3.1454  Validation loss = 11.1541  \n",
      "\n",
      "Fold: 9  Epoch: 204  Training loss = 3.1451  Validation loss = 11.1537  \n",
      "\n",
      "Fold: 9  Epoch: 205  Training loss = 3.1449  Validation loss = 11.1534  \n",
      "\n",
      "Fold: 9  Epoch: 206  Training loss = 3.1446  Validation loss = 11.1530  \n",
      "\n",
      "Fold: 9  Epoch: 207  Training loss = 3.1444  Validation loss = 11.1526  \n",
      "\n",
      "Fold: 9  Epoch: 208  Training loss = 3.1442  Validation loss = 11.1524  \n",
      "\n",
      "Fold: 9  Epoch: 209  Training loss = 3.1440  Validation loss = 11.1520  \n",
      "\n",
      "Fold: 9  Epoch: 210  Training loss = 3.1437  Validation loss = 11.1517  \n",
      "\n",
      "Fold: 9  Epoch: 211  Training loss = 3.1435  Validation loss = 11.1513  \n",
      "\n",
      "Fold: 9  Epoch: 212  Training loss = 3.1432  Validation loss = 11.1510  \n",
      "\n",
      "Fold: 9  Epoch: 213  Training loss = 3.1430  Validation loss = 11.1506  \n",
      "\n",
      "Fold: 9  Epoch: 214  Training loss = 3.1427  Validation loss = 11.1502  \n",
      "\n",
      "Fold: 9  Epoch: 215  Training loss = 3.1425  Validation loss = 11.1499  \n",
      "\n",
      "Fold: 9  Epoch: 216  Training loss = 3.1422  Validation loss = 11.1495  \n",
      "\n",
      "Fold: 9  Epoch: 217  Training loss = 3.1420  Validation loss = 11.1491  \n",
      "\n",
      "Fold: 9  Epoch: 218  Training loss = 3.1418  Validation loss = 11.1488  \n",
      "\n",
      "Fold: 9  Epoch: 219  Training loss = 3.1415  Validation loss = 11.1484  \n",
      "\n",
      "Fold: 9  Epoch: 220  Training loss = 3.1413  Validation loss = 11.1480  \n",
      "\n",
      "Fold: 9  Epoch: 221  Training loss = 3.1411  Validation loss = 11.1478  \n",
      "\n",
      "Fold: 9  Epoch: 222  Training loss = 3.1408  Validation loss = 11.1474  \n",
      "\n",
      "Fold: 9  Epoch: 223  Training loss = 3.1407  Validation loss = 11.1472  \n",
      "\n",
      "Fold: 9  Epoch: 224  Training loss = 3.1404  Validation loss = 11.1468  \n",
      "\n",
      "Fold: 9  Epoch: 225  Training loss = 3.1402  Validation loss = 11.1465  \n",
      "\n",
      "Fold: 9  Epoch: 226  Training loss = 3.1400  Validation loss = 11.1462  \n",
      "\n",
      "Fold: 9  Epoch: 227  Training loss = 3.1398  Validation loss = 11.1459  \n",
      "\n",
      "Fold: 9  Epoch: 228  Training loss = 3.1395  Validation loss = 11.1455  \n",
      "\n",
      "Fold: 9  Epoch: 229  Training loss = 3.1393  Validation loss = 11.1451  \n",
      "\n",
      "Fold: 9  Epoch: 230  Training loss = 3.1390  Validation loss = 11.1447  \n",
      "\n",
      "Fold: 9  Epoch: 231  Training loss = 3.1388  Validation loss = 11.1444  \n",
      "\n",
      "Fold: 9  Epoch: 232  Training loss = 3.1386  Validation loss = 11.1441  \n",
      "\n",
      "Fold: 9  Epoch: 233  Training loss = 3.1383  Validation loss = 11.1437  \n",
      "\n",
      "Fold: 9  Epoch: 234  Training loss = 3.1382  Validation loss = 11.1435  \n",
      "\n",
      "Fold: 9  Epoch: 235  Training loss = 3.1379  Validation loss = 11.1431  \n",
      "\n",
      "Fold: 9  Epoch: 236  Training loss = 3.1377  Validation loss = 11.1428  \n",
      "\n",
      "Fold: 9  Epoch: 237  Training loss = 3.1375  Validation loss = 11.1424  \n",
      "\n",
      "Fold: 9  Epoch: 238  Training loss = 3.1372  Validation loss = 11.1421  \n",
      "\n",
      "Fold: 9  Epoch: 239  Training loss = 3.1370  Validation loss = 11.1417  \n",
      "\n",
      "Fold: 9  Epoch: 240  Training loss = 3.1368  Validation loss = 11.1414  \n",
      "\n",
      "Fold: 9  Epoch: 241  Training loss = 3.1365  Validation loss = 11.1410  \n",
      "\n",
      "Fold: 9  Epoch: 242  Training loss = 3.1362  Validation loss = 11.1406  \n",
      "\n",
      "Fold: 9  Epoch: 243  Training loss = 3.1360  Validation loss = 11.1403  \n",
      "\n",
      "Fold: 9  Epoch: 244  Training loss = 3.1357  Validation loss = 11.1399  \n",
      "\n",
      "Fold: 9  Epoch: 245  Training loss = 3.1355  Validation loss = 11.1395  \n",
      "\n",
      "Fold: 9  Epoch: 246  Training loss = 3.1353  Validation loss = 11.1392  \n",
      "\n",
      "Fold: 9  Epoch: 247  Training loss = 3.1350  Validation loss = 11.1389  \n",
      "\n",
      "Fold: 9  Epoch: 248  Training loss = 3.1348  Validation loss = 11.1385  \n",
      "\n",
      "Fold: 9  Epoch: 249  Training loss = 3.1346  Validation loss = 11.1382  \n",
      "\n",
      "Fold: 9  Epoch: 250  Training loss = 3.1343  Validation loss = 11.1378  \n",
      "\n",
      "Fold: 9  Epoch: 251  Training loss = 3.1340  Validation loss = 11.1374  \n",
      "\n",
      "Fold: 9  Epoch: 252  Training loss = 3.1338  Validation loss = 11.1370  \n",
      "\n",
      "Fold: 9  Epoch: 253  Training loss = 3.1335  Validation loss = 11.1366  \n",
      "\n",
      "Fold: 9  Epoch: 254  Training loss = 3.1333  Validation loss = 11.1362  \n",
      "\n",
      "Fold: 9  Epoch: 255  Training loss = 3.1331  Validation loss = 11.1359  \n",
      "\n",
      "Fold: 9  Epoch: 256  Training loss = 3.1328  Validation loss = 11.1356  \n",
      "\n",
      "Fold: 9  Epoch: 257  Training loss = 3.1326  Validation loss = 11.1353  \n",
      "\n",
      "Fold: 9  Epoch: 258  Training loss = 3.1324  Validation loss = 11.1349  \n",
      "\n",
      "Fold: 9  Epoch: 259  Training loss = 3.1322  Validation loss = 11.1346  \n",
      "\n",
      "Fold: 9  Epoch: 260  Training loss = 3.1319  Validation loss = 11.1342  \n",
      "\n",
      "Fold: 9  Epoch: 261  Training loss = 3.1317  Validation loss = 11.1339  \n",
      "\n",
      "Fold: 9  Epoch: 262  Training loss = 3.1314  Validation loss = 11.1335  \n",
      "\n",
      "Fold: 9  Epoch: 263  Training loss = 3.1312  Validation loss = 11.1332  \n",
      "\n",
      "Fold: 9  Epoch: 264  Training loss = 3.1310  Validation loss = 11.1329  \n",
      "\n",
      "Fold: 9  Epoch: 265  Training loss = 3.1308  Validation loss = 11.1325  \n",
      "\n",
      "Fold: 9  Epoch: 266  Training loss = 3.1305  Validation loss = 11.1321  \n",
      "\n",
      "Fold: 9  Epoch: 267  Training loss = 3.1302  Validation loss = 11.1317  \n",
      "\n",
      "Fold: 9  Epoch: 268  Training loss = 3.1299  Validation loss = 11.1313  \n",
      "\n",
      "Fold: 9  Epoch: 269  Training loss = 3.1297  Validation loss = 11.1310  \n",
      "\n",
      "Fold: 9  Epoch: 270  Training loss = 3.1295  Validation loss = 11.1306  \n",
      "\n",
      "Fold: 9  Epoch: 271  Training loss = 3.1293  Validation loss = 11.1304  \n",
      "\n",
      "Fold: 9  Epoch: 272  Training loss = 3.1291  Validation loss = 11.1300  \n",
      "\n",
      "Fold: 9  Epoch: 273  Training loss = 3.1288  Validation loss = 11.1296  \n",
      "\n",
      "Fold: 9  Epoch: 274  Training loss = 3.1286  Validation loss = 11.1293  \n",
      "\n",
      "Fold: 9  Epoch: 275  Training loss = 3.1284  Validation loss = 11.1290  \n",
      "\n",
      "Fold: 9  Epoch: 276  Training loss = 3.1281  Validation loss = 11.1286  \n",
      "\n",
      "Fold: 9  Epoch: 277  Training loss = 3.1279  Validation loss = 11.1283  \n",
      "\n",
      "Fold: 9  Epoch: 278  Training loss = 3.1277  Validation loss = 11.1280  \n",
      "\n",
      "Fold: 9  Epoch: 279  Training loss = 3.1275  Validation loss = 11.1277  \n",
      "\n",
      "Fold: 9  Epoch: 280  Training loss = 3.1272  Validation loss = 11.1272  \n",
      "\n",
      "Fold: 9  Epoch: 281  Training loss = 3.1269  Validation loss = 11.1268  \n",
      "\n",
      "Fold: 9  Epoch: 282  Training loss = 3.1267  Validation loss = 11.1265  \n",
      "\n",
      "Fold: 9  Epoch: 283  Training loss = 3.1265  Validation loss = 11.1261  \n",
      "\n",
      "Fold: 9  Epoch: 284  Training loss = 3.1262  Validation loss = 11.1258  \n",
      "\n",
      "Fold: 9  Epoch: 285  Training loss = 3.1259  Validation loss = 11.1254  \n",
      "\n",
      "Fold: 9  Epoch: 286  Training loss = 3.1257  Validation loss = 11.1251  \n",
      "\n",
      "Fold: 9  Epoch: 287  Training loss = 3.1255  Validation loss = 11.1248  \n",
      "\n",
      "Fold: 9  Epoch: 288  Training loss = 3.1253  Validation loss = 11.1244  \n",
      "\n",
      "Fold: 9  Epoch: 289  Training loss = 3.1250  Validation loss = 11.1241  \n",
      "\n",
      "Fold: 9  Epoch: 290  Training loss = 3.1248  Validation loss = 11.1237  \n",
      "\n",
      "Fold: 9  Epoch: 291  Training loss = 3.1246  Validation loss = 11.1234  \n",
      "\n",
      "Fold: 9  Epoch: 292  Training loss = 3.1243  Validation loss = 11.1229  \n",
      "\n",
      "Fold: 9  Epoch: 293  Training loss = 3.1240  Validation loss = 11.1225  \n",
      "\n",
      "Fold: 9  Epoch: 294  Training loss = 3.1238  Validation loss = 11.1222  \n",
      "\n",
      "Fold: 9  Epoch: 295  Training loss = 3.1235  Validation loss = 11.1219  \n",
      "\n",
      "Fold: 9  Epoch: 296  Training loss = 3.1233  Validation loss = 11.1216  \n",
      "\n",
      "Fold: 9  Epoch: 297  Training loss = 3.1231  Validation loss = 11.1212  \n",
      "\n",
      "Fold: 9  Epoch: 298  Training loss = 3.1229  Validation loss = 11.1210  \n",
      "\n",
      "Fold: 9  Epoch: 299  Training loss = 3.1227  Validation loss = 11.1206  \n",
      "\n",
      "Fold: 9  Epoch: 300  Training loss = 3.1225  Validation loss = 11.1203  \n",
      "\n",
      "Fold: 9  Epoch: 301  Training loss = 3.1222  Validation loss = 11.1199  \n",
      "\n",
      "Fold: 9  Epoch: 302  Training loss = 3.1220  Validation loss = 11.1195  \n",
      "\n",
      "Fold: 9  Epoch: 303  Training loss = 3.1217  Validation loss = 11.1191  \n",
      "\n",
      "Fold: 9  Epoch: 304  Training loss = 3.1215  Validation loss = 11.1188  \n",
      "\n",
      "Fold: 9  Epoch: 305  Training loss = 3.1212  Validation loss = 11.1185  \n",
      "\n",
      "Fold: 9  Epoch: 306  Training loss = 3.1210  Validation loss = 11.1182  \n",
      "\n",
      "Fold: 9  Epoch: 307  Training loss = 3.1208  Validation loss = 11.1178  \n",
      "\n",
      "Fold: 9  Epoch: 308  Training loss = 3.1205  Validation loss = 11.1174  \n",
      "\n",
      "Fold: 9  Epoch: 309  Training loss = 3.1203  Validation loss = 11.1171  \n",
      "\n",
      "Fold: 9  Epoch: 310  Training loss = 3.1201  Validation loss = 11.1168  \n",
      "\n",
      "Fold: 9  Epoch: 311  Training loss = 3.1199  Validation loss = 11.1164  \n",
      "\n",
      "Fold: 9  Epoch: 312  Training loss = 3.1196  Validation loss = 11.1160  \n",
      "\n",
      "Fold: 9  Epoch: 313  Training loss = 3.1194  Validation loss = 11.1157  \n",
      "\n",
      "Fold: 9  Epoch: 314  Training loss = 3.1191  Validation loss = 11.1153  \n",
      "\n",
      "Fold: 9  Epoch: 315  Training loss = 3.1189  Validation loss = 11.1150  \n",
      "\n",
      "Fold: 9  Epoch: 316  Training loss = 3.1187  Validation loss = 11.1146  \n",
      "\n",
      "Fold: 9  Epoch: 317  Training loss = 3.1184  Validation loss = 11.1142  \n",
      "\n",
      "Fold: 9  Epoch: 318  Training loss = 3.1182  Validation loss = 11.1140  \n",
      "\n",
      "Fold: 9  Epoch: 319  Training loss = 3.1179  Validation loss = 11.1136  \n",
      "\n",
      "Fold: 9  Epoch: 320  Training loss = 3.1177  Validation loss = 11.1132  \n",
      "\n",
      "Fold: 9  Epoch: 321  Training loss = 3.1174  Validation loss = 11.1127  \n",
      "\n",
      "Fold: 9  Epoch: 322  Training loss = 3.1171  Validation loss = 11.1123  \n",
      "\n",
      "Fold: 9  Epoch: 323  Training loss = 3.1168  Validation loss = 11.1118  \n",
      "\n",
      "Fold: 9  Epoch: 324  Training loss = 3.1165  Validation loss = 11.1115  \n",
      "\n",
      "Fold: 9  Epoch: 325  Training loss = 3.1164  Validation loss = 11.1112  \n",
      "\n",
      "Fold: 9  Epoch: 326  Training loss = 3.1162  Validation loss = 11.1109  \n",
      "\n",
      "Fold: 9  Epoch: 327  Training loss = 3.1159  Validation loss = 11.1105  \n",
      "\n",
      "Fold: 9  Epoch: 328  Training loss = 3.1157  Validation loss = 11.1102  \n",
      "\n",
      "Fold: 9  Epoch: 329  Training loss = 3.1154  Validation loss = 11.1098  \n",
      "\n",
      "Fold: 9  Epoch: 330  Training loss = 3.1151  Validation loss = 11.1094  \n",
      "\n",
      "Fold: 9  Epoch: 331  Training loss = 3.1148  Validation loss = 11.1089  \n",
      "\n",
      "Fold: 9  Epoch: 332  Training loss = 3.1146  Validation loss = 11.1086  \n",
      "\n",
      "Fold: 9  Epoch: 333  Training loss = 3.1143  Validation loss = 11.1082  \n",
      "\n",
      "Fold: 9  Epoch: 334  Training loss = 3.1141  Validation loss = 11.1079  \n",
      "\n",
      "Fold: 9  Epoch: 335  Training loss = 3.1139  Validation loss = 11.1075  \n",
      "\n",
      "Fold: 9  Epoch: 336  Training loss = 3.1136  Validation loss = 11.1071  \n",
      "\n",
      "Fold: 9  Epoch: 337  Training loss = 3.1134  Validation loss = 11.1068  \n",
      "\n",
      "Fold: 9  Epoch: 338  Training loss = 3.1131  Validation loss = 11.1064  \n",
      "\n",
      "Fold: 9  Epoch: 339  Training loss = 3.1129  Validation loss = 11.1061  \n",
      "\n",
      "Fold: 9  Epoch: 340  Training loss = 3.1127  Validation loss = 11.1058  \n",
      "\n",
      "Fold: 9  Epoch: 341  Training loss = 3.1125  Validation loss = 11.1055  \n",
      "\n",
      "Fold: 9  Epoch: 342  Training loss = 3.1123  Validation loss = 11.1052  \n",
      "\n",
      "Fold: 9  Epoch: 343  Training loss = 3.1120  Validation loss = 11.1048  \n",
      "\n",
      "Fold: 9  Epoch: 344  Training loss = 3.1117  Validation loss = 11.1043  \n",
      "\n",
      "Fold: 9  Epoch: 345  Training loss = 3.1115  Validation loss = 11.1039  \n",
      "\n",
      "Fold: 9  Epoch: 346  Training loss = 3.1112  Validation loss = 11.1036  \n",
      "\n",
      "Fold: 9  Epoch: 347  Training loss = 3.1110  Validation loss = 11.1032  \n",
      "\n",
      "Fold: 9  Epoch: 348  Training loss = 3.1108  Validation loss = 11.1029  \n",
      "\n",
      "Fold: 9  Epoch: 349  Training loss = 3.1105  Validation loss = 11.1026  \n",
      "\n",
      "Fold: 9  Epoch: 350  Training loss = 3.1103  Validation loss = 11.1023  \n",
      "\n",
      "Fold: 9  Epoch: 351  Training loss = 3.1101  Validation loss = 11.1019  \n",
      "\n",
      "Fold: 9  Epoch: 352  Training loss = 3.1098  Validation loss = 11.1015  \n",
      "\n",
      "Fold: 9  Epoch: 353  Training loss = 3.1096  Validation loss = 11.1011  \n",
      "\n",
      "Fold: 9  Epoch: 354  Training loss = 3.1094  Validation loss = 11.1008  \n",
      "\n",
      "Fold: 9  Epoch: 355  Training loss = 3.1091  Validation loss = 11.1005  \n",
      "\n",
      "Fold: 9  Epoch: 356  Training loss = 3.1089  Validation loss = 11.1002  \n",
      "\n",
      "Fold: 9  Epoch: 357  Training loss = 3.1086  Validation loss = 11.0997  \n",
      "\n",
      "Fold: 9  Epoch: 358  Training loss = 3.1084  Validation loss = 11.0994  \n",
      "\n",
      "Fold: 9  Epoch: 359  Training loss = 3.1081  Validation loss = 11.0990  \n",
      "\n",
      "Fold: 9  Epoch: 360  Training loss = 3.1079  Validation loss = 11.0987  \n",
      "\n",
      "Fold: 9  Epoch: 361  Training loss = 3.1077  Validation loss = 11.0983  \n",
      "\n",
      "Fold: 9  Epoch: 362  Training loss = 3.1074  Validation loss = 11.0979  \n",
      "\n",
      "Fold: 9  Epoch: 363  Training loss = 3.1071  Validation loss = 11.0975  \n",
      "\n",
      "Fold: 9  Epoch: 364  Training loss = 3.1068  Validation loss = 11.0971  \n",
      "\n",
      "Fold: 9  Epoch: 365  Training loss = 3.1066  Validation loss = 11.0967  \n",
      "\n",
      "Fold: 9  Epoch: 366  Training loss = 3.1064  Validation loss = 11.0963  \n",
      "\n",
      "Fold: 9  Epoch: 367  Training loss = 3.1062  Validation loss = 11.0960  \n",
      "\n",
      "Fold: 9  Epoch: 368  Training loss = 3.1059  Validation loss = 11.0956  \n",
      "\n",
      "Fold: 9  Epoch: 369  Training loss = 3.1057  Validation loss = 11.0953  \n",
      "\n",
      "Fold: 9  Epoch: 370  Training loss = 3.1054  Validation loss = 11.0949  \n",
      "\n",
      "Fold: 9  Epoch: 371  Training loss = 3.1052  Validation loss = 11.0946  \n",
      "\n",
      "Fold: 9  Epoch: 372  Training loss = 3.1050  Validation loss = 11.0942  \n",
      "\n",
      "Fold: 9  Epoch: 373  Training loss = 3.1047  Validation loss = 11.0939  \n",
      "\n",
      "Fold: 9  Epoch: 374  Training loss = 3.1045  Validation loss = 11.0935  \n",
      "\n",
      "Fold: 9  Epoch: 375  Training loss = 3.1042  Validation loss = 11.0932  \n",
      "\n",
      "Fold: 9  Epoch: 376  Training loss = 3.1040  Validation loss = 11.0929  \n",
      "\n",
      "Fold: 9  Epoch: 377  Training loss = 3.1038  Validation loss = 11.0926  \n",
      "\n",
      "Fold: 9  Epoch: 378  Training loss = 3.1036  Validation loss = 11.0922  \n",
      "\n",
      "Fold: 9  Epoch: 379  Training loss = 3.1033  Validation loss = 11.0918  \n",
      "\n",
      "Fold: 9  Epoch: 380  Training loss = 3.1030  Validation loss = 11.0913  \n",
      "\n",
      "Fold: 9  Epoch: 381  Training loss = 3.1027  Validation loss = 11.0909  \n",
      "\n",
      "Fold: 9  Epoch: 382  Training loss = 3.1025  Validation loss = 11.0906  \n",
      "\n",
      "Fold: 9  Epoch: 383  Training loss = 3.1022  Validation loss = 11.0902  \n",
      "\n",
      "Fold: 9  Epoch: 384  Training loss = 3.1019  Validation loss = 11.0898  \n",
      "\n",
      "Fold: 9  Epoch: 385  Training loss = 3.1017  Validation loss = 11.0894  \n",
      "\n",
      "Fold: 9  Epoch: 386  Training loss = 3.1014  Validation loss = 11.0890  \n",
      "\n",
      "Fold: 9  Epoch: 387  Training loss = 3.1011  Validation loss = 11.0886  \n",
      "\n",
      "Fold: 9  Epoch: 388  Training loss = 3.1009  Validation loss = 11.0882  \n",
      "\n",
      "Fold: 9  Epoch: 389  Training loss = 3.1006  Validation loss = 11.0878  \n",
      "\n",
      "Fold: 9  Epoch: 390  Training loss = 3.1004  Validation loss = 11.0875  \n",
      "\n",
      "Fold: 9  Epoch: 391  Training loss = 3.1003  Validation loss = 11.0873  \n",
      "\n",
      "Fold: 9  Epoch: 392  Training loss = 3.1001  Validation loss = 11.0870  \n",
      "\n",
      "Fold: 9  Epoch: 393  Training loss = 3.0998  Validation loss = 11.0866  \n",
      "\n",
      "Fold: 9  Epoch: 394  Training loss = 3.0995  Validation loss = 11.0862  \n",
      "\n",
      "Fold: 9  Epoch: 395  Training loss = 3.0993  Validation loss = 11.0858  \n",
      "\n",
      "Fold: 9  Epoch: 396  Training loss = 3.0990  Validation loss = 11.0855  \n",
      "\n",
      "Fold: 9  Epoch: 397  Training loss = 3.0988  Validation loss = 11.0850  \n",
      "\n",
      "Fold: 9  Epoch: 398  Training loss = 3.0986  Validation loss = 11.0847  \n",
      "\n",
      "Fold: 9  Epoch: 399  Training loss = 3.0984  Validation loss = 11.0844  \n",
      "\n",
      "Fold: 9  Epoch: 400  Training loss = 3.0981  Validation loss = 11.0840  \n",
      "\n",
      "Fold: 9  Epoch: 401  Training loss = 3.0979  Validation loss = 11.0837  \n",
      "\n",
      "Fold: 9  Epoch: 402  Training loss = 3.0977  Validation loss = 11.0834  \n",
      "\n",
      "Fold: 9  Epoch: 403  Training loss = 3.0974  Validation loss = 11.0830  \n",
      "\n",
      "Fold: 9  Epoch: 404  Training loss = 3.0972  Validation loss = 11.0827  \n",
      "\n",
      "Fold: 9  Epoch: 405  Training loss = 3.0970  Validation loss = 11.0824  \n",
      "\n",
      "Fold: 9  Epoch: 406  Training loss = 3.0967  Validation loss = 11.0820  \n",
      "\n",
      "Fold: 9  Epoch: 407  Training loss = 3.0965  Validation loss = 11.0816  \n",
      "\n",
      "Fold: 9  Epoch: 408  Training loss = 3.0962  Validation loss = 11.0813  \n",
      "\n",
      "Fold: 9  Epoch: 409  Training loss = 3.0961  Validation loss = 11.0810  \n",
      "\n",
      "Fold: 9  Epoch: 410  Training loss = 3.0958  Validation loss = 11.0806  \n",
      "\n",
      "Fold: 9  Epoch: 411  Training loss = 3.0955  Validation loss = 11.0802  \n",
      "\n",
      "Fold: 9  Epoch: 412  Training loss = 3.0953  Validation loss = 11.0798  \n",
      "\n",
      "Fold: 9  Epoch: 413  Training loss = 3.0950  Validation loss = 11.0794  \n",
      "\n",
      "Fold: 9  Epoch: 414  Training loss = 3.0947  Validation loss = 11.0790  \n",
      "\n",
      "Fold: 9  Epoch: 415  Training loss = 3.0945  Validation loss = 11.0786  \n",
      "\n",
      "Fold: 9  Epoch: 416  Training loss = 3.0942  Validation loss = 11.0782  \n",
      "\n",
      "Fold: 9  Epoch: 417  Training loss = 3.0940  Validation loss = 11.0779  \n",
      "\n",
      "Fold: 9  Epoch: 418  Training loss = 3.0937  Validation loss = 11.0775  \n",
      "\n",
      "Fold: 9  Epoch: 419  Training loss = 3.0935  Validation loss = 11.0771  \n",
      "\n",
      "Fold: 9  Epoch: 420  Training loss = 3.0932  Validation loss = 11.0767  \n",
      "\n",
      "Fold: 9  Epoch: 421  Training loss = 3.0929  Validation loss = 11.0763  \n",
      "\n",
      "Fold: 9  Epoch: 422  Training loss = 3.0927  Validation loss = 11.0759  \n",
      "\n",
      "Fold: 9  Epoch: 423  Training loss = 3.0924  Validation loss = 11.0756  \n",
      "\n",
      "Fold: 9  Epoch: 424  Training loss = 3.0922  Validation loss = 11.0752  \n",
      "\n",
      "Fold: 9  Epoch: 425  Training loss = 3.0919  Validation loss = 11.0748  \n",
      "\n",
      "Fold: 9  Epoch: 426  Training loss = 3.0916  Validation loss = 11.0744  \n",
      "\n",
      "Fold: 9  Epoch: 427  Training loss = 3.0914  Validation loss = 11.0741  \n",
      "\n",
      "Fold: 9  Epoch: 428  Training loss = 3.0912  Validation loss = 11.0738  \n",
      "\n",
      "Fold: 9  Epoch: 429  Training loss = 3.0910  Validation loss = 11.0734  \n",
      "\n",
      "Fold: 9  Epoch: 430  Training loss = 3.0907  Validation loss = 11.0729  \n",
      "\n",
      "Fold: 9  Epoch: 431  Training loss = 3.0905  Validation loss = 11.0726  \n",
      "\n",
      "Fold: 9  Epoch: 432  Training loss = 3.0902  Validation loss = 11.0723  \n",
      "\n",
      "Fold: 9  Epoch: 433  Training loss = 3.0900  Validation loss = 11.0719  \n",
      "\n",
      "Fold: 9  Epoch: 434  Training loss = 3.0898  Validation loss = 11.0716  \n",
      "\n",
      "Fold: 9  Epoch: 435  Training loss = 3.0895  Validation loss = 11.0712  \n",
      "\n",
      "Fold: 9  Epoch: 436  Training loss = 3.0893  Validation loss = 11.0709  \n",
      "\n",
      "Fold: 9  Epoch: 437  Training loss = 3.0890  Validation loss = 11.0705  \n",
      "\n",
      "Fold: 9  Epoch: 438  Training loss = 3.0888  Validation loss = 11.0701  \n",
      "\n",
      "Fold: 9  Epoch: 439  Training loss = 3.0886  Validation loss = 11.0698  \n",
      "\n",
      "Fold: 9  Epoch: 440  Training loss = 3.0884  Validation loss = 11.0695  \n",
      "\n",
      "Fold: 9  Epoch: 441  Training loss = 3.0881  Validation loss = 11.0691  \n",
      "\n",
      "Fold: 9  Epoch: 442  Training loss = 3.0879  Validation loss = 11.0688  \n",
      "\n",
      "Fold: 9  Epoch: 443  Training loss = 3.0877  Validation loss = 11.0685  \n",
      "\n",
      "Fold: 9  Epoch: 444  Training loss = 3.0874  Validation loss = 11.0681  \n",
      "\n",
      "Fold: 9  Epoch: 445  Training loss = 3.0872  Validation loss = 11.0677  \n",
      "\n",
      "Fold: 9  Epoch: 446  Training loss = 3.0870  Validation loss = 11.0674  \n",
      "\n",
      "Fold: 9  Epoch: 447  Training loss = 3.0868  Validation loss = 11.0672  \n",
      "\n",
      "Fold: 9  Epoch: 448  Training loss = 3.0865  Validation loss = 11.0668  \n",
      "\n",
      "Fold: 9  Epoch: 449  Training loss = 3.0863  Validation loss = 11.0665  \n",
      "\n",
      "Fold: 9  Epoch: 450  Training loss = 3.0861  Validation loss = 11.0661  \n",
      "\n",
      "Fold: 9  Epoch: 451  Training loss = 3.0859  Validation loss = 11.0658  \n",
      "\n",
      "Fold: 9  Epoch: 452  Training loss = 3.0857  Validation loss = 11.0655  \n",
      "\n",
      "Fold: 9  Epoch: 453  Training loss = 3.0854  Validation loss = 11.0651  \n",
      "\n",
      "Fold: 9  Epoch: 454  Training loss = 3.0851  Validation loss = 11.0647  \n",
      "\n",
      "Fold: 9  Epoch: 455  Training loss = 3.0849  Validation loss = 11.0644  \n",
      "\n",
      "Fold: 9  Epoch: 456  Training loss = 3.0847  Validation loss = 11.0641  \n",
      "\n",
      "Fold: 9  Epoch: 457  Training loss = 3.0845  Validation loss = 11.0637  \n",
      "\n",
      "Fold: 9  Epoch: 458  Training loss = 3.0843  Validation loss = 11.0634  \n",
      "\n",
      "Fold: 9  Epoch: 459  Training loss = 3.0841  Validation loss = 11.0631  \n",
      "\n",
      "Fold: 9  Epoch: 460  Training loss = 3.0838  Validation loss = 11.0628  \n",
      "\n",
      "Fold: 9  Epoch: 461  Training loss = 3.0836  Validation loss = 11.0624  \n",
      "\n",
      "Fold: 9  Epoch: 462  Training loss = 3.0834  Validation loss = 11.0621  \n",
      "\n",
      "Fold: 9  Epoch: 463  Training loss = 3.0832  Validation loss = 11.0618  \n",
      "\n",
      "Fold: 9  Epoch: 464  Training loss = 3.0829  Validation loss = 11.0614  \n",
      "\n",
      "Fold: 9  Epoch: 465  Training loss = 3.0827  Validation loss = 11.0611  \n",
      "\n",
      "Fold: 9  Epoch: 466  Training loss = 3.0825  Validation loss = 11.0608  \n",
      "\n",
      "Fold: 9  Epoch: 467  Training loss = 3.0823  Validation loss = 11.0604  \n",
      "\n",
      "Fold: 9  Epoch: 468  Training loss = 3.0821  Validation loss = 11.0601  \n",
      "\n",
      "Fold: 9  Epoch: 469  Training loss = 3.0818  Validation loss = 11.0597  \n",
      "\n",
      "Fold: 9  Epoch: 470  Training loss = 3.0816  Validation loss = 11.0594  \n",
      "\n",
      "Fold: 9  Epoch: 471  Training loss = 3.0814  Validation loss = 11.0590  \n",
      "\n",
      "Fold: 9  Epoch: 472  Training loss = 3.0811  Validation loss = 11.0587  \n",
      "\n",
      "Fold: 9  Epoch: 473  Training loss = 3.0809  Validation loss = 11.0584  \n",
      "\n",
      "Fold: 9  Epoch: 474  Training loss = 3.0807  Validation loss = 11.0580  \n",
      "\n",
      "Fold: 9  Epoch: 475  Training loss = 3.0804  Validation loss = 11.0576  \n",
      "\n",
      "Fold: 9  Epoch: 476  Training loss = 3.0801  Validation loss = 11.0571  \n",
      "\n",
      "Fold: 9  Epoch: 477  Training loss = 3.0798  Validation loss = 11.0567  \n",
      "\n",
      "Fold: 9  Epoch: 478  Training loss = 3.0796  Validation loss = 11.0564  \n",
      "\n",
      "Fold: 9  Epoch: 479  Training loss = 3.0793  Validation loss = 11.0560  \n",
      "\n",
      "Fold: 9  Epoch: 480  Training loss = 3.0791  Validation loss = 11.0557  \n",
      "\n",
      "Fold: 9  Epoch: 481  Training loss = 3.0788  Validation loss = 11.0552  \n",
      "\n",
      "Fold: 9  Epoch: 482  Training loss = 3.0786  Validation loss = 11.0549  \n",
      "\n",
      "Fold: 9  Epoch: 483  Training loss = 3.0783  Validation loss = 11.0545  \n",
      "\n",
      "Fold: 9  Epoch: 484  Training loss = 3.0781  Validation loss = 11.0542  \n",
      "\n",
      "Fold: 9  Epoch: 485  Training loss = 3.0779  Validation loss = 11.0539  \n",
      "\n",
      "Fold: 9  Epoch: 486  Training loss = 3.0777  Validation loss = 11.0536  \n",
      "\n",
      "Fold: 9  Epoch: 487  Training loss = 3.0775  Validation loss = 11.0532  \n",
      "\n",
      "Fold: 9  Epoch: 488  Training loss = 3.0772  Validation loss = 11.0528  \n",
      "\n",
      "Fold: 9  Epoch: 489  Training loss = 3.0769  Validation loss = 11.0524  \n",
      "\n",
      "Fold: 9  Epoch: 490  Training loss = 3.0767  Validation loss = 11.0520  \n",
      "\n",
      "Fold: 9  Epoch: 491  Training loss = 3.0764  Validation loss = 11.0517  \n",
      "\n",
      "Fold: 9  Epoch: 492  Training loss = 3.0762  Validation loss = 11.0514  \n",
      "\n",
      "Fold: 9  Epoch: 493  Training loss = 3.0760  Validation loss = 11.0510  \n",
      "\n",
      "Fold: 9  Epoch: 494  Training loss = 3.0758  Validation loss = 11.0507  \n",
      "\n",
      "Fold: 9  Epoch: 495  Training loss = 3.0755  Validation loss = 11.0503  \n",
      "\n",
      "Fold: 9  Epoch: 496  Training loss = 3.0753  Validation loss = 11.0500  \n",
      "\n",
      "Fold: 9  Epoch: 497  Training loss = 3.0752  Validation loss = 11.0497  \n",
      "\n",
      "Fold: 9  Epoch: 498  Training loss = 3.0750  Validation loss = 11.0494  \n",
      "\n",
      "Fold: 9  Epoch: 499  Training loss = 3.0747  Validation loss = 11.0490  \n",
      "\n",
      "Fold: 9  Epoch: 500  Training loss = 3.0745  Validation loss = 11.0487  \n",
      "\n",
      "Check model:  Fold: 9  Optimal epoch: 500  \n",
      "\n",
      "Fold: 10  Epoch: 1  Training loss = 4.0841  Validation loss = 7.2568  \n",
      "\n",
      "Fold: 10  Epoch: 2  Training loss = 4.0839  Validation loss = 7.2566  \n",
      "\n",
      "Fold: 10  Epoch: 3  Training loss = 4.0835  Validation loss = 7.2563  \n",
      "\n",
      "Fold: 10  Epoch: 4  Training loss = 4.0831  Validation loss = 7.2559  \n",
      "\n",
      "Fold: 10  Epoch: 5  Training loss = 4.0828  Validation loss = 7.2556  \n",
      "\n",
      "Fold: 10  Epoch: 6  Training loss = 4.0825  Validation loss = 7.2554  \n",
      "\n",
      "Fold: 10  Epoch: 7  Training loss = 4.0823  Validation loss = 7.2551  \n",
      "\n",
      "Fold: 10  Epoch: 8  Training loss = 4.0820  Validation loss = 7.2549  \n",
      "\n",
      "Fold: 10  Epoch: 9  Training loss = 4.0816  Validation loss = 7.2545  \n",
      "\n",
      "Fold: 10  Epoch: 10  Training loss = 4.0813  Validation loss = 7.2542  \n",
      "\n",
      "Fold: 10  Epoch: 11  Training loss = 4.0810  Validation loss = 7.2540  \n",
      "\n",
      "Fold: 10  Epoch: 12  Training loss = 4.0806  Validation loss = 7.2536  \n",
      "\n",
      "Fold: 10  Epoch: 13  Training loss = 4.0803  Validation loss = 7.2533  \n",
      "\n",
      "Fold: 10  Epoch: 14  Training loss = 4.0801  Validation loss = 7.2531  \n",
      "\n",
      "Fold: 10  Epoch: 15  Training loss = 4.0797  Validation loss = 7.2527  \n",
      "\n",
      "Fold: 10  Epoch: 16  Training loss = 4.0795  Validation loss = 7.2525  \n",
      "\n",
      "Fold: 10  Epoch: 17  Training loss = 4.0792  Validation loss = 7.2522  \n",
      "\n",
      "Fold: 10  Epoch: 18  Training loss = 4.0789  Validation loss = 7.2519  \n",
      "\n",
      "Fold: 10  Epoch: 19  Training loss = 4.0785  Validation loss = 7.2516  \n",
      "\n",
      "Fold: 10  Epoch: 20  Training loss = 4.0782  Validation loss = 7.2513  \n",
      "\n",
      "Fold: 10  Epoch: 21  Training loss = 4.0780  Validation loss = 7.2510  \n",
      "\n",
      "Fold: 10  Epoch: 22  Training loss = 4.0777  Validation loss = 7.2508  \n",
      "\n",
      "Fold: 10  Epoch: 23  Training loss = 4.0775  Validation loss = 7.2506  \n",
      "\n",
      "Fold: 10  Epoch: 24  Training loss = 4.0772  Validation loss = 7.2504  \n",
      "\n",
      "Fold: 10  Epoch: 25  Training loss = 4.0769  Validation loss = 7.2500  \n",
      "\n",
      "Fold: 10  Epoch: 26  Training loss = 4.0765  Validation loss = 7.2497  \n",
      "\n",
      "Fold: 10  Epoch: 27  Training loss = 4.0762  Validation loss = 7.2494  \n",
      "\n",
      "Fold: 10  Epoch: 28  Training loss = 4.0759  Validation loss = 7.2492  \n",
      "\n",
      "Fold: 10  Epoch: 29  Training loss = 4.0757  Validation loss = 7.2489  \n",
      "\n",
      "Fold: 10  Epoch: 30  Training loss = 4.0754  Validation loss = 7.2487  \n",
      "\n",
      "Fold: 10  Epoch: 31  Training loss = 4.0751  Validation loss = 7.2485  \n",
      "\n",
      "Fold: 10  Epoch: 32  Training loss = 4.0748  Validation loss = 7.2482  \n",
      "\n",
      "Fold: 10  Epoch: 33  Training loss = 4.0745  Validation loss = 7.2479  \n",
      "\n",
      "Fold: 10  Epoch: 34  Training loss = 4.0741  Validation loss = 7.2475  \n",
      "\n",
      "Fold: 10  Epoch: 35  Training loss = 4.0739  Validation loss = 7.2473  \n",
      "\n",
      "Fold: 10  Epoch: 36  Training loss = 4.0735  Validation loss = 7.2469  \n",
      "\n",
      "Fold: 10  Epoch: 37  Training loss = 4.0732  Validation loss = 7.2466  \n",
      "\n",
      "Fold: 10  Epoch: 38  Training loss = 4.0729  Validation loss = 7.2464  \n",
      "\n",
      "Fold: 10  Epoch: 39  Training loss = 4.0727  Validation loss = 7.2462  \n",
      "\n",
      "Fold: 10  Epoch: 40  Training loss = 4.0724  Validation loss = 7.2459  \n",
      "\n",
      "Fold: 10  Epoch: 41  Training loss = 4.0721  Validation loss = 7.2456  \n",
      "\n",
      "Fold: 10  Epoch: 42  Training loss = 4.0718  Validation loss = 7.2453  \n",
      "\n",
      "Fold: 10  Epoch: 43  Training loss = 4.0714  Validation loss = 7.2451  \n",
      "\n",
      "Fold: 10  Epoch: 44  Training loss = 4.0712  Validation loss = 7.2448  \n",
      "\n",
      "Fold: 10  Epoch: 45  Training loss = 4.0709  Validation loss = 7.2445  \n",
      "\n",
      "Fold: 10  Epoch: 46  Training loss = 4.0706  Validation loss = 7.2442  \n",
      "\n",
      "Fold: 10  Epoch: 47  Training loss = 4.0703  Validation loss = 7.2440  \n",
      "\n",
      "Fold: 10  Epoch: 48  Training loss = 4.0700  Validation loss = 7.2437  \n",
      "\n",
      "Fold: 10  Epoch: 49  Training loss = 4.0697  Validation loss = 7.2434  \n",
      "\n",
      "Fold: 10  Epoch: 50  Training loss = 4.0694  Validation loss = 7.2431  \n",
      "\n",
      "Fold: 10  Epoch: 51  Training loss = 4.0691  Validation loss = 7.2429  \n",
      "\n",
      "Fold: 10  Epoch: 52  Training loss = 4.0689  Validation loss = 7.2426  \n",
      "\n",
      "Fold: 10  Epoch: 53  Training loss = 4.0686  Validation loss = 7.2424  \n",
      "\n",
      "Fold: 10  Epoch: 54  Training loss = 4.0684  Validation loss = 7.2422  \n",
      "\n",
      "Fold: 10  Epoch: 55  Training loss = 4.0681  Validation loss = 7.2419  \n",
      "\n",
      "Fold: 10  Epoch: 56  Training loss = 4.0678  Validation loss = 7.2416  \n",
      "\n",
      "Fold: 10  Epoch: 57  Training loss = 4.0675  Validation loss = 7.2414  \n",
      "\n",
      "Fold: 10  Epoch: 58  Training loss = 4.0672  Validation loss = 7.2411  \n",
      "\n",
      "Fold: 10  Epoch: 59  Training loss = 4.0670  Validation loss = 7.2409  \n",
      "\n",
      "Fold: 10  Epoch: 60  Training loss = 4.0667  Validation loss = 7.2406  \n",
      "\n",
      "Fold: 10  Epoch: 61  Training loss = 4.0664  Validation loss = 7.2404  \n",
      "\n",
      "Fold: 10  Epoch: 62  Training loss = 4.0662  Validation loss = 7.2401  \n",
      "\n",
      "Fold: 10  Epoch: 63  Training loss = 4.0659  Validation loss = 7.2398  \n",
      "\n",
      "Fold: 10  Epoch: 64  Training loss = 4.0656  Validation loss = 7.2395  \n",
      "\n",
      "Fold: 10  Epoch: 65  Training loss = 4.0654  Validation loss = 7.2394  \n",
      "\n",
      "Fold: 10  Epoch: 66  Training loss = 4.0651  Validation loss = 7.2390  \n",
      "\n",
      "Fold: 10  Epoch: 67  Training loss = 4.0648  Validation loss = 7.2388  \n",
      "\n",
      "Fold: 10  Epoch: 68  Training loss = 4.0645  Validation loss = 7.2384  \n",
      "\n",
      "Fold: 10  Epoch: 69  Training loss = 4.0643  Validation loss = 7.2383  \n",
      "\n",
      "Fold: 10  Epoch: 70  Training loss = 4.0640  Validation loss = 7.2380  \n",
      "\n",
      "Fold: 10  Epoch: 71  Training loss = 4.0637  Validation loss = 7.2377  \n",
      "\n",
      "Fold: 10  Epoch: 72  Training loss = 4.0635  Validation loss = 7.2375  \n",
      "\n",
      "Fold: 10  Epoch: 73  Training loss = 4.0632  Validation loss = 7.2373  \n",
      "\n",
      "Fold: 10  Epoch: 74  Training loss = 4.0629  Validation loss = 7.2370  \n",
      "\n",
      "Fold: 10  Epoch: 75  Training loss = 4.0626  Validation loss = 7.2367  \n",
      "\n",
      "Fold: 10  Epoch: 76  Training loss = 4.0623  Validation loss = 7.2365  \n",
      "\n",
      "Fold: 10  Epoch: 77  Training loss = 4.0620  Validation loss = 7.2362  \n",
      "\n",
      "Fold: 10  Epoch: 78  Training loss = 4.0618  Validation loss = 7.2360  \n",
      "\n",
      "Fold: 10  Epoch: 79  Training loss = 4.0615  Validation loss = 7.2358  \n",
      "\n",
      "Fold: 10  Epoch: 80  Training loss = 4.0612  Validation loss = 7.2356  \n",
      "\n",
      "Fold: 10  Epoch: 81  Training loss = 4.0609  Validation loss = 7.2352  \n",
      "\n",
      "Fold: 10  Epoch: 82  Training loss = 4.0606  Validation loss = 7.2349  \n",
      "\n",
      "Fold: 10  Epoch: 83  Training loss = 4.0603  Validation loss = 7.2347  \n",
      "\n",
      "Fold: 10  Epoch: 84  Training loss = 4.0600  Validation loss = 7.2342  \n",
      "\n",
      "Fold: 10  Epoch: 85  Training loss = 4.0597  Validation loss = 7.2340  \n",
      "\n",
      "Fold: 10  Epoch: 86  Training loss = 4.0594  Validation loss = 7.2337  \n",
      "\n",
      "Fold: 10  Epoch: 87  Training loss = 4.0591  Validation loss = 7.2334  \n",
      "\n",
      "Fold: 10  Epoch: 88  Training loss = 4.0588  Validation loss = 7.2331  \n",
      "\n",
      "Fold: 10  Epoch: 89  Training loss = 4.0585  Validation loss = 7.2328  \n",
      "\n",
      "Fold: 10  Epoch: 90  Training loss = 4.0581  Validation loss = 7.2325  \n",
      "\n",
      "Fold: 10  Epoch: 91  Training loss = 4.0578  Validation loss = 7.2323  \n",
      "\n",
      "Fold: 10  Epoch: 92  Training loss = 4.0576  Validation loss = 7.2320  \n",
      "\n",
      "Fold: 10  Epoch: 93  Training loss = 4.0573  Validation loss = 7.2318  \n",
      "\n",
      "Fold: 10  Epoch: 94  Training loss = 4.0570  Validation loss = 7.2315  \n",
      "\n",
      "Fold: 10  Epoch: 95  Training loss = 4.0567  Validation loss = 7.2313  \n",
      "\n",
      "Fold: 10  Epoch: 96  Training loss = 4.0564  Validation loss = 7.2311  \n",
      "\n",
      "Fold: 10  Epoch: 97  Training loss = 4.0561  Validation loss = 7.2308  \n",
      "\n",
      "Fold: 10  Epoch: 98  Training loss = 4.0557  Validation loss = 7.2304  \n",
      "\n",
      "Fold: 10  Epoch: 99  Training loss = 4.0554  Validation loss = 7.2302  \n",
      "\n",
      "Fold: 10  Epoch: 100  Training loss = 4.0551  Validation loss = 7.2299  \n",
      "\n",
      "Fold: 10  Epoch: 101  Training loss = 4.0548  Validation loss = 7.2296  \n",
      "\n",
      "Fold: 10  Epoch: 102  Training loss = 4.0545  Validation loss = 7.2293  \n",
      "\n",
      "Fold: 10  Epoch: 103  Training loss = 4.0542  Validation loss = 7.2290  \n",
      "\n",
      "Fold: 10  Epoch: 104  Training loss = 4.0538  Validation loss = 7.2287  \n",
      "\n",
      "Fold: 10  Epoch: 105  Training loss = 4.0536  Validation loss = 7.2285  \n",
      "\n",
      "Fold: 10  Epoch: 106  Training loss = 4.0533  Validation loss = 7.2282  \n",
      "\n",
      "Fold: 10  Epoch: 107  Training loss = 4.0529  Validation loss = 7.2278  \n",
      "\n",
      "Fold: 10  Epoch: 108  Training loss = 4.0527  Validation loss = 7.2276  \n",
      "\n",
      "Fold: 10  Epoch: 109  Training loss = 4.0524  Validation loss = 7.2273  \n",
      "\n",
      "Fold: 10  Epoch: 110  Training loss = 4.0520  Validation loss = 7.2270  \n",
      "\n",
      "Fold: 10  Epoch: 111  Training loss = 4.0518  Validation loss = 7.2268  \n",
      "\n",
      "Fold: 10  Epoch: 112  Training loss = 4.0515  Validation loss = 7.2265  \n",
      "\n",
      "Fold: 10  Epoch: 113  Training loss = 4.0513  Validation loss = 7.2263  \n",
      "\n",
      "Fold: 10  Epoch: 114  Training loss = 4.0510  Validation loss = 7.2260  \n",
      "\n",
      "Fold: 10  Epoch: 115  Training loss = 4.0507  Validation loss = 7.2257  \n",
      "\n",
      "Fold: 10  Epoch: 116  Training loss = 4.0504  Validation loss = 7.2255  \n",
      "\n",
      "Fold: 10  Epoch: 117  Training loss = 4.0501  Validation loss = 7.2252  \n",
      "\n",
      "Fold: 10  Epoch: 118  Training loss = 4.0499  Validation loss = 7.2250  \n",
      "\n",
      "Fold: 10  Epoch: 119  Training loss = 4.0496  Validation loss = 7.2247  \n",
      "\n",
      "Fold: 10  Epoch: 120  Training loss = 4.0492  Validation loss = 7.2244  \n",
      "\n",
      "Fold: 10  Epoch: 121  Training loss = 4.0490  Validation loss = 7.2241  \n",
      "\n",
      "Fold: 10  Epoch: 122  Training loss = 4.0488  Validation loss = 7.2239  \n",
      "\n",
      "Fold: 10  Epoch: 123  Training loss = 4.0484  Validation loss = 7.2235  \n",
      "\n",
      "Fold: 10  Epoch: 124  Training loss = 4.0482  Validation loss = 7.2233  \n",
      "\n",
      "Fold: 10  Epoch: 125  Training loss = 4.0479  Validation loss = 7.2231  \n",
      "\n",
      "Fold: 10  Epoch: 126  Training loss = 4.0476  Validation loss = 7.2228  \n",
      "\n",
      "Fold: 10  Epoch: 127  Training loss = 4.0474  Validation loss = 7.2226  \n",
      "\n",
      "Fold: 10  Epoch: 128  Training loss = 4.0471  Validation loss = 7.2224  \n",
      "\n",
      "Fold: 10  Epoch: 129  Training loss = 4.0468  Validation loss = 7.2221  \n",
      "\n",
      "Fold: 10  Epoch: 130  Training loss = 4.0466  Validation loss = 7.2219  \n",
      "\n",
      "Fold: 10  Epoch: 131  Training loss = 4.0462  Validation loss = 7.2216  \n",
      "\n",
      "Fold: 10  Epoch: 132  Training loss = 4.0460  Validation loss = 7.2213  \n",
      "\n",
      "Fold: 10  Epoch: 133  Training loss = 4.0458  Validation loss = 7.2211  \n",
      "\n",
      "Fold: 10  Epoch: 134  Training loss = 4.0455  Validation loss = 7.2209  \n",
      "\n",
      "Fold: 10  Epoch: 135  Training loss = 4.0453  Validation loss = 7.2207  \n",
      "\n",
      "Fold: 10  Epoch: 136  Training loss = 4.0451  Validation loss = 7.2205  \n",
      "\n",
      "Fold: 10  Epoch: 137  Training loss = 4.0447  Validation loss = 7.2202  \n",
      "\n",
      "Fold: 10  Epoch: 138  Training loss = 4.0444  Validation loss = 7.2199  \n",
      "\n",
      "Fold: 10  Epoch: 139  Training loss = 4.0441  Validation loss = 7.2196  \n",
      "\n",
      "Fold: 10  Epoch: 140  Training loss = 4.0438  Validation loss = 7.2193  \n",
      "\n",
      "Fold: 10  Epoch: 141  Training loss = 4.0436  Validation loss = 7.2191  \n",
      "\n",
      "Fold: 10  Epoch: 142  Training loss = 4.0433  Validation loss = 7.2188  \n",
      "\n",
      "Fold: 10  Epoch: 143  Training loss = 4.0430  Validation loss = 7.2185  \n",
      "\n",
      "Fold: 10  Epoch: 144  Training loss = 4.0428  Validation loss = 7.2183  \n",
      "\n",
      "Fold: 10  Epoch: 145  Training loss = 4.0424  Validation loss = 7.2179  \n",
      "\n",
      "Fold: 10  Epoch: 146  Training loss = 4.0421  Validation loss = 7.2176  \n",
      "\n",
      "Fold: 10  Epoch: 147  Training loss = 4.0419  Validation loss = 7.2174  \n",
      "\n",
      "Fold: 10  Epoch: 148  Training loss = 4.0416  Validation loss = 7.2171  \n",
      "\n",
      "Fold: 10  Epoch: 149  Training loss = 4.0413  Validation loss = 7.2168  \n",
      "\n",
      "Fold: 10  Epoch: 150  Training loss = 4.0409  Validation loss = 7.2164  \n",
      "\n",
      "Fold: 10  Epoch: 151  Training loss = 4.0406  Validation loss = 7.2161  \n",
      "\n",
      "Fold: 10  Epoch: 152  Training loss = 4.0404  Validation loss = 7.2159  \n",
      "\n",
      "Fold: 10  Epoch: 153  Training loss = 4.0401  Validation loss = 7.2156  \n",
      "\n",
      "Fold: 10  Epoch: 154  Training loss = 4.0397  Validation loss = 7.2153  \n",
      "\n",
      "Fold: 10  Epoch: 155  Training loss = 4.0394  Validation loss = 7.2150  \n",
      "\n",
      "Fold: 10  Epoch: 156  Training loss = 4.0391  Validation loss = 7.2147  \n",
      "\n",
      "Fold: 10  Epoch: 157  Training loss = 4.0388  Validation loss = 7.2145  \n",
      "\n",
      "Fold: 10  Epoch: 158  Training loss = 4.0386  Validation loss = 7.2142  \n",
      "\n",
      "Fold: 10  Epoch: 159  Training loss = 4.0384  Validation loss = 7.2139  \n",
      "\n",
      "Fold: 10  Epoch: 160  Training loss = 4.0380  Validation loss = 7.2136  \n",
      "\n",
      "Fold: 10  Epoch: 161  Training loss = 4.0377  Validation loss = 7.2134  \n",
      "\n",
      "Fold: 10  Epoch: 162  Training loss = 4.0374  Validation loss = 7.2130  \n",
      "\n",
      "Fold: 10  Epoch: 163  Training loss = 4.0373  Validation loss = 7.2129  \n",
      "\n",
      "Fold: 10  Epoch: 164  Training loss = 4.0371  Validation loss = 7.2127  \n",
      "\n",
      "Fold: 10  Epoch: 165  Training loss = 4.0368  Validation loss = 7.2124  \n",
      "\n",
      "Fold: 10  Epoch: 166  Training loss = 4.0365  Validation loss = 7.2121  \n",
      "\n",
      "Fold: 10  Epoch: 167  Training loss = 4.0362  Validation loss = 7.2118  \n",
      "\n",
      "Fold: 10  Epoch: 168  Training loss = 4.0359  Validation loss = 7.2116  \n",
      "\n",
      "Fold: 10  Epoch: 169  Training loss = 4.0356  Validation loss = 7.2113  \n",
      "\n",
      "Fold: 10  Epoch: 170  Training loss = 4.0353  Validation loss = 7.2110  \n",
      "\n",
      "Fold: 10  Epoch: 171  Training loss = 4.0349  Validation loss = 7.2107  \n",
      "\n",
      "Fold: 10  Epoch: 172  Training loss = 4.0346  Validation loss = 7.2104  \n",
      "\n",
      "Fold: 10  Epoch: 173  Training loss = 4.0343  Validation loss = 7.2102  \n",
      "\n",
      "Fold: 10  Epoch: 174  Training loss = 4.0340  Validation loss = 7.2098  \n",
      "\n",
      "Fold: 10  Epoch: 175  Training loss = 4.0337  Validation loss = 7.2095  \n",
      "\n",
      "Fold: 10  Epoch: 176  Training loss = 4.0335  Validation loss = 7.2093  \n",
      "\n",
      "Fold: 10  Epoch: 177  Training loss = 4.0333  Validation loss = 7.2091  \n",
      "\n",
      "Fold: 10  Epoch: 178  Training loss = 4.0331  Validation loss = 7.2089  \n",
      "\n",
      "Fold: 10  Epoch: 179  Training loss = 4.0328  Validation loss = 7.2085  \n",
      "\n",
      "Fold: 10  Epoch: 180  Training loss = 4.0326  Validation loss = 7.2084  \n",
      "\n",
      "Fold: 10  Epoch: 181  Training loss = 4.0323  Validation loss = 7.2081  \n",
      "\n",
      "Fold: 10  Epoch: 182  Training loss = 4.0320  Validation loss = 7.2078  \n",
      "\n",
      "Fold: 10  Epoch: 183  Training loss = 4.0317  Validation loss = 7.2075  \n",
      "\n",
      "Fold: 10  Epoch: 184  Training loss = 4.0314  Validation loss = 7.2073  \n",
      "\n",
      "Fold: 10  Epoch: 185  Training loss = 4.0312  Validation loss = 7.2070  \n",
      "\n",
      "Fold: 10  Epoch: 186  Training loss = 4.0309  Validation loss = 7.2068  \n",
      "\n",
      "Fold: 10  Epoch: 187  Training loss = 4.0306  Validation loss = 7.2065  \n",
      "\n",
      "Fold: 10  Epoch: 188  Training loss = 4.0304  Validation loss = 7.2063  \n",
      "\n",
      "Fold: 10  Epoch: 189  Training loss = 4.0301  Validation loss = 7.2061  \n",
      "\n",
      "Fold: 10  Epoch: 190  Training loss = 4.0298  Validation loss = 7.2057  \n",
      "\n",
      "Fold: 10  Epoch: 191  Training loss = 4.0295  Validation loss = 7.2055  \n",
      "\n",
      "Fold: 10  Epoch: 192  Training loss = 4.0292  Validation loss = 7.2052  \n",
      "\n",
      "Fold: 10  Epoch: 193  Training loss = 4.0290  Validation loss = 7.2050  \n",
      "\n",
      "Fold: 10  Epoch: 194  Training loss = 4.0287  Validation loss = 7.2047  \n",
      "\n",
      "Fold: 10  Epoch: 195  Training loss = 4.0284  Validation loss = 7.2043  \n",
      "\n",
      "Fold: 10  Epoch: 196  Training loss = 4.0282  Validation loss = 7.2041  \n",
      "\n",
      "Fold: 10  Epoch: 197  Training loss = 4.0278  Validation loss = 7.2038  \n",
      "\n",
      "Fold: 10  Epoch: 198  Training loss = 4.0276  Validation loss = 7.2036  \n",
      "\n",
      "Fold: 10  Epoch: 199  Training loss = 4.0273  Validation loss = 7.2033  \n",
      "\n",
      "Fold: 10  Epoch: 200  Training loss = 4.0270  Validation loss = 7.2030  \n",
      "\n",
      "Fold: 10  Epoch: 201  Training loss = 4.0267  Validation loss = 7.2027  \n",
      "\n",
      "Fold: 10  Epoch: 202  Training loss = 4.0265  Validation loss = 7.2025  \n",
      "\n",
      "Fold: 10  Epoch: 203  Training loss = 4.0262  Validation loss = 7.2022  \n",
      "\n",
      "Fold: 10  Epoch: 204  Training loss = 4.0259  Validation loss = 7.2020  \n",
      "\n",
      "Fold: 10  Epoch: 205  Training loss = 4.0257  Validation loss = 7.2018  \n",
      "\n",
      "Fold: 10  Epoch: 206  Training loss = 4.0254  Validation loss = 7.2015  \n",
      "\n",
      "Fold: 10  Epoch: 207  Training loss = 4.0252  Validation loss = 7.2012  \n",
      "\n",
      "Fold: 10  Epoch: 208  Training loss = 4.0249  Validation loss = 7.2009  \n",
      "\n",
      "Fold: 10  Epoch: 209  Training loss = 4.0247  Validation loss = 7.2008  \n",
      "\n",
      "Fold: 10  Epoch: 210  Training loss = 4.0244  Validation loss = 7.2005  \n",
      "\n",
      "Fold: 10  Epoch: 211  Training loss = 4.0241  Validation loss = 7.2001  \n",
      "\n",
      "Fold: 10  Epoch: 212  Training loss = 4.0238  Validation loss = 7.1999  \n",
      "\n",
      "Fold: 10  Epoch: 213  Training loss = 4.0235  Validation loss = 7.1996  \n",
      "\n",
      "Fold: 10  Epoch: 214  Training loss = 4.0232  Validation loss = 7.1994  \n",
      "\n",
      "Fold: 10  Epoch: 215  Training loss = 4.0229  Validation loss = 7.1990  \n",
      "\n",
      "Fold: 10  Epoch: 216  Training loss = 4.0226  Validation loss = 7.1987  \n",
      "\n",
      "Fold: 10  Epoch: 217  Training loss = 4.0224  Validation loss = 7.1985  \n",
      "\n",
      "Fold: 10  Epoch: 218  Training loss = 4.0221  Validation loss = 7.1983  \n",
      "\n",
      "Fold: 10  Epoch: 219  Training loss = 4.0218  Validation loss = 7.1979  \n",
      "\n",
      "Fold: 10  Epoch: 220  Training loss = 4.0214  Validation loss = 7.1976  \n",
      "\n",
      "Fold: 10  Epoch: 221  Training loss = 4.0212  Validation loss = 7.1974  \n",
      "\n",
      "Fold: 10  Epoch: 222  Training loss = 4.0209  Validation loss = 7.1971  \n",
      "\n",
      "Fold: 10  Epoch: 223  Training loss = 4.0206  Validation loss = 7.1968  \n",
      "\n",
      "Fold: 10  Epoch: 224  Training loss = 4.0204  Validation loss = 7.1966  \n",
      "\n",
      "Fold: 10  Epoch: 225  Training loss = 4.0201  Validation loss = 7.1963  \n",
      "\n",
      "Fold: 10  Epoch: 226  Training loss = 4.0197  Validation loss = 7.1960  \n",
      "\n",
      "Fold: 10  Epoch: 227  Training loss = 4.0195  Validation loss = 7.1958  \n",
      "\n",
      "Fold: 10  Epoch: 228  Training loss = 4.0192  Validation loss = 7.1956  \n",
      "\n",
      "Fold: 10  Epoch: 229  Training loss = 4.0190  Validation loss = 7.1954  \n",
      "\n",
      "Fold: 10  Epoch: 230  Training loss = 4.0187  Validation loss = 7.1951  \n",
      "\n",
      "Fold: 10  Epoch: 231  Training loss = 4.0184  Validation loss = 7.1948  \n",
      "\n",
      "Fold: 10  Epoch: 232  Training loss = 4.0181  Validation loss = 7.1946  \n",
      "\n",
      "Fold: 10  Epoch: 233  Training loss = 4.0177  Validation loss = 7.1942  \n",
      "\n",
      "Fold: 10  Epoch: 234  Training loss = 4.0175  Validation loss = 7.1940  \n",
      "\n",
      "Fold: 10  Epoch: 235  Training loss = 4.0173  Validation loss = 7.1938  \n",
      "\n",
      "Fold: 10  Epoch: 236  Training loss = 4.0170  Validation loss = 7.1935  \n",
      "\n",
      "Fold: 10  Epoch: 237  Training loss = 4.0166  Validation loss = 7.1932  \n",
      "\n",
      "Fold: 10  Epoch: 238  Training loss = 4.0164  Validation loss = 7.1929  \n",
      "\n",
      "Fold: 10  Epoch: 239  Training loss = 4.0161  Validation loss = 7.1926  \n",
      "\n",
      "Fold: 10  Epoch: 240  Training loss = 4.0158  Validation loss = 7.1923  \n",
      "\n",
      "Fold: 10  Epoch: 241  Training loss = 4.0154  Validation loss = 7.1920  \n",
      "\n",
      "Fold: 10  Epoch: 242  Training loss = 4.0151  Validation loss = 7.1917  \n",
      "\n",
      "Fold: 10  Epoch: 243  Training loss = 4.0149  Validation loss = 7.1915  \n",
      "\n",
      "Fold: 10  Epoch: 244  Training loss = 4.0145  Validation loss = 7.1911  \n",
      "\n",
      "Fold: 10  Epoch: 245  Training loss = 4.0141  Validation loss = 7.1908  \n",
      "\n",
      "Fold: 10  Epoch: 246  Training loss = 4.0139  Validation loss = 7.1905  \n",
      "\n",
      "Fold: 10  Epoch: 247  Training loss = 4.0136  Validation loss = 7.1903  \n",
      "\n",
      "Fold: 10  Epoch: 248  Training loss = 4.0133  Validation loss = 7.1901  \n",
      "\n",
      "Fold: 10  Epoch: 249  Training loss = 4.0131  Validation loss = 7.1898  \n",
      "\n",
      "Fold: 10  Epoch: 250  Training loss = 4.0129  Validation loss = 7.1896  \n",
      "\n",
      "Fold: 10  Epoch: 251  Training loss = 4.0126  Validation loss = 7.1893  \n",
      "\n",
      "Fold: 10  Epoch: 252  Training loss = 4.0123  Validation loss = 7.1890  \n",
      "\n",
      "Fold: 10  Epoch: 253  Training loss = 4.0120  Validation loss = 7.1887  \n",
      "\n",
      "Fold: 10  Epoch: 254  Training loss = 4.0117  Validation loss = 7.1885  \n",
      "\n",
      "Fold: 10  Epoch: 255  Training loss = 4.0114  Validation loss = 7.1882  \n",
      "\n",
      "Fold: 10  Epoch: 256  Training loss = 4.0112  Validation loss = 7.1879  \n",
      "\n",
      "Fold: 10  Epoch: 257  Training loss = 4.0110  Validation loss = 7.1877  \n",
      "\n",
      "Fold: 10  Epoch: 258  Training loss = 4.0107  Validation loss = 7.1875  \n",
      "\n",
      "Fold: 10  Epoch: 259  Training loss = 4.0104  Validation loss = 7.1873  \n",
      "\n",
      "Fold: 10  Epoch: 260  Training loss = 4.0102  Validation loss = 7.1870  \n",
      "\n",
      "Fold: 10  Epoch: 261  Training loss = 4.0099  Validation loss = 7.1868  \n",
      "\n",
      "Fold: 10  Epoch: 262  Training loss = 4.0097  Validation loss = 7.1865  \n",
      "\n",
      "Fold: 10  Epoch: 263  Training loss = 4.0094  Validation loss = 7.1863  \n",
      "\n",
      "Fold: 10  Epoch: 264  Training loss = 4.0091  Validation loss = 7.1860  \n",
      "\n",
      "Fold: 10  Epoch: 265  Training loss = 4.0088  Validation loss = 7.1857  \n",
      "\n",
      "Fold: 10  Epoch: 266  Training loss = 4.0085  Validation loss = 7.1854  \n",
      "\n",
      "Fold: 10  Epoch: 267  Training loss = 4.0083  Validation loss = 7.1851  \n",
      "\n",
      "Fold: 10  Epoch: 268  Training loss = 4.0080  Validation loss = 7.1849  \n",
      "\n",
      "Fold: 10  Epoch: 269  Training loss = 4.0078  Validation loss = 7.1846  \n",
      "\n",
      "Fold: 10  Epoch: 270  Training loss = 4.0074  Validation loss = 7.1844  \n",
      "\n",
      "Fold: 10  Epoch: 271  Training loss = 4.0072  Validation loss = 7.1841  \n",
      "\n",
      "Fold: 10  Epoch: 272  Training loss = 4.0070  Validation loss = 7.1839  \n",
      "\n",
      "Fold: 10  Epoch: 273  Training loss = 4.0068  Validation loss = 7.1838  \n",
      "\n",
      "Fold: 10  Epoch: 274  Training loss = 4.0065  Validation loss = 7.1835  \n",
      "\n",
      "Fold: 10  Epoch: 275  Training loss = 4.0063  Validation loss = 7.1833  \n",
      "\n",
      "Fold: 10  Epoch: 276  Training loss = 4.0059  Validation loss = 7.1830  \n",
      "\n",
      "Fold: 10  Epoch: 277  Training loss = 4.0057  Validation loss = 7.1828  \n",
      "\n",
      "Fold: 10  Epoch: 278  Training loss = 4.0055  Validation loss = 7.1825  \n",
      "\n",
      "Fold: 10  Epoch: 279  Training loss = 4.0052  Validation loss = 7.1822  \n",
      "\n",
      "Fold: 10  Epoch: 280  Training loss = 4.0049  Validation loss = 7.1820  \n",
      "\n",
      "Fold: 10  Epoch: 281  Training loss = 4.0047  Validation loss = 7.1818  \n",
      "\n",
      "Fold: 10  Epoch: 282  Training loss = 4.0044  Validation loss = 7.1815  \n",
      "\n",
      "Fold: 10  Epoch: 283  Training loss = 4.0042  Validation loss = 7.1813  \n",
      "\n",
      "Fold: 10  Epoch: 284  Training loss = 4.0039  Validation loss = 7.1810  \n",
      "\n",
      "Fold: 10  Epoch: 285  Training loss = 4.0036  Validation loss = 7.1807  \n",
      "\n",
      "Fold: 10  Epoch: 286  Training loss = 4.0033  Validation loss = 7.1805  \n",
      "\n",
      "Fold: 10  Epoch: 287  Training loss = 4.0031  Validation loss = 7.1802  \n",
      "\n",
      "Fold: 10  Epoch: 288  Training loss = 4.0028  Validation loss = 7.1799  \n",
      "\n",
      "Fold: 10  Epoch: 289  Training loss = 4.0025  Validation loss = 7.1797  \n",
      "\n",
      "Fold: 10  Epoch: 290  Training loss = 4.0023  Validation loss = 7.1794  \n",
      "\n",
      "Fold: 10  Epoch: 291  Training loss = 4.0021  Validation loss = 7.1792  \n",
      "\n",
      "Fold: 10  Epoch: 292  Training loss = 4.0018  Validation loss = 7.1789  \n",
      "\n",
      "Fold: 10  Epoch: 293  Training loss = 4.0015  Validation loss = 7.1786  \n",
      "\n",
      "Fold: 10  Epoch: 294  Training loss = 4.0012  Validation loss = 7.1783  \n",
      "\n",
      "Fold: 10  Epoch: 295  Training loss = 4.0009  Validation loss = 7.1780  \n",
      "\n",
      "Fold: 10  Epoch: 296  Training loss = 4.0006  Validation loss = 7.1777  \n",
      "\n",
      "Fold: 10  Epoch: 297  Training loss = 4.0003  Validation loss = 7.1774  \n",
      "\n",
      "Fold: 10  Epoch: 298  Training loss = 3.9999  Validation loss = 7.1771  \n",
      "\n",
      "Fold: 10  Epoch: 299  Training loss = 3.9997  Validation loss = 7.1768  \n",
      "\n",
      "Fold: 10  Epoch: 300  Training loss = 3.9994  Validation loss = 7.1765  \n",
      "\n",
      "Fold: 10  Epoch: 301  Training loss = 3.9992  Validation loss = 7.1763  \n",
      "\n",
      "Fold: 10  Epoch: 302  Training loss = 3.9990  Validation loss = 7.1761  \n",
      "\n",
      "Fold: 10  Epoch: 303  Training loss = 3.9988  Validation loss = 7.1758  \n",
      "\n",
      "Fold: 10  Epoch: 304  Training loss = 3.9985  Validation loss = 7.1755  \n",
      "\n",
      "Fold: 10  Epoch: 305  Training loss = 3.9983  Validation loss = 7.1753  \n",
      "\n",
      "Fold: 10  Epoch: 306  Training loss = 3.9980  Validation loss = 7.1750  \n",
      "\n",
      "Fold: 10  Epoch: 307  Training loss = 3.9978  Validation loss = 7.1748  \n",
      "\n",
      "Fold: 10  Epoch: 308  Training loss = 3.9975  Validation loss = 7.1745  \n",
      "\n",
      "Fold: 10  Epoch: 309  Training loss = 3.9972  Validation loss = 7.1742  \n",
      "\n",
      "Fold: 10  Epoch: 310  Training loss = 3.9969  Validation loss = 7.1739  \n",
      "\n",
      "Fold: 10  Epoch: 311  Training loss = 3.9966  Validation loss = 7.1736  \n",
      "\n",
      "Fold: 10  Epoch: 312  Training loss = 3.9962  Validation loss = 7.1732  \n",
      "\n",
      "Fold: 10  Epoch: 313  Training loss = 3.9959  Validation loss = 7.1730  \n",
      "\n",
      "Fold: 10  Epoch: 314  Training loss = 3.9957  Validation loss = 7.1727  \n",
      "\n",
      "Fold: 10  Epoch: 315  Training loss = 3.9955  Validation loss = 7.1725  \n",
      "\n",
      "Fold: 10  Epoch: 316  Training loss = 3.9951  Validation loss = 7.1721  \n",
      "\n",
      "Fold: 10  Epoch: 317  Training loss = 3.9948  Validation loss = 7.1718  \n",
      "\n",
      "Fold: 10  Epoch: 318  Training loss = 3.9945  Validation loss = 7.1715  \n",
      "\n",
      "Fold: 10  Epoch: 319  Training loss = 3.9942  Validation loss = 7.1712  \n",
      "\n",
      "Fold: 10  Epoch: 320  Training loss = 3.9940  Validation loss = 7.1709  \n",
      "\n",
      "Fold: 10  Epoch: 321  Training loss = 3.9937  Validation loss = 7.1706  \n",
      "\n",
      "Fold: 10  Epoch: 322  Training loss = 3.9934  Validation loss = 7.1703  \n",
      "\n",
      "Fold: 10  Epoch: 323  Training loss = 3.9930  Validation loss = 7.1701  \n",
      "\n",
      "Fold: 10  Epoch: 324  Training loss = 3.9928  Validation loss = 7.1698  \n",
      "\n",
      "Fold: 10  Epoch: 325  Training loss = 3.9926  Validation loss = 7.1696  \n",
      "\n",
      "Fold: 10  Epoch: 326  Training loss = 3.9923  Validation loss = 7.1693  \n",
      "\n",
      "Fold: 10  Epoch: 327  Training loss = 3.9919  Validation loss = 7.1691  \n",
      "\n",
      "Fold: 10  Epoch: 328  Training loss = 3.9917  Validation loss = 7.1688  \n",
      "\n",
      "Fold: 10  Epoch: 329  Training loss = 3.9914  Validation loss = 7.1685  \n",
      "\n",
      "Fold: 10  Epoch: 330  Training loss = 3.9912  Validation loss = 7.1683  \n",
      "\n",
      "Fold: 10  Epoch: 331  Training loss = 3.9909  Validation loss = 7.1680  \n",
      "\n",
      "Fold: 10  Epoch: 332  Training loss = 3.9907  Validation loss = 7.1678  \n",
      "\n",
      "Fold: 10  Epoch: 333  Training loss = 3.9904  Validation loss = 7.1676  \n",
      "\n",
      "Fold: 10  Epoch: 334  Training loss = 3.9901  Validation loss = 7.1673  \n",
      "\n",
      "Fold: 10  Epoch: 335  Training loss = 3.9899  Validation loss = 7.1670  \n",
      "\n",
      "Fold: 10  Epoch: 336  Training loss = 3.9896  Validation loss = 7.1667  \n",
      "\n",
      "Fold: 10  Epoch: 337  Training loss = 3.9895  Validation loss = 7.1666  \n",
      "\n",
      "Fold: 10  Epoch: 338  Training loss = 3.9892  Validation loss = 7.1663  \n",
      "\n",
      "Fold: 10  Epoch: 339  Training loss = 3.9889  Validation loss = 7.1660  \n",
      "\n",
      "Fold: 10  Epoch: 340  Training loss = 3.9886  Validation loss = 7.1656  \n",
      "\n",
      "Fold: 10  Epoch: 341  Training loss = 3.9884  Validation loss = 7.1653  \n",
      "\n",
      "Fold: 10  Epoch: 342  Training loss = 3.9881  Validation loss = 7.1651  \n",
      "\n",
      "Fold: 10  Epoch: 343  Training loss = 3.9878  Validation loss = 7.1647  \n",
      "\n",
      "Fold: 10  Epoch: 344  Training loss = 3.9875  Validation loss = 7.1644  \n",
      "\n",
      "Fold: 10  Epoch: 345  Training loss = 3.9873  Validation loss = 7.1641  \n",
      "\n",
      "Fold: 10  Epoch: 346  Training loss = 3.9869  Validation loss = 7.1637  \n",
      "\n",
      "Fold: 10  Epoch: 347  Training loss = 3.9866  Validation loss = 7.1634  \n",
      "\n",
      "Fold: 10  Epoch: 348  Training loss = 3.9863  Validation loss = 7.1631  \n",
      "\n",
      "Fold: 10  Epoch: 349  Training loss = 3.9861  Validation loss = 7.1629  \n",
      "\n",
      "Fold: 10  Epoch: 350  Training loss = 3.9858  Validation loss = 7.1626  \n",
      "\n",
      "Fold: 10  Epoch: 351  Training loss = 3.9856  Validation loss = 7.1623  \n",
      "\n",
      "Fold: 10  Epoch: 352  Training loss = 3.9854  Validation loss = 7.1621  \n",
      "\n",
      "Fold: 10  Epoch: 353  Training loss = 3.9851  Validation loss = 7.1618  \n",
      "\n",
      "Fold: 10  Epoch: 354  Training loss = 3.9848  Validation loss = 7.1616  \n",
      "\n",
      "Fold: 10  Epoch: 355  Training loss = 3.9845  Validation loss = 7.1613  \n",
      "\n",
      "Fold: 10  Epoch: 356  Training loss = 3.9842  Validation loss = 7.1610  \n",
      "\n",
      "Fold: 10  Epoch: 357  Training loss = 3.9838  Validation loss = 7.1607  \n",
      "\n",
      "Fold: 10  Epoch: 358  Training loss = 3.9836  Validation loss = 7.1604  \n",
      "\n",
      "Fold: 10  Epoch: 359  Training loss = 3.9833  Validation loss = 7.1600  \n",
      "\n",
      "Fold: 10  Epoch: 360  Training loss = 3.9830  Validation loss = 7.1597  \n",
      "\n",
      "Fold: 10  Epoch: 361  Training loss = 3.9827  Validation loss = 7.1594  \n",
      "\n",
      "Fold: 10  Epoch: 362  Training loss = 3.9824  Validation loss = 7.1591  \n",
      "\n",
      "Fold: 10  Epoch: 363  Training loss = 3.9821  Validation loss = 7.1589  \n",
      "\n",
      "Fold: 10  Epoch: 364  Training loss = 3.9819  Validation loss = 7.1586  \n",
      "\n",
      "Fold: 10  Epoch: 365  Training loss = 3.9816  Validation loss = 7.1582  \n",
      "\n",
      "Fold: 10  Epoch: 366  Training loss = 3.9814  Validation loss = 7.1580  \n",
      "\n",
      "Fold: 10  Epoch: 367  Training loss = 3.9810  Validation loss = 7.1576  \n",
      "\n",
      "Fold: 10  Epoch: 368  Training loss = 3.9808  Validation loss = 7.1573  \n",
      "\n",
      "Fold: 10  Epoch: 369  Training loss = 3.9804  Validation loss = 7.1569  \n",
      "\n",
      "Fold: 10  Epoch: 370  Training loss = 3.9801  Validation loss = 7.1566  \n",
      "\n",
      "Fold: 10  Epoch: 371  Training loss = 3.9799  Validation loss = 7.1563  \n",
      "\n",
      "Fold: 10  Epoch: 372  Training loss = 3.9795  Validation loss = 7.1559  \n",
      "\n",
      "Fold: 10  Epoch: 373  Training loss = 3.9792  Validation loss = 7.1556  \n",
      "\n",
      "Fold: 10  Epoch: 374  Training loss = 3.9788  Validation loss = 7.1552  \n",
      "\n",
      "Fold: 10  Epoch: 375  Training loss = 3.9786  Validation loss = 7.1550  \n",
      "\n",
      "Fold: 10  Epoch: 376  Training loss = 3.9783  Validation loss = 7.1546  \n",
      "\n",
      "Fold: 10  Epoch: 377  Training loss = 3.9780  Validation loss = 7.1543  \n",
      "\n",
      "Fold: 10  Epoch: 378  Training loss = 3.9778  Validation loss = 7.1541  \n",
      "\n",
      "Fold: 10  Epoch: 379  Training loss = 3.9775  Validation loss = 7.1538  \n",
      "\n",
      "Fold: 10  Epoch: 380  Training loss = 3.9773  Validation loss = 7.1534  \n",
      "\n",
      "Fold: 10  Epoch: 381  Training loss = 3.9770  Validation loss = 7.1532  \n",
      "\n",
      "Fold: 10  Epoch: 382  Training loss = 3.9767  Validation loss = 7.1529  \n",
      "\n",
      "Fold: 10  Epoch: 383  Training loss = 3.9765  Validation loss = 7.1526  \n",
      "\n",
      "Fold: 10  Epoch: 384  Training loss = 3.9762  Validation loss = 7.1523  \n",
      "\n",
      "Fold: 10  Epoch: 385  Training loss = 3.9759  Validation loss = 7.1520  \n",
      "\n",
      "Fold: 10  Epoch: 386  Training loss = 3.9756  Validation loss = 7.1517  \n",
      "\n",
      "Fold: 10  Epoch: 387  Training loss = 3.9754  Validation loss = 7.1513  \n",
      "\n",
      "Fold: 10  Epoch: 388  Training loss = 3.9751  Validation loss = 7.1511  \n",
      "\n",
      "Fold: 10  Epoch: 389  Training loss = 3.9748  Validation loss = 7.1507  \n",
      "\n",
      "Fold: 10  Epoch: 390  Training loss = 3.9745  Validation loss = 7.1504  \n",
      "\n",
      "Fold: 10  Epoch: 391  Training loss = 3.9742  Validation loss = 7.1500  \n",
      "\n",
      "Fold: 10  Epoch: 392  Training loss = 3.9739  Validation loss = 7.1497  \n",
      "\n",
      "Fold: 10  Epoch: 393  Training loss = 3.9736  Validation loss = 7.1493  \n",
      "\n",
      "Fold: 10  Epoch: 394  Training loss = 3.9734  Validation loss = 7.1491  \n",
      "\n",
      "Fold: 10  Epoch: 395  Training loss = 3.9731  Validation loss = 7.1488  \n",
      "\n",
      "Fold: 10  Epoch: 396  Training loss = 3.9728  Validation loss = 7.1484  \n",
      "\n",
      "Fold: 10  Epoch: 397  Training loss = 3.9726  Validation loss = 7.1481  \n",
      "\n",
      "Fold: 10  Epoch: 398  Training loss = 3.9723  Validation loss = 7.1478  \n",
      "\n",
      "Fold: 10  Epoch: 399  Training loss = 3.9721  Validation loss = 7.1475  \n",
      "\n",
      "Fold: 10  Epoch: 400  Training loss = 3.9718  Validation loss = 7.1473  \n",
      "\n",
      "Fold: 10  Epoch: 401  Training loss = 3.9716  Validation loss = 7.1470  \n",
      "\n",
      "Fold: 10  Epoch: 402  Training loss = 3.9712  Validation loss = 7.1465  \n",
      "\n",
      "Fold: 10  Epoch: 403  Training loss = 3.9709  Validation loss = 7.1463  \n",
      "\n",
      "Fold: 10  Epoch: 404  Training loss = 3.9707  Validation loss = 7.1460  \n",
      "\n",
      "Fold: 10  Epoch: 405  Training loss = 3.9704  Validation loss = 7.1457  \n",
      "\n",
      "Fold: 10  Epoch: 406  Training loss = 3.9701  Validation loss = 7.1454  \n",
      "\n",
      "Fold: 10  Epoch: 407  Training loss = 3.9699  Validation loss = 7.1451  \n",
      "\n",
      "Fold: 10  Epoch: 408  Training loss = 3.9696  Validation loss = 7.1449  \n",
      "\n",
      "Fold: 10  Epoch: 409  Training loss = 3.9693  Validation loss = 7.1446  \n",
      "\n",
      "Fold: 10  Epoch: 410  Training loss = 3.9690  Validation loss = 7.1442  \n",
      "\n",
      "Fold: 10  Epoch: 411  Training loss = 3.9687  Validation loss = 7.1439  \n",
      "\n",
      "Fold: 10  Epoch: 412  Training loss = 3.9684  Validation loss = 7.1435  \n",
      "\n",
      "Fold: 10  Epoch: 413  Training loss = 3.9681  Validation loss = 7.1431  \n",
      "\n",
      "Fold: 10  Epoch: 414  Training loss = 3.9678  Validation loss = 7.1428  \n",
      "\n",
      "Fold: 10  Epoch: 415  Training loss = 3.9675  Validation loss = 7.1426  \n",
      "\n",
      "Fold: 10  Epoch: 416  Training loss = 3.9673  Validation loss = 7.1423  \n",
      "\n",
      "Fold: 10  Epoch: 417  Training loss = 3.9670  Validation loss = 7.1420  \n",
      "\n",
      "Fold: 10  Epoch: 418  Training loss = 3.9668  Validation loss = 7.1417  \n",
      "\n",
      "Fold: 10  Epoch: 419  Training loss = 3.9666  Validation loss = 7.1415  \n",
      "\n",
      "Fold: 10  Epoch: 420  Training loss = 3.9663  Validation loss = 7.1412  \n",
      "\n",
      "Fold: 10  Epoch: 421  Training loss = 3.9661  Validation loss = 7.1409  \n",
      "\n",
      "Fold: 10  Epoch: 422  Training loss = 3.9658  Validation loss = 7.1406  \n",
      "\n",
      "Fold: 10  Epoch: 423  Training loss = 3.9655  Validation loss = 7.1403  \n",
      "\n",
      "Fold: 10  Epoch: 424  Training loss = 3.9652  Validation loss = 7.1399  \n",
      "\n",
      "Fold: 10  Epoch: 425  Training loss = 3.9649  Validation loss = 7.1395  \n",
      "\n",
      "Fold: 10  Epoch: 426  Training loss = 3.9646  Validation loss = 7.1392  \n",
      "\n",
      "Fold: 10  Epoch: 427  Training loss = 3.9644  Validation loss = 7.1388  \n",
      "\n",
      "Fold: 10  Epoch: 428  Training loss = 3.9641  Validation loss = 7.1386  \n",
      "\n",
      "Fold: 10  Epoch: 429  Training loss = 3.9639  Validation loss = 7.1383  \n",
      "\n",
      "Fold: 10  Epoch: 430  Training loss = 3.9636  Validation loss = 7.1380  \n",
      "\n",
      "Fold: 10  Epoch: 431  Training loss = 3.9634  Validation loss = 7.1378  \n",
      "\n",
      "Fold: 10  Epoch: 432  Training loss = 3.9632  Validation loss = 7.1375  \n",
      "\n",
      "Fold: 10  Epoch: 433  Training loss = 3.9629  Validation loss = 7.1372  \n",
      "\n",
      "Fold: 10  Epoch: 434  Training loss = 3.9627  Validation loss = 7.1370  \n",
      "\n",
      "Fold: 10  Epoch: 435  Training loss = 3.9625  Validation loss = 7.1368  \n",
      "\n",
      "Fold: 10  Epoch: 436  Training loss = 3.9621  Validation loss = 7.1365  \n",
      "\n",
      "Fold: 10  Epoch: 437  Training loss = 3.9619  Validation loss = 7.1362  \n",
      "\n",
      "Fold: 10  Epoch: 438  Training loss = 3.9616  Validation loss = 7.1359  \n",
      "\n",
      "Fold: 10  Epoch: 439  Training loss = 3.9614  Validation loss = 7.1357  \n",
      "\n",
      "Fold: 10  Epoch: 440  Training loss = 3.9611  Validation loss = 7.1354  \n",
      "\n",
      "Fold: 10  Epoch: 441  Training loss = 3.9608  Validation loss = 7.1350  \n",
      "\n",
      "Fold: 10  Epoch: 442  Training loss = 3.9605  Validation loss = 7.1347  \n",
      "\n",
      "Fold: 10  Epoch: 443  Training loss = 3.9602  Validation loss = 7.1344  \n",
      "\n",
      "Fold: 10  Epoch: 444  Training loss = 3.9600  Validation loss = 7.1341  \n",
      "\n",
      "Fold: 10  Epoch: 445  Training loss = 3.9597  Validation loss = 7.1338  \n",
      "\n",
      "Fold: 10  Epoch: 446  Training loss = 3.9595  Validation loss = 7.1335  \n",
      "\n",
      "Fold: 10  Epoch: 447  Training loss = 3.9593  Validation loss = 7.1332  \n",
      "\n",
      "Fold: 10  Epoch: 448  Training loss = 3.9590  Validation loss = 7.1329  \n",
      "\n",
      "Fold: 10  Epoch: 449  Training loss = 3.9588  Validation loss = 7.1326  \n",
      "\n",
      "Fold: 10  Epoch: 450  Training loss = 3.9584  Validation loss = 7.1322  \n",
      "\n",
      "Fold: 10  Epoch: 451  Training loss = 3.9581  Validation loss = 7.1319  \n",
      "\n",
      "Fold: 10  Epoch: 452  Training loss = 3.9578  Validation loss = 7.1314  \n",
      "\n",
      "Fold: 10  Epoch: 453  Training loss = 3.9575  Validation loss = 7.1311  \n",
      "\n",
      "Fold: 10  Epoch: 454  Training loss = 3.9572  Validation loss = 7.1308  \n",
      "\n",
      "Fold: 10  Epoch: 455  Training loss = 3.9570  Validation loss = 7.1305  \n",
      "\n",
      "Fold: 10  Epoch: 456  Training loss = 3.9567  Validation loss = 7.1301  \n",
      "\n",
      "Fold: 10  Epoch: 457  Training loss = 3.9564  Validation loss = 7.1298  \n",
      "\n",
      "Fold: 10  Epoch: 458  Training loss = 3.9561  Validation loss = 7.1294  \n",
      "\n",
      "Fold: 10  Epoch: 459  Training loss = 3.9558  Validation loss = 7.1290  \n",
      "\n",
      "Fold: 10  Epoch: 460  Training loss = 3.9555  Validation loss = 7.1287  \n",
      "\n",
      "Fold: 10  Epoch: 461  Training loss = 3.9552  Validation loss = 7.1283  \n",
      "\n",
      "Fold: 10  Epoch: 462  Training loss = 3.9550  Validation loss = 7.1280  \n",
      "\n",
      "Fold: 10  Epoch: 463  Training loss = 3.9548  Validation loss = 7.1277  \n",
      "\n",
      "Fold: 10  Epoch: 464  Training loss = 3.9546  Validation loss = 7.1275  \n",
      "\n",
      "Fold: 10  Epoch: 465  Training loss = 3.9543  Validation loss = 7.1272  \n",
      "\n",
      "Fold: 10  Epoch: 466  Training loss = 3.9540  Validation loss = 7.1267  \n",
      "\n",
      "Fold: 10  Epoch: 467  Training loss = 3.9537  Validation loss = 7.1264  \n",
      "\n",
      "Fold: 10  Epoch: 468  Training loss = 3.9534  Validation loss = 7.1260  \n",
      "\n",
      "Fold: 10  Epoch: 469  Training loss = 3.9531  Validation loss = 7.1255  \n",
      "\n",
      "Fold: 10  Epoch: 470  Training loss = 3.9529  Validation loss = 7.1253  \n",
      "\n",
      "Fold: 10  Epoch: 471  Training loss = 3.9526  Validation loss = 7.1249  \n",
      "\n",
      "Fold: 10  Epoch: 472  Training loss = 3.9523  Validation loss = 7.1246  \n",
      "\n",
      "Fold: 10  Epoch: 473  Training loss = 3.9520  Validation loss = 7.1242  \n",
      "\n",
      "Fold: 10  Epoch: 474  Training loss = 3.9517  Validation loss = 7.1238  \n",
      "\n",
      "Fold: 10  Epoch: 475  Training loss = 3.9514  Validation loss = 7.1234  \n",
      "\n",
      "Fold: 10  Epoch: 476  Training loss = 3.9512  Validation loss = 7.1231  \n",
      "\n",
      "Fold: 10  Epoch: 477  Training loss = 3.9508  Validation loss = 7.1227  \n",
      "\n",
      "Fold: 10  Epoch: 478  Training loss = 3.9504  Validation loss = 7.1223  \n",
      "\n",
      "Fold: 10  Epoch: 479  Training loss = 3.9502  Validation loss = 7.1220  \n",
      "\n",
      "Fold: 10  Epoch: 480  Training loss = 3.9499  Validation loss = 7.1217  \n",
      "\n",
      "Fold: 10  Epoch: 481  Training loss = 3.9497  Validation loss = 7.1214  \n",
      "\n",
      "Fold: 10  Epoch: 482  Training loss = 3.9495  Validation loss = 7.1211  \n",
      "\n",
      "Fold: 10  Epoch: 483  Training loss = 3.9492  Validation loss = 7.1208  \n",
      "\n",
      "Fold: 10  Epoch: 484  Training loss = 3.9490  Validation loss = 7.1205  \n",
      "\n",
      "Fold: 10  Epoch: 485  Training loss = 3.9487  Validation loss = 7.1201  \n",
      "\n",
      "Fold: 10  Epoch: 486  Training loss = 3.9484  Validation loss = 7.1198  \n",
      "\n",
      "Fold: 10  Epoch: 487  Training loss = 3.9482  Validation loss = 7.1195  \n",
      "\n",
      "Fold: 10  Epoch: 488  Training loss = 3.9479  Validation loss = 7.1193  \n",
      "\n",
      "Fold: 10  Epoch: 489  Training loss = 3.9477  Validation loss = 7.1189  \n",
      "\n",
      "Fold: 10  Epoch: 490  Training loss = 3.9473  Validation loss = 7.1184  \n",
      "\n",
      "Fold: 10  Epoch: 491  Training loss = 3.9470  Validation loss = 7.1180  \n",
      "\n",
      "Fold: 10  Epoch: 492  Training loss = 3.9467  Validation loss = 7.1176  \n",
      "\n",
      "Fold: 10  Epoch: 493  Training loss = 3.9464  Validation loss = 7.1173  \n",
      "\n",
      "Fold: 10  Epoch: 494  Training loss = 3.9462  Validation loss = 7.1169  \n",
      "\n",
      "Fold: 10  Epoch: 495  Training loss = 3.9459  Validation loss = 7.1165  \n",
      "\n",
      "Fold: 10  Epoch: 496  Training loss = 3.9456  Validation loss = 7.1161  \n",
      "\n",
      "Fold: 10  Epoch: 497  Training loss = 3.9454  Validation loss = 7.1159  \n",
      "\n",
      "Fold: 10  Epoch: 498  Training loss = 3.9451  Validation loss = 7.1155  \n",
      "\n",
      "Fold: 10  Epoch: 499  Training loss = 3.9448  Validation loss = 7.1150  \n",
      "\n",
      "Fold: 10  Epoch: 500  Training loss = 3.9445  Validation loss = 7.1147  \n",
      "\n",
      "Check model:  Fold: 10  Optimal epoch: 500  \n",
      "\n",
      "Fold: 11  Epoch: 1  Training loss = 4.3154  Validation loss = 4.1412  \n",
      "\n",
      "Fold: 11  Epoch: 2  Training loss = 4.3148  Validation loss = 4.1405  \n",
      "\n",
      "Fold: 11  Epoch: 3  Training loss = 4.3144  Validation loss = 4.1400  \n",
      "\n",
      "Fold: 11  Epoch: 4  Training loss = 4.3140  Validation loss = 4.1394  \n",
      "\n",
      "Fold: 11  Epoch: 5  Training loss = 4.3136  Validation loss = 4.1388  \n",
      "\n",
      "Fold: 11  Epoch: 6  Training loss = 4.3133  Validation loss = 4.1383  \n",
      "\n",
      "Fold: 11  Epoch: 7  Training loss = 4.3130  Validation loss = 4.1377  \n",
      "\n",
      "Fold: 11  Epoch: 8  Training loss = 4.3126  Validation loss = 4.1372  \n",
      "\n",
      "Fold: 11  Epoch: 9  Training loss = 4.3122  Validation loss = 4.1367  \n",
      "\n",
      "Fold: 11  Epoch: 10  Training loss = 4.3120  Validation loss = 4.1362  \n",
      "\n",
      "Fold: 11  Epoch: 11  Training loss = 4.3117  Validation loss = 4.1357  \n",
      "\n",
      "Fold: 11  Epoch: 12  Training loss = 4.3111  Validation loss = 4.1349  \n",
      "\n",
      "Fold: 11  Epoch: 13  Training loss = 4.3108  Validation loss = 4.1344  \n",
      "\n",
      "Fold: 11  Epoch: 14  Training loss = 4.3103  Validation loss = 4.1337  \n",
      "\n",
      "Fold: 11  Epoch: 15  Training loss = 4.3097  Validation loss = 4.1330  \n",
      "\n",
      "Fold: 11  Epoch: 16  Training loss = 4.3091  Validation loss = 4.1323  \n",
      "\n",
      "Fold: 11  Epoch: 17  Training loss = 4.3088  Validation loss = 4.1318  \n",
      "\n",
      "Fold: 11  Epoch: 18  Training loss = 4.3079  Validation loss = 4.1308  \n",
      "\n",
      "Fold: 11  Epoch: 19  Training loss = 4.3073  Validation loss = 4.1301  \n",
      "\n",
      "Fold: 11  Epoch: 20  Training loss = 4.3070  Validation loss = 4.1295  \n",
      "\n",
      "Fold: 11  Epoch: 21  Training loss = 4.3065  Validation loss = 4.1289  \n",
      "\n",
      "Fold: 11  Epoch: 22  Training loss = 4.3058  Validation loss = 4.1281  \n",
      "\n",
      "Fold: 11  Epoch: 23  Training loss = 4.3051  Validation loss = 4.1274  \n",
      "\n",
      "Fold: 11  Epoch: 24  Training loss = 4.3040  Validation loss = 4.1266  \n",
      "\n",
      "Fold: 11  Epoch: 25  Training loss = 4.3026  Validation loss = 4.1258  \n",
      "\n",
      "Fold: 11  Epoch: 26  Training loss = 4.3013  Validation loss = 4.1248  \n",
      "\n",
      "Fold: 11  Epoch: 27  Training loss = 4.3007  Validation loss = 4.1240  \n",
      "\n",
      "Fold: 11  Epoch: 28  Training loss = 4.3003  Validation loss = 4.1234  \n",
      "\n",
      "Fold: 11  Epoch: 29  Training loss = 4.2999  Validation loss = 4.1227  \n",
      "\n",
      "Fold: 11  Epoch: 30  Training loss = 4.2995  Validation loss = 4.1220  \n",
      "\n",
      "Fold: 11  Epoch: 31  Training loss = 4.2991  Validation loss = 4.1212  \n",
      "\n",
      "Fold: 11  Epoch: 32  Training loss = 4.2988  Validation loss = 4.1206  \n",
      "\n",
      "Fold: 11  Epoch: 33  Training loss = 4.2984  Validation loss = 4.1199  \n",
      "\n",
      "Fold: 11  Epoch: 34  Training loss = 4.2981  Validation loss = 4.1193  \n",
      "\n",
      "Fold: 11  Epoch: 35  Training loss = 4.2978  Validation loss = 4.1188  \n",
      "\n",
      "Fold: 11  Epoch: 36  Training loss = 4.2974  Validation loss = 4.1181  \n",
      "\n",
      "Fold: 11  Epoch: 37  Training loss = 4.2971  Validation loss = 4.1174  \n",
      "\n",
      "Fold: 11  Epoch: 38  Training loss = 4.2967  Validation loss = 4.1166  \n",
      "\n",
      "Fold: 11  Epoch: 39  Training loss = 4.2964  Validation loss = 4.1161  \n",
      "\n",
      "Fold: 11  Epoch: 40  Training loss = 4.2961  Validation loss = 4.1155  \n",
      "\n",
      "Fold: 11  Epoch: 41  Training loss = 4.2957  Validation loss = 4.1149  \n",
      "\n",
      "Fold: 11  Epoch: 42  Training loss = 4.2954  Validation loss = 4.1142  \n",
      "\n",
      "Fold: 11  Epoch: 43  Training loss = 4.2950  Validation loss = 4.1136  \n",
      "\n",
      "Fold: 11  Epoch: 44  Training loss = 4.2947  Validation loss = 4.1130  \n",
      "\n",
      "Fold: 11  Epoch: 45  Training loss = 4.2943  Validation loss = 4.1123  \n",
      "\n",
      "Fold: 11  Epoch: 46  Training loss = 4.2940  Validation loss = 4.1117  \n",
      "\n",
      "Fold: 11  Epoch: 47  Training loss = 4.2937  Validation loss = 4.1111  \n",
      "\n",
      "Fold: 11  Epoch: 48  Training loss = 4.2934  Validation loss = 4.1105  \n",
      "\n",
      "Fold: 11  Epoch: 49  Training loss = 4.2930  Validation loss = 4.1098  \n",
      "\n",
      "Fold: 11  Epoch: 50  Training loss = 4.2927  Validation loss = 4.1092  \n",
      "\n",
      "Fold: 11  Epoch: 51  Training loss = 4.2924  Validation loss = 4.1087  \n",
      "\n",
      "Fold: 11  Epoch: 52  Training loss = 4.2921  Validation loss = 4.1082  \n",
      "\n",
      "Fold: 11  Epoch: 53  Training loss = 4.2919  Validation loss = 4.1078  \n",
      "\n",
      "Fold: 11  Epoch: 54  Training loss = 4.2915  Validation loss = 4.1072  \n",
      "\n",
      "Fold: 11  Epoch: 55  Training loss = 4.2912  Validation loss = 4.1065  \n",
      "\n",
      "Fold: 11  Epoch: 56  Training loss = 4.2908  Validation loss = 4.1058  \n",
      "\n",
      "Fold: 11  Epoch: 57  Training loss = 4.2905  Validation loss = 4.1053  \n",
      "\n",
      "Fold: 11  Epoch: 58  Training loss = 4.2903  Validation loss = 4.1048  \n",
      "\n",
      "Fold: 11  Epoch: 59  Training loss = 4.2900  Validation loss = 4.1043  \n",
      "\n",
      "Fold: 11  Epoch: 60  Training loss = 4.2897  Validation loss = 4.1036  \n",
      "\n",
      "Fold: 11  Epoch: 61  Training loss = 4.2893  Validation loss = 4.1030  \n",
      "\n",
      "Fold: 11  Epoch: 62  Training loss = 4.2889  Validation loss = 4.1021  \n",
      "\n",
      "Fold: 11  Epoch: 63  Training loss = 4.2885  Validation loss = 4.1014  \n",
      "\n",
      "Fold: 11  Epoch: 64  Training loss = 4.2881  Validation loss = 4.1006  \n",
      "\n",
      "Fold: 11  Epoch: 65  Training loss = 4.2878  Validation loss = 4.1000  \n",
      "\n",
      "Fold: 11  Epoch: 66  Training loss = 4.2874  Validation loss = 4.0992  \n",
      "\n",
      "Fold: 11  Epoch: 67  Training loss = 4.2871  Validation loss = 4.0987  \n",
      "\n",
      "Fold: 11  Epoch: 68  Training loss = 4.2867  Validation loss = 4.0981  \n",
      "\n",
      "Fold: 11  Epoch: 69  Training loss = 4.2864  Validation loss = 4.0974  \n",
      "\n",
      "Fold: 11  Epoch: 70  Training loss = 4.2860  Validation loss = 4.0967  \n",
      "\n",
      "Fold: 11  Epoch: 71  Training loss = 4.2856  Validation loss = 4.0959  \n",
      "\n",
      "Fold: 11  Epoch: 72  Training loss = 4.2853  Validation loss = 4.0954  \n",
      "\n",
      "Fold: 11  Epoch: 73  Training loss = 4.2850  Validation loss = 4.0948  \n",
      "\n",
      "Fold: 11  Epoch: 74  Training loss = 4.2846  Validation loss = 4.0941  \n",
      "\n",
      "Fold: 11  Epoch: 75  Training loss = 4.2843  Validation loss = 4.0936  \n",
      "\n",
      "Fold: 11  Epoch: 76  Training loss = 4.2840  Validation loss = 4.0931  \n",
      "\n",
      "Fold: 11  Epoch: 77  Training loss = 4.2836  Validation loss = 4.0923  \n",
      "\n",
      "Fold: 11  Epoch: 78  Training loss = 4.2834  Validation loss = 4.0918  \n",
      "\n",
      "Fold: 11  Epoch: 79  Training loss = 4.2832  Validation loss = 4.0914  \n",
      "\n",
      "Fold: 11  Epoch: 80  Training loss = 4.2829  Validation loss = 4.0908  \n",
      "\n",
      "Fold: 11  Epoch: 81  Training loss = 4.2825  Validation loss = 4.0901  \n",
      "\n",
      "Fold: 11  Epoch: 82  Training loss = 4.2821  Validation loss = 4.0893  \n",
      "\n",
      "Fold: 11  Epoch: 83  Training loss = 4.2817  Validation loss = 4.0887  \n",
      "\n",
      "Fold: 11  Epoch: 84  Training loss = 4.2814  Validation loss = 4.0881  \n",
      "\n",
      "Fold: 11  Epoch: 85  Training loss = 4.2811  Validation loss = 4.0876  \n",
      "\n",
      "Fold: 11  Epoch: 86  Training loss = 4.2808  Validation loss = 4.0870  \n",
      "\n",
      "Fold: 11  Epoch: 87  Training loss = 4.2805  Validation loss = 4.0864  \n",
      "\n",
      "Fold: 11  Epoch: 88  Training loss = 4.2801  Validation loss = 4.0858  \n",
      "\n",
      "Fold: 11  Epoch: 89  Training loss = 4.2798  Validation loss = 4.0851  \n",
      "\n",
      "Fold: 11  Epoch: 90  Training loss = 4.2794  Validation loss = 4.0845  \n",
      "\n",
      "Fold: 11  Epoch: 91  Training loss = 4.2791  Validation loss = 4.0838  \n",
      "\n",
      "Fold: 11  Epoch: 92  Training loss = 4.2789  Validation loss = 4.0833  \n",
      "\n",
      "Fold: 11  Epoch: 93  Training loss = 4.2785  Validation loss = 4.0826  \n",
      "\n",
      "Fold: 11  Epoch: 94  Training loss = 4.2781  Validation loss = 4.0820  \n",
      "\n",
      "Fold: 11  Epoch: 95  Training loss = 4.2778  Validation loss = 4.0813  \n",
      "\n",
      "Fold: 11  Epoch: 96  Training loss = 4.2774  Validation loss = 4.0806  \n",
      "\n",
      "Fold: 11  Epoch: 97  Training loss = 4.2770  Validation loss = 4.0798  \n",
      "\n",
      "Fold: 11  Epoch: 98  Training loss = 4.2765  Validation loss = 4.0789  \n",
      "\n",
      "Fold: 11  Epoch: 99  Training loss = 4.2763  Validation loss = 4.0784  \n",
      "\n",
      "Fold: 11  Epoch: 100  Training loss = 4.2760  Validation loss = 4.0778  \n",
      "\n",
      "Fold: 11  Epoch: 101  Training loss = 4.2756  Validation loss = 4.0771  \n",
      "\n",
      "Fold: 11  Epoch: 102  Training loss = 4.2753  Validation loss = 4.0764  \n",
      "\n",
      "Fold: 11  Epoch: 103  Training loss = 4.2749  Validation loss = 4.0757  \n",
      "\n",
      "Fold: 11  Epoch: 104  Training loss = 4.2746  Validation loss = 4.0750  \n",
      "\n",
      "Fold: 11  Epoch: 105  Training loss = 4.2743  Validation loss = 4.0745  \n",
      "\n",
      "Fold: 11  Epoch: 106  Training loss = 4.2740  Validation loss = 4.0739  \n",
      "\n",
      "Fold: 11  Epoch: 107  Training loss = 4.2736  Validation loss = 4.0733  \n",
      "\n",
      "Fold: 11  Epoch: 108  Training loss = 4.2733  Validation loss = 4.0727  \n",
      "\n",
      "Fold: 11  Epoch: 109  Training loss = 4.2730  Validation loss = 4.0720  \n",
      "\n",
      "Fold: 11  Epoch: 110  Training loss = 4.2727  Validation loss = 4.0715  \n",
      "\n",
      "Fold: 11  Epoch: 111  Training loss = 4.2723  Validation loss = 4.0707  \n",
      "\n",
      "Fold: 11  Epoch: 112  Training loss = 4.2719  Validation loss = 4.0700  \n",
      "\n",
      "Fold: 11  Epoch: 113  Training loss = 4.2715  Validation loss = 4.0693  \n",
      "\n",
      "Fold: 11  Epoch: 114  Training loss = 4.2712  Validation loss = 4.0686  \n",
      "\n",
      "Fold: 11  Epoch: 115  Training loss = 4.2708  Validation loss = 4.0680  \n",
      "\n",
      "Fold: 11  Epoch: 116  Training loss = 4.2705  Validation loss = 4.0674  \n",
      "\n",
      "Fold: 11  Epoch: 117  Training loss = 4.2702  Validation loss = 4.0668  \n",
      "\n",
      "Fold: 11  Epoch: 118  Training loss = 4.2699  Validation loss = 4.0663  \n",
      "\n",
      "Fold: 11  Epoch: 119  Training loss = 4.2695  Validation loss = 4.0655  \n",
      "\n",
      "Fold: 11  Epoch: 120  Training loss = 4.2692  Validation loss = 4.0650  \n",
      "\n",
      "Fold: 11  Epoch: 121  Training loss = 4.2689  Validation loss = 4.0644  \n",
      "\n",
      "Fold: 11  Epoch: 122  Training loss = 4.2685  Validation loss = 4.0637  \n",
      "\n",
      "Fold: 11  Epoch: 123  Training loss = 4.2682  Validation loss = 4.0631  \n",
      "\n",
      "Fold: 11  Epoch: 124  Training loss = 4.2679  Validation loss = 4.0626  \n",
      "\n",
      "Fold: 11  Epoch: 125  Training loss = 4.2676  Validation loss = 4.0620  \n",
      "\n",
      "Fold: 11  Epoch: 126  Training loss = 4.2673  Validation loss = 4.0614  \n",
      "\n",
      "Fold: 11  Epoch: 127  Training loss = 4.2670  Validation loss = 4.0608  \n",
      "\n",
      "Fold: 11  Epoch: 128  Training loss = 4.2667  Validation loss = 4.0602  \n",
      "\n",
      "Fold: 11  Epoch: 129  Training loss = 4.2664  Validation loss = 4.0597  \n",
      "\n",
      "Fold: 11  Epoch: 130  Training loss = 4.2660  Validation loss = 4.0590  \n",
      "\n",
      "Fold: 11  Epoch: 131  Training loss = 4.2656  Validation loss = 4.0583  \n",
      "\n",
      "Fold: 11  Epoch: 132  Training loss = 4.2652  Validation loss = 4.0576  \n",
      "\n",
      "Fold: 11  Epoch: 133  Training loss = 4.2649  Validation loss = 4.0569  \n",
      "\n",
      "Fold: 11  Epoch: 134  Training loss = 4.2645  Validation loss = 4.0563  \n",
      "\n",
      "Fold: 11  Epoch: 135  Training loss = 4.2642  Validation loss = 4.0557  \n",
      "\n",
      "Fold: 11  Epoch: 136  Training loss = 4.2639  Validation loss = 4.0551  \n",
      "\n",
      "Fold: 11  Epoch: 137  Training loss = 4.2635  Validation loss = 4.0544  \n",
      "\n",
      "Fold: 11  Epoch: 138  Training loss = 4.2632  Validation loss = 4.0538  \n",
      "\n",
      "Fold: 11  Epoch: 139  Training loss = 4.2628  Validation loss = 4.0529  \n",
      "\n",
      "Fold: 11  Epoch: 140  Training loss = 4.2624  Validation loss = 4.0521  \n",
      "\n",
      "Fold: 11  Epoch: 141  Training loss = 4.2620  Validation loss = 4.0515  \n",
      "\n",
      "Fold: 11  Epoch: 142  Training loss = 4.2617  Validation loss = 4.0509  \n",
      "\n",
      "Fold: 11  Epoch: 143  Training loss = 4.2613  Validation loss = 4.0503  \n",
      "\n",
      "Fold: 11  Epoch: 144  Training loss = 4.2610  Validation loss = 4.0497  \n",
      "\n",
      "Fold: 11  Epoch: 145  Training loss = 4.2606  Validation loss = 4.0489  \n",
      "\n",
      "Fold: 11  Epoch: 146  Training loss = 4.2602  Validation loss = 4.0481  \n",
      "\n",
      "Fold: 11  Epoch: 147  Training loss = 4.2598  Validation loss = 4.0474  \n",
      "\n",
      "Fold: 11  Epoch: 148  Training loss = 4.2594  Validation loss = 4.0466  \n",
      "\n",
      "Fold: 11  Epoch: 149  Training loss = 4.2590  Validation loss = 4.0460  \n",
      "\n",
      "Fold: 11  Epoch: 150  Training loss = 4.2587  Validation loss = 4.0453  \n",
      "\n",
      "Fold: 11  Epoch: 151  Training loss = 4.2583  Validation loss = 4.0445  \n",
      "\n",
      "Fold: 11  Epoch: 152  Training loss = 4.2578  Validation loss = 4.0437  \n",
      "\n",
      "Fold: 11  Epoch: 153  Training loss = 4.2574  Validation loss = 4.0429  \n",
      "\n",
      "Fold: 11  Epoch: 154  Training loss = 4.2571  Validation loss = 4.0423  \n",
      "\n",
      "Fold: 11  Epoch: 155  Training loss = 4.2567  Validation loss = 4.0417  \n",
      "\n",
      "Fold: 11  Epoch: 156  Training loss = 4.2563  Validation loss = 4.0410  \n",
      "\n",
      "Fold: 11  Epoch: 157  Training loss = 4.2559  Validation loss = 4.0403  \n",
      "\n",
      "Fold: 11  Epoch: 158  Training loss = 4.2555  Validation loss = 4.0395  \n",
      "\n",
      "Fold: 11  Epoch: 159  Training loss = 4.2552  Validation loss = 4.0389  \n",
      "\n",
      "Fold: 11  Epoch: 160  Training loss = 4.2547  Validation loss = 4.0380  \n",
      "\n",
      "Fold: 11  Epoch: 161  Training loss = 4.2544  Validation loss = 4.0374  \n",
      "\n",
      "Fold: 11  Epoch: 162  Training loss = 4.2541  Validation loss = 4.0369  \n",
      "\n",
      "Fold: 11  Epoch: 163  Training loss = 4.2538  Validation loss = 4.0363  \n",
      "\n",
      "Fold: 11  Epoch: 164  Training loss = 4.2534  Validation loss = 4.0356  \n",
      "\n",
      "Fold: 11  Epoch: 165  Training loss = 4.2530  Validation loss = 4.0349  \n",
      "\n",
      "Fold: 11  Epoch: 166  Training loss = 4.2527  Validation loss = 4.0343  \n",
      "\n",
      "Fold: 11  Epoch: 167  Training loss = 4.2524  Validation loss = 4.0337  \n",
      "\n",
      "Fold: 11  Epoch: 168  Training loss = 4.2519  Validation loss = 4.0329  \n",
      "\n",
      "Fold: 11  Epoch: 169  Training loss = 4.2516  Validation loss = 4.0322  \n",
      "\n",
      "Fold: 11  Epoch: 170  Training loss = 4.2512  Validation loss = 4.0316  \n",
      "\n",
      "Fold: 11  Epoch: 171  Training loss = 4.2508  Validation loss = 4.0309  \n",
      "\n",
      "Fold: 11  Epoch: 172  Training loss = 4.2505  Validation loss = 4.0303  \n",
      "\n",
      "Fold: 11  Epoch: 173  Training loss = 4.2502  Validation loss = 4.0297  \n",
      "\n",
      "Fold: 11  Epoch: 174  Training loss = 4.2497  Validation loss = 4.0290  \n",
      "\n",
      "Fold: 11  Epoch: 175  Training loss = 4.2494  Validation loss = 4.0284  \n",
      "\n",
      "Fold: 11  Epoch: 176  Training loss = 4.2490  Validation loss = 4.0278  \n",
      "\n",
      "Fold: 11  Epoch: 177  Training loss = 4.2488  Validation loss = 4.0273  \n",
      "\n",
      "Fold: 11  Epoch: 178  Training loss = 4.2485  Validation loss = 4.0268  \n",
      "\n",
      "Fold: 11  Epoch: 179  Training loss = 4.2481  Validation loss = 4.0261  \n",
      "\n",
      "Fold: 11  Epoch: 180  Training loss = 4.2477  Validation loss = 4.0255  \n",
      "\n",
      "Fold: 11  Epoch: 181  Training loss = 4.2474  Validation loss = 4.0248  \n",
      "\n",
      "Fold: 11  Epoch: 182  Training loss = 4.2471  Validation loss = 4.0243  \n",
      "\n",
      "Fold: 11  Epoch: 183  Training loss = 4.2467  Validation loss = 4.0237  \n",
      "\n",
      "Fold: 11  Epoch: 184  Training loss = 4.2463  Validation loss = 4.0229  \n",
      "\n",
      "Fold: 11  Epoch: 185  Training loss = 4.2459  Validation loss = 4.0223  \n",
      "\n",
      "Fold: 11  Epoch: 186  Training loss = 4.2455  Validation loss = 4.0216  \n",
      "\n",
      "Fold: 11  Epoch: 187  Training loss = 4.2450  Validation loss = 4.0206  \n",
      "\n",
      "Fold: 11  Epoch: 188  Training loss = 4.2446  Validation loss = 4.0200  \n",
      "\n",
      "Fold: 11  Epoch: 189  Training loss = 4.2442  Validation loss = 4.0193  \n",
      "\n",
      "Fold: 11  Epoch: 190  Training loss = 4.2439  Validation loss = 4.0188  \n",
      "\n",
      "Fold: 11  Epoch: 191  Training loss = 4.2434  Validation loss = 4.0180  \n",
      "\n",
      "Fold: 11  Epoch: 192  Training loss = 4.2430  Validation loss = 4.0173  \n",
      "\n",
      "Fold: 11  Epoch: 193  Training loss = 4.2427  Validation loss = 4.0167  \n",
      "\n",
      "Fold: 11  Epoch: 194  Training loss = 4.2424  Validation loss = 4.0163  \n",
      "\n",
      "Fold: 11  Epoch: 195  Training loss = 4.2420  Validation loss = 4.0155  \n",
      "\n",
      "Fold: 11  Epoch: 196  Training loss = 4.2415  Validation loss = 4.0147  \n",
      "\n",
      "Fold: 11  Epoch: 197  Training loss = 4.2411  Validation loss = 4.0140  \n",
      "\n",
      "Fold: 11  Epoch: 198  Training loss = 4.2406  Validation loss = 4.0132  \n",
      "\n",
      "Fold: 11  Epoch: 199  Training loss = 4.2402  Validation loss = 4.0125  \n",
      "\n",
      "Fold: 11  Epoch: 200  Training loss = 4.2398  Validation loss = 4.0119  \n",
      "\n",
      "Fold: 11  Epoch: 201  Training loss = 4.2394  Validation loss = 4.0113  \n",
      "\n",
      "Fold: 11  Epoch: 202  Training loss = 4.2390  Validation loss = 4.0106  \n",
      "\n",
      "Fold: 11  Epoch: 203  Training loss = 4.2387  Validation loss = 4.0101  \n",
      "\n",
      "Fold: 11  Epoch: 204  Training loss = 4.2384  Validation loss = 4.0096  \n",
      "\n",
      "Fold: 11  Epoch: 205  Training loss = 4.2381  Validation loss = 4.0090  \n",
      "\n",
      "Fold: 11  Epoch: 206  Training loss = 4.2376  Validation loss = 4.0083  \n",
      "\n",
      "Fold: 11  Epoch: 207  Training loss = 4.2373  Validation loss = 4.0077  \n",
      "\n",
      "Fold: 11  Epoch: 208  Training loss = 4.2369  Validation loss = 4.0071  \n",
      "\n",
      "Fold: 11  Epoch: 209  Training loss = 4.2365  Validation loss = 4.0065  \n",
      "\n",
      "Fold: 11  Epoch: 210  Training loss = 4.2362  Validation loss = 4.0059  \n",
      "\n",
      "Fold: 11  Epoch: 211  Training loss = 4.2358  Validation loss = 4.0053  \n",
      "\n",
      "Fold: 11  Epoch: 212  Training loss = 4.2354  Validation loss = 4.0047  \n",
      "\n",
      "Fold: 11  Epoch: 213  Training loss = 4.2351  Validation loss = 4.0042  \n",
      "\n",
      "Fold: 11  Epoch: 214  Training loss = 4.2346  Validation loss = 4.0034  \n",
      "\n",
      "Fold: 11  Epoch: 215  Training loss = 4.2343  Validation loss = 4.0029  \n",
      "\n",
      "Fold: 11  Epoch: 216  Training loss = 4.2340  Validation loss = 4.0023  \n",
      "\n",
      "Fold: 11  Epoch: 217  Training loss = 4.2336  Validation loss = 4.0017  \n",
      "\n",
      "Fold: 11  Epoch: 218  Training loss = 4.2332  Validation loss = 4.0011  \n",
      "\n",
      "Fold: 11  Epoch: 219  Training loss = 4.2329  Validation loss = 4.0006  \n",
      "\n",
      "Fold: 11  Epoch: 220  Training loss = 4.2325  Validation loss = 3.9999  \n",
      "\n",
      "Fold: 11  Epoch: 221  Training loss = 4.2322  Validation loss = 3.9994  \n",
      "\n",
      "Fold: 11  Epoch: 222  Training loss = 4.2318  Validation loss = 3.9988  \n",
      "\n",
      "Fold: 11  Epoch: 223  Training loss = 4.2316  Validation loss = 3.9984  \n",
      "\n",
      "Fold: 11  Epoch: 224  Training loss = 4.2312  Validation loss = 3.9979  \n",
      "\n",
      "Fold: 11  Epoch: 225  Training loss = 4.2308  Validation loss = 3.9973  \n",
      "\n",
      "Fold: 11  Epoch: 226  Training loss = 4.2304  Validation loss = 3.9966  \n",
      "\n",
      "Fold: 11  Epoch: 227  Training loss = 4.2300  Validation loss = 3.9960  \n",
      "\n",
      "Fold: 11  Epoch: 228  Training loss = 4.2296  Validation loss = 3.9954  \n",
      "\n",
      "Fold: 11  Epoch: 229  Training loss = 4.2292  Validation loss = 3.9948  \n",
      "\n",
      "Fold: 11  Epoch: 230  Training loss = 4.2289  Validation loss = 3.9942  \n",
      "\n",
      "Fold: 11  Epoch: 231  Training loss = 4.2284  Validation loss = 3.9935  \n",
      "\n",
      "Fold: 11  Epoch: 232  Training loss = 4.2280  Validation loss = 3.9929  \n",
      "\n",
      "Fold: 11  Epoch: 233  Training loss = 4.2276  Validation loss = 3.9923  \n",
      "\n",
      "Fold: 11  Epoch: 234  Training loss = 4.2273  Validation loss = 3.9918  \n",
      "\n",
      "Fold: 11  Epoch: 235  Training loss = 4.2269  Validation loss = 3.9913  \n",
      "\n",
      "Fold: 11  Epoch: 236  Training loss = 4.2265  Validation loss = 3.9906  \n",
      "\n",
      "Fold: 11  Epoch: 237  Training loss = 4.2261  Validation loss = 3.9899  \n",
      "\n",
      "Fold: 11  Epoch: 238  Training loss = 4.2255  Validation loss = 3.9891  \n",
      "\n",
      "Fold: 11  Epoch: 239  Training loss = 4.2251  Validation loss = 3.9885  \n",
      "\n",
      "Fold: 11  Epoch: 240  Training loss = 4.2247  Validation loss = 3.9879  \n",
      "\n",
      "Fold: 11  Epoch: 241  Training loss = 4.2243  Validation loss = 3.9874  \n",
      "\n",
      "Fold: 11  Epoch: 242  Training loss = 4.2239  Validation loss = 3.9868  \n",
      "\n",
      "Fold: 11  Epoch: 243  Training loss = 4.2236  Validation loss = 3.9862  \n",
      "\n",
      "Fold: 11  Epoch: 244  Training loss = 4.2232  Validation loss = 3.9856  \n",
      "\n",
      "Fold: 11  Epoch: 245  Training loss = 4.2227  Validation loss = 3.9850  \n",
      "\n",
      "Fold: 11  Epoch: 246  Training loss = 4.2223  Validation loss = 3.9844  \n",
      "\n",
      "Fold: 11  Epoch: 247  Training loss = 4.2220  Validation loss = 3.9840  \n",
      "\n",
      "Fold: 11  Epoch: 248  Training loss = 4.2216  Validation loss = 3.9834  \n",
      "\n",
      "Fold: 11  Epoch: 249  Training loss = 4.2212  Validation loss = 3.9827  \n",
      "\n",
      "Fold: 11  Epoch: 250  Training loss = 4.2207  Validation loss = 3.9820  \n",
      "\n",
      "Fold: 11  Epoch: 251  Training loss = 4.2203  Validation loss = 3.9814  \n",
      "\n",
      "Fold: 11  Epoch: 252  Training loss = 4.2199  Validation loss = 3.9809  \n",
      "\n",
      "Fold: 11  Epoch: 253  Training loss = 4.2196  Validation loss = 3.9804  \n",
      "\n",
      "Fold: 11  Epoch: 254  Training loss = 4.2190  Validation loss = 3.9796  \n",
      "\n",
      "Fold: 11  Epoch: 255  Training loss = 4.2186  Validation loss = 3.9790  \n",
      "\n",
      "Fold: 11  Epoch: 256  Training loss = 4.2182  Validation loss = 3.9785  \n",
      "\n",
      "Fold: 11  Epoch: 257  Training loss = 4.2177  Validation loss = 3.9779  \n",
      "\n",
      "Fold: 11  Epoch: 258  Training loss = 4.2168  Validation loss = 3.9774  \n",
      "\n",
      "Fold: 11  Epoch: 259  Training loss = 4.2142  Validation loss = 3.9769  \n",
      "\n",
      "Fold: 11  Epoch: 260  Training loss = 4.2131  Validation loss = 3.9764  \n",
      "\n",
      "Fold: 11  Epoch: 261  Training loss = 4.2126  Validation loss = 3.9758  \n",
      "\n",
      "Fold: 11  Epoch: 262  Training loss = 4.2123  Validation loss = 3.9753  \n",
      "\n",
      "Fold: 11  Epoch: 263  Training loss = 4.2119  Validation loss = 3.9748  \n",
      "\n",
      "Fold: 11  Epoch: 264  Training loss = 4.2115  Validation loss = 3.9742  \n",
      "\n",
      "Fold: 11  Epoch: 265  Training loss = 4.2113  Validation loss = 3.9739  \n",
      "\n",
      "Fold: 11  Epoch: 266  Training loss = 4.2108  Validation loss = 3.9732  \n",
      "\n",
      "Fold: 11  Epoch: 267  Training loss = 4.2104  Validation loss = 3.9727  \n",
      "\n",
      "Fold: 11  Epoch: 268  Training loss = 4.2100  Validation loss = 3.9722  \n",
      "\n",
      "Fold: 11  Epoch: 269  Training loss = 4.2096  Validation loss = 3.9717  \n",
      "\n",
      "Fold: 11  Epoch: 270  Training loss = 4.2092  Validation loss = 3.9712  \n",
      "\n",
      "Fold: 11  Epoch: 271  Training loss = 4.2088  Validation loss = 3.9706  \n",
      "\n",
      "Fold: 11  Epoch: 272  Training loss = 4.2084  Validation loss = 3.9700  \n",
      "\n",
      "Fold: 11  Epoch: 273  Training loss = 4.2077  Validation loss = 3.9691  \n",
      "\n",
      "Fold: 11  Epoch: 274  Training loss = 4.2072  Validation loss = 3.9685  \n",
      "\n",
      "Fold: 11  Epoch: 275  Training loss = 4.2069  Validation loss = 3.9681  \n",
      "\n",
      "Fold: 11  Epoch: 276  Training loss = 4.2065  Validation loss = 3.9675  \n",
      "\n",
      "Fold: 11  Epoch: 277  Training loss = 4.2059  Validation loss = 3.9668  \n",
      "\n",
      "Fold: 11  Epoch: 278  Training loss = 4.2055  Validation loss = 3.9663  \n",
      "\n",
      "Fold: 11  Epoch: 279  Training loss = 4.2051  Validation loss = 3.9657  \n",
      "\n",
      "Fold: 11  Epoch: 280  Training loss = 4.2046  Validation loss = 3.9652  \n",
      "\n",
      "Fold: 11  Epoch: 281  Training loss = 4.2040  Validation loss = 3.9644  \n",
      "\n",
      "Fold: 11  Epoch: 282  Training loss = 4.2033  Validation loss = 3.9637  \n",
      "\n",
      "Fold: 11  Epoch: 283  Training loss = 4.2030  Validation loss = 3.9632  \n",
      "\n",
      "Fold: 11  Epoch: 284  Training loss = 4.2024  Validation loss = 3.9625  \n",
      "\n",
      "Fold: 11  Epoch: 285  Training loss = 4.2020  Validation loss = 3.9620  \n",
      "\n",
      "Fold: 11  Epoch: 286  Training loss = 4.2016  Validation loss = 3.9615  \n",
      "\n",
      "Fold: 11  Epoch: 287  Training loss = 4.2012  Validation loss = 3.9610  \n",
      "\n",
      "Fold: 11  Epoch: 288  Training loss = 4.2008  Validation loss = 3.9605  \n",
      "\n",
      "Fold: 11  Epoch: 289  Training loss = 4.2004  Validation loss = 3.9600  \n",
      "\n",
      "Fold: 11  Epoch: 290  Training loss = 4.2000  Validation loss = 3.9594  \n",
      "\n",
      "Fold: 11  Epoch: 291  Training loss = 4.1995  Validation loss = 3.9588  \n",
      "\n",
      "Fold: 11  Epoch: 292  Training loss = 4.1990  Validation loss = 3.9582  \n",
      "\n",
      "Fold: 11  Epoch: 293  Training loss = 4.1986  Validation loss = 3.9576  \n",
      "\n",
      "Fold: 11  Epoch: 294  Training loss = 4.1980  Validation loss = 3.9570  \n",
      "\n",
      "Fold: 11  Epoch: 295  Training loss = 4.1977  Validation loss = 3.9566  \n",
      "\n",
      "Fold: 11  Epoch: 296  Training loss = 4.1972  Validation loss = 3.9561  \n",
      "\n",
      "Fold: 11  Epoch: 297  Training loss = 4.1967  Validation loss = 3.9554  \n",
      "\n",
      "Fold: 11  Epoch: 298  Training loss = 4.1963  Validation loss = 3.9550  \n",
      "\n",
      "Fold: 11  Epoch: 299  Training loss = 4.1957  Validation loss = 3.9543  \n",
      "\n",
      "Fold: 11  Epoch: 300  Training loss = 4.1953  Validation loss = 3.9538  \n",
      "\n",
      "Fold: 11  Epoch: 301  Training loss = 4.1950  Validation loss = 3.9534  \n",
      "\n",
      "Fold: 11  Epoch: 302  Training loss = 4.1946  Validation loss = 3.9530  \n",
      "\n",
      "Fold: 11  Epoch: 303  Training loss = 4.1943  Validation loss = 3.9525  \n",
      "\n",
      "Fold: 11  Epoch: 304  Training loss = 4.1941  Validation loss = 3.9522  \n",
      "\n",
      "Fold: 11  Epoch: 305  Training loss = 4.1936  Validation loss = 3.9517  \n",
      "\n",
      "Fold: 11  Epoch: 306  Training loss = 4.1931  Validation loss = 3.9512  \n",
      "\n",
      "Fold: 11  Epoch: 307  Training loss = 4.1927  Validation loss = 3.9506  \n",
      "\n",
      "Fold: 11  Epoch: 308  Training loss = 4.1922  Validation loss = 3.9501  \n",
      "\n",
      "Fold: 11  Epoch: 309  Training loss = 4.1917  Validation loss = 3.9495  \n",
      "\n",
      "Fold: 11  Epoch: 310  Training loss = 4.1911  Validation loss = 3.9489  \n",
      "\n",
      "Fold: 11  Epoch: 311  Training loss = 4.1905  Validation loss = 3.9482  \n",
      "\n",
      "Fold: 11  Epoch: 312  Training loss = 4.1900  Validation loss = 3.9476  \n",
      "\n",
      "Fold: 11  Epoch: 313  Training loss = 4.1895  Validation loss = 3.9472  \n",
      "\n",
      "Fold: 11  Epoch: 314  Training loss = 4.1889  Validation loss = 3.9465  \n",
      "\n",
      "Fold: 11  Epoch: 315  Training loss = 4.1884  Validation loss = 3.9459  \n",
      "\n",
      "Fold: 11  Epoch: 316  Training loss = 4.1880  Validation loss = 3.9454  \n",
      "\n",
      "Fold: 11  Epoch: 317  Training loss = 4.1874  Validation loss = 3.9448  \n",
      "\n",
      "Fold: 11  Epoch: 318  Training loss = 4.1870  Validation loss = 3.9444  \n",
      "\n",
      "Fold: 11  Epoch: 319  Training loss = 4.1868  Validation loss = 3.9441  \n",
      "\n",
      "Fold: 11  Epoch: 320  Training loss = 4.1862  Validation loss = 3.9435  \n",
      "\n",
      "Fold: 11  Epoch: 321  Training loss = 4.1856  Validation loss = 3.9429  \n",
      "\n",
      "Fold: 11  Epoch: 322  Training loss = 4.1851  Validation loss = 3.9423  \n",
      "\n",
      "Fold: 11  Epoch: 323  Training loss = 4.1846  Validation loss = 3.9418  \n",
      "\n",
      "Fold: 11  Epoch: 324  Training loss = 4.1840  Validation loss = 3.9412  \n",
      "\n",
      "Fold: 11  Epoch: 325  Training loss = 4.1836  Validation loss = 3.9407  \n",
      "\n",
      "Fold: 11  Epoch: 326  Training loss = 4.1832  Validation loss = 3.9403  \n",
      "\n",
      "Fold: 11  Epoch: 327  Training loss = 4.1825  Validation loss = 3.9396  \n",
      "\n",
      "Fold: 11  Epoch: 328  Training loss = 4.1822  Validation loss = 3.9393  \n",
      "\n",
      "Fold: 11  Epoch: 329  Training loss = 4.1816  Validation loss = 3.9387  \n",
      "\n",
      "Fold: 11  Epoch: 330  Training loss = 4.1810  Validation loss = 3.9381  \n",
      "\n",
      "Fold: 11  Epoch: 331  Training loss = 4.1806  Validation loss = 3.9377  \n",
      "\n",
      "Fold: 11  Epoch: 332  Training loss = 4.1800  Validation loss = 3.9371  \n",
      "\n",
      "Fold: 11  Epoch: 333  Training loss = 4.1794  Validation loss = 3.9365  \n",
      "\n",
      "Fold: 11  Epoch: 334  Training loss = 4.1789  Validation loss = 3.9360  \n",
      "\n",
      "Fold: 11  Epoch: 335  Training loss = 4.1784  Validation loss = 3.9355  \n",
      "\n",
      "Fold: 11  Epoch: 336  Training loss = 4.1781  Validation loss = 3.9351  \n",
      "\n",
      "Fold: 11  Epoch: 337  Training loss = 4.1776  Validation loss = 3.9347  \n",
      "\n",
      "Fold: 11  Epoch: 338  Training loss = 4.1771  Validation loss = 3.9342  \n",
      "\n",
      "Fold: 11  Epoch: 339  Training loss = 4.1766  Validation loss = 3.9337  \n",
      "\n",
      "Fold: 11  Epoch: 340  Training loss = 4.1761  Validation loss = 3.9331  \n",
      "\n",
      "Fold: 11  Epoch: 341  Training loss = 4.1756  Validation loss = 3.9327  \n",
      "\n",
      "Fold: 11  Epoch: 342  Training loss = 4.1752  Validation loss = 3.9322  \n",
      "\n",
      "Fold: 11  Epoch: 343  Training loss = 4.1746  Validation loss = 3.9317  \n",
      "\n",
      "Fold: 11  Epoch: 344  Training loss = 4.1740  Validation loss = 3.9311  \n",
      "\n",
      "Fold: 11  Epoch: 345  Training loss = 4.1735  Validation loss = 3.9306  \n",
      "\n",
      "Fold: 11  Epoch: 346  Training loss = 4.1731  Validation loss = 3.9302  \n",
      "\n",
      "Fold: 11  Epoch: 347  Training loss = 4.1725  Validation loss = 3.9297  \n",
      "\n",
      "Fold: 11  Epoch: 348  Training loss = 4.1721  Validation loss = 3.9292  \n",
      "\n",
      "Fold: 11  Epoch: 349  Training loss = 4.1716  Validation loss = 3.9287  \n",
      "\n",
      "Fold: 11  Epoch: 350  Training loss = 4.1710  Validation loss = 3.9282  \n",
      "\n",
      "Fold: 11  Epoch: 351  Training loss = 4.1704  Validation loss = 3.9276  \n",
      "\n",
      "Fold: 11  Epoch: 352  Training loss = 4.1700  Validation loss = 3.9272  \n",
      "\n",
      "Fold: 11  Epoch: 353  Training loss = 4.1697  Validation loss = 3.9267  \n",
      "\n",
      "Fold: 11  Epoch: 354  Training loss = 4.1692  Validation loss = 3.9262  \n",
      "\n",
      "Fold: 11  Epoch: 355  Training loss = 4.1687  Validation loss = 3.9257  \n",
      "\n",
      "Fold: 11  Epoch: 356  Training loss = 4.1683  Validation loss = 3.9252  \n",
      "\n",
      "Fold: 11  Epoch: 357  Training loss = 4.1679  Validation loss = 3.9248  \n",
      "\n",
      "Fold: 11  Epoch: 358  Training loss = 4.1674  Validation loss = 3.9244  \n",
      "\n",
      "Fold: 11  Epoch: 359  Training loss = 4.1669  Validation loss = 3.9238  \n",
      "\n",
      "Fold: 11  Epoch: 360  Training loss = 4.1662  Validation loss = 3.9232  \n",
      "\n",
      "Fold: 11  Epoch: 361  Training loss = 4.1655  Validation loss = 3.9226  \n",
      "\n",
      "Fold: 11  Epoch: 362  Training loss = 4.1652  Validation loss = 3.9222  \n",
      "\n",
      "Fold: 11  Epoch: 363  Training loss = 4.1648  Validation loss = 3.9218  \n",
      "\n",
      "Fold: 11  Epoch: 364  Training loss = 4.1642  Validation loss = 3.9212  \n",
      "\n",
      "Fold: 11  Epoch: 365  Training loss = 4.1636  Validation loss = 3.9206  \n",
      "\n",
      "Fold: 11  Epoch: 366  Training loss = 4.1631  Validation loss = 3.9201  \n",
      "\n",
      "Fold: 11  Epoch: 367  Training loss = 4.1626  Validation loss = 3.9196  \n",
      "\n",
      "Fold: 11  Epoch: 368  Training loss = 4.1622  Validation loss = 3.9192  \n",
      "\n",
      "Fold: 11  Epoch: 369  Training loss = 4.1618  Validation loss = 3.9187  \n",
      "\n",
      "Fold: 11  Epoch: 370  Training loss = 4.1613  Validation loss = 3.9181  \n",
      "\n",
      "Fold: 11  Epoch: 371  Training loss = 4.1608  Validation loss = 3.9176  \n",
      "\n",
      "Fold: 11  Epoch: 372  Training loss = 4.1605  Validation loss = 3.9172  \n",
      "\n",
      "Fold: 11  Epoch: 373  Training loss = 4.1599  Validation loss = 3.9166  \n",
      "\n",
      "Fold: 11  Epoch: 374  Training loss = 4.1596  Validation loss = 3.9161  \n",
      "\n",
      "Fold: 11  Epoch: 375  Training loss = 4.1590  Validation loss = 3.9156  \n",
      "\n",
      "Fold: 11  Epoch: 376  Training loss = 4.1585  Validation loss = 3.9151  \n",
      "\n",
      "Fold: 11  Epoch: 377  Training loss = 4.1582  Validation loss = 3.9147  \n",
      "\n",
      "Fold: 11  Epoch: 378  Training loss = 4.1576  Validation loss = 3.9142  \n",
      "\n",
      "Fold: 11  Epoch: 379  Training loss = 4.1572  Validation loss = 3.9137  \n",
      "\n",
      "Fold: 11  Epoch: 380  Training loss = 4.1569  Validation loss = 3.9133  \n",
      "\n",
      "Fold: 11  Epoch: 381  Training loss = 4.1565  Validation loss = 3.9128  \n",
      "\n",
      "Fold: 11  Epoch: 382  Training loss = 4.1560  Validation loss = 3.9123  \n",
      "\n",
      "Fold: 11  Epoch: 383  Training loss = 4.1557  Validation loss = 3.9118  \n",
      "\n",
      "Fold: 11  Epoch: 384  Training loss = 4.1554  Validation loss = 3.9115  \n",
      "\n",
      "Fold: 11  Epoch: 385  Training loss = 4.1548  Validation loss = 3.9109  \n",
      "\n",
      "Fold: 11  Epoch: 386  Training loss = 4.1544  Validation loss = 3.9103  \n",
      "\n",
      "Fold: 11  Epoch: 387  Training loss = 4.1540  Validation loss = 3.9099  \n",
      "\n",
      "Fold: 11  Epoch: 388  Training loss = 4.1535  Validation loss = 3.9093  \n",
      "\n",
      "Fold: 11  Epoch: 389  Training loss = 4.1531  Validation loss = 3.9088  \n",
      "\n",
      "Fold: 11  Epoch: 390  Training loss = 4.1527  Validation loss = 3.9084  \n",
      "\n",
      "Fold: 11  Epoch: 391  Training loss = 4.1523  Validation loss = 3.9080  \n",
      "\n",
      "Fold: 11  Epoch: 392  Training loss = 4.1519  Validation loss = 3.9075  \n",
      "\n",
      "Fold: 11  Epoch: 393  Training loss = 4.1517  Validation loss = 3.9072  \n",
      "\n",
      "Fold: 11  Epoch: 394  Training loss = 4.1513  Validation loss = 3.9067  \n",
      "\n",
      "Fold: 11  Epoch: 395  Training loss = 4.1509  Validation loss = 3.9062  \n",
      "\n",
      "Fold: 11  Epoch: 396  Training loss = 4.1506  Validation loss = 3.9058  \n",
      "\n",
      "Fold: 11  Epoch: 397  Training loss = 4.1502  Validation loss = 3.9053  \n",
      "\n",
      "Fold: 11  Epoch: 398  Training loss = 4.1498  Validation loss = 3.9049  \n",
      "\n",
      "Fold: 11  Epoch: 399  Training loss = 4.1495  Validation loss = 3.9045  \n",
      "\n",
      "Fold: 11  Epoch: 400  Training loss = 4.1491  Validation loss = 3.9040  \n",
      "\n",
      "Fold: 11  Epoch: 401  Training loss = 4.1487  Validation loss = 3.9036  \n",
      "\n",
      "Fold: 11  Epoch: 402  Training loss = 4.1482  Validation loss = 3.9030  \n",
      "\n",
      "Fold: 11  Epoch: 403  Training loss = 4.1478  Validation loss = 3.9025  \n",
      "\n",
      "Fold: 11  Epoch: 404  Training loss = 4.1473  Validation loss = 3.9020  \n",
      "\n",
      "Fold: 11  Epoch: 405  Training loss = 4.1469  Validation loss = 3.9016  \n",
      "\n",
      "Fold: 11  Epoch: 406  Training loss = 4.1458  Validation loss = 3.9010  \n",
      "\n",
      "Fold: 11  Epoch: 407  Training loss = 4.1455  Validation loss = 3.9006  \n",
      "\n",
      "Fold: 11  Epoch: 408  Training loss = 4.1450  Validation loss = 3.9001  \n",
      "\n",
      "Fold: 11  Epoch: 409  Training loss = 4.1447  Validation loss = 3.8997  \n",
      "\n",
      "Fold: 11  Epoch: 410  Training loss = 4.1443  Validation loss = 3.8993  \n",
      "\n",
      "Fold: 11  Epoch: 411  Training loss = 4.1439  Validation loss = 3.8988  \n",
      "\n",
      "Fold: 11  Epoch: 412  Training loss = 4.1434  Validation loss = 3.8982  \n",
      "\n",
      "Fold: 11  Epoch: 413  Training loss = 4.1431  Validation loss = 3.8977  \n",
      "\n",
      "Fold: 11  Epoch: 414  Training loss = 4.1428  Validation loss = 3.8974  \n",
      "\n",
      "Fold: 11  Epoch: 415  Training loss = 4.1425  Validation loss = 3.8970  \n",
      "\n",
      "Fold: 11  Epoch: 416  Training loss = 4.1421  Validation loss = 3.8966  \n",
      "\n",
      "Fold: 11  Epoch: 417  Training loss = 4.1418  Validation loss = 3.8961  \n",
      "\n",
      "Fold: 11  Epoch: 418  Training loss = 4.1416  Validation loss = 3.8958  \n",
      "\n",
      "Fold: 11  Epoch: 419  Training loss = 4.1411  Validation loss = 3.8952  \n",
      "\n",
      "Fold: 11  Epoch: 420  Training loss = 4.1407  Validation loss = 3.8948  \n",
      "\n",
      "Fold: 11  Epoch: 421  Training loss = 4.1404  Validation loss = 3.8943  \n",
      "\n",
      "Fold: 11  Epoch: 422  Training loss = 4.1400  Validation loss = 3.8937  \n",
      "\n",
      "Fold: 11  Epoch: 423  Training loss = 4.1397  Validation loss = 3.8933  \n",
      "\n",
      "Fold: 11  Epoch: 424  Training loss = 4.1393  Validation loss = 3.8928  \n",
      "\n",
      "Fold: 11  Epoch: 425  Training loss = 4.1389  Validation loss = 3.8922  \n",
      "\n",
      "Fold: 11  Epoch: 426  Training loss = 4.1386  Validation loss = 3.8918  \n",
      "\n",
      "Fold: 11  Epoch: 427  Training loss = 4.1383  Validation loss = 3.8914  \n",
      "\n",
      "Fold: 11  Epoch: 428  Training loss = 4.1380  Validation loss = 3.8909  \n",
      "\n",
      "Fold: 11  Epoch: 429  Training loss = 4.1377  Validation loss = 3.8906  \n",
      "\n",
      "Fold: 11  Epoch: 430  Training loss = 4.1375  Validation loss = 3.8902  \n",
      "\n",
      "Fold: 11  Epoch: 431  Training loss = 4.1370  Validation loss = 3.8896  \n",
      "\n",
      "Fold: 11  Epoch: 432  Training loss = 4.1367  Validation loss = 3.8891  \n",
      "\n",
      "Fold: 11  Epoch: 433  Training loss = 4.1364  Validation loss = 3.8886  \n",
      "\n",
      "Fold: 11  Epoch: 434  Training loss = 4.1360  Validation loss = 3.8881  \n",
      "\n",
      "Fold: 11  Epoch: 435  Training loss = 4.1358  Validation loss = 3.8877  \n",
      "\n",
      "Fold: 11  Epoch: 436  Training loss = 4.1354  Validation loss = 3.8873  \n",
      "\n",
      "Fold: 11  Epoch: 437  Training loss = 4.1351  Validation loss = 3.8868  \n",
      "\n",
      "Fold: 11  Epoch: 438  Training loss = 4.1348  Validation loss = 3.8863  \n",
      "\n",
      "Fold: 11  Epoch: 439  Training loss = 4.1344  Validation loss = 3.8858  \n",
      "\n",
      "Fold: 11  Epoch: 440  Training loss = 4.1340  Validation loss = 3.8852  \n",
      "\n",
      "Fold: 11  Epoch: 441  Training loss = 4.1338  Validation loss = 3.8848  \n",
      "\n",
      "Fold: 11  Epoch: 442  Training loss = 4.1335  Validation loss = 3.8845  \n",
      "\n",
      "Fold: 11  Epoch: 443  Training loss = 4.1332  Validation loss = 3.8840  \n",
      "\n",
      "Fold: 11  Epoch: 444  Training loss = 4.1329  Validation loss = 3.8835  \n",
      "\n",
      "Fold: 11  Epoch: 445  Training loss = 4.1325  Validation loss = 3.8831  \n",
      "\n",
      "Fold: 11  Epoch: 446  Training loss = 4.1321  Validation loss = 3.8825  \n",
      "\n",
      "Fold: 11  Epoch: 447  Training loss = 4.1319  Validation loss = 3.8821  \n",
      "\n",
      "Fold: 11  Epoch: 448  Training loss = 4.1316  Validation loss = 3.8816  \n",
      "\n",
      "Fold: 11  Epoch: 449  Training loss = 4.1312  Validation loss = 3.8812  \n",
      "\n",
      "Fold: 11  Epoch: 450  Training loss = 4.1309  Validation loss = 3.8807  \n",
      "\n",
      "Fold: 11  Epoch: 451  Training loss = 4.1305  Validation loss = 3.8801  \n",
      "\n",
      "Fold: 11  Epoch: 452  Training loss = 4.1302  Validation loss = 3.8797  \n",
      "\n",
      "Fold: 11  Epoch: 453  Training loss = 4.1300  Validation loss = 3.8793  \n",
      "\n",
      "Fold: 11  Epoch: 454  Training loss = 4.1297  Validation loss = 3.8789  \n",
      "\n",
      "Fold: 11  Epoch: 455  Training loss = 4.1294  Validation loss = 3.8785  \n",
      "\n",
      "Fold: 11  Epoch: 456  Training loss = 4.1290  Validation loss = 3.8779  \n",
      "\n",
      "Fold: 11  Epoch: 457  Training loss = 4.1286  Validation loss = 3.8774  \n",
      "\n",
      "Fold: 11  Epoch: 458  Training loss = 4.1283  Validation loss = 3.8769  \n",
      "\n",
      "Fold: 11  Epoch: 459  Training loss = 4.1280  Validation loss = 3.8764  \n",
      "\n",
      "Fold: 11  Epoch: 460  Training loss = 4.1277  Validation loss = 3.8760  \n",
      "\n",
      "Fold: 11  Epoch: 461  Training loss = 4.1274  Validation loss = 3.8755  \n",
      "\n",
      "Fold: 11  Epoch: 462  Training loss = 4.1271  Validation loss = 3.8750  \n",
      "\n",
      "Fold: 11  Epoch: 463  Training loss = 4.1267  Validation loss = 3.8744  \n",
      "\n",
      "Fold: 11  Epoch: 464  Training loss = 4.1264  Validation loss = 3.8739  \n",
      "\n",
      "Fold: 11  Epoch: 465  Training loss = 4.1261  Validation loss = 3.8735  \n",
      "\n",
      "Fold: 11  Epoch: 466  Training loss = 4.1258  Validation loss = 3.8731  \n",
      "\n",
      "Fold: 11  Epoch: 467  Training loss = 4.1255  Validation loss = 3.8725  \n",
      "\n",
      "Fold: 11  Epoch: 468  Training loss = 4.1251  Validation loss = 3.8720  \n",
      "\n",
      "Fold: 11  Epoch: 469  Training loss = 4.1249  Validation loss = 3.8716  \n",
      "\n",
      "Fold: 11  Epoch: 470  Training loss = 4.1246  Validation loss = 3.8712  \n",
      "\n",
      "Fold: 11  Epoch: 471  Training loss = 4.1243  Validation loss = 3.8707  \n",
      "\n",
      "Fold: 11  Epoch: 472  Training loss = 4.1240  Validation loss = 3.8703  \n",
      "\n",
      "Fold: 11  Epoch: 473  Training loss = 4.1237  Validation loss = 3.8699  \n",
      "\n",
      "Fold: 11  Epoch: 474  Training loss = 4.1234  Validation loss = 3.8694  \n",
      "\n",
      "Fold: 11  Epoch: 475  Training loss = 4.1231  Validation loss = 3.8690  \n",
      "\n",
      "Fold: 11  Epoch: 476  Training loss = 4.1229  Validation loss = 3.8686  \n",
      "\n",
      "Fold: 11  Epoch: 477  Training loss = 4.1226  Validation loss = 3.8682  \n",
      "\n",
      "Fold: 11  Epoch: 478  Training loss = 4.1222  Validation loss = 3.8676  \n",
      "\n",
      "Fold: 11  Epoch: 479  Training loss = 4.1219  Validation loss = 3.8671  \n",
      "\n",
      "Fold: 11  Epoch: 480  Training loss = 4.1216  Validation loss = 3.8666  \n",
      "\n",
      "Fold: 11  Epoch: 481  Training loss = 4.1213  Validation loss = 3.8662  \n",
      "\n",
      "Fold: 11  Epoch: 482  Training loss = 4.1210  Validation loss = 3.8657  \n",
      "\n",
      "Fold: 11  Epoch: 483  Training loss = 4.1206  Validation loss = 3.8651  \n",
      "\n",
      "Fold: 11  Epoch: 484  Training loss = 4.1204  Validation loss = 3.8648  \n",
      "\n",
      "Fold: 11  Epoch: 485  Training loss = 4.1201  Validation loss = 3.8643  \n",
      "\n",
      "Fold: 11  Epoch: 486  Training loss = 4.1200  Validation loss = 3.8641  \n",
      "\n",
      "Fold: 11  Epoch: 487  Training loss = 4.1197  Validation loss = 3.8637  \n",
      "\n",
      "Fold: 11  Epoch: 488  Training loss = 4.1194  Validation loss = 3.8632  \n",
      "\n",
      "Fold: 11  Epoch: 489  Training loss = 4.1191  Validation loss = 3.8627  \n",
      "\n",
      "Fold: 11  Epoch: 490  Training loss = 4.1188  Validation loss = 3.8623  \n",
      "\n",
      "Fold: 11  Epoch: 491  Training loss = 4.1185  Validation loss = 3.8618  \n",
      "\n",
      "Fold: 11  Epoch: 492  Training loss = 4.1182  Validation loss = 3.8613  \n",
      "\n",
      "Fold: 11  Epoch: 493  Training loss = 4.1179  Validation loss = 3.8609  \n",
      "\n",
      "Fold: 11  Epoch: 494  Training loss = 4.1176  Validation loss = 3.8604  \n",
      "\n",
      "Fold: 11  Epoch: 495  Training loss = 4.1173  Validation loss = 3.8599  \n",
      "\n",
      "Fold: 11  Epoch: 496  Training loss = 4.1170  Validation loss = 3.8595  \n",
      "\n",
      "Fold: 11  Epoch: 497  Training loss = 4.1168  Validation loss = 3.8592  \n",
      "\n",
      "Fold: 11  Epoch: 498  Training loss = 4.1166  Validation loss = 3.8588  \n",
      "\n",
      "Fold: 11  Epoch: 499  Training loss = 4.1162  Validation loss = 3.8583  \n",
      "\n",
      "Fold: 11  Epoch: 500  Training loss = 4.1159  Validation loss = 3.8578  \n",
      "\n",
      "Check model:  Fold: 11  Optimal epoch: 500  \n",
      "\n",
      "Fold: 12  Epoch: 1  Training loss = 4.2159  Validation loss = 5.1791  \n",
      "\n",
      "Fold: 12  Epoch: 2  Training loss = 4.2156  Validation loss = 5.1786  \n",
      "\n",
      "Fold: 12  Epoch: 3  Training loss = 4.2152  Validation loss = 5.1781  \n",
      "\n",
      "Fold: 12  Epoch: 4  Training loss = 4.2148  Validation loss = 5.1775  \n",
      "\n",
      "Fold: 12  Epoch: 5  Training loss = 4.2143  Validation loss = 5.1770  \n",
      "\n",
      "Fold: 12  Epoch: 6  Training loss = 4.2139  Validation loss = 5.1765  \n",
      "\n",
      "Fold: 12  Epoch: 7  Training loss = 4.2123  Validation loss = 5.1760  \n",
      "\n",
      "Fold: 12  Epoch: 8  Training loss = 4.2076  Validation loss = 5.1756  \n",
      "\n",
      "Fold: 12  Epoch: 9  Training loss = 4.2072  Validation loss = 5.1750  \n",
      "\n",
      "Fold: 12  Epoch: 10  Training loss = 4.2068  Validation loss = 5.1745  \n",
      "\n",
      "Fold: 12  Epoch: 11  Training loss = 4.2065  Validation loss = 5.1740  \n",
      "\n",
      "Fold: 12  Epoch: 12  Training loss = 4.2063  Validation loss = 5.1736  \n",
      "\n",
      "Fold: 12  Epoch: 13  Training loss = 4.2059  Validation loss = 5.1730  \n",
      "\n",
      "Fold: 12  Epoch: 14  Training loss = 4.2055  Validation loss = 5.1723  \n",
      "\n",
      "Fold: 12  Epoch: 15  Training loss = 4.2052  Validation loss = 5.1719  \n",
      "\n",
      "Fold: 12  Epoch: 16  Training loss = 4.2048  Validation loss = 5.1714  \n",
      "\n",
      "Fold: 12  Epoch: 17  Training loss = 4.2045  Validation loss = 5.1708  \n",
      "\n",
      "Fold: 12  Epoch: 18  Training loss = 4.2042  Validation loss = 5.1704  \n",
      "\n",
      "Fold: 12  Epoch: 19  Training loss = 4.2038  Validation loss = 5.1697  \n",
      "\n",
      "Fold: 12  Epoch: 20  Training loss = 4.2034  Validation loss = 5.1691  \n",
      "\n",
      "Fold: 12  Epoch: 21  Training loss = 4.2030  Validation loss = 5.1685  \n",
      "\n",
      "Fold: 12  Epoch: 22  Training loss = 4.2027  Validation loss = 5.1680  \n",
      "\n",
      "Fold: 12  Epoch: 23  Training loss = 4.2023  Validation loss = 5.1674  \n",
      "\n",
      "Fold: 12  Epoch: 24  Training loss = 4.2020  Validation loss = 5.1670  \n",
      "\n",
      "Fold: 12  Epoch: 25  Training loss = 4.2017  Validation loss = 5.1665  \n",
      "\n",
      "Fold: 12  Epoch: 26  Training loss = 4.2014  Validation loss = 5.1660  \n",
      "\n",
      "Fold: 12  Epoch: 27  Training loss = 4.2010  Validation loss = 5.1654  \n",
      "\n",
      "Fold: 12  Epoch: 28  Training loss = 4.2007  Validation loss = 5.1649  \n",
      "\n",
      "Fold: 12  Epoch: 29  Training loss = 4.2004  Validation loss = 5.1646  \n",
      "\n",
      "Fold: 12  Epoch: 30  Training loss = 4.2001  Validation loss = 5.1641  \n",
      "\n",
      "Fold: 12  Epoch: 31  Training loss = 4.1998  Validation loss = 5.1636  \n",
      "\n",
      "Fold: 12  Epoch: 32  Training loss = 4.1995  Validation loss = 5.1631  \n",
      "\n",
      "Fold: 12  Epoch: 33  Training loss = 4.1991  Validation loss = 5.1626  \n",
      "\n",
      "Fold: 12  Epoch: 34  Training loss = 4.1988  Validation loss = 5.1621  \n",
      "\n",
      "Fold: 12  Epoch: 35  Training loss = 4.1985  Validation loss = 5.1616  \n",
      "\n",
      "Fold: 12  Epoch: 36  Training loss = 4.1982  Validation loss = 5.1611  \n",
      "\n",
      "Fold: 12  Epoch: 37  Training loss = 4.1979  Validation loss = 5.1606  \n",
      "\n",
      "Fold: 12  Epoch: 38  Training loss = 4.1976  Validation loss = 5.1602  \n",
      "\n",
      "Fold: 12  Epoch: 39  Training loss = 4.1973  Validation loss = 5.1597  \n",
      "\n",
      "Fold: 12  Epoch: 40  Training loss = 4.1969  Validation loss = 5.1592  \n",
      "\n",
      "Fold: 12  Epoch: 41  Training loss = 4.1966  Validation loss = 5.1587  \n",
      "\n",
      "Fold: 12  Epoch: 42  Training loss = 4.1963  Validation loss = 5.1582  \n",
      "\n",
      "Fold: 12  Epoch: 43  Training loss = 4.1960  Validation loss = 5.1577  \n",
      "\n",
      "Fold: 12  Epoch: 44  Training loss = 4.1956  Validation loss = 5.1572  \n",
      "\n",
      "Fold: 12  Epoch: 45  Training loss = 4.1953  Validation loss = 5.1566  \n",
      "\n",
      "Fold: 12  Epoch: 46  Training loss = 4.1950  Validation loss = 5.1562  \n",
      "\n",
      "Fold: 12  Epoch: 47  Training loss = 4.1947  Validation loss = 5.1557  \n",
      "\n",
      "Fold: 12  Epoch: 48  Training loss = 4.1943  Validation loss = 5.1552  \n",
      "\n",
      "Fold: 12  Epoch: 49  Training loss = 4.1940  Validation loss = 5.1546  \n",
      "\n",
      "Fold: 12  Epoch: 50  Training loss = 4.1936  Validation loss = 5.1541  \n",
      "\n",
      "Fold: 12  Epoch: 51  Training loss = 4.1933  Validation loss = 5.1536  \n",
      "\n",
      "Fold: 12  Epoch: 52  Training loss = 4.1930  Validation loss = 5.1531  \n",
      "\n",
      "Fold: 12  Epoch: 53  Training loss = 4.1927  Validation loss = 5.1526  \n",
      "\n",
      "Fold: 12  Epoch: 54  Training loss = 4.1923  Validation loss = 5.1521  \n",
      "\n",
      "Fold: 12  Epoch: 55  Training loss = 4.1920  Validation loss = 5.1516  \n",
      "\n",
      "Fold: 12  Epoch: 56  Training loss = 4.1917  Validation loss = 5.1511  \n",
      "\n",
      "Fold: 12  Epoch: 57  Training loss = 4.1913  Validation loss = 5.1506  \n",
      "\n",
      "Fold: 12  Epoch: 58  Training loss = 4.1909  Validation loss = 5.1500  \n",
      "\n",
      "Fold: 12  Epoch: 59  Training loss = 4.1907  Validation loss = 5.1495  \n",
      "\n",
      "Fold: 12  Epoch: 60  Training loss = 4.1903  Validation loss = 5.1490  \n",
      "\n",
      "Fold: 12  Epoch: 61  Training loss = 4.1900  Validation loss = 5.1485  \n",
      "\n",
      "Fold: 12  Epoch: 62  Training loss = 4.1896  Validation loss = 5.1479  \n",
      "\n",
      "Fold: 12  Epoch: 63  Training loss = 4.1893  Validation loss = 5.1473  \n",
      "\n",
      "Fold: 12  Epoch: 64  Training loss = 4.1890  Validation loss = 5.1469  \n",
      "\n",
      "Fold: 12  Epoch: 65  Training loss = 4.1887  Validation loss = 5.1464  \n",
      "\n",
      "Fold: 12  Epoch: 66  Training loss = 4.1883  Validation loss = 5.1459  \n",
      "\n",
      "Fold: 12  Epoch: 67  Training loss = 4.1880  Validation loss = 5.1454  \n",
      "\n",
      "Fold: 12  Epoch: 68  Training loss = 4.1877  Validation loss = 5.1449  \n",
      "\n",
      "Fold: 12  Epoch: 69  Training loss = 4.1873  Validation loss = 5.1443  \n",
      "\n",
      "Fold: 12  Epoch: 70  Training loss = 4.1870  Validation loss = 5.1438  \n",
      "\n",
      "Fold: 12  Epoch: 71  Training loss = 4.1866  Validation loss = 5.1433  \n",
      "\n",
      "Fold: 12  Epoch: 72  Training loss = 4.1864  Validation loss = 5.1429  \n",
      "\n",
      "Fold: 12  Epoch: 73  Training loss = 4.1860  Validation loss = 5.1424  \n",
      "\n",
      "Fold: 12  Epoch: 74  Training loss = 4.1857  Validation loss = 5.1418  \n",
      "\n",
      "Fold: 12  Epoch: 75  Training loss = 4.1854  Validation loss = 5.1413  \n",
      "\n",
      "Fold: 12  Epoch: 76  Training loss = 4.1850  Validation loss = 5.1408  \n",
      "\n",
      "Fold: 12  Epoch: 77  Training loss = 4.1847  Validation loss = 5.1403  \n",
      "\n",
      "Fold: 12  Epoch: 78  Training loss = 4.1844  Validation loss = 5.1398  \n",
      "\n",
      "Fold: 12  Epoch: 79  Training loss = 4.1841  Validation loss = 5.1392  \n",
      "\n",
      "Fold: 12  Epoch: 80  Training loss = 4.1838  Validation loss = 5.1388  \n",
      "\n",
      "Fold: 12  Epoch: 81  Training loss = 4.1834  Validation loss = 5.1382  \n",
      "\n",
      "Fold: 12  Epoch: 82  Training loss = 4.1831  Validation loss = 5.1377  \n",
      "\n",
      "Fold: 12  Epoch: 83  Training loss = 4.1828  Validation loss = 5.1372  \n",
      "\n",
      "Fold: 12  Epoch: 84  Training loss = 4.1825  Validation loss = 5.1367  \n",
      "\n",
      "Fold: 12  Epoch: 85  Training loss = 4.1822  Validation loss = 5.1363  \n",
      "\n",
      "Fold: 12  Epoch: 86  Training loss = 4.1818  Validation loss = 5.1358  \n",
      "\n",
      "Fold: 12  Epoch: 87  Training loss = 4.1816  Validation loss = 5.1354  \n",
      "\n",
      "Fold: 12  Epoch: 88  Training loss = 4.1812  Validation loss = 5.1348  \n",
      "\n",
      "Fold: 12  Epoch: 89  Training loss = 4.1809  Validation loss = 5.1343  \n",
      "\n",
      "Fold: 12  Epoch: 90  Training loss = 4.1806  Validation loss = 5.1338  \n",
      "\n",
      "Fold: 12  Epoch: 91  Training loss = 4.1802  Validation loss = 5.1332  \n",
      "\n",
      "Fold: 12  Epoch: 92  Training loss = 4.1798  Validation loss = 5.1327  \n",
      "\n",
      "Fold: 12  Epoch: 93  Training loss = 4.1795  Validation loss = 5.1322  \n",
      "\n",
      "Fold: 12  Epoch: 94  Training loss = 4.1792  Validation loss = 5.1317  \n",
      "\n",
      "Fold: 12  Epoch: 95  Training loss = 4.1789  Validation loss = 5.1312  \n",
      "\n",
      "Fold: 12  Epoch: 96  Training loss = 4.1786  Validation loss = 5.1307  \n",
      "\n",
      "Fold: 12  Epoch: 97  Training loss = 4.1782  Validation loss = 5.1302  \n",
      "\n",
      "Fold: 12  Epoch: 98  Training loss = 4.1778  Validation loss = 5.1296  \n",
      "\n",
      "Fold: 12  Epoch: 99  Training loss = 4.1776  Validation loss = 5.1291  \n",
      "\n",
      "Fold: 12  Epoch: 100  Training loss = 4.1772  Validation loss = 5.1286  \n",
      "\n",
      "Fold: 12  Epoch: 101  Training loss = 4.1768  Validation loss = 5.1280  \n",
      "\n",
      "Fold: 12  Epoch: 102  Training loss = 4.1765  Validation loss = 5.1276  \n",
      "\n",
      "Fold: 12  Epoch: 103  Training loss = 4.1762  Validation loss = 5.1271  \n",
      "\n",
      "Fold: 12  Epoch: 104  Training loss = 4.1759  Validation loss = 5.1267  \n",
      "\n",
      "Fold: 12  Epoch: 105  Training loss = 4.1757  Validation loss = 5.1263  \n",
      "\n",
      "Fold: 12  Epoch: 106  Training loss = 4.1754  Validation loss = 5.1258  \n",
      "\n",
      "Fold: 12  Epoch: 107  Training loss = 4.1750  Validation loss = 5.1252  \n",
      "\n",
      "Fold: 12  Epoch: 108  Training loss = 4.1747  Validation loss = 5.1247  \n",
      "\n",
      "Fold: 12  Epoch: 109  Training loss = 4.1744  Validation loss = 5.1243  \n",
      "\n",
      "Fold: 12  Epoch: 110  Training loss = 4.1740  Validation loss = 5.1237  \n",
      "\n",
      "Fold: 12  Epoch: 111  Training loss = 4.1737  Validation loss = 5.1232  \n",
      "\n",
      "Fold: 12  Epoch: 112  Training loss = 4.1735  Validation loss = 5.1228  \n",
      "\n",
      "Fold: 12  Epoch: 113  Training loss = 4.1732  Validation loss = 5.1224  \n",
      "\n",
      "Fold: 12  Epoch: 114  Training loss = 4.1729  Validation loss = 5.1219  \n",
      "\n",
      "Fold: 12  Epoch: 115  Training loss = 4.1725  Validation loss = 5.1214  \n",
      "\n",
      "Fold: 12  Epoch: 116  Training loss = 4.1722  Validation loss = 5.1209  \n",
      "\n",
      "Fold: 12  Epoch: 117  Training loss = 4.1719  Validation loss = 5.1204  \n",
      "\n",
      "Fold: 12  Epoch: 118  Training loss = 4.1716  Validation loss = 5.1199  \n",
      "\n",
      "Fold: 12  Epoch: 119  Training loss = 4.1712  Validation loss = 5.1193  \n",
      "\n",
      "Fold: 12  Epoch: 120  Training loss = 4.1709  Validation loss = 5.1188  \n",
      "\n",
      "Fold: 12  Epoch: 121  Training loss = 4.1706  Validation loss = 5.1183  \n",
      "\n",
      "Fold: 12  Epoch: 122  Training loss = 4.1702  Validation loss = 5.1178  \n",
      "\n",
      "Fold: 12  Epoch: 123  Training loss = 4.1699  Validation loss = 5.1172  \n",
      "\n",
      "Fold: 12  Epoch: 124  Training loss = 4.1696  Validation loss = 5.1167  \n",
      "\n",
      "Fold: 12  Epoch: 125  Training loss = 4.1692  Validation loss = 5.1162  \n",
      "\n",
      "Fold: 12  Epoch: 126  Training loss = 4.1689  Validation loss = 5.1157  \n",
      "\n",
      "Fold: 12  Epoch: 127  Training loss = 4.1686  Validation loss = 5.1152  \n",
      "\n",
      "Fold: 12  Epoch: 128  Training loss = 4.1683  Validation loss = 5.1148  \n",
      "\n",
      "Fold: 12  Epoch: 129  Training loss = 4.1681  Validation loss = 5.1144  \n",
      "\n",
      "Fold: 12  Epoch: 130  Training loss = 4.1677  Validation loss = 5.1139  \n",
      "\n",
      "Fold: 12  Epoch: 131  Training loss = 4.1674  Validation loss = 5.1134  \n",
      "\n",
      "Fold: 12  Epoch: 132  Training loss = 4.1671  Validation loss = 5.1130  \n",
      "\n",
      "Fold: 12  Epoch: 133  Training loss = 4.1669  Validation loss = 5.1125  \n",
      "\n",
      "Fold: 12  Epoch: 134  Training loss = 4.1666  Validation loss = 5.1122  \n",
      "\n",
      "Fold: 12  Epoch: 135  Training loss = 4.1663  Validation loss = 5.1116  \n",
      "\n",
      "Fold: 12  Epoch: 136  Training loss = 4.1660  Validation loss = 5.1112  \n",
      "\n",
      "Fold: 12  Epoch: 137  Training loss = 4.1657  Validation loss = 5.1107  \n",
      "\n",
      "Fold: 12  Epoch: 138  Training loss = 4.1654  Validation loss = 5.1102  \n",
      "\n",
      "Fold: 12  Epoch: 139  Training loss = 4.1651  Validation loss = 5.1097  \n",
      "\n",
      "Fold: 12  Epoch: 140  Training loss = 4.1648  Validation loss = 5.1092  \n",
      "\n",
      "Fold: 12  Epoch: 141  Training loss = 4.1644  Validation loss = 5.1087  \n",
      "\n",
      "Fold: 12  Epoch: 142  Training loss = 4.1641  Validation loss = 5.1082  \n",
      "\n",
      "Fold: 12  Epoch: 143  Training loss = 4.1639  Validation loss = 5.1078  \n",
      "\n",
      "Fold: 12  Epoch: 144  Training loss = 4.1635  Validation loss = 5.1073  \n",
      "\n",
      "Fold: 12  Epoch: 145  Training loss = 4.1632  Validation loss = 5.1068  \n",
      "\n",
      "Fold: 12  Epoch: 146  Training loss = 4.1629  Validation loss = 5.1064  \n",
      "\n",
      "Fold: 12  Epoch: 147  Training loss = 4.1627  Validation loss = 5.1059  \n",
      "\n",
      "Fold: 12  Epoch: 148  Training loss = 4.1623  Validation loss = 5.1054  \n",
      "\n",
      "Fold: 12  Epoch: 149  Training loss = 4.1620  Validation loss = 5.1049  \n",
      "\n",
      "Fold: 12  Epoch: 150  Training loss = 4.1617  Validation loss = 5.1044  \n",
      "\n",
      "Fold: 12  Epoch: 151  Training loss = 4.1613  Validation loss = 5.1039  \n",
      "\n",
      "Fold: 12  Epoch: 152  Training loss = 4.1610  Validation loss = 5.1034  \n",
      "\n",
      "Fold: 12  Epoch: 153  Training loss = 4.1607  Validation loss = 5.1029  \n",
      "\n",
      "Fold: 12  Epoch: 154  Training loss = 4.1604  Validation loss = 5.1024  \n",
      "\n",
      "Fold: 12  Epoch: 155  Training loss = 4.1600  Validation loss = 5.1018  \n",
      "\n",
      "Fold: 12  Epoch: 156  Training loss = 4.1597  Validation loss = 5.1012  \n",
      "\n",
      "Fold: 12  Epoch: 157  Training loss = 4.1593  Validation loss = 5.1007  \n",
      "\n",
      "Fold: 12  Epoch: 158  Training loss = 4.1590  Validation loss = 5.1002  \n",
      "\n",
      "Fold: 12  Epoch: 159  Training loss = 4.1587  Validation loss = 5.0997  \n",
      "\n",
      "Fold: 12  Epoch: 160  Training loss = 4.1583  Validation loss = 5.0991  \n",
      "\n",
      "Fold: 12  Epoch: 161  Training loss = 4.1580  Validation loss = 5.0986  \n",
      "\n",
      "Fold: 12  Epoch: 162  Training loss = 4.1577  Validation loss = 5.0981  \n",
      "\n",
      "Fold: 12  Epoch: 163  Training loss = 4.1573  Validation loss = 5.0976  \n",
      "\n",
      "Fold: 12  Epoch: 164  Training loss = 4.1571  Validation loss = 5.0972  \n",
      "\n",
      "Fold: 12  Epoch: 165  Training loss = 4.1567  Validation loss = 5.0966  \n",
      "\n",
      "Fold: 12  Epoch: 166  Training loss = 4.1563  Validation loss = 5.0960  \n",
      "\n",
      "Fold: 12  Epoch: 167  Training loss = 4.1560  Validation loss = 5.0956  \n",
      "\n",
      "Fold: 12  Epoch: 168  Training loss = 4.1558  Validation loss = 5.0952  \n",
      "\n",
      "Fold: 12  Epoch: 169  Training loss = 4.1554  Validation loss = 5.0946  \n",
      "\n",
      "Fold: 12  Epoch: 170  Training loss = 4.1551  Validation loss = 5.0941  \n",
      "\n",
      "Fold: 12  Epoch: 171  Training loss = 4.1547  Validation loss = 5.0935  \n",
      "\n",
      "Fold: 12  Epoch: 172  Training loss = 4.1543  Validation loss = 5.0929  \n",
      "\n",
      "Fold: 12  Epoch: 173  Training loss = 4.1540  Validation loss = 5.0924  \n",
      "\n",
      "Fold: 12  Epoch: 174  Training loss = 4.1537  Validation loss = 5.0919  \n",
      "\n",
      "Fold: 12  Epoch: 175  Training loss = 4.1534  Validation loss = 5.0915  \n",
      "\n",
      "Fold: 12  Epoch: 176  Training loss = 4.1530  Validation loss = 5.0910  \n",
      "\n",
      "Fold: 12  Epoch: 177  Training loss = 4.1527  Validation loss = 5.0905  \n",
      "\n",
      "Fold: 12  Epoch: 178  Training loss = 4.1523  Validation loss = 5.0899  \n",
      "\n",
      "Fold: 12  Epoch: 179  Training loss = 4.1520  Validation loss = 5.0893  \n",
      "\n",
      "Fold: 12  Epoch: 180  Training loss = 4.1517  Validation loss = 5.0889  \n",
      "\n",
      "Fold: 12  Epoch: 181  Training loss = 4.1514  Validation loss = 5.0883  \n",
      "\n",
      "Fold: 12  Epoch: 182  Training loss = 4.1510  Validation loss = 5.0878  \n",
      "\n",
      "Fold: 12  Epoch: 183  Training loss = 4.1508  Validation loss = 5.0874  \n",
      "\n",
      "Fold: 12  Epoch: 184  Training loss = 4.1504  Validation loss = 5.0868  \n",
      "\n",
      "Fold: 12  Epoch: 185  Training loss = 4.1500  Validation loss = 5.0862  \n",
      "\n",
      "Fold: 12  Epoch: 186  Training loss = 4.1497  Validation loss = 5.0857  \n",
      "\n",
      "Fold: 12  Epoch: 187  Training loss = 4.1494  Validation loss = 5.0853  \n",
      "\n",
      "Fold: 12  Epoch: 188  Training loss = 4.1492  Validation loss = 5.0849  \n",
      "\n",
      "Fold: 12  Epoch: 189  Training loss = 4.1488  Validation loss = 5.0843  \n",
      "\n",
      "Fold: 12  Epoch: 190  Training loss = 4.1485  Validation loss = 5.0838  \n",
      "\n",
      "Fold: 12  Epoch: 191  Training loss = 4.1482  Validation loss = 5.0833  \n",
      "\n",
      "Fold: 12  Epoch: 192  Training loss = 4.1479  Validation loss = 5.0829  \n",
      "\n",
      "Fold: 12  Epoch: 193  Training loss = 4.1475  Validation loss = 5.0823  \n",
      "\n",
      "Fold: 12  Epoch: 194  Training loss = 4.1472  Validation loss = 5.0818  \n",
      "\n",
      "Fold: 12  Epoch: 195  Training loss = 4.1469  Validation loss = 5.0813  \n",
      "\n",
      "Fold: 12  Epoch: 196  Training loss = 4.1466  Validation loss = 5.0809  \n",
      "\n",
      "Fold: 12  Epoch: 197  Training loss = 4.1464  Validation loss = 5.0805  \n",
      "\n",
      "Fold: 12  Epoch: 198  Training loss = 4.1460  Validation loss = 5.0799  \n",
      "\n",
      "Fold: 12  Epoch: 199  Training loss = 4.1457  Validation loss = 5.0794  \n",
      "\n",
      "Fold: 12  Epoch: 200  Training loss = 4.1453  Validation loss = 5.0789  \n",
      "\n",
      "Fold: 12  Epoch: 201  Training loss = 4.1450  Validation loss = 5.0784  \n",
      "\n",
      "Fold: 12  Epoch: 202  Training loss = 4.1448  Validation loss = 5.0780  \n",
      "\n",
      "Fold: 12  Epoch: 203  Training loss = 4.1444  Validation loss = 5.0774  \n",
      "\n",
      "Fold: 12  Epoch: 204  Training loss = 4.1441  Validation loss = 5.0770  \n",
      "\n",
      "Fold: 12  Epoch: 205  Training loss = 4.1438  Validation loss = 5.0765  \n",
      "\n",
      "Fold: 12  Epoch: 206  Training loss = 4.1435  Validation loss = 5.0760  \n",
      "\n",
      "Fold: 12  Epoch: 207  Training loss = 4.1433  Validation loss = 5.0756  \n",
      "\n",
      "Fold: 12  Epoch: 208  Training loss = 4.1430  Validation loss = 5.0751  \n",
      "\n",
      "Fold: 12  Epoch: 209  Training loss = 4.1427  Validation loss = 5.0746  \n",
      "\n",
      "Fold: 12  Epoch: 210  Training loss = 4.1423  Validation loss = 5.0741  \n",
      "\n",
      "Fold: 12  Epoch: 211  Training loss = 4.1420  Validation loss = 5.0737  \n",
      "\n",
      "Fold: 12  Epoch: 212  Training loss = 4.1417  Validation loss = 5.0732  \n",
      "\n",
      "Fold: 12  Epoch: 213  Training loss = 4.1415  Validation loss = 5.0728  \n",
      "\n",
      "Fold: 12  Epoch: 214  Training loss = 4.1412  Validation loss = 5.0723  \n",
      "\n",
      "Fold: 12  Epoch: 215  Training loss = 4.1409  Validation loss = 5.0719  \n",
      "\n",
      "Fold: 12  Epoch: 216  Training loss = 4.1406  Validation loss = 5.0714  \n",
      "\n",
      "Fold: 12  Epoch: 217  Training loss = 4.1403  Validation loss = 5.0709  \n",
      "\n",
      "Fold: 12  Epoch: 218  Training loss = 4.1400  Validation loss = 5.0705  \n",
      "\n",
      "Fold: 12  Epoch: 219  Training loss = 4.1397  Validation loss = 5.0700  \n",
      "\n",
      "Fold: 12  Epoch: 220  Training loss = 4.1395  Validation loss = 5.0696  \n",
      "\n",
      "Fold: 12  Epoch: 221  Training loss = 4.1392  Validation loss = 5.0692  \n",
      "\n",
      "Fold: 12  Epoch: 222  Training loss = 4.1389  Validation loss = 5.0688  \n",
      "\n",
      "Fold: 12  Epoch: 223  Training loss = 4.1386  Validation loss = 5.0682  \n",
      "\n",
      "Fold: 12  Epoch: 224  Training loss = 4.1383  Validation loss = 5.0678  \n",
      "\n",
      "Fold: 12  Epoch: 225  Training loss = 4.1380  Validation loss = 5.0673  \n",
      "\n",
      "Fold: 12  Epoch: 226  Training loss = 4.1377  Validation loss = 5.0669  \n",
      "\n",
      "Fold: 12  Epoch: 227  Training loss = 4.1374  Validation loss = 5.0664  \n",
      "\n",
      "Fold: 12  Epoch: 228  Training loss = 4.1372  Validation loss = 5.0660  \n",
      "\n",
      "Fold: 12  Epoch: 229  Training loss = 4.1368  Validation loss = 5.0655  \n",
      "\n",
      "Fold: 12  Epoch: 230  Training loss = 4.1364  Validation loss = 5.0648  \n",
      "\n",
      "Fold: 12  Epoch: 231  Training loss = 4.1361  Validation loss = 5.0644  \n",
      "\n",
      "Fold: 12  Epoch: 232  Training loss = 4.1358  Validation loss = 5.0639  \n",
      "\n",
      "Fold: 12  Epoch: 233  Training loss = 4.1356  Validation loss = 5.0635  \n",
      "\n",
      "Fold: 12  Epoch: 234  Training loss = 4.1353  Validation loss = 5.0631  \n",
      "\n",
      "Fold: 12  Epoch: 235  Training loss = 4.1349  Validation loss = 5.0626  \n",
      "\n",
      "Fold: 12  Epoch: 236  Training loss = 4.1347  Validation loss = 5.0621  \n",
      "\n",
      "Fold: 12  Epoch: 237  Training loss = 4.1344  Validation loss = 5.0617  \n",
      "\n",
      "Fold: 12  Epoch: 238  Training loss = 4.1341  Validation loss = 5.0611  \n",
      "\n",
      "Fold: 12  Epoch: 239  Training loss = 4.1338  Validation loss = 5.0607  \n",
      "\n",
      "Fold: 12  Epoch: 240  Training loss = 4.1335  Validation loss = 5.0602  \n",
      "\n",
      "Fold: 12  Epoch: 241  Training loss = 4.1331  Validation loss = 5.0596  \n",
      "\n",
      "Fold: 12  Epoch: 242  Training loss = 4.1328  Validation loss = 5.0591  \n",
      "\n",
      "Fold: 12  Epoch: 243  Training loss = 4.1325  Validation loss = 5.0587  \n",
      "\n",
      "Fold: 12  Epoch: 244  Training loss = 4.1322  Validation loss = 5.0582  \n",
      "\n",
      "Fold: 12  Epoch: 245  Training loss = 4.1319  Validation loss = 5.0577  \n",
      "\n",
      "Fold: 12  Epoch: 246  Training loss = 4.1316  Validation loss = 5.0573  \n",
      "\n",
      "Fold: 12  Epoch: 247  Training loss = 4.1314  Validation loss = 5.0569  \n",
      "\n",
      "Fold: 12  Epoch: 248  Training loss = 4.1310  Validation loss = 5.0563  \n",
      "\n",
      "Fold: 12  Epoch: 249  Training loss = 4.1308  Validation loss = 5.0559  \n",
      "\n",
      "Fold: 12  Epoch: 250  Training loss = 4.1304  Validation loss = 5.0554  \n",
      "\n",
      "Fold: 12  Epoch: 251  Training loss = 4.1302  Validation loss = 5.0549  \n",
      "\n",
      "Fold: 12  Epoch: 252  Training loss = 4.1298  Validation loss = 5.0544  \n",
      "\n",
      "Fold: 12  Epoch: 253  Training loss = 4.1295  Validation loss = 5.0539  \n",
      "\n",
      "Fold: 12  Epoch: 254  Training loss = 4.1293  Validation loss = 5.0535  \n",
      "\n",
      "Fold: 12  Epoch: 255  Training loss = 4.1290  Validation loss = 5.0531  \n",
      "\n",
      "Fold: 12  Epoch: 256  Training loss = 4.1287  Validation loss = 5.0526  \n",
      "\n",
      "Fold: 12  Epoch: 257  Training loss = 4.1283  Validation loss = 5.0521  \n",
      "\n",
      "Fold: 12  Epoch: 258  Training loss = 4.1280  Validation loss = 5.0516  \n",
      "\n",
      "Fold: 12  Epoch: 259  Training loss = 4.1278  Validation loss = 5.0512  \n",
      "\n",
      "Fold: 12  Epoch: 260  Training loss = 4.1275  Validation loss = 5.0508  \n",
      "\n",
      "Fold: 12  Epoch: 261  Training loss = 4.1272  Validation loss = 5.0503  \n",
      "\n",
      "Fold: 12  Epoch: 262  Training loss = 4.1269  Validation loss = 5.0498  \n",
      "\n",
      "Fold: 12  Epoch: 263  Training loss = 4.1266  Validation loss = 5.0493  \n",
      "\n",
      "Fold: 12  Epoch: 264  Training loss = 4.1263  Validation loss = 5.0488  \n",
      "\n",
      "Fold: 12  Epoch: 265  Training loss = 4.1260  Validation loss = 5.0484  \n",
      "\n",
      "Fold: 12  Epoch: 266  Training loss = 4.1256  Validation loss = 5.0478  \n",
      "\n",
      "Fold: 12  Epoch: 267  Training loss = 4.1253  Validation loss = 5.0473  \n",
      "\n",
      "Fold: 12  Epoch: 268  Training loss = 4.1251  Validation loss = 5.0469  \n",
      "\n",
      "Fold: 12  Epoch: 269  Training loss = 4.1247  Validation loss = 5.0464  \n",
      "\n",
      "Fold: 12  Epoch: 270  Training loss = 4.1245  Validation loss = 5.0460  \n",
      "\n",
      "Fold: 12  Epoch: 271  Training loss = 4.1242  Validation loss = 5.0455  \n",
      "\n",
      "Fold: 12  Epoch: 272  Training loss = 4.1238  Validation loss = 5.0449  \n",
      "\n",
      "Fold: 12  Epoch: 273  Training loss = 4.1235  Validation loss = 5.0445  \n",
      "\n",
      "Fold: 12  Epoch: 274  Training loss = 4.1231  Validation loss = 5.0439  \n",
      "\n",
      "Fold: 12  Epoch: 275  Training loss = 4.1229  Validation loss = 5.0435  \n",
      "\n",
      "Fold: 12  Epoch: 276  Training loss = 4.1227  Validation loss = 5.0431  \n",
      "\n",
      "Fold: 12  Epoch: 277  Training loss = 4.1223  Validation loss = 5.0426  \n",
      "\n",
      "Fold: 12  Epoch: 278  Training loss = 4.1221  Validation loss = 5.0422  \n",
      "\n",
      "Fold: 12  Epoch: 279  Training loss = 4.1218  Validation loss = 5.0417  \n",
      "\n",
      "Fold: 12  Epoch: 280  Training loss = 4.1215  Validation loss = 5.0413  \n",
      "\n",
      "Fold: 12  Epoch: 281  Training loss = 4.1213  Validation loss = 5.0409  \n",
      "\n",
      "Fold: 12  Epoch: 282  Training loss = 4.1209  Validation loss = 5.0404  \n",
      "\n",
      "Fold: 12  Epoch: 283  Training loss = 4.1206  Validation loss = 5.0399  \n",
      "\n",
      "Fold: 12  Epoch: 284  Training loss = 4.1203  Validation loss = 5.0394  \n",
      "\n",
      "Fold: 12  Epoch: 285  Training loss = 4.1200  Validation loss = 5.0389  \n",
      "\n",
      "Fold: 12  Epoch: 286  Training loss = 4.1197  Validation loss = 5.0385  \n",
      "\n",
      "Fold: 12  Epoch: 287  Training loss = 4.1195  Validation loss = 5.0381  \n",
      "\n",
      "Fold: 12  Epoch: 288  Training loss = 4.1191  Validation loss = 5.0376  \n",
      "\n",
      "Fold: 12  Epoch: 289  Training loss = 4.1188  Validation loss = 5.0370  \n",
      "\n",
      "Fold: 12  Epoch: 290  Training loss = 4.1184  Validation loss = 5.0365  \n",
      "\n",
      "Fold: 12  Epoch: 291  Training loss = 4.1182  Validation loss = 5.0361  \n",
      "\n",
      "Fold: 12  Epoch: 292  Training loss = 4.1179  Validation loss = 5.0356  \n",
      "\n",
      "Fold: 12  Epoch: 293  Training loss = 4.1175  Validation loss = 5.0350  \n",
      "\n",
      "Fold: 12  Epoch: 294  Training loss = 4.1172  Validation loss = 5.0345  \n",
      "\n",
      "Fold: 12  Epoch: 295  Training loss = 4.1168  Validation loss = 5.0339  \n",
      "\n",
      "Fold: 12  Epoch: 296  Training loss = 4.1165  Validation loss = 5.0334  \n",
      "\n",
      "Fold: 12  Epoch: 297  Training loss = 4.1162  Validation loss = 5.0329  \n",
      "\n",
      "Fold: 12  Epoch: 298  Training loss = 4.1159  Validation loss = 5.0324  \n",
      "\n",
      "Fold: 12  Epoch: 299  Training loss = 4.1156  Validation loss = 5.0320  \n",
      "\n",
      "Fold: 12  Epoch: 300  Training loss = 4.1153  Validation loss = 5.0315  \n",
      "\n",
      "Fold: 12  Epoch: 301  Training loss = 4.1150  Validation loss = 5.0310  \n",
      "\n",
      "Fold: 12  Epoch: 302  Training loss = 4.1147  Validation loss = 5.0305  \n",
      "\n",
      "Fold: 12  Epoch: 303  Training loss = 4.1143  Validation loss = 5.0300  \n",
      "\n",
      "Fold: 12  Epoch: 304  Training loss = 4.1140  Validation loss = 5.0294  \n",
      "\n",
      "Fold: 12  Epoch: 305  Training loss = 4.1136  Validation loss = 5.0288  \n",
      "\n",
      "Fold: 12  Epoch: 306  Training loss = 4.1134  Validation loss = 5.0284  \n",
      "\n",
      "Fold: 12  Epoch: 307  Training loss = 4.1130  Validation loss = 5.0279  \n",
      "\n",
      "Fold: 12  Epoch: 308  Training loss = 4.1128  Validation loss = 5.0275  \n",
      "\n",
      "Fold: 12  Epoch: 309  Training loss = 4.1125  Validation loss = 5.0270  \n",
      "\n",
      "Fold: 12  Epoch: 310  Training loss = 4.1122  Validation loss = 5.0266  \n",
      "\n",
      "Fold: 12  Epoch: 311  Training loss = 4.1119  Validation loss = 5.0261  \n",
      "\n",
      "Fold: 12  Epoch: 312  Training loss = 4.1116  Validation loss = 5.0256  \n",
      "\n",
      "Fold: 12  Epoch: 313  Training loss = 4.1113  Validation loss = 5.0251  \n",
      "\n",
      "Fold: 12  Epoch: 314  Training loss = 4.1110  Validation loss = 5.0247  \n",
      "\n",
      "Fold: 12  Epoch: 315  Training loss = 4.1106  Validation loss = 5.0242  \n",
      "\n",
      "Fold: 12  Epoch: 316  Training loss = 4.1104  Validation loss = 5.0238  \n",
      "\n",
      "Fold: 12  Epoch: 317  Training loss = 4.1101  Validation loss = 5.0233  \n",
      "\n",
      "Fold: 12  Epoch: 318  Training loss = 4.1097  Validation loss = 5.0227  \n",
      "\n",
      "Fold: 12  Epoch: 319  Training loss = 4.1094  Validation loss = 5.0222  \n",
      "\n",
      "Fold: 12  Epoch: 320  Training loss = 4.1091  Validation loss = 5.0218  \n",
      "\n",
      "Fold: 12  Epoch: 321  Training loss = 4.1088  Validation loss = 5.0213  \n",
      "\n",
      "Fold: 12  Epoch: 322  Training loss = 4.1085  Validation loss = 5.0208  \n",
      "\n",
      "Fold: 12  Epoch: 323  Training loss = 4.1082  Validation loss = 5.0202  \n",
      "\n",
      "Fold: 12  Epoch: 324  Training loss = 4.1079  Validation loss = 5.0199  \n",
      "\n",
      "Fold: 12  Epoch: 325  Training loss = 4.1076  Validation loss = 5.0194  \n",
      "\n",
      "Fold: 12  Epoch: 326  Training loss = 4.1072  Validation loss = 5.0188  \n",
      "\n",
      "Fold: 12  Epoch: 327  Training loss = 4.1069  Validation loss = 5.0183  \n",
      "\n",
      "Fold: 12  Epoch: 328  Training loss = 4.1066  Validation loss = 5.0179  \n",
      "\n",
      "Fold: 12  Epoch: 329  Training loss = 4.1063  Validation loss = 5.0173  \n",
      "\n",
      "Fold: 12  Epoch: 330  Training loss = 4.1059  Validation loss = 5.0168  \n",
      "\n",
      "Fold: 12  Epoch: 331  Training loss = 4.1057  Validation loss = 5.0164  \n",
      "\n",
      "Fold: 12  Epoch: 332  Training loss = 4.1053  Validation loss = 5.0159  \n",
      "\n",
      "Fold: 12  Epoch: 333  Training loss = 4.1050  Validation loss = 5.0154  \n",
      "\n",
      "Fold: 12  Epoch: 334  Training loss = 4.1045  Validation loss = 5.0148  \n",
      "\n",
      "Fold: 12  Epoch: 335  Training loss = 4.1039  Validation loss = 5.0142  \n",
      "\n",
      "Fold: 12  Epoch: 336  Training loss = 4.1031  Validation loss = 5.0137  \n",
      "\n",
      "Fold: 12  Epoch: 337  Training loss = 4.1008  Validation loss = 5.0131  \n",
      "\n",
      "Fold: 12  Epoch: 338  Training loss = 4.0996  Validation loss = 5.0127  \n",
      "\n",
      "Fold: 12  Epoch: 339  Training loss = 4.0971  Validation loss = 5.0119  \n",
      "\n",
      "Fold: 12  Epoch: 340  Training loss = 4.0966  Validation loss = 5.0115  \n",
      "\n",
      "Fold: 12  Epoch: 341  Training loss = 4.0962  Validation loss = 5.0109  \n",
      "\n",
      "Fold: 12  Epoch: 342  Training loss = 4.0958  Validation loss = 5.0104  \n",
      "\n",
      "Fold: 12  Epoch: 343  Training loss = 4.0954  Validation loss = 5.0099  \n",
      "\n",
      "Fold: 12  Epoch: 344  Training loss = 4.0951  Validation loss = 5.0094  \n",
      "\n",
      "Fold: 12  Epoch: 345  Training loss = 4.0947  Validation loss = 5.0089  \n",
      "\n",
      "Fold: 12  Epoch: 346  Training loss = 4.0944  Validation loss = 5.0084  \n",
      "\n",
      "Fold: 12  Epoch: 347  Training loss = 4.0941  Validation loss = 5.0079  \n",
      "\n",
      "Fold: 12  Epoch: 348  Training loss = 4.0938  Validation loss = 5.0075  \n",
      "\n",
      "Fold: 12  Epoch: 349  Training loss = 4.0936  Validation loss = 5.0070  \n",
      "\n",
      "Fold: 12  Epoch: 350  Training loss = 4.0933  Validation loss = 5.0066  \n",
      "\n",
      "Fold: 12  Epoch: 351  Training loss = 4.0929  Validation loss = 5.0061  \n",
      "\n",
      "Fold: 12  Epoch: 352  Training loss = 4.0926  Validation loss = 5.0056  \n",
      "\n",
      "Fold: 12  Epoch: 353  Training loss = 4.0924  Validation loss = 5.0052  \n",
      "\n",
      "Fold: 12  Epoch: 354  Training loss = 4.0921  Validation loss = 5.0047  \n",
      "\n",
      "Fold: 12  Epoch: 355  Training loss = 4.0918  Validation loss = 5.0043  \n",
      "\n",
      "Fold: 12  Epoch: 356  Training loss = 4.0915  Validation loss = 5.0038  \n",
      "\n",
      "Fold: 12  Epoch: 357  Training loss = 4.0912  Validation loss = 5.0033  \n",
      "\n",
      "Fold: 12  Epoch: 358  Training loss = 4.0909  Validation loss = 5.0028  \n",
      "\n",
      "Fold: 12  Epoch: 359  Training loss = 4.0905  Validation loss = 5.0023  \n",
      "\n",
      "Fold: 12  Epoch: 360  Training loss = 4.0902  Validation loss = 5.0018  \n",
      "\n",
      "Fold: 12  Epoch: 361  Training loss = 4.0899  Validation loss = 5.0013  \n",
      "\n",
      "Fold: 12  Epoch: 362  Training loss = 4.0896  Validation loss = 5.0009  \n",
      "\n",
      "Fold: 12  Epoch: 363  Training loss = 4.0893  Validation loss = 5.0004  \n",
      "\n",
      "Fold: 12  Epoch: 364  Training loss = 4.0890  Validation loss = 4.9999  \n",
      "\n",
      "Fold: 12  Epoch: 365  Training loss = 4.0887  Validation loss = 4.9995  \n",
      "\n",
      "Fold: 12  Epoch: 366  Training loss = 4.0885  Validation loss = 4.9990  \n",
      "\n",
      "Fold: 12  Epoch: 367  Training loss = 4.0881  Validation loss = 4.9985  \n",
      "\n",
      "Fold: 12  Epoch: 368  Training loss = 4.0879  Validation loss = 4.9981  \n",
      "\n",
      "Fold: 12  Epoch: 369  Training loss = 4.0876  Validation loss = 4.9976  \n",
      "\n",
      "Fold: 12  Epoch: 370  Training loss = 4.0872  Validation loss = 4.9971  \n",
      "\n",
      "Fold: 12  Epoch: 371  Training loss = 4.0869  Validation loss = 4.9966  \n",
      "\n",
      "Fold: 12  Epoch: 372  Training loss = 4.0867  Validation loss = 4.9962  \n",
      "\n",
      "Fold: 12  Epoch: 373  Training loss = 4.0864  Validation loss = 4.9958  \n",
      "\n",
      "Fold: 12  Epoch: 374  Training loss = 4.0861  Validation loss = 4.9953  \n",
      "\n",
      "Fold: 12  Epoch: 375  Training loss = 4.0858  Validation loss = 4.9948  \n",
      "\n",
      "Fold: 12  Epoch: 376  Training loss = 4.0855  Validation loss = 4.9943  \n",
      "\n",
      "Fold: 12  Epoch: 377  Training loss = 4.0852  Validation loss = 4.9938  \n",
      "\n",
      "Fold: 12  Epoch: 378  Training loss = 4.0849  Validation loss = 4.9934  \n",
      "\n",
      "Fold: 12  Epoch: 379  Training loss = 4.0846  Validation loss = 4.9930  \n",
      "\n",
      "Fold: 12  Epoch: 380  Training loss = 4.0843  Validation loss = 4.9925  \n",
      "\n",
      "Fold: 12  Epoch: 381  Training loss = 4.0840  Validation loss = 4.9920  \n",
      "\n",
      "Fold: 12  Epoch: 382  Training loss = 4.0837  Validation loss = 4.9914  \n",
      "\n",
      "Fold: 12  Epoch: 383  Training loss = 4.0834  Validation loss = 4.9910  \n",
      "\n",
      "Fold: 12  Epoch: 384  Training loss = 4.0831  Validation loss = 4.9905  \n",
      "\n",
      "Fold: 12  Epoch: 385  Training loss = 4.0828  Validation loss = 4.9900  \n",
      "\n",
      "Fold: 12  Epoch: 386  Training loss = 4.0824  Validation loss = 4.9895  \n",
      "\n",
      "Fold: 12  Epoch: 387  Training loss = 4.0822  Validation loss = 4.9891  \n",
      "\n",
      "Fold: 12  Epoch: 388  Training loss = 4.0819  Validation loss = 4.9887  \n",
      "\n",
      "Fold: 12  Epoch: 389  Training loss = 4.0816  Validation loss = 4.9882  \n",
      "\n",
      "Fold: 12  Epoch: 390  Training loss = 4.0813  Validation loss = 4.9877  \n",
      "\n",
      "Fold: 12  Epoch: 391  Training loss = 4.0810  Validation loss = 4.9872  \n",
      "\n",
      "Fold: 12  Epoch: 392  Training loss = 4.0807  Validation loss = 4.9867  \n",
      "\n",
      "Fold: 12  Epoch: 393  Training loss = 4.0804  Validation loss = 4.9863  \n",
      "\n",
      "Fold: 12  Epoch: 394  Training loss = 4.0801  Validation loss = 4.9858  \n",
      "\n",
      "Fold: 12  Epoch: 395  Training loss = 4.0798  Validation loss = 4.9853  \n",
      "\n",
      "Fold: 12  Epoch: 396  Training loss = 4.0795  Validation loss = 4.9848  \n",
      "\n",
      "Fold: 12  Epoch: 397  Training loss = 4.0792  Validation loss = 4.9844  \n",
      "\n",
      "Fold: 12  Epoch: 398  Training loss = 4.0789  Validation loss = 4.9839  \n",
      "\n",
      "Fold: 12  Epoch: 399  Training loss = 4.0785  Validation loss = 4.9833  \n",
      "\n",
      "Fold: 12  Epoch: 400  Training loss = 4.0782  Validation loss = 4.9828  \n",
      "\n",
      "Fold: 12  Epoch: 401  Training loss = 4.0779  Validation loss = 4.9823  \n",
      "\n",
      "Fold: 12  Epoch: 402  Training loss = 4.0775  Validation loss = 4.9817  \n",
      "\n",
      "Fold: 12  Epoch: 403  Training loss = 4.0772  Validation loss = 4.9812  \n",
      "\n",
      "Fold: 12  Epoch: 404  Training loss = 4.0770  Validation loss = 4.9808  \n",
      "\n",
      "Fold: 12  Epoch: 405  Training loss = 4.0766  Validation loss = 4.9803  \n",
      "\n",
      "Fold: 12  Epoch: 406  Training loss = 4.0764  Validation loss = 4.9799  \n",
      "\n",
      "Fold: 12  Epoch: 407  Training loss = 4.0761  Validation loss = 4.9795  \n",
      "\n",
      "Fold: 12  Epoch: 408  Training loss = 4.0758  Validation loss = 4.9790  \n",
      "\n",
      "Fold: 12  Epoch: 409  Training loss = 4.0755  Validation loss = 4.9785  \n",
      "\n",
      "Fold: 12  Epoch: 410  Training loss = 4.0752  Validation loss = 4.9780  \n",
      "\n",
      "Fold: 12  Epoch: 411  Training loss = 4.0749  Validation loss = 4.9775  \n",
      "\n",
      "Fold: 12  Epoch: 412  Training loss = 4.0746  Validation loss = 4.9771  \n",
      "\n",
      "Fold: 12  Epoch: 413  Training loss = 4.0743  Validation loss = 4.9766  \n",
      "\n",
      "Fold: 12  Epoch: 414  Training loss = 4.0740  Validation loss = 4.9761  \n",
      "\n",
      "Fold: 12  Epoch: 415  Training loss = 4.0738  Validation loss = 4.9757  \n",
      "\n",
      "Fold: 12  Epoch: 416  Training loss = 4.0735  Validation loss = 4.9753  \n",
      "\n",
      "Fold: 12  Epoch: 417  Training loss = 4.0733  Validation loss = 4.9749  \n",
      "\n",
      "Fold: 12  Epoch: 418  Training loss = 4.0729  Validation loss = 4.9744  \n",
      "\n",
      "Fold: 12  Epoch: 419  Training loss = 4.0725  Validation loss = 4.9738  \n",
      "\n",
      "Fold: 12  Epoch: 420  Training loss = 4.0722  Validation loss = 4.9733  \n",
      "\n",
      "Fold: 12  Epoch: 421  Training loss = 4.0720  Validation loss = 4.9729  \n",
      "\n",
      "Fold: 12  Epoch: 422  Training loss = 4.0717  Validation loss = 4.9725  \n",
      "\n",
      "Fold: 12  Epoch: 423  Training loss = 4.0714  Validation loss = 4.9720  \n",
      "\n",
      "Fold: 12  Epoch: 424  Training loss = 4.0710  Validation loss = 4.9714  \n",
      "\n",
      "Fold: 12  Epoch: 425  Training loss = 4.0708  Validation loss = 4.9710  \n",
      "\n",
      "Fold: 12  Epoch: 426  Training loss = 4.0705  Validation loss = 4.9706  \n",
      "\n",
      "Fold: 12  Epoch: 427  Training loss = 4.0703  Validation loss = 4.9702  \n",
      "\n",
      "Fold: 12  Epoch: 428  Training loss = 4.0700  Validation loss = 4.9698  \n",
      "\n",
      "Fold: 12  Epoch: 429  Training loss = 4.0698  Validation loss = 4.9694  \n",
      "\n",
      "Fold: 12  Epoch: 430  Training loss = 4.0694  Validation loss = 4.9689  \n",
      "\n",
      "Fold: 12  Epoch: 431  Training loss = 4.0691  Validation loss = 4.9683  \n",
      "\n",
      "Fold: 12  Epoch: 432  Training loss = 4.0688  Validation loss = 4.9679  \n",
      "\n",
      "Fold: 12  Epoch: 433  Training loss = 4.0685  Validation loss = 4.9675  \n",
      "\n",
      "Fold: 12  Epoch: 434  Training loss = 4.0683  Validation loss = 4.9671  \n",
      "\n",
      "Fold: 12  Epoch: 435  Training loss = 4.0679  Validation loss = 4.9665  \n",
      "\n",
      "Fold: 12  Epoch: 436  Training loss = 4.0676  Validation loss = 4.9660  \n",
      "\n",
      "Fold: 12  Epoch: 437  Training loss = 4.0672  Validation loss = 4.9654  \n",
      "\n",
      "Fold: 12  Epoch: 438  Training loss = 4.0669  Validation loss = 4.9648  \n",
      "\n",
      "Fold: 12  Epoch: 439  Training loss = 4.0665  Validation loss = 4.9642  \n",
      "\n",
      "Fold: 12  Epoch: 440  Training loss = 4.0662  Validation loss = 4.9638  \n",
      "\n",
      "Fold: 12  Epoch: 441  Training loss = 4.0659  Validation loss = 4.9634  \n",
      "\n",
      "Fold: 12  Epoch: 442  Training loss = 4.0656  Validation loss = 4.9628  \n",
      "\n",
      "Fold: 12  Epoch: 443  Training loss = 4.0653  Validation loss = 4.9624  \n",
      "\n",
      "Fold: 12  Epoch: 444  Training loss = 4.0650  Validation loss = 4.9619  \n",
      "\n",
      "Fold: 12  Epoch: 445  Training loss = 4.0647  Validation loss = 4.9614  \n",
      "\n",
      "Fold: 12  Epoch: 446  Training loss = 4.0645  Validation loss = 4.9610  \n",
      "\n",
      "Fold: 12  Epoch: 447  Training loss = 4.0641  Validation loss = 4.9603  \n",
      "\n",
      "Fold: 12  Epoch: 448  Training loss = 4.0638  Validation loss = 4.9599  \n",
      "\n",
      "Fold: 12  Epoch: 449  Training loss = 4.0635  Validation loss = 4.9594  \n",
      "\n",
      "Fold: 12  Epoch: 450  Training loss = 4.0632  Validation loss = 4.9590  \n",
      "\n",
      "Fold: 12  Epoch: 451  Training loss = 4.0629  Validation loss = 4.9585  \n",
      "\n",
      "Fold: 12  Epoch: 452  Training loss = 4.0625  Validation loss = 4.9579  \n",
      "\n",
      "Fold: 12  Epoch: 453  Training loss = 4.0622  Validation loss = 4.9574  \n",
      "\n",
      "Fold: 12  Epoch: 454  Training loss = 4.0619  Validation loss = 4.9569  \n",
      "\n",
      "Fold: 12  Epoch: 455  Training loss = 4.0616  Validation loss = 4.9564  \n",
      "\n",
      "Fold: 12  Epoch: 456  Training loss = 4.0613  Validation loss = 4.9559  \n",
      "\n",
      "Fold: 12  Epoch: 457  Training loss = 4.0609  Validation loss = 4.9554  \n",
      "\n",
      "Fold: 12  Epoch: 458  Training loss = 4.0607  Validation loss = 4.9549  \n",
      "\n",
      "Fold: 12  Epoch: 459  Training loss = 4.0604  Validation loss = 4.9545  \n",
      "\n",
      "Fold: 12  Epoch: 460  Training loss = 4.0601  Validation loss = 4.9540  \n",
      "\n",
      "Fold: 12  Epoch: 461  Training loss = 4.0598  Validation loss = 4.9536  \n",
      "\n",
      "Fold: 12  Epoch: 462  Training loss = 4.0594  Validation loss = 4.9530  \n",
      "\n",
      "Fold: 12  Epoch: 463  Training loss = 4.0591  Validation loss = 4.9525  \n",
      "\n",
      "Fold: 12  Epoch: 464  Training loss = 4.0589  Validation loss = 4.9521  \n",
      "\n",
      "Fold: 12  Epoch: 465  Training loss = 4.0585  Validation loss = 4.9515  \n",
      "\n",
      "Fold: 12  Epoch: 466  Training loss = 4.0583  Validation loss = 4.9512  \n",
      "\n",
      "Fold: 12  Epoch: 467  Training loss = 4.0580  Validation loss = 4.9507  \n",
      "\n",
      "Fold: 12  Epoch: 468  Training loss = 4.0577  Validation loss = 4.9502  \n",
      "\n",
      "Fold: 12  Epoch: 469  Training loss = 4.0574  Validation loss = 4.9497  \n",
      "\n",
      "Fold: 12  Epoch: 470  Training loss = 4.0571  Validation loss = 4.9492  \n",
      "\n",
      "Fold: 12  Epoch: 471  Training loss = 4.0568  Validation loss = 4.9488  \n",
      "\n",
      "Fold: 12  Epoch: 472  Training loss = 4.0564  Validation loss = 4.9482  \n",
      "\n",
      "Fold: 12  Epoch: 473  Training loss = 4.0561  Validation loss = 4.9477  \n",
      "\n",
      "Fold: 12  Epoch: 474  Training loss = 4.0558  Validation loss = 4.9471  \n",
      "\n",
      "Fold: 12  Epoch: 475  Training loss = 4.0555  Validation loss = 4.9467  \n",
      "\n",
      "Fold: 12  Epoch: 476  Training loss = 4.0552  Validation loss = 4.9462  \n",
      "\n",
      "Fold: 12  Epoch: 477  Training loss = 4.0549  Validation loss = 4.9457  \n",
      "\n",
      "Fold: 12  Epoch: 478  Training loss = 4.0546  Validation loss = 4.9452  \n",
      "\n",
      "Fold: 12  Epoch: 479  Training loss = 4.0543  Validation loss = 4.9448  \n",
      "\n",
      "Fold: 12  Epoch: 480  Training loss = 4.0541  Validation loss = 4.9444  \n",
      "\n",
      "Fold: 12  Epoch: 481  Training loss = 4.0538  Validation loss = 4.9439  \n",
      "\n",
      "Fold: 12  Epoch: 482  Training loss = 4.0534  Validation loss = 4.9434  \n",
      "\n",
      "Fold: 12  Epoch: 483  Training loss = 4.0531  Validation loss = 4.9428  \n",
      "\n",
      "Fold: 12  Epoch: 484  Training loss = 4.0528  Validation loss = 4.9423  \n",
      "\n",
      "Fold: 12  Epoch: 485  Training loss = 4.0525  Validation loss = 4.9419  \n",
      "\n",
      "Fold: 12  Epoch: 486  Training loss = 4.0522  Validation loss = 4.9414  \n",
      "\n",
      "Fold: 12  Epoch: 487  Training loss = 4.0519  Validation loss = 4.9409  \n",
      "\n",
      "Fold: 12  Epoch: 488  Training loss = 4.0516  Validation loss = 4.9404  \n",
      "\n",
      "Fold: 12  Epoch: 489  Training loss = 4.0514  Validation loss = 4.9400  \n",
      "\n",
      "Fold: 12  Epoch: 490  Training loss = 4.0510  Validation loss = 4.9396  \n",
      "\n",
      "Fold: 12  Epoch: 491  Training loss = 4.0507  Validation loss = 4.9390  \n",
      "\n",
      "Fold: 12  Epoch: 492  Training loss = 4.0505  Validation loss = 4.9386  \n",
      "\n",
      "Fold: 12  Epoch: 493  Training loss = 4.0502  Validation loss = 4.9382  \n",
      "\n",
      "Fold: 12  Epoch: 494  Training loss = 4.0498  Validation loss = 4.9376  \n",
      "\n",
      "Fold: 12  Epoch: 495  Training loss = 4.0496  Validation loss = 4.9372  \n",
      "\n",
      "Fold: 12  Epoch: 496  Training loss = 4.0493  Validation loss = 4.9368  \n",
      "\n",
      "Fold: 12  Epoch: 497  Training loss = 4.0490  Validation loss = 4.9363  \n",
      "\n",
      "Fold: 12  Epoch: 498  Training loss = 4.0487  Validation loss = 4.9359  \n",
      "\n",
      "Fold: 12  Epoch: 499  Training loss = 4.0484  Validation loss = 4.9353  \n",
      "\n",
      "Fold: 12  Epoch: 500  Training loss = 4.0481  Validation loss = 4.9348  \n",
      "\n",
      "Check model:  Fold: 12  Optimal epoch: 500  \n",
      "\n",
      "Fold: 13  Epoch: 1  Training loss = 4.2162  Validation loss = 7.4528  \n",
      "\n",
      "Fold: 13  Epoch: 2  Training loss = 4.2158  Validation loss = 7.4523  \n",
      "\n",
      "Fold: 13  Epoch: 3  Training loss = 4.2155  Validation loss = 7.4517  \n",
      "\n",
      "Fold: 13  Epoch: 4  Training loss = 4.2151  Validation loss = 7.4511  \n",
      "\n",
      "Fold: 13  Epoch: 5  Training loss = 4.2147  Validation loss = 7.4505  \n",
      "\n",
      "Fold: 13  Epoch: 6  Training loss = 4.2144  Validation loss = 7.4500  \n",
      "\n",
      "Fold: 13  Epoch: 7  Training loss = 4.2140  Validation loss = 7.4493  \n",
      "\n",
      "Fold: 13  Epoch: 8  Training loss = 4.2136  Validation loss = 7.4487  \n",
      "\n",
      "Fold: 13  Epoch: 9  Training loss = 4.2133  Validation loss = 7.4482  \n",
      "\n",
      "Fold: 13  Epoch: 10  Training loss = 4.2130  Validation loss = 7.4477  \n",
      "\n",
      "Fold: 13  Epoch: 11  Training loss = 4.2126  Validation loss = 7.4471  \n",
      "\n",
      "Fold: 13  Epoch: 12  Training loss = 4.2122  Validation loss = 7.4465  \n",
      "\n",
      "Fold: 13  Epoch: 13  Training loss = 4.2119  Validation loss = 7.4460  \n",
      "\n",
      "Fold: 13  Epoch: 14  Training loss = 4.2114  Validation loss = 7.4453  \n",
      "\n",
      "Fold: 13  Epoch: 15  Training loss = 4.2110  Validation loss = 7.4447  \n",
      "\n",
      "Fold: 13  Epoch: 16  Training loss = 4.2106  Validation loss = 7.4440  \n",
      "\n",
      "Fold: 13  Epoch: 17  Training loss = 4.2102  Validation loss = 7.4435  \n",
      "\n",
      "Fold: 13  Epoch: 18  Training loss = 4.2098  Validation loss = 7.4429  \n",
      "\n",
      "Fold: 13  Epoch: 19  Training loss = 4.2094  Validation loss = 7.4422  \n",
      "\n",
      "Fold: 13  Epoch: 20  Training loss = 4.2090  Validation loss = 7.4416  \n",
      "\n",
      "Fold: 13  Epoch: 21  Training loss = 4.2087  Validation loss = 7.4412  \n",
      "\n",
      "Fold: 13  Epoch: 22  Training loss = 4.2084  Validation loss = 7.4406  \n",
      "\n",
      "Fold: 13  Epoch: 23  Training loss = 4.2080  Validation loss = 7.4401  \n",
      "\n",
      "Fold: 13  Epoch: 24  Training loss = 4.2077  Validation loss = 7.4395  \n",
      "\n",
      "Fold: 13  Epoch: 25  Training loss = 4.2074  Validation loss = 7.4390  \n",
      "\n",
      "Fold: 13  Epoch: 26  Training loss = 4.2071  Validation loss = 7.4386  \n",
      "\n",
      "Fold: 13  Epoch: 27  Training loss = 4.2067  Validation loss = 7.4379  \n",
      "\n",
      "Fold: 13  Epoch: 28  Training loss = 4.2063  Validation loss = 7.4373  \n",
      "\n",
      "Fold: 13  Epoch: 29  Training loss = 4.2060  Validation loss = 7.4368  \n",
      "\n",
      "Fold: 13  Epoch: 30  Training loss = 4.2055  Validation loss = 7.4363  \n",
      "\n",
      "Fold: 13  Epoch: 31  Training loss = 4.2052  Validation loss = 7.4357  \n",
      "\n",
      "Fold: 13  Epoch: 32  Training loss = 4.2048  Validation loss = 7.4352  \n",
      "\n",
      "Fold: 13  Epoch: 33  Training loss = 4.2044  Validation loss = 7.4345  \n",
      "\n",
      "Fold: 13  Epoch: 34  Training loss = 4.2040  Validation loss = 7.4338  \n",
      "\n",
      "Fold: 13  Epoch: 35  Training loss = 4.2037  Validation loss = 7.4333  \n",
      "\n",
      "Fold: 13  Epoch: 36  Training loss = 4.2033  Validation loss = 7.4328  \n",
      "\n",
      "Fold: 13  Epoch: 37  Training loss = 4.2029  Validation loss = 7.4321  \n",
      "\n",
      "Fold: 13  Epoch: 38  Training loss = 4.2025  Validation loss = 7.4315  \n",
      "\n",
      "Fold: 13  Epoch: 39  Training loss = 4.2021  Validation loss = 7.4309  \n",
      "\n",
      "Fold: 13  Epoch: 40  Training loss = 4.2017  Validation loss = 7.4303  \n",
      "\n",
      "Fold: 13  Epoch: 41  Training loss = 4.2013  Validation loss = 7.4297  \n",
      "\n",
      "Fold: 13  Epoch: 42  Training loss = 4.2009  Validation loss = 7.4290  \n",
      "\n",
      "Fold: 13  Epoch: 43  Training loss = 4.2005  Validation loss = 7.4285  \n",
      "\n",
      "Fold: 13  Epoch: 44  Training loss = 4.2002  Validation loss = 7.4279  \n",
      "\n",
      "Fold: 13  Epoch: 45  Training loss = 4.1998  Validation loss = 7.4273  \n",
      "\n",
      "Fold: 13  Epoch: 46  Training loss = 4.1995  Validation loss = 7.4269  \n",
      "\n",
      "Fold: 13  Epoch: 47  Training loss = 4.1992  Validation loss = 7.4264  \n",
      "\n",
      "Fold: 13  Epoch: 48  Training loss = 4.1989  Validation loss = 7.4258  \n",
      "\n",
      "Fold: 13  Epoch: 49  Training loss = 4.1985  Validation loss = 7.4253  \n",
      "\n",
      "Fold: 13  Epoch: 50  Training loss = 4.1981  Validation loss = 7.4247  \n",
      "\n",
      "Fold: 13  Epoch: 51  Training loss = 4.1977  Validation loss = 7.4241  \n",
      "\n",
      "Fold: 13  Epoch: 52  Training loss = 4.1973  Validation loss = 7.4235  \n",
      "\n",
      "Fold: 13  Epoch: 53  Training loss = 4.1970  Validation loss = 7.4230  \n",
      "\n",
      "Fold: 13  Epoch: 54  Training loss = 4.1967  Validation loss = 7.4225  \n",
      "\n",
      "Fold: 13  Epoch: 55  Training loss = 4.1964  Validation loss = 7.4221  \n",
      "\n",
      "Fold: 13  Epoch: 56  Training loss = 4.1961  Validation loss = 7.4216  \n",
      "\n",
      "Fold: 13  Epoch: 57  Training loss = 4.1957  Validation loss = 7.4210  \n",
      "\n",
      "Fold: 13  Epoch: 58  Training loss = 4.1953  Validation loss = 7.4204  \n",
      "\n",
      "Fold: 13  Epoch: 59  Training loss = 4.1949  Validation loss = 7.4198  \n",
      "\n",
      "Fold: 13  Epoch: 60  Training loss = 4.1946  Validation loss = 7.4193  \n",
      "\n",
      "Fold: 13  Epoch: 61  Training loss = 4.1943  Validation loss = 7.4187  \n",
      "\n",
      "Fold: 13  Epoch: 62  Training loss = 4.1938  Validation loss = 7.4181  \n",
      "\n",
      "Fold: 13  Epoch: 63  Training loss = 4.1935  Validation loss = 7.4176  \n",
      "\n",
      "Fold: 13  Epoch: 64  Training loss = 4.1931  Validation loss = 7.4170  \n",
      "\n",
      "Fold: 13  Epoch: 65  Training loss = 4.1927  Validation loss = 7.4164  \n",
      "\n",
      "Fold: 13  Epoch: 66  Training loss = 4.1924  Validation loss = 7.4159  \n",
      "\n",
      "Fold: 13  Epoch: 67  Training loss = 4.1920  Validation loss = 7.4155  \n",
      "\n",
      "Fold: 13  Epoch: 68  Training loss = 4.1917  Validation loss = 7.4150  \n",
      "\n",
      "Fold: 13  Epoch: 69  Training loss = 4.1913  Validation loss = 7.4143  \n",
      "\n",
      "Fold: 13  Epoch: 70  Training loss = 4.1911  Validation loss = 7.4139  \n",
      "\n",
      "Fold: 13  Epoch: 71  Training loss = 4.1907  Validation loss = 7.4134  \n",
      "\n",
      "Fold: 13  Epoch: 72  Training loss = 4.1904  Validation loss = 7.4128  \n",
      "\n",
      "Fold: 13  Epoch: 73  Training loss = 4.1900  Validation loss = 7.4122  \n",
      "\n",
      "Fold: 13  Epoch: 74  Training loss = 4.1896  Validation loss = 7.4115  \n",
      "\n",
      "Fold: 13  Epoch: 75  Training loss = 4.1892  Validation loss = 7.4110  \n",
      "\n",
      "Fold: 13  Epoch: 76  Training loss = 4.1889  Validation loss = 7.4104  \n",
      "\n",
      "Fold: 13  Epoch: 77  Training loss = 4.1885  Validation loss = 7.4099  \n",
      "\n",
      "Fold: 13  Epoch: 78  Training loss = 4.1881  Validation loss = 7.4093  \n",
      "\n",
      "Fold: 13  Epoch: 79  Training loss = 4.1878  Validation loss = 7.4088  \n",
      "\n",
      "Fold: 13  Epoch: 80  Training loss = 4.1875  Validation loss = 7.4083  \n",
      "\n",
      "Fold: 13  Epoch: 81  Training loss = 4.1871  Validation loss = 7.4078  \n",
      "\n",
      "Fold: 13  Epoch: 82  Training loss = 4.1868  Validation loss = 7.4073  \n",
      "\n",
      "Fold: 13  Epoch: 83  Training loss = 4.1864  Validation loss = 7.4068  \n",
      "\n",
      "Fold: 13  Epoch: 84  Training loss = 4.1860  Validation loss = 7.4061  \n",
      "\n",
      "Fold: 13  Epoch: 85  Training loss = 4.1857  Validation loss = 7.4056  \n",
      "\n",
      "Fold: 13  Epoch: 86  Training loss = 4.1853  Validation loss = 7.4050  \n",
      "\n",
      "Fold: 13  Epoch: 87  Training loss = 4.1849  Validation loss = 7.4044  \n",
      "\n",
      "Fold: 13  Epoch: 88  Training loss = 4.1845  Validation loss = 7.4039  \n",
      "\n",
      "Fold: 13  Epoch: 89  Training loss = 4.1842  Validation loss = 7.4033  \n",
      "\n",
      "Fold: 13  Epoch: 90  Training loss = 4.1838  Validation loss = 7.4027  \n",
      "\n",
      "Fold: 13  Epoch: 91  Training loss = 4.1834  Validation loss = 7.4021  \n",
      "\n",
      "Fold: 13  Epoch: 92  Training loss = 4.1831  Validation loss = 7.4016  \n",
      "\n",
      "Fold: 13  Epoch: 93  Training loss = 4.1827  Validation loss = 7.4010  \n",
      "\n",
      "Fold: 13  Epoch: 94  Training loss = 4.1823  Validation loss = 7.4003  \n",
      "\n",
      "Fold: 13  Epoch: 95  Training loss = 4.1819  Validation loss = 7.3997  \n",
      "\n",
      "Fold: 13  Epoch: 96  Training loss = 4.1815  Validation loss = 7.3991  \n",
      "\n",
      "Fold: 13  Epoch: 97  Training loss = 4.1811  Validation loss = 7.3986  \n",
      "\n",
      "Fold: 13  Epoch: 98  Training loss = 4.1808  Validation loss = 7.3981  \n",
      "\n",
      "Fold: 13  Epoch: 99  Training loss = 4.1804  Validation loss = 7.3975  \n",
      "\n",
      "Fold: 13  Epoch: 100  Training loss = 4.1799  Validation loss = 7.3968  \n",
      "\n",
      "Fold: 13  Epoch: 101  Training loss = 4.1795  Validation loss = 7.3962  \n",
      "\n",
      "Fold: 13  Epoch: 102  Training loss = 4.1792  Validation loss = 7.3956  \n",
      "\n",
      "Fold: 13  Epoch: 103  Training loss = 4.1788  Validation loss = 7.3951  \n",
      "\n",
      "Fold: 13  Epoch: 104  Training loss = 4.1785  Validation loss = 7.3946  \n",
      "\n",
      "Fold: 13  Epoch: 105  Training loss = 4.1781  Validation loss = 7.3939  \n",
      "\n",
      "Fold: 13  Epoch: 106  Training loss = 4.1777  Validation loss = 7.3933  \n",
      "\n",
      "Fold: 13  Epoch: 107  Training loss = 4.1773  Validation loss = 7.3927  \n",
      "\n",
      "Fold: 13  Epoch: 108  Training loss = 4.1770  Validation loss = 7.3922  \n",
      "\n",
      "Fold: 13  Epoch: 109  Training loss = 4.1766  Validation loss = 7.3917  \n",
      "\n",
      "Fold: 13  Epoch: 110  Training loss = 4.1762  Validation loss = 7.3911  \n",
      "\n",
      "Fold: 13  Epoch: 111  Training loss = 4.1758  Validation loss = 7.3904  \n",
      "\n",
      "Fold: 13  Epoch: 112  Training loss = 4.1754  Validation loss = 7.3899  \n",
      "\n",
      "Fold: 13  Epoch: 113  Training loss = 4.1751  Validation loss = 7.3893  \n",
      "\n",
      "Fold: 13  Epoch: 114  Training loss = 4.1747  Validation loss = 7.3888  \n",
      "\n",
      "Fold: 13  Epoch: 115  Training loss = 4.1744  Validation loss = 7.3883  \n",
      "\n",
      "Fold: 13  Epoch: 116  Training loss = 4.1740  Validation loss = 7.3878  \n",
      "\n",
      "Fold: 13  Epoch: 117  Training loss = 4.1737  Validation loss = 7.3872  \n",
      "\n",
      "Fold: 13  Epoch: 118  Training loss = 4.1733  Validation loss = 7.3866  \n",
      "\n",
      "Fold: 13  Epoch: 119  Training loss = 4.1729  Validation loss = 7.3861  \n",
      "\n",
      "Fold: 13  Epoch: 120  Training loss = 4.1725  Validation loss = 7.3856  \n",
      "\n",
      "Fold: 13  Epoch: 121  Training loss = 4.1723  Validation loss = 7.3851  \n",
      "\n",
      "Fold: 13  Epoch: 122  Training loss = 4.1719  Validation loss = 7.3846  \n",
      "\n",
      "Fold: 13  Epoch: 123  Training loss = 4.1716  Validation loss = 7.3842  \n",
      "\n",
      "Fold: 13  Epoch: 124  Training loss = 4.1712  Validation loss = 7.3835  \n",
      "\n",
      "Fold: 13  Epoch: 125  Training loss = 4.1708  Validation loss = 7.3830  \n",
      "\n",
      "Fold: 13  Epoch: 126  Training loss = 4.1705  Validation loss = 7.3825  \n",
      "\n",
      "Fold: 13  Epoch: 127  Training loss = 4.1702  Validation loss = 7.3820  \n",
      "\n",
      "Fold: 13  Epoch: 128  Training loss = 4.1698  Validation loss = 7.3815  \n",
      "\n",
      "Fold: 13  Epoch: 129  Training loss = 4.1694  Validation loss = 7.3809  \n",
      "\n",
      "Fold: 13  Epoch: 130  Training loss = 4.1690  Validation loss = 7.3803  \n",
      "\n",
      "Fold: 13  Epoch: 131  Training loss = 4.1686  Validation loss = 7.3795  \n",
      "\n",
      "Fold: 13  Epoch: 132  Training loss = 4.1683  Validation loss = 7.3791  \n",
      "\n",
      "Fold: 13  Epoch: 133  Training loss = 4.1679  Validation loss = 7.3784  \n",
      "\n",
      "Fold: 13  Epoch: 134  Training loss = 4.1676  Validation loss = 7.3779  \n",
      "\n",
      "Fold: 13  Epoch: 135  Training loss = 4.1672  Validation loss = 7.3772  \n",
      "\n",
      "Fold: 13  Epoch: 136  Training loss = 4.1668  Validation loss = 7.3766  \n",
      "\n",
      "Fold: 13  Epoch: 137  Training loss = 4.1664  Validation loss = 7.3760  \n",
      "\n",
      "Fold: 13  Epoch: 138  Training loss = 4.1661  Validation loss = 7.3754  \n",
      "\n",
      "Fold: 13  Epoch: 139  Training loss = 4.1657  Validation loss = 7.3748  \n",
      "\n",
      "Fold: 13  Epoch: 140  Training loss = 4.1653  Validation loss = 7.3742  \n",
      "\n",
      "Fold: 13  Epoch: 141  Training loss = 4.1650  Validation loss = 7.3736  \n",
      "\n",
      "Fold: 13  Epoch: 142  Training loss = 4.1646  Validation loss = 7.3731  \n",
      "\n",
      "Fold: 13  Epoch: 143  Training loss = 4.1642  Validation loss = 7.3725  \n",
      "\n",
      "Fold: 13  Epoch: 144  Training loss = 4.1638  Validation loss = 7.3720  \n",
      "\n",
      "Fold: 13  Epoch: 145  Training loss = 4.1635  Validation loss = 7.3714  \n",
      "\n",
      "Fold: 13  Epoch: 146  Training loss = 4.1631  Validation loss = 7.3707  \n",
      "\n",
      "Fold: 13  Epoch: 147  Training loss = 4.1626  Validation loss = 7.3699  \n",
      "\n",
      "Fold: 13  Epoch: 148  Training loss = 4.1621  Validation loss = 7.3692  \n",
      "\n",
      "Fold: 13  Epoch: 149  Training loss = 4.1618  Validation loss = 7.3687  \n",
      "\n",
      "Fold: 13  Epoch: 150  Training loss = 4.1614  Validation loss = 7.3681  \n",
      "\n",
      "Fold: 13  Epoch: 151  Training loss = 4.1611  Validation loss = 7.3676  \n",
      "\n",
      "Fold: 13  Epoch: 152  Training loss = 4.1607  Validation loss = 7.3670  \n",
      "\n",
      "Fold: 13  Epoch: 153  Training loss = 4.1603  Validation loss = 7.3665  \n",
      "\n",
      "Fold: 13  Epoch: 154  Training loss = 4.1598  Validation loss = 7.3658  \n",
      "\n",
      "Fold: 13  Epoch: 155  Training loss = 4.1595  Validation loss = 7.3653  \n",
      "\n",
      "Fold: 13  Epoch: 156  Training loss = 4.1592  Validation loss = 7.3648  \n",
      "\n",
      "Fold: 13  Epoch: 157  Training loss = 4.1588  Validation loss = 7.3642  \n",
      "\n",
      "Fold: 13  Epoch: 158  Training loss = 4.1583  Validation loss = 7.3635  \n",
      "\n",
      "Fold: 13  Epoch: 159  Training loss = 4.1578  Validation loss = 7.3628  \n",
      "\n",
      "Fold: 13  Epoch: 160  Training loss = 4.1570  Validation loss = 7.3619  \n",
      "\n",
      "Fold: 13  Epoch: 161  Training loss = 4.1565  Validation loss = 7.3612  \n",
      "\n",
      "Fold: 13  Epoch: 162  Training loss = 4.1539  Validation loss = 7.3599  \n",
      "\n",
      "Fold: 13  Epoch: 163  Training loss = 4.1498  Validation loss = 7.3581  \n",
      "\n",
      "Fold: 13  Epoch: 164  Training loss = 4.1494  Validation loss = 7.3575  \n",
      "\n",
      "Fold: 13  Epoch: 165  Training loss = 4.1489  Validation loss = 7.3568  \n",
      "\n",
      "Fold: 13  Epoch: 166  Training loss = 4.1485  Validation loss = 7.3563  \n",
      "\n",
      "Fold: 13  Epoch: 167  Training loss = 4.1480  Validation loss = 7.3556  \n",
      "\n",
      "Fold: 13  Epoch: 168  Training loss = 4.1476  Validation loss = 7.3549  \n",
      "\n",
      "Fold: 13  Epoch: 169  Training loss = 4.1471  Validation loss = 7.3542  \n",
      "\n",
      "Fold: 13  Epoch: 170  Training loss = 4.1467  Validation loss = 7.3536  \n",
      "\n",
      "Fold: 13  Epoch: 171  Training loss = 4.1464  Validation loss = 7.3530  \n",
      "\n",
      "Fold: 13  Epoch: 172  Training loss = 4.1460  Validation loss = 7.3524  \n",
      "\n",
      "Fold: 13  Epoch: 173  Training loss = 4.1457  Validation loss = 7.3518  \n",
      "\n",
      "Fold: 13  Epoch: 174  Training loss = 4.1453  Validation loss = 7.3513  \n",
      "\n",
      "Fold: 13  Epoch: 175  Training loss = 4.1449  Validation loss = 7.3507  \n",
      "\n",
      "Fold: 13  Epoch: 176  Training loss = 4.1445  Validation loss = 7.3501  \n",
      "\n",
      "Fold: 13  Epoch: 177  Training loss = 4.1441  Validation loss = 7.3494  \n",
      "\n",
      "Fold: 13  Epoch: 178  Training loss = 4.1437  Validation loss = 7.3488  \n",
      "\n",
      "Fold: 13  Epoch: 179  Training loss = 4.1434  Validation loss = 7.3483  \n",
      "\n",
      "Fold: 13  Epoch: 180  Training loss = 4.1430  Validation loss = 7.3478  \n",
      "\n",
      "Fold: 13  Epoch: 181  Training loss = 4.1427  Validation loss = 7.3474  \n",
      "\n",
      "Fold: 13  Epoch: 182  Training loss = 4.1423  Validation loss = 7.3468  \n",
      "\n",
      "Fold: 13  Epoch: 183  Training loss = 4.1420  Validation loss = 7.3462  \n",
      "\n",
      "Fold: 13  Epoch: 184  Training loss = 4.1417  Validation loss = 7.3458  \n",
      "\n",
      "Fold: 13  Epoch: 185  Training loss = 4.1413  Validation loss = 7.3452  \n",
      "\n",
      "Fold: 13  Epoch: 186  Training loss = 4.1410  Validation loss = 7.3447  \n",
      "\n",
      "Fold: 13  Epoch: 187  Training loss = 4.1406  Validation loss = 7.3441  \n",
      "\n",
      "Fold: 13  Epoch: 188  Training loss = 4.1402  Validation loss = 7.3435  \n",
      "\n",
      "Fold: 13  Epoch: 189  Training loss = 4.1398  Validation loss = 7.3430  \n",
      "\n",
      "Fold: 13  Epoch: 190  Training loss = 4.1395  Validation loss = 7.3425  \n",
      "\n",
      "Fold: 13  Epoch: 191  Training loss = 4.1391  Validation loss = 7.3419  \n",
      "\n",
      "Fold: 13  Epoch: 192  Training loss = 4.1387  Validation loss = 7.3412  \n",
      "\n",
      "Fold: 13  Epoch: 193  Training loss = 4.1384  Validation loss = 7.3407  \n",
      "\n",
      "Fold: 13  Epoch: 194  Training loss = 4.1380  Validation loss = 7.3400  \n",
      "\n",
      "Fold: 13  Epoch: 195  Training loss = 4.1376  Validation loss = 7.3395  \n",
      "\n",
      "Fold: 13  Epoch: 196  Training loss = 4.1373  Validation loss = 7.3389  \n",
      "\n",
      "Fold: 13  Epoch: 197  Training loss = 4.1368  Validation loss = 7.3382  \n",
      "\n",
      "Fold: 13  Epoch: 198  Training loss = 4.1365  Validation loss = 7.3377  \n",
      "\n",
      "Fold: 13  Epoch: 199  Training loss = 4.1361  Validation loss = 7.3371  \n",
      "\n",
      "Fold: 13  Epoch: 200  Training loss = 4.1357  Validation loss = 7.3366  \n",
      "\n",
      "Fold: 13  Epoch: 201  Training loss = 4.1354  Validation loss = 7.3360  \n",
      "\n",
      "Fold: 13  Epoch: 202  Training loss = 4.1350  Validation loss = 7.3354  \n",
      "\n",
      "Fold: 13  Epoch: 203  Training loss = 4.1347  Validation loss = 7.3349  \n",
      "\n",
      "Fold: 13  Epoch: 204  Training loss = 4.1344  Validation loss = 7.3344  \n",
      "\n",
      "Fold: 13  Epoch: 205  Training loss = 4.1340  Validation loss = 7.3339  \n",
      "\n",
      "Fold: 13  Epoch: 206  Training loss = 4.1337  Validation loss = 7.3333  \n",
      "\n",
      "Fold: 13  Epoch: 207  Training loss = 4.1334  Validation loss = 7.3328  \n",
      "\n",
      "Fold: 13  Epoch: 208  Training loss = 4.1329  Validation loss = 7.3322  \n",
      "\n",
      "Fold: 13  Epoch: 209  Training loss = 4.1326  Validation loss = 7.3316  \n",
      "\n",
      "Fold: 13  Epoch: 210  Training loss = 4.1322  Validation loss = 7.3310  \n",
      "\n",
      "Fold: 13  Epoch: 211  Training loss = 4.1319  Validation loss = 7.3306  \n",
      "\n",
      "Fold: 13  Epoch: 212  Training loss = 4.1315  Validation loss = 7.3300  \n",
      "\n",
      "Fold: 13  Epoch: 213  Training loss = 4.1312  Validation loss = 7.3295  \n",
      "\n",
      "Fold: 13  Epoch: 214  Training loss = 4.1308  Validation loss = 7.3289  \n",
      "\n",
      "Fold: 13  Epoch: 215  Training loss = 4.1304  Validation loss = 7.3283  \n",
      "\n",
      "Fold: 13  Epoch: 216  Training loss = 4.1300  Validation loss = 7.3276  \n",
      "\n",
      "Fold: 13  Epoch: 217  Training loss = 4.1296  Validation loss = 7.3271  \n",
      "\n",
      "Fold: 13  Epoch: 218  Training loss = 4.1293  Validation loss = 7.3266  \n",
      "\n",
      "Fold: 13  Epoch: 219  Training loss = 4.1289  Validation loss = 7.3260  \n",
      "\n",
      "Fold: 13  Epoch: 220  Training loss = 4.1285  Validation loss = 7.3254  \n",
      "\n",
      "Fold: 13  Epoch: 221  Training loss = 4.1282  Validation loss = 7.3248  \n",
      "\n",
      "Fold: 13  Epoch: 222  Training loss = 4.1278  Validation loss = 7.3242  \n",
      "\n",
      "Fold: 13  Epoch: 223  Training loss = 4.1274  Validation loss = 7.3236  \n",
      "\n",
      "Fold: 13  Epoch: 224  Training loss = 4.1270  Validation loss = 7.3229  \n",
      "\n",
      "Fold: 13  Epoch: 225  Training loss = 4.1267  Validation loss = 7.3224  \n",
      "\n",
      "Fold: 13  Epoch: 226  Training loss = 4.1263  Validation loss = 7.3218  \n",
      "\n",
      "Fold: 13  Epoch: 227  Training loss = 4.1259  Validation loss = 7.3213  \n",
      "\n",
      "Fold: 13  Epoch: 228  Training loss = 4.1255  Validation loss = 7.3207  \n",
      "\n",
      "Fold: 13  Epoch: 229  Training loss = 4.1252  Validation loss = 7.3202  \n",
      "\n",
      "Fold: 13  Epoch: 230  Training loss = 4.1250  Validation loss = 7.3198  \n",
      "\n",
      "Fold: 13  Epoch: 231  Training loss = 4.1246  Validation loss = 7.3192  \n",
      "\n",
      "Fold: 13  Epoch: 232  Training loss = 4.1242  Validation loss = 7.3186  \n",
      "\n",
      "Fold: 13  Epoch: 233  Training loss = 4.1238  Validation loss = 7.3180  \n",
      "\n",
      "Fold: 13  Epoch: 234  Training loss = 4.1235  Validation loss = 7.3175  \n",
      "\n",
      "Fold: 13  Epoch: 235  Training loss = 4.1232  Validation loss = 7.3171  \n",
      "\n",
      "Fold: 13  Epoch: 236  Training loss = 4.1228  Validation loss = 7.3166  \n",
      "\n",
      "Fold: 13  Epoch: 237  Training loss = 4.1225  Validation loss = 7.3160  \n",
      "\n",
      "Fold: 13  Epoch: 238  Training loss = 4.1222  Validation loss = 7.3155  \n",
      "\n",
      "Fold: 13  Epoch: 239  Training loss = 4.1219  Validation loss = 7.3150  \n",
      "\n",
      "Fold: 13  Epoch: 240  Training loss = 4.1216  Validation loss = 7.3146  \n",
      "\n",
      "Fold: 13  Epoch: 241  Training loss = 4.1212  Validation loss = 7.3140  \n",
      "\n",
      "Fold: 13  Epoch: 242  Training loss = 4.1209  Validation loss = 7.3135  \n",
      "\n",
      "Fold: 13  Epoch: 243  Training loss = 4.1205  Validation loss = 7.3129  \n",
      "\n",
      "Fold: 13  Epoch: 244  Training loss = 4.1201  Validation loss = 7.3124  \n",
      "\n",
      "Fold: 13  Epoch: 245  Training loss = 4.1198  Validation loss = 7.3119  \n",
      "\n",
      "Fold: 13  Epoch: 246  Training loss = 4.1194  Validation loss = 7.3113  \n",
      "\n",
      "Fold: 13  Epoch: 247  Training loss = 4.1190  Validation loss = 7.3107  \n",
      "\n",
      "Fold: 13  Epoch: 248  Training loss = 4.1187  Validation loss = 7.3102  \n",
      "\n",
      "Fold: 13  Epoch: 249  Training loss = 4.1183  Validation loss = 7.3096  \n",
      "\n",
      "Fold: 13  Epoch: 250  Training loss = 4.1180  Validation loss = 7.3091  \n",
      "\n",
      "Fold: 13  Epoch: 251  Training loss = 4.1176  Validation loss = 7.3085  \n",
      "\n",
      "Fold: 13  Epoch: 252  Training loss = 4.1173  Validation loss = 7.3080  \n",
      "\n",
      "Fold: 13  Epoch: 253  Training loss = 4.1169  Validation loss = 7.3074  \n",
      "\n",
      "Fold: 13  Epoch: 254  Training loss = 4.1165  Validation loss = 7.3068  \n",
      "\n",
      "Fold: 13  Epoch: 255  Training loss = 4.1161  Validation loss = 7.3063  \n",
      "\n",
      "Fold: 13  Epoch: 256  Training loss = 4.1157  Validation loss = 7.3058  \n",
      "\n",
      "Fold: 13  Epoch: 257  Training loss = 4.1154  Validation loss = 7.3053  \n",
      "\n",
      "Fold: 13  Epoch: 258  Training loss = 4.1150  Validation loss = 7.3047  \n",
      "\n",
      "Fold: 13  Epoch: 259  Training loss = 4.1146  Validation loss = 7.3041  \n",
      "\n",
      "Fold: 13  Epoch: 260  Training loss = 4.1143  Validation loss = 7.3037  \n",
      "\n",
      "Fold: 13  Epoch: 261  Training loss = 4.1140  Validation loss = 7.3031  \n",
      "\n",
      "Fold: 13  Epoch: 262  Training loss = 4.1135  Validation loss = 7.3025  \n",
      "\n",
      "Fold: 13  Epoch: 263  Training loss = 4.1132  Validation loss = 7.3020  \n",
      "\n",
      "Fold: 13  Epoch: 264  Training loss = 4.1128  Validation loss = 7.3014  \n",
      "\n",
      "Fold: 13  Epoch: 265  Training loss = 4.1124  Validation loss = 7.3009  \n",
      "\n",
      "Fold: 13  Epoch: 266  Training loss = 4.1120  Validation loss = 7.3004  \n",
      "\n",
      "Fold: 13  Epoch: 267  Training loss = 4.1114  Validation loss = 7.2997  \n",
      "\n",
      "Fold: 13  Epoch: 268  Training loss = 4.1106  Validation loss = 7.2990  \n",
      "\n",
      "Fold: 13  Epoch: 269  Training loss = 4.1101  Validation loss = 7.2984  \n",
      "\n",
      "Fold: 13  Epoch: 270  Training loss = 4.1091  Validation loss = 7.2976  \n",
      "\n",
      "Fold: 13  Epoch: 271  Training loss = 4.1084  Validation loss = 7.2972  \n",
      "\n",
      "Fold: 13  Epoch: 272  Training loss = 4.1078  Validation loss = 7.2967  \n",
      "\n",
      "Fold: 13  Epoch: 273  Training loss = 4.1072  Validation loss = 7.2960  \n",
      "\n",
      "Fold: 13  Epoch: 274  Training loss = 4.1068  Validation loss = 7.2955  \n",
      "\n",
      "Fold: 13  Epoch: 275  Training loss = 4.1064  Validation loss = 7.2949  \n",
      "\n",
      "Fold: 13  Epoch: 276  Training loss = 4.1060  Validation loss = 7.2943  \n",
      "\n",
      "Fold: 13  Epoch: 277  Training loss = 4.1056  Validation loss = 7.2937  \n",
      "\n",
      "Fold: 13  Epoch: 278  Training loss = 4.1053  Validation loss = 7.2932  \n",
      "\n",
      "Fold: 13  Epoch: 279  Training loss = 4.1049  Validation loss = 7.2928  \n",
      "\n",
      "Fold: 13  Epoch: 280  Training loss = 4.1045  Validation loss = 7.2921  \n",
      "\n",
      "Fold: 13  Epoch: 281  Training loss = 4.1041  Validation loss = 7.2915  \n",
      "\n",
      "Fold: 13  Epoch: 282  Training loss = 4.1038  Validation loss = 7.2911  \n",
      "\n",
      "Fold: 13  Epoch: 283  Training loss = 4.1033  Validation loss = 7.2904  \n",
      "\n",
      "Fold: 13  Epoch: 284  Training loss = 4.1030  Validation loss = 7.2899  \n",
      "\n",
      "Fold: 13  Epoch: 285  Training loss = 4.1026  Validation loss = 7.2893  \n",
      "\n",
      "Fold: 13  Epoch: 286  Training loss = 4.1022  Validation loss = 7.2887  \n",
      "\n",
      "Fold: 13  Epoch: 287  Training loss = 4.1019  Validation loss = 7.2883  \n",
      "\n",
      "Fold: 13  Epoch: 288  Training loss = 4.1016  Validation loss = 7.2878  \n",
      "\n",
      "Fold: 13  Epoch: 289  Training loss = 4.1013  Validation loss = 7.2873  \n",
      "\n",
      "Fold: 13  Epoch: 290  Training loss = 4.1010  Validation loss = 7.2868  \n",
      "\n",
      "Fold: 13  Epoch: 291  Training loss = 4.1007  Validation loss = 7.2863  \n",
      "\n",
      "Fold: 13  Epoch: 292  Training loss = 4.1004  Validation loss = 7.2859  \n",
      "\n",
      "Fold: 13  Epoch: 293  Training loss = 4.1000  Validation loss = 7.2853  \n",
      "\n",
      "Fold: 13  Epoch: 294  Training loss = 4.0997  Validation loss = 7.2849  \n",
      "\n",
      "Fold: 13  Epoch: 295  Training loss = 4.0993  Validation loss = 7.2842  \n",
      "\n",
      "Fold: 13  Epoch: 296  Training loss = 4.0990  Validation loss = 7.2837  \n",
      "\n",
      "Fold: 13  Epoch: 297  Training loss = 4.0986  Validation loss = 7.2832  \n",
      "\n",
      "Fold: 13  Epoch: 298  Training loss = 4.0982  Validation loss = 7.2827  \n",
      "\n",
      "Fold: 13  Epoch: 299  Training loss = 4.0978  Validation loss = 7.2820  \n",
      "\n",
      "Fold: 13  Epoch: 300  Training loss = 4.0974  Validation loss = 7.2814  \n",
      "\n",
      "Fold: 13  Epoch: 301  Training loss = 4.0971  Validation loss = 7.2809  \n",
      "\n",
      "Fold: 13  Epoch: 302  Training loss = 4.0967  Validation loss = 7.2804  \n",
      "\n",
      "Fold: 13  Epoch: 303  Training loss = 4.0964  Validation loss = 7.2800  \n",
      "\n",
      "Fold: 13  Epoch: 304  Training loss = 4.0960  Validation loss = 7.2794  \n",
      "\n",
      "Fold: 13  Epoch: 305  Training loss = 4.0957  Validation loss = 7.2788  \n",
      "\n",
      "Fold: 13  Epoch: 306  Training loss = 4.0953  Validation loss = 7.2783  \n",
      "\n",
      "Fold: 13  Epoch: 307  Training loss = 4.0950  Validation loss = 7.2777  \n",
      "\n",
      "Fold: 13  Epoch: 308  Training loss = 4.0946  Validation loss = 7.2772  \n",
      "\n",
      "Fold: 13  Epoch: 309  Training loss = 4.0943  Validation loss = 7.2767  \n",
      "\n",
      "Fold: 13  Epoch: 310  Training loss = 4.0939  Validation loss = 7.2760  \n",
      "\n",
      "Fold: 13  Epoch: 311  Training loss = 4.0935  Validation loss = 7.2755  \n",
      "\n",
      "Fold: 13  Epoch: 312  Training loss = 4.0932  Validation loss = 7.2749  \n",
      "\n",
      "Fold: 13  Epoch: 313  Training loss = 4.0928  Validation loss = 7.2744  \n",
      "\n",
      "Fold: 13  Epoch: 314  Training loss = 4.0925  Validation loss = 7.2739  \n",
      "\n",
      "Fold: 13  Epoch: 315  Training loss = 4.0920  Validation loss = 7.2732  \n",
      "\n",
      "Fold: 13  Epoch: 316  Training loss = 4.0916  Validation loss = 7.2726  \n",
      "\n",
      "Fold: 13  Epoch: 317  Training loss = 4.0913  Validation loss = 7.2720  \n",
      "\n",
      "Fold: 13  Epoch: 318  Training loss = 4.0909  Validation loss = 7.2715  \n",
      "\n",
      "Fold: 13  Epoch: 319  Training loss = 4.0906  Validation loss = 7.2710  \n",
      "\n",
      "Fold: 13  Epoch: 320  Training loss = 4.0904  Validation loss = 7.2706  \n",
      "\n",
      "Fold: 13  Epoch: 321  Training loss = 4.0900  Validation loss = 7.2701  \n",
      "\n",
      "Fold: 13  Epoch: 322  Training loss = 4.0897  Validation loss = 7.2696  \n",
      "\n",
      "Fold: 13  Epoch: 323  Training loss = 4.0893  Validation loss = 7.2689  \n",
      "\n",
      "Fold: 13  Epoch: 324  Training loss = 4.0890  Validation loss = 7.2684  \n",
      "\n",
      "Fold: 13  Epoch: 325  Training loss = 4.0886  Validation loss = 7.2678  \n",
      "\n",
      "Fold: 13  Epoch: 326  Training loss = 4.0882  Validation loss = 7.2672  \n",
      "\n",
      "Fold: 13  Epoch: 327  Training loss = 4.0879  Validation loss = 7.2667  \n",
      "\n",
      "Fold: 13  Epoch: 328  Training loss = 4.0875  Validation loss = 7.2661  \n",
      "\n",
      "Fold: 13  Epoch: 329  Training loss = 4.0872  Validation loss = 7.2656  \n",
      "\n",
      "Fold: 13  Epoch: 330  Training loss = 4.0868  Validation loss = 7.2651  \n",
      "\n",
      "Fold: 13  Epoch: 331  Training loss = 4.0865  Validation loss = 7.2646  \n",
      "\n",
      "Fold: 13  Epoch: 332  Training loss = 4.0862  Validation loss = 7.2641  \n",
      "\n",
      "Fold: 13  Epoch: 333  Training loss = 4.0858  Validation loss = 7.2635  \n",
      "\n",
      "Fold: 13  Epoch: 334  Training loss = 4.0855  Validation loss = 7.2629  \n",
      "\n",
      "Fold: 13  Epoch: 335  Training loss = 4.0852  Validation loss = 7.2624  \n",
      "\n",
      "Fold: 13  Epoch: 336  Training loss = 4.0848  Validation loss = 7.2618  \n",
      "\n",
      "Fold: 13  Epoch: 337  Training loss = 4.0845  Validation loss = 7.2614  \n",
      "\n",
      "Fold: 13  Epoch: 338  Training loss = 4.0841  Validation loss = 7.2607  \n",
      "\n",
      "Fold: 13  Epoch: 339  Training loss = 4.0837  Validation loss = 7.2602  \n",
      "\n",
      "Fold: 13  Epoch: 340  Training loss = 4.0834  Validation loss = 7.2597  \n",
      "\n",
      "Fold: 13  Epoch: 341  Training loss = 4.0830  Validation loss = 7.2591  \n",
      "\n",
      "Fold: 13  Epoch: 342  Training loss = 4.0826  Validation loss = 7.2585  \n",
      "\n",
      "Fold: 13  Epoch: 343  Training loss = 4.0823  Validation loss = 7.2580  \n",
      "\n",
      "Fold: 13  Epoch: 344  Training loss = 4.0818  Validation loss = 7.2573  \n",
      "\n",
      "Fold: 13  Epoch: 345  Training loss = 4.0815  Validation loss = 7.2568  \n",
      "\n",
      "Fold: 13  Epoch: 346  Training loss = 4.0812  Validation loss = 7.2563  \n",
      "\n",
      "Fold: 13  Epoch: 347  Training loss = 4.0808  Validation loss = 7.2557  \n",
      "\n",
      "Fold: 13  Epoch: 348  Training loss = 4.0804  Validation loss = 7.2551  \n",
      "\n",
      "Fold: 13  Epoch: 349  Training loss = 4.0801  Validation loss = 7.2546  \n",
      "\n",
      "Fold: 13  Epoch: 350  Training loss = 4.0797  Validation loss = 7.2540  \n",
      "\n",
      "Fold: 13  Epoch: 351  Training loss = 4.0793  Validation loss = 7.2533  \n",
      "\n",
      "Fold: 13  Epoch: 352  Training loss = 4.0789  Validation loss = 7.2527  \n",
      "\n",
      "Fold: 13  Epoch: 353  Training loss = 4.0786  Validation loss = 7.2522  \n",
      "\n",
      "Fold: 13  Epoch: 354  Training loss = 4.0783  Validation loss = 7.2517  \n",
      "\n",
      "Fold: 13  Epoch: 355  Training loss = 4.0779  Validation loss = 7.2511  \n",
      "\n",
      "Fold: 13  Epoch: 356  Training loss = 4.0776  Validation loss = 7.2505  \n",
      "\n",
      "Fold: 13  Epoch: 357  Training loss = 4.0771  Validation loss = 7.2498  \n",
      "\n",
      "Fold: 13  Epoch: 358  Training loss = 4.0767  Validation loss = 7.2492  \n",
      "\n",
      "Fold: 13  Epoch: 359  Training loss = 4.0763  Validation loss = 7.2485  \n",
      "\n",
      "Fold: 13  Epoch: 360  Training loss = 4.0759  Validation loss = 7.2480  \n",
      "\n",
      "Fold: 13  Epoch: 361  Training loss = 4.0756  Validation loss = 7.2473  \n",
      "\n",
      "Fold: 13  Epoch: 362  Training loss = 4.0752  Validation loss = 7.2468  \n",
      "\n",
      "Fold: 13  Epoch: 363  Training loss = 4.0748  Validation loss = 7.2462  \n",
      "\n",
      "Fold: 13  Epoch: 364  Training loss = 4.0745  Validation loss = 7.2457  \n",
      "\n",
      "Fold: 13  Epoch: 365  Training loss = 4.0741  Validation loss = 7.2451  \n",
      "\n",
      "Fold: 13  Epoch: 366  Training loss = 4.0737  Validation loss = 7.2444  \n",
      "\n",
      "Fold: 13  Epoch: 367  Training loss = 4.0733  Validation loss = 7.2438  \n",
      "\n",
      "Fold: 13  Epoch: 368  Training loss = 4.0729  Validation loss = 7.2431  \n",
      "\n",
      "Fold: 13  Epoch: 369  Training loss = 4.0725  Validation loss = 7.2425  \n",
      "\n",
      "Fold: 13  Epoch: 370  Training loss = 4.0721  Validation loss = 7.2418  \n",
      "\n",
      "Fold: 13  Epoch: 371  Training loss = 4.0717  Validation loss = 7.2413  \n",
      "\n",
      "Fold: 13  Epoch: 372  Training loss = 4.0714  Validation loss = 7.2407  \n",
      "\n",
      "Fold: 13  Epoch: 373  Training loss = 4.0711  Validation loss = 7.2403  \n",
      "\n",
      "Fold: 13  Epoch: 374  Training loss = 4.0707  Validation loss = 7.2396  \n",
      "\n",
      "Fold: 13  Epoch: 375  Training loss = 4.0704  Validation loss = 7.2391  \n",
      "\n",
      "Fold: 13  Epoch: 376  Training loss = 4.0701  Validation loss = 7.2387  \n",
      "\n",
      "Fold: 13  Epoch: 377  Training loss = 4.0698  Validation loss = 7.2382  \n",
      "\n",
      "Fold: 13  Epoch: 378  Training loss = 4.0694  Validation loss = 7.2376  \n",
      "\n",
      "Fold: 13  Epoch: 379  Training loss = 4.0691  Validation loss = 7.2371  \n",
      "\n",
      "Fold: 13  Epoch: 380  Training loss = 4.0687  Validation loss = 7.2364  \n",
      "\n",
      "Fold: 13  Epoch: 381  Training loss = 4.0683  Validation loss = 7.2359  \n",
      "\n",
      "Fold: 13  Epoch: 382  Training loss = 4.0680  Validation loss = 7.2353  \n",
      "\n",
      "Fold: 13  Epoch: 383  Training loss = 4.0676  Validation loss = 7.2348  \n",
      "\n",
      "Fold: 13  Epoch: 384  Training loss = 4.0672  Validation loss = 7.2342  \n",
      "\n",
      "Fold: 13  Epoch: 385  Training loss = 4.0668  Validation loss = 7.2336  \n",
      "\n",
      "Fold: 13  Epoch: 386  Training loss = 4.0665  Validation loss = 7.2332  \n",
      "\n",
      "Fold: 13  Epoch: 387  Training loss = 4.0662  Validation loss = 7.2327  \n",
      "\n",
      "Fold: 13  Epoch: 388  Training loss = 4.0658  Validation loss = 7.2321  \n",
      "\n",
      "Fold: 13  Epoch: 389  Training loss = 4.0655  Validation loss = 7.2316  \n",
      "\n",
      "Fold: 13  Epoch: 390  Training loss = 4.0652  Validation loss = 7.2312  \n",
      "\n",
      "Fold: 13  Epoch: 391  Training loss = 4.0648  Validation loss = 7.2305  \n",
      "\n",
      "Fold: 13  Epoch: 392  Training loss = 4.0644  Validation loss = 7.2299  \n",
      "\n",
      "Fold: 13  Epoch: 393  Training loss = 4.0641  Validation loss = 7.2295  \n",
      "\n",
      "Fold: 13  Epoch: 394  Training loss = 4.0637  Validation loss = 7.2289  \n",
      "\n",
      "Fold: 13  Epoch: 395  Training loss = 4.0634  Validation loss = 7.2285  \n",
      "\n",
      "Fold: 13  Epoch: 396  Training loss = 4.0631  Validation loss = 7.2280  \n",
      "\n",
      "Fold: 13  Epoch: 397  Training loss = 4.0627  Validation loss = 7.2274  \n",
      "\n",
      "Fold: 13  Epoch: 398  Training loss = 4.0624  Validation loss = 7.2269  \n",
      "\n",
      "Fold: 13  Epoch: 399  Training loss = 4.0622  Validation loss = 7.2265  \n",
      "\n",
      "Fold: 13  Epoch: 400  Training loss = 4.0619  Validation loss = 7.2260  \n",
      "\n",
      "Fold: 13  Epoch: 401  Training loss = 4.0616  Validation loss = 7.2255  \n",
      "\n",
      "Fold: 13  Epoch: 402  Training loss = 4.0612  Validation loss = 7.2249  \n",
      "\n",
      "Fold: 13  Epoch: 403  Training loss = 4.0609  Validation loss = 7.2244  \n",
      "\n",
      "Fold: 13  Epoch: 404  Training loss = 4.0606  Validation loss = 7.2238  \n",
      "\n",
      "Fold: 13  Epoch: 405  Training loss = 4.0603  Validation loss = 7.2233  \n",
      "\n",
      "Fold: 13  Epoch: 406  Training loss = 4.0600  Validation loss = 7.2229  \n",
      "\n",
      "Fold: 13  Epoch: 407  Training loss = 4.0597  Validation loss = 7.2224  \n",
      "\n",
      "Fold: 13  Epoch: 408  Training loss = 4.0593  Validation loss = 7.2218  \n",
      "\n",
      "Fold: 13  Epoch: 409  Training loss = 4.0589  Validation loss = 7.2212  \n",
      "\n",
      "Fold: 13  Epoch: 410  Training loss = 4.0586  Validation loss = 7.2207  \n",
      "\n",
      "Fold: 13  Epoch: 411  Training loss = 4.0582  Validation loss = 7.2202  \n",
      "\n",
      "Fold: 13  Epoch: 412  Training loss = 4.0579  Validation loss = 7.2196  \n",
      "\n",
      "Fold: 13  Epoch: 413  Training loss = 4.0575  Validation loss = 7.2191  \n",
      "\n",
      "Fold: 13  Epoch: 414  Training loss = 4.0572  Validation loss = 7.2186  \n",
      "\n",
      "Fold: 13  Epoch: 415  Training loss = 4.0569  Validation loss = 7.2182  \n",
      "\n",
      "Fold: 13  Epoch: 416  Training loss = 4.0566  Validation loss = 7.2176  \n",
      "\n",
      "Fold: 13  Epoch: 417  Training loss = 4.0562  Validation loss = 7.2171  \n",
      "\n",
      "Fold: 13  Epoch: 418  Training loss = 4.0559  Validation loss = 7.2165  \n",
      "\n",
      "Fold: 13  Epoch: 419  Training loss = 4.0554  Validation loss = 7.2158  \n",
      "\n",
      "Fold: 13  Epoch: 420  Training loss = 4.0551  Validation loss = 7.2152  \n",
      "\n",
      "Fold: 13  Epoch: 421  Training loss = 4.0547  Validation loss = 7.2147  \n",
      "\n",
      "Fold: 13  Epoch: 422  Training loss = 4.0544  Validation loss = 7.2142  \n",
      "\n",
      "Fold: 13  Epoch: 423  Training loss = 4.0541  Validation loss = 7.2137  \n",
      "\n",
      "Fold: 13  Epoch: 424  Training loss = 4.0538  Validation loss = 7.2132  \n",
      "\n",
      "Fold: 13  Epoch: 425  Training loss = 4.0534  Validation loss = 7.2127  \n",
      "\n",
      "Fold: 13  Epoch: 426  Training loss = 4.0531  Validation loss = 7.2123  \n",
      "\n",
      "Fold: 13  Epoch: 427  Training loss = 4.0528  Validation loss = 7.2118  \n",
      "\n",
      "Fold: 13  Epoch: 428  Training loss = 4.0525  Validation loss = 7.2113  \n",
      "\n",
      "Fold: 13  Epoch: 429  Training loss = 4.0522  Validation loss = 7.2108  \n",
      "\n",
      "Fold: 13  Epoch: 430  Training loss = 4.0518  Validation loss = 7.2102  \n",
      "\n",
      "Fold: 13  Epoch: 431  Training loss = 4.0514  Validation loss = 7.2096  \n",
      "\n",
      "Fold: 13  Epoch: 432  Training loss = 4.0510  Validation loss = 7.2089  \n",
      "\n",
      "Fold: 13  Epoch: 433  Training loss = 4.0507  Validation loss = 7.2083  \n",
      "\n",
      "Fold: 13  Epoch: 434  Training loss = 4.0503  Validation loss = 7.2077  \n",
      "\n",
      "Fold: 13  Epoch: 435  Training loss = 4.0499  Validation loss = 7.2071  \n",
      "\n",
      "Fold: 13  Epoch: 436  Training loss = 4.0496  Validation loss = 7.2066  \n",
      "\n",
      "Fold: 13  Epoch: 437  Training loss = 4.0493  Validation loss = 7.2061  \n",
      "\n",
      "Fold: 13  Epoch: 438  Training loss = 4.0490  Validation loss = 7.2056  \n",
      "\n",
      "Fold: 13  Epoch: 439  Training loss = 4.0486  Validation loss = 7.2051  \n",
      "\n",
      "Fold: 13  Epoch: 440  Training loss = 4.0483  Validation loss = 7.2046  \n",
      "\n",
      "Fold: 13  Epoch: 441  Training loss = 4.0480  Validation loss = 7.2041  \n",
      "\n",
      "Fold: 13  Epoch: 442  Training loss = 4.0477  Validation loss = 7.2036  \n",
      "\n",
      "Fold: 13  Epoch: 443  Training loss = 4.0473  Validation loss = 7.2031  \n",
      "\n",
      "Fold: 13  Epoch: 444  Training loss = 4.0470  Validation loss = 7.2024  \n",
      "\n",
      "Fold: 13  Epoch: 445  Training loss = 4.0467  Validation loss = 7.2020  \n",
      "\n",
      "Fold: 13  Epoch: 446  Training loss = 4.0463  Validation loss = 7.2014  \n",
      "\n",
      "Fold: 13  Epoch: 447  Training loss = 4.0460  Validation loss = 7.2008  \n",
      "\n",
      "Fold: 13  Epoch: 448  Training loss = 4.0457  Validation loss = 7.2003  \n",
      "\n",
      "Fold: 13  Epoch: 449  Training loss = 4.0454  Validation loss = 7.1999  \n",
      "\n",
      "Fold: 13  Epoch: 450  Training loss = 4.0450  Validation loss = 7.1993  \n",
      "\n",
      "Fold: 13  Epoch: 451  Training loss = 4.0447  Validation loss = 7.1989  \n",
      "\n",
      "Fold: 13  Epoch: 452  Training loss = 4.0443  Validation loss = 7.1983  \n",
      "\n",
      "Fold: 13  Epoch: 453  Training loss = 4.0440  Validation loss = 7.1977  \n",
      "\n",
      "Fold: 13  Epoch: 454  Training loss = 4.0437  Validation loss = 7.1972  \n",
      "\n",
      "Fold: 13  Epoch: 455  Training loss = 4.0433  Validation loss = 7.1966  \n",
      "\n",
      "Fold: 13  Epoch: 456  Training loss = 4.0430  Validation loss = 7.1961  \n",
      "\n",
      "Fold: 13  Epoch: 457  Training loss = 4.0426  Validation loss = 7.1954  \n",
      "\n",
      "Fold: 13  Epoch: 458  Training loss = 4.0422  Validation loss = 7.1949  \n",
      "\n",
      "Fold: 13  Epoch: 459  Training loss = 4.0419  Validation loss = 7.1945  \n",
      "\n",
      "Fold: 13  Epoch: 460  Training loss = 4.0416  Validation loss = 7.1939  \n",
      "\n",
      "Fold: 13  Epoch: 461  Training loss = 4.0412  Validation loss = 7.1933  \n",
      "\n",
      "Fold: 13  Epoch: 462  Training loss = 4.0409  Validation loss = 7.1928  \n",
      "\n",
      "Fold: 13  Epoch: 463  Training loss = 4.0406  Validation loss = 7.1923  \n",
      "\n",
      "Fold: 13  Epoch: 464  Training loss = 4.0402  Validation loss = 7.1917  \n",
      "\n",
      "Fold: 13  Epoch: 465  Training loss = 4.0399  Validation loss = 7.1911  \n",
      "\n",
      "Fold: 13  Epoch: 466  Training loss = 4.0395  Validation loss = 7.1906  \n",
      "\n",
      "Fold: 13  Epoch: 467  Training loss = 4.0392  Validation loss = 7.1901  \n",
      "\n",
      "Fold: 13  Epoch: 468  Training loss = 4.0388  Validation loss = 7.1895  \n",
      "\n",
      "Fold: 13  Epoch: 469  Training loss = 4.0385  Validation loss = 7.1890  \n",
      "\n",
      "Fold: 13  Epoch: 470  Training loss = 4.0381  Validation loss = 7.1884  \n",
      "\n",
      "Fold: 13  Epoch: 471  Training loss = 4.0377  Validation loss = 7.1879  \n",
      "\n",
      "Fold: 13  Epoch: 472  Training loss = 4.0373  Validation loss = 7.1873  \n",
      "\n",
      "Fold: 13  Epoch: 473  Training loss = 4.0369  Validation loss = 7.1866  \n",
      "\n",
      "Fold: 13  Epoch: 474  Training loss = 4.0366  Validation loss = 7.1862  \n",
      "\n",
      "Fold: 13  Epoch: 475  Training loss = 4.0362  Validation loss = 7.1856  \n",
      "\n",
      "Fold: 13  Epoch: 476  Training loss = 4.0359  Validation loss = 7.1851  \n",
      "\n",
      "Fold: 13  Epoch: 477  Training loss = 4.0356  Validation loss = 7.1847  \n",
      "\n",
      "Fold: 13  Epoch: 478  Training loss = 4.0353  Validation loss = 7.1843  \n",
      "\n",
      "Fold: 13  Epoch: 479  Training loss = 4.0350  Validation loss = 7.1837  \n",
      "\n",
      "Fold: 13  Epoch: 480  Training loss = 4.0346  Validation loss = 7.1831  \n",
      "\n",
      "Fold: 13  Epoch: 481  Training loss = 4.0343  Validation loss = 7.1825  \n",
      "\n",
      "Fold: 13  Epoch: 482  Training loss = 4.0341  Validation loss = 7.1821  \n",
      "\n",
      "Fold: 13  Epoch: 483  Training loss = 4.0336  Validation loss = 7.1815  \n",
      "\n",
      "Fold: 13  Epoch: 484  Training loss = 4.0333  Validation loss = 7.1810  \n",
      "\n",
      "Fold: 13  Epoch: 485  Training loss = 4.0330  Validation loss = 7.1804  \n",
      "\n",
      "Fold: 13  Epoch: 486  Training loss = 4.0326  Validation loss = 7.1799  \n",
      "\n",
      "Fold: 13  Epoch: 487  Training loss = 4.0323  Validation loss = 7.1793  \n",
      "\n",
      "Fold: 13  Epoch: 488  Training loss = 4.0319  Validation loss = 7.1788  \n",
      "\n",
      "Fold: 13  Epoch: 489  Training loss = 4.0316  Validation loss = 7.1782  \n",
      "\n",
      "Fold: 13  Epoch: 490  Training loss = 4.0312  Validation loss = 7.1776  \n",
      "\n",
      "Fold: 13  Epoch: 491  Training loss = 4.0308  Validation loss = 7.1770  \n",
      "\n",
      "Fold: 13  Epoch: 492  Training loss = 4.0304  Validation loss = 7.1765  \n",
      "\n",
      "Fold: 13  Epoch: 493  Training loss = 4.0302  Validation loss = 7.1761  \n",
      "\n",
      "Fold: 13  Epoch: 494  Training loss = 4.0298  Validation loss = 7.1755  \n",
      "\n",
      "Fold: 13  Epoch: 495  Training loss = 4.0295  Validation loss = 7.1751  \n",
      "\n",
      "Fold: 13  Epoch: 496  Training loss = 4.0291  Validation loss = 7.1745  \n",
      "\n",
      "Fold: 13  Epoch: 497  Training loss = 4.0288  Validation loss = 7.1740  \n",
      "\n",
      "Fold: 13  Epoch: 498  Training loss = 4.0284  Validation loss = 7.1733  \n",
      "\n",
      "Fold: 13  Epoch: 499  Training loss = 4.0281  Validation loss = 7.1728  \n",
      "\n",
      "Fold: 13  Epoch: 500  Training loss = 4.0277  Validation loss = 7.1722  \n",
      "\n",
      "Check model:  Fold: 13  Optimal epoch: 500  \n",
      "\n",
      "Fold: 14  Epoch: 1  Training loss = 4.3988  Validation loss = 10.6897  \n",
      "\n",
      "Fold: 14  Epoch: 2  Training loss = 4.3985  Validation loss = 10.6892  \n",
      "\n",
      "Fold: 14  Epoch: 3  Training loss = 4.3981  Validation loss = 10.6885  \n",
      "\n",
      "Fold: 14  Epoch: 4  Training loss = 4.3977  Validation loss = 10.6879  \n",
      "\n",
      "Fold: 14  Epoch: 5  Training loss = 4.3973  Validation loss = 10.6873  \n",
      "\n",
      "Fold: 14  Epoch: 6  Training loss = 4.3968  Validation loss = 10.6865  \n",
      "\n",
      "Fold: 14  Epoch: 7  Training loss = 4.3963  Validation loss = 10.6858  \n",
      "\n",
      "Fold: 14  Epoch: 8  Training loss = 4.3959  Validation loss = 10.6851  \n",
      "\n",
      "Fold: 14  Epoch: 9  Training loss = 4.3954  Validation loss = 10.6844  \n",
      "\n",
      "Fold: 14  Epoch: 10  Training loss = 4.3950  Validation loss = 10.6838  \n",
      "\n",
      "Fold: 14  Epoch: 11  Training loss = 4.3946  Validation loss = 10.6832  \n",
      "\n",
      "Fold: 14  Epoch: 12  Training loss = 4.3941  Validation loss = 10.6824  \n",
      "\n",
      "Fold: 14  Epoch: 13  Training loss = 4.3936  Validation loss = 10.6817  \n",
      "\n",
      "Fold: 14  Epoch: 14  Training loss = 4.3931  Validation loss = 10.6809  \n",
      "\n",
      "Fold: 14  Epoch: 15  Training loss = 4.3926  Validation loss = 10.6801  \n",
      "\n",
      "Fold: 14  Epoch: 16  Training loss = 4.3922  Validation loss = 10.6796  \n",
      "\n",
      "Fold: 14  Epoch: 17  Training loss = 4.3919  Validation loss = 10.6790  \n",
      "\n",
      "Fold: 14  Epoch: 18  Training loss = 4.3914  Validation loss = 10.6782  \n",
      "\n",
      "Fold: 14  Epoch: 19  Training loss = 4.3909  Validation loss = 10.6775  \n",
      "\n",
      "Fold: 14  Epoch: 20  Training loss = 4.3905  Validation loss = 10.6769  \n",
      "\n",
      "Fold: 14  Epoch: 21  Training loss = 4.3900  Validation loss = 10.6762  \n",
      "\n",
      "Fold: 14  Epoch: 22  Training loss = 4.3896  Validation loss = 10.6755  \n",
      "\n",
      "Fold: 14  Epoch: 23  Training loss = 4.3892  Validation loss = 10.6750  \n",
      "\n",
      "Fold: 14  Epoch: 24  Training loss = 4.3888  Validation loss = 10.6743  \n",
      "\n",
      "Fold: 14  Epoch: 25  Training loss = 4.3883  Validation loss = 10.6736  \n",
      "\n",
      "Fold: 14  Epoch: 26  Training loss = 4.3878  Validation loss = 10.6728  \n",
      "\n",
      "Fold: 14  Epoch: 27  Training loss = 4.3875  Validation loss = 10.6722  \n",
      "\n",
      "Fold: 14  Epoch: 28  Training loss = 4.3870  Validation loss = 10.6715  \n",
      "\n",
      "Fold: 14  Epoch: 29  Training loss = 4.3865  Validation loss = 10.6708  \n",
      "\n",
      "Fold: 14  Epoch: 30  Training loss = 4.3862  Validation loss = 10.6702  \n",
      "\n",
      "Fold: 14  Epoch: 31  Training loss = 4.3857  Validation loss = 10.6695  \n",
      "\n",
      "Fold: 14  Epoch: 32  Training loss = 4.3852  Validation loss = 10.6688  \n",
      "\n",
      "Fold: 14  Epoch: 33  Training loss = 4.3847  Validation loss = 10.6680  \n",
      "\n",
      "Fold: 14  Epoch: 34  Training loss = 4.3843  Validation loss = 10.6674  \n",
      "\n",
      "Fold: 14  Epoch: 35  Training loss = 4.3839  Validation loss = 10.6667  \n",
      "\n",
      "Fold: 14  Epoch: 36  Training loss = 4.3833  Validation loss = 10.6659  \n",
      "\n",
      "Fold: 14  Epoch: 37  Training loss = 4.3830  Validation loss = 10.6653  \n",
      "\n",
      "Fold: 14  Epoch: 38  Training loss = 4.3825  Validation loss = 10.6646  \n",
      "\n",
      "Fold: 14  Epoch: 39  Training loss = 4.3821  Validation loss = 10.6640  \n",
      "\n",
      "Fold: 14  Epoch: 40  Training loss = 4.3816  Validation loss = 10.6633  \n",
      "\n",
      "Fold: 14  Epoch: 41  Training loss = 4.3811  Validation loss = 10.6626  \n",
      "\n",
      "Fold: 14  Epoch: 42  Training loss = 4.3807  Validation loss = 10.6618  \n",
      "\n",
      "Fold: 14  Epoch: 43  Training loss = 4.3802  Validation loss = 10.6610  \n",
      "\n",
      "Fold: 14  Epoch: 44  Training loss = 4.3796  Validation loss = 10.6602  \n",
      "\n",
      "Fold: 14  Epoch: 45  Training loss = 4.3792  Validation loss = 10.6595  \n",
      "\n",
      "Fold: 14  Epoch: 46  Training loss = 4.3788  Validation loss = 10.6589  \n",
      "\n",
      "Fold: 14  Epoch: 47  Training loss = 4.3783  Validation loss = 10.6582  \n",
      "\n",
      "Fold: 14  Epoch: 48  Training loss = 4.3779  Validation loss = 10.6576  \n",
      "\n",
      "Fold: 14  Epoch: 49  Training loss = 4.3776  Validation loss = 10.6571  \n",
      "\n",
      "Fold: 14  Epoch: 50  Training loss = 4.3772  Validation loss = 10.6565  \n",
      "\n",
      "Fold: 14  Epoch: 51  Training loss = 4.3768  Validation loss = 10.6559  \n",
      "\n",
      "Fold: 14  Epoch: 52  Training loss = 4.3763  Validation loss = 10.6552  \n",
      "\n",
      "Fold: 14  Epoch: 53  Training loss = 4.3759  Validation loss = 10.6545  \n",
      "\n",
      "Fold: 14  Epoch: 54  Training loss = 4.3755  Validation loss = 10.6538  \n",
      "\n",
      "Fold: 14  Epoch: 55  Training loss = 4.3751  Validation loss = 10.6532  \n",
      "\n",
      "Fold: 14  Epoch: 56  Training loss = 4.3746  Validation loss = 10.6525  \n",
      "\n",
      "Fold: 14  Epoch: 57  Training loss = 4.3742  Validation loss = 10.6519  \n",
      "\n",
      "Fold: 14  Epoch: 58  Training loss = 4.3737  Validation loss = 10.6510  \n",
      "\n",
      "Fold: 14  Epoch: 59  Training loss = 4.3732  Validation loss = 10.6504  \n",
      "\n",
      "Fold: 14  Epoch: 60  Training loss = 4.3728  Validation loss = 10.6498  \n",
      "\n",
      "Fold: 14  Epoch: 61  Training loss = 4.3724  Validation loss = 10.6491  \n",
      "\n",
      "Fold: 14  Epoch: 62  Training loss = 4.3719  Validation loss = 10.6484  \n",
      "\n",
      "Fold: 14  Epoch: 63  Training loss = 4.3716  Validation loss = 10.6478  \n",
      "\n",
      "Fold: 14  Epoch: 64  Training loss = 4.3711  Validation loss = 10.6471  \n",
      "\n",
      "Fold: 14  Epoch: 65  Training loss = 4.3707  Validation loss = 10.6465  \n",
      "\n",
      "Fold: 14  Epoch: 66  Training loss = 4.3702  Validation loss = 10.6457  \n",
      "\n",
      "Fold: 14  Epoch: 67  Training loss = 4.3697  Validation loss = 10.6450  \n",
      "\n",
      "Fold: 14  Epoch: 68  Training loss = 4.3693  Validation loss = 10.6443  \n",
      "\n",
      "Fold: 14  Epoch: 69  Training loss = 4.3689  Validation loss = 10.6438  \n",
      "\n",
      "Fold: 14  Epoch: 70  Training loss = 4.3685  Validation loss = 10.6430  \n",
      "\n",
      "Fold: 14  Epoch: 71  Training loss = 4.3680  Validation loss = 10.6424  \n",
      "\n",
      "Fold: 14  Epoch: 72  Training loss = 4.3675  Validation loss = 10.6416  \n",
      "\n",
      "Fold: 14  Epoch: 73  Training loss = 4.3672  Validation loss = 10.6410  \n",
      "\n",
      "Fold: 14  Epoch: 74  Training loss = 4.3668  Validation loss = 10.6405  \n",
      "\n",
      "Fold: 14  Epoch: 75  Training loss = 4.3663  Validation loss = 10.6397  \n",
      "\n",
      "Fold: 14  Epoch: 76  Training loss = 4.3659  Validation loss = 10.6390  \n",
      "\n",
      "Fold: 14  Epoch: 77  Training loss = 4.3654  Validation loss = 10.6383  \n",
      "\n",
      "Fold: 14  Epoch: 78  Training loss = 4.3650  Validation loss = 10.6376  \n",
      "\n",
      "Fold: 14  Epoch: 79  Training loss = 4.3645  Validation loss = 10.6369  \n",
      "\n",
      "Fold: 14  Epoch: 80  Training loss = 4.3641  Validation loss = 10.6364  \n",
      "\n",
      "Fold: 14  Epoch: 81  Training loss = 4.3637  Validation loss = 10.6357  \n",
      "\n",
      "Fold: 14  Epoch: 82  Training loss = 4.3633  Validation loss = 10.6351  \n",
      "\n",
      "Fold: 14  Epoch: 83  Training loss = 4.3629  Validation loss = 10.6344  \n",
      "\n",
      "Fold: 14  Epoch: 84  Training loss = 4.3625  Validation loss = 10.6338  \n",
      "\n",
      "Fold: 14  Epoch: 85  Training loss = 4.3620  Validation loss = 10.6331  \n",
      "\n",
      "Fold: 14  Epoch: 86  Training loss = 4.3616  Validation loss = 10.6324  \n",
      "\n",
      "Fold: 14  Epoch: 87  Training loss = 4.3611  Validation loss = 10.6317  \n",
      "\n",
      "Fold: 14  Epoch: 88  Training loss = 4.3607  Validation loss = 10.6311  \n",
      "\n",
      "Fold: 14  Epoch: 89  Training loss = 4.3603  Validation loss = 10.6304  \n",
      "\n",
      "Fold: 14  Epoch: 90  Training loss = 4.3599  Validation loss = 10.6297  \n",
      "\n",
      "Fold: 14  Epoch: 91  Training loss = 4.3594  Validation loss = 10.6290  \n",
      "\n",
      "Fold: 14  Epoch: 92  Training loss = 4.3590  Validation loss = 10.6283  \n",
      "\n",
      "Fold: 14  Epoch: 93  Training loss = 4.3586  Validation loss = 10.6278  \n",
      "\n",
      "Fold: 14  Epoch: 94  Training loss = 4.3581  Validation loss = 10.6270  \n",
      "\n",
      "Fold: 14  Epoch: 95  Training loss = 4.3576  Validation loss = 10.6263  \n",
      "\n",
      "Fold: 14  Epoch: 96  Training loss = 4.3572  Validation loss = 10.6256  \n",
      "\n",
      "Fold: 14  Epoch: 97  Training loss = 4.3567  Validation loss = 10.6249  \n",
      "\n",
      "Fold: 14  Epoch: 98  Training loss = 4.3563  Validation loss = 10.6243  \n",
      "\n",
      "Fold: 14  Epoch: 99  Training loss = 4.3559  Validation loss = 10.6237  \n",
      "\n",
      "Fold: 14  Epoch: 100  Training loss = 4.3555  Validation loss = 10.6231  \n",
      "\n",
      "Fold: 14  Epoch: 101  Training loss = 4.3551  Validation loss = 10.6224  \n",
      "\n",
      "Fold: 14  Epoch: 102  Training loss = 4.3547  Validation loss = 10.6218  \n",
      "\n",
      "Fold: 14  Epoch: 103  Training loss = 4.3543  Validation loss = 10.6212  \n",
      "\n",
      "Fold: 14  Epoch: 104  Training loss = 4.3539  Validation loss = 10.6206  \n",
      "\n",
      "Fold: 14  Epoch: 105  Training loss = 4.3536  Validation loss = 10.6201  \n",
      "\n",
      "Fold: 14  Epoch: 106  Training loss = 4.3532  Validation loss = 10.6195  \n",
      "\n",
      "Fold: 14  Epoch: 107  Training loss = 4.3527  Validation loss = 10.6187  \n",
      "\n",
      "Fold: 14  Epoch: 108  Training loss = 4.3523  Validation loss = 10.6181  \n",
      "\n",
      "Fold: 14  Epoch: 109  Training loss = 4.3519  Validation loss = 10.6174  \n",
      "\n",
      "Fold: 14  Epoch: 110  Training loss = 4.3514  Validation loss = 10.6167  \n",
      "\n",
      "Fold: 14  Epoch: 111  Training loss = 4.3510  Validation loss = 10.6160  \n",
      "\n",
      "Fold: 14  Epoch: 112  Training loss = 4.3505  Validation loss = 10.6153  \n",
      "\n",
      "Fold: 14  Epoch: 113  Training loss = 4.3501  Validation loss = 10.6146  \n",
      "\n",
      "Fold: 14  Epoch: 114  Training loss = 4.3497  Validation loss = 10.6141  \n",
      "\n",
      "Fold: 14  Epoch: 115  Training loss = 4.3492  Validation loss = 10.6133  \n",
      "\n",
      "Fold: 14  Epoch: 116  Training loss = 4.3488  Validation loss = 10.6127  \n",
      "\n",
      "Fold: 14  Epoch: 117  Training loss = 4.3484  Validation loss = 10.6121  \n",
      "\n",
      "Fold: 14  Epoch: 118  Training loss = 4.3480  Validation loss = 10.6114  \n",
      "\n",
      "Fold: 14  Epoch: 119  Training loss = 4.3475  Validation loss = 10.6107  \n",
      "\n",
      "Fold: 14  Epoch: 120  Training loss = 4.3472  Validation loss = 10.6101  \n",
      "\n",
      "Fold: 14  Epoch: 121  Training loss = 4.3467  Validation loss = 10.6094  \n",
      "\n",
      "Fold: 14  Epoch: 122  Training loss = 4.3462  Validation loss = 10.6087  \n",
      "\n",
      "Fold: 14  Epoch: 123  Training loss = 4.3458  Validation loss = 10.6081  \n",
      "\n",
      "Fold: 14  Epoch: 124  Training loss = 4.3454  Validation loss = 10.6075  \n",
      "\n",
      "Fold: 14  Epoch: 125  Training loss = 4.3450  Validation loss = 10.6068  \n",
      "\n",
      "Fold: 14  Epoch: 126  Training loss = 4.3447  Validation loss = 10.6063  \n",
      "\n",
      "Fold: 14  Epoch: 127  Training loss = 4.3443  Validation loss = 10.6057  \n",
      "\n",
      "Fold: 14  Epoch: 128  Training loss = 4.3438  Validation loss = 10.6050  \n",
      "\n",
      "Fold: 14  Epoch: 129  Training loss = 4.3434  Validation loss = 10.6044  \n",
      "\n",
      "Fold: 14  Epoch: 130  Training loss = 4.3430  Validation loss = 10.6037  \n",
      "\n",
      "Fold: 14  Epoch: 131  Training loss = 4.3426  Validation loss = 10.6030  \n",
      "\n",
      "Fold: 14  Epoch: 132  Training loss = 4.3421  Validation loss = 10.6023  \n",
      "\n",
      "Fold: 14  Epoch: 133  Training loss = 4.3416  Validation loss = 10.6015  \n",
      "\n",
      "Fold: 14  Epoch: 134  Training loss = 4.3412  Validation loss = 10.6009  \n",
      "\n",
      "Fold: 14  Epoch: 135  Training loss = 4.3407  Validation loss = 10.6002  \n",
      "\n",
      "Fold: 14  Epoch: 136  Training loss = 4.3403  Validation loss = 10.5995  \n",
      "\n",
      "Fold: 14  Epoch: 137  Training loss = 4.3399  Validation loss = 10.5990  \n",
      "\n",
      "Fold: 14  Epoch: 138  Training loss = 4.3395  Validation loss = 10.5983  \n",
      "\n",
      "Fold: 14  Epoch: 139  Training loss = 4.3391  Validation loss = 10.5976  \n",
      "\n",
      "Fold: 14  Epoch: 140  Training loss = 4.3386  Validation loss = 10.5969  \n",
      "\n",
      "Fold: 14  Epoch: 141  Training loss = 4.3381  Validation loss = 10.5962  \n",
      "\n",
      "Fold: 14  Epoch: 142  Training loss = 4.3378  Validation loss = 10.5956  \n",
      "\n",
      "Fold: 14  Epoch: 143  Training loss = 4.3374  Validation loss = 10.5950  \n",
      "\n",
      "Fold: 14  Epoch: 144  Training loss = 4.3370  Validation loss = 10.5944  \n",
      "\n",
      "Fold: 14  Epoch: 145  Training loss = 4.3366  Validation loss = 10.5938  \n",
      "\n",
      "Fold: 14  Epoch: 146  Training loss = 4.3361  Validation loss = 10.5931  \n",
      "\n",
      "Fold: 14  Epoch: 147  Training loss = 4.3356  Validation loss = 10.5922  \n",
      "\n",
      "Fold: 14  Epoch: 148  Training loss = 4.3351  Validation loss = 10.5914  \n",
      "\n",
      "Fold: 14  Epoch: 149  Training loss = 4.3345  Validation loss = 10.5906  \n",
      "\n",
      "Fold: 14  Epoch: 150  Training loss = 4.3342  Validation loss = 10.5901  \n",
      "\n",
      "Fold: 14  Epoch: 151  Training loss = 4.3338  Validation loss = 10.5895  \n",
      "\n",
      "Fold: 14  Epoch: 152  Training loss = 4.3334  Validation loss = 10.5888  \n",
      "\n",
      "Fold: 14  Epoch: 153  Training loss = 4.3330  Validation loss = 10.5882  \n",
      "\n",
      "Fold: 14  Epoch: 154  Training loss = 4.3325  Validation loss = 10.5874  \n",
      "\n",
      "Fold: 14  Epoch: 155  Training loss = 4.3321  Validation loss = 10.5869  \n",
      "\n",
      "Fold: 14  Epoch: 156  Training loss = 4.3317  Validation loss = 10.5861  \n",
      "\n",
      "Fold: 14  Epoch: 157  Training loss = 4.3313  Validation loss = 10.5855  \n",
      "\n",
      "Fold: 14  Epoch: 158  Training loss = 4.3309  Validation loss = 10.5849  \n",
      "\n",
      "Fold: 14  Epoch: 159  Training loss = 4.3304  Validation loss = 10.5842  \n",
      "\n",
      "Fold: 14  Epoch: 160  Training loss = 4.3300  Validation loss = 10.5835  \n",
      "\n",
      "Fold: 14  Epoch: 161  Training loss = 4.3296  Validation loss = 10.5830  \n",
      "\n",
      "Fold: 14  Epoch: 162  Training loss = 4.3291  Validation loss = 10.5822  \n",
      "\n",
      "Fold: 14  Epoch: 163  Training loss = 4.3286  Validation loss = 10.5814  \n",
      "\n",
      "Fold: 14  Epoch: 164  Training loss = 4.3282  Validation loss = 10.5808  \n",
      "\n",
      "Fold: 14  Epoch: 165  Training loss = 4.3278  Validation loss = 10.5801  \n",
      "\n",
      "Fold: 14  Epoch: 166  Training loss = 4.3274  Validation loss = 10.5794  \n",
      "\n",
      "Fold: 14  Epoch: 167  Training loss = 4.3269  Validation loss = 10.5787  \n",
      "\n",
      "Fold: 14  Epoch: 168  Training loss = 4.3265  Validation loss = 10.5780  \n",
      "\n",
      "Fold: 14  Epoch: 169  Training loss = 4.3261  Validation loss = 10.5774  \n",
      "\n",
      "Fold: 14  Epoch: 170  Training loss = 4.3256  Validation loss = 10.5767  \n",
      "\n",
      "Fold: 14  Epoch: 171  Training loss = 4.3252  Validation loss = 10.5761  \n",
      "\n",
      "Fold: 14  Epoch: 172  Training loss = 4.3247  Validation loss = 10.5753  \n",
      "\n",
      "Fold: 14  Epoch: 173  Training loss = 4.3243  Validation loss = 10.5747  \n",
      "\n",
      "Fold: 14  Epoch: 174  Training loss = 4.3239  Validation loss = 10.5740  \n",
      "\n",
      "Fold: 14  Epoch: 175  Training loss = 4.3235  Validation loss = 10.5734  \n",
      "\n",
      "Fold: 14  Epoch: 176  Training loss = 4.3230  Validation loss = 10.5727  \n",
      "\n",
      "Fold: 14  Epoch: 177  Training loss = 4.3225  Validation loss = 10.5720  \n",
      "\n",
      "Fold: 14  Epoch: 178  Training loss = 4.3221  Validation loss = 10.5712  \n",
      "\n",
      "Fold: 14  Epoch: 179  Training loss = 4.3216  Validation loss = 10.5706  \n",
      "\n",
      "Fold: 14  Epoch: 180  Training loss = 4.3212  Validation loss = 10.5699  \n",
      "\n",
      "Fold: 14  Epoch: 181  Training loss = 4.3208  Validation loss = 10.5692  \n",
      "\n",
      "Fold: 14  Epoch: 182  Training loss = 4.3203  Validation loss = 10.5685  \n",
      "\n",
      "Fold: 14  Epoch: 183  Training loss = 4.3198  Validation loss = 10.5678  \n",
      "\n",
      "Fold: 14  Epoch: 184  Training loss = 4.3194  Validation loss = 10.5671  \n",
      "\n",
      "Fold: 14  Epoch: 185  Training loss = 4.3189  Validation loss = 10.5664  \n",
      "\n",
      "Fold: 14  Epoch: 186  Training loss = 4.3186  Validation loss = 10.5658  \n",
      "\n",
      "Fold: 14  Epoch: 187  Training loss = 4.3181  Validation loss = 10.5651  \n",
      "\n",
      "Fold: 14  Epoch: 188  Training loss = 4.3176  Validation loss = 10.5644  \n",
      "\n",
      "Fold: 14  Epoch: 189  Training loss = 4.3172  Validation loss = 10.5638  \n",
      "\n",
      "Fold: 14  Epoch: 190  Training loss = 4.3168  Validation loss = 10.5631  \n",
      "\n",
      "Fold: 14  Epoch: 191  Training loss = 4.3164  Validation loss = 10.5625  \n",
      "\n",
      "Fold: 14  Epoch: 192  Training loss = 4.3159  Validation loss = 10.5618  \n",
      "\n",
      "Fold: 14  Epoch: 193  Training loss = 4.3156  Validation loss = 10.5613  \n",
      "\n",
      "Fold: 14  Epoch: 194  Training loss = 4.3153  Validation loss = 10.5607  \n",
      "\n",
      "Fold: 14  Epoch: 195  Training loss = 4.3148  Validation loss = 10.5601  \n",
      "\n",
      "Fold: 14  Epoch: 196  Training loss = 4.3144  Validation loss = 10.5593  \n",
      "\n",
      "Fold: 14  Epoch: 197  Training loss = 4.3139  Validation loss = 10.5586  \n",
      "\n",
      "Fold: 14  Epoch: 198  Training loss = 4.3135  Validation loss = 10.5579  \n",
      "\n",
      "Fold: 14  Epoch: 199  Training loss = 4.3130  Validation loss = 10.5572  \n",
      "\n",
      "Fold: 14  Epoch: 200  Training loss = 4.3126  Validation loss = 10.5566  \n",
      "\n",
      "Fold: 14  Epoch: 201  Training loss = 4.3121  Validation loss = 10.5558  \n",
      "\n",
      "Fold: 14  Epoch: 202  Training loss = 4.3117  Validation loss = 10.5552  \n",
      "\n",
      "Fold: 14  Epoch: 203  Training loss = 4.3113  Validation loss = 10.5546  \n",
      "\n",
      "Fold: 14  Epoch: 204  Training loss = 4.3110  Validation loss = 10.5540  \n",
      "\n",
      "Fold: 14  Epoch: 205  Training loss = 4.3106  Validation loss = 10.5535  \n",
      "\n",
      "Fold: 14  Epoch: 206  Training loss = 4.3102  Validation loss = 10.5529  \n",
      "\n",
      "Fold: 14  Epoch: 207  Training loss = 4.3099  Validation loss = 10.5523  \n",
      "\n",
      "Fold: 14  Epoch: 208  Training loss = 4.3093  Validation loss = 10.5515  \n",
      "\n",
      "Fold: 14  Epoch: 209  Training loss = 4.3089  Validation loss = 10.5509  \n",
      "\n",
      "Fold: 14  Epoch: 210  Training loss = 4.3085  Validation loss = 10.5501  \n",
      "\n",
      "Fold: 14  Epoch: 211  Training loss = 4.3080  Validation loss = 10.5494  \n",
      "\n",
      "Fold: 14  Epoch: 212  Training loss = 4.3076  Validation loss = 10.5487  \n",
      "\n",
      "Fold: 14  Epoch: 213  Training loss = 4.3070  Validation loss = 10.5479  \n",
      "\n",
      "Fold: 14  Epoch: 214  Training loss = 4.3066  Validation loss = 10.5472  \n",
      "\n",
      "Fold: 14  Epoch: 215  Training loss = 4.3060  Validation loss = 10.5463  \n",
      "\n",
      "Fold: 14  Epoch: 216  Training loss = 4.3056  Validation loss = 10.5456  \n",
      "\n",
      "Fold: 14  Epoch: 217  Training loss = 4.3052  Validation loss = 10.5450  \n",
      "\n",
      "Fold: 14  Epoch: 218  Training loss = 4.3047  Validation loss = 10.5442  \n",
      "\n",
      "Fold: 14  Epoch: 219  Training loss = 4.3043  Validation loss = 10.5436  \n",
      "\n",
      "Fold: 14  Epoch: 220  Training loss = 4.3038  Validation loss = 10.5429  \n",
      "\n",
      "Fold: 14  Epoch: 221  Training loss = 4.3034  Validation loss = 10.5422  \n",
      "\n",
      "Fold: 14  Epoch: 222  Training loss = 4.3030  Validation loss = 10.5416  \n",
      "\n",
      "Fold: 14  Epoch: 223  Training loss = 4.3026  Validation loss = 10.5410  \n",
      "\n",
      "Fold: 14  Epoch: 224  Training loss = 4.3022  Validation loss = 10.5404  \n",
      "\n",
      "Fold: 14  Epoch: 225  Training loss = 4.3019  Validation loss = 10.5398  \n",
      "\n",
      "Fold: 14  Epoch: 226  Training loss = 4.3015  Validation loss = 10.5392  \n",
      "\n",
      "Fold: 14  Epoch: 227  Training loss = 4.3010  Validation loss = 10.5385  \n",
      "\n",
      "Fold: 14  Epoch: 228  Training loss = 4.3005  Validation loss = 10.5377  \n",
      "\n",
      "Fold: 14  Epoch: 229  Training loss = 4.3001  Validation loss = 10.5371  \n",
      "\n",
      "Fold: 14  Epoch: 230  Training loss = 4.2996  Validation loss = 10.5363  \n",
      "\n",
      "Fold: 14  Epoch: 231  Training loss = 4.2991  Validation loss = 10.5356  \n",
      "\n",
      "Fold: 14  Epoch: 232  Training loss = 4.2987  Validation loss = 10.5349  \n",
      "\n",
      "Fold: 14  Epoch: 233  Training loss = 4.2984  Validation loss = 10.5344  \n",
      "\n",
      "Fold: 14  Epoch: 234  Training loss = 4.2978  Validation loss = 10.5336  \n",
      "\n",
      "Fold: 14  Epoch: 235  Training loss = 4.2974  Validation loss = 10.5329  \n",
      "\n",
      "Fold: 14  Epoch: 236  Training loss = 4.2970  Validation loss = 10.5322  \n",
      "\n",
      "Fold: 14  Epoch: 237  Training loss = 4.2966  Validation loss = 10.5316  \n",
      "\n",
      "Fold: 14  Epoch: 238  Training loss = 4.2961  Validation loss = 10.5309  \n",
      "\n",
      "Fold: 14  Epoch: 239  Training loss = 4.2957  Validation loss = 10.5302  \n",
      "\n",
      "Fold: 14  Epoch: 240  Training loss = 4.2953  Validation loss = 10.5296  \n",
      "\n",
      "Fold: 14  Epoch: 241  Training loss = 4.2949  Validation loss = 10.5289  \n",
      "\n",
      "Fold: 14  Epoch: 242  Training loss = 4.2945  Validation loss = 10.5283  \n",
      "\n",
      "Fold: 14  Epoch: 243  Training loss = 4.2941  Validation loss = 10.5277  \n",
      "\n",
      "Fold: 14  Epoch: 244  Training loss = 4.2936  Validation loss = 10.5269  \n",
      "\n",
      "Fold: 14  Epoch: 245  Training loss = 4.2931  Validation loss = 10.5263  \n",
      "\n",
      "Fold: 14  Epoch: 246  Training loss = 4.2927  Validation loss = 10.5256  \n",
      "\n",
      "Fold: 14  Epoch: 247  Training loss = 4.2923  Validation loss = 10.5250  \n",
      "\n",
      "Fold: 14  Epoch: 248  Training loss = 4.2919  Validation loss = 10.5244  \n",
      "\n",
      "Fold: 14  Epoch: 249  Training loss = 4.2916  Validation loss = 10.5239  \n",
      "\n",
      "Fold: 14  Epoch: 250  Training loss = 4.2912  Validation loss = 10.5232  \n",
      "\n",
      "Fold: 14  Epoch: 251  Training loss = 4.2907  Validation loss = 10.5225  \n",
      "\n",
      "Fold: 14  Epoch: 252  Training loss = 4.2903  Validation loss = 10.5219  \n",
      "\n",
      "Fold: 14  Epoch: 253  Training loss = 4.2898  Validation loss = 10.5211  \n",
      "\n",
      "Fold: 14  Epoch: 254  Training loss = 4.2894  Validation loss = 10.5204  \n",
      "\n",
      "Fold: 14  Epoch: 255  Training loss = 4.2889  Validation loss = 10.5196  \n",
      "\n",
      "Fold: 14  Epoch: 256  Training loss = 4.2884  Validation loss = 10.5188  \n",
      "\n",
      "Fold: 14  Epoch: 257  Training loss = 4.2880  Validation loss = 10.5182  \n",
      "\n",
      "Fold: 14  Epoch: 258  Training loss = 4.2876  Validation loss = 10.5175  \n",
      "\n",
      "Fold: 14  Epoch: 259  Training loss = 4.2872  Validation loss = 10.5170  \n",
      "\n",
      "Fold: 14  Epoch: 260  Training loss = 4.2867  Validation loss = 10.5163  \n",
      "\n",
      "Fold: 14  Epoch: 261  Training loss = 4.2863  Validation loss = 10.5155  \n",
      "\n",
      "Fold: 14  Epoch: 262  Training loss = 4.2858  Validation loss = 10.5149  \n",
      "\n",
      "Fold: 14  Epoch: 263  Training loss = 4.2854  Validation loss = 10.5143  \n",
      "\n",
      "Fold: 14  Epoch: 264  Training loss = 4.2850  Validation loss = 10.5136  \n",
      "\n",
      "Fold: 14  Epoch: 265  Training loss = 4.2845  Validation loss = 10.5127  \n",
      "\n",
      "Fold: 14  Epoch: 266  Training loss = 4.2840  Validation loss = 10.5121  \n",
      "\n",
      "Fold: 14  Epoch: 267  Training loss = 4.2835  Validation loss = 10.5112  \n",
      "\n",
      "Fold: 14  Epoch: 268  Training loss = 4.2831  Validation loss = 10.5107  \n",
      "\n",
      "Fold: 14  Epoch: 269  Training loss = 4.2827  Validation loss = 10.5100  \n",
      "\n",
      "Fold: 14  Epoch: 270  Training loss = 4.2822  Validation loss = 10.5092  \n",
      "\n",
      "Fold: 14  Epoch: 271  Training loss = 4.2818  Validation loss = 10.5086  \n",
      "\n",
      "Fold: 14  Epoch: 272  Training loss = 4.2814  Validation loss = 10.5079  \n",
      "\n",
      "Fold: 14  Epoch: 273  Training loss = 4.2809  Validation loss = 10.5072  \n",
      "\n",
      "Fold: 14  Epoch: 274  Training loss = 4.2804  Validation loss = 10.5064  \n",
      "\n",
      "Fold: 14  Epoch: 275  Training loss = 4.2801  Validation loss = 10.5059  \n",
      "\n",
      "Fold: 14  Epoch: 276  Training loss = 4.2797  Validation loss = 10.5052  \n",
      "\n",
      "Fold: 14  Epoch: 277  Training loss = 4.2793  Validation loss = 10.5046  \n",
      "\n",
      "Fold: 14  Epoch: 278  Training loss = 4.2789  Validation loss = 10.5041  \n",
      "\n",
      "Fold: 14  Epoch: 279  Training loss = 4.2786  Validation loss = 10.5035  \n",
      "\n",
      "Fold: 14  Epoch: 280  Training loss = 4.2782  Validation loss = 10.5029  \n",
      "\n",
      "Fold: 14  Epoch: 281  Training loss = 4.2778  Validation loss = 10.5023  \n",
      "\n",
      "Fold: 14  Epoch: 282  Training loss = 4.2773  Validation loss = 10.5016  \n",
      "\n",
      "Fold: 14  Epoch: 283  Training loss = 4.2770  Validation loss = 10.5010  \n",
      "\n",
      "Fold: 14  Epoch: 284  Training loss = 4.2767  Validation loss = 10.5005  \n",
      "\n",
      "Fold: 14  Epoch: 285  Training loss = 4.2762  Validation loss = 10.4997  \n",
      "\n",
      "Fold: 14  Epoch: 286  Training loss = 4.2758  Validation loss = 10.4991  \n",
      "\n",
      "Fold: 14  Epoch: 287  Training loss = 4.2753  Validation loss = 10.4985  \n",
      "\n",
      "Fold: 14  Epoch: 288  Training loss = 4.2749  Validation loss = 10.4978  \n",
      "\n",
      "Fold: 14  Epoch: 289  Training loss = 4.2745  Validation loss = 10.4971  \n",
      "\n",
      "Fold: 14  Epoch: 290  Training loss = 4.2741  Validation loss = 10.4964  \n",
      "\n",
      "Fold: 14  Epoch: 291  Training loss = 4.2737  Validation loss = 10.4959  \n",
      "\n",
      "Fold: 14  Epoch: 292  Training loss = 4.2732  Validation loss = 10.4952  \n",
      "\n",
      "Fold: 14  Epoch: 293  Training loss = 4.2728  Validation loss = 10.4945  \n",
      "\n",
      "Fold: 14  Epoch: 294  Training loss = 4.2724  Validation loss = 10.4938  \n",
      "\n",
      "Fold: 14  Epoch: 295  Training loss = 4.2719  Validation loss = 10.4931  \n",
      "\n",
      "Fold: 14  Epoch: 296  Training loss = 4.2715  Validation loss = 10.4925  \n",
      "\n",
      "Fold: 14  Epoch: 297  Training loss = 4.2711  Validation loss = 10.4919  \n",
      "\n",
      "Fold: 14  Epoch: 298  Training loss = 4.2707  Validation loss = 10.4912  \n",
      "\n",
      "Fold: 14  Epoch: 299  Training loss = 4.2704  Validation loss = 10.4907  \n",
      "\n",
      "Fold: 14  Epoch: 300  Training loss = 4.2699  Validation loss = 10.4900  \n",
      "\n",
      "Fold: 14  Epoch: 301  Training loss = 4.2694  Validation loss = 10.4892  \n",
      "\n",
      "Fold: 14  Epoch: 302  Training loss = 4.2690  Validation loss = 10.4886  \n",
      "\n",
      "Fold: 14  Epoch: 303  Training loss = 4.2686  Validation loss = 10.4879  \n",
      "\n",
      "Fold: 14  Epoch: 304  Training loss = 4.2681  Validation loss = 10.4871  \n",
      "\n",
      "Fold: 14  Epoch: 305  Training loss = 4.2678  Validation loss = 10.4866  \n",
      "\n",
      "Fold: 14  Epoch: 306  Training loss = 4.2673  Validation loss = 10.4859  \n",
      "\n",
      "Fold: 14  Epoch: 307  Training loss = 4.2669  Validation loss = 10.4853  \n",
      "\n",
      "Fold: 14  Epoch: 308  Training loss = 4.2665  Validation loss = 10.4847  \n",
      "\n",
      "Fold: 14  Epoch: 309  Training loss = 4.2661  Validation loss = 10.4840  \n",
      "\n",
      "Fold: 14  Epoch: 310  Training loss = 4.2657  Validation loss = 10.4834  \n",
      "\n",
      "Fold: 14  Epoch: 311  Training loss = 4.2652  Validation loss = 10.4827  \n",
      "\n",
      "Fold: 14  Epoch: 312  Training loss = 4.2649  Validation loss = 10.4821  \n",
      "\n",
      "Fold: 14  Epoch: 313  Training loss = 4.2644  Validation loss = 10.4813  \n",
      "\n",
      "Fold: 14  Epoch: 314  Training loss = 4.2639  Validation loss = 10.4806  \n",
      "\n",
      "Fold: 14  Epoch: 315  Training loss = 4.2635  Validation loss = 10.4800  \n",
      "\n",
      "Fold: 14  Epoch: 316  Training loss = 4.2631  Validation loss = 10.4793  \n",
      "\n",
      "Fold: 14  Epoch: 317  Training loss = 4.2628  Validation loss = 10.4788  \n",
      "\n",
      "Fold: 14  Epoch: 318  Training loss = 4.2624  Validation loss = 10.4782  \n",
      "\n",
      "Fold: 14  Epoch: 319  Training loss = 4.2620  Validation loss = 10.4776  \n",
      "\n",
      "Fold: 14  Epoch: 320  Training loss = 4.2616  Validation loss = 10.4770  \n",
      "\n",
      "Fold: 14  Epoch: 321  Training loss = 4.2611  Validation loss = 10.4762  \n",
      "\n",
      "Fold: 14  Epoch: 322  Training loss = 4.2606  Validation loss = 10.4754  \n",
      "\n",
      "Fold: 14  Epoch: 323  Training loss = 4.2602  Validation loss = 10.4748  \n",
      "\n",
      "Fold: 14  Epoch: 324  Training loss = 4.2598  Validation loss = 10.4742  \n",
      "\n",
      "Fold: 14  Epoch: 325  Training loss = 4.2594  Validation loss = 10.4735  \n",
      "\n",
      "Fold: 14  Epoch: 326  Training loss = 4.2589  Validation loss = 10.4728  \n",
      "\n",
      "Fold: 14  Epoch: 327  Training loss = 4.2585  Validation loss = 10.4722  \n",
      "\n",
      "Fold: 14  Epoch: 328  Training loss = 4.2579  Validation loss = 10.4712  \n",
      "\n",
      "Fold: 14  Epoch: 329  Training loss = 4.2575  Validation loss = 10.4706  \n",
      "\n",
      "Fold: 14  Epoch: 330  Training loss = 4.2571  Validation loss = 10.4699  \n",
      "\n",
      "Fold: 14  Epoch: 331  Training loss = 4.2567  Validation loss = 10.4692  \n",
      "\n",
      "Fold: 14  Epoch: 332  Training loss = 4.2563  Validation loss = 10.4687  \n",
      "\n",
      "Fold: 14  Epoch: 333  Training loss = 4.2559  Validation loss = 10.4680  \n",
      "\n",
      "Fold: 14  Epoch: 334  Training loss = 4.2555  Validation loss = 10.4673  \n",
      "\n",
      "Fold: 14  Epoch: 335  Training loss = 4.2550  Validation loss = 10.4667  \n",
      "\n",
      "Fold: 14  Epoch: 336  Training loss = 4.2547  Validation loss = 10.4661  \n",
      "\n",
      "Fold: 14  Epoch: 337  Training loss = 4.2542  Validation loss = 10.4654  \n",
      "\n",
      "Fold: 14  Epoch: 338  Training loss = 4.2538  Validation loss = 10.4648  \n",
      "\n",
      "Fold: 14  Epoch: 339  Training loss = 4.2533  Validation loss = 10.4640  \n",
      "\n",
      "Fold: 14  Epoch: 340  Training loss = 4.2528  Validation loss = 10.4632  \n",
      "\n",
      "Fold: 14  Epoch: 341  Training loss = 4.2524  Validation loss = 10.4625  \n",
      "\n",
      "Fold: 14  Epoch: 342  Training loss = 4.2520  Validation loss = 10.4619  \n",
      "\n",
      "Fold: 14  Epoch: 343  Training loss = 4.2516  Validation loss = 10.4613  \n",
      "\n",
      "Fold: 14  Epoch: 344  Training loss = 4.2512  Validation loss = 10.4606  \n",
      "\n",
      "Fold: 14  Epoch: 345  Training loss = 4.2509  Validation loss = 10.4602  \n",
      "\n",
      "Fold: 14  Epoch: 346  Training loss = 4.2505  Validation loss = 10.4596  \n",
      "\n",
      "Fold: 14  Epoch: 347  Training loss = 4.2500  Validation loss = 10.4588  \n",
      "\n",
      "Fold: 14  Epoch: 348  Training loss = 4.2496  Validation loss = 10.4581  \n",
      "\n",
      "Fold: 14  Epoch: 349  Training loss = 4.2491  Validation loss = 10.4574  \n",
      "\n",
      "Fold: 14  Epoch: 350  Training loss = 4.2486  Validation loss = 10.4567  \n",
      "\n",
      "Fold: 14  Epoch: 351  Training loss = 4.2483  Validation loss = 10.4561  \n",
      "\n",
      "Fold: 14  Epoch: 352  Training loss = 4.2479  Validation loss = 10.4554  \n",
      "\n",
      "Fold: 14  Epoch: 353  Training loss = 4.2475  Validation loss = 10.4549  \n",
      "\n",
      "Fold: 14  Epoch: 354  Training loss = 4.2471  Validation loss = 10.4542  \n",
      "\n",
      "Fold: 14  Epoch: 355  Training loss = 4.2467  Validation loss = 10.4536  \n",
      "\n",
      "Fold: 14  Epoch: 356  Training loss = 4.2462  Validation loss = 10.4529  \n",
      "\n",
      "Fold: 14  Epoch: 357  Training loss = 4.2458  Validation loss = 10.4522  \n",
      "\n",
      "Fold: 14  Epoch: 358  Training loss = 4.2454  Validation loss = 10.4515  \n",
      "\n",
      "Fold: 14  Epoch: 359  Training loss = 4.2449  Validation loss = 10.4508  \n",
      "\n",
      "Fold: 14  Epoch: 360  Training loss = 4.2446  Validation loss = 10.4502  \n",
      "\n",
      "Fold: 14  Epoch: 361  Training loss = 4.2440  Validation loss = 10.4494  \n",
      "\n",
      "Fold: 14  Epoch: 362  Training loss = 4.2436  Validation loss = 10.4488  \n",
      "\n",
      "Fold: 14  Epoch: 363  Training loss = 4.2431  Validation loss = 10.4480  \n",
      "\n",
      "Fold: 14  Epoch: 364  Training loss = 4.2428  Validation loss = 10.4474  \n",
      "\n",
      "Fold: 14  Epoch: 365  Training loss = 4.2423  Validation loss = 10.4467  \n",
      "\n",
      "Fold: 14  Epoch: 366  Training loss = 4.2419  Validation loss = 10.4461  \n",
      "\n",
      "Fold: 14  Epoch: 367  Training loss = 4.2414  Validation loss = 10.4453  \n",
      "\n",
      "Fold: 14  Epoch: 368  Training loss = 4.2410  Validation loss = 10.4446  \n",
      "\n",
      "Fold: 14  Epoch: 369  Training loss = 4.2406  Validation loss = 10.4440  \n",
      "\n",
      "Fold: 14  Epoch: 370  Training loss = 4.2402  Validation loss = 10.4434  \n",
      "\n",
      "Fold: 14  Epoch: 371  Training loss = 4.2397  Validation loss = 10.4427  \n",
      "\n",
      "Fold: 14  Epoch: 372  Training loss = 4.2393  Validation loss = 10.4420  \n",
      "\n",
      "Fold: 14  Epoch: 373  Training loss = 4.2388  Validation loss = 10.4413  \n",
      "\n",
      "Fold: 14  Epoch: 374  Training loss = 4.2384  Validation loss = 10.4406  \n",
      "\n",
      "Fold: 14  Epoch: 375  Training loss = 4.2380  Validation loss = 10.4399  \n",
      "\n",
      "Fold: 14  Epoch: 376  Training loss = 4.2376  Validation loss = 10.4393  \n",
      "\n",
      "Fold: 14  Epoch: 377  Training loss = 4.2372  Validation loss = 10.4387  \n",
      "\n",
      "Fold: 14  Epoch: 378  Training loss = 4.2368  Validation loss = 10.4381  \n",
      "\n",
      "Fold: 14  Epoch: 379  Training loss = 4.2364  Validation loss = 10.4374  \n",
      "\n",
      "Fold: 14  Epoch: 380  Training loss = 4.2360  Validation loss = 10.4369  \n",
      "\n",
      "Fold: 14  Epoch: 381  Training loss = 4.2356  Validation loss = 10.4362  \n",
      "\n",
      "Fold: 14  Epoch: 382  Training loss = 4.2352  Validation loss = 10.4355  \n",
      "\n",
      "Fold: 14  Epoch: 383  Training loss = 4.2348  Validation loss = 10.4349  \n",
      "\n",
      "Fold: 14  Epoch: 384  Training loss = 4.2344  Validation loss = 10.4342  \n",
      "\n",
      "Fold: 14  Epoch: 385  Training loss = 4.2339  Validation loss = 10.4335  \n",
      "\n",
      "Fold: 14  Epoch: 386  Training loss = 4.2335  Validation loss = 10.4328  \n",
      "\n",
      "Fold: 14  Epoch: 387  Training loss = 4.2330  Validation loss = 10.4321  \n",
      "\n",
      "Fold: 14  Epoch: 388  Training loss = 4.2326  Validation loss = 10.4315  \n",
      "\n",
      "Fold: 14  Epoch: 389  Training loss = 4.2322  Validation loss = 10.4309  \n",
      "\n",
      "Fold: 14  Epoch: 390  Training loss = 4.2318  Validation loss = 10.4302  \n",
      "\n",
      "Fold: 14  Epoch: 391  Training loss = 4.2313  Validation loss = 10.4295  \n",
      "\n",
      "Fold: 14  Epoch: 392  Training loss = 4.2309  Validation loss = 10.4288  \n",
      "\n",
      "Fold: 14  Epoch: 393  Training loss = 4.2305  Validation loss = 10.4282  \n",
      "\n",
      "Fold: 14  Epoch: 394  Training loss = 4.2301  Validation loss = 10.4275  \n",
      "\n",
      "Fold: 14  Epoch: 395  Training loss = 4.2297  Validation loss = 10.4269  \n",
      "\n",
      "Fold: 14  Epoch: 396  Training loss = 4.2292  Validation loss = 10.4261  \n",
      "\n",
      "Fold: 14  Epoch: 397  Training loss = 4.2289  Validation loss = 10.4256  \n",
      "\n",
      "Fold: 14  Epoch: 398  Training loss = 4.2285  Validation loss = 10.4250  \n",
      "\n",
      "Fold: 14  Epoch: 399  Training loss = 4.2279  Validation loss = 10.4240  \n",
      "\n",
      "Fold: 14  Epoch: 400  Training loss = 4.2275  Validation loss = 10.4234  \n",
      "\n",
      "Fold: 14  Epoch: 401  Training loss = 4.2270  Validation loss = 10.4227  \n",
      "\n",
      "Fold: 14  Epoch: 402  Training loss = 4.2267  Validation loss = 10.4222  \n",
      "\n",
      "Fold: 14  Epoch: 403  Training loss = 4.2263  Validation loss = 10.4215  \n",
      "\n",
      "Fold: 14  Epoch: 404  Training loss = 4.2259  Validation loss = 10.4209  \n",
      "\n",
      "Fold: 14  Epoch: 405  Training loss = 4.2254  Validation loss = 10.4202  \n",
      "\n",
      "Fold: 14  Epoch: 406  Training loss = 4.2251  Validation loss = 10.4196  \n",
      "\n",
      "Fold: 14  Epoch: 407  Training loss = 4.2247  Validation loss = 10.4190  \n",
      "\n",
      "Fold: 14  Epoch: 408  Training loss = 4.2242  Validation loss = 10.4183  \n",
      "\n",
      "Fold: 14  Epoch: 409  Training loss = 4.2239  Validation loss = 10.4178  \n",
      "\n",
      "Fold: 14  Epoch: 410  Training loss = 4.2235  Validation loss = 10.4172  \n",
      "\n",
      "Fold: 14  Epoch: 411  Training loss = 4.2231  Validation loss = 10.4166  \n",
      "\n",
      "Fold: 14  Epoch: 412  Training loss = 4.2228  Validation loss = 10.4160  \n",
      "\n",
      "Fold: 14  Epoch: 413  Training loss = 4.2224  Validation loss = 10.4154  \n",
      "\n",
      "Fold: 14  Epoch: 414  Training loss = 4.2219  Validation loss = 10.4146  \n",
      "\n",
      "Fold: 14  Epoch: 415  Training loss = 4.2214  Validation loss = 10.4139  \n",
      "\n",
      "Fold: 14  Epoch: 416  Training loss = 4.2210  Validation loss = 10.4132  \n",
      "\n",
      "Fold: 14  Epoch: 417  Training loss = 4.2205  Validation loss = 10.4124  \n",
      "\n",
      "Fold: 14  Epoch: 418  Training loss = 4.2201  Validation loss = 10.4119  \n",
      "\n",
      "Fold: 14  Epoch: 419  Training loss = 4.2196  Validation loss = 10.4111  \n",
      "\n",
      "Fold: 14  Epoch: 420  Training loss = 4.2191  Validation loss = 10.4104  \n",
      "\n",
      "Fold: 14  Epoch: 421  Training loss = 4.2187  Validation loss = 10.4097  \n",
      "\n",
      "Fold: 14  Epoch: 422  Training loss = 4.2183  Validation loss = 10.4090  \n",
      "\n",
      "Fold: 14  Epoch: 423  Training loss = 4.2178  Validation loss = 10.4083  \n",
      "\n",
      "Fold: 14  Epoch: 424  Training loss = 4.2174  Validation loss = 10.4077  \n",
      "\n",
      "Fold: 14  Epoch: 425  Training loss = 4.2170  Validation loss = 10.4069  \n",
      "\n",
      "Fold: 14  Epoch: 426  Training loss = 4.2166  Validation loss = 10.4064  \n",
      "\n",
      "Fold: 14  Epoch: 427  Training loss = 4.2161  Validation loss = 10.4057  \n",
      "\n",
      "Fold: 14  Epoch: 428  Training loss = 4.2158  Validation loss = 10.4051  \n",
      "\n",
      "Fold: 14  Epoch: 429  Training loss = 4.2153  Validation loss = 10.4044  \n",
      "\n",
      "Fold: 14  Epoch: 430  Training loss = 4.2149  Validation loss = 10.4037  \n",
      "\n",
      "Fold: 14  Epoch: 431  Training loss = 4.2144  Validation loss = 10.4030  \n",
      "\n",
      "Fold: 14  Epoch: 432  Training loss = 4.2140  Validation loss = 10.4023  \n",
      "\n",
      "Fold: 14  Epoch: 433  Training loss = 4.2135  Validation loss = 10.4016  \n",
      "\n",
      "Fold: 14  Epoch: 434  Training loss = 4.2129  Validation loss = 10.4007  \n",
      "\n",
      "Fold: 14  Epoch: 435  Training loss = 4.2125  Validation loss = 10.4000  \n",
      "\n",
      "Fold: 14  Epoch: 436  Training loss = 4.2122  Validation loss = 10.3995  \n",
      "\n",
      "Fold: 14  Epoch: 437  Training loss = 4.2117  Validation loss = 10.3988  \n",
      "\n",
      "Fold: 14  Epoch: 438  Training loss = 4.2113  Validation loss = 10.3982  \n",
      "\n",
      "Fold: 14  Epoch: 439  Training loss = 4.2110  Validation loss = 10.3976  \n",
      "\n",
      "Fold: 14  Epoch: 440  Training loss = 4.2106  Validation loss = 10.3970  \n",
      "\n",
      "Fold: 14  Epoch: 441  Training loss = 4.2102  Validation loss = 10.3963  \n",
      "\n",
      "Fold: 14  Epoch: 442  Training loss = 4.2097  Validation loss = 10.3956  \n",
      "\n",
      "Fold: 14  Epoch: 443  Training loss = 4.2092  Validation loss = 10.3948  \n",
      "\n",
      "Fold: 14  Epoch: 444  Training loss = 4.2087  Validation loss = 10.3940  \n",
      "\n",
      "Fold: 14  Epoch: 445  Training loss = 4.2083  Validation loss = 10.3933  \n",
      "\n",
      "Fold: 14  Epoch: 446  Training loss = 4.2078  Validation loss = 10.3927  \n",
      "\n",
      "Fold: 14  Epoch: 447  Training loss = 4.2073  Validation loss = 10.3919  \n",
      "\n",
      "Fold: 14  Epoch: 448  Training loss = 4.2068  Validation loss = 10.3911  \n",
      "\n",
      "Fold: 14  Epoch: 449  Training loss = 4.2064  Validation loss = 10.3904  \n",
      "\n",
      "Fold: 14  Epoch: 450  Training loss = 4.2060  Validation loss = 10.3897  \n",
      "\n",
      "Fold: 14  Epoch: 451  Training loss = 4.2055  Validation loss = 10.3890  \n",
      "\n",
      "Fold: 14  Epoch: 452  Training loss = 4.2051  Validation loss = 10.3883  \n",
      "\n",
      "Fold: 14  Epoch: 453  Training loss = 4.2046  Validation loss = 10.3876  \n",
      "\n",
      "Fold: 14  Epoch: 454  Training loss = 4.2043  Validation loss = 10.3870  \n",
      "\n",
      "Fold: 14  Epoch: 455  Training loss = 4.2038  Validation loss = 10.3863  \n",
      "\n",
      "Fold: 14  Epoch: 456  Training loss = 4.2033  Validation loss = 10.3856  \n",
      "\n",
      "Fold: 14  Epoch: 457  Training loss = 4.2029  Validation loss = 10.3850  \n",
      "\n",
      "Fold: 14  Epoch: 458  Training loss = 4.2025  Validation loss = 10.3843  \n",
      "\n",
      "Fold: 14  Epoch: 459  Training loss = 4.2021  Validation loss = 10.3837  \n",
      "\n",
      "Fold: 14  Epoch: 460  Training loss = 4.2017  Validation loss = 10.3830  \n",
      "\n",
      "Fold: 14  Epoch: 461  Training loss = 4.2013  Validation loss = 10.3823  \n",
      "\n",
      "Fold: 14  Epoch: 462  Training loss = 4.2008  Validation loss = 10.3816  \n",
      "\n",
      "Fold: 14  Epoch: 463  Training loss = 4.2004  Validation loss = 10.3809  \n",
      "\n",
      "Fold: 14  Epoch: 464  Training loss = 4.2000  Validation loss = 10.3804  \n",
      "\n",
      "Fold: 14  Epoch: 465  Training loss = 4.1997  Validation loss = 10.3798  \n",
      "\n",
      "Fold: 14  Epoch: 466  Training loss = 4.1992  Validation loss = 10.3791  \n",
      "\n",
      "Fold: 14  Epoch: 467  Training loss = 4.1988  Validation loss = 10.3785  \n",
      "\n",
      "Fold: 14  Epoch: 468  Training loss = 4.1983  Validation loss = 10.3777  \n",
      "\n",
      "Fold: 14  Epoch: 469  Training loss = 4.1980  Validation loss = 10.3771  \n",
      "\n",
      "Fold: 14  Epoch: 470  Training loss = 4.1975  Validation loss = 10.3765  \n",
      "\n",
      "Fold: 14  Epoch: 471  Training loss = 4.1972  Validation loss = 10.3759  \n",
      "\n",
      "Fold: 14  Epoch: 472  Training loss = 4.1968  Validation loss = 10.3753  \n",
      "\n",
      "Fold: 14  Epoch: 473  Training loss = 4.1964  Validation loss = 10.3747  \n",
      "\n",
      "Fold: 14  Epoch: 474  Training loss = 4.1960  Validation loss = 10.3741  \n",
      "\n",
      "Fold: 14  Epoch: 475  Training loss = 4.1955  Validation loss = 10.3733  \n",
      "\n",
      "Fold: 14  Epoch: 476  Training loss = 4.1951  Validation loss = 10.3727  \n",
      "\n",
      "Fold: 14  Epoch: 477  Training loss = 4.1947  Validation loss = 10.3721  \n",
      "\n",
      "Fold: 14  Epoch: 478  Training loss = 4.1943  Validation loss = 10.3714  \n",
      "\n",
      "Fold: 14  Epoch: 479  Training loss = 4.1939  Validation loss = 10.3708  \n",
      "\n",
      "Fold: 14  Epoch: 480  Training loss = 4.1934  Validation loss = 10.3700  \n",
      "\n",
      "Fold: 14  Epoch: 481  Training loss = 4.1930  Validation loss = 10.3693  \n",
      "\n",
      "Fold: 14  Epoch: 482  Training loss = 4.1925  Validation loss = 10.3687  \n",
      "\n",
      "Fold: 14  Epoch: 483  Training loss = 4.1922  Validation loss = 10.3681  \n",
      "\n",
      "Fold: 14  Epoch: 484  Training loss = 4.1917  Validation loss = 10.3674  \n",
      "\n",
      "Fold: 14  Epoch: 485  Training loss = 4.1913  Validation loss = 10.3667  \n",
      "\n",
      "Fold: 14  Epoch: 486  Training loss = 4.1908  Validation loss = 10.3661  \n",
      "\n",
      "Fold: 14  Epoch: 487  Training loss = 4.1905  Validation loss = 10.3655  \n",
      "\n",
      "Fold: 14  Epoch: 488  Training loss = 4.1900  Validation loss = 10.3648  \n",
      "\n",
      "Fold: 14  Epoch: 489  Training loss = 4.1896  Validation loss = 10.3641  \n",
      "\n",
      "Fold: 14  Epoch: 490  Training loss = 4.1893  Validation loss = 10.3636  \n",
      "\n",
      "Fold: 14  Epoch: 491  Training loss = 4.1888  Validation loss = 10.3629  \n",
      "\n",
      "Fold: 14  Epoch: 492  Training loss = 4.1884  Validation loss = 10.3623  \n",
      "\n",
      "Fold: 14  Epoch: 493  Training loss = 4.1881  Validation loss = 10.3617  \n",
      "\n",
      "Fold: 14  Epoch: 494  Training loss = 4.1876  Validation loss = 10.3609  \n",
      "\n",
      "Fold: 14  Epoch: 495  Training loss = 4.1871  Validation loss = 10.3603  \n",
      "\n",
      "Fold: 14  Epoch: 496  Training loss = 4.1868  Validation loss = 10.3597  \n",
      "\n",
      "Fold: 14  Epoch: 497  Training loss = 4.1863  Validation loss = 10.3590  \n",
      "\n",
      "Fold: 14  Epoch: 498  Training loss = 4.1859  Validation loss = 10.3583  \n",
      "\n",
      "Fold: 14  Epoch: 499  Training loss = 4.1854  Validation loss = 10.3575  \n",
      "\n",
      "Fold: 14  Epoch: 500  Training loss = 4.1849  Validation loss = 10.3567  \n",
      "\n",
      "Check model:  Fold: 14  Optimal epoch: 500  \n",
      "\n",
      "Fold: 15  Epoch: 1  Training loss = 4.9028  Validation loss = 10.7198  \n",
      "\n",
      "Fold: 15  Epoch: 2  Training loss = 4.9021  Validation loss = 10.7188  \n",
      "\n",
      "Fold: 15  Epoch: 3  Training loss = 4.9016  Validation loss = 10.7181  \n",
      "\n",
      "Fold: 15  Epoch: 4  Training loss = 4.9011  Validation loss = 10.7173  \n",
      "\n",
      "Fold: 15  Epoch: 5  Training loss = 4.9004  Validation loss = 10.7164  \n",
      "\n",
      "Fold: 15  Epoch: 6  Training loss = 4.8998  Validation loss = 10.7155  \n",
      "\n",
      "Fold: 15  Epoch: 7  Training loss = 4.8993  Validation loss = 10.7148  \n",
      "\n",
      "Fold: 15  Epoch: 8  Training loss = 4.8988  Validation loss = 10.7140  \n",
      "\n",
      "Fold: 15  Epoch: 9  Training loss = 4.8981  Validation loss = 10.7131  \n",
      "\n",
      "Fold: 15  Epoch: 10  Training loss = 4.8976  Validation loss = 10.7124  \n",
      "\n",
      "Fold: 15  Epoch: 11  Training loss = 4.8971  Validation loss = 10.7116  \n",
      "\n",
      "Fold: 15  Epoch: 12  Training loss = 4.8966  Validation loss = 10.7110  \n",
      "\n",
      "Fold: 15  Epoch: 13  Training loss = 4.8960  Validation loss = 10.7101  \n",
      "\n",
      "Fold: 15  Epoch: 14  Training loss = 4.8954  Validation loss = 10.7093  \n",
      "\n",
      "Fold: 15  Epoch: 15  Training loss = 4.8950  Validation loss = 10.7086  \n",
      "\n",
      "Fold: 15  Epoch: 16  Training loss = 4.8944  Validation loss = 10.7077  \n",
      "\n",
      "Fold: 15  Epoch: 17  Training loss = 4.8937  Validation loss = 10.7068  \n",
      "\n",
      "Fold: 15  Epoch: 18  Training loss = 4.8932  Validation loss = 10.7061  \n",
      "\n",
      "Fold: 15  Epoch: 19  Training loss = 4.8927  Validation loss = 10.7053  \n",
      "\n",
      "Fold: 15  Epoch: 20  Training loss = 4.8921  Validation loss = 10.7044  \n",
      "\n",
      "Fold: 15  Epoch: 21  Training loss = 4.8915  Validation loss = 10.7035  \n",
      "\n",
      "Fold: 15  Epoch: 22  Training loss = 4.8908  Validation loss = 10.7026  \n",
      "\n",
      "Fold: 15  Epoch: 23  Training loss = 4.8902  Validation loss = 10.7018  \n",
      "\n",
      "Fold: 15  Epoch: 24  Training loss = 4.8896  Validation loss = 10.7009  \n",
      "\n",
      "Fold: 15  Epoch: 25  Training loss = 4.8891  Validation loss = 10.7001  \n",
      "\n",
      "Fold: 15  Epoch: 26  Training loss = 4.8884  Validation loss = 10.6992  \n",
      "\n",
      "Fold: 15  Epoch: 27  Training loss = 4.8878  Validation loss = 10.6983  \n",
      "\n",
      "Fold: 15  Epoch: 28  Training loss = 4.8872  Validation loss = 10.6974  \n",
      "\n",
      "Fold: 15  Epoch: 29  Training loss = 4.8866  Validation loss = 10.6965  \n",
      "\n",
      "Fold: 15  Epoch: 30  Training loss = 4.8860  Validation loss = 10.6957  \n",
      "\n",
      "Fold: 15  Epoch: 31  Training loss = 4.8854  Validation loss = 10.6949  \n",
      "\n",
      "Fold: 15  Epoch: 32  Training loss = 4.8850  Validation loss = 10.6942  \n",
      "\n",
      "Fold: 15  Epoch: 33  Training loss = 4.8843  Validation loss = 10.6932  \n",
      "\n",
      "Fold: 15  Epoch: 34  Training loss = 4.8838  Validation loss = 10.6925  \n",
      "\n",
      "Fold: 15  Epoch: 35  Training loss = 4.8832  Validation loss = 10.6917  \n",
      "\n",
      "Fold: 15  Epoch: 36  Training loss = 4.8826  Validation loss = 10.6908  \n",
      "\n",
      "Fold: 15  Epoch: 37  Training loss = 4.8821  Validation loss = 10.6900  \n",
      "\n",
      "Fold: 15  Epoch: 38  Training loss = 4.8814  Validation loss = 10.6890  \n",
      "\n",
      "Fold: 15  Epoch: 39  Training loss = 4.8809  Validation loss = 10.6883  \n",
      "\n",
      "Fold: 15  Epoch: 40  Training loss = 4.8803  Validation loss = 10.6874  \n",
      "\n",
      "Fold: 15  Epoch: 41  Training loss = 4.8796  Validation loss = 10.6865  \n",
      "\n",
      "Fold: 15  Epoch: 42  Training loss = 4.8791  Validation loss = 10.6857  \n",
      "\n",
      "Fold: 15  Epoch: 43  Training loss = 4.8785  Validation loss = 10.6849  \n",
      "\n",
      "Fold: 15  Epoch: 44  Training loss = 4.8780  Validation loss = 10.6841  \n",
      "\n",
      "Fold: 15  Epoch: 45  Training loss = 4.8774  Validation loss = 10.6832  \n",
      "\n",
      "Fold: 15  Epoch: 46  Training loss = 4.8767  Validation loss = 10.6823  \n",
      "\n",
      "Fold: 15  Epoch: 47  Training loss = 4.8760  Validation loss = 10.6812  \n",
      "\n",
      "Fold: 15  Epoch: 48  Training loss = 4.8753  Validation loss = 10.6803  \n",
      "\n",
      "Fold: 15  Epoch: 49  Training loss = 4.8747  Validation loss = 10.6794  \n",
      "\n",
      "Fold: 15  Epoch: 50  Training loss = 4.8741  Validation loss = 10.6785  \n",
      "\n",
      "Fold: 15  Epoch: 51  Training loss = 4.8737  Validation loss = 10.6779  \n",
      "\n",
      "Fold: 15  Epoch: 52  Training loss = 4.8731  Validation loss = 10.6771  \n",
      "\n",
      "Fold: 15  Epoch: 53  Training loss = 4.8726  Validation loss = 10.6763  \n",
      "\n",
      "Fold: 15  Epoch: 54  Training loss = 4.8719  Validation loss = 10.6754  \n",
      "\n",
      "Fold: 15  Epoch: 55  Training loss = 4.8713  Validation loss = 10.6745  \n",
      "\n",
      "Fold: 15  Epoch: 56  Training loss = 4.8707  Validation loss = 10.6737  \n",
      "\n",
      "Fold: 15  Epoch: 57  Training loss = 4.8702  Validation loss = 10.6729  \n",
      "\n",
      "Fold: 15  Epoch: 58  Training loss = 4.8697  Validation loss = 10.6722  \n",
      "\n",
      "Fold: 15  Epoch: 59  Training loss = 4.8693  Validation loss = 10.6716  \n",
      "\n",
      "Fold: 15  Epoch: 60  Training loss = 4.8687  Validation loss = 10.6708  \n",
      "\n",
      "Fold: 15  Epoch: 61  Training loss = 4.8682  Validation loss = 10.6701  \n",
      "\n",
      "Fold: 15  Epoch: 62  Training loss = 4.8676  Validation loss = 10.6693  \n",
      "\n",
      "Fold: 15  Epoch: 63  Training loss = 4.8671  Validation loss = 10.6685  \n",
      "\n",
      "Fold: 15  Epoch: 64  Training loss = 4.8667  Validation loss = 10.6679  \n",
      "\n",
      "Fold: 15  Epoch: 65  Training loss = 4.8660  Validation loss = 10.6670  \n",
      "\n",
      "Fold: 15  Epoch: 66  Training loss = 4.8655  Validation loss = 10.6663  \n",
      "\n",
      "Fold: 15  Epoch: 67  Training loss = 4.8651  Validation loss = 10.6656  \n",
      "\n",
      "Fold: 15  Epoch: 68  Training loss = 4.8645  Validation loss = 10.6648  \n",
      "\n",
      "Fold: 15  Epoch: 69  Training loss = 4.8639  Validation loss = 10.6639  \n",
      "\n",
      "Fold: 15  Epoch: 70  Training loss = 4.8635  Validation loss = 10.6633  \n",
      "\n",
      "Fold: 15  Epoch: 71  Training loss = 4.8628  Validation loss = 10.6624  \n",
      "\n",
      "Fold: 15  Epoch: 72  Training loss = 4.8622  Validation loss = 10.6616  \n",
      "\n",
      "Fold: 15  Epoch: 73  Training loss = 4.8617  Validation loss = 10.6609  \n",
      "\n",
      "Fold: 15  Epoch: 74  Training loss = 4.8612  Validation loss = 10.6600  \n",
      "\n",
      "Fold: 15  Epoch: 75  Training loss = 4.8606  Validation loss = 10.6593  \n",
      "\n",
      "Fold: 15  Epoch: 76  Training loss = 4.8600  Validation loss = 10.6584  \n",
      "\n",
      "Fold: 15  Epoch: 77  Training loss = 4.8596  Validation loss = 10.6578  \n",
      "\n",
      "Fold: 15  Epoch: 78  Training loss = 4.8590  Validation loss = 10.6570  \n",
      "\n",
      "Fold: 15  Epoch: 79  Training loss = 4.8585  Validation loss = 10.6562  \n",
      "\n",
      "Fold: 15  Epoch: 80  Training loss = 4.8580  Validation loss = 10.6555  \n",
      "\n",
      "Fold: 15  Epoch: 81  Training loss = 4.8574  Validation loss = 10.6547  \n",
      "\n",
      "Fold: 15  Epoch: 82  Training loss = 4.8569  Validation loss = 10.6539  \n",
      "\n",
      "Fold: 15  Epoch: 83  Training loss = 4.8563  Validation loss = 10.6531  \n",
      "\n",
      "Fold: 15  Epoch: 84  Training loss = 4.8558  Validation loss = 10.6523  \n",
      "\n",
      "Fold: 15  Epoch: 85  Training loss = 4.8551  Validation loss = 10.6514  \n",
      "\n",
      "Fold: 15  Epoch: 86  Training loss = 4.8546  Validation loss = 10.6507  \n",
      "\n",
      "Fold: 15  Epoch: 87  Training loss = 4.8541  Validation loss = 10.6499  \n",
      "\n",
      "Fold: 15  Epoch: 88  Training loss = 4.8535  Validation loss = 10.6490  \n",
      "\n",
      "Fold: 15  Epoch: 89  Training loss = 4.8531  Validation loss = 10.6484  \n",
      "\n",
      "Fold: 15  Epoch: 90  Training loss = 4.8524  Validation loss = 10.6475  \n",
      "\n",
      "Fold: 15  Epoch: 91  Training loss = 4.8518  Validation loss = 10.6466  \n",
      "\n",
      "Fold: 15  Epoch: 92  Training loss = 4.8512  Validation loss = 10.6458  \n",
      "\n",
      "Fold: 15  Epoch: 93  Training loss = 4.8507  Validation loss = 10.6450  \n",
      "\n",
      "Fold: 15  Epoch: 94  Training loss = 4.8503  Validation loss = 10.6444  \n",
      "\n",
      "Fold: 15  Epoch: 95  Training loss = 4.8498  Validation loss = 10.6438  \n",
      "\n",
      "Fold: 15  Epoch: 96  Training loss = 4.8494  Validation loss = 10.6431  \n",
      "\n",
      "Fold: 15  Epoch: 97  Training loss = 4.8488  Validation loss = 10.6423  \n",
      "\n",
      "Fold: 15  Epoch: 98  Training loss = 4.8483  Validation loss = 10.6416  \n",
      "\n",
      "Fold: 15  Epoch: 99  Training loss = 4.8477  Validation loss = 10.6408  \n",
      "\n",
      "Fold: 15  Epoch: 100  Training loss = 4.8472  Validation loss = 10.6400  \n",
      "\n",
      "Fold: 15  Epoch: 101  Training loss = 4.8466  Validation loss = 10.6392  \n",
      "\n",
      "Fold: 15  Epoch: 102  Training loss = 4.8460  Validation loss = 10.6383  \n",
      "\n",
      "Fold: 15  Epoch: 103  Training loss = 4.8455  Validation loss = 10.6376  \n",
      "\n",
      "Fold: 15  Epoch: 104  Training loss = 4.8449  Validation loss = 10.6367  \n",
      "\n",
      "Fold: 15  Epoch: 105  Training loss = 4.8445  Validation loss = 10.6361  \n",
      "\n",
      "Fold: 15  Epoch: 106  Training loss = 4.8438  Validation loss = 10.6352  \n",
      "\n",
      "Fold: 15  Epoch: 107  Training loss = 4.8433  Validation loss = 10.6344  \n",
      "\n",
      "Fold: 15  Epoch: 108  Training loss = 4.8428  Validation loss = 10.6337  \n",
      "\n",
      "Fold: 15  Epoch: 109  Training loss = 4.8423  Validation loss = 10.6329  \n",
      "\n",
      "Fold: 15  Epoch: 110  Training loss = 4.8418  Validation loss = 10.6322  \n",
      "\n",
      "Fold: 15  Epoch: 111  Training loss = 4.8413  Validation loss = 10.6315  \n",
      "\n",
      "Fold: 15  Epoch: 112  Training loss = 4.8408  Validation loss = 10.6308  \n",
      "\n",
      "Fold: 15  Epoch: 113  Training loss = 4.8403  Validation loss = 10.6301  \n",
      "\n",
      "Fold: 15  Epoch: 114  Training loss = 4.8398  Validation loss = 10.6293  \n",
      "\n",
      "Fold: 15  Epoch: 115  Training loss = 4.8392  Validation loss = 10.6286  \n",
      "\n",
      "Fold: 15  Epoch: 116  Training loss = 4.8387  Validation loss = 10.6278  \n",
      "\n",
      "Fold: 15  Epoch: 117  Training loss = 4.8381  Validation loss = 10.6270  \n",
      "\n",
      "Fold: 15  Epoch: 118  Training loss = 4.8375  Validation loss = 10.6261  \n",
      "\n",
      "Fold: 15  Epoch: 119  Training loss = 4.8370  Validation loss = 10.6254  \n",
      "\n",
      "Fold: 15  Epoch: 120  Training loss = 4.8365  Validation loss = 10.6246  \n",
      "\n",
      "Fold: 15  Epoch: 121  Training loss = 4.8360  Validation loss = 10.6239  \n",
      "\n",
      "Fold: 15  Epoch: 122  Training loss = 4.8354  Validation loss = 10.6230  \n",
      "\n",
      "Fold: 15  Epoch: 123  Training loss = 4.8349  Validation loss = 10.6223  \n",
      "\n",
      "Fold: 15  Epoch: 124  Training loss = 4.8342  Validation loss = 10.6213  \n",
      "\n",
      "Fold: 15  Epoch: 125  Training loss = 4.8335  Validation loss = 10.6204  \n",
      "\n",
      "Fold: 15  Epoch: 126  Training loss = 4.8329  Validation loss = 10.6194  \n",
      "\n",
      "Fold: 15  Epoch: 127  Training loss = 4.8323  Validation loss = 10.6186  \n",
      "\n",
      "Fold: 15  Epoch: 128  Training loss = 4.8316  Validation loss = 10.6177  \n",
      "\n",
      "Fold: 15  Epoch: 129  Training loss = 4.8310  Validation loss = 10.6168  \n",
      "\n",
      "Fold: 15  Epoch: 130  Training loss = 4.8304  Validation loss = 10.6158  \n",
      "\n",
      "Fold: 15  Epoch: 131  Training loss = 4.8297  Validation loss = 10.6149  \n",
      "\n",
      "Fold: 15  Epoch: 132  Training loss = 4.8291  Validation loss = 10.6140  \n",
      "\n",
      "Fold: 15  Epoch: 133  Training loss = 4.8285  Validation loss = 10.6132  \n",
      "\n",
      "Fold: 15  Epoch: 134  Training loss = 4.8279  Validation loss = 10.6123  \n",
      "\n",
      "Fold: 15  Epoch: 135  Training loss = 4.8274  Validation loss = 10.6116  \n",
      "\n",
      "Fold: 15  Epoch: 136  Training loss = 4.8268  Validation loss = 10.6108  \n",
      "\n",
      "Fold: 15  Epoch: 137  Training loss = 4.8263  Validation loss = 10.6101  \n",
      "\n",
      "Fold: 15  Epoch: 138  Training loss = 4.8256  Validation loss = 10.6091  \n",
      "\n",
      "Fold: 15  Epoch: 139  Training loss = 4.8251  Validation loss = 10.6083  \n",
      "\n",
      "Fold: 15  Epoch: 140  Training loss = 4.8245  Validation loss = 10.6074  \n",
      "\n",
      "Fold: 15  Epoch: 141  Training loss = 4.8239  Validation loss = 10.6065  \n",
      "\n",
      "Fold: 15  Epoch: 142  Training loss = 4.8234  Validation loss = 10.6058  \n",
      "\n",
      "Fold: 15  Epoch: 143  Training loss = 4.8227  Validation loss = 10.6049  \n",
      "\n",
      "Fold: 15  Epoch: 144  Training loss = 4.8221  Validation loss = 10.6040  \n",
      "\n",
      "Fold: 15  Epoch: 145  Training loss = 4.8215  Validation loss = 10.6031  \n",
      "\n",
      "Fold: 15  Epoch: 146  Training loss = 4.8208  Validation loss = 10.6022  \n",
      "\n",
      "Fold: 15  Epoch: 147  Training loss = 4.8201  Validation loss = 10.6012  \n",
      "\n",
      "Fold: 15  Epoch: 148  Training loss = 4.8196  Validation loss = 10.6004  \n",
      "\n",
      "Fold: 15  Epoch: 149  Training loss = 4.8191  Validation loss = 10.5996  \n",
      "\n",
      "Fold: 15  Epoch: 150  Training loss = 4.8185  Validation loss = 10.5988  \n",
      "\n",
      "Fold: 15  Epoch: 151  Training loss = 4.8178  Validation loss = 10.5978  \n",
      "\n",
      "Fold: 15  Epoch: 152  Training loss = 4.8172  Validation loss = 10.5969  \n",
      "\n",
      "Fold: 15  Epoch: 153  Training loss = 4.8167  Validation loss = 10.5963  \n",
      "\n",
      "Fold: 15  Epoch: 154  Training loss = 4.8161  Validation loss = 10.5954  \n",
      "\n",
      "Fold: 15  Epoch: 155  Training loss = 4.8156  Validation loss = 10.5947  \n",
      "\n",
      "Fold: 15  Epoch: 156  Training loss = 4.8151  Validation loss = 10.5940  \n",
      "\n",
      "Fold: 15  Epoch: 157  Training loss = 4.8146  Validation loss = 10.5933  \n",
      "\n",
      "Fold: 15  Epoch: 158  Training loss = 4.8140  Validation loss = 10.5924  \n",
      "\n",
      "Fold: 15  Epoch: 159  Training loss = 4.8133  Validation loss = 10.5914  \n",
      "\n",
      "Fold: 15  Epoch: 160  Training loss = 4.8127  Validation loss = 10.5905  \n",
      "\n",
      "Fold: 15  Epoch: 161  Training loss = 4.8121  Validation loss = 10.5897  \n",
      "\n",
      "Fold: 15  Epoch: 162  Training loss = 4.8115  Validation loss = 10.5888  \n",
      "\n",
      "Fold: 15  Epoch: 163  Training loss = 4.8109  Validation loss = 10.5880  \n",
      "\n",
      "Fold: 15  Epoch: 164  Training loss = 4.8103  Validation loss = 10.5871  \n",
      "\n",
      "Fold: 15  Epoch: 165  Training loss = 4.8097  Validation loss = 10.5862  \n",
      "\n",
      "Fold: 15  Epoch: 166  Training loss = 4.8092  Validation loss = 10.5855  \n",
      "\n",
      "Fold: 15  Epoch: 167  Training loss = 4.8087  Validation loss = 10.5848  \n",
      "\n",
      "Fold: 15  Epoch: 168  Training loss = 4.8081  Validation loss = 10.5839  \n",
      "\n",
      "Fold: 15  Epoch: 169  Training loss = 4.8075  Validation loss = 10.5831  \n",
      "\n",
      "Fold: 15  Epoch: 170  Training loss = 4.8070  Validation loss = 10.5824  \n",
      "\n",
      "Fold: 15  Epoch: 171  Training loss = 4.8064  Validation loss = 10.5815  \n",
      "\n",
      "Fold: 15  Epoch: 172  Training loss = 4.8058  Validation loss = 10.5807  \n",
      "\n",
      "Fold: 15  Epoch: 173  Training loss = 4.8053  Validation loss = 10.5800  \n",
      "\n",
      "Fold: 15  Epoch: 174  Training loss = 4.8048  Validation loss = 10.5793  \n",
      "\n",
      "Fold: 15  Epoch: 175  Training loss = 4.8043  Validation loss = 10.5785  \n",
      "\n",
      "Fold: 15  Epoch: 176  Training loss = 4.8037  Validation loss = 10.5777  \n",
      "\n",
      "Fold: 15  Epoch: 177  Training loss = 4.8031  Validation loss = 10.5768  \n",
      "\n",
      "Fold: 15  Epoch: 178  Training loss = 4.8025  Validation loss = 10.5759  \n",
      "\n",
      "Fold: 15  Epoch: 179  Training loss = 4.8018  Validation loss = 10.5750  \n",
      "\n",
      "Fold: 15  Epoch: 180  Training loss = 4.8013  Validation loss = 10.5742  \n",
      "\n",
      "Fold: 15  Epoch: 181  Training loss = 4.8007  Validation loss = 10.5734  \n",
      "\n",
      "Fold: 15  Epoch: 182  Training loss = 4.8002  Validation loss = 10.5727  \n",
      "\n",
      "Fold: 15  Epoch: 183  Training loss = 4.7996  Validation loss = 10.5718  \n",
      "\n",
      "Fold: 15  Epoch: 184  Training loss = 4.7990  Validation loss = 10.5709  \n",
      "\n",
      "Fold: 15  Epoch: 185  Training loss = 4.7984  Validation loss = 10.5702  \n",
      "\n",
      "Fold: 15  Epoch: 186  Training loss = 4.7978  Validation loss = 10.5693  \n",
      "\n",
      "Fold: 15  Epoch: 187  Training loss = 4.7971  Validation loss = 10.5683  \n",
      "\n",
      "Fold: 15  Epoch: 188  Training loss = 4.7965  Validation loss = 10.5675  \n",
      "\n",
      "Fold: 15  Epoch: 189  Training loss = 4.7959  Validation loss = 10.5666  \n",
      "\n",
      "Fold: 15  Epoch: 190  Training loss = 4.7953  Validation loss = 10.5658  \n",
      "\n",
      "Fold: 15  Epoch: 191  Training loss = 4.7947  Validation loss = 10.5650  \n",
      "\n",
      "Fold: 15  Epoch: 192  Training loss = 4.7942  Validation loss = 10.5642  \n",
      "\n",
      "Fold: 15  Epoch: 193  Training loss = 4.7937  Validation loss = 10.5635  \n",
      "\n",
      "Fold: 15  Epoch: 194  Training loss = 4.7931  Validation loss = 10.5626  \n",
      "\n",
      "Fold: 15  Epoch: 195  Training loss = 4.7926  Validation loss = 10.5619  \n",
      "\n",
      "Fold: 15  Epoch: 196  Training loss = 4.7920  Validation loss = 10.5610  \n",
      "\n",
      "Fold: 15  Epoch: 197  Training loss = 4.7914  Validation loss = 10.5602  \n",
      "\n",
      "Fold: 15  Epoch: 198  Training loss = 4.7907  Validation loss = 10.5593  \n",
      "\n",
      "Fold: 15  Epoch: 199  Training loss = 4.7901  Validation loss = 10.5584  \n",
      "\n",
      "Fold: 15  Epoch: 200  Training loss = 4.7895  Validation loss = 10.5575  \n",
      "\n",
      "Fold: 15  Epoch: 201  Training loss = 4.7889  Validation loss = 10.5566  \n",
      "\n",
      "Fold: 15  Epoch: 202  Training loss = 4.7882  Validation loss = 10.5557  \n",
      "\n",
      "Fold: 15  Epoch: 203  Training loss = 4.7876  Validation loss = 10.5548  \n",
      "\n",
      "Fold: 15  Epoch: 204  Training loss = 4.7869  Validation loss = 10.5538  \n",
      "\n",
      "Fold: 15  Epoch: 205  Training loss = 4.7863  Validation loss = 10.5530  \n",
      "\n",
      "Fold: 15  Epoch: 206  Training loss = 4.7857  Validation loss = 10.5521  \n",
      "\n",
      "Fold: 15  Epoch: 207  Training loss = 4.7851  Validation loss = 10.5513  \n",
      "\n",
      "Fold: 15  Epoch: 208  Training loss = 4.7845  Validation loss = 10.5504  \n",
      "\n",
      "Fold: 15  Epoch: 209  Training loss = 4.7839  Validation loss = 10.5497  \n",
      "\n",
      "Fold: 15  Epoch: 210  Training loss = 4.7833  Validation loss = 10.5488  \n",
      "\n",
      "Fold: 15  Epoch: 211  Training loss = 4.7827  Validation loss = 10.5479  \n",
      "\n",
      "Fold: 15  Epoch: 212  Training loss = 4.7822  Validation loss = 10.5472  \n",
      "\n",
      "Fold: 15  Epoch: 213  Training loss = 4.7816  Validation loss = 10.5464  \n",
      "\n",
      "Fold: 15  Epoch: 214  Training loss = 4.7811  Validation loss = 10.5456  \n",
      "\n",
      "Fold: 15  Epoch: 215  Training loss = 4.7805  Validation loss = 10.5447  \n",
      "\n",
      "Fold: 15  Epoch: 216  Training loss = 4.7801  Validation loss = 10.5442  \n",
      "\n",
      "Fold: 15  Epoch: 217  Training loss = 4.7795  Validation loss = 10.5433  \n",
      "\n",
      "Fold: 15  Epoch: 218  Training loss = 4.7789  Validation loss = 10.5425  \n",
      "\n",
      "Fold: 15  Epoch: 219  Training loss = 4.7783  Validation loss = 10.5416  \n",
      "\n",
      "Fold: 15  Epoch: 220  Training loss = 4.7777  Validation loss = 10.5407  \n",
      "\n",
      "Fold: 15  Epoch: 221  Training loss = 4.7771  Validation loss = 10.5399  \n",
      "\n",
      "Fold: 15  Epoch: 222  Training loss = 4.7765  Validation loss = 10.5391  \n",
      "\n",
      "Fold: 15  Epoch: 223  Training loss = 4.7759  Validation loss = 10.5383  \n",
      "\n",
      "Fold: 15  Epoch: 224  Training loss = 4.7754  Validation loss = 10.5375  \n",
      "\n",
      "Fold: 15  Epoch: 225  Training loss = 4.7748  Validation loss = 10.5368  \n",
      "\n",
      "Fold: 15  Epoch: 226  Training loss = 4.7742  Validation loss = 10.5359  \n",
      "\n",
      "Fold: 15  Epoch: 227  Training loss = 4.7738  Validation loss = 10.5353  \n",
      "\n",
      "Fold: 15  Epoch: 228  Training loss = 4.7730  Validation loss = 10.5343  \n",
      "\n",
      "Fold: 15  Epoch: 229  Training loss = 4.7724  Validation loss = 10.5334  \n",
      "\n",
      "Fold: 15  Epoch: 230  Training loss = 4.7719  Validation loss = 10.5327  \n",
      "\n",
      "Fold: 15  Epoch: 231  Training loss = 4.7713  Validation loss = 10.5318  \n",
      "\n",
      "Fold: 15  Epoch: 232  Training loss = 4.7707  Validation loss = 10.5310  \n",
      "\n",
      "Fold: 15  Epoch: 233  Training loss = 4.7702  Validation loss = 10.5303  \n",
      "\n",
      "Fold: 15  Epoch: 234  Training loss = 4.7697  Validation loss = 10.5296  \n",
      "\n",
      "Fold: 15  Epoch: 235  Training loss = 4.7691  Validation loss = 10.5287  \n",
      "\n",
      "Fold: 15  Epoch: 236  Training loss = 4.7685  Validation loss = 10.5280  \n",
      "\n",
      "Fold: 15  Epoch: 237  Training loss = 4.7680  Validation loss = 10.5272  \n",
      "\n",
      "Fold: 15  Epoch: 238  Training loss = 4.7675  Validation loss = 10.5264  \n",
      "\n",
      "Fold: 15  Epoch: 239  Training loss = 4.7669  Validation loss = 10.5256  \n",
      "\n",
      "Fold: 15  Epoch: 240  Training loss = 4.7663  Validation loss = 10.5248  \n",
      "\n",
      "Fold: 15  Epoch: 241  Training loss = 4.7658  Validation loss = 10.5241  \n",
      "\n",
      "Fold: 15  Epoch: 242  Training loss = 4.7650  Validation loss = 10.5230  \n",
      "\n",
      "Fold: 15  Epoch: 243  Training loss = 4.7645  Validation loss = 10.5222  \n",
      "\n",
      "Fold: 15  Epoch: 244  Training loss = 4.7640  Validation loss = 10.5215  \n",
      "\n",
      "Fold: 15  Epoch: 245  Training loss = 4.7633  Validation loss = 10.5206  \n",
      "\n",
      "Fold: 15  Epoch: 246  Training loss = 4.7628  Validation loss = 10.5198  \n",
      "\n",
      "Fold: 15  Epoch: 247  Training loss = 4.7621  Validation loss = 10.5189  \n",
      "\n",
      "Fold: 15  Epoch: 248  Training loss = 4.7616  Validation loss = 10.5181  \n",
      "\n",
      "Fold: 15  Epoch: 249  Training loss = 4.7609  Validation loss = 10.5172  \n",
      "\n",
      "Fold: 15  Epoch: 250  Training loss = 4.7604  Validation loss = 10.5165  \n",
      "\n",
      "Fold: 15  Epoch: 251  Training loss = 4.7599  Validation loss = 10.5158  \n",
      "\n",
      "Fold: 15  Epoch: 252  Training loss = 4.7593  Validation loss = 10.5149  \n",
      "\n",
      "Fold: 15  Epoch: 253  Training loss = 4.7586  Validation loss = 10.5140  \n",
      "\n",
      "Fold: 15  Epoch: 254  Training loss = 4.7580  Validation loss = 10.5132  \n",
      "\n",
      "Fold: 15  Epoch: 255  Training loss = 4.7575  Validation loss = 10.5124  \n",
      "\n",
      "Fold: 15  Epoch: 256  Training loss = 4.7568  Validation loss = 10.5114  \n",
      "\n",
      "Fold: 15  Epoch: 257  Training loss = 4.7561  Validation loss = 10.5105  \n",
      "\n",
      "Fold: 15  Epoch: 258  Training loss = 4.7555  Validation loss = 10.5097  \n",
      "\n",
      "Fold: 15  Epoch: 259  Training loss = 4.7550  Validation loss = 10.5090  \n",
      "\n",
      "Fold: 15  Epoch: 260  Training loss = 4.7544  Validation loss = 10.5081  \n",
      "\n",
      "Fold: 15  Epoch: 261  Training loss = 4.7538  Validation loss = 10.5073  \n",
      "\n",
      "Fold: 15  Epoch: 262  Training loss = 4.7533  Validation loss = 10.5065  \n",
      "\n",
      "Fold: 15  Epoch: 263  Training loss = 4.7528  Validation loss = 10.5058  \n",
      "\n",
      "Fold: 15  Epoch: 264  Training loss = 4.7522  Validation loss = 10.5050  \n",
      "\n",
      "Fold: 15  Epoch: 265  Training loss = 4.7516  Validation loss = 10.5041  \n",
      "\n",
      "Fold: 15  Epoch: 266  Training loss = 4.7511  Validation loss = 10.5035  \n",
      "\n",
      "Fold: 15  Epoch: 267  Training loss = 4.7504  Validation loss = 10.5025  \n",
      "\n",
      "Fold: 15  Epoch: 268  Training loss = 4.7499  Validation loss = 10.5018  \n",
      "\n",
      "Fold: 15  Epoch: 269  Training loss = 4.7493  Validation loss = 10.5009  \n",
      "\n",
      "Fold: 15  Epoch: 270  Training loss = 4.7487  Validation loss = 10.5001  \n",
      "\n",
      "Fold: 15  Epoch: 271  Training loss = 4.7482  Validation loss = 10.4995  \n",
      "\n",
      "Fold: 15  Epoch: 272  Training loss = 4.7476  Validation loss = 10.4986  \n",
      "\n",
      "Fold: 15  Epoch: 273  Training loss = 4.7471  Validation loss = 10.4980  \n",
      "\n",
      "Fold: 15  Epoch: 274  Training loss = 4.7464  Validation loss = 10.4970  \n",
      "\n",
      "Fold: 15  Epoch: 275  Training loss = 4.7459  Validation loss = 10.4962  \n",
      "\n",
      "Fold: 15  Epoch: 276  Training loss = 4.7453  Validation loss = 10.4954  \n",
      "\n",
      "Fold: 15  Epoch: 277  Training loss = 4.7448  Validation loss = 10.4947  \n",
      "\n",
      "Fold: 15  Epoch: 278  Training loss = 4.7442  Validation loss = 10.4939  \n",
      "\n",
      "Fold: 15  Epoch: 279  Training loss = 4.7435  Validation loss = 10.4929  \n",
      "\n",
      "Fold: 15  Epoch: 280  Training loss = 4.7430  Validation loss = 10.4923  \n",
      "\n",
      "Fold: 15  Epoch: 281  Training loss = 4.7425  Validation loss = 10.4915  \n",
      "\n",
      "Fold: 15  Epoch: 282  Training loss = 4.7418  Validation loss = 10.4906  \n",
      "\n",
      "Fold: 15  Epoch: 283  Training loss = 4.7412  Validation loss = 10.4897  \n",
      "\n",
      "Fold: 15  Epoch: 284  Training loss = 4.7404  Validation loss = 10.4887  \n",
      "\n",
      "Fold: 15  Epoch: 285  Training loss = 4.7399  Validation loss = 10.4880  \n",
      "\n",
      "Fold: 15  Epoch: 286  Training loss = 4.7393  Validation loss = 10.4871  \n",
      "\n",
      "Fold: 15  Epoch: 287  Training loss = 4.7387  Validation loss = 10.4863  \n",
      "\n",
      "Fold: 15  Epoch: 288  Training loss = 4.7382  Validation loss = 10.4856  \n",
      "\n",
      "Fold: 15  Epoch: 289  Training loss = 4.7376  Validation loss = 10.4848  \n",
      "\n",
      "Fold: 15  Epoch: 290  Training loss = 4.7370  Validation loss = 10.4839  \n",
      "\n",
      "Fold: 15  Epoch: 291  Training loss = 4.7365  Validation loss = 10.4832  \n",
      "\n",
      "Fold: 15  Epoch: 292  Training loss = 4.7361  Validation loss = 10.4826  \n",
      "\n",
      "Fold: 15  Epoch: 293  Training loss = 4.7354  Validation loss = 10.4817  \n",
      "\n",
      "Fold: 15  Epoch: 294  Training loss = 4.7348  Validation loss = 10.4809  \n",
      "\n",
      "Fold: 15  Epoch: 295  Training loss = 4.7341  Validation loss = 10.4799  \n",
      "\n",
      "Fold: 15  Epoch: 296  Training loss = 4.7336  Validation loss = 10.4791  \n",
      "\n",
      "Fold: 15  Epoch: 297  Training loss = 4.7330  Validation loss = 10.4784  \n",
      "\n",
      "Fold: 15  Epoch: 298  Training loss = 4.7323  Validation loss = 10.4774  \n",
      "\n",
      "Fold: 15  Epoch: 299  Training loss = 4.7317  Validation loss = 10.4765  \n",
      "\n",
      "Fold: 15  Epoch: 300  Training loss = 4.7310  Validation loss = 10.4756  \n",
      "\n",
      "Fold: 15  Epoch: 301  Training loss = 4.7305  Validation loss = 10.4749  \n",
      "\n",
      "Fold: 15  Epoch: 302  Training loss = 4.7299  Validation loss = 10.4740  \n",
      "\n",
      "Fold: 15  Epoch: 303  Training loss = 4.7293  Validation loss = 10.4733  \n",
      "\n",
      "Fold: 15  Epoch: 304  Training loss = 4.7288  Validation loss = 10.4725  \n",
      "\n",
      "Fold: 15  Epoch: 305  Training loss = 4.7283  Validation loss = 10.4718  \n",
      "\n",
      "Fold: 15  Epoch: 306  Training loss = 4.7277  Validation loss = 10.4710  \n",
      "\n",
      "Fold: 15  Epoch: 307  Training loss = 4.7272  Validation loss = 10.4702  \n",
      "\n",
      "Fold: 15  Epoch: 308  Training loss = 4.7266  Validation loss = 10.4693  \n",
      "\n",
      "Fold: 15  Epoch: 309  Training loss = 4.7260  Validation loss = 10.4686  \n",
      "\n",
      "Fold: 15  Epoch: 310  Training loss = 4.7255  Validation loss = 10.4679  \n",
      "\n",
      "Fold: 15  Epoch: 311  Training loss = 4.7249  Validation loss = 10.4670  \n",
      "\n",
      "Fold: 15  Epoch: 312  Training loss = 4.7243  Validation loss = 10.4662  \n",
      "\n",
      "Fold: 15  Epoch: 313  Training loss = 4.7238  Validation loss = 10.4655  \n",
      "\n",
      "Fold: 15  Epoch: 314  Training loss = 4.7233  Validation loss = 10.4648  \n",
      "\n",
      "Fold: 15  Epoch: 315  Training loss = 4.7227  Validation loss = 10.4639  \n",
      "\n",
      "Fold: 15  Epoch: 316  Training loss = 4.7221  Validation loss = 10.4631  \n",
      "\n",
      "Fold: 15  Epoch: 317  Training loss = 4.7216  Validation loss = 10.4625  \n",
      "\n",
      "Fold: 15  Epoch: 318  Training loss = 4.7211  Validation loss = 10.4617  \n",
      "\n",
      "Fold: 15  Epoch: 319  Training loss = 4.7203  Validation loss = 10.4607  \n",
      "\n",
      "Fold: 15  Epoch: 320  Training loss = 4.7197  Validation loss = 10.4598  \n",
      "\n",
      "Fold: 15  Epoch: 321  Training loss = 4.7192  Validation loss = 10.4591  \n",
      "\n",
      "Fold: 15  Epoch: 322  Training loss = 4.7185  Validation loss = 10.4582  \n",
      "\n",
      "Fold: 15  Epoch: 323  Training loss = 4.7179  Validation loss = 10.4573  \n",
      "\n",
      "Fold: 15  Epoch: 324  Training loss = 4.7174  Validation loss = 10.4566  \n",
      "\n",
      "Fold: 15  Epoch: 325  Training loss = 4.7167  Validation loss = 10.4557  \n",
      "\n",
      "Fold: 15  Epoch: 326  Training loss = 4.7162  Validation loss = 10.4549  \n",
      "\n",
      "Fold: 15  Epoch: 327  Training loss = 4.7155  Validation loss = 10.4539  \n",
      "\n",
      "Fold: 15  Epoch: 328  Training loss = 4.7150  Validation loss = 10.4532  \n",
      "\n",
      "Fold: 15  Epoch: 329  Training loss = 4.7144  Validation loss = 10.4523  \n",
      "\n",
      "Fold: 15  Epoch: 330  Training loss = 4.7138  Validation loss = 10.4516  \n",
      "\n",
      "Fold: 15  Epoch: 331  Training loss = 4.7131  Validation loss = 10.4506  \n",
      "\n",
      "Fold: 15  Epoch: 332  Training loss = 4.7125  Validation loss = 10.4498  \n",
      "\n",
      "Fold: 15  Epoch: 333  Training loss = 4.7119  Validation loss = 10.4490  \n",
      "\n",
      "Fold: 15  Epoch: 334  Training loss = 4.7113  Validation loss = 10.4480  \n",
      "\n",
      "Fold: 15  Epoch: 335  Training loss = 4.7105  Validation loss = 10.4470  \n",
      "\n",
      "Fold: 15  Epoch: 336  Training loss = 4.7099  Validation loss = 10.4462  \n",
      "\n",
      "Fold: 15  Epoch: 337  Training loss = 4.7093  Validation loss = 10.4453  \n",
      "\n",
      "Fold: 15  Epoch: 338  Training loss = 4.7088  Validation loss = 10.4447  \n",
      "\n",
      "Fold: 15  Epoch: 339  Training loss = 4.7082  Validation loss = 10.4438  \n",
      "\n",
      "Fold: 15  Epoch: 340  Training loss = 4.7075  Validation loss = 10.4428  \n",
      "\n",
      "Fold: 15  Epoch: 341  Training loss = 4.7068  Validation loss = 10.4419  \n",
      "\n",
      "Fold: 15  Epoch: 342  Training loss = 4.7062  Validation loss = 10.4411  \n",
      "\n",
      "Fold: 15  Epoch: 343  Training loss = 4.7056  Validation loss = 10.4402  \n",
      "\n",
      "Fold: 15  Epoch: 344  Training loss = 4.7049  Validation loss = 10.4393  \n",
      "\n",
      "Fold: 15  Epoch: 345  Training loss = 4.7042  Validation loss = 10.4384  \n",
      "\n",
      "Fold: 15  Epoch: 346  Training loss = 4.7036  Validation loss = 10.4375  \n",
      "\n",
      "Fold: 15  Epoch: 347  Training loss = 4.7030  Validation loss = 10.4367  \n",
      "\n",
      "Fold: 15  Epoch: 348  Training loss = 4.7025  Validation loss = 10.4360  \n",
      "\n",
      "Fold: 15  Epoch: 349  Training loss = 4.7018  Validation loss = 10.4350  \n",
      "\n",
      "Fold: 15  Epoch: 350  Training loss = 4.7011  Validation loss = 10.4341  \n",
      "\n",
      "Fold: 15  Epoch: 351  Training loss = 4.7004  Validation loss = 10.4332  \n",
      "\n",
      "Fold: 15  Epoch: 352  Training loss = 4.6995  Validation loss = 10.4323  \n",
      "\n",
      "Fold: 15  Epoch: 353  Training loss = 4.6986  Validation loss = 10.4314  \n",
      "\n",
      "Fold: 15  Epoch: 354  Training loss = 4.6976  Validation loss = 10.4306  \n",
      "\n",
      "Fold: 15  Epoch: 355  Training loss = 4.6970  Validation loss = 10.4298  \n",
      "\n",
      "Fold: 15  Epoch: 356  Training loss = 4.6958  Validation loss = 10.4290  \n",
      "\n",
      "Fold: 15  Epoch: 357  Training loss = 4.6952  Validation loss = 10.4282  \n",
      "\n",
      "Fold: 15  Epoch: 358  Training loss = 4.6934  Validation loss = 10.4274  \n",
      "\n",
      "Fold: 15  Epoch: 359  Training loss = 4.6924  Validation loss = 10.4264  \n",
      "\n",
      "Fold: 15  Epoch: 360  Training loss = 4.6917  Validation loss = 10.4255  \n",
      "\n",
      "Fold: 15  Epoch: 361  Training loss = 4.6911  Validation loss = 10.4246  \n",
      "\n",
      "Fold: 15  Epoch: 362  Training loss = 4.6905  Validation loss = 10.4239  \n",
      "\n",
      "Fold: 15  Epoch: 363  Training loss = 4.6900  Validation loss = 10.4233  \n",
      "\n",
      "Fold: 15  Epoch: 364  Training loss = 4.6894  Validation loss = 10.4225  \n",
      "\n",
      "Fold: 15  Epoch: 365  Training loss = 4.6888  Validation loss = 10.4217  \n",
      "\n",
      "Fold: 15  Epoch: 366  Training loss = 4.6882  Validation loss = 10.4208  \n",
      "\n",
      "Fold: 15  Epoch: 367  Training loss = 4.6876  Validation loss = 10.4199  \n",
      "\n",
      "Fold: 15  Epoch: 368  Training loss = 4.6869  Validation loss = 10.4190  \n",
      "\n",
      "Fold: 15  Epoch: 369  Training loss = 4.6863  Validation loss = 10.4182  \n",
      "\n",
      "Fold: 15  Epoch: 370  Training loss = 4.6857  Validation loss = 10.4173  \n",
      "\n",
      "Fold: 15  Epoch: 371  Training loss = 4.6850  Validation loss = 10.4163  \n",
      "\n",
      "Fold: 15  Epoch: 372  Training loss = 4.6844  Validation loss = 10.4154  \n",
      "\n",
      "Fold: 15  Epoch: 373  Training loss = 4.6838  Validation loss = 10.4147  \n",
      "\n",
      "Fold: 15  Epoch: 374  Training loss = 4.6833  Validation loss = 10.4139  \n",
      "\n",
      "Fold: 15  Epoch: 375  Training loss = 4.6827  Validation loss = 10.4132  \n",
      "\n",
      "Fold: 15  Epoch: 376  Training loss = 4.6822  Validation loss = 10.4125  \n",
      "\n",
      "Fold: 15  Epoch: 377  Training loss = 4.6816  Validation loss = 10.4116  \n",
      "\n",
      "Fold: 15  Epoch: 378  Training loss = 4.6811  Validation loss = 10.4108  \n",
      "\n",
      "Fold: 15  Epoch: 379  Training loss = 4.6805  Validation loss = 10.4100  \n",
      "\n",
      "Fold: 15  Epoch: 380  Training loss = 4.6800  Validation loss = 10.4092  \n",
      "\n",
      "Fold: 15  Epoch: 381  Training loss = 4.6792  Validation loss = 10.4082  \n",
      "\n",
      "Fold: 15  Epoch: 382  Training loss = 4.6786  Validation loss = 10.4074  \n",
      "\n",
      "Fold: 15  Epoch: 383  Training loss = 4.6780  Validation loss = 10.4065  \n",
      "\n",
      "Fold: 15  Epoch: 384  Training loss = 4.6774  Validation loss = 10.4058  \n",
      "\n",
      "Fold: 15  Epoch: 385  Training loss = 4.6768  Validation loss = 10.4048  \n",
      "\n",
      "Fold: 15  Epoch: 386  Training loss = 4.6762  Validation loss = 10.4039  \n",
      "\n",
      "Fold: 15  Epoch: 387  Training loss = 4.6756  Validation loss = 10.4032  \n",
      "\n",
      "Fold: 15  Epoch: 388  Training loss = 4.6751  Validation loss = 10.4024  \n",
      "\n",
      "Fold: 15  Epoch: 389  Training loss = 4.6746  Validation loss = 10.4017  \n",
      "\n",
      "Fold: 15  Epoch: 390  Training loss = 4.6741  Validation loss = 10.4010  \n",
      "\n",
      "Fold: 15  Epoch: 391  Training loss = 4.6735  Validation loss = 10.4002  \n",
      "\n",
      "Fold: 15  Epoch: 392  Training loss = 4.6728  Validation loss = 10.3992  \n",
      "\n",
      "Fold: 15  Epoch: 393  Training loss = 4.6722  Validation loss = 10.3983  \n",
      "\n",
      "Fold: 15  Epoch: 394  Training loss = 4.6717  Validation loss = 10.3976  \n",
      "\n",
      "Fold: 15  Epoch: 395  Training loss = 4.6711  Validation loss = 10.3968  \n",
      "\n",
      "Fold: 15  Epoch: 396  Training loss = 4.6706  Validation loss = 10.3960  \n",
      "\n",
      "Fold: 15  Epoch: 397  Training loss = 4.6701  Validation loss = 10.3952  \n",
      "\n",
      "Fold: 15  Epoch: 398  Training loss = 4.6695  Validation loss = 10.3945  \n",
      "\n",
      "Fold: 15  Epoch: 399  Training loss = 4.6691  Validation loss = 10.3939  \n",
      "\n",
      "Fold: 15  Epoch: 400  Training loss = 4.6685  Validation loss = 10.3931  \n",
      "\n",
      "Fold: 15  Epoch: 401  Training loss = 4.6680  Validation loss = 10.3923  \n",
      "\n",
      "Fold: 15  Epoch: 402  Training loss = 4.6675  Validation loss = 10.3915  \n",
      "\n",
      "Fold: 15  Epoch: 403  Training loss = 4.6669  Validation loss = 10.3907  \n",
      "\n",
      "Fold: 15  Epoch: 404  Training loss = 4.6663  Validation loss = 10.3899  \n",
      "\n",
      "Fold: 15  Epoch: 405  Training loss = 4.6657  Validation loss = 10.3891  \n",
      "\n",
      "Fold: 15  Epoch: 406  Training loss = 4.6652  Validation loss = 10.3884  \n",
      "\n",
      "Fold: 15  Epoch: 407  Training loss = 4.6646  Validation loss = 10.3875  \n",
      "\n",
      "Fold: 15  Epoch: 408  Training loss = 4.6640  Validation loss = 10.3866  \n",
      "\n",
      "Fold: 15  Epoch: 409  Training loss = 4.6633  Validation loss = 10.3857  \n",
      "\n",
      "Fold: 15  Epoch: 410  Training loss = 4.6628  Validation loss = 10.3849  \n",
      "\n",
      "Fold: 15  Epoch: 411  Training loss = 4.6623  Validation loss = 10.3842  \n",
      "\n",
      "Fold: 15  Epoch: 412  Training loss = 4.6618  Validation loss = 10.3835  \n",
      "\n",
      "Fold: 15  Epoch: 413  Training loss = 4.6613  Validation loss = 10.3828  \n",
      "\n",
      "Fold: 15  Epoch: 414  Training loss = 4.6607  Validation loss = 10.3820  \n",
      "\n",
      "Fold: 15  Epoch: 415  Training loss = 4.6601  Validation loss = 10.3810  \n",
      "\n",
      "Fold: 15  Epoch: 416  Training loss = 4.6595  Validation loss = 10.3802  \n",
      "\n",
      "Fold: 15  Epoch: 417  Training loss = 4.6591  Validation loss = 10.3796  \n",
      "\n",
      "Fold: 15  Epoch: 418  Training loss = 4.6586  Validation loss = 10.3790  \n",
      "\n",
      "Fold: 15  Epoch: 419  Training loss = 4.6580  Validation loss = 10.3781  \n",
      "\n",
      "Fold: 15  Epoch: 420  Training loss = 4.6573  Validation loss = 10.3771  \n",
      "\n",
      "Fold: 15  Epoch: 421  Training loss = 4.6568  Validation loss = 10.3764  \n",
      "\n",
      "Fold: 15  Epoch: 422  Training loss = 4.6563  Validation loss = 10.3756  \n",
      "\n",
      "Fold: 15  Epoch: 423  Training loss = 4.6557  Validation loss = 10.3749  \n",
      "\n",
      "Fold: 15  Epoch: 424  Training loss = 4.6553  Validation loss = 10.3742  \n",
      "\n",
      "Fold: 15  Epoch: 425  Training loss = 4.6548  Validation loss = 10.3734  \n",
      "\n",
      "Fold: 15  Epoch: 426  Training loss = 4.6543  Validation loss = 10.3728  \n",
      "\n",
      "Fold: 15  Epoch: 427  Training loss = 4.6538  Validation loss = 10.3721  \n",
      "\n",
      "Fold: 15  Epoch: 428  Training loss = 4.6532  Validation loss = 10.3712  \n",
      "\n",
      "Fold: 15  Epoch: 429  Training loss = 4.6526  Validation loss = 10.3703  \n",
      "\n",
      "Fold: 15  Epoch: 430  Training loss = 4.6520  Validation loss = 10.3695  \n",
      "\n",
      "Fold: 15  Epoch: 431  Training loss = 4.6514  Validation loss = 10.3686  \n",
      "\n",
      "Fold: 15  Epoch: 432  Training loss = 4.6509  Validation loss = 10.3679  \n",
      "\n",
      "Fold: 15  Epoch: 433  Training loss = 4.6503  Validation loss = 10.3671  \n",
      "\n",
      "Fold: 15  Epoch: 434  Training loss = 4.6496  Validation loss = 10.3661  \n",
      "\n",
      "Fold: 15  Epoch: 435  Training loss = 4.6491  Validation loss = 10.3653  \n",
      "\n",
      "Fold: 15  Epoch: 436  Training loss = 4.6485  Validation loss = 10.3645  \n",
      "\n",
      "Fold: 15  Epoch: 437  Training loss = 4.6481  Validation loss = 10.3639  \n",
      "\n",
      "Fold: 15  Epoch: 438  Training loss = 4.6476  Validation loss = 10.3631  \n",
      "\n",
      "Fold: 15  Epoch: 439  Training loss = 4.6470  Validation loss = 10.3624  \n",
      "\n",
      "Fold: 15  Epoch: 440  Training loss = 4.6464  Validation loss = 10.3615  \n",
      "\n",
      "Fold: 15  Epoch: 441  Training loss = 4.6458  Validation loss = 10.3606  \n",
      "\n",
      "Fold: 15  Epoch: 442  Training loss = 4.6452  Validation loss = 10.3598  \n",
      "\n",
      "Fold: 15  Epoch: 443  Training loss = 4.6448  Validation loss = 10.3592  \n",
      "\n",
      "Fold: 15  Epoch: 444  Training loss = 4.6442  Validation loss = 10.3583  \n",
      "\n",
      "Fold: 15  Epoch: 445  Training loss = 4.6438  Validation loss = 10.3577  \n",
      "\n",
      "Fold: 15  Epoch: 446  Training loss = 4.6433  Validation loss = 10.3570  \n",
      "\n",
      "Fold: 15  Epoch: 447  Training loss = 4.6428  Validation loss = 10.3562  \n",
      "\n",
      "Fold: 15  Epoch: 448  Training loss = 4.6422  Validation loss = 10.3555  \n",
      "\n",
      "Fold: 15  Epoch: 449  Training loss = 4.6417  Validation loss = 10.3547  \n",
      "\n",
      "Fold: 15  Epoch: 450  Training loss = 4.6412  Validation loss = 10.3540  \n",
      "\n",
      "Fold: 15  Epoch: 451  Training loss = 4.6407  Validation loss = 10.3533  \n",
      "\n",
      "Fold: 15  Epoch: 452  Training loss = 4.6404  Validation loss = 10.3528  \n",
      "\n",
      "Fold: 15  Epoch: 453  Training loss = 4.6397  Validation loss = 10.3519  \n",
      "\n",
      "Fold: 15  Epoch: 454  Training loss = 4.6392  Validation loss = 10.3511  \n",
      "\n",
      "Fold: 15  Epoch: 455  Training loss = 4.6386  Validation loss = 10.3503  \n",
      "\n",
      "Fold: 15  Epoch: 456  Training loss = 4.6380  Validation loss = 10.3494  \n",
      "\n",
      "Fold: 15  Epoch: 457  Training loss = 4.6374  Validation loss = 10.3486  \n",
      "\n",
      "Fold: 15  Epoch: 458  Training loss = 4.6368  Validation loss = 10.3477  \n",
      "\n",
      "Fold: 15  Epoch: 459  Training loss = 4.6363  Validation loss = 10.3470  \n",
      "\n",
      "Fold: 15  Epoch: 460  Training loss = 4.6358  Validation loss = 10.3461  \n",
      "\n",
      "Fold: 15  Epoch: 461  Training loss = 4.6352  Validation loss = 10.3453  \n",
      "\n",
      "Fold: 15  Epoch: 462  Training loss = 4.6347  Validation loss = 10.3446  \n",
      "\n",
      "Fold: 15  Epoch: 463  Training loss = 4.6342  Validation loss = 10.3439  \n",
      "\n",
      "Fold: 15  Epoch: 464  Training loss = 4.6337  Validation loss = 10.3431  \n",
      "\n",
      "Fold: 15  Epoch: 465  Training loss = 4.6332  Validation loss = 10.3424  \n",
      "\n",
      "Fold: 15  Epoch: 466  Training loss = 4.6328  Validation loss = 10.3418  \n",
      "\n",
      "Fold: 15  Epoch: 467  Training loss = 4.6322  Validation loss = 10.3409  \n",
      "\n",
      "Fold: 15  Epoch: 468  Training loss = 4.6316  Validation loss = 10.3401  \n",
      "\n",
      "Fold: 15  Epoch: 469  Training loss = 4.6310  Validation loss = 10.3392  \n",
      "\n",
      "Fold: 15  Epoch: 470  Training loss = 4.6305  Validation loss = 10.3385  \n",
      "\n",
      "Fold: 15  Epoch: 471  Training loss = 4.6299  Validation loss = 10.3377  \n",
      "\n",
      "Fold: 15  Epoch: 472  Training loss = 4.6294  Validation loss = 10.3369  \n",
      "\n",
      "Fold: 15  Epoch: 473  Training loss = 4.6289  Validation loss = 10.3361  \n",
      "\n",
      "Fold: 15  Epoch: 474  Training loss = 4.6285  Validation loss = 10.3356  \n",
      "\n",
      "Fold: 15  Epoch: 475  Training loss = 4.6280  Validation loss = 10.3349  \n",
      "\n",
      "Fold: 15  Epoch: 476  Training loss = 4.6276  Validation loss = 10.3342  \n",
      "\n",
      "Fold: 15  Epoch: 477  Training loss = 4.6271  Validation loss = 10.3336  \n",
      "\n",
      "Fold: 15  Epoch: 478  Training loss = 4.6266  Validation loss = 10.3328  \n",
      "\n",
      "Fold: 15  Epoch: 479  Training loss = 4.6261  Validation loss = 10.3321  \n",
      "\n",
      "Fold: 15  Epoch: 480  Training loss = 4.6255  Validation loss = 10.3312  \n",
      "\n",
      "Fold: 15  Epoch: 481  Training loss = 4.6249  Validation loss = 10.3303  \n",
      "\n",
      "Fold: 15  Epoch: 482  Training loss = 4.6243  Validation loss = 10.3295  \n",
      "\n",
      "Fold: 15  Epoch: 483  Training loss = 4.6237  Validation loss = 10.3286  \n",
      "\n",
      "Fold: 15  Epoch: 484  Training loss = 4.6231  Validation loss = 10.3278  \n",
      "\n",
      "Fold: 15  Epoch: 485  Training loss = 4.6226  Validation loss = 10.3269  \n",
      "\n",
      "Fold: 15  Epoch: 486  Training loss = 4.6220  Validation loss = 10.3261  \n",
      "\n",
      "Fold: 15  Epoch: 487  Training loss = 4.6213  Validation loss = 10.3251  \n",
      "\n",
      "Fold: 15  Epoch: 488  Training loss = 4.6208  Validation loss = 10.3244  \n",
      "\n",
      "Fold: 15  Epoch: 489  Training loss = 4.6202  Validation loss = 10.3235  \n",
      "\n",
      "Fold: 15  Epoch: 490  Training loss = 4.6196  Validation loss = 10.3227  \n",
      "\n",
      "Fold: 15  Epoch: 491  Training loss = 4.6191  Validation loss = 10.3219  \n",
      "\n",
      "Fold: 15  Epoch: 492  Training loss = 4.6184  Validation loss = 10.3209  \n",
      "\n",
      "Fold: 15  Epoch: 493  Training loss = 4.6178  Validation loss = 10.3200  \n",
      "\n",
      "Fold: 15  Epoch: 494  Training loss = 4.6171  Validation loss = 10.3190  \n",
      "\n",
      "Fold: 15  Epoch: 495  Training loss = 4.6165  Validation loss = 10.3181  \n",
      "\n",
      "Fold: 15  Epoch: 496  Training loss = 4.6160  Validation loss = 10.3174  \n",
      "\n",
      "Fold: 15  Epoch: 497  Training loss = 4.6155  Validation loss = 10.3167  \n",
      "\n",
      "Fold: 15  Epoch: 498  Training loss = 4.6149  Validation loss = 10.3158  \n",
      "\n",
      "Fold: 15  Epoch: 499  Training loss = 4.6145  Validation loss = 10.3153  \n",
      "\n",
      "Fold: 15  Epoch: 500  Training loss = 4.6140  Validation loss = 10.3144  \n",
      "\n",
      "Check model:  Fold: 15  Optimal epoch: 500  \n",
      "\n",
      "Fold: 16  Epoch: 1  Training loss = 5.2631  Validation loss = 7.5563  \n",
      "\n",
      "Fold: 16  Epoch: 2  Training loss = 5.2623  Validation loss = 7.5555  \n",
      "\n",
      "Fold: 16  Epoch: 3  Training loss = 5.2616  Validation loss = 7.5546  \n",
      "\n",
      "Fold: 16  Epoch: 4  Training loss = 5.2609  Validation loss = 7.5540  \n",
      "\n",
      "Fold: 16  Epoch: 5  Training loss = 5.2602  Validation loss = 7.5531  \n",
      "\n",
      "Fold: 16  Epoch: 6  Training loss = 5.2596  Validation loss = 7.5524  \n",
      "\n",
      "Fold: 16  Epoch: 7  Training loss = 5.2589  Validation loss = 7.5516  \n",
      "\n",
      "Fold: 16  Epoch: 8  Training loss = 5.2582  Validation loss = 7.5508  \n",
      "\n",
      "Fold: 16  Epoch: 9  Training loss = 5.2575  Validation loss = 7.5500  \n",
      "\n",
      "Fold: 16  Epoch: 10  Training loss = 5.2570  Validation loss = 7.5494  \n",
      "\n",
      "Fold: 16  Epoch: 11  Training loss = 5.2563  Validation loss = 7.5487  \n",
      "\n",
      "Fold: 16  Epoch: 12  Training loss = 5.2555  Validation loss = 7.5478  \n",
      "\n",
      "Fold: 16  Epoch: 13  Training loss = 5.2549  Validation loss = 7.5471  \n",
      "\n",
      "Fold: 16  Epoch: 14  Training loss = 5.2541  Validation loss = 7.5463  \n",
      "\n",
      "Fold: 16  Epoch: 15  Training loss = 5.2533  Validation loss = 7.5456  \n",
      "\n",
      "Fold: 16  Epoch: 16  Training loss = 5.2526  Validation loss = 7.5445  \n",
      "\n",
      "Fold: 16  Epoch: 17  Training loss = 5.2519  Validation loss = 7.5438  \n",
      "\n",
      "Fold: 16  Epoch: 18  Training loss = 5.2514  Validation loss = 7.5432  \n",
      "\n",
      "Fold: 16  Epoch: 19  Training loss = 5.2507  Validation loss = 7.5423  \n",
      "\n",
      "Fold: 16  Epoch: 20  Training loss = 5.2501  Validation loss = 7.5415  \n",
      "\n",
      "Fold: 16  Epoch: 21  Training loss = 5.2494  Validation loss = 7.5407  \n",
      "\n",
      "Fold: 16  Epoch: 22  Training loss = 5.2488  Validation loss = 7.5399  \n",
      "\n",
      "Fold: 16  Epoch: 23  Training loss = 5.2480  Validation loss = 7.5390  \n",
      "\n",
      "Fold: 16  Epoch: 24  Training loss = 5.2474  Validation loss = 7.5384  \n",
      "\n",
      "Fold: 16  Epoch: 25  Training loss = 5.2467  Validation loss = 7.5376  \n",
      "\n",
      "Fold: 16  Epoch: 26  Training loss = 5.2459  Validation loss = 7.5367  \n",
      "\n",
      "Fold: 16  Epoch: 27  Training loss = 5.2452  Validation loss = 7.5359  \n",
      "\n",
      "Fold: 16  Epoch: 28  Training loss = 5.2445  Validation loss = 7.5351  \n",
      "\n",
      "Fold: 16  Epoch: 29  Training loss = 5.2438  Validation loss = 7.5343  \n",
      "\n",
      "Fold: 16  Epoch: 30  Training loss = 5.2430  Validation loss = 7.5334  \n",
      "\n",
      "Fold: 16  Epoch: 31  Training loss = 5.2421  Validation loss = 7.5325  \n",
      "\n",
      "Fold: 16  Epoch: 32  Training loss = 5.2413  Validation loss = 7.5315  \n",
      "\n",
      "Fold: 16  Epoch: 33  Training loss = 5.2407  Validation loss = 7.5307  \n",
      "\n",
      "Fold: 16  Epoch: 34  Training loss = 5.2399  Validation loss = 7.5298  \n",
      "\n",
      "Fold: 16  Epoch: 35  Training loss = 5.2393  Validation loss = 7.5291  \n",
      "\n",
      "Fold: 16  Epoch: 36  Training loss = 5.2385  Validation loss = 7.5282  \n",
      "\n",
      "Fold: 16  Epoch: 37  Training loss = 5.2376  Validation loss = 7.5272  \n",
      "\n",
      "Fold: 16  Epoch: 38  Training loss = 5.2369  Validation loss = 7.5264  \n",
      "\n",
      "Fold: 16  Epoch: 39  Training loss = 5.2361  Validation loss = 7.5254  \n",
      "\n",
      "Fold: 16  Epoch: 40  Training loss = 5.2354  Validation loss = 7.5246  \n",
      "\n",
      "Fold: 16  Epoch: 41  Training loss = 5.2347  Validation loss = 7.5239  \n",
      "\n",
      "Fold: 16  Epoch: 42  Training loss = 5.2339  Validation loss = 7.5230  \n",
      "\n",
      "Fold: 16  Epoch: 43  Training loss = 5.2333  Validation loss = 7.5221  \n",
      "\n",
      "Fold: 16  Epoch: 44  Training loss = 5.2326  Validation loss = 7.5213  \n",
      "\n",
      "Fold: 16  Epoch: 45  Training loss = 5.2319  Validation loss = 7.5205  \n",
      "\n",
      "Fold: 16  Epoch: 46  Training loss = 5.2312  Validation loss = 7.5196  \n",
      "\n",
      "Fold: 16  Epoch: 47  Training loss = 5.2304  Validation loss = 7.5186  \n",
      "\n",
      "Fold: 16  Epoch: 48  Training loss = 5.2297  Validation loss = 7.5177  \n",
      "\n",
      "Fold: 16  Epoch: 49  Training loss = 5.2289  Validation loss = 7.5168  \n",
      "\n",
      "Fold: 16  Epoch: 50  Training loss = 5.2283  Validation loss = 7.5161  \n",
      "\n",
      "Fold: 16  Epoch: 51  Training loss = 5.2275  Validation loss = 7.5153  \n",
      "\n",
      "Fold: 16  Epoch: 52  Training loss = 5.2268  Validation loss = 7.5144  \n",
      "\n",
      "Fold: 16  Epoch: 53  Training loss = 5.2261  Validation loss = 7.5136  \n",
      "\n",
      "Fold: 16  Epoch: 54  Training loss = 5.2255  Validation loss = 7.5130  \n",
      "\n",
      "Fold: 16  Epoch: 55  Training loss = 5.2249  Validation loss = 7.5122  \n",
      "\n",
      "Fold: 16  Epoch: 56  Training loss = 5.2242  Validation loss = 7.5113  \n",
      "\n",
      "Fold: 16  Epoch: 57  Training loss = 5.2235  Validation loss = 7.5105  \n",
      "\n",
      "Fold: 16  Epoch: 58  Training loss = 5.2228  Validation loss = 7.5097  \n",
      "\n",
      "Fold: 16  Epoch: 59  Training loss = 5.2219  Validation loss = 7.5087  \n",
      "\n",
      "Fold: 16  Epoch: 60  Training loss = 5.2213  Validation loss = 7.5079  \n",
      "\n",
      "Fold: 16  Epoch: 61  Training loss = 5.2206  Validation loss = 7.5071  \n",
      "\n",
      "Fold: 16  Epoch: 62  Training loss = 5.2200  Validation loss = 7.5064  \n",
      "\n",
      "Fold: 16  Epoch: 63  Training loss = 5.2193  Validation loss = 7.5057  \n",
      "\n",
      "Fold: 16  Epoch: 64  Training loss = 5.2186  Validation loss = 7.5049  \n",
      "\n",
      "Fold: 16  Epoch: 65  Training loss = 5.2178  Validation loss = 7.5040  \n",
      "\n",
      "Fold: 16  Epoch: 66  Training loss = 5.2170  Validation loss = 7.5032  \n",
      "\n",
      "Fold: 16  Epoch: 67  Training loss = 5.2162  Validation loss = 7.5022  \n",
      "\n",
      "Fold: 16  Epoch: 68  Training loss = 5.2154  Validation loss = 7.5014  \n",
      "\n",
      "Fold: 16  Epoch: 69  Training loss = 5.2147  Validation loss = 7.5006  \n",
      "\n",
      "Fold: 16  Epoch: 70  Training loss = 5.2140  Validation loss = 7.4999  \n",
      "\n",
      "Fold: 16  Epoch: 71  Training loss = 5.2133  Validation loss = 7.4990  \n",
      "\n",
      "Fold: 16  Epoch: 72  Training loss = 5.2125  Validation loss = 7.4982  \n",
      "\n",
      "Fold: 16  Epoch: 73  Training loss = 5.2118  Validation loss = 7.4973  \n",
      "\n",
      "Fold: 16  Epoch: 74  Training loss = 5.2111  Validation loss = 7.4965  \n",
      "\n",
      "Fold: 16  Epoch: 75  Training loss = 5.2105  Validation loss = 7.4958  \n",
      "\n",
      "Fold: 16  Epoch: 76  Training loss = 5.2096  Validation loss = 7.4946  \n",
      "\n",
      "Fold: 16  Epoch: 77  Training loss = 5.2090  Validation loss = 7.4940  \n",
      "\n",
      "Fold: 16  Epoch: 78  Training loss = 5.2083  Validation loss = 7.4932  \n",
      "\n",
      "Fold: 16  Epoch: 79  Training loss = 5.2075  Validation loss = 7.4922  \n",
      "\n",
      "Fold: 16  Epoch: 80  Training loss = 5.2068  Validation loss = 7.4915  \n",
      "\n",
      "Fold: 16  Epoch: 81  Training loss = 5.2060  Validation loss = 7.4905  \n",
      "\n",
      "Fold: 16  Epoch: 82  Training loss = 5.2052  Validation loss = 7.4895  \n",
      "\n",
      "Fold: 16  Epoch: 83  Training loss = 5.2046  Validation loss = 7.4888  \n",
      "\n",
      "Fold: 16  Epoch: 84  Training loss = 5.2039  Validation loss = 7.4880  \n",
      "\n",
      "Fold: 16  Epoch: 85  Training loss = 5.2034  Validation loss = 7.4875  \n",
      "\n",
      "Fold: 16  Epoch: 86  Training loss = 5.2028  Validation loss = 7.4867  \n",
      "\n",
      "Fold: 16  Epoch: 87  Training loss = 5.2021  Validation loss = 7.4860  \n",
      "\n",
      "Fold: 16  Epoch: 88  Training loss = 5.2015  Validation loss = 7.4853  \n",
      "\n",
      "Fold: 16  Epoch: 89  Training loss = 5.2009  Validation loss = 7.4846  \n",
      "\n",
      "Fold: 16  Epoch: 90  Training loss = 5.2002  Validation loss = 7.4838  \n",
      "\n",
      "Fold: 16  Epoch: 91  Training loss = 5.1996  Validation loss = 7.4831  \n",
      "\n",
      "Fold: 16  Epoch: 92  Training loss = 5.1989  Validation loss = 7.4824  \n",
      "\n",
      "Fold: 16  Epoch: 93  Training loss = 5.1982  Validation loss = 7.4817  \n",
      "\n",
      "Fold: 16  Epoch: 94  Training loss = 5.1975  Validation loss = 7.4808  \n",
      "\n",
      "Fold: 16  Epoch: 95  Training loss = 5.1969  Validation loss = 7.4802  \n",
      "\n",
      "Fold: 16  Epoch: 96  Training loss = 5.1963  Validation loss = 7.4796  \n",
      "\n",
      "Fold: 16  Epoch: 97  Training loss = 5.1956  Validation loss = 7.4788  \n",
      "\n",
      "Fold: 16  Epoch: 98  Training loss = 5.1947  Validation loss = 7.4777  \n",
      "\n",
      "Fold: 16  Epoch: 99  Training loss = 5.1939  Validation loss = 7.4768  \n",
      "\n",
      "Fold: 16  Epoch: 100  Training loss = 5.1932  Validation loss = 7.4760  \n",
      "\n",
      "Fold: 16  Epoch: 101  Training loss = 5.1924  Validation loss = 7.4752  \n",
      "\n",
      "Fold: 16  Epoch: 102  Training loss = 5.1918  Validation loss = 7.4744  \n",
      "\n",
      "Fold: 16  Epoch: 103  Training loss = 5.1911  Validation loss = 7.4736  \n",
      "\n",
      "Fold: 16  Epoch: 104  Training loss = 5.1907  Validation loss = 7.4731  \n",
      "\n",
      "Fold: 16  Epoch: 105  Training loss = 5.1899  Validation loss = 7.4725  \n",
      "\n",
      "Fold: 16  Epoch: 106  Training loss = 5.1892  Validation loss = 7.4716  \n",
      "\n",
      "Fold: 16  Epoch: 107  Training loss = 5.1886  Validation loss = 7.4708  \n",
      "\n",
      "Fold: 16  Epoch: 108  Training loss = 5.1879  Validation loss = 7.4701  \n",
      "\n",
      "Fold: 16  Epoch: 109  Training loss = 5.1872  Validation loss = 7.4692  \n",
      "\n",
      "Fold: 16  Epoch: 110  Training loss = 5.1865  Validation loss = 7.4685  \n",
      "\n",
      "Fold: 16  Epoch: 111  Training loss = 5.1858  Validation loss = 7.4676  \n",
      "\n",
      "Fold: 16  Epoch: 112  Training loss = 5.1851  Validation loss = 7.4668  \n",
      "\n",
      "Fold: 16  Epoch: 113  Training loss = 5.1845  Validation loss = 7.4661  \n",
      "\n",
      "Fold: 16  Epoch: 114  Training loss = 5.1837  Validation loss = 7.4653  \n",
      "\n",
      "Fold: 16  Epoch: 115  Training loss = 5.1831  Validation loss = 7.4646  \n",
      "\n",
      "Fold: 16  Epoch: 116  Training loss = 5.1825  Validation loss = 7.4639  \n",
      "\n",
      "Fold: 16  Epoch: 117  Training loss = 5.1817  Validation loss = 7.4630  \n",
      "\n",
      "Fold: 16  Epoch: 118  Training loss = 5.1811  Validation loss = 7.4623  \n",
      "\n",
      "Fold: 16  Epoch: 119  Training loss = 5.1805  Validation loss = 7.4617  \n",
      "\n",
      "Fold: 16  Epoch: 120  Training loss = 5.1798  Validation loss = 7.4608  \n",
      "\n",
      "Fold: 16  Epoch: 121  Training loss = 5.1791  Validation loss = 7.4600  \n",
      "\n",
      "Fold: 16  Epoch: 122  Training loss = 5.1783  Validation loss = 7.4591  \n",
      "\n",
      "Fold: 16  Epoch: 123  Training loss = 5.1777  Validation loss = 7.4584  \n",
      "\n",
      "Fold: 16  Epoch: 124  Training loss = 5.1770  Validation loss = 7.4575  \n",
      "\n",
      "Fold: 16  Epoch: 125  Training loss = 5.1764  Validation loss = 7.4567  \n",
      "\n",
      "Fold: 16  Epoch: 126  Training loss = 5.1758  Validation loss = 7.4561  \n",
      "\n",
      "Fold: 16  Epoch: 127  Training loss = 5.1752  Validation loss = 7.4554  \n",
      "\n",
      "Fold: 16  Epoch: 128  Training loss = 5.1744  Validation loss = 7.4546  \n",
      "\n",
      "Fold: 16  Epoch: 129  Training loss = 5.1738  Validation loss = 7.4538  \n",
      "\n",
      "Fold: 16  Epoch: 130  Training loss = 5.1732  Validation loss = 7.4531  \n",
      "\n",
      "Fold: 16  Epoch: 131  Training loss = 5.1725  Validation loss = 7.4524  \n",
      "\n",
      "Fold: 16  Epoch: 132  Training loss = 5.1718  Validation loss = 7.4516  \n",
      "\n",
      "Fold: 16  Epoch: 133  Training loss = 5.1711  Validation loss = 7.4510  \n",
      "\n",
      "Fold: 16  Epoch: 134  Training loss = 5.1702  Validation loss = 7.4499  \n",
      "\n",
      "Fold: 16  Epoch: 135  Training loss = 5.1695  Validation loss = 7.4490  \n",
      "\n",
      "Fold: 16  Epoch: 136  Training loss = 5.1688  Validation loss = 7.4481  \n",
      "\n",
      "Fold: 16  Epoch: 137  Training loss = 5.1684  Validation loss = 7.4476  \n",
      "\n",
      "Fold: 16  Epoch: 138  Training loss = 5.1677  Validation loss = 7.4468  \n",
      "\n",
      "Fold: 16  Epoch: 139  Training loss = 5.1671  Validation loss = 7.4462  \n",
      "\n",
      "Fold: 16  Epoch: 140  Training loss = 5.1665  Validation loss = 7.4455  \n",
      "\n",
      "Fold: 16  Epoch: 141  Training loss = 5.1659  Validation loss = 7.4448  \n",
      "\n",
      "Fold: 16  Epoch: 142  Training loss = 5.1653  Validation loss = 7.4442  \n",
      "\n",
      "Fold: 16  Epoch: 143  Training loss = 5.1645  Validation loss = 7.4434  \n",
      "\n",
      "Fold: 16  Epoch: 144  Training loss = 5.1639  Validation loss = 7.4427  \n",
      "\n",
      "Fold: 16  Epoch: 145  Training loss = 5.1632  Validation loss = 7.4420  \n",
      "\n",
      "Fold: 16  Epoch: 146  Training loss = 5.1626  Validation loss = 7.4413  \n",
      "\n",
      "Fold: 16  Epoch: 147  Training loss = 5.1621  Validation loss = 7.4406  \n",
      "\n",
      "Fold: 16  Epoch: 148  Training loss = 5.1614  Validation loss = 7.4398  \n",
      "\n",
      "Fold: 16  Epoch: 149  Training loss = 5.1607  Validation loss = 7.4391  \n",
      "\n",
      "Fold: 16  Epoch: 150  Training loss = 5.1600  Validation loss = 7.4382  \n",
      "\n",
      "Fold: 16  Epoch: 151  Training loss = 5.1594  Validation loss = 7.4375  \n",
      "\n",
      "Fold: 16  Epoch: 152  Training loss = 5.1588  Validation loss = 7.4368  \n",
      "\n",
      "Fold: 16  Epoch: 153  Training loss = 5.1579  Validation loss = 7.4358  \n",
      "\n",
      "Fold: 16  Epoch: 154  Training loss = 5.1572  Validation loss = 7.4351  \n",
      "\n",
      "Fold: 16  Epoch: 155  Training loss = 5.1565  Validation loss = 7.4343  \n",
      "\n",
      "Fold: 16  Epoch: 156  Training loss = 5.1559  Validation loss = 7.4336  \n",
      "\n",
      "Fold: 16  Epoch: 157  Training loss = 5.1552  Validation loss = 7.4328  \n",
      "\n",
      "Fold: 16  Epoch: 158  Training loss = 5.1545  Validation loss = 7.4320  \n",
      "\n",
      "Fold: 16  Epoch: 159  Training loss = 5.1538  Validation loss = 7.4314  \n",
      "\n",
      "Fold: 16  Epoch: 160  Training loss = 5.1532  Validation loss = 7.4307  \n",
      "\n",
      "Fold: 16  Epoch: 161  Training loss = 5.1524  Validation loss = 7.4297  \n",
      "\n",
      "Fold: 16  Epoch: 162  Training loss = 5.1518  Validation loss = 7.4291  \n",
      "\n",
      "Fold: 16  Epoch: 163  Training loss = 5.1513  Validation loss = 7.4284  \n",
      "\n",
      "Fold: 16  Epoch: 164  Training loss = 5.1506  Validation loss = 7.4277  \n",
      "\n",
      "Fold: 16  Epoch: 165  Training loss = 5.1498  Validation loss = 7.4269  \n",
      "\n",
      "Fold: 16  Epoch: 166  Training loss = 5.1492  Validation loss = 7.4262  \n",
      "\n",
      "Fold: 16  Epoch: 167  Training loss = 5.1483  Validation loss = 7.4252  \n",
      "\n",
      "Fold: 16  Epoch: 168  Training loss = 5.1478  Validation loss = 7.4246  \n",
      "\n",
      "Fold: 16  Epoch: 169  Training loss = 5.1472  Validation loss = 7.4240  \n",
      "\n",
      "Fold: 16  Epoch: 170  Training loss = 5.1465  Validation loss = 7.4232  \n",
      "\n",
      "Fold: 16  Epoch: 171  Training loss = 5.1459  Validation loss = 7.4226  \n",
      "\n",
      "Fold: 16  Epoch: 172  Training loss = 5.1452  Validation loss = 7.4219  \n",
      "\n",
      "Fold: 16  Epoch: 173  Training loss = 5.1446  Validation loss = 7.4212  \n",
      "\n",
      "Fold: 16  Epoch: 174  Training loss = 5.1438  Validation loss = 7.4203  \n",
      "\n",
      "Fold: 16  Epoch: 175  Training loss = 5.1432  Validation loss = 7.4196  \n",
      "\n",
      "Fold: 16  Epoch: 176  Training loss = 5.1426  Validation loss = 7.4189  \n",
      "\n",
      "Fold: 16  Epoch: 177  Training loss = 5.1420  Validation loss = 7.4180  \n",
      "\n",
      "Fold: 16  Epoch: 178  Training loss = 5.1412  Validation loss = 7.4173  \n",
      "\n",
      "Fold: 16  Epoch: 179  Training loss = 5.1404  Validation loss = 7.4164  \n",
      "\n",
      "Fold: 16  Epoch: 180  Training loss = 5.1397  Validation loss = 7.4157  \n",
      "\n",
      "Fold: 16  Epoch: 181  Training loss = 5.1391  Validation loss = 7.4152  \n",
      "\n",
      "Fold: 16  Epoch: 182  Training loss = 5.1385  Validation loss = 7.4145  \n",
      "\n",
      "Fold: 16  Epoch: 183  Training loss = 5.1378  Validation loss = 7.4137  \n",
      "\n",
      "Fold: 16  Epoch: 184  Training loss = 5.1372  Validation loss = 7.4129  \n",
      "\n",
      "Fold: 16  Epoch: 185  Training loss = 5.1365  Validation loss = 7.4121  \n",
      "\n",
      "Fold: 16  Epoch: 186  Training loss = 5.1357  Validation loss = 7.4112  \n",
      "\n",
      "Fold: 16  Epoch: 187  Training loss = 5.1350  Validation loss = 7.4103  \n",
      "\n",
      "Fold: 16  Epoch: 188  Training loss = 5.1343  Validation loss = 7.4093  \n",
      "\n",
      "Fold: 16  Epoch: 189  Training loss = 5.1336  Validation loss = 7.4085  \n",
      "\n",
      "Fold: 16  Epoch: 190  Training loss = 5.1329  Validation loss = 7.4076  \n",
      "\n",
      "Fold: 16  Epoch: 191  Training loss = 5.1322  Validation loss = 7.4069  \n",
      "\n",
      "Fold: 16  Epoch: 192  Training loss = 5.1315  Validation loss = 7.4060  \n",
      "\n",
      "Fold: 16  Epoch: 193  Training loss = 5.1308  Validation loss = 7.4051  \n",
      "\n",
      "Fold: 16  Epoch: 194  Training loss = 5.1302  Validation loss = 7.4045  \n",
      "\n",
      "Fold: 16  Epoch: 195  Training loss = 5.1296  Validation loss = 7.4039  \n",
      "\n",
      "Fold: 16  Epoch: 196  Training loss = 5.1289  Validation loss = 7.4031  \n",
      "\n",
      "Fold: 16  Epoch: 197  Training loss = 5.1282  Validation loss = 7.4023  \n",
      "\n",
      "Fold: 16  Epoch: 198  Training loss = 5.1275  Validation loss = 7.4015  \n",
      "\n",
      "Fold: 16  Epoch: 199  Training loss = 5.1269  Validation loss = 7.4008  \n",
      "\n",
      "Fold: 16  Epoch: 200  Training loss = 5.1261  Validation loss = 7.3998  \n",
      "\n",
      "Fold: 16  Epoch: 201  Training loss = 5.1254  Validation loss = 7.3991  \n",
      "\n",
      "Fold: 16  Epoch: 202  Training loss = 5.1247  Validation loss = 7.3983  \n",
      "\n",
      "Fold: 16  Epoch: 203  Training loss = 5.1238  Validation loss = 7.3972  \n",
      "\n",
      "Fold: 16  Epoch: 204  Training loss = 5.1231  Validation loss = 7.3963  \n",
      "\n",
      "Fold: 16  Epoch: 205  Training loss = 5.1225  Validation loss = 7.3954  \n",
      "\n",
      "Fold: 16  Epoch: 206  Training loss = 5.1216  Validation loss = 7.3945  \n",
      "\n",
      "Fold: 16  Epoch: 207  Training loss = 5.1211  Validation loss = 7.3940  \n",
      "\n",
      "Fold: 16  Epoch: 208  Training loss = 5.1205  Validation loss = 7.3932  \n",
      "\n",
      "Fold: 16  Epoch: 209  Training loss = 5.1198  Validation loss = 7.3923  \n",
      "\n",
      "Fold: 16  Epoch: 210  Training loss = 5.1191  Validation loss = 7.3915  \n",
      "\n",
      "Fold: 16  Epoch: 211  Training loss = 5.1185  Validation loss = 7.3908  \n",
      "\n",
      "Fold: 16  Epoch: 212  Training loss = 5.1178  Validation loss = 7.3901  \n",
      "\n",
      "Fold: 16  Epoch: 213  Training loss = 5.1171  Validation loss = 7.3891  \n",
      "\n",
      "Fold: 16  Epoch: 214  Training loss = 5.1165  Validation loss = 7.3884  \n",
      "\n",
      "Fold: 16  Epoch: 215  Training loss = 5.1158  Validation loss = 7.3876  \n",
      "\n",
      "Fold: 16  Epoch: 216  Training loss = 5.1151  Validation loss = 7.3868  \n",
      "\n",
      "Fold: 16  Epoch: 217  Training loss = 5.1144  Validation loss = 7.3860  \n",
      "\n",
      "Fold: 16  Epoch: 218  Training loss = 5.1138  Validation loss = 7.3854  \n",
      "\n",
      "Fold: 16  Epoch: 219  Training loss = 5.1132  Validation loss = 7.3847  \n",
      "\n",
      "Fold: 16  Epoch: 220  Training loss = 5.1126  Validation loss = 7.3838  \n",
      "\n",
      "Fold: 16  Epoch: 221  Training loss = 5.1121  Validation loss = 7.3833  \n",
      "\n",
      "Fold: 16  Epoch: 222  Training loss = 5.1115  Validation loss = 7.3827  \n",
      "\n",
      "Fold: 16  Epoch: 223  Training loss = 5.1109  Validation loss = 7.3818  \n",
      "\n",
      "Fold: 16  Epoch: 224  Training loss = 5.1101  Validation loss = 7.3810  \n",
      "\n",
      "Fold: 16  Epoch: 225  Training loss = 5.1093  Validation loss = 7.3801  \n",
      "\n",
      "Fold: 16  Epoch: 226  Training loss = 5.1087  Validation loss = 7.3793  \n",
      "\n",
      "Fold: 16  Epoch: 227  Training loss = 5.1080  Validation loss = 7.3785  \n",
      "\n",
      "Fold: 16  Epoch: 228  Training loss = 5.1073  Validation loss = 7.3777  \n",
      "\n",
      "Fold: 16  Epoch: 229  Training loss = 5.1065  Validation loss = 7.3769  \n",
      "\n",
      "Fold: 16  Epoch: 230  Training loss = 5.1058  Validation loss = 7.3761  \n",
      "\n",
      "Fold: 16  Epoch: 231  Training loss = 5.1051  Validation loss = 7.3753  \n",
      "\n",
      "Fold: 16  Epoch: 232  Training loss = 5.1044  Validation loss = 7.3745  \n",
      "\n",
      "Fold: 16  Epoch: 233  Training loss = 5.1038  Validation loss = 7.3738  \n",
      "\n",
      "Fold: 16  Epoch: 234  Training loss = 5.1030  Validation loss = 7.3731  \n",
      "\n",
      "Fold: 16  Epoch: 235  Training loss = 5.1023  Validation loss = 7.3723  \n",
      "\n",
      "Fold: 16  Epoch: 236  Training loss = 5.1015  Validation loss = 7.3713  \n",
      "\n",
      "Fold: 16  Epoch: 237  Training loss = 5.1010  Validation loss = 7.3706  \n",
      "\n",
      "Fold: 16  Epoch: 238  Training loss = 5.1003  Validation loss = 7.3699  \n",
      "\n",
      "Fold: 16  Epoch: 239  Training loss = 5.0997  Validation loss = 7.3691  \n",
      "\n",
      "Fold: 16  Epoch: 240  Training loss = 5.0991  Validation loss = 7.3683  \n",
      "\n",
      "Fold: 16  Epoch: 241  Training loss = 5.0984  Validation loss = 7.3675  \n",
      "\n",
      "Fold: 16  Epoch: 242  Training loss = 5.0979  Validation loss = 7.3668  \n",
      "\n",
      "Fold: 16  Epoch: 243  Training loss = 5.0974  Validation loss = 7.3662  \n",
      "\n",
      "Fold: 16  Epoch: 244  Training loss = 5.0967  Validation loss = 7.3654  \n",
      "\n",
      "Fold: 16  Epoch: 245  Training loss = 5.0961  Validation loss = 7.3646  \n",
      "\n",
      "Fold: 16  Epoch: 246  Training loss = 5.0955  Validation loss = 7.3639  \n",
      "\n",
      "Fold: 16  Epoch: 247  Training loss = 5.0950  Validation loss = 7.3632  \n",
      "\n",
      "Fold: 16  Epoch: 248  Training loss = 5.0942  Validation loss = 7.3625  \n",
      "\n",
      "Fold: 16  Epoch: 249  Training loss = 5.0936  Validation loss = 7.3618  \n",
      "\n",
      "Fold: 16  Epoch: 250  Training loss = 5.0929  Validation loss = 7.3610  \n",
      "\n",
      "Fold: 16  Epoch: 251  Training loss = 5.0923  Validation loss = 7.3604  \n",
      "\n",
      "Fold: 16  Epoch: 252  Training loss = 5.0916  Validation loss = 7.3596  \n",
      "\n",
      "Fold: 16  Epoch: 253  Training loss = 5.0909  Validation loss = 7.3589  \n",
      "\n",
      "Fold: 16  Epoch: 254  Training loss = 5.0903  Validation loss = 7.3581  \n",
      "\n",
      "Fold: 16  Epoch: 255  Training loss = 5.0895  Validation loss = 7.3572  \n",
      "\n",
      "Fold: 16  Epoch: 256  Training loss = 5.0888  Validation loss = 7.3564  \n",
      "\n",
      "Fold: 16  Epoch: 257  Training loss = 5.0881  Validation loss = 7.3554  \n",
      "\n",
      "Fold: 16  Epoch: 258  Training loss = 5.0873  Validation loss = 7.3547  \n",
      "\n",
      "Fold: 16  Epoch: 259  Training loss = 5.0867  Validation loss = 7.3540  \n",
      "\n",
      "Fold: 16  Epoch: 260  Training loss = 5.0861  Validation loss = 7.3533  \n",
      "\n",
      "Fold: 16  Epoch: 261  Training loss = 5.0855  Validation loss = 7.3526  \n",
      "\n",
      "Fold: 16  Epoch: 262  Training loss = 5.0848  Validation loss = 7.3519  \n",
      "\n",
      "Fold: 16  Epoch: 263  Training loss = 5.0843  Validation loss = 7.3513  \n",
      "\n",
      "Fold: 16  Epoch: 264  Training loss = 5.0834  Validation loss = 7.3503  \n",
      "\n",
      "Fold: 16  Epoch: 265  Training loss = 5.0827  Validation loss = 7.3496  \n",
      "\n",
      "Fold: 16  Epoch: 266  Training loss = 5.0820  Validation loss = 7.3486  \n",
      "\n",
      "Fold: 16  Epoch: 267  Training loss = 5.0814  Validation loss = 7.3477  \n",
      "\n",
      "Fold: 16  Epoch: 268  Training loss = 5.0806  Validation loss = 7.3467  \n",
      "\n",
      "Fold: 16  Epoch: 269  Training loss = 5.0800  Validation loss = 7.3461  \n",
      "\n",
      "Fold: 16  Epoch: 270  Training loss = 5.0794  Validation loss = 7.3454  \n",
      "\n",
      "Fold: 16  Epoch: 271  Training loss = 5.0788  Validation loss = 7.3446  \n",
      "\n",
      "Fold: 16  Epoch: 272  Training loss = 5.0781  Validation loss = 7.3438  \n",
      "\n",
      "Fold: 16  Epoch: 273  Training loss = 5.0775  Validation loss = 7.3431  \n",
      "\n",
      "Fold: 16  Epoch: 274  Training loss = 5.0769  Validation loss = 7.3423  \n",
      "\n",
      "Fold: 16  Epoch: 275  Training loss = 5.0763  Validation loss = 7.3416  \n",
      "\n",
      "Fold: 16  Epoch: 276  Training loss = 5.0756  Validation loss = 7.3408  \n",
      "\n",
      "Fold: 16  Epoch: 277  Training loss = 5.0751  Validation loss = 7.3402  \n",
      "\n",
      "Fold: 16  Epoch: 278  Training loss = 5.0744  Validation loss = 7.3395  \n",
      "\n",
      "Fold: 16  Epoch: 279  Training loss = 5.0738  Validation loss = 7.3386  \n",
      "\n",
      "Fold: 16  Epoch: 280  Training loss = 5.0732  Validation loss = 7.3379  \n",
      "\n",
      "Fold: 16  Epoch: 281  Training loss = 5.0726  Validation loss = 7.3371  \n",
      "\n",
      "Fold: 16  Epoch: 282  Training loss = 5.0719  Validation loss = 7.3363  \n",
      "\n",
      "Fold: 16  Epoch: 283  Training loss = 5.0712  Validation loss = 7.3355  \n",
      "\n",
      "Fold: 16  Epoch: 284  Training loss = 5.0705  Validation loss = 7.3346  \n",
      "\n",
      "Fold: 16  Epoch: 285  Training loss = 5.0697  Validation loss = 7.3337  \n",
      "\n",
      "Fold: 16  Epoch: 286  Training loss = 5.0688  Validation loss = 7.3328  \n",
      "\n",
      "Fold: 16  Epoch: 287  Training loss = 5.0682  Validation loss = 7.3321  \n",
      "\n",
      "Fold: 16  Epoch: 288  Training loss = 5.0675  Validation loss = 7.3313  \n",
      "\n",
      "Fold: 16  Epoch: 289  Training loss = 5.0668  Validation loss = 7.3305  \n",
      "\n",
      "Fold: 16  Epoch: 290  Training loss = 5.0660  Validation loss = 7.3296  \n",
      "\n",
      "Fold: 16  Epoch: 291  Training loss = 5.0654  Validation loss = 7.3289  \n",
      "\n",
      "Fold: 16  Epoch: 292  Training loss = 5.0648  Validation loss = 7.3283  \n",
      "\n",
      "Fold: 16  Epoch: 293  Training loss = 5.0643  Validation loss = 7.3277  \n",
      "\n",
      "Fold: 16  Epoch: 294  Training loss = 5.0637  Validation loss = 7.3270  \n",
      "\n",
      "Fold: 16  Epoch: 295  Training loss = 5.0630  Validation loss = 7.3263  \n",
      "\n",
      "Fold: 16  Epoch: 296  Training loss = 5.0624  Validation loss = 7.3255  \n",
      "\n",
      "Fold: 16  Epoch: 297  Training loss = 5.0619  Validation loss = 7.3249  \n",
      "\n",
      "Fold: 16  Epoch: 298  Training loss = 5.0612  Validation loss = 7.3241  \n",
      "\n",
      "Fold: 16  Epoch: 299  Training loss = 5.0605  Validation loss = 7.3232  \n",
      "\n",
      "Fold: 16  Epoch: 300  Training loss = 5.0597  Validation loss = 7.3224  \n",
      "\n",
      "Fold: 16  Epoch: 301  Training loss = 5.0591  Validation loss = 7.3217  \n",
      "\n",
      "Fold: 16  Epoch: 302  Training loss = 5.0586  Validation loss = 7.3210  \n",
      "\n",
      "Fold: 16  Epoch: 303  Training loss = 5.0579  Validation loss = 7.3203  \n",
      "\n",
      "Fold: 16  Epoch: 304  Training loss = 5.0572  Validation loss = 7.3194  \n",
      "\n",
      "Fold: 16  Epoch: 305  Training loss = 5.0566  Validation loss = 7.3188  \n",
      "\n",
      "Fold: 16  Epoch: 306  Training loss = 5.0561  Validation loss = 7.3180  \n",
      "\n",
      "Fold: 16  Epoch: 307  Training loss = 5.0555  Validation loss = 7.3174  \n",
      "\n",
      "Fold: 16  Epoch: 308  Training loss = 5.0549  Validation loss = 7.3166  \n",
      "\n",
      "Fold: 16  Epoch: 309  Training loss = 5.0542  Validation loss = 7.3158  \n",
      "\n",
      "Fold: 16  Epoch: 310  Training loss = 5.0536  Validation loss = 7.3151  \n",
      "\n",
      "Fold: 16  Epoch: 311  Training loss = 5.0530  Validation loss = 7.3144  \n",
      "\n",
      "Fold: 16  Epoch: 312  Training loss = 5.0524  Validation loss = 7.3136  \n",
      "\n",
      "Fold: 16  Epoch: 313  Training loss = 5.0516  Validation loss = 7.3128  \n",
      "\n",
      "Fold: 16  Epoch: 314  Training loss = 5.0510  Validation loss = 7.3120  \n",
      "\n",
      "Fold: 16  Epoch: 315  Training loss = 5.0502  Validation loss = 7.3111  \n",
      "\n",
      "Fold: 16  Epoch: 316  Training loss = 5.0495  Validation loss = 7.3101  \n",
      "\n",
      "Fold: 16  Epoch: 317  Training loss = 5.0487  Validation loss = 7.3090  \n",
      "\n",
      "Fold: 16  Epoch: 318  Training loss = 5.0481  Validation loss = 7.3084  \n",
      "\n",
      "Fold: 16  Epoch: 319  Training loss = 5.0473  Validation loss = 7.3075  \n",
      "\n",
      "Fold: 16  Epoch: 320  Training loss = 5.0467  Validation loss = 7.3068  \n",
      "\n",
      "Fold: 16  Epoch: 321  Training loss = 5.0460  Validation loss = 7.3059  \n",
      "\n",
      "Fold: 16  Epoch: 322  Training loss = 5.0454  Validation loss = 7.3052  \n",
      "\n",
      "Fold: 16  Epoch: 323  Training loss = 5.0446  Validation loss = 7.3044  \n",
      "\n",
      "Fold: 16  Epoch: 324  Training loss = 5.0440  Validation loss = 7.3037  \n",
      "\n",
      "Fold: 16  Epoch: 325  Training loss = 5.0434  Validation loss = 7.3028  \n",
      "\n",
      "Fold: 16  Epoch: 326  Training loss = 5.0427  Validation loss = 7.3018  \n",
      "\n",
      "Fold: 16  Epoch: 327  Training loss = 5.0421  Validation loss = 7.3012  \n",
      "\n",
      "Fold: 16  Epoch: 328  Training loss = 5.0415  Validation loss = 7.3005  \n",
      "\n",
      "Fold: 16  Epoch: 329  Training loss = 5.0408  Validation loss = 7.2998  \n",
      "\n",
      "Fold: 16  Epoch: 330  Training loss = 5.0401  Validation loss = 7.2990  \n",
      "\n",
      "Fold: 16  Epoch: 331  Training loss = 5.0393  Validation loss = 7.2980  \n",
      "\n",
      "Fold: 16  Epoch: 332  Training loss = 5.0387  Validation loss = 7.2974  \n",
      "\n",
      "Fold: 16  Epoch: 333  Training loss = 5.0382  Validation loss = 7.2968  \n",
      "\n",
      "Fold: 16  Epoch: 334  Training loss = 5.0375  Validation loss = 7.2960  \n",
      "\n",
      "Fold: 16  Epoch: 335  Training loss = 5.0369  Validation loss = 7.2953  \n",
      "\n",
      "Fold: 16  Epoch: 336  Training loss = 5.0362  Validation loss = 7.2944  \n",
      "\n",
      "Fold: 16  Epoch: 337  Training loss = 5.0354  Validation loss = 7.2935  \n",
      "\n",
      "Fold: 16  Epoch: 338  Training loss = 5.0348  Validation loss = 7.2928  \n",
      "\n",
      "Fold: 16  Epoch: 339  Training loss = 5.0343  Validation loss = 7.2921  \n",
      "\n",
      "Fold: 16  Epoch: 340  Training loss = 5.0335  Validation loss = 7.2913  \n",
      "\n",
      "Fold: 16  Epoch: 341  Training loss = 5.0331  Validation loss = 7.2906  \n",
      "\n",
      "Fold: 16  Epoch: 342  Training loss = 5.0325  Validation loss = 7.2899  \n",
      "\n",
      "Fold: 16  Epoch: 343  Training loss = 5.0318  Validation loss = 7.2891  \n",
      "\n",
      "Fold: 16  Epoch: 344  Training loss = 5.0313  Validation loss = 7.2884  \n",
      "\n",
      "Fold: 16  Epoch: 345  Training loss = 5.0307  Validation loss = 7.2877  \n",
      "\n",
      "Fold: 16  Epoch: 346  Training loss = 5.0301  Validation loss = 7.2870  \n",
      "\n",
      "Fold: 16  Epoch: 347  Training loss = 5.0296  Validation loss = 7.2862  \n",
      "\n",
      "Fold: 16  Epoch: 348  Training loss = 5.0291  Validation loss = 7.2857  \n",
      "\n",
      "Fold: 16  Epoch: 349  Training loss = 5.0284  Validation loss = 7.2848  \n",
      "\n",
      "Fold: 16  Epoch: 350  Training loss = 5.0276  Validation loss = 7.2838  \n",
      "\n",
      "Fold: 16  Epoch: 351  Training loss = 5.0269  Validation loss = 7.2830  \n",
      "\n",
      "Fold: 16  Epoch: 352  Training loss = 5.0261  Validation loss = 7.2819  \n",
      "\n",
      "Fold: 16  Epoch: 353  Training loss = 5.0254  Validation loss = 7.2812  \n",
      "\n",
      "Fold: 16  Epoch: 354  Training loss = 5.0247  Validation loss = 7.2803  \n",
      "\n",
      "Fold: 16  Epoch: 355  Training loss = 5.0241  Validation loss = 7.2795  \n",
      "\n",
      "Fold: 16  Epoch: 356  Training loss = 5.0236  Validation loss = 7.2789  \n",
      "\n",
      "Fold: 16  Epoch: 357  Training loss = 5.0230  Validation loss = 7.2782  \n",
      "\n",
      "Fold: 16  Epoch: 358  Training loss = 5.0224  Validation loss = 7.2776  \n",
      "\n",
      "Fold: 16  Epoch: 359  Training loss = 5.0218  Validation loss = 7.2768  \n",
      "\n",
      "Fold: 16  Epoch: 360  Training loss = 5.0213  Validation loss = 7.2761  \n",
      "\n",
      "Fold: 16  Epoch: 361  Training loss = 5.0205  Validation loss = 7.2751  \n",
      "\n",
      "Fold: 16  Epoch: 362  Training loss = 5.0200  Validation loss = 7.2744  \n",
      "\n",
      "Fold: 16  Epoch: 363  Training loss = 5.0193  Validation loss = 7.2736  \n",
      "\n",
      "Fold: 16  Epoch: 364  Training loss = 5.0186  Validation loss = 7.2726  \n",
      "\n",
      "Fold: 16  Epoch: 365  Training loss = 5.0180  Validation loss = 7.2718  \n",
      "\n",
      "Fold: 16  Epoch: 366  Training loss = 5.0173  Validation loss = 7.2710  \n",
      "\n",
      "Fold: 16  Epoch: 367  Training loss = 5.0167  Validation loss = 7.2703  \n",
      "\n",
      "Fold: 16  Epoch: 368  Training loss = 5.0161  Validation loss = 7.2694  \n",
      "\n",
      "Fold: 16  Epoch: 369  Training loss = 5.0153  Validation loss = 7.2686  \n",
      "\n",
      "Fold: 16  Epoch: 370  Training loss = 5.0146  Validation loss = 7.2679  \n",
      "\n",
      "Fold: 16  Epoch: 371  Training loss = 5.0141  Validation loss = 7.2673  \n",
      "\n",
      "Fold: 16  Epoch: 372  Training loss = 5.0134  Validation loss = 7.2664  \n",
      "\n",
      "Fold: 16  Epoch: 373  Training loss = 5.0127  Validation loss = 7.2656  \n",
      "\n",
      "Fold: 16  Epoch: 374  Training loss = 5.0121  Validation loss = 7.2649  \n",
      "\n",
      "Fold: 16  Epoch: 375  Training loss = 5.0116  Validation loss = 7.2642  \n",
      "\n",
      "Fold: 16  Epoch: 376  Training loss = 5.0109  Validation loss = 7.2635  \n",
      "\n",
      "Fold: 16  Epoch: 377  Training loss = 5.0103  Validation loss = 7.2627  \n",
      "\n",
      "Fold: 16  Epoch: 378  Training loss = 5.0096  Validation loss = 7.2618  \n",
      "\n",
      "Fold: 16  Epoch: 379  Training loss = 5.0091  Validation loss = 7.2612  \n",
      "\n",
      "Fold: 16  Epoch: 380  Training loss = 5.0086  Validation loss = 7.2605  \n",
      "\n",
      "Fold: 16  Epoch: 381  Training loss = 5.0081  Validation loss = 7.2599  \n",
      "\n",
      "Fold: 16  Epoch: 382  Training loss = 5.0075  Validation loss = 7.2591  \n",
      "\n",
      "Fold: 16  Epoch: 383  Training loss = 5.0068  Validation loss = 7.2584  \n",
      "\n",
      "Fold: 16  Epoch: 384  Training loss = 5.0061  Validation loss = 7.2576  \n",
      "\n",
      "Fold: 16  Epoch: 385  Training loss = 5.0056  Validation loss = 7.2570  \n",
      "\n",
      "Fold: 16  Epoch: 386  Training loss = 5.0050  Validation loss = 7.2561  \n",
      "\n",
      "Fold: 16  Epoch: 387  Training loss = 5.0042  Validation loss = 7.2552  \n",
      "\n",
      "Fold: 16  Epoch: 388  Training loss = 5.0035  Validation loss = 7.2544  \n",
      "\n",
      "Fold: 16  Epoch: 389  Training loss = 5.0030  Validation loss = 7.2537  \n",
      "\n",
      "Fold: 16  Epoch: 390  Training loss = 5.0023  Validation loss = 7.2527  \n",
      "\n",
      "Fold: 16  Epoch: 391  Training loss = 5.0017  Validation loss = 7.2520  \n",
      "\n",
      "Fold: 16  Epoch: 392  Training loss = 5.0010  Validation loss = 7.2513  \n",
      "\n",
      "Fold: 16  Epoch: 393  Training loss = 5.0004  Validation loss = 7.2506  \n",
      "\n",
      "Fold: 16  Epoch: 394  Training loss = 4.9997  Validation loss = 7.2497  \n",
      "\n",
      "Fold: 16  Epoch: 395  Training loss = 4.9989  Validation loss = 7.2486  \n",
      "\n",
      "Fold: 16  Epoch: 396  Training loss = 4.9982  Validation loss = 7.2478  \n",
      "\n",
      "Fold: 16  Epoch: 397  Training loss = 4.9976  Validation loss = 7.2470  \n",
      "\n",
      "Fold: 16  Epoch: 398  Training loss = 4.9969  Validation loss = 7.2463  \n",
      "\n",
      "Fold: 16  Epoch: 399  Training loss = 4.9964  Validation loss = 7.2456  \n",
      "\n",
      "Fold: 16  Epoch: 400  Training loss = 4.9958  Validation loss = 7.2448  \n",
      "\n",
      "Fold: 16  Epoch: 401  Training loss = 4.9950  Validation loss = 7.2440  \n",
      "\n",
      "Fold: 16  Epoch: 402  Training loss = 4.9943  Validation loss = 7.2432  \n",
      "\n",
      "Fold: 16  Epoch: 403  Training loss = 4.9936  Validation loss = 7.2424  \n",
      "\n",
      "Fold: 16  Epoch: 404  Training loss = 4.9931  Validation loss = 7.2417  \n",
      "\n",
      "Fold: 16  Epoch: 405  Training loss = 4.9926  Validation loss = 7.2410  \n",
      "\n",
      "Fold: 16  Epoch: 406  Training loss = 4.9919  Validation loss = 7.2401  \n",
      "\n",
      "Fold: 16  Epoch: 407  Training loss = 4.9912  Validation loss = 7.2394  \n",
      "\n",
      "Fold: 16  Epoch: 408  Training loss = 4.9906  Validation loss = 7.2386  \n",
      "\n",
      "Fold: 16  Epoch: 409  Training loss = 4.9899  Validation loss = 7.2377  \n",
      "\n",
      "Fold: 16  Epoch: 410  Training loss = 4.9892  Validation loss = 7.2368  \n",
      "\n",
      "Fold: 16  Epoch: 411  Training loss = 4.9886  Validation loss = 7.2362  \n",
      "\n",
      "Fold: 16  Epoch: 412  Training loss = 4.9880  Validation loss = 7.2354  \n",
      "\n",
      "Fold: 16  Epoch: 413  Training loss = 4.9874  Validation loss = 7.2347  \n",
      "\n",
      "Fold: 16  Epoch: 414  Training loss = 4.9868  Validation loss = 7.2341  \n",
      "\n",
      "Fold: 16  Epoch: 415  Training loss = 4.9860  Validation loss = 7.2331  \n",
      "\n",
      "Fold: 16  Epoch: 416  Training loss = 4.9854  Validation loss = 7.2322  \n",
      "\n",
      "Fold: 16  Epoch: 417  Training loss = 4.9849  Validation loss = 7.2315  \n",
      "\n",
      "Fold: 16  Epoch: 418  Training loss = 4.9842  Validation loss = 7.2306  \n",
      "\n",
      "Fold: 16  Epoch: 419  Training loss = 4.9835  Validation loss = 7.2297  \n",
      "\n",
      "Fold: 16  Epoch: 420  Training loss = 4.9828  Validation loss = 7.2288  \n",
      "\n",
      "Fold: 16  Epoch: 421  Training loss = 4.9822  Validation loss = 7.2281  \n",
      "\n",
      "Fold: 16  Epoch: 422  Training loss = 4.9816  Validation loss = 7.2273  \n",
      "\n",
      "Fold: 16  Epoch: 423  Training loss = 4.9810  Validation loss = 7.2266  \n",
      "\n",
      "Fold: 16  Epoch: 424  Training loss = 4.9804  Validation loss = 7.2260  \n",
      "\n",
      "Fold: 16  Epoch: 425  Training loss = 4.9798  Validation loss = 7.2253  \n",
      "\n",
      "Fold: 16  Epoch: 426  Training loss = 4.9793  Validation loss = 7.2246  \n",
      "\n",
      "Fold: 16  Epoch: 427  Training loss = 4.9786  Validation loss = 7.2237  \n",
      "\n",
      "Fold: 16  Epoch: 428  Training loss = 4.9780  Validation loss = 7.2229  \n",
      "\n",
      "Fold: 16  Epoch: 429  Training loss = 4.9773  Validation loss = 7.2221  \n",
      "\n",
      "Fold: 16  Epoch: 430  Training loss = 4.9768  Validation loss = 7.2215  \n",
      "\n",
      "Fold: 16  Epoch: 431  Training loss = 4.9761  Validation loss = 7.2205  \n",
      "\n",
      "Fold: 16  Epoch: 432  Training loss = 4.9755  Validation loss = 7.2197  \n",
      "\n",
      "Fold: 16  Epoch: 433  Training loss = 4.9748  Validation loss = 7.2189  \n",
      "\n",
      "Fold: 16  Epoch: 434  Training loss = 4.9742  Validation loss = 7.2181  \n",
      "\n",
      "Fold: 16  Epoch: 435  Training loss = 4.9736  Validation loss = 7.2173  \n",
      "\n",
      "Fold: 16  Epoch: 436  Training loss = 4.9728  Validation loss = 7.2162  \n",
      "\n",
      "Fold: 16  Epoch: 437  Training loss = 4.9721  Validation loss = 7.2154  \n",
      "\n",
      "Fold: 16  Epoch: 438  Training loss = 4.9715  Validation loss = 7.2146  \n",
      "\n",
      "Fold: 16  Epoch: 439  Training loss = 4.9709  Validation loss = 7.2137  \n",
      "\n",
      "Fold: 16  Epoch: 440  Training loss = 4.9703  Validation loss = 7.2130  \n",
      "\n",
      "Fold: 16  Epoch: 441  Training loss = 4.9697  Validation loss = 7.2122  \n",
      "\n",
      "Fold: 16  Epoch: 442  Training loss = 4.9689  Validation loss = 7.2112  \n",
      "\n",
      "Fold: 16  Epoch: 443  Training loss = 4.9683  Validation loss = 7.2105  \n",
      "\n",
      "Fold: 16  Epoch: 444  Training loss = 4.9677  Validation loss = 7.2097  \n",
      "\n",
      "Fold: 16  Epoch: 445  Training loss = 4.9671  Validation loss = 7.2090  \n",
      "\n",
      "Fold: 16  Epoch: 446  Training loss = 4.9665  Validation loss = 7.2081  \n",
      "\n",
      "Fold: 16  Epoch: 447  Training loss = 4.9659  Validation loss = 7.2073  \n",
      "\n",
      "Fold: 16  Epoch: 448  Training loss = 4.9653  Validation loss = 7.2064  \n",
      "\n",
      "Fold: 16  Epoch: 449  Training loss = 4.9646  Validation loss = 7.2055  \n",
      "\n",
      "Fold: 16  Epoch: 450  Training loss = 4.9640  Validation loss = 7.2049  \n",
      "\n",
      "Fold: 16  Epoch: 451  Training loss = 4.9635  Validation loss = 7.2042  \n",
      "\n",
      "Fold: 16  Epoch: 452  Training loss = 4.9628  Validation loss = 7.2031  \n",
      "\n",
      "Fold: 16  Epoch: 453  Training loss = 4.9621  Validation loss = 7.2023  \n",
      "\n",
      "Fold: 16  Epoch: 454  Training loss = 4.9613  Validation loss = 7.2014  \n",
      "\n",
      "Fold: 16  Epoch: 455  Training loss = 4.9607  Validation loss = 7.2007  \n",
      "\n",
      "Fold: 16  Epoch: 456  Training loss = 4.9601  Validation loss = 7.2001  \n",
      "\n",
      "Fold: 16  Epoch: 457  Training loss = 4.9593  Validation loss = 7.1992  \n",
      "\n",
      "Fold: 16  Epoch: 458  Training loss = 4.9586  Validation loss = 7.1983  \n",
      "\n",
      "Fold: 16  Epoch: 459  Training loss = 4.9580  Validation loss = 7.1975  \n",
      "\n",
      "Fold: 16  Epoch: 460  Training loss = 4.9576  Validation loss = 7.1969  \n",
      "\n",
      "Fold: 16  Epoch: 461  Training loss = 4.9569  Validation loss = 7.1959  \n",
      "\n",
      "Fold: 16  Epoch: 462  Training loss = 4.9562  Validation loss = 7.1951  \n",
      "\n",
      "Fold: 16  Epoch: 463  Training loss = 4.9556  Validation loss = 7.1944  \n",
      "\n",
      "Fold: 16  Epoch: 464  Training loss = 4.9550  Validation loss = 7.1936  \n",
      "\n",
      "Fold: 16  Epoch: 465  Training loss = 4.9544  Validation loss = 7.1929  \n",
      "\n",
      "Fold: 16  Epoch: 466  Training loss = 4.9537  Validation loss = 7.1920  \n",
      "\n",
      "Fold: 16  Epoch: 467  Training loss = 4.9531  Validation loss = 7.1914  \n",
      "\n",
      "Fold: 16  Epoch: 468  Training loss = 4.9525  Validation loss = 7.1906  \n",
      "\n",
      "Fold: 16  Epoch: 469  Training loss = 4.9518  Validation loss = 7.1897  \n",
      "\n",
      "Fold: 16  Epoch: 470  Training loss = 4.9511  Validation loss = 7.1886  \n",
      "\n",
      "Fold: 16  Epoch: 471  Training loss = 4.9505  Validation loss = 7.1878  \n",
      "\n",
      "Fold: 16  Epoch: 472  Training loss = 4.9499  Validation loss = 7.1871  \n",
      "\n",
      "Fold: 16  Epoch: 473  Training loss = 4.9493  Validation loss = 7.1864  \n",
      "\n",
      "Fold: 16  Epoch: 474  Training loss = 4.9487  Validation loss = 7.1854  \n",
      "\n",
      "Fold: 16  Epoch: 475  Training loss = 4.9479  Validation loss = 7.1845  \n",
      "\n",
      "Fold: 16  Epoch: 476  Training loss = 4.9473  Validation loss = 7.1838  \n",
      "\n",
      "Fold: 16  Epoch: 477  Training loss = 4.9466  Validation loss = 7.1828  \n",
      "\n",
      "Fold: 16  Epoch: 478  Training loss = 4.9460  Validation loss = 7.1822  \n",
      "\n",
      "Fold: 16  Epoch: 479  Training loss = 4.9453  Validation loss = 7.1815  \n",
      "\n",
      "Fold: 16  Epoch: 480  Training loss = 4.9448  Validation loss = 7.1806  \n",
      "\n",
      "Fold: 16  Epoch: 481  Training loss = 4.9441  Validation loss = 7.1797  \n",
      "\n",
      "Fold: 16  Epoch: 482  Training loss = 4.9434  Validation loss = 7.1788  \n",
      "\n",
      "Fold: 16  Epoch: 483  Training loss = 4.9427  Validation loss = 7.1780  \n",
      "\n",
      "Fold: 16  Epoch: 484  Training loss = 4.9420  Validation loss = 7.1772  \n",
      "\n",
      "Fold: 16  Epoch: 485  Training loss = 4.9414  Validation loss = 7.1766  \n",
      "\n",
      "Fold: 16  Epoch: 486  Training loss = 4.9409  Validation loss = 7.1759  \n",
      "\n",
      "Fold: 16  Epoch: 487  Training loss = 4.9403  Validation loss = 7.1752  \n",
      "\n",
      "Fold: 16  Epoch: 488  Training loss = 4.9395  Validation loss = 7.1740  \n",
      "\n",
      "Fold: 16  Epoch: 489  Training loss = 4.9387  Validation loss = 7.1726  \n",
      "\n",
      "Fold: 16  Epoch: 490  Training loss = 4.9380  Validation loss = 7.1717  \n",
      "\n",
      "Fold: 16  Epoch: 491  Training loss = 4.9373  Validation loss = 7.1707  \n",
      "\n",
      "Fold: 16  Epoch: 492  Training loss = 4.9367  Validation loss = 7.1699  \n",
      "\n",
      "Fold: 16  Epoch: 493  Training loss = 4.9361  Validation loss = 7.1692  \n",
      "\n",
      "Fold: 16  Epoch: 494  Training loss = 4.9355  Validation loss = 7.1684  \n",
      "\n",
      "Fold: 16  Epoch: 495  Training loss = 4.9346  Validation loss = 7.1675  \n",
      "\n",
      "Fold: 16  Epoch: 496  Training loss = 4.9339  Validation loss = 7.1668  \n",
      "\n",
      "Fold: 16  Epoch: 497  Training loss = 4.9333  Validation loss = 7.1659  \n",
      "\n",
      "Fold: 16  Epoch: 498  Training loss = 4.9328  Validation loss = 7.1653  \n",
      "\n",
      "Fold: 16  Epoch: 499  Training loss = 4.9322  Validation loss = 7.1646  \n",
      "\n",
      "Fold: 16  Epoch: 500  Training loss = 4.9315  Validation loss = 7.1637  \n",
      "\n",
      "Check model:  Fold: 16  Optimal epoch: 500  \n",
      "\n",
      "Fold: 17  Epoch: 1  Training loss = 5.2317  Validation loss = 2.7490  \n",
      "\n",
      "Fold: 17  Epoch: 2  Training loss = 5.2309  Validation loss = 2.7486  \n",
      "\n",
      "Fold: 17  Epoch: 3  Training loss = 5.2302  Validation loss = 2.7482  \n",
      "\n",
      "Fold: 17  Epoch: 4  Training loss = 5.2293  Validation loss = 2.7479  \n",
      "\n",
      "Fold: 17  Epoch: 5  Training loss = 5.2284  Validation loss = 2.7474  \n",
      "\n",
      "Fold: 17  Epoch: 6  Training loss = 5.2276  Validation loss = 2.7471  \n",
      "\n",
      "Fold: 17  Epoch: 7  Training loss = 5.2268  Validation loss = 2.7467  \n",
      "\n",
      "Fold: 17  Epoch: 8  Training loss = 5.2259  Validation loss = 2.7464  \n",
      "\n",
      "Fold: 17  Epoch: 9  Training loss = 5.2251  Validation loss = 2.7460  \n",
      "\n",
      "Fold: 17  Epoch: 10  Training loss = 5.2244  Validation loss = 2.7457  \n",
      "\n",
      "Fold: 17  Epoch: 11  Training loss = 5.2236  Validation loss = 2.7453  \n",
      "\n",
      "Fold: 17  Epoch: 12  Training loss = 5.2226  Validation loss = 2.7450  \n",
      "\n",
      "Fold: 17  Epoch: 13  Training loss = 5.2218  Validation loss = 2.7445  \n",
      "\n",
      "Fold: 17  Epoch: 14  Training loss = 5.2210  Validation loss = 2.7442  \n",
      "\n",
      "Fold: 17  Epoch: 15  Training loss = 5.2200  Validation loss = 2.7437  \n",
      "\n",
      "Fold: 17  Epoch: 16  Training loss = 5.2193  Validation loss = 2.7433  \n",
      "\n",
      "Fold: 17  Epoch: 17  Training loss = 5.2184  Validation loss = 2.7429  \n",
      "\n",
      "Fold: 17  Epoch: 18  Training loss = 5.2176  Validation loss = 2.7425  \n",
      "\n",
      "Fold: 17  Epoch: 19  Training loss = 5.2168  Validation loss = 2.7422  \n",
      "\n",
      "Fold: 17  Epoch: 20  Training loss = 5.2159  Validation loss = 2.7418  \n",
      "\n",
      "Fold: 17  Epoch: 21  Training loss = 5.2150  Validation loss = 2.7414  \n",
      "\n",
      "Fold: 17  Epoch: 22  Training loss = 5.2143  Validation loss = 2.7411  \n",
      "\n",
      "Fold: 17  Epoch: 23  Training loss = 5.2134  Validation loss = 2.7407  \n",
      "\n",
      "Fold: 17  Epoch: 24  Training loss = 5.2124  Validation loss = 2.7404  \n",
      "\n",
      "Fold: 17  Epoch: 25  Training loss = 5.2116  Validation loss = 2.7401  \n",
      "\n",
      "Fold: 17  Epoch: 26  Training loss = 5.2107  Validation loss = 2.7397  \n",
      "\n",
      "Fold: 17  Epoch: 27  Training loss = 5.2098  Validation loss = 2.7393  \n",
      "\n",
      "Fold: 17  Epoch: 28  Training loss = 5.2090  Validation loss = 2.7390  \n",
      "\n",
      "Fold: 17  Epoch: 29  Training loss = 5.2082  Validation loss = 2.7385  \n",
      "\n",
      "Fold: 17  Epoch: 30  Training loss = 5.2073  Validation loss = 2.7381  \n",
      "\n",
      "Fold: 17  Epoch: 31  Training loss = 5.2066  Validation loss = 2.7378  \n",
      "\n",
      "Fold: 17  Epoch: 32  Training loss = 5.2058  Validation loss = 2.7375  \n",
      "\n",
      "Fold: 17  Epoch: 33  Training loss = 5.2049  Validation loss = 2.7372  \n",
      "\n",
      "Fold: 17  Epoch: 34  Training loss = 5.2040  Validation loss = 2.7368  \n",
      "\n",
      "Fold: 17  Epoch: 35  Training loss = 5.2031  Validation loss = 2.7363  \n",
      "\n",
      "Fold: 17  Epoch: 36  Training loss = 5.2023  Validation loss = 2.7360  \n",
      "\n",
      "Fold: 17  Epoch: 37  Training loss = 5.2016  Validation loss = 2.7356  \n",
      "\n",
      "Fold: 17  Epoch: 38  Training loss = 5.2005  Validation loss = 2.7353  \n",
      "\n",
      "Fold: 17  Epoch: 39  Training loss = 5.1997  Validation loss = 2.7349  \n",
      "\n",
      "Fold: 17  Epoch: 40  Training loss = 5.1987  Validation loss = 2.7346  \n",
      "\n",
      "Fold: 17  Epoch: 41  Training loss = 5.1976  Validation loss = 2.7342  \n",
      "\n",
      "Fold: 17  Epoch: 42  Training loss = 5.1968  Validation loss = 2.7339  \n",
      "\n",
      "Fold: 17  Epoch: 43  Training loss = 5.1958  Validation loss = 2.7336  \n",
      "\n",
      "Fold: 17  Epoch: 44  Training loss = 5.1943  Validation loss = 2.7331  \n",
      "\n",
      "Fold: 17  Epoch: 45  Training loss = 5.1927  Validation loss = 2.7327  \n",
      "\n",
      "Fold: 17  Epoch: 46  Training loss = 5.1912  Validation loss = 2.7324  \n",
      "\n",
      "Fold: 17  Epoch: 47  Training loss = 5.1897  Validation loss = 2.7320  \n",
      "\n",
      "Fold: 17  Epoch: 48  Training loss = 5.1888  Validation loss = 2.7317  \n",
      "\n",
      "Fold: 17  Epoch: 49  Training loss = 5.1876  Validation loss = 2.7313  \n",
      "\n",
      "Fold: 17  Epoch: 50  Training loss = 5.1866  Validation loss = 2.7310  \n",
      "\n",
      "Fold: 17  Epoch: 51  Training loss = 5.1859  Validation loss = 2.7307  \n",
      "\n",
      "Fold: 17  Epoch: 52  Training loss = 5.1850  Validation loss = 2.7303  \n",
      "\n",
      "Fold: 17  Epoch: 53  Training loss = 5.1844  Validation loss = 2.7300  \n",
      "\n",
      "Fold: 17  Epoch: 54  Training loss = 5.1835  Validation loss = 2.7296  \n",
      "\n",
      "Fold: 17  Epoch: 55  Training loss = 5.1826  Validation loss = 2.7294  \n",
      "\n",
      "Fold: 17  Epoch: 56  Training loss = 5.1819  Validation loss = 2.7290  \n",
      "\n",
      "Fold: 17  Epoch: 57  Training loss = 5.1811  Validation loss = 2.7287  \n",
      "\n",
      "Fold: 17  Epoch: 58  Training loss = 5.1804  Validation loss = 2.7284  \n",
      "\n",
      "Fold: 17  Epoch: 59  Training loss = 5.1796  Validation loss = 2.7281  \n",
      "\n",
      "Fold: 17  Epoch: 60  Training loss = 5.1788  Validation loss = 2.7278  \n",
      "\n",
      "Fold: 17  Epoch: 61  Training loss = 5.1779  Validation loss = 2.7273  \n",
      "\n",
      "Fold: 17  Epoch: 62  Training loss = 5.1771  Validation loss = 2.7270  \n",
      "\n",
      "Fold: 17  Epoch: 63  Training loss = 5.1762  Validation loss = 2.7266  \n",
      "\n",
      "Fold: 17  Epoch: 64  Training loss = 5.1755  Validation loss = 2.7263  \n",
      "\n",
      "Fold: 17  Epoch: 65  Training loss = 5.1746  Validation loss = 2.7260  \n",
      "\n",
      "Fold: 17  Epoch: 66  Training loss = 5.1739  Validation loss = 2.7257  \n",
      "\n",
      "Fold: 17  Epoch: 67  Training loss = 5.1732  Validation loss = 2.7253  \n",
      "\n",
      "Fold: 17  Epoch: 68  Training loss = 5.1724  Validation loss = 2.7250  \n",
      "\n",
      "Fold: 17  Epoch: 69  Training loss = 5.1716  Validation loss = 2.7246  \n",
      "\n",
      "Fold: 17  Epoch: 70  Training loss = 5.1708  Validation loss = 2.7243  \n",
      "\n",
      "Fold: 17  Epoch: 71  Training loss = 5.1701  Validation loss = 2.7241  \n",
      "\n",
      "Fold: 17  Epoch: 72  Training loss = 5.1694  Validation loss = 2.7238  \n",
      "\n",
      "Fold: 17  Epoch: 73  Training loss = 5.1687  Validation loss = 2.7235  \n",
      "\n",
      "Fold: 17  Epoch: 74  Training loss = 5.1679  Validation loss = 2.7231  \n",
      "\n",
      "Fold: 17  Epoch: 75  Training loss = 5.1670  Validation loss = 2.7227  \n",
      "\n",
      "Fold: 17  Epoch: 76  Training loss = 5.1664  Validation loss = 2.7224  \n",
      "\n",
      "Fold: 17  Epoch: 77  Training loss = 5.1657  Validation loss = 2.7221  \n",
      "\n",
      "Fold: 17  Epoch: 78  Training loss = 5.1647  Validation loss = 2.7217  \n",
      "\n",
      "Fold: 17  Epoch: 79  Training loss = 5.1638  Validation loss = 2.7213  \n",
      "\n",
      "Fold: 17  Epoch: 80  Training loss = 5.1630  Validation loss = 2.7210  \n",
      "\n",
      "Fold: 17  Epoch: 81  Training loss = 5.1623  Validation loss = 2.7207  \n",
      "\n",
      "Fold: 17  Epoch: 82  Training loss = 5.1616  Validation loss = 2.7203  \n",
      "\n",
      "Fold: 17  Epoch: 83  Training loss = 5.1607  Validation loss = 2.7199  \n",
      "\n",
      "Fold: 17  Epoch: 84  Training loss = 5.1600  Validation loss = 2.7195  \n",
      "\n",
      "Fold: 17  Epoch: 85  Training loss = 5.1592  Validation loss = 2.7192  \n",
      "\n",
      "Fold: 17  Epoch: 86  Training loss = 5.1585  Validation loss = 2.7189  \n",
      "\n",
      "Fold: 17  Epoch: 87  Training loss = 5.1578  Validation loss = 2.7185  \n",
      "\n",
      "Fold: 17  Epoch: 88  Training loss = 5.1570  Validation loss = 2.7182  \n",
      "\n",
      "Fold: 17  Epoch: 89  Training loss = 5.1563  Validation loss = 2.7178  \n",
      "\n",
      "Fold: 17  Epoch: 90  Training loss = 5.1555  Validation loss = 2.7175  \n",
      "\n",
      "Fold: 17  Epoch: 91  Training loss = 5.1548  Validation loss = 2.7172  \n",
      "\n",
      "Fold: 17  Epoch: 92  Training loss = 5.1539  Validation loss = 2.7168  \n",
      "\n",
      "Fold: 17  Epoch: 93  Training loss = 5.1531  Validation loss = 2.7164  \n",
      "\n",
      "Fold: 17  Epoch: 94  Training loss = 5.1523  Validation loss = 2.7161  \n",
      "\n",
      "Fold: 17  Epoch: 95  Training loss = 5.1514  Validation loss = 2.7157  \n",
      "\n",
      "Fold: 17  Epoch: 96  Training loss = 5.1505  Validation loss = 2.7153  \n",
      "\n",
      "Fold: 17  Epoch: 97  Training loss = 5.1497  Validation loss = 2.7149  \n",
      "\n",
      "Fold: 17  Epoch: 98  Training loss = 5.1490  Validation loss = 2.7146  \n",
      "\n",
      "Fold: 17  Epoch: 99  Training loss = 5.1483  Validation loss = 2.7143  \n",
      "\n",
      "Fold: 17  Epoch: 100  Training loss = 5.1475  Validation loss = 2.7139  \n",
      "\n",
      "Fold: 17  Epoch: 101  Training loss = 5.1467  Validation loss = 2.7135  \n",
      "\n",
      "Fold: 17  Epoch: 102  Training loss = 5.1460  Validation loss = 2.7133  \n",
      "\n",
      "Fold: 17  Epoch: 103  Training loss = 5.1450  Validation loss = 2.7129  \n",
      "\n",
      "Fold: 17  Epoch: 104  Training loss = 5.1443  Validation loss = 2.7125  \n",
      "\n",
      "Fold: 17  Epoch: 105  Training loss = 5.1435  Validation loss = 2.7123  \n",
      "\n",
      "Fold: 17  Epoch: 106  Training loss = 5.1427  Validation loss = 2.7119  \n",
      "\n",
      "Fold: 17  Epoch: 107  Training loss = 5.1420  Validation loss = 2.7115  \n",
      "\n",
      "Fold: 17  Epoch: 108  Training loss = 5.1412  Validation loss = 2.7113  \n",
      "\n",
      "Fold: 17  Epoch: 109  Training loss = 5.1405  Validation loss = 2.7110  \n",
      "\n",
      "Fold: 17  Epoch: 110  Training loss = 5.1399  Validation loss = 2.7107  \n",
      "\n",
      "Fold: 17  Epoch: 111  Training loss = 5.1391  Validation loss = 2.7104  \n",
      "\n",
      "Fold: 17  Epoch: 112  Training loss = 5.1383  Validation loss = 2.7100  \n",
      "\n",
      "Fold: 17  Epoch: 113  Training loss = 5.1375  Validation loss = 2.7095  \n",
      "\n",
      "Fold: 17  Epoch: 114  Training loss = 5.1366  Validation loss = 2.7091  \n",
      "\n",
      "Fold: 17  Epoch: 115  Training loss = 5.1357  Validation loss = 2.7088  \n",
      "\n",
      "Fold: 17  Epoch: 116  Training loss = 5.1347  Validation loss = 2.7084  \n",
      "\n",
      "Fold: 17  Epoch: 117  Training loss = 5.1339  Validation loss = 2.7080  \n",
      "\n",
      "Fold: 17  Epoch: 118  Training loss = 5.1331  Validation loss = 2.7077  \n",
      "\n",
      "Fold: 17  Epoch: 119  Training loss = 5.1325  Validation loss = 2.7075  \n",
      "\n",
      "Fold: 17  Epoch: 120  Training loss = 5.1317  Validation loss = 2.7071  \n",
      "\n",
      "Fold: 17  Epoch: 121  Training loss = 5.1310  Validation loss = 2.7068  \n",
      "\n",
      "Fold: 17  Epoch: 122  Training loss = 5.1302  Validation loss = 2.7064  \n",
      "\n",
      "Fold: 17  Epoch: 123  Training loss = 5.1296  Validation loss = 2.7062  \n",
      "\n",
      "Fold: 17  Epoch: 124  Training loss = 5.1288  Validation loss = 2.7058  \n",
      "\n",
      "Fold: 17  Epoch: 125  Training loss = 5.1281  Validation loss = 2.7056  \n",
      "\n",
      "Fold: 17  Epoch: 126  Training loss = 5.1272  Validation loss = 2.7053  \n",
      "\n",
      "Fold: 17  Epoch: 127  Training loss = 5.1264  Validation loss = 2.7049  \n",
      "\n",
      "Fold: 17  Epoch: 128  Training loss = 5.1255  Validation loss = 2.7045  \n",
      "\n",
      "Fold: 17  Epoch: 129  Training loss = 5.1246  Validation loss = 2.7041  \n",
      "\n",
      "Fold: 17  Epoch: 130  Training loss = 5.1239  Validation loss = 2.7037  \n",
      "\n",
      "Fold: 17  Epoch: 131  Training loss = 5.1231  Validation loss = 2.7034  \n",
      "\n",
      "Fold: 17  Epoch: 132  Training loss = 5.1223  Validation loss = 2.7030  \n",
      "\n",
      "Fold: 17  Epoch: 133  Training loss = 5.1216  Validation loss = 2.7026  \n",
      "\n",
      "Fold: 17  Epoch: 134  Training loss = 5.1209  Validation loss = 2.7023  \n",
      "\n",
      "Fold: 17  Epoch: 135  Training loss = 5.1202  Validation loss = 2.7020  \n",
      "\n",
      "Fold: 17  Epoch: 136  Training loss = 5.1193  Validation loss = 2.7017  \n",
      "\n",
      "Fold: 17  Epoch: 137  Training loss = 5.1185  Validation loss = 2.7013  \n",
      "\n",
      "Fold: 17  Epoch: 138  Training loss = 5.1179  Validation loss = 2.7010  \n",
      "\n",
      "Fold: 17  Epoch: 139  Training loss = 5.1171  Validation loss = 2.7007  \n",
      "\n",
      "Fold: 17  Epoch: 140  Training loss = 5.1163  Validation loss = 2.7004  \n",
      "\n",
      "Fold: 17  Epoch: 141  Training loss = 5.1154  Validation loss = 2.7000  \n",
      "\n",
      "Fold: 17  Epoch: 142  Training loss = 5.1147  Validation loss = 2.6997  \n",
      "\n",
      "Fold: 17  Epoch: 143  Training loss = 5.1140  Validation loss = 2.6995  \n",
      "\n",
      "Fold: 17  Epoch: 144  Training loss = 5.1130  Validation loss = 2.6992  \n",
      "\n",
      "Fold: 17  Epoch: 145  Training loss = 5.1123  Validation loss = 2.6989  \n",
      "\n",
      "Fold: 17  Epoch: 146  Training loss = 5.1117  Validation loss = 2.6987  \n",
      "\n",
      "Fold: 17  Epoch: 147  Training loss = 5.1109  Validation loss = 2.6983  \n",
      "\n",
      "Fold: 17  Epoch: 148  Training loss = 5.1101  Validation loss = 2.6980  \n",
      "\n",
      "Fold: 17  Epoch: 149  Training loss = 5.1095  Validation loss = 2.6977  \n",
      "\n",
      "Fold: 17  Epoch: 150  Training loss = 5.1087  Validation loss = 2.6975  \n",
      "\n",
      "Fold: 17  Epoch: 151  Training loss = 5.1080  Validation loss = 2.6971  \n",
      "\n",
      "Fold: 17  Epoch: 152  Training loss = 5.1072  Validation loss = 2.6968  \n",
      "\n",
      "Fold: 17  Epoch: 153  Training loss = 5.1066  Validation loss = 2.6966  \n",
      "\n",
      "Fold: 17  Epoch: 154  Training loss = 5.1058  Validation loss = 2.6963  \n",
      "\n",
      "Fold: 17  Epoch: 155  Training loss = 5.1050  Validation loss = 2.6959  \n",
      "\n",
      "Fold: 17  Epoch: 156  Training loss = 5.1041  Validation loss = 2.6955  \n",
      "\n",
      "Fold: 17  Epoch: 157  Training loss = 5.1033  Validation loss = 2.6952  \n",
      "\n",
      "Fold: 17  Epoch: 158  Training loss = 5.1025  Validation loss = 2.6949  \n",
      "\n",
      "Fold: 17  Epoch: 159  Training loss = 5.1017  Validation loss = 2.6946  \n",
      "\n",
      "Fold: 17  Epoch: 160  Training loss = 5.1008  Validation loss = 2.6943  \n",
      "\n",
      "Fold: 17  Epoch: 161  Training loss = 5.1000  Validation loss = 2.6939  \n",
      "\n",
      "Fold: 17  Epoch: 162  Training loss = 5.0992  Validation loss = 2.6935  \n",
      "\n",
      "Fold: 17  Epoch: 163  Training loss = 5.0983  Validation loss = 2.6931  \n",
      "\n",
      "Fold: 17  Epoch: 164  Training loss = 5.0975  Validation loss = 2.6928  \n",
      "\n",
      "Fold: 17  Epoch: 165  Training loss = 5.0967  Validation loss = 2.6924  \n",
      "\n",
      "Fold: 17  Epoch: 166  Training loss = 5.0959  Validation loss = 2.6921  \n",
      "\n",
      "Fold: 17  Epoch: 167  Training loss = 5.0951  Validation loss = 2.6918  \n",
      "\n",
      "Fold: 17  Epoch: 168  Training loss = 5.0944  Validation loss = 2.6916  \n",
      "\n",
      "Fold: 17  Epoch: 169  Training loss = 5.0936  Validation loss = 2.6912  \n",
      "\n",
      "Fold: 17  Epoch: 170  Training loss = 5.0927  Validation loss = 2.6909  \n",
      "\n",
      "Fold: 17  Epoch: 171  Training loss = 5.0920  Validation loss = 2.6906  \n",
      "\n",
      "Fold: 17  Epoch: 172  Training loss = 5.0913  Validation loss = 2.6904  \n",
      "\n",
      "Fold: 17  Epoch: 173  Training loss = 5.0903  Validation loss = 2.6900  \n",
      "\n",
      "Fold: 17  Epoch: 174  Training loss = 5.0895  Validation loss = 2.6896  \n",
      "\n",
      "Fold: 17  Epoch: 175  Training loss = 5.0887  Validation loss = 2.6894  \n",
      "\n",
      "Fold: 17  Epoch: 176  Training loss = 5.0880  Validation loss = 2.6891  \n",
      "\n",
      "Fold: 17  Epoch: 177  Training loss = 5.0872  Validation loss = 2.6887  \n",
      "\n",
      "Fold: 17  Epoch: 178  Training loss = 5.0866  Validation loss = 2.6885  \n",
      "\n",
      "Fold: 17  Epoch: 179  Training loss = 5.0860  Validation loss = 2.6881  \n",
      "\n",
      "Fold: 17  Epoch: 180  Training loss = 5.0851  Validation loss = 2.6877  \n",
      "\n",
      "Fold: 17  Epoch: 181  Training loss = 5.0842  Validation loss = 2.6872  \n",
      "\n",
      "Fold: 17  Epoch: 182  Training loss = 5.0834  Validation loss = 2.6868  \n",
      "\n",
      "Fold: 17  Epoch: 183  Training loss = 5.0827  Validation loss = 2.6865  \n",
      "\n",
      "Fold: 17  Epoch: 184  Training loss = 5.0820  Validation loss = 2.6862  \n",
      "\n",
      "Fold: 17  Epoch: 185  Training loss = 5.0812  Validation loss = 2.6858  \n",
      "\n",
      "Fold: 17  Epoch: 186  Training loss = 5.0805  Validation loss = 2.6855  \n",
      "\n",
      "Fold: 17  Epoch: 187  Training loss = 5.0797  Validation loss = 2.6852  \n",
      "\n",
      "Fold: 17  Epoch: 188  Training loss = 5.0790  Validation loss = 2.6850  \n",
      "\n",
      "Fold: 17  Epoch: 189  Training loss = 5.0781  Validation loss = 2.6846  \n",
      "\n",
      "Fold: 17  Epoch: 190  Training loss = 5.0775  Validation loss = 2.6843  \n",
      "\n",
      "Fold: 17  Epoch: 191  Training loss = 5.0768  Validation loss = 2.6841  \n",
      "\n",
      "Fold: 17  Epoch: 192  Training loss = 5.0762  Validation loss = 2.6837  \n",
      "\n",
      "Fold: 17  Epoch: 193  Training loss = 5.0755  Validation loss = 2.6834  \n",
      "\n",
      "Fold: 17  Epoch: 194  Training loss = 5.0748  Validation loss = 2.6831  \n",
      "\n",
      "Fold: 17  Epoch: 195  Training loss = 5.0741  Validation loss = 2.6828  \n",
      "\n",
      "Fold: 17  Epoch: 196  Training loss = 5.0732  Validation loss = 2.6824  \n",
      "\n",
      "Fold: 17  Epoch: 197  Training loss = 5.0724  Validation loss = 2.6821  \n",
      "\n",
      "Fold: 17  Epoch: 198  Training loss = 5.0714  Validation loss = 2.6817  \n",
      "\n",
      "Fold: 17  Epoch: 199  Training loss = 5.0708  Validation loss = 2.6815  \n",
      "\n",
      "Fold: 17  Epoch: 200  Training loss = 5.0701  Validation loss = 2.6812  \n",
      "\n",
      "Fold: 17  Epoch: 201  Training loss = 5.0694  Validation loss = 2.6809  \n",
      "\n",
      "Fold: 17  Epoch: 202  Training loss = 5.0685  Validation loss = 2.6805  \n",
      "\n",
      "Fold: 17  Epoch: 203  Training loss = 5.0678  Validation loss = 2.6802  \n",
      "\n",
      "Fold: 17  Epoch: 204  Training loss = 5.0671  Validation loss = 2.6800  \n",
      "\n",
      "Fold: 17  Epoch: 205  Training loss = 5.0664  Validation loss = 2.6798  \n",
      "\n",
      "Fold: 17  Epoch: 206  Training loss = 5.0655  Validation loss = 2.6794  \n",
      "\n",
      "Fold: 17  Epoch: 207  Training loss = 5.0648  Validation loss = 2.6792  \n",
      "\n",
      "Fold: 17  Epoch: 208  Training loss = 5.0639  Validation loss = 2.6788  \n",
      "\n",
      "Fold: 17  Epoch: 209  Training loss = 5.0632  Validation loss = 2.6785  \n",
      "\n",
      "Fold: 17  Epoch: 210  Training loss = 5.0624  Validation loss = 2.6782  \n",
      "\n",
      "Fold: 17  Epoch: 211  Training loss = 5.0617  Validation loss = 2.6779  \n",
      "\n",
      "Fold: 17  Epoch: 212  Training loss = 5.0609  Validation loss = 2.6775  \n",
      "\n",
      "Fold: 17  Epoch: 213  Training loss = 5.0602  Validation loss = 2.6772  \n",
      "\n",
      "Fold: 17  Epoch: 214  Training loss = 5.0595  Validation loss = 2.6769  \n",
      "\n",
      "Fold: 17  Epoch: 215  Training loss = 5.0586  Validation loss = 2.6765  \n",
      "\n",
      "Fold: 17  Epoch: 216  Training loss = 5.0580  Validation loss = 2.6763  \n",
      "\n",
      "Fold: 17  Epoch: 217  Training loss = 5.0573  Validation loss = 2.6760  \n",
      "\n",
      "Fold: 17  Epoch: 218  Training loss = 5.0564  Validation loss = 2.6757  \n",
      "\n",
      "Fold: 17  Epoch: 219  Training loss = 5.0556  Validation loss = 2.6754  \n",
      "\n",
      "Fold: 17  Epoch: 220  Training loss = 5.0548  Validation loss = 2.6751  \n",
      "\n",
      "Fold: 17  Epoch: 221  Training loss = 5.0540  Validation loss = 2.6747  \n",
      "\n",
      "Fold: 17  Epoch: 222  Training loss = 5.0532  Validation loss = 2.6743  \n",
      "\n",
      "Fold: 17  Epoch: 223  Training loss = 5.0525  Validation loss = 2.6741  \n",
      "\n",
      "Fold: 17  Epoch: 224  Training loss = 5.0517  Validation loss = 2.6737  \n",
      "\n",
      "Fold: 17  Epoch: 225  Training loss = 5.0508  Validation loss = 2.6734  \n",
      "\n",
      "Fold: 17  Epoch: 226  Training loss = 5.0500  Validation loss = 2.6730  \n",
      "\n",
      "Fold: 17  Epoch: 227  Training loss = 5.0491  Validation loss = 2.6726  \n",
      "\n",
      "Fold: 17  Epoch: 228  Training loss = 5.0484  Validation loss = 2.6722  \n",
      "\n",
      "Fold: 17  Epoch: 229  Training loss = 5.0475  Validation loss = 2.6719  \n",
      "\n",
      "Fold: 17  Epoch: 230  Training loss = 5.0467  Validation loss = 2.6716  \n",
      "\n",
      "Fold: 17  Epoch: 231  Training loss = 5.0458  Validation loss = 2.6712  \n",
      "\n",
      "Fold: 17  Epoch: 232  Training loss = 5.0449  Validation loss = 2.6709  \n",
      "\n",
      "Fold: 17  Epoch: 233  Training loss = 5.0440  Validation loss = 2.6706  \n",
      "\n",
      "Fold: 17  Epoch: 234  Training loss = 5.0432  Validation loss = 2.6703  \n",
      "\n",
      "Fold: 17  Epoch: 235  Training loss = 5.0426  Validation loss = 2.6701  \n",
      "\n",
      "Fold: 17  Epoch: 236  Training loss = 5.0417  Validation loss = 2.6697  \n",
      "\n",
      "Fold: 17  Epoch: 237  Training loss = 5.0410  Validation loss = 2.6694  \n",
      "\n",
      "Fold: 17  Epoch: 238  Training loss = 5.0402  Validation loss = 2.6690  \n",
      "\n",
      "Fold: 17  Epoch: 239  Training loss = 5.0396  Validation loss = 2.6688  \n",
      "\n",
      "Fold: 17  Epoch: 240  Training loss = 5.0388  Validation loss = 2.6684  \n",
      "\n",
      "Fold: 17  Epoch: 241  Training loss = 5.0380  Validation loss = 2.6682  \n",
      "\n",
      "Fold: 17  Epoch: 242  Training loss = 5.0373  Validation loss = 2.6679  \n",
      "\n",
      "Fold: 17  Epoch: 243  Training loss = 5.0366  Validation loss = 2.6677  \n",
      "\n",
      "Fold: 17  Epoch: 244  Training loss = 5.0359  Validation loss = 2.6675  \n",
      "\n",
      "Fold: 17  Epoch: 245  Training loss = 5.0351  Validation loss = 2.6671  \n",
      "\n",
      "Fold: 17  Epoch: 246  Training loss = 5.0344  Validation loss = 2.6669  \n",
      "\n",
      "Fold: 17  Epoch: 247  Training loss = 5.0335  Validation loss = 2.6665  \n",
      "\n",
      "Fold: 17  Epoch: 248  Training loss = 5.0326  Validation loss = 2.6661  \n",
      "\n",
      "Fold: 17  Epoch: 249  Training loss = 5.0319  Validation loss = 2.6658  \n",
      "\n",
      "Fold: 17  Epoch: 250  Training loss = 5.0313  Validation loss = 2.6655  \n",
      "\n",
      "Fold: 17  Epoch: 251  Training loss = 5.0305  Validation loss = 2.6652  \n",
      "\n",
      "Fold: 17  Epoch: 252  Training loss = 5.0297  Validation loss = 2.6649  \n",
      "\n",
      "Fold: 17  Epoch: 253  Training loss = 5.0290  Validation loss = 2.6645  \n",
      "\n",
      "Fold: 17  Epoch: 254  Training loss = 5.0282  Validation loss = 2.6643  \n",
      "\n",
      "Fold: 17  Epoch: 255  Training loss = 5.0274  Validation loss = 2.6639  \n",
      "\n",
      "Fold: 17  Epoch: 256  Training loss = 5.0267  Validation loss = 2.6637  \n",
      "\n",
      "Fold: 17  Epoch: 257  Training loss = 5.0260  Validation loss = 2.6634  \n",
      "\n",
      "Fold: 17  Epoch: 258  Training loss = 5.0253  Validation loss = 2.6630  \n",
      "\n",
      "Fold: 17  Epoch: 259  Training loss = 5.0246  Validation loss = 2.6627  \n",
      "\n",
      "Fold: 17  Epoch: 260  Training loss = 5.0238  Validation loss = 2.6624  \n",
      "\n",
      "Fold: 17  Epoch: 261  Training loss = 5.0231  Validation loss = 2.6621  \n",
      "\n",
      "Fold: 17  Epoch: 262  Training loss = 5.0224  Validation loss = 2.6618  \n",
      "\n",
      "Fold: 17  Epoch: 263  Training loss = 5.0217  Validation loss = 2.6616  \n",
      "\n",
      "Fold: 17  Epoch: 264  Training loss = 5.0209  Validation loss = 2.6612  \n",
      "\n",
      "Fold: 17  Epoch: 265  Training loss = 5.0202  Validation loss = 2.6609  \n",
      "\n",
      "Fold: 17  Epoch: 266  Training loss = 5.0194  Validation loss = 2.6606  \n",
      "\n",
      "Fold: 17  Epoch: 267  Training loss = 5.0188  Validation loss = 2.6604  \n",
      "\n",
      "Fold: 17  Epoch: 268  Training loss = 5.0181  Validation loss = 2.6601  \n",
      "\n",
      "Fold: 17  Epoch: 269  Training loss = 5.0174  Validation loss = 2.6598  \n",
      "\n",
      "Fold: 17  Epoch: 270  Training loss = 5.0165  Validation loss = 2.6594  \n",
      "\n",
      "Fold: 17  Epoch: 271  Training loss = 5.0158  Validation loss = 2.6591  \n",
      "\n",
      "Fold: 17  Epoch: 272  Training loss = 5.0149  Validation loss = 2.6588  \n",
      "\n",
      "Fold: 17  Epoch: 273  Training loss = 5.0142  Validation loss = 2.6586  \n",
      "\n",
      "Fold: 17  Epoch: 274  Training loss = 5.0134  Validation loss = 2.6584  \n",
      "\n",
      "Fold: 17  Epoch: 275  Training loss = 5.0127  Validation loss = 2.6580  \n",
      "\n",
      "Fold: 17  Epoch: 276  Training loss = 5.0120  Validation loss = 2.6577  \n",
      "\n",
      "Fold: 17  Epoch: 277  Training loss = 5.0114  Validation loss = 2.6575  \n",
      "\n",
      "Fold: 17  Epoch: 278  Training loss = 5.0107  Validation loss = 2.6572  \n",
      "\n",
      "Fold: 17  Epoch: 279  Training loss = 5.0100  Validation loss = 2.6569  \n",
      "\n",
      "Fold: 17  Epoch: 280  Training loss = 5.0093  Validation loss = 2.6566  \n",
      "\n",
      "Fold: 17  Epoch: 281  Training loss = 5.0085  Validation loss = 2.6563  \n",
      "\n",
      "Fold: 17  Epoch: 282  Training loss = 5.0078  Validation loss = 2.6560  \n",
      "\n",
      "Fold: 17  Epoch: 283  Training loss = 5.0070  Validation loss = 2.6557  \n",
      "\n",
      "Fold: 17  Epoch: 284  Training loss = 5.0064  Validation loss = 2.6556  \n",
      "\n",
      "Fold: 17  Epoch: 285  Training loss = 5.0057  Validation loss = 2.6553  \n",
      "\n",
      "Fold: 17  Epoch: 286  Training loss = 5.0050  Validation loss = 2.6551  \n",
      "\n",
      "Fold: 17  Epoch: 287  Training loss = 5.0042  Validation loss = 2.6548  \n",
      "\n",
      "Fold: 17  Epoch: 288  Training loss = 5.0034  Validation loss = 2.6545  \n",
      "\n",
      "Fold: 17  Epoch: 289  Training loss = 5.0025  Validation loss = 2.6542  \n",
      "\n",
      "Fold: 17  Epoch: 290  Training loss = 5.0018  Validation loss = 2.6539  \n",
      "\n",
      "Fold: 17  Epoch: 291  Training loss = 5.0010  Validation loss = 2.6536  \n",
      "\n",
      "Fold: 17  Epoch: 292  Training loss = 5.0002  Validation loss = 2.6533  \n",
      "\n",
      "Fold: 17  Epoch: 293  Training loss = 4.9995  Validation loss = 2.6531  \n",
      "\n",
      "Fold: 17  Epoch: 294  Training loss = 4.9988  Validation loss = 2.6528  \n",
      "\n",
      "Fold: 17  Epoch: 295  Training loss = 4.9980  Validation loss = 2.6525  \n",
      "\n",
      "Fold: 17  Epoch: 296  Training loss = 4.9972  Validation loss = 2.6522  \n",
      "\n",
      "Fold: 17  Epoch: 297  Training loss = 4.9965  Validation loss = 2.6519  \n",
      "\n",
      "Fold: 17  Epoch: 298  Training loss = 4.9958  Validation loss = 2.6516  \n",
      "\n",
      "Fold: 17  Epoch: 299  Training loss = 4.9948  Validation loss = 2.6512  \n",
      "\n",
      "Fold: 17  Epoch: 300  Training loss = 4.9941  Validation loss = 2.6510  \n",
      "\n",
      "Fold: 17  Epoch: 301  Training loss = 4.9936  Validation loss = 2.6508  \n",
      "\n",
      "Fold: 17  Epoch: 302  Training loss = 4.9929  Validation loss = 2.6505  \n",
      "\n",
      "Fold: 17  Epoch: 303  Training loss = 4.9921  Validation loss = 2.6502  \n",
      "\n",
      "Fold: 17  Epoch: 304  Training loss = 4.9913  Validation loss = 2.6499  \n",
      "\n",
      "Fold: 17  Epoch: 305  Training loss = 4.9905  Validation loss = 2.6495  \n",
      "\n",
      "Fold: 17  Epoch: 306  Training loss = 4.9899  Validation loss = 2.6494  \n",
      "\n",
      "Fold: 17  Epoch: 307  Training loss = 4.9892  Validation loss = 2.6491  \n",
      "\n",
      "Fold: 17  Epoch: 308  Training loss = 4.9885  Validation loss = 2.6489  \n",
      "\n",
      "Fold: 17  Epoch: 309  Training loss = 4.9877  Validation loss = 2.6487  \n",
      "\n",
      "Fold: 17  Epoch: 310  Training loss = 4.9869  Validation loss = 2.6483  \n",
      "\n",
      "Fold: 17  Epoch: 311  Training loss = 4.9862  Validation loss = 2.6480  \n",
      "\n",
      "Fold: 17  Epoch: 312  Training loss = 4.9853  Validation loss = 2.6476  \n",
      "\n",
      "Fold: 17  Epoch: 313  Training loss = 4.9845  Validation loss = 2.6472  \n",
      "\n",
      "Fold: 17  Epoch: 314  Training loss = 4.9838  Validation loss = 2.6470  \n",
      "\n",
      "Fold: 17  Epoch: 315  Training loss = 4.9831  Validation loss = 2.6467  \n",
      "\n",
      "Fold: 17  Epoch: 316  Training loss = 4.9824  Validation loss = 2.6464  \n",
      "\n",
      "Fold: 17  Epoch: 317  Training loss = 4.9816  Validation loss = 2.6461  \n",
      "\n",
      "Fold: 17  Epoch: 318  Training loss = 4.9808  Validation loss = 2.6458  \n",
      "\n",
      "Fold: 17  Epoch: 319  Training loss = 4.9801  Validation loss = 2.6457  \n",
      "\n",
      "Fold: 17  Epoch: 320  Training loss = 4.9793  Validation loss = 2.6454  \n",
      "\n",
      "Fold: 17  Epoch: 321  Training loss = 4.9785  Validation loss = 2.6452  \n",
      "\n",
      "Fold: 17  Epoch: 322  Training loss = 4.9777  Validation loss = 2.6448  \n",
      "\n",
      "Fold: 17  Epoch: 323  Training loss = 4.9768  Validation loss = 2.6445  \n",
      "\n",
      "Fold: 17  Epoch: 324  Training loss = 4.9760  Validation loss = 2.6443  \n",
      "\n",
      "Fold: 17  Epoch: 325  Training loss = 4.9751  Validation loss = 2.6440  \n",
      "\n",
      "Fold: 17  Epoch: 326  Training loss = 4.9744  Validation loss = 2.6437  \n",
      "\n",
      "Fold: 17  Epoch: 327  Training loss = 4.9738  Validation loss = 2.6434  \n",
      "\n",
      "Fold: 17  Epoch: 328  Training loss = 4.9730  Validation loss = 2.6432  \n",
      "\n",
      "Fold: 17  Epoch: 329  Training loss = 4.9723  Validation loss = 2.6430  \n",
      "\n",
      "Fold: 17  Epoch: 330  Training loss = 4.9715  Validation loss = 2.6427  \n",
      "\n",
      "Fold: 17  Epoch: 331  Training loss = 4.9708  Validation loss = 2.6425  \n",
      "\n",
      "Fold: 17  Epoch: 332  Training loss = 4.9699  Validation loss = 2.6422  \n",
      "\n",
      "Fold: 17  Epoch: 333  Training loss = 4.9692  Validation loss = 2.6420  \n",
      "\n",
      "Fold: 17  Epoch: 334  Training loss = 4.9683  Validation loss = 2.6417  \n",
      "\n",
      "Fold: 17  Epoch: 335  Training loss = 4.9675  Validation loss = 2.6414  \n",
      "\n",
      "Fold: 17  Epoch: 336  Training loss = 4.9668  Validation loss = 2.6411  \n",
      "\n",
      "Fold: 17  Epoch: 337  Training loss = 4.9661  Validation loss = 2.6409  \n",
      "\n",
      "Fold: 17  Epoch: 338  Training loss = 4.9654  Validation loss = 2.6407  \n",
      "\n",
      "Fold: 17  Epoch: 339  Training loss = 4.9647  Validation loss = 2.6404  \n",
      "\n",
      "Fold: 17  Epoch: 340  Training loss = 4.9640  Validation loss = 2.6401  \n",
      "\n",
      "Fold: 17  Epoch: 341  Training loss = 4.9634  Validation loss = 2.6399  \n",
      "\n",
      "Fold: 17  Epoch: 342  Training loss = 4.9627  Validation loss = 2.6396  \n",
      "\n",
      "Fold: 17  Epoch: 343  Training loss = 4.9620  Validation loss = 2.6394  \n",
      "\n",
      "Fold: 17  Epoch: 344  Training loss = 4.9612  Validation loss = 2.6392  \n",
      "\n",
      "Fold: 17  Epoch: 345  Training loss = 4.9606  Validation loss = 2.6389  \n",
      "\n",
      "Fold: 17  Epoch: 346  Training loss = 4.9598  Validation loss = 2.6387  \n",
      "\n",
      "Fold: 17  Epoch: 347  Training loss = 4.9591  Validation loss = 2.6384  \n",
      "\n",
      "Fold: 17  Epoch: 348  Training loss = 4.9581  Validation loss = 2.6381  \n",
      "\n",
      "Fold: 17  Epoch: 349  Training loss = 4.9573  Validation loss = 2.6379  \n",
      "\n",
      "Fold: 17  Epoch: 350  Training loss = 4.9567  Validation loss = 2.6376  \n",
      "\n",
      "Fold: 17  Epoch: 351  Training loss = 4.9560  Validation loss = 2.6374  \n",
      "\n",
      "Fold: 17  Epoch: 352  Training loss = 4.9552  Validation loss = 2.6371  \n",
      "\n",
      "Fold: 17  Epoch: 353  Training loss = 4.9545  Validation loss = 2.6369  \n",
      "\n",
      "Fold: 17  Epoch: 354  Training loss = 4.9538  Validation loss = 2.6366  \n",
      "\n",
      "Fold: 17  Epoch: 355  Training loss = 4.9530  Validation loss = 2.6364  \n",
      "\n",
      "Fold: 17  Epoch: 356  Training loss = 4.9523  Validation loss = 2.6361  \n",
      "\n",
      "Fold: 17  Epoch: 357  Training loss = 4.9516  Validation loss = 2.6359  \n",
      "\n",
      "Fold: 17  Epoch: 358  Training loss = 4.9509  Validation loss = 2.6355  \n",
      "\n",
      "Fold: 17  Epoch: 359  Training loss = 4.9503  Validation loss = 2.6353  \n",
      "\n",
      "Fold: 17  Epoch: 360  Training loss = 4.9493  Validation loss = 2.6350  \n",
      "\n",
      "Fold: 17  Epoch: 361  Training loss = 4.9485  Validation loss = 2.6346  \n",
      "\n",
      "Fold: 17  Epoch: 362  Training loss = 4.9478  Validation loss = 2.6344  \n",
      "\n",
      "Fold: 17  Epoch: 363  Training loss = 4.9473  Validation loss = 2.6341  \n",
      "\n",
      "Fold: 17  Epoch: 364  Training loss = 4.9464  Validation loss = 2.6339  \n",
      "\n",
      "Fold: 17  Epoch: 365  Training loss = 4.9459  Validation loss = 2.6338  \n",
      "\n",
      "Fold: 17  Epoch: 366  Training loss = 4.9452  Validation loss = 2.6335  \n",
      "\n",
      "Fold: 17  Epoch: 367  Training loss = 4.9444  Validation loss = 2.6333  \n",
      "\n",
      "Fold: 17  Epoch: 368  Training loss = 4.9435  Validation loss = 2.6330  \n",
      "\n",
      "Fold: 17  Epoch: 369  Training loss = 4.9430  Validation loss = 2.6329  \n",
      "\n",
      "Fold: 17  Epoch: 370  Training loss = 4.9424  Validation loss = 2.6327  \n",
      "\n",
      "Fold: 17  Epoch: 371  Training loss = 4.9418  Validation loss = 2.6325  \n",
      "\n",
      "Fold: 17  Epoch: 372  Training loss = 4.9412  Validation loss = 2.6323  \n",
      "\n",
      "Fold: 17  Epoch: 373  Training loss = 4.9403  Validation loss = 2.6320  \n",
      "\n",
      "Fold: 17  Epoch: 374  Training loss = 4.9395  Validation loss = 2.6318  \n",
      "\n",
      "Fold: 17  Epoch: 375  Training loss = 4.9387  Validation loss = 2.6315  \n",
      "\n",
      "Fold: 17  Epoch: 376  Training loss = 4.9380  Validation loss = 2.6313  \n",
      "\n",
      "Fold: 17  Epoch: 377  Training loss = 4.9372  Validation loss = 2.6311  \n",
      "\n",
      "Fold: 17  Epoch: 378  Training loss = 4.9363  Validation loss = 2.6306  \n",
      "\n",
      "Fold: 17  Epoch: 379  Training loss = 4.9354  Validation loss = 2.6303  \n",
      "\n",
      "Fold: 17  Epoch: 380  Training loss = 4.9347  Validation loss = 2.6300  \n",
      "\n",
      "Fold: 17  Epoch: 381  Training loss = 4.9339  Validation loss = 2.6298  \n",
      "\n",
      "Fold: 17  Epoch: 382  Training loss = 4.9332  Validation loss = 2.6295  \n",
      "\n",
      "Fold: 17  Epoch: 383  Training loss = 4.9324  Validation loss = 2.6293  \n",
      "\n",
      "Fold: 17  Epoch: 384  Training loss = 4.9316  Validation loss = 2.6290  \n",
      "\n",
      "Fold: 17  Epoch: 385  Training loss = 4.9309  Validation loss = 2.6287  \n",
      "\n",
      "Fold: 17  Epoch: 386  Training loss = 4.9301  Validation loss = 2.6285  \n",
      "\n",
      "Fold: 17  Epoch: 387  Training loss = 4.9293  Validation loss = 2.6283  \n",
      "\n",
      "Fold: 17  Epoch: 388  Training loss = 4.9287  Validation loss = 2.6282  \n",
      "\n",
      "Fold: 17  Epoch: 389  Training loss = 4.9279  Validation loss = 2.6279  \n",
      "\n",
      "Fold: 17  Epoch: 390  Training loss = 4.9273  Validation loss = 2.6277  \n",
      "\n",
      "Fold: 17  Epoch: 391  Training loss = 4.9265  Validation loss = 2.6274  \n",
      "\n",
      "Fold: 17  Epoch: 392  Training loss = 4.9258  Validation loss = 2.6272  \n",
      "\n",
      "Fold: 17  Epoch: 393  Training loss = 4.9248  Validation loss = 2.6270  \n",
      "\n",
      "Fold: 17  Epoch: 394  Training loss = 4.9242  Validation loss = 2.6268  \n",
      "\n",
      "Fold: 17  Epoch: 395  Training loss = 4.9236  Validation loss = 2.6266  \n",
      "\n",
      "Fold: 17  Epoch: 396  Training loss = 4.9228  Validation loss = 2.6263  \n",
      "\n",
      "Fold: 17  Epoch: 397  Training loss = 4.9222  Validation loss = 2.6261  \n",
      "\n",
      "Fold: 17  Epoch: 398  Training loss = 4.9216  Validation loss = 2.6259  \n",
      "\n",
      "Fold: 17  Epoch: 399  Training loss = 4.9209  Validation loss = 2.6257  \n",
      "\n",
      "Fold: 17  Epoch: 400  Training loss = 4.9200  Validation loss = 2.6254  \n",
      "\n",
      "Fold: 17  Epoch: 401  Training loss = 4.9193  Validation loss = 2.6252  \n",
      "\n",
      "Fold: 17  Epoch: 402  Training loss = 4.9187  Validation loss = 2.6249  \n",
      "\n",
      "Fold: 17  Epoch: 403  Training loss = 4.9180  Validation loss = 2.6247  \n",
      "\n",
      "Fold: 17  Epoch: 404  Training loss = 4.9172  Validation loss = 2.6245  \n",
      "\n",
      "Fold: 17  Epoch: 405  Training loss = 4.9165  Validation loss = 2.6243  \n",
      "\n",
      "Fold: 17  Epoch: 406  Training loss = 4.9158  Validation loss = 2.6241  \n",
      "\n",
      "Fold: 17  Epoch: 407  Training loss = 4.9150  Validation loss = 2.6238  \n",
      "\n",
      "Fold: 17  Epoch: 408  Training loss = 4.9142  Validation loss = 2.6236  \n",
      "\n",
      "Fold: 17  Epoch: 409  Training loss = 4.9134  Validation loss = 2.6233  \n",
      "\n",
      "Fold: 17  Epoch: 410  Training loss = 4.9126  Validation loss = 2.6231  \n",
      "\n",
      "Fold: 17  Epoch: 411  Training loss = 4.9118  Validation loss = 2.6228  \n",
      "\n",
      "Fold: 17  Epoch: 412  Training loss = 4.9111  Validation loss = 2.6226  \n",
      "\n",
      "Fold: 17  Epoch: 413  Training loss = 4.9104  Validation loss = 2.6224  \n",
      "\n",
      "Fold: 17  Epoch: 414  Training loss = 4.9098  Validation loss = 2.6222  \n",
      "\n",
      "Fold: 17  Epoch: 415  Training loss = 4.9092  Validation loss = 2.6220  \n",
      "\n",
      "Fold: 17  Epoch: 416  Training loss = 4.9084  Validation loss = 2.6218  \n",
      "\n",
      "Fold: 17  Epoch: 417  Training loss = 4.9075  Validation loss = 2.6215  \n",
      "\n",
      "Fold: 17  Epoch: 418  Training loss = 4.9066  Validation loss = 2.6212  \n",
      "\n",
      "Fold: 17  Epoch: 419  Training loss = 4.9058  Validation loss = 2.6209  \n",
      "\n",
      "Fold: 17  Epoch: 420  Training loss = 4.9051  Validation loss = 2.6206  \n",
      "\n",
      "Fold: 17  Epoch: 421  Training loss = 4.9044  Validation loss = 2.6204  \n",
      "\n",
      "Fold: 17  Epoch: 422  Training loss = 4.9037  Validation loss = 2.6202  \n",
      "\n",
      "Fold: 17  Epoch: 423  Training loss = 4.9030  Validation loss = 2.6200  \n",
      "\n",
      "Fold: 17  Epoch: 424  Training loss = 4.9022  Validation loss = 2.6197  \n",
      "\n",
      "Fold: 17  Epoch: 425  Training loss = 4.9017  Validation loss = 2.6196  \n",
      "\n",
      "Fold: 17  Epoch: 426  Training loss = 4.9009  Validation loss = 2.6194  \n",
      "\n",
      "Fold: 17  Epoch: 427  Training loss = 4.9003  Validation loss = 2.6192  \n",
      "\n",
      "Fold: 17  Epoch: 428  Training loss = 4.8995  Validation loss = 2.6189  \n",
      "\n",
      "Fold: 17  Epoch: 429  Training loss = 4.8989  Validation loss = 2.6188  \n",
      "\n",
      "Fold: 17  Epoch: 430  Training loss = 4.8982  Validation loss = 2.6186  \n",
      "\n",
      "Fold: 17  Epoch: 431  Training loss = 4.8974  Validation loss = 2.6183  \n",
      "\n",
      "Fold: 17  Epoch: 432  Training loss = 4.8967  Validation loss = 2.6181  \n",
      "\n",
      "Fold: 17  Epoch: 433  Training loss = 4.8959  Validation loss = 2.6179  \n",
      "\n",
      "Fold: 17  Epoch: 434  Training loss = 4.8951  Validation loss = 2.6176  \n",
      "\n",
      "Fold: 17  Epoch: 435  Training loss = 4.8945  Validation loss = 2.6174  \n",
      "\n",
      "Fold: 17  Epoch: 436  Training loss = 4.8937  Validation loss = 2.6171  \n",
      "\n",
      "Fold: 17  Epoch: 437  Training loss = 4.8929  Validation loss = 2.6168  \n",
      "\n",
      "Fold: 17  Epoch: 438  Training loss = 4.8922  Validation loss = 2.6167  \n",
      "\n",
      "Fold: 17  Epoch: 439  Training loss = 4.8915  Validation loss = 2.6164  \n",
      "\n",
      "Fold: 17  Epoch: 440  Training loss = 4.8908  Validation loss = 2.6161  \n",
      "\n",
      "Fold: 17  Epoch: 441  Training loss = 4.8901  Validation loss = 2.6159  \n",
      "\n",
      "Fold: 17  Epoch: 442  Training loss = 4.8893  Validation loss = 2.6157  \n",
      "\n",
      "Fold: 17  Epoch: 443  Training loss = 4.8886  Validation loss = 2.6155  \n",
      "\n",
      "Fold: 17  Epoch: 444  Training loss = 4.8879  Validation loss = 2.6153  \n",
      "\n",
      "Fold: 17  Epoch: 445  Training loss = 4.8872  Validation loss = 2.6151  \n",
      "\n",
      "Fold: 17  Epoch: 446  Training loss = 4.8863  Validation loss = 2.6149  \n",
      "\n",
      "Fold: 17  Epoch: 447  Training loss = 4.8857  Validation loss = 2.6146  \n",
      "\n",
      "Fold: 17  Epoch: 448  Training loss = 4.8849  Validation loss = 2.6144  \n",
      "\n",
      "Fold: 17  Epoch: 449  Training loss = 4.8842  Validation loss = 2.6142  \n",
      "\n",
      "Fold: 17  Epoch: 450  Training loss = 4.8835  Validation loss = 2.6141  \n",
      "\n",
      "Fold: 17  Epoch: 451  Training loss = 4.8829  Validation loss = 2.6138  \n",
      "\n",
      "Fold: 17  Epoch: 452  Training loss = 4.8821  Validation loss = 2.6136  \n",
      "\n",
      "Fold: 17  Epoch: 453  Training loss = 4.8814  Validation loss = 2.6134  \n",
      "\n",
      "Fold: 17  Epoch: 454  Training loss = 4.8806  Validation loss = 2.6132  \n",
      "\n",
      "Fold: 17  Epoch: 455  Training loss = 4.8797  Validation loss = 2.6129  \n",
      "\n",
      "Fold: 17  Epoch: 456  Training loss = 4.8791  Validation loss = 2.6127  \n",
      "\n",
      "Fold: 17  Epoch: 457  Training loss = 4.8784  Validation loss = 2.6125  \n",
      "\n",
      "Fold: 17  Epoch: 458  Training loss = 4.8777  Validation loss = 2.6123  \n",
      "\n",
      "Fold: 17  Epoch: 459  Training loss = 4.8769  Validation loss = 2.6121  \n",
      "\n",
      "Fold: 17  Epoch: 460  Training loss = 4.8762  Validation loss = 2.6118  \n",
      "\n",
      "Fold: 17  Epoch: 461  Training loss = 4.8754  Validation loss = 2.6116  \n",
      "\n",
      "Fold: 17  Epoch: 462  Training loss = 4.8747  Validation loss = 2.6113  \n",
      "\n",
      "Fold: 17  Epoch: 463  Training loss = 4.8740  Validation loss = 2.6112  \n",
      "\n",
      "Fold: 17  Epoch: 464  Training loss = 4.8733  Validation loss = 2.6110  \n",
      "\n",
      "Fold: 17  Epoch: 465  Training loss = 4.8723  Validation loss = 2.6108  \n",
      "\n",
      "Fold: 17  Epoch: 466  Training loss = 4.8716  Validation loss = 2.6106  \n",
      "\n",
      "Fold: 17  Epoch: 467  Training loss = 4.8709  Validation loss = 2.6104  \n",
      "\n",
      "Fold: 17  Epoch: 468  Training loss = 4.8701  Validation loss = 2.6102  \n",
      "\n",
      "Fold: 17  Epoch: 469  Training loss = 4.8694  Validation loss = 2.6101  \n",
      "\n",
      "Fold: 17  Epoch: 470  Training loss = 4.8687  Validation loss = 2.6099  \n",
      "\n",
      "Fold: 17  Epoch: 471  Training loss = 4.8680  Validation loss = 2.6096  \n",
      "\n",
      "Fold: 17  Epoch: 472  Training loss = 4.8673  Validation loss = 2.6094  \n",
      "\n",
      "Fold: 17  Epoch: 473  Training loss = 4.8666  Validation loss = 2.6092  \n",
      "\n",
      "Fold: 17  Epoch: 474  Training loss = 4.8659  Validation loss = 2.6090  \n",
      "\n",
      "Fold: 17  Epoch: 475  Training loss = 4.8650  Validation loss = 2.6088  \n",
      "\n",
      "Fold: 17  Epoch: 476  Training loss = 4.8643  Validation loss = 2.6085  \n",
      "\n",
      "Fold: 17  Epoch: 477  Training loss = 4.8635  Validation loss = 2.6083  \n",
      "\n",
      "Fold: 17  Epoch: 478  Training loss = 4.8628  Validation loss = 2.6080  \n",
      "\n",
      "Fold: 17  Epoch: 479  Training loss = 4.8622  Validation loss = 2.6079  \n",
      "\n",
      "Fold: 17  Epoch: 480  Training loss = 4.8615  Validation loss = 2.6076  \n",
      "\n",
      "Fold: 17  Epoch: 481  Training loss = 4.8609  Validation loss = 2.6074  \n",
      "\n",
      "Fold: 17  Epoch: 482  Training loss = 4.8600  Validation loss = 2.6072  \n",
      "\n",
      "Fold: 17  Epoch: 483  Training loss = 4.8592  Validation loss = 2.6070  \n",
      "\n",
      "Fold: 17  Epoch: 484  Training loss = 4.8585  Validation loss = 2.6067  \n",
      "\n",
      "Fold: 17  Epoch: 485  Training loss = 4.8578  Validation loss = 2.6065  \n",
      "\n",
      "Fold: 17  Epoch: 486  Training loss = 4.8572  Validation loss = 2.6064  \n",
      "\n",
      "Fold: 17  Epoch: 487  Training loss = 4.8564  Validation loss = 2.6062  \n",
      "\n",
      "Fold: 17  Epoch: 488  Training loss = 4.8555  Validation loss = 2.6059  \n",
      "\n",
      "Fold: 17  Epoch: 489  Training loss = 4.8547  Validation loss = 2.6057  \n",
      "\n",
      "Fold: 17  Epoch: 490  Training loss = 4.8540  Validation loss = 2.6055  \n",
      "\n",
      "Fold: 17  Epoch: 491  Training loss = 4.8534  Validation loss = 2.6053  \n",
      "\n",
      "Fold: 17  Epoch: 492  Training loss = 4.8527  Validation loss = 2.6051  \n",
      "\n",
      "Fold: 17  Epoch: 493  Training loss = 4.8518  Validation loss = 2.6049  \n",
      "\n",
      "Fold: 17  Epoch: 494  Training loss = 4.8512  Validation loss = 2.6047  \n",
      "\n",
      "Fold: 17  Epoch: 495  Training loss = 4.8504  Validation loss = 2.6046  \n",
      "\n",
      "Fold: 17  Epoch: 496  Training loss = 4.8495  Validation loss = 2.6043  \n",
      "\n",
      "Fold: 17  Epoch: 497  Training loss = 4.8486  Validation loss = 2.6041  \n",
      "\n",
      "Fold: 17  Epoch: 498  Training loss = 4.8481  Validation loss = 2.6040  \n",
      "\n",
      "Fold: 17  Epoch: 499  Training loss = 4.8474  Validation loss = 2.6038  \n",
      "\n",
      "Fold: 17  Epoch: 500  Training loss = 4.8467  Validation loss = 2.6037  \n",
      "\n",
      "Check model:  Fold: 17  Optimal epoch: 500  \n",
      "\n",
      "Fold: 18  Epoch: 1  Training loss = 4.8869  Validation loss = 2.0677  \n",
      "\n",
      "Fold: 18  Epoch: 2  Training loss = 4.8863  Validation loss = 2.0678  \n",
      "\n",
      "Fold: 18  Epoch: 3  Training loss = 4.8855  Validation loss = 2.0678  \n",
      "\n",
      "Fold: 18  Epoch: 4  Training loss = 4.8849  Validation loss = 2.0678  \n",
      "\n",
      "Fold: 18  Epoch: 5  Training loss = 4.8842  Validation loss = 2.0679  \n",
      "\n",
      "Fold: 18  Epoch: 6  Training loss = 4.8834  Validation loss = 2.0679  \n",
      "\n",
      "Fold: 18  Epoch: 7  Training loss = 4.8825  Validation loss = 2.0680  \n",
      "\n",
      "Fold: 18  Epoch: 8  Training loss = 4.8819  Validation loss = 2.0680  \n",
      "\n",
      "Fold: 18  Epoch: 9  Training loss = 4.8811  Validation loss = 2.0680  \n",
      "\n",
      "Fold: 18  Epoch: 10  Training loss = 4.8804  Validation loss = 2.0681  \n",
      "\n",
      "Fold: 18  Epoch: 11  Training loss = 4.8797  Validation loss = 2.0682  \n",
      "\n",
      "Check model:  Fold: 18  Optimal epoch: 1  \n",
      "\n",
      "Fold: 19  Epoch: 1  Training loss = 4.8944  Validation loss = 1.2007  \n",
      "\n",
      "Fold: 19  Epoch: 2  Training loss = 4.8936  Validation loss = 1.2001  \n",
      "\n",
      "Fold: 19  Epoch: 3  Training loss = 4.8928  Validation loss = 1.1994  \n",
      "\n",
      "Fold: 19  Epoch: 4  Training loss = 4.8920  Validation loss = 1.1987  \n",
      "\n",
      "Fold: 19  Epoch: 5  Training loss = 4.8912  Validation loss = 1.1981  \n",
      "\n",
      "Fold: 19  Epoch: 6  Training loss = 4.8904  Validation loss = 1.1975  \n",
      "\n",
      "Fold: 19  Epoch: 7  Training loss = 4.8897  Validation loss = 1.1969  \n",
      "\n",
      "Fold: 19  Epoch: 8  Training loss = 4.8890  Validation loss = 1.1964  \n",
      "\n",
      "Fold: 19  Epoch: 9  Training loss = 4.8881  Validation loss = 1.1957  \n",
      "\n",
      "Fold: 19  Epoch: 10  Training loss = 4.8874  Validation loss = 1.1951  \n",
      "\n",
      "Fold: 19  Epoch: 11  Training loss = 4.8866  Validation loss = 1.1944  \n",
      "\n",
      "Fold: 19  Epoch: 12  Training loss = 4.8858  Validation loss = 1.1937  \n",
      "\n",
      "Fold: 19  Epoch: 13  Training loss = 4.8850  Validation loss = 1.1931  \n",
      "\n",
      "Fold: 19  Epoch: 14  Training loss = 4.8843  Validation loss = 1.1925  \n",
      "\n",
      "Fold: 19  Epoch: 15  Training loss = 4.8835  Validation loss = 1.1918  \n",
      "\n",
      "Fold: 19  Epoch: 16  Training loss = 4.8828  Validation loss = 1.1913  \n",
      "\n",
      "Fold: 19  Epoch: 17  Training loss = 4.8820  Validation loss = 1.1906  \n",
      "\n",
      "Fold: 19  Epoch: 18  Training loss = 4.8814  Validation loss = 1.1902  \n",
      "\n",
      "Fold: 19  Epoch: 19  Training loss = 4.8806  Validation loss = 1.1896  \n",
      "\n",
      "Fold: 19  Epoch: 20  Training loss = 4.8798  Validation loss = 1.1889  \n",
      "\n",
      "Fold: 19  Epoch: 21  Training loss = 4.8791  Validation loss = 1.1883  \n",
      "\n",
      "Fold: 19  Epoch: 22  Training loss = 4.8782  Validation loss = 1.1876  \n",
      "\n",
      "Fold: 19  Epoch: 23  Training loss = 4.8776  Validation loss = 1.1871  \n",
      "\n",
      "Fold: 19  Epoch: 24  Training loss = 4.8768  Validation loss = 1.1865  \n",
      "\n",
      "Fold: 19  Epoch: 25  Training loss = 4.8761  Validation loss = 1.1859  \n",
      "\n",
      "Fold: 19  Epoch: 26  Training loss = 4.8751  Validation loss = 1.1851  \n",
      "\n",
      "Fold: 19  Epoch: 27  Training loss = 4.8744  Validation loss = 1.1846  \n",
      "\n",
      "Fold: 19  Epoch: 28  Training loss = 4.8737  Validation loss = 1.1841  \n",
      "\n",
      "Fold: 19  Epoch: 29  Training loss = 4.8730  Validation loss = 1.1834  \n",
      "\n",
      "Fold: 19  Epoch: 30  Training loss = 4.8721  Validation loss = 1.1827  \n",
      "\n",
      "Fold: 19  Epoch: 31  Training loss = 4.8714  Validation loss = 1.1822  \n",
      "\n",
      "Fold: 19  Epoch: 32  Training loss = 4.8707  Validation loss = 1.1817  \n",
      "\n",
      "Fold: 19  Epoch: 33  Training loss = 4.8699  Validation loss = 1.1811  \n",
      "\n",
      "Fold: 19  Epoch: 34  Training loss = 4.8691  Validation loss = 1.1804  \n",
      "\n",
      "Fold: 19  Epoch: 35  Training loss = 4.8683  Validation loss = 1.1798  \n",
      "\n",
      "Fold: 19  Epoch: 36  Training loss = 4.8676  Validation loss = 1.1793  \n",
      "\n",
      "Fold: 19  Epoch: 37  Training loss = 4.8668  Validation loss = 1.1787  \n",
      "\n",
      "Fold: 19  Epoch: 38  Training loss = 4.8662  Validation loss = 1.1782  \n",
      "\n",
      "Fold: 19  Epoch: 39  Training loss = 4.8653  Validation loss = 1.1775  \n",
      "\n",
      "Fold: 19  Epoch: 40  Training loss = 4.8647  Validation loss = 1.1770  \n",
      "\n",
      "Fold: 19  Epoch: 41  Training loss = 4.8638  Validation loss = 1.1764  \n",
      "\n",
      "Fold: 19  Epoch: 42  Training loss = 4.8630  Validation loss = 1.1758  \n",
      "\n",
      "Fold: 19  Epoch: 43  Training loss = 4.8622  Validation loss = 1.1752  \n",
      "\n",
      "Fold: 19  Epoch: 44  Training loss = 4.8615  Validation loss = 1.1745  \n",
      "\n",
      "Fold: 19  Epoch: 45  Training loss = 4.8607  Validation loss = 1.1739  \n",
      "\n",
      "Fold: 19  Epoch: 46  Training loss = 4.8599  Validation loss = 1.1733  \n",
      "\n",
      "Fold: 19  Epoch: 47  Training loss = 4.8589  Validation loss = 1.1727  \n",
      "\n",
      "Fold: 19  Epoch: 48  Training loss = 4.8582  Validation loss = 1.1721  \n",
      "\n",
      "Fold: 19  Epoch: 49  Training loss = 4.8575  Validation loss = 1.1716  \n",
      "\n",
      "Fold: 19  Epoch: 50  Training loss = 4.8568  Validation loss = 1.1710  \n",
      "\n",
      "Fold: 19  Epoch: 51  Training loss = 4.8560  Validation loss = 1.1704  \n",
      "\n",
      "Fold: 19  Epoch: 52  Training loss = 4.8550  Validation loss = 1.1697  \n",
      "\n",
      "Fold: 19  Epoch: 53  Training loss = 4.8543  Validation loss = 1.1692  \n",
      "\n",
      "Fold: 19  Epoch: 54  Training loss = 4.8536  Validation loss = 1.1687  \n",
      "\n",
      "Fold: 19  Epoch: 55  Training loss = 4.8530  Validation loss = 1.1683  \n",
      "\n",
      "Fold: 19  Epoch: 56  Training loss = 4.8521  Validation loss = 1.1677  \n",
      "\n",
      "Fold: 19  Epoch: 57  Training loss = 4.8512  Validation loss = 1.1670  \n",
      "\n",
      "Fold: 19  Epoch: 58  Training loss = 4.8504  Validation loss = 1.1664  \n",
      "\n",
      "Fold: 19  Epoch: 59  Training loss = 4.8496  Validation loss = 1.1658  \n",
      "\n",
      "Fold: 19  Epoch: 60  Training loss = 4.8489  Validation loss = 1.1653  \n",
      "\n",
      "Fold: 19  Epoch: 61  Training loss = 4.8480  Validation loss = 1.1646  \n",
      "\n",
      "Fold: 19  Epoch: 62  Training loss = 4.8471  Validation loss = 1.1640  \n",
      "\n",
      "Fold: 19  Epoch: 63  Training loss = 4.8463  Validation loss = 1.1634  \n",
      "\n",
      "Fold: 19  Epoch: 64  Training loss = 4.8456  Validation loss = 1.1628  \n",
      "\n",
      "Fold: 19  Epoch: 65  Training loss = 4.8448  Validation loss = 1.1623  \n",
      "\n",
      "Fold: 19  Epoch: 66  Training loss = 4.8439  Validation loss = 1.1616  \n",
      "\n",
      "Fold: 19  Epoch: 67  Training loss = 4.8431  Validation loss = 1.1610  \n",
      "\n",
      "Fold: 19  Epoch: 68  Training loss = 4.8424  Validation loss = 1.1606  \n",
      "\n",
      "Fold: 19  Epoch: 69  Training loss = 4.8417  Validation loss = 1.1601  \n",
      "\n",
      "Fold: 19  Epoch: 70  Training loss = 4.8407  Validation loss = 1.1593  \n",
      "\n",
      "Fold: 19  Epoch: 71  Training loss = 4.8400  Validation loss = 1.1587  \n",
      "\n",
      "Fold: 19  Epoch: 72  Training loss = 4.8392  Validation loss = 1.1583  \n",
      "\n",
      "Fold: 19  Epoch: 73  Training loss = 4.8385  Validation loss = 1.1578  \n",
      "\n",
      "Fold: 19  Epoch: 74  Training loss = 4.8378  Validation loss = 1.1572  \n",
      "\n",
      "Fold: 19  Epoch: 75  Training loss = 4.8369  Validation loss = 1.1566  \n",
      "\n",
      "Fold: 19  Epoch: 76  Training loss = 4.8363  Validation loss = 1.1561  \n",
      "\n",
      "Fold: 19  Epoch: 77  Training loss = 4.8355  Validation loss = 1.1555  \n",
      "\n",
      "Fold: 19  Epoch: 78  Training loss = 4.8347  Validation loss = 1.1549  \n",
      "\n",
      "Fold: 19  Epoch: 79  Training loss = 4.8339  Validation loss = 1.1544  \n",
      "\n",
      "Fold: 19  Epoch: 80  Training loss = 4.8331  Validation loss = 1.1539  \n",
      "\n",
      "Fold: 19  Epoch: 81  Training loss = 4.8323  Validation loss = 1.1534  \n",
      "\n",
      "Fold: 19  Epoch: 82  Training loss = 4.8314  Validation loss = 1.1528  \n",
      "\n",
      "Fold: 19  Epoch: 83  Training loss = 4.8306  Validation loss = 1.1522  \n",
      "\n",
      "Fold: 19  Epoch: 84  Training loss = 4.8298  Validation loss = 1.1517  \n",
      "\n",
      "Fold: 19  Epoch: 85  Training loss = 4.8292  Validation loss = 1.1512  \n",
      "\n",
      "Fold: 19  Epoch: 86  Training loss = 4.8283  Validation loss = 1.1506  \n",
      "\n",
      "Fold: 19  Epoch: 87  Training loss = 4.8276  Validation loss = 1.1501  \n",
      "\n",
      "Fold: 19  Epoch: 88  Training loss = 4.8268  Validation loss = 1.1496  \n",
      "\n",
      "Fold: 19  Epoch: 89  Training loss = 4.8260  Validation loss = 1.1491  \n",
      "\n",
      "Fold: 19  Epoch: 90  Training loss = 4.8252  Validation loss = 1.1485  \n",
      "\n",
      "Fold: 19  Epoch: 91  Training loss = 4.8245  Validation loss = 1.1480  \n",
      "\n",
      "Fold: 19  Epoch: 92  Training loss = 4.8238  Validation loss = 1.1474  \n",
      "\n",
      "Fold: 19  Epoch: 93  Training loss = 4.8231  Validation loss = 1.1469  \n",
      "\n",
      "Fold: 19  Epoch: 94  Training loss = 4.8223  Validation loss = 1.1464  \n",
      "\n",
      "Fold: 19  Epoch: 95  Training loss = 4.8213  Validation loss = 1.1458  \n",
      "\n",
      "Fold: 19  Epoch: 96  Training loss = 4.8206  Validation loss = 1.1453  \n",
      "\n",
      "Fold: 19  Epoch: 97  Training loss = 4.8199  Validation loss = 1.1448  \n",
      "\n",
      "Fold: 19  Epoch: 98  Training loss = 4.8191  Validation loss = 1.1443  \n",
      "\n",
      "Fold: 19  Epoch: 99  Training loss = 4.8184  Validation loss = 1.1437  \n",
      "\n",
      "Fold: 19  Epoch: 100  Training loss = 4.8177  Validation loss = 1.1432  \n",
      "\n",
      "Fold: 19  Epoch: 101  Training loss = 4.8167  Validation loss = 1.1427  \n",
      "\n",
      "Fold: 19  Epoch: 102  Training loss = 4.8158  Validation loss = 1.1420  \n",
      "\n",
      "Fold: 19  Epoch: 103  Training loss = 4.8151  Validation loss = 1.1415  \n",
      "\n",
      "Fold: 19  Epoch: 104  Training loss = 4.8144  Validation loss = 1.1410  \n",
      "\n",
      "Fold: 19  Epoch: 105  Training loss = 4.8137  Validation loss = 1.1405  \n",
      "\n",
      "Fold: 19  Epoch: 106  Training loss = 4.8129  Validation loss = 1.1399  \n",
      "\n",
      "Fold: 19  Epoch: 107  Training loss = 4.8119  Validation loss = 1.1393  \n",
      "\n",
      "Fold: 19  Epoch: 108  Training loss = 4.8111  Validation loss = 1.1388  \n",
      "\n",
      "Fold: 19  Epoch: 109  Training loss = 4.8103  Validation loss = 1.1383  \n",
      "\n",
      "Fold: 19  Epoch: 110  Training loss = 4.8096  Validation loss = 1.1378  \n",
      "\n",
      "Fold: 19  Epoch: 111  Training loss = 4.8087  Validation loss = 1.1373  \n",
      "\n",
      "Fold: 19  Epoch: 112  Training loss = 4.8080  Validation loss = 1.1368  \n",
      "\n",
      "Fold: 19  Epoch: 113  Training loss = 4.8073  Validation loss = 1.1363  \n",
      "\n",
      "Fold: 19  Epoch: 114  Training loss = 4.8066  Validation loss = 1.1358  \n",
      "\n",
      "Fold: 19  Epoch: 115  Training loss = 4.8060  Validation loss = 1.1354  \n",
      "\n",
      "Fold: 19  Epoch: 116  Training loss = 4.8051  Validation loss = 1.1348  \n",
      "\n",
      "Fold: 19  Epoch: 117  Training loss = 4.8044  Validation loss = 1.1343  \n",
      "\n",
      "Fold: 19  Epoch: 118  Training loss = 4.8036  Validation loss = 1.1337  \n",
      "\n",
      "Fold: 19  Epoch: 119  Training loss = 4.8029  Validation loss = 1.1332  \n",
      "\n",
      "Fold: 19  Epoch: 120  Training loss = 4.8021  Validation loss = 1.1327  \n",
      "\n",
      "Fold: 19  Epoch: 121  Training loss = 4.8013  Validation loss = 1.1321  \n",
      "\n",
      "Fold: 19  Epoch: 122  Training loss = 4.8007  Validation loss = 1.1316  \n",
      "\n",
      "Fold: 19  Epoch: 123  Training loss = 4.7998  Validation loss = 1.1309  \n",
      "\n",
      "Fold: 19  Epoch: 124  Training loss = 4.7990  Validation loss = 1.1304  \n",
      "\n",
      "Fold: 19  Epoch: 125  Training loss = 4.7983  Validation loss = 1.1300  \n",
      "\n",
      "Fold: 19  Epoch: 126  Training loss = 4.7975  Validation loss = 1.1295  \n",
      "\n",
      "Fold: 19  Epoch: 127  Training loss = 4.7967  Validation loss = 1.1290  \n",
      "\n",
      "Fold: 19  Epoch: 128  Training loss = 4.7960  Validation loss = 1.1285  \n",
      "\n",
      "Fold: 19  Epoch: 129  Training loss = 4.7953  Validation loss = 1.1281  \n",
      "\n",
      "Fold: 19  Epoch: 130  Training loss = 4.7945  Validation loss = 1.1274  \n",
      "\n",
      "Fold: 19  Epoch: 131  Training loss = 4.7937  Validation loss = 1.1269  \n",
      "\n",
      "Fold: 19  Epoch: 132  Training loss = 4.7928  Validation loss = 1.1263  \n",
      "\n",
      "Fold: 19  Epoch: 133  Training loss = 4.7922  Validation loss = 1.1259  \n",
      "\n",
      "Fold: 19  Epoch: 134  Training loss = 4.7916  Validation loss = 1.1254  \n",
      "\n",
      "Fold: 19  Epoch: 135  Training loss = 4.7908  Validation loss = 1.1249  \n",
      "\n",
      "Fold: 19  Epoch: 136  Training loss = 4.7902  Validation loss = 1.1245  \n",
      "\n",
      "Fold: 19  Epoch: 137  Training loss = 4.7892  Validation loss = 1.1238  \n",
      "\n",
      "Fold: 19  Epoch: 138  Training loss = 4.7886  Validation loss = 1.1234  \n",
      "\n",
      "Fold: 19  Epoch: 139  Training loss = 4.7878  Validation loss = 1.1229  \n",
      "\n",
      "Fold: 19  Epoch: 140  Training loss = 4.7870  Validation loss = 1.1223  \n",
      "\n",
      "Fold: 19  Epoch: 141  Training loss = 4.7862  Validation loss = 1.1218  \n",
      "\n",
      "Fold: 19  Epoch: 142  Training loss = 4.7855  Validation loss = 1.1213  \n",
      "\n",
      "Fold: 19  Epoch: 143  Training loss = 4.7848  Validation loss = 1.1208  \n",
      "\n",
      "Fold: 19  Epoch: 144  Training loss = 4.7840  Validation loss = 1.1204  \n",
      "\n",
      "Fold: 19  Epoch: 145  Training loss = 4.7834  Validation loss = 1.1199  \n",
      "\n",
      "Fold: 19  Epoch: 146  Training loss = 4.7827  Validation loss = 1.1196  \n",
      "\n",
      "Fold: 19  Epoch: 147  Training loss = 4.7820  Validation loss = 1.1190  \n",
      "\n",
      "Fold: 19  Epoch: 148  Training loss = 4.7812  Validation loss = 1.1185  \n",
      "\n",
      "Fold: 19  Epoch: 149  Training loss = 4.7804  Validation loss = 1.1178  \n",
      "\n",
      "Fold: 19  Epoch: 150  Training loss = 4.7798  Validation loss = 1.1175  \n",
      "\n",
      "Fold: 19  Epoch: 151  Training loss = 4.7792  Validation loss = 1.1171  \n",
      "\n",
      "Fold: 19  Epoch: 152  Training loss = 4.7785  Validation loss = 1.1166  \n",
      "\n",
      "Fold: 19  Epoch: 153  Training loss = 4.7777  Validation loss = 1.1161  \n",
      "\n",
      "Fold: 19  Epoch: 154  Training loss = 4.7771  Validation loss = 1.1157  \n",
      "\n",
      "Fold: 19  Epoch: 155  Training loss = 4.7764  Validation loss = 1.1153  \n",
      "\n",
      "Fold: 19  Epoch: 156  Training loss = 4.7756  Validation loss = 1.1147  \n",
      "\n",
      "Fold: 19  Epoch: 157  Training loss = 4.7747  Validation loss = 1.1142  \n",
      "\n",
      "Fold: 19  Epoch: 158  Training loss = 4.7740  Validation loss = 1.1137  \n",
      "\n",
      "Fold: 19  Epoch: 159  Training loss = 4.7735  Validation loss = 1.1134  \n",
      "\n",
      "Fold: 19  Epoch: 160  Training loss = 4.7727  Validation loss = 1.1128  \n",
      "\n",
      "Fold: 19  Epoch: 161  Training loss = 4.7721  Validation loss = 1.1124  \n",
      "\n",
      "Fold: 19  Epoch: 162  Training loss = 4.7715  Validation loss = 1.1119  \n",
      "\n",
      "Fold: 19  Epoch: 163  Training loss = 4.7708  Validation loss = 1.1114  \n",
      "\n",
      "Fold: 19  Epoch: 164  Training loss = 4.7701  Validation loss = 1.1110  \n",
      "\n",
      "Fold: 19  Epoch: 165  Training loss = 4.7694  Validation loss = 1.1105  \n",
      "\n",
      "Fold: 19  Epoch: 166  Training loss = 4.7687  Validation loss = 1.1101  \n",
      "\n",
      "Fold: 19  Epoch: 167  Training loss = 4.7679  Validation loss = 1.1095  \n",
      "\n",
      "Fold: 19  Epoch: 168  Training loss = 4.7672  Validation loss = 1.1091  \n",
      "\n",
      "Fold: 19  Epoch: 169  Training loss = 4.7665  Validation loss = 1.1086  \n",
      "\n",
      "Fold: 19  Epoch: 170  Training loss = 4.7658  Validation loss = 1.1082  \n",
      "\n",
      "Fold: 19  Epoch: 171  Training loss = 4.7651  Validation loss = 1.1077  \n",
      "\n",
      "Fold: 19  Epoch: 172  Training loss = 4.7644  Validation loss = 1.1072  \n",
      "\n",
      "Fold: 19  Epoch: 173  Training loss = 4.7637  Validation loss = 1.1067  \n",
      "\n",
      "Fold: 19  Epoch: 174  Training loss = 4.7631  Validation loss = 1.1063  \n",
      "\n",
      "Fold: 19  Epoch: 175  Training loss = 4.7625  Validation loss = 1.1059  \n",
      "\n",
      "Fold: 19  Epoch: 176  Training loss = 4.7619  Validation loss = 1.1055  \n",
      "\n",
      "Fold: 19  Epoch: 177  Training loss = 4.7611  Validation loss = 1.1050  \n",
      "\n",
      "Fold: 19  Epoch: 178  Training loss = 4.7604  Validation loss = 1.1045  \n",
      "\n",
      "Fold: 19  Epoch: 179  Training loss = 4.7597  Validation loss = 1.1041  \n",
      "\n",
      "Fold: 19  Epoch: 180  Training loss = 4.7590  Validation loss = 1.1036  \n",
      "\n",
      "Fold: 19  Epoch: 181  Training loss = 4.7583  Validation loss = 1.1032  \n",
      "\n",
      "Fold: 19  Epoch: 182  Training loss = 4.7577  Validation loss = 1.1027  \n",
      "\n",
      "Fold: 19  Epoch: 183  Training loss = 4.7568  Validation loss = 1.1022  \n",
      "\n",
      "Fold: 19  Epoch: 184  Training loss = 4.7560  Validation loss = 1.1017  \n",
      "\n",
      "Fold: 19  Epoch: 185  Training loss = 4.7554  Validation loss = 1.1012  \n",
      "\n",
      "Fold: 19  Epoch: 186  Training loss = 4.7547  Validation loss = 1.1008  \n",
      "\n",
      "Fold: 19  Epoch: 187  Training loss = 4.7540  Validation loss = 1.1003  \n",
      "\n",
      "Fold: 19  Epoch: 188  Training loss = 4.7533  Validation loss = 1.0999  \n",
      "\n",
      "Fold: 19  Epoch: 189  Training loss = 4.7526  Validation loss = 1.0994  \n",
      "\n",
      "Fold: 19  Epoch: 190  Training loss = 4.7519  Validation loss = 1.0989  \n",
      "\n",
      "Fold: 19  Epoch: 191  Training loss = 4.7510  Validation loss = 1.0984  \n",
      "\n",
      "Fold: 19  Epoch: 192  Training loss = 4.7505  Validation loss = 1.0980  \n",
      "\n",
      "Fold: 19  Epoch: 193  Training loss = 4.7499  Validation loss = 1.0977  \n",
      "\n",
      "Fold: 19  Epoch: 194  Training loss = 4.7491  Validation loss = 1.0972  \n",
      "\n",
      "Fold: 19  Epoch: 195  Training loss = 4.7485  Validation loss = 1.0967  \n",
      "\n",
      "Fold: 19  Epoch: 196  Training loss = 4.7479  Validation loss = 1.0964  \n",
      "\n",
      "Fold: 19  Epoch: 197  Training loss = 4.7473  Validation loss = 1.0960  \n",
      "\n",
      "Fold: 19  Epoch: 198  Training loss = 4.7465  Validation loss = 1.0955  \n",
      "\n",
      "Fold: 19  Epoch: 199  Training loss = 4.7458  Validation loss = 1.0951  \n",
      "\n",
      "Fold: 19  Epoch: 200  Training loss = 4.7451  Validation loss = 1.0946  \n",
      "\n",
      "Fold: 19  Epoch: 201  Training loss = 4.7443  Validation loss = 1.0941  \n",
      "\n",
      "Fold: 19  Epoch: 202  Training loss = 4.7437  Validation loss = 1.0937  \n",
      "\n",
      "Fold: 19  Epoch: 203  Training loss = 4.7429  Validation loss = 1.0933  \n",
      "\n",
      "Fold: 19  Epoch: 204  Training loss = 4.7421  Validation loss = 1.0927  \n",
      "\n",
      "Fold: 19  Epoch: 205  Training loss = 4.7414  Validation loss = 1.0923  \n",
      "\n",
      "Fold: 19  Epoch: 206  Training loss = 4.7405  Validation loss = 1.0918  \n",
      "\n",
      "Fold: 19  Epoch: 207  Training loss = 4.7398  Validation loss = 1.0914  \n",
      "\n",
      "Fold: 19  Epoch: 208  Training loss = 4.7388  Validation loss = 1.0911  \n",
      "\n",
      "Fold: 19  Epoch: 209  Training loss = 4.7377  Validation loss = 1.0906  \n",
      "\n",
      "Fold: 19  Epoch: 210  Training loss = 4.7364  Validation loss = 1.0902  \n",
      "\n",
      "Fold: 19  Epoch: 211  Training loss = 4.7333  Validation loss = 1.0902  \n",
      "\n",
      "Fold: 19  Epoch: 212  Training loss = 4.7325  Validation loss = 1.0899  \n",
      "\n",
      "Fold: 19  Epoch: 213  Training loss = 4.7318  Validation loss = 1.0895  \n",
      "\n",
      "Fold: 19  Epoch: 214  Training loss = 4.7311  Validation loss = 1.0891  \n",
      "\n",
      "Fold: 19  Epoch: 215  Training loss = 4.7306  Validation loss = 1.0887  \n",
      "\n",
      "Fold: 19  Epoch: 216  Training loss = 4.7299  Validation loss = 1.0882  \n",
      "\n",
      "Fold: 19  Epoch: 217  Training loss = 4.7292  Validation loss = 1.0878  \n",
      "\n",
      "Fold: 19  Epoch: 218  Training loss = 4.7282  Validation loss = 1.0873  \n",
      "\n",
      "Fold: 19  Epoch: 219  Training loss = 4.7274  Validation loss = 1.0868  \n",
      "\n",
      "Fold: 19  Epoch: 220  Training loss = 4.7268  Validation loss = 1.0865  \n",
      "\n",
      "Fold: 19  Epoch: 221  Training loss = 4.7260  Validation loss = 1.0860  \n",
      "\n",
      "Fold: 19  Epoch: 222  Training loss = 4.7254  Validation loss = 1.0856  \n",
      "\n",
      "Fold: 19  Epoch: 223  Training loss = 4.7246  Validation loss = 1.0851  \n",
      "\n",
      "Fold: 19  Epoch: 224  Training loss = 4.7241  Validation loss = 1.0847  \n",
      "\n",
      "Fold: 19  Epoch: 225  Training loss = 4.7233  Validation loss = 1.0843  \n",
      "\n",
      "Fold: 19  Epoch: 226  Training loss = 4.7226  Validation loss = 1.0838  \n",
      "\n",
      "Fold: 19  Epoch: 227  Training loss = 4.7220  Validation loss = 1.0834  \n",
      "\n",
      "Fold: 19  Epoch: 228  Training loss = 4.7214  Validation loss = 1.0831  \n",
      "\n",
      "Fold: 19  Epoch: 229  Training loss = 4.7206  Validation loss = 1.0826  \n",
      "\n",
      "Fold: 19  Epoch: 230  Training loss = 4.7200  Validation loss = 1.0822  \n",
      "\n",
      "Fold: 19  Epoch: 231  Training loss = 4.7195  Validation loss = 1.0819  \n",
      "\n",
      "Fold: 19  Epoch: 232  Training loss = 4.7187  Validation loss = 1.0814  \n",
      "\n",
      "Fold: 19  Epoch: 233  Training loss = 4.7180  Validation loss = 1.0809  \n",
      "\n",
      "Fold: 19  Epoch: 234  Training loss = 4.7174  Validation loss = 1.0806  \n",
      "\n",
      "Fold: 19  Epoch: 235  Training loss = 4.7168  Validation loss = 1.0802  \n",
      "\n",
      "Fold: 19  Epoch: 236  Training loss = 4.7161  Validation loss = 1.0797  \n",
      "\n",
      "Fold: 19  Epoch: 237  Training loss = 4.7155  Validation loss = 1.0793  \n",
      "\n",
      "Fold: 19  Epoch: 238  Training loss = 4.7148  Validation loss = 1.0789  \n",
      "\n",
      "Fold: 19  Epoch: 239  Training loss = 4.7140  Validation loss = 1.0783  \n",
      "\n",
      "Fold: 19  Epoch: 240  Training loss = 4.7132  Validation loss = 1.0778  \n",
      "\n",
      "Fold: 19  Epoch: 241  Training loss = 4.7124  Validation loss = 1.0773  \n",
      "\n",
      "Fold: 19  Epoch: 242  Training loss = 4.7117  Validation loss = 1.0769  \n",
      "\n",
      "Fold: 19  Epoch: 243  Training loss = 4.7109  Validation loss = 1.0764  \n",
      "\n",
      "Fold: 19  Epoch: 244  Training loss = 4.7103  Validation loss = 1.0760  \n",
      "\n",
      "Fold: 19  Epoch: 245  Training loss = 4.7096  Validation loss = 1.0755  \n",
      "\n",
      "Fold: 19  Epoch: 246  Training loss = 4.7090  Validation loss = 1.0751  \n",
      "\n",
      "Fold: 19  Epoch: 247  Training loss = 4.7082  Validation loss = 1.0746  \n",
      "\n",
      "Fold: 19  Epoch: 248  Training loss = 4.7076  Validation loss = 1.0742  \n",
      "\n",
      "Fold: 19  Epoch: 249  Training loss = 4.7068  Validation loss = 1.0737  \n",
      "\n",
      "Fold: 19  Epoch: 250  Training loss = 4.7062  Validation loss = 1.0734  \n",
      "\n",
      "Fold: 19  Epoch: 251  Training loss = 4.7057  Validation loss = 1.0730  \n",
      "\n",
      "Fold: 19  Epoch: 252  Training loss = 4.7050  Validation loss = 1.0726  \n",
      "\n",
      "Fold: 19  Epoch: 253  Training loss = 4.7044  Validation loss = 1.0722  \n",
      "\n",
      "Fold: 19  Epoch: 254  Training loss = 4.7037  Validation loss = 1.0719  \n",
      "\n",
      "Fold: 19  Epoch: 255  Training loss = 4.7031  Validation loss = 1.0715  \n",
      "\n",
      "Fold: 19  Epoch: 256  Training loss = 4.7026  Validation loss = 1.0711  \n",
      "\n",
      "Fold: 19  Epoch: 257  Training loss = 4.7020  Validation loss = 1.0707  \n",
      "\n",
      "Fold: 19  Epoch: 258  Training loss = 4.7012  Validation loss = 1.0702  \n",
      "\n",
      "Fold: 19  Epoch: 259  Training loss = 4.7006  Validation loss = 1.0698  \n",
      "\n",
      "Fold: 19  Epoch: 260  Training loss = 4.7000  Validation loss = 1.0694  \n",
      "\n",
      "Fold: 19  Epoch: 261  Training loss = 4.6994  Validation loss = 1.0690  \n",
      "\n",
      "Fold: 19  Epoch: 262  Training loss = 4.6988  Validation loss = 1.0686  \n",
      "\n",
      "Fold: 19  Epoch: 263  Training loss = 4.6981  Validation loss = 1.0682  \n",
      "\n",
      "Fold: 19  Epoch: 264  Training loss = 4.6974  Validation loss = 1.0677  \n",
      "\n",
      "Fold: 19  Epoch: 265  Training loss = 4.6967  Validation loss = 1.0673  \n",
      "\n",
      "Fold: 19  Epoch: 266  Training loss = 4.6961  Validation loss = 1.0669  \n",
      "\n",
      "Fold: 19  Epoch: 267  Training loss = 4.6953  Validation loss = 1.0664  \n",
      "\n",
      "Fold: 19  Epoch: 268  Training loss = 4.6947  Validation loss = 1.0660  \n",
      "\n",
      "Fold: 19  Epoch: 269  Training loss = 4.6939  Validation loss = 1.0655  \n",
      "\n",
      "Fold: 19  Epoch: 270  Training loss = 4.6931  Validation loss = 1.0649  \n",
      "\n",
      "Fold: 19  Epoch: 271  Training loss = 4.6923  Validation loss = 1.0644  \n",
      "\n",
      "Fold: 19  Epoch: 272  Training loss = 4.6918  Validation loss = 1.0641  \n",
      "\n",
      "Fold: 19  Epoch: 273  Training loss = 4.6912  Validation loss = 1.0637  \n",
      "\n",
      "Fold: 19  Epoch: 274  Training loss = 4.6904  Validation loss = 1.0632  \n",
      "\n",
      "Fold: 19  Epoch: 275  Training loss = 4.6897  Validation loss = 1.0628  \n",
      "\n",
      "Fold: 19  Epoch: 276  Training loss = 4.6890  Validation loss = 1.0623  \n",
      "\n",
      "Fold: 19  Epoch: 277  Training loss = 4.6884  Validation loss = 1.0619  \n",
      "\n",
      "Fold: 19  Epoch: 278  Training loss = 4.6876  Validation loss = 1.0614  \n",
      "\n",
      "Fold: 19  Epoch: 279  Training loss = 4.6871  Validation loss = 1.0611  \n",
      "\n",
      "Fold: 19  Epoch: 280  Training loss = 4.6862  Validation loss = 1.0606  \n",
      "\n",
      "Fold: 19  Epoch: 281  Training loss = 4.6855  Validation loss = 1.0602  \n",
      "\n",
      "Fold: 19  Epoch: 282  Training loss = 4.6849  Validation loss = 1.0598  \n",
      "\n",
      "Fold: 19  Epoch: 283  Training loss = 4.6844  Validation loss = 1.0595  \n",
      "\n",
      "Fold: 19  Epoch: 284  Training loss = 4.6838  Validation loss = 1.0591  \n",
      "\n",
      "Fold: 19  Epoch: 285  Training loss = 4.6832  Validation loss = 1.0588  \n",
      "\n",
      "Fold: 19  Epoch: 286  Training loss = 4.6825  Validation loss = 1.0583  \n",
      "\n",
      "Fold: 19  Epoch: 287  Training loss = 4.6817  Validation loss = 1.0578  \n",
      "\n",
      "Fold: 19  Epoch: 288  Training loss = 4.6811  Validation loss = 1.0574  \n",
      "\n",
      "Fold: 19  Epoch: 289  Training loss = 4.6805  Validation loss = 1.0570  \n",
      "\n",
      "Fold: 19  Epoch: 290  Training loss = 4.6797  Validation loss = 1.0566  \n",
      "\n",
      "Fold: 19  Epoch: 291  Training loss = 4.6792  Validation loss = 1.0563  \n",
      "\n",
      "Fold: 19  Epoch: 292  Training loss = 4.6786  Validation loss = 1.0559  \n",
      "\n",
      "Fold: 19  Epoch: 293  Training loss = 4.6779  Validation loss = 1.0555  \n",
      "\n",
      "Fold: 19  Epoch: 294  Training loss = 4.6772  Validation loss = 1.0550  \n",
      "\n",
      "Fold: 19  Epoch: 295  Training loss = 4.6766  Validation loss = 1.0547  \n",
      "\n",
      "Fold: 19  Epoch: 296  Training loss = 4.6759  Validation loss = 1.0543  \n",
      "\n",
      "Fold: 19  Epoch: 297  Training loss = 4.6753  Validation loss = 1.0539  \n",
      "\n",
      "Fold: 19  Epoch: 298  Training loss = 4.6746  Validation loss = 1.0534  \n",
      "\n",
      "Fold: 19  Epoch: 299  Training loss = 4.6740  Validation loss = 1.0531  \n",
      "\n",
      "Fold: 19  Epoch: 300  Training loss = 4.6733  Validation loss = 1.0526  \n",
      "\n",
      "Fold: 19  Epoch: 301  Training loss = 4.6726  Validation loss = 1.0522  \n",
      "\n",
      "Fold: 19  Epoch: 302  Training loss = 4.6718  Validation loss = 1.0517  \n",
      "\n",
      "Fold: 19  Epoch: 303  Training loss = 4.6712  Validation loss = 1.0513  \n",
      "\n",
      "Fold: 19  Epoch: 304  Training loss = 4.6706  Validation loss = 1.0509  \n",
      "\n",
      "Fold: 19  Epoch: 305  Training loss = 4.6698  Validation loss = 1.0504  \n",
      "\n",
      "Fold: 19  Epoch: 306  Training loss = 4.6692  Validation loss = 1.0501  \n",
      "\n",
      "Fold: 19  Epoch: 307  Training loss = 4.6686  Validation loss = 1.0497  \n",
      "\n",
      "Fold: 19  Epoch: 308  Training loss = 4.6679  Validation loss = 1.0493  \n",
      "\n",
      "Fold: 19  Epoch: 309  Training loss = 4.6672  Validation loss = 1.0489  \n",
      "\n",
      "Fold: 19  Epoch: 310  Training loss = 4.6666  Validation loss = 1.0485  \n",
      "\n",
      "Fold: 19  Epoch: 311  Training loss = 4.6660  Validation loss = 1.0481  \n",
      "\n",
      "Fold: 19  Epoch: 312  Training loss = 4.6653  Validation loss = 1.0477  \n",
      "\n",
      "Fold: 19  Epoch: 313  Training loss = 4.6646  Validation loss = 1.0473  \n",
      "\n",
      "Fold: 19  Epoch: 314  Training loss = 4.6640  Validation loss = 1.0469  \n",
      "\n",
      "Fold: 19  Epoch: 315  Training loss = 4.6632  Validation loss = 1.0464  \n",
      "\n",
      "Fold: 19  Epoch: 316  Training loss = 4.6624  Validation loss = 1.0459  \n",
      "\n",
      "Fold: 19  Epoch: 317  Training loss = 4.6618  Validation loss = 1.0456  \n",
      "\n",
      "Fold: 19  Epoch: 318  Training loss = 4.6611  Validation loss = 1.0452  \n",
      "\n",
      "Fold: 19  Epoch: 319  Training loss = 4.6605  Validation loss = 1.0448  \n",
      "\n",
      "Fold: 19  Epoch: 320  Training loss = 4.6600  Validation loss = 1.0445  \n",
      "\n",
      "Fold: 19  Epoch: 321  Training loss = 4.6594  Validation loss = 1.0441  \n",
      "\n",
      "Fold: 19  Epoch: 322  Training loss = 4.6589  Validation loss = 1.0438  \n",
      "\n",
      "Fold: 19  Epoch: 323  Training loss = 4.6582  Validation loss = 1.0434  \n",
      "\n",
      "Fold: 19  Epoch: 324  Training loss = 4.6577  Validation loss = 1.0431  \n",
      "\n",
      "Fold: 19  Epoch: 325  Training loss = 4.6571  Validation loss = 1.0427  \n",
      "\n",
      "Fold: 19  Epoch: 326  Training loss = 4.6564  Validation loss = 1.0423  \n",
      "\n",
      "Fold: 19  Epoch: 327  Training loss = 4.6558  Validation loss = 1.0419  \n",
      "\n",
      "Fold: 19  Epoch: 328  Training loss = 4.6551  Validation loss = 1.0415  \n",
      "\n",
      "Fold: 19  Epoch: 329  Training loss = 4.6544  Validation loss = 1.0411  \n",
      "\n",
      "Fold: 19  Epoch: 330  Training loss = 4.6538  Validation loss = 1.0407  \n",
      "\n",
      "Fold: 19  Epoch: 331  Training loss = 4.6531  Validation loss = 1.0403  \n",
      "\n",
      "Fold: 19  Epoch: 332  Training loss = 4.6524  Validation loss = 1.0399  \n",
      "\n",
      "Fold: 19  Epoch: 333  Training loss = 4.6519  Validation loss = 1.0395  \n",
      "\n",
      "Fold: 19  Epoch: 334  Training loss = 4.6513  Validation loss = 1.0392  \n",
      "\n",
      "Fold: 19  Epoch: 335  Training loss = 4.6507  Validation loss = 1.0388  \n",
      "\n",
      "Fold: 19  Epoch: 336  Training loss = 4.6502  Validation loss = 1.0386  \n",
      "\n",
      "Fold: 19  Epoch: 337  Training loss = 4.6495  Validation loss = 1.0381  \n",
      "\n",
      "Fold: 19  Epoch: 338  Training loss = 4.6488  Validation loss = 1.0377  \n",
      "\n",
      "Fold: 19  Epoch: 339  Training loss = 4.6482  Validation loss = 1.0373  \n",
      "\n",
      "Fold: 19  Epoch: 340  Training loss = 4.6475  Validation loss = 1.0368  \n",
      "\n",
      "Fold: 19  Epoch: 341  Training loss = 4.6468  Validation loss = 1.0364  \n",
      "\n",
      "Fold: 19  Epoch: 342  Training loss = 4.6462  Validation loss = 1.0360  \n",
      "\n",
      "Fold: 19  Epoch: 343  Training loss = 4.6454  Validation loss = 1.0356  \n",
      "\n",
      "Fold: 19  Epoch: 344  Training loss = 4.6449  Validation loss = 1.0352  \n",
      "\n",
      "Fold: 19  Epoch: 345  Training loss = 4.6444  Validation loss = 1.0349  \n",
      "\n",
      "Fold: 19  Epoch: 346  Training loss = 4.6437  Validation loss = 1.0345  \n",
      "\n",
      "Fold: 19  Epoch: 347  Training loss = 4.6431  Validation loss = 1.0342  \n",
      "\n",
      "Fold: 19  Epoch: 348  Training loss = 4.6424  Validation loss = 1.0337  \n",
      "\n",
      "Fold: 19  Epoch: 349  Training loss = 4.6417  Validation loss = 1.0332  \n",
      "\n",
      "Fold: 19  Epoch: 350  Training loss = 4.6412  Validation loss = 1.0329  \n",
      "\n",
      "Fold: 19  Epoch: 351  Training loss = 4.6404  Validation loss = 1.0324  \n",
      "\n",
      "Fold: 19  Epoch: 352  Training loss = 4.6397  Validation loss = 1.0320  \n",
      "\n",
      "Fold: 19  Epoch: 353  Training loss = 4.6390  Validation loss = 1.0316  \n",
      "\n",
      "Fold: 19  Epoch: 354  Training loss = 4.6386  Validation loss = 1.0313  \n",
      "\n",
      "Fold: 19  Epoch: 355  Training loss = 4.6380  Validation loss = 1.0310  \n",
      "\n",
      "Fold: 19  Epoch: 356  Training loss = 4.6376  Validation loss = 1.0307  \n",
      "\n",
      "Fold: 19  Epoch: 357  Training loss = 4.6368  Validation loss = 1.0302  \n",
      "\n",
      "Fold: 19  Epoch: 358  Training loss = 4.6361  Validation loss = 1.0298  \n",
      "\n",
      "Fold: 19  Epoch: 359  Training loss = 4.6352  Validation loss = 1.0292  \n",
      "\n",
      "Fold: 19  Epoch: 360  Training loss = 4.6346  Validation loss = 1.0288  \n",
      "\n",
      "Fold: 19  Epoch: 361  Training loss = 4.6339  Validation loss = 1.0284  \n",
      "\n",
      "Fold: 19  Epoch: 362  Training loss = 4.6332  Validation loss = 1.0280  \n",
      "\n",
      "Fold: 19  Epoch: 363  Training loss = 4.6325  Validation loss = 1.0276  \n",
      "\n",
      "Fold: 19  Epoch: 364  Training loss = 4.6319  Validation loss = 1.0271  \n",
      "\n",
      "Fold: 19  Epoch: 365  Training loss = 4.6311  Validation loss = 1.0266  \n",
      "\n",
      "Fold: 19  Epoch: 366  Training loss = 4.6305  Validation loss = 1.0263  \n",
      "\n",
      "Fold: 19  Epoch: 367  Training loss = 4.6298  Validation loss = 1.0258  \n",
      "\n",
      "Fold: 19  Epoch: 368  Training loss = 4.6293  Validation loss = 1.0255  \n",
      "\n",
      "Fold: 19  Epoch: 369  Training loss = 4.6287  Validation loss = 1.0251  \n",
      "\n",
      "Fold: 19  Epoch: 370  Training loss = 4.6280  Validation loss = 1.0247  \n",
      "\n",
      "Fold: 19  Epoch: 371  Training loss = 4.6273  Validation loss = 1.0243  \n",
      "\n",
      "Fold: 19  Epoch: 372  Training loss = 4.6266  Validation loss = 1.0239  \n",
      "\n",
      "Fold: 19  Epoch: 373  Training loss = 4.6260  Validation loss = 1.0236  \n",
      "\n",
      "Fold: 19  Epoch: 374  Training loss = 4.6255  Validation loss = 1.0233  \n",
      "\n",
      "Fold: 19  Epoch: 375  Training loss = 4.6248  Validation loss = 1.0228  \n",
      "\n",
      "Fold: 19  Epoch: 376  Training loss = 4.6242  Validation loss = 1.0225  \n",
      "\n",
      "Fold: 19  Epoch: 377  Training loss = 4.6235  Validation loss = 1.0221  \n",
      "\n",
      "Fold: 19  Epoch: 378  Training loss = 4.6227  Validation loss = 1.0216  \n",
      "\n",
      "Fold: 19  Epoch: 379  Training loss = 4.6220  Validation loss = 1.0212  \n",
      "\n",
      "Fold: 19  Epoch: 380  Training loss = 4.6214  Validation loss = 1.0209  \n",
      "\n",
      "Fold: 19  Epoch: 381  Training loss = 4.6207  Validation loss = 1.0204  \n",
      "\n",
      "Fold: 19  Epoch: 382  Training loss = 4.6201  Validation loss = 1.0201  \n",
      "\n",
      "Fold: 19  Epoch: 383  Training loss = 4.6195  Validation loss = 1.0198  \n",
      "\n",
      "Fold: 19  Epoch: 384  Training loss = 4.6189  Validation loss = 1.0194  \n",
      "\n",
      "Fold: 19  Epoch: 385  Training loss = 4.6184  Validation loss = 1.0191  \n",
      "\n",
      "Fold: 19  Epoch: 386  Training loss = 4.6178  Validation loss = 1.0188  \n",
      "\n",
      "Fold: 19  Epoch: 387  Training loss = 4.6173  Validation loss = 1.0185  \n",
      "\n",
      "Fold: 19  Epoch: 388  Training loss = 4.6167  Validation loss = 1.0181  \n",
      "\n",
      "Fold: 19  Epoch: 389  Training loss = 4.6160  Validation loss = 1.0177  \n",
      "\n",
      "Fold: 19  Epoch: 390  Training loss = 4.6153  Validation loss = 1.0174  \n",
      "\n",
      "Fold: 19  Epoch: 391  Training loss = 4.6148  Validation loss = 1.0171  \n",
      "\n",
      "Fold: 19  Epoch: 392  Training loss = 4.6143  Validation loss = 1.0168  \n",
      "\n",
      "Fold: 19  Epoch: 393  Training loss = 4.6136  Validation loss = 1.0164  \n",
      "\n",
      "Fold: 19  Epoch: 394  Training loss = 4.6129  Validation loss = 1.0160  \n",
      "\n",
      "Fold: 19  Epoch: 395  Training loss = 4.6122  Validation loss = 1.0156  \n",
      "\n",
      "Fold: 19  Epoch: 396  Training loss = 4.6116  Validation loss = 1.0153  \n",
      "\n",
      "Fold: 19  Epoch: 397  Training loss = 4.6109  Validation loss = 1.0148  \n",
      "\n",
      "Fold: 19  Epoch: 398  Training loss = 4.6103  Validation loss = 1.0145  \n",
      "\n",
      "Fold: 19  Epoch: 399  Training loss = 4.6096  Validation loss = 1.0141  \n",
      "\n",
      "Fold: 19  Epoch: 400  Training loss = 4.6089  Validation loss = 1.0137  \n",
      "\n",
      "Fold: 19  Epoch: 401  Training loss = 4.6082  Validation loss = 1.0133  \n",
      "\n",
      "Fold: 19  Epoch: 402  Training loss = 4.6076  Validation loss = 1.0130  \n",
      "\n",
      "Fold: 19  Epoch: 403  Training loss = 4.6069  Validation loss = 1.0125  \n",
      "\n",
      "Fold: 19  Epoch: 404  Training loss = 4.6062  Validation loss = 1.0121  \n",
      "\n",
      "Fold: 19  Epoch: 405  Training loss = 4.6056  Validation loss = 1.0117  \n",
      "\n",
      "Fold: 19  Epoch: 406  Training loss = 4.6048  Validation loss = 1.0112  \n",
      "\n",
      "Fold: 19  Epoch: 407  Training loss = 4.6041  Validation loss = 1.0108  \n",
      "\n",
      "Fold: 19  Epoch: 408  Training loss = 4.6035  Validation loss = 1.0105  \n",
      "\n",
      "Fold: 19  Epoch: 409  Training loss = 4.6029  Validation loss = 1.0102  \n",
      "\n",
      "Fold: 19  Epoch: 410  Training loss = 4.6023  Validation loss = 1.0099  \n",
      "\n",
      "Fold: 19  Epoch: 411  Training loss = 4.6015  Validation loss = 1.0094  \n",
      "\n",
      "Fold: 19  Epoch: 412  Training loss = 4.6011  Validation loss = 1.0091  \n",
      "\n",
      "Fold: 19  Epoch: 413  Training loss = 4.6005  Validation loss = 1.0089  \n",
      "\n",
      "Fold: 19  Epoch: 414  Training loss = 4.5999  Validation loss = 1.0085  \n",
      "\n",
      "Fold: 19  Epoch: 415  Training loss = 4.5994  Validation loss = 1.0082  \n",
      "\n",
      "Fold: 19  Epoch: 416  Training loss = 4.5986  Validation loss = 1.0077  \n",
      "\n",
      "Fold: 19  Epoch: 417  Training loss = 4.5979  Validation loss = 1.0074  \n",
      "\n",
      "Fold: 19  Epoch: 418  Training loss = 4.5972  Validation loss = 1.0070  \n",
      "\n",
      "Fold: 19  Epoch: 419  Training loss = 4.5965  Validation loss = 1.0066  \n",
      "\n",
      "Fold: 19  Epoch: 420  Training loss = 4.5960  Validation loss = 1.0062  \n",
      "\n",
      "Fold: 19  Epoch: 421  Training loss = 4.5952  Validation loss = 1.0058  \n",
      "\n",
      "Fold: 19  Epoch: 422  Training loss = 4.5945  Validation loss = 1.0054  \n",
      "\n",
      "Fold: 19  Epoch: 423  Training loss = 4.5938  Validation loss = 1.0050  \n",
      "\n",
      "Fold: 19  Epoch: 424  Training loss = 4.5932  Validation loss = 1.0047  \n",
      "\n",
      "Fold: 19  Epoch: 425  Training loss = 4.5925  Validation loss = 1.0043  \n",
      "\n",
      "Fold: 19  Epoch: 426  Training loss = 4.5918  Validation loss = 1.0040  \n",
      "\n",
      "Fold: 19  Epoch: 427  Training loss = 4.5911  Validation loss = 1.0036  \n",
      "\n",
      "Fold: 19  Epoch: 428  Training loss = 4.5905  Validation loss = 1.0032  \n",
      "\n",
      "Fold: 19  Epoch: 429  Training loss = 4.5899  Validation loss = 1.0030  \n",
      "\n",
      "Fold: 19  Epoch: 430  Training loss = 4.5892  Validation loss = 1.0025  \n",
      "\n",
      "Fold: 19  Epoch: 431  Training loss = 4.5885  Validation loss = 1.0022  \n",
      "\n",
      "Fold: 19  Epoch: 432  Training loss = 4.5878  Validation loss = 1.0017  \n",
      "\n",
      "Fold: 19  Epoch: 433  Training loss = 4.5870  Validation loss = 1.0013  \n",
      "\n",
      "Fold: 19  Epoch: 434  Training loss = 4.5864  Validation loss = 1.0009  \n",
      "\n",
      "Fold: 19  Epoch: 435  Training loss = 4.5858  Validation loss = 1.0005  \n",
      "\n",
      "Fold: 19  Epoch: 436  Training loss = 4.5852  Validation loss = 1.0002  \n",
      "\n",
      "Fold: 19  Epoch: 437  Training loss = 4.5847  Validation loss = 0.9999  \n",
      "\n",
      "Fold: 19  Epoch: 438  Training loss = 4.5841  Validation loss = 0.9996  \n",
      "\n",
      "Fold: 19  Epoch: 439  Training loss = 4.5835  Validation loss = 0.9993  \n",
      "\n",
      "Fold: 19  Epoch: 440  Training loss = 4.5828  Validation loss = 0.9989  \n",
      "\n",
      "Fold: 19  Epoch: 441  Training loss = 4.5821  Validation loss = 0.9984  \n",
      "\n",
      "Fold: 19  Epoch: 442  Training loss = 4.5815  Validation loss = 0.9981  \n",
      "\n",
      "Fold: 19  Epoch: 443  Training loss = 4.5809  Validation loss = 0.9978  \n",
      "\n",
      "Fold: 19  Epoch: 444  Training loss = 4.5802  Validation loss = 0.9974  \n",
      "\n",
      "Fold: 19  Epoch: 445  Training loss = 4.5796  Validation loss = 0.9971  \n",
      "\n",
      "Fold: 19  Epoch: 446  Training loss = 4.5789  Validation loss = 0.9967  \n",
      "\n",
      "Fold: 19  Epoch: 447  Training loss = 4.5783  Validation loss = 0.9963  \n",
      "\n",
      "Fold: 19  Epoch: 448  Training loss = 4.5777  Validation loss = 0.9960  \n",
      "\n",
      "Fold: 19  Epoch: 449  Training loss = 4.5773  Validation loss = 0.9958  \n",
      "\n",
      "Fold: 19  Epoch: 450  Training loss = 4.5769  Validation loss = 0.9955  \n",
      "\n",
      "Fold: 19  Epoch: 451  Training loss = 4.5761  Validation loss = 0.9951  \n",
      "\n",
      "Fold: 19  Epoch: 452  Training loss = 4.5754  Validation loss = 0.9948  \n",
      "\n",
      "Fold: 19  Epoch: 453  Training loss = 4.5749  Validation loss = 0.9944  \n",
      "\n",
      "Fold: 19  Epoch: 454  Training loss = 4.5743  Validation loss = 0.9941  \n",
      "\n",
      "Fold: 19  Epoch: 455  Training loss = 4.5737  Validation loss = 0.9938  \n",
      "\n",
      "Fold: 19  Epoch: 456  Training loss = 4.5730  Validation loss = 0.9934  \n",
      "\n",
      "Fold: 19  Epoch: 457  Training loss = 4.5723  Validation loss = 0.9930  \n",
      "\n",
      "Fold: 19  Epoch: 458  Training loss = 4.5716  Validation loss = 0.9927  \n",
      "\n",
      "Fold: 19  Epoch: 459  Training loss = 4.5710  Validation loss = 0.9923  \n",
      "\n",
      "Fold: 19  Epoch: 460  Training loss = 4.5701  Validation loss = 0.9919  \n",
      "\n",
      "Fold: 19  Epoch: 461  Training loss = 4.5694  Validation loss = 0.9915  \n",
      "\n",
      "Fold: 19  Epoch: 462  Training loss = 4.5688  Validation loss = 0.9912  \n",
      "\n",
      "Fold: 19  Epoch: 463  Training loss = 4.5680  Validation loss = 0.9908  \n",
      "\n",
      "Fold: 19  Epoch: 464  Training loss = 4.5674  Validation loss = 0.9905  \n",
      "\n",
      "Fold: 19  Epoch: 465  Training loss = 4.5667  Validation loss = 0.9901  \n",
      "\n",
      "Fold: 19  Epoch: 466  Training loss = 4.5659  Validation loss = 0.9897  \n",
      "\n",
      "Fold: 19  Epoch: 467  Training loss = 4.5652  Validation loss = 0.9893  \n",
      "\n",
      "Fold: 19  Epoch: 468  Training loss = 4.5646  Validation loss = 0.9890  \n",
      "\n",
      "Fold: 19  Epoch: 469  Training loss = 4.5639  Validation loss = 0.9886  \n",
      "\n",
      "Fold: 19  Epoch: 470  Training loss = 4.5634  Validation loss = 0.9883  \n",
      "\n",
      "Fold: 19  Epoch: 471  Training loss = 4.5628  Validation loss = 0.9880  \n",
      "\n",
      "Fold: 19  Epoch: 472  Training loss = 4.5621  Validation loss = 0.9876  \n",
      "\n",
      "Fold: 19  Epoch: 473  Training loss = 4.5615  Validation loss = 0.9873  \n",
      "\n",
      "Fold: 19  Epoch: 474  Training loss = 4.5610  Validation loss = 0.9871  \n",
      "\n",
      "Fold: 19  Epoch: 475  Training loss = 4.5605  Validation loss = 0.9868  \n",
      "\n",
      "Fold: 19  Epoch: 476  Training loss = 4.5598  Validation loss = 0.9864  \n",
      "\n",
      "Fold: 19  Epoch: 477  Training loss = 4.5591  Validation loss = 0.9861  \n",
      "\n",
      "Fold: 19  Epoch: 478  Training loss = 4.5584  Validation loss = 0.9857  \n",
      "\n",
      "Fold: 19  Epoch: 479  Training loss = 4.5577  Validation loss = 0.9853  \n",
      "\n",
      "Fold: 19  Epoch: 480  Training loss = 4.5571  Validation loss = 0.9849  \n",
      "\n",
      "Fold: 19  Epoch: 481  Training loss = 4.5564  Validation loss = 0.9846  \n",
      "\n",
      "Fold: 19  Epoch: 482  Training loss = 4.5557  Validation loss = 0.9843  \n",
      "\n",
      "Fold: 19  Epoch: 483  Training loss = 4.5552  Validation loss = 0.9840  \n",
      "\n",
      "Fold: 19  Epoch: 484  Training loss = 4.5544  Validation loss = 0.9835  \n",
      "\n",
      "Fold: 19  Epoch: 485  Training loss = 4.5539  Validation loss = 0.9833  \n",
      "\n",
      "Fold: 19  Epoch: 486  Training loss = 4.5533  Validation loss = 0.9829  \n",
      "\n",
      "Fold: 19  Epoch: 487  Training loss = 4.5527  Validation loss = 0.9826  \n",
      "\n",
      "Fold: 19  Epoch: 488  Training loss = 4.5521  Validation loss = 0.9823  \n",
      "\n",
      "Fold: 19  Epoch: 489  Training loss = 4.5514  Validation loss = 0.9819  \n",
      "\n",
      "Fold: 19  Epoch: 490  Training loss = 4.5508  Validation loss = 0.9817  \n",
      "\n",
      "Fold: 19  Epoch: 491  Training loss = 4.5501  Validation loss = 0.9813  \n",
      "\n",
      "Fold: 19  Epoch: 492  Training loss = 4.5495  Validation loss = 0.9810  \n",
      "\n",
      "Fold: 19  Epoch: 493  Training loss = 4.5489  Validation loss = 0.9806  \n",
      "\n",
      "Fold: 19  Epoch: 494  Training loss = 4.5483  Validation loss = 0.9803  \n",
      "\n",
      "Fold: 19  Epoch: 495  Training loss = 4.5476  Validation loss = 0.9798  \n",
      "\n",
      "Fold: 19  Epoch: 496  Training loss = 4.5468  Validation loss = 0.9795  \n",
      "\n",
      "Fold: 19  Epoch: 497  Training loss = 4.5464  Validation loss = 0.9793  \n",
      "\n",
      "Fold: 19  Epoch: 498  Training loss = 4.5459  Validation loss = 0.9791  \n",
      "\n",
      "Fold: 19  Epoch: 499  Training loss = 4.5453  Validation loss = 0.9787  \n",
      "\n",
      "Fold: 19  Epoch: 500  Training loss = 4.5446  Validation loss = 0.9783  \n",
      "\n",
      "Check model:  Fold: 19  Optimal epoch: 500  \n",
      "\n",
      "Fold: 20  Epoch: 1  Training loss = 4.5424  Validation loss = 0.4144  \n",
      "\n",
      "Fold: 20  Epoch: 2  Training loss = 4.5418  Validation loss = 0.4151  \n",
      "\n",
      "Fold: 20  Epoch: 3  Training loss = 4.5411  Validation loss = 0.4159  \n",
      "\n",
      "Fold: 20  Epoch: 4  Training loss = 4.5404  Validation loss = 0.4167  \n",
      "\n",
      "Fold: 20  Epoch: 5  Training loss = 4.5399  Validation loss = 0.4173  \n",
      "\n",
      "Fold: 20  Epoch: 6  Training loss = 4.5394  Validation loss = 0.4179  \n",
      "\n",
      "Fold: 20  Epoch: 7  Training loss = 4.5387  Validation loss = 0.4186  \n",
      "\n",
      "Fold: 20  Epoch: 8  Training loss = 4.5380  Validation loss = 0.4194  \n",
      "\n",
      "Fold: 20  Epoch: 9  Training loss = 4.5373  Validation loss = 0.4202  \n",
      "\n",
      "Fold: 20  Epoch: 10  Training loss = 4.5366  Validation loss = 0.4209  \n",
      "\n",
      "Fold: 20  Epoch: 11  Training loss = 4.5359  Validation loss = 0.4217  \n",
      "\n",
      "Check model:  Fold: 20  Optimal epoch: 1  \n",
      "\n",
      "Fold: 21  Epoch: 1  Training loss = 4.5107  Validation loss = 2.7279  \n",
      "\n",
      "Fold: 21  Epoch: 2  Training loss = 4.5101  Validation loss = 2.7284  \n",
      "\n",
      "Fold: 21  Epoch: 3  Training loss = 4.5095  Validation loss = 2.7288  \n",
      "\n",
      "Fold: 21  Epoch: 4  Training loss = 4.5090  Validation loss = 2.7292  \n",
      "\n",
      "Fold: 21  Epoch: 5  Training loss = 4.5083  Validation loss = 2.7297  \n",
      "\n",
      "Fold: 21  Epoch: 6  Training loss = 4.5079  Validation loss = 2.7303  \n",
      "\n",
      "Fold: 21  Epoch: 7  Training loss = 4.5075  Validation loss = 2.7308  \n",
      "\n",
      "Fold: 21  Epoch: 8  Training loss = 4.5070  Validation loss = 2.7311  \n",
      "\n",
      "Fold: 21  Epoch: 9  Training loss = 4.5064  Validation loss = 2.7316  \n",
      "\n",
      "Fold: 21  Epoch: 10  Training loss = 4.5058  Validation loss = 2.7322  \n",
      "\n",
      "Fold: 21  Epoch: 11  Training loss = 4.5054  Validation loss = 2.7325  \n",
      "\n",
      "Check model:  Fold: 21  Optimal epoch: 1  \n",
      "\n",
      "Fold: 22  Epoch: 1  Training loss = 4.5262  Validation loss = 1.1718  \n",
      "\n",
      "Fold: 22  Epoch: 2  Training loss = 4.5257  Validation loss = 1.1714  \n",
      "\n",
      "Fold: 22  Epoch: 3  Training loss = 4.5252  Validation loss = 1.1710  \n",
      "\n",
      "Fold: 22  Epoch: 4  Training loss = 4.5246  Validation loss = 1.1705  \n",
      "\n",
      "Fold: 22  Epoch: 5  Training loss = 4.5242  Validation loss = 1.1702  \n",
      "\n",
      "Fold: 22  Epoch: 6  Training loss = 4.5239  Validation loss = 1.1699  \n",
      "\n",
      "Fold: 22  Epoch: 7  Training loss = 4.5234  Validation loss = 1.1694  \n",
      "\n",
      "Fold: 22  Epoch: 8  Training loss = 4.5229  Validation loss = 1.1690  \n",
      "\n",
      "Fold: 22  Epoch: 9  Training loss = 4.5224  Validation loss = 1.1685  \n",
      "\n",
      "Fold: 22  Epoch: 10  Training loss = 4.5218  Validation loss = 1.1681  \n",
      "\n",
      "Fold: 22  Epoch: 11  Training loss = 4.5212  Validation loss = 1.1676  \n",
      "\n",
      "Fold: 22  Epoch: 12  Training loss = 4.5207  Validation loss = 1.1671  \n",
      "\n",
      "Fold: 22  Epoch: 13  Training loss = 4.5203  Validation loss = 1.1667  \n",
      "\n",
      "Fold: 22  Epoch: 14  Training loss = 4.5197  Validation loss = 1.1662  \n",
      "\n",
      "Fold: 22  Epoch: 15  Training loss = 4.5193  Validation loss = 1.1660  \n",
      "\n",
      "Fold: 22  Epoch: 16  Training loss = 4.5190  Validation loss = 1.1658  \n",
      "\n",
      "Fold: 22  Epoch: 17  Training loss = 4.5185  Validation loss = 1.1654  \n",
      "\n",
      "Fold: 22  Epoch: 18  Training loss = 4.5179  Validation loss = 1.1648  \n",
      "\n",
      "Fold: 22  Epoch: 19  Training loss = 4.5174  Validation loss = 1.1644  \n",
      "\n",
      "Fold: 22  Epoch: 20  Training loss = 4.5169  Validation loss = 1.1639  \n",
      "\n",
      "Fold: 22  Epoch: 21  Training loss = 4.5163  Validation loss = 1.1635  \n",
      "\n",
      "Fold: 22  Epoch: 22  Training loss = 4.5158  Validation loss = 1.1631  \n",
      "\n",
      "Fold: 22  Epoch: 23  Training loss = 4.5153  Validation loss = 1.1627  \n",
      "\n",
      "Fold: 22  Epoch: 24  Training loss = 4.5148  Validation loss = 1.1623  \n",
      "\n",
      "Fold: 22  Epoch: 25  Training loss = 4.5143  Validation loss = 1.1620  \n",
      "\n",
      "Fold: 22  Epoch: 26  Training loss = 4.5137  Validation loss = 1.1615  \n",
      "\n",
      "Fold: 22  Epoch: 27  Training loss = 4.5133  Validation loss = 1.1612  \n",
      "\n",
      "Fold: 22  Epoch: 28  Training loss = 4.5128  Validation loss = 1.1608  \n",
      "\n",
      "Fold: 22  Epoch: 29  Training loss = 4.5123  Validation loss = 1.1604  \n",
      "\n",
      "Fold: 22  Epoch: 30  Training loss = 4.5118  Validation loss = 1.1600  \n",
      "\n",
      "Fold: 22  Epoch: 31  Training loss = 4.5113  Validation loss = 1.1597  \n",
      "\n",
      "Fold: 22  Epoch: 32  Training loss = 4.5107  Validation loss = 1.1591  \n",
      "\n",
      "Fold: 22  Epoch: 33  Training loss = 4.5101  Validation loss = 1.1587  \n",
      "\n",
      "Fold: 22  Epoch: 34  Training loss = 4.5096  Validation loss = 1.1582  \n",
      "\n",
      "Fold: 22  Epoch: 35  Training loss = 4.5091  Validation loss = 1.1577  \n",
      "\n",
      "Fold: 22  Epoch: 36  Training loss = 4.5088  Validation loss = 1.1575  \n",
      "\n",
      "Fold: 22  Epoch: 37  Training loss = 4.5084  Validation loss = 1.1572  \n",
      "\n",
      "Fold: 22  Epoch: 38  Training loss = 4.5079  Validation loss = 1.1567  \n",
      "\n",
      "Fold: 22  Epoch: 39  Training loss = 4.5073  Validation loss = 1.1562  \n",
      "\n",
      "Fold: 22  Epoch: 40  Training loss = 4.5067  Validation loss = 1.1557  \n",
      "\n",
      "Fold: 22  Epoch: 41  Training loss = 4.5062  Validation loss = 1.1553  \n",
      "\n",
      "Fold: 22  Epoch: 42  Training loss = 4.5056  Validation loss = 1.1547  \n",
      "\n",
      "Fold: 22  Epoch: 43  Training loss = 4.5051  Validation loss = 1.1544  \n",
      "\n",
      "Fold: 22  Epoch: 44  Training loss = 4.5046  Validation loss = 1.1539  \n",
      "\n",
      "Fold: 22  Epoch: 45  Training loss = 4.5041  Validation loss = 1.1535  \n",
      "\n",
      "Fold: 22  Epoch: 46  Training loss = 4.5037  Validation loss = 1.1532  \n",
      "\n",
      "Fold: 22  Epoch: 47  Training loss = 4.5031  Validation loss = 1.1527  \n",
      "\n",
      "Fold: 22  Epoch: 48  Training loss = 4.5026  Validation loss = 1.1523  \n",
      "\n",
      "Fold: 22  Epoch: 49  Training loss = 4.5022  Validation loss = 1.1519  \n",
      "\n",
      "Fold: 22  Epoch: 50  Training loss = 4.5017  Validation loss = 1.1515  \n",
      "\n",
      "Fold: 22  Epoch: 51  Training loss = 4.5011  Validation loss = 1.1511  \n",
      "\n",
      "Fold: 22  Epoch: 52  Training loss = 4.5006  Validation loss = 1.1507  \n",
      "\n",
      "Fold: 22  Epoch: 53  Training loss = 4.5003  Validation loss = 1.1504  \n",
      "\n",
      "Fold: 22  Epoch: 54  Training loss = 4.4996  Validation loss = 1.1498  \n",
      "\n",
      "Fold: 22  Epoch: 55  Training loss = 4.4991  Validation loss = 1.1494  \n",
      "\n",
      "Fold: 22  Epoch: 56  Training loss = 4.4987  Validation loss = 1.1491  \n",
      "\n",
      "Fold: 22  Epoch: 57  Training loss = 4.4982  Validation loss = 1.1488  \n",
      "\n",
      "Fold: 22  Epoch: 58  Training loss = 4.4977  Validation loss = 1.1484  \n",
      "\n",
      "Fold: 22  Epoch: 59  Training loss = 4.4971  Validation loss = 1.1479  \n",
      "\n",
      "Fold: 22  Epoch: 60  Training loss = 4.4967  Validation loss = 1.1475  \n",
      "\n",
      "Fold: 22  Epoch: 61  Training loss = 4.4964  Validation loss = 1.1472  \n",
      "\n",
      "Fold: 22  Epoch: 62  Training loss = 4.4959  Validation loss = 1.1469  \n",
      "\n",
      "Fold: 22  Epoch: 63  Training loss = 4.4953  Validation loss = 1.1465  \n",
      "\n",
      "Fold: 22  Epoch: 64  Training loss = 4.4949  Validation loss = 1.1463  \n",
      "\n",
      "Fold: 22  Epoch: 65  Training loss = 4.4946  Validation loss = 1.1461  \n",
      "\n",
      "Fold: 22  Epoch: 66  Training loss = 4.4940  Validation loss = 1.1457  \n",
      "\n",
      "Fold: 22  Epoch: 67  Training loss = 4.4934  Validation loss = 1.1452  \n",
      "\n",
      "Fold: 22  Epoch: 68  Training loss = 4.4930  Validation loss = 1.1450  \n",
      "\n",
      "Fold: 22  Epoch: 69  Training loss = 4.4926  Validation loss = 1.1446  \n",
      "\n",
      "Fold: 22  Epoch: 70  Training loss = 4.4922  Validation loss = 1.1442  \n",
      "\n",
      "Fold: 22  Epoch: 71  Training loss = 4.4916  Validation loss = 1.1437  \n",
      "\n",
      "Fold: 22  Epoch: 72  Training loss = 4.4911  Validation loss = 1.1433  \n",
      "\n",
      "Fold: 22  Epoch: 73  Training loss = 4.4906  Validation loss = 1.1428  \n",
      "\n",
      "Fold: 22  Epoch: 74  Training loss = 4.4902  Validation loss = 1.1425  \n",
      "\n",
      "Fold: 22  Epoch: 75  Training loss = 4.4898  Validation loss = 1.1421  \n",
      "\n",
      "Fold: 22  Epoch: 76  Training loss = 4.4893  Validation loss = 1.1418  \n",
      "\n",
      "Fold: 22  Epoch: 77  Training loss = 4.4889  Validation loss = 1.1415  \n",
      "\n",
      "Fold: 22  Epoch: 78  Training loss = 4.4885  Validation loss = 1.1412  \n",
      "\n",
      "Fold: 22  Epoch: 79  Training loss = 4.4879  Validation loss = 1.1408  \n",
      "\n",
      "Fold: 22  Epoch: 80  Training loss = 4.4874  Validation loss = 1.1404  \n",
      "\n",
      "Fold: 22  Epoch: 81  Training loss = 4.4869  Validation loss = 1.1401  \n",
      "\n",
      "Fold: 22  Epoch: 82  Training loss = 4.4863  Validation loss = 1.1396  \n",
      "\n",
      "Fold: 22  Epoch: 83  Training loss = 4.4858  Validation loss = 1.1392  \n",
      "\n",
      "Fold: 22  Epoch: 84  Training loss = 4.4852  Validation loss = 1.1387  \n",
      "\n",
      "Fold: 22  Epoch: 85  Training loss = 4.4847  Validation loss = 1.1384  \n",
      "\n",
      "Fold: 22  Epoch: 86  Training loss = 4.4843  Validation loss = 1.1381  \n",
      "\n",
      "Fold: 22  Epoch: 87  Training loss = 4.4839  Validation loss = 1.1377  \n",
      "\n",
      "Fold: 22  Epoch: 88  Training loss = 4.4836  Validation loss = 1.1376  \n",
      "\n",
      "Fold: 22  Epoch: 89  Training loss = 4.4831  Validation loss = 1.1371  \n",
      "\n",
      "Fold: 22  Epoch: 90  Training loss = 4.4826  Validation loss = 1.1368  \n",
      "\n",
      "Fold: 22  Epoch: 91  Training loss = 4.4822  Validation loss = 1.1365  \n",
      "\n",
      "Fold: 22  Epoch: 92  Training loss = 4.4818  Validation loss = 1.1362  \n",
      "\n",
      "Fold: 22  Epoch: 93  Training loss = 4.4814  Validation loss = 1.1358  \n",
      "\n",
      "Fold: 22  Epoch: 94  Training loss = 4.4809  Validation loss = 1.1355  \n",
      "\n",
      "Fold: 22  Epoch: 95  Training loss = 4.4805  Validation loss = 1.1352  \n",
      "\n",
      "Fold: 22  Epoch: 96  Training loss = 4.4800  Validation loss = 1.1348  \n",
      "\n",
      "Fold: 22  Epoch: 97  Training loss = 4.4796  Validation loss = 1.1344  \n",
      "\n",
      "Fold: 22  Epoch: 98  Training loss = 4.4792  Validation loss = 1.1341  \n",
      "\n",
      "Fold: 22  Epoch: 99  Training loss = 4.4788  Validation loss = 1.1337  \n",
      "\n",
      "Fold: 22  Epoch: 100  Training loss = 4.4784  Validation loss = 1.1334  \n",
      "\n",
      "Fold: 22  Epoch: 101  Training loss = 4.4780  Validation loss = 1.1331  \n",
      "\n",
      "Fold: 22  Epoch: 102  Training loss = 4.4774  Validation loss = 1.1327  \n",
      "\n",
      "Fold: 22  Epoch: 103  Training loss = 4.4769  Validation loss = 1.1322  \n",
      "\n",
      "Fold: 22  Epoch: 104  Training loss = 4.4763  Validation loss = 1.1318  \n",
      "\n",
      "Fold: 22  Epoch: 105  Training loss = 4.4759  Validation loss = 1.1314  \n",
      "\n",
      "Fold: 22  Epoch: 106  Training loss = 4.4755  Validation loss = 1.1312  \n",
      "\n",
      "Fold: 22  Epoch: 107  Training loss = 4.4750  Validation loss = 1.1309  \n",
      "\n",
      "Fold: 22  Epoch: 108  Training loss = 4.4745  Validation loss = 1.1304  \n",
      "\n",
      "Fold: 22  Epoch: 109  Training loss = 4.4740  Validation loss = 1.1300  \n",
      "\n",
      "Fold: 22  Epoch: 110  Training loss = 4.4734  Validation loss = 1.1297  \n",
      "\n",
      "Fold: 22  Epoch: 111  Training loss = 4.4729  Validation loss = 1.1293  \n",
      "\n",
      "Fold: 22  Epoch: 112  Training loss = 4.4725  Validation loss = 1.1289  \n",
      "\n",
      "Fold: 22  Epoch: 113  Training loss = 4.4720  Validation loss = 1.1285  \n",
      "\n",
      "Fold: 22  Epoch: 114  Training loss = 4.4714  Validation loss = 1.1282  \n",
      "\n",
      "Fold: 22  Epoch: 115  Training loss = 4.4708  Validation loss = 1.1277  \n",
      "\n",
      "Fold: 22  Epoch: 116  Training loss = 4.4704  Validation loss = 1.1274  \n",
      "\n",
      "Fold: 22  Epoch: 117  Training loss = 4.4700  Validation loss = 1.1272  \n",
      "\n",
      "Fold: 22  Epoch: 118  Training loss = 4.4696  Validation loss = 1.1268  \n",
      "\n",
      "Fold: 22  Epoch: 119  Training loss = 4.4689  Validation loss = 1.1264  \n",
      "\n",
      "Fold: 22  Epoch: 120  Training loss = 4.4683  Validation loss = 1.1259  \n",
      "\n",
      "Fold: 22  Epoch: 121  Training loss = 4.4679  Validation loss = 1.1256  \n",
      "\n",
      "Fold: 22  Epoch: 122  Training loss = 4.4673  Validation loss = 1.1251  \n",
      "\n",
      "Fold: 22  Epoch: 123  Training loss = 4.4670  Validation loss = 1.1249  \n",
      "\n",
      "Fold: 22  Epoch: 124  Training loss = 4.4665  Validation loss = 1.1244  \n",
      "\n",
      "Fold: 22  Epoch: 125  Training loss = 4.4661  Validation loss = 1.1241  \n",
      "\n",
      "Fold: 22  Epoch: 126  Training loss = 4.4655  Validation loss = 1.1238  \n",
      "\n",
      "Fold: 22  Epoch: 127  Training loss = 4.4651  Validation loss = 1.1235  \n",
      "\n",
      "Fold: 22  Epoch: 128  Training loss = 4.4646  Validation loss = 1.1231  \n",
      "\n",
      "Fold: 22  Epoch: 129  Training loss = 4.4641  Validation loss = 1.1228  \n",
      "\n",
      "Fold: 22  Epoch: 130  Training loss = 4.4635  Validation loss = 1.1225  \n",
      "\n",
      "Fold: 22  Epoch: 131  Training loss = 4.4630  Validation loss = 1.1220  \n",
      "\n",
      "Fold: 22  Epoch: 132  Training loss = 4.4625  Validation loss = 1.1217  \n",
      "\n",
      "Fold: 22  Epoch: 133  Training loss = 4.4620  Validation loss = 1.1213  \n",
      "\n",
      "Fold: 22  Epoch: 134  Training loss = 4.4616  Validation loss = 1.1211  \n",
      "\n",
      "Fold: 22  Epoch: 135  Training loss = 4.4611  Validation loss = 1.1208  \n",
      "\n",
      "Fold: 22  Epoch: 136  Training loss = 4.4606  Validation loss = 1.1204  \n",
      "\n",
      "Fold: 22  Epoch: 137  Training loss = 4.4601  Validation loss = 1.1200  \n",
      "\n",
      "Fold: 22  Epoch: 138  Training loss = 4.4597  Validation loss = 1.1197  \n",
      "\n",
      "Fold: 22  Epoch: 139  Training loss = 4.4592  Validation loss = 1.1193  \n",
      "\n",
      "Fold: 22  Epoch: 140  Training loss = 4.4586  Validation loss = 1.1188  \n",
      "\n",
      "Fold: 22  Epoch: 141  Training loss = 4.4580  Validation loss = 1.1183  \n",
      "\n",
      "Fold: 22  Epoch: 142  Training loss = 4.4575  Validation loss = 1.1179  \n",
      "\n",
      "Fold: 22  Epoch: 143  Training loss = 4.4570  Validation loss = 1.1176  \n",
      "\n",
      "Fold: 22  Epoch: 144  Training loss = 4.4565  Validation loss = 1.1172  \n",
      "\n",
      "Fold: 22  Epoch: 145  Training loss = 4.4561  Validation loss = 1.1169  \n",
      "\n",
      "Fold: 22  Epoch: 146  Training loss = 4.4556  Validation loss = 1.1165  \n",
      "\n",
      "Fold: 22  Epoch: 147  Training loss = 4.4551  Validation loss = 1.1161  \n",
      "\n",
      "Fold: 22  Epoch: 148  Training loss = 4.4546  Validation loss = 1.1157  \n",
      "\n",
      "Fold: 22  Epoch: 149  Training loss = 4.4542  Validation loss = 1.1154  \n",
      "\n",
      "Fold: 22  Epoch: 150  Training loss = 4.4538  Validation loss = 1.1151  \n",
      "\n",
      "Fold: 22  Epoch: 151  Training loss = 4.4533  Validation loss = 1.1147  \n",
      "\n",
      "Fold: 22  Epoch: 152  Training loss = 4.4527  Validation loss = 1.1144  \n",
      "\n",
      "Fold: 22  Epoch: 153  Training loss = 4.4523  Validation loss = 1.1140  \n",
      "\n",
      "Fold: 22  Epoch: 154  Training loss = 4.4518  Validation loss = 1.1138  \n",
      "\n",
      "Fold: 22  Epoch: 155  Training loss = 4.4514  Validation loss = 1.1135  \n",
      "\n",
      "Fold: 22  Epoch: 156  Training loss = 4.4510  Validation loss = 1.1131  \n",
      "\n",
      "Fold: 22  Epoch: 157  Training loss = 4.4507  Validation loss = 1.1129  \n",
      "\n",
      "Fold: 22  Epoch: 158  Training loss = 4.4502  Validation loss = 1.1127  \n",
      "\n",
      "Fold: 22  Epoch: 159  Training loss = 4.4497  Validation loss = 1.1123  \n",
      "\n",
      "Fold: 22  Epoch: 160  Training loss = 4.4492  Validation loss = 1.1119  \n",
      "\n",
      "Fold: 22  Epoch: 161  Training loss = 4.4488  Validation loss = 1.1116  \n",
      "\n",
      "Fold: 22  Epoch: 162  Training loss = 4.4483  Validation loss = 1.1113  \n",
      "\n",
      "Fold: 22  Epoch: 163  Training loss = 4.4479  Validation loss = 1.1109  \n",
      "\n",
      "Fold: 22  Epoch: 164  Training loss = 4.4474  Validation loss = 1.1107  \n",
      "\n",
      "Fold: 22  Epoch: 165  Training loss = 4.4469  Validation loss = 1.1103  \n",
      "\n",
      "Fold: 22  Epoch: 166  Training loss = 4.4465  Validation loss = 1.1100  \n",
      "\n",
      "Fold: 22  Epoch: 167  Training loss = 4.4460  Validation loss = 1.1097  \n",
      "\n",
      "Fold: 22  Epoch: 168  Training loss = 4.4457  Validation loss = 1.1096  \n",
      "\n",
      "Fold: 22  Epoch: 169  Training loss = 4.4453  Validation loss = 1.1094  \n",
      "\n",
      "Fold: 22  Epoch: 170  Training loss = 4.4448  Validation loss = 1.1089  \n",
      "\n",
      "Fold: 22  Epoch: 171  Training loss = 4.4444  Validation loss = 1.1086  \n",
      "\n",
      "Fold: 22  Epoch: 172  Training loss = 4.4438  Validation loss = 1.1082  \n",
      "\n",
      "Fold: 22  Epoch: 173  Training loss = 4.4433  Validation loss = 1.1078  \n",
      "\n",
      "Fold: 22  Epoch: 174  Training loss = 4.4428  Validation loss = 1.1074  \n",
      "\n",
      "Fold: 22  Epoch: 175  Training loss = 4.4423  Validation loss = 1.1070  \n",
      "\n",
      "Fold: 22  Epoch: 176  Training loss = 4.4417  Validation loss = 1.1066  \n",
      "\n",
      "Fold: 22  Epoch: 177  Training loss = 4.4412  Validation loss = 1.1062  \n",
      "\n",
      "Fold: 22  Epoch: 178  Training loss = 4.4406  Validation loss = 1.1059  \n",
      "\n",
      "Fold: 22  Epoch: 179  Training loss = 4.4402  Validation loss = 1.1056  \n",
      "\n",
      "Fold: 22  Epoch: 180  Training loss = 4.4397  Validation loss = 1.1052  \n",
      "\n",
      "Fold: 22  Epoch: 181  Training loss = 4.4392  Validation loss = 1.1048  \n",
      "\n",
      "Fold: 22  Epoch: 182  Training loss = 4.4387  Validation loss = 1.1046  \n",
      "\n",
      "Fold: 22  Epoch: 183  Training loss = 4.4383  Validation loss = 1.1043  \n",
      "\n",
      "Fold: 22  Epoch: 184  Training loss = 4.4379  Validation loss = 1.1040  \n",
      "\n",
      "Fold: 22  Epoch: 185  Training loss = 4.4373  Validation loss = 1.1037  \n",
      "\n",
      "Fold: 22  Epoch: 186  Training loss = 4.4366  Validation loss = 1.1033  \n",
      "\n",
      "Fold: 22  Epoch: 187  Training loss = 4.4361  Validation loss = 1.1029  \n",
      "\n",
      "Fold: 22  Epoch: 188  Training loss = 4.4356  Validation loss = 1.1025  \n",
      "\n",
      "Fold: 22  Epoch: 189  Training loss = 4.4351  Validation loss = 1.1021  \n",
      "\n",
      "Fold: 22  Epoch: 190  Training loss = 4.4348  Validation loss = 1.1019  \n",
      "\n",
      "Fold: 22  Epoch: 191  Training loss = 4.4344  Validation loss = 1.1016  \n",
      "\n",
      "Fold: 22  Epoch: 192  Training loss = 4.4340  Validation loss = 1.1013  \n",
      "\n",
      "Fold: 22  Epoch: 193  Training loss = 4.4335  Validation loss = 1.1010  \n",
      "\n",
      "Fold: 22  Epoch: 194  Training loss = 4.4330  Validation loss = 1.1007  \n",
      "\n",
      "Fold: 22  Epoch: 195  Training loss = 4.4325  Validation loss = 1.1004  \n",
      "\n",
      "Fold: 22  Epoch: 196  Training loss = 4.4320  Validation loss = 1.1001  \n",
      "\n",
      "Fold: 22  Epoch: 197  Training loss = 4.4315  Validation loss = 1.0997  \n",
      "\n",
      "Fold: 22  Epoch: 198  Training loss = 4.4311  Validation loss = 1.0996  \n",
      "\n",
      "Fold: 22  Epoch: 199  Training loss = 4.4305  Validation loss = 1.0991  \n",
      "\n",
      "Fold: 22  Epoch: 200  Training loss = 4.4301  Validation loss = 1.0988  \n",
      "\n",
      "Fold: 22  Epoch: 201  Training loss = 4.4295  Validation loss = 1.0985  \n",
      "\n",
      "Fold: 22  Epoch: 202  Training loss = 4.4291  Validation loss = 1.0982  \n",
      "\n",
      "Fold: 22  Epoch: 203  Training loss = 4.4286  Validation loss = 1.0978  \n",
      "\n",
      "Fold: 22  Epoch: 204  Training loss = 4.4282  Validation loss = 1.0976  \n",
      "\n",
      "Fold: 22  Epoch: 205  Training loss = 4.4277  Validation loss = 1.0972  \n",
      "\n",
      "Fold: 22  Epoch: 206  Training loss = 4.4272  Validation loss = 1.0967  \n",
      "\n",
      "Fold: 22  Epoch: 207  Training loss = 4.4267  Validation loss = 1.0964  \n",
      "\n",
      "Fold: 22  Epoch: 208  Training loss = 4.4262  Validation loss = 1.0959  \n",
      "\n",
      "Fold: 22  Epoch: 209  Training loss = 4.4257  Validation loss = 1.0956  \n",
      "\n",
      "Fold: 22  Epoch: 210  Training loss = 4.4253  Validation loss = 1.0952  \n",
      "\n",
      "Fold: 22  Epoch: 211  Training loss = 4.4246  Validation loss = 1.0947  \n",
      "\n",
      "Fold: 22  Epoch: 212  Training loss = 4.4241  Validation loss = 1.0943  \n",
      "\n",
      "Fold: 22  Epoch: 213  Training loss = 4.4238  Validation loss = 1.0941  \n",
      "\n",
      "Fold: 22  Epoch: 214  Training loss = 4.4233  Validation loss = 1.0939  \n",
      "\n",
      "Fold: 22  Epoch: 215  Training loss = 4.4229  Validation loss = 1.0936  \n",
      "\n",
      "Fold: 22  Epoch: 216  Training loss = 4.4223  Validation loss = 1.0934  \n",
      "\n",
      "Fold: 22  Epoch: 217  Training loss = 4.4219  Validation loss = 1.0931  \n",
      "\n",
      "Fold: 22  Epoch: 218  Training loss = 4.4214  Validation loss = 1.0927  \n",
      "\n",
      "Fold: 22  Epoch: 219  Training loss = 4.4210  Validation loss = 1.0924  \n",
      "\n",
      "Fold: 22  Epoch: 220  Training loss = 4.4204  Validation loss = 1.0920  \n",
      "\n",
      "Fold: 22  Epoch: 221  Training loss = 4.4199  Validation loss = 1.0916  \n",
      "\n",
      "Fold: 22  Epoch: 222  Training loss = 4.4194  Validation loss = 1.0910  \n",
      "\n",
      "Fold: 22  Epoch: 223  Training loss = 4.4187  Validation loss = 1.0907  \n",
      "\n",
      "Fold: 22  Epoch: 224  Training loss = 4.4182  Validation loss = 1.0903  \n",
      "\n",
      "Fold: 22  Epoch: 225  Training loss = 4.4177  Validation loss = 1.0899  \n",
      "\n",
      "Fold: 22  Epoch: 226  Training loss = 4.4174  Validation loss = 1.0895  \n",
      "\n",
      "Fold: 22  Epoch: 227  Training loss = 4.4169  Validation loss = 1.0893  \n",
      "\n",
      "Fold: 22  Epoch: 228  Training loss = 4.4164  Validation loss = 1.0888  \n",
      "\n",
      "Fold: 22  Epoch: 229  Training loss = 4.4158  Validation loss = 1.0884  \n",
      "\n",
      "Fold: 22  Epoch: 230  Training loss = 4.4154  Validation loss = 1.0879  \n",
      "\n",
      "Fold: 22  Epoch: 231  Training loss = 4.4149  Validation loss = 1.0874  \n",
      "\n",
      "Fold: 22  Epoch: 232  Training loss = 4.4145  Validation loss = 1.0872  \n",
      "\n",
      "Fold: 22  Epoch: 233  Training loss = 4.4141  Validation loss = 1.0870  \n",
      "\n",
      "Fold: 22  Epoch: 234  Training loss = 4.4136  Validation loss = 1.0866  \n",
      "\n",
      "Fold: 22  Epoch: 235  Training loss = 4.4131  Validation loss = 1.0862  \n",
      "\n",
      "Fold: 22  Epoch: 236  Training loss = 4.4128  Validation loss = 1.0860  \n",
      "\n",
      "Fold: 22  Epoch: 237  Training loss = 4.4123  Validation loss = 1.0857  \n",
      "\n",
      "Fold: 22  Epoch: 238  Training loss = 4.4119  Validation loss = 1.0856  \n",
      "\n",
      "Fold: 22  Epoch: 239  Training loss = 4.4115  Validation loss = 1.0852  \n",
      "\n",
      "Fold: 22  Epoch: 240  Training loss = 4.4110  Validation loss = 1.0850  \n",
      "\n",
      "Fold: 22  Epoch: 241  Training loss = 4.4104  Validation loss = 1.0846  \n",
      "\n",
      "Fold: 22  Epoch: 242  Training loss = 4.4097  Validation loss = 1.0842  \n",
      "\n",
      "Fold: 22  Epoch: 243  Training loss = 4.4094  Validation loss = 1.0839  \n",
      "\n",
      "Fold: 22  Epoch: 244  Training loss = 4.4090  Validation loss = 1.0836  \n",
      "\n",
      "Fold: 22  Epoch: 245  Training loss = 4.4087  Validation loss = 1.0834  \n",
      "\n",
      "Fold: 22  Epoch: 246  Training loss = 4.4082  Validation loss = 1.0831  \n",
      "\n",
      "Fold: 22  Epoch: 247  Training loss = 4.4078  Validation loss = 1.0829  \n",
      "\n",
      "Fold: 22  Epoch: 248  Training loss = 4.4074  Validation loss = 1.0827  \n",
      "\n",
      "Fold: 22  Epoch: 249  Training loss = 4.4069  Validation loss = 1.0825  \n",
      "\n",
      "Fold: 22  Epoch: 250  Training loss = 4.4064  Validation loss = 1.0822  \n",
      "\n",
      "Fold: 22  Epoch: 251  Training loss = 4.4060  Validation loss = 1.0821  \n",
      "\n",
      "Fold: 22  Epoch: 252  Training loss = 4.4055  Validation loss = 1.0818  \n",
      "\n",
      "Fold: 22  Epoch: 253  Training loss = 4.4050  Validation loss = 1.0815  \n",
      "\n",
      "Fold: 22  Epoch: 254  Training loss = 4.4046  Validation loss = 1.0812  \n",
      "\n",
      "Fold: 22  Epoch: 255  Training loss = 4.4042  Validation loss = 1.0810  \n",
      "\n",
      "Fold: 22  Epoch: 256  Training loss = 4.4036  Validation loss = 1.0805  \n",
      "\n",
      "Fold: 22  Epoch: 257  Training loss = 4.4031  Validation loss = 1.0802  \n",
      "\n",
      "Fold: 22  Epoch: 258  Training loss = 4.4025  Validation loss = 1.0798  \n",
      "\n",
      "Fold: 22  Epoch: 259  Training loss = 4.4021  Validation loss = 1.0796  \n",
      "\n",
      "Fold: 22  Epoch: 260  Training loss = 4.4015  Validation loss = 1.0793  \n",
      "\n",
      "Fold: 22  Epoch: 261  Training loss = 4.4009  Validation loss = 1.0789  \n",
      "\n",
      "Fold: 22  Epoch: 262  Training loss = 4.4005  Validation loss = 1.0788  \n",
      "\n",
      "Fold: 22  Epoch: 263  Training loss = 4.4000  Validation loss = 1.0785  \n",
      "\n",
      "Fold: 22  Epoch: 264  Training loss = 4.3996  Validation loss = 1.0782  \n",
      "\n",
      "Fold: 22  Epoch: 265  Training loss = 4.3990  Validation loss = 1.0780  \n",
      "\n",
      "Fold: 22  Epoch: 266  Training loss = 4.3985  Validation loss = 1.0779  \n",
      "\n",
      "Fold: 22  Epoch: 267  Training loss = 4.3980  Validation loss = 1.0778  \n",
      "\n",
      "Fold: 22  Epoch: 268  Training loss = 4.3976  Validation loss = 1.0775  \n",
      "\n",
      "Fold: 22  Epoch: 269  Training loss = 4.3970  Validation loss = 1.0774  \n",
      "\n",
      "Fold: 22  Epoch: 270  Training loss = 4.3966  Validation loss = 1.0773  \n",
      "\n",
      "Fold: 22  Epoch: 271  Training loss = 4.3962  Validation loss = 1.0769  \n",
      "\n",
      "Fold: 22  Epoch: 272  Training loss = 4.3956  Validation loss = 1.0766  \n",
      "\n",
      "Fold: 22  Epoch: 273  Training loss = 4.3952  Validation loss = 1.0763  \n",
      "\n",
      "Fold: 22  Epoch: 274  Training loss = 4.3949  Validation loss = 1.0761  \n",
      "\n",
      "Fold: 22  Epoch: 275  Training loss = 4.3944  Validation loss = 1.0760  \n",
      "\n",
      "Fold: 22  Epoch: 276  Training loss = 4.3939  Validation loss = 1.0757  \n",
      "\n",
      "Fold: 22  Epoch: 277  Training loss = 4.3933  Validation loss = 1.0753  \n",
      "\n",
      "Fold: 22  Epoch: 278  Training loss = 4.3930  Validation loss = 1.0753  \n",
      "\n",
      "Fold: 22  Epoch: 279  Training loss = 4.3927  Validation loss = 1.0752  \n",
      "\n",
      "Fold: 22  Epoch: 280  Training loss = 4.3922  Validation loss = 1.0749  \n",
      "\n",
      "Fold: 22  Epoch: 281  Training loss = 4.3917  Validation loss = 1.0748  \n",
      "\n",
      "Fold: 22  Epoch: 282  Training loss = 4.3912  Validation loss = 1.0747  \n",
      "\n",
      "Fold: 22  Epoch: 283  Training loss = 4.3908  Validation loss = 1.0746  \n",
      "\n",
      "Fold: 22  Epoch: 284  Training loss = 4.3904  Validation loss = 1.0746  \n",
      "\n",
      "Fold: 22  Epoch: 285  Training loss = 4.3899  Validation loss = 1.0744  \n",
      "\n",
      "Fold: 22  Epoch: 286  Training loss = 4.3894  Validation loss = 1.0743  \n",
      "\n",
      "Fold: 22  Epoch: 287  Training loss = 4.3888  Validation loss = 1.0742  \n",
      "\n",
      "Fold: 22  Epoch: 288  Training loss = 4.3883  Validation loss = 1.0740  \n",
      "\n",
      "Fold: 22  Epoch: 289  Training loss = 4.3878  Validation loss = 1.0738  \n",
      "\n",
      "Fold: 22  Epoch: 290  Training loss = 4.3873  Validation loss = 1.0736  \n",
      "\n",
      "Fold: 22  Epoch: 291  Training loss = 4.3869  Validation loss = 1.0732  \n",
      "\n",
      "Fold: 22  Epoch: 292  Training loss = 4.3862  Validation loss = 1.0728  \n",
      "\n",
      "Fold: 22  Epoch: 293  Training loss = 4.3857  Validation loss = 1.0725  \n",
      "\n",
      "Fold: 22  Epoch: 294  Training loss = 4.3852  Validation loss = 1.0724  \n",
      "\n",
      "Fold: 22  Epoch: 295  Training loss = 4.3847  Validation loss = 1.0721  \n",
      "\n",
      "Fold: 22  Epoch: 296  Training loss = 4.3841  Validation loss = 1.0719  \n",
      "\n",
      "Fold: 22  Epoch: 297  Training loss = 4.3835  Validation loss = 1.0717  \n",
      "\n",
      "Fold: 22  Epoch: 298  Training loss = 4.3832  Validation loss = 1.0716  \n",
      "\n",
      "Fold: 22  Epoch: 299  Training loss = 4.3827  Validation loss = 1.0712  \n",
      "\n",
      "Fold: 22  Epoch: 300  Training loss = 4.3822  Validation loss = 1.0709  \n",
      "\n",
      "Fold: 22  Epoch: 301  Training loss = 4.3817  Validation loss = 1.0706  \n",
      "\n",
      "Fold: 22  Epoch: 302  Training loss = 4.3812  Validation loss = 1.0704  \n",
      "\n",
      "Fold: 22  Epoch: 303  Training loss = 4.3808  Validation loss = 1.0703  \n",
      "\n",
      "Fold: 22  Epoch: 304  Training loss = 4.3804  Validation loss = 1.0700  \n",
      "\n",
      "Fold: 22  Epoch: 305  Training loss = 4.3798  Validation loss = 1.0696  \n",
      "\n",
      "Fold: 22  Epoch: 306  Training loss = 4.3793  Validation loss = 1.0696  \n",
      "\n",
      "Fold: 22  Epoch: 307  Training loss = 4.3788  Validation loss = 1.0694  \n",
      "\n",
      "Fold: 22  Epoch: 308  Training loss = 4.3784  Validation loss = 1.0693  \n",
      "\n",
      "Fold: 22  Epoch: 309  Training loss = 4.3780  Validation loss = 1.0691  \n",
      "\n",
      "Fold: 22  Epoch: 310  Training loss = 4.3776  Validation loss = 1.0689  \n",
      "\n",
      "Fold: 22  Epoch: 311  Training loss = 4.3771  Validation loss = 1.0691  \n",
      "\n",
      "Fold: 22  Epoch: 312  Training loss = 4.3765  Validation loss = 1.0688  \n",
      "\n",
      "Fold: 22  Epoch: 313  Training loss = 4.3761  Validation loss = 1.0686  \n",
      "\n",
      "Fold: 22  Epoch: 314  Training loss = 4.3756  Validation loss = 1.0683  \n",
      "\n",
      "Fold: 22  Epoch: 315  Training loss = 4.3752  Validation loss = 1.0682  \n",
      "\n",
      "Fold: 22  Epoch: 316  Training loss = 4.3748  Validation loss = 1.0682  \n",
      "\n",
      "Fold: 22  Epoch: 317  Training loss = 4.3744  Validation loss = 1.0681  \n",
      "\n",
      "Fold: 22  Epoch: 318  Training loss = 4.3740  Validation loss = 1.0679  \n",
      "\n",
      "Fold: 22  Epoch: 319  Training loss = 4.3736  Validation loss = 1.0676  \n",
      "\n",
      "Fold: 22  Epoch: 320  Training loss = 4.3731  Validation loss = 1.0675  \n",
      "\n",
      "Fold: 22  Epoch: 321  Training loss = 4.3727  Validation loss = 1.0671  \n",
      "\n",
      "Fold: 22  Epoch: 322  Training loss = 4.3722  Validation loss = 1.0669  \n",
      "\n",
      "Fold: 22  Epoch: 323  Training loss = 4.3718  Validation loss = 1.0668  \n",
      "\n",
      "Fold: 22  Epoch: 324  Training loss = 4.3715  Validation loss = 1.0668  \n",
      "\n",
      "Fold: 22  Epoch: 325  Training loss = 4.3711  Validation loss = 1.0666  \n",
      "\n",
      "Fold: 22  Epoch: 326  Training loss = 4.3708  Validation loss = 1.0665  \n",
      "\n",
      "Fold: 22  Epoch: 327  Training loss = 4.3705  Validation loss = 1.0663  \n",
      "\n",
      "Fold: 22  Epoch: 328  Training loss = 4.3702  Validation loss = 1.0662  \n",
      "\n",
      "Fold: 22  Epoch: 329  Training loss = 4.3696  Validation loss = 1.0660  \n",
      "\n",
      "Fold: 22  Epoch: 330  Training loss = 4.3692  Validation loss = 1.0657  \n",
      "\n",
      "Fold: 22  Epoch: 331  Training loss = 4.3687  Validation loss = 1.0654  \n",
      "\n",
      "Fold: 22  Epoch: 332  Training loss = 4.3683  Validation loss = 1.0652  \n",
      "\n",
      "Fold: 22  Epoch: 333  Training loss = 4.3679  Validation loss = 1.0651  \n",
      "\n",
      "Fold: 22  Epoch: 334  Training loss = 4.3675  Validation loss = 1.0649  \n",
      "\n",
      "Fold: 22  Epoch: 335  Training loss = 4.3670  Validation loss = 1.0647  \n",
      "\n",
      "Fold: 22  Epoch: 336  Training loss = 4.3666  Validation loss = 1.0643  \n",
      "\n",
      "Fold: 22  Epoch: 337  Training loss = 4.3662  Validation loss = 1.0641  \n",
      "\n",
      "Fold: 22  Epoch: 338  Training loss = 4.3657  Validation loss = 1.0638  \n",
      "\n",
      "Fold: 22  Epoch: 339  Training loss = 4.3653  Validation loss = 1.0636  \n",
      "\n",
      "Fold: 22  Epoch: 340  Training loss = 4.3649  Validation loss = 1.0635  \n",
      "\n",
      "Fold: 22  Epoch: 341  Training loss = 4.3645  Validation loss = 1.0634  \n",
      "\n",
      "Fold: 22  Epoch: 342  Training loss = 4.3641  Validation loss = 1.0633  \n",
      "\n",
      "Fold: 22  Epoch: 343  Training loss = 4.3636  Validation loss = 1.0632  \n",
      "\n",
      "Fold: 22  Epoch: 344  Training loss = 4.3632  Validation loss = 1.0629  \n",
      "\n",
      "Fold: 22  Epoch: 345  Training loss = 4.3627  Validation loss = 1.0628  \n",
      "\n",
      "Fold: 22  Epoch: 346  Training loss = 4.3625  Validation loss = 1.0626  \n",
      "\n",
      "Fold: 22  Epoch: 347  Training loss = 4.3619  Validation loss = 1.0625  \n",
      "\n",
      "Fold: 22  Epoch: 348  Training loss = 4.3615  Validation loss = 1.0623  \n",
      "\n",
      "Fold: 22  Epoch: 349  Training loss = 4.3611  Validation loss = 1.0622  \n",
      "\n",
      "Fold: 22  Epoch: 350  Training loss = 4.3606  Validation loss = 1.0621  \n",
      "\n",
      "Fold: 22  Epoch: 351  Training loss = 4.3602  Validation loss = 1.0620  \n",
      "\n",
      "Fold: 22  Epoch: 352  Training loss = 4.3597  Validation loss = 1.0616  \n",
      "\n",
      "Fold: 22  Epoch: 353  Training loss = 4.3594  Validation loss = 1.0615  \n",
      "\n",
      "Fold: 22  Epoch: 354  Training loss = 4.3589  Validation loss = 1.0613  \n",
      "\n",
      "Fold: 22  Epoch: 355  Training loss = 4.3584  Validation loss = 1.0613  \n",
      "\n",
      "Fold: 22  Epoch: 356  Training loss = 4.3580  Validation loss = 1.0613  \n",
      "\n",
      "Fold: 22  Epoch: 357  Training loss = 4.3576  Validation loss = 1.0610  \n",
      "\n",
      "Fold: 22  Epoch: 358  Training loss = 4.3570  Validation loss = 1.0606  \n",
      "\n",
      "Fold: 22  Epoch: 359  Training loss = 4.3567  Validation loss = 1.0604  \n",
      "\n",
      "Fold: 22  Epoch: 360  Training loss = 4.3562  Validation loss = 1.0600  \n",
      "\n",
      "Fold: 22  Epoch: 361  Training loss = 4.3559  Validation loss = 1.0598  \n",
      "\n",
      "Fold: 22  Epoch: 362  Training loss = 4.3553  Validation loss = 1.0596  \n",
      "\n",
      "Fold: 22  Epoch: 363  Training loss = 4.3549  Validation loss = 1.0594  \n",
      "\n",
      "Fold: 22  Epoch: 364  Training loss = 4.3545  Validation loss = 1.0592  \n",
      "\n",
      "Fold: 22  Epoch: 365  Training loss = 4.3541  Validation loss = 1.0591  \n",
      "\n",
      "Fold: 22  Epoch: 366  Training loss = 4.3537  Validation loss = 1.0587  \n",
      "\n",
      "Fold: 22  Epoch: 367  Training loss = 4.3534  Validation loss = 1.0585  \n",
      "\n",
      "Fold: 22  Epoch: 368  Training loss = 4.3528  Validation loss = 1.0581  \n",
      "\n",
      "Fold: 22  Epoch: 369  Training loss = 4.3523  Validation loss = 1.0581  \n",
      "\n",
      "Fold: 22  Epoch: 370  Training loss = 4.3520  Validation loss = 1.0579  \n",
      "\n",
      "Fold: 22  Epoch: 371  Training loss = 4.3515  Validation loss = 1.0576  \n",
      "\n",
      "Fold: 22  Epoch: 372  Training loss = 4.3512  Validation loss = 1.0577  \n",
      "\n",
      "Fold: 22  Epoch: 373  Training loss = 4.3507  Validation loss = 1.0574  \n",
      "\n",
      "Fold: 22  Epoch: 374  Training loss = 4.3503  Validation loss = 1.0572  \n",
      "\n",
      "Fold: 22  Epoch: 375  Training loss = 4.3498  Validation loss = 1.0571  \n",
      "\n",
      "Fold: 22  Epoch: 376  Training loss = 4.3493  Validation loss = 1.0570  \n",
      "\n",
      "Fold: 22  Epoch: 377  Training loss = 4.3489  Validation loss = 1.0568  \n",
      "\n",
      "Fold: 22  Epoch: 378  Training loss = 4.3485  Validation loss = 1.0567  \n",
      "\n",
      "Fold: 22  Epoch: 379  Training loss = 4.3482  Validation loss = 1.0566  \n",
      "\n",
      "Fold: 22  Epoch: 380  Training loss = 4.3476  Validation loss = 1.0563  \n",
      "\n",
      "Fold: 22  Epoch: 381  Training loss = 4.3473  Validation loss = 1.0562  \n",
      "\n",
      "Fold: 22  Epoch: 382  Training loss = 4.3468  Validation loss = 1.0559  \n",
      "\n",
      "Fold: 22  Epoch: 383  Training loss = 4.3465  Validation loss = 1.0557  \n",
      "\n",
      "Fold: 22  Epoch: 384  Training loss = 4.3462  Validation loss = 1.0557  \n",
      "\n",
      "Fold: 22  Epoch: 385  Training loss = 4.3459  Validation loss = 1.0555  \n",
      "\n",
      "Fold: 22  Epoch: 386  Training loss = 4.3456  Validation loss = 1.0554  \n",
      "\n",
      "Fold: 22  Epoch: 387  Training loss = 4.3451  Validation loss = 1.0552  \n",
      "\n",
      "Fold: 22  Epoch: 388  Training loss = 4.3446  Validation loss = 1.0551  \n",
      "\n",
      "Fold: 22  Epoch: 389  Training loss = 4.3442  Validation loss = 1.0548  \n",
      "\n",
      "Fold: 22  Epoch: 390  Training loss = 4.3438  Validation loss = 1.0547  \n",
      "\n",
      "Fold: 22  Epoch: 391  Training loss = 4.3433  Validation loss = 1.0543  \n",
      "\n",
      "Fold: 22  Epoch: 392  Training loss = 4.3428  Validation loss = 1.0541  \n",
      "\n",
      "Fold: 22  Epoch: 393  Training loss = 4.3422  Validation loss = 1.0540  \n",
      "\n",
      "Fold: 22  Epoch: 394  Training loss = 4.3417  Validation loss = 1.0537  \n",
      "\n",
      "Fold: 22  Epoch: 395  Training loss = 4.3413  Validation loss = 1.0536  \n",
      "\n",
      "Fold: 22  Epoch: 396  Training loss = 4.3408  Validation loss = 1.0536  \n",
      "\n",
      "Fold: 22  Epoch: 397  Training loss = 4.3401  Validation loss = 1.0538  \n",
      "\n",
      "Fold: 22  Epoch: 398  Training loss = 4.3387  Validation loss = 1.0542  \n",
      "\n",
      "Fold: 22  Epoch: 399  Training loss = 4.3371  Validation loss = 1.0549  \n",
      "\n",
      "Check model:  Fold: 22  Optimal epoch: 395  \n",
      "\n",
      "Fold: 23  Epoch: 1  Training loss = 4.3356  Validation loss = 0.8749  \n",
      "\n",
      "Fold: 23  Epoch: 2  Training loss = 4.3351  Validation loss = 0.8745  \n",
      "\n",
      "Fold: 23  Epoch: 3  Training loss = 4.3346  Validation loss = 0.8743  \n",
      "\n",
      "Fold: 23  Epoch: 4  Training loss = 4.3343  Validation loss = 0.8740  \n",
      "\n",
      "Fold: 23  Epoch: 5  Training loss = 4.3338  Validation loss = 0.8736  \n",
      "\n",
      "Fold: 23  Epoch: 6  Training loss = 4.3333  Validation loss = 0.8733  \n",
      "\n",
      "Fold: 23  Epoch: 7  Training loss = 4.3330  Validation loss = 0.8730  \n",
      "\n",
      "Fold: 23  Epoch: 8  Training loss = 4.3326  Validation loss = 0.8727  \n",
      "\n",
      "Fold: 23  Epoch: 9  Training loss = 4.3322  Validation loss = 0.8724  \n",
      "\n",
      "Fold: 23  Epoch: 10  Training loss = 4.3319  Validation loss = 0.8722  \n",
      "\n",
      "Fold: 23  Epoch: 11  Training loss = 4.3314  Validation loss = 0.8718  \n",
      "\n",
      "Fold: 23  Epoch: 12  Training loss = 4.3311  Validation loss = 0.8715  \n",
      "\n",
      "Fold: 23  Epoch: 13  Training loss = 4.3308  Validation loss = 0.8711  \n",
      "\n",
      "Fold: 23  Epoch: 14  Training loss = 4.3304  Validation loss = 0.8708  \n",
      "\n",
      "Fold: 23  Epoch: 15  Training loss = 4.3301  Validation loss = 0.8706  \n",
      "\n",
      "Fold: 23  Epoch: 16  Training loss = 4.3298  Validation loss = 0.8703  \n",
      "\n",
      "Fold: 23  Epoch: 17  Training loss = 4.3293  Validation loss = 0.8698  \n",
      "\n",
      "Fold: 23  Epoch: 18  Training loss = 4.3290  Validation loss = 0.8696  \n",
      "\n",
      "Fold: 23  Epoch: 19  Training loss = 4.3286  Validation loss = 0.8693  \n",
      "\n",
      "Fold: 23  Epoch: 20  Training loss = 4.3281  Validation loss = 0.8688  \n",
      "\n",
      "Fold: 23  Epoch: 21  Training loss = 4.3277  Validation loss = 0.8685  \n",
      "\n",
      "Fold: 23  Epoch: 22  Training loss = 4.3274  Validation loss = 0.8683  \n",
      "\n",
      "Fold: 23  Epoch: 23  Training loss = 4.3270  Validation loss = 0.8679  \n",
      "\n",
      "Fold: 23  Epoch: 24  Training loss = 4.3265  Validation loss = 0.8675  \n",
      "\n",
      "Fold: 23  Epoch: 25  Training loss = 4.3261  Validation loss = 0.8671  \n",
      "\n",
      "Fold: 23  Epoch: 26  Training loss = 4.3258  Validation loss = 0.8668  \n",
      "\n",
      "Fold: 23  Epoch: 27  Training loss = 4.3255  Validation loss = 0.8666  \n",
      "\n",
      "Fold: 23  Epoch: 28  Training loss = 4.3251  Validation loss = 0.8662  \n",
      "\n",
      "Fold: 23  Epoch: 29  Training loss = 4.3247  Validation loss = 0.8660  \n",
      "\n",
      "Fold: 23  Epoch: 30  Training loss = 4.3243  Validation loss = 0.8656  \n",
      "\n",
      "Fold: 23  Epoch: 31  Training loss = 4.3239  Validation loss = 0.8652  \n",
      "\n",
      "Fold: 23  Epoch: 32  Training loss = 4.3235  Validation loss = 0.8648  \n",
      "\n",
      "Fold: 23  Epoch: 33  Training loss = 4.3232  Validation loss = 0.8645  \n",
      "\n",
      "Fold: 23  Epoch: 34  Training loss = 4.3227  Validation loss = 0.8641  \n",
      "\n",
      "Fold: 23  Epoch: 35  Training loss = 4.3223  Validation loss = 0.8638  \n",
      "\n",
      "Fold: 23  Epoch: 36  Training loss = 4.3220  Validation loss = 0.8634  \n",
      "\n",
      "Fold: 23  Epoch: 37  Training loss = 4.3216  Validation loss = 0.8631  \n",
      "\n",
      "Fold: 23  Epoch: 38  Training loss = 4.3212  Validation loss = 0.8627  \n",
      "\n",
      "Fold: 23  Epoch: 39  Training loss = 4.3207  Validation loss = 0.8623  \n",
      "\n",
      "Fold: 23  Epoch: 40  Training loss = 4.3203  Validation loss = 0.8620  \n",
      "\n",
      "Fold: 23  Epoch: 41  Training loss = 4.3198  Validation loss = 0.8616  \n",
      "\n",
      "Fold: 23  Epoch: 42  Training loss = 4.3196  Validation loss = 0.8613  \n",
      "\n",
      "Fold: 23  Epoch: 43  Training loss = 4.3192  Validation loss = 0.8610  \n",
      "\n",
      "Fold: 23  Epoch: 44  Training loss = 4.3188  Validation loss = 0.8606  \n",
      "\n",
      "Fold: 23  Epoch: 45  Training loss = 4.3184  Validation loss = 0.8602  \n",
      "\n",
      "Fold: 23  Epoch: 46  Training loss = 4.3179  Validation loss = 0.8598  \n",
      "\n",
      "Fold: 23  Epoch: 47  Training loss = 4.3175  Validation loss = 0.8595  \n",
      "\n",
      "Fold: 23  Epoch: 48  Training loss = 4.3171  Validation loss = 0.8591  \n",
      "\n",
      "Fold: 23  Epoch: 49  Training loss = 4.3168  Validation loss = 0.8588  \n",
      "\n",
      "Fold: 23  Epoch: 50  Training loss = 4.3164  Validation loss = 0.8584  \n",
      "\n",
      "Fold: 23  Epoch: 51  Training loss = 4.3159  Validation loss = 0.8580  \n",
      "\n",
      "Fold: 23  Epoch: 52  Training loss = 4.3155  Validation loss = 0.8576  \n",
      "\n",
      "Fold: 23  Epoch: 53  Training loss = 4.3152  Validation loss = 0.8574  \n",
      "\n",
      "Fold: 23  Epoch: 54  Training loss = 4.3148  Validation loss = 0.8571  \n",
      "\n",
      "Fold: 23  Epoch: 55  Training loss = 4.3144  Validation loss = 0.8567  \n",
      "\n",
      "Fold: 23  Epoch: 56  Training loss = 4.3141  Validation loss = 0.8565  \n",
      "\n",
      "Fold: 23  Epoch: 57  Training loss = 4.3138  Validation loss = 0.8561  \n",
      "\n",
      "Fold: 23  Epoch: 58  Training loss = 4.3133  Validation loss = 0.8556  \n",
      "\n",
      "Fold: 23  Epoch: 59  Training loss = 4.3129  Validation loss = 0.8553  \n",
      "\n",
      "Fold: 23  Epoch: 60  Training loss = 4.3125  Validation loss = 0.8550  \n",
      "\n",
      "Fold: 23  Epoch: 61  Training loss = 4.3121  Validation loss = 0.8547  \n",
      "\n",
      "Fold: 23  Epoch: 62  Training loss = 4.3117  Validation loss = 0.8543  \n",
      "\n",
      "Fold: 23  Epoch: 63  Training loss = 4.3114  Validation loss = 0.8541  \n",
      "\n",
      "Fold: 23  Epoch: 64  Training loss = 4.3111  Validation loss = 0.8538  \n",
      "\n",
      "Fold: 23  Epoch: 65  Training loss = 4.3107  Validation loss = 0.8535  \n",
      "\n",
      "Fold: 23  Epoch: 66  Training loss = 4.3104  Validation loss = 0.8532  \n",
      "\n",
      "Fold: 23  Epoch: 67  Training loss = 4.3100  Validation loss = 0.8529  \n",
      "\n",
      "Fold: 23  Epoch: 68  Training loss = 4.3095  Validation loss = 0.8524  \n",
      "\n",
      "Fold: 23  Epoch: 69  Training loss = 4.3091  Validation loss = 0.8520  \n",
      "\n",
      "Fold: 23  Epoch: 70  Training loss = 4.3087  Validation loss = 0.8516  \n",
      "\n",
      "Fold: 23  Epoch: 71  Training loss = 4.3083  Validation loss = 0.8513  \n",
      "\n",
      "Fold: 23  Epoch: 72  Training loss = 4.3078  Validation loss = 0.8508  \n",
      "\n",
      "Fold: 23  Epoch: 73  Training loss = 4.3075  Validation loss = 0.8506  \n",
      "\n",
      "Fold: 23  Epoch: 74  Training loss = 4.3069  Validation loss = 0.8501  \n",
      "\n",
      "Fold: 23  Epoch: 75  Training loss = 4.3064  Validation loss = 0.8496  \n",
      "\n",
      "Fold: 23  Epoch: 76  Training loss = 4.3060  Validation loss = 0.8493  \n",
      "\n",
      "Fold: 23  Epoch: 77  Training loss = 4.3056  Validation loss = 0.8489  \n",
      "\n",
      "Fold: 23  Epoch: 78  Training loss = 4.3052  Validation loss = 0.8485  \n",
      "\n",
      "Fold: 23  Epoch: 79  Training loss = 4.3048  Validation loss = 0.8481  \n",
      "\n",
      "Fold: 23  Epoch: 80  Training loss = 4.3045  Validation loss = 0.8479  \n",
      "\n",
      "Fold: 23  Epoch: 81  Training loss = 4.3042  Validation loss = 0.8476  \n",
      "\n",
      "Fold: 23  Epoch: 82  Training loss = 4.3039  Validation loss = 0.8474  \n",
      "\n",
      "Fold: 23  Epoch: 83  Training loss = 4.3036  Validation loss = 0.8471  \n",
      "\n",
      "Fold: 23  Epoch: 84  Training loss = 4.3032  Validation loss = 0.8468  \n",
      "\n",
      "Fold: 23  Epoch: 85  Training loss = 4.3027  Validation loss = 0.8465  \n",
      "\n",
      "Fold: 23  Epoch: 86  Training loss = 4.3022  Validation loss = 0.8461  \n",
      "\n",
      "Fold: 23  Epoch: 87  Training loss = 4.3019  Validation loss = 0.8458  \n",
      "\n",
      "Fold: 23  Epoch: 88  Training loss = 4.3017  Validation loss = 0.8456  \n",
      "\n",
      "Fold: 23  Epoch: 89  Training loss = 4.3014  Validation loss = 0.8454  \n",
      "\n",
      "Fold: 23  Epoch: 90  Training loss = 4.3010  Validation loss = 0.8450  \n",
      "\n",
      "Fold: 23  Epoch: 91  Training loss = 4.3006  Validation loss = 0.8447  \n",
      "\n",
      "Fold: 23  Epoch: 92  Training loss = 4.3002  Validation loss = 0.8444  \n",
      "\n",
      "Fold: 23  Epoch: 93  Training loss = 4.2998  Validation loss = 0.8441  \n",
      "\n",
      "Fold: 23  Epoch: 94  Training loss = 4.2995  Validation loss = 0.8438  \n",
      "\n",
      "Fold: 23  Epoch: 95  Training loss = 4.2992  Validation loss = 0.8435  \n",
      "\n",
      "Fold: 23  Epoch: 96  Training loss = 4.2988  Validation loss = 0.8432  \n",
      "\n",
      "Fold: 23  Epoch: 97  Training loss = 4.2985  Validation loss = 0.8429  \n",
      "\n",
      "Fold: 23  Epoch: 98  Training loss = 4.2980  Validation loss = 0.8425  \n",
      "\n",
      "Fold: 23  Epoch: 99  Training loss = 4.2976  Validation loss = 0.8421  \n",
      "\n",
      "Fold: 23  Epoch: 100  Training loss = 4.2972  Validation loss = 0.8418  \n",
      "\n",
      "Fold: 23  Epoch: 101  Training loss = 4.2967  Validation loss = 0.8414  \n",
      "\n",
      "Fold: 23  Epoch: 102  Training loss = 4.2962  Validation loss = 0.8409  \n",
      "\n",
      "Fold: 23  Epoch: 103  Training loss = 4.2959  Validation loss = 0.8406  \n",
      "\n",
      "Fold: 23  Epoch: 104  Training loss = 4.2954  Validation loss = 0.8402  \n",
      "\n",
      "Fold: 23  Epoch: 105  Training loss = 4.2950  Validation loss = 0.8398  \n",
      "\n",
      "Fold: 23  Epoch: 106  Training loss = 4.2946  Validation loss = 0.8395  \n",
      "\n",
      "Fold: 23  Epoch: 107  Training loss = 4.2943  Validation loss = 0.8393  \n",
      "\n",
      "Fold: 23  Epoch: 108  Training loss = 4.2940  Validation loss = 0.8390  \n",
      "\n",
      "Fold: 23  Epoch: 109  Training loss = 4.2937  Validation loss = 0.8388  \n",
      "\n",
      "Fold: 23  Epoch: 110  Training loss = 4.2933  Validation loss = 0.8386  \n",
      "\n",
      "Fold: 23  Epoch: 111  Training loss = 4.2930  Validation loss = 0.8382  \n",
      "\n",
      "Fold: 23  Epoch: 112  Training loss = 4.2927  Validation loss = 0.8381  \n",
      "\n",
      "Fold: 23  Epoch: 113  Training loss = 4.2923  Validation loss = 0.8378  \n",
      "\n",
      "Fold: 23  Epoch: 114  Training loss = 4.2921  Validation loss = 0.8376  \n",
      "\n",
      "Fold: 23  Epoch: 115  Training loss = 4.2917  Validation loss = 0.8372  \n",
      "\n",
      "Fold: 23  Epoch: 116  Training loss = 4.2913  Validation loss = 0.8369  \n",
      "\n",
      "Fold: 23  Epoch: 117  Training loss = 4.2908  Validation loss = 0.8365  \n",
      "\n",
      "Fold: 23  Epoch: 118  Training loss = 4.2904  Validation loss = 0.8361  \n",
      "\n",
      "Fold: 23  Epoch: 119  Training loss = 4.2900  Validation loss = 0.8358  \n",
      "\n",
      "Fold: 23  Epoch: 120  Training loss = 4.2897  Validation loss = 0.8356  \n",
      "\n",
      "Fold: 23  Epoch: 121  Training loss = 4.2893  Validation loss = 0.8351  \n",
      "\n",
      "Fold: 23  Epoch: 122  Training loss = 4.2889  Validation loss = 0.8349  \n",
      "\n",
      "Fold: 23  Epoch: 123  Training loss = 4.2886  Validation loss = 0.8347  \n",
      "\n",
      "Fold: 23  Epoch: 124  Training loss = 4.2883  Validation loss = 0.8344  \n",
      "\n",
      "Fold: 23  Epoch: 125  Training loss = 4.2880  Validation loss = 0.8341  \n",
      "\n",
      "Fold: 23  Epoch: 126  Training loss = 4.2876  Validation loss = 0.8338  \n",
      "\n",
      "Fold: 23  Epoch: 127  Training loss = 4.2873  Validation loss = 0.8334  \n",
      "\n",
      "Fold: 23  Epoch: 128  Training loss = 4.2869  Validation loss = 0.8331  \n",
      "\n",
      "Fold: 23  Epoch: 129  Training loss = 4.2865  Validation loss = 0.8328  \n",
      "\n",
      "Fold: 23  Epoch: 130  Training loss = 4.2861  Validation loss = 0.8324  \n",
      "\n",
      "Fold: 23  Epoch: 131  Training loss = 4.2857  Validation loss = 0.8321  \n",
      "\n",
      "Fold: 23  Epoch: 132  Training loss = 4.2853  Validation loss = 0.8319  \n",
      "\n",
      "Fold: 23  Epoch: 133  Training loss = 4.2850  Validation loss = 0.8316  \n",
      "\n",
      "Fold: 23  Epoch: 134  Training loss = 4.2845  Validation loss = 0.8311  \n",
      "\n",
      "Fold: 23  Epoch: 135  Training loss = 4.2842  Validation loss = 0.8309  \n",
      "\n",
      "Fold: 23  Epoch: 136  Training loss = 4.2837  Validation loss = 0.8306  \n",
      "\n",
      "Fold: 23  Epoch: 137  Training loss = 4.2832  Validation loss = 0.8301  \n",
      "\n",
      "Fold: 23  Epoch: 138  Training loss = 4.2828  Validation loss = 0.8297  \n",
      "\n",
      "Fold: 23  Epoch: 139  Training loss = 4.2825  Validation loss = 0.8294  \n",
      "\n",
      "Fold: 23  Epoch: 140  Training loss = 4.2821  Validation loss = 0.8291  \n",
      "\n",
      "Fold: 23  Epoch: 141  Training loss = 4.2818  Validation loss = 0.8288  \n",
      "\n",
      "Fold: 23  Epoch: 142  Training loss = 4.2814  Validation loss = 0.8285  \n",
      "\n",
      "Fold: 23  Epoch: 143  Training loss = 4.2810  Validation loss = 0.8283  \n",
      "\n",
      "Fold: 23  Epoch: 144  Training loss = 4.2807  Validation loss = 0.8279  \n",
      "\n",
      "Fold: 23  Epoch: 145  Training loss = 4.2802  Validation loss = 0.8275  \n",
      "\n",
      "Fold: 23  Epoch: 146  Training loss = 4.2798  Validation loss = 0.8273  \n",
      "\n",
      "Fold: 23  Epoch: 147  Training loss = 4.2795  Validation loss = 0.8270  \n",
      "\n",
      "Fold: 23  Epoch: 148  Training loss = 4.2791  Validation loss = 0.8266  \n",
      "\n",
      "Fold: 23  Epoch: 149  Training loss = 4.2787  Validation loss = 0.8263  \n",
      "\n",
      "Fold: 23  Epoch: 150  Training loss = 4.2784  Validation loss = 0.8261  \n",
      "\n",
      "Fold: 23  Epoch: 151  Training loss = 4.2781  Validation loss = 0.8258  \n",
      "\n",
      "Fold: 23  Epoch: 152  Training loss = 4.2777  Validation loss = 0.8255  \n",
      "\n",
      "Fold: 23  Epoch: 153  Training loss = 4.2772  Validation loss = 0.8251  \n",
      "\n",
      "Fold: 23  Epoch: 154  Training loss = 4.2768  Validation loss = 0.8248  \n",
      "\n",
      "Fold: 23  Epoch: 155  Training loss = 4.2764  Validation loss = 0.8245  \n",
      "\n",
      "Fold: 23  Epoch: 156  Training loss = 4.2761  Validation loss = 0.8243  \n",
      "\n",
      "Fold: 23  Epoch: 157  Training loss = 4.2757  Validation loss = 0.8240  \n",
      "\n",
      "Fold: 23  Epoch: 158  Training loss = 4.2752  Validation loss = 0.8236  \n",
      "\n",
      "Fold: 23  Epoch: 159  Training loss = 4.2750  Validation loss = 0.8233  \n",
      "\n",
      "Fold: 23  Epoch: 160  Training loss = 4.2745  Validation loss = 0.8230  \n",
      "\n",
      "Fold: 23  Epoch: 161  Training loss = 4.2742  Validation loss = 0.8227  \n",
      "\n",
      "Fold: 23  Epoch: 162  Training loss = 4.2738  Validation loss = 0.8224  \n",
      "\n",
      "Fold: 23  Epoch: 163  Training loss = 4.2733  Validation loss = 0.8221  \n",
      "\n",
      "Fold: 23  Epoch: 164  Training loss = 4.2730  Validation loss = 0.8219  \n",
      "\n",
      "Fold: 23  Epoch: 165  Training loss = 4.2727  Validation loss = 0.8216  \n",
      "\n",
      "Fold: 23  Epoch: 166  Training loss = 4.2722  Validation loss = 0.8212  \n",
      "\n",
      "Fold: 23  Epoch: 167  Training loss = 4.2718  Validation loss = 0.8209  \n",
      "\n",
      "Fold: 23  Epoch: 168  Training loss = 4.2714  Validation loss = 0.8206  \n",
      "\n",
      "Fold: 23  Epoch: 169  Training loss = 4.2711  Validation loss = 0.8203  \n",
      "\n",
      "Fold: 23  Epoch: 170  Training loss = 4.2708  Validation loss = 0.8201  \n",
      "\n",
      "Fold: 23  Epoch: 171  Training loss = 4.2704  Validation loss = 0.8197  \n",
      "\n",
      "Fold: 23  Epoch: 172  Training loss = 4.2699  Validation loss = 0.8193  \n",
      "\n",
      "Fold: 23  Epoch: 173  Training loss = 4.2694  Validation loss = 0.8190  \n",
      "\n",
      "Fold: 23  Epoch: 174  Training loss = 4.2690  Validation loss = 0.8187  \n",
      "\n",
      "Fold: 23  Epoch: 175  Training loss = 4.2686  Validation loss = 0.8183  \n",
      "\n",
      "Fold: 23  Epoch: 176  Training loss = 4.2684  Validation loss = 0.8180  \n",
      "\n",
      "Fold: 23  Epoch: 177  Training loss = 4.2680  Validation loss = 0.8177  \n",
      "\n",
      "Fold: 23  Epoch: 178  Training loss = 4.2676  Validation loss = 0.8175  \n",
      "\n",
      "Fold: 23  Epoch: 179  Training loss = 4.2673  Validation loss = 0.8171  \n",
      "\n",
      "Fold: 23  Epoch: 180  Training loss = 4.2669  Validation loss = 0.8168  \n",
      "\n",
      "Fold: 23  Epoch: 181  Training loss = 4.2665  Validation loss = 0.8164  \n",
      "\n",
      "Fold: 23  Epoch: 182  Training loss = 4.2660  Validation loss = 0.8161  \n",
      "\n",
      "Fold: 23  Epoch: 183  Training loss = 4.2657  Validation loss = 0.8158  \n",
      "\n",
      "Fold: 23  Epoch: 184  Training loss = 4.2653  Validation loss = 0.8156  \n",
      "\n",
      "Fold: 23  Epoch: 185  Training loss = 4.2651  Validation loss = 0.8153  \n",
      "\n",
      "Fold: 23  Epoch: 186  Training loss = 4.2647  Validation loss = 0.8150  \n",
      "\n",
      "Fold: 23  Epoch: 187  Training loss = 4.2643  Validation loss = 0.8149  \n",
      "\n",
      "Fold: 23  Epoch: 188  Training loss = 4.2640  Validation loss = 0.8146  \n",
      "\n",
      "Fold: 23  Epoch: 189  Training loss = 4.2635  Validation loss = 0.8142  \n",
      "\n",
      "Fold: 23  Epoch: 190  Training loss = 4.2631  Validation loss = 0.8139  \n",
      "\n",
      "Fold: 23  Epoch: 191  Training loss = 4.2626  Validation loss = 0.8135  \n",
      "\n",
      "Fold: 23  Epoch: 192  Training loss = 4.2622  Validation loss = 0.8132  \n",
      "\n",
      "Fold: 23  Epoch: 193  Training loss = 4.2618  Validation loss = 0.8129  \n",
      "\n",
      "Fold: 23  Epoch: 194  Training loss = 4.2615  Validation loss = 0.8125  \n",
      "\n",
      "Fold: 23  Epoch: 195  Training loss = 4.2612  Validation loss = 0.8123  \n",
      "\n",
      "Fold: 23  Epoch: 196  Training loss = 4.2608  Validation loss = 0.8120  \n",
      "\n",
      "Fold: 23  Epoch: 197  Training loss = 4.2604  Validation loss = 0.8118  \n",
      "\n",
      "Fold: 23  Epoch: 198  Training loss = 4.2602  Validation loss = 0.8115  \n",
      "\n",
      "Fold: 23  Epoch: 199  Training loss = 4.2599  Validation loss = 0.8113  \n",
      "\n",
      "Fold: 23  Epoch: 200  Training loss = 4.2596  Validation loss = 0.8111  \n",
      "\n",
      "Fold: 23  Epoch: 201  Training loss = 4.2593  Validation loss = 0.8109  \n",
      "\n",
      "Fold: 23  Epoch: 202  Training loss = 4.2589  Validation loss = 0.8105  \n",
      "\n",
      "Fold: 23  Epoch: 203  Training loss = 4.2586  Validation loss = 0.8103  \n",
      "\n",
      "Fold: 23  Epoch: 204  Training loss = 4.2582  Validation loss = 0.8100  \n",
      "\n",
      "Fold: 23  Epoch: 205  Training loss = 4.2579  Validation loss = 0.8097  \n",
      "\n",
      "Fold: 23  Epoch: 206  Training loss = 4.2575  Validation loss = 0.8094  \n",
      "\n",
      "Fold: 23  Epoch: 207  Training loss = 4.2571  Validation loss = 0.8091  \n",
      "\n",
      "Fold: 23  Epoch: 208  Training loss = 4.2568  Validation loss = 0.8088  \n",
      "\n",
      "Fold: 23  Epoch: 209  Training loss = 4.2564  Validation loss = 0.8086  \n",
      "\n",
      "Fold: 23  Epoch: 210  Training loss = 4.2560  Validation loss = 0.8083  \n",
      "\n",
      "Fold: 23  Epoch: 211  Training loss = 4.2557  Validation loss = 0.8080  \n",
      "\n",
      "Fold: 23  Epoch: 212  Training loss = 4.2554  Validation loss = 0.8078  \n",
      "\n",
      "Fold: 23  Epoch: 213  Training loss = 4.2549  Validation loss = 0.8075  \n",
      "\n",
      "Fold: 23  Epoch: 214  Training loss = 4.2545  Validation loss = 0.8072  \n",
      "\n",
      "Fold: 23  Epoch: 215  Training loss = 4.2541  Validation loss = 0.8068  \n",
      "\n",
      "Fold: 23  Epoch: 216  Training loss = 4.2538  Validation loss = 0.8065  \n",
      "\n",
      "Fold: 23  Epoch: 217  Training loss = 4.2534  Validation loss = 0.8062  \n",
      "\n",
      "Fold: 23  Epoch: 218  Training loss = 4.2529  Validation loss = 0.8059  \n",
      "\n",
      "Fold: 23  Epoch: 219  Training loss = 4.2525  Validation loss = 0.8056  \n",
      "\n",
      "Fold: 23  Epoch: 220  Training loss = 4.2521  Validation loss = 0.8053  \n",
      "\n",
      "Fold: 23  Epoch: 221  Training loss = 4.2517  Validation loss = 0.8050  \n",
      "\n",
      "Fold: 23  Epoch: 222  Training loss = 4.2514  Validation loss = 0.8048  \n",
      "\n",
      "Fold: 23  Epoch: 223  Training loss = 4.2511  Validation loss = 0.8046  \n",
      "\n",
      "Fold: 23  Epoch: 224  Training loss = 4.2507  Validation loss = 0.8043  \n",
      "\n",
      "Fold: 23  Epoch: 225  Training loss = 4.2503  Validation loss = 0.8040  \n",
      "\n",
      "Fold: 23  Epoch: 226  Training loss = 4.2499  Validation loss = 0.8037  \n",
      "\n",
      "Fold: 23  Epoch: 227  Training loss = 4.2496  Validation loss = 0.8035  \n",
      "\n",
      "Fold: 23  Epoch: 228  Training loss = 4.2492  Validation loss = 0.8032  \n",
      "\n",
      "Fold: 23  Epoch: 229  Training loss = 4.2489  Validation loss = 0.8030  \n",
      "\n",
      "Fold: 23  Epoch: 230  Training loss = 4.2485  Validation loss = 0.8028  \n",
      "\n",
      "Fold: 23  Epoch: 231  Training loss = 4.2482  Validation loss = 0.8025  \n",
      "\n",
      "Fold: 23  Epoch: 232  Training loss = 4.2479  Validation loss = 0.8023  \n",
      "\n",
      "Fold: 23  Epoch: 233  Training loss = 4.2476  Validation loss = 0.8020  \n",
      "\n",
      "Fold: 23  Epoch: 234  Training loss = 4.2471  Validation loss = 0.8017  \n",
      "\n",
      "Fold: 23  Epoch: 235  Training loss = 4.2467  Validation loss = 0.8013  \n",
      "\n",
      "Fold: 23  Epoch: 236  Training loss = 4.2463  Validation loss = 0.8010  \n",
      "\n",
      "Fold: 23  Epoch: 237  Training loss = 4.2459  Validation loss = 0.8007  \n",
      "\n",
      "Fold: 23  Epoch: 238  Training loss = 4.2454  Validation loss = 0.8003  \n",
      "\n",
      "Fold: 23  Epoch: 239  Training loss = 4.2450  Validation loss = 0.8000  \n",
      "\n",
      "Fold: 23  Epoch: 240  Training loss = 4.2447  Validation loss = 0.7997  \n",
      "\n",
      "Fold: 23  Epoch: 241  Training loss = 4.2443  Validation loss = 0.7994  \n",
      "\n",
      "Fold: 23  Epoch: 242  Training loss = 4.2439  Validation loss = 0.7991  \n",
      "\n",
      "Fold: 23  Epoch: 243  Training loss = 4.2434  Validation loss = 0.7988  \n",
      "\n",
      "Fold: 23  Epoch: 244  Training loss = 4.2431  Validation loss = 0.7985  \n",
      "\n",
      "Fold: 23  Epoch: 245  Training loss = 4.2427  Validation loss = 0.7983  \n",
      "\n",
      "Fold: 23  Epoch: 246  Training loss = 4.2424  Validation loss = 0.7980  \n",
      "\n",
      "Fold: 23  Epoch: 247  Training loss = 4.2422  Validation loss = 0.7978  \n",
      "\n",
      "Fold: 23  Epoch: 248  Training loss = 4.2418  Validation loss = 0.7976  \n",
      "\n",
      "Fold: 23  Epoch: 249  Training loss = 4.2413  Validation loss = 0.7972  \n",
      "\n",
      "Fold: 23  Epoch: 250  Training loss = 4.2410  Validation loss = 0.7969  \n",
      "\n",
      "Fold: 23  Epoch: 251  Training loss = 4.2407  Validation loss = 0.7967  \n",
      "\n",
      "Fold: 23  Epoch: 252  Training loss = 4.2402  Validation loss = 0.7964  \n",
      "\n",
      "Fold: 23  Epoch: 253  Training loss = 4.2400  Validation loss = 0.7962  \n",
      "\n",
      "Fold: 23  Epoch: 254  Training loss = 4.2396  Validation loss = 0.7960  \n",
      "\n",
      "Fold: 23  Epoch: 255  Training loss = 4.2393  Validation loss = 0.7957  \n",
      "\n",
      "Fold: 23  Epoch: 256  Training loss = 4.2389  Validation loss = 0.7955  \n",
      "\n",
      "Fold: 23  Epoch: 257  Training loss = 4.2385  Validation loss = 0.7952  \n",
      "\n",
      "Fold: 23  Epoch: 258  Training loss = 4.2383  Validation loss = 0.7949  \n",
      "\n",
      "Fold: 23  Epoch: 259  Training loss = 4.2379  Validation loss = 0.7947  \n",
      "\n",
      "Fold: 23  Epoch: 260  Training loss = 4.2377  Validation loss = 0.7945  \n",
      "\n",
      "Fold: 23  Epoch: 261  Training loss = 4.2373  Validation loss = 0.7943  \n",
      "\n",
      "Fold: 23  Epoch: 262  Training loss = 4.2369  Validation loss = 0.7940  \n",
      "\n",
      "Fold: 23  Epoch: 263  Training loss = 4.2365  Validation loss = 0.7938  \n",
      "\n",
      "Fold: 23  Epoch: 264  Training loss = 4.2362  Validation loss = 0.7935  \n",
      "\n",
      "Fold: 23  Epoch: 265  Training loss = 4.2358  Validation loss = 0.7931  \n",
      "\n",
      "Fold: 23  Epoch: 266  Training loss = 4.2353  Validation loss = 0.7928  \n",
      "\n",
      "Fold: 23  Epoch: 267  Training loss = 4.2350  Validation loss = 0.7927  \n",
      "\n",
      "Fold: 23  Epoch: 268  Training loss = 4.2346  Validation loss = 0.7924  \n",
      "\n",
      "Fold: 23  Epoch: 269  Training loss = 4.2342  Validation loss = 0.7921  \n",
      "\n",
      "Fold: 23  Epoch: 270  Training loss = 4.2337  Validation loss = 0.7917  \n",
      "\n",
      "Fold: 23  Epoch: 271  Training loss = 4.2335  Validation loss = 0.7915  \n",
      "\n",
      "Fold: 23  Epoch: 272  Training loss = 4.2332  Validation loss = 0.7913  \n",
      "\n",
      "Fold: 23  Epoch: 273  Training loss = 4.2328  Validation loss = 0.7911  \n",
      "\n",
      "Fold: 23  Epoch: 274  Training loss = 4.2325  Validation loss = 0.7908  \n",
      "\n",
      "Fold: 23  Epoch: 275  Training loss = 4.2321  Validation loss = 0.7904  \n",
      "\n",
      "Fold: 23  Epoch: 276  Training loss = 4.2319  Validation loss = 0.7902  \n",
      "\n",
      "Fold: 23  Epoch: 277  Training loss = 4.2315  Validation loss = 0.7899  \n",
      "\n",
      "Fold: 23  Epoch: 278  Training loss = 4.2311  Validation loss = 0.7896  \n",
      "\n",
      "Fold: 23  Epoch: 279  Training loss = 4.2309  Validation loss = 0.7894  \n",
      "\n",
      "Fold: 23  Epoch: 280  Training loss = 4.2304  Validation loss = 0.7891  \n",
      "\n",
      "Fold: 23  Epoch: 281  Training loss = 4.2300  Validation loss = 0.7888  \n",
      "\n",
      "Fold: 23  Epoch: 282  Training loss = 4.2296  Validation loss = 0.7886  \n",
      "\n",
      "Fold: 23  Epoch: 283  Training loss = 4.2293  Validation loss = 0.7884  \n",
      "\n",
      "Fold: 23  Epoch: 284  Training loss = 4.2290  Validation loss = 0.7881  \n",
      "\n",
      "Fold: 23  Epoch: 285  Training loss = 4.2287  Validation loss = 0.7878  \n",
      "\n",
      "Fold: 23  Epoch: 286  Training loss = 4.2283  Validation loss = 0.7875  \n",
      "\n",
      "Fold: 23  Epoch: 287  Training loss = 4.2279  Validation loss = 0.7872  \n",
      "\n",
      "Fold: 23  Epoch: 288  Training loss = 4.2275  Validation loss = 0.7870  \n",
      "\n",
      "Fold: 23  Epoch: 289  Training loss = 4.2272  Validation loss = 0.7868  \n",
      "\n",
      "Fold: 23  Epoch: 290  Training loss = 4.2268  Validation loss = 0.7865  \n",
      "\n",
      "Fold: 23  Epoch: 291  Training loss = 4.2265  Validation loss = 0.7863  \n",
      "\n",
      "Fold: 23  Epoch: 292  Training loss = 4.2262  Validation loss = 0.7861  \n",
      "\n",
      "Fold: 23  Epoch: 293  Training loss = 4.2259  Validation loss = 0.7860  \n",
      "\n",
      "Fold: 23  Epoch: 294  Training loss = 4.2256  Validation loss = 0.7857  \n",
      "\n",
      "Fold: 23  Epoch: 295  Training loss = 4.2253  Validation loss = 0.7855  \n",
      "\n",
      "Fold: 23  Epoch: 296  Training loss = 4.2248  Validation loss = 0.7851  \n",
      "\n",
      "Fold: 23  Epoch: 297  Training loss = 4.2245  Validation loss = 0.7849  \n",
      "\n",
      "Fold: 23  Epoch: 298  Training loss = 4.2241  Validation loss = 0.7847  \n",
      "\n",
      "Fold: 23  Epoch: 299  Training loss = 4.2238  Validation loss = 0.7845  \n",
      "\n",
      "Fold: 23  Epoch: 300  Training loss = 4.2236  Validation loss = 0.7843  \n",
      "\n",
      "Fold: 23  Epoch: 301  Training loss = 4.2233  Validation loss = 0.7841  \n",
      "\n",
      "Fold: 23  Epoch: 302  Training loss = 4.2230  Validation loss = 0.7839  \n",
      "\n",
      "Fold: 23  Epoch: 303  Training loss = 4.2226  Validation loss = 0.7837  \n",
      "\n",
      "Fold: 23  Epoch: 304  Training loss = 4.2223  Validation loss = 0.7835  \n",
      "\n",
      "Fold: 23  Epoch: 305  Training loss = 4.2220  Validation loss = 0.7833  \n",
      "\n",
      "Fold: 23  Epoch: 306  Training loss = 4.2215  Validation loss = 0.7830  \n",
      "\n",
      "Fold: 23  Epoch: 307  Training loss = 4.2212  Validation loss = 0.7826  \n",
      "\n",
      "Fold: 23  Epoch: 308  Training loss = 4.2209  Validation loss = 0.7824  \n",
      "\n",
      "Fold: 23  Epoch: 309  Training loss = 4.2204  Validation loss = 0.7822  \n",
      "\n",
      "Fold: 23  Epoch: 310  Training loss = 4.2201  Validation loss = 0.7819  \n",
      "\n",
      "Fold: 23  Epoch: 311  Training loss = 4.2197  Validation loss = 0.7817  \n",
      "\n",
      "Fold: 23  Epoch: 312  Training loss = 4.2193  Validation loss = 0.7814  \n",
      "\n",
      "Fold: 23  Epoch: 313  Training loss = 4.2188  Validation loss = 0.7811  \n",
      "\n",
      "Fold: 23  Epoch: 314  Training loss = 4.2186  Validation loss = 0.7810  \n",
      "\n",
      "Fold: 23  Epoch: 315  Training loss = 4.2182  Validation loss = 0.7808  \n",
      "\n",
      "Fold: 23  Epoch: 316  Training loss = 4.2178  Validation loss = 0.7805  \n",
      "\n",
      "Fold: 23  Epoch: 317  Training loss = 4.2174  Validation loss = 0.7803  \n",
      "\n",
      "Fold: 23  Epoch: 318  Training loss = 4.2171  Validation loss = 0.7801  \n",
      "\n",
      "Fold: 23  Epoch: 319  Training loss = 4.2170  Validation loss = 0.7800  \n",
      "\n",
      "Fold: 23  Epoch: 320  Training loss = 4.2166  Validation loss = 0.7799  \n",
      "\n",
      "Fold: 23  Epoch: 321  Training loss = 4.2162  Validation loss = 0.7796  \n",
      "\n",
      "Fold: 23  Epoch: 322  Training loss = 4.2158  Validation loss = 0.7792  \n",
      "\n",
      "Fold: 23  Epoch: 323  Training loss = 4.2155  Validation loss = 0.7790  \n",
      "\n",
      "Fold: 23  Epoch: 324  Training loss = 4.2152  Validation loss = 0.7788  \n",
      "\n",
      "Fold: 23  Epoch: 325  Training loss = 4.2149  Validation loss = 0.7786  \n",
      "\n",
      "Fold: 23  Epoch: 326  Training loss = 4.2145  Validation loss = 0.7784  \n",
      "\n",
      "Fold: 23  Epoch: 327  Training loss = 4.2142  Validation loss = 0.7782  \n",
      "\n",
      "Fold: 23  Epoch: 328  Training loss = 4.2138  Validation loss = 0.7780  \n",
      "\n",
      "Fold: 23  Epoch: 329  Training loss = 4.2136  Validation loss = 0.7779  \n",
      "\n",
      "Fold: 23  Epoch: 330  Training loss = 4.2133  Validation loss = 0.7777  \n",
      "\n",
      "Fold: 23  Epoch: 331  Training loss = 4.2129  Validation loss = 0.7774  \n",
      "\n",
      "Fold: 23  Epoch: 332  Training loss = 4.2126  Validation loss = 0.7772  \n",
      "\n",
      "Fold: 23  Epoch: 333  Training loss = 4.2122  Validation loss = 0.7770  \n",
      "\n",
      "Fold: 23  Epoch: 334  Training loss = 4.2119  Validation loss = 0.7768  \n",
      "\n",
      "Fold: 23  Epoch: 335  Training loss = 4.2115  Validation loss = 0.7766  \n",
      "\n",
      "Fold: 23  Epoch: 336  Training loss = 4.2114  Validation loss = 0.7764  \n",
      "\n",
      "Fold: 23  Epoch: 337  Training loss = 4.2110  Validation loss = 0.7761  \n",
      "\n",
      "Fold: 23  Epoch: 338  Training loss = 4.2107  Validation loss = 0.7760  \n",
      "\n",
      "Fold: 23  Epoch: 339  Training loss = 4.2105  Validation loss = 0.7758  \n",
      "\n",
      "Fold: 23  Epoch: 340  Training loss = 4.2102  Validation loss = 0.7754  \n",
      "\n",
      "Fold: 23  Epoch: 341  Training loss = 4.2099  Validation loss = 0.7752  \n",
      "\n",
      "Fold: 23  Epoch: 342  Training loss = 4.2094  Validation loss = 0.7749  \n",
      "\n",
      "Fold: 23  Epoch: 343  Training loss = 4.2090  Validation loss = 0.7746  \n",
      "\n",
      "Fold: 23  Epoch: 344  Training loss = 4.2086  Validation loss = 0.7745  \n",
      "\n",
      "Fold: 23  Epoch: 345  Training loss = 4.2083  Validation loss = 0.7742  \n",
      "\n",
      "Fold: 23  Epoch: 346  Training loss = 4.2079  Validation loss = 0.7740  \n",
      "\n",
      "Fold: 23  Epoch: 347  Training loss = 4.2075  Validation loss = 0.7738  \n",
      "\n",
      "Fold: 23  Epoch: 348  Training loss = 4.2072  Validation loss = 0.7736  \n",
      "\n",
      "Fold: 23  Epoch: 349  Training loss = 4.2069  Validation loss = 0.7733  \n",
      "\n",
      "Fold: 23  Epoch: 350  Training loss = 4.2066  Validation loss = 0.7731  \n",
      "\n",
      "Fold: 23  Epoch: 351  Training loss = 4.2062  Validation loss = 0.7729  \n",
      "\n",
      "Fold: 23  Epoch: 352  Training loss = 4.2058  Validation loss = 0.7726  \n",
      "\n",
      "Fold: 23  Epoch: 353  Training loss = 4.2055  Validation loss = 0.7724  \n",
      "\n",
      "Fold: 23  Epoch: 354  Training loss = 4.2050  Validation loss = 0.7721  \n",
      "\n",
      "Fold: 23  Epoch: 355  Training loss = 4.2047  Validation loss = 0.7719  \n",
      "\n",
      "Fold: 23  Epoch: 356  Training loss = 4.2043  Validation loss = 0.7716  \n",
      "\n",
      "Fold: 23  Epoch: 357  Training loss = 4.2039  Validation loss = 0.7713  \n",
      "\n",
      "Fold: 23  Epoch: 358  Training loss = 4.2035  Validation loss = 0.7712  \n",
      "\n",
      "Fold: 23  Epoch: 359  Training loss = 4.2031  Validation loss = 0.7709  \n",
      "\n",
      "Fold: 23  Epoch: 360  Training loss = 4.2028  Validation loss = 0.7706  \n",
      "\n",
      "Fold: 23  Epoch: 361  Training loss = 4.2025  Validation loss = 0.7705  \n",
      "\n",
      "Fold: 23  Epoch: 362  Training loss = 4.2022  Validation loss = 0.7702  \n",
      "\n",
      "Fold: 23  Epoch: 363  Training loss = 4.2018  Validation loss = 0.7699  \n",
      "\n",
      "Fold: 23  Epoch: 364  Training loss = 4.2015  Validation loss = 0.7698  \n",
      "\n",
      "Fold: 23  Epoch: 365  Training loss = 4.2012  Validation loss = 0.7696  \n",
      "\n",
      "Fold: 23  Epoch: 366  Training loss = 4.2008  Validation loss = 0.7694  \n",
      "\n",
      "Fold: 23  Epoch: 367  Training loss = 4.2006  Validation loss = 0.7692  \n",
      "\n",
      "Fold: 23  Epoch: 368  Training loss = 4.2003  Validation loss = 0.7690  \n",
      "\n",
      "Fold: 23  Epoch: 369  Training loss = 4.2001  Validation loss = 0.7688  \n",
      "\n",
      "Fold: 23  Epoch: 370  Training loss = 4.1997  Validation loss = 0.7686  \n",
      "\n",
      "Fold: 23  Epoch: 371  Training loss = 4.1994  Validation loss = 0.7683  \n",
      "\n",
      "Fold: 23  Epoch: 372  Training loss = 4.1990  Validation loss = 0.7680  \n",
      "\n",
      "Fold: 23  Epoch: 373  Training loss = 4.1986  Validation loss = 0.7677  \n",
      "\n",
      "Fold: 23  Epoch: 374  Training loss = 4.1983  Validation loss = 0.7675  \n",
      "\n",
      "Fold: 23  Epoch: 375  Training loss = 4.1980  Validation loss = 0.7673  \n",
      "\n",
      "Fold: 23  Epoch: 376  Training loss = 4.1977  Validation loss = 0.7671  \n",
      "\n",
      "Fold: 23  Epoch: 377  Training loss = 4.1973  Validation loss = 0.7669  \n",
      "\n",
      "Fold: 23  Epoch: 378  Training loss = 4.1968  Validation loss = 0.7666  \n",
      "\n",
      "Fold: 23  Epoch: 379  Training loss = 4.1965  Validation loss = 0.7664  \n",
      "\n",
      "Fold: 23  Epoch: 380  Training loss = 4.1962  Validation loss = 0.7663  \n",
      "\n",
      "Fold: 23  Epoch: 381  Training loss = 4.1958  Validation loss = 0.7660  \n",
      "\n",
      "Fold: 23  Epoch: 382  Training loss = 4.1955  Validation loss = 0.7659  \n",
      "\n",
      "Fold: 23  Epoch: 383  Training loss = 4.1951  Validation loss = 0.7656  \n",
      "\n",
      "Fold: 23  Epoch: 384  Training loss = 4.1945  Validation loss = 0.7653  \n",
      "\n",
      "Fold: 23  Epoch: 385  Training loss = 4.1942  Validation loss = 0.7651  \n",
      "\n",
      "Fold: 23  Epoch: 386  Training loss = 4.1938  Validation loss = 0.7650  \n",
      "\n",
      "Fold: 23  Epoch: 387  Training loss = 4.1935  Validation loss = 0.7647  \n",
      "\n",
      "Fold: 23  Epoch: 388  Training loss = 4.1932  Validation loss = 0.7645  \n",
      "\n",
      "Fold: 23  Epoch: 389  Training loss = 4.1928  Validation loss = 0.7643  \n",
      "\n",
      "Fold: 23  Epoch: 390  Training loss = 4.1924  Validation loss = 0.7641  \n",
      "\n",
      "Fold: 23  Epoch: 391  Training loss = 4.1921  Validation loss = 0.7639  \n",
      "\n",
      "Fold: 23  Epoch: 392  Training loss = 4.1918  Validation loss = 0.7638  \n",
      "\n",
      "Fold: 23  Epoch: 393  Training loss = 4.1914  Validation loss = 0.7635  \n",
      "\n",
      "Fold: 23  Epoch: 394  Training loss = 4.1910  Validation loss = 0.7633  \n",
      "\n",
      "Fold: 23  Epoch: 395  Training loss = 4.1906  Validation loss = 0.7630  \n",
      "\n",
      "Fold: 23  Epoch: 396  Training loss = 4.1902  Validation loss = 0.7627  \n",
      "\n",
      "Fold: 23  Epoch: 397  Training loss = 4.1898  Validation loss = 0.7625  \n",
      "\n",
      "Fold: 23  Epoch: 398  Training loss = 4.1895  Validation loss = 0.7623  \n",
      "\n",
      "Fold: 23  Epoch: 399  Training loss = 4.1891  Validation loss = 0.7621  \n",
      "\n",
      "Fold: 23  Epoch: 400  Training loss = 4.1888  Validation loss = 0.7618  \n",
      "\n",
      "Fold: 23  Epoch: 401  Training loss = 4.1885  Validation loss = 0.7616  \n",
      "\n",
      "Fold: 23  Epoch: 402  Training loss = 4.1883  Validation loss = 0.7614  \n",
      "\n",
      "Fold: 23  Epoch: 403  Training loss = 4.1880  Validation loss = 0.7613  \n",
      "\n",
      "Fold: 23  Epoch: 404  Training loss = 4.1876  Validation loss = 0.7609  \n",
      "\n",
      "Fold: 23  Epoch: 405  Training loss = 4.1872  Validation loss = 0.7607  \n",
      "\n",
      "Fold: 23  Epoch: 406  Training loss = 4.1869  Validation loss = 0.7605  \n",
      "\n",
      "Fold: 23  Epoch: 407  Training loss = 4.1865  Validation loss = 0.7603  \n",
      "\n",
      "Fold: 23  Epoch: 408  Training loss = 4.1862  Validation loss = 0.7601  \n",
      "\n",
      "Fold: 23  Epoch: 409  Training loss = 4.1858  Validation loss = 0.7598  \n",
      "\n",
      "Fold: 23  Epoch: 410  Training loss = 4.1855  Validation loss = 0.7595  \n",
      "\n",
      "Fold: 23  Epoch: 411  Training loss = 4.1851  Validation loss = 0.7593  \n",
      "\n",
      "Fold: 23  Epoch: 412  Training loss = 4.1846  Validation loss = 0.7590  \n",
      "\n",
      "Fold: 23  Epoch: 413  Training loss = 4.1843  Validation loss = 0.7587  \n",
      "\n",
      "Fold: 23  Epoch: 414  Training loss = 4.1838  Validation loss = 0.7585  \n",
      "\n",
      "Fold: 23  Epoch: 415  Training loss = 4.1833  Validation loss = 0.7583  \n",
      "\n",
      "Fold: 23  Epoch: 416  Training loss = 4.1830  Validation loss = 0.7580  \n",
      "\n",
      "Fold: 23  Epoch: 417  Training loss = 4.1827  Validation loss = 0.7579  \n",
      "\n",
      "Fold: 23  Epoch: 418  Training loss = 4.1824  Validation loss = 0.7578  \n",
      "\n",
      "Fold: 23  Epoch: 419  Training loss = 4.1821  Validation loss = 0.7576  \n",
      "\n",
      "Fold: 23  Epoch: 420  Training loss = 4.1817  Validation loss = 0.7574  \n",
      "\n",
      "Fold: 23  Epoch: 421  Training loss = 4.1814  Validation loss = 0.7572  \n",
      "\n",
      "Fold: 23  Epoch: 422  Training loss = 4.1811  Validation loss = 0.7570  \n",
      "\n",
      "Fold: 23  Epoch: 423  Training loss = 4.1809  Validation loss = 0.7568  \n",
      "\n",
      "Fold: 23  Epoch: 424  Training loss = 4.1805  Validation loss = 0.7566  \n",
      "\n",
      "Fold: 23  Epoch: 425  Training loss = 4.1802  Validation loss = 0.7564  \n",
      "\n",
      "Fold: 23  Epoch: 426  Training loss = 4.1798  Validation loss = 0.7562  \n",
      "\n",
      "Fold: 23  Epoch: 427  Training loss = 4.1795  Validation loss = 0.7561  \n",
      "\n",
      "Fold: 23  Epoch: 428  Training loss = 4.1792  Validation loss = 0.7559  \n",
      "\n",
      "Fold: 23  Epoch: 429  Training loss = 4.1787  Validation loss = 0.7557  \n",
      "\n",
      "Fold: 23  Epoch: 430  Training loss = 4.1784  Validation loss = 0.7555  \n",
      "\n",
      "Fold: 23  Epoch: 431  Training loss = 4.1781  Validation loss = 0.7552  \n",
      "\n",
      "Fold: 23  Epoch: 432  Training loss = 4.1779  Validation loss = 0.7552  \n",
      "\n",
      "Fold: 23  Epoch: 433  Training loss = 4.1775  Validation loss = 0.7550  \n",
      "\n",
      "Fold: 23  Epoch: 434  Training loss = 4.1773  Validation loss = 0.7549  \n",
      "\n",
      "Fold: 23  Epoch: 435  Training loss = 4.1769  Validation loss = 0.7547  \n",
      "\n",
      "Fold: 23  Epoch: 436  Training loss = 4.1766  Validation loss = 0.7545  \n",
      "\n",
      "Fold: 23  Epoch: 437  Training loss = 4.1763  Validation loss = 0.7543  \n",
      "\n",
      "Fold: 23  Epoch: 438  Training loss = 4.1760  Validation loss = 0.7540  \n",
      "\n",
      "Fold: 23  Epoch: 439  Training loss = 4.1755  Validation loss = 0.7538  \n",
      "\n",
      "Fold: 23  Epoch: 440  Training loss = 4.1751  Validation loss = 0.7535  \n",
      "\n",
      "Fold: 23  Epoch: 441  Training loss = 4.1747  Validation loss = 0.7533  \n",
      "\n",
      "Fold: 23  Epoch: 442  Training loss = 4.1745  Validation loss = 0.7532  \n",
      "\n",
      "Fold: 23  Epoch: 443  Training loss = 4.1741  Validation loss = 0.7531  \n",
      "\n",
      "Fold: 23  Epoch: 444  Training loss = 4.1739  Validation loss = 0.7530  \n",
      "\n",
      "Fold: 23  Epoch: 445  Training loss = 4.1735  Validation loss = 0.7528  \n",
      "\n",
      "Fold: 23  Epoch: 446  Training loss = 4.1732  Validation loss = 0.7527  \n",
      "\n",
      "Fold: 23  Epoch: 447  Training loss = 4.1728  Validation loss = 0.7525  \n",
      "\n",
      "Fold: 23  Epoch: 448  Training loss = 4.1725  Validation loss = 0.7523  \n",
      "\n",
      "Fold: 23  Epoch: 449  Training loss = 4.1721  Validation loss = 0.7522  \n",
      "\n",
      "Fold: 23  Epoch: 450  Training loss = 4.1718  Validation loss = 0.7521  \n",
      "\n",
      "Fold: 23  Epoch: 451  Training loss = 4.1715  Validation loss = 0.7518  \n",
      "\n",
      "Fold: 23  Epoch: 452  Training loss = 4.1712  Validation loss = 0.7518  \n",
      "\n",
      "Fold: 23  Epoch: 453  Training loss = 4.1709  Validation loss = 0.7515  \n",
      "\n",
      "Fold: 23  Epoch: 454  Training loss = 4.1706  Validation loss = 0.7514  \n",
      "\n",
      "Fold: 23  Epoch: 455  Training loss = 4.1703  Validation loss = 0.7513  \n",
      "\n",
      "Fold: 23  Epoch: 456  Training loss = 4.1700  Validation loss = 0.7511  \n",
      "\n",
      "Fold: 23  Epoch: 457  Training loss = 4.1696  Validation loss = 0.7509  \n",
      "\n",
      "Fold: 23  Epoch: 458  Training loss = 4.1693  Validation loss = 0.7508  \n",
      "\n",
      "Fold: 23  Epoch: 459  Training loss = 4.1689  Validation loss = 0.7506  \n",
      "\n",
      "Fold: 23  Epoch: 460  Training loss = 4.1685  Validation loss = 0.7504  \n",
      "\n",
      "Fold: 23  Epoch: 461  Training loss = 4.1682  Validation loss = 0.7502  \n",
      "\n",
      "Fold: 23  Epoch: 462  Training loss = 4.1678  Validation loss = 0.7501  \n",
      "\n",
      "Fold: 23  Epoch: 463  Training loss = 4.1675  Validation loss = 0.7499  \n",
      "\n",
      "Fold: 23  Epoch: 464  Training loss = 4.1672  Validation loss = 0.7496  \n",
      "\n",
      "Fold: 23  Epoch: 465  Training loss = 4.1669  Validation loss = 0.7494  \n",
      "\n",
      "Fold: 23  Epoch: 466  Training loss = 4.1665  Validation loss = 0.7492  \n",
      "\n",
      "Fold: 23  Epoch: 467  Training loss = 4.1661  Validation loss = 0.7490  \n",
      "\n",
      "Fold: 23  Epoch: 468  Training loss = 4.1657  Validation loss = 0.7488  \n",
      "\n",
      "Fold: 23  Epoch: 469  Training loss = 4.1653  Validation loss = 0.7486  \n",
      "\n",
      "Fold: 23  Epoch: 470  Training loss = 4.1651  Validation loss = 0.7484  \n",
      "\n",
      "Fold: 23  Epoch: 471  Training loss = 4.1647  Validation loss = 0.7482  \n",
      "\n",
      "Fold: 23  Epoch: 472  Training loss = 4.1644  Validation loss = 0.7481  \n",
      "\n",
      "Fold: 23  Epoch: 473  Training loss = 4.1640  Validation loss = 0.7478  \n",
      "\n",
      "Fold: 23  Epoch: 474  Training loss = 4.1635  Validation loss = 0.7476  \n",
      "\n",
      "Fold: 23  Epoch: 475  Training loss = 4.1634  Validation loss = 0.7476  \n",
      "\n",
      "Fold: 23  Epoch: 476  Training loss = 4.1632  Validation loss = 0.7474  \n",
      "\n",
      "Fold: 23  Epoch: 477  Training loss = 4.1628  Validation loss = 0.7472  \n",
      "\n",
      "Fold: 23  Epoch: 478  Training loss = 4.1624  Validation loss = 0.7470  \n",
      "\n",
      "Fold: 23  Epoch: 479  Training loss = 4.1621  Validation loss = 0.7469  \n",
      "\n",
      "Fold: 23  Epoch: 480  Training loss = 4.1618  Validation loss = 0.7468  \n",
      "\n",
      "Fold: 23  Epoch: 481  Training loss = 4.1614  Validation loss = 0.7466  \n",
      "\n",
      "Fold: 23  Epoch: 482  Training loss = 4.1611  Validation loss = 0.7464  \n",
      "\n",
      "Fold: 23  Epoch: 483  Training loss = 4.1608  Validation loss = 0.7462  \n",
      "\n",
      "Fold: 23  Epoch: 484  Training loss = 4.1605  Validation loss = 0.7460  \n",
      "\n",
      "Fold: 23  Epoch: 485  Training loss = 4.1601  Validation loss = 0.7459  \n",
      "\n",
      "Fold: 23  Epoch: 486  Training loss = 4.1598  Validation loss = 0.7458  \n",
      "\n",
      "Fold: 23  Epoch: 487  Training loss = 4.1596  Validation loss = 0.7455  \n",
      "\n",
      "Fold: 23  Epoch: 488  Training loss = 4.1593  Validation loss = 0.7454  \n",
      "\n",
      "Fold: 23  Epoch: 489  Training loss = 4.1590  Validation loss = 0.7452  \n",
      "\n",
      "Fold: 23  Epoch: 490  Training loss = 4.1586  Validation loss = 0.7451  \n",
      "\n",
      "Fold: 23  Epoch: 491  Training loss = 4.1583  Validation loss = 0.7450  \n",
      "\n",
      "Fold: 23  Epoch: 492  Training loss = 4.1579  Validation loss = 0.7447  \n",
      "\n",
      "Fold: 23  Epoch: 493  Training loss = 4.1575  Validation loss = 0.7446  \n",
      "\n",
      "Fold: 23  Epoch: 494  Training loss = 4.1572  Validation loss = 0.7443  \n",
      "\n",
      "Fold: 23  Epoch: 495  Training loss = 4.1568  Validation loss = 0.7441  \n",
      "\n",
      "Fold: 23  Epoch: 496  Training loss = 4.1565  Validation loss = 0.7440  \n",
      "\n",
      "Fold: 23  Epoch: 497  Training loss = 4.1562  Validation loss = 0.7438  \n",
      "\n",
      "Fold: 23  Epoch: 498  Training loss = 4.1559  Validation loss = 0.7436  \n",
      "\n",
      "Fold: 23  Epoch: 499  Training loss = 4.1555  Validation loss = 0.7434  \n",
      "\n",
      "Fold: 23  Epoch: 500  Training loss = 4.1553  Validation loss = 0.7432  \n",
      "\n",
      "Check model:  Fold: 23  Optimal epoch: 500  \n",
      "\n",
      "Fold: 24  Epoch: 1  Training loss = 4.1380  Validation loss = 1.6865  \n",
      "\n",
      "Fold: 24  Epoch: 2  Training loss = 4.1377  Validation loss = 1.6863  \n",
      "\n",
      "Fold: 24  Epoch: 3  Training loss = 4.1373  Validation loss = 1.6859  \n",
      "\n",
      "Fold: 24  Epoch: 4  Training loss = 4.1370  Validation loss = 1.6858  \n",
      "\n",
      "Fold: 24  Epoch: 5  Training loss = 4.1366  Validation loss = 1.6854  \n",
      "\n",
      "Fold: 24  Epoch: 6  Training loss = 4.1362  Validation loss = 1.6851  \n",
      "\n",
      "Fold: 24  Epoch: 7  Training loss = 4.1359  Validation loss = 1.6848  \n",
      "\n",
      "Fold: 24  Epoch: 8  Training loss = 4.1355  Validation loss = 1.6845  \n",
      "\n",
      "Fold: 24  Epoch: 9  Training loss = 4.1352  Validation loss = 1.6844  \n",
      "\n",
      "Fold: 24  Epoch: 10  Training loss = 4.1348  Validation loss = 1.6840  \n",
      "\n",
      "Fold: 24  Epoch: 11  Training loss = 4.1343  Validation loss = 1.6836  \n",
      "\n",
      "Fold: 24  Epoch: 12  Training loss = 4.1338  Validation loss = 1.6833  \n",
      "\n",
      "Fold: 24  Epoch: 13  Training loss = 4.1335  Validation loss = 1.6831  \n",
      "\n",
      "Fold: 24  Epoch: 14  Training loss = 4.1331  Validation loss = 1.6827  \n",
      "\n",
      "Fold: 24  Epoch: 15  Training loss = 4.1328  Validation loss = 1.6825  \n",
      "\n",
      "Fold: 24  Epoch: 16  Training loss = 4.1326  Validation loss = 1.6824  \n",
      "\n",
      "Fold: 24  Epoch: 17  Training loss = 4.1323  Validation loss = 1.6821  \n",
      "\n",
      "Fold: 24  Epoch: 18  Training loss = 4.1319  Validation loss = 1.6818  \n",
      "\n",
      "Fold: 24  Epoch: 19  Training loss = 4.1315  Validation loss = 1.6815  \n",
      "\n",
      "Fold: 24  Epoch: 20  Training loss = 4.1310  Validation loss = 1.6811  \n",
      "\n",
      "Fold: 24  Epoch: 21  Training loss = 4.1307  Validation loss = 1.6809  \n",
      "\n",
      "Fold: 24  Epoch: 22  Training loss = 4.1303  Validation loss = 1.6806  \n",
      "\n",
      "Fold: 24  Epoch: 23  Training loss = 4.1300  Validation loss = 1.6803  \n",
      "\n",
      "Fold: 24  Epoch: 24  Training loss = 4.1296  Validation loss = 1.6801  \n",
      "\n",
      "Fold: 24  Epoch: 25  Training loss = 4.1292  Validation loss = 1.6798  \n",
      "\n",
      "Fold: 24  Epoch: 26  Training loss = 4.1288  Validation loss = 1.6795  \n",
      "\n",
      "Fold: 24  Epoch: 27  Training loss = 4.1285  Validation loss = 1.6792  \n",
      "\n",
      "Fold: 24  Epoch: 28  Training loss = 4.1280  Validation loss = 1.6790  \n",
      "\n",
      "Fold: 24  Epoch: 29  Training loss = 4.1276  Validation loss = 1.6786  \n",
      "\n",
      "Fold: 24  Epoch: 30  Training loss = 4.1273  Validation loss = 1.6784  \n",
      "\n",
      "Fold: 24  Epoch: 31  Training loss = 4.1269  Validation loss = 1.6781  \n",
      "\n",
      "Fold: 24  Epoch: 32  Training loss = 4.1265  Validation loss = 1.6777  \n",
      "\n",
      "Fold: 24  Epoch: 33  Training loss = 4.1262  Validation loss = 1.6774  \n",
      "\n",
      "Fold: 24  Epoch: 34  Training loss = 4.1259  Validation loss = 1.6773  \n",
      "\n",
      "Fold: 24  Epoch: 35  Training loss = 4.1255  Validation loss = 1.6769  \n",
      "\n",
      "Fold: 24  Epoch: 36  Training loss = 4.1251  Validation loss = 1.6766  \n",
      "\n",
      "Fold: 24  Epoch: 37  Training loss = 4.1247  Validation loss = 1.6762  \n",
      "\n",
      "Fold: 24  Epoch: 38  Training loss = 4.1243  Validation loss = 1.6760  \n",
      "\n",
      "Fold: 24  Epoch: 39  Training loss = 4.1240  Validation loss = 1.6757  \n",
      "\n",
      "Fold: 24  Epoch: 40  Training loss = 4.1237  Validation loss = 1.6755  \n",
      "\n",
      "Fold: 24  Epoch: 41  Training loss = 4.1234  Validation loss = 1.6754  \n",
      "\n",
      "Fold: 24  Epoch: 42  Training loss = 4.1231  Validation loss = 1.6751  \n",
      "\n",
      "Fold: 24  Epoch: 43  Training loss = 4.1227  Validation loss = 1.6747  \n",
      "\n",
      "Fold: 24  Epoch: 44  Training loss = 4.1223  Validation loss = 1.6745  \n",
      "\n",
      "Fold: 24  Epoch: 45  Training loss = 4.1220  Validation loss = 1.6744  \n",
      "\n",
      "Fold: 24  Epoch: 46  Training loss = 4.1217  Validation loss = 1.6743  \n",
      "\n",
      "Fold: 24  Epoch: 47  Training loss = 4.1213  Validation loss = 1.6740  \n",
      "\n",
      "Fold: 24  Epoch: 48  Training loss = 4.1210  Validation loss = 1.6737  \n",
      "\n",
      "Fold: 24  Epoch: 49  Training loss = 4.1207  Validation loss = 1.6734  \n",
      "\n",
      "Fold: 24  Epoch: 50  Training loss = 4.1204  Validation loss = 1.6733  \n",
      "\n",
      "Fold: 24  Epoch: 51  Training loss = 4.1200  Validation loss = 1.6730  \n",
      "\n",
      "Fold: 24  Epoch: 52  Training loss = 4.1197  Validation loss = 1.6727  \n",
      "\n",
      "Fold: 24  Epoch: 53  Training loss = 4.1194  Validation loss = 1.6725  \n",
      "\n",
      "Fold: 24  Epoch: 54  Training loss = 4.1190  Validation loss = 1.6721  \n",
      "\n",
      "Fold: 24  Epoch: 55  Training loss = 4.1188  Validation loss = 1.6719  \n",
      "\n",
      "Fold: 24  Epoch: 56  Training loss = 4.1184  Validation loss = 1.6716  \n",
      "\n",
      "Fold: 24  Epoch: 57  Training loss = 4.1180  Validation loss = 1.6714  \n",
      "\n",
      "Fold: 24  Epoch: 58  Training loss = 4.1177  Validation loss = 1.6712  \n",
      "\n",
      "Fold: 24  Epoch: 59  Training loss = 4.1174  Validation loss = 1.6710  \n",
      "\n",
      "Fold: 24  Epoch: 60  Training loss = 4.1170  Validation loss = 1.6706  \n",
      "\n",
      "Fold: 24  Epoch: 61  Training loss = 4.1166  Validation loss = 1.6704  \n",
      "\n",
      "Fold: 24  Epoch: 62  Training loss = 4.1163  Validation loss = 1.6701  \n",
      "\n",
      "Fold: 24  Epoch: 63  Training loss = 4.1159  Validation loss = 1.6698  \n",
      "\n",
      "Fold: 24  Epoch: 64  Training loss = 4.1157  Validation loss = 1.6697  \n",
      "\n",
      "Fold: 24  Epoch: 65  Training loss = 4.1154  Validation loss = 1.6694  \n",
      "\n",
      "Fold: 24  Epoch: 66  Training loss = 4.1150  Validation loss = 1.6690  \n",
      "\n",
      "Fold: 24  Epoch: 67  Training loss = 4.1146  Validation loss = 1.6686  \n",
      "\n",
      "Fold: 24  Epoch: 68  Training loss = 4.1142  Validation loss = 1.6683  \n",
      "\n",
      "Fold: 24  Epoch: 69  Training loss = 4.1138  Validation loss = 1.6680  \n",
      "\n",
      "Fold: 24  Epoch: 70  Training loss = 4.1135  Validation loss = 1.6678  \n",
      "\n",
      "Fold: 24  Epoch: 71  Training loss = 4.1131  Validation loss = 1.6675  \n",
      "\n",
      "Fold: 24  Epoch: 72  Training loss = 4.1127  Validation loss = 1.6672  \n",
      "\n",
      "Fold: 24  Epoch: 73  Training loss = 4.1124  Validation loss = 1.6670  \n",
      "\n",
      "Fold: 24  Epoch: 74  Training loss = 4.1122  Validation loss = 1.6667  \n",
      "\n",
      "Fold: 24  Epoch: 75  Training loss = 4.1117  Validation loss = 1.6664  \n",
      "\n",
      "Fold: 24  Epoch: 76  Training loss = 4.1114  Validation loss = 1.6662  \n",
      "\n",
      "Fold: 24  Epoch: 77  Training loss = 4.1111  Validation loss = 1.6660  \n",
      "\n",
      "Fold: 24  Epoch: 78  Training loss = 4.1108  Validation loss = 1.6658  \n",
      "\n",
      "Fold: 24  Epoch: 79  Training loss = 4.1103  Validation loss = 1.6654  \n",
      "\n",
      "Fold: 24  Epoch: 80  Training loss = 4.1101  Validation loss = 1.6652  \n",
      "\n",
      "Fold: 24  Epoch: 81  Training loss = 4.1097  Validation loss = 1.6648  \n",
      "\n",
      "Fold: 24  Epoch: 82  Training loss = 4.1094  Validation loss = 1.6646  \n",
      "\n",
      "Fold: 24  Epoch: 83  Training loss = 4.1090  Validation loss = 1.6643  \n",
      "\n",
      "Fold: 24  Epoch: 84  Training loss = 4.1085  Validation loss = 1.6639  \n",
      "\n",
      "Fold: 24  Epoch: 85  Training loss = 4.1081  Validation loss = 1.6636  \n",
      "\n",
      "Fold: 24  Epoch: 86  Training loss = 4.1078  Validation loss = 1.6633  \n",
      "\n",
      "Fold: 24  Epoch: 87  Training loss = 4.1073  Validation loss = 1.6630  \n",
      "\n",
      "Fold: 24  Epoch: 88  Training loss = 4.1069  Validation loss = 1.6628  \n",
      "\n",
      "Fold: 24  Epoch: 89  Training loss = 4.1067  Validation loss = 1.6625  \n",
      "\n",
      "Fold: 24  Epoch: 90  Training loss = 4.1062  Validation loss = 1.6621  \n",
      "\n",
      "Fold: 24  Epoch: 91  Training loss = 4.1059  Validation loss = 1.6617  \n",
      "\n",
      "Fold: 24  Epoch: 92  Training loss = 4.1054  Validation loss = 1.6613  \n",
      "\n",
      "Fold: 24  Epoch: 93  Training loss = 4.1050  Validation loss = 1.6611  \n",
      "\n",
      "Fold: 24  Epoch: 94  Training loss = 4.1047  Validation loss = 1.6609  \n",
      "\n",
      "Fold: 24  Epoch: 95  Training loss = 4.1043  Validation loss = 1.6607  \n",
      "\n",
      "Fold: 24  Epoch: 96  Training loss = 4.1040  Validation loss = 1.6604  \n",
      "\n",
      "Fold: 24  Epoch: 97  Training loss = 4.1037  Validation loss = 1.6602  \n",
      "\n",
      "Fold: 24  Epoch: 98  Training loss = 4.1034  Validation loss = 1.6599  \n",
      "\n",
      "Fold: 24  Epoch: 99  Training loss = 4.1030  Validation loss = 1.6596  \n",
      "\n",
      "Fold: 24  Epoch: 100  Training loss = 4.1027  Validation loss = 1.6593  \n",
      "\n",
      "Fold: 24  Epoch: 101  Training loss = 4.1023  Validation loss = 1.6590  \n",
      "\n",
      "Fold: 24  Epoch: 102  Training loss = 4.1020  Validation loss = 1.6587  \n",
      "\n",
      "Fold: 24  Epoch: 103  Training loss = 4.1016  Validation loss = 1.6584  \n",
      "\n",
      "Fold: 24  Epoch: 104  Training loss = 4.1011  Validation loss = 1.6581  \n",
      "\n",
      "Fold: 24  Epoch: 105  Training loss = 4.1006  Validation loss = 1.6576  \n",
      "\n",
      "Fold: 24  Epoch: 106  Training loss = 4.1003  Validation loss = 1.6574  \n",
      "\n",
      "Fold: 24  Epoch: 107  Training loss = 4.0999  Validation loss = 1.6571  \n",
      "\n",
      "Fold: 24  Epoch: 108  Training loss = 4.0996  Validation loss = 1.6569  \n",
      "\n",
      "Fold: 24  Epoch: 109  Training loss = 4.0991  Validation loss = 1.6565  \n",
      "\n",
      "Fold: 24  Epoch: 110  Training loss = 4.0988  Validation loss = 1.6563  \n",
      "\n",
      "Fold: 24  Epoch: 111  Training loss = 4.0984  Validation loss = 1.6561  \n",
      "\n",
      "Fold: 24  Epoch: 112  Training loss = 4.0980  Validation loss = 1.6558  \n",
      "\n",
      "Fold: 24  Epoch: 113  Training loss = 4.0976  Validation loss = 1.6554  \n",
      "\n",
      "Fold: 24  Epoch: 114  Training loss = 4.0973  Validation loss = 1.6551  \n",
      "\n",
      "Fold: 24  Epoch: 115  Training loss = 4.0969  Validation loss = 1.6550  \n",
      "\n",
      "Fold: 24  Epoch: 116  Training loss = 4.0966  Validation loss = 1.6546  \n",
      "\n",
      "Fold: 24  Epoch: 117  Training loss = 4.0960  Validation loss = 1.6542  \n",
      "\n",
      "Fold: 24  Epoch: 118  Training loss = 4.0956  Validation loss = 1.6539  \n",
      "\n",
      "Fold: 24  Epoch: 119  Training loss = 4.0953  Validation loss = 1.6538  \n",
      "\n",
      "Fold: 24  Epoch: 120  Training loss = 4.0950  Validation loss = 1.6535  \n",
      "\n",
      "Fold: 24  Epoch: 121  Training loss = 4.0947  Validation loss = 1.6534  \n",
      "\n",
      "Fold: 24  Epoch: 122  Training loss = 4.0943  Validation loss = 1.6532  \n",
      "\n",
      "Fold: 24  Epoch: 123  Training loss = 4.0938  Validation loss = 1.6528  \n",
      "\n",
      "Fold: 24  Epoch: 124  Training loss = 4.0935  Validation loss = 1.6525  \n",
      "\n",
      "Fold: 24  Epoch: 125  Training loss = 4.0930  Validation loss = 1.6521  \n",
      "\n",
      "Fold: 24  Epoch: 126  Training loss = 4.0926  Validation loss = 1.6518  \n",
      "\n",
      "Fold: 24  Epoch: 127  Training loss = 4.0924  Validation loss = 1.6517  \n",
      "\n",
      "Fold: 24  Epoch: 128  Training loss = 4.0920  Validation loss = 1.6514  \n",
      "\n",
      "Fold: 24  Epoch: 129  Training loss = 4.0917  Validation loss = 1.6512  \n",
      "\n",
      "Fold: 24  Epoch: 130  Training loss = 4.0914  Validation loss = 1.6509  \n",
      "\n",
      "Fold: 24  Epoch: 131  Training loss = 4.0911  Validation loss = 1.6508  \n",
      "\n",
      "Fold: 24  Epoch: 132  Training loss = 4.0907  Validation loss = 1.6505  \n",
      "\n",
      "Fold: 24  Epoch: 133  Training loss = 4.0904  Validation loss = 1.6503  \n",
      "\n",
      "Fold: 24  Epoch: 134  Training loss = 4.0900  Validation loss = 1.6501  \n",
      "\n",
      "Fold: 24  Epoch: 135  Training loss = 4.0897  Validation loss = 1.6499  \n",
      "\n",
      "Fold: 24  Epoch: 136  Training loss = 4.0894  Validation loss = 1.6496  \n",
      "\n",
      "Fold: 24  Epoch: 137  Training loss = 4.0891  Validation loss = 1.6494  \n",
      "\n",
      "Fold: 24  Epoch: 138  Training loss = 4.0886  Validation loss = 1.6490  \n",
      "\n",
      "Fold: 24  Epoch: 139  Training loss = 4.0882  Validation loss = 1.6487  \n",
      "\n",
      "Fold: 24  Epoch: 140  Training loss = 4.0878  Validation loss = 1.6485  \n",
      "\n",
      "Fold: 24  Epoch: 141  Training loss = 4.0873  Validation loss = 1.6481  \n",
      "\n",
      "Fold: 24  Epoch: 142  Training loss = 4.0870  Validation loss = 1.6479  \n",
      "\n",
      "Fold: 24  Epoch: 143  Training loss = 4.0867  Validation loss = 1.6477  \n",
      "\n",
      "Fold: 24  Epoch: 144  Training loss = 4.0862  Validation loss = 1.6473  \n",
      "\n",
      "Fold: 24  Epoch: 145  Training loss = 4.0859  Validation loss = 1.6471  \n",
      "\n",
      "Fold: 24  Epoch: 146  Training loss = 4.0856  Validation loss = 1.6469  \n",
      "\n",
      "Fold: 24  Epoch: 147  Training loss = 4.0853  Validation loss = 1.6467  \n",
      "\n",
      "Fold: 24  Epoch: 148  Training loss = 4.0850  Validation loss = 1.6464  \n",
      "\n",
      "Fold: 24  Epoch: 149  Training loss = 4.0845  Validation loss = 1.6461  \n",
      "\n",
      "Fold: 24  Epoch: 150  Training loss = 4.0842  Validation loss = 1.6459  \n",
      "\n",
      "Fold: 24  Epoch: 151  Training loss = 4.0839  Validation loss = 1.6456  \n",
      "\n",
      "Fold: 24  Epoch: 152  Training loss = 4.0836  Validation loss = 1.6454  \n",
      "\n",
      "Fold: 24  Epoch: 153  Training loss = 4.0832  Validation loss = 1.6451  \n",
      "\n",
      "Fold: 24  Epoch: 154  Training loss = 4.0828  Validation loss = 1.6448  \n",
      "\n",
      "Fold: 24  Epoch: 155  Training loss = 4.0824  Validation loss = 1.6445  \n",
      "\n",
      "Fold: 24  Epoch: 156  Training loss = 4.0820  Validation loss = 1.6443  \n",
      "\n",
      "Fold: 24  Epoch: 157  Training loss = 4.0817  Validation loss = 1.6440  \n",
      "\n",
      "Fold: 24  Epoch: 158  Training loss = 4.0814  Validation loss = 1.6437  \n",
      "\n",
      "Fold: 24  Epoch: 159  Training loss = 4.0810  Validation loss = 1.6434  \n",
      "\n",
      "Fold: 24  Epoch: 160  Training loss = 4.0806  Validation loss = 1.6431  \n",
      "\n",
      "Fold: 24  Epoch: 161  Training loss = 4.0803  Validation loss = 1.6429  \n",
      "\n",
      "Fold: 24  Epoch: 162  Training loss = 4.0799  Validation loss = 1.6426  \n",
      "\n",
      "Fold: 24  Epoch: 163  Training loss = 4.0796  Validation loss = 1.6424  \n",
      "\n",
      "Fold: 24  Epoch: 164  Training loss = 4.0792  Validation loss = 1.6421  \n",
      "\n",
      "Fold: 24  Epoch: 165  Training loss = 4.0789  Validation loss = 1.6420  \n",
      "\n",
      "Fold: 24  Epoch: 166  Training loss = 4.0786  Validation loss = 1.6417  \n",
      "\n",
      "Fold: 24  Epoch: 167  Training loss = 4.0783  Validation loss = 1.6415  \n",
      "\n",
      "Fold: 24  Epoch: 168  Training loss = 4.0779  Validation loss = 1.6411  \n",
      "\n",
      "Fold: 24  Epoch: 169  Training loss = 4.0776  Validation loss = 1.6410  \n",
      "\n",
      "Fold: 24  Epoch: 170  Training loss = 4.0773  Validation loss = 1.6407  \n",
      "\n",
      "Fold: 24  Epoch: 171  Training loss = 4.0768  Validation loss = 1.6404  \n",
      "\n",
      "Fold: 24  Epoch: 172  Training loss = 4.0764  Validation loss = 1.6404  \n",
      "\n",
      "Fold: 24  Epoch: 173  Training loss = 4.0760  Validation loss = 1.6401  \n",
      "\n",
      "Fold: 24  Epoch: 174  Training loss = 4.0755  Validation loss = 1.6398  \n",
      "\n",
      "Fold: 24  Epoch: 175  Training loss = 4.0750  Validation loss = 1.6397  \n",
      "\n",
      "Fold: 24  Epoch: 176  Training loss = 4.0747  Validation loss = 1.6395  \n",
      "\n",
      "Fold: 24  Epoch: 177  Training loss = 4.0744  Validation loss = 1.6393  \n",
      "\n",
      "Fold: 24  Epoch: 178  Training loss = 4.0740  Validation loss = 1.6391  \n",
      "\n",
      "Fold: 24  Epoch: 179  Training loss = 4.0736  Validation loss = 1.6388  \n",
      "\n",
      "Fold: 24  Epoch: 180  Training loss = 4.0731  Validation loss = 1.6385  \n",
      "\n",
      "Fold: 24  Epoch: 181  Training loss = 4.0725  Validation loss = 1.6381  \n",
      "\n",
      "Fold: 24  Epoch: 182  Training loss = 4.0721  Validation loss = 1.6378  \n",
      "\n",
      "Fold: 24  Epoch: 183  Training loss = 4.0717  Validation loss = 1.6376  \n",
      "\n",
      "Fold: 24  Epoch: 184  Training loss = 4.0713  Validation loss = 1.6374  \n",
      "\n",
      "Fold: 24  Epoch: 185  Training loss = 4.0710  Validation loss = 1.6372  \n",
      "\n",
      "Fold: 24  Epoch: 186  Training loss = 4.0707  Validation loss = 1.6370  \n",
      "\n",
      "Fold: 24  Epoch: 187  Training loss = 4.0702  Validation loss = 1.6366  \n",
      "\n",
      "Fold: 24  Epoch: 188  Training loss = 4.0697  Validation loss = 1.6363  \n",
      "\n",
      "Fold: 24  Epoch: 189  Training loss = 4.0693  Validation loss = 1.6360  \n",
      "\n",
      "Fold: 24  Epoch: 190  Training loss = 4.0689  Validation loss = 1.6357  \n",
      "\n",
      "Fold: 24  Epoch: 191  Training loss = 4.0686  Validation loss = 1.6354  \n",
      "\n",
      "Fold: 24  Epoch: 192  Training loss = 4.0682  Validation loss = 1.6351  \n",
      "\n",
      "Fold: 24  Epoch: 193  Training loss = 4.0679  Validation loss = 1.6349  \n",
      "\n",
      "Fold: 24  Epoch: 194  Training loss = 4.0675  Validation loss = 1.6347  \n",
      "\n",
      "Fold: 24  Epoch: 195  Training loss = 4.0671  Validation loss = 1.6343  \n",
      "\n",
      "Fold: 24  Epoch: 196  Training loss = 4.0667  Validation loss = 1.6341  \n",
      "\n",
      "Fold: 24  Epoch: 197  Training loss = 4.0664  Validation loss = 1.6339  \n",
      "\n",
      "Fold: 24  Epoch: 198  Training loss = 4.0661  Validation loss = 1.6337  \n",
      "\n",
      "Fold: 24  Epoch: 199  Training loss = 4.0657  Validation loss = 1.6333  \n",
      "\n",
      "Fold: 24  Epoch: 200  Training loss = 4.0653  Validation loss = 1.6330  \n",
      "\n",
      "Fold: 24  Epoch: 201  Training loss = 4.0650  Validation loss = 1.6327  \n",
      "\n",
      "Fold: 24  Epoch: 202  Training loss = 4.0646  Validation loss = 1.6325  \n",
      "\n",
      "Fold: 24  Epoch: 203  Training loss = 4.0644  Validation loss = 1.6323  \n",
      "\n",
      "Fold: 24  Epoch: 204  Training loss = 4.0640  Validation loss = 1.6320  \n",
      "\n",
      "Fold: 24  Epoch: 205  Training loss = 4.0637  Validation loss = 1.6318  \n",
      "\n",
      "Fold: 24  Epoch: 206  Training loss = 4.0634  Validation loss = 1.6315  \n",
      "\n",
      "Fold: 24  Epoch: 207  Training loss = 4.0630  Validation loss = 1.6312  \n",
      "\n",
      "Fold: 24  Epoch: 208  Training loss = 4.0626  Validation loss = 1.6310  \n",
      "\n",
      "Fold: 24  Epoch: 209  Training loss = 4.0623  Validation loss = 1.6308  \n",
      "\n",
      "Fold: 24  Epoch: 210  Training loss = 4.0620  Validation loss = 1.6306  \n",
      "\n",
      "Fold: 24  Epoch: 211  Training loss = 4.0618  Validation loss = 1.6304  \n",
      "\n",
      "Fold: 24  Epoch: 212  Training loss = 4.0615  Validation loss = 1.6302  \n",
      "\n",
      "Fold: 24  Epoch: 213  Training loss = 4.0612  Validation loss = 1.6299  \n",
      "\n",
      "Fold: 24  Epoch: 214  Training loss = 4.0610  Validation loss = 1.6297  \n",
      "\n",
      "Fold: 24  Epoch: 215  Training loss = 4.0606  Validation loss = 1.6296  \n",
      "\n",
      "Fold: 24  Epoch: 216  Training loss = 4.0603  Validation loss = 1.6293  \n",
      "\n",
      "Fold: 24  Epoch: 217  Training loss = 4.0599  Validation loss = 1.6291  \n",
      "\n",
      "Fold: 24  Epoch: 218  Training loss = 4.0595  Validation loss = 1.6288  \n",
      "\n",
      "Fold: 24  Epoch: 219  Training loss = 4.0592  Validation loss = 1.6285  \n",
      "\n",
      "Fold: 24  Epoch: 220  Training loss = 4.0588  Validation loss = 1.6282  \n",
      "\n",
      "Fold: 24  Epoch: 221  Training loss = 4.0584  Validation loss = 1.6279  \n",
      "\n",
      "Fold: 24  Epoch: 222  Training loss = 4.0580  Validation loss = 1.6277  \n",
      "\n",
      "Fold: 24  Epoch: 223  Training loss = 4.0576  Validation loss = 1.6275  \n",
      "\n",
      "Fold: 24  Epoch: 224  Training loss = 4.0573  Validation loss = 1.6274  \n",
      "\n",
      "Fold: 24  Epoch: 225  Training loss = 4.0570  Validation loss = 1.6271  \n",
      "\n",
      "Fold: 24  Epoch: 226  Training loss = 4.0566  Validation loss = 1.6268  \n",
      "\n",
      "Fold: 24  Epoch: 227  Training loss = 4.0563  Validation loss = 1.6267  \n",
      "\n",
      "Fold: 24  Epoch: 228  Training loss = 4.0561  Validation loss = 1.6265  \n",
      "\n",
      "Fold: 24  Epoch: 229  Training loss = 4.0559  Validation loss = 1.6264  \n",
      "\n",
      "Fold: 24  Epoch: 230  Training loss = 4.0555  Validation loss = 1.6261  \n",
      "\n",
      "Fold: 24  Epoch: 231  Training loss = 4.0553  Validation loss = 1.6260  \n",
      "\n",
      "Fold: 24  Epoch: 232  Training loss = 4.0550  Validation loss = 1.6257  \n",
      "\n",
      "Fold: 24  Epoch: 233  Training loss = 4.0546  Validation loss = 1.6255  \n",
      "\n",
      "Fold: 24  Epoch: 234  Training loss = 4.0542  Validation loss = 1.6251  \n",
      "\n",
      "Fold: 24  Epoch: 235  Training loss = 4.0539  Validation loss = 1.6251  \n",
      "\n",
      "Fold: 24  Epoch: 236  Training loss = 4.0536  Validation loss = 1.6248  \n",
      "\n",
      "Fold: 24  Epoch: 237  Training loss = 4.0532  Validation loss = 1.6245  \n",
      "\n",
      "Fold: 24  Epoch: 238  Training loss = 4.0528  Validation loss = 1.6243  \n",
      "\n",
      "Fold: 24  Epoch: 239  Training loss = 4.0526  Validation loss = 1.6241  \n",
      "\n",
      "Fold: 24  Epoch: 240  Training loss = 4.0523  Validation loss = 1.6239  \n",
      "\n",
      "Fold: 24  Epoch: 241  Training loss = 4.0520  Validation loss = 1.6236  \n",
      "\n",
      "Fold: 24  Epoch: 242  Training loss = 4.0517  Validation loss = 1.6234  \n",
      "\n",
      "Fold: 24  Epoch: 243  Training loss = 4.0512  Validation loss = 1.6231  \n",
      "\n",
      "Fold: 24  Epoch: 244  Training loss = 4.0508  Validation loss = 1.6229  \n",
      "\n",
      "Fold: 24  Epoch: 245  Training loss = 4.0505  Validation loss = 1.6226  \n",
      "\n",
      "Fold: 24  Epoch: 246  Training loss = 4.0501  Validation loss = 1.6224  \n",
      "\n",
      "Fold: 24  Epoch: 247  Training loss = 4.0498  Validation loss = 1.6222  \n",
      "\n",
      "Fold: 24  Epoch: 248  Training loss = 4.0495  Validation loss = 1.6220  \n",
      "\n",
      "Fold: 24  Epoch: 249  Training loss = 4.0493  Validation loss = 1.6218  \n",
      "\n",
      "Fold: 24  Epoch: 250  Training loss = 4.0490  Validation loss = 1.6215  \n",
      "\n",
      "Fold: 24  Epoch: 251  Training loss = 4.0487  Validation loss = 1.6213  \n",
      "\n",
      "Fold: 24  Epoch: 252  Training loss = 4.0483  Validation loss = 1.6210  \n",
      "\n",
      "Fold: 24  Epoch: 253  Training loss = 4.0479  Validation loss = 1.6207  \n",
      "\n",
      "Fold: 24  Epoch: 254  Training loss = 4.0476  Validation loss = 1.6205  \n",
      "\n",
      "Fold: 24  Epoch: 255  Training loss = 4.0473  Validation loss = 1.6203  \n",
      "\n",
      "Fold: 24  Epoch: 256  Training loss = 4.0470  Validation loss = 1.6201  \n",
      "\n",
      "Fold: 24  Epoch: 257  Training loss = 4.0467  Validation loss = 1.6200  \n",
      "\n",
      "Fold: 24  Epoch: 258  Training loss = 4.0463  Validation loss = 1.6197  \n",
      "\n",
      "Fold: 24  Epoch: 259  Training loss = 4.0460  Validation loss = 1.6196  \n",
      "\n",
      "Fold: 24  Epoch: 260  Training loss = 4.0457  Validation loss = 1.6193  \n",
      "\n",
      "Fold: 24  Epoch: 261  Training loss = 4.0453  Validation loss = 1.6191  \n",
      "\n",
      "Fold: 24  Epoch: 262  Training loss = 4.0451  Validation loss = 1.6189  \n",
      "\n",
      "Fold: 24  Epoch: 263  Training loss = 4.0447  Validation loss = 1.6187  \n",
      "\n",
      "Fold: 24  Epoch: 264  Training loss = 4.0443  Validation loss = 1.6183  \n",
      "\n",
      "Fold: 24  Epoch: 265  Training loss = 4.0439  Validation loss = 1.6182  \n",
      "\n",
      "Fold: 24  Epoch: 266  Training loss = 4.0436  Validation loss = 1.6179  \n",
      "\n",
      "Fold: 24  Epoch: 267  Training loss = 4.0432  Validation loss = 1.6176  \n",
      "\n",
      "Fold: 24  Epoch: 268  Training loss = 4.0428  Validation loss = 1.6173  \n",
      "\n",
      "Fold: 24  Epoch: 269  Training loss = 4.0426  Validation loss = 1.6171  \n",
      "\n",
      "Fold: 24  Epoch: 270  Training loss = 4.0422  Validation loss = 1.6167  \n",
      "\n",
      "Fold: 24  Epoch: 271  Training loss = 4.0419  Validation loss = 1.6165  \n",
      "\n",
      "Fold: 24  Epoch: 272  Training loss = 4.0416  Validation loss = 1.6162  \n",
      "\n",
      "Fold: 24  Epoch: 273  Training loss = 4.0413  Validation loss = 1.6160  \n",
      "\n",
      "Fold: 24  Epoch: 274  Training loss = 4.0409  Validation loss = 1.6157  \n",
      "\n",
      "Fold: 24  Epoch: 275  Training loss = 4.0406  Validation loss = 1.6154  \n",
      "\n",
      "Fold: 24  Epoch: 276  Training loss = 4.0402  Validation loss = 1.6151  \n",
      "\n",
      "Fold: 24  Epoch: 277  Training loss = 4.0400  Validation loss = 1.6149  \n",
      "\n",
      "Fold: 24  Epoch: 278  Training loss = 4.0395  Validation loss = 1.6145  \n",
      "\n",
      "Fold: 24  Epoch: 279  Training loss = 4.0391  Validation loss = 1.6142  \n",
      "\n",
      "Fold: 24  Epoch: 280  Training loss = 4.0388  Validation loss = 1.6140  \n",
      "\n",
      "Fold: 24  Epoch: 281  Training loss = 4.0384  Validation loss = 1.6138  \n",
      "\n",
      "Fold: 24  Epoch: 282  Training loss = 4.0381  Validation loss = 1.6135  \n",
      "\n",
      "Fold: 24  Epoch: 283  Training loss = 4.0377  Validation loss = 1.6133  \n",
      "\n",
      "Fold: 24  Epoch: 284  Training loss = 4.0374  Validation loss = 1.6129  \n",
      "\n",
      "Fold: 24  Epoch: 285  Training loss = 4.0369  Validation loss = 1.6126  \n",
      "\n",
      "Fold: 24  Epoch: 286  Training loss = 4.0365  Validation loss = 1.6122  \n",
      "\n",
      "Fold: 24  Epoch: 287  Training loss = 4.0362  Validation loss = 1.6119  \n",
      "\n",
      "Fold: 24  Epoch: 288  Training loss = 4.0359  Validation loss = 1.6117  \n",
      "\n",
      "Fold: 24  Epoch: 289  Training loss = 4.0356  Validation loss = 1.6114  \n",
      "\n",
      "Fold: 24  Epoch: 290  Training loss = 4.0351  Validation loss = 1.6110  \n",
      "\n",
      "Fold: 24  Epoch: 291  Training loss = 4.0349  Validation loss = 1.6109  \n",
      "\n",
      "Fold: 24  Epoch: 292  Training loss = 4.0345  Validation loss = 1.6106  \n",
      "\n",
      "Fold: 24  Epoch: 293  Training loss = 4.0342  Validation loss = 1.6104  \n",
      "\n",
      "Fold: 24  Epoch: 294  Training loss = 4.0339  Validation loss = 1.6102  \n",
      "\n",
      "Fold: 24  Epoch: 295  Training loss = 4.0336  Validation loss = 1.6099  \n",
      "\n",
      "Fold: 24  Epoch: 296  Training loss = 4.0334  Validation loss = 1.6097  \n",
      "\n",
      "Fold: 24  Epoch: 297  Training loss = 4.0330  Validation loss = 1.6095  \n",
      "\n",
      "Fold: 24  Epoch: 298  Training loss = 4.0327  Validation loss = 1.6092  \n",
      "\n",
      "Fold: 24  Epoch: 299  Training loss = 4.0323  Validation loss = 1.6090  \n",
      "\n",
      "Fold: 24  Epoch: 300  Training loss = 4.0320  Validation loss = 1.6088  \n",
      "\n",
      "Fold: 24  Epoch: 301  Training loss = 4.0318  Validation loss = 1.6087  \n",
      "\n",
      "Fold: 24  Epoch: 302  Training loss = 4.0315  Validation loss = 1.6085  \n",
      "\n",
      "Fold: 24  Epoch: 303  Training loss = 4.0311  Validation loss = 1.6083  \n",
      "\n",
      "Fold: 24  Epoch: 304  Training loss = 4.0309  Validation loss = 1.6081  \n",
      "\n",
      "Fold: 24  Epoch: 305  Training loss = 4.0306  Validation loss = 1.6080  \n",
      "\n",
      "Fold: 24  Epoch: 306  Training loss = 4.0304  Validation loss = 1.6078  \n",
      "\n",
      "Fold: 24  Epoch: 307  Training loss = 4.0301  Validation loss = 1.6077  \n",
      "\n",
      "Fold: 24  Epoch: 308  Training loss = 4.0299  Validation loss = 1.6076  \n",
      "\n",
      "Fold: 24  Epoch: 309  Training loss = 4.0294  Validation loss = 1.6073  \n",
      "\n",
      "Fold: 24  Epoch: 310  Training loss = 4.0290  Validation loss = 1.6071  \n",
      "\n",
      "Fold: 24  Epoch: 311  Training loss = 4.0287  Validation loss = 1.6069  \n",
      "\n",
      "Fold: 24  Epoch: 312  Training loss = 4.0283  Validation loss = 1.6066  \n",
      "\n",
      "Fold: 24  Epoch: 313  Training loss = 4.0279  Validation loss = 1.6064  \n",
      "\n",
      "Fold: 24  Epoch: 314  Training loss = 4.0276  Validation loss = 1.6062  \n",
      "\n",
      "Fold: 24  Epoch: 315  Training loss = 4.0271  Validation loss = 1.6059  \n",
      "\n",
      "Fold: 24  Epoch: 316  Training loss = 4.0267  Validation loss = 1.6056  \n",
      "\n",
      "Fold: 24  Epoch: 317  Training loss = 4.0264  Validation loss = 1.6053  \n",
      "\n",
      "Fold: 24  Epoch: 318  Training loss = 4.0261  Validation loss = 1.6052  \n",
      "\n",
      "Fold: 24  Epoch: 319  Training loss = 4.0258  Validation loss = 1.6050  \n",
      "\n",
      "Fold: 24  Epoch: 320  Training loss = 4.0253  Validation loss = 1.6046  \n",
      "\n",
      "Fold: 24  Epoch: 321  Training loss = 4.0250  Validation loss = 1.6042  \n",
      "\n",
      "Fold: 24  Epoch: 322  Training loss = 4.0246  Validation loss = 1.6040  \n",
      "\n",
      "Fold: 24  Epoch: 323  Training loss = 4.0243  Validation loss = 1.6038  \n",
      "\n",
      "Fold: 24  Epoch: 324  Training loss = 4.0240  Validation loss = 1.6036  \n",
      "\n",
      "Fold: 24  Epoch: 325  Training loss = 4.0237  Validation loss = 1.6033  \n",
      "\n",
      "Fold: 24  Epoch: 326  Training loss = 4.0233  Validation loss = 1.6030  \n",
      "\n",
      "Fold: 24  Epoch: 327  Training loss = 4.0230  Validation loss = 1.6028  \n",
      "\n",
      "Fold: 24  Epoch: 328  Training loss = 4.0227  Validation loss = 1.6025  \n",
      "\n",
      "Fold: 24  Epoch: 329  Training loss = 4.0224  Validation loss = 1.6023  \n",
      "\n",
      "Fold: 24  Epoch: 330  Training loss = 4.0221  Validation loss = 1.6022  \n",
      "\n",
      "Fold: 24  Epoch: 331  Training loss = 4.0218  Validation loss = 1.6020  \n",
      "\n",
      "Fold: 24  Epoch: 332  Training loss = 4.0215  Validation loss = 1.6018  \n",
      "\n",
      "Fold: 24  Epoch: 333  Training loss = 4.0211  Validation loss = 1.6016  \n",
      "\n",
      "Fold: 24  Epoch: 334  Training loss = 4.0208  Validation loss = 1.6013  \n",
      "\n",
      "Fold: 24  Epoch: 335  Training loss = 4.0204  Validation loss = 1.6011  \n",
      "\n",
      "Fold: 24  Epoch: 336  Training loss = 4.0201  Validation loss = 1.6008  \n",
      "\n",
      "Fold: 24  Epoch: 337  Training loss = 4.0197  Validation loss = 1.6005  \n",
      "\n",
      "Fold: 24  Epoch: 338  Training loss = 4.0194  Validation loss = 1.6003  \n",
      "\n",
      "Fold: 24  Epoch: 339  Training loss = 4.0189  Validation loss = 1.5999  \n",
      "\n",
      "Fold: 24  Epoch: 340  Training loss = 4.0187  Validation loss = 1.5997  \n",
      "\n",
      "Fold: 24  Epoch: 341  Training loss = 4.0184  Validation loss = 1.5995  \n",
      "\n",
      "Fold: 24  Epoch: 342  Training loss = 4.0182  Validation loss = 1.5993  \n",
      "\n",
      "Fold: 24  Epoch: 343  Training loss = 4.0179  Validation loss = 1.5991  \n",
      "\n",
      "Fold: 24  Epoch: 344  Training loss = 4.0176  Validation loss = 1.5989  \n",
      "\n",
      "Fold: 24  Epoch: 345  Training loss = 4.0174  Validation loss = 1.5987  \n",
      "\n",
      "Fold: 24  Epoch: 346  Training loss = 4.0171  Validation loss = 1.5985  \n",
      "\n",
      "Fold: 24  Epoch: 347  Training loss = 4.0168  Validation loss = 1.5982  \n",
      "\n",
      "Fold: 24  Epoch: 348  Training loss = 4.0164  Validation loss = 1.5980  \n",
      "\n",
      "Fold: 24  Epoch: 349  Training loss = 4.0161  Validation loss = 1.5977  \n",
      "\n",
      "Fold: 24  Epoch: 350  Training loss = 4.0157  Validation loss = 1.5973  \n",
      "\n",
      "Fold: 24  Epoch: 351  Training loss = 4.0154  Validation loss = 1.5971  \n",
      "\n",
      "Fold: 24  Epoch: 352  Training loss = 4.0151  Validation loss = 1.5968  \n",
      "\n",
      "Fold: 24  Epoch: 353  Training loss = 4.0147  Validation loss = 1.5966  \n",
      "\n",
      "Fold: 24  Epoch: 354  Training loss = 4.0145  Validation loss = 1.5964  \n",
      "\n",
      "Fold: 24  Epoch: 355  Training loss = 4.0141  Validation loss = 1.5961  \n",
      "\n",
      "Fold: 24  Epoch: 356  Training loss = 4.0137  Validation loss = 1.5959  \n",
      "\n",
      "Fold: 24  Epoch: 357  Training loss = 4.0135  Validation loss = 1.5957  \n",
      "\n",
      "Fold: 24  Epoch: 358  Training loss = 4.0131  Validation loss = 1.5954  \n",
      "\n",
      "Fold: 24  Epoch: 359  Training loss = 4.0128  Validation loss = 1.5951  \n",
      "\n",
      "Fold: 24  Epoch: 360  Training loss = 4.0124  Validation loss = 1.5948  \n",
      "\n",
      "Fold: 24  Epoch: 361  Training loss = 4.0120  Validation loss = 1.5945  \n",
      "\n",
      "Fold: 24  Epoch: 362  Training loss = 4.0116  Validation loss = 1.5942  \n",
      "\n",
      "Fold: 24  Epoch: 363  Training loss = 4.0113  Validation loss = 1.5940  \n",
      "\n",
      "Fold: 24  Epoch: 364  Training loss = 4.0110  Validation loss = 1.5938  \n",
      "\n",
      "Fold: 24  Epoch: 365  Training loss = 4.0107  Validation loss = 1.5936  \n",
      "\n",
      "Fold: 24  Epoch: 366  Training loss = 4.0104  Validation loss = 1.5933  \n",
      "\n",
      "Fold: 24  Epoch: 367  Training loss = 4.0100  Validation loss = 1.5931  \n",
      "\n",
      "Fold: 24  Epoch: 368  Training loss = 4.0098  Validation loss = 1.5929  \n",
      "\n",
      "Fold: 24  Epoch: 369  Training loss = 4.0095  Validation loss = 1.5927  \n",
      "\n",
      "Fold: 24  Epoch: 370  Training loss = 4.0092  Validation loss = 1.5925  \n",
      "\n",
      "Fold: 24  Epoch: 371  Training loss = 4.0088  Validation loss = 1.5923  \n",
      "\n",
      "Fold: 24  Epoch: 372  Training loss = 4.0084  Validation loss = 1.5920  \n",
      "\n",
      "Fold: 24  Epoch: 373  Training loss = 4.0081  Validation loss = 1.5918  \n",
      "\n",
      "Fold: 24  Epoch: 374  Training loss = 4.0077  Validation loss = 1.5916  \n",
      "\n",
      "Fold: 24  Epoch: 375  Training loss = 4.0075  Validation loss = 1.5914  \n",
      "\n",
      "Fold: 24  Epoch: 376  Training loss = 4.0072  Validation loss = 1.5912  \n",
      "\n",
      "Fold: 24  Epoch: 377  Training loss = 4.0069  Validation loss = 1.5910  \n",
      "\n",
      "Fold: 24  Epoch: 378  Training loss = 4.0066  Validation loss = 1.5908  \n",
      "\n",
      "Fold: 24  Epoch: 379  Training loss = 4.0062  Validation loss = 1.5906  \n",
      "\n",
      "Fold: 24  Epoch: 380  Training loss = 4.0059  Validation loss = 1.5903  \n",
      "\n",
      "Fold: 24  Epoch: 381  Training loss = 4.0056  Validation loss = 1.5901  \n",
      "\n",
      "Fold: 24  Epoch: 382  Training loss = 4.0054  Validation loss = 1.5900  \n",
      "\n",
      "Fold: 24  Epoch: 383  Training loss = 4.0049  Validation loss = 1.5896  \n",
      "\n",
      "Fold: 24  Epoch: 384  Training loss = 4.0045  Validation loss = 1.5893  \n",
      "\n",
      "Fold: 24  Epoch: 385  Training loss = 4.0042  Validation loss = 1.5891  \n",
      "\n",
      "Fold: 24  Epoch: 386  Training loss = 4.0039  Validation loss = 1.5889  \n",
      "\n",
      "Fold: 24  Epoch: 387  Training loss = 4.0035  Validation loss = 1.5887  \n",
      "\n",
      "Fold: 24  Epoch: 388  Training loss = 4.0032  Validation loss = 1.5885  \n",
      "\n",
      "Fold: 24  Epoch: 389  Training loss = 4.0030  Validation loss = 1.5882  \n",
      "\n",
      "Fold: 24  Epoch: 390  Training loss = 4.0026  Validation loss = 1.5879  \n",
      "\n",
      "Fold: 24  Epoch: 391  Training loss = 4.0022  Validation loss = 1.5876  \n",
      "\n",
      "Fold: 24  Epoch: 392  Training loss = 4.0020  Validation loss = 1.5875  \n",
      "\n",
      "Fold: 24  Epoch: 393  Training loss = 4.0017  Validation loss = 1.5873  \n",
      "\n",
      "Fold: 24  Epoch: 394  Training loss = 4.0012  Validation loss = 1.5870  \n",
      "\n",
      "Fold: 24  Epoch: 395  Training loss = 4.0010  Validation loss = 1.5867  \n",
      "\n",
      "Fold: 24  Epoch: 396  Training loss = 4.0007  Validation loss = 1.5864  \n",
      "\n",
      "Fold: 24  Epoch: 397  Training loss = 4.0004  Validation loss = 1.5862  \n",
      "\n",
      "Fold: 24  Epoch: 398  Training loss = 4.0001  Validation loss = 1.5860  \n",
      "\n",
      "Fold: 24  Epoch: 399  Training loss = 3.9998  Validation loss = 1.5859  \n",
      "\n",
      "Fold: 24  Epoch: 400  Training loss = 3.9994  Validation loss = 1.5857  \n",
      "\n",
      "Fold: 24  Epoch: 401  Training loss = 3.9991  Validation loss = 1.5854  \n",
      "\n",
      "Fold: 24  Epoch: 402  Training loss = 3.9988  Validation loss = 1.5853  \n",
      "\n",
      "Fold: 24  Epoch: 403  Training loss = 3.9985  Validation loss = 1.5850  \n",
      "\n",
      "Fold: 24  Epoch: 404  Training loss = 3.9982  Validation loss = 1.5848  \n",
      "\n",
      "Fold: 24  Epoch: 405  Training loss = 3.9979  Validation loss = 1.5846  \n",
      "\n",
      "Fold: 24  Epoch: 406  Training loss = 3.9976  Validation loss = 1.5844  \n",
      "\n",
      "Fold: 24  Epoch: 407  Training loss = 3.9973  Validation loss = 1.5841  \n",
      "\n",
      "Fold: 24  Epoch: 408  Training loss = 3.9969  Validation loss = 1.5839  \n",
      "\n",
      "Fold: 24  Epoch: 409  Training loss = 3.9967  Validation loss = 1.5837  \n",
      "\n",
      "Fold: 24  Epoch: 410  Training loss = 3.9963  Validation loss = 1.5834  \n",
      "\n",
      "Fold: 24  Epoch: 411  Training loss = 3.9960  Validation loss = 1.5832  \n",
      "\n",
      "Fold: 24  Epoch: 412  Training loss = 3.9957  Validation loss = 1.5830  \n",
      "\n",
      "Fold: 24  Epoch: 413  Training loss = 3.9954  Validation loss = 1.5827  \n",
      "\n",
      "Fold: 24  Epoch: 414  Training loss = 3.9951  Validation loss = 1.5826  \n",
      "\n",
      "Fold: 24  Epoch: 415  Training loss = 3.9948  Validation loss = 1.5823  \n",
      "\n",
      "Fold: 24  Epoch: 416  Training loss = 3.9946  Validation loss = 1.5821  \n",
      "\n",
      "Fold: 24  Epoch: 417  Training loss = 3.9943  Validation loss = 1.5818  \n",
      "\n",
      "Fold: 24  Epoch: 418  Training loss = 3.9940  Validation loss = 1.5818  \n",
      "\n",
      "Fold: 24  Epoch: 419  Training loss = 3.9938  Validation loss = 1.5816  \n",
      "\n",
      "Fold: 24  Epoch: 420  Training loss = 3.9934  Validation loss = 1.5813  \n",
      "\n",
      "Fold: 24  Epoch: 421  Training loss = 3.9931  Validation loss = 1.5811  \n",
      "\n",
      "Fold: 24  Epoch: 422  Training loss = 3.9927  Validation loss = 1.5807  \n",
      "\n",
      "Fold: 24  Epoch: 423  Training loss = 3.9923  Validation loss = 1.5803  \n",
      "\n",
      "Fold: 24  Epoch: 424  Training loss = 3.9918  Validation loss = 1.5800  \n",
      "\n",
      "Fold: 24  Epoch: 425  Training loss = 3.9916  Validation loss = 1.5798  \n",
      "\n",
      "Fold: 24  Epoch: 426  Training loss = 3.9912  Validation loss = 1.5796  \n",
      "\n",
      "Fold: 24  Epoch: 427  Training loss = 3.9909  Validation loss = 1.5794  \n",
      "\n",
      "Fold: 24  Epoch: 428  Training loss = 3.9905  Validation loss = 1.5791  \n",
      "\n",
      "Fold: 24  Epoch: 429  Training loss = 3.9903  Validation loss = 1.5790  \n",
      "\n",
      "Fold: 24  Epoch: 430  Training loss = 3.9900  Validation loss = 1.5788  \n",
      "\n",
      "Fold: 24  Epoch: 431  Training loss = 3.9898  Validation loss = 1.5788  \n",
      "\n",
      "Fold: 24  Epoch: 432  Training loss = 3.9895  Validation loss = 1.5786  \n",
      "\n",
      "Fold: 24  Epoch: 433  Training loss = 3.9892  Validation loss = 1.5784  \n",
      "\n",
      "Fold: 24  Epoch: 434  Training loss = 3.9889  Validation loss = 1.5782  \n",
      "\n",
      "Fold: 24  Epoch: 435  Training loss = 3.9887  Validation loss = 1.5781  \n",
      "\n",
      "Fold: 24  Epoch: 436  Training loss = 3.9884  Validation loss = 1.5779  \n",
      "\n",
      "Fold: 24  Epoch: 437  Training loss = 3.9881  Validation loss = 1.5777  \n",
      "\n",
      "Fold: 24  Epoch: 438  Training loss = 3.9878  Validation loss = 1.5775  \n",
      "\n",
      "Fold: 24  Epoch: 439  Training loss = 3.9875  Validation loss = 1.5773  \n",
      "\n",
      "Fold: 24  Epoch: 440  Training loss = 3.9872  Validation loss = 1.5770  \n",
      "\n",
      "Fold: 24  Epoch: 441  Training loss = 3.9870  Validation loss = 1.5769  \n",
      "\n",
      "Fold: 24  Epoch: 442  Training loss = 3.9867  Validation loss = 1.5766  \n",
      "\n",
      "Fold: 24  Epoch: 443  Training loss = 3.9864  Validation loss = 1.5763  \n",
      "\n",
      "Fold: 24  Epoch: 444  Training loss = 3.9862  Validation loss = 1.5762  \n",
      "\n",
      "Fold: 24  Epoch: 445  Training loss = 3.9859  Validation loss = 1.5759  \n",
      "\n",
      "Fold: 24  Epoch: 446  Training loss = 3.9855  Validation loss = 1.5757  \n",
      "\n",
      "Fold: 24  Epoch: 447  Training loss = 3.9853  Validation loss = 1.5756  \n",
      "\n",
      "Fold: 24  Epoch: 448  Training loss = 3.9850  Validation loss = 1.5753  \n",
      "\n",
      "Fold: 24  Epoch: 449  Training loss = 3.9846  Validation loss = 1.5751  \n",
      "\n",
      "Fold: 24  Epoch: 450  Training loss = 3.9842  Validation loss = 1.5749  \n",
      "\n",
      "Fold: 24  Epoch: 451  Training loss = 3.9839  Validation loss = 1.5746  \n",
      "\n",
      "Fold: 24  Epoch: 452  Training loss = 3.9836  Validation loss = 1.5742  \n",
      "\n",
      "Fold: 24  Epoch: 453  Training loss = 3.9833  Validation loss = 1.5740  \n",
      "\n",
      "Fold: 24  Epoch: 454  Training loss = 3.9831  Validation loss = 1.5739  \n",
      "\n",
      "Fold: 24  Epoch: 455  Training loss = 3.9828  Validation loss = 1.5738  \n",
      "\n",
      "Fold: 24  Epoch: 456  Training loss = 3.9825  Validation loss = 1.5737  \n",
      "\n",
      "Fold: 24  Epoch: 457  Training loss = 3.9822  Validation loss = 1.5735  \n",
      "\n",
      "Fold: 24  Epoch: 458  Training loss = 3.9819  Validation loss = 1.5733  \n",
      "\n",
      "Fold: 24  Epoch: 459  Training loss = 3.9817  Validation loss = 1.5731  \n",
      "\n",
      "Fold: 24  Epoch: 460  Training loss = 3.9814  Validation loss = 1.5729  \n",
      "\n",
      "Fold: 24  Epoch: 461  Training loss = 3.9811  Validation loss = 1.5728  \n",
      "\n",
      "Fold: 24  Epoch: 462  Training loss = 3.9808  Validation loss = 1.5726  \n",
      "\n",
      "Fold: 24  Epoch: 463  Training loss = 3.9805  Validation loss = 1.5725  \n",
      "\n",
      "Fold: 24  Epoch: 464  Training loss = 3.9802  Validation loss = 1.5722  \n",
      "\n",
      "Fold: 24  Epoch: 465  Training loss = 3.9798  Validation loss = 1.5720  \n",
      "\n",
      "Fold: 24  Epoch: 466  Training loss = 3.9793  Validation loss = 1.5715  \n",
      "\n",
      "Fold: 24  Epoch: 467  Training loss = 3.9789  Validation loss = 1.5712  \n",
      "\n",
      "Fold: 24  Epoch: 468  Training loss = 3.9784  Validation loss = 1.5709  \n",
      "\n",
      "Fold: 24  Epoch: 469  Training loss = 3.9781  Validation loss = 1.5706  \n",
      "\n",
      "Fold: 24  Epoch: 470  Training loss = 3.9778  Validation loss = 1.5704  \n",
      "\n",
      "Fold: 24  Epoch: 471  Training loss = 3.9775  Validation loss = 1.5702  \n",
      "\n",
      "Fold: 24  Epoch: 472  Training loss = 3.9771  Validation loss = 1.5700  \n",
      "\n",
      "Fold: 24  Epoch: 473  Training loss = 3.9769  Validation loss = 1.5698  \n",
      "\n",
      "Fold: 24  Epoch: 474  Training loss = 3.9765  Validation loss = 1.5696  \n",
      "\n",
      "Fold: 24  Epoch: 475  Training loss = 3.9762  Validation loss = 1.5693  \n",
      "\n",
      "Fold: 24  Epoch: 476  Training loss = 3.9760  Validation loss = 1.5692  \n",
      "\n",
      "Fold: 24  Epoch: 477  Training loss = 3.9756  Validation loss = 1.5690  \n",
      "\n",
      "Fold: 24  Epoch: 478  Training loss = 3.9753  Validation loss = 1.5688  \n",
      "\n",
      "Fold: 24  Epoch: 479  Training loss = 3.9750  Validation loss = 1.5687  \n",
      "\n",
      "Fold: 24  Epoch: 480  Training loss = 3.9747  Validation loss = 1.5684  \n",
      "\n",
      "Fold: 24  Epoch: 481  Training loss = 3.9744  Validation loss = 1.5682  \n",
      "\n",
      "Fold: 24  Epoch: 482  Training loss = 3.9742  Validation loss = 1.5680  \n",
      "\n",
      "Fold: 24  Epoch: 483  Training loss = 3.9738  Validation loss = 1.5677  \n",
      "\n",
      "Fold: 24  Epoch: 484  Training loss = 3.9734  Validation loss = 1.5674  \n",
      "\n",
      "Fold: 24  Epoch: 485  Training loss = 3.9732  Validation loss = 1.5673  \n",
      "\n",
      "Fold: 24  Epoch: 486  Training loss = 3.9729  Validation loss = 1.5670  \n",
      "\n",
      "Fold: 24  Epoch: 487  Training loss = 3.9725  Validation loss = 1.5668  \n",
      "\n",
      "Fold: 24  Epoch: 488  Training loss = 3.9722  Validation loss = 1.5667  \n",
      "\n",
      "Fold: 24  Epoch: 489  Training loss = 3.9720  Validation loss = 1.5664  \n",
      "\n",
      "Fold: 24  Epoch: 490  Training loss = 3.9716  Validation loss = 1.5662  \n",
      "\n",
      "Fold: 24  Epoch: 491  Training loss = 3.9713  Validation loss = 1.5660  \n",
      "\n",
      "Fold: 24  Epoch: 492  Training loss = 3.9710  Validation loss = 1.5658  \n",
      "\n",
      "Fold: 24  Epoch: 493  Training loss = 3.9707  Validation loss = 1.5655  \n",
      "\n",
      "Fold: 24  Epoch: 494  Training loss = 3.9704  Validation loss = 1.5654  \n",
      "\n",
      "Fold: 24  Epoch: 495  Training loss = 3.9702  Validation loss = 1.5652  \n",
      "\n",
      "Fold: 24  Epoch: 496  Training loss = 3.9698  Validation loss = 1.5649  \n",
      "\n",
      "Fold: 24  Epoch: 497  Training loss = 3.9695  Validation loss = 1.5648  \n",
      "\n",
      "Fold: 24  Epoch: 498  Training loss = 3.9692  Validation loss = 1.5647  \n",
      "\n",
      "Fold: 24  Epoch: 499  Training loss = 3.9689  Validation loss = 1.5646  \n",
      "\n",
      "Fold: 24  Epoch: 500  Training loss = 3.9687  Validation loss = 1.5644  \n",
      "\n",
      "Check model:  Fold: 24  Optimal epoch: 500  \n",
      "\n",
      "Fold: 25  Epoch: 1  Training loss = 3.9373  Validation loss = 2.4600  \n",
      "\n",
      "Fold: 25  Epoch: 2  Training loss = 3.9370  Validation loss = 2.4596  \n",
      "\n",
      "Fold: 25  Epoch: 3  Training loss = 3.9367  Validation loss = 2.4591  \n",
      "\n",
      "Fold: 25  Epoch: 4  Training loss = 3.9364  Validation loss = 2.4587  \n",
      "\n",
      "Fold: 25  Epoch: 5  Training loss = 3.9360  Validation loss = 2.4581  \n",
      "\n",
      "Fold: 25  Epoch: 6  Training loss = 3.9357  Validation loss = 2.4577  \n",
      "\n",
      "Fold: 25  Epoch: 7  Training loss = 3.9355  Validation loss = 2.4574  \n",
      "\n",
      "Fold: 25  Epoch: 8  Training loss = 3.9353  Validation loss = 2.4571  \n",
      "\n",
      "Fold: 25  Epoch: 9  Training loss = 3.9350  Validation loss = 2.4565  \n",
      "\n",
      "Fold: 25  Epoch: 10  Training loss = 3.9348  Validation loss = 2.4562  \n",
      "\n",
      "Fold: 25  Epoch: 11  Training loss = 3.9345  Validation loss = 2.4559  \n",
      "\n",
      "Fold: 25  Epoch: 12  Training loss = 3.9343  Validation loss = 2.4556  \n",
      "\n",
      "Fold: 25  Epoch: 13  Training loss = 3.9340  Validation loss = 2.4552  \n",
      "\n",
      "Fold: 25  Epoch: 14  Training loss = 3.9337  Validation loss = 2.4548  \n",
      "\n",
      "Fold: 25  Epoch: 15  Training loss = 3.9334  Validation loss = 2.4544  \n",
      "\n",
      "Fold: 25  Epoch: 16  Training loss = 3.9332  Validation loss = 2.4541  \n",
      "\n",
      "Fold: 25  Epoch: 17  Training loss = 3.9329  Validation loss = 2.4539  \n",
      "\n",
      "Fold: 25  Epoch: 18  Training loss = 3.9326  Validation loss = 2.4536  \n",
      "\n",
      "Fold: 25  Epoch: 19  Training loss = 3.9324  Validation loss = 2.4534  \n",
      "\n",
      "Fold: 25  Epoch: 20  Training loss = 3.9321  Validation loss = 2.4530  \n",
      "\n",
      "Fold: 25  Epoch: 21  Training loss = 3.9318  Validation loss = 2.4526  \n",
      "\n",
      "Fold: 25  Epoch: 22  Training loss = 3.9315  Validation loss = 2.4522  \n",
      "\n",
      "Fold: 25  Epoch: 23  Training loss = 3.9313  Validation loss = 2.4520  \n",
      "\n",
      "Fold: 25  Epoch: 24  Training loss = 3.9310  Validation loss = 2.4517  \n",
      "\n",
      "Fold: 25  Epoch: 25  Training loss = 3.9308  Validation loss = 2.4513  \n",
      "\n",
      "Fold: 25  Epoch: 26  Training loss = 3.9305  Validation loss = 2.4509  \n",
      "\n",
      "Fold: 25  Epoch: 27  Training loss = 3.9303  Validation loss = 2.4505  \n",
      "\n",
      "Fold: 25  Epoch: 28  Training loss = 3.9301  Validation loss = 2.4501  \n",
      "\n",
      "Fold: 25  Epoch: 29  Training loss = 3.9298  Validation loss = 2.4497  \n",
      "\n",
      "Fold: 25  Epoch: 30  Training loss = 3.9295  Validation loss = 2.4492  \n",
      "\n",
      "Fold: 25  Epoch: 31  Training loss = 3.9292  Validation loss = 2.4489  \n",
      "\n",
      "Fold: 25  Epoch: 32  Training loss = 3.9289  Validation loss = 2.4484  \n",
      "\n",
      "Fold: 25  Epoch: 33  Training loss = 3.9286  Validation loss = 2.4481  \n",
      "\n",
      "Fold: 25  Epoch: 34  Training loss = 3.9282  Validation loss = 2.4475  \n",
      "\n",
      "Fold: 25  Epoch: 35  Training loss = 3.9280  Validation loss = 2.4470  \n",
      "\n",
      "Fold: 25  Epoch: 36  Training loss = 3.9277  Validation loss = 2.4467  \n",
      "\n",
      "Fold: 25  Epoch: 37  Training loss = 3.9274  Validation loss = 2.4462  \n",
      "\n",
      "Fold: 25  Epoch: 38  Training loss = 3.9271  Validation loss = 2.4457  \n",
      "\n",
      "Fold: 25  Epoch: 39  Training loss = 3.9267  Validation loss = 2.4452  \n",
      "\n",
      "Fold: 25  Epoch: 40  Training loss = 3.9264  Validation loss = 2.4446  \n",
      "\n",
      "Fold: 25  Epoch: 41  Training loss = 3.9261  Validation loss = 2.4445  \n",
      "\n",
      "Fold: 25  Epoch: 42  Training loss = 3.9258  Validation loss = 2.4440  \n",
      "\n",
      "Fold: 25  Epoch: 43  Training loss = 3.9255  Validation loss = 2.4436  \n",
      "\n",
      "Fold: 25  Epoch: 44  Training loss = 3.9251  Validation loss = 2.4432  \n",
      "\n",
      "Fold: 25  Epoch: 45  Training loss = 3.9249  Validation loss = 2.4430  \n",
      "\n",
      "Fold: 25  Epoch: 46  Training loss = 3.9246  Validation loss = 2.4427  \n",
      "\n",
      "Fold: 25  Epoch: 47  Training loss = 3.9243  Validation loss = 2.4423  \n",
      "\n",
      "Fold: 25  Epoch: 48  Training loss = 3.9239  Validation loss = 2.4419  \n",
      "\n",
      "Fold: 25  Epoch: 49  Training loss = 3.9236  Validation loss = 2.4414  \n",
      "\n",
      "Fold: 25  Epoch: 50  Training loss = 3.9234  Validation loss = 2.4410  \n",
      "\n",
      "Fold: 25  Epoch: 51  Training loss = 3.9233  Validation loss = 2.4409  \n",
      "\n",
      "Fold: 25  Epoch: 52  Training loss = 3.9230  Validation loss = 2.4405  \n",
      "\n",
      "Fold: 25  Epoch: 53  Training loss = 3.9226  Validation loss = 2.4401  \n",
      "\n",
      "Fold: 25  Epoch: 54  Training loss = 3.9223  Validation loss = 2.4395  \n",
      "\n",
      "Fold: 25  Epoch: 55  Training loss = 3.9221  Validation loss = 2.4393  \n",
      "\n",
      "Fold: 25  Epoch: 56  Training loss = 3.9218  Validation loss = 2.4389  \n",
      "\n",
      "Fold: 25  Epoch: 57  Training loss = 3.9216  Validation loss = 2.4386  \n",
      "\n",
      "Fold: 25  Epoch: 58  Training loss = 3.9212  Validation loss = 2.4380  \n",
      "\n",
      "Fold: 25  Epoch: 59  Training loss = 3.9210  Validation loss = 2.4378  \n",
      "\n",
      "Fold: 25  Epoch: 60  Training loss = 3.9207  Validation loss = 2.4375  \n",
      "\n",
      "Fold: 25  Epoch: 61  Training loss = 3.9203  Validation loss = 2.4370  \n",
      "\n",
      "Fold: 25  Epoch: 62  Training loss = 3.9201  Validation loss = 2.4367  \n",
      "\n",
      "Fold: 25  Epoch: 63  Training loss = 3.9198  Validation loss = 2.4363  \n",
      "\n",
      "Fold: 25  Epoch: 64  Training loss = 3.9195  Validation loss = 2.4359  \n",
      "\n",
      "Fold: 25  Epoch: 65  Training loss = 3.9192  Validation loss = 2.4355  \n",
      "\n",
      "Fold: 25  Epoch: 66  Training loss = 3.9188  Validation loss = 2.4351  \n",
      "\n",
      "Fold: 25  Epoch: 67  Training loss = 3.9186  Validation loss = 2.4350  \n",
      "\n",
      "Fold: 25  Epoch: 68  Training loss = 3.9183  Validation loss = 2.4345  \n",
      "\n",
      "Fold: 25  Epoch: 69  Training loss = 3.9180  Validation loss = 2.4341  \n",
      "\n",
      "Fold: 25  Epoch: 70  Training loss = 3.9177  Validation loss = 2.4337  \n",
      "\n",
      "Fold: 25  Epoch: 71  Training loss = 3.9174  Validation loss = 2.4333  \n",
      "\n",
      "Fold: 25  Epoch: 72  Training loss = 3.9172  Validation loss = 2.4330  \n",
      "\n",
      "Fold: 25  Epoch: 73  Training loss = 3.9169  Validation loss = 2.4326  \n",
      "\n",
      "Fold: 25  Epoch: 74  Training loss = 3.9166  Validation loss = 2.4321  \n",
      "\n",
      "Fold: 25  Epoch: 75  Training loss = 3.9162  Validation loss = 2.4318  \n",
      "\n",
      "Fold: 25  Epoch: 76  Training loss = 3.9160  Validation loss = 2.4315  \n",
      "\n",
      "Fold: 25  Epoch: 77  Training loss = 3.9158  Validation loss = 2.4314  \n",
      "\n",
      "Fold: 25  Epoch: 78  Training loss = 3.9155  Validation loss = 2.4311  \n",
      "\n",
      "Fold: 25  Epoch: 79  Training loss = 3.9152  Validation loss = 2.4307  \n",
      "\n",
      "Fold: 25  Epoch: 80  Training loss = 3.9150  Validation loss = 2.4303  \n",
      "\n",
      "Fold: 25  Epoch: 81  Training loss = 3.9147  Validation loss = 2.4298  \n",
      "\n",
      "Fold: 25  Epoch: 82  Training loss = 3.9144  Validation loss = 2.4295  \n",
      "\n",
      "Fold: 25  Epoch: 83  Training loss = 3.9142  Validation loss = 2.4291  \n",
      "\n",
      "Fold: 25  Epoch: 84  Training loss = 3.9138  Validation loss = 2.4285  \n",
      "\n",
      "Fold: 25  Epoch: 85  Training loss = 3.9134  Validation loss = 2.4280  \n",
      "\n",
      "Fold: 25  Epoch: 86  Training loss = 3.9131  Validation loss = 2.4276  \n",
      "\n",
      "Fold: 25  Epoch: 87  Training loss = 3.9130  Validation loss = 2.4274  \n",
      "\n",
      "Fold: 25  Epoch: 88  Training loss = 3.9128  Validation loss = 2.4272  \n",
      "\n",
      "Fold: 25  Epoch: 89  Training loss = 3.9125  Validation loss = 2.4267  \n",
      "\n",
      "Fold: 25  Epoch: 90  Training loss = 3.9123  Validation loss = 2.4265  \n",
      "\n",
      "Fold: 25  Epoch: 91  Training loss = 3.9120  Validation loss = 2.4261  \n",
      "\n",
      "Fold: 25  Epoch: 92  Training loss = 3.9118  Validation loss = 2.4258  \n",
      "\n",
      "Fold: 25  Epoch: 93  Training loss = 3.9114  Validation loss = 2.4253  \n",
      "\n",
      "Fold: 25  Epoch: 94  Training loss = 3.9112  Validation loss = 2.4250  \n",
      "\n",
      "Fold: 25  Epoch: 95  Training loss = 3.9110  Validation loss = 2.4247  \n",
      "\n",
      "Fold: 25  Epoch: 96  Training loss = 3.9107  Validation loss = 2.4244  \n",
      "\n",
      "Fold: 25  Epoch: 97  Training loss = 3.9103  Validation loss = 2.4238  \n",
      "\n",
      "Fold: 25  Epoch: 98  Training loss = 3.9099  Validation loss = 2.4233  \n",
      "\n",
      "Fold: 25  Epoch: 99  Training loss = 3.9096  Validation loss = 2.4230  \n",
      "\n",
      "Fold: 25  Epoch: 100  Training loss = 3.9094  Validation loss = 2.4227  \n",
      "\n",
      "Fold: 25  Epoch: 101  Training loss = 3.9091  Validation loss = 2.4223  \n",
      "\n",
      "Fold: 25  Epoch: 102  Training loss = 3.9088  Validation loss = 2.4219  \n",
      "\n",
      "Fold: 25  Epoch: 103  Training loss = 3.9086  Validation loss = 2.4216  \n",
      "\n",
      "Fold: 25  Epoch: 104  Training loss = 3.9083  Validation loss = 2.4213  \n",
      "\n",
      "Fold: 25  Epoch: 105  Training loss = 3.9080  Validation loss = 2.4208  \n",
      "\n",
      "Fold: 25  Epoch: 106  Training loss = 3.9077  Validation loss = 2.4203  \n",
      "\n",
      "Fold: 25  Epoch: 107  Training loss = 3.9074  Validation loss = 2.4198  \n",
      "\n",
      "Fold: 25  Epoch: 108  Training loss = 3.9071  Validation loss = 2.4194  \n",
      "\n",
      "Fold: 25  Epoch: 109  Training loss = 3.9069  Validation loss = 2.4192  \n",
      "\n",
      "Fold: 25  Epoch: 110  Training loss = 3.9066  Validation loss = 2.4188  \n",
      "\n",
      "Fold: 25  Epoch: 111  Training loss = 3.9063  Validation loss = 2.4186  \n",
      "\n",
      "Fold: 25  Epoch: 112  Training loss = 3.9060  Validation loss = 2.4183  \n",
      "\n",
      "Fold: 25  Epoch: 113  Training loss = 3.9058  Validation loss = 2.4180  \n",
      "\n",
      "Fold: 25  Epoch: 114  Training loss = 3.9055  Validation loss = 2.4175  \n",
      "\n",
      "Fold: 25  Epoch: 115  Training loss = 3.9051  Validation loss = 2.4170  \n",
      "\n",
      "Fold: 25  Epoch: 116  Training loss = 3.9048  Validation loss = 2.4166  \n",
      "\n",
      "Fold: 25  Epoch: 117  Training loss = 3.9045  Validation loss = 2.4162  \n",
      "\n",
      "Fold: 25  Epoch: 118  Training loss = 3.9043  Validation loss = 2.4159  \n",
      "\n",
      "Fold: 25  Epoch: 119  Training loss = 3.9041  Validation loss = 2.4157  \n",
      "\n",
      "Fold: 25  Epoch: 120  Training loss = 3.9038  Validation loss = 2.4152  \n",
      "\n",
      "Fold: 25  Epoch: 121  Training loss = 3.9036  Validation loss = 2.4151  \n",
      "\n",
      "Fold: 25  Epoch: 122  Training loss = 3.9032  Validation loss = 2.4146  \n",
      "\n",
      "Fold: 25  Epoch: 123  Training loss = 3.9030  Validation loss = 2.4144  \n",
      "\n",
      "Fold: 25  Epoch: 124  Training loss = 3.9028  Validation loss = 2.4139  \n",
      "\n",
      "Fold: 25  Epoch: 125  Training loss = 3.9026  Validation loss = 2.4136  \n",
      "\n",
      "Fold: 25  Epoch: 126  Training loss = 3.9022  Validation loss = 2.4132  \n",
      "\n",
      "Fold: 25  Epoch: 127  Training loss = 3.9019  Validation loss = 2.4127  \n",
      "\n",
      "Fold: 25  Epoch: 128  Training loss = 3.9017  Validation loss = 2.4124  \n",
      "\n",
      "Fold: 25  Epoch: 129  Training loss = 3.9015  Validation loss = 2.4121  \n",
      "\n",
      "Fold: 25  Epoch: 130  Training loss = 3.9013  Validation loss = 2.4119  \n",
      "\n",
      "Fold: 25  Epoch: 131  Training loss = 3.9010  Validation loss = 2.4117  \n",
      "\n",
      "Fold: 25  Epoch: 132  Training loss = 3.9008  Validation loss = 2.4116  \n",
      "\n",
      "Fold: 25  Epoch: 133  Training loss = 3.9005  Validation loss = 2.4111  \n",
      "\n",
      "Fold: 25  Epoch: 134  Training loss = 3.9002  Validation loss = 2.4105  \n",
      "\n",
      "Fold: 25  Epoch: 135  Training loss = 3.8999  Validation loss = 2.4102  \n",
      "\n",
      "Fold: 25  Epoch: 136  Training loss = 3.8996  Validation loss = 2.4098  \n",
      "\n",
      "Fold: 25  Epoch: 137  Training loss = 3.8994  Validation loss = 2.4096  \n",
      "\n",
      "Fold: 25  Epoch: 138  Training loss = 3.8990  Validation loss = 2.4090  \n",
      "\n",
      "Fold: 25  Epoch: 139  Training loss = 3.8987  Validation loss = 2.4085  \n",
      "\n",
      "Fold: 25  Epoch: 140  Training loss = 3.8984  Validation loss = 2.4080  \n",
      "\n",
      "Fold: 25  Epoch: 141  Training loss = 3.8980  Validation loss = 2.4074  \n",
      "\n",
      "Fold: 25  Epoch: 142  Training loss = 3.8977  Validation loss = 2.4071  \n",
      "\n",
      "Fold: 25  Epoch: 143  Training loss = 3.8975  Validation loss = 2.4068  \n",
      "\n",
      "Fold: 25  Epoch: 144  Training loss = 3.8973  Validation loss = 2.4066  \n",
      "\n",
      "Fold: 25  Epoch: 145  Training loss = 3.8972  Validation loss = 2.4065  \n",
      "\n",
      "Fold: 25  Epoch: 146  Training loss = 3.8969  Validation loss = 2.4062  \n",
      "\n",
      "Fold: 25  Epoch: 147  Training loss = 3.8966  Validation loss = 2.4058  \n",
      "\n",
      "Fold: 25  Epoch: 148  Training loss = 3.8963  Validation loss = 2.4055  \n",
      "\n",
      "Fold: 25  Epoch: 149  Training loss = 3.8960  Validation loss = 2.4049  \n",
      "\n",
      "Fold: 25  Epoch: 150  Training loss = 3.8956  Validation loss = 2.4043  \n",
      "\n",
      "Fold: 25  Epoch: 151  Training loss = 3.8953  Validation loss = 2.4039  \n",
      "\n",
      "Fold: 25  Epoch: 152  Training loss = 3.8950  Validation loss = 2.4035  \n",
      "\n",
      "Fold: 25  Epoch: 153  Training loss = 3.8946  Validation loss = 2.4031  \n",
      "\n",
      "Fold: 25  Epoch: 154  Training loss = 3.8944  Validation loss = 2.4027  \n",
      "\n",
      "Fold: 25  Epoch: 155  Training loss = 3.8940  Validation loss = 2.4021  \n",
      "\n",
      "Fold: 25  Epoch: 156  Training loss = 3.8937  Validation loss = 2.4017  \n",
      "\n",
      "Fold: 25  Epoch: 157  Training loss = 3.8929  Validation loss = 2.4007  \n",
      "\n",
      "Fold: 25  Epoch: 158  Training loss = 3.8920  Validation loss = 2.4000  \n",
      "\n",
      "Fold: 25  Epoch: 159  Training loss = 3.8916  Validation loss = 2.3995  \n",
      "\n",
      "Fold: 25  Epoch: 160  Training loss = 3.8913  Validation loss = 2.3992  \n",
      "\n",
      "Fold: 25  Epoch: 161  Training loss = 3.8908  Validation loss = 2.3987  \n",
      "\n",
      "Fold: 25  Epoch: 162  Training loss = 3.8904  Validation loss = 2.3982  \n",
      "\n",
      "Fold: 25  Epoch: 163  Training loss = 3.8900  Validation loss = 2.3977  \n",
      "\n",
      "Fold: 25  Epoch: 164  Training loss = 3.8897  Validation loss = 2.3972  \n",
      "\n",
      "Fold: 25  Epoch: 165  Training loss = 3.8894  Validation loss = 2.3970  \n",
      "\n",
      "Fold: 25  Epoch: 166  Training loss = 3.8892  Validation loss = 2.3967  \n",
      "\n",
      "Fold: 25  Epoch: 167  Training loss = 3.8889  Validation loss = 2.3964  \n",
      "\n",
      "Fold: 25  Epoch: 168  Training loss = 3.8887  Validation loss = 2.3961  \n",
      "\n",
      "Fold: 25  Epoch: 169  Training loss = 3.8884  Validation loss = 2.3960  \n",
      "\n",
      "Fold: 25  Epoch: 170  Training loss = 3.8881  Validation loss = 2.3955  \n",
      "\n",
      "Fold: 25  Epoch: 171  Training loss = 3.8878  Validation loss = 2.3950  \n",
      "\n",
      "Fold: 25  Epoch: 172  Training loss = 3.8876  Validation loss = 2.3947  \n",
      "\n",
      "Fold: 25  Epoch: 173  Training loss = 3.8874  Validation loss = 2.3946  \n",
      "\n",
      "Fold: 25  Epoch: 174  Training loss = 3.8872  Validation loss = 2.3943  \n",
      "\n",
      "Fold: 25  Epoch: 175  Training loss = 3.8870  Validation loss = 2.3942  \n",
      "\n",
      "Fold: 25  Epoch: 176  Training loss = 3.8868  Validation loss = 2.3938  \n",
      "\n",
      "Fold: 25  Epoch: 177  Training loss = 3.8864  Validation loss = 2.3933  \n",
      "\n",
      "Fold: 25  Epoch: 178  Training loss = 3.8861  Validation loss = 2.3928  \n",
      "\n",
      "Fold: 25  Epoch: 179  Training loss = 3.8858  Validation loss = 2.3922  \n",
      "\n",
      "Fold: 25  Epoch: 180  Training loss = 3.8855  Validation loss = 2.3918  \n",
      "\n",
      "Fold: 25  Epoch: 181  Training loss = 3.8853  Validation loss = 2.3916  \n",
      "\n",
      "Fold: 25  Epoch: 182  Training loss = 3.8850  Validation loss = 2.3913  \n",
      "\n",
      "Fold: 25  Epoch: 183  Training loss = 3.8848  Validation loss = 2.3910  \n",
      "\n",
      "Fold: 25  Epoch: 184  Training loss = 3.8845  Validation loss = 2.3907  \n",
      "\n",
      "Fold: 25  Epoch: 185  Training loss = 3.8843  Validation loss = 2.3904  \n",
      "\n",
      "Fold: 25  Epoch: 186  Training loss = 3.8842  Validation loss = 2.3901  \n",
      "\n",
      "Fold: 25  Epoch: 187  Training loss = 3.8839  Validation loss = 2.3897  \n",
      "\n",
      "Fold: 25  Epoch: 188  Training loss = 3.8836  Validation loss = 2.3894  \n",
      "\n",
      "Fold: 25  Epoch: 189  Training loss = 3.8832  Validation loss = 2.3890  \n",
      "\n",
      "Fold: 25  Epoch: 190  Training loss = 3.8829  Validation loss = 2.3886  \n",
      "\n",
      "Fold: 25  Epoch: 191  Training loss = 3.8827  Validation loss = 2.3882  \n",
      "\n",
      "Fold: 25  Epoch: 192  Training loss = 3.8824  Validation loss = 2.3878  \n",
      "\n",
      "Fold: 25  Epoch: 193  Training loss = 3.8822  Validation loss = 2.3875  \n",
      "\n",
      "Fold: 25  Epoch: 194  Training loss = 3.8819  Validation loss = 2.3872  \n",
      "\n",
      "Fold: 25  Epoch: 195  Training loss = 3.8817  Validation loss = 2.3868  \n",
      "\n",
      "Fold: 25  Epoch: 196  Training loss = 3.8813  Validation loss = 2.3863  \n",
      "\n",
      "Fold: 25  Epoch: 197  Training loss = 3.8811  Validation loss = 2.3859  \n",
      "\n",
      "Fold: 25  Epoch: 198  Training loss = 3.8809  Validation loss = 2.3856  \n",
      "\n",
      "Fold: 25  Epoch: 199  Training loss = 3.8806  Validation loss = 2.3851  \n",
      "\n",
      "Fold: 25  Epoch: 200  Training loss = 3.8803  Validation loss = 2.3847  \n",
      "\n",
      "Fold: 25  Epoch: 201  Training loss = 3.8800  Validation loss = 2.3844  \n",
      "\n",
      "Fold: 25  Epoch: 202  Training loss = 3.8798  Validation loss = 2.3840  \n",
      "\n",
      "Fold: 25  Epoch: 203  Training loss = 3.8794  Validation loss = 2.3837  \n",
      "\n",
      "Fold: 25  Epoch: 204  Training loss = 3.8792  Validation loss = 2.3833  \n",
      "\n",
      "Fold: 25  Epoch: 205  Training loss = 3.8790  Validation loss = 2.3830  \n",
      "\n",
      "Fold: 25  Epoch: 206  Training loss = 3.8786  Validation loss = 2.3824  \n",
      "\n",
      "Fold: 25  Epoch: 207  Training loss = 3.8783  Validation loss = 2.3819  \n",
      "\n",
      "Fold: 25  Epoch: 208  Training loss = 3.8780  Validation loss = 2.3815  \n",
      "\n",
      "Fold: 25  Epoch: 209  Training loss = 3.8778  Validation loss = 2.3812  \n",
      "\n",
      "Fold: 25  Epoch: 210  Training loss = 3.8775  Validation loss = 2.3808  \n",
      "\n",
      "Fold: 25  Epoch: 211  Training loss = 3.8772  Validation loss = 2.3802  \n",
      "\n",
      "Fold: 25  Epoch: 212  Training loss = 3.8769  Validation loss = 2.3796  \n",
      "\n",
      "Fold: 25  Epoch: 213  Training loss = 3.8767  Validation loss = 2.3795  \n",
      "\n",
      "Fold: 25  Epoch: 214  Training loss = 3.8765  Validation loss = 2.3793  \n",
      "\n",
      "Fold: 25  Epoch: 215  Training loss = 3.8761  Validation loss = 2.3788  \n",
      "\n",
      "Fold: 25  Epoch: 216  Training loss = 3.8759  Validation loss = 2.3787  \n",
      "\n",
      "Fold: 25  Epoch: 217  Training loss = 3.8756  Validation loss = 2.3783  \n",
      "\n",
      "Fold: 25  Epoch: 218  Training loss = 3.8754  Validation loss = 2.3782  \n",
      "\n",
      "Fold: 25  Epoch: 219  Training loss = 3.8751  Validation loss = 2.3776  \n",
      "\n",
      "Fold: 25  Epoch: 220  Training loss = 3.8748  Validation loss = 2.3772  \n",
      "\n",
      "Fold: 25  Epoch: 221  Training loss = 3.8745  Validation loss = 2.3770  \n",
      "\n",
      "Fold: 25  Epoch: 222  Training loss = 3.8743  Validation loss = 2.3768  \n",
      "\n",
      "Fold: 25  Epoch: 223  Training loss = 3.8740  Validation loss = 2.3762  \n",
      "\n",
      "Fold: 25  Epoch: 224  Training loss = 3.8737  Validation loss = 2.3758  \n",
      "\n",
      "Fold: 25  Epoch: 225  Training loss = 3.8735  Validation loss = 2.3755  \n",
      "\n",
      "Fold: 25  Epoch: 226  Training loss = 3.8733  Validation loss = 2.3753  \n",
      "\n",
      "Fold: 25  Epoch: 227  Training loss = 3.8730  Validation loss = 2.3749  \n",
      "\n",
      "Fold: 25  Epoch: 228  Training loss = 3.8728  Validation loss = 2.3745  \n",
      "\n",
      "Fold: 25  Epoch: 229  Training loss = 3.8725  Validation loss = 2.3740  \n",
      "\n",
      "Fold: 25  Epoch: 230  Training loss = 3.8722  Validation loss = 2.3738  \n",
      "\n",
      "Fold: 25  Epoch: 231  Training loss = 3.8719  Validation loss = 2.3733  \n",
      "\n",
      "Fold: 25  Epoch: 232  Training loss = 3.8716  Validation loss = 2.3731  \n",
      "\n",
      "Fold: 25  Epoch: 233  Training loss = 3.8715  Validation loss = 2.3731  \n",
      "\n",
      "Fold: 25  Epoch: 234  Training loss = 3.8711  Validation loss = 2.3726  \n",
      "\n",
      "Fold: 25  Epoch: 235  Training loss = 3.8709  Validation loss = 2.3722  \n",
      "\n",
      "Fold: 25  Epoch: 236  Training loss = 3.8706  Validation loss = 2.3718  \n",
      "\n",
      "Fold: 25  Epoch: 237  Training loss = 3.8704  Validation loss = 2.3715  \n",
      "\n",
      "Fold: 25  Epoch: 238  Training loss = 3.8701  Validation loss = 2.3712  \n",
      "\n",
      "Fold: 25  Epoch: 239  Training loss = 3.8698  Validation loss = 2.3707  \n",
      "\n",
      "Fold: 25  Epoch: 240  Training loss = 3.8696  Validation loss = 2.3704  \n",
      "\n",
      "Fold: 25  Epoch: 241  Training loss = 3.8694  Validation loss = 2.3702  \n",
      "\n",
      "Fold: 25  Epoch: 242  Training loss = 3.8691  Validation loss = 2.3697  \n",
      "\n",
      "Fold: 25  Epoch: 243  Training loss = 3.8688  Validation loss = 2.3692  \n",
      "\n",
      "Fold: 25  Epoch: 244  Training loss = 3.8687  Validation loss = 2.3690  \n",
      "\n",
      "Fold: 25  Epoch: 245  Training loss = 3.8684  Validation loss = 2.3687  \n",
      "\n",
      "Fold: 25  Epoch: 246  Training loss = 3.8682  Validation loss = 2.3684  \n",
      "\n",
      "Fold: 25  Epoch: 247  Training loss = 3.8679  Validation loss = 2.3680  \n",
      "\n",
      "Fold: 25  Epoch: 248  Training loss = 3.8676  Validation loss = 2.3677  \n",
      "\n",
      "Fold: 25  Epoch: 249  Training loss = 3.8673  Validation loss = 2.3671  \n",
      "\n",
      "Fold: 25  Epoch: 250  Training loss = 3.8671  Validation loss = 2.3668  \n",
      "\n",
      "Fold: 25  Epoch: 251  Training loss = 3.8670  Validation loss = 2.3666  \n",
      "\n",
      "Fold: 25  Epoch: 252  Training loss = 3.8668  Validation loss = 2.3664  \n",
      "\n",
      "Fold: 25  Epoch: 253  Training loss = 3.8665  Validation loss = 2.3661  \n",
      "\n",
      "Fold: 25  Epoch: 254  Training loss = 3.8662  Validation loss = 2.3657  \n",
      "\n",
      "Fold: 25  Epoch: 255  Training loss = 3.8660  Validation loss = 2.3655  \n",
      "\n",
      "Fold: 25  Epoch: 256  Training loss = 3.8659  Validation loss = 2.3653  \n",
      "\n",
      "Fold: 25  Epoch: 257  Training loss = 3.8655  Validation loss = 2.3649  \n",
      "\n",
      "Fold: 25  Epoch: 258  Training loss = 3.8653  Validation loss = 2.3647  \n",
      "\n",
      "Fold: 25  Epoch: 259  Training loss = 3.8651  Validation loss = 2.3645  \n",
      "\n",
      "Fold: 25  Epoch: 260  Training loss = 3.8650  Validation loss = 2.3643  \n",
      "\n",
      "Fold: 25  Epoch: 261  Training loss = 3.8648  Validation loss = 2.3642  \n",
      "\n",
      "Fold: 25  Epoch: 262  Training loss = 3.8645  Validation loss = 2.3637  \n",
      "\n",
      "Fold: 25  Epoch: 263  Training loss = 3.8642  Validation loss = 2.3634  \n",
      "\n",
      "Fold: 25  Epoch: 264  Training loss = 3.8640  Validation loss = 2.3632  \n",
      "\n",
      "Fold: 25  Epoch: 265  Training loss = 3.8637  Validation loss = 2.3628  \n",
      "\n",
      "Fold: 25  Epoch: 266  Training loss = 3.8635  Validation loss = 2.3626  \n",
      "\n",
      "Fold: 25  Epoch: 267  Training loss = 3.8632  Validation loss = 2.3622  \n",
      "\n",
      "Fold: 25  Epoch: 268  Training loss = 3.8630  Validation loss = 2.3617  \n",
      "\n",
      "Fold: 25  Epoch: 269  Training loss = 3.8628  Validation loss = 2.3613  \n",
      "\n",
      "Fold: 25  Epoch: 270  Training loss = 3.8625  Validation loss = 2.3609  \n",
      "\n",
      "Fold: 25  Epoch: 271  Training loss = 3.8622  Validation loss = 2.3605  \n",
      "\n",
      "Fold: 25  Epoch: 272  Training loss = 3.8619  Validation loss = 2.3603  \n",
      "\n",
      "Fold: 25  Epoch: 273  Training loss = 3.8616  Validation loss = 2.3599  \n",
      "\n",
      "Fold: 25  Epoch: 274  Training loss = 3.8614  Validation loss = 2.3596  \n",
      "\n",
      "Fold: 25  Epoch: 275  Training loss = 3.8611  Validation loss = 2.3593  \n",
      "\n",
      "Fold: 25  Epoch: 276  Training loss = 3.8610  Validation loss = 2.3593  \n",
      "\n",
      "Fold: 25  Epoch: 277  Training loss = 3.8608  Validation loss = 2.3591  \n",
      "\n",
      "Fold: 25  Epoch: 278  Training loss = 3.8606  Validation loss = 2.3589  \n",
      "\n",
      "Fold: 25  Epoch: 279  Training loss = 3.8602  Validation loss = 2.3585  \n",
      "\n",
      "Fold: 25  Epoch: 280  Training loss = 3.8599  Validation loss = 2.3581  \n",
      "\n",
      "Fold: 25  Epoch: 281  Training loss = 3.8598  Validation loss = 2.3579  \n",
      "\n",
      "Fold: 25  Epoch: 282  Training loss = 3.8595  Validation loss = 2.3575  \n",
      "\n",
      "Fold: 25  Epoch: 283  Training loss = 3.8592  Validation loss = 2.3572  \n",
      "\n",
      "Fold: 25  Epoch: 284  Training loss = 3.8589  Validation loss = 2.3567  \n",
      "\n",
      "Fold: 25  Epoch: 285  Training loss = 3.8587  Validation loss = 2.3566  \n",
      "\n",
      "Fold: 25  Epoch: 286  Training loss = 3.8584  Validation loss = 2.3563  \n",
      "\n",
      "Fold: 25  Epoch: 287  Training loss = 3.8582  Validation loss = 2.3560  \n",
      "\n",
      "Fold: 25  Epoch: 288  Training loss = 3.8579  Validation loss = 2.3557  \n",
      "\n",
      "Fold: 25  Epoch: 289  Training loss = 3.8577  Validation loss = 2.3554  \n",
      "\n",
      "Fold: 25  Epoch: 290  Training loss = 3.8574  Validation loss = 2.3550  \n",
      "\n",
      "Fold: 25  Epoch: 291  Training loss = 3.8571  Validation loss = 2.3544  \n",
      "\n",
      "Fold: 25  Epoch: 292  Training loss = 3.8569  Validation loss = 2.3541  \n",
      "\n",
      "Fold: 25  Epoch: 293  Training loss = 3.8565  Validation loss = 2.3536  \n",
      "\n",
      "Fold: 25  Epoch: 294  Training loss = 3.8563  Validation loss = 2.3532  \n",
      "\n",
      "Fold: 25  Epoch: 295  Training loss = 3.8561  Validation loss = 2.3530  \n",
      "\n",
      "Fold: 25  Epoch: 296  Training loss = 3.8558  Validation loss = 2.3527  \n",
      "\n",
      "Fold: 25  Epoch: 297  Training loss = 3.8556  Validation loss = 2.3525  \n",
      "\n",
      "Fold: 25  Epoch: 298  Training loss = 3.8552  Validation loss = 2.3522  \n",
      "\n",
      "Fold: 25  Epoch: 299  Training loss = 3.8550  Validation loss = 2.3517  \n",
      "\n",
      "Fold: 25  Epoch: 300  Training loss = 3.8547  Validation loss = 2.3514  \n",
      "\n",
      "Fold: 25  Epoch: 301  Training loss = 3.8544  Validation loss = 2.3511  \n",
      "\n",
      "Fold: 25  Epoch: 302  Training loss = 3.8541  Validation loss = 2.3508  \n",
      "\n",
      "Fold: 25  Epoch: 303  Training loss = 3.8539  Validation loss = 2.3505  \n",
      "\n",
      "Fold: 25  Epoch: 304  Training loss = 3.8537  Validation loss = 2.3503  \n",
      "\n",
      "Fold: 25  Epoch: 305  Training loss = 3.8535  Validation loss = 2.3501  \n",
      "\n",
      "Fold: 25  Epoch: 306  Training loss = 3.8531  Validation loss = 2.3495  \n",
      "\n",
      "Fold: 25  Epoch: 307  Training loss = 3.8528  Validation loss = 2.3491  \n",
      "\n",
      "Fold: 25  Epoch: 308  Training loss = 3.8525  Validation loss = 2.3487  \n",
      "\n",
      "Fold: 25  Epoch: 309  Training loss = 3.8523  Validation loss = 2.3483  \n",
      "\n",
      "Fold: 25  Epoch: 310  Training loss = 3.8520  Validation loss = 2.3479  \n",
      "\n",
      "Fold: 25  Epoch: 311  Training loss = 3.8518  Validation loss = 2.3476  \n",
      "\n",
      "Fold: 25  Epoch: 312  Training loss = 3.8514  Validation loss = 2.3472  \n",
      "\n",
      "Fold: 25  Epoch: 313  Training loss = 3.8512  Validation loss = 2.3469  \n",
      "\n",
      "Fold: 25  Epoch: 314  Training loss = 3.8509  Validation loss = 2.3466  \n",
      "\n",
      "Fold: 25  Epoch: 315  Training loss = 3.8506  Validation loss = 2.3462  \n",
      "\n",
      "Fold: 25  Epoch: 316  Training loss = 3.8503  Validation loss = 2.3459  \n",
      "\n",
      "Fold: 25  Epoch: 317  Training loss = 3.8501  Validation loss = 2.3457  \n",
      "\n",
      "Fold: 25  Epoch: 318  Training loss = 3.8499  Validation loss = 2.3453  \n",
      "\n",
      "Fold: 25  Epoch: 319  Training loss = 3.8496  Validation loss = 2.3452  \n",
      "\n",
      "Fold: 25  Epoch: 320  Training loss = 3.8494  Validation loss = 2.3447  \n",
      "\n",
      "Fold: 25  Epoch: 321  Training loss = 3.8490  Validation loss = 2.3441  \n",
      "\n",
      "Fold: 25  Epoch: 322  Training loss = 3.8489  Validation loss = 2.3439  \n",
      "\n",
      "Fold: 25  Epoch: 323  Training loss = 3.8487  Validation loss = 2.3436  \n",
      "\n",
      "Fold: 25  Epoch: 324  Training loss = 3.8484  Validation loss = 2.3434  \n",
      "\n",
      "Fold: 25  Epoch: 325  Training loss = 3.8482  Validation loss = 2.3432  \n",
      "\n",
      "Fold: 25  Epoch: 326  Training loss = 3.8479  Validation loss = 2.3429  \n",
      "\n",
      "Fold: 25  Epoch: 327  Training loss = 3.8477  Validation loss = 2.3427  \n",
      "\n",
      "Fold: 25  Epoch: 328  Training loss = 3.8474  Validation loss = 2.3425  \n",
      "\n",
      "Fold: 25  Epoch: 329  Training loss = 3.8471  Validation loss = 2.3422  \n",
      "\n",
      "Fold: 25  Epoch: 330  Training loss = 3.8469  Validation loss = 2.3420  \n",
      "\n",
      "Fold: 25  Epoch: 331  Training loss = 3.8466  Validation loss = 2.3416  \n",
      "\n",
      "Fold: 25  Epoch: 332  Training loss = 3.8464  Validation loss = 2.3413  \n",
      "\n",
      "Fold: 25  Epoch: 333  Training loss = 3.8462  Validation loss = 2.3412  \n",
      "\n",
      "Fold: 25  Epoch: 334  Training loss = 3.8459  Validation loss = 2.3409  \n",
      "\n",
      "Fold: 25  Epoch: 335  Training loss = 3.8457  Validation loss = 2.3405  \n",
      "\n",
      "Fold: 25  Epoch: 336  Training loss = 3.8454  Validation loss = 2.3401  \n",
      "\n",
      "Fold: 25  Epoch: 337  Training loss = 3.8451  Validation loss = 2.3398  \n",
      "\n",
      "Fold: 25  Epoch: 338  Training loss = 3.8449  Validation loss = 2.3395  \n",
      "\n",
      "Fold: 25  Epoch: 339  Training loss = 3.8447  Validation loss = 2.3392  \n",
      "\n",
      "Fold: 25  Epoch: 340  Training loss = 3.8443  Validation loss = 2.3387  \n",
      "\n",
      "Fold: 25  Epoch: 341  Training loss = 3.8441  Validation loss = 2.3384  \n",
      "\n",
      "Fold: 25  Epoch: 342  Training loss = 3.8439  Validation loss = 2.3379  \n",
      "\n",
      "Fold: 25  Epoch: 343  Training loss = 3.8436  Validation loss = 2.3376  \n",
      "\n",
      "Fold: 25  Epoch: 344  Training loss = 3.8432  Validation loss = 2.3370  \n",
      "\n",
      "Fold: 25  Epoch: 345  Training loss = 3.8429  Validation loss = 2.3364  \n",
      "\n",
      "Fold: 25  Epoch: 346  Training loss = 3.8427  Validation loss = 2.3364  \n",
      "\n",
      "Fold: 25  Epoch: 347  Training loss = 3.8425  Validation loss = 2.3362  \n",
      "\n",
      "Fold: 25  Epoch: 348  Training loss = 3.8423  Validation loss = 2.3360  \n",
      "\n",
      "Fold: 25  Epoch: 349  Training loss = 3.8421  Validation loss = 2.3358  \n",
      "\n",
      "Fold: 25  Epoch: 350  Training loss = 3.8419  Validation loss = 2.3355  \n",
      "\n",
      "Fold: 25  Epoch: 351  Training loss = 3.8416  Validation loss = 2.3352  \n",
      "\n",
      "Fold: 25  Epoch: 352  Training loss = 3.8414  Validation loss = 2.3349  \n",
      "\n",
      "Fold: 25  Epoch: 353  Training loss = 3.8411  Validation loss = 2.3345  \n",
      "\n",
      "Fold: 25  Epoch: 354  Training loss = 3.8409  Validation loss = 2.3342  \n",
      "\n",
      "Fold: 25  Epoch: 355  Training loss = 3.8407  Validation loss = 2.3340  \n",
      "\n",
      "Fold: 25  Epoch: 356  Training loss = 3.8405  Validation loss = 2.3337  \n",
      "\n",
      "Fold: 25  Epoch: 357  Training loss = 3.8403  Validation loss = 2.3334  \n",
      "\n",
      "Fold: 25  Epoch: 358  Training loss = 3.8401  Validation loss = 2.3331  \n",
      "\n",
      "Fold: 25  Epoch: 359  Training loss = 3.8399  Validation loss = 2.3327  \n",
      "\n",
      "Fold: 25  Epoch: 360  Training loss = 3.8396  Validation loss = 2.3324  \n",
      "\n",
      "Fold: 25  Epoch: 361  Training loss = 3.8394  Validation loss = 2.3325  \n",
      "\n",
      "Fold: 25  Epoch: 362  Training loss = 3.8392  Validation loss = 2.3322  \n",
      "\n",
      "Fold: 25  Epoch: 363  Training loss = 3.8391  Validation loss = 2.3320  \n",
      "\n",
      "Fold: 25  Epoch: 364  Training loss = 3.8389  Validation loss = 2.3319  \n",
      "\n",
      "Fold: 25  Epoch: 365  Training loss = 3.8386  Validation loss = 2.3316  \n",
      "\n",
      "Fold: 25  Epoch: 366  Training loss = 3.8384  Validation loss = 2.3312  \n",
      "\n",
      "Fold: 25  Epoch: 367  Training loss = 3.8380  Validation loss = 2.3308  \n",
      "\n",
      "Fold: 25  Epoch: 368  Training loss = 3.8377  Validation loss = 2.3303  \n",
      "\n",
      "Fold: 25  Epoch: 369  Training loss = 3.8374  Validation loss = 2.3300  \n",
      "\n",
      "Fold: 25  Epoch: 370  Training loss = 3.8371  Validation loss = 2.3296  \n",
      "\n",
      "Fold: 25  Epoch: 371  Training loss = 3.8369  Validation loss = 2.3292  \n",
      "\n",
      "Fold: 25  Epoch: 372  Training loss = 3.8366  Validation loss = 2.3288  \n",
      "\n",
      "Fold: 25  Epoch: 373  Training loss = 3.8364  Validation loss = 2.3285  \n",
      "\n",
      "Fold: 25  Epoch: 374  Training loss = 3.8361  Validation loss = 2.3282  \n",
      "\n",
      "Fold: 25  Epoch: 375  Training loss = 3.8360  Validation loss = 2.3279  \n",
      "\n",
      "Fold: 25  Epoch: 376  Training loss = 3.8358  Validation loss = 2.3277  \n",
      "\n",
      "Fold: 25  Epoch: 377  Training loss = 3.8357  Validation loss = 2.3277  \n",
      "\n",
      "Fold: 25  Epoch: 378  Training loss = 3.8355  Validation loss = 2.3276  \n",
      "\n",
      "Fold: 25  Epoch: 379  Training loss = 3.8355  Validation loss = 2.3278  \n",
      "\n",
      "Fold: 25  Epoch: 380  Training loss = 3.8352  Validation loss = 2.3273  \n",
      "\n",
      "Fold: 25  Epoch: 381  Training loss = 3.8350  Validation loss = 2.3270  \n",
      "\n",
      "Fold: 25  Epoch: 382  Training loss = 3.8347  Validation loss = 2.3268  \n",
      "\n",
      "Fold: 25  Epoch: 383  Training loss = 3.8345  Validation loss = 2.3267  \n",
      "\n",
      "Fold: 25  Epoch: 384  Training loss = 3.8342  Validation loss = 2.3262  \n",
      "\n",
      "Fold: 25  Epoch: 385  Training loss = 3.8340  Validation loss = 2.3261  \n",
      "\n",
      "Fold: 25  Epoch: 386  Training loss = 3.8338  Validation loss = 2.3256  \n",
      "\n",
      "Fold: 25  Epoch: 387  Training loss = 3.8336  Validation loss = 2.3254  \n",
      "\n",
      "Fold: 25  Epoch: 388  Training loss = 3.8333  Validation loss = 2.3251  \n",
      "\n",
      "Fold: 25  Epoch: 389  Training loss = 3.8331  Validation loss = 2.3248  \n",
      "\n",
      "Fold: 25  Epoch: 390  Training loss = 3.8329  Validation loss = 2.3245  \n",
      "\n",
      "Fold: 25  Epoch: 391  Training loss = 3.8326  Validation loss = 2.3243  \n",
      "\n",
      "Fold: 25  Epoch: 392  Training loss = 3.8324  Validation loss = 2.3240  \n",
      "\n",
      "Fold: 25  Epoch: 393  Training loss = 3.8322  Validation loss = 2.3237  \n",
      "\n",
      "Fold: 25  Epoch: 394  Training loss = 3.8318  Validation loss = 2.3231  \n",
      "\n",
      "Fold: 25  Epoch: 395  Training loss = 3.8316  Validation loss = 2.3228  \n",
      "\n",
      "Fold: 25  Epoch: 396  Training loss = 3.8314  Validation loss = 2.3227  \n",
      "\n",
      "Fold: 25  Epoch: 397  Training loss = 3.8312  Validation loss = 2.3225  \n",
      "\n",
      "Fold: 25  Epoch: 398  Training loss = 3.8310  Validation loss = 2.3223  \n",
      "\n",
      "Fold: 25  Epoch: 399  Training loss = 3.8307  Validation loss = 2.3219  \n",
      "\n",
      "Fold: 25  Epoch: 400  Training loss = 3.8305  Validation loss = 2.3216  \n",
      "\n",
      "Fold: 25  Epoch: 401  Training loss = 3.8303  Validation loss = 2.3213  \n",
      "\n",
      "Fold: 25  Epoch: 402  Training loss = 3.8302  Validation loss = 2.3213  \n",
      "\n",
      "Fold: 25  Epoch: 403  Training loss = 3.8299  Validation loss = 2.3209  \n",
      "\n",
      "Fold: 25  Epoch: 404  Training loss = 3.8296  Validation loss = 2.3206  \n",
      "\n",
      "Fold: 25  Epoch: 405  Training loss = 3.8294  Validation loss = 2.3206  \n",
      "\n",
      "Fold: 25  Epoch: 406  Training loss = 3.8291  Validation loss = 2.3203  \n",
      "\n",
      "Fold: 25  Epoch: 407  Training loss = 3.8289  Validation loss = 2.3200  \n",
      "\n",
      "Fold: 25  Epoch: 408  Training loss = 3.8287  Validation loss = 2.3197  \n",
      "\n",
      "Fold: 25  Epoch: 409  Training loss = 3.8286  Validation loss = 2.3198  \n",
      "\n",
      "Fold: 25  Epoch: 410  Training loss = 3.8284  Validation loss = 2.3195  \n",
      "\n",
      "Fold: 25  Epoch: 411  Training loss = 3.8281  Validation loss = 2.3191  \n",
      "\n",
      "Fold: 25  Epoch: 412  Training loss = 3.8278  Validation loss = 2.3188  \n",
      "\n",
      "Fold: 25  Epoch: 413  Training loss = 3.8276  Validation loss = 2.3185  \n",
      "\n",
      "Fold: 25  Epoch: 414  Training loss = 3.8274  Validation loss = 2.3182  \n",
      "\n",
      "Fold: 25  Epoch: 415  Training loss = 3.8270  Validation loss = 2.3178  \n",
      "\n",
      "Fold: 25  Epoch: 416  Training loss = 3.8267  Validation loss = 2.3173  \n",
      "\n",
      "Fold: 25  Epoch: 417  Training loss = 3.8265  Validation loss = 2.3172  \n",
      "\n",
      "Fold: 25  Epoch: 418  Training loss = 3.8262  Validation loss = 2.3168  \n",
      "\n",
      "Fold: 25  Epoch: 419  Training loss = 3.8260  Validation loss = 2.3165  \n",
      "\n",
      "Fold: 25  Epoch: 420  Training loss = 3.8257  Validation loss = 2.3161  \n",
      "\n",
      "Fold: 25  Epoch: 421  Training loss = 3.8253  Validation loss = 2.3156  \n",
      "\n",
      "Fold: 25  Epoch: 422  Training loss = 3.8251  Validation loss = 2.3153  \n",
      "\n",
      "Fold: 25  Epoch: 423  Training loss = 3.8249  Validation loss = 2.3150  \n",
      "\n",
      "Fold: 25  Epoch: 424  Training loss = 3.8246  Validation loss = 2.3148  \n",
      "\n",
      "Fold: 25  Epoch: 425  Training loss = 3.8243  Validation loss = 2.3143  \n",
      "\n",
      "Fold: 25  Epoch: 426  Training loss = 3.8240  Validation loss = 2.3139  \n",
      "\n",
      "Fold: 25  Epoch: 427  Training loss = 3.8237  Validation loss = 2.3137  \n",
      "\n",
      "Fold: 25  Epoch: 428  Training loss = 3.8235  Validation loss = 2.3137  \n",
      "\n",
      "Fold: 25  Epoch: 429  Training loss = 3.8233  Validation loss = 2.3135  \n",
      "\n",
      "Fold: 25  Epoch: 430  Training loss = 3.8230  Validation loss = 2.3133  \n",
      "\n",
      "Fold: 25  Epoch: 431  Training loss = 3.8227  Validation loss = 2.3128  \n",
      "\n",
      "Fold: 25  Epoch: 432  Training loss = 3.8225  Validation loss = 2.3126  \n",
      "\n",
      "Fold: 25  Epoch: 433  Training loss = 3.8223  Validation loss = 2.3123  \n",
      "\n",
      "Fold: 25  Epoch: 434  Training loss = 3.8221  Validation loss = 2.3120  \n",
      "\n",
      "Fold: 25  Epoch: 435  Training loss = 3.8218  Validation loss = 2.3115  \n",
      "\n",
      "Fold: 25  Epoch: 436  Training loss = 3.8216  Validation loss = 2.3111  \n",
      "\n",
      "Fold: 25  Epoch: 437  Training loss = 3.8214  Validation loss = 2.3110  \n",
      "\n",
      "Fold: 25  Epoch: 438  Training loss = 3.8212  Validation loss = 2.3107  \n",
      "\n",
      "Fold: 25  Epoch: 439  Training loss = 3.8210  Validation loss = 2.3103  \n",
      "\n",
      "Fold: 25  Epoch: 440  Training loss = 3.8208  Validation loss = 2.3101  \n",
      "\n",
      "Fold: 25  Epoch: 441  Training loss = 3.8206  Validation loss = 2.3098  \n",
      "\n",
      "Fold: 25  Epoch: 442  Training loss = 3.8204  Validation loss = 2.3095  \n",
      "\n",
      "Fold: 25  Epoch: 443  Training loss = 3.8201  Validation loss = 2.3090  \n",
      "\n",
      "Fold: 25  Epoch: 444  Training loss = 3.8198  Validation loss = 2.3086  \n",
      "\n",
      "Fold: 25  Epoch: 445  Training loss = 3.8196  Validation loss = 2.3084  \n",
      "\n",
      "Fold: 25  Epoch: 446  Training loss = 3.8194  Validation loss = 2.3081  \n",
      "\n",
      "Fold: 25  Epoch: 447  Training loss = 3.8191  Validation loss = 2.3077  \n",
      "\n",
      "Fold: 25  Epoch: 448  Training loss = 3.8188  Validation loss = 2.3073  \n",
      "\n",
      "Fold: 25  Epoch: 449  Training loss = 3.8185  Validation loss = 2.3067  \n",
      "\n",
      "Fold: 25  Epoch: 450  Training loss = 3.8182  Validation loss = 2.3063  \n",
      "\n",
      "Fold: 25  Epoch: 451  Training loss = 3.8180  Validation loss = 2.3061  \n",
      "\n",
      "Fold: 25  Epoch: 452  Training loss = 3.8178  Validation loss = 2.3060  \n",
      "\n",
      "Fold: 25  Epoch: 453  Training loss = 3.8177  Validation loss = 2.3057  \n",
      "\n",
      "Fold: 25  Epoch: 454  Training loss = 3.8174  Validation loss = 2.3052  \n",
      "\n",
      "Fold: 25  Epoch: 455  Training loss = 3.8171  Validation loss = 2.3047  \n",
      "\n",
      "Fold: 25  Epoch: 456  Training loss = 3.8167  Validation loss = 2.3041  \n",
      "\n",
      "Fold: 25  Epoch: 457  Training loss = 3.8165  Validation loss = 2.3037  \n",
      "\n",
      "Fold: 25  Epoch: 458  Training loss = 3.8162  Validation loss = 2.3034  \n",
      "\n",
      "Fold: 25  Epoch: 459  Training loss = 3.8160  Validation loss = 2.3031  \n",
      "\n",
      "Fold: 25  Epoch: 460  Training loss = 3.8157  Validation loss = 2.3028  \n",
      "\n",
      "Fold: 25  Epoch: 461  Training loss = 3.8155  Validation loss = 2.3025  \n",
      "\n",
      "Fold: 25  Epoch: 462  Training loss = 3.8152  Validation loss = 2.3019  \n",
      "\n",
      "Fold: 25  Epoch: 463  Training loss = 3.8149  Validation loss = 2.3015  \n",
      "\n",
      "Fold: 25  Epoch: 464  Training loss = 3.8146  Validation loss = 2.3011  \n",
      "\n",
      "Fold: 25  Epoch: 465  Training loss = 3.8144  Validation loss = 2.3007  \n",
      "\n",
      "Fold: 25  Epoch: 466  Training loss = 3.8142  Validation loss = 2.3005  \n",
      "\n",
      "Fold: 25  Epoch: 467  Training loss = 3.8139  Validation loss = 2.3003  \n",
      "\n",
      "Fold: 25  Epoch: 468  Training loss = 3.8137  Validation loss = 2.2999  \n",
      "\n",
      "Fold: 25  Epoch: 469  Training loss = 3.8135  Validation loss = 2.2996  \n",
      "\n",
      "Fold: 25  Epoch: 470  Training loss = 3.8133  Validation loss = 2.2995  \n",
      "\n",
      "Fold: 25  Epoch: 471  Training loss = 3.8131  Validation loss = 2.2993  \n",
      "\n",
      "Fold: 25  Epoch: 472  Training loss = 3.8128  Validation loss = 2.2989  \n",
      "\n",
      "Fold: 25  Epoch: 473  Training loss = 3.8125  Validation loss = 2.2983  \n",
      "\n",
      "Fold: 25  Epoch: 474  Training loss = 3.8123  Validation loss = 2.2979  \n",
      "\n",
      "Fold: 25  Epoch: 475  Training loss = 3.8120  Validation loss = 2.2975  \n",
      "\n",
      "Fold: 25  Epoch: 476  Training loss = 3.8117  Validation loss = 2.2974  \n",
      "\n",
      "Fold: 25  Epoch: 477  Training loss = 3.8115  Validation loss = 2.2970  \n",
      "\n",
      "Fold: 25  Epoch: 478  Training loss = 3.8112  Validation loss = 2.2965  \n",
      "\n",
      "Fold: 25  Epoch: 479  Training loss = 3.8110  Validation loss = 2.2963  \n",
      "\n",
      "Fold: 25  Epoch: 480  Training loss = 3.8107  Validation loss = 2.2960  \n",
      "\n",
      "Fold: 25  Epoch: 481  Training loss = 3.8105  Validation loss = 2.2958  \n",
      "\n",
      "Fold: 25  Epoch: 482  Training loss = 3.8102  Validation loss = 2.2953  \n",
      "\n",
      "Fold: 25  Epoch: 483  Training loss = 3.8100  Validation loss = 2.2950  \n",
      "\n",
      "Fold: 25  Epoch: 484  Training loss = 3.8097  Validation loss = 2.2947  \n",
      "\n",
      "Fold: 25  Epoch: 485  Training loss = 3.8094  Validation loss = 2.2945  \n",
      "\n",
      "Fold: 25  Epoch: 486  Training loss = 3.8092  Validation loss = 2.2942  \n",
      "\n",
      "Fold: 25  Epoch: 487  Training loss = 3.8088  Validation loss = 2.2937  \n",
      "\n",
      "Fold: 25  Epoch: 488  Training loss = 3.8085  Validation loss = 2.2933  \n",
      "\n",
      "Fold: 25  Epoch: 489  Training loss = 3.8083  Validation loss = 2.2930  \n",
      "\n",
      "Fold: 25  Epoch: 490  Training loss = 3.8082  Validation loss = 2.2928  \n",
      "\n",
      "Fold: 25  Epoch: 491  Training loss = 3.8079  Validation loss = 2.2924  \n",
      "\n",
      "Fold: 25  Epoch: 492  Training loss = 3.8076  Validation loss = 2.2918  \n",
      "\n",
      "Fold: 25  Epoch: 493  Training loss = 3.8073  Validation loss = 2.2917  \n",
      "\n",
      "Fold: 25  Epoch: 494  Training loss = 3.8071  Validation loss = 2.2912  \n",
      "\n",
      "Fold: 25  Epoch: 495  Training loss = 3.8069  Validation loss = 2.2911  \n",
      "\n",
      "Fold: 25  Epoch: 496  Training loss = 3.8067  Validation loss = 2.2908  \n",
      "\n",
      "Fold: 25  Epoch: 497  Training loss = 3.8064  Validation loss = 2.2905  \n",
      "\n",
      "Fold: 25  Epoch: 498  Training loss = 3.8062  Validation loss = 2.2903  \n",
      "\n",
      "Fold: 25  Epoch: 499  Training loss = 3.8060  Validation loss = 2.2900  \n",
      "\n",
      "Fold: 25  Epoch: 500  Training loss = 3.8060  Validation loss = 2.2900  \n",
      "\n",
      "Check model:  Fold: 25  Optimal epoch: 500  \n",
      "\n",
      "Fold: 26  Epoch: 1  Training loss = 3.5207  Validation loss = 1.7023  \n",
      "\n",
      "Fold: 26  Epoch: 2  Training loss = 3.5205  Validation loss = 1.7027  \n",
      "\n",
      "Fold: 26  Epoch: 3  Training loss = 3.5203  Validation loss = 1.7031  \n",
      "\n",
      "Fold: 26  Epoch: 4  Training loss = 3.5202  Validation loss = 1.7034  \n",
      "\n",
      "Fold: 26  Epoch: 5  Training loss = 3.5200  Validation loss = 1.7040  \n",
      "\n",
      "Fold: 26  Epoch: 6  Training loss = 3.5199  Validation loss = 1.7043  \n",
      "\n",
      "Fold: 26  Epoch: 7  Training loss = 3.5196  Validation loss = 1.7048  \n",
      "\n",
      "Fold: 26  Epoch: 8  Training loss = 3.5195  Validation loss = 1.7050  \n",
      "\n",
      "Fold: 26  Epoch: 9  Training loss = 3.5194  Validation loss = 1.7053  \n",
      "\n",
      "Fold: 26  Epoch: 10  Training loss = 3.5192  Validation loss = 1.7057  \n",
      "\n",
      "Fold: 26  Epoch: 11  Training loss = 3.5190  Validation loss = 1.7061  \n",
      "\n",
      "Check model:  Fold: 26  Optimal epoch: 1  \n",
      "\n",
      "Fold: 27  Epoch: 1  Training loss = 3.3807  Validation loss = 1.6910  \n",
      "\n",
      "Fold: 27  Epoch: 2  Training loss = 3.3805  Validation loss = 1.6910  \n",
      "\n",
      "Fold: 27  Epoch: 3  Training loss = 3.3803  Validation loss = 1.6915  \n",
      "\n",
      "Fold: 27  Epoch: 4  Training loss = 3.3802  Validation loss = 1.6917  \n",
      "\n",
      "Fold: 27  Epoch: 5  Training loss = 3.3802  Validation loss = 1.6916  \n",
      "\n",
      "Fold: 27  Epoch: 6  Training loss = 3.3800  Validation loss = 1.6918  \n",
      "\n",
      "Fold: 27  Epoch: 7  Training loss = 3.3799  Validation loss = 1.6919  \n",
      "\n",
      "Fold: 27  Epoch: 8  Training loss = 3.3798  Validation loss = 1.6921  \n",
      "\n",
      "Fold: 27  Epoch: 9  Training loss = 3.3796  Validation loss = 1.6921  \n",
      "\n",
      "Fold: 27  Epoch: 10  Training loss = 3.3795  Validation loss = 1.6924  \n",
      "\n",
      "Fold: 27  Epoch: 11  Training loss = 3.3794  Validation loss = 1.6925  \n",
      "\n",
      "Check model:  Fold: 27  Optimal epoch: 1  \n",
      "\n",
      "Fold: 28  Epoch: 1  Training loss = 3.3805  Validation loss = 1.8836  \n",
      "\n",
      "Fold: 28  Epoch: 2  Training loss = 3.3804  Validation loss = 1.8834  \n",
      "\n",
      "Fold: 28  Epoch: 3  Training loss = 3.3803  Validation loss = 1.8836  \n",
      "\n",
      "Fold: 28  Epoch: 4  Training loss = 3.3802  Validation loss = 1.8836  \n",
      "\n",
      "Fold: 28  Epoch: 5  Training loss = 3.3801  Validation loss = 1.8837  \n",
      "\n",
      "Fold: 28  Epoch: 6  Training loss = 3.3799  Validation loss = 1.8839  \n",
      "\n",
      "Fold: 28  Epoch: 7  Training loss = 3.3798  Validation loss = 1.8841  \n",
      "\n",
      "Fold: 28  Epoch: 8  Training loss = 3.3797  Validation loss = 1.8843  \n",
      "\n",
      "Fold: 28  Epoch: 9  Training loss = 3.3795  Validation loss = 1.8844  \n",
      "\n",
      "Fold: 28  Epoch: 10  Training loss = 3.3794  Validation loss = 1.8846  \n",
      "\n",
      "Fold: 28  Epoch: 11  Training loss = 3.3793  Validation loss = 1.8847  \n",
      "\n",
      "Check model:  Fold: 28  Optimal epoch: 2  \n",
      "\n",
      "Fold: 29  Epoch: 1  Training loss = 3.4023  Validation loss = 2.2082  \n",
      "\n",
      "Fold: 29  Epoch: 2  Training loss = 3.4022  Validation loss = 2.2081  \n",
      "\n",
      "Fold: 29  Epoch: 3  Training loss = 3.4021  Validation loss = 2.2082  \n",
      "\n",
      "Fold: 29  Epoch: 4  Training loss = 3.4020  Validation loss = 2.2082  \n",
      "\n",
      "Fold: 29  Epoch: 5  Training loss = 3.4020  Validation loss = 2.2078  \n",
      "\n",
      "Fold: 29  Epoch: 6  Training loss = 3.4019  Validation loss = 2.2080  \n",
      "\n",
      "Fold: 29  Epoch: 7  Training loss = 3.4018  Validation loss = 2.2081  \n",
      "\n",
      "Fold: 29  Epoch: 8  Training loss = 3.4017  Validation loss = 2.2082  \n",
      "\n",
      "Fold: 29  Epoch: 9  Training loss = 3.4016  Validation loss = 2.2081  \n",
      "\n",
      "Fold: 29  Epoch: 10  Training loss = 3.4015  Validation loss = 2.2079  \n",
      "\n",
      "Fold: 29  Epoch: 11  Training loss = 3.4015  Validation loss = 2.2076  \n",
      "\n",
      "Fold: 29  Epoch: 12  Training loss = 3.4014  Validation loss = 2.2076  \n",
      "\n",
      "Fold: 29  Epoch: 13  Training loss = 3.4013  Validation loss = 2.2078  \n",
      "\n",
      "Fold: 29  Epoch: 14  Training loss = 3.4012  Validation loss = 2.2079  \n",
      "\n",
      "Fold: 29  Epoch: 15  Training loss = 3.4011  Validation loss = 2.2079  \n",
      "\n",
      "Fold: 29  Epoch: 16  Training loss = 3.4009  Validation loss = 2.2082  \n",
      "\n",
      "Check model:  Fold: 29  Optimal epoch: 11  \n",
      "\n",
      "Fold: 30  Epoch: 1  Training loss = 3.3651  Validation loss = 0.7070  \n",
      "\n",
      "Fold: 30  Epoch: 2  Training loss = 3.3650  Validation loss = 0.7071  \n",
      "\n",
      "Fold: 30  Epoch: 3  Training loss = 3.3649  Validation loss = 0.7071  \n",
      "\n",
      "Fold: 30  Epoch: 4  Training loss = 3.3648  Validation loss = 0.7071  \n",
      "\n",
      "Fold: 30  Epoch: 5  Training loss = 3.3647  Validation loss = 0.7070  \n",
      "\n",
      "Fold: 30  Epoch: 6  Training loss = 3.3646  Validation loss = 0.7070  \n",
      "\n",
      "Fold: 30  Epoch: 7  Training loss = 3.3645  Validation loss = 0.7071  \n",
      "\n",
      "Fold: 30  Epoch: 8  Training loss = 3.3645  Validation loss = 0.7071  \n",
      "\n",
      "Fold: 30  Epoch: 9  Training loss = 3.3644  Validation loss = 0.7071  \n",
      "\n",
      "Fold: 30  Epoch: 10  Training loss = 3.3643  Validation loss = 0.7071  \n",
      "\n",
      "Fold: 30  Epoch: 11  Training loss = 3.3642  Validation loss = 0.7071  \n",
      "\n",
      "Check model:  Fold: 30  Optimal epoch: 5  \n",
      "\n",
      "Fold: 31  Epoch: 1  Training loss = 2.9871  Validation loss = 1.4112  \n",
      "\n",
      "Fold: 31  Epoch: 2  Training loss = 2.9870  Validation loss = 1.4111  \n",
      "\n",
      "Fold: 31  Epoch: 3  Training loss = 2.9869  Validation loss = 1.4108  \n",
      "\n",
      "Fold: 31  Epoch: 4  Training loss = 2.9869  Validation loss = 1.4107  \n",
      "\n",
      "Fold: 31  Epoch: 5  Training loss = 2.9868  Validation loss = 1.4106  \n",
      "\n",
      "Fold: 31  Epoch: 6  Training loss = 2.9867  Validation loss = 1.4103  \n",
      "\n",
      "Fold: 31  Epoch: 7  Training loss = 2.9867  Validation loss = 1.4099  \n",
      "\n",
      "Fold: 31  Epoch: 8  Training loss = 2.9866  Validation loss = 1.4098  \n",
      "\n",
      "Fold: 31  Epoch: 9  Training loss = 2.9865  Validation loss = 1.4096  \n",
      "\n",
      "Fold: 31  Epoch: 10  Training loss = 2.9864  Validation loss = 1.4093  \n",
      "\n",
      "Fold: 31  Epoch: 11  Training loss = 2.9864  Validation loss = 1.4091  \n",
      "\n",
      "Fold: 31  Epoch: 12  Training loss = 2.9863  Validation loss = 1.4090  \n",
      "\n",
      "Fold: 31  Epoch: 13  Training loss = 2.9862  Validation loss = 1.4086  \n",
      "\n",
      "Fold: 31  Epoch: 14  Training loss = 2.9862  Validation loss = 1.4086  \n",
      "\n",
      "Fold: 31  Epoch: 15  Training loss = 2.9861  Validation loss = 1.4082  \n",
      "\n",
      "Fold: 31  Epoch: 16  Training loss = 2.9861  Validation loss = 1.4082  \n",
      "\n",
      "Fold: 31  Epoch: 17  Training loss = 2.9860  Validation loss = 1.4079  \n",
      "\n",
      "Fold: 31  Epoch: 18  Training loss = 2.9860  Validation loss = 1.4077  \n",
      "\n",
      "Fold: 31  Epoch: 19  Training loss = 2.9859  Validation loss = 1.4076  \n",
      "\n",
      "Fold: 31  Epoch: 20  Training loss = 2.9858  Validation loss = 1.4074  \n",
      "\n",
      "Fold: 31  Epoch: 21  Training loss = 2.9858  Validation loss = 1.4074  \n",
      "\n",
      "Fold: 31  Epoch: 22  Training loss = 2.9857  Validation loss = 1.4073  \n",
      "\n",
      "Fold: 31  Epoch: 23  Training loss = 2.9857  Validation loss = 1.4072  \n",
      "\n",
      "Fold: 31  Epoch: 24  Training loss = 2.9856  Validation loss = 1.4072  \n",
      "\n",
      "Fold: 31  Epoch: 25  Training loss = 2.9856  Validation loss = 1.4068  \n",
      "\n",
      "Fold: 31  Epoch: 26  Training loss = 2.9855  Validation loss = 1.4067  \n",
      "\n",
      "Fold: 31  Epoch: 27  Training loss = 2.9855  Validation loss = 1.4066  \n",
      "\n",
      "Fold: 31  Epoch: 28  Training loss = 2.9854  Validation loss = 1.4062  \n",
      "\n",
      "Fold: 31  Epoch: 29  Training loss = 2.9853  Validation loss = 1.4061  \n",
      "\n",
      "Fold: 31  Epoch: 30  Training loss = 2.9853  Validation loss = 1.4059  \n",
      "\n",
      "Fold: 31  Epoch: 31  Training loss = 2.9852  Validation loss = 1.4060  \n",
      "\n",
      "Fold: 31  Epoch: 32  Training loss = 2.9852  Validation loss = 1.4060  \n",
      "\n",
      "Fold: 31  Epoch: 33  Training loss = 2.9851  Validation loss = 1.4061  \n",
      "\n",
      "Fold: 31  Epoch: 34  Training loss = 2.9851  Validation loss = 1.4059  \n",
      "\n",
      "Fold: 31  Epoch: 35  Training loss = 2.9850  Validation loss = 1.4058  \n",
      "\n",
      "Fold: 31  Epoch: 36  Training loss = 2.9849  Validation loss = 1.4057  \n",
      "\n",
      "Fold: 31  Epoch: 37  Training loss = 2.9849  Validation loss = 1.4056  \n",
      "\n",
      "Fold: 31  Epoch: 38  Training loss = 2.9848  Validation loss = 1.4053  \n",
      "\n",
      "Fold: 31  Epoch: 39  Training loss = 2.9848  Validation loss = 1.4052  \n",
      "\n",
      "Fold: 31  Epoch: 40  Training loss = 2.9847  Validation loss = 1.4047  \n",
      "\n",
      "Fold: 31  Epoch: 41  Training loss = 2.9846  Validation loss = 1.4047  \n",
      "\n",
      "Fold: 31  Epoch: 42  Training loss = 2.9846  Validation loss = 1.4044  \n",
      "\n",
      "Fold: 31  Epoch: 43  Training loss = 2.9845  Validation loss = 1.4042  \n",
      "\n",
      "Fold: 31  Epoch: 44  Training loss = 2.9844  Validation loss = 1.4042  \n",
      "\n",
      "Fold: 31  Epoch: 45  Training loss = 2.9844  Validation loss = 1.4042  \n",
      "\n",
      "Fold: 31  Epoch: 46  Training loss = 2.9843  Validation loss = 1.4038  \n",
      "\n",
      "Fold: 31  Epoch: 47  Training loss = 2.9843  Validation loss = 1.4034  \n",
      "\n",
      "Fold: 31  Epoch: 48  Training loss = 2.9842  Validation loss = 1.4032  \n",
      "\n",
      "Fold: 31  Epoch: 49  Training loss = 2.9841  Validation loss = 1.4031  \n",
      "\n",
      "Fold: 31  Epoch: 50  Training loss = 2.9841  Validation loss = 1.4030  \n",
      "\n",
      "Fold: 31  Epoch: 51  Training loss = 2.9840  Validation loss = 1.4029  \n",
      "\n",
      "Fold: 31  Epoch: 52  Training loss = 2.9840  Validation loss = 1.4029  \n",
      "\n",
      "Fold: 31  Epoch: 53  Training loss = 2.9839  Validation loss = 1.4028  \n",
      "\n",
      "Fold: 31  Epoch: 54  Training loss = 2.9838  Validation loss = 1.4025  \n",
      "\n",
      "Fold: 31  Epoch: 55  Training loss = 2.9838  Validation loss = 1.4024  \n",
      "\n",
      "Fold: 31  Epoch: 56  Training loss = 2.9837  Validation loss = 1.4019  \n",
      "\n",
      "Fold: 31  Epoch: 57  Training loss = 2.9836  Validation loss = 1.4015  \n",
      "\n",
      "Fold: 31  Epoch: 58  Training loss = 2.9836  Validation loss = 1.4012  \n",
      "\n",
      "Fold: 31  Epoch: 59  Training loss = 2.9835  Validation loss = 1.4009  \n",
      "\n",
      "Fold: 31  Epoch: 60  Training loss = 2.9835  Validation loss = 1.4010  \n",
      "\n",
      "Fold: 31  Epoch: 61  Training loss = 2.9834  Validation loss = 1.4009  \n",
      "\n",
      "Fold: 31  Epoch: 62  Training loss = 2.9834  Validation loss = 1.4009  \n",
      "\n",
      "Fold: 31  Epoch: 63  Training loss = 2.9833  Validation loss = 1.4007  \n",
      "\n",
      "Fold: 31  Epoch: 64  Training loss = 2.9832  Validation loss = 1.4005  \n",
      "\n",
      "Fold: 31  Epoch: 65  Training loss = 2.9832  Validation loss = 1.4004  \n",
      "\n",
      "Fold: 31  Epoch: 66  Training loss = 2.9831  Validation loss = 1.4001  \n",
      "\n",
      "Fold: 31  Epoch: 67  Training loss = 2.9830  Validation loss = 1.3997  \n",
      "\n",
      "Fold: 31  Epoch: 68  Training loss = 2.9830  Validation loss = 1.3994  \n",
      "\n",
      "Fold: 31  Epoch: 69  Training loss = 2.9829  Validation loss = 1.3991  \n",
      "\n",
      "Fold: 31  Epoch: 70  Training loss = 2.9828  Validation loss = 1.3988  \n",
      "\n",
      "Fold: 31  Epoch: 71  Training loss = 2.9827  Validation loss = 1.3984  \n",
      "\n",
      "Fold: 31  Epoch: 72  Training loss = 2.9827  Validation loss = 1.3981  \n",
      "\n",
      "Fold: 31  Epoch: 73  Training loss = 2.9826  Validation loss = 1.3980  \n",
      "\n",
      "Fold: 31  Epoch: 74  Training loss = 2.9826  Validation loss = 1.3982  \n",
      "\n",
      "Fold: 31  Epoch: 75  Training loss = 2.9825  Validation loss = 1.3980  \n",
      "\n",
      "Fold: 31  Epoch: 76  Training loss = 2.9824  Validation loss = 1.3980  \n",
      "\n",
      "Fold: 31  Epoch: 77  Training loss = 2.9824  Validation loss = 1.3980  \n",
      "\n",
      "Fold: 31  Epoch: 78  Training loss = 2.9823  Validation loss = 1.3980  \n",
      "\n",
      "Fold: 31  Epoch: 79  Training loss = 2.9823  Validation loss = 1.3982  \n",
      "\n",
      "Fold: 31  Epoch: 80  Training loss = 2.9822  Validation loss = 1.3980  \n",
      "\n",
      "Fold: 31  Epoch: 81  Training loss = 2.9821  Validation loss = 1.3977  \n",
      "\n",
      "Fold: 31  Epoch: 82  Training loss = 2.9821  Validation loss = 1.3976  \n",
      "\n",
      "Fold: 31  Epoch: 83  Training loss = 2.9820  Validation loss = 1.3976  \n",
      "\n",
      "Fold: 31  Epoch: 84  Training loss = 2.9820  Validation loss = 1.3973  \n",
      "\n",
      "Fold: 31  Epoch: 85  Training loss = 2.9819  Validation loss = 1.3972  \n",
      "\n",
      "Fold: 31  Epoch: 86  Training loss = 2.9818  Validation loss = 1.3969  \n",
      "\n",
      "Fold: 31  Epoch: 87  Training loss = 2.9817  Validation loss = 1.3969  \n",
      "\n",
      "Fold: 31  Epoch: 88  Training loss = 2.9816  Validation loss = 1.3967  \n",
      "\n",
      "Fold: 31  Epoch: 89  Training loss = 2.9816  Validation loss = 1.3965  \n",
      "\n",
      "Fold: 31  Epoch: 90  Training loss = 2.9815  Validation loss = 1.3962  \n",
      "\n",
      "Fold: 31  Epoch: 91  Training loss = 2.9815  Validation loss = 1.3962  \n",
      "\n",
      "Fold: 31  Epoch: 92  Training loss = 2.9814  Validation loss = 1.3961  \n",
      "\n",
      "Fold: 31  Epoch: 93  Training loss = 2.9813  Validation loss = 1.3956  \n",
      "\n",
      "Fold: 31  Epoch: 94  Training loss = 2.9812  Validation loss = 1.3953  \n",
      "\n",
      "Fold: 31  Epoch: 95  Training loss = 2.9811  Validation loss = 1.3951  \n",
      "\n",
      "Fold: 31  Epoch: 96  Training loss = 2.9810  Validation loss = 1.3952  \n",
      "\n",
      "Fold: 31  Epoch: 97  Training loss = 2.9810  Validation loss = 1.3949  \n",
      "\n",
      "Fold: 31  Epoch: 98  Training loss = 2.9809  Validation loss = 1.3948  \n",
      "\n",
      "Fold: 31  Epoch: 99  Training loss = 2.9809  Validation loss = 1.3948  \n",
      "\n",
      "Fold: 31  Epoch: 100  Training loss = 2.9808  Validation loss = 1.3946  \n",
      "\n",
      "Fold: 31  Epoch: 101  Training loss = 2.9808  Validation loss = 1.3944  \n",
      "\n",
      "Fold: 31  Epoch: 102  Training loss = 2.9807  Validation loss = 1.3942  \n",
      "\n",
      "Fold: 31  Epoch: 103  Training loss = 2.9806  Validation loss = 1.3941  \n",
      "\n",
      "Fold: 31  Epoch: 104  Training loss = 2.9805  Validation loss = 1.3940  \n",
      "\n",
      "Fold: 31  Epoch: 105  Training loss = 2.9805  Validation loss = 1.3940  \n",
      "\n",
      "Fold: 31  Epoch: 106  Training loss = 2.9804  Validation loss = 1.3936  \n",
      "\n",
      "Fold: 31  Epoch: 107  Training loss = 2.9803  Validation loss = 1.3934  \n",
      "\n",
      "Fold: 31  Epoch: 108  Training loss = 2.9803  Validation loss = 1.3932  \n",
      "\n",
      "Fold: 31  Epoch: 109  Training loss = 2.9802  Validation loss = 1.3935  \n",
      "\n",
      "Fold: 31  Epoch: 110  Training loss = 2.9801  Validation loss = 1.3932  \n",
      "\n",
      "Fold: 31  Epoch: 111  Training loss = 2.9801  Validation loss = 1.3928  \n",
      "\n",
      "Fold: 31  Epoch: 112  Training loss = 2.9800  Validation loss = 1.3927  \n",
      "\n",
      "Fold: 31  Epoch: 113  Training loss = 2.9799  Validation loss = 1.3924  \n",
      "\n",
      "Fold: 31  Epoch: 114  Training loss = 2.9799  Validation loss = 1.3925  \n",
      "\n",
      "Fold: 31  Epoch: 115  Training loss = 2.9798  Validation loss = 1.3926  \n",
      "\n",
      "Fold: 31  Epoch: 116  Training loss = 2.9798  Validation loss = 1.3924  \n",
      "\n",
      "Fold: 31  Epoch: 117  Training loss = 2.9797  Validation loss = 1.3920  \n",
      "\n",
      "Fold: 31  Epoch: 118  Training loss = 2.9797  Validation loss = 1.3921  \n",
      "\n",
      "Fold: 31  Epoch: 119  Training loss = 2.9796  Validation loss = 1.3922  \n",
      "\n",
      "Fold: 31  Epoch: 120  Training loss = 2.9796  Validation loss = 1.3922  \n",
      "\n",
      "Fold: 31  Epoch: 121  Training loss = 2.9795  Validation loss = 1.3919  \n",
      "\n",
      "Fold: 31  Epoch: 122  Training loss = 2.9795  Validation loss = 1.3917  \n",
      "\n",
      "Fold: 31  Epoch: 123  Training loss = 2.9794  Validation loss = 1.3913  \n",
      "\n",
      "Fold: 31  Epoch: 124  Training loss = 2.9793  Validation loss = 1.3907  \n",
      "\n",
      "Fold: 31  Epoch: 125  Training loss = 2.9792  Validation loss = 1.3903  \n",
      "\n",
      "Fold: 31  Epoch: 126  Training loss = 2.9791  Validation loss = 1.3903  \n",
      "\n",
      "Fold: 31  Epoch: 127  Training loss = 2.9790  Validation loss = 1.3901  \n",
      "\n",
      "Fold: 31  Epoch: 128  Training loss = 2.9790  Validation loss = 1.3900  \n",
      "\n",
      "Fold: 31  Epoch: 129  Training loss = 2.9789  Validation loss = 1.3899  \n",
      "\n",
      "Fold: 31  Epoch: 130  Training loss = 2.9788  Validation loss = 1.3898  \n",
      "\n",
      "Fold: 31  Epoch: 131  Training loss = 2.9787  Validation loss = 1.3897  \n",
      "\n",
      "Fold: 31  Epoch: 132  Training loss = 2.9787  Validation loss = 1.3894  \n",
      "\n",
      "Fold: 31  Epoch: 133  Training loss = 2.9786  Validation loss = 1.3891  \n",
      "\n",
      "Fold: 31  Epoch: 134  Training loss = 2.9785  Validation loss = 1.3891  \n",
      "\n",
      "Fold: 31  Epoch: 135  Training loss = 2.9785  Validation loss = 1.3887  \n",
      "\n",
      "Fold: 31  Epoch: 136  Training loss = 2.9784  Validation loss = 1.3884  \n",
      "\n",
      "Fold: 31  Epoch: 137  Training loss = 2.9783  Validation loss = 1.3883  \n",
      "\n",
      "Fold: 31  Epoch: 138  Training loss = 2.9783  Validation loss = 1.3882  \n",
      "\n",
      "Fold: 31  Epoch: 139  Training loss = 2.9782  Validation loss = 1.3880  \n",
      "\n",
      "Fold: 31  Epoch: 140  Training loss = 2.9781  Validation loss = 1.3876  \n",
      "\n",
      "Fold: 31  Epoch: 141  Training loss = 2.9780  Validation loss = 1.3876  \n",
      "\n",
      "Fold: 31  Epoch: 142  Training loss = 2.9780  Validation loss = 1.3875  \n",
      "\n",
      "Fold: 31  Epoch: 143  Training loss = 2.9779  Validation loss = 1.3871  \n",
      "\n",
      "Fold: 31  Epoch: 144  Training loss = 2.9778  Validation loss = 1.3868  \n",
      "\n",
      "Fold: 31  Epoch: 145  Training loss = 2.9778  Validation loss = 1.3865  \n",
      "\n",
      "Fold: 31  Epoch: 146  Training loss = 2.9777  Validation loss = 1.3860  \n",
      "\n",
      "Fold: 31  Epoch: 147  Training loss = 2.9776  Validation loss = 1.3856  \n",
      "\n",
      "Fold: 31  Epoch: 148  Training loss = 2.9776  Validation loss = 1.3853  \n",
      "\n",
      "Fold: 31  Epoch: 149  Training loss = 2.9775  Validation loss = 1.3852  \n",
      "\n",
      "Fold: 31  Epoch: 150  Training loss = 2.9774  Validation loss = 1.3846  \n",
      "\n",
      "Fold: 31  Epoch: 151  Training loss = 2.9774  Validation loss = 1.3845  \n",
      "\n",
      "Fold: 31  Epoch: 152  Training loss = 2.9774  Validation loss = 1.3847  \n",
      "\n",
      "Fold: 31  Epoch: 153  Training loss = 2.9773  Validation loss = 1.3843  \n",
      "\n",
      "Fold: 31  Epoch: 154  Training loss = 2.9772  Validation loss = 1.3840  \n",
      "\n",
      "Fold: 31  Epoch: 155  Training loss = 2.9771  Validation loss = 1.3839  \n",
      "\n",
      "Fold: 31  Epoch: 156  Training loss = 2.9771  Validation loss = 1.3835  \n",
      "\n",
      "Fold: 31  Epoch: 157  Training loss = 2.9770  Validation loss = 1.3833  \n",
      "\n",
      "Fold: 31  Epoch: 158  Training loss = 2.9769  Validation loss = 1.3832  \n",
      "\n",
      "Fold: 31  Epoch: 159  Training loss = 2.9769  Validation loss = 1.3834  \n",
      "\n",
      "Fold: 31  Epoch: 160  Training loss = 2.9769  Validation loss = 1.3834  \n",
      "\n",
      "Fold: 31  Epoch: 161  Training loss = 2.9768  Validation loss = 1.3830  \n",
      "\n",
      "Fold: 31  Epoch: 162  Training loss = 2.9767  Validation loss = 1.3828  \n",
      "\n",
      "Fold: 31  Epoch: 163  Training loss = 2.9766  Validation loss = 1.3825  \n",
      "\n",
      "Fold: 31  Epoch: 164  Training loss = 2.9765  Validation loss = 1.3822  \n",
      "\n",
      "Fold: 31  Epoch: 165  Training loss = 2.9764  Validation loss = 1.3816  \n",
      "\n",
      "Fold: 31  Epoch: 166  Training loss = 2.9763  Validation loss = 1.3814  \n",
      "\n",
      "Fold: 31  Epoch: 167  Training loss = 2.9762  Validation loss = 1.3808  \n",
      "\n",
      "Fold: 31  Epoch: 168  Training loss = 2.9762  Validation loss = 1.3807  \n",
      "\n",
      "Fold: 31  Epoch: 169  Training loss = 2.9761  Validation loss = 1.3804  \n",
      "\n",
      "Fold: 31  Epoch: 170  Training loss = 2.9760  Validation loss = 1.3798  \n",
      "\n",
      "Fold: 31  Epoch: 171  Training loss = 2.9759  Validation loss = 1.3791  \n",
      "\n",
      "Fold: 31  Epoch: 172  Training loss = 2.9758  Validation loss = 1.3789  \n",
      "\n",
      "Fold: 31  Epoch: 173  Training loss = 2.9757  Validation loss = 1.3789  \n",
      "\n",
      "Fold: 31  Epoch: 174  Training loss = 2.9756  Validation loss = 1.3787  \n",
      "\n",
      "Fold: 31  Epoch: 175  Training loss = 2.9756  Validation loss = 1.3786  \n",
      "\n",
      "Fold: 31  Epoch: 176  Training loss = 2.9755  Validation loss = 1.3783  \n",
      "\n",
      "Fold: 31  Epoch: 177  Training loss = 2.9754  Validation loss = 1.3781  \n",
      "\n",
      "Fold: 31  Epoch: 178  Training loss = 2.9753  Validation loss = 1.3776  \n",
      "\n",
      "Fold: 31  Epoch: 179  Training loss = 2.9753  Validation loss = 1.3774  \n",
      "\n",
      "Fold: 31  Epoch: 180  Training loss = 2.9752  Validation loss = 1.3771  \n",
      "\n",
      "Fold: 31  Epoch: 181  Training loss = 2.9750  Validation loss = 1.3764  \n",
      "\n",
      "Fold: 31  Epoch: 182  Training loss = 2.9749  Validation loss = 1.3760  \n",
      "\n",
      "Fold: 31  Epoch: 183  Training loss = 2.9749  Validation loss = 1.3756  \n",
      "\n",
      "Fold: 31  Epoch: 184  Training loss = 2.9747  Validation loss = 1.3751  \n",
      "\n",
      "Fold: 31  Epoch: 185  Training loss = 2.9747  Validation loss = 1.3749  \n",
      "\n",
      "Fold: 31  Epoch: 186  Training loss = 2.9746  Validation loss = 1.3744  \n",
      "\n",
      "Fold: 31  Epoch: 187  Training loss = 2.9745  Validation loss = 1.3741  \n",
      "\n",
      "Fold: 31  Epoch: 188  Training loss = 2.9744  Validation loss = 1.3739  \n",
      "\n",
      "Fold: 31  Epoch: 189  Training loss = 2.9744  Validation loss = 1.3738  \n",
      "\n",
      "Fold: 31  Epoch: 190  Training loss = 2.9743  Validation loss = 1.3735  \n",
      "\n",
      "Fold: 31  Epoch: 191  Training loss = 2.9742  Validation loss = 1.3730  \n",
      "\n",
      "Fold: 31  Epoch: 192  Training loss = 2.9742  Validation loss = 1.3726  \n",
      "\n",
      "Fold: 31  Epoch: 193  Training loss = 2.9741  Validation loss = 1.3724  \n",
      "\n",
      "Fold: 31  Epoch: 194  Training loss = 2.9740  Validation loss = 1.3719  \n",
      "\n",
      "Fold: 31  Epoch: 195  Training loss = 2.9739  Validation loss = 1.3717  \n",
      "\n",
      "Fold: 31  Epoch: 196  Training loss = 2.9737  Validation loss = 1.3710  \n",
      "\n",
      "Fold: 31  Epoch: 197  Training loss = 2.9737  Validation loss = 1.3706  \n",
      "\n",
      "Fold: 31  Epoch: 198  Training loss = 2.9736  Validation loss = 1.3703  \n",
      "\n",
      "Fold: 31  Epoch: 199  Training loss = 2.9734  Validation loss = 1.3693  \n",
      "\n",
      "Fold: 31  Epoch: 200  Training loss = 2.9733  Validation loss = 1.3690  \n",
      "\n",
      "Fold: 31  Epoch: 201  Training loss = 2.9732  Validation loss = 1.3687  \n",
      "\n",
      "Fold: 31  Epoch: 202  Training loss = 2.9731  Validation loss = 1.3683  \n",
      "\n",
      "Fold: 31  Epoch: 203  Training loss = 2.9730  Validation loss = 1.3680  \n",
      "\n",
      "Fold: 31  Epoch: 204  Training loss = 2.9729  Validation loss = 1.3677  \n",
      "\n",
      "Fold: 31  Epoch: 205  Training loss = 2.9727  Validation loss = 1.3670  \n",
      "\n",
      "Fold: 31  Epoch: 206  Training loss = 2.9726  Validation loss = 1.3667  \n",
      "\n",
      "Fold: 31  Epoch: 207  Training loss = 2.9725  Validation loss = 1.3667  \n",
      "\n",
      "Fold: 31  Epoch: 208  Training loss = 2.9724  Validation loss = 1.3663  \n",
      "\n",
      "Fold: 31  Epoch: 209  Training loss = 2.9724  Validation loss = 1.3661  \n",
      "\n",
      "Fold: 31  Epoch: 210  Training loss = 2.9723  Validation loss = 1.3660  \n",
      "\n",
      "Fold: 31  Epoch: 211  Training loss = 2.9723  Validation loss = 1.3657  \n",
      "\n",
      "Fold: 31  Epoch: 212  Training loss = 2.9722  Validation loss = 1.3658  \n",
      "\n",
      "Fold: 31  Epoch: 213  Training loss = 2.9720  Validation loss = 1.3647  \n",
      "\n",
      "Fold: 31  Epoch: 214  Training loss = 2.9719  Validation loss = 1.3642  \n",
      "\n",
      "Fold: 31  Epoch: 215  Training loss = 2.9718  Validation loss = 1.3640  \n",
      "\n",
      "Fold: 31  Epoch: 216  Training loss = 2.9717  Validation loss = 1.3633  \n",
      "\n",
      "Fold: 31  Epoch: 217  Training loss = 2.9715  Validation loss = 1.3625  \n",
      "\n",
      "Fold: 31  Epoch: 218  Training loss = 2.9714  Validation loss = 1.3624  \n",
      "\n",
      "Fold: 31  Epoch: 219  Training loss = 2.9712  Validation loss = 1.3613  \n",
      "\n",
      "Fold: 31  Epoch: 220  Training loss = 2.9710  Validation loss = 1.3604  \n",
      "\n",
      "Fold: 31  Epoch: 221  Training loss = 2.9708  Validation loss = 1.3595  \n",
      "\n",
      "Fold: 31  Epoch: 222  Training loss = 2.9708  Validation loss = 1.3595  \n",
      "\n",
      "Fold: 31  Epoch: 223  Training loss = 2.9707  Validation loss = 1.3592  \n",
      "\n",
      "Fold: 31  Epoch: 224  Training loss = 2.9706  Validation loss = 1.3590  \n",
      "\n",
      "Fold: 31  Epoch: 225  Training loss = 2.9705  Validation loss = 1.3587  \n",
      "\n",
      "Fold: 31  Epoch: 226  Training loss = 2.9704  Validation loss = 1.3583  \n",
      "\n",
      "Fold: 31  Epoch: 227  Training loss = 2.9701  Validation loss = 1.3568  \n",
      "\n",
      "Fold: 31  Epoch: 228  Training loss = 2.9701  Validation loss = 1.3567  \n",
      "\n",
      "Fold: 31  Epoch: 229  Training loss = 2.9700  Validation loss = 1.3563  \n",
      "\n",
      "Fold: 31  Epoch: 230  Training loss = 2.9698  Validation loss = 1.3556  \n",
      "\n",
      "Fold: 31  Epoch: 231  Training loss = 2.9696  Validation loss = 1.3545  \n",
      "\n",
      "Fold: 31  Epoch: 232  Training loss = 2.9695  Validation loss = 1.3544  \n",
      "\n",
      "Fold: 31  Epoch: 233  Training loss = 2.9694  Validation loss = 1.3537  \n",
      "\n",
      "Fold: 31  Epoch: 234  Training loss = 2.9693  Validation loss = 1.3532  \n",
      "\n",
      "Fold: 31  Epoch: 235  Training loss = 2.9692  Validation loss = 1.3528  \n",
      "\n",
      "Fold: 31  Epoch: 236  Training loss = 2.9691  Validation loss = 1.3526  \n",
      "\n",
      "Fold: 31  Epoch: 237  Training loss = 2.9689  Validation loss = 1.3523  \n",
      "\n",
      "Fold: 31  Epoch: 238  Training loss = 2.9689  Validation loss = 1.3522  \n",
      "\n",
      "Fold: 31  Epoch: 239  Training loss = 2.9687  Validation loss = 1.3517  \n",
      "\n",
      "Fold: 31  Epoch: 240  Training loss = 2.9687  Validation loss = 1.3517  \n",
      "\n",
      "Fold: 31  Epoch: 241  Training loss = 2.9687  Validation loss = 1.3519  \n",
      "\n",
      "Fold: 31  Epoch: 242  Training loss = 2.9686  Validation loss = 1.3516  \n",
      "\n",
      "Fold: 31  Epoch: 243  Training loss = 2.9685  Validation loss = 1.3515  \n",
      "\n",
      "Fold: 31  Epoch: 244  Training loss = 2.9684  Validation loss = 1.3510  \n",
      "\n",
      "Fold: 31  Epoch: 245  Training loss = 2.9683  Validation loss = 1.3503  \n",
      "\n",
      "Fold: 31  Epoch: 246  Training loss = 2.9682  Validation loss = 1.3500  \n",
      "\n",
      "Fold: 31  Epoch: 247  Training loss = 2.9681  Validation loss = 1.3499  \n",
      "\n",
      "Fold: 31  Epoch: 248  Training loss = 2.9680  Validation loss = 1.3492  \n",
      "\n",
      "Fold: 31  Epoch: 249  Training loss = 2.9679  Validation loss = 1.3491  \n",
      "\n",
      "Fold: 31  Epoch: 250  Training loss = 2.9678  Validation loss = 1.3481  \n",
      "\n",
      "Fold: 31  Epoch: 251  Training loss = 2.9677  Validation loss = 1.3481  \n",
      "\n",
      "Fold: 31  Epoch: 252  Training loss = 2.9676  Validation loss = 1.3476  \n",
      "\n",
      "Fold: 31  Epoch: 253  Training loss = 2.9676  Validation loss = 1.3476  \n",
      "\n",
      "Fold: 31  Epoch: 254  Training loss = 2.9675  Validation loss = 1.3469  \n",
      "\n",
      "Fold: 31  Epoch: 255  Training loss = 2.9674  Validation loss = 1.3465  \n",
      "\n",
      "Fold: 31  Epoch: 256  Training loss = 2.9673  Validation loss = 1.3461  \n",
      "\n",
      "Fold: 31  Epoch: 257  Training loss = 2.9672  Validation loss = 1.3463  \n",
      "\n",
      "Fold: 31  Epoch: 258  Training loss = 2.9671  Validation loss = 1.3460  \n",
      "\n",
      "Fold: 31  Epoch: 259  Training loss = 2.9670  Validation loss = 1.3453  \n",
      "\n",
      "Fold: 31  Epoch: 260  Training loss = 2.9669  Validation loss = 1.3449  \n",
      "\n",
      "Fold: 31  Epoch: 261  Training loss = 2.9668  Validation loss = 1.3446  \n",
      "\n",
      "Fold: 31  Epoch: 262  Training loss = 2.9668  Validation loss = 1.3445  \n",
      "\n",
      "Fold: 31  Epoch: 263  Training loss = 2.9666  Validation loss = 1.3439  \n",
      "\n",
      "Fold: 31  Epoch: 264  Training loss = 2.9666  Validation loss = 1.3434  \n",
      "\n",
      "Fold: 31  Epoch: 265  Training loss = 2.9665  Validation loss = 1.3430  \n",
      "\n",
      "Fold: 31  Epoch: 266  Training loss = 2.9664  Validation loss = 1.3430  \n",
      "\n",
      "Fold: 31  Epoch: 267  Training loss = 2.9663  Validation loss = 1.3420  \n",
      "\n",
      "Fold: 31  Epoch: 268  Training loss = 2.9662  Validation loss = 1.3414  \n",
      "\n",
      "Fold: 31  Epoch: 269  Training loss = 2.9661  Validation loss = 1.3409  \n",
      "\n",
      "Fold: 31  Epoch: 270  Training loss = 2.9660  Validation loss = 1.3409  \n",
      "\n",
      "Fold: 31  Epoch: 271  Training loss = 2.9660  Validation loss = 1.3406  \n",
      "\n",
      "Fold: 31  Epoch: 272  Training loss = 2.9658  Validation loss = 1.3399  \n",
      "\n",
      "Fold: 31  Epoch: 273  Training loss = 2.9658  Validation loss = 1.3399  \n",
      "\n",
      "Fold: 31  Epoch: 274  Training loss = 2.9657  Validation loss = 1.3396  \n",
      "\n",
      "Fold: 31  Epoch: 275  Training loss = 2.9657  Validation loss = 1.3395  \n",
      "\n",
      "Fold: 31  Epoch: 276  Training loss = 2.9656  Validation loss = 1.3394  \n",
      "\n",
      "Fold: 31  Epoch: 277  Training loss = 2.9656  Validation loss = 1.3390  \n",
      "\n",
      "Fold: 31  Epoch: 278  Training loss = 2.9655  Validation loss = 1.3384  \n",
      "\n",
      "Fold: 31  Epoch: 279  Training loss = 2.9654  Validation loss = 1.3382  \n",
      "\n",
      "Fold: 31  Epoch: 280  Training loss = 2.9653  Validation loss = 1.3374  \n",
      "\n",
      "Fold: 31  Epoch: 281  Training loss = 2.9652  Validation loss = 1.3371  \n",
      "\n",
      "Fold: 31  Epoch: 282  Training loss = 2.9651  Validation loss = 1.3371  \n",
      "\n",
      "Fold: 31  Epoch: 283  Training loss = 2.9651  Validation loss = 1.3366  \n",
      "\n",
      "Fold: 31  Epoch: 284  Training loss = 2.9650  Validation loss = 1.3360  \n",
      "\n",
      "Fold: 31  Epoch: 285  Training loss = 2.9649  Validation loss = 1.3358  \n",
      "\n",
      "Fold: 31  Epoch: 286  Training loss = 2.9648  Validation loss = 1.3352  \n",
      "\n",
      "Fold: 31  Epoch: 287  Training loss = 2.9648  Validation loss = 1.3354  \n",
      "\n",
      "Fold: 31  Epoch: 288  Training loss = 2.9647  Validation loss = 1.3352  \n",
      "\n",
      "Fold: 31  Epoch: 289  Training loss = 2.9647  Validation loss = 1.3351  \n",
      "\n",
      "Fold: 31  Epoch: 290  Training loss = 2.9646  Validation loss = 1.3345  \n",
      "\n",
      "Fold: 31  Epoch: 291  Training loss = 2.9645  Validation loss = 1.3339  \n",
      "\n",
      "Fold: 31  Epoch: 292  Training loss = 2.9644  Validation loss = 1.3340  \n",
      "\n",
      "Fold: 31  Epoch: 293  Training loss = 2.9643  Validation loss = 1.3338  \n",
      "\n",
      "Fold: 31  Epoch: 294  Training loss = 2.9643  Validation loss = 1.3337  \n",
      "\n",
      "Fold: 31  Epoch: 295  Training loss = 2.9642  Validation loss = 1.3335  \n",
      "\n",
      "Fold: 31  Epoch: 296  Training loss = 2.9641  Validation loss = 1.3333  \n",
      "\n",
      "Fold: 31  Epoch: 297  Training loss = 2.9641  Validation loss = 1.3330  \n",
      "\n",
      "Fold: 31  Epoch: 298  Training loss = 2.9640  Validation loss = 1.3325  \n",
      "\n",
      "Fold: 31  Epoch: 299  Training loss = 2.9639  Validation loss = 1.3327  \n",
      "\n",
      "Fold: 31  Epoch: 300  Training loss = 2.9639  Validation loss = 1.3321  \n",
      "\n",
      "Fold: 31  Epoch: 301  Training loss = 2.9638  Validation loss = 1.3316  \n",
      "\n",
      "Fold: 31  Epoch: 302  Training loss = 2.9638  Validation loss = 1.3313  \n",
      "\n",
      "Fold: 31  Epoch: 303  Training loss = 2.9637  Validation loss = 1.3313  \n",
      "\n",
      "Fold: 31  Epoch: 304  Training loss = 2.9637  Validation loss = 1.3312  \n",
      "\n",
      "Fold: 31  Epoch: 305  Training loss = 2.9636  Validation loss = 1.3308  \n",
      "\n",
      "Fold: 31  Epoch: 306  Training loss = 2.9635  Validation loss = 1.3305  \n",
      "\n",
      "Fold: 31  Epoch: 307  Training loss = 2.9634  Validation loss = 1.3299  \n",
      "\n",
      "Fold: 31  Epoch: 308  Training loss = 2.9633  Validation loss = 1.3294  \n",
      "\n",
      "Fold: 31  Epoch: 309  Training loss = 2.9633  Validation loss = 1.3290  \n",
      "\n",
      "Fold: 31  Epoch: 310  Training loss = 2.9632  Validation loss = 1.3285  \n",
      "\n",
      "Fold: 31  Epoch: 311  Training loss = 2.9631  Validation loss = 1.3281  \n",
      "\n",
      "Fold: 31  Epoch: 312  Training loss = 2.9630  Validation loss = 1.3279  \n",
      "\n",
      "Fold: 31  Epoch: 313  Training loss = 2.9630  Validation loss = 1.3276  \n",
      "\n",
      "Fold: 31  Epoch: 314  Training loss = 2.9629  Validation loss = 1.3276  \n",
      "\n",
      "Fold: 31  Epoch: 315  Training loss = 2.9629  Validation loss = 1.3273  \n",
      "\n",
      "Fold: 31  Epoch: 316  Training loss = 2.9628  Validation loss = 1.3273  \n",
      "\n",
      "Fold: 31  Epoch: 317  Training loss = 2.9628  Validation loss = 1.3269  \n",
      "\n",
      "Fold: 31  Epoch: 318  Training loss = 2.9627  Validation loss = 1.3265  \n",
      "\n",
      "Fold: 31  Epoch: 319  Training loss = 2.9627  Validation loss = 1.3263  \n",
      "\n",
      "Fold: 31  Epoch: 320  Training loss = 2.9626  Validation loss = 1.3260  \n",
      "\n",
      "Fold: 31  Epoch: 321  Training loss = 2.9625  Validation loss = 1.3257  \n",
      "\n",
      "Fold: 31  Epoch: 322  Training loss = 2.9625  Validation loss = 1.3255  \n",
      "\n",
      "Fold: 31  Epoch: 323  Training loss = 2.9624  Validation loss = 1.3249  \n",
      "\n",
      "Fold: 31  Epoch: 324  Training loss = 2.9623  Validation loss = 1.3249  \n",
      "\n",
      "Fold: 31  Epoch: 325  Training loss = 2.9623  Validation loss = 1.3245  \n",
      "\n",
      "Fold: 31  Epoch: 326  Training loss = 2.9622  Validation loss = 1.3244  \n",
      "\n",
      "Fold: 31  Epoch: 327  Training loss = 2.9621  Validation loss = 1.3240  \n",
      "\n",
      "Fold: 31  Epoch: 328  Training loss = 2.9621  Validation loss = 1.3236  \n",
      "\n",
      "Fold: 31  Epoch: 329  Training loss = 2.9620  Validation loss = 1.3239  \n",
      "\n",
      "Fold: 31  Epoch: 330  Training loss = 2.9620  Validation loss = 1.3236  \n",
      "\n",
      "Fold: 31  Epoch: 331  Training loss = 2.9619  Validation loss = 1.3238  \n",
      "\n",
      "Fold: 31  Epoch: 332  Training loss = 2.9618  Validation loss = 1.3233  \n",
      "\n",
      "Fold: 31  Epoch: 333  Training loss = 2.9618  Validation loss = 1.3234  \n",
      "\n",
      "Fold: 31  Epoch: 334  Training loss = 2.9617  Validation loss = 1.3228  \n",
      "\n",
      "Fold: 31  Epoch: 335  Training loss = 2.9616  Validation loss = 1.3222  \n",
      "\n",
      "Fold: 31  Epoch: 336  Training loss = 2.9616  Validation loss = 1.3224  \n",
      "\n",
      "Fold: 31  Epoch: 337  Training loss = 2.9615  Validation loss = 1.3219  \n",
      "\n",
      "Fold: 31  Epoch: 338  Training loss = 2.9614  Validation loss = 1.3216  \n",
      "\n",
      "Fold: 31  Epoch: 339  Training loss = 2.9613  Validation loss = 1.3214  \n",
      "\n",
      "Fold: 31  Epoch: 340  Training loss = 2.9613  Validation loss = 1.3212  \n",
      "\n",
      "Fold: 31  Epoch: 341  Training loss = 2.9612  Validation loss = 1.3207  \n",
      "\n",
      "Fold: 31  Epoch: 342  Training loss = 2.9612  Validation loss = 1.3204  \n",
      "\n",
      "Fold: 31  Epoch: 343  Training loss = 2.9611  Validation loss = 1.3204  \n",
      "\n",
      "Fold: 31  Epoch: 344  Training loss = 2.9611  Validation loss = 1.3203  \n",
      "\n",
      "Fold: 31  Epoch: 345  Training loss = 2.9610  Validation loss = 1.3199  \n",
      "\n",
      "Fold: 31  Epoch: 346  Training loss = 2.9610  Validation loss = 1.3202  \n",
      "\n",
      "Fold: 31  Epoch: 347  Training loss = 2.9609  Validation loss = 1.3199  \n",
      "\n",
      "Fold: 31  Epoch: 348  Training loss = 2.9609  Validation loss = 1.3195  \n",
      "\n",
      "Fold: 31  Epoch: 349  Training loss = 2.9608  Validation loss = 1.3195  \n",
      "\n",
      "Fold: 31  Epoch: 350  Training loss = 2.9607  Validation loss = 1.3189  \n",
      "\n",
      "Fold: 31  Epoch: 351  Training loss = 2.9606  Validation loss = 1.3179  \n",
      "\n",
      "Fold: 31  Epoch: 352  Training loss = 2.9606  Validation loss = 1.3181  \n",
      "\n",
      "Fold: 31  Epoch: 353  Training loss = 2.9605  Validation loss = 1.3179  \n",
      "\n",
      "Fold: 31  Epoch: 354  Training loss = 2.9605  Validation loss = 1.3176  \n",
      "\n",
      "Fold: 31  Epoch: 355  Training loss = 2.9604  Validation loss = 1.3166  \n",
      "\n",
      "Fold: 31  Epoch: 356  Training loss = 2.9603  Validation loss = 1.3167  \n",
      "\n",
      "Fold: 31  Epoch: 357  Training loss = 2.9602  Validation loss = 1.3165  \n",
      "\n",
      "Fold: 31  Epoch: 358  Training loss = 2.9601  Validation loss = 1.3158  \n",
      "\n",
      "Fold: 31  Epoch: 359  Training loss = 2.9601  Validation loss = 1.3161  \n",
      "\n",
      "Fold: 31  Epoch: 360  Training loss = 2.9601  Validation loss = 1.3157  \n",
      "\n",
      "Fold: 31  Epoch: 361  Training loss = 2.9600  Validation loss = 1.3152  \n",
      "\n",
      "Fold: 31  Epoch: 362  Training loss = 2.9599  Validation loss = 1.3149  \n",
      "\n",
      "Fold: 31  Epoch: 363  Training loss = 2.9599  Validation loss = 1.3150  \n",
      "\n",
      "Fold: 31  Epoch: 364  Training loss = 2.9598  Validation loss = 1.3150  \n",
      "\n",
      "Fold: 31  Epoch: 365  Training loss = 2.9598  Validation loss = 1.3144  \n",
      "\n",
      "Fold: 31  Epoch: 366  Training loss = 2.9597  Validation loss = 1.3137  \n",
      "\n",
      "Fold: 31  Epoch: 367  Training loss = 2.9596  Validation loss = 1.3134  \n",
      "\n",
      "Fold: 31  Epoch: 368  Training loss = 2.9596  Validation loss = 1.3129  \n",
      "\n",
      "Fold: 31  Epoch: 369  Training loss = 2.9595  Validation loss = 1.3121  \n",
      "\n",
      "Fold: 31  Epoch: 370  Training loss = 2.9594  Validation loss = 1.3119  \n",
      "\n",
      "Fold: 31  Epoch: 371  Training loss = 2.9594  Validation loss = 1.3115  \n",
      "\n",
      "Fold: 31  Epoch: 372  Training loss = 2.9593  Validation loss = 1.3109  \n",
      "\n",
      "Fold: 31  Epoch: 373  Training loss = 2.9592  Validation loss = 1.3106  \n",
      "\n",
      "Fold: 31  Epoch: 374  Training loss = 2.9592  Validation loss = 1.3100  \n",
      "\n",
      "Fold: 31  Epoch: 375  Training loss = 2.9591  Validation loss = 1.3098  \n",
      "\n",
      "Fold: 31  Epoch: 376  Training loss = 2.9590  Validation loss = 1.3095  \n",
      "\n",
      "Fold: 31  Epoch: 377  Training loss = 2.9589  Validation loss = 1.3093  \n",
      "\n",
      "Fold: 31  Epoch: 378  Training loss = 2.9589  Validation loss = 1.3088  \n",
      "\n",
      "Fold: 31  Epoch: 379  Training loss = 2.9588  Validation loss = 1.3089  \n",
      "\n",
      "Fold: 31  Epoch: 380  Training loss = 2.9588  Validation loss = 1.3088  \n",
      "\n",
      "Fold: 31  Epoch: 381  Training loss = 2.9587  Validation loss = 1.3084  \n",
      "\n",
      "Fold: 31  Epoch: 382  Training loss = 2.9586  Validation loss = 1.3080  \n",
      "\n",
      "Fold: 31  Epoch: 383  Training loss = 2.9586  Validation loss = 1.3073  \n",
      "\n",
      "Fold: 31  Epoch: 384  Training loss = 2.9584  Validation loss = 1.3065  \n",
      "\n",
      "Fold: 31  Epoch: 385  Training loss = 2.9584  Validation loss = 1.3066  \n",
      "\n",
      "Fold: 31  Epoch: 386  Training loss = 2.9584  Validation loss = 1.3060  \n",
      "\n",
      "Fold: 31  Epoch: 387  Training loss = 2.9583  Validation loss = 1.3059  \n",
      "\n",
      "Fold: 31  Epoch: 388  Training loss = 2.9583  Validation loss = 1.3056  \n",
      "\n",
      "Fold: 31  Epoch: 389  Training loss = 2.9582  Validation loss = 1.3059  \n",
      "\n",
      "Fold: 31  Epoch: 390  Training loss = 2.9582  Validation loss = 1.3058  \n",
      "\n",
      "Fold: 31  Epoch: 391  Training loss = 2.9581  Validation loss = 1.3054  \n",
      "\n",
      "Fold: 31  Epoch: 392  Training loss = 2.9581  Validation loss = 1.3052  \n",
      "\n",
      "Fold: 31  Epoch: 393  Training loss = 2.9580  Validation loss = 1.3045  \n",
      "\n",
      "Fold: 31  Epoch: 394  Training loss = 2.9580  Validation loss = 1.3046  \n",
      "\n",
      "Fold: 31  Epoch: 395  Training loss = 2.9579  Validation loss = 1.3040  \n",
      "\n",
      "Fold: 31  Epoch: 396  Training loss = 2.9578  Validation loss = 1.3036  \n",
      "\n",
      "Fold: 31  Epoch: 397  Training loss = 2.9578  Validation loss = 1.3030  \n",
      "\n",
      "Fold: 31  Epoch: 398  Training loss = 2.9577  Validation loss = 1.3025  \n",
      "\n",
      "Fold: 31  Epoch: 399  Training loss = 2.9576  Validation loss = 1.3020  \n",
      "\n",
      "Fold: 31  Epoch: 400  Training loss = 2.9576  Validation loss = 1.3020  \n",
      "\n",
      "Fold: 31  Epoch: 401  Training loss = 2.9575  Validation loss = 1.3018  \n",
      "\n",
      "Fold: 31  Epoch: 402  Training loss = 2.9575  Validation loss = 1.3017  \n",
      "\n",
      "Fold: 31  Epoch: 403  Training loss = 2.9574  Validation loss = 1.3013  \n",
      "\n",
      "Fold: 31  Epoch: 404  Training loss = 2.9574  Validation loss = 1.3014  \n",
      "\n",
      "Fold: 31  Epoch: 405  Training loss = 2.9573  Validation loss = 1.3016  \n",
      "\n",
      "Fold: 31  Epoch: 406  Training loss = 2.9573  Validation loss = 1.3016  \n",
      "\n",
      "Fold: 31  Epoch: 407  Training loss = 2.9572  Validation loss = 1.3012  \n",
      "\n",
      "Fold: 31  Epoch: 408  Training loss = 2.9572  Validation loss = 1.3009  \n",
      "\n",
      "Fold: 31  Epoch: 409  Training loss = 2.9571  Validation loss = 1.3007  \n",
      "\n",
      "Fold: 31  Epoch: 410  Training loss = 2.9571  Validation loss = 1.3007  \n",
      "\n",
      "Fold: 31  Epoch: 411  Training loss = 2.9570  Validation loss = 1.3002  \n",
      "\n",
      "Fold: 31  Epoch: 412  Training loss = 2.9570  Validation loss = 1.3001  \n",
      "\n",
      "Fold: 31  Epoch: 413  Training loss = 2.9569  Validation loss = 1.3000  \n",
      "\n",
      "Fold: 31  Epoch: 414  Training loss = 2.9569  Validation loss = 1.2997  \n",
      "\n",
      "Fold: 31  Epoch: 415  Training loss = 2.9568  Validation loss = 1.2994  \n",
      "\n",
      "Fold: 31  Epoch: 416  Training loss = 2.9568  Validation loss = 1.2992  \n",
      "\n",
      "Fold: 31  Epoch: 417  Training loss = 2.9567  Validation loss = 1.2992  \n",
      "\n",
      "Fold: 31  Epoch: 418  Training loss = 2.9567  Validation loss = 1.2987  \n",
      "\n",
      "Fold: 31  Epoch: 419  Training loss = 2.9566  Validation loss = 1.2983  \n",
      "\n",
      "Fold: 31  Epoch: 420  Training loss = 2.9566  Validation loss = 1.2982  \n",
      "\n",
      "Fold: 31  Epoch: 421  Training loss = 2.9565  Validation loss = 1.2981  \n",
      "\n",
      "Fold: 31  Epoch: 422  Training loss = 2.9565  Validation loss = 1.2976  \n",
      "\n",
      "Fold: 31  Epoch: 423  Training loss = 2.9564  Validation loss = 1.2973  \n",
      "\n",
      "Fold: 31  Epoch: 424  Training loss = 2.9563  Validation loss = 1.2970  \n",
      "\n",
      "Fold: 31  Epoch: 425  Training loss = 2.9563  Validation loss = 1.2961  \n",
      "\n",
      "Fold: 31  Epoch: 426  Training loss = 2.9562  Validation loss = 1.2960  \n",
      "\n",
      "Fold: 31  Epoch: 427  Training loss = 2.9561  Validation loss = 1.2959  \n",
      "\n",
      "Fold: 31  Epoch: 428  Training loss = 2.9561  Validation loss = 1.2955  \n",
      "\n",
      "Fold: 31  Epoch: 429  Training loss = 2.9561  Validation loss = 1.2957  \n",
      "\n",
      "Fold: 31  Epoch: 430  Training loss = 2.9560  Validation loss = 1.2956  \n",
      "\n",
      "Fold: 31  Epoch: 431  Training loss = 2.9559  Validation loss = 1.2956  \n",
      "\n",
      "Fold: 31  Epoch: 432  Training loss = 2.9559  Validation loss = 1.2953  \n",
      "\n",
      "Fold: 31  Epoch: 433  Training loss = 2.9559  Validation loss = 1.2950  \n",
      "\n",
      "Fold: 31  Epoch: 434  Training loss = 2.9558  Validation loss = 1.2949  \n",
      "\n",
      "Fold: 31  Epoch: 435  Training loss = 2.9557  Validation loss = 1.2946  \n",
      "\n",
      "Fold: 31  Epoch: 436  Training loss = 2.9557  Validation loss = 1.2948  \n",
      "\n",
      "Fold: 31  Epoch: 437  Training loss = 2.9556  Validation loss = 1.2944  \n",
      "\n",
      "Fold: 31  Epoch: 438  Training loss = 2.9556  Validation loss = 1.2938  \n",
      "\n",
      "Fold: 31  Epoch: 439  Training loss = 2.9555  Validation loss = 1.2935  \n",
      "\n",
      "Fold: 31  Epoch: 440  Training loss = 2.9555  Validation loss = 1.2936  \n",
      "\n",
      "Fold: 31  Epoch: 441  Training loss = 2.9554  Validation loss = 1.2933  \n",
      "\n",
      "Fold: 31  Epoch: 442  Training loss = 2.9553  Validation loss = 1.2928  \n",
      "\n",
      "Fold: 31  Epoch: 443  Training loss = 2.9553  Validation loss = 1.2927  \n",
      "\n",
      "Fold: 31  Epoch: 444  Training loss = 2.9552  Validation loss = 1.2925  \n",
      "\n",
      "Fold: 31  Epoch: 445  Training loss = 2.9551  Validation loss = 1.2920  \n",
      "\n",
      "Fold: 31  Epoch: 446  Training loss = 2.9551  Validation loss = 1.2920  \n",
      "\n",
      "Fold: 31  Epoch: 447  Training loss = 2.9550  Validation loss = 1.2921  \n",
      "\n",
      "Fold: 31  Epoch: 448  Training loss = 2.9550  Validation loss = 1.2920  \n",
      "\n",
      "Fold: 31  Epoch: 449  Training loss = 2.9550  Validation loss = 1.2923  \n",
      "\n",
      "Fold: 31  Epoch: 450  Training loss = 2.9549  Validation loss = 1.2920  \n",
      "\n",
      "Fold: 31  Epoch: 451  Training loss = 2.9549  Validation loss = 1.2919  \n",
      "\n",
      "Fold: 31  Epoch: 452  Training loss = 2.9548  Validation loss = 1.2917  \n",
      "\n",
      "Fold: 31  Epoch: 453  Training loss = 2.9548  Validation loss = 1.2913  \n",
      "\n",
      "Fold: 31  Epoch: 454  Training loss = 2.9547  Validation loss = 1.2914  \n",
      "\n",
      "Fold: 31  Epoch: 455  Training loss = 2.9547  Validation loss = 1.2916  \n",
      "\n",
      "Fold: 31  Epoch: 456  Training loss = 2.9546  Validation loss = 1.2907  \n",
      "\n",
      "Fold: 31  Epoch: 457  Training loss = 2.9545  Validation loss = 1.2900  \n",
      "\n",
      "Fold: 31  Epoch: 458  Training loss = 2.9545  Validation loss = 1.2898  \n",
      "\n",
      "Fold: 31  Epoch: 459  Training loss = 2.9544  Validation loss = 1.2897  \n",
      "\n",
      "Fold: 31  Epoch: 460  Training loss = 2.9544  Validation loss = 1.2894  \n",
      "\n",
      "Fold: 31  Epoch: 461  Training loss = 2.9543  Validation loss = 1.2893  \n",
      "\n",
      "Fold: 31  Epoch: 462  Training loss = 2.9542  Validation loss = 1.2892  \n",
      "\n",
      "Fold: 31  Epoch: 463  Training loss = 2.9542  Validation loss = 1.2890  \n",
      "\n",
      "Fold: 31  Epoch: 464  Training loss = 2.9541  Validation loss = 1.2883  \n",
      "\n",
      "Fold: 31  Epoch: 465  Training loss = 2.9541  Validation loss = 1.2875  \n",
      "\n",
      "Fold: 31  Epoch: 466  Training loss = 2.9540  Validation loss = 1.2874  \n",
      "\n",
      "Fold: 31  Epoch: 467  Training loss = 2.9539  Validation loss = 1.2869  \n",
      "\n",
      "Fold: 31  Epoch: 468  Training loss = 2.9539  Validation loss = 1.2867  \n",
      "\n",
      "Fold: 31  Epoch: 469  Training loss = 2.9538  Validation loss = 1.2863  \n",
      "\n",
      "Fold: 31  Epoch: 470  Training loss = 2.9538  Validation loss = 1.2864  \n",
      "\n",
      "Fold: 31  Epoch: 471  Training loss = 2.9537  Validation loss = 1.2860  \n",
      "\n",
      "Fold: 31  Epoch: 472  Training loss = 2.9537  Validation loss = 1.2859  \n",
      "\n",
      "Fold: 31  Epoch: 473  Training loss = 2.9536  Validation loss = 1.2855  \n",
      "\n",
      "Fold: 31  Epoch: 474  Training loss = 2.9535  Validation loss = 1.2851  \n",
      "\n",
      "Fold: 31  Epoch: 475  Training loss = 2.9535  Validation loss = 1.2848  \n",
      "\n",
      "Fold: 31  Epoch: 476  Training loss = 2.9534  Validation loss = 1.2848  \n",
      "\n",
      "Fold: 31  Epoch: 477  Training loss = 2.9534  Validation loss = 1.2849  \n",
      "\n",
      "Fold: 31  Epoch: 478  Training loss = 2.9534  Validation loss = 1.2848  \n",
      "\n",
      "Fold: 31  Epoch: 479  Training loss = 2.9533  Validation loss = 1.2846  \n",
      "\n",
      "Fold: 31  Epoch: 480  Training loss = 2.9533  Validation loss = 1.2841  \n",
      "\n",
      "Fold: 31  Epoch: 481  Training loss = 2.9532  Validation loss = 1.2839  \n",
      "\n",
      "Fold: 31  Epoch: 482  Training loss = 2.9532  Validation loss = 1.2838  \n",
      "\n",
      "Fold: 31  Epoch: 483  Training loss = 2.9531  Validation loss = 1.2837  \n",
      "\n",
      "Fold: 31  Epoch: 484  Training loss = 2.9531  Validation loss = 1.2833  \n",
      "\n",
      "Fold: 31  Epoch: 485  Training loss = 2.9530  Validation loss = 1.2830  \n",
      "\n",
      "Fold: 31  Epoch: 486  Training loss = 2.9530  Validation loss = 1.2826  \n",
      "\n",
      "Fold: 31  Epoch: 487  Training loss = 2.9529  Validation loss = 1.2818  \n",
      "\n",
      "Fold: 31  Epoch: 488  Training loss = 2.9529  Validation loss = 1.2819  \n",
      "\n",
      "Fold: 31  Epoch: 489  Training loss = 2.9528  Validation loss = 1.2813  \n",
      "\n",
      "Fold: 31  Epoch: 490  Training loss = 2.9528  Validation loss = 1.2815  \n",
      "\n",
      "Fold: 31  Epoch: 491  Training loss = 2.9527  Validation loss = 1.2814  \n",
      "\n",
      "Fold: 31  Epoch: 492  Training loss = 2.9527  Validation loss = 1.2811  \n",
      "\n",
      "Fold: 31  Epoch: 493  Training loss = 2.9526  Validation loss = 1.2810  \n",
      "\n",
      "Fold: 31  Epoch: 494  Training loss = 2.9526  Validation loss = 1.2810  \n",
      "\n",
      "Fold: 31  Epoch: 495  Training loss = 2.9525  Validation loss = 1.2809  \n",
      "\n",
      "Fold: 31  Epoch: 496  Training loss = 2.9525  Validation loss = 1.2807  \n",
      "\n",
      "Fold: 31  Epoch: 497  Training loss = 2.9525  Validation loss = 1.2807  \n",
      "\n",
      "Fold: 31  Epoch: 498  Training loss = 2.9524  Validation loss = 1.2805  \n",
      "\n",
      "Fold: 31  Epoch: 499  Training loss = 2.9524  Validation loss = 1.2803  \n",
      "\n",
      "Fold: 31  Epoch: 500  Training loss = 2.9523  Validation loss = 1.2804  \n",
      "\n",
      "Check model:  Fold: 31  Optimal epoch: 499  \n",
      "\n",
      "Fold: 32  Epoch: 1  Training loss = 2.2527  Validation loss = 2.2699  \n",
      "\n",
      "Fold: 32  Epoch: 2  Training loss = 2.2525  Validation loss = 2.2697  \n",
      "\n",
      "Fold: 32  Epoch: 3  Training loss = 2.2525  Validation loss = 2.2696  \n",
      "\n",
      "Fold: 32  Epoch: 4  Training loss = 2.2524  Validation loss = 2.2695  \n",
      "\n",
      "Fold: 32  Epoch: 5  Training loss = 2.2523  Validation loss = 2.2695  \n",
      "\n",
      "Fold: 32  Epoch: 6  Training loss = 2.2522  Validation loss = 2.2693  \n",
      "\n",
      "Fold: 32  Epoch: 7  Training loss = 2.2521  Validation loss = 2.2691  \n",
      "\n",
      "Fold: 32  Epoch: 8  Training loss = 2.2521  Validation loss = 2.2690  \n",
      "\n",
      "Fold: 32  Epoch: 9  Training loss = 2.2520  Validation loss = 2.2688  \n",
      "\n",
      "Fold: 32  Epoch: 10  Training loss = 2.2519  Validation loss = 2.2688  \n",
      "\n",
      "Fold: 32  Epoch: 11  Training loss = 2.2519  Validation loss = 2.2687  \n",
      "\n",
      "Fold: 32  Epoch: 12  Training loss = 2.2517  Validation loss = 2.2684  \n",
      "\n",
      "Fold: 32  Epoch: 13  Training loss = 2.2516  Validation loss = 2.2682  \n",
      "\n",
      "Fold: 32  Epoch: 14  Training loss = 2.2515  Validation loss = 2.2680  \n",
      "\n",
      "Fold: 32  Epoch: 15  Training loss = 2.2515  Validation loss = 2.2679  \n",
      "\n",
      "Fold: 32  Epoch: 16  Training loss = 2.2514  Validation loss = 2.2678  \n",
      "\n",
      "Fold: 32  Epoch: 17  Training loss = 2.2513  Validation loss = 2.2676  \n",
      "\n",
      "Fold: 32  Epoch: 18  Training loss = 2.2512  Validation loss = 2.2673  \n",
      "\n",
      "Fold: 32  Epoch: 19  Training loss = 2.2511  Validation loss = 2.2672  \n",
      "\n",
      "Fold: 32  Epoch: 20  Training loss = 2.2510  Validation loss = 2.2669  \n",
      "\n",
      "Fold: 32  Epoch: 21  Training loss = 2.2509  Validation loss = 2.2668  \n",
      "\n",
      "Fold: 32  Epoch: 22  Training loss = 2.2508  Validation loss = 2.2664  \n",
      "\n",
      "Fold: 32  Epoch: 23  Training loss = 2.2507  Validation loss = 2.2663  \n",
      "\n",
      "Fold: 32  Epoch: 24  Training loss = 2.2505  Validation loss = 2.2660  \n",
      "\n",
      "Fold: 32  Epoch: 25  Training loss = 2.2505  Validation loss = 2.2659  \n",
      "\n",
      "Fold: 32  Epoch: 26  Training loss = 2.2504  Validation loss = 2.2657  \n",
      "\n",
      "Fold: 32  Epoch: 27  Training loss = 2.2503  Validation loss = 2.2655  \n",
      "\n",
      "Fold: 32  Epoch: 28  Training loss = 2.2503  Validation loss = 2.2655  \n",
      "\n",
      "Fold: 32  Epoch: 29  Training loss = 2.2502  Validation loss = 2.2653  \n",
      "\n",
      "Fold: 32  Epoch: 30  Training loss = 2.2501  Validation loss = 2.2654  \n",
      "\n",
      "Fold: 32  Epoch: 31  Training loss = 2.2500  Validation loss = 2.2651  \n",
      "\n",
      "Fold: 32  Epoch: 32  Training loss = 2.2499  Validation loss = 2.2650  \n",
      "\n",
      "Fold: 32  Epoch: 33  Training loss = 2.2498  Validation loss = 2.2648  \n",
      "\n",
      "Fold: 32  Epoch: 34  Training loss = 2.2497  Validation loss = 2.2646  \n",
      "\n",
      "Fold: 32  Epoch: 35  Training loss = 2.2496  Validation loss = 2.2645  \n",
      "\n",
      "Fold: 32  Epoch: 36  Training loss = 2.2495  Validation loss = 2.2643  \n",
      "\n",
      "Fold: 32  Epoch: 37  Training loss = 2.2495  Validation loss = 2.2642  \n",
      "\n",
      "Fold: 32  Epoch: 38  Training loss = 2.2494  Validation loss = 2.2640  \n",
      "\n",
      "Fold: 32  Epoch: 39  Training loss = 2.2493  Validation loss = 2.2639  \n",
      "\n",
      "Fold: 32  Epoch: 40  Training loss = 2.2492  Validation loss = 2.2637  \n",
      "\n",
      "Fold: 32  Epoch: 41  Training loss = 2.2491  Validation loss = 2.2634  \n",
      "\n",
      "Fold: 32  Epoch: 42  Training loss = 2.2490  Validation loss = 2.2635  \n",
      "\n",
      "Fold: 32  Epoch: 43  Training loss = 2.2489  Validation loss = 2.2633  \n",
      "\n",
      "Fold: 32  Epoch: 44  Training loss = 2.2488  Validation loss = 2.2629  \n",
      "\n",
      "Fold: 32  Epoch: 45  Training loss = 2.2487  Validation loss = 2.2627  \n",
      "\n",
      "Fold: 32  Epoch: 46  Training loss = 2.2486  Validation loss = 2.2626  \n",
      "\n",
      "Fold: 32  Epoch: 47  Training loss = 2.2486  Validation loss = 2.2625  \n",
      "\n",
      "Fold: 32  Epoch: 48  Training loss = 2.2484  Validation loss = 2.2622  \n",
      "\n",
      "Fold: 32  Epoch: 49  Training loss = 2.2483  Validation loss = 2.2618  \n",
      "\n",
      "Fold: 32  Epoch: 50  Training loss = 2.2481  Validation loss = 2.2615  \n",
      "\n",
      "Fold: 32  Epoch: 51  Training loss = 2.2481  Validation loss = 2.2613  \n",
      "\n",
      "Fold: 32  Epoch: 52  Training loss = 2.2480  Validation loss = 2.2611  \n",
      "\n",
      "Fold: 32  Epoch: 53  Training loss = 2.2479  Validation loss = 2.2609  \n",
      "\n",
      "Fold: 32  Epoch: 54  Training loss = 2.2478  Validation loss = 2.2608  \n",
      "\n",
      "Fold: 32  Epoch: 55  Training loss = 2.2477  Validation loss = 2.2604  \n",
      "\n",
      "Fold: 32  Epoch: 56  Training loss = 2.2475  Validation loss = 2.2601  \n",
      "\n",
      "Fold: 32  Epoch: 57  Training loss = 2.2475  Validation loss = 2.2600  \n",
      "\n",
      "Fold: 32  Epoch: 58  Training loss = 2.2474  Validation loss = 2.2600  \n",
      "\n",
      "Fold: 32  Epoch: 59  Training loss = 2.2473  Validation loss = 2.2599  \n",
      "\n",
      "Fold: 32  Epoch: 60  Training loss = 2.2472  Validation loss = 2.2597  \n",
      "\n",
      "Fold: 32  Epoch: 61  Training loss = 2.2471  Validation loss = 2.2594  \n",
      "\n",
      "Fold: 32  Epoch: 62  Training loss = 2.2471  Validation loss = 2.2593  \n",
      "\n",
      "Fold: 32  Epoch: 63  Training loss = 2.2470  Validation loss = 2.2591  \n",
      "\n",
      "Fold: 32  Epoch: 64  Training loss = 2.2469  Validation loss = 2.2589  \n",
      "\n",
      "Fold: 32  Epoch: 65  Training loss = 2.2468  Validation loss = 2.2587  \n",
      "\n",
      "Fold: 32  Epoch: 66  Training loss = 2.2467  Validation loss = 2.2585  \n",
      "\n",
      "Fold: 32  Epoch: 67  Training loss = 2.2467  Validation loss = 2.2584  \n",
      "\n",
      "Fold: 32  Epoch: 68  Training loss = 2.2466  Validation loss = 2.2583  \n",
      "\n",
      "Fold: 32  Epoch: 69  Training loss = 2.2465  Validation loss = 2.2581  \n",
      "\n",
      "Fold: 32  Epoch: 70  Training loss = 2.2465  Validation loss = 2.2581  \n",
      "\n",
      "Fold: 32  Epoch: 71  Training loss = 2.2464  Validation loss = 2.2578  \n",
      "\n",
      "Fold: 32  Epoch: 72  Training loss = 2.2463  Validation loss = 2.2576  \n",
      "\n",
      "Fold: 32  Epoch: 73  Training loss = 2.2462  Validation loss = 2.2575  \n",
      "\n",
      "Fold: 32  Epoch: 74  Training loss = 2.2461  Validation loss = 2.2573  \n",
      "\n",
      "Fold: 32  Epoch: 75  Training loss = 2.2460  Validation loss = 2.2569  \n",
      "\n",
      "Fold: 32  Epoch: 76  Training loss = 2.2459  Validation loss = 2.2569  \n",
      "\n",
      "Fold: 32  Epoch: 77  Training loss = 2.2459  Validation loss = 2.2567  \n",
      "\n",
      "Fold: 32  Epoch: 78  Training loss = 2.2458  Validation loss = 2.2568  \n",
      "\n",
      "Fold: 32  Epoch: 79  Training loss = 2.2458  Validation loss = 2.2569  \n",
      "\n",
      "Fold: 32  Epoch: 80  Training loss = 2.2457  Validation loss = 2.2567  \n",
      "\n",
      "Fold: 32  Epoch: 81  Training loss = 2.2456  Validation loss = 2.2564  \n",
      "\n",
      "Fold: 32  Epoch: 82  Training loss = 2.2455  Validation loss = 2.2561  \n",
      "\n",
      "Fold: 32  Epoch: 83  Training loss = 2.2454  Validation loss = 2.2560  \n",
      "\n",
      "Fold: 32  Epoch: 84  Training loss = 2.2453  Validation loss = 2.2556  \n",
      "\n",
      "Fold: 32  Epoch: 85  Training loss = 2.2452  Validation loss = 2.2553  \n",
      "\n",
      "Fold: 32  Epoch: 86  Training loss = 2.2450  Validation loss = 2.2550  \n",
      "\n",
      "Fold: 32  Epoch: 87  Training loss = 2.2450  Validation loss = 2.2548  \n",
      "\n",
      "Fold: 32  Epoch: 88  Training loss = 2.2449  Validation loss = 2.2546  \n",
      "\n",
      "Fold: 32  Epoch: 89  Training loss = 2.2448  Validation loss = 2.2544  \n",
      "\n",
      "Fold: 32  Epoch: 90  Training loss = 2.2446  Validation loss = 2.2540  \n",
      "\n",
      "Fold: 32  Epoch: 91  Training loss = 2.2445  Validation loss = 2.2538  \n",
      "\n",
      "Fold: 32  Epoch: 92  Training loss = 2.2444  Validation loss = 2.2536  \n",
      "\n",
      "Fold: 32  Epoch: 93  Training loss = 2.2444  Validation loss = 2.2536  \n",
      "\n",
      "Fold: 32  Epoch: 94  Training loss = 2.2443  Validation loss = 2.2535  \n",
      "\n",
      "Fold: 32  Epoch: 95  Training loss = 2.2443  Validation loss = 2.2534  \n",
      "\n",
      "Fold: 32  Epoch: 96  Training loss = 2.2442  Validation loss = 2.2532  \n",
      "\n",
      "Fold: 32  Epoch: 97  Training loss = 2.2441  Validation loss = 2.2530  \n",
      "\n",
      "Fold: 32  Epoch: 98  Training loss = 2.2440  Validation loss = 2.2527  \n",
      "\n",
      "Fold: 32  Epoch: 99  Training loss = 2.2439  Validation loss = 2.2526  \n",
      "\n",
      "Fold: 32  Epoch: 100  Training loss = 2.2438  Validation loss = 2.2525  \n",
      "\n",
      "Fold: 32  Epoch: 101  Training loss = 2.2437  Validation loss = 2.2523  \n",
      "\n",
      "Fold: 32  Epoch: 102  Training loss = 2.2437  Validation loss = 2.2524  \n",
      "\n",
      "Fold: 32  Epoch: 103  Training loss = 2.2436  Validation loss = 2.2522  \n",
      "\n",
      "Fold: 32  Epoch: 104  Training loss = 2.2436  Validation loss = 2.2521  \n",
      "\n",
      "Fold: 32  Epoch: 105  Training loss = 2.2435  Validation loss = 2.2519  \n",
      "\n",
      "Fold: 32  Epoch: 106  Training loss = 2.2434  Validation loss = 2.2518  \n",
      "\n",
      "Fold: 32  Epoch: 107  Training loss = 2.2433  Validation loss = 2.2516  \n",
      "\n",
      "Fold: 32  Epoch: 108  Training loss = 2.2432  Validation loss = 2.2512  \n",
      "\n",
      "Fold: 32  Epoch: 109  Training loss = 2.2431  Validation loss = 2.2510  \n",
      "\n",
      "Fold: 32  Epoch: 110  Training loss = 2.2431  Validation loss = 2.2510  \n",
      "\n",
      "Fold: 32  Epoch: 111  Training loss = 2.2429  Validation loss = 2.2507  \n",
      "\n",
      "Fold: 32  Epoch: 112  Training loss = 2.2429  Validation loss = 2.2506  \n",
      "\n",
      "Fold: 32  Epoch: 113  Training loss = 2.2428  Validation loss = 2.2505  \n",
      "\n",
      "Fold: 32  Epoch: 114  Training loss = 2.2427  Validation loss = 2.2504  \n",
      "\n",
      "Fold: 32  Epoch: 115  Training loss = 2.2427  Validation loss = 2.2503  \n",
      "\n",
      "Fold: 32  Epoch: 116  Training loss = 2.2427  Validation loss = 2.2504  \n",
      "\n",
      "Fold: 32  Epoch: 117  Training loss = 2.2426  Validation loss = 2.2502  \n",
      "\n",
      "Fold: 32  Epoch: 118  Training loss = 2.2425  Validation loss = 2.2501  \n",
      "\n",
      "Fold: 32  Epoch: 119  Training loss = 2.2424  Validation loss = 2.2500  \n",
      "\n",
      "Fold: 32  Epoch: 120  Training loss = 2.2424  Validation loss = 2.2499  \n",
      "\n",
      "Fold: 32  Epoch: 121  Training loss = 2.2424  Validation loss = 2.2499  \n",
      "\n",
      "Fold: 32  Epoch: 122  Training loss = 2.2423  Validation loss = 2.2497  \n",
      "\n",
      "Fold: 32  Epoch: 123  Training loss = 2.2422  Validation loss = 2.2495  \n",
      "\n",
      "Fold: 32  Epoch: 124  Training loss = 2.2422  Validation loss = 2.2495  \n",
      "\n",
      "Fold: 32  Epoch: 125  Training loss = 2.2421  Validation loss = 2.2492  \n",
      "\n",
      "Fold: 32  Epoch: 126  Training loss = 2.2420  Validation loss = 2.2490  \n",
      "\n",
      "Fold: 32  Epoch: 127  Training loss = 2.2419  Validation loss = 2.2489  \n",
      "\n",
      "Fold: 32  Epoch: 128  Training loss = 2.2418  Validation loss = 2.2486  \n",
      "\n",
      "Fold: 32  Epoch: 129  Training loss = 2.2417  Validation loss = 2.2483  \n",
      "\n",
      "Fold: 32  Epoch: 130  Training loss = 2.2416  Validation loss = 2.2481  \n",
      "\n",
      "Fold: 32  Epoch: 131  Training loss = 2.2415  Validation loss = 2.2478  \n",
      "\n",
      "Fold: 32  Epoch: 132  Training loss = 2.2414  Validation loss = 2.2475  \n",
      "\n",
      "Fold: 32  Epoch: 133  Training loss = 2.2413  Validation loss = 2.2474  \n",
      "\n",
      "Fold: 32  Epoch: 134  Training loss = 2.2413  Validation loss = 2.2475  \n",
      "\n",
      "Fold: 32  Epoch: 135  Training loss = 2.2412  Validation loss = 2.2472  \n",
      "\n",
      "Fold: 32  Epoch: 136  Training loss = 2.2411  Validation loss = 2.2472  \n",
      "\n",
      "Fold: 32  Epoch: 137  Training loss = 2.2411  Validation loss = 2.2472  \n",
      "\n",
      "Fold: 32  Epoch: 138  Training loss = 2.2411  Validation loss = 2.2472  \n",
      "\n",
      "Fold: 32  Epoch: 139  Training loss = 2.2410  Validation loss = 2.2472  \n",
      "\n",
      "Fold: 32  Epoch: 140  Training loss = 2.2409  Validation loss = 2.2470  \n",
      "\n",
      "Fold: 32  Epoch: 141  Training loss = 2.2408  Validation loss = 2.2467  \n",
      "\n",
      "Fold: 32  Epoch: 142  Training loss = 2.2407  Validation loss = 2.2465  \n",
      "\n",
      "Fold: 32  Epoch: 143  Training loss = 2.2406  Validation loss = 2.2463  \n",
      "\n",
      "Fold: 32  Epoch: 144  Training loss = 2.2405  Validation loss = 2.2462  \n",
      "\n",
      "Fold: 32  Epoch: 145  Training loss = 2.2405  Validation loss = 2.2461  \n",
      "\n",
      "Fold: 32  Epoch: 146  Training loss = 2.2404  Validation loss = 2.2458  \n",
      "\n",
      "Fold: 32  Epoch: 147  Training loss = 2.2404  Validation loss = 2.2458  \n",
      "\n",
      "Fold: 32  Epoch: 148  Training loss = 2.2403  Validation loss = 2.2458  \n",
      "\n",
      "Fold: 32  Epoch: 149  Training loss = 2.2402  Validation loss = 2.2454  \n",
      "\n",
      "Fold: 32  Epoch: 150  Training loss = 2.2401  Validation loss = 2.2454  \n",
      "\n",
      "Fold: 32  Epoch: 151  Training loss = 2.2401  Validation loss = 2.2455  \n",
      "\n",
      "Fold: 32  Epoch: 152  Training loss = 2.2400  Validation loss = 2.2453  \n",
      "\n",
      "Fold: 32  Epoch: 153  Training loss = 2.2399  Validation loss = 2.2449  \n",
      "\n",
      "Fold: 32  Epoch: 154  Training loss = 2.2399  Validation loss = 2.2449  \n",
      "\n",
      "Fold: 32  Epoch: 155  Training loss = 2.2398  Validation loss = 2.2450  \n",
      "\n",
      "Fold: 32  Epoch: 156  Training loss = 2.2398  Validation loss = 2.2449  \n",
      "\n",
      "Fold: 32  Epoch: 157  Training loss = 2.2397  Validation loss = 2.2448  \n",
      "\n",
      "Fold: 32  Epoch: 158  Training loss = 2.2396  Validation loss = 2.2444  \n",
      "\n",
      "Fold: 32  Epoch: 159  Training loss = 2.2395  Validation loss = 2.2442  \n",
      "\n",
      "Fold: 32  Epoch: 160  Training loss = 2.2394  Validation loss = 2.2441  \n",
      "\n",
      "Fold: 32  Epoch: 161  Training loss = 2.2394  Validation loss = 2.2439  \n",
      "\n",
      "Fold: 32  Epoch: 162  Training loss = 2.2393  Validation loss = 2.2437  \n",
      "\n",
      "Fold: 32  Epoch: 163  Training loss = 2.2392  Validation loss = 2.2435  \n",
      "\n",
      "Fold: 32  Epoch: 164  Training loss = 2.2391  Validation loss = 2.2434  \n",
      "\n",
      "Fold: 32  Epoch: 165  Training loss = 2.2391  Validation loss = 2.2434  \n",
      "\n",
      "Fold: 32  Epoch: 166  Training loss = 2.2390  Validation loss = 2.2433  \n",
      "\n",
      "Fold: 32  Epoch: 167  Training loss = 2.2390  Validation loss = 2.2432  \n",
      "\n",
      "Fold: 32  Epoch: 168  Training loss = 2.2389  Validation loss = 2.2429  \n",
      "\n",
      "Fold: 32  Epoch: 169  Training loss = 2.2388  Validation loss = 2.2427  \n",
      "\n",
      "Fold: 32  Epoch: 170  Training loss = 2.2387  Validation loss = 2.2425  \n",
      "\n",
      "Fold: 32  Epoch: 171  Training loss = 2.2387  Validation loss = 2.2424  \n",
      "\n",
      "Fold: 32  Epoch: 172  Training loss = 2.2386  Validation loss = 2.2422  \n",
      "\n",
      "Fold: 32  Epoch: 173  Training loss = 2.2385  Validation loss = 2.2419  \n",
      "\n",
      "Fold: 32  Epoch: 174  Training loss = 2.2384  Validation loss = 2.2417  \n",
      "\n",
      "Fold: 32  Epoch: 175  Training loss = 2.2383  Validation loss = 2.2415  \n",
      "\n",
      "Fold: 32  Epoch: 176  Training loss = 2.2383  Validation loss = 2.2413  \n",
      "\n",
      "Fold: 32  Epoch: 177  Training loss = 2.2382  Validation loss = 2.2411  \n",
      "\n",
      "Fold: 32  Epoch: 178  Training loss = 2.2381  Validation loss = 2.2410  \n",
      "\n",
      "Fold: 32  Epoch: 179  Training loss = 2.2380  Validation loss = 2.2405  \n",
      "\n",
      "Fold: 32  Epoch: 180  Training loss = 2.2379  Validation loss = 2.2403  \n",
      "\n",
      "Fold: 32  Epoch: 181  Training loss = 2.2379  Validation loss = 2.2403  \n",
      "\n",
      "Fold: 32  Epoch: 182  Training loss = 2.2378  Validation loss = 2.2403  \n",
      "\n",
      "Fold: 32  Epoch: 183  Training loss = 2.2377  Validation loss = 2.2402  \n",
      "\n",
      "Fold: 32  Epoch: 184  Training loss = 2.2377  Validation loss = 2.2400  \n",
      "\n",
      "Fold: 32  Epoch: 185  Training loss = 2.2376  Validation loss = 2.2398  \n",
      "\n",
      "Fold: 32  Epoch: 186  Training loss = 2.2375  Validation loss = 2.2396  \n",
      "\n",
      "Fold: 32  Epoch: 187  Training loss = 2.2374  Validation loss = 2.2392  \n",
      "\n",
      "Fold: 32  Epoch: 188  Training loss = 2.2373  Validation loss = 2.2390  \n",
      "\n",
      "Fold: 32  Epoch: 189  Training loss = 2.2372  Validation loss = 2.2388  \n",
      "\n",
      "Fold: 32  Epoch: 190  Training loss = 2.2371  Validation loss = 2.2387  \n",
      "\n",
      "Fold: 32  Epoch: 191  Training loss = 2.2371  Validation loss = 2.2386  \n",
      "\n",
      "Fold: 32  Epoch: 192  Training loss = 2.2370  Validation loss = 2.2383  \n",
      "\n",
      "Fold: 32  Epoch: 193  Training loss = 2.2369  Validation loss = 2.2380  \n",
      "\n",
      "Fold: 32  Epoch: 194  Training loss = 2.2368  Validation loss = 2.2378  \n",
      "\n",
      "Fold: 32  Epoch: 195  Training loss = 2.2367  Validation loss = 2.2376  \n",
      "\n",
      "Fold: 32  Epoch: 196  Training loss = 2.2366  Validation loss = 2.2375  \n",
      "\n",
      "Fold: 32  Epoch: 197  Training loss = 2.2366  Validation loss = 2.2374  \n",
      "\n",
      "Fold: 32  Epoch: 198  Training loss = 2.2365  Validation loss = 2.2373  \n",
      "\n",
      "Fold: 32  Epoch: 199  Training loss = 2.2364  Validation loss = 2.2371  \n",
      "\n",
      "Fold: 32  Epoch: 200  Training loss = 2.2364  Validation loss = 2.2371  \n",
      "\n",
      "Fold: 32  Epoch: 201  Training loss = 2.2363  Validation loss = 2.2369  \n",
      "\n",
      "Fold: 32  Epoch: 202  Training loss = 2.2362  Validation loss = 2.2367  \n",
      "\n",
      "Fold: 32  Epoch: 203  Training loss = 2.2362  Validation loss = 2.2366  \n",
      "\n",
      "Fold: 32  Epoch: 204  Training loss = 2.2361  Validation loss = 2.2363  \n",
      "\n",
      "Fold: 32  Epoch: 205  Training loss = 2.2360  Validation loss = 2.2362  \n",
      "\n",
      "Fold: 32  Epoch: 206  Training loss = 2.2359  Validation loss = 2.2360  \n",
      "\n",
      "Fold: 32  Epoch: 207  Training loss = 2.2359  Validation loss = 2.2360  \n",
      "\n",
      "Fold: 32  Epoch: 208  Training loss = 2.2359  Validation loss = 2.2360  \n",
      "\n",
      "Fold: 32  Epoch: 209  Training loss = 2.2358  Validation loss = 2.2357  \n",
      "\n",
      "Fold: 32  Epoch: 210  Training loss = 2.2357  Validation loss = 2.2357  \n",
      "\n",
      "Fold: 32  Epoch: 211  Training loss = 2.2357  Validation loss = 2.2357  \n",
      "\n",
      "Fold: 32  Epoch: 212  Training loss = 2.2356  Validation loss = 2.2357  \n",
      "\n",
      "Fold: 32  Epoch: 213  Training loss = 2.2356  Validation loss = 2.2357  \n",
      "\n",
      "Fold: 32  Epoch: 214  Training loss = 2.2356  Validation loss = 2.2357  \n",
      "\n",
      "Fold: 32  Epoch: 215  Training loss = 2.2355  Validation loss = 2.2357  \n",
      "\n",
      "Fold: 32  Epoch: 216  Training loss = 2.2354  Validation loss = 2.2355  \n",
      "\n",
      "Fold: 32  Epoch: 217  Training loss = 2.2354  Validation loss = 2.2353  \n",
      "\n",
      "Fold: 32  Epoch: 218  Training loss = 2.2353  Validation loss = 2.2350  \n",
      "\n",
      "Fold: 32  Epoch: 219  Training loss = 2.2352  Validation loss = 2.2348  \n",
      "\n",
      "Fold: 32  Epoch: 220  Training loss = 2.2352  Validation loss = 2.2348  \n",
      "\n",
      "Fold: 32  Epoch: 221  Training loss = 2.2351  Validation loss = 2.2345  \n",
      "\n",
      "Fold: 32  Epoch: 222  Training loss = 2.2349  Validation loss = 2.2341  \n",
      "\n",
      "Fold: 32  Epoch: 223  Training loss = 2.2348  Validation loss = 2.2337  \n",
      "\n",
      "Fold: 32  Epoch: 224  Training loss = 2.2347  Validation loss = 2.2333  \n",
      "\n",
      "Fold: 32  Epoch: 225  Training loss = 2.2346  Validation loss = 2.2333  \n",
      "\n",
      "Fold: 32  Epoch: 226  Training loss = 2.2346  Validation loss = 2.2334  \n",
      "\n",
      "Fold: 32  Epoch: 227  Training loss = 2.2346  Validation loss = 2.2333  \n",
      "\n",
      "Fold: 32  Epoch: 228  Training loss = 2.2345  Validation loss = 2.2333  \n",
      "\n",
      "Fold: 32  Epoch: 229  Training loss = 2.2345  Validation loss = 2.2332  \n",
      "\n",
      "Fold: 32  Epoch: 230  Training loss = 2.2344  Validation loss = 2.2332  \n",
      "\n",
      "Fold: 32  Epoch: 231  Training loss = 2.2344  Validation loss = 2.2329  \n",
      "\n",
      "Fold: 32  Epoch: 232  Training loss = 2.2343  Validation loss = 2.2328  \n",
      "\n",
      "Fold: 32  Epoch: 233  Training loss = 2.2342  Validation loss = 2.2325  \n",
      "\n",
      "Fold: 32  Epoch: 234  Training loss = 2.2341  Validation loss = 2.2324  \n",
      "\n",
      "Fold: 32  Epoch: 235  Training loss = 2.2341  Validation loss = 2.2325  \n",
      "\n",
      "Fold: 32  Epoch: 236  Training loss = 2.2340  Validation loss = 2.2325  \n",
      "\n",
      "Fold: 32  Epoch: 237  Training loss = 2.2339  Validation loss = 2.2321  \n",
      "\n",
      "Fold: 32  Epoch: 238  Training loss = 2.2338  Validation loss = 2.2319  \n",
      "\n",
      "Fold: 32  Epoch: 239  Training loss = 2.2338  Validation loss = 2.2319  \n",
      "\n",
      "Fold: 32  Epoch: 240  Training loss = 2.2338  Validation loss = 2.2319  \n",
      "\n",
      "Fold: 32  Epoch: 241  Training loss = 2.2336  Validation loss = 2.2315  \n",
      "\n",
      "Fold: 32  Epoch: 242  Training loss = 2.2336  Validation loss = 2.2312  \n",
      "\n",
      "Fold: 32  Epoch: 243  Training loss = 2.2334  Validation loss = 2.2309  \n",
      "\n",
      "Fold: 32  Epoch: 244  Training loss = 2.2334  Validation loss = 2.2309  \n",
      "\n",
      "Fold: 32  Epoch: 245  Training loss = 2.2334  Validation loss = 2.2310  \n",
      "\n",
      "Fold: 32  Epoch: 246  Training loss = 2.2333  Validation loss = 2.2309  \n",
      "\n",
      "Fold: 32  Epoch: 247  Training loss = 2.2333  Validation loss = 2.2308  \n",
      "\n",
      "Fold: 32  Epoch: 248  Training loss = 2.2332  Validation loss = 2.2306  \n",
      "\n",
      "Fold: 32  Epoch: 249  Training loss = 2.2331  Validation loss = 2.2306  \n",
      "\n",
      "Fold: 32  Epoch: 250  Training loss = 2.2330  Validation loss = 2.2306  \n",
      "\n",
      "Fold: 32  Epoch: 251  Training loss = 2.2330  Validation loss = 2.2306  \n",
      "\n",
      "Fold: 32  Epoch: 252  Training loss = 2.2330  Validation loss = 2.2306  \n",
      "\n",
      "Fold: 32  Epoch: 253  Training loss = 2.2330  Validation loss = 2.2308  \n",
      "\n",
      "Fold: 32  Epoch: 254  Training loss = 2.2329  Validation loss = 2.2306  \n",
      "\n",
      "Fold: 32  Epoch: 255  Training loss = 2.2328  Validation loss = 2.2304  \n",
      "\n",
      "Fold: 32  Epoch: 256  Training loss = 2.2328  Validation loss = 2.2304  \n",
      "\n",
      "Fold: 32  Epoch: 257  Training loss = 2.2327  Validation loss = 2.2304  \n",
      "\n",
      "Fold: 32  Epoch: 258  Training loss = 2.2327  Validation loss = 2.2303  \n",
      "\n",
      "Fold: 32  Epoch: 259  Training loss = 2.2326  Validation loss = 2.2300  \n",
      "\n",
      "Fold: 32  Epoch: 260  Training loss = 2.2325  Validation loss = 2.2299  \n",
      "\n",
      "Fold: 32  Epoch: 261  Training loss = 2.2325  Validation loss = 2.2299  \n",
      "\n",
      "Fold: 32  Epoch: 262  Training loss = 2.2324  Validation loss = 2.2298  \n",
      "\n",
      "Fold: 32  Epoch: 263  Training loss = 2.2324  Validation loss = 2.2298  \n",
      "\n",
      "Fold: 32  Epoch: 264  Training loss = 2.2323  Validation loss = 2.2297  \n",
      "\n",
      "Fold: 32  Epoch: 265  Training loss = 2.2322  Validation loss = 2.2293  \n",
      "\n",
      "Fold: 32  Epoch: 266  Training loss = 2.2322  Validation loss = 2.2293  \n",
      "\n",
      "Fold: 32  Epoch: 267  Training loss = 2.2321  Validation loss = 2.2291  \n",
      "\n",
      "Fold: 32  Epoch: 268  Training loss = 2.2320  Validation loss = 2.2289  \n",
      "\n",
      "Fold: 32  Epoch: 269  Training loss = 2.2320  Validation loss = 2.2287  \n",
      "\n",
      "Fold: 32  Epoch: 270  Training loss = 2.2319  Validation loss = 2.2285  \n",
      "\n",
      "Fold: 32  Epoch: 271  Training loss = 2.2318  Validation loss = 2.2282  \n",
      "\n",
      "Fold: 32  Epoch: 272  Training loss = 2.2317  Validation loss = 2.2279  \n",
      "\n",
      "Fold: 32  Epoch: 273  Training loss = 2.2316  Validation loss = 2.2279  \n",
      "\n",
      "Fold: 32  Epoch: 274  Training loss = 2.2316  Validation loss = 2.2276  \n",
      "\n",
      "Fold: 32  Epoch: 275  Training loss = 2.2315  Validation loss = 2.2273  \n",
      "\n",
      "Fold: 32  Epoch: 276  Training loss = 2.2314  Validation loss = 2.2272  \n",
      "\n",
      "Fold: 32  Epoch: 277  Training loss = 2.2314  Validation loss = 2.2272  \n",
      "\n",
      "Fold: 32  Epoch: 278  Training loss = 2.2313  Validation loss = 2.2272  \n",
      "\n",
      "Fold: 32  Epoch: 279  Training loss = 2.2312  Validation loss = 2.2269  \n",
      "\n",
      "Fold: 32  Epoch: 280  Training loss = 2.2312  Validation loss = 2.2269  \n",
      "\n",
      "Fold: 32  Epoch: 281  Training loss = 2.2312  Validation loss = 2.2269  \n",
      "\n",
      "Fold: 32  Epoch: 282  Training loss = 2.2311  Validation loss = 2.2269  \n",
      "\n",
      "Fold: 32  Epoch: 283  Training loss = 2.2311  Validation loss = 2.2271  \n",
      "\n",
      "Fold: 32  Epoch: 284  Training loss = 2.2311  Validation loss = 2.2270  \n",
      "\n",
      "Fold: 32  Epoch: 285  Training loss = 2.2311  Validation loss = 2.2270  \n",
      "\n",
      "Fold: 32  Epoch: 286  Training loss = 2.2310  Validation loss = 2.2267  \n",
      "\n",
      "Fold: 32  Epoch: 287  Training loss = 2.2309  Validation loss = 2.2266  \n",
      "\n",
      "Fold: 32  Epoch: 288  Training loss = 2.2308  Validation loss = 2.2264  \n",
      "\n",
      "Fold: 32  Epoch: 289  Training loss = 2.2308  Validation loss = 2.2265  \n",
      "\n",
      "Fold: 32  Epoch: 290  Training loss = 2.2307  Validation loss = 2.2263  \n",
      "\n",
      "Fold: 32  Epoch: 291  Training loss = 2.2306  Validation loss = 2.2261  \n",
      "\n",
      "Fold: 32  Epoch: 292  Training loss = 2.2306  Validation loss = 2.2261  \n",
      "\n",
      "Fold: 32  Epoch: 293  Training loss = 2.2306  Validation loss = 2.2260  \n",
      "\n",
      "Fold: 32  Epoch: 294  Training loss = 2.2305  Validation loss = 2.2260  \n",
      "\n",
      "Fold: 32  Epoch: 295  Training loss = 2.2304  Validation loss = 2.2258  \n",
      "\n",
      "Fold: 32  Epoch: 296  Training loss = 2.2304  Validation loss = 2.2257  \n",
      "\n",
      "Fold: 32  Epoch: 297  Training loss = 2.2303  Validation loss = 2.2255  \n",
      "\n",
      "Fold: 32  Epoch: 298  Training loss = 2.2302  Validation loss = 2.2253  \n",
      "\n",
      "Fold: 32  Epoch: 299  Training loss = 2.2302  Validation loss = 2.2250  \n",
      "\n",
      "Fold: 32  Epoch: 300  Training loss = 2.2300  Validation loss = 2.2246  \n",
      "\n",
      "Fold: 32  Epoch: 301  Training loss = 2.2300  Validation loss = 2.2245  \n",
      "\n",
      "Fold: 32  Epoch: 302  Training loss = 2.2299  Validation loss = 2.2244  \n",
      "\n",
      "Fold: 32  Epoch: 303  Training loss = 2.2298  Validation loss = 2.2239  \n",
      "\n",
      "Fold: 32  Epoch: 304  Training loss = 2.2297  Validation loss = 2.2239  \n",
      "\n",
      "Fold: 32  Epoch: 305  Training loss = 2.2297  Validation loss = 2.2237  \n",
      "\n",
      "Fold: 32  Epoch: 306  Training loss = 2.2296  Validation loss = 2.2236  \n",
      "\n",
      "Fold: 32  Epoch: 307  Training loss = 2.2295  Validation loss = 2.2233  \n",
      "\n",
      "Fold: 32  Epoch: 308  Training loss = 2.2294  Validation loss = 2.2231  \n",
      "\n",
      "Fold: 32  Epoch: 309  Training loss = 2.2294  Validation loss = 2.2231  \n",
      "\n",
      "Fold: 32  Epoch: 310  Training loss = 2.2293  Validation loss = 2.2230  \n",
      "\n",
      "Fold: 32  Epoch: 311  Training loss = 2.2293  Validation loss = 2.2229  \n",
      "\n",
      "Fold: 32  Epoch: 312  Training loss = 2.2292  Validation loss = 2.2228  \n",
      "\n",
      "Fold: 32  Epoch: 313  Training loss = 2.2292  Validation loss = 2.2228  \n",
      "\n",
      "Fold: 32  Epoch: 314  Training loss = 2.2291  Validation loss = 2.2227  \n",
      "\n",
      "Fold: 32  Epoch: 315  Training loss = 2.2291  Validation loss = 2.2227  \n",
      "\n",
      "Fold: 32  Epoch: 316  Training loss = 2.2290  Validation loss = 2.2227  \n",
      "\n",
      "Fold: 32  Epoch: 317  Training loss = 2.2290  Validation loss = 2.2225  \n",
      "\n",
      "Fold: 32  Epoch: 318  Training loss = 2.2289  Validation loss = 2.2224  \n",
      "\n",
      "Fold: 32  Epoch: 319  Training loss = 2.2287  Validation loss = 2.2218  \n",
      "\n",
      "Fold: 32  Epoch: 320  Training loss = 2.2287  Validation loss = 2.2217  \n",
      "\n",
      "Fold: 32  Epoch: 321  Training loss = 2.2286  Validation loss = 2.2214  \n",
      "\n",
      "Fold: 32  Epoch: 322  Training loss = 2.2285  Validation loss = 2.2211  \n",
      "\n",
      "Fold: 32  Epoch: 323  Training loss = 2.2284  Validation loss = 2.2209  \n",
      "\n",
      "Fold: 32  Epoch: 324  Training loss = 2.2284  Validation loss = 2.2209  \n",
      "\n",
      "Fold: 32  Epoch: 325  Training loss = 2.2283  Validation loss = 2.2209  \n",
      "\n",
      "Fold: 32  Epoch: 326  Training loss = 2.2283  Validation loss = 2.2208  \n",
      "\n",
      "Fold: 32  Epoch: 327  Training loss = 2.2282  Validation loss = 2.2206  \n",
      "\n",
      "Fold: 32  Epoch: 328  Training loss = 2.2282  Validation loss = 2.2206  \n",
      "\n",
      "Fold: 32  Epoch: 329  Training loss = 2.2281  Validation loss = 2.2206  \n",
      "\n",
      "Fold: 32  Epoch: 330  Training loss = 2.2281  Validation loss = 2.2206  \n",
      "\n",
      "Fold: 32  Epoch: 331  Training loss = 2.2280  Validation loss = 2.2206  \n",
      "\n",
      "Fold: 32  Epoch: 332  Training loss = 2.2279  Validation loss = 2.2202  \n",
      "\n",
      "Fold: 32  Epoch: 333  Training loss = 2.2279  Validation loss = 2.2200  \n",
      "\n",
      "Fold: 32  Epoch: 334  Training loss = 2.2279  Validation loss = 2.2201  \n",
      "\n",
      "Fold: 32  Epoch: 335  Training loss = 2.2278  Validation loss = 2.2201  \n",
      "\n",
      "Fold: 32  Epoch: 336  Training loss = 2.2277  Validation loss = 2.2197  \n",
      "\n",
      "Fold: 32  Epoch: 337  Training loss = 2.2276  Validation loss = 2.2195  \n",
      "\n",
      "Fold: 32  Epoch: 338  Training loss = 2.2276  Validation loss = 2.2195  \n",
      "\n",
      "Fold: 32  Epoch: 339  Training loss = 2.2275  Validation loss = 2.2193  \n",
      "\n",
      "Fold: 32  Epoch: 340  Training loss = 2.2275  Validation loss = 2.2192  \n",
      "\n",
      "Fold: 32  Epoch: 341  Training loss = 2.2274  Validation loss = 2.2191  \n",
      "\n",
      "Fold: 32  Epoch: 342  Training loss = 2.2273  Validation loss = 2.2189  \n",
      "\n",
      "Fold: 32  Epoch: 343  Training loss = 2.2273  Validation loss = 2.2187  \n",
      "\n",
      "Fold: 32  Epoch: 344  Training loss = 2.2273  Validation loss = 2.2188  \n",
      "\n",
      "Fold: 32  Epoch: 345  Training loss = 2.2272  Validation loss = 2.2186  \n",
      "\n",
      "Fold: 32  Epoch: 346  Training loss = 2.2271  Validation loss = 2.2183  \n",
      "\n",
      "Fold: 32  Epoch: 347  Training loss = 2.2270  Validation loss = 2.2180  \n",
      "\n",
      "Fold: 32  Epoch: 348  Training loss = 2.2270  Validation loss = 2.2180  \n",
      "\n",
      "Fold: 32  Epoch: 349  Training loss = 2.2269  Validation loss = 2.2181  \n",
      "\n",
      "Fold: 32  Epoch: 350  Training loss = 2.2270  Validation loss = 2.2183  \n",
      "\n",
      "Fold: 32  Epoch: 351  Training loss = 2.2269  Validation loss = 2.2181  \n",
      "\n",
      "Fold: 32  Epoch: 352  Training loss = 2.2268  Validation loss = 2.2180  \n",
      "\n",
      "Fold: 32  Epoch: 353  Training loss = 2.2268  Validation loss = 2.2179  \n",
      "\n",
      "Fold: 32  Epoch: 354  Training loss = 2.2268  Validation loss = 2.2178  \n",
      "\n",
      "Fold: 32  Epoch: 355  Training loss = 2.2267  Validation loss = 2.2177  \n",
      "\n",
      "Fold: 32  Epoch: 356  Training loss = 2.2267  Validation loss = 2.2176  \n",
      "\n",
      "Fold: 32  Epoch: 357  Training loss = 2.2267  Validation loss = 2.2178  \n",
      "\n",
      "Fold: 32  Epoch: 358  Training loss = 2.2266  Validation loss = 2.2175  \n",
      "\n",
      "Fold: 32  Epoch: 359  Training loss = 2.2265  Validation loss = 2.2172  \n",
      "\n",
      "Fold: 32  Epoch: 360  Training loss = 2.2264  Validation loss = 2.2171  \n",
      "\n",
      "Fold: 32  Epoch: 361  Training loss = 2.2264  Validation loss = 2.2170  \n",
      "\n",
      "Fold: 32  Epoch: 362  Training loss = 2.2263  Validation loss = 2.2170  \n",
      "\n",
      "Fold: 32  Epoch: 363  Training loss = 2.2263  Validation loss = 2.2168  \n",
      "\n",
      "Fold: 32  Epoch: 364  Training loss = 2.2262  Validation loss = 2.2165  \n",
      "\n",
      "Fold: 32  Epoch: 365  Training loss = 2.2261  Validation loss = 2.2164  \n",
      "\n",
      "Fold: 32  Epoch: 366  Training loss = 2.2260  Validation loss = 2.2163  \n",
      "\n",
      "Fold: 32  Epoch: 367  Training loss = 2.2260  Validation loss = 2.2161  \n",
      "\n",
      "Fold: 32  Epoch: 368  Training loss = 2.2260  Validation loss = 2.2161  \n",
      "\n",
      "Fold: 32  Epoch: 369  Training loss = 2.2259  Validation loss = 2.2159  \n",
      "\n",
      "Fold: 32  Epoch: 370  Training loss = 2.2258  Validation loss = 2.2157  \n",
      "\n",
      "Fold: 32  Epoch: 371  Training loss = 2.2257  Validation loss = 2.2154  \n",
      "\n",
      "Fold: 32  Epoch: 372  Training loss = 2.2257  Validation loss = 2.2154  \n",
      "\n",
      "Fold: 32  Epoch: 373  Training loss = 2.2256  Validation loss = 2.2150  \n",
      "\n",
      "Fold: 32  Epoch: 374  Training loss = 2.2256  Validation loss = 2.2149  \n",
      "\n",
      "Fold: 32  Epoch: 375  Training loss = 2.2255  Validation loss = 2.2148  \n",
      "\n",
      "Fold: 32  Epoch: 376  Training loss = 2.2255  Validation loss = 2.2146  \n",
      "\n",
      "Fold: 32  Epoch: 377  Training loss = 2.2254  Validation loss = 2.2147  \n",
      "\n",
      "Fold: 32  Epoch: 378  Training loss = 2.2254  Validation loss = 2.2145  \n",
      "\n",
      "Fold: 32  Epoch: 379  Training loss = 2.2254  Validation loss = 2.2144  \n",
      "\n",
      "Fold: 32  Epoch: 380  Training loss = 2.2253  Validation loss = 2.2145  \n",
      "\n",
      "Fold: 32  Epoch: 381  Training loss = 2.2253  Validation loss = 2.2143  \n",
      "\n",
      "Fold: 32  Epoch: 382  Training loss = 2.2252  Validation loss = 2.2142  \n",
      "\n",
      "Fold: 32  Epoch: 383  Training loss = 2.2251  Validation loss = 2.2139  \n",
      "\n",
      "Fold: 32  Epoch: 384  Training loss = 2.2251  Validation loss = 2.2137  \n",
      "\n",
      "Fold: 32  Epoch: 385  Training loss = 2.2250  Validation loss = 2.2137  \n",
      "\n",
      "Fold: 32  Epoch: 386  Training loss = 2.2250  Validation loss = 2.2137  \n",
      "\n",
      "Fold: 32  Epoch: 387  Training loss = 2.2250  Validation loss = 2.2136  \n",
      "\n",
      "Fold: 32  Epoch: 388  Training loss = 2.2249  Validation loss = 2.2137  \n",
      "\n",
      "Fold: 32  Epoch: 389  Training loss = 2.2249  Validation loss = 2.2137  \n",
      "\n",
      "Fold: 32  Epoch: 390  Training loss = 2.2249  Validation loss = 2.2136  \n",
      "\n",
      "Fold: 32  Epoch: 391  Training loss = 2.2248  Validation loss = 2.2136  \n",
      "\n",
      "Fold: 32  Epoch: 392  Training loss = 2.2248  Validation loss = 2.2136  \n",
      "\n",
      "Fold: 32  Epoch: 393  Training loss = 2.2247  Validation loss = 2.2135  \n",
      "\n",
      "Fold: 32  Epoch: 394  Training loss = 2.2247  Validation loss = 2.2133  \n",
      "\n",
      "Fold: 32  Epoch: 395  Training loss = 2.2246  Validation loss = 2.2130  \n",
      "\n",
      "Fold: 32  Epoch: 396  Training loss = 2.2245  Validation loss = 2.2128  \n",
      "\n",
      "Fold: 32  Epoch: 397  Training loss = 2.2245  Validation loss = 2.2126  \n",
      "\n",
      "Fold: 32  Epoch: 398  Training loss = 2.2244  Validation loss = 2.2125  \n",
      "\n",
      "Fold: 32  Epoch: 399  Training loss = 2.2243  Validation loss = 2.2124  \n",
      "\n",
      "Fold: 32  Epoch: 400  Training loss = 2.2243  Validation loss = 2.2124  \n",
      "\n",
      "Fold: 32  Epoch: 401  Training loss = 2.2243  Validation loss = 2.2125  \n",
      "\n",
      "Fold: 32  Epoch: 402  Training loss = 2.2242  Validation loss = 2.2123  \n",
      "\n",
      "Fold: 32  Epoch: 403  Training loss = 2.2242  Validation loss = 2.2123  \n",
      "\n",
      "Fold: 32  Epoch: 404  Training loss = 2.2241  Validation loss = 2.2122  \n",
      "\n",
      "Fold: 32  Epoch: 405  Training loss = 2.2241  Validation loss = 2.2123  \n",
      "\n",
      "Fold: 32  Epoch: 406  Training loss = 2.2241  Validation loss = 2.2124  \n",
      "\n",
      "Fold: 32  Epoch: 407  Training loss = 2.2241  Validation loss = 2.2125  \n",
      "\n",
      "Fold: 32  Epoch: 408  Training loss = 2.2240  Validation loss = 2.2123  \n",
      "\n",
      "Fold: 32  Epoch: 409  Training loss = 2.2240  Validation loss = 2.2127  \n",
      "\n",
      "Check model:  Fold: 32  Optimal epoch: 404  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 2. Train model\n",
    "# ==================================\n",
    "sess = tf.InteractiveSession()  # Launch Graph\n",
    "sess.run(tf.global_variables_initializer())  # Initialise all variables\n",
    "\n",
    "print(\"Start training\", \n",
    "      \"\\nHyperparameters:\",\n",
    "      \"\\nDimension of recurrent unit =\", n_hidden,\n",
    "      \"\\nLearning rate =\", learning_rate,\n",
    "      \"\\nEpochs =\", epochs,\n",
    "      \"\\nBatch size =\", batch_size,\n",
    "      \"\\nEarly stopping epochs =\", early_stop_iters,\n",
    "      \"\\nLearning rate =\", learning_rate)\n",
    "\n",
    "total_batch = int(window_length / batch_size)\n",
    "validation_fold_error = [] # store validation error of each fold\n",
    "optimal_epochs = []\n",
    "\n",
    "# loop through folds\n",
    "for fold in range(1, len(valIndex)):\n",
    "    validx = train_features[valIndex[fold-1]:valIndex[fold]]\n",
    "    validy = train_target[valIndex[fold-1]:valIndex[fold]]\n",
    "    trainx = train_features[(fold-1)*4:valIndex[(fold-1)]]\n",
    "    trainy = train_target[(fold-1)*4:valIndex[(fold-1)]]\n",
    "\n",
    "    loss_list = [] # store validation loss after each epoch for early stopping\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i in range(total_batch):\n",
    "            # Backprop\n",
    "            batch_xs, batch_ys = next_batch(num=batch_size, data=trainx, labels=trainy)\n",
    "            optimizer.run(feed_dict={x:batch_xs, y:batch_ys, lr:learning_rate})\n",
    "\n",
    "        # Loss\n",
    "        loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "        loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "        loss_list.append(loss_valid)\n",
    "\n",
    "        print(\"Fold: {0:d}\".format(fold),\n",
    "              \" Epoch: {0:d}\".format(epoch+1),\n",
    "              \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "              \" Validation loss = {0:.4f}\".format(np.sqrt(loss_valid)),\n",
    "              \" \\n\")\n",
    "\n",
    "        if all(j <= loss_valid for j in loss_list[-early_stop_iters:]) and len(loss_list)>early_stop_iters:\n",
    "            break\n",
    "    \n",
    "    # Load model with lowest validation error for each fold\n",
    "    epoch_hat = np.argmin(loss_list) + 1\n",
    "    optimal_epochs.append(epoch_hat) # store optimal number of epochs for each fold\n",
    "    \n",
    "    # RMSE\n",
    "    loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "    loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "    validation_fold_error.append(np.sqrt(loss_valid))\n",
    "    \n",
    "    print(\"Check model:\",\n",
    "          \" Fold: {0:d}\".format(fold),\n",
    "          \" Optimal epoch: {0:d}\".format(epoch_hat),\n",
    "          \" \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average number of epochs: 369\n",
      "Average validation error: 3.91034\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 3. Optimal epoch choice\n",
    "# ==================================\n",
    "# Pick number of epochs to train model for out-of-sample testing\n",
    "epoch_hat = int(np.mean(optimal_epochs))\n",
    "print(\"\\nAverage number of epochs:\", epoch_hat)\n",
    "# Average validation error\n",
    "print(\"Average validation error:\", np.mean(validation_fold_error))\n",
    "\n",
    "# Save validated model\n",
    "saveModel(sess, \n",
    "          MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + str(epoch_hat) + \"_validated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fixed scheme:\n",
      "Epoch: 1  Training loss = 1.7957  Test loss = 2.9437  \n",
      "\n",
      "Epoch: 2  Training loss = 1.7957  Test loss = 2.9437  \n",
      "\n",
      "Epoch: 3  Training loss = 1.7957  Test loss = 2.9436  \n",
      "\n",
      "Epoch: 4  Training loss = 1.7957  Test loss = 2.9436  \n",
      "\n",
      "Epoch: 5  Training loss = 1.7957  Test loss = 2.9436  \n",
      "\n",
      "Epoch: 6  Training loss = 1.7957  Test loss = 2.9435  \n",
      "\n",
      "Epoch: 7  Training loss = 1.7957  Test loss = 2.9435  \n",
      "\n",
      "Epoch: 8  Training loss = 1.7956  Test loss = 2.9435  \n",
      "\n",
      "Epoch: 9  Training loss = 1.7956  Test loss = 2.9434  \n",
      "\n",
      "Epoch: 10  Training loss = 1.7956  Test loss = 2.9434  \n",
      "\n",
      "Epoch: 11  Training loss = 1.7956  Test loss = 2.9434  \n",
      "\n",
      "Epoch: 12  Training loss = 1.7956  Test loss = 2.9433  \n",
      "\n",
      "Epoch: 13  Training loss = 1.7956  Test loss = 2.9433  \n",
      "\n",
      "Epoch: 14  Training loss = 1.7955  Test loss = 2.9433  \n",
      "\n",
      "Epoch: 15  Training loss = 1.7955  Test loss = 2.9432  \n",
      "\n",
      "Epoch: 16  Training loss = 1.7955  Test loss = 2.9432  \n",
      "\n",
      "Epoch: 17  Training loss = 1.7955  Test loss = 2.9432  \n",
      "\n",
      "Epoch: 18  Training loss = 1.7955  Test loss = 2.9431  \n",
      "\n",
      "Epoch: 19  Training loss = 1.7955  Test loss = 2.9431  \n",
      "\n",
      "Epoch: 20  Training loss = 1.7955  Test loss = 2.9431  \n",
      "\n",
      "Epoch: 21  Training loss = 1.7954  Test loss = 2.9430  \n",
      "\n",
      "Epoch: 22  Training loss = 1.7954  Test loss = 2.9430  \n",
      "\n",
      "Epoch: 23  Training loss = 1.7954  Test loss = 2.9430  \n",
      "\n",
      "Epoch: 24  Training loss = 1.7954  Test loss = 2.9429  \n",
      "\n",
      "Epoch: 25  Training loss = 1.7954  Test loss = 2.9429  \n",
      "\n",
      "Epoch: 26  Training loss = 1.7954  Test loss = 2.9429  \n",
      "\n",
      "Epoch: 27  Training loss = 1.7953  Test loss = 2.9428  \n",
      "\n",
      "Epoch: 28  Training loss = 1.7953  Test loss = 2.9428  \n",
      "\n",
      "Epoch: 29  Training loss = 1.7953  Test loss = 2.9428  \n",
      "\n",
      "Epoch: 30  Training loss = 1.7953  Test loss = 2.9427  \n",
      "\n",
      "Epoch: 31  Training loss = 1.7953  Test loss = 2.9427  \n",
      "\n",
      "Epoch: 32  Training loss = 1.7953  Test loss = 2.9427  \n",
      "\n",
      "Epoch: 33  Training loss = 1.7953  Test loss = 2.9426  \n",
      "\n",
      "Epoch: 34  Training loss = 1.7952  Test loss = 2.9426  \n",
      "\n",
      "Epoch: 35  Training loss = 1.7952  Test loss = 2.9426  \n",
      "\n",
      "Epoch: 36  Training loss = 1.7952  Test loss = 2.9425  \n",
      "\n",
      "Epoch: 37  Training loss = 1.7952  Test loss = 2.9425  \n",
      "\n",
      "Epoch: 38  Training loss = 1.7952  Test loss = 2.9425  \n",
      "\n",
      "Epoch: 39  Training loss = 1.7952  Test loss = 2.9424  \n",
      "\n",
      "Epoch: 40  Training loss = 1.7951  Test loss = 2.9424  \n",
      "\n",
      "Epoch: 41  Training loss = 1.7951  Test loss = 2.9424  \n",
      "\n",
      "Epoch: 42  Training loss = 1.7951  Test loss = 2.9423  \n",
      "\n",
      "Epoch: 43  Training loss = 1.7951  Test loss = 2.9423  \n",
      "\n",
      "Epoch: 44  Training loss = 1.7951  Test loss = 2.9423  \n",
      "\n",
      "Epoch: 45  Training loss = 1.7951  Test loss = 2.9422  \n",
      "\n",
      "Epoch: 46  Training loss = 1.7951  Test loss = 2.9422  \n",
      "\n",
      "Epoch: 47  Training loss = 1.7950  Test loss = 2.9422  \n",
      "\n",
      "Epoch: 48  Training loss = 1.7950  Test loss = 2.9421  \n",
      "\n",
      "Epoch: 49  Training loss = 1.7950  Test loss = 2.9421  \n",
      "\n",
      "Epoch: 50  Training loss = 1.7950  Test loss = 2.9421  \n",
      "\n",
      "Epoch: 51  Training loss = 1.7950  Test loss = 2.9420  \n",
      "\n",
      "Epoch: 52  Training loss = 1.7950  Test loss = 2.9420  \n",
      "\n",
      "Epoch: 53  Training loss = 1.7949  Test loss = 2.9420  \n",
      "\n",
      "Epoch: 54  Training loss = 1.7949  Test loss = 2.9419  \n",
      "\n",
      "Epoch: 55  Training loss = 1.7949  Test loss = 2.9419  \n",
      "\n",
      "Epoch: 56  Training loss = 1.7949  Test loss = 2.9419  \n",
      "\n",
      "Epoch: 57  Training loss = 1.7949  Test loss = 2.9418  \n",
      "\n",
      "Epoch: 58  Training loss = 1.7949  Test loss = 2.9418  \n",
      "\n",
      "Epoch: 59  Training loss = 1.7949  Test loss = 2.9418  \n",
      "\n",
      "Epoch: 60  Training loss = 1.7948  Test loss = 2.9417  \n",
      "\n",
      "Epoch: 61  Training loss = 1.7948  Test loss = 2.9417  \n",
      "\n",
      "Epoch: 62  Training loss = 1.7948  Test loss = 2.9417  \n",
      "\n",
      "Epoch: 63  Training loss = 1.7948  Test loss = 2.9416  \n",
      "\n",
      "Epoch: 64  Training loss = 1.7948  Test loss = 2.9416  \n",
      "\n",
      "Epoch: 65  Training loss = 1.7948  Test loss = 2.9416  \n",
      "\n",
      "Epoch: 66  Training loss = 1.7948  Test loss = 2.9415  \n",
      "\n",
      "Epoch: 67  Training loss = 1.7947  Test loss = 2.9415  \n",
      "\n",
      "Epoch: 68  Training loss = 1.7947  Test loss = 2.9415  \n",
      "\n",
      "Epoch: 69  Training loss = 1.7947  Test loss = 2.9414  \n",
      "\n",
      "Epoch: 70  Training loss = 1.7947  Test loss = 2.9414  \n",
      "\n",
      "Epoch: 71  Training loss = 1.7947  Test loss = 2.9414  \n",
      "\n",
      "Epoch: 72  Training loss = 1.7947  Test loss = 2.9413  \n",
      "\n",
      "Epoch: 73  Training loss = 1.7946  Test loss = 2.9413  \n",
      "\n",
      "Epoch: 74  Training loss = 1.7946  Test loss = 2.9413  \n",
      "\n",
      "Epoch: 75  Training loss = 1.7946  Test loss = 2.9412  \n",
      "\n",
      "Epoch: 76  Training loss = 1.7946  Test loss = 2.9412  \n",
      "\n",
      "Epoch: 77  Training loss = 1.7946  Test loss = 2.9412  \n",
      "\n",
      "Epoch: 78  Training loss = 1.7946  Test loss = 2.9411  \n",
      "\n",
      "Epoch: 79  Training loss = 1.7946  Test loss = 2.9411  \n",
      "\n",
      "Epoch: 80  Training loss = 1.7945  Test loss = 2.9411  \n",
      "\n",
      "Epoch: 81  Training loss = 1.7945  Test loss = 2.9410  \n",
      "\n",
      "Epoch: 82  Training loss = 1.7945  Test loss = 2.9410  \n",
      "\n",
      "Epoch: 83  Training loss = 1.7945  Test loss = 2.9410  \n",
      "\n",
      "Epoch: 84  Training loss = 1.7945  Test loss = 2.9409  \n",
      "\n",
      "Epoch: 85  Training loss = 1.7945  Test loss = 2.9409  \n",
      "\n",
      "Epoch: 86  Training loss = 1.7944  Test loss = 2.9409  \n",
      "\n",
      "Epoch: 87  Training loss = 1.7944  Test loss = 2.9408  \n",
      "\n",
      "Epoch: 88  Training loss = 1.7944  Test loss = 2.9408  \n",
      "\n",
      "Epoch: 89  Training loss = 1.7944  Test loss = 2.9408  \n",
      "\n",
      "Epoch: 90  Training loss = 1.7944  Test loss = 2.9407  \n",
      "\n",
      "Epoch: 91  Training loss = 1.7944  Test loss = 2.9407  \n",
      "\n",
      "Epoch: 92  Training loss = 1.7944  Test loss = 2.9407  \n",
      "\n",
      "Epoch: 93  Training loss = 1.7943  Test loss = 2.9406  \n",
      "\n",
      "Epoch: 94  Training loss = 1.7943  Test loss = 2.9406  \n",
      "\n",
      "Epoch: 95  Training loss = 1.7943  Test loss = 2.9406  \n",
      "\n",
      "Epoch: 96  Training loss = 1.7943  Test loss = 2.9405  \n",
      "\n",
      "Epoch: 97  Training loss = 1.7943  Test loss = 2.9405  \n",
      "\n",
      "Epoch: 98  Training loss = 1.7943  Test loss = 2.9405  \n",
      "\n",
      "Epoch: 99  Training loss = 1.7943  Test loss = 2.9404  \n",
      "\n",
      "Epoch: 100  Training loss = 1.7942  Test loss = 2.9404  \n",
      "\n",
      "Epoch: 101  Training loss = 1.7942  Test loss = 2.9404  \n",
      "\n",
      "Epoch: 102  Training loss = 1.7942  Test loss = 2.9403  \n",
      "\n",
      "Epoch: 103  Training loss = 1.7942  Test loss = 2.9403  \n",
      "\n",
      "Epoch: 104  Training loss = 1.7942  Test loss = 2.9403  \n",
      "\n",
      "Epoch: 105  Training loss = 1.7942  Test loss = 2.9402  \n",
      "\n",
      "Epoch: 106  Training loss = 1.7941  Test loss = 2.9402  \n",
      "\n",
      "Epoch: 107  Training loss = 1.7941  Test loss = 2.9402  \n",
      "\n",
      "Epoch: 108  Training loss = 1.7941  Test loss = 2.9401  \n",
      "\n",
      "Epoch: 109  Training loss = 1.7941  Test loss = 2.9401  \n",
      "\n",
      "Epoch: 110  Training loss = 1.7941  Test loss = 2.9401  \n",
      "\n",
      "Epoch: 111  Training loss = 1.7941  Test loss = 2.9400  \n",
      "\n",
      "Epoch: 112  Training loss = 1.7941  Test loss = 2.9400  \n",
      "\n",
      "Epoch: 113  Training loss = 1.7940  Test loss = 2.9400  \n",
      "\n",
      "Epoch: 114  Training loss = 1.7940  Test loss = 2.9399  \n",
      "\n",
      "Epoch: 115  Training loss = 1.7940  Test loss = 2.9399  \n",
      "\n",
      "Epoch: 116  Training loss = 1.7940  Test loss = 2.9399  \n",
      "\n",
      "Epoch: 117  Training loss = 1.7940  Test loss = 2.9398  \n",
      "\n",
      "Epoch: 118  Training loss = 1.7940  Test loss = 2.9398  \n",
      "\n",
      "Epoch: 119  Training loss = 1.7939  Test loss = 2.9398  \n",
      "\n",
      "Epoch: 120  Training loss = 1.7939  Test loss = 2.9397  \n",
      "\n",
      "Epoch: 121  Training loss = 1.7939  Test loss = 2.9397  \n",
      "\n",
      "Epoch: 122  Training loss = 1.7939  Test loss = 2.9397  \n",
      "\n",
      "Epoch: 123  Training loss = 1.7939  Test loss = 2.9396  \n",
      "\n",
      "Epoch: 124  Training loss = 1.7939  Test loss = 2.9396  \n",
      "\n",
      "Epoch: 125  Training loss = 1.7939  Test loss = 2.9396  \n",
      "\n",
      "Epoch: 126  Training loss = 1.7938  Test loss = 2.9395  \n",
      "\n",
      "Epoch: 127  Training loss = 1.7938  Test loss = 2.9395  \n",
      "\n",
      "Epoch: 128  Training loss = 1.7938  Test loss = 2.9395  \n",
      "\n",
      "Epoch: 129  Training loss = 1.7938  Test loss = 2.9394  \n",
      "\n",
      "Epoch: 130  Training loss = 1.7938  Test loss = 2.9394  \n",
      "\n",
      "Epoch: 131  Training loss = 1.7938  Test loss = 2.9394  \n",
      "\n",
      "Epoch: 132  Training loss = 1.7937  Test loss = 2.9393  \n",
      "\n",
      "Epoch: 133  Training loss = 1.7937  Test loss = 2.9393  \n",
      "\n",
      "Epoch: 134  Training loss = 1.7937  Test loss = 2.9393  \n",
      "\n",
      "Epoch: 135  Training loss = 1.7937  Test loss = 2.9392  \n",
      "\n",
      "Epoch: 136  Training loss = 1.7937  Test loss = 2.9392  \n",
      "\n",
      "Epoch: 137  Training loss = 1.7937  Test loss = 2.9392  \n",
      "\n",
      "Epoch: 138  Training loss = 1.7937  Test loss = 2.9391  \n",
      "\n",
      "Epoch: 139  Training loss = 1.7936  Test loss = 2.9391  \n",
      "\n",
      "Epoch: 140  Training loss = 1.7936  Test loss = 2.9391  \n",
      "\n",
      "Epoch: 141  Training loss = 1.7936  Test loss = 2.9390  \n",
      "\n",
      "Epoch: 142  Training loss = 1.7936  Test loss = 2.9390  \n",
      "\n",
      "Epoch: 143  Training loss = 1.7936  Test loss = 2.9390  \n",
      "\n",
      "Epoch: 144  Training loss = 1.7936  Test loss = 2.9389  \n",
      "\n",
      "Epoch: 145  Training loss = 1.7936  Test loss = 2.9389  \n",
      "\n",
      "Epoch: 146  Training loss = 1.7935  Test loss = 2.9389  \n",
      "\n",
      "Epoch: 147  Training loss = 1.7935  Test loss = 2.9388  \n",
      "\n",
      "Epoch: 148  Training loss = 1.7935  Test loss = 2.9388  \n",
      "\n",
      "Epoch: 149  Training loss = 1.7935  Test loss = 2.9388  \n",
      "\n",
      "Epoch: 150  Training loss = 1.7935  Test loss = 2.9387  \n",
      "\n",
      "Epoch: 151  Training loss = 1.7935  Test loss = 2.9387  \n",
      "\n",
      "Epoch: 152  Training loss = 1.7934  Test loss = 2.9387  \n",
      "\n",
      "Epoch: 153  Training loss = 1.7934  Test loss = 2.9386  \n",
      "\n",
      "Epoch: 154  Training loss = 1.7934  Test loss = 2.9386  \n",
      "\n",
      "Epoch: 155  Training loss = 1.7934  Test loss = 2.9386  \n",
      "\n",
      "Epoch: 156  Training loss = 1.7934  Test loss = 2.9385  \n",
      "\n",
      "Epoch: 157  Training loss = 1.7934  Test loss = 2.9385  \n",
      "\n",
      "Epoch: 158  Training loss = 1.7934  Test loss = 2.9385  \n",
      "\n",
      "Epoch: 159  Training loss = 1.7933  Test loss = 2.9384  \n",
      "\n",
      "Epoch: 160  Training loss = 1.7933  Test loss = 2.9384  \n",
      "\n",
      "Epoch: 161  Training loss = 1.7933  Test loss = 2.9384  \n",
      "\n",
      "Epoch: 162  Training loss = 1.7933  Test loss = 2.9383  \n",
      "\n",
      "Epoch: 163  Training loss = 1.7933  Test loss = 2.9383  \n",
      "\n",
      "Epoch: 164  Training loss = 1.7933  Test loss = 2.9383  \n",
      "\n",
      "Epoch: 165  Training loss = 1.7932  Test loss = 2.9382  \n",
      "\n",
      "Epoch: 166  Training loss = 1.7932  Test loss = 2.9382  \n",
      "\n",
      "Epoch: 167  Training loss = 1.7932  Test loss = 2.9382  \n",
      "\n",
      "Epoch: 168  Training loss = 1.7932  Test loss = 2.9381  \n",
      "\n",
      "Epoch: 169  Training loss = 1.7932  Test loss = 2.9381  \n",
      "\n",
      "Epoch: 170  Training loss = 1.7932  Test loss = 2.9381  \n",
      "\n",
      "Epoch: 171  Training loss = 1.7932  Test loss = 2.9380  \n",
      "\n",
      "Epoch: 172  Training loss = 1.7931  Test loss = 2.9380  \n",
      "\n",
      "Epoch: 173  Training loss = 1.7931  Test loss = 2.9380  \n",
      "\n",
      "Epoch: 174  Training loss = 1.7931  Test loss = 2.9379  \n",
      "\n",
      "Epoch: 175  Training loss = 1.7931  Test loss = 2.9379  \n",
      "\n",
      "Epoch: 176  Training loss = 1.7931  Test loss = 2.9379  \n",
      "\n",
      "Epoch: 177  Training loss = 1.7931  Test loss = 2.9378  \n",
      "\n",
      "Epoch: 178  Training loss = 1.7931  Test loss = 2.9378  \n",
      "\n",
      "Epoch: 179  Training loss = 1.7930  Test loss = 2.9378  \n",
      "\n",
      "Epoch: 180  Training loss = 1.7930  Test loss = 2.9377  \n",
      "\n",
      "Epoch: 181  Training loss = 1.7930  Test loss = 2.9377  \n",
      "\n",
      "Epoch: 182  Training loss = 1.7930  Test loss = 2.9377  \n",
      "\n",
      "Epoch: 183  Training loss = 1.7930  Test loss = 2.9377  \n",
      "\n",
      "Epoch: 184  Training loss = 1.7930  Test loss = 2.9376  \n",
      "\n",
      "Epoch: 185  Training loss = 1.7929  Test loss = 2.9376  \n",
      "\n",
      "Epoch: 186  Training loss = 1.7929  Test loss = 2.9376  \n",
      "\n",
      "Epoch: 187  Training loss = 1.7929  Test loss = 2.9375  \n",
      "\n",
      "Epoch: 188  Training loss = 1.7929  Test loss = 2.9375  \n",
      "\n",
      "Epoch: 189  Training loss = 1.7929  Test loss = 2.9375  \n",
      "\n",
      "Epoch: 190  Training loss = 1.7929  Test loss = 2.9374  \n",
      "\n",
      "Epoch: 191  Training loss = 1.7929  Test loss = 2.9374  \n",
      "\n",
      "Epoch: 192  Training loss = 1.7928  Test loss = 2.9374  \n",
      "\n",
      "Epoch: 193  Training loss = 1.7928  Test loss = 2.9373  \n",
      "\n",
      "Epoch: 194  Training loss = 1.7928  Test loss = 2.9373  \n",
      "\n",
      "Epoch: 195  Training loss = 1.7928  Test loss = 2.9373  \n",
      "\n",
      "Epoch: 196  Training loss = 1.7928  Test loss = 2.9372  \n",
      "\n",
      "Epoch: 197  Training loss = 1.7928  Test loss = 2.9372  \n",
      "\n",
      "Epoch: 198  Training loss = 1.7927  Test loss = 2.9372  \n",
      "\n",
      "Epoch: 199  Training loss = 1.7927  Test loss = 2.9371  \n",
      "\n",
      "Epoch: 200  Training loss = 1.7927  Test loss = 2.9371  \n",
      "\n",
      "Epoch: 201  Training loss = 1.7927  Test loss = 2.9371  \n",
      "\n",
      "Epoch: 202  Training loss = 1.7927  Test loss = 2.9370  \n",
      "\n",
      "Epoch: 203  Training loss = 1.7927  Test loss = 2.9370  \n",
      "\n",
      "Epoch: 204  Training loss = 1.7927  Test loss = 2.9370  \n",
      "\n",
      "Epoch: 205  Training loss = 1.7926  Test loss = 2.9369  \n",
      "\n",
      "Epoch: 206  Training loss = 1.7926  Test loss = 2.9369  \n",
      "\n",
      "Epoch: 207  Training loss = 1.7926  Test loss = 2.9369  \n",
      "\n",
      "Epoch: 208  Training loss = 1.7926  Test loss = 2.9368  \n",
      "\n",
      "Epoch: 209  Training loss = 1.7926  Test loss = 2.9368  \n",
      "\n",
      "Epoch: 210  Training loss = 1.7926  Test loss = 2.9368  \n",
      "\n",
      "Epoch: 211  Training loss = 1.7926  Test loss = 2.9367  \n",
      "\n",
      "Epoch: 212  Training loss = 1.7925  Test loss = 2.9367  \n",
      "\n",
      "Epoch: 213  Training loss = 1.7925  Test loss = 2.9367  \n",
      "\n",
      "Epoch: 214  Training loss = 1.7925  Test loss = 2.9366  \n",
      "\n",
      "Epoch: 215  Training loss = 1.7925  Test loss = 2.9366  \n",
      "\n",
      "Epoch: 216  Training loss = 1.7925  Test loss = 2.9366  \n",
      "\n",
      "Epoch: 217  Training loss = 1.7925  Test loss = 2.9365  \n",
      "\n",
      "Epoch: 218  Training loss = 1.7924  Test loss = 2.9365  \n",
      "\n",
      "Epoch: 219  Training loss = 1.7924  Test loss = 2.9365  \n",
      "\n",
      "Epoch: 220  Training loss = 1.7924  Test loss = 2.9364  \n",
      "\n",
      "Epoch: 221  Training loss = 1.7924  Test loss = 2.9364  \n",
      "\n",
      "Epoch: 222  Training loss = 1.7924  Test loss = 2.9364  \n",
      "\n",
      "Epoch: 223  Training loss = 1.7924  Test loss = 2.9363  \n",
      "\n",
      "Epoch: 224  Training loss = 1.7924  Test loss = 2.9363  \n",
      "\n",
      "Epoch: 225  Training loss = 1.7923  Test loss = 2.9363  \n",
      "\n",
      "Epoch: 226  Training loss = 1.7923  Test loss = 2.9362  \n",
      "\n",
      "Epoch: 227  Training loss = 1.7923  Test loss = 2.9362  \n",
      "\n",
      "Epoch: 228  Training loss = 1.7923  Test loss = 2.9362  \n",
      "\n",
      "Epoch: 229  Training loss = 1.7923  Test loss = 2.9361  \n",
      "\n",
      "Epoch: 230  Training loss = 1.7923  Test loss = 2.9361  \n",
      "\n",
      "Epoch: 231  Training loss = 1.7922  Test loss = 2.9361  \n",
      "\n",
      "Epoch: 232  Training loss = 1.7922  Test loss = 2.9360  \n",
      "\n",
      "Epoch: 233  Training loss = 1.7922  Test loss = 2.9360  \n",
      "\n",
      "Epoch: 234  Training loss = 1.7922  Test loss = 2.9360  \n",
      "\n",
      "Epoch: 235  Training loss = 1.7922  Test loss = 2.9359  \n",
      "\n",
      "Epoch: 236  Training loss = 1.7922  Test loss = 2.9359  \n",
      "\n",
      "Epoch: 237  Training loss = 1.7922  Test loss = 2.9359  \n",
      "\n",
      "Epoch: 238  Training loss = 1.7921  Test loss = 2.9358  \n",
      "\n",
      "Epoch: 239  Training loss = 1.7921  Test loss = 2.9358  \n",
      "\n",
      "Epoch: 240  Training loss = 1.7921  Test loss = 2.9358  \n",
      "\n",
      "Epoch: 241  Training loss = 1.7921  Test loss = 2.9357  \n",
      "\n",
      "Epoch: 242  Training loss = 1.7921  Test loss = 2.9357  \n",
      "\n",
      "Epoch: 243  Training loss = 1.7921  Test loss = 2.9357  \n",
      "\n",
      "Epoch: 244  Training loss = 1.7921  Test loss = 2.9356  \n",
      "\n",
      "Epoch: 245  Training loss = 1.7920  Test loss = 2.9356  \n",
      "\n",
      "Epoch: 246  Training loss = 1.7920  Test loss = 2.9356  \n",
      "\n",
      "Epoch: 247  Training loss = 1.7920  Test loss = 2.9355  \n",
      "\n",
      "Epoch: 248  Training loss = 1.7920  Test loss = 2.9355  \n",
      "\n",
      "Epoch: 249  Training loss = 1.7920  Test loss = 2.9355  \n",
      "\n",
      "Epoch: 250  Training loss = 1.7920  Test loss = 2.9354  \n",
      "\n",
      "Epoch: 251  Training loss = 1.7919  Test loss = 2.9354  \n",
      "\n",
      "Epoch: 252  Training loss = 1.7919  Test loss = 2.9354  \n",
      "\n",
      "Epoch: 253  Training loss = 1.7919  Test loss = 2.9353  \n",
      "\n",
      "Epoch: 254  Training loss = 1.7919  Test loss = 2.9353  \n",
      "\n",
      "Epoch: 255  Training loss = 1.7919  Test loss = 2.9353  \n",
      "\n",
      "Epoch: 256  Training loss = 1.7919  Test loss = 2.9352  \n",
      "\n",
      "Epoch: 257  Training loss = 1.7919  Test loss = 2.9352  \n",
      "\n",
      "Epoch: 258  Training loss = 1.7918  Test loss = 2.9352  \n",
      "\n",
      "Epoch: 259  Training loss = 1.7918  Test loss = 2.9351  \n",
      "\n",
      "Epoch: 260  Training loss = 1.7918  Test loss = 2.9351  \n",
      "\n",
      "Epoch: 261  Training loss = 1.7918  Test loss = 2.9351  \n",
      "\n",
      "Epoch: 262  Training loss = 1.7918  Test loss = 2.9350  \n",
      "\n",
      "Epoch: 263  Training loss = 1.7918  Test loss = 2.9350  \n",
      "\n",
      "Epoch: 264  Training loss = 1.7918  Test loss = 2.9350  \n",
      "\n",
      "Epoch: 265  Training loss = 1.7917  Test loss = 2.9349  \n",
      "\n",
      "Epoch: 266  Training loss = 1.7917  Test loss = 2.9349  \n",
      "\n",
      "Epoch: 267  Training loss = 1.7917  Test loss = 2.9349  \n",
      "\n",
      "Epoch: 268  Training loss = 1.7917  Test loss = 2.9348  \n",
      "\n",
      "Epoch: 269  Training loss = 1.7917  Test loss = 2.9348  \n",
      "\n",
      "Epoch: 270  Training loss = 1.7917  Test loss = 2.9348  \n",
      "\n",
      "Epoch: 271  Training loss = 1.7916  Test loss = 2.9347  \n",
      "\n",
      "Epoch: 272  Training loss = 1.7916  Test loss = 2.9347  \n",
      "\n",
      "Epoch: 273  Training loss = 1.7916  Test loss = 2.9347  \n",
      "\n",
      "Epoch: 274  Training loss = 1.7916  Test loss = 2.9346  \n",
      "\n",
      "Epoch: 275  Training loss = 1.7916  Test loss = 2.9346  \n",
      "\n",
      "Epoch: 276  Training loss = 1.7916  Test loss = 2.9346  \n",
      "\n",
      "Epoch: 277  Training loss = 1.7916  Test loss = 2.9346  \n",
      "\n",
      "Epoch: 278  Training loss = 1.7915  Test loss = 2.9345  \n",
      "\n",
      "Epoch: 279  Training loss = 1.7915  Test loss = 2.9345  \n",
      "\n",
      "Epoch: 280  Training loss = 1.7915  Test loss = 2.9345  \n",
      "\n",
      "Epoch: 281  Training loss = 1.7915  Test loss = 2.9344  \n",
      "\n",
      "Epoch: 282  Training loss = 1.7915  Test loss = 2.9344  \n",
      "\n",
      "Epoch: 283  Training loss = 1.7915  Test loss = 2.9344  \n",
      "\n",
      "Epoch: 284  Training loss = 1.7915  Test loss = 2.9343  \n",
      "\n",
      "Epoch: 285  Training loss = 1.7914  Test loss = 2.9343  \n",
      "\n",
      "Epoch: 286  Training loss = 1.7914  Test loss = 2.9343  \n",
      "\n",
      "Epoch: 287  Training loss = 1.7914  Test loss = 2.9342  \n",
      "\n",
      "Epoch: 288  Training loss = 1.7914  Test loss = 2.9342  \n",
      "\n",
      "Epoch: 289  Training loss = 1.7914  Test loss = 2.9342  \n",
      "\n",
      "Epoch: 290  Training loss = 1.7914  Test loss = 2.9341  \n",
      "\n",
      "Epoch: 291  Training loss = 1.7913  Test loss = 2.9341  \n",
      "\n",
      "Epoch: 292  Training loss = 1.7913  Test loss = 2.9341  \n",
      "\n",
      "Epoch: 293  Training loss = 1.7913  Test loss = 2.9340  \n",
      "\n",
      "Epoch: 294  Training loss = 1.7913  Test loss = 2.9340  \n",
      "\n",
      "Epoch: 295  Training loss = 1.7913  Test loss = 2.9340  \n",
      "\n",
      "Epoch: 296  Training loss = 1.7913  Test loss = 2.9339  \n",
      "\n",
      "Epoch: 297  Training loss = 1.7913  Test loss = 2.9339  \n",
      "\n",
      "Epoch: 298  Training loss = 1.7912  Test loss = 2.9339  \n",
      "\n",
      "Epoch: 299  Training loss = 1.7912  Test loss = 2.9338  \n",
      "\n",
      "Epoch: 300  Training loss = 1.7912  Test loss = 2.9338  \n",
      "\n",
      "Epoch: 301  Training loss = 1.7912  Test loss = 2.9338  \n",
      "\n",
      "Epoch: 302  Training loss = 1.7912  Test loss = 2.9337  \n",
      "\n",
      "Epoch: 303  Training loss = 1.7912  Test loss = 2.9337  \n",
      "\n",
      "Epoch: 304  Training loss = 1.7911  Test loss = 2.9337  \n",
      "\n",
      "Epoch: 305  Training loss = 1.7911  Test loss = 2.9336  \n",
      "\n",
      "Epoch: 306  Training loss = 1.7911  Test loss = 2.9336  \n",
      "\n",
      "Epoch: 307  Training loss = 1.7911  Test loss = 2.9336  \n",
      "\n",
      "Epoch: 308  Training loss = 1.7911  Test loss = 2.9335  \n",
      "\n",
      "Epoch: 309  Training loss = 1.7911  Test loss = 2.9335  \n",
      "\n",
      "Epoch: 310  Training loss = 1.7911  Test loss = 2.9335  \n",
      "\n",
      "Epoch: 311  Training loss = 1.7910  Test loss = 2.9334  \n",
      "\n",
      "Epoch: 312  Training loss = 1.7910  Test loss = 2.9334  \n",
      "\n",
      "Epoch: 313  Training loss = 1.7910  Test loss = 2.9334  \n",
      "\n",
      "Epoch: 314  Training loss = 1.7910  Test loss = 2.9333  \n",
      "\n",
      "Epoch: 315  Training loss = 1.7910  Test loss = 2.9333  \n",
      "\n",
      "Epoch: 316  Training loss = 1.7910  Test loss = 2.9333  \n",
      "\n",
      "Epoch: 317  Training loss = 1.7910  Test loss = 2.9332  \n",
      "\n",
      "Epoch: 318  Training loss = 1.7909  Test loss = 2.9332  \n",
      "\n",
      "Epoch: 319  Training loss = 1.7909  Test loss = 2.9332  \n",
      "\n",
      "Epoch: 320  Training loss = 1.7909  Test loss = 2.9331  \n",
      "\n",
      "Epoch: 321  Training loss = 1.7909  Test loss = 2.9331  \n",
      "\n",
      "Epoch: 322  Training loss = 1.7909  Test loss = 2.9331  \n",
      "\n",
      "Epoch: 323  Training loss = 1.7909  Test loss = 2.9330  \n",
      "\n",
      "Epoch: 324  Training loss = 1.7908  Test loss = 2.9330  \n",
      "\n",
      "Epoch: 325  Training loss = 1.7908  Test loss = 2.9330  \n",
      "\n",
      "Epoch: 326  Training loss = 1.7908  Test loss = 2.9329  \n",
      "\n",
      "Epoch: 327  Training loss = 1.7908  Test loss = 2.9329  \n",
      "\n",
      "Epoch: 328  Training loss = 1.7908  Test loss = 2.9329  \n",
      "\n",
      "Epoch: 329  Training loss = 1.7908  Test loss = 2.9328  \n",
      "\n",
      "Epoch: 330  Training loss = 1.7908  Test loss = 2.9328  \n",
      "\n",
      "Epoch: 331  Training loss = 1.7907  Test loss = 2.9328  \n",
      "\n",
      "Epoch: 332  Training loss = 1.7907  Test loss = 2.9327  \n",
      "\n",
      "Epoch: 333  Training loss = 1.7907  Test loss = 2.9327  \n",
      "\n",
      "Epoch: 334  Training loss = 1.7907  Test loss = 2.9327  \n",
      "\n",
      "Epoch: 335  Training loss = 1.7907  Test loss = 2.9326  \n",
      "\n",
      "Epoch: 336  Training loss = 1.7907  Test loss = 2.9326  \n",
      "\n",
      "Epoch: 337  Training loss = 1.7907  Test loss = 2.9326  \n",
      "\n",
      "Epoch: 338  Training loss = 1.7906  Test loss = 2.9325  \n",
      "\n",
      "Epoch: 339  Training loss = 1.7906  Test loss = 2.9325  \n",
      "\n",
      "Epoch: 340  Training loss = 1.7906  Test loss = 2.9325  \n",
      "\n",
      "Epoch: 341  Training loss = 1.7906  Test loss = 2.9324  \n",
      "\n",
      "Epoch: 342  Training loss = 1.7906  Test loss = 2.9324  \n",
      "\n",
      "Epoch: 343  Training loss = 1.7906  Test loss = 2.9324  \n",
      "\n",
      "Epoch: 344  Training loss = 1.7905  Test loss = 2.9323  \n",
      "\n",
      "Epoch: 345  Training loss = 1.7905  Test loss = 2.9323  \n",
      "\n",
      "Epoch: 346  Training loss = 1.7905  Test loss = 2.9323  \n",
      "\n",
      "Epoch: 347  Training loss = 1.7905  Test loss = 2.9323  \n",
      "\n",
      "Epoch: 348  Training loss = 1.7905  Test loss = 2.9322  \n",
      "\n",
      "Epoch: 349  Training loss = 1.7905  Test loss = 2.9322  \n",
      "\n",
      "Epoch: 350  Training loss = 1.7905  Test loss = 2.9322  \n",
      "\n",
      "Epoch: 351  Training loss = 1.7904  Test loss = 2.9321  \n",
      "\n",
      "Epoch: 352  Training loss = 1.7904  Test loss = 2.9321  \n",
      "\n",
      "Epoch: 353  Training loss = 1.7904  Test loss = 2.9321  \n",
      "\n",
      "Epoch: 354  Training loss = 1.7904  Test loss = 2.9320  \n",
      "\n",
      "Epoch: 355  Training loss = 1.7904  Test loss = 2.9320  \n",
      "\n",
      "Epoch: 356  Training loss = 1.7904  Test loss = 2.9320  \n",
      "\n",
      "Epoch: 357  Training loss = 1.7904  Test loss = 2.9319  \n",
      "\n",
      "Epoch: 358  Training loss = 1.7903  Test loss = 2.9319  \n",
      "\n",
      "Epoch: 359  Training loss = 1.7903  Test loss = 2.9319  \n",
      "\n",
      "Epoch: 360  Training loss = 1.7903  Test loss = 2.9318  \n",
      "\n",
      "Epoch: 361  Training loss = 1.7903  Test loss = 2.9318  \n",
      "\n",
      "Epoch: 362  Training loss = 1.7903  Test loss = 2.9318  \n",
      "\n",
      "Epoch: 363  Training loss = 1.7903  Test loss = 2.9317  \n",
      "\n",
      "Epoch: 364  Training loss = 1.7902  Test loss = 2.9317  \n",
      "\n",
      "Epoch: 365  Training loss = 1.7902  Test loss = 2.9317  \n",
      "\n",
      "Epoch: 366  Training loss = 1.7902  Test loss = 2.9316  \n",
      "\n",
      "Epoch: 367  Training loss = 1.7902  Test loss = 2.9316  \n",
      "\n",
      "Epoch: 368  Training loss = 1.7902  Test loss = 2.9316  \n",
      "\n",
      "Epoch: 369  Training loss = 1.7902  Test loss = 2.9315  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 4. Fixed scheme\n",
    "# ==================================\n",
    "print(\"\\nFixed scheme:\")\n",
    "for epoch in range(epoch_hat):\n",
    "    x_train = train_features[-window_length:]\n",
    "    y_train = train_target[-window_length:]\n",
    "    optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:test_features, y:test_target})\n",
    "    print(\"Epoch: {0:d}\".format(epoch+1),\n",
    "          \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "          \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "          \" \\n\")\n",
    "\n",
    "# Forecasts\n",
    "yhat_test_fixed = pred.eval(feed_dict={x:test_features})\n",
    "yhat_train_fixed = pred.eval(feed_dict={x:x_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nP1aO+HX78AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa7ba198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train set\n",
    "plt.plot(y_train, 'black')\n",
    "plt.plot(yhat_train_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xcc12b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: fixed scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_test_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed scheme RMSE: 2.93153064186 \n",
      "Fixed scheme MAE:  2.16134234687\n"
     ]
    }
   ],
   "source": [
    "rmse_fixed = np.sqrt(np.mean((yhat_test_fixed[:,0]-test_target)**2))\n",
    "mae_fixed = np.mean(np.abs((yhat_test_fixed[:,0]-test_target)))\n",
    "print(\"Fixed scheme RMSE:\", rmse_fixed,\n",
    "     \"\\nFixed scheme MAE: \", mae_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Stack training and test set, this makes updating scheme easier to train\n",
    "all_features = np.concatenate((train_features[-window_length:], test_features), axis=0)\n",
    "all_target = np.concatenate((train_target[-window_length:], test_target), axis=0)\n",
    "\n",
    "# Vectors to store loss and forecasts\n",
    "test_loss = np.zeros(len(test_target))\n",
    "yhat_update = np.zeros(len(test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test period = 1  Training loss = 1.7902  Test loss = 4.2136  Model updated 0 times  \n",
      "\n",
      "Test period = 2  Training loss = 1.8605  Test loss = 3.1101  Model updated 0 times  \n",
      "\n",
      "Test period = 3  Training loss = 1.8899  Test loss = 2.1067  Model updated 0 times  \n",
      "\n",
      "Test period = 4  Training loss = 1.8950  Test loss = 0.5588  Model updated 0 times  \n",
      "\n",
      "Test period = 5  Training loss = 1.7754  Test loss = 0.9834  Model updated 1 times  \n",
      "\n",
      "Test period = 6  Training loss = 1.7000  Test loss = 0.6318  Model updated 1 times  \n",
      "\n",
      "Test period = 7  Training loss = 1.6109  Test loss = 0.0322  Model updated 1 times  \n",
      "\n",
      "Test period = 8  Training loss = 1.6101  Test loss = 1.2206  Model updated 1 times  \n",
      "\n",
      "Test period = 9  Training loss = 1.5703  Test loss = 1.8364  Model updated 2 times  \n",
      "\n",
      "Test period = 10  Training loss = 1.5804  Test loss = 0.3030  Model updated 2 times  \n",
      "\n",
      "Test period = 11  Training loss = 1.5797  Test loss = 0.9082  Model updated 2 times  \n",
      "\n",
      "Test period = 12  Training loss = 1.5728  Test loss = 0.5773  Model updated 2 times  \n",
      "\n",
      "Test period = 13  Training loss = 1.5420  Test loss = 0.4044  Model updated 3 times  \n",
      "\n",
      "Test period = 14  Training loss = 1.5418  Test loss = 1.3118  Model updated 3 times  \n",
      "\n",
      "Test period = 15  Training loss = 1.5435  Test loss = 3.1677  Model updated 3 times  \n",
      "\n",
      "Test period = 16  Training loss = 1.5900  Test loss = 4.7906  Model updated 3 times  \n",
      "\n",
      "Test period = 17  Training loss = 1.6608  Test loss = 2.7780  Model updated 4 times  \n",
      "\n",
      "Test period = 18  Training loss = 1.6927  Test loss = 0.7446  Model updated 4 times  \n",
      "\n",
      "Test period = 19  Training loss = 1.6769  Test loss = 0.8115  Model updated 4 times  \n",
      "\n",
      "Test period = 20  Training loss = 1.5568  Test loss = 0.5827  Model updated 4 times  \n",
      "\n",
      "Test period = 21  Training loss = 1.5195  Test loss = 1.5989  Model updated 5 times  \n",
      "\n",
      "Test period = 22  Training loss = 1.5111  Test loss = 3.5607  Model updated 5 times  \n",
      "\n",
      "Test period = 23  Training loss = 1.5743  Test loss = 0.0640  Model updated 5 times  \n",
      "\n",
      "Test period = 24  Training loss = 1.5733  Test loss = 2.4840  Model updated 5 times  \n",
      "\n",
      "Test period = 25  Training loss = 1.5817  Test loss = 0.4447  Model updated 6 times  \n",
      "\n",
      "Test period = 26  Training loss = 1.5799  Test loss = 0.8253  Model updated 6 times  \n",
      "\n",
      "Test period = 27  Training loss = 1.5832  Test loss = 1.2140  Model updated 6 times  \n",
      "\n",
      "Test period = 28  Training loss = 1.5893  Test loss = 1.1218  Model updated 6 times  \n",
      "\n",
      "Test period = 29  Training loss = 1.5676  Test loss = 1.0025  Model updated 7 times  \n",
      "\n",
      "Test period = 30  Training loss = 1.5673  Test loss = 0.8188  Model updated 7 times  \n",
      "\n",
      "Test period = 31  Training loss = 1.5670  Test loss = 2.9028  Model updated 7 times  \n",
      "\n",
      "Test period = 32  Training loss = 1.5616  Test loss = 0.5326  Model updated 7 times  \n",
      "\n",
      "Test period = 33  Training loss = 1.5430  Test loss = 1.2660  Model updated 8 times  \n",
      "\n",
      "Test period = 34  Training loss = 1.5412  Test loss = 0.4984  Model updated 8 times  \n",
      "\n",
      "Test period = 35  Training loss = 1.4852  Test loss = 0.5037  Model updated 8 times  \n",
      "\n",
      "Test period = 36  Training loss = 1.4819  Test loss = 4.9753  Model updated 8 times  \n",
      "\n",
      "Test period = 37  Training loss = 1.5077  Test loss = 0.6981  Model updated 9 times  \n",
      "\n",
      "Test period = 38  Training loss = 1.4352  Test loss = 1.4794  Model updated 9 times  \n",
      "\n",
      "Test period = 39  Training loss = 1.4462  Test loss = 0.5206  Model updated 9 times  \n",
      "\n",
      "Test period = 40  Training loss = 1.4458  Test loss = 1.2962  Model updated 9 times  \n",
      "\n",
      "Test period = 41  Training loss = 1.4278  Test loss = 1.0328  Model updated 10 times  \n",
      "\n",
      "Test period = 42  Training loss = 1.4335  Test loss = 1.7019  Model updated 10 times  \n",
      "\n",
      "Test period = 43  Training loss = 1.4490  Test loss = 3.5150  Model updated 10 times  \n",
      "\n",
      "Test period = 44  Training loss = 1.5129  Test loss = 11.9786  Model updated 10 times  \n",
      "\n",
      "Test period = 45  Training loss = 2.1100  Test loss = 5.7252  Model updated 11 times  \n",
      "\n",
      "Test period = 46  Training loss = 2.2255  Test loss = 0.6225  Model updated 11 times  \n",
      "\n",
      "Test period = 47  Training loss = 2.2268  Test loss = 0.5829  Model updated 11 times  \n",
      "\n",
      "Test period = 48  Training loss = 2.2236  Test loss = 0.0428  Model updated 11 times  \n",
      "\n",
      "Test period = 49  Training loss = 2.1151  Test loss = 1.1742  Model updated 12 times  \n",
      "\n",
      "Test period = 50  Training loss = 2.1174  Test loss = 2.1414  Model updated 12 times  \n",
      "\n",
      "Test period = 51  Training loss = 2.1312  Test loss = 0.7737  Model updated 12 times  \n",
      "\n",
      "Test period = 52  Training loss = 2.1275  Test loss = 1.4552  Model updated 12 times  \n",
      "\n",
      "Test period = 53  Training loss = 2.1179  Test loss = 1.8130  Model updated 13 times  \n",
      "\n",
      "Test period = 54  Training loss = 2.1285  Test loss = 1.8213  Model updated 13 times  \n",
      "\n",
      "Test period = 55  Training loss = 2.1405  Test loss = 1.0764  Model updated 13 times  \n",
      "\n",
      "Test period = 56  Training loss = 2.1379  Test loss = 2.2217  Model updated 13 times  \n",
      "\n",
      "Test period = 57  Training loss = 2.1452  Test loss = 1.5293  Model updated 14 times  \n",
      "\n",
      "Test period = 58  Training loss = 2.1533  Test loss = 1.9179  Model updated 14 times  \n",
      "\n",
      "Test period = 59  Training loss = 2.1621  Test loss = 0.4205  Model updated 14 times  \n",
      "\n",
      "Test period = 60  Training loss = 2.1626  Test loss = 0.1003  Model updated 14 times  \n",
      "\n",
      "Test period = 61  Training loss = 2.1402  Test loss = 0.3688  Model updated 15 times  \n",
      "\n",
      "Test period = 62  Training loss = 2.1388  Test loss = 2.5652  Model updated 15 times  \n",
      "\n",
      "Test period = 63  Training loss = 2.1623  Test loss = 0.3529  Model updated 15 times  \n",
      "\n",
      "Test period = 64  Training loss = 2.1577  Test loss = 0.6409  Model updated 15 times  \n",
      "\n",
      "Test period = 65  Training loss = 2.1469  Test loss = 0.1922  Model updated 16 times  \n",
      "\n",
      "Test period = 66  Training loss = 2.1471  Test loss = 1.6929  Model updated 16 times  \n",
      "\n",
      "Test period = 67  Training loss = 2.1506  Test loss = 0.9503  Model updated 16 times  \n",
      "\n",
      "Test period = 68  Training loss = 2.1501  Test loss = 3.1757  Model updated 16 times  \n",
      "\n",
      "Test period = 69  Training loss = 2.1762  Test loss = 4.7970  Model updated 17 times  \n",
      "\n",
      "Test period = 70  Training loss = 2.2550  Test loss = 0.2140  Model updated 17 times  \n",
      "\n",
      "Test period = 71  Training loss = 2.2512  Test loss = 0.8602  Model updated 17 times  \n",
      "\n",
      "Test period = 72  Training loss = 2.2536  Test loss = 2.5723  Model updated 17 times  \n",
      "\n",
      "Test period = 73  Training loss = 2.2631  Test loss = 2.0974  Model updated 18 times  \n",
      "\n",
      "Test period = 74  Training loss = 2.2740  Test loss = 0.4990  Model updated 18 times  \n",
      "\n",
      "Test period = 75  Training loss = 2.2630  Test loss = 0.0699  Model updated 18 times  \n",
      "\n",
      "Test period = 76  Training loss = 2.2595  Test loss = 1.3068  Model updated 18 times  \n",
      "\n",
      "Test period = 77  Training loss = 2.2399  Test loss = 0.9773  Model updated 19 times  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "retrain_count = 0\n",
    "for t in range(len(test_target)):\n",
    "    x_test = np.reshape(test_features[t], newshape=(1,4,3))\n",
    "    y_test = test_target[t]\n",
    "    test_loss[t] = np.sqrt(sess.run(loss, feed_dict={x:x_test, y:y_test}))\n",
    "    yhat_update[t] = pred.eval(feed_dict={x:x_test})\n",
    "\n",
    "    x_train = all_features[t:(window_length+t)]\n",
    "    y_train = all_target[t:(window_length+t)]\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:x_test, y:y_test})\n",
    "    \n",
    "    print(\"Test period = {0:d}\".format(t+1),\n",
    "      \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "      \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "      \" Model updated {0:d} times\".format(retrain_count),\n",
    "      \" \\n\")\n",
    "\n",
    "    if (t+1)%4==0:\n",
    "        retrain_count += 1\n",
    "        for epoch in range(epoch_hat):\n",
    "            for i in range(total_batch):\n",
    "                optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzsnXlclPX2xz9fYFgE2UTcFQTUAhVzwf3nkmZaVlpmVzPN\nvTKzMtPqdutm1+yabVaaqZWWplmmlqaldhU3xA133MAUxQ1kZ5jz++PLM8zAbDAzzMJ5v168dJ7n\nme+ceWbm85znfM85X0FEYBiGYdwHD0cbwDAMw9gWFnaGYRg3g4WdYRjGzWBhZxiGcTNY2BmGYdwM\nFnaGYRg3g4WdYRjGzWBhZxiGcTNY2BmGYdwML0e8aFhYGEVERDjipRmGYVyWAwcOXCeiuuaOc4iw\nR0REICkpyREvzTAM47IIIS5achyHYhiGYdwMFnaGYRg3g4WdYRjGzWBhZxiGcTNY2BmGYdwMFnaG\nYRg3g4WdYRjGzWBhZxgbkZWVha+//trRZjAMCzvD2IqPPvoIo0ePxqVLlxxtClPDsYmwCyGChRBr\nhBAnhRAnhBBdbDEuU7M4cuQIJk2ahJKSEkebUiU2bNgAAMjPz3ewJUxNx1Ye+0cANhFRKwBtAZyw\n0bhMDWLdunVYuHAhLl60qGraqbhy5Qr2798PACguLnawNUxNx2phF0IEAegJ4CsAIKIiIrpt7bhM\nzePq1asAgAsXLjjWkCqwceNG7f9Z2BlHYwuPPRJAJoClQoiDQojFQgh/G4zL1DCuXbsGADh//ryD\nLak8ShgGYGFnHI8thN0LwD0APieidgByAbxa/iAhxAQhRJIQIikzM9MGL8u4G67qsRcUFGDLli2I\niooCwMLOOB5bCPslAJeIaG/p4zWQQq8HES0iog5E1KFuXbPthJkaiCLsruaxb9u2DXl5eRgyZAgA\nFnbG8Vgt7ESUASBdCNGydFNfAMetHZepebiqx75+/Xr4+/ujf//+AICioiIHW8TUdGy10MYUACuE\nEN4AzgEYY6NxmRpCUVERbt+Wc+6u5LETETZs2IB+/fohICAAAHvsjOOxSbojER0qDbO0IaKHieiW\nLcZlag7KxGnjxo1x+fJlFBQUONgiyzhy5AjS09Px4IMPQqVSAWBhZxwPV54yToEShklISAAApKWl\nOdIci1GyYQYOHMjCzjgNLOyMU6B47Iqwu0o4Zv369ejUqRPq168Pb29vACzsjONhYWecgvIeuytM\noF69ehX79u3DAw88AABaj50nTxlHw8LOOAWKsMfHx0OlUrmEx75+/XoQUQVhZ4+dcTQs7IxTcO3a\nNdSqVQuBgYFo1qyZS3js3333HaKjoxEfHw+AhZ1xHljYGafg6tWrqFevHgAgIiLC6T32S5cuYfv2\n7Rg5ciSEEABY2BnnwbWE/auvgFGjHG0FYwd0hT0yMtLphf37778HEWHEiBHabTx5yjgLriXsN28C\n334L7NrlaEsYG3Pt2jWEh4cDkMKemZmJ3Nxch9p0/vx5TJ8+HYWFhRX2rVixAgkJCYiOjtZu48lT\nxllwLWF/5hkgPBx4801HW8LYmPKhGMDxmTFr1qzBf//7X3zwwQd621NSUnD48GE9bx3gUAzjPLiW\nsPv7AzNmAH/8Afz1l6OtYWxESUkJMjMz9UIxgOOFXQkHvfPOO3rL3a1YsQKenp54/PHH9Y739PQE\nwMLOOB7XEnYAmDQJqFePvXY34saNG9BoNNpQjOKxOzrOfuHCBTRu3BgajQYvv/wyAECj0eC7775D\n//79tfYqCCGgUqlY2BmH43rCXqsWMHMmsH27/GNcHqXqVPHY69WrB19fX7sLe0ZGBhYsWAAiMrj/\n/Pnz6NSpE1599VWsWrUK27dvx86dO5GWllYhDKPgSsJ+69YtfPXVV9BoNI42hbExrifsADBhAtCg\ngfTajfwoGddBKU5ShF0IgYiICLuHYl5//XU899xzSE1NrbCPiHDhwgVERETglVdeQUREBKZMmYKv\nv/4a/v7+ePjhhw2O6e3t7RLCfufOHdx3330YN26cdq1Wxn1wTWH38wNmzZJx9j//dLQ19iM5GVix\nwtFW2B1F2HVDG/ZOeczMzMTy5csBAGfOnDFoU0FBASIjI+Hn54cPPvgAKSkpWLJkCR5++GH4+xte\n/VGlUjl9Vkx+fj4efPBBraCfPHnSwRYxtsY1hR0Axo0DGjeWk6nZ2Y62xrZkZQFTpgAdOwIjRwLf\nf+9oi+xK+VAMALt77AsXLtSmMZ4+fbrCfuW1lXj/ww8/jH79+gEARo4caXRcZw/FFBUV4bHHHsNf\nf/2Fr7/+Gl5eXjh16pSjzWJsjOsKu68v8OGHwKFDQLduwMWLjrbIeoiAVauAVq2ABQtkemeXLnLC\n2AVK7Mvz119/YfDgwVCr1SaPu3r1Kry8vBASEqLdFhkZiVu3biErK8vmdhUVFWHBggXo378/goKC\nDHrsyt2CkqEjhMDixYvx9ttvawXeEM4s7CUlJRg1ahQ2btyIzz//HKNGjUJUVBQLuxviusIOAEOH\nAr/9BqSnA506AXv2ONqiqkEkUzh79ACGDwcaNQL27QM++aQsFDNyJGBGIJ2NNWvWYP369WZ7q1+9\nehXh4eHa0nzAvrnsP/zwAzIyMjBt2jS0aNHCoLArr9usWTPttqZNm+KNN97QpjUawpmFfdWqVVi1\nahXmzJmDiRMnAgBatmzJoRg3xGbCLoTwFEIcFEJssNWYFtGvH7B7NxAQAPTqBaxZU60vbzU7dki7\n771XeuVffAHs3Qt06CD3R0YCn30mq23ffdeql7p58ya2bdtmtcmWkpKSAgA4d+6cyeOuXbumF4YB\nyjxlW8fZiQjz589Hq1at0L9/f8TExBgNxYSFhWmXu7MUZ548XbduHerXr4/p06drt7Vs2RKpqako\nKSlxoGWMrbGlxz4VwAkbjmc5d90lxbBNG+DppwFXSd/64AMp6mfOSO88NRWYOBEo7xGOGCH/3n5b\nXsSqyLx589C/f3+DJfL2QBF2c+KsW3WqYC9h37VrF5KTkzF16lR4eHigRYsWSEtLq7AU3/nz57U2\nVAZnnTwtLi7Gpk2bMGjQIHh4lP3sW7VqhaKiIocXgzG2xSbCLoRoDGAQgMW2GK9KhIVJUbxzBzDj\nIVaV27dva8XKavLzgf/8B+jbFzh7FnjuOTlvYIwFC4AmTYAhQ4CPP5bvs5IcPnwYarVau2i0WYqK\nAFPx1+JiOdFrgGvXriEzMxOAeY/dkLCHhoYiICDA5oLz0UcfISQkBE8++SQAICYmBkRUwUYl1bGy\nOGsoZufOncjOztb2jldo2bIlABiOs69fL50lTod0OWzlsX8I4BUAjnWV27SR/x49apfhZ86ciY4d\nO+LWLRus1b1sGXD9OvDGGzJ90xxBQcDPPwPNmwNTp8qMoBdfrNSkqnJRsljY339fTuR26QKsXl0W\n48/MlGGhyEigTh15J1Eu/q97ATQl7ESk1wBMQQhh85THixcvYu3atZgwYYI2XTEmJgaAfmaMRqPB\nxYsXq+yxO6Owb9iwAd7e3rj33nv1thsV9r17gccfl7+lQYPk3STjMlgt7EKIBwBcI6IDZo6bIIRI\nEkIkKZ6czYmNBYQAjhyx+dBEhHXr1qGgoACrV6+u0hinTp3CsmXLgJISYN48OeHbs6flA7RtK2Pt\ne/cCDzwgwzft2wM5OWafeufOHVwszRyyWNh/+gmIiJBCPmwY0KIF8MQT8s7htdeAu++WdxBvvikn\nfnV+/Iqwt23b1qSwZ2dno7CwsILHDtg+5XHjxo3QaDQYN26cdpsi7LoTqFeuXEFRUZFbeewbNmxA\n7969K8wZhIWFITQ0VH8CNTVVfr8aNJC1IiUlwIABQGlaKuP82MJj7wZgsBDiAoCVAPoIIZaXP4iI\nFhFRByLqULduXRu8rAFq1QKio+0i7AcPHsSVK1fg4eGBb7/9tkpj/POf/8SYMWNwY/FiGX6ZPl1e\niCpLp04yW+a332Qr499+M/uU48ePa/9vkbBfuQIcOACMHy/DMWvXAg0bAhs3ynmMY8eA338HfvhB\n5tmfPAnEx8s7EUhhDwsLQ+fOnU163eWrTnVRPHZjJf+63L59G6+88gr69+9vNMatvO8mTZpotwUH\nB6Nu3bp6wl4+1bEyOOPk6enTp3H69OkKYRiFli1blnnsmZlSxImATZvkBXvDBuDyZem5W+BEMI7H\namEnoplE1JiIIgAMB/AnERmv4LA3bdrYJRSzYcMGCCEwdepU7Ny506BY5eXlGSxPB4DCwkL8VirA\nJXPmAFFRwCOPWGdU796yjfGPP5o9VDc0YlEoadMm+e+gQXIy95FHgJ07ZTHYZ59Jb11h+HB5Me3U\nCRgzBti9GykpKYiNjUVUVBRu3LhhNB/dUNWpQmRkJHJycrQFTIYoLi7Gxx9/jKioKLz//vvYsmUL\nMjIyDB6bnZ0Nb29v+Pj46G0vnxlTvjipMjjj5OnGjRsBAIMGDTK4v1WrVlLY8/OBBx8E/v5bxtdL\n72bQpYusr0hOBh59VHrwjFPj2nnshmjdWt5KWrJIw86dwDvvWDTshg0b0LlzZ7zwwgsAoC1H12X0\n6NFo27atQY94x44duHPnDnoJgfALF4CXX66Y/VJZFMHduFH+KE2gK+wWeewbN8p8emXewhxNmgC/\n/AI0aAB68UWkHD2KuLg4NG/eHIDx7BZDVacKrVu3BgAcNXKhTk1NRWxsLKZOnYp27drhjTfeACAF\n3BDZ2dkIDAyssL18Lrtia0RWlgw9VSIc5IyhmA0bNiA2NtboHUjLli2RkZGB/M8+k2G+FSukmOvy\n4INy0n7zZovuEBnHYlNhJ6LtRGT4fq+6aNNG3kbqhB6MMneunLw009s9IyMD+/fvxwMPPICmTZui\nV69e+Oabb/RCBDt27MDq1auRl5eHH374ocIY69atQ61atfBho0bIBFA4fHhl35lhhg6Vt8e//27y\nMMWDBiwQ9uJiOd7AgZULFQUEALNnQ+zZg/tzchAXF6cVE4Nx9pIS5JZ+ToaEvU3pReXw4cMGX27J\nkiU4f/48NmzYgC1btqB79+4AjAt7VlaWQWGPiYnB5cuXkVMaZrhw4QLq16sH31deAVaulK0ddu7U\nf1J+PvD660BCggyHleJswp6VlYW//vrLaBgGKJtALV6+HIiLk/Mmhhg/HggOlhPpjFPjfh674mGa\ni7OXlJQJ+ttvmzz0119/BQDtj+PJJ59Eamoq9u7dWzpUCaZOnYqmTZuiZcuW+Prrr8uefP066MwZ\nnF+zBv+Ki0PbS5fwMYAd+/ZV+q0ZpFcvICTEbDgmJSUFHTt2hI+Pj/lQzM6dMp1y4MDK2zNqFLKa\nN8d7AFrHxJj22KdPx8h//hMzAYTVqVNhd926ddGgQQMcMfJZJicnIzY2FoMGDYIQQivaxsI+2dnZ\nCAoKqrBdmUBVwmjnz5/Ho3XqyO/HtGny/PbtCyif6+bNUgBnz5YVwjp3b9YIe1FREfbs2WPRnIKl\nbN68GWq12qywNwIQeOiQDKsZw9sbeOghYN06oJpqIUzy99/yjvX6dUdb4nS4n7BHRsqVlswJ+8GD\nMge7SxdZzm9iHdUNGzagSZMm2tDAo48+Cl9fX+0k6pIlS3D48GHMnTsXY8eORWJioozZvv8+ULcu\nRIsW+PXaNUzftw8UEIAlPj7auKfVqFTAww/LMIiR2O6NGzeQkZGBuLg4BAcHm/fYf/1VjlsuNS41\nNRVvvPGGUY8YAODpiU333osIAO3+9z8EBwcjJCSkosd+5Ajw0UfI8vfHuwC8xowByhUJATKrxpDH\nTkQ4cOAA7rnnHu02RdirEooByjJjLpw/j+euXZOhqHffleGJHj2A0aOBzp3l5KKXl/zedOwIfPml\ntn20NZOn3377Lbp06YJ58+ZV6fmG2LBhA0JDQ9G5c2ejx0RFReEJ5c6s3KpQFRg2TP5utm61mY1V\nZsUKmQKszAcxZRBRtf+1b9+e7EpCAlHv3qaPee89IoDo7FmiunWJ+vc3eFh+fj75+/vT5MmT9bY/\n/vjjFBoaSteuXaO6detS9+7dSaPR0OXLl8nDw4PefvlloqAgol69aM3DD9NDQtCtn38mSkujgQMH\nUlRUFGk0Gtu83w0b5Hv59VeDu3fs2EEAaNOmTdSyZUsaNmyY6fHuuovo3nsrbH755ZcJAN111110\n+vRpo08fNWoUbfb1Japdm+jqVWrfvj0NGDCg7ACNhqh7d6I6dejJgQPpw/BwaX+nTkSXL+uNNWPG\nDFJ5eVHRrl1EzzwjP6fduyktLY0A0Keffqo99u/jx+lRgP4aMUJ+vjNnEr32GtFffxGp1RQfH08P\nPvhgBXtzcnIIAM2ePZuKi4vpPg8Pac9nn5UdVFQkX9/Xl+hf/yIqKJDbFy6Ux+7dS0REY8eOpUaN\nGpk+v0Z48sknCQABoO+//75KY+iiVqupTp06NGLECLPHHvHxoTMhIeYHLSwkCg4mGjXKavus5v/+\nT577qVMdbUm1ASCJLNBY9xT2ceOI6tSRAmKMAQOkgBERzZ0rT8Xu3RUO27RpEwGgjRs36m3fuHEj\nAaB77rmHhBB04MAB7b7777+f/h0UJMfcv5/atm1LPXr00O5fsGABAaCTJ09a9z4VCgqIAgOJxo41\nuFt5vfT0dOrcuTP1N3IRIyKic+ek3fPnV9g1cOBAql+/PtWpU4eCg4Np06ZNBoe45557aGz37kRe\nXkQTJ9Kjjz5KLVq0KDvgm2/kayxeTF27dqXevXsTrV1L5O8vL4Y9e8r38t57dPDxx+mo9IelqIaH\nE3l40KlHHiEfgBITE+X7nzePNCEh8jjlz9NT/gFE4eH0fe3aNLdXL6I7dyrY3LBhQ3rqqafowvnz\nlAhQdmhomXjrUlSk/zgri6hWLaLx44mIaNKkSVS3bl3j59cEkZGRNHDgQOrZsyd5e3vTtm3bqjSO\nQmJiomUXiTNniACaW7++ZQM/9ZT8nAydn+ri9u2yz7ZrV8fZUUms/c3XbGH/+GP51sp5f1qKiqSI\nPPOMfHznjrwQDBxY4dDnnnuO/Pz8KC8vT297cXExhYeHEwAaW05Qf/j2W7oE0I127ejChQsEgN5/\n/33tfmXbvHnzrHqbGRkZtHnzZvlgxAj5HoqLKxw3efJkCgoKIo1GQwMGDKCOHTsaH/TTT+W5M+CR\nR0ZG0vDhw+ncuXPUpk0b8vDwqPAe1Go1+fr60ksvvUQ0ZQoRQInx8RSqUlFJSQnRrVtSnBMSiEpK\nKDo6moYPHy6ffPgw0ZgxRN26yWNKBXoXQLvHjJE/5qwsKaIAHQeo8D//IWrWjAggTf/+1AOguVOn\nys9Uo5HHr1xJNGwY3RFCjunlJV/jjTeIduwgUqupV69e1LVrVzpSeid3rDJe4JgxRAEBRHfu0JQp\nUyg4OLhsn4V3ZZcvX9Z+J27evEl333031QsMpFQrPPdPPvmEANDff/9t+sB33iECKMrbm9RqtfmB\nlTvEDRuqbJvVrF4tbejQgcjPz+D33pnIzc2ladOmkRCC1q1bV+Vxarawb98u35oRj5ISE+X+1avL\ntr37rty2b592k0ajoYiICIO370REr7zyCgUHB1NGRobe9qLS2/M5ffrQxx9/TAAqhC5iY2OpT58+\nVXt/Oq+v/eGuXSvt37q1wnE9evSgbt26ERHR8OHDKSYmxvigAwcSRUdX2Jybm0tCCHrrrbeISIYv\nhgwZQgBoz5492uNOnz5NAGjp0qVE+flEL71EGiHoPEDXvv+e6PnniYQgKr3DqV27Nk01JqK3b1Px\nhQvk7e1NL7/8st6u1zt1ossqlXzP99xDtGULEREFBQXR888/b3C42ioVLR42jGjGDKKOHYmUkEuD\nBrQlLo76BwdTZkQEnQPozLFjxs9ReXbt0t6BvPjii+Tv7y+3f/KJvNh+9BGRGcFcvXq13rlMP3yY\n9pe+v1yd81sZnn/+eQoICDAf8ouLoyvR0QSAzp07Z37gwkLpsT/1VJXssgljxsiQ0LJl8twfPuw4\nW8ywfft2ioqKIgA0efJkys7OrvJYNVvYb9yQb03HS9Zj9mwigNIPHqQFCxbQihUraMvatVQcFEQ5\nffvS7du3SaPRUEpKCgGghQsXGhymqKiIbty4ob+xpISoVSu6WKcO+fn6UkJCAt2lhHx0eOWVV8jL\ny4uysrKq/DYHDhxYZl9urgwJlJsL0Gg0FBISQhMnTiQi06GCnGvXqMTHx2DMMjk5mQDQap2LYXZ2\nNoWFhdF9992n3bZ27VoCQPv379du2zt/Pp1UwiNCaG3My8vTxrZN0a5duwrho/r169P4xx8n2rZN\nnvNSmjRpQqNHj64wRkFBQcXXun2baNUqoocfpmLlth6gpwEqqEyYQaORYb3OnWnGjBnk7e1dFm5q\n2JC04YLjx40O8cILL5Cvry8VFhYSpaUR3XUXlXh5EQF0/oUXLLdFh/vvv5/i4+NNH3T0KBFAZ154\ngQDQb7/9ZtngjgzHlJQQ1a9P9PjjRKdOaS+qzoZarabnnnuOAFDz5s3pzz//tHrMmi3sRESNGhE9\n+aThfffeS9S6NY0dO1Y7WQWAZgOkBigQIE9PTwoICCAAdOnSJctf9+efiQA6/dZb2nFnzJhR4TBl\nQnPNmjVVfINEERERBIAGDRokNzz2GFG9enpC9/fffxMA+uSTT4iIaObMmeTl5aXvxV2/TrRzJyX2\n7UsE0J0ff6zwWitWrCAAlJKSord97ty5BIB27txJRERvv/02CSEoJydHe8yZM2fIF6CjAwZIT7n0\nYqiEpBab+VGOHj2a6tWrp32shC0+/PDDCsfGxcXRI488UmH7tWvX9M5DeTYsX06jAfoiLIwiqjL5\nOW8eEUCfTJxIDwKk8fQk6ttX3rV8+y1RaCiRt7cMexgQww4dOtD//d//SfFv3JgoMJDOLVlC5wBK\nMxU6M0F0dLT5ifLXXyfy8KBrR48aPacGcWQ45sAB+dpffy2/60FBRKWOizOxYcMGAkCTJk3S+z1Y\ng6XC7n7pjgqtWxtOeSwslHnaffrgwIED6N27N06ePIldu3ah17//DU8AS8aOxYwZMzBixAjMmTMH\njRo1Mvwa16/L0mulhJ0IeO89IDIS0TNnatPoHnrooQpP7dq1K4KDg6uc9piXl4eLFy/Cx8cHf/zx\nB3Jzc2XjpqtX9VoqKBWncXFxAGRvFLVajby8PGDxYtmSICwM6N4dXf74A2kA9hnoNnn8+HF4enpq\nc74VnnnmGYSHh+Of//yn9vWaN2+ut9hz06ZNUeThgR86dpR536GhAEz3idGlbdu2uHr1qvb4Awdk\nvzndVEeFwMBAg+mOyjZD6Y4AENmuHZYBmHT9OhpXoUcMRo0CVCoM3LIFqwDZN+enn2Qr5pEjZcHc\nQw/Joqa775b7SKZI5ubm4nxyMl729ga6d5edMv/6C+HDhuEvAHWOHdMeaynFxcU4f/58hc9LDyJZ\ngNWnD8JiYxEcHGz5akr9+smOo44oViqtK8GAAYCHh2yEZ4/WwidOyAVvDCzEYgnbt2+Hj48P5s+f\nb3Txc3vhvsLepo38YMrnFO/dCxQUoKhbN6SkpKBz585o2bIlunbtiq4vvgh4eWFoeDhmz56NL774\nAjNmzDD+Gs88AwweLLvgRUfLKtDdu4GXXoJQqTB9+nR07doVnTp1qvBULy8vDBgwAL/++qu8daok\np06dAhFhzJgxKCgowNatW2URDSDzq0s5duwYAGirToODgwEAhUuXAhMmyLa8H3wAbNyI5wcNQiSA\n/QYuiCdOnEB0dDS8vb31tvv7++PVV1/Fn3/+ie3btyMlJUV7EVHw9vZGkyZNKhQpmeoTo0v5CtTk\n5GQIIRAfH1/h2KCgIIPCrhQtGRP25s2ba5fmq0rzL4SFAY88gubnzuEigIKffgJq1y7bX6+ebJi2\naZMU+yFDZK+f1atx55FHkK7R4IEtW2QHzcREoG1b+Pv742Dt2qiVlye/y5Xg/PnzKCkpMS3sO3bI\n9hvDh0MIod8MzBze3rJ+4uefjdZP2I1ff5X1A8r3pmNH6cwYqIOoMkTAs8/KRnjvv1+lIbZv346E\nhAT4mlpnwU64t7AXFVW82m7bBgiBY3XqQK1W63t9tWrJK7SZFgMAZP+QH38EnnoK+O9/5R3C//4n\ne6aMGQMAGDduHHbt2mV0jcwePXrg6tWr+Pvvvyv99pRujRMnTkRQUBB++eUXWVDTsqWesKekpCA8\nPBxKR83g4GAMAhDywguyZfDmzbK6cuBAHMvPhwbAfgPez4kTJ3DXXXcZtGXSpElo0KABZs2ahdOn\nT1cQdkAKZ/kiJVN9YnRp27YtAGgrUA8cOIAWLVqgtq5wlhIYGGiw8tScx+7r66td37Qqzb8AALNm\nITU2Fv0BFBuocAUA3HcfcPiwbKSWkgIMG4bgv/7CEgDZO3ZIx0DnwnKptHLXou+kDkqxlVFhP3JE\nOiLNmsnGXkDlhB2QfXSyssoqcquD69fl2sa6VdEdO0oHzpZdXdeskVrRrBnw7bey62UlyMrKQnJy\nMnr16mU7myqB+wp7aZVohU6P27YB7dphX+kXv3379vr7e/aU4QIzTbXw0UfyNvCdd4CXXpK31teu\nAefPywuEBZjrhWKKEydOwNPTE3fffTfuv/9+rF+/Xq5b2aePFIHSO5XyHnTz9HSsBpATEyOrVXXC\nLorQlhf24uJinDlzxqiw+/n5YdasWdi9ezfUarVBYY+MjKwg7Fu3bkVgYCAaNGhg8r3WqVMHjRo1\n0vPYK3xupZgLxRhqKaCgiGCVPHYAaNsWv06YgHTAdPWplxcwebL0ln/7DcN79MDnsbEINNCbX9Wq\nFa56elZa2JVulUo4UI+TJ2VVsZ8f8OefMqQC2eXx8uXLuGPp6lz9+wPdugH//KfBdr4ajQa7rVjK\nsTzFxcXY/dZb0psuL+yA7cIxubnyNx0fL1sWFxYCCxdWaohdu3ZBo9GwsNucVq3kD0j3Kp6fLz2i\n3r2RnJyMkJCQit5Zjx5SFEv7wBgkK0vGpx9/XK5kpCBEpTo2Ki0KjPVCMcXx48e1oZHBgwcjMzMT\n+/btk+HVS1zwAAAgAElEQVSYnBxg/35oNBocO3asTGiPHEG7N9/EBQCJr78OlPNeMzMz4enpibS0\nNL1WuampqVCr1bhbt1VvOcaNG4fGpefCmMeekZEhY/sA0tLSsHr1aowfP75CeMcQSmuBa9eu4dKl\nSwbj64AU7qp47ECZsFfZYwe078WitgLBwSjp1w/b9u3TNjArT0RkJLZrNKAdOyoVZz9z5gyCg4NR\np3wPnrNn5XfEw0Pe2Sl3BCj7PiYmJlr2IkLIMEVGhlw4phzffPMNunbtarMF1FetWoWzn36KgsDA\nssXeAXmXXLcukJRkk9fBnDlAerpcyCYuTsbyFyyoVMhp+/bt8Pb2NtnKwZ64r7B7e0tx1/XYExPl\nh9O7t7bPiCjfvbBbN/mF/d//jI+9eLEUzxdftMrEoKAgREREVEnYdUMjAwYMgKenJ9avXy+bggkB\n/PEHLl68iNzc3DKhfestQKVCPwCZ5URCo9Hg+vXr6Nq1KwAgSedHcqI0vmvMYwdkKGPu3LmIj483\n6CUqzcCUXueffvopiAhTpkyx6P22adMGJ06cwJ49ewAYnjgFpHDn5+dXEFZLhF15f1FRURbZZAiV\nSgUAFvdkP3bsGLKzs9GtWzeD+yMjI7GdCOLy5Uqt5XvmzBnExMTof7+vXJF3dIWFstdLaVdHhX79\n+iE0NBRLly61+HXQpYsM5SgCr8P12bNxBcC+BQssG+vOHdl3p/TiX57Nv/6KAQB2BgTIC5OCENJr\nt4XHfvas7Po6YoScyAaAF16Q723VKouHUeLrfpYse2kH3FfYARln/+03OckSGiqzRjw9UZSQgKNH\njxoWh5AQ+Txjt75qtQzD9OoFGBGXypnYptKhmKKiIqSmpmo96JCQEPTs2VPG2evUkbeQf/6pnxGT\nkQH88gsKR4zA36i42MatW7dQUlKC++67D0IIvXCMEs9v1aqVSbueeOIJHDx40KAHrgj7uXPnkJOT\ng0WLFmHo0KHauLY52rZtC7VajRUrVgAA2rVrZ/A4JdRSPhxjibA//fTT2LRpE5o2bWqRTYZQhN3S\nRmC7SpvPmRJ27TexEuEYRdj1mDNHroT0++/SEy2Hj48PRowYgZ9++gk3btyw+LXwn/9Ih+nNN7Wb\nMl97DS+npqI+gEHr1kFjrhukRgM8+aSc0B80qMJ6ChqNBnXWr0cYgCVXrlScl+rYUU4w64aEDh2S\nbZXnzzcfWlWYNk06hXPnlm3r3x+46y45jgV3TdnZ2Thw4IDDwjCAuwv7tGnA2LFykmjECGDSJGDx\nYhxLT0dRUZHROC169JDevaEf548/yts0K711hTZt2uDUqVMoqMSMvhIa0fWgBw8ejGPHjuFs6a02\nJSbi83nzIISQF4BlywC1GqpJkwBU7MmurEPbvHlztGrVSk/YT5w4gWbNmlmVsqUr7MuWLUNWVham\nTZtm8fOVCdSff/4ZUVFR2uye8hjr8JidnQ0vLy+TGQq1atXCfffdZ7FNhqiKsNevX99oXD8yMhLH\nARQEBMgsFgsoKChAWlqa/p3TzZvAV18B//iHSYdk7NixKCoqwnfffWfRawGQGWGTJ8s72ePHgf/8\nB3XffRc/AvjlH/9AnFqNNHO/l//8R7YDHjZMXsDuv79MpImQMXEiPszJwYWICPxEVHGhm44d5cUh\nOVk+zsmRodLDh+VvNToa+PxzvXCKWq3G0qVL5d0VkWzfvX69XKOhYcOysYWQXvvBgxX68t/U6cWv\n4Oj4OgA3LlAyweLFiw2W+Wv54QdZAFHasU+LRiMLbGJi9IqArOGHH34gAHpNxMyxZs0aAkBJSUna\nbampqQSA5s+fT7veeIMIoPtVKvriiy+krVFRsrkWEfn7+9OLL76oN6ZSMLVlyxYaNWoU1atXT1vE\n1K5dO/3ujFVAo9GQv78/TZkyhaKjoykhIaFSzy8uLiYfHx8CYLLo5scffyQAdOjQIb3tzz77LIWG\nhlbJ9sqgtAY4cuSIRcc3a9aMhg4danR/YWEhCSHoWKtWRJGRFo2pVEyvWLGibGNptbUlpfft27en\ntm3bVq77aGambETXqBERQD/VqkUD+/enrKws+lkIKvTyIkpNNfzc336TFckjRsjf2MqVssFXt25E\nV6/KClOAvgLo2qVL1L17d2rVqpW+fRkZ8v0pvYvGjJFjbtsmW4x07y73N2tGtHQpkVpNf/zxBwGg\nrz77jGjkSLl/1KiKjd6IZGV3aCjRkCHaTYcPHyYhhF41NpGsKlepVJSbm6s/hlpN9MUXsmitiqC6\nKk8BNAGwDcBxAMcATDX3HEcL++TJkykwMFA2pTLElStksCXB//4nt+u2c7WSU6dOlfVWsZB///vf\nBKBCNVtsbCwFBgaSP0BFAGWOGyd3bN0q7V6+nIiIGjVqRE8//bTec5WLxeHDh7XNo9LS0qikpIT8\n/Pxo2rRpVr1PIqLWrVtTSEgIAaBVq1ZV+vnt27cnADRnzhyjx2zdupUA0I4dO/S2P/nkkxQREVHp\n16ws69ats/hCfenSJe3F2BRNmjSh5R06yM8wLc3suD/99BMBoH1K36OCAlmRrNP6wRRKN1Bdx4GI\n6MaNG/Tpp58abxQ2Zw4RQH8PGEAeAK1cuZKIiJ7s3ZuyhSBNv34Vm6KdPUsUEkLUtq0UT4XVq2Wz\nNl9fIiHo02bNqGOHDkRE9OWXXxIA2lve8WrShGj4cKLvvpPn6vXXy/ZpNLJ3VPv2ct9dd9HOF1+k\nugAdql1bbps923TTtpkzZX+h0tYQy5YtIwDUpEkTvd9ip06dqHv37hWf/+WX8nWsqDa3VNhtEYpR\nA3iJiO4G0BnAs0II4+kTTkBycjLatWsHDw8jb79+fbmQr25Ms7AQeP55Ofv+1FM2syUqKgp+fn6V\nirMfP37cYGhk2LBhyMnJwdRZs+DZrRvClDG//FLOHQwdCkDG5MvH2JVQTN26ddGhNONg//79uHjx\nIvLz801mxFhK8+bNcevWLTRt2hRDjC2/ZgIlHGM0hAbToRhT8XVbUZlQjLIClzJhbYyIiAj8qSwg\nbUGcvUIO+4oVsiL55ZfNPhcA/vGPf8DX1xdfffWVdlt+fj4efPBBPPfcc/jzzz8NP/Hll4GdO/Fq\nnTqoHRSkrbjuNXIkXiWC2LJF2gLI1OCtW2WhFhGwdi3OXrmCjh07ynDio4/Kgq4mTZDzzTd4Pj0d\n9w0YAAB47LHH4Ofnh2XLlum/fseOMp150iQ5qasT84cQsoZg/36Zo06Ebh98gDQALe7cweX584FZ\ns0wvBfn88/J3NGwYkJurXXErPT0dc+bMAQDcuXPHcHw9K0uO37278aUHbYjVwk5EV4goufT/dwCc\nAGCkBt++fPnll+jevbuswjSCWq3G4cOHTYoDAJnPvnOnjNsBwIwZMsb21VcW56lbgqenJ+Li4iqV\nGXPixAmDQjtr1iykp6dj9uzZ8OjbV1bNpaYCa9fKkvfS+LKhVZSU9MawsDDEx8fDy8sL+/fvtygj\nxlKUOPuUKVPg5eVV6ef36NED/v7+Jj87ZfK0fMpjdQu7JVkxGaVZJObSKyMjI7H12jWZb26BsJ8+\nfRp169aV8xAajSygi48vq0w2Q3BwMIYOHYrvvvsO+fn5KCkpwciRI7F7924IIbCz/PqvCp6eyG7d\nGmvWrsUTTzyhnc8YPHgwvvTwQFqjRjIW36CBrMTt109OeH73HdC8OXbu3ImkpCTtouR45BHg9Gls\n8vWFRqPBgFJhDwoKwpAhQ/D999/rz0117CgvYELIMQ19x4SQDk5KCjYOG4YdAHoD+FQnvdco9evL\nFgzHjwPjxuFsaioiIiIwYsQIvP/++zh37hx27dqFkpKSisL+73/L4qoPP6zcOsJVxKaTp0KICADt\nAJhIArcPxcXF+Ne//oVdu3ahX79+eOihh7RXVF1OnDiBgoICo+lyWnr2BG7dAo4dk4U8H30ETJ0q\nV2u3MUpmDFkw415SUoKTJ08aFFovLy80VCZ9+vaVP+px4+Qk8Pjx2uMMCXtmZiZCQkKgUqng6+uL\n1q1bIykpSZsRYwth79mzJ2JiYjBu3LgqPX/UqFFIT09HSEiI0WOMeezGFrK2NZXx2JXPwFTRFCCF\nPf3yZZR07SonUG/ckNWX334rM10+/BBYtEh6w5s348KpU2Xe+m+/SfF8+eVKCcrTTz+NrKwsrF27\nFi+99BLWrl2LefPmIT4+3riwA/jhhx+Qn5+P0aNHa7eFhYWhR69eeNbHR/Z1ue8+mfe+davM0rn/\nfgCytgEAVq5ciaM6acqbNm1CUFAQEhIStNueeuop3L59W6b4KvTuLd/jl18C5moRPD2xKyoKD3h5\nIWzQIHzzzTeywM8c994rixJXrkSHXbsQHR2N9957D15eXnjxxRexfft2qFQqdOnSpew5p08DH38M\nPP20fP/VgSXxGkv+AAQAOABgiJH9EwAkAUhq2rRplWNMxlAmzVatWkXvvvsuBQQEkEqlojfffFNv\nkmXp0qUEgE6cOGF6QGUloRkz5KRJu3Z2a1Gq9Gy/bGxhEB3Onj1LAOjLL780fWBhoVyAACDq0kVv\n18iRIyvEm4cNG6a3ytGECRMoODiYxowZo9dZ0dnJzc01GIePjo6mJ554wu6vv2vXLgJgdHUpXaZP\nn05+fn5mj1NiuZnTp5PSWtjU3w0PD9p8111yorRXL9kt0tCEoAlKSkooMjKS6tSpQwC0PfOnTJlC\n/v7+VGRkvG7dutFdd91VYeL1008/JQB03ETr4nHjxlFwcDAFBgbSQw89RERy0r1Ro0b06KOP6h2r\nVqupcePGNLD84ji3b1v8HidPnkxhYWHa+SVLPrNSo2SrZ4D+W2rnnHffpWYA9Q8MpJ7lV3R64AG5\nTGS5dRuqAqqzbS8AFYDNAF605Hh7TJ727duXmjZtqp3YuXz5Mg0fPpwA0LJly7THKV9MsyvFaDTy\nBwHI1XFMrPFpLdu3bydY2AtbaQW6a9cu8wP37y/tLzcxW2GVHyLq3bu33oTPokWLCADVr1+fevXq\nZdH7cAY0Gg15eXnRzJkz9baHh4dre9Lbk3379hEAWr9+vdljx48fTw0aNDB7nJKxtG3VKqLp04k+\n+IBo/XqiEyeIcnKIbt4kSk8nOnmS8tasoZWAXn95+u9/q/Re3n77bQJAQ4YM0f5eVq1aRYB+v30F\nZZGV9957r8I+pX30O++8Y/T1+vXrR506ddK+7t69e+loaTthQ62dZ86cSZ6enhY5RIZQFp0pKCig\n0NBQevzxxy1+7s3z5+kkQHm1ahG1bk0aX1/t+b4ZFCRXccvJkRk/hhIxqoilwm51KEbI0ravAJwg\nog+sHa8qnDp1Cn/88QcmTpyobbjVoEEDLF++HL169cKzzz6r7Z1x4MABtGvXzmhjLi1CyHx2APji\nCzmZaicq01qgUqGRxx+XJeOPPaa3OTg4GFlZWdAo8weQMXalURgAdCztv5GRkWGTMEx1IYQw2C+m\numLslWkpcPv2baP5+LooOe6nbt2ShTPTpsliu1atAH9/OaHXuDHQsiVORUVhOICNixbJ2//Ro2XR\nTxWYNm0avvjiCyxfvlz7e1EKqQyFY1aVVmaOGDGiwr6GDRuiS5cuWLt2rdHXS0tLQ9OmTfHCCy8g\nLCwMr732GjZt2gQABusLxowZg5KSEixZsqTybw5l518pzPr5558rJBUYIzUzE48AyGneHGjWDOKZ\nZ5AyZQqeFAKeTZvKidZmzWQoNDpaPq5GbBFj7wbgSQB9hBCHSv8GmnuSLfniiy+gUqkwduxYve2e\nnp5Yvnw5fH19MXz4cOTl5eHQoUPm4+sKr78uiy4MfFFtSWhoKBo3bmyRsJ84cQL16tUzGWfW8vTT\nskS6XPZMcHAwiEiv2VNmZqaesMfGxmonv2yREVOdlO8XU1RUhIKCAqebPLVU2Bs2bAiVSlWh7bEh\nlIyYZvfcA0yZAixdqt8+uBIEBARg4sSJemXxjRo1QmRkpEFhX7NmDbp27Wp0/YIhQ4YgOTkZFy9e\nrLCPiLTCXrt2bcycORNbt27F/PnzERcXp+1DpEtMTAzuvfdeLFy40LL4eDl0z//o0aNRWFiIlStX\nWvTc1NRUnABw9fvvZVHTvHmI+/hjfHrrFgKPHJGJF127yorvjz6S1azViC2yYnYSkSCiNkQUX/r3\nqy2Ms4Tc3FwsXboUQ4cONdj+tVGjRli6dCkOHjyIxx57DHl5eeYzYhTuvltWrlYDbdu2tdhjt1Zo\nlYuC4p0ofWJ0+6KrVCptv3NX8tiBih0elQuYM06eWiLsnp6eaNq0qbbPjikUYY+OjjZ7bFXp3r07\ndu7cqTfZn5qaisOHD+PR0hbAhuhRegdsKLX3xo0byM/P17aYmDx5Mho2bIjLly9rs2EMMXnyZKSn\np1dpwRrd89+uXTu0adPG4j45Z8+eBVCW6aWgnQjv1k0mXeTm6neirCZcvqXAypUrkZWVhWeeecbo\nMQ8++CCef/55/Fq68orFHns1ojS5KjTRU4OITPZFtxTly6xkZdy8eRMajUbPYwfKwjGuLuyW9Imx\nFfYQdkCGYyzx2E+fPo2GDRsiICDAonGrQvfu3XH16lWtuAHAjz/+CAAYWlorYQglU0e5+OiiZMQo\nfXr8/Py0q3INGjTI6JiDBw9Gw4YN8fnnn1fyXeiffyEExowZg/3792vDnaZITU1Fw4YNUctc6rOP\nT6XtsgUuLexEhM8++wxxcXFG254qKJ0HAwICzDazcgRt2rSBWq02uTTZlStXkJ2dbbXHXl7YleKk\n8isZPffcc5g7d67ZfunORvlQTE0SdoPNv2yM8lvTDcesWbMGHTt2NNlALTQ0FKGhoQaFXQnP6D5/\nwoQJSEpKMtlzxcvLC+PHj8fmzZsr9Ps3x61bt/RCmspFafPmzWafm5qaate7ImtxaWHfv38/kpOT\nMXny5Irtd8vh4+ODzZs3488//6xScYy9URbdMBWOsVVOuSImSihGKU4q77G3aNEC06dPN3tunQ1H\neuyWTp4SUaWFPTMzEzkGFrTQpTqEvVWrVggNDdUK+8WLF5GUlGQyDKMQExNjsL6kvMcOSC/akrDp\n+PHj4eHhgYWVWAyjoKAAhYWFeue/SZMmiImJMV5Zq8PZs2dZ2O3F7NmzERAQgJEjR1p0fHh4uDa8\n4Gy0aNECPj4+JoXdVlWgipdizmN3VZzBYzc3ear0jDdXnKSgZMaYirPfvn0bmZmZdhd2Dw8PdOvW\nTSvsloRhFKKjo42GYvz8/CouDGIBjRo1wuDBg7FkyRKLu6Qq3/3yF9Y+ffpgx44dUKvVRp+bk5OD\njIwMq/r22xuXFfZ169bhl19+wRtvvFEtP1h74+XlhdjYWJM9Y44cOYLQ0FDUr1/fqtcyFoop77G7\nKq4QYzcmLMZQhN1UOEYRTIPL4dmY7t2749SpU8jMzMSaNWsQHx9vkdDFxMQgPT29ggCnpaWhWbNm\nVb47nDx5Mq5fv441a9ZYdLwpYVf6vRhDmVtgj93G5OTkYMqUKYiLi6tUT29nx9yiG8nJyYZXfaok\ngYGBEEJov9xKKKYq3pIzEhgYiKKiIu1EtOK9W+odW4O9hF3pJ2NK2JU7uuoQdiWfffXq1di9e7dF\nYRhACjsRVYiHX7x40aoFTvr27Yvo6GiLJ1GNnX8lnm8qHMPCbifeeustpKenY+HChdofkjvQrl07\n7Zqe5SkqKkJKSopNMno8PDwQGBiojbFnZmYiNDTUbc5l+UZg7uCxh4eHo1atWiaFfc+ePahduzZa\nllvyzh506NABPj4++Ne//gUAlRJ2oGJmjJLDXlU8PDwwadIkJCYmai9wplC+++XrQcLDw9G6dWuT\nwq7MEXAoxoYcPnwY8+fPx/jx4822O3U1lCZHew0spH38+HEUFRXZLFUzJCREz2N3lzAMULERWHZ2\nNjw8PMynptkAIQS8vLxsLuxCCERERJiMsScmJqJz587mq6ptgI+PDzp27IjMzEzExsZafDFRvFxd\nYS8oKMDVq1etEnYAGFiaL55kwaLWps5/nz59sHPnTqOpx6mpqQgLC6uWO8Cq4lLCrtFoMGnSJISG\nhmr7H7sT8fHx8Pb2xr59+yrsSy5d8svYWp+VRbfDY2ZmpttMnAKGPXYl/FQdqFQqs5OnlRV2wHTK\nY3Z2No4ePVqtzo6S9miptw5Ih6JOnTp6wq7coVq6/q0xoqOj4e3trV3r1xTmhL2goEC7cHp5nD0j\nBnAxYf/yyy+xZ88ezJs3D6GhoY42x+b4+PggPj7eoMd+8OBBBAQE2OwLFRwcrJfu6O4ee3VOsKtU\nKpt77ECZsOtWfCrs27cPGo2mWoX9gQcegJ+fH5544olKPa98yqOhHPaqoFKp0KpVK6uFvWfPnvDw\n8DAajnH2HHbAxYS9sLAQgwYNsji90RVJSEhAUlJShd4XZld9qiS6oZjyfWJcHUXEy3vs1UVlhL0y\nt/ORkZHIzs422KgqMTERQgi9nuX2plu3brhz506lY/oxMTF6HruhHPaqEhsbi2PHjpk97tatW/D1\n9TW4uHlwcDDat29vUNgLCwuRnp7u1PF1wMWE/fnnn8f69etdrmCmMnTq1Am5ubl6X86SkhIcOnTI\nZmEYoCwUU1JSghs3brhlKMbZPXZjwmIMpQuooQZciYmJiIuLq/a4b1Xi+dHR0UhPT0d+fj4AKexC\nCKPNwypDXFwcLl68qNfgzhDmisP69OmDPXv2IDc3V2+7csfEHruNcWdRBwxPoJ4+fRp5eXk27XGj\nCLuxPjGujKNDMd7e3hYJe2XCMIBMxQsJCcHq1av1tms0GuzevdtlkgmUzBgl5TEtLQ3169eHjw36\nqsTFxQGA2X4vlgi7Wq2ucBFVQkgs7EyliI6ORmhoqN4E6sGDBwHYtnlZcHAwcnJycPnyZQDuU3UK\nuE4oprLCrlKp8Mgjj+CXX37Ry9g4fvw4srOzXU7YlXCMUpxkC2JjYwHAbJzd3Pnv1q0bVCpVhXAM\nCztTJYQQ6NSpk57HnpycDB8fH5s2L1Pyd5Uflzt57D4+PvDx8XFoKMaSrJjKCjsAPPbYY8jOzsbv\nv/+u3ZaYmAgALiPs5VMerS1O0iUyMhJ+fn5WC7u/vz86d+5cQdjPnj2LwMBApy/mY2F3QhISEnDs\n2DFtw6fk5GS0adPGpgVEypfaHYUdkF674rFnZWVVa+zZXh47ICssy4djEhMTUbduXaef0FMIDg5G\nWFgYzpw5o7fAhi3w8PCwaAK1fGdHQ/Tp0wfJycl6k9VKRoyzh4RZ2J2QhIQEaDQaJCUlgYhw8OBB\nm/eQV0RFWTLQnUIxgJxAzc7OhlqtRl5enluEYpSxH374Yaxbt04bjklMTES3bt2cXmx0UVIeMzMz\nUVhYaDNhB2Q4xlqPHZAFTxqNBgMGDNDOB7hCqiNgI2EXQgwQQpwSQqQKIV61xZg1GaUD5d69e3Hh\nwgXcvn3bphkxQEVhd/Zby8qiNAKrztWTFOwp7IB+OCYzMxNnzpxxmTCMgpLyqKQ62irGDsgJ1CtX\nruDmzZsG91vaMrlTp05Ys2YNTp8+jXbt2mHFihW4cOGCS9wZ2WIxa08ACwDcD+BuAE8IIVxrkUwn\nIywsDFFRUdi3b5+24tTWHrtujL1OnTpO2aPeGpTWvdXZJ0bBXFZMZXuxl0c3HLN7924ArhNfV4iO\njsalS5e0C8vY2mMHYDQck5eXB7VabdH5Hzp0KA4dOoTY2FiMHDkSarW6xnjsnQCkEtE5IioCsBLA\nQzYYt0aTkJCAvXv34uDBg/D09NTmMNsK5UvtbsVJCorH7ghhNzd5qvRir6qwe3t7a8Mx27Ztg0ql\nsnwdXydByYzZtm0bANsKu5LyaCwcU9mq32bNmmHHjh2YNWsWatWqVa1FYFXFFsLeCEC6zuNLpdsY\nK0hISMDff/+N9evXIzY2tlKFLJag+6V2V2F3lMduLhRTlXYC5VHCMYsWLUL79u1t/v2wN4qw//HH\nH/D39zc7kVkZGjdujMDAQKMeu7HOjqZQqVSYPXs2cnJytHcEzky1TZ4KISYIIZKEEEnKwg6McRSv\n4MiRIzaPrwMynUsJv7jbxClQNnnqrsLet29fBAcHIy8vz+XCMEBZyuPFixetWmDDEEIIkxOo1px/\nV5mgtoWw/w2gic7jxqXb9CCiRUTUgYg6uKOHaGuUTo+A7ePrgPyCKl9sd/w8lFCMkvLoTMKu2GSN\nsCvhGMD14uuAvPAq3ztbhmEU4uLikJKSYrBhmi0urM6OLYR9P4AYIUSkEMIbwHAAv9hg3BqN0ukR\nsI+wA2VfbHf12EtKSpCRkQHAuSZPbSUskyZNQuvWrbWr/rgaSjjGXsJ+48YN7epgurCwWwARqQE8\nB2AzgBMAfiAi8+3VGLN07twZHh4eaNu2rV3Gd3ePHSjr9e1Mk6dV6exoiISEBBw5csRlU1XtKeym\nWgtUJcbuatgkxk5EvxJRCyKKIqLZthiTAWbNmoVNmzahdu3adhlf+WK7s7Cnp6dDCIGAgIBqe+3q\niLG7A/b22AHDKY+2urA6M1x56sTUq1cP/fr1s9v47h6KAaSw165d22Z97C2Bhd0yFGFXFuq2JeHh\n4QgLCzPosd++fRv+/v5us8avIVjYazA1JRRTnWEYwDJh9/HxcbkURVvz0EMPYeHChXaZ/DWVGWNN\ncZirwMJeg1FCMe7ssV++fLnahd2SyVN3FxZL8PHxwYQJE+y2+HZcXByOHTtWITOmJpx/FvYaTNu2\nbREdHe2yk2+mUMS8pKTEKT12dxcWZyA2NhbZ2dnaCXQFSzo7ujos7DWYf/zjHzhz5ozdPCZHoivm\njhB2c1kxLOz2x1hrgZpw/lnYGbfE0cKu0Wig0WgM7q8JwuIMsLAzjJvh5eWFWrVqAXCMsAMwGo6p\nCcLiDISEhKBRo0Ys7AzjTigTqI6YPAVY2J0BpbWAgkajQVZWltuffxZ2xm1RBN2ZPHZre7EzlSMu\nLhGeiJoAAA2DSURBVA7Hjx9HSUkJAODOnTvQaDQ8ecowroqjhd3QBGpBQQGKiopY2KuJuLg4FBQU\n4OzZswBqTnEYCzvjtiihmOouHTflsdcUYXEWyk+g1pTzz8LOuC2O9thZ2B3P3XffDSEECzvDuAuO\nmjxlYXceatWqhaioKBZ2hnEXHOWxm8qKqSnC4kzoZsbUhJa9AAs748Y4OhRjaPKUhb36iYuLw+nT\np1FYWFhjzj8LO+O2cCiGAaSwl5SU4OTJk9rzX93fieqGhZ1xW/r3748RI0agYcOG1fq6LOzOhW5m\nzO3btxEYGOiW/ZF0sUrYhRDvCyFOCiGOCCF+EkLwt5VxGlq3bo3ly5fDy8urWl/XnLBzL/bqpUWL\nFlCpVEhJSakRnR0B6z32LQDiiKgNgNMAZlpvEsO4NuYmT9lbr15UKhVatWql9dhrwvm3StiJ6PfS\nxawBYA+AxtabxDCujTmPvSYIi7MRFxeHo0eP1pjzb8sY+9MAfrPheAzjkpjLinHnRZSdlbi4OFy8\neBFpaWks7AAghNgqhEgx8PeQzjGvAVADWGFinAlCiCQhRFJmZqZtrGcYJ4Q9dudDmUC9cOFCjTj/\nZmeViOheU/uFEKMBPACgL5VfXFB/nEUAFgFAhw4djB7HMK6OOWGPiIioZosYRdgB9y9OAqzPihkA\n4BUAg4kozzYmMYxrw5OnzkdERAT8/f0B1IxUU2tj7J8CqA1gixDikBDiCxvYxDAujTGPnXuxOw4P\nDw/ExsYCqBnCblWCLxFF28oQhnEXjE2eci92xxIXF4d9+/bViPPPlacMY2OMeexcdepYlDh7TTj/\nLOwMY2NY2J2ThIQEAECzZs0cbIn9qd5aa4apARibPM3KygLAwu4ounbtinPnziEyMtLRptgd9tgZ\nxsawx+681ARRB1jYGcbmeHh4wMPDo8LkKQs7U12wsDOMHVCpVEZDMe7eC5xxPCzsDGMHDAn7nTt3\nAAC1a9d2hElMDYKFnWHsgClhDwgIcIRJTA2ChZ1h7IC3t7dBYff394eHB//sGPvC3zCGsQMqlarC\n5OmdO3c4DMNUCyzsDGMHjIViWNiZ6oCFnWHsAAs740hY2BnGDrCwM46EhZ1h7ICxyVMWdqY6YGFn\nGDvAHjvjSFjYGcYOcFYM40hY2BnGDrDHzjgSmwi7EOIlIQQJIcJsMR7DuDrlhV2tViM/P5+FnakW\nrBZ2IUQTAP0BpFlvDsO4B+UnT3NycgBwnximerCFxz4fwCsAyAZjMYxbUN5j5wZgTHVilbALIR4C\n8DcRHbaRPQzjFpSfPGVhZ6oTs0vjCSG2AqhvYNdrAGZBhmHMIoSYAGACADRt2rQSJjKM68EeO+NI\nzAo7Ed1raLsQojWASACHhRAA0BhAshCiExFlGBhnEYBFANChQwcO2zBuDQs740iqvJg1ER0FEK48\nFkJcANCBiK7bwC6GcWlY2BlHwnnsDGMHymfFsLAz1UmVPfbyEFGErcZiGFeHJ08ZR8IeO8PYAQ7F\nMI6EhZ1h7IAhYffw8ICfn58DrWJqCizsDGMHVCoV1Go1iGQCmNInpjSDjGHsCgs7w9gBb29vALJH\nDMANwJjqhYWdYeyASqUCAG04hoWdqU5Y2BnGDijCrmTGsLAz1QkLO8PYAfbYGUfCws4wdoCFnXEk\nLOwMYweUyVMWdsYRsLAzjB1gj51xJCzsDGMHePKUcSQs7AxjB3Q99sLCQhQXF7OwM9UGCzvD2AFd\nYec+MUx1w8LOMHZAd/KUhZ2pbljYGcYOsMfOOBIWdoaxA7qTpyzsTHVjs4U2GIYpQ9djVxqBsbAz\n1YXVHrsQYooQ4qQQ4pgQYq4tjGIYV4dDMYwjscpjF0L0BvAQgLZEVCiECDf3HIapCbCwM47EWo99\nMoA5RFQIAER0zXqTGMb14awYxpFYK+wtAPQQQuwVQuwQQnS0hVEM4+qwx844ErOhGCHEVgD1Dex6\nrfT5oQA6A+gI4AchRHNS1gPTH2cCgAkA0LRpU2tsZhinp3xWjLe3t9aLZxh7Y1bYieheY/uEEJMB\nrC0V8n1CCA2AMACZBsZZBGARAHTo0KGC8DOMO1HeY2dvnalOrA3F/AygNwAIIVoA8AZw3VqjGMbV\nYWFnHIm1eexLACwRQqQAKALwlKEwDMPUNMpPnrKwM9WJVcJOREUARtrIFoZxG9hjZxwJtxRgGDtQ\nfvKUhZ2pTljYGcYOeHp6AmCPnXEMLOwMYweEEFCpVCzsjENgYWcYO+Ht7c3CzjgEFnaGsRMqlQpF\nRUXIyclhYWeqFRZ2hrETKpUKWVlZ0Gg0LOxMtcLCzjB2QqVS4ebNmwC4TwxTvbCwM4ydUKlUuHXr\nFgAWdqZ6YWFnGDvh7e3NHjvjEFjYGcZOcCiGcRQs7AxjJ1QqFW7cuAGAhZ2pXljYGcZOqFQqXsia\ncQgs7AxjJ5R+MQALO1O9sLAzjJ1gYWccBQs7w9gJ3aXwAgICHGgJU9NgYWcYO6F47LVq1dJ2e2SY\n6oCFnWHshCLsHIZhqhurhF0IES+E2COEOCSESBJCdLKVYQzj6rCwM47CWo99LoC3iCgewD9LHzMM\nAxZ2xnFYK+wEILD0/0EALls5HsO4DcrkKQs7U91YtZg1gBcAbBZC/BfyItHVepMYxj1gj51xFGaF\nXQixFUB9A7teA9AXwDQi+lEIMQzAVwDuNTLOBAATAKBp06ZVNphhXAUWdsZRmBV2IjIo1AAghPgG\nwNTSh6sBLDYxziIAiwCgQ4cOVDkzGcb1YGFnHIW1MfbLAP6v9P99AJyxcjyGcRtY2BlHYW2MfTyA\nj4QQXgAKUBpqYRiGJ08Zx2GVsBPRTgDtbWQLw7gV7LEzjoIrTxnGTrCwM46ChZ1h7AQLO+MoWNgZ\nxk6wsDOOgoWdYewECzvjKFjYGcZOcFYM4yhY2BnGTrCwM46ChZ1h7MT999+P1157DVFRUY42halh\nCKLqr+7v0KEDJSUlVfvrMgzDuDJCiANE1MHcceyxMwzDuBks7AzDMG4GCzvDMIybwcLOMAzjZrCw\nMwzDuBks7AzDMG4GCzvDMIybwcLOMAzjZjikQEkIkQngYhWfHgbgug3NsTVsn3WwfdbB9lmPM9vY\njIjqmjvIIcJuDUKIJEsqrxwF22cdbJ91sH3W4wo2moNDMQzDMG4GCzvDMIyb4YrCvsjRBpiB7bMO\nts862D7rcQUbTeJyMXaGYRjGNK7osTMMwzAmcClhF0IMEEKcEkKkCiFedQJ7lgghrgkhUnS2hQoh\ntgghzpT+G+JA+5oIIbYJIY4LIY4JIaY6k41CCF8hxD4hxOFS+94q3R4phNhb+jmvEkJ4O8I+HTs9\nhRAHhRAbnM0+IcQFIcRRIcQhIURS6Tan+HxLbQkWQqwRQpwUQpwQQnRxFvuEEC1Lz5vyly2EeMFZ\n7LMGlxF2IYQngAUA7gdwN4AnhBB3O9YqLAMwoNy2VwH8QUQxAP4ofewo1ABeIqK7AXQG8GzpOXMW\nGwsB9CGitgDiAQwQQnQG8B6A+UQUDeAWgLEOsk9hKoATOo+dzb7eRBSvk6LnLJ8vAHwEYBMRtQLQ\nFvI8OoV9RHSq9LzFA2gPIA/AT85in1UQkUv8AegCYLPO45kAZjqBXREAUnQenwLQoPT/DQCccrSN\nOratA9DPGW0EUAtAMoAEyOIQL0OfuwPsagz54+4DYAMA4WT2XQAQVm6bU3y+AIIAnEfpXJ6z2VfO\npv4AdjmrfZX9cxmPHUAjAOk6jy+VbnM26hHRldL/ZwCo50hjFIQQEQDaAdgLJ7KxNMxxCMA1AFsA\nnAVwm4jUpYc4+nP+EMArADSlj+vAuewjAL8LIQ4IISaUbnOWzzcSQCaApaWhrMVCCH8nsk+X4QC+\nL/2/M9pXKVxJ2F0Okpd8h6cdCSECAPwI4AUiytbd52gbiaiE5K1wYwCdALRylC3lEUI8AOAaER1w\ntC0m6E5E90CGKJ8VQvTU3engz9cLwD0APieidgByUS6s4ejvH/6/fbtnjSKKwjj+P+ALEiSJkEJI\nIAhiJ1Y2WghWpkhlIxYp8ikk4EcQ/ACWIYIiEiyj1r4QX4gG1EIwISYg2Fs8FvcsLmLhppmzw/OD\nYebeaR64u4e9Z2aBfEayCDz4+16FfIcxToV9F5gbGs/mXDX7EXEaIM8HXYaJiKO0or4q6VFOl8oI\nIOkn8JzW2piKiCN5q8t1vgQsRsRX4D6tHXOXOvmQtJvnA1p/+CJ11ncH2JH0IscPaYW+Sr6Ba8Cm\npP0cV8s3snEq7K+As/lGwjHa1mm940z/sg4s5fUSra/diYgI4B6wLenO0K0SGSNiJiKm8voErf+/\nTSvw17vOJ+mWpFlJ87TP2zNJN6vki4iJiDg5uKb1ibcosr6SvgPfIuJcTl0FPlIk35Ab/GnDQL18\no+u6yT/iA44F4BOtD7tSIM8asAf8ov06Wab1YJ8Cn4EN4FSH+S7TtpHvgbd5LFTJCJwH3mS+LeB2\nzp8BXgJfaNvj4wXW+grwpFK+zPEujw+D70SV9c0sF4DXucaPgeli+SaAH8Dk0FyZfIc9/M9TM7Oe\nGadWjJmZ/QcXdjOznnFhNzPrGRd2M7OecWE3M+sZF3Yzs55xYTcz6xkXdjOznvkNa+0NusO2EwIA\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xcbba320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: updating scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_update, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating scheme RMSE: 2.3643885185 \n",
      "Updating scheme MAE:  1.60857864074\n"
     ]
    }
   ],
   "source": [
    "rmse_update = np.sqrt(np.mean((yhat_update-test_target)**2))\n",
    "mae_update = np.mean(np.abs((yhat_update-test_target)))\n",
    "print(\"Updating scheme RMSE:\", rmse_update,\n",
    "     \"\\nUpdating scheme MAE: \", mae_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + \"yhat_test_fixed.csv\", yhat_test_fixed)\n",
    "np.savetxt(MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + \"yhat_update.csv\", yhat_update)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
