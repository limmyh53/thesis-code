{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Directories\n",
    "MODEL_FOLDER = \"../../../models/lstm/\"\n",
    "MODEL_FILENAME = MODEL_FOLDER + \"4Q/128_units/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: model saver\n",
    "def saveModel(sess, MODEL_FILENAME):\n",
    "    if not os.path.exists(MODEL_FOLDER):\n",
    "        print('Creating path where to save model: ' + MODEL_FOLDER)\n",
    "        os.mkdir(MODEL_FOLDER)\n",
    "\n",
    "    #print('Saving model at: ' + MODEL_FILENAME)\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, MODEL_FILENAME)\n",
    "    #print('Model successfully saved.\\n')\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: model loader\n",
    "def loadModel(sess, MODEL_FILENAME):\n",
    "    if os.path.exists(MODEL_FILENAME + \".index\"):\n",
    "        print('Loading save model from: ' + MODEL_FILENAME)\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, MODEL_FILENAME)\n",
    "        print('Model successfully loaded.\\n')\n",
    "        return True\n",
    "    else:\n",
    "        print('Model file <<' + MODEL_FILENAME + '>> does not exists!')\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Hyperparameters\n",
    "epochs = 500\n",
    "learning_rate = 1e-1\n",
    "batch_size = 5\n",
    "early_stop_iters = 10\n",
    "folds = 32\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 3  # data input\n",
    "n_steps = 4  # timesteps\n",
    "n_hidden = 128 # dimension of recurrent unit\n",
    "\n",
    "# (REPRODUCIBILITY) set random seeds\n",
    "tf.set_random_seed(123)\n",
    "\n",
    "# Define weights and biases\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.truncated_normal([n_hidden, 1], stddev = 1.0 / tf.sqrt(float(n_hidden))),\n",
    "        name='out_weight')\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.zeros([1]),\n",
    "        name='out_bias')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: Build model\n",
    "def RNN(X, weights, biases, n_hidden):\n",
    "\n",
    "    # Define a LSTM cell with tensorflow\n",
    "    lstm_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden, state_is_tuple=True)\n",
    "    outputs, _ = tf.nn.dynamic_rnn(lstm_cell, X, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    out_layer = tf.matmul(outputs[:,-1,:], weights['out']) + biases['out']\n",
    "\n",
    "    return out_layer\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: select batch\n",
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the data...\n",
      "Finished: data loaded. Stats below: \n",
      "Nr of training samples: 193\n",
      "Nr of testing  samples: 77\n",
      "Number of variables: 3\n",
      "Number of lags: 4\n",
      "Window length: 65\n",
      "Number of validation folds: 32\n"
     ]
    }
   ],
   "source": [
    "# =================================\n",
    "# 0. Load dataset\n",
    "# =================================\n",
    "print(\"Loading the data...\")\n",
    "# Training set pre-processing\n",
    "train = pd.read_csv('../../../Data/train.csv')\n",
    "train_4lag_inflation = np.array(train[['inflation.lag4',\n",
    "                                       'inflation.lag5',\n",
    "                                       'inflation.lag6',\n",
    "                                       'inflation.lag7']])\n",
    "train_4lag_unemp = np.array(train[['unemp.lag4',\n",
    "                                   'unemp.lag5',\n",
    "                                   'unemp.lag6',\n",
    "                                   'unemp.lag7']])\n",
    "train_4lag_oil = np.array(train[['oil.lag4',\n",
    "                                 'oil.lag5',\n",
    "                                 'oil.lag6',\n",
    "                                 'oil.lag7']])\n",
    "train_features = np.concatenate((train_4lag_inflation[:,:,np.newaxis], \n",
    "\t                             train_4lag_unemp[:,:,np.newaxis],\n",
    "\t                             train_4lag_oil[:,:,np.newaxis]),\n",
    "\t                             axis=2)\n",
    "train_target = np.array(train['inflation.target'])\n",
    "\n",
    "# Test set pre-processing\n",
    "test = pd.read_csv('../../../Data/test.csv')\n",
    "test_4lag_inflation = np.array(test[['inflation.lag4',\n",
    "                                     'inflation.lag5',\n",
    "                                     'inflation.lag6',\n",
    "                                     'inflation.lag7']])\n",
    "test_4lag_unemp = np.array(test[['unemp.lag4',\n",
    "                                 'unemp.lag5',\n",
    "                                 'unemp.lag6',\n",
    "                                 'unemp.lag7']])\n",
    "test_4lag_oil = np.array(test[['oil.lag4',\n",
    "                               'oil.lag5',\n",
    "                               'oil.lag6',\n",
    "                               'oil.lag7']])\n",
    "test_features = np.concatenate((test_4lag_inflation[:,:,np.newaxis], \n",
    "\t                            test_4lag_unemp[:,:,np.newaxis],\n",
    "\t                            test_4lag_oil[:,:,np.newaxis]),\n",
    "\t                            axis=2)\n",
    "test_target = np.array(test['inflation.target'])\n",
    "\n",
    "(nrTrainSamples, timesteps, variables) = train_features.shape\n",
    "(nrTestSamples, _, _) = test_features.shape\n",
    "\n",
    "# Window length and validation fold index\n",
    "window_length = 65\n",
    "valIndex = np.linspace(start=window_length, stop=nrTrainSamples, \n",
    "                       endpoint=True, num=folds+1, dtype=np.int)\n",
    "\n",
    "print(\"Finished: data loaded. Stats below: \")\n",
    "print(\"Nr of training samples: %d\" % nrTrainSamples)\n",
    "print(\"Nr of testing  samples: %d\" % nrTestSamples)\n",
    "print(\"Number of variables: %d\" % variables)\n",
    "print(\"Number of lags: %d\" % timesteps)\n",
    "print(\"Window length: %d\" % window_length)\n",
    "print(\"Number of validation folds: %d\" % folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 1. Build model\n",
    "# ==================================\n",
    "# tf graph input\n",
    "x = tf.placeholder(\"float\", [None, n_steps, n_input], name='Batch')\n",
    "y = tf.placeholder(\"float\", name='True_labels_of_batch')\n",
    "lr = tf.placeholder(\"float\", name='Learning_rate')\n",
    "\n",
    "# Make predictions with the model\n",
    "pred = RNN(x, weights, biases, n_hidden)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss = tf.reduce_mean(tf.diag_part(tf.square(tf.subtract(x=pred, y=y))))\n",
    "optimizer = tf.train.GradientDescentOptimizer(lr).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training \n",
      "Hyperparameters: \n",
      "Dimension of recurrent unit = 128 \n",
      "Learning rate = 0.1 \n",
      "Epochs = 500 \n",
      "Batch size = 5 \n",
      "Early stopping epochs = 10 \n",
      "Learning rate = 0.1\n",
      "Fold: 1  Epoch: 1  Training loss = 2.9003  Validation loss = 2.8133  \n",
      "\n",
      "Fold: 1  Epoch: 2  Training loss = 2.4275  Validation loss = 1.1340  \n",
      "\n",
      "Fold: 1  Epoch: 3  Training loss = 2.2881  Validation loss = 1.4973  \n",
      "\n",
      "Fold: 1  Epoch: 4  Training loss = 2.2928  Validation loss = 1.3842  \n",
      "\n",
      "Fold: 1  Epoch: 5  Training loss = 2.2289  Validation loss = 1.6402  \n",
      "\n",
      "Fold: 1  Epoch: 6  Training loss = 2.2988  Validation loss = 1.3870  \n",
      "\n",
      "Fold: 1  Epoch: 7  Training loss = 2.4862  Validation loss = 0.6984  \n",
      "\n",
      "Fold: 1  Epoch: 8  Training loss = 2.2792  Validation loss = 2.3047  \n",
      "\n",
      "Fold: 1  Epoch: 9  Training loss = 2.3703  Validation loss = 2.4380  \n",
      "\n",
      "Fold: 1  Epoch: 10  Training loss = 2.1747  Validation loss = 1.9532  \n",
      "\n",
      "Fold: 1  Epoch: 11  Training loss = 2.1796  Validation loss = 1.9168  \n",
      "\n",
      "Fold: 1  Epoch: 12  Training loss = 2.3784  Validation loss = 2.4095  \n",
      "\n",
      "Fold: 1  Epoch: 13  Training loss = 2.1744  Validation loss = 1.9198  \n",
      "\n",
      "Fold: 1  Epoch: 14  Training loss = 2.1978  Validation loss = 2.0769  \n",
      "\n",
      "Fold: 1  Epoch: 15  Training loss = 2.2394  Validation loss = 2.3266  \n",
      "\n",
      "Fold: 1  Epoch: 16  Training loss = 2.1696  Validation loss = 1.9804  \n",
      "\n",
      "Fold: 1  Epoch: 17  Training loss = 2.2030  Validation loss = 2.4403  \n",
      "\n",
      "Check model:  Fold: 1  Optimal epoch: 7  \n",
      "\n",
      "Fold: 2  Epoch: 1  Training loss = 2.2586  Validation loss = 2.7060  \n",
      "\n",
      "Fold: 2  Epoch: 2  Training loss = 2.1530  Validation loss = 2.2142  \n",
      "\n",
      "Fold: 2  Epoch: 3  Training loss = 2.2322  Validation loss = 2.3805  \n",
      "\n",
      "Fold: 2  Epoch: 4  Training loss = 2.1462  Validation loss = 2.3361  \n",
      "\n",
      "Fold: 2  Epoch: 5  Training loss = 2.1510  Validation loss = 2.3065  \n",
      "\n",
      "Fold: 2  Epoch: 6  Training loss = 2.1910  Validation loss = 2.2378  \n",
      "\n",
      "Fold: 2  Epoch: 7  Training loss = 2.4253  Validation loss = 1.7318  \n",
      "\n",
      "Fold: 2  Epoch: 8  Training loss = 2.1640  Validation loss = 1.9751  \n",
      "\n",
      "Fold: 2  Epoch: 9  Training loss = 2.2432  Validation loss = 2.4186  \n",
      "\n",
      "Fold: 2  Epoch: 10  Training loss = 2.1867  Validation loss = 2.3428  \n",
      "\n",
      "Fold: 2  Epoch: 11  Training loss = 2.1812  Validation loss = 1.8417  \n",
      "\n",
      "Fold: 2  Epoch: 12  Training loss = 2.2112  Validation loss = 2.1253  \n",
      "\n",
      "Fold: 2  Epoch: 13  Training loss = 2.2622  Validation loss = 2.6584  \n",
      "\n",
      "Check model:  Fold: 2  Optimal epoch: 7  \n",
      "\n",
      "Fold: 3  Epoch: 1  Training loss = 1.3107  Validation loss = 3.5104  \n",
      "\n",
      "Fold: 3  Epoch: 2  Training loss = 1.3232  Validation loss = 3.6190  \n",
      "\n",
      "Fold: 3  Epoch: 3  Training loss = 1.2921  Validation loss = 3.1400  \n",
      "\n",
      "Fold: 3  Epoch: 4  Training loss = 1.2779  Validation loss = 3.5344  \n",
      "\n",
      "Fold: 3  Epoch: 5  Training loss = 1.3280  Validation loss = 3.8390  \n",
      "\n",
      "Fold: 3  Epoch: 6  Training loss = 1.2998  Validation loss = 3.1752  \n",
      "\n",
      "Fold: 3  Epoch: 7  Training loss = 1.2614  Validation loss = 3.2032  \n",
      "\n",
      "Fold: 3  Epoch: 8  Training loss = 1.2177  Validation loss = 3.0756  \n",
      "\n",
      "Fold: 3  Epoch: 9  Training loss = 1.4628  Validation loss = 3.8990  \n",
      "\n",
      "Fold: 3  Epoch: 10  Training loss = 1.2417  Validation loss = 3.2392  \n",
      "\n",
      "Fold: 3  Epoch: 11  Training loss = 1.2285  Validation loss = 3.1467  \n",
      "\n",
      "Fold: 3  Epoch: 12  Training loss = 1.2119  Validation loss = 3.2214  \n",
      "\n",
      "Fold: 3  Epoch: 13  Training loss = 1.3268  Validation loss = 2.0446  \n",
      "\n",
      "Fold: 3  Epoch: 14  Training loss = 1.1592  Validation loss = 2.8022  \n",
      "\n",
      "Fold: 3  Epoch: 15  Training loss = 1.3065  Validation loss = 3.4917  \n",
      "\n",
      "Fold: 3  Epoch: 16  Training loss = 1.1672  Validation loss = 3.2429  \n",
      "\n",
      "Fold: 3  Epoch: 17  Training loss = 1.1951  Validation loss = 2.7337  \n",
      "\n",
      "Fold: 3  Epoch: 18  Training loss = 1.2357  Validation loss = 2.9876  \n",
      "\n",
      "Fold: 3  Epoch: 19  Training loss = 1.1435  Validation loss = 2.5716  \n",
      "\n",
      "Fold: 3  Epoch: 20  Training loss = 1.1722  Validation loss = 2.3155  \n",
      "\n",
      "Fold: 3  Epoch: 21  Training loss = 1.1888  Validation loss = 2.7204  \n",
      "\n",
      "Fold: 3  Epoch: 22  Training loss = 1.1074  Validation loss = 3.2370  \n",
      "\n",
      "Fold: 3  Epoch: 23  Training loss = 1.0837  Validation loss = 2.5830  \n",
      "\n",
      "Fold: 3  Epoch: 24  Training loss = 1.1705  Validation loss = 3.2836  \n",
      "\n",
      "Fold: 3  Epoch: 25  Training loss = 1.1011  Validation loss = 2.6896  \n",
      "\n",
      "Fold: 3  Epoch: 26  Training loss = 1.2181  Validation loss = 2.3460  \n",
      "\n",
      "Fold: 3  Epoch: 27  Training loss = 1.1786  Validation loss = 2.3580  \n",
      "\n",
      "Fold: 3  Epoch: 28  Training loss = 1.0847  Validation loss = 2.8510  \n",
      "\n",
      "Fold: 3  Epoch: 29  Training loss = 1.0916  Validation loss = 3.0626  \n",
      "\n",
      "Fold: 3  Epoch: 30  Training loss = 1.0805  Validation loss = 2.9782  \n",
      "\n",
      "Fold: 3  Epoch: 31  Training loss = 1.1007  Validation loss = 2.8354  \n",
      "\n",
      "Fold: 3  Epoch: 32  Training loss = 1.0340  Validation loss = 2.2794  \n",
      "\n",
      "Fold: 3  Epoch: 33  Training loss = 1.2807  Validation loss = 2.6745  \n",
      "\n",
      "Fold: 3  Epoch: 34  Training loss = 1.0690  Validation loss = 1.7903  \n",
      "\n",
      "Fold: 3  Epoch: 35  Training loss = 1.0310  Validation loss = 2.3219  \n",
      "\n",
      "Fold: 3  Epoch: 36  Training loss = 1.0132  Validation loss = 2.3772  \n",
      "\n",
      "Fold: 3  Epoch: 37  Training loss = 1.1253  Validation loss = 1.7340  \n",
      "\n",
      "Fold: 3  Epoch: 38  Training loss = 1.0893  Validation loss = 2.2901  \n",
      "\n",
      "Fold: 3  Epoch: 39  Training loss = 1.0103  Validation loss = 2.2220  \n",
      "\n",
      "Fold: 3  Epoch: 40  Training loss = 1.0527  Validation loss = 2.7829  \n",
      "\n",
      "Fold: 3  Epoch: 41  Training loss = 1.0854  Validation loss = 1.9083  \n",
      "\n",
      "Fold: 3  Epoch: 42  Training loss = 0.9689  Validation loss = 2.2729  \n",
      "\n",
      "Fold: 3  Epoch: 43  Training loss = 0.9825  Validation loss = 2.0007  \n",
      "\n",
      "Fold: 3  Epoch: 44  Training loss = 1.0002  Validation loss = 2.5120  \n",
      "\n",
      "Fold: 3  Epoch: 45  Training loss = 0.9806  Validation loss = 2.0669  \n",
      "\n",
      "Fold: 3  Epoch: 46  Training loss = 1.0266  Validation loss = 1.8046  \n",
      "\n",
      "Fold: 3  Epoch: 47  Training loss = 1.0001  Validation loss = 2.4844  \n",
      "\n",
      "Fold: 3  Epoch: 48  Training loss = 0.9655  Validation loss = 2.2279  \n",
      "\n",
      "Fold: 3  Epoch: 49  Training loss = 0.9342  Validation loss = 1.5985  \n",
      "\n",
      "Fold: 3  Epoch: 50  Training loss = 1.0369  Validation loss = 1.7480  \n",
      "\n",
      "Fold: 3  Epoch: 51  Training loss = 0.9123  Validation loss = 1.8272  \n",
      "\n",
      "Fold: 3  Epoch: 52  Training loss = 1.1502  Validation loss = 1.9118  \n",
      "\n",
      "Fold: 3  Epoch: 53  Training loss = 1.0682  Validation loss = 2.0593  \n",
      "\n",
      "Fold: 3  Epoch: 54  Training loss = 0.9262  Validation loss = 2.0635  \n",
      "\n",
      "Fold: 3  Epoch: 55  Training loss = 1.1729  Validation loss = 1.8290  \n",
      "\n",
      "Fold: 3  Epoch: 56  Training loss = 1.1066  Validation loss = 1.9979  \n",
      "\n",
      "Fold: 3  Epoch: 57  Training loss = 1.1441  Validation loss = 2.3441  \n",
      "\n",
      "Check model:  Fold: 3  Optimal epoch: 49  \n",
      "\n",
      "Fold: 4  Epoch: 1  Training loss = 0.9245  Validation loss = 3.1593  \n",
      "\n",
      "Fold: 4  Epoch: 2  Training loss = 0.8598  Validation loss = 2.7834  \n",
      "\n",
      "Fold: 4  Epoch: 3  Training loss = 1.2977  Validation loss = 2.7629  \n",
      "\n",
      "Fold: 4  Epoch: 4  Training loss = 0.8267  Validation loss = 2.6517  \n",
      "\n",
      "Fold: 4  Epoch: 5  Training loss = 0.9014  Validation loss = 2.9929  \n",
      "\n",
      "Fold: 4  Epoch: 6  Training loss = 0.8936  Validation loss = 2.4442  \n",
      "\n",
      "Fold: 4  Epoch: 7  Training loss = 0.8340  Validation loss = 2.8838  \n",
      "\n",
      "Fold: 4  Epoch: 8  Training loss = 0.8990  Validation loss = 2.2054  \n",
      "\n",
      "Fold: 4  Epoch: 9  Training loss = 1.0232  Validation loss = 2.4082  \n",
      "\n",
      "Fold: 4  Epoch: 10  Training loss = 0.7857  Validation loss = 2.4538  \n",
      "\n",
      "Fold: 4  Epoch: 11  Training loss = 0.8293  Validation loss = 2.6820  \n",
      "\n",
      "Fold: 4  Epoch: 12  Training loss = 0.7822  Validation loss = 2.5999  \n",
      "\n",
      "Fold: 4  Epoch: 13  Training loss = 0.7878  Validation loss = 2.6078  \n",
      "\n",
      "Fold: 4  Epoch: 14  Training loss = 0.8003  Validation loss = 2.0708  \n",
      "\n",
      "Fold: 4  Epoch: 15  Training loss = 0.8040  Validation loss = 2.8047  \n",
      "\n",
      "Fold: 4  Epoch: 16  Training loss = 0.7721  Validation loss = 2.4207  \n",
      "\n",
      "Fold: 4  Epoch: 17  Training loss = 0.9152  Validation loss = 2.4467  \n",
      "\n",
      "Fold: 4  Epoch: 18  Training loss = 0.7657  Validation loss = 2.2715  \n",
      "\n",
      "Fold: 4  Epoch: 19  Training loss = 0.7516  Validation loss = 2.3279  \n",
      "\n",
      "Fold: 4  Epoch: 20  Training loss = 0.8824  Validation loss = 2.2123  \n",
      "\n",
      "Fold: 4  Epoch: 21  Training loss = 0.7246  Validation loss = 2.0574  \n",
      "\n",
      "Fold: 4  Epoch: 22  Training loss = 0.7552  Validation loss = 2.2898  \n",
      "\n",
      "Fold: 4  Epoch: 23  Training loss = 0.9013  Validation loss = 2.1959  \n",
      "\n",
      "Fold: 4  Epoch: 24  Training loss = 0.8091  Validation loss = 2.3892  \n",
      "\n",
      "Fold: 4  Epoch: 25  Training loss = 0.7207  Validation loss = 1.9417  \n",
      "\n",
      "Fold: 4  Epoch: 26  Training loss = 0.7040  Validation loss = 2.2903  \n",
      "\n",
      "Fold: 4  Epoch: 27  Training loss = 0.8236  Validation loss = 2.4949  \n",
      "\n",
      "Check model:  Fold: 4  Optimal epoch: 25  \n",
      "\n",
      "Fold: 5  Epoch: 1  Training loss = 0.8939  Validation loss = 1.8033  \n",
      "\n",
      "Fold: 5  Epoch: 2  Training loss = 1.1583  Validation loss = 3.1997  \n",
      "\n",
      "Fold: 5  Epoch: 3  Training loss = 0.7770  Validation loss = 2.7391  \n",
      "\n",
      "Fold: 5  Epoch: 4  Training loss = 0.7929  Validation loss = 2.7125  \n",
      "\n",
      "Fold: 5  Epoch: 5  Training loss = 0.9638  Validation loss = 1.4171  \n",
      "\n",
      "Fold: 5  Epoch: 6  Training loss = 1.1188  Validation loss = 1.3979  \n",
      "\n",
      "Fold: 5  Epoch: 7  Training loss = 0.9800  Validation loss = 2.1342  \n",
      "\n",
      "Fold: 5  Epoch: 8  Training loss = 0.8770  Validation loss = 2.4420  \n",
      "\n",
      "Fold: 5  Epoch: 9  Training loss = 0.7938  Validation loss = 2.0965  \n",
      "\n",
      "Fold: 5  Epoch: 10  Training loss = 0.8811  Validation loss = 2.5768  \n",
      "\n",
      "Fold: 5  Epoch: 11  Training loss = 0.7731  Validation loss = 2.6244  \n",
      "\n",
      "Fold: 5  Epoch: 12  Training loss = 0.7899  Validation loss = 2.5953  \n",
      "\n",
      "Fold: 5  Epoch: 13  Training loss = 0.7820  Validation loss = 2.3826  \n",
      "\n",
      "Fold: 5  Epoch: 14  Training loss = 0.8434  Validation loss = 2.0145  \n",
      "\n",
      "Fold: 5  Epoch: 15  Training loss = 0.7067  Validation loss = 2.2761  \n",
      "\n",
      "Fold: 5  Epoch: 16  Training loss = 0.6797  Validation loss = 2.1820  \n",
      "\n",
      "Fold: 5  Epoch: 17  Training loss = 0.6645  Validation loss = 1.9876  \n",
      "\n",
      "Fold: 5  Epoch: 18  Training loss = 0.6869  Validation loss = 1.6674  \n",
      "\n",
      "Fold: 5  Epoch: 19  Training loss = 0.6851  Validation loss = 1.4764  \n",
      "\n",
      "Fold: 5  Epoch: 20  Training loss = 0.6065  Validation loss = 1.4760  \n",
      "\n",
      "Fold: 5  Epoch: 21  Training loss = 0.6499  Validation loss = 1.5301  \n",
      "\n",
      "Fold: 5  Epoch: 22  Training loss = 0.6422  Validation loss = 1.3861  \n",
      "\n",
      "Fold: 5  Epoch: 23  Training loss = 0.7190  Validation loss = 1.7160  \n",
      "\n",
      "Fold: 5  Epoch: 24  Training loss = 0.8049  Validation loss = 1.6095  \n",
      "\n",
      "Fold: 5  Epoch: 25  Training loss = 0.6280  Validation loss = 2.2121  \n",
      "\n",
      "Check model:  Fold: 5  Optimal epoch: 22  \n",
      "\n",
      "Fold: 6  Epoch: 1  Training loss = 0.8549  Validation loss = 2.4244  \n",
      "\n",
      "Fold: 6  Epoch: 2  Training loss = 0.9030  Validation loss = 2.9600  \n",
      "\n",
      "Fold: 6  Epoch: 3  Training loss = 0.7182  Validation loss = 2.4054  \n",
      "\n",
      "Fold: 6  Epoch: 4  Training loss = 0.7419  Validation loss = 2.8190  \n",
      "\n",
      "Fold: 6  Epoch: 5  Training loss = 0.6906  Validation loss = 2.7661  \n",
      "\n",
      "Fold: 6  Epoch: 6  Training loss = 0.6332  Validation loss = 2.3006  \n",
      "\n",
      "Fold: 6  Epoch: 7  Training loss = 0.8023  Validation loss = 3.2235  \n",
      "\n",
      "Fold: 6  Epoch: 8  Training loss = 0.5720  Validation loss = 2.3179  \n",
      "\n",
      "Fold: 6  Epoch: 9  Training loss = 0.5608  Validation loss = 2.6298  \n",
      "\n",
      "Fold: 6  Epoch: 10  Training loss = 0.6578  Validation loss = 2.5184  \n",
      "\n",
      "Fold: 6  Epoch: 11  Training loss = 0.5599  Validation loss = 2.4879  \n",
      "\n",
      "Fold: 6  Epoch: 12  Training loss = 0.5384  Validation loss = 2.7267  \n",
      "\n",
      "Fold: 6  Epoch: 13  Training loss = 0.6657  Validation loss = 2.5524  \n",
      "\n",
      "Fold: 6  Epoch: 14  Training loss = 0.5763  Validation loss = 2.7301  \n",
      "\n",
      "Fold: 6  Epoch: 15  Training loss = 0.6026  Validation loss = 2.3462  \n",
      "\n",
      "Fold: 6  Epoch: 16  Training loss = 0.5040  Validation loss = 2.7827  \n",
      "\n",
      "Fold: 6  Epoch: 17  Training loss = 0.5523  Validation loss = 2.6441  \n",
      "\n",
      "Fold: 6  Epoch: 18  Training loss = 0.5783  Validation loss = 2.5861  \n",
      "\n",
      "Fold: 6  Epoch: 19  Training loss = 0.5629  Validation loss = 2.7850  \n",
      "\n",
      "Check model:  Fold: 6  Optimal epoch: 6  \n",
      "\n",
      "Fold: 7  Epoch: 1  Training loss = 0.8142  Validation loss = 2.9600  \n",
      "\n",
      "Fold: 7  Epoch: 2  Training loss = 0.8501  Validation loss = 2.9024  \n",
      "\n",
      "Fold: 7  Epoch: 3  Training loss = 0.8552  Validation loss = 2.1513  \n",
      "\n",
      "Fold: 7  Epoch: 4  Training loss = 0.6828  Validation loss = 2.4435  \n",
      "\n",
      "Fold: 7  Epoch: 5  Training loss = 0.6305  Validation loss = 2.6003  \n",
      "\n",
      "Fold: 7  Epoch: 6  Training loss = 0.6863  Validation loss = 2.2783  \n",
      "\n",
      "Fold: 7  Epoch: 7  Training loss = 0.6091  Validation loss = 2.2781  \n",
      "\n",
      "Fold: 7  Epoch: 8  Training loss = 0.6521  Validation loss = 2.5871  \n",
      "\n",
      "Fold: 7  Epoch: 9  Training loss = 0.5858  Validation loss = 2.6571  \n",
      "\n",
      "Fold: 7  Epoch: 10  Training loss = 0.6303  Validation loss = 2.7732  \n",
      "\n",
      "Fold: 7  Epoch: 11  Training loss = 0.7612  Validation loss = 2.2459  \n",
      "\n",
      "Fold: 7  Epoch: 12  Training loss = 0.7816  Validation loss = 2.2073  \n",
      "\n",
      "Fold: 7  Epoch: 13  Training loss = 0.6726  Validation loss = 2.0391  \n",
      "\n",
      "Fold: 7  Epoch: 14  Training loss = 0.5886  Validation loss = 2.4829  \n",
      "\n",
      "Fold: 7  Epoch: 15  Training loss = 0.6464  Validation loss = 2.2644  \n",
      "\n",
      "Fold: 7  Epoch: 16  Training loss = 0.6688  Validation loss = 2.5271  \n",
      "\n",
      "Fold: 7  Epoch: 17  Training loss = 0.6337  Validation loss = 2.4505  \n",
      "\n",
      "Fold: 7  Epoch: 18  Training loss = 0.5893  Validation loss = 2.4267  \n",
      "\n",
      "Fold: 7  Epoch: 19  Training loss = 0.5394  Validation loss = 2.3521  \n",
      "\n",
      "Fold: 7  Epoch: 20  Training loss = 0.5640  Validation loss = 2.3773  \n",
      "\n",
      "Fold: 7  Epoch: 21  Training loss = 0.6064  Validation loss = 2.5329  \n",
      "\n",
      "Check model:  Fold: 7  Optimal epoch: 13  \n",
      "\n",
      "Fold: 8  Epoch: 1  Training loss = 0.8182  Validation loss = 7.6321  \n",
      "\n",
      "Fold: 8  Epoch: 2  Training loss = 1.3047  Validation loss = 5.9232  \n",
      "\n",
      "Fold: 8  Epoch: 3  Training loss = 0.9343  Validation loss = 7.9040  \n",
      "\n",
      "Fold: 8  Epoch: 4  Training loss = 0.6855  Validation loss = 7.0458  \n",
      "\n",
      "Fold: 8  Epoch: 5  Training loss = 0.6772  Validation loss = 7.2387  \n",
      "\n",
      "Fold: 8  Epoch: 6  Training loss = 0.7498  Validation loss = 7.2395  \n",
      "\n",
      "Fold: 8  Epoch: 7  Training loss = 0.7146  Validation loss = 7.7440  \n",
      "\n",
      "Fold: 8  Epoch: 8  Training loss = 0.6542  Validation loss = 7.2324  \n",
      "\n",
      "Fold: 8  Epoch: 9  Training loss = 0.6591  Validation loss = 7.0150  \n",
      "\n",
      "Fold: 8  Epoch: 10  Training loss = 0.7775  Validation loss = 6.4923  \n",
      "\n",
      "Fold: 8  Epoch: 11  Training loss = 0.6904  Validation loss = 7.6042  \n",
      "\n",
      "Fold: 8  Epoch: 12  Training loss = 0.7953  Validation loss = 7.3071  \n",
      "\n",
      "Fold: 8  Epoch: 13  Training loss = 0.6616  Validation loss = 7.5965  \n",
      "\n",
      "Fold: 8  Epoch: 14  Training loss = 0.9132  Validation loss = 7.1420  \n",
      "\n",
      "Fold: 8  Epoch: 15  Training loss = 0.6535  Validation loss = 7.2386  \n",
      "\n",
      "Fold: 8  Epoch: 16  Training loss = 0.5749  Validation loss = 7.4447  \n",
      "\n",
      "Fold: 8  Epoch: 17  Training loss = 0.5700  Validation loss = 7.4607  \n",
      "\n",
      "Fold: 8  Epoch: 18  Training loss = 0.6108  Validation loss = 7.8881  \n",
      "\n",
      "Check model:  Fold: 8  Optimal epoch: 2  \n",
      "\n",
      "Fold: 9  Epoch: 1  Training loss = 1.3673  Validation loss = 6.9456  \n",
      "\n",
      "Fold: 9  Epoch: 2  Training loss = 1.6554  Validation loss = 7.5158  \n",
      "\n",
      "Fold: 9  Epoch: 3  Training loss = 1.4546  Validation loss = 7.4312  \n",
      "\n",
      "Fold: 9  Epoch: 4  Training loss = 1.3750  Validation loss = 7.1915  \n",
      "\n",
      "Fold: 9  Epoch: 5  Training loss = 1.5121  Validation loss = 7.2335  \n",
      "\n",
      "Fold: 9  Epoch: 6  Training loss = 1.5811  Validation loss = 7.8541  \n",
      "\n",
      "Fold: 9  Epoch: 7  Training loss = 1.3675  Validation loss = 7.3228  \n",
      "\n",
      "Fold: 9  Epoch: 8  Training loss = 1.2617  Validation loss = 6.1202  \n",
      "\n",
      "Fold: 9  Epoch: 9  Training loss = 1.3003  Validation loss = 6.8598  \n",
      "\n",
      "Fold: 9  Epoch: 10  Training loss = 1.2933  Validation loss = 7.4479  \n",
      "\n",
      "Fold: 9  Epoch: 11  Training loss = 1.5326  Validation loss = 7.5833  \n",
      "\n",
      "Fold: 9  Epoch: 12  Training loss = 1.3769  Validation loss = 6.5857  \n",
      "\n",
      "Fold: 9  Epoch: 13  Training loss = 1.1929  Validation loss = 6.9890  \n",
      "\n",
      "Fold: 9  Epoch: 14  Training loss = 1.2831  Validation loss = 6.8102  \n",
      "\n",
      "Fold: 9  Epoch: 15  Training loss = 1.2112  Validation loss = 6.5942  \n",
      "\n",
      "Fold: 9  Epoch: 16  Training loss = 1.5719  Validation loss = 5.5053  \n",
      "\n",
      "Fold: 9  Epoch: 17  Training loss = 1.2335  Validation loss = 7.0623  \n",
      "\n",
      "Fold: 9  Epoch: 18  Training loss = 1.1998  Validation loss = 7.3812  \n",
      "\n",
      "Fold: 9  Epoch: 19  Training loss = 1.2859  Validation loss = 6.1071  \n",
      "\n",
      "Fold: 9  Epoch: 20  Training loss = 1.7253  Validation loss = 4.6694  \n",
      "\n",
      "Fold: 9  Epoch: 21  Training loss = 1.2257  Validation loss = 7.0354  \n",
      "\n",
      "Fold: 9  Epoch: 22  Training loss = 1.2819  Validation loss = 5.8430  \n",
      "\n",
      "Fold: 9  Epoch: 23  Training loss = 1.5403  Validation loss = 8.2161  \n",
      "\n",
      "Check model:  Fold: 9  Optimal epoch: 20  \n",
      "\n",
      "Fold: 10  Epoch: 1  Training loss = 1.8556  Validation loss = 3.2971  \n",
      "\n",
      "Fold: 10  Epoch: 2  Training loss = 2.1225  Validation loss = 4.7339  \n",
      "\n",
      "Fold: 10  Epoch: 3  Training loss = 1.8859  Validation loss = 6.6122  \n",
      "\n",
      "Fold: 10  Epoch: 4  Training loss = 2.0822  Validation loss = 4.0349  \n",
      "\n",
      "Fold: 10  Epoch: 5  Training loss = 1.7968  Validation loss = 4.6936  \n",
      "\n",
      "Fold: 10  Epoch: 6  Training loss = 1.6400  Validation loss = 4.1489  \n",
      "\n",
      "Fold: 10  Epoch: 7  Training loss = 1.5560  Validation loss = 3.7890  \n",
      "\n",
      "Fold: 10  Epoch: 8  Training loss = 1.6490  Validation loss = 3.9854  \n",
      "\n",
      "Fold: 10  Epoch: 9  Training loss = 1.7841  Validation loss = 3.1215  \n",
      "\n",
      "Fold: 10  Epoch: 10  Training loss = 1.6053  Validation loss = 4.6732  \n",
      "\n",
      "Fold: 10  Epoch: 11  Training loss = 2.4961  Validation loss = 6.7856  \n",
      "\n",
      "Check model:  Fold: 10  Optimal epoch: 9  \n",
      "\n",
      "Fold: 11  Epoch: 1  Training loss = 1.8467  Validation loss = 1.7824  \n",
      "\n",
      "Fold: 11  Epoch: 2  Training loss = 2.0915  Validation loss = 2.5588  \n",
      "\n",
      "Fold: 11  Epoch: 3  Training loss = 1.7811  Validation loss = 2.8399  \n",
      "\n",
      "Fold: 11  Epoch: 4  Training loss = 1.6067  Validation loss = 3.2926  \n",
      "\n",
      "Fold: 11  Epoch: 5  Training loss = 1.5972  Validation loss = 2.7663  \n",
      "\n",
      "Fold: 11  Epoch: 6  Training loss = 1.7791  Validation loss = 3.3514  \n",
      "\n",
      "Fold: 11  Epoch: 7  Training loss = 1.6333  Validation loss = 3.1116  \n",
      "\n",
      "Fold: 11  Epoch: 8  Training loss = 1.6446  Validation loss = 2.5903  \n",
      "\n",
      "Fold: 11  Epoch: 9  Training loss = 1.5148  Validation loss = 2.8729  \n",
      "\n",
      "Fold: 11  Epoch: 10  Training loss = 1.8352  Validation loss = 4.2887  \n",
      "\n",
      "Fold: 11  Epoch: 11  Training loss = 1.4767  Validation loss = 3.0216  \n",
      "\n",
      "Fold: 11  Epoch: 12  Training loss = 1.3190  Validation loss = 2.9315  \n",
      "\n",
      "Fold: 11  Epoch: 13  Training loss = 1.3476  Validation loss = 3.1865  \n",
      "\n",
      "Fold: 11  Epoch: 14  Training loss = 1.8711  Validation loss = 4.9144  \n",
      "\n",
      "Check model:  Fold: 11  Optimal epoch: 1  \n",
      "\n",
      "Fold: 12  Epoch: 1  Training loss = 1.6934  Validation loss = 1.5791  \n",
      "\n",
      "Fold: 12  Epoch: 2  Training loss = 2.1275  Validation loss = 3.9514  \n",
      "\n",
      "Fold: 12  Epoch: 3  Training loss = 1.8428  Validation loss = 3.2505  \n",
      "\n",
      "Fold: 12  Epoch: 4  Training loss = 1.5647  Validation loss = 1.2517  \n",
      "\n",
      "Fold: 12  Epoch: 5  Training loss = 1.5713  Validation loss = 1.5135  \n",
      "\n",
      "Fold: 12  Epoch: 6  Training loss = 1.2811  Validation loss = 3.2536  \n",
      "\n",
      "Fold: 12  Epoch: 7  Training loss = 1.2732  Validation loss = 3.4773  \n",
      "\n",
      "Fold: 12  Epoch: 8  Training loss = 1.1693  Validation loss = 2.3383  \n",
      "\n",
      "Fold: 12  Epoch: 9  Training loss = 1.4158  Validation loss = 3.0580  \n",
      "\n",
      "Fold: 12  Epoch: 10  Training loss = 1.3033  Validation loss = 3.8122  \n",
      "\n",
      "Fold: 12  Epoch: 11  Training loss = 1.0258  Validation loss = 3.1837  \n",
      "\n",
      "Fold: 12  Epoch: 12  Training loss = 1.1241  Validation loss = 3.7709  \n",
      "\n",
      "Fold: 12  Epoch: 13  Training loss = 1.3948  Validation loss = 3.4151  \n",
      "\n",
      "Fold: 12  Epoch: 14  Training loss = 1.0540  Validation loss = 3.8878  \n",
      "\n",
      "Check model:  Fold: 12  Optimal epoch: 4  \n",
      "\n",
      "Fold: 13  Epoch: 1  Training loss = 1.2677  Validation loss = 3.8747  \n",
      "\n",
      "Fold: 13  Epoch: 2  Training loss = 1.2829  Validation loss = 2.5560  \n",
      "\n",
      "Fold: 13  Epoch: 3  Training loss = 1.1625  Validation loss = 3.5266  \n",
      "\n",
      "Fold: 13  Epoch: 4  Training loss = 1.3639  Validation loss = 4.1882  \n",
      "\n",
      "Fold: 13  Epoch: 5  Training loss = 1.3898  Validation loss = 4.6889  \n",
      "\n",
      "Fold: 13  Epoch: 6  Training loss = 1.6737  Validation loss = 4.7503  \n",
      "\n",
      "Fold: 13  Epoch: 7  Training loss = 1.1525  Validation loss = 4.0883  \n",
      "\n",
      "Fold: 13  Epoch: 8  Training loss = 1.1057  Validation loss = 4.2368  \n",
      "\n",
      "Fold: 13  Epoch: 9  Training loss = 1.2173  Validation loss = 3.4334  \n",
      "\n",
      "Fold: 13  Epoch: 10  Training loss = 1.1617  Validation loss = 3.5965  \n",
      "\n",
      "Fold: 13  Epoch: 11  Training loss = 1.3171  Validation loss = 4.0183  \n",
      "\n",
      "Fold: 13  Epoch: 12  Training loss = 1.2070  Validation loss = 3.7398  \n",
      "\n",
      "Fold: 13  Epoch: 13  Training loss = 1.0791  Validation loss = 4.1719  \n",
      "\n",
      "Fold: 13  Epoch: 14  Training loss = 1.0939  Validation loss = 4.9288  \n",
      "\n",
      "Check model:  Fold: 13  Optimal epoch: 2  \n",
      "\n",
      "Fold: 14  Epoch: 1  Training loss = 1.4282  Validation loss = 6.0095  \n",
      "\n",
      "Fold: 14  Epoch: 2  Training loss = 1.5335  Validation loss = 6.6833  \n",
      "\n",
      "Fold: 14  Epoch: 3  Training loss = 1.3893  Validation loss = 5.7913  \n",
      "\n",
      "Fold: 14  Epoch: 4  Training loss = 1.5988  Validation loss = 6.4686  \n",
      "\n",
      "Fold: 14  Epoch: 5  Training loss = 2.0499  Validation loss = 6.6619  \n",
      "\n",
      "Fold: 14  Epoch: 6  Training loss = 1.7451  Validation loss = 5.7520  \n",
      "\n",
      "Fold: 14  Epoch: 7  Training loss = 2.0903  Validation loss = 4.2497  \n",
      "\n",
      "Fold: 14  Epoch: 8  Training loss = 1.2635  Validation loss = 6.5462  \n",
      "\n",
      "Fold: 14  Epoch: 9  Training loss = 1.5340  Validation loss = 7.5699  \n",
      "\n",
      "Fold: 14  Epoch: 10  Training loss = 1.8430  Validation loss = 7.6447  \n",
      "\n",
      "Fold: 14  Epoch: 11  Training loss = 1.4187  Validation loss = 6.5696  \n",
      "\n",
      "Fold: 14  Epoch: 12  Training loss = 1.1360  Validation loss = 5.5989  \n",
      "\n",
      "Fold: 14  Epoch: 13  Training loss = 1.2273  Validation loss = 5.4579  \n",
      "\n",
      "Fold: 14  Epoch: 14  Training loss = 1.1621  Validation loss = 5.6685  \n",
      "\n",
      "Fold: 14  Epoch: 15  Training loss = 1.5307  Validation loss = 5.3641  \n",
      "\n",
      "Fold: 14  Epoch: 16  Training loss = 1.5947  Validation loss = 7.3267  \n",
      "\n",
      "Fold: 14  Epoch: 17  Training loss = 1.1751  Validation loss = 6.3331  \n",
      "\n",
      "Fold: 14  Epoch: 18  Training loss = 1.5446  Validation loss = 7.2281  \n",
      "\n",
      "Fold: 14  Epoch: 19  Training loss = 1.1133  Validation loss = 6.5774  \n",
      "\n",
      "Fold: 14  Epoch: 20  Training loss = 1.3697  Validation loss = 6.7968  \n",
      "\n",
      "Fold: 14  Epoch: 21  Training loss = 1.0980  Validation loss = 5.9744  \n",
      "\n",
      "Fold: 14  Epoch: 22  Training loss = 1.2124  Validation loss = 6.9095  \n",
      "\n",
      "Fold: 14  Epoch: 23  Training loss = 1.1451  Validation loss = 6.1333  \n",
      "\n",
      "Fold: 14  Epoch: 24  Training loss = 1.2641  Validation loss = 5.9948  \n",
      "\n",
      "Fold: 14  Epoch: 25  Training loss = 1.3740  Validation loss = 5.4010  \n",
      "\n",
      "Fold: 14  Epoch: 26  Training loss = 1.1642  Validation loss = 6.1923  \n",
      "\n",
      "Fold: 14  Epoch: 27  Training loss = 1.2574  Validation loss = 6.8101  \n",
      "\n",
      "Fold: 14  Epoch: 28  Training loss = 1.4575  Validation loss = 7.1342  \n",
      "\n",
      "Check model:  Fold: 14  Optimal epoch: 7  \n",
      "\n",
      "Fold: 15  Epoch: 1  Training loss = 1.9612  Validation loss = 5.9280  \n",
      "\n",
      "Fold: 15  Epoch: 2  Training loss = 2.3281  Validation loss = 5.2043  \n",
      "\n",
      "Fold: 15  Epoch: 3  Training loss = 2.0921  Validation loss = 7.9649  \n",
      "\n",
      "Fold: 15  Epoch: 4  Training loss = 2.0643  Validation loss = 7.4338  \n",
      "\n",
      "Fold: 15  Epoch: 5  Training loss = 1.8475  Validation loss = 5.9046  \n",
      "\n",
      "Fold: 15  Epoch: 6  Training loss = 1.7399  Validation loss = 5.9600  \n",
      "\n",
      "Fold: 15  Epoch: 7  Training loss = 2.0075  Validation loss = 7.5628  \n",
      "\n",
      "Fold: 15  Epoch: 8  Training loss = 2.2570  Validation loss = 5.7648  \n",
      "\n",
      "Fold: 15  Epoch: 9  Training loss = 1.8857  Validation loss = 7.8156  \n",
      "\n",
      "Fold: 15  Epoch: 10  Training loss = 1.6557  Validation loss = 7.5272  \n",
      "\n",
      "Fold: 15  Epoch: 11  Training loss = 1.7007  Validation loss = 6.7537  \n",
      "\n",
      "Fold: 15  Epoch: 12  Training loss = 2.1287  Validation loss = 5.9479  \n",
      "\n",
      "Fold: 15  Epoch: 13  Training loss = 2.3508  Validation loss = 6.0028  \n",
      "\n",
      "Fold: 15  Epoch: 14  Training loss = 2.0309  Validation loss = 6.4417  \n",
      "\n",
      "Fold: 15  Epoch: 15  Training loss = 2.1003  Validation loss = 6.7286  \n",
      "\n",
      "Fold: 15  Epoch: 16  Training loss = 2.0315  Validation loss = 5.9801  \n",
      "\n",
      "Fold: 15  Epoch: 17  Training loss = 2.2477  Validation loss = 4.5766  \n",
      "\n",
      "Fold: 15  Epoch: 18  Training loss = 1.9520  Validation loss = 6.8132  \n",
      "\n",
      "Fold: 15  Epoch: 19  Training loss = 2.1866  Validation loss = 7.8286  \n",
      "\n",
      "Check model:  Fold: 15  Optimal epoch: 17  \n",
      "\n",
      "Fold: 16  Epoch: 1  Training loss = 2.5521  Validation loss = 2.9727  \n",
      "\n",
      "Fold: 16  Epoch: 2  Training loss = 2.8540  Validation loss = 4.2865  \n",
      "\n",
      "Fold: 16  Epoch: 3  Training loss = 2.6127  Validation loss = 3.2054  \n",
      "\n",
      "Fold: 16  Epoch: 4  Training loss = 2.7060  Validation loss = 3.6056  \n",
      "\n",
      "Fold: 16  Epoch: 5  Training loss = 2.7514  Validation loss = 2.3643  \n",
      "\n",
      "Fold: 16  Epoch: 6  Training loss = 2.3967  Validation loss = 3.1265  \n",
      "\n",
      "Fold: 16  Epoch: 7  Training loss = 2.6281  Validation loss = 4.3147  \n",
      "\n",
      "Fold: 16  Epoch: 8  Training loss = 2.3398  Validation loss = 3.7954  \n",
      "\n",
      "Fold: 16  Epoch: 9  Training loss = 2.8423  Validation loss = 2.2146  \n",
      "\n",
      "Fold: 16  Epoch: 10  Training loss = 3.2262  Validation loss = 4.2059  \n",
      "\n",
      "Fold: 16  Epoch: 11  Training loss = 2.3773  Validation loss = 3.7381  \n",
      "\n",
      "Fold: 16  Epoch: 12  Training loss = 3.1709  Validation loss = 3.0969  \n",
      "\n",
      "Fold: 16  Epoch: 13  Training loss = 2.6760  Validation loss = 4.8327  \n",
      "\n",
      "Check model:  Fold: 16  Optimal epoch: 9  \n",
      "\n",
      "Fold: 17  Epoch: 1  Training loss = 2.7483  Validation loss = 4.8353  \n",
      "\n",
      "Fold: 17  Epoch: 2  Training loss = 3.0275  Validation loss = 4.8285  \n",
      "\n",
      "Fold: 17  Epoch: 3  Training loss = 2.7019  Validation loss = 6.6182  \n",
      "\n",
      "Fold: 17  Epoch: 4  Training loss = 2.9151  Validation loss = 6.8314  \n",
      "\n",
      "Fold: 17  Epoch: 5  Training loss = 2.9216  Validation loss = 5.6205  \n",
      "\n",
      "Fold: 17  Epoch: 6  Training loss = 2.7295  Validation loss = 4.7224  \n",
      "\n",
      "Fold: 17  Epoch: 7  Training loss = 2.8750  Validation loss = 4.1550  \n",
      "\n",
      "Fold: 17  Epoch: 8  Training loss = 4.5267  Validation loss = 3.2476  \n",
      "\n",
      "Fold: 17  Epoch: 9  Training loss = 3.4290  Validation loss = 6.7557  \n",
      "\n",
      "Fold: 17  Epoch: 10  Training loss = 2.7140  Validation loss = 6.0994  \n",
      "\n",
      "Fold: 17  Epoch: 11  Training loss = 3.1008  Validation loss = 3.2833  \n",
      "\n",
      "Fold: 17  Epoch: 12  Training loss = 2.7570  Validation loss = 4.7855  \n",
      "\n",
      "Fold: 17  Epoch: 13  Training loss = 2.9506  Validation loss = 6.2321  \n",
      "\n",
      "Fold: 17  Epoch: 14  Training loss = 2.3870  Validation loss = 5.6988  \n",
      "\n",
      "Fold: 17  Epoch: 15  Training loss = 2.6926  Validation loss = 5.6315  \n",
      "\n",
      "Fold: 17  Epoch: 16  Training loss = 2.6643  Validation loss = 6.4585  \n",
      "\n",
      "Fold: 17  Epoch: 17  Training loss = 2.9593  Validation loss = 7.8704  \n",
      "\n",
      "Check model:  Fold: 17  Optimal epoch: 8  \n",
      "\n",
      "Fold: 18  Epoch: 1  Training loss = 2.9689  Validation loss = 5.8243  \n",
      "\n",
      "Fold: 18  Epoch: 2  Training loss = 2.9108  Validation loss = 3.2043  \n",
      "\n",
      "Fold: 18  Epoch: 3  Training loss = 2.5742  Validation loss = 3.8378  \n",
      "\n",
      "Fold: 18  Epoch: 4  Training loss = 3.2141  Validation loss = 5.6653  \n",
      "\n",
      "Fold: 18  Epoch: 5  Training loss = 2.9460  Validation loss = 4.0002  \n",
      "\n",
      "Fold: 18  Epoch: 6  Training loss = 3.3920  Validation loss = 3.5101  \n",
      "\n",
      "Fold: 18  Epoch: 7  Training loss = 2.9414  Validation loss = 2.7748  \n",
      "\n",
      "Fold: 18  Epoch: 8  Training loss = 2.6553  Validation loss = 2.8404  \n",
      "\n",
      "Fold: 18  Epoch: 9  Training loss = 2.5750  Validation loss = 2.4481  \n",
      "\n",
      "Fold: 18  Epoch: 10  Training loss = 2.8498  Validation loss = 2.1374  \n",
      "\n",
      "Fold: 18  Epoch: 11  Training loss = 2.8826  Validation loss = 4.0621  \n",
      "\n",
      "Fold: 18  Epoch: 12  Training loss = 2.7387  Validation loss = 3.1992  \n",
      "\n",
      "Fold: 18  Epoch: 13  Training loss = 2.8965  Validation loss = 2.2535  \n",
      "\n",
      "Fold: 18  Epoch: 14  Training loss = 2.6018  Validation loss = 2.4081  \n",
      "\n",
      "Fold: 18  Epoch: 15  Training loss = 2.5978  Validation loss = 2.7003  \n",
      "\n",
      "Fold: 18  Epoch: 16  Training loss = 2.5426  Validation loss = 3.6709  \n",
      "\n",
      "Fold: 18  Epoch: 17  Training loss = 2.7876  Validation loss = 2.7030  \n",
      "\n",
      "Fold: 18  Epoch: 18  Training loss = 2.3724  Validation loss = 2.2740  \n",
      "\n",
      "Fold: 18  Epoch: 19  Training loss = 2.5392  Validation loss = 3.3282  \n",
      "\n",
      "Fold: 18  Epoch: 20  Training loss = 2.4559  Validation loss = 3.2066  \n",
      "\n",
      "Fold: 18  Epoch: 21  Training loss = 2.8848  Validation loss = 3.0160  \n",
      "\n",
      "Fold: 18  Epoch: 22  Training loss = 2.3715  Validation loss = 3.7598  \n",
      "\n",
      "Check model:  Fold: 18  Optimal epoch: 10  \n",
      "\n",
      "Fold: 19  Epoch: 1  Training loss = 2.9918  Validation loss = 3.9754  \n",
      "\n",
      "Fold: 19  Epoch: 2  Training loss = 3.7878  Validation loss = 3.9584  \n",
      "\n",
      "Fold: 19  Epoch: 3  Training loss = 2.9456  Validation loss = 2.5848  \n",
      "\n",
      "Fold: 19  Epoch: 4  Training loss = 2.6248  Validation loss = 2.8913  \n",
      "\n",
      "Fold: 19  Epoch: 5  Training loss = 4.1730  Validation loss = 2.0893  \n",
      "\n",
      "Fold: 19  Epoch: 6  Training loss = 2.4276  Validation loss = 3.3880  \n",
      "\n",
      "Fold: 19  Epoch: 7  Training loss = 2.6114  Validation loss = 2.7679  \n",
      "\n",
      "Fold: 19  Epoch: 8  Training loss = 2.7461  Validation loss = 2.7141  \n",
      "\n",
      "Fold: 19  Epoch: 9  Training loss = 2.7313  Validation loss = 0.9741  \n",
      "\n",
      "Fold: 19  Epoch: 10  Training loss = 3.4713  Validation loss = 2.7557  \n",
      "\n",
      "Fold: 19  Epoch: 11  Training loss = 2.5746  Validation loss = 2.9916  \n",
      "\n",
      "Fold: 19  Epoch: 12  Training loss = 2.8963  Validation loss = 3.4628  \n",
      "\n",
      "Check model:  Fold: 19  Optimal epoch: 9  \n",
      "\n",
      "Fold: 20  Epoch: 1  Training loss = 2.9805  Validation loss = 2.5602  \n",
      "\n",
      "Fold: 20  Epoch: 2  Training loss = 2.5094  Validation loss = 2.9539  \n",
      "\n",
      "Fold: 20  Epoch: 3  Training loss = 2.5546  Validation loss = 3.1257  \n",
      "\n",
      "Fold: 20  Epoch: 4  Training loss = 2.6502  Validation loss = 3.0602  \n",
      "\n",
      "Fold: 20  Epoch: 5  Training loss = 2.6004  Validation loss = 3.3589  \n",
      "\n",
      "Fold: 20  Epoch: 6  Training loss = 2.6044  Validation loss = 4.6051  \n",
      "\n",
      "Fold: 20  Epoch: 7  Training loss = 2.9311  Validation loss = 3.6448  \n",
      "\n",
      "Fold: 20  Epoch: 8  Training loss = 3.2043  Validation loss = 4.8664  \n",
      "\n",
      "Fold: 20  Epoch: 9  Training loss = 2.8082  Validation loss = 4.4213  \n",
      "\n",
      "Fold: 20  Epoch: 10  Training loss = 2.8728  Validation loss = 5.0497  \n",
      "\n",
      "Fold: 20  Epoch: 11  Training loss = 2.3427  Validation loss = 4.4570  \n",
      "\n",
      "Fold: 20  Epoch: 12  Training loss = 2.9275  Validation loss = 1.9872  \n",
      "\n",
      "Fold: 20  Epoch: 13  Training loss = 3.1342  Validation loss = 5.7111  \n",
      "\n",
      "Check model:  Fold: 20  Optimal epoch: 12  \n",
      "\n",
      "Fold: 21  Epoch: 1  Training loss = 2.8468  Validation loss = 6.5381  \n",
      "\n",
      "Fold: 21  Epoch: 2  Training loss = 3.4916  Validation loss = 6.6762  \n",
      "\n",
      "Fold: 21  Epoch: 3  Training loss = 2.6673  Validation loss = 3.9487  \n",
      "\n",
      "Fold: 21  Epoch: 4  Training loss = 2.7949  Validation loss = 3.9895  \n",
      "\n",
      "Fold: 21  Epoch: 5  Training loss = 2.5254  Validation loss = 2.9687  \n",
      "\n",
      "Fold: 21  Epoch: 6  Training loss = 3.1510  Validation loss = 3.9471  \n",
      "\n",
      "Fold: 21  Epoch: 7  Training loss = 2.6824  Validation loss = 4.5015  \n",
      "\n",
      "Fold: 21  Epoch: 8  Training loss = 3.0546  Validation loss = 3.7912  \n",
      "\n",
      "Fold: 21  Epoch: 9  Training loss = 2.8107  Validation loss = 3.9111  \n",
      "\n",
      "Fold: 21  Epoch: 10  Training loss = 2.9373  Validation loss = 3.0947  \n",
      "\n",
      "Fold: 21  Epoch: 11  Training loss = 3.8010  Validation loss = 5.1105  \n",
      "\n",
      "Fold: 21  Epoch: 12  Training loss = 2.5684  Validation loss = 3.9870  \n",
      "\n",
      "Fold: 21  Epoch: 13  Training loss = 2.5498  Validation loss = 3.6253  \n",
      "\n",
      "Fold: 21  Epoch: 14  Training loss = 2.6000  Validation loss = 2.9850  \n",
      "\n",
      "Fold: 21  Epoch: 15  Training loss = 3.4304  Validation loss = 3.1020  \n",
      "\n",
      "Fold: 21  Epoch: 16  Training loss = 2.4903  Validation loss = 3.1261  \n",
      "\n",
      "Fold: 21  Epoch: 17  Training loss = 2.4987  Validation loss = 3.3148  \n",
      "\n",
      "Fold: 21  Epoch: 18  Training loss = 2.9441  Validation loss = 3.0632  \n",
      "\n",
      "Fold: 21  Epoch: 19  Training loss = 3.4181  Validation loss = 3.4246  \n",
      "\n",
      "Fold: 21  Epoch: 20  Training loss = 2.6106  Validation loss = 3.7996  \n",
      "\n",
      "Fold: 21  Epoch: 21  Training loss = 2.5879  Validation loss = 2.6802  \n",
      "\n",
      "Fold: 21  Epoch: 22  Training loss = 2.4339  Validation loss = 3.7232  \n",
      "\n",
      "Fold: 21  Epoch: 23  Training loss = 2.7134  Validation loss = 3.0642  \n",
      "\n",
      "Fold: 21  Epoch: 24  Training loss = 3.0423  Validation loss = 3.3714  \n",
      "\n",
      "Fold: 21  Epoch: 25  Training loss = 2.7098  Validation loss = 3.8096  \n",
      "\n",
      "Check model:  Fold: 21  Optimal epoch: 21  \n",
      "\n",
      "Fold: 22  Epoch: 1  Training loss = 2.8454  Validation loss = 4.3892  \n",
      "\n",
      "Fold: 22  Epoch: 2  Training loss = 2.4348  Validation loss = 3.5718  \n",
      "\n",
      "Fold: 22  Epoch: 3  Training loss = 2.5349  Validation loss = 2.3592  \n",
      "\n",
      "Fold: 22  Epoch: 4  Training loss = 2.8126  Validation loss = 2.6067  \n",
      "\n",
      "Fold: 22  Epoch: 5  Training loss = 2.5701  Validation loss = 1.8421  \n",
      "\n",
      "Fold: 22  Epoch: 6  Training loss = 2.6691  Validation loss = 3.4613  \n",
      "\n",
      "Fold: 22  Epoch: 7  Training loss = 3.8863  Validation loss = 2.0659  \n",
      "\n",
      "Fold: 22  Epoch: 8  Training loss = 2.5930  Validation loss = 4.5016  \n",
      "\n",
      "Fold: 22  Epoch: 9  Training loss = 2.9817  Validation loss = 3.5539  \n",
      "\n",
      "Fold: 22  Epoch: 10  Training loss = 2.4816  Validation loss = 4.7304  \n",
      "\n",
      "Fold: 22  Epoch: 11  Training loss = 2.7221  Validation loss = 3.7348  \n",
      "\n",
      "Fold: 22  Epoch: 12  Training loss = 2.9721  Validation loss = 2.5895  \n",
      "\n",
      "Fold: 22  Epoch: 13  Training loss = 3.2209  Validation loss = 6.2226  \n",
      "\n",
      "Check model:  Fold: 22  Optimal epoch: 5  \n",
      "\n",
      "Fold: 23  Epoch: 1  Training loss = 3.6155  Validation loss = 2.9163  \n",
      "\n",
      "Fold: 23  Epoch: 2  Training loss = 2.6217  Validation loss = 4.6351  \n",
      "\n",
      "Fold: 23  Epoch: 3  Training loss = 2.4625  Validation loss = 2.6019  \n",
      "\n",
      "Fold: 23  Epoch: 4  Training loss = 2.4421  Validation loss = 2.8382  \n",
      "\n",
      "Fold: 23  Epoch: 5  Training loss = 2.4030  Validation loss = 3.5444  \n",
      "\n",
      "Fold: 23  Epoch: 6  Training loss = 2.4260  Validation loss = 2.9499  \n",
      "\n",
      "Fold: 23  Epoch: 7  Training loss = 2.8462  Validation loss = 2.2489  \n",
      "\n",
      "Fold: 23  Epoch: 8  Training loss = 2.2620  Validation loss = 2.5020  \n",
      "\n",
      "Fold: 23  Epoch: 9  Training loss = 2.4679  Validation loss = 3.1970  \n",
      "\n",
      "Fold: 23  Epoch: 10  Training loss = 3.4156  Validation loss = 3.3111  \n",
      "\n",
      "Fold: 23  Epoch: 11  Training loss = 2.4412  Validation loss = 2.9342  \n",
      "\n",
      "Fold: 23  Epoch: 12  Training loss = 3.1987  Validation loss = 3.1900  \n",
      "\n",
      "Fold: 23  Epoch: 13  Training loss = 3.1130  Validation loss = 3.6445  \n",
      "\n",
      "Check model:  Fold: 23  Optimal epoch: 7  \n",
      "\n",
      "Fold: 24  Epoch: 1  Training loss = 2.8514  Validation loss = 4.3277  \n",
      "\n",
      "Fold: 24  Epoch: 2  Training loss = 2.9901  Validation loss = 0.8559  \n",
      "\n",
      "Fold: 24  Epoch: 3  Training loss = 2.6893  Validation loss = 3.6539  \n",
      "\n",
      "Fold: 24  Epoch: 4  Training loss = 3.2813  Validation loss = 4.7514  \n",
      "\n",
      "Fold: 24  Epoch: 5  Training loss = 2.5138  Validation loss = 1.7317  \n",
      "\n",
      "Fold: 24  Epoch: 6  Training loss = 2.5191  Validation loss = 2.0108  \n",
      "\n",
      "Fold: 24  Epoch: 7  Training loss = 2.6059  Validation loss = 3.5925  \n",
      "\n",
      "Fold: 24  Epoch: 8  Training loss = 2.2824  Validation loss = 2.3756  \n",
      "\n",
      "Fold: 24  Epoch: 9  Training loss = 2.1012  Validation loss = 2.0843  \n",
      "\n",
      "Fold: 24  Epoch: 10  Training loss = 2.5981  Validation loss = 1.9012  \n",
      "\n",
      "Fold: 24  Epoch: 11  Training loss = 2.6201  Validation loss = 2.5857  \n",
      "\n",
      "Fold: 24  Epoch: 12  Training loss = 2.3721  Validation loss = 1.7265  \n",
      "\n",
      "Fold: 24  Epoch: 13  Training loss = 2.2394  Validation loss = 1.3156  \n",
      "\n",
      "Fold: 24  Epoch: 14  Training loss = 2.1666  Validation loss = 1.5403  \n",
      "\n",
      "Fold: 24  Epoch: 15  Training loss = 2.6896  Validation loss = 1.1557  \n",
      "\n",
      "Fold: 24  Epoch: 16  Training loss = 2.1886  Validation loss = 1.9221  \n",
      "\n",
      "Fold: 24  Epoch: 17  Training loss = 2.3415  Validation loss = 3.1996  \n",
      "\n",
      "Check model:  Fold: 24  Optimal epoch: 2  \n",
      "\n",
      "Fold: 25  Epoch: 1  Training loss = 2.6286  Validation loss = 3.1687  \n",
      "\n",
      "Fold: 25  Epoch: 2  Training loss = 2.4027  Validation loss = 3.2239  \n",
      "\n",
      "Fold: 25  Epoch: 3  Training loss = 2.4806  Validation loss = 4.8942  \n",
      "\n",
      "Fold: 25  Epoch: 4  Training loss = 2.2889  Validation loss = 3.4960  \n",
      "\n",
      "Fold: 25  Epoch: 5  Training loss = 2.2699  Validation loss = 2.9652  \n",
      "\n",
      "Fold: 25  Epoch: 6  Training loss = 2.6368  Validation loss = 4.8869  \n",
      "\n",
      "Fold: 25  Epoch: 7  Training loss = 2.8650  Validation loss = 3.3387  \n",
      "\n",
      "Fold: 25  Epoch: 8  Training loss = 2.1798  Validation loss = 4.2082  \n",
      "\n",
      "Fold: 25  Epoch: 9  Training loss = 2.4672  Validation loss = 4.9645  \n",
      "\n",
      "Fold: 25  Epoch: 10  Training loss = 3.5874  Validation loss = 4.0697  \n",
      "\n",
      "Fold: 25  Epoch: 11  Training loss = 2.2754  Validation loss = 3.2543  \n",
      "\n",
      "Fold: 25  Epoch: 12  Training loss = 2.4889  Validation loss = 2.3875  \n",
      "\n",
      "Fold: 25  Epoch: 13  Training loss = 2.2213  Validation loss = 2.4158  \n",
      "\n",
      "Fold: 25  Epoch: 14  Training loss = 2.5537  Validation loss = 2.6746  \n",
      "\n",
      "Fold: 25  Epoch: 15  Training loss = 2.4743  Validation loss = 2.9282  \n",
      "\n",
      "Fold: 25  Epoch: 16  Training loss = 2.2966  Validation loss = 2.8087  \n",
      "\n",
      "Fold: 25  Epoch: 17  Training loss = 2.7115  Validation loss = 4.3660  \n",
      "\n",
      "Fold: 25  Epoch: 18  Training loss = 2.3683  Validation loss = 2.9275  \n",
      "\n",
      "Fold: 25  Epoch: 19  Training loss = 1.9465  Validation loss = 2.3506  \n",
      "\n",
      "Fold: 25  Epoch: 20  Training loss = 2.8641  Validation loss = 2.8219  \n",
      "\n",
      "Fold: 25  Epoch: 21  Training loss = 2.8581  Validation loss = 4.9513  \n",
      "\n",
      "Check model:  Fold: 25  Optimal epoch: 19  \n",
      "\n",
      "Fold: 26  Epoch: 1  Training loss = 2.4317  Validation loss = 2.7626  \n",
      "\n",
      "Fold: 26  Epoch: 2  Training loss = 2.5301  Validation loss = 3.1349  \n",
      "\n",
      "Fold: 26  Epoch: 3  Training loss = 3.0255  Validation loss = 4.3061  \n",
      "\n",
      "Fold: 26  Epoch: 4  Training loss = 2.5414  Validation loss = 2.1706  \n",
      "\n",
      "Fold: 26  Epoch: 5  Training loss = 2.2735  Validation loss = 2.3429  \n",
      "\n",
      "Fold: 26  Epoch: 6  Training loss = 2.4980  Validation loss = 1.0963  \n",
      "\n",
      "Fold: 26  Epoch: 7  Training loss = 2.4280  Validation loss = 1.8507  \n",
      "\n",
      "Fold: 26  Epoch: 8  Training loss = 2.6594  Validation loss = 3.7290  \n",
      "\n",
      "Fold: 26  Epoch: 9  Training loss = 2.1656  Validation loss = 2.4438  \n",
      "\n",
      "Fold: 26  Epoch: 10  Training loss = 2.8980  Validation loss = 4.7094  \n",
      "\n",
      "Fold: 26  Epoch: 11  Training loss = 2.1433  Validation loss = 2.9083  \n",
      "\n",
      "Fold: 26  Epoch: 12  Training loss = 2.0594  Validation loss = 2.1712  \n",
      "\n",
      "Fold: 26  Epoch: 13  Training loss = 2.3263  Validation loss = 0.9868  \n",
      "\n",
      "Fold: 26  Epoch: 14  Training loss = 2.6432  Validation loss = 1.9459  \n",
      "\n",
      "Fold: 26  Epoch: 15  Training loss = 2.0036  Validation loss = 3.0248  \n",
      "\n",
      "Fold: 26  Epoch: 16  Training loss = 2.3860  Validation loss = 0.8203  \n",
      "\n",
      "Fold: 26  Epoch: 17  Training loss = 1.8604  Validation loss = 2.5077  \n",
      "\n",
      "Fold: 26  Epoch: 18  Training loss = 1.9036  Validation loss = 2.4414  \n",
      "\n",
      "Fold: 26  Epoch: 19  Training loss = 2.0941  Validation loss = 1.4423  \n",
      "\n",
      "Fold: 26  Epoch: 20  Training loss = 1.9877  Validation loss = 1.8594  \n",
      "\n",
      "Fold: 26  Epoch: 21  Training loss = 2.3874  Validation loss = 1.9470  \n",
      "\n",
      "Fold: 26  Epoch: 22  Training loss = 2.4799  Validation loss = 1.4553  \n",
      "\n",
      "Fold: 26  Epoch: 23  Training loss = 3.3390  Validation loss = 3.6427  \n",
      "\n",
      "Check model:  Fold: 26  Optimal epoch: 16  \n",
      "\n",
      "Fold: 27  Epoch: 1  Training loss = 2.9732  Validation loss = 4.3021  \n",
      "\n",
      "Fold: 27  Epoch: 2  Training loss = 2.9711  Validation loss = 0.6489  \n",
      "\n",
      "Fold: 27  Epoch: 3  Training loss = 2.2863  Validation loss = 1.7751  \n",
      "\n",
      "Fold: 27  Epoch: 4  Training loss = 2.5184  Validation loss = 2.2887  \n",
      "\n",
      "Fold: 27  Epoch: 5  Training loss = 2.5045  Validation loss = 1.4699  \n",
      "\n",
      "Fold: 27  Epoch: 6  Training loss = 2.3123  Validation loss = 0.9295  \n",
      "\n",
      "Fold: 27  Epoch: 7  Training loss = 2.4655  Validation loss = 0.6408  \n",
      "\n",
      "Fold: 27  Epoch: 8  Training loss = 2.4055  Validation loss = 1.5728  \n",
      "\n",
      "Fold: 27  Epoch: 9  Training loss = 2.3287  Validation loss = 1.4874  \n",
      "\n",
      "Fold: 27  Epoch: 10  Training loss = 2.7590  Validation loss = 0.7745  \n",
      "\n",
      "Fold: 27  Epoch: 11  Training loss = 2.3145  Validation loss = 1.8964  \n",
      "\n",
      "Fold: 27  Epoch: 12  Training loss = 2.6420  Validation loss = 1.4270  \n",
      "\n",
      "Fold: 27  Epoch: 13  Training loss = 2.5668  Validation loss = 2.2833  \n",
      "\n",
      "Fold: 27  Epoch: 14  Training loss = 2.4864  Validation loss = 2.3249  \n",
      "\n",
      "Check model:  Fold: 27  Optimal epoch: 7  \n",
      "\n",
      "Fold: 28  Epoch: 1  Training loss = 2.1837  Validation loss = 1.4219  \n",
      "\n",
      "Fold: 28  Epoch: 2  Training loss = 2.0376  Validation loss = 1.4696  \n",
      "\n",
      "Fold: 28  Epoch: 3  Training loss = 2.5438  Validation loss = 2.3456  \n",
      "\n",
      "Fold: 28  Epoch: 4  Training loss = 2.2809  Validation loss = 2.4227  \n",
      "\n",
      "Fold: 28  Epoch: 5  Training loss = 2.1752  Validation loss = 1.4528  \n",
      "\n",
      "Fold: 28  Epoch: 6  Training loss = 2.0955  Validation loss = 1.3197  \n",
      "\n",
      "Fold: 28  Epoch: 7  Training loss = 2.1833  Validation loss = 1.1726  \n",
      "\n",
      "Fold: 28  Epoch: 8  Training loss = 2.2894  Validation loss = 2.4346  \n",
      "\n",
      "Fold: 28  Epoch: 9  Training loss = 2.5832  Validation loss = 2.7817  \n",
      "\n",
      "Fold: 28  Epoch: 10  Training loss = 2.0804  Validation loss = 1.5983  \n",
      "\n",
      "Fold: 28  Epoch: 11  Training loss = 2.3796  Validation loss = 1.9882  \n",
      "\n",
      "Fold: 28  Epoch: 12  Training loss = 1.9770  Validation loss = 1.1730  \n",
      "\n",
      "Fold: 28  Epoch: 13  Training loss = 2.4270  Validation loss = 1.0741  \n",
      "\n",
      "Fold: 28  Epoch: 14  Training loss = 2.6413  Validation loss = 1.0437  \n",
      "\n",
      "Fold: 28  Epoch: 15  Training loss = 2.2659  Validation loss = 0.9029  \n",
      "\n",
      "Fold: 28  Epoch: 16  Training loss = 2.0562  Validation loss = 1.3605  \n",
      "\n",
      "Fold: 28  Epoch: 17  Training loss = 2.1250  Validation loss = 0.8368  \n",
      "\n",
      "Fold: 28  Epoch: 18  Training loss = 2.1215  Validation loss = 2.3082  \n",
      "\n",
      "Fold: 28  Epoch: 19  Training loss = 2.2871  Validation loss = 3.0243  \n",
      "\n",
      "Check model:  Fold: 28  Optimal epoch: 17  \n",
      "\n",
      "Fold: 29  Epoch: 1  Training loss = 2.1368  Validation loss = 1.2173  \n",
      "\n",
      "Fold: 29  Epoch: 2  Training loss = 1.9387  Validation loss = 2.3754  \n",
      "\n",
      "Fold: 29  Epoch: 3  Training loss = 1.7633  Validation loss = 3.2937  \n",
      "\n",
      "Fold: 29  Epoch: 4  Training loss = 1.9166  Validation loss = 3.4564  \n",
      "\n",
      "Fold: 29  Epoch: 5  Training loss = 1.9016  Validation loss = 3.6447  \n",
      "\n",
      "Fold: 29  Epoch: 6  Training loss = 1.8091  Validation loss = 2.5273  \n",
      "\n",
      "Fold: 29  Epoch: 7  Training loss = 1.7392  Validation loss = 2.0824  \n",
      "\n",
      "Fold: 29  Epoch: 8  Training loss = 2.9514  Validation loss = 1.7597  \n",
      "\n",
      "Fold: 29  Epoch: 9  Training loss = 2.3049  Validation loss = 0.2364  \n",
      "\n",
      "Fold: 29  Epoch: 10  Training loss = 1.9621  Validation loss = 1.1237  \n",
      "\n",
      "Fold: 29  Epoch: 11  Training loss = 2.0188  Validation loss = 1.0587  \n",
      "\n",
      "Fold: 29  Epoch: 12  Training loss = 2.1466  Validation loss = 2.9169  \n",
      "\n",
      "Fold: 29  Epoch: 13  Training loss = 3.8264  Validation loss = 5.9723  \n",
      "\n",
      "Check model:  Fold: 29  Optimal epoch: 9  \n",
      "\n",
      "Fold: 30  Epoch: 1  Training loss = 2.8048  Validation loss = 1.1038  \n",
      "\n",
      "Fold: 30  Epoch: 2  Training loss = 2.4905  Validation loss = 1.8337  \n",
      "\n",
      "Fold: 30  Epoch: 3  Training loss = 2.7788  Validation loss = 1.0352  \n",
      "\n",
      "Fold: 30  Epoch: 4  Training loss = 1.6965  Validation loss = 1.4843  \n",
      "\n",
      "Fold: 30  Epoch: 5  Training loss = 2.0326  Validation loss = 1.1670  \n",
      "\n",
      "Fold: 30  Epoch: 6  Training loss = 1.5945  Validation loss = 1.1668  \n",
      "\n",
      "Fold: 30  Epoch: 7  Training loss = 2.4455  Validation loss = 3.6516  \n",
      "\n",
      "Fold: 30  Epoch: 8  Training loss = 1.5369  Validation loss = 0.8862  \n",
      "\n",
      "Fold: 30  Epoch: 9  Training loss = 2.5914  Validation loss = 1.0978  \n",
      "\n",
      "Fold: 30  Epoch: 10  Training loss = 1.9382  Validation loss = 1.0213  \n",
      "\n",
      "Fold: 30  Epoch: 11  Training loss = 1.5625  Validation loss = 0.9512  \n",
      "\n",
      "Fold: 30  Epoch: 12  Training loss = 2.1589  Validation loss = 1.0365  \n",
      "\n",
      "Fold: 30  Epoch: 13  Training loss = 1.5980  Validation loss = 1.0774  \n",
      "\n",
      "Fold: 30  Epoch: 14  Training loss = 2.0256  Validation loss = 1.1519  \n",
      "\n",
      "Fold: 30  Epoch: 15  Training loss = 4.5799  Validation loss = 1.0908  \n",
      "\n",
      "Fold: 30  Epoch: 16  Training loss = 2.1692  Validation loss = 0.9703  \n",
      "\n",
      "Fold: 30  Epoch: 17  Training loss = 4.1555  Validation loss = 2.3990  \n",
      "\n",
      "Check model:  Fold: 30  Optimal epoch: 8  \n",
      "\n",
      "Fold: 31  Epoch: 1  Training loss = 3.3053  Validation loss = 6.0063  \n",
      "\n",
      "Fold: 31  Epoch: 2  Training loss = 1.6259  Validation loss = 1.2065  \n",
      "\n",
      "Fold: 31  Epoch: 3  Training loss = 1.7161  Validation loss = 0.5831  \n",
      "\n",
      "Fold: 31  Epoch: 4  Training loss = 1.9534  Validation loss = 2.9160  \n",
      "\n",
      "Fold: 31  Epoch: 5  Training loss = 2.0628  Validation loss = 3.3706  \n",
      "\n",
      "Fold: 31  Epoch: 6  Training loss = 2.4772  Validation loss = 4.5051  \n",
      "\n",
      "Fold: 31  Epoch: 7  Training loss = 1.9907  Validation loss = 0.8279  \n",
      "\n",
      "Fold: 31  Epoch: 8  Training loss = 1.5184  Validation loss = 2.1248  \n",
      "\n",
      "Fold: 31  Epoch: 9  Training loss = 2.5898  Validation loss = 4.7974  \n",
      "\n",
      "Fold: 31  Epoch: 10  Training loss = 1.5894  Validation loss = 2.5282  \n",
      "\n",
      "Fold: 31  Epoch: 11  Training loss = 2.0282  Validation loss = 0.3378  \n",
      "\n",
      "Fold: 31  Epoch: 12  Training loss = 1.6273  Validation loss = 0.5079  \n",
      "\n",
      "Fold: 31  Epoch: 13  Training loss = 1.5054  Validation loss = 1.0175  \n",
      "\n",
      "Fold: 31  Epoch: 14  Training loss = 2.2159  Validation loss = 0.9321  \n",
      "\n",
      "Fold: 31  Epoch: 15  Training loss = 1.6183  Validation loss = 0.6556  \n",
      "\n",
      "Fold: 31  Epoch: 16  Training loss = 1.7700  Validation loss = 3.1079  \n",
      "\n",
      "Fold: 31  Epoch: 17  Training loss = 1.5593  Validation loss = 0.5185  \n",
      "\n",
      "Fold: 31  Epoch: 18  Training loss = 1.5237  Validation loss = 0.5963  \n",
      "\n",
      "Fold: 31  Epoch: 19  Training loss = 1.4014  Validation loss = 1.9754  \n",
      "\n",
      "Fold: 31  Epoch: 20  Training loss = 2.0307  Validation loss = 0.7944  \n",
      "\n",
      "Fold: 31  Epoch: 21  Training loss = 1.4987  Validation loss = 0.9512  \n",
      "\n",
      "Fold: 31  Epoch: 22  Training loss = 1.4875  Validation loss = 0.6014  \n",
      "\n",
      "Fold: 31  Epoch: 23  Training loss = 1.7578  Validation loss = 2.7867  \n",
      "\n",
      "Fold: 31  Epoch: 24  Training loss = 1.6142  Validation loss = 0.6693  \n",
      "\n",
      "Fold: 31  Epoch: 25  Training loss = 1.4540  Validation loss = 0.7628  \n",
      "\n",
      "Fold: 31  Epoch: 26  Training loss = 1.7522  Validation loss = 2.9280  \n",
      "\n",
      "Check model:  Fold: 31  Optimal epoch: 11  \n",
      "\n",
      "Fold: 32  Epoch: 1  Training loss = 1.8360  Validation loss = 5.8279  \n",
      "\n",
      "Fold: 32  Epoch: 2  Training loss = 1.8460  Validation loss = 4.7124  \n",
      "\n",
      "Fold: 32  Epoch: 3  Training loss = 2.1125  Validation loss = 4.7191  \n",
      "\n",
      "Fold: 32  Epoch: 4  Training loss = 1.5743  Validation loss = 5.1692  \n",
      "\n",
      "Fold: 32  Epoch: 5  Training loss = 2.1876  Validation loss = 7.2817  \n",
      "\n",
      "Fold: 32  Epoch: 6  Training loss = 1.5739  Validation loss = 4.9821  \n",
      "\n",
      "Fold: 32  Epoch: 7  Training loss = 1.9625  Validation loss = 4.7718  \n",
      "\n",
      "Fold: 32  Epoch: 8  Training loss = 4.0321  Validation loss = 3.4494  \n",
      "\n",
      "Fold: 32  Epoch: 9  Training loss = 1.5237  Validation loss = 5.4890  \n",
      "\n",
      "Fold: 32  Epoch: 10  Training loss = 1.4698  Validation loss = 5.5198  \n",
      "\n",
      "Fold: 32  Epoch: 11  Training loss = 9.6589  Validation loss = 13.9722  \n",
      "\n",
      "Check model:  Fold: 32  Optimal epoch: 8  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 2. Train model\n",
    "# ==================================\n",
    "sess = tf.InteractiveSession()  # Launch Graph\n",
    "sess.run(tf.global_variables_initializer())  # Initialise all variables\n",
    "\n",
    "print(\"Start training\", \n",
    "      \"\\nHyperparameters:\",\n",
    "      \"\\nDimension of recurrent unit =\", n_hidden,\n",
    "      \"\\nLearning rate =\", learning_rate,\n",
    "      \"\\nEpochs =\", epochs,\n",
    "      \"\\nBatch size =\", batch_size,\n",
    "      \"\\nEarly stopping epochs =\", early_stop_iters,\n",
    "      \"\\nLearning rate =\", learning_rate)\n",
    "\n",
    "total_batch = int(window_length / batch_size)\n",
    "validation_fold_error = [] # store validation error of each fold\n",
    "optimal_epochs = []\n",
    "\n",
    "# loop through folds\n",
    "for fold in range(1, len(valIndex)):\n",
    "    validx = train_features[valIndex[fold-1]:valIndex[fold]]\n",
    "    validy = train_target[valIndex[fold-1]:valIndex[fold]]\n",
    "    trainx = train_features[(fold-1)*4:valIndex[(fold-1)]]\n",
    "    trainy = train_target[(fold-1)*4:valIndex[(fold-1)]]\n",
    "\n",
    "    loss_list = [] # store validation loss after each epoch for early stopping\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i in range(total_batch):\n",
    "            # Backprop\n",
    "            batch_xs, batch_ys = next_batch(num=batch_size, data=trainx, labels=trainy)\n",
    "            optimizer.run(feed_dict={x:batch_xs, y:batch_ys, lr:learning_rate})\n",
    "\n",
    "        # Loss\n",
    "        loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "        loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "        loss_list.append(loss_valid)\n",
    "\n",
    "        print(\"Fold: {0:d}\".format(fold),\n",
    "              \" Epoch: {0:d}\".format(epoch+1),\n",
    "              \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "              \" Validation loss = {0:.4f}\".format(np.sqrt(loss_valid)),\n",
    "              \" \\n\")\n",
    "\n",
    "        if all(j <= loss_valid for j in loss_list[-early_stop_iters:]) and len(loss_list)>early_stop_iters:\n",
    "            break\n",
    "    \n",
    "    # Load model with lowest validation error for each fold\n",
    "    epoch_hat = np.argmin(loss_list) + 1\n",
    "    optimal_epochs.append(epoch_hat) # store optimal number of epochs for each fold\n",
    "    \n",
    "    # RMSE\n",
    "    loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "    loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "    validation_fold_error.append(np.sqrt(loss_valid))\n",
    "    \n",
    "    print(\"Check model:\",\n",
    "          \" Fold: {0:d}\".format(fold),\n",
    "          \" Optimal epoch: {0:d}\".format(epoch_hat),\n",
    "          \" \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average number of epochs: 11\n",
      "Average validation error: 4.71184\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 3. Optimal epoch choice\n",
    "# ==================================\n",
    "# Pick number of epochs to train model for out-of-sample testing\n",
    "epoch_hat = int(np.mean(optimal_epochs))\n",
    "print(\"\\nAverage number of epochs:\", epoch_hat)\n",
    "# Average validation error\n",
    "print(\"Average validation error:\", np.mean(validation_fold_error))\n",
    "\n",
    "# Save validated model\n",
    "saveModel(sess, \n",
    "          MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + str(epoch_hat) + \"_validated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fixed scheme:\n",
      "Epoch: 1  Training loss = 3.0032  Test loss = 3.7655  \n",
      "\n",
      "Epoch: 2  Training loss = 1.8141  Test loss = 4.6614  \n",
      "\n",
      "Epoch: 3  Training loss = 1.6177  Test loss = 4.0888  \n",
      "\n",
      "Epoch: 4  Training loss = 1.5598  Test loss = 4.1734  \n",
      "\n",
      "Epoch: 5  Training loss = 1.5199  Test loss = 4.0735  \n",
      "\n",
      "Epoch: 6  Training loss = 1.4839  Test loss = 4.0413  \n",
      "\n",
      "Epoch: 7  Training loss = 1.4503  Test loss = 3.9926  \n",
      "\n",
      "Epoch: 8  Training loss = 1.4194  Test loss = 3.9543  \n",
      "\n",
      "Epoch: 9  Training loss = 1.3913  Test loss = 3.9168  \n",
      "\n",
      "Epoch: 10  Training loss = 1.3655  Test loss = 3.8819  \n",
      "\n",
      "Epoch: 11  Training loss = 1.3417  Test loss = 3.8479  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 4. Fixed scheme\n",
    "# ==================================\n",
    "print(\"\\nFixed scheme:\")\n",
    "for epoch in range(epoch_hat):\n",
    "    x_train = train_features[-window_length:]\n",
    "    y_train = train_target[-window_length:]\n",
    "    optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:test_features, y:test_target})\n",
    "    print(\"Epoch: {0:d}\".format(epoch+1),\n",
    "          \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "          \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "          \" \\n\")\n",
    "\n",
    "# Forecasts\n",
    "yhat_test_fixed = pred.eval(feed_dict={x:test_features})\n",
    "yhat_train_fixed = pred.eval(feed_dict={x:x_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc09b8ac750>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train set\n",
    "plt.plot(y_train, 'black')\n",
    "plt.plot(yhat_train_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nz+O5DikmAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc098091690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: fixed scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_test_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed scheme RMSE: 3.84786922388 \n",
      "Fixed scheme MAE:  2.72411960124\n"
     ]
    }
   ],
   "source": [
    "rmse_fixed = np.sqrt(np.mean((yhat_test_fixed[:,0]-test_target)**2))\n",
    "mae_fixed = np.mean(np.abs((yhat_test_fixed[:,0]-test_target)))\n",
    "print(\"Fixed scheme RMSE:\", rmse_fixed,\n",
    "     \"\\nFixed scheme MAE: \", mae_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Stack training and test set, this makes updating scheme easier to train\n",
    "all_features = np.concatenate((train_features[-window_length:], test_features), axis=0)\n",
    "all_target = np.concatenate((train_target[-window_length:], test_target), axis=0)\n",
    "\n",
    "# Vectors to store loss and forecasts\n",
    "test_loss = np.zeros(len(test_target))\n",
    "yhat_update = np.zeros(len(test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test period = 1  Training loss = 1.3417  Test loss = 3.7780  Model updated 0 times  \n",
      "\n",
      "Test period = 2  Training loss = 1.3898  Test loss = 2.5755  Model updated 0 times  \n",
      "\n",
      "Test period = 3  Training loss = 1.4253  Test loss = 1.9693  Model updated 0 times  \n",
      "\n",
      "Test period = 4  Training loss = 1.4458  Test loss = 0.0522  Model updated 0 times  \n",
      "\n",
      "Test period = 5  Training loss = 1.0110  Test loss = 0.2316  Model updated 1 times  \n",
      "\n",
      "Test period = 6  Training loss = 1.0114  Test loss = 1.1370  Model updated 1 times  \n",
      "\n",
      "Test period = 7  Training loss = 1.0212  Test loss = 0.0615  Model updated 1 times  \n",
      "\n",
      "Test period = 8  Training loss = 1.0212  Test loss = 1.3716  Model updated 1 times  \n",
      "\n",
      "Test period = 9  Training loss = 0.9519  Test loss = 1.2958  Model updated 2 times  \n",
      "\n",
      "Test period = 10  Training loss = 0.9649  Test loss = 2.1469  Model updated 2 times  \n",
      "\n",
      "Test period = 11  Training loss = 1.0006  Test loss = 1.1395  Model updated 2 times  \n",
      "\n",
      "Test period = 12  Training loss = 1.0103  Test loss = 0.2241  Model updated 2 times  \n",
      "\n",
      "Test period = 13  Training loss = 0.9543  Test loss = 0.2227  Model updated 3 times  \n",
      "\n",
      "Test period = 14  Training loss = 0.9547  Test loss = 3.7735  Model updated 3 times  \n",
      "\n",
      "Test period = 15  Training loss = 1.0625  Test loss = 4.8527  Model updated 3 times  \n",
      "\n",
      "Test period = 16  Training loss = 1.2202  Test loss = 4.7861  Model updated 3 times  \n",
      "\n",
      "Test period = 17  Training loss = 0.9076  Test loss = 2.9669  Model updated 4 times  \n",
      "\n",
      "Test period = 18  Training loss = 0.9793  Test loss = 0.2493  Model updated 4 times  \n",
      "\n",
      "Test period = 19  Training loss = 0.9797  Test loss = 1.6910  Model updated 4 times  \n",
      "\n",
      "Test period = 20  Training loss = 1.0018  Test loss = 1.2096  Model updated 4 times  \n",
      "\n",
      "Test period = 21  Training loss = 0.9181  Test loss = 0.2802  Model updated 5 times  \n",
      "\n",
      "Test period = 22  Training loss = 0.9187  Test loss = 4.8688  Model updated 5 times  \n",
      "\n",
      "Test period = 23  Training loss = 1.0985  Test loss = 0.0495  Model updated 5 times  \n",
      "\n",
      "Test period = 24  Training loss = 1.0983  Test loss = 3.6549  Model updated 5 times  \n",
      "\n",
      "Test period = 25  Training loss = 1.0328  Test loss = 0.9551  Model updated 6 times  \n",
      "\n",
      "Test period = 26  Training loss = 1.0378  Test loss = 0.4320  Model updated 6 times  \n",
      "\n",
      "Test period = 27  Training loss = 1.0381  Test loss = 0.0507  Model updated 6 times  \n",
      "\n",
      "Test period = 28  Training loss = 1.0381  Test loss = 1.1987  Model updated 6 times  \n",
      "\n",
      "Test period = 29  Training loss = 0.7838  Test loss = 1.6414  Model updated 7 times  \n",
      "\n",
      "Test period = 30  Training loss = 0.8091  Test loss = 0.6756  Model updated 7 times  \n",
      "\n",
      "Test period = 31  Training loss = 0.8111  Test loss = 3.0344  Model updated 7 times  \n",
      "\n",
      "Test period = 32  Training loss = 0.8726  Test loss = 0.0350  Model updated 7 times  \n",
      "\n",
      "Test period = 33  Training loss = 0.6941  Test loss = 1.4539  Model updated 8 times  \n",
      "\n",
      "Test period = 34  Training loss = 0.7153  Test loss = 0.1131  Model updated 8 times  \n",
      "\n",
      "Test period = 35  Training loss = 0.7083  Test loss = 0.3185  Model updated 8 times  \n",
      "\n",
      "Test period = 36  Training loss = 0.7094  Test loss = 4.0128  Model updated 8 times  \n",
      "\n",
      "Test period = 37  Training loss = 0.8056  Test loss = 0.1105  Model updated 9 times  \n",
      "\n",
      "Test period = 38  Training loss = 0.7171  Test loss = 0.5278  Model updated 9 times  \n",
      "\n",
      "Test period = 39  Training loss = 0.7082  Test loss = 2.6589  Model updated 9 times  \n",
      "\n",
      "Test period = 40  Training loss = 0.7811  Test loss = 1.3057  Model updated 9 times  \n",
      "\n",
      "Test period = 41  Training loss = 0.5762  Test loss = 2.6782  Model updated 10 times  \n",
      "\n",
      "Test period = 42  Training loss = 0.6647  Test loss = 3.1497  Model updated 10 times  \n",
      "\n",
      "Test period = 43  Training loss = 0.7708  Test loss = 3.0019  Model updated 10 times  \n",
      "\n",
      "Test period = 44  Training loss = 0.8529  Test loss = 12.6355  Model updated 10 times  \n",
      "\n",
      "Test period = 45  Training loss = 1.7886  Test loss = 6.3593  Model updated 11 times  \n",
      "\n",
      "Test period = 46  Training loss = 1.9535  Test loss = 1.5236  Model updated 11 times  \n",
      "\n",
      "Test period = 47  Training loss = 1.9622  Test loss = 0.4456  Model updated 11 times  \n",
      "\n",
      "Test period = 48  Training loss = 1.9624  Test loss = 0.2516  Model updated 11 times  \n",
      "\n",
      "Test period = 49  Training loss = 0.8853  Test loss = 3.3920  Model updated 12 times  \n",
      "\n",
      "Test period = 50  Training loss = 0.9799  Test loss = 2.3426  Model updated 12 times  \n",
      "\n",
      "Test period = 51  Training loss = 1.0213  Test loss = 2.9030  Model updated 12 times  \n",
      "\n",
      "Test period = 52  Training loss = 1.0828  Test loss = 0.9752  Model updated 12 times  \n",
      "\n",
      "Test period = 53  Training loss = 0.9197  Test loss = 1.6053  Model updated 13 times  \n",
      "\n",
      "Test period = 54  Training loss = 0.9406  Test loss = 2.8211  Model updated 13 times  \n",
      "\n",
      "Test period = 55  Training loss = 1.0030  Test loss = 1.3852  Model updated 13 times  \n",
      "\n",
      "Test period = 56  Training loss = 1.0143  Test loss = 1.4936  Model updated 13 times  \n",
      "\n",
      "Test period = 57  Training loss = 0.9182  Test loss = 1.4840  Model updated 14 times  \n",
      "\n",
      "Test period = 58  Training loss = 0.9360  Test loss = 2.7125  Model updated 14 times  \n",
      "\n",
      "Test period = 59  Training loss = 0.9917  Test loss = 0.3771  Model updated 14 times  \n",
      "\n",
      "Test period = 60  Training loss = 0.9891  Test loss = 0.3233  Model updated 14 times  \n",
      "\n",
      "Test period = 61  Training loss = 0.8363  Test loss = 0.7050  Model updated 15 times  \n",
      "\n",
      "Test period = 62  Training loss = 0.8403  Test loss = 1.4486  Model updated 15 times  \n",
      "\n",
      "Test period = 63  Training loss = 0.8590  Test loss = 1.8005  Model updated 15 times  \n",
      "\n",
      "Test period = 64  Training loss = 0.8874  Test loss = 0.4237  Model updated 15 times  \n",
      "\n",
      "Test period = 65  Training loss = 0.9075  Test loss = 0.1244  Model updated 16 times  \n",
      "\n",
      "Test period = 66  Training loss = 0.9057  Test loss = 2.7984  Model updated 16 times  \n",
      "\n",
      "Test period = 67  Training loss = 0.9641  Test loss = 1.4825  Model updated 16 times  \n",
      "\n",
      "Test period = 68  Training loss = 0.9797  Test loss = 3.5741  Model updated 16 times  \n",
      "\n",
      "Test period = 69  Training loss = 0.8676  Test loss = 6.5379  Model updated 17 times  \n",
      "\n",
      "Test period = 70  Training loss = 1.1874  Test loss = 0.1126  Model updated 17 times  \n",
      "\n",
      "Test period = 71  Training loss = 1.1874  Test loss = 2.2414  Model updated 17 times  \n",
      "\n",
      "Test period = 72  Training loss = 1.2194  Test loss = 3.6799  Model updated 17 times  \n",
      "\n",
      "Test period = 73  Training loss = 0.9125  Test loss = 3.1188  Model updated 18 times  \n",
      "\n",
      "Test period = 74  Training loss = 0.9904  Test loss = 2.2379  Model updated 18 times  \n",
      "\n",
      "Test period = 75  Training loss = 1.0282  Test loss = 2.6971  Model updated 18 times  \n",
      "\n",
      "Test period = 76  Training loss = 1.0809  Test loss = 2.1314  Model updated 18 times  \n",
      "\n",
      "Test period = 77  Training loss = 0.8784  Test loss = 0.8836  Model updated 19 times  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "retrain_count = 0\n",
    "for t in range(len(test_target)):\n",
    "    x_test = np.reshape(test_features[t], newshape=(1,4,3))\n",
    "    y_test = test_target[t]\n",
    "    test_loss[t] = np.sqrt(sess.run(loss, feed_dict={x:x_test, y:y_test}))\n",
    "    yhat_update[t] = pred.eval(feed_dict={x:x_test})\n",
    "\n",
    "    x_train = all_features[t:(window_length+t)]\n",
    "    y_train = all_target[t:(window_length+t)]\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:x_test, y:y_test})\n",
    "    \n",
    "    print(\"Test period = {0:d}\".format(t+1),\n",
    "      \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "      \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "      \" Model updated {0:d} times\".format(retrain_count),\n",
    "      \" \\n\")\n",
    "\n",
    "    if (t+1)%4==0:\n",
    "        retrain_count += 1\n",
    "        for epoch in range(epoch_hat):\n",
    "            for i in range(total_batch):\n",
    "                optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCCIzabYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc08a7c4090>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: updating scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_update, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating scheme RMSE: 2.7590779523 \n",
      "Updating scheme MAE:  1.96065511207\n"
     ]
    }
   ],
   "source": [
    "rmse_update = np.sqrt(np.mean((yhat_update-test_target)**2))\n",
    "mae_update = np.mean(np.abs((yhat_update-test_target)))\n",
    "print(\"Updating scheme RMSE:\", rmse_update,\n",
    "     \"\\nUpdating scheme MAE: \", mae_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + \"yhat_test_fixed.csv\", yhat_test_fixed)\n",
    "np.savetxt(MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + \"yhat_update.csv\", yhat_update)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
