{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Directories\n",
    "MODEL_FOLDER = \"../../../models/lstm/\"\n",
    "MODEL_FILENAME = MODEL_FOLDER + \"4Q/16_units/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: model saver\n",
    "def saveModel(sess, MODEL_FILENAME):\n",
    "    if not os.path.exists(MODEL_FOLDER):\n",
    "        print('Creating path where to save model: ' + MODEL_FOLDER)\n",
    "        os.mkdir(MODEL_FOLDER)\n",
    "\n",
    "    #print('Saving model at: ' + MODEL_FILENAME)\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, MODEL_FILENAME)\n",
    "    #print('Model successfully saved.\\n')\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: model loader\n",
    "def loadModel(sess, MODEL_FILENAME):\n",
    "    if os.path.exists(MODEL_FILENAME + \".index\"):\n",
    "        print('Loading save model from: ' + MODEL_FILENAME)\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, MODEL_FILENAME)\n",
    "        print('Model successfully loaded.\\n')\n",
    "        return True\n",
    "    else:\n",
    "        print('Model file <<' + MODEL_FILENAME + '>> does not exists!')\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Hyperparameters\n",
    "epochs = 500\n",
    "learning_rate = 1e-6\n",
    "batch_size = 5\n",
    "early_stop_iters = 10\n",
    "folds = 32\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 3  # data input\n",
    "n_steps = 4  # timesteps\n",
    "n_hidden = 16 # dimension of recurrent unit\n",
    "\n",
    "# (REPRODUCIBILITY) set random seeds\n",
    "tf.set_random_seed(123)\n",
    "\n",
    "# Define weights and biases\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.truncated_normal([n_hidden, 1], stddev = 1.0 / tf.sqrt(float(n_hidden))),\n",
    "        name='out_weight')\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.zeros([1]),\n",
    "        name='out_bias')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: Build model\n",
    "def RNN(X, weights, biases, n_hidden):\n",
    "\n",
    "    # Define a LSTM cell with tensorflow\n",
    "    lstm_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden, state_is_tuple=True)\n",
    "    outputs, _ = tf.nn.dynamic_rnn(lstm_cell, X, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    out_layer = tf.matmul(outputs[:,-1,:], weights['out']) + biases['out']\n",
    "\n",
    "    return out_layer\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: select batch\n",
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the data...\n",
      "Finished: data loaded. Stats below: \n",
      "Nr of training samples: 193\n",
      "Nr of testing  samples: 77\n",
      "Number of variables: 3\n",
      "Number of lags: 4\n",
      "Window length: 65\n",
      "Number of validation folds: 32\n"
     ]
    }
   ],
   "source": [
    "# =================================\n",
    "# 0. Load dataset\n",
    "# =================================\n",
    "print(\"Loading the data...\")\n",
    "# Training set pre-processing\n",
    "train = pd.read_csv('../../../Data/train.csv')\n",
    "train_4lag_inflation = np.array(train[['inflation.lag4',\n",
    "                                       'inflation.lag5',\n",
    "                                       'inflation.lag6',\n",
    "                                       'inflation.lag7']])\n",
    "train_4lag_unemp = np.array(train[['unemp.lag4',\n",
    "                                   'unemp.lag5',\n",
    "                                   'unemp.lag6',\n",
    "                                   'unemp.lag7']])\n",
    "train_4lag_oil = np.array(train[['oil.lag4',\n",
    "                                 'oil.lag5',\n",
    "                                 'oil.lag6',\n",
    "                                 'oil.lag7']])\n",
    "train_features = np.concatenate((train_4lag_inflation[:,:,np.newaxis], \n",
    "\t                             train_4lag_unemp[:,:,np.newaxis],\n",
    "\t                             train_4lag_oil[:,:,np.newaxis]),\n",
    "\t                             axis=2)\n",
    "train_target = np.array(train['inflation.target'])\n",
    "\n",
    "# Test set pre-processing\n",
    "test = pd.read_csv('../../../Data/test.csv')\n",
    "test_4lag_inflation = np.array(test[['inflation.lag4',\n",
    "                                     'inflation.lag5',\n",
    "                                     'inflation.lag6',\n",
    "                                     'inflation.lag7']])\n",
    "test_4lag_unemp = np.array(test[['unemp.lag4',\n",
    "                                 'unemp.lag5',\n",
    "                                 'unemp.lag6',\n",
    "                                 'unemp.lag7']])\n",
    "test_4lag_oil = np.array(test[['oil.lag4',\n",
    "                               'oil.lag5',\n",
    "                               'oil.lag6',\n",
    "                               'oil.lag7']])\n",
    "test_features = np.concatenate((test_4lag_inflation[:,:,np.newaxis], \n",
    "\t                            test_4lag_unemp[:,:,np.newaxis],\n",
    "\t                            test_4lag_oil[:,:,np.newaxis]),\n",
    "\t                            axis=2)\n",
    "test_target = np.array(test['inflation.target'])\n",
    "\n",
    "(nrTrainSamples, timesteps, variables) = train_features.shape\n",
    "(nrTestSamples, _, _) = test_features.shape\n",
    "\n",
    "# Window length and validation fold index\n",
    "window_length = 65\n",
    "valIndex = np.linspace(start=window_length, stop=nrTrainSamples, \n",
    "                       endpoint=True, num=folds+1, dtype=np.int)\n",
    "\n",
    "print(\"Finished: data loaded. Stats below: \")\n",
    "print(\"Nr of training samples: %d\" % nrTrainSamples)\n",
    "print(\"Nr of testing  samples: %d\" % nrTestSamples)\n",
    "print(\"Number of variables: %d\" % variables)\n",
    "print(\"Number of lags: %d\" % timesteps)\n",
    "print(\"Window length: %d\" % window_length)\n",
    "print(\"Number of validation folds: %d\" % folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 1. Build model\n",
    "# ==================================\n",
    "# tf graph input\n",
    "x = tf.placeholder(\"float\", [None, n_steps, n_input], name='Batch')\n",
    "y = tf.placeholder(\"float\", name='True_labels_of_batch')\n",
    "lr = tf.placeholder(\"float\", name='Learning_rate')\n",
    "\n",
    "# Make predictions with the model\n",
    "pred = RNN(x, weights, biases, n_hidden)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss = tf.reduce_mean(tf.diag_part(tf.square(tf.subtract(x=pred, y=y))))\n",
    "optimizer = tf.train.GradientDescentOptimizer(lr).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training \n",
      "Hyperparameters: \n",
      "Dimension of recurrent unit = 16 \n",
      "Learning rate = 1e-06 \n",
      "Epochs = 500 \n",
      "Batch size = 5 \n",
      "Early stopping epochs = 10 \n",
      "Learning rate = 1e-06\n",
      "Fold: 1  Epoch: 1  Training loss = 3.2108  Validation loss = 3.4321  \n",
      "\n",
      "Fold: 1  Epoch: 2  Training loss = 3.2107  Validation loss = 3.4318  \n",
      "\n",
      "Fold: 1  Epoch: 3  Training loss = 3.2106  Validation loss = 3.4316  \n",
      "\n",
      "Fold: 1  Epoch: 4  Training loss = 3.2104  Validation loss = 3.4313  \n",
      "\n",
      "Fold: 1  Epoch: 5  Training loss = 3.2103  Validation loss = 3.4311  \n",
      "\n",
      "Fold: 1  Epoch: 6  Training loss = 3.2102  Validation loss = 3.4309  \n",
      "\n",
      "Fold: 1  Epoch: 7  Training loss = 3.2101  Validation loss = 3.4307  \n",
      "\n",
      "Fold: 1  Epoch: 8  Training loss = 3.2100  Validation loss = 3.4304  \n",
      "\n",
      "Fold: 1  Epoch: 9  Training loss = 3.2098  Validation loss = 3.4302  \n",
      "\n",
      "Fold: 1  Epoch: 10  Training loss = 3.2097  Validation loss = 3.4299  \n",
      "\n",
      "Fold: 1  Epoch: 11  Training loss = 3.2095  Validation loss = 3.4297  \n",
      "\n",
      "Fold: 1  Epoch: 12  Training loss = 3.2094  Validation loss = 3.4295  \n",
      "\n",
      "Fold: 1  Epoch: 13  Training loss = 3.2093  Validation loss = 3.4293  \n",
      "\n",
      "Fold: 1  Epoch: 14  Training loss = 3.2092  Validation loss = 3.4290  \n",
      "\n",
      "Fold: 1  Epoch: 15  Training loss = 3.2090  Validation loss = 3.4287  \n",
      "\n",
      "Fold: 1  Epoch: 16  Training loss = 3.2089  Validation loss = 3.4286  \n",
      "\n",
      "Fold: 1  Epoch: 17  Training loss = 3.2087  Validation loss = 3.4282  \n",
      "\n",
      "Fold: 1  Epoch: 18  Training loss = 3.2086  Validation loss = 3.4280  \n",
      "\n",
      "Fold: 1  Epoch: 19  Training loss = 3.2085  Validation loss = 3.4278  \n",
      "\n",
      "Fold: 1  Epoch: 20  Training loss = 3.2084  Validation loss = 3.4276  \n",
      "\n",
      "Fold: 1  Epoch: 21  Training loss = 3.2083  Validation loss = 3.4273  \n",
      "\n",
      "Fold: 1  Epoch: 22  Training loss = 3.2081  Validation loss = 3.4271  \n",
      "\n",
      "Fold: 1  Epoch: 23  Training loss = 3.2080  Validation loss = 3.4269  \n",
      "\n",
      "Fold: 1  Epoch: 24  Training loss = 3.2079  Validation loss = 3.4267  \n",
      "\n",
      "Fold: 1  Epoch: 25  Training loss = 3.2077  Validation loss = 3.4264  \n",
      "\n",
      "Fold: 1  Epoch: 26  Training loss = 3.2076  Validation loss = 3.4262  \n",
      "\n",
      "Fold: 1  Epoch: 27  Training loss = 3.2075  Validation loss = 3.4260  \n",
      "\n",
      "Fold: 1  Epoch: 28  Training loss = 3.2074  Validation loss = 3.4257  \n",
      "\n",
      "Fold: 1  Epoch: 29  Training loss = 3.2072  Validation loss = 3.4255  \n",
      "\n",
      "Fold: 1  Epoch: 30  Training loss = 3.2071  Validation loss = 3.4252  \n",
      "\n",
      "Fold: 1  Epoch: 31  Training loss = 3.2070  Validation loss = 3.4250  \n",
      "\n",
      "Fold: 1  Epoch: 32  Training loss = 3.2068  Validation loss = 3.4248  \n",
      "\n",
      "Fold: 1  Epoch: 33  Training loss = 3.2067  Validation loss = 3.4246  \n",
      "\n",
      "Fold: 1  Epoch: 34  Training loss = 3.2066  Validation loss = 3.4244  \n",
      "\n",
      "Fold: 1  Epoch: 35  Training loss = 3.2065  Validation loss = 3.4241  \n",
      "\n",
      "Fold: 1  Epoch: 36  Training loss = 3.2063  Validation loss = 3.4238  \n",
      "\n",
      "Fold: 1  Epoch: 37  Training loss = 3.2062  Validation loss = 3.4236  \n",
      "\n",
      "Fold: 1  Epoch: 38  Training loss = 3.2061  Validation loss = 3.4234  \n",
      "\n",
      "Fold: 1  Epoch: 39  Training loss = 3.2060  Validation loss = 3.4232  \n",
      "\n",
      "Fold: 1  Epoch: 40  Training loss = 3.2059  Validation loss = 3.4230  \n",
      "\n",
      "Fold: 1  Epoch: 41  Training loss = 3.2057  Validation loss = 3.4227  \n",
      "\n",
      "Fold: 1  Epoch: 42  Training loss = 3.2056  Validation loss = 3.4225  \n",
      "\n",
      "Fold: 1  Epoch: 43  Training loss = 3.2055  Validation loss = 3.4222  \n",
      "\n",
      "Fold: 1  Epoch: 44  Training loss = 3.2053  Validation loss = 3.4220  \n",
      "\n",
      "Fold: 1  Epoch: 45  Training loss = 3.2052  Validation loss = 3.4218  \n",
      "\n",
      "Fold: 1  Epoch: 46  Training loss = 3.2050  Validation loss = 3.4215  \n",
      "\n",
      "Fold: 1  Epoch: 47  Training loss = 3.2049  Validation loss = 3.4212  \n",
      "\n",
      "Fold: 1  Epoch: 48  Training loss = 3.2048  Validation loss = 3.4210  \n",
      "\n",
      "Fold: 1  Epoch: 49  Training loss = 3.2047  Validation loss = 3.4207  \n",
      "\n",
      "Fold: 1  Epoch: 50  Training loss = 3.2045  Validation loss = 3.4204  \n",
      "\n",
      "Fold: 1  Epoch: 51  Training loss = 3.2044  Validation loss = 3.4202  \n",
      "\n",
      "Fold: 1  Epoch: 52  Training loss = 3.2043  Validation loss = 3.4200  \n",
      "\n",
      "Fold: 1  Epoch: 53  Training loss = 3.2041  Validation loss = 3.4198  \n",
      "\n",
      "Fold: 1  Epoch: 54  Training loss = 3.2040  Validation loss = 3.4196  \n",
      "\n",
      "Fold: 1  Epoch: 55  Training loss = 3.2039  Validation loss = 3.4193  \n",
      "\n",
      "Fold: 1  Epoch: 56  Training loss = 3.2037  Validation loss = 3.4191  \n",
      "\n",
      "Fold: 1  Epoch: 57  Training loss = 3.2036  Validation loss = 3.4189  \n",
      "\n",
      "Fold: 1  Epoch: 58  Training loss = 3.2034  Validation loss = 3.4185  \n",
      "\n",
      "Fold: 1  Epoch: 59  Training loss = 3.2033  Validation loss = 3.4182  \n",
      "\n",
      "Fold: 1  Epoch: 60  Training loss = 3.2032  Validation loss = 3.4181  \n",
      "\n",
      "Fold: 1  Epoch: 61  Training loss = 3.2030  Validation loss = 3.4178  \n",
      "\n",
      "Fold: 1  Epoch: 62  Training loss = 3.2029  Validation loss = 3.4175  \n",
      "\n",
      "Fold: 1  Epoch: 63  Training loss = 3.2027  Validation loss = 3.4172  \n",
      "\n",
      "Fold: 1  Epoch: 64  Training loss = 3.2026  Validation loss = 3.4170  \n",
      "\n",
      "Fold: 1  Epoch: 65  Training loss = 3.2024  Validation loss = 3.4167  \n",
      "\n",
      "Fold: 1  Epoch: 66  Training loss = 3.2023  Validation loss = 3.4164  \n",
      "\n",
      "Fold: 1  Epoch: 67  Training loss = 3.2021  Validation loss = 3.4162  \n",
      "\n",
      "Fold: 1  Epoch: 68  Training loss = 3.2020  Validation loss = 3.4160  \n",
      "\n",
      "Fold: 1  Epoch: 69  Training loss = 3.2019  Validation loss = 3.4157  \n",
      "\n",
      "Fold: 1  Epoch: 70  Training loss = 3.2018  Validation loss = 3.4155  \n",
      "\n",
      "Fold: 1  Epoch: 71  Training loss = 3.2016  Validation loss = 3.4151  \n",
      "\n",
      "Fold: 1  Epoch: 72  Training loss = 3.2014  Validation loss = 3.4149  \n",
      "\n",
      "Fold: 1  Epoch: 73  Training loss = 3.2013  Validation loss = 3.4147  \n",
      "\n",
      "Fold: 1  Epoch: 74  Training loss = 3.2012  Validation loss = 3.4145  \n",
      "\n",
      "Fold: 1  Epoch: 75  Training loss = 3.2011  Validation loss = 3.4142  \n",
      "\n",
      "Fold: 1  Epoch: 76  Training loss = 3.2010  Validation loss = 3.4140  \n",
      "\n",
      "Fold: 1  Epoch: 77  Training loss = 3.2008  Validation loss = 3.4138  \n",
      "\n",
      "Fold: 1  Epoch: 78  Training loss = 3.2007  Validation loss = 3.4135  \n",
      "\n",
      "Fold: 1  Epoch: 79  Training loss = 3.2005  Validation loss = 3.4132  \n",
      "\n",
      "Fold: 1  Epoch: 80  Training loss = 3.2004  Validation loss = 3.4130  \n",
      "\n",
      "Fold: 1  Epoch: 81  Training loss = 3.2003  Validation loss = 3.4128  \n",
      "\n",
      "Fold: 1  Epoch: 82  Training loss = 3.2001  Validation loss = 3.4125  \n",
      "\n",
      "Fold: 1  Epoch: 83  Training loss = 3.2000  Validation loss = 3.4122  \n",
      "\n",
      "Fold: 1  Epoch: 84  Training loss = 3.1999  Validation loss = 3.4120  \n",
      "\n",
      "Fold: 1  Epoch: 85  Training loss = 3.1997  Validation loss = 3.4118  \n",
      "\n",
      "Fold: 1  Epoch: 86  Training loss = 3.1996  Validation loss = 3.4116  \n",
      "\n",
      "Fold: 1  Epoch: 87  Training loss = 3.1995  Validation loss = 3.4113  \n",
      "\n",
      "Fold: 1  Epoch: 88  Training loss = 3.1994  Validation loss = 3.4111  \n",
      "\n",
      "Fold: 1  Epoch: 89  Training loss = 3.1993  Validation loss = 3.4109  \n",
      "\n",
      "Fold: 1  Epoch: 90  Training loss = 3.1991  Validation loss = 3.4106  \n",
      "\n",
      "Fold: 1  Epoch: 91  Training loss = 3.1990  Validation loss = 3.4103  \n",
      "\n",
      "Fold: 1  Epoch: 92  Training loss = 3.1988  Validation loss = 3.4100  \n",
      "\n",
      "Fold: 1  Epoch: 93  Training loss = 3.1987  Validation loss = 3.4098  \n",
      "\n",
      "Fold: 1  Epoch: 94  Training loss = 3.1985  Validation loss = 3.4096  \n",
      "\n",
      "Fold: 1  Epoch: 95  Training loss = 3.1984  Validation loss = 3.4093  \n",
      "\n",
      "Fold: 1  Epoch: 96  Training loss = 3.1983  Validation loss = 3.4091  \n",
      "\n",
      "Fold: 1  Epoch: 97  Training loss = 3.1981  Validation loss = 3.4088  \n",
      "\n",
      "Fold: 1  Epoch: 98  Training loss = 3.1980  Validation loss = 3.4086  \n",
      "\n",
      "Fold: 1  Epoch: 99  Training loss = 3.1979  Validation loss = 3.4084  \n",
      "\n",
      "Fold: 1  Epoch: 100  Training loss = 3.1978  Validation loss = 3.4082  \n",
      "\n",
      "Fold: 1  Epoch: 101  Training loss = 3.1977  Validation loss = 3.4080  \n",
      "\n",
      "Fold: 1  Epoch: 102  Training loss = 3.1975  Validation loss = 3.4077  \n",
      "\n",
      "Fold: 1  Epoch: 103  Training loss = 3.1974  Validation loss = 3.4075  \n",
      "\n",
      "Fold: 1  Epoch: 104  Training loss = 3.1972  Validation loss = 3.4072  \n",
      "\n",
      "Fold: 1  Epoch: 105  Training loss = 3.1971  Validation loss = 3.4070  \n",
      "\n",
      "Fold: 1  Epoch: 106  Training loss = 3.1970  Validation loss = 3.4067  \n",
      "\n",
      "Fold: 1  Epoch: 107  Training loss = 3.1969  Validation loss = 3.4065  \n",
      "\n",
      "Fold: 1  Epoch: 108  Training loss = 3.1968  Validation loss = 3.4064  \n",
      "\n",
      "Fold: 1  Epoch: 109  Training loss = 3.1967  Validation loss = 3.4062  \n",
      "\n",
      "Fold: 1  Epoch: 110  Training loss = 3.1965  Validation loss = 3.4059  \n",
      "\n",
      "Fold: 1  Epoch: 111  Training loss = 3.1964  Validation loss = 3.4056  \n",
      "\n",
      "Fold: 1  Epoch: 112  Training loss = 3.1962  Validation loss = 3.4053  \n",
      "\n",
      "Fold: 1  Epoch: 113  Training loss = 3.1961  Validation loss = 3.4051  \n",
      "\n",
      "Fold: 1  Epoch: 114  Training loss = 3.1959  Validation loss = 3.4048  \n",
      "\n",
      "Fold: 1  Epoch: 115  Training loss = 3.1958  Validation loss = 3.4045  \n",
      "\n",
      "Fold: 1  Epoch: 116  Training loss = 3.1956  Validation loss = 3.4042  \n",
      "\n",
      "Fold: 1  Epoch: 117  Training loss = 3.1955  Validation loss = 3.4040  \n",
      "\n",
      "Fold: 1  Epoch: 118  Training loss = 3.1954  Validation loss = 3.4038  \n",
      "\n",
      "Fold: 1  Epoch: 119  Training loss = 3.1952  Validation loss = 3.4035  \n",
      "\n",
      "Fold: 1  Epoch: 120  Training loss = 3.1951  Validation loss = 3.4033  \n",
      "\n",
      "Fold: 1  Epoch: 121  Training loss = 3.1950  Validation loss = 3.4030  \n",
      "\n",
      "Fold: 1  Epoch: 122  Training loss = 3.1949  Validation loss = 3.4028  \n",
      "\n",
      "Fold: 1  Epoch: 123  Training loss = 3.1947  Validation loss = 3.4026  \n",
      "\n",
      "Fold: 1  Epoch: 124  Training loss = 3.1946  Validation loss = 3.4023  \n",
      "\n",
      "Fold: 1  Epoch: 125  Training loss = 3.1945  Validation loss = 3.4021  \n",
      "\n",
      "Fold: 1  Epoch: 126  Training loss = 3.1944  Validation loss = 3.4019  \n",
      "\n",
      "Fold: 1  Epoch: 127  Training loss = 3.1943  Validation loss = 3.4017  \n",
      "\n",
      "Fold: 1  Epoch: 128  Training loss = 3.1942  Validation loss = 3.4015  \n",
      "\n",
      "Fold: 1  Epoch: 129  Training loss = 3.1940  Validation loss = 3.4013  \n",
      "\n",
      "Fold: 1  Epoch: 130  Training loss = 3.1939  Validation loss = 3.4011  \n",
      "\n",
      "Fold: 1  Epoch: 131  Training loss = 3.1938  Validation loss = 3.4008  \n",
      "\n",
      "Fold: 1  Epoch: 132  Training loss = 3.1937  Validation loss = 3.4007  \n",
      "\n",
      "Fold: 1  Epoch: 133  Training loss = 3.1936  Validation loss = 3.4004  \n",
      "\n",
      "Fold: 1  Epoch: 134  Training loss = 3.1935  Validation loss = 3.4002  \n",
      "\n",
      "Fold: 1  Epoch: 135  Training loss = 3.1933  Validation loss = 3.4000  \n",
      "\n",
      "Fold: 1  Epoch: 136  Training loss = 3.1932  Validation loss = 3.3997  \n",
      "\n",
      "Fold: 1  Epoch: 137  Training loss = 3.1930  Validation loss = 3.3995  \n",
      "\n",
      "Fold: 1  Epoch: 138  Training loss = 3.1929  Validation loss = 3.3992  \n",
      "\n",
      "Fold: 1  Epoch: 139  Training loss = 3.1928  Validation loss = 3.3990  \n",
      "\n",
      "Fold: 1  Epoch: 140  Training loss = 3.1926  Validation loss = 3.3987  \n",
      "\n",
      "Fold: 1  Epoch: 141  Training loss = 3.1925  Validation loss = 3.3985  \n",
      "\n",
      "Fold: 1  Epoch: 142  Training loss = 3.1923  Validation loss = 3.3982  \n",
      "\n",
      "Fold: 1  Epoch: 143  Training loss = 3.1922  Validation loss = 3.3980  \n",
      "\n",
      "Fold: 1  Epoch: 144  Training loss = 3.1921  Validation loss = 3.3977  \n",
      "\n",
      "Fold: 1  Epoch: 145  Training loss = 3.1919  Validation loss = 3.3975  \n",
      "\n",
      "Fold: 1  Epoch: 146  Training loss = 3.1918  Validation loss = 3.3973  \n",
      "\n",
      "Fold: 1  Epoch: 147  Training loss = 3.1917  Validation loss = 3.3970  \n",
      "\n",
      "Fold: 1  Epoch: 148  Training loss = 3.1915  Validation loss = 3.3966  \n",
      "\n",
      "Fold: 1  Epoch: 149  Training loss = 3.1914  Validation loss = 3.3964  \n",
      "\n",
      "Fold: 1  Epoch: 150  Training loss = 3.1912  Validation loss = 3.3962  \n",
      "\n",
      "Fold: 1  Epoch: 151  Training loss = 3.1911  Validation loss = 3.3959  \n",
      "\n",
      "Fold: 1  Epoch: 152  Training loss = 3.1909  Validation loss = 3.3956  \n",
      "\n",
      "Fold: 1  Epoch: 153  Training loss = 3.1908  Validation loss = 3.3954  \n",
      "\n",
      "Fold: 1  Epoch: 154  Training loss = 3.1907  Validation loss = 3.3952  \n",
      "\n",
      "Fold: 1  Epoch: 155  Training loss = 3.1906  Validation loss = 3.3949  \n",
      "\n",
      "Fold: 1  Epoch: 156  Training loss = 3.1904  Validation loss = 3.3947  \n",
      "\n",
      "Fold: 1  Epoch: 157  Training loss = 3.1903  Validation loss = 3.3945  \n",
      "\n",
      "Fold: 1  Epoch: 158  Training loss = 3.1902  Validation loss = 3.3943  \n",
      "\n",
      "Fold: 1  Epoch: 159  Training loss = 3.1901  Validation loss = 3.3941  \n",
      "\n",
      "Fold: 1  Epoch: 160  Training loss = 3.1899  Validation loss = 3.3938  \n",
      "\n",
      "Fold: 1  Epoch: 161  Training loss = 3.1898  Validation loss = 3.3935  \n",
      "\n",
      "Fold: 1  Epoch: 162  Training loss = 3.1897  Validation loss = 3.3933  \n",
      "\n",
      "Fold: 1  Epoch: 163  Training loss = 3.1895  Validation loss = 3.3931  \n",
      "\n",
      "Fold: 1  Epoch: 164  Training loss = 3.1894  Validation loss = 3.3928  \n",
      "\n",
      "Fold: 1  Epoch: 165  Training loss = 3.1893  Validation loss = 3.3926  \n",
      "\n",
      "Fold: 1  Epoch: 166  Training loss = 3.1892  Validation loss = 3.3924  \n",
      "\n",
      "Fold: 1  Epoch: 167  Training loss = 3.1891  Validation loss = 3.3922  \n",
      "\n",
      "Fold: 1  Epoch: 168  Training loss = 3.1890  Validation loss = 3.3920  \n",
      "\n",
      "Fold: 1  Epoch: 169  Training loss = 3.1888  Validation loss = 3.3917  \n",
      "\n",
      "Fold: 1  Epoch: 170  Training loss = 3.1887  Validation loss = 3.3914  \n",
      "\n",
      "Fold: 1  Epoch: 171  Training loss = 3.1885  Validation loss = 3.3912  \n",
      "\n",
      "Fold: 1  Epoch: 172  Training loss = 3.1884  Validation loss = 3.3910  \n",
      "\n",
      "Fold: 1  Epoch: 173  Training loss = 3.1883  Validation loss = 3.3908  \n",
      "\n",
      "Fold: 1  Epoch: 174  Training loss = 3.1882  Validation loss = 3.3906  \n",
      "\n",
      "Fold: 1  Epoch: 175  Training loss = 3.1880  Validation loss = 3.3902  \n",
      "\n",
      "Fold: 1  Epoch: 176  Training loss = 3.1879  Validation loss = 3.3900  \n",
      "\n",
      "Fold: 1  Epoch: 177  Training loss = 3.1877  Validation loss = 3.3897  \n",
      "\n",
      "Fold: 1  Epoch: 178  Training loss = 3.1876  Validation loss = 3.3895  \n",
      "\n",
      "Fold: 1  Epoch: 179  Training loss = 3.1875  Validation loss = 3.3892  \n",
      "\n",
      "Fold: 1  Epoch: 180  Training loss = 3.1873  Validation loss = 3.3890  \n",
      "\n",
      "Fold: 1  Epoch: 181  Training loss = 3.1872  Validation loss = 3.3888  \n",
      "\n",
      "Fold: 1  Epoch: 182  Training loss = 3.1871  Validation loss = 3.3885  \n",
      "\n",
      "Fold: 1  Epoch: 183  Training loss = 3.1870  Validation loss = 3.3883  \n",
      "\n",
      "Fold: 1  Epoch: 184  Training loss = 3.1868  Validation loss = 3.3881  \n",
      "\n",
      "Fold: 1  Epoch: 185  Training loss = 3.1867  Validation loss = 3.3879  \n",
      "\n",
      "Fold: 1  Epoch: 186  Training loss = 3.1866  Validation loss = 3.3876  \n",
      "\n",
      "Fold: 1  Epoch: 187  Training loss = 3.1865  Validation loss = 3.3874  \n",
      "\n",
      "Fold: 1  Epoch: 188  Training loss = 3.1864  Validation loss = 3.3872  \n",
      "\n",
      "Fold: 1  Epoch: 189  Training loss = 3.1862  Validation loss = 3.3869  \n",
      "\n",
      "Fold: 1  Epoch: 190  Training loss = 3.1861  Validation loss = 3.3867  \n",
      "\n",
      "Fold: 1  Epoch: 191  Training loss = 3.1860  Validation loss = 3.3865  \n",
      "\n",
      "Fold: 1  Epoch: 192  Training loss = 3.1859  Validation loss = 3.3863  \n",
      "\n",
      "Fold: 1  Epoch: 193  Training loss = 3.1857  Validation loss = 3.3860  \n",
      "\n",
      "Fold: 1  Epoch: 194  Training loss = 3.1856  Validation loss = 3.3858  \n",
      "\n",
      "Fold: 1  Epoch: 195  Training loss = 3.1855  Validation loss = 3.3856  \n",
      "\n",
      "Fold: 1  Epoch: 196  Training loss = 3.1854  Validation loss = 3.3854  \n",
      "\n",
      "Fold: 1  Epoch: 197  Training loss = 3.1852  Validation loss = 3.3851  \n",
      "\n",
      "Fold: 1  Epoch: 198  Training loss = 3.1851  Validation loss = 3.3849  \n",
      "\n",
      "Fold: 1  Epoch: 199  Training loss = 3.1850  Validation loss = 3.3847  \n",
      "\n",
      "Fold: 1  Epoch: 200  Training loss = 3.1849  Validation loss = 3.3845  \n",
      "\n",
      "Fold: 1  Epoch: 201  Training loss = 3.1848  Validation loss = 3.3843  \n",
      "\n",
      "Fold: 1  Epoch: 202  Training loss = 3.1846  Validation loss = 3.3840  \n",
      "\n",
      "Fold: 1  Epoch: 203  Training loss = 3.1845  Validation loss = 3.3837  \n",
      "\n",
      "Fold: 1  Epoch: 204  Training loss = 3.1843  Validation loss = 3.3834  \n",
      "\n",
      "Fold: 1  Epoch: 205  Training loss = 3.1842  Validation loss = 3.3831  \n",
      "\n",
      "Fold: 1  Epoch: 206  Training loss = 3.1840  Validation loss = 3.3828  \n",
      "\n",
      "Fold: 1  Epoch: 207  Training loss = 3.1838  Validation loss = 3.3825  \n",
      "\n",
      "Fold: 1  Epoch: 208  Training loss = 3.1837  Validation loss = 3.3823  \n",
      "\n",
      "Fold: 1  Epoch: 209  Training loss = 3.1836  Validation loss = 3.3822  \n",
      "\n",
      "Fold: 1  Epoch: 210  Training loss = 3.1835  Validation loss = 3.3819  \n",
      "\n",
      "Fold: 1  Epoch: 211  Training loss = 3.1834  Validation loss = 3.3818  \n",
      "\n",
      "Fold: 1  Epoch: 212  Training loss = 3.1833  Validation loss = 3.3815  \n",
      "\n",
      "Fold: 1  Epoch: 213  Training loss = 3.1832  Validation loss = 3.3813  \n",
      "\n",
      "Fold: 1  Epoch: 214  Training loss = 3.1831  Validation loss = 3.3811  \n",
      "\n",
      "Fold: 1  Epoch: 215  Training loss = 3.1830  Validation loss = 3.3809  \n",
      "\n",
      "Fold: 1  Epoch: 216  Training loss = 3.1829  Validation loss = 3.3807  \n",
      "\n",
      "Fold: 1  Epoch: 217  Training loss = 3.1827  Validation loss = 3.3804  \n",
      "\n",
      "Fold: 1  Epoch: 218  Training loss = 3.1826  Validation loss = 3.3802  \n",
      "\n",
      "Fold: 1  Epoch: 219  Training loss = 3.1825  Validation loss = 3.3800  \n",
      "\n",
      "Fold: 1  Epoch: 220  Training loss = 3.1824  Validation loss = 3.3798  \n",
      "\n",
      "Fold: 1  Epoch: 221  Training loss = 3.1823  Validation loss = 3.3796  \n",
      "\n",
      "Fold: 1  Epoch: 222  Training loss = 3.1821  Validation loss = 3.3794  \n",
      "\n",
      "Fold: 1  Epoch: 223  Training loss = 3.1820  Validation loss = 3.3790  \n",
      "\n",
      "Fold: 1  Epoch: 224  Training loss = 3.1818  Validation loss = 3.3788  \n",
      "\n",
      "Fold: 1  Epoch: 225  Training loss = 3.1817  Validation loss = 3.3786  \n",
      "\n",
      "Fold: 1  Epoch: 226  Training loss = 3.1816  Validation loss = 3.3784  \n",
      "\n",
      "Fold: 1  Epoch: 227  Training loss = 3.1815  Validation loss = 3.3781  \n",
      "\n",
      "Fold: 1  Epoch: 228  Training loss = 3.1813  Validation loss = 3.3779  \n",
      "\n",
      "Fold: 1  Epoch: 229  Training loss = 3.1812  Validation loss = 3.3777  \n",
      "\n",
      "Fold: 1  Epoch: 230  Training loss = 3.1811  Validation loss = 3.3774  \n",
      "\n",
      "Fold: 1  Epoch: 231  Training loss = 3.1809  Validation loss = 3.3772  \n",
      "\n",
      "Fold: 1  Epoch: 232  Training loss = 3.1808  Validation loss = 3.3770  \n",
      "\n",
      "Fold: 1  Epoch: 233  Training loss = 3.1807  Validation loss = 3.3768  \n",
      "\n",
      "Fold: 1  Epoch: 234  Training loss = 3.1806  Validation loss = 3.3766  \n",
      "\n",
      "Fold: 1  Epoch: 235  Training loss = 3.1805  Validation loss = 3.3764  \n",
      "\n",
      "Fold: 1  Epoch: 236  Training loss = 3.1804  Validation loss = 3.3762  \n",
      "\n",
      "Fold: 1  Epoch: 237  Training loss = 3.1803  Validation loss = 3.3760  \n",
      "\n",
      "Fold: 1  Epoch: 238  Training loss = 3.1802  Validation loss = 3.3758  \n",
      "\n",
      "Fold: 1  Epoch: 239  Training loss = 3.1800  Validation loss = 3.3755  \n",
      "\n",
      "Fold: 1  Epoch: 240  Training loss = 3.1799  Validation loss = 3.3753  \n",
      "\n",
      "Fold: 1  Epoch: 241  Training loss = 3.1798  Validation loss = 3.3750  \n",
      "\n",
      "Fold: 1  Epoch: 242  Training loss = 3.1796  Validation loss = 3.3748  \n",
      "\n",
      "Fold: 1  Epoch: 243  Training loss = 3.1795  Validation loss = 3.3745  \n",
      "\n",
      "Fold: 1  Epoch: 244  Training loss = 3.1794  Validation loss = 3.3743  \n",
      "\n",
      "Fold: 1  Epoch: 245  Training loss = 3.1793  Validation loss = 3.3741  \n",
      "\n",
      "Fold: 1  Epoch: 246  Training loss = 3.1791  Validation loss = 3.3738  \n",
      "\n",
      "Fold: 1  Epoch: 247  Training loss = 3.1790  Validation loss = 3.3736  \n",
      "\n",
      "Fold: 1  Epoch: 248  Training loss = 3.1788  Validation loss = 3.3732  \n",
      "\n",
      "Fold: 1  Epoch: 249  Training loss = 3.1787  Validation loss = 3.3730  \n",
      "\n",
      "Fold: 1  Epoch: 250  Training loss = 3.1785  Validation loss = 3.3727  \n",
      "\n",
      "Fold: 1  Epoch: 251  Training loss = 3.1784  Validation loss = 3.3725  \n",
      "\n",
      "Fold: 1  Epoch: 252  Training loss = 3.1783  Validation loss = 3.3723  \n",
      "\n",
      "Fold: 1  Epoch: 253  Training loss = 3.1782  Validation loss = 3.3720  \n",
      "\n",
      "Fold: 1  Epoch: 254  Training loss = 3.1780  Validation loss = 3.3717  \n",
      "\n",
      "Fold: 1  Epoch: 255  Training loss = 3.1779  Validation loss = 3.3715  \n",
      "\n",
      "Fold: 1  Epoch: 256  Training loss = 3.1778  Validation loss = 3.3714  \n",
      "\n",
      "Fold: 1  Epoch: 257  Training loss = 3.1776  Validation loss = 3.3711  \n",
      "\n",
      "Fold: 1  Epoch: 258  Training loss = 3.1775  Validation loss = 3.3708  \n",
      "\n",
      "Fold: 1  Epoch: 259  Training loss = 3.1774  Validation loss = 3.3706  \n",
      "\n",
      "Fold: 1  Epoch: 260  Training loss = 3.1773  Validation loss = 3.3704  \n",
      "\n",
      "Fold: 1  Epoch: 261  Training loss = 3.1772  Validation loss = 3.3702  \n",
      "\n",
      "Fold: 1  Epoch: 262  Training loss = 3.1770  Validation loss = 3.3699  \n",
      "\n",
      "Fold: 1  Epoch: 263  Training loss = 3.1769  Validation loss = 3.3697  \n",
      "\n",
      "Fold: 1  Epoch: 264  Training loss = 3.1768  Validation loss = 3.3695  \n",
      "\n",
      "Fold: 1  Epoch: 265  Training loss = 3.1766  Validation loss = 3.3693  \n",
      "\n",
      "Fold: 1  Epoch: 266  Training loss = 3.1766  Validation loss = 3.3691  \n",
      "\n",
      "Fold: 1  Epoch: 267  Training loss = 3.1765  Validation loss = 3.3689  \n",
      "\n",
      "Fold: 1  Epoch: 268  Training loss = 3.1763  Validation loss = 3.3686  \n",
      "\n",
      "Fold: 1  Epoch: 269  Training loss = 3.1762  Validation loss = 3.3684  \n",
      "\n",
      "Fold: 1  Epoch: 270  Training loss = 3.1761  Validation loss = 3.3682  \n",
      "\n",
      "Fold: 1  Epoch: 271  Training loss = 3.1760  Validation loss = 3.3679  \n",
      "\n",
      "Fold: 1  Epoch: 272  Training loss = 3.1759  Validation loss = 3.3677  \n",
      "\n",
      "Fold: 1  Epoch: 273  Training loss = 3.1757  Validation loss = 3.3675  \n",
      "\n",
      "Fold: 1  Epoch: 274  Training loss = 3.1756  Validation loss = 3.3673  \n",
      "\n",
      "Fold: 1  Epoch: 275  Training loss = 3.1755  Validation loss = 3.3670  \n",
      "\n",
      "Fold: 1  Epoch: 276  Training loss = 3.1754  Validation loss = 3.3668  \n",
      "\n",
      "Fold: 1  Epoch: 277  Training loss = 3.1752  Validation loss = 3.3666  \n",
      "\n",
      "Fold: 1  Epoch: 278  Training loss = 3.1751  Validation loss = 3.3663  \n",
      "\n",
      "Fold: 1  Epoch: 279  Training loss = 3.1750  Validation loss = 3.3661  \n",
      "\n",
      "Fold: 1  Epoch: 280  Training loss = 3.1749  Validation loss = 3.3659  \n",
      "\n",
      "Fold: 1  Epoch: 281  Training loss = 3.1747  Validation loss = 3.3656  \n",
      "\n",
      "Fold: 1  Epoch: 282  Training loss = 3.1746  Validation loss = 3.3654  \n",
      "\n",
      "Fold: 1  Epoch: 283  Training loss = 3.1745  Validation loss = 3.3652  \n",
      "\n",
      "Fold: 1  Epoch: 284  Training loss = 3.1744  Validation loss = 3.3650  \n",
      "\n",
      "Fold: 1  Epoch: 285  Training loss = 3.1742  Validation loss = 3.3647  \n",
      "\n",
      "Fold: 1  Epoch: 286  Training loss = 3.1741  Validation loss = 3.3645  \n",
      "\n",
      "Fold: 1  Epoch: 287  Training loss = 3.1741  Validation loss = 3.3644  \n",
      "\n",
      "Fold: 1  Epoch: 288  Training loss = 3.1739  Validation loss = 3.3641  \n",
      "\n",
      "Fold: 1  Epoch: 289  Training loss = 3.1738  Validation loss = 3.3639  \n",
      "\n",
      "Fold: 1  Epoch: 290  Training loss = 3.1736  Validation loss = 3.3636  \n",
      "\n",
      "Fold: 1  Epoch: 291  Training loss = 3.1735  Validation loss = 3.3634  \n",
      "\n",
      "Fold: 1  Epoch: 292  Training loss = 3.1734  Validation loss = 3.3632  \n",
      "\n",
      "Fold: 1  Epoch: 293  Training loss = 3.1733  Validation loss = 3.3629  \n",
      "\n",
      "Fold: 1  Epoch: 294  Training loss = 3.1731  Validation loss = 3.3627  \n",
      "\n",
      "Fold: 1  Epoch: 295  Training loss = 3.1730  Validation loss = 3.3624  \n",
      "\n",
      "Fold: 1  Epoch: 296  Training loss = 3.1729  Validation loss = 3.3622  \n",
      "\n",
      "Fold: 1  Epoch: 297  Training loss = 3.1728  Validation loss = 3.3620  \n",
      "\n",
      "Fold: 1  Epoch: 298  Training loss = 3.1727  Validation loss = 3.3618  \n",
      "\n",
      "Fold: 1  Epoch: 299  Training loss = 3.1725  Validation loss = 3.3616  \n",
      "\n",
      "Fold: 1  Epoch: 300  Training loss = 3.1724  Validation loss = 3.3613  \n",
      "\n",
      "Fold: 1  Epoch: 301  Training loss = 3.1722  Validation loss = 3.3610  \n",
      "\n",
      "Fold: 1  Epoch: 302  Training loss = 3.1721  Validation loss = 3.3607  \n",
      "\n",
      "Fold: 1  Epoch: 303  Training loss = 3.1720  Validation loss = 3.3605  \n",
      "\n",
      "Fold: 1  Epoch: 304  Training loss = 3.1719  Validation loss = 3.3603  \n",
      "\n",
      "Fold: 1  Epoch: 305  Training loss = 3.1717  Validation loss = 3.3600  \n",
      "\n",
      "Fold: 1  Epoch: 306  Training loss = 3.1716  Validation loss = 3.3598  \n",
      "\n",
      "Fold: 1  Epoch: 307  Training loss = 3.1715  Validation loss = 3.3596  \n",
      "\n",
      "Fold: 1  Epoch: 308  Training loss = 3.1714  Validation loss = 3.3594  \n",
      "\n",
      "Fold: 1  Epoch: 309  Training loss = 3.1713  Validation loss = 3.3592  \n",
      "\n",
      "Fold: 1  Epoch: 310  Training loss = 3.1712  Validation loss = 3.3590  \n",
      "\n",
      "Fold: 1  Epoch: 311  Training loss = 3.1711  Validation loss = 3.3588  \n",
      "\n",
      "Fold: 1  Epoch: 312  Training loss = 3.1709  Validation loss = 3.3586  \n",
      "\n",
      "Fold: 1  Epoch: 313  Training loss = 3.1708  Validation loss = 3.3584  \n",
      "\n",
      "Fold: 1  Epoch: 314  Training loss = 3.1707  Validation loss = 3.3581  \n",
      "\n",
      "Fold: 1  Epoch: 315  Training loss = 3.1706  Validation loss = 3.3579  \n",
      "\n",
      "Fold: 1  Epoch: 316  Training loss = 3.1705  Validation loss = 3.3576  \n",
      "\n",
      "Fold: 1  Epoch: 317  Training loss = 3.1703  Validation loss = 3.3574  \n",
      "\n",
      "Fold: 1  Epoch: 318  Training loss = 3.1702  Validation loss = 3.3571  \n",
      "\n",
      "Fold: 1  Epoch: 319  Training loss = 3.1700  Validation loss = 3.3568  \n",
      "\n",
      "Fold: 1  Epoch: 320  Training loss = 3.1699  Validation loss = 3.3566  \n",
      "\n",
      "Fold: 1  Epoch: 321  Training loss = 3.1697  Validation loss = 3.3563  \n",
      "\n",
      "Fold: 1  Epoch: 322  Training loss = 3.1696  Validation loss = 3.3561  \n",
      "\n",
      "Fold: 1  Epoch: 323  Training loss = 3.1695  Validation loss = 3.3559  \n",
      "\n",
      "Fold: 1  Epoch: 324  Training loss = 3.1694  Validation loss = 3.3556  \n",
      "\n",
      "Fold: 1  Epoch: 325  Training loss = 3.1692  Validation loss = 3.3554  \n",
      "\n",
      "Fold: 1  Epoch: 326  Training loss = 3.1692  Validation loss = 3.3552  \n",
      "\n",
      "Fold: 1  Epoch: 327  Training loss = 3.1690  Validation loss = 3.3550  \n",
      "\n",
      "Fold: 1  Epoch: 328  Training loss = 3.1689  Validation loss = 3.3548  \n",
      "\n",
      "Fold: 1  Epoch: 329  Training loss = 3.1688  Validation loss = 3.3545  \n",
      "\n",
      "Fold: 1  Epoch: 330  Training loss = 3.1687  Validation loss = 3.3543  \n",
      "\n",
      "Fold: 1  Epoch: 331  Training loss = 3.1686  Validation loss = 3.3541  \n",
      "\n",
      "Fold: 1  Epoch: 332  Training loss = 3.1685  Validation loss = 3.3539  \n",
      "\n",
      "Fold: 1  Epoch: 333  Training loss = 3.1683  Validation loss = 3.3536  \n",
      "\n",
      "Fold: 1  Epoch: 334  Training loss = 3.1681  Validation loss = 3.3533  \n",
      "\n",
      "Fold: 1  Epoch: 335  Training loss = 3.1680  Validation loss = 3.3531  \n",
      "\n",
      "Fold: 1  Epoch: 336  Training loss = 3.1679  Validation loss = 3.3529  \n",
      "\n",
      "Fold: 1  Epoch: 337  Training loss = 3.1677  Validation loss = 3.3526  \n",
      "\n",
      "Fold: 1  Epoch: 338  Training loss = 3.1676  Validation loss = 3.3523  \n",
      "\n",
      "Fold: 1  Epoch: 339  Training loss = 3.1675  Validation loss = 3.3521  \n",
      "\n",
      "Fold: 1  Epoch: 340  Training loss = 3.1673  Validation loss = 3.3518  \n",
      "\n",
      "Fold: 1  Epoch: 341  Training loss = 3.1672  Validation loss = 3.3516  \n",
      "\n",
      "Fold: 1  Epoch: 342  Training loss = 3.1671  Validation loss = 3.3514  \n",
      "\n",
      "Fold: 1  Epoch: 343  Training loss = 3.1670  Validation loss = 3.3512  \n",
      "\n",
      "Fold: 1  Epoch: 344  Training loss = 3.1669  Validation loss = 3.3509  \n",
      "\n",
      "Fold: 1  Epoch: 345  Training loss = 3.1667  Validation loss = 3.3507  \n",
      "\n",
      "Fold: 1  Epoch: 346  Training loss = 3.1666  Validation loss = 3.3505  \n",
      "\n",
      "Fold: 1  Epoch: 347  Training loss = 3.1665  Validation loss = 3.3503  \n",
      "\n",
      "Fold: 1  Epoch: 348  Training loss = 3.1664  Validation loss = 3.3501  \n",
      "\n",
      "Fold: 1  Epoch: 349  Training loss = 3.1663  Validation loss = 3.3498  \n",
      "\n",
      "Fold: 1  Epoch: 350  Training loss = 3.1661  Validation loss = 3.3495  \n",
      "\n",
      "Fold: 1  Epoch: 351  Training loss = 3.1660  Validation loss = 3.3493  \n",
      "\n",
      "Fold: 1  Epoch: 352  Training loss = 3.1659  Validation loss = 3.3491  \n",
      "\n",
      "Fold: 1  Epoch: 353  Training loss = 3.1658  Validation loss = 3.3490  \n",
      "\n",
      "Fold: 1  Epoch: 354  Training loss = 3.1657  Validation loss = 3.3487  \n",
      "\n",
      "Fold: 1  Epoch: 355  Training loss = 3.1656  Validation loss = 3.3485  \n",
      "\n",
      "Fold: 1  Epoch: 356  Training loss = 3.1654  Validation loss = 3.3483  \n",
      "\n",
      "Fold: 1  Epoch: 357  Training loss = 3.1653  Validation loss = 3.3480  \n",
      "\n",
      "Fold: 1  Epoch: 358  Training loss = 3.1652  Validation loss = 3.3478  \n",
      "\n",
      "Fold: 1  Epoch: 359  Training loss = 3.1651  Validation loss = 3.3476  \n",
      "\n",
      "Fold: 1  Epoch: 360  Training loss = 3.1650  Validation loss = 3.3474  \n",
      "\n",
      "Fold: 1  Epoch: 361  Training loss = 3.1649  Validation loss = 3.3472  \n",
      "\n",
      "Fold: 1  Epoch: 362  Training loss = 3.1647  Validation loss = 3.3468  \n",
      "\n",
      "Fold: 1  Epoch: 363  Training loss = 3.1646  Validation loss = 3.3467  \n",
      "\n",
      "Fold: 1  Epoch: 364  Training loss = 3.1644  Validation loss = 3.3464  \n",
      "\n",
      "Fold: 1  Epoch: 365  Training loss = 3.1643  Validation loss = 3.3461  \n",
      "\n",
      "Fold: 1  Epoch: 366  Training loss = 3.1642  Validation loss = 3.3460  \n",
      "\n",
      "Fold: 1  Epoch: 367  Training loss = 3.1641  Validation loss = 3.3458  \n",
      "\n",
      "Fold: 1  Epoch: 368  Training loss = 3.1640  Validation loss = 3.3455  \n",
      "\n",
      "Fold: 1  Epoch: 369  Training loss = 3.1638  Validation loss = 3.3452  \n",
      "\n",
      "Fold: 1  Epoch: 370  Training loss = 3.1637  Validation loss = 3.3451  \n",
      "\n",
      "Fold: 1  Epoch: 371  Training loss = 3.1636  Validation loss = 3.3448  \n",
      "\n",
      "Fold: 1  Epoch: 372  Training loss = 3.1635  Validation loss = 3.3446  \n",
      "\n",
      "Fold: 1  Epoch: 373  Training loss = 3.1633  Validation loss = 3.3442  \n",
      "\n",
      "Fold: 1  Epoch: 374  Training loss = 3.1632  Validation loss = 3.3440  \n",
      "\n",
      "Fold: 1  Epoch: 375  Training loss = 3.1630  Validation loss = 3.3438  \n",
      "\n",
      "Fold: 1  Epoch: 376  Training loss = 3.1629  Validation loss = 3.3436  \n",
      "\n",
      "Fold: 1  Epoch: 377  Training loss = 3.1628  Validation loss = 3.3434  \n",
      "\n",
      "Fold: 1  Epoch: 378  Training loss = 3.1627  Validation loss = 3.3431  \n",
      "\n",
      "Fold: 1  Epoch: 379  Training loss = 3.1625  Validation loss = 3.3428  \n",
      "\n",
      "Fold: 1  Epoch: 380  Training loss = 3.1624  Validation loss = 3.3426  \n",
      "\n",
      "Fold: 1  Epoch: 381  Training loss = 3.1623  Validation loss = 3.3424  \n",
      "\n",
      "Fold: 1  Epoch: 382  Training loss = 3.1621  Validation loss = 3.3421  \n",
      "\n",
      "Fold: 1  Epoch: 383  Training loss = 3.1620  Validation loss = 3.3419  \n",
      "\n",
      "Fold: 1  Epoch: 384  Training loss = 3.1619  Validation loss = 3.3417  \n",
      "\n",
      "Fold: 1  Epoch: 385  Training loss = 3.1618  Validation loss = 3.3415  \n",
      "\n",
      "Fold: 1  Epoch: 386  Training loss = 3.1617  Validation loss = 3.3413  \n",
      "\n",
      "Fold: 1  Epoch: 387  Training loss = 3.1616  Validation loss = 3.3410  \n",
      "\n",
      "Fold: 1  Epoch: 388  Training loss = 3.1614  Validation loss = 3.3408  \n",
      "\n",
      "Fold: 1  Epoch: 389  Training loss = 3.1613  Validation loss = 3.3405  \n",
      "\n",
      "Fold: 1  Epoch: 390  Training loss = 3.1612  Validation loss = 3.3403  \n",
      "\n",
      "Fold: 1  Epoch: 391  Training loss = 3.1611  Validation loss = 3.3401  \n",
      "\n",
      "Fold: 1  Epoch: 392  Training loss = 3.1610  Validation loss = 3.3399  \n",
      "\n",
      "Fold: 1  Epoch: 393  Training loss = 3.1609  Validation loss = 3.3397  \n",
      "\n",
      "Fold: 1  Epoch: 394  Training loss = 3.1607  Validation loss = 3.3394  \n",
      "\n",
      "Fold: 1  Epoch: 395  Training loss = 3.1606  Validation loss = 3.3393  \n",
      "\n",
      "Fold: 1  Epoch: 396  Training loss = 3.1605  Validation loss = 3.3390  \n",
      "\n",
      "Fold: 1  Epoch: 397  Training loss = 3.1604  Validation loss = 3.3388  \n",
      "\n",
      "Fold: 1  Epoch: 398  Training loss = 3.1603  Validation loss = 3.3386  \n",
      "\n",
      "Fold: 1  Epoch: 399  Training loss = 3.1602  Validation loss = 3.3384  \n",
      "\n",
      "Fold: 1  Epoch: 400  Training loss = 3.1601  Validation loss = 3.3383  \n",
      "\n",
      "Fold: 1  Epoch: 401  Training loss = 3.1600  Validation loss = 3.3381  \n",
      "\n",
      "Fold: 1  Epoch: 402  Training loss = 3.1599  Validation loss = 3.3378  \n",
      "\n",
      "Fold: 1  Epoch: 403  Training loss = 3.1598  Validation loss = 3.3376  \n",
      "\n",
      "Fold: 1  Epoch: 404  Training loss = 3.1597  Validation loss = 3.3374  \n",
      "\n",
      "Fold: 1  Epoch: 405  Training loss = 3.1596  Validation loss = 3.3373  \n",
      "\n",
      "Fold: 1  Epoch: 406  Training loss = 3.1595  Validation loss = 3.3370  \n",
      "\n",
      "Fold: 1  Epoch: 407  Training loss = 3.1593  Validation loss = 3.3368  \n",
      "\n",
      "Fold: 1  Epoch: 408  Training loss = 3.1592  Validation loss = 3.3366  \n",
      "\n",
      "Fold: 1  Epoch: 409  Training loss = 3.1591  Validation loss = 3.3363  \n",
      "\n",
      "Fold: 1  Epoch: 410  Training loss = 3.1590  Validation loss = 3.3361  \n",
      "\n",
      "Fold: 1  Epoch: 411  Training loss = 3.1589  Validation loss = 3.3359  \n",
      "\n",
      "Fold: 1  Epoch: 412  Training loss = 3.1587  Validation loss = 3.3356  \n",
      "\n",
      "Fold: 1  Epoch: 413  Training loss = 3.1586  Validation loss = 3.3354  \n",
      "\n",
      "Fold: 1  Epoch: 414  Training loss = 3.1585  Validation loss = 3.3352  \n",
      "\n",
      "Fold: 1  Epoch: 415  Training loss = 3.1583  Validation loss = 3.3349  \n",
      "\n",
      "Fold: 1  Epoch: 416  Training loss = 3.1582  Validation loss = 3.3347  \n",
      "\n",
      "Fold: 1  Epoch: 417  Training loss = 3.1581  Validation loss = 3.3345  \n",
      "\n",
      "Fold: 1  Epoch: 418  Training loss = 3.1580  Validation loss = 3.3343  \n",
      "\n",
      "Fold: 1  Epoch: 419  Training loss = 3.1579  Validation loss = 3.3340  \n",
      "\n",
      "Fold: 1  Epoch: 420  Training loss = 3.1578  Validation loss = 3.3338  \n",
      "\n",
      "Fold: 1  Epoch: 421  Training loss = 3.1577  Validation loss = 3.3337  \n",
      "\n",
      "Fold: 1  Epoch: 422  Training loss = 3.1576  Validation loss = 3.3335  \n",
      "\n",
      "Fold: 1  Epoch: 423  Training loss = 3.1574  Validation loss = 3.3332  \n",
      "\n",
      "Fold: 1  Epoch: 424  Training loss = 3.1573  Validation loss = 3.3330  \n",
      "\n",
      "Fold: 1  Epoch: 425  Training loss = 3.1572  Validation loss = 3.3328  \n",
      "\n",
      "Fold: 1  Epoch: 426  Training loss = 3.1571  Validation loss = 3.3326  \n",
      "\n",
      "Fold: 1  Epoch: 427  Training loss = 3.1570  Validation loss = 3.3324  \n",
      "\n",
      "Fold: 1  Epoch: 428  Training loss = 3.1569  Validation loss = 3.3322  \n",
      "\n",
      "Fold: 1  Epoch: 429  Training loss = 3.1568  Validation loss = 3.3319  \n",
      "\n",
      "Fold: 1  Epoch: 430  Training loss = 3.1566  Validation loss = 3.3317  \n",
      "\n",
      "Fold: 1  Epoch: 431  Training loss = 3.1566  Validation loss = 3.3316  \n",
      "\n",
      "Fold: 1  Epoch: 432  Training loss = 3.1564  Validation loss = 3.3313  \n",
      "\n",
      "Fold: 1  Epoch: 433  Training loss = 3.1563  Validation loss = 3.3310  \n",
      "\n",
      "Fold: 1  Epoch: 434  Training loss = 3.1562  Validation loss = 3.3308  \n",
      "\n",
      "Fold: 1  Epoch: 435  Training loss = 3.1560  Validation loss = 3.3306  \n",
      "\n",
      "Fold: 1  Epoch: 436  Training loss = 3.1559  Validation loss = 3.3304  \n",
      "\n",
      "Fold: 1  Epoch: 437  Training loss = 3.1558  Validation loss = 3.3302  \n",
      "\n",
      "Fold: 1  Epoch: 438  Training loss = 3.1557  Validation loss = 3.3300  \n",
      "\n",
      "Fold: 1  Epoch: 439  Training loss = 3.1556  Validation loss = 3.3297  \n",
      "\n",
      "Fold: 1  Epoch: 440  Training loss = 3.1554  Validation loss = 3.3295  \n",
      "\n",
      "Fold: 1  Epoch: 441  Training loss = 3.1553  Validation loss = 3.3292  \n",
      "\n",
      "Fold: 1  Epoch: 442  Training loss = 3.1552  Validation loss = 3.3290  \n",
      "\n",
      "Fold: 1  Epoch: 443  Training loss = 3.1550  Validation loss = 3.3286  \n",
      "\n",
      "Fold: 1  Epoch: 444  Training loss = 3.1549  Validation loss = 3.3284  \n",
      "\n",
      "Fold: 1  Epoch: 445  Training loss = 3.1548  Validation loss = 3.3282  \n",
      "\n",
      "Fold: 1  Epoch: 446  Training loss = 3.1546  Validation loss = 3.3279  \n",
      "\n",
      "Fold: 1  Epoch: 447  Training loss = 3.1545  Validation loss = 3.3277  \n",
      "\n",
      "Fold: 1  Epoch: 448  Training loss = 3.1544  Validation loss = 3.3275  \n",
      "\n",
      "Fold: 1  Epoch: 449  Training loss = 3.1543  Validation loss = 3.3273  \n",
      "\n",
      "Fold: 1  Epoch: 450  Training loss = 3.1542  Validation loss = 3.3272  \n",
      "\n",
      "Fold: 1  Epoch: 451  Training loss = 3.1541  Validation loss = 3.3269  \n",
      "\n",
      "Fold: 1  Epoch: 452  Training loss = 3.1539  Validation loss = 3.3266  \n",
      "\n",
      "Fold: 1  Epoch: 453  Training loss = 3.1538  Validation loss = 3.3264  \n",
      "\n",
      "Fold: 1  Epoch: 454  Training loss = 3.1537  Validation loss = 3.3262  \n",
      "\n",
      "Fold: 1  Epoch: 455  Training loss = 3.1536  Validation loss = 3.3260  \n",
      "\n",
      "Fold: 1  Epoch: 456  Training loss = 3.1534  Validation loss = 3.3257  \n",
      "\n",
      "Fold: 1  Epoch: 457  Training loss = 3.1533  Validation loss = 3.3255  \n",
      "\n",
      "Fold: 1  Epoch: 458  Training loss = 3.1532  Validation loss = 3.3252  \n",
      "\n",
      "Fold: 1  Epoch: 459  Training loss = 3.1531  Validation loss = 3.3251  \n",
      "\n",
      "Fold: 1  Epoch: 460  Training loss = 3.1529  Validation loss = 3.3247  \n",
      "\n",
      "Fold: 1  Epoch: 461  Training loss = 3.1527  Validation loss = 3.3245  \n",
      "\n",
      "Fold: 1  Epoch: 462  Training loss = 3.1526  Validation loss = 3.3242  \n",
      "\n",
      "Fold: 1  Epoch: 463  Training loss = 3.1525  Validation loss = 3.3240  \n",
      "\n",
      "Fold: 1  Epoch: 464  Training loss = 3.1524  Validation loss = 3.3238  \n",
      "\n",
      "Fold: 1  Epoch: 465  Training loss = 3.1523  Validation loss = 3.3236  \n",
      "\n",
      "Fold: 1  Epoch: 466  Training loss = 3.1522  Validation loss = 3.3234  \n",
      "\n",
      "Fold: 1  Epoch: 467  Training loss = 3.1520  Validation loss = 3.3232  \n",
      "\n",
      "Fold: 1  Epoch: 468  Training loss = 3.1519  Validation loss = 3.3229  \n",
      "\n",
      "Fold: 1  Epoch: 469  Training loss = 3.1518  Validation loss = 3.3227  \n",
      "\n",
      "Fold: 1  Epoch: 470  Training loss = 3.1516  Validation loss = 3.3224  \n",
      "\n",
      "Fold: 1  Epoch: 471  Training loss = 3.1515  Validation loss = 3.3222  \n",
      "\n",
      "Fold: 1  Epoch: 472  Training loss = 3.1514  Validation loss = 3.3220  \n",
      "\n",
      "Fold: 1  Epoch: 473  Training loss = 3.1513  Validation loss = 3.3219  \n",
      "\n",
      "Fold: 1  Epoch: 474  Training loss = 3.1512  Validation loss = 3.3216  \n",
      "\n",
      "Fold: 1  Epoch: 475  Training loss = 3.1511  Validation loss = 3.3213  \n",
      "\n",
      "Fold: 1  Epoch: 476  Training loss = 3.1509  Validation loss = 3.3211  \n",
      "\n",
      "Fold: 1  Epoch: 477  Training loss = 3.1508  Validation loss = 3.3208  \n",
      "\n",
      "Fold: 1  Epoch: 478  Training loss = 3.1507  Validation loss = 3.3206  \n",
      "\n",
      "Fold: 1  Epoch: 479  Training loss = 3.1505  Validation loss = 3.3204  \n",
      "\n",
      "Fold: 1  Epoch: 480  Training loss = 3.1504  Validation loss = 3.3202  \n",
      "\n",
      "Fold: 1  Epoch: 481  Training loss = 3.1503  Validation loss = 3.3200  \n",
      "\n",
      "Fold: 1  Epoch: 482  Training loss = 3.1502  Validation loss = 3.3197  \n",
      "\n",
      "Fold: 1  Epoch: 483  Training loss = 3.1500  Validation loss = 3.3194  \n",
      "\n",
      "Fold: 1  Epoch: 484  Training loss = 3.1499  Validation loss = 3.3193  \n",
      "\n",
      "Fold: 1  Epoch: 485  Training loss = 3.1498  Validation loss = 3.3191  \n",
      "\n",
      "Fold: 1  Epoch: 486  Training loss = 3.1498  Validation loss = 3.3189  \n",
      "\n",
      "Fold: 1  Epoch: 487  Training loss = 3.1496  Validation loss = 3.3186  \n",
      "\n",
      "Fold: 1  Epoch: 488  Training loss = 3.1495  Validation loss = 3.3184  \n",
      "\n",
      "Fold: 1  Epoch: 489  Training loss = 3.1494  Validation loss = 3.3182  \n",
      "\n",
      "Fold: 1  Epoch: 490  Training loss = 3.1493  Validation loss = 3.3180  \n",
      "\n",
      "Fold: 1  Epoch: 491  Training loss = 3.1491  Validation loss = 3.3177  \n",
      "\n",
      "Fold: 1  Epoch: 492  Training loss = 3.1491  Validation loss = 3.3176  \n",
      "\n",
      "Fold: 1  Epoch: 493  Training loss = 3.1489  Validation loss = 3.3173  \n",
      "\n",
      "Fold: 1  Epoch: 494  Training loss = 3.1488  Validation loss = 3.3171  \n",
      "\n",
      "Fold: 1  Epoch: 495  Training loss = 3.1487  Validation loss = 3.3169  \n",
      "\n",
      "Fold: 1  Epoch: 496  Training loss = 3.1486  Validation loss = 3.3167  \n",
      "\n",
      "Fold: 1  Epoch: 497  Training loss = 3.1485  Validation loss = 3.3165  \n",
      "\n",
      "Fold: 1  Epoch: 498  Training loss = 3.1484  Validation loss = 3.3163  \n",
      "\n",
      "Fold: 1  Epoch: 499  Training loss = 3.1483  Validation loss = 3.3161  \n",
      "\n",
      "Fold: 1  Epoch: 500  Training loss = 3.1482  Validation loss = 3.3159  \n",
      "\n",
      "Check model:  Fold: 1  Optimal epoch: 500  \n",
      "\n",
      "Fold: 2  Epoch: 1  Training loss = 3.1064  Validation loss = 3.2985  \n",
      "\n",
      "Fold: 2  Epoch: 2  Training loss = 3.1063  Validation loss = 3.2983  \n",
      "\n",
      "Fold: 2  Epoch: 3  Training loss = 3.1062  Validation loss = 3.2981  \n",
      "\n",
      "Fold: 2  Epoch: 4  Training loss = 3.1060  Validation loss = 3.2980  \n",
      "\n",
      "Fold: 2  Epoch: 5  Training loss = 3.1059  Validation loss = 3.2978  \n",
      "\n",
      "Fold: 2  Epoch: 6  Training loss = 3.1058  Validation loss = 3.2976  \n",
      "\n",
      "Fold: 2  Epoch: 7  Training loss = 3.1056  Validation loss = 3.2975  \n",
      "\n",
      "Fold: 2  Epoch: 8  Training loss = 3.1055  Validation loss = 3.2973  \n",
      "\n",
      "Fold: 2  Epoch: 9  Training loss = 3.1054  Validation loss = 3.2971  \n",
      "\n",
      "Fold: 2  Epoch: 10  Training loss = 3.1052  Validation loss = 3.2970  \n",
      "\n",
      "Fold: 2  Epoch: 11  Training loss = 3.1051  Validation loss = 3.2968  \n",
      "\n",
      "Fold: 2  Epoch: 12  Training loss = 3.1049  Validation loss = 3.2966  \n",
      "\n",
      "Fold: 2  Epoch: 13  Training loss = 3.1048  Validation loss = 3.2964  \n",
      "\n",
      "Fold: 2  Epoch: 14  Training loss = 3.1047  Validation loss = 3.2963  \n",
      "\n",
      "Fold: 2  Epoch: 15  Training loss = 3.1046  Validation loss = 3.2961  \n",
      "\n",
      "Fold: 2  Epoch: 16  Training loss = 3.1044  Validation loss = 3.2960  \n",
      "\n",
      "Fold: 2  Epoch: 17  Training loss = 3.1043  Validation loss = 3.2958  \n",
      "\n",
      "Fold: 2  Epoch: 18  Training loss = 3.1042  Validation loss = 3.2957  \n",
      "\n",
      "Fold: 2  Epoch: 19  Training loss = 3.1041  Validation loss = 3.2955  \n",
      "\n",
      "Fold: 2  Epoch: 20  Training loss = 3.1040  Validation loss = 3.2954  \n",
      "\n",
      "Fold: 2  Epoch: 21  Training loss = 3.1038  Validation loss = 3.2952  \n",
      "\n",
      "Fold: 2  Epoch: 22  Training loss = 3.1037  Validation loss = 3.2950  \n",
      "\n",
      "Fold: 2  Epoch: 23  Training loss = 3.1036  Validation loss = 3.2949  \n",
      "\n",
      "Fold: 2  Epoch: 24  Training loss = 3.1034  Validation loss = 3.2947  \n",
      "\n",
      "Fold: 2  Epoch: 25  Training loss = 3.1033  Validation loss = 3.2945  \n",
      "\n",
      "Fold: 2  Epoch: 26  Training loss = 3.1032  Validation loss = 3.2944  \n",
      "\n",
      "Fold: 2  Epoch: 27  Training loss = 3.1031  Validation loss = 3.2942  \n",
      "\n",
      "Fold: 2  Epoch: 28  Training loss = 3.1030  Validation loss = 3.2941  \n",
      "\n",
      "Fold: 2  Epoch: 29  Training loss = 3.1029  Validation loss = 3.2940  \n",
      "\n",
      "Fold: 2  Epoch: 30  Training loss = 3.1028  Validation loss = 3.2938  \n",
      "\n",
      "Fold: 2  Epoch: 31  Training loss = 3.1026  Validation loss = 3.2936  \n",
      "\n",
      "Fold: 2  Epoch: 32  Training loss = 3.1025  Validation loss = 3.2935  \n",
      "\n",
      "Fold: 2  Epoch: 33  Training loss = 3.1024  Validation loss = 3.2933  \n",
      "\n",
      "Fold: 2  Epoch: 34  Training loss = 3.1023  Validation loss = 3.2932  \n",
      "\n",
      "Fold: 2  Epoch: 35  Training loss = 3.1022  Validation loss = 3.2930  \n",
      "\n",
      "Fold: 2  Epoch: 36  Training loss = 3.1020  Validation loss = 3.2928  \n",
      "\n",
      "Fold: 2  Epoch: 37  Training loss = 3.1019  Validation loss = 3.2927  \n",
      "\n",
      "Fold: 2  Epoch: 38  Training loss = 3.1018  Validation loss = 3.2925  \n",
      "\n",
      "Fold: 2  Epoch: 39  Training loss = 3.1017  Validation loss = 3.2924  \n",
      "\n",
      "Fold: 2  Epoch: 40  Training loss = 3.1016  Validation loss = 3.2922  \n",
      "\n",
      "Fold: 2  Epoch: 41  Training loss = 3.1015  Validation loss = 3.2921  \n",
      "\n",
      "Fold: 2  Epoch: 42  Training loss = 3.1014  Validation loss = 3.2920  \n",
      "\n",
      "Fold: 2  Epoch: 43  Training loss = 3.1012  Validation loss = 3.2917  \n",
      "\n",
      "Fold: 2  Epoch: 44  Training loss = 3.1011  Validation loss = 3.2916  \n",
      "\n",
      "Fold: 2  Epoch: 45  Training loss = 3.1009  Validation loss = 3.2914  \n",
      "\n",
      "Fold: 2  Epoch: 46  Training loss = 3.1008  Validation loss = 3.2913  \n",
      "\n",
      "Fold: 2  Epoch: 47  Training loss = 3.1007  Validation loss = 3.2911  \n",
      "\n",
      "Fold: 2  Epoch: 48  Training loss = 3.1005  Validation loss = 3.2909  \n",
      "\n",
      "Fold: 2  Epoch: 49  Training loss = 3.1004  Validation loss = 3.2908  \n",
      "\n",
      "Fold: 2  Epoch: 50  Training loss = 3.1003  Validation loss = 3.2906  \n",
      "\n",
      "Fold: 2  Epoch: 51  Training loss = 3.1002  Validation loss = 3.2905  \n",
      "\n",
      "Fold: 2  Epoch: 52  Training loss = 3.1000  Validation loss = 3.2903  \n",
      "\n",
      "Fold: 2  Epoch: 53  Training loss = 3.0999  Validation loss = 3.2901  \n",
      "\n",
      "Fold: 2  Epoch: 54  Training loss = 3.0998  Validation loss = 3.2900  \n",
      "\n",
      "Fold: 2  Epoch: 55  Training loss = 3.0997  Validation loss = 3.2898  \n",
      "\n",
      "Fold: 2  Epoch: 56  Training loss = 3.0996  Validation loss = 3.2897  \n",
      "\n",
      "Fold: 2  Epoch: 57  Training loss = 3.0995  Validation loss = 3.2895  \n",
      "\n",
      "Fold: 2  Epoch: 58  Training loss = 3.0993  Validation loss = 3.2894  \n",
      "\n",
      "Fold: 2  Epoch: 59  Training loss = 3.0992  Validation loss = 3.2892  \n",
      "\n",
      "Fold: 2  Epoch: 60  Training loss = 3.0991  Validation loss = 3.2891  \n",
      "\n",
      "Fold: 2  Epoch: 61  Training loss = 3.0990  Validation loss = 3.2889  \n",
      "\n",
      "Fold: 2  Epoch: 62  Training loss = 3.0988  Validation loss = 3.2888  \n",
      "\n",
      "Fold: 2  Epoch: 63  Training loss = 3.0987  Validation loss = 3.2886  \n",
      "\n",
      "Fold: 2  Epoch: 64  Training loss = 3.0986  Validation loss = 3.2884  \n",
      "\n",
      "Fold: 2  Epoch: 65  Training loss = 3.0985  Validation loss = 3.2883  \n",
      "\n",
      "Fold: 2  Epoch: 66  Training loss = 3.0983  Validation loss = 3.2881  \n",
      "\n",
      "Fold: 2  Epoch: 67  Training loss = 3.0982  Validation loss = 3.2880  \n",
      "\n",
      "Fold: 2  Epoch: 68  Training loss = 3.0980  Validation loss = 3.2878  \n",
      "\n",
      "Fold: 2  Epoch: 69  Training loss = 3.0979  Validation loss = 3.2877  \n",
      "\n",
      "Fold: 2  Epoch: 70  Training loss = 3.0978  Validation loss = 3.2875  \n",
      "\n",
      "Fold: 2  Epoch: 71  Training loss = 3.0977  Validation loss = 3.2873  \n",
      "\n",
      "Fold: 2  Epoch: 72  Training loss = 3.0975  Validation loss = 3.2872  \n",
      "\n",
      "Fold: 2  Epoch: 73  Training loss = 3.0974  Validation loss = 3.2870  \n",
      "\n",
      "Fold: 2  Epoch: 74  Training loss = 3.0973  Validation loss = 3.2868  \n",
      "\n",
      "Fold: 2  Epoch: 75  Training loss = 3.0971  Validation loss = 3.2866  \n",
      "\n",
      "Fold: 2  Epoch: 76  Training loss = 3.0970  Validation loss = 3.2865  \n",
      "\n",
      "Fold: 2  Epoch: 77  Training loss = 3.0968  Validation loss = 3.2863  \n",
      "\n",
      "Fold: 2  Epoch: 78  Training loss = 3.0967  Validation loss = 3.2861  \n",
      "\n",
      "Fold: 2  Epoch: 79  Training loss = 3.0966  Validation loss = 3.2859  \n",
      "\n",
      "Fold: 2  Epoch: 80  Training loss = 3.0964  Validation loss = 3.2858  \n",
      "\n",
      "Fold: 2  Epoch: 81  Training loss = 3.0963  Validation loss = 3.2856  \n",
      "\n",
      "Fold: 2  Epoch: 82  Training loss = 3.0962  Validation loss = 3.2854  \n",
      "\n",
      "Fold: 2  Epoch: 83  Training loss = 3.0960  Validation loss = 3.2853  \n",
      "\n",
      "Fold: 2  Epoch: 84  Training loss = 3.0958  Validation loss = 3.2851  \n",
      "\n",
      "Fold: 2  Epoch: 85  Training loss = 3.0957  Validation loss = 3.2849  \n",
      "\n",
      "Fold: 2  Epoch: 86  Training loss = 3.0956  Validation loss = 3.2847  \n",
      "\n",
      "Fold: 2  Epoch: 87  Training loss = 3.0955  Validation loss = 3.2846  \n",
      "\n",
      "Fold: 2  Epoch: 88  Training loss = 3.0954  Validation loss = 3.2844  \n",
      "\n",
      "Fold: 2  Epoch: 89  Training loss = 3.0952  Validation loss = 3.2842  \n",
      "\n",
      "Fold: 2  Epoch: 90  Training loss = 3.0951  Validation loss = 3.2841  \n",
      "\n",
      "Fold: 2  Epoch: 91  Training loss = 3.0950  Validation loss = 3.2839  \n",
      "\n",
      "Fold: 2  Epoch: 92  Training loss = 3.0949  Validation loss = 3.2837  \n",
      "\n",
      "Fold: 2  Epoch: 93  Training loss = 3.0948  Validation loss = 3.2836  \n",
      "\n",
      "Fold: 2  Epoch: 94  Training loss = 3.0946  Validation loss = 3.2834  \n",
      "\n",
      "Fold: 2  Epoch: 95  Training loss = 3.0945  Validation loss = 3.2832  \n",
      "\n",
      "Fold: 2  Epoch: 96  Training loss = 3.0943  Validation loss = 3.2831  \n",
      "\n",
      "Fold: 2  Epoch: 97  Training loss = 3.0942  Validation loss = 3.2829  \n",
      "\n",
      "Fold: 2  Epoch: 98  Training loss = 3.0941  Validation loss = 3.2828  \n",
      "\n",
      "Fold: 2  Epoch: 99  Training loss = 3.0940  Validation loss = 3.2826  \n",
      "\n",
      "Fold: 2  Epoch: 100  Training loss = 3.0938  Validation loss = 3.2824  \n",
      "\n",
      "Fold: 2  Epoch: 101  Training loss = 3.0937  Validation loss = 3.2823  \n",
      "\n",
      "Fold: 2  Epoch: 102  Training loss = 3.0936  Validation loss = 3.2821  \n",
      "\n",
      "Fold: 2  Epoch: 103  Training loss = 3.0935  Validation loss = 3.2820  \n",
      "\n",
      "Fold: 2  Epoch: 104  Training loss = 3.0934  Validation loss = 3.2818  \n",
      "\n",
      "Fold: 2  Epoch: 105  Training loss = 3.0932  Validation loss = 3.2816  \n",
      "\n",
      "Fold: 2  Epoch: 106  Training loss = 3.0931  Validation loss = 3.2815  \n",
      "\n",
      "Fold: 2  Epoch: 107  Training loss = 3.0930  Validation loss = 3.2813  \n",
      "\n",
      "Fold: 2  Epoch: 108  Training loss = 3.0929  Validation loss = 3.2811  \n",
      "\n",
      "Fold: 2  Epoch: 109  Training loss = 3.0927  Validation loss = 3.2810  \n",
      "\n",
      "Fold: 2  Epoch: 110  Training loss = 3.0926  Validation loss = 3.2808  \n",
      "\n",
      "Fold: 2  Epoch: 111  Training loss = 3.0924  Validation loss = 3.2806  \n",
      "\n",
      "Fold: 2  Epoch: 112  Training loss = 3.0923  Validation loss = 3.2805  \n",
      "\n",
      "Fold: 2  Epoch: 113  Training loss = 3.0922  Validation loss = 3.2803  \n",
      "\n",
      "Fold: 2  Epoch: 114  Training loss = 3.0920  Validation loss = 3.2802  \n",
      "\n",
      "Fold: 2  Epoch: 115  Training loss = 3.0919  Validation loss = 3.2800  \n",
      "\n",
      "Fold: 2  Epoch: 116  Training loss = 3.0918  Validation loss = 3.2798  \n",
      "\n",
      "Fold: 2  Epoch: 117  Training loss = 3.0917  Validation loss = 3.2797  \n",
      "\n",
      "Fold: 2  Epoch: 118  Training loss = 3.0916  Validation loss = 3.2795  \n",
      "\n",
      "Fold: 2  Epoch: 119  Training loss = 3.0914  Validation loss = 3.2794  \n",
      "\n",
      "Fold: 2  Epoch: 120  Training loss = 3.0914  Validation loss = 3.2792  \n",
      "\n",
      "Fold: 2  Epoch: 121  Training loss = 3.0912  Validation loss = 3.2790  \n",
      "\n",
      "Fold: 2  Epoch: 122  Training loss = 3.0910  Validation loss = 3.2788  \n",
      "\n",
      "Fold: 2  Epoch: 123  Training loss = 3.0909  Validation loss = 3.2787  \n",
      "\n",
      "Fold: 2  Epoch: 124  Training loss = 3.0907  Validation loss = 3.2785  \n",
      "\n",
      "Fold: 2  Epoch: 125  Training loss = 3.0906  Validation loss = 3.2783  \n",
      "\n",
      "Fold: 2  Epoch: 126  Training loss = 3.0906  Validation loss = 3.2782  \n",
      "\n",
      "Fold: 2  Epoch: 127  Training loss = 3.0905  Validation loss = 3.2781  \n",
      "\n",
      "Fold: 2  Epoch: 128  Training loss = 3.0903  Validation loss = 3.2779  \n",
      "\n",
      "Fold: 2  Epoch: 129  Training loss = 3.0902  Validation loss = 3.2777  \n",
      "\n",
      "Fold: 2  Epoch: 130  Training loss = 3.0900  Validation loss = 3.2775  \n",
      "\n",
      "Fold: 2  Epoch: 131  Training loss = 3.0899  Validation loss = 3.2774  \n",
      "\n",
      "Fold: 2  Epoch: 132  Training loss = 3.0898  Validation loss = 3.2773  \n",
      "\n",
      "Fold: 2  Epoch: 133  Training loss = 3.0897  Validation loss = 3.2771  \n",
      "\n",
      "Fold: 2  Epoch: 134  Training loss = 3.0896  Validation loss = 3.2770  \n",
      "\n",
      "Fold: 2  Epoch: 135  Training loss = 3.0894  Validation loss = 3.2768  \n",
      "\n",
      "Fold: 2  Epoch: 136  Training loss = 3.0893  Validation loss = 3.2766  \n",
      "\n",
      "Fold: 2  Epoch: 137  Training loss = 3.0891  Validation loss = 3.2765  \n",
      "\n",
      "Fold: 2  Epoch: 138  Training loss = 3.0890  Validation loss = 3.2763  \n",
      "\n",
      "Fold: 2  Epoch: 139  Training loss = 3.0889  Validation loss = 3.2761  \n",
      "\n",
      "Fold: 2  Epoch: 140  Training loss = 3.0888  Validation loss = 3.2760  \n",
      "\n",
      "Fold: 2  Epoch: 141  Training loss = 3.0887  Validation loss = 3.2759  \n",
      "\n",
      "Fold: 2  Epoch: 142  Training loss = 3.0886  Validation loss = 3.2758  \n",
      "\n",
      "Fold: 2  Epoch: 143  Training loss = 3.0884  Validation loss = 3.2756  \n",
      "\n",
      "Fold: 2  Epoch: 144  Training loss = 3.0883  Validation loss = 3.2754  \n",
      "\n",
      "Fold: 2  Epoch: 145  Training loss = 3.0882  Validation loss = 3.2752  \n",
      "\n",
      "Fold: 2  Epoch: 146  Training loss = 3.0880  Validation loss = 3.2750  \n",
      "\n",
      "Fold: 2  Epoch: 147  Training loss = 3.0879  Validation loss = 3.2749  \n",
      "\n",
      "Fold: 2  Epoch: 148  Training loss = 3.0878  Validation loss = 3.2747  \n",
      "\n",
      "Fold: 2  Epoch: 149  Training loss = 3.0877  Validation loss = 3.2746  \n",
      "\n",
      "Fold: 2  Epoch: 150  Training loss = 3.0876  Validation loss = 3.2744  \n",
      "\n",
      "Fold: 2  Epoch: 151  Training loss = 3.0875  Validation loss = 3.2743  \n",
      "\n",
      "Fold: 2  Epoch: 152  Training loss = 3.0873  Validation loss = 3.2741  \n",
      "\n",
      "Fold: 2  Epoch: 153  Training loss = 3.0872  Validation loss = 3.2740  \n",
      "\n",
      "Fold: 2  Epoch: 154  Training loss = 3.0871  Validation loss = 3.2738  \n",
      "\n",
      "Fold: 2  Epoch: 155  Training loss = 3.0870  Validation loss = 3.2737  \n",
      "\n",
      "Fold: 2  Epoch: 156  Training loss = 3.0868  Validation loss = 3.2735  \n",
      "\n",
      "Fold: 2  Epoch: 157  Training loss = 3.0867  Validation loss = 3.2733  \n",
      "\n",
      "Fold: 2  Epoch: 158  Training loss = 3.0865  Validation loss = 3.2731  \n",
      "\n",
      "Fold: 2  Epoch: 159  Training loss = 3.0864  Validation loss = 3.2730  \n",
      "\n",
      "Fold: 2  Epoch: 160  Training loss = 3.0863  Validation loss = 3.2728  \n",
      "\n",
      "Fold: 2  Epoch: 161  Training loss = 3.0861  Validation loss = 3.2726  \n",
      "\n",
      "Fold: 2  Epoch: 162  Training loss = 3.0860  Validation loss = 3.2724  \n",
      "\n",
      "Fold: 2  Epoch: 163  Training loss = 3.0859  Validation loss = 3.2723  \n",
      "\n",
      "Fold: 2  Epoch: 164  Training loss = 3.0857  Validation loss = 3.2721  \n",
      "\n",
      "Fold: 2  Epoch: 165  Training loss = 3.0856  Validation loss = 3.2719  \n",
      "\n",
      "Fold: 2  Epoch: 166  Training loss = 3.0854  Validation loss = 3.2717  \n",
      "\n",
      "Fold: 2  Epoch: 167  Training loss = 3.0853  Validation loss = 3.2715  \n",
      "\n",
      "Fold: 2  Epoch: 168  Training loss = 3.0852  Validation loss = 3.2714  \n",
      "\n",
      "Fold: 2  Epoch: 169  Training loss = 3.0851  Validation loss = 3.2713  \n",
      "\n",
      "Fold: 2  Epoch: 170  Training loss = 3.0849  Validation loss = 3.2711  \n",
      "\n",
      "Fold: 2  Epoch: 171  Training loss = 3.0848  Validation loss = 3.2709  \n",
      "\n",
      "Fold: 2  Epoch: 172  Training loss = 3.0846  Validation loss = 3.2708  \n",
      "\n",
      "Fold: 2  Epoch: 173  Training loss = 3.0845  Validation loss = 3.2706  \n",
      "\n",
      "Fold: 2  Epoch: 174  Training loss = 3.0844  Validation loss = 3.2705  \n",
      "\n",
      "Fold: 2  Epoch: 175  Training loss = 3.0843  Validation loss = 3.2703  \n",
      "\n",
      "Fold: 2  Epoch: 176  Training loss = 3.0841  Validation loss = 3.2701  \n",
      "\n",
      "Fold: 2  Epoch: 177  Training loss = 3.0840  Validation loss = 3.2700  \n",
      "\n",
      "Fold: 2  Epoch: 178  Training loss = 3.0839  Validation loss = 3.2698  \n",
      "\n",
      "Fold: 2  Epoch: 179  Training loss = 3.0838  Validation loss = 3.2697  \n",
      "\n",
      "Fold: 2  Epoch: 180  Training loss = 3.0837  Validation loss = 3.2695  \n",
      "\n",
      "Fold: 2  Epoch: 181  Training loss = 3.0836  Validation loss = 3.2694  \n",
      "\n",
      "Fold: 2  Epoch: 182  Training loss = 3.0835  Validation loss = 3.2693  \n",
      "\n",
      "Fold: 2  Epoch: 183  Training loss = 3.0833  Validation loss = 3.2691  \n",
      "\n",
      "Fold: 2  Epoch: 184  Training loss = 3.0832  Validation loss = 3.2689  \n",
      "\n",
      "Fold: 2  Epoch: 185  Training loss = 3.0830  Validation loss = 3.2687  \n",
      "\n",
      "Fold: 2  Epoch: 186  Training loss = 3.0829  Validation loss = 3.2686  \n",
      "\n",
      "Fold: 2  Epoch: 187  Training loss = 3.0828  Validation loss = 3.2684  \n",
      "\n",
      "Fold: 2  Epoch: 188  Training loss = 3.0827  Validation loss = 3.2683  \n",
      "\n",
      "Fold: 2  Epoch: 189  Training loss = 3.0825  Validation loss = 3.2681  \n",
      "\n",
      "Fold: 2  Epoch: 190  Training loss = 3.0824  Validation loss = 3.2679  \n",
      "\n",
      "Fold: 2  Epoch: 191  Training loss = 3.0823  Validation loss = 3.2678  \n",
      "\n",
      "Fold: 2  Epoch: 192  Training loss = 3.0821  Validation loss = 3.2676  \n",
      "\n",
      "Fold: 2  Epoch: 193  Training loss = 3.0820  Validation loss = 3.2674  \n",
      "\n",
      "Fold: 2  Epoch: 194  Training loss = 3.0819  Validation loss = 3.2673  \n",
      "\n",
      "Fold: 2  Epoch: 195  Training loss = 3.0818  Validation loss = 3.2671  \n",
      "\n",
      "Fold: 2  Epoch: 196  Training loss = 3.0816  Validation loss = 3.2669  \n",
      "\n",
      "Fold: 2  Epoch: 197  Training loss = 3.0815  Validation loss = 3.2668  \n",
      "\n",
      "Fold: 2  Epoch: 198  Training loss = 3.0814  Validation loss = 3.2666  \n",
      "\n",
      "Fold: 2  Epoch: 199  Training loss = 3.0813  Validation loss = 3.2665  \n",
      "\n",
      "Fold: 2  Epoch: 200  Training loss = 3.0811  Validation loss = 3.2663  \n",
      "\n",
      "Fold: 2  Epoch: 201  Training loss = 3.0810  Validation loss = 3.2661  \n",
      "\n",
      "Fold: 2  Epoch: 202  Training loss = 3.0809  Validation loss = 3.2660  \n",
      "\n",
      "Fold: 2  Epoch: 203  Training loss = 3.0808  Validation loss = 3.2658  \n",
      "\n",
      "Fold: 2  Epoch: 204  Training loss = 3.0806  Validation loss = 3.2656  \n",
      "\n",
      "Fold: 2  Epoch: 205  Training loss = 3.0805  Validation loss = 3.2655  \n",
      "\n",
      "Fold: 2  Epoch: 206  Training loss = 3.0804  Validation loss = 3.2653  \n",
      "\n",
      "Fold: 2  Epoch: 207  Training loss = 3.0803  Validation loss = 3.2652  \n",
      "\n",
      "Fold: 2  Epoch: 208  Training loss = 3.0802  Validation loss = 3.2650  \n",
      "\n",
      "Fold: 2  Epoch: 209  Training loss = 3.0801  Validation loss = 3.2649  \n",
      "\n",
      "Fold: 2  Epoch: 210  Training loss = 3.0800  Validation loss = 3.2647  \n",
      "\n",
      "Fold: 2  Epoch: 211  Training loss = 3.0798  Validation loss = 3.2646  \n",
      "\n",
      "Fold: 2  Epoch: 212  Training loss = 3.0797  Validation loss = 3.2644  \n",
      "\n",
      "Fold: 2  Epoch: 213  Training loss = 3.0796  Validation loss = 3.2642  \n",
      "\n",
      "Fold: 2  Epoch: 214  Training loss = 3.0795  Validation loss = 3.2641  \n",
      "\n",
      "Fold: 2  Epoch: 215  Training loss = 3.0793  Validation loss = 3.2639  \n",
      "\n",
      "Fold: 2  Epoch: 216  Training loss = 3.0792  Validation loss = 3.2637  \n",
      "\n",
      "Fold: 2  Epoch: 217  Training loss = 3.0791  Validation loss = 3.2636  \n",
      "\n",
      "Fold: 2  Epoch: 218  Training loss = 3.0790  Validation loss = 3.2635  \n",
      "\n",
      "Fold: 2  Epoch: 219  Training loss = 3.0789  Validation loss = 3.2633  \n",
      "\n",
      "Fold: 2  Epoch: 220  Training loss = 3.0788  Validation loss = 3.2631  \n",
      "\n",
      "Fold: 2  Epoch: 221  Training loss = 3.0787  Validation loss = 3.2630  \n",
      "\n",
      "Fold: 2  Epoch: 222  Training loss = 3.0786  Validation loss = 3.2629  \n",
      "\n",
      "Fold: 2  Epoch: 223  Training loss = 3.0785  Validation loss = 3.2628  \n",
      "\n",
      "Fold: 2  Epoch: 224  Training loss = 3.0784  Validation loss = 3.2626  \n",
      "\n",
      "Fold: 2  Epoch: 225  Training loss = 3.0783  Validation loss = 3.2625  \n",
      "\n",
      "Fold: 2  Epoch: 226  Training loss = 3.0781  Validation loss = 3.2623  \n",
      "\n",
      "Fold: 2  Epoch: 227  Training loss = 3.0780  Validation loss = 3.2621  \n",
      "\n",
      "Fold: 2  Epoch: 228  Training loss = 3.0779  Validation loss = 3.2620  \n",
      "\n",
      "Fold: 2  Epoch: 229  Training loss = 3.0778  Validation loss = 3.2618  \n",
      "\n",
      "Fold: 2  Epoch: 230  Training loss = 3.0777  Validation loss = 3.2617  \n",
      "\n",
      "Fold: 2  Epoch: 231  Training loss = 3.0776  Validation loss = 3.2615  \n",
      "\n",
      "Fold: 2  Epoch: 232  Training loss = 3.0774  Validation loss = 3.2614  \n",
      "\n",
      "Fold: 2  Epoch: 233  Training loss = 3.0773  Validation loss = 3.2612  \n",
      "\n",
      "Fold: 2  Epoch: 234  Training loss = 3.0772  Validation loss = 3.2611  \n",
      "\n",
      "Fold: 2  Epoch: 235  Training loss = 3.0771  Validation loss = 3.2609  \n",
      "\n",
      "Fold: 2  Epoch: 236  Training loss = 3.0770  Validation loss = 3.2608  \n",
      "\n",
      "Fold: 2  Epoch: 237  Training loss = 3.0769  Validation loss = 3.2606  \n",
      "\n",
      "Fold: 2  Epoch: 238  Training loss = 3.0768  Validation loss = 3.2604  \n",
      "\n",
      "Fold: 2  Epoch: 239  Training loss = 3.0767  Validation loss = 3.2603  \n",
      "\n",
      "Fold: 2  Epoch: 240  Training loss = 3.0766  Validation loss = 3.2602  \n",
      "\n",
      "Fold: 2  Epoch: 241  Training loss = 3.0764  Validation loss = 3.2600  \n",
      "\n",
      "Fold: 2  Epoch: 242  Training loss = 3.0763  Validation loss = 3.2598  \n",
      "\n",
      "Fold: 2  Epoch: 243  Training loss = 3.0761  Validation loss = 3.2596  \n",
      "\n",
      "Fold: 2  Epoch: 244  Training loss = 3.0760  Validation loss = 3.2595  \n",
      "\n",
      "Fold: 2  Epoch: 245  Training loss = 3.0758  Validation loss = 3.2593  \n",
      "\n",
      "Fold: 2  Epoch: 246  Training loss = 3.0757  Validation loss = 3.2591  \n",
      "\n",
      "Fold: 2  Epoch: 247  Training loss = 3.0756  Validation loss = 3.2590  \n",
      "\n",
      "Fold: 2  Epoch: 248  Training loss = 3.0755  Validation loss = 3.2589  \n",
      "\n",
      "Fold: 2  Epoch: 249  Training loss = 3.0754  Validation loss = 3.2587  \n",
      "\n",
      "Fold: 2  Epoch: 250  Training loss = 3.0753  Validation loss = 3.2585  \n",
      "\n",
      "Fold: 2  Epoch: 251  Training loss = 3.0752  Validation loss = 3.2584  \n",
      "\n",
      "Fold: 2  Epoch: 252  Training loss = 3.0750  Validation loss = 3.2582  \n",
      "\n",
      "Fold: 2  Epoch: 253  Training loss = 3.0749  Validation loss = 3.2581  \n",
      "\n",
      "Fold: 2  Epoch: 254  Training loss = 3.0749  Validation loss = 3.2580  \n",
      "\n",
      "Fold: 2  Epoch: 255  Training loss = 3.0747  Validation loss = 3.2578  \n",
      "\n",
      "Fold: 2  Epoch: 256  Training loss = 3.0746  Validation loss = 3.2577  \n",
      "\n",
      "Fold: 2  Epoch: 257  Training loss = 3.0745  Validation loss = 3.2575  \n",
      "\n",
      "Fold: 2  Epoch: 258  Training loss = 3.0744  Validation loss = 3.2574  \n",
      "\n",
      "Fold: 2  Epoch: 259  Training loss = 3.0743  Validation loss = 3.2572  \n",
      "\n",
      "Fold: 2  Epoch: 260  Training loss = 3.0741  Validation loss = 3.2570  \n",
      "\n",
      "Fold: 2  Epoch: 261  Training loss = 3.0740  Validation loss = 3.2568  \n",
      "\n",
      "Fold: 2  Epoch: 262  Training loss = 3.0738  Validation loss = 3.2567  \n",
      "\n",
      "Fold: 2  Epoch: 263  Training loss = 3.0737  Validation loss = 3.2565  \n",
      "\n",
      "Fold: 2  Epoch: 264  Training loss = 3.0736  Validation loss = 3.2563  \n",
      "\n",
      "Fold: 2  Epoch: 265  Training loss = 3.0735  Validation loss = 3.2562  \n",
      "\n",
      "Fold: 2  Epoch: 266  Training loss = 3.0734  Validation loss = 3.2561  \n",
      "\n",
      "Fold: 2  Epoch: 267  Training loss = 3.0733  Validation loss = 3.2559  \n",
      "\n",
      "Fold: 2  Epoch: 268  Training loss = 3.0731  Validation loss = 3.2558  \n",
      "\n",
      "Fold: 2  Epoch: 269  Training loss = 3.0730  Validation loss = 3.2556  \n",
      "\n",
      "Fold: 2  Epoch: 270  Training loss = 3.0729  Validation loss = 3.2554  \n",
      "\n",
      "Fold: 2  Epoch: 271  Training loss = 3.0728  Validation loss = 3.2553  \n",
      "\n",
      "Fold: 2  Epoch: 272  Training loss = 3.0726  Validation loss = 3.2551  \n",
      "\n",
      "Fold: 2  Epoch: 273  Training loss = 3.0725  Validation loss = 3.2549  \n",
      "\n",
      "Fold: 2  Epoch: 274  Training loss = 3.0724  Validation loss = 3.2548  \n",
      "\n",
      "Fold: 2  Epoch: 275  Training loss = 3.0723  Validation loss = 3.2546  \n",
      "\n",
      "Fold: 2  Epoch: 276  Training loss = 3.0721  Validation loss = 3.2545  \n",
      "\n",
      "Fold: 2  Epoch: 277  Training loss = 3.0720  Validation loss = 3.2543  \n",
      "\n",
      "Fold: 2  Epoch: 278  Training loss = 3.0719  Validation loss = 3.2542  \n",
      "\n",
      "Fold: 2  Epoch: 279  Training loss = 3.0718  Validation loss = 3.2540  \n",
      "\n",
      "Fold: 2  Epoch: 280  Training loss = 3.0717  Validation loss = 3.2539  \n",
      "\n",
      "Fold: 2  Epoch: 281  Training loss = 3.0716  Validation loss = 3.2538  \n",
      "\n",
      "Fold: 2  Epoch: 282  Training loss = 3.0715  Validation loss = 3.2536  \n",
      "\n",
      "Fold: 2  Epoch: 283  Training loss = 3.0713  Validation loss = 3.2535  \n",
      "\n",
      "Fold: 2  Epoch: 284  Training loss = 3.0712  Validation loss = 3.2533  \n",
      "\n",
      "Fold: 2  Epoch: 285  Training loss = 3.0711  Validation loss = 3.2532  \n",
      "\n",
      "Fold: 2  Epoch: 286  Training loss = 3.0710  Validation loss = 3.2530  \n",
      "\n",
      "Fold: 2  Epoch: 287  Training loss = 3.0709  Validation loss = 3.2529  \n",
      "\n",
      "Fold: 2  Epoch: 288  Training loss = 3.0708  Validation loss = 3.2528  \n",
      "\n",
      "Fold: 2  Epoch: 289  Training loss = 3.0707  Validation loss = 3.2526  \n",
      "\n",
      "Fold: 2  Epoch: 290  Training loss = 3.0706  Validation loss = 3.2525  \n",
      "\n",
      "Fold: 2  Epoch: 291  Training loss = 3.0705  Validation loss = 3.2523  \n",
      "\n",
      "Fold: 2  Epoch: 292  Training loss = 3.0703  Validation loss = 3.2522  \n",
      "\n",
      "Fold: 2  Epoch: 293  Training loss = 3.0703  Validation loss = 3.2521  \n",
      "\n",
      "Fold: 2  Epoch: 294  Training loss = 3.0701  Validation loss = 3.2519  \n",
      "\n",
      "Fold: 2  Epoch: 295  Training loss = 3.0700  Validation loss = 3.2517  \n",
      "\n",
      "Fold: 2  Epoch: 296  Training loss = 3.0699  Validation loss = 3.2516  \n",
      "\n",
      "Fold: 2  Epoch: 297  Training loss = 3.0698  Validation loss = 3.2515  \n",
      "\n",
      "Fold: 2  Epoch: 298  Training loss = 3.0697  Validation loss = 3.2513  \n",
      "\n",
      "Fold: 2  Epoch: 299  Training loss = 3.0695  Validation loss = 3.2511  \n",
      "\n",
      "Fold: 2  Epoch: 300  Training loss = 3.0695  Validation loss = 3.2510  \n",
      "\n",
      "Fold: 2  Epoch: 301  Training loss = 3.0694  Validation loss = 3.2509  \n",
      "\n",
      "Fold: 2  Epoch: 302  Training loss = 3.0692  Validation loss = 3.2507  \n",
      "\n",
      "Fold: 2  Epoch: 303  Training loss = 3.0691  Validation loss = 3.2506  \n",
      "\n",
      "Fold: 2  Epoch: 304  Training loss = 3.0690  Validation loss = 3.2504  \n",
      "\n",
      "Fold: 2  Epoch: 305  Training loss = 3.0689  Validation loss = 3.2503  \n",
      "\n",
      "Fold: 2  Epoch: 306  Training loss = 3.0688  Validation loss = 3.2501  \n",
      "\n",
      "Fold: 2  Epoch: 307  Training loss = 3.0687  Validation loss = 3.2499  \n",
      "\n",
      "Fold: 2  Epoch: 308  Training loss = 3.0685  Validation loss = 3.2498  \n",
      "\n",
      "Fold: 2  Epoch: 309  Training loss = 3.0684  Validation loss = 3.2496  \n",
      "\n",
      "Fold: 2  Epoch: 310  Training loss = 3.0684  Validation loss = 3.2495  \n",
      "\n",
      "Fold: 2  Epoch: 311  Training loss = 3.0683  Validation loss = 3.2494  \n",
      "\n",
      "Fold: 2  Epoch: 312  Training loss = 3.0681  Validation loss = 3.2492  \n",
      "\n",
      "Fold: 2  Epoch: 313  Training loss = 3.0680  Validation loss = 3.2490  \n",
      "\n",
      "Fold: 2  Epoch: 314  Training loss = 3.0679  Validation loss = 3.2489  \n",
      "\n",
      "Fold: 2  Epoch: 315  Training loss = 3.0678  Validation loss = 3.2488  \n",
      "\n",
      "Fold: 2  Epoch: 316  Training loss = 3.0677  Validation loss = 3.2486  \n",
      "\n",
      "Fold: 2  Epoch: 317  Training loss = 3.0676  Validation loss = 3.2485  \n",
      "\n",
      "Fold: 2  Epoch: 318  Training loss = 3.0675  Validation loss = 3.2484  \n",
      "\n",
      "Fold: 2  Epoch: 319  Training loss = 3.0673  Validation loss = 3.2482  \n",
      "\n",
      "Fold: 2  Epoch: 320  Training loss = 3.0672  Validation loss = 3.2480  \n",
      "\n",
      "Fold: 2  Epoch: 321  Training loss = 3.0671  Validation loss = 3.2479  \n",
      "\n",
      "Fold: 2  Epoch: 322  Training loss = 3.0670  Validation loss = 3.2477  \n",
      "\n",
      "Fold: 2  Epoch: 323  Training loss = 3.0669  Validation loss = 3.2476  \n",
      "\n",
      "Fold: 2  Epoch: 324  Training loss = 3.0668  Validation loss = 3.2474  \n",
      "\n",
      "Fold: 2  Epoch: 325  Training loss = 3.0667  Validation loss = 3.2473  \n",
      "\n",
      "Fold: 2  Epoch: 326  Training loss = 3.0666  Validation loss = 3.2471  \n",
      "\n",
      "Fold: 2  Epoch: 327  Training loss = 3.0665  Validation loss = 3.2470  \n",
      "\n",
      "Fold: 2  Epoch: 328  Training loss = 3.0663  Validation loss = 3.2468  \n",
      "\n",
      "Fold: 2  Epoch: 329  Training loss = 3.0662  Validation loss = 3.2466  \n",
      "\n",
      "Fold: 2  Epoch: 330  Training loss = 3.0660  Validation loss = 3.2465  \n",
      "\n",
      "Fold: 2  Epoch: 331  Training loss = 3.0659  Validation loss = 3.2463  \n",
      "\n",
      "Fold: 2  Epoch: 332  Training loss = 3.0658  Validation loss = 3.2462  \n",
      "\n",
      "Fold: 2  Epoch: 333  Training loss = 3.0657  Validation loss = 3.2460  \n",
      "\n",
      "Fold: 2  Epoch: 334  Training loss = 3.0656  Validation loss = 3.2459  \n",
      "\n",
      "Fold: 2  Epoch: 335  Training loss = 3.0655  Validation loss = 3.2458  \n",
      "\n",
      "Fold: 2  Epoch: 336  Training loss = 3.0654  Validation loss = 3.2456  \n",
      "\n",
      "Fold: 2  Epoch: 337  Training loss = 3.0652  Validation loss = 3.2455  \n",
      "\n",
      "Fold: 2  Epoch: 338  Training loss = 3.0651  Validation loss = 3.2453  \n",
      "\n",
      "Fold: 2  Epoch: 339  Training loss = 3.0650  Validation loss = 3.2451  \n",
      "\n",
      "Fold: 2  Epoch: 340  Training loss = 3.0649  Validation loss = 3.2450  \n",
      "\n",
      "Fold: 2  Epoch: 341  Training loss = 3.0647  Validation loss = 3.2448  \n",
      "\n",
      "Fold: 2  Epoch: 342  Training loss = 3.0646  Validation loss = 3.2447  \n",
      "\n",
      "Fold: 2  Epoch: 343  Training loss = 3.0645  Validation loss = 3.2445  \n",
      "\n",
      "Fold: 2  Epoch: 344  Training loss = 3.0643  Validation loss = 3.2443  \n",
      "\n",
      "Fold: 2  Epoch: 345  Training loss = 3.0642  Validation loss = 3.2441  \n",
      "\n",
      "Fold: 2  Epoch: 346  Training loss = 3.0641  Validation loss = 3.2440  \n",
      "\n",
      "Fold: 2  Epoch: 347  Training loss = 3.0640  Validation loss = 3.2438  \n",
      "\n",
      "Fold: 2  Epoch: 348  Training loss = 3.0639  Validation loss = 3.2437  \n",
      "\n",
      "Fold: 2  Epoch: 349  Training loss = 3.0638  Validation loss = 3.2435  \n",
      "\n",
      "Fold: 2  Epoch: 350  Training loss = 3.0636  Validation loss = 3.2433  \n",
      "\n",
      "Fold: 2  Epoch: 351  Training loss = 3.0635  Validation loss = 3.2432  \n",
      "\n",
      "Fold: 2  Epoch: 352  Training loss = 3.0634  Validation loss = 3.2430  \n",
      "\n",
      "Fold: 2  Epoch: 353  Training loss = 3.0632  Validation loss = 3.2428  \n",
      "\n",
      "Fold: 2  Epoch: 354  Training loss = 3.0631  Validation loss = 3.2427  \n",
      "\n",
      "Fold: 2  Epoch: 355  Training loss = 3.0630  Validation loss = 3.2425  \n",
      "\n",
      "Fold: 2  Epoch: 356  Training loss = 3.0629  Validation loss = 3.2424  \n",
      "\n",
      "Fold: 2  Epoch: 357  Training loss = 3.0628  Validation loss = 3.2422  \n",
      "\n",
      "Fold: 2  Epoch: 358  Training loss = 3.0627  Validation loss = 3.2421  \n",
      "\n",
      "Fold: 2  Epoch: 359  Training loss = 3.0625  Validation loss = 3.2419  \n",
      "\n",
      "Fold: 2  Epoch: 360  Training loss = 3.0624  Validation loss = 3.2418  \n",
      "\n",
      "Fold: 2  Epoch: 361  Training loss = 3.0623  Validation loss = 3.2417  \n",
      "\n",
      "Fold: 2  Epoch: 362  Training loss = 3.0622  Validation loss = 3.2415  \n",
      "\n",
      "Fold: 2  Epoch: 363  Training loss = 3.0620  Validation loss = 3.2414  \n",
      "\n",
      "Fold: 2  Epoch: 364  Training loss = 3.0619  Validation loss = 3.2412  \n",
      "\n",
      "Fold: 2  Epoch: 365  Training loss = 3.0618  Validation loss = 3.2411  \n",
      "\n",
      "Fold: 2  Epoch: 366  Training loss = 3.0617  Validation loss = 3.2409  \n",
      "\n",
      "Fold: 2  Epoch: 367  Training loss = 3.0616  Validation loss = 3.2408  \n",
      "\n",
      "Fold: 2  Epoch: 368  Training loss = 3.0615  Validation loss = 3.2406  \n",
      "\n",
      "Fold: 2  Epoch: 369  Training loss = 3.0614  Validation loss = 3.2405  \n",
      "\n",
      "Fold: 2  Epoch: 370  Training loss = 3.0613  Validation loss = 3.2404  \n",
      "\n",
      "Fold: 2  Epoch: 371  Training loss = 3.0612  Validation loss = 3.2403  \n",
      "\n",
      "Fold: 2  Epoch: 372  Training loss = 3.0611  Validation loss = 3.2401  \n",
      "\n",
      "Fold: 2  Epoch: 373  Training loss = 3.0610  Validation loss = 3.2399  \n",
      "\n",
      "Fold: 2  Epoch: 374  Training loss = 3.0608  Validation loss = 3.2398  \n",
      "\n",
      "Fold: 2  Epoch: 375  Training loss = 3.0607  Validation loss = 3.2396  \n",
      "\n",
      "Fold: 2  Epoch: 376  Training loss = 3.0605  Validation loss = 3.2394  \n",
      "\n",
      "Fold: 2  Epoch: 377  Training loss = 3.0604  Validation loss = 3.2392  \n",
      "\n",
      "Fold: 2  Epoch: 378  Training loss = 3.0603  Validation loss = 3.2391  \n",
      "\n",
      "Fold: 2  Epoch: 379  Training loss = 3.0602  Validation loss = 3.2390  \n",
      "\n",
      "Fold: 2  Epoch: 380  Training loss = 3.0601  Validation loss = 3.2388  \n",
      "\n",
      "Fold: 2  Epoch: 381  Training loss = 3.0600  Validation loss = 3.2387  \n",
      "\n",
      "Fold: 2  Epoch: 382  Training loss = 3.0598  Validation loss = 3.2385  \n",
      "\n",
      "Fold: 2  Epoch: 383  Training loss = 3.0597  Validation loss = 3.2384  \n",
      "\n",
      "Fold: 2  Epoch: 384  Training loss = 3.0596  Validation loss = 3.2382  \n",
      "\n",
      "Fold: 2  Epoch: 385  Training loss = 3.0595  Validation loss = 3.2381  \n",
      "\n",
      "Fold: 2  Epoch: 386  Training loss = 3.0593  Validation loss = 3.2379  \n",
      "\n",
      "Fold: 2  Epoch: 387  Training loss = 3.0592  Validation loss = 3.2377  \n",
      "\n",
      "Fold: 2  Epoch: 388  Training loss = 3.0591  Validation loss = 3.2376  \n",
      "\n",
      "Fold: 2  Epoch: 389  Training loss = 3.0590  Validation loss = 3.2374  \n",
      "\n",
      "Fold: 2  Epoch: 390  Training loss = 3.0589  Validation loss = 3.2373  \n",
      "\n",
      "Fold: 2  Epoch: 391  Training loss = 3.0588  Validation loss = 3.2372  \n",
      "\n",
      "Fold: 2  Epoch: 392  Training loss = 3.0587  Validation loss = 3.2370  \n",
      "\n",
      "Fold: 2  Epoch: 393  Training loss = 3.0586  Validation loss = 3.2369  \n",
      "\n",
      "Fold: 2  Epoch: 394  Training loss = 3.0585  Validation loss = 3.2367  \n",
      "\n",
      "Fold: 2  Epoch: 395  Training loss = 3.0584  Validation loss = 3.2366  \n",
      "\n",
      "Fold: 2  Epoch: 396  Training loss = 3.0583  Validation loss = 3.2365  \n",
      "\n",
      "Fold: 2  Epoch: 397  Training loss = 3.0582  Validation loss = 3.2363  \n",
      "\n",
      "Fold: 2  Epoch: 398  Training loss = 3.0580  Validation loss = 3.2361  \n",
      "\n",
      "Fold: 2  Epoch: 399  Training loss = 3.0579  Validation loss = 3.2360  \n",
      "\n",
      "Fold: 2  Epoch: 400  Training loss = 3.0578  Validation loss = 3.2358  \n",
      "\n",
      "Fold: 2  Epoch: 401  Training loss = 3.0577  Validation loss = 3.2356  \n",
      "\n",
      "Fold: 2  Epoch: 402  Training loss = 3.0575  Validation loss = 3.2354  \n",
      "\n",
      "Fold: 2  Epoch: 403  Training loss = 3.0573  Validation loss = 3.2353  \n",
      "\n",
      "Fold: 2  Epoch: 404  Training loss = 3.0572  Validation loss = 3.2351  \n",
      "\n",
      "Fold: 2  Epoch: 405  Training loss = 3.0571  Validation loss = 3.2349  \n",
      "\n",
      "Fold: 2  Epoch: 406  Training loss = 3.0570  Validation loss = 3.2348  \n",
      "\n",
      "Fold: 2  Epoch: 407  Training loss = 3.0568  Validation loss = 3.2346  \n",
      "\n",
      "Fold: 2  Epoch: 408  Training loss = 3.0567  Validation loss = 3.2345  \n",
      "\n",
      "Fold: 2  Epoch: 409  Training loss = 3.0567  Validation loss = 3.2343  \n",
      "\n",
      "Fold: 2  Epoch: 410  Training loss = 3.0566  Validation loss = 3.2342  \n",
      "\n",
      "Fold: 2  Epoch: 411  Training loss = 3.0564  Validation loss = 3.2341  \n",
      "\n",
      "Fold: 2  Epoch: 412  Training loss = 3.0563  Validation loss = 3.2339  \n",
      "\n",
      "Fold: 2  Epoch: 413  Training loss = 3.0562  Validation loss = 3.2337  \n",
      "\n",
      "Fold: 2  Epoch: 414  Training loss = 3.0561  Validation loss = 3.2336  \n",
      "\n",
      "Fold: 2  Epoch: 415  Training loss = 3.0560  Validation loss = 3.2335  \n",
      "\n",
      "Fold: 2  Epoch: 416  Training loss = 3.0559  Validation loss = 3.2333  \n",
      "\n",
      "Fold: 2  Epoch: 417  Training loss = 3.0557  Validation loss = 3.2331  \n",
      "\n",
      "Fold: 2  Epoch: 418  Training loss = 3.0556  Validation loss = 3.2330  \n",
      "\n",
      "Fold: 2  Epoch: 419  Training loss = 3.0555  Validation loss = 3.2328  \n",
      "\n",
      "Fold: 2  Epoch: 420  Training loss = 3.0553  Validation loss = 3.2326  \n",
      "\n",
      "Fold: 2  Epoch: 421  Training loss = 3.0552  Validation loss = 3.2325  \n",
      "\n",
      "Fold: 2  Epoch: 422  Training loss = 3.0551  Validation loss = 3.2323  \n",
      "\n",
      "Fold: 2  Epoch: 423  Training loss = 3.0550  Validation loss = 3.2322  \n",
      "\n",
      "Fold: 2  Epoch: 424  Training loss = 3.0549  Validation loss = 3.2321  \n",
      "\n",
      "Fold: 2  Epoch: 425  Training loss = 3.0548  Validation loss = 3.2319  \n",
      "\n",
      "Fold: 2  Epoch: 426  Training loss = 3.0547  Validation loss = 3.2318  \n",
      "\n",
      "Fold: 2  Epoch: 427  Training loss = 3.0545  Validation loss = 3.2316  \n",
      "\n",
      "Fold: 2  Epoch: 428  Training loss = 3.0544  Validation loss = 3.2315  \n",
      "\n",
      "Fold: 2  Epoch: 429  Training loss = 3.0543  Validation loss = 3.2314  \n",
      "\n",
      "Fold: 2  Epoch: 430  Training loss = 3.0542  Validation loss = 3.2312  \n",
      "\n",
      "Fold: 2  Epoch: 431  Training loss = 3.0541  Validation loss = 3.2311  \n",
      "\n",
      "Fold: 2  Epoch: 432  Training loss = 3.0540  Validation loss = 3.2310  \n",
      "\n",
      "Fold: 2  Epoch: 433  Training loss = 3.0539  Validation loss = 3.2308  \n",
      "\n",
      "Fold: 2  Epoch: 434  Training loss = 3.0538  Validation loss = 3.2307  \n",
      "\n",
      "Fold: 2  Epoch: 435  Training loss = 3.0537  Validation loss = 3.2306  \n",
      "\n",
      "Fold: 2  Epoch: 436  Training loss = 3.0536  Validation loss = 3.2304  \n",
      "\n",
      "Fold: 2  Epoch: 437  Training loss = 3.0535  Validation loss = 3.2303  \n",
      "\n",
      "Fold: 2  Epoch: 438  Training loss = 3.0534  Validation loss = 3.2302  \n",
      "\n",
      "Fold: 2  Epoch: 439  Training loss = 3.0533  Validation loss = 3.2300  \n",
      "\n",
      "Fold: 2  Epoch: 440  Training loss = 3.0532  Validation loss = 3.2299  \n",
      "\n",
      "Fold: 2  Epoch: 441  Training loss = 3.0531  Validation loss = 3.2297  \n",
      "\n",
      "Fold: 2  Epoch: 442  Training loss = 3.0530  Validation loss = 3.2296  \n",
      "\n",
      "Fold: 2  Epoch: 443  Training loss = 3.0528  Validation loss = 3.2294  \n",
      "\n",
      "Fold: 2  Epoch: 444  Training loss = 3.0527  Validation loss = 3.2293  \n",
      "\n",
      "Fold: 2  Epoch: 445  Training loss = 3.0526  Validation loss = 3.2291  \n",
      "\n",
      "Fold: 2  Epoch: 446  Training loss = 3.0524  Validation loss = 3.2289  \n",
      "\n",
      "Fold: 2  Epoch: 447  Training loss = 3.0522  Validation loss = 3.2287  \n",
      "\n",
      "Fold: 2  Epoch: 448  Training loss = 3.0521  Validation loss = 3.2286  \n",
      "\n",
      "Fold: 2  Epoch: 449  Training loss = 3.0520  Validation loss = 3.2284  \n",
      "\n",
      "Fold: 2  Epoch: 450  Training loss = 3.0519  Validation loss = 3.2283  \n",
      "\n",
      "Fold: 2  Epoch: 451  Training loss = 3.0518  Validation loss = 3.2281  \n",
      "\n",
      "Fold: 2  Epoch: 452  Training loss = 3.0517  Validation loss = 3.2280  \n",
      "\n",
      "Fold: 2  Epoch: 453  Training loss = 3.0516  Validation loss = 3.2279  \n",
      "\n",
      "Fold: 2  Epoch: 454  Training loss = 3.0515  Validation loss = 3.2277  \n",
      "\n",
      "Fold: 2  Epoch: 455  Training loss = 3.0514  Validation loss = 3.2276  \n",
      "\n",
      "Fold: 2  Epoch: 456  Training loss = 3.0513  Validation loss = 3.2275  \n",
      "\n",
      "Fold: 2  Epoch: 457  Training loss = 3.0512  Validation loss = 3.2274  \n",
      "\n",
      "Fold: 2  Epoch: 458  Training loss = 3.0512  Validation loss = 3.2272  \n",
      "\n",
      "Fold: 2  Epoch: 459  Training loss = 3.0510  Validation loss = 3.2271  \n",
      "\n",
      "Fold: 2  Epoch: 460  Training loss = 3.0509  Validation loss = 3.2269  \n",
      "\n",
      "Fold: 2  Epoch: 461  Training loss = 3.0508  Validation loss = 3.2268  \n",
      "\n",
      "Fold: 2  Epoch: 462  Training loss = 3.0507  Validation loss = 3.2266  \n",
      "\n",
      "Fold: 2  Epoch: 463  Training loss = 3.0506  Validation loss = 3.2265  \n",
      "\n",
      "Fold: 2  Epoch: 464  Training loss = 3.0505  Validation loss = 3.2263  \n",
      "\n",
      "Fold: 2  Epoch: 465  Training loss = 3.0503  Validation loss = 3.2262  \n",
      "\n",
      "Fold: 2  Epoch: 466  Training loss = 3.0502  Validation loss = 3.2260  \n",
      "\n",
      "Fold: 2  Epoch: 467  Training loss = 3.0501  Validation loss = 3.2259  \n",
      "\n",
      "Fold: 2  Epoch: 468  Training loss = 3.0500  Validation loss = 3.2257  \n",
      "\n",
      "Fold: 2  Epoch: 469  Training loss = 3.0499  Validation loss = 3.2256  \n",
      "\n",
      "Fold: 2  Epoch: 470  Training loss = 3.0498  Validation loss = 3.2254  \n",
      "\n",
      "Fold: 2  Epoch: 471  Training loss = 3.0496  Validation loss = 3.2253  \n",
      "\n",
      "Fold: 2  Epoch: 472  Training loss = 3.0495  Validation loss = 3.2252  \n",
      "\n",
      "Fold: 2  Epoch: 473  Training loss = 3.0494  Validation loss = 3.2250  \n",
      "\n",
      "Fold: 2  Epoch: 474  Training loss = 3.0493  Validation loss = 3.2249  \n",
      "\n",
      "Fold: 2  Epoch: 475  Training loss = 3.0492  Validation loss = 3.2247  \n",
      "\n",
      "Fold: 2  Epoch: 476  Training loss = 3.0491  Validation loss = 3.2245  \n",
      "\n",
      "Fold: 2  Epoch: 477  Training loss = 3.0490  Validation loss = 3.2244  \n",
      "\n",
      "Fold: 2  Epoch: 478  Training loss = 3.0489  Validation loss = 3.2242  \n",
      "\n",
      "Fold: 2  Epoch: 479  Training loss = 3.0488  Validation loss = 3.2241  \n",
      "\n",
      "Fold: 2  Epoch: 480  Training loss = 3.0486  Validation loss = 3.2239  \n",
      "\n",
      "Fold: 2  Epoch: 481  Training loss = 3.0485  Validation loss = 3.2238  \n",
      "\n",
      "Fold: 2  Epoch: 482  Training loss = 3.0484  Validation loss = 3.2237  \n",
      "\n",
      "Fold: 2  Epoch: 483  Training loss = 3.0484  Validation loss = 3.2235  \n",
      "\n",
      "Fold: 2  Epoch: 484  Training loss = 3.0482  Validation loss = 3.2234  \n",
      "\n",
      "Fold: 2  Epoch: 485  Training loss = 3.0481  Validation loss = 3.2232  \n",
      "\n",
      "Fold: 2  Epoch: 486  Training loss = 3.0480  Validation loss = 3.2231  \n",
      "\n",
      "Fold: 2  Epoch: 487  Training loss = 3.0479  Validation loss = 3.2229  \n",
      "\n",
      "Fold: 2  Epoch: 488  Training loss = 3.0478  Validation loss = 3.2228  \n",
      "\n",
      "Fold: 2  Epoch: 489  Training loss = 3.0477  Validation loss = 3.2227  \n",
      "\n",
      "Fold: 2  Epoch: 490  Training loss = 3.0476  Validation loss = 3.2225  \n",
      "\n",
      "Fold: 2  Epoch: 491  Training loss = 3.0475  Validation loss = 3.2224  \n",
      "\n",
      "Fold: 2  Epoch: 492  Training loss = 3.0474  Validation loss = 3.2222  \n",
      "\n",
      "Fold: 2  Epoch: 493  Training loss = 3.0473  Validation loss = 3.2221  \n",
      "\n",
      "Fold: 2  Epoch: 494  Training loss = 3.0472  Validation loss = 3.2219  \n",
      "\n",
      "Fold: 2  Epoch: 495  Training loss = 3.0470  Validation loss = 3.2218  \n",
      "\n",
      "Fold: 2  Epoch: 496  Training loss = 3.0469  Validation loss = 3.2216  \n",
      "\n",
      "Fold: 2  Epoch: 497  Training loss = 3.0468  Validation loss = 3.2215  \n",
      "\n",
      "Fold: 2  Epoch: 498  Training loss = 3.0467  Validation loss = 3.2213  \n",
      "\n",
      "Fold: 2  Epoch: 499  Training loss = 3.0466  Validation loss = 3.2212  \n",
      "\n",
      "Fold: 2  Epoch: 500  Training loss = 3.0465  Validation loss = 3.2210  \n",
      "\n",
      "Check model:  Fold: 2  Optimal epoch: 500  \n",
      "\n",
      "Fold: 3  Epoch: 1  Training loss = 2.1079  Validation loss = 4.6081  \n",
      "\n",
      "Fold: 3  Epoch: 2  Training loss = 2.1078  Validation loss = 4.6079  \n",
      "\n",
      "Fold: 3  Epoch: 3  Training loss = 2.1077  Validation loss = 4.6078  \n",
      "\n",
      "Fold: 3  Epoch: 4  Training loss = 2.1075  Validation loss = 4.6077  \n",
      "\n",
      "Fold: 3  Epoch: 5  Training loss = 2.1074  Validation loss = 4.6075  \n",
      "\n",
      "Fold: 3  Epoch: 6  Training loss = 2.1073  Validation loss = 4.6074  \n",
      "\n",
      "Fold: 3  Epoch: 7  Training loss = 2.1072  Validation loss = 4.6073  \n",
      "\n",
      "Fold: 3  Epoch: 8  Training loss = 2.1071  Validation loss = 4.6072  \n",
      "\n",
      "Fold: 3  Epoch: 9  Training loss = 2.1070  Validation loss = 4.6071  \n",
      "\n",
      "Fold: 3  Epoch: 10  Training loss = 2.1069  Validation loss = 4.6069  \n",
      "\n",
      "Fold: 3  Epoch: 11  Training loss = 2.1067  Validation loss = 4.6068  \n",
      "\n",
      "Fold: 3  Epoch: 12  Training loss = 2.1066  Validation loss = 4.6067  \n",
      "\n",
      "Fold: 3  Epoch: 13  Training loss = 2.1065  Validation loss = 4.6065  \n",
      "\n",
      "Fold: 3  Epoch: 14  Training loss = 2.1064  Validation loss = 4.6064  \n",
      "\n",
      "Fold: 3  Epoch: 15  Training loss = 2.1063  Validation loss = 4.6063  \n",
      "\n",
      "Fold: 3  Epoch: 16  Training loss = 2.1061  Validation loss = 4.6061  \n",
      "\n",
      "Fold: 3  Epoch: 17  Training loss = 2.1060  Validation loss = 4.6060  \n",
      "\n",
      "Fold: 3  Epoch: 18  Training loss = 2.1059  Validation loss = 4.6059  \n",
      "\n",
      "Fold: 3  Epoch: 19  Training loss = 2.1058  Validation loss = 4.6058  \n",
      "\n",
      "Fold: 3  Epoch: 20  Training loss = 2.1057  Validation loss = 4.6056  \n",
      "\n",
      "Fold: 3  Epoch: 21  Training loss = 2.1056  Validation loss = 4.6055  \n",
      "\n",
      "Fold: 3  Epoch: 22  Training loss = 2.1054  Validation loss = 4.6054  \n",
      "\n",
      "Fold: 3  Epoch: 23  Training loss = 2.1053  Validation loss = 4.6052  \n",
      "\n",
      "Fold: 3  Epoch: 24  Training loss = 2.1052  Validation loss = 4.6051  \n",
      "\n",
      "Fold: 3  Epoch: 25  Training loss = 2.1051  Validation loss = 4.6050  \n",
      "\n",
      "Fold: 3  Epoch: 26  Training loss = 2.1050  Validation loss = 4.6049  \n",
      "\n",
      "Fold: 3  Epoch: 27  Training loss = 2.1049  Validation loss = 4.6048  \n",
      "\n",
      "Fold: 3  Epoch: 28  Training loss = 2.1048  Validation loss = 4.6047  \n",
      "\n",
      "Fold: 3  Epoch: 29  Training loss = 2.1047  Validation loss = 4.6046  \n",
      "\n",
      "Fold: 3  Epoch: 30  Training loss = 2.1046  Validation loss = 4.6044  \n",
      "\n",
      "Fold: 3  Epoch: 31  Training loss = 2.1044  Validation loss = 4.6043  \n",
      "\n",
      "Fold: 3  Epoch: 32  Training loss = 2.1043  Validation loss = 4.6042  \n",
      "\n",
      "Fold: 3  Epoch: 33  Training loss = 2.1042  Validation loss = 4.6041  \n",
      "\n",
      "Fold: 3  Epoch: 34  Training loss = 2.1041  Validation loss = 4.6039  \n",
      "\n",
      "Fold: 3  Epoch: 35  Training loss = 2.1040  Validation loss = 4.6038  \n",
      "\n",
      "Fold: 3  Epoch: 36  Training loss = 2.1039  Validation loss = 4.6037  \n",
      "\n",
      "Fold: 3  Epoch: 37  Training loss = 2.1037  Validation loss = 4.6035  \n",
      "\n",
      "Fold: 3  Epoch: 38  Training loss = 2.1036  Validation loss = 4.6034  \n",
      "\n",
      "Fold: 3  Epoch: 39  Training loss = 2.1035  Validation loss = 4.6033  \n",
      "\n",
      "Fold: 3  Epoch: 40  Training loss = 2.1034  Validation loss = 4.6032  \n",
      "\n",
      "Fold: 3  Epoch: 41  Training loss = 2.1033  Validation loss = 4.6031  \n",
      "\n",
      "Fold: 3  Epoch: 42  Training loss = 2.1032  Validation loss = 4.6030  \n",
      "\n",
      "Fold: 3  Epoch: 43  Training loss = 2.1031  Validation loss = 4.6029  \n",
      "\n",
      "Fold: 3  Epoch: 44  Training loss = 2.1030  Validation loss = 4.6027  \n",
      "\n",
      "Fold: 3  Epoch: 45  Training loss = 2.1029  Validation loss = 4.6025  \n",
      "\n",
      "Fold: 3  Epoch: 46  Training loss = 2.1027  Validation loss = 4.6024  \n",
      "\n",
      "Fold: 3  Epoch: 47  Training loss = 2.1026  Validation loss = 4.6022  \n",
      "\n",
      "Fold: 3  Epoch: 48  Training loss = 2.1024  Validation loss = 4.6021  \n",
      "\n",
      "Fold: 3  Epoch: 49  Training loss = 2.1023  Validation loss = 4.6019  \n",
      "\n",
      "Fold: 3  Epoch: 50  Training loss = 2.1022  Validation loss = 4.6018  \n",
      "\n",
      "Fold: 3  Epoch: 51  Training loss = 2.1021  Validation loss = 4.6017  \n",
      "\n",
      "Fold: 3  Epoch: 52  Training loss = 2.1019  Validation loss = 4.6015  \n",
      "\n",
      "Fold: 3  Epoch: 53  Training loss = 2.1019  Validation loss = 4.6014  \n",
      "\n",
      "Fold: 3  Epoch: 54  Training loss = 2.1018  Validation loss = 4.6013  \n",
      "\n",
      "Fold: 3  Epoch: 55  Training loss = 2.1016  Validation loss = 4.6012  \n",
      "\n",
      "Fold: 3  Epoch: 56  Training loss = 2.1015  Validation loss = 4.6010  \n",
      "\n",
      "Fold: 3  Epoch: 57  Training loss = 2.1014  Validation loss = 4.6009  \n",
      "\n",
      "Fold: 3  Epoch: 58  Training loss = 2.1013  Validation loss = 4.6008  \n",
      "\n",
      "Fold: 3  Epoch: 59  Training loss = 2.1012  Validation loss = 4.6006  \n",
      "\n",
      "Fold: 3  Epoch: 60  Training loss = 2.1011  Validation loss = 4.6005  \n",
      "\n",
      "Fold: 3  Epoch: 61  Training loss = 2.1009  Validation loss = 4.6004  \n",
      "\n",
      "Fold: 3  Epoch: 62  Training loss = 2.1008  Validation loss = 4.6003  \n",
      "\n",
      "Fold: 3  Epoch: 63  Training loss = 2.1007  Validation loss = 4.6002  \n",
      "\n",
      "Fold: 3  Epoch: 64  Training loss = 2.1006  Validation loss = 4.6000  \n",
      "\n",
      "Fold: 3  Epoch: 65  Training loss = 2.1005  Validation loss = 4.5999  \n",
      "\n",
      "Fold: 3  Epoch: 66  Training loss = 2.1004  Validation loss = 4.5998  \n",
      "\n",
      "Fold: 3  Epoch: 67  Training loss = 2.1003  Validation loss = 4.5996  \n",
      "\n",
      "Fold: 3  Epoch: 68  Training loss = 2.1001  Validation loss = 4.5995  \n",
      "\n",
      "Fold: 3  Epoch: 69  Training loss = 2.1000  Validation loss = 4.5994  \n",
      "\n",
      "Fold: 3  Epoch: 70  Training loss = 2.0999  Validation loss = 4.5992  \n",
      "\n",
      "Fold: 3  Epoch: 71  Training loss = 2.0998  Validation loss = 4.5991  \n",
      "\n",
      "Fold: 3  Epoch: 72  Training loss = 2.0997  Validation loss = 4.5990  \n",
      "\n",
      "Fold: 3  Epoch: 73  Training loss = 2.0996  Validation loss = 4.5989  \n",
      "\n",
      "Fold: 3  Epoch: 74  Training loss = 2.0994  Validation loss = 4.5987  \n",
      "\n",
      "Fold: 3  Epoch: 75  Training loss = 2.0993  Validation loss = 4.5986  \n",
      "\n",
      "Fold: 3  Epoch: 76  Training loss = 2.0992  Validation loss = 4.5985  \n",
      "\n",
      "Fold: 3  Epoch: 77  Training loss = 2.0991  Validation loss = 4.5983  \n",
      "\n",
      "Fold: 3  Epoch: 78  Training loss = 2.0990  Validation loss = 4.5982  \n",
      "\n",
      "Fold: 3  Epoch: 79  Training loss = 2.0989  Validation loss = 4.5981  \n",
      "\n",
      "Fold: 3  Epoch: 80  Training loss = 2.0988  Validation loss = 4.5980  \n",
      "\n",
      "Fold: 3  Epoch: 81  Training loss = 2.0987  Validation loss = 4.5978  \n",
      "\n",
      "Fold: 3  Epoch: 82  Training loss = 2.0985  Validation loss = 4.5977  \n",
      "\n",
      "Fold: 3  Epoch: 83  Training loss = 2.0984  Validation loss = 4.5975  \n",
      "\n",
      "Fold: 3  Epoch: 84  Training loss = 2.0983  Validation loss = 4.5974  \n",
      "\n",
      "Fold: 3  Epoch: 85  Training loss = 2.0982  Validation loss = 4.5973  \n",
      "\n",
      "Fold: 3  Epoch: 86  Training loss = 2.0981  Validation loss = 4.5972  \n",
      "\n",
      "Fold: 3  Epoch: 87  Training loss = 2.0980  Validation loss = 4.5971  \n",
      "\n",
      "Fold: 3  Epoch: 88  Training loss = 2.0979  Validation loss = 4.5969  \n",
      "\n",
      "Fold: 3  Epoch: 89  Training loss = 2.0977  Validation loss = 4.5968  \n",
      "\n",
      "Fold: 3  Epoch: 90  Training loss = 2.0976  Validation loss = 4.5966  \n",
      "\n",
      "Fold: 3  Epoch: 91  Training loss = 2.0975  Validation loss = 4.5965  \n",
      "\n",
      "Fold: 3  Epoch: 92  Training loss = 2.0974  Validation loss = 4.5964  \n",
      "\n",
      "Fold: 3  Epoch: 93  Training loss = 2.0973  Validation loss = 4.5962  \n",
      "\n",
      "Fold: 3  Epoch: 94  Training loss = 2.0972  Validation loss = 4.5961  \n",
      "\n",
      "Fold: 3  Epoch: 95  Training loss = 2.0970  Validation loss = 4.5960  \n",
      "\n",
      "Fold: 3  Epoch: 96  Training loss = 2.0969  Validation loss = 4.5959  \n",
      "\n",
      "Fold: 3  Epoch: 97  Training loss = 2.0968  Validation loss = 4.5958  \n",
      "\n",
      "Fold: 3  Epoch: 98  Training loss = 2.0967  Validation loss = 4.5957  \n",
      "\n",
      "Fold: 3  Epoch: 99  Training loss = 2.0966  Validation loss = 4.5955  \n",
      "\n",
      "Fold: 3  Epoch: 100  Training loss = 2.0965  Validation loss = 4.5954  \n",
      "\n",
      "Fold: 3  Epoch: 101  Training loss = 2.0964  Validation loss = 4.5953  \n",
      "\n",
      "Fold: 3  Epoch: 102  Training loss = 2.0963  Validation loss = 4.5952  \n",
      "\n",
      "Fold: 3  Epoch: 103  Training loss = 2.0962  Validation loss = 4.5950  \n",
      "\n",
      "Fold: 3  Epoch: 104  Training loss = 2.0961  Validation loss = 4.5949  \n",
      "\n",
      "Fold: 3  Epoch: 105  Training loss = 2.0959  Validation loss = 4.5947  \n",
      "\n",
      "Fold: 3  Epoch: 106  Training loss = 2.0958  Validation loss = 4.5946  \n",
      "\n",
      "Fold: 3  Epoch: 107  Training loss = 2.0957  Validation loss = 4.5945  \n",
      "\n",
      "Fold: 3  Epoch: 108  Training loss = 2.0956  Validation loss = 4.5944  \n",
      "\n",
      "Fold: 3  Epoch: 109  Training loss = 2.0955  Validation loss = 4.5942  \n",
      "\n",
      "Fold: 3  Epoch: 110  Training loss = 2.0954  Validation loss = 4.5940  \n",
      "\n",
      "Fold: 3  Epoch: 111  Training loss = 2.0952  Validation loss = 4.5939  \n",
      "\n",
      "Fold: 3  Epoch: 112  Training loss = 2.0951  Validation loss = 4.5938  \n",
      "\n",
      "Fold: 3  Epoch: 113  Training loss = 2.0950  Validation loss = 4.5936  \n",
      "\n",
      "Fold: 3  Epoch: 114  Training loss = 2.0949  Validation loss = 4.5935  \n",
      "\n",
      "Fold: 3  Epoch: 115  Training loss = 2.0948  Validation loss = 4.5934  \n",
      "\n",
      "Fold: 3  Epoch: 116  Training loss = 2.0947  Validation loss = 4.5933  \n",
      "\n",
      "Fold: 3  Epoch: 117  Training loss = 2.0946  Validation loss = 4.5932  \n",
      "\n",
      "Fold: 3  Epoch: 118  Training loss = 2.0945  Validation loss = 4.5931  \n",
      "\n",
      "Fold: 3  Epoch: 119  Training loss = 2.0943  Validation loss = 4.5929  \n",
      "\n",
      "Fold: 3  Epoch: 120  Training loss = 2.0942  Validation loss = 4.5928  \n",
      "\n",
      "Fold: 3  Epoch: 121  Training loss = 2.0941  Validation loss = 4.5927  \n",
      "\n",
      "Fold: 3  Epoch: 122  Training loss = 2.0941  Validation loss = 4.5926  \n",
      "\n",
      "Fold: 3  Epoch: 123  Training loss = 2.0939  Validation loss = 4.5925  \n",
      "\n",
      "Fold: 3  Epoch: 124  Training loss = 2.0938  Validation loss = 4.5923  \n",
      "\n",
      "Fold: 3  Epoch: 125  Training loss = 2.0937  Validation loss = 4.5922  \n",
      "\n",
      "Fold: 3  Epoch: 126  Training loss = 2.0936  Validation loss = 4.5921  \n",
      "\n",
      "Fold: 3  Epoch: 127  Training loss = 2.0935  Validation loss = 4.5920  \n",
      "\n",
      "Fold: 3  Epoch: 128  Training loss = 2.0934  Validation loss = 4.5919  \n",
      "\n",
      "Fold: 3  Epoch: 129  Training loss = 2.0933  Validation loss = 4.5917  \n",
      "\n",
      "Fold: 3  Epoch: 130  Training loss = 2.0931  Validation loss = 4.5916  \n",
      "\n",
      "Fold: 3  Epoch: 131  Training loss = 2.0930  Validation loss = 4.5915  \n",
      "\n",
      "Fold: 3  Epoch: 132  Training loss = 2.0929  Validation loss = 4.5913  \n",
      "\n",
      "Fold: 3  Epoch: 133  Training loss = 2.0928  Validation loss = 4.5912  \n",
      "\n",
      "Fold: 3  Epoch: 134  Training loss = 2.0927  Validation loss = 4.5911  \n",
      "\n",
      "Fold: 3  Epoch: 135  Training loss = 2.0926  Validation loss = 4.5910  \n",
      "\n",
      "Fold: 3  Epoch: 136  Training loss = 2.0924  Validation loss = 4.5909  \n",
      "\n",
      "Fold: 3  Epoch: 137  Training loss = 2.0924  Validation loss = 4.5907  \n",
      "\n",
      "Fold: 3  Epoch: 138  Training loss = 2.0922  Validation loss = 4.5906  \n",
      "\n",
      "Fold: 3  Epoch: 139  Training loss = 2.0921  Validation loss = 4.5905  \n",
      "\n",
      "Fold: 3  Epoch: 140  Training loss = 2.0920  Validation loss = 4.5904  \n",
      "\n",
      "Fold: 3  Epoch: 141  Training loss = 2.0919  Validation loss = 4.5903  \n",
      "\n",
      "Fold: 3  Epoch: 142  Training loss = 2.0918  Validation loss = 4.5902  \n",
      "\n",
      "Fold: 3  Epoch: 143  Training loss = 2.0917  Validation loss = 4.5901  \n",
      "\n",
      "Fold: 3  Epoch: 144  Training loss = 2.0916  Validation loss = 4.5899  \n",
      "\n",
      "Fold: 3  Epoch: 145  Training loss = 2.0915  Validation loss = 4.5898  \n",
      "\n",
      "Fold: 3  Epoch: 146  Training loss = 2.0914  Validation loss = 4.5897  \n",
      "\n",
      "Fold: 3  Epoch: 147  Training loss = 2.0913  Validation loss = 4.5895  \n",
      "\n",
      "Fold: 3  Epoch: 148  Training loss = 2.0911  Validation loss = 4.5894  \n",
      "\n",
      "Fold: 3  Epoch: 149  Training loss = 2.0910  Validation loss = 4.5893  \n",
      "\n",
      "Fold: 3  Epoch: 150  Training loss = 2.0909  Validation loss = 4.5892  \n",
      "\n",
      "Fold: 3  Epoch: 151  Training loss = 2.0908  Validation loss = 4.5891  \n",
      "\n",
      "Fold: 3  Epoch: 152  Training loss = 2.0907  Validation loss = 4.5889  \n",
      "\n",
      "Fold: 3  Epoch: 153  Training loss = 2.0906  Validation loss = 4.5888  \n",
      "\n",
      "Fold: 3  Epoch: 154  Training loss = 2.0905  Validation loss = 4.5887  \n",
      "\n",
      "Fold: 3  Epoch: 155  Training loss = 2.0904  Validation loss = 4.5886  \n",
      "\n",
      "Fold: 3  Epoch: 156  Training loss = 2.0903  Validation loss = 4.5884  \n",
      "\n",
      "Fold: 3  Epoch: 157  Training loss = 2.0901  Validation loss = 4.5883  \n",
      "\n",
      "Fold: 3  Epoch: 158  Training loss = 2.0900  Validation loss = 4.5882  \n",
      "\n",
      "Fold: 3  Epoch: 159  Training loss = 2.0899  Validation loss = 4.5880  \n",
      "\n",
      "Fold: 3  Epoch: 160  Training loss = 2.0898  Validation loss = 4.5879  \n",
      "\n",
      "Fold: 3  Epoch: 161  Training loss = 2.0897  Validation loss = 4.5878  \n",
      "\n",
      "Fold: 3  Epoch: 162  Training loss = 2.0896  Validation loss = 4.5877  \n",
      "\n",
      "Fold: 3  Epoch: 163  Training loss = 2.0895  Validation loss = 4.5876  \n",
      "\n",
      "Fold: 3  Epoch: 164  Training loss = 2.0894  Validation loss = 4.5875  \n",
      "\n",
      "Fold: 3  Epoch: 165  Training loss = 2.0893  Validation loss = 4.5873  \n",
      "\n",
      "Fold: 3  Epoch: 166  Training loss = 2.0892  Validation loss = 4.5872  \n",
      "\n",
      "Fold: 3  Epoch: 167  Training loss = 2.0890  Validation loss = 4.5871  \n",
      "\n",
      "Fold: 3  Epoch: 168  Training loss = 2.0889  Validation loss = 4.5870  \n",
      "\n",
      "Fold: 3  Epoch: 169  Training loss = 2.0888  Validation loss = 4.5868  \n",
      "\n",
      "Fold: 3  Epoch: 170  Training loss = 2.0887  Validation loss = 4.5867  \n",
      "\n",
      "Fold: 3  Epoch: 171  Training loss = 2.0886  Validation loss = 4.5866  \n",
      "\n",
      "Fold: 3  Epoch: 172  Training loss = 2.0885  Validation loss = 4.5865  \n",
      "\n",
      "Fold: 3  Epoch: 173  Training loss = 2.0884  Validation loss = 4.5864  \n",
      "\n",
      "Fold: 3  Epoch: 174  Training loss = 2.0883  Validation loss = 4.5863  \n",
      "\n",
      "Fold: 3  Epoch: 175  Training loss = 2.0882  Validation loss = 4.5862  \n",
      "\n",
      "Fold: 3  Epoch: 176  Training loss = 2.0881  Validation loss = 4.5861  \n",
      "\n",
      "Fold: 3  Epoch: 177  Training loss = 2.0880  Validation loss = 4.5860  \n",
      "\n",
      "Fold: 3  Epoch: 178  Training loss = 2.0879  Validation loss = 4.5858  \n",
      "\n",
      "Fold: 3  Epoch: 179  Training loss = 2.0878  Validation loss = 4.5857  \n",
      "\n",
      "Fold: 3  Epoch: 180  Training loss = 2.0877  Validation loss = 4.5856  \n",
      "\n",
      "Fold: 3  Epoch: 181  Training loss = 2.0876  Validation loss = 4.5855  \n",
      "\n",
      "Fold: 3  Epoch: 182  Training loss = 2.0875  Validation loss = 4.5854  \n",
      "\n",
      "Fold: 3  Epoch: 183  Training loss = 2.0874  Validation loss = 4.5853  \n",
      "\n",
      "Fold: 3  Epoch: 184  Training loss = 2.0873  Validation loss = 4.5852  \n",
      "\n",
      "Fold: 3  Epoch: 185  Training loss = 2.0872  Validation loss = 4.5851  \n",
      "\n",
      "Fold: 3  Epoch: 186  Training loss = 2.0870  Validation loss = 4.5849  \n",
      "\n",
      "Fold: 3  Epoch: 187  Training loss = 2.0869  Validation loss = 4.5848  \n",
      "\n",
      "Fold: 3  Epoch: 188  Training loss = 2.0868  Validation loss = 4.5847  \n",
      "\n",
      "Fold: 3  Epoch: 189  Training loss = 2.0867  Validation loss = 4.5845  \n",
      "\n",
      "Fold: 3  Epoch: 190  Training loss = 2.0866  Validation loss = 4.5844  \n",
      "\n",
      "Fold: 3  Epoch: 191  Training loss = 2.0865  Validation loss = 4.5843  \n",
      "\n",
      "Fold: 3  Epoch: 192  Training loss = 2.0863  Validation loss = 4.5841  \n",
      "\n",
      "Fold: 3  Epoch: 193  Training loss = 2.0862  Validation loss = 4.5840  \n",
      "\n",
      "Fold: 3  Epoch: 194  Training loss = 2.0861  Validation loss = 4.5839  \n",
      "\n",
      "Fold: 3  Epoch: 195  Training loss = 2.0860  Validation loss = 4.5838  \n",
      "\n",
      "Fold: 3  Epoch: 196  Training loss = 2.0859  Validation loss = 4.5836  \n",
      "\n",
      "Fold: 3  Epoch: 197  Training loss = 2.0858  Validation loss = 4.5835  \n",
      "\n",
      "Fold: 3  Epoch: 198  Training loss = 2.0857  Validation loss = 4.5834  \n",
      "\n",
      "Fold: 3  Epoch: 199  Training loss = 2.0856  Validation loss = 4.5833  \n",
      "\n",
      "Fold: 3  Epoch: 200  Training loss = 2.0855  Validation loss = 4.5832  \n",
      "\n",
      "Fold: 3  Epoch: 201  Training loss = 2.0854  Validation loss = 4.5831  \n",
      "\n",
      "Fold: 3  Epoch: 202  Training loss = 2.0853  Validation loss = 4.5830  \n",
      "\n",
      "Fold: 3  Epoch: 203  Training loss = 2.0852  Validation loss = 4.5829  \n",
      "\n",
      "Fold: 3  Epoch: 204  Training loss = 2.0851  Validation loss = 4.5827  \n",
      "\n",
      "Fold: 3  Epoch: 205  Training loss = 2.0850  Validation loss = 4.5826  \n",
      "\n",
      "Fold: 3  Epoch: 206  Training loss = 2.0849  Validation loss = 4.5825  \n",
      "\n",
      "Fold: 3  Epoch: 207  Training loss = 2.0848  Validation loss = 4.5824  \n",
      "\n",
      "Fold: 3  Epoch: 208  Training loss = 2.0846  Validation loss = 4.5822  \n",
      "\n",
      "Fold: 3  Epoch: 209  Training loss = 2.0845  Validation loss = 4.5821  \n",
      "\n",
      "Fold: 3  Epoch: 210  Training loss = 2.0844  Validation loss = 4.5820  \n",
      "\n",
      "Fold: 3  Epoch: 211  Training loss = 2.0843  Validation loss = 4.5819  \n",
      "\n",
      "Fold: 3  Epoch: 212  Training loss = 2.0842  Validation loss = 4.5818  \n",
      "\n",
      "Fold: 3  Epoch: 213  Training loss = 2.0841  Validation loss = 4.5816  \n",
      "\n",
      "Fold: 3  Epoch: 214  Training loss = 2.0840  Validation loss = 4.5815  \n",
      "\n",
      "Fold: 3  Epoch: 215  Training loss = 2.0839  Validation loss = 4.5814  \n",
      "\n",
      "Fold: 3  Epoch: 216  Training loss = 2.0838  Validation loss = 4.5813  \n",
      "\n",
      "Fold: 3  Epoch: 217  Training loss = 2.0837  Validation loss = 4.5812  \n",
      "\n",
      "Fold: 3  Epoch: 218  Training loss = 2.0836  Validation loss = 4.5811  \n",
      "\n",
      "Fold: 3  Epoch: 219  Training loss = 2.0835  Validation loss = 4.5810  \n",
      "\n",
      "Fold: 3  Epoch: 220  Training loss = 2.0834  Validation loss = 4.5809  \n",
      "\n",
      "Fold: 3  Epoch: 221  Training loss = 2.0833  Validation loss = 4.5808  \n",
      "\n",
      "Fold: 3  Epoch: 222  Training loss = 2.0831  Validation loss = 4.5806  \n",
      "\n",
      "Fold: 3  Epoch: 223  Training loss = 2.0830  Validation loss = 4.5805  \n",
      "\n",
      "Fold: 3  Epoch: 224  Training loss = 2.0829  Validation loss = 4.5804  \n",
      "\n",
      "Fold: 3  Epoch: 225  Training loss = 2.0828  Validation loss = 4.5803  \n",
      "\n",
      "Fold: 3  Epoch: 226  Training loss = 2.0827  Validation loss = 4.5802  \n",
      "\n",
      "Fold: 3  Epoch: 227  Training loss = 2.0826  Validation loss = 4.5800  \n",
      "\n",
      "Fold: 3  Epoch: 228  Training loss = 2.0825  Validation loss = 4.5799  \n",
      "\n",
      "Fold: 3  Epoch: 229  Training loss = 2.0824  Validation loss = 4.5798  \n",
      "\n",
      "Fold: 3  Epoch: 230  Training loss = 2.0822  Validation loss = 4.5796  \n",
      "\n",
      "Fold: 3  Epoch: 231  Training loss = 2.0821  Validation loss = 4.5795  \n",
      "\n",
      "Fold: 3  Epoch: 232  Training loss = 2.0820  Validation loss = 4.5794  \n",
      "\n",
      "Fold: 3  Epoch: 233  Training loss = 2.0819  Validation loss = 4.5793  \n",
      "\n",
      "Fold: 3  Epoch: 234  Training loss = 2.0819  Validation loss = 4.5793  \n",
      "\n",
      "Fold: 3  Epoch: 235  Training loss = 2.0817  Validation loss = 4.5791  \n",
      "\n",
      "Fold: 3  Epoch: 236  Training loss = 2.0817  Validation loss = 4.5790  \n",
      "\n",
      "Fold: 3  Epoch: 237  Training loss = 2.0815  Validation loss = 4.5789  \n",
      "\n",
      "Fold: 3  Epoch: 238  Training loss = 2.0815  Validation loss = 4.5788  \n",
      "\n",
      "Fold: 3  Epoch: 239  Training loss = 2.0814  Validation loss = 4.5787  \n",
      "\n",
      "Fold: 3  Epoch: 240  Training loss = 2.0813  Validation loss = 4.5786  \n",
      "\n",
      "Fold: 3  Epoch: 241  Training loss = 2.0812  Validation loss = 4.5785  \n",
      "\n",
      "Fold: 3  Epoch: 242  Training loss = 2.0811  Validation loss = 4.5784  \n",
      "\n",
      "Fold: 3  Epoch: 243  Training loss = 2.0809  Validation loss = 4.5782  \n",
      "\n",
      "Fold: 3  Epoch: 244  Training loss = 2.0809  Validation loss = 4.5781  \n",
      "\n",
      "Fold: 3  Epoch: 245  Training loss = 2.0807  Validation loss = 4.5780  \n",
      "\n",
      "Fold: 3  Epoch: 246  Training loss = 2.0806  Validation loss = 4.5778  \n",
      "\n",
      "Fold: 3  Epoch: 247  Training loss = 2.0805  Validation loss = 4.5777  \n",
      "\n",
      "Fold: 3  Epoch: 248  Training loss = 2.0804  Validation loss = 4.5776  \n",
      "\n",
      "Fold: 3  Epoch: 249  Training loss = 2.0803  Validation loss = 4.5775  \n",
      "\n",
      "Fold: 3  Epoch: 250  Training loss = 2.0802  Validation loss = 4.5774  \n",
      "\n",
      "Fold: 3  Epoch: 251  Training loss = 2.0801  Validation loss = 4.5772  \n",
      "\n",
      "Fold: 3  Epoch: 252  Training loss = 2.0800  Validation loss = 4.5771  \n",
      "\n",
      "Fold: 3  Epoch: 253  Training loss = 2.0798  Validation loss = 4.5770  \n",
      "\n",
      "Fold: 3  Epoch: 254  Training loss = 2.0798  Validation loss = 4.5768  \n",
      "\n",
      "Fold: 3  Epoch: 255  Training loss = 2.0797  Validation loss = 4.5767  \n",
      "\n",
      "Fold: 3  Epoch: 256  Training loss = 2.0796  Validation loss = 4.5767  \n",
      "\n",
      "Fold: 3  Epoch: 257  Training loss = 2.0794  Validation loss = 4.5765  \n",
      "\n",
      "Fold: 3  Epoch: 258  Training loss = 2.0793  Validation loss = 4.5764  \n",
      "\n",
      "Fold: 3  Epoch: 259  Training loss = 2.0792  Validation loss = 4.5762  \n",
      "\n",
      "Fold: 3  Epoch: 260  Training loss = 2.0791  Validation loss = 4.5761  \n",
      "\n",
      "Fold: 3  Epoch: 261  Training loss = 2.0789  Validation loss = 4.5760  \n",
      "\n",
      "Fold: 3  Epoch: 262  Training loss = 2.0788  Validation loss = 4.5759  \n",
      "\n",
      "Fold: 3  Epoch: 263  Training loss = 2.0788  Validation loss = 4.5758  \n",
      "\n",
      "Fold: 3  Epoch: 264  Training loss = 2.0786  Validation loss = 4.5756  \n",
      "\n",
      "Fold: 3  Epoch: 265  Training loss = 2.0785  Validation loss = 4.5755  \n",
      "\n",
      "Fold: 3  Epoch: 266  Training loss = 2.0784  Validation loss = 4.5754  \n",
      "\n",
      "Fold: 3  Epoch: 267  Training loss = 2.0783  Validation loss = 4.5752  \n",
      "\n",
      "Fold: 3  Epoch: 268  Training loss = 2.0782  Validation loss = 4.5751  \n",
      "\n",
      "Fold: 3  Epoch: 269  Training loss = 2.0781  Validation loss = 4.5750  \n",
      "\n",
      "Fold: 3  Epoch: 270  Training loss = 2.0780  Validation loss = 4.5748  \n",
      "\n",
      "Fold: 3  Epoch: 271  Training loss = 2.0778  Validation loss = 4.5747  \n",
      "\n",
      "Fold: 3  Epoch: 272  Training loss = 2.0777  Validation loss = 4.5746  \n",
      "\n",
      "Fold: 3  Epoch: 273  Training loss = 2.0776  Validation loss = 4.5744  \n",
      "\n",
      "Fold: 3  Epoch: 274  Training loss = 2.0775  Validation loss = 4.5743  \n",
      "\n",
      "Fold: 3  Epoch: 275  Training loss = 2.0774  Validation loss = 4.5742  \n",
      "\n",
      "Fold: 3  Epoch: 276  Training loss = 2.0773  Validation loss = 4.5741  \n",
      "\n",
      "Fold: 3  Epoch: 277  Training loss = 2.0771  Validation loss = 4.5739  \n",
      "\n",
      "Fold: 3  Epoch: 278  Training loss = 2.0770  Validation loss = 4.5738  \n",
      "\n",
      "Fold: 3  Epoch: 279  Training loss = 2.0769  Validation loss = 4.5737  \n",
      "\n",
      "Fold: 3  Epoch: 280  Training loss = 2.0768  Validation loss = 4.5736  \n",
      "\n",
      "Fold: 3  Epoch: 281  Training loss = 2.0767  Validation loss = 4.5735  \n",
      "\n",
      "Fold: 3  Epoch: 282  Training loss = 2.0766  Validation loss = 4.5733  \n",
      "\n",
      "Fold: 3  Epoch: 283  Training loss = 2.0765  Validation loss = 4.5732  \n",
      "\n",
      "Fold: 3  Epoch: 284  Training loss = 2.0764  Validation loss = 4.5731  \n",
      "\n",
      "Fold: 3  Epoch: 285  Training loss = 2.0763  Validation loss = 4.5729  \n",
      "\n",
      "Fold: 3  Epoch: 286  Training loss = 2.0762  Validation loss = 4.5728  \n",
      "\n",
      "Fold: 3  Epoch: 287  Training loss = 2.0760  Validation loss = 4.5727  \n",
      "\n",
      "Fold: 3  Epoch: 288  Training loss = 2.0759  Validation loss = 4.5726  \n",
      "\n",
      "Fold: 3  Epoch: 289  Training loss = 2.0758  Validation loss = 4.5725  \n",
      "\n",
      "Fold: 3  Epoch: 290  Training loss = 2.0757  Validation loss = 4.5723  \n",
      "\n",
      "Fold: 3  Epoch: 291  Training loss = 2.0756  Validation loss = 4.5722  \n",
      "\n",
      "Fold: 3  Epoch: 292  Training loss = 2.0755  Validation loss = 4.5721  \n",
      "\n",
      "Fold: 3  Epoch: 293  Training loss = 2.0754  Validation loss = 4.5719  \n",
      "\n",
      "Fold: 3  Epoch: 294  Training loss = 2.0752  Validation loss = 4.5718  \n",
      "\n",
      "Fold: 3  Epoch: 295  Training loss = 2.0751  Validation loss = 4.5717  \n",
      "\n",
      "Fold: 3  Epoch: 296  Training loss = 2.0750  Validation loss = 4.5716  \n",
      "\n",
      "Fold: 3  Epoch: 297  Training loss = 2.0749  Validation loss = 4.5715  \n",
      "\n",
      "Fold: 3  Epoch: 298  Training loss = 2.0748  Validation loss = 4.5714  \n",
      "\n",
      "Fold: 3  Epoch: 299  Training loss = 2.0747  Validation loss = 4.5712  \n",
      "\n",
      "Fold: 3  Epoch: 300  Training loss = 2.0746  Validation loss = 4.5711  \n",
      "\n",
      "Fold: 3  Epoch: 301  Training loss = 2.0745  Validation loss = 4.5710  \n",
      "\n",
      "Fold: 3  Epoch: 302  Training loss = 2.0744  Validation loss = 4.5709  \n",
      "\n",
      "Fold: 3  Epoch: 303  Training loss = 2.0743  Validation loss = 4.5707  \n",
      "\n",
      "Fold: 3  Epoch: 304  Training loss = 2.0742  Validation loss = 4.5706  \n",
      "\n",
      "Fold: 3  Epoch: 305  Training loss = 2.0741  Validation loss = 4.5705  \n",
      "\n",
      "Fold: 3  Epoch: 306  Training loss = 2.0740  Validation loss = 4.5704  \n",
      "\n",
      "Fold: 3  Epoch: 307  Training loss = 2.0739  Validation loss = 4.5703  \n",
      "\n",
      "Fold: 3  Epoch: 308  Training loss = 2.0738  Validation loss = 4.5702  \n",
      "\n",
      "Fold: 3  Epoch: 309  Training loss = 2.0737  Validation loss = 4.5701  \n",
      "\n",
      "Fold: 3  Epoch: 310  Training loss = 2.0736  Validation loss = 4.5700  \n",
      "\n",
      "Fold: 3  Epoch: 311  Training loss = 2.0735  Validation loss = 4.5698  \n",
      "\n",
      "Fold: 3  Epoch: 312  Training loss = 2.0734  Validation loss = 4.5697  \n",
      "\n",
      "Fold: 3  Epoch: 313  Training loss = 2.0732  Validation loss = 4.5696  \n",
      "\n",
      "Fold: 3  Epoch: 314  Training loss = 2.0731  Validation loss = 4.5695  \n",
      "\n",
      "Fold: 3  Epoch: 315  Training loss = 2.0730  Validation loss = 4.5693  \n",
      "\n",
      "Fold: 3  Epoch: 316  Training loss = 2.0730  Validation loss = 4.5693  \n",
      "\n",
      "Fold: 3  Epoch: 317  Training loss = 2.0728  Validation loss = 4.5691  \n",
      "\n",
      "Fold: 3  Epoch: 318  Training loss = 2.0727  Validation loss = 4.5690  \n",
      "\n",
      "Fold: 3  Epoch: 319  Training loss = 2.0726  Validation loss = 4.5689  \n",
      "\n",
      "Fold: 3  Epoch: 320  Training loss = 2.0726  Validation loss = 4.5688  \n",
      "\n",
      "Fold: 3  Epoch: 321  Training loss = 2.0724  Validation loss = 4.5687  \n",
      "\n",
      "Fold: 3  Epoch: 322  Training loss = 2.0723  Validation loss = 4.5686  \n",
      "\n",
      "Fold: 3  Epoch: 323  Training loss = 2.0722  Validation loss = 4.5685  \n",
      "\n",
      "Fold: 3  Epoch: 324  Training loss = 2.0722  Validation loss = 4.5684  \n",
      "\n",
      "Fold: 3  Epoch: 325  Training loss = 2.0720  Validation loss = 4.5682  \n",
      "\n",
      "Fold: 3  Epoch: 326  Training loss = 2.0719  Validation loss = 4.5681  \n",
      "\n",
      "Fold: 3  Epoch: 327  Training loss = 2.0718  Validation loss = 4.5680  \n",
      "\n",
      "Fold: 3  Epoch: 328  Training loss = 2.0717  Validation loss = 4.5679  \n",
      "\n",
      "Fold: 3  Epoch: 329  Training loss = 2.0716  Validation loss = 4.5678  \n",
      "\n",
      "Fold: 3  Epoch: 330  Training loss = 2.0715  Validation loss = 4.5677  \n",
      "\n",
      "Fold: 3  Epoch: 331  Training loss = 2.0714  Validation loss = 4.5676  \n",
      "\n",
      "Fold: 3  Epoch: 332  Training loss = 2.0713  Validation loss = 4.5675  \n",
      "\n",
      "Fold: 3  Epoch: 333  Training loss = 2.0712  Validation loss = 4.5673  \n",
      "\n",
      "Fold: 3  Epoch: 334  Training loss = 2.0711  Validation loss = 4.5672  \n",
      "\n",
      "Fold: 3  Epoch: 335  Training loss = 2.0710  Validation loss = 4.5671  \n",
      "\n",
      "Fold: 3  Epoch: 336  Training loss = 2.0709  Validation loss = 4.5669  \n",
      "\n",
      "Fold: 3  Epoch: 337  Training loss = 2.0708  Validation loss = 4.5668  \n",
      "\n",
      "Fold: 3  Epoch: 338  Training loss = 2.0706  Validation loss = 4.5667  \n",
      "\n",
      "Fold: 3  Epoch: 339  Training loss = 2.0705  Validation loss = 4.5666  \n",
      "\n",
      "Fold: 3  Epoch: 340  Training loss = 2.0704  Validation loss = 4.5665  \n",
      "\n",
      "Fold: 3  Epoch: 341  Training loss = 2.0703  Validation loss = 4.5664  \n",
      "\n",
      "Fold: 3  Epoch: 342  Training loss = 2.0702  Validation loss = 4.5662  \n",
      "\n",
      "Fold: 3  Epoch: 343  Training loss = 2.0701  Validation loss = 4.5660  \n",
      "\n",
      "Fold: 3  Epoch: 344  Training loss = 2.0700  Validation loss = 4.5659  \n",
      "\n",
      "Fold: 3  Epoch: 345  Training loss = 2.0699  Validation loss = 4.5658  \n",
      "\n",
      "Fold: 3  Epoch: 346  Training loss = 2.0698  Validation loss = 4.5657  \n",
      "\n",
      "Fold: 3  Epoch: 347  Training loss = 2.0697  Validation loss = 4.5656  \n",
      "\n",
      "Fold: 3  Epoch: 348  Training loss = 2.0695  Validation loss = 4.5654  \n",
      "\n",
      "Fold: 3  Epoch: 349  Training loss = 2.0694  Validation loss = 4.5653  \n",
      "\n",
      "Fold: 3  Epoch: 350  Training loss = 2.0693  Validation loss = 4.5651  \n",
      "\n",
      "Fold: 3  Epoch: 351  Training loss = 2.0692  Validation loss = 4.5651  \n",
      "\n",
      "Fold: 3  Epoch: 352  Training loss = 2.0691  Validation loss = 4.5650  \n",
      "\n",
      "Fold: 3  Epoch: 353  Training loss = 2.0690  Validation loss = 4.5649  \n",
      "\n",
      "Fold: 3  Epoch: 354  Training loss = 2.0689  Validation loss = 4.5647  \n",
      "\n",
      "Fold: 3  Epoch: 355  Training loss = 2.0688  Validation loss = 4.5646  \n",
      "\n",
      "Fold: 3  Epoch: 356  Training loss = 2.0687  Validation loss = 4.5645  \n",
      "\n",
      "Fold: 3  Epoch: 357  Training loss = 2.0686  Validation loss = 4.5644  \n",
      "\n",
      "Fold: 3  Epoch: 358  Training loss = 2.0685  Validation loss = 4.5643  \n",
      "\n",
      "Fold: 3  Epoch: 359  Training loss = 2.0684  Validation loss = 4.5641  \n",
      "\n",
      "Fold: 3  Epoch: 360  Training loss = 2.0683  Validation loss = 4.5640  \n",
      "\n",
      "Fold: 3  Epoch: 361  Training loss = 2.0682  Validation loss = 4.5639  \n",
      "\n",
      "Fold: 3  Epoch: 362  Training loss = 2.0681  Validation loss = 4.5638  \n",
      "\n",
      "Fold: 3  Epoch: 363  Training loss = 2.0679  Validation loss = 4.5637  \n",
      "\n",
      "Fold: 3  Epoch: 364  Training loss = 2.0678  Validation loss = 4.5635  \n",
      "\n",
      "Fold: 3  Epoch: 365  Training loss = 2.0677  Validation loss = 4.5634  \n",
      "\n",
      "Fold: 3  Epoch: 366  Training loss = 2.0676  Validation loss = 4.5633  \n",
      "\n",
      "Fold: 3  Epoch: 367  Training loss = 2.0676  Validation loss = 4.5632  \n",
      "\n",
      "Fold: 3  Epoch: 368  Training loss = 2.0675  Validation loss = 4.5631  \n",
      "\n",
      "Fold: 3  Epoch: 369  Training loss = 2.0674  Validation loss = 4.5630  \n",
      "\n",
      "Fold: 3  Epoch: 370  Training loss = 2.0672  Validation loss = 4.5629  \n",
      "\n",
      "Fold: 3  Epoch: 371  Training loss = 2.0672  Validation loss = 4.5628  \n",
      "\n",
      "Fold: 3  Epoch: 372  Training loss = 2.0670  Validation loss = 4.5626  \n",
      "\n",
      "Fold: 3  Epoch: 373  Training loss = 2.0670  Validation loss = 4.5625  \n",
      "\n",
      "Fold: 3  Epoch: 374  Training loss = 2.0668  Validation loss = 4.5624  \n",
      "\n",
      "Fold: 3  Epoch: 375  Training loss = 2.0667  Validation loss = 4.5623  \n",
      "\n",
      "Fold: 3  Epoch: 376  Training loss = 2.0666  Validation loss = 4.5621  \n",
      "\n",
      "Fold: 3  Epoch: 377  Training loss = 2.0665  Validation loss = 4.5620  \n",
      "\n",
      "Fold: 3  Epoch: 378  Training loss = 2.0664  Validation loss = 4.5619  \n",
      "\n",
      "Fold: 3  Epoch: 379  Training loss = 2.0663  Validation loss = 4.5618  \n",
      "\n",
      "Fold: 3  Epoch: 380  Training loss = 2.0662  Validation loss = 4.5617  \n",
      "\n",
      "Fold: 3  Epoch: 381  Training loss = 2.0661  Validation loss = 4.5616  \n",
      "\n",
      "Fold: 3  Epoch: 382  Training loss = 2.0660  Validation loss = 4.5614  \n",
      "\n",
      "Fold: 3  Epoch: 383  Training loss = 2.0659  Validation loss = 4.5613  \n",
      "\n",
      "Fold: 3  Epoch: 384  Training loss = 2.0658  Validation loss = 4.5612  \n",
      "\n",
      "Fold: 3  Epoch: 385  Training loss = 2.0657  Validation loss = 4.5611  \n",
      "\n",
      "Fold: 3  Epoch: 386  Training loss = 2.0655  Validation loss = 4.5609  \n",
      "\n",
      "Fold: 3  Epoch: 387  Training loss = 2.0654  Validation loss = 4.5608  \n",
      "\n",
      "Fold: 3  Epoch: 388  Training loss = 2.0653  Validation loss = 4.5607  \n",
      "\n",
      "Fold: 3  Epoch: 389  Training loss = 2.0652  Validation loss = 4.5606  \n",
      "\n",
      "Fold: 3  Epoch: 390  Training loss = 2.0652  Validation loss = 4.5605  \n",
      "\n",
      "Fold: 3  Epoch: 391  Training loss = 2.0650  Validation loss = 4.5603  \n",
      "\n",
      "Fold: 3  Epoch: 392  Training loss = 2.0649  Validation loss = 4.5602  \n",
      "\n",
      "Fold: 3  Epoch: 393  Training loss = 2.0648  Validation loss = 4.5601  \n",
      "\n",
      "Fold: 3  Epoch: 394  Training loss = 2.0647  Validation loss = 4.5600  \n",
      "\n",
      "Fold: 3  Epoch: 395  Training loss = 2.0646  Validation loss = 4.5599  \n",
      "\n",
      "Fold: 3  Epoch: 396  Training loss = 2.0646  Validation loss = 4.5598  \n",
      "\n",
      "Fold: 3  Epoch: 397  Training loss = 2.0644  Validation loss = 4.5597  \n",
      "\n",
      "Fold: 3  Epoch: 398  Training loss = 2.0644  Validation loss = 4.5596  \n",
      "\n",
      "Fold: 3  Epoch: 399  Training loss = 2.0643  Validation loss = 4.5594  \n",
      "\n",
      "Fold: 3  Epoch: 400  Training loss = 2.0642  Validation loss = 4.5593  \n",
      "\n",
      "Fold: 3  Epoch: 401  Training loss = 2.0640  Validation loss = 4.5592  \n",
      "\n",
      "Fold: 3  Epoch: 402  Training loss = 2.0639  Validation loss = 4.5591  \n",
      "\n",
      "Fold: 3  Epoch: 403  Training loss = 2.0638  Validation loss = 4.5589  \n",
      "\n",
      "Fold: 3  Epoch: 404  Training loss = 2.0637  Validation loss = 4.5588  \n",
      "\n",
      "Fold: 3  Epoch: 405  Training loss = 2.0636  Validation loss = 4.5587  \n",
      "\n",
      "Fold: 3  Epoch: 406  Training loss = 2.0635  Validation loss = 4.5586  \n",
      "\n",
      "Fold: 3  Epoch: 407  Training loss = 2.0634  Validation loss = 4.5585  \n",
      "\n",
      "Fold: 3  Epoch: 408  Training loss = 2.0633  Validation loss = 4.5584  \n",
      "\n",
      "Fold: 3  Epoch: 409  Training loss = 2.0632  Validation loss = 4.5583  \n",
      "\n",
      "Fold: 3  Epoch: 410  Training loss = 2.0631  Validation loss = 4.5582  \n",
      "\n",
      "Fold: 3  Epoch: 411  Training loss = 2.0630  Validation loss = 4.5580  \n",
      "\n",
      "Fold: 3  Epoch: 412  Training loss = 2.0629  Validation loss = 4.5579  \n",
      "\n",
      "Fold: 3  Epoch: 413  Training loss = 2.0628  Validation loss = 4.5578  \n",
      "\n",
      "Fold: 3  Epoch: 414  Training loss = 2.0627  Validation loss = 4.5577  \n",
      "\n",
      "Fold: 3  Epoch: 415  Training loss = 2.0626  Validation loss = 4.5575  \n",
      "\n",
      "Fold: 3  Epoch: 416  Training loss = 2.0625  Validation loss = 4.5574  \n",
      "\n",
      "Fold: 3  Epoch: 417  Training loss = 2.0624  Validation loss = 4.5573  \n",
      "\n",
      "Fold: 3  Epoch: 418  Training loss = 2.0622  Validation loss = 4.5571  \n",
      "\n",
      "Fold: 3  Epoch: 419  Training loss = 2.0621  Validation loss = 4.5570  \n",
      "\n",
      "Fold: 3  Epoch: 420  Training loss = 2.0620  Validation loss = 4.5569  \n",
      "\n",
      "Fold: 3  Epoch: 421  Training loss = 2.0619  Validation loss = 4.5568  \n",
      "\n",
      "Fold: 3  Epoch: 422  Training loss = 2.0618  Validation loss = 4.5567  \n",
      "\n",
      "Fold: 3  Epoch: 423  Training loss = 2.0617  Validation loss = 4.5566  \n",
      "\n",
      "Fold: 3  Epoch: 424  Training loss = 2.0616  Validation loss = 4.5565  \n",
      "\n",
      "Fold: 3  Epoch: 425  Training loss = 2.0615  Validation loss = 4.5563  \n",
      "\n",
      "Fold: 3  Epoch: 426  Training loss = 2.0614  Validation loss = 4.5562  \n",
      "\n",
      "Fold: 3  Epoch: 427  Training loss = 2.0613  Validation loss = 4.5561  \n",
      "\n",
      "Fold: 3  Epoch: 428  Training loss = 2.0613  Validation loss = 4.5560  \n",
      "\n",
      "Fold: 3  Epoch: 429  Training loss = 2.0611  Validation loss = 4.5559  \n",
      "\n",
      "Fold: 3  Epoch: 430  Training loss = 2.0611  Validation loss = 4.5557  \n",
      "\n",
      "Fold: 3  Epoch: 431  Training loss = 2.0609  Validation loss = 4.5556  \n",
      "\n",
      "Fold: 3  Epoch: 432  Training loss = 2.0609  Validation loss = 4.5555  \n",
      "\n",
      "Fold: 3  Epoch: 433  Training loss = 2.0607  Validation loss = 4.5554  \n",
      "\n",
      "Fold: 3  Epoch: 434  Training loss = 2.0606  Validation loss = 4.5553  \n",
      "\n",
      "Fold: 3  Epoch: 435  Training loss = 2.0605  Validation loss = 4.5551  \n",
      "\n",
      "Fold: 3  Epoch: 436  Training loss = 2.0604  Validation loss = 4.5550  \n",
      "\n",
      "Fold: 3  Epoch: 437  Training loss = 2.0603  Validation loss = 4.5549  \n",
      "\n",
      "Fold: 3  Epoch: 438  Training loss = 2.0602  Validation loss = 4.5548  \n",
      "\n",
      "Fold: 3  Epoch: 439  Training loss = 2.0601  Validation loss = 4.5547  \n",
      "\n",
      "Fold: 3  Epoch: 440  Training loss = 2.0600  Validation loss = 4.5546  \n",
      "\n",
      "Fold: 3  Epoch: 441  Training loss = 2.0600  Validation loss = 4.5545  \n",
      "\n",
      "Fold: 3  Epoch: 442  Training loss = 2.0599  Validation loss = 4.5544  \n",
      "\n",
      "Fold: 3  Epoch: 443  Training loss = 2.0597  Validation loss = 4.5542  \n",
      "\n",
      "Fold: 3  Epoch: 444  Training loss = 2.0597  Validation loss = 4.5541  \n",
      "\n",
      "Fold: 3  Epoch: 445  Training loss = 2.0595  Validation loss = 4.5540  \n",
      "\n",
      "Fold: 3  Epoch: 446  Training loss = 2.0594  Validation loss = 4.5539  \n",
      "\n",
      "Fold: 3  Epoch: 447  Training loss = 2.0593  Validation loss = 4.5537  \n",
      "\n",
      "Fold: 3  Epoch: 448  Training loss = 2.0592  Validation loss = 4.5536  \n",
      "\n",
      "Fold: 3  Epoch: 449  Training loss = 2.0591  Validation loss = 4.5535  \n",
      "\n",
      "Fold: 3  Epoch: 450  Training loss = 2.0590  Validation loss = 4.5534  \n",
      "\n",
      "Fold: 3  Epoch: 451  Training loss = 2.0589  Validation loss = 4.5533  \n",
      "\n",
      "Fold: 3  Epoch: 452  Training loss = 2.0588  Validation loss = 4.5531  \n",
      "\n",
      "Fold: 3  Epoch: 453  Training loss = 2.0587  Validation loss = 4.5530  \n",
      "\n",
      "Fold: 3  Epoch: 454  Training loss = 2.0586  Validation loss = 4.5529  \n",
      "\n",
      "Fold: 3  Epoch: 455  Training loss = 2.0585  Validation loss = 4.5528  \n",
      "\n",
      "Fold: 3  Epoch: 456  Training loss = 2.0584  Validation loss = 4.5527  \n",
      "\n",
      "Fold: 3  Epoch: 457  Training loss = 2.0583  Validation loss = 4.5526  \n",
      "\n",
      "Fold: 3  Epoch: 458  Training loss = 2.0582  Validation loss = 4.5524  \n",
      "\n",
      "Fold: 3  Epoch: 459  Training loss = 2.0581  Validation loss = 4.5523  \n",
      "\n",
      "Fold: 3  Epoch: 460  Training loss = 2.0579  Validation loss = 4.5522  \n",
      "\n",
      "Fold: 3  Epoch: 461  Training loss = 2.0578  Validation loss = 4.5520  \n",
      "\n",
      "Fold: 3  Epoch: 462  Training loss = 2.0577  Validation loss = 4.5519  \n",
      "\n",
      "Fold: 3  Epoch: 463  Training loss = 2.0576  Validation loss = 4.5518  \n",
      "\n",
      "Fold: 3  Epoch: 464  Training loss = 2.0575  Validation loss = 4.5517  \n",
      "\n",
      "Fold: 3  Epoch: 465  Training loss = 2.0574  Validation loss = 4.5516  \n",
      "\n",
      "Fold: 3  Epoch: 466  Training loss = 2.0573  Validation loss = 4.5514  \n",
      "\n",
      "Fold: 3  Epoch: 467  Training loss = 2.0572  Validation loss = 4.5513  \n",
      "\n",
      "Fold: 3  Epoch: 468  Training loss = 2.0571  Validation loss = 4.5512  \n",
      "\n",
      "Fold: 3  Epoch: 469  Training loss = 2.0570  Validation loss = 4.5511  \n",
      "\n",
      "Fold: 3  Epoch: 470  Training loss = 2.0569  Validation loss = 4.5510  \n",
      "\n",
      "Fold: 3  Epoch: 471  Training loss = 2.0568  Validation loss = 4.5508  \n",
      "\n",
      "Fold: 3  Epoch: 472  Training loss = 2.0567  Validation loss = 4.5507  \n",
      "\n",
      "Fold: 3  Epoch: 473  Training loss = 2.0566  Validation loss = 4.5506  \n",
      "\n",
      "Fold: 3  Epoch: 474  Training loss = 2.0565  Validation loss = 4.5505  \n",
      "\n",
      "Fold: 3  Epoch: 475  Training loss = 2.0564  Validation loss = 4.5504  \n",
      "\n",
      "Fold: 3  Epoch: 476  Training loss = 2.0564  Validation loss = 4.5503  \n",
      "\n",
      "Fold: 3  Epoch: 477  Training loss = 2.0562  Validation loss = 4.5502  \n",
      "\n",
      "Fold: 3  Epoch: 478  Training loss = 2.0562  Validation loss = 4.5501  \n",
      "\n",
      "Fold: 3  Epoch: 479  Training loss = 2.0560  Validation loss = 4.5500  \n",
      "\n",
      "Fold: 3  Epoch: 480  Training loss = 2.0559  Validation loss = 4.5498  \n",
      "\n",
      "Fold: 3  Epoch: 481  Training loss = 2.0558  Validation loss = 4.5497  \n",
      "\n",
      "Fold: 3  Epoch: 482  Training loss = 2.0557  Validation loss = 4.5496  \n",
      "\n",
      "Fold: 3  Epoch: 483  Training loss = 2.0556  Validation loss = 4.5495  \n",
      "\n",
      "Fold: 3  Epoch: 484  Training loss = 2.0555  Validation loss = 4.5494  \n",
      "\n",
      "Fold: 3  Epoch: 485  Training loss = 2.0555  Validation loss = 4.5493  \n",
      "\n",
      "Fold: 3  Epoch: 486  Training loss = 2.0554  Validation loss = 4.5492  \n",
      "\n",
      "Fold: 3  Epoch: 487  Training loss = 2.0553  Validation loss = 4.5490  \n",
      "\n",
      "Fold: 3  Epoch: 488  Training loss = 2.0551  Validation loss = 4.5489  \n",
      "\n",
      "Fold: 3  Epoch: 489  Training loss = 2.0550  Validation loss = 4.5488  \n",
      "\n",
      "Fold: 3  Epoch: 490  Training loss = 2.0549  Validation loss = 4.5486  \n",
      "\n",
      "Fold: 3  Epoch: 491  Training loss = 2.0548  Validation loss = 4.5485  \n",
      "\n",
      "Fold: 3  Epoch: 492  Training loss = 2.0547  Validation loss = 4.5484  \n",
      "\n",
      "Fold: 3  Epoch: 493  Training loss = 2.0546  Validation loss = 4.5483  \n",
      "\n",
      "Fold: 3  Epoch: 494  Training loss = 2.0545  Validation loss = 4.5482  \n",
      "\n",
      "Fold: 3  Epoch: 495  Training loss = 2.0544  Validation loss = 4.5481  \n",
      "\n",
      "Fold: 3  Epoch: 496  Training loss = 2.0543  Validation loss = 4.5480  \n",
      "\n",
      "Fold: 3  Epoch: 497  Training loss = 2.0542  Validation loss = 4.5479  \n",
      "\n",
      "Fold: 3  Epoch: 498  Training loss = 2.0541  Validation loss = 4.5477  \n",
      "\n",
      "Fold: 3  Epoch: 499  Training loss = 2.0540  Validation loss = 4.5476  \n",
      "\n",
      "Fold: 3  Epoch: 500  Training loss = 2.0539  Validation loss = 4.5475  \n",
      "\n",
      "Check model:  Fold: 3  Optimal epoch: 500  \n",
      "\n",
      "Fold: 4  Epoch: 1  Training loss = 2.1791  Validation loss = 5.7723  \n",
      "\n",
      "Fold: 4  Epoch: 2  Training loss = 2.1790  Validation loss = 5.7721  \n",
      "\n",
      "Fold: 4  Epoch: 3  Training loss = 2.1789  Validation loss = 5.7720  \n",
      "\n",
      "Fold: 4  Epoch: 4  Training loss = 2.1788  Validation loss = 5.7718  \n",
      "\n",
      "Fold: 4  Epoch: 5  Training loss = 2.1786  Validation loss = 5.7717  \n",
      "\n",
      "Fold: 4  Epoch: 6  Training loss = 2.1785  Validation loss = 5.7715  \n",
      "\n",
      "Fold: 4  Epoch: 7  Training loss = 2.1784  Validation loss = 5.7714  \n",
      "\n",
      "Fold: 4  Epoch: 8  Training loss = 2.1783  Validation loss = 5.7712  \n",
      "\n",
      "Fold: 4  Epoch: 9  Training loss = 2.1782  Validation loss = 5.7711  \n",
      "\n",
      "Fold: 4  Epoch: 10  Training loss = 2.1781  Validation loss = 5.7709  \n",
      "\n",
      "Fold: 4  Epoch: 11  Training loss = 2.1780  Validation loss = 5.7708  \n",
      "\n",
      "Fold: 4  Epoch: 12  Training loss = 2.1779  Validation loss = 5.7707  \n",
      "\n",
      "Fold: 4  Epoch: 13  Training loss = 2.1778  Validation loss = 5.7705  \n",
      "\n",
      "Fold: 4  Epoch: 14  Training loss = 2.1777  Validation loss = 5.7703  \n",
      "\n",
      "Fold: 4  Epoch: 15  Training loss = 2.1776  Validation loss = 5.7702  \n",
      "\n",
      "Fold: 4  Epoch: 16  Training loss = 2.1775  Validation loss = 5.7700  \n",
      "\n",
      "Fold: 4  Epoch: 17  Training loss = 2.1774  Validation loss = 5.7699  \n",
      "\n",
      "Fold: 4  Epoch: 18  Training loss = 2.1772  Validation loss = 5.7697  \n",
      "\n",
      "Fold: 4  Epoch: 19  Training loss = 2.1771  Validation loss = 5.7696  \n",
      "\n",
      "Fold: 4  Epoch: 20  Training loss = 2.1770  Validation loss = 5.7694  \n",
      "\n",
      "Fold: 4  Epoch: 21  Training loss = 2.1769  Validation loss = 5.7693  \n",
      "\n",
      "Fold: 4  Epoch: 22  Training loss = 2.1768  Validation loss = 5.7692  \n",
      "\n",
      "Fold: 4  Epoch: 23  Training loss = 2.1767  Validation loss = 5.7691  \n",
      "\n",
      "Fold: 4  Epoch: 24  Training loss = 2.1766  Validation loss = 5.7689  \n",
      "\n",
      "Fold: 4  Epoch: 25  Training loss = 2.1765  Validation loss = 5.7688  \n",
      "\n",
      "Fold: 4  Epoch: 26  Training loss = 2.1764  Validation loss = 5.7686  \n",
      "\n",
      "Fold: 4  Epoch: 27  Training loss = 2.1763  Validation loss = 5.7685  \n",
      "\n",
      "Fold: 4  Epoch: 28  Training loss = 2.1762  Validation loss = 5.7683  \n",
      "\n",
      "Fold: 4  Epoch: 29  Training loss = 2.1761  Validation loss = 5.7682  \n",
      "\n",
      "Fold: 4  Epoch: 30  Training loss = 2.1760  Validation loss = 5.7681  \n",
      "\n",
      "Fold: 4  Epoch: 31  Training loss = 2.1759  Validation loss = 5.7679  \n",
      "\n",
      "Fold: 4  Epoch: 32  Training loss = 2.1758  Validation loss = 5.7678  \n",
      "\n",
      "Fold: 4  Epoch: 33  Training loss = 2.1757  Validation loss = 5.7677  \n",
      "\n",
      "Fold: 4  Epoch: 34  Training loss = 2.1756  Validation loss = 5.7675  \n",
      "\n",
      "Fold: 4  Epoch: 35  Training loss = 2.1755  Validation loss = 5.7674  \n",
      "\n",
      "Fold: 4  Epoch: 36  Training loss = 2.1754  Validation loss = 5.7673  \n",
      "\n",
      "Fold: 4  Epoch: 37  Training loss = 2.1753  Validation loss = 5.7671  \n",
      "\n",
      "Fold: 4  Epoch: 38  Training loss = 2.1752  Validation loss = 5.7670  \n",
      "\n",
      "Fold: 4  Epoch: 39  Training loss = 2.1751  Validation loss = 5.7668  \n",
      "\n",
      "Fold: 4  Epoch: 40  Training loss = 2.1750  Validation loss = 5.7666  \n",
      "\n",
      "Fold: 4  Epoch: 41  Training loss = 2.1749  Validation loss = 5.7665  \n",
      "\n",
      "Fold: 4  Epoch: 42  Training loss = 2.1748  Validation loss = 5.7664  \n",
      "\n",
      "Fold: 4  Epoch: 43  Training loss = 2.1747  Validation loss = 5.7662  \n",
      "\n",
      "Fold: 4  Epoch: 44  Training loss = 2.1746  Validation loss = 5.7660  \n",
      "\n",
      "Fold: 4  Epoch: 45  Training loss = 2.1745  Validation loss = 5.7659  \n",
      "\n",
      "Fold: 4  Epoch: 46  Training loss = 2.1744  Validation loss = 5.7658  \n",
      "\n",
      "Fold: 4  Epoch: 47  Training loss = 2.1742  Validation loss = 5.7656  \n",
      "\n",
      "Fold: 4  Epoch: 48  Training loss = 2.1741  Validation loss = 5.7654  \n",
      "\n",
      "Fold: 4  Epoch: 49  Training loss = 2.1740  Validation loss = 5.7652  \n",
      "\n",
      "Fold: 4  Epoch: 50  Training loss = 2.1738  Validation loss = 5.7650  \n",
      "\n",
      "Fold: 4  Epoch: 51  Training loss = 2.1737  Validation loss = 5.7649  \n",
      "\n",
      "Fold: 4  Epoch: 52  Training loss = 2.1736  Validation loss = 5.7647  \n",
      "\n",
      "Fold: 4  Epoch: 53  Training loss = 2.1735  Validation loss = 5.7646  \n",
      "\n",
      "Fold: 4  Epoch: 54  Training loss = 2.1734  Validation loss = 5.7644  \n",
      "\n",
      "Fold: 4  Epoch: 55  Training loss = 2.1733  Validation loss = 5.7643  \n",
      "\n",
      "Fold: 4  Epoch: 56  Training loss = 2.1732  Validation loss = 5.7641  \n",
      "\n",
      "Fold: 4  Epoch: 57  Training loss = 2.1730  Validation loss = 5.7640  \n",
      "\n",
      "Fold: 4  Epoch: 58  Training loss = 2.1729  Validation loss = 5.7638  \n",
      "\n",
      "Fold: 4  Epoch: 59  Training loss = 2.1728  Validation loss = 5.7637  \n",
      "\n",
      "Fold: 4  Epoch: 60  Training loss = 2.1727  Validation loss = 5.7635  \n",
      "\n",
      "Fold: 4  Epoch: 61  Training loss = 2.1726  Validation loss = 5.7634  \n",
      "\n",
      "Fold: 4  Epoch: 62  Training loss = 2.1725  Validation loss = 5.7632  \n",
      "\n",
      "Fold: 4  Epoch: 63  Training loss = 2.1724  Validation loss = 5.7631  \n",
      "\n",
      "Fold: 4  Epoch: 64  Training loss = 2.1723  Validation loss = 5.7629  \n",
      "\n",
      "Fold: 4  Epoch: 65  Training loss = 2.1722  Validation loss = 5.7628  \n",
      "\n",
      "Fold: 4  Epoch: 66  Training loss = 2.1721  Validation loss = 5.7626  \n",
      "\n",
      "Fold: 4  Epoch: 67  Training loss = 2.1720  Validation loss = 5.7625  \n",
      "\n",
      "Fold: 4  Epoch: 68  Training loss = 2.1719  Validation loss = 5.7623  \n",
      "\n",
      "Fold: 4  Epoch: 69  Training loss = 2.1718  Validation loss = 5.7621  \n",
      "\n",
      "Fold: 4  Epoch: 70  Training loss = 2.1717  Validation loss = 5.7620  \n",
      "\n",
      "Fold: 4  Epoch: 71  Training loss = 2.1716  Validation loss = 5.7619  \n",
      "\n",
      "Fold: 4  Epoch: 72  Training loss = 2.1715  Validation loss = 5.7618  \n",
      "\n",
      "Fold: 4  Epoch: 73  Training loss = 2.1714  Validation loss = 5.7616  \n",
      "\n",
      "Fold: 4  Epoch: 74  Training loss = 2.1713  Validation loss = 5.7615  \n",
      "\n",
      "Fold: 4  Epoch: 75  Training loss = 2.1712  Validation loss = 5.7613  \n",
      "\n",
      "Fold: 4  Epoch: 76  Training loss = 2.1710  Validation loss = 5.7611  \n",
      "\n",
      "Fold: 4  Epoch: 77  Training loss = 2.1709  Validation loss = 5.7610  \n",
      "\n",
      "Fold: 4  Epoch: 78  Training loss = 2.1708  Validation loss = 5.7608  \n",
      "\n",
      "Fold: 4  Epoch: 79  Training loss = 2.1707  Validation loss = 5.7607  \n",
      "\n",
      "Fold: 4  Epoch: 80  Training loss = 2.1706  Validation loss = 5.7605  \n",
      "\n",
      "Fold: 4  Epoch: 81  Training loss = 2.1705  Validation loss = 5.7604  \n",
      "\n",
      "Fold: 4  Epoch: 82  Training loss = 2.1704  Validation loss = 5.7602  \n",
      "\n",
      "Fold: 4  Epoch: 83  Training loss = 2.1703  Validation loss = 5.7601  \n",
      "\n",
      "Fold: 4  Epoch: 84  Training loss = 2.1702  Validation loss = 5.7599  \n",
      "\n",
      "Fold: 4  Epoch: 85  Training loss = 2.1701  Validation loss = 5.7598  \n",
      "\n",
      "Fold: 4  Epoch: 86  Training loss = 2.1700  Validation loss = 5.7596  \n",
      "\n",
      "Fold: 4  Epoch: 87  Training loss = 2.1699  Validation loss = 5.7595  \n",
      "\n",
      "Fold: 4  Epoch: 88  Training loss = 2.1698  Validation loss = 5.7594  \n",
      "\n",
      "Fold: 4  Epoch: 89  Training loss = 2.1697  Validation loss = 5.7592  \n",
      "\n",
      "Fold: 4  Epoch: 90  Training loss = 2.1696  Validation loss = 5.7591  \n",
      "\n",
      "Fold: 4  Epoch: 91  Training loss = 2.1695  Validation loss = 5.7590  \n",
      "\n",
      "Fold: 4  Epoch: 92  Training loss = 2.1694  Validation loss = 5.7588  \n",
      "\n",
      "Fold: 4  Epoch: 93  Training loss = 2.1693  Validation loss = 5.7586  \n",
      "\n",
      "Fold: 4  Epoch: 94  Training loss = 2.1691  Validation loss = 5.7584  \n",
      "\n",
      "Fold: 4  Epoch: 95  Training loss = 2.1690  Validation loss = 5.7583  \n",
      "\n",
      "Fold: 4  Epoch: 96  Training loss = 2.1689  Validation loss = 5.7581  \n",
      "\n",
      "Fold: 4  Epoch: 97  Training loss = 2.1688  Validation loss = 5.7580  \n",
      "\n",
      "Fold: 4  Epoch: 98  Training loss = 2.1687  Validation loss = 5.7578  \n",
      "\n",
      "Fold: 4  Epoch: 99  Training loss = 2.1686  Validation loss = 5.7577  \n",
      "\n",
      "Fold: 4  Epoch: 100  Training loss = 2.1685  Validation loss = 5.7575  \n",
      "\n",
      "Fold: 4  Epoch: 101  Training loss = 2.1684  Validation loss = 5.7573  \n",
      "\n",
      "Fold: 4  Epoch: 102  Training loss = 2.1683  Validation loss = 5.7572  \n",
      "\n",
      "Fold: 4  Epoch: 103  Training loss = 2.1681  Validation loss = 5.7570  \n",
      "\n",
      "Fold: 4  Epoch: 104  Training loss = 2.1680  Validation loss = 5.7569  \n",
      "\n",
      "Fold: 4  Epoch: 105  Training loss = 2.1680  Validation loss = 5.7568  \n",
      "\n",
      "Fold: 4  Epoch: 106  Training loss = 2.1679  Validation loss = 5.7566  \n",
      "\n",
      "Fold: 4  Epoch: 107  Training loss = 2.1678  Validation loss = 5.7565  \n",
      "\n",
      "Fold: 4  Epoch: 108  Training loss = 2.1676  Validation loss = 5.7563  \n",
      "\n",
      "Fold: 4  Epoch: 109  Training loss = 2.1675  Validation loss = 5.7562  \n",
      "\n",
      "Fold: 4  Epoch: 110  Training loss = 2.1674  Validation loss = 5.7560  \n",
      "\n",
      "Fold: 4  Epoch: 111  Training loss = 2.1673  Validation loss = 5.7559  \n",
      "\n",
      "Fold: 4  Epoch: 112  Training loss = 2.1672  Validation loss = 5.7557  \n",
      "\n",
      "Fold: 4  Epoch: 113  Training loss = 2.1671  Validation loss = 5.7555  \n",
      "\n",
      "Fold: 4  Epoch: 114  Training loss = 2.1670  Validation loss = 5.7554  \n",
      "\n",
      "Fold: 4  Epoch: 115  Training loss = 2.1669  Validation loss = 5.7552  \n",
      "\n",
      "Fold: 4  Epoch: 116  Training loss = 2.1668  Validation loss = 5.7551  \n",
      "\n",
      "Fold: 4  Epoch: 117  Training loss = 2.1667  Validation loss = 5.7549  \n",
      "\n",
      "Fold: 4  Epoch: 118  Training loss = 2.1666  Validation loss = 5.7548  \n",
      "\n",
      "Fold: 4  Epoch: 119  Training loss = 2.1664  Validation loss = 5.7546  \n",
      "\n",
      "Fold: 4  Epoch: 120  Training loss = 2.1663  Validation loss = 5.7545  \n",
      "\n",
      "Fold: 4  Epoch: 121  Training loss = 2.1662  Validation loss = 5.7543  \n",
      "\n",
      "Fold: 4  Epoch: 122  Training loss = 2.1661  Validation loss = 5.7542  \n",
      "\n",
      "Fold: 4  Epoch: 123  Training loss = 2.1660  Validation loss = 5.7540  \n",
      "\n",
      "Fold: 4  Epoch: 124  Training loss = 2.1659  Validation loss = 5.7538  \n",
      "\n",
      "Fold: 4  Epoch: 125  Training loss = 2.1658  Validation loss = 5.7537  \n",
      "\n",
      "Fold: 4  Epoch: 126  Training loss = 2.1657  Validation loss = 5.7536  \n",
      "\n",
      "Fold: 4  Epoch: 127  Training loss = 2.1656  Validation loss = 5.7534  \n",
      "\n",
      "Fold: 4  Epoch: 128  Training loss = 2.1655  Validation loss = 5.7533  \n",
      "\n",
      "Fold: 4  Epoch: 129  Training loss = 2.1654  Validation loss = 5.7532  \n",
      "\n",
      "Fold: 4  Epoch: 130  Training loss = 2.1652  Validation loss = 5.7530  \n",
      "\n",
      "Fold: 4  Epoch: 131  Training loss = 2.1651  Validation loss = 5.7528  \n",
      "\n",
      "Fold: 4  Epoch: 132  Training loss = 2.1650  Validation loss = 5.7527  \n",
      "\n",
      "Fold: 4  Epoch: 133  Training loss = 2.1649  Validation loss = 5.7526  \n",
      "\n",
      "Fold: 4  Epoch: 134  Training loss = 2.1648  Validation loss = 5.7524  \n",
      "\n",
      "Fold: 4  Epoch: 135  Training loss = 2.1647  Validation loss = 5.7523  \n",
      "\n",
      "Fold: 4  Epoch: 136  Training loss = 2.1646  Validation loss = 5.7521  \n",
      "\n",
      "Fold: 4  Epoch: 137  Training loss = 2.1646  Validation loss = 5.7520  \n",
      "\n",
      "Fold: 4  Epoch: 138  Training loss = 2.1645  Validation loss = 5.7519  \n",
      "\n",
      "Fold: 4  Epoch: 139  Training loss = 2.1644  Validation loss = 5.7518  \n",
      "\n",
      "Fold: 4  Epoch: 140  Training loss = 2.1643  Validation loss = 5.7516  \n",
      "\n",
      "Fold: 4  Epoch: 141  Training loss = 2.1642  Validation loss = 5.7515  \n",
      "\n",
      "Fold: 4  Epoch: 142  Training loss = 2.1641  Validation loss = 5.7513  \n",
      "\n",
      "Fold: 4  Epoch: 143  Training loss = 2.1640  Validation loss = 5.7512  \n",
      "\n",
      "Fold: 4  Epoch: 144  Training loss = 2.1639  Validation loss = 5.7511  \n",
      "\n",
      "Fold: 4  Epoch: 145  Training loss = 2.1638  Validation loss = 5.7509  \n",
      "\n",
      "Fold: 4  Epoch: 146  Training loss = 2.1637  Validation loss = 5.7508  \n",
      "\n",
      "Fold: 4  Epoch: 147  Training loss = 2.1636  Validation loss = 5.7506  \n",
      "\n",
      "Fold: 4  Epoch: 148  Training loss = 2.1635  Validation loss = 5.7505  \n",
      "\n",
      "Fold: 4  Epoch: 149  Training loss = 2.1633  Validation loss = 5.7503  \n",
      "\n",
      "Fold: 4  Epoch: 150  Training loss = 2.1632  Validation loss = 5.7501  \n",
      "\n",
      "Fold: 4  Epoch: 151  Training loss = 2.1631  Validation loss = 5.7499  \n",
      "\n",
      "Fold: 4  Epoch: 152  Training loss = 2.1630  Validation loss = 5.7498  \n",
      "\n",
      "Fold: 4  Epoch: 153  Training loss = 2.1629  Validation loss = 5.7497  \n",
      "\n",
      "Fold: 4  Epoch: 154  Training loss = 2.1628  Validation loss = 5.7495  \n",
      "\n",
      "Fold: 4  Epoch: 155  Training loss = 2.1627  Validation loss = 5.7494  \n",
      "\n",
      "Fold: 4  Epoch: 156  Training loss = 2.1626  Validation loss = 5.7492  \n",
      "\n",
      "Fold: 4  Epoch: 157  Training loss = 2.1625  Validation loss = 5.7491  \n",
      "\n",
      "Fold: 4  Epoch: 158  Training loss = 2.1624  Validation loss = 5.7489  \n",
      "\n",
      "Fold: 4  Epoch: 159  Training loss = 2.1623  Validation loss = 5.7488  \n",
      "\n",
      "Fold: 4  Epoch: 160  Training loss = 2.1622  Validation loss = 5.7487  \n",
      "\n",
      "Fold: 4  Epoch: 161  Training loss = 2.1621  Validation loss = 5.7485  \n",
      "\n",
      "Fold: 4  Epoch: 162  Training loss = 2.1620  Validation loss = 5.7484  \n",
      "\n",
      "Fold: 4  Epoch: 163  Training loss = 2.1619  Validation loss = 5.7482  \n",
      "\n",
      "Fold: 4  Epoch: 164  Training loss = 2.1618  Validation loss = 5.7481  \n",
      "\n",
      "Fold: 4  Epoch: 165  Training loss = 2.1617  Validation loss = 5.7479  \n",
      "\n",
      "Fold: 4  Epoch: 166  Training loss = 2.1616  Validation loss = 5.7478  \n",
      "\n",
      "Fold: 4  Epoch: 167  Training loss = 2.1615  Validation loss = 5.7477  \n",
      "\n",
      "Fold: 4  Epoch: 168  Training loss = 2.1614  Validation loss = 5.7475  \n",
      "\n",
      "Fold: 4  Epoch: 169  Training loss = 2.1613  Validation loss = 5.7474  \n",
      "\n",
      "Fold: 4  Epoch: 170  Training loss = 2.1612  Validation loss = 5.7472  \n",
      "\n",
      "Fold: 4  Epoch: 171  Training loss = 2.1611  Validation loss = 5.7471  \n",
      "\n",
      "Fold: 4  Epoch: 172  Training loss = 2.1610  Validation loss = 5.7470  \n",
      "\n",
      "Fold: 4  Epoch: 173  Training loss = 2.1609  Validation loss = 5.7468  \n",
      "\n",
      "Fold: 4  Epoch: 174  Training loss = 2.1608  Validation loss = 5.7467  \n",
      "\n",
      "Fold: 4  Epoch: 175  Training loss = 2.1607  Validation loss = 5.7465  \n",
      "\n",
      "Fold: 4  Epoch: 176  Training loss = 2.1605  Validation loss = 5.7463  \n",
      "\n",
      "Fold: 4  Epoch: 177  Training loss = 2.1605  Validation loss = 5.7462  \n",
      "\n",
      "Fold: 4  Epoch: 178  Training loss = 2.1603  Validation loss = 5.7461  \n",
      "\n",
      "Fold: 4  Epoch: 179  Training loss = 2.1603  Validation loss = 5.7460  \n",
      "\n",
      "Fold: 4  Epoch: 180  Training loss = 2.1602  Validation loss = 5.7458  \n",
      "\n",
      "Fold: 4  Epoch: 181  Training loss = 2.1601  Validation loss = 5.7457  \n",
      "\n",
      "Fold: 4  Epoch: 182  Training loss = 2.1600  Validation loss = 5.7456  \n",
      "\n",
      "Fold: 4  Epoch: 183  Training loss = 2.1599  Validation loss = 5.7455  \n",
      "\n",
      "Fold: 4  Epoch: 184  Training loss = 2.1598  Validation loss = 5.7453  \n",
      "\n",
      "Fold: 4  Epoch: 185  Training loss = 2.1597  Validation loss = 5.7452  \n",
      "\n",
      "Fold: 4  Epoch: 186  Training loss = 2.1596  Validation loss = 5.7451  \n",
      "\n",
      "Fold: 4  Epoch: 187  Training loss = 2.1595  Validation loss = 5.7449  \n",
      "\n",
      "Fold: 4  Epoch: 188  Training loss = 2.1594  Validation loss = 5.7448  \n",
      "\n",
      "Fold: 4  Epoch: 189  Training loss = 2.1593  Validation loss = 5.7447  \n",
      "\n",
      "Fold: 4  Epoch: 190  Training loss = 2.1592  Validation loss = 5.7445  \n",
      "\n",
      "Fold: 4  Epoch: 191  Training loss = 2.1591  Validation loss = 5.7443  \n",
      "\n",
      "Fold: 4  Epoch: 192  Training loss = 2.1590  Validation loss = 5.7442  \n",
      "\n",
      "Fold: 4  Epoch: 193  Training loss = 2.1588  Validation loss = 5.7439  \n",
      "\n",
      "Fold: 4  Epoch: 194  Training loss = 2.1587  Validation loss = 5.7438  \n",
      "\n",
      "Fold: 4  Epoch: 195  Training loss = 2.1586  Validation loss = 5.7436  \n",
      "\n",
      "Fold: 4  Epoch: 196  Training loss = 2.1586  Validation loss = 5.7435  \n",
      "\n",
      "Fold: 4  Epoch: 197  Training loss = 2.1584  Validation loss = 5.7433  \n",
      "\n",
      "Fold: 4  Epoch: 198  Training loss = 2.1583  Validation loss = 5.7432  \n",
      "\n",
      "Fold: 4  Epoch: 199  Training loss = 2.1582  Validation loss = 5.7430  \n",
      "\n",
      "Fold: 4  Epoch: 200  Training loss = 2.1581  Validation loss = 5.7428  \n",
      "\n",
      "Fold: 4  Epoch: 201  Training loss = 2.1580  Validation loss = 5.7427  \n",
      "\n",
      "Fold: 4  Epoch: 202  Training loss = 2.1579  Validation loss = 5.7425  \n",
      "\n",
      "Fold: 4  Epoch: 203  Training loss = 2.1578  Validation loss = 5.7424  \n",
      "\n",
      "Fold: 4  Epoch: 204  Training loss = 2.1577  Validation loss = 5.7423  \n",
      "\n",
      "Fold: 4  Epoch: 205  Training loss = 2.1576  Validation loss = 5.7421  \n",
      "\n",
      "Fold: 4  Epoch: 206  Training loss = 2.1575  Validation loss = 5.7420  \n",
      "\n",
      "Fold: 4  Epoch: 207  Training loss = 2.1574  Validation loss = 5.7418  \n",
      "\n",
      "Fold: 4  Epoch: 208  Training loss = 2.1573  Validation loss = 5.7417  \n",
      "\n",
      "Fold: 4  Epoch: 209  Training loss = 2.1572  Validation loss = 5.7416  \n",
      "\n",
      "Fold: 4  Epoch: 210  Training loss = 2.1571  Validation loss = 5.7414  \n",
      "\n",
      "Fold: 4  Epoch: 211  Training loss = 2.1570  Validation loss = 5.7413  \n",
      "\n",
      "Fold: 4  Epoch: 212  Training loss = 2.1569  Validation loss = 5.7412  \n",
      "\n",
      "Fold: 4  Epoch: 213  Training loss = 2.1568  Validation loss = 5.7410  \n",
      "\n",
      "Fold: 4  Epoch: 214  Training loss = 2.1567  Validation loss = 5.7409  \n",
      "\n",
      "Fold: 4  Epoch: 215  Training loss = 2.1566  Validation loss = 5.7407  \n",
      "\n",
      "Fold: 4  Epoch: 216  Training loss = 2.1565  Validation loss = 5.7406  \n",
      "\n",
      "Fold: 4  Epoch: 217  Training loss = 2.1564  Validation loss = 5.7405  \n",
      "\n",
      "Fold: 4  Epoch: 218  Training loss = 2.1563  Validation loss = 5.7403  \n",
      "\n",
      "Fold: 4  Epoch: 219  Training loss = 2.1563  Validation loss = 5.7402  \n",
      "\n",
      "Fold: 4  Epoch: 220  Training loss = 2.1561  Validation loss = 5.7400  \n",
      "\n",
      "Fold: 4  Epoch: 221  Training loss = 2.1560  Validation loss = 5.7399  \n",
      "\n",
      "Fold: 4  Epoch: 222  Training loss = 2.1559  Validation loss = 5.7397  \n",
      "\n",
      "Fold: 4  Epoch: 223  Training loss = 2.1558  Validation loss = 5.7395  \n",
      "\n",
      "Fold: 4  Epoch: 224  Training loss = 2.1557  Validation loss = 5.7394  \n",
      "\n",
      "Fold: 4  Epoch: 225  Training loss = 2.1556  Validation loss = 5.7392  \n",
      "\n",
      "Fold: 4  Epoch: 226  Training loss = 2.1555  Validation loss = 5.7391  \n",
      "\n",
      "Fold: 4  Epoch: 227  Training loss = 2.1554  Validation loss = 5.7389  \n",
      "\n",
      "Fold: 4  Epoch: 228  Training loss = 2.1553  Validation loss = 5.7388  \n",
      "\n",
      "Fold: 4  Epoch: 229  Training loss = 2.1551  Validation loss = 5.7386  \n",
      "\n",
      "Fold: 4  Epoch: 230  Training loss = 2.1550  Validation loss = 5.7385  \n",
      "\n",
      "Fold: 4  Epoch: 231  Training loss = 2.1549  Validation loss = 5.7383  \n",
      "\n",
      "Fold: 4  Epoch: 232  Training loss = 2.1548  Validation loss = 5.7381  \n",
      "\n",
      "Fold: 4  Epoch: 233  Training loss = 2.1547  Validation loss = 5.7380  \n",
      "\n",
      "Fold: 4  Epoch: 234  Training loss = 2.1546  Validation loss = 5.7378  \n",
      "\n",
      "Fold: 4  Epoch: 235  Training loss = 2.1545  Validation loss = 5.7377  \n",
      "\n",
      "Fold: 4  Epoch: 236  Training loss = 2.1544  Validation loss = 5.7376  \n",
      "\n",
      "Fold: 4  Epoch: 237  Training loss = 2.1543  Validation loss = 5.7374  \n",
      "\n",
      "Fold: 4  Epoch: 238  Training loss = 2.1542  Validation loss = 5.7373  \n",
      "\n",
      "Fold: 4  Epoch: 239  Training loss = 2.1541  Validation loss = 5.7371  \n",
      "\n",
      "Fold: 4  Epoch: 240  Training loss = 2.1540  Validation loss = 5.7370  \n",
      "\n",
      "Fold: 4  Epoch: 241  Training loss = 2.1539  Validation loss = 5.7368  \n",
      "\n",
      "Fold: 4  Epoch: 242  Training loss = 2.1538  Validation loss = 5.7367  \n",
      "\n",
      "Fold: 4  Epoch: 243  Training loss = 2.1537  Validation loss = 5.7365  \n",
      "\n",
      "Fold: 4  Epoch: 244  Training loss = 2.1536  Validation loss = 5.7364  \n",
      "\n",
      "Fold: 4  Epoch: 245  Training loss = 2.1535  Validation loss = 5.7363  \n",
      "\n",
      "Fold: 4  Epoch: 246  Training loss = 2.1534  Validation loss = 5.7361  \n",
      "\n",
      "Fold: 4  Epoch: 247  Training loss = 2.1533  Validation loss = 5.7359  \n",
      "\n",
      "Fold: 4  Epoch: 248  Training loss = 2.1532  Validation loss = 5.7358  \n",
      "\n",
      "Fold: 4  Epoch: 249  Training loss = 2.1531  Validation loss = 5.7357  \n",
      "\n",
      "Fold: 4  Epoch: 250  Training loss = 2.1530  Validation loss = 5.7355  \n",
      "\n",
      "Fold: 4  Epoch: 251  Training loss = 2.1529  Validation loss = 5.7354  \n",
      "\n",
      "Fold: 4  Epoch: 252  Training loss = 2.1528  Validation loss = 5.7353  \n",
      "\n",
      "Fold: 4  Epoch: 253  Training loss = 2.1527  Validation loss = 5.7352  \n",
      "\n",
      "Fold: 4  Epoch: 254  Training loss = 2.1526  Validation loss = 5.7351  \n",
      "\n",
      "Fold: 4  Epoch: 255  Training loss = 2.1525  Validation loss = 5.7349  \n",
      "\n",
      "Fold: 4  Epoch: 256  Training loss = 2.1524  Validation loss = 5.7348  \n",
      "\n",
      "Fold: 4  Epoch: 257  Training loss = 2.1523  Validation loss = 5.7347  \n",
      "\n",
      "Fold: 4  Epoch: 258  Training loss = 2.1522  Validation loss = 5.7345  \n",
      "\n",
      "Fold: 4  Epoch: 259  Training loss = 2.1521  Validation loss = 5.7344  \n",
      "\n",
      "Fold: 4  Epoch: 260  Training loss = 2.1520  Validation loss = 5.7343  \n",
      "\n",
      "Fold: 4  Epoch: 261  Training loss = 2.1519  Validation loss = 5.7341  \n",
      "\n",
      "Fold: 4  Epoch: 262  Training loss = 2.1518  Validation loss = 5.7340  \n",
      "\n",
      "Fold: 4  Epoch: 263  Training loss = 2.1517  Validation loss = 5.7338  \n",
      "\n",
      "Fold: 4  Epoch: 264  Training loss = 2.1517  Validation loss = 5.7337  \n",
      "\n",
      "Fold: 4  Epoch: 265  Training loss = 2.1515  Validation loss = 5.7336  \n",
      "\n",
      "Fold: 4  Epoch: 266  Training loss = 2.1514  Validation loss = 5.7334  \n",
      "\n",
      "Fold: 4  Epoch: 267  Training loss = 2.1514  Validation loss = 5.7333  \n",
      "\n",
      "Fold: 4  Epoch: 268  Training loss = 2.1512  Validation loss = 5.7331  \n",
      "\n",
      "Fold: 4  Epoch: 269  Training loss = 2.1511  Validation loss = 5.7330  \n",
      "\n",
      "Fold: 4  Epoch: 270  Training loss = 2.1511  Validation loss = 5.7329  \n",
      "\n",
      "Fold: 4  Epoch: 271  Training loss = 2.1509  Validation loss = 5.7327  \n",
      "\n",
      "Fold: 4  Epoch: 272  Training loss = 2.1508  Validation loss = 5.7326  \n",
      "\n",
      "Fold: 4  Epoch: 273  Training loss = 2.1508  Validation loss = 5.7325  \n",
      "\n",
      "Fold: 4  Epoch: 274  Training loss = 2.1507  Validation loss = 5.7324  \n",
      "\n",
      "Fold: 4  Epoch: 275  Training loss = 2.1506  Validation loss = 5.7322  \n",
      "\n",
      "Fold: 4  Epoch: 276  Training loss = 2.1505  Validation loss = 5.7321  \n",
      "\n",
      "Fold: 4  Epoch: 277  Training loss = 2.1503  Validation loss = 5.7319  \n",
      "\n",
      "Fold: 4  Epoch: 278  Training loss = 2.1502  Validation loss = 5.7317  \n",
      "\n",
      "Fold: 4  Epoch: 279  Training loss = 2.1501  Validation loss = 5.7316  \n",
      "\n",
      "Fold: 4  Epoch: 280  Training loss = 2.1500  Validation loss = 5.7314  \n",
      "\n",
      "Fold: 4  Epoch: 281  Training loss = 2.1499  Validation loss = 5.7313  \n",
      "\n",
      "Fold: 4  Epoch: 282  Training loss = 2.1498  Validation loss = 5.7312  \n",
      "\n",
      "Fold: 4  Epoch: 283  Training loss = 2.1498  Validation loss = 5.7311  \n",
      "\n",
      "Fold: 4  Epoch: 284  Training loss = 2.1497  Validation loss = 5.7309  \n",
      "\n",
      "Fold: 4  Epoch: 285  Training loss = 2.1496  Validation loss = 5.7308  \n",
      "\n",
      "Fold: 4  Epoch: 286  Training loss = 2.1495  Validation loss = 5.7306  \n",
      "\n",
      "Fold: 4  Epoch: 287  Training loss = 2.1493  Validation loss = 5.7305  \n",
      "\n",
      "Fold: 4  Epoch: 288  Training loss = 2.1493  Validation loss = 5.7304  \n",
      "\n",
      "Fold: 4  Epoch: 289  Training loss = 2.1492  Validation loss = 5.7303  \n",
      "\n",
      "Fold: 4  Epoch: 290  Training loss = 2.1491  Validation loss = 5.7301  \n",
      "\n",
      "Fold: 4  Epoch: 291  Training loss = 2.1490  Validation loss = 5.7300  \n",
      "\n",
      "Fold: 4  Epoch: 292  Training loss = 2.1489  Validation loss = 5.7298  \n",
      "\n",
      "Fold: 4  Epoch: 293  Training loss = 2.1488  Validation loss = 5.7297  \n",
      "\n",
      "Fold: 4  Epoch: 294  Training loss = 2.1487  Validation loss = 5.7295  \n",
      "\n",
      "Fold: 4  Epoch: 295  Training loss = 2.1486  Validation loss = 5.7293  \n",
      "\n",
      "Fold: 4  Epoch: 296  Training loss = 2.1484  Validation loss = 5.7292  \n",
      "\n",
      "Fold: 4  Epoch: 297  Training loss = 2.1483  Validation loss = 5.7290  \n",
      "\n",
      "Fold: 4  Epoch: 298  Training loss = 2.1482  Validation loss = 5.7288  \n",
      "\n",
      "Fold: 4  Epoch: 299  Training loss = 2.1481  Validation loss = 5.7287  \n",
      "\n",
      "Fold: 4  Epoch: 300  Training loss = 2.1480  Validation loss = 5.7286  \n",
      "\n",
      "Fold: 4  Epoch: 301  Training loss = 2.1480  Validation loss = 5.7285  \n",
      "\n",
      "Fold: 4  Epoch: 302  Training loss = 2.1479  Validation loss = 5.7283  \n",
      "\n",
      "Fold: 4  Epoch: 303  Training loss = 2.1478  Validation loss = 5.7281  \n",
      "\n",
      "Fold: 4  Epoch: 304  Training loss = 2.1476  Validation loss = 5.7280  \n",
      "\n",
      "Fold: 4  Epoch: 305  Training loss = 2.1475  Validation loss = 5.7278  \n",
      "\n",
      "Fold: 4  Epoch: 306  Training loss = 2.1474  Validation loss = 5.7277  \n",
      "\n",
      "Fold: 4  Epoch: 307  Training loss = 2.1473  Validation loss = 5.7275  \n",
      "\n",
      "Fold: 4  Epoch: 308  Training loss = 2.1472  Validation loss = 5.7274  \n",
      "\n",
      "Fold: 4  Epoch: 309  Training loss = 2.1471  Validation loss = 5.7273  \n",
      "\n",
      "Fold: 4  Epoch: 310  Training loss = 2.1470  Validation loss = 5.7271  \n",
      "\n",
      "Fold: 4  Epoch: 311  Training loss = 2.1469  Validation loss = 5.7270  \n",
      "\n",
      "Fold: 4  Epoch: 312  Training loss = 2.1468  Validation loss = 5.7269  \n",
      "\n",
      "Fold: 4  Epoch: 313  Training loss = 2.1467  Validation loss = 5.7267  \n",
      "\n",
      "Fold: 4  Epoch: 314  Training loss = 2.1466  Validation loss = 5.7266  \n",
      "\n",
      "Fold: 4  Epoch: 315  Training loss = 2.1465  Validation loss = 5.7265  \n",
      "\n",
      "Fold: 4  Epoch: 316  Training loss = 2.1464  Validation loss = 5.7263  \n",
      "\n",
      "Fold: 4  Epoch: 317  Training loss = 2.1463  Validation loss = 5.7261  \n",
      "\n",
      "Fold: 4  Epoch: 318  Training loss = 2.1462  Validation loss = 5.7260  \n",
      "\n",
      "Fold: 4  Epoch: 319  Training loss = 2.1461  Validation loss = 5.7258  \n",
      "\n",
      "Fold: 4  Epoch: 320  Training loss = 2.1460  Validation loss = 5.7257  \n",
      "\n",
      "Fold: 4  Epoch: 321  Training loss = 2.1459  Validation loss = 5.7255  \n",
      "\n",
      "Fold: 4  Epoch: 322  Training loss = 2.1458  Validation loss = 5.7254  \n",
      "\n",
      "Fold: 4  Epoch: 323  Training loss = 2.1457  Validation loss = 5.7253  \n",
      "\n",
      "Fold: 4  Epoch: 324  Training loss = 2.1456  Validation loss = 5.7251  \n",
      "\n",
      "Fold: 4  Epoch: 325  Training loss = 2.1456  Validation loss = 5.7250  \n",
      "\n",
      "Fold: 4  Epoch: 326  Training loss = 2.1455  Validation loss = 5.7248  \n",
      "\n",
      "Fold: 4  Epoch: 327  Training loss = 2.1454  Validation loss = 5.7247  \n",
      "\n",
      "Fold: 4  Epoch: 328  Training loss = 2.1453  Validation loss = 5.7246  \n",
      "\n",
      "Fold: 4  Epoch: 329  Training loss = 2.1452  Validation loss = 5.7244  \n",
      "\n",
      "Fold: 4  Epoch: 330  Training loss = 2.1451  Validation loss = 5.7243  \n",
      "\n",
      "Fold: 4  Epoch: 331  Training loss = 2.1450  Validation loss = 5.7242  \n",
      "\n",
      "Fold: 4  Epoch: 332  Training loss = 2.1449  Validation loss = 5.7240  \n",
      "\n",
      "Fold: 4  Epoch: 333  Training loss = 2.1448  Validation loss = 5.7239  \n",
      "\n",
      "Fold: 4  Epoch: 334  Training loss = 2.1447  Validation loss = 5.7238  \n",
      "\n",
      "Fold: 4  Epoch: 335  Training loss = 2.1446  Validation loss = 5.7237  \n",
      "\n",
      "Fold: 4  Epoch: 336  Training loss = 2.1445  Validation loss = 5.7235  \n",
      "\n",
      "Fold: 4  Epoch: 337  Training loss = 2.1444  Validation loss = 5.7233  \n",
      "\n",
      "Fold: 4  Epoch: 338  Training loss = 2.1443  Validation loss = 5.7232  \n",
      "\n",
      "Fold: 4  Epoch: 339  Training loss = 2.1442  Validation loss = 5.7230  \n",
      "\n",
      "Fold: 4  Epoch: 340  Training loss = 2.1441  Validation loss = 5.7229  \n",
      "\n",
      "Fold: 4  Epoch: 341  Training loss = 2.1440  Validation loss = 5.7228  \n",
      "\n",
      "Fold: 4  Epoch: 342  Training loss = 2.1439  Validation loss = 5.7226  \n",
      "\n",
      "Fold: 4  Epoch: 343  Training loss = 2.1438  Validation loss = 5.7224  \n",
      "\n",
      "Fold: 4  Epoch: 344  Training loss = 2.1437  Validation loss = 5.7223  \n",
      "\n",
      "Fold: 4  Epoch: 345  Training loss = 2.1436  Validation loss = 5.7221  \n",
      "\n",
      "Fold: 4  Epoch: 346  Training loss = 2.1435  Validation loss = 5.7220  \n",
      "\n",
      "Fold: 4  Epoch: 347  Training loss = 2.1433  Validation loss = 5.7218  \n",
      "\n",
      "Fold: 4  Epoch: 348  Training loss = 2.1432  Validation loss = 5.7216  \n",
      "\n",
      "Fold: 4  Epoch: 349  Training loss = 2.1431  Validation loss = 5.7215  \n",
      "\n",
      "Fold: 4  Epoch: 350  Training loss = 2.1430  Validation loss = 5.7213  \n",
      "\n",
      "Fold: 4  Epoch: 351  Training loss = 2.1429  Validation loss = 5.7212  \n",
      "\n",
      "Fold: 4  Epoch: 352  Training loss = 2.1428  Validation loss = 5.7210  \n",
      "\n",
      "Fold: 4  Epoch: 353  Training loss = 2.1427  Validation loss = 5.7209  \n",
      "\n",
      "Fold: 4  Epoch: 354  Training loss = 2.1426  Validation loss = 5.7207  \n",
      "\n",
      "Fold: 4  Epoch: 355  Training loss = 2.1425  Validation loss = 5.7205  \n",
      "\n",
      "Fold: 4  Epoch: 356  Training loss = 2.1424  Validation loss = 5.7204  \n",
      "\n",
      "Fold: 4  Epoch: 357  Training loss = 2.1423  Validation loss = 5.7203  \n",
      "\n",
      "Fold: 4  Epoch: 358  Training loss = 2.1422  Validation loss = 5.7202  \n",
      "\n",
      "Fold: 4  Epoch: 359  Training loss = 2.1421  Validation loss = 5.7200  \n",
      "\n",
      "Fold: 4  Epoch: 360  Training loss = 2.1420  Validation loss = 5.7199  \n",
      "\n",
      "Fold: 4  Epoch: 361  Training loss = 2.1420  Validation loss = 5.7198  \n",
      "\n",
      "Fold: 4  Epoch: 362  Training loss = 2.1418  Validation loss = 5.7196  \n",
      "\n",
      "Fold: 4  Epoch: 363  Training loss = 2.1418  Validation loss = 5.7195  \n",
      "\n",
      "Fold: 4  Epoch: 364  Training loss = 2.1417  Validation loss = 5.7193  \n",
      "\n",
      "Fold: 4  Epoch: 365  Training loss = 2.1416  Validation loss = 5.7192  \n",
      "\n",
      "Fold: 4  Epoch: 366  Training loss = 2.1414  Validation loss = 5.7190  \n",
      "\n",
      "Fold: 4  Epoch: 367  Training loss = 2.1413  Validation loss = 5.7189  \n",
      "\n",
      "Fold: 4  Epoch: 368  Training loss = 2.1412  Validation loss = 5.7187  \n",
      "\n",
      "Fold: 4  Epoch: 369  Training loss = 2.1411  Validation loss = 5.7185  \n",
      "\n",
      "Fold: 4  Epoch: 370  Training loss = 2.1410  Validation loss = 5.7184  \n",
      "\n",
      "Fold: 4  Epoch: 371  Training loss = 2.1410  Validation loss = 5.7183  \n",
      "\n",
      "Fold: 4  Epoch: 372  Training loss = 2.1409  Validation loss = 5.7182  \n",
      "\n",
      "Fold: 4  Epoch: 373  Training loss = 2.1408  Validation loss = 5.7180  \n",
      "\n",
      "Fold: 4  Epoch: 374  Training loss = 2.1407  Validation loss = 5.7178  \n",
      "\n",
      "Fold: 4  Epoch: 375  Training loss = 2.1406  Validation loss = 5.7177  \n",
      "\n",
      "Fold: 4  Epoch: 376  Training loss = 2.1405  Validation loss = 5.7175  \n",
      "\n",
      "Fold: 4  Epoch: 377  Training loss = 2.1404  Validation loss = 5.7174  \n",
      "\n",
      "Fold: 4  Epoch: 378  Training loss = 2.1403  Validation loss = 5.7172  \n",
      "\n",
      "Fold: 4  Epoch: 379  Training loss = 2.1401  Validation loss = 5.7171  \n",
      "\n",
      "Fold: 4  Epoch: 380  Training loss = 2.1400  Validation loss = 5.7169  \n",
      "\n",
      "Fold: 4  Epoch: 381  Training loss = 2.1399  Validation loss = 5.7168  \n",
      "\n",
      "Fold: 4  Epoch: 382  Training loss = 2.1398  Validation loss = 5.7166  \n",
      "\n",
      "Fold: 4  Epoch: 383  Training loss = 2.1397  Validation loss = 5.7164  \n",
      "\n",
      "Fold: 4  Epoch: 384  Training loss = 2.1396  Validation loss = 5.7163  \n",
      "\n",
      "Fold: 4  Epoch: 385  Training loss = 2.1395  Validation loss = 5.7161  \n",
      "\n",
      "Fold: 4  Epoch: 386  Training loss = 2.1394  Validation loss = 5.7160  \n",
      "\n",
      "Fold: 4  Epoch: 387  Training loss = 2.1393  Validation loss = 5.7159  \n",
      "\n",
      "Fold: 4  Epoch: 388  Training loss = 2.1392  Validation loss = 5.7157  \n",
      "\n",
      "Fold: 4  Epoch: 389  Training loss = 2.1391  Validation loss = 5.7156  \n",
      "\n",
      "Fold: 4  Epoch: 390  Training loss = 2.1390  Validation loss = 5.7154  \n",
      "\n",
      "Fold: 4  Epoch: 391  Training loss = 2.1389  Validation loss = 5.7153  \n",
      "\n",
      "Fold: 4  Epoch: 392  Training loss = 2.1388  Validation loss = 5.7152  \n",
      "\n",
      "Fold: 4  Epoch: 393  Training loss = 2.1387  Validation loss = 5.7150  \n",
      "\n",
      "Fold: 4  Epoch: 394  Training loss = 2.1386  Validation loss = 5.7149  \n",
      "\n",
      "Fold: 4  Epoch: 395  Training loss = 2.1385  Validation loss = 5.7147  \n",
      "\n",
      "Fold: 4  Epoch: 396  Training loss = 2.1384  Validation loss = 5.7146  \n",
      "\n",
      "Fold: 4  Epoch: 397  Training loss = 2.1383  Validation loss = 5.7144  \n",
      "\n",
      "Fold: 4  Epoch: 398  Training loss = 2.1382  Validation loss = 5.7143  \n",
      "\n",
      "Fold: 4  Epoch: 399  Training loss = 2.1381  Validation loss = 5.7141  \n",
      "\n",
      "Fold: 4  Epoch: 400  Training loss = 2.1380  Validation loss = 5.7140  \n",
      "\n",
      "Fold: 4  Epoch: 401  Training loss = 2.1379  Validation loss = 5.7138  \n",
      "\n",
      "Fold: 4  Epoch: 402  Training loss = 2.1378  Validation loss = 5.7137  \n",
      "\n",
      "Fold: 4  Epoch: 403  Training loss = 2.1377  Validation loss = 5.7135  \n",
      "\n",
      "Fold: 4  Epoch: 404  Training loss = 2.1376  Validation loss = 5.7134  \n",
      "\n",
      "Fold: 4  Epoch: 405  Training loss = 2.1375  Validation loss = 5.7132  \n",
      "\n",
      "Fold: 4  Epoch: 406  Training loss = 2.1374  Validation loss = 5.7131  \n",
      "\n",
      "Fold: 4  Epoch: 407  Training loss = 2.1373  Validation loss = 5.7129  \n",
      "\n",
      "Fold: 4  Epoch: 408  Training loss = 2.1372  Validation loss = 5.7128  \n",
      "\n",
      "Fold: 4  Epoch: 409  Training loss = 2.1371  Validation loss = 5.7127  \n",
      "\n",
      "Fold: 4  Epoch: 410  Training loss = 2.1370  Validation loss = 5.7125  \n",
      "\n",
      "Fold: 4  Epoch: 411  Training loss = 2.1369  Validation loss = 5.7123  \n",
      "\n",
      "Fold: 4  Epoch: 412  Training loss = 2.1368  Validation loss = 5.7122  \n",
      "\n",
      "Fold: 4  Epoch: 413  Training loss = 2.1367  Validation loss = 5.7121  \n",
      "\n",
      "Fold: 4  Epoch: 414  Training loss = 2.1366  Validation loss = 5.7119  \n",
      "\n",
      "Fold: 4  Epoch: 415  Training loss = 2.1365  Validation loss = 5.7118  \n",
      "\n",
      "Fold: 4  Epoch: 416  Training loss = 2.1364  Validation loss = 5.7116  \n",
      "\n",
      "Fold: 4  Epoch: 417  Training loss = 2.1363  Validation loss = 5.7115  \n",
      "\n",
      "Fold: 4  Epoch: 418  Training loss = 2.1362  Validation loss = 5.7113  \n",
      "\n",
      "Fold: 4  Epoch: 419  Training loss = 2.1361  Validation loss = 5.7112  \n",
      "\n",
      "Fold: 4  Epoch: 420  Training loss = 2.1360  Validation loss = 5.7110  \n",
      "\n",
      "Fold: 4  Epoch: 421  Training loss = 2.1359  Validation loss = 5.7108  \n",
      "\n",
      "Fold: 4  Epoch: 422  Training loss = 2.1358  Validation loss = 5.7107  \n",
      "\n",
      "Fold: 4  Epoch: 423  Training loss = 2.1357  Validation loss = 5.7106  \n",
      "\n",
      "Fold: 4  Epoch: 424  Training loss = 2.1356  Validation loss = 5.7104  \n",
      "\n",
      "Fold: 4  Epoch: 425  Training loss = 2.1355  Validation loss = 5.7103  \n",
      "\n",
      "Fold: 4  Epoch: 426  Training loss = 2.1354  Validation loss = 5.7101  \n",
      "\n",
      "Fold: 4  Epoch: 427  Training loss = 2.1353  Validation loss = 5.7099  \n",
      "\n",
      "Fold: 4  Epoch: 428  Training loss = 2.1352  Validation loss = 5.7097  \n",
      "\n",
      "Fold: 4  Epoch: 429  Training loss = 2.1351  Validation loss = 5.7096  \n",
      "\n",
      "Fold: 4  Epoch: 430  Training loss = 2.1350  Validation loss = 5.7095  \n",
      "\n",
      "Fold: 4  Epoch: 431  Training loss = 2.1349  Validation loss = 5.7093  \n",
      "\n",
      "Fold: 4  Epoch: 432  Training loss = 2.1348  Validation loss = 5.7091  \n",
      "\n",
      "Fold: 4  Epoch: 433  Training loss = 2.1347  Validation loss = 5.7090  \n",
      "\n",
      "Fold: 4  Epoch: 434  Training loss = 2.1346  Validation loss = 5.7088  \n",
      "\n",
      "Fold: 4  Epoch: 435  Training loss = 2.1345  Validation loss = 5.7087  \n",
      "\n",
      "Fold: 4  Epoch: 436  Training loss = 2.1344  Validation loss = 5.7086  \n",
      "\n",
      "Fold: 4  Epoch: 437  Training loss = 2.1343  Validation loss = 5.7084  \n",
      "\n",
      "Fold: 4  Epoch: 438  Training loss = 2.1342  Validation loss = 5.7083  \n",
      "\n",
      "Fold: 4  Epoch: 439  Training loss = 2.1341  Validation loss = 5.7081  \n",
      "\n",
      "Fold: 4  Epoch: 440  Training loss = 2.1340  Validation loss = 5.7080  \n",
      "\n",
      "Fold: 4  Epoch: 441  Training loss = 2.1339  Validation loss = 5.7079  \n",
      "\n",
      "Fold: 4  Epoch: 442  Training loss = 2.1338  Validation loss = 5.7077  \n",
      "\n",
      "Fold: 4  Epoch: 443  Training loss = 2.1337  Validation loss = 5.7076  \n",
      "\n",
      "Fold: 4  Epoch: 444  Training loss = 2.1336  Validation loss = 5.7075  \n",
      "\n",
      "Fold: 4  Epoch: 445  Training loss = 2.1335  Validation loss = 5.7073  \n",
      "\n",
      "Fold: 4  Epoch: 446  Training loss = 2.1334  Validation loss = 5.7072  \n",
      "\n",
      "Fold: 4  Epoch: 447  Training loss = 2.1333  Validation loss = 5.7070  \n",
      "\n",
      "Fold: 4  Epoch: 448  Training loss = 2.1332  Validation loss = 5.7068  \n",
      "\n",
      "Fold: 4  Epoch: 449  Training loss = 2.1331  Validation loss = 5.7067  \n",
      "\n",
      "Fold: 4  Epoch: 450  Training loss = 2.1330  Validation loss = 5.7065  \n",
      "\n",
      "Fold: 4  Epoch: 451  Training loss = 2.1329  Validation loss = 5.7064  \n",
      "\n",
      "Fold: 4  Epoch: 452  Training loss = 2.1328  Validation loss = 5.7062  \n",
      "\n",
      "Fold: 4  Epoch: 453  Training loss = 2.1327  Validation loss = 5.7061  \n",
      "\n",
      "Fold: 4  Epoch: 454  Training loss = 2.1326  Validation loss = 5.7059  \n",
      "\n",
      "Fold: 4  Epoch: 455  Training loss = 2.1325  Validation loss = 5.7058  \n",
      "\n",
      "Fold: 4  Epoch: 456  Training loss = 2.1324  Validation loss = 5.7057  \n",
      "\n",
      "Fold: 4  Epoch: 457  Training loss = 2.1323  Validation loss = 5.7056  \n",
      "\n",
      "Fold: 4  Epoch: 458  Training loss = 2.1323  Validation loss = 5.7055  \n",
      "\n",
      "Fold: 4  Epoch: 459  Training loss = 2.1322  Validation loss = 5.7054  \n",
      "\n",
      "Fold: 4  Epoch: 460  Training loss = 2.1321  Validation loss = 5.7052  \n",
      "\n",
      "Fold: 4  Epoch: 461  Training loss = 2.1320  Validation loss = 5.7051  \n",
      "\n",
      "Fold: 4  Epoch: 462  Training loss = 2.1319  Validation loss = 5.7049  \n",
      "\n",
      "Fold: 4  Epoch: 463  Training loss = 2.1318  Validation loss = 5.7048  \n",
      "\n",
      "Fold: 4  Epoch: 464  Training loss = 2.1317  Validation loss = 5.7047  \n",
      "\n",
      "Fold: 4  Epoch: 465  Training loss = 2.1316  Validation loss = 5.7045  \n",
      "\n",
      "Fold: 4  Epoch: 466  Training loss = 2.1315  Validation loss = 5.7044  \n",
      "\n",
      "Fold: 4  Epoch: 467  Training loss = 2.1314  Validation loss = 5.7042  \n",
      "\n",
      "Fold: 4  Epoch: 468  Training loss = 2.1313  Validation loss = 5.7041  \n",
      "\n",
      "Fold: 4  Epoch: 469  Training loss = 2.1312  Validation loss = 5.7039  \n",
      "\n",
      "Fold: 4  Epoch: 470  Training loss = 2.1311  Validation loss = 5.7038  \n",
      "\n",
      "Fold: 4  Epoch: 471  Training loss = 2.1310  Validation loss = 5.7036  \n",
      "\n",
      "Fold: 4  Epoch: 472  Training loss = 2.1309  Validation loss = 5.7035  \n",
      "\n",
      "Fold: 4  Epoch: 473  Training loss = 2.1308  Validation loss = 5.7034  \n",
      "\n",
      "Fold: 4  Epoch: 474  Training loss = 2.1307  Validation loss = 5.7033  \n",
      "\n",
      "Fold: 4  Epoch: 475  Training loss = 2.1306  Validation loss = 5.7032  \n",
      "\n",
      "Fold: 4  Epoch: 476  Training loss = 2.1305  Validation loss = 5.7030  \n",
      "\n",
      "Fold: 4  Epoch: 477  Training loss = 2.1304  Validation loss = 5.7028  \n",
      "\n",
      "Fold: 4  Epoch: 478  Training loss = 2.1303  Validation loss = 5.7027  \n",
      "\n",
      "Fold: 4  Epoch: 479  Training loss = 2.1302  Validation loss = 5.7025  \n",
      "\n",
      "Fold: 4  Epoch: 480  Training loss = 2.1301  Validation loss = 5.7024  \n",
      "\n",
      "Fold: 4  Epoch: 481  Training loss = 2.1300  Validation loss = 5.7022  \n",
      "\n",
      "Fold: 4  Epoch: 482  Training loss = 2.1299  Validation loss = 5.7021  \n",
      "\n",
      "Fold: 4  Epoch: 483  Training loss = 2.1298  Validation loss = 5.7020  \n",
      "\n",
      "Fold: 4  Epoch: 484  Training loss = 2.1297  Validation loss = 5.7018  \n",
      "\n",
      "Fold: 4  Epoch: 485  Training loss = 2.1296  Validation loss = 5.7017  \n",
      "\n",
      "Fold: 4  Epoch: 486  Training loss = 2.1295  Validation loss = 5.7016  \n",
      "\n",
      "Fold: 4  Epoch: 487  Training loss = 2.1294  Validation loss = 5.7014  \n",
      "\n",
      "Fold: 4  Epoch: 488  Training loss = 2.1293  Validation loss = 5.7013  \n",
      "\n",
      "Fold: 4  Epoch: 489  Training loss = 2.1292  Validation loss = 5.7011  \n",
      "\n",
      "Fold: 4  Epoch: 490  Training loss = 2.1291  Validation loss = 5.7010  \n",
      "\n",
      "Fold: 4  Epoch: 491  Training loss = 2.1290  Validation loss = 5.7008  \n",
      "\n",
      "Fold: 4  Epoch: 492  Training loss = 2.1289  Validation loss = 5.7007  \n",
      "\n",
      "Fold: 4  Epoch: 493  Training loss = 2.1288  Validation loss = 5.7005  \n",
      "\n",
      "Fold: 4  Epoch: 494  Training loss = 2.1287  Validation loss = 5.7004  \n",
      "\n",
      "Fold: 4  Epoch: 495  Training loss = 2.1286  Validation loss = 5.7002  \n",
      "\n",
      "Fold: 4  Epoch: 496  Training loss = 2.1285  Validation loss = 5.7001  \n",
      "\n",
      "Fold: 4  Epoch: 497  Training loss = 2.1284  Validation loss = 5.7000  \n",
      "\n",
      "Fold: 4  Epoch: 498  Training loss = 2.1284  Validation loss = 5.6999  \n",
      "\n",
      "Fold: 4  Epoch: 499  Training loss = 2.1282  Validation loss = 5.6997  \n",
      "\n",
      "Fold: 4  Epoch: 500  Training loss = 2.1281  Validation loss = 5.6995  \n",
      "\n",
      "Check model:  Fold: 4  Optimal epoch: 500  \n",
      "\n",
      "Fold: 5  Epoch: 1  Training loss = 2.5272  Validation loss = 5.5274  \n",
      "\n",
      "Fold: 5  Epoch: 2  Training loss = 2.5271  Validation loss = 5.5272  \n",
      "\n",
      "Fold: 5  Epoch: 3  Training loss = 2.5269  Validation loss = 5.5270  \n",
      "\n",
      "Fold: 5  Epoch: 4  Training loss = 2.5268  Validation loss = 5.5269  \n",
      "\n",
      "Fold: 5  Epoch: 5  Training loss = 2.5267  Validation loss = 5.5267  \n",
      "\n",
      "Fold: 5  Epoch: 6  Training loss = 2.5266  Validation loss = 5.5265  \n",
      "\n",
      "Fold: 5  Epoch: 7  Training loss = 2.5265  Validation loss = 5.5264  \n",
      "\n",
      "Fold: 5  Epoch: 8  Training loss = 2.5264  Validation loss = 5.5263  \n",
      "\n",
      "Fold: 5  Epoch: 9  Training loss = 2.5263  Validation loss = 5.5261  \n",
      "\n",
      "Fold: 5  Epoch: 10  Training loss = 2.5261  Validation loss = 5.5259  \n",
      "\n",
      "Fold: 5  Epoch: 11  Training loss = 2.5260  Validation loss = 5.5258  \n",
      "\n",
      "Fold: 5  Epoch: 12  Training loss = 2.5259  Validation loss = 5.5256  \n",
      "\n",
      "Fold: 5  Epoch: 13  Training loss = 2.5258  Validation loss = 5.5254  \n",
      "\n",
      "Fold: 5  Epoch: 14  Training loss = 2.5256  Validation loss = 5.5252  \n",
      "\n",
      "Fold: 5  Epoch: 15  Training loss = 2.5255  Validation loss = 5.5250  \n",
      "\n",
      "Fold: 5  Epoch: 16  Training loss = 2.5254  Validation loss = 5.5248  \n",
      "\n",
      "Fold: 5  Epoch: 17  Training loss = 2.5252  Validation loss = 5.5246  \n",
      "\n",
      "Fold: 5  Epoch: 18  Training loss = 2.5251  Validation loss = 5.5244  \n",
      "\n",
      "Fold: 5  Epoch: 19  Training loss = 2.5250  Validation loss = 5.5242  \n",
      "\n",
      "Fold: 5  Epoch: 20  Training loss = 2.5249  Validation loss = 5.5240  \n",
      "\n",
      "Fold: 5  Epoch: 21  Training loss = 2.5247  Validation loss = 5.5239  \n",
      "\n",
      "Fold: 5  Epoch: 22  Training loss = 2.5246  Validation loss = 5.5237  \n",
      "\n",
      "Fold: 5  Epoch: 23  Training loss = 2.5245  Validation loss = 5.5236  \n",
      "\n",
      "Fold: 5  Epoch: 24  Training loss = 2.5244  Validation loss = 5.5234  \n",
      "\n",
      "Fold: 5  Epoch: 25  Training loss = 2.5243  Validation loss = 5.5232  \n",
      "\n",
      "Fold: 5  Epoch: 26  Training loss = 2.5241  Validation loss = 5.5230  \n",
      "\n",
      "Fold: 5  Epoch: 27  Training loss = 2.5240  Validation loss = 5.5228  \n",
      "\n",
      "Fold: 5  Epoch: 28  Training loss = 2.5238  Validation loss = 5.5226  \n",
      "\n",
      "Fold: 5  Epoch: 29  Training loss = 2.5237  Validation loss = 5.5224  \n",
      "\n",
      "Fold: 5  Epoch: 30  Training loss = 2.5236  Validation loss = 5.5223  \n",
      "\n",
      "Fold: 5  Epoch: 31  Training loss = 2.5235  Validation loss = 5.5220  \n",
      "\n",
      "Fold: 5  Epoch: 32  Training loss = 2.5233  Validation loss = 5.5219  \n",
      "\n",
      "Fold: 5  Epoch: 33  Training loss = 2.5232  Validation loss = 5.5216  \n",
      "\n",
      "Fold: 5  Epoch: 34  Training loss = 2.5231  Validation loss = 5.5214  \n",
      "\n",
      "Fold: 5  Epoch: 35  Training loss = 2.5229  Validation loss = 5.5213  \n",
      "\n",
      "Fold: 5  Epoch: 36  Training loss = 2.5228  Validation loss = 5.5211  \n",
      "\n",
      "Fold: 5  Epoch: 37  Training loss = 2.5227  Validation loss = 5.5209  \n",
      "\n",
      "Fold: 5  Epoch: 38  Training loss = 2.5226  Validation loss = 5.5207  \n",
      "\n",
      "Fold: 5  Epoch: 39  Training loss = 2.5224  Validation loss = 5.5205  \n",
      "\n",
      "Fold: 5  Epoch: 40  Training loss = 2.5223  Validation loss = 5.5203  \n",
      "\n",
      "Fold: 5  Epoch: 41  Training loss = 2.5222  Validation loss = 5.5201  \n",
      "\n",
      "Fold: 5  Epoch: 42  Training loss = 2.5221  Validation loss = 5.5200  \n",
      "\n",
      "Fold: 5  Epoch: 43  Training loss = 2.5220  Validation loss = 5.5199  \n",
      "\n",
      "Fold: 5  Epoch: 44  Training loss = 2.5218  Validation loss = 5.5197  \n",
      "\n",
      "Fold: 5  Epoch: 45  Training loss = 2.5217  Validation loss = 5.5195  \n",
      "\n",
      "Fold: 5  Epoch: 46  Training loss = 2.5216  Validation loss = 5.5194  \n",
      "\n",
      "Fold: 5  Epoch: 47  Training loss = 2.5215  Validation loss = 5.5192  \n",
      "\n",
      "Fold: 5  Epoch: 48  Training loss = 2.5214  Validation loss = 5.5191  \n",
      "\n",
      "Fold: 5  Epoch: 49  Training loss = 2.5212  Validation loss = 5.5189  \n",
      "\n",
      "Fold: 5  Epoch: 50  Training loss = 2.5211  Validation loss = 5.5187  \n",
      "\n",
      "Fold: 5  Epoch: 51  Training loss = 2.5210  Validation loss = 5.5185  \n",
      "\n",
      "Fold: 5  Epoch: 52  Training loss = 2.5209  Validation loss = 5.5183  \n",
      "\n",
      "Fold: 5  Epoch: 53  Training loss = 2.5208  Validation loss = 5.5182  \n",
      "\n",
      "Fold: 5  Epoch: 54  Training loss = 2.5206  Validation loss = 5.5180  \n",
      "\n",
      "Fold: 5  Epoch: 55  Training loss = 2.5205  Validation loss = 5.5178  \n",
      "\n",
      "Fold: 5  Epoch: 56  Training loss = 2.5204  Validation loss = 5.5176  \n",
      "\n",
      "Fold: 5  Epoch: 57  Training loss = 2.5203  Validation loss = 5.5174  \n",
      "\n",
      "Fold: 5  Epoch: 58  Training loss = 2.5201  Validation loss = 5.5172  \n",
      "\n",
      "Fold: 5  Epoch: 59  Training loss = 2.5199  Validation loss = 5.5170  \n",
      "\n",
      "Fold: 5  Epoch: 60  Training loss = 2.5198  Validation loss = 5.5167  \n",
      "\n",
      "Fold: 5  Epoch: 61  Training loss = 2.5197  Validation loss = 5.5166  \n",
      "\n",
      "Fold: 5  Epoch: 62  Training loss = 2.5196  Validation loss = 5.5164  \n",
      "\n",
      "Fold: 5  Epoch: 63  Training loss = 2.5194  Validation loss = 5.5161  \n",
      "\n",
      "Fold: 5  Epoch: 64  Training loss = 2.5193  Validation loss = 5.5159  \n",
      "\n",
      "Fold: 5  Epoch: 65  Training loss = 2.5191  Validation loss = 5.5157  \n",
      "\n",
      "Fold: 5  Epoch: 66  Training loss = 2.5190  Validation loss = 5.5156  \n",
      "\n",
      "Fold: 5  Epoch: 67  Training loss = 2.5189  Validation loss = 5.5154  \n",
      "\n",
      "Fold: 5  Epoch: 68  Training loss = 2.5187  Validation loss = 5.5152  \n",
      "\n",
      "Fold: 5  Epoch: 69  Training loss = 2.5186  Validation loss = 5.5149  \n",
      "\n",
      "Fold: 5  Epoch: 70  Training loss = 2.5184  Validation loss = 5.5146  \n",
      "\n",
      "Fold: 5  Epoch: 71  Training loss = 2.5182  Validation loss = 5.5144  \n",
      "\n",
      "Fold: 5  Epoch: 72  Training loss = 2.5181  Validation loss = 5.5142  \n",
      "\n",
      "Fold: 5  Epoch: 73  Training loss = 2.5180  Validation loss = 5.5140  \n",
      "\n",
      "Fold: 5  Epoch: 74  Training loss = 2.5179  Validation loss = 5.5139  \n",
      "\n",
      "Fold: 5  Epoch: 75  Training loss = 2.5178  Validation loss = 5.5137  \n",
      "\n",
      "Fold: 5  Epoch: 76  Training loss = 2.5177  Validation loss = 5.5136  \n",
      "\n",
      "Fold: 5  Epoch: 77  Training loss = 2.5176  Validation loss = 5.5134  \n",
      "\n",
      "Fold: 5  Epoch: 78  Training loss = 2.5174  Validation loss = 5.5132  \n",
      "\n",
      "Fold: 5  Epoch: 79  Training loss = 2.5173  Validation loss = 5.5131  \n",
      "\n",
      "Fold: 5  Epoch: 80  Training loss = 2.5172  Validation loss = 5.5129  \n",
      "\n",
      "Fold: 5  Epoch: 81  Training loss = 2.5171  Validation loss = 5.5127  \n",
      "\n",
      "Fold: 5  Epoch: 82  Training loss = 2.5170  Validation loss = 5.5126  \n",
      "\n",
      "Fold: 5  Epoch: 83  Training loss = 2.5169  Validation loss = 5.5124  \n",
      "\n",
      "Fold: 5  Epoch: 84  Training loss = 2.5168  Validation loss = 5.5123  \n",
      "\n",
      "Fold: 5  Epoch: 85  Training loss = 2.5167  Validation loss = 5.5122  \n",
      "\n",
      "Fold: 5  Epoch: 86  Training loss = 2.5165  Validation loss = 5.5119  \n",
      "\n",
      "Fold: 5  Epoch: 87  Training loss = 2.5164  Validation loss = 5.5117  \n",
      "\n",
      "Fold: 5  Epoch: 88  Training loss = 2.5163  Validation loss = 5.5115  \n",
      "\n",
      "Fold: 5  Epoch: 89  Training loss = 2.5161  Validation loss = 5.5114  \n",
      "\n",
      "Fold: 5  Epoch: 90  Training loss = 2.5160  Validation loss = 5.5112  \n",
      "\n",
      "Fold: 5  Epoch: 91  Training loss = 2.5159  Validation loss = 5.5110  \n",
      "\n",
      "Fold: 5  Epoch: 92  Training loss = 2.5158  Validation loss = 5.5109  \n",
      "\n",
      "Fold: 5  Epoch: 93  Training loss = 2.5157  Validation loss = 5.5108  \n",
      "\n",
      "Fold: 5  Epoch: 94  Training loss = 2.5156  Validation loss = 5.5106  \n",
      "\n",
      "Fold: 5  Epoch: 95  Training loss = 2.5155  Validation loss = 5.5104  \n",
      "\n",
      "Fold: 5  Epoch: 96  Training loss = 2.5153  Validation loss = 5.5103  \n",
      "\n",
      "Fold: 5  Epoch: 97  Training loss = 2.5152  Validation loss = 5.5100  \n",
      "\n",
      "Fold: 5  Epoch: 98  Training loss = 2.5151  Validation loss = 5.5099  \n",
      "\n",
      "Fold: 5  Epoch: 99  Training loss = 2.5150  Validation loss = 5.5097  \n",
      "\n",
      "Fold: 5  Epoch: 100  Training loss = 2.5149  Validation loss = 5.5096  \n",
      "\n",
      "Fold: 5  Epoch: 101  Training loss = 2.5147  Validation loss = 5.5094  \n",
      "\n",
      "Fold: 5  Epoch: 102  Training loss = 2.5146  Validation loss = 5.5092  \n",
      "\n",
      "Fold: 5  Epoch: 103  Training loss = 2.5145  Validation loss = 5.5091  \n",
      "\n",
      "Fold: 5  Epoch: 104  Training loss = 2.5144  Validation loss = 5.5090  \n",
      "\n",
      "Fold: 5  Epoch: 105  Training loss = 2.5143  Validation loss = 5.5088  \n",
      "\n",
      "Fold: 5  Epoch: 106  Training loss = 2.5142  Validation loss = 5.5087  \n",
      "\n",
      "Fold: 5  Epoch: 107  Training loss = 2.5141  Validation loss = 5.5085  \n",
      "\n",
      "Fold: 5  Epoch: 108  Training loss = 2.5140  Validation loss = 5.5083  \n",
      "\n",
      "Fold: 5  Epoch: 109  Training loss = 2.5138  Validation loss = 5.5080  \n",
      "\n",
      "Fold: 5  Epoch: 110  Training loss = 2.5137  Validation loss = 5.5079  \n",
      "\n",
      "Fold: 5  Epoch: 111  Training loss = 2.5136  Validation loss = 5.5077  \n",
      "\n",
      "Fold: 5  Epoch: 112  Training loss = 2.5134  Validation loss = 5.5075  \n",
      "\n",
      "Fold: 5  Epoch: 113  Training loss = 2.5133  Validation loss = 5.5073  \n",
      "\n",
      "Fold: 5  Epoch: 114  Training loss = 2.5132  Validation loss = 5.5071  \n",
      "\n",
      "Fold: 5  Epoch: 115  Training loss = 2.5130  Validation loss = 5.5069  \n",
      "\n",
      "Fold: 5  Epoch: 116  Training loss = 2.5129  Validation loss = 5.5068  \n",
      "\n",
      "Fold: 5  Epoch: 117  Training loss = 2.5128  Validation loss = 5.5067  \n",
      "\n",
      "Fold: 5  Epoch: 118  Training loss = 2.5127  Validation loss = 5.5065  \n",
      "\n",
      "Fold: 5  Epoch: 119  Training loss = 2.5126  Validation loss = 5.5063  \n",
      "\n",
      "Fold: 5  Epoch: 120  Training loss = 2.5125  Validation loss = 5.5061  \n",
      "\n",
      "Fold: 5  Epoch: 121  Training loss = 2.5124  Validation loss = 5.5060  \n",
      "\n",
      "Fold: 5  Epoch: 122  Training loss = 2.5122  Validation loss = 5.5058  \n",
      "\n",
      "Fold: 5  Epoch: 123  Training loss = 2.5121  Validation loss = 5.5057  \n",
      "\n",
      "Fold: 5  Epoch: 124  Training loss = 2.5120  Validation loss = 5.5055  \n",
      "\n",
      "Fold: 5  Epoch: 125  Training loss = 2.5119  Validation loss = 5.5053  \n",
      "\n",
      "Fold: 5  Epoch: 126  Training loss = 2.5117  Validation loss = 5.5051  \n",
      "\n",
      "Fold: 5  Epoch: 127  Training loss = 2.5116  Validation loss = 5.5049  \n",
      "\n",
      "Fold: 5  Epoch: 128  Training loss = 2.5115  Validation loss = 5.5048  \n",
      "\n",
      "Fold: 5  Epoch: 129  Training loss = 2.5113  Validation loss = 5.5045  \n",
      "\n",
      "Fold: 5  Epoch: 130  Training loss = 2.5112  Validation loss = 5.5043  \n",
      "\n",
      "Fold: 5  Epoch: 131  Training loss = 2.5111  Validation loss = 5.5041  \n",
      "\n",
      "Fold: 5  Epoch: 132  Training loss = 2.5110  Validation loss = 5.5040  \n",
      "\n",
      "Fold: 5  Epoch: 133  Training loss = 2.5109  Validation loss = 5.5038  \n",
      "\n",
      "Fold: 5  Epoch: 134  Training loss = 2.5107  Validation loss = 5.5037  \n",
      "\n",
      "Fold: 5  Epoch: 135  Training loss = 2.5106  Validation loss = 5.5035  \n",
      "\n",
      "Fold: 5  Epoch: 136  Training loss = 2.5105  Validation loss = 5.5033  \n",
      "\n",
      "Fold: 5  Epoch: 137  Training loss = 2.5104  Validation loss = 5.5032  \n",
      "\n",
      "Fold: 5  Epoch: 138  Training loss = 2.5103  Validation loss = 5.5030  \n",
      "\n",
      "Fold: 5  Epoch: 139  Training loss = 2.5101  Validation loss = 5.5028  \n",
      "\n",
      "Fold: 5  Epoch: 140  Training loss = 2.5100  Validation loss = 5.5026  \n",
      "\n",
      "Fold: 5  Epoch: 141  Training loss = 2.5099  Validation loss = 5.5024  \n",
      "\n",
      "Fold: 5  Epoch: 142  Training loss = 2.5098  Validation loss = 5.5023  \n",
      "\n",
      "Fold: 5  Epoch: 143  Training loss = 2.5096  Validation loss = 5.5021  \n",
      "\n",
      "Fold: 5  Epoch: 144  Training loss = 2.5095  Validation loss = 5.5019  \n",
      "\n",
      "Fold: 5  Epoch: 145  Training loss = 2.5094  Validation loss = 5.5018  \n",
      "\n",
      "Fold: 5  Epoch: 146  Training loss = 2.5093  Validation loss = 5.5016  \n",
      "\n",
      "Fold: 5  Epoch: 147  Training loss = 2.5092  Validation loss = 5.5014  \n",
      "\n",
      "Fold: 5  Epoch: 148  Training loss = 2.5090  Validation loss = 5.5012  \n",
      "\n",
      "Fold: 5  Epoch: 149  Training loss = 2.5089  Validation loss = 5.5010  \n",
      "\n",
      "Fold: 5  Epoch: 150  Training loss = 2.5088  Validation loss = 5.5009  \n",
      "\n",
      "Fold: 5  Epoch: 151  Training loss = 2.5087  Validation loss = 5.5007  \n",
      "\n",
      "Fold: 5  Epoch: 152  Training loss = 2.5085  Validation loss = 5.5005  \n",
      "\n",
      "Fold: 5  Epoch: 153  Training loss = 2.5084  Validation loss = 5.5003  \n",
      "\n",
      "Fold: 5  Epoch: 154  Training loss = 2.5083  Validation loss = 5.5001  \n",
      "\n",
      "Fold: 5  Epoch: 155  Training loss = 2.5082  Validation loss = 5.4999  \n",
      "\n",
      "Fold: 5  Epoch: 156  Training loss = 2.5081  Validation loss = 5.4997  \n",
      "\n",
      "Fold: 5  Epoch: 157  Training loss = 2.5080  Validation loss = 5.4996  \n",
      "\n",
      "Fold: 5  Epoch: 158  Training loss = 2.5078  Validation loss = 5.4994  \n",
      "\n",
      "Fold: 5  Epoch: 159  Training loss = 2.5078  Validation loss = 5.4993  \n",
      "\n",
      "Fold: 5  Epoch: 160  Training loss = 2.5076  Validation loss = 5.4991  \n",
      "\n",
      "Fold: 5  Epoch: 161  Training loss = 2.5075  Validation loss = 5.4989  \n",
      "\n",
      "Fold: 5  Epoch: 162  Training loss = 2.5074  Validation loss = 5.4988  \n",
      "\n",
      "Fold: 5  Epoch: 163  Training loss = 2.5073  Validation loss = 5.4986  \n",
      "\n",
      "Fold: 5  Epoch: 164  Training loss = 2.5072  Validation loss = 5.4985  \n",
      "\n",
      "Fold: 5  Epoch: 165  Training loss = 2.5071  Validation loss = 5.4983  \n",
      "\n",
      "Fold: 5  Epoch: 166  Training loss = 2.5070  Validation loss = 5.4982  \n",
      "\n",
      "Fold: 5  Epoch: 167  Training loss = 2.5069  Validation loss = 5.4980  \n",
      "\n",
      "Fold: 5  Epoch: 168  Training loss = 2.5068  Validation loss = 5.4978  \n",
      "\n",
      "Fold: 5  Epoch: 169  Training loss = 2.5067  Validation loss = 5.4977  \n",
      "\n",
      "Fold: 5  Epoch: 170  Training loss = 2.5065  Validation loss = 5.4974  \n",
      "\n",
      "Fold: 5  Epoch: 171  Training loss = 2.5064  Validation loss = 5.4973  \n",
      "\n",
      "Fold: 5  Epoch: 172  Training loss = 2.5063  Validation loss = 5.4971  \n",
      "\n",
      "Fold: 5  Epoch: 173  Training loss = 2.5062  Validation loss = 5.4970  \n",
      "\n",
      "Fold: 5  Epoch: 174  Training loss = 2.5061  Validation loss = 5.4968  \n",
      "\n",
      "Fold: 5  Epoch: 175  Training loss = 2.5060  Validation loss = 5.4967  \n",
      "\n",
      "Fold: 5  Epoch: 176  Training loss = 2.5058  Validation loss = 5.4965  \n",
      "\n",
      "Fold: 5  Epoch: 177  Training loss = 2.5057  Validation loss = 5.4963  \n",
      "\n",
      "Fold: 5  Epoch: 178  Training loss = 2.5056  Validation loss = 5.4962  \n",
      "\n",
      "Fold: 5  Epoch: 179  Training loss = 2.5054  Validation loss = 5.4960  \n",
      "\n",
      "Fold: 5  Epoch: 180  Training loss = 2.5053  Validation loss = 5.4957  \n",
      "\n",
      "Fold: 5  Epoch: 181  Training loss = 2.5052  Validation loss = 5.4955  \n",
      "\n",
      "Fold: 5  Epoch: 182  Training loss = 2.5051  Validation loss = 5.4954  \n",
      "\n",
      "Fold: 5  Epoch: 183  Training loss = 2.5049  Validation loss = 5.4952  \n",
      "\n",
      "Fold: 5  Epoch: 184  Training loss = 2.5048  Validation loss = 5.4950  \n",
      "\n",
      "Fold: 5  Epoch: 185  Training loss = 2.5047  Validation loss = 5.4948  \n",
      "\n",
      "Fold: 5  Epoch: 186  Training loss = 2.5046  Validation loss = 5.4946  \n",
      "\n",
      "Fold: 5  Epoch: 187  Training loss = 2.5045  Validation loss = 5.4945  \n",
      "\n",
      "Fold: 5  Epoch: 188  Training loss = 2.5043  Validation loss = 5.4943  \n",
      "\n",
      "Fold: 5  Epoch: 189  Training loss = 2.5042  Validation loss = 5.4941  \n",
      "\n",
      "Fold: 5  Epoch: 190  Training loss = 2.5041  Validation loss = 5.4939  \n",
      "\n",
      "Fold: 5  Epoch: 191  Training loss = 2.5039  Validation loss = 5.4937  \n",
      "\n",
      "Fold: 5  Epoch: 192  Training loss = 2.5038  Validation loss = 5.4935  \n",
      "\n",
      "Fold: 5  Epoch: 193  Training loss = 2.5037  Validation loss = 5.4933  \n",
      "\n",
      "Fold: 5  Epoch: 194  Training loss = 2.5036  Validation loss = 5.4931  \n",
      "\n",
      "Fold: 5  Epoch: 195  Training loss = 2.5035  Validation loss = 5.4929  \n",
      "\n",
      "Fold: 5  Epoch: 196  Training loss = 2.5033  Validation loss = 5.4927  \n",
      "\n",
      "Fold: 5  Epoch: 197  Training loss = 2.5032  Validation loss = 5.4925  \n",
      "\n",
      "Fold: 5  Epoch: 198  Training loss = 2.5031  Validation loss = 5.4923  \n",
      "\n",
      "Fold: 5  Epoch: 199  Training loss = 2.5030  Validation loss = 5.4922  \n",
      "\n",
      "Fold: 5  Epoch: 200  Training loss = 2.5028  Validation loss = 5.4920  \n",
      "\n",
      "Fold: 5  Epoch: 201  Training loss = 2.5027  Validation loss = 5.4917  \n",
      "\n",
      "Fold: 5  Epoch: 202  Training loss = 2.5026  Validation loss = 5.4915  \n",
      "\n",
      "Fold: 5  Epoch: 203  Training loss = 2.5024  Validation loss = 5.4913  \n",
      "\n",
      "Fold: 5  Epoch: 204  Training loss = 2.5023  Validation loss = 5.4912  \n",
      "\n",
      "Fold: 5  Epoch: 205  Training loss = 2.5022  Validation loss = 5.4910  \n",
      "\n",
      "Fold: 5  Epoch: 206  Training loss = 2.5021  Validation loss = 5.4908  \n",
      "\n",
      "Fold: 5  Epoch: 207  Training loss = 2.5020  Validation loss = 5.4907  \n",
      "\n",
      "Fold: 5  Epoch: 208  Training loss = 2.5019  Validation loss = 5.4906  \n",
      "\n",
      "Fold: 5  Epoch: 209  Training loss = 2.5018  Validation loss = 5.4904  \n",
      "\n",
      "Fold: 5  Epoch: 210  Training loss = 2.5017  Validation loss = 5.4902  \n",
      "\n",
      "Fold: 5  Epoch: 211  Training loss = 2.5016  Validation loss = 5.4901  \n",
      "\n",
      "Fold: 5  Epoch: 212  Training loss = 2.5014  Validation loss = 5.4898  \n",
      "\n",
      "Fold: 5  Epoch: 213  Training loss = 2.5013  Validation loss = 5.4896  \n",
      "\n",
      "Fold: 5  Epoch: 214  Training loss = 2.5011  Validation loss = 5.4895  \n",
      "\n",
      "Fold: 5  Epoch: 215  Training loss = 2.5010  Validation loss = 5.4893  \n",
      "\n",
      "Fold: 5  Epoch: 216  Training loss = 2.5009  Validation loss = 5.4891  \n",
      "\n",
      "Fold: 5  Epoch: 217  Training loss = 2.5008  Validation loss = 5.4890  \n",
      "\n",
      "Fold: 5  Epoch: 218  Training loss = 2.5007  Validation loss = 5.4888  \n",
      "\n",
      "Fold: 5  Epoch: 219  Training loss = 2.5006  Validation loss = 5.4886  \n",
      "\n",
      "Fold: 5  Epoch: 220  Training loss = 2.5004  Validation loss = 5.4884  \n",
      "\n",
      "Fold: 5  Epoch: 221  Training loss = 2.5003  Validation loss = 5.4882  \n",
      "\n",
      "Fold: 5  Epoch: 222  Training loss = 2.5002  Validation loss = 5.4880  \n",
      "\n",
      "Fold: 5  Epoch: 223  Training loss = 2.5001  Validation loss = 5.4878  \n",
      "\n",
      "Fold: 5  Epoch: 224  Training loss = 2.4999  Validation loss = 5.4876  \n",
      "\n",
      "Fold: 5  Epoch: 225  Training loss = 2.4998  Validation loss = 5.4874  \n",
      "\n",
      "Fold: 5  Epoch: 226  Training loss = 2.4997  Validation loss = 5.4873  \n",
      "\n",
      "Fold: 5  Epoch: 227  Training loss = 2.4996  Validation loss = 5.4871  \n",
      "\n",
      "Fold: 5  Epoch: 228  Training loss = 2.4995  Validation loss = 5.4869  \n",
      "\n",
      "Fold: 5  Epoch: 229  Training loss = 2.4993  Validation loss = 5.4867  \n",
      "\n",
      "Fold: 5  Epoch: 230  Training loss = 2.4992  Validation loss = 5.4866  \n",
      "\n",
      "Fold: 5  Epoch: 231  Training loss = 2.4991  Validation loss = 5.4863  \n",
      "\n",
      "Fold: 5  Epoch: 232  Training loss = 2.4990  Validation loss = 5.4862  \n",
      "\n",
      "Fold: 5  Epoch: 233  Training loss = 2.4989  Validation loss = 5.4860  \n",
      "\n",
      "Fold: 5  Epoch: 234  Training loss = 2.4987  Validation loss = 5.4859  \n",
      "\n",
      "Fold: 5  Epoch: 235  Training loss = 2.4986  Validation loss = 5.4857  \n",
      "\n",
      "Fold: 5  Epoch: 236  Training loss = 2.4985  Validation loss = 5.4854  \n",
      "\n",
      "Fold: 5  Epoch: 237  Training loss = 2.4984  Validation loss = 5.4852  \n",
      "\n",
      "Fold: 5  Epoch: 238  Training loss = 2.4983  Validation loss = 5.4851  \n",
      "\n",
      "Fold: 5  Epoch: 239  Training loss = 2.4981  Validation loss = 5.4848  \n",
      "\n",
      "Fold: 5  Epoch: 240  Training loss = 2.4980  Validation loss = 5.4846  \n",
      "\n",
      "Fold: 5  Epoch: 241  Training loss = 2.4978  Validation loss = 5.4844  \n",
      "\n",
      "Fold: 5  Epoch: 242  Training loss = 2.4977  Validation loss = 5.4843  \n",
      "\n",
      "Fold: 5  Epoch: 243  Training loss = 2.4976  Validation loss = 5.4841  \n",
      "\n",
      "Fold: 5  Epoch: 244  Training loss = 2.4975  Validation loss = 5.4839  \n",
      "\n",
      "Fold: 5  Epoch: 245  Training loss = 2.4973  Validation loss = 5.4837  \n",
      "\n",
      "Fold: 5  Epoch: 246  Training loss = 2.4972  Validation loss = 5.4835  \n",
      "\n",
      "Fold: 5  Epoch: 247  Training loss = 2.4971  Validation loss = 5.4834  \n",
      "\n",
      "Fold: 5  Epoch: 248  Training loss = 2.4970  Validation loss = 5.4832  \n",
      "\n",
      "Fold: 5  Epoch: 249  Training loss = 2.4969  Validation loss = 5.4830  \n",
      "\n",
      "Fold: 5  Epoch: 250  Training loss = 2.4967  Validation loss = 5.4828  \n",
      "\n",
      "Fold: 5  Epoch: 251  Training loss = 2.4966  Validation loss = 5.4826  \n",
      "\n",
      "Fold: 5  Epoch: 252  Training loss = 2.4965  Validation loss = 5.4825  \n",
      "\n",
      "Fold: 5  Epoch: 253  Training loss = 2.4964  Validation loss = 5.4823  \n",
      "\n",
      "Fold: 5  Epoch: 254  Training loss = 2.4963  Validation loss = 5.4822  \n",
      "\n",
      "Fold: 5  Epoch: 255  Training loss = 2.4961  Validation loss = 5.4820  \n",
      "\n",
      "Fold: 5  Epoch: 256  Training loss = 2.4960  Validation loss = 5.4818  \n",
      "\n",
      "Fold: 5  Epoch: 257  Training loss = 2.4959  Validation loss = 5.4817  \n",
      "\n",
      "Fold: 5  Epoch: 258  Training loss = 2.4958  Validation loss = 5.4815  \n",
      "\n",
      "Fold: 5  Epoch: 259  Training loss = 2.4957  Validation loss = 5.4813  \n",
      "\n",
      "Fold: 5  Epoch: 260  Training loss = 2.4956  Validation loss = 5.4812  \n",
      "\n",
      "Fold: 5  Epoch: 261  Training loss = 2.4955  Validation loss = 5.4811  \n",
      "\n",
      "Fold: 5  Epoch: 262  Training loss = 2.4954  Validation loss = 5.4810  \n",
      "\n",
      "Fold: 5  Epoch: 263  Training loss = 2.4953  Validation loss = 5.4807  \n",
      "\n",
      "Fold: 5  Epoch: 264  Training loss = 2.4952  Validation loss = 5.4806  \n",
      "\n",
      "Fold: 5  Epoch: 265  Training loss = 2.4951  Validation loss = 5.4804  \n",
      "\n",
      "Fold: 5  Epoch: 266  Training loss = 2.4949  Validation loss = 5.4802  \n",
      "\n",
      "Fold: 5  Epoch: 267  Training loss = 2.4948  Validation loss = 5.4800  \n",
      "\n",
      "Fold: 5  Epoch: 268  Training loss = 2.4947  Validation loss = 5.4798  \n",
      "\n",
      "Fold: 5  Epoch: 269  Training loss = 2.4946  Validation loss = 5.4796  \n",
      "\n",
      "Fold: 5  Epoch: 270  Training loss = 2.4945  Validation loss = 5.4795  \n",
      "\n",
      "Fold: 5  Epoch: 271  Training loss = 2.4943  Validation loss = 5.4793  \n",
      "\n",
      "Fold: 5  Epoch: 272  Training loss = 2.4942  Validation loss = 5.4791  \n",
      "\n",
      "Fold: 5  Epoch: 273  Training loss = 2.4941  Validation loss = 5.4789  \n",
      "\n",
      "Fold: 5  Epoch: 274  Training loss = 2.4940  Validation loss = 5.4788  \n",
      "\n",
      "Fold: 5  Epoch: 275  Training loss = 2.4938  Validation loss = 5.4786  \n",
      "\n",
      "Fold: 5  Epoch: 276  Training loss = 2.4937  Validation loss = 5.4785  \n",
      "\n",
      "Fold: 5  Epoch: 277  Training loss = 2.4936  Validation loss = 5.4783  \n",
      "\n",
      "Fold: 5  Epoch: 278  Training loss = 2.4935  Validation loss = 5.4780  \n",
      "\n",
      "Fold: 5  Epoch: 279  Training loss = 2.4934  Validation loss = 5.4779  \n",
      "\n",
      "Fold: 5  Epoch: 280  Training loss = 2.4933  Validation loss = 5.4778  \n",
      "\n",
      "Fold: 5  Epoch: 281  Training loss = 2.4931  Validation loss = 5.4776  \n",
      "\n",
      "Fold: 5  Epoch: 282  Training loss = 2.4930  Validation loss = 5.4773  \n",
      "\n",
      "Fold: 5  Epoch: 283  Training loss = 2.4929  Validation loss = 5.4771  \n",
      "\n",
      "Fold: 5  Epoch: 284  Training loss = 2.4928  Validation loss = 5.4770  \n",
      "\n",
      "Fold: 5  Epoch: 285  Training loss = 2.4926  Validation loss = 5.4768  \n",
      "\n",
      "Fold: 5  Epoch: 286  Training loss = 2.4925  Validation loss = 5.4766  \n",
      "\n",
      "Fold: 5  Epoch: 287  Training loss = 2.4924  Validation loss = 5.4764  \n",
      "\n",
      "Fold: 5  Epoch: 288  Training loss = 2.4923  Validation loss = 5.4763  \n",
      "\n",
      "Fold: 5  Epoch: 289  Training loss = 2.4921  Validation loss = 5.4760  \n",
      "\n",
      "Fold: 5  Epoch: 290  Training loss = 2.4921  Validation loss = 5.4759  \n",
      "\n",
      "Fold: 5  Epoch: 291  Training loss = 2.4919  Validation loss = 5.4757  \n",
      "\n",
      "Fold: 5  Epoch: 292  Training loss = 2.4918  Validation loss = 5.4755  \n",
      "\n",
      "Fold: 5  Epoch: 293  Training loss = 2.4917  Validation loss = 5.4754  \n",
      "\n",
      "Fold: 5  Epoch: 294  Training loss = 2.4916  Validation loss = 5.4752  \n",
      "\n",
      "Fold: 5  Epoch: 295  Training loss = 2.4914  Validation loss = 5.4750  \n",
      "\n",
      "Fold: 5  Epoch: 296  Training loss = 2.4913  Validation loss = 5.4748  \n",
      "\n",
      "Fold: 5  Epoch: 297  Training loss = 2.4912  Validation loss = 5.4746  \n",
      "\n",
      "Fold: 5  Epoch: 298  Training loss = 2.4911  Validation loss = 5.4744  \n",
      "\n",
      "Fold: 5  Epoch: 299  Training loss = 2.4909  Validation loss = 5.4743  \n",
      "\n",
      "Fold: 5  Epoch: 300  Training loss = 2.4908  Validation loss = 5.4741  \n",
      "\n",
      "Fold: 5  Epoch: 301  Training loss = 2.4907  Validation loss = 5.4740  \n",
      "\n",
      "Fold: 5  Epoch: 302  Training loss = 2.4906  Validation loss = 5.4738  \n",
      "\n",
      "Fold: 5  Epoch: 303  Training loss = 2.4905  Validation loss = 5.4735  \n",
      "\n",
      "Fold: 5  Epoch: 304  Training loss = 2.4903  Validation loss = 5.4734  \n",
      "\n",
      "Fold: 5  Epoch: 305  Training loss = 2.4902  Validation loss = 5.4732  \n",
      "\n",
      "Fold: 5  Epoch: 306  Training loss = 2.4901  Validation loss = 5.4730  \n",
      "\n",
      "Fold: 5  Epoch: 307  Training loss = 2.4899  Validation loss = 5.4728  \n",
      "\n",
      "Fold: 5  Epoch: 308  Training loss = 2.4898  Validation loss = 5.4726  \n",
      "\n",
      "Fold: 5  Epoch: 309  Training loss = 2.4897  Validation loss = 5.4724  \n",
      "\n",
      "Fold: 5  Epoch: 310  Training loss = 2.4896  Validation loss = 5.4722  \n",
      "\n",
      "Fold: 5  Epoch: 311  Training loss = 2.4895  Validation loss = 5.4720  \n",
      "\n",
      "Fold: 5  Epoch: 312  Training loss = 2.4893  Validation loss = 5.4718  \n",
      "\n",
      "Fold: 5  Epoch: 313  Training loss = 2.4892  Validation loss = 5.4717  \n",
      "\n",
      "Fold: 5  Epoch: 314  Training loss = 2.4891  Validation loss = 5.4715  \n",
      "\n",
      "Fold: 5  Epoch: 315  Training loss = 2.4890  Validation loss = 5.4713  \n",
      "\n",
      "Fold: 5  Epoch: 316  Training loss = 2.4889  Validation loss = 5.4711  \n",
      "\n",
      "Fold: 5  Epoch: 317  Training loss = 2.4887  Validation loss = 5.4709  \n",
      "\n",
      "Fold: 5  Epoch: 318  Training loss = 2.4886  Validation loss = 5.4707  \n",
      "\n",
      "Fold: 5  Epoch: 319  Training loss = 2.4885  Validation loss = 5.4705  \n",
      "\n",
      "Fold: 5  Epoch: 320  Training loss = 2.4884  Validation loss = 5.4704  \n",
      "\n",
      "Fold: 5  Epoch: 321  Training loss = 2.4883  Validation loss = 5.4702  \n",
      "\n",
      "Fold: 5  Epoch: 322  Training loss = 2.4882  Validation loss = 5.4701  \n",
      "\n",
      "Fold: 5  Epoch: 323  Training loss = 2.4881  Validation loss = 5.4700  \n",
      "\n",
      "Fold: 5  Epoch: 324  Training loss = 2.4879  Validation loss = 5.4698  \n",
      "\n",
      "Fold: 5  Epoch: 325  Training loss = 2.4878  Validation loss = 5.4696  \n",
      "\n",
      "Fold: 5  Epoch: 326  Training loss = 2.4877  Validation loss = 5.4694  \n",
      "\n",
      "Fold: 5  Epoch: 327  Training loss = 2.4875  Validation loss = 5.4692  \n",
      "\n",
      "Fold: 5  Epoch: 328  Training loss = 2.4874  Validation loss = 5.4690  \n",
      "\n",
      "Fold: 5  Epoch: 329  Training loss = 2.4873  Validation loss = 5.4689  \n",
      "\n",
      "Fold: 5  Epoch: 330  Training loss = 2.4872  Validation loss = 5.4688  \n",
      "\n",
      "Fold: 5  Epoch: 331  Training loss = 2.4871  Validation loss = 5.4686  \n",
      "\n",
      "Fold: 5  Epoch: 332  Training loss = 2.4870  Validation loss = 5.4684  \n",
      "\n",
      "Fold: 5  Epoch: 333  Training loss = 2.4869  Validation loss = 5.4682  \n",
      "\n",
      "Fold: 5  Epoch: 334  Training loss = 2.4867  Validation loss = 5.4681  \n",
      "\n",
      "Fold: 5  Epoch: 335  Training loss = 2.4866  Validation loss = 5.4679  \n",
      "\n",
      "Fold: 5  Epoch: 336  Training loss = 2.4865  Validation loss = 5.4678  \n",
      "\n",
      "Fold: 5  Epoch: 337  Training loss = 2.4864  Validation loss = 5.4676  \n",
      "\n",
      "Fold: 5  Epoch: 338  Training loss = 2.4863  Validation loss = 5.4674  \n",
      "\n",
      "Fold: 5  Epoch: 339  Training loss = 2.4862  Validation loss = 5.4672  \n",
      "\n",
      "Fold: 5  Epoch: 340  Training loss = 2.4860  Validation loss = 5.4670  \n",
      "\n",
      "Fold: 5  Epoch: 341  Training loss = 2.4859  Validation loss = 5.4668  \n",
      "\n",
      "Fold: 5  Epoch: 342  Training loss = 2.4858  Validation loss = 5.4667  \n",
      "\n",
      "Fold: 5  Epoch: 343  Training loss = 2.4857  Validation loss = 5.4665  \n",
      "\n",
      "Fold: 5  Epoch: 344  Training loss = 2.4856  Validation loss = 5.4663  \n",
      "\n",
      "Fold: 5  Epoch: 345  Training loss = 2.4855  Validation loss = 5.4661  \n",
      "\n",
      "Fold: 5  Epoch: 346  Training loss = 2.4853  Validation loss = 5.4660  \n",
      "\n",
      "Fold: 5  Epoch: 347  Training loss = 2.4852  Validation loss = 5.4657  \n",
      "\n",
      "Fold: 5  Epoch: 348  Training loss = 2.4850  Validation loss = 5.4655  \n",
      "\n",
      "Fold: 5  Epoch: 349  Training loss = 2.4849  Validation loss = 5.4653  \n",
      "\n",
      "Fold: 5  Epoch: 350  Training loss = 2.4848  Validation loss = 5.4652  \n",
      "\n",
      "Fold: 5  Epoch: 351  Training loss = 2.4847  Validation loss = 5.4651  \n",
      "\n",
      "Fold: 5  Epoch: 352  Training loss = 2.4846  Validation loss = 5.4649  \n",
      "\n",
      "Fold: 5  Epoch: 353  Training loss = 2.4844  Validation loss = 5.4647  \n",
      "\n",
      "Fold: 5  Epoch: 354  Training loss = 2.4843  Validation loss = 5.4645  \n",
      "\n",
      "Fold: 5  Epoch: 355  Training loss = 2.4842  Validation loss = 5.4643  \n",
      "\n",
      "Fold: 5  Epoch: 356  Training loss = 2.4841  Validation loss = 5.4642  \n",
      "\n",
      "Fold: 5  Epoch: 357  Training loss = 2.4840  Validation loss = 5.4640  \n",
      "\n",
      "Fold: 5  Epoch: 358  Training loss = 2.4839  Validation loss = 5.4638  \n",
      "\n",
      "Fold: 5  Epoch: 359  Training loss = 2.4837  Validation loss = 5.4636  \n",
      "\n",
      "Fold: 5  Epoch: 360  Training loss = 2.4836  Validation loss = 5.4634  \n",
      "\n",
      "Fold: 5  Epoch: 361  Training loss = 2.4835  Validation loss = 5.4632  \n",
      "\n",
      "Fold: 5  Epoch: 362  Training loss = 2.4834  Validation loss = 5.4630  \n",
      "\n",
      "Fold: 5  Epoch: 363  Training loss = 2.4833  Validation loss = 5.4629  \n",
      "\n",
      "Fold: 5  Epoch: 364  Training loss = 2.4831  Validation loss = 5.4627  \n",
      "\n",
      "Fold: 5  Epoch: 365  Training loss = 2.4830  Validation loss = 5.4626  \n",
      "\n",
      "Fold: 5  Epoch: 366  Training loss = 2.4829  Validation loss = 5.4623  \n",
      "\n",
      "Fold: 5  Epoch: 367  Training loss = 2.4828  Validation loss = 5.4622  \n",
      "\n",
      "Fold: 5  Epoch: 368  Training loss = 2.4827  Validation loss = 5.4620  \n",
      "\n",
      "Fold: 5  Epoch: 369  Training loss = 2.4826  Validation loss = 5.4619  \n",
      "\n",
      "Fold: 5  Epoch: 370  Training loss = 2.4825  Validation loss = 5.4617  \n",
      "\n",
      "Fold: 5  Epoch: 371  Training loss = 2.4823  Validation loss = 5.4615  \n",
      "\n",
      "Fold: 5  Epoch: 372  Training loss = 2.4822  Validation loss = 5.4613  \n",
      "\n",
      "Fold: 5  Epoch: 373  Training loss = 2.4821  Validation loss = 5.4612  \n",
      "\n",
      "Fold: 5  Epoch: 374  Training loss = 2.4820  Validation loss = 5.4610  \n",
      "\n",
      "Fold: 5  Epoch: 375  Training loss = 2.4818  Validation loss = 5.4608  \n",
      "\n",
      "Fold: 5  Epoch: 376  Training loss = 2.4817  Validation loss = 5.4606  \n",
      "\n",
      "Fold: 5  Epoch: 377  Training loss = 2.4816  Validation loss = 5.4605  \n",
      "\n",
      "Fold: 5  Epoch: 378  Training loss = 2.4815  Validation loss = 5.4603  \n",
      "\n",
      "Fold: 5  Epoch: 379  Training loss = 2.4813  Validation loss = 5.4601  \n",
      "\n",
      "Fold: 5  Epoch: 380  Training loss = 2.4812  Validation loss = 5.4600  \n",
      "\n",
      "Fold: 5  Epoch: 381  Training loss = 2.4811  Validation loss = 5.4598  \n",
      "\n",
      "Fold: 5  Epoch: 382  Training loss = 2.4810  Validation loss = 5.4596  \n",
      "\n",
      "Fold: 5  Epoch: 383  Training loss = 2.4809  Validation loss = 5.4594  \n",
      "\n",
      "Fold: 5  Epoch: 384  Training loss = 2.4807  Validation loss = 5.4592  \n",
      "\n",
      "Fold: 5  Epoch: 385  Training loss = 2.4806  Validation loss = 5.4589  \n",
      "\n",
      "Fold: 5  Epoch: 386  Training loss = 2.4804  Validation loss = 5.4587  \n",
      "\n",
      "Fold: 5  Epoch: 387  Training loss = 2.4803  Validation loss = 5.4586  \n",
      "\n",
      "Fold: 5  Epoch: 388  Training loss = 2.4802  Validation loss = 5.4584  \n",
      "\n",
      "Fold: 5  Epoch: 389  Training loss = 2.4801  Validation loss = 5.4582  \n",
      "\n",
      "Fold: 5  Epoch: 390  Training loss = 2.4800  Validation loss = 5.4580  \n",
      "\n",
      "Fold: 5  Epoch: 391  Training loss = 2.4799  Validation loss = 5.4579  \n",
      "\n",
      "Fold: 5  Epoch: 392  Training loss = 2.4798  Validation loss = 5.4577  \n",
      "\n",
      "Fold: 5  Epoch: 393  Training loss = 2.4797  Validation loss = 5.4576  \n",
      "\n",
      "Fold: 5  Epoch: 394  Training loss = 2.4796  Validation loss = 5.4574  \n",
      "\n",
      "Fold: 5  Epoch: 395  Training loss = 2.4794  Validation loss = 5.4572  \n",
      "\n",
      "Fold: 5  Epoch: 396  Training loss = 2.4793  Validation loss = 5.4571  \n",
      "\n",
      "Fold: 5  Epoch: 397  Training loss = 2.4792  Validation loss = 5.4569  \n",
      "\n",
      "Fold: 5  Epoch: 398  Training loss = 2.4791  Validation loss = 5.4567  \n",
      "\n",
      "Fold: 5  Epoch: 399  Training loss = 2.4790  Validation loss = 5.4565  \n",
      "\n",
      "Fold: 5  Epoch: 400  Training loss = 2.4788  Validation loss = 5.4563  \n",
      "\n",
      "Fold: 5  Epoch: 401  Training loss = 2.4787  Validation loss = 5.4562  \n",
      "\n",
      "Fold: 5  Epoch: 402  Training loss = 2.4786  Validation loss = 5.4560  \n",
      "\n",
      "Fold: 5  Epoch: 403  Training loss = 2.4785  Validation loss = 5.4559  \n",
      "\n",
      "Fold: 5  Epoch: 404  Training loss = 2.4784  Validation loss = 5.4557  \n",
      "\n",
      "Fold: 5  Epoch: 405  Training loss = 2.4783  Validation loss = 5.4556  \n",
      "\n",
      "Fold: 5  Epoch: 406  Training loss = 2.4782  Validation loss = 5.4554  \n",
      "\n",
      "Fold: 5  Epoch: 407  Training loss = 2.4781  Validation loss = 5.4553  \n",
      "\n",
      "Fold: 5  Epoch: 408  Training loss = 2.4780  Validation loss = 5.4551  \n",
      "\n",
      "Fold: 5  Epoch: 409  Training loss = 2.4778  Validation loss = 5.4549  \n",
      "\n",
      "Fold: 5  Epoch: 410  Training loss = 2.4777  Validation loss = 5.4548  \n",
      "\n",
      "Fold: 5  Epoch: 411  Training loss = 2.4776  Validation loss = 5.4546  \n",
      "\n",
      "Fold: 5  Epoch: 412  Training loss = 2.4775  Validation loss = 5.4544  \n",
      "\n",
      "Fold: 5  Epoch: 413  Training loss = 2.4774  Validation loss = 5.4542  \n",
      "\n",
      "Fold: 5  Epoch: 414  Training loss = 2.4772  Validation loss = 5.4540  \n",
      "\n",
      "Fold: 5  Epoch: 415  Training loss = 2.4771  Validation loss = 5.4538  \n",
      "\n",
      "Fold: 5  Epoch: 416  Training loss = 2.4770  Validation loss = 5.4536  \n",
      "\n",
      "Fold: 5  Epoch: 417  Training loss = 2.4769  Validation loss = 5.4534  \n",
      "\n",
      "Fold: 5  Epoch: 418  Training loss = 2.4767  Validation loss = 5.4532  \n",
      "\n",
      "Fold: 5  Epoch: 419  Training loss = 2.4766  Validation loss = 5.4530  \n",
      "\n",
      "Fold: 5  Epoch: 420  Training loss = 2.4765  Validation loss = 5.4529  \n",
      "\n",
      "Fold: 5  Epoch: 421  Training loss = 2.4764  Validation loss = 5.4527  \n",
      "\n",
      "Fold: 5  Epoch: 422  Training loss = 2.4763  Validation loss = 5.4525  \n",
      "\n",
      "Fold: 5  Epoch: 423  Training loss = 2.4762  Validation loss = 5.4523  \n",
      "\n",
      "Fold: 5  Epoch: 424  Training loss = 2.4760  Validation loss = 5.4522  \n",
      "\n",
      "Fold: 5  Epoch: 425  Training loss = 2.4759  Validation loss = 5.4520  \n",
      "\n",
      "Fold: 5  Epoch: 426  Training loss = 2.4759  Validation loss = 5.4519  \n",
      "\n",
      "Fold: 5  Epoch: 427  Training loss = 2.4757  Validation loss = 5.4517  \n",
      "\n",
      "Fold: 5  Epoch: 428  Training loss = 2.4756  Validation loss = 5.4516  \n",
      "\n",
      "Fold: 5  Epoch: 429  Training loss = 2.4755  Validation loss = 5.4514  \n",
      "\n",
      "Fold: 5  Epoch: 430  Training loss = 2.4754  Validation loss = 5.4512  \n",
      "\n",
      "Fold: 5  Epoch: 431  Training loss = 2.4753  Validation loss = 5.4511  \n",
      "\n",
      "Fold: 5  Epoch: 432  Training loss = 2.4752  Validation loss = 5.4508  \n",
      "\n",
      "Fold: 5  Epoch: 433  Training loss = 2.4750  Validation loss = 5.4507  \n",
      "\n",
      "Fold: 5  Epoch: 434  Training loss = 2.4749  Validation loss = 5.4505  \n",
      "\n",
      "Fold: 5  Epoch: 435  Training loss = 2.4748  Validation loss = 5.4504  \n",
      "\n",
      "Fold: 5  Epoch: 436  Training loss = 2.4747  Validation loss = 5.4501  \n",
      "\n",
      "Fold: 5  Epoch: 437  Training loss = 2.4746  Validation loss = 5.4500  \n",
      "\n",
      "Fold: 5  Epoch: 438  Training loss = 2.4745  Validation loss = 5.4498  \n",
      "\n",
      "Fold: 5  Epoch: 439  Training loss = 2.4743  Validation loss = 5.4496  \n",
      "\n",
      "Fold: 5  Epoch: 440  Training loss = 2.4742  Validation loss = 5.4494  \n",
      "\n",
      "Fold: 5  Epoch: 441  Training loss = 2.4741  Validation loss = 5.4492  \n",
      "\n",
      "Fold: 5  Epoch: 442  Training loss = 2.4740  Validation loss = 5.4491  \n",
      "\n",
      "Fold: 5  Epoch: 443  Training loss = 2.4738  Validation loss = 5.4489  \n",
      "\n",
      "Fold: 5  Epoch: 444  Training loss = 2.4737  Validation loss = 5.4487  \n",
      "\n",
      "Fold: 5  Epoch: 445  Training loss = 2.4736  Validation loss = 5.4485  \n",
      "\n",
      "Fold: 5  Epoch: 446  Training loss = 2.4735  Validation loss = 5.4483  \n",
      "\n",
      "Fold: 5  Epoch: 447  Training loss = 2.4733  Validation loss = 5.4481  \n",
      "\n",
      "Fold: 5  Epoch: 448  Training loss = 2.4732  Validation loss = 5.4480  \n",
      "\n",
      "Fold: 5  Epoch: 449  Training loss = 2.4731  Validation loss = 5.4478  \n",
      "\n",
      "Fold: 5  Epoch: 450  Training loss = 2.4730  Validation loss = 5.4477  \n",
      "\n",
      "Fold: 5  Epoch: 451  Training loss = 2.4729  Validation loss = 5.4474  \n",
      "\n",
      "Fold: 5  Epoch: 452  Training loss = 2.4728  Validation loss = 5.4473  \n",
      "\n",
      "Fold: 5  Epoch: 453  Training loss = 2.4726  Validation loss = 5.4471  \n",
      "\n",
      "Fold: 5  Epoch: 454  Training loss = 2.4725  Validation loss = 5.4469  \n",
      "\n",
      "Fold: 5  Epoch: 455  Training loss = 2.4724  Validation loss = 5.4467  \n",
      "\n",
      "Fold: 5  Epoch: 456  Training loss = 2.4723  Validation loss = 5.4465  \n",
      "\n",
      "Fold: 5  Epoch: 457  Training loss = 2.4722  Validation loss = 5.4463  \n",
      "\n",
      "Fold: 5  Epoch: 458  Training loss = 2.4720  Validation loss = 5.4462  \n",
      "\n",
      "Fold: 5  Epoch: 459  Training loss = 2.4719  Validation loss = 5.4460  \n",
      "\n",
      "Fold: 5  Epoch: 460  Training loss = 2.4718  Validation loss = 5.4458  \n",
      "\n",
      "Fold: 5  Epoch: 461  Training loss = 2.4716  Validation loss = 5.4455  \n",
      "\n",
      "Fold: 5  Epoch: 462  Training loss = 2.4715  Validation loss = 5.4454  \n",
      "\n",
      "Fold: 5  Epoch: 463  Training loss = 2.4714  Validation loss = 5.4452  \n",
      "\n",
      "Fold: 5  Epoch: 464  Training loss = 2.4713  Validation loss = 5.4450  \n",
      "\n",
      "Fold: 5  Epoch: 465  Training loss = 2.4712  Validation loss = 5.4448  \n",
      "\n",
      "Fold: 5  Epoch: 466  Training loss = 2.4710  Validation loss = 5.4446  \n",
      "\n",
      "Fold: 5  Epoch: 467  Training loss = 2.4709  Validation loss = 5.4445  \n",
      "\n",
      "Fold: 5  Epoch: 468  Training loss = 2.4708  Validation loss = 5.4443  \n",
      "\n",
      "Fold: 5  Epoch: 469  Training loss = 2.4707  Validation loss = 5.4441  \n",
      "\n",
      "Fold: 5  Epoch: 470  Training loss = 2.4705  Validation loss = 5.4439  \n",
      "\n",
      "Fold: 5  Epoch: 471  Training loss = 2.4704  Validation loss = 5.4437  \n",
      "\n",
      "Fold: 5  Epoch: 472  Training loss = 2.4703  Validation loss = 5.4435  \n",
      "\n",
      "Fold: 5  Epoch: 473  Training loss = 2.4702  Validation loss = 5.4433  \n",
      "\n",
      "Fold: 5  Epoch: 474  Training loss = 2.4701  Validation loss = 5.4432  \n",
      "\n",
      "Fold: 5  Epoch: 475  Training loss = 2.4700  Validation loss = 5.4430  \n",
      "\n",
      "Fold: 5  Epoch: 476  Training loss = 2.4699  Validation loss = 5.4428  \n",
      "\n",
      "Fold: 5  Epoch: 477  Training loss = 2.4697  Validation loss = 5.4427  \n",
      "\n",
      "Fold: 5  Epoch: 478  Training loss = 2.4696  Validation loss = 5.4425  \n",
      "\n",
      "Fold: 5  Epoch: 479  Training loss = 2.4695  Validation loss = 5.4423  \n",
      "\n",
      "Fold: 5  Epoch: 480  Training loss = 2.4694  Validation loss = 5.4422  \n",
      "\n",
      "Fold: 5  Epoch: 481  Training loss = 2.4693  Validation loss = 5.4420  \n",
      "\n",
      "Fold: 5  Epoch: 482  Training loss = 2.4692  Validation loss = 5.4419  \n",
      "\n",
      "Fold: 5  Epoch: 483  Training loss = 2.4691  Validation loss = 5.4417  \n",
      "\n",
      "Fold: 5  Epoch: 484  Training loss = 2.4690  Validation loss = 5.4416  \n",
      "\n",
      "Fold: 5  Epoch: 485  Training loss = 2.4689  Validation loss = 5.4414  \n",
      "\n",
      "Fold: 5  Epoch: 486  Training loss = 2.4688  Validation loss = 5.4412  \n",
      "\n",
      "Fold: 5  Epoch: 487  Training loss = 2.4686  Validation loss = 5.4410  \n",
      "\n",
      "Fold: 5  Epoch: 488  Training loss = 2.4685  Validation loss = 5.4408  \n",
      "\n",
      "Fold: 5  Epoch: 489  Training loss = 2.4684  Validation loss = 5.4406  \n",
      "\n",
      "Fold: 5  Epoch: 490  Training loss = 2.4682  Validation loss = 5.4404  \n",
      "\n",
      "Fold: 5  Epoch: 491  Training loss = 2.4681  Validation loss = 5.4403  \n",
      "\n",
      "Fold: 5  Epoch: 492  Training loss = 2.4680  Validation loss = 5.4401  \n",
      "\n",
      "Fold: 5  Epoch: 493  Training loss = 2.4679  Validation loss = 5.4400  \n",
      "\n",
      "Fold: 5  Epoch: 494  Training loss = 2.4678  Validation loss = 5.4398  \n",
      "\n",
      "Fold: 5  Epoch: 495  Training loss = 2.4677  Validation loss = 5.4396  \n",
      "\n",
      "Fold: 5  Epoch: 496  Training loss = 2.4676  Validation loss = 5.4395  \n",
      "\n",
      "Fold: 5  Epoch: 497  Training loss = 2.4675  Validation loss = 5.4393  \n",
      "\n",
      "Fold: 5  Epoch: 498  Training loss = 2.4674  Validation loss = 5.4391  \n",
      "\n",
      "Fold: 5  Epoch: 499  Training loss = 2.4673  Validation loss = 5.4390  \n",
      "\n",
      "Fold: 5  Epoch: 500  Training loss = 2.4672  Validation loss = 5.4388  \n",
      "\n",
      "Check model:  Fold: 5  Optimal epoch: 500  \n",
      "\n",
      "Fold: 6  Epoch: 1  Training loss = 2.8067  Validation loss = 3.3346  \n",
      "\n",
      "Fold: 6  Epoch: 2  Training loss = 2.8066  Validation loss = 3.3344  \n",
      "\n",
      "Fold: 6  Epoch: 3  Training loss = 2.8064  Validation loss = 3.3341  \n",
      "\n",
      "Fold: 6  Epoch: 4  Training loss = 2.8062  Validation loss = 3.3338  \n",
      "\n",
      "Fold: 6  Epoch: 5  Training loss = 2.8060  Validation loss = 3.3335  \n",
      "\n",
      "Fold: 6  Epoch: 6  Training loss = 2.8059  Validation loss = 3.3332  \n",
      "\n",
      "Fold: 6  Epoch: 7  Training loss = 2.8057  Validation loss = 3.3329  \n",
      "\n",
      "Fold: 6  Epoch: 8  Training loss = 2.8056  Validation loss = 3.3327  \n",
      "\n",
      "Fold: 6  Epoch: 9  Training loss = 2.8054  Validation loss = 3.3325  \n",
      "\n",
      "Fold: 6  Epoch: 10  Training loss = 2.8053  Validation loss = 3.3323  \n",
      "\n",
      "Fold: 6  Epoch: 11  Training loss = 2.8052  Validation loss = 3.3320  \n",
      "\n",
      "Fold: 6  Epoch: 12  Training loss = 2.8050  Validation loss = 3.3318  \n",
      "\n",
      "Fold: 6  Epoch: 13  Training loss = 2.8048  Validation loss = 3.3315  \n",
      "\n",
      "Fold: 6  Epoch: 14  Training loss = 2.8047  Validation loss = 3.3313  \n",
      "\n",
      "Fold: 6  Epoch: 15  Training loss = 2.8045  Validation loss = 3.3310  \n",
      "\n",
      "Fold: 6  Epoch: 16  Training loss = 2.8044  Validation loss = 3.3307  \n",
      "\n",
      "Fold: 6  Epoch: 17  Training loss = 2.8042  Validation loss = 3.3304  \n",
      "\n",
      "Fold: 6  Epoch: 18  Training loss = 2.8040  Validation loss = 3.3302  \n",
      "\n",
      "Fold: 6  Epoch: 19  Training loss = 2.8039  Validation loss = 3.3299  \n",
      "\n",
      "Fold: 6  Epoch: 20  Training loss = 2.8037  Validation loss = 3.3296  \n",
      "\n",
      "Fold: 6  Epoch: 21  Training loss = 2.8036  Validation loss = 3.3294  \n",
      "\n",
      "Fold: 6  Epoch: 22  Training loss = 2.8034  Validation loss = 3.3291  \n",
      "\n",
      "Fold: 6  Epoch: 23  Training loss = 2.8032  Validation loss = 3.3288  \n",
      "\n",
      "Fold: 6  Epoch: 24  Training loss = 2.8031  Validation loss = 3.3286  \n",
      "\n",
      "Fold: 6  Epoch: 25  Training loss = 2.8029  Validation loss = 3.3283  \n",
      "\n",
      "Fold: 6  Epoch: 26  Training loss = 2.8028  Validation loss = 3.3280  \n",
      "\n",
      "Fold: 6  Epoch: 27  Training loss = 2.8026  Validation loss = 3.3278  \n",
      "\n",
      "Fold: 6  Epoch: 28  Training loss = 2.8024  Validation loss = 3.3275  \n",
      "\n",
      "Fold: 6  Epoch: 29  Training loss = 2.8023  Validation loss = 3.3273  \n",
      "\n",
      "Fold: 6  Epoch: 30  Training loss = 2.8021  Validation loss = 3.3270  \n",
      "\n",
      "Fold: 6  Epoch: 31  Training loss = 2.8019  Validation loss = 3.3267  \n",
      "\n",
      "Fold: 6  Epoch: 32  Training loss = 2.8018  Validation loss = 3.3265  \n",
      "\n",
      "Fold: 6  Epoch: 33  Training loss = 2.8017  Validation loss = 3.3263  \n",
      "\n",
      "Fold: 6  Epoch: 34  Training loss = 2.8015  Validation loss = 3.3260  \n",
      "\n",
      "Fold: 6  Epoch: 35  Training loss = 2.8013  Validation loss = 3.3257  \n",
      "\n",
      "Fold: 6  Epoch: 36  Training loss = 2.8012  Validation loss = 3.3255  \n",
      "\n",
      "Fold: 6  Epoch: 37  Training loss = 2.8010  Validation loss = 3.3251  \n",
      "\n",
      "Fold: 6  Epoch: 38  Training loss = 2.8009  Validation loss = 3.3249  \n",
      "\n",
      "Fold: 6  Epoch: 39  Training loss = 2.8008  Validation loss = 3.3247  \n",
      "\n",
      "Fold: 6  Epoch: 40  Training loss = 2.8006  Validation loss = 3.3245  \n",
      "\n",
      "Fold: 6  Epoch: 41  Training loss = 2.8004  Validation loss = 3.3241  \n",
      "\n",
      "Fold: 6  Epoch: 42  Training loss = 2.8003  Validation loss = 3.3239  \n",
      "\n",
      "Fold: 6  Epoch: 43  Training loss = 2.8001  Validation loss = 3.3236  \n",
      "\n",
      "Fold: 6  Epoch: 44  Training loss = 2.8000  Validation loss = 3.3234  \n",
      "\n",
      "Fold: 6  Epoch: 45  Training loss = 2.7998  Validation loss = 3.3231  \n",
      "\n",
      "Fold: 6  Epoch: 46  Training loss = 2.7996  Validation loss = 3.3228  \n",
      "\n",
      "Fold: 6  Epoch: 47  Training loss = 2.7994  Validation loss = 3.3225  \n",
      "\n",
      "Fold: 6  Epoch: 48  Training loss = 2.7993  Validation loss = 3.3222  \n",
      "\n",
      "Fold: 6  Epoch: 49  Training loss = 2.7991  Validation loss = 3.3220  \n",
      "\n",
      "Fold: 6  Epoch: 50  Training loss = 2.7990  Validation loss = 3.3217  \n",
      "\n",
      "Fold: 6  Epoch: 51  Training loss = 2.7988  Validation loss = 3.3214  \n",
      "\n",
      "Fold: 6  Epoch: 52  Training loss = 2.7987  Validation loss = 3.3212  \n",
      "\n",
      "Fold: 6  Epoch: 53  Training loss = 2.7985  Validation loss = 3.3210  \n",
      "\n",
      "Fold: 6  Epoch: 54  Training loss = 2.7984  Validation loss = 3.3207  \n",
      "\n",
      "Fold: 6  Epoch: 55  Training loss = 2.7982  Validation loss = 3.3205  \n",
      "\n",
      "Fold: 6  Epoch: 56  Training loss = 2.7981  Validation loss = 3.3203  \n",
      "\n",
      "Fold: 6  Epoch: 57  Training loss = 2.7979  Validation loss = 3.3200  \n",
      "\n",
      "Fold: 6  Epoch: 58  Training loss = 2.7978  Validation loss = 3.3197  \n",
      "\n",
      "Fold: 6  Epoch: 59  Training loss = 2.7976  Validation loss = 3.3194  \n",
      "\n",
      "Fold: 6  Epoch: 60  Training loss = 2.7975  Validation loss = 3.3192  \n",
      "\n",
      "Fold: 6  Epoch: 61  Training loss = 2.7973  Validation loss = 3.3189  \n",
      "\n",
      "Fold: 6  Epoch: 62  Training loss = 2.7971  Validation loss = 3.3186  \n",
      "\n",
      "Fold: 6  Epoch: 63  Training loss = 2.7969  Validation loss = 3.3183  \n",
      "\n",
      "Fold: 6  Epoch: 64  Training loss = 2.7968  Validation loss = 3.3181  \n",
      "\n",
      "Fold: 6  Epoch: 65  Training loss = 2.7966  Validation loss = 3.3178  \n",
      "\n",
      "Fold: 6  Epoch: 66  Training loss = 2.7965  Validation loss = 3.3176  \n",
      "\n",
      "Fold: 6  Epoch: 67  Training loss = 2.7963  Validation loss = 3.3173  \n",
      "\n",
      "Fold: 6  Epoch: 68  Training loss = 2.7962  Validation loss = 3.3172  \n",
      "\n",
      "Fold: 6  Epoch: 69  Training loss = 2.7961  Validation loss = 3.3169  \n",
      "\n",
      "Fold: 6  Epoch: 70  Training loss = 2.7959  Validation loss = 3.3166  \n",
      "\n",
      "Fold: 6  Epoch: 71  Training loss = 2.7957  Validation loss = 3.3163  \n",
      "\n",
      "Fold: 6  Epoch: 72  Training loss = 2.7956  Validation loss = 3.3161  \n",
      "\n",
      "Fold: 6  Epoch: 73  Training loss = 2.7955  Validation loss = 3.3159  \n",
      "\n",
      "Fold: 6  Epoch: 74  Training loss = 2.7953  Validation loss = 3.3156  \n",
      "\n",
      "Fold: 6  Epoch: 75  Training loss = 2.7951  Validation loss = 3.3153  \n",
      "\n",
      "Fold: 6  Epoch: 76  Training loss = 2.7949  Validation loss = 3.3150  \n",
      "\n",
      "Fold: 6  Epoch: 77  Training loss = 2.7948  Validation loss = 3.3147  \n",
      "\n",
      "Fold: 6  Epoch: 78  Training loss = 2.7946  Validation loss = 3.3145  \n",
      "\n",
      "Fold: 6  Epoch: 79  Training loss = 2.7945  Validation loss = 3.3142  \n",
      "\n",
      "Fold: 6  Epoch: 80  Training loss = 2.7943  Validation loss = 3.3139  \n",
      "\n",
      "Fold: 6  Epoch: 81  Training loss = 2.7942  Validation loss = 3.3137  \n",
      "\n",
      "Fold: 6  Epoch: 82  Training loss = 2.7940  Validation loss = 3.3134  \n",
      "\n",
      "Fold: 6  Epoch: 83  Training loss = 2.7938  Validation loss = 3.3131  \n",
      "\n",
      "Fold: 6  Epoch: 84  Training loss = 2.7937  Validation loss = 3.3129  \n",
      "\n",
      "Fold: 6  Epoch: 85  Training loss = 2.7935  Validation loss = 3.3126  \n",
      "\n",
      "Fold: 6  Epoch: 86  Training loss = 2.7934  Validation loss = 3.3124  \n",
      "\n",
      "Fold: 6  Epoch: 87  Training loss = 2.7933  Validation loss = 3.3122  \n",
      "\n",
      "Fold: 6  Epoch: 88  Training loss = 2.7931  Validation loss = 3.3119  \n",
      "\n",
      "Fold: 6  Epoch: 89  Training loss = 2.7930  Validation loss = 3.3117  \n",
      "\n",
      "Fold: 6  Epoch: 90  Training loss = 2.7928  Validation loss = 3.3115  \n",
      "\n",
      "Fold: 6  Epoch: 91  Training loss = 2.7927  Validation loss = 3.3112  \n",
      "\n",
      "Fold: 6  Epoch: 92  Training loss = 2.7925  Validation loss = 3.3109  \n",
      "\n",
      "Fold: 6  Epoch: 93  Training loss = 2.7924  Validation loss = 3.3108  \n",
      "\n",
      "Fold: 6  Epoch: 94  Training loss = 2.7922  Validation loss = 3.3104  \n",
      "\n",
      "Fold: 6  Epoch: 95  Training loss = 2.7920  Validation loss = 3.3101  \n",
      "\n",
      "Fold: 6  Epoch: 96  Training loss = 2.7918  Validation loss = 3.3098  \n",
      "\n",
      "Fold: 6  Epoch: 97  Training loss = 2.7917  Validation loss = 3.3095  \n",
      "\n",
      "Fold: 6  Epoch: 98  Training loss = 2.7915  Validation loss = 3.3092  \n",
      "\n",
      "Fold: 6  Epoch: 99  Training loss = 2.7913  Validation loss = 3.3089  \n",
      "\n",
      "Fold: 6  Epoch: 100  Training loss = 2.7912  Validation loss = 3.3087  \n",
      "\n",
      "Fold: 6  Epoch: 101  Training loss = 2.7910  Validation loss = 3.3085  \n",
      "\n",
      "Fold: 6  Epoch: 102  Training loss = 2.7909  Validation loss = 3.3082  \n",
      "\n",
      "Fold: 6  Epoch: 103  Training loss = 2.7907  Validation loss = 3.3080  \n",
      "\n",
      "Fold: 6  Epoch: 104  Training loss = 2.7906  Validation loss = 3.3077  \n",
      "\n",
      "Fold: 6  Epoch: 105  Training loss = 2.7904  Validation loss = 3.3074  \n",
      "\n",
      "Fold: 6  Epoch: 106  Training loss = 2.7903  Validation loss = 3.3072  \n",
      "\n",
      "Fold: 6  Epoch: 107  Training loss = 2.7901  Validation loss = 3.3069  \n",
      "\n",
      "Fold: 6  Epoch: 108  Training loss = 2.7899  Validation loss = 3.3066  \n",
      "\n",
      "Fold: 6  Epoch: 109  Training loss = 2.7898  Validation loss = 3.3064  \n",
      "\n",
      "Fold: 6  Epoch: 110  Training loss = 2.7897  Validation loss = 3.3061  \n",
      "\n",
      "Fold: 6  Epoch: 111  Training loss = 2.7895  Validation loss = 3.3059  \n",
      "\n",
      "Fold: 6  Epoch: 112  Training loss = 2.7894  Validation loss = 3.3057  \n",
      "\n",
      "Fold: 6  Epoch: 113  Training loss = 2.7892  Validation loss = 3.3053  \n",
      "\n",
      "Fold: 6  Epoch: 114  Training loss = 2.7890  Validation loss = 3.3051  \n",
      "\n",
      "Fold: 6  Epoch: 115  Training loss = 2.7889  Validation loss = 3.3048  \n",
      "\n",
      "Fold: 6  Epoch: 116  Training loss = 2.7887  Validation loss = 3.3046  \n",
      "\n",
      "Fold: 6  Epoch: 117  Training loss = 2.7886  Validation loss = 3.3044  \n",
      "\n",
      "Fold: 6  Epoch: 118  Training loss = 2.7884  Validation loss = 3.3041  \n",
      "\n",
      "Fold: 6  Epoch: 119  Training loss = 2.7883  Validation loss = 3.3039  \n",
      "\n",
      "Fold: 6  Epoch: 120  Training loss = 2.7881  Validation loss = 3.3036  \n",
      "\n",
      "Fold: 6  Epoch: 121  Training loss = 2.7880  Validation loss = 3.3033  \n",
      "\n",
      "Fold: 6  Epoch: 122  Training loss = 2.7878  Validation loss = 3.3030  \n",
      "\n",
      "Fold: 6  Epoch: 123  Training loss = 2.7876  Validation loss = 3.3028  \n",
      "\n",
      "Fold: 6  Epoch: 124  Training loss = 2.7875  Validation loss = 3.3025  \n",
      "\n",
      "Fold: 6  Epoch: 125  Training loss = 2.7873  Validation loss = 3.3022  \n",
      "\n",
      "Fold: 6  Epoch: 126  Training loss = 2.7871  Validation loss = 3.3019  \n",
      "\n",
      "Fold: 6  Epoch: 127  Training loss = 2.7870  Validation loss = 3.3017  \n",
      "\n",
      "Fold: 6  Epoch: 128  Training loss = 2.7868  Validation loss = 3.3014  \n",
      "\n",
      "Fold: 6  Epoch: 129  Training loss = 2.7867  Validation loss = 3.3012  \n",
      "\n",
      "Fold: 6  Epoch: 130  Training loss = 2.7865  Validation loss = 3.3008  \n",
      "\n",
      "Fold: 6  Epoch: 131  Training loss = 2.7863  Validation loss = 3.3005  \n",
      "\n",
      "Fold: 6  Epoch: 132  Training loss = 2.7861  Validation loss = 3.3002  \n",
      "\n",
      "Fold: 6  Epoch: 133  Training loss = 2.7860  Validation loss = 3.2999  \n",
      "\n",
      "Fold: 6  Epoch: 134  Training loss = 2.7858  Validation loss = 3.2997  \n",
      "\n",
      "Fold: 6  Epoch: 135  Training loss = 2.7857  Validation loss = 3.2995  \n",
      "\n",
      "Fold: 6  Epoch: 136  Training loss = 2.7855  Validation loss = 3.2992  \n",
      "\n",
      "Fold: 6  Epoch: 137  Training loss = 2.7854  Validation loss = 3.2989  \n",
      "\n",
      "Fold: 6  Epoch: 138  Training loss = 2.7852  Validation loss = 3.2987  \n",
      "\n",
      "Fold: 6  Epoch: 139  Training loss = 2.7851  Validation loss = 3.2985  \n",
      "\n",
      "Fold: 6  Epoch: 140  Training loss = 2.7849  Validation loss = 3.2982  \n",
      "\n",
      "Fold: 6  Epoch: 141  Training loss = 2.7848  Validation loss = 3.2980  \n",
      "\n",
      "Fold: 6  Epoch: 142  Training loss = 2.7847  Validation loss = 3.2978  \n",
      "\n",
      "Fold: 6  Epoch: 143  Training loss = 2.7845  Validation loss = 3.2975  \n",
      "\n",
      "Fold: 6  Epoch: 144  Training loss = 2.7844  Validation loss = 3.2973  \n",
      "\n",
      "Fold: 6  Epoch: 145  Training loss = 2.7842  Validation loss = 3.2970  \n",
      "\n",
      "Fold: 6  Epoch: 146  Training loss = 2.7841  Validation loss = 3.2968  \n",
      "\n",
      "Fold: 6  Epoch: 147  Training loss = 2.7839  Validation loss = 3.2966  \n",
      "\n",
      "Fold: 6  Epoch: 148  Training loss = 2.7838  Validation loss = 3.2963  \n",
      "\n",
      "Fold: 6  Epoch: 149  Training loss = 2.7836  Validation loss = 3.2960  \n",
      "\n",
      "Fold: 6  Epoch: 150  Training loss = 2.7835  Validation loss = 3.2958  \n",
      "\n",
      "Fold: 6  Epoch: 151  Training loss = 2.7833  Validation loss = 3.2955  \n",
      "\n",
      "Fold: 6  Epoch: 152  Training loss = 2.7831  Validation loss = 3.2952  \n",
      "\n",
      "Fold: 6  Epoch: 153  Training loss = 2.7830  Validation loss = 3.2950  \n",
      "\n",
      "Fold: 6  Epoch: 154  Training loss = 2.7829  Validation loss = 3.2948  \n",
      "\n",
      "Fold: 6  Epoch: 155  Training loss = 2.7827  Validation loss = 3.2945  \n",
      "\n",
      "Fold: 6  Epoch: 156  Training loss = 2.7825  Validation loss = 3.2942  \n",
      "\n",
      "Fold: 6  Epoch: 157  Training loss = 2.7824  Validation loss = 3.2939  \n",
      "\n",
      "Fold: 6  Epoch: 158  Training loss = 2.7822  Validation loss = 3.2936  \n",
      "\n",
      "Fold: 6  Epoch: 159  Training loss = 2.7820  Validation loss = 3.2933  \n",
      "\n",
      "Fold: 6  Epoch: 160  Training loss = 2.7819  Validation loss = 3.2930  \n",
      "\n",
      "Fold: 6  Epoch: 161  Training loss = 2.7817  Validation loss = 3.2927  \n",
      "\n",
      "Fold: 6  Epoch: 162  Training loss = 2.7815  Validation loss = 3.2925  \n",
      "\n",
      "Fold: 6  Epoch: 163  Training loss = 2.7814  Validation loss = 3.2922  \n",
      "\n",
      "Fold: 6  Epoch: 164  Training loss = 2.7812  Validation loss = 3.2920  \n",
      "\n",
      "Fold: 6  Epoch: 165  Training loss = 2.7811  Validation loss = 3.2917  \n",
      "\n",
      "Fold: 6  Epoch: 166  Training loss = 2.7810  Validation loss = 3.2915  \n",
      "\n",
      "Fold: 6  Epoch: 167  Training loss = 2.7808  Validation loss = 3.2912  \n",
      "\n",
      "Fold: 6  Epoch: 168  Training loss = 2.7806  Validation loss = 3.2910  \n",
      "\n",
      "Fold: 6  Epoch: 169  Training loss = 2.7805  Validation loss = 3.2907  \n",
      "\n",
      "Fold: 6  Epoch: 170  Training loss = 2.7804  Validation loss = 3.2905  \n",
      "\n",
      "Fold: 6  Epoch: 171  Training loss = 2.7802  Validation loss = 3.2903  \n",
      "\n",
      "Fold: 6  Epoch: 172  Training loss = 2.7801  Validation loss = 3.2901  \n",
      "\n",
      "Fold: 6  Epoch: 173  Training loss = 2.7799  Validation loss = 3.2898  \n",
      "\n",
      "Fold: 6  Epoch: 174  Training loss = 2.7798  Validation loss = 3.2896  \n",
      "\n",
      "Fold: 6  Epoch: 175  Training loss = 2.7797  Validation loss = 3.2894  \n",
      "\n",
      "Fold: 6  Epoch: 176  Training loss = 2.7796  Validation loss = 3.2892  \n",
      "\n",
      "Fold: 6  Epoch: 177  Training loss = 2.7794  Validation loss = 3.2890  \n",
      "\n",
      "Fold: 6  Epoch: 178  Training loss = 2.7793  Validation loss = 3.2887  \n",
      "\n",
      "Fold: 6  Epoch: 179  Training loss = 2.7791  Validation loss = 3.2884  \n",
      "\n",
      "Fold: 6  Epoch: 180  Training loss = 2.7790  Validation loss = 3.2882  \n",
      "\n",
      "Fold: 6  Epoch: 181  Training loss = 2.7788  Validation loss = 3.2880  \n",
      "\n",
      "Fold: 6  Epoch: 182  Training loss = 2.7787  Validation loss = 3.2877  \n",
      "\n",
      "Fold: 6  Epoch: 183  Training loss = 2.7785  Validation loss = 3.2875  \n",
      "\n",
      "Fold: 6  Epoch: 184  Training loss = 2.7784  Validation loss = 3.2872  \n",
      "\n",
      "Fold: 6  Epoch: 185  Training loss = 2.7783  Validation loss = 3.2870  \n",
      "\n",
      "Fold: 6  Epoch: 186  Training loss = 2.7781  Validation loss = 3.2868  \n",
      "\n",
      "Fold: 6  Epoch: 187  Training loss = 2.7780  Validation loss = 3.2865  \n",
      "\n",
      "Fold: 6  Epoch: 188  Training loss = 2.7778  Validation loss = 3.2863  \n",
      "\n",
      "Fold: 6  Epoch: 189  Training loss = 2.7777  Validation loss = 3.2861  \n",
      "\n",
      "Fold: 6  Epoch: 190  Training loss = 2.7776  Validation loss = 3.2859  \n",
      "\n",
      "Fold: 6  Epoch: 191  Training loss = 2.7774  Validation loss = 3.2857  \n",
      "\n",
      "Fold: 6  Epoch: 192  Training loss = 2.7773  Validation loss = 3.2854  \n",
      "\n",
      "Fold: 6  Epoch: 193  Training loss = 2.7771  Validation loss = 3.2851  \n",
      "\n",
      "Fold: 6  Epoch: 194  Training loss = 2.7770  Validation loss = 3.2849  \n",
      "\n",
      "Fold: 6  Epoch: 195  Training loss = 2.7768  Validation loss = 3.2846  \n",
      "\n",
      "Fold: 6  Epoch: 196  Training loss = 2.7767  Validation loss = 3.2844  \n",
      "\n",
      "Fold: 6  Epoch: 197  Training loss = 2.7765  Validation loss = 3.2841  \n",
      "\n",
      "Fold: 6  Epoch: 198  Training loss = 2.7764  Validation loss = 3.2839  \n",
      "\n",
      "Fold: 6  Epoch: 199  Training loss = 2.7762  Validation loss = 3.2836  \n",
      "\n",
      "Fold: 6  Epoch: 200  Training loss = 2.7760  Validation loss = 3.2833  \n",
      "\n",
      "Fold: 6  Epoch: 201  Training loss = 2.7758  Validation loss = 3.2830  \n",
      "\n",
      "Fold: 6  Epoch: 202  Training loss = 2.7757  Validation loss = 3.2826  \n",
      "\n",
      "Fold: 6  Epoch: 203  Training loss = 2.7755  Validation loss = 3.2824  \n",
      "\n",
      "Fold: 6  Epoch: 204  Training loss = 2.7753  Validation loss = 3.2821  \n",
      "\n",
      "Fold: 6  Epoch: 205  Training loss = 2.7752  Validation loss = 3.2818  \n",
      "\n",
      "Fold: 6  Epoch: 206  Training loss = 2.7750  Validation loss = 3.2816  \n",
      "\n",
      "Fold: 6  Epoch: 207  Training loss = 2.7749  Validation loss = 3.2813  \n",
      "\n",
      "Fold: 6  Epoch: 208  Training loss = 2.7747  Validation loss = 3.2810  \n",
      "\n",
      "Fold: 6  Epoch: 209  Training loss = 2.7745  Validation loss = 3.2807  \n",
      "\n",
      "Fold: 6  Epoch: 210  Training loss = 2.7744  Validation loss = 3.2805  \n",
      "\n",
      "Fold: 6  Epoch: 211  Training loss = 2.7742  Validation loss = 3.2802  \n",
      "\n",
      "Fold: 6  Epoch: 212  Training loss = 2.7740  Validation loss = 3.2799  \n",
      "\n",
      "Fold: 6  Epoch: 213  Training loss = 2.7739  Validation loss = 3.2797  \n",
      "\n",
      "Fold: 6  Epoch: 214  Training loss = 2.7738  Validation loss = 3.2794  \n",
      "\n",
      "Fold: 6  Epoch: 215  Training loss = 2.7736  Validation loss = 3.2792  \n",
      "\n",
      "Fold: 6  Epoch: 216  Training loss = 2.7735  Validation loss = 3.2789  \n",
      "\n",
      "Fold: 6  Epoch: 217  Training loss = 2.7733  Validation loss = 3.2787  \n",
      "\n",
      "Fold: 6  Epoch: 218  Training loss = 2.7732  Validation loss = 3.2784  \n",
      "\n",
      "Fold: 6  Epoch: 219  Training loss = 2.7730  Validation loss = 3.2782  \n",
      "\n",
      "Fold: 6  Epoch: 220  Training loss = 2.7729  Validation loss = 3.2779  \n",
      "\n",
      "Fold: 6  Epoch: 221  Training loss = 2.7727  Validation loss = 3.2776  \n",
      "\n",
      "Fold: 6  Epoch: 222  Training loss = 2.7725  Validation loss = 3.2773  \n",
      "\n",
      "Fold: 6  Epoch: 223  Training loss = 2.7724  Validation loss = 3.2770  \n",
      "\n",
      "Fold: 6  Epoch: 224  Training loss = 2.7722  Validation loss = 3.2768  \n",
      "\n",
      "Fold: 6  Epoch: 225  Training loss = 2.7721  Validation loss = 3.2765  \n",
      "\n",
      "Fold: 6  Epoch: 226  Training loss = 2.7719  Validation loss = 3.2764  \n",
      "\n",
      "Fold: 6  Epoch: 227  Training loss = 2.7718  Validation loss = 3.2762  \n",
      "\n",
      "Fold: 6  Epoch: 228  Training loss = 2.7717  Validation loss = 3.2760  \n",
      "\n",
      "Fold: 6  Epoch: 229  Training loss = 2.7715  Validation loss = 3.2757  \n",
      "\n",
      "Fold: 6  Epoch: 230  Training loss = 2.7714  Validation loss = 3.2754  \n",
      "\n",
      "Fold: 6  Epoch: 231  Training loss = 2.7713  Validation loss = 3.2752  \n",
      "\n",
      "Fold: 6  Epoch: 232  Training loss = 2.7711  Validation loss = 3.2750  \n",
      "\n",
      "Fold: 6  Epoch: 233  Training loss = 2.7710  Validation loss = 3.2747  \n",
      "\n",
      "Fold: 6  Epoch: 234  Training loss = 2.7708  Validation loss = 3.2744  \n",
      "\n",
      "Fold: 6  Epoch: 235  Training loss = 2.7707  Validation loss = 3.2742  \n",
      "\n",
      "Fold: 6  Epoch: 236  Training loss = 2.7705  Validation loss = 3.2739  \n",
      "\n",
      "Fold: 6  Epoch: 237  Training loss = 2.7704  Validation loss = 3.2737  \n",
      "\n",
      "Fold: 6  Epoch: 238  Training loss = 2.7702  Validation loss = 3.2734  \n",
      "\n",
      "Fold: 6  Epoch: 239  Training loss = 2.7701  Validation loss = 3.2732  \n",
      "\n",
      "Fold: 6  Epoch: 240  Training loss = 2.7699  Validation loss = 3.2730  \n",
      "\n",
      "Fold: 6  Epoch: 241  Training loss = 2.7698  Validation loss = 3.2728  \n",
      "\n",
      "Fold: 6  Epoch: 242  Training loss = 2.7697  Validation loss = 3.2726  \n",
      "\n",
      "Fold: 6  Epoch: 243  Training loss = 2.7696  Validation loss = 3.2724  \n",
      "\n",
      "Fold: 6  Epoch: 244  Training loss = 2.7694  Validation loss = 3.2721  \n",
      "\n",
      "Fold: 6  Epoch: 245  Training loss = 2.7693  Validation loss = 3.2719  \n",
      "\n",
      "Fold: 6  Epoch: 246  Training loss = 2.7691  Validation loss = 3.2716  \n",
      "\n",
      "Fold: 6  Epoch: 247  Training loss = 2.7690  Validation loss = 3.2714  \n",
      "\n",
      "Fold: 6  Epoch: 248  Training loss = 2.7689  Validation loss = 3.2712  \n",
      "\n",
      "Fold: 6  Epoch: 249  Training loss = 2.7687  Validation loss = 3.2710  \n",
      "\n",
      "Fold: 6  Epoch: 250  Training loss = 2.7686  Validation loss = 3.2707  \n",
      "\n",
      "Fold: 6  Epoch: 251  Training loss = 2.7684  Validation loss = 3.2704  \n",
      "\n",
      "Fold: 6  Epoch: 252  Training loss = 2.7682  Validation loss = 3.2701  \n",
      "\n",
      "Fold: 6  Epoch: 253  Training loss = 2.7681  Validation loss = 3.2699  \n",
      "\n",
      "Fold: 6  Epoch: 254  Training loss = 2.7679  Validation loss = 3.2696  \n",
      "\n",
      "Fold: 6  Epoch: 255  Training loss = 2.7678  Validation loss = 3.2694  \n",
      "\n",
      "Fold: 6  Epoch: 256  Training loss = 2.7676  Validation loss = 3.2691  \n",
      "\n",
      "Fold: 6  Epoch: 257  Training loss = 2.7675  Validation loss = 3.2688  \n",
      "\n",
      "Fold: 6  Epoch: 258  Training loss = 2.7673  Validation loss = 3.2686  \n",
      "\n",
      "Fold: 6  Epoch: 259  Training loss = 2.7672  Validation loss = 3.2684  \n",
      "\n",
      "Fold: 6  Epoch: 260  Training loss = 2.7670  Validation loss = 3.2681  \n",
      "\n",
      "Fold: 6  Epoch: 261  Training loss = 2.7669  Validation loss = 3.2678  \n",
      "\n",
      "Fold: 6  Epoch: 262  Training loss = 2.7667  Validation loss = 3.2675  \n",
      "\n",
      "Fold: 6  Epoch: 263  Training loss = 2.7665  Validation loss = 3.2673  \n",
      "\n",
      "Fold: 6  Epoch: 264  Training loss = 2.7664  Validation loss = 3.2671  \n",
      "\n",
      "Fold: 6  Epoch: 265  Training loss = 2.7663  Validation loss = 3.2668  \n",
      "\n",
      "Fold: 6  Epoch: 266  Training loss = 2.7661  Validation loss = 3.2666  \n",
      "\n",
      "Fold: 6  Epoch: 267  Training loss = 2.7659  Validation loss = 3.2662  \n",
      "\n",
      "Fold: 6  Epoch: 268  Training loss = 2.7657  Validation loss = 3.2659  \n",
      "\n",
      "Fold: 6  Epoch: 269  Training loss = 2.7656  Validation loss = 3.2657  \n",
      "\n",
      "Fold: 6  Epoch: 270  Training loss = 2.7655  Validation loss = 3.2655  \n",
      "\n",
      "Fold: 6  Epoch: 271  Training loss = 2.7653  Validation loss = 3.2652  \n",
      "\n",
      "Fold: 6  Epoch: 272  Training loss = 2.7651  Validation loss = 3.2649  \n",
      "\n",
      "Fold: 6  Epoch: 273  Training loss = 2.7650  Validation loss = 3.2647  \n",
      "\n",
      "Fold: 6  Epoch: 274  Training loss = 2.7648  Validation loss = 3.2644  \n",
      "\n",
      "Fold: 6  Epoch: 275  Training loss = 2.7647  Validation loss = 3.2642  \n",
      "\n",
      "Fold: 6  Epoch: 276  Training loss = 2.7646  Validation loss = 3.2639  \n",
      "\n",
      "Fold: 6  Epoch: 277  Training loss = 2.7644  Validation loss = 3.2637  \n",
      "\n",
      "Fold: 6  Epoch: 278  Training loss = 2.7643  Validation loss = 3.2635  \n",
      "\n",
      "Fold: 6  Epoch: 279  Training loss = 2.7641  Validation loss = 3.2632  \n",
      "\n",
      "Fold: 6  Epoch: 280  Training loss = 2.7640  Validation loss = 3.2629  \n",
      "\n",
      "Fold: 6  Epoch: 281  Training loss = 2.7639  Validation loss = 3.2627  \n",
      "\n",
      "Fold: 6  Epoch: 282  Training loss = 2.7637  Validation loss = 3.2624  \n",
      "\n",
      "Fold: 6  Epoch: 283  Training loss = 2.7635  Validation loss = 3.2622  \n",
      "\n",
      "Fold: 6  Epoch: 284  Training loss = 2.7633  Validation loss = 3.2618  \n",
      "\n",
      "Fold: 6  Epoch: 285  Training loss = 2.7632  Validation loss = 3.2616  \n",
      "\n",
      "Fold: 6  Epoch: 286  Training loss = 2.7631  Validation loss = 3.2614  \n",
      "\n",
      "Fold: 6  Epoch: 287  Training loss = 2.7629  Validation loss = 3.2611  \n",
      "\n",
      "Fold: 6  Epoch: 288  Training loss = 2.7628  Validation loss = 3.2609  \n",
      "\n",
      "Fold: 6  Epoch: 289  Training loss = 2.7626  Validation loss = 3.2606  \n",
      "\n",
      "Fold: 6  Epoch: 290  Training loss = 2.7625  Validation loss = 3.2604  \n",
      "\n",
      "Fold: 6  Epoch: 291  Training loss = 2.7623  Validation loss = 3.2601  \n",
      "\n",
      "Fold: 6  Epoch: 292  Training loss = 2.7622  Validation loss = 3.2598  \n",
      "\n",
      "Fold: 6  Epoch: 293  Training loss = 2.7620  Validation loss = 3.2596  \n",
      "\n",
      "Fold: 6  Epoch: 294  Training loss = 2.7619  Validation loss = 3.2593  \n",
      "\n",
      "Fold: 6  Epoch: 295  Training loss = 2.7617  Validation loss = 3.2591  \n",
      "\n",
      "Fold: 6  Epoch: 296  Training loss = 2.7616  Validation loss = 3.2589  \n",
      "\n",
      "Fold: 6  Epoch: 297  Training loss = 2.7615  Validation loss = 3.2587  \n",
      "\n",
      "Fold: 6  Epoch: 298  Training loss = 2.7613  Validation loss = 3.2585  \n",
      "\n",
      "Fold: 6  Epoch: 299  Training loss = 2.7612  Validation loss = 3.2582  \n",
      "\n",
      "Fold: 6  Epoch: 300  Training loss = 2.7610  Validation loss = 3.2579  \n",
      "\n",
      "Fold: 6  Epoch: 301  Training loss = 2.7609  Validation loss = 3.2576  \n",
      "\n",
      "Fold: 6  Epoch: 302  Training loss = 2.7607  Validation loss = 3.2574  \n",
      "\n",
      "Fold: 6  Epoch: 303  Training loss = 2.7606  Validation loss = 3.2573  \n",
      "\n",
      "Fold: 6  Epoch: 304  Training loss = 2.7605  Validation loss = 3.2570  \n",
      "\n",
      "Fold: 6  Epoch: 305  Training loss = 2.7603  Validation loss = 3.2567  \n",
      "\n",
      "Fold: 6  Epoch: 306  Training loss = 2.7602  Validation loss = 3.2565  \n",
      "\n",
      "Fold: 6  Epoch: 307  Training loss = 2.7600  Validation loss = 3.2562  \n",
      "\n",
      "Fold: 6  Epoch: 308  Training loss = 2.7599  Validation loss = 3.2560  \n",
      "\n",
      "Fold: 6  Epoch: 309  Training loss = 2.7597  Validation loss = 3.2557  \n",
      "\n",
      "Fold: 6  Epoch: 310  Training loss = 2.7596  Validation loss = 3.2554  \n",
      "\n",
      "Fold: 6  Epoch: 311  Training loss = 2.7594  Validation loss = 3.2552  \n",
      "\n",
      "Fold: 6  Epoch: 312  Training loss = 2.7593  Validation loss = 3.2550  \n",
      "\n",
      "Fold: 6  Epoch: 313  Training loss = 2.7591  Validation loss = 3.2547  \n",
      "\n",
      "Fold: 6  Epoch: 314  Training loss = 2.7590  Validation loss = 3.2545  \n",
      "\n",
      "Fold: 6  Epoch: 315  Training loss = 2.7588  Validation loss = 3.2542  \n",
      "\n",
      "Fold: 6  Epoch: 316  Training loss = 2.7587  Validation loss = 3.2539  \n",
      "\n",
      "Fold: 6  Epoch: 317  Training loss = 2.7585  Validation loss = 3.2536  \n",
      "\n",
      "Fold: 6  Epoch: 318  Training loss = 2.7584  Validation loss = 3.2534  \n",
      "\n",
      "Fold: 6  Epoch: 319  Training loss = 2.7582  Validation loss = 3.2531  \n",
      "\n",
      "Fold: 6  Epoch: 320  Training loss = 2.7581  Validation loss = 3.2528  \n",
      "\n",
      "Fold: 6  Epoch: 321  Training loss = 2.7579  Validation loss = 3.2526  \n",
      "\n",
      "Fold: 6  Epoch: 322  Training loss = 2.7578  Validation loss = 3.2524  \n",
      "\n",
      "Fold: 6  Epoch: 323  Training loss = 2.7577  Validation loss = 3.2522  \n",
      "\n",
      "Fold: 6  Epoch: 324  Training loss = 2.7575  Validation loss = 3.2519  \n",
      "\n",
      "Fold: 6  Epoch: 325  Training loss = 2.7574  Validation loss = 3.2517  \n",
      "\n",
      "Fold: 6  Epoch: 326  Training loss = 2.7572  Validation loss = 3.2514  \n",
      "\n",
      "Fold: 6  Epoch: 327  Training loss = 2.7571  Validation loss = 3.2512  \n",
      "\n",
      "Fold: 6  Epoch: 328  Training loss = 2.7570  Validation loss = 3.2510  \n",
      "\n",
      "Fold: 6  Epoch: 329  Training loss = 2.7568  Validation loss = 3.2508  \n",
      "\n",
      "Fold: 6  Epoch: 330  Training loss = 2.7567  Validation loss = 3.2505  \n",
      "\n",
      "Fold: 6  Epoch: 331  Training loss = 2.7565  Validation loss = 3.2501  \n",
      "\n",
      "Fold: 6  Epoch: 332  Training loss = 2.7563  Validation loss = 3.2499  \n",
      "\n",
      "Fold: 6  Epoch: 333  Training loss = 2.7562  Validation loss = 3.2496  \n",
      "\n",
      "Fold: 6  Epoch: 334  Training loss = 2.7560  Validation loss = 3.2492  \n",
      "\n",
      "Fold: 6  Epoch: 335  Training loss = 2.7558  Validation loss = 3.2490  \n",
      "\n",
      "Fold: 6  Epoch: 336  Training loss = 2.7556  Validation loss = 3.2487  \n",
      "\n",
      "Fold: 6  Epoch: 337  Training loss = 2.7555  Validation loss = 3.2485  \n",
      "\n",
      "Fold: 6  Epoch: 338  Training loss = 2.7553  Validation loss = 3.2482  \n",
      "\n",
      "Fold: 6  Epoch: 339  Training loss = 2.7552  Validation loss = 3.2479  \n",
      "\n",
      "Fold: 6  Epoch: 340  Training loss = 2.7550  Validation loss = 3.2476  \n",
      "\n",
      "Fold: 6  Epoch: 341  Training loss = 2.7549  Validation loss = 3.2474  \n",
      "\n",
      "Fold: 6  Epoch: 342  Training loss = 2.7548  Validation loss = 3.2472  \n",
      "\n",
      "Fold: 6  Epoch: 343  Training loss = 2.7546  Validation loss = 3.2469  \n",
      "\n",
      "Fold: 6  Epoch: 344  Training loss = 2.7544  Validation loss = 3.2467  \n",
      "\n",
      "Fold: 6  Epoch: 345  Training loss = 2.7543  Validation loss = 3.2464  \n",
      "\n",
      "Fold: 6  Epoch: 346  Training loss = 2.7541  Validation loss = 3.2461  \n",
      "\n",
      "Fold: 6  Epoch: 347  Training loss = 2.7540  Validation loss = 3.2459  \n",
      "\n",
      "Fold: 6  Epoch: 348  Training loss = 2.7539  Validation loss = 3.2457  \n",
      "\n",
      "Fold: 6  Epoch: 349  Training loss = 2.7537  Validation loss = 3.2454  \n",
      "\n",
      "Fold: 6  Epoch: 350  Training loss = 2.7536  Validation loss = 3.2452  \n",
      "\n",
      "Fold: 6  Epoch: 351  Training loss = 2.7534  Validation loss = 3.2449  \n",
      "\n",
      "Fold: 6  Epoch: 352  Training loss = 2.7533  Validation loss = 3.2446  \n",
      "\n",
      "Fold: 6  Epoch: 353  Training loss = 2.7531  Validation loss = 3.2444  \n",
      "\n",
      "Fold: 6  Epoch: 354  Training loss = 2.7530  Validation loss = 3.2441  \n",
      "\n",
      "Fold: 6  Epoch: 355  Training loss = 2.7528  Validation loss = 3.2439  \n",
      "\n",
      "Fold: 6  Epoch: 356  Training loss = 2.7527  Validation loss = 3.2436  \n",
      "\n",
      "Fold: 6  Epoch: 357  Training loss = 2.7525  Validation loss = 3.2433  \n",
      "\n",
      "Fold: 6  Epoch: 358  Training loss = 2.7523  Validation loss = 3.2430  \n",
      "\n",
      "Fold: 6  Epoch: 359  Training loss = 2.7522  Validation loss = 3.2428  \n",
      "\n",
      "Fold: 6  Epoch: 360  Training loss = 2.7520  Validation loss = 3.2425  \n",
      "\n",
      "Fold: 6  Epoch: 361  Training loss = 2.7519  Validation loss = 3.2422  \n",
      "\n",
      "Fold: 6  Epoch: 362  Training loss = 2.7517  Validation loss = 3.2420  \n",
      "\n",
      "Fold: 6  Epoch: 363  Training loss = 2.7516  Validation loss = 3.2417  \n",
      "\n",
      "Fold: 6  Epoch: 364  Training loss = 2.7514  Validation loss = 3.2414  \n",
      "\n",
      "Fold: 6  Epoch: 365  Training loss = 2.7513  Validation loss = 3.2411  \n",
      "\n",
      "Fold: 6  Epoch: 366  Training loss = 2.7511  Validation loss = 3.2409  \n",
      "\n",
      "Fold: 6  Epoch: 367  Training loss = 2.7510  Validation loss = 3.2407  \n",
      "\n",
      "Fold: 6  Epoch: 368  Training loss = 2.7508  Validation loss = 3.2404  \n",
      "\n",
      "Fold: 6  Epoch: 369  Training loss = 2.7507  Validation loss = 3.2402  \n",
      "\n",
      "Fold: 6  Epoch: 370  Training loss = 2.7505  Validation loss = 3.2399  \n",
      "\n",
      "Fold: 6  Epoch: 371  Training loss = 2.7504  Validation loss = 3.2397  \n",
      "\n",
      "Fold: 6  Epoch: 372  Training loss = 2.7502  Validation loss = 3.2394  \n",
      "\n",
      "Fold: 6  Epoch: 373  Training loss = 2.7501  Validation loss = 3.2392  \n",
      "\n",
      "Fold: 6  Epoch: 374  Training loss = 2.7500  Validation loss = 3.2390  \n",
      "\n",
      "Fold: 6  Epoch: 375  Training loss = 2.7498  Validation loss = 3.2386  \n",
      "\n",
      "Fold: 6  Epoch: 376  Training loss = 2.7496  Validation loss = 3.2383  \n",
      "\n",
      "Fold: 6  Epoch: 377  Training loss = 2.7495  Validation loss = 3.2381  \n",
      "\n",
      "Fold: 6  Epoch: 378  Training loss = 2.7493  Validation loss = 3.2378  \n",
      "\n",
      "Fold: 6  Epoch: 379  Training loss = 2.7492  Validation loss = 3.2375  \n",
      "\n",
      "Fold: 6  Epoch: 380  Training loss = 2.7490  Validation loss = 3.2373  \n",
      "\n",
      "Fold: 6  Epoch: 381  Training loss = 2.7489  Validation loss = 3.2371  \n",
      "\n",
      "Fold: 6  Epoch: 382  Training loss = 2.7488  Validation loss = 3.2369  \n",
      "\n",
      "Fold: 6  Epoch: 383  Training loss = 2.7486  Validation loss = 3.2366  \n",
      "\n",
      "Fold: 6  Epoch: 384  Training loss = 2.7485  Validation loss = 3.2364  \n",
      "\n",
      "Fold: 6  Epoch: 385  Training loss = 2.7483  Validation loss = 3.2361  \n",
      "\n",
      "Fold: 6  Epoch: 386  Training loss = 2.7482  Validation loss = 3.2359  \n",
      "\n",
      "Fold: 6  Epoch: 387  Training loss = 2.7481  Validation loss = 3.2357  \n",
      "\n",
      "Fold: 6  Epoch: 388  Training loss = 2.7479  Validation loss = 3.2354  \n",
      "\n",
      "Fold: 6  Epoch: 389  Training loss = 2.7478  Validation loss = 3.2352  \n",
      "\n",
      "Fold: 6  Epoch: 390  Training loss = 2.7477  Validation loss = 3.2350  \n",
      "\n",
      "Fold: 6  Epoch: 391  Training loss = 2.7475  Validation loss = 3.2347  \n",
      "\n",
      "Fold: 6  Epoch: 392  Training loss = 2.7473  Validation loss = 3.2344  \n",
      "\n",
      "Fold: 6  Epoch: 393  Training loss = 2.7472  Validation loss = 3.2342  \n",
      "\n",
      "Fold: 6  Epoch: 394  Training loss = 2.7470  Validation loss = 3.2339  \n",
      "\n",
      "Fold: 6  Epoch: 395  Training loss = 2.7469  Validation loss = 3.2336  \n",
      "\n",
      "Fold: 6  Epoch: 396  Training loss = 2.7467  Validation loss = 3.2334  \n",
      "\n",
      "Fold: 6  Epoch: 397  Training loss = 2.7466  Validation loss = 3.2332  \n",
      "\n",
      "Fold: 6  Epoch: 398  Training loss = 2.7464  Validation loss = 3.2329  \n",
      "\n",
      "Fold: 6  Epoch: 399  Training loss = 2.7463  Validation loss = 3.2326  \n",
      "\n",
      "Fold: 6  Epoch: 400  Training loss = 2.7461  Validation loss = 3.2324  \n",
      "\n",
      "Fold: 6  Epoch: 401  Training loss = 2.7460  Validation loss = 3.2322  \n",
      "\n",
      "Fold: 6  Epoch: 402  Training loss = 2.7458  Validation loss = 3.2319  \n",
      "\n",
      "Fold: 6  Epoch: 403  Training loss = 2.7456  Validation loss = 3.2315  \n",
      "\n",
      "Fold: 6  Epoch: 404  Training loss = 2.7455  Validation loss = 3.2313  \n",
      "\n",
      "Fold: 6  Epoch: 405  Training loss = 2.7454  Validation loss = 3.2311  \n",
      "\n",
      "Fold: 6  Epoch: 406  Training loss = 2.7452  Validation loss = 3.2308  \n",
      "\n",
      "Fold: 6  Epoch: 407  Training loss = 2.7451  Validation loss = 3.2306  \n",
      "\n",
      "Fold: 6  Epoch: 408  Training loss = 2.7449  Validation loss = 3.2303  \n",
      "\n",
      "Fold: 6  Epoch: 409  Training loss = 2.7448  Validation loss = 3.2301  \n",
      "\n",
      "Fold: 6  Epoch: 410  Training loss = 2.7447  Validation loss = 3.2299  \n",
      "\n",
      "Fold: 6  Epoch: 411  Training loss = 2.7445  Validation loss = 3.2296  \n",
      "\n",
      "Fold: 6  Epoch: 412  Training loss = 2.7444  Validation loss = 3.2294  \n",
      "\n",
      "Fold: 6  Epoch: 413  Training loss = 2.7442  Validation loss = 3.2291  \n",
      "\n",
      "Fold: 6  Epoch: 414  Training loss = 2.7440  Validation loss = 3.2288  \n",
      "\n",
      "Fold: 6  Epoch: 415  Training loss = 2.7439  Validation loss = 3.2286  \n",
      "\n",
      "Fold: 6  Epoch: 416  Training loss = 2.7438  Validation loss = 3.2283  \n",
      "\n",
      "Fold: 6  Epoch: 417  Training loss = 2.7436  Validation loss = 3.2281  \n",
      "\n",
      "Fold: 6  Epoch: 418  Training loss = 2.7435  Validation loss = 3.2278  \n",
      "\n",
      "Fold: 6  Epoch: 419  Training loss = 2.7433  Validation loss = 3.2275  \n",
      "\n",
      "Fold: 6  Epoch: 420  Training loss = 2.7432  Validation loss = 3.2272  \n",
      "\n",
      "Fold: 6  Epoch: 421  Training loss = 2.7430  Validation loss = 3.2268  \n",
      "\n",
      "Fold: 6  Epoch: 422  Training loss = 2.7428  Validation loss = 3.2265  \n",
      "\n",
      "Fold: 6  Epoch: 423  Training loss = 2.7427  Validation loss = 3.2263  \n",
      "\n",
      "Fold: 6  Epoch: 424  Training loss = 2.7425  Validation loss = 3.2261  \n",
      "\n",
      "Fold: 6  Epoch: 425  Training loss = 2.7425  Validation loss = 3.2260  \n",
      "\n",
      "Fold: 6  Epoch: 426  Training loss = 2.7423  Validation loss = 3.2257  \n",
      "\n",
      "Fold: 6  Epoch: 427  Training loss = 2.7422  Validation loss = 3.2255  \n",
      "\n",
      "Fold: 6  Epoch: 428  Training loss = 2.7420  Validation loss = 3.2253  \n",
      "\n",
      "Fold: 6  Epoch: 429  Training loss = 2.7419  Validation loss = 3.2250  \n",
      "\n",
      "Fold: 6  Epoch: 430  Training loss = 2.7417  Validation loss = 3.2248  \n",
      "\n",
      "Fold: 6  Epoch: 431  Training loss = 2.7416  Validation loss = 3.2246  \n",
      "\n",
      "Fold: 6  Epoch: 432  Training loss = 2.7415  Validation loss = 3.2244  \n",
      "\n",
      "Fold: 6  Epoch: 433  Training loss = 2.7414  Validation loss = 3.2242  \n",
      "\n",
      "Fold: 6  Epoch: 434  Training loss = 2.7413  Validation loss = 3.2240  \n",
      "\n",
      "Fold: 6  Epoch: 435  Training loss = 2.7411  Validation loss = 3.2237  \n",
      "\n",
      "Fold: 6  Epoch: 436  Training loss = 2.7410  Validation loss = 3.2235  \n",
      "\n",
      "Fold: 6  Epoch: 437  Training loss = 2.7408  Validation loss = 3.2231  \n",
      "\n",
      "Fold: 6  Epoch: 438  Training loss = 2.7406  Validation loss = 3.2229  \n",
      "\n",
      "Fold: 6  Epoch: 439  Training loss = 2.7405  Validation loss = 3.2226  \n",
      "\n",
      "Fold: 6  Epoch: 440  Training loss = 2.7404  Validation loss = 3.2224  \n",
      "\n",
      "Fold: 6  Epoch: 441  Training loss = 2.7402  Validation loss = 3.2221  \n",
      "\n",
      "Fold: 6  Epoch: 442  Training loss = 2.7401  Validation loss = 3.2219  \n",
      "\n",
      "Fold: 6  Epoch: 443  Training loss = 2.7399  Validation loss = 3.2217  \n",
      "\n",
      "Fold: 6  Epoch: 444  Training loss = 2.7398  Validation loss = 3.2214  \n",
      "\n",
      "Fold: 6  Epoch: 445  Training loss = 2.7396  Validation loss = 3.2211  \n",
      "\n",
      "Fold: 6  Epoch: 446  Training loss = 2.7394  Validation loss = 3.2208  \n",
      "\n",
      "Fold: 6  Epoch: 447  Training loss = 2.7393  Validation loss = 3.2205  \n",
      "\n",
      "Fold: 6  Epoch: 448  Training loss = 2.7392  Validation loss = 3.2203  \n",
      "\n",
      "Fold: 6  Epoch: 449  Training loss = 2.7390  Validation loss = 3.2201  \n",
      "\n",
      "Fold: 6  Epoch: 450  Training loss = 2.7388  Validation loss = 3.2198  \n",
      "\n",
      "Fold: 6  Epoch: 451  Training loss = 2.7387  Validation loss = 3.2195  \n",
      "\n",
      "Fold: 6  Epoch: 452  Training loss = 2.7385  Validation loss = 3.2193  \n",
      "\n",
      "Fold: 6  Epoch: 453  Training loss = 2.7384  Validation loss = 3.2190  \n",
      "\n",
      "Fold: 6  Epoch: 454  Training loss = 2.7382  Validation loss = 3.2188  \n",
      "\n",
      "Fold: 6  Epoch: 455  Training loss = 2.7381  Validation loss = 3.2185  \n",
      "\n",
      "Fold: 6  Epoch: 456  Training loss = 2.7379  Validation loss = 3.2181  \n",
      "\n",
      "Fold: 6  Epoch: 457  Training loss = 2.7378  Validation loss = 3.2179  \n",
      "\n",
      "Fold: 6  Epoch: 458  Training loss = 2.7376  Validation loss = 3.2176  \n",
      "\n",
      "Fold: 6  Epoch: 459  Training loss = 2.7375  Validation loss = 3.2174  \n",
      "\n",
      "Fold: 6  Epoch: 460  Training loss = 2.7373  Validation loss = 3.2172  \n",
      "\n",
      "Fold: 6  Epoch: 461  Training loss = 2.7372  Validation loss = 3.2170  \n",
      "\n",
      "Fold: 6  Epoch: 462  Training loss = 2.7371  Validation loss = 3.2167  \n",
      "\n",
      "Fold: 6  Epoch: 463  Training loss = 2.7369  Validation loss = 3.2164  \n",
      "\n",
      "Fold: 6  Epoch: 464  Training loss = 2.7367  Validation loss = 3.2161  \n",
      "\n",
      "Fold: 6  Epoch: 465  Training loss = 2.7366  Validation loss = 3.2158  \n",
      "\n",
      "Fold: 6  Epoch: 466  Training loss = 2.7364  Validation loss = 3.2156  \n",
      "\n",
      "Fold: 6  Epoch: 467  Training loss = 2.7363  Validation loss = 3.2154  \n",
      "\n",
      "Fold: 6  Epoch: 468  Training loss = 2.7362  Validation loss = 3.2152  \n",
      "\n",
      "Fold: 6  Epoch: 469  Training loss = 2.7360  Validation loss = 3.2149  \n",
      "\n",
      "Fold: 6  Epoch: 470  Training loss = 2.7359  Validation loss = 3.2146  \n",
      "\n",
      "Fold: 6  Epoch: 471  Training loss = 2.7357  Validation loss = 3.2143  \n",
      "\n",
      "Fold: 6  Epoch: 472  Training loss = 2.7355  Validation loss = 3.2140  \n",
      "\n",
      "Fold: 6  Epoch: 473  Training loss = 2.7354  Validation loss = 3.2138  \n",
      "\n",
      "Fold: 6  Epoch: 474  Training loss = 2.7352  Validation loss = 3.2135  \n",
      "\n",
      "Fold: 6  Epoch: 475  Training loss = 2.7351  Validation loss = 3.2133  \n",
      "\n",
      "Fold: 6  Epoch: 476  Training loss = 2.7349  Validation loss = 3.2130  \n",
      "\n",
      "Fold: 6  Epoch: 477  Training loss = 2.7348  Validation loss = 3.2127  \n",
      "\n",
      "Fold: 6  Epoch: 478  Training loss = 2.7347  Validation loss = 3.2125  \n",
      "\n",
      "Fold: 6  Epoch: 479  Training loss = 2.7345  Validation loss = 3.2123  \n",
      "\n",
      "Fold: 6  Epoch: 480  Training loss = 2.7343  Validation loss = 3.2120  \n",
      "\n",
      "Fold: 6  Epoch: 481  Training loss = 2.7342  Validation loss = 3.2118  \n",
      "\n",
      "Fold: 6  Epoch: 482  Training loss = 2.7341  Validation loss = 3.2115  \n",
      "\n",
      "Fold: 6  Epoch: 483  Training loss = 2.7339  Validation loss = 3.2113  \n",
      "\n",
      "Fold: 6  Epoch: 484  Training loss = 2.7338  Validation loss = 3.2109  \n",
      "\n",
      "Fold: 6  Epoch: 485  Training loss = 2.7336  Validation loss = 3.2107  \n",
      "\n",
      "Fold: 6  Epoch: 486  Training loss = 2.7334  Validation loss = 3.2104  \n",
      "\n",
      "Fold: 6  Epoch: 487  Training loss = 2.7333  Validation loss = 3.2101  \n",
      "\n",
      "Fold: 6  Epoch: 488  Training loss = 2.7331  Validation loss = 3.2098  \n",
      "\n",
      "Fold: 6  Epoch: 489  Training loss = 2.7330  Validation loss = 3.2095  \n",
      "\n",
      "Fold: 6  Epoch: 490  Training loss = 2.7328  Validation loss = 3.2093  \n",
      "\n",
      "Fold: 6  Epoch: 491  Training loss = 2.7326  Validation loss = 3.2089  \n",
      "\n",
      "Fold: 6  Epoch: 492  Training loss = 2.7324  Validation loss = 3.2086  \n",
      "\n",
      "Fold: 6  Epoch: 493  Training loss = 2.7323  Validation loss = 3.2084  \n",
      "\n",
      "Fold: 6  Epoch: 494  Training loss = 2.7321  Validation loss = 3.2081  \n",
      "\n",
      "Fold: 6  Epoch: 495  Training loss = 2.7320  Validation loss = 3.2078  \n",
      "\n",
      "Fold: 6  Epoch: 496  Training loss = 2.7318  Validation loss = 3.2075  \n",
      "\n",
      "Fold: 6  Epoch: 497  Training loss = 2.7316  Validation loss = 3.2072  \n",
      "\n",
      "Fold: 6  Epoch: 498  Training loss = 2.7315  Validation loss = 3.2069  \n",
      "\n",
      "Fold: 6  Epoch: 499  Training loss = 2.7313  Validation loss = 3.2067  \n",
      "\n",
      "Fold: 6  Epoch: 500  Training loss = 2.7312  Validation loss = 3.2064  \n",
      "\n",
      "Check model:  Fold: 6  Optimal epoch: 500  \n",
      "\n",
      "Fold: 7  Epoch: 1  Training loss = 2.8325  Validation loss = 3.0201  \n",
      "\n",
      "Fold: 7  Epoch: 2  Training loss = 2.8323  Validation loss = 3.0197  \n",
      "\n",
      "Fold: 7  Epoch: 3  Training loss = 2.8321  Validation loss = 3.0194  \n",
      "\n",
      "Fold: 7  Epoch: 4  Training loss = 2.8319  Validation loss = 3.0191  \n",
      "\n",
      "Fold: 7  Epoch: 5  Training loss = 2.8317  Validation loss = 3.0188  \n",
      "\n",
      "Fold: 7  Epoch: 6  Training loss = 2.8315  Validation loss = 3.0185  \n",
      "\n",
      "Fold: 7  Epoch: 7  Training loss = 2.8313  Validation loss = 3.0182  \n",
      "\n",
      "Fold: 7  Epoch: 8  Training loss = 2.8311  Validation loss = 3.0179  \n",
      "\n",
      "Fold: 7  Epoch: 9  Training loss = 2.8309  Validation loss = 3.0176  \n",
      "\n",
      "Fold: 7  Epoch: 10  Training loss = 2.8307  Validation loss = 3.0173  \n",
      "\n",
      "Fold: 7  Epoch: 11  Training loss = 2.8305  Validation loss = 3.0170  \n",
      "\n",
      "Fold: 7  Epoch: 12  Training loss = 2.8303  Validation loss = 3.0166  \n",
      "\n",
      "Fold: 7  Epoch: 13  Training loss = 2.8301  Validation loss = 3.0163  \n",
      "\n",
      "Fold: 7  Epoch: 14  Training loss = 2.8300  Validation loss = 3.0160  \n",
      "\n",
      "Fold: 7  Epoch: 15  Training loss = 2.8298  Validation loss = 3.0157  \n",
      "\n",
      "Fold: 7  Epoch: 16  Training loss = 2.8296  Validation loss = 3.0154  \n",
      "\n",
      "Fold: 7  Epoch: 17  Training loss = 2.8294  Validation loss = 3.0150  \n",
      "\n",
      "Fold: 7  Epoch: 18  Training loss = 2.8292  Validation loss = 3.0147  \n",
      "\n",
      "Fold: 7  Epoch: 19  Training loss = 2.8290  Validation loss = 3.0144  \n",
      "\n",
      "Fold: 7  Epoch: 20  Training loss = 2.8288  Validation loss = 3.0141  \n",
      "\n",
      "Fold: 7  Epoch: 21  Training loss = 2.8286  Validation loss = 3.0139  \n",
      "\n",
      "Fold: 7  Epoch: 22  Training loss = 2.8285  Validation loss = 3.0136  \n",
      "\n",
      "Fold: 7  Epoch: 23  Training loss = 2.8283  Validation loss = 3.0133  \n",
      "\n",
      "Fold: 7  Epoch: 24  Training loss = 2.8281  Validation loss = 3.0131  \n",
      "\n",
      "Fold: 7  Epoch: 25  Training loss = 2.8280  Validation loss = 3.0128  \n",
      "\n",
      "Fold: 7  Epoch: 26  Training loss = 2.8278  Validation loss = 3.0126  \n",
      "\n",
      "Fold: 7  Epoch: 27  Training loss = 2.8276  Validation loss = 3.0123  \n",
      "\n",
      "Fold: 7  Epoch: 28  Training loss = 2.8274  Validation loss = 3.0120  \n",
      "\n",
      "Fold: 7  Epoch: 29  Training loss = 2.8273  Validation loss = 3.0118  \n",
      "\n",
      "Fold: 7  Epoch: 30  Training loss = 2.8270  Validation loss = 3.0114  \n",
      "\n",
      "Fold: 7  Epoch: 31  Training loss = 2.8269  Validation loss = 3.0112  \n",
      "\n",
      "Fold: 7  Epoch: 32  Training loss = 2.8267  Validation loss = 3.0109  \n",
      "\n",
      "Fold: 7  Epoch: 33  Training loss = 2.8265  Validation loss = 3.0106  \n",
      "\n",
      "Fold: 7  Epoch: 34  Training loss = 2.8264  Validation loss = 3.0103  \n",
      "\n",
      "Fold: 7  Epoch: 35  Training loss = 2.8262  Validation loss = 3.0100  \n",
      "\n",
      "Fold: 7  Epoch: 36  Training loss = 2.8260  Validation loss = 3.0097  \n",
      "\n",
      "Fold: 7  Epoch: 37  Training loss = 2.8258  Validation loss = 3.0095  \n",
      "\n",
      "Fold: 7  Epoch: 38  Training loss = 2.8256  Validation loss = 3.0092  \n",
      "\n",
      "Fold: 7  Epoch: 39  Training loss = 2.8254  Validation loss = 3.0088  \n",
      "\n",
      "Fold: 7  Epoch: 40  Training loss = 2.8252  Validation loss = 3.0085  \n",
      "\n",
      "Fold: 7  Epoch: 41  Training loss = 2.8250  Validation loss = 3.0082  \n",
      "\n",
      "Fold: 7  Epoch: 42  Training loss = 2.8248  Validation loss = 3.0079  \n",
      "\n",
      "Fold: 7  Epoch: 43  Training loss = 2.8246  Validation loss = 3.0076  \n",
      "\n",
      "Fold: 7  Epoch: 44  Training loss = 2.8244  Validation loss = 3.0072  \n",
      "\n",
      "Fold: 7  Epoch: 45  Training loss = 2.8242  Validation loss = 3.0070  \n",
      "\n",
      "Fold: 7  Epoch: 46  Training loss = 2.8241  Validation loss = 3.0067  \n",
      "\n",
      "Fold: 7  Epoch: 47  Training loss = 2.8239  Validation loss = 3.0065  \n",
      "\n",
      "Fold: 7  Epoch: 48  Training loss = 2.8237  Validation loss = 3.0062  \n",
      "\n",
      "Fold: 7  Epoch: 49  Training loss = 2.8236  Validation loss = 3.0059  \n",
      "\n",
      "Fold: 7  Epoch: 50  Training loss = 2.8234  Validation loss = 3.0056  \n",
      "\n",
      "Fold: 7  Epoch: 51  Training loss = 2.8232  Validation loss = 3.0053  \n",
      "\n",
      "Fold: 7  Epoch: 52  Training loss = 2.8230  Validation loss = 3.0051  \n",
      "\n",
      "Fold: 7  Epoch: 53  Training loss = 2.8229  Validation loss = 3.0049  \n",
      "\n",
      "Fold: 7  Epoch: 54  Training loss = 2.8227  Validation loss = 3.0046  \n",
      "\n",
      "Fold: 7  Epoch: 55  Training loss = 2.8225  Validation loss = 3.0043  \n",
      "\n",
      "Fold: 7  Epoch: 56  Training loss = 2.8223  Validation loss = 3.0039  \n",
      "\n",
      "Fold: 7  Epoch: 57  Training loss = 2.8221  Validation loss = 3.0037  \n",
      "\n",
      "Fold: 7  Epoch: 58  Training loss = 2.8220  Validation loss = 3.0034  \n",
      "\n",
      "Fold: 7  Epoch: 59  Training loss = 2.8218  Validation loss = 3.0032  \n",
      "\n",
      "Fold: 7  Epoch: 60  Training loss = 2.8216  Validation loss = 3.0029  \n",
      "\n",
      "Fold: 7  Epoch: 61  Training loss = 2.8214  Validation loss = 3.0026  \n",
      "\n",
      "Fold: 7  Epoch: 62  Training loss = 2.8213  Validation loss = 3.0024  \n",
      "\n",
      "Fold: 7  Epoch: 63  Training loss = 2.8211  Validation loss = 3.0021  \n",
      "\n",
      "Fold: 7  Epoch: 64  Training loss = 2.8209  Validation loss = 3.0019  \n",
      "\n",
      "Fold: 7  Epoch: 65  Training loss = 2.8208  Validation loss = 3.0017  \n",
      "\n",
      "Fold: 7  Epoch: 66  Training loss = 2.8206  Validation loss = 3.0013  \n",
      "\n",
      "Fold: 7  Epoch: 67  Training loss = 2.8204  Validation loss = 3.0010  \n",
      "\n",
      "Fold: 7  Epoch: 68  Training loss = 2.8202  Validation loss = 3.0007  \n",
      "\n",
      "Fold: 7  Epoch: 69  Training loss = 2.8201  Validation loss = 3.0005  \n",
      "\n",
      "Fold: 7  Epoch: 70  Training loss = 2.8199  Validation loss = 3.0002  \n",
      "\n",
      "Fold: 7  Epoch: 71  Training loss = 2.8197  Validation loss = 3.0000  \n",
      "\n",
      "Fold: 7  Epoch: 72  Training loss = 2.8195  Validation loss = 2.9998  \n",
      "\n",
      "Fold: 7  Epoch: 73  Training loss = 2.8194  Validation loss = 2.9994  \n",
      "\n",
      "Fold: 7  Epoch: 74  Training loss = 2.8192  Validation loss = 2.9992  \n",
      "\n",
      "Fold: 7  Epoch: 75  Training loss = 2.8190  Validation loss = 2.9989  \n",
      "\n",
      "Fold: 7  Epoch: 76  Training loss = 2.8188  Validation loss = 2.9986  \n",
      "\n",
      "Fold: 7  Epoch: 77  Training loss = 2.8186  Validation loss = 2.9983  \n",
      "\n",
      "Fold: 7  Epoch: 78  Training loss = 2.8184  Validation loss = 2.9980  \n",
      "\n",
      "Fold: 7  Epoch: 79  Training loss = 2.8182  Validation loss = 2.9977  \n",
      "\n",
      "Fold: 7  Epoch: 80  Training loss = 2.8180  Validation loss = 2.9975  \n",
      "\n",
      "Fold: 7  Epoch: 81  Training loss = 2.8179  Validation loss = 2.9971  \n",
      "\n",
      "Fold: 7  Epoch: 82  Training loss = 2.8177  Validation loss = 2.9968  \n",
      "\n",
      "Fold: 7  Epoch: 83  Training loss = 2.8175  Validation loss = 2.9966  \n",
      "\n",
      "Fold: 7  Epoch: 84  Training loss = 2.8173  Validation loss = 2.9963  \n",
      "\n",
      "Fold: 7  Epoch: 85  Training loss = 2.8172  Validation loss = 2.9961  \n",
      "\n",
      "Fold: 7  Epoch: 86  Training loss = 2.8169  Validation loss = 2.9957  \n",
      "\n",
      "Fold: 7  Epoch: 87  Training loss = 2.8167  Validation loss = 2.9954  \n",
      "\n",
      "Fold: 7  Epoch: 88  Training loss = 2.8166  Validation loss = 2.9951  \n",
      "\n",
      "Fold: 7  Epoch: 89  Training loss = 2.8164  Validation loss = 2.9949  \n",
      "\n",
      "Fold: 7  Epoch: 90  Training loss = 2.8162  Validation loss = 2.9946  \n",
      "\n",
      "Fold: 7  Epoch: 91  Training loss = 2.8160  Validation loss = 2.9943  \n",
      "\n",
      "Fold: 7  Epoch: 92  Training loss = 2.8158  Validation loss = 2.9940  \n",
      "\n",
      "Fold: 7  Epoch: 93  Training loss = 2.8156  Validation loss = 2.9937  \n",
      "\n",
      "Fold: 7  Epoch: 94  Training loss = 2.8154  Validation loss = 2.9934  \n",
      "\n",
      "Fold: 7  Epoch: 95  Training loss = 2.8153  Validation loss = 2.9931  \n",
      "\n",
      "Fold: 7  Epoch: 96  Training loss = 2.8150  Validation loss = 2.9928  \n",
      "\n",
      "Fold: 7  Epoch: 97  Training loss = 2.8149  Validation loss = 2.9925  \n",
      "\n",
      "Fold: 7  Epoch: 98  Training loss = 2.8147  Validation loss = 2.9923  \n",
      "\n",
      "Fold: 7  Epoch: 99  Training loss = 2.8145  Validation loss = 2.9919  \n",
      "\n",
      "Fold: 7  Epoch: 100  Training loss = 2.8143  Validation loss = 2.9917  \n",
      "\n",
      "Fold: 7  Epoch: 101  Training loss = 2.8142  Validation loss = 2.9915  \n",
      "\n",
      "Fold: 7  Epoch: 102  Training loss = 2.8140  Validation loss = 2.9912  \n",
      "\n",
      "Fold: 7  Epoch: 103  Training loss = 2.8138  Validation loss = 2.9910  \n",
      "\n",
      "Fold: 7  Epoch: 104  Training loss = 2.8137  Validation loss = 2.9907  \n",
      "\n",
      "Fold: 7  Epoch: 105  Training loss = 2.8135  Validation loss = 2.9904  \n",
      "\n",
      "Fold: 7  Epoch: 106  Training loss = 2.8133  Validation loss = 2.9902  \n",
      "\n",
      "Fold: 7  Epoch: 107  Training loss = 2.8131  Validation loss = 2.9898  \n",
      "\n",
      "Fold: 7  Epoch: 108  Training loss = 2.8129  Validation loss = 2.9896  \n",
      "\n",
      "Fold: 7  Epoch: 109  Training loss = 2.8128  Validation loss = 2.9893  \n",
      "\n",
      "Fold: 7  Epoch: 110  Training loss = 2.8126  Validation loss = 2.9890  \n",
      "\n",
      "Fold: 7  Epoch: 111  Training loss = 2.8124  Validation loss = 2.9888  \n",
      "\n",
      "Fold: 7  Epoch: 112  Training loss = 2.8123  Validation loss = 2.9885  \n",
      "\n",
      "Fold: 7  Epoch: 113  Training loss = 2.8121  Validation loss = 2.9882  \n",
      "\n",
      "Fold: 7  Epoch: 114  Training loss = 2.8119  Validation loss = 2.9879  \n",
      "\n",
      "Fold: 7  Epoch: 115  Training loss = 2.8117  Validation loss = 2.9877  \n",
      "\n",
      "Fold: 7  Epoch: 116  Training loss = 2.8116  Validation loss = 2.9875  \n",
      "\n",
      "Fold: 7  Epoch: 117  Training loss = 2.8114  Validation loss = 2.9872  \n",
      "\n",
      "Fold: 7  Epoch: 118  Training loss = 2.8112  Validation loss = 2.9869  \n",
      "\n",
      "Fold: 7  Epoch: 119  Training loss = 2.8110  Validation loss = 2.9866  \n",
      "\n",
      "Fold: 7  Epoch: 120  Training loss = 2.8109  Validation loss = 2.9863  \n",
      "\n",
      "Fold: 7  Epoch: 121  Training loss = 2.8107  Validation loss = 2.9861  \n",
      "\n",
      "Fold: 7  Epoch: 122  Training loss = 2.8105  Validation loss = 2.9859  \n",
      "\n",
      "Fold: 7  Epoch: 123  Training loss = 2.8104  Validation loss = 2.9856  \n",
      "\n",
      "Fold: 7  Epoch: 124  Training loss = 2.8102  Validation loss = 2.9854  \n",
      "\n",
      "Fold: 7  Epoch: 125  Training loss = 2.8100  Validation loss = 2.9851  \n",
      "\n",
      "Fold: 7  Epoch: 126  Training loss = 2.8098  Validation loss = 2.9848  \n",
      "\n",
      "Fold: 7  Epoch: 127  Training loss = 2.8096  Validation loss = 2.9845  \n",
      "\n",
      "Fold: 7  Epoch: 128  Training loss = 2.8094  Validation loss = 2.9842  \n",
      "\n",
      "Fold: 7  Epoch: 129  Training loss = 2.8092  Validation loss = 2.9838  \n",
      "\n",
      "Fold: 7  Epoch: 130  Training loss = 2.8091  Validation loss = 2.9836  \n",
      "\n",
      "Fold: 7  Epoch: 131  Training loss = 2.8088  Validation loss = 2.9832  \n",
      "\n",
      "Fold: 7  Epoch: 132  Training loss = 2.8086  Validation loss = 2.9829  \n",
      "\n",
      "Fold: 7  Epoch: 133  Training loss = 2.8085  Validation loss = 2.9826  \n",
      "\n",
      "Fold: 7  Epoch: 134  Training loss = 2.8083  Validation loss = 2.9822  \n",
      "\n",
      "Fold: 7  Epoch: 135  Training loss = 2.8081  Validation loss = 2.9820  \n",
      "\n",
      "Fold: 7  Epoch: 136  Training loss = 2.8079  Validation loss = 2.9817  \n",
      "\n",
      "Fold: 7  Epoch: 137  Training loss = 2.8077  Validation loss = 2.9814  \n",
      "\n",
      "Fold: 7  Epoch: 138  Training loss = 2.8075  Validation loss = 2.9811  \n",
      "\n",
      "Fold: 7  Epoch: 139  Training loss = 2.8073  Validation loss = 2.9808  \n",
      "\n",
      "Fold: 7  Epoch: 140  Training loss = 2.8072  Validation loss = 2.9805  \n",
      "\n",
      "Fold: 7  Epoch: 141  Training loss = 2.8070  Validation loss = 2.9802  \n",
      "\n",
      "Fold: 7  Epoch: 142  Training loss = 2.8068  Validation loss = 2.9800  \n",
      "\n",
      "Fold: 7  Epoch: 143  Training loss = 2.8066  Validation loss = 2.9797  \n",
      "\n",
      "Fold: 7  Epoch: 144  Training loss = 2.8064  Validation loss = 2.9794  \n",
      "\n",
      "Fold: 7  Epoch: 145  Training loss = 2.8062  Validation loss = 2.9791  \n",
      "\n",
      "Fold: 7  Epoch: 146  Training loss = 2.8060  Validation loss = 2.9787  \n",
      "\n",
      "Fold: 7  Epoch: 147  Training loss = 2.8058  Validation loss = 2.9785  \n",
      "\n",
      "Fold: 7  Epoch: 148  Training loss = 2.8056  Validation loss = 2.9782  \n",
      "\n",
      "Fold: 7  Epoch: 149  Training loss = 2.8054  Validation loss = 2.9778  \n",
      "\n",
      "Fold: 7  Epoch: 150  Training loss = 2.8052  Validation loss = 2.9775  \n",
      "\n",
      "Fold: 7  Epoch: 151  Training loss = 2.8050  Validation loss = 2.9772  \n",
      "\n",
      "Fold: 7  Epoch: 152  Training loss = 2.8048  Validation loss = 2.9769  \n",
      "\n",
      "Fold: 7  Epoch: 153  Training loss = 2.8046  Validation loss = 2.9766  \n",
      "\n",
      "Fold: 7  Epoch: 154  Training loss = 2.8044  Validation loss = 2.9763  \n",
      "\n",
      "Fold: 7  Epoch: 155  Training loss = 2.8042  Validation loss = 2.9760  \n",
      "\n",
      "Fold: 7  Epoch: 156  Training loss = 2.8040  Validation loss = 2.9756  \n",
      "\n",
      "Fold: 7  Epoch: 157  Training loss = 2.8038  Validation loss = 2.9753  \n",
      "\n",
      "Fold: 7  Epoch: 158  Training loss = 2.8035  Validation loss = 2.9749  \n",
      "\n",
      "Fold: 7  Epoch: 159  Training loss = 2.8034  Validation loss = 2.9747  \n",
      "\n",
      "Fold: 7  Epoch: 160  Training loss = 2.8032  Validation loss = 2.9744  \n",
      "\n",
      "Fold: 7  Epoch: 161  Training loss = 2.8030  Validation loss = 2.9741  \n",
      "\n",
      "Fold: 7  Epoch: 162  Training loss = 2.8028  Validation loss = 2.9738  \n",
      "\n",
      "Fold: 7  Epoch: 163  Training loss = 2.8027  Validation loss = 2.9736  \n",
      "\n",
      "Fold: 7  Epoch: 164  Training loss = 2.8025  Validation loss = 2.9733  \n",
      "\n",
      "Fold: 7  Epoch: 165  Training loss = 2.8023  Validation loss = 2.9730  \n",
      "\n",
      "Fold: 7  Epoch: 166  Training loss = 2.8021  Validation loss = 2.9728  \n",
      "\n",
      "Fold: 7  Epoch: 167  Training loss = 2.8019  Validation loss = 2.9725  \n",
      "\n",
      "Fold: 7  Epoch: 168  Training loss = 2.8017  Validation loss = 2.9722  \n",
      "\n",
      "Fold: 7  Epoch: 169  Training loss = 2.8016  Validation loss = 2.9719  \n",
      "\n",
      "Fold: 7  Epoch: 170  Training loss = 2.8014  Validation loss = 2.9716  \n",
      "\n",
      "Fold: 7  Epoch: 171  Training loss = 2.8012  Validation loss = 2.9713  \n",
      "\n",
      "Fold: 7  Epoch: 172  Training loss = 2.8010  Validation loss = 2.9711  \n",
      "\n",
      "Fold: 7  Epoch: 173  Training loss = 2.8008  Validation loss = 2.9708  \n",
      "\n",
      "Fold: 7  Epoch: 174  Training loss = 2.8007  Validation loss = 2.9705  \n",
      "\n",
      "Fold: 7  Epoch: 175  Training loss = 2.8005  Validation loss = 2.9703  \n",
      "\n",
      "Fold: 7  Epoch: 176  Training loss = 2.8003  Validation loss = 2.9700  \n",
      "\n",
      "Fold: 7  Epoch: 177  Training loss = 2.8001  Validation loss = 2.9697  \n",
      "\n",
      "Fold: 7  Epoch: 178  Training loss = 2.7999  Validation loss = 2.9694  \n",
      "\n",
      "Fold: 7  Epoch: 179  Training loss = 2.7997  Validation loss = 2.9691  \n",
      "\n",
      "Fold: 7  Epoch: 180  Training loss = 2.7996  Validation loss = 2.9689  \n",
      "\n",
      "Fold: 7  Epoch: 181  Training loss = 2.7995  Validation loss = 2.9687  \n",
      "\n",
      "Fold: 7  Epoch: 182  Training loss = 2.7993  Validation loss = 2.9684  \n",
      "\n",
      "Fold: 7  Epoch: 183  Training loss = 2.7991  Validation loss = 2.9682  \n",
      "\n",
      "Fold: 7  Epoch: 184  Training loss = 2.7989  Validation loss = 2.9679  \n",
      "\n",
      "Fold: 7  Epoch: 185  Training loss = 2.7987  Validation loss = 2.9676  \n",
      "\n",
      "Fold: 7  Epoch: 186  Training loss = 2.7985  Validation loss = 2.9674  \n",
      "\n",
      "Fold: 7  Epoch: 187  Training loss = 2.7984  Validation loss = 2.9671  \n",
      "\n",
      "Fold: 7  Epoch: 188  Training loss = 2.7982  Validation loss = 2.9668  \n",
      "\n",
      "Fold: 7  Epoch: 189  Training loss = 2.7979  Validation loss = 2.9665  \n",
      "\n",
      "Fold: 7  Epoch: 190  Training loss = 2.7978  Validation loss = 2.9663  \n",
      "\n",
      "Fold: 7  Epoch: 191  Training loss = 2.7976  Validation loss = 2.9660  \n",
      "\n",
      "Fold: 7  Epoch: 192  Training loss = 2.7974  Validation loss = 2.9657  \n",
      "\n",
      "Fold: 7  Epoch: 193  Training loss = 2.7972  Validation loss = 2.9654  \n",
      "\n",
      "Fold: 7  Epoch: 194  Training loss = 2.7970  Validation loss = 2.9652  \n",
      "\n",
      "Fold: 7  Epoch: 195  Training loss = 2.7968  Validation loss = 2.9649  \n",
      "\n",
      "Fold: 7  Epoch: 196  Training loss = 2.7967  Validation loss = 2.9647  \n",
      "\n",
      "Fold: 7  Epoch: 197  Training loss = 2.7965  Validation loss = 2.9644  \n",
      "\n",
      "Fold: 7  Epoch: 198  Training loss = 2.7963  Validation loss = 2.9641  \n",
      "\n",
      "Fold: 7  Epoch: 199  Training loss = 2.7961  Validation loss = 2.9637  \n",
      "\n",
      "Fold: 7  Epoch: 200  Training loss = 2.7959  Validation loss = 2.9635  \n",
      "\n",
      "Fold: 7  Epoch: 201  Training loss = 2.7957  Validation loss = 2.9631  \n",
      "\n",
      "Fold: 7  Epoch: 202  Training loss = 2.7955  Validation loss = 2.9628  \n",
      "\n",
      "Fold: 7  Epoch: 203  Training loss = 2.7953  Validation loss = 2.9625  \n",
      "\n",
      "Fold: 7  Epoch: 204  Training loss = 2.7951  Validation loss = 2.9623  \n",
      "\n",
      "Fold: 7  Epoch: 205  Training loss = 2.7949  Validation loss = 2.9620  \n",
      "\n",
      "Fold: 7  Epoch: 206  Training loss = 2.7948  Validation loss = 2.9617  \n",
      "\n",
      "Fold: 7  Epoch: 207  Training loss = 2.7946  Validation loss = 2.9615  \n",
      "\n",
      "Fold: 7  Epoch: 208  Training loss = 2.7944  Validation loss = 2.9612  \n",
      "\n",
      "Fold: 7  Epoch: 209  Training loss = 2.7942  Validation loss = 2.9609  \n",
      "\n",
      "Fold: 7  Epoch: 210  Training loss = 2.7940  Validation loss = 2.9606  \n",
      "\n",
      "Fold: 7  Epoch: 211  Training loss = 2.7938  Validation loss = 2.9604  \n",
      "\n",
      "Fold: 7  Epoch: 212  Training loss = 2.7936  Validation loss = 2.9601  \n",
      "\n",
      "Fold: 7  Epoch: 213  Training loss = 2.7935  Validation loss = 2.9599  \n",
      "\n",
      "Fold: 7  Epoch: 214  Training loss = 2.7934  Validation loss = 2.9597  \n",
      "\n",
      "Fold: 7  Epoch: 215  Training loss = 2.7932  Validation loss = 2.9594  \n",
      "\n",
      "Fold: 7  Epoch: 216  Training loss = 2.7930  Validation loss = 2.9591  \n",
      "\n",
      "Fold: 7  Epoch: 217  Training loss = 2.7927  Validation loss = 2.9587  \n",
      "\n",
      "Fold: 7  Epoch: 218  Training loss = 2.7925  Validation loss = 2.9584  \n",
      "\n",
      "Fold: 7  Epoch: 219  Training loss = 2.7924  Validation loss = 2.9582  \n",
      "\n",
      "Fold: 7  Epoch: 220  Training loss = 2.7922  Validation loss = 2.9579  \n",
      "\n",
      "Fold: 7  Epoch: 221  Training loss = 2.7920  Validation loss = 2.9576  \n",
      "\n",
      "Fold: 7  Epoch: 222  Training loss = 2.7918  Validation loss = 2.9573  \n",
      "\n",
      "Fold: 7  Epoch: 223  Training loss = 2.7916  Validation loss = 2.9571  \n",
      "\n",
      "Fold: 7  Epoch: 224  Training loss = 2.7915  Validation loss = 2.9568  \n",
      "\n",
      "Fold: 7  Epoch: 225  Training loss = 2.7912  Validation loss = 2.9565  \n",
      "\n",
      "Fold: 7  Epoch: 226  Training loss = 2.7911  Validation loss = 2.9563  \n",
      "\n",
      "Fold: 7  Epoch: 227  Training loss = 2.7909  Validation loss = 2.9560  \n",
      "\n",
      "Fold: 7  Epoch: 228  Training loss = 2.7907  Validation loss = 2.9557  \n",
      "\n",
      "Fold: 7  Epoch: 229  Training loss = 2.7906  Validation loss = 2.9555  \n",
      "\n",
      "Fold: 7  Epoch: 230  Training loss = 2.7904  Validation loss = 2.9552  \n",
      "\n",
      "Fold: 7  Epoch: 231  Training loss = 2.7902  Validation loss = 2.9550  \n",
      "\n",
      "Fold: 7  Epoch: 232  Training loss = 2.7901  Validation loss = 2.9548  \n",
      "\n",
      "Fold: 7  Epoch: 233  Training loss = 2.7898  Validation loss = 2.9544  \n",
      "\n",
      "Fold: 7  Epoch: 234  Training loss = 2.7896  Validation loss = 2.9541  \n",
      "\n",
      "Fold: 7  Epoch: 235  Training loss = 2.7895  Validation loss = 2.9539  \n",
      "\n",
      "Fold: 7  Epoch: 236  Training loss = 2.7893  Validation loss = 2.9536  \n",
      "\n",
      "Fold: 7  Epoch: 237  Training loss = 2.7891  Validation loss = 2.9533  \n",
      "\n",
      "Fold: 7  Epoch: 238  Training loss = 2.7890  Validation loss = 2.9531  \n",
      "\n",
      "Fold: 7  Epoch: 239  Training loss = 2.7888  Validation loss = 2.9529  \n",
      "\n",
      "Fold: 7  Epoch: 240  Training loss = 2.7886  Validation loss = 2.9526  \n",
      "\n",
      "Fold: 7  Epoch: 241  Training loss = 2.7884  Validation loss = 2.9523  \n",
      "\n",
      "Fold: 7  Epoch: 242  Training loss = 2.7882  Validation loss = 2.9520  \n",
      "\n",
      "Fold: 7  Epoch: 243  Training loss = 2.7881  Validation loss = 2.9517  \n",
      "\n",
      "Fold: 7  Epoch: 244  Training loss = 2.7879  Validation loss = 2.9514  \n",
      "\n",
      "Fold: 7  Epoch: 245  Training loss = 2.7877  Validation loss = 2.9511  \n",
      "\n",
      "Fold: 7  Epoch: 246  Training loss = 2.7875  Validation loss = 2.9509  \n",
      "\n",
      "Fold: 7  Epoch: 247  Training loss = 2.7873  Validation loss = 2.9506  \n",
      "\n",
      "Fold: 7  Epoch: 248  Training loss = 2.7871  Validation loss = 2.9503  \n",
      "\n",
      "Fold: 7  Epoch: 249  Training loss = 2.7870  Validation loss = 2.9500  \n",
      "\n",
      "Fold: 7  Epoch: 250  Training loss = 2.7868  Validation loss = 2.9498  \n",
      "\n",
      "Fold: 7  Epoch: 251  Training loss = 2.7866  Validation loss = 2.9495  \n",
      "\n",
      "Fold: 7  Epoch: 252  Training loss = 2.7864  Validation loss = 2.9493  \n",
      "\n",
      "Fold: 7  Epoch: 253  Training loss = 2.7862  Validation loss = 2.9489  \n",
      "\n",
      "Fold: 7  Epoch: 254  Training loss = 2.7860  Validation loss = 2.9486  \n",
      "\n",
      "Fold: 7  Epoch: 255  Training loss = 2.7859  Validation loss = 2.9484  \n",
      "\n",
      "Fold: 7  Epoch: 256  Training loss = 2.7857  Validation loss = 2.9481  \n",
      "\n",
      "Fold: 7  Epoch: 257  Training loss = 2.7855  Validation loss = 2.9477  \n",
      "\n",
      "Fold: 7  Epoch: 258  Training loss = 2.7853  Validation loss = 2.9475  \n",
      "\n",
      "Fold: 7  Epoch: 259  Training loss = 2.7851  Validation loss = 2.9473  \n",
      "\n",
      "Fold: 7  Epoch: 260  Training loss = 2.7849  Validation loss = 2.9470  \n",
      "\n",
      "Fold: 7  Epoch: 261  Training loss = 2.7848  Validation loss = 2.9467  \n",
      "\n",
      "Fold: 7  Epoch: 262  Training loss = 2.7846  Validation loss = 2.9465  \n",
      "\n",
      "Fold: 7  Epoch: 263  Training loss = 2.7844  Validation loss = 2.9462  \n",
      "\n",
      "Fold: 7  Epoch: 264  Training loss = 2.7842  Validation loss = 2.9460  \n",
      "\n",
      "Fold: 7  Epoch: 265  Training loss = 2.7841  Validation loss = 2.9458  \n",
      "\n",
      "Fold: 7  Epoch: 266  Training loss = 2.7839  Validation loss = 2.9455  \n",
      "\n",
      "Fold: 7  Epoch: 267  Training loss = 2.7837  Validation loss = 2.9452  \n",
      "\n",
      "Fold: 7  Epoch: 268  Training loss = 2.7835  Validation loss = 2.9449  \n",
      "\n",
      "Fold: 7  Epoch: 269  Training loss = 2.7833  Validation loss = 2.9446  \n",
      "\n",
      "Fold: 7  Epoch: 270  Training loss = 2.7831  Validation loss = 2.9444  \n",
      "\n",
      "Fold: 7  Epoch: 271  Training loss = 2.7829  Validation loss = 2.9441  \n",
      "\n",
      "Fold: 7  Epoch: 272  Training loss = 2.7828  Validation loss = 2.9439  \n",
      "\n",
      "Fold: 7  Epoch: 273  Training loss = 2.7826  Validation loss = 2.9436  \n",
      "\n",
      "Fold: 7  Epoch: 274  Training loss = 2.7824  Validation loss = 2.9434  \n",
      "\n",
      "Fold: 7  Epoch: 275  Training loss = 2.7823  Validation loss = 2.9431  \n",
      "\n",
      "Fold: 7  Epoch: 276  Training loss = 2.7821  Validation loss = 2.9429  \n",
      "\n",
      "Fold: 7  Epoch: 277  Training loss = 2.7819  Validation loss = 2.9426  \n",
      "\n",
      "Fold: 7  Epoch: 278  Training loss = 2.7818  Validation loss = 2.9424  \n",
      "\n",
      "Fold: 7  Epoch: 279  Training loss = 2.7816  Validation loss = 2.9420  \n",
      "\n",
      "Fold: 7  Epoch: 280  Training loss = 2.7814  Validation loss = 2.9418  \n",
      "\n",
      "Fold: 7  Epoch: 281  Training loss = 2.7812  Validation loss = 2.9415  \n",
      "\n",
      "Fold: 7  Epoch: 282  Training loss = 2.7810  Validation loss = 2.9413  \n",
      "\n",
      "Fold: 7  Epoch: 283  Training loss = 2.7809  Validation loss = 2.9410  \n",
      "\n",
      "Fold: 7  Epoch: 284  Training loss = 2.7807  Validation loss = 2.9407  \n",
      "\n",
      "Fold: 7  Epoch: 285  Training loss = 2.7805  Validation loss = 2.9404  \n",
      "\n",
      "Fold: 7  Epoch: 286  Training loss = 2.7803  Validation loss = 2.9402  \n",
      "\n",
      "Fold: 7  Epoch: 287  Training loss = 2.7802  Validation loss = 2.9400  \n",
      "\n",
      "Fold: 7  Epoch: 288  Training loss = 2.7800  Validation loss = 2.9398  \n",
      "\n",
      "Fold: 7  Epoch: 289  Training loss = 2.7798  Validation loss = 2.9394  \n",
      "\n",
      "Fold: 7  Epoch: 290  Training loss = 2.7796  Validation loss = 2.9392  \n",
      "\n",
      "Fold: 7  Epoch: 291  Training loss = 2.7794  Validation loss = 2.9388  \n",
      "\n",
      "Fold: 7  Epoch: 292  Training loss = 2.7792  Validation loss = 2.9386  \n",
      "\n",
      "Fold: 7  Epoch: 293  Training loss = 2.7790  Validation loss = 2.9383  \n",
      "\n",
      "Fold: 7  Epoch: 294  Training loss = 2.7789  Validation loss = 2.9380  \n",
      "\n",
      "Fold: 7  Epoch: 295  Training loss = 2.7787  Validation loss = 2.9378  \n",
      "\n",
      "Fold: 7  Epoch: 296  Training loss = 2.7785  Validation loss = 2.9375  \n",
      "\n",
      "Fold: 7  Epoch: 297  Training loss = 2.7784  Validation loss = 2.9373  \n",
      "\n",
      "Fold: 7  Epoch: 298  Training loss = 2.7782  Validation loss = 2.9370  \n",
      "\n",
      "Fold: 7  Epoch: 299  Training loss = 2.7780  Validation loss = 2.9368  \n",
      "\n",
      "Fold: 7  Epoch: 300  Training loss = 2.7778  Validation loss = 2.9365  \n",
      "\n",
      "Fold: 7  Epoch: 301  Training loss = 2.7776  Validation loss = 2.9363  \n",
      "\n",
      "Fold: 7  Epoch: 302  Training loss = 2.7774  Validation loss = 2.9360  \n",
      "\n",
      "Fold: 7  Epoch: 303  Training loss = 2.7772  Validation loss = 2.9356  \n",
      "\n",
      "Fold: 7  Epoch: 304  Training loss = 2.7770  Validation loss = 2.9354  \n",
      "\n",
      "Fold: 7  Epoch: 305  Training loss = 2.7768  Validation loss = 2.9351  \n",
      "\n",
      "Fold: 7  Epoch: 306  Training loss = 2.7766  Validation loss = 2.9348  \n",
      "\n",
      "Fold: 7  Epoch: 307  Training loss = 2.7764  Validation loss = 2.9346  \n",
      "\n",
      "Fold: 7  Epoch: 308  Training loss = 2.7763  Validation loss = 2.9344  \n",
      "\n",
      "Fold: 7  Epoch: 309  Training loss = 2.7761  Validation loss = 2.9341  \n",
      "\n",
      "Fold: 7  Epoch: 310  Training loss = 2.7759  Validation loss = 2.9338  \n",
      "\n",
      "Fold: 7  Epoch: 311  Training loss = 2.7758  Validation loss = 2.9336  \n",
      "\n",
      "Fold: 7  Epoch: 312  Training loss = 2.7756  Validation loss = 2.9334  \n",
      "\n",
      "Fold: 7  Epoch: 313  Training loss = 2.7754  Validation loss = 2.9331  \n",
      "\n",
      "Fold: 7  Epoch: 314  Training loss = 2.7752  Validation loss = 2.9329  \n",
      "\n",
      "Fold: 7  Epoch: 315  Training loss = 2.7750  Validation loss = 2.9326  \n",
      "\n",
      "Fold: 7  Epoch: 316  Training loss = 2.7749  Validation loss = 2.9323  \n",
      "\n",
      "Fold: 7  Epoch: 317  Training loss = 2.7747  Validation loss = 2.9321  \n",
      "\n",
      "Fold: 7  Epoch: 318  Training loss = 2.7745  Validation loss = 2.9318  \n",
      "\n",
      "Fold: 7  Epoch: 319  Training loss = 2.7743  Validation loss = 2.9316  \n",
      "\n",
      "Fold: 7  Epoch: 320  Training loss = 2.7742  Validation loss = 2.9313  \n",
      "\n",
      "Fold: 7  Epoch: 321  Training loss = 2.7740  Validation loss = 2.9310  \n",
      "\n",
      "Fold: 7  Epoch: 322  Training loss = 2.7738  Validation loss = 2.9307  \n",
      "\n",
      "Fold: 7  Epoch: 323  Training loss = 2.7736  Validation loss = 2.9305  \n",
      "\n",
      "Fold: 7  Epoch: 324  Training loss = 2.7735  Validation loss = 2.9302  \n",
      "\n",
      "Fold: 7  Epoch: 325  Training loss = 2.7733  Validation loss = 2.9300  \n",
      "\n",
      "Fold: 7  Epoch: 326  Training loss = 2.7731  Validation loss = 2.9297  \n",
      "\n",
      "Fold: 7  Epoch: 327  Training loss = 2.7728  Validation loss = 2.9293  \n",
      "\n",
      "Fold: 7  Epoch: 328  Training loss = 2.7727  Validation loss = 2.9291  \n",
      "\n",
      "Fold: 7  Epoch: 329  Training loss = 2.7725  Validation loss = 2.9289  \n",
      "\n",
      "Fold: 7  Epoch: 330  Training loss = 2.7723  Validation loss = 2.9286  \n",
      "\n",
      "Fold: 7  Epoch: 331  Training loss = 2.7721  Validation loss = 2.9283  \n",
      "\n",
      "Fold: 7  Epoch: 332  Training loss = 2.7719  Validation loss = 2.9281  \n",
      "\n",
      "Fold: 7  Epoch: 333  Training loss = 2.7717  Validation loss = 2.9277  \n",
      "\n",
      "Fold: 7  Epoch: 334  Training loss = 2.7716  Validation loss = 2.9275  \n",
      "\n",
      "Fold: 7  Epoch: 335  Training loss = 2.7714  Validation loss = 2.9272  \n",
      "\n",
      "Fold: 7  Epoch: 336  Training loss = 2.7712  Validation loss = 2.9270  \n",
      "\n",
      "Fold: 7  Epoch: 337  Training loss = 2.7710  Validation loss = 2.9267  \n",
      "\n",
      "Fold: 7  Epoch: 338  Training loss = 2.7708  Validation loss = 2.9264  \n",
      "\n",
      "Fold: 7  Epoch: 339  Training loss = 2.7706  Validation loss = 2.9261  \n",
      "\n",
      "Fold: 7  Epoch: 340  Training loss = 2.7704  Validation loss = 2.9258  \n",
      "\n",
      "Fold: 7  Epoch: 341  Training loss = 2.7702  Validation loss = 2.9256  \n",
      "\n",
      "Fold: 7  Epoch: 342  Training loss = 2.7700  Validation loss = 2.9253  \n",
      "\n",
      "Fold: 7  Epoch: 343  Training loss = 2.7698  Validation loss = 2.9250  \n",
      "\n",
      "Fold: 7  Epoch: 344  Training loss = 2.7696  Validation loss = 2.9247  \n",
      "\n",
      "Fold: 7  Epoch: 345  Training loss = 2.7694  Validation loss = 2.9243  \n",
      "\n",
      "Fold: 7  Epoch: 346  Training loss = 2.7692  Validation loss = 2.9241  \n",
      "\n",
      "Fold: 7  Epoch: 347  Training loss = 2.7690  Validation loss = 2.9238  \n",
      "\n",
      "Fold: 7  Epoch: 348  Training loss = 2.7689  Validation loss = 2.9236  \n",
      "\n",
      "Fold: 7  Epoch: 349  Training loss = 2.7687  Validation loss = 2.9233  \n",
      "\n",
      "Fold: 7  Epoch: 350  Training loss = 2.7685  Validation loss = 2.9231  \n",
      "\n",
      "Fold: 7  Epoch: 351  Training loss = 2.7683  Validation loss = 2.9228  \n",
      "\n",
      "Fold: 7  Epoch: 352  Training loss = 2.7682  Validation loss = 2.9226  \n",
      "\n",
      "Fold: 7  Epoch: 353  Training loss = 2.7680  Validation loss = 2.9223  \n",
      "\n",
      "Fold: 7  Epoch: 354  Training loss = 2.7678  Validation loss = 2.9220  \n",
      "\n",
      "Fold: 7  Epoch: 355  Training loss = 2.7676  Validation loss = 2.9217  \n",
      "\n",
      "Fold: 7  Epoch: 356  Training loss = 2.7674  Validation loss = 2.9215  \n",
      "\n",
      "Fold: 7  Epoch: 357  Training loss = 2.7672  Validation loss = 2.9212  \n",
      "\n",
      "Fold: 7  Epoch: 358  Training loss = 2.7671  Validation loss = 2.9210  \n",
      "\n",
      "Fold: 7  Epoch: 359  Training loss = 2.7669  Validation loss = 2.9208  \n",
      "\n",
      "Fold: 7  Epoch: 360  Training loss = 2.7667  Validation loss = 2.9205  \n",
      "\n",
      "Fold: 7  Epoch: 361  Training loss = 2.7666  Validation loss = 2.9203  \n",
      "\n",
      "Fold: 7  Epoch: 362  Training loss = 2.7664  Validation loss = 2.9200  \n",
      "\n",
      "Fold: 7  Epoch: 363  Training loss = 2.7662  Validation loss = 2.9198  \n",
      "\n",
      "Fold: 7  Epoch: 364  Training loss = 2.7660  Validation loss = 2.9195  \n",
      "\n",
      "Fold: 7  Epoch: 365  Training loss = 2.7659  Validation loss = 2.9193  \n",
      "\n",
      "Fold: 7  Epoch: 366  Training loss = 2.7657  Validation loss = 2.9190  \n",
      "\n",
      "Fold: 7  Epoch: 367  Training loss = 2.7655  Validation loss = 2.9187  \n",
      "\n",
      "Fold: 7  Epoch: 368  Training loss = 2.7653  Validation loss = 2.9184  \n",
      "\n",
      "Fold: 7  Epoch: 369  Training loss = 2.7651  Validation loss = 2.9182  \n",
      "\n",
      "Fold: 7  Epoch: 370  Training loss = 2.7650  Validation loss = 2.9180  \n",
      "\n",
      "Fold: 7  Epoch: 371  Training loss = 2.7648  Validation loss = 2.9177  \n",
      "\n",
      "Fold: 7  Epoch: 372  Training loss = 2.7646  Validation loss = 2.9175  \n",
      "\n",
      "Fold: 7  Epoch: 373  Training loss = 2.7644  Validation loss = 2.9172  \n",
      "\n",
      "Fold: 7  Epoch: 374  Training loss = 2.7642  Validation loss = 2.9170  \n",
      "\n",
      "Fold: 7  Epoch: 375  Training loss = 2.7640  Validation loss = 2.9167  \n",
      "\n",
      "Fold: 7  Epoch: 376  Training loss = 2.7638  Validation loss = 2.9164  \n",
      "\n",
      "Fold: 7  Epoch: 377  Training loss = 2.7636  Validation loss = 2.9161  \n",
      "\n",
      "Fold: 7  Epoch: 378  Training loss = 2.7635  Validation loss = 2.9159  \n",
      "\n",
      "Fold: 7  Epoch: 379  Training loss = 2.7633  Validation loss = 2.9157  \n",
      "\n",
      "Fold: 7  Epoch: 380  Training loss = 2.7631  Validation loss = 2.9154  \n",
      "\n",
      "Fold: 7  Epoch: 381  Training loss = 2.7629  Validation loss = 2.9150  \n",
      "\n",
      "Fold: 7  Epoch: 382  Training loss = 2.7627  Validation loss = 2.9147  \n",
      "\n",
      "Fold: 7  Epoch: 383  Training loss = 2.7625  Validation loss = 2.9145  \n",
      "\n",
      "Fold: 7  Epoch: 384  Training loss = 2.7623  Validation loss = 2.9142  \n",
      "\n",
      "Fold: 7  Epoch: 385  Training loss = 2.7621  Validation loss = 2.9140  \n",
      "\n",
      "Fold: 7  Epoch: 386  Training loss = 2.7620  Validation loss = 2.9137  \n",
      "\n",
      "Fold: 7  Epoch: 387  Training loss = 2.7618  Validation loss = 2.9135  \n",
      "\n",
      "Fold: 7  Epoch: 388  Training loss = 2.7617  Validation loss = 2.9133  \n",
      "\n",
      "Fold: 7  Epoch: 389  Training loss = 2.7615  Validation loss = 2.9130  \n",
      "\n",
      "Fold: 7  Epoch: 390  Training loss = 2.7613  Validation loss = 2.9127  \n",
      "\n",
      "Fold: 7  Epoch: 391  Training loss = 2.7611  Validation loss = 2.9124  \n",
      "\n",
      "Fold: 7  Epoch: 392  Training loss = 2.7609  Validation loss = 2.9121  \n",
      "\n",
      "Fold: 7  Epoch: 393  Training loss = 2.7607  Validation loss = 2.9119  \n",
      "\n",
      "Fold: 7  Epoch: 394  Training loss = 2.7605  Validation loss = 2.9116  \n",
      "\n",
      "Fold: 7  Epoch: 395  Training loss = 2.7603  Validation loss = 2.9113  \n",
      "\n",
      "Fold: 7  Epoch: 396  Training loss = 2.7601  Validation loss = 2.9110  \n",
      "\n",
      "Fold: 7  Epoch: 397  Training loss = 2.7599  Validation loss = 2.9108  \n",
      "\n",
      "Fold: 7  Epoch: 398  Training loss = 2.7598  Validation loss = 2.9105  \n",
      "\n",
      "Fold: 7  Epoch: 399  Training loss = 2.7596  Validation loss = 2.9102  \n",
      "\n",
      "Fold: 7  Epoch: 400  Training loss = 2.7594  Validation loss = 2.9099  \n",
      "\n",
      "Fold: 7  Epoch: 401  Training loss = 2.7592  Validation loss = 2.9097  \n",
      "\n",
      "Fold: 7  Epoch: 402  Training loss = 2.7590  Validation loss = 2.9094  \n",
      "\n",
      "Fold: 7  Epoch: 403  Training loss = 2.7589  Validation loss = 2.9093  \n",
      "\n",
      "Fold: 7  Epoch: 404  Training loss = 2.7588  Validation loss = 2.9091  \n",
      "\n",
      "Fold: 7  Epoch: 405  Training loss = 2.7586  Validation loss = 2.9088  \n",
      "\n",
      "Fold: 7  Epoch: 406  Training loss = 2.7584  Validation loss = 2.9086  \n",
      "\n",
      "Fold: 7  Epoch: 407  Training loss = 2.7582  Validation loss = 2.9082  \n",
      "\n",
      "Fold: 7  Epoch: 408  Training loss = 2.7580  Validation loss = 2.9080  \n",
      "\n",
      "Fold: 7  Epoch: 409  Training loss = 2.7578  Validation loss = 2.9077  \n",
      "\n",
      "Fold: 7  Epoch: 410  Training loss = 2.7576  Validation loss = 2.9074  \n",
      "\n",
      "Fold: 7  Epoch: 411  Training loss = 2.7574  Validation loss = 2.9072  \n",
      "\n",
      "Fold: 7  Epoch: 412  Training loss = 2.7572  Validation loss = 2.9069  \n",
      "\n",
      "Fold: 7  Epoch: 413  Training loss = 2.7571  Validation loss = 2.9067  \n",
      "\n",
      "Fold: 7  Epoch: 414  Training loss = 2.7569  Validation loss = 2.9064  \n",
      "\n",
      "Fold: 7  Epoch: 415  Training loss = 2.7567  Validation loss = 2.9061  \n",
      "\n",
      "Fold: 7  Epoch: 416  Training loss = 2.7565  Validation loss = 2.9059  \n",
      "\n",
      "Fold: 7  Epoch: 417  Training loss = 2.7563  Validation loss = 2.9056  \n",
      "\n",
      "Fold: 7  Epoch: 418  Training loss = 2.7562  Validation loss = 2.9055  \n",
      "\n",
      "Fold: 7  Epoch: 419  Training loss = 2.7560  Validation loss = 2.9052  \n",
      "\n",
      "Fold: 7  Epoch: 420  Training loss = 2.7558  Validation loss = 2.9050  \n",
      "\n",
      "Fold: 7  Epoch: 421  Training loss = 2.7557  Validation loss = 2.9048  \n",
      "\n",
      "Fold: 7  Epoch: 422  Training loss = 2.7555  Validation loss = 2.9045  \n",
      "\n",
      "Fold: 7  Epoch: 423  Training loss = 2.7553  Validation loss = 2.9042  \n",
      "\n",
      "Fold: 7  Epoch: 424  Training loss = 2.7552  Validation loss = 2.9040  \n",
      "\n",
      "Fold: 7  Epoch: 425  Training loss = 2.7550  Validation loss = 2.9037  \n",
      "\n",
      "Fold: 7  Epoch: 426  Training loss = 2.7548  Validation loss = 2.9035  \n",
      "\n",
      "Fold: 7  Epoch: 427  Training loss = 2.7546  Validation loss = 2.9033  \n",
      "\n",
      "Fold: 7  Epoch: 428  Training loss = 2.7544  Validation loss = 2.9030  \n",
      "\n",
      "Fold: 7  Epoch: 429  Training loss = 2.7543  Validation loss = 2.9028  \n",
      "\n",
      "Fold: 7  Epoch: 430  Training loss = 2.7541  Validation loss = 2.9025  \n",
      "\n",
      "Fold: 7  Epoch: 431  Training loss = 2.7539  Validation loss = 2.9022  \n",
      "\n",
      "Fold: 7  Epoch: 432  Training loss = 2.7537  Validation loss = 2.9020  \n",
      "\n",
      "Fold: 7  Epoch: 433  Training loss = 2.7535  Validation loss = 2.9017  \n",
      "\n",
      "Fold: 7  Epoch: 434  Training loss = 2.7533  Validation loss = 2.9014  \n",
      "\n",
      "Fold: 7  Epoch: 435  Training loss = 2.7531  Validation loss = 2.9012  \n",
      "\n",
      "Fold: 7  Epoch: 436  Training loss = 2.7530  Validation loss = 2.9009  \n",
      "\n",
      "Fold: 7  Epoch: 437  Training loss = 2.7528  Validation loss = 2.9007  \n",
      "\n",
      "Fold: 7  Epoch: 438  Training loss = 2.7526  Validation loss = 2.9004  \n",
      "\n",
      "Fold: 7  Epoch: 439  Training loss = 2.7524  Validation loss = 2.9002  \n",
      "\n",
      "Fold: 7  Epoch: 440  Training loss = 2.7522  Validation loss = 2.8998  \n",
      "\n",
      "Fold: 7  Epoch: 441  Training loss = 2.7520  Validation loss = 2.8996  \n",
      "\n",
      "Fold: 7  Epoch: 442  Training loss = 2.7519  Validation loss = 2.8994  \n",
      "\n",
      "Fold: 7  Epoch: 443  Training loss = 2.7517  Validation loss = 2.8991  \n",
      "\n",
      "Fold: 7  Epoch: 444  Training loss = 2.7515  Validation loss = 2.8988  \n",
      "\n",
      "Fold: 7  Epoch: 445  Training loss = 2.7514  Validation loss = 2.8986  \n",
      "\n",
      "Fold: 7  Epoch: 446  Training loss = 2.7512  Validation loss = 2.8983  \n",
      "\n",
      "Fold: 7  Epoch: 447  Training loss = 2.7510  Validation loss = 2.8981  \n",
      "\n",
      "Fold: 7  Epoch: 448  Training loss = 2.7508  Validation loss = 2.8979  \n",
      "\n",
      "Fold: 7  Epoch: 449  Training loss = 2.7506  Validation loss = 2.8976  \n",
      "\n",
      "Fold: 7  Epoch: 450  Training loss = 2.7505  Validation loss = 2.8974  \n",
      "\n",
      "Fold: 7  Epoch: 451  Training loss = 2.7503  Validation loss = 2.8971  \n",
      "\n",
      "Fold: 7  Epoch: 452  Training loss = 2.7501  Validation loss = 2.8969  \n",
      "\n",
      "Fold: 7  Epoch: 453  Training loss = 2.7499  Validation loss = 2.8966  \n",
      "\n",
      "Fold: 7  Epoch: 454  Training loss = 2.7497  Validation loss = 2.8963  \n",
      "\n",
      "Fold: 7  Epoch: 455  Training loss = 2.7495  Validation loss = 2.8960  \n",
      "\n",
      "Fold: 7  Epoch: 456  Training loss = 2.7494  Validation loss = 2.8959  \n",
      "\n",
      "Fold: 7  Epoch: 457  Training loss = 2.7492  Validation loss = 2.8956  \n",
      "\n",
      "Fold: 7  Epoch: 458  Training loss = 2.7490  Validation loss = 2.8954  \n",
      "\n",
      "Fold: 7  Epoch: 459  Training loss = 2.7489  Validation loss = 2.8952  \n",
      "\n",
      "Fold: 7  Epoch: 460  Training loss = 2.7487  Validation loss = 2.8950  \n",
      "\n",
      "Fold: 7  Epoch: 461  Training loss = 2.7485  Validation loss = 2.8947  \n",
      "\n",
      "Fold: 7  Epoch: 462  Training loss = 2.7484  Validation loss = 2.8945  \n",
      "\n",
      "Fold: 7  Epoch: 463  Training loss = 2.7482  Validation loss = 2.8942  \n",
      "\n",
      "Fold: 7  Epoch: 464  Training loss = 2.7480  Validation loss = 2.8939  \n",
      "\n",
      "Fold: 7  Epoch: 465  Training loss = 2.7478  Validation loss = 2.8936  \n",
      "\n",
      "Fold: 7  Epoch: 466  Training loss = 2.7476  Validation loss = 2.8934  \n",
      "\n",
      "Fold: 7  Epoch: 467  Training loss = 2.7475  Validation loss = 2.8932  \n",
      "\n",
      "Fold: 7  Epoch: 468  Training loss = 2.7473  Validation loss = 2.8929  \n",
      "\n",
      "Fold: 7  Epoch: 469  Training loss = 2.7472  Validation loss = 2.8927  \n",
      "\n",
      "Fold: 7  Epoch: 470  Training loss = 2.7470  Validation loss = 2.8925  \n",
      "\n",
      "Fold: 7  Epoch: 471  Training loss = 2.7468  Validation loss = 2.8923  \n",
      "\n",
      "Fold: 7  Epoch: 472  Training loss = 2.7466  Validation loss = 2.8920  \n",
      "\n",
      "Fold: 7  Epoch: 473  Training loss = 2.7465  Validation loss = 2.8918  \n",
      "\n",
      "Fold: 7  Epoch: 474  Training loss = 2.7463  Validation loss = 2.8916  \n",
      "\n",
      "Fold: 7  Epoch: 475  Training loss = 2.7461  Validation loss = 2.8913  \n",
      "\n",
      "Fold: 7  Epoch: 476  Training loss = 2.7459  Validation loss = 2.8910  \n",
      "\n",
      "Fold: 7  Epoch: 477  Training loss = 2.7458  Validation loss = 2.8908  \n",
      "\n",
      "Fold: 7  Epoch: 478  Training loss = 2.7456  Validation loss = 2.8906  \n",
      "\n",
      "Fold: 7  Epoch: 479  Training loss = 2.7455  Validation loss = 2.8904  \n",
      "\n",
      "Fold: 7  Epoch: 480  Training loss = 2.7453  Validation loss = 2.8902  \n",
      "\n",
      "Fold: 7  Epoch: 481  Training loss = 2.7451  Validation loss = 2.8898  \n",
      "\n",
      "Fold: 7  Epoch: 482  Training loss = 2.7449  Validation loss = 2.8896  \n",
      "\n",
      "Fold: 7  Epoch: 483  Training loss = 2.7448  Validation loss = 2.8894  \n",
      "\n",
      "Fold: 7  Epoch: 484  Training loss = 2.7446  Validation loss = 2.8892  \n",
      "\n",
      "Fold: 7  Epoch: 485  Training loss = 2.7444  Validation loss = 2.8889  \n",
      "\n",
      "Fold: 7  Epoch: 486  Training loss = 2.7442  Validation loss = 2.8887  \n",
      "\n",
      "Fold: 7  Epoch: 487  Training loss = 2.7441  Validation loss = 2.8884  \n",
      "\n",
      "Fold: 7  Epoch: 488  Training loss = 2.7438  Validation loss = 2.8881  \n",
      "\n",
      "Fold: 7  Epoch: 489  Training loss = 2.7436  Validation loss = 2.8879  \n",
      "\n",
      "Fold: 7  Epoch: 490  Training loss = 2.7435  Validation loss = 2.8876  \n",
      "\n",
      "Fold: 7  Epoch: 491  Training loss = 2.7433  Validation loss = 2.8873  \n",
      "\n",
      "Fold: 7  Epoch: 492  Training loss = 2.7431  Validation loss = 2.8871  \n",
      "\n",
      "Fold: 7  Epoch: 493  Training loss = 2.7429  Validation loss = 2.8869  \n",
      "\n",
      "Fold: 7  Epoch: 494  Training loss = 2.7428  Validation loss = 2.8867  \n",
      "\n",
      "Fold: 7  Epoch: 495  Training loss = 2.7426  Validation loss = 2.8864  \n",
      "\n",
      "Fold: 7  Epoch: 496  Training loss = 2.7424  Validation loss = 2.8862  \n",
      "\n",
      "Fold: 7  Epoch: 497  Training loss = 2.7422  Validation loss = 2.8859  \n",
      "\n",
      "Fold: 7  Epoch: 498  Training loss = 2.7420  Validation loss = 2.8857  \n",
      "\n",
      "Fold: 7  Epoch: 499  Training loss = 2.7419  Validation loss = 2.8854  \n",
      "\n",
      "Fold: 7  Epoch: 500  Training loss = 2.7417  Validation loss = 2.8852  \n",
      "\n",
      "Check model:  Fold: 7  Optimal epoch: 500  \n",
      "\n",
      "Fold: 8  Epoch: 1  Training loss = 2.7848  Validation loss = 7.7665  \n",
      "\n",
      "Fold: 8  Epoch: 2  Training loss = 2.7846  Validation loss = 7.7663  \n",
      "\n",
      "Fold: 8  Epoch: 3  Training loss = 2.7844  Validation loss = 7.7661  \n",
      "\n",
      "Fold: 8  Epoch: 4  Training loss = 2.7842  Validation loss = 7.7658  \n",
      "\n",
      "Fold: 8  Epoch: 5  Training loss = 2.7840  Validation loss = 7.7656  \n",
      "\n",
      "Fold: 8  Epoch: 6  Training loss = 2.7838  Validation loss = 7.7654  \n",
      "\n",
      "Fold: 8  Epoch: 7  Training loss = 2.7836  Validation loss = 7.7651  \n",
      "\n",
      "Fold: 8  Epoch: 8  Training loss = 2.7834  Validation loss = 7.7649  \n",
      "\n",
      "Fold: 8  Epoch: 9  Training loss = 2.7831  Validation loss = 7.7647  \n",
      "\n",
      "Fold: 8  Epoch: 10  Training loss = 2.7829  Validation loss = 7.7645  \n",
      "\n",
      "Fold: 8  Epoch: 11  Training loss = 2.7827  Validation loss = 7.7642  \n",
      "\n",
      "Fold: 8  Epoch: 12  Training loss = 2.7825  Validation loss = 7.7640  \n",
      "\n",
      "Fold: 8  Epoch: 13  Training loss = 2.7824  Validation loss = 7.7638  \n",
      "\n",
      "Fold: 8  Epoch: 14  Training loss = 2.7821  Validation loss = 7.7636  \n",
      "\n",
      "Fold: 8  Epoch: 15  Training loss = 2.7820  Validation loss = 7.7634  \n",
      "\n",
      "Fold: 8  Epoch: 16  Training loss = 2.7818  Validation loss = 7.7632  \n",
      "\n",
      "Fold: 8  Epoch: 17  Training loss = 2.7816  Validation loss = 7.7630  \n",
      "\n",
      "Fold: 8  Epoch: 18  Training loss = 2.7814  Validation loss = 7.7628  \n",
      "\n",
      "Fold: 8  Epoch: 19  Training loss = 2.7812  Validation loss = 7.7625  \n",
      "\n",
      "Fold: 8  Epoch: 20  Training loss = 2.7810  Validation loss = 7.7623  \n",
      "\n",
      "Fold: 8  Epoch: 21  Training loss = 2.7808  Validation loss = 7.7620  \n",
      "\n",
      "Fold: 8  Epoch: 22  Training loss = 2.7806  Validation loss = 7.7618  \n",
      "\n",
      "Fold: 8  Epoch: 23  Training loss = 2.7803  Validation loss = 7.7615  \n",
      "\n",
      "Fold: 8  Epoch: 24  Training loss = 2.7801  Validation loss = 7.7613  \n",
      "\n",
      "Fold: 8  Epoch: 25  Training loss = 2.7799  Validation loss = 7.7611  \n",
      "\n",
      "Fold: 8  Epoch: 26  Training loss = 2.7797  Validation loss = 7.7609  \n",
      "\n",
      "Fold: 8  Epoch: 27  Training loss = 2.7795  Validation loss = 7.7607  \n",
      "\n",
      "Fold: 8  Epoch: 28  Training loss = 2.7793  Validation loss = 7.7605  \n",
      "\n",
      "Fold: 8  Epoch: 29  Training loss = 2.7791  Validation loss = 7.7602  \n",
      "\n",
      "Fold: 8  Epoch: 30  Training loss = 2.7790  Validation loss = 7.7601  \n",
      "\n",
      "Fold: 8  Epoch: 31  Training loss = 2.7787  Validation loss = 7.7598  \n",
      "\n",
      "Fold: 8  Epoch: 32  Training loss = 2.7785  Validation loss = 7.7596  \n",
      "\n",
      "Fold: 8  Epoch: 33  Training loss = 2.7783  Validation loss = 7.7594  \n",
      "\n",
      "Fold: 8  Epoch: 34  Training loss = 2.7782  Validation loss = 7.7592  \n",
      "\n",
      "Fold: 8  Epoch: 35  Training loss = 2.7780  Validation loss = 7.7590  \n",
      "\n",
      "Fold: 8  Epoch: 36  Training loss = 2.7778  Validation loss = 7.7588  \n",
      "\n",
      "Fold: 8  Epoch: 37  Training loss = 2.7776  Validation loss = 7.7585  \n",
      "\n",
      "Fold: 8  Epoch: 38  Training loss = 2.7774  Validation loss = 7.7583  \n",
      "\n",
      "Fold: 8  Epoch: 39  Training loss = 2.7771  Validation loss = 7.7580  \n",
      "\n",
      "Fold: 8  Epoch: 40  Training loss = 2.7769  Validation loss = 7.7578  \n",
      "\n",
      "Fold: 8  Epoch: 41  Training loss = 2.7767  Validation loss = 7.7576  \n",
      "\n",
      "Fold: 8  Epoch: 42  Training loss = 2.7766  Validation loss = 7.7574  \n",
      "\n",
      "Fold: 8  Epoch: 43  Training loss = 2.7764  Validation loss = 7.7572  \n",
      "\n",
      "Fold: 8  Epoch: 44  Training loss = 2.7762  Validation loss = 7.7570  \n",
      "\n",
      "Fold: 8  Epoch: 45  Training loss = 2.7761  Validation loss = 7.7568  \n",
      "\n",
      "Fold: 8  Epoch: 46  Training loss = 2.7759  Validation loss = 7.7566  \n",
      "\n",
      "Fold: 8  Epoch: 47  Training loss = 2.7756  Validation loss = 7.7564  \n",
      "\n",
      "Fold: 8  Epoch: 48  Training loss = 2.7754  Validation loss = 7.7561  \n",
      "\n",
      "Fold: 8  Epoch: 49  Training loss = 2.7752  Validation loss = 7.7559  \n",
      "\n",
      "Fold: 8  Epoch: 50  Training loss = 2.7751  Validation loss = 7.7557  \n",
      "\n",
      "Fold: 8  Epoch: 51  Training loss = 2.7749  Validation loss = 7.7555  \n",
      "\n",
      "Fold: 8  Epoch: 52  Training loss = 2.7746  Validation loss = 7.7553  \n",
      "\n",
      "Fold: 8  Epoch: 53  Training loss = 2.7744  Validation loss = 7.7550  \n",
      "\n",
      "Fold: 8  Epoch: 54  Training loss = 2.7742  Validation loss = 7.7548  \n",
      "\n",
      "Fold: 8  Epoch: 55  Training loss = 2.7740  Validation loss = 7.7546  \n",
      "\n",
      "Fold: 8  Epoch: 56  Training loss = 2.7738  Validation loss = 7.7544  \n",
      "\n",
      "Fold: 8  Epoch: 57  Training loss = 2.7736  Validation loss = 7.7542  \n",
      "\n",
      "Fold: 8  Epoch: 58  Training loss = 2.7734  Validation loss = 7.7539  \n",
      "\n",
      "Fold: 8  Epoch: 59  Training loss = 2.7733  Validation loss = 7.7538  \n",
      "\n",
      "Fold: 8  Epoch: 60  Training loss = 2.7731  Validation loss = 7.7536  \n",
      "\n",
      "Fold: 8  Epoch: 61  Training loss = 2.7729  Validation loss = 7.7533  \n",
      "\n",
      "Fold: 8  Epoch: 62  Training loss = 2.7727  Validation loss = 7.7531  \n",
      "\n",
      "Fold: 8  Epoch: 63  Training loss = 2.7725  Validation loss = 7.7529  \n",
      "\n",
      "Fold: 8  Epoch: 64  Training loss = 2.7723  Validation loss = 7.7526  \n",
      "\n",
      "Fold: 8  Epoch: 65  Training loss = 2.7721  Validation loss = 7.7524  \n",
      "\n",
      "Fold: 8  Epoch: 66  Training loss = 2.7719  Validation loss = 7.7522  \n",
      "\n",
      "Fold: 8  Epoch: 67  Training loss = 2.7716  Validation loss = 7.7519  \n",
      "\n",
      "Fold: 8  Epoch: 68  Training loss = 2.7714  Validation loss = 7.7517  \n",
      "\n",
      "Fold: 8  Epoch: 69  Training loss = 2.7712  Validation loss = 7.7515  \n",
      "\n",
      "Fold: 8  Epoch: 70  Training loss = 2.7710  Validation loss = 7.7512  \n",
      "\n",
      "Fold: 8  Epoch: 71  Training loss = 2.7708  Validation loss = 7.7510  \n",
      "\n",
      "Fold: 8  Epoch: 72  Training loss = 2.7705  Validation loss = 7.7507  \n",
      "\n",
      "Fold: 8  Epoch: 73  Training loss = 2.7704  Validation loss = 7.7505  \n",
      "\n",
      "Fold: 8  Epoch: 74  Training loss = 2.7702  Validation loss = 7.7503  \n",
      "\n",
      "Fold: 8  Epoch: 75  Training loss = 2.7700  Validation loss = 7.7501  \n",
      "\n",
      "Fold: 8  Epoch: 76  Training loss = 2.7698  Validation loss = 7.7499  \n",
      "\n",
      "Fold: 8  Epoch: 77  Training loss = 2.7696  Validation loss = 7.7497  \n",
      "\n",
      "Fold: 8  Epoch: 78  Training loss = 2.7695  Validation loss = 7.7495  \n",
      "\n",
      "Fold: 8  Epoch: 79  Training loss = 2.7692  Validation loss = 7.7493  \n",
      "\n",
      "Fold: 8  Epoch: 80  Training loss = 2.7690  Validation loss = 7.7491  \n",
      "\n",
      "Fold: 8  Epoch: 81  Training loss = 2.7688  Validation loss = 7.7489  \n",
      "\n",
      "Fold: 8  Epoch: 82  Training loss = 2.7686  Validation loss = 7.7486  \n",
      "\n",
      "Fold: 8  Epoch: 83  Training loss = 2.7684  Validation loss = 7.7484  \n",
      "\n",
      "Fold: 8  Epoch: 84  Training loss = 2.7681  Validation loss = 7.7481  \n",
      "\n",
      "Fold: 8  Epoch: 85  Training loss = 2.7679  Validation loss = 7.7479  \n",
      "\n",
      "Fold: 8  Epoch: 86  Training loss = 2.7677  Validation loss = 7.7476  \n",
      "\n",
      "Fold: 8  Epoch: 87  Training loss = 2.7675  Validation loss = 7.7474  \n",
      "\n",
      "Fold: 8  Epoch: 88  Training loss = 2.7673  Validation loss = 7.7472  \n",
      "\n",
      "Fold: 8  Epoch: 89  Training loss = 2.7671  Validation loss = 7.7470  \n",
      "\n",
      "Fold: 8  Epoch: 90  Training loss = 2.7669  Validation loss = 7.7468  \n",
      "\n",
      "Fold: 8  Epoch: 91  Training loss = 2.7667  Validation loss = 7.7465  \n",
      "\n",
      "Fold: 8  Epoch: 92  Training loss = 2.7665  Validation loss = 7.7463  \n",
      "\n",
      "Fold: 8  Epoch: 93  Training loss = 2.7663  Validation loss = 7.7461  \n",
      "\n",
      "Fold: 8  Epoch: 94  Training loss = 2.7661  Validation loss = 7.7459  \n",
      "\n",
      "Fold: 8  Epoch: 95  Training loss = 2.7658  Validation loss = 7.7456  \n",
      "\n",
      "Fold: 8  Epoch: 96  Training loss = 2.7656  Validation loss = 7.7454  \n",
      "\n",
      "Fold: 8  Epoch: 97  Training loss = 2.7654  Validation loss = 7.7452  \n",
      "\n",
      "Fold: 8  Epoch: 98  Training loss = 2.7652  Validation loss = 7.7450  \n",
      "\n",
      "Fold: 8  Epoch: 99  Training loss = 2.7650  Validation loss = 7.7448  \n",
      "\n",
      "Fold: 8  Epoch: 100  Training loss = 2.7648  Validation loss = 7.7446  \n",
      "\n",
      "Fold: 8  Epoch: 101  Training loss = 2.7646  Validation loss = 7.7443  \n",
      "\n",
      "Fold: 8  Epoch: 102  Training loss = 2.7644  Validation loss = 7.7441  \n",
      "\n",
      "Fold: 8  Epoch: 103  Training loss = 2.7642  Validation loss = 7.7439  \n",
      "\n",
      "Fold: 8  Epoch: 104  Training loss = 2.7640  Validation loss = 7.7436  \n",
      "\n",
      "Fold: 8  Epoch: 105  Training loss = 2.7637  Validation loss = 7.7433  \n",
      "\n",
      "Fold: 8  Epoch: 106  Training loss = 2.7635  Validation loss = 7.7431  \n",
      "\n",
      "Fold: 8  Epoch: 107  Training loss = 2.7633  Validation loss = 7.7429  \n",
      "\n",
      "Fold: 8  Epoch: 108  Training loss = 2.7631  Validation loss = 7.7427  \n",
      "\n",
      "Fold: 8  Epoch: 109  Training loss = 2.7629  Validation loss = 7.7425  \n",
      "\n",
      "Fold: 8  Epoch: 110  Training loss = 2.7627  Validation loss = 7.7423  \n",
      "\n",
      "Fold: 8  Epoch: 111  Training loss = 2.7625  Validation loss = 7.7421  \n",
      "\n",
      "Fold: 8  Epoch: 112  Training loss = 2.7623  Validation loss = 7.7418  \n",
      "\n",
      "Fold: 8  Epoch: 113  Training loss = 2.7621  Validation loss = 7.7417  \n",
      "\n",
      "Fold: 8  Epoch: 114  Training loss = 2.7619  Validation loss = 7.7414  \n",
      "\n",
      "Fold: 8  Epoch: 115  Training loss = 2.7617  Validation loss = 7.7412  \n",
      "\n",
      "Fold: 8  Epoch: 116  Training loss = 2.7614  Validation loss = 7.7409  \n",
      "\n",
      "Fold: 8  Epoch: 117  Training loss = 2.7612  Validation loss = 7.7407  \n",
      "\n",
      "Fold: 8  Epoch: 118  Training loss = 2.7611  Validation loss = 7.7405  \n",
      "\n",
      "Fold: 8  Epoch: 119  Training loss = 2.7609  Validation loss = 7.7403  \n",
      "\n",
      "Fold: 8  Epoch: 120  Training loss = 2.7607  Validation loss = 7.7401  \n",
      "\n",
      "Fold: 8  Epoch: 121  Training loss = 2.7605  Validation loss = 7.7399  \n",
      "\n",
      "Fold: 8  Epoch: 122  Training loss = 2.7603  Validation loss = 7.7396  \n",
      "\n",
      "Fold: 8  Epoch: 123  Training loss = 2.7601  Validation loss = 7.7394  \n",
      "\n",
      "Fold: 8  Epoch: 124  Training loss = 2.7599  Validation loss = 7.7392  \n",
      "\n",
      "Fold: 8  Epoch: 125  Training loss = 2.7597  Validation loss = 7.7390  \n",
      "\n",
      "Fold: 8  Epoch: 126  Training loss = 2.7595  Validation loss = 7.7388  \n",
      "\n",
      "Fold: 8  Epoch: 127  Training loss = 2.7593  Validation loss = 7.7386  \n",
      "\n",
      "Fold: 8  Epoch: 128  Training loss = 2.7591  Validation loss = 7.7384  \n",
      "\n",
      "Fold: 8  Epoch: 129  Training loss = 2.7589  Validation loss = 7.7382  \n",
      "\n",
      "Fold: 8  Epoch: 130  Training loss = 2.7587  Validation loss = 7.7379  \n",
      "\n",
      "Fold: 8  Epoch: 131  Training loss = 2.7586  Validation loss = 7.7378  \n",
      "\n",
      "Fold: 8  Epoch: 132  Training loss = 2.7583  Validation loss = 7.7375  \n",
      "\n",
      "Fold: 8  Epoch: 133  Training loss = 2.7581  Validation loss = 7.7373  \n",
      "\n",
      "Fold: 8  Epoch: 134  Training loss = 2.7580  Validation loss = 7.7371  \n",
      "\n",
      "Fold: 8  Epoch: 135  Training loss = 2.7577  Validation loss = 7.7369  \n",
      "\n",
      "Fold: 8  Epoch: 136  Training loss = 2.7576  Validation loss = 7.7366  \n",
      "\n",
      "Fold: 8  Epoch: 137  Training loss = 2.7574  Validation loss = 7.7365  \n",
      "\n",
      "Fold: 8  Epoch: 138  Training loss = 2.7572  Validation loss = 7.7362  \n",
      "\n",
      "Fold: 8  Epoch: 139  Training loss = 2.7570  Validation loss = 7.7360  \n",
      "\n",
      "Fold: 8  Epoch: 140  Training loss = 2.7568  Validation loss = 7.7358  \n",
      "\n",
      "Fold: 8  Epoch: 141  Training loss = 2.7565  Validation loss = 7.7355  \n",
      "\n",
      "Fold: 8  Epoch: 142  Training loss = 2.7564  Validation loss = 7.7354  \n",
      "\n",
      "Fold: 8  Epoch: 143  Training loss = 2.7562  Validation loss = 7.7352  \n",
      "\n",
      "Fold: 8  Epoch: 144  Training loss = 2.7560  Validation loss = 7.7349  \n",
      "\n",
      "Fold: 8  Epoch: 145  Training loss = 2.7558  Validation loss = 7.7347  \n",
      "\n",
      "Fold: 8  Epoch: 146  Training loss = 2.7556  Validation loss = 7.7345  \n",
      "\n",
      "Fold: 8  Epoch: 147  Training loss = 2.7554  Validation loss = 7.7342  \n",
      "\n",
      "Fold: 8  Epoch: 148  Training loss = 2.7552  Validation loss = 7.7340  \n",
      "\n",
      "Fold: 8  Epoch: 149  Training loss = 2.7550  Validation loss = 7.7338  \n",
      "\n",
      "Fold: 8  Epoch: 150  Training loss = 2.7548  Validation loss = 7.7336  \n",
      "\n",
      "Fold: 8  Epoch: 151  Training loss = 2.7546  Validation loss = 7.7334  \n",
      "\n",
      "Fold: 8  Epoch: 152  Training loss = 2.7544  Validation loss = 7.7332  \n",
      "\n",
      "Fold: 8  Epoch: 153  Training loss = 2.7542  Validation loss = 7.7330  \n",
      "\n",
      "Fold: 8  Epoch: 154  Training loss = 2.7540  Validation loss = 7.7328  \n",
      "\n",
      "Fold: 8  Epoch: 155  Training loss = 2.7538  Validation loss = 7.7326  \n",
      "\n",
      "Fold: 8  Epoch: 156  Training loss = 2.7536  Validation loss = 7.7323  \n",
      "\n",
      "Fold: 8  Epoch: 157  Training loss = 2.7534  Validation loss = 7.7321  \n",
      "\n",
      "Fold: 8  Epoch: 158  Training loss = 2.7532  Validation loss = 7.7319  \n",
      "\n",
      "Fold: 8  Epoch: 159  Training loss = 2.7531  Validation loss = 7.7318  \n",
      "\n",
      "Fold: 8  Epoch: 160  Training loss = 2.7529  Validation loss = 7.7315  \n",
      "\n",
      "Fold: 8  Epoch: 161  Training loss = 2.7526  Validation loss = 7.7313  \n",
      "\n",
      "Fold: 8  Epoch: 162  Training loss = 2.7524  Validation loss = 7.7311  \n",
      "\n",
      "Fold: 8  Epoch: 163  Training loss = 2.7522  Validation loss = 7.7308  \n",
      "\n",
      "Fold: 8  Epoch: 164  Training loss = 2.7521  Validation loss = 7.7306  \n",
      "\n",
      "Fold: 8  Epoch: 165  Training loss = 2.7518  Validation loss = 7.7304  \n",
      "\n",
      "Fold: 8  Epoch: 166  Training loss = 2.7516  Validation loss = 7.7302  \n",
      "\n",
      "Fold: 8  Epoch: 167  Training loss = 2.7515  Validation loss = 7.7300  \n",
      "\n",
      "Fold: 8  Epoch: 168  Training loss = 2.7512  Validation loss = 7.7297  \n",
      "\n",
      "Fold: 8  Epoch: 169  Training loss = 2.7510  Validation loss = 7.7295  \n",
      "\n",
      "Fold: 8  Epoch: 170  Training loss = 2.7508  Validation loss = 7.7293  \n",
      "\n",
      "Fold: 8  Epoch: 171  Training loss = 2.7506  Validation loss = 7.7290  \n",
      "\n",
      "Fold: 8  Epoch: 172  Training loss = 2.7504  Validation loss = 7.7288  \n",
      "\n",
      "Fold: 8  Epoch: 173  Training loss = 2.7502  Validation loss = 7.7286  \n",
      "\n",
      "Fold: 8  Epoch: 174  Training loss = 2.7500  Validation loss = 7.7284  \n",
      "\n",
      "Fold: 8  Epoch: 175  Training loss = 2.7498  Validation loss = 7.7282  \n",
      "\n",
      "Fold: 8  Epoch: 176  Training loss = 2.7496  Validation loss = 7.7279  \n",
      "\n",
      "Fold: 8  Epoch: 177  Training loss = 2.7494  Validation loss = 7.7277  \n",
      "\n",
      "Fold: 8  Epoch: 178  Training loss = 2.7492  Validation loss = 7.7275  \n",
      "\n",
      "Fold: 8  Epoch: 179  Training loss = 2.7490  Validation loss = 7.7273  \n",
      "\n",
      "Fold: 8  Epoch: 180  Training loss = 2.7488  Validation loss = 7.7271  \n",
      "\n",
      "Fold: 8  Epoch: 181  Training loss = 2.7486  Validation loss = 7.7269  \n",
      "\n",
      "Fold: 8  Epoch: 182  Training loss = 2.7484  Validation loss = 7.7266  \n",
      "\n",
      "Fold: 8  Epoch: 183  Training loss = 2.7482  Validation loss = 7.7264  \n",
      "\n",
      "Fold: 8  Epoch: 184  Training loss = 2.7480  Validation loss = 7.7262  \n",
      "\n",
      "Fold: 8  Epoch: 185  Training loss = 2.7477  Validation loss = 7.7259  \n",
      "\n",
      "Fold: 8  Epoch: 186  Training loss = 2.7475  Validation loss = 7.7257  \n",
      "\n",
      "Fold: 8  Epoch: 187  Training loss = 2.7473  Validation loss = 7.7254  \n",
      "\n",
      "Fold: 8  Epoch: 188  Training loss = 2.7471  Validation loss = 7.7252  \n",
      "\n",
      "Fold: 8  Epoch: 189  Training loss = 2.7469  Validation loss = 7.7250  \n",
      "\n",
      "Fold: 8  Epoch: 190  Training loss = 2.7466  Validation loss = 7.7247  \n",
      "\n",
      "Fold: 8  Epoch: 191  Training loss = 2.7464  Validation loss = 7.7245  \n",
      "\n",
      "Fold: 8  Epoch: 192  Training loss = 2.7462  Validation loss = 7.7242  \n",
      "\n",
      "Fold: 8  Epoch: 193  Training loss = 2.7460  Validation loss = 7.7240  \n",
      "\n",
      "Fold: 8  Epoch: 194  Training loss = 2.7458  Validation loss = 7.7238  \n",
      "\n",
      "Fold: 8  Epoch: 195  Training loss = 2.7456  Validation loss = 7.7236  \n",
      "\n",
      "Fold: 8  Epoch: 196  Training loss = 2.7454  Validation loss = 7.7233  \n",
      "\n",
      "Fold: 8  Epoch: 197  Training loss = 2.7452  Validation loss = 7.7231  \n",
      "\n",
      "Fold: 8  Epoch: 198  Training loss = 2.7449  Validation loss = 7.7229  \n",
      "\n",
      "Fold: 8  Epoch: 199  Training loss = 2.7447  Validation loss = 7.7226  \n",
      "\n",
      "Fold: 8  Epoch: 200  Training loss = 2.7445  Validation loss = 7.7224  \n",
      "\n",
      "Fold: 8  Epoch: 201  Training loss = 2.7443  Validation loss = 7.7222  \n",
      "\n",
      "Fold: 8  Epoch: 202  Training loss = 2.7441  Validation loss = 7.7220  \n",
      "\n",
      "Fold: 8  Epoch: 203  Training loss = 2.7440  Validation loss = 7.7218  \n",
      "\n",
      "Fold: 8  Epoch: 204  Training loss = 2.7438  Validation loss = 7.7216  \n",
      "\n",
      "Fold: 8  Epoch: 205  Training loss = 2.7436  Validation loss = 7.7214  \n",
      "\n",
      "Fold: 8  Epoch: 206  Training loss = 2.7434  Validation loss = 7.7212  \n",
      "\n",
      "Fold: 8  Epoch: 207  Training loss = 2.7432  Validation loss = 7.7210  \n",
      "\n",
      "Fold: 8  Epoch: 208  Training loss = 2.7430  Validation loss = 7.7208  \n",
      "\n",
      "Fold: 8  Epoch: 209  Training loss = 2.7428  Validation loss = 7.7205  \n",
      "\n",
      "Fold: 8  Epoch: 210  Training loss = 2.7426  Validation loss = 7.7203  \n",
      "\n",
      "Fold: 8  Epoch: 211  Training loss = 2.7424  Validation loss = 7.7201  \n",
      "\n",
      "Fold: 8  Epoch: 212  Training loss = 2.7422  Validation loss = 7.7199  \n",
      "\n",
      "Fold: 8  Epoch: 213  Training loss = 2.7420  Validation loss = 7.7197  \n",
      "\n",
      "Fold: 8  Epoch: 214  Training loss = 2.7418  Validation loss = 7.7194  \n",
      "\n",
      "Fold: 8  Epoch: 215  Training loss = 2.7416  Validation loss = 7.7192  \n",
      "\n",
      "Fold: 8  Epoch: 216  Training loss = 2.7414  Validation loss = 7.7190  \n",
      "\n",
      "Fold: 8  Epoch: 217  Training loss = 2.7412  Validation loss = 7.7188  \n",
      "\n",
      "Fold: 8  Epoch: 218  Training loss = 2.7410  Validation loss = 7.7186  \n",
      "\n",
      "Fold: 8  Epoch: 219  Training loss = 2.7408  Validation loss = 7.7183  \n",
      "\n",
      "Fold: 8  Epoch: 220  Training loss = 2.7405  Validation loss = 7.7181  \n",
      "\n",
      "Fold: 8  Epoch: 221  Training loss = 2.7403  Validation loss = 7.7178  \n",
      "\n",
      "Fold: 8  Epoch: 222  Training loss = 2.7401  Validation loss = 7.7176  \n",
      "\n",
      "Fold: 8  Epoch: 223  Training loss = 2.7399  Validation loss = 7.7174  \n",
      "\n",
      "Fold: 8  Epoch: 224  Training loss = 2.7397  Validation loss = 7.7172  \n",
      "\n",
      "Fold: 8  Epoch: 225  Training loss = 2.7396  Validation loss = 7.7170  \n",
      "\n",
      "Fold: 8  Epoch: 226  Training loss = 2.7394  Validation loss = 7.7168  \n",
      "\n",
      "Fold: 8  Epoch: 227  Training loss = 2.7391  Validation loss = 7.7166  \n",
      "\n",
      "Fold: 8  Epoch: 228  Training loss = 2.7389  Validation loss = 7.7164  \n",
      "\n",
      "Fold: 8  Epoch: 229  Training loss = 2.7388  Validation loss = 7.7162  \n",
      "\n",
      "Fold: 8  Epoch: 230  Training loss = 2.7386  Validation loss = 7.7160  \n",
      "\n",
      "Fold: 8  Epoch: 231  Training loss = 2.7384  Validation loss = 7.7157  \n",
      "\n",
      "Fold: 8  Epoch: 232  Training loss = 2.7381  Validation loss = 7.7155  \n",
      "\n",
      "Fold: 8  Epoch: 233  Training loss = 2.7379  Validation loss = 7.7153  \n",
      "\n",
      "Fold: 8  Epoch: 234  Training loss = 2.7378  Validation loss = 7.7151  \n",
      "\n",
      "Fold: 8  Epoch: 235  Training loss = 2.7376  Validation loss = 7.7149  \n",
      "\n",
      "Fold: 8  Epoch: 236  Training loss = 2.7374  Validation loss = 7.7147  \n",
      "\n",
      "Fold: 8  Epoch: 237  Training loss = 2.7373  Validation loss = 7.7145  \n",
      "\n",
      "Fold: 8  Epoch: 238  Training loss = 2.7370  Validation loss = 7.7143  \n",
      "\n",
      "Fold: 8  Epoch: 239  Training loss = 2.7368  Validation loss = 7.7140  \n",
      "\n",
      "Fold: 8  Epoch: 240  Training loss = 2.7366  Validation loss = 7.7138  \n",
      "\n",
      "Fold: 8  Epoch: 241  Training loss = 2.7364  Validation loss = 7.7136  \n",
      "\n",
      "Fold: 8  Epoch: 242  Training loss = 2.7363  Validation loss = 7.7134  \n",
      "\n",
      "Fold: 8  Epoch: 243  Training loss = 2.7360  Validation loss = 7.7132  \n",
      "\n",
      "Fold: 8  Epoch: 244  Training loss = 2.7359  Validation loss = 7.7130  \n",
      "\n",
      "Fold: 8  Epoch: 245  Training loss = 2.7356  Validation loss = 7.7127  \n",
      "\n",
      "Fold: 8  Epoch: 246  Training loss = 2.7354  Validation loss = 7.7125  \n",
      "\n",
      "Fold: 8  Epoch: 247  Training loss = 2.7352  Validation loss = 7.7123  \n",
      "\n",
      "Fold: 8  Epoch: 248  Training loss = 2.7350  Validation loss = 7.7121  \n",
      "\n",
      "Fold: 8  Epoch: 249  Training loss = 2.7348  Validation loss = 7.7119  \n",
      "\n",
      "Fold: 8  Epoch: 250  Training loss = 2.7346  Validation loss = 7.7116  \n",
      "\n",
      "Fold: 8  Epoch: 251  Training loss = 2.7344  Validation loss = 7.7114  \n",
      "\n",
      "Fold: 8  Epoch: 252  Training loss = 2.7342  Validation loss = 7.7112  \n",
      "\n",
      "Fold: 8  Epoch: 253  Training loss = 2.7340  Validation loss = 7.7110  \n",
      "\n",
      "Fold: 8  Epoch: 254  Training loss = 2.7338  Validation loss = 7.7108  \n",
      "\n",
      "Fold: 8  Epoch: 255  Training loss = 2.7336  Validation loss = 7.7106  \n",
      "\n",
      "Fold: 8  Epoch: 256  Training loss = 2.7334  Validation loss = 7.7103  \n",
      "\n",
      "Fold: 8  Epoch: 257  Training loss = 2.7332  Validation loss = 7.7101  \n",
      "\n",
      "Fold: 8  Epoch: 258  Training loss = 2.7330  Validation loss = 7.7099  \n",
      "\n",
      "Fold: 8  Epoch: 259  Training loss = 2.7327  Validation loss = 7.7096  \n",
      "\n",
      "Fold: 8  Epoch: 260  Training loss = 2.7325  Validation loss = 7.7093  \n",
      "\n",
      "Fold: 8  Epoch: 261  Training loss = 2.7323  Validation loss = 7.7091  \n",
      "\n",
      "Fold: 8  Epoch: 262  Training loss = 2.7321  Validation loss = 7.7089  \n",
      "\n",
      "Fold: 8  Epoch: 263  Training loss = 2.7319  Validation loss = 7.7087  \n",
      "\n",
      "Fold: 8  Epoch: 264  Training loss = 2.7317  Validation loss = 7.7084  \n",
      "\n",
      "Fold: 8  Epoch: 265  Training loss = 2.7315  Validation loss = 7.7082  \n",
      "\n",
      "Fold: 8  Epoch: 266  Training loss = 2.7313  Validation loss = 7.7080  \n",
      "\n",
      "Fold: 8  Epoch: 267  Training loss = 2.7310  Validation loss = 7.7078  \n",
      "\n",
      "Fold: 8  Epoch: 268  Training loss = 2.7308  Validation loss = 7.7076  \n",
      "\n",
      "Fold: 8  Epoch: 269  Training loss = 2.7307  Validation loss = 7.7073  \n",
      "\n",
      "Fold: 8  Epoch: 270  Training loss = 2.7305  Validation loss = 7.7071  \n",
      "\n",
      "Fold: 8  Epoch: 271  Training loss = 2.7303  Validation loss = 7.7069  \n",
      "\n",
      "Fold: 8  Epoch: 272  Training loss = 2.7301  Validation loss = 7.7067  \n",
      "\n",
      "Fold: 8  Epoch: 273  Training loss = 2.7299  Validation loss = 7.7065  \n",
      "\n",
      "Fold: 8  Epoch: 274  Training loss = 2.7297  Validation loss = 7.7063  \n",
      "\n",
      "Fold: 8  Epoch: 275  Training loss = 2.7295  Validation loss = 7.7061  \n",
      "\n",
      "Fold: 8  Epoch: 276  Training loss = 2.7293  Validation loss = 7.7059  \n",
      "\n",
      "Fold: 8  Epoch: 277  Training loss = 2.7291  Validation loss = 7.7056  \n",
      "\n",
      "Fold: 8  Epoch: 278  Training loss = 2.7289  Validation loss = 7.7054  \n",
      "\n",
      "Fold: 8  Epoch: 279  Training loss = 2.7287  Validation loss = 7.7052  \n",
      "\n",
      "Fold: 8  Epoch: 280  Training loss = 2.7285  Validation loss = 7.7050  \n",
      "\n",
      "Fold: 8  Epoch: 281  Training loss = 2.7283  Validation loss = 7.7048  \n",
      "\n",
      "Fold: 8  Epoch: 282  Training loss = 2.7281  Validation loss = 7.7046  \n",
      "\n",
      "Fold: 8  Epoch: 283  Training loss = 2.7279  Validation loss = 7.7044  \n",
      "\n",
      "Fold: 8  Epoch: 284  Training loss = 2.7277  Validation loss = 7.7042  \n",
      "\n",
      "Fold: 8  Epoch: 285  Training loss = 2.7275  Validation loss = 7.7039  \n",
      "\n",
      "Fold: 8  Epoch: 286  Training loss = 2.7273  Validation loss = 7.7037  \n",
      "\n",
      "Fold: 8  Epoch: 287  Training loss = 2.7271  Validation loss = 7.7035  \n",
      "\n",
      "Fold: 8  Epoch: 288  Training loss = 2.7269  Validation loss = 7.7033  \n",
      "\n",
      "Fold: 8  Epoch: 289  Training loss = 2.7268  Validation loss = 7.7031  \n",
      "\n",
      "Fold: 8  Epoch: 290  Training loss = 2.7266  Validation loss = 7.7029  \n",
      "\n",
      "Fold: 8  Epoch: 291  Training loss = 2.7264  Validation loss = 7.7027  \n",
      "\n",
      "Fold: 8  Epoch: 292  Training loss = 2.7262  Validation loss = 7.7025  \n",
      "\n",
      "Fold: 8  Epoch: 293  Training loss = 2.7260  Validation loss = 7.7022  \n",
      "\n",
      "Fold: 8  Epoch: 294  Training loss = 2.7258  Validation loss = 7.7020  \n",
      "\n",
      "Fold: 8  Epoch: 295  Training loss = 2.7256  Validation loss = 7.7018  \n",
      "\n",
      "Fold: 8  Epoch: 296  Training loss = 2.7253  Validation loss = 7.7016  \n",
      "\n",
      "Fold: 8  Epoch: 297  Training loss = 2.7251  Validation loss = 7.7013  \n",
      "\n",
      "Fold: 8  Epoch: 298  Training loss = 2.7249  Validation loss = 7.7011  \n",
      "\n",
      "Fold: 8  Epoch: 299  Training loss = 2.7247  Validation loss = 7.7009  \n",
      "\n",
      "Fold: 8  Epoch: 300  Training loss = 2.7245  Validation loss = 7.7007  \n",
      "\n",
      "Fold: 8  Epoch: 301  Training loss = 2.7244  Validation loss = 7.7005  \n",
      "\n",
      "Fold: 8  Epoch: 302  Training loss = 2.7241  Validation loss = 7.7003  \n",
      "\n",
      "Fold: 8  Epoch: 303  Training loss = 2.7240  Validation loss = 7.7001  \n",
      "\n",
      "Fold: 8  Epoch: 304  Training loss = 2.7238  Validation loss = 7.6999  \n",
      "\n",
      "Fold: 8  Epoch: 305  Training loss = 2.7236  Validation loss = 7.6996  \n",
      "\n",
      "Fold: 8  Epoch: 306  Training loss = 2.7234  Validation loss = 7.6994  \n",
      "\n",
      "Fold: 8  Epoch: 307  Training loss = 2.7232  Validation loss = 7.6992  \n",
      "\n",
      "Fold: 8  Epoch: 308  Training loss = 2.7230  Validation loss = 7.6991  \n",
      "\n",
      "Fold: 8  Epoch: 309  Training loss = 2.7228  Validation loss = 7.6988  \n",
      "\n",
      "Fold: 8  Epoch: 310  Training loss = 2.7226  Validation loss = 7.6986  \n",
      "\n",
      "Fold: 8  Epoch: 311  Training loss = 2.7224  Validation loss = 7.6984  \n",
      "\n",
      "Fold: 8  Epoch: 312  Training loss = 2.7222  Validation loss = 7.6981  \n",
      "\n",
      "Fold: 8  Epoch: 313  Training loss = 2.7220  Validation loss = 7.6979  \n",
      "\n",
      "Fold: 8  Epoch: 314  Training loss = 2.7218  Validation loss = 7.6977  \n",
      "\n",
      "Fold: 8  Epoch: 315  Training loss = 2.7216  Validation loss = 7.6975  \n",
      "\n",
      "Fold: 8  Epoch: 316  Training loss = 2.7214  Validation loss = 7.6973  \n",
      "\n",
      "Fold: 8  Epoch: 317  Training loss = 2.7212  Validation loss = 7.6971  \n",
      "\n",
      "Fold: 8  Epoch: 318  Training loss = 2.7210  Validation loss = 7.6968  \n",
      "\n",
      "Fold: 8  Epoch: 319  Training loss = 2.7207  Validation loss = 7.6966  \n",
      "\n",
      "Fold: 8  Epoch: 320  Training loss = 2.7205  Validation loss = 7.6964  \n",
      "\n",
      "Fold: 8  Epoch: 321  Training loss = 2.7203  Validation loss = 7.6962  \n",
      "\n",
      "Fold: 8  Epoch: 322  Training loss = 2.7201  Validation loss = 7.6959  \n",
      "\n",
      "Fold: 8  Epoch: 323  Training loss = 2.7199  Validation loss = 7.6957  \n",
      "\n",
      "Fold: 8  Epoch: 324  Training loss = 2.7197  Validation loss = 7.6955  \n",
      "\n",
      "Fold: 8  Epoch: 325  Training loss = 2.7195  Validation loss = 7.6953  \n",
      "\n",
      "Fold: 8  Epoch: 326  Training loss = 2.7193  Validation loss = 7.6951  \n",
      "\n",
      "Fold: 8  Epoch: 327  Training loss = 2.7191  Validation loss = 7.6949  \n",
      "\n",
      "Fold: 8  Epoch: 328  Training loss = 2.7190  Validation loss = 7.6947  \n",
      "\n",
      "Fold: 8  Epoch: 329  Training loss = 2.7188  Validation loss = 7.6945  \n",
      "\n",
      "Fold: 8  Epoch: 330  Training loss = 2.7185  Validation loss = 7.6942  \n",
      "\n",
      "Fold: 8  Epoch: 331  Training loss = 2.7183  Validation loss = 7.6940  \n",
      "\n",
      "Fold: 8  Epoch: 332  Training loss = 2.7182  Validation loss = 7.6938  \n",
      "\n",
      "Fold: 8  Epoch: 333  Training loss = 2.7179  Validation loss = 7.6936  \n",
      "\n",
      "Fold: 8  Epoch: 334  Training loss = 2.7177  Validation loss = 7.6934  \n",
      "\n",
      "Fold: 8  Epoch: 335  Training loss = 2.7176  Validation loss = 7.6932  \n",
      "\n",
      "Fold: 8  Epoch: 336  Training loss = 2.7174  Validation loss = 7.6930  \n",
      "\n",
      "Fold: 8  Epoch: 337  Training loss = 2.7172  Validation loss = 7.6928  \n",
      "\n",
      "Fold: 8  Epoch: 338  Training loss = 2.7170  Validation loss = 7.6926  \n",
      "\n",
      "Fold: 8  Epoch: 339  Training loss = 2.7168  Validation loss = 7.6924  \n",
      "\n",
      "Fold: 8  Epoch: 340  Training loss = 2.7166  Validation loss = 7.6921  \n",
      "\n",
      "Fold: 8  Epoch: 341  Training loss = 2.7164  Validation loss = 7.6919  \n",
      "\n",
      "Fold: 8  Epoch: 342  Training loss = 2.7162  Validation loss = 7.6917  \n",
      "\n",
      "Fold: 8  Epoch: 343  Training loss = 2.7160  Validation loss = 7.6915  \n",
      "\n",
      "Fold: 8  Epoch: 344  Training loss = 2.7158  Validation loss = 7.6913  \n",
      "\n",
      "Fold: 8  Epoch: 345  Training loss = 2.7156  Validation loss = 7.6911  \n",
      "\n",
      "Fold: 8  Epoch: 346  Training loss = 2.7154  Validation loss = 7.6909  \n",
      "\n",
      "Fold: 8  Epoch: 347  Training loss = 2.7153  Validation loss = 7.6907  \n",
      "\n",
      "Fold: 8  Epoch: 348  Training loss = 2.7151  Validation loss = 7.6905  \n",
      "\n",
      "Fold: 8  Epoch: 349  Training loss = 2.7149  Validation loss = 7.6903  \n",
      "\n",
      "Fold: 8  Epoch: 350  Training loss = 2.7147  Validation loss = 7.6901  \n",
      "\n",
      "Fold: 8  Epoch: 351  Training loss = 2.7145  Validation loss = 7.6899  \n",
      "\n",
      "Fold: 8  Epoch: 352  Training loss = 2.7143  Validation loss = 7.6897  \n",
      "\n",
      "Fold: 8  Epoch: 353  Training loss = 2.7141  Validation loss = 7.6895  \n",
      "\n",
      "Fold: 8  Epoch: 354  Training loss = 2.7139  Validation loss = 7.6893  \n",
      "\n",
      "Fold: 8  Epoch: 355  Training loss = 2.7137  Validation loss = 7.6891  \n",
      "\n",
      "Fold: 8  Epoch: 356  Training loss = 2.7135  Validation loss = 7.6889  \n",
      "\n",
      "Fold: 8  Epoch: 357  Training loss = 2.7133  Validation loss = 7.6887  \n",
      "\n",
      "Fold: 8  Epoch: 358  Training loss = 2.7132  Validation loss = 7.6885  \n",
      "\n",
      "Fold: 8  Epoch: 359  Training loss = 2.7130  Validation loss = 7.6882  \n",
      "\n",
      "Fold: 8  Epoch: 360  Training loss = 2.7128  Validation loss = 7.6880  \n",
      "\n",
      "Fold: 8  Epoch: 361  Training loss = 2.7125  Validation loss = 7.6878  \n",
      "\n",
      "Fold: 8  Epoch: 362  Training loss = 2.7123  Validation loss = 7.6876  \n",
      "\n",
      "Fold: 8  Epoch: 363  Training loss = 2.7121  Validation loss = 7.6874  \n",
      "\n",
      "Fold: 8  Epoch: 364  Training loss = 2.7119  Validation loss = 7.6872  \n",
      "\n",
      "Fold: 8  Epoch: 365  Training loss = 2.7117  Validation loss = 7.6870  \n",
      "\n",
      "Fold: 8  Epoch: 366  Training loss = 2.7115  Validation loss = 7.6867  \n",
      "\n",
      "Fold: 8  Epoch: 367  Training loss = 2.7114  Validation loss = 7.6866  \n",
      "\n",
      "Fold: 8  Epoch: 368  Training loss = 2.7111  Validation loss = 7.6863  \n",
      "\n",
      "Fold: 8  Epoch: 369  Training loss = 2.7109  Validation loss = 7.6861  \n",
      "\n",
      "Fold: 8  Epoch: 370  Training loss = 2.7107  Validation loss = 7.6859  \n",
      "\n",
      "Fold: 8  Epoch: 371  Training loss = 2.7105  Validation loss = 7.6857  \n",
      "\n",
      "Fold: 8  Epoch: 372  Training loss = 2.7104  Validation loss = 7.6855  \n",
      "\n",
      "Fold: 8  Epoch: 373  Training loss = 2.7101  Validation loss = 7.6853  \n",
      "\n",
      "Fold: 8  Epoch: 374  Training loss = 2.7099  Validation loss = 7.6850  \n",
      "\n",
      "Fold: 8  Epoch: 375  Training loss = 2.7097  Validation loss = 7.6848  \n",
      "\n",
      "Fold: 8  Epoch: 376  Training loss = 2.7095  Validation loss = 7.6846  \n",
      "\n",
      "Fold: 8  Epoch: 377  Training loss = 2.7093  Validation loss = 7.6843  \n",
      "\n",
      "Fold: 8  Epoch: 378  Training loss = 2.7091  Validation loss = 7.6842  \n",
      "\n",
      "Fold: 8  Epoch: 379  Training loss = 2.7089  Validation loss = 7.6839  \n",
      "\n",
      "Fold: 8  Epoch: 380  Training loss = 2.7087  Validation loss = 7.6837  \n",
      "\n",
      "Fold: 8  Epoch: 381  Training loss = 2.7086  Validation loss = 7.6835  \n",
      "\n",
      "Fold: 8  Epoch: 382  Training loss = 2.7083  Validation loss = 7.6833  \n",
      "\n",
      "Fold: 8  Epoch: 383  Training loss = 2.7081  Validation loss = 7.6831  \n",
      "\n",
      "Fold: 8  Epoch: 384  Training loss = 2.7080  Validation loss = 7.6829  \n",
      "\n",
      "Fold: 8  Epoch: 385  Training loss = 2.7077  Validation loss = 7.6826  \n",
      "\n",
      "Fold: 8  Epoch: 386  Training loss = 2.7075  Validation loss = 7.6824  \n",
      "\n",
      "Fold: 8  Epoch: 387  Training loss = 2.7073  Validation loss = 7.6822  \n",
      "\n",
      "Fold: 8  Epoch: 388  Training loss = 2.7071  Validation loss = 7.6820  \n",
      "\n",
      "Fold: 8  Epoch: 389  Training loss = 2.7069  Validation loss = 7.6818  \n",
      "\n",
      "Fold: 8  Epoch: 390  Training loss = 2.7067  Validation loss = 7.6815  \n",
      "\n",
      "Fold: 8  Epoch: 391  Training loss = 2.7065  Validation loss = 7.6813  \n",
      "\n",
      "Fold: 8  Epoch: 392  Training loss = 2.7063  Validation loss = 7.6810  \n",
      "\n",
      "Fold: 8  Epoch: 393  Training loss = 2.7060  Validation loss = 7.6808  \n",
      "\n",
      "Fold: 8  Epoch: 394  Training loss = 2.7059  Validation loss = 7.6806  \n",
      "\n",
      "Fold: 8  Epoch: 395  Training loss = 2.7057  Validation loss = 7.6805  \n",
      "\n",
      "Fold: 8  Epoch: 396  Training loss = 2.7055  Validation loss = 7.6803  \n",
      "\n",
      "Fold: 8  Epoch: 397  Training loss = 2.7054  Validation loss = 7.6801  \n",
      "\n",
      "Fold: 8  Epoch: 398  Training loss = 2.7051  Validation loss = 7.6798  \n",
      "\n",
      "Fold: 8  Epoch: 399  Training loss = 2.7049  Validation loss = 7.6796  \n",
      "\n",
      "Fold: 8  Epoch: 400  Training loss = 2.7047  Validation loss = 7.6794  \n",
      "\n",
      "Fold: 8  Epoch: 401  Training loss = 2.7045  Validation loss = 7.6792  \n",
      "\n",
      "Fold: 8  Epoch: 402  Training loss = 2.7044  Validation loss = 7.6790  \n",
      "\n",
      "Fold: 8  Epoch: 403  Training loss = 2.7042  Validation loss = 7.6788  \n",
      "\n",
      "Fold: 8  Epoch: 404  Training loss = 2.7040  Validation loss = 7.6786  \n",
      "\n",
      "Fold: 8  Epoch: 405  Training loss = 2.7038  Validation loss = 7.6784  \n",
      "\n",
      "Fold: 8  Epoch: 406  Training loss = 2.7036  Validation loss = 7.6782  \n",
      "\n",
      "Fold: 8  Epoch: 407  Training loss = 2.7034  Validation loss = 7.6779  \n",
      "\n",
      "Fold: 8  Epoch: 408  Training loss = 2.7032  Validation loss = 7.6777  \n",
      "\n",
      "Fold: 8  Epoch: 409  Training loss = 2.7031  Validation loss = 7.6776  \n",
      "\n",
      "Fold: 8  Epoch: 410  Training loss = 2.7029  Validation loss = 7.6773  \n",
      "\n",
      "Fold: 8  Epoch: 411  Training loss = 2.7027  Validation loss = 7.6771  \n",
      "\n",
      "Fold: 8  Epoch: 412  Training loss = 2.7025  Validation loss = 7.6769  \n",
      "\n",
      "Fold: 8  Epoch: 413  Training loss = 2.7023  Validation loss = 7.6767  \n",
      "\n",
      "Fold: 8  Epoch: 414  Training loss = 2.7022  Validation loss = 7.6766  \n",
      "\n",
      "Fold: 8  Epoch: 415  Training loss = 2.7020  Validation loss = 7.6764  \n",
      "\n",
      "Fold: 8  Epoch: 416  Training loss = 2.7018  Validation loss = 7.6761  \n",
      "\n",
      "Fold: 8  Epoch: 417  Training loss = 2.7015  Validation loss = 7.6759  \n",
      "\n",
      "Fold: 8  Epoch: 418  Training loss = 2.7014  Validation loss = 7.6757  \n",
      "\n",
      "Fold: 8  Epoch: 419  Training loss = 2.7011  Validation loss = 7.6755  \n",
      "\n",
      "Fold: 8  Epoch: 420  Training loss = 2.7009  Validation loss = 7.6753  \n",
      "\n",
      "Fold: 8  Epoch: 421  Training loss = 2.7007  Validation loss = 7.6751  \n",
      "\n",
      "Fold: 8  Epoch: 422  Training loss = 2.7006  Validation loss = 7.6749  \n",
      "\n",
      "Fold: 8  Epoch: 423  Training loss = 2.7004  Validation loss = 7.6747  \n",
      "\n",
      "Fold: 8  Epoch: 424  Training loss = 2.7002  Validation loss = 7.6745  \n",
      "\n",
      "Fold: 8  Epoch: 425  Training loss = 2.7000  Validation loss = 7.6743  \n",
      "\n",
      "Fold: 8  Epoch: 426  Training loss = 2.6998  Validation loss = 7.6741  \n",
      "\n",
      "Fold: 8  Epoch: 427  Training loss = 2.6997  Validation loss = 7.6739  \n",
      "\n",
      "Fold: 8  Epoch: 428  Training loss = 2.6994  Validation loss = 7.6736  \n",
      "\n",
      "Fold: 8  Epoch: 429  Training loss = 2.6992  Validation loss = 7.6734  \n",
      "\n",
      "Fold: 8  Epoch: 430  Training loss = 2.6991  Validation loss = 7.6733  \n",
      "\n",
      "Fold: 8  Epoch: 431  Training loss = 2.6989  Validation loss = 7.6731  \n",
      "\n",
      "Fold: 8  Epoch: 432  Training loss = 2.6987  Validation loss = 7.6729  \n",
      "\n",
      "Fold: 8  Epoch: 433  Training loss = 2.6985  Validation loss = 7.6727  \n",
      "\n",
      "Fold: 8  Epoch: 434  Training loss = 2.6983  Validation loss = 7.6724  \n",
      "\n",
      "Fold: 8  Epoch: 435  Training loss = 2.6981  Validation loss = 7.6722  \n",
      "\n",
      "Fold: 8  Epoch: 436  Training loss = 2.6980  Validation loss = 7.6721  \n",
      "\n",
      "Fold: 8  Epoch: 437  Training loss = 2.6978  Validation loss = 7.6719  \n",
      "\n",
      "Fold: 8  Epoch: 438  Training loss = 2.6976  Validation loss = 7.6716  \n",
      "\n",
      "Fold: 8  Epoch: 439  Training loss = 2.6974  Validation loss = 7.6714  \n",
      "\n",
      "Fold: 8  Epoch: 440  Training loss = 2.6972  Validation loss = 7.6712  \n",
      "\n",
      "Fold: 8  Epoch: 441  Training loss = 2.6970  Validation loss = 7.6710  \n",
      "\n",
      "Fold: 8  Epoch: 442  Training loss = 2.6968  Validation loss = 7.6708  \n",
      "\n",
      "Fold: 8  Epoch: 443  Training loss = 2.6966  Validation loss = 7.6706  \n",
      "\n",
      "Fold: 8  Epoch: 444  Training loss = 2.6964  Validation loss = 7.6704  \n",
      "\n",
      "Fold: 8  Epoch: 445  Training loss = 2.6962  Validation loss = 7.6702  \n",
      "\n",
      "Fold: 8  Epoch: 446  Training loss = 2.6961  Validation loss = 7.6700  \n",
      "\n",
      "Fold: 8  Epoch: 447  Training loss = 2.6958  Validation loss = 7.6698  \n",
      "\n",
      "Fold: 8  Epoch: 448  Training loss = 2.6956  Validation loss = 7.6696  \n",
      "\n",
      "Fold: 8  Epoch: 449  Training loss = 2.6954  Validation loss = 7.6694  \n",
      "\n",
      "Fold: 8  Epoch: 450  Training loss = 2.6953  Validation loss = 7.6692  \n",
      "\n",
      "Fold: 8  Epoch: 451  Training loss = 2.6950  Validation loss = 7.6689  \n",
      "\n",
      "Fold: 8  Epoch: 452  Training loss = 2.6949  Validation loss = 7.6688  \n",
      "\n",
      "Fold: 8  Epoch: 453  Training loss = 2.6947  Validation loss = 7.6686  \n",
      "\n",
      "Fold: 8  Epoch: 454  Training loss = 2.6945  Validation loss = 7.6684  \n",
      "\n",
      "Fold: 8  Epoch: 455  Training loss = 2.6943  Validation loss = 7.6681  \n",
      "\n",
      "Fold: 8  Epoch: 456  Training loss = 2.6941  Validation loss = 7.6679  \n",
      "\n",
      "Fold: 8  Epoch: 457  Training loss = 2.6939  Validation loss = 7.6677  \n",
      "\n",
      "Fold: 8  Epoch: 458  Training loss = 2.6937  Validation loss = 7.6674  \n",
      "\n",
      "Fold: 8  Epoch: 459  Training loss = 2.6935  Validation loss = 7.6672  \n",
      "\n",
      "Fold: 8  Epoch: 460  Training loss = 2.6933  Validation loss = 7.6670  \n",
      "\n",
      "Fold: 8  Epoch: 461  Training loss = 2.6931  Validation loss = 7.6668  \n",
      "\n",
      "Fold: 8  Epoch: 462  Training loss = 2.6929  Validation loss = 7.6666  \n",
      "\n",
      "Fold: 8  Epoch: 463  Training loss = 2.6927  Validation loss = 7.6664  \n",
      "\n",
      "Fold: 8  Epoch: 464  Training loss = 2.6925  Validation loss = 7.6662  \n",
      "\n",
      "Fold: 8  Epoch: 465  Training loss = 2.6923  Validation loss = 7.6659  \n",
      "\n",
      "Fold: 8  Epoch: 466  Training loss = 2.6920  Validation loss = 7.6657  \n",
      "\n",
      "Fold: 8  Epoch: 467  Training loss = 2.6919  Validation loss = 7.6655  \n",
      "\n",
      "Fold: 8  Epoch: 468  Training loss = 2.6917  Validation loss = 7.6654  \n",
      "\n",
      "Fold: 8  Epoch: 469  Training loss = 2.6915  Validation loss = 7.6651  \n",
      "\n",
      "Fold: 8  Epoch: 470  Training loss = 2.6912  Validation loss = 7.6649  \n",
      "\n",
      "Fold: 8  Epoch: 471  Training loss = 2.6910  Validation loss = 7.6647  \n",
      "\n",
      "Fold: 8  Epoch: 472  Training loss = 2.6908  Validation loss = 7.6644  \n",
      "\n",
      "Fold: 8  Epoch: 473  Training loss = 2.6906  Validation loss = 7.6642  \n",
      "\n",
      "Fold: 8  Epoch: 474  Training loss = 2.6904  Validation loss = 7.6640  \n",
      "\n",
      "Fold: 8  Epoch: 475  Training loss = 2.6902  Validation loss = 7.6638  \n",
      "\n",
      "Fold: 8  Epoch: 476  Training loss = 2.6900  Validation loss = 7.6635  \n",
      "\n",
      "Fold: 8  Epoch: 477  Training loss = 2.6898  Validation loss = 7.6633  \n",
      "\n",
      "Fold: 8  Epoch: 478  Training loss = 2.6896  Validation loss = 7.6631  \n",
      "\n",
      "Fold: 8  Epoch: 479  Training loss = 2.6894  Validation loss = 7.6629  \n",
      "\n",
      "Fold: 8  Epoch: 480  Training loss = 2.6892  Validation loss = 7.6627  \n",
      "\n",
      "Fold: 8  Epoch: 481  Training loss = 2.6890  Validation loss = 7.6625  \n",
      "\n",
      "Fold: 8  Epoch: 482  Training loss = 2.6888  Validation loss = 7.6623  \n",
      "\n",
      "Fold: 8  Epoch: 483  Training loss = 2.6887  Validation loss = 7.6621  \n",
      "\n",
      "Fold: 8  Epoch: 484  Training loss = 2.6885  Validation loss = 7.6619  \n",
      "\n",
      "Fold: 8  Epoch: 485  Training loss = 2.6883  Validation loss = 7.6617  \n",
      "\n",
      "Fold: 8  Epoch: 486  Training loss = 2.6881  Validation loss = 7.6615  \n",
      "\n",
      "Fold: 8  Epoch: 487  Training loss = 2.6879  Validation loss = 7.6613  \n",
      "\n",
      "Fold: 8  Epoch: 488  Training loss = 2.6876  Validation loss = 7.6610  \n",
      "\n",
      "Fold: 8  Epoch: 489  Training loss = 2.6874  Validation loss = 7.6608  \n",
      "\n",
      "Fold: 8  Epoch: 490  Training loss = 2.6872  Validation loss = 7.6606  \n",
      "\n",
      "Fold: 8  Epoch: 491  Training loss = 2.6871  Validation loss = 7.6604  \n",
      "\n",
      "Fold: 8  Epoch: 492  Training loss = 2.6869  Validation loss = 7.6602  \n",
      "\n",
      "Fold: 8  Epoch: 493  Training loss = 2.6867  Validation loss = 7.6600  \n",
      "\n",
      "Fold: 8  Epoch: 494  Training loss = 2.6866  Validation loss = 7.6599  \n",
      "\n",
      "Fold: 8  Epoch: 495  Training loss = 2.6865  Validation loss = 7.6597  \n",
      "\n",
      "Fold: 8  Epoch: 496  Training loss = 2.6862  Validation loss = 7.6594  \n",
      "\n",
      "Fold: 8  Epoch: 497  Training loss = 2.6860  Validation loss = 7.6592  \n",
      "\n",
      "Fold: 8  Epoch: 498  Training loss = 2.6858  Validation loss = 7.6590  \n",
      "\n",
      "Fold: 8  Epoch: 499  Training loss = 2.6857  Validation loss = 7.6589  \n",
      "\n",
      "Fold: 8  Epoch: 500  Training loss = 2.6855  Validation loss = 7.6587  \n",
      "\n",
      "Check model:  Fold: 8  Optimal epoch: 500  \n",
      "\n",
      "Fold: 9  Epoch: 1  Training loss = 3.2235  Validation loss = 11.3722  \n",
      "\n",
      "Fold: 9  Epoch: 2  Training loss = 3.2233  Validation loss = 11.3719  \n",
      "\n",
      "Fold: 9  Epoch: 3  Training loss = 3.2230  Validation loss = 11.3715  \n",
      "\n",
      "Fold: 9  Epoch: 4  Training loss = 3.2228  Validation loss = 11.3712  \n",
      "\n",
      "Fold: 9  Epoch: 5  Training loss = 3.2226  Validation loss = 11.3708  \n",
      "\n",
      "Fold: 9  Epoch: 6  Training loss = 3.2223  Validation loss = 11.3704  \n",
      "\n",
      "Fold: 9  Epoch: 7  Training loss = 3.2221  Validation loss = 11.3701  \n",
      "\n",
      "Fold: 9  Epoch: 8  Training loss = 3.2219  Validation loss = 11.3698  \n",
      "\n",
      "Fold: 9  Epoch: 9  Training loss = 3.2217  Validation loss = 11.3695  \n",
      "\n",
      "Fold: 9  Epoch: 10  Training loss = 3.2216  Validation loss = 11.3692  \n",
      "\n",
      "Fold: 9  Epoch: 11  Training loss = 3.2213  Validation loss = 11.3688  \n",
      "\n",
      "Fold: 9  Epoch: 12  Training loss = 3.2211  Validation loss = 11.3685  \n",
      "\n",
      "Fold: 9  Epoch: 13  Training loss = 3.2209  Validation loss = 11.3680  \n",
      "\n",
      "Fold: 9  Epoch: 14  Training loss = 3.2207  Validation loss = 11.3678  \n",
      "\n",
      "Fold: 9  Epoch: 15  Training loss = 3.2205  Validation loss = 11.3675  \n",
      "\n",
      "Fold: 9  Epoch: 16  Training loss = 3.2203  Validation loss = 11.3671  \n",
      "\n",
      "Fold: 9  Epoch: 17  Training loss = 3.2201  Validation loss = 11.3668  \n",
      "\n",
      "Fold: 9  Epoch: 18  Training loss = 3.2199  Validation loss = 11.3664  \n",
      "\n",
      "Fold: 9  Epoch: 19  Training loss = 3.2197  Validation loss = 11.3661  \n",
      "\n",
      "Fold: 9  Epoch: 20  Training loss = 3.2194  Validation loss = 11.3657  \n",
      "\n",
      "Fold: 9  Epoch: 21  Training loss = 3.2193  Validation loss = 11.3654  \n",
      "\n",
      "Fold: 9  Epoch: 22  Training loss = 3.2190  Validation loss = 11.3651  \n",
      "\n",
      "Fold: 9  Epoch: 23  Training loss = 3.2188  Validation loss = 11.3647  \n",
      "\n",
      "Fold: 9  Epoch: 24  Training loss = 3.2186  Validation loss = 11.3644  \n",
      "\n",
      "Fold: 9  Epoch: 25  Training loss = 3.2184  Validation loss = 11.3640  \n",
      "\n",
      "Fold: 9  Epoch: 26  Training loss = 3.2182  Validation loss = 11.3637  \n",
      "\n",
      "Fold: 9  Epoch: 27  Training loss = 3.2180  Validation loss = 11.3633  \n",
      "\n",
      "Fold: 9  Epoch: 28  Training loss = 3.2178  Validation loss = 11.3630  \n",
      "\n",
      "Fold: 9  Epoch: 29  Training loss = 3.2175  Validation loss = 11.3626  \n",
      "\n",
      "Fold: 9  Epoch: 30  Training loss = 3.2174  Validation loss = 11.3623  \n",
      "\n",
      "Fold: 9  Epoch: 31  Training loss = 3.2172  Validation loss = 11.3620  \n",
      "\n",
      "Fold: 9  Epoch: 32  Training loss = 3.2169  Validation loss = 11.3617  \n",
      "\n",
      "Fold: 9  Epoch: 33  Training loss = 3.2167  Validation loss = 11.3613  \n",
      "\n",
      "Fold: 9  Epoch: 34  Training loss = 3.2165  Validation loss = 11.3609  \n",
      "\n",
      "Fold: 9  Epoch: 35  Training loss = 3.2163  Validation loss = 11.3606  \n",
      "\n",
      "Fold: 9  Epoch: 36  Training loss = 3.2160  Validation loss = 11.3602  \n",
      "\n",
      "Fold: 9  Epoch: 37  Training loss = 3.2158  Validation loss = 11.3598  \n",
      "\n",
      "Fold: 9  Epoch: 38  Training loss = 3.2156  Validation loss = 11.3595  \n",
      "\n",
      "Fold: 9  Epoch: 39  Training loss = 3.2154  Validation loss = 11.3592  \n",
      "\n",
      "Fold: 9  Epoch: 40  Training loss = 3.2151  Validation loss = 11.3587  \n",
      "\n",
      "Fold: 9  Epoch: 41  Training loss = 3.2149  Validation loss = 11.3584  \n",
      "\n",
      "Fold: 9  Epoch: 42  Training loss = 3.2147  Validation loss = 11.3580  \n",
      "\n",
      "Fold: 9  Epoch: 43  Training loss = 3.2145  Validation loss = 11.3577  \n",
      "\n",
      "Fold: 9  Epoch: 44  Training loss = 3.2143  Validation loss = 11.3573  \n",
      "\n",
      "Fold: 9  Epoch: 45  Training loss = 3.2141  Validation loss = 11.3571  \n",
      "\n",
      "Fold: 9  Epoch: 46  Training loss = 3.2140  Validation loss = 11.3568  \n",
      "\n",
      "Fold: 9  Epoch: 47  Training loss = 3.2138  Validation loss = 11.3565  \n",
      "\n",
      "Fold: 9  Epoch: 48  Training loss = 3.2135  Validation loss = 11.3561  \n",
      "\n",
      "Fold: 9  Epoch: 49  Training loss = 3.2134  Validation loss = 11.3558  \n",
      "\n",
      "Fold: 9  Epoch: 50  Training loss = 3.2132  Validation loss = 11.3555  \n",
      "\n",
      "Fold: 9  Epoch: 51  Training loss = 3.2129  Validation loss = 11.3551  \n",
      "\n",
      "Fold: 9  Epoch: 52  Training loss = 3.2127  Validation loss = 11.3547  \n",
      "\n",
      "Fold: 9  Epoch: 53  Training loss = 3.2125  Validation loss = 11.3544  \n",
      "\n",
      "Fold: 9  Epoch: 54  Training loss = 3.2123  Validation loss = 11.3540  \n",
      "\n",
      "Fold: 9  Epoch: 55  Training loss = 3.2121  Validation loss = 11.3537  \n",
      "\n",
      "Fold: 9  Epoch: 56  Training loss = 3.2118  Validation loss = 11.3533  \n",
      "\n",
      "Fold: 9  Epoch: 57  Training loss = 3.2116  Validation loss = 11.3530  \n",
      "\n",
      "Fold: 9  Epoch: 58  Training loss = 3.2114  Validation loss = 11.3526  \n",
      "\n",
      "Fold: 9  Epoch: 59  Training loss = 3.2112  Validation loss = 11.3523  \n",
      "\n",
      "Fold: 9  Epoch: 60  Training loss = 3.2110  Validation loss = 11.3519  \n",
      "\n",
      "Fold: 9  Epoch: 61  Training loss = 3.2108  Validation loss = 11.3516  \n",
      "\n",
      "Fold: 9  Epoch: 62  Training loss = 3.2105  Validation loss = 11.3512  \n",
      "\n",
      "Fold: 9  Epoch: 63  Training loss = 3.2103  Validation loss = 11.3509  \n",
      "\n",
      "Fold: 9  Epoch: 64  Training loss = 3.2102  Validation loss = 11.3506  \n",
      "\n",
      "Fold: 9  Epoch: 65  Training loss = 3.2099  Validation loss = 11.3502  \n",
      "\n",
      "Fold: 9  Epoch: 66  Training loss = 3.2097  Validation loss = 11.3498  \n",
      "\n",
      "Fold: 9  Epoch: 67  Training loss = 3.2095  Validation loss = 11.3495  \n",
      "\n",
      "Fold: 9  Epoch: 68  Training loss = 3.2092  Validation loss = 11.3491  \n",
      "\n",
      "Fold: 9  Epoch: 69  Training loss = 3.2090  Validation loss = 11.3487  \n",
      "\n",
      "Fold: 9  Epoch: 70  Training loss = 3.2088  Validation loss = 11.3484  \n",
      "\n",
      "Fold: 9  Epoch: 71  Training loss = 3.2086  Validation loss = 11.3481  \n",
      "\n",
      "Fold: 9  Epoch: 72  Training loss = 3.2084  Validation loss = 11.3477  \n",
      "\n",
      "Fold: 9  Epoch: 73  Training loss = 3.2082  Validation loss = 11.3474  \n",
      "\n",
      "Fold: 9  Epoch: 74  Training loss = 3.2079  Validation loss = 11.3470  \n",
      "\n",
      "Fold: 9  Epoch: 75  Training loss = 3.2077  Validation loss = 11.3466  \n",
      "\n",
      "Fold: 9  Epoch: 76  Training loss = 3.2075  Validation loss = 11.3462  \n",
      "\n",
      "Fold: 9  Epoch: 77  Training loss = 3.2073  Validation loss = 11.3459  \n",
      "\n",
      "Fold: 9  Epoch: 78  Training loss = 3.2070  Validation loss = 11.3455  \n",
      "\n",
      "Fold: 9  Epoch: 79  Training loss = 3.2068  Validation loss = 11.3451  \n",
      "\n",
      "Fold: 9  Epoch: 80  Training loss = 3.2066  Validation loss = 11.3448  \n",
      "\n",
      "Fold: 9  Epoch: 81  Training loss = 3.2064  Validation loss = 11.3444  \n",
      "\n",
      "Fold: 9  Epoch: 82  Training loss = 3.2062  Validation loss = 11.3441  \n",
      "\n",
      "Fold: 9  Epoch: 83  Training loss = 3.2060  Validation loss = 11.3439  \n",
      "\n",
      "Fold: 9  Epoch: 84  Training loss = 3.2058  Validation loss = 11.3434  \n",
      "\n",
      "Fold: 9  Epoch: 85  Training loss = 3.2055  Validation loss = 11.3430  \n",
      "\n",
      "Fold: 9  Epoch: 86  Training loss = 3.2053  Validation loss = 11.3427  \n",
      "\n",
      "Fold: 9  Epoch: 87  Training loss = 3.2051  Validation loss = 11.3424  \n",
      "\n",
      "Fold: 9  Epoch: 88  Training loss = 3.2049  Validation loss = 11.3420  \n",
      "\n",
      "Fold: 9  Epoch: 89  Training loss = 3.2047  Validation loss = 11.3417  \n",
      "\n",
      "Fold: 9  Epoch: 90  Training loss = 3.2046  Validation loss = 11.3414  \n",
      "\n",
      "Fold: 9  Epoch: 91  Training loss = 3.2043  Validation loss = 11.3410  \n",
      "\n",
      "Fold: 9  Epoch: 92  Training loss = 3.2041  Validation loss = 11.3406  \n",
      "\n",
      "Fold: 9  Epoch: 93  Training loss = 3.2038  Validation loss = 11.3402  \n",
      "\n",
      "Fold: 9  Epoch: 94  Training loss = 3.2036  Validation loss = 11.3398  \n",
      "\n",
      "Fold: 9  Epoch: 95  Training loss = 3.2034  Validation loss = 11.3396  \n",
      "\n",
      "Fold: 9  Epoch: 96  Training loss = 3.2032  Validation loss = 11.3392  \n",
      "\n",
      "Fold: 9  Epoch: 97  Training loss = 3.2029  Validation loss = 11.3388  \n",
      "\n",
      "Fold: 9  Epoch: 98  Training loss = 3.2027  Validation loss = 11.3384  \n",
      "\n",
      "Fold: 9  Epoch: 99  Training loss = 3.2024  Validation loss = 11.3380  \n",
      "\n",
      "Fold: 9  Epoch: 100  Training loss = 3.2022  Validation loss = 11.3376  \n",
      "\n",
      "Fold: 9  Epoch: 101  Training loss = 3.2020  Validation loss = 11.3373  \n",
      "\n",
      "Fold: 9  Epoch: 102  Training loss = 3.2018  Validation loss = 11.3369  \n",
      "\n",
      "Fold: 9  Epoch: 103  Training loss = 3.2016  Validation loss = 11.3365  \n",
      "\n",
      "Fold: 9  Epoch: 104  Training loss = 3.2013  Validation loss = 11.3362  \n",
      "\n",
      "Fold: 9  Epoch: 105  Training loss = 3.2011  Validation loss = 11.3358  \n",
      "\n",
      "Fold: 9  Epoch: 106  Training loss = 3.2009  Validation loss = 11.3354  \n",
      "\n",
      "Fold: 9  Epoch: 107  Training loss = 3.2006  Validation loss = 11.3350  \n",
      "\n",
      "Fold: 9  Epoch: 108  Training loss = 3.2004  Validation loss = 11.3347  \n",
      "\n",
      "Fold: 9  Epoch: 109  Training loss = 3.2002  Validation loss = 11.3344  \n",
      "\n",
      "Fold: 9  Epoch: 110  Training loss = 3.2000  Validation loss = 11.3340  \n",
      "\n",
      "Fold: 9  Epoch: 111  Training loss = 3.1998  Validation loss = 11.3337  \n",
      "\n",
      "Fold: 9  Epoch: 112  Training loss = 3.1996  Validation loss = 11.3333  \n",
      "\n",
      "Fold: 9  Epoch: 113  Training loss = 3.1993  Validation loss = 11.3329  \n",
      "\n",
      "Fold: 9  Epoch: 114  Training loss = 3.1991  Validation loss = 11.3325  \n",
      "\n",
      "Fold: 9  Epoch: 115  Training loss = 3.1989  Validation loss = 11.3322  \n",
      "\n",
      "Fold: 9  Epoch: 116  Training loss = 3.1987  Validation loss = 11.3318  \n",
      "\n",
      "Fold: 9  Epoch: 117  Training loss = 3.1985  Validation loss = 11.3315  \n",
      "\n",
      "Fold: 9  Epoch: 118  Training loss = 3.1983  Validation loss = 11.3312  \n",
      "\n",
      "Fold: 9  Epoch: 119  Training loss = 3.1980  Validation loss = 11.3308  \n",
      "\n",
      "Fold: 9  Epoch: 120  Training loss = 3.1979  Validation loss = 11.3305  \n",
      "\n",
      "Fold: 9  Epoch: 121  Training loss = 3.1977  Validation loss = 11.3302  \n",
      "\n",
      "Fold: 9  Epoch: 122  Training loss = 3.1975  Validation loss = 11.3298  \n",
      "\n",
      "Fold: 9  Epoch: 123  Training loss = 3.1973  Validation loss = 11.3295  \n",
      "\n",
      "Fold: 9  Epoch: 124  Training loss = 3.1971  Validation loss = 11.3292  \n",
      "\n",
      "Fold: 9  Epoch: 125  Training loss = 3.1969  Validation loss = 11.3289  \n",
      "\n",
      "Fold: 9  Epoch: 126  Training loss = 3.1967  Validation loss = 11.3285  \n",
      "\n",
      "Fold: 9  Epoch: 127  Training loss = 3.1965  Validation loss = 11.3282  \n",
      "\n",
      "Fold: 9  Epoch: 128  Training loss = 3.1963  Validation loss = 11.3279  \n",
      "\n",
      "Fold: 9  Epoch: 129  Training loss = 3.1961  Validation loss = 11.3276  \n",
      "\n",
      "Fold: 9  Epoch: 130  Training loss = 3.1959  Validation loss = 11.3273  \n",
      "\n",
      "Fold: 9  Epoch: 131  Training loss = 3.1957  Validation loss = 11.3269  \n",
      "\n",
      "Fold: 9  Epoch: 132  Training loss = 3.1955  Validation loss = 11.3265  \n",
      "\n",
      "Fold: 9  Epoch: 133  Training loss = 3.1953  Validation loss = 11.3262  \n",
      "\n",
      "Fold: 9  Epoch: 134  Training loss = 3.1951  Validation loss = 11.3259  \n",
      "\n",
      "Fold: 9  Epoch: 135  Training loss = 3.1949  Validation loss = 11.3255  \n",
      "\n",
      "Fold: 9  Epoch: 136  Training loss = 3.1947  Validation loss = 11.3252  \n",
      "\n",
      "Fold: 9  Epoch: 137  Training loss = 3.1944  Validation loss = 11.3248  \n",
      "\n",
      "Fold: 9  Epoch: 138  Training loss = 3.1942  Validation loss = 11.3244  \n",
      "\n",
      "Fold: 9  Epoch: 139  Training loss = 3.1940  Validation loss = 11.3241  \n",
      "\n",
      "Fold: 9  Epoch: 140  Training loss = 3.1938  Validation loss = 11.3237  \n",
      "\n",
      "Fold: 9  Epoch: 141  Training loss = 3.1935  Validation loss = 11.3233  \n",
      "\n",
      "Fold: 9  Epoch: 142  Training loss = 3.1933  Validation loss = 11.3229  \n",
      "\n",
      "Fold: 9  Epoch: 143  Training loss = 3.1931  Validation loss = 11.3227  \n",
      "\n",
      "Fold: 9  Epoch: 144  Training loss = 3.1929  Validation loss = 11.3223  \n",
      "\n",
      "Fold: 9  Epoch: 145  Training loss = 3.1926  Validation loss = 11.3219  \n",
      "\n",
      "Fold: 9  Epoch: 146  Training loss = 3.1925  Validation loss = 11.3216  \n",
      "\n",
      "Fold: 9  Epoch: 147  Training loss = 3.1923  Validation loss = 11.3213  \n",
      "\n",
      "Fold: 9  Epoch: 148  Training loss = 3.1921  Validation loss = 11.3210  \n",
      "\n",
      "Fold: 9  Epoch: 149  Training loss = 3.1919  Validation loss = 11.3207  \n",
      "\n",
      "Fold: 9  Epoch: 150  Training loss = 3.1917  Validation loss = 11.3204  \n",
      "\n",
      "Fold: 9  Epoch: 151  Training loss = 3.1915  Validation loss = 11.3200  \n",
      "\n",
      "Fold: 9  Epoch: 152  Training loss = 3.1913  Validation loss = 11.3197  \n",
      "\n",
      "Fold: 9  Epoch: 153  Training loss = 3.1911  Validation loss = 11.3193  \n",
      "\n",
      "Fold: 9  Epoch: 154  Training loss = 3.1909  Validation loss = 11.3189  \n",
      "\n",
      "Fold: 9  Epoch: 155  Training loss = 3.1906  Validation loss = 11.3184  \n",
      "\n",
      "Fold: 9  Epoch: 156  Training loss = 3.1904  Validation loss = 11.3181  \n",
      "\n",
      "Fold: 9  Epoch: 157  Training loss = 3.1902  Validation loss = 11.3178  \n",
      "\n",
      "Fold: 9  Epoch: 158  Training loss = 3.1899  Validation loss = 11.3174  \n",
      "\n",
      "Fold: 9  Epoch: 159  Training loss = 3.1897  Validation loss = 11.3170  \n",
      "\n",
      "Fold: 9  Epoch: 160  Training loss = 3.1895  Validation loss = 11.3167  \n",
      "\n",
      "Fold: 9  Epoch: 161  Training loss = 3.1893  Validation loss = 11.3164  \n",
      "\n",
      "Fold: 9  Epoch: 162  Training loss = 3.1891  Validation loss = 11.3160  \n",
      "\n",
      "Fold: 9  Epoch: 163  Training loss = 3.1889  Validation loss = 11.3157  \n",
      "\n",
      "Fold: 9  Epoch: 164  Training loss = 3.1886  Validation loss = 11.3153  \n",
      "\n",
      "Fold: 9  Epoch: 165  Training loss = 3.1884  Validation loss = 11.3150  \n",
      "\n",
      "Fold: 9  Epoch: 166  Training loss = 3.1882  Validation loss = 11.3146  \n",
      "\n",
      "Fold: 9  Epoch: 167  Training loss = 3.1880  Validation loss = 11.3142  \n",
      "\n",
      "Fold: 9  Epoch: 168  Training loss = 3.1879  Validation loss = 11.3140  \n",
      "\n",
      "Fold: 9  Epoch: 169  Training loss = 3.1876  Validation loss = 11.3136  \n",
      "\n",
      "Fold: 9  Epoch: 170  Training loss = 3.1874  Validation loss = 11.3133  \n",
      "\n",
      "Fold: 9  Epoch: 171  Training loss = 3.1872  Validation loss = 11.3130  \n",
      "\n",
      "Fold: 9  Epoch: 172  Training loss = 3.1870  Validation loss = 11.3126  \n",
      "\n",
      "Fold: 9  Epoch: 173  Training loss = 3.1867  Validation loss = 11.3121  \n",
      "\n",
      "Fold: 9  Epoch: 174  Training loss = 3.1865  Validation loss = 11.3118  \n",
      "\n",
      "Fold: 9  Epoch: 175  Training loss = 3.1864  Validation loss = 11.3115  \n",
      "\n",
      "Fold: 9  Epoch: 176  Training loss = 3.1862  Validation loss = 11.3112  \n",
      "\n",
      "Fold: 9  Epoch: 177  Training loss = 3.1860  Validation loss = 11.3109  \n",
      "\n",
      "Fold: 9  Epoch: 178  Training loss = 3.1858  Validation loss = 11.3105  \n",
      "\n",
      "Fold: 9  Epoch: 179  Training loss = 3.1856  Validation loss = 11.3102  \n",
      "\n",
      "Fold: 9  Epoch: 180  Training loss = 3.1853  Validation loss = 11.3098  \n",
      "\n",
      "Fold: 9  Epoch: 181  Training loss = 3.1851  Validation loss = 11.3095  \n",
      "\n",
      "Fold: 9  Epoch: 182  Training loss = 3.1849  Validation loss = 11.3092  \n",
      "\n",
      "Fold: 9  Epoch: 183  Training loss = 3.1847  Validation loss = 11.3089  \n",
      "\n",
      "Fold: 9  Epoch: 184  Training loss = 3.1845  Validation loss = 11.3085  \n",
      "\n",
      "Fold: 9  Epoch: 185  Training loss = 3.1843  Validation loss = 11.3082  \n",
      "\n",
      "Fold: 9  Epoch: 186  Training loss = 3.1841  Validation loss = 11.3078  \n",
      "\n",
      "Fold: 9  Epoch: 187  Training loss = 3.1839  Validation loss = 11.3074  \n",
      "\n",
      "Fold: 9  Epoch: 188  Training loss = 3.1837  Validation loss = 11.3072  \n",
      "\n",
      "Fold: 9  Epoch: 189  Training loss = 3.1835  Validation loss = 11.3069  \n",
      "\n",
      "Fold: 9  Epoch: 190  Training loss = 3.1833  Validation loss = 11.3065  \n",
      "\n",
      "Fold: 9  Epoch: 191  Training loss = 3.1831  Validation loss = 11.3061  \n",
      "\n",
      "Fold: 9  Epoch: 192  Training loss = 3.1829  Validation loss = 11.3057  \n",
      "\n",
      "Fold: 9  Epoch: 193  Training loss = 3.1827  Validation loss = 11.3054  \n",
      "\n",
      "Fold: 9  Epoch: 194  Training loss = 3.1824  Validation loss = 11.3050  \n",
      "\n",
      "Fold: 9  Epoch: 195  Training loss = 3.1822  Validation loss = 11.3046  \n",
      "\n",
      "Fold: 9  Epoch: 196  Training loss = 3.1820  Validation loss = 11.3043  \n",
      "\n",
      "Fold: 9  Epoch: 197  Training loss = 3.1818  Validation loss = 11.3040  \n",
      "\n",
      "Fold: 9  Epoch: 198  Training loss = 3.1816  Validation loss = 11.3036  \n",
      "\n",
      "Fold: 9  Epoch: 199  Training loss = 3.1814  Validation loss = 11.3033  \n",
      "\n",
      "Fold: 9  Epoch: 200  Training loss = 3.1812  Validation loss = 11.3030  \n",
      "\n",
      "Fold: 9  Epoch: 201  Training loss = 3.1810  Validation loss = 11.3026  \n",
      "\n",
      "Fold: 9  Epoch: 202  Training loss = 3.1808  Validation loss = 11.3023  \n",
      "\n",
      "Fold: 9  Epoch: 203  Training loss = 3.1806  Validation loss = 11.3019  \n",
      "\n",
      "Fold: 9  Epoch: 204  Training loss = 3.1804  Validation loss = 11.3016  \n",
      "\n",
      "Fold: 9  Epoch: 205  Training loss = 3.1802  Validation loss = 11.3013  \n",
      "\n",
      "Fold: 9  Epoch: 206  Training loss = 3.1800  Validation loss = 11.3009  \n",
      "\n",
      "Fold: 9  Epoch: 207  Training loss = 3.1797  Validation loss = 11.3005  \n",
      "\n",
      "Fold: 9  Epoch: 208  Training loss = 3.1795  Validation loss = 11.3001  \n",
      "\n",
      "Fold: 9  Epoch: 209  Training loss = 3.1792  Validation loss = 11.2997  \n",
      "\n",
      "Fold: 9  Epoch: 210  Training loss = 3.1791  Validation loss = 11.2994  \n",
      "\n",
      "Fold: 9  Epoch: 211  Training loss = 3.1789  Validation loss = 11.2991  \n",
      "\n",
      "Fold: 9  Epoch: 212  Training loss = 3.1787  Validation loss = 11.2987  \n",
      "\n",
      "Fold: 9  Epoch: 213  Training loss = 3.1785  Validation loss = 11.2984  \n",
      "\n",
      "Fold: 9  Epoch: 214  Training loss = 3.1783  Validation loss = 11.2981  \n",
      "\n",
      "Fold: 9  Epoch: 215  Training loss = 3.1781  Validation loss = 11.2977  \n",
      "\n",
      "Fold: 9  Epoch: 216  Training loss = 3.1779  Validation loss = 11.2975  \n",
      "\n",
      "Fold: 9  Epoch: 217  Training loss = 3.1777  Validation loss = 11.2972  \n",
      "\n",
      "Fold: 9  Epoch: 218  Training loss = 3.1775  Validation loss = 11.2968  \n",
      "\n",
      "Fold: 9  Epoch: 219  Training loss = 3.1773  Validation loss = 11.2965  \n",
      "\n",
      "Fold: 9  Epoch: 220  Training loss = 3.1771  Validation loss = 11.2961  \n",
      "\n",
      "Fold: 9  Epoch: 221  Training loss = 3.1769  Validation loss = 11.2958  \n",
      "\n",
      "Fold: 9  Epoch: 222  Training loss = 3.1768  Validation loss = 11.2955  \n",
      "\n",
      "Fold: 9  Epoch: 223  Training loss = 3.1766  Validation loss = 11.2952  \n",
      "\n",
      "Fold: 9  Epoch: 224  Training loss = 3.1764  Validation loss = 11.2949  \n",
      "\n",
      "Fold: 9  Epoch: 225  Training loss = 3.1762  Validation loss = 11.2946  \n",
      "\n",
      "Fold: 9  Epoch: 226  Training loss = 3.1760  Validation loss = 11.2942  \n",
      "\n",
      "Fold: 9  Epoch: 227  Training loss = 3.1758  Validation loss = 11.2939  \n",
      "\n",
      "Fold: 9  Epoch: 228  Training loss = 3.1756  Validation loss = 11.2936  \n",
      "\n",
      "Fold: 9  Epoch: 229  Training loss = 3.1754  Validation loss = 11.2933  \n",
      "\n",
      "Fold: 9  Epoch: 230  Training loss = 3.1752  Validation loss = 11.2929  \n",
      "\n",
      "Fold: 9  Epoch: 231  Training loss = 3.1750  Validation loss = 11.2926  \n",
      "\n",
      "Fold: 9  Epoch: 232  Training loss = 3.1748  Validation loss = 11.2923  \n",
      "\n",
      "Fold: 9  Epoch: 233  Training loss = 3.1746  Validation loss = 11.2919  \n",
      "\n",
      "Fold: 9  Epoch: 234  Training loss = 3.1744  Validation loss = 11.2916  \n",
      "\n",
      "Fold: 9  Epoch: 235  Training loss = 3.1742  Validation loss = 11.2912  \n",
      "\n",
      "Fold: 9  Epoch: 236  Training loss = 3.1740  Validation loss = 11.2909  \n",
      "\n",
      "Fold: 9  Epoch: 237  Training loss = 3.1738  Validation loss = 11.2906  \n",
      "\n",
      "Fold: 9  Epoch: 238  Training loss = 3.1736  Validation loss = 11.2902  \n",
      "\n",
      "Fold: 9  Epoch: 239  Training loss = 3.1734  Validation loss = 11.2899  \n",
      "\n",
      "Fold: 9  Epoch: 240  Training loss = 3.1732  Validation loss = 11.2895  \n",
      "\n",
      "Fold: 9  Epoch: 241  Training loss = 3.1729  Validation loss = 11.2891  \n",
      "\n",
      "Fold: 9  Epoch: 242  Training loss = 3.1727  Validation loss = 11.2887  \n",
      "\n",
      "Fold: 9  Epoch: 243  Training loss = 3.1724  Validation loss = 11.2883  \n",
      "\n",
      "Fold: 9  Epoch: 244  Training loss = 3.1722  Validation loss = 11.2879  \n",
      "\n",
      "Fold: 9  Epoch: 245  Training loss = 3.1720  Validation loss = 11.2875  \n",
      "\n",
      "Fold: 9  Epoch: 246  Training loss = 3.1718  Validation loss = 11.2873  \n",
      "\n",
      "Fold: 9  Epoch: 247  Training loss = 3.1716  Validation loss = 11.2869  \n",
      "\n",
      "Fold: 9  Epoch: 248  Training loss = 3.1714  Validation loss = 11.2866  \n",
      "\n",
      "Fold: 9  Epoch: 249  Training loss = 3.1712  Validation loss = 11.2863  \n",
      "\n",
      "Fold: 9  Epoch: 250  Training loss = 3.1710  Validation loss = 11.2860  \n",
      "\n",
      "Fold: 9  Epoch: 251  Training loss = 3.1708  Validation loss = 11.2856  \n",
      "\n",
      "Fold: 9  Epoch: 252  Training loss = 3.1706  Validation loss = 11.2853  \n",
      "\n",
      "Fold: 9  Epoch: 253  Training loss = 3.1705  Validation loss = 11.2851  \n",
      "\n",
      "Fold: 9  Epoch: 254  Training loss = 3.1703  Validation loss = 11.2848  \n",
      "\n",
      "Fold: 9  Epoch: 255  Training loss = 3.1701  Validation loss = 11.2844  \n",
      "\n",
      "Fold: 9  Epoch: 256  Training loss = 3.1699  Validation loss = 11.2840  \n",
      "\n",
      "Fold: 9  Epoch: 257  Training loss = 3.1697  Validation loss = 11.2837  \n",
      "\n",
      "Fold: 9  Epoch: 258  Training loss = 3.1695  Validation loss = 11.2833  \n",
      "\n",
      "Fold: 9  Epoch: 259  Training loss = 3.1693  Validation loss = 11.2831  \n",
      "\n",
      "Fold: 9  Epoch: 260  Training loss = 3.1691  Validation loss = 11.2827  \n",
      "\n",
      "Fold: 9  Epoch: 261  Training loss = 3.1689  Validation loss = 11.2823  \n",
      "\n",
      "Fold: 9  Epoch: 262  Training loss = 3.1686  Validation loss = 11.2819  \n",
      "\n",
      "Fold: 9  Epoch: 263  Training loss = 3.1684  Validation loss = 11.2816  \n",
      "\n",
      "Fold: 9  Epoch: 264  Training loss = 3.1682  Validation loss = 11.2812  \n",
      "\n",
      "Fold: 9  Epoch: 265  Training loss = 3.1680  Validation loss = 11.2809  \n",
      "\n",
      "Fold: 9  Epoch: 266  Training loss = 3.1678  Validation loss = 11.2805  \n",
      "\n",
      "Fold: 9  Epoch: 267  Training loss = 3.1676  Validation loss = 11.2801  \n",
      "\n",
      "Fold: 9  Epoch: 268  Training loss = 3.1674  Validation loss = 11.2798  \n",
      "\n",
      "Fold: 9  Epoch: 269  Training loss = 3.1671  Validation loss = 11.2794  \n",
      "\n",
      "Fold: 9  Epoch: 270  Training loss = 3.1669  Validation loss = 11.2790  \n",
      "\n",
      "Fold: 9  Epoch: 271  Training loss = 3.1667  Validation loss = 11.2787  \n",
      "\n",
      "Fold: 9  Epoch: 272  Training loss = 3.1665  Validation loss = 11.2784  \n",
      "\n",
      "Fold: 9  Epoch: 273  Training loss = 3.1663  Validation loss = 11.2780  \n",
      "\n",
      "Fold: 9  Epoch: 274  Training loss = 3.1661  Validation loss = 11.2777  \n",
      "\n",
      "Fold: 9  Epoch: 275  Training loss = 3.1659  Validation loss = 11.2774  \n",
      "\n",
      "Fold: 9  Epoch: 276  Training loss = 3.1657  Validation loss = 11.2770  \n",
      "\n",
      "Fold: 9  Epoch: 277  Training loss = 3.1655  Validation loss = 11.2767  \n",
      "\n",
      "Fold: 9  Epoch: 278  Training loss = 3.1653  Validation loss = 11.2763  \n",
      "\n",
      "Fold: 9  Epoch: 279  Training loss = 3.1651  Validation loss = 11.2760  \n",
      "\n",
      "Fold: 9  Epoch: 280  Training loss = 3.1648  Validation loss = 11.2756  \n",
      "\n",
      "Fold: 9  Epoch: 281  Training loss = 3.1647  Validation loss = 11.2753  \n",
      "\n",
      "Fold: 9  Epoch: 282  Training loss = 3.1645  Validation loss = 11.2749  \n",
      "\n",
      "Fold: 9  Epoch: 283  Training loss = 3.1642  Validation loss = 11.2746  \n",
      "\n",
      "Fold: 9  Epoch: 284  Training loss = 3.1641  Validation loss = 11.2743  \n",
      "\n",
      "Fold: 9  Epoch: 285  Training loss = 3.1639  Validation loss = 11.2740  \n",
      "\n",
      "Fold: 9  Epoch: 286  Training loss = 3.1637  Validation loss = 11.2737  \n",
      "\n",
      "Fold: 9  Epoch: 287  Training loss = 3.1635  Validation loss = 11.2734  \n",
      "\n",
      "Fold: 9  Epoch: 288  Training loss = 3.1633  Validation loss = 11.2730  \n",
      "\n",
      "Fold: 9  Epoch: 289  Training loss = 3.1631  Validation loss = 11.2727  \n",
      "\n",
      "Fold: 9  Epoch: 290  Training loss = 3.1629  Validation loss = 11.2724  \n",
      "\n",
      "Fold: 9  Epoch: 291  Training loss = 3.1627  Validation loss = 11.2720  \n",
      "\n",
      "Fold: 9  Epoch: 292  Training loss = 3.1625  Validation loss = 11.2717  \n",
      "\n",
      "Fold: 9  Epoch: 293  Training loss = 3.1623  Validation loss = 11.2713  \n",
      "\n",
      "Fold: 9  Epoch: 294  Training loss = 3.1621  Validation loss = 11.2709  \n",
      "\n",
      "Fold: 9  Epoch: 295  Training loss = 3.1619  Validation loss = 11.2707  \n",
      "\n",
      "Fold: 9  Epoch: 296  Training loss = 3.1617  Validation loss = 11.2703  \n",
      "\n",
      "Fold: 9  Epoch: 297  Training loss = 3.1615  Validation loss = 11.2700  \n",
      "\n",
      "Fold: 9  Epoch: 298  Training loss = 3.1613  Validation loss = 11.2696  \n",
      "\n",
      "Fold: 9  Epoch: 299  Training loss = 3.1611  Validation loss = 11.2693  \n",
      "\n",
      "Fold: 9  Epoch: 300  Training loss = 3.1608  Validation loss = 11.2689  \n",
      "\n",
      "Fold: 9  Epoch: 301  Training loss = 3.1606  Validation loss = 11.2686  \n",
      "\n",
      "Fold: 9  Epoch: 302  Training loss = 3.1605  Validation loss = 11.2683  \n",
      "\n",
      "Fold: 9  Epoch: 303  Training loss = 3.1603  Validation loss = 11.2680  \n",
      "\n",
      "Fold: 9  Epoch: 304  Training loss = 3.1601  Validation loss = 11.2676  \n",
      "\n",
      "Fold: 9  Epoch: 305  Training loss = 3.1599  Validation loss = 11.2672  \n",
      "\n",
      "Fold: 9  Epoch: 306  Training loss = 3.1597  Validation loss = 11.2669  \n",
      "\n",
      "Fold: 9  Epoch: 307  Training loss = 3.1595  Validation loss = 11.2666  \n",
      "\n",
      "Fold: 9  Epoch: 308  Training loss = 3.1593  Validation loss = 11.2663  \n",
      "\n",
      "Fold: 9  Epoch: 309  Training loss = 3.1591  Validation loss = 11.2660  \n",
      "\n",
      "Fold: 9  Epoch: 310  Training loss = 3.1589  Validation loss = 11.2656  \n",
      "\n",
      "Fold: 9  Epoch: 311  Training loss = 3.1587  Validation loss = 11.2653  \n",
      "\n",
      "Fold: 9  Epoch: 312  Training loss = 3.1585  Validation loss = 11.2649  \n",
      "\n",
      "Fold: 9  Epoch: 313  Training loss = 3.1583  Validation loss = 11.2646  \n",
      "\n",
      "Fold: 9  Epoch: 314  Training loss = 3.1581  Validation loss = 11.2642  \n",
      "\n",
      "Fold: 9  Epoch: 315  Training loss = 3.1579  Validation loss = 11.2639  \n",
      "\n",
      "Fold: 9  Epoch: 316  Training loss = 3.1577  Validation loss = 11.2636  \n",
      "\n",
      "Fold: 9  Epoch: 317  Training loss = 3.1575  Validation loss = 11.2632  \n",
      "\n",
      "Fold: 9  Epoch: 318  Training loss = 3.1572  Validation loss = 11.2628  \n",
      "\n",
      "Fold: 9  Epoch: 319  Training loss = 3.1570  Validation loss = 11.2624  \n",
      "\n",
      "Fold: 9  Epoch: 320  Training loss = 3.1568  Validation loss = 11.2620  \n",
      "\n",
      "Fold: 9  Epoch: 321  Training loss = 3.1566  Validation loss = 11.2617  \n",
      "\n",
      "Fold: 9  Epoch: 322  Training loss = 3.1564  Validation loss = 11.2614  \n",
      "\n",
      "Fold: 9  Epoch: 323  Training loss = 3.1561  Validation loss = 11.2610  \n",
      "\n",
      "Fold: 9  Epoch: 324  Training loss = 3.1560  Validation loss = 11.2607  \n",
      "\n",
      "Fold: 9  Epoch: 325  Training loss = 3.1557  Validation loss = 11.2602  \n",
      "\n",
      "Fold: 9  Epoch: 326  Training loss = 3.1555  Validation loss = 11.2599  \n",
      "\n",
      "Fold: 9  Epoch: 327  Training loss = 3.1553  Validation loss = 11.2596  \n",
      "\n",
      "Fold: 9  Epoch: 328  Training loss = 3.1551  Validation loss = 11.2592  \n",
      "\n",
      "Fold: 9  Epoch: 329  Training loss = 3.1549  Validation loss = 11.2589  \n",
      "\n",
      "Fold: 9  Epoch: 330  Training loss = 3.1547  Validation loss = 11.2586  \n",
      "\n",
      "Fold: 9  Epoch: 331  Training loss = 3.1545  Validation loss = 11.2582  \n",
      "\n",
      "Fold: 9  Epoch: 332  Training loss = 3.1543  Validation loss = 11.2579  \n",
      "\n",
      "Fold: 9  Epoch: 333  Training loss = 3.1542  Validation loss = 11.2576  \n",
      "\n",
      "Fold: 9  Epoch: 334  Training loss = 3.1539  Validation loss = 11.2573  \n",
      "\n",
      "Fold: 9  Epoch: 335  Training loss = 3.1537  Validation loss = 11.2569  \n",
      "\n",
      "Fold: 9  Epoch: 336  Training loss = 3.1535  Validation loss = 11.2565  \n",
      "\n",
      "Fold: 9  Epoch: 337  Training loss = 3.1533  Validation loss = 11.2561  \n",
      "\n",
      "Fold: 9  Epoch: 338  Training loss = 3.1531  Validation loss = 11.2558  \n",
      "\n",
      "Fold: 9  Epoch: 339  Training loss = 3.1529  Validation loss = 11.2556  \n",
      "\n",
      "Fold: 9  Epoch: 340  Training loss = 3.1528  Validation loss = 11.2553  \n",
      "\n",
      "Fold: 9  Epoch: 341  Training loss = 3.1526  Validation loss = 11.2549  \n",
      "\n",
      "Fold: 9  Epoch: 342  Training loss = 3.1523  Validation loss = 11.2545  \n",
      "\n",
      "Fold: 9  Epoch: 343  Training loss = 3.1521  Validation loss = 11.2541  \n",
      "\n",
      "Fold: 9  Epoch: 344  Training loss = 3.1519  Validation loss = 11.2538  \n",
      "\n",
      "Fold: 9  Epoch: 345  Training loss = 3.1517  Validation loss = 11.2534  \n",
      "\n",
      "Fold: 9  Epoch: 346  Training loss = 3.1514  Validation loss = 11.2529  \n",
      "\n",
      "Fold: 9  Epoch: 347  Training loss = 3.1512  Validation loss = 11.2526  \n",
      "\n",
      "Fold: 9  Epoch: 348  Training loss = 3.1510  Validation loss = 11.2524  \n",
      "\n",
      "Fold: 9  Epoch: 349  Training loss = 3.1508  Validation loss = 11.2520  \n",
      "\n",
      "Fold: 9  Epoch: 350  Training loss = 3.1506  Validation loss = 11.2516  \n",
      "\n",
      "Fold: 9  Epoch: 351  Training loss = 3.1504  Validation loss = 11.2513  \n",
      "\n",
      "Fold: 9  Epoch: 352  Training loss = 3.1502  Validation loss = 11.2510  \n",
      "\n",
      "Fold: 9  Epoch: 353  Training loss = 3.1500  Validation loss = 11.2506  \n",
      "\n",
      "Fold: 9  Epoch: 354  Training loss = 3.1498  Validation loss = 11.2502  \n",
      "\n",
      "Fold: 9  Epoch: 355  Training loss = 3.1496  Validation loss = 11.2500  \n",
      "\n",
      "Fold: 9  Epoch: 356  Training loss = 3.1494  Validation loss = 11.2496  \n",
      "\n",
      "Fold: 9  Epoch: 357  Training loss = 3.1492  Validation loss = 11.2492  \n",
      "\n",
      "Fold: 9  Epoch: 358  Training loss = 3.1490  Validation loss = 11.2489  \n",
      "\n",
      "Fold: 9  Epoch: 359  Training loss = 3.1488  Validation loss = 11.2486  \n",
      "\n",
      "Fold: 9  Epoch: 360  Training loss = 3.1486  Validation loss = 11.2482  \n",
      "\n",
      "Fold: 9  Epoch: 361  Training loss = 3.1484  Validation loss = 11.2479  \n",
      "\n",
      "Fold: 9  Epoch: 362  Training loss = 3.1482  Validation loss = 11.2475  \n",
      "\n",
      "Fold: 9  Epoch: 363  Training loss = 3.1480  Validation loss = 11.2471  \n",
      "\n",
      "Fold: 9  Epoch: 364  Training loss = 3.1478  Validation loss = 11.2467  \n",
      "\n",
      "Fold: 9  Epoch: 365  Training loss = 3.1475  Validation loss = 11.2464  \n",
      "\n",
      "Fold: 9  Epoch: 366  Training loss = 3.1473  Validation loss = 11.2460  \n",
      "\n",
      "Fold: 9  Epoch: 367  Training loss = 3.1471  Validation loss = 11.2457  \n",
      "\n",
      "Fold: 9  Epoch: 368  Training loss = 3.1470  Validation loss = 11.2454  \n",
      "\n",
      "Fold: 9  Epoch: 369  Training loss = 3.1468  Validation loss = 11.2450  \n",
      "\n",
      "Fold: 9  Epoch: 370  Training loss = 3.1466  Validation loss = 11.2447  \n",
      "\n",
      "Fold: 9  Epoch: 371  Training loss = 3.1464  Validation loss = 11.2444  \n",
      "\n",
      "Fold: 9  Epoch: 372  Training loss = 3.1461  Validation loss = 11.2440  \n",
      "\n",
      "Fold: 9  Epoch: 373  Training loss = 3.1459  Validation loss = 11.2436  \n",
      "\n",
      "Fold: 9  Epoch: 374  Training loss = 3.1457  Validation loss = 11.2433  \n",
      "\n",
      "Fold: 9  Epoch: 375  Training loss = 3.1455  Validation loss = 11.2428  \n",
      "\n",
      "Fold: 9  Epoch: 376  Training loss = 3.1452  Validation loss = 11.2424  \n",
      "\n",
      "Fold: 9  Epoch: 377  Training loss = 3.1450  Validation loss = 11.2420  \n",
      "\n",
      "Fold: 9  Epoch: 378  Training loss = 3.1448  Validation loss = 11.2417  \n",
      "\n",
      "Fold: 9  Epoch: 379  Training loss = 3.1446  Validation loss = 11.2413  \n",
      "\n",
      "Fold: 9  Epoch: 380  Training loss = 3.1444  Validation loss = 11.2409  \n",
      "\n",
      "Fold: 9  Epoch: 381  Training loss = 3.1441  Validation loss = 11.2405  \n",
      "\n",
      "Fold: 9  Epoch: 382  Training loss = 3.1439  Validation loss = 11.2401  \n",
      "\n",
      "Fold: 9  Epoch: 383  Training loss = 3.1437  Validation loss = 11.2399  \n",
      "\n",
      "Fold: 9  Epoch: 384  Training loss = 3.1435  Validation loss = 11.2395  \n",
      "\n",
      "Fold: 9  Epoch: 385  Training loss = 3.1433  Validation loss = 11.2392  \n",
      "\n",
      "Fold: 9  Epoch: 386  Training loss = 3.1431  Validation loss = 11.2388  \n",
      "\n",
      "Fold: 9  Epoch: 387  Training loss = 3.1429  Validation loss = 11.2384  \n",
      "\n",
      "Fold: 9  Epoch: 388  Training loss = 3.1427  Validation loss = 11.2381  \n",
      "\n",
      "Fold: 9  Epoch: 389  Training loss = 3.1424  Validation loss = 11.2377  \n",
      "\n",
      "Fold: 9  Epoch: 390  Training loss = 3.1422  Validation loss = 11.2373  \n",
      "\n",
      "Fold: 9  Epoch: 391  Training loss = 3.1420  Validation loss = 11.2369  \n",
      "\n",
      "Fold: 9  Epoch: 392  Training loss = 3.1418  Validation loss = 11.2365  \n",
      "\n",
      "Fold: 9  Epoch: 393  Training loss = 3.1415  Validation loss = 11.2361  \n",
      "\n",
      "Fold: 9  Epoch: 394  Training loss = 3.1414  Validation loss = 11.2358  \n",
      "\n",
      "Fold: 9  Epoch: 395  Training loss = 3.1412  Validation loss = 11.2355  \n",
      "\n",
      "Fold: 9  Epoch: 396  Training loss = 3.1410  Validation loss = 11.2351  \n",
      "\n",
      "Fold: 9  Epoch: 397  Training loss = 3.1408  Validation loss = 11.2348  \n",
      "\n",
      "Fold: 9  Epoch: 398  Training loss = 3.1406  Validation loss = 11.2344  \n",
      "\n",
      "Fold: 9  Epoch: 399  Training loss = 3.1404  Validation loss = 11.2341  \n",
      "\n",
      "Fold: 9  Epoch: 400  Training loss = 3.1402  Validation loss = 11.2338  \n",
      "\n",
      "Fold: 9  Epoch: 401  Training loss = 3.1400  Validation loss = 11.2334  \n",
      "\n",
      "Fold: 9  Epoch: 402  Training loss = 3.1398  Validation loss = 11.2331  \n",
      "\n",
      "Fold: 9  Epoch: 403  Training loss = 3.1396  Validation loss = 11.2328  \n",
      "\n",
      "Fold: 9  Epoch: 404  Training loss = 3.1394  Validation loss = 11.2324  \n",
      "\n",
      "Fold: 9  Epoch: 405  Training loss = 3.1392  Validation loss = 11.2321  \n",
      "\n",
      "Fold: 9  Epoch: 406  Training loss = 3.1389  Validation loss = 11.2317  \n",
      "\n",
      "Fold: 9  Epoch: 407  Training loss = 3.1388  Validation loss = 11.2314  \n",
      "\n",
      "Fold: 9  Epoch: 408  Training loss = 3.1386  Validation loss = 11.2310  \n",
      "\n",
      "Fold: 9  Epoch: 409  Training loss = 3.1384  Validation loss = 11.2307  \n",
      "\n",
      "Fold: 9  Epoch: 410  Training loss = 3.1382  Validation loss = 11.2304  \n",
      "\n",
      "Fold: 9  Epoch: 411  Training loss = 3.1381  Validation loss = 11.2302  \n",
      "\n",
      "Fold: 9  Epoch: 412  Training loss = 3.1379  Validation loss = 11.2299  \n",
      "\n",
      "Fold: 9  Epoch: 413  Training loss = 3.1377  Validation loss = 11.2295  \n",
      "\n",
      "Fold: 9  Epoch: 414  Training loss = 3.1375  Validation loss = 11.2291  \n",
      "\n",
      "Fold: 9  Epoch: 415  Training loss = 3.1372  Validation loss = 11.2288  \n",
      "\n",
      "Fold: 9  Epoch: 416  Training loss = 3.1370  Validation loss = 11.2284  \n",
      "\n",
      "Fold: 9  Epoch: 417  Training loss = 3.1368  Validation loss = 11.2281  \n",
      "\n",
      "Fold: 9  Epoch: 418  Training loss = 3.1367  Validation loss = 11.2278  \n",
      "\n",
      "Fold: 9  Epoch: 419  Training loss = 3.1364  Validation loss = 11.2274  \n",
      "\n",
      "Fold: 9  Epoch: 420  Training loss = 3.1362  Validation loss = 11.2270  \n",
      "\n",
      "Fold: 9  Epoch: 421  Training loss = 3.1360  Validation loss = 11.2267  \n",
      "\n",
      "Fold: 9  Epoch: 422  Training loss = 3.1358  Validation loss = 11.2264  \n",
      "\n",
      "Fold: 9  Epoch: 423  Training loss = 3.1356  Validation loss = 11.2260  \n",
      "\n",
      "Fold: 9  Epoch: 424  Training loss = 3.1354  Validation loss = 11.2257  \n",
      "\n",
      "Fold: 9  Epoch: 425  Training loss = 3.1352  Validation loss = 11.2254  \n",
      "\n",
      "Fold: 9  Epoch: 426  Training loss = 3.1351  Validation loss = 11.2251  \n",
      "\n",
      "Fold: 9  Epoch: 427  Training loss = 3.1349  Validation loss = 11.2248  \n",
      "\n",
      "Fold: 9  Epoch: 428  Training loss = 3.1347  Validation loss = 11.2245  \n",
      "\n",
      "Fold: 9  Epoch: 429  Training loss = 3.1346  Validation loss = 11.2242  \n",
      "\n",
      "Fold: 9  Epoch: 430  Training loss = 3.1344  Validation loss = 11.2239  \n",
      "\n",
      "Fold: 9  Epoch: 431  Training loss = 3.1342  Validation loss = 11.2235  \n",
      "\n",
      "Fold: 9  Epoch: 432  Training loss = 3.1340  Validation loss = 11.2233  \n",
      "\n",
      "Fold: 9  Epoch: 433  Training loss = 3.1338  Validation loss = 11.2229  \n",
      "\n",
      "Fold: 9  Epoch: 434  Training loss = 3.1336  Validation loss = 11.2226  \n",
      "\n",
      "Fold: 9  Epoch: 435  Training loss = 3.1334  Validation loss = 11.2223  \n",
      "\n",
      "Fold: 9  Epoch: 436  Training loss = 3.1332  Validation loss = 11.2220  \n",
      "\n",
      "Fold: 9  Epoch: 437  Training loss = 3.1331  Validation loss = 11.2217  \n",
      "\n",
      "Fold: 9  Epoch: 438  Training loss = 3.1329  Validation loss = 11.2213  \n",
      "\n",
      "Fold: 9  Epoch: 439  Training loss = 3.1327  Validation loss = 11.2210  \n",
      "\n",
      "Fold: 9  Epoch: 440  Training loss = 3.1325  Validation loss = 11.2207  \n",
      "\n",
      "Fold: 9  Epoch: 441  Training loss = 3.1323  Validation loss = 11.2203  \n",
      "\n",
      "Fold: 9  Epoch: 442  Training loss = 3.1321  Validation loss = 11.2200  \n",
      "\n",
      "Fold: 9  Epoch: 443  Training loss = 3.1319  Validation loss = 11.2196  \n",
      "\n",
      "Fold: 9  Epoch: 444  Training loss = 3.1317  Validation loss = 11.2193  \n",
      "\n",
      "Fold: 9  Epoch: 445  Training loss = 3.1315  Validation loss = 11.2190  \n",
      "\n",
      "Fold: 9  Epoch: 446  Training loss = 3.1314  Validation loss = 11.2187  \n",
      "\n",
      "Fold: 9  Epoch: 447  Training loss = 3.1311  Validation loss = 11.2184  \n",
      "\n",
      "Fold: 9  Epoch: 448  Training loss = 3.1310  Validation loss = 11.2180  \n",
      "\n",
      "Fold: 9  Epoch: 449  Training loss = 3.1307  Validation loss = 11.2177  \n",
      "\n",
      "Fold: 9  Epoch: 450  Training loss = 3.1305  Validation loss = 11.2173  \n",
      "\n",
      "Fold: 9  Epoch: 451  Training loss = 3.1303  Validation loss = 11.2169  \n",
      "\n",
      "Fold: 9  Epoch: 452  Training loss = 3.1301  Validation loss = 11.2166  \n",
      "\n",
      "Fold: 9  Epoch: 453  Training loss = 3.1299  Validation loss = 11.2163  \n",
      "\n",
      "Fold: 9  Epoch: 454  Training loss = 3.1298  Validation loss = 11.2160  \n",
      "\n",
      "Fold: 9  Epoch: 455  Training loss = 3.1295  Validation loss = 11.2156  \n",
      "\n",
      "Fold: 9  Epoch: 456  Training loss = 3.1294  Validation loss = 11.2153  \n",
      "\n",
      "Fold: 9  Epoch: 457  Training loss = 3.1292  Validation loss = 11.2150  \n",
      "\n",
      "Fold: 9  Epoch: 458  Training loss = 3.1290  Validation loss = 11.2147  \n",
      "\n",
      "Fold: 9  Epoch: 459  Training loss = 3.1288  Validation loss = 11.2144  \n",
      "\n",
      "Fold: 9  Epoch: 460  Training loss = 3.1286  Validation loss = 11.2140  \n",
      "\n",
      "Fold: 9  Epoch: 461  Training loss = 3.1284  Validation loss = 11.2137  \n",
      "\n",
      "Fold: 9  Epoch: 462  Training loss = 3.1282  Validation loss = 11.2133  \n",
      "\n",
      "Fold: 9  Epoch: 463  Training loss = 3.1280  Validation loss = 11.2130  \n",
      "\n",
      "Fold: 9  Epoch: 464  Training loss = 3.1279  Validation loss = 11.2127  \n",
      "\n",
      "Fold: 9  Epoch: 465  Training loss = 3.1277  Validation loss = 11.2124  \n",
      "\n",
      "Fold: 9  Epoch: 466  Training loss = 3.1275  Validation loss = 11.2121  \n",
      "\n",
      "Fold: 9  Epoch: 467  Training loss = 3.1273  Validation loss = 11.2117  \n",
      "\n",
      "Fold: 9  Epoch: 468  Training loss = 3.1271  Validation loss = 11.2115  \n",
      "\n",
      "Fold: 9  Epoch: 469  Training loss = 3.1269  Validation loss = 11.2111  \n",
      "\n",
      "Fold: 9  Epoch: 470  Training loss = 3.1267  Validation loss = 11.2107  \n",
      "\n",
      "Fold: 9  Epoch: 471  Training loss = 3.1265  Validation loss = 11.2104  \n",
      "\n",
      "Fold: 9  Epoch: 472  Training loss = 3.1263  Validation loss = 11.2101  \n",
      "\n",
      "Fold: 9  Epoch: 473  Training loss = 3.1261  Validation loss = 11.2097  \n",
      "\n",
      "Fold: 9  Epoch: 474  Training loss = 3.1259  Validation loss = 11.2094  \n",
      "\n",
      "Fold: 9  Epoch: 475  Training loss = 3.1257  Validation loss = 11.2090  \n",
      "\n",
      "Fold: 9  Epoch: 476  Training loss = 3.1255  Validation loss = 11.2087  \n",
      "\n",
      "Fold: 9  Epoch: 477  Training loss = 3.1253  Validation loss = 11.2084  \n",
      "\n",
      "Fold: 9  Epoch: 478  Training loss = 3.1251  Validation loss = 11.2080  \n",
      "\n",
      "Fold: 9  Epoch: 479  Training loss = 3.1250  Validation loss = 11.2077  \n",
      "\n",
      "Fold: 9  Epoch: 480  Training loss = 3.1247  Validation loss = 11.2073  \n",
      "\n",
      "Fold: 9  Epoch: 481  Training loss = 3.1245  Validation loss = 11.2070  \n",
      "\n",
      "Fold: 9  Epoch: 482  Training loss = 3.1244  Validation loss = 11.2067  \n",
      "\n",
      "Fold: 9  Epoch: 483  Training loss = 3.1241  Validation loss = 11.2063  \n",
      "\n",
      "Fold: 9  Epoch: 484  Training loss = 3.1240  Validation loss = 11.2060  \n",
      "\n",
      "Fold: 9  Epoch: 485  Training loss = 3.1238  Validation loss = 11.2057  \n",
      "\n",
      "Fold: 9  Epoch: 486  Training loss = 3.1236  Validation loss = 11.2053  \n",
      "\n",
      "Fold: 9  Epoch: 487  Training loss = 3.1234  Validation loss = 11.2051  \n",
      "\n",
      "Fold: 9  Epoch: 488  Training loss = 3.1232  Validation loss = 11.2047  \n",
      "\n",
      "Fold: 9  Epoch: 489  Training loss = 3.1230  Validation loss = 11.2043  \n",
      "\n",
      "Fold: 9  Epoch: 490  Training loss = 3.1228  Validation loss = 11.2040  \n",
      "\n",
      "Fold: 9  Epoch: 491  Training loss = 3.1226  Validation loss = 11.2037  \n",
      "\n",
      "Fold: 9  Epoch: 492  Training loss = 3.1224  Validation loss = 11.2033  \n",
      "\n",
      "Fold: 9  Epoch: 493  Training loss = 3.1222  Validation loss = 11.2030  \n",
      "\n",
      "Fold: 9  Epoch: 494  Training loss = 3.1220  Validation loss = 11.2027  \n",
      "\n",
      "Fold: 9  Epoch: 495  Training loss = 3.1219  Validation loss = 11.2024  \n",
      "\n",
      "Fold: 9  Epoch: 496  Training loss = 3.1217  Validation loss = 11.2021  \n",
      "\n",
      "Fold: 9  Epoch: 497  Training loss = 3.1215  Validation loss = 11.2018  \n",
      "\n",
      "Fold: 9  Epoch: 498  Training loss = 3.1213  Validation loss = 11.2015  \n",
      "\n",
      "Fold: 9  Epoch: 499  Training loss = 3.1212  Validation loss = 11.2012  \n",
      "\n",
      "Fold: 9  Epoch: 500  Training loss = 3.1210  Validation loss = 11.2009  \n",
      "\n",
      "Check model:  Fold: 9  Optimal epoch: 500  \n",
      "\n",
      "Fold: 10  Epoch: 1  Training loss = 4.1427  Validation loss = 6.8561  \n",
      "\n",
      "Fold: 10  Epoch: 2  Training loss = 4.1424  Validation loss = 6.8557  \n",
      "\n",
      "Fold: 10  Epoch: 3  Training loss = 4.1421  Validation loss = 6.8550  \n",
      "\n",
      "Fold: 10  Epoch: 4  Training loss = 4.1417  Validation loss = 6.8544  \n",
      "\n",
      "Fold: 10  Epoch: 5  Training loss = 4.1414  Validation loss = 6.8540  \n",
      "\n",
      "Fold: 10  Epoch: 6  Training loss = 4.1412  Validation loss = 6.8537  \n",
      "\n",
      "Fold: 10  Epoch: 7  Training loss = 4.1409  Validation loss = 6.8533  \n",
      "\n",
      "Fold: 10  Epoch: 8  Training loss = 4.1406  Validation loss = 6.8528  \n",
      "\n",
      "Fold: 10  Epoch: 9  Training loss = 4.1403  Validation loss = 6.8523  \n",
      "\n",
      "Fold: 10  Epoch: 10  Training loss = 4.1400  Validation loss = 6.8517  \n",
      "\n",
      "Fold: 10  Epoch: 11  Training loss = 4.1397  Validation loss = 6.8512  \n",
      "\n",
      "Fold: 10  Epoch: 12  Training loss = 4.1394  Validation loss = 6.8508  \n",
      "\n",
      "Fold: 10  Epoch: 13  Training loss = 4.1390  Validation loss = 6.8503  \n",
      "\n",
      "Fold: 10  Epoch: 14  Training loss = 4.1388  Validation loss = 6.8498  \n",
      "\n",
      "Fold: 10  Epoch: 15  Training loss = 4.1385  Validation loss = 6.8495  \n",
      "\n",
      "Fold: 10  Epoch: 16  Training loss = 4.1383  Validation loss = 6.8492  \n",
      "\n",
      "Fold: 10  Epoch: 17  Training loss = 4.1381  Validation loss = 6.8489  \n",
      "\n",
      "Fold: 10  Epoch: 18  Training loss = 4.1378  Validation loss = 6.8485  \n",
      "\n",
      "Fold: 10  Epoch: 19  Training loss = 4.1376  Validation loss = 6.8482  \n",
      "\n",
      "Fold: 10  Epoch: 20  Training loss = 4.1373  Validation loss = 6.8478  \n",
      "\n",
      "Fold: 10  Epoch: 21  Training loss = 4.1370  Validation loss = 6.8473  \n",
      "\n",
      "Fold: 10  Epoch: 22  Training loss = 4.1367  Validation loss = 6.8469  \n",
      "\n",
      "Fold: 10  Epoch: 23  Training loss = 4.1364  Validation loss = 6.8464  \n",
      "\n",
      "Fold: 10  Epoch: 24  Training loss = 4.1360  Validation loss = 6.8459  \n",
      "\n",
      "Fold: 10  Epoch: 25  Training loss = 4.1358  Validation loss = 6.8455  \n",
      "\n",
      "Fold: 10  Epoch: 26  Training loss = 4.1354  Validation loss = 6.8449  \n",
      "\n",
      "Fold: 10  Epoch: 27  Training loss = 4.1353  Validation loss = 6.8447  \n",
      "\n",
      "Fold: 10  Epoch: 28  Training loss = 4.1349  Validation loss = 6.8442  \n",
      "\n",
      "Fold: 10  Epoch: 29  Training loss = 4.1347  Validation loss = 6.8439  \n",
      "\n",
      "Fold: 10  Epoch: 30  Training loss = 4.1344  Validation loss = 6.8435  \n",
      "\n",
      "Fold: 10  Epoch: 31  Training loss = 4.1342  Validation loss = 6.8432  \n",
      "\n",
      "Fold: 10  Epoch: 32  Training loss = 4.1339  Validation loss = 6.8428  \n",
      "\n",
      "Fold: 10  Epoch: 33  Training loss = 4.1336  Validation loss = 6.8422  \n",
      "\n",
      "Fold: 10  Epoch: 34  Training loss = 4.1333  Validation loss = 6.8418  \n",
      "\n",
      "Fold: 10  Epoch: 35  Training loss = 4.1332  Validation loss = 6.8416  \n",
      "\n",
      "Fold: 10  Epoch: 36  Training loss = 4.1329  Validation loss = 6.8412  \n",
      "\n",
      "Fold: 10  Epoch: 37  Training loss = 4.1326  Validation loss = 6.8407  \n",
      "\n",
      "Fold: 10  Epoch: 38  Training loss = 4.1324  Validation loss = 6.8404  \n",
      "\n",
      "Fold: 10  Epoch: 39  Training loss = 4.1321  Validation loss = 6.8401  \n",
      "\n",
      "Fold: 10  Epoch: 40  Training loss = 4.1319  Validation loss = 6.8397  \n",
      "\n",
      "Fold: 10  Epoch: 41  Training loss = 4.1316  Validation loss = 6.8393  \n",
      "\n",
      "Fold: 10  Epoch: 42  Training loss = 4.1313  Validation loss = 6.8389  \n",
      "\n",
      "Fold: 10  Epoch: 43  Training loss = 4.1312  Validation loss = 6.8387  \n",
      "\n",
      "Fold: 10  Epoch: 44  Training loss = 4.1309  Validation loss = 6.8384  \n",
      "\n",
      "Fold: 10  Epoch: 45  Training loss = 4.1306  Validation loss = 6.8378  \n",
      "\n",
      "Fold: 10  Epoch: 46  Training loss = 4.1303  Validation loss = 6.8374  \n",
      "\n",
      "Fold: 10  Epoch: 47  Training loss = 4.1301  Validation loss = 6.8372  \n",
      "\n",
      "Fold: 10  Epoch: 48  Training loss = 4.1299  Validation loss = 6.8369  \n",
      "\n",
      "Fold: 10  Epoch: 49  Training loss = 4.1296  Validation loss = 6.8365  \n",
      "\n",
      "Fold: 10  Epoch: 50  Training loss = 4.1293  Validation loss = 6.8359  \n",
      "\n",
      "Fold: 10  Epoch: 51  Training loss = 4.1289  Validation loss = 6.8352  \n",
      "\n",
      "Fold: 10  Epoch: 52  Training loss = 4.1287  Validation loss = 6.8348  \n",
      "\n",
      "Fold: 10  Epoch: 53  Training loss = 4.1284  Validation loss = 6.8344  \n",
      "\n",
      "Fold: 10  Epoch: 54  Training loss = 4.1282  Validation loss = 6.8341  \n",
      "\n",
      "Fold: 10  Epoch: 55  Training loss = 4.1279  Validation loss = 6.8337  \n",
      "\n",
      "Fold: 10  Epoch: 56  Training loss = 4.1276  Validation loss = 6.8334  \n",
      "\n",
      "Fold: 10  Epoch: 57  Training loss = 4.1274  Validation loss = 6.8330  \n",
      "\n",
      "Fold: 10  Epoch: 58  Training loss = 4.1271  Validation loss = 6.8325  \n",
      "\n",
      "Fold: 10  Epoch: 59  Training loss = 4.1268  Validation loss = 6.8321  \n",
      "\n",
      "Fold: 10  Epoch: 60  Training loss = 4.1265  Validation loss = 6.8317  \n",
      "\n",
      "Fold: 10  Epoch: 61  Training loss = 4.1261  Validation loss = 6.8311  \n",
      "\n",
      "Fold: 10  Epoch: 62  Training loss = 4.1258  Validation loss = 6.8307  \n",
      "\n",
      "Fold: 10  Epoch: 63  Training loss = 4.1255  Validation loss = 6.8303  \n",
      "\n",
      "Fold: 10  Epoch: 64  Training loss = 4.1253  Validation loss = 6.8299  \n",
      "\n",
      "Fold: 10  Epoch: 65  Training loss = 4.1250  Validation loss = 6.8294  \n",
      "\n",
      "Fold: 10  Epoch: 66  Training loss = 4.1247  Validation loss = 6.8290  \n",
      "\n",
      "Fold: 10  Epoch: 67  Training loss = 4.1245  Validation loss = 6.8287  \n",
      "\n",
      "Fold: 10  Epoch: 68  Training loss = 4.1242  Validation loss = 6.8283  \n",
      "\n",
      "Fold: 10  Epoch: 69  Training loss = 4.1239  Validation loss = 6.8278  \n",
      "\n",
      "Fold: 10  Epoch: 70  Training loss = 4.1236  Validation loss = 6.8274  \n",
      "\n",
      "Fold: 10  Epoch: 71  Training loss = 4.1233  Validation loss = 6.8270  \n",
      "\n",
      "Fold: 10  Epoch: 72  Training loss = 4.1231  Validation loss = 6.8265  \n",
      "\n",
      "Fold: 10  Epoch: 73  Training loss = 4.1229  Validation loss = 6.8262  \n",
      "\n",
      "Fold: 10  Epoch: 74  Training loss = 4.1226  Validation loss = 6.8258  \n",
      "\n",
      "Fold: 10  Epoch: 75  Training loss = 4.1224  Validation loss = 6.8255  \n",
      "\n",
      "Fold: 10  Epoch: 76  Training loss = 4.1221  Validation loss = 6.8252  \n",
      "\n",
      "Fold: 10  Epoch: 77  Training loss = 4.1219  Validation loss = 6.8248  \n",
      "\n",
      "Fold: 10  Epoch: 78  Training loss = 4.1217  Validation loss = 6.8246  \n",
      "\n",
      "Fold: 10  Epoch: 79  Training loss = 4.1214  Validation loss = 6.8242  \n",
      "\n",
      "Fold: 10  Epoch: 80  Training loss = 4.1212  Validation loss = 6.8238  \n",
      "\n",
      "Fold: 10  Epoch: 81  Training loss = 4.1210  Validation loss = 6.8235  \n",
      "\n",
      "Fold: 10  Epoch: 82  Training loss = 4.1207  Validation loss = 6.8232  \n",
      "\n",
      "Fold: 10  Epoch: 83  Training loss = 4.1204  Validation loss = 6.8228  \n",
      "\n",
      "Fold: 10  Epoch: 84  Training loss = 4.1201  Validation loss = 6.8223  \n",
      "\n",
      "Fold: 10  Epoch: 85  Training loss = 4.1199  Validation loss = 6.8220  \n",
      "\n",
      "Fold: 10  Epoch: 86  Training loss = 4.1197  Validation loss = 6.8216  \n",
      "\n",
      "Fold: 10  Epoch: 87  Training loss = 4.1194  Validation loss = 6.8213  \n",
      "\n",
      "Fold: 10  Epoch: 88  Training loss = 4.1191  Validation loss = 6.8209  \n",
      "\n",
      "Fold: 10  Epoch: 89  Training loss = 4.1189  Validation loss = 6.8206  \n",
      "\n",
      "Fold: 10  Epoch: 90  Training loss = 4.1187  Validation loss = 6.8203  \n",
      "\n",
      "Fold: 10  Epoch: 91  Training loss = 4.1184  Validation loss = 6.8198  \n",
      "\n",
      "Fold: 10  Epoch: 92  Training loss = 4.1181  Validation loss = 6.8195  \n",
      "\n",
      "Fold: 10  Epoch: 93  Training loss = 4.1179  Validation loss = 6.8192  \n",
      "\n",
      "Fold: 10  Epoch: 94  Training loss = 4.1176  Validation loss = 6.8189  \n",
      "\n",
      "Fold: 10  Epoch: 95  Training loss = 4.1173  Validation loss = 6.8184  \n",
      "\n",
      "Fold: 10  Epoch: 96  Training loss = 4.1170  Validation loss = 6.8180  \n",
      "\n",
      "Fold: 10  Epoch: 97  Training loss = 4.1166  Validation loss = 6.8174  \n",
      "\n",
      "Fold: 10  Epoch: 98  Training loss = 4.1163  Validation loss = 6.8170  \n",
      "\n",
      "Fold: 10  Epoch: 99  Training loss = 4.1161  Validation loss = 6.8166  \n",
      "\n",
      "Fold: 10  Epoch: 100  Training loss = 4.1157  Validation loss = 6.8161  \n",
      "\n",
      "Fold: 10  Epoch: 101  Training loss = 4.1154  Validation loss = 6.8157  \n",
      "\n",
      "Fold: 10  Epoch: 102  Training loss = 4.1152  Validation loss = 6.8154  \n",
      "\n",
      "Fold: 10  Epoch: 103  Training loss = 4.1149  Validation loss = 6.8150  \n",
      "\n",
      "Fold: 10  Epoch: 104  Training loss = 4.1146  Validation loss = 6.8146  \n",
      "\n",
      "Fold: 10  Epoch: 105  Training loss = 4.1144  Validation loss = 6.8143  \n",
      "\n",
      "Fold: 10  Epoch: 106  Training loss = 4.1141  Validation loss = 6.8139  \n",
      "\n",
      "Fold: 10  Epoch: 107  Training loss = 4.1138  Validation loss = 6.8135  \n",
      "\n",
      "Fold: 10  Epoch: 108  Training loss = 4.1135  Validation loss = 6.8131  \n",
      "\n",
      "Fold: 10  Epoch: 109  Training loss = 4.1133  Validation loss = 6.8127  \n",
      "\n",
      "Fold: 10  Epoch: 110  Training loss = 4.1131  Validation loss = 6.8125  \n",
      "\n",
      "Fold: 10  Epoch: 111  Training loss = 4.1128  Validation loss = 6.8121  \n",
      "\n",
      "Fold: 10  Epoch: 112  Training loss = 4.1126  Validation loss = 6.8118  \n",
      "\n",
      "Fold: 10  Epoch: 113  Training loss = 4.1123  Validation loss = 6.8114  \n",
      "\n",
      "Fold: 10  Epoch: 114  Training loss = 4.1121  Validation loss = 6.8110  \n",
      "\n",
      "Fold: 10  Epoch: 115  Training loss = 4.1118  Validation loss = 6.8106  \n",
      "\n",
      "Fold: 10  Epoch: 116  Training loss = 4.1115  Validation loss = 6.8102  \n",
      "\n",
      "Fold: 10  Epoch: 117  Training loss = 4.1112  Validation loss = 6.8098  \n",
      "\n",
      "Fold: 10  Epoch: 118  Training loss = 4.1109  Validation loss = 6.8094  \n",
      "\n",
      "Fold: 10  Epoch: 119  Training loss = 4.1106  Validation loss = 6.8090  \n",
      "\n",
      "Fold: 10  Epoch: 120  Training loss = 4.1103  Validation loss = 6.8085  \n",
      "\n",
      "Fold: 10  Epoch: 121  Training loss = 4.1101  Validation loss = 6.8083  \n",
      "\n",
      "Fold: 10  Epoch: 122  Training loss = 4.1099  Validation loss = 6.8080  \n",
      "\n",
      "Fold: 10  Epoch: 123  Training loss = 4.1097  Validation loss = 6.8077  \n",
      "\n",
      "Fold: 10  Epoch: 124  Training loss = 4.1094  Validation loss = 6.8073  \n",
      "\n",
      "Fold: 10  Epoch: 125  Training loss = 4.1091  Validation loss = 6.8068  \n",
      "\n",
      "Fold: 10  Epoch: 126  Training loss = 4.1089  Validation loss = 6.8065  \n",
      "\n",
      "Fold: 10  Epoch: 127  Training loss = 4.1086  Validation loss = 6.8061  \n",
      "\n",
      "Fold: 10  Epoch: 128  Training loss = 4.1084  Validation loss = 6.8058  \n",
      "\n",
      "Fold: 10  Epoch: 129  Training loss = 4.1081  Validation loss = 6.8054  \n",
      "\n",
      "Fold: 10  Epoch: 130  Training loss = 4.1078  Validation loss = 6.8050  \n",
      "\n",
      "Fold: 10  Epoch: 131  Training loss = 4.1075  Validation loss = 6.8045  \n",
      "\n",
      "Fold: 10  Epoch: 132  Training loss = 4.1072  Validation loss = 6.8041  \n",
      "\n",
      "Fold: 10  Epoch: 133  Training loss = 4.1069  Validation loss = 6.8037  \n",
      "\n",
      "Fold: 10  Epoch: 134  Training loss = 4.1067  Validation loss = 6.8034  \n",
      "\n",
      "Fold: 10  Epoch: 135  Training loss = 4.1064  Validation loss = 6.8030  \n",
      "\n",
      "Fold: 10  Epoch: 136  Training loss = 4.1061  Validation loss = 6.8026  \n",
      "\n",
      "Fold: 10  Epoch: 137  Training loss = 4.1059  Validation loss = 6.8023  \n",
      "\n",
      "Fold: 10  Epoch: 138  Training loss = 4.1056  Validation loss = 6.8020  \n",
      "\n",
      "Fold: 10  Epoch: 139  Training loss = 4.1054  Validation loss = 6.8016  \n",
      "\n",
      "Fold: 10  Epoch: 140  Training loss = 4.1051  Validation loss = 6.8012  \n",
      "\n",
      "Fold: 10  Epoch: 141  Training loss = 4.1047  Validation loss = 6.8008  \n",
      "\n",
      "Fold: 10  Epoch: 142  Training loss = 4.1044  Validation loss = 6.8003  \n",
      "\n",
      "Fold: 10  Epoch: 143  Training loss = 4.1042  Validation loss = 6.8000  \n",
      "\n",
      "Fold: 10  Epoch: 144  Training loss = 4.1040  Validation loss = 6.7996  \n",
      "\n",
      "Fold: 10  Epoch: 145  Training loss = 4.1037  Validation loss = 6.7992  \n",
      "\n",
      "Fold: 10  Epoch: 146  Training loss = 4.1034  Validation loss = 6.7988  \n",
      "\n",
      "Fold: 10  Epoch: 147  Training loss = 4.1031  Validation loss = 6.7984  \n",
      "\n",
      "Fold: 10  Epoch: 148  Training loss = 4.1028  Validation loss = 6.7980  \n",
      "\n",
      "Fold: 10  Epoch: 149  Training loss = 4.1026  Validation loss = 6.7977  \n",
      "\n",
      "Fold: 10  Epoch: 150  Training loss = 4.1023  Validation loss = 6.7974  \n",
      "\n",
      "Fold: 10  Epoch: 151  Training loss = 4.1021  Validation loss = 6.7970  \n",
      "\n",
      "Fold: 10  Epoch: 152  Training loss = 4.1018  Validation loss = 6.7967  \n",
      "\n",
      "Fold: 10  Epoch: 153  Training loss = 4.1016  Validation loss = 6.7963  \n",
      "\n",
      "Fold: 10  Epoch: 154  Training loss = 4.1012  Validation loss = 6.7959  \n",
      "\n",
      "Fold: 10  Epoch: 155  Training loss = 4.1009  Validation loss = 6.7954  \n",
      "\n",
      "Fold: 10  Epoch: 156  Training loss = 4.1006  Validation loss = 6.7950  \n",
      "\n",
      "Fold: 10  Epoch: 157  Training loss = 4.1004  Validation loss = 6.7947  \n",
      "\n",
      "Fold: 10  Epoch: 158  Training loss = 4.1001  Validation loss = 6.7943  \n",
      "\n",
      "Fold: 10  Epoch: 159  Training loss = 4.0999  Validation loss = 6.7940  \n",
      "\n",
      "Fold: 10  Epoch: 160  Training loss = 4.0996  Validation loss = 6.7937  \n",
      "\n",
      "Fold: 10  Epoch: 161  Training loss = 4.0994  Validation loss = 6.7933  \n",
      "\n",
      "Fold: 10  Epoch: 162  Training loss = 4.0992  Validation loss = 6.7930  \n",
      "\n",
      "Fold: 10  Epoch: 163  Training loss = 4.0989  Validation loss = 6.7927  \n",
      "\n",
      "Fold: 10  Epoch: 164  Training loss = 4.0987  Validation loss = 6.7923  \n",
      "\n",
      "Fold: 10  Epoch: 165  Training loss = 4.0984  Validation loss = 6.7920  \n",
      "\n",
      "Fold: 10  Epoch: 166  Training loss = 4.0983  Validation loss = 6.7918  \n",
      "\n",
      "Fold: 10  Epoch: 167  Training loss = 4.0980  Validation loss = 6.7915  \n",
      "\n",
      "Fold: 10  Epoch: 168  Training loss = 4.0977  Validation loss = 6.7912  \n",
      "\n",
      "Fold: 10  Epoch: 169  Training loss = 4.0975  Validation loss = 6.7908  \n",
      "\n",
      "Fold: 10  Epoch: 170  Training loss = 4.0972  Validation loss = 6.7904  \n",
      "\n",
      "Fold: 10  Epoch: 171  Training loss = 4.0970  Validation loss = 6.7901  \n",
      "\n",
      "Fold: 10  Epoch: 172  Training loss = 4.0967  Validation loss = 6.7897  \n",
      "\n",
      "Fold: 10  Epoch: 173  Training loss = 4.0965  Validation loss = 6.7894  \n",
      "\n",
      "Fold: 10  Epoch: 174  Training loss = 4.0963  Validation loss = 6.7891  \n",
      "\n",
      "Fold: 10  Epoch: 175  Training loss = 4.0960  Validation loss = 6.7887  \n",
      "\n",
      "Fold: 10  Epoch: 176  Training loss = 4.0958  Validation loss = 6.7884  \n",
      "\n",
      "Fold: 10  Epoch: 177  Training loss = 4.0956  Validation loss = 6.7881  \n",
      "\n",
      "Fold: 10  Epoch: 178  Training loss = 4.0954  Validation loss = 6.7878  \n",
      "\n",
      "Fold: 10  Epoch: 179  Training loss = 4.0951  Validation loss = 6.7875  \n",
      "\n",
      "Fold: 10  Epoch: 180  Training loss = 4.0948  Validation loss = 6.7871  \n",
      "\n",
      "Fold: 10  Epoch: 181  Training loss = 4.0945  Validation loss = 6.7867  \n",
      "\n",
      "Fold: 10  Epoch: 182  Training loss = 4.0942  Validation loss = 6.7862  \n",
      "\n",
      "Fold: 10  Epoch: 183  Training loss = 4.0939  Validation loss = 6.7858  \n",
      "\n",
      "Fold: 10  Epoch: 184  Training loss = 4.0935  Validation loss = 6.7853  \n",
      "\n",
      "Fold: 10  Epoch: 185  Training loss = 4.0933  Validation loss = 6.7850  \n",
      "\n",
      "Fold: 10  Epoch: 186  Training loss = 4.0930  Validation loss = 6.7846  \n",
      "\n",
      "Fold: 10  Epoch: 187  Training loss = 4.0928  Validation loss = 6.7843  \n",
      "\n",
      "Fold: 10  Epoch: 188  Training loss = 4.0925  Validation loss = 6.7839  \n",
      "\n",
      "Fold: 10  Epoch: 189  Training loss = 4.0922  Validation loss = 6.7836  \n",
      "\n",
      "Fold: 10  Epoch: 190  Training loss = 4.0921  Validation loss = 6.7833  \n",
      "\n",
      "Fold: 10  Epoch: 191  Training loss = 4.0918  Validation loss = 6.7830  \n",
      "\n",
      "Fold: 10  Epoch: 192  Training loss = 4.0915  Validation loss = 6.7827  \n",
      "\n",
      "Fold: 10  Epoch: 193  Training loss = 4.0913  Validation loss = 6.7824  \n",
      "\n",
      "Fold: 10  Epoch: 194  Training loss = 4.0910  Validation loss = 6.7819  \n",
      "\n",
      "Fold: 10  Epoch: 195  Training loss = 4.0907  Validation loss = 6.7816  \n",
      "\n",
      "Fold: 10  Epoch: 196  Training loss = 4.0905  Validation loss = 6.7813  \n",
      "\n",
      "Fold: 10  Epoch: 197  Training loss = 4.0902  Validation loss = 6.7810  \n",
      "\n",
      "Fold: 10  Epoch: 198  Training loss = 4.0901  Validation loss = 6.7808  \n",
      "\n",
      "Fold: 10  Epoch: 199  Training loss = 4.0899  Validation loss = 6.7805  \n",
      "\n",
      "Fold: 10  Epoch: 200  Training loss = 4.0896  Validation loss = 6.7801  \n",
      "\n",
      "Fold: 10  Epoch: 201  Training loss = 4.0892  Validation loss = 6.7796  \n",
      "\n",
      "Fold: 10  Epoch: 202  Training loss = 4.0890  Validation loss = 6.7793  \n",
      "\n",
      "Fold: 10  Epoch: 203  Training loss = 4.0888  Validation loss = 6.7790  \n",
      "\n",
      "Fold: 10  Epoch: 204  Training loss = 4.0885  Validation loss = 6.7787  \n",
      "\n",
      "Fold: 10  Epoch: 205  Training loss = 4.0883  Validation loss = 6.7783  \n",
      "\n",
      "Fold: 10  Epoch: 206  Training loss = 4.0880  Validation loss = 6.7780  \n",
      "\n",
      "Fold: 10  Epoch: 207  Training loss = 4.0878  Validation loss = 6.7777  \n",
      "\n",
      "Fold: 10  Epoch: 208  Training loss = 4.0875  Validation loss = 6.7774  \n",
      "\n",
      "Fold: 10  Epoch: 209  Training loss = 4.0873  Validation loss = 6.7771  \n",
      "\n",
      "Fold: 10  Epoch: 210  Training loss = 4.0871  Validation loss = 6.7767  \n",
      "\n",
      "Fold: 10  Epoch: 211  Training loss = 4.0868  Validation loss = 6.7764  \n",
      "\n",
      "Fold: 10  Epoch: 212  Training loss = 4.0865  Validation loss = 6.7759  \n",
      "\n",
      "Fold: 10  Epoch: 213  Training loss = 4.0863  Validation loss = 6.7756  \n",
      "\n",
      "Fold: 10  Epoch: 214  Training loss = 4.0860  Validation loss = 6.7753  \n",
      "\n",
      "Fold: 10  Epoch: 215  Training loss = 4.0858  Validation loss = 6.7750  \n",
      "\n",
      "Fold: 10  Epoch: 216  Training loss = 4.0855  Validation loss = 6.7747  \n",
      "\n",
      "Fold: 10  Epoch: 217  Training loss = 4.0853  Validation loss = 6.7744  \n",
      "\n",
      "Fold: 10  Epoch: 218  Training loss = 4.0850  Validation loss = 6.7740  \n",
      "\n",
      "Fold: 10  Epoch: 219  Training loss = 4.0848  Validation loss = 6.7737  \n",
      "\n",
      "Fold: 10  Epoch: 220  Training loss = 4.0846  Validation loss = 6.7734  \n",
      "\n",
      "Fold: 10  Epoch: 221  Training loss = 4.0843  Validation loss = 6.7731  \n",
      "\n",
      "Fold: 10  Epoch: 222  Training loss = 4.0841  Validation loss = 6.7728  \n",
      "\n",
      "Fold: 10  Epoch: 223  Training loss = 4.0839  Validation loss = 6.7725  \n",
      "\n",
      "Fold: 10  Epoch: 224  Training loss = 4.0837  Validation loss = 6.7722  \n",
      "\n",
      "Fold: 10  Epoch: 225  Training loss = 4.0835  Validation loss = 6.7719  \n",
      "\n",
      "Fold: 10  Epoch: 226  Training loss = 4.0832  Validation loss = 6.7715  \n",
      "\n",
      "Fold: 10  Epoch: 227  Training loss = 4.0829  Validation loss = 6.7711  \n",
      "\n",
      "Fold: 10  Epoch: 228  Training loss = 4.0827  Validation loss = 6.7708  \n",
      "\n",
      "Fold: 10  Epoch: 229  Training loss = 4.0824  Validation loss = 6.7705  \n",
      "\n",
      "Fold: 10  Epoch: 230  Training loss = 4.0820  Validation loss = 6.7700  \n",
      "\n",
      "Fold: 10  Epoch: 231  Training loss = 4.0817  Validation loss = 6.7696  \n",
      "\n",
      "Fold: 10  Epoch: 232  Training loss = 4.0815  Validation loss = 6.7692  \n",
      "\n",
      "Fold: 10  Epoch: 233  Training loss = 4.0812  Validation loss = 6.7689  \n",
      "\n",
      "Fold: 10  Epoch: 234  Training loss = 4.0811  Validation loss = 6.7686  \n",
      "\n",
      "Fold: 10  Epoch: 235  Training loss = 4.0809  Validation loss = 6.7684  \n",
      "\n",
      "Fold: 10  Epoch: 236  Training loss = 4.0806  Validation loss = 6.7681  \n",
      "\n",
      "Fold: 10  Epoch: 237  Training loss = 4.0804  Validation loss = 6.7678  \n",
      "\n",
      "Fold: 10  Epoch: 238  Training loss = 4.0801  Validation loss = 6.7674  \n",
      "\n",
      "Fold: 10  Epoch: 239  Training loss = 4.0799  Validation loss = 6.7671  \n",
      "\n",
      "Fold: 10  Epoch: 240  Training loss = 4.0797  Validation loss = 6.7668  \n",
      "\n",
      "Fold: 10  Epoch: 241  Training loss = 4.0795  Validation loss = 6.7666  \n",
      "\n",
      "Fold: 10  Epoch: 242  Training loss = 4.0792  Validation loss = 6.7662  \n",
      "\n",
      "Fold: 10  Epoch: 243  Training loss = 4.0789  Validation loss = 6.7659  \n",
      "\n",
      "Fold: 10  Epoch: 244  Training loss = 4.0786  Validation loss = 6.7655  \n",
      "\n",
      "Fold: 10  Epoch: 245  Training loss = 4.0783  Validation loss = 6.7651  \n",
      "\n",
      "Fold: 10  Epoch: 246  Training loss = 4.0780  Validation loss = 6.7647  \n",
      "\n",
      "Fold: 10  Epoch: 247  Training loss = 4.0778  Validation loss = 6.7644  \n",
      "\n",
      "Fold: 10  Epoch: 248  Training loss = 4.0776  Validation loss = 6.7640  \n",
      "\n",
      "Fold: 10  Epoch: 249  Training loss = 4.0772  Validation loss = 6.7636  \n",
      "\n",
      "Fold: 10  Epoch: 250  Training loss = 4.0770  Validation loss = 6.7632  \n",
      "\n",
      "Fold: 10  Epoch: 251  Training loss = 4.0768  Validation loss = 6.7630  \n",
      "\n",
      "Fold: 10  Epoch: 252  Training loss = 4.0766  Validation loss = 6.7627  \n",
      "\n",
      "Fold: 10  Epoch: 253  Training loss = 4.0764  Validation loss = 6.7625  \n",
      "\n",
      "Fold: 10  Epoch: 254  Training loss = 4.0761  Validation loss = 6.7621  \n",
      "\n",
      "Fold: 10  Epoch: 255  Training loss = 4.0759  Validation loss = 6.7618  \n",
      "\n",
      "Fold: 10  Epoch: 256  Training loss = 4.0756  Validation loss = 6.7615  \n",
      "\n",
      "Fold: 10  Epoch: 257  Training loss = 4.0753  Validation loss = 6.7611  \n",
      "\n",
      "Fold: 10  Epoch: 258  Training loss = 4.0750  Validation loss = 6.7607  \n",
      "\n",
      "Fold: 10  Epoch: 259  Training loss = 4.0747  Validation loss = 6.7602  \n",
      "\n",
      "Fold: 10  Epoch: 260  Training loss = 4.0745  Validation loss = 6.7600  \n",
      "\n",
      "Fold: 10  Epoch: 261  Training loss = 4.0742  Validation loss = 6.7597  \n",
      "\n",
      "Fold: 10  Epoch: 262  Training loss = 4.0739  Validation loss = 6.7593  \n",
      "\n",
      "Fold: 10  Epoch: 263  Training loss = 4.0737  Validation loss = 6.7590  \n",
      "\n",
      "Fold: 10  Epoch: 264  Training loss = 4.0734  Validation loss = 6.7586  \n",
      "\n",
      "Fold: 10  Epoch: 265  Training loss = 4.0731  Validation loss = 6.7582  \n",
      "\n",
      "Fold: 10  Epoch: 266  Training loss = 4.0728  Validation loss = 6.7579  \n",
      "\n",
      "Fold: 10  Epoch: 267  Training loss = 4.0726  Validation loss = 6.7576  \n",
      "\n",
      "Fold: 10  Epoch: 268  Training loss = 4.0723  Validation loss = 6.7573  \n",
      "\n",
      "Fold: 10  Epoch: 269  Training loss = 4.0721  Validation loss = 6.7570  \n",
      "\n",
      "Fold: 10  Epoch: 270  Training loss = 4.0719  Validation loss = 6.7566  \n",
      "\n",
      "Fold: 10  Epoch: 271  Training loss = 4.0716  Validation loss = 6.7562  \n",
      "\n",
      "Fold: 10  Epoch: 272  Training loss = 4.0713  Validation loss = 6.7559  \n",
      "\n",
      "Fold: 10  Epoch: 273  Training loss = 4.0711  Validation loss = 6.7556  \n",
      "\n",
      "Fold: 10  Epoch: 274  Training loss = 4.0707  Validation loss = 6.7552  \n",
      "\n",
      "Fold: 10  Epoch: 275  Training loss = 4.0704  Validation loss = 6.7548  \n",
      "\n",
      "Fold: 10  Epoch: 276  Training loss = 4.0702  Validation loss = 6.7545  \n",
      "\n",
      "Fold: 10  Epoch: 277  Training loss = 4.0700  Validation loss = 6.7542  \n",
      "\n",
      "Fold: 10  Epoch: 278  Training loss = 4.0698  Validation loss = 6.7539  \n",
      "\n",
      "Fold: 10  Epoch: 279  Training loss = 4.0695  Validation loss = 6.7536  \n",
      "\n",
      "Fold: 10  Epoch: 280  Training loss = 4.0692  Validation loss = 6.7531  \n",
      "\n",
      "Fold: 10  Epoch: 281  Training loss = 4.0689  Validation loss = 6.7527  \n",
      "\n",
      "Fold: 10  Epoch: 282  Training loss = 4.0687  Validation loss = 6.7525  \n",
      "\n",
      "Fold: 10  Epoch: 283  Training loss = 4.0684  Validation loss = 6.7521  \n",
      "\n",
      "Fold: 10  Epoch: 284  Training loss = 4.0683  Validation loss = 6.7519  \n",
      "\n",
      "Fold: 10  Epoch: 285  Training loss = 4.0680  Validation loss = 6.7515  \n",
      "\n",
      "Fold: 10  Epoch: 286  Training loss = 4.0677  Validation loss = 6.7512  \n",
      "\n",
      "Fold: 10  Epoch: 287  Training loss = 4.0675  Validation loss = 6.7509  \n",
      "\n",
      "Fold: 10  Epoch: 288  Training loss = 4.0673  Validation loss = 6.7506  \n",
      "\n",
      "Fold: 10  Epoch: 289  Training loss = 4.0670  Validation loss = 6.7502  \n",
      "\n",
      "Fold: 10  Epoch: 290  Training loss = 4.0668  Validation loss = 6.7499  \n",
      "\n",
      "Fold: 10  Epoch: 291  Training loss = 4.0666  Validation loss = 6.7496  \n",
      "\n",
      "Fold: 10  Epoch: 292  Training loss = 4.0663  Validation loss = 6.7493  \n",
      "\n",
      "Fold: 10  Epoch: 293  Training loss = 4.0660  Validation loss = 6.7489  \n",
      "\n",
      "Fold: 10  Epoch: 294  Training loss = 4.0657  Validation loss = 6.7486  \n",
      "\n",
      "Fold: 10  Epoch: 295  Training loss = 4.0655  Validation loss = 6.7483  \n",
      "\n",
      "Fold: 10  Epoch: 296  Training loss = 4.0653  Validation loss = 6.7480  \n",
      "\n",
      "Fold: 10  Epoch: 297  Training loss = 4.0651  Validation loss = 6.7477  \n",
      "\n",
      "Fold: 10  Epoch: 298  Training loss = 4.0649  Validation loss = 6.7475  \n",
      "\n",
      "Fold: 10  Epoch: 299  Training loss = 4.0646  Validation loss = 6.7471  \n",
      "\n",
      "Fold: 10  Epoch: 300  Training loss = 4.0643  Validation loss = 6.7467  \n",
      "\n",
      "Fold: 10  Epoch: 301  Training loss = 4.0641  Validation loss = 6.7463  \n",
      "\n",
      "Fold: 10  Epoch: 302  Training loss = 4.0639  Validation loss = 6.7461  \n",
      "\n",
      "Fold: 10  Epoch: 303  Training loss = 4.0635  Validation loss = 6.7457  \n",
      "\n",
      "Fold: 10  Epoch: 304  Training loss = 4.0632  Validation loss = 6.7453  \n",
      "\n",
      "Fold: 10  Epoch: 305  Training loss = 4.0630  Validation loss = 6.7450  \n",
      "\n",
      "Fold: 10  Epoch: 306  Training loss = 4.0627  Validation loss = 6.7446  \n",
      "\n",
      "Fold: 10  Epoch: 307  Training loss = 4.0625  Validation loss = 6.7444  \n",
      "\n",
      "Fold: 10  Epoch: 308  Training loss = 4.0623  Validation loss = 6.7441  \n",
      "\n",
      "Fold: 10  Epoch: 309  Training loss = 4.0620  Validation loss = 6.7437  \n",
      "\n",
      "Fold: 10  Epoch: 310  Training loss = 4.0618  Validation loss = 6.7434  \n",
      "\n",
      "Fold: 10  Epoch: 311  Training loss = 4.0616  Validation loss = 6.7431  \n",
      "\n",
      "Fold: 10  Epoch: 312  Training loss = 4.0613  Validation loss = 6.7428  \n",
      "\n",
      "Fold: 10  Epoch: 313  Training loss = 4.0610  Validation loss = 6.7424  \n",
      "\n",
      "Fold: 10  Epoch: 314  Training loss = 4.0608  Validation loss = 6.7421  \n",
      "\n",
      "Fold: 10  Epoch: 315  Training loss = 4.0605  Validation loss = 6.7417  \n",
      "\n",
      "Fold: 10  Epoch: 316  Training loss = 4.0603  Validation loss = 6.7414  \n",
      "\n",
      "Fold: 10  Epoch: 317  Training loss = 4.0600  Validation loss = 6.7410  \n",
      "\n",
      "Fold: 10  Epoch: 318  Training loss = 4.0597  Validation loss = 6.7407  \n",
      "\n",
      "Fold: 10  Epoch: 319  Training loss = 4.0596  Validation loss = 6.7404  \n",
      "\n",
      "Fold: 10  Epoch: 320  Training loss = 4.0593  Validation loss = 6.7401  \n",
      "\n",
      "Fold: 10  Epoch: 321  Training loss = 4.0590  Validation loss = 6.7398  \n",
      "\n",
      "Fold: 10  Epoch: 322  Training loss = 4.0588  Validation loss = 6.7395  \n",
      "\n",
      "Fold: 10  Epoch: 323  Training loss = 4.0586  Validation loss = 6.7392  \n",
      "\n",
      "Fold: 10  Epoch: 324  Training loss = 4.0583  Validation loss = 6.7388  \n",
      "\n",
      "Fold: 10  Epoch: 325  Training loss = 4.0580  Validation loss = 6.7384  \n",
      "\n",
      "Fold: 10  Epoch: 326  Training loss = 4.0577  Validation loss = 6.7381  \n",
      "\n",
      "Fold: 10  Epoch: 327  Training loss = 4.0574  Validation loss = 6.7377  \n",
      "\n",
      "Fold: 10  Epoch: 328  Training loss = 4.0572  Validation loss = 6.7374  \n",
      "\n",
      "Fold: 10  Epoch: 329  Training loss = 4.0570  Validation loss = 6.7371  \n",
      "\n",
      "Fold: 10  Epoch: 330  Training loss = 4.0567  Validation loss = 6.7368  \n",
      "\n",
      "Fold: 10  Epoch: 331  Training loss = 4.0565  Validation loss = 6.7365  \n",
      "\n",
      "Fold: 10  Epoch: 332  Training loss = 4.0563  Validation loss = 6.7362  \n",
      "\n",
      "Fold: 10  Epoch: 333  Training loss = 4.0560  Validation loss = 6.7359  \n",
      "\n",
      "Fold: 10  Epoch: 334  Training loss = 4.0558  Validation loss = 6.7356  \n",
      "\n",
      "Fold: 10  Epoch: 335  Training loss = 4.0556  Validation loss = 6.7353  \n",
      "\n",
      "Fold: 10  Epoch: 336  Training loss = 4.0553  Validation loss = 6.7349  \n",
      "\n",
      "Fold: 10  Epoch: 337  Training loss = 4.0550  Validation loss = 6.7345  \n",
      "\n",
      "Fold: 10  Epoch: 338  Training loss = 4.0547  Validation loss = 6.7340  \n",
      "\n",
      "Fold: 10  Epoch: 339  Training loss = 4.0544  Validation loss = 6.7337  \n",
      "\n",
      "Fold: 10  Epoch: 340  Training loss = 4.0541  Validation loss = 6.7333  \n",
      "\n",
      "Fold: 10  Epoch: 341  Training loss = 4.0539  Validation loss = 6.7330  \n",
      "\n",
      "Fold: 10  Epoch: 342  Training loss = 4.0536  Validation loss = 6.7327  \n",
      "\n",
      "Fold: 10  Epoch: 343  Training loss = 4.0534  Validation loss = 6.7324  \n",
      "\n",
      "Fold: 10  Epoch: 344  Training loss = 4.0532  Validation loss = 6.7321  \n",
      "\n",
      "Fold: 10  Epoch: 345  Training loss = 4.0529  Validation loss = 6.7318  \n",
      "\n",
      "Fold: 10  Epoch: 346  Training loss = 4.0526  Validation loss = 6.7313  \n",
      "\n",
      "Fold: 10  Epoch: 347  Training loss = 4.0523  Validation loss = 6.7310  \n",
      "\n",
      "Fold: 10  Epoch: 348  Training loss = 4.0521  Validation loss = 6.7307  \n",
      "\n",
      "Fold: 10  Epoch: 349  Training loss = 4.0518  Validation loss = 6.7303  \n",
      "\n",
      "Fold: 10  Epoch: 350  Training loss = 4.0516  Validation loss = 6.7300  \n",
      "\n",
      "Fold: 10  Epoch: 351  Training loss = 4.0513  Validation loss = 6.7297  \n",
      "\n",
      "Fold: 10  Epoch: 352  Training loss = 4.0510  Validation loss = 6.7294  \n",
      "\n",
      "Fold: 10  Epoch: 353  Training loss = 4.0508  Validation loss = 6.7290  \n",
      "\n",
      "Fold: 10  Epoch: 354  Training loss = 4.0505  Validation loss = 6.7288  \n",
      "\n",
      "Fold: 10  Epoch: 355  Training loss = 4.0503  Validation loss = 6.7284  \n",
      "\n",
      "Fold: 10  Epoch: 356  Training loss = 4.0501  Validation loss = 6.7281  \n",
      "\n",
      "Fold: 10  Epoch: 357  Training loss = 4.0499  Validation loss = 6.7279  \n",
      "\n",
      "Fold: 10  Epoch: 358  Training loss = 4.0496  Validation loss = 6.7275  \n",
      "\n",
      "Fold: 10  Epoch: 359  Training loss = 4.0494  Validation loss = 6.7272  \n",
      "\n",
      "Fold: 10  Epoch: 360  Training loss = 4.0491  Validation loss = 6.7268  \n",
      "\n",
      "Fold: 10  Epoch: 361  Training loss = 4.0489  Validation loss = 6.7265  \n",
      "\n",
      "Fold: 10  Epoch: 362  Training loss = 4.0486  Validation loss = 6.7262  \n",
      "\n",
      "Fold: 10  Epoch: 363  Training loss = 4.0484  Validation loss = 6.7259  \n",
      "\n",
      "Fold: 10  Epoch: 364  Training loss = 4.0482  Validation loss = 6.7256  \n",
      "\n",
      "Fold: 10  Epoch: 365  Training loss = 4.0478  Validation loss = 6.7252  \n",
      "\n",
      "Fold: 10  Epoch: 366  Training loss = 4.0476  Validation loss = 6.7248  \n",
      "\n",
      "Fold: 10  Epoch: 367  Training loss = 4.0473  Validation loss = 6.7245  \n",
      "\n",
      "Fold: 10  Epoch: 368  Training loss = 4.0471  Validation loss = 6.7242  \n",
      "\n",
      "Fold: 10  Epoch: 369  Training loss = 4.0468  Validation loss = 6.7239  \n",
      "\n",
      "Fold: 10  Epoch: 370  Training loss = 4.0466  Validation loss = 6.7235  \n",
      "\n",
      "Fold: 10  Epoch: 371  Training loss = 4.0463  Validation loss = 6.7232  \n",
      "\n",
      "Fold: 10  Epoch: 372  Training loss = 4.0461  Validation loss = 6.7229  \n",
      "\n",
      "Fold: 10  Epoch: 373  Training loss = 4.0458  Validation loss = 6.7225  \n",
      "\n",
      "Fold: 10  Epoch: 374  Training loss = 4.0455  Validation loss = 6.7222  \n",
      "\n",
      "Fold: 10  Epoch: 375  Training loss = 4.0453  Validation loss = 6.7219  \n",
      "\n",
      "Fold: 10  Epoch: 376  Training loss = 4.0451  Validation loss = 6.7217  \n",
      "\n",
      "Fold: 10  Epoch: 377  Training loss = 4.0449  Validation loss = 6.7214  \n",
      "\n",
      "Fold: 10  Epoch: 378  Training loss = 4.0446  Validation loss = 6.7210  \n",
      "\n",
      "Fold: 10  Epoch: 379  Training loss = 4.0444  Validation loss = 6.7207  \n",
      "\n",
      "Fold: 10  Epoch: 380  Training loss = 4.0442  Validation loss = 6.7204  \n",
      "\n",
      "Fold: 10  Epoch: 381  Training loss = 4.0439  Validation loss = 6.7201  \n",
      "\n",
      "Fold: 10  Epoch: 382  Training loss = 4.0437  Validation loss = 6.7197  \n",
      "\n",
      "Fold: 10  Epoch: 383  Training loss = 4.0434  Validation loss = 6.7194  \n",
      "\n",
      "Fold: 10  Epoch: 384  Training loss = 4.0432  Validation loss = 6.7191  \n",
      "\n",
      "Fold: 10  Epoch: 385  Training loss = 4.0429  Validation loss = 6.7187  \n",
      "\n",
      "Fold: 10  Epoch: 386  Training loss = 4.0427  Validation loss = 6.7184  \n",
      "\n",
      "Fold: 10  Epoch: 387  Training loss = 4.0424  Validation loss = 6.7181  \n",
      "\n",
      "Fold: 10  Epoch: 388  Training loss = 4.0422  Validation loss = 6.7179  \n",
      "\n",
      "Fold: 10  Epoch: 389  Training loss = 4.0420  Validation loss = 6.7176  \n",
      "\n",
      "Fold: 10  Epoch: 390  Training loss = 4.0417  Validation loss = 6.7172  \n",
      "\n",
      "Fold: 10  Epoch: 391  Training loss = 4.0414  Validation loss = 6.7169  \n",
      "\n",
      "Fold: 10  Epoch: 392  Training loss = 4.0412  Validation loss = 6.7166  \n",
      "\n",
      "Fold: 10  Epoch: 393  Training loss = 4.0409  Validation loss = 6.7162  \n",
      "\n",
      "Fold: 10  Epoch: 394  Training loss = 4.0407  Validation loss = 6.7160  \n",
      "\n",
      "Fold: 10  Epoch: 395  Training loss = 4.0405  Validation loss = 6.7157  \n",
      "\n",
      "Fold: 10  Epoch: 396  Training loss = 4.0403  Validation loss = 6.7153  \n",
      "\n",
      "Fold: 10  Epoch: 397  Training loss = 4.0400  Validation loss = 6.7150  \n",
      "\n",
      "Fold: 10  Epoch: 398  Training loss = 4.0398  Validation loss = 6.7147  \n",
      "\n",
      "Fold: 10  Epoch: 399  Training loss = 4.0396  Validation loss = 6.7144  \n",
      "\n",
      "Fold: 10  Epoch: 400  Training loss = 4.0393  Validation loss = 6.7141  \n",
      "\n",
      "Fold: 10  Epoch: 401  Training loss = 4.0391  Validation loss = 6.7138  \n",
      "\n",
      "Fold: 10  Epoch: 402  Training loss = 4.0389  Validation loss = 6.7136  \n",
      "\n",
      "Fold: 10  Epoch: 403  Training loss = 4.0387  Validation loss = 6.7133  \n",
      "\n",
      "Fold: 10  Epoch: 404  Training loss = 4.0385  Validation loss = 6.7130  \n",
      "\n",
      "Fold: 10  Epoch: 405  Training loss = 4.0383  Validation loss = 6.7128  \n",
      "\n",
      "Fold: 10  Epoch: 406  Training loss = 4.0380  Validation loss = 6.7124  \n",
      "\n",
      "Fold: 10  Epoch: 407  Training loss = 4.0378  Validation loss = 6.7121  \n",
      "\n",
      "Fold: 10  Epoch: 408  Training loss = 4.0376  Validation loss = 6.7118  \n",
      "\n",
      "Fold: 10  Epoch: 409  Training loss = 4.0373  Validation loss = 6.7115  \n",
      "\n",
      "Fold: 10  Epoch: 410  Training loss = 4.0371  Validation loss = 6.7113  \n",
      "\n",
      "Fold: 10  Epoch: 411  Training loss = 4.0368  Validation loss = 6.7109  \n",
      "\n",
      "Fold: 10  Epoch: 412  Training loss = 4.0367  Validation loss = 6.7107  \n",
      "\n",
      "Fold: 10  Epoch: 413  Training loss = 4.0364  Validation loss = 6.7104  \n",
      "\n",
      "Fold: 10  Epoch: 414  Training loss = 4.0362  Validation loss = 6.7101  \n",
      "\n",
      "Fold: 10  Epoch: 415  Training loss = 4.0360  Validation loss = 6.7099  \n",
      "\n",
      "Fold: 10  Epoch: 416  Training loss = 4.0358  Validation loss = 6.7096  \n",
      "\n",
      "Fold: 10  Epoch: 417  Training loss = 4.0355  Validation loss = 6.7092  \n",
      "\n",
      "Fold: 10  Epoch: 418  Training loss = 4.0353  Validation loss = 6.7089  \n",
      "\n",
      "Fold: 10  Epoch: 419  Training loss = 4.0350  Validation loss = 6.7086  \n",
      "\n",
      "Fold: 10  Epoch: 420  Training loss = 4.0348  Validation loss = 6.7083  \n",
      "\n",
      "Fold: 10  Epoch: 421  Training loss = 4.0346  Validation loss = 6.7080  \n",
      "\n",
      "Fold: 10  Epoch: 422  Training loss = 4.0343  Validation loss = 6.7076  \n",
      "\n",
      "Fold: 10  Epoch: 423  Training loss = 4.0341  Validation loss = 6.7073  \n",
      "\n",
      "Fold: 10  Epoch: 424  Training loss = 4.0339  Validation loss = 6.7070  \n",
      "\n",
      "Fold: 10  Epoch: 425  Training loss = 4.0336  Validation loss = 6.7067  \n",
      "\n",
      "Fold: 10  Epoch: 426  Training loss = 4.0334  Validation loss = 6.7064  \n",
      "\n",
      "Fold: 10  Epoch: 427  Training loss = 4.0331  Validation loss = 6.7060  \n",
      "\n",
      "Fold: 10  Epoch: 428  Training loss = 4.0329  Validation loss = 6.7058  \n",
      "\n",
      "Fold: 10  Epoch: 429  Training loss = 4.0327  Validation loss = 6.7055  \n",
      "\n",
      "Fold: 10  Epoch: 430  Training loss = 4.0325  Validation loss = 6.7053  \n",
      "\n",
      "Fold: 10  Epoch: 431  Training loss = 4.0323  Validation loss = 6.7050  \n",
      "\n",
      "Fold: 10  Epoch: 432  Training loss = 4.0321  Validation loss = 6.7047  \n",
      "\n",
      "Fold: 10  Epoch: 433  Training loss = 4.0318  Validation loss = 6.7043  \n",
      "\n",
      "Fold: 10  Epoch: 434  Training loss = 4.0316  Validation loss = 6.7041  \n",
      "\n",
      "Fold: 10  Epoch: 435  Training loss = 4.0314  Validation loss = 6.7038  \n",
      "\n",
      "Fold: 10  Epoch: 436  Training loss = 4.0311  Validation loss = 6.7034  \n",
      "\n",
      "Fold: 10  Epoch: 437  Training loss = 4.0309  Validation loss = 6.7032  \n",
      "\n",
      "Fold: 10  Epoch: 438  Training loss = 4.0306  Validation loss = 6.7028  \n",
      "\n",
      "Fold: 10  Epoch: 439  Training loss = 4.0304  Validation loss = 6.7026  \n",
      "\n",
      "Fold: 10  Epoch: 440  Training loss = 4.0301  Validation loss = 6.7022  \n",
      "\n",
      "Fold: 10  Epoch: 441  Training loss = 4.0299  Validation loss = 6.7019  \n",
      "\n",
      "Fold: 10  Epoch: 442  Training loss = 4.0297  Validation loss = 6.7016  \n",
      "\n",
      "Fold: 10  Epoch: 443  Training loss = 4.0295  Validation loss = 6.7014  \n",
      "\n",
      "Fold: 10  Epoch: 444  Training loss = 4.0292  Validation loss = 6.7011  \n",
      "\n",
      "Fold: 10  Epoch: 445  Training loss = 4.0290  Validation loss = 6.7008  \n",
      "\n",
      "Fold: 10  Epoch: 446  Training loss = 4.0287  Validation loss = 6.7004  \n",
      "\n",
      "Fold: 10  Epoch: 447  Training loss = 4.0285  Validation loss = 6.7001  \n",
      "\n",
      "Fold: 10  Epoch: 448  Training loss = 4.0282  Validation loss = 6.6998  \n",
      "\n",
      "Fold: 10  Epoch: 449  Training loss = 4.0280  Validation loss = 6.6995  \n",
      "\n",
      "Fold: 10  Epoch: 450  Training loss = 4.0278  Validation loss = 6.6993  \n",
      "\n",
      "Fold: 10  Epoch: 451  Training loss = 4.0275  Validation loss = 6.6989  \n",
      "\n",
      "Fold: 10  Epoch: 452  Training loss = 4.0273  Validation loss = 6.6986  \n",
      "\n",
      "Fold: 10  Epoch: 453  Training loss = 4.0271  Validation loss = 6.6982  \n",
      "\n",
      "Fold: 10  Epoch: 454  Training loss = 4.0268  Validation loss = 6.6979  \n",
      "\n",
      "Fold: 10  Epoch: 455  Training loss = 4.0265  Validation loss = 6.6975  \n",
      "\n",
      "Fold: 10  Epoch: 456  Training loss = 4.0263  Validation loss = 6.6971  \n",
      "\n",
      "Fold: 10  Epoch: 457  Training loss = 4.0260  Validation loss = 6.6968  \n",
      "\n",
      "Fold: 10  Epoch: 458  Training loss = 4.0258  Validation loss = 6.6965  \n",
      "\n",
      "Fold: 10  Epoch: 459  Training loss = 4.0256  Validation loss = 6.6962  \n",
      "\n",
      "Fold: 10  Epoch: 460  Training loss = 4.0253  Validation loss = 6.6959  \n",
      "\n",
      "Fold: 10  Epoch: 461  Training loss = 4.0251  Validation loss = 6.6957  \n",
      "\n",
      "Fold: 10  Epoch: 462  Training loss = 4.0249  Validation loss = 6.6954  \n",
      "\n",
      "Fold: 10  Epoch: 463  Training loss = 4.0247  Validation loss = 6.6951  \n",
      "\n",
      "Fold: 10  Epoch: 464  Training loss = 4.0244  Validation loss = 6.6948  \n",
      "\n",
      "Fold: 10  Epoch: 465  Training loss = 4.0243  Validation loss = 6.6946  \n",
      "\n",
      "Fold: 10  Epoch: 466  Training loss = 4.0240  Validation loss = 6.6943  \n",
      "\n",
      "Fold: 10  Epoch: 467  Training loss = 4.0238  Validation loss = 6.6940  \n",
      "\n",
      "Fold: 10  Epoch: 468  Training loss = 4.0236  Validation loss = 6.6936  \n",
      "\n",
      "Fold: 10  Epoch: 469  Training loss = 4.0233  Validation loss = 6.6933  \n",
      "\n",
      "Fold: 10  Epoch: 470  Training loss = 4.0230  Validation loss = 6.6930  \n",
      "\n",
      "Fold: 10  Epoch: 471  Training loss = 4.0228  Validation loss = 6.6926  \n",
      "\n",
      "Fold: 10  Epoch: 472  Training loss = 4.0226  Validation loss = 6.6924  \n",
      "\n",
      "Fold: 10  Epoch: 473  Training loss = 4.0223  Validation loss = 6.6920  \n",
      "\n",
      "Fold: 10  Epoch: 474  Training loss = 4.0221  Validation loss = 6.6917  \n",
      "\n",
      "Fold: 10  Epoch: 475  Training loss = 4.0219  Validation loss = 6.6914  \n",
      "\n",
      "Fold: 10  Epoch: 476  Training loss = 4.0216  Validation loss = 6.6911  \n",
      "\n",
      "Fold: 10  Epoch: 477  Training loss = 4.0214  Validation loss = 6.6909  \n",
      "\n",
      "Fold: 10  Epoch: 478  Training loss = 4.0212  Validation loss = 6.6906  \n",
      "\n",
      "Fold: 10  Epoch: 479  Training loss = 4.0209  Validation loss = 6.6903  \n",
      "\n",
      "Fold: 10  Epoch: 480  Training loss = 4.0207  Validation loss = 6.6900  \n",
      "\n",
      "Fold: 10  Epoch: 481  Training loss = 4.0204  Validation loss = 6.6896  \n",
      "\n",
      "Fold: 10  Epoch: 482  Training loss = 4.0202  Validation loss = 6.6892  \n",
      "\n",
      "Fold: 10  Epoch: 483  Training loss = 4.0199  Validation loss = 6.6890  \n",
      "\n",
      "Fold: 10  Epoch: 484  Training loss = 4.0197  Validation loss = 6.6887  \n",
      "\n",
      "Fold: 10  Epoch: 485  Training loss = 4.0195  Validation loss = 6.6884  \n",
      "\n",
      "Fold: 10  Epoch: 486  Training loss = 4.0192  Validation loss = 6.6880  \n",
      "\n",
      "Fold: 10  Epoch: 487  Training loss = 4.0190  Validation loss = 6.6877  \n",
      "\n",
      "Fold: 10  Epoch: 488  Training loss = 4.0187  Validation loss = 6.6874  \n",
      "\n",
      "Fold: 10  Epoch: 489  Training loss = 4.0185  Validation loss = 6.6871  \n",
      "\n",
      "Fold: 10  Epoch: 490  Training loss = 4.0183  Validation loss = 6.6869  \n",
      "\n",
      "Fold: 10  Epoch: 491  Training loss = 4.0180  Validation loss = 6.6865  \n",
      "\n",
      "Fold: 10  Epoch: 492  Training loss = 4.0178  Validation loss = 6.6862  \n",
      "\n",
      "Fold: 10  Epoch: 493  Training loss = 4.0175  Validation loss = 6.6858  \n",
      "\n",
      "Fold: 10  Epoch: 494  Training loss = 4.0172  Validation loss = 6.6855  \n",
      "\n",
      "Fold: 10  Epoch: 495  Training loss = 4.0170  Validation loss = 6.6851  \n",
      "\n",
      "Fold: 10  Epoch: 496  Training loss = 4.0167  Validation loss = 6.6848  \n",
      "\n",
      "Fold: 10  Epoch: 497  Training loss = 4.0165  Validation loss = 6.6845  \n",
      "\n",
      "Fold: 10  Epoch: 498  Training loss = 4.0163  Validation loss = 6.6843  \n",
      "\n",
      "Fold: 10  Epoch: 499  Training loss = 4.0161  Validation loss = 6.6839  \n",
      "\n",
      "Fold: 10  Epoch: 500  Training loss = 4.0158  Validation loss = 6.6836  \n",
      "\n",
      "Check model:  Fold: 10  Optimal epoch: 500  \n",
      "\n",
      "Fold: 11  Epoch: 1  Training loss = 4.3380  Validation loss = 4.3264  \n",
      "\n",
      "Fold: 11  Epoch: 2  Training loss = 4.3378  Validation loss = 4.3261  \n",
      "\n",
      "Fold: 11  Epoch: 3  Training loss = 4.3375  Validation loss = 4.3256  \n",
      "\n",
      "Fold: 11  Epoch: 4  Training loss = 4.3372  Validation loss = 4.3251  \n",
      "\n",
      "Fold: 11  Epoch: 5  Training loss = 4.3369  Validation loss = 4.3246  \n",
      "\n",
      "Fold: 11  Epoch: 6  Training loss = 4.3366  Validation loss = 4.3241  \n",
      "\n",
      "Fold: 11  Epoch: 7  Training loss = 4.3363  Validation loss = 4.3237  \n",
      "\n",
      "Fold: 11  Epoch: 8  Training loss = 4.3360  Validation loss = 4.3231  \n",
      "\n",
      "Fold: 11  Epoch: 9  Training loss = 4.3356  Validation loss = 4.3226  \n",
      "\n",
      "Fold: 11  Epoch: 10  Training loss = 4.3354  Validation loss = 4.3221  \n",
      "\n",
      "Fold: 11  Epoch: 11  Training loss = 4.3350  Validation loss = 4.3216  \n",
      "\n",
      "Fold: 11  Epoch: 12  Training loss = 4.3348  Validation loss = 4.3212  \n",
      "\n",
      "Fold: 11  Epoch: 13  Training loss = 4.3344  Validation loss = 4.3207  \n",
      "\n",
      "Fold: 11  Epoch: 14  Training loss = 4.3341  Validation loss = 4.3202  \n",
      "\n",
      "Fold: 11  Epoch: 15  Training loss = 4.3339  Validation loss = 4.3198  \n",
      "\n",
      "Fold: 11  Epoch: 16  Training loss = 4.3336  Validation loss = 4.3194  \n",
      "\n",
      "Fold: 11  Epoch: 17  Training loss = 4.3333  Validation loss = 4.3189  \n",
      "\n",
      "Fold: 11  Epoch: 18  Training loss = 4.3330  Validation loss = 4.3185  \n",
      "\n",
      "Fold: 11  Epoch: 19  Training loss = 4.3328  Validation loss = 4.3181  \n",
      "\n",
      "Fold: 11  Epoch: 20  Training loss = 4.3325  Validation loss = 4.3176  \n",
      "\n",
      "Fold: 11  Epoch: 21  Training loss = 4.3322  Validation loss = 4.3172  \n",
      "\n",
      "Fold: 11  Epoch: 22  Training loss = 4.3319  Validation loss = 4.3167  \n",
      "\n",
      "Fold: 11  Epoch: 23  Training loss = 4.3316  Validation loss = 4.3161  \n",
      "\n",
      "Fold: 11  Epoch: 24  Training loss = 4.3313  Validation loss = 4.3157  \n",
      "\n",
      "Fold: 11  Epoch: 25  Training loss = 4.3310  Validation loss = 4.3152  \n",
      "\n",
      "Fold: 11  Epoch: 26  Training loss = 4.3307  Validation loss = 4.3148  \n",
      "\n",
      "Fold: 11  Epoch: 27  Training loss = 4.3304  Validation loss = 4.3143  \n",
      "\n",
      "Fold: 11  Epoch: 28  Training loss = 4.3301  Validation loss = 4.3138  \n",
      "\n",
      "Fold: 11  Epoch: 29  Training loss = 4.3298  Validation loss = 4.3132  \n",
      "\n",
      "Fold: 11  Epoch: 30  Training loss = 4.3295  Validation loss = 4.3128  \n",
      "\n",
      "Fold: 11  Epoch: 31  Training loss = 4.3292  Validation loss = 4.3123  \n",
      "\n",
      "Fold: 11  Epoch: 32  Training loss = 4.3290  Validation loss = 4.3119  \n",
      "\n",
      "Fold: 11  Epoch: 33  Training loss = 4.3287  Validation loss = 4.3115  \n",
      "\n",
      "Fold: 11  Epoch: 34  Training loss = 4.3284  Validation loss = 4.3110  \n",
      "\n",
      "Fold: 11  Epoch: 35  Training loss = 4.3281  Validation loss = 4.3106  \n",
      "\n",
      "Fold: 11  Epoch: 36  Training loss = 4.3278  Validation loss = 4.3101  \n",
      "\n",
      "Fold: 11  Epoch: 37  Training loss = 4.3275  Validation loss = 4.3096  \n",
      "\n",
      "Fold: 11  Epoch: 38  Training loss = 4.3272  Validation loss = 4.3091  \n",
      "\n",
      "Fold: 11  Epoch: 39  Training loss = 4.3270  Validation loss = 4.3087  \n",
      "\n",
      "Fold: 11  Epoch: 40  Training loss = 4.3267  Validation loss = 4.3081  \n",
      "\n",
      "Fold: 11  Epoch: 41  Training loss = 4.3263  Validation loss = 4.3076  \n",
      "\n",
      "Fold: 11  Epoch: 42  Training loss = 4.3261  Validation loss = 4.3072  \n",
      "\n",
      "Fold: 11  Epoch: 43  Training loss = 4.3258  Validation loss = 4.3067  \n",
      "\n",
      "Fold: 11  Epoch: 44  Training loss = 4.3256  Validation loss = 4.3063  \n",
      "\n",
      "Fold: 11  Epoch: 45  Training loss = 4.3253  Validation loss = 4.3058  \n",
      "\n",
      "Fold: 11  Epoch: 46  Training loss = 4.3250  Validation loss = 4.3053  \n",
      "\n",
      "Fold: 11  Epoch: 47  Training loss = 4.3247  Validation loss = 4.3049  \n",
      "\n",
      "Fold: 11  Epoch: 48  Training loss = 4.3245  Validation loss = 4.3045  \n",
      "\n",
      "Fold: 11  Epoch: 49  Training loss = 4.3242  Validation loss = 4.3041  \n",
      "\n",
      "Fold: 11  Epoch: 50  Training loss = 4.3240  Validation loss = 4.3037  \n",
      "\n",
      "Fold: 11  Epoch: 51  Training loss = 4.3236  Validation loss = 4.3031  \n",
      "\n",
      "Fold: 11  Epoch: 52  Training loss = 4.3233  Validation loss = 4.3026  \n",
      "\n",
      "Fold: 11  Epoch: 53  Training loss = 4.3230  Validation loss = 4.3022  \n",
      "\n",
      "Fold: 11  Epoch: 54  Training loss = 4.3227  Validation loss = 4.3016  \n",
      "\n",
      "Fold: 11  Epoch: 55  Training loss = 4.3225  Validation loss = 4.3011  \n",
      "\n",
      "Fold: 11  Epoch: 56  Training loss = 4.3222  Validation loss = 4.3007  \n",
      "\n",
      "Fold: 11  Epoch: 57  Training loss = 4.3220  Validation loss = 4.3003  \n",
      "\n",
      "Fold: 11  Epoch: 58  Training loss = 4.3217  Validation loss = 4.2999  \n",
      "\n",
      "Fold: 11  Epoch: 59  Training loss = 4.3214  Validation loss = 4.2994  \n",
      "\n",
      "Fold: 11  Epoch: 60  Training loss = 4.3211  Validation loss = 4.2989  \n",
      "\n",
      "Fold: 11  Epoch: 61  Training loss = 4.3209  Validation loss = 4.2985  \n",
      "\n",
      "Fold: 11  Epoch: 62  Training loss = 4.3205  Validation loss = 4.2978  \n",
      "\n",
      "Fold: 11  Epoch: 63  Training loss = 4.3203  Validation loss = 4.2975  \n",
      "\n",
      "Fold: 11  Epoch: 64  Training loss = 4.3200  Validation loss = 4.2970  \n",
      "\n",
      "Fold: 11  Epoch: 65  Training loss = 4.3197  Validation loss = 4.2966  \n",
      "\n",
      "Fold: 11  Epoch: 66  Training loss = 4.3194  Validation loss = 4.2962  \n",
      "\n",
      "Fold: 11  Epoch: 67  Training loss = 4.3192  Validation loss = 4.2957  \n",
      "\n",
      "Fold: 11  Epoch: 68  Training loss = 4.3189  Validation loss = 4.2953  \n",
      "\n",
      "Fold: 11  Epoch: 69  Training loss = 4.3187  Validation loss = 4.2949  \n",
      "\n",
      "Fold: 11  Epoch: 70  Training loss = 4.3184  Validation loss = 4.2944  \n",
      "\n",
      "Fold: 11  Epoch: 71  Training loss = 4.3181  Validation loss = 4.2940  \n",
      "\n",
      "Fold: 11  Epoch: 72  Training loss = 4.3179  Validation loss = 4.2936  \n",
      "\n",
      "Fold: 11  Epoch: 73  Training loss = 4.3175  Validation loss = 4.2930  \n",
      "\n",
      "Fold: 11  Epoch: 74  Training loss = 4.3173  Validation loss = 4.2926  \n",
      "\n",
      "Fold: 11  Epoch: 75  Training loss = 4.3169  Validation loss = 4.2920  \n",
      "\n",
      "Fold: 11  Epoch: 76  Training loss = 4.3167  Validation loss = 4.2916  \n",
      "\n",
      "Fold: 11  Epoch: 77  Training loss = 4.3164  Validation loss = 4.2912  \n",
      "\n",
      "Fold: 11  Epoch: 78  Training loss = 4.3162  Validation loss = 4.2908  \n",
      "\n",
      "Fold: 11  Epoch: 79  Training loss = 4.3159  Validation loss = 4.2905  \n",
      "\n",
      "Fold: 11  Epoch: 80  Training loss = 4.3157  Validation loss = 4.2900  \n",
      "\n",
      "Fold: 11  Epoch: 81  Training loss = 4.3154  Validation loss = 4.2895  \n",
      "\n",
      "Fold: 11  Epoch: 82  Training loss = 4.3151  Validation loss = 4.2890  \n",
      "\n",
      "Fold: 11  Epoch: 83  Training loss = 4.3149  Validation loss = 4.2887  \n",
      "\n",
      "Fold: 11  Epoch: 84  Training loss = 4.3147  Validation loss = 4.2883  \n",
      "\n",
      "Fold: 11  Epoch: 85  Training loss = 4.3144  Validation loss = 4.2878  \n",
      "\n",
      "Fold: 11  Epoch: 86  Training loss = 4.3141  Validation loss = 4.2875  \n",
      "\n",
      "Fold: 11  Epoch: 87  Training loss = 4.3138  Validation loss = 4.2870  \n",
      "\n",
      "Fold: 11  Epoch: 88  Training loss = 4.3135  Validation loss = 4.2866  \n",
      "\n",
      "Fold: 11  Epoch: 89  Training loss = 4.3132  Validation loss = 4.2861  \n",
      "\n",
      "Fold: 11  Epoch: 90  Training loss = 4.3128  Validation loss = 4.2856  \n",
      "\n",
      "Fold: 11  Epoch: 91  Training loss = 4.3120  Validation loss = 4.2851  \n",
      "\n",
      "Fold: 11  Epoch: 92  Training loss = 4.3109  Validation loss = 4.2847  \n",
      "\n",
      "Fold: 11  Epoch: 93  Training loss = 4.3106  Validation loss = 4.2843  \n",
      "\n",
      "Fold: 11  Epoch: 94  Training loss = 4.3102  Validation loss = 4.2839  \n",
      "\n",
      "Fold: 11  Epoch: 95  Training loss = 4.3099  Validation loss = 4.2835  \n",
      "\n",
      "Fold: 11  Epoch: 96  Training loss = 4.3096  Validation loss = 4.2831  \n",
      "\n",
      "Fold: 11  Epoch: 97  Training loss = 4.3092  Validation loss = 4.2825  \n",
      "\n",
      "Fold: 11  Epoch: 98  Training loss = 4.3089  Validation loss = 4.2820  \n",
      "\n",
      "Fold: 11  Epoch: 99  Training loss = 4.3086  Validation loss = 4.2815  \n",
      "\n",
      "Fold: 11  Epoch: 100  Training loss = 4.3083  Validation loss = 4.2810  \n",
      "\n",
      "Fold: 11  Epoch: 101  Training loss = 4.3079  Validation loss = 4.2805  \n",
      "\n",
      "Fold: 11  Epoch: 102  Training loss = 4.3077  Validation loss = 4.2800  \n",
      "\n",
      "Fold: 11  Epoch: 103  Training loss = 4.3074  Validation loss = 4.2795  \n",
      "\n",
      "Fold: 11  Epoch: 104  Training loss = 4.3071  Validation loss = 4.2790  \n",
      "\n",
      "Fold: 11  Epoch: 105  Training loss = 4.3067  Validation loss = 4.2784  \n",
      "\n",
      "Fold: 11  Epoch: 106  Training loss = 4.3064  Validation loss = 4.2779  \n",
      "\n",
      "Fold: 11  Epoch: 107  Training loss = 4.3062  Validation loss = 4.2775  \n",
      "\n",
      "Fold: 11  Epoch: 108  Training loss = 4.3059  Validation loss = 4.2769  \n",
      "\n",
      "Fold: 11  Epoch: 109  Training loss = 4.3056  Validation loss = 4.2765  \n",
      "\n",
      "Fold: 11  Epoch: 110  Training loss = 4.3053  Validation loss = 4.2760  \n",
      "\n",
      "Fold: 11  Epoch: 111  Training loss = 4.3051  Validation loss = 4.2756  \n",
      "\n",
      "Fold: 11  Epoch: 112  Training loss = 4.3048  Validation loss = 4.2751  \n",
      "\n",
      "Fold: 11  Epoch: 113  Training loss = 4.3046  Validation loss = 4.2748  \n",
      "\n",
      "Fold: 11  Epoch: 114  Training loss = 4.3043  Validation loss = 4.2743  \n",
      "\n",
      "Fold: 11  Epoch: 115  Training loss = 4.3040  Validation loss = 4.2738  \n",
      "\n",
      "Fold: 11  Epoch: 116  Training loss = 4.3037  Validation loss = 4.2733  \n",
      "\n",
      "Fold: 11  Epoch: 117  Training loss = 4.3034  Validation loss = 4.2728  \n",
      "\n",
      "Fold: 11  Epoch: 118  Training loss = 4.3032  Validation loss = 4.2724  \n",
      "\n",
      "Fold: 11  Epoch: 119  Training loss = 4.3029  Validation loss = 4.2719  \n",
      "\n",
      "Fold: 11  Epoch: 120  Training loss = 4.3027  Validation loss = 4.2715  \n",
      "\n",
      "Fold: 11  Epoch: 121  Training loss = 4.3025  Validation loss = 4.2712  \n",
      "\n",
      "Fold: 11  Epoch: 122  Training loss = 4.3023  Validation loss = 4.2708  \n",
      "\n",
      "Fold: 11  Epoch: 123  Training loss = 4.3020  Validation loss = 4.2704  \n",
      "\n",
      "Fold: 11  Epoch: 124  Training loss = 4.3018  Validation loss = 4.2700  \n",
      "\n",
      "Fold: 11  Epoch: 125  Training loss = 4.3015  Validation loss = 4.2695  \n",
      "\n",
      "Fold: 11  Epoch: 126  Training loss = 4.3012  Validation loss = 4.2690  \n",
      "\n",
      "Fold: 11  Epoch: 127  Training loss = 4.3009  Validation loss = 4.2686  \n",
      "\n",
      "Fold: 11  Epoch: 128  Training loss = 4.3006  Validation loss = 4.2681  \n",
      "\n",
      "Fold: 11  Epoch: 129  Training loss = 4.3004  Validation loss = 4.2676  \n",
      "\n",
      "Fold: 11  Epoch: 130  Training loss = 4.3001  Validation loss = 4.2671  \n",
      "\n",
      "Fold: 11  Epoch: 131  Training loss = 4.2998  Validation loss = 4.2667  \n",
      "\n",
      "Fold: 11  Epoch: 132  Training loss = 4.2996  Validation loss = 4.2663  \n",
      "\n",
      "Fold: 11  Epoch: 133  Training loss = 4.2993  Validation loss = 4.2658  \n",
      "\n",
      "Fold: 11  Epoch: 134  Training loss = 4.2990  Validation loss = 4.2652  \n",
      "\n",
      "Fold: 11  Epoch: 135  Training loss = 4.2986  Validation loss = 4.2647  \n",
      "\n",
      "Fold: 11  Epoch: 136  Training loss = 4.2984  Validation loss = 4.2643  \n",
      "\n",
      "Fold: 11  Epoch: 137  Training loss = 4.2981  Validation loss = 4.2638  \n",
      "\n",
      "Fold: 11  Epoch: 138  Training loss = 4.2979  Validation loss = 4.2634  \n",
      "\n",
      "Fold: 11  Epoch: 139  Training loss = 4.2976  Validation loss = 4.2630  \n",
      "\n",
      "Fold: 11  Epoch: 140  Training loss = 4.2973  Validation loss = 4.2624  \n",
      "\n",
      "Fold: 11  Epoch: 141  Training loss = 4.2970  Validation loss = 4.2619  \n",
      "\n",
      "Fold: 11  Epoch: 142  Training loss = 4.2967  Validation loss = 4.2614  \n",
      "\n",
      "Fold: 11  Epoch: 143  Training loss = 4.2964  Validation loss = 4.2609  \n",
      "\n",
      "Fold: 11  Epoch: 144  Training loss = 4.2961  Validation loss = 4.2604  \n",
      "\n",
      "Fold: 11  Epoch: 145  Training loss = 4.2958  Validation loss = 4.2599  \n",
      "\n",
      "Fold: 11  Epoch: 146  Training loss = 4.2956  Validation loss = 4.2595  \n",
      "\n",
      "Fold: 11  Epoch: 147  Training loss = 4.2953  Validation loss = 4.2590  \n",
      "\n",
      "Fold: 11  Epoch: 148  Training loss = 4.2950  Validation loss = 4.2584  \n",
      "\n",
      "Fold: 11  Epoch: 149  Training loss = 4.2947  Validation loss = 4.2580  \n",
      "\n",
      "Fold: 11  Epoch: 150  Training loss = 4.2944  Validation loss = 4.2576  \n",
      "\n",
      "Fold: 11  Epoch: 151  Training loss = 4.2941  Validation loss = 4.2570  \n",
      "\n",
      "Fold: 11  Epoch: 152  Training loss = 4.2938  Validation loss = 4.2566  \n",
      "\n",
      "Fold: 11  Epoch: 153  Training loss = 4.2935  Validation loss = 4.2561  \n",
      "\n",
      "Fold: 11  Epoch: 154  Training loss = 4.2933  Validation loss = 4.2556  \n",
      "\n",
      "Fold: 11  Epoch: 155  Training loss = 4.2930  Validation loss = 4.2551  \n",
      "\n",
      "Fold: 11  Epoch: 156  Training loss = 4.2927  Validation loss = 4.2547  \n",
      "\n",
      "Fold: 11  Epoch: 157  Training loss = 4.2925  Validation loss = 4.2542  \n",
      "\n",
      "Fold: 11  Epoch: 158  Training loss = 4.2922  Validation loss = 4.2538  \n",
      "\n",
      "Fold: 11  Epoch: 159  Training loss = 4.2919  Validation loss = 4.2533  \n",
      "\n",
      "Fold: 11  Epoch: 160  Training loss = 4.2917  Validation loss = 4.2529  \n",
      "\n",
      "Fold: 11  Epoch: 161  Training loss = 4.2915  Validation loss = 4.2525  \n",
      "\n",
      "Fold: 11  Epoch: 162  Training loss = 4.2912  Validation loss = 4.2521  \n",
      "\n",
      "Fold: 11  Epoch: 163  Training loss = 4.2910  Validation loss = 4.2517  \n",
      "\n",
      "Fold: 11  Epoch: 164  Training loss = 4.2907  Validation loss = 4.2513  \n",
      "\n",
      "Fold: 11  Epoch: 165  Training loss = 4.2905  Validation loss = 4.2509  \n",
      "\n",
      "Fold: 11  Epoch: 166  Training loss = 4.2902  Validation loss = 4.2503  \n",
      "\n",
      "Fold: 11  Epoch: 167  Training loss = 4.2899  Validation loss = 4.2498  \n",
      "\n",
      "Fold: 11  Epoch: 168  Training loss = 4.2896  Validation loss = 4.2494  \n",
      "\n",
      "Fold: 11  Epoch: 169  Training loss = 4.2893  Validation loss = 4.2489  \n",
      "\n",
      "Fold: 11  Epoch: 170  Training loss = 4.2891  Validation loss = 4.2484  \n",
      "\n",
      "Fold: 11  Epoch: 171  Training loss = 4.2888  Validation loss = 4.2480  \n",
      "\n",
      "Fold: 11  Epoch: 172  Training loss = 4.2885  Validation loss = 4.2474  \n",
      "\n",
      "Fold: 11  Epoch: 173  Training loss = 4.2882  Validation loss = 4.2469  \n",
      "\n",
      "Fold: 11  Epoch: 174  Training loss = 4.2879  Validation loss = 4.2464  \n",
      "\n",
      "Fold: 11  Epoch: 175  Training loss = 4.2876  Validation loss = 4.2459  \n",
      "\n",
      "Fold: 11  Epoch: 176  Training loss = 4.2873  Validation loss = 4.2453  \n",
      "\n",
      "Fold: 11  Epoch: 177  Training loss = 4.2870  Validation loss = 4.2449  \n",
      "\n",
      "Fold: 11  Epoch: 178  Training loss = 4.2868  Validation loss = 4.2444  \n",
      "\n",
      "Fold: 11  Epoch: 179  Training loss = 4.2865  Validation loss = 4.2440  \n",
      "\n",
      "Fold: 11  Epoch: 180  Training loss = 4.2863  Validation loss = 4.2437  \n",
      "\n",
      "Fold: 11  Epoch: 181  Training loss = 4.2861  Validation loss = 4.2433  \n",
      "\n",
      "Fold: 11  Epoch: 182  Training loss = 4.2859  Validation loss = 4.2429  \n",
      "\n",
      "Fold: 11  Epoch: 183  Training loss = 4.2857  Validation loss = 4.2425  \n",
      "\n",
      "Fold: 11  Epoch: 184  Training loss = 4.2854  Validation loss = 4.2421  \n",
      "\n",
      "Fold: 11  Epoch: 185  Training loss = 4.2851  Validation loss = 4.2416  \n",
      "\n",
      "Fold: 11  Epoch: 186  Training loss = 4.2849  Validation loss = 4.2412  \n",
      "\n",
      "Fold: 11  Epoch: 187  Training loss = 4.2846  Validation loss = 4.2407  \n",
      "\n",
      "Fold: 11  Epoch: 188  Training loss = 4.2843  Validation loss = 4.2403  \n",
      "\n",
      "Fold: 11  Epoch: 189  Training loss = 4.2840  Validation loss = 4.2398  \n",
      "\n",
      "Fold: 11  Epoch: 190  Training loss = 4.2838  Validation loss = 4.2395  \n",
      "\n",
      "Fold: 11  Epoch: 191  Training loss = 4.2836  Validation loss = 4.2392  \n",
      "\n",
      "Fold: 11  Epoch: 192  Training loss = 4.2833  Validation loss = 4.2387  \n",
      "\n",
      "Fold: 11  Epoch: 193  Training loss = 4.2831  Validation loss = 4.2383  \n",
      "\n",
      "Fold: 11  Epoch: 194  Training loss = 4.2828  Validation loss = 4.2378  \n",
      "\n",
      "Fold: 11  Epoch: 195  Training loss = 4.2825  Validation loss = 4.2373  \n",
      "\n",
      "Fold: 11  Epoch: 196  Training loss = 4.2822  Validation loss = 4.2367  \n",
      "\n",
      "Fold: 11  Epoch: 197  Training loss = 4.2819  Validation loss = 4.2362  \n",
      "\n",
      "Fold: 11  Epoch: 198  Training loss = 4.2817  Validation loss = 4.2357  \n",
      "\n",
      "Fold: 11  Epoch: 199  Training loss = 4.2813  Validation loss = 4.2351  \n",
      "\n",
      "Fold: 11  Epoch: 200  Training loss = 4.2810  Validation loss = 4.2346  \n",
      "\n",
      "Fold: 11  Epoch: 201  Training loss = 4.2807  Validation loss = 4.2341  \n",
      "\n",
      "Fold: 11  Epoch: 202  Training loss = 4.2805  Validation loss = 4.2336  \n",
      "\n",
      "Fold: 11  Epoch: 203  Training loss = 4.2802  Validation loss = 4.2332  \n",
      "\n",
      "Fold: 11  Epoch: 204  Training loss = 4.2799  Validation loss = 4.2327  \n",
      "\n",
      "Fold: 11  Epoch: 205  Training loss = 4.2797  Validation loss = 4.2323  \n",
      "\n",
      "Fold: 11  Epoch: 206  Training loss = 4.2794  Validation loss = 4.2318  \n",
      "\n",
      "Fold: 11  Epoch: 207  Training loss = 4.2792  Validation loss = 4.2314  \n",
      "\n",
      "Fold: 11  Epoch: 208  Training loss = 4.2790  Validation loss = 4.2311  \n",
      "\n",
      "Fold: 11  Epoch: 209  Training loss = 4.2786  Validation loss = 4.2305  \n",
      "\n",
      "Fold: 11  Epoch: 210  Training loss = 4.2784  Validation loss = 4.2301  \n",
      "\n",
      "Fold: 11  Epoch: 211  Training loss = 4.2782  Validation loss = 4.2297  \n",
      "\n",
      "Fold: 11  Epoch: 212  Training loss = 4.2778  Validation loss = 4.2291  \n",
      "\n",
      "Fold: 11  Epoch: 213  Training loss = 4.2776  Validation loss = 4.2286  \n",
      "\n",
      "Fold: 11  Epoch: 214  Training loss = 4.2773  Validation loss = 4.2282  \n",
      "\n",
      "Fold: 11  Epoch: 215  Training loss = 4.2770  Validation loss = 4.2276  \n",
      "\n",
      "Fold: 11  Epoch: 216  Training loss = 4.2767  Validation loss = 4.2271  \n",
      "\n",
      "Fold: 11  Epoch: 217  Training loss = 4.2764  Validation loss = 4.2266  \n",
      "\n",
      "Fold: 11  Epoch: 218  Training loss = 4.2761  Validation loss = 4.2262  \n",
      "\n",
      "Fold: 11  Epoch: 219  Training loss = 4.2759  Validation loss = 4.2257  \n",
      "\n",
      "Fold: 11  Epoch: 220  Training loss = 4.2756  Validation loss = 4.2253  \n",
      "\n",
      "Fold: 11  Epoch: 221  Training loss = 4.2754  Validation loss = 4.2249  \n",
      "\n",
      "Fold: 11  Epoch: 222  Training loss = 4.2752  Validation loss = 4.2245  \n",
      "\n",
      "Fold: 11  Epoch: 223  Training loss = 4.2749  Validation loss = 4.2239  \n",
      "\n",
      "Fold: 11  Epoch: 224  Training loss = 4.2746  Validation loss = 4.2235  \n",
      "\n",
      "Fold: 11  Epoch: 225  Training loss = 4.2743  Validation loss = 4.2230  \n",
      "\n",
      "Fold: 11  Epoch: 226  Training loss = 4.2741  Validation loss = 4.2226  \n",
      "\n",
      "Fold: 11  Epoch: 227  Training loss = 4.2739  Validation loss = 4.2222  \n",
      "\n",
      "Fold: 11  Epoch: 228  Training loss = 4.2736  Validation loss = 4.2217  \n",
      "\n",
      "Fold: 11  Epoch: 229  Training loss = 4.2733  Validation loss = 4.2213  \n",
      "\n",
      "Fold: 11  Epoch: 230  Training loss = 4.2731  Validation loss = 4.2208  \n",
      "\n",
      "Fold: 11  Epoch: 231  Training loss = 4.2728  Validation loss = 4.2204  \n",
      "\n",
      "Fold: 11  Epoch: 232  Training loss = 4.2726  Validation loss = 4.2200  \n",
      "\n",
      "Fold: 11  Epoch: 233  Training loss = 4.2724  Validation loss = 4.2196  \n",
      "\n",
      "Fold: 11  Epoch: 234  Training loss = 4.2721  Validation loss = 4.2191  \n",
      "\n",
      "Fold: 11  Epoch: 235  Training loss = 4.2718  Validation loss = 4.2186  \n",
      "\n",
      "Fold: 11  Epoch: 236  Training loss = 4.2715  Validation loss = 4.2182  \n",
      "\n",
      "Fold: 11  Epoch: 237  Training loss = 4.2713  Validation loss = 4.2178  \n",
      "\n",
      "Fold: 11  Epoch: 238  Training loss = 4.2711  Validation loss = 4.2174  \n",
      "\n",
      "Fold: 11  Epoch: 239  Training loss = 4.2708  Validation loss = 4.2169  \n",
      "\n",
      "Fold: 11  Epoch: 240  Training loss = 4.2706  Validation loss = 4.2165  \n",
      "\n",
      "Fold: 11  Epoch: 241  Training loss = 4.2703  Validation loss = 4.2160  \n",
      "\n",
      "Fold: 11  Epoch: 242  Training loss = 4.2700  Validation loss = 4.2155  \n",
      "\n",
      "Fold: 11  Epoch: 243  Training loss = 4.2697  Validation loss = 4.2150  \n",
      "\n",
      "Fold: 11  Epoch: 244  Training loss = 4.2694  Validation loss = 4.2145  \n",
      "\n",
      "Fold: 11  Epoch: 245  Training loss = 4.2691  Validation loss = 4.2140  \n",
      "\n",
      "Fold: 11  Epoch: 246  Training loss = 4.2688  Validation loss = 4.2134  \n",
      "\n",
      "Fold: 11  Epoch: 247  Training loss = 4.2685  Validation loss = 4.2129  \n",
      "\n",
      "Fold: 11  Epoch: 248  Training loss = 4.2683  Validation loss = 4.2125  \n",
      "\n",
      "Fold: 11  Epoch: 249  Training loss = 4.2680  Validation loss = 4.2121  \n",
      "\n",
      "Fold: 11  Epoch: 250  Training loss = 4.2678  Validation loss = 4.2116  \n",
      "\n",
      "Fold: 11  Epoch: 251  Training loss = 4.2676  Validation loss = 4.2112  \n",
      "\n",
      "Fold: 11  Epoch: 252  Training loss = 4.2673  Validation loss = 4.2108  \n",
      "\n",
      "Fold: 11  Epoch: 253  Training loss = 4.2671  Validation loss = 4.2104  \n",
      "\n",
      "Fold: 11  Epoch: 254  Training loss = 4.2668  Validation loss = 4.2099  \n",
      "\n",
      "Fold: 11  Epoch: 255  Training loss = 4.2665  Validation loss = 4.2094  \n",
      "\n",
      "Fold: 11  Epoch: 256  Training loss = 4.2663  Validation loss = 4.2089  \n",
      "\n",
      "Fold: 11  Epoch: 257  Training loss = 4.2660  Validation loss = 4.2085  \n",
      "\n",
      "Fold: 11  Epoch: 258  Training loss = 4.2658  Validation loss = 4.2081  \n",
      "\n",
      "Fold: 11  Epoch: 259  Training loss = 4.2655  Validation loss = 4.2077  \n",
      "\n",
      "Fold: 11  Epoch: 260  Training loss = 4.2653  Validation loss = 4.2072  \n",
      "\n",
      "Fold: 11  Epoch: 261  Training loss = 4.2650  Validation loss = 4.2067  \n",
      "\n",
      "Fold: 11  Epoch: 262  Training loss = 4.2647  Validation loss = 4.2061  \n",
      "\n",
      "Fold: 11  Epoch: 263  Training loss = 4.2644  Validation loss = 4.2056  \n",
      "\n",
      "Fold: 11  Epoch: 264  Training loss = 4.2642  Validation loss = 4.2053  \n",
      "\n",
      "Fold: 11  Epoch: 265  Training loss = 4.2639  Validation loss = 4.2047  \n",
      "\n",
      "Fold: 11  Epoch: 266  Training loss = 4.2636  Validation loss = 4.2042  \n",
      "\n",
      "Fold: 11  Epoch: 267  Training loss = 4.2634  Validation loss = 4.2038  \n",
      "\n",
      "Fold: 11  Epoch: 268  Training loss = 4.2631  Validation loss = 4.2034  \n",
      "\n",
      "Fold: 11  Epoch: 269  Training loss = 4.2628  Validation loss = 4.2029  \n",
      "\n",
      "Fold: 11  Epoch: 270  Training loss = 4.2626  Validation loss = 4.2025  \n",
      "\n",
      "Fold: 11  Epoch: 271  Training loss = 4.2624  Validation loss = 4.2021  \n",
      "\n",
      "Fold: 11  Epoch: 272  Training loss = 4.2621  Validation loss = 4.2016  \n",
      "\n",
      "Fold: 11  Epoch: 273  Training loss = 4.2618  Validation loss = 4.2012  \n",
      "\n",
      "Fold: 11  Epoch: 274  Training loss = 4.2616  Validation loss = 4.2008  \n",
      "\n",
      "Fold: 11  Epoch: 275  Training loss = 4.2614  Validation loss = 4.2004  \n",
      "\n",
      "Fold: 11  Epoch: 276  Training loss = 4.2611  Validation loss = 4.1999  \n",
      "\n",
      "Fold: 11  Epoch: 277  Training loss = 4.2608  Validation loss = 4.1994  \n",
      "\n",
      "Fold: 11  Epoch: 278  Training loss = 4.2606  Validation loss = 4.1990  \n",
      "\n",
      "Fold: 11  Epoch: 279  Training loss = 4.2603  Validation loss = 4.1984  \n",
      "\n",
      "Fold: 11  Epoch: 280  Training loss = 4.2600  Validation loss = 4.1979  \n",
      "\n",
      "Fold: 11  Epoch: 281  Training loss = 4.2597  Validation loss = 4.1974  \n",
      "\n",
      "Fold: 11  Epoch: 282  Training loss = 4.2595  Validation loss = 4.1970  \n",
      "\n",
      "Fold: 11  Epoch: 283  Training loss = 4.2592  Validation loss = 4.1965  \n",
      "\n",
      "Fold: 11  Epoch: 284  Training loss = 4.2590  Validation loss = 4.1961  \n",
      "\n",
      "Fold: 11  Epoch: 285  Training loss = 4.2587  Validation loss = 4.1957  \n",
      "\n",
      "Fold: 11  Epoch: 286  Training loss = 4.2585  Validation loss = 4.1953  \n",
      "\n",
      "Fold: 11  Epoch: 287  Training loss = 4.2582  Validation loss = 4.1948  \n",
      "\n",
      "Fold: 11  Epoch: 288  Training loss = 4.2580  Validation loss = 4.1944  \n",
      "\n",
      "Fold: 11  Epoch: 289  Training loss = 4.2577  Validation loss = 4.1939  \n",
      "\n",
      "Fold: 11  Epoch: 290  Training loss = 4.2575  Validation loss = 4.1935  \n",
      "\n",
      "Fold: 11  Epoch: 291  Training loss = 4.2573  Validation loss = 4.1931  \n",
      "\n",
      "Fold: 11  Epoch: 292  Training loss = 4.2570  Validation loss = 4.1926  \n",
      "\n",
      "Fold: 11  Epoch: 293  Training loss = 4.2567  Validation loss = 4.1921  \n",
      "\n",
      "Fold: 11  Epoch: 294  Training loss = 4.2564  Validation loss = 4.1916  \n",
      "\n",
      "Fold: 11  Epoch: 295  Training loss = 4.2561  Validation loss = 4.1911  \n",
      "\n",
      "Fold: 11  Epoch: 296  Training loss = 4.2559  Validation loss = 4.1907  \n",
      "\n",
      "Fold: 11  Epoch: 297  Training loss = 4.2556  Validation loss = 4.1902  \n",
      "\n",
      "Fold: 11  Epoch: 298  Training loss = 4.2554  Validation loss = 4.1899  \n",
      "\n",
      "Fold: 11  Epoch: 299  Training loss = 4.2551  Validation loss = 4.1894  \n",
      "\n",
      "Fold: 11  Epoch: 300  Training loss = 4.2549  Validation loss = 4.1890  \n",
      "\n",
      "Fold: 11  Epoch: 301  Training loss = 4.2547  Validation loss = 4.1887  \n",
      "\n",
      "Fold: 11  Epoch: 302  Training loss = 4.2544  Validation loss = 4.1881  \n",
      "\n",
      "Fold: 11  Epoch: 303  Training loss = 4.2541  Validation loss = 4.1876  \n",
      "\n",
      "Fold: 11  Epoch: 304  Training loss = 4.2539  Validation loss = 4.1873  \n",
      "\n",
      "Fold: 11  Epoch: 305  Training loss = 4.2536  Validation loss = 4.1868  \n",
      "\n",
      "Fold: 11  Epoch: 306  Training loss = 4.2533  Validation loss = 4.1862  \n",
      "\n",
      "Fold: 11  Epoch: 307  Training loss = 4.2530  Validation loss = 4.1857  \n",
      "\n",
      "Fold: 11  Epoch: 308  Training loss = 4.2528  Validation loss = 4.1852  \n",
      "\n",
      "Fold: 11  Epoch: 309  Training loss = 4.2525  Validation loss = 4.1847  \n",
      "\n",
      "Fold: 11  Epoch: 310  Training loss = 4.2523  Validation loss = 4.1843  \n",
      "\n",
      "Fold: 11  Epoch: 311  Training loss = 4.2520  Validation loss = 4.1838  \n",
      "\n",
      "Fold: 11  Epoch: 312  Training loss = 4.2517  Validation loss = 4.1834  \n",
      "\n",
      "Fold: 11  Epoch: 313  Training loss = 4.2514  Validation loss = 4.1829  \n",
      "\n",
      "Fold: 11  Epoch: 314  Training loss = 4.2512  Validation loss = 4.1826  \n",
      "\n",
      "Fold: 11  Epoch: 315  Training loss = 4.2509  Validation loss = 4.1821  \n",
      "\n",
      "Fold: 11  Epoch: 316  Training loss = 4.2506  Validation loss = 4.1815  \n",
      "\n",
      "Fold: 11  Epoch: 317  Training loss = 4.2504  Validation loss = 4.1812  \n",
      "\n",
      "Fold: 11  Epoch: 318  Training loss = 4.2502  Validation loss = 4.1808  \n",
      "\n",
      "Fold: 11  Epoch: 319  Training loss = 4.2498  Validation loss = 4.1801  \n",
      "\n",
      "Fold: 11  Epoch: 320  Training loss = 4.2496  Validation loss = 4.1797  \n",
      "\n",
      "Fold: 11  Epoch: 321  Training loss = 4.2494  Validation loss = 4.1793  \n",
      "\n",
      "Fold: 11  Epoch: 322  Training loss = 4.2491  Validation loss = 4.1788  \n",
      "\n",
      "Fold: 11  Epoch: 323  Training loss = 4.2488  Validation loss = 4.1784  \n",
      "\n",
      "Fold: 11  Epoch: 324  Training loss = 4.2486  Validation loss = 4.1780  \n",
      "\n",
      "Fold: 11  Epoch: 325  Training loss = 4.2484  Validation loss = 4.1776  \n",
      "\n",
      "Fold: 11  Epoch: 326  Training loss = 4.2481  Validation loss = 4.1771  \n",
      "\n",
      "Fold: 11  Epoch: 327  Training loss = 4.2479  Validation loss = 4.1767  \n",
      "\n",
      "Fold: 11  Epoch: 328  Training loss = 4.2476  Validation loss = 4.1763  \n",
      "\n",
      "Fold: 11  Epoch: 329  Training loss = 4.2474  Validation loss = 4.1758  \n",
      "\n",
      "Fold: 11  Epoch: 330  Training loss = 4.2471  Validation loss = 4.1753  \n",
      "\n",
      "Fold: 11  Epoch: 331  Training loss = 4.2469  Validation loss = 4.1749  \n",
      "\n",
      "Fold: 11  Epoch: 332  Training loss = 4.2467  Validation loss = 4.1745  \n",
      "\n",
      "Fold: 11  Epoch: 333  Training loss = 4.2464  Validation loss = 4.1740  \n",
      "\n",
      "Fold: 11  Epoch: 334  Training loss = 4.2461  Validation loss = 4.1735  \n",
      "\n",
      "Fold: 11  Epoch: 335  Training loss = 4.2458  Validation loss = 4.1729  \n",
      "\n",
      "Fold: 11  Epoch: 336  Training loss = 4.2455  Validation loss = 4.1725  \n",
      "\n",
      "Fold: 11  Epoch: 337  Training loss = 4.2453  Validation loss = 4.1720  \n",
      "\n",
      "Fold: 11  Epoch: 338  Training loss = 4.2449  Validation loss = 4.1715  \n",
      "\n",
      "Fold: 11  Epoch: 339  Training loss = 4.2446  Validation loss = 4.1709  \n",
      "\n",
      "Fold: 11  Epoch: 340  Training loss = 4.2444  Validation loss = 4.1704  \n",
      "\n",
      "Fold: 11  Epoch: 341  Training loss = 4.2441  Validation loss = 4.1700  \n",
      "\n",
      "Fold: 11  Epoch: 342  Training loss = 4.2438  Validation loss = 4.1694  \n",
      "\n",
      "Fold: 11  Epoch: 343  Training loss = 4.2435  Validation loss = 4.1690  \n",
      "\n",
      "Fold: 11  Epoch: 344  Training loss = 4.2432  Validation loss = 4.1684  \n",
      "\n",
      "Fold: 11  Epoch: 345  Training loss = 4.2430  Validation loss = 4.1679  \n",
      "\n",
      "Fold: 11  Epoch: 346  Training loss = 4.2427  Validation loss = 4.1675  \n",
      "\n",
      "Fold: 11  Epoch: 347  Training loss = 4.2425  Validation loss = 4.1671  \n",
      "\n",
      "Fold: 11  Epoch: 348  Training loss = 4.2422  Validation loss = 4.1666  \n",
      "\n",
      "Fold: 11  Epoch: 349  Training loss = 4.2420  Validation loss = 4.1662  \n",
      "\n",
      "Fold: 11  Epoch: 350  Training loss = 4.2418  Validation loss = 4.1657  \n",
      "\n",
      "Fold: 11  Epoch: 351  Training loss = 4.2415  Validation loss = 4.1652  \n",
      "\n",
      "Fold: 11  Epoch: 352  Training loss = 4.2412  Validation loss = 4.1647  \n",
      "\n",
      "Fold: 11  Epoch: 353  Training loss = 4.2409  Validation loss = 4.1643  \n",
      "\n",
      "Fold: 11  Epoch: 354  Training loss = 4.2407  Validation loss = 4.1639  \n",
      "\n",
      "Fold: 11  Epoch: 355  Training loss = 4.2404  Validation loss = 4.1633  \n",
      "\n",
      "Fold: 11  Epoch: 356  Training loss = 4.2402  Validation loss = 4.1629  \n",
      "\n",
      "Fold: 11  Epoch: 357  Training loss = 4.2399  Validation loss = 4.1625  \n",
      "\n",
      "Fold: 11  Epoch: 358  Training loss = 4.2396  Validation loss = 4.1620  \n",
      "\n",
      "Fold: 11  Epoch: 359  Training loss = 4.2394  Validation loss = 4.1615  \n",
      "\n",
      "Fold: 11  Epoch: 360  Training loss = 4.2391  Validation loss = 4.1609  \n",
      "\n",
      "Fold: 11  Epoch: 361  Training loss = 4.2388  Validation loss = 4.1604  \n",
      "\n",
      "Fold: 11  Epoch: 362  Training loss = 4.2386  Validation loss = 4.1601  \n",
      "\n",
      "Fold: 11  Epoch: 363  Training loss = 4.2384  Validation loss = 4.1597  \n",
      "\n",
      "Fold: 11  Epoch: 364  Training loss = 4.2381  Validation loss = 4.1592  \n",
      "\n",
      "Fold: 11  Epoch: 365  Training loss = 4.2379  Validation loss = 4.1589  \n",
      "\n",
      "Fold: 11  Epoch: 366  Training loss = 4.2376  Validation loss = 4.1585  \n",
      "\n",
      "Fold: 11  Epoch: 367  Training loss = 4.2374  Validation loss = 4.1580  \n",
      "\n",
      "Fold: 11  Epoch: 368  Training loss = 4.2371  Validation loss = 4.1575  \n",
      "\n",
      "Fold: 11  Epoch: 369  Training loss = 4.2368  Validation loss = 4.1570  \n",
      "\n",
      "Fold: 11  Epoch: 370  Training loss = 4.2366  Validation loss = 4.1566  \n",
      "\n",
      "Fold: 11  Epoch: 371  Training loss = 4.2364  Validation loss = 4.1561  \n",
      "\n",
      "Fold: 11  Epoch: 372  Training loss = 4.2361  Validation loss = 4.1557  \n",
      "\n",
      "Fold: 11  Epoch: 373  Training loss = 4.2359  Validation loss = 4.1553  \n",
      "\n",
      "Fold: 11  Epoch: 374  Training loss = 4.2356  Validation loss = 4.1547  \n",
      "\n",
      "Fold: 11  Epoch: 375  Training loss = 4.2352  Validation loss = 4.1541  \n",
      "\n",
      "Fold: 11  Epoch: 376  Training loss = 4.2351  Validation loss = 4.1538  \n",
      "\n",
      "Fold: 11  Epoch: 377  Training loss = 4.2348  Validation loss = 4.1533  \n",
      "\n",
      "Fold: 11  Epoch: 378  Training loss = 4.2345  Validation loss = 4.1527  \n",
      "\n",
      "Fold: 11  Epoch: 379  Training loss = 4.2342  Validation loss = 4.1523  \n",
      "\n",
      "Fold: 11  Epoch: 380  Training loss = 4.2340  Validation loss = 4.1519  \n",
      "\n",
      "Fold: 11  Epoch: 381  Training loss = 4.2338  Validation loss = 4.1515  \n",
      "\n",
      "Fold: 11  Epoch: 382  Training loss = 4.2335  Validation loss = 4.1511  \n",
      "\n",
      "Fold: 11  Epoch: 383  Training loss = 4.2333  Validation loss = 4.1507  \n",
      "\n",
      "Fold: 11  Epoch: 384  Training loss = 4.2330  Validation loss = 4.1502  \n",
      "\n",
      "Fold: 11  Epoch: 385  Training loss = 4.2328  Validation loss = 4.1497  \n",
      "\n",
      "Fold: 11  Epoch: 386  Training loss = 4.2325  Validation loss = 4.1492  \n",
      "\n",
      "Fold: 11  Epoch: 387  Training loss = 4.2322  Validation loss = 4.1488  \n",
      "\n",
      "Fold: 11  Epoch: 388  Training loss = 4.2320  Validation loss = 4.1483  \n",
      "\n",
      "Fold: 11  Epoch: 389  Training loss = 4.2318  Validation loss = 4.1479  \n",
      "\n",
      "Fold: 11  Epoch: 390  Training loss = 4.2314  Validation loss = 4.1473  \n",
      "\n",
      "Fold: 11  Epoch: 391  Training loss = 4.2312  Validation loss = 4.1469  \n",
      "\n",
      "Fold: 11  Epoch: 392  Training loss = 4.2309  Validation loss = 4.1464  \n",
      "\n",
      "Fold: 11  Epoch: 393  Training loss = 4.2307  Validation loss = 4.1459  \n",
      "\n",
      "Fold: 11  Epoch: 394  Training loss = 4.2305  Validation loss = 4.1455  \n",
      "\n",
      "Fold: 11  Epoch: 395  Training loss = 4.2302  Validation loss = 4.1451  \n",
      "\n",
      "Fold: 11  Epoch: 396  Training loss = 4.2300  Validation loss = 4.1447  \n",
      "\n",
      "Fold: 11  Epoch: 397  Training loss = 4.2297  Validation loss = 4.1442  \n",
      "\n",
      "Fold: 11  Epoch: 398  Training loss = 4.2294  Validation loss = 4.1437  \n",
      "\n",
      "Fold: 11  Epoch: 399  Training loss = 4.2291  Validation loss = 4.1432  \n",
      "\n",
      "Fold: 11  Epoch: 400  Training loss = 4.2288  Validation loss = 4.1427  \n",
      "\n",
      "Fold: 11  Epoch: 401  Training loss = 4.2286  Validation loss = 4.1423  \n",
      "\n",
      "Fold: 11  Epoch: 402  Training loss = 4.2284  Validation loss = 4.1419  \n",
      "\n",
      "Fold: 11  Epoch: 403  Training loss = 4.2281  Validation loss = 4.1413  \n",
      "\n",
      "Fold: 11  Epoch: 404  Training loss = 4.2278  Validation loss = 4.1409  \n",
      "\n",
      "Fold: 11  Epoch: 405  Training loss = 4.2276  Validation loss = 4.1404  \n",
      "\n",
      "Fold: 11  Epoch: 406  Training loss = 4.2272  Validation loss = 4.1399  \n",
      "\n",
      "Fold: 11  Epoch: 407  Training loss = 4.2269  Validation loss = 4.1393  \n",
      "\n",
      "Fold: 11  Epoch: 408  Training loss = 4.2267  Validation loss = 4.1389  \n",
      "\n",
      "Fold: 11  Epoch: 409  Training loss = 4.2264  Validation loss = 4.1384  \n",
      "\n",
      "Fold: 11  Epoch: 410  Training loss = 4.2262  Validation loss = 4.1379  \n",
      "\n",
      "Fold: 11  Epoch: 411  Training loss = 4.2258  Validation loss = 4.1373  \n",
      "\n",
      "Fold: 11  Epoch: 412  Training loss = 4.2256  Validation loss = 4.1368  \n",
      "\n",
      "Fold: 11  Epoch: 413  Training loss = 4.2253  Validation loss = 4.1364  \n",
      "\n",
      "Fold: 11  Epoch: 414  Training loss = 4.2251  Validation loss = 4.1360  \n",
      "\n",
      "Fold: 11  Epoch: 415  Training loss = 4.2248  Validation loss = 4.1355  \n",
      "\n",
      "Fold: 11  Epoch: 416  Training loss = 4.2245  Validation loss = 4.1350  \n",
      "\n",
      "Fold: 11  Epoch: 417  Training loss = 4.2242  Validation loss = 4.1345  \n",
      "\n",
      "Fold: 11  Epoch: 418  Training loss = 4.2240  Validation loss = 4.1340  \n",
      "\n",
      "Fold: 11  Epoch: 419  Training loss = 4.2237  Validation loss = 4.1335  \n",
      "\n",
      "Fold: 11  Epoch: 420  Training loss = 4.2235  Validation loss = 4.1331  \n",
      "\n",
      "Fold: 11  Epoch: 421  Training loss = 4.2232  Validation loss = 4.1326  \n",
      "\n",
      "Fold: 11  Epoch: 422  Training loss = 4.2230  Validation loss = 4.1322  \n",
      "\n",
      "Fold: 11  Epoch: 423  Training loss = 4.2228  Validation loss = 4.1318  \n",
      "\n",
      "Fold: 11  Epoch: 424  Training loss = 4.2226  Validation loss = 4.1314  \n",
      "\n",
      "Fold: 11  Epoch: 425  Training loss = 4.2223  Validation loss = 4.1310  \n",
      "\n",
      "Fold: 11  Epoch: 426  Training loss = 4.2220  Validation loss = 4.1304  \n",
      "\n",
      "Fold: 11  Epoch: 427  Training loss = 4.2217  Validation loss = 4.1299  \n",
      "\n",
      "Fold: 11  Epoch: 428  Training loss = 4.2215  Validation loss = 4.1295  \n",
      "\n",
      "Fold: 11  Epoch: 429  Training loss = 4.2212  Validation loss = 4.1291  \n",
      "\n",
      "Fold: 11  Epoch: 430  Training loss = 4.2210  Validation loss = 4.1286  \n",
      "\n",
      "Fold: 11  Epoch: 431  Training loss = 4.2208  Validation loss = 4.1282  \n",
      "\n",
      "Fold: 11  Epoch: 432  Training loss = 4.2205  Validation loss = 4.1276  \n",
      "\n",
      "Fold: 11  Epoch: 433  Training loss = 4.2202  Validation loss = 4.1270  \n",
      "\n",
      "Fold: 11  Epoch: 434  Training loss = 4.2199  Validation loss = 4.1266  \n",
      "\n",
      "Fold: 11  Epoch: 435  Training loss = 4.2197  Validation loss = 4.1262  \n",
      "\n",
      "Fold: 11  Epoch: 436  Training loss = 4.2194  Validation loss = 4.1256  \n",
      "\n",
      "Fold: 11  Epoch: 437  Training loss = 4.2190  Validation loss = 4.1250  \n",
      "\n",
      "Fold: 11  Epoch: 438  Training loss = 4.2187  Validation loss = 4.1244  \n",
      "\n",
      "Fold: 11  Epoch: 439  Training loss = 4.2185  Validation loss = 4.1240  \n",
      "\n",
      "Fold: 11  Epoch: 440  Training loss = 4.2183  Validation loss = 4.1236  \n",
      "\n",
      "Fold: 11  Epoch: 441  Training loss = 4.2180  Validation loss = 4.1232  \n",
      "\n",
      "Fold: 11  Epoch: 442  Training loss = 4.2177  Validation loss = 4.1227  \n",
      "\n",
      "Fold: 11  Epoch: 443  Training loss = 4.2174  Validation loss = 4.1221  \n",
      "\n",
      "Fold: 11  Epoch: 444  Training loss = 4.2171  Validation loss = 4.1216  \n",
      "\n",
      "Fold: 11  Epoch: 445  Training loss = 4.2169  Validation loss = 4.1210  \n",
      "\n",
      "Fold: 11  Epoch: 446  Training loss = 4.2166  Validation loss = 4.1206  \n",
      "\n",
      "Fold: 11  Epoch: 447  Training loss = 4.2164  Validation loss = 4.1202  \n",
      "\n",
      "Fold: 11  Epoch: 448  Training loss = 4.2162  Validation loss = 4.1197  \n",
      "\n",
      "Fold: 11  Epoch: 449  Training loss = 4.2159  Validation loss = 4.1193  \n",
      "\n",
      "Fold: 11  Epoch: 450  Training loss = 4.2156  Validation loss = 4.1188  \n",
      "\n",
      "Fold: 11  Epoch: 451  Training loss = 4.2154  Validation loss = 4.1184  \n",
      "\n",
      "Fold: 11  Epoch: 452  Training loss = 4.2152  Validation loss = 4.1179  \n",
      "\n",
      "Fold: 11  Epoch: 453  Training loss = 4.2149  Validation loss = 4.1175  \n",
      "\n",
      "Fold: 11  Epoch: 454  Training loss = 4.2147  Validation loss = 4.1171  \n",
      "\n",
      "Fold: 11  Epoch: 455  Training loss = 4.2144  Validation loss = 4.1166  \n",
      "\n",
      "Fold: 11  Epoch: 456  Training loss = 4.2141  Validation loss = 4.1161  \n",
      "\n",
      "Fold: 11  Epoch: 457  Training loss = 4.2139  Validation loss = 4.1158  \n",
      "\n",
      "Fold: 11  Epoch: 458  Training loss = 4.2137  Validation loss = 4.1153  \n",
      "\n",
      "Fold: 11  Epoch: 459  Training loss = 4.2134  Validation loss = 4.1148  \n",
      "\n",
      "Fold: 11  Epoch: 460  Training loss = 4.2131  Validation loss = 4.1143  \n",
      "\n",
      "Fold: 11  Epoch: 461  Training loss = 4.2129  Validation loss = 4.1139  \n",
      "\n",
      "Fold: 11  Epoch: 462  Training loss = 4.2126  Validation loss = 4.1133  \n",
      "\n",
      "Fold: 11  Epoch: 463  Training loss = 4.2123  Validation loss = 4.1129  \n",
      "\n",
      "Fold: 11  Epoch: 464  Training loss = 4.2121  Validation loss = 4.1124  \n",
      "\n",
      "Fold: 11  Epoch: 465  Training loss = 4.2118  Validation loss = 4.1120  \n",
      "\n",
      "Fold: 11  Epoch: 466  Training loss = 4.2116  Validation loss = 4.1116  \n",
      "\n",
      "Fold: 11  Epoch: 467  Training loss = 4.2113  Validation loss = 4.1110  \n",
      "\n",
      "Fold: 11  Epoch: 468  Training loss = 4.2110  Validation loss = 4.1106  \n",
      "\n",
      "Fold: 11  Epoch: 469  Training loss = 4.2108  Validation loss = 4.1101  \n",
      "\n",
      "Fold: 11  Epoch: 470  Training loss = 4.2105  Validation loss = 4.1096  \n",
      "\n",
      "Fold: 11  Epoch: 471  Training loss = 4.2102  Validation loss = 4.1091  \n",
      "\n",
      "Fold: 11  Epoch: 472  Training loss = 4.2100  Validation loss = 4.1087  \n",
      "\n",
      "Fold: 11  Epoch: 473  Training loss = 4.2098  Validation loss = 4.1083  \n",
      "\n",
      "Fold: 11  Epoch: 474  Training loss = 4.2095  Validation loss = 4.1078  \n",
      "\n",
      "Fold: 11  Epoch: 475  Training loss = 4.2093  Validation loss = 4.1074  \n",
      "\n",
      "Fold: 11  Epoch: 476  Training loss = 4.2090  Validation loss = 4.1069  \n",
      "\n",
      "Fold: 11  Epoch: 477  Training loss = 4.2088  Validation loss = 4.1064  \n",
      "\n",
      "Fold: 11  Epoch: 478  Training loss = 4.2085  Validation loss = 4.1059  \n",
      "\n",
      "Fold: 11  Epoch: 479  Training loss = 4.2082  Validation loss = 4.1054  \n",
      "\n",
      "Fold: 11  Epoch: 480  Training loss = 4.2079  Validation loss = 4.1049  \n",
      "\n",
      "Fold: 11  Epoch: 481  Training loss = 4.2076  Validation loss = 4.1044  \n",
      "\n",
      "Fold: 11  Epoch: 482  Training loss = 4.2074  Validation loss = 4.1040  \n",
      "\n",
      "Fold: 11  Epoch: 483  Training loss = 4.2071  Validation loss = 4.1034  \n",
      "\n",
      "Fold: 11  Epoch: 484  Training loss = 4.2068  Validation loss = 4.1030  \n",
      "\n",
      "Fold: 11  Epoch: 485  Training loss = 4.2066  Validation loss = 4.1025  \n",
      "\n",
      "Fold: 11  Epoch: 486  Training loss = 4.2063  Validation loss = 4.1021  \n",
      "\n",
      "Fold: 11  Epoch: 487  Training loss = 4.2061  Validation loss = 4.1016  \n",
      "\n",
      "Fold: 11  Epoch: 488  Training loss = 4.2058  Validation loss = 4.1011  \n",
      "\n",
      "Fold: 11  Epoch: 489  Training loss = 4.2055  Validation loss = 4.1006  \n",
      "\n",
      "Fold: 11  Epoch: 490  Training loss = 4.2052  Validation loss = 4.1002  \n",
      "\n",
      "Fold: 11  Epoch: 491  Training loss = 4.2050  Validation loss = 4.0997  \n",
      "\n",
      "Fold: 11  Epoch: 492  Training loss = 4.2047  Validation loss = 4.0992  \n",
      "\n",
      "Fold: 11  Epoch: 493  Training loss = 4.2045  Validation loss = 4.0988  \n",
      "\n",
      "Fold: 11  Epoch: 494  Training loss = 4.2042  Validation loss = 4.0983  \n",
      "\n",
      "Fold: 11  Epoch: 495  Training loss = 4.2040  Validation loss = 4.0978  \n",
      "\n",
      "Fold: 11  Epoch: 496  Training loss = 4.2037  Validation loss = 4.0974  \n",
      "\n",
      "Fold: 11  Epoch: 497  Training loss = 4.2034  Validation loss = 4.0969  \n",
      "\n",
      "Fold: 11  Epoch: 498  Training loss = 4.2031  Validation loss = 4.0963  \n",
      "\n",
      "Fold: 11  Epoch: 499  Training loss = 4.2029  Validation loss = 4.0959  \n",
      "\n",
      "Fold: 11  Epoch: 500  Training loss = 4.2026  Validation loss = 4.0954  \n",
      "\n",
      "Check model:  Fold: 11  Optimal epoch: 500  \n",
      "\n",
      "Fold: 12  Epoch: 1  Training loss = 4.3163  Validation loss = 5.4228  \n",
      "\n",
      "Fold: 12  Epoch: 2  Training loss = 4.3160  Validation loss = 5.4224  \n",
      "\n",
      "Fold: 12  Epoch: 3  Training loss = 4.3157  Validation loss = 5.4220  \n",
      "\n",
      "Fold: 12  Epoch: 4  Training loss = 4.3154  Validation loss = 5.4216  \n",
      "\n",
      "Fold: 12  Epoch: 5  Training loss = 4.3151  Validation loss = 5.4212  \n",
      "\n",
      "Fold: 12  Epoch: 6  Training loss = 4.3148  Validation loss = 5.4208  \n",
      "\n",
      "Fold: 12  Epoch: 7  Training loss = 4.3145  Validation loss = 5.4203  \n",
      "\n",
      "Fold: 12  Epoch: 8  Training loss = 4.3141  Validation loss = 5.4199  \n",
      "\n",
      "Fold: 12  Epoch: 9  Training loss = 4.3138  Validation loss = 5.4193  \n",
      "\n",
      "Fold: 12  Epoch: 10  Training loss = 4.3135  Validation loss = 5.4190  \n",
      "\n",
      "Fold: 12  Epoch: 11  Training loss = 4.3132  Validation loss = 5.4186  \n",
      "\n",
      "Fold: 12  Epoch: 12  Training loss = 4.3128  Validation loss = 5.4181  \n",
      "\n",
      "Fold: 12  Epoch: 13  Training loss = 4.3125  Validation loss = 5.4176  \n",
      "\n",
      "Fold: 12  Epoch: 14  Training loss = 4.3122  Validation loss = 5.4172  \n",
      "\n",
      "Fold: 12  Epoch: 15  Training loss = 4.3118  Validation loss = 5.4167  \n",
      "\n",
      "Fold: 12  Epoch: 16  Training loss = 4.3115  Validation loss = 5.4162  \n",
      "\n",
      "Fold: 12  Epoch: 17  Training loss = 4.3112  Validation loss = 5.4158  \n",
      "\n",
      "Fold: 12  Epoch: 18  Training loss = 4.3109  Validation loss = 5.4154  \n",
      "\n",
      "Fold: 12  Epoch: 19  Training loss = 4.3105  Validation loss = 5.4149  \n",
      "\n",
      "Fold: 12  Epoch: 20  Training loss = 4.3102  Validation loss = 5.4145  \n",
      "\n",
      "Fold: 12  Epoch: 21  Training loss = 4.3099  Validation loss = 5.4141  \n",
      "\n",
      "Fold: 12  Epoch: 22  Training loss = 4.3096  Validation loss = 5.4137  \n",
      "\n",
      "Fold: 12  Epoch: 23  Training loss = 4.3093  Validation loss = 5.4132  \n",
      "\n",
      "Fold: 12  Epoch: 24  Training loss = 4.3090  Validation loss = 5.4128  \n",
      "\n",
      "Fold: 12  Epoch: 25  Training loss = 4.3086  Validation loss = 5.4123  \n",
      "\n",
      "Fold: 12  Epoch: 26  Training loss = 4.3084  Validation loss = 5.4119  \n",
      "\n",
      "Fold: 12  Epoch: 27  Training loss = 4.3080  Validation loss = 5.4115  \n",
      "\n",
      "Fold: 12  Epoch: 28  Training loss = 4.3077  Validation loss = 5.4111  \n",
      "\n",
      "Fold: 12  Epoch: 29  Training loss = 4.3075  Validation loss = 5.4107  \n",
      "\n",
      "Fold: 12  Epoch: 30  Training loss = 4.3072  Validation loss = 5.4103  \n",
      "\n",
      "Fold: 12  Epoch: 31  Training loss = 4.3068  Validation loss = 5.4098  \n",
      "\n",
      "Fold: 12  Epoch: 32  Training loss = 4.3065  Validation loss = 5.4094  \n",
      "\n",
      "Fold: 12  Epoch: 33  Training loss = 4.3062  Validation loss = 5.4089  \n",
      "\n",
      "Fold: 12  Epoch: 34  Training loss = 4.3058  Validation loss = 5.4085  \n",
      "\n",
      "Fold: 12  Epoch: 35  Training loss = 4.3056  Validation loss = 5.4081  \n",
      "\n",
      "Fold: 12  Epoch: 36  Training loss = 4.3053  Validation loss = 5.4077  \n",
      "\n",
      "Fold: 12  Epoch: 37  Training loss = 4.3049  Validation loss = 5.4073  \n",
      "\n",
      "Fold: 12  Epoch: 38  Training loss = 4.3046  Validation loss = 5.4069  \n",
      "\n",
      "Fold: 12  Epoch: 39  Training loss = 4.3043  Validation loss = 5.4065  \n",
      "\n",
      "Fold: 12  Epoch: 40  Training loss = 4.3040  Validation loss = 5.4061  \n",
      "\n",
      "Fold: 12  Epoch: 41  Training loss = 4.3037  Validation loss = 5.4056  \n",
      "\n",
      "Fold: 12  Epoch: 42  Training loss = 4.3034  Validation loss = 5.4052  \n",
      "\n",
      "Fold: 12  Epoch: 43  Training loss = 4.3031  Validation loss = 5.4048  \n",
      "\n",
      "Fold: 12  Epoch: 44  Training loss = 4.3029  Validation loss = 5.4045  \n",
      "\n",
      "Fold: 12  Epoch: 45  Training loss = 4.3026  Validation loss = 5.4041  \n",
      "\n",
      "Fold: 12  Epoch: 46  Training loss = 4.3023  Validation loss = 5.4037  \n",
      "\n",
      "Fold: 12  Epoch: 47  Training loss = 4.3021  Validation loss = 5.4033  \n",
      "\n",
      "Fold: 12  Epoch: 48  Training loss = 4.3017  Validation loss = 5.4029  \n",
      "\n",
      "Fold: 12  Epoch: 49  Training loss = 4.3014  Validation loss = 5.4024  \n",
      "\n",
      "Fold: 12  Epoch: 50  Training loss = 4.3011  Validation loss = 5.4020  \n",
      "\n",
      "Fold: 12  Epoch: 51  Training loss = 4.3008  Validation loss = 5.4015  \n",
      "\n",
      "Fold: 12  Epoch: 52  Training loss = 4.3004  Validation loss = 5.4010  \n",
      "\n",
      "Fold: 12  Epoch: 53  Training loss = 4.3001  Validation loss = 5.4006  \n",
      "\n",
      "Fold: 12  Epoch: 54  Training loss = 4.2998  Validation loss = 5.4002  \n",
      "\n",
      "Fold: 12  Epoch: 55  Training loss = 4.2995  Validation loss = 5.3998  \n",
      "\n",
      "Fold: 12  Epoch: 56  Training loss = 4.2992  Validation loss = 5.3994  \n",
      "\n",
      "Fold: 12  Epoch: 57  Training loss = 4.2989  Validation loss = 5.3990  \n",
      "\n",
      "Fold: 12  Epoch: 58  Training loss = 4.2986  Validation loss = 5.3985  \n",
      "\n",
      "Fold: 12  Epoch: 59  Training loss = 4.2982  Validation loss = 5.3981  \n",
      "\n",
      "Fold: 12  Epoch: 60  Training loss = 4.2980  Validation loss = 5.3977  \n",
      "\n",
      "Fold: 12  Epoch: 61  Training loss = 4.2978  Validation loss = 5.3974  \n",
      "\n",
      "Fold: 12  Epoch: 62  Training loss = 4.2975  Validation loss = 5.3970  \n",
      "\n",
      "Fold: 12  Epoch: 63  Training loss = 4.2972  Validation loss = 5.3967  \n",
      "\n",
      "Fold: 12  Epoch: 64  Training loss = 4.2970  Validation loss = 5.3963  \n",
      "\n",
      "Fold: 12  Epoch: 65  Training loss = 4.2967  Validation loss = 5.3960  \n",
      "\n",
      "Fold: 12  Epoch: 66  Training loss = 4.2964  Validation loss = 5.3955  \n",
      "\n",
      "Fold: 12  Epoch: 67  Training loss = 4.2960  Validation loss = 5.3950  \n",
      "\n",
      "Fold: 12  Epoch: 68  Training loss = 4.2957  Validation loss = 5.3946  \n",
      "\n",
      "Fold: 12  Epoch: 69  Training loss = 4.2955  Validation loss = 5.3942  \n",
      "\n",
      "Fold: 12  Epoch: 70  Training loss = 4.2951  Validation loss = 5.3938  \n",
      "\n",
      "Fold: 12  Epoch: 71  Training loss = 4.2948  Validation loss = 5.3934  \n",
      "\n",
      "Fold: 12  Epoch: 72  Training loss = 4.2946  Validation loss = 5.3930  \n",
      "\n",
      "Fold: 12  Epoch: 73  Training loss = 4.2943  Validation loss = 5.3926  \n",
      "\n",
      "Fold: 12  Epoch: 74  Training loss = 4.2940  Validation loss = 5.3922  \n",
      "\n",
      "Fold: 12  Epoch: 75  Training loss = 4.2937  Validation loss = 5.3918  \n",
      "\n",
      "Fold: 12  Epoch: 76  Training loss = 4.2934  Validation loss = 5.3914  \n",
      "\n",
      "Fold: 12  Epoch: 77  Training loss = 4.2931  Validation loss = 5.3910  \n",
      "\n",
      "Fold: 12  Epoch: 78  Training loss = 4.2928  Validation loss = 5.3906  \n",
      "\n",
      "Fold: 12  Epoch: 79  Training loss = 4.2925  Validation loss = 5.3902  \n",
      "\n",
      "Fold: 12  Epoch: 80  Training loss = 4.2922  Validation loss = 5.3898  \n",
      "\n",
      "Fold: 12  Epoch: 81  Training loss = 4.2920  Validation loss = 5.3894  \n",
      "\n",
      "Fold: 12  Epoch: 82  Training loss = 4.2916  Validation loss = 5.3889  \n",
      "\n",
      "Fold: 12  Epoch: 83  Training loss = 4.2913  Validation loss = 5.3884  \n",
      "\n",
      "Fold: 12  Epoch: 84  Training loss = 4.2910  Validation loss = 5.3880  \n",
      "\n",
      "Fold: 12  Epoch: 85  Training loss = 4.2906  Validation loss = 5.3876  \n",
      "\n",
      "Fold: 12  Epoch: 86  Training loss = 4.2904  Validation loss = 5.3872  \n",
      "\n",
      "Fold: 12  Epoch: 87  Training loss = 4.2902  Validation loss = 5.3869  \n",
      "\n",
      "Fold: 12  Epoch: 88  Training loss = 4.2899  Validation loss = 5.3865  \n",
      "\n",
      "Fold: 12  Epoch: 89  Training loss = 4.2896  Validation loss = 5.3861  \n",
      "\n",
      "Fold: 12  Epoch: 90  Training loss = 4.2893  Validation loss = 5.3858  \n",
      "\n",
      "Fold: 12  Epoch: 91  Training loss = 4.2890  Validation loss = 5.3853  \n",
      "\n",
      "Fold: 12  Epoch: 92  Training loss = 4.2887  Validation loss = 5.3849  \n",
      "\n",
      "Fold: 12  Epoch: 93  Training loss = 4.2884  Validation loss = 5.3845  \n",
      "\n",
      "Fold: 12  Epoch: 94  Training loss = 4.2881  Validation loss = 5.3841  \n",
      "\n",
      "Fold: 12  Epoch: 95  Training loss = 4.2878  Validation loss = 5.3837  \n",
      "\n",
      "Fold: 12  Epoch: 96  Training loss = 4.2875  Validation loss = 5.3833  \n",
      "\n",
      "Fold: 12  Epoch: 97  Training loss = 4.2873  Validation loss = 5.3829  \n",
      "\n",
      "Fold: 12  Epoch: 98  Training loss = 4.2870  Validation loss = 5.3825  \n",
      "\n",
      "Fold: 12  Epoch: 99  Training loss = 4.2867  Validation loss = 5.3821  \n",
      "\n",
      "Fold: 12  Epoch: 100  Training loss = 4.2864  Validation loss = 5.3816  \n",
      "\n",
      "Fold: 12  Epoch: 101  Training loss = 4.2861  Validation loss = 5.3813  \n",
      "\n",
      "Fold: 12  Epoch: 102  Training loss = 4.2858  Validation loss = 5.3809  \n",
      "\n",
      "Fold: 12  Epoch: 103  Training loss = 4.2855  Validation loss = 5.3805  \n",
      "\n",
      "Fold: 12  Epoch: 104  Training loss = 4.2852  Validation loss = 5.3801  \n",
      "\n",
      "Fold: 12  Epoch: 105  Training loss = 4.2849  Validation loss = 5.3797  \n",
      "\n",
      "Fold: 12  Epoch: 106  Training loss = 4.2846  Validation loss = 5.3793  \n",
      "\n",
      "Fold: 12  Epoch: 107  Training loss = 4.2843  Validation loss = 5.3788  \n",
      "\n",
      "Fold: 12  Epoch: 108  Training loss = 4.2840  Validation loss = 5.3784  \n",
      "\n",
      "Fold: 12  Epoch: 109  Training loss = 4.2838  Validation loss = 5.3781  \n",
      "\n",
      "Fold: 12  Epoch: 110  Training loss = 4.2835  Validation loss = 5.3777  \n",
      "\n",
      "Fold: 12  Epoch: 111  Training loss = 4.2832  Validation loss = 5.3773  \n",
      "\n",
      "Fold: 12  Epoch: 112  Training loss = 4.2828  Validation loss = 5.3768  \n",
      "\n",
      "Fold: 12  Epoch: 113  Training loss = 4.2826  Validation loss = 5.3764  \n",
      "\n",
      "Fold: 12  Epoch: 114  Training loss = 4.2822  Validation loss = 5.3759  \n",
      "\n",
      "Fold: 12  Epoch: 115  Training loss = 4.2819  Validation loss = 5.3755  \n",
      "\n",
      "Fold: 12  Epoch: 116  Training loss = 4.2817  Validation loss = 5.3752  \n",
      "\n",
      "Fold: 12  Epoch: 117  Training loss = 4.2814  Validation loss = 5.3747  \n",
      "\n",
      "Fold: 12  Epoch: 118  Training loss = 4.2811  Validation loss = 5.3744  \n",
      "\n",
      "Fold: 12  Epoch: 119  Training loss = 4.2808  Validation loss = 5.3740  \n",
      "\n",
      "Fold: 12  Epoch: 120  Training loss = 4.2805  Validation loss = 5.3735  \n",
      "\n",
      "Fold: 12  Epoch: 121  Training loss = 4.2802  Validation loss = 5.3731  \n",
      "\n",
      "Fold: 12  Epoch: 122  Training loss = 4.2799  Validation loss = 5.3727  \n",
      "\n",
      "Fold: 12  Epoch: 123  Training loss = 4.2796  Validation loss = 5.3723  \n",
      "\n",
      "Fold: 12  Epoch: 124  Training loss = 4.2793  Validation loss = 5.3718  \n",
      "\n",
      "Fold: 12  Epoch: 125  Training loss = 4.2789  Validation loss = 5.3714  \n",
      "\n",
      "Fold: 12  Epoch: 126  Training loss = 4.2786  Validation loss = 5.3709  \n",
      "\n",
      "Fold: 12  Epoch: 127  Training loss = 4.2783  Validation loss = 5.3705  \n",
      "\n",
      "Fold: 12  Epoch: 128  Training loss = 4.2780  Validation loss = 5.3700  \n",
      "\n",
      "Fold: 12  Epoch: 129  Training loss = 4.2777  Validation loss = 5.3696  \n",
      "\n",
      "Fold: 12  Epoch: 130  Training loss = 4.2774  Validation loss = 5.3692  \n",
      "\n",
      "Fold: 12  Epoch: 131  Training loss = 4.2771  Validation loss = 5.3688  \n",
      "\n",
      "Fold: 12  Epoch: 132  Training loss = 4.2767  Validation loss = 5.3683  \n",
      "\n",
      "Fold: 12  Epoch: 133  Training loss = 4.2765  Validation loss = 5.3679  \n",
      "\n",
      "Fold: 12  Epoch: 134  Training loss = 4.2762  Validation loss = 5.3675  \n",
      "\n",
      "Fold: 12  Epoch: 135  Training loss = 4.2759  Validation loss = 5.3671  \n",
      "\n",
      "Fold: 12  Epoch: 136  Training loss = 4.2756  Validation loss = 5.3667  \n",
      "\n",
      "Fold: 12  Epoch: 137  Training loss = 4.2753  Validation loss = 5.3664  \n",
      "\n",
      "Fold: 12  Epoch: 138  Training loss = 4.2750  Validation loss = 5.3659  \n",
      "\n",
      "Fold: 12  Epoch: 139  Training loss = 4.2747  Validation loss = 5.3655  \n",
      "\n",
      "Fold: 12  Epoch: 140  Training loss = 4.2744  Validation loss = 5.3651  \n",
      "\n",
      "Fold: 12  Epoch: 141  Training loss = 4.2741  Validation loss = 5.3647  \n",
      "\n",
      "Fold: 12  Epoch: 142  Training loss = 4.2739  Validation loss = 5.3643  \n",
      "\n",
      "Fold: 12  Epoch: 143  Training loss = 4.2736  Validation loss = 5.3639  \n",
      "\n",
      "Fold: 12  Epoch: 144  Training loss = 4.2732  Validation loss = 5.3634  \n",
      "\n",
      "Fold: 12  Epoch: 145  Training loss = 4.2729  Validation loss = 5.3630  \n",
      "\n",
      "Fold: 12  Epoch: 146  Training loss = 4.2727  Validation loss = 5.3626  \n",
      "\n",
      "Fold: 12  Epoch: 147  Training loss = 4.2724  Validation loss = 5.3622  \n",
      "\n",
      "Fold: 12  Epoch: 148  Training loss = 4.2721  Validation loss = 5.3618  \n",
      "\n",
      "Fold: 12  Epoch: 149  Training loss = 4.2718  Validation loss = 5.3614  \n",
      "\n",
      "Fold: 12  Epoch: 150  Training loss = 4.2715  Validation loss = 5.3610  \n",
      "\n",
      "Fold: 12  Epoch: 151  Training loss = 4.2713  Validation loss = 5.3607  \n",
      "\n",
      "Fold: 12  Epoch: 152  Training loss = 4.2709  Validation loss = 5.3602  \n",
      "\n",
      "Fold: 12  Epoch: 153  Training loss = 4.2707  Validation loss = 5.3599  \n",
      "\n",
      "Fold: 12  Epoch: 154  Training loss = 4.2704  Validation loss = 5.3595  \n",
      "\n",
      "Fold: 12  Epoch: 155  Training loss = 4.2702  Validation loss = 5.3592  \n",
      "\n",
      "Fold: 12  Epoch: 156  Training loss = 4.2699  Validation loss = 5.3588  \n",
      "\n",
      "Fold: 12  Epoch: 157  Training loss = 4.2696  Validation loss = 5.3584  \n",
      "\n",
      "Fold: 12  Epoch: 158  Training loss = 4.2693  Validation loss = 5.3580  \n",
      "\n",
      "Fold: 12  Epoch: 159  Training loss = 4.2690  Validation loss = 5.3576  \n",
      "\n",
      "Fold: 12  Epoch: 160  Training loss = 4.2688  Validation loss = 5.3572  \n",
      "\n",
      "Fold: 12  Epoch: 161  Training loss = 4.2684  Validation loss = 5.3567  \n",
      "\n",
      "Fold: 12  Epoch: 162  Training loss = 4.2681  Validation loss = 5.3563  \n",
      "\n",
      "Fold: 12  Epoch: 163  Training loss = 4.2678  Validation loss = 5.3559  \n",
      "\n",
      "Fold: 12  Epoch: 164  Training loss = 4.2676  Validation loss = 5.3556  \n",
      "\n",
      "Fold: 12  Epoch: 165  Training loss = 4.2673  Validation loss = 5.3552  \n",
      "\n",
      "Fold: 12  Epoch: 166  Training loss = 4.2670  Validation loss = 5.3547  \n",
      "\n",
      "Fold: 12  Epoch: 167  Training loss = 4.2667  Validation loss = 5.3543  \n",
      "\n",
      "Fold: 12  Epoch: 168  Training loss = 4.2664  Validation loss = 5.3539  \n",
      "\n",
      "Fold: 12  Epoch: 169  Training loss = 4.2661  Validation loss = 5.3535  \n",
      "\n",
      "Fold: 12  Epoch: 170  Training loss = 4.2658  Validation loss = 5.3530  \n",
      "\n",
      "Fold: 12  Epoch: 171  Training loss = 4.2655  Validation loss = 5.3526  \n",
      "\n",
      "Fold: 12  Epoch: 172  Training loss = 4.2651  Validation loss = 5.3521  \n",
      "\n",
      "Fold: 12  Epoch: 173  Training loss = 4.2648  Validation loss = 5.3516  \n",
      "\n",
      "Fold: 12  Epoch: 174  Training loss = 4.2645  Validation loss = 5.3513  \n",
      "\n",
      "Fold: 12  Epoch: 175  Training loss = 4.2642  Validation loss = 5.3509  \n",
      "\n",
      "Fold: 12  Epoch: 176  Training loss = 4.2640  Validation loss = 5.3505  \n",
      "\n",
      "Fold: 12  Epoch: 177  Training loss = 4.2638  Validation loss = 5.3502  \n",
      "\n",
      "Fold: 12  Epoch: 178  Training loss = 4.2635  Validation loss = 5.3499  \n",
      "\n",
      "Fold: 12  Epoch: 179  Training loss = 4.2632  Validation loss = 5.3495  \n",
      "\n",
      "Fold: 12  Epoch: 180  Training loss = 4.2629  Validation loss = 5.3491  \n",
      "\n",
      "Fold: 12  Epoch: 181  Training loss = 4.2627  Validation loss = 5.3487  \n",
      "\n",
      "Fold: 12  Epoch: 182  Training loss = 4.2624  Validation loss = 5.3484  \n",
      "\n",
      "Fold: 12  Epoch: 183  Training loss = 4.2621  Validation loss = 5.3480  \n",
      "\n",
      "Fold: 12  Epoch: 184  Training loss = 4.2618  Validation loss = 5.3475  \n",
      "\n",
      "Fold: 12  Epoch: 185  Training loss = 4.2615  Validation loss = 5.3471  \n",
      "\n",
      "Fold: 12  Epoch: 186  Training loss = 4.2612  Validation loss = 5.3466  \n",
      "\n",
      "Fold: 12  Epoch: 187  Training loss = 4.2609  Validation loss = 5.3462  \n",
      "\n",
      "Fold: 12  Epoch: 188  Training loss = 4.2606  Validation loss = 5.3458  \n",
      "\n",
      "Fold: 12  Epoch: 189  Training loss = 4.2603  Validation loss = 5.3454  \n",
      "\n",
      "Fold: 12  Epoch: 190  Training loss = 4.2600  Validation loss = 5.3449  \n",
      "\n",
      "Fold: 12  Epoch: 191  Training loss = 4.2596  Validation loss = 5.3444  \n",
      "\n",
      "Fold: 12  Epoch: 192  Training loss = 4.2593  Validation loss = 5.3440  \n",
      "\n",
      "Fold: 12  Epoch: 193  Training loss = 4.2590  Validation loss = 5.3435  \n",
      "\n",
      "Fold: 12  Epoch: 194  Training loss = 4.2586  Validation loss = 5.3430  \n",
      "\n",
      "Fold: 12  Epoch: 195  Training loss = 4.2583  Validation loss = 5.3426  \n",
      "\n",
      "Fold: 12  Epoch: 196  Training loss = 4.2581  Validation loss = 5.3423  \n",
      "\n",
      "Fold: 12  Epoch: 197  Training loss = 4.2578  Validation loss = 5.3419  \n",
      "\n",
      "Fold: 12  Epoch: 198  Training loss = 4.2575  Validation loss = 5.3415  \n",
      "\n",
      "Fold: 12  Epoch: 199  Training loss = 4.2572  Validation loss = 5.3410  \n",
      "\n",
      "Fold: 12  Epoch: 200  Training loss = 4.2569  Validation loss = 5.3406  \n",
      "\n",
      "Fold: 12  Epoch: 201  Training loss = 4.2566  Validation loss = 5.3401  \n",
      "\n",
      "Fold: 12  Epoch: 202  Training loss = 4.2562  Validation loss = 5.3397  \n",
      "\n",
      "Fold: 12  Epoch: 203  Training loss = 4.2559  Validation loss = 5.3392  \n",
      "\n",
      "Fold: 12  Epoch: 204  Training loss = 4.2557  Validation loss = 5.3389  \n",
      "\n",
      "Fold: 12  Epoch: 205  Training loss = 4.2554  Validation loss = 5.3385  \n",
      "\n",
      "Fold: 12  Epoch: 206  Training loss = 4.2551  Validation loss = 5.3381  \n",
      "\n",
      "Fold: 12  Epoch: 207  Training loss = 4.2547  Validation loss = 5.3376  \n",
      "\n",
      "Fold: 12  Epoch: 208  Training loss = 4.2544  Validation loss = 5.3372  \n",
      "\n",
      "Fold: 12  Epoch: 209  Training loss = 4.2541  Validation loss = 5.3367  \n",
      "\n",
      "Fold: 12  Epoch: 210  Training loss = 4.2539  Validation loss = 5.3364  \n",
      "\n",
      "Fold: 12  Epoch: 211  Training loss = 4.2536  Validation loss = 5.3361  \n",
      "\n",
      "Fold: 12  Epoch: 212  Training loss = 4.2533  Validation loss = 5.3356  \n",
      "\n",
      "Fold: 12  Epoch: 213  Training loss = 4.2530  Validation loss = 5.3352  \n",
      "\n",
      "Fold: 12  Epoch: 214  Training loss = 4.2527  Validation loss = 5.3348  \n",
      "\n",
      "Fold: 12  Epoch: 215  Training loss = 4.2524  Validation loss = 5.3343  \n",
      "\n",
      "Fold: 12  Epoch: 216  Training loss = 4.2521  Validation loss = 5.3338  \n",
      "\n",
      "Fold: 12  Epoch: 217  Training loss = 4.2518  Validation loss = 5.3335  \n",
      "\n",
      "Fold: 12  Epoch: 218  Training loss = 4.2514  Validation loss = 5.3330  \n",
      "\n",
      "Fold: 12  Epoch: 219  Training loss = 4.2512  Validation loss = 5.3326  \n",
      "\n",
      "Fold: 12  Epoch: 220  Training loss = 4.2508  Validation loss = 5.3321  \n",
      "\n",
      "Fold: 12  Epoch: 221  Training loss = 4.2505  Validation loss = 5.3316  \n",
      "\n",
      "Fold: 12  Epoch: 222  Training loss = 4.2502  Validation loss = 5.3313  \n",
      "\n",
      "Fold: 12  Epoch: 223  Training loss = 4.2499  Validation loss = 5.3308  \n",
      "\n",
      "Fold: 12  Epoch: 224  Training loss = 4.2496  Validation loss = 5.3303  \n",
      "\n",
      "Fold: 12  Epoch: 225  Training loss = 4.2493  Validation loss = 5.3299  \n",
      "\n",
      "Fold: 12  Epoch: 226  Training loss = 4.2490  Validation loss = 5.3295  \n",
      "\n",
      "Fold: 12  Epoch: 227  Training loss = 4.2487  Validation loss = 5.3292  \n",
      "\n",
      "Fold: 12  Epoch: 228  Training loss = 4.2485  Validation loss = 5.3288  \n",
      "\n",
      "Fold: 12  Epoch: 229  Training loss = 4.2481  Validation loss = 5.3283  \n",
      "\n",
      "Fold: 12  Epoch: 230  Training loss = 4.2478  Validation loss = 5.3278  \n",
      "\n",
      "Fold: 12  Epoch: 231  Training loss = 4.2475  Validation loss = 5.3274  \n",
      "\n",
      "Fold: 12  Epoch: 232  Training loss = 4.2472  Validation loss = 5.3270  \n",
      "\n",
      "Fold: 12  Epoch: 233  Training loss = 4.2469  Validation loss = 5.3266  \n",
      "\n",
      "Fold: 12  Epoch: 234  Training loss = 4.2466  Validation loss = 5.3262  \n",
      "\n",
      "Fold: 12  Epoch: 235  Training loss = 4.2464  Validation loss = 5.3258  \n",
      "\n",
      "Fold: 12  Epoch: 236  Training loss = 4.2461  Validation loss = 5.3254  \n",
      "\n",
      "Fold: 12  Epoch: 237  Training loss = 4.2458  Validation loss = 5.3250  \n",
      "\n",
      "Fold: 12  Epoch: 238  Training loss = 4.2455  Validation loss = 5.3246  \n",
      "\n",
      "Fold: 12  Epoch: 239  Training loss = 4.2452  Validation loss = 5.3242  \n",
      "\n",
      "Fold: 12  Epoch: 240  Training loss = 4.2449  Validation loss = 5.3237  \n",
      "\n",
      "Fold: 12  Epoch: 241  Training loss = 4.2446  Validation loss = 5.3234  \n",
      "\n",
      "Fold: 12  Epoch: 242  Training loss = 4.2444  Validation loss = 5.3230  \n",
      "\n",
      "Fold: 12  Epoch: 243  Training loss = 4.2441  Validation loss = 5.3227  \n",
      "\n",
      "Fold: 12  Epoch: 244  Training loss = 4.2439  Validation loss = 5.3223  \n",
      "\n",
      "Fold: 12  Epoch: 245  Training loss = 4.2436  Validation loss = 5.3219  \n",
      "\n",
      "Fold: 12  Epoch: 246  Training loss = 4.2433  Validation loss = 5.3215  \n",
      "\n",
      "Fold: 12  Epoch: 247  Training loss = 4.2430  Validation loss = 5.3211  \n",
      "\n",
      "Fold: 12  Epoch: 248  Training loss = 4.2427  Validation loss = 5.3207  \n",
      "\n",
      "Fold: 12  Epoch: 249  Training loss = 4.2424  Validation loss = 5.3202  \n",
      "\n",
      "Fold: 12  Epoch: 250  Training loss = 4.2421  Validation loss = 5.3198  \n",
      "\n",
      "Fold: 12  Epoch: 251  Training loss = 4.2418  Validation loss = 5.3194  \n",
      "\n",
      "Fold: 12  Epoch: 252  Training loss = 4.2414  Validation loss = 5.3189  \n",
      "\n",
      "Fold: 12  Epoch: 253  Training loss = 4.2411  Validation loss = 5.3185  \n",
      "\n",
      "Fold: 12  Epoch: 254  Training loss = 4.2409  Validation loss = 5.3181  \n",
      "\n",
      "Fold: 12  Epoch: 255  Training loss = 4.2406  Validation loss = 5.3177  \n",
      "\n",
      "Fold: 12  Epoch: 256  Training loss = 4.2403  Validation loss = 5.3172  \n",
      "\n",
      "Fold: 12  Epoch: 257  Training loss = 4.2400  Validation loss = 5.3168  \n",
      "\n",
      "Fold: 12  Epoch: 258  Training loss = 4.2397  Validation loss = 5.3164  \n",
      "\n",
      "Fold: 12  Epoch: 259  Training loss = 4.2394  Validation loss = 5.3160  \n",
      "\n",
      "Fold: 12  Epoch: 260  Training loss = 4.2392  Validation loss = 5.3157  \n",
      "\n",
      "Fold: 12  Epoch: 261  Training loss = 4.2388  Validation loss = 5.3152  \n",
      "\n",
      "Fold: 12  Epoch: 262  Training loss = 4.2385  Validation loss = 5.3148  \n",
      "\n",
      "Fold: 12  Epoch: 263  Training loss = 4.2382  Validation loss = 5.3143  \n",
      "\n",
      "Fold: 12  Epoch: 264  Training loss = 4.2379  Validation loss = 5.3139  \n",
      "\n",
      "Fold: 12  Epoch: 265  Training loss = 4.2376  Validation loss = 5.3135  \n",
      "\n",
      "Fold: 12  Epoch: 266  Training loss = 4.2373  Validation loss = 5.3131  \n",
      "\n",
      "Fold: 12  Epoch: 267  Training loss = 4.2370  Validation loss = 5.3126  \n",
      "\n",
      "Fold: 12  Epoch: 268  Training loss = 4.2367  Validation loss = 5.3122  \n",
      "\n",
      "Fold: 12  Epoch: 269  Training loss = 4.2364  Validation loss = 5.3118  \n",
      "\n",
      "Fold: 12  Epoch: 270  Training loss = 4.2362  Validation loss = 5.3114  \n",
      "\n",
      "Fold: 12  Epoch: 271  Training loss = 4.2358  Validation loss = 5.3109  \n",
      "\n",
      "Fold: 12  Epoch: 272  Training loss = 4.2355  Validation loss = 5.3104  \n",
      "\n",
      "Fold: 12  Epoch: 273  Training loss = 4.2352  Validation loss = 5.3101  \n",
      "\n",
      "Fold: 12  Epoch: 274  Training loss = 4.2350  Validation loss = 5.3098  \n",
      "\n",
      "Fold: 12  Epoch: 275  Training loss = 4.2347  Validation loss = 5.3093  \n",
      "\n",
      "Fold: 12  Epoch: 276  Training loss = 4.2343  Validation loss = 5.3088  \n",
      "\n",
      "Fold: 12  Epoch: 277  Training loss = 4.2340  Validation loss = 5.3084  \n",
      "\n",
      "Fold: 12  Epoch: 278  Training loss = 4.2337  Validation loss = 5.3080  \n",
      "\n",
      "Fold: 12  Epoch: 279  Training loss = 4.2334  Validation loss = 5.3076  \n",
      "\n",
      "Fold: 12  Epoch: 280  Training loss = 4.2332  Validation loss = 5.3072  \n",
      "\n",
      "Fold: 12  Epoch: 281  Training loss = 4.2329  Validation loss = 5.3068  \n",
      "\n",
      "Fold: 12  Epoch: 282  Training loss = 4.2326  Validation loss = 5.3064  \n",
      "\n",
      "Fold: 12  Epoch: 283  Training loss = 4.2323  Validation loss = 5.3060  \n",
      "\n",
      "Fold: 12  Epoch: 284  Training loss = 4.2320  Validation loss = 5.3055  \n",
      "\n",
      "Fold: 12  Epoch: 285  Training loss = 4.2317  Validation loss = 5.3051  \n",
      "\n",
      "Fold: 12  Epoch: 286  Training loss = 4.2315  Validation loss = 5.3048  \n",
      "\n",
      "Fold: 12  Epoch: 287  Training loss = 4.2312  Validation loss = 5.3044  \n",
      "\n",
      "Fold: 12  Epoch: 288  Training loss = 4.2309  Validation loss = 5.3040  \n",
      "\n",
      "Fold: 12  Epoch: 289  Training loss = 4.2307  Validation loss = 5.3036  \n",
      "\n",
      "Fold: 12  Epoch: 290  Training loss = 4.2304  Validation loss = 5.3032  \n",
      "\n",
      "Fold: 12  Epoch: 291  Training loss = 4.2300  Validation loss = 5.3028  \n",
      "\n",
      "Fold: 12  Epoch: 292  Training loss = 4.2298  Validation loss = 5.3023  \n",
      "\n",
      "Fold: 12  Epoch: 293  Training loss = 4.2294  Validation loss = 5.3019  \n",
      "\n",
      "Fold: 12  Epoch: 294  Training loss = 4.2292  Validation loss = 5.3015  \n",
      "\n",
      "Fold: 12  Epoch: 295  Training loss = 4.2288  Validation loss = 5.3010  \n",
      "\n",
      "Fold: 12  Epoch: 296  Training loss = 4.2285  Validation loss = 5.3006  \n",
      "\n",
      "Fold: 12  Epoch: 297  Training loss = 4.2282  Validation loss = 5.3001  \n",
      "\n",
      "Fold: 12  Epoch: 298  Training loss = 4.2279  Validation loss = 5.2997  \n",
      "\n",
      "Fold: 12  Epoch: 299  Training loss = 4.2276  Validation loss = 5.2993  \n",
      "\n",
      "Fold: 12  Epoch: 300  Training loss = 4.2273  Validation loss = 5.2989  \n",
      "\n",
      "Fold: 12  Epoch: 301  Training loss = 4.2270  Validation loss = 5.2985  \n",
      "\n",
      "Fold: 12  Epoch: 302  Training loss = 4.2268  Validation loss = 5.2981  \n",
      "\n",
      "Fold: 12  Epoch: 303  Training loss = 4.2265  Validation loss = 5.2977  \n",
      "\n",
      "Fold: 12  Epoch: 304  Training loss = 4.2262  Validation loss = 5.2973  \n",
      "\n",
      "Fold: 12  Epoch: 305  Training loss = 4.2259  Validation loss = 5.2968  \n",
      "\n",
      "Fold: 12  Epoch: 306  Training loss = 4.2255  Validation loss = 5.2964  \n",
      "\n",
      "Fold: 12  Epoch: 307  Training loss = 4.2252  Validation loss = 5.2959  \n",
      "\n",
      "Fold: 12  Epoch: 308  Training loss = 4.2249  Validation loss = 5.2955  \n",
      "\n",
      "Fold: 12  Epoch: 309  Training loss = 4.2247  Validation loss = 5.2951  \n",
      "\n",
      "Fold: 12  Epoch: 310  Training loss = 4.2244  Validation loss = 5.2947  \n",
      "\n",
      "Fold: 12  Epoch: 311  Training loss = 4.2240  Validation loss = 5.2942  \n",
      "\n",
      "Fold: 12  Epoch: 312  Training loss = 4.2237  Validation loss = 5.2938  \n",
      "\n",
      "Fold: 12  Epoch: 313  Training loss = 4.2235  Validation loss = 5.2934  \n",
      "\n",
      "Fold: 12  Epoch: 314  Training loss = 4.2231  Validation loss = 5.2929  \n",
      "\n",
      "Fold: 12  Epoch: 315  Training loss = 4.2229  Validation loss = 5.2925  \n",
      "\n",
      "Fold: 12  Epoch: 316  Training loss = 4.2225  Validation loss = 5.2921  \n",
      "\n",
      "Fold: 12  Epoch: 317  Training loss = 4.2222  Validation loss = 5.2916  \n",
      "\n",
      "Fold: 12  Epoch: 318  Training loss = 4.2219  Validation loss = 5.2912  \n",
      "\n",
      "Fold: 12  Epoch: 319  Training loss = 4.2216  Validation loss = 5.2907  \n",
      "\n",
      "Fold: 12  Epoch: 320  Training loss = 4.2212  Validation loss = 5.2902  \n",
      "\n",
      "Fold: 12  Epoch: 321  Training loss = 4.2210  Validation loss = 5.2899  \n",
      "\n",
      "Fold: 12  Epoch: 322  Training loss = 4.2207  Validation loss = 5.2895  \n",
      "\n",
      "Fold: 12  Epoch: 323  Training loss = 4.2204  Validation loss = 5.2890  \n",
      "\n",
      "Fold: 12  Epoch: 324  Training loss = 4.2201  Validation loss = 5.2886  \n",
      "\n",
      "Fold: 12  Epoch: 325  Training loss = 4.2197  Validation loss = 5.2881  \n",
      "\n",
      "Fold: 12  Epoch: 326  Training loss = 4.2194  Validation loss = 5.2877  \n",
      "\n",
      "Fold: 12  Epoch: 327  Training loss = 4.2192  Validation loss = 5.2873  \n",
      "\n",
      "Fold: 12  Epoch: 328  Training loss = 4.2189  Validation loss = 5.2869  \n",
      "\n",
      "Fold: 12  Epoch: 329  Training loss = 4.2186  Validation loss = 5.2864  \n",
      "\n",
      "Fold: 12  Epoch: 330  Training loss = 4.2183  Validation loss = 5.2860  \n",
      "\n",
      "Fold: 12  Epoch: 331  Training loss = 4.2180  Validation loss = 5.2857  \n",
      "\n",
      "Fold: 12  Epoch: 332  Training loss = 4.2178  Validation loss = 5.2853  \n",
      "\n",
      "Fold: 12  Epoch: 333  Training loss = 4.2175  Validation loss = 5.2850  \n",
      "\n",
      "Fold: 12  Epoch: 334  Training loss = 4.2172  Validation loss = 5.2846  \n",
      "\n",
      "Fold: 12  Epoch: 335  Training loss = 4.2170  Validation loss = 5.2842  \n",
      "\n",
      "Fold: 12  Epoch: 336  Training loss = 4.2166  Validation loss = 5.2837  \n",
      "\n",
      "Fold: 12  Epoch: 337  Training loss = 4.2164  Validation loss = 5.2833  \n",
      "\n",
      "Fold: 12  Epoch: 338  Training loss = 4.2160  Validation loss = 5.2828  \n",
      "\n",
      "Fold: 12  Epoch: 339  Training loss = 4.2158  Validation loss = 5.2824  \n",
      "\n",
      "Fold: 12  Epoch: 340  Training loss = 4.2155  Validation loss = 5.2820  \n",
      "\n",
      "Fold: 12  Epoch: 341  Training loss = 4.2152  Validation loss = 5.2816  \n",
      "\n",
      "Fold: 12  Epoch: 342  Training loss = 4.2148  Validation loss = 5.2811  \n",
      "\n",
      "Fold: 12  Epoch: 343  Training loss = 4.2146  Validation loss = 5.2808  \n",
      "\n",
      "Fold: 12  Epoch: 344  Training loss = 4.2143  Validation loss = 5.2803  \n",
      "\n",
      "Fold: 12  Epoch: 345  Training loss = 4.2140  Validation loss = 5.2799  \n",
      "\n",
      "Fold: 12  Epoch: 346  Training loss = 4.2136  Validation loss = 5.2794  \n",
      "\n",
      "Fold: 12  Epoch: 347  Training loss = 4.2133  Validation loss = 5.2790  \n",
      "\n",
      "Fold: 12  Epoch: 348  Training loss = 4.2131  Validation loss = 5.2786  \n",
      "\n",
      "Fold: 12  Epoch: 349  Training loss = 4.2128  Validation loss = 5.2782  \n",
      "\n",
      "Fold: 12  Epoch: 350  Training loss = 4.2125  Validation loss = 5.2778  \n",
      "\n",
      "Fold: 12  Epoch: 351  Training loss = 4.2121  Validation loss = 5.2772  \n",
      "\n",
      "Fold: 12  Epoch: 352  Training loss = 4.2118  Validation loss = 5.2768  \n",
      "\n",
      "Fold: 12  Epoch: 353  Training loss = 4.2115  Validation loss = 5.2763  \n",
      "\n",
      "Fold: 12  Epoch: 354  Training loss = 4.2112  Validation loss = 5.2759  \n",
      "\n",
      "Fold: 12  Epoch: 355  Training loss = 4.2110  Validation loss = 5.2756  \n",
      "\n",
      "Fold: 12  Epoch: 356  Training loss = 4.2106  Validation loss = 5.2751  \n",
      "\n",
      "Fold: 12  Epoch: 357  Training loss = 4.2104  Validation loss = 5.2747  \n",
      "\n",
      "Fold: 12  Epoch: 358  Training loss = 4.2100  Validation loss = 5.2741  \n",
      "\n",
      "Fold: 12  Epoch: 359  Training loss = 4.2097  Validation loss = 5.2737  \n",
      "\n",
      "Fold: 12  Epoch: 360  Training loss = 4.2094  Validation loss = 5.2733  \n",
      "\n",
      "Fold: 12  Epoch: 361  Training loss = 4.2091  Validation loss = 5.2730  \n",
      "\n",
      "Fold: 12  Epoch: 362  Training loss = 4.2089  Validation loss = 5.2726  \n",
      "\n",
      "Fold: 12  Epoch: 363  Training loss = 4.2086  Validation loss = 5.2723  \n",
      "\n",
      "Fold: 12  Epoch: 364  Training loss = 4.2083  Validation loss = 5.2718  \n",
      "\n",
      "Fold: 12  Epoch: 365  Training loss = 4.2080  Validation loss = 5.2714  \n",
      "\n",
      "Fold: 12  Epoch: 366  Training loss = 4.2077  Validation loss = 5.2710  \n",
      "\n",
      "Fold: 12  Epoch: 367  Training loss = 4.2075  Validation loss = 5.2706  \n",
      "\n",
      "Fold: 12  Epoch: 368  Training loss = 4.2073  Validation loss = 5.2703  \n",
      "\n",
      "Fold: 12  Epoch: 369  Training loss = 4.2069  Validation loss = 5.2698  \n",
      "\n",
      "Fold: 12  Epoch: 370  Training loss = 4.2067  Validation loss = 5.2694  \n",
      "\n",
      "Fold: 12  Epoch: 371  Training loss = 4.2064  Validation loss = 5.2690  \n",
      "\n",
      "Fold: 12  Epoch: 372  Training loss = 4.2061  Validation loss = 5.2686  \n",
      "\n",
      "Fold: 12  Epoch: 373  Training loss = 4.2058  Validation loss = 5.2681  \n",
      "\n",
      "Fold: 12  Epoch: 374  Training loss = 4.2055  Validation loss = 5.2677  \n",
      "\n",
      "Fold: 12  Epoch: 375  Training loss = 4.2052  Validation loss = 5.2674  \n",
      "\n",
      "Fold: 12  Epoch: 376  Training loss = 4.2049  Validation loss = 5.2669  \n",
      "\n",
      "Fold: 12  Epoch: 377  Training loss = 4.2046  Validation loss = 5.2665  \n",
      "\n",
      "Fold: 12  Epoch: 378  Training loss = 4.2043  Validation loss = 5.2661  \n",
      "\n",
      "Fold: 12  Epoch: 379  Training loss = 4.2041  Validation loss = 5.2658  \n",
      "\n",
      "Fold: 12  Epoch: 380  Training loss = 4.2039  Validation loss = 5.2654  \n",
      "\n",
      "Fold: 12  Epoch: 381  Training loss = 4.2035  Validation loss = 5.2649  \n",
      "\n",
      "Fold: 12  Epoch: 382  Training loss = 4.2032  Validation loss = 5.2645  \n",
      "\n",
      "Fold: 12  Epoch: 383  Training loss = 4.2029  Validation loss = 5.2641  \n",
      "\n",
      "Fold: 12  Epoch: 384  Training loss = 4.2027  Validation loss = 5.2637  \n",
      "\n",
      "Fold: 12  Epoch: 385  Training loss = 4.2024  Validation loss = 5.2633  \n",
      "\n",
      "Fold: 12  Epoch: 386  Training loss = 4.2022  Validation loss = 5.2630  \n",
      "\n",
      "Fold: 12  Epoch: 387  Training loss = 4.2018  Validation loss = 5.2625  \n",
      "\n",
      "Fold: 12  Epoch: 388  Training loss = 4.2015  Validation loss = 5.2620  \n",
      "\n",
      "Fold: 12  Epoch: 389  Training loss = 4.2012  Validation loss = 5.2616  \n",
      "\n",
      "Fold: 12  Epoch: 390  Training loss = 4.2010  Validation loss = 5.2613  \n",
      "\n",
      "Fold: 12  Epoch: 391  Training loss = 4.2007  Validation loss = 5.2608  \n",
      "\n",
      "Fold: 12  Epoch: 392  Training loss = 4.2004  Validation loss = 5.2604  \n",
      "\n",
      "Fold: 12  Epoch: 393  Training loss = 4.2001  Validation loss = 5.2600  \n",
      "\n",
      "Fold: 12  Epoch: 394  Training loss = 4.1998  Validation loss = 5.2596  \n",
      "\n",
      "Fold: 12  Epoch: 395  Training loss = 4.1995  Validation loss = 5.2592  \n",
      "\n",
      "Fold: 12  Epoch: 396  Training loss = 4.1993  Validation loss = 5.2588  \n",
      "\n",
      "Fold: 12  Epoch: 397  Training loss = 4.1990  Validation loss = 5.2584  \n",
      "\n",
      "Fold: 12  Epoch: 398  Training loss = 4.1987  Validation loss = 5.2580  \n",
      "\n",
      "Fold: 12  Epoch: 399  Training loss = 4.1984  Validation loss = 5.2575  \n",
      "\n",
      "Fold: 12  Epoch: 400  Training loss = 4.1982  Validation loss = 5.2572  \n",
      "\n",
      "Fold: 12  Epoch: 401  Training loss = 4.1978  Validation loss = 5.2568  \n",
      "\n",
      "Fold: 12  Epoch: 402  Training loss = 4.1976  Validation loss = 5.2564  \n",
      "\n",
      "Fold: 12  Epoch: 403  Training loss = 4.1973  Validation loss = 5.2560  \n",
      "\n",
      "Fold: 12  Epoch: 404  Training loss = 4.1971  Validation loss = 5.2556  \n",
      "\n",
      "Fold: 12  Epoch: 405  Training loss = 4.1968  Validation loss = 5.2553  \n",
      "\n",
      "Fold: 12  Epoch: 406  Training loss = 4.1965  Validation loss = 5.2549  \n",
      "\n",
      "Fold: 12  Epoch: 407  Training loss = 4.1962  Validation loss = 5.2544  \n",
      "\n",
      "Fold: 12  Epoch: 408  Training loss = 4.1959  Validation loss = 5.2540  \n",
      "\n",
      "Fold: 12  Epoch: 409  Training loss = 4.1956  Validation loss = 5.2536  \n",
      "\n",
      "Fold: 12  Epoch: 410  Training loss = 4.1954  Validation loss = 5.2532  \n",
      "\n",
      "Fold: 12  Epoch: 411  Training loss = 4.1951  Validation loss = 5.2528  \n",
      "\n",
      "Fold: 12  Epoch: 412  Training loss = 4.1948  Validation loss = 5.2524  \n",
      "\n",
      "Fold: 12  Epoch: 413  Training loss = 4.1945  Validation loss = 5.2519  \n",
      "\n",
      "Fold: 12  Epoch: 414  Training loss = 4.1942  Validation loss = 5.2516  \n",
      "\n",
      "Fold: 12  Epoch: 415  Training loss = 4.1940  Validation loss = 5.2512  \n",
      "\n",
      "Fold: 12  Epoch: 416  Training loss = 4.1937  Validation loss = 5.2508  \n",
      "\n",
      "Fold: 12  Epoch: 417  Training loss = 4.1934  Validation loss = 5.2504  \n",
      "\n",
      "Fold: 12  Epoch: 418  Training loss = 4.1931  Validation loss = 5.2499  \n",
      "\n",
      "Fold: 12  Epoch: 419  Training loss = 4.1928  Validation loss = 5.2495  \n",
      "\n",
      "Fold: 12  Epoch: 420  Training loss = 4.1926  Validation loss = 5.2493  \n",
      "\n",
      "Fold: 12  Epoch: 421  Training loss = 4.1923  Validation loss = 5.2488  \n",
      "\n",
      "Fold: 12  Epoch: 422  Training loss = 4.1920  Validation loss = 5.2484  \n",
      "\n",
      "Fold: 12  Epoch: 423  Training loss = 4.1917  Validation loss = 5.2480  \n",
      "\n",
      "Fold: 12  Epoch: 424  Training loss = 4.1915  Validation loss = 5.2477  \n",
      "\n",
      "Fold: 12  Epoch: 425  Training loss = 4.1912  Validation loss = 5.2472  \n",
      "\n",
      "Fold: 12  Epoch: 426  Training loss = 4.1910  Validation loss = 5.2469  \n",
      "\n",
      "Fold: 12  Epoch: 427  Training loss = 4.1907  Validation loss = 5.2465  \n",
      "\n",
      "Fold: 12  Epoch: 428  Training loss = 4.1904  Validation loss = 5.2460  \n",
      "\n",
      "Fold: 12  Epoch: 429  Training loss = 4.1902  Validation loss = 5.2457  \n",
      "\n",
      "Fold: 12  Epoch: 430  Training loss = 4.1898  Validation loss = 5.2452  \n",
      "\n",
      "Fold: 12  Epoch: 431  Training loss = 4.1895  Validation loss = 5.2448  \n",
      "\n",
      "Fold: 12  Epoch: 432  Training loss = 4.1892  Validation loss = 5.2443  \n",
      "\n",
      "Fold: 12  Epoch: 433  Training loss = 4.1889  Validation loss = 5.2439  \n",
      "\n",
      "Fold: 12  Epoch: 434  Training loss = 4.1886  Validation loss = 5.2434  \n",
      "\n",
      "Fold: 12  Epoch: 435  Training loss = 4.1884  Validation loss = 5.2431  \n",
      "\n",
      "Fold: 12  Epoch: 436  Training loss = 4.1881  Validation loss = 5.2427  \n",
      "\n",
      "Fold: 12  Epoch: 437  Training loss = 4.1878  Validation loss = 5.2422  \n",
      "\n",
      "Fold: 12  Epoch: 438  Training loss = 4.1874  Validation loss = 5.2418  \n",
      "\n",
      "Fold: 12  Epoch: 439  Training loss = 4.1872  Validation loss = 5.2414  \n",
      "\n",
      "Fold: 12  Epoch: 440  Training loss = 4.1869  Validation loss = 5.2409  \n",
      "\n",
      "Fold: 12  Epoch: 441  Training loss = 4.1866  Validation loss = 5.2406  \n",
      "\n",
      "Fold: 12  Epoch: 442  Training loss = 4.1863  Validation loss = 5.2401  \n",
      "\n",
      "Fold: 12  Epoch: 443  Training loss = 4.1859  Validation loss = 5.2396  \n",
      "\n",
      "Fold: 12  Epoch: 444  Training loss = 4.1857  Validation loss = 5.2392  \n",
      "\n",
      "Fold: 12  Epoch: 445  Training loss = 4.1853  Validation loss = 5.2387  \n",
      "\n",
      "Fold: 12  Epoch: 446  Training loss = 4.1850  Validation loss = 5.2383  \n",
      "\n",
      "Fold: 12  Epoch: 447  Training loss = 4.1847  Validation loss = 5.2379  \n",
      "\n",
      "Fold: 12  Epoch: 448  Training loss = 4.1845  Validation loss = 5.2375  \n",
      "\n",
      "Fold: 12  Epoch: 449  Training loss = 4.1842  Validation loss = 5.2371  \n",
      "\n",
      "Fold: 12  Epoch: 450  Training loss = 4.1839  Validation loss = 5.2367  \n",
      "\n",
      "Fold: 12  Epoch: 451  Training loss = 4.1836  Validation loss = 5.2362  \n",
      "\n",
      "Fold: 12  Epoch: 452  Training loss = 4.1833  Validation loss = 5.2358  \n",
      "\n",
      "Fold: 12  Epoch: 453  Training loss = 4.1830  Validation loss = 5.2354  \n",
      "\n",
      "Fold: 12  Epoch: 454  Training loss = 4.1828  Validation loss = 5.2350  \n",
      "\n",
      "Fold: 12  Epoch: 455  Training loss = 4.1825  Validation loss = 5.2347  \n",
      "\n",
      "Fold: 12  Epoch: 456  Training loss = 4.1823  Validation loss = 5.2344  \n",
      "\n",
      "Fold: 12  Epoch: 457  Training loss = 4.1820  Validation loss = 5.2339  \n",
      "\n",
      "Fold: 12  Epoch: 458  Training loss = 4.1817  Validation loss = 5.2335  \n",
      "\n",
      "Fold: 12  Epoch: 459  Training loss = 4.1814  Validation loss = 5.2331  \n",
      "\n",
      "Fold: 12  Epoch: 460  Training loss = 4.1811  Validation loss = 5.2325  \n",
      "\n",
      "Fold: 12  Epoch: 461  Training loss = 4.1808  Validation loss = 5.2321  \n",
      "\n",
      "Fold: 12  Epoch: 462  Training loss = 4.1805  Validation loss = 5.2317  \n",
      "\n",
      "Fold: 12  Epoch: 463  Training loss = 4.1803  Validation loss = 5.2314  \n",
      "\n",
      "Fold: 12  Epoch: 464  Training loss = 4.1800  Validation loss = 5.2310  \n",
      "\n",
      "Fold: 12  Epoch: 465  Training loss = 4.1797  Validation loss = 5.2306  \n",
      "\n",
      "Fold: 12  Epoch: 466  Training loss = 4.1794  Validation loss = 5.2302  \n",
      "\n",
      "Fold: 12  Epoch: 467  Training loss = 4.1792  Validation loss = 5.2299  \n",
      "\n",
      "Fold: 12  Epoch: 468  Training loss = 4.1789  Validation loss = 5.2295  \n",
      "\n",
      "Fold: 12  Epoch: 469  Training loss = 4.1787  Validation loss = 5.2291  \n",
      "\n",
      "Fold: 12  Epoch: 470  Training loss = 4.1784  Validation loss = 5.2287  \n",
      "\n",
      "Fold: 12  Epoch: 471  Training loss = 4.1781  Validation loss = 5.2282  \n",
      "\n",
      "Fold: 12  Epoch: 472  Training loss = 4.1778  Validation loss = 5.2278  \n",
      "\n",
      "Fold: 12  Epoch: 473  Training loss = 4.1775  Validation loss = 5.2274  \n",
      "\n",
      "Fold: 12  Epoch: 474  Training loss = 4.1772  Validation loss = 5.2270  \n",
      "\n",
      "Fold: 12  Epoch: 475  Training loss = 4.1769  Validation loss = 5.2266  \n",
      "\n",
      "Fold: 12  Epoch: 476  Training loss = 4.1766  Validation loss = 5.2261  \n",
      "\n",
      "Fold: 12  Epoch: 477  Training loss = 4.1763  Validation loss = 5.2256  \n",
      "\n",
      "Fold: 12  Epoch: 478  Training loss = 4.1760  Validation loss = 5.2252  \n",
      "\n",
      "Fold: 12  Epoch: 479  Training loss = 4.1757  Validation loss = 5.2248  \n",
      "\n",
      "Fold: 12  Epoch: 480  Training loss = 4.1754  Validation loss = 5.2243  \n",
      "\n",
      "Fold: 12  Epoch: 481  Training loss = 4.1751  Validation loss = 5.2239  \n",
      "\n",
      "Fold: 12  Epoch: 482  Training loss = 4.1748  Validation loss = 5.2235  \n",
      "\n",
      "Fold: 12  Epoch: 483  Training loss = 4.1746  Validation loss = 5.2231  \n",
      "\n",
      "Fold: 12  Epoch: 484  Training loss = 4.1743  Validation loss = 5.2228  \n",
      "\n",
      "Fold: 12  Epoch: 485  Training loss = 4.1740  Validation loss = 5.2224  \n",
      "\n",
      "Fold: 12  Epoch: 486  Training loss = 4.1737  Validation loss = 5.2219  \n",
      "\n",
      "Fold: 12  Epoch: 487  Training loss = 4.1734  Validation loss = 5.2214  \n",
      "\n",
      "Fold: 12  Epoch: 488  Training loss = 4.1731  Validation loss = 5.2210  \n",
      "\n",
      "Fold: 12  Epoch: 489  Training loss = 4.1728  Validation loss = 5.2205  \n",
      "\n",
      "Fold: 12  Epoch: 490  Training loss = 4.1725  Validation loss = 5.2201  \n",
      "\n",
      "Fold: 12  Epoch: 491  Training loss = 4.1722  Validation loss = 5.2197  \n",
      "\n",
      "Fold: 12  Epoch: 492  Training loss = 4.1718  Validation loss = 5.2191  \n",
      "\n",
      "Fold: 12  Epoch: 493  Training loss = 4.1716  Validation loss = 5.2188  \n",
      "\n",
      "Fold: 12  Epoch: 494  Training loss = 4.1713  Validation loss = 5.2184  \n",
      "\n",
      "Fold: 12  Epoch: 495  Training loss = 4.1711  Validation loss = 5.2180  \n",
      "\n",
      "Fold: 12  Epoch: 496  Training loss = 4.1707  Validation loss = 5.2176  \n",
      "\n",
      "Fold: 12  Epoch: 497  Training loss = 4.1705  Validation loss = 5.2172  \n",
      "\n",
      "Fold: 12  Epoch: 498  Training loss = 4.1702  Validation loss = 5.2168  \n",
      "\n",
      "Fold: 12  Epoch: 499  Training loss = 4.1699  Validation loss = 5.2164  \n",
      "\n",
      "Fold: 12  Epoch: 500  Training loss = 4.1696  Validation loss = 5.2159  \n",
      "\n",
      "Check model:  Fold: 12  Optimal epoch: 500  \n",
      "\n",
      "Fold: 13  Epoch: 1  Training loss = 4.3538  Validation loss = 7.6261  \n",
      "\n",
      "Fold: 13  Epoch: 2  Training loss = 4.3534  Validation loss = 7.6254  \n",
      "\n",
      "Fold: 13  Epoch: 3  Training loss = 4.3530  Validation loss = 7.6248  \n",
      "\n",
      "Fold: 13  Epoch: 4  Training loss = 4.3526  Validation loss = 7.6242  \n",
      "\n",
      "Fold: 13  Epoch: 5  Training loss = 4.3523  Validation loss = 7.6237  \n",
      "\n",
      "Fold: 13  Epoch: 6  Training loss = 4.3519  Validation loss = 7.6231  \n",
      "\n",
      "Fold: 13  Epoch: 7  Training loss = 4.3516  Validation loss = 7.6226  \n",
      "\n",
      "Fold: 13  Epoch: 8  Training loss = 4.3513  Validation loss = 7.6221  \n",
      "\n",
      "Fold: 13  Epoch: 9  Training loss = 4.3510  Validation loss = 7.6216  \n",
      "\n",
      "Fold: 13  Epoch: 10  Training loss = 4.3506  Validation loss = 7.6211  \n",
      "\n",
      "Fold: 13  Epoch: 11  Training loss = 4.3503  Validation loss = 7.6204  \n",
      "\n",
      "Fold: 13  Epoch: 12  Training loss = 4.3499  Validation loss = 7.6199  \n",
      "\n",
      "Fold: 13  Epoch: 13  Training loss = 4.3497  Validation loss = 7.6194  \n",
      "\n",
      "Fold: 13  Epoch: 14  Training loss = 4.3493  Validation loss = 7.6189  \n",
      "\n",
      "Fold: 13  Epoch: 15  Training loss = 4.3490  Validation loss = 7.6183  \n",
      "\n",
      "Fold: 13  Epoch: 16  Training loss = 4.3486  Validation loss = 7.6177  \n",
      "\n",
      "Fold: 13  Epoch: 17  Training loss = 4.3482  Validation loss = 7.6171  \n",
      "\n",
      "Fold: 13  Epoch: 18  Training loss = 4.3479  Validation loss = 7.6164  \n",
      "\n",
      "Fold: 13  Epoch: 19  Training loss = 4.3475  Validation loss = 7.6158  \n",
      "\n",
      "Fold: 13  Epoch: 20  Training loss = 4.3472  Validation loss = 7.6153  \n",
      "\n",
      "Fold: 13  Epoch: 21  Training loss = 4.3469  Validation loss = 7.6147  \n",
      "\n",
      "Fold: 13  Epoch: 22  Training loss = 4.3465  Validation loss = 7.6142  \n",
      "\n",
      "Fold: 13  Epoch: 23  Training loss = 4.3462  Validation loss = 7.6137  \n",
      "\n",
      "Fold: 13  Epoch: 24  Training loss = 4.3458  Validation loss = 7.6131  \n",
      "\n",
      "Fold: 13  Epoch: 25  Training loss = 4.3454  Validation loss = 7.6125  \n",
      "\n",
      "Fold: 13  Epoch: 26  Training loss = 4.3450  Validation loss = 7.6118  \n",
      "\n",
      "Fold: 13  Epoch: 27  Training loss = 4.3447  Validation loss = 7.6114  \n",
      "\n",
      "Fold: 13  Epoch: 28  Training loss = 4.3444  Validation loss = 7.6109  \n",
      "\n",
      "Fold: 13  Epoch: 29  Training loss = 4.3441  Validation loss = 7.6105  \n",
      "\n",
      "Fold: 13  Epoch: 30  Training loss = 4.3438  Validation loss = 7.6100  \n",
      "\n",
      "Fold: 13  Epoch: 31  Training loss = 4.3435  Validation loss = 7.6095  \n",
      "\n",
      "Fold: 13  Epoch: 32  Training loss = 4.3431  Validation loss = 7.6088  \n",
      "\n",
      "Fold: 13  Epoch: 33  Training loss = 4.3427  Validation loss = 7.6083  \n",
      "\n",
      "Fold: 13  Epoch: 34  Training loss = 4.3424  Validation loss = 7.6078  \n",
      "\n",
      "Fold: 13  Epoch: 35  Training loss = 4.3420  Validation loss = 7.6071  \n",
      "\n",
      "Fold: 13  Epoch: 36  Training loss = 4.3416  Validation loss = 7.6066  \n",
      "\n",
      "Fold: 13  Epoch: 37  Training loss = 4.3413  Validation loss = 7.6059  \n",
      "\n",
      "Fold: 13  Epoch: 38  Training loss = 4.3410  Validation loss = 7.6054  \n",
      "\n",
      "Fold: 13  Epoch: 39  Training loss = 4.3406  Validation loss = 7.6049  \n",
      "\n",
      "Fold: 13  Epoch: 40  Training loss = 4.3402  Validation loss = 7.6042  \n",
      "\n",
      "Fold: 13  Epoch: 41  Training loss = 4.3399  Validation loss = 7.6037  \n",
      "\n",
      "Fold: 13  Epoch: 42  Training loss = 4.3395  Validation loss = 7.6031  \n",
      "\n",
      "Fold: 13  Epoch: 43  Training loss = 4.3392  Validation loss = 7.6024  \n",
      "\n",
      "Fold: 13  Epoch: 44  Training loss = 4.3388  Validation loss = 7.6019  \n",
      "\n",
      "Fold: 13  Epoch: 45  Training loss = 4.3384  Validation loss = 7.6011  \n",
      "\n",
      "Fold: 13  Epoch: 46  Training loss = 4.3381  Validation loss = 7.6006  \n",
      "\n",
      "Fold: 13  Epoch: 47  Training loss = 4.3377  Validation loss = 7.6000  \n",
      "\n",
      "Fold: 13  Epoch: 48  Training loss = 4.3374  Validation loss = 7.5995  \n",
      "\n",
      "Fold: 13  Epoch: 49  Training loss = 4.3371  Validation loss = 7.5991  \n",
      "\n",
      "Fold: 13  Epoch: 50  Training loss = 4.3367  Validation loss = 7.5984  \n",
      "\n",
      "Fold: 13  Epoch: 51  Training loss = 4.3365  Validation loss = 7.5980  \n",
      "\n",
      "Fold: 13  Epoch: 52  Training loss = 4.3361  Validation loss = 7.5975  \n",
      "\n",
      "Fold: 13  Epoch: 53  Training loss = 4.3358  Validation loss = 7.5970  \n",
      "\n",
      "Fold: 13  Epoch: 54  Training loss = 4.3355  Validation loss = 7.5965  \n",
      "\n",
      "Fold: 13  Epoch: 55  Training loss = 4.3352  Validation loss = 7.5960  \n",
      "\n",
      "Fold: 13  Epoch: 56  Training loss = 4.3349  Validation loss = 7.5955  \n",
      "\n",
      "Fold: 13  Epoch: 57  Training loss = 4.3345  Validation loss = 7.5950  \n",
      "\n",
      "Fold: 13  Epoch: 58  Training loss = 4.3341  Validation loss = 7.5944  \n",
      "\n",
      "Fold: 13  Epoch: 59  Training loss = 4.3338  Validation loss = 7.5939  \n",
      "\n",
      "Fold: 13  Epoch: 60  Training loss = 4.3335  Validation loss = 7.5933  \n",
      "\n",
      "Fold: 13  Epoch: 61  Training loss = 4.3332  Validation loss = 7.5928  \n",
      "\n",
      "Fold: 13  Epoch: 62  Training loss = 4.3328  Validation loss = 7.5922  \n",
      "\n",
      "Fold: 13  Epoch: 63  Training loss = 4.3325  Validation loss = 7.5916  \n",
      "\n",
      "Fold: 13  Epoch: 64  Training loss = 4.3322  Validation loss = 7.5911  \n",
      "\n",
      "Fold: 13  Epoch: 65  Training loss = 4.3318  Validation loss = 7.5904  \n",
      "\n",
      "Fold: 13  Epoch: 66  Training loss = 4.3315  Validation loss = 7.5900  \n",
      "\n",
      "Fold: 13  Epoch: 67  Training loss = 4.3310  Validation loss = 7.5892  \n",
      "\n",
      "Fold: 13  Epoch: 68  Training loss = 4.3307  Validation loss = 7.5886  \n",
      "\n",
      "Fold: 13  Epoch: 69  Training loss = 4.3304  Validation loss = 7.5881  \n",
      "\n",
      "Fold: 13  Epoch: 70  Training loss = 4.3301  Validation loss = 7.5877  \n",
      "\n",
      "Fold: 13  Epoch: 71  Training loss = 4.3297  Validation loss = 7.5871  \n",
      "\n",
      "Fold: 13  Epoch: 72  Training loss = 4.3294  Validation loss = 7.5866  \n",
      "\n",
      "Fold: 13  Epoch: 73  Training loss = 4.3290  Validation loss = 7.5860  \n",
      "\n",
      "Fold: 13  Epoch: 74  Training loss = 4.3287  Validation loss = 7.5854  \n",
      "\n",
      "Fold: 13  Epoch: 75  Training loss = 4.3283  Validation loss = 7.5849  \n",
      "\n",
      "Fold: 13  Epoch: 76  Training loss = 4.3279  Validation loss = 7.5842  \n",
      "\n",
      "Fold: 13  Epoch: 77  Training loss = 4.3276  Validation loss = 7.5837  \n",
      "\n",
      "Fold: 13  Epoch: 78  Training loss = 4.3273  Validation loss = 7.5832  \n",
      "\n",
      "Fold: 13  Epoch: 79  Training loss = 4.3269  Validation loss = 7.5825  \n",
      "\n",
      "Fold: 13  Epoch: 80  Training loss = 4.3265  Validation loss = 7.5819  \n",
      "\n",
      "Fold: 13  Epoch: 81  Training loss = 4.3262  Validation loss = 7.5815  \n",
      "\n",
      "Fold: 13  Epoch: 82  Training loss = 4.3259  Validation loss = 7.5809  \n",
      "\n",
      "Fold: 13  Epoch: 83  Training loss = 4.3256  Validation loss = 7.5803  \n",
      "\n",
      "Fold: 13  Epoch: 84  Training loss = 4.3253  Validation loss = 7.5798  \n",
      "\n",
      "Fold: 13  Epoch: 85  Training loss = 4.3249  Validation loss = 7.5792  \n",
      "\n",
      "Fold: 13  Epoch: 86  Training loss = 4.3245  Validation loss = 7.5786  \n",
      "\n",
      "Fold: 13  Epoch: 87  Training loss = 4.3242  Validation loss = 7.5780  \n",
      "\n",
      "Fold: 13  Epoch: 88  Training loss = 4.3239  Validation loss = 7.5776  \n",
      "\n",
      "Fold: 13  Epoch: 89  Training loss = 4.3235  Validation loss = 7.5771  \n",
      "\n",
      "Fold: 13  Epoch: 90  Training loss = 4.3232  Validation loss = 7.5765  \n",
      "\n",
      "Fold: 13  Epoch: 91  Training loss = 4.3228  Validation loss = 7.5760  \n",
      "\n",
      "Fold: 13  Epoch: 92  Training loss = 4.3225  Validation loss = 7.5754  \n",
      "\n",
      "Fold: 13  Epoch: 93  Training loss = 4.3220  Validation loss = 7.5748  \n",
      "\n",
      "Fold: 13  Epoch: 94  Training loss = 4.3216  Validation loss = 7.5741  \n",
      "\n",
      "Fold: 13  Epoch: 95  Training loss = 4.3213  Validation loss = 7.5735  \n",
      "\n",
      "Fold: 13  Epoch: 96  Training loss = 4.3210  Validation loss = 7.5729  \n",
      "\n",
      "Fold: 13  Epoch: 97  Training loss = 4.3207  Validation loss = 7.5725  \n",
      "\n",
      "Fold: 13  Epoch: 98  Training loss = 4.3204  Validation loss = 7.5719  \n",
      "\n",
      "Fold: 13  Epoch: 99  Training loss = 4.3200  Validation loss = 7.5713  \n",
      "\n",
      "Fold: 13  Epoch: 100  Training loss = 4.3197  Validation loss = 7.5707  \n",
      "\n",
      "Fold: 13  Epoch: 101  Training loss = 4.3193  Validation loss = 7.5701  \n",
      "\n",
      "Fold: 13  Epoch: 102  Training loss = 4.3190  Validation loss = 7.5695  \n",
      "\n",
      "Fold: 13  Epoch: 103  Training loss = 4.3186  Validation loss = 7.5690  \n",
      "\n",
      "Fold: 13  Epoch: 104  Training loss = 4.3184  Validation loss = 7.5685  \n",
      "\n",
      "Fold: 13  Epoch: 105  Training loss = 4.3180  Validation loss = 7.5679  \n",
      "\n",
      "Fold: 13  Epoch: 106  Training loss = 4.3177  Validation loss = 7.5674  \n",
      "\n",
      "Fold: 13  Epoch: 107  Training loss = 4.3174  Validation loss = 7.5669  \n",
      "\n",
      "Fold: 13  Epoch: 108  Training loss = 4.3170  Validation loss = 7.5662  \n",
      "\n",
      "Fold: 13  Epoch: 109  Training loss = 4.3166  Validation loss = 7.5656  \n",
      "\n",
      "Fold: 13  Epoch: 110  Training loss = 4.3163  Validation loss = 7.5651  \n",
      "\n",
      "Fold: 13  Epoch: 111  Training loss = 4.3160  Validation loss = 7.5646  \n",
      "\n",
      "Fold: 13  Epoch: 112  Training loss = 4.3156  Validation loss = 7.5639  \n",
      "\n",
      "Fold: 13  Epoch: 113  Training loss = 4.3152  Validation loss = 7.5634  \n",
      "\n",
      "Fold: 13  Epoch: 114  Training loss = 4.3149  Validation loss = 7.5629  \n",
      "\n",
      "Fold: 13  Epoch: 115  Training loss = 4.3146  Validation loss = 7.5624  \n",
      "\n",
      "Fold: 13  Epoch: 116  Training loss = 4.3143  Validation loss = 7.5619  \n",
      "\n",
      "Fold: 13  Epoch: 117  Training loss = 4.3139  Validation loss = 7.5613  \n",
      "\n",
      "Fold: 13  Epoch: 118  Training loss = 4.3136  Validation loss = 7.5607  \n",
      "\n",
      "Fold: 13  Epoch: 119  Training loss = 4.3131  Validation loss = 7.5599  \n",
      "\n",
      "Fold: 13  Epoch: 120  Training loss = 4.3128  Validation loss = 7.5593  \n",
      "\n",
      "Fold: 13  Epoch: 121  Training loss = 4.3125  Validation loss = 7.5588  \n",
      "\n",
      "Fold: 13  Epoch: 122  Training loss = 4.3121  Validation loss = 7.5580  \n",
      "\n",
      "Fold: 13  Epoch: 123  Training loss = 4.3118  Validation loss = 7.5575  \n",
      "\n",
      "Fold: 13  Epoch: 124  Training loss = 4.3115  Validation loss = 7.5571  \n",
      "\n",
      "Fold: 13  Epoch: 125  Training loss = 4.3111  Validation loss = 7.5564  \n",
      "\n",
      "Fold: 13  Epoch: 126  Training loss = 4.3108  Validation loss = 7.5560  \n",
      "\n",
      "Fold: 13  Epoch: 127  Training loss = 4.3105  Validation loss = 7.5555  \n",
      "\n",
      "Fold: 13  Epoch: 128  Training loss = 4.3102  Validation loss = 7.5550  \n",
      "\n",
      "Fold: 13  Epoch: 129  Training loss = 4.3099  Validation loss = 7.5545  \n",
      "\n",
      "Fold: 13  Epoch: 130  Training loss = 4.3095  Validation loss = 7.5538  \n",
      "\n",
      "Fold: 13  Epoch: 131  Training loss = 4.3091  Validation loss = 7.5532  \n",
      "\n",
      "Fold: 13  Epoch: 132  Training loss = 4.3088  Validation loss = 7.5526  \n",
      "\n",
      "Fold: 13  Epoch: 133  Training loss = 4.3085  Validation loss = 7.5521  \n",
      "\n",
      "Fold: 13  Epoch: 134  Training loss = 4.3081  Validation loss = 7.5516  \n",
      "\n",
      "Fold: 13  Epoch: 135  Training loss = 4.3079  Validation loss = 7.5512  \n",
      "\n",
      "Fold: 13  Epoch: 136  Training loss = 4.3076  Validation loss = 7.5506  \n",
      "\n",
      "Fold: 13  Epoch: 137  Training loss = 4.3072  Validation loss = 7.5500  \n",
      "\n",
      "Fold: 13  Epoch: 138  Training loss = 4.3069  Validation loss = 7.5495  \n",
      "\n",
      "Fold: 13  Epoch: 139  Training loss = 4.3065  Validation loss = 7.5489  \n",
      "\n",
      "Fold: 13  Epoch: 140  Training loss = 4.3062  Validation loss = 7.5483  \n",
      "\n",
      "Fold: 13  Epoch: 141  Training loss = 4.3059  Validation loss = 7.5477  \n",
      "\n",
      "Fold: 13  Epoch: 142  Training loss = 4.3056  Validation loss = 7.5473  \n",
      "\n",
      "Fold: 13  Epoch: 143  Training loss = 4.3052  Validation loss = 7.5466  \n",
      "\n",
      "Fold: 13  Epoch: 144  Training loss = 4.3050  Validation loss = 7.5462  \n",
      "\n",
      "Fold: 13  Epoch: 145  Training loss = 4.3046  Validation loss = 7.5457  \n",
      "\n",
      "Fold: 13  Epoch: 146  Training loss = 4.3043  Validation loss = 7.5452  \n",
      "\n",
      "Fold: 13  Epoch: 147  Training loss = 4.3040  Validation loss = 7.5446  \n",
      "\n",
      "Fold: 13  Epoch: 148  Training loss = 4.3036  Validation loss = 7.5440  \n",
      "\n",
      "Fold: 13  Epoch: 149  Training loss = 4.3033  Validation loss = 7.5435  \n",
      "\n",
      "Fold: 13  Epoch: 150  Training loss = 4.3029  Validation loss = 7.5429  \n",
      "\n",
      "Fold: 13  Epoch: 151  Training loss = 4.3024  Validation loss = 7.5421  \n",
      "\n",
      "Fold: 13  Epoch: 152  Training loss = 4.3021  Validation loss = 7.5416  \n",
      "\n",
      "Fold: 13  Epoch: 153  Training loss = 4.3018  Validation loss = 7.5412  \n",
      "\n",
      "Fold: 13  Epoch: 154  Training loss = 4.3015  Validation loss = 7.5407  \n",
      "\n",
      "Fold: 13  Epoch: 155  Training loss = 4.3012  Validation loss = 7.5402  \n",
      "\n",
      "Fold: 13  Epoch: 156  Training loss = 4.3009  Validation loss = 7.5395  \n",
      "\n",
      "Fold: 13  Epoch: 157  Training loss = 4.3006  Validation loss = 7.5389  \n",
      "\n",
      "Fold: 13  Epoch: 158  Training loss = 4.3002  Validation loss = 7.5381  \n",
      "\n",
      "Fold: 13  Epoch: 159  Training loss = 4.2998  Validation loss = 7.5375  \n",
      "\n",
      "Fold: 13  Epoch: 160  Training loss = 4.2994  Validation loss = 7.5369  \n",
      "\n",
      "Fold: 13  Epoch: 161  Training loss = 4.2991  Validation loss = 7.5363  \n",
      "\n",
      "Fold: 13  Epoch: 162  Training loss = 4.2987  Validation loss = 7.5357  \n",
      "\n",
      "Fold: 13  Epoch: 163  Training loss = 4.2984  Validation loss = 7.5351  \n",
      "\n",
      "Fold: 13  Epoch: 164  Training loss = 4.2981  Validation loss = 7.5346  \n",
      "\n",
      "Fold: 13  Epoch: 165  Training loss = 4.2977  Validation loss = 7.5338  \n",
      "\n",
      "Fold: 13  Epoch: 166  Training loss = 4.2973  Validation loss = 7.5331  \n",
      "\n",
      "Fold: 13  Epoch: 167  Training loss = 4.2970  Validation loss = 7.5326  \n",
      "\n",
      "Fold: 13  Epoch: 168  Training loss = 4.2967  Validation loss = 7.5322  \n",
      "\n",
      "Fold: 13  Epoch: 169  Training loss = 4.2964  Validation loss = 7.5316  \n",
      "\n",
      "Fold: 13  Epoch: 170  Training loss = 4.2961  Validation loss = 7.5311  \n",
      "\n",
      "Fold: 13  Epoch: 171  Training loss = 4.2957  Validation loss = 7.5305  \n",
      "\n",
      "Fold: 13  Epoch: 172  Training loss = 4.2954  Validation loss = 7.5299  \n",
      "\n",
      "Fold: 13  Epoch: 173  Training loss = 4.2951  Validation loss = 7.5295  \n",
      "\n",
      "Fold: 13  Epoch: 174  Training loss = 4.2947  Validation loss = 7.5289  \n",
      "\n",
      "Fold: 13  Epoch: 175  Training loss = 4.2944  Validation loss = 7.5284  \n",
      "\n",
      "Fold: 13  Epoch: 176  Training loss = 4.2940  Validation loss = 7.5279  \n",
      "\n",
      "Fold: 13  Epoch: 177  Training loss = 4.2938  Validation loss = 7.5274  \n",
      "\n",
      "Fold: 13  Epoch: 178  Training loss = 4.2933  Validation loss = 7.5267  \n",
      "\n",
      "Fold: 13  Epoch: 179  Training loss = 4.2930  Validation loss = 7.5261  \n",
      "\n",
      "Fold: 13  Epoch: 180  Training loss = 4.2927  Validation loss = 7.5256  \n",
      "\n",
      "Fold: 13  Epoch: 181  Training loss = 4.2924  Validation loss = 7.5251  \n",
      "\n",
      "Fold: 13  Epoch: 182  Training loss = 4.2920  Validation loss = 7.5245  \n",
      "\n",
      "Fold: 13  Epoch: 183  Training loss = 4.2918  Validation loss = 7.5241  \n",
      "\n",
      "Fold: 13  Epoch: 184  Training loss = 4.2914  Validation loss = 7.5234  \n",
      "\n",
      "Fold: 13  Epoch: 185  Training loss = 4.2910  Validation loss = 7.5228  \n",
      "\n",
      "Fold: 13  Epoch: 186  Training loss = 4.2907  Validation loss = 7.5224  \n",
      "\n",
      "Fold: 13  Epoch: 187  Training loss = 4.2904  Validation loss = 7.5219  \n",
      "\n",
      "Fold: 13  Epoch: 188  Training loss = 4.2901  Validation loss = 7.5215  \n",
      "\n",
      "Fold: 13  Epoch: 189  Training loss = 4.2897  Validation loss = 7.5208  \n",
      "\n",
      "Fold: 13  Epoch: 190  Training loss = 4.2893  Validation loss = 7.5202  \n",
      "\n",
      "Fold: 13  Epoch: 191  Training loss = 4.2890  Validation loss = 7.5196  \n",
      "\n",
      "Fold: 13  Epoch: 192  Training loss = 4.2885  Validation loss = 7.5189  \n",
      "\n",
      "Fold: 13  Epoch: 193  Training loss = 4.2882  Validation loss = 7.5183  \n",
      "\n",
      "Fold: 13  Epoch: 194  Training loss = 4.2878  Validation loss = 7.5177  \n",
      "\n",
      "Fold: 13  Epoch: 195  Training loss = 4.2875  Validation loss = 7.5171  \n",
      "\n",
      "Fold: 13  Epoch: 196  Training loss = 4.2872  Validation loss = 7.5166  \n",
      "\n",
      "Fold: 13  Epoch: 197  Training loss = 4.2869  Validation loss = 7.5161  \n",
      "\n",
      "Fold: 13  Epoch: 198  Training loss = 4.2866  Validation loss = 7.5156  \n",
      "\n",
      "Fold: 13  Epoch: 199  Training loss = 4.2862  Validation loss = 7.5150  \n",
      "\n",
      "Fold: 13  Epoch: 200  Training loss = 4.2859  Validation loss = 7.5145  \n",
      "\n",
      "Fold: 13  Epoch: 201  Training loss = 4.2856  Validation loss = 7.5141  \n",
      "\n",
      "Fold: 13  Epoch: 202  Training loss = 4.2852  Validation loss = 7.5136  \n",
      "\n",
      "Fold: 13  Epoch: 203  Training loss = 4.2850  Validation loss = 7.5131  \n",
      "\n",
      "Fold: 13  Epoch: 204  Training loss = 4.2847  Validation loss = 7.5126  \n",
      "\n",
      "Fold: 13  Epoch: 205  Training loss = 4.2843  Validation loss = 7.5122  \n",
      "\n",
      "Fold: 13  Epoch: 206  Training loss = 4.2839  Validation loss = 7.5115  \n",
      "\n",
      "Fold: 13  Epoch: 207  Training loss = 4.2836  Validation loss = 7.5110  \n",
      "\n",
      "Fold: 13  Epoch: 208  Training loss = 4.2833  Validation loss = 7.5105  \n",
      "\n",
      "Fold: 13  Epoch: 209  Training loss = 4.2829  Validation loss = 7.5099  \n",
      "\n",
      "Fold: 13  Epoch: 210  Training loss = 4.2826  Validation loss = 7.5094  \n",
      "\n",
      "Fold: 13  Epoch: 211  Training loss = 4.2823  Validation loss = 7.5089  \n",
      "\n",
      "Fold: 13  Epoch: 212  Training loss = 4.2820  Validation loss = 7.5083  \n",
      "\n",
      "Fold: 13  Epoch: 213  Training loss = 4.2816  Validation loss = 7.5078  \n",
      "\n",
      "Fold: 13  Epoch: 214  Training loss = 4.2813  Validation loss = 7.5073  \n",
      "\n",
      "Fold: 13  Epoch: 215  Training loss = 4.2810  Validation loss = 7.5069  \n",
      "\n",
      "Fold: 13  Epoch: 216  Training loss = 4.2807  Validation loss = 7.5063  \n",
      "\n",
      "Fold: 13  Epoch: 217  Training loss = 4.2803  Validation loss = 7.5057  \n",
      "\n",
      "Fold: 13  Epoch: 218  Training loss = 4.2800  Validation loss = 7.5052  \n",
      "\n",
      "Fold: 13  Epoch: 219  Training loss = 4.2796  Validation loss = 7.5046  \n",
      "\n",
      "Fold: 13  Epoch: 220  Training loss = 4.2793  Validation loss = 7.5040  \n",
      "\n",
      "Fold: 13  Epoch: 221  Training loss = 4.2790  Validation loss = 7.5034  \n",
      "\n",
      "Fold: 13  Epoch: 222  Training loss = 4.2786  Validation loss = 7.5028  \n",
      "\n",
      "Fold: 13  Epoch: 223  Training loss = 4.2783  Validation loss = 7.5023  \n",
      "\n",
      "Fold: 13  Epoch: 224  Training loss = 4.2780  Validation loss = 7.5018  \n",
      "\n",
      "Fold: 13  Epoch: 225  Training loss = 4.2777  Validation loss = 7.5014  \n",
      "\n",
      "Fold: 13  Epoch: 226  Training loss = 4.2774  Validation loss = 7.5008  \n",
      "\n",
      "Fold: 13  Epoch: 227  Training loss = 4.2770  Validation loss = 7.5003  \n",
      "\n",
      "Fold: 13  Epoch: 228  Training loss = 4.2766  Validation loss = 7.4996  \n",
      "\n",
      "Fold: 13  Epoch: 229  Training loss = 4.2763  Validation loss = 7.4991  \n",
      "\n",
      "Fold: 13  Epoch: 230  Training loss = 4.2759  Validation loss = 7.4985  \n",
      "\n",
      "Fold: 13  Epoch: 231  Training loss = 4.2755  Validation loss = 7.4978  \n",
      "\n",
      "Fold: 13  Epoch: 232  Training loss = 4.2751  Validation loss = 7.4971  \n",
      "\n",
      "Fold: 13  Epoch: 233  Training loss = 4.2747  Validation loss = 7.4966  \n",
      "\n",
      "Fold: 13  Epoch: 234  Training loss = 4.2744  Validation loss = 7.4960  \n",
      "\n",
      "Fold: 13  Epoch: 235  Training loss = 4.2741  Validation loss = 7.4955  \n",
      "\n",
      "Fold: 13  Epoch: 236  Training loss = 4.2738  Validation loss = 7.4950  \n",
      "\n",
      "Fold: 13  Epoch: 237  Training loss = 4.2735  Validation loss = 7.4944  \n",
      "\n",
      "Fold: 13  Epoch: 238  Training loss = 4.2732  Validation loss = 7.4939  \n",
      "\n",
      "Fold: 13  Epoch: 239  Training loss = 4.2728  Validation loss = 7.4933  \n",
      "\n",
      "Fold: 13  Epoch: 240  Training loss = 4.2725  Validation loss = 7.4928  \n",
      "\n",
      "Fold: 13  Epoch: 241  Training loss = 4.2722  Validation loss = 7.4923  \n",
      "\n",
      "Fold: 13  Epoch: 242  Training loss = 4.2718  Validation loss = 7.4917  \n",
      "\n",
      "Fold: 13  Epoch: 243  Training loss = 4.2715  Validation loss = 7.4912  \n",
      "\n",
      "Fold: 13  Epoch: 244  Training loss = 4.2711  Validation loss = 7.4906  \n",
      "\n",
      "Fold: 13  Epoch: 245  Training loss = 4.2708  Validation loss = 7.4900  \n",
      "\n",
      "Fold: 13  Epoch: 246  Training loss = 4.2704  Validation loss = 7.4894  \n",
      "\n",
      "Fold: 13  Epoch: 247  Training loss = 4.2701  Validation loss = 7.4889  \n",
      "\n",
      "Fold: 13  Epoch: 248  Training loss = 4.2698  Validation loss = 7.4884  \n",
      "\n",
      "Fold: 13  Epoch: 249  Training loss = 4.2695  Validation loss = 7.4879  \n",
      "\n",
      "Fold: 13  Epoch: 250  Training loss = 4.2692  Validation loss = 7.4873  \n",
      "\n",
      "Fold: 13  Epoch: 251  Training loss = 4.2689  Validation loss = 7.4868  \n",
      "\n",
      "Fold: 13  Epoch: 252  Training loss = 4.2686  Validation loss = 7.4863  \n",
      "\n",
      "Fold: 13  Epoch: 253  Training loss = 4.2683  Validation loss = 7.4858  \n",
      "\n",
      "Fold: 13  Epoch: 254  Training loss = 4.2680  Validation loss = 7.4852  \n",
      "\n",
      "Fold: 13  Epoch: 255  Training loss = 4.2677  Validation loss = 7.4848  \n",
      "\n",
      "Fold: 13  Epoch: 256  Training loss = 4.2673  Validation loss = 7.4842  \n",
      "\n",
      "Fold: 13  Epoch: 257  Training loss = 4.2670  Validation loss = 7.4836  \n",
      "\n",
      "Fold: 13  Epoch: 258  Training loss = 4.2667  Validation loss = 7.4832  \n",
      "\n",
      "Fold: 13  Epoch: 259  Training loss = 4.2664  Validation loss = 7.4827  \n",
      "\n",
      "Fold: 13  Epoch: 260  Training loss = 4.2662  Validation loss = 7.4823  \n",
      "\n",
      "Fold: 13  Epoch: 261  Training loss = 4.2658  Validation loss = 7.4817  \n",
      "\n",
      "Fold: 13  Epoch: 262  Training loss = 4.2654  Validation loss = 7.4811  \n",
      "\n",
      "Fold: 13  Epoch: 263  Training loss = 4.2651  Validation loss = 7.4806  \n",
      "\n",
      "Fold: 13  Epoch: 264  Training loss = 4.2647  Validation loss = 7.4800  \n",
      "\n",
      "Fold: 13  Epoch: 265  Training loss = 4.2644  Validation loss = 7.4795  \n",
      "\n",
      "Fold: 13  Epoch: 266  Training loss = 4.2641  Validation loss = 7.4789  \n",
      "\n",
      "Fold: 13  Epoch: 267  Training loss = 4.2637  Validation loss = 7.4783  \n",
      "\n",
      "Fold: 13  Epoch: 268  Training loss = 4.2633  Validation loss = 7.4776  \n",
      "\n",
      "Fold: 13  Epoch: 269  Training loss = 4.2630  Validation loss = 7.4770  \n",
      "\n",
      "Fold: 13  Epoch: 270  Training loss = 4.2626  Validation loss = 7.4765  \n",
      "\n",
      "Fold: 13  Epoch: 271  Training loss = 4.2623  Validation loss = 7.4759  \n",
      "\n",
      "Fold: 13  Epoch: 272  Training loss = 4.2619  Validation loss = 7.4753  \n",
      "\n",
      "Fold: 13  Epoch: 273  Training loss = 4.2617  Validation loss = 7.4749  \n",
      "\n",
      "Fold: 13  Epoch: 274  Training loss = 4.2614  Validation loss = 7.4743  \n",
      "\n",
      "Fold: 13  Epoch: 275  Training loss = 4.2611  Validation loss = 7.4737  \n",
      "\n",
      "Fold: 13  Epoch: 276  Training loss = 4.2607  Validation loss = 7.4731  \n",
      "\n",
      "Fold: 13  Epoch: 277  Training loss = 4.2603  Validation loss = 7.4726  \n",
      "\n",
      "Fold: 13  Epoch: 278  Training loss = 4.2600  Validation loss = 7.4720  \n",
      "\n",
      "Fold: 13  Epoch: 279  Training loss = 4.2597  Validation loss = 7.4716  \n",
      "\n",
      "Fold: 13  Epoch: 280  Training loss = 4.2594  Validation loss = 7.4710  \n",
      "\n",
      "Fold: 13  Epoch: 281  Training loss = 4.2591  Validation loss = 7.4705  \n",
      "\n",
      "Fold: 13  Epoch: 282  Training loss = 4.2588  Validation loss = 7.4701  \n",
      "\n",
      "Fold: 13  Epoch: 283  Training loss = 4.2584  Validation loss = 7.4694  \n",
      "\n",
      "Fold: 13  Epoch: 284  Training loss = 4.2581  Validation loss = 7.4688  \n",
      "\n",
      "Fold: 13  Epoch: 285  Training loss = 4.2578  Validation loss = 7.4682  \n",
      "\n",
      "Fold: 13  Epoch: 286  Training loss = 4.2574  Validation loss = 7.4677  \n",
      "\n",
      "Fold: 13  Epoch: 287  Training loss = 4.2571  Validation loss = 7.4672  \n",
      "\n",
      "Fold: 13  Epoch: 288  Training loss = 4.2568  Validation loss = 7.4666  \n",
      "\n",
      "Fold: 13  Epoch: 289  Training loss = 4.2563  Validation loss = 7.4658  \n",
      "\n",
      "Fold: 13  Epoch: 290  Training loss = 4.2560  Validation loss = 7.4652  \n",
      "\n",
      "Fold: 13  Epoch: 291  Training loss = 4.2556  Validation loss = 7.4647  \n",
      "\n",
      "Fold: 13  Epoch: 292  Training loss = 4.2553  Validation loss = 7.4641  \n",
      "\n",
      "Fold: 13  Epoch: 293  Training loss = 4.2549  Validation loss = 7.4635  \n",
      "\n",
      "Fold: 13  Epoch: 294  Training loss = 4.2546  Validation loss = 7.4629  \n",
      "\n",
      "Fold: 13  Epoch: 295  Training loss = 4.2543  Validation loss = 7.4624  \n",
      "\n",
      "Fold: 13  Epoch: 296  Training loss = 4.2540  Validation loss = 7.4620  \n",
      "\n",
      "Fold: 13  Epoch: 297  Training loss = 4.2537  Validation loss = 7.4613  \n",
      "\n",
      "Fold: 13  Epoch: 298  Training loss = 4.2533  Validation loss = 7.4607  \n",
      "\n",
      "Fold: 13  Epoch: 299  Training loss = 4.2531  Validation loss = 7.4602  \n",
      "\n",
      "Fold: 13  Epoch: 300  Training loss = 4.2527  Validation loss = 7.4596  \n",
      "\n",
      "Fold: 13  Epoch: 301  Training loss = 4.2523  Validation loss = 7.4589  \n",
      "\n",
      "Fold: 13  Epoch: 302  Training loss = 4.2519  Validation loss = 7.4582  \n",
      "\n",
      "Fold: 13  Epoch: 303  Training loss = 4.2516  Validation loss = 7.4576  \n",
      "\n",
      "Fold: 13  Epoch: 304  Training loss = 4.2511  Validation loss = 7.4569  \n",
      "\n",
      "Fold: 13  Epoch: 305  Training loss = 4.2508  Validation loss = 7.4563  \n",
      "\n",
      "Fold: 13  Epoch: 306  Training loss = 4.2504  Validation loss = 7.4557  \n",
      "\n",
      "Fold: 13  Epoch: 307  Training loss = 4.2500  Validation loss = 7.4552  \n",
      "\n",
      "Fold: 13  Epoch: 308  Training loss = 4.2497  Validation loss = 7.4546  \n",
      "\n",
      "Fold: 13  Epoch: 309  Training loss = 4.2494  Validation loss = 7.4540  \n",
      "\n",
      "Fold: 13  Epoch: 310  Training loss = 4.2490  Validation loss = 7.4534  \n",
      "\n",
      "Fold: 13  Epoch: 311  Training loss = 4.2486  Validation loss = 7.4529  \n",
      "\n",
      "Fold: 13  Epoch: 312  Training loss = 4.2484  Validation loss = 7.4524  \n",
      "\n",
      "Fold: 13  Epoch: 313  Training loss = 4.2480  Validation loss = 7.4518  \n",
      "\n",
      "Fold: 13  Epoch: 314  Training loss = 4.2477  Validation loss = 7.4513  \n",
      "\n",
      "Fold: 13  Epoch: 315  Training loss = 4.2474  Validation loss = 7.4507  \n",
      "\n",
      "Fold: 13  Epoch: 316  Training loss = 4.2471  Validation loss = 7.4503  \n",
      "\n",
      "Fold: 13  Epoch: 317  Training loss = 4.2468  Validation loss = 7.4497  \n",
      "\n",
      "Fold: 13  Epoch: 318  Training loss = 4.2464  Validation loss = 7.4492  \n",
      "\n",
      "Fold: 13  Epoch: 319  Training loss = 4.2461  Validation loss = 7.4487  \n",
      "\n",
      "Fold: 13  Epoch: 320  Training loss = 4.2458  Validation loss = 7.4482  \n",
      "\n",
      "Fold: 13  Epoch: 321  Training loss = 4.2454  Validation loss = 7.4476  \n",
      "\n",
      "Fold: 13  Epoch: 322  Training loss = 4.2451  Validation loss = 7.4470  \n",
      "\n",
      "Fold: 13  Epoch: 323  Training loss = 4.2448  Validation loss = 7.4464  \n",
      "\n",
      "Fold: 13  Epoch: 324  Training loss = 4.2444  Validation loss = 7.4459  \n",
      "\n",
      "Fold: 13  Epoch: 325  Training loss = 4.2441  Validation loss = 7.4453  \n",
      "\n",
      "Fold: 13  Epoch: 326  Training loss = 4.2438  Validation loss = 7.4448  \n",
      "\n",
      "Fold: 13  Epoch: 327  Training loss = 4.2434  Validation loss = 7.4441  \n",
      "\n",
      "Fold: 13  Epoch: 328  Training loss = 4.2431  Validation loss = 7.4437  \n",
      "\n",
      "Fold: 13  Epoch: 329  Training loss = 4.2428  Validation loss = 7.4430  \n",
      "\n",
      "Fold: 13  Epoch: 330  Training loss = 4.2424  Validation loss = 7.4425  \n",
      "\n",
      "Fold: 13  Epoch: 331  Training loss = 4.2421  Validation loss = 7.4420  \n",
      "\n",
      "Fold: 13  Epoch: 332  Training loss = 4.2418  Validation loss = 7.4414  \n",
      "\n",
      "Fold: 13  Epoch: 333  Training loss = 4.2414  Validation loss = 7.4409  \n",
      "\n",
      "Fold: 13  Epoch: 334  Training loss = 4.2412  Validation loss = 7.4405  \n",
      "\n",
      "Fold: 13  Epoch: 335  Training loss = 4.2408  Validation loss = 7.4400  \n",
      "\n",
      "Fold: 13  Epoch: 336  Training loss = 4.2404  Validation loss = 7.4393  \n",
      "\n",
      "Fold: 13  Epoch: 337  Training loss = 4.2401  Validation loss = 7.4389  \n",
      "\n",
      "Fold: 13  Epoch: 338  Training loss = 4.2398  Validation loss = 7.4384  \n",
      "\n",
      "Fold: 13  Epoch: 339  Training loss = 4.2395  Validation loss = 7.4379  \n",
      "\n",
      "Fold: 13  Epoch: 340  Training loss = 4.2391  Validation loss = 7.4373  \n",
      "\n",
      "Fold: 13  Epoch: 341  Training loss = 4.2389  Validation loss = 7.4368  \n",
      "\n",
      "Fold: 13  Epoch: 342  Training loss = 4.2386  Validation loss = 7.4364  \n",
      "\n",
      "Fold: 13  Epoch: 343  Training loss = 4.2383  Validation loss = 7.4358  \n",
      "\n",
      "Fold: 13  Epoch: 344  Training loss = 4.2380  Validation loss = 7.4354  \n",
      "\n",
      "Fold: 13  Epoch: 345  Training loss = 4.2376  Validation loss = 7.4348  \n",
      "\n",
      "Fold: 13  Epoch: 346  Training loss = 4.2373  Validation loss = 7.4344  \n",
      "\n",
      "Fold: 13  Epoch: 347  Training loss = 4.2370  Validation loss = 7.4338  \n",
      "\n",
      "Fold: 13  Epoch: 348  Training loss = 4.2366  Validation loss = 7.4333  \n",
      "\n",
      "Fold: 13  Epoch: 349  Training loss = 4.2363  Validation loss = 7.4326  \n",
      "\n",
      "Fold: 13  Epoch: 350  Training loss = 4.2360  Validation loss = 7.4320  \n",
      "\n",
      "Fold: 13  Epoch: 351  Training loss = 4.2356  Validation loss = 7.4315  \n",
      "\n",
      "Fold: 13  Epoch: 352  Training loss = 4.2353  Validation loss = 7.4310  \n",
      "\n",
      "Fold: 13  Epoch: 353  Training loss = 4.2349  Validation loss = 7.4303  \n",
      "\n",
      "Fold: 13  Epoch: 354  Training loss = 4.2346  Validation loss = 7.4296  \n",
      "\n",
      "Fold: 13  Epoch: 355  Training loss = 4.2342  Validation loss = 7.4289  \n",
      "\n",
      "Fold: 13  Epoch: 356  Training loss = 4.2339  Validation loss = 7.4284  \n",
      "\n",
      "Fold: 13  Epoch: 357  Training loss = 4.2335  Validation loss = 7.4279  \n",
      "\n",
      "Fold: 13  Epoch: 358  Training loss = 4.2331  Validation loss = 7.4272  \n",
      "\n",
      "Fold: 13  Epoch: 359  Training loss = 4.2327  Validation loss = 7.4265  \n",
      "\n",
      "Fold: 13  Epoch: 360  Training loss = 4.2325  Validation loss = 7.4261  \n",
      "\n",
      "Fold: 13  Epoch: 361  Training loss = 4.2322  Validation loss = 7.4256  \n",
      "\n",
      "Fold: 13  Epoch: 362  Training loss = 4.2318  Validation loss = 7.4251  \n",
      "\n",
      "Fold: 13  Epoch: 363  Training loss = 4.2315  Validation loss = 7.4245  \n",
      "\n",
      "Fold: 13  Epoch: 364  Training loss = 4.2311  Validation loss = 7.4239  \n",
      "\n",
      "Fold: 13  Epoch: 365  Training loss = 4.2308  Validation loss = 7.4235  \n",
      "\n",
      "Fold: 13  Epoch: 366  Training loss = 4.2305  Validation loss = 7.4229  \n",
      "\n",
      "Fold: 13  Epoch: 367  Training loss = 4.2303  Validation loss = 7.4225  \n",
      "\n",
      "Fold: 13  Epoch: 368  Training loss = 4.2299  Validation loss = 7.4219  \n",
      "\n",
      "Fold: 13  Epoch: 369  Training loss = 4.2295  Validation loss = 7.4213  \n",
      "\n",
      "Fold: 13  Epoch: 370  Training loss = 4.2292  Validation loss = 7.4209  \n",
      "\n",
      "Fold: 13  Epoch: 371  Training loss = 4.2289  Validation loss = 7.4204  \n",
      "\n",
      "Fold: 13  Epoch: 372  Training loss = 4.2287  Validation loss = 7.4199  \n",
      "\n",
      "Fold: 13  Epoch: 373  Training loss = 4.2283  Validation loss = 7.4193  \n",
      "\n",
      "Fold: 13  Epoch: 374  Training loss = 4.2279  Validation loss = 7.4188  \n",
      "\n",
      "Fold: 13  Epoch: 375  Training loss = 4.2276  Validation loss = 7.4181  \n",
      "\n",
      "Fold: 13  Epoch: 376  Training loss = 4.2273  Validation loss = 7.4176  \n",
      "\n",
      "Fold: 13  Epoch: 377  Training loss = 4.2270  Validation loss = 7.4171  \n",
      "\n",
      "Fold: 13  Epoch: 378  Training loss = 4.2267  Validation loss = 7.4166  \n",
      "\n",
      "Fold: 13  Epoch: 379  Training loss = 4.2264  Validation loss = 7.4162  \n",
      "\n",
      "Fold: 13  Epoch: 380  Training loss = 4.2261  Validation loss = 7.4157  \n",
      "\n",
      "Fold: 13  Epoch: 381  Training loss = 4.2258  Validation loss = 7.4150  \n",
      "\n",
      "Fold: 13  Epoch: 382  Training loss = 4.2255  Validation loss = 7.4144  \n",
      "\n",
      "Fold: 13  Epoch: 383  Training loss = 4.2251  Validation loss = 7.4138  \n",
      "\n",
      "Fold: 13  Epoch: 384  Training loss = 4.2248  Validation loss = 7.4133  \n",
      "\n",
      "Fold: 13  Epoch: 385  Training loss = 4.2245  Validation loss = 7.4128  \n",
      "\n",
      "Fold: 13  Epoch: 386  Training loss = 4.2241  Validation loss = 7.4123  \n",
      "\n",
      "Fold: 13  Epoch: 387  Training loss = 4.2238  Validation loss = 7.4117  \n",
      "\n",
      "Fold: 13  Epoch: 388  Training loss = 4.2236  Validation loss = 7.4112  \n",
      "\n",
      "Fold: 13  Epoch: 389  Training loss = 4.2233  Validation loss = 7.4106  \n",
      "\n",
      "Fold: 13  Epoch: 390  Training loss = 4.2230  Validation loss = 7.4101  \n",
      "\n",
      "Fold: 13  Epoch: 391  Training loss = 4.2226  Validation loss = 7.4094  \n",
      "\n",
      "Fold: 13  Epoch: 392  Training loss = 4.2223  Validation loss = 7.4090  \n",
      "\n",
      "Fold: 13  Epoch: 393  Training loss = 4.2219  Validation loss = 7.4085  \n",
      "\n",
      "Fold: 13  Epoch: 394  Training loss = 4.2217  Validation loss = 7.4080  \n",
      "\n",
      "Fold: 13  Epoch: 395  Training loss = 4.2213  Validation loss = 7.4074  \n",
      "\n",
      "Fold: 13  Epoch: 396  Training loss = 4.2210  Validation loss = 7.4068  \n",
      "\n",
      "Fold: 13  Epoch: 397  Training loss = 4.2207  Validation loss = 7.4062  \n",
      "\n",
      "Fold: 13  Epoch: 398  Training loss = 4.2203  Validation loss = 7.4056  \n",
      "\n",
      "Fold: 13  Epoch: 399  Training loss = 4.2200  Validation loss = 7.4050  \n",
      "\n",
      "Fold: 13  Epoch: 400  Training loss = 4.2196  Validation loss = 7.4043  \n",
      "\n",
      "Fold: 13  Epoch: 401  Training loss = 4.2192  Validation loss = 7.4037  \n",
      "\n",
      "Fold: 13  Epoch: 402  Training loss = 4.2189  Validation loss = 7.4031  \n",
      "\n",
      "Fold: 13  Epoch: 403  Training loss = 4.2186  Validation loss = 7.4026  \n",
      "\n",
      "Fold: 13  Epoch: 404  Training loss = 4.2182  Validation loss = 7.4021  \n",
      "\n",
      "Fold: 13  Epoch: 405  Training loss = 4.2179  Validation loss = 7.4014  \n",
      "\n",
      "Fold: 13  Epoch: 406  Training loss = 4.2175  Validation loss = 7.4009  \n",
      "\n",
      "Fold: 13  Epoch: 407  Training loss = 4.2172  Validation loss = 7.4002  \n",
      "\n",
      "Fold: 13  Epoch: 408  Training loss = 4.2168  Validation loss = 7.3997  \n",
      "\n",
      "Fold: 13  Epoch: 409  Training loss = 4.2165  Validation loss = 7.3991  \n",
      "\n",
      "Fold: 13  Epoch: 410  Training loss = 4.2162  Validation loss = 7.3985  \n",
      "\n",
      "Fold: 13  Epoch: 411  Training loss = 4.2159  Validation loss = 7.3980  \n",
      "\n",
      "Fold: 13  Epoch: 412  Training loss = 4.2155  Validation loss = 7.3976  \n",
      "\n",
      "Fold: 13  Epoch: 413  Training loss = 4.2152  Validation loss = 7.3970  \n",
      "\n",
      "Fold: 13  Epoch: 414  Training loss = 4.2149  Validation loss = 7.3965  \n",
      "\n",
      "Fold: 13  Epoch: 415  Training loss = 4.2146  Validation loss = 7.3959  \n",
      "\n",
      "Fold: 13  Epoch: 416  Training loss = 4.2142  Validation loss = 7.3953  \n",
      "\n",
      "Fold: 13  Epoch: 417  Training loss = 4.2139  Validation loss = 7.3948  \n",
      "\n",
      "Fold: 13  Epoch: 418  Training loss = 4.2136  Validation loss = 7.3942  \n",
      "\n",
      "Fold: 13  Epoch: 419  Training loss = 4.2133  Validation loss = 7.3936  \n",
      "\n",
      "Fold: 13  Epoch: 420  Training loss = 4.2130  Validation loss = 7.3930  \n",
      "\n",
      "Fold: 13  Epoch: 421  Training loss = 4.2126  Validation loss = 7.3925  \n",
      "\n",
      "Fold: 13  Epoch: 422  Training loss = 4.2123  Validation loss = 7.3919  \n",
      "\n",
      "Fold: 13  Epoch: 423  Training loss = 4.2119  Validation loss = 7.3913  \n",
      "\n",
      "Fold: 13  Epoch: 424  Training loss = 4.2116  Validation loss = 7.3906  \n",
      "\n",
      "Fold: 13  Epoch: 425  Training loss = 4.2113  Validation loss = 7.3901  \n",
      "\n",
      "Fold: 13  Epoch: 426  Training loss = 4.2109  Validation loss = 7.3895  \n",
      "\n",
      "Fold: 13  Epoch: 427  Training loss = 4.2106  Validation loss = 7.3889  \n",
      "\n",
      "Fold: 13  Epoch: 428  Training loss = 4.2103  Validation loss = 7.3884  \n",
      "\n",
      "Fold: 13  Epoch: 429  Training loss = 4.2100  Validation loss = 7.3879  \n",
      "\n",
      "Fold: 13  Epoch: 430  Training loss = 4.2097  Validation loss = 7.3873  \n",
      "\n",
      "Fold: 13  Epoch: 431  Training loss = 4.2093  Validation loss = 7.3867  \n",
      "\n",
      "Fold: 13  Epoch: 432  Training loss = 4.2090  Validation loss = 7.3860  \n",
      "\n",
      "Fold: 13  Epoch: 433  Training loss = 4.2086  Validation loss = 7.3854  \n",
      "\n",
      "Fold: 13  Epoch: 434  Training loss = 4.2082  Validation loss = 7.3848  \n",
      "\n",
      "Fold: 13  Epoch: 435  Training loss = 4.2079  Validation loss = 7.3842  \n",
      "\n",
      "Fold: 13  Epoch: 436  Training loss = 4.2076  Validation loss = 7.3838  \n",
      "\n",
      "Fold: 13  Epoch: 437  Training loss = 4.2073  Validation loss = 7.3832  \n",
      "\n",
      "Fold: 13  Epoch: 438  Training loss = 4.2069  Validation loss = 7.3826  \n",
      "\n",
      "Fold: 13  Epoch: 439  Training loss = 4.2066  Validation loss = 7.3821  \n",
      "\n",
      "Fold: 13  Epoch: 440  Training loss = 4.2063  Validation loss = 7.3816  \n",
      "\n",
      "Fold: 13  Epoch: 441  Training loss = 4.2060  Validation loss = 7.3811  \n",
      "\n",
      "Fold: 13  Epoch: 442  Training loss = 4.2057  Validation loss = 7.3806  \n",
      "\n",
      "Fold: 13  Epoch: 443  Training loss = 4.2054  Validation loss = 7.3802  \n",
      "\n",
      "Fold: 13  Epoch: 444  Training loss = 4.2052  Validation loss = 7.3797  \n",
      "\n",
      "Fold: 13  Epoch: 445  Training loss = 4.2048  Validation loss = 7.3791  \n",
      "\n",
      "Fold: 13  Epoch: 446  Training loss = 4.2045  Validation loss = 7.3787  \n",
      "\n",
      "Fold: 13  Epoch: 447  Training loss = 4.2042  Validation loss = 7.3782  \n",
      "\n",
      "Fold: 13  Epoch: 448  Training loss = 4.2039  Validation loss = 7.3777  \n",
      "\n",
      "Fold: 13  Epoch: 449  Training loss = 4.2035  Validation loss = 7.3771  \n",
      "\n",
      "Fold: 13  Epoch: 450  Training loss = 4.2032  Validation loss = 7.3766  \n",
      "\n",
      "Fold: 13  Epoch: 451  Training loss = 4.2029  Validation loss = 7.3759  \n",
      "\n",
      "Fold: 13  Epoch: 452  Training loss = 4.2025  Validation loss = 7.3753  \n",
      "\n",
      "Fold: 13  Epoch: 453  Training loss = 4.2022  Validation loss = 7.3747  \n",
      "\n",
      "Fold: 13  Epoch: 454  Training loss = 4.2019  Validation loss = 7.3742  \n",
      "\n",
      "Fold: 13  Epoch: 455  Training loss = 4.2016  Validation loss = 7.3736  \n",
      "\n",
      "Fold: 13  Epoch: 456  Training loss = 4.2013  Validation loss = 7.3731  \n",
      "\n",
      "Fold: 13  Epoch: 457  Training loss = 4.2010  Validation loss = 7.3727  \n",
      "\n",
      "Fold: 13  Epoch: 458  Training loss = 4.2007  Validation loss = 7.3722  \n",
      "\n",
      "Fold: 13  Epoch: 459  Training loss = 4.2004  Validation loss = 7.3718  \n",
      "\n",
      "Fold: 13  Epoch: 460  Training loss = 4.2000  Validation loss = 7.3710  \n",
      "\n",
      "Fold: 13  Epoch: 461  Training loss = 4.1997  Validation loss = 7.3705  \n",
      "\n",
      "Fold: 13  Epoch: 462  Training loss = 4.1993  Validation loss = 7.3699  \n",
      "\n",
      "Fold: 13  Epoch: 463  Training loss = 4.1990  Validation loss = 7.3693  \n",
      "\n",
      "Fold: 13  Epoch: 464  Training loss = 4.1987  Validation loss = 7.3688  \n",
      "\n",
      "Fold: 13  Epoch: 465  Training loss = 4.1984  Validation loss = 7.3683  \n",
      "\n",
      "Fold: 13  Epoch: 466  Training loss = 4.1980  Validation loss = 7.3677  \n",
      "\n",
      "Fold: 13  Epoch: 467  Training loss = 4.1976  Validation loss = 7.3670  \n",
      "\n",
      "Fold: 13  Epoch: 468  Training loss = 4.1973  Validation loss = 7.3665  \n",
      "\n",
      "Fold: 13  Epoch: 469  Training loss = 4.1969  Validation loss = 7.3659  \n",
      "\n",
      "Fold: 13  Epoch: 470  Training loss = 4.1966  Validation loss = 7.3654  \n",
      "\n",
      "Fold: 13  Epoch: 471  Training loss = 4.1963  Validation loss = 7.3647  \n",
      "\n",
      "Fold: 13  Epoch: 472  Training loss = 4.1959  Validation loss = 7.3640  \n",
      "\n",
      "Fold: 13  Epoch: 473  Training loss = 4.1955  Validation loss = 7.3634  \n",
      "\n",
      "Fold: 13  Epoch: 474  Training loss = 4.1952  Validation loss = 7.3628  \n",
      "\n",
      "Fold: 13  Epoch: 475  Training loss = 4.1948  Validation loss = 7.3623  \n",
      "\n",
      "Fold: 13  Epoch: 476  Training loss = 4.1945  Validation loss = 7.3618  \n",
      "\n",
      "Fold: 13  Epoch: 477  Training loss = 4.1942  Validation loss = 7.3613  \n",
      "\n",
      "Fold: 13  Epoch: 478  Training loss = 4.1939  Validation loss = 7.3607  \n",
      "\n",
      "Fold: 13  Epoch: 479  Training loss = 4.1936  Validation loss = 7.3602  \n",
      "\n",
      "Fold: 13  Epoch: 480  Training loss = 4.1932  Validation loss = 7.3596  \n",
      "\n",
      "Fold: 13  Epoch: 481  Training loss = 4.1928  Validation loss = 7.3590  \n",
      "\n",
      "Fold: 13  Epoch: 482  Training loss = 4.1926  Validation loss = 7.3586  \n",
      "\n",
      "Fold: 13  Epoch: 483  Training loss = 4.1924  Validation loss = 7.3583  \n",
      "\n",
      "Fold: 13  Epoch: 484  Training loss = 4.1920  Validation loss = 7.3577  \n",
      "\n",
      "Fold: 13  Epoch: 485  Training loss = 4.1916  Validation loss = 7.3571  \n",
      "\n",
      "Fold: 13  Epoch: 486  Training loss = 4.1913  Validation loss = 7.3566  \n",
      "\n",
      "Fold: 13  Epoch: 487  Training loss = 4.1910  Validation loss = 7.3560  \n",
      "\n",
      "Fold: 13  Epoch: 488  Training loss = 4.1906  Validation loss = 7.3554  \n",
      "\n",
      "Fold: 13  Epoch: 489  Training loss = 4.1903  Validation loss = 7.3548  \n",
      "\n",
      "Fold: 13  Epoch: 490  Training loss = 4.1900  Validation loss = 7.3542  \n",
      "\n",
      "Fold: 13  Epoch: 491  Training loss = 4.1897  Validation loss = 7.3537  \n",
      "\n",
      "Fold: 13  Epoch: 492  Training loss = 4.1894  Validation loss = 7.3532  \n",
      "\n",
      "Fold: 13  Epoch: 493  Training loss = 4.1890  Validation loss = 7.3526  \n",
      "\n",
      "Fold: 13  Epoch: 494  Training loss = 4.1887  Validation loss = 7.3520  \n",
      "\n",
      "Fold: 13  Epoch: 495  Training loss = 4.1884  Validation loss = 7.3515  \n",
      "\n",
      "Fold: 13  Epoch: 496  Training loss = 4.1880  Validation loss = 7.3508  \n",
      "\n",
      "Fold: 13  Epoch: 497  Training loss = 4.1877  Validation loss = 7.3503  \n",
      "\n",
      "Fold: 13  Epoch: 498  Training loss = 4.1874  Validation loss = 7.3498  \n",
      "\n",
      "Fold: 13  Epoch: 499  Training loss = 4.1871  Validation loss = 7.3492  \n",
      "\n",
      "Fold: 13  Epoch: 500  Training loss = 4.1868  Validation loss = 7.3487  \n",
      "\n",
      "Check model:  Fold: 13  Optimal epoch: 500  \n",
      "\n",
      "Fold: 14  Epoch: 1  Training loss = 4.5646  Validation loss = 10.8995  \n",
      "\n",
      "Fold: 14  Epoch: 2  Training loss = 4.5641  Validation loss = 10.8988  \n",
      "\n",
      "Fold: 14  Epoch: 3  Training loss = 4.5636  Validation loss = 10.8980  \n",
      "\n",
      "Fold: 14  Epoch: 4  Training loss = 4.5632  Validation loss = 10.8974  \n",
      "\n",
      "Fold: 14  Epoch: 5  Training loss = 4.5628  Validation loss = 10.8967  \n",
      "\n",
      "Fold: 14  Epoch: 6  Training loss = 4.5624  Validation loss = 10.8962  \n",
      "\n",
      "Fold: 14  Epoch: 7  Training loss = 4.5620  Validation loss = 10.8956  \n",
      "\n",
      "Fold: 14  Epoch: 8  Training loss = 4.5616  Validation loss = 10.8949  \n",
      "\n",
      "Fold: 14  Epoch: 9  Training loss = 4.5612  Validation loss = 10.8943  \n",
      "\n",
      "Fold: 14  Epoch: 10  Training loss = 4.5608  Validation loss = 10.8937  \n",
      "\n",
      "Fold: 14  Epoch: 11  Training loss = 4.5604  Validation loss = 10.8931  \n",
      "\n",
      "Fold: 14  Epoch: 12  Training loss = 4.5600  Validation loss = 10.8925  \n",
      "\n",
      "Fold: 14  Epoch: 13  Training loss = 4.5596  Validation loss = 10.8919  \n",
      "\n",
      "Fold: 14  Epoch: 14  Training loss = 4.5591  Validation loss = 10.8912  \n",
      "\n",
      "Fold: 14  Epoch: 15  Training loss = 4.5588  Validation loss = 10.8906  \n",
      "\n",
      "Fold: 14  Epoch: 16  Training loss = 4.5583  Validation loss = 10.8899  \n",
      "\n",
      "Fold: 14  Epoch: 17  Training loss = 4.5579  Validation loss = 10.8892  \n",
      "\n",
      "Fold: 14  Epoch: 18  Training loss = 4.5574  Validation loss = 10.8885  \n",
      "\n",
      "Fold: 14  Epoch: 19  Training loss = 4.5570  Validation loss = 10.8878  \n",
      "\n",
      "Fold: 14  Epoch: 20  Training loss = 4.5565  Validation loss = 10.8871  \n",
      "\n",
      "Fold: 14  Epoch: 21  Training loss = 4.5560  Validation loss = 10.8864  \n",
      "\n",
      "Fold: 14  Epoch: 22  Training loss = 4.5556  Validation loss = 10.8857  \n",
      "\n",
      "Fold: 14  Epoch: 23  Training loss = 4.5551  Validation loss = 10.8850  \n",
      "\n",
      "Fold: 14  Epoch: 24  Training loss = 4.5547  Validation loss = 10.8844  \n",
      "\n",
      "Fold: 14  Epoch: 25  Training loss = 4.5543  Validation loss = 10.8837  \n",
      "\n",
      "Fold: 14  Epoch: 26  Training loss = 4.5539  Validation loss = 10.8831  \n",
      "\n",
      "Fold: 14  Epoch: 27  Training loss = 4.5535  Validation loss = 10.8825  \n",
      "\n",
      "Fold: 14  Epoch: 28  Training loss = 4.5530  Validation loss = 10.8818  \n",
      "\n",
      "Fold: 14  Epoch: 29  Training loss = 4.5526  Validation loss = 10.8811  \n",
      "\n",
      "Fold: 14  Epoch: 30  Training loss = 4.5522  Validation loss = 10.8805  \n",
      "\n",
      "Fold: 14  Epoch: 31  Training loss = 4.5517  Validation loss = 10.8798  \n",
      "\n",
      "Fold: 14  Epoch: 32  Training loss = 4.5514  Validation loss = 10.8792  \n",
      "\n",
      "Fold: 14  Epoch: 33  Training loss = 4.5509  Validation loss = 10.8786  \n",
      "\n",
      "Fold: 14  Epoch: 34  Training loss = 4.5506  Validation loss = 10.8780  \n",
      "\n",
      "Fold: 14  Epoch: 35  Training loss = 4.5500  Validation loss = 10.8772  \n",
      "\n",
      "Fold: 14  Epoch: 36  Training loss = 4.5495  Validation loss = 10.8765  \n",
      "\n",
      "Fold: 14  Epoch: 37  Training loss = 4.5492  Validation loss = 10.8759  \n",
      "\n",
      "Fold: 14  Epoch: 38  Training loss = 4.5487  Validation loss = 10.8752  \n",
      "\n",
      "Fold: 14  Epoch: 39  Training loss = 4.5482  Validation loss = 10.8744  \n",
      "\n",
      "Fold: 14  Epoch: 40  Training loss = 4.5478  Validation loss = 10.8738  \n",
      "\n",
      "Fold: 14  Epoch: 41  Training loss = 4.5474  Validation loss = 10.8732  \n",
      "\n",
      "Fold: 14  Epoch: 42  Training loss = 4.5470  Validation loss = 10.8726  \n",
      "\n",
      "Fold: 14  Epoch: 43  Training loss = 4.5466  Validation loss = 10.8719  \n",
      "\n",
      "Fold: 14  Epoch: 44  Training loss = 4.5462  Validation loss = 10.8713  \n",
      "\n",
      "Fold: 14  Epoch: 45  Training loss = 4.5458  Validation loss = 10.8706  \n",
      "\n",
      "Fold: 14  Epoch: 46  Training loss = 4.5453  Validation loss = 10.8700  \n",
      "\n",
      "Fold: 14  Epoch: 47  Training loss = 4.5449  Validation loss = 10.8693  \n",
      "\n",
      "Fold: 14  Epoch: 48  Training loss = 4.5445  Validation loss = 10.8687  \n",
      "\n",
      "Fold: 14  Epoch: 49  Training loss = 4.5440  Validation loss = 10.8679  \n",
      "\n",
      "Fold: 14  Epoch: 50  Training loss = 4.5436  Validation loss = 10.8673  \n",
      "\n",
      "Fold: 14  Epoch: 51  Training loss = 4.5432  Validation loss = 10.8667  \n",
      "\n",
      "Fold: 14  Epoch: 52  Training loss = 4.5428  Validation loss = 10.8661  \n",
      "\n",
      "Fold: 14  Epoch: 53  Training loss = 4.5424  Validation loss = 10.8654  \n",
      "\n",
      "Fold: 14  Epoch: 54  Training loss = 4.5419  Validation loss = 10.8648  \n",
      "\n",
      "Fold: 14  Epoch: 55  Training loss = 4.5416  Validation loss = 10.8642  \n",
      "\n",
      "Fold: 14  Epoch: 56  Training loss = 4.5411  Validation loss = 10.8635  \n",
      "\n",
      "Fold: 14  Epoch: 57  Training loss = 4.5407  Validation loss = 10.8628  \n",
      "\n",
      "Fold: 14  Epoch: 58  Training loss = 4.5402  Validation loss = 10.8620  \n",
      "\n",
      "Fold: 14  Epoch: 59  Training loss = 4.5397  Validation loss = 10.8613  \n",
      "\n",
      "Fold: 14  Epoch: 60  Training loss = 4.5393  Validation loss = 10.8607  \n",
      "\n",
      "Fold: 14  Epoch: 61  Training loss = 4.5389  Validation loss = 10.8601  \n",
      "\n",
      "Fold: 14  Epoch: 62  Training loss = 4.5385  Validation loss = 10.8595  \n",
      "\n",
      "Fold: 14  Epoch: 63  Training loss = 4.5381  Validation loss = 10.8589  \n",
      "\n",
      "Fold: 14  Epoch: 64  Training loss = 4.5377  Validation loss = 10.8583  \n",
      "\n",
      "Fold: 14  Epoch: 65  Training loss = 4.5374  Validation loss = 10.8577  \n",
      "\n",
      "Fold: 14  Epoch: 66  Training loss = 4.5369  Validation loss = 10.8570  \n",
      "\n",
      "Fold: 14  Epoch: 67  Training loss = 4.5365  Validation loss = 10.8565  \n",
      "\n",
      "Fold: 14  Epoch: 68  Training loss = 4.5359  Validation loss = 10.8555  \n",
      "\n",
      "Fold: 14  Epoch: 69  Training loss = 4.5355  Validation loss = 10.8550  \n",
      "\n",
      "Fold: 14  Epoch: 70  Training loss = 4.5351  Validation loss = 10.8542  \n",
      "\n",
      "Fold: 14  Epoch: 71  Training loss = 4.5346  Validation loss = 10.8536  \n",
      "\n",
      "Fold: 14  Epoch: 72  Training loss = 4.5342  Validation loss = 10.8529  \n",
      "\n",
      "Fold: 14  Epoch: 73  Training loss = 4.5338  Validation loss = 10.8523  \n",
      "\n",
      "Fold: 14  Epoch: 74  Training loss = 4.5334  Validation loss = 10.8516  \n",
      "\n",
      "Fold: 14  Epoch: 75  Training loss = 4.5329  Validation loss = 10.8509  \n",
      "\n",
      "Fold: 14  Epoch: 76  Training loss = 4.5325  Validation loss = 10.8503  \n",
      "\n",
      "Fold: 14  Epoch: 77  Training loss = 4.5321  Validation loss = 10.8497  \n",
      "\n",
      "Fold: 14  Epoch: 78  Training loss = 4.5317  Validation loss = 10.8491  \n",
      "\n",
      "Fold: 14  Epoch: 79  Training loss = 4.5314  Validation loss = 10.8485  \n",
      "\n",
      "Fold: 14  Epoch: 80  Training loss = 4.5309  Validation loss = 10.8478  \n",
      "\n",
      "Fold: 14  Epoch: 81  Training loss = 4.5305  Validation loss = 10.8472  \n",
      "\n",
      "Fold: 14  Epoch: 82  Training loss = 4.5301  Validation loss = 10.8466  \n",
      "\n",
      "Fold: 14  Epoch: 83  Training loss = 4.5297  Validation loss = 10.8460  \n",
      "\n",
      "Fold: 14  Epoch: 84  Training loss = 4.5294  Validation loss = 10.8454  \n",
      "\n",
      "Fold: 14  Epoch: 85  Training loss = 4.5290  Validation loss = 10.8448  \n",
      "\n",
      "Fold: 14  Epoch: 86  Training loss = 4.5286  Validation loss = 10.8443  \n",
      "\n",
      "Fold: 14  Epoch: 87  Training loss = 4.5282  Validation loss = 10.8437  \n",
      "\n",
      "Fold: 14  Epoch: 88  Training loss = 4.5278  Validation loss = 10.8430  \n",
      "\n",
      "Fold: 14  Epoch: 89  Training loss = 4.5274  Validation loss = 10.8424  \n",
      "\n",
      "Fold: 14  Epoch: 90  Training loss = 4.5270  Validation loss = 10.8418  \n",
      "\n",
      "Fold: 14  Epoch: 91  Training loss = 4.5266  Validation loss = 10.8412  \n",
      "\n",
      "Fold: 14  Epoch: 92  Training loss = 4.5262  Validation loss = 10.8406  \n",
      "\n",
      "Fold: 14  Epoch: 93  Training loss = 4.5258  Validation loss = 10.8400  \n",
      "\n",
      "Fold: 14  Epoch: 94  Training loss = 4.5254  Validation loss = 10.8394  \n",
      "\n",
      "Fold: 14  Epoch: 95  Training loss = 4.5250  Validation loss = 10.8387  \n",
      "\n",
      "Fold: 14  Epoch: 96  Training loss = 4.5245  Validation loss = 10.8380  \n",
      "\n",
      "Fold: 14  Epoch: 97  Training loss = 4.5241  Validation loss = 10.8374  \n",
      "\n",
      "Fold: 14  Epoch: 98  Training loss = 4.5237  Validation loss = 10.8367  \n",
      "\n",
      "Fold: 14  Epoch: 99  Training loss = 4.5232  Validation loss = 10.8360  \n",
      "\n",
      "Fold: 14  Epoch: 100  Training loss = 4.5228  Validation loss = 10.8354  \n",
      "\n",
      "Fold: 14  Epoch: 101  Training loss = 4.5225  Validation loss = 10.8348  \n",
      "\n",
      "Fold: 14  Epoch: 102  Training loss = 4.5220  Validation loss = 10.8342  \n",
      "\n",
      "Fold: 14  Epoch: 103  Training loss = 4.5215  Validation loss = 10.8334  \n",
      "\n",
      "Fold: 14  Epoch: 104  Training loss = 4.5211  Validation loss = 10.8327  \n",
      "\n",
      "Fold: 14  Epoch: 105  Training loss = 4.5206  Validation loss = 10.8320  \n",
      "\n",
      "Fold: 14  Epoch: 106  Training loss = 4.5201  Validation loss = 10.8313  \n",
      "\n",
      "Fold: 14  Epoch: 107  Training loss = 4.5198  Validation loss = 10.8308  \n",
      "\n",
      "Fold: 14  Epoch: 108  Training loss = 4.5194  Validation loss = 10.8300  \n",
      "\n",
      "Fold: 14  Epoch: 109  Training loss = 4.5189  Validation loss = 10.8294  \n",
      "\n",
      "Fold: 14  Epoch: 110  Training loss = 4.5186  Validation loss = 10.8289  \n",
      "\n",
      "Fold: 14  Epoch: 111  Training loss = 4.5182  Validation loss = 10.8282  \n",
      "\n",
      "Fold: 14  Epoch: 112  Training loss = 4.5178  Validation loss = 10.8276  \n",
      "\n",
      "Fold: 14  Epoch: 113  Training loss = 4.5174  Validation loss = 10.8270  \n",
      "\n",
      "Fold: 14  Epoch: 114  Training loss = 4.5169  Validation loss = 10.8263  \n",
      "\n",
      "Fold: 14  Epoch: 115  Training loss = 4.5166  Validation loss = 10.8257  \n",
      "\n",
      "Fold: 14  Epoch: 116  Training loss = 4.5161  Validation loss = 10.8251  \n",
      "\n",
      "Fold: 14  Epoch: 117  Training loss = 4.5159  Validation loss = 10.8247  \n",
      "\n",
      "Fold: 14  Epoch: 118  Training loss = 4.5154  Validation loss = 10.8240  \n",
      "\n",
      "Fold: 14  Epoch: 119  Training loss = 4.5150  Validation loss = 10.8233  \n",
      "\n",
      "Fold: 14  Epoch: 120  Training loss = 4.5146  Validation loss = 10.8227  \n",
      "\n",
      "Fold: 14  Epoch: 121  Training loss = 4.5142  Validation loss = 10.8222  \n",
      "\n",
      "Fold: 14  Epoch: 122  Training loss = 4.5138  Validation loss = 10.8216  \n",
      "\n",
      "Fold: 14  Epoch: 123  Training loss = 4.5134  Validation loss = 10.8208  \n",
      "\n",
      "Fold: 14  Epoch: 124  Training loss = 4.5129  Validation loss = 10.8202  \n",
      "\n",
      "Fold: 14  Epoch: 125  Training loss = 4.5125  Validation loss = 10.8196  \n",
      "\n",
      "Fold: 14  Epoch: 126  Training loss = 4.5121  Validation loss = 10.8189  \n",
      "\n",
      "Fold: 14  Epoch: 127  Training loss = 4.5117  Validation loss = 10.8183  \n",
      "\n",
      "Fold: 14  Epoch: 128  Training loss = 4.5113  Validation loss = 10.8177  \n",
      "\n",
      "Fold: 14  Epoch: 129  Training loss = 4.5109  Validation loss = 10.8170  \n",
      "\n",
      "Fold: 14  Epoch: 130  Training loss = 4.5104  Validation loss = 10.8163  \n",
      "\n",
      "Fold: 14  Epoch: 131  Training loss = 4.5100  Validation loss = 10.8157  \n",
      "\n",
      "Fold: 14  Epoch: 132  Training loss = 4.5096  Validation loss = 10.8151  \n",
      "\n",
      "Fold: 14  Epoch: 133  Training loss = 4.5091  Validation loss = 10.8143  \n",
      "\n",
      "Fold: 14  Epoch: 134  Training loss = 4.5088  Validation loss = 10.8137  \n",
      "\n",
      "Fold: 14  Epoch: 135  Training loss = 4.5083  Validation loss = 10.8130  \n",
      "\n",
      "Fold: 14  Epoch: 136  Training loss = 4.5079  Validation loss = 10.8124  \n",
      "\n",
      "Fold: 14  Epoch: 137  Training loss = 4.5075  Validation loss = 10.8117  \n",
      "\n",
      "Fold: 14  Epoch: 138  Training loss = 4.5070  Validation loss = 10.8110  \n",
      "\n",
      "Fold: 14  Epoch: 139  Training loss = 4.5066  Validation loss = 10.8104  \n",
      "\n",
      "Fold: 14  Epoch: 140  Training loss = 4.5063  Validation loss = 10.8098  \n",
      "\n",
      "Fold: 14  Epoch: 141  Training loss = 4.5058  Validation loss = 10.8092  \n",
      "\n",
      "Fold: 14  Epoch: 142  Training loss = 4.5054  Validation loss = 10.8086  \n",
      "\n",
      "Fold: 14  Epoch: 143  Training loss = 4.5050  Validation loss = 10.8079  \n",
      "\n",
      "Fold: 14  Epoch: 144  Training loss = 4.5046  Validation loss = 10.8073  \n",
      "\n",
      "Fold: 14  Epoch: 145  Training loss = 4.5042  Validation loss = 10.8067  \n",
      "\n",
      "Fold: 14  Epoch: 146  Training loss = 4.5038  Validation loss = 10.8061  \n",
      "\n",
      "Fold: 14  Epoch: 147  Training loss = 4.5035  Validation loss = 10.8056  \n",
      "\n",
      "Fold: 14  Epoch: 148  Training loss = 4.5030  Validation loss = 10.8048  \n",
      "\n",
      "Fold: 14  Epoch: 149  Training loss = 4.5026  Validation loss = 10.8041  \n",
      "\n",
      "Fold: 14  Epoch: 150  Training loss = 4.5021  Validation loss = 10.8035  \n",
      "\n",
      "Fold: 14  Epoch: 151  Training loss = 4.5018  Validation loss = 10.8029  \n",
      "\n",
      "Fold: 14  Epoch: 152  Training loss = 4.5014  Validation loss = 10.8024  \n",
      "\n",
      "Fold: 14  Epoch: 153  Training loss = 4.5009  Validation loss = 10.8016  \n",
      "\n",
      "Fold: 14  Epoch: 154  Training loss = 4.5005  Validation loss = 10.8010  \n",
      "\n",
      "Fold: 14  Epoch: 155  Training loss = 4.5001  Validation loss = 10.8003  \n",
      "\n",
      "Fold: 14  Epoch: 156  Training loss = 4.4997  Validation loss = 10.7997  \n",
      "\n",
      "Fold: 14  Epoch: 157  Training loss = 4.4993  Validation loss = 10.7990  \n",
      "\n",
      "Fold: 14  Epoch: 158  Training loss = 4.4989  Validation loss = 10.7985  \n",
      "\n",
      "Fold: 14  Epoch: 159  Training loss = 4.4985  Validation loss = 10.7979  \n",
      "\n",
      "Fold: 14  Epoch: 160  Training loss = 4.4981  Validation loss = 10.7973  \n",
      "\n",
      "Fold: 14  Epoch: 161  Training loss = 4.4977  Validation loss = 10.7966  \n",
      "\n",
      "Fold: 14  Epoch: 162  Training loss = 4.4973  Validation loss = 10.7960  \n",
      "\n",
      "Fold: 14  Epoch: 163  Training loss = 4.4969  Validation loss = 10.7954  \n",
      "\n",
      "Fold: 14  Epoch: 164  Training loss = 4.4966  Validation loss = 10.7949  \n",
      "\n",
      "Fold: 14  Epoch: 165  Training loss = 4.4962  Validation loss = 10.7943  \n",
      "\n",
      "Fold: 14  Epoch: 166  Training loss = 4.4958  Validation loss = 10.7936  \n",
      "\n",
      "Fold: 14  Epoch: 167  Training loss = 4.4954  Validation loss = 10.7930  \n",
      "\n",
      "Fold: 14  Epoch: 168  Training loss = 4.4950  Validation loss = 10.7923  \n",
      "\n",
      "Fold: 14  Epoch: 169  Training loss = 4.4946  Validation loss = 10.7917  \n",
      "\n",
      "Fold: 14  Epoch: 170  Training loss = 4.4942  Validation loss = 10.7912  \n",
      "\n",
      "Fold: 14  Epoch: 171  Training loss = 4.4938  Validation loss = 10.7906  \n",
      "\n",
      "Fold: 14  Epoch: 172  Training loss = 4.4934  Validation loss = 10.7900  \n",
      "\n",
      "Fold: 14  Epoch: 173  Training loss = 4.4930  Validation loss = 10.7894  \n",
      "\n",
      "Fold: 14  Epoch: 174  Training loss = 4.4927  Validation loss = 10.7888  \n",
      "\n",
      "Fold: 14  Epoch: 175  Training loss = 4.4923  Validation loss = 10.7882  \n",
      "\n",
      "Fold: 14  Epoch: 176  Training loss = 4.4918  Validation loss = 10.7875  \n",
      "\n",
      "Fold: 14  Epoch: 177  Training loss = 4.4914  Validation loss = 10.7869  \n",
      "\n",
      "Fold: 14  Epoch: 178  Training loss = 4.4910  Validation loss = 10.7863  \n",
      "\n",
      "Fold: 14  Epoch: 179  Training loss = 4.4906  Validation loss = 10.7856  \n",
      "\n",
      "Fold: 14  Epoch: 180  Training loss = 4.4901  Validation loss = 10.7849  \n",
      "\n",
      "Fold: 14  Epoch: 181  Training loss = 4.4896  Validation loss = 10.7841  \n",
      "\n",
      "Fold: 14  Epoch: 182  Training loss = 4.4892  Validation loss = 10.7835  \n",
      "\n",
      "Fold: 14  Epoch: 183  Training loss = 4.4888  Validation loss = 10.7828  \n",
      "\n",
      "Fold: 14  Epoch: 184  Training loss = 4.4884  Validation loss = 10.7822  \n",
      "\n",
      "Fold: 14  Epoch: 185  Training loss = 4.4879  Validation loss = 10.7815  \n",
      "\n",
      "Fold: 14  Epoch: 186  Training loss = 4.4875  Validation loss = 10.7808  \n",
      "\n",
      "Fold: 14  Epoch: 187  Training loss = 4.4870  Validation loss = 10.7801  \n",
      "\n",
      "Fold: 14  Epoch: 188  Training loss = 4.4867  Validation loss = 10.7795  \n",
      "\n",
      "Fold: 14  Epoch: 189  Training loss = 4.4863  Validation loss = 10.7789  \n",
      "\n",
      "Fold: 14  Epoch: 190  Training loss = 4.4858  Validation loss = 10.7782  \n",
      "\n",
      "Fold: 14  Epoch: 191  Training loss = 4.4854  Validation loss = 10.7775  \n",
      "\n",
      "Fold: 14  Epoch: 192  Training loss = 4.4850  Validation loss = 10.7770  \n",
      "\n",
      "Fold: 14  Epoch: 193  Training loss = 4.4846  Validation loss = 10.7764  \n",
      "\n",
      "Fold: 14  Epoch: 194  Training loss = 4.4843  Validation loss = 10.7758  \n",
      "\n",
      "Fold: 14  Epoch: 195  Training loss = 4.4839  Validation loss = 10.7752  \n",
      "\n",
      "Fold: 14  Epoch: 196  Training loss = 4.4834  Validation loss = 10.7745  \n",
      "\n",
      "Fold: 14  Epoch: 197  Training loss = 4.4830  Validation loss = 10.7739  \n",
      "\n",
      "Fold: 14  Epoch: 198  Training loss = 4.4826  Validation loss = 10.7733  \n",
      "\n",
      "Fold: 14  Epoch: 199  Training loss = 4.4822  Validation loss = 10.7725  \n",
      "\n",
      "Fold: 14  Epoch: 200  Training loss = 4.4818  Validation loss = 10.7719  \n",
      "\n",
      "Fold: 14  Epoch: 201  Training loss = 4.4814  Validation loss = 10.7714  \n",
      "\n",
      "Fold: 14  Epoch: 202  Training loss = 4.4809  Validation loss = 10.7706  \n",
      "\n",
      "Fold: 14  Epoch: 203  Training loss = 4.4806  Validation loss = 10.7701  \n",
      "\n",
      "Fold: 14  Epoch: 204  Training loss = 4.4801  Validation loss = 10.7694  \n",
      "\n",
      "Fold: 14  Epoch: 205  Training loss = 4.4797  Validation loss = 10.7687  \n",
      "\n",
      "Fold: 14  Epoch: 206  Training loss = 4.4794  Validation loss = 10.7682  \n",
      "\n",
      "Fold: 14  Epoch: 207  Training loss = 4.4789  Validation loss = 10.7675  \n",
      "\n",
      "Fold: 14  Epoch: 208  Training loss = 4.4784  Validation loss = 10.7667  \n",
      "\n",
      "Fold: 14  Epoch: 209  Training loss = 4.4780  Validation loss = 10.7661  \n",
      "\n",
      "Fold: 14  Epoch: 210  Training loss = 4.4776  Validation loss = 10.7654  \n",
      "\n",
      "Fold: 14  Epoch: 211  Training loss = 4.4772  Validation loss = 10.7649  \n",
      "\n",
      "Fold: 14  Epoch: 212  Training loss = 4.4767  Validation loss = 10.7641  \n",
      "\n",
      "Fold: 14  Epoch: 213  Training loss = 4.4764  Validation loss = 10.7635  \n",
      "\n",
      "Fold: 14  Epoch: 214  Training loss = 4.4759  Validation loss = 10.7629  \n",
      "\n",
      "Fold: 14  Epoch: 215  Training loss = 4.4755  Validation loss = 10.7622  \n",
      "\n",
      "Fold: 14  Epoch: 216  Training loss = 4.4751  Validation loss = 10.7616  \n",
      "\n",
      "Fold: 14  Epoch: 217  Training loss = 4.4747  Validation loss = 10.7610  \n",
      "\n",
      "Fold: 14  Epoch: 218  Training loss = 4.4742  Validation loss = 10.7602  \n",
      "\n",
      "Fold: 14  Epoch: 219  Training loss = 4.4738  Validation loss = 10.7595  \n",
      "\n",
      "Fold: 14  Epoch: 220  Training loss = 4.4734  Validation loss = 10.7589  \n",
      "\n",
      "Fold: 14  Epoch: 221  Training loss = 4.4730  Validation loss = 10.7583  \n",
      "\n",
      "Fold: 14  Epoch: 222  Training loss = 4.4725  Validation loss = 10.7576  \n",
      "\n",
      "Fold: 14  Epoch: 223  Training loss = 4.4721  Validation loss = 10.7569  \n",
      "\n",
      "Fold: 14  Epoch: 224  Training loss = 4.4718  Validation loss = 10.7564  \n",
      "\n",
      "Fold: 14  Epoch: 225  Training loss = 4.4713  Validation loss = 10.7557  \n",
      "\n",
      "Fold: 14  Epoch: 226  Training loss = 4.4710  Validation loss = 10.7551  \n",
      "\n",
      "Fold: 14  Epoch: 227  Training loss = 4.4706  Validation loss = 10.7545  \n",
      "\n",
      "Fold: 14  Epoch: 228  Training loss = 4.4701  Validation loss = 10.7539  \n",
      "\n",
      "Fold: 14  Epoch: 229  Training loss = 4.4698  Validation loss = 10.7533  \n",
      "\n",
      "Fold: 14  Epoch: 230  Training loss = 4.4695  Validation loss = 10.7528  \n",
      "\n",
      "Fold: 14  Epoch: 231  Training loss = 4.4691  Validation loss = 10.7522  \n",
      "\n",
      "Fold: 14  Epoch: 232  Training loss = 4.4687  Validation loss = 10.7516  \n",
      "\n",
      "Fold: 14  Epoch: 233  Training loss = 4.4682  Validation loss = 10.7509  \n",
      "\n",
      "Fold: 14  Epoch: 234  Training loss = 4.4679  Validation loss = 10.7503  \n",
      "\n",
      "Fold: 14  Epoch: 235  Training loss = 4.4674  Validation loss = 10.7496  \n",
      "\n",
      "Fold: 14  Epoch: 236  Training loss = 4.4670  Validation loss = 10.7490  \n",
      "\n",
      "Fold: 14  Epoch: 237  Training loss = 4.4665  Validation loss = 10.7483  \n",
      "\n",
      "Fold: 14  Epoch: 238  Training loss = 4.4661  Validation loss = 10.7476  \n",
      "\n",
      "Fold: 14  Epoch: 239  Training loss = 4.4658  Validation loss = 10.7471  \n",
      "\n",
      "Fold: 14  Epoch: 240  Training loss = 4.4654  Validation loss = 10.7464  \n",
      "\n",
      "Fold: 14  Epoch: 241  Training loss = 4.4649  Validation loss = 10.7457  \n",
      "\n",
      "Fold: 14  Epoch: 242  Training loss = 4.4644  Validation loss = 10.7450  \n",
      "\n",
      "Fold: 14  Epoch: 243  Training loss = 4.4639  Validation loss = 10.7442  \n",
      "\n",
      "Fold: 14  Epoch: 244  Training loss = 4.4635  Validation loss = 10.7435  \n",
      "\n",
      "Fold: 14  Epoch: 245  Training loss = 4.4632  Validation loss = 10.7430  \n",
      "\n",
      "Fold: 14  Epoch: 246  Training loss = 4.4627  Validation loss = 10.7424  \n",
      "\n",
      "Fold: 14  Epoch: 247  Training loss = 4.4623  Validation loss = 10.7417  \n",
      "\n",
      "Fold: 14  Epoch: 248  Training loss = 4.4619  Validation loss = 10.7410  \n",
      "\n",
      "Fold: 14  Epoch: 249  Training loss = 4.4614  Validation loss = 10.7404  \n",
      "\n",
      "Fold: 14  Epoch: 250  Training loss = 4.4610  Validation loss = 10.7396  \n",
      "\n",
      "Fold: 14  Epoch: 251  Training loss = 4.4606  Validation loss = 10.7390  \n",
      "\n",
      "Fold: 14  Epoch: 252  Training loss = 4.4602  Validation loss = 10.7383  \n",
      "\n",
      "Fold: 14  Epoch: 253  Training loss = 4.4598  Validation loss = 10.7378  \n",
      "\n",
      "Fold: 14  Epoch: 254  Training loss = 4.4595  Validation loss = 10.7373  \n",
      "\n",
      "Fold: 14  Epoch: 255  Training loss = 4.4590  Validation loss = 10.7366  \n",
      "\n",
      "Fold: 14  Epoch: 256  Training loss = 4.4587  Validation loss = 10.7361  \n",
      "\n",
      "Fold: 14  Epoch: 257  Training loss = 4.4584  Validation loss = 10.7356  \n",
      "\n",
      "Fold: 14  Epoch: 258  Training loss = 4.4580  Validation loss = 10.7351  \n",
      "\n",
      "Fold: 14  Epoch: 259  Training loss = 4.4577  Validation loss = 10.7345  \n",
      "\n",
      "Fold: 14  Epoch: 260  Training loss = 4.4573  Validation loss = 10.7338  \n",
      "\n",
      "Fold: 14  Epoch: 261  Training loss = 4.4568  Validation loss = 10.7331  \n",
      "\n",
      "Fold: 14  Epoch: 262  Training loss = 4.4563  Validation loss = 10.7323  \n",
      "\n",
      "Fold: 14  Epoch: 263  Training loss = 4.4558  Validation loss = 10.7315  \n",
      "\n",
      "Fold: 14  Epoch: 264  Training loss = 4.4554  Validation loss = 10.7309  \n",
      "\n",
      "Fold: 14  Epoch: 265  Training loss = 4.4550  Validation loss = 10.7302  \n",
      "\n",
      "Fold: 14  Epoch: 266  Training loss = 4.4545  Validation loss = 10.7295  \n",
      "\n",
      "Fold: 14  Epoch: 267  Training loss = 4.4542  Validation loss = 10.7290  \n",
      "\n",
      "Fold: 14  Epoch: 268  Training loss = 4.4537  Validation loss = 10.7284  \n",
      "\n",
      "Fold: 14  Epoch: 269  Training loss = 4.4533  Validation loss = 10.7277  \n",
      "\n",
      "Fold: 14  Epoch: 270  Training loss = 4.4529  Validation loss = 10.7271  \n",
      "\n",
      "Fold: 14  Epoch: 271  Training loss = 4.4525  Validation loss = 10.7265  \n",
      "\n",
      "Fold: 14  Epoch: 272  Training loss = 4.4521  Validation loss = 10.7257  \n",
      "\n",
      "Fold: 14  Epoch: 273  Training loss = 4.4517  Validation loss = 10.7251  \n",
      "\n",
      "Fold: 14  Epoch: 274  Training loss = 4.4512  Validation loss = 10.7244  \n",
      "\n",
      "Fold: 14  Epoch: 275  Training loss = 4.4508  Validation loss = 10.7237  \n",
      "\n",
      "Fold: 14  Epoch: 276  Training loss = 4.4504  Validation loss = 10.7231  \n",
      "\n",
      "Fold: 14  Epoch: 277  Training loss = 4.4499  Validation loss = 10.7224  \n",
      "\n",
      "Fold: 14  Epoch: 278  Training loss = 4.4496  Validation loss = 10.7219  \n",
      "\n",
      "Fold: 14  Epoch: 279  Training loss = 4.4492  Validation loss = 10.7212  \n",
      "\n",
      "Fold: 14  Epoch: 280  Training loss = 4.4488  Validation loss = 10.7207  \n",
      "\n",
      "Fold: 14  Epoch: 281  Training loss = 4.4484  Validation loss = 10.7200  \n",
      "\n",
      "Fold: 14  Epoch: 282  Training loss = 4.4481  Validation loss = 10.7195  \n",
      "\n",
      "Fold: 14  Epoch: 283  Training loss = 4.4476  Validation loss = 10.7188  \n",
      "\n",
      "Fold: 14  Epoch: 284  Training loss = 4.4472  Validation loss = 10.7181  \n",
      "\n",
      "Fold: 14  Epoch: 285  Training loss = 4.4468  Validation loss = 10.7176  \n",
      "\n",
      "Fold: 14  Epoch: 286  Training loss = 4.4465  Validation loss = 10.7171  \n",
      "\n",
      "Fold: 14  Epoch: 287  Training loss = 4.4461  Validation loss = 10.7164  \n",
      "\n",
      "Fold: 14  Epoch: 288  Training loss = 4.4457  Validation loss = 10.7158  \n",
      "\n",
      "Fold: 14  Epoch: 289  Training loss = 4.4453  Validation loss = 10.7151  \n",
      "\n",
      "Fold: 14  Epoch: 290  Training loss = 4.4448  Validation loss = 10.7145  \n",
      "\n",
      "Fold: 14  Epoch: 291  Training loss = 4.4444  Validation loss = 10.7139  \n",
      "\n",
      "Fold: 14  Epoch: 292  Training loss = 4.4440  Validation loss = 10.7132  \n",
      "\n",
      "Fold: 14  Epoch: 293  Training loss = 4.4437  Validation loss = 10.7126  \n",
      "\n",
      "Fold: 14  Epoch: 294  Training loss = 4.4433  Validation loss = 10.7121  \n",
      "\n",
      "Fold: 14  Epoch: 295  Training loss = 4.4429  Validation loss = 10.7115  \n",
      "\n",
      "Fold: 14  Epoch: 296  Training loss = 4.4425  Validation loss = 10.7109  \n",
      "\n",
      "Fold: 14  Epoch: 297  Training loss = 4.4421  Validation loss = 10.7102  \n",
      "\n",
      "Fold: 14  Epoch: 298  Training loss = 4.4416  Validation loss = 10.7095  \n",
      "\n",
      "Fold: 14  Epoch: 299  Training loss = 4.4412  Validation loss = 10.7088  \n",
      "\n",
      "Fold: 14  Epoch: 300  Training loss = 4.4408  Validation loss = 10.7082  \n",
      "\n",
      "Fold: 14  Epoch: 301  Training loss = 4.4404  Validation loss = 10.7075  \n",
      "\n",
      "Fold: 14  Epoch: 302  Training loss = 4.4400  Validation loss = 10.7069  \n",
      "\n",
      "Fold: 14  Epoch: 303  Training loss = 4.4395  Validation loss = 10.7062  \n",
      "\n",
      "Fold: 14  Epoch: 304  Training loss = 4.4391  Validation loss = 10.7055  \n",
      "\n",
      "Fold: 14  Epoch: 305  Training loss = 4.4387  Validation loss = 10.7049  \n",
      "\n",
      "Fold: 14  Epoch: 306  Training loss = 4.4383  Validation loss = 10.7043  \n",
      "\n",
      "Fold: 14  Epoch: 307  Training loss = 4.4379  Validation loss = 10.7036  \n",
      "\n",
      "Fold: 14  Epoch: 308  Training loss = 4.4375  Validation loss = 10.7031  \n",
      "\n",
      "Fold: 14  Epoch: 309  Training loss = 4.4371  Validation loss = 10.7024  \n",
      "\n",
      "Fold: 14  Epoch: 310  Training loss = 4.4367  Validation loss = 10.7019  \n",
      "\n",
      "Fold: 14  Epoch: 311  Training loss = 4.4364  Validation loss = 10.7013  \n",
      "\n",
      "Fold: 14  Epoch: 312  Training loss = 4.4361  Validation loss = 10.7008  \n",
      "\n",
      "Fold: 14  Epoch: 313  Training loss = 4.4356  Validation loss = 10.7001  \n",
      "\n",
      "Fold: 14  Epoch: 314  Training loss = 4.4352  Validation loss = 10.6995  \n",
      "\n",
      "Fold: 14  Epoch: 315  Training loss = 4.4348  Validation loss = 10.6989  \n",
      "\n",
      "Fold: 14  Epoch: 316  Training loss = 4.4345  Validation loss = 10.6983  \n",
      "\n",
      "Fold: 14  Epoch: 317  Training loss = 4.4340  Validation loss = 10.6977  \n",
      "\n",
      "Fold: 14  Epoch: 318  Training loss = 4.4336  Validation loss = 10.6971  \n",
      "\n",
      "Fold: 14  Epoch: 319  Training loss = 4.4333  Validation loss = 10.6965  \n",
      "\n",
      "Fold: 14  Epoch: 320  Training loss = 4.4329  Validation loss = 10.6959  \n",
      "\n",
      "Fold: 14  Epoch: 321  Training loss = 4.4324  Validation loss = 10.6951  \n",
      "\n",
      "Fold: 14  Epoch: 322  Training loss = 4.4320  Validation loss = 10.6944  \n",
      "\n",
      "Fold: 14  Epoch: 323  Training loss = 4.4316  Validation loss = 10.6939  \n",
      "\n",
      "Fold: 14  Epoch: 324  Training loss = 4.4312  Validation loss = 10.6932  \n",
      "\n",
      "Fold: 14  Epoch: 325  Training loss = 4.4308  Validation loss = 10.6927  \n",
      "\n",
      "Fold: 14  Epoch: 326  Training loss = 4.4304  Validation loss = 10.6921  \n",
      "\n",
      "Fold: 14  Epoch: 327  Training loss = 4.4300  Validation loss = 10.6913  \n",
      "\n",
      "Fold: 14  Epoch: 328  Training loss = 4.4296  Validation loss = 10.6908  \n",
      "\n",
      "Fold: 14  Epoch: 329  Training loss = 4.4292  Validation loss = 10.6900  \n",
      "\n",
      "Fold: 14  Epoch: 330  Training loss = 4.4288  Validation loss = 10.6894  \n",
      "\n",
      "Fold: 14  Epoch: 331  Training loss = 4.4284  Validation loss = 10.6889  \n",
      "\n",
      "Fold: 14  Epoch: 332  Training loss = 4.4280  Validation loss = 10.6883  \n",
      "\n",
      "Fold: 14  Epoch: 333  Training loss = 4.4277  Validation loss = 10.6878  \n",
      "\n",
      "Fold: 14  Epoch: 334  Training loss = 4.4273  Validation loss = 10.6872  \n",
      "\n",
      "Fold: 14  Epoch: 335  Training loss = 4.4270  Validation loss = 10.6866  \n",
      "\n",
      "Fold: 14  Epoch: 336  Training loss = 4.4266  Validation loss = 10.6860  \n",
      "\n",
      "Fold: 14  Epoch: 337  Training loss = 4.4261  Validation loss = 10.6853  \n",
      "\n",
      "Fold: 14  Epoch: 338  Training loss = 4.4257  Validation loss = 10.6847  \n",
      "\n",
      "Fold: 14  Epoch: 339  Training loss = 4.4253  Validation loss = 10.6841  \n",
      "\n",
      "Fold: 14  Epoch: 340  Training loss = 4.4249  Validation loss = 10.6834  \n",
      "\n",
      "Fold: 14  Epoch: 341  Training loss = 4.4245  Validation loss = 10.6828  \n",
      "\n",
      "Fold: 14  Epoch: 342  Training loss = 4.4241  Validation loss = 10.6822  \n",
      "\n",
      "Fold: 14  Epoch: 343  Training loss = 4.4237  Validation loss = 10.6815  \n",
      "\n",
      "Fold: 14  Epoch: 344  Training loss = 4.4233  Validation loss = 10.6809  \n",
      "\n",
      "Fold: 14  Epoch: 345  Training loss = 4.4230  Validation loss = 10.6804  \n",
      "\n",
      "Fold: 14  Epoch: 346  Training loss = 4.4225  Validation loss = 10.6797  \n",
      "\n",
      "Fold: 14  Epoch: 347  Training loss = 4.4222  Validation loss = 10.6791  \n",
      "\n",
      "Fold: 14  Epoch: 348  Training loss = 4.4217  Validation loss = 10.6784  \n",
      "\n",
      "Fold: 14  Epoch: 349  Training loss = 4.4213  Validation loss = 10.6777  \n",
      "\n",
      "Fold: 14  Epoch: 350  Training loss = 4.4209  Validation loss = 10.6771  \n",
      "\n",
      "Fold: 14  Epoch: 351  Training loss = 4.4205  Validation loss = 10.6765  \n",
      "\n",
      "Fold: 14  Epoch: 352  Training loss = 4.4201  Validation loss = 10.6759  \n",
      "\n",
      "Fold: 14  Epoch: 353  Training loss = 4.4196  Validation loss = 10.6752  \n",
      "\n",
      "Fold: 14  Epoch: 354  Training loss = 4.4192  Validation loss = 10.6744  \n",
      "\n",
      "Fold: 14  Epoch: 355  Training loss = 4.4187  Validation loss = 10.6737  \n",
      "\n",
      "Fold: 14  Epoch: 356  Training loss = 4.4183  Validation loss = 10.6731  \n",
      "\n",
      "Fold: 14  Epoch: 357  Training loss = 4.4179  Validation loss = 10.6724  \n",
      "\n",
      "Fold: 14  Epoch: 358  Training loss = 4.4175  Validation loss = 10.6718  \n",
      "\n",
      "Fold: 14  Epoch: 359  Training loss = 4.4172  Validation loss = 10.6713  \n",
      "\n",
      "Fold: 14  Epoch: 360  Training loss = 4.4168  Validation loss = 10.6707  \n",
      "\n",
      "Fold: 14  Epoch: 361  Training loss = 4.4163  Validation loss = 10.6700  \n",
      "\n",
      "Fold: 14  Epoch: 362  Training loss = 4.4159  Validation loss = 10.6693  \n",
      "\n",
      "Fold: 14  Epoch: 363  Training loss = 4.4155  Validation loss = 10.6686  \n",
      "\n",
      "Fold: 14  Epoch: 364  Training loss = 4.4151  Validation loss = 10.6680  \n",
      "\n",
      "Fold: 14  Epoch: 365  Training loss = 4.4147  Validation loss = 10.6674  \n",
      "\n",
      "Fold: 14  Epoch: 366  Training loss = 4.4143  Validation loss = 10.6668  \n",
      "\n",
      "Fold: 14  Epoch: 367  Training loss = 4.4139  Validation loss = 10.6661  \n",
      "\n",
      "Fold: 14  Epoch: 368  Training loss = 4.4135  Validation loss = 10.6655  \n",
      "\n",
      "Fold: 14  Epoch: 369  Training loss = 4.4131  Validation loss = 10.6649  \n",
      "\n",
      "Fold: 14  Epoch: 370  Training loss = 4.4129  Validation loss = 10.6645  \n",
      "\n",
      "Fold: 14  Epoch: 371  Training loss = 4.4125  Validation loss = 10.6639  \n",
      "\n",
      "Fold: 14  Epoch: 372  Training loss = 4.4121  Validation loss = 10.6633  \n",
      "\n",
      "Fold: 14  Epoch: 373  Training loss = 4.4116  Validation loss = 10.6625  \n",
      "\n",
      "Fold: 14  Epoch: 374  Training loss = 4.4112  Validation loss = 10.6619  \n",
      "\n",
      "Fold: 14  Epoch: 375  Training loss = 4.4108  Validation loss = 10.6613  \n",
      "\n",
      "Fold: 14  Epoch: 376  Training loss = 4.4104  Validation loss = 10.6607  \n",
      "\n",
      "Fold: 14  Epoch: 377  Training loss = 4.4100  Validation loss = 10.6600  \n",
      "\n",
      "Fold: 14  Epoch: 378  Training loss = 4.4095  Validation loss = 10.6593  \n",
      "\n",
      "Fold: 14  Epoch: 379  Training loss = 4.4092  Validation loss = 10.6587  \n",
      "\n",
      "Fold: 14  Epoch: 380  Training loss = 4.4087  Validation loss = 10.6580  \n",
      "\n",
      "Fold: 14  Epoch: 381  Training loss = 4.4083  Validation loss = 10.6574  \n",
      "\n",
      "Fold: 14  Epoch: 382  Training loss = 4.4079  Validation loss = 10.6567  \n",
      "\n",
      "Fold: 14  Epoch: 383  Training loss = 4.4074  Validation loss = 10.6560  \n",
      "\n",
      "Fold: 14  Epoch: 384  Training loss = 4.4070  Validation loss = 10.6553  \n",
      "\n",
      "Fold: 14  Epoch: 385  Training loss = 4.4066  Validation loss = 10.6546  \n",
      "\n",
      "Fold: 14  Epoch: 386  Training loss = 4.4061  Validation loss = 10.6539  \n",
      "\n",
      "Fold: 14  Epoch: 387  Training loss = 4.4056  Validation loss = 10.6532  \n",
      "\n",
      "Fold: 14  Epoch: 388  Training loss = 4.4052  Validation loss = 10.6525  \n",
      "\n",
      "Fold: 14  Epoch: 389  Training loss = 4.4048  Validation loss = 10.6519  \n",
      "\n",
      "Fold: 14  Epoch: 390  Training loss = 4.4044  Validation loss = 10.6512  \n",
      "\n",
      "Fold: 14  Epoch: 391  Training loss = 4.4040  Validation loss = 10.6506  \n",
      "\n",
      "Fold: 14  Epoch: 392  Training loss = 4.4036  Validation loss = 10.6499  \n",
      "\n",
      "Fold: 14  Epoch: 393  Training loss = 4.4032  Validation loss = 10.6493  \n",
      "\n",
      "Fold: 14  Epoch: 394  Training loss = 4.4028  Validation loss = 10.6487  \n",
      "\n",
      "Fold: 14  Epoch: 395  Training loss = 4.4024  Validation loss = 10.6480  \n",
      "\n",
      "Fold: 14  Epoch: 396  Training loss = 4.4020  Validation loss = 10.6475  \n",
      "\n",
      "Fold: 14  Epoch: 397  Training loss = 4.4016  Validation loss = 10.6469  \n",
      "\n",
      "Fold: 14  Epoch: 398  Training loss = 4.4012  Validation loss = 10.6462  \n",
      "\n",
      "Fold: 14  Epoch: 399  Training loss = 4.4007  Validation loss = 10.6455  \n",
      "\n",
      "Fold: 14  Epoch: 400  Training loss = 4.4003  Validation loss = 10.6449  \n",
      "\n",
      "Fold: 14  Epoch: 401  Training loss = 4.3999  Validation loss = 10.6442  \n",
      "\n",
      "Fold: 14  Epoch: 402  Training loss = 4.3995  Validation loss = 10.6435  \n",
      "\n",
      "Fold: 14  Epoch: 403  Training loss = 4.3990  Validation loss = 10.6428  \n",
      "\n",
      "Fold: 14  Epoch: 404  Training loss = 4.3986  Validation loss = 10.6421  \n",
      "\n",
      "Fold: 14  Epoch: 405  Training loss = 4.3982  Validation loss = 10.6415  \n",
      "\n",
      "Fold: 14  Epoch: 406  Training loss = 4.3979  Validation loss = 10.6409  \n",
      "\n",
      "Fold: 14  Epoch: 407  Training loss = 4.3975  Validation loss = 10.6404  \n",
      "\n",
      "Fold: 14  Epoch: 408  Training loss = 4.3970  Validation loss = 10.6396  \n",
      "\n",
      "Fold: 14  Epoch: 409  Training loss = 4.3966  Validation loss = 10.6389  \n",
      "\n",
      "Fold: 14  Epoch: 410  Training loss = 4.3962  Validation loss = 10.6384  \n",
      "\n",
      "Fold: 14  Epoch: 411  Training loss = 4.3958  Validation loss = 10.6377  \n",
      "\n",
      "Fold: 14  Epoch: 412  Training loss = 4.3953  Validation loss = 10.6370  \n",
      "\n",
      "Fold: 14  Epoch: 413  Training loss = 4.3951  Validation loss = 10.6366  \n",
      "\n",
      "Fold: 14  Epoch: 414  Training loss = 4.3947  Validation loss = 10.6361  \n",
      "\n",
      "Fold: 14  Epoch: 415  Training loss = 4.3943  Validation loss = 10.6354  \n",
      "\n",
      "Fold: 14  Epoch: 416  Training loss = 4.3939  Validation loss = 10.6346  \n",
      "\n",
      "Fold: 14  Epoch: 417  Training loss = 4.3935  Validation loss = 10.6340  \n",
      "\n",
      "Fold: 14  Epoch: 418  Training loss = 4.3931  Validation loss = 10.6334  \n",
      "\n",
      "Fold: 14  Epoch: 419  Training loss = 4.3928  Validation loss = 10.6330  \n",
      "\n",
      "Fold: 14  Epoch: 420  Training loss = 4.3923  Validation loss = 10.6322  \n",
      "\n",
      "Fold: 14  Epoch: 421  Training loss = 4.3920  Validation loss = 10.6317  \n",
      "\n",
      "Fold: 14  Epoch: 422  Training loss = 4.3917  Validation loss = 10.6312  \n",
      "\n",
      "Fold: 14  Epoch: 423  Training loss = 4.3912  Validation loss = 10.6304  \n",
      "\n",
      "Fold: 14  Epoch: 424  Training loss = 4.3908  Validation loss = 10.6297  \n",
      "\n",
      "Fold: 14  Epoch: 425  Training loss = 4.3903  Validation loss = 10.6291  \n",
      "\n",
      "Fold: 14  Epoch: 426  Training loss = 4.3900  Validation loss = 10.6285  \n",
      "\n",
      "Fold: 14  Epoch: 427  Training loss = 4.3895  Validation loss = 10.6278  \n",
      "\n",
      "Fold: 14  Epoch: 428  Training loss = 4.3891  Validation loss = 10.6272  \n",
      "\n",
      "Fold: 14  Epoch: 429  Training loss = 4.3887  Validation loss = 10.6265  \n",
      "\n",
      "Fold: 14  Epoch: 430  Training loss = 4.3884  Validation loss = 10.6260  \n",
      "\n",
      "Fold: 14  Epoch: 431  Training loss = 4.3880  Validation loss = 10.6253  \n",
      "\n",
      "Fold: 14  Epoch: 432  Training loss = 4.3875  Validation loss = 10.6246  \n",
      "\n",
      "Fold: 14  Epoch: 433  Training loss = 4.3871  Validation loss = 10.6240  \n",
      "\n",
      "Fold: 14  Epoch: 434  Training loss = 4.3867  Validation loss = 10.6233  \n",
      "\n",
      "Fold: 14  Epoch: 435  Training loss = 4.3863  Validation loss = 10.6227  \n",
      "\n",
      "Fold: 14  Epoch: 436  Training loss = 4.3859  Validation loss = 10.6221  \n",
      "\n",
      "Fold: 14  Epoch: 437  Training loss = 4.3855  Validation loss = 10.6214  \n",
      "\n",
      "Fold: 14  Epoch: 438  Training loss = 4.3851  Validation loss = 10.6209  \n",
      "\n",
      "Fold: 14  Epoch: 439  Training loss = 4.3848  Validation loss = 10.6203  \n",
      "\n",
      "Fold: 14  Epoch: 440  Training loss = 4.3843  Validation loss = 10.6196  \n",
      "\n",
      "Fold: 14  Epoch: 441  Training loss = 4.3839  Validation loss = 10.6189  \n",
      "\n",
      "Fold: 14  Epoch: 442  Training loss = 4.3834  Validation loss = 10.6181  \n",
      "\n",
      "Fold: 14  Epoch: 443  Training loss = 4.3829  Validation loss = 10.6173  \n",
      "\n",
      "Fold: 14  Epoch: 444  Training loss = 4.3825  Validation loss = 10.6167  \n",
      "\n",
      "Fold: 14  Epoch: 445  Training loss = 4.3821  Validation loss = 10.6160  \n",
      "\n",
      "Fold: 14  Epoch: 446  Training loss = 4.3817  Validation loss = 10.6155  \n",
      "\n",
      "Fold: 14  Epoch: 447  Training loss = 4.3813  Validation loss = 10.6147  \n",
      "\n",
      "Fold: 14  Epoch: 448  Training loss = 4.3808  Validation loss = 10.6140  \n",
      "\n",
      "Fold: 14  Epoch: 449  Training loss = 4.3804  Validation loss = 10.6134  \n",
      "\n",
      "Fold: 14  Epoch: 450  Training loss = 4.3800  Validation loss = 10.6127  \n",
      "\n",
      "Fold: 14  Epoch: 451  Training loss = 4.3795  Validation loss = 10.6119  \n",
      "\n",
      "Fold: 14  Epoch: 452  Training loss = 4.3791  Validation loss = 10.6113  \n",
      "\n",
      "Fold: 14  Epoch: 453  Training loss = 4.3787  Validation loss = 10.6106  \n",
      "\n",
      "Fold: 14  Epoch: 454  Training loss = 4.3783  Validation loss = 10.6100  \n",
      "\n",
      "Fold: 14  Epoch: 455  Training loss = 4.3779  Validation loss = 10.6094  \n",
      "\n",
      "Fold: 14  Epoch: 456  Training loss = 4.3774  Validation loss = 10.6086  \n",
      "\n",
      "Fold: 14  Epoch: 457  Training loss = 4.3770  Validation loss = 10.6081  \n",
      "\n",
      "Fold: 14  Epoch: 458  Training loss = 4.3766  Validation loss = 10.6073  \n",
      "\n",
      "Fold: 14  Epoch: 459  Training loss = 4.3762  Validation loss = 10.6067  \n",
      "\n",
      "Fold: 14  Epoch: 460  Training loss = 4.3758  Validation loss = 10.6060  \n",
      "\n",
      "Fold: 14  Epoch: 461  Training loss = 4.3754  Validation loss = 10.6054  \n",
      "\n",
      "Fold: 14  Epoch: 462  Training loss = 4.3750  Validation loss = 10.6048  \n",
      "\n",
      "Fold: 14  Epoch: 463  Training loss = 4.3746  Validation loss = 10.6042  \n",
      "\n",
      "Fold: 14  Epoch: 464  Training loss = 4.3742  Validation loss = 10.6036  \n",
      "\n",
      "Fold: 14  Epoch: 465  Training loss = 4.3739  Validation loss = 10.6030  \n",
      "\n",
      "Fold: 14  Epoch: 466  Training loss = 4.3735  Validation loss = 10.6024  \n",
      "\n",
      "Fold: 14  Epoch: 467  Training loss = 4.3732  Validation loss = 10.6019  \n",
      "\n",
      "Fold: 14  Epoch: 468  Training loss = 4.3728  Validation loss = 10.6012  \n",
      "\n",
      "Fold: 14  Epoch: 469  Training loss = 4.3723  Validation loss = 10.6006  \n",
      "\n",
      "Fold: 14  Epoch: 470  Training loss = 4.3720  Validation loss = 10.6000  \n",
      "\n",
      "Fold: 14  Epoch: 471  Training loss = 4.3715  Validation loss = 10.5993  \n",
      "\n",
      "Fold: 14  Epoch: 472  Training loss = 4.3711  Validation loss = 10.5986  \n",
      "\n",
      "Fold: 14  Epoch: 473  Training loss = 4.3706  Validation loss = 10.5978  \n",
      "\n",
      "Fold: 14  Epoch: 474  Training loss = 4.3702  Validation loss = 10.5971  \n",
      "\n",
      "Fold: 14  Epoch: 475  Training loss = 4.3697  Validation loss = 10.5964  \n",
      "\n",
      "Fold: 14  Epoch: 476  Training loss = 4.3693  Validation loss = 10.5957  \n",
      "\n",
      "Fold: 14  Epoch: 477  Training loss = 4.3688  Validation loss = 10.5949  \n",
      "\n",
      "Fold: 14  Epoch: 478  Training loss = 4.3684  Validation loss = 10.5943  \n",
      "\n",
      "Fold: 14  Epoch: 479  Training loss = 4.3679  Validation loss = 10.5936  \n",
      "\n",
      "Fold: 14  Epoch: 480  Training loss = 4.3675  Validation loss = 10.5929  \n",
      "\n",
      "Fold: 14  Epoch: 481  Training loss = 4.3672  Validation loss = 10.5924  \n",
      "\n",
      "Fold: 14  Epoch: 482  Training loss = 4.3668  Validation loss = 10.5917  \n",
      "\n",
      "Fold: 14  Epoch: 483  Training loss = 4.3663  Validation loss = 10.5910  \n",
      "\n",
      "Fold: 14  Epoch: 484  Training loss = 4.3659  Validation loss = 10.5904  \n",
      "\n",
      "Fold: 14  Epoch: 485  Training loss = 4.3655  Validation loss = 10.5897  \n",
      "\n",
      "Fold: 14  Epoch: 486  Training loss = 4.3650  Validation loss = 10.5890  \n",
      "\n",
      "Fold: 14  Epoch: 487  Training loss = 4.3647  Validation loss = 10.5885  \n",
      "\n",
      "Fold: 14  Epoch: 488  Training loss = 4.3643  Validation loss = 10.5878  \n",
      "\n",
      "Fold: 14  Epoch: 489  Training loss = 4.3639  Validation loss = 10.5873  \n",
      "\n",
      "Fold: 14  Epoch: 490  Training loss = 4.3636  Validation loss = 10.5867  \n",
      "\n",
      "Fold: 14  Epoch: 491  Training loss = 4.3632  Validation loss = 10.5860  \n",
      "\n",
      "Fold: 14  Epoch: 492  Training loss = 4.3627  Validation loss = 10.5853  \n",
      "\n",
      "Fold: 14  Epoch: 493  Training loss = 4.3623  Validation loss = 10.5846  \n",
      "\n",
      "Fold: 14  Epoch: 494  Training loss = 4.3619  Validation loss = 10.5841  \n",
      "\n",
      "Fold: 14  Epoch: 495  Training loss = 4.3615  Validation loss = 10.5835  \n",
      "\n",
      "Fold: 14  Epoch: 496  Training loss = 4.3612  Validation loss = 10.5829  \n",
      "\n",
      "Fold: 14  Epoch: 497  Training loss = 4.3608  Validation loss = 10.5823  \n",
      "\n",
      "Fold: 14  Epoch: 498  Training loss = 4.3604  Validation loss = 10.5816  \n",
      "\n",
      "Fold: 14  Epoch: 499  Training loss = 4.3600  Validation loss = 10.5809  \n",
      "\n",
      "Fold: 14  Epoch: 500  Training loss = 4.3595  Validation loss = 10.5802  \n",
      "\n",
      "Check model:  Fold: 14  Optimal epoch: 500  \n",
      "\n",
      "Fold: 15  Epoch: 1  Training loss = 5.0840  Validation loss = 11.1263  \n",
      "\n",
      "Fold: 15  Epoch: 2  Training loss = 5.0834  Validation loss = 11.1256  \n",
      "\n",
      "Fold: 15  Epoch: 3  Training loss = 5.0828  Validation loss = 11.1248  \n",
      "\n",
      "Fold: 15  Epoch: 4  Training loss = 5.0823  Validation loss = 11.1241  \n",
      "\n",
      "Fold: 15  Epoch: 5  Training loss = 5.0818  Validation loss = 11.1235  \n",
      "\n",
      "Fold: 15  Epoch: 6  Training loss = 5.0813  Validation loss = 11.1229  \n",
      "\n",
      "Fold: 15  Epoch: 7  Training loss = 5.0808  Validation loss = 11.1222  \n",
      "\n",
      "Fold: 15  Epoch: 8  Training loss = 5.0803  Validation loss = 11.1216  \n",
      "\n",
      "Fold: 15  Epoch: 9  Training loss = 5.0798  Validation loss = 11.1210  \n",
      "\n",
      "Fold: 15  Epoch: 10  Training loss = 5.0794  Validation loss = 11.1205  \n",
      "\n",
      "Fold: 15  Epoch: 11  Training loss = 5.0788  Validation loss = 11.1198  \n",
      "\n",
      "Fold: 15  Epoch: 12  Training loss = 5.0784  Validation loss = 11.1192  \n",
      "\n",
      "Fold: 15  Epoch: 13  Training loss = 5.0779  Validation loss = 11.1186  \n",
      "\n",
      "Fold: 15  Epoch: 14  Training loss = 5.0773  Validation loss = 11.1178  \n",
      "\n",
      "Fold: 15  Epoch: 15  Training loss = 5.0767  Validation loss = 11.1171  \n",
      "\n",
      "Fold: 15  Epoch: 16  Training loss = 5.0763  Validation loss = 11.1166  \n",
      "\n",
      "Fold: 15  Epoch: 17  Training loss = 5.0758  Validation loss = 11.1160  \n",
      "\n",
      "Fold: 15  Epoch: 18  Training loss = 5.0753  Validation loss = 11.1153  \n",
      "\n",
      "Fold: 15  Epoch: 19  Training loss = 5.0749  Validation loss = 11.1147  \n",
      "\n",
      "Fold: 15  Epoch: 20  Training loss = 5.0743  Validation loss = 11.1140  \n",
      "\n",
      "Fold: 15  Epoch: 21  Training loss = 5.0737  Validation loss = 11.1133  \n",
      "\n",
      "Fold: 15  Epoch: 22  Training loss = 5.0732  Validation loss = 11.1127  \n",
      "\n",
      "Fold: 15  Epoch: 23  Training loss = 5.0726  Validation loss = 11.1119  \n",
      "\n",
      "Fold: 15  Epoch: 24  Training loss = 5.0721  Validation loss = 11.1112  \n",
      "\n",
      "Fold: 15  Epoch: 25  Training loss = 5.0715  Validation loss = 11.1104  \n",
      "\n",
      "Fold: 15  Epoch: 26  Training loss = 5.0710  Validation loss = 11.1098  \n",
      "\n",
      "Fold: 15  Epoch: 27  Training loss = 5.0705  Validation loss = 11.1092  \n",
      "\n",
      "Fold: 15  Epoch: 28  Training loss = 5.0701  Validation loss = 11.1086  \n",
      "\n",
      "Fold: 15  Epoch: 29  Training loss = 5.0695  Validation loss = 11.1079  \n",
      "\n",
      "Fold: 15  Epoch: 30  Training loss = 5.0690  Validation loss = 11.1071  \n",
      "\n",
      "Fold: 15  Epoch: 31  Training loss = 5.0684  Validation loss = 11.1064  \n",
      "\n",
      "Fold: 15  Epoch: 32  Training loss = 5.0679  Validation loss = 11.1058  \n",
      "\n",
      "Fold: 15  Epoch: 33  Training loss = 5.0674  Validation loss = 11.1051  \n",
      "\n",
      "Fold: 15  Epoch: 34  Training loss = 5.0669  Validation loss = 11.1046  \n",
      "\n",
      "Fold: 15  Epoch: 35  Training loss = 5.0664  Validation loss = 11.1039  \n",
      "\n",
      "Fold: 15  Epoch: 36  Training loss = 5.0659  Validation loss = 11.1032  \n",
      "\n",
      "Fold: 15  Epoch: 37  Training loss = 5.0655  Validation loss = 11.1026  \n",
      "\n",
      "Fold: 15  Epoch: 38  Training loss = 5.0650  Validation loss = 11.1020  \n",
      "\n",
      "Fold: 15  Epoch: 39  Training loss = 5.0645  Validation loss = 11.1013  \n",
      "\n",
      "Fold: 15  Epoch: 40  Training loss = 5.0640  Validation loss = 11.1007  \n",
      "\n",
      "Fold: 15  Epoch: 41  Training loss = 5.0635  Validation loss = 11.1001  \n",
      "\n",
      "Fold: 15  Epoch: 42  Training loss = 5.0631  Validation loss = 11.0995  \n",
      "\n",
      "Fold: 15  Epoch: 43  Training loss = 5.0626  Validation loss = 11.0990  \n",
      "\n",
      "Fold: 15  Epoch: 44  Training loss = 5.0622  Validation loss = 11.0983  \n",
      "\n",
      "Fold: 15  Epoch: 45  Training loss = 5.0617  Validation loss = 11.0977  \n",
      "\n",
      "Fold: 15  Epoch: 46  Training loss = 5.0611  Validation loss = 11.0970  \n",
      "\n",
      "Fold: 15  Epoch: 47  Training loss = 5.0606  Validation loss = 11.0963  \n",
      "\n",
      "Fold: 15  Epoch: 48  Training loss = 5.0601  Validation loss = 11.0957  \n",
      "\n",
      "Fold: 15  Epoch: 49  Training loss = 5.0596  Validation loss = 11.0950  \n",
      "\n",
      "Fold: 15  Epoch: 50  Training loss = 5.0591  Validation loss = 11.0943  \n",
      "\n",
      "Fold: 15  Epoch: 51  Training loss = 5.0586  Validation loss = 11.0937  \n",
      "\n",
      "Fold: 15  Epoch: 52  Training loss = 5.0581  Validation loss = 11.0931  \n",
      "\n",
      "Fold: 15  Epoch: 53  Training loss = 5.0575  Validation loss = 11.0923  \n",
      "\n",
      "Fold: 15  Epoch: 54  Training loss = 5.0571  Validation loss = 11.0918  \n",
      "\n",
      "Fold: 15  Epoch: 55  Training loss = 5.0566  Validation loss = 11.0912  \n",
      "\n",
      "Fold: 15  Epoch: 56  Training loss = 5.0561  Validation loss = 11.0904  \n",
      "\n",
      "Fold: 15  Epoch: 57  Training loss = 5.0556  Validation loss = 11.0897  \n",
      "\n",
      "Fold: 15  Epoch: 58  Training loss = 5.0550  Validation loss = 11.0890  \n",
      "\n",
      "Fold: 15  Epoch: 59  Training loss = 5.0545  Validation loss = 11.0884  \n",
      "\n",
      "Fold: 15  Epoch: 60  Training loss = 5.0541  Validation loss = 11.0877  \n",
      "\n",
      "Fold: 15  Epoch: 61  Training loss = 5.0536  Validation loss = 11.0871  \n",
      "\n",
      "Fold: 15  Epoch: 62  Training loss = 5.0531  Validation loss = 11.0864  \n",
      "\n",
      "Fold: 15  Epoch: 63  Training loss = 5.0525  Validation loss = 11.0857  \n",
      "\n",
      "Fold: 15  Epoch: 64  Training loss = 5.0519  Validation loss = 11.0849  \n",
      "\n",
      "Fold: 15  Epoch: 65  Training loss = 5.0514  Validation loss = 11.0842  \n",
      "\n",
      "Fold: 15  Epoch: 66  Training loss = 5.0508  Validation loss = 11.0835  \n",
      "\n",
      "Fold: 15  Epoch: 67  Training loss = 5.0502  Validation loss = 11.0828  \n",
      "\n",
      "Fold: 15  Epoch: 68  Training loss = 5.0497  Validation loss = 11.0821  \n",
      "\n",
      "Fold: 15  Epoch: 69  Training loss = 5.0492  Validation loss = 11.0814  \n",
      "\n",
      "Fold: 15  Epoch: 70  Training loss = 5.0487  Validation loss = 11.0808  \n",
      "\n",
      "Fold: 15  Epoch: 71  Training loss = 5.0482  Validation loss = 11.0802  \n",
      "\n",
      "Fold: 15  Epoch: 72  Training loss = 5.0478  Validation loss = 11.0796  \n",
      "\n",
      "Fold: 15  Epoch: 73  Training loss = 5.0472  Validation loss = 11.0788  \n",
      "\n",
      "Fold: 15  Epoch: 74  Training loss = 5.0466  Validation loss = 11.0780  \n",
      "\n",
      "Fold: 15  Epoch: 75  Training loss = 5.0459  Validation loss = 11.0772  \n",
      "\n",
      "Fold: 15  Epoch: 76  Training loss = 5.0453  Validation loss = 11.0764  \n",
      "\n",
      "Fold: 15  Epoch: 77  Training loss = 5.0448  Validation loss = 11.0758  \n",
      "\n",
      "Fold: 15  Epoch: 78  Training loss = 5.0444  Validation loss = 11.0752  \n",
      "\n",
      "Fold: 15  Epoch: 79  Training loss = 5.0437  Validation loss = 11.0743  \n",
      "\n",
      "Fold: 15  Epoch: 80  Training loss = 5.0430  Validation loss = 11.0735  \n",
      "\n",
      "Fold: 15  Epoch: 81  Training loss = 5.0426  Validation loss = 11.0730  \n",
      "\n",
      "Fold: 15  Epoch: 82  Training loss = 5.0421  Validation loss = 11.0723  \n",
      "\n",
      "Fold: 15  Epoch: 83  Training loss = 5.0416  Validation loss = 11.0717  \n",
      "\n",
      "Fold: 15  Epoch: 84  Training loss = 5.0410  Validation loss = 11.0709  \n",
      "\n",
      "Fold: 15  Epoch: 85  Training loss = 5.0405  Validation loss = 11.0703  \n",
      "\n",
      "Fold: 15  Epoch: 86  Training loss = 5.0400  Validation loss = 11.0696  \n",
      "\n",
      "Fold: 15  Epoch: 87  Training loss = 5.0395  Validation loss = 11.0690  \n",
      "\n",
      "Fold: 15  Epoch: 88  Training loss = 5.0390  Validation loss = 11.0683  \n",
      "\n",
      "Fold: 15  Epoch: 89  Training loss = 5.0385  Validation loss = 11.0676  \n",
      "\n",
      "Fold: 15  Epoch: 90  Training loss = 5.0380  Validation loss = 11.0670  \n",
      "\n",
      "Fold: 15  Epoch: 91  Training loss = 5.0376  Validation loss = 11.0665  \n",
      "\n",
      "Fold: 15  Epoch: 92  Training loss = 5.0371  Validation loss = 11.0658  \n",
      "\n",
      "Fold: 15  Epoch: 93  Training loss = 5.0366  Validation loss = 11.0652  \n",
      "\n",
      "Fold: 15  Epoch: 94  Training loss = 5.0360  Validation loss = 11.0645  \n",
      "\n",
      "Fold: 15  Epoch: 95  Training loss = 5.0355  Validation loss = 11.0638  \n",
      "\n",
      "Fold: 15  Epoch: 96  Training loss = 5.0349  Validation loss = 11.0630  \n",
      "\n",
      "Fold: 15  Epoch: 97  Training loss = 5.0344  Validation loss = 11.0624  \n",
      "\n",
      "Fold: 15  Epoch: 98  Training loss = 5.0339  Validation loss = 11.0617  \n",
      "\n",
      "Fold: 15  Epoch: 99  Training loss = 5.0334  Validation loss = 11.0609  \n",
      "\n",
      "Fold: 15  Epoch: 100  Training loss = 5.0328  Validation loss = 11.0602  \n",
      "\n",
      "Fold: 15  Epoch: 101  Training loss = 5.0324  Validation loss = 11.0597  \n",
      "\n",
      "Fold: 15  Epoch: 102  Training loss = 5.0319  Validation loss = 11.0590  \n",
      "\n",
      "Fold: 15  Epoch: 103  Training loss = 5.0314  Validation loss = 11.0583  \n",
      "\n",
      "Fold: 15  Epoch: 104  Training loss = 5.0309  Validation loss = 11.0577  \n",
      "\n",
      "Fold: 15  Epoch: 105  Training loss = 5.0304  Validation loss = 11.0570  \n",
      "\n",
      "Fold: 15  Epoch: 106  Training loss = 5.0298  Validation loss = 11.0563  \n",
      "\n",
      "Fold: 15  Epoch: 107  Training loss = 5.0294  Validation loss = 11.0557  \n",
      "\n",
      "Fold: 15  Epoch: 108  Training loss = 5.0288  Validation loss = 11.0549  \n",
      "\n",
      "Fold: 15  Epoch: 109  Training loss = 5.0282  Validation loss = 11.0541  \n",
      "\n",
      "Fold: 15  Epoch: 110  Training loss = 5.0277  Validation loss = 11.0535  \n",
      "\n",
      "Fold: 15  Epoch: 111  Training loss = 5.0271  Validation loss = 11.0528  \n",
      "\n",
      "Fold: 15  Epoch: 112  Training loss = 5.0267  Validation loss = 11.0522  \n",
      "\n",
      "Fold: 15  Epoch: 113  Training loss = 5.0262  Validation loss = 11.0515  \n",
      "\n",
      "Fold: 15  Epoch: 114  Training loss = 5.0257  Validation loss = 11.0508  \n",
      "\n",
      "Fold: 15  Epoch: 115  Training loss = 5.0251  Validation loss = 11.0501  \n",
      "\n",
      "Fold: 15  Epoch: 116  Training loss = 5.0245  Validation loss = 11.0493  \n",
      "\n",
      "Fold: 15  Epoch: 117  Training loss = 5.0240  Validation loss = 11.0486  \n",
      "\n",
      "Fold: 15  Epoch: 118  Training loss = 5.0236  Validation loss = 11.0480  \n",
      "\n",
      "Fold: 15  Epoch: 119  Training loss = 5.0229  Validation loss = 11.0472  \n",
      "\n",
      "Fold: 15  Epoch: 120  Training loss = 5.0224  Validation loss = 11.0465  \n",
      "\n",
      "Fold: 15  Epoch: 121  Training loss = 5.0219  Validation loss = 11.0458  \n",
      "\n",
      "Fold: 15  Epoch: 122  Training loss = 5.0214  Validation loss = 11.0452  \n",
      "\n",
      "Fold: 15  Epoch: 123  Training loss = 5.0208  Validation loss = 11.0445  \n",
      "\n",
      "Fold: 15  Epoch: 124  Training loss = 5.0203  Validation loss = 11.0438  \n",
      "\n",
      "Fold: 15  Epoch: 125  Training loss = 5.0197  Validation loss = 11.0430  \n",
      "\n",
      "Fold: 15  Epoch: 126  Training loss = 5.0192  Validation loss = 11.0424  \n",
      "\n",
      "Fold: 15  Epoch: 127  Training loss = 5.0187  Validation loss = 11.0417  \n",
      "\n",
      "Fold: 15  Epoch: 128  Training loss = 5.0183  Validation loss = 11.0411  \n",
      "\n",
      "Fold: 15  Epoch: 129  Training loss = 5.0178  Validation loss = 11.0405  \n",
      "\n",
      "Fold: 15  Epoch: 130  Training loss = 5.0174  Validation loss = 11.0399  \n",
      "\n",
      "Fold: 15  Epoch: 131  Training loss = 5.0168  Validation loss = 11.0392  \n",
      "\n",
      "Fold: 15  Epoch: 132  Training loss = 5.0162  Validation loss = 11.0384  \n",
      "\n",
      "Fold: 15  Epoch: 133  Training loss = 5.0156  Validation loss = 11.0376  \n",
      "\n",
      "Fold: 15  Epoch: 134  Training loss = 5.0150  Validation loss = 11.0368  \n",
      "\n",
      "Fold: 15  Epoch: 135  Training loss = 5.0145  Validation loss = 11.0362  \n",
      "\n",
      "Fold: 15  Epoch: 136  Training loss = 5.0141  Validation loss = 11.0356  \n",
      "\n",
      "Fold: 15  Epoch: 137  Training loss = 5.0135  Validation loss = 11.0349  \n",
      "\n",
      "Fold: 15  Epoch: 138  Training loss = 5.0131  Validation loss = 11.0343  \n",
      "\n",
      "Fold: 15  Epoch: 139  Training loss = 5.0126  Validation loss = 11.0336  \n",
      "\n",
      "Fold: 15  Epoch: 140  Training loss = 5.0121  Validation loss = 11.0329  \n",
      "\n",
      "Fold: 15  Epoch: 141  Training loss = 5.0115  Validation loss = 11.0322  \n",
      "\n",
      "Fold: 15  Epoch: 142  Training loss = 5.0108  Validation loss = 11.0313  \n",
      "\n",
      "Fold: 15  Epoch: 143  Training loss = 5.0104  Validation loss = 11.0307  \n",
      "\n",
      "Fold: 15  Epoch: 144  Training loss = 5.0099  Validation loss = 11.0301  \n",
      "\n",
      "Fold: 15  Epoch: 145  Training loss = 5.0094  Validation loss = 11.0295  \n",
      "\n",
      "Fold: 15  Epoch: 146  Training loss = 5.0089  Validation loss = 11.0288  \n",
      "\n",
      "Fold: 15  Epoch: 147  Training loss = 5.0084  Validation loss = 11.0282  \n",
      "\n",
      "Fold: 15  Epoch: 148  Training loss = 5.0079  Validation loss = 11.0276  \n",
      "\n",
      "Fold: 15  Epoch: 149  Training loss = 5.0074  Validation loss = 11.0269  \n",
      "\n",
      "Fold: 15  Epoch: 150  Training loss = 5.0068  Validation loss = 11.0262  \n",
      "\n",
      "Fold: 15  Epoch: 151  Training loss = 5.0064  Validation loss = 11.0255  \n",
      "\n",
      "Fold: 15  Epoch: 152  Training loss = 5.0057  Validation loss = 11.0247  \n",
      "\n",
      "Fold: 15  Epoch: 153  Training loss = 5.0053  Validation loss = 11.0241  \n",
      "\n",
      "Fold: 15  Epoch: 154  Training loss = 5.0048  Validation loss = 11.0235  \n",
      "\n",
      "Fold: 15  Epoch: 155  Training loss = 5.0043  Validation loss = 11.0229  \n",
      "\n",
      "Fold: 15  Epoch: 156  Training loss = 5.0038  Validation loss = 11.0221  \n",
      "\n",
      "Fold: 15  Epoch: 157  Training loss = 5.0032  Validation loss = 11.0214  \n",
      "\n",
      "Fold: 15  Epoch: 158  Training loss = 5.0027  Validation loss = 11.0207  \n",
      "\n",
      "Fold: 15  Epoch: 159  Training loss = 5.0021  Validation loss = 11.0199  \n",
      "\n",
      "Fold: 15  Epoch: 160  Training loss = 5.0016  Validation loss = 11.0192  \n",
      "\n",
      "Fold: 15  Epoch: 161  Training loss = 5.0011  Validation loss = 11.0185  \n",
      "\n",
      "Fold: 15  Epoch: 162  Training loss = 5.0006  Validation loss = 11.0179  \n",
      "\n",
      "Fold: 15  Epoch: 163  Training loss = 5.0000  Validation loss = 11.0171  \n",
      "\n",
      "Fold: 15  Epoch: 164  Training loss = 4.9995  Validation loss = 11.0165  \n",
      "\n",
      "Fold: 15  Epoch: 165  Training loss = 4.9990  Validation loss = 11.0158  \n",
      "\n",
      "Fold: 15  Epoch: 166  Training loss = 4.9985  Validation loss = 11.0152  \n",
      "\n",
      "Fold: 15  Epoch: 167  Training loss = 4.9980  Validation loss = 11.0145  \n",
      "\n",
      "Fold: 15  Epoch: 168  Training loss = 4.9974  Validation loss = 11.0137  \n",
      "\n",
      "Fold: 15  Epoch: 169  Training loss = 4.9969  Validation loss = 11.0131  \n",
      "\n",
      "Fold: 15  Epoch: 170  Training loss = 4.9965  Validation loss = 11.0125  \n",
      "\n",
      "Fold: 15  Epoch: 171  Training loss = 4.9960  Validation loss = 11.0119  \n",
      "\n",
      "Fold: 15  Epoch: 172  Training loss = 4.9955  Validation loss = 11.0112  \n",
      "\n",
      "Fold: 15  Epoch: 173  Training loss = 4.9950  Validation loss = 11.0105  \n",
      "\n",
      "Fold: 15  Epoch: 174  Training loss = 4.9944  Validation loss = 11.0098  \n",
      "\n",
      "Fold: 15  Epoch: 175  Training loss = 4.9939  Validation loss = 11.0091  \n",
      "\n",
      "Fold: 15  Epoch: 176  Training loss = 4.9935  Validation loss = 11.0085  \n",
      "\n",
      "Fold: 15  Epoch: 177  Training loss = 4.9929  Validation loss = 11.0078  \n",
      "\n",
      "Fold: 15  Epoch: 178  Training loss = 4.9923  Validation loss = 11.0069  \n",
      "\n",
      "Fold: 15  Epoch: 179  Training loss = 4.9918  Validation loss = 11.0062  \n",
      "\n",
      "Fold: 15  Epoch: 180  Training loss = 4.9913  Validation loss = 11.0056  \n",
      "\n",
      "Fold: 15  Epoch: 181  Training loss = 4.9908  Validation loss = 11.0049  \n",
      "\n",
      "Fold: 15  Epoch: 182  Training loss = 4.9903  Validation loss = 11.0043  \n",
      "\n",
      "Fold: 15  Epoch: 183  Training loss = 4.9898  Validation loss = 11.0036  \n",
      "\n",
      "Fold: 15  Epoch: 184  Training loss = 4.9892  Validation loss = 11.0028  \n",
      "\n",
      "Fold: 15  Epoch: 185  Training loss = 4.9886  Validation loss = 11.0021  \n",
      "\n",
      "Fold: 15  Epoch: 186  Training loss = 4.9881  Validation loss = 11.0014  \n",
      "\n",
      "Fold: 15  Epoch: 187  Training loss = 4.9876  Validation loss = 11.0007  \n",
      "\n",
      "Fold: 15  Epoch: 188  Training loss = 4.9870  Validation loss = 11.0000  \n",
      "\n",
      "Fold: 15  Epoch: 189  Training loss = 4.9866  Validation loss = 10.9994  \n",
      "\n",
      "Fold: 15  Epoch: 190  Training loss = 4.9860  Validation loss = 10.9986  \n",
      "\n",
      "Fold: 15  Epoch: 191  Training loss = 4.9855  Validation loss = 10.9979  \n",
      "\n",
      "Fold: 15  Epoch: 192  Training loss = 4.9851  Validation loss = 10.9974  \n",
      "\n",
      "Fold: 15  Epoch: 193  Training loss = 4.9846  Validation loss = 10.9968  \n",
      "\n",
      "Fold: 15  Epoch: 194  Training loss = 4.9842  Validation loss = 10.9962  \n",
      "\n",
      "Fold: 15  Epoch: 195  Training loss = 4.9837  Validation loss = 10.9956  \n",
      "\n",
      "Fold: 15  Epoch: 196  Training loss = 4.9831  Validation loss = 10.9948  \n",
      "\n",
      "Fold: 15  Epoch: 197  Training loss = 4.9826  Validation loss = 10.9941  \n",
      "\n",
      "Fold: 15  Epoch: 198  Training loss = 4.9821  Validation loss = 10.9934  \n",
      "\n",
      "Fold: 15  Epoch: 199  Training loss = 4.9816  Validation loss = 10.9928  \n",
      "\n",
      "Fold: 15  Epoch: 200  Training loss = 4.9810  Validation loss = 10.9920  \n",
      "\n",
      "Fold: 15  Epoch: 201  Training loss = 4.9805  Validation loss = 10.9913  \n",
      "\n",
      "Fold: 15  Epoch: 202  Training loss = 4.9800  Validation loss = 10.9906  \n",
      "\n",
      "Fold: 15  Epoch: 203  Training loss = 4.9794  Validation loss = 10.9899  \n",
      "\n",
      "Fold: 15  Epoch: 204  Training loss = 4.9789  Validation loss = 10.9892  \n",
      "\n",
      "Fold: 15  Epoch: 205  Training loss = 4.9784  Validation loss = 10.9885  \n",
      "\n",
      "Fold: 15  Epoch: 206  Training loss = 4.9780  Validation loss = 10.9880  \n",
      "\n",
      "Fold: 15  Epoch: 207  Training loss = 4.9774  Validation loss = 10.9872  \n",
      "\n",
      "Fold: 15  Epoch: 208  Training loss = 4.9769  Validation loss = 10.9865  \n",
      "\n",
      "Fold: 15  Epoch: 209  Training loss = 4.9764  Validation loss = 10.9859  \n",
      "\n",
      "Fold: 15  Epoch: 210  Training loss = 4.9759  Validation loss = 10.9853  \n",
      "\n",
      "Fold: 15  Epoch: 211  Training loss = 4.9753  Validation loss = 10.9845  \n",
      "\n",
      "Fold: 15  Epoch: 212  Training loss = 4.9748  Validation loss = 10.9838  \n",
      "\n",
      "Fold: 15  Epoch: 213  Training loss = 4.9743  Validation loss = 10.9832  \n",
      "\n",
      "Fold: 15  Epoch: 214  Training loss = 4.9739  Validation loss = 10.9825  \n",
      "\n",
      "Fold: 15  Epoch: 215  Training loss = 4.9733  Validation loss = 10.9818  \n",
      "\n",
      "Fold: 15  Epoch: 216  Training loss = 4.9728  Validation loss = 10.9811  \n",
      "\n",
      "Fold: 15  Epoch: 217  Training loss = 4.9723  Validation loss = 10.9805  \n",
      "\n",
      "Fold: 15  Epoch: 218  Training loss = 4.9718  Validation loss = 10.9798  \n",
      "\n",
      "Fold: 15  Epoch: 219  Training loss = 4.9713  Validation loss = 10.9792  \n",
      "\n",
      "Fold: 15  Epoch: 220  Training loss = 4.9708  Validation loss = 10.9785  \n",
      "\n",
      "Fold: 15  Epoch: 221  Training loss = 4.9703  Validation loss = 10.9778  \n",
      "\n",
      "Fold: 15  Epoch: 222  Training loss = 4.9698  Validation loss = 10.9771  \n",
      "\n",
      "Fold: 15  Epoch: 223  Training loss = 4.9692  Validation loss = 10.9764  \n",
      "\n",
      "Fold: 15  Epoch: 224  Training loss = 4.9687  Validation loss = 10.9758  \n",
      "\n",
      "Fold: 15  Epoch: 225  Training loss = 4.9683  Validation loss = 10.9752  \n",
      "\n",
      "Fold: 15  Epoch: 226  Training loss = 4.9678  Validation loss = 10.9746  \n",
      "\n",
      "Fold: 15  Epoch: 227  Training loss = 4.9673  Validation loss = 10.9739  \n",
      "\n",
      "Fold: 15  Epoch: 228  Training loss = 4.9669  Validation loss = 10.9732  \n",
      "\n",
      "Fold: 15  Epoch: 229  Training loss = 4.9664  Validation loss = 10.9727  \n",
      "\n",
      "Fold: 15  Epoch: 230  Training loss = 4.9660  Validation loss = 10.9721  \n",
      "\n",
      "Fold: 15  Epoch: 231  Training loss = 4.9655  Validation loss = 10.9714  \n",
      "\n",
      "Fold: 15  Epoch: 232  Training loss = 4.9650  Validation loss = 10.9708  \n",
      "\n",
      "Fold: 15  Epoch: 233  Training loss = 4.9645  Validation loss = 10.9700  \n",
      "\n",
      "Fold: 15  Epoch: 234  Training loss = 4.9640  Validation loss = 10.9693  \n",
      "\n",
      "Fold: 15  Epoch: 235  Training loss = 4.9634  Validation loss = 10.9686  \n",
      "\n",
      "Fold: 15  Epoch: 236  Training loss = 4.9629  Validation loss = 10.9679  \n",
      "\n",
      "Fold: 15  Epoch: 237  Training loss = 4.9625  Validation loss = 10.9674  \n",
      "\n",
      "Fold: 15  Epoch: 238  Training loss = 4.9620  Validation loss = 10.9668  \n",
      "\n",
      "Fold: 15  Epoch: 239  Training loss = 4.9616  Validation loss = 10.9662  \n",
      "\n",
      "Fold: 15  Epoch: 240  Training loss = 4.9612  Validation loss = 10.9656  \n",
      "\n",
      "Fold: 15  Epoch: 241  Training loss = 4.9606  Validation loss = 10.9649  \n",
      "\n",
      "Fold: 15  Epoch: 242  Training loss = 4.9601  Validation loss = 10.9641  \n",
      "\n",
      "Fold: 15  Epoch: 243  Training loss = 4.9596  Validation loss = 10.9635  \n",
      "\n",
      "Fold: 15  Epoch: 244  Training loss = 4.9590  Validation loss = 10.9627  \n",
      "\n",
      "Fold: 15  Epoch: 245  Training loss = 4.9584  Validation loss = 10.9619  \n",
      "\n",
      "Fold: 15  Epoch: 246  Training loss = 4.9580  Validation loss = 10.9613  \n",
      "\n",
      "Fold: 15  Epoch: 247  Training loss = 4.9574  Validation loss = 10.9605  \n",
      "\n",
      "Fold: 15  Epoch: 248  Training loss = 4.9569  Validation loss = 10.9599  \n",
      "\n",
      "Fold: 15  Epoch: 249  Training loss = 4.9564  Validation loss = 10.9592  \n",
      "\n",
      "Fold: 15  Epoch: 250  Training loss = 4.9558  Validation loss = 10.9585  \n",
      "\n",
      "Fold: 15  Epoch: 251  Training loss = 4.9553  Validation loss = 10.9578  \n",
      "\n",
      "Fold: 15  Epoch: 252  Training loss = 4.9547  Validation loss = 10.9570  \n",
      "\n",
      "Fold: 15  Epoch: 253  Training loss = 4.9541  Validation loss = 10.9562  \n",
      "\n",
      "Fold: 15  Epoch: 254  Training loss = 4.9536  Validation loss = 10.9554  \n",
      "\n",
      "Fold: 15  Epoch: 255  Training loss = 4.9531  Validation loss = 10.9548  \n",
      "\n",
      "Fold: 15  Epoch: 256  Training loss = 4.9525  Validation loss = 10.9539  \n",
      "\n",
      "Fold: 15  Epoch: 257  Training loss = 4.9519  Validation loss = 10.9532  \n",
      "\n",
      "Fold: 15  Epoch: 258  Training loss = 4.9514  Validation loss = 10.9526  \n",
      "\n",
      "Fold: 15  Epoch: 259  Training loss = 4.9509  Validation loss = 10.9519  \n",
      "\n",
      "Fold: 15  Epoch: 260  Training loss = 4.9505  Validation loss = 10.9513  \n",
      "\n",
      "Fold: 15  Epoch: 261  Training loss = 4.9499  Validation loss = 10.9505  \n",
      "\n",
      "Fold: 15  Epoch: 262  Training loss = 4.9493  Validation loss = 10.9498  \n",
      "\n",
      "Fold: 15  Epoch: 263  Training loss = 4.9487  Validation loss = 10.9490  \n",
      "\n",
      "Fold: 15  Epoch: 264  Training loss = 4.9482  Validation loss = 10.9483  \n",
      "\n",
      "Fold: 15  Epoch: 265  Training loss = 4.9476  Validation loss = 10.9475  \n",
      "\n",
      "Fold: 15  Epoch: 266  Training loss = 4.9471  Validation loss = 10.9468  \n",
      "\n",
      "Fold: 15  Epoch: 267  Training loss = 4.9465  Validation loss = 10.9460  \n",
      "\n",
      "Fold: 15  Epoch: 268  Training loss = 4.9460  Validation loss = 10.9453  \n",
      "\n",
      "Fold: 15  Epoch: 269  Training loss = 4.9455  Validation loss = 10.9446  \n",
      "\n",
      "Fold: 15  Epoch: 270  Training loss = 4.9449  Validation loss = 10.9438  \n",
      "\n",
      "Fold: 15  Epoch: 271  Training loss = 4.9444  Validation loss = 10.9431  \n",
      "\n",
      "Fold: 15  Epoch: 272  Training loss = 4.9438  Validation loss = 10.9424  \n",
      "\n",
      "Fold: 15  Epoch: 273  Training loss = 4.9433  Validation loss = 10.9416  \n",
      "\n",
      "Fold: 15  Epoch: 274  Training loss = 4.9428  Validation loss = 10.9409  \n",
      "\n",
      "Fold: 15  Epoch: 275  Training loss = 4.9422  Validation loss = 10.9402  \n",
      "\n",
      "Fold: 15  Epoch: 276  Training loss = 4.9418  Validation loss = 10.9396  \n",
      "\n",
      "Fold: 15  Epoch: 277  Training loss = 4.9414  Validation loss = 10.9390  \n",
      "\n",
      "Fold: 15  Epoch: 278  Training loss = 4.9409  Validation loss = 10.9384  \n",
      "\n",
      "Fold: 15  Epoch: 279  Training loss = 4.9404  Validation loss = 10.9377  \n",
      "\n",
      "Fold: 15  Epoch: 280  Training loss = 4.9398  Validation loss = 10.9369  \n",
      "\n",
      "Fold: 15  Epoch: 281  Training loss = 4.9392  Validation loss = 10.9362  \n",
      "\n",
      "Fold: 15  Epoch: 282  Training loss = 4.9388  Validation loss = 10.9356  \n",
      "\n",
      "Fold: 15  Epoch: 283  Training loss = 4.9383  Validation loss = 10.9349  \n",
      "\n",
      "Fold: 15  Epoch: 284  Training loss = 4.9379  Validation loss = 10.9343  \n",
      "\n",
      "Fold: 15  Epoch: 285  Training loss = 4.9373  Validation loss = 10.9335  \n",
      "\n",
      "Fold: 15  Epoch: 286  Training loss = 4.9368  Validation loss = 10.9329  \n",
      "\n",
      "Fold: 15  Epoch: 287  Training loss = 4.9363  Validation loss = 10.9322  \n",
      "\n",
      "Fold: 15  Epoch: 288  Training loss = 4.9358  Validation loss = 10.9315  \n",
      "\n",
      "Fold: 15  Epoch: 289  Training loss = 4.9353  Validation loss = 10.9308  \n",
      "\n",
      "Fold: 15  Epoch: 290  Training loss = 4.9348  Validation loss = 10.9301  \n",
      "\n",
      "Fold: 15  Epoch: 291  Training loss = 4.9343  Validation loss = 10.9295  \n",
      "\n",
      "Fold: 15  Epoch: 292  Training loss = 4.9338  Validation loss = 10.9289  \n",
      "\n",
      "Fold: 15  Epoch: 293  Training loss = 4.9333  Validation loss = 10.9282  \n",
      "\n",
      "Fold: 15  Epoch: 294  Training loss = 4.9328  Validation loss = 10.9275  \n",
      "\n",
      "Fold: 15  Epoch: 295  Training loss = 4.9321  Validation loss = 10.9266  \n",
      "\n",
      "Fold: 15  Epoch: 296  Training loss = 4.9315  Validation loss = 10.9258  \n",
      "\n",
      "Fold: 15  Epoch: 297  Training loss = 4.9310  Validation loss = 10.9251  \n",
      "\n",
      "Fold: 15  Epoch: 298  Training loss = 4.9305  Validation loss = 10.9244  \n",
      "\n",
      "Fold: 15  Epoch: 299  Training loss = 4.9299  Validation loss = 10.9237  \n",
      "\n",
      "Fold: 15  Epoch: 300  Training loss = 4.9293  Validation loss = 10.9228  \n",
      "\n",
      "Fold: 15  Epoch: 301  Training loss = 4.9288  Validation loss = 10.9221  \n",
      "\n",
      "Fold: 15  Epoch: 302  Training loss = 4.9283  Validation loss = 10.9214  \n",
      "\n",
      "Fold: 15  Epoch: 303  Training loss = 4.9278  Validation loss = 10.9208  \n",
      "\n",
      "Fold: 15  Epoch: 304  Training loss = 4.9273  Validation loss = 10.9201  \n",
      "\n",
      "Fold: 15  Epoch: 305  Training loss = 4.9267  Validation loss = 10.9193  \n",
      "\n",
      "Fold: 15  Epoch: 306  Training loss = 4.9261  Validation loss = 10.9186  \n",
      "\n",
      "Fold: 15  Epoch: 307  Training loss = 4.9257  Validation loss = 10.9180  \n",
      "\n",
      "Fold: 15  Epoch: 308  Training loss = 4.9252  Validation loss = 10.9173  \n",
      "\n",
      "Fold: 15  Epoch: 309  Training loss = 4.9248  Validation loss = 10.9167  \n",
      "\n",
      "Fold: 15  Epoch: 310  Training loss = 4.9243  Validation loss = 10.9160  \n",
      "\n",
      "Fold: 15  Epoch: 311  Training loss = 4.9238  Validation loss = 10.9154  \n",
      "\n",
      "Fold: 15  Epoch: 312  Training loss = 4.9233  Validation loss = 10.9148  \n",
      "\n",
      "Fold: 15  Epoch: 313  Training loss = 4.9228  Validation loss = 10.9140  \n",
      "\n",
      "Fold: 15  Epoch: 314  Training loss = 4.9222  Validation loss = 10.9133  \n",
      "\n",
      "Fold: 15  Epoch: 315  Training loss = 4.9218  Validation loss = 10.9127  \n",
      "\n",
      "Fold: 15  Epoch: 316  Training loss = 4.9213  Validation loss = 10.9121  \n",
      "\n",
      "Fold: 15  Epoch: 317  Training loss = 4.9208  Validation loss = 10.9114  \n",
      "\n",
      "Fold: 15  Epoch: 318  Training loss = 4.9203  Validation loss = 10.9107  \n",
      "\n",
      "Fold: 15  Epoch: 319  Training loss = 4.9198  Validation loss = 10.9101  \n",
      "\n",
      "Fold: 15  Epoch: 320  Training loss = 4.9193  Validation loss = 10.9093  \n",
      "\n",
      "Fold: 15  Epoch: 321  Training loss = 4.9188  Validation loss = 10.9086  \n",
      "\n",
      "Fold: 15  Epoch: 322  Training loss = 4.9183  Validation loss = 10.9080  \n",
      "\n",
      "Fold: 15  Epoch: 323  Training loss = 4.9177  Validation loss = 10.9073  \n",
      "\n",
      "Fold: 15  Epoch: 324  Training loss = 4.9171  Validation loss = 10.9065  \n",
      "\n",
      "Fold: 15  Epoch: 325  Training loss = 4.9167  Validation loss = 10.9059  \n",
      "\n",
      "Fold: 15  Epoch: 326  Training loss = 4.9161  Validation loss = 10.9051  \n",
      "\n",
      "Fold: 15  Epoch: 327  Training loss = 4.9156  Validation loss = 10.9044  \n",
      "\n",
      "Fold: 15  Epoch: 328  Training loss = 4.9151  Validation loss = 10.9038  \n",
      "\n",
      "Fold: 15  Epoch: 329  Training loss = 4.9147  Validation loss = 10.9032  \n",
      "\n",
      "Fold: 15  Epoch: 330  Training loss = 4.9142  Validation loss = 10.9025  \n",
      "\n",
      "Fold: 15  Epoch: 331  Training loss = 4.9138  Validation loss = 10.9019  \n",
      "\n",
      "Fold: 15  Epoch: 332  Training loss = 4.9132  Validation loss = 10.9011  \n",
      "\n",
      "Fold: 15  Epoch: 333  Training loss = 4.9126  Validation loss = 10.9004  \n",
      "\n",
      "Fold: 15  Epoch: 334  Training loss = 4.9122  Validation loss = 10.8997  \n",
      "\n",
      "Fold: 15  Epoch: 335  Training loss = 4.9116  Validation loss = 10.8990  \n",
      "\n",
      "Fold: 15  Epoch: 336  Training loss = 4.9111  Validation loss = 10.8983  \n",
      "\n",
      "Fold: 15  Epoch: 337  Training loss = 4.9105  Validation loss = 10.8975  \n",
      "\n",
      "Fold: 15  Epoch: 338  Training loss = 4.9101  Validation loss = 10.8969  \n",
      "\n",
      "Fold: 15  Epoch: 339  Training loss = 4.9095  Validation loss = 10.8962  \n",
      "\n",
      "Fold: 15  Epoch: 340  Training loss = 4.9090  Validation loss = 10.8954  \n",
      "\n",
      "Fold: 15  Epoch: 341  Training loss = 4.9085  Validation loss = 10.8948  \n",
      "\n",
      "Fold: 15  Epoch: 342  Training loss = 4.9082  Validation loss = 10.8943  \n",
      "\n",
      "Fold: 15  Epoch: 343  Training loss = 4.9075  Validation loss = 10.8935  \n",
      "\n",
      "Fold: 15  Epoch: 344  Training loss = 4.9070  Validation loss = 10.8928  \n",
      "\n",
      "Fold: 15  Epoch: 345  Training loss = 4.9065  Validation loss = 10.8920  \n",
      "\n",
      "Fold: 15  Epoch: 346  Training loss = 4.9060  Validation loss = 10.8914  \n",
      "\n",
      "Fold: 15  Epoch: 347  Training loss = 4.9054  Validation loss = 10.8906  \n",
      "\n",
      "Fold: 15  Epoch: 348  Training loss = 4.9049  Validation loss = 10.8899  \n",
      "\n",
      "Fold: 15  Epoch: 349  Training loss = 4.9043  Validation loss = 10.8891  \n",
      "\n",
      "Fold: 15  Epoch: 350  Training loss = 4.9039  Validation loss = 10.8885  \n",
      "\n",
      "Fold: 15  Epoch: 351  Training loss = 4.9033  Validation loss = 10.8878  \n",
      "\n",
      "Fold: 15  Epoch: 352  Training loss = 4.9027  Validation loss = 10.8869  \n",
      "\n",
      "Fold: 15  Epoch: 353  Training loss = 4.9022  Validation loss = 10.8861  \n",
      "\n",
      "Fold: 15  Epoch: 354  Training loss = 4.9015  Validation loss = 10.8853  \n",
      "\n",
      "Fold: 15  Epoch: 355  Training loss = 4.9010  Validation loss = 10.8845  \n",
      "\n",
      "Fold: 15  Epoch: 356  Training loss = 4.9004  Validation loss = 10.8837  \n",
      "\n",
      "Fold: 15  Epoch: 357  Training loss = 4.8999  Validation loss = 10.8831  \n",
      "\n",
      "Fold: 15  Epoch: 358  Training loss = 4.8993  Validation loss = 10.8823  \n",
      "\n",
      "Fold: 15  Epoch: 359  Training loss = 4.8989  Validation loss = 10.8816  \n",
      "\n",
      "Fold: 15  Epoch: 360  Training loss = 4.8983  Validation loss = 10.8809  \n",
      "\n",
      "Fold: 15  Epoch: 361  Training loss = 4.8978  Validation loss = 10.8802  \n",
      "\n",
      "Fold: 15  Epoch: 362  Training loss = 4.8973  Validation loss = 10.8795  \n",
      "\n",
      "Fold: 15  Epoch: 363  Training loss = 4.8968  Validation loss = 10.8788  \n",
      "\n",
      "Fold: 15  Epoch: 364  Training loss = 4.8963  Validation loss = 10.8782  \n",
      "\n",
      "Fold: 15  Epoch: 365  Training loss = 4.8958  Validation loss = 10.8775  \n",
      "\n",
      "Fold: 15  Epoch: 366  Training loss = 4.8953  Validation loss = 10.8768  \n",
      "\n",
      "Fold: 15  Epoch: 367  Training loss = 4.8948  Validation loss = 10.8762  \n",
      "\n",
      "Fold: 15  Epoch: 368  Training loss = 4.8944  Validation loss = 10.8755  \n",
      "\n",
      "Fold: 15  Epoch: 369  Training loss = 4.8938  Validation loss = 10.8747  \n",
      "\n",
      "Fold: 15  Epoch: 370  Training loss = 4.8933  Validation loss = 10.8741  \n",
      "\n",
      "Fold: 15  Epoch: 371  Training loss = 4.8928  Validation loss = 10.8733  \n",
      "\n",
      "Fold: 15  Epoch: 372  Training loss = 4.8923  Validation loss = 10.8727  \n",
      "\n",
      "Fold: 15  Epoch: 373  Training loss = 4.8918  Validation loss = 10.8720  \n",
      "\n",
      "Fold: 15  Epoch: 374  Training loss = 4.8913  Validation loss = 10.8713  \n",
      "\n",
      "Fold: 15  Epoch: 375  Training loss = 4.8909  Validation loss = 10.8708  \n",
      "\n",
      "Fold: 15  Epoch: 376  Training loss = 4.8904  Validation loss = 10.8701  \n",
      "\n",
      "Fold: 15  Epoch: 377  Training loss = 4.8899  Validation loss = 10.8694  \n",
      "\n",
      "Fold: 15  Epoch: 378  Training loss = 4.8894  Validation loss = 10.8687  \n",
      "\n",
      "Fold: 15  Epoch: 379  Training loss = 4.8889  Validation loss = 10.8679  \n",
      "\n",
      "Fold: 15  Epoch: 380  Training loss = 4.8883  Validation loss = 10.8672  \n",
      "\n",
      "Fold: 15  Epoch: 381  Training loss = 4.8877  Validation loss = 10.8664  \n",
      "\n",
      "Fold: 15  Epoch: 382  Training loss = 4.8871  Validation loss = 10.8656  \n",
      "\n",
      "Fold: 15  Epoch: 383  Training loss = 4.8867  Validation loss = 10.8650  \n",
      "\n",
      "Fold: 15  Epoch: 384  Training loss = 4.8862  Validation loss = 10.8643  \n",
      "\n",
      "Fold: 15  Epoch: 385  Training loss = 4.8857  Validation loss = 10.8635  \n",
      "\n",
      "Fold: 15  Epoch: 386  Training loss = 4.8851  Validation loss = 10.8628  \n",
      "\n",
      "Fold: 15  Epoch: 387  Training loss = 4.8845  Validation loss = 10.8619  \n",
      "\n",
      "Fold: 15  Epoch: 388  Training loss = 4.8840  Validation loss = 10.8612  \n",
      "\n",
      "Fold: 15  Epoch: 389  Training loss = 4.8835  Validation loss = 10.8605  \n",
      "\n",
      "Fold: 15  Epoch: 390  Training loss = 4.8830  Validation loss = 10.8599  \n",
      "\n",
      "Fold: 15  Epoch: 391  Training loss = 4.8825  Validation loss = 10.8592  \n",
      "\n",
      "Fold: 15  Epoch: 392  Training loss = 4.8820  Validation loss = 10.8585  \n",
      "\n",
      "Fold: 15  Epoch: 393  Training loss = 4.8815  Validation loss = 10.8578  \n",
      "\n",
      "Fold: 15  Epoch: 394  Training loss = 4.8809  Validation loss = 10.8570  \n",
      "\n",
      "Fold: 15  Epoch: 395  Training loss = 4.8804  Validation loss = 10.8563  \n",
      "\n",
      "Fold: 15  Epoch: 396  Training loss = 4.8798  Validation loss = 10.8555  \n",
      "\n",
      "Fold: 15  Epoch: 397  Training loss = 4.8794  Validation loss = 10.8549  \n",
      "\n",
      "Fold: 15  Epoch: 398  Training loss = 4.8788  Validation loss = 10.8542  \n",
      "\n",
      "Fold: 15  Epoch: 399  Training loss = 4.8783  Validation loss = 10.8534  \n",
      "\n",
      "Fold: 15  Epoch: 400  Training loss = 4.8777  Validation loss = 10.8527  \n",
      "\n",
      "Fold: 15  Epoch: 401  Training loss = 4.8772  Validation loss = 10.8520  \n",
      "\n",
      "Fold: 15  Epoch: 402  Training loss = 4.8766  Validation loss = 10.8511  \n",
      "\n",
      "Fold: 15  Epoch: 403  Training loss = 4.8761  Validation loss = 10.8504  \n",
      "\n",
      "Fold: 15  Epoch: 404  Training loss = 4.8755  Validation loss = 10.8496  \n",
      "\n",
      "Fold: 15  Epoch: 405  Training loss = 4.8750  Validation loss = 10.8489  \n",
      "\n",
      "Fold: 15  Epoch: 406  Training loss = 4.8744  Validation loss = 10.8481  \n",
      "\n",
      "Fold: 15  Epoch: 407  Training loss = 4.8738  Validation loss = 10.8473  \n",
      "\n",
      "Fold: 15  Epoch: 408  Training loss = 4.8733  Validation loss = 10.8466  \n",
      "\n",
      "Fold: 15  Epoch: 409  Training loss = 4.8728  Validation loss = 10.8459  \n",
      "\n",
      "Fold: 15  Epoch: 410  Training loss = 4.8723  Validation loss = 10.8452  \n",
      "\n",
      "Fold: 15  Epoch: 411  Training loss = 4.8718  Validation loss = 10.8445  \n",
      "\n",
      "Fold: 15  Epoch: 412  Training loss = 4.8714  Validation loss = 10.8439  \n",
      "\n",
      "Fold: 15  Epoch: 413  Training loss = 4.8708  Validation loss = 10.8431  \n",
      "\n",
      "Fold: 15  Epoch: 414  Training loss = 4.8701  Validation loss = 10.8422  \n",
      "\n",
      "Fold: 15  Epoch: 415  Training loss = 4.8696  Validation loss = 10.8415  \n",
      "\n",
      "Fold: 15  Epoch: 416  Training loss = 4.8692  Validation loss = 10.8409  \n",
      "\n",
      "Fold: 15  Epoch: 417  Training loss = 4.8686  Validation loss = 10.8402  \n",
      "\n",
      "Fold: 15  Epoch: 418  Training loss = 4.8681  Validation loss = 10.8395  \n",
      "\n",
      "Fold: 15  Epoch: 419  Training loss = 4.8677  Validation loss = 10.8389  \n",
      "\n",
      "Fold: 15  Epoch: 420  Training loss = 4.8671  Validation loss = 10.8381  \n",
      "\n",
      "Fold: 15  Epoch: 421  Training loss = 4.8667  Validation loss = 10.8375  \n",
      "\n",
      "Fold: 15  Epoch: 422  Training loss = 4.8662  Validation loss = 10.8368  \n",
      "\n",
      "Fold: 15  Epoch: 423  Training loss = 4.8656  Validation loss = 10.8360  \n",
      "\n",
      "Fold: 15  Epoch: 424  Training loss = 4.8652  Validation loss = 10.8354  \n",
      "\n",
      "Fold: 15  Epoch: 425  Training loss = 4.8646  Validation loss = 10.8347  \n",
      "\n",
      "Fold: 15  Epoch: 426  Training loss = 4.8640  Validation loss = 10.8337  \n",
      "\n",
      "Fold: 15  Epoch: 427  Training loss = 4.8634  Validation loss = 10.8330  \n",
      "\n",
      "Fold: 15  Epoch: 428  Training loss = 4.8628  Validation loss = 10.8321  \n",
      "\n",
      "Fold: 15  Epoch: 429  Training loss = 4.8624  Validation loss = 10.8316  \n",
      "\n",
      "Fold: 15  Epoch: 430  Training loss = 4.8619  Validation loss = 10.8309  \n",
      "\n",
      "Fold: 15  Epoch: 431  Training loss = 4.8613  Validation loss = 10.8300  \n",
      "\n",
      "Fold: 15  Epoch: 432  Training loss = 4.8608  Validation loss = 10.8293  \n",
      "\n",
      "Fold: 15  Epoch: 433  Training loss = 4.8603  Validation loss = 10.8286  \n",
      "\n",
      "Fold: 15  Epoch: 434  Training loss = 4.8598  Validation loss = 10.8279  \n",
      "\n",
      "Fold: 15  Epoch: 435  Training loss = 4.8592  Validation loss = 10.8271  \n",
      "\n",
      "Fold: 15  Epoch: 436  Training loss = 4.8586  Validation loss = 10.8262  \n",
      "\n",
      "Fold: 15  Epoch: 437  Training loss = 4.8580  Validation loss = 10.8254  \n",
      "\n",
      "Fold: 15  Epoch: 438  Training loss = 4.8574  Validation loss = 10.8245  \n",
      "\n",
      "Fold: 15  Epoch: 439  Training loss = 4.8568  Validation loss = 10.8237  \n",
      "\n",
      "Fold: 15  Epoch: 440  Training loss = 4.8564  Validation loss = 10.8231  \n",
      "\n",
      "Fold: 15  Epoch: 441  Training loss = 4.8558  Validation loss = 10.8224  \n",
      "\n",
      "Fold: 15  Epoch: 442  Training loss = 4.8553  Validation loss = 10.8217  \n",
      "\n",
      "Fold: 15  Epoch: 443  Training loss = 4.8548  Validation loss = 10.8210  \n",
      "\n",
      "Fold: 15  Epoch: 444  Training loss = 4.8544  Validation loss = 10.8204  \n",
      "\n",
      "Fold: 15  Epoch: 445  Training loss = 4.8538  Validation loss = 10.8195  \n",
      "\n",
      "Fold: 15  Epoch: 446  Training loss = 4.8532  Validation loss = 10.8187  \n",
      "\n",
      "Fold: 15  Epoch: 447  Training loss = 4.8527  Validation loss = 10.8180  \n",
      "\n",
      "Fold: 15  Epoch: 448  Training loss = 4.8522  Validation loss = 10.8173  \n",
      "\n",
      "Fold: 15  Epoch: 449  Training loss = 4.8516  Validation loss = 10.8165  \n",
      "\n",
      "Fold: 15  Epoch: 450  Training loss = 4.8511  Validation loss = 10.8158  \n",
      "\n",
      "Fold: 15  Epoch: 451  Training loss = 4.8506  Validation loss = 10.8150  \n",
      "\n",
      "Fold: 15  Epoch: 452  Training loss = 4.8502  Validation loss = 10.8145  \n",
      "\n",
      "Fold: 15  Epoch: 453  Training loss = 4.8495  Validation loss = 10.8135  \n",
      "\n",
      "Fold: 15  Epoch: 454  Training loss = 4.8490  Validation loss = 10.8129  \n",
      "\n",
      "Fold: 15  Epoch: 455  Training loss = 4.8486  Validation loss = 10.8122  \n",
      "\n",
      "Fold: 15  Epoch: 456  Training loss = 4.8480  Validation loss = 10.8114  \n",
      "\n",
      "Fold: 15  Epoch: 457  Training loss = 4.8475  Validation loss = 10.8107  \n",
      "\n",
      "Fold: 15  Epoch: 458  Training loss = 4.8470  Validation loss = 10.8101  \n",
      "\n",
      "Fold: 15  Epoch: 459  Training loss = 4.8465  Validation loss = 10.8093  \n",
      "\n",
      "Fold: 15  Epoch: 460  Training loss = 4.8460  Validation loss = 10.8086  \n",
      "\n",
      "Fold: 15  Epoch: 461  Training loss = 4.8455  Validation loss = 10.8080  \n",
      "\n",
      "Fold: 15  Epoch: 462  Training loss = 4.8450  Validation loss = 10.8073  \n",
      "\n",
      "Fold: 15  Epoch: 463  Training loss = 4.8445  Validation loss = 10.8065  \n",
      "\n",
      "Fold: 15  Epoch: 464  Training loss = 4.8440  Validation loss = 10.8058  \n",
      "\n",
      "Fold: 15  Epoch: 465  Training loss = 4.8435  Validation loss = 10.8051  \n",
      "\n",
      "Fold: 15  Epoch: 466  Training loss = 4.8431  Validation loss = 10.8046  \n",
      "\n",
      "Fold: 15  Epoch: 467  Training loss = 4.8427  Validation loss = 10.8040  \n",
      "\n",
      "Fold: 15  Epoch: 468  Training loss = 4.8421  Validation loss = 10.8032  \n",
      "\n",
      "Fold: 15  Epoch: 469  Training loss = 4.8415  Validation loss = 10.8023  \n",
      "\n",
      "Fold: 15  Epoch: 470  Training loss = 4.8410  Validation loss = 10.8016  \n",
      "\n",
      "Fold: 15  Epoch: 471  Training loss = 4.8406  Validation loss = 10.8010  \n",
      "\n",
      "Fold: 15  Epoch: 472  Training loss = 4.8401  Validation loss = 10.8004  \n",
      "\n",
      "Fold: 15  Epoch: 473  Training loss = 4.8397  Validation loss = 10.7998  \n",
      "\n",
      "Fold: 15  Epoch: 474  Training loss = 4.8392  Validation loss = 10.7991  \n",
      "\n",
      "Fold: 15  Epoch: 475  Training loss = 4.8387  Validation loss = 10.7984  \n",
      "\n",
      "Fold: 15  Epoch: 476  Training loss = 4.8381  Validation loss = 10.7976  \n",
      "\n",
      "Fold: 15  Epoch: 477  Training loss = 4.8375  Validation loss = 10.7967  \n",
      "\n",
      "Fold: 15  Epoch: 478  Training loss = 4.8370  Validation loss = 10.7959  \n",
      "\n",
      "Fold: 15  Epoch: 479  Training loss = 4.8364  Validation loss = 10.7952  \n",
      "\n",
      "Fold: 15  Epoch: 480  Training loss = 4.8359  Validation loss = 10.7944  \n",
      "\n",
      "Fold: 15  Epoch: 481  Training loss = 4.8354  Validation loss = 10.7937  \n",
      "\n",
      "Fold: 15  Epoch: 482  Training loss = 4.8348  Validation loss = 10.7930  \n",
      "\n",
      "Fold: 15  Epoch: 483  Training loss = 4.8344  Validation loss = 10.7924  \n",
      "\n",
      "Fold: 15  Epoch: 484  Training loss = 4.8340  Validation loss = 10.7918  \n",
      "\n",
      "Fold: 15  Epoch: 485  Training loss = 4.8335  Validation loss = 10.7912  \n",
      "\n",
      "Fold: 15  Epoch: 486  Training loss = 4.8330  Validation loss = 10.7904  \n",
      "\n",
      "Fold: 15  Epoch: 487  Training loss = 4.8323  Validation loss = 10.7894  \n",
      "\n",
      "Fold: 15  Epoch: 488  Training loss = 4.8318  Validation loss = 10.7887  \n",
      "\n",
      "Fold: 15  Epoch: 489  Training loss = 4.8312  Validation loss = 10.7879  \n",
      "\n",
      "Fold: 15  Epoch: 490  Training loss = 4.8307  Validation loss = 10.7871  \n",
      "\n",
      "Fold: 15  Epoch: 491  Training loss = 4.8302  Validation loss = 10.7865  \n",
      "\n",
      "Fold: 15  Epoch: 492  Training loss = 4.8296  Validation loss = 10.7856  \n",
      "\n",
      "Fold: 15  Epoch: 493  Training loss = 4.8292  Validation loss = 10.7850  \n",
      "\n",
      "Fold: 15  Epoch: 494  Training loss = 4.8286  Validation loss = 10.7843  \n",
      "\n",
      "Fold: 15  Epoch: 495  Training loss = 4.8281  Validation loss = 10.7835  \n",
      "\n",
      "Fold: 15  Epoch: 496  Training loss = 4.8276  Validation loss = 10.7828  \n",
      "\n",
      "Fold: 15  Epoch: 497  Training loss = 4.8271  Validation loss = 10.7820  \n",
      "\n",
      "Fold: 15  Epoch: 498  Training loss = 4.8266  Validation loss = 10.7813  \n",
      "\n",
      "Fold: 15  Epoch: 499  Training loss = 4.8261  Validation loss = 10.7807  \n",
      "\n",
      "Fold: 15  Epoch: 500  Training loss = 4.8256  Validation loss = 10.7800  \n",
      "\n",
      "Check model:  Fold: 15  Optimal epoch: 500  \n",
      "\n",
      "Fold: 16  Epoch: 1  Training loss = 5.5103  Validation loss = 8.2229  \n",
      "\n",
      "Fold: 16  Epoch: 2  Training loss = 5.5097  Validation loss = 8.2222  \n",
      "\n",
      "Fold: 16  Epoch: 3  Training loss = 5.5091  Validation loss = 8.2215  \n",
      "\n",
      "Fold: 16  Epoch: 4  Training loss = 5.5084  Validation loss = 8.2208  \n",
      "\n",
      "Fold: 16  Epoch: 5  Training loss = 5.5079  Validation loss = 8.2203  \n",
      "\n",
      "Fold: 16  Epoch: 6  Training loss = 5.5072  Validation loss = 8.2196  \n",
      "\n",
      "Fold: 16  Epoch: 7  Training loss = 5.5065  Validation loss = 8.2188  \n",
      "\n",
      "Fold: 16  Epoch: 8  Training loss = 5.5057  Validation loss = 8.2180  \n",
      "\n",
      "Fold: 16  Epoch: 9  Training loss = 5.5050  Validation loss = 8.2173  \n",
      "\n",
      "Fold: 16  Epoch: 10  Training loss = 5.5041  Validation loss = 8.2166  \n",
      "\n",
      "Fold: 16  Epoch: 11  Training loss = 5.5035  Validation loss = 8.2160  \n",
      "\n",
      "Fold: 16  Epoch: 12  Training loss = 5.5029  Validation loss = 8.2154  \n",
      "\n",
      "Fold: 16  Epoch: 13  Training loss = 5.5022  Validation loss = 8.2146  \n",
      "\n",
      "Fold: 16  Epoch: 14  Training loss = 5.5014  Validation loss = 8.2139  \n",
      "\n",
      "Fold: 16  Epoch: 15  Training loss = 5.5007  Validation loss = 8.2132  \n",
      "\n",
      "Fold: 16  Epoch: 16  Training loss = 5.5000  Validation loss = 8.2125  \n",
      "\n",
      "Fold: 16  Epoch: 17  Training loss = 5.4993  Validation loss = 8.2119  \n",
      "\n",
      "Fold: 16  Epoch: 18  Training loss = 5.4985  Validation loss = 8.2112  \n",
      "\n",
      "Fold: 16  Epoch: 19  Training loss = 5.4979  Validation loss = 8.2105  \n",
      "\n",
      "Fold: 16  Epoch: 20  Training loss = 5.4973  Validation loss = 8.2099  \n",
      "\n",
      "Fold: 16  Epoch: 21  Training loss = 5.4967  Validation loss = 8.2093  \n",
      "\n",
      "Fold: 16  Epoch: 22  Training loss = 5.4961  Validation loss = 8.2088  \n",
      "\n",
      "Fold: 16  Epoch: 23  Training loss = 5.4955  Validation loss = 8.2082  \n",
      "\n",
      "Fold: 16  Epoch: 24  Training loss = 5.4949  Validation loss = 8.2077  \n",
      "\n",
      "Fold: 16  Epoch: 25  Training loss = 5.4943  Validation loss = 8.2071  \n",
      "\n",
      "Fold: 16  Epoch: 26  Training loss = 5.4937  Validation loss = 8.2066  \n",
      "\n",
      "Fold: 16  Epoch: 27  Training loss = 5.4931  Validation loss = 8.2059  \n",
      "\n",
      "Fold: 16  Epoch: 28  Training loss = 5.4925  Validation loss = 8.2053  \n",
      "\n",
      "Fold: 16  Epoch: 29  Training loss = 5.4918  Validation loss = 8.2046  \n",
      "\n",
      "Fold: 16  Epoch: 30  Training loss = 5.4912  Validation loss = 8.2040  \n",
      "\n",
      "Fold: 16  Epoch: 31  Training loss = 5.4905  Validation loss = 8.2034  \n",
      "\n",
      "Fold: 16  Epoch: 32  Training loss = 5.4899  Validation loss = 8.2027  \n",
      "\n",
      "Fold: 16  Epoch: 33  Training loss = 5.4894  Validation loss = 8.2022  \n",
      "\n",
      "Fold: 16  Epoch: 34  Training loss = 5.4886  Validation loss = 8.2015  \n",
      "\n",
      "Fold: 16  Epoch: 35  Training loss = 5.4878  Validation loss = 8.2006  \n",
      "\n",
      "Fold: 16  Epoch: 36  Training loss = 5.4870  Validation loss = 8.1999  \n",
      "\n",
      "Fold: 16  Epoch: 37  Training loss = 5.4863  Validation loss = 8.1991  \n",
      "\n",
      "Fold: 16  Epoch: 38  Training loss = 5.4857  Validation loss = 8.1984  \n",
      "\n",
      "Fold: 16  Epoch: 39  Training loss = 5.4850  Validation loss = 8.1978  \n",
      "\n",
      "Fold: 16  Epoch: 40  Training loss = 5.4842  Validation loss = 8.1970  \n",
      "\n",
      "Fold: 16  Epoch: 41  Training loss = 5.4836  Validation loss = 8.1964  \n",
      "\n",
      "Fold: 16  Epoch: 42  Training loss = 5.4828  Validation loss = 8.1957  \n",
      "\n",
      "Fold: 16  Epoch: 43  Training loss = 5.4820  Validation loss = 8.1948  \n",
      "\n",
      "Fold: 16  Epoch: 44  Training loss = 5.4814  Validation loss = 8.1942  \n",
      "\n",
      "Fold: 16  Epoch: 45  Training loss = 5.4806  Validation loss = 8.1935  \n",
      "\n",
      "Fold: 16  Epoch: 46  Training loss = 5.4799  Validation loss = 8.1929  \n",
      "\n",
      "Fold: 16  Epoch: 47  Training loss = 5.4792  Validation loss = 8.1923  \n",
      "\n",
      "Fold: 16  Epoch: 48  Training loss = 5.4786  Validation loss = 8.1917  \n",
      "\n",
      "Fold: 16  Epoch: 49  Training loss = 5.4779  Validation loss = 8.1910  \n",
      "\n",
      "Fold: 16  Epoch: 50  Training loss = 5.4772  Validation loss = 8.1903  \n",
      "\n",
      "Fold: 16  Epoch: 51  Training loss = 5.4766  Validation loss = 8.1897  \n",
      "\n",
      "Fold: 16  Epoch: 52  Training loss = 5.4760  Validation loss = 8.1891  \n",
      "\n",
      "Fold: 16  Epoch: 53  Training loss = 5.4753  Validation loss = 8.1884  \n",
      "\n",
      "Fold: 16  Epoch: 54  Training loss = 5.4746  Validation loss = 8.1877  \n",
      "\n",
      "Fold: 16  Epoch: 55  Training loss = 5.4737  Validation loss = 8.1869  \n",
      "\n",
      "Fold: 16  Epoch: 56  Training loss = 5.4729  Validation loss = 8.1862  \n",
      "\n",
      "Fold: 16  Epoch: 57  Training loss = 5.4721  Validation loss = 8.1853  \n",
      "\n",
      "Fold: 16  Epoch: 58  Training loss = 5.4715  Validation loss = 8.1846  \n",
      "\n",
      "Fold: 16  Epoch: 59  Training loss = 5.4708  Validation loss = 8.1838  \n",
      "\n",
      "Fold: 16  Epoch: 60  Training loss = 5.4701  Validation loss = 8.1832  \n",
      "\n",
      "Fold: 16  Epoch: 61  Training loss = 5.4693  Validation loss = 8.1823  \n",
      "\n",
      "Fold: 16  Epoch: 62  Training loss = 5.4686  Validation loss = 8.1816  \n",
      "\n",
      "Fold: 16  Epoch: 63  Training loss = 5.4679  Validation loss = 8.1808  \n",
      "\n",
      "Fold: 16  Epoch: 64  Training loss = 5.4673  Validation loss = 8.1801  \n",
      "\n",
      "Fold: 16  Epoch: 65  Training loss = 5.4665  Validation loss = 8.1792  \n",
      "\n",
      "Fold: 16  Epoch: 66  Training loss = 5.4658  Validation loss = 8.1785  \n",
      "\n",
      "Fold: 16  Epoch: 67  Training loss = 5.4652  Validation loss = 8.1779  \n",
      "\n",
      "Fold: 16  Epoch: 68  Training loss = 5.4645  Validation loss = 8.1771  \n",
      "\n",
      "Fold: 16  Epoch: 69  Training loss = 5.4638  Validation loss = 8.1764  \n",
      "\n",
      "Fold: 16  Epoch: 70  Training loss = 5.4631  Validation loss = 8.1756  \n",
      "\n",
      "Fold: 16  Epoch: 71  Training loss = 5.4623  Validation loss = 8.1749  \n",
      "\n",
      "Fold: 16  Epoch: 72  Training loss = 5.4616  Validation loss = 8.1741  \n",
      "\n",
      "Fold: 16  Epoch: 73  Training loss = 5.4609  Validation loss = 8.1733  \n",
      "\n",
      "Fold: 16  Epoch: 74  Training loss = 5.4602  Validation loss = 8.1725  \n",
      "\n",
      "Fold: 16  Epoch: 75  Training loss = 5.4597  Validation loss = 8.1721  \n",
      "\n",
      "Fold: 16  Epoch: 76  Training loss = 5.4589  Validation loss = 8.1711  \n",
      "\n",
      "Fold: 16  Epoch: 77  Training loss = 5.4582  Validation loss = 8.1704  \n",
      "\n",
      "Fold: 16  Epoch: 78  Training loss = 5.4575  Validation loss = 8.1696  \n",
      "\n",
      "Fold: 16  Epoch: 79  Training loss = 5.4569  Validation loss = 8.1691  \n",
      "\n",
      "Fold: 16  Epoch: 80  Training loss = 5.4561  Validation loss = 8.1684  \n",
      "\n",
      "Fold: 16  Epoch: 81  Training loss = 5.4555  Validation loss = 8.1677  \n",
      "\n",
      "Fold: 16  Epoch: 82  Training loss = 5.4547  Validation loss = 8.1668  \n",
      "\n",
      "Fold: 16  Epoch: 83  Training loss = 5.4539  Validation loss = 8.1661  \n",
      "\n",
      "Fold: 16  Epoch: 84  Training loss = 5.4532  Validation loss = 8.1652  \n",
      "\n",
      "Fold: 16  Epoch: 85  Training loss = 5.4525  Validation loss = 8.1645  \n",
      "\n",
      "Fold: 16  Epoch: 86  Training loss = 5.4516  Validation loss = 8.1635  \n",
      "\n",
      "Fold: 16  Epoch: 87  Training loss = 5.4510  Validation loss = 8.1629  \n",
      "\n",
      "Fold: 16  Epoch: 88  Training loss = 5.4505  Validation loss = 8.1621  \n",
      "\n",
      "Fold: 16  Epoch: 89  Training loss = 5.4498  Validation loss = 8.1612  \n",
      "\n",
      "Fold: 16  Epoch: 90  Training loss = 5.4491  Validation loss = 8.1605  \n",
      "\n",
      "Fold: 16  Epoch: 91  Training loss = 5.4484  Validation loss = 8.1599  \n",
      "\n",
      "Fold: 16  Epoch: 92  Training loss = 5.4478  Validation loss = 8.1593  \n",
      "\n",
      "Fold: 16  Epoch: 93  Training loss = 5.4472  Validation loss = 8.1587  \n",
      "\n",
      "Fold: 16  Epoch: 94  Training loss = 5.4466  Validation loss = 8.1580  \n",
      "\n",
      "Fold: 16  Epoch: 95  Training loss = 5.4459  Validation loss = 8.1574  \n",
      "\n",
      "Fold: 16  Epoch: 96  Training loss = 5.4450  Validation loss = 8.1563  \n",
      "\n",
      "Fold: 16  Epoch: 97  Training loss = 5.4444  Validation loss = 8.1555  \n",
      "\n",
      "Fold: 16  Epoch: 98  Training loss = 5.4436  Validation loss = 8.1548  \n",
      "\n",
      "Fold: 16  Epoch: 99  Training loss = 5.4430  Validation loss = 8.1541  \n",
      "\n",
      "Fold: 16  Epoch: 100  Training loss = 5.4424  Validation loss = 8.1532  \n",
      "\n",
      "Fold: 16  Epoch: 101  Training loss = 5.4417  Validation loss = 8.1524  \n",
      "\n",
      "Fold: 16  Epoch: 102  Training loss = 5.4409  Validation loss = 8.1514  \n",
      "\n",
      "Fold: 16  Epoch: 103  Training loss = 5.4403  Validation loss = 8.1507  \n",
      "\n",
      "Fold: 16  Epoch: 104  Training loss = 5.4395  Validation loss = 8.1499  \n",
      "\n",
      "Fold: 16  Epoch: 105  Training loss = 5.4388  Validation loss = 8.1493  \n",
      "\n",
      "Fold: 16  Epoch: 106  Training loss = 5.4382  Validation loss = 8.1487  \n",
      "\n",
      "Fold: 16  Epoch: 107  Training loss = 5.4375  Validation loss = 8.1479  \n",
      "\n",
      "Fold: 16  Epoch: 108  Training loss = 5.4368  Validation loss = 8.1471  \n",
      "\n",
      "Fold: 16  Epoch: 109  Training loss = 5.4361  Validation loss = 8.1464  \n",
      "\n",
      "Fold: 16  Epoch: 110  Training loss = 5.4354  Validation loss = 8.1455  \n",
      "\n",
      "Fold: 16  Epoch: 111  Training loss = 5.4347  Validation loss = 8.1447  \n",
      "\n",
      "Fold: 16  Epoch: 112  Training loss = 5.4341  Validation loss = 8.1440  \n",
      "\n",
      "Fold: 16  Epoch: 113  Training loss = 5.4334  Validation loss = 8.1433  \n",
      "\n",
      "Fold: 16  Epoch: 114  Training loss = 5.4326  Validation loss = 8.1423  \n",
      "\n",
      "Fold: 16  Epoch: 115  Training loss = 5.4318  Validation loss = 8.1415  \n",
      "\n",
      "Fold: 16  Epoch: 116  Training loss = 5.4312  Validation loss = 8.1407  \n",
      "\n",
      "Fold: 16  Epoch: 117  Training loss = 5.4305  Validation loss = 8.1400  \n",
      "\n",
      "Fold: 16  Epoch: 118  Training loss = 5.4298  Validation loss = 8.1394  \n",
      "\n",
      "Fold: 16  Epoch: 119  Training loss = 5.4290  Validation loss = 8.1385  \n",
      "\n",
      "Fold: 16  Epoch: 120  Training loss = 5.4282  Validation loss = 8.1374  \n",
      "\n",
      "Fold: 16  Epoch: 121  Training loss = 5.4275  Validation loss = 8.1367  \n",
      "\n",
      "Fold: 16  Epoch: 122  Training loss = 5.4269  Validation loss = 8.1361  \n",
      "\n",
      "Fold: 16  Epoch: 123  Training loss = 5.4261  Validation loss = 8.1353  \n",
      "\n",
      "Fold: 16  Epoch: 124  Training loss = 5.4253  Validation loss = 8.1344  \n",
      "\n",
      "Fold: 16  Epoch: 125  Training loss = 5.4246  Validation loss = 8.1336  \n",
      "\n",
      "Fold: 16  Epoch: 126  Training loss = 5.4239  Validation loss = 8.1327  \n",
      "\n",
      "Fold: 16  Epoch: 127  Training loss = 5.4232  Validation loss = 8.1320  \n",
      "\n",
      "Fold: 16  Epoch: 128  Training loss = 5.4225  Validation loss = 8.1313  \n",
      "\n",
      "Fold: 16  Epoch: 129  Training loss = 5.4219  Validation loss = 8.1306  \n",
      "\n",
      "Fold: 16  Epoch: 130  Training loss = 5.4211  Validation loss = 8.1297  \n",
      "\n",
      "Fold: 16  Epoch: 131  Training loss = 5.4204  Validation loss = 8.1289  \n",
      "\n",
      "Fold: 16  Epoch: 132  Training loss = 5.4197  Validation loss = 8.1281  \n",
      "\n",
      "Fold: 16  Epoch: 133  Training loss = 5.4191  Validation loss = 8.1272  \n",
      "\n",
      "Fold: 16  Epoch: 134  Training loss = 5.4183  Validation loss = 8.1263  \n",
      "\n",
      "Fold: 16  Epoch: 135  Training loss = 5.4175  Validation loss = 8.1254  \n",
      "\n",
      "Fold: 16  Epoch: 136  Training loss = 5.4168  Validation loss = 8.1245  \n",
      "\n",
      "Fold: 16  Epoch: 137  Training loss = 5.4162  Validation loss = 8.1238  \n",
      "\n",
      "Fold: 16  Epoch: 138  Training loss = 5.4155  Validation loss = 8.1231  \n",
      "\n",
      "Fold: 16  Epoch: 139  Training loss = 5.4149  Validation loss = 8.1226  \n",
      "\n",
      "Fold: 16  Epoch: 140  Training loss = 5.4141  Validation loss = 8.1216  \n",
      "\n",
      "Fold: 16  Epoch: 141  Training loss = 5.4133  Validation loss = 8.1207  \n",
      "\n",
      "Fold: 16  Epoch: 142  Training loss = 5.4126  Validation loss = 8.1199  \n",
      "\n",
      "Fold: 16  Epoch: 143  Training loss = 5.4119  Validation loss = 8.1191  \n",
      "\n",
      "Fold: 16  Epoch: 144  Training loss = 5.4112  Validation loss = 8.1184  \n",
      "\n",
      "Fold: 16  Epoch: 145  Training loss = 5.4104  Validation loss = 8.1171  \n",
      "\n",
      "Fold: 16  Epoch: 146  Training loss = 5.4097  Validation loss = 8.1162  \n",
      "\n",
      "Fold: 16  Epoch: 147  Training loss = 5.4089  Validation loss = 8.1153  \n",
      "\n",
      "Fold: 16  Epoch: 148  Training loss = 5.4081  Validation loss = 8.1144  \n",
      "\n",
      "Fold: 16  Epoch: 149  Training loss = 5.4075  Validation loss = 8.1136  \n",
      "\n",
      "Fold: 16  Epoch: 150  Training loss = 5.4066  Validation loss = 8.1126  \n",
      "\n",
      "Fold: 16  Epoch: 151  Training loss = 5.4059  Validation loss = 8.1119  \n",
      "\n",
      "Fold: 16  Epoch: 152  Training loss = 5.4052  Validation loss = 8.1112  \n",
      "\n",
      "Fold: 16  Epoch: 153  Training loss = 5.4046  Validation loss = 8.1106  \n",
      "\n",
      "Fold: 16  Epoch: 154  Training loss = 5.4039  Validation loss = 8.1099  \n",
      "\n",
      "Fold: 16  Epoch: 155  Training loss = 5.4033  Validation loss = 8.1090  \n",
      "\n",
      "Fold: 16  Epoch: 156  Training loss = 5.4025  Validation loss = 8.1080  \n",
      "\n",
      "Fold: 16  Epoch: 157  Training loss = 5.4017  Validation loss = 8.1071  \n",
      "\n",
      "Fold: 16  Epoch: 158  Training loss = 5.4010  Validation loss = 8.1064  \n",
      "\n",
      "Fold: 16  Epoch: 159  Training loss = 5.4002  Validation loss = 8.1057  \n",
      "\n",
      "Fold: 16  Epoch: 160  Training loss = 5.3995  Validation loss = 8.1049  \n",
      "\n",
      "Fold: 16  Epoch: 161  Training loss = 5.3988  Validation loss = 8.1041  \n",
      "\n",
      "Fold: 16  Epoch: 162  Training loss = 5.3982  Validation loss = 8.1034  \n",
      "\n",
      "Fold: 16  Epoch: 163  Training loss = 5.3974  Validation loss = 8.1026  \n",
      "\n",
      "Fold: 16  Epoch: 164  Training loss = 5.3967  Validation loss = 8.1019  \n",
      "\n",
      "Fold: 16  Epoch: 165  Training loss = 5.3960  Validation loss = 8.1010  \n",
      "\n",
      "Fold: 16  Epoch: 166  Training loss = 5.3953  Validation loss = 8.1002  \n",
      "\n",
      "Fold: 16  Epoch: 167  Training loss = 5.3945  Validation loss = 8.0994  \n",
      "\n",
      "Fold: 16  Epoch: 168  Training loss = 5.3938  Validation loss = 8.0985  \n",
      "\n",
      "Fold: 16  Epoch: 169  Training loss = 5.3930  Validation loss = 8.0975  \n",
      "\n",
      "Fold: 16  Epoch: 170  Training loss = 5.3923  Validation loss = 8.0966  \n",
      "\n",
      "Fold: 16  Epoch: 171  Training loss = 5.3915  Validation loss = 8.0956  \n",
      "\n",
      "Fold: 16  Epoch: 172  Training loss = 5.3908  Validation loss = 8.0948  \n",
      "\n",
      "Fold: 16  Epoch: 173  Training loss = 5.3901  Validation loss = 8.0938  \n",
      "\n",
      "Fold: 16  Epoch: 174  Training loss = 5.3893  Validation loss = 8.0931  \n",
      "\n",
      "Fold: 16  Epoch: 175  Training loss = 5.3886  Validation loss = 8.0920  \n",
      "\n",
      "Fold: 16  Epoch: 176  Training loss = 5.3878  Validation loss = 8.0911  \n",
      "\n",
      "Fold: 16  Epoch: 177  Training loss = 5.3871  Validation loss = 8.0904  \n",
      "\n",
      "Fold: 16  Epoch: 178  Training loss = 5.3864  Validation loss = 8.0895  \n",
      "\n",
      "Fold: 16  Epoch: 179  Training loss = 5.3856  Validation loss = 8.0886  \n",
      "\n",
      "Fold: 16  Epoch: 180  Training loss = 5.3849  Validation loss = 8.0877  \n",
      "\n",
      "Fold: 16  Epoch: 181  Training loss = 5.3843  Validation loss = 8.0871  \n",
      "\n",
      "Fold: 16  Epoch: 182  Training loss = 5.3835  Validation loss = 8.0861  \n",
      "\n",
      "Fold: 16  Epoch: 183  Training loss = 5.3829  Validation loss = 8.0856  \n",
      "\n",
      "Fold: 16  Epoch: 184  Training loss = 5.3822  Validation loss = 8.0847  \n",
      "\n",
      "Fold: 16  Epoch: 185  Training loss = 5.3815  Validation loss = 8.0840  \n",
      "\n",
      "Fold: 16  Epoch: 186  Training loss = 5.3810  Validation loss = 8.0833  \n",
      "\n",
      "Fold: 16  Epoch: 187  Training loss = 5.3803  Validation loss = 8.0824  \n",
      "\n",
      "Fold: 16  Epoch: 188  Training loss = 5.3795  Validation loss = 8.0814  \n",
      "\n",
      "Fold: 16  Epoch: 189  Training loss = 5.3786  Validation loss = 8.0804  \n",
      "\n",
      "Fold: 16  Epoch: 190  Training loss = 5.3779  Validation loss = 8.0796  \n",
      "\n",
      "Fold: 16  Epoch: 191  Training loss = 5.3773  Validation loss = 8.0785  \n",
      "\n",
      "Fold: 16  Epoch: 192  Training loss = 5.3764  Validation loss = 8.0776  \n",
      "\n",
      "Fold: 16  Epoch: 193  Training loss = 5.3757  Validation loss = 8.0765  \n",
      "\n",
      "Fold: 16  Epoch: 194  Training loss = 5.3749  Validation loss = 8.0756  \n",
      "\n",
      "Fold: 16  Epoch: 195  Training loss = 5.3742  Validation loss = 8.0747  \n",
      "\n",
      "Fold: 16  Epoch: 196  Training loss = 5.3736  Validation loss = 8.0738  \n",
      "\n",
      "Fold: 16  Epoch: 197  Training loss = 5.3729  Validation loss = 8.0730  \n",
      "\n",
      "Fold: 16  Epoch: 198  Training loss = 5.3722  Validation loss = 8.0721  \n",
      "\n",
      "Fold: 16  Epoch: 199  Training loss = 5.3716  Validation loss = 8.0713  \n",
      "\n",
      "Fold: 16  Epoch: 200  Training loss = 5.3708  Validation loss = 8.0703  \n",
      "\n",
      "Fold: 16  Epoch: 201  Training loss = 5.3701  Validation loss = 8.0694  \n",
      "\n",
      "Fold: 16  Epoch: 202  Training loss = 5.3694  Validation loss = 8.0686  \n",
      "\n",
      "Fold: 16  Epoch: 203  Training loss = 5.3686  Validation loss = 8.0675  \n",
      "\n",
      "Fold: 16  Epoch: 204  Training loss = 5.3681  Validation loss = 8.0668  \n",
      "\n",
      "Fold: 16  Epoch: 205  Training loss = 5.3674  Validation loss = 8.0659  \n",
      "\n",
      "Fold: 16  Epoch: 206  Training loss = 5.3668  Validation loss = 8.0652  \n",
      "\n",
      "Fold: 16  Epoch: 207  Training loss = 5.3661  Validation loss = 8.0643  \n",
      "\n",
      "Fold: 16  Epoch: 208  Training loss = 5.3655  Validation loss = 8.0636  \n",
      "\n",
      "Fold: 16  Epoch: 209  Training loss = 5.3648  Validation loss = 8.0627  \n",
      "\n",
      "Fold: 16  Epoch: 210  Training loss = 5.3641  Validation loss = 8.0617  \n",
      "\n",
      "Fold: 16  Epoch: 211  Training loss = 5.3635  Validation loss = 8.0610  \n",
      "\n",
      "Fold: 16  Epoch: 212  Training loss = 5.3627  Validation loss = 8.0601  \n",
      "\n",
      "Fold: 16  Epoch: 213  Training loss = 5.3622  Validation loss = 8.0594  \n",
      "\n",
      "Fold: 16  Epoch: 214  Training loss = 5.3616  Validation loss = 8.0585  \n",
      "\n",
      "Fold: 16  Epoch: 215  Training loss = 5.3611  Validation loss = 8.0577  \n",
      "\n",
      "Fold: 16  Epoch: 216  Training loss = 5.3605  Validation loss = 8.0568  \n",
      "\n",
      "Fold: 16  Epoch: 217  Training loss = 5.3597  Validation loss = 8.0558  \n",
      "\n",
      "Fold: 16  Epoch: 218  Training loss = 5.3590  Validation loss = 8.0549  \n",
      "\n",
      "Fold: 16  Epoch: 219  Training loss = 5.3583  Validation loss = 8.0540  \n",
      "\n",
      "Fold: 16  Epoch: 220  Training loss = 5.3575  Validation loss = 8.0528  \n",
      "\n",
      "Fold: 16  Epoch: 221  Training loss = 5.3568  Validation loss = 8.0521  \n",
      "\n",
      "Fold: 16  Epoch: 222  Training loss = 5.3561  Validation loss = 8.0513  \n",
      "\n",
      "Fold: 16  Epoch: 223  Training loss = 5.3555  Validation loss = 8.0507  \n",
      "\n",
      "Fold: 16  Epoch: 224  Training loss = 5.3547  Validation loss = 8.0497  \n",
      "\n",
      "Fold: 16  Epoch: 225  Training loss = 5.3540  Validation loss = 8.0488  \n",
      "\n",
      "Fold: 16  Epoch: 226  Training loss = 5.3532  Validation loss = 8.0476  \n",
      "\n",
      "Fold: 16  Epoch: 227  Training loss = 5.3525  Validation loss = 8.0468  \n",
      "\n",
      "Fold: 16  Epoch: 228  Training loss = 5.3519  Validation loss = 8.0462  \n",
      "\n",
      "Fold: 16  Epoch: 229  Training loss = 5.3513  Validation loss = 8.0455  \n",
      "\n",
      "Fold: 16  Epoch: 230  Training loss = 5.3506  Validation loss = 8.0447  \n",
      "\n",
      "Fold: 16  Epoch: 231  Training loss = 5.3498  Validation loss = 8.0438  \n",
      "\n",
      "Fold: 16  Epoch: 232  Training loss = 5.3492  Validation loss = 8.0429  \n",
      "\n",
      "Fold: 16  Epoch: 233  Training loss = 5.3486  Validation loss = 8.0420  \n",
      "\n",
      "Fold: 16  Epoch: 234  Training loss = 5.3479  Validation loss = 8.0409  \n",
      "\n",
      "Fold: 16  Epoch: 235  Training loss = 5.3472  Validation loss = 8.0399  \n",
      "\n",
      "Fold: 16  Epoch: 236  Training loss = 5.3465  Validation loss = 8.0391  \n",
      "\n",
      "Fold: 16  Epoch: 237  Training loss = 5.3458  Validation loss = 8.0381  \n",
      "\n",
      "Fold: 16  Epoch: 238  Training loss = 5.3452  Validation loss = 8.0373  \n",
      "\n",
      "Fold: 16  Epoch: 239  Training loss = 5.3445  Validation loss = 8.0363  \n",
      "\n",
      "Fold: 16  Epoch: 240  Training loss = 5.3439  Validation loss = 8.0354  \n",
      "\n",
      "Fold: 16  Epoch: 241  Training loss = 5.3432  Validation loss = 8.0345  \n",
      "\n",
      "Fold: 16  Epoch: 242  Training loss = 5.3425  Validation loss = 8.0336  \n",
      "\n",
      "Fold: 16  Epoch: 243  Training loss = 5.3417  Validation loss = 8.0328  \n",
      "\n",
      "Fold: 16  Epoch: 244  Training loss = 5.3409  Validation loss = 8.0318  \n",
      "\n",
      "Fold: 16  Epoch: 245  Training loss = 5.3400  Validation loss = 8.0306  \n",
      "\n",
      "Fold: 16  Epoch: 246  Training loss = 5.3393  Validation loss = 8.0296  \n",
      "\n",
      "Fold: 16  Epoch: 247  Training loss = 5.3385  Validation loss = 8.0288  \n",
      "\n",
      "Fold: 16  Epoch: 248  Training loss = 5.3379  Validation loss = 8.0281  \n",
      "\n",
      "Fold: 16  Epoch: 249  Training loss = 5.3372  Validation loss = 8.0270  \n",
      "\n",
      "Fold: 16  Epoch: 250  Training loss = 5.3365  Validation loss = 8.0261  \n",
      "\n",
      "Fold: 16  Epoch: 251  Training loss = 5.3359  Validation loss = 8.0254  \n",
      "\n",
      "Fold: 16  Epoch: 252  Training loss = 5.3351  Validation loss = 8.0244  \n",
      "\n",
      "Fold: 16  Epoch: 253  Training loss = 5.3344  Validation loss = 8.0237  \n",
      "\n",
      "Fold: 16  Epoch: 254  Training loss = 5.3337  Validation loss = 8.0228  \n",
      "\n",
      "Fold: 16  Epoch: 255  Training loss = 5.3331  Validation loss = 8.0218  \n",
      "\n",
      "Fold: 16  Epoch: 256  Training loss = 5.3324  Validation loss = 8.0211  \n",
      "\n",
      "Fold: 16  Epoch: 257  Training loss = 5.3318  Validation loss = 8.0202  \n",
      "\n",
      "Fold: 16  Epoch: 258  Training loss = 5.3311  Validation loss = 8.0191  \n",
      "\n",
      "Fold: 16  Epoch: 259  Training loss = 5.3304  Validation loss = 8.0181  \n",
      "\n",
      "Fold: 16  Epoch: 260  Training loss = 5.3297  Validation loss = 8.0170  \n",
      "\n",
      "Fold: 16  Epoch: 261  Training loss = 5.3292  Validation loss = 8.0163  \n",
      "\n",
      "Fold: 16  Epoch: 262  Training loss = 5.3285  Validation loss = 8.0155  \n",
      "\n",
      "Fold: 16  Epoch: 263  Training loss = 5.3278  Validation loss = 8.0146  \n",
      "\n",
      "Fold: 16  Epoch: 264  Training loss = 5.3272  Validation loss = 8.0138  \n",
      "\n",
      "Fold: 16  Epoch: 265  Training loss = 5.3264  Validation loss = 8.0127  \n",
      "\n",
      "Fold: 16  Epoch: 266  Training loss = 5.3256  Validation loss = 8.0115  \n",
      "\n",
      "Fold: 16  Epoch: 267  Training loss = 5.3250  Validation loss = 8.0106  \n",
      "\n",
      "Fold: 16  Epoch: 268  Training loss = 5.3243  Validation loss = 8.0098  \n",
      "\n",
      "Fold: 16  Epoch: 269  Training loss = 5.3236  Validation loss = 8.0088  \n",
      "\n",
      "Fold: 16  Epoch: 270  Training loss = 5.3229  Validation loss = 8.0080  \n",
      "\n",
      "Fold: 16  Epoch: 271  Training loss = 5.3222  Validation loss = 8.0070  \n",
      "\n",
      "Fold: 16  Epoch: 272  Training loss = 5.3216  Validation loss = 8.0061  \n",
      "\n",
      "Fold: 16  Epoch: 273  Training loss = 5.3211  Validation loss = 8.0053  \n",
      "\n",
      "Fold: 16  Epoch: 274  Training loss = 5.3202  Validation loss = 8.0041  \n",
      "\n",
      "Fold: 16  Epoch: 275  Training loss = 5.3196  Validation loss = 8.0032  \n",
      "\n",
      "Fold: 16  Epoch: 276  Training loss = 5.3190  Validation loss = 8.0024  \n",
      "\n",
      "Fold: 16  Epoch: 277  Training loss = 5.3182  Validation loss = 8.0013  \n",
      "\n",
      "Fold: 16  Epoch: 278  Training loss = 5.3175  Validation loss = 8.0002  \n",
      "\n",
      "Fold: 16  Epoch: 279  Training loss = 5.3168  Validation loss = 7.9991  \n",
      "\n",
      "Fold: 16  Epoch: 280  Training loss = 5.3161  Validation loss = 7.9982  \n",
      "\n",
      "Fold: 16  Epoch: 281  Training loss = 5.3154  Validation loss = 7.9971  \n",
      "\n",
      "Fold: 16  Epoch: 282  Training loss = 5.3149  Validation loss = 7.9963  \n",
      "\n",
      "Fold: 16  Epoch: 283  Training loss = 5.3144  Validation loss = 7.9957  \n",
      "\n",
      "Fold: 16  Epoch: 284  Training loss = 5.3137  Validation loss = 7.9948  \n",
      "\n",
      "Fold: 16  Epoch: 285  Training loss = 5.3129  Validation loss = 7.9939  \n",
      "\n",
      "Fold: 16  Epoch: 286  Training loss = 5.3123  Validation loss = 7.9931  \n",
      "\n",
      "Fold: 16  Epoch: 287  Training loss = 5.3115  Validation loss = 7.9920  \n",
      "\n",
      "Fold: 16  Epoch: 288  Training loss = 5.3109  Validation loss = 7.9913  \n",
      "\n",
      "Fold: 16  Epoch: 289  Training loss = 5.3102  Validation loss = 7.9904  \n",
      "\n",
      "Fold: 16  Epoch: 290  Training loss = 5.3096  Validation loss = 7.9895  \n",
      "\n",
      "Fold: 16  Epoch: 291  Training loss = 5.3088  Validation loss = 7.9886  \n",
      "\n",
      "Fold: 16  Epoch: 292  Training loss = 5.3082  Validation loss = 7.9878  \n",
      "\n",
      "Fold: 16  Epoch: 293  Training loss = 5.3076  Validation loss = 7.9869  \n",
      "\n",
      "Fold: 16  Epoch: 294  Training loss = 5.3069  Validation loss = 7.9858  \n",
      "\n",
      "Fold: 16  Epoch: 295  Training loss = 5.3062  Validation loss = 7.9847  \n",
      "\n",
      "Fold: 16  Epoch: 296  Training loss = 5.3056  Validation loss = 7.9841  \n",
      "\n",
      "Fold: 16  Epoch: 297  Training loss = 5.3048  Validation loss = 7.9831  \n",
      "\n",
      "Fold: 16  Epoch: 298  Training loss = 5.3040  Validation loss = 7.9822  \n",
      "\n",
      "Fold: 16  Epoch: 299  Training loss = 5.3033  Validation loss = 7.9814  \n",
      "\n",
      "Fold: 16  Epoch: 300  Training loss = 5.3028  Validation loss = 7.9807  \n",
      "\n",
      "Fold: 16  Epoch: 301  Training loss = 5.3020  Validation loss = 7.9798  \n",
      "\n",
      "Fold: 16  Epoch: 302  Training loss = 5.3013  Validation loss = 7.9788  \n",
      "\n",
      "Fold: 16  Epoch: 303  Training loss = 5.3007  Validation loss = 7.9781  \n",
      "\n",
      "Fold: 16  Epoch: 304  Training loss = 5.3001  Validation loss = 7.9774  \n",
      "\n",
      "Fold: 16  Epoch: 305  Training loss = 5.2995  Validation loss = 7.9765  \n",
      "\n",
      "Fold: 16  Epoch: 306  Training loss = 5.2988  Validation loss = 7.9756  \n",
      "\n",
      "Fold: 16  Epoch: 307  Training loss = 5.2982  Validation loss = 7.9749  \n",
      "\n",
      "Fold: 16  Epoch: 308  Training loss = 5.2972  Validation loss = 7.9736  \n",
      "\n",
      "Fold: 16  Epoch: 309  Training loss = 5.2965  Validation loss = 7.9725  \n",
      "\n",
      "Fold: 16  Epoch: 310  Training loss = 5.2959  Validation loss = 7.9715  \n",
      "\n",
      "Fold: 16  Epoch: 311  Training loss = 5.2953  Validation loss = 7.9706  \n",
      "\n",
      "Fold: 16  Epoch: 312  Training loss = 5.2947  Validation loss = 7.9699  \n",
      "\n",
      "Fold: 16  Epoch: 313  Training loss = 5.2940  Validation loss = 7.9691  \n",
      "\n",
      "Fold: 16  Epoch: 314  Training loss = 5.2933  Validation loss = 7.9680  \n",
      "\n",
      "Fold: 16  Epoch: 315  Training loss = 5.2925  Validation loss = 7.9667  \n",
      "\n",
      "Fold: 16  Epoch: 316  Training loss = 5.2919  Validation loss = 7.9657  \n",
      "\n",
      "Fold: 16  Epoch: 317  Training loss = 5.2913  Validation loss = 7.9649  \n",
      "\n",
      "Fold: 16  Epoch: 318  Training loss = 5.2906  Validation loss = 7.9641  \n",
      "\n",
      "Fold: 16  Epoch: 319  Training loss = 5.2900  Validation loss = 7.9632  \n",
      "\n",
      "Fold: 16  Epoch: 320  Training loss = 5.2892  Validation loss = 7.9619  \n",
      "\n",
      "Fold: 16  Epoch: 321  Training loss = 5.2885  Validation loss = 7.9611  \n",
      "\n",
      "Fold: 16  Epoch: 322  Training loss = 5.2878  Validation loss = 7.9601  \n",
      "\n",
      "Fold: 16  Epoch: 323  Training loss = 5.2870  Validation loss = 7.9591  \n",
      "\n",
      "Fold: 16  Epoch: 324  Training loss = 5.2863  Validation loss = 7.9582  \n",
      "\n",
      "Fold: 16  Epoch: 325  Training loss = 5.2857  Validation loss = 7.9573  \n",
      "\n",
      "Fold: 16  Epoch: 326  Training loss = 5.2851  Validation loss = 7.9565  \n",
      "\n",
      "Fold: 16  Epoch: 327  Training loss = 5.2845  Validation loss = 7.9555  \n",
      "\n",
      "Fold: 16  Epoch: 328  Training loss = 5.2840  Validation loss = 7.9550  \n",
      "\n",
      "Fold: 16  Epoch: 329  Training loss = 5.2834  Validation loss = 7.9541  \n",
      "\n",
      "Fold: 16  Epoch: 330  Training loss = 5.2827  Validation loss = 7.9531  \n",
      "\n",
      "Fold: 16  Epoch: 331  Training loss = 5.2822  Validation loss = 7.9522  \n",
      "\n",
      "Fold: 16  Epoch: 332  Training loss = 5.2816  Validation loss = 7.9514  \n",
      "\n",
      "Fold: 16  Epoch: 333  Training loss = 5.2809  Validation loss = 7.9504  \n",
      "\n",
      "Fold: 16  Epoch: 334  Training loss = 5.2801  Validation loss = 7.9492  \n",
      "\n",
      "Fold: 16  Epoch: 335  Training loss = 5.2794  Validation loss = 7.9482  \n",
      "\n",
      "Fold: 16  Epoch: 336  Training loss = 5.2787  Validation loss = 7.9473  \n",
      "\n",
      "Fold: 16  Epoch: 337  Training loss = 5.2781  Validation loss = 7.9465  \n",
      "\n",
      "Fold: 16  Epoch: 338  Training loss = 5.2774  Validation loss = 7.9454  \n",
      "\n",
      "Fold: 16  Epoch: 339  Training loss = 5.2767  Validation loss = 7.9445  \n",
      "\n",
      "Fold: 16  Epoch: 340  Training loss = 5.2761  Validation loss = 7.9438  \n",
      "\n",
      "Fold: 16  Epoch: 341  Training loss = 5.2754  Validation loss = 7.9428  \n",
      "\n",
      "Fold: 16  Epoch: 342  Training loss = 5.2748  Validation loss = 7.9420  \n",
      "\n",
      "Fold: 16  Epoch: 343  Training loss = 5.2740  Validation loss = 7.9411  \n",
      "\n",
      "Fold: 16  Epoch: 344  Training loss = 5.2734  Validation loss = 7.9402  \n",
      "\n",
      "Fold: 16  Epoch: 345  Training loss = 5.2727  Validation loss = 7.9393  \n",
      "\n",
      "Fold: 16  Epoch: 346  Training loss = 5.2719  Validation loss = 7.9384  \n",
      "\n",
      "Fold: 16  Epoch: 347  Training loss = 5.2713  Validation loss = 7.9375  \n",
      "\n",
      "Fold: 16  Epoch: 348  Training loss = 5.2706  Validation loss = 7.9364  \n",
      "\n",
      "Fold: 16  Epoch: 349  Training loss = 5.2698  Validation loss = 7.9354  \n",
      "\n",
      "Fold: 16  Epoch: 350  Training loss = 5.2692  Validation loss = 7.9346  \n",
      "\n",
      "Fold: 16  Epoch: 351  Training loss = 5.2686  Validation loss = 7.9337  \n",
      "\n",
      "Fold: 16  Epoch: 352  Training loss = 5.2681  Validation loss = 7.9330  \n",
      "\n",
      "Fold: 16  Epoch: 353  Training loss = 5.2674  Validation loss = 7.9319  \n",
      "\n",
      "Fold: 16  Epoch: 354  Training loss = 5.2668  Validation loss = 7.9310  \n",
      "\n",
      "Fold: 16  Epoch: 355  Training loss = 5.2661  Validation loss = 7.9302  \n",
      "\n",
      "Fold: 16  Epoch: 356  Training loss = 5.2654  Validation loss = 7.9292  \n",
      "\n",
      "Fold: 16  Epoch: 357  Training loss = 5.2647  Validation loss = 7.9282  \n",
      "\n",
      "Fold: 16  Epoch: 358  Training loss = 5.2641  Validation loss = 7.9275  \n",
      "\n",
      "Fold: 16  Epoch: 359  Training loss = 5.2635  Validation loss = 7.9265  \n",
      "\n",
      "Fold: 16  Epoch: 360  Training loss = 5.2630  Validation loss = 7.9258  \n",
      "\n",
      "Fold: 16  Epoch: 361  Training loss = 5.2624  Validation loss = 7.9249  \n",
      "\n",
      "Fold: 16  Epoch: 362  Training loss = 5.2618  Validation loss = 7.9241  \n",
      "\n",
      "Fold: 16  Epoch: 363  Training loss = 5.2611  Validation loss = 7.9230  \n",
      "\n",
      "Fold: 16  Epoch: 364  Training loss = 5.2604  Validation loss = 7.9221  \n",
      "\n",
      "Fold: 16  Epoch: 365  Training loss = 5.2598  Validation loss = 7.9212  \n",
      "\n",
      "Fold: 16  Epoch: 366  Training loss = 5.2592  Validation loss = 7.9204  \n",
      "\n",
      "Fold: 16  Epoch: 367  Training loss = 5.2587  Validation loss = 7.9194  \n",
      "\n",
      "Fold: 16  Epoch: 368  Training loss = 5.2580  Validation loss = 7.9185  \n",
      "\n",
      "Fold: 16  Epoch: 369  Training loss = 5.2572  Validation loss = 7.9173  \n",
      "\n",
      "Fold: 16  Epoch: 370  Training loss = 5.2567  Validation loss = 7.9165  \n",
      "\n",
      "Fold: 16  Epoch: 371  Training loss = 5.2559  Validation loss = 7.9154  \n",
      "\n",
      "Fold: 16  Epoch: 372  Training loss = 5.2553  Validation loss = 7.9146  \n",
      "\n",
      "Fold: 16  Epoch: 373  Training loss = 5.2547  Validation loss = 7.9136  \n",
      "\n",
      "Fold: 16  Epoch: 374  Training loss = 5.2539  Validation loss = 7.9124  \n",
      "\n",
      "Fold: 16  Epoch: 375  Training loss = 5.2534  Validation loss = 7.9118  \n",
      "\n",
      "Fold: 16  Epoch: 376  Training loss = 5.2529  Validation loss = 7.9112  \n",
      "\n",
      "Fold: 16  Epoch: 377  Training loss = 5.2523  Validation loss = 7.9102  \n",
      "\n",
      "Fold: 16  Epoch: 378  Training loss = 5.2518  Validation loss = 7.9097  \n",
      "\n",
      "Fold: 16  Epoch: 379  Training loss = 5.2512  Validation loss = 7.9088  \n",
      "\n",
      "Fold: 16  Epoch: 380  Training loss = 5.2506  Validation loss = 7.9078  \n",
      "\n",
      "Fold: 16  Epoch: 381  Training loss = 5.2500  Validation loss = 7.9069  \n",
      "\n",
      "Fold: 16  Epoch: 382  Training loss = 5.2493  Validation loss = 7.9060  \n",
      "\n",
      "Fold: 16  Epoch: 383  Training loss = 5.2487  Validation loss = 7.9052  \n",
      "\n",
      "Fold: 16  Epoch: 384  Training loss = 5.2481  Validation loss = 7.9040  \n",
      "\n",
      "Fold: 16  Epoch: 385  Training loss = 5.2474  Validation loss = 7.9032  \n",
      "\n",
      "Fold: 16  Epoch: 386  Training loss = 5.2467  Validation loss = 7.9022  \n",
      "\n",
      "Fold: 16  Epoch: 387  Training loss = 5.2459  Validation loss = 7.9008  \n",
      "\n",
      "Fold: 16  Epoch: 388  Training loss = 5.2453  Validation loss = 7.8998  \n",
      "\n",
      "Fold: 16  Epoch: 389  Training loss = 5.2447  Validation loss = 7.8990  \n",
      "\n",
      "Fold: 16  Epoch: 390  Training loss = 5.2439  Validation loss = 7.8980  \n",
      "\n",
      "Fold: 16  Epoch: 391  Training loss = 5.2432  Validation loss = 7.8972  \n",
      "\n",
      "Fold: 16  Epoch: 392  Training loss = 5.2425  Validation loss = 7.8961  \n",
      "\n",
      "Fold: 16  Epoch: 393  Training loss = 5.2417  Validation loss = 7.8950  \n",
      "\n",
      "Fold: 16  Epoch: 394  Training loss = 5.2410  Validation loss = 7.8939  \n",
      "\n",
      "Fold: 16  Epoch: 395  Training loss = 5.2403  Validation loss = 7.8929  \n",
      "\n",
      "Fold: 16  Epoch: 396  Training loss = 5.2395  Validation loss = 7.8919  \n",
      "\n",
      "Fold: 16  Epoch: 397  Training loss = 5.2388  Validation loss = 7.8908  \n",
      "\n",
      "Fold: 16  Epoch: 398  Training loss = 5.2381  Validation loss = 7.8900  \n",
      "\n",
      "Fold: 16  Epoch: 399  Training loss = 5.2375  Validation loss = 7.8891  \n",
      "\n",
      "Fold: 16  Epoch: 400  Training loss = 5.2367  Validation loss = 7.8881  \n",
      "\n",
      "Fold: 16  Epoch: 401  Training loss = 5.2361  Validation loss = 7.8874  \n",
      "\n",
      "Fold: 16  Epoch: 402  Training loss = 5.2355  Validation loss = 7.8866  \n",
      "\n",
      "Fold: 16  Epoch: 403  Training loss = 5.2349  Validation loss = 7.8857  \n",
      "\n",
      "Fold: 16  Epoch: 404  Training loss = 5.2341  Validation loss = 7.8846  \n",
      "\n",
      "Fold: 16  Epoch: 405  Training loss = 5.2335  Validation loss = 7.8840  \n",
      "\n",
      "Fold: 16  Epoch: 406  Training loss = 5.2330  Validation loss = 7.8832  \n",
      "\n",
      "Fold: 16  Epoch: 407  Training loss = 5.2321  Validation loss = 7.8817  \n",
      "\n",
      "Fold: 16  Epoch: 408  Training loss = 5.2315  Validation loss = 7.8809  \n",
      "\n",
      "Fold: 16  Epoch: 409  Training loss = 5.2308  Validation loss = 7.8800  \n",
      "\n",
      "Fold: 16  Epoch: 410  Training loss = 5.2302  Validation loss = 7.8791  \n",
      "\n",
      "Fold: 16  Epoch: 411  Training loss = 5.2294  Validation loss = 7.8779  \n",
      "\n",
      "Fold: 16  Epoch: 412  Training loss = 5.2288  Validation loss = 7.8771  \n",
      "\n",
      "Fold: 16  Epoch: 413  Training loss = 5.2280  Validation loss = 7.8762  \n",
      "\n",
      "Fold: 16  Epoch: 414  Training loss = 5.2273  Validation loss = 7.8750  \n",
      "\n",
      "Fold: 16  Epoch: 415  Training loss = 5.2266  Validation loss = 7.8739  \n",
      "\n",
      "Fold: 16  Epoch: 416  Training loss = 5.2260  Validation loss = 7.8730  \n",
      "\n",
      "Fold: 16  Epoch: 417  Training loss = 5.2254  Validation loss = 7.8720  \n",
      "\n",
      "Fold: 16  Epoch: 418  Training loss = 5.2248  Validation loss = 7.8712  \n",
      "\n",
      "Fold: 16  Epoch: 419  Training loss = 5.2242  Validation loss = 7.8703  \n",
      "\n",
      "Fold: 16  Epoch: 420  Training loss = 5.2235  Validation loss = 7.8693  \n",
      "\n",
      "Fold: 16  Epoch: 421  Training loss = 5.2230  Validation loss = 7.8685  \n",
      "\n",
      "Fold: 16  Epoch: 422  Training loss = 5.2223  Validation loss = 7.8676  \n",
      "\n",
      "Fold: 16  Epoch: 423  Training loss = 5.2216  Validation loss = 7.8663  \n",
      "\n",
      "Fold: 16  Epoch: 424  Training loss = 5.2210  Validation loss = 7.8655  \n",
      "\n",
      "Fold: 16  Epoch: 425  Training loss = 5.2203  Validation loss = 7.8646  \n",
      "\n",
      "Fold: 16  Epoch: 426  Training loss = 5.2197  Validation loss = 7.8637  \n",
      "\n",
      "Fold: 16  Epoch: 427  Training loss = 5.2190  Validation loss = 7.8629  \n",
      "\n",
      "Fold: 16  Epoch: 428  Training loss = 5.2183  Validation loss = 7.8619  \n",
      "\n",
      "Fold: 16  Epoch: 429  Training loss = 5.2177  Validation loss = 7.8611  \n",
      "\n",
      "Fold: 16  Epoch: 430  Training loss = 5.2171  Validation loss = 7.8603  \n",
      "\n",
      "Fold: 16  Epoch: 431  Training loss = 5.2167  Validation loss = 7.8597  \n",
      "\n",
      "Fold: 16  Epoch: 432  Training loss = 5.2160  Validation loss = 7.8587  \n",
      "\n",
      "Fold: 16  Epoch: 433  Training loss = 5.2153  Validation loss = 7.8577  \n",
      "\n",
      "Fold: 16  Epoch: 434  Training loss = 5.2146  Validation loss = 7.8569  \n",
      "\n",
      "Fold: 16  Epoch: 435  Training loss = 5.2140  Validation loss = 7.8559  \n",
      "\n",
      "Fold: 16  Epoch: 436  Training loss = 5.2134  Validation loss = 7.8550  \n",
      "\n",
      "Fold: 16  Epoch: 437  Training loss = 5.2127  Validation loss = 7.8542  \n",
      "\n",
      "Fold: 16  Epoch: 438  Training loss = 5.2122  Validation loss = 7.8534  \n",
      "\n",
      "Fold: 16  Epoch: 439  Training loss = 5.2115  Validation loss = 7.8525  \n",
      "\n",
      "Fold: 16  Epoch: 440  Training loss = 5.2109  Validation loss = 7.8514  \n",
      "\n",
      "Fold: 16  Epoch: 441  Training loss = 5.2102  Validation loss = 7.8505  \n",
      "\n",
      "Fold: 16  Epoch: 442  Training loss = 5.2096  Validation loss = 7.8496  \n",
      "\n",
      "Fold: 16  Epoch: 443  Training loss = 5.2090  Validation loss = 7.8488  \n",
      "\n",
      "Fold: 16  Epoch: 444  Training loss = 5.2083  Validation loss = 7.8479  \n",
      "\n",
      "Fold: 16  Epoch: 445  Training loss = 5.2076  Validation loss = 7.8469  \n",
      "\n",
      "Fold: 16  Epoch: 446  Training loss = 5.2070  Validation loss = 7.8460  \n",
      "\n",
      "Fold: 16  Epoch: 447  Training loss = 5.2065  Validation loss = 7.8454  \n",
      "\n",
      "Fold: 16  Epoch: 448  Training loss = 5.2061  Validation loss = 7.8448  \n",
      "\n",
      "Fold: 16  Epoch: 449  Training loss = 5.2054  Validation loss = 7.8440  \n",
      "\n",
      "Fold: 16  Epoch: 450  Training loss = 5.2048  Validation loss = 7.8430  \n",
      "\n",
      "Fold: 16  Epoch: 451  Training loss = 5.2041  Validation loss = 7.8421  \n",
      "\n",
      "Fold: 16  Epoch: 452  Training loss = 5.2034  Validation loss = 7.8410  \n",
      "\n",
      "Fold: 16  Epoch: 453  Training loss = 5.2027  Validation loss = 7.8401  \n",
      "\n",
      "Fold: 16  Epoch: 454  Training loss = 5.2021  Validation loss = 7.8390  \n",
      "\n",
      "Fold: 16  Epoch: 455  Training loss = 5.2014  Validation loss = 7.8382  \n",
      "\n",
      "Fold: 16  Epoch: 456  Training loss = 5.2009  Validation loss = 7.8374  \n",
      "\n",
      "Fold: 16  Epoch: 457  Training loss = 5.2003  Validation loss = 7.8367  \n",
      "\n",
      "Fold: 16  Epoch: 458  Training loss = 5.1997  Validation loss = 7.8359  \n",
      "\n",
      "Fold: 16  Epoch: 459  Training loss = 5.1990  Validation loss = 7.8349  \n",
      "\n",
      "Fold: 16  Epoch: 460  Training loss = 5.1984  Validation loss = 7.8341  \n",
      "\n",
      "Fold: 16  Epoch: 461  Training loss = 5.1979  Validation loss = 7.8334  \n",
      "\n",
      "Fold: 16  Epoch: 462  Training loss = 5.1972  Validation loss = 7.8323  \n",
      "\n",
      "Fold: 16  Epoch: 463  Training loss = 5.1965  Validation loss = 7.8313  \n",
      "\n",
      "Fold: 16  Epoch: 464  Training loss = 5.1958  Validation loss = 7.8304  \n",
      "\n",
      "Fold: 16  Epoch: 465  Training loss = 5.1953  Validation loss = 7.8298  \n",
      "\n",
      "Fold: 16  Epoch: 466  Training loss = 5.1947  Validation loss = 7.8290  \n",
      "\n",
      "Fold: 16  Epoch: 467  Training loss = 5.1941  Validation loss = 7.8282  \n",
      "\n",
      "Fold: 16  Epoch: 468  Training loss = 5.1935  Validation loss = 7.8271  \n",
      "\n",
      "Fold: 16  Epoch: 469  Training loss = 5.1928  Validation loss = 7.8262  \n",
      "\n",
      "Fold: 16  Epoch: 470  Training loss = 5.1921  Validation loss = 7.8252  \n",
      "\n",
      "Fold: 16  Epoch: 471  Training loss = 5.1914  Validation loss = 7.8243  \n",
      "\n",
      "Fold: 16  Epoch: 472  Training loss = 5.1908  Validation loss = 7.8233  \n",
      "\n",
      "Fold: 16  Epoch: 473  Training loss = 5.1901  Validation loss = 7.8224  \n",
      "\n",
      "Fold: 16  Epoch: 474  Training loss = 5.1895  Validation loss = 7.8217  \n",
      "\n",
      "Fold: 16  Epoch: 475  Training loss = 5.1890  Validation loss = 7.8211  \n",
      "\n",
      "Fold: 16  Epoch: 476  Training loss = 5.1885  Validation loss = 7.8203  \n",
      "\n",
      "Fold: 16  Epoch: 477  Training loss = 5.1879  Validation loss = 7.8194  \n",
      "\n",
      "Fold: 16  Epoch: 478  Training loss = 5.1872  Validation loss = 7.8185  \n",
      "\n",
      "Fold: 16  Epoch: 479  Training loss = 5.1865  Validation loss = 7.8175  \n",
      "\n",
      "Fold: 16  Epoch: 480  Training loss = 5.1859  Validation loss = 7.8165  \n",
      "\n",
      "Fold: 16  Epoch: 481  Training loss = 5.1853  Validation loss = 7.8158  \n",
      "\n",
      "Fold: 16  Epoch: 482  Training loss = 5.1846  Validation loss = 7.8148  \n",
      "\n",
      "Fold: 16  Epoch: 483  Training loss = 5.1839  Validation loss = 7.8138  \n",
      "\n",
      "Fold: 16  Epoch: 484  Training loss = 5.1833  Validation loss = 7.8129  \n",
      "\n",
      "Fold: 16  Epoch: 485  Training loss = 5.1826  Validation loss = 7.8121  \n",
      "\n",
      "Fold: 16  Epoch: 486  Training loss = 5.1822  Validation loss = 7.8115  \n",
      "\n",
      "Fold: 16  Epoch: 487  Training loss = 5.1815  Validation loss = 7.8106  \n",
      "\n",
      "Fold: 16  Epoch: 488  Training loss = 5.1809  Validation loss = 7.8097  \n",
      "\n",
      "Fold: 16  Epoch: 489  Training loss = 5.1803  Validation loss = 7.8088  \n",
      "\n",
      "Fold: 16  Epoch: 490  Training loss = 5.1796  Validation loss = 7.8077  \n",
      "\n",
      "Fold: 16  Epoch: 491  Training loss = 5.1789  Validation loss = 7.8065  \n",
      "\n",
      "Fold: 16  Epoch: 492  Training loss = 5.1784  Validation loss = 7.8056  \n",
      "\n",
      "Fold: 16  Epoch: 493  Training loss = 5.1777  Validation loss = 7.8048  \n",
      "\n",
      "Fold: 16  Epoch: 494  Training loss = 5.1771  Validation loss = 7.8039  \n",
      "\n",
      "Fold: 16  Epoch: 495  Training loss = 5.1765  Validation loss = 7.8032  \n",
      "\n",
      "Fold: 16  Epoch: 496  Training loss = 5.1757  Validation loss = 7.8018  \n",
      "\n",
      "Fold: 16  Epoch: 497  Training loss = 5.1751  Validation loss = 7.8009  \n",
      "\n",
      "Fold: 16  Epoch: 498  Training loss = 5.1744  Validation loss = 7.7999  \n",
      "\n",
      "Fold: 16  Epoch: 499  Training loss = 5.1738  Validation loss = 7.7990  \n",
      "\n",
      "Fold: 16  Epoch: 500  Training loss = 5.1730  Validation loss = 7.7978  \n",
      "\n",
      "Check model:  Fold: 16  Optimal epoch: 500  \n",
      "\n",
      "Fold: 17  Epoch: 1  Training loss = 5.5185  Validation loss = 3.3060  \n",
      "\n",
      "Fold: 17  Epoch: 2  Training loss = 5.5177  Validation loss = 3.3057  \n",
      "\n",
      "Fold: 17  Epoch: 3  Training loss = 5.5167  Validation loss = 3.3052  \n",
      "\n",
      "Fold: 17  Epoch: 4  Training loss = 5.5159  Validation loss = 3.3048  \n",
      "\n",
      "Fold: 17  Epoch: 5  Training loss = 5.5153  Validation loss = 3.3045  \n",
      "\n",
      "Fold: 17  Epoch: 6  Training loss = 5.5144  Validation loss = 3.3041  \n",
      "\n",
      "Fold: 17  Epoch: 7  Training loss = 5.5136  Validation loss = 3.3037  \n",
      "\n",
      "Fold: 17  Epoch: 8  Training loss = 5.5127  Validation loss = 3.3033  \n",
      "\n",
      "Fold: 17  Epoch: 9  Training loss = 5.5120  Validation loss = 3.3029  \n",
      "\n",
      "Fold: 17  Epoch: 10  Training loss = 5.5114  Validation loss = 3.3026  \n",
      "\n",
      "Fold: 17  Epoch: 11  Training loss = 5.5106  Validation loss = 3.3023  \n",
      "\n",
      "Fold: 17  Epoch: 12  Training loss = 5.5098  Validation loss = 3.3019  \n",
      "\n",
      "Fold: 17  Epoch: 13  Training loss = 5.5090  Validation loss = 3.3016  \n",
      "\n",
      "Fold: 17  Epoch: 14  Training loss = 5.5081  Validation loss = 3.3012  \n",
      "\n",
      "Fold: 17  Epoch: 15  Training loss = 5.5073  Validation loss = 3.3008  \n",
      "\n",
      "Fold: 17  Epoch: 16  Training loss = 5.5064  Validation loss = 3.3005  \n",
      "\n",
      "Fold: 17  Epoch: 17  Training loss = 5.5055  Validation loss = 3.3001  \n",
      "\n",
      "Fold: 17  Epoch: 18  Training loss = 5.5046  Validation loss = 3.2997  \n",
      "\n",
      "Fold: 17  Epoch: 19  Training loss = 5.5036  Validation loss = 3.2993  \n",
      "\n",
      "Fold: 17  Epoch: 20  Training loss = 5.5028  Validation loss = 3.2989  \n",
      "\n",
      "Fold: 17  Epoch: 21  Training loss = 5.5019  Validation loss = 3.2985  \n",
      "\n",
      "Fold: 17  Epoch: 22  Training loss = 5.5013  Validation loss = 3.2982  \n",
      "\n",
      "Fold: 17  Epoch: 23  Training loss = 5.5005  Validation loss = 3.2978  \n",
      "\n",
      "Fold: 17  Epoch: 24  Training loss = 5.4997  Validation loss = 3.2975  \n",
      "\n",
      "Fold: 17  Epoch: 25  Training loss = 5.4988  Validation loss = 3.2971  \n",
      "\n",
      "Fold: 17  Epoch: 26  Training loss = 5.4979  Validation loss = 3.2968  \n",
      "\n",
      "Fold: 17  Epoch: 27  Training loss = 5.4970  Validation loss = 3.2964  \n",
      "\n",
      "Fold: 17  Epoch: 28  Training loss = 5.4961  Validation loss = 3.2960  \n",
      "\n",
      "Fold: 17  Epoch: 29  Training loss = 5.4953  Validation loss = 3.2956  \n",
      "\n",
      "Fold: 17  Epoch: 30  Training loss = 5.4945  Validation loss = 3.2953  \n",
      "\n",
      "Fold: 17  Epoch: 31  Training loss = 5.4940  Validation loss = 3.2950  \n",
      "\n",
      "Fold: 17  Epoch: 32  Training loss = 5.4932  Validation loss = 3.2947  \n",
      "\n",
      "Fold: 17  Epoch: 33  Training loss = 5.4924  Validation loss = 3.2943  \n",
      "\n",
      "Fold: 17  Epoch: 34  Training loss = 5.4915  Validation loss = 3.2939  \n",
      "\n",
      "Fold: 17  Epoch: 35  Training loss = 5.4906  Validation loss = 3.2935  \n",
      "\n",
      "Fold: 17  Epoch: 36  Training loss = 5.4896  Validation loss = 3.2931  \n",
      "\n",
      "Fold: 17  Epoch: 37  Training loss = 5.4886  Validation loss = 3.2927  \n",
      "\n",
      "Fold: 17  Epoch: 38  Training loss = 5.4877  Validation loss = 3.2924  \n",
      "\n",
      "Fold: 17  Epoch: 39  Training loss = 5.4871  Validation loss = 3.2921  \n",
      "\n",
      "Fold: 17  Epoch: 40  Training loss = 5.4863  Validation loss = 3.2917  \n",
      "\n",
      "Fold: 17  Epoch: 41  Training loss = 5.4855  Validation loss = 3.2913  \n",
      "\n",
      "Fold: 17  Epoch: 42  Training loss = 5.4846  Validation loss = 3.2910  \n",
      "\n",
      "Fold: 17  Epoch: 43  Training loss = 5.4835  Validation loss = 3.2905  \n",
      "\n",
      "Fold: 17  Epoch: 44  Training loss = 5.4826  Validation loss = 3.2901  \n",
      "\n",
      "Fold: 17  Epoch: 45  Training loss = 5.4819  Validation loss = 3.2897  \n",
      "\n",
      "Fold: 17  Epoch: 46  Training loss = 5.4809  Validation loss = 3.2893  \n",
      "\n",
      "Fold: 17  Epoch: 47  Training loss = 5.4801  Validation loss = 3.2889  \n",
      "\n",
      "Fold: 17  Epoch: 48  Training loss = 5.4792  Validation loss = 3.2885  \n",
      "\n",
      "Fold: 17  Epoch: 49  Training loss = 5.4783  Validation loss = 3.2881  \n",
      "\n",
      "Fold: 17  Epoch: 50  Training loss = 5.4775  Validation loss = 3.2877  \n",
      "\n",
      "Fold: 17  Epoch: 51  Training loss = 5.4765  Validation loss = 3.2873  \n",
      "\n",
      "Fold: 17  Epoch: 52  Training loss = 5.4756  Validation loss = 3.2869  \n",
      "\n",
      "Fold: 17  Epoch: 53  Training loss = 5.4747  Validation loss = 3.2864  \n",
      "\n",
      "Fold: 17  Epoch: 54  Training loss = 5.4739  Validation loss = 3.2860  \n",
      "\n",
      "Fold: 17  Epoch: 55  Training loss = 5.4730  Validation loss = 3.2856  \n",
      "\n",
      "Fold: 17  Epoch: 56  Training loss = 5.4720  Validation loss = 3.2851  \n",
      "\n",
      "Fold: 17  Epoch: 57  Training loss = 5.4712  Validation loss = 3.2849  \n",
      "\n",
      "Fold: 17  Epoch: 58  Training loss = 5.4704  Validation loss = 3.2845  \n",
      "\n",
      "Fold: 17  Epoch: 59  Training loss = 5.4697  Validation loss = 3.2841  \n",
      "\n",
      "Fold: 17  Epoch: 60  Training loss = 5.4686  Validation loss = 3.2837  \n",
      "\n",
      "Fold: 17  Epoch: 61  Training loss = 5.4678  Validation loss = 3.2833  \n",
      "\n",
      "Fold: 17  Epoch: 62  Training loss = 5.4669  Validation loss = 3.2829  \n",
      "\n",
      "Fold: 17  Epoch: 63  Training loss = 5.4661  Validation loss = 3.2826  \n",
      "\n",
      "Fold: 17  Epoch: 64  Training loss = 5.4652  Validation loss = 3.2822  \n",
      "\n",
      "Fold: 17  Epoch: 65  Training loss = 5.4642  Validation loss = 3.2819  \n",
      "\n",
      "Fold: 17  Epoch: 66  Training loss = 5.4632  Validation loss = 3.2815  \n",
      "\n",
      "Fold: 17  Epoch: 67  Training loss = 5.4622  Validation loss = 3.2811  \n",
      "\n",
      "Fold: 17  Epoch: 68  Training loss = 5.4614  Validation loss = 3.2807  \n",
      "\n",
      "Fold: 17  Epoch: 69  Training loss = 5.4605  Validation loss = 3.2803  \n",
      "\n",
      "Fold: 17  Epoch: 70  Training loss = 5.4592  Validation loss = 3.2798  \n",
      "\n",
      "Fold: 17  Epoch: 71  Training loss = 5.4582  Validation loss = 3.2794  \n",
      "\n",
      "Fold: 17  Epoch: 72  Training loss = 5.4575  Validation loss = 3.2790  \n",
      "\n",
      "Fold: 17  Epoch: 73  Training loss = 5.4564  Validation loss = 3.2786  \n",
      "\n",
      "Fold: 17  Epoch: 74  Training loss = 5.4553  Validation loss = 3.2782  \n",
      "\n",
      "Fold: 17  Epoch: 75  Training loss = 5.4540  Validation loss = 3.2777  \n",
      "\n",
      "Fold: 17  Epoch: 76  Training loss = 5.4530  Validation loss = 3.2772  \n",
      "\n",
      "Fold: 17  Epoch: 77  Training loss = 5.4521  Validation loss = 3.2769  \n",
      "\n",
      "Fold: 17  Epoch: 78  Training loss = 5.4511  Validation loss = 3.2764  \n",
      "\n",
      "Fold: 17  Epoch: 79  Training loss = 5.4500  Validation loss = 3.2760  \n",
      "\n",
      "Fold: 17  Epoch: 80  Training loss = 5.4491  Validation loss = 3.2756  \n",
      "\n",
      "Fold: 17  Epoch: 81  Training loss = 5.4479  Validation loss = 3.2751  \n",
      "\n",
      "Fold: 17  Epoch: 82  Training loss = 5.4468  Validation loss = 3.2747  \n",
      "\n",
      "Fold: 17  Epoch: 83  Training loss = 5.4458  Validation loss = 3.2743  \n",
      "\n",
      "Fold: 17  Epoch: 84  Training loss = 5.4449  Validation loss = 3.2739  \n",
      "\n",
      "Fold: 17  Epoch: 85  Training loss = 5.4438  Validation loss = 3.2735  \n",
      "\n",
      "Fold: 17  Epoch: 86  Training loss = 5.4428  Validation loss = 3.2732  \n",
      "\n",
      "Fold: 17  Epoch: 87  Training loss = 5.4418  Validation loss = 3.2727  \n",
      "\n",
      "Fold: 17  Epoch: 88  Training loss = 5.4412  Validation loss = 3.2725  \n",
      "\n",
      "Fold: 17  Epoch: 89  Training loss = 5.4393  Validation loss = 3.2720  \n",
      "\n",
      "Fold: 17  Epoch: 90  Training loss = 5.4370  Validation loss = 3.2716  \n",
      "\n",
      "Fold: 17  Epoch: 91  Training loss = 5.4297  Validation loss = 3.2713  \n",
      "\n",
      "Fold: 17  Epoch: 92  Training loss = 5.4285  Validation loss = 3.2709  \n",
      "\n",
      "Fold: 17  Epoch: 93  Training loss = 5.4273  Validation loss = 3.2706  \n",
      "\n",
      "Fold: 17  Epoch: 94  Training loss = 5.4261  Validation loss = 3.2701  \n",
      "\n",
      "Fold: 17  Epoch: 95  Training loss = 5.4250  Validation loss = 3.2697  \n",
      "\n",
      "Fold: 17  Epoch: 96  Training loss = 5.4240  Validation loss = 3.2693  \n",
      "\n",
      "Fold: 17  Epoch: 97  Training loss = 5.4229  Validation loss = 3.2689  \n",
      "\n",
      "Fold: 17  Epoch: 98  Training loss = 5.4217  Validation loss = 3.2684  \n",
      "\n",
      "Fold: 17  Epoch: 99  Training loss = 5.4208  Validation loss = 3.2680  \n",
      "\n",
      "Fold: 17  Epoch: 100  Training loss = 5.4199  Validation loss = 3.2677  \n",
      "\n",
      "Fold: 17  Epoch: 101  Training loss = 5.4190  Validation loss = 3.2674  \n",
      "\n",
      "Fold: 17  Epoch: 102  Training loss = 5.4181  Validation loss = 3.2670  \n",
      "\n",
      "Fold: 17  Epoch: 103  Training loss = 5.4171  Validation loss = 3.2666  \n",
      "\n",
      "Fold: 17  Epoch: 104  Training loss = 5.4161  Validation loss = 3.2662  \n",
      "\n",
      "Fold: 17  Epoch: 105  Training loss = 5.4154  Validation loss = 3.2658  \n",
      "\n",
      "Fold: 17  Epoch: 106  Training loss = 5.4143  Validation loss = 3.2654  \n",
      "\n",
      "Fold: 17  Epoch: 107  Training loss = 5.4134  Validation loss = 3.2651  \n",
      "\n",
      "Fold: 17  Epoch: 108  Training loss = 5.4126  Validation loss = 3.2647  \n",
      "\n",
      "Fold: 17  Epoch: 109  Training loss = 5.4116  Validation loss = 3.2643  \n",
      "\n",
      "Fold: 17  Epoch: 110  Training loss = 5.4105  Validation loss = 3.2639  \n",
      "\n",
      "Fold: 17  Epoch: 111  Training loss = 5.4097  Validation loss = 3.2636  \n",
      "\n",
      "Fold: 17  Epoch: 112  Training loss = 5.4088  Validation loss = 3.2631  \n",
      "\n",
      "Fold: 17  Epoch: 113  Training loss = 5.4079  Validation loss = 3.2628  \n",
      "\n",
      "Fold: 17  Epoch: 114  Training loss = 5.4071  Validation loss = 3.2625  \n",
      "\n",
      "Fold: 17  Epoch: 115  Training loss = 5.4058  Validation loss = 3.2621  \n",
      "\n",
      "Fold: 17  Epoch: 116  Training loss = 5.4051  Validation loss = 3.2617  \n",
      "\n",
      "Fold: 17  Epoch: 117  Training loss = 5.4044  Validation loss = 3.2614  \n",
      "\n",
      "Fold: 17  Epoch: 118  Training loss = 5.4036  Validation loss = 3.2611  \n",
      "\n",
      "Fold: 17  Epoch: 119  Training loss = 5.4029  Validation loss = 3.2607  \n",
      "\n",
      "Fold: 17  Epoch: 120  Training loss = 5.4018  Validation loss = 3.2603  \n",
      "\n",
      "Fold: 17  Epoch: 121  Training loss = 5.4010  Validation loss = 3.2599  \n",
      "\n",
      "Fold: 17  Epoch: 122  Training loss = 5.4001  Validation loss = 3.2596  \n",
      "\n",
      "Fold: 17  Epoch: 123  Training loss = 5.3991  Validation loss = 3.2592  \n",
      "\n",
      "Fold: 17  Epoch: 124  Training loss = 5.3984  Validation loss = 3.2588  \n",
      "\n",
      "Fold: 17  Epoch: 125  Training loss = 5.3975  Validation loss = 3.2584  \n",
      "\n",
      "Fold: 17  Epoch: 126  Training loss = 5.3968  Validation loss = 3.2581  \n",
      "\n",
      "Fold: 17  Epoch: 127  Training loss = 5.3959  Validation loss = 3.2577  \n",
      "\n",
      "Fold: 17  Epoch: 128  Training loss = 5.3949  Validation loss = 3.2574  \n",
      "\n",
      "Fold: 17  Epoch: 129  Training loss = 5.3937  Validation loss = 3.2569  \n",
      "\n",
      "Fold: 17  Epoch: 130  Training loss = 5.3927  Validation loss = 3.2565  \n",
      "\n",
      "Fold: 17  Epoch: 131  Training loss = 5.3915  Validation loss = 3.2561  \n",
      "\n",
      "Fold: 17  Epoch: 132  Training loss = 5.3907  Validation loss = 3.2557  \n",
      "\n",
      "Fold: 17  Epoch: 133  Training loss = 5.3898  Validation loss = 3.2553  \n",
      "\n",
      "Fold: 17  Epoch: 134  Training loss = 5.3890  Validation loss = 3.2550  \n",
      "\n",
      "Fold: 17  Epoch: 135  Training loss = 5.3880  Validation loss = 3.2546  \n",
      "\n",
      "Fold: 17  Epoch: 136  Training loss = 5.3874  Validation loss = 3.2543  \n",
      "\n",
      "Fold: 17  Epoch: 137  Training loss = 5.3865  Validation loss = 3.2540  \n",
      "\n",
      "Fold: 17  Epoch: 138  Training loss = 5.3857  Validation loss = 3.2537  \n",
      "\n",
      "Fold: 17  Epoch: 139  Training loss = 5.3845  Validation loss = 3.2532  \n",
      "\n",
      "Fold: 17  Epoch: 140  Training loss = 5.3837  Validation loss = 3.2529  \n",
      "\n",
      "Fold: 17  Epoch: 141  Training loss = 5.3828  Validation loss = 3.2525  \n",
      "\n",
      "Fold: 17  Epoch: 142  Training loss = 5.3821  Validation loss = 3.2522  \n",
      "\n",
      "Fold: 17  Epoch: 143  Training loss = 5.3813  Validation loss = 3.2518  \n",
      "\n",
      "Fold: 17  Epoch: 144  Training loss = 5.3805  Validation loss = 3.2515  \n",
      "\n",
      "Fold: 17  Epoch: 145  Training loss = 5.3797  Validation loss = 3.2511  \n",
      "\n",
      "Fold: 17  Epoch: 146  Training loss = 5.3788  Validation loss = 3.2508  \n",
      "\n",
      "Fold: 17  Epoch: 147  Training loss = 5.3781  Validation loss = 3.2505  \n",
      "\n",
      "Fold: 17  Epoch: 148  Training loss = 5.3772  Validation loss = 3.2501  \n",
      "\n",
      "Fold: 17  Epoch: 149  Training loss = 5.3765  Validation loss = 3.2498  \n",
      "\n",
      "Fold: 17  Epoch: 150  Training loss = 5.3757  Validation loss = 3.2495  \n",
      "\n",
      "Fold: 17  Epoch: 151  Training loss = 5.3750  Validation loss = 3.2492  \n",
      "\n",
      "Fold: 17  Epoch: 152  Training loss = 5.3742  Validation loss = 3.2488  \n",
      "\n",
      "Fold: 17  Epoch: 153  Training loss = 5.3735  Validation loss = 3.2485  \n",
      "\n",
      "Fold: 17  Epoch: 154  Training loss = 5.3729  Validation loss = 3.2482  \n",
      "\n",
      "Fold: 17  Epoch: 155  Training loss = 5.3721  Validation loss = 3.2478  \n",
      "\n",
      "Fold: 17  Epoch: 156  Training loss = 5.3713  Validation loss = 3.2475  \n",
      "\n",
      "Fold: 17  Epoch: 157  Training loss = 5.3705  Validation loss = 3.2472  \n",
      "\n",
      "Fold: 17  Epoch: 158  Training loss = 5.3696  Validation loss = 3.2468  \n",
      "\n",
      "Fold: 17  Epoch: 159  Training loss = 5.3688  Validation loss = 3.2465  \n",
      "\n",
      "Fold: 17  Epoch: 160  Training loss = 5.3679  Validation loss = 3.2461  \n",
      "\n",
      "Fold: 17  Epoch: 161  Training loss = 5.3672  Validation loss = 3.2458  \n",
      "\n",
      "Fold: 17  Epoch: 162  Training loss = 5.3665  Validation loss = 3.2455  \n",
      "\n",
      "Fold: 17  Epoch: 163  Training loss = 5.3655  Validation loss = 3.2451  \n",
      "\n",
      "Fold: 17  Epoch: 164  Training loss = 5.3649  Validation loss = 3.2449  \n",
      "\n",
      "Fold: 17  Epoch: 165  Training loss = 5.3641  Validation loss = 3.2445  \n",
      "\n",
      "Fold: 17  Epoch: 166  Training loss = 5.3633  Validation loss = 3.2442  \n",
      "\n",
      "Fold: 17  Epoch: 167  Training loss = 5.3625  Validation loss = 3.2438  \n",
      "\n",
      "Fold: 17  Epoch: 168  Training loss = 5.3616  Validation loss = 3.2435  \n",
      "\n",
      "Fold: 17  Epoch: 169  Training loss = 5.3606  Validation loss = 3.2430  \n",
      "\n",
      "Fold: 17  Epoch: 170  Training loss = 5.3597  Validation loss = 3.2427  \n",
      "\n",
      "Fold: 17  Epoch: 171  Training loss = 5.3588  Validation loss = 3.2423  \n",
      "\n",
      "Fold: 17  Epoch: 172  Training loss = 5.3578  Validation loss = 3.2419  \n",
      "\n",
      "Fold: 17  Epoch: 173  Training loss = 5.3571  Validation loss = 3.2415  \n",
      "\n",
      "Fold: 17  Epoch: 174  Training loss = 5.3563  Validation loss = 3.2412  \n",
      "\n",
      "Fold: 17  Epoch: 175  Training loss = 5.3553  Validation loss = 3.2408  \n",
      "\n",
      "Fold: 17  Epoch: 176  Training loss = 5.3547  Validation loss = 3.2405  \n",
      "\n",
      "Fold: 17  Epoch: 177  Training loss = 5.3538  Validation loss = 3.2402  \n",
      "\n",
      "Fold: 17  Epoch: 178  Training loss = 5.3529  Validation loss = 3.2398  \n",
      "\n",
      "Fold: 17  Epoch: 179  Training loss = 5.3520  Validation loss = 3.2395  \n",
      "\n",
      "Fold: 17  Epoch: 180  Training loss = 5.3514  Validation loss = 3.2391  \n",
      "\n",
      "Fold: 17  Epoch: 181  Training loss = 5.3506  Validation loss = 3.2387  \n",
      "\n",
      "Fold: 17  Epoch: 182  Training loss = 5.3498  Validation loss = 3.2384  \n",
      "\n",
      "Fold: 17  Epoch: 183  Training loss = 5.3490  Validation loss = 3.2380  \n",
      "\n",
      "Fold: 17  Epoch: 184  Training loss = 5.3482  Validation loss = 3.2377  \n",
      "\n",
      "Fold: 17  Epoch: 185  Training loss = 5.3476  Validation loss = 3.2374  \n",
      "\n",
      "Fold: 17  Epoch: 186  Training loss = 5.3468  Validation loss = 3.2370  \n",
      "\n",
      "Fold: 17  Epoch: 187  Training loss = 5.3460  Validation loss = 3.2367  \n",
      "\n",
      "Fold: 17  Epoch: 188  Training loss = 5.3451  Validation loss = 3.2363  \n",
      "\n",
      "Fold: 17  Epoch: 189  Training loss = 5.3445  Validation loss = 3.2360  \n",
      "\n",
      "Fold: 17  Epoch: 190  Training loss = 5.3437  Validation loss = 3.2357  \n",
      "\n",
      "Fold: 17  Epoch: 191  Training loss = 5.3430  Validation loss = 3.2354  \n",
      "\n",
      "Fold: 17  Epoch: 192  Training loss = 5.3424  Validation loss = 3.2351  \n",
      "\n",
      "Fold: 17  Epoch: 193  Training loss = 5.3416  Validation loss = 3.2347  \n",
      "\n",
      "Fold: 17  Epoch: 194  Training loss = 5.3408  Validation loss = 3.2343  \n",
      "\n",
      "Fold: 17  Epoch: 195  Training loss = 5.3400  Validation loss = 3.2340  \n",
      "\n",
      "Fold: 17  Epoch: 196  Training loss = 5.3393  Validation loss = 3.2337  \n",
      "\n",
      "Fold: 17  Epoch: 197  Training loss = 5.3386  Validation loss = 3.2333  \n",
      "\n",
      "Fold: 17  Epoch: 198  Training loss = 5.3378  Validation loss = 3.2330  \n",
      "\n",
      "Fold: 17  Epoch: 199  Training loss = 5.3371  Validation loss = 3.2326  \n",
      "\n",
      "Fold: 17  Epoch: 200  Training loss = 5.3362  Validation loss = 3.2322  \n",
      "\n",
      "Fold: 17  Epoch: 201  Training loss = 5.3354  Validation loss = 3.2318  \n",
      "\n",
      "Fold: 17  Epoch: 202  Training loss = 5.3347  Validation loss = 3.2315  \n",
      "\n",
      "Fold: 17  Epoch: 203  Training loss = 5.3339  Validation loss = 3.2311  \n",
      "\n",
      "Fold: 17  Epoch: 204  Training loss = 5.3332  Validation loss = 3.2308  \n",
      "\n",
      "Fold: 17  Epoch: 205  Training loss = 5.3323  Validation loss = 3.2305  \n",
      "\n",
      "Fold: 17  Epoch: 206  Training loss = 5.3316  Validation loss = 3.2301  \n",
      "\n",
      "Fold: 17  Epoch: 207  Training loss = 5.3309  Validation loss = 3.2298  \n",
      "\n",
      "Fold: 17  Epoch: 208  Training loss = 5.3301  Validation loss = 3.2294  \n",
      "\n",
      "Fold: 17  Epoch: 209  Training loss = 5.3294  Validation loss = 3.2291  \n",
      "\n",
      "Fold: 17  Epoch: 210  Training loss = 5.3286  Validation loss = 3.2287  \n",
      "\n",
      "Fold: 17  Epoch: 211  Training loss = 5.3278  Validation loss = 3.2284  \n",
      "\n",
      "Fold: 17  Epoch: 212  Training loss = 5.3270  Validation loss = 3.2280  \n",
      "\n",
      "Fold: 17  Epoch: 213  Training loss = 5.3262  Validation loss = 3.2276  \n",
      "\n",
      "Fold: 17  Epoch: 214  Training loss = 5.3256  Validation loss = 3.2273  \n",
      "\n",
      "Fold: 17  Epoch: 215  Training loss = 5.3247  Validation loss = 3.2269  \n",
      "\n",
      "Fold: 17  Epoch: 216  Training loss = 5.3240  Validation loss = 3.2266  \n",
      "\n",
      "Fold: 17  Epoch: 217  Training loss = 5.3233  Validation loss = 3.2262  \n",
      "\n",
      "Fold: 17  Epoch: 218  Training loss = 5.3226  Validation loss = 3.2259  \n",
      "\n",
      "Fold: 17  Epoch: 219  Training loss = 5.3216  Validation loss = 3.2255  \n",
      "\n",
      "Fold: 17  Epoch: 220  Training loss = 5.3210  Validation loss = 3.2252  \n",
      "\n",
      "Fold: 17  Epoch: 221  Training loss = 5.3203  Validation loss = 3.2249  \n",
      "\n",
      "Fold: 17  Epoch: 222  Training loss = 5.3196  Validation loss = 3.2246  \n",
      "\n",
      "Fold: 17  Epoch: 223  Training loss = 5.3190  Validation loss = 3.2243  \n",
      "\n",
      "Fold: 17  Epoch: 224  Training loss = 5.3184  Validation loss = 3.2240  \n",
      "\n",
      "Fold: 17  Epoch: 225  Training loss = 5.3178  Validation loss = 3.2237  \n",
      "\n",
      "Fold: 17  Epoch: 226  Training loss = 5.3170  Validation loss = 3.2233  \n",
      "\n",
      "Fold: 17  Epoch: 227  Training loss = 5.3163  Validation loss = 3.2230  \n",
      "\n",
      "Fold: 17  Epoch: 228  Training loss = 5.3156  Validation loss = 3.2227  \n",
      "\n",
      "Fold: 17  Epoch: 229  Training loss = 5.3150  Validation loss = 3.2224  \n",
      "\n",
      "Fold: 17  Epoch: 230  Training loss = 5.3141  Validation loss = 3.2220  \n",
      "\n",
      "Fold: 17  Epoch: 231  Training loss = 5.3134  Validation loss = 3.2216  \n",
      "\n",
      "Fold: 17  Epoch: 232  Training loss = 5.3126  Validation loss = 3.2213  \n",
      "\n",
      "Fold: 17  Epoch: 233  Training loss = 5.3119  Validation loss = 3.2209  \n",
      "\n",
      "Fold: 17  Epoch: 234  Training loss = 5.3112  Validation loss = 3.2206  \n",
      "\n",
      "Fold: 17  Epoch: 235  Training loss = 5.3106  Validation loss = 3.2203  \n",
      "\n",
      "Fold: 17  Epoch: 236  Training loss = 5.3099  Validation loss = 3.2200  \n",
      "\n",
      "Fold: 17  Epoch: 237  Training loss = 5.3093  Validation loss = 3.2197  \n",
      "\n",
      "Fold: 17  Epoch: 238  Training loss = 5.3087  Validation loss = 3.2194  \n",
      "\n",
      "Fold: 17  Epoch: 239  Training loss = 5.3078  Validation loss = 3.2190  \n",
      "\n",
      "Fold: 17  Epoch: 240  Training loss = 5.3070  Validation loss = 3.2186  \n",
      "\n",
      "Fold: 17  Epoch: 241  Training loss = 5.3063  Validation loss = 3.2183  \n",
      "\n",
      "Fold: 17  Epoch: 242  Training loss = 5.3055  Validation loss = 3.2179  \n",
      "\n",
      "Fold: 17  Epoch: 243  Training loss = 5.3046  Validation loss = 3.2175  \n",
      "\n",
      "Fold: 17  Epoch: 244  Training loss = 5.3039  Validation loss = 3.2172  \n",
      "\n",
      "Fold: 17  Epoch: 245  Training loss = 5.3033  Validation loss = 3.2169  \n",
      "\n",
      "Fold: 17  Epoch: 246  Training loss = 5.3026  Validation loss = 3.2166  \n",
      "\n",
      "Fold: 17  Epoch: 247  Training loss = 5.3018  Validation loss = 3.2162  \n",
      "\n",
      "Fold: 17  Epoch: 248  Training loss = 5.3011  Validation loss = 3.2159  \n",
      "\n",
      "Fold: 17  Epoch: 249  Training loss = 5.3005  Validation loss = 3.2156  \n",
      "\n",
      "Fold: 17  Epoch: 250  Training loss = 5.2998  Validation loss = 3.2152  \n",
      "\n",
      "Fold: 17  Epoch: 251  Training loss = 5.2992  Validation loss = 3.2149  \n",
      "\n",
      "Fold: 17  Epoch: 252  Training loss = 5.2984  Validation loss = 3.2146  \n",
      "\n",
      "Fold: 17  Epoch: 253  Training loss = 5.2976  Validation loss = 3.2142  \n",
      "\n",
      "Fold: 17  Epoch: 254  Training loss = 5.2970  Validation loss = 3.2139  \n",
      "\n",
      "Fold: 17  Epoch: 255  Training loss = 5.2963  Validation loss = 3.2136  \n",
      "\n",
      "Fold: 17  Epoch: 256  Training loss = 5.2957  Validation loss = 3.2133  \n",
      "\n",
      "Fold: 17  Epoch: 257  Training loss = 5.2951  Validation loss = 3.2130  \n",
      "\n",
      "Fold: 17  Epoch: 258  Training loss = 5.2944  Validation loss = 3.2127  \n",
      "\n",
      "Fold: 17  Epoch: 259  Training loss = 5.2937  Validation loss = 3.2124  \n",
      "\n",
      "Fold: 17  Epoch: 260  Training loss = 5.2930  Validation loss = 3.2120  \n",
      "\n",
      "Fold: 17  Epoch: 261  Training loss = 5.2921  Validation loss = 3.2116  \n",
      "\n",
      "Fold: 17  Epoch: 262  Training loss = 5.2916  Validation loss = 3.2113  \n",
      "\n",
      "Fold: 17  Epoch: 263  Training loss = 5.2909  Validation loss = 3.2109  \n",
      "\n",
      "Fold: 17  Epoch: 264  Training loss = 5.2900  Validation loss = 3.2105  \n",
      "\n",
      "Fold: 17  Epoch: 265  Training loss = 5.2892  Validation loss = 3.2101  \n",
      "\n",
      "Fold: 17  Epoch: 266  Training loss = 5.2885  Validation loss = 3.2098  \n",
      "\n",
      "Fold: 17  Epoch: 267  Training loss = 5.2878  Validation loss = 3.2095  \n",
      "\n",
      "Fold: 17  Epoch: 268  Training loss = 5.2871  Validation loss = 3.2091  \n",
      "\n",
      "Fold: 17  Epoch: 269  Training loss = 5.2864  Validation loss = 3.2088  \n",
      "\n",
      "Fold: 17  Epoch: 270  Training loss = 5.2857  Validation loss = 3.2085  \n",
      "\n",
      "Fold: 17  Epoch: 271  Training loss = 5.2850  Validation loss = 3.2081  \n",
      "\n",
      "Fold: 17  Epoch: 272  Training loss = 5.2841  Validation loss = 3.2077  \n",
      "\n",
      "Fold: 17  Epoch: 273  Training loss = 5.2833  Validation loss = 3.2073  \n",
      "\n",
      "Fold: 17  Epoch: 274  Training loss = 5.2826  Validation loss = 3.2069  \n",
      "\n",
      "Fold: 17  Epoch: 275  Training loss = 5.2820  Validation loss = 3.2067  \n",
      "\n",
      "Fold: 17  Epoch: 276  Training loss = 5.2814  Validation loss = 3.2064  \n",
      "\n",
      "Fold: 17  Epoch: 277  Training loss = 5.2806  Validation loss = 3.2059  \n",
      "\n",
      "Fold: 17  Epoch: 278  Training loss = 5.2800  Validation loss = 3.2056  \n",
      "\n",
      "Fold: 17  Epoch: 279  Training loss = 5.2794  Validation loss = 3.2053  \n",
      "\n",
      "Fold: 17  Epoch: 280  Training loss = 5.2787  Validation loss = 3.2050  \n",
      "\n",
      "Fold: 17  Epoch: 281  Training loss = 5.2781  Validation loss = 3.2046  \n",
      "\n",
      "Fold: 17  Epoch: 282  Training loss = 5.2773  Validation loss = 3.2042  \n",
      "\n",
      "Fold: 17  Epoch: 283  Training loss = 5.2766  Validation loss = 3.2039  \n",
      "\n",
      "Fold: 17  Epoch: 284  Training loss = 5.2760  Validation loss = 3.2036  \n",
      "\n",
      "Fold: 17  Epoch: 285  Training loss = 5.2753  Validation loss = 3.2032  \n",
      "\n",
      "Fold: 17  Epoch: 286  Training loss = 5.2745  Validation loss = 3.2028  \n",
      "\n",
      "Fold: 17  Epoch: 287  Training loss = 5.2737  Validation loss = 3.2024  \n",
      "\n",
      "Fold: 17  Epoch: 288  Training loss = 5.2730  Validation loss = 3.2020  \n",
      "\n",
      "Fold: 17  Epoch: 289  Training loss = 5.2723  Validation loss = 3.2017  \n",
      "\n",
      "Fold: 17  Epoch: 290  Training loss = 5.2718  Validation loss = 3.2014  \n",
      "\n",
      "Fold: 17  Epoch: 291  Training loss = 5.2711  Validation loss = 3.2010  \n",
      "\n",
      "Fold: 17  Epoch: 292  Training loss = 5.2705  Validation loss = 3.2007  \n",
      "\n",
      "Fold: 17  Epoch: 293  Training loss = 5.2699  Validation loss = 3.2004  \n",
      "\n",
      "Fold: 17  Epoch: 294  Training loss = 5.2690  Validation loss = 3.2000  \n",
      "\n",
      "Fold: 17  Epoch: 295  Training loss = 5.2684  Validation loss = 3.1997  \n",
      "\n",
      "Fold: 17  Epoch: 296  Training loss = 5.2677  Validation loss = 3.1993  \n",
      "\n",
      "Fold: 17  Epoch: 297  Training loss = 5.2671  Validation loss = 3.1990  \n",
      "\n",
      "Fold: 17  Epoch: 298  Training loss = 5.2665  Validation loss = 3.1987  \n",
      "\n",
      "Fold: 17  Epoch: 299  Training loss = 5.2657  Validation loss = 3.1983  \n",
      "\n",
      "Fold: 17  Epoch: 300  Training loss = 5.2650  Validation loss = 3.1980  \n",
      "\n",
      "Fold: 17  Epoch: 301  Training loss = 5.2642  Validation loss = 3.1976  \n",
      "\n",
      "Fold: 17  Epoch: 302  Training loss = 5.2636  Validation loss = 3.1973  \n",
      "\n",
      "Fold: 17  Epoch: 303  Training loss = 5.2630  Validation loss = 3.1970  \n",
      "\n",
      "Fold: 17  Epoch: 304  Training loss = 5.2623  Validation loss = 3.1967  \n",
      "\n",
      "Fold: 17  Epoch: 305  Training loss = 5.2616  Validation loss = 3.1964  \n",
      "\n",
      "Fold: 17  Epoch: 306  Training loss = 5.2610  Validation loss = 3.1961  \n",
      "\n",
      "Fold: 17  Epoch: 307  Training loss = 5.2603  Validation loss = 3.1957  \n",
      "\n",
      "Fold: 17  Epoch: 308  Training loss = 5.2596  Validation loss = 3.1954  \n",
      "\n",
      "Fold: 17  Epoch: 309  Training loss = 5.2588  Validation loss = 3.1950  \n",
      "\n",
      "Fold: 17  Epoch: 310  Training loss = 5.2581  Validation loss = 3.1946  \n",
      "\n",
      "Fold: 17  Epoch: 311  Training loss = 5.2575  Validation loss = 3.1943  \n",
      "\n",
      "Fold: 17  Epoch: 312  Training loss = 5.2569  Validation loss = 3.1940  \n",
      "\n",
      "Fold: 17  Epoch: 313  Training loss = 5.2560  Validation loss = 3.1935  \n",
      "\n",
      "Fold: 17  Epoch: 314  Training loss = 5.2552  Validation loss = 3.1932  \n",
      "\n",
      "Fold: 17  Epoch: 315  Training loss = 5.2545  Validation loss = 3.1928  \n",
      "\n",
      "Fold: 17  Epoch: 316  Training loss = 5.2538  Validation loss = 3.1925  \n",
      "\n",
      "Fold: 17  Epoch: 317  Training loss = 5.2532  Validation loss = 3.1922  \n",
      "\n",
      "Fold: 17  Epoch: 318  Training loss = 5.2526  Validation loss = 3.1919  \n",
      "\n",
      "Fold: 17  Epoch: 319  Training loss = 5.2519  Validation loss = 3.1915  \n",
      "\n",
      "Fold: 17  Epoch: 320  Training loss = 5.2513  Validation loss = 3.1912  \n",
      "\n",
      "Fold: 17  Epoch: 321  Training loss = 5.2504  Validation loss = 3.1908  \n",
      "\n",
      "Fold: 17  Epoch: 322  Training loss = 5.2497  Validation loss = 3.1905  \n",
      "\n",
      "Fold: 17  Epoch: 323  Training loss = 5.2491  Validation loss = 3.1902  \n",
      "\n",
      "Fold: 17  Epoch: 324  Training loss = 5.2484  Validation loss = 3.1898  \n",
      "\n",
      "Fold: 17  Epoch: 325  Training loss = 5.2476  Validation loss = 3.1895  \n",
      "\n",
      "Fold: 17  Epoch: 326  Training loss = 5.2469  Validation loss = 3.1891  \n",
      "\n",
      "Fold: 17  Epoch: 327  Training loss = 5.2462  Validation loss = 3.1888  \n",
      "\n",
      "Fold: 17  Epoch: 328  Training loss = 5.2455  Validation loss = 3.1885  \n",
      "\n",
      "Fold: 17  Epoch: 329  Training loss = 5.2447  Validation loss = 3.1881  \n",
      "\n",
      "Fold: 17  Epoch: 330  Training loss = 5.2438  Validation loss = 3.1878  \n",
      "\n",
      "Fold: 17  Epoch: 331  Training loss = 5.2431  Validation loss = 3.1874  \n",
      "\n",
      "Fold: 17  Epoch: 332  Training loss = 5.2423  Validation loss = 3.1870  \n",
      "\n",
      "Fold: 17  Epoch: 333  Training loss = 5.2414  Validation loss = 3.1866  \n",
      "\n",
      "Fold: 17  Epoch: 334  Training loss = 5.2407  Validation loss = 3.1863  \n",
      "\n",
      "Fold: 17  Epoch: 335  Training loss = 5.2399  Validation loss = 3.1859  \n",
      "\n",
      "Fold: 17  Epoch: 336  Training loss = 5.2392  Validation loss = 3.1856  \n",
      "\n",
      "Fold: 17  Epoch: 337  Training loss = 5.2384  Validation loss = 3.1853  \n",
      "\n",
      "Fold: 17  Epoch: 338  Training loss = 5.2377  Validation loss = 3.1849  \n",
      "\n",
      "Fold: 17  Epoch: 339  Training loss = 5.2369  Validation loss = 3.1845  \n",
      "\n",
      "Fold: 17  Epoch: 340  Training loss = 5.2362  Validation loss = 3.1842  \n",
      "\n",
      "Fold: 17  Epoch: 341  Training loss = 5.2354  Validation loss = 3.1838  \n",
      "\n",
      "Fold: 17  Epoch: 342  Training loss = 5.2347  Validation loss = 3.1834  \n",
      "\n",
      "Fold: 17  Epoch: 343  Training loss = 5.2341  Validation loss = 3.1831  \n",
      "\n",
      "Fold: 17  Epoch: 344  Training loss = 5.2335  Validation loss = 3.1828  \n",
      "\n",
      "Fold: 17  Epoch: 345  Training loss = 5.2327  Validation loss = 3.1825  \n",
      "\n",
      "Fold: 17  Epoch: 346  Training loss = 5.2321  Validation loss = 3.1822  \n",
      "\n",
      "Fold: 17  Epoch: 347  Training loss = 5.2313  Validation loss = 3.1818  \n",
      "\n",
      "Fold: 17  Epoch: 348  Training loss = 5.2308  Validation loss = 3.1816  \n",
      "\n",
      "Fold: 17  Epoch: 349  Training loss = 5.2301  Validation loss = 3.1812  \n",
      "\n",
      "Fold: 17  Epoch: 350  Training loss = 5.2295  Validation loss = 3.1809  \n",
      "\n",
      "Fold: 17  Epoch: 351  Training loss = 5.2287  Validation loss = 3.1806  \n",
      "\n",
      "Fold: 17  Epoch: 352  Training loss = 5.2282  Validation loss = 3.1803  \n",
      "\n",
      "Fold: 17  Epoch: 353  Training loss = 5.2274  Validation loss = 3.1799  \n",
      "\n",
      "Fold: 17  Epoch: 354  Training loss = 5.2269  Validation loss = 3.1796  \n",
      "\n",
      "Fold: 17  Epoch: 355  Training loss = 5.2263  Validation loss = 3.1794  \n",
      "\n",
      "Fold: 17  Epoch: 356  Training loss = 5.2256  Validation loss = 3.1791  \n",
      "\n",
      "Fold: 17  Epoch: 357  Training loss = 5.2249  Validation loss = 3.1787  \n",
      "\n",
      "Fold: 17  Epoch: 358  Training loss = 5.2242  Validation loss = 3.1784  \n",
      "\n",
      "Fold: 17  Epoch: 359  Training loss = 5.2235  Validation loss = 3.1781  \n",
      "\n",
      "Fold: 17  Epoch: 360  Training loss = 5.2228  Validation loss = 3.1778  \n",
      "\n",
      "Fold: 17  Epoch: 361  Training loss = 5.2222  Validation loss = 3.1775  \n",
      "\n",
      "Fold: 17  Epoch: 362  Training loss = 5.2216  Validation loss = 3.1772  \n",
      "\n",
      "Fold: 17  Epoch: 363  Training loss = 5.2210  Validation loss = 3.1770  \n",
      "\n",
      "Fold: 17  Epoch: 364  Training loss = 5.2201  Validation loss = 3.1766  \n",
      "\n",
      "Fold: 17  Epoch: 365  Training loss = 5.2195  Validation loss = 3.1763  \n",
      "\n",
      "Fold: 17  Epoch: 366  Training loss = 5.2187  Validation loss = 3.1759  \n",
      "\n",
      "Fold: 17  Epoch: 367  Training loss = 5.2180  Validation loss = 3.1756  \n",
      "\n",
      "Fold: 17  Epoch: 368  Training loss = 5.2173  Validation loss = 3.1753  \n",
      "\n",
      "Fold: 17  Epoch: 369  Training loss = 5.2166  Validation loss = 3.1749  \n",
      "\n",
      "Fold: 17  Epoch: 370  Training loss = 5.2160  Validation loss = 3.1746  \n",
      "\n",
      "Fold: 17  Epoch: 371  Training loss = 5.2152  Validation loss = 3.1743  \n",
      "\n",
      "Fold: 17  Epoch: 372  Training loss = 5.2144  Validation loss = 3.1739  \n",
      "\n",
      "Fold: 17  Epoch: 373  Training loss = 5.2137  Validation loss = 3.1736  \n",
      "\n",
      "Fold: 17  Epoch: 374  Training loss = 5.2130  Validation loss = 3.1733  \n",
      "\n",
      "Fold: 17  Epoch: 375  Training loss = 5.2124  Validation loss = 3.1730  \n",
      "\n",
      "Fold: 17  Epoch: 376  Training loss = 5.2117  Validation loss = 3.1727  \n",
      "\n",
      "Fold: 17  Epoch: 377  Training loss = 5.2110  Validation loss = 3.1724  \n",
      "\n",
      "Fold: 17  Epoch: 378  Training loss = 5.2103  Validation loss = 3.1721  \n",
      "\n",
      "Fold: 17  Epoch: 379  Training loss = 5.2096  Validation loss = 3.1717  \n",
      "\n",
      "Fold: 17  Epoch: 380  Training loss = 5.2089  Validation loss = 3.1715  \n",
      "\n",
      "Fold: 17  Epoch: 381  Training loss = 5.2082  Validation loss = 3.1711  \n",
      "\n",
      "Fold: 17  Epoch: 382  Training loss = 5.2076  Validation loss = 3.1709  \n",
      "\n",
      "Fold: 17  Epoch: 383  Training loss = 5.2069  Validation loss = 3.1706  \n",
      "\n",
      "Fold: 17  Epoch: 384  Training loss = 5.2062  Validation loss = 3.1702  \n",
      "\n",
      "Fold: 17  Epoch: 385  Training loss = 5.2055  Validation loss = 3.1700  \n",
      "\n",
      "Fold: 17  Epoch: 386  Training loss = 5.2048  Validation loss = 3.1697  \n",
      "\n",
      "Fold: 17  Epoch: 387  Training loss = 5.2040  Validation loss = 3.1693  \n",
      "\n",
      "Fold: 17  Epoch: 388  Training loss = 5.2033  Validation loss = 3.1690  \n",
      "\n",
      "Fold: 17  Epoch: 389  Training loss = 5.2027  Validation loss = 3.1687  \n",
      "\n",
      "Fold: 17  Epoch: 390  Training loss = 5.2020  Validation loss = 3.1684  \n",
      "\n",
      "Fold: 17  Epoch: 391  Training loss = 5.2014  Validation loss = 3.1681  \n",
      "\n",
      "Fold: 17  Epoch: 392  Training loss = 5.2007  Validation loss = 3.1678  \n",
      "\n",
      "Fold: 17  Epoch: 393  Training loss = 5.2000  Validation loss = 3.1675  \n",
      "\n",
      "Fold: 17  Epoch: 394  Training loss = 5.1993  Validation loss = 3.1672  \n",
      "\n",
      "Fold: 17  Epoch: 395  Training loss = 5.1986  Validation loss = 3.1669  \n",
      "\n",
      "Fold: 17  Epoch: 396  Training loss = 5.1981  Validation loss = 3.1667  \n",
      "\n",
      "Fold: 17  Epoch: 397  Training loss = 5.1976  Validation loss = 3.1665  \n",
      "\n",
      "Fold: 17  Epoch: 398  Training loss = 5.1968  Validation loss = 3.1661  \n",
      "\n",
      "Fold: 17  Epoch: 399  Training loss = 5.1963  Validation loss = 3.1658  \n",
      "\n",
      "Fold: 17  Epoch: 400  Training loss = 5.1956  Validation loss = 3.1656  \n",
      "\n",
      "Fold: 17  Epoch: 401  Training loss = 5.1950  Validation loss = 3.1653  \n",
      "\n",
      "Fold: 17  Epoch: 402  Training loss = 5.1944  Validation loss = 3.1651  \n",
      "\n",
      "Fold: 17  Epoch: 403  Training loss = 5.1937  Validation loss = 3.1648  \n",
      "\n",
      "Fold: 17  Epoch: 404  Training loss = 5.1930  Validation loss = 3.1644  \n",
      "\n",
      "Fold: 17  Epoch: 405  Training loss = 5.1924  Validation loss = 3.1641  \n",
      "\n",
      "Fold: 17  Epoch: 406  Training loss = 5.1917  Validation loss = 3.1639  \n",
      "\n",
      "Fold: 17  Epoch: 407  Training loss = 5.1911  Validation loss = 3.1636  \n",
      "\n",
      "Fold: 17  Epoch: 408  Training loss = 5.1904  Validation loss = 3.1633  \n",
      "\n",
      "Fold: 17  Epoch: 409  Training loss = 5.1898  Validation loss = 3.1631  \n",
      "\n",
      "Fold: 17  Epoch: 410  Training loss = 5.1892  Validation loss = 3.1627  \n",
      "\n",
      "Fold: 17  Epoch: 411  Training loss = 5.1885  Validation loss = 3.1624  \n",
      "\n",
      "Fold: 17  Epoch: 412  Training loss = 5.1879  Validation loss = 3.1622  \n",
      "\n",
      "Fold: 17  Epoch: 413  Training loss = 5.1872  Validation loss = 3.1619  \n",
      "\n",
      "Fold: 17  Epoch: 414  Training loss = 5.1865  Validation loss = 3.1616  \n",
      "\n",
      "Fold: 17  Epoch: 415  Training loss = 5.1860  Validation loss = 3.1614  \n",
      "\n",
      "Fold: 17  Epoch: 416  Training loss = 5.1853  Validation loss = 3.1610  \n",
      "\n",
      "Fold: 17  Epoch: 417  Training loss = 5.1846  Validation loss = 3.1608  \n",
      "\n",
      "Fold: 17  Epoch: 418  Training loss = 5.1839  Validation loss = 3.1605  \n",
      "\n",
      "Fold: 17  Epoch: 419  Training loss = 5.1831  Validation loss = 3.1601  \n",
      "\n",
      "Fold: 17  Epoch: 420  Training loss = 5.1825  Validation loss = 3.1599  \n",
      "\n",
      "Fold: 17  Epoch: 421  Training loss = 5.1818  Validation loss = 3.1596  \n",
      "\n",
      "Fold: 17  Epoch: 422  Training loss = 5.1812  Validation loss = 3.1593  \n",
      "\n",
      "Fold: 17  Epoch: 423  Training loss = 5.1805  Validation loss = 3.1590  \n",
      "\n",
      "Fold: 17  Epoch: 424  Training loss = 5.1798  Validation loss = 3.1588  \n",
      "\n",
      "Fold: 17  Epoch: 425  Training loss = 5.1791  Validation loss = 3.1585  \n",
      "\n",
      "Fold: 17  Epoch: 426  Training loss = 5.1784  Validation loss = 3.1582  \n",
      "\n",
      "Fold: 17  Epoch: 427  Training loss = 5.1777  Validation loss = 3.1580  \n",
      "\n",
      "Fold: 17  Epoch: 428  Training loss = 5.1771  Validation loss = 3.1577  \n",
      "\n",
      "Fold: 17  Epoch: 429  Training loss = 5.1764  Validation loss = 3.1574  \n",
      "\n",
      "Fold: 17  Epoch: 430  Training loss = 5.1757  Validation loss = 3.1571  \n",
      "\n",
      "Fold: 17  Epoch: 431  Training loss = 5.1751  Validation loss = 3.1568  \n",
      "\n",
      "Fold: 17  Epoch: 432  Training loss = 5.1745  Validation loss = 3.1565  \n",
      "\n",
      "Fold: 17  Epoch: 433  Training loss = 5.1739  Validation loss = 3.1563  \n",
      "\n",
      "Fold: 17  Epoch: 434  Training loss = 5.1731  Validation loss = 3.1559  \n",
      "\n",
      "Fold: 17  Epoch: 435  Training loss = 5.1724  Validation loss = 3.1557  \n",
      "\n",
      "Fold: 17  Epoch: 436  Training loss = 5.1717  Validation loss = 3.1554  \n",
      "\n",
      "Fold: 17  Epoch: 437  Training loss = 5.1710  Validation loss = 3.1550  \n",
      "\n",
      "Fold: 17  Epoch: 438  Training loss = 5.1702  Validation loss = 3.1548  \n",
      "\n",
      "Fold: 17  Epoch: 439  Training loss = 5.1697  Validation loss = 3.1545  \n",
      "\n",
      "Fold: 17  Epoch: 440  Training loss = 5.1689  Validation loss = 3.1542  \n",
      "\n",
      "Fold: 17  Epoch: 441  Training loss = 5.1683  Validation loss = 3.1540  \n",
      "\n",
      "Fold: 17  Epoch: 442  Training loss = 5.1676  Validation loss = 3.1537  \n",
      "\n",
      "Fold: 17  Epoch: 443  Training loss = 5.1670  Validation loss = 3.1535  \n",
      "\n",
      "Fold: 17  Epoch: 444  Training loss = 5.1663  Validation loss = 3.1532  \n",
      "\n",
      "Fold: 17  Epoch: 445  Training loss = 5.1656  Validation loss = 3.1529  \n",
      "\n",
      "Fold: 17  Epoch: 446  Training loss = 5.1649  Validation loss = 3.1526  \n",
      "\n",
      "Fold: 17  Epoch: 447  Training loss = 5.1643  Validation loss = 3.1524  \n",
      "\n",
      "Fold: 17  Epoch: 448  Training loss = 5.1638  Validation loss = 3.1522  \n",
      "\n",
      "Fold: 17  Epoch: 449  Training loss = 5.1631  Validation loss = 3.1520  \n",
      "\n",
      "Fold: 17  Epoch: 450  Training loss = 5.1624  Validation loss = 3.1517  \n",
      "\n",
      "Fold: 17  Epoch: 451  Training loss = 5.1618  Validation loss = 3.1515  \n",
      "\n",
      "Fold: 17  Epoch: 452  Training loss = 5.1611  Validation loss = 3.1512  \n",
      "\n",
      "Fold: 17  Epoch: 453  Training loss = 5.1605  Validation loss = 3.1510  \n",
      "\n",
      "Fold: 17  Epoch: 454  Training loss = 5.1599  Validation loss = 3.1507  \n",
      "\n",
      "Fold: 17  Epoch: 455  Training loss = 5.1591  Validation loss = 3.1504  \n",
      "\n",
      "Fold: 17  Epoch: 456  Training loss = 5.1585  Validation loss = 3.1502  \n",
      "\n",
      "Fold: 17  Epoch: 457  Training loss = 5.1580  Validation loss = 3.1499  \n",
      "\n",
      "Fold: 17  Epoch: 458  Training loss = 5.1574  Validation loss = 3.1497  \n",
      "\n",
      "Fold: 17  Epoch: 459  Training loss = 5.1568  Validation loss = 3.1495  \n",
      "\n",
      "Fold: 17  Epoch: 460  Training loss = 5.1561  Validation loss = 3.1492  \n",
      "\n",
      "Fold: 17  Epoch: 461  Training loss = 5.1555  Validation loss = 3.1490  \n",
      "\n",
      "Fold: 17  Epoch: 462  Training loss = 5.1549  Validation loss = 3.1487  \n",
      "\n",
      "Fold: 17  Epoch: 463  Training loss = 5.1541  Validation loss = 3.1484  \n",
      "\n",
      "Fold: 17  Epoch: 464  Training loss = 5.1534  Validation loss = 3.1481  \n",
      "\n",
      "Fold: 17  Epoch: 465  Training loss = 5.1528  Validation loss = 3.1479  \n",
      "\n",
      "Fold: 17  Epoch: 466  Training loss = 5.1523  Validation loss = 3.1477  \n",
      "\n",
      "Fold: 17  Epoch: 467  Training loss = 5.1517  Validation loss = 3.1474  \n",
      "\n",
      "Fold: 17  Epoch: 468  Training loss = 5.1510  Validation loss = 3.1472  \n",
      "\n",
      "Fold: 17  Epoch: 469  Training loss = 5.1503  Validation loss = 3.1469  \n",
      "\n",
      "Fold: 17  Epoch: 470  Training loss = 5.1497  Validation loss = 3.1467  \n",
      "\n",
      "Fold: 17  Epoch: 471  Training loss = 5.1492  Validation loss = 3.1465  \n",
      "\n",
      "Fold: 17  Epoch: 472  Training loss = 5.1485  Validation loss = 3.1462  \n",
      "\n",
      "Fold: 17  Epoch: 473  Training loss = 5.1479  Validation loss = 3.1460  \n",
      "\n",
      "Fold: 17  Epoch: 474  Training loss = 5.1474  Validation loss = 3.1458  \n",
      "\n",
      "Fold: 17  Epoch: 475  Training loss = 5.1467  Validation loss = 3.1455  \n",
      "\n",
      "Fold: 17  Epoch: 476  Training loss = 5.1459  Validation loss = 3.1452  \n",
      "\n",
      "Fold: 17  Epoch: 477  Training loss = 5.1452  Validation loss = 3.1450  \n",
      "\n",
      "Fold: 17  Epoch: 478  Training loss = 5.1446  Validation loss = 3.1448  \n",
      "\n",
      "Fold: 17  Epoch: 479  Training loss = 5.1439  Validation loss = 3.1446  \n",
      "\n",
      "Fold: 17  Epoch: 480  Training loss = 5.1432  Validation loss = 3.1443  \n",
      "\n",
      "Fold: 17  Epoch: 481  Training loss = 5.1424  Validation loss = 3.1439  \n",
      "\n",
      "Fold: 17  Epoch: 482  Training loss = 5.1419  Validation loss = 3.1438  \n",
      "\n",
      "Fold: 17  Epoch: 483  Training loss = 5.1413  Validation loss = 3.1435  \n",
      "\n",
      "Fold: 17  Epoch: 484  Training loss = 5.1406  Validation loss = 3.1432  \n",
      "\n",
      "Fold: 17  Epoch: 485  Training loss = 5.1400  Validation loss = 3.1430  \n",
      "\n",
      "Fold: 17  Epoch: 486  Training loss = 5.1393  Validation loss = 3.1428  \n",
      "\n",
      "Fold: 17  Epoch: 487  Training loss = 5.1387  Validation loss = 3.1426  \n",
      "\n",
      "Fold: 17  Epoch: 488  Training loss = 5.1381  Validation loss = 3.1423  \n",
      "\n",
      "Fold: 17  Epoch: 489  Training loss = 5.1375  Validation loss = 3.1421  \n",
      "\n",
      "Fold: 17  Epoch: 490  Training loss = 5.1367  Validation loss = 3.1418  \n",
      "\n",
      "Fold: 17  Epoch: 491  Training loss = 5.1361  Validation loss = 3.1416  \n",
      "\n",
      "Fold: 17  Epoch: 492  Training loss = 5.1354  Validation loss = 3.1413  \n",
      "\n",
      "Fold: 17  Epoch: 493  Training loss = 5.1347  Validation loss = 3.1411  \n",
      "\n",
      "Fold: 17  Epoch: 494  Training loss = 5.1342  Validation loss = 3.1409  \n",
      "\n",
      "Fold: 17  Epoch: 495  Training loss = 5.1335  Validation loss = 3.1407  \n",
      "\n",
      "Fold: 17  Epoch: 496  Training loss = 5.1329  Validation loss = 3.1404  \n",
      "\n",
      "Fold: 17  Epoch: 497  Training loss = 5.1321  Validation loss = 3.1401  \n",
      "\n",
      "Fold: 17  Epoch: 498  Training loss = 5.1314  Validation loss = 3.1398  \n",
      "\n",
      "Fold: 17  Epoch: 499  Training loss = 5.1307  Validation loss = 3.1396  \n",
      "\n",
      "Fold: 17  Epoch: 500  Training loss = 5.1299  Validation loss = 3.1393  \n",
      "\n",
      "Check model:  Fold: 17  Optimal epoch: 500  \n",
      "\n",
      "Fold: 18  Epoch: 1  Training loss = 5.1803  Validation loss = 2.1159  \n",
      "\n",
      "Fold: 18  Epoch: 2  Training loss = 5.1796  Validation loss = 2.1156  \n",
      "\n",
      "Fold: 18  Epoch: 3  Training loss = 5.1789  Validation loss = 2.1154  \n",
      "\n",
      "Fold: 18  Epoch: 4  Training loss = 5.1783  Validation loss = 2.1151  \n",
      "\n",
      "Fold: 18  Epoch: 5  Training loss = 5.1776  Validation loss = 2.1149  \n",
      "\n",
      "Fold: 18  Epoch: 6  Training loss = 5.1768  Validation loss = 2.1146  \n",
      "\n",
      "Fold: 18  Epoch: 7  Training loss = 5.1761  Validation loss = 2.1143  \n",
      "\n",
      "Fold: 18  Epoch: 8  Training loss = 5.1754  Validation loss = 2.1141  \n",
      "\n",
      "Fold: 18  Epoch: 9  Training loss = 5.1747  Validation loss = 2.1138  \n",
      "\n",
      "Fold: 18  Epoch: 10  Training loss = 5.1740  Validation loss = 2.1135  \n",
      "\n",
      "Fold: 18  Epoch: 11  Training loss = 5.1734  Validation loss = 2.1133  \n",
      "\n",
      "Fold: 18  Epoch: 12  Training loss = 5.1727  Validation loss = 2.1130  \n",
      "\n",
      "Fold: 18  Epoch: 13  Training loss = 5.1721  Validation loss = 2.1128  \n",
      "\n",
      "Fold: 18  Epoch: 14  Training loss = 5.1714  Validation loss = 2.1125  \n",
      "\n",
      "Fold: 18  Epoch: 15  Training loss = 5.1707  Validation loss = 2.1123  \n",
      "\n",
      "Fold: 18  Epoch: 16  Training loss = 5.1700  Validation loss = 2.1120  \n",
      "\n",
      "Fold: 18  Epoch: 17  Training loss = 5.1693  Validation loss = 2.1118  \n",
      "\n",
      "Fold: 18  Epoch: 18  Training loss = 5.1686  Validation loss = 2.1115  \n",
      "\n",
      "Fold: 18  Epoch: 19  Training loss = 5.1680  Validation loss = 2.1113  \n",
      "\n",
      "Fold: 18  Epoch: 20  Training loss = 5.1672  Validation loss = 2.1110  \n",
      "\n",
      "Fold: 18  Epoch: 21  Training loss = 5.1666  Validation loss = 2.1108  \n",
      "\n",
      "Fold: 18  Epoch: 22  Training loss = 5.1660  Validation loss = 2.1105  \n",
      "\n",
      "Fold: 18  Epoch: 23  Training loss = 5.1652  Validation loss = 2.1103  \n",
      "\n",
      "Fold: 18  Epoch: 24  Training loss = 5.1645  Validation loss = 2.1100  \n",
      "\n",
      "Fold: 18  Epoch: 25  Training loss = 5.1638  Validation loss = 2.1098  \n",
      "\n",
      "Fold: 18  Epoch: 26  Training loss = 5.1633  Validation loss = 2.1096  \n",
      "\n",
      "Fold: 18  Epoch: 27  Training loss = 5.1626  Validation loss = 2.1094  \n",
      "\n",
      "Fold: 18  Epoch: 28  Training loss = 5.1619  Validation loss = 2.1091  \n",
      "\n",
      "Fold: 18  Epoch: 29  Training loss = 5.1613  Validation loss = 2.1089  \n",
      "\n",
      "Fold: 18  Epoch: 30  Training loss = 5.1605  Validation loss = 2.1086  \n",
      "\n",
      "Fold: 18  Epoch: 31  Training loss = 5.1597  Validation loss = 2.1083  \n",
      "\n",
      "Fold: 18  Epoch: 32  Training loss = 5.1589  Validation loss = 2.1081  \n",
      "\n",
      "Fold: 18  Epoch: 33  Training loss = 5.1584  Validation loss = 2.1079  \n",
      "\n",
      "Fold: 18  Epoch: 34  Training loss = 5.1578  Validation loss = 2.1077  \n",
      "\n",
      "Fold: 18  Epoch: 35  Training loss = 5.1571  Validation loss = 2.1074  \n",
      "\n",
      "Fold: 18  Epoch: 36  Training loss = 5.1564  Validation loss = 2.1072  \n",
      "\n",
      "Fold: 18  Epoch: 37  Training loss = 5.1556  Validation loss = 2.1069  \n",
      "\n",
      "Fold: 18  Epoch: 38  Training loss = 5.1549  Validation loss = 2.1067  \n",
      "\n",
      "Fold: 18  Epoch: 39  Training loss = 5.1541  Validation loss = 2.1064  \n",
      "\n",
      "Fold: 18  Epoch: 40  Training loss = 5.1535  Validation loss = 2.1062  \n",
      "\n",
      "Fold: 18  Epoch: 41  Training loss = 5.1531  Validation loss = 2.1061  \n",
      "\n",
      "Fold: 18  Epoch: 42  Training loss = 5.1523  Validation loss = 2.1058  \n",
      "\n",
      "Fold: 18  Epoch: 43  Training loss = 5.1516  Validation loss = 2.1056  \n",
      "\n",
      "Fold: 18  Epoch: 44  Training loss = 5.1508  Validation loss = 2.1053  \n",
      "\n",
      "Fold: 18  Epoch: 45  Training loss = 5.1502  Validation loss = 2.1051  \n",
      "\n",
      "Fold: 18  Epoch: 46  Training loss = 5.1496  Validation loss = 2.1049  \n",
      "\n",
      "Fold: 18  Epoch: 47  Training loss = 5.1488  Validation loss = 2.1046  \n",
      "\n",
      "Fold: 18  Epoch: 48  Training loss = 5.1479  Validation loss = 2.1043  \n",
      "\n",
      "Fold: 18  Epoch: 49  Training loss = 5.1472  Validation loss = 2.1040  \n",
      "\n",
      "Fold: 18  Epoch: 50  Training loss = 5.1465  Validation loss = 2.1038  \n",
      "\n",
      "Fold: 18  Epoch: 51  Training loss = 5.1458  Validation loss = 2.1036  \n",
      "\n",
      "Fold: 18  Epoch: 52  Training loss = 5.1452  Validation loss = 2.1034  \n",
      "\n",
      "Fold: 18  Epoch: 53  Training loss = 5.1446  Validation loss = 2.1032  \n",
      "\n",
      "Fold: 18  Epoch: 54  Training loss = 5.1439  Validation loss = 2.1030  \n",
      "\n",
      "Fold: 18  Epoch: 55  Training loss = 5.1433  Validation loss = 2.1028  \n",
      "\n",
      "Fold: 18  Epoch: 56  Training loss = 5.1426  Validation loss = 2.1026  \n",
      "\n",
      "Fold: 18  Epoch: 57  Training loss = 5.1419  Validation loss = 2.1023  \n",
      "\n",
      "Fold: 18  Epoch: 58  Training loss = 5.1412  Validation loss = 2.1021  \n",
      "\n",
      "Fold: 18  Epoch: 59  Training loss = 5.1406  Validation loss = 2.1019  \n",
      "\n",
      "Fold: 18  Epoch: 60  Training loss = 5.1399  Validation loss = 2.1017  \n",
      "\n",
      "Fold: 18  Epoch: 61  Training loss = 5.1390  Validation loss = 2.1014  \n",
      "\n",
      "Fold: 18  Epoch: 62  Training loss = 5.1382  Validation loss = 2.1012  \n",
      "\n",
      "Fold: 18  Epoch: 63  Training loss = 5.1375  Validation loss = 2.1010  \n",
      "\n",
      "Fold: 18  Epoch: 64  Training loss = 5.1369  Validation loss = 2.1008  \n",
      "\n",
      "Fold: 18  Epoch: 65  Training loss = 5.1362  Validation loss = 2.1006  \n",
      "\n",
      "Fold: 18  Epoch: 66  Training loss = 5.1355  Validation loss = 2.1004  \n",
      "\n",
      "Fold: 18  Epoch: 67  Training loss = 5.1346  Validation loss = 2.1001  \n",
      "\n",
      "Fold: 18  Epoch: 68  Training loss = 5.1338  Validation loss = 2.0999  \n",
      "\n",
      "Fold: 18  Epoch: 69  Training loss = 5.1330  Validation loss = 2.0997  \n",
      "\n",
      "Fold: 18  Epoch: 70  Training loss = 5.1323  Validation loss = 2.0995  \n",
      "\n",
      "Fold: 18  Epoch: 71  Training loss = 5.1315  Validation loss = 2.0992  \n",
      "\n",
      "Fold: 18  Epoch: 72  Training loss = 5.1306  Validation loss = 2.0990  \n",
      "\n",
      "Fold: 18  Epoch: 73  Training loss = 5.1299  Validation loss = 2.0988  \n",
      "\n",
      "Fold: 18  Epoch: 74  Training loss = 5.1292  Validation loss = 2.0986  \n",
      "\n",
      "Fold: 18  Epoch: 75  Training loss = 5.1284  Validation loss = 2.0984  \n",
      "\n",
      "Fold: 18  Epoch: 76  Training loss = 5.1277  Validation loss = 2.0982  \n",
      "\n",
      "Fold: 18  Epoch: 77  Training loss = 5.1269  Validation loss = 2.0980  \n",
      "\n",
      "Fold: 18  Epoch: 78  Training loss = 5.1262  Validation loss = 2.0977  \n",
      "\n",
      "Fold: 18  Epoch: 79  Training loss = 5.1253  Validation loss = 2.0975  \n",
      "\n",
      "Fold: 18  Epoch: 80  Training loss = 5.1247  Validation loss = 2.0973  \n",
      "\n",
      "Fold: 18  Epoch: 81  Training loss = 5.1238  Validation loss = 2.0971  \n",
      "\n",
      "Fold: 18  Epoch: 82  Training loss = 5.1229  Validation loss = 2.0968  \n",
      "\n",
      "Fold: 18  Epoch: 83  Training loss = 5.1220  Validation loss = 2.0966  \n",
      "\n",
      "Fold: 18  Epoch: 84  Training loss = 5.1212  Validation loss = 2.0964  \n",
      "\n",
      "Fold: 18  Epoch: 85  Training loss = 5.1204  Validation loss = 2.0962  \n",
      "\n",
      "Fold: 18  Epoch: 86  Training loss = 5.1197  Validation loss = 2.0960  \n",
      "\n",
      "Fold: 18  Epoch: 87  Training loss = 5.1189  Validation loss = 2.0958  \n",
      "\n",
      "Fold: 18  Epoch: 88  Training loss = 5.1179  Validation loss = 2.0955  \n",
      "\n",
      "Fold: 18  Epoch: 89  Training loss = 5.1169  Validation loss = 2.0953  \n",
      "\n",
      "Fold: 18  Epoch: 90  Training loss = 5.1162  Validation loss = 2.0952  \n",
      "\n",
      "Fold: 18  Epoch: 91  Training loss = 5.1154  Validation loss = 2.0950  \n",
      "\n",
      "Fold: 18  Epoch: 92  Training loss = 5.1145  Validation loss = 2.0948  \n",
      "\n",
      "Fold: 18  Epoch: 93  Training loss = 5.1136  Validation loss = 2.0946  \n",
      "\n",
      "Fold: 18  Epoch: 94  Training loss = 5.1126  Validation loss = 2.0944  \n",
      "\n",
      "Fold: 18  Epoch: 95  Training loss = 5.1117  Validation loss = 2.0942  \n",
      "\n",
      "Fold: 18  Epoch: 96  Training loss = 5.1109  Validation loss = 2.0940  \n",
      "\n",
      "Fold: 18  Epoch: 97  Training loss = 5.1098  Validation loss = 2.0937  \n",
      "\n",
      "Fold: 18  Epoch: 98  Training loss = 5.1085  Validation loss = 2.0935  \n",
      "\n",
      "Fold: 18  Epoch: 99  Training loss = 5.1074  Validation loss = 2.0933  \n",
      "\n",
      "Fold: 18  Epoch: 100  Training loss = 5.1066  Validation loss = 2.0931  \n",
      "\n",
      "Fold: 18  Epoch: 101  Training loss = 5.1059  Validation loss = 2.0929  \n",
      "\n",
      "Fold: 18  Epoch: 102  Training loss = 5.1051  Validation loss = 2.0927  \n",
      "\n",
      "Fold: 18  Epoch: 103  Training loss = 5.1041  Validation loss = 2.0925  \n",
      "\n",
      "Fold: 18  Epoch: 104  Training loss = 5.1032  Validation loss = 2.0923  \n",
      "\n",
      "Fold: 18  Epoch: 105  Training loss = 5.1023  Validation loss = 2.0920  \n",
      "\n",
      "Fold: 18  Epoch: 106  Training loss = 5.1015  Validation loss = 2.0919  \n",
      "\n",
      "Fold: 18  Epoch: 107  Training loss = 5.1005  Validation loss = 2.0917  \n",
      "\n",
      "Fold: 18  Epoch: 108  Training loss = 5.0994  Validation loss = 2.0915  \n",
      "\n",
      "Fold: 18  Epoch: 109  Training loss = 5.0987  Validation loss = 2.0913  \n",
      "\n",
      "Fold: 18  Epoch: 110  Training loss = 5.0977  Validation loss = 2.0911  \n",
      "\n",
      "Fold: 18  Epoch: 111  Training loss = 5.0970  Validation loss = 2.0909  \n",
      "\n",
      "Fold: 18  Epoch: 112  Training loss = 5.0959  Validation loss = 2.0907  \n",
      "\n",
      "Fold: 18  Epoch: 113  Training loss = 5.0950  Validation loss = 2.0906  \n",
      "\n",
      "Fold: 18  Epoch: 114  Training loss = 5.0943  Validation loss = 2.0904  \n",
      "\n",
      "Fold: 18  Epoch: 115  Training loss = 5.0932  Validation loss = 2.0902  \n",
      "\n",
      "Fold: 18  Epoch: 116  Training loss = 5.0922  Validation loss = 2.0900  \n",
      "\n",
      "Fold: 18  Epoch: 117  Training loss = 5.0913  Validation loss = 2.0898  \n",
      "\n",
      "Fold: 18  Epoch: 118  Training loss = 5.0900  Validation loss = 2.0895  \n",
      "\n",
      "Fold: 18  Epoch: 119  Training loss = 5.0888  Validation loss = 2.0893  \n",
      "\n",
      "Fold: 18  Epoch: 120  Training loss = 5.0880  Validation loss = 2.0891  \n",
      "\n",
      "Fold: 18  Epoch: 121  Training loss = 5.0869  Validation loss = 2.0889  \n",
      "\n",
      "Fold: 18  Epoch: 122  Training loss = 5.0857  Validation loss = 2.0887  \n",
      "\n",
      "Fold: 18  Epoch: 123  Training loss = 5.0845  Validation loss = 2.0885  \n",
      "\n",
      "Fold: 18  Epoch: 124  Training loss = 5.0836  Validation loss = 2.0883  \n",
      "\n",
      "Fold: 18  Epoch: 125  Training loss = 5.0829  Validation loss = 2.0881  \n",
      "\n",
      "Fold: 18  Epoch: 126  Training loss = 5.0823  Validation loss = 2.0880  \n",
      "\n",
      "Fold: 18  Epoch: 127  Training loss = 5.0810  Validation loss = 2.0878  \n",
      "\n",
      "Fold: 18  Epoch: 128  Training loss = 5.0798  Validation loss = 2.0876  \n",
      "\n",
      "Fold: 18  Epoch: 129  Training loss = 5.0789  Validation loss = 2.0874  \n",
      "\n",
      "Fold: 18  Epoch: 130  Training loss = 5.0782  Validation loss = 2.0872  \n",
      "\n",
      "Fold: 18  Epoch: 131  Training loss = 5.0768  Validation loss = 2.0870  \n",
      "\n",
      "Fold: 18  Epoch: 132  Training loss = 5.0759  Validation loss = 2.0868  \n",
      "\n",
      "Fold: 18  Epoch: 133  Training loss = 5.0750  Validation loss = 2.0866  \n",
      "\n",
      "Fold: 18  Epoch: 134  Training loss = 5.0741  Validation loss = 2.0865  \n",
      "\n",
      "Fold: 18  Epoch: 135  Training loss = 5.0727  Validation loss = 2.0862  \n",
      "\n",
      "Fold: 18  Epoch: 136  Training loss = 5.0719  Validation loss = 2.0860  \n",
      "\n",
      "Fold: 18  Epoch: 137  Training loss = 5.0711  Validation loss = 2.0859  \n",
      "\n",
      "Fold: 18  Epoch: 138  Training loss = 5.0704  Validation loss = 2.0857  \n",
      "\n",
      "Fold: 18  Epoch: 139  Training loss = 5.0693  Validation loss = 2.0855  \n",
      "\n",
      "Fold: 18  Epoch: 140  Training loss = 5.0685  Validation loss = 2.0853  \n",
      "\n",
      "Fold: 18  Epoch: 141  Training loss = 5.0679  Validation loss = 2.0852  \n",
      "\n",
      "Fold: 18  Epoch: 142  Training loss = 5.0670  Validation loss = 2.0850  \n",
      "\n",
      "Fold: 18  Epoch: 143  Training loss = 5.0663  Validation loss = 2.0848  \n",
      "\n",
      "Fold: 18  Epoch: 144  Training loss = 5.0657  Validation loss = 2.0846  \n",
      "\n",
      "Fold: 18  Epoch: 145  Training loss = 5.0648  Validation loss = 2.0845  \n",
      "\n",
      "Fold: 18  Epoch: 146  Training loss = 5.0642  Validation loss = 2.0843  \n",
      "\n",
      "Fold: 18  Epoch: 147  Training loss = 5.0633  Validation loss = 2.0842  \n",
      "\n",
      "Fold: 18  Epoch: 148  Training loss = 5.0627  Validation loss = 2.0840  \n",
      "\n",
      "Fold: 18  Epoch: 149  Training loss = 5.0620  Validation loss = 2.0838  \n",
      "\n",
      "Fold: 18  Epoch: 150  Training loss = 5.0612  Validation loss = 2.0836  \n",
      "\n",
      "Fold: 18  Epoch: 151  Training loss = 5.0601  Validation loss = 2.0834  \n",
      "\n",
      "Fold: 18  Epoch: 152  Training loss = 5.0591  Validation loss = 2.0832  \n",
      "\n",
      "Fold: 18  Epoch: 153  Training loss = 5.0580  Validation loss = 2.0830  \n",
      "\n",
      "Fold: 18  Epoch: 154  Training loss = 5.0574  Validation loss = 2.0828  \n",
      "\n",
      "Fold: 18  Epoch: 155  Training loss = 5.0561  Validation loss = 2.0827  \n",
      "\n",
      "Fold: 18  Epoch: 156  Training loss = 5.0550  Validation loss = 2.0825  \n",
      "\n",
      "Fold: 18  Epoch: 157  Training loss = 5.0537  Validation loss = 2.0823  \n",
      "\n",
      "Fold: 18  Epoch: 158  Training loss = 5.0526  Validation loss = 2.0821  \n",
      "\n",
      "Fold: 18  Epoch: 159  Training loss = 5.0519  Validation loss = 2.0820  \n",
      "\n",
      "Fold: 18  Epoch: 160  Training loss = 5.0510  Validation loss = 2.0818  \n",
      "\n",
      "Fold: 18  Epoch: 161  Training loss = 5.0502  Validation loss = 2.0816  \n",
      "\n",
      "Fold: 18  Epoch: 162  Training loss = 5.0490  Validation loss = 2.0815  \n",
      "\n",
      "Fold: 18  Epoch: 163  Training loss = 5.0480  Validation loss = 2.0813  \n",
      "\n",
      "Fold: 18  Epoch: 164  Training loss = 5.0473  Validation loss = 2.0812  \n",
      "\n",
      "Fold: 18  Epoch: 165  Training loss = 5.0467  Validation loss = 2.0810  \n",
      "\n",
      "Fold: 18  Epoch: 166  Training loss = 5.0456  Validation loss = 2.0808  \n",
      "\n",
      "Fold: 18  Epoch: 167  Training loss = 5.0446  Validation loss = 2.0806  \n",
      "\n",
      "Fold: 18  Epoch: 168  Training loss = 5.0436  Validation loss = 2.0805  \n",
      "\n",
      "Fold: 18  Epoch: 169  Training loss = 5.0427  Validation loss = 2.0802  \n",
      "\n",
      "Fold: 18  Epoch: 170  Training loss = 5.0419  Validation loss = 2.0801  \n",
      "\n",
      "Fold: 18  Epoch: 171  Training loss = 5.0411  Validation loss = 2.0799  \n",
      "\n",
      "Fold: 18  Epoch: 172  Training loss = 5.0406  Validation loss = 2.0797  \n",
      "\n",
      "Fold: 18  Epoch: 173  Training loss = 5.0398  Validation loss = 2.0796  \n",
      "\n",
      "Fold: 18  Epoch: 174  Training loss = 5.0393  Validation loss = 2.0794  \n",
      "\n",
      "Fold: 18  Epoch: 175  Training loss = 5.0385  Validation loss = 2.0792  \n",
      "\n",
      "Fold: 18  Epoch: 176  Training loss = 5.0381  Validation loss = 2.0791  \n",
      "\n",
      "Fold: 18  Epoch: 177  Training loss = 5.0373  Validation loss = 2.0789  \n",
      "\n",
      "Fold: 18  Epoch: 178  Training loss = 5.0365  Validation loss = 2.0787  \n",
      "\n",
      "Fold: 18  Epoch: 179  Training loss = 5.0360  Validation loss = 2.0786  \n",
      "\n",
      "Fold: 18  Epoch: 180  Training loss = 5.0353  Validation loss = 2.0784  \n",
      "\n",
      "Fold: 18  Epoch: 181  Training loss = 5.0346  Validation loss = 2.0783  \n",
      "\n",
      "Fold: 18  Epoch: 182  Training loss = 5.0339  Validation loss = 2.0781  \n",
      "\n",
      "Fold: 18  Epoch: 183  Training loss = 5.0331  Validation loss = 2.0779  \n",
      "\n",
      "Fold: 18  Epoch: 184  Training loss = 5.0325  Validation loss = 2.0777  \n",
      "\n",
      "Fold: 18  Epoch: 185  Training loss = 5.0319  Validation loss = 2.0775  \n",
      "\n",
      "Fold: 18  Epoch: 186  Training loss = 5.0313  Validation loss = 2.0774  \n",
      "\n",
      "Fold: 18  Epoch: 187  Training loss = 5.0305  Validation loss = 2.0772  \n",
      "\n",
      "Fold: 18  Epoch: 188  Training loss = 5.0298  Validation loss = 2.0770  \n",
      "\n",
      "Fold: 18  Epoch: 189  Training loss = 5.0292  Validation loss = 2.0769  \n",
      "\n",
      "Fold: 18  Epoch: 190  Training loss = 5.0285  Validation loss = 2.0767  \n",
      "\n",
      "Fold: 18  Epoch: 191  Training loss = 5.0278  Validation loss = 2.0765  \n",
      "\n",
      "Fold: 18  Epoch: 192  Training loss = 5.0273  Validation loss = 2.0764  \n",
      "\n",
      "Fold: 18  Epoch: 193  Training loss = 5.0266  Validation loss = 2.0762  \n",
      "\n",
      "Fold: 18  Epoch: 194  Training loss = 5.0259  Validation loss = 2.0760  \n",
      "\n",
      "Fold: 18  Epoch: 195  Training loss = 5.0252  Validation loss = 2.0759  \n",
      "\n",
      "Fold: 18  Epoch: 196  Training loss = 5.0246  Validation loss = 2.0757  \n",
      "\n",
      "Fold: 18  Epoch: 197  Training loss = 5.0240  Validation loss = 2.0756  \n",
      "\n",
      "Fold: 18  Epoch: 198  Training loss = 5.0235  Validation loss = 2.0755  \n",
      "\n",
      "Fold: 18  Epoch: 199  Training loss = 5.0230  Validation loss = 2.0753  \n",
      "\n",
      "Fold: 18  Epoch: 200  Training loss = 5.0224  Validation loss = 2.0752  \n",
      "\n",
      "Fold: 18  Epoch: 201  Training loss = 5.0219  Validation loss = 2.0750  \n",
      "\n",
      "Fold: 18  Epoch: 202  Training loss = 5.0212  Validation loss = 2.0748  \n",
      "\n",
      "Fold: 18  Epoch: 203  Training loss = 5.0205  Validation loss = 2.0747  \n",
      "\n",
      "Fold: 18  Epoch: 204  Training loss = 5.0200  Validation loss = 2.0745  \n",
      "\n",
      "Fold: 18  Epoch: 205  Training loss = 5.0193  Validation loss = 2.0743  \n",
      "\n",
      "Fold: 18  Epoch: 206  Training loss = 5.0187  Validation loss = 2.0742  \n",
      "\n",
      "Fold: 18  Epoch: 207  Training loss = 5.0180  Validation loss = 2.0740  \n",
      "\n",
      "Fold: 18  Epoch: 208  Training loss = 5.0174  Validation loss = 2.0739  \n",
      "\n",
      "Fold: 18  Epoch: 209  Training loss = 5.0167  Validation loss = 2.0737  \n",
      "\n",
      "Fold: 18  Epoch: 210  Training loss = 5.0160  Validation loss = 2.0735  \n",
      "\n",
      "Fold: 18  Epoch: 211  Training loss = 5.0155  Validation loss = 2.0734  \n",
      "\n",
      "Fold: 18  Epoch: 212  Training loss = 5.0150  Validation loss = 2.0732  \n",
      "\n",
      "Fold: 18  Epoch: 213  Training loss = 5.0143  Validation loss = 2.0730  \n",
      "\n",
      "Fold: 18  Epoch: 214  Training loss = 5.0138  Validation loss = 2.0729  \n",
      "\n",
      "Fold: 18  Epoch: 215  Training loss = 5.0132  Validation loss = 2.0727  \n",
      "\n",
      "Fold: 18  Epoch: 216  Training loss = 5.0125  Validation loss = 2.0726  \n",
      "\n",
      "Fold: 18  Epoch: 217  Training loss = 5.0120  Validation loss = 2.0724  \n",
      "\n",
      "Fold: 18  Epoch: 218  Training loss = 5.0113  Validation loss = 2.0723  \n",
      "\n",
      "Fold: 18  Epoch: 219  Training loss = 5.0106  Validation loss = 2.0721  \n",
      "\n",
      "Fold: 18  Epoch: 220  Training loss = 5.0101  Validation loss = 2.0719  \n",
      "\n",
      "Fold: 18  Epoch: 221  Training loss = 5.0095  Validation loss = 2.0717  \n",
      "\n",
      "Fold: 18  Epoch: 222  Training loss = 5.0089  Validation loss = 2.0716  \n",
      "\n",
      "Fold: 18  Epoch: 223  Training loss = 5.0082  Validation loss = 2.0714  \n",
      "\n",
      "Fold: 18  Epoch: 224  Training loss = 5.0075  Validation loss = 2.0712  \n",
      "\n",
      "Fold: 18  Epoch: 225  Training loss = 5.0069  Validation loss = 2.0710  \n",
      "\n",
      "Fold: 18  Epoch: 226  Training loss = 5.0063  Validation loss = 2.0709  \n",
      "\n",
      "Fold: 18  Epoch: 227  Training loss = 5.0056  Validation loss = 2.0707  \n",
      "\n",
      "Fold: 18  Epoch: 228  Training loss = 5.0050  Validation loss = 2.0705  \n",
      "\n",
      "Fold: 18  Epoch: 229  Training loss = 5.0043  Validation loss = 2.0703  \n",
      "\n",
      "Fold: 18  Epoch: 230  Training loss = 5.0038  Validation loss = 2.0702  \n",
      "\n",
      "Fold: 18  Epoch: 231  Training loss = 5.0032  Validation loss = 2.0701  \n",
      "\n",
      "Fold: 18  Epoch: 232  Training loss = 5.0027  Validation loss = 2.0699  \n",
      "\n",
      "Fold: 18  Epoch: 233  Training loss = 5.0021  Validation loss = 2.0698  \n",
      "\n",
      "Fold: 18  Epoch: 234  Training loss = 5.0014  Validation loss = 2.0696  \n",
      "\n",
      "Fold: 18  Epoch: 235  Training loss = 5.0008  Validation loss = 2.0694  \n",
      "\n",
      "Fold: 18  Epoch: 236  Training loss = 5.0003  Validation loss = 2.0693  \n",
      "\n",
      "Fold: 18  Epoch: 237  Training loss = 4.9996  Validation loss = 2.0691  \n",
      "\n",
      "Fold: 18  Epoch: 238  Training loss = 4.9990  Validation loss = 2.0689  \n",
      "\n",
      "Fold: 18  Epoch: 239  Training loss = 4.9983  Validation loss = 2.0687  \n",
      "\n",
      "Fold: 18  Epoch: 240  Training loss = 4.9977  Validation loss = 2.0686  \n",
      "\n",
      "Fold: 18  Epoch: 241  Training loss = 4.9971  Validation loss = 2.0684  \n",
      "\n",
      "Fold: 18  Epoch: 242  Training loss = 4.9964  Validation loss = 2.0682  \n",
      "\n",
      "Fold: 18  Epoch: 243  Training loss = 4.9957  Validation loss = 2.0680  \n",
      "\n",
      "Fold: 18  Epoch: 244  Training loss = 4.9951  Validation loss = 2.0679  \n",
      "\n",
      "Fold: 18  Epoch: 245  Training loss = 4.9945  Validation loss = 2.0677  \n",
      "\n",
      "Fold: 18  Epoch: 246  Training loss = 4.9938  Validation loss = 2.0675  \n",
      "\n",
      "Fold: 18  Epoch: 247  Training loss = 4.9931  Validation loss = 2.0673  \n",
      "\n",
      "Fold: 18  Epoch: 248  Training loss = 4.9925  Validation loss = 2.0671  \n",
      "\n",
      "Fold: 18  Epoch: 249  Training loss = 4.9919  Validation loss = 2.0670  \n",
      "\n",
      "Fold: 18  Epoch: 250  Training loss = 4.9911  Validation loss = 2.0668  \n",
      "\n",
      "Fold: 18  Epoch: 251  Training loss = 4.9904  Validation loss = 2.0666  \n",
      "\n",
      "Fold: 18  Epoch: 252  Training loss = 4.9899  Validation loss = 2.0665  \n",
      "\n",
      "Fold: 18  Epoch: 253  Training loss = 4.9891  Validation loss = 2.0663  \n",
      "\n",
      "Fold: 18  Epoch: 254  Training loss = 4.9885  Validation loss = 2.0661  \n",
      "\n",
      "Fold: 18  Epoch: 255  Training loss = 4.9877  Validation loss = 2.0659  \n",
      "\n",
      "Fold: 18  Epoch: 256  Training loss = 4.9872  Validation loss = 2.0658  \n",
      "\n",
      "Fold: 18  Epoch: 257  Training loss = 4.9865  Validation loss = 2.0657  \n",
      "\n",
      "Fold: 18  Epoch: 258  Training loss = 4.9859  Validation loss = 2.0655  \n",
      "\n",
      "Fold: 18  Epoch: 259  Training loss = 4.9852  Validation loss = 2.0654  \n",
      "\n",
      "Fold: 18  Epoch: 260  Training loss = 4.9848  Validation loss = 2.0653  \n",
      "\n",
      "Fold: 18  Epoch: 261  Training loss = 4.9841  Validation loss = 2.0651  \n",
      "\n",
      "Fold: 18  Epoch: 262  Training loss = 4.9835  Validation loss = 2.0650  \n",
      "\n",
      "Fold: 18  Epoch: 263  Training loss = 4.9828  Validation loss = 2.0648  \n",
      "\n",
      "Fold: 18  Epoch: 264  Training loss = 4.9816  Validation loss = 2.0647  \n",
      "\n",
      "Fold: 18  Epoch: 265  Training loss = 4.9809  Validation loss = 2.0645  \n",
      "\n",
      "Fold: 18  Epoch: 266  Training loss = 4.9796  Validation loss = 2.0643  \n",
      "\n",
      "Fold: 18  Epoch: 267  Training loss = 4.9787  Validation loss = 2.0642  \n",
      "\n",
      "Fold: 18  Epoch: 268  Training loss = 4.9780  Validation loss = 2.0640  \n",
      "\n",
      "Fold: 18  Epoch: 269  Training loss = 4.9774  Validation loss = 2.0639  \n",
      "\n",
      "Fold: 18  Epoch: 270  Training loss = 4.9764  Validation loss = 2.0638  \n",
      "\n",
      "Fold: 18  Epoch: 271  Training loss = 4.9754  Validation loss = 2.0637  \n",
      "\n",
      "Fold: 18  Epoch: 272  Training loss = 4.9746  Validation loss = 2.0635  \n",
      "\n",
      "Fold: 18  Epoch: 273  Training loss = 4.9740  Validation loss = 2.0633  \n",
      "\n",
      "Fold: 18  Epoch: 274  Training loss = 4.9725  Validation loss = 2.0631  \n",
      "\n",
      "Fold: 18  Epoch: 275  Training loss = 4.9705  Validation loss = 2.0629  \n",
      "\n",
      "Fold: 18  Epoch: 276  Training loss = 4.9699  Validation loss = 2.0628  \n",
      "\n",
      "Fold: 18  Epoch: 277  Training loss = 4.9687  Validation loss = 2.0626  \n",
      "\n",
      "Fold: 18  Epoch: 278  Training loss = 4.9676  Validation loss = 2.0624  \n",
      "\n",
      "Fold: 18  Epoch: 279  Training loss = 4.9664  Validation loss = 2.0623  \n",
      "\n",
      "Fold: 18  Epoch: 280  Training loss = 4.9657  Validation loss = 2.0622  \n",
      "\n",
      "Fold: 18  Epoch: 281  Training loss = 4.9650  Validation loss = 2.0620  \n",
      "\n",
      "Fold: 18  Epoch: 282  Training loss = 4.9642  Validation loss = 2.0618  \n",
      "\n",
      "Fold: 18  Epoch: 283  Training loss = 4.9633  Validation loss = 2.0616  \n",
      "\n",
      "Fold: 18  Epoch: 284  Training loss = 4.9626  Validation loss = 2.0615  \n",
      "\n",
      "Fold: 18  Epoch: 285  Training loss = 4.9621  Validation loss = 2.0613  \n",
      "\n",
      "Fold: 18  Epoch: 286  Training loss = 4.9613  Validation loss = 2.0612  \n",
      "\n",
      "Fold: 18  Epoch: 287  Training loss = 4.9606  Validation loss = 2.0610  \n",
      "\n",
      "Fold: 18  Epoch: 288  Training loss = 4.9599  Validation loss = 2.0608  \n",
      "\n",
      "Fold: 18  Epoch: 289  Training loss = 4.9591  Validation loss = 2.0606  \n",
      "\n",
      "Fold: 18  Epoch: 290  Training loss = 4.9586  Validation loss = 2.0605  \n",
      "\n",
      "Fold: 18  Epoch: 291  Training loss = 4.9581  Validation loss = 2.0604  \n",
      "\n",
      "Fold: 18  Epoch: 292  Training loss = 4.9575  Validation loss = 2.0602  \n",
      "\n",
      "Fold: 18  Epoch: 293  Training loss = 4.9569  Validation loss = 2.0601  \n",
      "\n",
      "Fold: 18  Epoch: 294  Training loss = 4.9561  Validation loss = 2.0598  \n",
      "\n",
      "Fold: 18  Epoch: 295  Training loss = 4.9556  Validation loss = 2.0597  \n",
      "\n",
      "Fold: 18  Epoch: 296  Training loss = 4.9549  Validation loss = 2.0596  \n",
      "\n",
      "Fold: 18  Epoch: 297  Training loss = 4.9543  Validation loss = 2.0594  \n",
      "\n",
      "Fold: 18  Epoch: 298  Training loss = 4.9538  Validation loss = 2.0593  \n",
      "\n",
      "Fold: 18  Epoch: 299  Training loss = 4.9531  Validation loss = 2.0591  \n",
      "\n",
      "Fold: 18  Epoch: 300  Training loss = 4.9525  Validation loss = 2.0589  \n",
      "\n",
      "Fold: 18  Epoch: 301  Training loss = 4.9519  Validation loss = 2.0588  \n",
      "\n",
      "Fold: 18  Epoch: 302  Training loss = 4.9514  Validation loss = 2.0586  \n",
      "\n",
      "Fold: 18  Epoch: 303  Training loss = 4.9509  Validation loss = 2.0585  \n",
      "\n",
      "Fold: 18  Epoch: 304  Training loss = 4.9502  Validation loss = 2.0583  \n",
      "\n",
      "Fold: 18  Epoch: 305  Training loss = 4.9498  Validation loss = 2.0582  \n",
      "\n",
      "Fold: 18  Epoch: 306  Training loss = 4.9494  Validation loss = 2.0581  \n",
      "\n",
      "Fold: 18  Epoch: 307  Training loss = 4.9488  Validation loss = 2.0580  \n",
      "\n",
      "Fold: 18  Epoch: 308  Training loss = 4.9482  Validation loss = 2.0579  \n",
      "\n",
      "Fold: 18  Epoch: 309  Training loss = 4.9476  Validation loss = 2.0577  \n",
      "\n",
      "Fold: 18  Epoch: 310  Training loss = 4.9470  Validation loss = 2.0576  \n",
      "\n",
      "Fold: 18  Epoch: 311  Training loss = 4.9463  Validation loss = 2.0574  \n",
      "\n",
      "Fold: 18  Epoch: 312  Training loss = 4.9458  Validation loss = 2.0572  \n",
      "\n",
      "Fold: 18  Epoch: 313  Training loss = 4.9453  Validation loss = 2.0571  \n",
      "\n",
      "Fold: 18  Epoch: 314  Training loss = 4.9446  Validation loss = 2.0569  \n",
      "\n",
      "Fold: 18  Epoch: 315  Training loss = 4.9440  Validation loss = 2.0568  \n",
      "\n",
      "Fold: 18  Epoch: 316  Training loss = 4.9435  Validation loss = 2.0566  \n",
      "\n",
      "Fold: 18  Epoch: 317  Training loss = 4.9430  Validation loss = 2.0565  \n",
      "\n",
      "Fold: 18  Epoch: 318  Training loss = 4.9424  Validation loss = 2.0563  \n",
      "\n",
      "Fold: 18  Epoch: 319  Training loss = 4.9418  Validation loss = 2.0562  \n",
      "\n",
      "Fold: 18  Epoch: 320  Training loss = 4.9412  Validation loss = 2.0560  \n",
      "\n",
      "Fold: 18  Epoch: 321  Training loss = 4.9406  Validation loss = 2.0559  \n",
      "\n",
      "Fold: 18  Epoch: 322  Training loss = 4.9401  Validation loss = 2.0558  \n",
      "\n",
      "Fold: 18  Epoch: 323  Training loss = 4.9394  Validation loss = 2.0556  \n",
      "\n",
      "Fold: 18  Epoch: 324  Training loss = 4.9389  Validation loss = 2.0555  \n",
      "\n",
      "Fold: 18  Epoch: 325  Training loss = 4.9382  Validation loss = 2.0553  \n",
      "\n",
      "Fold: 18  Epoch: 326  Training loss = 4.9377  Validation loss = 2.0551  \n",
      "\n",
      "Fold: 18  Epoch: 327  Training loss = 4.9372  Validation loss = 2.0550  \n",
      "\n",
      "Fold: 18  Epoch: 328  Training loss = 4.9365  Validation loss = 2.0549  \n",
      "\n",
      "Fold: 18  Epoch: 329  Training loss = 4.9360  Validation loss = 2.0547  \n",
      "\n",
      "Fold: 18  Epoch: 330  Training loss = 4.9354  Validation loss = 2.0546  \n",
      "\n",
      "Fold: 18  Epoch: 331  Training loss = 4.9347  Validation loss = 2.0544  \n",
      "\n",
      "Fold: 18  Epoch: 332  Training loss = 4.9342  Validation loss = 2.0543  \n",
      "\n",
      "Fold: 18  Epoch: 333  Training loss = 4.9336  Validation loss = 2.0541  \n",
      "\n",
      "Fold: 18  Epoch: 334  Training loss = 4.9330  Validation loss = 2.0540  \n",
      "\n",
      "Fold: 18  Epoch: 335  Training loss = 4.9326  Validation loss = 2.0539  \n",
      "\n",
      "Fold: 18  Epoch: 336  Training loss = 4.9321  Validation loss = 2.0537  \n",
      "\n",
      "Fold: 18  Epoch: 337  Training loss = 4.9316  Validation loss = 2.0536  \n",
      "\n",
      "Fold: 18  Epoch: 338  Training loss = 4.9311  Validation loss = 2.0535  \n",
      "\n",
      "Fold: 18  Epoch: 339  Training loss = 4.9305  Validation loss = 2.0533  \n",
      "\n",
      "Fold: 18  Epoch: 340  Training loss = 4.9298  Validation loss = 2.0532  \n",
      "\n",
      "Fold: 18  Epoch: 341  Training loss = 4.9293  Validation loss = 2.0530  \n",
      "\n",
      "Fold: 18  Epoch: 342  Training loss = 4.9287  Validation loss = 2.0529  \n",
      "\n",
      "Fold: 18  Epoch: 343  Training loss = 4.9281  Validation loss = 2.0527  \n",
      "\n",
      "Fold: 18  Epoch: 344  Training loss = 4.9277  Validation loss = 2.0526  \n",
      "\n",
      "Fold: 18  Epoch: 345  Training loss = 4.9271  Validation loss = 2.0525  \n",
      "\n",
      "Fold: 18  Epoch: 346  Training loss = 4.9265  Validation loss = 2.0523  \n",
      "\n",
      "Fold: 18  Epoch: 347  Training loss = 4.9258  Validation loss = 2.0522  \n",
      "\n",
      "Fold: 18  Epoch: 348  Training loss = 4.9253  Validation loss = 2.0521  \n",
      "\n",
      "Fold: 18  Epoch: 349  Training loss = 4.9242  Validation loss = 2.0519  \n",
      "\n",
      "Fold: 18  Epoch: 350  Training loss = 4.9181  Validation loss = 2.0518  \n",
      "\n",
      "Fold: 18  Epoch: 351  Training loss = 4.9175  Validation loss = 2.0517  \n",
      "\n",
      "Fold: 18  Epoch: 352  Training loss = 4.9166  Validation loss = 2.0515  \n",
      "\n",
      "Fold: 18  Epoch: 353  Training loss = 4.9150  Validation loss = 2.0514  \n",
      "\n",
      "Fold: 18  Epoch: 354  Training loss = 4.9144  Validation loss = 2.0512  \n",
      "\n",
      "Fold: 18  Epoch: 355  Training loss = 4.9140  Validation loss = 2.0511  \n",
      "\n",
      "Fold: 18  Epoch: 356  Training loss = 4.9134  Validation loss = 2.0510  \n",
      "\n",
      "Fold: 18  Epoch: 357  Training loss = 4.9130  Validation loss = 2.0509  \n",
      "\n",
      "Fold: 18  Epoch: 358  Training loss = 4.9124  Validation loss = 2.0507  \n",
      "\n",
      "Fold: 18  Epoch: 359  Training loss = 4.9119  Validation loss = 2.0506  \n",
      "\n",
      "Fold: 18  Epoch: 360  Training loss = 4.9113  Validation loss = 2.0504  \n",
      "\n",
      "Fold: 18  Epoch: 361  Training loss = 4.9108  Validation loss = 2.0503  \n",
      "\n",
      "Fold: 18  Epoch: 362  Training loss = 4.9102  Validation loss = 2.0502  \n",
      "\n",
      "Fold: 18  Epoch: 363  Training loss = 4.9096  Validation loss = 2.0500  \n",
      "\n",
      "Fold: 18  Epoch: 364  Training loss = 4.9091  Validation loss = 2.0499  \n",
      "\n",
      "Fold: 18  Epoch: 365  Training loss = 4.9085  Validation loss = 2.0498  \n",
      "\n",
      "Fold: 18  Epoch: 366  Training loss = 4.9079  Validation loss = 2.0496  \n",
      "\n",
      "Fold: 18  Epoch: 367  Training loss = 4.9073  Validation loss = 2.0495  \n",
      "\n",
      "Fold: 18  Epoch: 368  Training loss = 4.9068  Validation loss = 2.0493  \n",
      "\n",
      "Fold: 18  Epoch: 369  Training loss = 4.9063  Validation loss = 2.0492  \n",
      "\n",
      "Fold: 18  Epoch: 370  Training loss = 4.9057  Validation loss = 2.0490  \n",
      "\n",
      "Fold: 18  Epoch: 371  Training loss = 4.9051  Validation loss = 2.0489  \n",
      "\n",
      "Fold: 18  Epoch: 372  Training loss = 4.9046  Validation loss = 2.0488  \n",
      "\n",
      "Fold: 18  Epoch: 373  Training loss = 4.9042  Validation loss = 2.0486  \n",
      "\n",
      "Fold: 18  Epoch: 374  Training loss = 4.9037  Validation loss = 2.0485  \n",
      "\n",
      "Fold: 18  Epoch: 375  Training loss = 4.9030  Validation loss = 2.0484  \n",
      "\n",
      "Fold: 18  Epoch: 376  Training loss = 4.9024  Validation loss = 2.0482  \n",
      "\n",
      "Fold: 18  Epoch: 377  Training loss = 4.9018  Validation loss = 2.0481  \n",
      "\n",
      "Fold: 18  Epoch: 378  Training loss = 4.9012  Validation loss = 2.0479  \n",
      "\n",
      "Fold: 18  Epoch: 379  Training loss = 4.9006  Validation loss = 2.0478  \n",
      "\n",
      "Fold: 18  Epoch: 380  Training loss = 4.9000  Validation loss = 2.0476  \n",
      "\n",
      "Fold: 18  Epoch: 381  Training loss = 4.8994  Validation loss = 2.0475  \n",
      "\n",
      "Fold: 18  Epoch: 382  Training loss = 4.8988  Validation loss = 2.0473  \n",
      "\n",
      "Fold: 18  Epoch: 383  Training loss = 4.8983  Validation loss = 2.0472  \n",
      "\n",
      "Fold: 18  Epoch: 384  Training loss = 4.8978  Validation loss = 2.0471  \n",
      "\n",
      "Fold: 18  Epoch: 385  Training loss = 4.8972  Validation loss = 2.0469  \n",
      "\n",
      "Fold: 18  Epoch: 386  Training loss = 4.8967  Validation loss = 2.0468  \n",
      "\n",
      "Fold: 18  Epoch: 387  Training loss = 4.8960  Validation loss = 2.0466  \n",
      "\n",
      "Fold: 18  Epoch: 388  Training loss = 4.8954  Validation loss = 2.0465  \n",
      "\n",
      "Fold: 18  Epoch: 389  Training loss = 4.8949  Validation loss = 2.0464  \n",
      "\n",
      "Fold: 18  Epoch: 390  Training loss = 4.8943  Validation loss = 2.0462  \n",
      "\n",
      "Fold: 18  Epoch: 391  Training loss = 4.8938  Validation loss = 2.0461  \n",
      "\n",
      "Fold: 18  Epoch: 392  Training loss = 4.8933  Validation loss = 2.0460  \n",
      "\n",
      "Fold: 18  Epoch: 393  Training loss = 4.8927  Validation loss = 2.0458  \n",
      "\n",
      "Fold: 18  Epoch: 394  Training loss = 4.8922  Validation loss = 2.0457  \n",
      "\n",
      "Fold: 18  Epoch: 395  Training loss = 4.8916  Validation loss = 2.0456  \n",
      "\n",
      "Fold: 18  Epoch: 396  Training loss = 4.8910  Validation loss = 2.0454  \n",
      "\n",
      "Fold: 18  Epoch: 397  Training loss = 4.8905  Validation loss = 2.0453  \n",
      "\n",
      "Fold: 18  Epoch: 398  Training loss = 4.8900  Validation loss = 2.0452  \n",
      "\n",
      "Fold: 18  Epoch: 399  Training loss = 4.8893  Validation loss = 2.0450  \n",
      "\n",
      "Fold: 18  Epoch: 400  Training loss = 4.8887  Validation loss = 2.0449  \n",
      "\n",
      "Fold: 18  Epoch: 401  Training loss = 4.8883  Validation loss = 2.0448  \n",
      "\n",
      "Fold: 18  Epoch: 402  Training loss = 4.8877  Validation loss = 2.0446  \n",
      "\n",
      "Fold: 18  Epoch: 403  Training loss = 4.8871  Validation loss = 2.0445  \n",
      "\n",
      "Fold: 18  Epoch: 404  Training loss = 4.8866  Validation loss = 2.0444  \n",
      "\n",
      "Fold: 18  Epoch: 405  Training loss = 4.8861  Validation loss = 2.0442  \n",
      "\n",
      "Fold: 18  Epoch: 406  Training loss = 4.8855  Validation loss = 2.0441  \n",
      "\n",
      "Fold: 18  Epoch: 407  Training loss = 4.8849  Validation loss = 2.0439  \n",
      "\n",
      "Fold: 18  Epoch: 408  Training loss = 4.8843  Validation loss = 2.0438  \n",
      "\n",
      "Fold: 18  Epoch: 409  Training loss = 4.8839  Validation loss = 2.0437  \n",
      "\n",
      "Fold: 18  Epoch: 410  Training loss = 4.8834  Validation loss = 2.0435  \n",
      "\n",
      "Fold: 18  Epoch: 411  Training loss = 4.8829  Validation loss = 2.0434  \n",
      "\n",
      "Fold: 18  Epoch: 412  Training loss = 4.8823  Validation loss = 2.0433  \n",
      "\n",
      "Fold: 18  Epoch: 413  Training loss = 4.8817  Validation loss = 2.0431  \n",
      "\n",
      "Fold: 18  Epoch: 414  Training loss = 4.8811  Validation loss = 2.0430  \n",
      "\n",
      "Fold: 18  Epoch: 415  Training loss = 4.8806  Validation loss = 2.0429  \n",
      "\n",
      "Fold: 18  Epoch: 416  Training loss = 4.8800  Validation loss = 2.0427  \n",
      "\n",
      "Fold: 18  Epoch: 417  Training loss = 4.8794  Validation loss = 2.0426  \n",
      "\n",
      "Fold: 18  Epoch: 418  Training loss = 4.8789  Validation loss = 2.0424  \n",
      "\n",
      "Fold: 18  Epoch: 419  Training loss = 4.8783  Validation loss = 2.0423  \n",
      "\n",
      "Fold: 18  Epoch: 420  Training loss = 4.8778  Validation loss = 2.0422  \n",
      "\n",
      "Fold: 18  Epoch: 421  Training loss = 4.8772  Validation loss = 2.0420  \n",
      "\n",
      "Fold: 18  Epoch: 422  Training loss = 4.8768  Validation loss = 2.0419  \n",
      "\n",
      "Fold: 18  Epoch: 423  Training loss = 4.8762  Validation loss = 2.0418  \n",
      "\n",
      "Fold: 18  Epoch: 424  Training loss = 4.8757  Validation loss = 2.0416  \n",
      "\n",
      "Fold: 18  Epoch: 425  Training loss = 4.8751  Validation loss = 2.0415  \n",
      "\n",
      "Fold: 18  Epoch: 426  Training loss = 4.8745  Validation loss = 2.0414  \n",
      "\n",
      "Fold: 18  Epoch: 427  Training loss = 4.8739  Validation loss = 2.0412  \n",
      "\n",
      "Fold: 18  Epoch: 428  Training loss = 4.8735  Validation loss = 2.0411  \n",
      "\n",
      "Fold: 18  Epoch: 429  Training loss = 4.8728  Validation loss = 2.0410  \n",
      "\n",
      "Fold: 18  Epoch: 430  Training loss = 4.8722  Validation loss = 2.0408  \n",
      "\n",
      "Fold: 18  Epoch: 431  Training loss = 4.8717  Validation loss = 2.0407  \n",
      "\n",
      "Fold: 18  Epoch: 432  Training loss = 4.8712  Validation loss = 2.0406  \n",
      "\n",
      "Fold: 18  Epoch: 433  Training loss = 4.8706  Validation loss = 2.0404  \n",
      "\n",
      "Fold: 18  Epoch: 434  Training loss = 4.8700  Validation loss = 2.0403  \n",
      "\n",
      "Fold: 18  Epoch: 435  Training loss = 4.8695  Validation loss = 2.0401  \n",
      "\n",
      "Fold: 18  Epoch: 436  Training loss = 4.8691  Validation loss = 2.0400  \n",
      "\n",
      "Fold: 18  Epoch: 437  Training loss = 4.8685  Validation loss = 2.0399  \n",
      "\n",
      "Fold: 18  Epoch: 438  Training loss = 4.8679  Validation loss = 2.0398  \n",
      "\n",
      "Fold: 18  Epoch: 439  Training loss = 4.8674  Validation loss = 2.0397  \n",
      "\n",
      "Fold: 18  Epoch: 440  Training loss = 4.8668  Validation loss = 2.0395  \n",
      "\n",
      "Fold: 18  Epoch: 441  Training loss = 4.8663  Validation loss = 2.0394  \n",
      "\n",
      "Fold: 18  Epoch: 442  Training loss = 4.8656  Validation loss = 2.0393  \n",
      "\n",
      "Fold: 18  Epoch: 443  Training loss = 4.8651  Validation loss = 2.0391  \n",
      "\n",
      "Fold: 18  Epoch: 444  Training loss = 4.8646  Validation loss = 2.0390  \n",
      "\n",
      "Fold: 18  Epoch: 445  Training loss = 4.8639  Validation loss = 2.0389  \n",
      "\n",
      "Fold: 18  Epoch: 446  Training loss = 4.8633  Validation loss = 2.0387  \n",
      "\n",
      "Fold: 18  Epoch: 447  Training loss = 4.8629  Validation loss = 2.0386  \n",
      "\n",
      "Fold: 18  Epoch: 448  Training loss = 4.8623  Validation loss = 2.0385  \n",
      "\n",
      "Fold: 18  Epoch: 449  Training loss = 4.8617  Validation loss = 2.0383  \n",
      "\n",
      "Fold: 18  Epoch: 450  Training loss = 4.8611  Validation loss = 2.0382  \n",
      "\n",
      "Fold: 18  Epoch: 451  Training loss = 4.8606  Validation loss = 2.0381  \n",
      "\n",
      "Fold: 18  Epoch: 452  Training loss = 4.8601  Validation loss = 2.0379  \n",
      "\n",
      "Fold: 18  Epoch: 453  Training loss = 4.8596  Validation loss = 2.0378  \n",
      "\n",
      "Fold: 18  Epoch: 454  Training loss = 4.8592  Validation loss = 2.0377  \n",
      "\n",
      "Fold: 18  Epoch: 455  Training loss = 4.8587  Validation loss = 2.0376  \n",
      "\n",
      "Fold: 18  Epoch: 456  Training loss = 4.8582  Validation loss = 2.0375  \n",
      "\n",
      "Fold: 18  Epoch: 457  Training loss = 4.8577  Validation loss = 2.0374  \n",
      "\n",
      "Fold: 18  Epoch: 458  Training loss = 4.8570  Validation loss = 2.0372  \n",
      "\n",
      "Fold: 18  Epoch: 459  Training loss = 4.8565  Validation loss = 2.0371  \n",
      "\n",
      "Fold: 18  Epoch: 460  Training loss = 4.8559  Validation loss = 2.0370  \n",
      "\n",
      "Fold: 18  Epoch: 461  Training loss = 4.8555  Validation loss = 2.0369  \n",
      "\n",
      "Fold: 18  Epoch: 462  Training loss = 4.8551  Validation loss = 2.0368  \n",
      "\n",
      "Fold: 18  Epoch: 463  Training loss = 4.8545  Validation loss = 2.0367  \n",
      "\n",
      "Fold: 18  Epoch: 464  Training loss = 4.8542  Validation loss = 2.0366  \n",
      "\n",
      "Fold: 18  Epoch: 465  Training loss = 4.8536  Validation loss = 2.0365  \n",
      "\n",
      "Fold: 18  Epoch: 466  Training loss = 4.8531  Validation loss = 2.0364  \n",
      "\n",
      "Fold: 18  Epoch: 467  Training loss = 4.8526  Validation loss = 2.0362  \n",
      "\n",
      "Fold: 18  Epoch: 468  Training loss = 4.8521  Validation loss = 2.0361  \n",
      "\n",
      "Fold: 18  Epoch: 469  Training loss = 4.8516  Validation loss = 2.0360  \n",
      "\n",
      "Fold: 18  Epoch: 470  Training loss = 4.8509  Validation loss = 2.0359  \n",
      "\n",
      "Fold: 18  Epoch: 471  Training loss = 4.8503  Validation loss = 2.0357  \n",
      "\n",
      "Fold: 18  Epoch: 472  Training loss = 4.8497  Validation loss = 2.0356  \n",
      "\n",
      "Fold: 18  Epoch: 473  Training loss = 4.8491  Validation loss = 2.0354  \n",
      "\n",
      "Fold: 18  Epoch: 474  Training loss = 4.8484  Validation loss = 2.0353  \n",
      "\n",
      "Fold: 18  Epoch: 475  Training loss = 4.8478  Validation loss = 2.0351  \n",
      "\n",
      "Fold: 18  Epoch: 476  Training loss = 4.8472  Validation loss = 2.0350  \n",
      "\n",
      "Fold: 18  Epoch: 477  Training loss = 4.8467  Validation loss = 2.0349  \n",
      "\n",
      "Fold: 18  Epoch: 478  Training loss = 4.8462  Validation loss = 2.0348  \n",
      "\n",
      "Fold: 18  Epoch: 479  Training loss = 4.8457  Validation loss = 2.0346  \n",
      "\n",
      "Fold: 18  Epoch: 480  Training loss = 4.8451  Validation loss = 2.0345  \n",
      "\n",
      "Fold: 18  Epoch: 481  Training loss = 4.8445  Validation loss = 2.0344  \n",
      "\n",
      "Fold: 18  Epoch: 482  Training loss = 4.8439  Validation loss = 2.0343  \n",
      "\n",
      "Fold: 18  Epoch: 483  Training loss = 4.8434  Validation loss = 2.0341  \n",
      "\n",
      "Fold: 18  Epoch: 484  Training loss = 4.8429  Validation loss = 2.0340  \n",
      "\n",
      "Fold: 18  Epoch: 485  Training loss = 4.8424  Validation loss = 2.0339  \n",
      "\n",
      "Fold: 18  Epoch: 486  Training loss = 4.8418  Validation loss = 2.0338  \n",
      "\n",
      "Fold: 18  Epoch: 487  Training loss = 4.8412  Validation loss = 2.0337  \n",
      "\n",
      "Fold: 18  Epoch: 488  Training loss = 4.8408  Validation loss = 2.0336  \n",
      "\n",
      "Fold: 18  Epoch: 489  Training loss = 4.8402  Validation loss = 2.0335  \n",
      "\n",
      "Fold: 18  Epoch: 490  Training loss = 4.8397  Validation loss = 2.0333  \n",
      "\n",
      "Fold: 18  Epoch: 491  Training loss = 4.8392  Validation loss = 2.0332  \n",
      "\n",
      "Fold: 18  Epoch: 492  Training loss = 4.8387  Validation loss = 2.0331  \n",
      "\n",
      "Fold: 18  Epoch: 493  Training loss = 4.8381  Validation loss = 2.0330  \n",
      "\n",
      "Fold: 18  Epoch: 494  Training loss = 4.8374  Validation loss = 2.0328  \n",
      "\n",
      "Fold: 18  Epoch: 495  Training loss = 4.8369  Validation loss = 2.0327  \n",
      "\n",
      "Fold: 18  Epoch: 496  Training loss = 4.8363  Validation loss = 2.0326  \n",
      "\n",
      "Fold: 18  Epoch: 497  Training loss = 4.8357  Validation loss = 2.0324  \n",
      "\n",
      "Fold: 18  Epoch: 498  Training loss = 4.8352  Validation loss = 2.0323  \n",
      "\n",
      "Fold: 18  Epoch: 499  Training loss = 4.8348  Validation loss = 2.0322  \n",
      "\n",
      "Fold: 18  Epoch: 500  Training loss = 4.8342  Validation loss = 2.0321  \n",
      "\n",
      "Check model:  Fold: 18  Optimal epoch: 500  \n",
      "\n",
      "Fold: 19  Epoch: 1  Training loss = 4.8494  Validation loss = 1.4278  \n",
      "\n",
      "Fold: 19  Epoch: 2  Training loss = 4.8489  Validation loss = 1.4273  \n",
      "\n",
      "Fold: 19  Epoch: 3  Training loss = 4.8483  Validation loss = 1.4268  \n",
      "\n",
      "Fold: 19  Epoch: 4  Training loss = 4.8476  Validation loss = 1.4262  \n",
      "\n",
      "Fold: 19  Epoch: 5  Training loss = 4.8470  Validation loss = 1.4256  \n",
      "\n",
      "Fold: 19  Epoch: 6  Training loss = 4.8464  Validation loss = 1.4250  \n",
      "\n",
      "Fold: 19  Epoch: 7  Training loss = 4.8457  Validation loss = 1.4244  \n",
      "\n",
      "Fold: 19  Epoch: 8  Training loss = 4.8452  Validation loss = 1.4239  \n",
      "\n",
      "Fold: 19  Epoch: 9  Training loss = 4.8446  Validation loss = 1.4233  \n",
      "\n",
      "Fold: 19  Epoch: 10  Training loss = 4.8440  Validation loss = 1.4229  \n",
      "\n",
      "Fold: 19  Epoch: 11  Training loss = 4.8435  Validation loss = 1.4224  \n",
      "\n",
      "Fold: 19  Epoch: 12  Training loss = 4.8430  Validation loss = 1.4220  \n",
      "\n",
      "Fold: 19  Epoch: 13  Training loss = 4.8425  Validation loss = 1.4215  \n",
      "\n",
      "Fold: 19  Epoch: 14  Training loss = 4.8420  Validation loss = 1.4211  \n",
      "\n",
      "Fold: 19  Epoch: 15  Training loss = 4.8414  Validation loss = 1.4205  \n",
      "\n",
      "Fold: 19  Epoch: 16  Training loss = 4.8410  Validation loss = 1.4201  \n",
      "\n",
      "Fold: 19  Epoch: 17  Training loss = 4.8404  Validation loss = 1.4196  \n",
      "\n",
      "Fold: 19  Epoch: 18  Training loss = 4.8398  Validation loss = 1.4190  \n",
      "\n",
      "Fold: 19  Epoch: 19  Training loss = 4.8392  Validation loss = 1.4185  \n",
      "\n",
      "Fold: 19  Epoch: 20  Training loss = 4.8387  Validation loss = 1.4181  \n",
      "\n",
      "Fold: 19  Epoch: 21  Training loss = 4.8381  Validation loss = 1.4175  \n",
      "\n",
      "Fold: 19  Epoch: 22  Training loss = 4.8375  Validation loss = 1.4170  \n",
      "\n",
      "Fold: 19  Epoch: 23  Training loss = 4.8371  Validation loss = 1.4165  \n",
      "\n",
      "Fold: 19  Epoch: 24  Training loss = 4.8366  Validation loss = 1.4161  \n",
      "\n",
      "Fold: 19  Epoch: 25  Training loss = 4.8360  Validation loss = 1.4156  \n",
      "\n",
      "Fold: 19  Epoch: 26  Training loss = 4.8353  Validation loss = 1.4149  \n",
      "\n",
      "Fold: 19  Epoch: 27  Training loss = 4.8347  Validation loss = 1.4144  \n",
      "\n",
      "Fold: 19  Epoch: 28  Training loss = 4.8342  Validation loss = 1.4139  \n",
      "\n",
      "Fold: 19  Epoch: 29  Training loss = 4.8336  Validation loss = 1.4134  \n",
      "\n",
      "Fold: 19  Epoch: 30  Training loss = 4.8329  Validation loss = 1.4127  \n",
      "\n",
      "Fold: 19  Epoch: 31  Training loss = 4.8323  Validation loss = 1.4122  \n",
      "\n",
      "Fold: 19  Epoch: 32  Training loss = 4.8318  Validation loss = 1.4118  \n",
      "\n",
      "Fold: 19  Epoch: 33  Training loss = 4.8313  Validation loss = 1.4113  \n",
      "\n",
      "Fold: 19  Epoch: 34  Training loss = 4.8308  Validation loss = 1.4109  \n",
      "\n",
      "Fold: 19  Epoch: 35  Training loss = 4.8303  Validation loss = 1.4104  \n",
      "\n",
      "Fold: 19  Epoch: 36  Training loss = 4.8296  Validation loss = 1.4098  \n",
      "\n",
      "Fold: 19  Epoch: 37  Training loss = 4.8290  Validation loss = 1.4093  \n",
      "\n",
      "Fold: 19  Epoch: 38  Training loss = 4.8284  Validation loss = 1.4087  \n",
      "\n",
      "Fold: 19  Epoch: 39  Training loss = 4.8276  Validation loss = 1.4080  \n",
      "\n",
      "Fold: 19  Epoch: 40  Training loss = 4.8270  Validation loss = 1.4074  \n",
      "\n",
      "Fold: 19  Epoch: 41  Training loss = 4.8265  Validation loss = 1.4070  \n",
      "\n",
      "Fold: 19  Epoch: 42  Training loss = 4.8259  Validation loss = 1.4064  \n",
      "\n",
      "Fold: 19  Epoch: 43  Training loss = 4.8253  Validation loss = 1.4059  \n",
      "\n",
      "Fold: 19  Epoch: 44  Training loss = 4.8248  Validation loss = 1.4054  \n",
      "\n",
      "Fold: 19  Epoch: 45  Training loss = 4.8244  Validation loss = 1.4050  \n",
      "\n",
      "Fold: 19  Epoch: 46  Training loss = 4.8238  Validation loss = 1.4045  \n",
      "\n",
      "Fold: 19  Epoch: 47  Training loss = 4.8233  Validation loss = 1.4040  \n",
      "\n",
      "Fold: 19  Epoch: 48  Training loss = 4.8228  Validation loss = 1.4035  \n",
      "\n",
      "Fold: 19  Epoch: 49  Training loss = 4.8222  Validation loss = 1.4030  \n",
      "\n",
      "Fold: 19  Epoch: 50  Training loss = 4.8217  Validation loss = 1.4025  \n",
      "\n",
      "Fold: 19  Epoch: 51  Training loss = 4.8212  Validation loss = 1.4020  \n",
      "\n",
      "Fold: 19  Epoch: 52  Training loss = 4.8207  Validation loss = 1.4016  \n",
      "\n",
      "Fold: 19  Epoch: 53  Training loss = 4.8201  Validation loss = 1.4011  \n",
      "\n",
      "Fold: 19  Epoch: 54  Training loss = 4.8195  Validation loss = 1.4006  \n",
      "\n",
      "Fold: 19  Epoch: 55  Training loss = 4.8190  Validation loss = 1.4002  \n",
      "\n",
      "Fold: 19  Epoch: 56  Training loss = 4.8184  Validation loss = 1.3996  \n",
      "\n",
      "Fold: 19  Epoch: 57  Training loss = 4.8177  Validation loss = 1.3990  \n",
      "\n",
      "Fold: 19  Epoch: 58  Training loss = 4.8172  Validation loss = 1.3986  \n",
      "\n",
      "Fold: 19  Epoch: 59  Training loss = 4.8168  Validation loss = 1.3981  \n",
      "\n",
      "Fold: 19  Epoch: 60  Training loss = 4.8163  Validation loss = 1.3977  \n",
      "\n",
      "Fold: 19  Epoch: 61  Training loss = 4.8156  Validation loss = 1.3971  \n",
      "\n",
      "Fold: 19  Epoch: 62  Training loss = 4.8150  Validation loss = 1.3966  \n",
      "\n",
      "Fold: 19  Epoch: 63  Training loss = 4.8145  Validation loss = 1.3961  \n",
      "\n",
      "Fold: 19  Epoch: 64  Training loss = 4.8141  Validation loss = 1.3957  \n",
      "\n",
      "Fold: 19  Epoch: 65  Training loss = 4.8135  Validation loss = 1.3952  \n",
      "\n",
      "Fold: 19  Epoch: 66  Training loss = 4.8131  Validation loss = 1.3948  \n",
      "\n",
      "Fold: 19  Epoch: 67  Training loss = 4.8126  Validation loss = 1.3944  \n",
      "\n",
      "Fold: 19  Epoch: 68  Training loss = 4.8121  Validation loss = 1.3938  \n",
      "\n",
      "Fold: 19  Epoch: 69  Training loss = 4.8114  Validation loss = 1.3933  \n",
      "\n",
      "Fold: 19  Epoch: 70  Training loss = 4.8108  Validation loss = 1.3927  \n",
      "\n",
      "Fold: 19  Epoch: 71  Training loss = 4.8103  Validation loss = 1.3922  \n",
      "\n",
      "Fold: 19  Epoch: 72  Training loss = 4.8098  Validation loss = 1.3918  \n",
      "\n",
      "Fold: 19  Epoch: 73  Training loss = 4.8092  Validation loss = 1.3913  \n",
      "\n",
      "Fold: 19  Epoch: 74  Training loss = 4.8086  Validation loss = 1.3907  \n",
      "\n",
      "Fold: 19  Epoch: 75  Training loss = 4.8082  Validation loss = 1.3903  \n",
      "\n",
      "Fold: 19  Epoch: 76  Training loss = 4.8076  Validation loss = 1.3898  \n",
      "\n",
      "Fold: 19  Epoch: 77  Training loss = 4.8071  Validation loss = 1.3894  \n",
      "\n",
      "Fold: 19  Epoch: 78  Training loss = 4.8066  Validation loss = 1.3889  \n",
      "\n",
      "Fold: 19  Epoch: 79  Training loss = 4.8060  Validation loss = 1.3884  \n",
      "\n",
      "Fold: 19  Epoch: 80  Training loss = 4.8054  Validation loss = 1.3879  \n",
      "\n",
      "Fold: 19  Epoch: 81  Training loss = 4.8048  Validation loss = 1.3873  \n",
      "\n",
      "Fold: 19  Epoch: 82  Training loss = 4.8043  Validation loss = 1.3868  \n",
      "\n",
      "Fold: 19  Epoch: 83  Training loss = 4.8038  Validation loss = 1.3864  \n",
      "\n",
      "Fold: 19  Epoch: 84  Training loss = 4.8032  Validation loss = 1.3859  \n",
      "\n",
      "Fold: 19  Epoch: 85  Training loss = 4.8025  Validation loss = 1.3853  \n",
      "\n",
      "Fold: 19  Epoch: 86  Training loss = 4.8021  Validation loss = 1.3849  \n",
      "\n",
      "Fold: 19  Epoch: 87  Training loss = 4.8016  Validation loss = 1.3845  \n",
      "\n",
      "Fold: 19  Epoch: 88  Training loss = 4.8011  Validation loss = 1.3840  \n",
      "\n",
      "Fold: 19  Epoch: 89  Training loss = 4.8006  Validation loss = 1.3836  \n",
      "\n",
      "Fold: 19  Epoch: 90  Training loss = 4.8001  Validation loss = 1.3831  \n",
      "\n",
      "Fold: 19  Epoch: 91  Training loss = 4.7996  Validation loss = 1.3826  \n",
      "\n",
      "Fold: 19  Epoch: 92  Training loss = 4.7989  Validation loss = 1.3820  \n",
      "\n",
      "Fold: 19  Epoch: 93  Training loss = 4.7983  Validation loss = 1.3815  \n",
      "\n",
      "Fold: 19  Epoch: 94  Training loss = 4.7976  Validation loss = 1.3808  \n",
      "\n",
      "Fold: 19  Epoch: 95  Training loss = 4.7972  Validation loss = 1.3804  \n",
      "\n",
      "Fold: 19  Epoch: 96  Training loss = 4.7966  Validation loss = 1.3799  \n",
      "\n",
      "Fold: 19  Epoch: 97  Training loss = 4.7961  Validation loss = 1.3796  \n",
      "\n",
      "Fold: 19  Epoch: 98  Training loss = 4.7956  Validation loss = 1.3791  \n",
      "\n",
      "Fold: 19  Epoch: 99  Training loss = 4.7951  Validation loss = 1.3786  \n",
      "\n",
      "Fold: 19  Epoch: 100  Training loss = 4.7946  Validation loss = 1.3782  \n",
      "\n",
      "Fold: 19  Epoch: 101  Training loss = 4.7941  Validation loss = 1.3777  \n",
      "\n",
      "Fold: 19  Epoch: 102  Training loss = 4.7937  Validation loss = 1.3773  \n",
      "\n",
      "Fold: 19  Epoch: 103  Training loss = 4.7931  Validation loss = 1.3767  \n",
      "\n",
      "Fold: 19  Epoch: 104  Training loss = 4.7925  Validation loss = 1.3762  \n",
      "\n",
      "Fold: 19  Epoch: 105  Training loss = 4.7920  Validation loss = 1.3758  \n",
      "\n",
      "Fold: 19  Epoch: 106  Training loss = 4.7915  Validation loss = 1.3753  \n",
      "\n",
      "Fold: 19  Epoch: 107  Training loss = 4.7909  Validation loss = 1.3747  \n",
      "\n",
      "Fold: 19  Epoch: 108  Training loss = 4.7903  Validation loss = 1.3742  \n",
      "\n",
      "Fold: 19  Epoch: 109  Training loss = 4.7898  Validation loss = 1.3738  \n",
      "\n",
      "Fold: 19  Epoch: 110  Training loss = 4.7893  Validation loss = 1.3734  \n",
      "\n",
      "Fold: 19  Epoch: 111  Training loss = 4.7887  Validation loss = 1.3729  \n",
      "\n",
      "Fold: 19  Epoch: 112  Training loss = 4.7881  Validation loss = 1.3723  \n",
      "\n",
      "Fold: 19  Epoch: 113  Training loss = 4.7876  Validation loss = 1.3719  \n",
      "\n",
      "Fold: 19  Epoch: 114  Training loss = 4.7871  Validation loss = 1.3714  \n",
      "\n",
      "Fold: 19  Epoch: 115  Training loss = 4.7866  Validation loss = 1.3710  \n",
      "\n",
      "Fold: 19  Epoch: 116  Training loss = 4.7861  Validation loss = 1.3705  \n",
      "\n",
      "Fold: 19  Epoch: 117  Training loss = 4.7855  Validation loss = 1.3700  \n",
      "\n",
      "Fold: 19  Epoch: 118  Training loss = 4.7849  Validation loss = 1.3695  \n",
      "\n",
      "Fold: 19  Epoch: 119  Training loss = 4.7844  Validation loss = 1.3690  \n",
      "\n",
      "Fold: 19  Epoch: 120  Training loss = 4.7838  Validation loss = 1.3685  \n",
      "\n",
      "Fold: 19  Epoch: 121  Training loss = 4.7832  Validation loss = 1.3680  \n",
      "\n",
      "Fold: 19  Epoch: 122  Training loss = 4.7827  Validation loss = 1.3676  \n",
      "\n",
      "Fold: 19  Epoch: 123  Training loss = 4.7822  Validation loss = 1.3671  \n",
      "\n",
      "Fold: 19  Epoch: 124  Training loss = 4.7816  Validation loss = 1.3665  \n",
      "\n",
      "Fold: 19  Epoch: 125  Training loss = 4.7810  Validation loss = 1.3660  \n",
      "\n",
      "Fold: 19  Epoch: 126  Training loss = 4.7805  Validation loss = 1.3656  \n",
      "\n",
      "Fold: 19  Epoch: 127  Training loss = 4.7801  Validation loss = 1.3652  \n",
      "\n",
      "Fold: 19  Epoch: 128  Training loss = 4.7796  Validation loss = 1.3647  \n",
      "\n",
      "Fold: 19  Epoch: 129  Training loss = 4.7790  Validation loss = 1.3641  \n",
      "\n",
      "Fold: 19  Epoch: 130  Training loss = 4.7785  Validation loss = 1.3637  \n",
      "\n",
      "Fold: 19  Epoch: 131  Training loss = 4.7780  Validation loss = 1.3632  \n",
      "\n",
      "Fold: 19  Epoch: 132  Training loss = 4.7775  Validation loss = 1.3628  \n",
      "\n",
      "Fold: 19  Epoch: 133  Training loss = 4.7770  Validation loss = 1.3623  \n",
      "\n",
      "Fold: 19  Epoch: 134  Training loss = 4.7765  Validation loss = 1.3619  \n",
      "\n",
      "Fold: 19  Epoch: 135  Training loss = 4.7759  Validation loss = 1.3614  \n",
      "\n",
      "Fold: 19  Epoch: 136  Training loss = 4.7754  Validation loss = 1.3609  \n",
      "\n",
      "Fold: 19  Epoch: 137  Training loss = 4.7748  Validation loss = 1.3604  \n",
      "\n",
      "Fold: 19  Epoch: 138  Training loss = 4.7743  Validation loss = 1.3600  \n",
      "\n",
      "Fold: 19  Epoch: 139  Training loss = 4.7738  Validation loss = 1.3595  \n",
      "\n",
      "Fold: 19  Epoch: 140  Training loss = 4.7733  Validation loss = 1.3591  \n",
      "\n",
      "Fold: 19  Epoch: 141  Training loss = 4.7728  Validation loss = 1.3586  \n",
      "\n",
      "Fold: 19  Epoch: 142  Training loss = 4.7723  Validation loss = 1.3582  \n",
      "\n",
      "Fold: 19  Epoch: 143  Training loss = 4.7719  Validation loss = 1.3578  \n",
      "\n",
      "Fold: 19  Epoch: 144  Training loss = 4.7714  Validation loss = 1.3573  \n",
      "\n",
      "Fold: 19  Epoch: 145  Training loss = 4.7707  Validation loss = 1.3567  \n",
      "\n",
      "Fold: 19  Epoch: 146  Training loss = 4.7702  Validation loss = 1.3563  \n",
      "\n",
      "Fold: 19  Epoch: 147  Training loss = 4.7696  Validation loss = 1.3557  \n",
      "\n",
      "Fold: 19  Epoch: 148  Training loss = 4.7690  Validation loss = 1.3552  \n",
      "\n",
      "Fold: 19  Epoch: 149  Training loss = 4.7683  Validation loss = 1.3546  \n",
      "\n",
      "Fold: 19  Epoch: 150  Training loss = 4.7678  Validation loss = 1.3542  \n",
      "\n",
      "Fold: 19  Epoch: 151  Training loss = 4.7673  Validation loss = 1.3536  \n",
      "\n",
      "Fold: 19  Epoch: 152  Training loss = 4.7667  Validation loss = 1.3532  \n",
      "\n",
      "Fold: 19  Epoch: 153  Training loss = 4.7662  Validation loss = 1.3526  \n",
      "\n",
      "Fold: 19  Epoch: 154  Training loss = 4.7654  Validation loss = 1.3520  \n",
      "\n",
      "Fold: 19  Epoch: 155  Training loss = 4.7650  Validation loss = 1.3516  \n",
      "\n",
      "Fold: 19  Epoch: 156  Training loss = 4.7645  Validation loss = 1.3512  \n",
      "\n",
      "Fold: 19  Epoch: 157  Training loss = 4.7639  Validation loss = 1.3506  \n",
      "\n",
      "Fold: 19  Epoch: 158  Training loss = 4.7634  Validation loss = 1.3501  \n",
      "\n",
      "Fold: 19  Epoch: 159  Training loss = 4.7629  Validation loss = 1.3497  \n",
      "\n",
      "Fold: 19  Epoch: 160  Training loss = 4.7624  Validation loss = 1.3493  \n",
      "\n",
      "Fold: 19  Epoch: 161  Training loss = 4.7619  Validation loss = 1.3488  \n",
      "\n",
      "Fold: 19  Epoch: 162  Training loss = 4.7614  Validation loss = 1.3483  \n",
      "\n",
      "Fold: 19  Epoch: 163  Training loss = 4.7608  Validation loss = 1.3478  \n",
      "\n",
      "Fold: 19  Epoch: 164  Training loss = 4.7603  Validation loss = 1.3474  \n",
      "\n",
      "Fold: 19  Epoch: 165  Training loss = 4.7596  Validation loss = 1.3467  \n",
      "\n",
      "Fold: 19  Epoch: 166  Training loss = 4.7590  Validation loss = 1.3462  \n",
      "\n",
      "Fold: 19  Epoch: 167  Training loss = 4.7585  Validation loss = 1.3457  \n",
      "\n",
      "Fold: 19  Epoch: 168  Training loss = 4.7579  Validation loss = 1.3452  \n",
      "\n",
      "Fold: 19  Epoch: 169  Training loss = 4.7574  Validation loss = 1.3448  \n",
      "\n",
      "Fold: 19  Epoch: 170  Training loss = 4.7568  Validation loss = 1.3443  \n",
      "\n",
      "Fold: 19  Epoch: 171  Training loss = 4.7564  Validation loss = 1.3438  \n",
      "\n",
      "Fold: 19  Epoch: 172  Training loss = 4.7558  Validation loss = 1.3433  \n",
      "\n",
      "Fold: 19  Epoch: 173  Training loss = 4.7553  Validation loss = 1.3428  \n",
      "\n",
      "Fold: 19  Epoch: 174  Training loss = 4.7547  Validation loss = 1.3423  \n",
      "\n",
      "Fold: 19  Epoch: 175  Training loss = 4.7542  Validation loss = 1.3419  \n",
      "\n",
      "Fold: 19  Epoch: 176  Training loss = 4.7537  Validation loss = 1.3414  \n",
      "\n",
      "Fold: 19  Epoch: 177  Training loss = 4.7531  Validation loss = 1.3409  \n",
      "\n",
      "Fold: 19  Epoch: 178  Training loss = 4.7527  Validation loss = 1.3405  \n",
      "\n",
      "Fold: 19  Epoch: 179  Training loss = 4.7521  Validation loss = 1.3400  \n",
      "\n",
      "Fold: 19  Epoch: 180  Training loss = 4.7515  Validation loss = 1.3395  \n",
      "\n",
      "Fold: 19  Epoch: 181  Training loss = 4.7509  Validation loss = 1.3390  \n",
      "\n",
      "Fold: 19  Epoch: 182  Training loss = 4.7504  Validation loss = 1.3385  \n",
      "\n",
      "Fold: 19  Epoch: 183  Training loss = 4.7499  Validation loss = 1.3380  \n",
      "\n",
      "Fold: 19  Epoch: 184  Training loss = 4.7493  Validation loss = 1.3375  \n",
      "\n",
      "Fold: 19  Epoch: 185  Training loss = 4.7488  Validation loss = 1.3371  \n",
      "\n",
      "Fold: 19  Epoch: 186  Training loss = 4.7482  Validation loss = 1.3365  \n",
      "\n",
      "Fold: 19  Epoch: 187  Training loss = 4.7475  Validation loss = 1.3360  \n",
      "\n",
      "Fold: 19  Epoch: 188  Training loss = 4.7470  Validation loss = 1.3354  \n",
      "\n",
      "Fold: 19  Epoch: 189  Training loss = 4.7463  Validation loss = 1.3349  \n",
      "\n",
      "Fold: 19  Epoch: 190  Training loss = 4.7459  Validation loss = 1.3345  \n",
      "\n",
      "Fold: 19  Epoch: 191  Training loss = 4.7454  Validation loss = 1.3340  \n",
      "\n",
      "Fold: 19  Epoch: 192  Training loss = 4.7448  Validation loss = 1.3335  \n",
      "\n",
      "Fold: 19  Epoch: 193  Training loss = 4.7440  Validation loss = 1.3328  \n",
      "\n",
      "Fold: 19  Epoch: 194  Training loss = 4.7434  Validation loss = 1.3322  \n",
      "\n",
      "Fold: 19  Epoch: 195  Training loss = 4.7429  Validation loss = 1.3318  \n",
      "\n",
      "Fold: 19  Epoch: 196  Training loss = 4.7424  Validation loss = 1.3313  \n",
      "\n",
      "Fold: 19  Epoch: 197  Training loss = 4.7419  Validation loss = 1.3309  \n",
      "\n",
      "Fold: 19  Epoch: 198  Training loss = 4.7412  Validation loss = 1.3303  \n",
      "\n",
      "Fold: 19  Epoch: 199  Training loss = 4.7407  Validation loss = 1.3298  \n",
      "\n",
      "Fold: 19  Epoch: 200  Training loss = 4.7402  Validation loss = 1.3294  \n",
      "\n",
      "Fold: 19  Epoch: 201  Training loss = 4.7395  Validation loss = 1.3288  \n",
      "\n",
      "Fold: 19  Epoch: 202  Training loss = 4.7392  Validation loss = 1.3285  \n",
      "\n",
      "Fold: 19  Epoch: 203  Training loss = 4.7386  Validation loss = 1.3280  \n",
      "\n",
      "Fold: 19  Epoch: 204  Training loss = 4.7380  Validation loss = 1.3275  \n",
      "\n",
      "Fold: 19  Epoch: 205  Training loss = 4.7376  Validation loss = 1.3271  \n",
      "\n",
      "Fold: 19  Epoch: 206  Training loss = 4.7371  Validation loss = 1.3266  \n",
      "\n",
      "Fold: 19  Epoch: 207  Training loss = 4.7366  Validation loss = 1.3262  \n",
      "\n",
      "Fold: 19  Epoch: 208  Training loss = 4.7361  Validation loss = 1.3258  \n",
      "\n",
      "Fold: 19  Epoch: 209  Training loss = 4.7357  Validation loss = 1.3254  \n",
      "\n",
      "Fold: 19  Epoch: 210  Training loss = 4.7352  Validation loss = 1.3250  \n",
      "\n",
      "Fold: 19  Epoch: 211  Training loss = 4.7348  Validation loss = 1.3245  \n",
      "\n",
      "Fold: 19  Epoch: 212  Training loss = 4.7343  Validation loss = 1.3241  \n",
      "\n",
      "Fold: 19  Epoch: 213  Training loss = 4.7337  Validation loss = 1.3236  \n",
      "\n",
      "Fold: 19  Epoch: 214  Training loss = 4.7331  Validation loss = 1.3231  \n",
      "\n",
      "Fold: 19  Epoch: 215  Training loss = 4.7326  Validation loss = 1.3226  \n",
      "\n",
      "Fold: 19  Epoch: 216  Training loss = 4.7321  Validation loss = 1.3222  \n",
      "\n",
      "Fold: 19  Epoch: 217  Training loss = 4.7316  Validation loss = 1.3217  \n",
      "\n",
      "Fold: 19  Epoch: 218  Training loss = 4.7312  Validation loss = 1.3213  \n",
      "\n",
      "Fold: 19  Epoch: 219  Training loss = 4.7306  Validation loss = 1.3208  \n",
      "\n",
      "Fold: 19  Epoch: 220  Training loss = 4.7302  Validation loss = 1.3204  \n",
      "\n",
      "Fold: 19  Epoch: 221  Training loss = 4.7296  Validation loss = 1.3199  \n",
      "\n",
      "Fold: 19  Epoch: 222  Training loss = 4.7290  Validation loss = 1.3193  \n",
      "\n",
      "Fold: 19  Epoch: 223  Training loss = 4.7285  Validation loss = 1.3189  \n",
      "\n",
      "Fold: 19  Epoch: 224  Training loss = 4.7279  Validation loss = 1.3183  \n",
      "\n",
      "Fold: 19  Epoch: 225  Training loss = 4.7274  Validation loss = 1.3179  \n",
      "\n",
      "Fold: 19  Epoch: 226  Training loss = 4.7270  Validation loss = 1.3175  \n",
      "\n",
      "Fold: 19  Epoch: 227  Training loss = 4.7265  Validation loss = 1.3171  \n",
      "\n",
      "Fold: 19  Epoch: 228  Training loss = 4.7259  Validation loss = 1.3166  \n",
      "\n",
      "Fold: 19  Epoch: 229  Training loss = 4.7253  Validation loss = 1.3160  \n",
      "\n",
      "Fold: 19  Epoch: 230  Training loss = 4.7246  Validation loss = 1.3154  \n",
      "\n",
      "Fold: 19  Epoch: 231  Training loss = 4.7241  Validation loss = 1.3149  \n",
      "\n",
      "Fold: 19  Epoch: 232  Training loss = 4.7237  Validation loss = 1.3146  \n",
      "\n",
      "Fold: 19  Epoch: 233  Training loss = 4.7232  Validation loss = 1.3141  \n",
      "\n",
      "Fold: 19  Epoch: 234  Training loss = 4.7227  Validation loss = 1.3136  \n",
      "\n",
      "Fold: 19  Epoch: 235  Training loss = 4.7221  Validation loss = 1.3131  \n",
      "\n",
      "Fold: 19  Epoch: 236  Training loss = 4.7216  Validation loss = 1.3127  \n",
      "\n",
      "Fold: 19  Epoch: 237  Training loss = 4.7211  Validation loss = 1.3122  \n",
      "\n",
      "Fold: 19  Epoch: 238  Training loss = 4.7205  Validation loss = 1.3117  \n",
      "\n",
      "Fold: 19  Epoch: 239  Training loss = 4.7199  Validation loss = 1.3111  \n",
      "\n",
      "Fold: 19  Epoch: 240  Training loss = 4.7193  Validation loss = 1.3106  \n",
      "\n",
      "Fold: 19  Epoch: 241  Training loss = 4.7187  Validation loss = 1.3101  \n",
      "\n",
      "Fold: 19  Epoch: 242  Training loss = 4.7183  Validation loss = 1.3097  \n",
      "\n",
      "Fold: 19  Epoch: 243  Training loss = 4.7177  Validation loss = 1.3092  \n",
      "\n",
      "Fold: 19  Epoch: 244  Training loss = 4.7172  Validation loss = 1.3087  \n",
      "\n",
      "Fold: 19  Epoch: 245  Training loss = 4.7166  Validation loss = 1.3082  \n",
      "\n",
      "Fold: 19  Epoch: 246  Training loss = 4.7160  Validation loss = 1.3077  \n",
      "\n",
      "Fold: 19  Epoch: 247  Training loss = 4.7154  Validation loss = 1.3072  \n",
      "\n",
      "Fold: 19  Epoch: 248  Training loss = 4.7149  Validation loss = 1.3067  \n",
      "\n",
      "Fold: 19  Epoch: 249  Training loss = 4.7143  Validation loss = 1.3061  \n",
      "\n",
      "Fold: 19  Epoch: 250  Training loss = 4.7138  Validation loss = 1.3057  \n",
      "\n",
      "Fold: 19  Epoch: 251  Training loss = 4.7133  Validation loss = 1.3052  \n",
      "\n",
      "Fold: 19  Epoch: 252  Training loss = 4.7129  Validation loss = 1.3048  \n",
      "\n",
      "Fold: 19  Epoch: 253  Training loss = 4.7124  Validation loss = 1.3044  \n",
      "\n",
      "Fold: 19  Epoch: 254  Training loss = 4.7118  Validation loss = 1.3039  \n",
      "\n",
      "Fold: 19  Epoch: 255  Training loss = 4.7113  Validation loss = 1.3034  \n",
      "\n",
      "Fold: 19  Epoch: 256  Training loss = 4.7108  Validation loss = 1.3030  \n",
      "\n",
      "Fold: 19  Epoch: 257  Training loss = 4.7102  Validation loss = 1.3025  \n",
      "\n",
      "Fold: 19  Epoch: 258  Training loss = 4.7098  Validation loss = 1.3021  \n",
      "\n",
      "Fold: 19  Epoch: 259  Training loss = 4.7093  Validation loss = 1.3016  \n",
      "\n",
      "Fold: 19  Epoch: 260  Training loss = 4.7088  Validation loss = 1.3012  \n",
      "\n",
      "Fold: 19  Epoch: 261  Training loss = 4.7082  Validation loss = 1.3007  \n",
      "\n",
      "Fold: 19  Epoch: 262  Training loss = 4.7078  Validation loss = 1.3003  \n",
      "\n",
      "Fold: 19  Epoch: 263  Training loss = 4.7072  Validation loss = 1.2998  \n",
      "\n",
      "Fold: 19  Epoch: 264  Training loss = 4.7066  Validation loss = 1.2993  \n",
      "\n",
      "Fold: 19  Epoch: 265  Training loss = 4.7061  Validation loss = 1.2988  \n",
      "\n",
      "Fold: 19  Epoch: 266  Training loss = 4.7056  Validation loss = 1.2983  \n",
      "\n",
      "Fold: 19  Epoch: 267  Training loss = 4.7051  Validation loss = 1.2979  \n",
      "\n",
      "Fold: 19  Epoch: 268  Training loss = 4.7046  Validation loss = 1.2975  \n",
      "\n",
      "Fold: 19  Epoch: 269  Training loss = 4.7041  Validation loss = 1.2970  \n",
      "\n",
      "Fold: 19  Epoch: 270  Training loss = 4.7036  Validation loss = 1.2965  \n",
      "\n",
      "Fold: 19  Epoch: 271  Training loss = 4.7030  Validation loss = 1.2960  \n",
      "\n",
      "Fold: 19  Epoch: 272  Training loss = 4.7025  Validation loss = 1.2955  \n",
      "\n",
      "Fold: 19  Epoch: 273  Training loss = 4.7019  Validation loss = 1.2950  \n",
      "\n",
      "Fold: 19  Epoch: 274  Training loss = 4.7014  Validation loss = 1.2946  \n",
      "\n",
      "Fold: 19  Epoch: 275  Training loss = 4.7009  Validation loss = 1.2941  \n",
      "\n",
      "Fold: 19  Epoch: 276  Training loss = 4.7003  Validation loss = 1.2936  \n",
      "\n",
      "Fold: 19  Epoch: 277  Training loss = 4.6996  Validation loss = 1.2931  \n",
      "\n",
      "Fold: 19  Epoch: 278  Training loss = 4.6991  Validation loss = 1.2926  \n",
      "\n",
      "Fold: 19  Epoch: 279  Training loss = 4.6986  Validation loss = 1.2921  \n",
      "\n",
      "Fold: 19  Epoch: 280  Training loss = 4.6980  Validation loss = 1.2916  \n",
      "\n",
      "Fold: 19  Epoch: 281  Training loss = 4.6976  Validation loss = 1.2913  \n",
      "\n",
      "Fold: 19  Epoch: 282  Training loss = 4.6970  Validation loss = 1.2907  \n",
      "\n",
      "Fold: 19  Epoch: 283  Training loss = 4.6965  Validation loss = 1.2902  \n",
      "\n",
      "Fold: 19  Epoch: 284  Training loss = 4.6959  Validation loss = 1.2898  \n",
      "\n",
      "Fold: 19  Epoch: 285  Training loss = 4.6954  Validation loss = 1.2893  \n",
      "\n",
      "Fold: 19  Epoch: 286  Training loss = 4.6949  Validation loss = 1.2889  \n",
      "\n",
      "Fold: 19  Epoch: 287  Training loss = 4.6944  Validation loss = 1.2884  \n",
      "\n",
      "Fold: 19  Epoch: 288  Training loss = 4.6939  Validation loss = 1.2879  \n",
      "\n",
      "Fold: 19  Epoch: 289  Training loss = 4.6934  Validation loss = 1.2875  \n",
      "\n",
      "Fold: 19  Epoch: 290  Training loss = 4.6928  Validation loss = 1.2870  \n",
      "\n",
      "Fold: 19  Epoch: 291  Training loss = 4.6923  Validation loss = 1.2865  \n",
      "\n",
      "Fold: 19  Epoch: 292  Training loss = 4.6917  Validation loss = 1.2860  \n",
      "\n",
      "Fold: 19  Epoch: 293  Training loss = 4.6911  Validation loss = 1.2855  \n",
      "\n",
      "Fold: 19  Epoch: 294  Training loss = 4.6906  Validation loss = 1.2850  \n",
      "\n",
      "Fold: 19  Epoch: 295  Training loss = 4.6901  Validation loss = 1.2846  \n",
      "\n",
      "Fold: 19  Epoch: 296  Training loss = 4.6896  Validation loss = 1.2841  \n",
      "\n",
      "Fold: 19  Epoch: 297  Training loss = 4.6890  Validation loss = 1.2836  \n",
      "\n",
      "Fold: 19  Epoch: 298  Training loss = 4.6884  Validation loss = 1.2831  \n",
      "\n",
      "Fold: 19  Epoch: 299  Training loss = 4.6880  Validation loss = 1.2827  \n",
      "\n",
      "Fold: 19  Epoch: 300  Training loss = 4.6875  Validation loss = 1.2822  \n",
      "\n",
      "Fold: 19  Epoch: 301  Training loss = 4.6868  Validation loss = 1.2816  \n",
      "\n",
      "Fold: 19  Epoch: 302  Training loss = 4.6863  Validation loss = 1.2812  \n",
      "\n",
      "Fold: 19  Epoch: 303  Training loss = 4.6859  Validation loss = 1.2808  \n",
      "\n",
      "Fold: 19  Epoch: 304  Training loss = 4.6853  Validation loss = 1.2803  \n",
      "\n",
      "Fold: 19  Epoch: 305  Training loss = 4.6848  Validation loss = 1.2798  \n",
      "\n",
      "Fold: 19  Epoch: 306  Training loss = 4.6843  Validation loss = 1.2793  \n",
      "\n",
      "Fold: 19  Epoch: 307  Training loss = 4.6838  Validation loss = 1.2789  \n",
      "\n",
      "Fold: 19  Epoch: 308  Training loss = 4.6833  Validation loss = 1.2785  \n",
      "\n",
      "Fold: 19  Epoch: 309  Training loss = 4.6828  Validation loss = 1.2780  \n",
      "\n",
      "Fold: 19  Epoch: 310  Training loss = 4.6822  Validation loss = 1.2775  \n",
      "\n",
      "Fold: 19  Epoch: 311  Training loss = 4.6816  Validation loss = 1.2770  \n",
      "\n",
      "Fold: 19  Epoch: 312  Training loss = 4.6811  Validation loss = 1.2765  \n",
      "\n",
      "Fold: 19  Epoch: 313  Training loss = 4.6805  Validation loss = 1.2760  \n",
      "\n",
      "Fold: 19  Epoch: 314  Training loss = 4.6800  Validation loss = 1.2755  \n",
      "\n",
      "Fold: 19  Epoch: 315  Training loss = 4.6794  Validation loss = 1.2750  \n",
      "\n",
      "Fold: 19  Epoch: 316  Training loss = 4.6788  Validation loss = 1.2745  \n",
      "\n",
      "Fold: 19  Epoch: 317  Training loss = 4.6783  Validation loss = 1.2741  \n",
      "\n",
      "Fold: 19  Epoch: 318  Training loss = 4.6779  Validation loss = 1.2737  \n",
      "\n",
      "Fold: 19  Epoch: 319  Training loss = 4.6774  Validation loss = 1.2733  \n",
      "\n",
      "Fold: 19  Epoch: 320  Training loss = 4.6768  Validation loss = 1.2728  \n",
      "\n",
      "Fold: 19  Epoch: 321  Training loss = 4.6763  Validation loss = 1.2724  \n",
      "\n",
      "Fold: 19  Epoch: 322  Training loss = 4.6758  Validation loss = 1.2719  \n",
      "\n",
      "Fold: 19  Epoch: 323  Training loss = 4.6753  Validation loss = 1.2714  \n",
      "\n",
      "Fold: 19  Epoch: 324  Training loss = 4.6747  Validation loss = 1.2709  \n",
      "\n",
      "Fold: 19  Epoch: 325  Training loss = 4.6742  Validation loss = 1.2704  \n",
      "\n",
      "Fold: 19  Epoch: 326  Training loss = 4.6737  Validation loss = 1.2700  \n",
      "\n",
      "Fold: 19  Epoch: 327  Training loss = 4.6732  Validation loss = 1.2695  \n",
      "\n",
      "Fold: 19  Epoch: 328  Training loss = 4.6726  Validation loss = 1.2691  \n",
      "\n",
      "Fold: 19  Epoch: 329  Training loss = 4.6721  Validation loss = 1.2686  \n",
      "\n",
      "Fold: 19  Epoch: 330  Training loss = 4.6715  Validation loss = 1.2681  \n",
      "\n",
      "Fold: 19  Epoch: 331  Training loss = 4.6710  Validation loss = 1.2676  \n",
      "\n",
      "Fold: 19  Epoch: 332  Training loss = 4.6705  Validation loss = 1.2671  \n",
      "\n",
      "Fold: 19  Epoch: 333  Training loss = 4.6700  Validation loss = 1.2667  \n",
      "\n",
      "Fold: 19  Epoch: 334  Training loss = 4.6694  Validation loss = 1.2662  \n",
      "\n",
      "Fold: 19  Epoch: 335  Training loss = 4.6691  Validation loss = 1.2659  \n",
      "\n",
      "Fold: 19  Epoch: 336  Training loss = 4.6685  Validation loss = 1.2654  \n",
      "\n",
      "Fold: 19  Epoch: 337  Training loss = 4.6680  Validation loss = 1.2649  \n",
      "\n",
      "Fold: 19  Epoch: 338  Training loss = 4.6674  Validation loss = 1.2645  \n",
      "\n",
      "Fold: 19  Epoch: 339  Training loss = 4.6668  Validation loss = 1.2639  \n",
      "\n",
      "Fold: 19  Epoch: 340  Training loss = 4.6664  Validation loss = 1.2636  \n",
      "\n",
      "Fold: 19  Epoch: 341  Training loss = 4.6659  Validation loss = 1.2631  \n",
      "\n",
      "Fold: 19  Epoch: 342  Training loss = 4.6653  Validation loss = 1.2627  \n",
      "\n",
      "Fold: 19  Epoch: 343  Training loss = 4.6649  Validation loss = 1.2622  \n",
      "\n",
      "Fold: 19  Epoch: 344  Training loss = 4.6642  Validation loss = 1.2617  \n",
      "\n",
      "Fold: 19  Epoch: 345  Training loss = 4.6639  Validation loss = 1.2614  \n",
      "\n",
      "Fold: 19  Epoch: 346  Training loss = 4.6634  Validation loss = 1.2609  \n",
      "\n",
      "Fold: 19  Epoch: 347  Training loss = 4.6630  Validation loss = 1.2606  \n",
      "\n",
      "Fold: 19  Epoch: 348  Training loss = 4.6624  Validation loss = 1.2601  \n",
      "\n",
      "Fold: 19  Epoch: 349  Training loss = 4.6618  Validation loss = 1.2596  \n",
      "\n",
      "Fold: 19  Epoch: 350  Training loss = 4.6613  Validation loss = 1.2591  \n",
      "\n",
      "Fold: 19  Epoch: 351  Training loss = 4.6608  Validation loss = 1.2586  \n",
      "\n",
      "Fold: 19  Epoch: 352  Training loss = 4.6603  Validation loss = 1.2582  \n",
      "\n",
      "Fold: 19  Epoch: 353  Training loss = 4.6598  Validation loss = 1.2578  \n",
      "\n",
      "Fold: 19  Epoch: 354  Training loss = 4.6593  Validation loss = 1.2573  \n",
      "\n",
      "Fold: 19  Epoch: 355  Training loss = 4.6588  Validation loss = 1.2569  \n",
      "\n",
      "Fold: 19  Epoch: 356  Training loss = 4.6583  Validation loss = 1.2564  \n",
      "\n",
      "Fold: 19  Epoch: 357  Training loss = 4.6577  Validation loss = 1.2560  \n",
      "\n",
      "Fold: 19  Epoch: 358  Training loss = 4.6572  Validation loss = 1.2555  \n",
      "\n",
      "Fold: 19  Epoch: 359  Training loss = 4.6567  Validation loss = 1.2551  \n",
      "\n",
      "Fold: 19  Epoch: 360  Training loss = 4.6562  Validation loss = 1.2546  \n",
      "\n",
      "Fold: 19  Epoch: 361  Training loss = 4.6557  Validation loss = 1.2541  \n",
      "\n",
      "Fold: 19  Epoch: 362  Training loss = 4.6552  Validation loss = 1.2536  \n",
      "\n",
      "Fold: 19  Epoch: 363  Training loss = 4.6548  Validation loss = 1.2533  \n",
      "\n",
      "Fold: 19  Epoch: 364  Training loss = 4.6542  Validation loss = 1.2528  \n",
      "\n",
      "Fold: 19  Epoch: 365  Training loss = 4.6538  Validation loss = 1.2524  \n",
      "\n",
      "Fold: 19  Epoch: 366  Training loss = 4.6533  Validation loss = 1.2520  \n",
      "\n",
      "Fold: 19  Epoch: 367  Training loss = 4.6529  Validation loss = 1.2516  \n",
      "\n",
      "Fold: 19  Epoch: 368  Training loss = 4.6525  Validation loss = 1.2513  \n",
      "\n",
      "Fold: 19  Epoch: 369  Training loss = 4.6520  Validation loss = 1.2508  \n",
      "\n",
      "Fold: 19  Epoch: 370  Training loss = 4.6515  Validation loss = 1.2504  \n",
      "\n",
      "Fold: 19  Epoch: 371  Training loss = 4.6508  Validation loss = 1.2498  \n",
      "\n",
      "Fold: 19  Epoch: 372  Training loss = 4.6503  Validation loss = 1.2493  \n",
      "\n",
      "Fold: 19  Epoch: 373  Training loss = 4.6498  Validation loss = 1.2489  \n",
      "\n",
      "Fold: 19  Epoch: 374  Training loss = 4.6492  Validation loss = 1.2484  \n",
      "\n",
      "Fold: 19  Epoch: 375  Training loss = 4.6488  Validation loss = 1.2481  \n",
      "\n",
      "Fold: 19  Epoch: 376  Training loss = 4.6483  Validation loss = 1.2476  \n",
      "\n",
      "Fold: 19  Epoch: 377  Training loss = 4.6478  Validation loss = 1.2472  \n",
      "\n",
      "Fold: 19  Epoch: 378  Training loss = 4.6472  Validation loss = 1.2466  \n",
      "\n",
      "Fold: 19  Epoch: 379  Training loss = 4.6467  Validation loss = 1.2462  \n",
      "\n",
      "Fold: 19  Epoch: 380  Training loss = 4.6461  Validation loss = 1.2457  \n",
      "\n",
      "Fold: 19  Epoch: 381  Training loss = 4.6456  Validation loss = 1.2452  \n",
      "\n",
      "Fold: 19  Epoch: 382  Training loss = 4.6450  Validation loss = 1.2447  \n",
      "\n",
      "Fold: 19  Epoch: 383  Training loss = 4.6444  Validation loss = 1.2442  \n",
      "\n",
      "Fold: 19  Epoch: 384  Training loss = 4.6440  Validation loss = 1.2438  \n",
      "\n",
      "Fold: 19  Epoch: 385  Training loss = 4.6434  Validation loss = 1.2433  \n",
      "\n",
      "Fold: 19  Epoch: 386  Training loss = 4.6430  Validation loss = 1.2429  \n",
      "\n",
      "Fold: 19  Epoch: 387  Training loss = 4.6424  Validation loss = 1.2424  \n",
      "\n",
      "Fold: 19  Epoch: 388  Training loss = 4.6419  Validation loss = 1.2420  \n",
      "\n",
      "Fold: 19  Epoch: 389  Training loss = 4.6414  Validation loss = 1.2416  \n",
      "\n",
      "Fold: 19  Epoch: 390  Training loss = 4.6408  Validation loss = 1.2411  \n",
      "\n",
      "Fold: 19  Epoch: 391  Training loss = 4.6403  Validation loss = 1.2406  \n",
      "\n",
      "Fold: 19  Epoch: 392  Training loss = 4.6398  Validation loss = 1.2402  \n",
      "\n",
      "Fold: 19  Epoch: 393  Training loss = 4.6392  Validation loss = 1.2397  \n",
      "\n",
      "Fold: 19  Epoch: 394  Training loss = 4.6388  Validation loss = 1.2393  \n",
      "\n",
      "Fold: 19  Epoch: 395  Training loss = 4.6384  Validation loss = 1.2389  \n",
      "\n",
      "Fold: 19  Epoch: 396  Training loss = 4.6379  Validation loss = 1.2385  \n",
      "\n",
      "Fold: 19  Epoch: 397  Training loss = 4.6373  Validation loss = 1.2380  \n",
      "\n",
      "Fold: 19  Epoch: 398  Training loss = 4.6369  Validation loss = 1.2376  \n",
      "\n",
      "Fold: 19  Epoch: 399  Training loss = 4.6365  Validation loss = 1.2373  \n",
      "\n",
      "Fold: 19  Epoch: 400  Training loss = 4.6359  Validation loss = 1.2367  \n",
      "\n",
      "Fold: 19  Epoch: 401  Training loss = 4.6354  Validation loss = 1.2363  \n",
      "\n",
      "Fold: 19  Epoch: 402  Training loss = 4.6349  Validation loss = 1.2359  \n",
      "\n",
      "Fold: 19  Epoch: 403  Training loss = 4.6344  Validation loss = 1.2355  \n",
      "\n",
      "Fold: 19  Epoch: 404  Training loss = 4.6338  Validation loss = 1.2349  \n",
      "\n",
      "Fold: 19  Epoch: 405  Training loss = 4.6333  Validation loss = 1.2345  \n",
      "\n",
      "Fold: 19  Epoch: 406  Training loss = 4.6329  Validation loss = 1.2341  \n",
      "\n",
      "Fold: 19  Epoch: 407  Training loss = 4.6324  Validation loss = 1.2337  \n",
      "\n",
      "Fold: 19  Epoch: 408  Training loss = 4.6317  Validation loss = 1.2331  \n",
      "\n",
      "Fold: 19  Epoch: 409  Training loss = 4.6312  Validation loss = 1.2327  \n",
      "\n",
      "Fold: 19  Epoch: 410  Training loss = 4.6308  Validation loss = 1.2323  \n",
      "\n",
      "Fold: 19  Epoch: 411  Training loss = 4.6304  Validation loss = 1.2319  \n",
      "\n",
      "Fold: 19  Epoch: 412  Training loss = 4.6298  Validation loss = 1.2314  \n",
      "\n",
      "Fold: 19  Epoch: 413  Training loss = 4.6293  Validation loss = 1.2310  \n",
      "\n",
      "Fold: 19  Epoch: 414  Training loss = 4.6287  Validation loss = 1.2305  \n",
      "\n",
      "Fold: 19  Epoch: 415  Training loss = 4.6282  Validation loss = 1.2300  \n",
      "\n",
      "Fold: 19  Epoch: 416  Training loss = 4.6278  Validation loss = 1.2296  \n",
      "\n",
      "Fold: 19  Epoch: 417  Training loss = 4.6272  Validation loss = 1.2291  \n",
      "\n",
      "Fold: 19  Epoch: 418  Training loss = 4.6268  Validation loss = 1.2287  \n",
      "\n",
      "Fold: 19  Epoch: 419  Training loss = 4.6263  Validation loss = 1.2283  \n",
      "\n",
      "Fold: 19  Epoch: 420  Training loss = 4.6258  Validation loss = 1.2279  \n",
      "\n",
      "Fold: 19  Epoch: 421  Training loss = 4.6253  Validation loss = 1.2274  \n",
      "\n",
      "Fold: 19  Epoch: 422  Training loss = 4.6249  Validation loss = 1.2271  \n",
      "\n",
      "Fold: 19  Epoch: 423  Training loss = 4.6243  Validation loss = 1.2266  \n",
      "\n",
      "Fold: 19  Epoch: 424  Training loss = 4.6239  Validation loss = 1.2262  \n",
      "\n",
      "Fold: 19  Epoch: 425  Training loss = 4.6235  Validation loss = 1.2258  \n",
      "\n",
      "Fold: 19  Epoch: 426  Training loss = 4.6230  Validation loss = 1.2254  \n",
      "\n",
      "Fold: 19  Epoch: 427  Training loss = 4.6225  Validation loss = 1.2249  \n",
      "\n",
      "Fold: 19  Epoch: 428  Training loss = 4.6220  Validation loss = 1.2245  \n",
      "\n",
      "Fold: 19  Epoch: 429  Training loss = 4.6215  Validation loss = 1.2241  \n",
      "\n",
      "Fold: 19  Epoch: 430  Training loss = 4.6210  Validation loss = 1.2237  \n",
      "\n",
      "Fold: 19  Epoch: 431  Training loss = 4.6205  Validation loss = 1.2233  \n",
      "\n",
      "Fold: 19  Epoch: 432  Training loss = 4.6200  Validation loss = 1.2228  \n",
      "\n",
      "Fold: 19  Epoch: 433  Training loss = 4.6195  Validation loss = 1.2224  \n",
      "\n",
      "Fold: 19  Epoch: 434  Training loss = 4.6190  Validation loss = 1.2220  \n",
      "\n",
      "Fold: 19  Epoch: 435  Training loss = 4.6185  Validation loss = 1.2216  \n",
      "\n",
      "Fold: 19  Epoch: 436  Training loss = 4.6180  Validation loss = 1.2211  \n",
      "\n",
      "Fold: 19  Epoch: 437  Training loss = 4.6175  Validation loss = 1.2207  \n",
      "\n",
      "Fold: 19  Epoch: 438  Training loss = 4.6170  Validation loss = 1.2203  \n",
      "\n",
      "Fold: 19  Epoch: 439  Training loss = 4.6165  Validation loss = 1.2198  \n",
      "\n",
      "Fold: 19  Epoch: 440  Training loss = 4.6160  Validation loss = 1.2193  \n",
      "\n",
      "Fold: 19  Epoch: 441  Training loss = 4.6154  Validation loss = 1.2188  \n",
      "\n",
      "Fold: 19  Epoch: 442  Training loss = 4.6150  Validation loss = 1.2184  \n",
      "\n",
      "Fold: 19  Epoch: 443  Training loss = 4.6145  Validation loss = 1.2181  \n",
      "\n",
      "Fold: 19  Epoch: 444  Training loss = 4.6141  Validation loss = 1.2176  \n",
      "\n",
      "Fold: 19  Epoch: 445  Training loss = 4.6136  Validation loss = 1.2173  \n",
      "\n",
      "Fold: 19  Epoch: 446  Training loss = 4.6132  Validation loss = 1.2169  \n",
      "\n",
      "Fold: 19  Epoch: 447  Training loss = 4.6126  Validation loss = 1.2164  \n",
      "\n",
      "Fold: 19  Epoch: 448  Training loss = 4.6123  Validation loss = 1.2161  \n",
      "\n",
      "Fold: 19  Epoch: 449  Training loss = 4.6117  Validation loss = 1.2157  \n",
      "\n",
      "Fold: 19  Epoch: 450  Training loss = 4.6112  Validation loss = 1.2152  \n",
      "\n",
      "Fold: 19  Epoch: 451  Training loss = 4.6106  Validation loss = 1.2147  \n",
      "\n",
      "Fold: 19  Epoch: 452  Training loss = 4.6100  Validation loss = 1.2142  \n",
      "\n",
      "Fold: 19  Epoch: 453  Training loss = 4.6095  Validation loss = 1.2138  \n",
      "\n",
      "Fold: 19  Epoch: 454  Training loss = 4.6090  Validation loss = 1.2133  \n",
      "\n",
      "Fold: 19  Epoch: 455  Training loss = 4.6085  Validation loss = 1.2129  \n",
      "\n",
      "Fold: 19  Epoch: 456  Training loss = 4.6080  Validation loss = 1.2124  \n",
      "\n",
      "Fold: 19  Epoch: 457  Training loss = 4.6076  Validation loss = 1.2121  \n",
      "\n",
      "Fold: 19  Epoch: 458  Training loss = 4.6072  Validation loss = 1.2118  \n",
      "\n",
      "Fold: 19  Epoch: 459  Training loss = 4.6066  Validation loss = 1.2112  \n",
      "\n",
      "Fold: 19  Epoch: 460  Training loss = 4.6060  Validation loss = 1.2107  \n",
      "\n",
      "Fold: 19  Epoch: 461  Training loss = 4.6056  Validation loss = 1.2103  \n",
      "\n",
      "Fold: 19  Epoch: 462  Training loss = 4.6050  Validation loss = 1.2098  \n",
      "\n",
      "Fold: 19  Epoch: 463  Training loss = 4.6044  Validation loss = 1.2093  \n",
      "\n",
      "Fold: 19  Epoch: 464  Training loss = 4.6040  Validation loss = 1.2090  \n",
      "\n",
      "Fold: 19  Epoch: 465  Training loss = 4.6036  Validation loss = 1.2086  \n",
      "\n",
      "Fold: 19  Epoch: 466  Training loss = 4.6031  Validation loss = 1.2081  \n",
      "\n",
      "Fold: 19  Epoch: 467  Training loss = 4.6026  Validation loss = 1.2077  \n",
      "\n",
      "Fold: 19  Epoch: 468  Training loss = 4.6020  Validation loss = 1.2072  \n",
      "\n",
      "Fold: 19  Epoch: 469  Training loss = 4.6014  Validation loss = 1.2066  \n",
      "\n",
      "Fold: 19  Epoch: 470  Training loss = 4.6009  Validation loss = 1.2062  \n",
      "\n",
      "Fold: 19  Epoch: 471  Training loss = 4.6003  Validation loss = 1.2057  \n",
      "\n",
      "Fold: 19  Epoch: 472  Training loss = 4.5997  Validation loss = 1.2052  \n",
      "\n",
      "Fold: 19  Epoch: 473  Training loss = 4.5992  Validation loss = 1.2047  \n",
      "\n",
      "Fold: 19  Epoch: 474  Training loss = 4.5986  Validation loss = 1.2042  \n",
      "\n",
      "Fold: 19  Epoch: 475  Training loss = 4.5981  Validation loss = 1.2037  \n",
      "\n",
      "Fold: 19  Epoch: 476  Training loss = 4.5976  Validation loss = 1.2033  \n",
      "\n",
      "Fold: 19  Epoch: 477  Training loss = 4.5971  Validation loss = 1.2029  \n",
      "\n",
      "Fold: 19  Epoch: 478  Training loss = 4.5966  Validation loss = 1.2025  \n",
      "\n",
      "Fold: 19  Epoch: 479  Training loss = 4.5960  Validation loss = 1.2020  \n",
      "\n",
      "Fold: 19  Epoch: 480  Training loss = 4.5956  Validation loss = 1.2016  \n",
      "\n",
      "Fold: 19  Epoch: 481  Training loss = 4.5951  Validation loss = 1.2012  \n",
      "\n",
      "Fold: 19  Epoch: 482  Training loss = 4.5946  Validation loss = 1.2007  \n",
      "\n",
      "Fold: 19  Epoch: 483  Training loss = 4.5942  Validation loss = 1.2003  \n",
      "\n",
      "Fold: 19  Epoch: 484  Training loss = 4.5935  Validation loss = 1.1998  \n",
      "\n",
      "Fold: 19  Epoch: 485  Training loss = 4.5929  Validation loss = 1.1992  \n",
      "\n",
      "Fold: 19  Epoch: 486  Training loss = 4.5925  Validation loss = 1.1988  \n",
      "\n",
      "Fold: 19  Epoch: 487  Training loss = 4.5921  Validation loss = 1.1985  \n",
      "\n",
      "Fold: 19  Epoch: 488  Training loss = 4.5916  Validation loss = 1.1981  \n",
      "\n",
      "Fold: 19  Epoch: 489  Training loss = 4.5910  Validation loss = 1.1976  \n",
      "\n",
      "Fold: 19  Epoch: 490  Training loss = 4.5905  Validation loss = 1.1972  \n",
      "\n",
      "Fold: 19  Epoch: 491  Training loss = 4.5901  Validation loss = 1.1968  \n",
      "\n",
      "Fold: 19  Epoch: 492  Training loss = 4.5897  Validation loss = 1.1964  \n",
      "\n",
      "Fold: 19  Epoch: 493  Training loss = 4.5892  Validation loss = 1.1960  \n",
      "\n",
      "Fold: 19  Epoch: 494  Training loss = 4.5889  Validation loss = 1.1957  \n",
      "\n",
      "Fold: 19  Epoch: 495  Training loss = 4.5884  Validation loss = 1.1953  \n",
      "\n",
      "Fold: 19  Epoch: 496  Training loss = 4.5880  Validation loss = 1.1950  \n",
      "\n",
      "Fold: 19  Epoch: 497  Training loss = 4.5875  Validation loss = 1.1945  \n",
      "\n",
      "Fold: 19  Epoch: 498  Training loss = 4.5870  Validation loss = 1.1941  \n",
      "\n",
      "Fold: 19  Epoch: 499  Training loss = 4.5866  Validation loss = 1.1937  \n",
      "\n",
      "Fold: 19  Epoch: 500  Training loss = 4.5860  Validation loss = 1.1932  \n",
      "\n",
      "Check model:  Fold: 19  Optimal epoch: 500  \n",
      "\n",
      "Fold: 20  Epoch: 1  Training loss = 4.5895  Validation loss = 0.3768  \n",
      "\n",
      "Fold: 20  Epoch: 2  Training loss = 4.5890  Validation loss = 0.3773  \n",
      "\n",
      "Fold: 20  Epoch: 3  Training loss = 4.5885  Validation loss = 0.3776  \n",
      "\n",
      "Fold: 20  Epoch: 4  Training loss = 4.5880  Validation loss = 0.3780  \n",
      "\n",
      "Fold: 20  Epoch: 5  Training loss = 4.5875  Validation loss = 0.3784  \n",
      "\n",
      "Fold: 20  Epoch: 6  Training loss = 4.5870  Validation loss = 0.3789  \n",
      "\n",
      "Fold: 20  Epoch: 7  Training loss = 4.5865  Validation loss = 0.3793  \n",
      "\n",
      "Fold: 20  Epoch: 8  Training loss = 4.5860  Validation loss = 0.3798  \n",
      "\n",
      "Fold: 20  Epoch: 9  Training loss = 4.5855  Validation loss = 0.3801  \n",
      "\n",
      "Fold: 20  Epoch: 10  Training loss = 4.5849  Validation loss = 0.3806  \n",
      "\n",
      "Fold: 20  Epoch: 11  Training loss = 4.5844  Validation loss = 0.3810  \n",
      "\n",
      "Check model:  Fold: 20  Optimal epoch: 1  \n",
      "\n",
      "Fold: 21  Epoch: 1  Training loss = 4.5650  Validation loss = 2.1581  \n",
      "\n",
      "Fold: 21  Epoch: 2  Training loss = 4.5645  Validation loss = 2.1584  \n",
      "\n",
      "Fold: 21  Epoch: 3  Training loss = 4.5641  Validation loss = 2.1587  \n",
      "\n",
      "Fold: 21  Epoch: 4  Training loss = 4.5636  Validation loss = 2.1590  \n",
      "\n",
      "Fold: 21  Epoch: 5  Training loss = 4.5631  Validation loss = 2.1593  \n",
      "\n",
      "Fold: 21  Epoch: 6  Training loss = 4.5625  Validation loss = 2.1597  \n",
      "\n",
      "Fold: 21  Epoch: 7  Training loss = 4.5620  Validation loss = 2.1600  \n",
      "\n",
      "Fold: 21  Epoch: 8  Training loss = 4.5615  Validation loss = 2.1603  \n",
      "\n",
      "Fold: 21  Epoch: 9  Training loss = 4.5611  Validation loss = 2.1606  \n",
      "\n",
      "Fold: 21  Epoch: 10  Training loss = 4.5606  Validation loss = 2.1609  \n",
      "\n",
      "Fold: 21  Epoch: 11  Training loss = 4.5602  Validation loss = 2.1612  \n",
      "\n",
      "Check model:  Fold: 21  Optimal epoch: 1  \n",
      "\n",
      "Fold: 22  Epoch: 1  Training loss = 4.5618  Validation loss = 1.3444  \n",
      "\n",
      "Fold: 22  Epoch: 2  Training loss = 4.5614  Validation loss = 1.3440  \n",
      "\n",
      "Fold: 22  Epoch: 3  Training loss = 4.5610  Validation loss = 1.3436  \n",
      "\n",
      "Fold: 22  Epoch: 4  Training loss = 4.5606  Validation loss = 1.3433  \n",
      "\n",
      "Fold: 22  Epoch: 5  Training loss = 4.5602  Validation loss = 1.3429  \n",
      "\n",
      "Fold: 22  Epoch: 6  Training loss = 4.5599  Validation loss = 1.3426  \n",
      "\n",
      "Fold: 22  Epoch: 7  Training loss = 4.5594  Validation loss = 1.3422  \n",
      "\n",
      "Fold: 22  Epoch: 8  Training loss = 4.5590  Validation loss = 1.3419  \n",
      "\n",
      "Fold: 22  Epoch: 9  Training loss = 4.5586  Validation loss = 1.3415  \n",
      "\n",
      "Fold: 22  Epoch: 10  Training loss = 4.5582  Validation loss = 1.3412  \n",
      "\n",
      "Fold: 22  Epoch: 11  Training loss = 4.5577  Validation loss = 1.3408  \n",
      "\n",
      "Fold: 22  Epoch: 12  Training loss = 4.5573  Validation loss = 1.3404  \n",
      "\n",
      "Fold: 22  Epoch: 13  Training loss = 4.5568  Validation loss = 1.3399  \n",
      "\n",
      "Fold: 22  Epoch: 14  Training loss = 4.5564  Validation loss = 1.3395  \n",
      "\n",
      "Fold: 22  Epoch: 15  Training loss = 4.5560  Validation loss = 1.3392  \n",
      "\n",
      "Fold: 22  Epoch: 16  Training loss = 4.5555  Validation loss = 1.3388  \n",
      "\n",
      "Fold: 22  Epoch: 17  Training loss = 4.5551  Validation loss = 1.3384  \n",
      "\n",
      "Fold: 22  Epoch: 18  Training loss = 4.5546  Validation loss = 1.3380  \n",
      "\n",
      "Fold: 22  Epoch: 19  Training loss = 4.5542  Validation loss = 1.3376  \n",
      "\n",
      "Fold: 22  Epoch: 20  Training loss = 4.5537  Validation loss = 1.3372  \n",
      "\n",
      "Fold: 22  Epoch: 21  Training loss = 4.5533  Validation loss = 1.3369  \n",
      "\n",
      "Fold: 22  Epoch: 22  Training loss = 4.5528  Validation loss = 1.3364  \n",
      "\n",
      "Fold: 22  Epoch: 23  Training loss = 4.5523  Validation loss = 1.3359  \n",
      "\n",
      "Fold: 22  Epoch: 24  Training loss = 4.5519  Validation loss = 1.3356  \n",
      "\n",
      "Fold: 22  Epoch: 25  Training loss = 4.5514  Validation loss = 1.3351  \n",
      "\n",
      "Fold: 22  Epoch: 26  Training loss = 4.5510  Validation loss = 1.3348  \n",
      "\n",
      "Fold: 22  Epoch: 27  Training loss = 4.5507  Validation loss = 1.3345  \n",
      "\n",
      "Fold: 22  Epoch: 28  Training loss = 4.5503  Validation loss = 1.3341  \n",
      "\n",
      "Fold: 22  Epoch: 29  Training loss = 4.5499  Validation loss = 1.3337  \n",
      "\n",
      "Fold: 22  Epoch: 30  Training loss = 4.5494  Validation loss = 1.3334  \n",
      "\n",
      "Fold: 22  Epoch: 31  Training loss = 4.5490  Validation loss = 1.3330  \n",
      "\n",
      "Fold: 22  Epoch: 32  Training loss = 4.5487  Validation loss = 1.3327  \n",
      "\n",
      "Fold: 22  Epoch: 33  Training loss = 4.5483  Validation loss = 1.3323  \n",
      "\n",
      "Fold: 22  Epoch: 34  Training loss = 4.5479  Validation loss = 1.3320  \n",
      "\n",
      "Fold: 22  Epoch: 35  Training loss = 4.5475  Validation loss = 1.3316  \n",
      "\n",
      "Fold: 22  Epoch: 36  Training loss = 4.5471  Validation loss = 1.3312  \n",
      "\n",
      "Fold: 22  Epoch: 37  Training loss = 4.5467  Validation loss = 1.3309  \n",
      "\n",
      "Fold: 22  Epoch: 38  Training loss = 4.5463  Validation loss = 1.3305  \n",
      "\n",
      "Fold: 22  Epoch: 39  Training loss = 4.5459  Validation loss = 1.3302  \n",
      "\n",
      "Fold: 22  Epoch: 40  Training loss = 4.5454  Validation loss = 1.3297  \n",
      "\n",
      "Fold: 22  Epoch: 41  Training loss = 4.5449  Validation loss = 1.3293  \n",
      "\n",
      "Fold: 22  Epoch: 42  Training loss = 4.5444  Validation loss = 1.3289  \n",
      "\n",
      "Fold: 22  Epoch: 43  Training loss = 4.5440  Validation loss = 1.3286  \n",
      "\n",
      "Fold: 22  Epoch: 44  Training loss = 4.5436  Validation loss = 1.3282  \n",
      "\n",
      "Fold: 22  Epoch: 45  Training loss = 4.5433  Validation loss = 1.3279  \n",
      "\n",
      "Fold: 22  Epoch: 46  Training loss = 4.5428  Validation loss = 1.3275  \n",
      "\n",
      "Fold: 22  Epoch: 47  Training loss = 4.5425  Validation loss = 1.3272  \n",
      "\n",
      "Fold: 22  Epoch: 48  Training loss = 4.5420  Validation loss = 1.3268  \n",
      "\n",
      "Fold: 22  Epoch: 49  Training loss = 4.5416  Validation loss = 1.3265  \n",
      "\n",
      "Fold: 22  Epoch: 50  Training loss = 4.5412  Validation loss = 1.3261  \n",
      "\n",
      "Fold: 22  Epoch: 51  Training loss = 4.5408  Validation loss = 1.3258  \n",
      "\n",
      "Fold: 22  Epoch: 52  Training loss = 4.5404  Validation loss = 1.3254  \n",
      "\n",
      "Fold: 22  Epoch: 53  Training loss = 4.5401  Validation loss = 1.3251  \n",
      "\n",
      "Fold: 22  Epoch: 54  Training loss = 4.5397  Validation loss = 1.3247  \n",
      "\n",
      "Fold: 22  Epoch: 55  Training loss = 4.5392  Validation loss = 1.3243  \n",
      "\n",
      "Fold: 22  Epoch: 56  Training loss = 4.5388  Validation loss = 1.3239  \n",
      "\n",
      "Fold: 22  Epoch: 57  Training loss = 4.5382  Validation loss = 1.3235  \n",
      "\n",
      "Fold: 22  Epoch: 58  Training loss = 4.5378  Validation loss = 1.3231  \n",
      "\n",
      "Fold: 22  Epoch: 59  Training loss = 4.5375  Validation loss = 1.3228  \n",
      "\n",
      "Fold: 22  Epoch: 60  Training loss = 4.5370  Validation loss = 1.3224  \n",
      "\n",
      "Fold: 22  Epoch: 61  Training loss = 4.5367  Validation loss = 1.3221  \n",
      "\n",
      "Fold: 22  Epoch: 62  Training loss = 4.5364  Validation loss = 1.3219  \n",
      "\n",
      "Fold: 22  Epoch: 63  Training loss = 4.5360  Validation loss = 1.3216  \n",
      "\n",
      "Fold: 22  Epoch: 64  Training loss = 4.5357  Validation loss = 1.3213  \n",
      "\n",
      "Fold: 22  Epoch: 65  Training loss = 4.5353  Validation loss = 1.3209  \n",
      "\n",
      "Fold: 22  Epoch: 66  Training loss = 4.5348  Validation loss = 1.3205  \n",
      "\n",
      "Fold: 22  Epoch: 67  Training loss = 4.5342  Validation loss = 1.3200  \n",
      "\n",
      "Fold: 22  Epoch: 68  Training loss = 4.5338  Validation loss = 1.3196  \n",
      "\n",
      "Fold: 22  Epoch: 69  Training loss = 4.5334  Validation loss = 1.3192  \n",
      "\n",
      "Fold: 22  Epoch: 70  Training loss = 4.5330  Validation loss = 1.3189  \n",
      "\n",
      "Fold: 22  Epoch: 71  Training loss = 4.5326  Validation loss = 1.3185  \n",
      "\n",
      "Fold: 22  Epoch: 72  Training loss = 4.5321  Validation loss = 1.3180  \n",
      "\n",
      "Fold: 22  Epoch: 73  Training loss = 4.5317  Validation loss = 1.3177  \n",
      "\n",
      "Fold: 22  Epoch: 74  Training loss = 4.5314  Validation loss = 1.3174  \n",
      "\n",
      "Fold: 22  Epoch: 75  Training loss = 4.5309  Validation loss = 1.3170  \n",
      "\n",
      "Fold: 22  Epoch: 76  Training loss = 4.5304  Validation loss = 1.3165  \n",
      "\n",
      "Fold: 22  Epoch: 77  Training loss = 4.5300  Validation loss = 1.3162  \n",
      "\n",
      "Fold: 22  Epoch: 78  Training loss = 4.5296  Validation loss = 1.3158  \n",
      "\n",
      "Fold: 22  Epoch: 79  Training loss = 4.5291  Validation loss = 1.3155  \n",
      "\n",
      "Fold: 22  Epoch: 80  Training loss = 4.5288  Validation loss = 1.3152  \n",
      "\n",
      "Fold: 22  Epoch: 81  Training loss = 4.5284  Validation loss = 1.3148  \n",
      "\n",
      "Fold: 22  Epoch: 82  Training loss = 4.5280  Validation loss = 1.3145  \n",
      "\n",
      "Fold: 22  Epoch: 83  Training loss = 4.5276  Validation loss = 1.3142  \n",
      "\n",
      "Fold: 22  Epoch: 84  Training loss = 4.5271  Validation loss = 1.3138  \n",
      "\n",
      "Fold: 22  Epoch: 85  Training loss = 4.5268  Validation loss = 1.3135  \n",
      "\n",
      "Fold: 22  Epoch: 86  Training loss = 4.5265  Validation loss = 1.3133  \n",
      "\n",
      "Fold: 22  Epoch: 87  Training loss = 4.5260  Validation loss = 1.3129  \n",
      "\n",
      "Fold: 22  Epoch: 88  Training loss = 4.5256  Validation loss = 1.3125  \n",
      "\n",
      "Fold: 22  Epoch: 89  Training loss = 4.5252  Validation loss = 1.3122  \n",
      "\n",
      "Fold: 22  Epoch: 90  Training loss = 4.5249  Validation loss = 1.3119  \n",
      "\n",
      "Fold: 22  Epoch: 91  Training loss = 4.5244  Validation loss = 1.3115  \n",
      "\n",
      "Fold: 22  Epoch: 92  Training loss = 4.5242  Validation loss = 1.3112  \n",
      "\n",
      "Fold: 22  Epoch: 93  Training loss = 4.5238  Validation loss = 1.3110  \n",
      "\n",
      "Fold: 22  Epoch: 94  Training loss = 4.5234  Validation loss = 1.3106  \n",
      "\n",
      "Fold: 22  Epoch: 95  Training loss = 4.5231  Validation loss = 1.3104  \n",
      "\n",
      "Fold: 22  Epoch: 96  Training loss = 4.5227  Validation loss = 1.3101  \n",
      "\n",
      "Fold: 22  Epoch: 97  Training loss = 4.5224  Validation loss = 1.3098  \n",
      "\n",
      "Fold: 22  Epoch: 98  Training loss = 4.5219  Validation loss = 1.3093  \n",
      "\n",
      "Fold: 22  Epoch: 99  Training loss = 4.5216  Validation loss = 1.3091  \n",
      "\n",
      "Fold: 22  Epoch: 100  Training loss = 4.5212  Validation loss = 1.3087  \n",
      "\n",
      "Fold: 22  Epoch: 101  Training loss = 4.5207  Validation loss = 1.3083  \n",
      "\n",
      "Fold: 22  Epoch: 102  Training loss = 4.5203  Validation loss = 1.3079  \n",
      "\n",
      "Fold: 22  Epoch: 103  Training loss = 4.5200  Validation loss = 1.3076  \n",
      "\n",
      "Fold: 22  Epoch: 104  Training loss = 4.5196  Validation loss = 1.3072  \n",
      "\n",
      "Fold: 22  Epoch: 105  Training loss = 4.5193  Validation loss = 1.3070  \n",
      "\n",
      "Fold: 22  Epoch: 106  Training loss = 4.5189  Validation loss = 1.3067  \n",
      "\n",
      "Fold: 22  Epoch: 107  Training loss = 4.5184  Validation loss = 1.3064  \n",
      "\n",
      "Fold: 22  Epoch: 108  Training loss = 4.5180  Validation loss = 1.3060  \n",
      "\n",
      "Fold: 22  Epoch: 109  Training loss = 4.5176  Validation loss = 1.3056  \n",
      "\n",
      "Fold: 22  Epoch: 110  Training loss = 4.5173  Validation loss = 1.3053  \n",
      "\n",
      "Fold: 22  Epoch: 111  Training loss = 4.5169  Validation loss = 1.3050  \n",
      "\n",
      "Fold: 22  Epoch: 112  Training loss = 4.5164  Validation loss = 1.3047  \n",
      "\n",
      "Fold: 22  Epoch: 113  Training loss = 4.5160  Validation loss = 1.3043  \n",
      "\n",
      "Fold: 22  Epoch: 114  Training loss = 4.5155  Validation loss = 1.3039  \n",
      "\n",
      "Fold: 22  Epoch: 115  Training loss = 4.5152  Validation loss = 1.3036  \n",
      "\n",
      "Fold: 22  Epoch: 116  Training loss = 4.5148  Validation loss = 1.3033  \n",
      "\n",
      "Fold: 22  Epoch: 117  Training loss = 4.5143  Validation loss = 1.3028  \n",
      "\n",
      "Fold: 22  Epoch: 118  Training loss = 4.5138  Validation loss = 1.3025  \n",
      "\n",
      "Fold: 22  Epoch: 119  Training loss = 4.5134  Validation loss = 1.3020  \n",
      "\n",
      "Fold: 22  Epoch: 120  Training loss = 4.5130  Validation loss = 1.3017  \n",
      "\n",
      "Fold: 22  Epoch: 121  Training loss = 4.5125  Validation loss = 1.3013  \n",
      "\n",
      "Fold: 22  Epoch: 122  Training loss = 4.5120  Validation loss = 1.3010  \n",
      "\n",
      "Fold: 22  Epoch: 123  Training loss = 4.5118  Validation loss = 1.3007  \n",
      "\n",
      "Fold: 22  Epoch: 124  Training loss = 4.5114  Validation loss = 1.3004  \n",
      "\n",
      "Fold: 22  Epoch: 125  Training loss = 4.5110  Validation loss = 1.3001  \n",
      "\n",
      "Fold: 22  Epoch: 126  Training loss = 4.5105  Validation loss = 1.2996  \n",
      "\n",
      "Fold: 22  Epoch: 127  Training loss = 4.5101  Validation loss = 1.2993  \n",
      "\n",
      "Fold: 22  Epoch: 128  Training loss = 4.5096  Validation loss = 1.2989  \n",
      "\n",
      "Fold: 22  Epoch: 129  Training loss = 4.5093  Validation loss = 1.2987  \n",
      "\n",
      "Fold: 22  Epoch: 130  Training loss = 4.5089  Validation loss = 1.2984  \n",
      "\n",
      "Fold: 22  Epoch: 131  Training loss = 4.5086  Validation loss = 1.2981  \n",
      "\n",
      "Fold: 22  Epoch: 132  Training loss = 4.5081  Validation loss = 1.2977  \n",
      "\n",
      "Fold: 22  Epoch: 133  Training loss = 4.5077  Validation loss = 1.2974  \n",
      "\n",
      "Fold: 22  Epoch: 134  Training loss = 4.5073  Validation loss = 1.2970  \n",
      "\n",
      "Fold: 22  Epoch: 135  Training loss = 4.5069  Validation loss = 1.2967  \n",
      "\n",
      "Fold: 22  Epoch: 136  Training loss = 4.5064  Validation loss = 1.2963  \n",
      "\n",
      "Fold: 22  Epoch: 137  Training loss = 4.5060  Validation loss = 1.2959  \n",
      "\n",
      "Fold: 22  Epoch: 138  Training loss = 4.5054  Validation loss = 1.2953  \n",
      "\n",
      "Fold: 22  Epoch: 139  Training loss = 4.5051  Validation loss = 1.2951  \n",
      "\n",
      "Fold: 22  Epoch: 140  Training loss = 4.5048  Validation loss = 1.2949  \n",
      "\n",
      "Fold: 22  Epoch: 141  Training loss = 4.5044  Validation loss = 1.2946  \n",
      "\n",
      "Fold: 22  Epoch: 142  Training loss = 4.5041  Validation loss = 1.2943  \n",
      "\n",
      "Fold: 22  Epoch: 143  Training loss = 4.5037  Validation loss = 1.2940  \n",
      "\n",
      "Fold: 22  Epoch: 144  Training loss = 4.5034  Validation loss = 1.2937  \n",
      "\n",
      "Fold: 22  Epoch: 145  Training loss = 4.5029  Validation loss = 1.2934  \n",
      "\n",
      "Fold: 22  Epoch: 146  Training loss = 4.5026  Validation loss = 1.2931  \n",
      "\n",
      "Fold: 22  Epoch: 147  Training loss = 4.5022  Validation loss = 1.2928  \n",
      "\n",
      "Fold: 22  Epoch: 148  Training loss = 4.5018  Validation loss = 1.2925  \n",
      "\n",
      "Fold: 22  Epoch: 149  Training loss = 4.5015  Validation loss = 1.2922  \n",
      "\n",
      "Fold: 22  Epoch: 150  Training loss = 4.5011  Validation loss = 1.2918  \n",
      "\n",
      "Fold: 22  Epoch: 151  Training loss = 4.5007  Validation loss = 1.2915  \n",
      "\n",
      "Fold: 22  Epoch: 152  Training loss = 4.5002  Validation loss = 1.2911  \n",
      "\n",
      "Fold: 22  Epoch: 153  Training loss = 4.4999  Validation loss = 1.2909  \n",
      "\n",
      "Fold: 22  Epoch: 154  Training loss = 4.4995  Validation loss = 1.2906  \n",
      "\n",
      "Fold: 22  Epoch: 155  Training loss = 4.4992  Validation loss = 1.2903  \n",
      "\n",
      "Fold: 22  Epoch: 156  Training loss = 4.4987  Validation loss = 1.2899  \n",
      "\n",
      "Fold: 22  Epoch: 157  Training loss = 4.4983  Validation loss = 1.2895  \n",
      "\n",
      "Fold: 22  Epoch: 158  Training loss = 4.4976  Validation loss = 1.2890  \n",
      "\n",
      "Fold: 22  Epoch: 159  Training loss = 4.4972  Validation loss = 1.2886  \n",
      "\n",
      "Fold: 22  Epoch: 160  Training loss = 4.4968  Validation loss = 1.2883  \n",
      "\n",
      "Fold: 22  Epoch: 161  Training loss = 4.4965  Validation loss = 1.2880  \n",
      "\n",
      "Fold: 22  Epoch: 162  Training loss = 4.4960  Validation loss = 1.2877  \n",
      "\n",
      "Fold: 22  Epoch: 163  Training loss = 4.4956  Validation loss = 1.2874  \n",
      "\n",
      "Fold: 22  Epoch: 164  Training loss = 4.4952  Validation loss = 1.2871  \n",
      "\n",
      "Fold: 22  Epoch: 165  Training loss = 4.4949  Validation loss = 1.2868  \n",
      "\n",
      "Fold: 22  Epoch: 166  Training loss = 4.4945  Validation loss = 1.2864  \n",
      "\n",
      "Fold: 22  Epoch: 167  Training loss = 4.4941  Validation loss = 1.2860  \n",
      "\n",
      "Fold: 22  Epoch: 168  Training loss = 4.4938  Validation loss = 1.2857  \n",
      "\n",
      "Fold: 22  Epoch: 169  Training loss = 4.4934  Validation loss = 1.2854  \n",
      "\n",
      "Fold: 22  Epoch: 170  Training loss = 4.4931  Validation loss = 1.2852  \n",
      "\n",
      "Fold: 22  Epoch: 171  Training loss = 4.4927  Validation loss = 1.2848  \n",
      "\n",
      "Fold: 22  Epoch: 172  Training loss = 4.4923  Validation loss = 1.2844  \n",
      "\n",
      "Fold: 22  Epoch: 173  Training loss = 4.4919  Validation loss = 1.2841  \n",
      "\n",
      "Fold: 22  Epoch: 174  Training loss = 4.4914  Validation loss = 1.2837  \n",
      "\n",
      "Fold: 22  Epoch: 175  Training loss = 4.4910  Validation loss = 1.2834  \n",
      "\n",
      "Fold: 22  Epoch: 176  Training loss = 4.4906  Validation loss = 1.2830  \n",
      "\n",
      "Fold: 22  Epoch: 177  Training loss = 4.4902  Validation loss = 1.2826  \n",
      "\n",
      "Fold: 22  Epoch: 178  Training loss = 4.4898  Validation loss = 1.2823  \n",
      "\n",
      "Fold: 22  Epoch: 179  Training loss = 4.4893  Validation loss = 1.2819  \n",
      "\n",
      "Fold: 22  Epoch: 180  Training loss = 4.4888  Validation loss = 1.2815  \n",
      "\n",
      "Fold: 22  Epoch: 181  Training loss = 4.4885  Validation loss = 1.2812  \n",
      "\n",
      "Fold: 22  Epoch: 182  Training loss = 4.4881  Validation loss = 1.2809  \n",
      "\n",
      "Fold: 22  Epoch: 183  Training loss = 4.4878  Validation loss = 1.2806  \n",
      "\n",
      "Fold: 22  Epoch: 184  Training loss = 4.4874  Validation loss = 1.2803  \n",
      "\n",
      "Fold: 22  Epoch: 185  Training loss = 4.4869  Validation loss = 1.2799  \n",
      "\n",
      "Fold: 22  Epoch: 186  Training loss = 4.4865  Validation loss = 1.2796  \n",
      "\n",
      "Fold: 22  Epoch: 187  Training loss = 4.4861  Validation loss = 1.2792  \n",
      "\n",
      "Fold: 22  Epoch: 188  Training loss = 4.4857  Validation loss = 1.2788  \n",
      "\n",
      "Fold: 22  Epoch: 189  Training loss = 4.4855  Validation loss = 1.2786  \n",
      "\n",
      "Fold: 22  Epoch: 190  Training loss = 4.4850  Validation loss = 1.2783  \n",
      "\n",
      "Fold: 22  Epoch: 191  Training loss = 4.4846  Validation loss = 1.2779  \n",
      "\n",
      "Fold: 22  Epoch: 192  Training loss = 4.4843  Validation loss = 1.2776  \n",
      "\n",
      "Fold: 22  Epoch: 193  Training loss = 4.4839  Validation loss = 1.2773  \n",
      "\n",
      "Fold: 22  Epoch: 194  Training loss = 4.4835  Validation loss = 1.2770  \n",
      "\n",
      "Fold: 22  Epoch: 195  Training loss = 4.4830  Validation loss = 1.2765  \n",
      "\n",
      "Fold: 22  Epoch: 196  Training loss = 4.4826  Validation loss = 1.2762  \n",
      "\n",
      "Fold: 22  Epoch: 197  Training loss = 4.4821  Validation loss = 1.2758  \n",
      "\n",
      "Fold: 22  Epoch: 198  Training loss = 4.4818  Validation loss = 1.2755  \n",
      "\n",
      "Fold: 22  Epoch: 199  Training loss = 4.4814  Validation loss = 1.2752  \n",
      "\n",
      "Fold: 22  Epoch: 200  Training loss = 4.4811  Validation loss = 1.2749  \n",
      "\n",
      "Fold: 22  Epoch: 201  Training loss = 4.4807  Validation loss = 1.2747  \n",
      "\n",
      "Fold: 22  Epoch: 202  Training loss = 4.4805  Validation loss = 1.2745  \n",
      "\n",
      "Fold: 22  Epoch: 203  Training loss = 4.4800  Validation loss = 1.2741  \n",
      "\n",
      "Fold: 22  Epoch: 204  Training loss = 4.4797  Validation loss = 1.2738  \n",
      "\n",
      "Fold: 22  Epoch: 205  Training loss = 4.4793  Validation loss = 1.2735  \n",
      "\n",
      "Fold: 22  Epoch: 206  Training loss = 4.4790  Validation loss = 1.2732  \n",
      "\n",
      "Fold: 22  Epoch: 207  Training loss = 4.4787  Validation loss = 1.2729  \n",
      "\n",
      "Fold: 22  Epoch: 208  Training loss = 4.4782  Validation loss = 1.2726  \n",
      "\n",
      "Fold: 22  Epoch: 209  Training loss = 4.4779  Validation loss = 1.2723  \n",
      "\n",
      "Fold: 22  Epoch: 210  Training loss = 4.4775  Validation loss = 1.2720  \n",
      "\n",
      "Fold: 22  Epoch: 211  Training loss = 4.4771  Validation loss = 1.2717  \n",
      "\n",
      "Fold: 22  Epoch: 212  Training loss = 4.4766  Validation loss = 1.2713  \n",
      "\n",
      "Fold: 22  Epoch: 213  Training loss = 4.4762  Validation loss = 1.2709  \n",
      "\n",
      "Fold: 22  Epoch: 214  Training loss = 4.4758  Validation loss = 1.2707  \n",
      "\n",
      "Fold: 22  Epoch: 215  Training loss = 4.4754  Validation loss = 1.2703  \n",
      "\n",
      "Fold: 22  Epoch: 216  Training loss = 4.4749  Validation loss = 1.2698  \n",
      "\n",
      "Fold: 22  Epoch: 217  Training loss = 4.4744  Validation loss = 1.2695  \n",
      "\n",
      "Fold: 22  Epoch: 218  Training loss = 4.4741  Validation loss = 1.2692  \n",
      "\n",
      "Fold: 22  Epoch: 219  Training loss = 4.4737  Validation loss = 1.2689  \n",
      "\n",
      "Fold: 22  Epoch: 220  Training loss = 4.4733  Validation loss = 1.2686  \n",
      "\n",
      "Fold: 22  Epoch: 221  Training loss = 4.4730  Validation loss = 1.2683  \n",
      "\n",
      "Fold: 22  Epoch: 222  Training loss = 4.4725  Validation loss = 1.2679  \n",
      "\n",
      "Fold: 22  Epoch: 223  Training loss = 4.4721  Validation loss = 1.2676  \n",
      "\n",
      "Fold: 22  Epoch: 224  Training loss = 4.4717  Validation loss = 1.2673  \n",
      "\n",
      "Fold: 22  Epoch: 225  Training loss = 4.4714  Validation loss = 1.2670  \n",
      "\n",
      "Fold: 22  Epoch: 226  Training loss = 4.4710  Validation loss = 1.2666  \n",
      "\n",
      "Fold: 22  Epoch: 227  Training loss = 4.4706  Validation loss = 1.2664  \n",
      "\n",
      "Fold: 22  Epoch: 228  Training loss = 4.4703  Validation loss = 1.2661  \n",
      "\n",
      "Fold: 22  Epoch: 229  Training loss = 4.4698  Validation loss = 1.2657  \n",
      "\n",
      "Fold: 22  Epoch: 230  Training loss = 4.4694  Validation loss = 1.2654  \n",
      "\n",
      "Fold: 22  Epoch: 231  Training loss = 4.4689  Validation loss = 1.2651  \n",
      "\n",
      "Fold: 22  Epoch: 232  Training loss = 4.4686  Validation loss = 1.2647  \n",
      "\n",
      "Fold: 22  Epoch: 233  Training loss = 4.4682  Validation loss = 1.2644  \n",
      "\n",
      "Fold: 22  Epoch: 234  Training loss = 4.4678  Validation loss = 1.2641  \n",
      "\n",
      "Fold: 22  Epoch: 235  Training loss = 4.4673  Validation loss = 1.2637  \n",
      "\n",
      "Fold: 22  Epoch: 236  Training loss = 4.4671  Validation loss = 1.2635  \n",
      "\n",
      "Fold: 22  Epoch: 237  Training loss = 4.4667  Validation loss = 1.2632  \n",
      "\n",
      "Fold: 22  Epoch: 238  Training loss = 4.4663  Validation loss = 1.2629  \n",
      "\n",
      "Fold: 22  Epoch: 239  Training loss = 4.4659  Validation loss = 1.2626  \n",
      "\n",
      "Fold: 22  Epoch: 240  Training loss = 4.4656  Validation loss = 1.2624  \n",
      "\n",
      "Fold: 22  Epoch: 241  Training loss = 4.4652  Validation loss = 1.2621  \n",
      "\n",
      "Fold: 22  Epoch: 242  Training loss = 4.4649  Validation loss = 1.2618  \n",
      "\n",
      "Fold: 22  Epoch: 243  Training loss = 4.4644  Validation loss = 1.2614  \n",
      "\n",
      "Fold: 22  Epoch: 244  Training loss = 4.4640  Validation loss = 1.2610  \n",
      "\n",
      "Fold: 22  Epoch: 245  Training loss = 4.4636  Validation loss = 1.2607  \n",
      "\n",
      "Fold: 22  Epoch: 246  Training loss = 4.4633  Validation loss = 1.2603  \n",
      "\n",
      "Fold: 22  Epoch: 247  Training loss = 4.4629  Validation loss = 1.2600  \n",
      "\n",
      "Fold: 22  Epoch: 248  Training loss = 4.4625  Validation loss = 1.2597  \n",
      "\n",
      "Fold: 22  Epoch: 249  Training loss = 4.4621  Validation loss = 1.2594  \n",
      "\n",
      "Fold: 22  Epoch: 250  Training loss = 4.4617  Validation loss = 1.2591  \n",
      "\n",
      "Fold: 22  Epoch: 251  Training loss = 4.4613  Validation loss = 1.2587  \n",
      "\n",
      "Fold: 22  Epoch: 252  Training loss = 4.4610  Validation loss = 1.2584  \n",
      "\n",
      "Fold: 22  Epoch: 253  Training loss = 4.4606  Validation loss = 1.2581  \n",
      "\n",
      "Fold: 22  Epoch: 254  Training loss = 4.4601  Validation loss = 1.2578  \n",
      "\n",
      "Fold: 22  Epoch: 255  Training loss = 4.4599  Validation loss = 1.2576  \n",
      "\n",
      "Fold: 22  Epoch: 256  Training loss = 4.4595  Validation loss = 1.2573  \n",
      "\n",
      "Fold: 22  Epoch: 257  Training loss = 4.4590  Validation loss = 1.2569  \n",
      "\n",
      "Fold: 22  Epoch: 258  Training loss = 4.4587  Validation loss = 1.2568  \n",
      "\n",
      "Fold: 22  Epoch: 259  Training loss = 4.4583  Validation loss = 1.2565  \n",
      "\n",
      "Fold: 22  Epoch: 260  Training loss = 4.4579  Validation loss = 1.2562  \n",
      "\n",
      "Fold: 22  Epoch: 261  Training loss = 4.4575  Validation loss = 1.2558  \n",
      "\n",
      "Fold: 22  Epoch: 262  Training loss = 4.4571  Validation loss = 1.2555  \n",
      "\n",
      "Fold: 22  Epoch: 263  Training loss = 4.4567  Validation loss = 1.2552  \n",
      "\n",
      "Fold: 22  Epoch: 264  Training loss = 4.4562  Validation loss = 1.2548  \n",
      "\n",
      "Fold: 22  Epoch: 265  Training loss = 4.4559  Validation loss = 1.2545  \n",
      "\n",
      "Fold: 22  Epoch: 266  Training loss = 4.4555  Validation loss = 1.2542  \n",
      "\n",
      "Fold: 22  Epoch: 267  Training loss = 4.4551  Validation loss = 1.2538  \n",
      "\n",
      "Fold: 22  Epoch: 268  Training loss = 4.4547  Validation loss = 1.2534  \n",
      "\n",
      "Fold: 22  Epoch: 269  Training loss = 4.4544  Validation loss = 1.2532  \n",
      "\n",
      "Fold: 22  Epoch: 270  Training loss = 4.4540  Validation loss = 1.2529  \n",
      "\n",
      "Fold: 22  Epoch: 271  Training loss = 4.4535  Validation loss = 1.2525  \n",
      "\n",
      "Fold: 22  Epoch: 272  Training loss = 4.4532  Validation loss = 1.2522  \n",
      "\n",
      "Fold: 22  Epoch: 273  Training loss = 4.4527  Validation loss = 1.2519  \n",
      "\n",
      "Fold: 22  Epoch: 274  Training loss = 4.4522  Validation loss = 1.2515  \n",
      "\n",
      "Fold: 22  Epoch: 275  Training loss = 4.4517  Validation loss = 1.2510  \n",
      "\n",
      "Fold: 22  Epoch: 276  Training loss = 4.4513  Validation loss = 1.2506  \n",
      "\n",
      "Fold: 22  Epoch: 277  Training loss = 4.4510  Validation loss = 1.2504  \n",
      "\n",
      "Fold: 22  Epoch: 278  Training loss = 4.4507  Validation loss = 1.2502  \n",
      "\n",
      "Fold: 22  Epoch: 279  Training loss = 4.4504  Validation loss = 1.2500  \n",
      "\n",
      "Fold: 22  Epoch: 280  Training loss = 4.4500  Validation loss = 1.2497  \n",
      "\n",
      "Fold: 22  Epoch: 281  Training loss = 4.4496  Validation loss = 1.2494  \n",
      "\n",
      "Fold: 22  Epoch: 282  Training loss = 4.4492  Validation loss = 1.2491  \n",
      "\n",
      "Fold: 22  Epoch: 283  Training loss = 4.4488  Validation loss = 1.2487  \n",
      "\n",
      "Fold: 22  Epoch: 284  Training loss = 4.4484  Validation loss = 1.2484  \n",
      "\n",
      "Fold: 22  Epoch: 285  Training loss = 4.4480  Validation loss = 1.2480  \n",
      "\n",
      "Fold: 22  Epoch: 286  Training loss = 4.4477  Validation loss = 1.2478  \n",
      "\n",
      "Fold: 22  Epoch: 287  Training loss = 4.4474  Validation loss = 1.2475  \n",
      "\n",
      "Fold: 22  Epoch: 288  Training loss = 4.4470  Validation loss = 1.2473  \n",
      "\n",
      "Fold: 22  Epoch: 289  Training loss = 4.4466  Validation loss = 1.2469  \n",
      "\n",
      "Fold: 22  Epoch: 290  Training loss = 4.4463  Validation loss = 1.2466  \n",
      "\n",
      "Fold: 22  Epoch: 291  Training loss = 4.4460  Validation loss = 1.2464  \n",
      "\n",
      "Fold: 22  Epoch: 292  Training loss = 4.4456  Validation loss = 1.2461  \n",
      "\n",
      "Fold: 22  Epoch: 293  Training loss = 4.4452  Validation loss = 1.2458  \n",
      "\n",
      "Fold: 22  Epoch: 294  Training loss = 4.4449  Validation loss = 1.2456  \n",
      "\n",
      "Fold: 22  Epoch: 295  Training loss = 4.4446  Validation loss = 1.2453  \n",
      "\n",
      "Fold: 22  Epoch: 296  Training loss = 4.4441  Validation loss = 1.2450  \n",
      "\n",
      "Fold: 22  Epoch: 297  Training loss = 4.4437  Validation loss = 1.2448  \n",
      "\n",
      "Fold: 22  Epoch: 298  Training loss = 4.4434  Validation loss = 1.2446  \n",
      "\n",
      "Fold: 22  Epoch: 299  Training loss = 4.4430  Validation loss = 1.2442  \n",
      "\n",
      "Fold: 22  Epoch: 300  Training loss = 4.4427  Validation loss = 1.2440  \n",
      "\n",
      "Fold: 22  Epoch: 301  Training loss = 4.4423  Validation loss = 1.2436  \n",
      "\n",
      "Fold: 22  Epoch: 302  Training loss = 4.4420  Validation loss = 1.2434  \n",
      "\n",
      "Fold: 22  Epoch: 303  Training loss = 4.4415  Validation loss = 1.2430  \n",
      "\n",
      "Fold: 22  Epoch: 304  Training loss = 4.4411  Validation loss = 1.2427  \n",
      "\n",
      "Fold: 22  Epoch: 305  Training loss = 4.4408  Validation loss = 1.2425  \n",
      "\n",
      "Fold: 22  Epoch: 306  Training loss = 4.4405  Validation loss = 1.2422  \n",
      "\n",
      "Fold: 22  Epoch: 307  Training loss = 4.4401  Validation loss = 1.2420  \n",
      "\n",
      "Fold: 22  Epoch: 308  Training loss = 4.4397  Validation loss = 1.2416  \n",
      "\n",
      "Fold: 22  Epoch: 309  Training loss = 4.4392  Validation loss = 1.2413  \n",
      "\n",
      "Fold: 22  Epoch: 310  Training loss = 4.4390  Validation loss = 1.2411  \n",
      "\n",
      "Fold: 22  Epoch: 311  Training loss = 4.4386  Validation loss = 1.2408  \n",
      "\n",
      "Fold: 22  Epoch: 312  Training loss = 4.4382  Validation loss = 1.2405  \n",
      "\n",
      "Fold: 22  Epoch: 313  Training loss = 4.4379  Validation loss = 1.2402  \n",
      "\n",
      "Fold: 22  Epoch: 314  Training loss = 4.4376  Validation loss = 1.2400  \n",
      "\n",
      "Fold: 22  Epoch: 315  Training loss = 4.4372  Validation loss = 1.2398  \n",
      "\n",
      "Fold: 22  Epoch: 316  Training loss = 4.4369  Validation loss = 1.2396  \n",
      "\n",
      "Fold: 22  Epoch: 317  Training loss = 4.4365  Validation loss = 1.2392  \n",
      "\n",
      "Fold: 22  Epoch: 318  Training loss = 4.4361  Validation loss = 1.2390  \n",
      "\n",
      "Fold: 22  Epoch: 319  Training loss = 4.4355  Validation loss = 1.2385  \n",
      "\n",
      "Fold: 22  Epoch: 320  Training loss = 4.4351  Validation loss = 1.2381  \n",
      "\n",
      "Fold: 22  Epoch: 321  Training loss = 4.4347  Validation loss = 1.2378  \n",
      "\n",
      "Fold: 22  Epoch: 322  Training loss = 4.4342  Validation loss = 1.2374  \n",
      "\n",
      "Fold: 22  Epoch: 323  Training loss = 4.4338  Validation loss = 1.2371  \n",
      "\n",
      "Fold: 22  Epoch: 324  Training loss = 4.4335  Validation loss = 1.2369  \n",
      "\n",
      "Fold: 22  Epoch: 325  Training loss = 4.4331  Validation loss = 1.2366  \n",
      "\n",
      "Fold: 22  Epoch: 326  Training loss = 4.4328  Validation loss = 1.2364  \n",
      "\n",
      "Fold: 22  Epoch: 327  Training loss = 4.4325  Validation loss = 1.2362  \n",
      "\n",
      "Fold: 22  Epoch: 328  Training loss = 4.4321  Validation loss = 1.2358  \n",
      "\n",
      "Fold: 22  Epoch: 329  Training loss = 4.4317  Validation loss = 1.2356  \n",
      "\n",
      "Fold: 22  Epoch: 330  Training loss = 4.4315  Validation loss = 1.2353  \n",
      "\n",
      "Fold: 22  Epoch: 331  Training loss = 4.4311  Validation loss = 1.2350  \n",
      "\n",
      "Fold: 22  Epoch: 332  Training loss = 4.4308  Validation loss = 1.2348  \n",
      "\n",
      "Fold: 22  Epoch: 333  Training loss = 4.4304  Validation loss = 1.2345  \n",
      "\n",
      "Fold: 22  Epoch: 334  Training loss = 4.4299  Validation loss = 1.2341  \n",
      "\n",
      "Fold: 22  Epoch: 335  Training loss = 4.4297  Validation loss = 1.2339  \n",
      "\n",
      "Fold: 22  Epoch: 336  Training loss = 4.4293  Validation loss = 1.2336  \n",
      "\n",
      "Fold: 22  Epoch: 337  Training loss = 4.4290  Validation loss = 1.2334  \n",
      "\n",
      "Fold: 22  Epoch: 338  Training loss = 4.4286  Validation loss = 1.2331  \n",
      "\n",
      "Fold: 22  Epoch: 339  Training loss = 4.4282  Validation loss = 1.2328  \n",
      "\n",
      "Fold: 22  Epoch: 340  Training loss = 4.4279  Validation loss = 1.2326  \n",
      "\n",
      "Fold: 22  Epoch: 341  Training loss = 4.4275  Validation loss = 1.2323  \n",
      "\n",
      "Fold: 22  Epoch: 342  Training loss = 4.4272  Validation loss = 1.2320  \n",
      "\n",
      "Fold: 22  Epoch: 343  Training loss = 4.4269  Validation loss = 1.2318  \n",
      "\n",
      "Fold: 22  Epoch: 344  Training loss = 4.4264  Validation loss = 1.2314  \n",
      "\n",
      "Fold: 22  Epoch: 345  Training loss = 4.4261  Validation loss = 1.2311  \n",
      "\n",
      "Fold: 22  Epoch: 346  Training loss = 4.4258  Validation loss = 1.2310  \n",
      "\n",
      "Fold: 22  Epoch: 347  Training loss = 4.4255  Validation loss = 1.2307  \n",
      "\n",
      "Fold: 22  Epoch: 348  Training loss = 4.4250  Validation loss = 1.2303  \n",
      "\n",
      "Fold: 22  Epoch: 349  Training loss = 4.4246  Validation loss = 1.2300  \n",
      "\n",
      "Fold: 22  Epoch: 350  Training loss = 4.4243  Validation loss = 1.2298  \n",
      "\n",
      "Fold: 22  Epoch: 351  Training loss = 4.4240  Validation loss = 1.2296  \n",
      "\n",
      "Fold: 22  Epoch: 352  Training loss = 4.4235  Validation loss = 1.2292  \n",
      "\n",
      "Fold: 22  Epoch: 353  Training loss = 4.4232  Validation loss = 1.2290  \n",
      "\n",
      "Fold: 22  Epoch: 354  Training loss = 4.4228  Validation loss = 1.2287  \n",
      "\n",
      "Fold: 22  Epoch: 355  Training loss = 4.4224  Validation loss = 1.2284  \n",
      "\n",
      "Fold: 22  Epoch: 356  Training loss = 4.4220  Validation loss = 1.2281  \n",
      "\n",
      "Fold: 22  Epoch: 357  Training loss = 4.4217  Validation loss = 1.2279  \n",
      "\n",
      "Fold: 22  Epoch: 358  Training loss = 4.4212  Validation loss = 1.2275  \n",
      "\n",
      "Fold: 22  Epoch: 359  Training loss = 4.4209  Validation loss = 1.2273  \n",
      "\n",
      "Fold: 22  Epoch: 360  Training loss = 4.4205  Validation loss = 1.2270  \n",
      "\n",
      "Fold: 22  Epoch: 361  Training loss = 4.4201  Validation loss = 1.2267  \n",
      "\n",
      "Fold: 22  Epoch: 362  Training loss = 4.4197  Validation loss = 1.2264  \n",
      "\n",
      "Fold: 22  Epoch: 363  Training loss = 4.4191  Validation loss = 1.2260  \n",
      "\n",
      "Fold: 22  Epoch: 364  Training loss = 4.4187  Validation loss = 1.2257  \n",
      "\n",
      "Fold: 22  Epoch: 365  Training loss = 4.4184  Validation loss = 1.2256  \n",
      "\n",
      "Fold: 22  Epoch: 366  Training loss = 4.4182  Validation loss = 1.2254  \n",
      "\n",
      "Fold: 22  Epoch: 367  Training loss = 4.4178  Validation loss = 1.2251  \n",
      "\n",
      "Fold: 22  Epoch: 368  Training loss = 4.4175  Validation loss = 1.2248  \n",
      "\n",
      "Fold: 22  Epoch: 369  Training loss = 4.4171  Validation loss = 1.2244  \n",
      "\n",
      "Fold: 22  Epoch: 370  Training loss = 4.4166  Validation loss = 1.2240  \n",
      "\n",
      "Fold: 22  Epoch: 371  Training loss = 4.4162  Validation loss = 1.2237  \n",
      "\n",
      "Fold: 22  Epoch: 372  Training loss = 4.4160  Validation loss = 1.2235  \n",
      "\n",
      "Fold: 22  Epoch: 373  Training loss = 4.4156  Validation loss = 1.2232  \n",
      "\n",
      "Fold: 22  Epoch: 374  Training loss = 4.4152  Validation loss = 1.2230  \n",
      "\n",
      "Fold: 22  Epoch: 375  Training loss = 4.4149  Validation loss = 1.2227  \n",
      "\n",
      "Fold: 22  Epoch: 376  Training loss = 4.4146  Validation loss = 1.2225  \n",
      "\n",
      "Fold: 22  Epoch: 377  Training loss = 4.4143  Validation loss = 1.2222  \n",
      "\n",
      "Fold: 22  Epoch: 378  Training loss = 4.4139  Validation loss = 1.2220  \n",
      "\n",
      "Fold: 22  Epoch: 379  Training loss = 4.4136  Validation loss = 1.2217  \n",
      "\n",
      "Fold: 22  Epoch: 380  Training loss = 4.4133  Validation loss = 1.2215  \n",
      "\n",
      "Fold: 22  Epoch: 381  Training loss = 4.4130  Validation loss = 1.2213  \n",
      "\n",
      "Fold: 22  Epoch: 382  Training loss = 4.4127  Validation loss = 1.2211  \n",
      "\n",
      "Fold: 22  Epoch: 383  Training loss = 4.4122  Validation loss = 1.2206  \n",
      "\n",
      "Fold: 22  Epoch: 384  Training loss = 4.4120  Validation loss = 1.2205  \n",
      "\n",
      "Fold: 22  Epoch: 385  Training loss = 4.4116  Validation loss = 1.2202  \n",
      "\n",
      "Fold: 22  Epoch: 386  Training loss = 4.4111  Validation loss = 1.2198  \n",
      "\n",
      "Fold: 22  Epoch: 387  Training loss = 4.4109  Validation loss = 1.2196  \n",
      "\n",
      "Fold: 22  Epoch: 388  Training loss = 4.4106  Validation loss = 1.2194  \n",
      "\n",
      "Fold: 22  Epoch: 389  Training loss = 4.4101  Validation loss = 1.2190  \n",
      "\n",
      "Fold: 22  Epoch: 390  Training loss = 4.4097  Validation loss = 1.2187  \n",
      "\n",
      "Fold: 22  Epoch: 391  Training loss = 4.4092  Validation loss = 1.2183  \n",
      "\n",
      "Fold: 22  Epoch: 392  Training loss = 4.4088  Validation loss = 1.2180  \n",
      "\n",
      "Fold: 22  Epoch: 393  Training loss = 4.4085  Validation loss = 1.2178  \n",
      "\n",
      "Fold: 22  Epoch: 394  Training loss = 4.4082  Validation loss = 1.2175  \n",
      "\n",
      "Fold: 22  Epoch: 395  Training loss = 4.4078  Validation loss = 1.2173  \n",
      "\n",
      "Fold: 22  Epoch: 396  Training loss = 4.4074  Validation loss = 1.2170  \n",
      "\n",
      "Fold: 22  Epoch: 397  Training loss = 4.4071  Validation loss = 1.2167  \n",
      "\n",
      "Fold: 22  Epoch: 398  Training loss = 4.4067  Validation loss = 1.2165  \n",
      "\n",
      "Fold: 22  Epoch: 399  Training loss = 4.4063  Validation loss = 1.2163  \n",
      "\n",
      "Fold: 22  Epoch: 400  Training loss = 4.4059  Validation loss = 1.2160  \n",
      "\n",
      "Fold: 22  Epoch: 401  Training loss = 4.4056  Validation loss = 1.2156  \n",
      "\n",
      "Fold: 22  Epoch: 402  Training loss = 4.4052  Validation loss = 1.2154  \n",
      "\n",
      "Fold: 22  Epoch: 403  Training loss = 4.4049  Validation loss = 1.2151  \n",
      "\n",
      "Fold: 22  Epoch: 404  Training loss = 4.4045  Validation loss = 1.2148  \n",
      "\n",
      "Fold: 22  Epoch: 405  Training loss = 4.4041  Validation loss = 1.2146  \n",
      "\n",
      "Fold: 22  Epoch: 406  Training loss = 4.4038  Validation loss = 1.2143  \n",
      "\n",
      "Fold: 22  Epoch: 407  Training loss = 4.4034  Validation loss = 1.2140  \n",
      "\n",
      "Fold: 22  Epoch: 408  Training loss = 4.4031  Validation loss = 1.2138  \n",
      "\n",
      "Fold: 22  Epoch: 409  Training loss = 4.4027  Validation loss = 1.2135  \n",
      "\n",
      "Fold: 22  Epoch: 410  Training loss = 4.4024  Validation loss = 1.2133  \n",
      "\n",
      "Fold: 22  Epoch: 411  Training loss = 4.4020  Validation loss = 1.2130  \n",
      "\n",
      "Fold: 22  Epoch: 412  Training loss = 4.4017  Validation loss = 1.2127  \n",
      "\n",
      "Fold: 22  Epoch: 413  Training loss = 4.4013  Validation loss = 1.2124  \n",
      "\n",
      "Fold: 22  Epoch: 414  Training loss = 4.4009  Validation loss = 1.2121  \n",
      "\n",
      "Fold: 22  Epoch: 415  Training loss = 4.4007  Validation loss = 1.2119  \n",
      "\n",
      "Fold: 22  Epoch: 416  Training loss = 4.4002  Validation loss = 1.2116  \n",
      "\n",
      "Fold: 22  Epoch: 417  Training loss = 4.3998  Validation loss = 1.2114  \n",
      "\n",
      "Fold: 22  Epoch: 418  Training loss = 4.3994  Validation loss = 1.2110  \n",
      "\n",
      "Fold: 22  Epoch: 419  Training loss = 4.3991  Validation loss = 1.2108  \n",
      "\n",
      "Fold: 22  Epoch: 420  Training loss = 4.3989  Validation loss = 1.2106  \n",
      "\n",
      "Fold: 22  Epoch: 421  Training loss = 4.3986  Validation loss = 1.2105  \n",
      "\n",
      "Fold: 22  Epoch: 422  Training loss = 4.3982  Validation loss = 1.2102  \n",
      "\n",
      "Fold: 22  Epoch: 423  Training loss = 4.3977  Validation loss = 1.2098  \n",
      "\n",
      "Fold: 22  Epoch: 424  Training loss = 4.3974  Validation loss = 1.2096  \n",
      "\n",
      "Fold: 22  Epoch: 425  Training loss = 4.3969  Validation loss = 1.2093  \n",
      "\n",
      "Fold: 22  Epoch: 426  Training loss = 4.3967  Validation loss = 1.2090  \n",
      "\n",
      "Fold: 22  Epoch: 427  Training loss = 4.3963  Validation loss = 1.2088  \n",
      "\n",
      "Fold: 22  Epoch: 428  Training loss = 4.3960  Validation loss = 1.2086  \n",
      "\n",
      "Fold: 22  Epoch: 429  Training loss = 4.3956  Validation loss = 1.2083  \n",
      "\n",
      "Fold: 22  Epoch: 430  Training loss = 4.3953  Validation loss = 1.2081  \n",
      "\n",
      "Fold: 22  Epoch: 431  Training loss = 4.3949  Validation loss = 1.2078  \n",
      "\n",
      "Fold: 22  Epoch: 432  Training loss = 4.3944  Validation loss = 1.2075  \n",
      "\n",
      "Fold: 22  Epoch: 433  Training loss = 4.3941  Validation loss = 1.2073  \n",
      "\n",
      "Fold: 22  Epoch: 434  Training loss = 4.3937  Validation loss = 1.2070  \n",
      "\n",
      "Fold: 22  Epoch: 435  Training loss = 4.3934  Validation loss = 1.2068  \n",
      "\n",
      "Fold: 22  Epoch: 436  Training loss = 4.3931  Validation loss = 1.2066  \n",
      "\n",
      "Fold: 22  Epoch: 437  Training loss = 4.3928  Validation loss = 1.2064  \n",
      "\n",
      "Fold: 22  Epoch: 438  Training loss = 4.3923  Validation loss = 1.2060  \n",
      "\n",
      "Fold: 22  Epoch: 439  Training loss = 4.3919  Validation loss = 1.2056  \n",
      "\n",
      "Fold: 22  Epoch: 440  Training loss = 4.3916  Validation loss = 1.2055  \n",
      "\n",
      "Fold: 22  Epoch: 441  Training loss = 4.3914  Validation loss = 1.2053  \n",
      "\n",
      "Fold: 22  Epoch: 442  Training loss = 4.3912  Validation loss = 1.2052  \n",
      "\n",
      "Fold: 22  Epoch: 443  Training loss = 4.3909  Validation loss = 1.2049  \n",
      "\n",
      "Fold: 22  Epoch: 444  Training loss = 4.3905  Validation loss = 1.2046  \n",
      "\n",
      "Fold: 22  Epoch: 445  Training loss = 4.3902  Validation loss = 1.2045  \n",
      "\n",
      "Fold: 22  Epoch: 446  Training loss = 4.3897  Validation loss = 1.2041  \n",
      "\n",
      "Fold: 22  Epoch: 447  Training loss = 4.3894  Validation loss = 1.2039  \n",
      "\n",
      "Fold: 22  Epoch: 448  Training loss = 4.3891  Validation loss = 1.2038  \n",
      "\n",
      "Fold: 22  Epoch: 449  Training loss = 4.3887  Validation loss = 1.2035  \n",
      "\n",
      "Fold: 22  Epoch: 450  Training loss = 4.3882  Validation loss = 1.2032  \n",
      "\n",
      "Fold: 22  Epoch: 451  Training loss = 4.3879  Validation loss = 1.2030  \n",
      "\n",
      "Fold: 22  Epoch: 452  Training loss = 4.3877  Validation loss = 1.2028  \n",
      "\n",
      "Fold: 22  Epoch: 453  Training loss = 4.3873  Validation loss = 1.2026  \n",
      "\n",
      "Fold: 22  Epoch: 454  Training loss = 4.3869  Validation loss = 1.2023  \n",
      "\n",
      "Fold: 22  Epoch: 455  Training loss = 4.3866  Validation loss = 1.2020  \n",
      "\n",
      "Fold: 22  Epoch: 456  Training loss = 4.3862  Validation loss = 1.2018  \n",
      "\n",
      "Fold: 22  Epoch: 457  Training loss = 4.3860  Validation loss = 1.2016  \n",
      "\n",
      "Fold: 22  Epoch: 458  Training loss = 4.3856  Validation loss = 1.2014  \n",
      "\n",
      "Fold: 22  Epoch: 459  Training loss = 4.3853  Validation loss = 1.2011  \n",
      "\n",
      "Fold: 22  Epoch: 460  Training loss = 4.3849  Validation loss = 1.2009  \n",
      "\n",
      "Fold: 22  Epoch: 461  Training loss = 4.3845  Validation loss = 1.2006  \n",
      "\n",
      "Fold: 22  Epoch: 462  Training loss = 4.3841  Validation loss = 1.2004  \n",
      "\n",
      "Fold: 22  Epoch: 463  Training loss = 4.3838  Validation loss = 1.2003  \n",
      "\n",
      "Fold: 22  Epoch: 464  Training loss = 4.3834  Validation loss = 1.2000  \n",
      "\n",
      "Fold: 22  Epoch: 465  Training loss = 4.3830  Validation loss = 1.1997  \n",
      "\n",
      "Fold: 22  Epoch: 466  Training loss = 4.3827  Validation loss = 1.1995  \n",
      "\n",
      "Fold: 22  Epoch: 467  Training loss = 4.3824  Validation loss = 1.1993  \n",
      "\n",
      "Fold: 22  Epoch: 468  Training loss = 4.3821  Validation loss = 1.1991  \n",
      "\n",
      "Fold: 22  Epoch: 469  Training loss = 4.3817  Validation loss = 1.1989  \n",
      "\n",
      "Fold: 22  Epoch: 470  Training loss = 4.3814  Validation loss = 1.1987  \n",
      "\n",
      "Fold: 22  Epoch: 471  Training loss = 4.3811  Validation loss = 1.1985  \n",
      "\n",
      "Fold: 22  Epoch: 472  Training loss = 4.3808  Validation loss = 1.1984  \n",
      "\n",
      "Fold: 22  Epoch: 473  Training loss = 4.3805  Validation loss = 1.1982  \n",
      "\n",
      "Fold: 22  Epoch: 474  Training loss = 4.3802  Validation loss = 1.1980  \n",
      "\n",
      "Fold: 22  Epoch: 475  Training loss = 4.3798  Validation loss = 1.1977  \n",
      "\n",
      "Fold: 22  Epoch: 476  Training loss = 4.3795  Validation loss = 1.1975  \n",
      "\n",
      "Fold: 22  Epoch: 477  Training loss = 4.3790  Validation loss = 1.1971  \n",
      "\n",
      "Fold: 22  Epoch: 478  Training loss = 4.3787  Validation loss = 1.1970  \n",
      "\n",
      "Fold: 22  Epoch: 479  Training loss = 4.3783  Validation loss = 1.1967  \n",
      "\n",
      "Fold: 22  Epoch: 480  Training loss = 4.3780  Validation loss = 1.1966  \n",
      "\n",
      "Fold: 22  Epoch: 481  Training loss = 4.3776  Validation loss = 1.1964  \n",
      "\n",
      "Fold: 22  Epoch: 482  Training loss = 4.3774  Validation loss = 1.1963  \n",
      "\n",
      "Fold: 22  Epoch: 483  Training loss = 4.3771  Validation loss = 1.1960  \n",
      "\n",
      "Fold: 22  Epoch: 484  Training loss = 4.3768  Validation loss = 1.1958  \n",
      "\n",
      "Fold: 22  Epoch: 485  Training loss = 4.3765  Validation loss = 1.1955  \n",
      "\n",
      "Fold: 22  Epoch: 486  Training loss = 4.3761  Validation loss = 1.1953  \n",
      "\n",
      "Fold: 22  Epoch: 487  Training loss = 4.3757  Validation loss = 1.1950  \n",
      "\n",
      "Fold: 22  Epoch: 488  Training loss = 4.3753  Validation loss = 1.1947  \n",
      "\n",
      "Fold: 22  Epoch: 489  Training loss = 4.3749  Validation loss = 1.1944  \n",
      "\n",
      "Fold: 22  Epoch: 490  Training loss = 4.3746  Validation loss = 1.1942  \n",
      "\n",
      "Fold: 22  Epoch: 491  Training loss = 4.3742  Validation loss = 1.1940  \n",
      "\n",
      "Fold: 22  Epoch: 492  Training loss = 4.3738  Validation loss = 1.1937  \n",
      "\n",
      "Fold: 22  Epoch: 493  Training loss = 4.3736  Validation loss = 1.1936  \n",
      "\n",
      "Fold: 22  Epoch: 494  Training loss = 4.3734  Validation loss = 1.1934  \n",
      "\n",
      "Fold: 22  Epoch: 495  Training loss = 4.3731  Validation loss = 1.1932  \n",
      "\n",
      "Fold: 22  Epoch: 496  Training loss = 4.3727  Validation loss = 1.1929  \n",
      "\n",
      "Fold: 22  Epoch: 497  Training loss = 4.3724  Validation loss = 1.1926  \n",
      "\n",
      "Fold: 22  Epoch: 498  Training loss = 4.3719  Validation loss = 1.1923  \n",
      "\n",
      "Fold: 22  Epoch: 499  Training loss = 4.3715  Validation loss = 1.1921  \n",
      "\n",
      "Fold: 22  Epoch: 500  Training loss = 4.3711  Validation loss = 1.1918  \n",
      "\n",
      "Check model:  Fold: 22  Optimal epoch: 500  \n",
      "\n",
      "Fold: 23  Epoch: 1  Training loss = 4.3743  Validation loss = 0.9555  \n",
      "\n",
      "Fold: 23  Epoch: 2  Training loss = 4.3740  Validation loss = 0.9551  \n",
      "\n",
      "Fold: 23  Epoch: 3  Training loss = 4.3737  Validation loss = 0.9548  \n",
      "\n",
      "Fold: 23  Epoch: 4  Training loss = 4.3733  Validation loss = 0.9545  \n",
      "\n",
      "Fold: 23  Epoch: 5  Training loss = 4.3729  Validation loss = 0.9542  \n",
      "\n",
      "Fold: 23  Epoch: 6  Training loss = 4.3726  Validation loss = 0.9538  \n",
      "\n",
      "Fold: 23  Epoch: 7  Training loss = 4.3722  Validation loss = 0.9535  \n",
      "\n",
      "Fold: 23  Epoch: 8  Training loss = 4.3719  Validation loss = 0.9532  \n",
      "\n",
      "Fold: 23  Epoch: 9  Training loss = 4.3715  Validation loss = 0.9528  \n",
      "\n",
      "Fold: 23  Epoch: 10  Training loss = 4.3712  Validation loss = 0.9525  \n",
      "\n",
      "Fold: 23  Epoch: 11  Training loss = 4.3707  Validation loss = 0.9520  \n",
      "\n",
      "Fold: 23  Epoch: 12  Training loss = 4.3704  Validation loss = 0.9517  \n",
      "\n",
      "Fold: 23  Epoch: 13  Training loss = 4.3700  Validation loss = 0.9512  \n",
      "\n",
      "Fold: 23  Epoch: 14  Training loss = 4.3696  Validation loss = 0.9508  \n",
      "\n",
      "Fold: 23  Epoch: 15  Training loss = 4.3693  Validation loss = 0.9505  \n",
      "\n",
      "Fold: 23  Epoch: 16  Training loss = 4.3688  Validation loss = 0.9501  \n",
      "\n",
      "Fold: 23  Epoch: 17  Training loss = 4.3684  Validation loss = 0.9497  \n",
      "\n",
      "Fold: 23  Epoch: 18  Training loss = 4.3681  Validation loss = 0.9494  \n",
      "\n",
      "Fold: 23  Epoch: 19  Training loss = 4.3678  Validation loss = 0.9491  \n",
      "\n",
      "Fold: 23  Epoch: 20  Training loss = 4.3675  Validation loss = 0.9488  \n",
      "\n",
      "Fold: 23  Epoch: 21  Training loss = 4.3671  Validation loss = 0.9485  \n",
      "\n",
      "Fold: 23  Epoch: 22  Training loss = 4.3668  Validation loss = 0.9482  \n",
      "\n",
      "Fold: 23  Epoch: 23  Training loss = 4.3664  Validation loss = 0.9478  \n",
      "\n",
      "Fold: 23  Epoch: 24  Training loss = 4.3662  Validation loss = 0.9476  \n",
      "\n",
      "Fold: 23  Epoch: 25  Training loss = 4.3658  Validation loss = 0.9472  \n",
      "\n",
      "Fold: 23  Epoch: 26  Training loss = 4.3655  Validation loss = 0.9469  \n",
      "\n",
      "Fold: 23  Epoch: 27  Training loss = 4.3651  Validation loss = 0.9465  \n",
      "\n",
      "Fold: 23  Epoch: 28  Training loss = 4.3647  Validation loss = 0.9461  \n",
      "\n",
      "Fold: 23  Epoch: 29  Training loss = 4.3643  Validation loss = 0.9458  \n",
      "\n",
      "Fold: 23  Epoch: 30  Training loss = 4.3639  Validation loss = 0.9454  \n",
      "\n",
      "Fold: 23  Epoch: 31  Training loss = 4.3637  Validation loss = 0.9452  \n",
      "\n",
      "Fold: 23  Epoch: 32  Training loss = 4.3633  Validation loss = 0.9448  \n",
      "\n",
      "Fold: 23  Epoch: 33  Training loss = 4.3630  Validation loss = 0.9444  \n",
      "\n",
      "Fold: 23  Epoch: 34  Training loss = 4.3626  Validation loss = 0.9441  \n",
      "\n",
      "Fold: 23  Epoch: 35  Training loss = 4.3622  Validation loss = 0.9437  \n",
      "\n",
      "Fold: 23  Epoch: 36  Training loss = 4.3619  Validation loss = 0.9435  \n",
      "\n",
      "Fold: 23  Epoch: 37  Training loss = 4.3615  Validation loss = 0.9431  \n",
      "\n",
      "Fold: 23  Epoch: 38  Training loss = 4.3612  Validation loss = 0.9428  \n",
      "\n",
      "Fold: 23  Epoch: 39  Training loss = 4.3608  Validation loss = 0.9424  \n",
      "\n",
      "Fold: 23  Epoch: 40  Training loss = 4.3604  Validation loss = 0.9420  \n",
      "\n",
      "Fold: 23  Epoch: 41  Training loss = 4.3600  Validation loss = 0.9417  \n",
      "\n",
      "Fold: 23  Epoch: 42  Training loss = 4.3596  Validation loss = 0.9413  \n",
      "\n",
      "Fold: 23  Epoch: 43  Training loss = 4.3593  Validation loss = 0.9410  \n",
      "\n",
      "Fold: 23  Epoch: 44  Training loss = 4.3589  Validation loss = 0.9406  \n",
      "\n",
      "Fold: 23  Epoch: 45  Training loss = 4.3585  Validation loss = 0.9403  \n",
      "\n",
      "Fold: 23  Epoch: 46  Training loss = 4.3583  Validation loss = 0.9400  \n",
      "\n",
      "Fold: 23  Epoch: 47  Training loss = 4.3580  Validation loss = 0.9397  \n",
      "\n",
      "Fold: 23  Epoch: 48  Training loss = 4.3576  Validation loss = 0.9394  \n",
      "\n",
      "Fold: 23  Epoch: 49  Training loss = 4.3572  Validation loss = 0.9391  \n",
      "\n",
      "Fold: 23  Epoch: 50  Training loss = 4.3569  Validation loss = 0.9388  \n",
      "\n",
      "Fold: 23  Epoch: 51  Training loss = 4.3565  Validation loss = 0.9384  \n",
      "\n",
      "Fold: 23  Epoch: 52  Training loss = 4.3561  Validation loss = 0.9381  \n",
      "\n",
      "Fold: 23  Epoch: 53  Training loss = 4.3558  Validation loss = 0.9378  \n",
      "\n",
      "Fold: 23  Epoch: 54  Training loss = 4.3554  Validation loss = 0.9374  \n",
      "\n",
      "Fold: 23  Epoch: 55  Training loss = 4.3552  Validation loss = 0.9372  \n",
      "\n",
      "Fold: 23  Epoch: 56  Training loss = 4.3549  Validation loss = 0.9369  \n",
      "\n",
      "Fold: 23  Epoch: 57  Training loss = 4.3547  Validation loss = 0.9366  \n",
      "\n",
      "Fold: 23  Epoch: 58  Training loss = 4.3542  Validation loss = 0.9362  \n",
      "\n",
      "Fold: 23  Epoch: 59  Training loss = 4.3538  Validation loss = 0.9359  \n",
      "\n",
      "Fold: 23  Epoch: 60  Training loss = 4.3535  Validation loss = 0.9356  \n",
      "\n",
      "Fold: 23  Epoch: 61  Training loss = 4.3531  Validation loss = 0.9352  \n",
      "\n",
      "Fold: 23  Epoch: 62  Training loss = 4.3527  Validation loss = 0.9348  \n",
      "\n",
      "Fold: 23  Epoch: 63  Training loss = 4.3525  Validation loss = 0.9346  \n",
      "\n",
      "Fold: 23  Epoch: 64  Training loss = 4.3520  Validation loss = 0.9341  \n",
      "\n",
      "Fold: 23  Epoch: 65  Training loss = 4.3516  Validation loss = 0.9338  \n",
      "\n",
      "Fold: 23  Epoch: 66  Training loss = 4.3512  Validation loss = 0.9334  \n",
      "\n",
      "Fold: 23  Epoch: 67  Training loss = 4.3509  Validation loss = 0.9331  \n",
      "\n",
      "Fold: 23  Epoch: 68  Training loss = 4.3505  Validation loss = 0.9327  \n",
      "\n",
      "Fold: 23  Epoch: 69  Training loss = 4.3501  Validation loss = 0.9324  \n",
      "\n",
      "Fold: 23  Epoch: 70  Training loss = 4.3498  Validation loss = 0.9321  \n",
      "\n",
      "Fold: 23  Epoch: 71  Training loss = 4.3495  Validation loss = 0.9318  \n",
      "\n",
      "Fold: 23  Epoch: 72  Training loss = 4.3491  Validation loss = 0.9315  \n",
      "\n",
      "Fold: 23  Epoch: 73  Training loss = 4.3487  Validation loss = 0.9311  \n",
      "\n",
      "Fold: 23  Epoch: 74  Training loss = 4.3484  Validation loss = 0.9309  \n",
      "\n",
      "Fold: 23  Epoch: 75  Training loss = 4.3480  Validation loss = 0.9305  \n",
      "\n",
      "Fold: 23  Epoch: 76  Training loss = 4.3477  Validation loss = 0.9302  \n",
      "\n",
      "Fold: 23  Epoch: 77  Training loss = 4.3474  Validation loss = 0.9299  \n",
      "\n",
      "Fold: 23  Epoch: 78  Training loss = 4.3471  Validation loss = 0.9295  \n",
      "\n",
      "Fold: 23  Epoch: 79  Training loss = 4.3467  Validation loss = 0.9292  \n",
      "\n",
      "Fold: 23  Epoch: 80  Training loss = 4.3464  Validation loss = 0.9289  \n",
      "\n",
      "Fold: 23  Epoch: 81  Training loss = 4.3459  Validation loss = 0.9285  \n",
      "\n",
      "Fold: 23  Epoch: 82  Training loss = 4.3455  Validation loss = 0.9281  \n",
      "\n",
      "Fold: 23  Epoch: 83  Training loss = 4.3452  Validation loss = 0.9278  \n",
      "\n",
      "Fold: 23  Epoch: 84  Training loss = 4.3448  Validation loss = 0.9274  \n",
      "\n",
      "Fold: 23  Epoch: 85  Training loss = 4.3443  Validation loss = 0.9270  \n",
      "\n",
      "Fold: 23  Epoch: 86  Training loss = 4.3440  Validation loss = 0.9266  \n",
      "\n",
      "Fold: 23  Epoch: 87  Training loss = 4.3436  Validation loss = 0.9262  \n",
      "\n",
      "Fold: 23  Epoch: 88  Training loss = 4.3432  Validation loss = 0.9259  \n",
      "\n",
      "Fold: 23  Epoch: 89  Training loss = 4.3428  Validation loss = 0.9255  \n",
      "\n",
      "Fold: 23  Epoch: 90  Training loss = 4.3423  Validation loss = 0.9251  \n",
      "\n",
      "Fold: 23  Epoch: 91  Training loss = 4.3421  Validation loss = 0.9248  \n",
      "\n",
      "Fold: 23  Epoch: 92  Training loss = 4.3416  Validation loss = 0.9244  \n",
      "\n",
      "Fold: 23  Epoch: 93  Training loss = 4.3413  Validation loss = 0.9241  \n",
      "\n",
      "Fold: 23  Epoch: 94  Training loss = 4.3409  Validation loss = 0.9237  \n",
      "\n",
      "Fold: 23  Epoch: 95  Training loss = 4.3405  Validation loss = 0.9234  \n",
      "\n",
      "Fold: 23  Epoch: 96  Training loss = 4.3400  Validation loss = 0.9230  \n",
      "\n",
      "Fold: 23  Epoch: 97  Training loss = 4.3396  Validation loss = 0.9227  \n",
      "\n",
      "Fold: 23  Epoch: 98  Training loss = 4.3393  Validation loss = 0.9224  \n",
      "\n",
      "Fold: 23  Epoch: 99  Training loss = 4.3390  Validation loss = 0.9221  \n",
      "\n",
      "Fold: 23  Epoch: 100  Training loss = 4.3386  Validation loss = 0.9218  \n",
      "\n",
      "Fold: 23  Epoch: 101  Training loss = 4.3383  Validation loss = 0.9214  \n",
      "\n",
      "Fold: 23  Epoch: 102  Training loss = 4.3379  Validation loss = 0.9211  \n",
      "\n",
      "Fold: 23  Epoch: 103  Training loss = 4.3375  Validation loss = 0.9206  \n",
      "\n",
      "Fold: 23  Epoch: 104  Training loss = 4.3371  Validation loss = 0.9203  \n",
      "\n",
      "Fold: 23  Epoch: 105  Training loss = 4.3368  Validation loss = 0.9200  \n",
      "\n",
      "Fold: 23  Epoch: 106  Training loss = 4.3364  Validation loss = 0.9196  \n",
      "\n",
      "Fold: 23  Epoch: 107  Training loss = 4.3361  Validation loss = 0.9192  \n",
      "\n",
      "Fold: 23  Epoch: 108  Training loss = 4.3357  Validation loss = 0.9188  \n",
      "\n",
      "Fold: 23  Epoch: 109  Training loss = 4.3352  Validation loss = 0.9184  \n",
      "\n",
      "Fold: 23  Epoch: 110  Training loss = 4.3349  Validation loss = 0.9181  \n",
      "\n",
      "Fold: 23  Epoch: 111  Training loss = 4.3345  Validation loss = 0.9178  \n",
      "\n",
      "Fold: 23  Epoch: 112  Training loss = 4.3341  Validation loss = 0.9174  \n",
      "\n",
      "Fold: 23  Epoch: 113  Training loss = 4.3337  Validation loss = 0.9171  \n",
      "\n",
      "Fold: 23  Epoch: 114  Training loss = 4.3335  Validation loss = 0.9168  \n",
      "\n",
      "Fold: 23  Epoch: 115  Training loss = 4.3330  Validation loss = 0.9164  \n",
      "\n",
      "Fold: 23  Epoch: 116  Training loss = 4.3327  Validation loss = 0.9160  \n",
      "\n",
      "Fold: 23  Epoch: 117  Training loss = 4.3322  Validation loss = 0.9157  \n",
      "\n",
      "Fold: 23  Epoch: 118  Training loss = 4.3318  Validation loss = 0.9152  \n",
      "\n",
      "Fold: 23  Epoch: 119  Training loss = 4.3314  Validation loss = 0.9149  \n",
      "\n",
      "Fold: 23  Epoch: 120  Training loss = 4.3309  Validation loss = 0.9145  \n",
      "\n",
      "Fold: 23  Epoch: 121  Training loss = 4.3306  Validation loss = 0.9142  \n",
      "\n",
      "Fold: 23  Epoch: 122  Training loss = 4.3301  Validation loss = 0.9138  \n",
      "\n",
      "Fold: 23  Epoch: 123  Training loss = 4.3299  Validation loss = 0.9135  \n",
      "\n",
      "Fold: 23  Epoch: 124  Training loss = 4.3294  Validation loss = 0.9132  \n",
      "\n",
      "Fold: 23  Epoch: 125  Training loss = 4.3291  Validation loss = 0.9129  \n",
      "\n",
      "Fold: 23  Epoch: 126  Training loss = 4.3288  Validation loss = 0.9125  \n",
      "\n",
      "Fold: 23  Epoch: 127  Training loss = 4.3283  Validation loss = 0.9121  \n",
      "\n",
      "Fold: 23  Epoch: 128  Training loss = 4.3279  Validation loss = 0.9118  \n",
      "\n",
      "Fold: 23  Epoch: 129  Training loss = 4.3277  Validation loss = 0.9115  \n",
      "\n",
      "Fold: 23  Epoch: 130  Training loss = 4.3273  Validation loss = 0.9111  \n",
      "\n",
      "Fold: 23  Epoch: 131  Training loss = 4.3269  Validation loss = 0.9107  \n",
      "\n",
      "Fold: 23  Epoch: 132  Training loss = 4.3264  Validation loss = 0.9103  \n",
      "\n",
      "Fold: 23  Epoch: 133  Training loss = 4.3260  Validation loss = 0.9099  \n",
      "\n",
      "Fold: 23  Epoch: 134  Training loss = 4.3256  Validation loss = 0.9096  \n",
      "\n",
      "Fold: 23  Epoch: 135  Training loss = 4.3252  Validation loss = 0.9092  \n",
      "\n",
      "Fold: 23  Epoch: 136  Training loss = 4.3248  Validation loss = 0.9089  \n",
      "\n",
      "Fold: 23  Epoch: 137  Training loss = 4.3245  Validation loss = 0.9086  \n",
      "\n",
      "Fold: 23  Epoch: 138  Training loss = 4.3240  Validation loss = 0.9082  \n",
      "\n",
      "Fold: 23  Epoch: 139  Training loss = 4.3235  Validation loss = 0.9078  \n",
      "\n",
      "Fold: 23  Epoch: 140  Training loss = 4.3232  Validation loss = 0.9075  \n",
      "\n",
      "Fold: 23  Epoch: 141  Training loss = 4.3229  Validation loss = 0.9072  \n",
      "\n",
      "Fold: 23  Epoch: 142  Training loss = 4.3226  Validation loss = 0.9069  \n",
      "\n",
      "Fold: 23  Epoch: 143  Training loss = 4.3223  Validation loss = 0.9066  \n",
      "\n",
      "Fold: 23  Epoch: 144  Training loss = 4.3219  Validation loss = 0.9063  \n",
      "\n",
      "Fold: 23  Epoch: 145  Training loss = 4.3215  Validation loss = 0.9059  \n",
      "\n",
      "Fold: 23  Epoch: 146  Training loss = 4.3210  Validation loss = 0.9055  \n",
      "\n",
      "Fold: 23  Epoch: 147  Training loss = 4.3206  Validation loss = 0.9051  \n",
      "\n",
      "Fold: 23  Epoch: 148  Training loss = 4.3201  Validation loss = 0.9047  \n",
      "\n",
      "Fold: 23  Epoch: 149  Training loss = 4.3197  Validation loss = 0.9043  \n",
      "\n",
      "Fold: 23  Epoch: 150  Training loss = 4.3194  Validation loss = 0.9040  \n",
      "\n",
      "Fold: 23  Epoch: 151  Training loss = 4.3190  Validation loss = 0.9036  \n",
      "\n",
      "Fold: 23  Epoch: 152  Training loss = 4.3186  Validation loss = 0.9033  \n",
      "\n",
      "Fold: 23  Epoch: 153  Training loss = 4.3182  Validation loss = 0.9029  \n",
      "\n",
      "Fold: 23  Epoch: 154  Training loss = 4.3179  Validation loss = 0.9026  \n",
      "\n",
      "Fold: 23  Epoch: 155  Training loss = 4.3174  Validation loss = 0.9022  \n",
      "\n",
      "Fold: 23  Epoch: 156  Training loss = 4.3170  Validation loss = 0.9019  \n",
      "\n",
      "Fold: 23  Epoch: 157  Training loss = 4.3167  Validation loss = 0.9016  \n",
      "\n",
      "Fold: 23  Epoch: 158  Training loss = 4.3161  Validation loss = 0.9011  \n",
      "\n",
      "Fold: 23  Epoch: 159  Training loss = 4.3157  Validation loss = 0.9007  \n",
      "\n",
      "Fold: 23  Epoch: 160  Training loss = 4.3155  Validation loss = 0.9005  \n",
      "\n",
      "Fold: 23  Epoch: 161  Training loss = 4.3151  Validation loss = 0.9002  \n",
      "\n",
      "Fold: 23  Epoch: 162  Training loss = 4.3147  Validation loss = 0.8998  \n",
      "\n",
      "Fold: 23  Epoch: 163  Training loss = 4.3145  Validation loss = 0.8996  \n",
      "\n",
      "Fold: 23  Epoch: 164  Training loss = 4.3142  Validation loss = 0.8992  \n",
      "\n",
      "Fold: 23  Epoch: 165  Training loss = 4.3138  Validation loss = 0.8988  \n",
      "\n",
      "Fold: 23  Epoch: 166  Training loss = 4.3135  Validation loss = 0.8985  \n",
      "\n",
      "Fold: 23  Epoch: 167  Training loss = 4.3132  Validation loss = 0.8982  \n",
      "\n",
      "Fold: 23  Epoch: 168  Training loss = 4.3128  Validation loss = 0.8979  \n",
      "\n",
      "Fold: 23  Epoch: 169  Training loss = 4.3126  Validation loss = 0.8976  \n",
      "\n",
      "Fold: 23  Epoch: 170  Training loss = 4.3123  Validation loss = 0.8974  \n",
      "\n",
      "Fold: 23  Epoch: 171  Training loss = 4.3120  Validation loss = 0.8972  \n",
      "\n",
      "Fold: 23  Epoch: 172  Training loss = 4.3117  Validation loss = 0.8969  \n",
      "\n",
      "Fold: 23  Epoch: 173  Training loss = 4.3114  Validation loss = 0.8967  \n",
      "\n",
      "Fold: 23  Epoch: 174  Training loss = 4.3112  Validation loss = 0.8964  \n",
      "\n",
      "Fold: 23  Epoch: 175  Training loss = 4.3109  Validation loss = 0.8961  \n",
      "\n",
      "Fold: 23  Epoch: 176  Training loss = 4.3106  Validation loss = 0.8958  \n",
      "\n",
      "Fold: 23  Epoch: 177  Training loss = 4.3102  Validation loss = 0.8955  \n",
      "\n",
      "Fold: 23  Epoch: 178  Training loss = 4.3099  Validation loss = 0.8951  \n",
      "\n",
      "Fold: 23  Epoch: 179  Training loss = 4.3095  Validation loss = 0.8947  \n",
      "\n",
      "Fold: 23  Epoch: 180  Training loss = 4.3090  Validation loss = 0.8944  \n",
      "\n",
      "Fold: 23  Epoch: 181  Training loss = 4.3086  Validation loss = 0.8940  \n",
      "\n",
      "Fold: 23  Epoch: 182  Training loss = 4.3083  Validation loss = 0.8937  \n",
      "\n",
      "Fold: 23  Epoch: 183  Training loss = 4.3080  Validation loss = 0.8935  \n",
      "\n",
      "Fold: 23  Epoch: 184  Training loss = 4.3077  Validation loss = 0.8932  \n",
      "\n",
      "Fold: 23  Epoch: 185  Training loss = 4.3074  Validation loss = 0.8929  \n",
      "\n",
      "Fold: 23  Epoch: 186  Training loss = 4.3070  Validation loss = 0.8926  \n",
      "\n",
      "Fold: 23  Epoch: 187  Training loss = 4.3067  Validation loss = 0.8923  \n",
      "\n",
      "Fold: 23  Epoch: 188  Training loss = 4.3062  Validation loss = 0.8919  \n",
      "\n",
      "Fold: 23  Epoch: 189  Training loss = 4.3058  Validation loss = 0.8916  \n",
      "\n",
      "Fold: 23  Epoch: 190  Training loss = 4.3056  Validation loss = 0.8914  \n",
      "\n",
      "Fold: 23  Epoch: 191  Training loss = 4.3053  Validation loss = 0.8911  \n",
      "\n",
      "Fold: 23  Epoch: 192  Training loss = 4.3049  Validation loss = 0.8907  \n",
      "\n",
      "Fold: 23  Epoch: 193  Training loss = 4.3044  Validation loss = 0.8903  \n",
      "\n",
      "Fold: 23  Epoch: 194  Training loss = 4.3041  Validation loss = 0.8900  \n",
      "\n",
      "Fold: 23  Epoch: 195  Training loss = 4.3037  Validation loss = 0.8896  \n",
      "\n",
      "Fold: 23  Epoch: 196  Training loss = 4.3034  Validation loss = 0.8893  \n",
      "\n",
      "Fold: 23  Epoch: 197  Training loss = 4.3031  Validation loss = 0.8890  \n",
      "\n",
      "Fold: 23  Epoch: 198  Training loss = 4.3026  Validation loss = 0.8886  \n",
      "\n",
      "Fold: 23  Epoch: 199  Training loss = 4.3023  Validation loss = 0.8882  \n",
      "\n",
      "Fold: 23  Epoch: 200  Training loss = 4.3020  Validation loss = 0.8880  \n",
      "\n",
      "Fold: 23  Epoch: 201  Training loss = 4.3018  Validation loss = 0.8878  \n",
      "\n",
      "Fold: 23  Epoch: 202  Training loss = 4.3014  Validation loss = 0.8875  \n",
      "\n",
      "Fold: 23  Epoch: 203  Training loss = 4.3011  Validation loss = 0.8872  \n",
      "\n",
      "Fold: 23  Epoch: 204  Training loss = 4.3007  Validation loss = 0.8869  \n",
      "\n",
      "Fold: 23  Epoch: 205  Training loss = 4.3003  Validation loss = 0.8866  \n",
      "\n",
      "Fold: 23  Epoch: 206  Training loss = 4.3000  Validation loss = 0.8862  \n",
      "\n",
      "Fold: 23  Epoch: 207  Training loss = 4.2996  Validation loss = 0.8859  \n",
      "\n",
      "Fold: 23  Epoch: 208  Training loss = 4.2991  Validation loss = 0.8855  \n",
      "\n",
      "Fold: 23  Epoch: 209  Training loss = 4.2988  Validation loss = 0.8852  \n",
      "\n",
      "Fold: 23  Epoch: 210  Training loss = 4.2984  Validation loss = 0.8848  \n",
      "\n",
      "Fold: 23  Epoch: 211  Training loss = 4.2981  Validation loss = 0.8845  \n",
      "\n",
      "Fold: 23  Epoch: 212  Training loss = 4.2977  Validation loss = 0.8842  \n",
      "\n",
      "Fold: 23  Epoch: 213  Training loss = 4.2974  Validation loss = 0.8839  \n",
      "\n",
      "Fold: 23  Epoch: 214  Training loss = 4.2971  Validation loss = 0.8836  \n",
      "\n",
      "Fold: 23  Epoch: 215  Training loss = 4.2967  Validation loss = 0.8833  \n",
      "\n",
      "Fold: 23  Epoch: 216  Training loss = 4.2963  Validation loss = 0.8829  \n",
      "\n",
      "Fold: 23  Epoch: 217  Training loss = 4.2960  Validation loss = 0.8827  \n",
      "\n",
      "Fold: 23  Epoch: 218  Training loss = 4.2957  Validation loss = 0.8823  \n",
      "\n",
      "Fold: 23  Epoch: 219  Training loss = 4.2953  Validation loss = 0.8819  \n",
      "\n",
      "Fold: 23  Epoch: 220  Training loss = 4.2949  Validation loss = 0.8816  \n",
      "\n",
      "Fold: 23  Epoch: 221  Training loss = 4.2946  Validation loss = 0.8812  \n",
      "\n",
      "Fold: 23  Epoch: 222  Training loss = 4.2942  Validation loss = 0.8809  \n",
      "\n",
      "Fold: 23  Epoch: 223  Training loss = 4.2939  Validation loss = 0.8806  \n",
      "\n",
      "Fold: 23  Epoch: 224  Training loss = 4.2935  Validation loss = 0.8801  \n",
      "\n",
      "Fold: 23  Epoch: 225  Training loss = 4.2931  Validation loss = 0.8798  \n",
      "\n",
      "Fold: 23  Epoch: 226  Training loss = 4.2927  Validation loss = 0.8795  \n",
      "\n",
      "Fold: 23  Epoch: 227  Training loss = 4.2924  Validation loss = 0.8792  \n",
      "\n",
      "Fold: 23  Epoch: 228  Training loss = 4.2921  Validation loss = 0.8789  \n",
      "\n",
      "Fold: 23  Epoch: 229  Training loss = 4.2918  Validation loss = 0.8786  \n",
      "\n",
      "Fold: 23  Epoch: 230  Training loss = 4.2915  Validation loss = 0.8783  \n",
      "\n",
      "Fold: 23  Epoch: 231  Training loss = 4.2912  Validation loss = 0.8780  \n",
      "\n",
      "Fold: 23  Epoch: 232  Training loss = 4.2909  Validation loss = 0.8778  \n",
      "\n",
      "Fold: 23  Epoch: 233  Training loss = 4.2906  Validation loss = 0.8775  \n",
      "\n",
      "Fold: 23  Epoch: 234  Training loss = 4.2901  Validation loss = 0.8772  \n",
      "\n",
      "Fold: 23  Epoch: 235  Training loss = 4.2898  Validation loss = 0.8769  \n",
      "\n",
      "Fold: 23  Epoch: 236  Training loss = 4.2894  Validation loss = 0.8765  \n",
      "\n",
      "Fold: 23  Epoch: 237  Training loss = 4.2891  Validation loss = 0.8762  \n",
      "\n",
      "Fold: 23  Epoch: 238  Training loss = 4.2888  Validation loss = 0.8760  \n",
      "\n",
      "Fold: 23  Epoch: 239  Training loss = 4.2885  Validation loss = 0.8758  \n",
      "\n",
      "Fold: 23  Epoch: 240  Training loss = 4.2883  Validation loss = 0.8756  \n",
      "\n",
      "Fold: 23  Epoch: 241  Training loss = 4.2879  Validation loss = 0.8753  \n",
      "\n",
      "Fold: 23  Epoch: 242  Training loss = 4.2874  Validation loss = 0.8749  \n",
      "\n",
      "Fold: 23  Epoch: 243  Training loss = 4.2871  Validation loss = 0.8746  \n",
      "\n",
      "Fold: 23  Epoch: 244  Training loss = 4.2868  Validation loss = 0.8743  \n",
      "\n",
      "Fold: 23  Epoch: 245  Training loss = 4.2865  Validation loss = 0.8741  \n",
      "\n",
      "Fold: 23  Epoch: 246  Training loss = 4.2862  Validation loss = 0.8738  \n",
      "\n",
      "Fold: 23  Epoch: 247  Training loss = 4.2859  Validation loss = 0.8736  \n",
      "\n",
      "Fold: 23  Epoch: 248  Training loss = 4.2856  Validation loss = 0.8733  \n",
      "\n",
      "Fold: 23  Epoch: 249  Training loss = 4.2853  Validation loss = 0.8730  \n",
      "\n",
      "Fold: 23  Epoch: 250  Training loss = 4.2848  Validation loss = 0.8726  \n",
      "\n",
      "Fold: 23  Epoch: 251  Training loss = 4.2846  Validation loss = 0.8725  \n",
      "\n",
      "Fold: 23  Epoch: 252  Training loss = 4.2843  Validation loss = 0.8722  \n",
      "\n",
      "Fold: 23  Epoch: 253  Training loss = 4.2839  Validation loss = 0.8718  \n",
      "\n",
      "Fold: 23  Epoch: 254  Training loss = 4.2835  Validation loss = 0.8715  \n",
      "\n",
      "Fold: 23  Epoch: 255  Training loss = 4.2831  Validation loss = 0.8711  \n",
      "\n",
      "Fold: 23  Epoch: 256  Training loss = 4.2828  Validation loss = 0.8708  \n",
      "\n",
      "Fold: 23  Epoch: 257  Training loss = 4.2825  Validation loss = 0.8705  \n",
      "\n",
      "Fold: 23  Epoch: 258  Training loss = 4.2822  Validation loss = 0.8703  \n",
      "\n",
      "Fold: 23  Epoch: 259  Training loss = 4.2818  Validation loss = 0.8699  \n",
      "\n",
      "Fold: 23  Epoch: 260  Training loss = 4.2815  Validation loss = 0.8697  \n",
      "\n",
      "Fold: 23  Epoch: 261  Training loss = 4.2812  Validation loss = 0.8693  \n",
      "\n",
      "Fold: 23  Epoch: 262  Training loss = 4.2809  Validation loss = 0.8690  \n",
      "\n",
      "Fold: 23  Epoch: 263  Training loss = 4.2806  Validation loss = 0.8689  \n",
      "\n",
      "Fold: 23  Epoch: 264  Training loss = 4.2802  Validation loss = 0.8685  \n",
      "\n",
      "Fold: 23  Epoch: 265  Training loss = 4.2798  Validation loss = 0.8682  \n",
      "\n",
      "Fold: 23  Epoch: 266  Training loss = 4.2795  Validation loss = 0.8679  \n",
      "\n",
      "Fold: 23  Epoch: 267  Training loss = 4.2792  Validation loss = 0.8677  \n",
      "\n",
      "Fold: 23  Epoch: 268  Training loss = 4.2790  Validation loss = 0.8674  \n",
      "\n",
      "Fold: 23  Epoch: 269  Training loss = 4.2786  Validation loss = 0.8671  \n",
      "\n",
      "Fold: 23  Epoch: 270  Training loss = 4.2781  Validation loss = 0.8667  \n",
      "\n",
      "Fold: 23  Epoch: 271  Training loss = 4.2778  Validation loss = 0.8664  \n",
      "\n",
      "Fold: 23  Epoch: 272  Training loss = 4.2776  Validation loss = 0.8662  \n",
      "\n",
      "Fold: 23  Epoch: 273  Training loss = 4.2774  Validation loss = 0.8659  \n",
      "\n",
      "Fold: 23  Epoch: 274  Training loss = 4.2769  Validation loss = 0.8655  \n",
      "\n",
      "Fold: 23  Epoch: 275  Training loss = 4.2766  Validation loss = 0.8652  \n",
      "\n",
      "Fold: 23  Epoch: 276  Training loss = 4.2762  Validation loss = 0.8649  \n",
      "\n",
      "Fold: 23  Epoch: 277  Training loss = 4.2759  Validation loss = 0.8646  \n",
      "\n",
      "Fold: 23  Epoch: 278  Training loss = 4.2756  Validation loss = 0.8643  \n",
      "\n",
      "Fold: 23  Epoch: 279  Training loss = 4.2754  Validation loss = 0.8640  \n",
      "\n",
      "Fold: 23  Epoch: 280  Training loss = 4.2750  Validation loss = 0.8637  \n",
      "\n",
      "Fold: 23  Epoch: 281  Training loss = 4.2747  Validation loss = 0.8634  \n",
      "\n",
      "Fold: 23  Epoch: 282  Training loss = 4.2745  Validation loss = 0.8633  \n",
      "\n",
      "Fold: 23  Epoch: 283  Training loss = 4.2741  Validation loss = 0.8630  \n",
      "\n",
      "Fold: 23  Epoch: 284  Training loss = 4.2738  Validation loss = 0.8627  \n",
      "\n",
      "Fold: 23  Epoch: 285  Training loss = 4.2734  Validation loss = 0.8623  \n",
      "\n",
      "Fold: 23  Epoch: 286  Training loss = 4.2731  Validation loss = 0.8620  \n",
      "\n",
      "Fold: 23  Epoch: 287  Training loss = 4.2727  Validation loss = 0.8618  \n",
      "\n",
      "Fold: 23  Epoch: 288  Training loss = 4.2725  Validation loss = 0.8615  \n",
      "\n",
      "Fold: 23  Epoch: 289  Training loss = 4.2722  Validation loss = 0.8612  \n",
      "\n",
      "Fold: 23  Epoch: 290  Training loss = 4.2718  Validation loss = 0.8609  \n",
      "\n",
      "Fold: 23  Epoch: 291  Training loss = 4.2715  Validation loss = 0.8606  \n",
      "\n",
      "Fold: 23  Epoch: 292  Training loss = 4.2711  Validation loss = 0.8602  \n",
      "\n",
      "Fold: 23  Epoch: 293  Training loss = 4.2707  Validation loss = 0.8599  \n",
      "\n",
      "Fold: 23  Epoch: 294  Training loss = 4.2704  Validation loss = 0.8597  \n",
      "\n",
      "Fold: 23  Epoch: 295  Training loss = 4.2700  Validation loss = 0.8594  \n",
      "\n",
      "Fold: 23  Epoch: 296  Training loss = 4.2697  Validation loss = 0.8591  \n",
      "\n",
      "Fold: 23  Epoch: 297  Training loss = 4.2693  Validation loss = 0.8587  \n",
      "\n",
      "Fold: 23  Epoch: 298  Training loss = 4.2690  Validation loss = 0.8583  \n",
      "\n",
      "Fold: 23  Epoch: 299  Training loss = 4.2687  Validation loss = 0.8581  \n",
      "\n",
      "Fold: 23  Epoch: 300  Training loss = 4.2683  Validation loss = 0.8578  \n",
      "\n",
      "Fold: 23  Epoch: 301  Training loss = 4.2680  Validation loss = 0.8575  \n",
      "\n",
      "Fold: 23  Epoch: 302  Training loss = 4.2676  Validation loss = 0.8572  \n",
      "\n",
      "Fold: 23  Epoch: 303  Training loss = 4.2673  Validation loss = 0.8570  \n",
      "\n",
      "Fold: 23  Epoch: 304  Training loss = 4.2671  Validation loss = 0.8567  \n",
      "\n",
      "Fold: 23  Epoch: 305  Training loss = 4.2667  Validation loss = 0.8564  \n",
      "\n",
      "Fold: 23  Epoch: 306  Training loss = 4.2663  Validation loss = 0.8560  \n",
      "\n",
      "Fold: 23  Epoch: 307  Training loss = 4.2659  Validation loss = 0.8556  \n",
      "\n",
      "Fold: 23  Epoch: 308  Training loss = 4.2657  Validation loss = 0.8554  \n",
      "\n",
      "Fold: 23  Epoch: 309  Training loss = 4.2654  Validation loss = 0.8553  \n",
      "\n",
      "Fold: 23  Epoch: 310  Training loss = 4.2651  Validation loss = 0.8550  \n",
      "\n",
      "Fold: 23  Epoch: 311  Training loss = 4.2648  Validation loss = 0.8547  \n",
      "\n",
      "Fold: 23  Epoch: 312  Training loss = 4.2645  Validation loss = 0.8545  \n",
      "\n",
      "Fold: 23  Epoch: 313  Training loss = 4.2642  Validation loss = 0.8542  \n",
      "\n",
      "Fold: 23  Epoch: 314  Training loss = 4.2638  Validation loss = 0.8539  \n",
      "\n",
      "Fold: 23  Epoch: 315  Training loss = 4.2634  Validation loss = 0.8535  \n",
      "\n",
      "Fold: 23  Epoch: 316  Training loss = 4.2631  Validation loss = 0.8532  \n",
      "\n",
      "Fold: 23  Epoch: 317  Training loss = 4.2628  Validation loss = 0.8529  \n",
      "\n",
      "Fold: 23  Epoch: 318  Training loss = 4.2625  Validation loss = 0.8525  \n",
      "\n",
      "Fold: 23  Epoch: 319  Training loss = 4.2621  Validation loss = 0.8522  \n",
      "\n",
      "Fold: 23  Epoch: 320  Training loss = 4.2617  Validation loss = 0.8519  \n",
      "\n",
      "Fold: 23  Epoch: 321  Training loss = 4.2614  Validation loss = 0.8516  \n",
      "\n",
      "Fold: 23  Epoch: 322  Training loss = 4.2611  Validation loss = 0.8513  \n",
      "\n",
      "Fold: 23  Epoch: 323  Training loss = 4.2607  Validation loss = 0.8509  \n",
      "\n",
      "Fold: 23  Epoch: 324  Training loss = 4.2604  Validation loss = 0.8507  \n",
      "\n",
      "Fold: 23  Epoch: 325  Training loss = 4.2601  Validation loss = 0.8503  \n",
      "\n",
      "Fold: 23  Epoch: 326  Training loss = 4.2597  Validation loss = 0.8499  \n",
      "\n",
      "Fold: 23  Epoch: 327  Training loss = 4.2593  Validation loss = 0.8496  \n",
      "\n",
      "Fold: 23  Epoch: 328  Training loss = 4.2589  Validation loss = 0.8493  \n",
      "\n",
      "Fold: 23  Epoch: 329  Training loss = 4.2586  Validation loss = 0.8490  \n",
      "\n",
      "Fold: 23  Epoch: 330  Training loss = 4.2582  Validation loss = 0.8486  \n",
      "\n",
      "Fold: 23  Epoch: 331  Training loss = 4.2579  Validation loss = 0.8484  \n",
      "\n",
      "Fold: 23  Epoch: 332  Training loss = 4.2575  Validation loss = 0.8481  \n",
      "\n",
      "Fold: 23  Epoch: 333  Training loss = 4.2571  Validation loss = 0.8478  \n",
      "\n",
      "Fold: 23  Epoch: 334  Training loss = 4.2569  Validation loss = 0.8475  \n",
      "\n",
      "Fold: 23  Epoch: 335  Training loss = 4.2565  Validation loss = 0.8472  \n",
      "\n",
      "Fold: 23  Epoch: 336  Training loss = 4.2563  Validation loss = 0.8469  \n",
      "\n",
      "Fold: 23  Epoch: 337  Training loss = 4.2560  Validation loss = 0.8467  \n",
      "\n",
      "Fold: 23  Epoch: 338  Training loss = 4.2556  Validation loss = 0.8463  \n",
      "\n",
      "Fold: 23  Epoch: 339  Training loss = 4.2553  Validation loss = 0.8461  \n",
      "\n",
      "Fold: 23  Epoch: 340  Training loss = 4.2550  Validation loss = 0.8457  \n",
      "\n",
      "Fold: 23  Epoch: 341  Training loss = 4.2547  Validation loss = 0.8454  \n",
      "\n",
      "Fold: 23  Epoch: 342  Training loss = 4.2543  Validation loss = 0.8451  \n",
      "\n",
      "Fold: 23  Epoch: 343  Training loss = 4.2540  Validation loss = 0.8449  \n",
      "\n",
      "Fold: 23  Epoch: 344  Training loss = 4.2538  Validation loss = 0.8447  \n",
      "\n",
      "Fold: 23  Epoch: 345  Training loss = 4.2534  Validation loss = 0.8443  \n",
      "\n",
      "Fold: 23  Epoch: 346  Training loss = 4.2532  Validation loss = 0.8441  \n",
      "\n",
      "Fold: 23  Epoch: 347  Training loss = 4.2529  Validation loss = 0.8438  \n",
      "\n",
      "Fold: 23  Epoch: 348  Training loss = 4.2525  Validation loss = 0.8435  \n",
      "\n",
      "Fold: 23  Epoch: 349  Training loss = 4.2521  Validation loss = 0.8431  \n",
      "\n",
      "Fold: 23  Epoch: 350  Training loss = 4.2517  Validation loss = 0.8428  \n",
      "\n",
      "Fold: 23  Epoch: 351  Training loss = 4.2513  Validation loss = 0.8424  \n",
      "\n",
      "Fold: 23  Epoch: 352  Training loss = 4.2509  Validation loss = 0.8421  \n",
      "\n",
      "Fold: 23  Epoch: 353  Training loss = 4.2506  Validation loss = 0.8418  \n",
      "\n",
      "Fold: 23  Epoch: 354  Training loss = 4.2504  Validation loss = 0.8416  \n",
      "\n",
      "Fold: 23  Epoch: 355  Training loss = 4.2500  Validation loss = 0.8413  \n",
      "\n",
      "Fold: 23  Epoch: 356  Training loss = 4.2497  Validation loss = 0.8411  \n",
      "\n",
      "Fold: 23  Epoch: 357  Training loss = 4.2493  Validation loss = 0.8407  \n",
      "\n",
      "Fold: 23  Epoch: 358  Training loss = 4.2491  Validation loss = 0.8405  \n",
      "\n",
      "Fold: 23  Epoch: 359  Training loss = 4.2487  Validation loss = 0.8401  \n",
      "\n",
      "Fold: 23  Epoch: 360  Training loss = 4.2484  Validation loss = 0.8398  \n",
      "\n",
      "Fold: 23  Epoch: 361  Training loss = 4.2481  Validation loss = 0.8396  \n",
      "\n",
      "Fold: 23  Epoch: 362  Training loss = 4.2477  Validation loss = 0.8392  \n",
      "\n",
      "Fold: 23  Epoch: 363  Training loss = 4.2474  Validation loss = 0.8389  \n",
      "\n",
      "Fold: 23  Epoch: 364  Training loss = 4.2471  Validation loss = 0.8386  \n",
      "\n",
      "Fold: 23  Epoch: 365  Training loss = 4.2469  Validation loss = 0.8384  \n",
      "\n",
      "Fold: 23  Epoch: 366  Training loss = 4.2466  Validation loss = 0.8381  \n",
      "\n",
      "Fold: 23  Epoch: 367  Training loss = 4.2464  Validation loss = 0.8379  \n",
      "\n",
      "Fold: 23  Epoch: 368  Training loss = 4.2463  Validation loss = 0.8378  \n",
      "\n",
      "Fold: 23  Epoch: 369  Training loss = 4.2460  Validation loss = 0.8376  \n",
      "\n",
      "Fold: 23  Epoch: 370  Training loss = 4.2456  Validation loss = 0.8373  \n",
      "\n",
      "Fold: 23  Epoch: 371  Training loss = 4.2453  Validation loss = 0.8370  \n",
      "\n",
      "Fold: 23  Epoch: 372  Training loss = 4.2451  Validation loss = 0.8368  \n",
      "\n",
      "Fold: 23  Epoch: 373  Training loss = 4.2448  Validation loss = 0.8365  \n",
      "\n",
      "Fold: 23  Epoch: 374  Training loss = 4.2445  Validation loss = 0.8362  \n",
      "\n",
      "Fold: 23  Epoch: 375  Training loss = 4.2442  Validation loss = 0.8360  \n",
      "\n",
      "Fold: 23  Epoch: 376  Training loss = 4.2439  Validation loss = 0.8357  \n",
      "\n",
      "Fold: 23  Epoch: 377  Training loss = 4.2435  Validation loss = 0.8354  \n",
      "\n",
      "Fold: 23  Epoch: 378  Training loss = 4.2432  Validation loss = 0.8352  \n",
      "\n",
      "Fold: 23  Epoch: 379  Training loss = 4.2427  Validation loss = 0.8348  \n",
      "\n",
      "Fold: 23  Epoch: 380  Training loss = 4.2423  Validation loss = 0.8345  \n",
      "\n",
      "Fold: 23  Epoch: 381  Training loss = 4.2420  Validation loss = 0.8341  \n",
      "\n",
      "Fold: 23  Epoch: 382  Training loss = 4.2416  Validation loss = 0.8338  \n",
      "\n",
      "Fold: 23  Epoch: 383  Training loss = 4.2413  Validation loss = 0.8335  \n",
      "\n",
      "Fold: 23  Epoch: 384  Training loss = 4.2409  Validation loss = 0.8332  \n",
      "\n",
      "Fold: 23  Epoch: 385  Training loss = 4.2406  Validation loss = 0.8330  \n",
      "\n",
      "Fold: 23  Epoch: 386  Training loss = 4.2403  Validation loss = 0.8327  \n",
      "\n",
      "Fold: 23  Epoch: 387  Training loss = 4.2401  Validation loss = 0.8325  \n",
      "\n",
      "Fold: 23  Epoch: 388  Training loss = 4.2398  Validation loss = 0.8322  \n",
      "\n",
      "Fold: 23  Epoch: 389  Training loss = 4.2395  Validation loss = 0.8320  \n",
      "\n",
      "Fold: 23  Epoch: 390  Training loss = 4.2391  Validation loss = 0.8317  \n",
      "\n",
      "Fold: 23  Epoch: 391  Training loss = 4.2388  Validation loss = 0.8314  \n",
      "\n",
      "Fold: 23  Epoch: 392  Training loss = 4.2385  Validation loss = 0.8311  \n",
      "\n",
      "Fold: 23  Epoch: 393  Training loss = 4.2381  Validation loss = 0.8308  \n",
      "\n",
      "Fold: 23  Epoch: 394  Training loss = 4.2378  Validation loss = 0.8306  \n",
      "\n",
      "Fold: 23  Epoch: 395  Training loss = 4.2373  Validation loss = 0.8302  \n",
      "\n",
      "Fold: 23  Epoch: 396  Training loss = 4.2370  Validation loss = 0.8299  \n",
      "\n",
      "Fold: 23  Epoch: 397  Training loss = 4.2367  Validation loss = 0.8297  \n",
      "\n",
      "Fold: 23  Epoch: 398  Training loss = 4.2363  Validation loss = 0.8294  \n",
      "\n",
      "Fold: 23  Epoch: 399  Training loss = 4.2359  Validation loss = 0.8291  \n",
      "\n",
      "Fold: 23  Epoch: 400  Training loss = 4.2357  Validation loss = 0.8288  \n",
      "\n",
      "Fold: 23  Epoch: 401  Training loss = 4.2354  Validation loss = 0.8286  \n",
      "\n",
      "Fold: 23  Epoch: 402  Training loss = 4.2348  Validation loss = 0.8284  \n",
      "\n",
      "Fold: 23  Epoch: 403  Training loss = 4.2345  Validation loss = 0.8282  \n",
      "\n",
      "Fold: 23  Epoch: 404  Training loss = 4.2340  Validation loss = 0.8279  \n",
      "\n",
      "Fold: 23  Epoch: 405  Training loss = 4.2333  Validation loss = 0.8277  \n",
      "\n",
      "Fold: 23  Epoch: 406  Training loss = 4.2330  Validation loss = 0.8274  \n",
      "\n",
      "Fold: 23  Epoch: 407  Training loss = 4.2322  Validation loss = 0.8272  \n",
      "\n",
      "Fold: 23  Epoch: 408  Training loss = 4.2319  Validation loss = 0.8269  \n",
      "\n",
      "Fold: 23  Epoch: 409  Training loss = 4.2314  Validation loss = 0.8266  \n",
      "\n",
      "Fold: 23  Epoch: 410  Training loss = 4.2309  Validation loss = 0.8263  \n",
      "\n",
      "Fold: 23  Epoch: 411  Training loss = 4.2304  Validation loss = 0.8260  \n",
      "\n",
      "Fold: 23  Epoch: 412  Training loss = 4.2301  Validation loss = 0.8257  \n",
      "\n",
      "Fold: 23  Epoch: 413  Training loss = 4.2298  Validation loss = 0.8254  \n",
      "\n",
      "Fold: 23  Epoch: 414  Training loss = 4.2293  Validation loss = 0.8252  \n",
      "\n",
      "Fold: 23  Epoch: 415  Training loss = 4.2289  Validation loss = 0.8249  \n",
      "\n",
      "Fold: 23  Epoch: 416  Training loss = 4.2285  Validation loss = 0.8247  \n",
      "\n",
      "Fold: 23  Epoch: 417  Training loss = 4.2281  Validation loss = 0.8244  \n",
      "\n",
      "Fold: 23  Epoch: 418  Training loss = 4.2277  Validation loss = 0.8241  \n",
      "\n",
      "Fold: 23  Epoch: 419  Training loss = 4.2273  Validation loss = 0.8238  \n",
      "\n",
      "Fold: 23  Epoch: 420  Training loss = 4.2271  Validation loss = 0.8235  \n",
      "\n",
      "Fold: 23  Epoch: 421  Training loss = 4.2267  Validation loss = 0.8231  \n",
      "\n",
      "Fold: 23  Epoch: 422  Training loss = 4.2263  Validation loss = 0.8228  \n",
      "\n",
      "Fold: 23  Epoch: 423  Training loss = 4.2260  Validation loss = 0.8225  \n",
      "\n",
      "Fold: 23  Epoch: 424  Training loss = 4.2257  Validation loss = 0.8223  \n",
      "\n",
      "Fold: 23  Epoch: 425  Training loss = 4.2255  Validation loss = 0.8222  \n",
      "\n",
      "Fold: 23  Epoch: 426  Training loss = 4.2252  Validation loss = 0.8220  \n",
      "\n",
      "Fold: 23  Epoch: 427  Training loss = 4.2249  Validation loss = 0.8217  \n",
      "\n",
      "Fold: 23  Epoch: 428  Training loss = 4.2245  Validation loss = 0.8213  \n",
      "\n",
      "Fold: 23  Epoch: 429  Training loss = 4.2241  Validation loss = 0.8211  \n",
      "\n",
      "Fold: 23  Epoch: 430  Training loss = 4.2239  Validation loss = 0.8209  \n",
      "\n",
      "Fold: 23  Epoch: 431  Training loss = 4.2236  Validation loss = 0.8206  \n",
      "\n",
      "Fold: 23  Epoch: 432  Training loss = 4.2232  Validation loss = 0.8203  \n",
      "\n",
      "Fold: 23  Epoch: 433  Training loss = 4.2229  Validation loss = 0.8200  \n",
      "\n",
      "Fold: 23  Epoch: 434  Training loss = 4.2225  Validation loss = 0.8197  \n",
      "\n",
      "Fold: 23  Epoch: 435  Training loss = 4.2222  Validation loss = 0.8194  \n",
      "\n",
      "Fold: 23  Epoch: 436  Training loss = 4.2219  Validation loss = 0.8191  \n",
      "\n",
      "Fold: 23  Epoch: 437  Training loss = 4.2217  Validation loss = 0.8189  \n",
      "\n",
      "Fold: 23  Epoch: 438  Training loss = 4.2214  Validation loss = 0.8187  \n",
      "\n",
      "Fold: 23  Epoch: 439  Training loss = 4.2210  Validation loss = 0.8184  \n",
      "\n",
      "Fold: 23  Epoch: 440  Training loss = 4.2207  Validation loss = 0.8181  \n",
      "\n",
      "Fold: 23  Epoch: 441  Training loss = 4.2204  Validation loss = 0.8179  \n",
      "\n",
      "Fold: 23  Epoch: 442  Training loss = 4.2199  Validation loss = 0.8175  \n",
      "\n",
      "Fold: 23  Epoch: 443  Training loss = 4.2196  Validation loss = 0.8172  \n",
      "\n",
      "Fold: 23  Epoch: 444  Training loss = 4.2193  Validation loss = 0.8170  \n",
      "\n",
      "Fold: 23  Epoch: 445  Training loss = 4.2190  Validation loss = 0.8167  \n",
      "\n",
      "Fold: 23  Epoch: 446  Training loss = 4.2186  Validation loss = 0.8164  \n",
      "\n",
      "Fold: 23  Epoch: 447  Training loss = 4.2183  Validation loss = 0.8162  \n",
      "\n",
      "Fold: 23  Epoch: 448  Training loss = 4.2180  Validation loss = 0.8159  \n",
      "\n",
      "Fold: 23  Epoch: 449  Training loss = 4.2177  Validation loss = 0.8156  \n",
      "\n",
      "Fold: 23  Epoch: 450  Training loss = 4.2173  Validation loss = 0.8153  \n",
      "\n",
      "Fold: 23  Epoch: 451  Training loss = 4.2171  Validation loss = 0.8151  \n",
      "\n",
      "Fold: 23  Epoch: 452  Training loss = 4.2167  Validation loss = 0.8149  \n",
      "\n",
      "Fold: 23  Epoch: 453  Training loss = 4.2165  Validation loss = 0.8146  \n",
      "\n",
      "Fold: 23  Epoch: 454  Training loss = 4.2162  Validation loss = 0.8144  \n",
      "\n",
      "Fold: 23  Epoch: 455  Training loss = 4.2159  Validation loss = 0.8141  \n",
      "\n",
      "Fold: 23  Epoch: 456  Training loss = 4.2156  Validation loss = 0.8139  \n",
      "\n",
      "Fold: 23  Epoch: 457  Training loss = 4.2153  Validation loss = 0.8136  \n",
      "\n",
      "Fold: 23  Epoch: 458  Training loss = 4.2149  Validation loss = 0.8133  \n",
      "\n",
      "Fold: 23  Epoch: 459  Training loss = 4.2146  Validation loss = 0.8130  \n",
      "\n",
      "Fold: 23  Epoch: 460  Training loss = 4.2143  Validation loss = 0.8126  \n",
      "\n",
      "Fold: 23  Epoch: 461  Training loss = 4.2139  Validation loss = 0.8124  \n",
      "\n",
      "Fold: 23  Epoch: 462  Training loss = 4.2136  Validation loss = 0.8120  \n",
      "\n",
      "Fold: 23  Epoch: 463  Training loss = 4.2133  Validation loss = 0.8118  \n",
      "\n",
      "Fold: 23  Epoch: 464  Training loss = 4.2129  Validation loss = 0.8116  \n",
      "\n",
      "Fold: 23  Epoch: 465  Training loss = 4.2127  Validation loss = 0.8114  \n",
      "\n",
      "Fold: 23  Epoch: 466  Training loss = 4.2124  Validation loss = 0.8112  \n",
      "\n",
      "Fold: 23  Epoch: 467  Training loss = 4.2121  Validation loss = 0.8110  \n",
      "\n",
      "Fold: 23  Epoch: 468  Training loss = 4.2119  Validation loss = 0.8107  \n",
      "\n",
      "Fold: 23  Epoch: 469  Training loss = 4.2116  Validation loss = 0.8105  \n",
      "\n",
      "Fold: 23  Epoch: 470  Training loss = 4.2113  Validation loss = 0.8103  \n",
      "\n",
      "Fold: 23  Epoch: 471  Training loss = 4.2111  Validation loss = 0.8100  \n",
      "\n",
      "Fold: 23  Epoch: 472  Training loss = 4.2109  Validation loss = 0.8098  \n",
      "\n",
      "Fold: 23  Epoch: 473  Training loss = 4.2105  Validation loss = 0.8095  \n",
      "\n",
      "Fold: 23  Epoch: 474  Training loss = 4.2102  Validation loss = 0.8092  \n",
      "\n",
      "Fold: 23  Epoch: 475  Training loss = 4.2098  Validation loss = 0.8088  \n",
      "\n",
      "Fold: 23  Epoch: 476  Training loss = 4.2095  Validation loss = 0.8086  \n",
      "\n",
      "Fold: 23  Epoch: 477  Training loss = 4.2091  Validation loss = 0.8083  \n",
      "\n",
      "Fold: 23  Epoch: 478  Training loss = 4.2088  Validation loss = 0.8081  \n",
      "\n",
      "Fold: 23  Epoch: 479  Training loss = 4.2084  Validation loss = 0.8078  \n",
      "\n",
      "Fold: 23  Epoch: 480  Training loss = 4.2081  Validation loss = 0.8075  \n",
      "\n",
      "Fold: 23  Epoch: 481  Training loss = 4.2078  Validation loss = 0.8072  \n",
      "\n",
      "Fold: 23  Epoch: 482  Training loss = 4.2074  Validation loss = 0.8068  \n",
      "\n",
      "Fold: 23  Epoch: 483  Training loss = 4.2073  Validation loss = 0.8066  \n",
      "\n",
      "Fold: 23  Epoch: 484  Training loss = 4.2069  Validation loss = 0.8064  \n",
      "\n",
      "Fold: 23  Epoch: 485  Training loss = 4.2066  Validation loss = 0.8062  \n",
      "\n",
      "Fold: 23  Epoch: 486  Training loss = 4.2062  Validation loss = 0.8057  \n",
      "\n",
      "Fold: 23  Epoch: 487  Training loss = 4.2059  Validation loss = 0.8055  \n",
      "\n",
      "Fold: 23  Epoch: 488  Training loss = 4.2056  Validation loss = 0.8052  \n",
      "\n",
      "Fold: 23  Epoch: 489  Training loss = 4.2053  Validation loss = 0.8051  \n",
      "\n",
      "Fold: 23  Epoch: 490  Training loss = 4.2050  Validation loss = 0.8048  \n",
      "\n",
      "Fold: 23  Epoch: 491  Training loss = 4.2047  Validation loss = 0.8046  \n",
      "\n",
      "Fold: 23  Epoch: 492  Training loss = 4.2045  Validation loss = 0.8043  \n",
      "\n",
      "Fold: 23  Epoch: 493  Training loss = 4.2042  Validation loss = 0.8040  \n",
      "\n",
      "Fold: 23  Epoch: 494  Training loss = 4.2039  Validation loss = 0.8039  \n",
      "\n",
      "Fold: 23  Epoch: 495  Training loss = 4.2037  Validation loss = 0.8036  \n",
      "\n",
      "Fold: 23  Epoch: 496  Training loss = 4.2034  Validation loss = 0.8033  \n",
      "\n",
      "Fold: 23  Epoch: 497  Training loss = 4.2031  Validation loss = 0.8031  \n",
      "\n",
      "Fold: 23  Epoch: 498  Training loss = 4.2028  Validation loss = 0.8028  \n",
      "\n",
      "Fold: 23  Epoch: 499  Training loss = 4.2024  Validation loss = 0.8025  \n",
      "\n",
      "Fold: 23  Epoch: 500  Training loss = 4.2021  Validation loss = 0.8022  \n",
      "\n",
      "Check model:  Fold: 23  Optimal epoch: 500  \n",
      "\n",
      "Fold: 24  Epoch: 1  Training loss = 4.1858  Validation loss = 1.8405  \n",
      "\n",
      "Fold: 24  Epoch: 2  Training loss = 4.1855  Validation loss = 1.8403  \n",
      "\n",
      "Fold: 24  Epoch: 3  Training loss = 4.1851  Validation loss = 1.8400  \n",
      "\n",
      "Fold: 24  Epoch: 4  Training loss = 4.1848  Validation loss = 1.8398  \n",
      "\n",
      "Fold: 24  Epoch: 5  Training loss = 4.1843  Validation loss = 1.8393  \n",
      "\n",
      "Fold: 24  Epoch: 6  Training loss = 4.1839  Validation loss = 1.8389  \n",
      "\n",
      "Fold: 24  Epoch: 7  Training loss = 4.1836  Validation loss = 1.8387  \n",
      "\n",
      "Fold: 24  Epoch: 8  Training loss = 4.1832  Validation loss = 1.8384  \n",
      "\n",
      "Fold: 24  Epoch: 9  Training loss = 4.1828  Validation loss = 1.8381  \n",
      "\n",
      "Fold: 24  Epoch: 10  Training loss = 4.1826  Validation loss = 1.8378  \n",
      "\n",
      "Fold: 24  Epoch: 11  Training loss = 4.1821  Validation loss = 1.8375  \n",
      "\n",
      "Fold: 24  Epoch: 12  Training loss = 4.1818  Validation loss = 1.8372  \n",
      "\n",
      "Fold: 24  Epoch: 13  Training loss = 4.1814  Validation loss = 1.8369  \n",
      "\n",
      "Fold: 24  Epoch: 14  Training loss = 4.1809  Validation loss = 1.8364  \n",
      "\n",
      "Fold: 24  Epoch: 15  Training loss = 4.1804  Validation loss = 1.8361  \n",
      "\n",
      "Fold: 24  Epoch: 16  Training loss = 4.1800  Validation loss = 1.8358  \n",
      "\n",
      "Fold: 24  Epoch: 17  Training loss = 4.1796  Validation loss = 1.8354  \n",
      "\n",
      "Fold: 24  Epoch: 18  Training loss = 4.1793  Validation loss = 1.8351  \n",
      "\n",
      "Fold: 24  Epoch: 19  Training loss = 4.1789  Validation loss = 1.8347  \n",
      "\n",
      "Fold: 24  Epoch: 20  Training loss = 4.1785  Validation loss = 1.8343  \n",
      "\n",
      "Fold: 24  Epoch: 21  Training loss = 4.1782  Validation loss = 1.8341  \n",
      "\n",
      "Fold: 24  Epoch: 22  Training loss = 4.1779  Validation loss = 1.8338  \n",
      "\n",
      "Fold: 24  Epoch: 23  Training loss = 4.1777  Validation loss = 1.8336  \n",
      "\n",
      "Fold: 24  Epoch: 24  Training loss = 4.1772  Validation loss = 1.8333  \n",
      "\n",
      "Fold: 24  Epoch: 25  Training loss = 4.1769  Validation loss = 1.8330  \n",
      "\n",
      "Fold: 24  Epoch: 26  Training loss = 4.1765  Validation loss = 1.8326  \n",
      "\n",
      "Fold: 24  Epoch: 27  Training loss = 4.1762  Validation loss = 1.8323  \n",
      "\n",
      "Fold: 24  Epoch: 28  Training loss = 4.1758  Validation loss = 1.8320  \n",
      "\n",
      "Fold: 24  Epoch: 29  Training loss = 4.1754  Validation loss = 1.8316  \n",
      "\n",
      "Fold: 24  Epoch: 30  Training loss = 4.1750  Validation loss = 1.8314  \n",
      "\n",
      "Fold: 24  Epoch: 31  Training loss = 4.1748  Validation loss = 1.8311  \n",
      "\n",
      "Fold: 24  Epoch: 32  Training loss = 4.1745  Validation loss = 1.8309  \n",
      "\n",
      "Fold: 24  Epoch: 33  Training loss = 4.1742  Validation loss = 1.8307  \n",
      "\n",
      "Fold: 24  Epoch: 34  Training loss = 4.1739  Validation loss = 1.8304  \n",
      "\n",
      "Fold: 24  Epoch: 35  Training loss = 4.1736  Validation loss = 1.8301  \n",
      "\n",
      "Fold: 24  Epoch: 36  Training loss = 4.1732  Validation loss = 1.8299  \n",
      "\n",
      "Fold: 24  Epoch: 37  Training loss = 4.1730  Validation loss = 1.8296  \n",
      "\n",
      "Fold: 24  Epoch: 38  Training loss = 4.1725  Validation loss = 1.8292  \n",
      "\n",
      "Fold: 24  Epoch: 39  Training loss = 4.1721  Validation loss = 1.8288  \n",
      "\n",
      "Fold: 24  Epoch: 40  Training loss = 4.1718  Validation loss = 1.8286  \n",
      "\n",
      "Fold: 24  Epoch: 41  Training loss = 4.1714  Validation loss = 1.8283  \n",
      "\n",
      "Fold: 24  Epoch: 42  Training loss = 4.1710  Validation loss = 1.8279  \n",
      "\n",
      "Fold: 24  Epoch: 43  Training loss = 4.1706  Validation loss = 1.8276  \n",
      "\n",
      "Fold: 24  Epoch: 44  Training loss = 4.1703  Validation loss = 1.8272  \n",
      "\n",
      "Fold: 24  Epoch: 45  Training loss = 4.1700  Validation loss = 1.8269  \n",
      "\n",
      "Fold: 24  Epoch: 46  Training loss = 4.1696  Validation loss = 1.8266  \n",
      "\n",
      "Fold: 24  Epoch: 47  Training loss = 4.1693  Validation loss = 1.8263  \n",
      "\n",
      "Fold: 24  Epoch: 48  Training loss = 4.1690  Validation loss = 1.8261  \n",
      "\n",
      "Fold: 24  Epoch: 49  Training loss = 4.1687  Validation loss = 1.8258  \n",
      "\n",
      "Fold: 24  Epoch: 50  Training loss = 4.1683  Validation loss = 1.8255  \n",
      "\n",
      "Fold: 24  Epoch: 51  Training loss = 4.1681  Validation loss = 1.8253  \n",
      "\n",
      "Fold: 24  Epoch: 52  Training loss = 4.1678  Validation loss = 1.8250  \n",
      "\n",
      "Fold: 24  Epoch: 53  Training loss = 4.1674  Validation loss = 1.8247  \n",
      "\n",
      "Fold: 24  Epoch: 54  Training loss = 4.1672  Validation loss = 1.8245  \n",
      "\n",
      "Fold: 24  Epoch: 55  Training loss = 4.1668  Validation loss = 1.8242  \n",
      "\n",
      "Fold: 24  Epoch: 56  Training loss = 4.1665  Validation loss = 1.8239  \n",
      "\n",
      "Fold: 24  Epoch: 57  Training loss = 4.1661  Validation loss = 1.8236  \n",
      "\n",
      "Fold: 24  Epoch: 58  Training loss = 4.1657  Validation loss = 1.8232  \n",
      "\n",
      "Fold: 24  Epoch: 59  Training loss = 4.1654  Validation loss = 1.8230  \n",
      "\n",
      "Fold: 24  Epoch: 60  Training loss = 4.1650  Validation loss = 1.8227  \n",
      "\n",
      "Fold: 24  Epoch: 61  Training loss = 4.1647  Validation loss = 1.8225  \n",
      "\n",
      "Fold: 24  Epoch: 62  Training loss = 4.1644  Validation loss = 1.8222  \n",
      "\n",
      "Fold: 24  Epoch: 63  Training loss = 4.1640  Validation loss = 1.8219  \n",
      "\n",
      "Fold: 24  Epoch: 64  Training loss = 4.1636  Validation loss = 1.8215  \n",
      "\n",
      "Fold: 24  Epoch: 65  Training loss = 4.1634  Validation loss = 1.8213  \n",
      "\n",
      "Fold: 24  Epoch: 66  Training loss = 4.1631  Validation loss = 1.8211  \n",
      "\n",
      "Fold: 24  Epoch: 67  Training loss = 4.1627  Validation loss = 1.8208  \n",
      "\n",
      "Fold: 24  Epoch: 68  Training loss = 4.1624  Validation loss = 1.8206  \n",
      "\n",
      "Fold: 24  Epoch: 69  Training loss = 4.1621  Validation loss = 1.8203  \n",
      "\n",
      "Fold: 24  Epoch: 70  Training loss = 4.1619  Validation loss = 1.8201  \n",
      "\n",
      "Fold: 24  Epoch: 71  Training loss = 4.1615  Validation loss = 1.8198  \n",
      "\n",
      "Fold: 24  Epoch: 72  Training loss = 4.1612  Validation loss = 1.8195  \n",
      "\n",
      "Fold: 24  Epoch: 73  Training loss = 4.1609  Validation loss = 1.8192  \n",
      "\n",
      "Fold: 24  Epoch: 74  Training loss = 4.1605  Validation loss = 1.8189  \n",
      "\n",
      "Fold: 24  Epoch: 75  Training loss = 4.1601  Validation loss = 1.8185  \n",
      "\n",
      "Fold: 24  Epoch: 76  Training loss = 4.1597  Validation loss = 1.8182  \n",
      "\n",
      "Fold: 24  Epoch: 77  Training loss = 4.1593  Validation loss = 1.8179  \n",
      "\n",
      "Fold: 24  Epoch: 78  Training loss = 4.1589  Validation loss = 1.8176  \n",
      "\n",
      "Fold: 24  Epoch: 79  Training loss = 4.1586  Validation loss = 1.8173  \n",
      "\n",
      "Fold: 24  Epoch: 80  Training loss = 4.1583  Validation loss = 1.8170  \n",
      "\n",
      "Fold: 24  Epoch: 81  Training loss = 4.1580  Validation loss = 1.8167  \n",
      "\n",
      "Fold: 24  Epoch: 82  Training loss = 4.1575  Validation loss = 1.8163  \n",
      "\n",
      "Fold: 24  Epoch: 83  Training loss = 4.1571  Validation loss = 1.8160  \n",
      "\n",
      "Fold: 24  Epoch: 84  Training loss = 4.1567  Validation loss = 1.8157  \n",
      "\n",
      "Fold: 24  Epoch: 85  Training loss = 4.1564  Validation loss = 1.8154  \n",
      "\n",
      "Fold: 24  Epoch: 86  Training loss = 4.1560  Validation loss = 1.8150  \n",
      "\n",
      "Fold: 24  Epoch: 87  Training loss = 4.1556  Validation loss = 1.8147  \n",
      "\n",
      "Fold: 24  Epoch: 88  Training loss = 4.1554  Validation loss = 1.8144  \n",
      "\n",
      "Fold: 24  Epoch: 89  Training loss = 4.1551  Validation loss = 1.8142  \n",
      "\n",
      "Fold: 24  Epoch: 90  Training loss = 4.1548  Validation loss = 1.8140  \n",
      "\n",
      "Fold: 24  Epoch: 91  Training loss = 4.1545  Validation loss = 1.8138  \n",
      "\n",
      "Fold: 24  Epoch: 92  Training loss = 4.1541  Validation loss = 1.8134  \n",
      "\n",
      "Fold: 24  Epoch: 93  Training loss = 4.1538  Validation loss = 1.8132  \n",
      "\n",
      "Fold: 24  Epoch: 94  Training loss = 4.1535  Validation loss = 1.8129  \n",
      "\n",
      "Fold: 24  Epoch: 95  Training loss = 4.1532  Validation loss = 1.8126  \n",
      "\n",
      "Fold: 24  Epoch: 96  Training loss = 4.1529  Validation loss = 1.8124  \n",
      "\n",
      "Fold: 24  Epoch: 97  Training loss = 4.1525  Validation loss = 1.8120  \n",
      "\n",
      "Fold: 24  Epoch: 98  Training loss = 4.1522  Validation loss = 1.8117  \n",
      "\n",
      "Fold: 24  Epoch: 99  Training loss = 4.1518  Validation loss = 1.8114  \n",
      "\n",
      "Fold: 24  Epoch: 100  Training loss = 4.1515  Validation loss = 1.8111  \n",
      "\n",
      "Fold: 24  Epoch: 101  Training loss = 4.1512  Validation loss = 1.8109  \n",
      "\n",
      "Fold: 24  Epoch: 102  Training loss = 4.1508  Validation loss = 1.8106  \n",
      "\n",
      "Fold: 24  Epoch: 103  Training loss = 4.1506  Validation loss = 1.8104  \n",
      "\n",
      "Fold: 24  Epoch: 104  Training loss = 4.1503  Validation loss = 1.8101  \n",
      "\n",
      "Fold: 24  Epoch: 105  Training loss = 4.1500  Validation loss = 1.8099  \n",
      "\n",
      "Fold: 24  Epoch: 106  Training loss = 4.1498  Validation loss = 1.8096  \n",
      "\n",
      "Fold: 24  Epoch: 107  Training loss = 4.1495  Validation loss = 1.8094  \n",
      "\n",
      "Fold: 24  Epoch: 108  Training loss = 4.1492  Validation loss = 1.8092  \n",
      "\n",
      "Fold: 24  Epoch: 109  Training loss = 4.1489  Validation loss = 1.8089  \n",
      "\n",
      "Fold: 24  Epoch: 110  Training loss = 4.1486  Validation loss = 1.8086  \n",
      "\n",
      "Fold: 24  Epoch: 111  Training loss = 4.1483  Validation loss = 1.8083  \n",
      "\n",
      "Fold: 24  Epoch: 112  Training loss = 4.1479  Validation loss = 1.8080  \n",
      "\n",
      "Fold: 24  Epoch: 113  Training loss = 4.1475  Validation loss = 1.8076  \n",
      "\n",
      "Fold: 24  Epoch: 114  Training loss = 4.1470  Validation loss = 1.8073  \n",
      "\n",
      "Fold: 24  Epoch: 115  Training loss = 4.1468  Validation loss = 1.8071  \n",
      "\n",
      "Fold: 24  Epoch: 116  Training loss = 4.1465  Validation loss = 1.8069  \n",
      "\n",
      "Fold: 24  Epoch: 117  Training loss = 4.1462  Validation loss = 1.8067  \n",
      "\n",
      "Fold: 24  Epoch: 118  Training loss = 4.1459  Validation loss = 1.8064  \n",
      "\n",
      "Fold: 24  Epoch: 119  Training loss = 4.1456  Validation loss = 1.8062  \n",
      "\n",
      "Fold: 24  Epoch: 120  Training loss = 4.1453  Validation loss = 1.8060  \n",
      "\n",
      "Fold: 24  Epoch: 121  Training loss = 4.1449  Validation loss = 1.8056  \n",
      "\n",
      "Fold: 24  Epoch: 122  Training loss = 4.1445  Validation loss = 1.8053  \n",
      "\n",
      "Fold: 24  Epoch: 123  Training loss = 4.1441  Validation loss = 1.8050  \n",
      "\n",
      "Fold: 24  Epoch: 124  Training loss = 4.1437  Validation loss = 1.8047  \n",
      "\n",
      "Fold: 24  Epoch: 125  Training loss = 4.1434  Validation loss = 1.8045  \n",
      "\n",
      "Fold: 24  Epoch: 126  Training loss = 4.1430  Validation loss = 1.8041  \n",
      "\n",
      "Fold: 24  Epoch: 127  Training loss = 4.1426  Validation loss = 1.8038  \n",
      "\n",
      "Fold: 24  Epoch: 128  Training loss = 4.1423  Validation loss = 1.8035  \n",
      "\n",
      "Fold: 24  Epoch: 129  Training loss = 4.1420  Validation loss = 1.8031  \n",
      "\n",
      "Fold: 24  Epoch: 130  Training loss = 4.1416  Validation loss = 1.8028  \n",
      "\n",
      "Fold: 24  Epoch: 131  Training loss = 4.1413  Validation loss = 1.8026  \n",
      "\n",
      "Fold: 24  Epoch: 132  Training loss = 4.1410  Validation loss = 1.8024  \n",
      "\n",
      "Fold: 24  Epoch: 133  Training loss = 4.1408  Validation loss = 1.8022  \n",
      "\n",
      "Fold: 24  Epoch: 134  Training loss = 4.1405  Validation loss = 1.8019  \n",
      "\n",
      "Fold: 24  Epoch: 135  Training loss = 4.1402  Validation loss = 1.8016  \n",
      "\n",
      "Fold: 24  Epoch: 136  Training loss = 4.1397  Validation loss = 1.8012  \n",
      "\n",
      "Fold: 24  Epoch: 137  Training loss = 4.1393  Validation loss = 1.8009  \n",
      "\n",
      "Fold: 24  Epoch: 138  Training loss = 4.1391  Validation loss = 1.8006  \n",
      "\n",
      "Fold: 24  Epoch: 139  Training loss = 4.1387  Validation loss = 1.8003  \n",
      "\n",
      "Fold: 24  Epoch: 140  Training loss = 4.1383  Validation loss = 1.8000  \n",
      "\n",
      "Fold: 24  Epoch: 141  Training loss = 4.1380  Validation loss = 1.7998  \n",
      "\n",
      "Fold: 24  Epoch: 142  Training loss = 4.1377  Validation loss = 1.7995  \n",
      "\n",
      "Fold: 24  Epoch: 143  Training loss = 4.1373  Validation loss = 1.7991  \n",
      "\n",
      "Fold: 24  Epoch: 144  Training loss = 4.1369  Validation loss = 1.7988  \n",
      "\n",
      "Fold: 24  Epoch: 145  Training loss = 4.1366  Validation loss = 1.7985  \n",
      "\n",
      "Fold: 24  Epoch: 146  Training loss = 4.1364  Validation loss = 1.7984  \n",
      "\n",
      "Fold: 24  Epoch: 147  Training loss = 4.1361  Validation loss = 1.7982  \n",
      "\n",
      "Fold: 24  Epoch: 148  Training loss = 4.1356  Validation loss = 1.7978  \n",
      "\n",
      "Fold: 24  Epoch: 149  Training loss = 4.1353  Validation loss = 1.7975  \n",
      "\n",
      "Fold: 24  Epoch: 150  Training loss = 4.1350  Validation loss = 1.7973  \n",
      "\n",
      "Fold: 24  Epoch: 151  Training loss = 4.1347  Validation loss = 1.7971  \n",
      "\n",
      "Fold: 24  Epoch: 152  Training loss = 4.1344  Validation loss = 1.7968  \n",
      "\n",
      "Fold: 24  Epoch: 153  Training loss = 4.1340  Validation loss = 1.7965  \n",
      "\n",
      "Fold: 24  Epoch: 154  Training loss = 4.1338  Validation loss = 1.7963  \n",
      "\n",
      "Fold: 24  Epoch: 155  Training loss = 4.1333  Validation loss = 1.7959  \n",
      "\n",
      "Fold: 24  Epoch: 156  Training loss = 4.1328  Validation loss = 1.7955  \n",
      "\n",
      "Fold: 24  Epoch: 157  Training loss = 4.1325  Validation loss = 1.7951  \n",
      "\n",
      "Fold: 24  Epoch: 158  Training loss = 4.1320  Validation loss = 1.7948  \n",
      "\n",
      "Fold: 24  Epoch: 159  Training loss = 4.1317  Validation loss = 1.7945  \n",
      "\n",
      "Fold: 24  Epoch: 160  Training loss = 4.1313  Validation loss = 1.7942  \n",
      "\n",
      "Fold: 24  Epoch: 161  Training loss = 4.1310  Validation loss = 1.7939  \n",
      "\n",
      "Fold: 24  Epoch: 162  Training loss = 4.1306  Validation loss = 1.7935  \n",
      "\n",
      "Fold: 24  Epoch: 163  Training loss = 4.1303  Validation loss = 1.7933  \n",
      "\n",
      "Fold: 24  Epoch: 164  Training loss = 4.1298  Validation loss = 1.7929  \n",
      "\n",
      "Fold: 24  Epoch: 165  Training loss = 4.1295  Validation loss = 1.7926  \n",
      "\n",
      "Fold: 24  Epoch: 166  Training loss = 4.1291  Validation loss = 1.7923  \n",
      "\n",
      "Fold: 24  Epoch: 167  Training loss = 4.1288  Validation loss = 1.7920  \n",
      "\n",
      "Fold: 24  Epoch: 168  Training loss = 4.1284  Validation loss = 1.7917  \n",
      "\n",
      "Fold: 24  Epoch: 169  Training loss = 4.1281  Validation loss = 1.7914  \n",
      "\n",
      "Fold: 24  Epoch: 170  Training loss = 4.1276  Validation loss = 1.7911  \n",
      "\n",
      "Fold: 24  Epoch: 171  Training loss = 4.1272  Validation loss = 1.7907  \n",
      "\n",
      "Fold: 24  Epoch: 172  Training loss = 4.1269  Validation loss = 1.7904  \n",
      "\n",
      "Fold: 24  Epoch: 173  Training loss = 4.1265  Validation loss = 1.7900  \n",
      "\n",
      "Fold: 24  Epoch: 174  Training loss = 4.1261  Validation loss = 1.7897  \n",
      "\n",
      "Fold: 24  Epoch: 175  Training loss = 4.1258  Validation loss = 1.7895  \n",
      "\n",
      "Fold: 24  Epoch: 176  Training loss = 4.1253  Validation loss = 1.7890  \n",
      "\n",
      "Fold: 24  Epoch: 177  Training loss = 4.1249  Validation loss = 1.7887  \n",
      "\n",
      "Fold: 24  Epoch: 178  Training loss = 4.1245  Validation loss = 1.7884  \n",
      "\n",
      "Fold: 24  Epoch: 179  Training loss = 4.1241  Validation loss = 1.7881  \n",
      "\n",
      "Fold: 24  Epoch: 180  Training loss = 4.1238  Validation loss = 1.7878  \n",
      "\n",
      "Fold: 24  Epoch: 181  Training loss = 4.1236  Validation loss = 1.7876  \n",
      "\n",
      "Fold: 24  Epoch: 182  Training loss = 4.1233  Validation loss = 1.7873  \n",
      "\n",
      "Fold: 24  Epoch: 183  Training loss = 4.1229  Validation loss = 1.7870  \n",
      "\n",
      "Fold: 24  Epoch: 184  Training loss = 4.1225  Validation loss = 1.7866  \n",
      "\n",
      "Fold: 24  Epoch: 185  Training loss = 4.1221  Validation loss = 1.7863  \n",
      "\n",
      "Fold: 24  Epoch: 186  Training loss = 4.1218  Validation loss = 1.7860  \n",
      "\n",
      "Fold: 24  Epoch: 187  Training loss = 4.1214  Validation loss = 1.7858  \n",
      "\n",
      "Fold: 24  Epoch: 188  Training loss = 4.1211  Validation loss = 1.7855  \n",
      "\n",
      "Fold: 24  Epoch: 189  Training loss = 4.1208  Validation loss = 1.7852  \n",
      "\n",
      "Fold: 24  Epoch: 190  Training loss = 4.1204  Validation loss = 1.7849  \n",
      "\n",
      "Fold: 24  Epoch: 191  Training loss = 4.1200  Validation loss = 1.7845  \n",
      "\n",
      "Fold: 24  Epoch: 192  Training loss = 4.1197  Validation loss = 1.7843  \n",
      "\n",
      "Fold: 24  Epoch: 193  Training loss = 4.1194  Validation loss = 1.7841  \n",
      "\n",
      "Fold: 24  Epoch: 194  Training loss = 4.1191  Validation loss = 1.7838  \n",
      "\n",
      "Fold: 24  Epoch: 195  Training loss = 4.1187  Validation loss = 1.7835  \n",
      "\n",
      "Fold: 24  Epoch: 196  Training loss = 4.1185  Validation loss = 1.7832  \n",
      "\n",
      "Fold: 24  Epoch: 197  Training loss = 4.1182  Validation loss = 1.7830  \n",
      "\n",
      "Fold: 24  Epoch: 198  Training loss = 4.1179  Validation loss = 1.7828  \n",
      "\n",
      "Fold: 24  Epoch: 199  Training loss = 4.1176  Validation loss = 1.7825  \n",
      "\n",
      "Fold: 24  Epoch: 200  Training loss = 4.1174  Validation loss = 1.7824  \n",
      "\n",
      "Fold: 24  Epoch: 201  Training loss = 4.1172  Validation loss = 1.7821  \n",
      "\n",
      "Fold: 24  Epoch: 202  Training loss = 4.1169  Validation loss = 1.7819  \n",
      "\n",
      "Fold: 24  Epoch: 203  Training loss = 4.1165  Validation loss = 1.7816  \n",
      "\n",
      "Fold: 24  Epoch: 204  Training loss = 4.1161  Validation loss = 1.7813  \n",
      "\n",
      "Fold: 24  Epoch: 205  Training loss = 4.1157  Validation loss = 1.7810  \n",
      "\n",
      "Fold: 24  Epoch: 206  Training loss = 4.1153  Validation loss = 1.7806  \n",
      "\n",
      "Fold: 24  Epoch: 207  Training loss = 4.1150  Validation loss = 1.7804  \n",
      "\n",
      "Fold: 24  Epoch: 208  Training loss = 4.1146  Validation loss = 1.7801  \n",
      "\n",
      "Fold: 24  Epoch: 209  Training loss = 4.1145  Validation loss = 1.7799  \n",
      "\n",
      "Fold: 24  Epoch: 210  Training loss = 4.1141  Validation loss = 1.7796  \n",
      "\n",
      "Fold: 24  Epoch: 211  Training loss = 4.1138  Validation loss = 1.7794  \n",
      "\n",
      "Fold: 24  Epoch: 212  Training loss = 4.1135  Validation loss = 1.7791  \n",
      "\n",
      "Fold: 24  Epoch: 213  Training loss = 4.1132  Validation loss = 1.7789  \n",
      "\n",
      "Fold: 24  Epoch: 214  Training loss = 4.1129  Validation loss = 1.7786  \n",
      "\n",
      "Fold: 24  Epoch: 215  Training loss = 4.1125  Validation loss = 1.7783  \n",
      "\n",
      "Fold: 24  Epoch: 216  Training loss = 4.1123  Validation loss = 1.7781  \n",
      "\n",
      "Fold: 24  Epoch: 217  Training loss = 4.1119  Validation loss = 1.7778  \n",
      "\n",
      "Fold: 24  Epoch: 218  Training loss = 4.1116  Validation loss = 1.7776  \n",
      "\n",
      "Fold: 24  Epoch: 219  Training loss = 4.1113  Validation loss = 1.7774  \n",
      "\n",
      "Fold: 24  Epoch: 220  Training loss = 4.1110  Validation loss = 1.7771  \n",
      "\n",
      "Fold: 24  Epoch: 221  Training loss = 4.1107  Validation loss = 1.7769  \n",
      "\n",
      "Fold: 24  Epoch: 222  Training loss = 4.1104  Validation loss = 1.7766  \n",
      "\n",
      "Fold: 24  Epoch: 223  Training loss = 4.1100  Validation loss = 1.7763  \n",
      "\n",
      "Fold: 24  Epoch: 224  Training loss = 4.1097  Validation loss = 1.7761  \n",
      "\n",
      "Fold: 24  Epoch: 225  Training loss = 4.1095  Validation loss = 1.7759  \n",
      "\n",
      "Fold: 24  Epoch: 226  Training loss = 4.1092  Validation loss = 1.7757  \n",
      "\n",
      "Fold: 24  Epoch: 227  Training loss = 4.1088  Validation loss = 1.7753  \n",
      "\n",
      "Fold: 24  Epoch: 228  Training loss = 4.1085  Validation loss = 1.7751  \n",
      "\n",
      "Fold: 24  Epoch: 229  Training loss = 4.1082  Validation loss = 1.7748  \n",
      "\n",
      "Fold: 24  Epoch: 230  Training loss = 4.1079  Validation loss = 1.7747  \n",
      "\n",
      "Fold: 24  Epoch: 231  Training loss = 4.1076  Validation loss = 1.7744  \n",
      "\n",
      "Fold: 24  Epoch: 232  Training loss = 4.1073  Validation loss = 1.7742  \n",
      "\n",
      "Fold: 24  Epoch: 233  Training loss = 4.1071  Validation loss = 1.7739  \n",
      "\n",
      "Fold: 24  Epoch: 234  Training loss = 4.1068  Validation loss = 1.7737  \n",
      "\n",
      "Fold: 24  Epoch: 235  Training loss = 4.1065  Validation loss = 1.7734  \n",
      "\n",
      "Fold: 24  Epoch: 236  Training loss = 4.1063  Validation loss = 1.7732  \n",
      "\n",
      "Fold: 24  Epoch: 237  Training loss = 4.1060  Validation loss = 1.7729  \n",
      "\n",
      "Fold: 24  Epoch: 238  Training loss = 4.1057  Validation loss = 1.7727  \n",
      "\n",
      "Fold: 24  Epoch: 239  Training loss = 4.1053  Validation loss = 1.7724  \n",
      "\n",
      "Fold: 24  Epoch: 240  Training loss = 4.1050  Validation loss = 1.7722  \n",
      "\n",
      "Fold: 24  Epoch: 241  Training loss = 4.1047  Validation loss = 1.7719  \n",
      "\n",
      "Fold: 24  Epoch: 242  Training loss = 4.1044  Validation loss = 1.7717  \n",
      "\n",
      "Fold: 24  Epoch: 243  Training loss = 4.1040  Validation loss = 1.7713  \n",
      "\n",
      "Fold: 24  Epoch: 244  Training loss = 4.1038  Validation loss = 1.7711  \n",
      "\n",
      "Fold: 24  Epoch: 245  Training loss = 4.1034  Validation loss = 1.7708  \n",
      "\n",
      "Fold: 24  Epoch: 246  Training loss = 4.1032  Validation loss = 1.7706  \n",
      "\n",
      "Fold: 24  Epoch: 247  Training loss = 4.1029  Validation loss = 1.7704  \n",
      "\n",
      "Fold: 24  Epoch: 248  Training loss = 4.1027  Validation loss = 1.7702  \n",
      "\n",
      "Fold: 24  Epoch: 249  Training loss = 4.1023  Validation loss = 1.7699  \n",
      "\n",
      "Fold: 24  Epoch: 250  Training loss = 4.1019  Validation loss = 1.7696  \n",
      "\n",
      "Fold: 24  Epoch: 251  Training loss = 4.1016  Validation loss = 1.7693  \n",
      "\n",
      "Fold: 24  Epoch: 252  Training loss = 4.1013  Validation loss = 1.7691  \n",
      "\n",
      "Fold: 24  Epoch: 253  Training loss = 4.1011  Validation loss = 1.7689  \n",
      "\n",
      "Fold: 24  Epoch: 254  Training loss = 4.1008  Validation loss = 1.7687  \n",
      "\n",
      "Fold: 24  Epoch: 255  Training loss = 4.1004  Validation loss = 1.7684  \n",
      "\n",
      "Fold: 24  Epoch: 256  Training loss = 4.1001  Validation loss = 1.7681  \n",
      "\n",
      "Fold: 24  Epoch: 257  Training loss = 4.0997  Validation loss = 1.7677  \n",
      "\n",
      "Fold: 24  Epoch: 258  Training loss = 4.0994  Validation loss = 1.7675  \n",
      "\n",
      "Fold: 24  Epoch: 259  Training loss = 4.0991  Validation loss = 1.7672  \n",
      "\n",
      "Fold: 24  Epoch: 260  Training loss = 4.0989  Validation loss = 1.7671  \n",
      "\n",
      "Fold: 24  Epoch: 261  Training loss = 4.0985  Validation loss = 1.7667  \n",
      "\n",
      "Fold: 24  Epoch: 262  Training loss = 4.0981  Validation loss = 1.7665  \n",
      "\n",
      "Fold: 24  Epoch: 263  Training loss = 4.0978  Validation loss = 1.7661  \n",
      "\n",
      "Fold: 24  Epoch: 264  Training loss = 4.0976  Validation loss = 1.7659  \n",
      "\n",
      "Fold: 24  Epoch: 265  Training loss = 4.0972  Validation loss = 1.7656  \n",
      "\n",
      "Fold: 24  Epoch: 266  Training loss = 4.0969  Validation loss = 1.7654  \n",
      "\n",
      "Fold: 24  Epoch: 267  Training loss = 4.0967  Validation loss = 1.7652  \n",
      "\n",
      "Fold: 24  Epoch: 268  Training loss = 4.0964  Validation loss = 1.7649  \n",
      "\n",
      "Fold: 24  Epoch: 269  Training loss = 4.0961  Validation loss = 1.7646  \n",
      "\n",
      "Fold: 24  Epoch: 270  Training loss = 4.0958  Validation loss = 1.7643  \n",
      "\n",
      "Fold: 24  Epoch: 271  Training loss = 4.0955  Validation loss = 1.7641  \n",
      "\n",
      "Fold: 24  Epoch: 272  Training loss = 4.0951  Validation loss = 1.7638  \n",
      "\n",
      "Fold: 24  Epoch: 273  Training loss = 4.0949  Validation loss = 1.7636  \n",
      "\n",
      "Fold: 24  Epoch: 274  Training loss = 4.0945  Validation loss = 1.7633  \n",
      "\n",
      "Fold: 24  Epoch: 275  Training loss = 4.0941  Validation loss = 1.7630  \n",
      "\n",
      "Fold: 24  Epoch: 276  Training loss = 4.0938  Validation loss = 1.7627  \n",
      "\n",
      "Fold: 24  Epoch: 277  Training loss = 4.0934  Validation loss = 1.7625  \n",
      "\n",
      "Fold: 24  Epoch: 278  Training loss = 4.0931  Validation loss = 1.7621  \n",
      "\n",
      "Fold: 24  Epoch: 279  Training loss = 4.0928  Validation loss = 1.7619  \n",
      "\n",
      "Fold: 24  Epoch: 280  Training loss = 4.0924  Validation loss = 1.7616  \n",
      "\n",
      "Fold: 24  Epoch: 281  Training loss = 4.0921  Validation loss = 1.7613  \n",
      "\n",
      "Fold: 24  Epoch: 282  Training loss = 4.0918  Validation loss = 1.7610  \n",
      "\n",
      "Fold: 24  Epoch: 283  Training loss = 4.0914  Validation loss = 1.7607  \n",
      "\n",
      "Fold: 24  Epoch: 284  Training loss = 4.0911  Validation loss = 1.7603  \n",
      "\n",
      "Fold: 24  Epoch: 285  Training loss = 4.0906  Validation loss = 1.7600  \n",
      "\n",
      "Fold: 24  Epoch: 286  Training loss = 4.0904  Validation loss = 1.7599  \n",
      "\n",
      "Fold: 24  Epoch: 287  Training loss = 4.0902  Validation loss = 1.7596  \n",
      "\n",
      "Fold: 24  Epoch: 288  Training loss = 4.0899  Validation loss = 1.7593  \n",
      "\n",
      "Fold: 24  Epoch: 289  Training loss = 4.0896  Validation loss = 1.7591  \n",
      "\n",
      "Fold: 24  Epoch: 290  Training loss = 4.0891  Validation loss = 1.7587  \n",
      "\n",
      "Fold: 24  Epoch: 291  Training loss = 4.0888  Validation loss = 1.7584  \n",
      "\n",
      "Fold: 24  Epoch: 292  Training loss = 4.0885  Validation loss = 1.7582  \n",
      "\n",
      "Fold: 24  Epoch: 293  Training loss = 4.0883  Validation loss = 1.7580  \n",
      "\n",
      "Fold: 24  Epoch: 294  Training loss = 4.0880  Validation loss = 1.7578  \n",
      "\n",
      "Fold: 24  Epoch: 295  Training loss = 4.0877  Validation loss = 1.7575  \n",
      "\n",
      "Fold: 24  Epoch: 296  Training loss = 4.0873  Validation loss = 1.7572  \n",
      "\n",
      "Fold: 24  Epoch: 297  Training loss = 4.0869  Validation loss = 1.7569  \n",
      "\n",
      "Fold: 24  Epoch: 298  Training loss = 4.0865  Validation loss = 1.7565  \n",
      "\n",
      "Fold: 24  Epoch: 299  Training loss = 4.0863  Validation loss = 1.7563  \n",
      "\n",
      "Fold: 24  Epoch: 300  Training loss = 4.0860  Validation loss = 1.7561  \n",
      "\n",
      "Fold: 24  Epoch: 301  Training loss = 4.0856  Validation loss = 1.7558  \n",
      "\n",
      "Fold: 24  Epoch: 302  Training loss = 4.0853  Validation loss = 1.7555  \n",
      "\n",
      "Fold: 24  Epoch: 303  Training loss = 4.0850  Validation loss = 1.7553  \n",
      "\n",
      "Fold: 24  Epoch: 304  Training loss = 4.0848  Validation loss = 1.7550  \n",
      "\n",
      "Fold: 24  Epoch: 305  Training loss = 4.0844  Validation loss = 1.7547  \n",
      "\n",
      "Fold: 24  Epoch: 306  Training loss = 4.0841  Validation loss = 1.7544  \n",
      "\n",
      "Fold: 24  Epoch: 307  Training loss = 4.0838  Validation loss = 1.7542  \n",
      "\n",
      "Fold: 24  Epoch: 308  Training loss = 4.0836  Validation loss = 1.7540  \n",
      "\n",
      "Fold: 24  Epoch: 309  Training loss = 4.0833  Validation loss = 1.7538  \n",
      "\n",
      "Fold: 24  Epoch: 310  Training loss = 4.0830  Validation loss = 1.7535  \n",
      "\n",
      "Fold: 24  Epoch: 311  Training loss = 4.0827  Validation loss = 1.7532  \n",
      "\n",
      "Fold: 24  Epoch: 312  Training loss = 4.0824  Validation loss = 1.7529  \n",
      "\n",
      "Fold: 24  Epoch: 313  Training loss = 4.0821  Validation loss = 1.7527  \n",
      "\n",
      "Fold: 24  Epoch: 314  Training loss = 4.0818  Validation loss = 1.7525  \n",
      "\n",
      "Fold: 24  Epoch: 315  Training loss = 4.0815  Validation loss = 1.7522  \n",
      "\n",
      "Fold: 24  Epoch: 316  Training loss = 4.0811  Validation loss = 1.7519  \n",
      "\n",
      "Fold: 24  Epoch: 317  Training loss = 4.0808  Validation loss = 1.7517  \n",
      "\n",
      "Fold: 24  Epoch: 318  Training loss = 4.0806  Validation loss = 1.7515  \n",
      "\n",
      "Fold: 24  Epoch: 319  Training loss = 4.0802  Validation loss = 1.7512  \n",
      "\n",
      "Fold: 24  Epoch: 320  Training loss = 4.0800  Validation loss = 1.7510  \n",
      "\n",
      "Fold: 24  Epoch: 321  Training loss = 4.0796  Validation loss = 1.7507  \n",
      "\n",
      "Fold: 24  Epoch: 322  Training loss = 4.0792  Validation loss = 1.7504  \n",
      "\n",
      "Fold: 24  Epoch: 323  Training loss = 4.0789  Validation loss = 1.7501  \n",
      "\n",
      "Fold: 24  Epoch: 324  Training loss = 4.0785  Validation loss = 1.7498  \n",
      "\n",
      "Fold: 24  Epoch: 325  Training loss = 4.0781  Validation loss = 1.7495  \n",
      "\n",
      "Fold: 24  Epoch: 326  Training loss = 4.0778  Validation loss = 1.7492  \n",
      "\n",
      "Fold: 24  Epoch: 327  Training loss = 4.0774  Validation loss = 1.7489  \n",
      "\n",
      "Fold: 24  Epoch: 328  Training loss = 4.0771  Validation loss = 1.7487  \n",
      "\n",
      "Fold: 24  Epoch: 329  Training loss = 4.0768  Validation loss = 1.7485  \n",
      "\n",
      "Fold: 24  Epoch: 330  Training loss = 4.0764  Validation loss = 1.7482  \n",
      "\n",
      "Fold: 24  Epoch: 331  Training loss = 4.0762  Validation loss = 1.7480  \n",
      "\n",
      "Fold: 24  Epoch: 332  Training loss = 4.0759  Validation loss = 1.7477  \n",
      "\n",
      "Fold: 24  Epoch: 333  Training loss = 4.0756  Validation loss = 1.7475  \n",
      "\n",
      "Fold: 24  Epoch: 334  Training loss = 4.0755  Validation loss = 1.7474  \n",
      "\n",
      "Fold: 24  Epoch: 335  Training loss = 4.0751  Validation loss = 1.7471  \n",
      "\n",
      "Fold: 24  Epoch: 336  Training loss = 4.0747  Validation loss = 1.7468  \n",
      "\n",
      "Fold: 24  Epoch: 337  Training loss = 4.0745  Validation loss = 1.7466  \n",
      "\n",
      "Fold: 24  Epoch: 338  Training loss = 4.0741  Validation loss = 1.7463  \n",
      "\n",
      "Fold: 24  Epoch: 339  Training loss = 4.0739  Validation loss = 1.7461  \n",
      "\n",
      "Fold: 24  Epoch: 340  Training loss = 4.0737  Validation loss = 1.7459  \n",
      "\n",
      "Fold: 24  Epoch: 341  Training loss = 4.0733  Validation loss = 1.7456  \n",
      "\n",
      "Fold: 24  Epoch: 342  Training loss = 4.0731  Validation loss = 1.7454  \n",
      "\n",
      "Fold: 24  Epoch: 343  Training loss = 4.0727  Validation loss = 1.7450  \n",
      "\n",
      "Fold: 24  Epoch: 344  Training loss = 4.0724  Validation loss = 1.7448  \n",
      "\n",
      "Fold: 24  Epoch: 345  Training loss = 4.0722  Validation loss = 1.7446  \n",
      "\n",
      "Fold: 24  Epoch: 346  Training loss = 4.0719  Validation loss = 1.7444  \n",
      "\n",
      "Fold: 24  Epoch: 347  Training loss = 4.0716  Validation loss = 1.7441  \n",
      "\n",
      "Fold: 24  Epoch: 348  Training loss = 4.0712  Validation loss = 1.7437  \n",
      "\n",
      "Fold: 24  Epoch: 349  Training loss = 4.0709  Validation loss = 1.7435  \n",
      "\n",
      "Fold: 24  Epoch: 350  Training loss = 4.0706  Validation loss = 1.7433  \n",
      "\n",
      "Fold: 24  Epoch: 351  Training loss = 4.0704  Validation loss = 1.7431  \n",
      "\n",
      "Fold: 24  Epoch: 352  Training loss = 4.0700  Validation loss = 1.7428  \n",
      "\n",
      "Fold: 24  Epoch: 353  Training loss = 4.0697  Validation loss = 1.7425  \n",
      "\n",
      "Fold: 24  Epoch: 354  Training loss = 4.0693  Validation loss = 1.7422  \n",
      "\n",
      "Fold: 24  Epoch: 355  Training loss = 4.0689  Validation loss = 1.7419  \n",
      "\n",
      "Fold: 24  Epoch: 356  Training loss = 4.0686  Validation loss = 1.7416  \n",
      "\n",
      "Fold: 24  Epoch: 357  Training loss = 4.0682  Validation loss = 1.7412  \n",
      "\n",
      "Fold: 24  Epoch: 358  Training loss = 4.0678  Validation loss = 1.7410  \n",
      "\n",
      "Fold: 24  Epoch: 359  Training loss = 4.0675  Validation loss = 1.7407  \n",
      "\n",
      "Fold: 24  Epoch: 360  Training loss = 4.0671  Validation loss = 1.7404  \n",
      "\n",
      "Fold: 24  Epoch: 361  Training loss = 4.0668  Validation loss = 1.7402  \n",
      "\n",
      "Fold: 24  Epoch: 362  Training loss = 4.0665  Validation loss = 1.7400  \n",
      "\n",
      "Fold: 24  Epoch: 363  Training loss = 4.0662  Validation loss = 1.7397  \n",
      "\n",
      "Fold: 24  Epoch: 364  Training loss = 4.0659  Validation loss = 1.7394  \n",
      "\n",
      "Fold: 24  Epoch: 365  Training loss = 4.0656  Validation loss = 1.7392  \n",
      "\n",
      "Fold: 24  Epoch: 366  Training loss = 4.0653  Validation loss = 1.7389  \n",
      "\n",
      "Fold: 24  Epoch: 367  Training loss = 4.0651  Validation loss = 1.7388  \n",
      "\n",
      "Fold: 24  Epoch: 368  Training loss = 4.0648  Validation loss = 1.7385  \n",
      "\n",
      "Fold: 24  Epoch: 369  Training loss = 4.0645  Validation loss = 1.7382  \n",
      "\n",
      "Fold: 24  Epoch: 370  Training loss = 4.0642  Validation loss = 1.7380  \n",
      "\n",
      "Fold: 24  Epoch: 371  Training loss = 4.0639  Validation loss = 1.7378  \n",
      "\n",
      "Fold: 24  Epoch: 372  Training loss = 4.0637  Validation loss = 1.7376  \n",
      "\n",
      "Fold: 24  Epoch: 373  Training loss = 4.0634  Validation loss = 1.7373  \n",
      "\n",
      "Fold: 24  Epoch: 374  Training loss = 4.0631  Validation loss = 1.7370  \n",
      "\n",
      "Fold: 24  Epoch: 375  Training loss = 4.0628  Validation loss = 1.7368  \n",
      "\n",
      "Fold: 24  Epoch: 376  Training loss = 4.0624  Validation loss = 1.7365  \n",
      "\n",
      "Fold: 24  Epoch: 377  Training loss = 4.0621  Validation loss = 1.7362  \n",
      "\n",
      "Fold: 24  Epoch: 378  Training loss = 4.0617  Validation loss = 1.7359  \n",
      "\n",
      "Fold: 24  Epoch: 379  Training loss = 4.0613  Validation loss = 1.7355  \n",
      "\n",
      "Fold: 24  Epoch: 380  Training loss = 4.0610  Validation loss = 1.7353  \n",
      "\n",
      "Fold: 24  Epoch: 381  Training loss = 4.0608  Validation loss = 1.7351  \n",
      "\n",
      "Fold: 24  Epoch: 382  Training loss = 4.0605  Validation loss = 1.7348  \n",
      "\n",
      "Fold: 24  Epoch: 383  Training loss = 4.0603  Validation loss = 1.7347  \n",
      "\n",
      "Fold: 24  Epoch: 384  Training loss = 4.0599  Validation loss = 1.7344  \n",
      "\n",
      "Fold: 24  Epoch: 385  Training loss = 4.0597  Validation loss = 1.7342  \n",
      "\n",
      "Fold: 24  Epoch: 386  Training loss = 4.0595  Validation loss = 1.7340  \n",
      "\n",
      "Fold: 24  Epoch: 387  Training loss = 4.0592  Validation loss = 1.7338  \n",
      "\n",
      "Fold: 24  Epoch: 388  Training loss = 4.0588  Validation loss = 1.7335  \n",
      "\n",
      "Fold: 24  Epoch: 389  Training loss = 4.0585  Validation loss = 1.7333  \n",
      "\n",
      "Fold: 24  Epoch: 390  Training loss = 4.0582  Validation loss = 1.7330  \n",
      "\n",
      "Fold: 24  Epoch: 391  Training loss = 4.0579  Validation loss = 1.7328  \n",
      "\n",
      "Fold: 24  Epoch: 392  Training loss = 4.0577  Validation loss = 1.7326  \n",
      "\n",
      "Fold: 24  Epoch: 393  Training loss = 4.0574  Validation loss = 1.7323  \n",
      "\n",
      "Fold: 24  Epoch: 394  Training loss = 4.0571  Validation loss = 1.7321  \n",
      "\n",
      "Fold: 24  Epoch: 395  Training loss = 4.0568  Validation loss = 1.7319  \n",
      "\n",
      "Fold: 24  Epoch: 396  Training loss = 4.0566  Validation loss = 1.7317  \n",
      "\n",
      "Fold: 24  Epoch: 397  Training loss = 4.0563  Validation loss = 1.7314  \n",
      "\n",
      "Fold: 24  Epoch: 398  Training loss = 4.0559  Validation loss = 1.7311  \n",
      "\n",
      "Fold: 24  Epoch: 399  Training loss = 4.0557  Validation loss = 1.7309  \n",
      "\n",
      "Fold: 24  Epoch: 400  Training loss = 4.0553  Validation loss = 1.7306  \n",
      "\n",
      "Fold: 24  Epoch: 401  Training loss = 4.0550  Validation loss = 1.7304  \n",
      "\n",
      "Fold: 24  Epoch: 402  Training loss = 4.0546  Validation loss = 1.7300  \n",
      "\n",
      "Fold: 24  Epoch: 403  Training loss = 4.0543  Validation loss = 1.7297  \n",
      "\n",
      "Fold: 24  Epoch: 404  Training loss = 4.0540  Validation loss = 1.7295  \n",
      "\n",
      "Fold: 24  Epoch: 405  Training loss = 4.0537  Validation loss = 1.7293  \n",
      "\n",
      "Fold: 24  Epoch: 406  Training loss = 4.0534  Validation loss = 1.7290  \n",
      "\n",
      "Fold: 24  Epoch: 407  Training loss = 4.0531  Validation loss = 1.7288  \n",
      "\n",
      "Fold: 24  Epoch: 408  Training loss = 4.0527  Validation loss = 1.7285  \n",
      "\n",
      "Fold: 24  Epoch: 409  Training loss = 4.0525  Validation loss = 1.7283  \n",
      "\n",
      "Fold: 24  Epoch: 410  Training loss = 4.0522  Validation loss = 1.7280  \n",
      "\n",
      "Fold: 24  Epoch: 411  Training loss = 4.0518  Validation loss = 1.7278  \n",
      "\n",
      "Fold: 24  Epoch: 412  Training loss = 4.0515  Validation loss = 1.7275  \n",
      "\n",
      "Fold: 24  Epoch: 413  Training loss = 4.0512  Validation loss = 1.7272  \n",
      "\n",
      "Fold: 24  Epoch: 414  Training loss = 4.0510  Validation loss = 1.7270  \n",
      "\n",
      "Fold: 24  Epoch: 415  Training loss = 4.0506  Validation loss = 1.7267  \n",
      "\n",
      "Fold: 24  Epoch: 416  Training loss = 4.0502  Validation loss = 1.7264  \n",
      "\n",
      "Fold: 24  Epoch: 417  Training loss = 4.0499  Validation loss = 1.7262  \n",
      "\n",
      "Fold: 24  Epoch: 418  Training loss = 4.0496  Validation loss = 1.7259  \n",
      "\n",
      "Fold: 24  Epoch: 419  Training loss = 4.0493  Validation loss = 1.7256  \n",
      "\n",
      "Fold: 24  Epoch: 420  Training loss = 4.0490  Validation loss = 1.7254  \n",
      "\n",
      "Fold: 24  Epoch: 421  Training loss = 4.0487  Validation loss = 1.7252  \n",
      "\n",
      "Fold: 24  Epoch: 422  Training loss = 4.0484  Validation loss = 1.7249  \n",
      "\n",
      "Fold: 24  Epoch: 423  Training loss = 4.0481  Validation loss = 1.7247  \n",
      "\n",
      "Fold: 24  Epoch: 424  Training loss = 4.0478  Validation loss = 1.7244  \n",
      "\n",
      "Fold: 24  Epoch: 425  Training loss = 4.0475  Validation loss = 1.7242  \n",
      "\n",
      "Fold: 24  Epoch: 426  Training loss = 4.0471  Validation loss = 1.7239  \n",
      "\n",
      "Fold: 24  Epoch: 427  Training loss = 4.0467  Validation loss = 1.7236  \n",
      "\n",
      "Fold: 24  Epoch: 428  Training loss = 4.0464  Validation loss = 1.7233  \n",
      "\n",
      "Fold: 24  Epoch: 429  Training loss = 4.0461  Validation loss = 1.7230  \n",
      "\n",
      "Fold: 24  Epoch: 430  Training loss = 4.0458  Validation loss = 1.7228  \n",
      "\n",
      "Fold: 24  Epoch: 431  Training loss = 4.0455  Validation loss = 1.7226  \n",
      "\n",
      "Fold: 24  Epoch: 432  Training loss = 4.0453  Validation loss = 1.7224  \n",
      "\n",
      "Fold: 24  Epoch: 433  Training loss = 4.0450  Validation loss = 1.7222  \n",
      "\n",
      "Fold: 24  Epoch: 434  Training loss = 4.0447  Validation loss = 1.7219  \n",
      "\n",
      "Fold: 24  Epoch: 435  Training loss = 4.0443  Validation loss = 1.7216  \n",
      "\n",
      "Fold: 24  Epoch: 436  Training loss = 4.0441  Validation loss = 1.7214  \n",
      "\n",
      "Fold: 24  Epoch: 437  Training loss = 4.0437  Validation loss = 1.7212  \n",
      "\n",
      "Fold: 24  Epoch: 438  Training loss = 4.0434  Validation loss = 1.7209  \n",
      "\n",
      "Fold: 24  Epoch: 439  Training loss = 4.0431  Validation loss = 1.7207  \n",
      "\n",
      "Fold: 24  Epoch: 440  Training loss = 4.0428  Validation loss = 1.7204  \n",
      "\n",
      "Fold: 24  Epoch: 441  Training loss = 4.0425  Validation loss = 1.7202  \n",
      "\n",
      "Fold: 24  Epoch: 442  Training loss = 4.0422  Validation loss = 1.7199  \n",
      "\n",
      "Fold: 24  Epoch: 443  Training loss = 4.0418  Validation loss = 1.7196  \n",
      "\n",
      "Fold: 24  Epoch: 444  Training loss = 4.0415  Validation loss = 1.7193  \n",
      "\n",
      "Fold: 24  Epoch: 445  Training loss = 4.0412  Validation loss = 1.7191  \n",
      "\n",
      "Fold: 24  Epoch: 446  Training loss = 4.0408  Validation loss = 1.7188  \n",
      "\n",
      "Fold: 24  Epoch: 447  Training loss = 4.0406  Validation loss = 1.7186  \n",
      "\n",
      "Fold: 24  Epoch: 448  Training loss = 4.0402  Validation loss = 1.7183  \n",
      "\n",
      "Fold: 24  Epoch: 449  Training loss = 4.0400  Validation loss = 1.7181  \n",
      "\n",
      "Fold: 24  Epoch: 450  Training loss = 4.0396  Validation loss = 1.7178  \n",
      "\n",
      "Fold: 24  Epoch: 451  Training loss = 4.0392  Validation loss = 1.7174  \n",
      "\n",
      "Fold: 24  Epoch: 452  Training loss = 4.0389  Validation loss = 1.7172  \n",
      "\n",
      "Fold: 24  Epoch: 453  Training loss = 4.0387  Validation loss = 1.7170  \n",
      "\n",
      "Fold: 24  Epoch: 454  Training loss = 4.0385  Validation loss = 1.7169  \n",
      "\n",
      "Fold: 24  Epoch: 455  Training loss = 4.0381  Validation loss = 1.7165  \n",
      "\n",
      "Fold: 24  Epoch: 456  Training loss = 4.0378  Validation loss = 1.7163  \n",
      "\n",
      "Fold: 24  Epoch: 457  Training loss = 4.0374  Validation loss = 1.7160  \n",
      "\n",
      "Fold: 24  Epoch: 458  Training loss = 4.0371  Validation loss = 1.7157  \n",
      "\n",
      "Fold: 24  Epoch: 459  Training loss = 4.0368  Validation loss = 1.7155  \n",
      "\n",
      "Fold: 24  Epoch: 460  Training loss = 4.0365  Validation loss = 1.7152  \n",
      "\n",
      "Fold: 24  Epoch: 461  Training loss = 4.0362  Validation loss = 1.7149  \n",
      "\n",
      "Fold: 24  Epoch: 462  Training loss = 4.0359  Validation loss = 1.7147  \n",
      "\n",
      "Fold: 24  Epoch: 463  Training loss = 4.0355  Validation loss = 1.7144  \n",
      "\n",
      "Fold: 24  Epoch: 464  Training loss = 4.0353  Validation loss = 1.7141  \n",
      "\n",
      "Fold: 24  Epoch: 465  Training loss = 4.0349  Validation loss = 1.7138  \n",
      "\n",
      "Fold: 24  Epoch: 466  Training loss = 4.0347  Validation loss = 1.7136  \n",
      "\n",
      "Fold: 24  Epoch: 467  Training loss = 4.0343  Validation loss = 1.7133  \n",
      "\n",
      "Fold: 24  Epoch: 468  Training loss = 4.0340  Validation loss = 1.7130  \n",
      "\n",
      "Fold: 24  Epoch: 469  Training loss = 4.0337  Validation loss = 1.7127  \n",
      "\n",
      "Fold: 24  Epoch: 470  Training loss = 4.0334  Validation loss = 1.7125  \n",
      "\n",
      "Fold: 24  Epoch: 471  Training loss = 4.0333  Validation loss = 1.7123  \n",
      "\n",
      "Fold: 24  Epoch: 472  Training loss = 4.0329  Validation loss = 1.7121  \n",
      "\n",
      "Fold: 24  Epoch: 473  Training loss = 4.0327  Validation loss = 1.7120  \n",
      "\n",
      "Fold: 24  Epoch: 474  Training loss = 4.0325  Validation loss = 1.7118  \n",
      "\n",
      "Fold: 24  Epoch: 475  Training loss = 4.0322  Validation loss = 1.7116  \n",
      "\n",
      "Fold: 24  Epoch: 476  Training loss = 4.0319  Validation loss = 1.7114  \n",
      "\n",
      "Fold: 24  Epoch: 477  Training loss = 4.0317  Validation loss = 1.7111  \n",
      "\n",
      "Fold: 24  Epoch: 478  Training loss = 4.0313  Validation loss = 1.7109  \n",
      "\n",
      "Fold: 24  Epoch: 479  Training loss = 4.0310  Validation loss = 1.7106  \n",
      "\n",
      "Fold: 24  Epoch: 480  Training loss = 4.0307  Validation loss = 1.7104  \n",
      "\n",
      "Fold: 24  Epoch: 481  Training loss = 4.0305  Validation loss = 1.7102  \n",
      "\n",
      "Fold: 24  Epoch: 482  Training loss = 4.0301  Validation loss = 1.7099  \n",
      "\n",
      "Fold: 24  Epoch: 483  Training loss = 4.0298  Validation loss = 1.7096  \n",
      "\n",
      "Fold: 24  Epoch: 484  Training loss = 4.0294  Validation loss = 1.7094  \n",
      "\n",
      "Fold: 24  Epoch: 485  Training loss = 4.0290  Validation loss = 1.7090  \n",
      "\n",
      "Fold: 24  Epoch: 486  Training loss = 4.0287  Validation loss = 1.7087  \n",
      "\n",
      "Fold: 24  Epoch: 487  Training loss = 4.0283  Validation loss = 1.7085  \n",
      "\n",
      "Fold: 24  Epoch: 488  Training loss = 4.0280  Validation loss = 1.7082  \n",
      "\n",
      "Fold: 24  Epoch: 489  Training loss = 4.0278  Validation loss = 1.7080  \n",
      "\n",
      "Fold: 24  Epoch: 490  Training loss = 4.0275  Validation loss = 1.7078  \n",
      "\n",
      "Fold: 24  Epoch: 491  Training loss = 4.0272  Validation loss = 1.7076  \n",
      "\n",
      "Fold: 24  Epoch: 492  Training loss = 4.0269  Validation loss = 1.7073  \n",
      "\n",
      "Fold: 24  Epoch: 493  Training loss = 4.0266  Validation loss = 1.7072  \n",
      "\n",
      "Fold: 24  Epoch: 494  Training loss = 4.0262  Validation loss = 1.7068  \n",
      "\n",
      "Fold: 24  Epoch: 495  Training loss = 4.0259  Validation loss = 1.7066  \n",
      "\n",
      "Fold: 24  Epoch: 496  Training loss = 4.0257  Validation loss = 1.7064  \n",
      "\n",
      "Fold: 24  Epoch: 497  Training loss = 4.0254  Validation loss = 1.7061  \n",
      "\n",
      "Fold: 24  Epoch: 498  Training loss = 4.0251  Validation loss = 1.7059  \n",
      "\n",
      "Fold: 24  Epoch: 499  Training loss = 4.0247  Validation loss = 1.7056  \n",
      "\n",
      "Fold: 24  Epoch: 500  Training loss = 4.0244  Validation loss = 1.7053  \n",
      "\n",
      "Check model:  Fold: 24  Optimal epoch: 500  \n",
      "\n",
      "Fold: 25  Epoch: 1  Training loss = 3.9859  Validation loss = 2.5888  \n",
      "\n",
      "Fold: 25  Epoch: 2  Training loss = 3.9856  Validation loss = 2.5883  \n",
      "\n",
      "Fold: 25  Epoch: 3  Training loss = 3.9853  Validation loss = 2.5880  \n",
      "\n",
      "Fold: 25  Epoch: 4  Training loss = 3.9851  Validation loss = 2.5876  \n",
      "\n",
      "Fold: 25  Epoch: 5  Training loss = 3.9849  Validation loss = 2.5873  \n",
      "\n",
      "Fold: 25  Epoch: 6  Training loss = 3.9846  Validation loss = 2.5869  \n",
      "\n",
      "Fold: 25  Epoch: 7  Training loss = 3.9842  Validation loss = 2.5864  \n",
      "\n",
      "Fold: 25  Epoch: 8  Training loss = 3.9840  Validation loss = 2.5860  \n",
      "\n",
      "Fold: 25  Epoch: 9  Training loss = 3.9837  Validation loss = 2.5856  \n",
      "\n",
      "Fold: 25  Epoch: 10  Training loss = 3.9834  Validation loss = 2.5852  \n",
      "\n",
      "Fold: 25  Epoch: 11  Training loss = 3.9832  Validation loss = 2.5848  \n",
      "\n",
      "Fold: 25  Epoch: 12  Training loss = 3.9829  Validation loss = 2.5845  \n",
      "\n",
      "Fold: 25  Epoch: 13  Training loss = 3.9826  Validation loss = 2.5841  \n",
      "\n",
      "Fold: 25  Epoch: 14  Training loss = 3.9824  Validation loss = 2.5838  \n",
      "\n",
      "Fold: 25  Epoch: 15  Training loss = 3.9821  Validation loss = 2.5834  \n",
      "\n",
      "Fold: 25  Epoch: 16  Training loss = 3.9818  Validation loss = 2.5830  \n",
      "\n",
      "Fold: 25  Epoch: 17  Training loss = 3.9815  Validation loss = 2.5826  \n",
      "\n",
      "Fold: 25  Epoch: 18  Training loss = 3.9813  Validation loss = 2.5822  \n",
      "\n",
      "Fold: 25  Epoch: 19  Training loss = 3.9810  Validation loss = 2.5819  \n",
      "\n",
      "Fold: 25  Epoch: 20  Training loss = 3.9807  Validation loss = 2.5814  \n",
      "\n",
      "Fold: 25  Epoch: 21  Training loss = 3.9805  Validation loss = 2.5811  \n",
      "\n",
      "Fold: 25  Epoch: 22  Training loss = 3.9802  Validation loss = 2.5807  \n",
      "\n",
      "Fold: 25  Epoch: 23  Training loss = 3.9799  Validation loss = 2.5803  \n",
      "\n",
      "Fold: 25  Epoch: 24  Training loss = 3.9796  Validation loss = 2.5798  \n",
      "\n",
      "Fold: 25  Epoch: 25  Training loss = 3.9792  Validation loss = 2.5794  \n",
      "\n",
      "Fold: 25  Epoch: 26  Training loss = 3.9789  Validation loss = 2.5788  \n",
      "\n",
      "Fold: 25  Epoch: 27  Training loss = 3.9786  Validation loss = 2.5784  \n",
      "\n",
      "Fold: 25  Epoch: 28  Training loss = 3.9783  Validation loss = 2.5779  \n",
      "\n",
      "Fold: 25  Epoch: 29  Training loss = 3.9779  Validation loss = 2.5775  \n",
      "\n",
      "Fold: 25  Epoch: 30  Training loss = 3.9777  Validation loss = 2.5772  \n",
      "\n",
      "Fold: 25  Epoch: 31  Training loss = 3.9775  Validation loss = 2.5770  \n",
      "\n",
      "Fold: 25  Epoch: 32  Training loss = 3.9773  Validation loss = 2.5766  \n",
      "\n",
      "Fold: 25  Epoch: 33  Training loss = 3.9770  Validation loss = 2.5762  \n",
      "\n",
      "Fold: 25  Epoch: 34  Training loss = 3.9767  Validation loss = 2.5758  \n",
      "\n",
      "Fold: 25  Epoch: 35  Training loss = 3.9765  Validation loss = 2.5755  \n",
      "\n",
      "Fold: 25  Epoch: 36  Training loss = 3.9761  Validation loss = 2.5750  \n",
      "\n",
      "Fold: 25  Epoch: 37  Training loss = 3.9759  Validation loss = 2.5747  \n",
      "\n",
      "Fold: 25  Epoch: 38  Training loss = 3.9756  Validation loss = 2.5743  \n",
      "\n",
      "Fold: 25  Epoch: 39  Training loss = 3.9753  Validation loss = 2.5739  \n",
      "\n",
      "Fold: 25  Epoch: 40  Training loss = 3.9750  Validation loss = 2.5736  \n",
      "\n",
      "Fold: 25  Epoch: 41  Training loss = 3.9747  Validation loss = 2.5731  \n",
      "\n",
      "Fold: 25  Epoch: 42  Training loss = 3.9744  Validation loss = 2.5726  \n",
      "\n",
      "Fold: 25  Epoch: 43  Training loss = 3.9741  Validation loss = 2.5722  \n",
      "\n",
      "Fold: 25  Epoch: 44  Training loss = 3.9737  Validation loss = 2.5717  \n",
      "\n",
      "Fold: 25  Epoch: 45  Training loss = 3.9734  Validation loss = 2.5712  \n",
      "\n",
      "Fold: 25  Epoch: 46  Training loss = 3.9731  Validation loss = 2.5708  \n",
      "\n",
      "Fold: 25  Epoch: 47  Training loss = 3.9727  Validation loss = 2.5703  \n",
      "\n",
      "Fold: 25  Epoch: 48  Training loss = 3.9725  Validation loss = 2.5699  \n",
      "\n",
      "Fold: 25  Epoch: 49  Training loss = 3.9723  Validation loss = 2.5697  \n",
      "\n",
      "Fold: 25  Epoch: 50  Training loss = 3.9721  Validation loss = 2.5694  \n",
      "\n",
      "Fold: 25  Epoch: 51  Training loss = 3.9718  Validation loss = 2.5690  \n",
      "\n",
      "Fold: 25  Epoch: 52  Training loss = 3.9716  Validation loss = 2.5687  \n",
      "\n",
      "Fold: 25  Epoch: 53  Training loss = 3.9714  Validation loss = 2.5684  \n",
      "\n",
      "Fold: 25  Epoch: 54  Training loss = 3.9711  Validation loss = 2.5680  \n",
      "\n",
      "Fold: 25  Epoch: 55  Training loss = 3.9708  Validation loss = 2.5675  \n",
      "\n",
      "Fold: 25  Epoch: 56  Training loss = 3.9706  Validation loss = 2.5673  \n",
      "\n",
      "Fold: 25  Epoch: 57  Training loss = 3.9703  Validation loss = 2.5668  \n",
      "\n",
      "Fold: 25  Epoch: 58  Training loss = 3.9700  Validation loss = 2.5664  \n",
      "\n",
      "Fold: 25  Epoch: 59  Training loss = 3.9697  Validation loss = 2.5660  \n",
      "\n",
      "Fold: 25  Epoch: 60  Training loss = 3.9695  Validation loss = 2.5657  \n",
      "\n",
      "Fold: 25  Epoch: 61  Training loss = 3.9692  Validation loss = 2.5653  \n",
      "\n",
      "Fold: 25  Epoch: 62  Training loss = 3.9689  Validation loss = 2.5649  \n",
      "\n",
      "Fold: 25  Epoch: 63  Training loss = 3.9687  Validation loss = 2.5646  \n",
      "\n",
      "Fold: 25  Epoch: 64  Training loss = 3.9684  Validation loss = 2.5642  \n",
      "\n",
      "Fold: 25  Epoch: 65  Training loss = 3.9681  Validation loss = 2.5638  \n",
      "\n",
      "Fold: 25  Epoch: 66  Training loss = 3.9678  Validation loss = 2.5633  \n",
      "\n",
      "Fold: 25  Epoch: 67  Training loss = 3.9676  Validation loss = 2.5630  \n",
      "\n",
      "Fold: 25  Epoch: 68  Training loss = 3.9673  Validation loss = 2.5626  \n",
      "\n",
      "Fold: 25  Epoch: 69  Training loss = 3.9669  Validation loss = 2.5621  \n",
      "\n",
      "Fold: 25  Epoch: 70  Training loss = 3.9667  Validation loss = 2.5618  \n",
      "\n",
      "Fold: 25  Epoch: 71  Training loss = 3.9665  Validation loss = 2.5615  \n",
      "\n",
      "Fold: 25  Epoch: 72  Training loss = 3.9662  Validation loss = 2.5610  \n",
      "\n",
      "Fold: 25  Epoch: 73  Training loss = 3.9660  Validation loss = 2.5607  \n",
      "\n",
      "Fold: 25  Epoch: 74  Training loss = 3.9656  Validation loss = 2.5601  \n",
      "\n",
      "Fold: 25  Epoch: 75  Training loss = 3.9653  Validation loss = 2.5597  \n",
      "\n",
      "Fold: 25  Epoch: 76  Training loss = 3.9651  Validation loss = 2.5594  \n",
      "\n",
      "Fold: 25  Epoch: 77  Training loss = 3.9648  Validation loss = 2.5591  \n",
      "\n",
      "Fold: 25  Epoch: 78  Training loss = 3.9646  Validation loss = 2.5588  \n",
      "\n",
      "Fold: 25  Epoch: 79  Training loss = 3.9644  Validation loss = 2.5584  \n",
      "\n",
      "Fold: 25  Epoch: 80  Training loss = 3.9641  Validation loss = 2.5580  \n",
      "\n",
      "Fold: 25  Epoch: 81  Training loss = 3.9638  Validation loss = 2.5576  \n",
      "\n",
      "Fold: 25  Epoch: 82  Training loss = 3.9636  Validation loss = 2.5573  \n",
      "\n",
      "Fold: 25  Epoch: 83  Training loss = 3.9633  Validation loss = 2.5569  \n",
      "\n",
      "Fold: 25  Epoch: 84  Training loss = 3.9630  Validation loss = 2.5565  \n",
      "\n",
      "Fold: 25  Epoch: 85  Training loss = 3.9627  Validation loss = 2.5560  \n",
      "\n",
      "Fold: 25  Epoch: 86  Training loss = 3.9624  Validation loss = 2.5557  \n",
      "\n",
      "Fold: 25  Epoch: 87  Training loss = 3.9623  Validation loss = 2.5555  \n",
      "\n",
      "Fold: 25  Epoch: 88  Training loss = 3.9620  Validation loss = 2.5551  \n",
      "\n",
      "Fold: 25  Epoch: 89  Training loss = 3.9617  Validation loss = 2.5548  \n",
      "\n",
      "Fold: 25  Epoch: 90  Training loss = 3.9614  Validation loss = 2.5543  \n",
      "\n",
      "Fold: 25  Epoch: 91  Training loss = 3.9612  Validation loss = 2.5540  \n",
      "\n",
      "Fold: 25  Epoch: 92  Training loss = 3.9609  Validation loss = 2.5536  \n",
      "\n",
      "Fold: 25  Epoch: 93  Training loss = 3.9607  Validation loss = 2.5533  \n",
      "\n",
      "Fold: 25  Epoch: 94  Training loss = 3.9604  Validation loss = 2.5528  \n",
      "\n",
      "Fold: 25  Epoch: 95  Training loss = 3.9600  Validation loss = 2.5523  \n",
      "\n",
      "Fold: 25  Epoch: 96  Training loss = 3.9597  Validation loss = 2.5519  \n",
      "\n",
      "Fold: 25  Epoch: 97  Training loss = 3.9594  Validation loss = 2.5514  \n",
      "\n",
      "Fold: 25  Epoch: 98  Training loss = 3.9592  Validation loss = 2.5513  \n",
      "\n",
      "Fold: 25  Epoch: 99  Training loss = 3.9590  Validation loss = 2.5509  \n",
      "\n",
      "Fold: 25  Epoch: 100  Training loss = 3.9588  Validation loss = 2.5506  \n",
      "\n",
      "Fold: 25  Epoch: 101  Training loss = 3.9585  Validation loss = 2.5502  \n",
      "\n",
      "Fold: 25  Epoch: 102  Training loss = 3.9582  Validation loss = 2.5498  \n",
      "\n",
      "Fold: 25  Epoch: 103  Training loss = 3.9579  Validation loss = 2.5493  \n",
      "\n",
      "Fold: 25  Epoch: 104  Training loss = 3.9576  Validation loss = 2.5489  \n",
      "\n",
      "Fold: 25  Epoch: 105  Training loss = 3.9573  Validation loss = 2.5485  \n",
      "\n",
      "Fold: 25  Epoch: 106  Training loss = 3.9571  Validation loss = 2.5483  \n",
      "\n",
      "Fold: 25  Epoch: 107  Training loss = 3.9569  Validation loss = 2.5479  \n",
      "\n",
      "Fold: 25  Epoch: 108  Training loss = 3.9565  Validation loss = 2.5473  \n",
      "\n",
      "Fold: 25  Epoch: 109  Training loss = 3.9563  Validation loss = 2.5471  \n",
      "\n",
      "Fold: 25  Epoch: 110  Training loss = 3.9560  Validation loss = 2.5467  \n",
      "\n",
      "Fold: 25  Epoch: 111  Training loss = 3.9556  Validation loss = 2.5462  \n",
      "\n",
      "Fold: 25  Epoch: 112  Training loss = 3.9554  Validation loss = 2.5458  \n",
      "\n",
      "Fold: 25  Epoch: 113  Training loss = 3.9551  Validation loss = 2.5455  \n",
      "\n",
      "Fold: 25  Epoch: 114  Training loss = 3.9549  Validation loss = 2.5452  \n",
      "\n",
      "Fold: 25  Epoch: 115  Training loss = 3.9546  Validation loss = 2.5447  \n",
      "\n",
      "Fold: 25  Epoch: 116  Training loss = 3.9543  Validation loss = 2.5443  \n",
      "\n",
      "Fold: 25  Epoch: 117  Training loss = 3.9541  Validation loss = 2.5440  \n",
      "\n",
      "Fold: 25  Epoch: 118  Training loss = 3.9538  Validation loss = 2.5435  \n",
      "\n",
      "Fold: 25  Epoch: 119  Training loss = 3.9535  Validation loss = 2.5431  \n",
      "\n",
      "Fold: 25  Epoch: 120  Training loss = 3.9532  Validation loss = 2.5427  \n",
      "\n",
      "Fold: 25  Epoch: 121  Training loss = 3.9529  Validation loss = 2.5422  \n",
      "\n",
      "Fold: 25  Epoch: 122  Training loss = 3.9526  Validation loss = 2.5418  \n",
      "\n",
      "Fold: 25  Epoch: 123  Training loss = 3.9523  Validation loss = 2.5415  \n",
      "\n",
      "Fold: 25  Epoch: 124  Training loss = 3.9520  Validation loss = 2.5410  \n",
      "\n",
      "Fold: 25  Epoch: 125  Training loss = 3.9518  Validation loss = 2.5407  \n",
      "\n",
      "Fold: 25  Epoch: 126  Training loss = 3.9516  Validation loss = 2.5404  \n",
      "\n",
      "Fold: 25  Epoch: 127  Training loss = 3.9513  Validation loss = 2.5400  \n",
      "\n",
      "Fold: 25  Epoch: 128  Training loss = 3.9510  Validation loss = 2.5396  \n",
      "\n",
      "Fold: 25  Epoch: 129  Training loss = 3.9507  Validation loss = 2.5393  \n",
      "\n",
      "Fold: 25  Epoch: 130  Training loss = 3.9504  Validation loss = 2.5388  \n",
      "\n",
      "Fold: 25  Epoch: 131  Training loss = 3.9501  Validation loss = 2.5383  \n",
      "\n",
      "Fold: 25  Epoch: 132  Training loss = 3.9499  Validation loss = 2.5380  \n",
      "\n",
      "Fold: 25  Epoch: 133  Training loss = 3.9496  Validation loss = 2.5376  \n",
      "\n",
      "Fold: 25  Epoch: 134  Training loss = 3.9494  Validation loss = 2.5373  \n",
      "\n",
      "Fold: 25  Epoch: 135  Training loss = 3.9492  Validation loss = 2.5370  \n",
      "\n",
      "Fold: 25  Epoch: 136  Training loss = 3.9489  Validation loss = 2.5366  \n",
      "\n",
      "Fold: 25  Epoch: 137  Training loss = 3.9486  Validation loss = 2.5362  \n",
      "\n",
      "Fold: 25  Epoch: 138  Training loss = 3.9484  Validation loss = 2.5358  \n",
      "\n",
      "Fold: 25  Epoch: 139  Training loss = 3.9481  Validation loss = 2.5354  \n",
      "\n",
      "Fold: 25  Epoch: 140  Training loss = 3.9478  Validation loss = 2.5349  \n",
      "\n",
      "Fold: 25  Epoch: 141  Training loss = 3.9476  Validation loss = 2.5347  \n",
      "\n",
      "Fold: 25  Epoch: 142  Training loss = 3.9474  Validation loss = 2.5344  \n",
      "\n",
      "Fold: 25  Epoch: 143  Training loss = 3.9470  Validation loss = 2.5339  \n",
      "\n",
      "Fold: 25  Epoch: 144  Training loss = 3.9467  Validation loss = 2.5335  \n",
      "\n",
      "Fold: 25  Epoch: 145  Training loss = 3.9464  Validation loss = 2.5331  \n",
      "\n",
      "Fold: 25  Epoch: 146  Training loss = 3.9461  Validation loss = 2.5327  \n",
      "\n",
      "Fold: 25  Epoch: 147  Training loss = 3.9460  Validation loss = 2.5324  \n",
      "\n",
      "Fold: 25  Epoch: 148  Training loss = 3.9457  Validation loss = 2.5321  \n",
      "\n",
      "Fold: 25  Epoch: 149  Training loss = 3.9454  Validation loss = 2.5317  \n",
      "\n",
      "Fold: 25  Epoch: 150  Training loss = 3.9453  Validation loss = 2.5315  \n",
      "\n",
      "Fold: 25  Epoch: 151  Training loss = 3.9449  Validation loss = 2.5309  \n",
      "\n",
      "Fold: 25  Epoch: 152  Training loss = 3.9447  Validation loss = 2.5306  \n",
      "\n",
      "Fold: 25  Epoch: 153  Training loss = 3.9443  Validation loss = 2.5301  \n",
      "\n",
      "Fold: 25  Epoch: 154  Training loss = 3.9440  Validation loss = 2.5297  \n",
      "\n",
      "Fold: 25  Epoch: 155  Training loss = 3.9438  Validation loss = 2.5294  \n",
      "\n",
      "Fold: 25  Epoch: 156  Training loss = 3.9436  Validation loss = 2.5290  \n",
      "\n",
      "Fold: 25  Epoch: 157  Training loss = 3.9433  Validation loss = 2.5286  \n",
      "\n",
      "Fold: 25  Epoch: 158  Training loss = 3.9431  Validation loss = 2.5282  \n",
      "\n",
      "Fold: 25  Epoch: 159  Training loss = 3.9428  Validation loss = 2.5279  \n",
      "\n",
      "Fold: 25  Epoch: 160  Training loss = 3.9426  Validation loss = 2.5276  \n",
      "\n",
      "Fold: 25  Epoch: 161  Training loss = 3.9423  Validation loss = 2.5272  \n",
      "\n",
      "Fold: 25  Epoch: 162  Training loss = 3.9419  Validation loss = 2.5266  \n",
      "\n",
      "Fold: 25  Epoch: 163  Training loss = 3.9416  Validation loss = 2.5262  \n",
      "\n",
      "Fold: 25  Epoch: 164  Training loss = 3.9413  Validation loss = 2.5257  \n",
      "\n",
      "Fold: 25  Epoch: 165  Training loss = 3.9409  Validation loss = 2.5252  \n",
      "\n",
      "Fold: 25  Epoch: 166  Training loss = 3.9406  Validation loss = 2.5247  \n",
      "\n",
      "Fold: 25  Epoch: 167  Training loss = 3.9403  Validation loss = 2.5244  \n",
      "\n",
      "Fold: 25  Epoch: 168  Training loss = 3.9401  Validation loss = 2.5241  \n",
      "\n",
      "Fold: 25  Epoch: 169  Training loss = 3.9398  Validation loss = 2.5236  \n",
      "\n",
      "Fold: 25  Epoch: 170  Training loss = 3.9394  Validation loss = 2.5231  \n",
      "\n",
      "Fold: 25  Epoch: 171  Training loss = 3.9391  Validation loss = 2.5227  \n",
      "\n",
      "Fold: 25  Epoch: 172  Training loss = 3.9388  Validation loss = 2.5223  \n",
      "\n",
      "Fold: 25  Epoch: 173  Training loss = 3.9386  Validation loss = 2.5220  \n",
      "\n",
      "Fold: 25  Epoch: 174  Training loss = 3.9384  Validation loss = 2.5217  \n",
      "\n",
      "Fold: 25  Epoch: 175  Training loss = 3.9382  Validation loss = 2.5214  \n",
      "\n",
      "Fold: 25  Epoch: 176  Training loss = 3.9379  Validation loss = 2.5211  \n",
      "\n",
      "Fold: 25  Epoch: 177  Training loss = 3.9378  Validation loss = 2.5208  \n",
      "\n",
      "Fold: 25  Epoch: 178  Training loss = 3.9375  Validation loss = 2.5205  \n",
      "\n",
      "Fold: 25  Epoch: 179  Training loss = 3.9373  Validation loss = 2.5201  \n",
      "\n",
      "Fold: 25  Epoch: 180  Training loss = 3.9370  Validation loss = 2.5196  \n",
      "\n",
      "Fold: 25  Epoch: 181  Training loss = 3.9366  Validation loss = 2.5191  \n",
      "\n",
      "Fold: 25  Epoch: 182  Training loss = 3.9363  Validation loss = 2.5187  \n",
      "\n",
      "Fold: 25  Epoch: 183  Training loss = 3.9360  Validation loss = 2.5183  \n",
      "\n",
      "Fold: 25  Epoch: 184  Training loss = 3.9358  Validation loss = 2.5179  \n",
      "\n",
      "Fold: 25  Epoch: 185  Training loss = 3.9355  Validation loss = 2.5176  \n",
      "\n",
      "Fold: 25  Epoch: 186  Training loss = 3.9352  Validation loss = 2.5171  \n",
      "\n",
      "Fold: 25  Epoch: 187  Training loss = 3.9349  Validation loss = 2.5167  \n",
      "\n",
      "Fold: 25  Epoch: 188  Training loss = 3.9347  Validation loss = 2.5164  \n",
      "\n",
      "Fold: 25  Epoch: 189  Training loss = 3.9343  Validation loss = 2.5159  \n",
      "\n",
      "Fold: 25  Epoch: 190  Training loss = 3.9340  Validation loss = 2.5154  \n",
      "\n",
      "Fold: 25  Epoch: 191  Training loss = 3.9337  Validation loss = 2.5151  \n",
      "\n",
      "Fold: 25  Epoch: 192  Training loss = 3.9335  Validation loss = 2.5147  \n",
      "\n",
      "Fold: 25  Epoch: 193  Training loss = 3.9332  Validation loss = 2.5143  \n",
      "\n",
      "Fold: 25  Epoch: 194  Training loss = 3.9330  Validation loss = 2.5140  \n",
      "\n",
      "Fold: 25  Epoch: 195  Training loss = 3.9327  Validation loss = 2.5136  \n",
      "\n",
      "Fold: 25  Epoch: 196  Training loss = 3.9324  Validation loss = 2.5131  \n",
      "\n",
      "Fold: 25  Epoch: 197  Training loss = 3.9321  Validation loss = 2.5127  \n",
      "\n",
      "Fold: 25  Epoch: 198  Training loss = 3.9318  Validation loss = 2.5124  \n",
      "\n",
      "Fold: 25  Epoch: 199  Training loss = 3.9317  Validation loss = 2.5121  \n",
      "\n",
      "Fold: 25  Epoch: 200  Training loss = 3.9314  Validation loss = 2.5117  \n",
      "\n",
      "Fold: 25  Epoch: 201  Training loss = 3.9312  Validation loss = 2.5114  \n",
      "\n",
      "Fold: 25  Epoch: 202  Training loss = 3.9310  Validation loss = 2.5111  \n",
      "\n",
      "Fold: 25  Epoch: 203  Training loss = 3.9307  Validation loss = 2.5108  \n",
      "\n",
      "Fold: 25  Epoch: 204  Training loss = 3.9304  Validation loss = 2.5103  \n",
      "\n",
      "Fold: 25  Epoch: 205  Training loss = 3.9301  Validation loss = 2.5100  \n",
      "\n",
      "Fold: 25  Epoch: 206  Training loss = 3.9299  Validation loss = 2.5096  \n",
      "\n",
      "Fold: 25  Epoch: 207  Training loss = 3.9297  Validation loss = 2.5093  \n",
      "\n",
      "Fold: 25  Epoch: 208  Training loss = 3.9295  Validation loss = 2.5089  \n",
      "\n",
      "Fold: 25  Epoch: 209  Training loss = 3.9292  Validation loss = 2.5085  \n",
      "\n",
      "Fold: 25  Epoch: 210  Training loss = 3.9288  Validation loss = 2.5079  \n",
      "\n",
      "Fold: 25  Epoch: 211  Training loss = 3.9285  Validation loss = 2.5076  \n",
      "\n",
      "Fold: 25  Epoch: 212  Training loss = 3.9283  Validation loss = 2.5073  \n",
      "\n",
      "Fold: 25  Epoch: 213  Training loss = 3.9280  Validation loss = 2.5068  \n",
      "\n",
      "Fold: 25  Epoch: 214  Training loss = 3.9278  Validation loss = 2.5065  \n",
      "\n",
      "Fold: 25  Epoch: 215  Training loss = 3.9274  Validation loss = 2.5060  \n",
      "\n",
      "Fold: 25  Epoch: 216  Training loss = 3.9271  Validation loss = 2.5055  \n",
      "\n",
      "Fold: 25  Epoch: 217  Training loss = 3.9268  Validation loss = 2.5051  \n",
      "\n",
      "Fold: 25  Epoch: 218  Training loss = 3.9266  Validation loss = 2.5048  \n",
      "\n",
      "Fold: 25  Epoch: 219  Training loss = 3.9263  Validation loss = 2.5044  \n",
      "\n",
      "Fold: 25  Epoch: 220  Training loss = 3.9260  Validation loss = 2.5040  \n",
      "\n",
      "Fold: 25  Epoch: 221  Training loss = 3.9258  Validation loss = 2.5036  \n",
      "\n",
      "Fold: 25  Epoch: 222  Training loss = 3.9255  Validation loss = 2.5032  \n",
      "\n",
      "Fold: 25  Epoch: 223  Training loss = 3.9253  Validation loss = 2.5029  \n",
      "\n",
      "Fold: 25  Epoch: 224  Training loss = 3.9250  Validation loss = 2.5025  \n",
      "\n",
      "Fold: 25  Epoch: 225  Training loss = 3.9246  Validation loss = 2.5019  \n",
      "\n",
      "Fold: 25  Epoch: 226  Training loss = 3.9244  Validation loss = 2.5016  \n",
      "\n",
      "Fold: 25  Epoch: 227  Training loss = 3.9242  Validation loss = 2.5013  \n",
      "\n",
      "Fold: 25  Epoch: 228  Training loss = 3.9240  Validation loss = 2.5010  \n",
      "\n",
      "Fold: 25  Epoch: 229  Training loss = 3.9238  Validation loss = 2.5007  \n",
      "\n",
      "Fold: 25  Epoch: 230  Training loss = 3.9235  Validation loss = 2.5003  \n",
      "\n",
      "Fold: 25  Epoch: 231  Training loss = 3.9233  Validation loss = 2.5000  \n",
      "\n",
      "Fold: 25  Epoch: 232  Training loss = 3.9229  Validation loss = 2.4993  \n",
      "\n",
      "Fold: 25  Epoch: 233  Training loss = 3.9227  Validation loss = 2.4990  \n",
      "\n",
      "Fold: 25  Epoch: 234  Training loss = 3.9225  Validation loss = 2.4988  \n",
      "\n",
      "Fold: 25  Epoch: 235  Training loss = 3.9222  Validation loss = 2.4984  \n",
      "\n",
      "Fold: 25  Epoch: 236  Training loss = 3.9220  Validation loss = 2.4981  \n",
      "\n",
      "Fold: 25  Epoch: 237  Training loss = 3.9217  Validation loss = 2.4977  \n",
      "\n",
      "Fold: 25  Epoch: 238  Training loss = 3.9213  Validation loss = 2.4972  \n",
      "\n",
      "Fold: 25  Epoch: 239  Training loss = 3.9211  Validation loss = 2.4968  \n",
      "\n",
      "Fold: 25  Epoch: 240  Training loss = 3.9208  Validation loss = 2.4964  \n",
      "\n",
      "Fold: 25  Epoch: 241  Training loss = 3.9206  Validation loss = 2.4960  \n",
      "\n",
      "Fold: 25  Epoch: 242  Training loss = 3.9204  Validation loss = 2.4958  \n",
      "\n",
      "Fold: 25  Epoch: 243  Training loss = 3.9201  Validation loss = 2.4954  \n",
      "\n",
      "Fold: 25  Epoch: 244  Training loss = 3.9199  Validation loss = 2.4951  \n",
      "\n",
      "Fold: 25  Epoch: 245  Training loss = 3.9196  Validation loss = 2.4946  \n",
      "\n",
      "Fold: 25  Epoch: 246  Training loss = 3.9193  Validation loss = 2.4942  \n",
      "\n",
      "Fold: 25  Epoch: 247  Training loss = 3.9191  Validation loss = 2.4938  \n",
      "\n",
      "Fold: 25  Epoch: 248  Training loss = 3.9188  Validation loss = 2.4934  \n",
      "\n",
      "Fold: 25  Epoch: 249  Training loss = 3.9185  Validation loss = 2.4931  \n",
      "\n",
      "Fold: 25  Epoch: 250  Training loss = 3.9183  Validation loss = 2.4928  \n",
      "\n",
      "Fold: 25  Epoch: 251  Training loss = 3.9181  Validation loss = 2.4925  \n",
      "\n",
      "Fold: 25  Epoch: 252  Training loss = 3.9179  Validation loss = 2.4922  \n",
      "\n",
      "Fold: 25  Epoch: 253  Training loss = 3.9176  Validation loss = 2.4918  \n",
      "\n",
      "Fold: 25  Epoch: 254  Training loss = 3.9173  Validation loss = 2.4913  \n",
      "\n",
      "Fold: 25  Epoch: 255  Training loss = 3.9169  Validation loss = 2.4909  \n",
      "\n",
      "Fold: 25  Epoch: 256  Training loss = 3.9167  Validation loss = 2.4905  \n",
      "\n",
      "Fold: 25  Epoch: 257  Training loss = 3.9165  Validation loss = 2.4902  \n",
      "\n",
      "Fold: 25  Epoch: 258  Training loss = 3.9162  Validation loss = 2.4898  \n",
      "\n",
      "Fold: 25  Epoch: 259  Training loss = 3.9159  Validation loss = 2.4894  \n",
      "\n",
      "Fold: 25  Epoch: 260  Training loss = 3.9156  Validation loss = 2.4890  \n",
      "\n",
      "Fold: 25  Epoch: 261  Training loss = 3.9153  Validation loss = 2.4886  \n",
      "\n",
      "Fold: 25  Epoch: 262  Training loss = 3.9151  Validation loss = 2.4883  \n",
      "\n",
      "Fold: 25  Epoch: 263  Training loss = 3.9148  Validation loss = 2.4879  \n",
      "\n",
      "Fold: 25  Epoch: 264  Training loss = 3.9146  Validation loss = 2.4875  \n",
      "\n",
      "Fold: 25  Epoch: 265  Training loss = 3.9143  Validation loss = 2.4871  \n",
      "\n",
      "Fold: 25  Epoch: 266  Training loss = 3.9141  Validation loss = 2.4867  \n",
      "\n",
      "Fold: 25  Epoch: 267  Training loss = 3.9138  Validation loss = 2.4863  \n",
      "\n",
      "Fold: 25  Epoch: 268  Training loss = 3.9136  Validation loss = 2.4860  \n",
      "\n",
      "Fold: 25  Epoch: 269  Training loss = 3.9134  Validation loss = 2.4857  \n",
      "\n",
      "Fold: 25  Epoch: 270  Training loss = 3.9132  Validation loss = 2.4855  \n",
      "\n",
      "Fold: 25  Epoch: 271  Training loss = 3.9129  Validation loss = 2.4851  \n",
      "\n",
      "Fold: 25  Epoch: 272  Training loss = 3.9127  Validation loss = 2.4848  \n",
      "\n",
      "Fold: 25  Epoch: 273  Training loss = 3.9125  Validation loss = 2.4844  \n",
      "\n",
      "Fold: 25  Epoch: 274  Training loss = 3.9122  Validation loss = 2.4840  \n",
      "\n",
      "Fold: 25  Epoch: 275  Training loss = 3.9119  Validation loss = 2.4836  \n",
      "\n",
      "Fold: 25  Epoch: 276  Training loss = 3.9115  Validation loss = 2.4831  \n",
      "\n",
      "Fold: 25  Epoch: 277  Training loss = 3.9113  Validation loss = 2.4828  \n",
      "\n",
      "Fold: 25  Epoch: 278  Training loss = 3.9110  Validation loss = 2.4824  \n",
      "\n",
      "Fold: 25  Epoch: 279  Training loss = 3.9108  Validation loss = 2.4820  \n",
      "\n",
      "Fold: 25  Epoch: 280  Training loss = 3.9104  Validation loss = 2.4815  \n",
      "\n",
      "Fold: 25  Epoch: 281  Training loss = 3.9102  Validation loss = 2.4812  \n",
      "\n",
      "Fold: 25  Epoch: 282  Training loss = 3.9099  Validation loss = 2.4807  \n",
      "\n",
      "Fold: 25  Epoch: 283  Training loss = 3.9096  Validation loss = 2.4803  \n",
      "\n",
      "Fold: 25  Epoch: 284  Training loss = 3.9094  Validation loss = 2.4800  \n",
      "\n",
      "Fold: 25  Epoch: 285  Training loss = 3.9091  Validation loss = 2.4796  \n",
      "\n",
      "Fold: 25  Epoch: 286  Training loss = 3.9088  Validation loss = 2.4792  \n",
      "\n",
      "Fold: 25  Epoch: 287  Training loss = 3.9086  Validation loss = 2.4789  \n",
      "\n",
      "Fold: 25  Epoch: 288  Training loss = 3.9084  Validation loss = 2.4786  \n",
      "\n",
      "Fold: 25  Epoch: 289  Training loss = 3.9082  Validation loss = 2.4782  \n",
      "\n",
      "Fold: 25  Epoch: 290  Training loss = 3.9080  Validation loss = 2.4780  \n",
      "\n",
      "Fold: 25  Epoch: 291  Training loss = 3.9078  Validation loss = 2.4776  \n",
      "\n",
      "Fold: 25  Epoch: 292  Training loss = 3.9075  Validation loss = 2.4773  \n",
      "\n",
      "Fold: 25  Epoch: 293  Training loss = 3.9073  Validation loss = 2.4770  \n",
      "\n",
      "Fold: 25  Epoch: 294  Training loss = 3.9071  Validation loss = 2.4767  \n",
      "\n",
      "Fold: 25  Epoch: 295  Training loss = 3.9068  Validation loss = 2.4763  \n",
      "\n",
      "Fold: 25  Epoch: 296  Training loss = 3.9066  Validation loss = 2.4760  \n",
      "\n",
      "Fold: 25  Epoch: 297  Training loss = 3.9064  Validation loss = 2.4757  \n",
      "\n",
      "Fold: 25  Epoch: 298  Training loss = 3.9062  Validation loss = 2.4754  \n",
      "\n",
      "Fold: 25  Epoch: 299  Training loss = 3.9059  Validation loss = 2.4751  \n",
      "\n",
      "Fold: 25  Epoch: 300  Training loss = 3.9058  Validation loss = 2.4748  \n",
      "\n",
      "Fold: 25  Epoch: 301  Training loss = 3.9054  Validation loss = 2.4743  \n",
      "\n",
      "Fold: 25  Epoch: 302  Training loss = 3.9051  Validation loss = 2.4739  \n",
      "\n",
      "Fold: 25  Epoch: 303  Training loss = 3.9049  Validation loss = 2.4736  \n",
      "\n",
      "Fold: 25  Epoch: 304  Training loss = 3.9046  Validation loss = 2.4731  \n",
      "\n",
      "Fold: 25  Epoch: 305  Training loss = 3.9043  Validation loss = 2.4727  \n",
      "\n",
      "Fold: 25  Epoch: 306  Training loss = 3.9040  Validation loss = 2.4722  \n",
      "\n",
      "Fold: 25  Epoch: 307  Training loss = 3.9037  Validation loss = 2.4717  \n",
      "\n",
      "Fold: 25  Epoch: 308  Training loss = 3.9035  Validation loss = 2.4714  \n",
      "\n",
      "Fold: 25  Epoch: 309  Training loss = 3.9033  Validation loss = 2.4710  \n",
      "\n",
      "Fold: 25  Epoch: 310  Training loss = 3.9030  Validation loss = 2.4707  \n",
      "\n",
      "Fold: 25  Epoch: 311  Training loss = 3.9027  Validation loss = 2.4702  \n",
      "\n",
      "Fold: 25  Epoch: 312  Training loss = 3.9025  Validation loss = 2.4698  \n",
      "\n",
      "Fold: 25  Epoch: 313  Training loss = 3.9022  Validation loss = 2.4694  \n",
      "\n",
      "Fold: 25  Epoch: 314  Training loss = 3.9019  Validation loss = 2.4691  \n",
      "\n",
      "Fold: 25  Epoch: 315  Training loss = 3.9017  Validation loss = 2.4687  \n",
      "\n",
      "Fold: 25  Epoch: 316  Training loss = 3.9014  Validation loss = 2.4683  \n",
      "\n",
      "Fold: 25  Epoch: 317  Training loss = 3.9010  Validation loss = 2.4678  \n",
      "\n",
      "Fold: 25  Epoch: 318  Training loss = 3.9008  Validation loss = 2.4675  \n",
      "\n",
      "Fold: 25  Epoch: 319  Training loss = 3.9005  Validation loss = 2.4671  \n",
      "\n",
      "Fold: 25  Epoch: 320  Training loss = 3.9003  Validation loss = 2.4667  \n",
      "\n",
      "Fold: 25  Epoch: 321  Training loss = 3.8999  Validation loss = 2.4662  \n",
      "\n",
      "Fold: 25  Epoch: 322  Training loss = 3.8997  Validation loss = 2.4659  \n",
      "\n",
      "Fold: 25  Epoch: 323  Training loss = 3.8993  Validation loss = 2.4654  \n",
      "\n",
      "Fold: 25  Epoch: 324  Training loss = 3.8991  Validation loss = 2.4650  \n",
      "\n",
      "Fold: 25  Epoch: 325  Training loss = 3.8988  Validation loss = 2.4646  \n",
      "\n",
      "Fold: 25  Epoch: 326  Training loss = 3.8985  Validation loss = 2.4641  \n",
      "\n",
      "Fold: 25  Epoch: 327  Training loss = 3.8982  Validation loss = 2.4638  \n",
      "\n",
      "Fold: 25  Epoch: 328  Training loss = 3.8979  Validation loss = 2.4634  \n",
      "\n",
      "Fold: 25  Epoch: 329  Training loss = 3.8978  Validation loss = 2.4633  \n",
      "\n",
      "Fold: 25  Epoch: 330  Training loss = 3.8976  Validation loss = 2.4629  \n",
      "\n",
      "Fold: 25  Epoch: 331  Training loss = 3.8973  Validation loss = 2.4626  \n",
      "\n",
      "Fold: 25  Epoch: 332  Training loss = 3.8971  Validation loss = 2.4623  \n",
      "\n",
      "Fold: 25  Epoch: 333  Training loss = 3.8968  Validation loss = 2.4619  \n",
      "\n",
      "Fold: 25  Epoch: 334  Training loss = 3.8965  Validation loss = 2.4614  \n",
      "\n",
      "Fold: 25  Epoch: 335  Training loss = 3.8963  Validation loss = 2.4611  \n",
      "\n",
      "Fold: 25  Epoch: 336  Training loss = 3.8961  Validation loss = 2.4607  \n",
      "\n",
      "Fold: 25  Epoch: 337  Training loss = 3.8958  Validation loss = 2.4604  \n",
      "\n",
      "Fold: 25  Epoch: 338  Training loss = 3.8956  Validation loss = 2.4601  \n",
      "\n",
      "Fold: 25  Epoch: 339  Training loss = 3.8954  Validation loss = 2.4598  \n",
      "\n",
      "Fold: 25  Epoch: 340  Training loss = 3.8951  Validation loss = 2.4593  \n",
      "\n",
      "Fold: 25  Epoch: 341  Training loss = 3.8947  Validation loss = 2.4588  \n",
      "\n",
      "Fold: 25  Epoch: 342  Training loss = 3.8945  Validation loss = 2.4585  \n",
      "\n",
      "Fold: 25  Epoch: 343  Training loss = 3.8943  Validation loss = 2.4581  \n",
      "\n",
      "Fold: 25  Epoch: 344  Training loss = 3.8941  Validation loss = 2.4578  \n",
      "\n",
      "Fold: 25  Epoch: 345  Training loss = 3.8939  Validation loss = 2.4575  \n",
      "\n",
      "Fold: 25  Epoch: 346  Training loss = 3.8936  Validation loss = 2.4572  \n",
      "\n",
      "Fold: 25  Epoch: 347  Training loss = 3.8934  Validation loss = 2.4570  \n",
      "\n",
      "Fold: 25  Epoch: 348  Training loss = 3.8932  Validation loss = 2.4566  \n",
      "\n",
      "Fold: 25  Epoch: 349  Training loss = 3.8930  Validation loss = 2.4563  \n",
      "\n",
      "Fold: 25  Epoch: 350  Training loss = 3.8927  Validation loss = 2.4559  \n",
      "\n",
      "Fold: 25  Epoch: 351  Training loss = 3.8925  Validation loss = 2.4556  \n",
      "\n",
      "Fold: 25  Epoch: 352  Training loss = 3.8922  Validation loss = 2.4552  \n",
      "\n",
      "Fold: 25  Epoch: 353  Training loss = 3.8920  Validation loss = 2.4549  \n",
      "\n",
      "Fold: 25  Epoch: 354  Training loss = 3.8918  Validation loss = 2.4546  \n",
      "\n",
      "Fold: 25  Epoch: 355  Training loss = 3.8914  Validation loss = 2.4541  \n",
      "\n",
      "Fold: 25  Epoch: 356  Training loss = 3.8912  Validation loss = 2.4538  \n",
      "\n",
      "Fold: 25  Epoch: 357  Training loss = 3.8910  Validation loss = 2.4535  \n",
      "\n",
      "Fold: 25  Epoch: 358  Training loss = 3.8908  Validation loss = 2.4533  \n",
      "\n",
      "Fold: 25  Epoch: 359  Training loss = 3.8905  Validation loss = 2.4528  \n",
      "\n",
      "Fold: 25  Epoch: 360  Training loss = 3.8903  Validation loss = 2.4525  \n",
      "\n",
      "Fold: 25  Epoch: 361  Training loss = 3.8901  Validation loss = 2.4522  \n",
      "\n",
      "Fold: 25  Epoch: 362  Training loss = 3.8897  Validation loss = 2.4517  \n",
      "\n",
      "Fold: 25  Epoch: 363  Training loss = 3.8894  Validation loss = 2.4512  \n",
      "\n",
      "Fold: 25  Epoch: 364  Training loss = 3.8891  Validation loss = 2.4507  \n",
      "\n",
      "Fold: 25  Epoch: 365  Training loss = 3.8889  Validation loss = 2.4504  \n",
      "\n",
      "Fold: 25  Epoch: 366  Training loss = 3.8886  Validation loss = 2.4500  \n",
      "\n",
      "Fold: 25  Epoch: 367  Training loss = 3.8882  Validation loss = 2.4495  \n",
      "\n",
      "Fold: 25  Epoch: 368  Training loss = 3.8879  Validation loss = 2.4490  \n",
      "\n",
      "Fold: 25  Epoch: 369  Training loss = 3.8876  Validation loss = 2.4486  \n",
      "\n",
      "Fold: 25  Epoch: 370  Training loss = 3.8875  Validation loss = 2.4484  \n",
      "\n",
      "Fold: 25  Epoch: 371  Training loss = 3.8872  Validation loss = 2.4479  \n",
      "\n",
      "Fold: 25  Epoch: 372  Training loss = 3.8870  Validation loss = 2.4476  \n",
      "\n",
      "Fold: 25  Epoch: 373  Training loss = 3.8868  Validation loss = 2.4473  \n",
      "\n",
      "Fold: 25  Epoch: 374  Training loss = 3.8864  Validation loss = 2.4468  \n",
      "\n",
      "Fold: 25  Epoch: 375  Training loss = 3.8861  Validation loss = 2.4463  \n",
      "\n",
      "Fold: 25  Epoch: 376  Training loss = 3.8858  Validation loss = 2.4459  \n",
      "\n",
      "Fold: 25  Epoch: 377  Training loss = 3.8856  Validation loss = 2.4456  \n",
      "\n",
      "Fold: 25  Epoch: 378  Training loss = 3.8853  Validation loss = 2.4452  \n",
      "\n",
      "Fold: 25  Epoch: 379  Training loss = 3.8851  Validation loss = 2.4449  \n",
      "\n",
      "Fold: 25  Epoch: 380  Training loss = 3.8848  Validation loss = 2.4444  \n",
      "\n",
      "Fold: 25  Epoch: 381  Training loss = 3.8846  Validation loss = 2.4441  \n",
      "\n",
      "Fold: 25  Epoch: 382  Training loss = 3.8842  Validation loss = 2.4437  \n",
      "\n",
      "Fold: 25  Epoch: 383  Training loss = 3.8839  Validation loss = 2.4432  \n",
      "\n",
      "Fold: 25  Epoch: 384  Training loss = 3.8837  Validation loss = 2.4428  \n",
      "\n",
      "Fold: 25  Epoch: 385  Training loss = 3.8834  Validation loss = 2.4424  \n",
      "\n",
      "Fold: 25  Epoch: 386  Training loss = 3.8832  Validation loss = 2.4422  \n",
      "\n",
      "Fold: 25  Epoch: 387  Training loss = 3.8829  Validation loss = 2.4418  \n",
      "\n",
      "Fold: 25  Epoch: 388  Training loss = 3.8827  Validation loss = 2.4415  \n",
      "\n",
      "Fold: 25  Epoch: 389  Training loss = 3.8825  Validation loss = 2.4412  \n",
      "\n",
      "Fold: 25  Epoch: 390  Training loss = 3.8823  Validation loss = 2.4408  \n",
      "\n",
      "Fold: 25  Epoch: 391  Training loss = 3.8820  Validation loss = 2.4404  \n",
      "\n",
      "Fold: 25  Epoch: 392  Training loss = 3.8816  Validation loss = 2.4398  \n",
      "\n",
      "Fold: 25  Epoch: 393  Training loss = 3.8813  Validation loss = 2.4394  \n",
      "\n",
      "Fold: 25  Epoch: 394  Training loss = 3.8811  Validation loss = 2.4391  \n",
      "\n",
      "Fold: 25  Epoch: 395  Training loss = 3.8809  Validation loss = 2.4389  \n",
      "\n",
      "Fold: 25  Epoch: 396  Training loss = 3.8806  Validation loss = 2.4385  \n",
      "\n",
      "Fold: 25  Epoch: 397  Training loss = 3.8803  Validation loss = 2.4381  \n",
      "\n",
      "Fold: 25  Epoch: 398  Training loss = 3.8800  Validation loss = 2.4376  \n",
      "\n",
      "Fold: 25  Epoch: 399  Training loss = 3.8797  Validation loss = 2.4372  \n",
      "\n",
      "Fold: 25  Epoch: 400  Training loss = 3.8795  Validation loss = 2.4369  \n",
      "\n",
      "Fold: 25  Epoch: 401  Training loss = 3.8793  Validation loss = 2.4365  \n",
      "\n",
      "Fold: 25  Epoch: 402  Training loss = 3.8791  Validation loss = 2.4362  \n",
      "\n",
      "Fold: 25  Epoch: 403  Training loss = 3.8787  Validation loss = 2.4358  \n",
      "\n",
      "Fold: 25  Epoch: 404  Training loss = 3.8786  Validation loss = 2.4355  \n",
      "\n",
      "Fold: 25  Epoch: 405  Training loss = 3.8784  Validation loss = 2.4352  \n",
      "\n",
      "Fold: 25  Epoch: 406  Training loss = 3.8780  Validation loss = 2.4347  \n",
      "\n",
      "Fold: 25  Epoch: 407  Training loss = 3.8778  Validation loss = 2.4344  \n",
      "\n",
      "Fold: 25  Epoch: 408  Training loss = 3.8776  Validation loss = 2.4341  \n",
      "\n",
      "Fold: 25  Epoch: 409  Training loss = 3.8775  Validation loss = 2.4339  \n",
      "\n",
      "Fold: 25  Epoch: 410  Training loss = 3.8773  Validation loss = 2.4336  \n",
      "\n",
      "Fold: 25  Epoch: 411  Training loss = 3.8770  Validation loss = 2.4333  \n",
      "\n",
      "Fold: 25  Epoch: 412  Training loss = 3.8768  Validation loss = 2.4329  \n",
      "\n",
      "Fold: 25  Epoch: 413  Training loss = 3.8765  Validation loss = 2.4326  \n",
      "\n",
      "Fold: 25  Epoch: 414  Training loss = 3.8763  Validation loss = 2.4322  \n",
      "\n",
      "Fold: 25  Epoch: 415  Training loss = 3.8760  Validation loss = 2.4317  \n",
      "\n",
      "Fold: 25  Epoch: 416  Training loss = 3.8758  Validation loss = 2.4314  \n",
      "\n",
      "Fold: 25  Epoch: 417  Training loss = 3.8755  Validation loss = 2.4310  \n",
      "\n",
      "Fold: 25  Epoch: 418  Training loss = 3.8753  Validation loss = 2.4306  \n",
      "\n",
      "Fold: 25  Epoch: 419  Training loss = 3.8750  Validation loss = 2.4302  \n",
      "\n",
      "Fold: 25  Epoch: 420  Training loss = 3.8747  Validation loss = 2.4298  \n",
      "\n",
      "Fold: 25  Epoch: 421  Training loss = 3.8745  Validation loss = 2.4295  \n",
      "\n",
      "Fold: 25  Epoch: 422  Training loss = 3.8743  Validation loss = 2.4292  \n",
      "\n",
      "Fold: 25  Epoch: 423  Training loss = 3.8741  Validation loss = 2.4290  \n",
      "\n",
      "Fold: 25  Epoch: 424  Training loss = 3.8739  Validation loss = 2.4286  \n",
      "\n",
      "Fold: 25  Epoch: 425  Training loss = 3.8736  Validation loss = 2.4283  \n",
      "\n",
      "Fold: 25  Epoch: 426  Training loss = 3.8734  Validation loss = 2.4280  \n",
      "\n",
      "Fold: 25  Epoch: 427  Training loss = 3.8733  Validation loss = 2.4278  \n",
      "\n",
      "Fold: 25  Epoch: 428  Training loss = 3.8730  Validation loss = 2.4274  \n",
      "\n",
      "Fold: 25  Epoch: 429  Training loss = 3.8727  Validation loss = 2.4269  \n",
      "\n",
      "Fold: 25  Epoch: 430  Training loss = 3.8725  Validation loss = 2.4266  \n",
      "\n",
      "Fold: 25  Epoch: 431  Training loss = 3.8722  Validation loss = 2.4262  \n",
      "\n",
      "Fold: 25  Epoch: 432  Training loss = 3.8718  Validation loss = 2.4257  \n",
      "\n",
      "Fold: 25  Epoch: 433  Training loss = 3.8716  Validation loss = 2.4253  \n",
      "\n",
      "Fold: 25  Epoch: 434  Training loss = 3.8712  Validation loss = 2.4248  \n",
      "\n",
      "Fold: 25  Epoch: 435  Training loss = 3.8710  Validation loss = 2.4245  \n",
      "\n",
      "Fold: 25  Epoch: 436  Training loss = 3.8709  Validation loss = 2.4242  \n",
      "\n",
      "Fold: 25  Epoch: 437  Training loss = 3.8707  Validation loss = 2.4240  \n",
      "\n",
      "Fold: 25  Epoch: 438  Training loss = 3.8706  Validation loss = 2.4237  \n",
      "\n",
      "Fold: 25  Epoch: 439  Training loss = 3.8703  Validation loss = 2.4233  \n",
      "\n",
      "Fold: 25  Epoch: 440  Training loss = 3.8700  Validation loss = 2.4229  \n",
      "\n",
      "Fold: 25  Epoch: 441  Training loss = 3.8698  Validation loss = 2.4226  \n",
      "\n",
      "Fold: 25  Epoch: 442  Training loss = 3.8695  Validation loss = 2.4223  \n",
      "\n",
      "Fold: 25  Epoch: 443  Training loss = 3.8692  Validation loss = 2.4218  \n",
      "\n",
      "Fold: 25  Epoch: 444  Training loss = 3.8690  Validation loss = 2.4214  \n",
      "\n",
      "Fold: 25  Epoch: 445  Training loss = 3.8688  Validation loss = 2.4212  \n",
      "\n",
      "Fold: 25  Epoch: 446  Training loss = 3.8686  Validation loss = 2.4209  \n",
      "\n",
      "Fold: 25  Epoch: 447  Training loss = 3.8683  Validation loss = 2.4204  \n",
      "\n",
      "Fold: 25  Epoch: 448  Training loss = 3.8681  Validation loss = 2.4201  \n",
      "\n",
      "Fold: 25  Epoch: 449  Training loss = 3.8679  Validation loss = 2.4199  \n",
      "\n",
      "Fold: 25  Epoch: 450  Training loss = 3.8677  Validation loss = 2.4196  \n",
      "\n",
      "Fold: 25  Epoch: 451  Training loss = 3.8675  Validation loss = 2.4193  \n",
      "\n",
      "Fold: 25  Epoch: 452  Training loss = 3.8672  Validation loss = 2.4189  \n",
      "\n",
      "Fold: 25  Epoch: 453  Training loss = 3.8670  Validation loss = 2.4186  \n",
      "\n",
      "Fold: 25  Epoch: 454  Training loss = 3.8667  Validation loss = 2.4182  \n",
      "\n",
      "Fold: 25  Epoch: 455  Training loss = 3.8665  Validation loss = 2.4180  \n",
      "\n",
      "Fold: 25  Epoch: 456  Training loss = 3.8662  Validation loss = 2.4175  \n",
      "\n",
      "Fold: 25  Epoch: 457  Training loss = 3.8660  Validation loss = 2.4173  \n",
      "\n",
      "Fold: 25  Epoch: 458  Training loss = 3.8657  Validation loss = 2.4169  \n",
      "\n",
      "Fold: 25  Epoch: 459  Training loss = 3.8655  Validation loss = 2.4165  \n",
      "\n",
      "Fold: 25  Epoch: 460  Training loss = 3.8652  Validation loss = 2.4161  \n",
      "\n",
      "Fold: 25  Epoch: 461  Training loss = 3.8650  Validation loss = 2.4158  \n",
      "\n",
      "Fold: 25  Epoch: 462  Training loss = 3.8647  Validation loss = 2.4154  \n",
      "\n",
      "Fold: 25  Epoch: 463  Training loss = 3.8645  Validation loss = 2.4151  \n",
      "\n",
      "Fold: 25  Epoch: 464  Training loss = 3.8642  Validation loss = 2.4148  \n",
      "\n",
      "Fold: 25  Epoch: 465  Training loss = 3.8640  Validation loss = 2.4145  \n",
      "\n",
      "Fold: 25  Epoch: 466  Training loss = 3.8638  Validation loss = 2.4142  \n",
      "\n",
      "Fold: 25  Epoch: 467  Training loss = 3.8636  Validation loss = 2.4139  \n",
      "\n",
      "Fold: 25  Epoch: 468  Training loss = 3.8633  Validation loss = 2.4135  \n",
      "\n",
      "Fold: 25  Epoch: 469  Training loss = 3.8630  Validation loss = 2.4130  \n",
      "\n",
      "Fold: 25  Epoch: 470  Training loss = 3.8628  Validation loss = 2.4128  \n",
      "\n",
      "Fold: 25  Epoch: 471  Training loss = 3.8626  Validation loss = 2.4125  \n",
      "\n",
      "Fold: 25  Epoch: 472  Training loss = 3.8623  Validation loss = 2.4122  \n",
      "\n",
      "Fold: 25  Epoch: 473  Training loss = 3.8620  Validation loss = 2.4117  \n",
      "\n",
      "Fold: 25  Epoch: 474  Training loss = 3.8618  Validation loss = 2.4113  \n",
      "\n",
      "Fold: 25  Epoch: 475  Training loss = 3.8615  Validation loss = 2.4109  \n",
      "\n",
      "Fold: 25  Epoch: 476  Training loss = 3.8613  Validation loss = 2.4106  \n",
      "\n",
      "Fold: 25  Epoch: 477  Training loss = 3.8610  Validation loss = 2.4102  \n",
      "\n",
      "Fold: 25  Epoch: 478  Training loss = 3.8607  Validation loss = 2.4098  \n",
      "\n",
      "Fold: 25  Epoch: 479  Training loss = 3.8605  Validation loss = 2.4096  \n",
      "\n",
      "Fold: 25  Epoch: 480  Training loss = 3.8603  Validation loss = 2.4092  \n",
      "\n",
      "Fold: 25  Epoch: 481  Training loss = 3.8600  Validation loss = 2.4088  \n",
      "\n",
      "Fold: 25  Epoch: 482  Training loss = 3.8598  Validation loss = 2.4085  \n",
      "\n",
      "Fold: 25  Epoch: 483  Training loss = 3.8594  Validation loss = 2.4080  \n",
      "\n",
      "Fold: 25  Epoch: 484  Training loss = 3.8592  Validation loss = 2.4076  \n",
      "\n",
      "Fold: 25  Epoch: 485  Training loss = 3.8590  Validation loss = 2.4073  \n",
      "\n",
      "Fold: 25  Epoch: 486  Training loss = 3.8588  Validation loss = 2.4070  \n",
      "\n",
      "Fold: 25  Epoch: 487  Training loss = 3.8585  Validation loss = 2.4065  \n",
      "\n",
      "Fold: 25  Epoch: 488  Training loss = 3.8581  Validation loss = 2.4061  \n",
      "\n",
      "Fold: 25  Epoch: 489  Training loss = 3.8579  Validation loss = 2.4057  \n",
      "\n",
      "Fold: 25  Epoch: 490  Training loss = 3.8577  Validation loss = 2.4055  \n",
      "\n",
      "Fold: 25  Epoch: 491  Training loss = 3.8575  Validation loss = 2.4053  \n",
      "\n",
      "Fold: 25  Epoch: 492  Training loss = 3.8572  Validation loss = 2.4048  \n",
      "\n",
      "Fold: 25  Epoch: 493  Training loss = 3.8571  Validation loss = 2.4046  \n",
      "\n",
      "Fold: 25  Epoch: 494  Training loss = 3.8568  Validation loss = 2.4042  \n",
      "\n",
      "Fold: 25  Epoch: 495  Training loss = 3.8566  Validation loss = 2.4039  \n",
      "\n",
      "Fold: 25  Epoch: 496  Training loss = 3.8563  Validation loss = 2.4036  \n",
      "\n",
      "Fold: 25  Epoch: 497  Training loss = 3.8561  Validation loss = 2.4032  \n",
      "\n",
      "Fold: 25  Epoch: 498  Training loss = 3.8559  Validation loss = 2.4029  \n",
      "\n",
      "Fold: 25  Epoch: 499  Training loss = 3.8557  Validation loss = 2.4026  \n",
      "\n",
      "Fold: 25  Epoch: 500  Training loss = 3.8554  Validation loss = 2.4022  \n",
      "\n",
      "Check model:  Fold: 25  Optimal epoch: 500  \n",
      "\n",
      "Fold: 26  Epoch: 1  Training loss = 3.5418  Validation loss = 1.5160  \n",
      "\n",
      "Fold: 26  Epoch: 2  Training loss = 3.5415  Validation loss = 1.5164  \n",
      "\n",
      "Fold: 26  Epoch: 3  Training loss = 3.5413  Validation loss = 1.5168  \n",
      "\n",
      "Fold: 26  Epoch: 4  Training loss = 3.5412  Validation loss = 1.5170  \n",
      "\n",
      "Fold: 26  Epoch: 5  Training loss = 3.5410  Validation loss = 1.5175  \n",
      "\n",
      "Fold: 26  Epoch: 6  Training loss = 3.5408  Validation loss = 1.5179  \n",
      "\n",
      "Fold: 26  Epoch: 7  Training loss = 3.5406  Validation loss = 1.5184  \n",
      "\n",
      "Fold: 26  Epoch: 8  Training loss = 3.5404  Validation loss = 1.5188  \n",
      "\n",
      "Fold: 26  Epoch: 9  Training loss = 3.5402  Validation loss = 1.5190  \n",
      "\n",
      "Fold: 26  Epoch: 10  Training loss = 3.5400  Validation loss = 1.5195  \n",
      "\n",
      "Fold: 26  Epoch: 11  Training loss = 3.5398  Validation loss = 1.5199  \n",
      "\n",
      "Check model:  Fold: 26  Optimal epoch: 1  \n",
      "\n",
      "Fold: 27  Epoch: 1  Training loss = 3.3949  Validation loss = 1.3824  \n",
      "\n",
      "Fold: 27  Epoch: 2  Training loss = 3.3948  Validation loss = 1.3825  \n",
      "\n",
      "Fold: 27  Epoch: 3  Training loss = 3.3946  Validation loss = 1.3825  \n",
      "\n",
      "Fold: 27  Epoch: 4  Training loss = 3.3945  Validation loss = 1.3827  \n",
      "\n",
      "Fold: 27  Epoch: 5  Training loss = 3.3944  Validation loss = 1.3828  \n",
      "\n",
      "Fold: 27  Epoch: 6  Training loss = 3.3942  Validation loss = 1.3829  \n",
      "\n",
      "Fold: 27  Epoch: 7  Training loss = 3.3941  Validation loss = 1.3830  \n",
      "\n",
      "Fold: 27  Epoch: 8  Training loss = 3.3940  Validation loss = 1.3831  \n",
      "\n",
      "Fold: 27  Epoch: 9  Training loss = 3.3938  Validation loss = 1.3832  \n",
      "\n",
      "Fold: 27  Epoch: 10  Training loss = 3.3937  Validation loss = 1.3833  \n",
      "\n",
      "Fold: 27  Epoch: 11  Training loss = 3.3936  Validation loss = 1.3833  \n",
      "\n",
      "Check model:  Fold: 27  Optimal epoch: 1  \n",
      "\n",
      "Fold: 28  Epoch: 1  Training loss = 3.3809  Validation loss = 1.7255  \n",
      "\n",
      "Fold: 28  Epoch: 2  Training loss = 3.3807  Validation loss = 1.7257  \n",
      "\n",
      "Fold: 28  Epoch: 3  Training loss = 3.3806  Validation loss = 1.7258  \n",
      "\n",
      "Fold: 28  Epoch: 4  Training loss = 3.3804  Validation loss = 1.7260  \n",
      "\n",
      "Fold: 28  Epoch: 5  Training loss = 3.3803  Validation loss = 1.7262  \n",
      "\n",
      "Fold: 28  Epoch: 6  Training loss = 3.3802  Validation loss = 1.7263  \n",
      "\n",
      "Fold: 28  Epoch: 7  Training loss = 3.3799  Validation loss = 1.7268  \n",
      "\n",
      "Fold: 28  Epoch: 8  Training loss = 3.3797  Validation loss = 1.7269  \n",
      "\n",
      "Fold: 28  Epoch: 9  Training loss = 3.3796  Validation loss = 1.7272  \n",
      "\n",
      "Fold: 28  Epoch: 10  Training loss = 3.3794  Validation loss = 1.7273  \n",
      "\n",
      "Fold: 28  Epoch: 11  Training loss = 3.3793  Validation loss = 1.7274  \n",
      "\n",
      "Check model:  Fold: 28  Optimal epoch: 1  \n",
      "\n",
      "Fold: 29  Epoch: 1  Training loss = 3.3920  Validation loss = 2.0196  \n",
      "\n",
      "Fold: 29  Epoch: 2  Training loss = 3.3918  Validation loss = 2.0197  \n",
      "\n",
      "Fold: 29  Epoch: 3  Training loss = 3.3917  Validation loss = 2.0198  \n",
      "\n",
      "Fold: 29  Epoch: 4  Training loss = 3.3916  Validation loss = 2.0199  \n",
      "\n",
      "Fold: 29  Epoch: 5  Training loss = 3.3915  Validation loss = 2.0200  \n",
      "\n",
      "Fold: 29  Epoch: 6  Training loss = 3.3914  Validation loss = 2.0201  \n",
      "\n",
      "Fold: 29  Epoch: 7  Training loss = 3.3913  Validation loss = 2.0202  \n",
      "\n",
      "Fold: 29  Epoch: 8  Training loss = 3.3912  Validation loss = 2.0202  \n",
      "\n",
      "Fold: 29  Epoch: 9  Training loss = 3.3910  Validation loss = 2.0203  \n",
      "\n",
      "Fold: 29  Epoch: 10  Training loss = 3.3910  Validation loss = 2.0203  \n",
      "\n",
      "Fold: 29  Epoch: 11  Training loss = 3.3909  Validation loss = 2.0204  \n",
      "\n",
      "Check model:  Fold: 29  Optimal epoch: 1  \n",
      "\n",
      "Fold: 30  Epoch: 1  Training loss = 3.3452  Validation loss = 0.6615  \n",
      "\n",
      "Fold: 30  Epoch: 2  Training loss = 3.3451  Validation loss = 0.6615  \n",
      "\n",
      "Fold: 30  Epoch: 3  Training loss = 3.3450  Validation loss = 0.6615  \n",
      "\n",
      "Fold: 30  Epoch: 4  Training loss = 3.3450  Validation loss = 0.6615  \n",
      "\n",
      "Fold: 30  Epoch: 5  Training loss = 3.3448  Validation loss = 0.6614  \n",
      "\n",
      "Fold: 30  Epoch: 6  Training loss = 3.3448  Validation loss = 0.6614  \n",
      "\n",
      "Fold: 30  Epoch: 7  Training loss = 3.3447  Validation loss = 0.6614  \n",
      "\n",
      "Fold: 30  Epoch: 8  Training loss = 3.3446  Validation loss = 0.6614  \n",
      "\n",
      "Fold: 30  Epoch: 9  Training loss = 3.3445  Validation loss = 0.6614  \n",
      "\n",
      "Fold: 30  Epoch: 10  Training loss = 3.3444  Validation loss = 0.6614  \n",
      "\n",
      "Fold: 30  Epoch: 11  Training loss = 3.3443  Validation loss = 0.6614  \n",
      "\n",
      "Fold: 30  Epoch: 12  Training loss = 3.3442  Validation loss = 0.6614  \n",
      "\n",
      "Fold: 30  Epoch: 13  Training loss = 3.3440  Validation loss = 0.6613  \n",
      "\n",
      "Fold: 30  Epoch: 14  Training loss = 3.3440  Validation loss = 0.6613  \n",
      "\n",
      "Fold: 30  Epoch: 15  Training loss = 3.3439  Validation loss = 0.6613  \n",
      "\n",
      "Fold: 30  Epoch: 16  Training loss = 3.3438  Validation loss = 0.6613  \n",
      "\n",
      "Fold: 30  Epoch: 17  Training loss = 3.3437  Validation loss = 0.6613  \n",
      "\n",
      "Fold: 30  Epoch: 18  Training loss = 3.3436  Validation loss = 0.6613  \n",
      "\n",
      "Fold: 30  Epoch: 19  Training loss = 3.3435  Validation loss = 0.6613  \n",
      "\n",
      "Fold: 30  Epoch: 20  Training loss = 3.3434  Validation loss = 0.6613  \n",
      "\n",
      "Fold: 30  Epoch: 21  Training loss = 3.3433  Validation loss = 0.6613  \n",
      "\n",
      "Fold: 30  Epoch: 22  Training loss = 3.3432  Validation loss = 0.6613  \n",
      "\n",
      "Fold: 30  Epoch: 23  Training loss = 3.3431  Validation loss = 0.6613  \n",
      "\n",
      "Fold: 30  Epoch: 24  Training loss = 3.3431  Validation loss = 0.6612  \n",
      "\n",
      "Fold: 30  Epoch: 25  Training loss = 3.3430  Validation loss = 0.6612  \n",
      "\n",
      "Fold: 30  Epoch: 26  Training loss = 3.3429  Validation loss = 0.6612  \n",
      "\n",
      "Fold: 30  Epoch: 27  Training loss = 3.3428  Validation loss = 0.6612  \n",
      "\n",
      "Fold: 30  Epoch: 28  Training loss = 3.3427  Validation loss = 0.6612  \n",
      "\n",
      "Fold: 30  Epoch: 29  Training loss = 3.3426  Validation loss = 0.6612  \n",
      "\n",
      "Fold: 30  Epoch: 30  Training loss = 3.3425  Validation loss = 0.6612  \n",
      "\n",
      "Fold: 30  Epoch: 31  Training loss = 3.3423  Validation loss = 0.6611  \n",
      "\n",
      "Fold: 30  Epoch: 32  Training loss = 3.3423  Validation loss = 0.6611  \n",
      "\n",
      "Fold: 30  Epoch: 33  Training loss = 3.3422  Validation loss = 0.6611  \n",
      "\n",
      "Fold: 30  Epoch: 34  Training loss = 3.3422  Validation loss = 0.6611  \n",
      "\n",
      "Fold: 30  Epoch: 35  Training loss = 3.3420  Validation loss = 0.6611  \n",
      "\n",
      "Fold: 30  Epoch: 36  Training loss = 3.3419  Validation loss = 0.6610  \n",
      "\n",
      "Fold: 30  Epoch: 37  Training loss = 3.3418  Validation loss = 0.6610  \n",
      "\n",
      "Fold: 30  Epoch: 38  Training loss = 3.3418  Validation loss = 0.6610  \n",
      "\n",
      "Fold: 30  Epoch: 39  Training loss = 3.3416  Validation loss = 0.6610  \n",
      "\n",
      "Fold: 30  Epoch: 40  Training loss = 3.3416  Validation loss = 0.6610  \n",
      "\n",
      "Fold: 30  Epoch: 41  Training loss = 3.3415  Validation loss = 0.6610  \n",
      "\n",
      "Fold: 30  Epoch: 42  Training loss = 3.3414  Validation loss = 0.6610  \n",
      "\n",
      "Fold: 30  Epoch: 43  Training loss = 3.3413  Validation loss = 0.6610  \n",
      "\n",
      "Fold: 30  Epoch: 44  Training loss = 3.3412  Validation loss = 0.6610  \n",
      "\n",
      "Fold: 30  Epoch: 45  Training loss = 3.3411  Validation loss = 0.6610  \n",
      "\n",
      "Fold: 30  Epoch: 46  Training loss = 3.3410  Validation loss = 0.6610  \n",
      "\n",
      "Fold: 30  Epoch: 47  Training loss = 3.3410  Validation loss = 0.6610  \n",
      "\n",
      "Fold: 30  Epoch: 48  Training loss = 3.3409  Validation loss = 0.6609  \n",
      "\n",
      "Fold: 30  Epoch: 49  Training loss = 3.3408  Validation loss = 0.6609  \n",
      "\n",
      "Fold: 30  Epoch: 50  Training loss = 3.3408  Validation loss = 0.6609  \n",
      "\n",
      "Fold: 30  Epoch: 51  Training loss = 3.3407  Validation loss = 0.6609  \n",
      "\n",
      "Fold: 30  Epoch: 52  Training loss = 3.3406  Validation loss = 0.6609  \n",
      "\n",
      "Fold: 30  Epoch: 53  Training loss = 3.3406  Validation loss = 0.6609  \n",
      "\n",
      "Fold: 30  Epoch: 54  Training loss = 3.3405  Validation loss = 0.6609  \n",
      "\n",
      "Fold: 30  Epoch: 55  Training loss = 3.3404  Validation loss = 0.6609  \n",
      "\n",
      "Fold: 30  Epoch: 56  Training loss = 3.3404  Validation loss = 0.6609  \n",
      "\n",
      "Fold: 30  Epoch: 57  Training loss = 3.3403  Validation loss = 0.6608  \n",
      "\n",
      "Fold: 30  Epoch: 58  Training loss = 3.3402  Validation loss = 0.6608  \n",
      "\n",
      "Fold: 30  Epoch: 59  Training loss = 3.3401  Validation loss = 0.6608  \n",
      "\n",
      "Fold: 30  Epoch: 60  Training loss = 3.3400  Validation loss = 0.6608  \n",
      "\n",
      "Fold: 30  Epoch: 61  Training loss = 3.3398  Validation loss = 0.6608  \n",
      "\n",
      "Fold: 30  Epoch: 62  Training loss = 3.3397  Validation loss = 0.6608  \n",
      "\n",
      "Fold: 30  Epoch: 63  Training loss = 3.3396  Validation loss = 0.6608  \n",
      "\n",
      "Fold: 30  Epoch: 64  Training loss = 3.3395  Validation loss = 0.6608  \n",
      "\n",
      "Fold: 30  Epoch: 65  Training loss = 3.3395  Validation loss = 0.6608  \n",
      "\n",
      "Fold: 30  Epoch: 66  Training loss = 3.3394  Validation loss = 0.6608  \n",
      "\n",
      "Fold: 30  Epoch: 67  Training loss = 3.3393  Validation loss = 0.6608  \n",
      "\n",
      "Fold: 30  Epoch: 68  Training loss = 3.3392  Validation loss = 0.6608  \n",
      "\n",
      "Fold: 30  Epoch: 69  Training loss = 3.3391  Validation loss = 0.6607  \n",
      "\n",
      "Fold: 30  Epoch: 70  Training loss = 3.3390  Validation loss = 0.6607  \n",
      "\n",
      "Fold: 30  Epoch: 71  Training loss = 3.3389  Validation loss = 0.6607  \n",
      "\n",
      "Fold: 30  Epoch: 72  Training loss = 3.3389  Validation loss = 0.6607  \n",
      "\n",
      "Fold: 30  Epoch: 73  Training loss = 3.3388  Validation loss = 0.6607  \n",
      "\n",
      "Fold: 30  Epoch: 74  Training loss = 3.3387  Validation loss = 0.6607  \n",
      "\n",
      "Fold: 30  Epoch: 75  Training loss = 3.3386  Validation loss = 0.6607  \n",
      "\n",
      "Fold: 30  Epoch: 76  Training loss = 3.3386  Validation loss = 0.6607  \n",
      "\n",
      "Fold: 30  Epoch: 77  Training loss = 3.3384  Validation loss = 0.6607  \n",
      "\n",
      "Fold: 30  Epoch: 78  Training loss = 3.3384  Validation loss = 0.6607  \n",
      "\n",
      "Fold: 30  Epoch: 79  Training loss = 3.3383  Validation loss = 0.6606  \n",
      "\n",
      "Fold: 30  Epoch: 80  Training loss = 3.3382  Validation loss = 0.6606  \n",
      "\n",
      "Fold: 30  Epoch: 81  Training loss = 3.3381  Validation loss = 0.6606  \n",
      "\n",
      "Fold: 30  Epoch: 82  Training loss = 3.3380  Validation loss = 0.6606  \n",
      "\n",
      "Fold: 30  Epoch: 83  Training loss = 3.3379  Validation loss = 0.6606  \n",
      "\n",
      "Fold: 30  Epoch: 84  Training loss = 3.3379  Validation loss = 0.6606  \n",
      "\n",
      "Fold: 30  Epoch: 85  Training loss = 3.3377  Validation loss = 0.6606  \n",
      "\n",
      "Fold: 30  Epoch: 86  Training loss = 3.3376  Validation loss = 0.6606  \n",
      "\n",
      "Fold: 30  Epoch: 87  Training loss = 3.3376  Validation loss = 0.6606  \n",
      "\n",
      "Fold: 30  Epoch: 88  Training loss = 3.3375  Validation loss = 0.6606  \n",
      "\n",
      "Fold: 30  Epoch: 89  Training loss = 3.3374  Validation loss = 0.6606  \n",
      "\n",
      "Fold: 30  Epoch: 90  Training loss = 3.3373  Validation loss = 0.6606  \n",
      "\n",
      "Fold: 30  Epoch: 91  Training loss = 3.3372  Validation loss = 0.6605  \n",
      "\n",
      "Fold: 30  Epoch: 92  Training loss = 3.3371  Validation loss = 0.6605  \n",
      "\n",
      "Fold: 30  Epoch: 93  Training loss = 3.3370  Validation loss = 0.6605  \n",
      "\n",
      "Fold: 30  Epoch: 94  Training loss = 3.3369  Validation loss = 0.6605  \n",
      "\n",
      "Fold: 30  Epoch: 95  Training loss = 3.3368  Validation loss = 0.6605  \n",
      "\n",
      "Fold: 30  Epoch: 96  Training loss = 3.3367  Validation loss = 0.6605  \n",
      "\n",
      "Fold: 30  Epoch: 97  Training loss = 3.3366  Validation loss = 0.6605  \n",
      "\n",
      "Fold: 30  Epoch: 98  Training loss = 3.3365  Validation loss = 0.6605  \n",
      "\n",
      "Fold: 30  Epoch: 99  Training loss = 3.3364  Validation loss = 0.6604  \n",
      "\n",
      "Fold: 30  Epoch: 100  Training loss = 3.3364  Validation loss = 0.6604  \n",
      "\n",
      "Fold: 30  Epoch: 101  Training loss = 3.3363  Validation loss = 0.6604  \n",
      "\n",
      "Fold: 30  Epoch: 102  Training loss = 3.3361  Validation loss = 0.6604  \n",
      "\n",
      "Fold: 30  Epoch: 103  Training loss = 3.3361  Validation loss = 0.6604  \n",
      "\n",
      "Fold: 30  Epoch: 104  Training loss = 3.3360  Validation loss = 0.6604  \n",
      "\n",
      "Fold: 30  Epoch: 105  Training loss = 3.3359  Validation loss = 0.6604  \n",
      "\n",
      "Fold: 30  Epoch: 106  Training loss = 3.3358  Validation loss = 0.6604  \n",
      "\n",
      "Fold: 30  Epoch: 107  Training loss = 3.3357  Validation loss = 0.6604  \n",
      "\n",
      "Fold: 30  Epoch: 108  Training loss = 3.3357  Validation loss = 0.6604  \n",
      "\n",
      "Fold: 30  Epoch: 109  Training loss = 3.3355  Validation loss = 0.6604  \n",
      "\n",
      "Fold: 30  Epoch: 110  Training loss = 3.3355  Validation loss = 0.6604  \n",
      "\n",
      "Fold: 30  Epoch: 111  Training loss = 3.3354  Validation loss = 0.6604  \n",
      "\n",
      "Fold: 30  Epoch: 112  Training loss = 3.3353  Validation loss = 0.6604  \n",
      "\n",
      "Fold: 30  Epoch: 113  Training loss = 3.3353  Validation loss = 0.6604  \n",
      "\n",
      "Fold: 30  Epoch: 114  Training loss = 3.3352  Validation loss = 0.6604  \n",
      "\n",
      "Fold: 30  Epoch: 115  Training loss = 3.3351  Validation loss = 0.6603  \n",
      "\n",
      "Fold: 30  Epoch: 116  Training loss = 3.3351  Validation loss = 0.6604  \n",
      "\n",
      "Fold: 30  Epoch: 117  Training loss = 3.3349  Validation loss = 0.6604  \n",
      "\n",
      "Fold: 30  Epoch: 118  Training loss = 3.3348  Validation loss = 0.6604  \n",
      "\n",
      "Fold: 30  Epoch: 119  Training loss = 3.3348  Validation loss = 0.6604  \n",
      "\n",
      "Fold: 30  Epoch: 120  Training loss = 3.3347  Validation loss = 0.6603  \n",
      "\n",
      "Fold: 30  Epoch: 121  Training loss = 3.3346  Validation loss = 0.6603  \n",
      "\n",
      "Fold: 30  Epoch: 122  Training loss = 3.3346  Validation loss = 0.6603  \n",
      "\n",
      "Fold: 30  Epoch: 123  Training loss = 3.3345  Validation loss = 0.6603  \n",
      "\n",
      "Fold: 30  Epoch: 124  Training loss = 3.3345  Validation loss = 0.6603  \n",
      "\n",
      "Fold: 30  Epoch: 125  Training loss = 3.3344  Validation loss = 0.6603  \n",
      "\n",
      "Fold: 30  Epoch: 126  Training loss = 3.3343  Validation loss = 0.6603  \n",
      "\n",
      "Fold: 30  Epoch: 127  Training loss = 3.3342  Validation loss = 0.6603  \n",
      "\n",
      "Fold: 30  Epoch: 128  Training loss = 3.3342  Validation loss = 0.6603  \n",
      "\n",
      "Fold: 30  Epoch: 129  Training loss = 3.3341  Validation loss = 0.6603  \n",
      "\n",
      "Fold: 30  Epoch: 130  Training loss = 3.3340  Validation loss = 0.6603  \n",
      "\n",
      "Fold: 30  Epoch: 131  Training loss = 3.3339  Validation loss = 0.6603  \n",
      "\n",
      "Fold: 30  Epoch: 132  Training loss = 3.3339  Validation loss = 0.6603  \n",
      "\n",
      "Fold: 30  Epoch: 133  Training loss = 3.3338  Validation loss = 0.6603  \n",
      "\n",
      "Fold: 30  Epoch: 134  Training loss = 3.3337  Validation loss = 0.6603  \n",
      "\n",
      "Fold: 30  Epoch: 135  Training loss = 3.3336  Validation loss = 0.6603  \n",
      "\n",
      "Fold: 30  Epoch: 136  Training loss = 3.3335  Validation loss = 0.6603  \n",
      "\n",
      "Fold: 30  Epoch: 137  Training loss = 3.3334  Validation loss = 0.6603  \n",
      "\n",
      "Fold: 30  Epoch: 138  Training loss = 3.3333  Validation loss = 0.6603  \n",
      "\n",
      "Fold: 30  Epoch: 139  Training loss = 3.3331  Validation loss = 0.6603  \n",
      "\n",
      "Fold: 30  Epoch: 140  Training loss = 3.3330  Validation loss = 0.6603  \n",
      "\n",
      "Fold: 30  Epoch: 141  Training loss = 3.3330  Validation loss = 0.6603  \n",
      "\n",
      "Fold: 30  Epoch: 142  Training loss = 3.3328  Validation loss = 0.6603  \n",
      "\n",
      "Fold: 30  Epoch: 143  Training loss = 3.3328  Validation loss = 0.6603  \n",
      "\n",
      "Check model:  Fold: 30  Optimal epoch: 130  \n",
      "\n",
      "Fold: 31  Epoch: 1  Training loss = 2.9529  Validation loss = 1.3463  \n",
      "\n",
      "Fold: 31  Epoch: 2  Training loss = 2.9528  Validation loss = 1.3463  \n",
      "\n",
      "Fold: 31  Epoch: 3  Training loss = 2.9528  Validation loss = 1.3463  \n",
      "\n",
      "Fold: 31  Epoch: 4  Training loss = 2.9528  Validation loss = 1.3462  \n",
      "\n",
      "Fold: 31  Epoch: 5  Training loss = 2.9527  Validation loss = 1.3459  \n",
      "\n",
      "Fold: 31  Epoch: 6  Training loss = 2.9527  Validation loss = 1.3460  \n",
      "\n",
      "Fold: 31  Epoch: 7  Training loss = 2.9526  Validation loss = 1.3457  \n",
      "\n",
      "Fold: 31  Epoch: 8  Training loss = 2.9526  Validation loss = 1.3457  \n",
      "\n",
      "Fold: 31  Epoch: 9  Training loss = 2.9526  Validation loss = 1.3457  \n",
      "\n",
      "Fold: 31  Epoch: 10  Training loss = 2.9525  Validation loss = 1.3460  \n",
      "\n",
      "Fold: 31  Epoch: 11  Training loss = 2.9524  Validation loss = 1.3460  \n",
      "\n",
      "Fold: 31  Epoch: 12  Training loss = 2.9524  Validation loss = 1.3459  \n",
      "\n",
      "Fold: 31  Epoch: 13  Training loss = 2.9524  Validation loss = 1.3458  \n",
      "\n",
      "Fold: 31  Epoch: 14  Training loss = 2.9523  Validation loss = 1.3458  \n",
      "\n",
      "Fold: 31  Epoch: 15  Training loss = 2.9522  Validation loss = 1.3457  \n",
      "\n",
      "Fold: 31  Epoch: 16  Training loss = 2.9522  Validation loss = 1.3459  \n",
      "\n",
      "Fold: 31  Epoch: 17  Training loss = 2.9521  Validation loss = 1.3459  \n",
      "\n",
      "Fold: 31  Epoch: 18  Training loss = 2.9521  Validation loss = 1.3459  \n",
      "\n",
      "Fold: 31  Epoch: 19  Training loss = 2.9520  Validation loss = 1.3457  \n",
      "\n",
      "Fold: 31  Epoch: 20  Training loss = 2.9520  Validation loss = 1.3455  \n",
      "\n",
      "Fold: 31  Epoch: 21  Training loss = 2.9519  Validation loss = 1.3454  \n",
      "\n",
      "Fold: 31  Epoch: 22  Training loss = 2.9519  Validation loss = 1.3454  \n",
      "\n",
      "Fold: 31  Epoch: 23  Training loss = 2.9518  Validation loss = 1.3453  \n",
      "\n",
      "Fold: 31  Epoch: 24  Training loss = 2.9518  Validation loss = 1.3454  \n",
      "\n",
      "Fold: 31  Epoch: 25  Training loss = 2.9517  Validation loss = 1.3453  \n",
      "\n",
      "Fold: 31  Epoch: 26  Training loss = 2.9517  Validation loss = 1.3452  \n",
      "\n",
      "Fold: 31  Epoch: 27  Training loss = 2.9516  Validation loss = 1.3449  \n",
      "\n",
      "Fold: 31  Epoch: 28  Training loss = 2.9516  Validation loss = 1.3449  \n",
      "\n",
      "Fold: 31  Epoch: 29  Training loss = 2.9515  Validation loss = 1.3449  \n",
      "\n",
      "Fold: 31  Epoch: 30  Training loss = 2.9515  Validation loss = 1.3448  \n",
      "\n",
      "Fold: 31  Epoch: 31  Training loss = 2.9514  Validation loss = 1.3446  \n",
      "\n",
      "Fold: 31  Epoch: 32  Training loss = 2.9514  Validation loss = 1.3445  \n",
      "\n",
      "Fold: 31  Epoch: 33  Training loss = 2.9513  Validation loss = 1.3445  \n",
      "\n",
      "Fold: 31  Epoch: 34  Training loss = 2.9513  Validation loss = 1.3446  \n",
      "\n",
      "Fold: 31  Epoch: 35  Training loss = 2.9512  Validation loss = 1.3446  \n",
      "\n",
      "Fold: 31  Epoch: 36  Training loss = 2.9511  Validation loss = 1.3448  \n",
      "\n",
      "Fold: 31  Epoch: 37  Training loss = 2.9511  Validation loss = 1.3448  \n",
      "\n",
      "Fold: 31  Epoch: 38  Training loss = 2.9510  Validation loss = 1.3448  \n",
      "\n",
      "Fold: 31  Epoch: 39  Training loss = 2.9510  Validation loss = 1.3446  \n",
      "\n",
      "Fold: 31  Epoch: 40  Training loss = 2.9509  Validation loss = 1.3447  \n",
      "\n",
      "Fold: 31  Epoch: 41  Training loss = 2.9509  Validation loss = 1.3447  \n",
      "\n",
      "Fold: 31  Epoch: 42  Training loss = 2.9508  Validation loss = 1.3444  \n",
      "\n",
      "Fold: 31  Epoch: 43  Training loss = 2.9508  Validation loss = 1.3443  \n",
      "\n",
      "Fold: 31  Epoch: 44  Training loss = 2.9507  Validation loss = 1.3443  \n",
      "\n",
      "Fold: 31  Epoch: 45  Training loss = 2.9507  Validation loss = 1.3444  \n",
      "\n",
      "Fold: 31  Epoch: 46  Training loss = 2.9506  Validation loss = 1.3446  \n",
      "\n",
      "Fold: 31  Epoch: 47  Training loss = 2.9506  Validation loss = 1.3444  \n",
      "\n",
      "Fold: 31  Epoch: 48  Training loss = 2.9505  Validation loss = 1.3442  \n",
      "\n",
      "Fold: 31  Epoch: 49  Training loss = 2.9505  Validation loss = 1.3443  \n",
      "\n",
      "Fold: 31  Epoch: 50  Training loss = 2.9504  Validation loss = 1.3444  \n",
      "\n",
      "Fold: 31  Epoch: 51  Training loss = 2.9503  Validation loss = 1.3443  \n",
      "\n",
      "Fold: 31  Epoch: 52  Training loss = 2.9503  Validation loss = 1.3444  \n",
      "\n",
      "Fold: 31  Epoch: 53  Training loss = 2.9502  Validation loss = 1.3442  \n",
      "\n",
      "Fold: 31  Epoch: 54  Training loss = 2.9502  Validation loss = 1.3443  \n",
      "\n",
      "Fold: 31  Epoch: 55  Training loss = 2.9502  Validation loss = 1.3444  \n",
      "\n",
      "Fold: 31  Epoch: 56  Training loss = 2.9501  Validation loss = 1.3446  \n",
      "\n",
      "Check model:  Fold: 31  Optimal epoch: 48  \n",
      "\n",
      "Fold: 32  Epoch: 1  Training loss = 2.2344  Validation loss = 2.4520  \n",
      "\n",
      "Fold: 32  Epoch: 2  Training loss = 2.2343  Validation loss = 2.4519  \n",
      "\n",
      "Fold: 32  Epoch: 3  Training loss = 2.2343  Validation loss = 2.4518  \n",
      "\n",
      "Fold: 32  Epoch: 4  Training loss = 2.2342  Validation loss = 2.4517  \n",
      "\n",
      "Fold: 32  Epoch: 5  Training loss = 2.2342  Validation loss = 2.4517  \n",
      "\n",
      "Fold: 32  Epoch: 6  Training loss = 2.2342  Validation loss = 2.4517  \n",
      "\n",
      "Fold: 32  Epoch: 7  Training loss = 2.2341  Validation loss = 2.4517  \n",
      "\n",
      "Fold: 32  Epoch: 8  Training loss = 2.2340  Validation loss = 2.4515  \n",
      "\n",
      "Fold: 32  Epoch: 9  Training loss = 2.2340  Validation loss = 2.4514  \n",
      "\n",
      "Fold: 32  Epoch: 10  Training loss = 2.2340  Validation loss = 2.4513  \n",
      "\n",
      "Fold: 32  Epoch: 11  Training loss = 2.2339  Validation loss = 2.4514  \n",
      "\n",
      "Fold: 32  Epoch: 12  Training loss = 2.2339  Validation loss = 2.4515  \n",
      "\n",
      "Fold: 32  Epoch: 13  Training loss = 2.2339  Validation loss = 2.4514  \n",
      "\n",
      "Fold: 32  Epoch: 14  Training loss = 2.2338  Validation loss = 2.4513  \n",
      "\n",
      "Fold: 32  Epoch: 15  Training loss = 2.2338  Validation loss = 2.4512  \n",
      "\n",
      "Fold: 32  Epoch: 16  Training loss = 2.2337  Validation loss = 2.4513  \n",
      "\n",
      "Fold: 32  Epoch: 17  Training loss = 2.2337  Validation loss = 2.4511  \n",
      "\n",
      "Fold: 32  Epoch: 18  Training loss = 2.2336  Validation loss = 2.4509  \n",
      "\n",
      "Fold: 32  Epoch: 19  Training loss = 2.2335  Validation loss = 2.4508  \n",
      "\n",
      "Fold: 32  Epoch: 20  Training loss = 2.2335  Validation loss = 2.4507  \n",
      "\n",
      "Fold: 32  Epoch: 21  Training loss = 2.2334  Validation loss = 2.4507  \n",
      "\n",
      "Fold: 32  Epoch: 22  Training loss = 2.2334  Validation loss = 2.4507  \n",
      "\n",
      "Fold: 32  Epoch: 23  Training loss = 2.2334  Validation loss = 2.4506  \n",
      "\n",
      "Fold: 32  Epoch: 24  Training loss = 2.2333  Validation loss = 2.4505  \n",
      "\n",
      "Fold: 32  Epoch: 25  Training loss = 2.2332  Validation loss = 2.4505  \n",
      "\n",
      "Fold: 32  Epoch: 26  Training loss = 2.2332  Validation loss = 2.4504  \n",
      "\n",
      "Fold: 32  Epoch: 27  Training loss = 2.2332  Validation loss = 2.4504  \n",
      "\n",
      "Fold: 32  Epoch: 28  Training loss = 2.2331  Validation loss = 2.4504  \n",
      "\n",
      "Fold: 32  Epoch: 29  Training loss = 2.2331  Validation loss = 2.4503  \n",
      "\n",
      "Fold: 32  Epoch: 30  Training loss = 2.2330  Validation loss = 2.4503  \n",
      "\n",
      "Fold: 32  Epoch: 31  Training loss = 2.2330  Validation loss = 2.4502  \n",
      "\n",
      "Fold: 32  Epoch: 32  Training loss = 2.2329  Validation loss = 2.4501  \n",
      "\n",
      "Fold: 32  Epoch: 33  Training loss = 2.2329  Validation loss = 2.4501  \n",
      "\n",
      "Fold: 32  Epoch: 34  Training loss = 2.2328  Validation loss = 2.4500  \n",
      "\n",
      "Fold: 32  Epoch: 35  Training loss = 2.2328  Validation loss = 2.4498  \n",
      "\n",
      "Fold: 32  Epoch: 36  Training loss = 2.2327  Validation loss = 2.4499  \n",
      "\n",
      "Fold: 32  Epoch: 37  Training loss = 2.2327  Validation loss = 2.4498  \n",
      "\n",
      "Fold: 32  Epoch: 38  Training loss = 2.2326  Validation loss = 2.4497  \n",
      "\n",
      "Fold: 32  Epoch: 39  Training loss = 2.2326  Validation loss = 2.4495  \n",
      "\n",
      "Fold: 32  Epoch: 40  Training loss = 2.2326  Validation loss = 2.4496  \n",
      "\n",
      "Fold: 32  Epoch: 41  Training loss = 2.2325  Validation loss = 2.4494  \n",
      "\n",
      "Fold: 32  Epoch: 42  Training loss = 2.2324  Validation loss = 2.4493  \n",
      "\n",
      "Fold: 32  Epoch: 43  Training loss = 2.2324  Validation loss = 2.4492  \n",
      "\n",
      "Fold: 32  Epoch: 44  Training loss = 2.2323  Validation loss = 2.4492  \n",
      "\n",
      "Fold: 32  Epoch: 45  Training loss = 2.2323  Validation loss = 2.4491  \n",
      "\n",
      "Fold: 32  Epoch: 46  Training loss = 2.2322  Validation loss = 2.4490  \n",
      "\n",
      "Fold: 32  Epoch: 47  Training loss = 2.2322  Validation loss = 2.4490  \n",
      "\n",
      "Fold: 32  Epoch: 48  Training loss = 2.2322  Validation loss = 2.4490  \n",
      "\n",
      "Fold: 32  Epoch: 49  Training loss = 2.2321  Validation loss = 2.4489  \n",
      "\n",
      "Fold: 32  Epoch: 50  Training loss = 2.2321  Validation loss = 2.4488  \n",
      "\n",
      "Fold: 32  Epoch: 51  Training loss = 2.2320  Validation loss = 2.4489  \n",
      "\n",
      "Fold: 32  Epoch: 52  Training loss = 2.2320  Validation loss = 2.4489  \n",
      "\n",
      "Fold: 32  Epoch: 53  Training loss = 2.2319  Validation loss = 2.4490  \n",
      "\n",
      "Fold: 32  Epoch: 54  Training loss = 2.2319  Validation loss = 2.4490  \n",
      "\n",
      "Fold: 32  Epoch: 55  Training loss = 2.2319  Validation loss = 2.4491  \n",
      "\n",
      "Check model:  Fold: 32  Optimal epoch: 50  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 2. Train model\n",
    "# ==================================\n",
    "sess = tf.InteractiveSession()  # Launch Graph\n",
    "sess.run(tf.global_variables_initializer())  # Initialise all variables\n",
    "\n",
    "print(\"Start training\", \n",
    "      \"\\nHyperparameters:\",\n",
    "      \"\\nDimension of recurrent unit =\", n_hidden,\n",
    "      \"\\nLearning rate =\", learning_rate,\n",
    "      \"\\nEpochs =\", epochs,\n",
    "      \"\\nBatch size =\", batch_size,\n",
    "      \"\\nEarly stopping epochs =\", early_stop_iters,\n",
    "      \"\\nLearning rate =\", learning_rate)\n",
    "\n",
    "total_batch = int(window_length / batch_size)\n",
    "validation_fold_error = [] # store validation error of each fold\n",
    "optimal_epochs = []\n",
    "\n",
    "# loop through folds\n",
    "for fold in range(1, len(valIndex)):\n",
    "    validx = train_features[valIndex[fold-1]:valIndex[fold]]\n",
    "    validy = train_target[valIndex[fold-1]:valIndex[fold]]\n",
    "    trainx = train_features[(fold-1)*4:valIndex[(fold-1)]]\n",
    "    trainy = train_target[(fold-1)*4:valIndex[(fold-1)]]\n",
    "\n",
    "    loss_list = [] # store validation loss after each epoch for early stopping\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i in range(total_batch):\n",
    "            # Backprop\n",
    "            batch_xs, batch_ys = next_batch(num=batch_size, data=trainx, labels=trainy)\n",
    "            optimizer.run(feed_dict={x:batch_xs, y:batch_ys, lr:learning_rate})\n",
    "\n",
    "        # Loss\n",
    "        loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "        loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "        loss_list.append(loss_valid)\n",
    "\n",
    "        print(\"Fold: {0:d}\".format(fold),\n",
    "              \" Epoch: {0:d}\".format(epoch+1),\n",
    "              \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "              \" Validation loss = {0:.4f}\".format(np.sqrt(loss_valid)),\n",
    "              \" \\n\")\n",
    "\n",
    "        if all(j <= loss_valid for j in loss_list[-early_stop_iters:]) and len(loss_list)>early_stop_iters:\n",
    "            break\n",
    "    \n",
    "    # Load model with lowest validation error for each fold\n",
    "    epoch_hat = np.argmin(loss_list) + 1\n",
    "    optimal_epochs.append(epoch_hat) # store optimal number of epochs for each fold\n",
    "    \n",
    "    # RMSE\n",
    "    loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "    loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "    validation_fold_error.append(np.sqrt(loss_valid))\n",
    "    \n",
    "    print(\"Check model:\",\n",
    "          \" Fold: {0:d}\".format(fold),\n",
    "          \" Optimal epoch: {0:d}\".format(epoch_hat),\n",
    "          \" \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average number of epochs: 366\n",
      "Average validation error: 3.9309\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 3. Optimal epoch choice\n",
    "# ==================================\n",
    "# Pick number of epochs to train model for out-of-sample testing\n",
    "epoch_hat = int(np.mean(optimal_epochs))\n",
    "print(\"\\nAverage number of epochs:\", epoch_hat)\n",
    "# Average validation error\n",
    "print(\"Average validation error:\", np.mean(validation_fold_error))\n",
    "\n",
    "# Save validated model\n",
    "saveModel(sess, \n",
    "          MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + str(epoch_hat) + \"_validated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fixed scheme:\n",
      "Epoch: 1  Training loss = 1.7758  Test loss = 2.9907  \n",
      "\n",
      "Epoch: 2  Training loss = 1.7758  Test loss = 2.9907  \n",
      "\n",
      "Epoch: 3  Training loss = 1.7758  Test loss = 2.9907  \n",
      "\n",
      "Epoch: 4  Training loss = 1.7758  Test loss = 2.9907  \n",
      "\n",
      "Epoch: 5  Training loss = 1.7758  Test loss = 2.9907  \n",
      "\n",
      "Epoch: 6  Training loss = 1.7758  Test loss = 2.9906  \n",
      "\n",
      "Epoch: 7  Training loss = 1.7758  Test loss = 2.9906  \n",
      "\n",
      "Epoch: 8  Training loss = 1.7757  Test loss = 2.9906  \n",
      "\n",
      "Epoch: 9  Training loss = 1.7757  Test loss = 2.9906  \n",
      "\n",
      "Epoch: 10  Training loss = 1.7757  Test loss = 2.9906  \n",
      "\n",
      "Epoch: 11  Training loss = 1.7757  Test loss = 2.9906  \n",
      "\n",
      "Epoch: 12  Training loss = 1.7757  Test loss = 2.9906  \n",
      "\n",
      "Epoch: 13  Training loss = 1.7757  Test loss = 2.9905  \n",
      "\n",
      "Epoch: 14  Training loss = 1.7757  Test loss = 2.9905  \n",
      "\n",
      "Epoch: 15  Training loss = 1.7757  Test loss = 2.9905  \n",
      "\n",
      "Epoch: 16  Training loss = 1.7757  Test loss = 2.9905  \n",
      "\n",
      "Epoch: 17  Training loss = 1.7757  Test loss = 2.9905  \n",
      "\n",
      "Epoch: 18  Training loss = 1.7757  Test loss = 2.9905  \n",
      "\n",
      "Epoch: 19  Training loss = 1.7757  Test loss = 2.9905  \n",
      "\n",
      "Epoch: 20  Training loss = 1.7756  Test loss = 2.9904  \n",
      "\n",
      "Epoch: 21  Training loss = 1.7756  Test loss = 2.9904  \n",
      "\n",
      "Epoch: 22  Training loss = 1.7756  Test loss = 2.9904  \n",
      "\n",
      "Epoch: 23  Training loss = 1.7756  Test loss = 2.9904  \n",
      "\n",
      "Epoch: 24  Training loss = 1.7756  Test loss = 2.9904  \n",
      "\n",
      "Epoch: 25  Training loss = 1.7756  Test loss = 2.9904  \n",
      "\n",
      "Epoch: 26  Training loss = 1.7756  Test loss = 2.9904  \n",
      "\n",
      "Epoch: 27  Training loss = 1.7756  Test loss = 2.9903  \n",
      "\n",
      "Epoch: 28  Training loss = 1.7756  Test loss = 2.9903  \n",
      "\n",
      "Epoch: 29  Training loss = 1.7756  Test loss = 2.9903  \n",
      "\n",
      "Epoch: 30  Training loss = 1.7756  Test loss = 2.9903  \n",
      "\n",
      "Epoch: 31  Training loss = 1.7755  Test loss = 2.9903  \n",
      "\n",
      "Epoch: 32  Training loss = 1.7755  Test loss = 2.9903  \n",
      "\n",
      "Epoch: 33  Training loss = 1.7755  Test loss = 2.9903  \n",
      "\n",
      "Epoch: 34  Training loss = 1.7755  Test loss = 2.9902  \n",
      "\n",
      "Epoch: 35  Training loss = 1.7755  Test loss = 2.9902  \n",
      "\n",
      "Epoch: 36  Training loss = 1.7755  Test loss = 2.9902  \n",
      "\n",
      "Epoch: 37  Training loss = 1.7755  Test loss = 2.9902  \n",
      "\n",
      "Epoch: 38  Training loss = 1.7755  Test loss = 2.9902  \n",
      "\n",
      "Epoch: 39  Training loss = 1.7755  Test loss = 2.9902  \n",
      "\n",
      "Epoch: 40  Training loss = 1.7755  Test loss = 2.9902  \n",
      "\n",
      "Epoch: 41  Training loss = 1.7755  Test loss = 2.9901  \n",
      "\n",
      "Epoch: 42  Training loss = 1.7755  Test loss = 2.9901  \n",
      "\n",
      "Epoch: 43  Training loss = 1.7754  Test loss = 2.9901  \n",
      "\n",
      "Epoch: 44  Training loss = 1.7754  Test loss = 2.9901  \n",
      "\n",
      "Epoch: 45  Training loss = 1.7754  Test loss = 2.9901  \n",
      "\n",
      "Epoch: 46  Training loss = 1.7754  Test loss = 2.9901  \n",
      "\n",
      "Epoch: 47  Training loss = 1.7754  Test loss = 2.9901  \n",
      "\n",
      "Epoch: 48  Training loss = 1.7754  Test loss = 2.9900  \n",
      "\n",
      "Epoch: 49  Training loss = 1.7754  Test loss = 2.9900  \n",
      "\n",
      "Epoch: 50  Training loss = 1.7754  Test loss = 2.9900  \n",
      "\n",
      "Epoch: 51  Training loss = 1.7754  Test loss = 2.9900  \n",
      "\n",
      "Epoch: 52  Training loss = 1.7754  Test loss = 2.9900  \n",
      "\n",
      "Epoch: 53  Training loss = 1.7754  Test loss = 2.9900  \n",
      "\n",
      "Epoch: 54  Training loss = 1.7754  Test loss = 2.9900  \n",
      "\n",
      "Epoch: 55  Training loss = 1.7753  Test loss = 2.9899  \n",
      "\n",
      "Epoch: 56  Training loss = 1.7753  Test loss = 2.9899  \n",
      "\n",
      "Epoch: 57  Training loss = 1.7753  Test loss = 2.9899  \n",
      "\n",
      "Epoch: 58  Training loss = 1.7753  Test loss = 2.9899  \n",
      "\n",
      "Epoch: 59  Training loss = 1.7753  Test loss = 2.9899  \n",
      "\n",
      "Epoch: 60  Training loss = 1.7753  Test loss = 2.9899  \n",
      "\n",
      "Epoch: 61  Training loss = 1.7753  Test loss = 2.9899  \n",
      "\n",
      "Epoch: 62  Training loss = 1.7753  Test loss = 2.9898  \n",
      "\n",
      "Epoch: 63  Training loss = 1.7753  Test loss = 2.9898  \n",
      "\n",
      "Epoch: 64  Training loss = 1.7753  Test loss = 2.9898  \n",
      "\n",
      "Epoch: 65  Training loss = 1.7753  Test loss = 2.9898  \n",
      "\n",
      "Epoch: 66  Training loss = 1.7752  Test loss = 2.9898  \n",
      "\n",
      "Epoch: 67  Training loss = 1.7752  Test loss = 2.9898  \n",
      "\n",
      "Epoch: 68  Training loss = 1.7752  Test loss = 2.9897  \n",
      "\n",
      "Epoch: 69  Training loss = 1.7752  Test loss = 2.9897  \n",
      "\n",
      "Epoch: 70  Training loss = 1.7752  Test loss = 2.9897  \n",
      "\n",
      "Epoch: 71  Training loss = 1.7752  Test loss = 2.9897  \n",
      "\n",
      "Epoch: 72  Training loss = 1.7752  Test loss = 2.9897  \n",
      "\n",
      "Epoch: 73  Training loss = 1.7752  Test loss = 2.9897  \n",
      "\n",
      "Epoch: 74  Training loss = 1.7752  Test loss = 2.9897  \n",
      "\n",
      "Epoch: 75  Training loss = 1.7752  Test loss = 2.9896  \n",
      "\n",
      "Epoch: 76  Training loss = 1.7752  Test loss = 2.9896  \n",
      "\n",
      "Epoch: 77  Training loss = 1.7752  Test loss = 2.9896  \n",
      "\n",
      "Epoch: 78  Training loss = 1.7751  Test loss = 2.9896  \n",
      "\n",
      "Epoch: 79  Training loss = 1.7751  Test loss = 2.9896  \n",
      "\n",
      "Epoch: 80  Training loss = 1.7751  Test loss = 2.9896  \n",
      "\n",
      "Epoch: 81  Training loss = 1.7751  Test loss = 2.9896  \n",
      "\n",
      "Epoch: 82  Training loss = 1.7751  Test loss = 2.9895  \n",
      "\n",
      "Epoch: 83  Training loss = 1.7751  Test loss = 2.9895  \n",
      "\n",
      "Epoch: 84  Training loss = 1.7751  Test loss = 2.9895  \n",
      "\n",
      "Epoch: 85  Training loss = 1.7751  Test loss = 2.9895  \n",
      "\n",
      "Epoch: 86  Training loss = 1.7751  Test loss = 2.9895  \n",
      "\n",
      "Epoch: 87  Training loss = 1.7751  Test loss = 2.9895  \n",
      "\n",
      "Epoch: 88  Training loss = 1.7751  Test loss = 2.9895  \n",
      "\n",
      "Epoch: 89  Training loss = 1.7751  Test loss = 2.9894  \n",
      "\n",
      "Epoch: 90  Training loss = 1.7750  Test loss = 2.9894  \n",
      "\n",
      "Epoch: 91  Training loss = 1.7750  Test loss = 2.9894  \n",
      "\n",
      "Epoch: 92  Training loss = 1.7750  Test loss = 2.9894  \n",
      "\n",
      "Epoch: 93  Training loss = 1.7750  Test loss = 2.9894  \n",
      "\n",
      "Epoch: 94  Training loss = 1.7750  Test loss = 2.9894  \n",
      "\n",
      "Epoch: 95  Training loss = 1.7750  Test loss = 2.9894  \n",
      "\n",
      "Epoch: 96  Training loss = 1.7750  Test loss = 2.9893  \n",
      "\n",
      "Epoch: 97  Training loss = 1.7750  Test loss = 2.9893  \n",
      "\n",
      "Epoch: 98  Training loss = 1.7750  Test loss = 2.9893  \n",
      "\n",
      "Epoch: 99  Training loss = 1.7750  Test loss = 2.9893  \n",
      "\n",
      "Epoch: 100  Training loss = 1.7750  Test loss = 2.9893  \n",
      "\n",
      "Epoch: 101  Training loss = 1.7749  Test loss = 2.9893  \n",
      "\n",
      "Epoch: 102  Training loss = 1.7749  Test loss = 2.9893  \n",
      "\n",
      "Epoch: 103  Training loss = 1.7749  Test loss = 2.9892  \n",
      "\n",
      "Epoch: 104  Training loss = 1.7749  Test loss = 2.9892  \n",
      "\n",
      "Epoch: 105  Training loss = 1.7749  Test loss = 2.9892  \n",
      "\n",
      "Epoch: 106  Training loss = 1.7749  Test loss = 2.9892  \n",
      "\n",
      "Epoch: 107  Training loss = 1.7749  Test loss = 2.9892  \n",
      "\n",
      "Epoch: 108  Training loss = 1.7749  Test loss = 2.9892  \n",
      "\n",
      "Epoch: 109  Training loss = 1.7749  Test loss = 2.9892  \n",
      "\n",
      "Epoch: 110  Training loss = 1.7749  Test loss = 2.9891  \n",
      "\n",
      "Epoch: 111  Training loss = 1.7749  Test loss = 2.9891  \n",
      "\n",
      "Epoch: 112  Training loss = 1.7749  Test loss = 2.9891  \n",
      "\n",
      "Epoch: 113  Training loss = 1.7748  Test loss = 2.9891  \n",
      "\n",
      "Epoch: 114  Training loss = 1.7748  Test loss = 2.9891  \n",
      "\n",
      "Epoch: 115  Training loss = 1.7748  Test loss = 2.9891  \n",
      "\n",
      "Epoch: 116  Training loss = 1.7748  Test loss = 2.9891  \n",
      "\n",
      "Epoch: 117  Training loss = 1.7748  Test loss = 2.9890  \n",
      "\n",
      "Epoch: 118  Training loss = 1.7748  Test loss = 2.9890  \n",
      "\n",
      "Epoch: 119  Training loss = 1.7748  Test loss = 2.9890  \n",
      "\n",
      "Epoch: 120  Training loss = 1.7748  Test loss = 2.9890  \n",
      "\n",
      "Epoch: 121  Training loss = 1.7748  Test loss = 2.9890  \n",
      "\n",
      "Epoch: 122  Training loss = 1.7748  Test loss = 2.9890  \n",
      "\n",
      "Epoch: 123  Training loss = 1.7748  Test loss = 2.9890  \n",
      "\n",
      "Epoch: 124  Training loss = 1.7747  Test loss = 2.9889  \n",
      "\n",
      "Epoch: 125  Training loss = 1.7747  Test loss = 2.9889  \n",
      "\n",
      "Epoch: 126  Training loss = 1.7747  Test loss = 2.9889  \n",
      "\n",
      "Epoch: 127  Training loss = 1.7747  Test loss = 2.9889  \n",
      "\n",
      "Epoch: 128  Training loss = 1.7747  Test loss = 2.9889  \n",
      "\n",
      "Epoch: 129  Training loss = 1.7747  Test loss = 2.9889  \n",
      "\n",
      "Epoch: 130  Training loss = 1.7747  Test loss = 2.9889  \n",
      "\n",
      "Epoch: 131  Training loss = 1.7747  Test loss = 2.9888  \n",
      "\n",
      "Epoch: 132  Training loss = 1.7747  Test loss = 2.9888  \n",
      "\n",
      "Epoch: 133  Training loss = 1.7747  Test loss = 2.9888  \n",
      "\n",
      "Epoch: 134  Training loss = 1.7747  Test loss = 2.9888  \n",
      "\n",
      "Epoch: 135  Training loss = 1.7747  Test loss = 2.9888  \n",
      "\n",
      "Epoch: 136  Training loss = 1.7746  Test loss = 2.9888  \n",
      "\n",
      "Epoch: 137  Training loss = 1.7746  Test loss = 2.9888  \n",
      "\n",
      "Epoch: 138  Training loss = 1.7746  Test loss = 2.9887  \n",
      "\n",
      "Epoch: 139  Training loss = 1.7746  Test loss = 2.9887  \n",
      "\n",
      "Epoch: 140  Training loss = 1.7746  Test loss = 2.9887  \n",
      "\n",
      "Epoch: 141  Training loss = 1.7746  Test loss = 2.9887  \n",
      "\n",
      "Epoch: 142  Training loss = 1.7746  Test loss = 2.9887  \n",
      "\n",
      "Epoch: 143  Training loss = 1.7746  Test loss = 2.9887  \n",
      "\n",
      "Epoch: 144  Training loss = 1.7746  Test loss = 2.9886  \n",
      "\n",
      "Epoch: 145  Training loss = 1.7746  Test loss = 2.9886  \n",
      "\n",
      "Epoch: 146  Training loss = 1.7746  Test loss = 2.9886  \n",
      "\n",
      "Epoch: 147  Training loss = 1.7746  Test loss = 2.9886  \n",
      "\n",
      "Epoch: 148  Training loss = 1.7745  Test loss = 2.9886  \n",
      "\n",
      "Epoch: 149  Training loss = 1.7745  Test loss = 2.9886  \n",
      "\n",
      "Epoch: 150  Training loss = 1.7745  Test loss = 2.9886  \n",
      "\n",
      "Epoch: 151  Training loss = 1.7745  Test loss = 2.9885  \n",
      "\n",
      "Epoch: 152  Training loss = 1.7745  Test loss = 2.9885  \n",
      "\n",
      "Epoch: 153  Training loss = 1.7745  Test loss = 2.9885  \n",
      "\n",
      "Epoch: 154  Training loss = 1.7745  Test loss = 2.9885  \n",
      "\n",
      "Epoch: 155  Training loss = 1.7745  Test loss = 2.9885  \n",
      "\n",
      "Epoch: 156  Training loss = 1.7745  Test loss = 2.9885  \n",
      "\n",
      "Epoch: 157  Training loss = 1.7745  Test loss = 2.9885  \n",
      "\n",
      "Epoch: 158  Training loss = 1.7745  Test loss = 2.9884  \n",
      "\n",
      "Epoch: 159  Training loss = 1.7744  Test loss = 2.9884  \n",
      "\n",
      "Epoch: 160  Training loss = 1.7744  Test loss = 2.9884  \n",
      "\n",
      "Epoch: 161  Training loss = 1.7744  Test loss = 2.9884  \n",
      "\n",
      "Epoch: 162  Training loss = 1.7744  Test loss = 2.9884  \n",
      "\n",
      "Epoch: 163  Training loss = 1.7744  Test loss = 2.9884  \n",
      "\n",
      "Epoch: 164  Training loss = 1.7744  Test loss = 2.9884  \n",
      "\n",
      "Epoch: 165  Training loss = 1.7744  Test loss = 2.9883  \n",
      "\n",
      "Epoch: 166  Training loss = 1.7744  Test loss = 2.9883  \n",
      "\n",
      "Epoch: 167  Training loss = 1.7744  Test loss = 2.9883  \n",
      "\n",
      "Epoch: 168  Training loss = 1.7744  Test loss = 2.9883  \n",
      "\n",
      "Epoch: 169  Training loss = 1.7744  Test loss = 2.9883  \n",
      "\n",
      "Epoch: 170  Training loss = 1.7744  Test loss = 2.9883  \n",
      "\n",
      "Epoch: 171  Training loss = 1.7743  Test loss = 2.9883  \n",
      "\n",
      "Epoch: 172  Training loss = 1.7743  Test loss = 2.9882  \n",
      "\n",
      "Epoch: 173  Training loss = 1.7743  Test loss = 2.9882  \n",
      "\n",
      "Epoch: 174  Training loss = 1.7743  Test loss = 2.9882  \n",
      "\n",
      "Epoch: 175  Training loss = 1.7743  Test loss = 2.9882  \n",
      "\n",
      "Epoch: 176  Training loss = 1.7743  Test loss = 2.9882  \n",
      "\n",
      "Epoch: 177  Training loss = 1.7743  Test loss = 2.9882  \n",
      "\n",
      "Epoch: 178  Training loss = 1.7743  Test loss = 2.9882  \n",
      "\n",
      "Epoch: 179  Training loss = 1.7743  Test loss = 2.9881  \n",
      "\n",
      "Epoch: 180  Training loss = 1.7743  Test loss = 2.9881  \n",
      "\n",
      "Epoch: 181  Training loss = 1.7743  Test loss = 2.9881  \n",
      "\n",
      "Epoch: 182  Training loss = 1.7743  Test loss = 2.9881  \n",
      "\n",
      "Epoch: 183  Training loss = 1.7742  Test loss = 2.9881  \n",
      "\n",
      "Epoch: 184  Training loss = 1.7742  Test loss = 2.9881  \n",
      "\n",
      "Epoch: 185  Training loss = 1.7742  Test loss = 2.9881  \n",
      "\n",
      "Epoch: 186  Training loss = 1.7742  Test loss = 2.9880  \n",
      "\n",
      "Epoch: 187  Training loss = 1.7742  Test loss = 2.9880  \n",
      "\n",
      "Epoch: 188  Training loss = 1.7742  Test loss = 2.9880  \n",
      "\n",
      "Epoch: 189  Training loss = 1.7742  Test loss = 2.9880  \n",
      "\n",
      "Epoch: 190  Training loss = 1.7742  Test loss = 2.9880  \n",
      "\n",
      "Epoch: 191  Training loss = 1.7742  Test loss = 2.9880  \n",
      "\n",
      "Epoch: 192  Training loss = 1.7742  Test loss = 2.9880  \n",
      "\n",
      "Epoch: 193  Training loss = 1.7742  Test loss = 2.9879  \n",
      "\n",
      "Epoch: 194  Training loss = 1.7741  Test loss = 2.9879  \n",
      "\n",
      "Epoch: 195  Training loss = 1.7741  Test loss = 2.9879  \n",
      "\n",
      "Epoch: 196  Training loss = 1.7741  Test loss = 2.9879  \n",
      "\n",
      "Epoch: 197  Training loss = 1.7741  Test loss = 2.9879  \n",
      "\n",
      "Epoch: 198  Training loss = 1.7741  Test loss = 2.9879  \n",
      "\n",
      "Epoch: 199  Training loss = 1.7741  Test loss = 2.9879  \n",
      "\n",
      "Epoch: 200  Training loss = 1.7741  Test loss = 2.9878  \n",
      "\n",
      "Epoch: 201  Training loss = 1.7741  Test loss = 2.9878  \n",
      "\n",
      "Epoch: 202  Training loss = 1.7741  Test loss = 2.9878  \n",
      "\n",
      "Epoch: 203  Training loss = 1.7741  Test loss = 2.9878  \n",
      "\n",
      "Epoch: 204  Training loss = 1.7741  Test loss = 2.9878  \n",
      "\n",
      "Epoch: 205  Training loss = 1.7741  Test loss = 2.9878  \n",
      "\n",
      "Epoch: 206  Training loss = 1.7740  Test loss = 2.9877  \n",
      "\n",
      "Epoch: 207  Training loss = 1.7740  Test loss = 2.9877  \n",
      "\n",
      "Epoch: 208  Training loss = 1.7740  Test loss = 2.9877  \n",
      "\n",
      "Epoch: 209  Training loss = 1.7740  Test loss = 2.9877  \n",
      "\n",
      "Epoch: 210  Training loss = 1.7740  Test loss = 2.9877  \n",
      "\n",
      "Epoch: 211  Training loss = 1.7740  Test loss = 2.9877  \n",
      "\n",
      "Epoch: 212  Training loss = 1.7740  Test loss = 2.9877  \n",
      "\n",
      "Epoch: 213  Training loss = 1.7740  Test loss = 2.9876  \n",
      "\n",
      "Epoch: 214  Training loss = 1.7740  Test loss = 2.9876  \n",
      "\n",
      "Epoch: 215  Training loss = 1.7740  Test loss = 2.9876  \n",
      "\n",
      "Epoch: 216  Training loss = 1.7740  Test loss = 2.9876  \n",
      "\n",
      "Epoch: 217  Training loss = 1.7739  Test loss = 2.9876  \n",
      "\n",
      "Epoch: 218  Training loss = 1.7739  Test loss = 2.9876  \n",
      "\n",
      "Epoch: 219  Training loss = 1.7739  Test loss = 2.9876  \n",
      "\n",
      "Epoch: 220  Training loss = 1.7739  Test loss = 2.9875  \n",
      "\n",
      "Epoch: 221  Training loss = 1.7739  Test loss = 2.9875  \n",
      "\n",
      "Epoch: 222  Training loss = 1.7739  Test loss = 2.9875  \n",
      "\n",
      "Epoch: 223  Training loss = 1.7739  Test loss = 2.9875  \n",
      "\n",
      "Epoch: 224  Training loss = 1.7739  Test loss = 2.9875  \n",
      "\n",
      "Epoch: 225  Training loss = 1.7739  Test loss = 2.9875  \n",
      "\n",
      "Epoch: 226  Training loss = 1.7739  Test loss = 2.9875  \n",
      "\n",
      "Epoch: 227  Training loss = 1.7739  Test loss = 2.9874  \n",
      "\n",
      "Epoch: 228  Training loss = 1.7739  Test loss = 2.9874  \n",
      "\n",
      "Epoch: 229  Training loss = 1.7738  Test loss = 2.9874  \n",
      "\n",
      "Epoch: 230  Training loss = 1.7738  Test loss = 2.9874  \n",
      "\n",
      "Epoch: 231  Training loss = 1.7738  Test loss = 2.9874  \n",
      "\n",
      "Epoch: 232  Training loss = 1.7738  Test loss = 2.9874  \n",
      "\n",
      "Epoch: 233  Training loss = 1.7738  Test loss = 2.9874  \n",
      "\n",
      "Epoch: 234  Training loss = 1.7738  Test loss = 2.9873  \n",
      "\n",
      "Epoch: 235  Training loss = 1.7738  Test loss = 2.9873  \n",
      "\n",
      "Epoch: 236  Training loss = 1.7738  Test loss = 2.9873  \n",
      "\n",
      "Epoch: 237  Training loss = 1.7738  Test loss = 2.9873  \n",
      "\n",
      "Epoch: 238  Training loss = 1.7738  Test loss = 2.9873  \n",
      "\n",
      "Epoch: 239  Training loss = 1.7738  Test loss = 2.9873  \n",
      "\n",
      "Epoch: 240  Training loss = 1.7737  Test loss = 2.9873  \n",
      "\n",
      "Epoch: 241  Training loss = 1.7737  Test loss = 2.9872  \n",
      "\n",
      "Epoch: 242  Training loss = 1.7737  Test loss = 2.9872  \n",
      "\n",
      "Epoch: 243  Training loss = 1.7737  Test loss = 2.9872  \n",
      "\n",
      "Epoch: 244  Training loss = 1.7737  Test loss = 2.9872  \n",
      "\n",
      "Epoch: 245  Training loss = 1.7737  Test loss = 2.9872  \n",
      "\n",
      "Epoch: 246  Training loss = 1.7737  Test loss = 2.9872  \n",
      "\n",
      "Epoch: 247  Training loss = 1.7737  Test loss = 2.9871  \n",
      "\n",
      "Epoch: 248  Training loss = 1.7737  Test loss = 2.9871  \n",
      "\n",
      "Epoch: 249  Training loss = 1.7737  Test loss = 2.9871  \n",
      "\n",
      "Epoch: 250  Training loss = 1.7737  Test loss = 2.9871  \n",
      "\n",
      "Epoch: 251  Training loss = 1.7737  Test loss = 2.9871  \n",
      "\n",
      "Epoch: 252  Training loss = 1.7736  Test loss = 2.9871  \n",
      "\n",
      "Epoch: 253  Training loss = 1.7736  Test loss = 2.9871  \n",
      "\n",
      "Epoch: 254  Training loss = 1.7736  Test loss = 2.9870  \n",
      "\n",
      "Epoch: 255  Training loss = 1.7736  Test loss = 2.9870  \n",
      "\n",
      "Epoch: 256  Training loss = 1.7736  Test loss = 2.9870  \n",
      "\n",
      "Epoch: 257  Training loss = 1.7736  Test loss = 2.9870  \n",
      "\n",
      "Epoch: 258  Training loss = 1.7736  Test loss = 2.9870  \n",
      "\n",
      "Epoch: 259  Training loss = 1.7736  Test loss = 2.9870  \n",
      "\n",
      "Epoch: 260  Training loss = 1.7736  Test loss = 2.9870  \n",
      "\n",
      "Epoch: 261  Training loss = 1.7736  Test loss = 2.9869  \n",
      "\n",
      "Epoch: 262  Training loss = 1.7736  Test loss = 2.9869  \n",
      "\n",
      "Epoch: 263  Training loss = 1.7736  Test loss = 2.9869  \n",
      "\n",
      "Epoch: 264  Training loss = 1.7735  Test loss = 2.9869  \n",
      "\n",
      "Epoch: 265  Training loss = 1.7735  Test loss = 2.9869  \n",
      "\n",
      "Epoch: 266  Training loss = 1.7735  Test loss = 2.9869  \n",
      "\n",
      "Epoch: 267  Training loss = 1.7735  Test loss = 2.9869  \n",
      "\n",
      "Epoch: 268  Training loss = 1.7735  Test loss = 2.9868  \n",
      "\n",
      "Epoch: 269  Training loss = 1.7735  Test loss = 2.9868  \n",
      "\n",
      "Epoch: 270  Training loss = 1.7735  Test loss = 2.9868  \n",
      "\n",
      "Epoch: 271  Training loss = 1.7735  Test loss = 2.9868  \n",
      "\n",
      "Epoch: 272  Training loss = 1.7735  Test loss = 2.9868  \n",
      "\n",
      "Epoch: 273  Training loss = 1.7735  Test loss = 2.9868  \n",
      "\n",
      "Epoch: 274  Training loss = 1.7735  Test loss = 2.9868  \n",
      "\n",
      "Epoch: 275  Training loss = 1.7734  Test loss = 2.9867  \n",
      "\n",
      "Epoch: 276  Training loss = 1.7734  Test loss = 2.9867  \n",
      "\n",
      "Epoch: 277  Training loss = 1.7734  Test loss = 2.9867  \n",
      "\n",
      "Epoch: 278  Training loss = 1.7734  Test loss = 2.9867  \n",
      "\n",
      "Epoch: 279  Training loss = 1.7734  Test loss = 2.9867  \n",
      "\n",
      "Epoch: 280  Training loss = 1.7734  Test loss = 2.9867  \n",
      "\n",
      "Epoch: 281  Training loss = 1.7734  Test loss = 2.9867  \n",
      "\n",
      "Epoch: 282  Training loss = 1.7734  Test loss = 2.9866  \n",
      "\n",
      "Epoch: 283  Training loss = 1.7734  Test loss = 2.9866  \n",
      "\n",
      "Epoch: 284  Training loss = 1.7734  Test loss = 2.9866  \n",
      "\n",
      "Epoch: 285  Training loss = 1.7734  Test loss = 2.9866  \n",
      "\n",
      "Epoch: 286  Training loss = 1.7734  Test loss = 2.9866  \n",
      "\n",
      "Epoch: 287  Training loss = 1.7733  Test loss = 2.9866  \n",
      "\n",
      "Epoch: 288  Training loss = 1.7733  Test loss = 2.9865  \n",
      "\n",
      "Epoch: 289  Training loss = 1.7733  Test loss = 2.9865  \n",
      "\n",
      "Epoch: 290  Training loss = 1.7733  Test loss = 2.9865  \n",
      "\n",
      "Epoch: 291  Training loss = 1.7733  Test loss = 2.9865  \n",
      "\n",
      "Epoch: 292  Training loss = 1.7733  Test loss = 2.9865  \n",
      "\n",
      "Epoch: 293  Training loss = 1.7733  Test loss = 2.9865  \n",
      "\n",
      "Epoch: 294  Training loss = 1.7733  Test loss = 2.9865  \n",
      "\n",
      "Epoch: 295  Training loss = 1.7733  Test loss = 2.9864  \n",
      "\n",
      "Epoch: 296  Training loss = 1.7733  Test loss = 2.9864  \n",
      "\n",
      "Epoch: 297  Training loss = 1.7733  Test loss = 2.9864  \n",
      "\n",
      "Epoch: 298  Training loss = 1.7732  Test loss = 2.9864  \n",
      "\n",
      "Epoch: 299  Training loss = 1.7732  Test loss = 2.9864  \n",
      "\n",
      "Epoch: 300  Training loss = 1.7732  Test loss = 2.9864  \n",
      "\n",
      "Epoch: 301  Training loss = 1.7732  Test loss = 2.9864  \n",
      "\n",
      "Epoch: 302  Training loss = 1.7732  Test loss = 2.9863  \n",
      "\n",
      "Epoch: 303  Training loss = 1.7732  Test loss = 2.9863  \n",
      "\n",
      "Epoch: 304  Training loss = 1.7732  Test loss = 2.9863  \n",
      "\n",
      "Epoch: 305  Training loss = 1.7732  Test loss = 2.9863  \n",
      "\n",
      "Epoch: 306  Training loss = 1.7732  Test loss = 2.9863  \n",
      "\n",
      "Epoch: 307  Training loss = 1.7732  Test loss = 2.9863  \n",
      "\n",
      "Epoch: 308  Training loss = 1.7732  Test loss = 2.9863  \n",
      "\n",
      "Epoch: 309  Training loss = 1.7732  Test loss = 2.9862  \n",
      "\n",
      "Epoch: 310  Training loss = 1.7731  Test loss = 2.9862  \n",
      "\n",
      "Epoch: 311  Training loss = 1.7731  Test loss = 2.9862  \n",
      "\n",
      "Epoch: 312  Training loss = 1.7731  Test loss = 2.9862  \n",
      "\n",
      "Epoch: 313  Training loss = 1.7731  Test loss = 2.9862  \n",
      "\n",
      "Epoch: 314  Training loss = 1.7731  Test loss = 2.9862  \n",
      "\n",
      "Epoch: 315  Training loss = 1.7731  Test loss = 2.9862  \n",
      "\n",
      "Epoch: 316  Training loss = 1.7731  Test loss = 2.9861  \n",
      "\n",
      "Epoch: 317  Training loss = 1.7731  Test loss = 2.9861  \n",
      "\n",
      "Epoch: 318  Training loss = 1.7731  Test loss = 2.9861  \n",
      "\n",
      "Epoch: 319  Training loss = 1.7731  Test loss = 2.9861  \n",
      "\n",
      "Epoch: 320  Training loss = 1.7731  Test loss = 2.9861  \n",
      "\n",
      "Epoch: 321  Training loss = 1.7730  Test loss = 2.9861  \n",
      "\n",
      "Epoch: 322  Training loss = 1.7730  Test loss = 2.9861  \n",
      "\n",
      "Epoch: 323  Training loss = 1.7730  Test loss = 2.9860  \n",
      "\n",
      "Epoch: 324  Training loss = 1.7730  Test loss = 2.9860  \n",
      "\n",
      "Epoch: 325  Training loss = 1.7730  Test loss = 2.9860  \n",
      "\n",
      "Epoch: 326  Training loss = 1.7730  Test loss = 2.9860  \n",
      "\n",
      "Epoch: 327  Training loss = 1.7730  Test loss = 2.9860  \n",
      "\n",
      "Epoch: 328  Training loss = 1.7730  Test loss = 2.9860  \n",
      "\n",
      "Epoch: 329  Training loss = 1.7730  Test loss = 2.9859  \n",
      "\n",
      "Epoch: 330  Training loss = 1.7730  Test loss = 2.9859  \n",
      "\n",
      "Epoch: 331  Training loss = 1.7730  Test loss = 2.9859  \n",
      "\n",
      "Epoch: 332  Training loss = 1.7730  Test loss = 2.9859  \n",
      "\n",
      "Epoch: 333  Training loss = 1.7729  Test loss = 2.9859  \n",
      "\n",
      "Epoch: 334  Training loss = 1.7729  Test loss = 2.9859  \n",
      "\n",
      "Epoch: 335  Training loss = 1.7729  Test loss = 2.9859  \n",
      "\n",
      "Epoch: 336  Training loss = 1.7729  Test loss = 2.9858  \n",
      "\n",
      "Epoch: 337  Training loss = 1.7729  Test loss = 2.9858  \n",
      "\n",
      "Epoch: 338  Training loss = 1.7729  Test loss = 2.9858  \n",
      "\n",
      "Epoch: 339  Training loss = 1.7729  Test loss = 2.9858  \n",
      "\n",
      "Epoch: 340  Training loss = 1.7729  Test loss = 2.9858  \n",
      "\n",
      "Epoch: 341  Training loss = 1.7729  Test loss = 2.9858  \n",
      "\n",
      "Epoch: 342  Training loss = 1.7729  Test loss = 2.9858  \n",
      "\n",
      "Epoch: 343  Training loss = 1.7729  Test loss = 2.9857  \n",
      "\n",
      "Epoch: 344  Training loss = 1.7728  Test loss = 2.9857  \n",
      "\n",
      "Epoch: 345  Training loss = 1.7728  Test loss = 2.9857  \n",
      "\n",
      "Epoch: 346  Training loss = 1.7728  Test loss = 2.9857  \n",
      "\n",
      "Epoch: 347  Training loss = 1.7728  Test loss = 2.9857  \n",
      "\n",
      "Epoch: 348  Training loss = 1.7728  Test loss = 2.9857  \n",
      "\n",
      "Epoch: 349  Training loss = 1.7728  Test loss = 2.9857  \n",
      "\n",
      "Epoch: 350  Training loss = 1.7728  Test loss = 2.9856  \n",
      "\n",
      "Epoch: 351  Training loss = 1.7728  Test loss = 2.9856  \n",
      "\n",
      "Epoch: 352  Training loss = 1.7728  Test loss = 2.9856  \n",
      "\n",
      "Epoch: 353  Training loss = 1.7728  Test loss = 2.9856  \n",
      "\n",
      "Epoch: 354  Training loss = 1.7728  Test loss = 2.9856  \n",
      "\n",
      "Epoch: 355  Training loss = 1.7728  Test loss = 2.9856  \n",
      "\n",
      "Epoch: 356  Training loss = 1.7727  Test loss = 2.9856  \n",
      "\n",
      "Epoch: 357  Training loss = 1.7727  Test loss = 2.9855  \n",
      "\n",
      "Epoch: 358  Training loss = 1.7727  Test loss = 2.9855  \n",
      "\n",
      "Epoch: 359  Training loss = 1.7727  Test loss = 2.9855  \n",
      "\n",
      "Epoch: 360  Training loss = 1.7727  Test loss = 2.9855  \n",
      "\n",
      "Epoch: 361  Training loss = 1.7727  Test loss = 2.9855  \n",
      "\n",
      "Epoch: 362  Training loss = 1.7727  Test loss = 2.9855  \n",
      "\n",
      "Epoch: 363  Training loss = 1.7727  Test loss = 2.9854  \n",
      "\n",
      "Epoch: 364  Training loss = 1.7727  Test loss = 2.9854  \n",
      "\n",
      "Epoch: 365  Training loss = 1.7727  Test loss = 2.9854  \n",
      "\n",
      "Epoch: 366  Training loss = 1.7727  Test loss = 2.9854  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 4. Fixed scheme\n",
    "# ==================================\n",
    "print(\"\\nFixed scheme:\")\n",
    "for epoch in range(epoch_hat):\n",
    "    x_train = train_features[-window_length:]\n",
    "    y_train = train_target[-window_length:]\n",
    "    optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:test_features, y:test_target})\n",
    "    print(\"Epoch: {0:d}\".format(epoch+1),\n",
    "          \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "          \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "          \" \\n\")\n",
    "\n",
    "# Forecasts\n",
    "yhat_test_fixed = pred.eval(feed_dict={x:test_features})\n",
    "yhat_train_fixed = pred.eval(feed_dict={x:x_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f58c1c2b4d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train set\n",
    "plt.plot(y_train, 'black')\n",
    "plt.plot(yhat_train_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIGgzorAHQRC0GVHYgyAI2oz/AFhDnTUOm6qJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f58bccea1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: fixed scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_test_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed scheme RMSE: 2.98540307326 \n",
      "Fixed scheme MAE:  2.21734786178\n"
     ]
    }
   ],
   "source": [
    "rmse_fixed = np.sqrt(np.mean((yhat_test_fixed[:,0]-test_target)**2))\n",
    "mae_fixed = np.mean(np.abs((yhat_test_fixed[:,0]-test_target)))\n",
    "print(\"Fixed scheme RMSE:\", rmse_fixed,\n",
    "     \"\\nFixed scheme MAE: \", mae_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Stack training and test set, this makes updating scheme easier to train\n",
    "all_features = np.concatenate((train_features[-window_length:], test_features), axis=0)\n",
    "all_target = np.concatenate((train_target[-window_length:], test_target), axis=0)\n",
    "\n",
    "# Vectors to store loss and forecasts\n",
    "test_loss = np.zeros(len(test_target))\n",
    "yhat_update = np.zeros(len(test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test period = 1  Training loss = 1.7727  Test loss = 4.2914  Model updated 0 times  \n",
      "\n",
      "Test period = 2  Training loss = 1.8437  Test loss = 3.5270  Model updated 0 times  \n",
      "\n",
      "Test period = 3  Training loss = 1.8844  Test loss = 1.9690  Model updated 0 times  \n",
      "\n",
      "Test period = 4  Training loss = 1.8810  Test loss = 0.2416  Model updated 0 times  \n",
      "\n",
      "Test period = 5  Training loss = 1.7683  Test loss = 0.5796  Model updated 1 times  \n",
      "\n",
      "Test period = 6  Training loss = 1.6875  Test loss = 0.3378  Model updated 1 times  \n",
      "\n",
      "Test period = 7  Training loss = 1.6245  Test loss = 0.0820  Model updated 1 times  \n",
      "\n",
      "Test period = 8  Training loss = 1.6206  Test loss = 2.0544  Model updated 1 times  \n",
      "\n",
      "Test period = 9  Training loss = 1.5852  Test loss = 2.1472  Model updated 2 times  \n",
      "\n",
      "Test period = 10  Training loss = 1.5995  Test loss = 0.3432  Model updated 2 times  \n",
      "\n",
      "Test period = 11  Training loss = 1.5966  Test loss = 0.9307  Model updated 2 times  \n",
      "\n",
      "Test period = 12  Training loss = 1.5976  Test loss = 0.8064  Model updated 2 times  \n",
      "\n",
      "Test period = 13  Training loss = 1.5352  Test loss = 1.0659  Model updated 3 times  \n",
      "\n",
      "Test period = 14  Training loss = 1.5380  Test loss = 0.7886  Model updated 3 times  \n",
      "\n",
      "Test period = 15  Training loss = 1.5291  Test loss = 2.6145  Model updated 3 times  \n",
      "\n",
      "Test period = 16  Training loss = 1.5570  Test loss = 4.3289  Model updated 3 times  \n",
      "\n",
      "Test period = 17  Training loss = 1.6310  Test loss = 2.8984  Model updated 4 times  \n",
      "\n",
      "Test period = 18  Training loss = 1.6673  Test loss = 0.4489  Model updated 4 times  \n",
      "\n",
      "Test period = 19  Training loss = 1.6573  Test loss = 0.6091  Model updated 4 times  \n",
      "\n",
      "Test period = 20  Training loss = 1.5573  Test loss = 1.3753  Model updated 4 times  \n",
      "\n",
      "Test period = 21  Training loss = 1.5482  Test loss = 1.8584  Model updated 5 times  \n",
      "\n",
      "Test period = 22  Training loss = 1.5501  Test loss = 3.4198  Model updated 5 times  \n",
      "\n",
      "Test period = 23  Training loss = 1.6071  Test loss = 0.4638  Model updated 5 times  \n",
      "\n",
      "Test period = 24  Training loss = 1.6058  Test loss = 2.2172  Model updated 5 times  \n",
      "\n",
      "Test period = 25  Training loss = 1.6113  Test loss = 0.2251  Model updated 6 times  \n",
      "\n",
      "Test period = 26  Training loss = 1.6060  Test loss = 0.3363  Model updated 6 times  \n",
      "\n",
      "Test period = 27  Training loss = 1.6050  Test loss = 0.9810  Model updated 6 times  \n",
      "\n",
      "Test period = 28  Training loss = 1.6085  Test loss = 1.5246  Model updated 6 times  \n",
      "\n",
      "Test period = 29  Training loss = 1.5971  Test loss = 0.6373  Model updated 7 times  \n",
      "\n",
      "Test period = 30  Training loss = 1.5934  Test loss = 1.0070  Model updated 7 times  \n",
      "\n",
      "Test period = 31  Training loss = 1.5894  Test loss = 2.7470  Model updated 7 times  \n",
      "\n",
      "Test period = 32  Training loss = 1.5698  Test loss = 0.7084  Model updated 7 times  \n",
      "\n",
      "Test period = 33  Training loss = 1.5568  Test loss = 1.2881  Model updated 8 times  \n",
      "\n",
      "Test period = 34  Training loss = 1.5512  Test loss = 0.3702  Model updated 8 times  \n",
      "\n",
      "Test period = 35  Training loss = 1.4943  Test loss = 0.4368  Model updated 8 times  \n",
      "\n",
      "Test period = 36  Training loss = 1.4889  Test loss = 5.0120  Model updated 8 times  \n",
      "\n",
      "Test period = 37  Training loss = 1.5271  Test loss = 0.9871  Model updated 9 times  \n",
      "\n",
      "Test period = 38  Training loss = 1.4481  Test loss = 1.6739  Model updated 9 times  \n",
      "\n",
      "Test period = 39  Training loss = 1.4629  Test loss = 0.6495  Model updated 9 times  \n",
      "\n",
      "Test period = 40  Training loss = 1.4636  Test loss = 1.5171  Model updated 9 times  \n",
      "\n",
      "Test period = 41  Training loss = 1.4594  Test loss = 1.1758  Model updated 10 times  \n",
      "\n",
      "Test period = 42  Training loss = 1.4665  Test loss = 1.8684  Model updated 10 times  \n",
      "\n",
      "Test period = 43  Training loss = 1.4846  Test loss = 3.8777  Model updated 10 times  \n",
      "\n",
      "Test period = 44  Training loss = 1.5601  Test loss = 12.2121  Model updated 10 times  \n",
      "\n",
      "Test period = 45  Training loss = 2.1667  Test loss = 5.6002  Model updated 11 times  \n",
      "\n",
      "Test period = 46  Training loss = 2.2733  Test loss = 0.4907  Model updated 11 times  \n",
      "\n",
      "Test period = 47  Training loss = 2.2741  Test loss = 0.6406  Model updated 11 times  \n",
      "\n",
      "Test period = 48  Training loss = 2.2714  Test loss = 0.2916  Model updated 11 times  \n",
      "\n",
      "Test period = 49  Training loss = 2.2466  Test loss = 1.7220  Model updated 12 times  \n",
      "\n",
      "Test period = 50  Training loss = 2.2553  Test loss = 2.8893  Model updated 12 times  \n",
      "\n",
      "Test period = 51  Training loss = 2.2803  Test loss = 0.7841  Model updated 12 times  \n",
      "\n",
      "Test period = 52  Training loss = 2.2779  Test loss = 0.8584  Model updated 12 times  \n",
      "\n",
      "Test period = 53  Training loss = 2.2620  Test loss = 1.3812  Model updated 13 times  \n",
      "\n",
      "Test period = 54  Training loss = 2.2684  Test loss = 1.0154  Model updated 13 times  \n",
      "\n",
      "Test period = 55  Training loss = 2.2715  Test loss = 1.0404  Model updated 13 times  \n",
      "\n",
      "Test period = 56  Training loss = 2.2727  Test loss = 2.2282  Model updated 13 times  \n",
      "\n",
      "Test period = 57  Training loss = 2.2712  Test loss = 1.4499  Model updated 14 times  \n",
      "\n",
      "Test period = 58  Training loss = 2.2780  Test loss = 2.5970  Model updated 14 times  \n",
      "\n",
      "Test period = 59  Training loss = 2.2987  Test loss = 0.9370  Model updated 14 times  \n",
      "\n",
      "Test period = 60  Training loss = 2.3015  Test loss = 0.1653  Model updated 14 times  \n",
      "\n",
      "Test period = 61  Training loss = 2.2906  Test loss = 1.0511  Model updated 15 times  \n",
      "\n",
      "Test period = 62  Training loss = 2.2934  Test loss = 3.1842  Model updated 15 times  \n",
      "\n",
      "Test period = 63  Training loss = 2.3266  Test loss = 0.7496  Model updated 15 times  \n",
      "\n",
      "Test period = 64  Training loss = 2.3165  Test loss = 0.9100  Model updated 15 times  \n",
      "\n",
      "Test period = 65  Training loss = 2.3004  Test loss = 0.2978  Model updated 16 times  \n",
      "\n",
      "Test period = 66  Training loss = 2.2988  Test loss = 1.5195  Model updated 16 times  \n",
      "\n",
      "Test period = 67  Training loss = 2.2934  Test loss = 1.9090  Model updated 16 times  \n",
      "\n",
      "Test period = 68  Training loss = 2.2986  Test loss = 3.8430  Model updated 16 times  \n",
      "\n",
      "Test period = 69  Training loss = 2.3377  Test loss = 5.5209  Model updated 17 times  \n",
      "\n",
      "Test period = 70  Training loss = 2.4356  Test loss = 0.2235  Model updated 17 times  \n",
      "\n",
      "Test period = 71  Training loss = 2.4344  Test loss = 1.1174  Model updated 17 times  \n",
      "\n",
      "Test period = 72  Training loss = 2.4383  Test loss = 2.8748  Model updated 17 times  \n",
      "\n",
      "Test period = 73  Training loss = 2.4361  Test loss = 2.0920  Model updated 18 times  \n",
      "\n",
      "Test period = 74  Training loss = 2.4400  Test loss = 0.4538  Model updated 18 times  \n",
      "\n",
      "Test period = 75  Training loss = 2.4273  Test loss = 0.0730  Model updated 18 times  \n",
      "\n",
      "Test period = 76  Training loss = 2.4257  Test loss = 1.4962  Model updated 18 times  \n",
      "\n",
      "Test period = 77  Training loss = 2.3768  Test loss = 1.0423  Model updated 19 times  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "retrain_count = 0\n",
    "for t in range(len(test_target)):\n",
    "    x_test = np.reshape(test_features[t], newshape=(1,4,3))\n",
    "    y_test = test_target[t]\n",
    "    test_loss[t] = np.sqrt(sess.run(loss, feed_dict={x:x_test, y:y_test}))\n",
    "    yhat_update[t] = pred.eval(feed_dict={x:x_test})\n",
    "\n",
    "    x_train = all_features[t:(window_length+t)]\n",
    "    y_train = all_target[t:(window_length+t)]\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:x_test, y:y_test})\n",
    "    \n",
    "    print(\"Test period = {0:d}\".format(t+1),\n",
    "      \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "      \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "      \" Model updated {0:d} times\".format(retrain_count),\n",
    "      \" \\n\")\n",
    "\n",
    "    if (t+1)%4==0:\n",
    "        retrain_count += 1\n",
    "        for epoch in range(epoch_hat):\n",
    "            for i in range(total_batch):\n",
    "                optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f58bc330c90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: updating scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_update, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating scheme RMSE: 2.45653577717 \n",
      "Updating scheme MAE:  1.7023888006\n"
     ]
    }
   ],
   "source": [
    "rmse_update = np.sqrt(np.mean((yhat_update-test_target)**2))\n",
    "mae_update = np.mean(np.abs((yhat_update-test_target)))\n",
    "print(\"Updating scheme RMSE:\", rmse_update,\n",
    "     \"\\nUpdating scheme MAE: \", mae_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
