{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Directories\n",
    "MODEL_FOLDER = \"../../../models/lstm/\"\n",
    "MODEL_FILENAME = MODEL_FOLDER + \"4Q/64_units/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: model saver\n",
    "def saveModel(sess, MODEL_FILENAME):\n",
    "    if not os.path.exists(MODEL_FOLDER):\n",
    "        print('Creating path where to save model: ' + MODEL_FOLDER)\n",
    "        os.mkdir(MODEL_FOLDER)\n",
    "\n",
    "    #print('Saving model at: ' + MODEL_FILENAME)\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, MODEL_FILENAME)\n",
    "    #print('Model successfully saved.\\n')\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: model loader\n",
    "def loadModel(sess, MODEL_FILENAME):\n",
    "    if os.path.exists(MODEL_FILENAME + \".index\"):\n",
    "        print('Loading save model from: ' + MODEL_FILENAME)\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, MODEL_FILENAME)\n",
    "        print('Model successfully loaded.\\n')\n",
    "        return True\n",
    "    else:\n",
    "        print('Model file <<' + MODEL_FILENAME + '>> does not exists!')\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Hyperparameters\n",
    "epochs = 500\n",
    "learning_rate = 1e-5\n",
    "batch_size = 5\n",
    "early_stop_iters = 10\n",
    "folds = 32\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 3  # data input\n",
    "n_steps = 4  # timesteps\n",
    "n_hidden = 64 # dimension of recurrent unit\n",
    "\n",
    "# (REPRODUCIBILITY) set random seeds\n",
    "tf.set_random_seed(123)\n",
    "\n",
    "# Define weights and biases\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.truncated_normal([n_hidden, 1], stddev = 1.0 / tf.sqrt(float(n_hidden))),\n",
    "        name='out_weight')\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.zeros([1]),\n",
    "        name='out_bias')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: Build model\n",
    "def RNN(X, weights, biases, n_hidden):\n",
    "\n",
    "    # Define a LSTM cell with tensorflow\n",
    "    lstm_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden, state_is_tuple=True)\n",
    "    outputs, _ = tf.nn.dynamic_rnn(lstm_cell, X, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    out_layer = tf.matmul(outputs[:,-1,:], weights['out']) + biases['out']\n",
    "\n",
    "    return out_layer\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: select batch\n",
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the data...\n",
      "Finished: data loaded. Stats below: \n",
      "Nr of training samples: 193\n",
      "Nr of testing  samples: 77\n",
      "Number of variables: 3\n",
      "Number of lags: 4\n",
      "Window length: 65\n",
      "Number of validation folds: 32\n"
     ]
    }
   ],
   "source": [
    "# =================================\n",
    "# 0. Load dataset\n",
    "# =================================\n",
    "print(\"Loading the data...\")\n",
    "# Training set pre-processing\n",
    "train = pd.read_csv('../../../Data/train.csv')\n",
    "train_4lag_inflation = np.array(train[['inflation.lag4',\n",
    "                                       'inflation.lag5',\n",
    "                                       'inflation.lag6',\n",
    "                                       'inflation.lag7']])\n",
    "train_4lag_unemp = np.array(train[['unemp.lag4',\n",
    "                                   'unemp.lag5',\n",
    "                                   'unemp.lag6',\n",
    "                                   'unemp.lag7']])\n",
    "train_4lag_oil = np.array(train[['oil.lag4',\n",
    "                                 'oil.lag5',\n",
    "                                 'oil.lag6',\n",
    "                                 'oil.lag7']])\n",
    "train_features = np.concatenate((train_4lag_inflation[:,:,np.newaxis], \n",
    "\t                             train_4lag_unemp[:,:,np.newaxis],\n",
    "\t                             train_4lag_oil[:,:,np.newaxis]),\n",
    "\t                             axis=2)\n",
    "train_target = np.array(train['inflation.target'])\n",
    "\n",
    "# Test set pre-processing\n",
    "test = pd.read_csv('../../../Data/test.csv')\n",
    "test_4lag_inflation = np.array(test[['inflation.lag4',\n",
    "                                     'inflation.lag5',\n",
    "                                     'inflation.lag6',\n",
    "                                     'inflation.lag7']])\n",
    "test_4lag_unemp = np.array(test[['unemp.lag4',\n",
    "                                 'unemp.lag5',\n",
    "                                 'unemp.lag6',\n",
    "                                 'unemp.lag7']])\n",
    "test_4lag_oil = np.array(test[['oil.lag4',\n",
    "                               'oil.lag5',\n",
    "                               'oil.lag6',\n",
    "                               'oil.lag7']])\n",
    "test_features = np.concatenate((test_4lag_inflation[:,:,np.newaxis], \n",
    "\t                            test_4lag_unemp[:,:,np.newaxis],\n",
    "\t                            test_4lag_oil[:,:,np.newaxis]),\n",
    "\t                            axis=2)\n",
    "test_target = np.array(test['inflation.target'])\n",
    "\n",
    "(nrTrainSamples, timesteps, variables) = train_features.shape\n",
    "(nrTestSamples, _, _) = test_features.shape\n",
    "\n",
    "# Window length and validation fold index\n",
    "window_length = 65\n",
    "valIndex = np.linspace(start=window_length, stop=nrTrainSamples, \n",
    "                       endpoint=True, num=folds+1, dtype=np.int)\n",
    "\n",
    "print(\"Finished: data loaded. Stats below: \")\n",
    "print(\"Nr of training samples: %d\" % nrTrainSamples)\n",
    "print(\"Nr of testing  samples: %d\" % nrTestSamples)\n",
    "print(\"Number of variables: %d\" % variables)\n",
    "print(\"Number of lags: %d\" % timesteps)\n",
    "print(\"Window length: %d\" % window_length)\n",
    "print(\"Number of validation folds: %d\" % folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 1. Build model\n",
    "# ==================================\n",
    "# tf graph input\n",
    "x = tf.placeholder(\"float\", [None, n_steps, n_input], name='Batch')\n",
    "y = tf.placeholder(\"float\", name='True_labels_of_batch')\n",
    "lr = tf.placeholder(\"float\", name='Learning_rate')\n",
    "\n",
    "# Make predictions with the model\n",
    "pred = RNN(x, weights, biases, n_hidden)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss = tf.reduce_mean(tf.diag_part(tf.square(tf.subtract(x=pred, y=y))))\n",
    "optimizer = tf.train.GradientDescentOptimizer(lr).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training \n",
      "Hyperparameters: \n",
      "Dimension of recurrent unit = 64 \n",
      "Learning rate = 1e-05 \n",
      "Epochs = 500 \n",
      "Batch size = 5 \n",
      "Early stopping epochs = 10 \n",
      "Learning rate = 1e-05\n",
      "Fold: 1  Epoch: 1  Training loss = 3.2823  Validation loss = 3.5067  \n",
      "\n",
      "Fold: 1  Epoch: 2  Training loss = 3.2791  Validation loss = 3.5013  \n",
      "\n",
      "Fold: 1  Epoch: 3  Training loss = 3.2763  Validation loss = 3.4966  \n",
      "\n",
      "Fold: 1  Epoch: 4  Training loss = 3.2740  Validation loss = 3.4927  \n",
      "\n",
      "Fold: 1  Epoch: 5  Training loss = 3.2713  Validation loss = 3.4880  \n",
      "\n",
      "Fold: 1  Epoch: 6  Training loss = 3.2694  Validation loss = 3.4847  \n",
      "\n",
      "Fold: 1  Epoch: 7  Training loss = 3.2664  Validation loss = 3.4797  \n",
      "\n",
      "Fold: 1  Epoch: 8  Training loss = 3.2640  Validation loss = 3.4756  \n",
      "\n",
      "Fold: 1  Epoch: 9  Training loss = 3.2614  Validation loss = 3.4711  \n",
      "\n",
      "Fold: 1  Epoch: 10  Training loss = 3.2593  Validation loss = 3.4675  \n",
      "\n",
      "Fold: 1  Epoch: 11  Training loss = 3.2565  Validation loss = 3.4629  \n",
      "\n",
      "Fold: 1  Epoch: 12  Training loss = 3.2546  Validation loss = 3.4594  \n",
      "\n",
      "Fold: 1  Epoch: 13  Training loss = 3.2517  Validation loss = 3.4545  \n",
      "\n",
      "Fold: 1  Epoch: 14  Training loss = 3.2483  Validation loss = 3.4487  \n",
      "\n",
      "Fold: 1  Epoch: 15  Training loss = 3.2468  Validation loss = 3.4461  \n",
      "\n",
      "Fold: 1  Epoch: 16  Training loss = 3.2446  Validation loss = 3.4421  \n",
      "\n",
      "Fold: 1  Epoch: 17  Training loss = 3.2427  Validation loss = 3.4386  \n",
      "\n",
      "Fold: 1  Epoch: 18  Training loss = 3.2402  Validation loss = 3.4343  \n",
      "\n",
      "Fold: 1  Epoch: 19  Training loss = 3.2383  Validation loss = 3.4309  \n",
      "\n",
      "Fold: 1  Epoch: 20  Training loss = 3.2353  Validation loss = 3.4258  \n",
      "\n",
      "Fold: 1  Epoch: 21  Training loss = 3.2327  Validation loss = 3.4210  \n",
      "\n",
      "Fold: 1  Epoch: 22  Training loss = 3.2301  Validation loss = 3.4165  \n",
      "\n",
      "Fold: 1  Epoch: 23  Training loss = 3.2279  Validation loss = 3.4126  \n",
      "\n",
      "Fold: 1  Epoch: 24  Training loss = 3.2261  Validation loss = 3.4091  \n",
      "\n",
      "Fold: 1  Epoch: 25  Training loss = 3.2237  Validation loss = 3.4050  \n",
      "\n",
      "Fold: 1  Epoch: 26  Training loss = 3.2213  Validation loss = 3.4008  \n",
      "\n",
      "Fold: 1  Epoch: 27  Training loss = 3.2195  Validation loss = 3.3974  \n",
      "\n",
      "Fold: 1  Epoch: 28  Training loss = 3.2177  Validation loss = 3.3941  \n",
      "\n",
      "Fold: 1  Epoch: 29  Training loss = 3.2156  Validation loss = 3.3902  \n",
      "\n",
      "Fold: 1  Epoch: 30  Training loss = 3.2131  Validation loss = 3.3858  \n",
      "\n",
      "Fold: 1  Epoch: 31  Training loss = 3.2101  Validation loss = 3.3806  \n",
      "\n",
      "Fold: 1  Epoch: 32  Training loss = 3.2081  Validation loss = 3.3769  \n",
      "\n",
      "Fold: 1  Epoch: 33  Training loss = 3.2058  Validation loss = 3.3729  \n",
      "\n",
      "Fold: 1  Epoch: 34  Training loss = 3.2038  Validation loss = 3.3692  \n",
      "\n",
      "Fold: 1  Epoch: 35  Training loss = 3.2017  Validation loss = 3.3654  \n",
      "\n",
      "Fold: 1  Epoch: 36  Training loss = 3.1994  Validation loss = 3.3614  \n",
      "\n",
      "Fold: 1  Epoch: 37  Training loss = 3.1968  Validation loss = 3.3565  \n",
      "\n",
      "Fold: 1  Epoch: 38  Training loss = 3.1951  Validation loss = 3.3535  \n",
      "\n",
      "Fold: 1  Epoch: 39  Training loss = 3.1930  Validation loss = 3.3499  \n",
      "\n",
      "Fold: 1  Epoch: 40  Training loss = 3.1904  Validation loss = 3.3452  \n",
      "\n",
      "Fold: 1  Epoch: 41  Training loss = 3.1883  Validation loss = 3.3413  \n",
      "\n",
      "Fold: 1  Epoch: 42  Training loss = 3.1863  Validation loss = 3.3375  \n",
      "\n",
      "Fold: 1  Epoch: 43  Training loss = 3.1842  Validation loss = 3.3335  \n",
      "\n",
      "Fold: 1  Epoch: 44  Training loss = 3.1821  Validation loss = 3.3297  \n",
      "\n",
      "Fold: 1  Epoch: 45  Training loss = 3.1798  Validation loss = 3.3256  \n",
      "\n",
      "Fold: 1  Epoch: 46  Training loss = 3.1774  Validation loss = 3.3212  \n",
      "\n",
      "Fold: 1  Epoch: 47  Training loss = 3.1750  Validation loss = 3.3170  \n",
      "\n",
      "Fold: 1  Epoch: 48  Training loss = 3.1726  Validation loss = 3.3127  \n",
      "\n",
      "Fold: 1  Epoch: 49  Training loss = 3.1704  Validation loss = 3.3085  \n",
      "\n",
      "Fold: 1  Epoch: 50  Training loss = 3.1682  Validation loss = 3.3045  \n",
      "\n",
      "Fold: 1  Epoch: 51  Training loss = 3.1659  Validation loss = 3.3004  \n",
      "\n",
      "Fold: 1  Epoch: 52  Training loss = 3.1635  Validation loss = 3.2961  \n",
      "\n",
      "Fold: 1  Epoch: 53  Training loss = 3.1610  Validation loss = 3.2915  \n",
      "\n",
      "Fold: 1  Epoch: 54  Training loss = 3.1596  Validation loss = 3.2887  \n",
      "\n",
      "Fold: 1  Epoch: 55  Training loss = 3.1571  Validation loss = 3.2842  \n",
      "\n",
      "Fold: 1  Epoch: 56  Training loss = 3.1553  Validation loss = 3.2809  \n",
      "\n",
      "Fold: 1  Epoch: 57  Training loss = 3.1535  Validation loss = 3.2775  \n",
      "\n",
      "Fold: 1  Epoch: 58  Training loss = 3.1511  Validation loss = 3.2732  \n",
      "\n",
      "Fold: 1  Epoch: 59  Training loss = 3.1488  Validation loss = 3.2689  \n",
      "\n",
      "Fold: 1  Epoch: 60  Training loss = 3.1461  Validation loss = 3.2641  \n",
      "\n",
      "Fold: 1  Epoch: 61  Training loss = 3.1446  Validation loss = 3.2611  \n",
      "\n",
      "Fold: 1  Epoch: 62  Training loss = 3.1428  Validation loss = 3.2577  \n",
      "\n",
      "Fold: 1  Epoch: 63  Training loss = 3.1412  Validation loss = 3.2547  \n",
      "\n",
      "Fold: 1  Epoch: 64  Training loss = 3.1391  Validation loss = 3.2508  \n",
      "\n",
      "Fold: 1  Epoch: 65  Training loss = 3.1367  Validation loss = 3.2462  \n",
      "\n",
      "Fold: 1  Epoch: 66  Training loss = 3.1348  Validation loss = 3.2429  \n",
      "\n",
      "Fold: 1  Epoch: 67  Training loss = 3.1326  Validation loss = 3.2386  \n",
      "\n",
      "Fold: 1  Epoch: 68  Training loss = 3.1306  Validation loss = 3.2350  \n",
      "\n",
      "Fold: 1  Epoch: 69  Training loss = 3.1292  Validation loss = 3.2322  \n",
      "\n",
      "Fold: 1  Epoch: 70  Training loss = 3.1268  Validation loss = 3.2277  \n",
      "\n",
      "Fold: 1  Epoch: 71  Training loss = 3.1250  Validation loss = 3.2244  \n",
      "\n",
      "Fold: 1  Epoch: 72  Training loss = 3.1235  Validation loss = 3.2215  \n",
      "\n",
      "Fold: 1  Epoch: 73  Training loss = 3.1215  Validation loss = 3.2176  \n",
      "\n",
      "Fold: 1  Epoch: 74  Training loss = 3.1190  Validation loss = 3.2130  \n",
      "\n",
      "Fold: 1  Epoch: 75  Training loss = 3.1171  Validation loss = 3.2090  \n",
      "\n",
      "Fold: 1  Epoch: 76  Training loss = 3.1152  Validation loss = 3.2054  \n",
      "\n",
      "Fold: 1  Epoch: 77  Training loss = 3.1133  Validation loss = 3.2019  \n",
      "\n",
      "Fold: 1  Epoch: 78  Training loss = 3.1115  Validation loss = 3.1984  \n",
      "\n",
      "Fold: 1  Epoch: 79  Training loss = 3.1099  Validation loss = 3.1955  \n",
      "\n",
      "Fold: 1  Epoch: 80  Training loss = 3.1087  Validation loss = 3.1931  \n",
      "\n",
      "Fold: 1  Epoch: 81  Training loss = 3.1067  Validation loss = 3.1892  \n",
      "\n",
      "Fold: 1  Epoch: 82  Training loss = 3.1042  Validation loss = 3.1845  \n",
      "\n",
      "Fold: 1  Epoch: 83  Training loss = 3.1016  Validation loss = 3.1797  \n",
      "\n",
      "Fold: 1  Epoch: 84  Training loss = 3.1002  Validation loss = 3.1769  \n",
      "\n",
      "Fold: 1  Epoch: 85  Training loss = 3.0984  Validation loss = 3.1736  \n",
      "\n",
      "Fold: 1  Epoch: 86  Training loss = 3.0964  Validation loss = 3.1698  \n",
      "\n",
      "Fold: 1  Epoch: 87  Training loss = 3.0942  Validation loss = 3.1658  \n",
      "\n",
      "Fold: 1  Epoch: 88  Training loss = 3.0927  Validation loss = 3.1628  \n",
      "\n",
      "Fold: 1  Epoch: 89  Training loss = 3.0907  Validation loss = 3.1590  \n",
      "\n",
      "Fold: 1  Epoch: 90  Training loss = 3.0888  Validation loss = 3.1553  \n",
      "\n",
      "Fold: 1  Epoch: 91  Training loss = 3.0872  Validation loss = 3.1521  \n",
      "\n",
      "Fold: 1  Epoch: 92  Training loss = 3.0857  Validation loss = 3.1489  \n",
      "\n",
      "Fold: 1  Epoch: 93  Training loss = 3.0840  Validation loss = 3.1457  \n",
      "\n",
      "Fold: 1  Epoch: 94  Training loss = 3.0821  Validation loss = 3.1418  \n",
      "\n",
      "Fold: 1  Epoch: 95  Training loss = 3.0802  Validation loss = 3.1382  \n",
      "\n",
      "Fold: 1  Epoch: 96  Training loss = 3.0788  Validation loss = 3.1354  \n",
      "\n",
      "Fold: 1  Epoch: 97  Training loss = 3.0769  Validation loss = 3.1317  \n",
      "\n",
      "Fold: 1  Epoch: 98  Training loss = 3.0745  Validation loss = 3.1272  \n",
      "\n",
      "Fold: 1  Epoch: 99  Training loss = 3.0726  Validation loss = 3.1236  \n",
      "\n",
      "Fold: 1  Epoch: 100  Training loss = 3.0713  Validation loss = 3.1210  \n",
      "\n",
      "Fold: 1  Epoch: 101  Training loss = 3.0701  Validation loss = 3.1186  \n",
      "\n",
      "Fold: 1  Epoch: 102  Training loss = 3.0687  Validation loss = 3.1160  \n",
      "\n",
      "Fold: 1  Epoch: 103  Training loss = 3.0668  Validation loss = 3.1121  \n",
      "\n",
      "Fold: 1  Epoch: 104  Training loss = 3.0653  Validation loss = 3.1090  \n",
      "\n",
      "Fold: 1  Epoch: 105  Training loss = 3.0630  Validation loss = 3.1044  \n",
      "\n",
      "Fold: 1  Epoch: 106  Training loss = 3.0612  Validation loss = 3.1006  \n",
      "\n",
      "Fold: 1  Epoch: 107  Training loss = 3.0592  Validation loss = 3.0967  \n",
      "\n",
      "Fold: 1  Epoch: 108  Training loss = 3.0568  Validation loss = 3.0922  \n",
      "\n",
      "Fold: 1  Epoch: 109  Training loss = 3.0556  Validation loss = 3.0897  \n",
      "\n",
      "Fold: 1  Epoch: 110  Training loss = 3.0540  Validation loss = 3.0865  \n",
      "\n",
      "Fold: 1  Epoch: 111  Training loss = 3.0524  Validation loss = 3.0833  \n",
      "\n",
      "Fold: 1  Epoch: 112  Training loss = 3.0502  Validation loss = 3.0792  \n",
      "\n",
      "Fold: 1  Epoch: 113  Training loss = 3.0481  Validation loss = 3.0749  \n",
      "\n",
      "Fold: 1  Epoch: 114  Training loss = 3.0459  Validation loss = 3.0703  \n",
      "\n",
      "Fold: 1  Epoch: 115  Training loss = 3.0443  Validation loss = 3.0671  \n",
      "\n",
      "Fold: 1  Epoch: 116  Training loss = 3.0427  Validation loss = 3.0638  \n",
      "\n",
      "Fold: 1  Epoch: 117  Training loss = 3.0408  Validation loss = 3.0601  \n",
      "\n",
      "Fold: 1  Epoch: 118  Training loss = 3.0394  Validation loss = 3.0573  \n",
      "\n",
      "Fold: 1  Epoch: 119  Training loss = 3.0379  Validation loss = 3.0541  \n",
      "\n",
      "Fold: 1  Epoch: 120  Training loss = 3.0361  Validation loss = 3.0507  \n",
      "\n",
      "Fold: 1  Epoch: 121  Training loss = 3.0349  Validation loss = 3.0483  \n",
      "\n",
      "Fold: 1  Epoch: 122  Training loss = 3.0333  Validation loss = 3.0448  \n",
      "\n",
      "Fold: 1  Epoch: 123  Training loss = 3.0320  Validation loss = 3.0422  \n",
      "\n",
      "Fold: 1  Epoch: 124  Training loss = 3.0305  Validation loss = 3.0391  \n",
      "\n",
      "Fold: 1  Epoch: 125  Training loss = 3.0288  Validation loss = 3.0356  \n",
      "\n",
      "Fold: 1  Epoch: 126  Training loss = 3.0278  Validation loss = 3.0336  \n",
      "\n",
      "Fold: 1  Epoch: 127  Training loss = 3.0264  Validation loss = 3.0308  \n",
      "\n",
      "Fold: 1  Epoch: 128  Training loss = 3.0250  Validation loss = 3.0279  \n",
      "\n",
      "Fold: 1  Epoch: 129  Training loss = 3.0230  Validation loss = 3.0239  \n",
      "\n",
      "Fold: 1  Epoch: 130  Training loss = 3.0208  Validation loss = 3.0195  \n",
      "\n",
      "Fold: 1  Epoch: 131  Training loss = 3.0189  Validation loss = 3.0156  \n",
      "\n",
      "Fold: 1  Epoch: 132  Training loss = 3.0170  Validation loss = 3.0120  \n",
      "\n",
      "Fold: 1  Epoch: 133  Training loss = 3.0154  Validation loss = 3.0085  \n",
      "\n",
      "Fold: 1  Epoch: 134  Training loss = 3.0144  Validation loss = 3.0066  \n",
      "\n",
      "Fold: 1  Epoch: 135  Training loss = 3.0131  Validation loss = 3.0038  \n",
      "\n",
      "Fold: 1  Epoch: 136  Training loss = 3.0107  Validation loss = 2.9989  \n",
      "\n",
      "Fold: 1  Epoch: 137  Training loss = 3.0084  Validation loss = 2.9943  \n",
      "\n",
      "Fold: 1  Epoch: 138  Training loss = 3.0069  Validation loss = 2.9911  \n",
      "\n",
      "Fold: 1  Epoch: 139  Training loss = 3.0053  Validation loss = 2.9879  \n",
      "\n",
      "Fold: 1  Epoch: 140  Training loss = 3.0034  Validation loss = 2.9839  \n",
      "\n",
      "Fold: 1  Epoch: 141  Training loss = 3.0019  Validation loss = 2.9808  \n",
      "\n",
      "Fold: 1  Epoch: 142  Training loss = 3.0003  Validation loss = 2.9774  \n",
      "\n",
      "Fold: 1  Epoch: 143  Training loss = 2.9989  Validation loss = 2.9744  \n",
      "\n",
      "Fold: 1  Epoch: 144  Training loss = 2.9981  Validation loss = 2.9725  \n",
      "\n",
      "Fold: 1  Epoch: 145  Training loss = 2.9969  Validation loss = 2.9700  \n",
      "\n",
      "Fold: 1  Epoch: 146  Training loss = 2.9954  Validation loss = 2.9669  \n",
      "\n",
      "Fold: 1  Epoch: 147  Training loss = 2.9935  Validation loss = 2.9631  \n",
      "\n",
      "Fold: 1  Epoch: 148  Training loss = 2.9924  Validation loss = 2.9604  \n",
      "\n",
      "Fold: 1  Epoch: 149  Training loss = 2.9909  Validation loss = 2.9571  \n",
      "\n",
      "Fold: 1  Epoch: 150  Training loss = 2.9896  Validation loss = 2.9543  \n",
      "\n",
      "Fold: 1  Epoch: 151  Training loss = 2.9887  Validation loss = 2.9523  \n",
      "\n",
      "Fold: 1  Epoch: 152  Training loss = 2.9878  Validation loss = 2.9505  \n",
      "\n",
      "Fold: 1  Epoch: 153  Training loss = 2.9867  Validation loss = 2.9482  \n",
      "\n",
      "Fold: 1  Epoch: 154  Training loss = 2.9853  Validation loss = 2.9453  \n",
      "\n",
      "Fold: 1  Epoch: 155  Training loss = 2.9837  Validation loss = 2.9419  \n",
      "\n",
      "Fold: 1  Epoch: 156  Training loss = 2.9822  Validation loss = 2.9387  \n",
      "\n",
      "Fold: 1  Epoch: 157  Training loss = 2.9812  Validation loss = 2.9365  \n",
      "\n",
      "Fold: 1  Epoch: 158  Training loss = 2.9801  Validation loss = 2.9340  \n",
      "\n",
      "Fold: 1  Epoch: 159  Training loss = 2.9791  Validation loss = 2.9318  \n",
      "\n",
      "Fold: 1  Epoch: 160  Training loss = 2.9777  Validation loss = 2.9287  \n",
      "\n",
      "Fold: 1  Epoch: 161  Training loss = 2.9768  Validation loss = 2.9268  \n",
      "\n",
      "Fold: 1  Epoch: 162  Training loss = 2.9761  Validation loss = 2.9253  \n",
      "\n",
      "Fold: 1  Epoch: 163  Training loss = 2.9751  Validation loss = 2.9230  \n",
      "\n",
      "Fold: 1  Epoch: 164  Training loss = 2.9740  Validation loss = 2.9205  \n",
      "\n",
      "Fold: 1  Epoch: 165  Training loss = 2.9720  Validation loss = 2.9163  \n",
      "\n",
      "Fold: 1  Epoch: 166  Training loss = 2.9702  Validation loss = 2.9123  \n",
      "\n",
      "Fold: 1  Epoch: 167  Training loss = 2.9693  Validation loss = 2.9102  \n",
      "\n",
      "Fold: 1  Epoch: 168  Training loss = 2.9680  Validation loss = 2.9071  \n",
      "\n",
      "Fold: 1  Epoch: 169  Training loss = 2.9665  Validation loss = 2.9037  \n",
      "\n",
      "Fold: 1  Epoch: 170  Training loss = 2.9654  Validation loss = 2.9014  \n",
      "\n",
      "Fold: 1  Epoch: 171  Training loss = 2.9650  Validation loss = 2.9004  \n",
      "\n",
      "Fold: 1  Epoch: 172  Training loss = 2.9641  Validation loss = 2.8985  \n",
      "\n",
      "Fold: 1  Epoch: 173  Training loss = 2.9626  Validation loss = 2.8953  \n",
      "\n",
      "Fold: 1  Epoch: 174  Training loss = 2.9613  Validation loss = 2.8923  \n",
      "\n",
      "Fold: 1  Epoch: 175  Training loss = 2.9602  Validation loss = 2.8898  \n",
      "\n",
      "Fold: 1  Epoch: 176  Training loss = 2.9585  Validation loss = 2.8860  \n",
      "\n",
      "Fold: 1  Epoch: 177  Training loss = 2.9573  Validation loss = 2.8835  \n",
      "\n",
      "Fold: 1  Epoch: 178  Training loss = 2.9567  Validation loss = 2.8820  \n",
      "\n",
      "Fold: 1  Epoch: 179  Training loss = 2.9555  Validation loss = 2.8793  \n",
      "\n",
      "Fold: 1  Epoch: 180  Training loss = 2.9535  Validation loss = 2.8750  \n",
      "\n",
      "Fold: 1  Epoch: 181  Training loss = 2.9525  Validation loss = 2.8729  \n",
      "\n",
      "Fold: 1  Epoch: 182  Training loss = 2.9505  Validation loss = 2.8684  \n",
      "\n",
      "Fold: 1  Epoch: 183  Training loss = 2.9497  Validation loss = 2.8667  \n",
      "\n",
      "Fold: 1  Epoch: 184  Training loss = 2.9489  Validation loss = 2.8648  \n",
      "\n",
      "Fold: 1  Epoch: 185  Training loss = 2.9479  Validation loss = 2.8624  \n",
      "\n",
      "Fold: 1  Epoch: 186  Training loss = 2.9465  Validation loss = 2.8594  \n",
      "\n",
      "Fold: 1  Epoch: 187  Training loss = 2.9452  Validation loss = 2.8564  \n",
      "\n",
      "Fold: 1  Epoch: 188  Training loss = 2.9436  Validation loss = 2.8529  \n",
      "\n",
      "Fold: 1  Epoch: 189  Training loss = 2.9424  Validation loss = 2.8501  \n",
      "\n",
      "Fold: 1  Epoch: 190  Training loss = 2.9414  Validation loss = 2.8478  \n",
      "\n",
      "Fold: 1  Epoch: 191  Training loss = 2.9404  Validation loss = 2.8456  \n",
      "\n",
      "Fold: 1  Epoch: 192  Training loss = 2.9388  Validation loss = 2.8420  \n",
      "\n",
      "Fold: 1  Epoch: 193  Training loss = 2.9379  Validation loss = 2.8398  \n",
      "\n",
      "Fold: 1  Epoch: 194  Training loss = 2.9371  Validation loss = 2.8378  \n",
      "\n",
      "Fold: 1  Epoch: 195  Training loss = 2.9359  Validation loss = 2.8352  \n",
      "\n",
      "Fold: 1  Epoch: 196  Training loss = 2.9348  Validation loss = 2.8326  \n",
      "\n",
      "Fold: 1  Epoch: 197  Training loss = 2.9334  Validation loss = 2.8295  \n",
      "\n",
      "Fold: 1  Epoch: 198  Training loss = 2.9319  Validation loss = 2.8261  \n",
      "\n",
      "Fold: 1  Epoch: 199  Training loss = 2.9312  Validation loss = 2.8246  \n",
      "\n",
      "Fold: 1  Epoch: 200  Training loss = 2.9294  Validation loss = 2.8204  \n",
      "\n",
      "Fold: 1  Epoch: 201  Training loss = 2.9276  Validation loss = 2.8164  \n",
      "\n",
      "Fold: 1  Epoch: 202  Training loss = 2.9261  Validation loss = 2.8130  \n",
      "\n",
      "Fold: 1  Epoch: 203  Training loss = 2.9254  Validation loss = 2.8114  \n",
      "\n",
      "Fold: 1  Epoch: 204  Training loss = 2.9247  Validation loss = 2.8097  \n",
      "\n",
      "Fold: 1  Epoch: 205  Training loss = 2.9234  Validation loss = 2.8069  \n",
      "\n",
      "Fold: 1  Epoch: 206  Training loss = 2.9219  Validation loss = 2.8034  \n",
      "\n",
      "Fold: 1  Epoch: 207  Training loss = 2.9211  Validation loss = 2.8014  \n",
      "\n",
      "Fold: 1  Epoch: 208  Training loss = 2.9199  Validation loss = 2.7987  \n",
      "\n",
      "Fold: 1  Epoch: 209  Training loss = 2.9193  Validation loss = 2.7972  \n",
      "\n",
      "Fold: 1  Epoch: 210  Training loss = 2.9180  Validation loss = 2.7940  \n",
      "\n",
      "Fold: 1  Epoch: 211  Training loss = 2.9160  Validation loss = 2.7894  \n",
      "\n",
      "Fold: 1  Epoch: 212  Training loss = 2.9154  Validation loss = 2.7881  \n",
      "\n",
      "Fold: 1  Epoch: 213  Training loss = 2.9136  Validation loss = 2.7839  \n",
      "\n",
      "Fold: 1  Epoch: 214  Training loss = 2.9126  Validation loss = 2.7817  \n",
      "\n",
      "Fold: 1  Epoch: 215  Training loss = 2.9116  Validation loss = 2.7792  \n",
      "\n",
      "Fold: 1  Epoch: 216  Training loss = 2.9104  Validation loss = 2.7763  \n",
      "\n",
      "Fold: 1  Epoch: 217  Training loss = 2.9087  Validation loss = 2.7725  \n",
      "\n",
      "Fold: 1  Epoch: 218  Training loss = 2.9078  Validation loss = 2.7706  \n",
      "\n",
      "Fold: 1  Epoch: 219  Training loss = 2.9070  Validation loss = 2.7685  \n",
      "\n",
      "Fold: 1  Epoch: 220  Training loss = 2.9063  Validation loss = 2.7669  \n",
      "\n",
      "Fold: 1  Epoch: 221  Training loss = 2.9052  Validation loss = 2.7642  \n",
      "\n",
      "Fold: 1  Epoch: 222  Training loss = 2.9039  Validation loss = 2.7612  \n",
      "\n",
      "Fold: 1  Epoch: 223  Training loss = 2.9029  Validation loss = 2.7589  \n",
      "\n",
      "Fold: 1  Epoch: 224  Training loss = 2.9015  Validation loss = 2.7556  \n",
      "\n",
      "Fold: 1  Epoch: 225  Training loss = 2.9006  Validation loss = 2.7536  \n",
      "\n",
      "Fold: 1  Epoch: 226  Training loss = 2.8993  Validation loss = 2.7505  \n",
      "\n",
      "Fold: 1  Epoch: 227  Training loss = 2.8982  Validation loss = 2.7477  \n",
      "\n",
      "Fold: 1  Epoch: 228  Training loss = 2.8969  Validation loss = 2.7447  \n",
      "\n",
      "Fold: 1  Epoch: 229  Training loss = 2.8958  Validation loss = 2.7420  \n",
      "\n",
      "Fold: 1  Epoch: 230  Training loss = 2.8941  Validation loss = 2.7383  \n",
      "\n",
      "Fold: 1  Epoch: 231  Training loss = 2.8925  Validation loss = 2.7346  \n",
      "\n",
      "Fold: 1  Epoch: 232  Training loss = 2.8917  Validation loss = 2.7324  \n",
      "\n",
      "Fold: 1  Epoch: 233  Training loss = 2.8908  Validation loss = 2.7304  \n",
      "\n",
      "Fold: 1  Epoch: 234  Training loss = 2.8896  Validation loss = 2.7276  \n",
      "\n",
      "Fold: 1  Epoch: 235  Training loss = 2.8884  Validation loss = 2.7248  \n",
      "\n",
      "Fold: 1  Epoch: 236  Training loss = 2.8873  Validation loss = 2.7222  \n",
      "\n",
      "Fold: 1  Epoch: 237  Training loss = 2.8861  Validation loss = 2.7193  \n",
      "\n",
      "Fold: 1  Epoch: 238  Training loss = 2.8850  Validation loss = 2.7165  \n",
      "\n",
      "Fold: 1  Epoch: 239  Training loss = 2.8839  Validation loss = 2.7140  \n",
      "\n",
      "Fold: 1  Epoch: 240  Training loss = 2.8832  Validation loss = 2.7120  \n",
      "\n",
      "Fold: 1  Epoch: 241  Training loss = 2.8824  Validation loss = 2.7102  \n",
      "\n",
      "Fold: 1  Epoch: 242  Training loss = 2.8814  Validation loss = 2.7078  \n",
      "\n",
      "Fold: 1  Epoch: 243  Training loss = 2.8802  Validation loss = 2.7048  \n",
      "\n",
      "Fold: 1  Epoch: 244  Training loss = 2.8791  Validation loss = 2.7022  \n",
      "\n",
      "Fold: 1  Epoch: 245  Training loss = 2.8778  Validation loss = 2.6991  \n",
      "\n",
      "Fold: 1  Epoch: 246  Training loss = 2.8771  Validation loss = 2.6971  \n",
      "\n",
      "Fold: 1  Epoch: 247  Training loss = 2.8757  Validation loss = 2.6939  \n",
      "\n",
      "Fold: 1  Epoch: 248  Training loss = 2.8743  Validation loss = 2.6904  \n",
      "\n",
      "Fold: 1  Epoch: 249  Training loss = 2.8733  Validation loss = 2.6879  \n",
      "\n",
      "Fold: 1  Epoch: 250  Training loss = 2.8723  Validation loss = 2.6853  \n",
      "\n",
      "Fold: 1  Epoch: 251  Training loss = 2.8711  Validation loss = 2.6824  \n",
      "\n",
      "Fold: 1  Epoch: 252  Training loss = 2.8703  Validation loss = 2.6802  \n",
      "\n",
      "Fold: 1  Epoch: 253  Training loss = 2.8692  Validation loss = 2.6776  \n",
      "\n",
      "Fold: 1  Epoch: 254  Training loss = 2.8681  Validation loss = 2.6751  \n",
      "\n",
      "Fold: 1  Epoch: 255  Training loss = 2.8671  Validation loss = 2.6726  \n",
      "\n",
      "Fold: 1  Epoch: 256  Training loss = 2.8659  Validation loss = 2.6697  \n",
      "\n",
      "Fold: 1  Epoch: 257  Training loss = 2.8648  Validation loss = 2.6670  \n",
      "\n",
      "Fold: 1  Epoch: 258  Training loss = 2.8641  Validation loss = 2.6652  \n",
      "\n",
      "Fold: 1  Epoch: 259  Training loss = 2.8631  Validation loss = 2.6627  \n",
      "\n",
      "Fold: 1  Epoch: 260  Training loss = 2.8624  Validation loss = 2.6608  \n",
      "\n",
      "Fold: 1  Epoch: 261  Training loss = 2.8617  Validation loss = 2.6590  \n",
      "\n",
      "Fold: 1  Epoch: 262  Training loss = 2.8603  Validation loss = 2.6557  \n",
      "\n",
      "Fold: 1  Epoch: 263  Training loss = 2.8586  Validation loss = 2.6515  \n",
      "\n",
      "Fold: 1  Epoch: 264  Training loss = 2.8579  Validation loss = 2.6496  \n",
      "\n",
      "Fold: 1  Epoch: 265  Training loss = 2.8567  Validation loss = 2.6467  \n",
      "\n",
      "Fold: 1  Epoch: 266  Training loss = 2.8552  Validation loss = 2.6428  \n",
      "\n",
      "Fold: 1  Epoch: 267  Training loss = 2.8543  Validation loss = 2.6407  \n",
      "\n",
      "Fold: 1  Epoch: 268  Training loss = 2.8534  Validation loss = 2.6383  \n",
      "\n",
      "Fold: 1  Epoch: 269  Training loss = 2.8527  Validation loss = 2.6365  \n",
      "\n",
      "Fold: 1  Epoch: 270  Training loss = 2.8513  Validation loss = 2.6331  \n",
      "\n",
      "Fold: 1  Epoch: 271  Training loss = 2.8505  Validation loss = 2.6312  \n",
      "\n",
      "Fold: 1  Epoch: 272  Training loss = 2.8496  Validation loss = 2.6291  \n",
      "\n",
      "Fold: 1  Epoch: 273  Training loss = 2.8488  Validation loss = 2.6268  \n",
      "\n",
      "Fold: 1  Epoch: 274  Training loss = 2.8479  Validation loss = 2.6246  \n",
      "\n",
      "Fold: 1  Epoch: 275  Training loss = 2.8474  Validation loss = 2.6232  \n",
      "\n",
      "Fold: 1  Epoch: 276  Training loss = 2.8467  Validation loss = 2.6215  \n",
      "\n",
      "Fold: 1  Epoch: 277  Training loss = 2.8459  Validation loss = 2.6194  \n",
      "\n",
      "Fold: 1  Epoch: 278  Training loss = 2.8454  Validation loss = 2.6181  \n",
      "\n",
      "Fold: 1  Epoch: 279  Training loss = 2.8447  Validation loss = 2.6163  \n",
      "\n",
      "Fold: 1  Epoch: 280  Training loss = 2.8438  Validation loss = 2.6139  \n",
      "\n",
      "Fold: 1  Epoch: 281  Training loss = 2.8433  Validation loss = 2.6127  \n",
      "\n",
      "Fold: 1  Epoch: 282  Training loss = 2.8422  Validation loss = 2.6098  \n",
      "\n",
      "Fold: 1  Epoch: 283  Training loss = 2.8416  Validation loss = 2.6082  \n",
      "\n",
      "Fold: 1  Epoch: 284  Training loss = 2.8409  Validation loss = 2.6062  \n",
      "\n",
      "Fold: 1  Epoch: 285  Training loss = 2.8404  Validation loss = 2.6048  \n",
      "\n",
      "Fold: 1  Epoch: 286  Training loss = 2.8394  Validation loss = 2.6024  \n",
      "\n",
      "Fold: 1  Epoch: 287  Training loss = 2.8383  Validation loss = 2.5995  \n",
      "\n",
      "Fold: 1  Epoch: 288  Training loss = 2.8373  Validation loss = 2.5970  \n",
      "\n",
      "Fold: 1  Epoch: 289  Training loss = 2.8366  Validation loss = 2.5950  \n",
      "\n",
      "Fold: 1  Epoch: 290  Training loss = 2.8358  Validation loss = 2.5929  \n",
      "\n",
      "Fold: 1  Epoch: 291  Training loss = 2.8344  Validation loss = 2.5892  \n",
      "\n",
      "Fold: 1  Epoch: 292  Training loss = 2.8335  Validation loss = 2.5867  \n",
      "\n",
      "Fold: 1  Epoch: 293  Training loss = 2.8330  Validation loss = 2.5854  \n",
      "\n",
      "Fold: 1  Epoch: 294  Training loss = 2.8324  Validation loss = 2.5841  \n",
      "\n",
      "Fold: 1  Epoch: 295  Training loss = 2.8314  Validation loss = 2.5811  \n",
      "\n",
      "Fold: 1  Epoch: 296  Training loss = 2.8296  Validation loss = 2.5769  \n",
      "\n",
      "Fold: 1  Epoch: 297  Training loss = 2.8290  Validation loss = 2.5753  \n",
      "\n",
      "Fold: 1  Epoch: 298  Training loss = 2.8284  Validation loss = 2.5738  \n",
      "\n",
      "Fold: 1  Epoch: 299  Training loss = 2.8274  Validation loss = 2.5713  \n",
      "\n",
      "Fold: 1  Epoch: 300  Training loss = 2.8269  Validation loss = 2.5698  \n",
      "\n",
      "Fold: 1  Epoch: 301  Training loss = 2.8262  Validation loss = 2.5678  \n",
      "\n",
      "Fold: 1  Epoch: 302  Training loss = 2.8256  Validation loss = 2.5661  \n",
      "\n",
      "Fold: 1  Epoch: 303  Training loss = 2.8242  Validation loss = 2.5623  \n",
      "\n",
      "Fold: 1  Epoch: 304  Training loss = 2.8232  Validation loss = 2.5598  \n",
      "\n",
      "Fold: 1  Epoch: 305  Training loss = 2.8223  Validation loss = 2.5575  \n",
      "\n",
      "Fold: 1  Epoch: 306  Training loss = 2.8212  Validation loss = 2.5545  \n",
      "\n",
      "Fold: 1  Epoch: 307  Training loss = 2.8203  Validation loss = 2.5523  \n",
      "\n",
      "Fold: 1  Epoch: 308  Training loss = 2.8198  Validation loss = 2.5509  \n",
      "\n",
      "Fold: 1  Epoch: 309  Training loss = 2.8193  Validation loss = 2.5499  \n",
      "\n",
      "Fold: 1  Epoch: 310  Training loss = 2.8182  Validation loss = 2.5469  \n",
      "\n",
      "Fold: 1  Epoch: 311  Training loss = 2.8176  Validation loss = 2.5450  \n",
      "\n",
      "Fold: 1  Epoch: 312  Training loss = 2.8167  Validation loss = 2.5428  \n",
      "\n",
      "Fold: 1  Epoch: 313  Training loss = 2.8163  Validation loss = 2.5414  \n",
      "\n",
      "Fold: 1  Epoch: 314  Training loss = 2.8155  Validation loss = 2.5393  \n",
      "\n",
      "Fold: 1  Epoch: 315  Training loss = 2.8144  Validation loss = 2.5363  \n",
      "\n",
      "Fold: 1  Epoch: 316  Training loss = 2.8140  Validation loss = 2.5353  \n",
      "\n",
      "Fold: 1  Epoch: 317  Training loss = 2.8128  Validation loss = 2.5320  \n",
      "\n",
      "Fold: 1  Epoch: 318  Training loss = 2.8122  Validation loss = 2.5303  \n",
      "\n",
      "Fold: 1  Epoch: 319  Training loss = 2.8117  Validation loss = 2.5288  \n",
      "\n",
      "Fold: 1  Epoch: 320  Training loss = 2.8111  Validation loss = 2.5272  \n",
      "\n",
      "Fold: 1  Epoch: 321  Training loss = 2.8100  Validation loss = 2.5242  \n",
      "\n",
      "Fold: 1  Epoch: 322  Training loss = 2.8089  Validation loss = 2.5214  \n",
      "\n",
      "Fold: 1  Epoch: 323  Training loss = 2.8085  Validation loss = 2.5201  \n",
      "\n",
      "Fold: 1  Epoch: 324  Training loss = 2.8075  Validation loss = 2.5174  \n",
      "\n",
      "Fold: 1  Epoch: 325  Training loss = 2.8067  Validation loss = 2.5151  \n",
      "\n",
      "Fold: 1  Epoch: 326  Training loss = 2.8058  Validation loss = 2.5127  \n",
      "\n",
      "Fold: 1  Epoch: 327  Training loss = 2.8052  Validation loss = 2.5110  \n",
      "\n",
      "Fold: 1  Epoch: 328  Training loss = 2.8049  Validation loss = 2.5101  \n",
      "\n",
      "Fold: 1  Epoch: 329  Training loss = 2.8038  Validation loss = 2.5072  \n",
      "\n",
      "Fold: 1  Epoch: 330  Training loss = 2.8029  Validation loss = 2.5045  \n",
      "\n",
      "Fold: 1  Epoch: 331  Training loss = 2.8023  Validation loss = 2.5029  \n",
      "\n",
      "Fold: 1  Epoch: 332  Training loss = 2.8019  Validation loss = 2.5018  \n",
      "\n",
      "Fold: 1  Epoch: 333  Training loss = 2.8012  Validation loss = 2.4998  \n",
      "\n",
      "Fold: 1  Epoch: 334  Training loss = 2.8004  Validation loss = 2.4975  \n",
      "\n",
      "Fold: 1  Epoch: 335  Training loss = 2.8000  Validation loss = 2.4963  \n",
      "\n",
      "Fold: 1  Epoch: 336  Training loss = 2.7992  Validation loss = 2.4941  \n",
      "\n",
      "Fold: 1  Epoch: 337  Training loss = 2.7985  Validation loss = 2.4920  \n",
      "\n",
      "Fold: 1  Epoch: 338  Training loss = 2.7981  Validation loss = 2.4906  \n",
      "\n",
      "Fold: 1  Epoch: 339  Training loss = 2.7977  Validation loss = 2.4895  \n",
      "\n",
      "Fold: 1  Epoch: 340  Training loss = 2.7971  Validation loss = 2.4878  \n",
      "\n",
      "Fold: 1  Epoch: 341  Training loss = 2.7964  Validation loss = 2.4856  \n",
      "\n",
      "Fold: 1  Epoch: 342  Training loss = 2.7959  Validation loss = 2.4844  \n",
      "\n",
      "Fold: 1  Epoch: 343  Training loss = 2.7955  Validation loss = 2.4832  \n",
      "\n",
      "Fold: 1  Epoch: 344  Training loss = 2.7947  Validation loss = 2.4809  \n",
      "\n",
      "Fold: 1  Epoch: 345  Training loss = 2.7939  Validation loss = 2.4787  \n",
      "\n",
      "Fold: 1  Epoch: 346  Training loss = 2.7929  Validation loss = 2.4761  \n",
      "\n",
      "Fold: 1  Epoch: 347  Training loss = 2.7923  Validation loss = 2.4741  \n",
      "\n",
      "Fold: 1  Epoch: 348  Training loss = 2.7917  Validation loss = 2.4727  \n",
      "\n",
      "Fold: 1  Epoch: 349  Training loss = 2.7908  Validation loss = 2.4703  \n",
      "\n",
      "Fold: 1  Epoch: 350  Training loss = 2.7900  Validation loss = 2.4680  \n",
      "\n",
      "Fold: 1  Epoch: 351  Training loss = 2.7896  Validation loss = 2.4668  \n",
      "\n",
      "Fold: 1  Epoch: 352  Training loss = 2.7886  Validation loss = 2.4641  \n",
      "\n",
      "Fold: 1  Epoch: 353  Training loss = 2.7878  Validation loss = 2.4620  \n",
      "\n",
      "Fold: 1  Epoch: 354  Training loss = 2.7870  Validation loss = 2.4596  \n",
      "\n",
      "Fold: 1  Epoch: 355  Training loss = 2.7863  Validation loss = 2.4576  \n",
      "\n",
      "Fold: 1  Epoch: 356  Training loss = 2.7854  Validation loss = 2.4550  \n",
      "\n",
      "Fold: 1  Epoch: 357  Training loss = 2.7849  Validation loss = 2.4536  \n",
      "\n",
      "Fold: 1  Epoch: 358  Training loss = 2.7838  Validation loss = 2.4506  \n",
      "\n",
      "Fold: 1  Epoch: 359  Training loss = 2.7836  Validation loss = 2.4497  \n",
      "\n",
      "Fold: 1  Epoch: 360  Training loss = 2.7832  Validation loss = 2.4485  \n",
      "\n",
      "Fold: 1  Epoch: 361  Training loss = 2.7821  Validation loss = 2.4454  \n",
      "\n",
      "Fold: 1  Epoch: 362  Training loss = 2.7814  Validation loss = 2.4435  \n",
      "\n",
      "Fold: 1  Epoch: 363  Training loss = 2.7809  Validation loss = 2.4421  \n",
      "\n",
      "Fold: 1  Epoch: 364  Training loss = 2.7799  Validation loss = 2.4394  \n",
      "\n",
      "Fold: 1  Epoch: 365  Training loss = 2.7790  Validation loss = 2.4369  \n",
      "\n",
      "Fold: 1  Epoch: 366  Training loss = 2.7781  Validation loss = 2.4342  \n",
      "\n",
      "Fold: 1  Epoch: 367  Training loss = 2.7776  Validation loss = 2.4325  \n",
      "\n",
      "Fold: 1  Epoch: 368  Training loss = 2.7763  Validation loss = 2.4289  \n",
      "\n",
      "Fold: 1  Epoch: 369  Training loss = 2.7759  Validation loss = 2.4276  \n",
      "\n",
      "Fold: 1  Epoch: 370  Training loss = 2.7752  Validation loss = 2.4256  \n",
      "\n",
      "Fold: 1  Epoch: 371  Training loss = 2.7750  Validation loss = 2.4249  \n",
      "\n",
      "Fold: 1  Epoch: 372  Training loss = 2.7741  Validation loss = 2.4222  \n",
      "\n",
      "Fold: 1  Epoch: 373  Training loss = 2.7735  Validation loss = 2.4207  \n",
      "\n",
      "Fold: 1  Epoch: 374  Training loss = 2.7730  Validation loss = 2.4191  \n",
      "\n",
      "Fold: 1  Epoch: 375  Training loss = 2.7723  Validation loss = 2.4168  \n",
      "\n",
      "Fold: 1  Epoch: 376  Training loss = 2.7719  Validation loss = 2.4157  \n",
      "\n",
      "Fold: 1  Epoch: 377  Training loss = 2.7716  Validation loss = 2.4149  \n",
      "\n",
      "Fold: 1  Epoch: 378  Training loss = 2.7708  Validation loss = 2.4124  \n",
      "\n",
      "Fold: 1  Epoch: 379  Training loss = 2.7704  Validation loss = 2.4113  \n",
      "\n",
      "Fold: 1  Epoch: 380  Training loss = 2.7700  Validation loss = 2.4103  \n",
      "\n",
      "Fold: 1  Epoch: 381  Training loss = 2.7694  Validation loss = 2.4084  \n",
      "\n",
      "Fold: 1  Epoch: 382  Training loss = 2.7686  Validation loss = 2.4059  \n",
      "\n",
      "Fold: 1  Epoch: 383  Training loss = 2.7679  Validation loss = 2.4034  \n",
      "\n",
      "Fold: 1  Epoch: 384  Training loss = 2.7670  Validation loss = 2.4007  \n",
      "\n",
      "Fold: 1  Epoch: 385  Training loss = 2.7663  Validation loss = 2.3986  \n",
      "\n",
      "Fold: 1  Epoch: 386  Training loss = 2.7657  Validation loss = 2.3965  \n",
      "\n",
      "Fold: 1  Epoch: 387  Training loss = 2.7649  Validation loss = 2.3942  \n",
      "\n",
      "Fold: 1  Epoch: 388  Training loss = 2.7645  Validation loss = 2.3931  \n",
      "\n",
      "Fold: 1  Epoch: 389  Training loss = 2.7639  Validation loss = 2.3913  \n",
      "\n",
      "Fold: 1  Epoch: 390  Training loss = 2.7634  Validation loss = 2.3898  \n",
      "\n",
      "Fold: 1  Epoch: 391  Training loss = 2.7629  Validation loss = 2.3881  \n",
      "\n",
      "Fold: 1  Epoch: 392  Training loss = 2.7625  Validation loss = 2.3870  \n",
      "\n",
      "Fold: 1  Epoch: 393  Training loss = 2.7617  Validation loss = 2.3845  \n",
      "\n",
      "Fold: 1  Epoch: 394  Training loss = 2.7604  Validation loss = 2.3806  \n",
      "\n",
      "Fold: 1  Epoch: 395  Training loss = 2.7597  Validation loss = 2.3786  \n",
      "\n",
      "Fold: 1  Epoch: 396  Training loss = 2.7588  Validation loss = 2.3759  \n",
      "\n",
      "Fold: 1  Epoch: 397  Training loss = 2.7579  Validation loss = 2.3733  \n",
      "\n",
      "Fold: 1  Epoch: 398  Training loss = 2.7571  Validation loss = 2.3708  \n",
      "\n",
      "Fold: 1  Epoch: 399  Training loss = 2.7568  Validation loss = 2.3700  \n",
      "\n",
      "Fold: 1  Epoch: 400  Training loss = 2.7563  Validation loss = 2.3686  \n",
      "\n",
      "Fold: 1  Epoch: 401  Training loss = 2.7561  Validation loss = 2.3677  \n",
      "\n",
      "Fold: 1  Epoch: 402  Training loss = 2.7555  Validation loss = 2.3657  \n",
      "\n",
      "Fold: 1  Epoch: 403  Training loss = 2.7548  Validation loss = 2.3636  \n",
      "\n",
      "Fold: 1  Epoch: 404  Training loss = 2.7544  Validation loss = 2.3624  \n",
      "\n",
      "Fold: 1  Epoch: 405  Training loss = 2.7539  Validation loss = 2.3609  \n",
      "\n",
      "Fold: 1  Epoch: 406  Training loss = 2.7533  Validation loss = 2.3589  \n",
      "\n",
      "Fold: 1  Epoch: 407  Training loss = 2.7528  Validation loss = 2.3577  \n",
      "\n",
      "Fold: 1  Epoch: 408  Training loss = 2.7524  Validation loss = 2.3561  \n",
      "\n",
      "Fold: 1  Epoch: 409  Training loss = 2.7517  Validation loss = 2.3541  \n",
      "\n",
      "Fold: 1  Epoch: 410  Training loss = 2.7511  Validation loss = 2.3520  \n",
      "\n",
      "Fold: 1  Epoch: 411  Training loss = 2.7504  Validation loss = 2.3500  \n",
      "\n",
      "Fold: 1  Epoch: 412  Training loss = 2.7495  Validation loss = 2.3472  \n",
      "\n",
      "Fold: 1  Epoch: 413  Training loss = 2.7491  Validation loss = 2.3458  \n",
      "\n",
      "Fold: 1  Epoch: 414  Training loss = 2.7480  Validation loss = 2.3424  \n",
      "\n",
      "Fold: 1  Epoch: 415  Training loss = 2.7476  Validation loss = 2.3410  \n",
      "\n",
      "Fold: 1  Epoch: 416  Training loss = 2.7471  Validation loss = 2.3398  \n",
      "\n",
      "Fold: 1  Epoch: 417  Training loss = 2.7465  Validation loss = 2.3379  \n",
      "\n",
      "Fold: 1  Epoch: 418  Training loss = 2.7461  Validation loss = 2.3369  \n",
      "\n",
      "Fold: 1  Epoch: 419  Training loss = 2.7457  Validation loss = 2.3354  \n",
      "\n",
      "Fold: 1  Epoch: 420  Training loss = 2.7453  Validation loss = 2.3340  \n",
      "\n",
      "Fold: 1  Epoch: 421  Training loss = 2.7446  Validation loss = 2.3321  \n",
      "\n",
      "Fold: 1  Epoch: 422  Training loss = 2.7442  Validation loss = 2.3306  \n",
      "\n",
      "Fold: 1  Epoch: 423  Training loss = 2.7434  Validation loss = 2.3284  \n",
      "\n",
      "Fold: 1  Epoch: 424  Training loss = 2.7430  Validation loss = 2.3270  \n",
      "\n",
      "Fold: 1  Epoch: 425  Training loss = 2.7422  Validation loss = 2.3243  \n",
      "\n",
      "Fold: 1  Epoch: 426  Training loss = 2.7416  Validation loss = 2.3223  \n",
      "\n",
      "Fold: 1  Epoch: 427  Training loss = 2.7411  Validation loss = 2.3206  \n",
      "\n",
      "Fold: 1  Epoch: 428  Training loss = 2.7405  Validation loss = 2.3183  \n",
      "\n",
      "Fold: 1  Epoch: 429  Training loss = 2.7397  Validation loss = 2.3156  \n",
      "\n",
      "Fold: 1  Epoch: 430  Training loss = 2.7391  Validation loss = 2.3137  \n",
      "\n",
      "Fold: 1  Epoch: 431  Training loss = 2.7380  Validation loss = 2.3098  \n",
      "\n",
      "Fold: 1  Epoch: 432  Training loss = 2.7376  Validation loss = 2.3086  \n",
      "\n",
      "Fold: 1  Epoch: 433  Training loss = 2.7369  Validation loss = 2.3067  \n",
      "\n",
      "Fold: 1  Epoch: 434  Training loss = 2.7363  Validation loss = 2.3047  \n",
      "\n",
      "Fold: 1  Epoch: 435  Training loss = 2.7358  Validation loss = 2.3028  \n",
      "\n",
      "Fold: 1  Epoch: 436  Training loss = 2.7346  Validation loss = 2.2989  \n",
      "\n",
      "Fold: 1  Epoch: 437  Training loss = 2.7343  Validation loss = 2.2978  \n",
      "\n",
      "Fold: 1  Epoch: 438  Training loss = 2.7339  Validation loss = 2.2966  \n",
      "\n",
      "Fold: 1  Epoch: 439  Training loss = 2.7337  Validation loss = 2.2957  \n",
      "\n",
      "Fold: 1  Epoch: 440  Training loss = 2.7329  Validation loss = 2.2934  \n",
      "\n",
      "Fold: 1  Epoch: 441  Training loss = 2.7324  Validation loss = 2.2916  \n",
      "\n",
      "Fold: 1  Epoch: 442  Training loss = 2.7317  Validation loss = 2.2891  \n",
      "\n",
      "Fold: 1  Epoch: 443  Training loss = 2.7310  Validation loss = 2.2867  \n",
      "\n",
      "Fold: 1  Epoch: 444  Training loss = 2.7308  Validation loss = 2.2860  \n",
      "\n",
      "Fold: 1  Epoch: 445  Training loss = 2.7306  Validation loss = 2.2855  \n",
      "\n",
      "Fold: 1  Epoch: 446  Training loss = 2.7299  Validation loss = 2.2832  \n",
      "\n",
      "Fold: 1  Epoch: 447  Training loss = 2.7292  Validation loss = 2.2810  \n",
      "\n",
      "Fold: 1  Epoch: 448  Training loss = 2.7288  Validation loss = 2.2796  \n",
      "\n",
      "Fold: 1  Epoch: 449  Training loss = 2.7283  Validation loss = 2.2780  \n",
      "\n",
      "Fold: 1  Epoch: 450  Training loss = 2.7278  Validation loss = 2.2760  \n",
      "\n",
      "Fold: 1  Epoch: 451  Training loss = 2.7274  Validation loss = 2.2749  \n",
      "\n",
      "Fold: 1  Epoch: 452  Training loss = 2.7270  Validation loss = 2.2735  \n",
      "\n",
      "Fold: 1  Epoch: 453  Training loss = 2.7262  Validation loss = 2.2710  \n",
      "\n",
      "Fold: 1  Epoch: 454  Training loss = 2.7259  Validation loss = 2.2702  \n",
      "\n",
      "Fold: 1  Epoch: 455  Training loss = 2.7253  Validation loss = 2.2681  \n",
      "\n",
      "Fold: 1  Epoch: 456  Training loss = 2.7248  Validation loss = 2.2665  \n",
      "\n",
      "Fold: 1  Epoch: 457  Training loss = 2.7243  Validation loss = 2.2650  \n",
      "\n",
      "Fold: 1  Epoch: 458  Training loss = 2.7241  Validation loss = 2.2644  \n",
      "\n",
      "Fold: 1  Epoch: 459  Training loss = 2.7238  Validation loss = 2.2635  \n",
      "\n",
      "Fold: 1  Epoch: 460  Training loss = 2.7236  Validation loss = 2.2625  \n",
      "\n",
      "Fold: 1  Epoch: 461  Training loss = 2.7230  Validation loss = 2.2608  \n",
      "\n",
      "Fold: 1  Epoch: 462  Training loss = 2.7224  Validation loss = 2.2586  \n",
      "\n",
      "Fold: 1  Epoch: 463  Training loss = 2.7217  Validation loss = 2.2563  \n",
      "\n",
      "Fold: 1  Epoch: 464  Training loss = 2.7214  Validation loss = 2.2555  \n",
      "\n",
      "Fold: 1  Epoch: 465  Training loss = 2.7209  Validation loss = 2.2539  \n",
      "\n",
      "Fold: 1  Epoch: 466  Training loss = 2.7209  Validation loss = 2.2540  \n",
      "\n",
      "Fold: 1  Epoch: 467  Training loss = 2.7207  Validation loss = 2.2533  \n",
      "\n",
      "Fold: 1  Epoch: 468  Training loss = 2.7206  Validation loss = 2.2528  \n",
      "\n",
      "Fold: 1  Epoch: 469  Training loss = 2.7198  Validation loss = 2.2503  \n",
      "\n",
      "Fold: 1  Epoch: 470  Training loss = 2.7194  Validation loss = 2.2491  \n",
      "\n",
      "Fold: 1  Epoch: 471  Training loss = 2.7191  Validation loss = 2.2480  \n",
      "\n",
      "Fold: 1  Epoch: 472  Training loss = 2.7187  Validation loss = 2.2466  \n",
      "\n",
      "Fold: 1  Epoch: 473  Training loss = 2.7182  Validation loss = 2.2450  \n",
      "\n",
      "Fold: 1  Epoch: 474  Training loss = 2.7176  Validation loss = 2.2429  \n",
      "\n",
      "Fold: 1  Epoch: 475  Training loss = 2.7170  Validation loss = 2.2406  \n",
      "\n",
      "Fold: 1  Epoch: 476  Training loss = 2.7161  Validation loss = 2.2374  \n",
      "\n",
      "Fold: 1  Epoch: 477  Training loss = 2.7154  Validation loss = 2.2352  \n",
      "\n",
      "Fold: 1  Epoch: 478  Training loss = 2.7150  Validation loss = 2.2340  \n",
      "\n",
      "Fold: 1  Epoch: 479  Training loss = 2.7147  Validation loss = 2.2330  \n",
      "\n",
      "Fold: 1  Epoch: 480  Training loss = 2.7141  Validation loss = 2.2309  \n",
      "\n",
      "Fold: 1  Epoch: 481  Training loss = 2.7139  Validation loss = 2.2303  \n",
      "\n",
      "Fold: 1  Epoch: 482  Training loss = 2.7137  Validation loss = 2.2299  \n",
      "\n",
      "Fold: 1  Epoch: 483  Training loss = 2.7135  Validation loss = 2.2293  \n",
      "\n",
      "Fold: 1  Epoch: 484  Training loss = 2.7129  Validation loss = 2.2273  \n",
      "\n",
      "Fold: 1  Epoch: 485  Training loss = 2.7126  Validation loss = 2.2261  \n",
      "\n",
      "Fold: 1  Epoch: 486  Training loss = 2.7123  Validation loss = 2.2250  \n",
      "\n",
      "Fold: 1  Epoch: 487  Training loss = 2.7122  Validation loss = 2.2248  \n",
      "\n",
      "Fold: 1  Epoch: 488  Training loss = 2.7118  Validation loss = 2.2230  \n",
      "\n",
      "Fold: 1  Epoch: 489  Training loss = 2.7112  Validation loss = 2.2210  \n",
      "\n",
      "Fold: 1  Epoch: 490  Training loss = 2.7105  Validation loss = 2.2187  \n",
      "\n",
      "Fold: 1  Epoch: 491  Training loss = 2.7102  Validation loss = 2.2177  \n",
      "\n",
      "Fold: 1  Epoch: 492  Training loss = 2.7101  Validation loss = 2.2173  \n",
      "\n",
      "Fold: 1  Epoch: 493  Training loss = 2.7096  Validation loss = 2.2156  \n",
      "\n",
      "Fold: 1  Epoch: 494  Training loss = 2.7093  Validation loss = 2.2142  \n",
      "\n",
      "Fold: 1  Epoch: 495  Training loss = 2.7089  Validation loss = 2.2130  \n",
      "\n",
      "Fold: 1  Epoch: 496  Training loss = 2.7084  Validation loss = 2.2109  \n",
      "\n",
      "Fold: 1  Epoch: 497  Training loss = 2.7081  Validation loss = 2.2097  \n",
      "\n",
      "Fold: 1  Epoch: 498  Training loss = 2.7078  Validation loss = 2.2086  \n",
      "\n",
      "Fold: 1  Epoch: 499  Training loss = 2.7072  Validation loss = 2.2068  \n",
      "\n",
      "Fold: 1  Epoch: 500  Training loss = 2.7063  Validation loss = 2.2038  \n",
      "\n",
      "Check model:  Fold: 1  Epoch: 500  Training loss = 2.7063  Validation loss = 2.2038  \n",
      "\n",
      "Fold: 2  Epoch: 1  Training loss = 2.6155  Validation loss = 2.3147  \n",
      "\n",
      "Fold: 2  Epoch: 2  Training loss = 2.6147  Validation loss = 2.3128  \n",
      "\n",
      "Fold: 2  Epoch: 3  Training loss = 2.6140  Validation loss = 2.3113  \n",
      "\n",
      "Fold: 2  Epoch: 4  Training loss = 2.6136  Validation loss = 2.3105  \n",
      "\n",
      "Fold: 2  Epoch: 5  Training loss = 2.6130  Validation loss = 2.3088  \n",
      "\n",
      "Fold: 2  Epoch: 6  Training loss = 2.6125  Validation loss = 2.3077  \n",
      "\n",
      "Fold: 2  Epoch: 7  Training loss = 2.6115  Validation loss = 2.3055  \n",
      "\n",
      "Fold: 2  Epoch: 8  Training loss = 2.6110  Validation loss = 2.3044  \n",
      "\n",
      "Fold: 2  Epoch: 9  Training loss = 2.6101  Validation loss = 2.3025  \n",
      "\n",
      "Fold: 2  Epoch: 10  Training loss = 2.6094  Validation loss = 2.3009  \n",
      "\n",
      "Fold: 2  Epoch: 11  Training loss = 2.6089  Validation loss = 2.3000  \n",
      "\n",
      "Fold: 2  Epoch: 12  Training loss = 2.6085  Validation loss = 2.2990  \n",
      "\n",
      "Fold: 2  Epoch: 13  Training loss = 2.6083  Validation loss = 2.2984  \n",
      "\n",
      "Fold: 2  Epoch: 14  Training loss = 2.6076  Validation loss = 2.2968  \n",
      "\n",
      "Fold: 2  Epoch: 15  Training loss = 2.6071  Validation loss = 2.2955  \n",
      "\n",
      "Fold: 2  Epoch: 16  Training loss = 2.6066  Validation loss = 2.2949  \n",
      "\n",
      "Fold: 2  Epoch: 17  Training loss = 2.6058  Validation loss = 2.2929  \n",
      "\n",
      "Fold: 2  Epoch: 18  Training loss = 2.6049  Validation loss = 2.2910  \n",
      "\n",
      "Fold: 2  Epoch: 19  Training loss = 2.6044  Validation loss = 2.2899  \n",
      "\n",
      "Fold: 2  Epoch: 20  Training loss = 2.6039  Validation loss = 2.2886  \n",
      "\n",
      "Fold: 2  Epoch: 21  Training loss = 2.6034  Validation loss = 2.2874  \n",
      "\n",
      "Fold: 2  Epoch: 22  Training loss = 2.6031  Validation loss = 2.2870  \n",
      "\n",
      "Fold: 2  Epoch: 23  Training loss = 2.6024  Validation loss = 2.2852  \n",
      "\n",
      "Fold: 2  Epoch: 24  Training loss = 2.6021  Validation loss = 2.2844  \n",
      "\n",
      "Fold: 2  Epoch: 25  Training loss = 2.6017  Validation loss = 2.2836  \n",
      "\n",
      "Fold: 2  Epoch: 26  Training loss = 2.6012  Validation loss = 2.2823  \n",
      "\n",
      "Fold: 2  Epoch: 27  Training loss = 2.6007  Validation loss = 2.2813  \n",
      "\n",
      "Fold: 2  Epoch: 28  Training loss = 2.6004  Validation loss = 2.2805  \n",
      "\n",
      "Fold: 2  Epoch: 29  Training loss = 2.6001  Validation loss = 2.2797  \n",
      "\n",
      "Fold: 2  Epoch: 30  Training loss = 2.5995  Validation loss = 2.2783  \n",
      "\n",
      "Fold: 2  Epoch: 31  Training loss = 2.5994  Validation loss = 2.2782  \n",
      "\n",
      "Fold: 2  Epoch: 32  Training loss = 2.5992  Validation loss = 2.2777  \n",
      "\n",
      "Fold: 2  Epoch: 33  Training loss = 2.5986  Validation loss = 2.2763  \n",
      "\n",
      "Fold: 2  Epoch: 34  Training loss = 2.5981  Validation loss = 2.2751  \n",
      "\n",
      "Fold: 2  Epoch: 35  Training loss = 2.5971  Validation loss = 2.2728  \n",
      "\n",
      "Fold: 2  Epoch: 36  Training loss = 2.5968  Validation loss = 2.2722  \n",
      "\n",
      "Fold: 2  Epoch: 37  Training loss = 2.5965  Validation loss = 2.2715  \n",
      "\n",
      "Fold: 2  Epoch: 38  Training loss = 2.5961  Validation loss = 2.2703  \n",
      "\n",
      "Fold: 2  Epoch: 39  Training loss = 2.5954  Validation loss = 2.2688  \n",
      "\n",
      "Fold: 2  Epoch: 40  Training loss = 2.5950  Validation loss = 2.2676  \n",
      "\n",
      "Fold: 2  Epoch: 41  Training loss = 2.5946  Validation loss = 2.2665  \n",
      "\n",
      "Fold: 2  Epoch: 42  Training loss = 2.5943  Validation loss = 2.2661  \n",
      "\n",
      "Fold: 2  Epoch: 43  Training loss = 2.5941  Validation loss = 2.2657  \n",
      "\n",
      "Fold: 2  Epoch: 44  Training loss = 2.5936  Validation loss = 2.2644  \n",
      "\n",
      "Fold: 2  Epoch: 45  Training loss = 2.5929  Validation loss = 2.2630  \n",
      "\n",
      "Fold: 2  Epoch: 46  Training loss = 2.5926  Validation loss = 2.2622  \n",
      "\n",
      "Fold: 2  Epoch: 47  Training loss = 2.5920  Validation loss = 2.2606  \n",
      "\n",
      "Fold: 2  Epoch: 48  Training loss = 2.5916  Validation loss = 2.2596  \n",
      "\n",
      "Fold: 2  Epoch: 49  Training loss = 2.5911  Validation loss = 2.2584  \n",
      "\n",
      "Fold: 2  Epoch: 50  Training loss = 2.5906  Validation loss = 2.2573  \n",
      "\n",
      "Fold: 2  Epoch: 51  Training loss = 2.5904  Validation loss = 2.2569  \n",
      "\n",
      "Fold: 2  Epoch: 52  Training loss = 2.5902  Validation loss = 2.2564  \n",
      "\n",
      "Fold: 2  Epoch: 53  Training loss = 2.5899  Validation loss = 2.2558  \n",
      "\n",
      "Fold: 2  Epoch: 54  Training loss = 2.5894  Validation loss = 2.2548  \n",
      "\n",
      "Fold: 2  Epoch: 55  Training loss = 2.5891  Validation loss = 2.2539  \n",
      "\n",
      "Fold: 2  Epoch: 56  Training loss = 2.5886  Validation loss = 2.2528  \n",
      "\n",
      "Fold: 2  Epoch: 57  Training loss = 2.5884  Validation loss = 2.2524  \n",
      "\n",
      "Fold: 2  Epoch: 58  Training loss = 2.5879  Validation loss = 2.2514  \n",
      "\n",
      "Fold: 2  Epoch: 59  Training loss = 2.5878  Validation loss = 2.2513  \n",
      "\n",
      "Fold: 2  Epoch: 60  Training loss = 2.5875  Validation loss = 2.2506  \n",
      "\n",
      "Fold: 2  Epoch: 61  Training loss = 2.5871  Validation loss = 2.2496  \n",
      "\n",
      "Fold: 2  Epoch: 62  Training loss = 2.5868  Validation loss = 2.2488  \n",
      "\n",
      "Fold: 2  Epoch: 63  Training loss = 2.5864  Validation loss = 2.2479  \n",
      "\n",
      "Fold: 2  Epoch: 64  Training loss = 2.5863  Validation loss = 2.2476  \n",
      "\n",
      "Fold: 2  Epoch: 65  Training loss = 2.5862  Validation loss = 2.2476  \n",
      "\n",
      "Fold: 2  Epoch: 66  Training loss = 2.5859  Validation loss = 2.2467  \n",
      "\n",
      "Fold: 2  Epoch: 67  Training loss = 2.5856  Validation loss = 2.2460  \n",
      "\n",
      "Fold: 2  Epoch: 68  Training loss = 2.5855  Validation loss = 2.2456  \n",
      "\n",
      "Fold: 2  Epoch: 69  Training loss = 2.5852  Validation loss = 2.2450  \n",
      "\n",
      "Fold: 2  Epoch: 70  Training loss = 2.5850  Validation loss = 2.2444  \n",
      "\n",
      "Fold: 2  Epoch: 71  Training loss = 2.5845  Validation loss = 2.2433  \n",
      "\n",
      "Fold: 2  Epoch: 72  Training loss = 2.5841  Validation loss = 2.2423  \n",
      "\n",
      "Fold: 2  Epoch: 73  Training loss = 2.5839  Validation loss = 2.2415  \n",
      "\n",
      "Fold: 2  Epoch: 74  Training loss = 2.5834  Validation loss = 2.2407  \n",
      "\n",
      "Fold: 2  Epoch: 75  Training loss = 2.5831  Validation loss = 2.2396  \n",
      "\n",
      "Fold: 2  Epoch: 76  Training loss = 2.5830  Validation loss = 2.2395  \n",
      "\n",
      "Fold: 2  Epoch: 77  Training loss = 2.5821  Validation loss = 2.2373  \n",
      "\n",
      "Fold: 2  Epoch: 78  Training loss = 2.5819  Validation loss = 2.2369  \n",
      "\n",
      "Fold: 2  Epoch: 79  Training loss = 2.5816  Validation loss = 2.2361  \n",
      "\n",
      "Fold: 2  Epoch: 80  Training loss = 2.5811  Validation loss = 2.2348  \n",
      "\n",
      "Fold: 2  Epoch: 81  Training loss = 2.5808  Validation loss = 2.2342  \n",
      "\n",
      "Fold: 2  Epoch: 82  Training loss = 2.5804  Validation loss = 2.2330  \n",
      "\n",
      "Fold: 2  Epoch: 83  Training loss = 2.5803  Validation loss = 2.2325  \n",
      "\n",
      "Fold: 2  Epoch: 84  Training loss = 2.5800  Validation loss = 2.2317  \n",
      "\n",
      "Fold: 2  Epoch: 85  Training loss = 2.5797  Validation loss = 2.2309  \n",
      "\n",
      "Fold: 2  Epoch: 86  Training loss = 2.5793  Validation loss = 2.2300  \n",
      "\n",
      "Fold: 2  Epoch: 87  Training loss = 2.5788  Validation loss = 2.2286  \n",
      "\n",
      "Fold: 2  Epoch: 88  Training loss = 2.5785  Validation loss = 2.2278  \n",
      "\n",
      "Fold: 2  Epoch: 89  Training loss = 2.5779  Validation loss = 2.2264  \n",
      "\n",
      "Fold: 2  Epoch: 90  Training loss = 2.5777  Validation loss = 2.2258  \n",
      "\n",
      "Fold: 2  Epoch: 91  Training loss = 2.5773  Validation loss = 2.2248  \n",
      "\n",
      "Fold: 2  Epoch: 92  Training loss = 2.5771  Validation loss = 2.2244  \n",
      "\n",
      "Fold: 2  Epoch: 93  Training loss = 2.5770  Validation loss = 2.2241  \n",
      "\n",
      "Fold: 2  Epoch: 94  Training loss = 2.5770  Validation loss = 2.2241  \n",
      "\n",
      "Fold: 2  Epoch: 95  Training loss = 2.5765  Validation loss = 2.2228  \n",
      "\n",
      "Fold: 2  Epoch: 96  Training loss = 2.5760  Validation loss = 2.2215  \n",
      "\n",
      "Fold: 2  Epoch: 97  Training loss = 2.5759  Validation loss = 2.2215  \n",
      "\n",
      "Fold: 2  Epoch: 98  Training loss = 2.5757  Validation loss = 2.2208  \n",
      "\n",
      "Fold: 2  Epoch: 99  Training loss = 2.5755  Validation loss = 2.2205  \n",
      "\n",
      "Fold: 2  Epoch: 100  Training loss = 2.5749  Validation loss = 2.2187  \n",
      "\n",
      "Fold: 2  Epoch: 101  Training loss = 2.5748  Validation loss = 2.2185  \n",
      "\n",
      "Fold: 2  Epoch: 102  Training loss = 2.5746  Validation loss = 2.2182  \n",
      "\n",
      "Fold: 2  Epoch: 103  Training loss = 2.5740  Validation loss = 2.2165  \n",
      "\n",
      "Fold: 2  Epoch: 104  Training loss = 2.5738  Validation loss = 2.2160  \n",
      "\n",
      "Fold: 2  Epoch: 105  Training loss = 2.5735  Validation loss = 2.2151  \n",
      "\n",
      "Fold: 2  Epoch: 106  Training loss = 2.5730  Validation loss = 2.2137  \n",
      "\n",
      "Fold: 2  Epoch: 107  Training loss = 2.5727  Validation loss = 2.2128  \n",
      "\n",
      "Fold: 2  Epoch: 108  Training loss = 2.5724  Validation loss = 2.2121  \n",
      "\n",
      "Fold: 2  Epoch: 109  Training loss = 2.5720  Validation loss = 2.2113  \n",
      "\n",
      "Fold: 2  Epoch: 110  Training loss = 2.5719  Validation loss = 2.2110  \n",
      "\n",
      "Fold: 2  Epoch: 111  Training loss = 2.5714  Validation loss = 2.2098  \n",
      "\n",
      "Fold: 2  Epoch: 112  Training loss = 2.5713  Validation loss = 2.2095  \n",
      "\n",
      "Fold: 2  Epoch: 113  Training loss = 2.5711  Validation loss = 2.2087  \n",
      "\n",
      "Fold: 2  Epoch: 114  Training loss = 2.5710  Validation loss = 2.2084  \n",
      "\n",
      "Fold: 2  Epoch: 115  Training loss = 2.5708  Validation loss = 2.2076  \n",
      "\n",
      "Fold: 2  Epoch: 116  Training loss = 2.5705  Validation loss = 2.2070  \n",
      "\n",
      "Fold: 2  Epoch: 117  Training loss = 2.5701  Validation loss = 2.2061  \n",
      "\n",
      "Fold: 2  Epoch: 118  Training loss = 2.5697  Validation loss = 2.2052  \n",
      "\n",
      "Fold: 2  Epoch: 119  Training loss = 2.5693  Validation loss = 2.2042  \n",
      "\n",
      "Fold: 2  Epoch: 120  Training loss = 2.5693  Validation loss = 2.2042  \n",
      "\n",
      "Fold: 2  Epoch: 121  Training loss = 2.5691  Validation loss = 2.2039  \n",
      "\n",
      "Fold: 2  Epoch: 122  Training loss = 2.5688  Validation loss = 2.2029  \n",
      "\n",
      "Fold: 2  Epoch: 123  Training loss = 2.5684  Validation loss = 2.2019  \n",
      "\n",
      "Fold: 2  Epoch: 124  Training loss = 2.5681  Validation loss = 2.2013  \n",
      "\n",
      "Fold: 2  Epoch: 125  Training loss = 2.5680  Validation loss = 2.2012  \n",
      "\n",
      "Fold: 2  Epoch: 126  Training loss = 2.5673  Validation loss = 2.1992  \n",
      "\n",
      "Fold: 2  Epoch: 127  Training loss = 2.5672  Validation loss = 2.1985  \n",
      "\n",
      "Fold: 2  Epoch: 128  Training loss = 2.5668  Validation loss = 2.1974  \n",
      "\n",
      "Fold: 2  Epoch: 129  Training loss = 2.5667  Validation loss = 2.1972  \n",
      "\n",
      "Fold: 2  Epoch: 130  Training loss = 2.5663  Validation loss = 2.1960  \n",
      "\n",
      "Fold: 2  Epoch: 131  Training loss = 2.5658  Validation loss = 2.1947  \n",
      "\n",
      "Fold: 2  Epoch: 132  Training loss = 2.5652  Validation loss = 2.1935  \n",
      "\n",
      "Fold: 2  Epoch: 133  Training loss = 2.5648  Validation loss = 2.1921  \n",
      "\n",
      "Fold: 2  Epoch: 134  Training loss = 2.5645  Validation loss = 2.1913  \n",
      "\n",
      "Fold: 2  Epoch: 135  Training loss = 2.5644  Validation loss = 2.1911  \n",
      "\n",
      "Fold: 2  Epoch: 136  Training loss = 2.5643  Validation loss = 2.1907  \n",
      "\n",
      "Fold: 2  Epoch: 137  Training loss = 2.5639  Validation loss = 2.1897  \n",
      "\n",
      "Fold: 2  Epoch: 138  Training loss = 2.5633  Validation loss = 2.1882  \n",
      "\n",
      "Fold: 2  Epoch: 139  Training loss = 2.5632  Validation loss = 2.1879  \n",
      "\n",
      "Fold: 2  Epoch: 140  Training loss = 2.5629  Validation loss = 2.1872  \n",
      "\n",
      "Fold: 2  Epoch: 141  Training loss = 2.5627  Validation loss = 2.1867  \n",
      "\n",
      "Fold: 2  Epoch: 142  Training loss = 2.5625  Validation loss = 2.1860  \n",
      "\n",
      "Fold: 2  Epoch: 143  Training loss = 2.5623  Validation loss = 2.1852  \n",
      "\n",
      "Fold: 2  Epoch: 144  Training loss = 2.5622  Validation loss = 2.1852  \n",
      "\n",
      "Fold: 2  Epoch: 145  Training loss = 2.5617  Validation loss = 2.1836  \n",
      "\n",
      "Fold: 2  Epoch: 146  Training loss = 2.5613  Validation loss = 2.1824  \n",
      "\n",
      "Fold: 2  Epoch: 147  Training loss = 2.5610  Validation loss = 2.1817  \n",
      "\n",
      "Fold: 2  Epoch: 148  Training loss = 2.5608  Validation loss = 2.1809  \n",
      "\n",
      "Fold: 2  Epoch: 149  Training loss = 2.5606  Validation loss = 2.1803  \n",
      "\n",
      "Fold: 2  Epoch: 150  Training loss = 2.5598  Validation loss = 2.1784  \n",
      "\n",
      "Fold: 2  Epoch: 151  Training loss = 2.5595  Validation loss = 2.1777  \n",
      "\n",
      "Fold: 2  Epoch: 152  Training loss = 2.5595  Validation loss = 2.1778  \n",
      "\n",
      "Fold: 2  Epoch: 153  Training loss = 2.5591  Validation loss = 2.1766  \n",
      "\n",
      "Fold: 2  Epoch: 154  Training loss = 2.5586  Validation loss = 2.1751  \n",
      "\n",
      "Fold: 2  Epoch: 155  Training loss = 2.5583  Validation loss = 2.1744  \n",
      "\n",
      "Fold: 2  Epoch: 156  Training loss = 2.5580  Validation loss = 2.1734  \n",
      "\n",
      "Fold: 2  Epoch: 157  Training loss = 2.5575  Validation loss = 2.1723  \n",
      "\n",
      "Fold: 2  Epoch: 158  Training loss = 2.5572  Validation loss = 2.1714  \n",
      "\n",
      "Fold: 2  Epoch: 159  Training loss = 2.5568  Validation loss = 2.1703  \n",
      "\n",
      "Fold: 2  Epoch: 160  Training loss = 2.5567  Validation loss = 2.1703  \n",
      "\n",
      "Fold: 2  Epoch: 161  Training loss = 2.5565  Validation loss = 2.1698  \n",
      "\n",
      "Fold: 2  Epoch: 162  Training loss = 2.5560  Validation loss = 2.1684  \n",
      "\n",
      "Fold: 2  Epoch: 163  Training loss = 2.5559  Validation loss = 2.1683  \n",
      "\n",
      "Fold: 2  Epoch: 164  Training loss = 2.5555  Validation loss = 2.1667  \n",
      "\n",
      "Fold: 2  Epoch: 165  Training loss = 2.5553  Validation loss = 2.1661  \n",
      "\n",
      "Fold: 2  Epoch: 166  Training loss = 2.5550  Validation loss = 2.1650  \n",
      "\n",
      "Fold: 2  Epoch: 167  Training loss = 2.5550  Validation loss = 2.1651  \n",
      "\n",
      "Fold: 2  Epoch: 168  Training loss = 2.5545  Validation loss = 2.1636  \n",
      "\n",
      "Fold: 2  Epoch: 169  Training loss = 2.5546  Validation loss = 2.1640  \n",
      "\n",
      "Fold: 2  Epoch: 170  Training loss = 2.5543  Validation loss = 2.1632  \n",
      "\n",
      "Fold: 2  Epoch: 171  Training loss = 2.5541  Validation loss = 2.1628  \n",
      "\n",
      "Fold: 2  Epoch: 172  Training loss = 2.5539  Validation loss = 2.1619  \n",
      "\n",
      "Fold: 2  Epoch: 173  Training loss = 2.5538  Validation loss = 2.1620  \n",
      "\n",
      "Fold: 2  Epoch: 174  Training loss = 2.5538  Validation loss = 2.1616  \n",
      "\n",
      "Fold: 2  Epoch: 175  Training loss = 2.5535  Validation loss = 2.1609  \n",
      "\n",
      "Fold: 2  Epoch: 176  Training loss = 2.5533  Validation loss = 2.1603  \n",
      "\n",
      "Fold: 2  Epoch: 177  Training loss = 2.5532  Validation loss = 2.1598  \n",
      "\n",
      "Fold: 2  Epoch: 178  Training loss = 2.5527  Validation loss = 2.1586  \n",
      "\n",
      "Fold: 2  Epoch: 179  Training loss = 2.5525  Validation loss = 2.1581  \n",
      "\n",
      "Fold: 2  Epoch: 180  Training loss = 2.5522  Validation loss = 2.1574  \n",
      "\n",
      "Fold: 2  Epoch: 181  Training loss = 2.5521  Validation loss = 2.1573  \n",
      "\n",
      "Fold: 2  Epoch: 182  Training loss = 2.5521  Validation loss = 2.1573  \n",
      "\n",
      "Fold: 2  Epoch: 183  Training loss = 2.5516  Validation loss = 2.1560  \n",
      "\n",
      "Fold: 2  Epoch: 184  Training loss = 2.5512  Validation loss = 2.1547  \n",
      "\n",
      "Fold: 2  Epoch: 185  Training loss = 2.5511  Validation loss = 2.1543  \n",
      "\n",
      "Fold: 2  Epoch: 186  Training loss = 2.5508  Validation loss = 2.1534  \n",
      "\n",
      "Fold: 2  Epoch: 187  Training loss = 2.5506  Validation loss = 2.1525  \n",
      "\n",
      "Fold: 2  Epoch: 188  Training loss = 2.5503  Validation loss = 2.1512  \n",
      "\n",
      "Fold: 2  Epoch: 189  Training loss = 2.5501  Validation loss = 2.1509  \n",
      "\n",
      "Fold: 2  Epoch: 190  Training loss = 2.5500  Validation loss = 2.1506  \n",
      "\n",
      "Fold: 2  Epoch: 191  Training loss = 2.5500  Validation loss = 2.1505  \n",
      "\n",
      "Fold: 2  Epoch: 192  Training loss = 2.5498  Validation loss = 2.1503  \n",
      "\n",
      "Fold: 2  Epoch: 193  Training loss = 2.5496  Validation loss = 2.1498  \n",
      "\n",
      "Fold: 2  Epoch: 194  Training loss = 2.5492  Validation loss = 2.1488  \n",
      "\n",
      "Fold: 2  Epoch: 195  Training loss = 2.5486  Validation loss = 2.1473  \n",
      "\n",
      "Fold: 2  Epoch: 196  Training loss = 2.5486  Validation loss = 2.1470  \n",
      "\n",
      "Fold: 2  Epoch: 197  Training loss = 2.5485  Validation loss = 2.1467  \n",
      "\n",
      "Fold: 2  Epoch: 198  Training loss = 2.5482  Validation loss = 2.1457  \n",
      "\n",
      "Fold: 2  Epoch: 199  Training loss = 2.5480  Validation loss = 2.1452  \n",
      "\n",
      "Fold: 2  Epoch: 200  Training loss = 2.5478  Validation loss = 2.1449  \n",
      "\n",
      "Fold: 2  Epoch: 201  Training loss = 2.5470  Validation loss = 2.1427  \n",
      "\n",
      "Fold: 2  Epoch: 202  Training loss = 2.5468  Validation loss = 2.1418  \n",
      "\n",
      "Fold: 2  Epoch: 203  Training loss = 2.5467  Validation loss = 2.1415  \n",
      "\n",
      "Fold: 2  Epoch: 204  Training loss = 2.5464  Validation loss = 2.1406  \n",
      "\n",
      "Fold: 2  Epoch: 205  Training loss = 2.5461  Validation loss = 2.1400  \n",
      "\n",
      "Fold: 2  Epoch: 206  Training loss = 2.5460  Validation loss = 2.1396  \n",
      "\n",
      "Fold: 2  Epoch: 207  Training loss = 2.5459  Validation loss = 2.1395  \n",
      "\n",
      "Fold: 2  Epoch: 208  Training loss = 2.5459  Validation loss = 2.1396  \n",
      "\n",
      "Fold: 2  Epoch: 209  Training loss = 2.5458  Validation loss = 2.1393  \n",
      "\n",
      "Fold: 2  Epoch: 210  Training loss = 2.5456  Validation loss = 2.1387  \n",
      "\n",
      "Fold: 2  Epoch: 211  Training loss = 2.5453  Validation loss = 2.1381  \n",
      "\n",
      "Fold: 2  Epoch: 212  Training loss = 2.5449  Validation loss = 2.1369  \n",
      "\n",
      "Fold: 2  Epoch: 213  Training loss = 2.5447  Validation loss = 2.1363  \n",
      "\n",
      "Fold: 2  Epoch: 214  Training loss = 2.5446  Validation loss = 2.1359  \n",
      "\n",
      "Fold: 2  Epoch: 215  Training loss = 2.5442  Validation loss = 2.1347  \n",
      "\n",
      "Fold: 2  Epoch: 216  Training loss = 2.5439  Validation loss = 2.1338  \n",
      "\n",
      "Fold: 2  Epoch: 217  Training loss = 2.5435  Validation loss = 2.1325  \n",
      "\n",
      "Fold: 2  Epoch: 218  Training loss = 2.5432  Validation loss = 2.1315  \n",
      "\n",
      "Fold: 2  Epoch: 219  Training loss = 2.5430  Validation loss = 2.1310  \n",
      "\n",
      "Fold: 2  Epoch: 220  Training loss = 2.5428  Validation loss = 2.1304  \n",
      "\n",
      "Fold: 2  Epoch: 221  Training loss = 2.5423  Validation loss = 2.1287  \n",
      "\n",
      "Fold: 2  Epoch: 222  Training loss = 2.5421  Validation loss = 2.1282  \n",
      "\n",
      "Fold: 2  Epoch: 223  Training loss = 2.5419  Validation loss = 2.1276  \n",
      "\n",
      "Fold: 2  Epoch: 224  Training loss = 2.5416  Validation loss = 2.1269  \n",
      "\n",
      "Fold: 2  Epoch: 225  Training loss = 2.5416  Validation loss = 2.1269  \n",
      "\n",
      "Fold: 2  Epoch: 226  Training loss = 2.5415  Validation loss = 2.1268  \n",
      "\n",
      "Fold: 2  Epoch: 227  Training loss = 2.5411  Validation loss = 2.1258  \n",
      "\n",
      "Fold: 2  Epoch: 228  Training loss = 2.5408  Validation loss = 2.1249  \n",
      "\n",
      "Fold: 2  Epoch: 229  Training loss = 2.5408  Validation loss = 2.1247  \n",
      "\n",
      "Fold: 2  Epoch: 230  Training loss = 2.5403  Validation loss = 2.1233  \n",
      "\n",
      "Fold: 2  Epoch: 231  Training loss = 2.5403  Validation loss = 2.1232  \n",
      "\n",
      "Fold: 2  Epoch: 232  Training loss = 2.5402  Validation loss = 2.1230  \n",
      "\n",
      "Fold: 2  Epoch: 233  Training loss = 2.5397  Validation loss = 2.1212  \n",
      "\n",
      "Fold: 2  Epoch: 234  Training loss = 2.5396  Validation loss = 2.1213  \n",
      "\n",
      "Fold: 2  Epoch: 235  Training loss = 2.5394  Validation loss = 2.1207  \n",
      "\n",
      "Fold: 2  Epoch: 236  Training loss = 2.5391  Validation loss = 2.1198  \n",
      "\n",
      "Fold: 2  Epoch: 237  Training loss = 2.5391  Validation loss = 2.1196  \n",
      "\n",
      "Fold: 2  Epoch: 238  Training loss = 2.5389  Validation loss = 2.1187  \n",
      "\n",
      "Fold: 2  Epoch: 239  Training loss = 2.5386  Validation loss = 2.1179  \n",
      "\n",
      "Fold: 2  Epoch: 240  Training loss = 2.5384  Validation loss = 2.1172  \n",
      "\n",
      "Fold: 2  Epoch: 241  Training loss = 2.5381  Validation loss = 2.1168  \n",
      "\n",
      "Fold: 2  Epoch: 242  Training loss = 2.5378  Validation loss = 2.1159  \n",
      "\n",
      "Fold: 2  Epoch: 243  Training loss = 2.5377  Validation loss = 2.1157  \n",
      "\n",
      "Fold: 2  Epoch: 244  Training loss = 2.5375  Validation loss = 2.1156  \n",
      "\n",
      "Fold: 2  Epoch: 245  Training loss = 2.5373  Validation loss = 2.1152  \n",
      "\n",
      "Fold: 2  Epoch: 246  Training loss = 2.5371  Validation loss = 2.1143  \n",
      "\n",
      "Fold: 2  Epoch: 247  Training loss = 2.5369  Validation loss = 2.1137  \n",
      "\n",
      "Fold: 2  Epoch: 248  Training loss = 2.5367  Validation loss = 2.1130  \n",
      "\n",
      "Fold: 2  Epoch: 249  Training loss = 2.5367  Validation loss = 2.1133  \n",
      "\n",
      "Fold: 2  Epoch: 250  Training loss = 2.5366  Validation loss = 2.1128  \n",
      "\n",
      "Fold: 2  Epoch: 251  Training loss = 2.5364  Validation loss = 2.1126  \n",
      "\n",
      "Fold: 2  Epoch: 252  Training loss = 2.5362  Validation loss = 2.1120  \n",
      "\n",
      "Fold: 2  Epoch: 253  Training loss = 2.5361  Validation loss = 2.1119  \n",
      "\n",
      "Fold: 2  Epoch: 254  Training loss = 2.5359  Validation loss = 2.1110  \n",
      "\n",
      "Fold: 2  Epoch: 255  Training loss = 2.5357  Validation loss = 2.1100  \n",
      "\n",
      "Fold: 2  Epoch: 256  Training loss = 2.5357  Validation loss = 2.1099  \n",
      "\n",
      "Fold: 2  Epoch: 257  Training loss = 2.5356  Validation loss = 2.1096  \n",
      "\n",
      "Fold: 2  Epoch: 258  Training loss = 2.5355  Validation loss = 2.1093  \n",
      "\n",
      "Fold: 2  Epoch: 259  Training loss = 2.5354  Validation loss = 2.1093  \n",
      "\n",
      "Fold: 2  Epoch: 260  Training loss = 2.5352  Validation loss = 2.1088  \n",
      "\n",
      "Fold: 2  Epoch: 261  Training loss = 2.5351  Validation loss = 2.1084  \n",
      "\n",
      "Fold: 2  Epoch: 262  Training loss = 2.5349  Validation loss = 2.1080  \n",
      "\n",
      "Fold: 2  Epoch: 263  Training loss = 2.5347  Validation loss = 2.1076  \n",
      "\n",
      "Fold: 2  Epoch: 264  Training loss = 2.5347  Validation loss = 2.1076  \n",
      "\n",
      "Fold: 2  Epoch: 265  Training loss = 2.5346  Validation loss = 2.1075  \n",
      "\n",
      "Fold: 2  Epoch: 266  Training loss = 2.5345  Validation loss = 2.1073  \n",
      "\n",
      "Fold: 2  Epoch: 267  Training loss = 2.5341  Validation loss = 2.1061  \n",
      "\n",
      "Fold: 2  Epoch: 268  Training loss = 2.5342  Validation loss = 2.1065  \n",
      "\n",
      "Fold: 2  Epoch: 269  Training loss = 2.5338  Validation loss = 2.1056  \n",
      "\n",
      "Fold: 2  Epoch: 270  Training loss = 2.5337  Validation loss = 2.1052  \n",
      "\n",
      "Fold: 2  Epoch: 271  Training loss = 2.5335  Validation loss = 2.1045  \n",
      "\n",
      "Fold: 2  Epoch: 272  Training loss = 2.5333  Validation loss = 2.1042  \n",
      "\n",
      "Fold: 2  Epoch: 273  Training loss = 2.5333  Validation loss = 2.1040  \n",
      "\n",
      "Fold: 2  Epoch: 274  Training loss = 2.5329  Validation loss = 2.1026  \n",
      "\n",
      "Fold: 2  Epoch: 275  Training loss = 2.5326  Validation loss = 2.1019  \n",
      "\n",
      "Fold: 2  Epoch: 276  Training loss = 2.5324  Validation loss = 2.1014  \n",
      "\n",
      "Fold: 2  Epoch: 277  Training loss = 2.5323  Validation loss = 2.1012  \n",
      "\n",
      "Fold: 2  Epoch: 278  Training loss = 2.5320  Validation loss = 2.1003  \n",
      "\n",
      "Fold: 2  Epoch: 279  Training loss = 2.5318  Validation loss = 2.0995  \n",
      "\n",
      "Fold: 2  Epoch: 280  Training loss = 2.5316  Validation loss = 2.0990  \n",
      "\n",
      "Fold: 2  Epoch: 281  Training loss = 2.5314  Validation loss = 2.0983  \n",
      "\n",
      "Fold: 2  Epoch: 282  Training loss = 2.5310  Validation loss = 2.0970  \n",
      "\n",
      "Fold: 2  Epoch: 283  Training loss = 2.5309  Validation loss = 2.0966  \n",
      "\n",
      "Fold: 2  Epoch: 284  Training loss = 2.5308  Validation loss = 2.0965  \n",
      "\n",
      "Fold: 2  Epoch: 285  Training loss = 2.5306  Validation loss = 2.0963  \n",
      "\n",
      "Fold: 2  Epoch: 286  Training loss = 2.5303  Validation loss = 2.0950  \n",
      "\n",
      "Fold: 2  Epoch: 287  Training loss = 2.5299  Validation loss = 2.0940  \n",
      "\n",
      "Fold: 2  Epoch: 288  Training loss = 2.5297  Validation loss = 2.0933  \n",
      "\n",
      "Fold: 2  Epoch: 289  Training loss = 2.5296  Validation loss = 2.0932  \n",
      "\n",
      "Fold: 2  Epoch: 290  Training loss = 2.5295  Validation loss = 2.0927  \n",
      "\n",
      "Fold: 2  Epoch: 291  Training loss = 2.5294  Validation loss = 2.0921  \n",
      "\n",
      "Fold: 2  Epoch: 292  Training loss = 2.5292  Validation loss = 2.0913  \n",
      "\n",
      "Fold: 2  Epoch: 293  Training loss = 2.5290  Validation loss = 2.0911  \n",
      "\n",
      "Fold: 2  Epoch: 294  Training loss = 2.5290  Validation loss = 2.0910  \n",
      "\n",
      "Fold: 2  Epoch: 295  Training loss = 2.5288  Validation loss = 2.0905  \n",
      "\n",
      "Fold: 2  Epoch: 296  Training loss = 2.5287  Validation loss = 2.0904  \n",
      "\n",
      "Fold: 2  Epoch: 297  Training loss = 2.5284  Validation loss = 2.0895  \n",
      "\n",
      "Fold: 2  Epoch: 298  Training loss = 2.5280  Validation loss = 2.0881  \n",
      "\n",
      "Fold: 2  Epoch: 299  Training loss = 2.5279  Validation loss = 2.0877  \n",
      "\n",
      "Fold: 2  Epoch: 300  Training loss = 2.5278  Validation loss = 2.0878  \n",
      "\n",
      "Fold: 2  Epoch: 301  Training loss = 2.5275  Validation loss = 2.0870  \n",
      "\n",
      "Fold: 2  Epoch: 302  Training loss = 2.5274  Validation loss = 2.0866  \n",
      "\n",
      "Fold: 2  Epoch: 303  Training loss = 2.5272  Validation loss = 2.0858  \n",
      "\n",
      "Fold: 2  Epoch: 304  Training loss = 2.5270  Validation loss = 2.0852  \n",
      "\n",
      "Fold: 2  Epoch: 305  Training loss = 2.5269  Validation loss = 2.0850  \n",
      "\n",
      "Fold: 2  Epoch: 306  Training loss = 2.5269  Validation loss = 2.0854  \n",
      "\n",
      "Fold: 2  Epoch: 307  Training loss = 2.5269  Validation loss = 2.0854  \n",
      "\n",
      "Fold: 2  Epoch: 308  Training loss = 2.5264  Validation loss = 2.0839  \n",
      "\n",
      "Fold: 2  Epoch: 309  Training loss = 2.5263  Validation loss = 2.0835  \n",
      "\n",
      "Fold: 2  Epoch: 310  Training loss = 2.5261  Validation loss = 2.0829  \n",
      "\n",
      "Fold: 2  Epoch: 311  Training loss = 2.5259  Validation loss = 2.0823  \n",
      "\n",
      "Fold: 2  Epoch: 312  Training loss = 2.5257  Validation loss = 2.0817  \n",
      "\n",
      "Fold: 2  Epoch: 313  Training loss = 2.5255  Validation loss = 2.0811  \n",
      "\n",
      "Fold: 2  Epoch: 314  Training loss = 2.5255  Validation loss = 2.0812  \n",
      "\n",
      "Fold: 2  Epoch: 315  Training loss = 2.5252  Validation loss = 2.0804  \n",
      "\n",
      "Fold: 2  Epoch: 316  Training loss = 2.5252  Validation loss = 2.0803  \n",
      "\n",
      "Fold: 2  Epoch: 317  Training loss = 2.5252  Validation loss = 2.0805  \n",
      "\n",
      "Fold: 2  Epoch: 318  Training loss = 2.5250  Validation loss = 2.0801  \n",
      "\n",
      "Fold: 2  Epoch: 319  Training loss = 2.5249  Validation loss = 2.0799  \n",
      "\n",
      "Fold: 2  Epoch: 320  Training loss = 2.5249  Validation loss = 2.0800  \n",
      "\n",
      "Fold: 2  Epoch: 321  Training loss = 2.5248  Validation loss = 2.0798  \n",
      "\n",
      "Fold: 2  Epoch: 322  Training loss = 2.5248  Validation loss = 2.0800  \n",
      "\n",
      "Fold: 2  Epoch: 323  Training loss = 2.5246  Validation loss = 2.0793  \n",
      "\n",
      "Fold: 2  Epoch: 324  Training loss = 2.5246  Validation loss = 2.0796  \n",
      "\n",
      "Fold: 2  Epoch: 325  Training loss = 2.5245  Validation loss = 2.0792  \n",
      "\n",
      "Fold: 2  Epoch: 326  Training loss = 2.5243  Validation loss = 2.0784  \n",
      "\n",
      "Fold: 2  Epoch: 327  Training loss = 2.5244  Validation loss = 2.0790  \n",
      "\n",
      "Fold: 2  Epoch: 328  Training loss = 2.5242  Validation loss = 2.0787  \n",
      "\n",
      "Fold: 2  Epoch: 329  Training loss = 2.5241  Validation loss = 2.0784  \n",
      "\n",
      "Fold: 2  Epoch: 330  Training loss = 2.5242  Validation loss = 2.0788  \n",
      "\n",
      "Fold: 2  Epoch: 331  Training loss = 2.5241  Validation loss = 2.0784  \n",
      "\n",
      "Fold: 2  Epoch: 332  Training loss = 2.5241  Validation loss = 2.0788  \n",
      "\n",
      "Fold: 2  Epoch: 333  Training loss = 2.5239  Validation loss = 2.0776  \n",
      "\n",
      "Fold: 2  Epoch: 334  Training loss = 2.5237  Validation loss = 2.0770  \n",
      "\n",
      "Fold: 2  Epoch: 335  Training loss = 2.5237  Validation loss = 2.0769  \n",
      "\n",
      "Fold: 2  Epoch: 336  Training loss = 2.5235  Validation loss = 2.0763  \n",
      "\n",
      "Fold: 2  Epoch: 337  Training loss = 2.5234  Validation loss = 2.0759  \n",
      "\n",
      "Fold: 2  Epoch: 338  Training loss = 2.5233  Validation loss = 2.0752  \n",
      "\n",
      "Fold: 2  Epoch: 339  Training loss = 2.5232  Validation loss = 2.0752  \n",
      "\n",
      "Fold: 2  Epoch: 340  Training loss = 2.5231  Validation loss = 2.0751  \n",
      "\n",
      "Fold: 2  Epoch: 341  Training loss = 2.5230  Validation loss = 2.0750  \n",
      "\n",
      "Fold: 2  Epoch: 342  Training loss = 2.5230  Validation loss = 2.0752  \n",
      "\n",
      "Fold: 2  Epoch: 343  Training loss = 2.5228  Validation loss = 2.0745  \n",
      "\n",
      "Fold: 2  Epoch: 344  Training loss = 2.5227  Validation loss = 2.0745  \n",
      "\n",
      "Fold: 2  Epoch: 345  Training loss = 2.5226  Validation loss = 2.0743  \n",
      "\n",
      "Fold: 2  Epoch: 346  Training loss = 2.5226  Validation loss = 2.0745  \n",
      "\n",
      "Fold: 2  Epoch: 347  Training loss = 2.5224  Validation loss = 2.0735  \n",
      "\n",
      "Fold: 2  Epoch: 348  Training loss = 2.5222  Validation loss = 2.0729  \n",
      "\n",
      "Fold: 2  Epoch: 349  Training loss = 2.5221  Validation loss = 2.0725  \n",
      "\n",
      "Fold: 2  Epoch: 350  Training loss = 2.5218  Validation loss = 2.0717  \n",
      "\n",
      "Fold: 2  Epoch: 351  Training loss = 2.5218  Validation loss = 2.0715  \n",
      "\n",
      "Fold: 2  Epoch: 352  Training loss = 2.5214  Validation loss = 2.0701  \n",
      "\n",
      "Fold: 2  Epoch: 353  Training loss = 2.5214  Validation loss = 2.0699  \n",
      "\n",
      "Fold: 2  Epoch: 354  Training loss = 2.5212  Validation loss = 2.0697  \n",
      "\n",
      "Fold: 2  Epoch: 355  Training loss = 2.5212  Validation loss = 2.0695  \n",
      "\n",
      "Fold: 2  Epoch: 356  Training loss = 2.5212  Validation loss = 2.0696  \n",
      "\n",
      "Fold: 2  Epoch: 357  Training loss = 2.5211  Validation loss = 2.0693  \n",
      "\n",
      "Fold: 2  Epoch: 358  Training loss = 2.5208  Validation loss = 2.0687  \n",
      "\n",
      "Fold: 2  Epoch: 359  Training loss = 2.5206  Validation loss = 2.0676  \n",
      "\n",
      "Fold: 2  Epoch: 360  Training loss = 2.5203  Validation loss = 2.0666  \n",
      "\n",
      "Fold: 2  Epoch: 361  Training loss = 2.5202  Validation loss = 2.0661  \n",
      "\n",
      "Fold: 2  Epoch: 362  Training loss = 2.5201  Validation loss = 2.0659  \n",
      "\n",
      "Fold: 2  Epoch: 363  Training loss = 2.5201  Validation loss = 2.0663  \n",
      "\n",
      "Fold: 2  Epoch: 364  Training loss = 2.5199  Validation loss = 2.0659  \n",
      "\n",
      "Fold: 2  Epoch: 365  Training loss = 2.5198  Validation loss = 2.0659  \n",
      "\n",
      "Fold: 2  Epoch: 366  Training loss = 2.5196  Validation loss = 2.0652  \n",
      "\n",
      "Fold: 2  Epoch: 367  Training loss = 2.5195  Validation loss = 2.0652  \n",
      "\n",
      "Fold: 2  Epoch: 368  Training loss = 2.5194  Validation loss = 2.0651  \n",
      "\n",
      "Fold: 2  Epoch: 369  Training loss = 2.5193  Validation loss = 2.0648  \n",
      "\n",
      "Fold: 2  Epoch: 370  Training loss = 2.5193  Validation loss = 2.0647  \n",
      "\n",
      "Fold: 2  Epoch: 371  Training loss = 2.5192  Validation loss = 2.0645  \n",
      "\n",
      "Fold: 2  Epoch: 372  Training loss = 2.5190  Validation loss = 2.0636  \n",
      "\n",
      "Fold: 2  Epoch: 373  Training loss = 2.5189  Validation loss = 2.0636  \n",
      "\n",
      "Fold: 2  Epoch: 374  Training loss = 2.5187  Validation loss = 2.0628  \n",
      "\n",
      "Fold: 2  Epoch: 375  Training loss = 2.5188  Validation loss = 2.0632  \n",
      "\n",
      "Fold: 2  Epoch: 376  Training loss = 2.5186  Validation loss = 2.0627  \n",
      "\n",
      "Fold: 2  Epoch: 377  Training loss = 2.5183  Validation loss = 2.0615  \n",
      "\n",
      "Fold: 2  Epoch: 378  Training loss = 2.5180  Validation loss = 2.0607  \n",
      "\n",
      "Fold: 2  Epoch: 379  Training loss = 2.5179  Validation loss = 2.0603  \n",
      "\n",
      "Fold: 2  Epoch: 380  Training loss = 2.5179  Validation loss = 2.0603  \n",
      "\n",
      "Fold: 2  Epoch: 381  Training loss = 2.5177  Validation loss = 2.0598  \n",
      "\n",
      "Fold: 2  Epoch: 382  Training loss = 2.5177  Validation loss = 2.0596  \n",
      "\n",
      "Fold: 2  Epoch: 383  Training loss = 2.5177  Validation loss = 2.0594  \n",
      "\n",
      "Fold: 2  Epoch: 384  Training loss = 2.5177  Validation loss = 2.0595  \n",
      "\n",
      "Fold: 2  Epoch: 385  Training loss = 2.5176  Validation loss = 2.0593  \n",
      "\n",
      "Fold: 2  Epoch: 386  Training loss = 2.5174  Validation loss = 2.0583  \n",
      "\n",
      "Fold: 2  Epoch: 387  Training loss = 2.5173  Validation loss = 2.0582  \n",
      "\n",
      "Fold: 2  Epoch: 388  Training loss = 2.5171  Validation loss = 2.0573  \n",
      "\n",
      "Fold: 2  Epoch: 389  Training loss = 2.5171  Validation loss = 2.0573  \n",
      "\n",
      "Fold: 2  Epoch: 390  Training loss = 2.5170  Validation loss = 2.0574  \n",
      "\n",
      "Fold: 2  Epoch: 391  Training loss = 2.5169  Validation loss = 2.0569  \n",
      "\n",
      "Fold: 2  Epoch: 392  Training loss = 2.5168  Validation loss = 2.0570  \n",
      "\n",
      "Fold: 2  Epoch: 393  Training loss = 2.5168  Validation loss = 2.0564  \n",
      "\n",
      "Fold: 2  Epoch: 394  Training loss = 2.5167  Validation loss = 2.0560  \n",
      "\n",
      "Fold: 2  Epoch: 395  Training loss = 2.5164  Validation loss = 2.0551  \n",
      "\n",
      "Fold: 2  Epoch: 396  Training loss = 2.5164  Validation loss = 2.0550  \n",
      "\n",
      "Fold: 2  Epoch: 397  Training loss = 2.5163  Validation loss = 2.0549  \n",
      "\n",
      "Fold: 2  Epoch: 398  Training loss = 2.5161  Validation loss = 2.0543  \n",
      "\n",
      "Fold: 2  Epoch: 399  Training loss = 2.5160  Validation loss = 2.0540  \n",
      "\n",
      "Fold: 2  Epoch: 400  Training loss = 2.5159  Validation loss = 2.0535  \n",
      "\n",
      "Fold: 2  Epoch: 401  Training loss = 2.5158  Validation loss = 2.0530  \n",
      "\n",
      "Fold: 2  Epoch: 402  Training loss = 2.5157  Validation loss = 2.0522  \n",
      "\n",
      "Fold: 2  Epoch: 403  Training loss = 2.5156  Validation loss = 2.0519  \n",
      "\n",
      "Fold: 2  Epoch: 404  Training loss = 2.5155  Validation loss = 2.0517  \n",
      "\n",
      "Fold: 2  Epoch: 405  Training loss = 2.5153  Validation loss = 2.0509  \n",
      "\n",
      "Fold: 2  Epoch: 406  Training loss = 2.5152  Validation loss = 2.0508  \n",
      "\n",
      "Fold: 2  Epoch: 407  Training loss = 2.5151  Validation loss = 2.0504  \n",
      "\n",
      "Fold: 2  Epoch: 408  Training loss = 2.5149  Validation loss = 2.0496  \n",
      "\n",
      "Fold: 2  Epoch: 409  Training loss = 2.5148  Validation loss = 2.0495  \n",
      "\n",
      "Fold: 2  Epoch: 410  Training loss = 2.5147  Validation loss = 2.0492  \n",
      "\n",
      "Fold: 2  Epoch: 411  Training loss = 2.5146  Validation loss = 2.0486  \n",
      "\n",
      "Fold: 2  Epoch: 412  Training loss = 2.5146  Validation loss = 2.0483  \n",
      "\n",
      "Fold: 2  Epoch: 413  Training loss = 2.5146  Validation loss = 2.0483  \n",
      "\n",
      "Fold: 2  Epoch: 414  Training loss = 2.5145  Validation loss = 2.0481  \n",
      "\n",
      "Fold: 2  Epoch: 415  Training loss = 2.5143  Validation loss = 2.0477  \n",
      "\n",
      "Fold: 2  Epoch: 416  Training loss = 2.5142  Validation loss = 2.0471  \n",
      "\n",
      "Fold: 2  Epoch: 417  Training loss = 2.5141  Validation loss = 2.0471  \n",
      "\n",
      "Fold: 2  Epoch: 418  Training loss = 2.5140  Validation loss = 2.0469  \n",
      "\n",
      "Fold: 2  Epoch: 419  Training loss = 2.5138  Validation loss = 2.0465  \n",
      "\n",
      "Fold: 2  Epoch: 420  Training loss = 2.5137  Validation loss = 2.0461  \n",
      "\n",
      "Fold: 2  Epoch: 421  Training loss = 2.5137  Validation loss = 2.0463  \n",
      "\n",
      "Fold: 2  Epoch: 422  Training loss = 2.5138  Validation loss = 2.0467  \n",
      "\n",
      "Fold: 2  Epoch: 423  Training loss = 2.5137  Validation loss = 2.0469  \n",
      "\n",
      "Fold: 2  Epoch: 424  Training loss = 2.5135  Validation loss = 2.0459  \n",
      "\n",
      "Fold: 2  Epoch: 425  Training loss = 2.5133  Validation loss = 2.0455  \n",
      "\n",
      "Fold: 2  Epoch: 426  Training loss = 2.5132  Validation loss = 2.0450  \n",
      "\n",
      "Fold: 2  Epoch: 427  Training loss = 2.5132  Validation loss = 2.0453  \n",
      "\n",
      "Fold: 2  Epoch: 428  Training loss = 2.5132  Validation loss = 2.0454  \n",
      "\n",
      "Fold: 2  Epoch: 429  Training loss = 2.5131  Validation loss = 2.0450  \n",
      "\n",
      "Fold: 2  Epoch: 430  Training loss = 2.5128  Validation loss = 2.0439  \n",
      "\n",
      "Fold: 2  Epoch: 431  Training loss = 2.5125  Validation loss = 2.0427  \n",
      "\n",
      "Fold: 2  Epoch: 432  Training loss = 2.5124  Validation loss = 2.0425  \n",
      "\n",
      "Fold: 2  Epoch: 433  Training loss = 2.5123  Validation loss = 2.0416  \n",
      "\n",
      "Fold: 2  Epoch: 434  Training loss = 2.5122  Validation loss = 2.0415  \n",
      "\n",
      "Fold: 2  Epoch: 435  Training loss = 2.5121  Validation loss = 2.0415  \n",
      "\n",
      "Fold: 2  Epoch: 436  Training loss = 2.5121  Validation loss = 2.0415  \n",
      "\n",
      "Fold: 2  Epoch: 437  Training loss = 2.5120  Validation loss = 2.0409  \n",
      "\n",
      "Fold: 2  Epoch: 438  Training loss = 2.5119  Validation loss = 2.0404  \n",
      "\n",
      "Fold: 2  Epoch: 439  Training loss = 2.5117  Validation loss = 2.0396  \n",
      "\n",
      "Fold: 2  Epoch: 440  Training loss = 2.5116  Validation loss = 2.0396  \n",
      "\n",
      "Fold: 2  Epoch: 441  Training loss = 2.5115  Validation loss = 2.0390  \n",
      "\n",
      "Fold: 2  Epoch: 442  Training loss = 2.5115  Validation loss = 2.0386  \n",
      "\n",
      "Fold: 2  Epoch: 443  Training loss = 2.5114  Validation loss = 2.0384  \n",
      "\n",
      "Fold: 2  Epoch: 444  Training loss = 2.5113  Validation loss = 2.0383  \n",
      "\n",
      "Fold: 2  Epoch: 445  Training loss = 2.5112  Validation loss = 2.0379  \n",
      "\n",
      "Fold: 2  Epoch: 446  Training loss = 2.5110  Validation loss = 2.0372  \n",
      "\n",
      "Fold: 2  Epoch: 447  Training loss = 2.5109  Validation loss = 2.0366  \n",
      "\n",
      "Fold: 2  Epoch: 448  Training loss = 2.5107  Validation loss = 2.0361  \n",
      "\n",
      "Fold: 2  Epoch: 449  Training loss = 2.5106  Validation loss = 2.0355  \n",
      "\n",
      "Fold: 2  Epoch: 450  Training loss = 2.5105  Validation loss = 2.0352  \n",
      "\n",
      "Fold: 2  Epoch: 451  Training loss = 2.5105  Validation loss = 2.0352  \n",
      "\n",
      "Fold: 2  Epoch: 452  Training loss = 2.5104  Validation loss = 2.0346  \n",
      "\n",
      "Fold: 2  Epoch: 453  Training loss = 2.5103  Validation loss = 2.0344  \n",
      "\n",
      "Fold: 2  Epoch: 454  Training loss = 2.5102  Validation loss = 2.0339  \n",
      "\n",
      "Fold: 2  Epoch: 455  Training loss = 2.5102  Validation loss = 2.0336  \n",
      "\n",
      "Fold: 2  Epoch: 456  Training loss = 2.5102  Validation loss = 2.0339  \n",
      "\n",
      "Fold: 2  Epoch: 457  Training loss = 2.5101  Validation loss = 2.0334  \n",
      "\n",
      "Fold: 2  Epoch: 458  Training loss = 2.5100  Validation loss = 2.0334  \n",
      "\n",
      "Fold: 2  Epoch: 459  Training loss = 2.5099  Validation loss = 2.0334  \n",
      "\n",
      "Fold: 2  Epoch: 460  Training loss = 2.5099  Validation loss = 2.0330  \n",
      "\n",
      "Fold: 2  Epoch: 461  Training loss = 2.5099  Validation loss = 2.0326  \n",
      "\n",
      "Fold: 2  Epoch: 462  Training loss = 2.5098  Validation loss = 2.0324  \n",
      "\n",
      "Fold: 2  Epoch: 463  Training loss = 2.5095  Validation loss = 2.0312  \n",
      "\n",
      "Fold: 2  Epoch: 464  Training loss = 2.5094  Validation loss = 2.0309  \n",
      "\n",
      "Fold: 2  Epoch: 465  Training loss = 2.5093  Validation loss = 2.0305  \n",
      "\n",
      "Fold: 2  Epoch: 466  Training loss = 2.5092  Validation loss = 2.0301  \n",
      "\n",
      "Fold: 2  Epoch: 467  Training loss = 2.5091  Validation loss = 2.0297  \n",
      "\n",
      "Fold: 2  Epoch: 468  Training loss = 2.5092  Validation loss = 2.0306  \n",
      "\n",
      "Fold: 2  Epoch: 469  Training loss = 2.5093  Validation loss = 2.0312  \n",
      "\n",
      "Fold: 2  Epoch: 470  Training loss = 2.5091  Validation loss = 2.0308  \n",
      "\n",
      "Fold: 2  Epoch: 471  Training loss = 2.5091  Validation loss = 2.0306  \n",
      "\n",
      "Fold: 2  Epoch: 472  Training loss = 2.5089  Validation loss = 2.0300  \n",
      "\n",
      "Fold: 2  Epoch: 473  Training loss = 2.5089  Validation loss = 2.0299  \n",
      "\n",
      "Fold: 2  Epoch: 474  Training loss = 2.5088  Validation loss = 2.0297  \n",
      "\n",
      "Fold: 2  Epoch: 475  Training loss = 2.5086  Validation loss = 2.0290  \n",
      "\n",
      "Fold: 2  Epoch: 476  Training loss = 2.5086  Validation loss = 2.0292  \n",
      "\n",
      "Fold: 2  Epoch: 477  Training loss = 2.5086  Validation loss = 2.0296  \n",
      "\n",
      "Fold: 2  Epoch: 478  Training loss = 2.5086  Validation loss = 2.0291  \n",
      "\n",
      "Fold: 2  Epoch: 479  Training loss = 2.5085  Validation loss = 2.0287  \n",
      "\n",
      "Fold: 2  Epoch: 480  Training loss = 2.5084  Validation loss = 2.0282  \n",
      "\n",
      "Fold: 2  Epoch: 481  Training loss = 2.5083  Validation loss = 2.0278  \n",
      "\n",
      "Fold: 2  Epoch: 482  Training loss = 2.5080  Validation loss = 2.0265  \n",
      "\n",
      "Fold: 2  Epoch: 483  Training loss = 2.5079  Validation loss = 2.0261  \n",
      "\n",
      "Fold: 2  Epoch: 484  Training loss = 2.5079  Validation loss = 2.0262  \n",
      "\n",
      "Fold: 2  Epoch: 485  Training loss = 2.5079  Validation loss = 2.0261  \n",
      "\n",
      "Fold: 2  Epoch: 486  Training loss = 2.5078  Validation loss = 2.0259  \n",
      "\n",
      "Fold: 2  Epoch: 487  Training loss = 2.5075  Validation loss = 2.0250  \n",
      "\n",
      "Fold: 2  Epoch: 488  Training loss = 2.5074  Validation loss = 2.0244  \n",
      "\n",
      "Fold: 2  Epoch: 489  Training loss = 2.5073  Validation loss = 2.0243  \n",
      "\n",
      "Fold: 2  Epoch: 490  Training loss = 2.5073  Validation loss = 2.0241  \n",
      "\n",
      "Fold: 2  Epoch: 491  Training loss = 2.5072  Validation loss = 2.0243  \n",
      "\n",
      "Fold: 2  Epoch: 492  Training loss = 2.5073  Validation loss = 2.0248  \n",
      "\n",
      "Fold: 2  Epoch: 493  Training loss = 2.5070  Validation loss = 2.0239  \n",
      "\n",
      "Fold: 2  Epoch: 494  Training loss = 2.5070  Validation loss = 2.0238  \n",
      "\n",
      "Fold: 2  Epoch: 495  Training loss = 2.5067  Validation loss = 2.0229  \n",
      "\n",
      "Fold: 2  Epoch: 496  Training loss = 2.5068  Validation loss = 2.0234  \n",
      "\n",
      "Fold: 2  Epoch: 497  Training loss = 2.5068  Validation loss = 2.0234  \n",
      "\n",
      "Fold: 2  Epoch: 498  Training loss = 2.5067  Validation loss = 2.0231  \n",
      "\n",
      "Fold: 2  Epoch: 499  Training loss = 2.5067  Validation loss = 2.0232  \n",
      "\n",
      "Fold: 2  Epoch: 500  Training loss = 2.5066  Validation loss = 2.0229  \n",
      "\n",
      "Check model:  Fold: 2  Epoch: 500  Training loss = 2.5066  Validation loss = 2.0229  \n",
      "\n",
      "Fold: 3  Epoch: 1  Training loss = 1.5076  Validation loss = 3.2293  \n",
      "\n",
      "Fold: 3  Epoch: 2  Training loss = 1.5075  Validation loss = 3.2302  \n",
      "\n",
      "Fold: 3  Epoch: 3  Training loss = 1.5074  Validation loss = 3.2304  \n",
      "\n",
      "Fold: 3  Epoch: 4  Training loss = 1.5074  Validation loss = 3.2304  \n",
      "\n",
      "Fold: 3  Epoch: 5  Training loss = 1.5074  Validation loss = 3.2309  \n",
      "\n",
      "Fold: 3  Epoch: 6  Training loss = 1.5073  Validation loss = 3.2312  \n",
      "\n",
      "Fold: 3  Epoch: 7  Training loss = 1.5073  Validation loss = 3.2312  \n",
      "\n",
      "Fold: 3  Epoch: 8  Training loss = 1.5073  Validation loss = 3.2313  \n",
      "\n",
      "Fold: 3  Epoch: 9  Training loss = 1.5072  Validation loss = 3.2316  \n",
      "\n",
      "Fold: 3  Epoch: 10  Training loss = 1.5071  Validation loss = 3.2322  \n",
      "\n",
      "Fold: 3  Epoch: 11  Training loss = 1.5071  Validation loss = 3.2323  \n",
      "\n",
      "Check model:  Fold: 3  Epoch: 1  Training loss = 1.5071  Validation loss = 3.2323  \n",
      "\n",
      "Fold: 4  Epoch: 1  Training loss = 1.6018  Validation loss = 4.4430  \n",
      "\n",
      "Fold: 4  Epoch: 2  Training loss = 1.6017  Validation loss = 4.4425  \n",
      "\n",
      "Fold: 4  Epoch: 3  Training loss = 1.6017  Validation loss = 4.4422  \n",
      "\n",
      "Fold: 4  Epoch: 4  Training loss = 1.6016  Validation loss = 4.4419  \n",
      "\n",
      "Fold: 4  Epoch: 5  Training loss = 1.6016  Validation loss = 4.4413  \n",
      "\n",
      "Fold: 4  Epoch: 6  Training loss = 1.6015  Validation loss = 4.4414  \n",
      "\n",
      "Fold: 4  Epoch: 7  Training loss = 1.6015  Validation loss = 4.4417  \n",
      "\n",
      "Fold: 4  Epoch: 8  Training loss = 1.6014  Validation loss = 4.4412  \n",
      "\n",
      "Fold: 4  Epoch: 9  Training loss = 1.6013  Validation loss = 4.4404  \n",
      "\n",
      "Fold: 4  Epoch: 10  Training loss = 1.6013  Validation loss = 4.4399  \n",
      "\n",
      "Fold: 4  Epoch: 11  Training loss = 1.6012  Validation loss = 4.4387  \n",
      "\n",
      "Fold: 4  Epoch: 12  Training loss = 1.6011  Validation loss = 4.4382  \n",
      "\n",
      "Fold: 4  Epoch: 13  Training loss = 1.6011  Validation loss = 4.4372  \n",
      "\n",
      "Fold: 4  Epoch: 14  Training loss = 1.6010  Validation loss = 4.4375  \n",
      "\n",
      "Fold: 4  Epoch: 15  Training loss = 1.6010  Validation loss = 4.4371  \n",
      "\n",
      "Fold: 4  Epoch: 16  Training loss = 1.6009  Validation loss = 4.4357  \n",
      "\n",
      "Fold: 4  Epoch: 17  Training loss = 1.6008  Validation loss = 4.4352  \n",
      "\n",
      "Fold: 4  Epoch: 18  Training loss = 1.6007  Validation loss = 4.4340  \n",
      "\n",
      "Fold: 4  Epoch: 19  Training loss = 1.6007  Validation loss = 4.4335  \n",
      "\n",
      "Fold: 4  Epoch: 20  Training loss = 1.6006  Validation loss = 4.4327  \n",
      "\n",
      "Fold: 4  Epoch: 21  Training loss = 1.6005  Validation loss = 4.4328  \n",
      "\n",
      "Fold: 4  Epoch: 22  Training loss = 1.6005  Validation loss = 4.4320  \n",
      "\n",
      "Fold: 4  Epoch: 23  Training loss = 1.6004  Validation loss = 4.4323  \n",
      "\n",
      "Fold: 4  Epoch: 24  Training loss = 1.6004  Validation loss = 4.4329  \n",
      "\n",
      "Fold: 4  Epoch: 25  Training loss = 1.6004  Validation loss = 4.4329  \n",
      "\n",
      "Fold: 4  Epoch: 26  Training loss = 1.6003  Validation loss = 4.4327  \n",
      "\n",
      "Fold: 4  Epoch: 27  Training loss = 1.6003  Validation loss = 4.4332  \n",
      "\n",
      "Fold: 4  Epoch: 28  Training loss = 1.6002  Validation loss = 4.4326  \n",
      "\n",
      "Fold: 4  Epoch: 29  Training loss = 1.6002  Validation loss = 4.4320  \n",
      "\n",
      "Fold: 4  Epoch: 30  Training loss = 1.6001  Validation loss = 4.4318  \n",
      "\n",
      "Fold: 4  Epoch: 31  Training loss = 1.6000  Validation loss = 4.4303  \n",
      "\n",
      "Fold: 4  Epoch: 32  Training loss = 1.5999  Validation loss = 4.4295  \n",
      "\n",
      "Fold: 4  Epoch: 33  Training loss = 1.5999  Validation loss = 4.4303  \n",
      "\n",
      "Fold: 4  Epoch: 34  Training loss = 1.5999  Validation loss = 4.4297  \n",
      "\n",
      "Fold: 4  Epoch: 35  Training loss = 1.5998  Validation loss = 4.4293  \n",
      "\n",
      "Fold: 4  Epoch: 36  Training loss = 1.5997  Validation loss = 4.4276  \n",
      "\n",
      "Fold: 4  Epoch: 37  Training loss = 1.5997  Validation loss = 4.4270  \n",
      "\n",
      "Fold: 4  Epoch: 38  Training loss = 1.5996  Validation loss = 4.4266  \n",
      "\n",
      "Fold: 4  Epoch: 39  Training loss = 1.5996  Validation loss = 4.4267  \n",
      "\n",
      "Fold: 4  Epoch: 40  Training loss = 1.5996  Validation loss = 4.4264  \n",
      "\n",
      "Fold: 4  Epoch: 41  Training loss = 1.5995  Validation loss = 4.4259  \n",
      "\n",
      "Fold: 4  Epoch: 42  Training loss = 1.5994  Validation loss = 4.4254  \n",
      "\n",
      "Fold: 4  Epoch: 43  Training loss = 1.5993  Validation loss = 4.4242  \n",
      "\n",
      "Fold: 4  Epoch: 44  Training loss = 1.5993  Validation loss = 4.4252  \n",
      "\n",
      "Fold: 4  Epoch: 45  Training loss = 1.5993  Validation loss = 4.4250  \n",
      "\n",
      "Fold: 4  Epoch: 46  Training loss = 1.5992  Validation loss = 4.4234  \n",
      "\n",
      "Fold: 4  Epoch: 47  Training loss = 1.5992  Validation loss = 4.4238  \n",
      "\n",
      "Fold: 4  Epoch: 48  Training loss = 1.5991  Validation loss = 4.4228  \n",
      "\n",
      "Fold: 4  Epoch: 49  Training loss = 1.5990  Validation loss = 4.4221  \n",
      "\n",
      "Fold: 4  Epoch: 50  Training loss = 1.5990  Validation loss = 4.4217  \n",
      "\n",
      "Fold: 4  Epoch: 51  Training loss = 1.5989  Validation loss = 4.4205  \n",
      "\n",
      "Fold: 4  Epoch: 52  Training loss = 1.5988  Validation loss = 4.4195  \n",
      "\n",
      "Fold: 4  Epoch: 53  Training loss = 1.5988  Validation loss = 4.4199  \n",
      "\n",
      "Fold: 4  Epoch: 54  Training loss = 1.5988  Validation loss = 4.4196  \n",
      "\n",
      "Fold: 4  Epoch: 55  Training loss = 1.5987  Validation loss = 4.4192  \n",
      "\n",
      "Fold: 4  Epoch: 56  Training loss = 1.5987  Validation loss = 4.4197  \n",
      "\n",
      "Fold: 4  Epoch: 57  Training loss = 1.5987  Validation loss = 4.4203  \n",
      "\n",
      "Fold: 4  Epoch: 58  Training loss = 1.5985  Validation loss = 4.4186  \n",
      "\n",
      "Fold: 4  Epoch: 59  Training loss = 1.5985  Validation loss = 4.4180  \n",
      "\n",
      "Fold: 4  Epoch: 60  Training loss = 1.5984  Validation loss = 4.4169  \n",
      "\n",
      "Fold: 4  Epoch: 61  Training loss = 1.5983  Validation loss = 4.4163  \n",
      "\n",
      "Fold: 4  Epoch: 62  Training loss = 1.5983  Validation loss = 4.4155  \n",
      "\n",
      "Fold: 4  Epoch: 63  Training loss = 1.5982  Validation loss = 4.4147  \n",
      "\n",
      "Fold: 4  Epoch: 64  Training loss = 1.5981  Validation loss = 4.4141  \n",
      "\n",
      "Fold: 4  Epoch: 65  Training loss = 1.5981  Validation loss = 4.4139  \n",
      "\n",
      "Fold: 4  Epoch: 66  Training loss = 1.5980  Validation loss = 4.4132  \n",
      "\n",
      "Fold: 4  Epoch: 67  Training loss = 1.5979  Validation loss = 4.4120  \n",
      "\n",
      "Fold: 4  Epoch: 68  Training loss = 1.5978  Validation loss = 4.4110  \n",
      "\n",
      "Fold: 4  Epoch: 69  Training loss = 1.5978  Validation loss = 4.4105  \n",
      "\n",
      "Fold: 4  Epoch: 70  Training loss = 1.5977  Validation loss = 4.4099  \n",
      "\n",
      "Fold: 4  Epoch: 71  Training loss = 1.5977  Validation loss = 4.4096  \n",
      "\n",
      "Fold: 4  Epoch: 72  Training loss = 1.5977  Validation loss = 4.4095  \n",
      "\n",
      "Fold: 4  Epoch: 73  Training loss = 1.5976  Validation loss = 4.4094  \n",
      "\n",
      "Fold: 4  Epoch: 74  Training loss = 1.5976  Validation loss = 4.4090  \n",
      "\n",
      "Fold: 4  Epoch: 75  Training loss = 1.5975  Validation loss = 4.4090  \n",
      "\n",
      "Fold: 4  Epoch: 76  Training loss = 1.5975  Validation loss = 4.4086  \n",
      "\n",
      "Fold: 4  Epoch: 77  Training loss = 1.5975  Validation loss = 4.4089  \n",
      "\n",
      "Fold: 4  Epoch: 78  Training loss = 1.5974  Validation loss = 4.4087  \n",
      "\n",
      "Fold: 4  Epoch: 79  Training loss = 1.5974  Validation loss = 4.4086  \n",
      "\n",
      "Fold: 4  Epoch: 80  Training loss = 1.5974  Validation loss = 4.4086  \n",
      "\n",
      "Fold: 4  Epoch: 81  Training loss = 1.5973  Validation loss = 4.4071  \n",
      "\n",
      "Fold: 4  Epoch: 82  Training loss = 1.5973  Validation loss = 4.4067  \n",
      "\n",
      "Fold: 4  Epoch: 83  Training loss = 1.5972  Validation loss = 4.4065  \n",
      "\n",
      "Fold: 4  Epoch: 84  Training loss = 1.5971  Validation loss = 4.4058  \n",
      "\n",
      "Fold: 4  Epoch: 85  Training loss = 1.5971  Validation loss = 4.4058  \n",
      "\n",
      "Fold: 4  Epoch: 86  Training loss = 1.5970  Validation loss = 4.4050  \n",
      "\n",
      "Fold: 4  Epoch: 87  Training loss = 1.5970  Validation loss = 4.4055  \n",
      "\n",
      "Fold: 4  Epoch: 88  Training loss = 1.5970  Validation loss = 4.4058  \n",
      "\n",
      "Fold: 4  Epoch: 89  Training loss = 1.5970  Validation loss = 4.4062  \n",
      "\n",
      "Fold: 4  Epoch: 90  Training loss = 1.5970  Validation loss = 4.4064  \n",
      "\n",
      "Fold: 4  Epoch: 91  Training loss = 1.5969  Validation loss = 4.4057  \n",
      "\n",
      "Fold: 4  Epoch: 92  Training loss = 1.5968  Validation loss = 4.4055  \n",
      "\n",
      "Fold: 4  Epoch: 93  Training loss = 1.5968  Validation loss = 4.4052  \n",
      "\n",
      "Fold: 4  Epoch: 94  Training loss = 1.5968  Validation loss = 4.4052  \n",
      "\n",
      "Fold: 4  Epoch: 95  Training loss = 1.5967  Validation loss = 4.4041  \n",
      "\n",
      "Fold: 4  Epoch: 96  Training loss = 1.5966  Validation loss = 4.4038  \n",
      "\n",
      "Fold: 4  Epoch: 97  Training loss = 1.5966  Validation loss = 4.4032  \n",
      "\n",
      "Fold: 4  Epoch: 98  Training loss = 1.5965  Validation loss = 4.4027  \n",
      "\n",
      "Fold: 4  Epoch: 99  Training loss = 1.5965  Validation loss = 4.4027  \n",
      "\n",
      "Fold: 4  Epoch: 100  Training loss = 1.5965  Validation loss = 4.4029  \n",
      "\n",
      "Fold: 4  Epoch: 101  Training loss = 1.5964  Validation loss = 4.4025  \n",
      "\n",
      "Fold: 4  Epoch: 102  Training loss = 1.5964  Validation loss = 4.4025  \n",
      "\n",
      "Fold: 4  Epoch: 103  Training loss = 1.5963  Validation loss = 4.4020  \n",
      "\n",
      "Fold: 4  Epoch: 104  Training loss = 1.5963  Validation loss = 4.4014  \n",
      "\n",
      "Fold: 4  Epoch: 105  Training loss = 1.5962  Validation loss = 4.4008  \n",
      "\n",
      "Fold: 4  Epoch: 106  Training loss = 1.5961  Validation loss = 4.4005  \n",
      "\n",
      "Fold: 4  Epoch: 107  Training loss = 1.5961  Validation loss = 4.3999  \n",
      "\n",
      "Fold: 4  Epoch: 108  Training loss = 1.5960  Validation loss = 4.3997  \n",
      "\n",
      "Fold: 4  Epoch: 109  Training loss = 1.5960  Validation loss = 4.3997  \n",
      "\n",
      "Fold: 4  Epoch: 110  Training loss = 1.5959  Validation loss = 4.3989  \n",
      "\n",
      "Fold: 4  Epoch: 111  Training loss = 1.5959  Validation loss = 4.3982  \n",
      "\n",
      "Fold: 4  Epoch: 112  Training loss = 1.5958  Validation loss = 4.3983  \n",
      "\n",
      "Fold: 4  Epoch: 113  Training loss = 1.5958  Validation loss = 4.3985  \n",
      "\n",
      "Fold: 4  Epoch: 114  Training loss = 1.5957  Validation loss = 4.3972  \n",
      "\n",
      "Fold: 4  Epoch: 115  Training loss = 1.5956  Validation loss = 4.3973  \n",
      "\n",
      "Fold: 4  Epoch: 116  Training loss = 1.5956  Validation loss = 4.3966  \n",
      "\n",
      "Fold: 4  Epoch: 117  Training loss = 1.5956  Validation loss = 4.3969  \n",
      "\n",
      "Fold: 4  Epoch: 118  Training loss = 1.5955  Validation loss = 4.3957  \n",
      "\n",
      "Fold: 4  Epoch: 119  Training loss = 1.5954  Validation loss = 4.3963  \n",
      "\n",
      "Fold: 4  Epoch: 120  Training loss = 1.5954  Validation loss = 4.3958  \n",
      "\n",
      "Fold: 4  Epoch: 121  Training loss = 1.5953  Validation loss = 4.3949  \n",
      "\n",
      "Fold: 4  Epoch: 122  Training loss = 1.5953  Validation loss = 4.3946  \n",
      "\n",
      "Fold: 4  Epoch: 123  Training loss = 1.5952  Validation loss = 4.3944  \n",
      "\n",
      "Fold: 4  Epoch: 124  Training loss = 1.5952  Validation loss = 4.3934  \n",
      "\n",
      "Fold: 4  Epoch: 125  Training loss = 1.5952  Validation loss = 4.3940  \n",
      "\n",
      "Fold: 4  Epoch: 126  Training loss = 1.5951  Validation loss = 4.3928  \n",
      "\n",
      "Fold: 4  Epoch: 127  Training loss = 1.5950  Validation loss = 4.3917  \n",
      "\n",
      "Fold: 4  Epoch: 128  Training loss = 1.5949  Validation loss = 4.3913  \n",
      "\n",
      "Fold: 4  Epoch: 129  Training loss = 1.5949  Validation loss = 4.3911  \n",
      "\n",
      "Fold: 4  Epoch: 130  Training loss = 1.5948  Validation loss = 4.3906  \n",
      "\n",
      "Fold: 4  Epoch: 131  Training loss = 1.5948  Validation loss = 4.3901  \n",
      "\n",
      "Fold: 4  Epoch: 132  Training loss = 1.5947  Validation loss = 4.3900  \n",
      "\n",
      "Fold: 4  Epoch: 133  Training loss = 1.5946  Validation loss = 4.3902  \n",
      "\n",
      "Fold: 4  Epoch: 134  Training loss = 1.5946  Validation loss = 4.3899  \n",
      "\n",
      "Fold: 4  Epoch: 135  Training loss = 1.5946  Validation loss = 4.3896  \n",
      "\n",
      "Fold: 4  Epoch: 136  Training loss = 1.5945  Validation loss = 4.3891  \n",
      "\n",
      "Fold: 4  Epoch: 137  Training loss = 1.5945  Validation loss = 4.3894  \n",
      "\n",
      "Fold: 4  Epoch: 138  Training loss = 1.5944  Validation loss = 4.3882  \n",
      "\n",
      "Fold: 4  Epoch: 139  Training loss = 1.5943  Validation loss = 4.3878  \n",
      "\n",
      "Fold: 4  Epoch: 140  Training loss = 1.5943  Validation loss = 4.3874  \n",
      "\n",
      "Fold: 4  Epoch: 141  Training loss = 1.5942  Validation loss = 4.3862  \n",
      "\n",
      "Fold: 4  Epoch: 142  Training loss = 1.5942  Validation loss = 4.3859  \n",
      "\n",
      "Fold: 4  Epoch: 143  Training loss = 1.5941  Validation loss = 4.3851  \n",
      "\n",
      "Fold: 4  Epoch: 144  Training loss = 1.5941  Validation loss = 4.3853  \n",
      "\n",
      "Fold: 4  Epoch: 145  Training loss = 1.5940  Validation loss = 4.3848  \n",
      "\n",
      "Fold: 4  Epoch: 146  Training loss = 1.5940  Validation loss = 4.3850  \n",
      "\n",
      "Fold: 4  Epoch: 147  Training loss = 1.5940  Validation loss = 4.3847  \n",
      "\n",
      "Fold: 4  Epoch: 148  Training loss = 1.5940  Validation loss = 4.3856  \n",
      "\n",
      "Fold: 4  Epoch: 149  Training loss = 1.5939  Validation loss = 4.3855  \n",
      "\n",
      "Fold: 4  Epoch: 150  Training loss = 1.5939  Validation loss = 4.3848  \n",
      "\n",
      "Fold: 4  Epoch: 151  Training loss = 1.5938  Validation loss = 4.3845  \n",
      "\n",
      "Fold: 4  Epoch: 152  Training loss = 1.5938  Validation loss = 4.3845  \n",
      "\n",
      "Fold: 4  Epoch: 153  Training loss = 1.5938  Validation loss = 4.3844  \n",
      "\n",
      "Fold: 4  Epoch: 154  Training loss = 1.5937  Validation loss = 4.3843  \n",
      "\n",
      "Fold: 4  Epoch: 155  Training loss = 1.5937  Validation loss = 4.3850  \n",
      "\n",
      "Fold: 4  Epoch: 156  Training loss = 1.5937  Validation loss = 4.3843  \n",
      "\n",
      "Fold: 4  Epoch: 157  Training loss = 1.5936  Validation loss = 4.3837  \n",
      "\n",
      "Fold: 4  Epoch: 158  Training loss = 1.5936  Validation loss = 4.3831  \n",
      "\n",
      "Fold: 4  Epoch: 159  Training loss = 1.5935  Validation loss = 4.3825  \n",
      "\n",
      "Fold: 4  Epoch: 160  Training loss = 1.5935  Validation loss = 4.3819  \n",
      "\n",
      "Fold: 4  Epoch: 161  Training loss = 1.5934  Validation loss = 4.3819  \n",
      "\n",
      "Fold: 4  Epoch: 162  Training loss = 1.5934  Validation loss = 4.3814  \n",
      "\n",
      "Fold: 4  Epoch: 163  Training loss = 1.5933  Validation loss = 4.3812  \n",
      "\n",
      "Fold: 4  Epoch: 164  Training loss = 1.5933  Validation loss = 4.3809  \n",
      "\n",
      "Fold: 4  Epoch: 165  Training loss = 1.5932  Validation loss = 4.3799  \n",
      "\n",
      "Fold: 4  Epoch: 166  Training loss = 1.5931  Validation loss = 4.3795  \n",
      "\n",
      "Fold: 4  Epoch: 167  Training loss = 1.5931  Validation loss = 4.3790  \n",
      "\n",
      "Fold: 4  Epoch: 168  Training loss = 1.5931  Validation loss = 4.3789  \n",
      "\n",
      "Fold: 4  Epoch: 169  Training loss = 1.5930  Validation loss = 4.3786  \n",
      "\n",
      "Fold: 4  Epoch: 170  Training loss = 1.5930  Validation loss = 4.3783  \n",
      "\n",
      "Fold: 4  Epoch: 171  Training loss = 1.5929  Validation loss = 4.3783  \n",
      "\n",
      "Fold: 4  Epoch: 172  Training loss = 1.5929  Validation loss = 4.3774  \n",
      "\n",
      "Fold: 4  Epoch: 173  Training loss = 1.5928  Validation loss = 4.3768  \n",
      "\n",
      "Fold: 4  Epoch: 174  Training loss = 1.5928  Validation loss = 4.3763  \n",
      "\n",
      "Fold: 4  Epoch: 175  Training loss = 1.5927  Validation loss = 4.3759  \n",
      "\n",
      "Fold: 4  Epoch: 176  Training loss = 1.5927  Validation loss = 4.3755  \n",
      "\n",
      "Fold: 4  Epoch: 177  Training loss = 1.5927  Validation loss = 4.3754  \n",
      "\n",
      "Fold: 4  Epoch: 178  Training loss = 1.5926  Validation loss = 4.3740  \n",
      "\n",
      "Fold: 4  Epoch: 179  Training loss = 1.5925  Validation loss = 4.3728  \n",
      "\n",
      "Fold: 4  Epoch: 180  Training loss = 1.5925  Validation loss = 4.3729  \n",
      "\n",
      "Fold: 4  Epoch: 181  Training loss = 1.5924  Validation loss = 4.3729  \n",
      "\n",
      "Fold: 4  Epoch: 182  Training loss = 1.5923  Validation loss = 4.3718  \n",
      "\n",
      "Fold: 4  Epoch: 183  Training loss = 1.5923  Validation loss = 4.3714  \n",
      "\n",
      "Fold: 4  Epoch: 184  Training loss = 1.5923  Validation loss = 4.3718  \n",
      "\n",
      "Fold: 4  Epoch: 185  Training loss = 1.5922  Validation loss = 4.3713  \n",
      "\n",
      "Fold: 4  Epoch: 186  Training loss = 1.5921  Validation loss = 4.3695  \n",
      "\n",
      "Fold: 4  Epoch: 187  Training loss = 1.5921  Validation loss = 4.3689  \n",
      "\n",
      "Fold: 4  Epoch: 188  Training loss = 1.5920  Validation loss = 4.3688  \n",
      "\n",
      "Fold: 4  Epoch: 189  Training loss = 1.5920  Validation loss = 4.3685  \n",
      "\n",
      "Fold: 4  Epoch: 190  Training loss = 1.5920  Validation loss = 4.3692  \n",
      "\n",
      "Fold: 4  Epoch: 191  Training loss = 1.5919  Validation loss = 4.3679  \n",
      "\n",
      "Fold: 4  Epoch: 192  Training loss = 1.5919  Validation loss = 4.3680  \n",
      "\n",
      "Fold: 4  Epoch: 193  Training loss = 1.5918  Validation loss = 4.3666  \n",
      "\n",
      "Fold: 4  Epoch: 194  Training loss = 1.5918  Validation loss = 4.3668  \n",
      "\n",
      "Fold: 4  Epoch: 195  Training loss = 1.5918  Validation loss = 4.3662  \n",
      "\n",
      "Fold: 4  Epoch: 196  Training loss = 1.5917  Validation loss = 4.3662  \n",
      "\n",
      "Fold: 4  Epoch: 197  Training loss = 1.5917  Validation loss = 4.3657  \n",
      "\n",
      "Fold: 4  Epoch: 198  Training loss = 1.5916  Validation loss = 4.3653  \n",
      "\n",
      "Fold: 4  Epoch: 199  Training loss = 1.5916  Validation loss = 4.3649  \n",
      "\n",
      "Fold: 4  Epoch: 200  Training loss = 1.5915  Validation loss = 4.3644  \n",
      "\n",
      "Fold: 4  Epoch: 201  Training loss = 1.5915  Validation loss = 4.3646  \n",
      "\n",
      "Fold: 4  Epoch: 202  Training loss = 1.5914  Validation loss = 4.3646  \n",
      "\n",
      "Fold: 4  Epoch: 203  Training loss = 1.5914  Validation loss = 4.3645  \n",
      "\n",
      "Fold: 4  Epoch: 204  Training loss = 1.5914  Validation loss = 4.3647  \n",
      "\n",
      "Fold: 4  Epoch: 205  Training loss = 1.5913  Validation loss = 4.3647  \n",
      "\n",
      "Fold: 4  Epoch: 206  Training loss = 1.5913  Validation loss = 4.3643  \n",
      "\n",
      "Fold: 4  Epoch: 207  Training loss = 1.5913  Validation loss = 4.3639  \n",
      "\n",
      "Fold: 4  Epoch: 208  Training loss = 1.5913  Validation loss = 4.3638  \n",
      "\n",
      "Fold: 4  Epoch: 209  Training loss = 1.5912  Validation loss = 4.3630  \n",
      "\n",
      "Fold: 4  Epoch: 210  Training loss = 1.5912  Validation loss = 4.3623  \n",
      "\n",
      "Fold: 4  Epoch: 211  Training loss = 1.5911  Validation loss = 4.3621  \n",
      "\n",
      "Fold: 4  Epoch: 212  Training loss = 1.5911  Validation loss = 4.3613  \n",
      "\n",
      "Fold: 4  Epoch: 213  Training loss = 1.5910  Validation loss = 4.3617  \n",
      "\n",
      "Fold: 4  Epoch: 214  Training loss = 1.5910  Validation loss = 4.3616  \n",
      "\n",
      "Fold: 4  Epoch: 215  Training loss = 1.5909  Validation loss = 4.3601  \n",
      "\n",
      "Fold: 4  Epoch: 216  Training loss = 1.5909  Validation loss = 4.3597  \n",
      "\n",
      "Fold: 4  Epoch: 217  Training loss = 1.5908  Validation loss = 4.3591  \n",
      "\n",
      "Fold: 4  Epoch: 218  Training loss = 1.5908  Validation loss = 4.3585  \n",
      "\n",
      "Fold: 4  Epoch: 219  Training loss = 1.5907  Validation loss = 4.3598  \n",
      "\n",
      "Fold: 4  Epoch: 220  Training loss = 1.5907  Validation loss = 4.3597  \n",
      "\n",
      "Fold: 4  Epoch: 221  Training loss = 1.5907  Validation loss = 4.3594  \n",
      "\n",
      "Fold: 4  Epoch: 222  Training loss = 1.5906  Validation loss = 4.3593  \n",
      "\n",
      "Fold: 4  Epoch: 223  Training loss = 1.5906  Validation loss = 4.3594  \n",
      "\n",
      "Fold: 4  Epoch: 224  Training loss = 1.5906  Validation loss = 4.3598  \n",
      "\n",
      "Fold: 4  Epoch: 225  Training loss = 1.5905  Validation loss = 4.3589  \n",
      "\n",
      "Fold: 4  Epoch: 226  Training loss = 1.5904  Validation loss = 4.3581  \n",
      "\n",
      "Fold: 4  Epoch: 227  Training loss = 1.5904  Validation loss = 4.3576  \n",
      "\n",
      "Fold: 4  Epoch: 228  Training loss = 1.5904  Validation loss = 4.3578  \n",
      "\n",
      "Fold: 4  Epoch: 229  Training loss = 1.5903  Validation loss = 4.3573  \n",
      "\n",
      "Fold: 4  Epoch: 230  Training loss = 1.5903  Validation loss = 4.3574  \n",
      "\n",
      "Fold: 4  Epoch: 231  Training loss = 1.5902  Validation loss = 4.3578  \n",
      "\n",
      "Fold: 4  Epoch: 232  Training loss = 1.5902  Validation loss = 4.3575  \n",
      "\n",
      "Fold: 4  Epoch: 233  Training loss = 1.5902  Validation loss = 4.3574  \n",
      "\n",
      "Fold: 4  Epoch: 234  Training loss = 1.5901  Validation loss = 4.3561  \n",
      "\n",
      "Fold: 4  Epoch: 235  Training loss = 1.5900  Validation loss = 4.3553  \n",
      "\n",
      "Fold: 4  Epoch: 236  Training loss = 1.5900  Validation loss = 4.3544  \n",
      "\n",
      "Fold: 4  Epoch: 237  Training loss = 1.5899  Validation loss = 4.3540  \n",
      "\n",
      "Fold: 4  Epoch: 238  Training loss = 1.5899  Validation loss = 4.3530  \n",
      "\n",
      "Fold: 4  Epoch: 239  Training loss = 1.5898  Validation loss = 4.3535  \n",
      "\n",
      "Fold: 4  Epoch: 240  Training loss = 1.5898  Validation loss = 4.3537  \n",
      "\n",
      "Fold: 4  Epoch: 241  Training loss = 1.5897  Validation loss = 4.3519  \n",
      "\n",
      "Fold: 4  Epoch: 242  Training loss = 1.5897  Validation loss = 4.3518  \n",
      "\n",
      "Fold: 4  Epoch: 243  Training loss = 1.5896  Validation loss = 4.3517  \n",
      "\n",
      "Fold: 4  Epoch: 244  Training loss = 1.5896  Validation loss = 4.3524  \n",
      "\n",
      "Fold: 4  Epoch: 245  Training loss = 1.5895  Validation loss = 4.3507  \n",
      "\n",
      "Fold: 4  Epoch: 246  Training loss = 1.5895  Validation loss = 4.3502  \n",
      "\n",
      "Fold: 4  Epoch: 247  Training loss = 1.5894  Validation loss = 4.3505  \n",
      "\n",
      "Fold: 4  Epoch: 248  Training loss = 1.5894  Validation loss = 4.3509  \n",
      "\n",
      "Fold: 4  Epoch: 249  Training loss = 1.5893  Validation loss = 4.3499  \n",
      "\n",
      "Fold: 4  Epoch: 250  Training loss = 1.5893  Validation loss = 4.3505  \n",
      "\n",
      "Fold: 4  Epoch: 251  Training loss = 1.5892  Validation loss = 4.3490  \n",
      "\n",
      "Fold: 4  Epoch: 252  Training loss = 1.5892  Validation loss = 4.3479  \n",
      "\n",
      "Fold: 4  Epoch: 253  Training loss = 1.5892  Validation loss = 4.3478  \n",
      "\n",
      "Fold: 4  Epoch: 254  Training loss = 1.5891  Validation loss = 4.3479  \n",
      "\n",
      "Fold: 4  Epoch: 255  Training loss = 1.5891  Validation loss = 4.3476  \n",
      "\n",
      "Fold: 4  Epoch: 256  Training loss = 1.5890  Validation loss = 4.3462  \n",
      "\n",
      "Fold: 4  Epoch: 257  Training loss = 1.5890  Validation loss = 4.3460  \n",
      "\n",
      "Fold: 4  Epoch: 258  Training loss = 1.5889  Validation loss = 4.3463  \n",
      "\n",
      "Fold: 4  Epoch: 259  Training loss = 1.5889  Validation loss = 4.3466  \n",
      "\n",
      "Fold: 4  Epoch: 260  Training loss = 1.5888  Validation loss = 4.3460  \n",
      "\n",
      "Fold: 4  Epoch: 261  Training loss = 1.5888  Validation loss = 4.3458  \n",
      "\n",
      "Fold: 4  Epoch: 262  Training loss = 1.5888  Validation loss = 4.3464  \n",
      "\n",
      "Fold: 4  Epoch: 263  Training loss = 1.5887  Validation loss = 4.3454  \n",
      "\n",
      "Fold: 4  Epoch: 264  Training loss = 1.5887  Validation loss = 4.3449  \n",
      "\n",
      "Fold: 4  Epoch: 265  Training loss = 1.5886  Validation loss = 4.3447  \n",
      "\n",
      "Fold: 4  Epoch: 266  Training loss = 1.5886  Validation loss = 4.3434  \n",
      "\n",
      "Fold: 4  Epoch: 267  Training loss = 1.5885  Validation loss = 4.3438  \n",
      "\n",
      "Fold: 4  Epoch: 268  Training loss = 1.5885  Validation loss = 4.3438  \n",
      "\n",
      "Fold: 4  Epoch: 269  Training loss = 1.5884  Validation loss = 4.3432  \n",
      "\n",
      "Fold: 4  Epoch: 270  Training loss = 1.5884  Validation loss = 4.3422  \n",
      "\n",
      "Fold: 4  Epoch: 271  Training loss = 1.5883  Validation loss = 4.3409  \n",
      "\n",
      "Fold: 4  Epoch: 272  Training loss = 1.5883  Validation loss = 4.3404  \n",
      "\n",
      "Fold: 4  Epoch: 273  Training loss = 1.5882  Validation loss = 4.3400  \n",
      "\n",
      "Fold: 4  Epoch: 274  Training loss = 1.5882  Validation loss = 4.3383  \n",
      "\n",
      "Fold: 4  Epoch: 275  Training loss = 1.5881  Validation loss = 4.3390  \n",
      "\n",
      "Fold: 4  Epoch: 276  Training loss = 1.5881  Validation loss = 4.3390  \n",
      "\n",
      "Fold: 4  Epoch: 277  Training loss = 1.5881  Validation loss = 4.3391  \n",
      "\n",
      "Fold: 4  Epoch: 278  Training loss = 1.5880  Validation loss = 4.3384  \n",
      "\n",
      "Fold: 4  Epoch: 279  Training loss = 1.5880  Validation loss = 4.3386  \n",
      "\n",
      "Fold: 4  Epoch: 280  Training loss = 1.5879  Validation loss = 4.3380  \n",
      "\n",
      "Fold: 4  Epoch: 281  Training loss = 1.5879  Validation loss = 4.3381  \n",
      "\n",
      "Fold: 4  Epoch: 282  Training loss = 1.5879  Validation loss = 4.3385  \n",
      "\n",
      "Fold: 4  Epoch: 283  Training loss = 1.5878  Validation loss = 4.3379  \n",
      "\n",
      "Fold: 4  Epoch: 284  Training loss = 1.5877  Validation loss = 4.3368  \n",
      "\n",
      "Fold: 4  Epoch: 285  Training loss = 1.5877  Validation loss = 4.3367  \n",
      "\n",
      "Fold: 4  Epoch: 286  Training loss = 1.5877  Validation loss = 4.3365  \n",
      "\n",
      "Fold: 4  Epoch: 287  Training loss = 1.5876  Validation loss = 4.3355  \n",
      "\n",
      "Fold: 4  Epoch: 288  Training loss = 1.5875  Validation loss = 4.3353  \n",
      "\n",
      "Fold: 4  Epoch: 289  Training loss = 1.5875  Validation loss = 4.3339  \n",
      "\n",
      "Fold: 4  Epoch: 290  Training loss = 1.5874  Validation loss = 4.3339  \n",
      "\n",
      "Fold: 4  Epoch: 291  Training loss = 1.5874  Validation loss = 4.3338  \n",
      "\n",
      "Fold: 4  Epoch: 292  Training loss = 1.5873  Validation loss = 4.3327  \n",
      "\n",
      "Fold: 4  Epoch: 293  Training loss = 1.5873  Validation loss = 4.3327  \n",
      "\n",
      "Fold: 4  Epoch: 294  Training loss = 1.5872  Validation loss = 4.3323  \n",
      "\n",
      "Fold: 4  Epoch: 295  Training loss = 1.5872  Validation loss = 4.3321  \n",
      "\n",
      "Fold: 4  Epoch: 296  Training loss = 1.5872  Validation loss = 4.3325  \n",
      "\n",
      "Fold: 4  Epoch: 297  Training loss = 1.5872  Validation loss = 4.3316  \n",
      "\n",
      "Fold: 4  Epoch: 298  Training loss = 1.5871  Validation loss = 4.3319  \n",
      "\n",
      "Fold: 4  Epoch: 299  Training loss = 1.5871  Validation loss = 4.3329  \n",
      "\n",
      "Fold: 4  Epoch: 300  Training loss = 1.5871  Validation loss = 4.3335  \n",
      "\n",
      "Fold: 4  Epoch: 301  Training loss = 1.5870  Validation loss = 4.3328  \n",
      "\n",
      "Fold: 4  Epoch: 302  Training loss = 1.5870  Validation loss = 4.3332  \n",
      "\n",
      "Fold: 4  Epoch: 303  Training loss = 1.5870  Validation loss = 4.3333  \n",
      "\n",
      "Fold: 4  Epoch: 304  Training loss = 1.5869  Validation loss = 4.3326  \n",
      "\n",
      "Fold: 4  Epoch: 305  Training loss = 1.5869  Validation loss = 4.3320  \n",
      "\n",
      "Fold: 4  Epoch: 306  Training loss = 1.5868  Validation loss = 4.3316  \n",
      "\n",
      "Fold: 4  Epoch: 307  Training loss = 1.5868  Validation loss = 4.3322  \n",
      "\n",
      "Fold: 4  Epoch: 308  Training loss = 1.5868  Validation loss = 4.3320  \n",
      "\n",
      "Fold: 4  Epoch: 309  Training loss = 1.5868  Validation loss = 4.3333  \n",
      "\n",
      "Fold: 4  Epoch: 310  Training loss = 1.5868  Validation loss = 4.3338  \n",
      "\n",
      "Check model:  Fold: 4  Epoch: 306  Training loss = 1.5868  Validation loss = 4.3338  \n",
      "\n",
      "Fold: 5  Epoch: 1  Training loss = 1.8766  Validation loss = 4.4317  \n",
      "\n",
      "Fold: 5  Epoch: 2  Training loss = 1.8762  Validation loss = 4.4297  \n",
      "\n",
      "Fold: 5  Epoch: 3  Training loss = 1.8760  Validation loss = 4.4287  \n",
      "\n",
      "Fold: 5  Epoch: 4  Training loss = 1.8753  Validation loss = 4.4255  \n",
      "\n",
      "Fold: 5  Epoch: 5  Training loss = 1.8751  Validation loss = 4.4244  \n",
      "\n",
      "Fold: 5  Epoch: 6  Training loss = 1.8749  Validation loss = 4.4233  \n",
      "\n",
      "Fold: 5  Epoch: 7  Training loss = 1.8744  Validation loss = 4.4213  \n",
      "\n",
      "Fold: 5  Epoch: 8  Training loss = 1.8742  Validation loss = 4.4203  \n",
      "\n",
      "Fold: 5  Epoch: 9  Training loss = 1.8742  Validation loss = 4.4207  \n",
      "\n",
      "Fold: 5  Epoch: 10  Training loss = 1.8739  Validation loss = 4.4191  \n",
      "\n",
      "Fold: 5  Epoch: 11  Training loss = 1.8738  Validation loss = 4.4191  \n",
      "\n",
      "Fold: 5  Epoch: 12  Training loss = 1.8737  Validation loss = 4.4187  \n",
      "\n",
      "Fold: 5  Epoch: 13  Training loss = 1.8733  Validation loss = 4.4169  \n",
      "\n",
      "Fold: 5  Epoch: 14  Training loss = 1.8729  Validation loss = 4.4154  \n",
      "\n",
      "Fold: 5  Epoch: 15  Training loss = 1.8725  Validation loss = 4.4135  \n",
      "\n",
      "Fold: 5  Epoch: 16  Training loss = 1.8721  Validation loss = 4.4112  \n",
      "\n",
      "Fold: 5  Epoch: 17  Training loss = 1.8718  Validation loss = 4.4100  \n",
      "\n",
      "Fold: 5  Epoch: 18  Training loss = 1.8715  Validation loss = 4.4084  \n",
      "\n",
      "Fold: 5  Epoch: 19  Training loss = 1.8710  Validation loss = 4.4062  \n",
      "\n",
      "Fold: 5  Epoch: 20  Training loss = 1.8707  Validation loss = 4.4047  \n",
      "\n",
      "Fold: 5  Epoch: 21  Training loss = 1.8704  Validation loss = 4.4035  \n",
      "\n",
      "Fold: 5  Epoch: 22  Training loss = 1.8702  Validation loss = 4.4026  \n",
      "\n",
      "Fold: 5  Epoch: 23  Training loss = 1.8702  Validation loss = 4.4027  \n",
      "\n",
      "Fold: 5  Epoch: 24  Training loss = 1.8699  Validation loss = 4.4015  \n",
      "\n",
      "Fold: 5  Epoch: 25  Training loss = 1.8695  Validation loss = 4.3996  \n",
      "\n",
      "Fold: 5  Epoch: 26  Training loss = 1.8692  Validation loss = 4.3981  \n",
      "\n",
      "Fold: 5  Epoch: 27  Training loss = 1.8689  Validation loss = 4.3968  \n",
      "\n",
      "Fold: 5  Epoch: 28  Training loss = 1.8689  Validation loss = 4.3968  \n",
      "\n",
      "Fold: 5  Epoch: 29  Training loss = 1.8688  Validation loss = 4.3968  \n",
      "\n",
      "Fold: 5  Epoch: 30  Training loss = 1.8687  Validation loss = 4.3965  \n",
      "\n",
      "Fold: 5  Epoch: 31  Training loss = 1.8686  Validation loss = 4.3963  \n",
      "\n",
      "Fold: 5  Epoch: 32  Training loss = 1.8684  Validation loss = 4.3958  \n",
      "\n",
      "Fold: 5  Epoch: 33  Training loss = 1.8683  Validation loss = 4.3953  \n",
      "\n",
      "Fold: 5  Epoch: 34  Training loss = 1.8681  Validation loss = 4.3945  \n",
      "\n",
      "Fold: 5  Epoch: 35  Training loss = 1.8678  Validation loss = 4.3931  \n",
      "\n",
      "Fold: 5  Epoch: 36  Training loss = 1.8674  Validation loss = 4.3913  \n",
      "\n",
      "Fold: 5  Epoch: 37  Training loss = 1.8670  Validation loss = 4.3893  \n",
      "\n",
      "Fold: 5  Epoch: 38  Training loss = 1.8667  Validation loss = 4.3879  \n",
      "\n",
      "Fold: 5  Epoch: 39  Training loss = 1.8664  Validation loss = 4.3865  \n",
      "\n",
      "Fold: 5  Epoch: 40  Training loss = 1.8662  Validation loss = 4.3857  \n",
      "\n",
      "Fold: 5  Epoch: 41  Training loss = 1.8657  Validation loss = 4.3832  \n",
      "\n",
      "Fold: 5  Epoch: 42  Training loss = 1.8654  Validation loss = 4.3824  \n",
      "\n",
      "Fold: 5  Epoch: 43  Training loss = 1.8652  Validation loss = 4.3816  \n",
      "\n",
      "Fold: 5  Epoch: 44  Training loss = 1.8650  Validation loss = 4.3805  \n",
      "\n",
      "Fold: 5  Epoch: 45  Training loss = 1.8646  Validation loss = 4.3788  \n",
      "\n",
      "Fold: 5  Epoch: 46  Training loss = 1.8642  Validation loss = 4.3766  \n",
      "\n",
      "Fold: 5  Epoch: 47  Training loss = 1.8639  Validation loss = 4.3748  \n",
      "\n",
      "Fold: 5  Epoch: 48  Training loss = 1.8633  Validation loss = 4.3718  \n",
      "\n",
      "Fold: 5  Epoch: 49  Training loss = 1.8631  Validation loss = 4.3707  \n",
      "\n",
      "Fold: 5  Epoch: 50  Training loss = 1.8630  Validation loss = 4.3705  \n",
      "\n",
      "Fold: 5  Epoch: 51  Training loss = 1.8626  Validation loss = 4.3685  \n",
      "\n",
      "Fold: 5  Epoch: 52  Training loss = 1.8622  Validation loss = 4.3667  \n",
      "\n",
      "Fold: 5  Epoch: 53  Training loss = 1.8619  Validation loss = 4.3657  \n",
      "\n",
      "Fold: 5  Epoch: 54  Training loss = 1.8616  Validation loss = 4.3643  \n",
      "\n",
      "Fold: 5  Epoch: 55  Training loss = 1.8613  Validation loss = 4.3626  \n",
      "\n",
      "Fold: 5  Epoch: 56  Training loss = 1.8610  Validation loss = 4.3613  \n",
      "\n",
      "Fold: 5  Epoch: 57  Training loss = 1.8610  Validation loss = 4.3617  \n",
      "\n",
      "Fold: 5  Epoch: 58  Training loss = 1.8607  Validation loss = 4.3600  \n",
      "\n",
      "Fold: 5  Epoch: 59  Training loss = 1.8604  Validation loss = 4.3591  \n",
      "\n",
      "Fold: 5  Epoch: 60  Training loss = 1.8601  Validation loss = 4.3573  \n",
      "\n",
      "Fold: 5  Epoch: 61  Training loss = 1.8598  Validation loss = 4.3560  \n",
      "\n",
      "Fold: 5  Epoch: 62  Training loss = 1.8597  Validation loss = 4.3556  \n",
      "\n",
      "Fold: 5  Epoch: 63  Training loss = 1.8595  Validation loss = 4.3549  \n",
      "\n",
      "Fold: 5  Epoch: 64  Training loss = 1.8593  Validation loss = 4.3536  \n",
      "\n",
      "Fold: 5  Epoch: 65  Training loss = 1.8592  Validation loss = 4.3532  \n",
      "\n",
      "Fold: 5  Epoch: 66  Training loss = 1.8592  Validation loss = 4.3537  \n",
      "\n",
      "Fold: 5  Epoch: 67  Training loss = 1.8589  Validation loss = 4.3521  \n",
      "\n",
      "Fold: 5  Epoch: 68  Training loss = 1.8587  Validation loss = 4.3516  \n",
      "\n",
      "Fold: 5  Epoch: 69  Training loss = 1.8585  Validation loss = 4.3502  \n",
      "\n",
      "Fold: 5  Epoch: 70  Training loss = 1.8583  Validation loss = 4.3496  \n",
      "\n",
      "Fold: 5  Epoch: 71  Training loss = 1.8582  Validation loss = 4.3492  \n",
      "\n",
      "Fold: 5  Epoch: 72  Training loss = 1.8579  Validation loss = 4.3477  \n",
      "\n",
      "Fold: 5  Epoch: 73  Training loss = 1.8577  Validation loss = 4.3475  \n",
      "\n",
      "Fold: 5  Epoch: 74  Training loss = 1.8575  Validation loss = 4.3462  \n",
      "\n",
      "Fold: 5  Epoch: 75  Training loss = 1.8571  Validation loss = 4.3444  \n",
      "\n",
      "Fold: 5  Epoch: 76  Training loss = 1.8568  Validation loss = 4.3430  \n",
      "\n",
      "Fold: 5  Epoch: 77  Training loss = 1.8565  Validation loss = 4.3413  \n",
      "\n",
      "Fold: 5  Epoch: 78  Training loss = 1.8563  Validation loss = 4.3406  \n",
      "\n",
      "Fold: 5  Epoch: 79  Training loss = 1.8561  Validation loss = 4.3394  \n",
      "\n",
      "Fold: 5  Epoch: 80  Training loss = 1.8558  Validation loss = 4.3381  \n",
      "\n",
      "Fold: 5  Epoch: 81  Training loss = 1.8555  Validation loss = 4.3366  \n",
      "\n",
      "Fold: 5  Epoch: 82  Training loss = 1.8552  Validation loss = 4.3350  \n",
      "\n",
      "Fold: 5  Epoch: 83  Training loss = 1.8550  Validation loss = 4.3343  \n",
      "\n",
      "Fold: 5  Epoch: 84  Training loss = 1.8547  Validation loss = 4.3329  \n",
      "\n",
      "Fold: 5  Epoch: 85  Training loss = 1.8543  Validation loss = 4.3305  \n",
      "\n",
      "Fold: 5  Epoch: 86  Training loss = 1.8540  Validation loss = 4.3291  \n",
      "\n",
      "Fold: 5  Epoch: 87  Training loss = 1.8537  Validation loss = 4.3274  \n",
      "\n",
      "Fold: 5  Epoch: 88  Training loss = 1.8536  Validation loss = 4.3276  \n",
      "\n",
      "Fold: 5  Epoch: 89  Training loss = 1.8534  Validation loss = 4.3261  \n",
      "\n",
      "Fold: 5  Epoch: 90  Training loss = 1.8533  Validation loss = 4.3257  \n",
      "\n",
      "Fold: 5  Epoch: 91  Training loss = 1.8533  Validation loss = 4.3265  \n",
      "\n",
      "Fold: 5  Epoch: 92  Training loss = 1.8532  Validation loss = 4.3265  \n",
      "\n",
      "Fold: 5  Epoch: 93  Training loss = 1.8529  Validation loss = 4.3246  \n",
      "\n",
      "Fold: 5  Epoch: 94  Training loss = 1.8526  Validation loss = 4.3239  \n",
      "\n",
      "Fold: 5  Epoch: 95  Training loss = 1.8523  Validation loss = 4.3221  \n",
      "\n",
      "Fold: 5  Epoch: 96  Training loss = 1.8521  Validation loss = 4.3213  \n",
      "\n",
      "Fold: 5  Epoch: 97  Training loss = 1.8519  Validation loss = 4.3202  \n",
      "\n",
      "Fold: 5  Epoch: 98  Training loss = 1.8517  Validation loss = 4.3193  \n",
      "\n",
      "Fold: 5  Epoch: 99  Training loss = 1.8512  Validation loss = 4.3166  \n",
      "\n",
      "Fold: 5  Epoch: 100  Training loss = 1.8508  Validation loss = 4.3141  \n",
      "\n",
      "Fold: 5  Epoch: 101  Training loss = 1.8507  Validation loss = 4.3139  \n",
      "\n",
      "Fold: 5  Epoch: 102  Training loss = 1.8505  Validation loss = 4.3128  \n",
      "\n",
      "Fold: 5  Epoch: 103  Training loss = 1.8503  Validation loss = 4.3119  \n",
      "\n",
      "Fold: 5  Epoch: 104  Training loss = 1.8503  Validation loss = 4.3122  \n",
      "\n",
      "Fold: 5  Epoch: 105  Training loss = 1.8502  Validation loss = 4.3120  \n",
      "\n",
      "Fold: 5  Epoch: 106  Training loss = 1.8500  Validation loss = 4.3112  \n",
      "\n",
      "Fold: 5  Epoch: 107  Training loss = 1.8497  Validation loss = 4.3098  \n",
      "\n",
      "Fold: 5  Epoch: 108  Training loss = 1.8492  Validation loss = 4.3066  \n",
      "\n",
      "Fold: 5  Epoch: 109  Training loss = 1.8490  Validation loss = 4.3059  \n",
      "\n",
      "Fold: 5  Epoch: 110  Training loss = 1.8488  Validation loss = 4.3050  \n",
      "\n",
      "Fold: 5  Epoch: 111  Training loss = 1.8485  Validation loss = 4.3037  \n",
      "\n",
      "Fold: 5  Epoch: 112  Training loss = 1.8481  Validation loss = 4.3013  \n",
      "\n",
      "Fold: 5  Epoch: 113  Training loss = 1.8477  Validation loss = 4.2992  \n",
      "\n",
      "Fold: 5  Epoch: 114  Training loss = 1.8475  Validation loss = 4.2981  \n",
      "\n",
      "Fold: 5  Epoch: 115  Training loss = 1.8472  Validation loss = 4.2968  \n",
      "\n",
      "Fold: 5  Epoch: 116  Training loss = 1.8471  Validation loss = 4.2963  \n",
      "\n",
      "Fold: 5  Epoch: 117  Training loss = 1.8469  Validation loss = 4.2955  \n",
      "\n",
      "Fold: 5  Epoch: 118  Training loss = 1.8467  Validation loss = 4.2941  \n",
      "\n",
      "Fold: 5  Epoch: 119  Training loss = 1.8465  Validation loss = 4.2940  \n",
      "\n",
      "Fold: 5  Epoch: 120  Training loss = 1.8463  Validation loss = 4.2929  \n",
      "\n",
      "Fold: 5  Epoch: 121  Training loss = 1.8461  Validation loss = 4.2918  \n",
      "\n",
      "Fold: 5  Epoch: 122  Training loss = 1.8458  Validation loss = 4.2907  \n",
      "\n",
      "Fold: 5  Epoch: 123  Training loss = 1.8455  Validation loss = 4.2891  \n",
      "\n",
      "Fold: 5  Epoch: 124  Training loss = 1.8455  Validation loss = 4.2891  \n",
      "\n",
      "Fold: 5  Epoch: 125  Training loss = 1.8454  Validation loss = 4.2892  \n",
      "\n",
      "Fold: 5  Epoch: 126  Training loss = 1.8453  Validation loss = 4.2886  \n",
      "\n",
      "Fold: 5  Epoch: 127  Training loss = 1.8449  Validation loss = 4.2863  \n",
      "\n",
      "Fold: 5  Epoch: 128  Training loss = 1.8449  Validation loss = 4.2864  \n",
      "\n",
      "Fold: 5  Epoch: 129  Training loss = 1.8445  Validation loss = 4.2846  \n",
      "\n",
      "Fold: 5  Epoch: 130  Training loss = 1.8445  Validation loss = 4.2845  \n",
      "\n",
      "Fold: 5  Epoch: 131  Training loss = 1.8444  Validation loss = 4.2846  \n",
      "\n",
      "Fold: 5  Epoch: 132  Training loss = 1.8443  Validation loss = 4.2840  \n",
      "\n",
      "Fold: 5  Epoch: 133  Training loss = 1.8440  Validation loss = 4.2829  \n",
      "\n",
      "Fold: 5  Epoch: 134  Training loss = 1.8441  Validation loss = 4.2834  \n",
      "\n",
      "Fold: 5  Epoch: 135  Training loss = 1.8438  Validation loss = 4.2821  \n",
      "\n",
      "Fold: 5  Epoch: 136  Training loss = 1.8436  Validation loss = 4.2812  \n",
      "\n",
      "Fold: 5  Epoch: 137  Training loss = 1.8434  Validation loss = 4.2803  \n",
      "\n",
      "Fold: 5  Epoch: 138  Training loss = 1.8432  Validation loss = 4.2791  \n",
      "\n",
      "Fold: 5  Epoch: 139  Training loss = 1.8429  Validation loss = 4.2777  \n",
      "\n",
      "Fold: 5  Epoch: 140  Training loss = 1.8428  Validation loss = 4.2772  \n",
      "\n",
      "Fold: 5  Epoch: 141  Training loss = 1.8424  Validation loss = 4.2751  \n",
      "\n",
      "Fold: 5  Epoch: 142  Training loss = 1.8422  Validation loss = 4.2739  \n",
      "\n",
      "Fold: 5  Epoch: 143  Training loss = 1.8421  Validation loss = 4.2734  \n",
      "\n",
      "Fold: 5  Epoch: 144  Training loss = 1.8417  Validation loss = 4.2715  \n",
      "\n",
      "Fold: 5  Epoch: 145  Training loss = 1.8415  Validation loss = 4.2703  \n",
      "\n",
      "Fold: 5  Epoch: 146  Training loss = 1.8410  Validation loss = 4.2673  \n",
      "\n",
      "Fold: 5  Epoch: 147  Training loss = 1.8408  Validation loss = 4.2666  \n",
      "\n",
      "Fold: 5  Epoch: 148  Training loss = 1.8405  Validation loss = 4.2650  \n",
      "\n",
      "Fold: 5  Epoch: 149  Training loss = 1.8403  Validation loss = 4.2641  \n",
      "\n",
      "Fold: 5  Epoch: 150  Training loss = 1.8402  Validation loss = 4.2634  \n",
      "\n",
      "Fold: 5  Epoch: 151  Training loss = 1.8399  Validation loss = 4.2619  \n",
      "\n",
      "Fold: 5  Epoch: 152  Training loss = 1.8396  Validation loss = 4.2608  \n",
      "\n",
      "Fold: 5  Epoch: 153  Training loss = 1.8396  Validation loss = 4.2611  \n",
      "\n",
      "Fold: 5  Epoch: 154  Training loss = 1.8394  Validation loss = 4.2600  \n",
      "\n",
      "Fold: 5  Epoch: 155  Training loss = 1.8391  Validation loss = 4.2584  \n",
      "\n",
      "Fold: 5  Epoch: 156  Training loss = 1.8390  Validation loss = 4.2577  \n",
      "\n",
      "Fold: 5  Epoch: 157  Training loss = 1.8386  Validation loss = 4.2555  \n",
      "\n",
      "Fold: 5  Epoch: 158  Training loss = 1.8384  Validation loss = 4.2541  \n",
      "\n",
      "Fold: 5  Epoch: 159  Training loss = 1.8382  Validation loss = 4.2531  \n",
      "\n",
      "Fold: 5  Epoch: 160  Training loss = 1.8379  Validation loss = 4.2517  \n",
      "\n",
      "Fold: 5  Epoch: 161  Training loss = 1.8378  Validation loss = 4.2509  \n",
      "\n",
      "Fold: 5  Epoch: 162  Training loss = 1.8378  Validation loss = 4.2510  \n",
      "\n",
      "Fold: 5  Epoch: 163  Training loss = 1.8376  Validation loss = 4.2506  \n",
      "\n",
      "Fold: 5  Epoch: 164  Training loss = 1.8376  Validation loss = 4.2510  \n",
      "\n",
      "Fold: 5  Epoch: 165  Training loss = 1.8373  Validation loss = 4.2487  \n",
      "\n",
      "Fold: 5  Epoch: 166  Training loss = 1.8372  Validation loss = 4.2482  \n",
      "\n",
      "Fold: 5  Epoch: 167  Training loss = 1.8370  Validation loss = 4.2473  \n",
      "\n",
      "Fold: 5  Epoch: 168  Training loss = 1.8367  Validation loss = 4.2458  \n",
      "\n",
      "Fold: 5  Epoch: 169  Training loss = 1.8364  Validation loss = 4.2438  \n",
      "\n",
      "Fold: 5  Epoch: 170  Training loss = 1.8362  Validation loss = 4.2428  \n",
      "\n",
      "Fold: 5  Epoch: 171  Training loss = 1.8360  Validation loss = 4.2421  \n",
      "\n",
      "Fold: 5  Epoch: 172  Training loss = 1.8358  Validation loss = 4.2414  \n",
      "\n",
      "Fold: 5  Epoch: 173  Training loss = 1.8357  Validation loss = 4.2409  \n",
      "\n",
      "Fold: 5  Epoch: 174  Training loss = 1.8355  Validation loss = 4.2398  \n",
      "\n",
      "Fold: 5  Epoch: 175  Training loss = 1.8352  Validation loss = 4.2380  \n",
      "\n",
      "Fold: 5  Epoch: 176  Training loss = 1.8349  Validation loss = 4.2365  \n",
      "\n",
      "Fold: 5  Epoch: 177  Training loss = 1.8347  Validation loss = 4.2357  \n",
      "\n",
      "Fold: 5  Epoch: 178  Training loss = 1.8346  Validation loss = 4.2352  \n",
      "\n",
      "Fold: 5  Epoch: 179  Training loss = 1.8343  Validation loss = 4.2334  \n",
      "\n",
      "Fold: 5  Epoch: 180  Training loss = 1.8340  Validation loss = 4.2321  \n",
      "\n",
      "Fold: 5  Epoch: 181  Training loss = 1.8339  Validation loss = 4.2314  \n",
      "\n",
      "Fold: 5  Epoch: 182  Training loss = 1.8338  Validation loss = 4.2311  \n",
      "\n",
      "Fold: 5  Epoch: 183  Training loss = 1.8335  Validation loss = 4.2297  \n",
      "\n",
      "Fold: 5  Epoch: 184  Training loss = 1.8333  Validation loss = 4.2279  \n",
      "\n",
      "Fold: 5  Epoch: 185  Training loss = 1.8330  Validation loss = 4.2264  \n",
      "\n",
      "Fold: 5  Epoch: 186  Training loss = 1.8328  Validation loss = 4.2253  \n",
      "\n",
      "Fold: 5  Epoch: 187  Training loss = 1.8328  Validation loss = 4.2257  \n",
      "\n",
      "Fold: 5  Epoch: 188  Training loss = 1.8326  Validation loss = 4.2246  \n",
      "\n",
      "Fold: 5  Epoch: 189  Training loss = 1.8325  Validation loss = 4.2244  \n",
      "\n",
      "Fold: 5  Epoch: 190  Training loss = 1.8324  Validation loss = 4.2244  \n",
      "\n",
      "Fold: 5  Epoch: 191  Training loss = 1.8323  Validation loss = 4.2239  \n",
      "\n",
      "Fold: 5  Epoch: 192  Training loss = 1.8322  Validation loss = 4.2231  \n",
      "\n",
      "Fold: 5  Epoch: 193  Training loss = 1.8319  Validation loss = 4.2218  \n",
      "\n",
      "Fold: 5  Epoch: 194  Training loss = 1.8318  Validation loss = 4.2216  \n",
      "\n",
      "Fold: 5  Epoch: 195  Training loss = 1.8317  Validation loss = 4.2210  \n",
      "\n",
      "Fold: 5  Epoch: 196  Training loss = 1.8317  Validation loss = 4.2210  \n",
      "\n",
      "Fold: 5  Epoch: 197  Training loss = 1.8315  Validation loss = 4.2205  \n",
      "\n",
      "Fold: 5  Epoch: 198  Training loss = 1.8313  Validation loss = 4.2194  \n",
      "\n",
      "Fold: 5  Epoch: 199  Training loss = 1.8314  Validation loss = 4.2201  \n",
      "\n",
      "Fold: 5  Epoch: 200  Training loss = 1.8312  Validation loss = 4.2196  \n",
      "\n",
      "Fold: 5  Epoch: 201  Training loss = 1.8309  Validation loss = 4.2177  \n",
      "\n",
      "Fold: 5  Epoch: 202  Training loss = 1.8306  Validation loss = 4.2162  \n",
      "\n",
      "Fold: 5  Epoch: 203  Training loss = 1.8304  Validation loss = 4.2152  \n",
      "\n",
      "Fold: 5  Epoch: 204  Training loss = 1.8303  Validation loss = 4.2152  \n",
      "\n",
      "Fold: 5  Epoch: 205  Training loss = 1.8302  Validation loss = 4.2144  \n",
      "\n",
      "Fold: 5  Epoch: 206  Training loss = 1.8299  Validation loss = 4.2128  \n",
      "\n",
      "Fold: 5  Epoch: 207  Training loss = 1.8297  Validation loss = 4.2121  \n",
      "\n",
      "Fold: 5  Epoch: 208  Training loss = 1.8295  Validation loss = 4.2107  \n",
      "\n",
      "Fold: 5  Epoch: 209  Training loss = 1.8294  Validation loss = 4.2103  \n",
      "\n",
      "Fold: 5  Epoch: 210  Training loss = 1.8291  Validation loss = 4.2090  \n",
      "\n",
      "Fold: 5  Epoch: 211  Training loss = 1.8291  Validation loss = 4.2090  \n",
      "\n",
      "Fold: 5  Epoch: 212  Training loss = 1.8288  Validation loss = 4.2071  \n",
      "\n",
      "Fold: 5  Epoch: 213  Training loss = 1.8286  Validation loss = 4.2057  \n",
      "\n",
      "Fold: 5  Epoch: 214  Training loss = 1.8284  Validation loss = 4.2046  \n",
      "\n",
      "Fold: 5  Epoch: 215  Training loss = 1.8283  Validation loss = 4.2047  \n",
      "\n",
      "Fold: 5  Epoch: 216  Training loss = 1.8281  Validation loss = 4.2037  \n",
      "\n",
      "Fold: 5  Epoch: 217  Training loss = 1.8279  Validation loss = 4.2027  \n",
      "\n",
      "Fold: 5  Epoch: 218  Training loss = 1.8278  Validation loss = 4.2026  \n",
      "\n",
      "Fold: 5  Epoch: 219  Training loss = 1.8277  Validation loss = 4.2022  \n",
      "\n",
      "Fold: 5  Epoch: 220  Training loss = 1.8276  Validation loss = 4.2015  \n",
      "\n",
      "Fold: 5  Epoch: 221  Training loss = 1.8274  Validation loss = 4.2009  \n",
      "\n",
      "Fold: 5  Epoch: 222  Training loss = 1.8272  Validation loss = 4.2003  \n",
      "\n",
      "Fold: 5  Epoch: 223  Training loss = 1.8271  Validation loss = 4.1996  \n",
      "\n",
      "Fold: 5  Epoch: 224  Training loss = 1.8269  Validation loss = 4.1985  \n",
      "\n",
      "Fold: 5  Epoch: 225  Training loss = 1.8266  Validation loss = 4.1968  \n",
      "\n",
      "Fold: 5  Epoch: 226  Training loss = 1.8263  Validation loss = 4.1951  \n",
      "\n",
      "Fold: 5  Epoch: 227  Training loss = 1.8261  Validation loss = 4.1936  \n",
      "\n",
      "Fold: 5  Epoch: 228  Training loss = 1.8259  Validation loss = 4.1926  \n",
      "\n",
      "Fold: 5  Epoch: 229  Training loss = 1.8258  Validation loss = 4.1928  \n",
      "\n",
      "Fold: 5  Epoch: 230  Training loss = 1.8257  Validation loss = 4.1918  \n",
      "\n",
      "Fold: 5  Epoch: 231  Training loss = 1.8256  Validation loss = 4.1915  \n",
      "\n",
      "Fold: 5  Epoch: 232  Training loss = 1.8254  Validation loss = 4.1903  \n",
      "\n",
      "Fold: 5  Epoch: 233  Training loss = 1.8252  Validation loss = 4.1901  \n",
      "\n",
      "Fold: 5  Epoch: 234  Training loss = 1.8250  Validation loss = 4.1887  \n",
      "\n",
      "Fold: 5  Epoch: 235  Training loss = 1.8247  Validation loss = 4.1874  \n",
      "\n",
      "Fold: 5  Epoch: 236  Training loss = 1.8246  Validation loss = 4.1864  \n",
      "\n",
      "Fold: 5  Epoch: 237  Training loss = 1.8240  Validation loss = 4.1828  \n",
      "\n",
      "Fold: 5  Epoch: 238  Training loss = 1.8240  Validation loss = 4.1825  \n",
      "\n",
      "Fold: 5  Epoch: 239  Training loss = 1.8238  Validation loss = 4.1817  \n",
      "\n",
      "Fold: 5  Epoch: 240  Training loss = 1.8236  Validation loss = 4.1807  \n",
      "\n",
      "Fold: 5  Epoch: 241  Training loss = 1.8234  Validation loss = 4.1799  \n",
      "\n",
      "Fold: 5  Epoch: 242  Training loss = 1.8233  Validation loss = 4.1789  \n",
      "\n",
      "Fold: 5  Epoch: 243  Training loss = 1.8231  Validation loss = 4.1783  \n",
      "\n",
      "Fold: 5  Epoch: 244  Training loss = 1.8231  Validation loss = 4.1783  \n",
      "\n",
      "Fold: 5  Epoch: 245  Training loss = 1.8230  Validation loss = 4.1780  \n",
      "\n",
      "Fold: 5  Epoch: 246  Training loss = 1.8227  Validation loss = 4.1763  \n",
      "\n",
      "Fold: 5  Epoch: 247  Training loss = 1.8224  Validation loss = 4.1744  \n",
      "\n",
      "Fold: 5  Epoch: 248  Training loss = 1.8223  Validation loss = 4.1736  \n",
      "\n",
      "Fold: 5  Epoch: 249  Training loss = 1.8220  Validation loss = 4.1718  \n",
      "\n",
      "Fold: 5  Epoch: 250  Training loss = 1.8218  Validation loss = 4.1706  \n",
      "\n",
      "Fold: 5  Epoch: 251  Training loss = 1.8217  Validation loss = 4.1702  \n",
      "\n",
      "Fold: 5  Epoch: 252  Training loss = 1.8216  Validation loss = 4.1700  \n",
      "\n",
      "Fold: 5  Epoch: 253  Training loss = 1.8214  Validation loss = 4.1684  \n",
      "\n",
      "Fold: 5  Epoch: 254  Training loss = 1.8212  Validation loss = 4.1671  \n",
      "\n",
      "Fold: 5  Epoch: 255  Training loss = 1.8210  Validation loss = 4.1659  \n",
      "\n",
      "Fold: 5  Epoch: 256  Training loss = 1.8208  Validation loss = 4.1649  \n",
      "\n",
      "Fold: 5  Epoch: 257  Training loss = 1.8206  Validation loss = 4.1638  \n",
      "\n",
      "Fold: 5  Epoch: 258  Training loss = 1.8204  Validation loss = 4.1628  \n",
      "\n",
      "Fold: 5  Epoch: 259  Training loss = 1.8203  Validation loss = 4.1621  \n",
      "\n",
      "Fold: 5  Epoch: 260  Training loss = 1.8200  Validation loss = 4.1601  \n",
      "\n",
      "Fold: 5  Epoch: 261  Training loss = 1.8199  Validation loss = 4.1596  \n",
      "\n",
      "Fold: 5  Epoch: 262  Training loss = 1.8196  Validation loss = 4.1578  \n",
      "\n",
      "Fold: 5  Epoch: 263  Training loss = 1.8194  Validation loss = 4.1565  \n",
      "\n",
      "Fold: 5  Epoch: 264  Training loss = 1.8192  Validation loss = 4.1554  \n",
      "\n",
      "Fold: 5  Epoch: 265  Training loss = 1.8191  Validation loss = 4.1549  \n",
      "\n",
      "Fold: 5  Epoch: 266  Training loss = 1.8190  Validation loss = 4.1547  \n",
      "\n",
      "Fold: 5  Epoch: 267  Training loss = 1.8187  Validation loss = 4.1533  \n",
      "\n",
      "Fold: 5  Epoch: 268  Training loss = 1.8187  Validation loss = 4.1533  \n",
      "\n",
      "Fold: 5  Epoch: 269  Training loss = 1.8186  Validation loss = 4.1530  \n",
      "\n",
      "Fold: 5  Epoch: 270  Training loss = 1.8184  Validation loss = 4.1520  \n",
      "\n",
      "Fold: 5  Epoch: 271  Training loss = 1.8183  Validation loss = 4.1512  \n",
      "\n",
      "Fold: 5  Epoch: 272  Training loss = 1.8182  Validation loss = 4.1507  \n",
      "\n",
      "Fold: 5  Epoch: 273  Training loss = 1.8180  Validation loss = 4.1498  \n",
      "\n",
      "Fold: 5  Epoch: 274  Training loss = 1.8178  Validation loss = 4.1489  \n",
      "\n",
      "Fold: 5  Epoch: 275  Training loss = 1.8176  Validation loss = 4.1473  \n",
      "\n",
      "Fold: 5  Epoch: 276  Training loss = 1.8174  Validation loss = 4.1468  \n",
      "\n",
      "Fold: 5  Epoch: 277  Training loss = 1.8171  Validation loss = 4.1451  \n",
      "\n",
      "Fold: 5  Epoch: 278  Training loss = 1.8170  Validation loss = 4.1448  \n",
      "\n",
      "Fold: 5  Epoch: 279  Training loss = 1.8169  Validation loss = 4.1443  \n",
      "\n",
      "Fold: 5  Epoch: 280  Training loss = 1.8167  Validation loss = 4.1435  \n",
      "\n",
      "Fold: 5  Epoch: 281  Training loss = 1.8166  Validation loss = 4.1428  \n",
      "\n",
      "Fold: 5  Epoch: 282  Training loss = 1.8164  Validation loss = 4.1417  \n",
      "\n",
      "Fold: 5  Epoch: 283  Training loss = 1.8163  Validation loss = 4.1420  \n",
      "\n",
      "Fold: 5  Epoch: 284  Training loss = 1.8161  Validation loss = 4.1408  \n",
      "\n",
      "Fold: 5  Epoch: 285  Training loss = 1.8161  Validation loss = 4.1411  \n",
      "\n",
      "Fold: 5  Epoch: 286  Training loss = 1.8160  Validation loss = 4.1409  \n",
      "\n",
      "Fold: 5  Epoch: 287  Training loss = 1.8159  Validation loss = 4.1407  \n",
      "\n",
      "Fold: 5  Epoch: 288  Training loss = 1.8157  Validation loss = 4.1393  \n",
      "\n",
      "Fold: 5  Epoch: 289  Training loss = 1.8155  Validation loss = 4.1387  \n",
      "\n",
      "Fold: 5  Epoch: 290  Training loss = 1.8153  Validation loss = 4.1373  \n",
      "\n",
      "Fold: 5  Epoch: 291  Training loss = 1.8152  Validation loss = 4.1367  \n",
      "\n",
      "Fold: 5  Epoch: 292  Training loss = 1.8151  Validation loss = 4.1365  \n",
      "\n",
      "Fold: 5  Epoch: 293  Training loss = 1.8149  Validation loss = 4.1352  \n",
      "\n",
      "Fold: 5  Epoch: 294  Training loss = 1.8146  Validation loss = 4.1336  \n",
      "\n",
      "Fold: 5  Epoch: 295  Training loss = 1.8146  Validation loss = 4.1345  \n",
      "\n",
      "Fold: 5  Epoch: 296  Training loss = 1.8145  Validation loss = 4.1338  \n",
      "\n",
      "Fold: 5  Epoch: 297  Training loss = 1.8143  Validation loss = 4.1330  \n",
      "\n",
      "Fold: 5  Epoch: 298  Training loss = 1.8140  Validation loss = 4.1309  \n",
      "\n",
      "Fold: 5  Epoch: 299  Training loss = 1.8138  Validation loss = 4.1303  \n",
      "\n",
      "Fold: 5  Epoch: 300  Training loss = 1.8136  Validation loss = 4.1289  \n",
      "\n",
      "Fold: 5  Epoch: 301  Training loss = 1.8134  Validation loss = 4.1277  \n",
      "\n",
      "Fold: 5  Epoch: 302  Training loss = 1.8133  Validation loss = 4.1270  \n",
      "\n",
      "Fold: 5  Epoch: 303  Training loss = 1.8132  Validation loss = 4.1267  \n",
      "\n",
      "Fold: 5  Epoch: 304  Training loss = 1.8131  Validation loss = 4.1263  \n",
      "\n",
      "Fold: 5  Epoch: 305  Training loss = 1.8130  Validation loss = 4.1258  \n",
      "\n",
      "Fold: 5  Epoch: 306  Training loss = 1.8129  Validation loss = 4.1257  \n",
      "\n",
      "Fold: 5  Epoch: 307  Training loss = 1.8126  Validation loss = 4.1238  \n",
      "\n",
      "Fold: 5  Epoch: 308  Training loss = 1.8126  Validation loss = 4.1247  \n",
      "\n",
      "Fold: 5  Epoch: 309  Training loss = 1.8125  Validation loss = 4.1245  \n",
      "\n",
      "Fold: 5  Epoch: 310  Training loss = 1.8123  Validation loss = 4.1228  \n",
      "\n",
      "Fold: 5  Epoch: 311  Training loss = 1.8122  Validation loss = 4.1220  \n",
      "\n",
      "Fold: 5  Epoch: 312  Training loss = 1.8119  Validation loss = 4.1200  \n",
      "\n",
      "Fold: 5  Epoch: 313  Training loss = 1.8118  Validation loss = 4.1197  \n",
      "\n",
      "Fold: 5  Epoch: 314  Training loss = 1.8116  Validation loss = 4.1189  \n",
      "\n",
      "Fold: 5  Epoch: 315  Training loss = 1.8116  Validation loss = 4.1192  \n",
      "\n",
      "Fold: 5  Epoch: 316  Training loss = 1.8115  Validation loss = 4.1190  \n",
      "\n",
      "Fold: 5  Epoch: 317  Training loss = 1.8114  Validation loss = 4.1181  \n",
      "\n",
      "Fold: 5  Epoch: 318  Training loss = 1.8112  Validation loss = 4.1175  \n",
      "\n",
      "Fold: 5  Epoch: 319  Training loss = 1.8110  Validation loss = 4.1157  \n",
      "\n",
      "Fold: 5  Epoch: 320  Training loss = 1.8109  Validation loss = 4.1154  \n",
      "\n",
      "Fold: 5  Epoch: 321  Training loss = 1.8107  Validation loss = 4.1149  \n",
      "\n",
      "Fold: 5  Epoch: 322  Training loss = 1.8105  Validation loss = 4.1138  \n",
      "\n",
      "Fold: 5  Epoch: 323  Training loss = 1.8102  Validation loss = 4.1116  \n",
      "\n",
      "Fold: 5  Epoch: 324  Training loss = 1.8100  Validation loss = 4.1099  \n",
      "\n",
      "Fold: 5  Epoch: 325  Training loss = 1.8098  Validation loss = 4.1091  \n",
      "\n",
      "Fold: 5  Epoch: 326  Training loss = 1.8097  Validation loss = 4.1085  \n",
      "\n",
      "Fold: 5  Epoch: 327  Training loss = 1.8094  Validation loss = 4.1070  \n",
      "\n",
      "Fold: 5  Epoch: 328  Training loss = 1.8093  Validation loss = 4.1060  \n",
      "\n",
      "Fold: 5  Epoch: 329  Training loss = 1.8092  Validation loss = 4.1056  \n",
      "\n",
      "Fold: 5  Epoch: 330  Training loss = 1.8090  Validation loss = 4.1049  \n",
      "\n",
      "Fold: 5  Epoch: 331  Training loss = 1.8089  Validation loss = 4.1038  \n",
      "\n",
      "Fold: 5  Epoch: 332  Training loss = 1.8088  Validation loss = 4.1037  \n",
      "\n",
      "Fold: 5  Epoch: 333  Training loss = 1.8086  Validation loss = 4.1033  \n",
      "\n",
      "Fold: 5  Epoch: 334  Training loss = 1.8085  Validation loss = 4.1029  \n",
      "\n",
      "Fold: 5  Epoch: 335  Training loss = 1.8084  Validation loss = 4.1025  \n",
      "\n",
      "Fold: 5  Epoch: 336  Training loss = 1.8083  Validation loss = 4.1016  \n",
      "\n",
      "Fold: 5  Epoch: 337  Training loss = 1.8081  Validation loss = 4.1005  \n",
      "\n",
      "Fold: 5  Epoch: 338  Training loss = 1.8080  Validation loss = 4.1004  \n",
      "\n",
      "Fold: 5  Epoch: 339  Training loss = 1.8077  Validation loss = 4.0984  \n",
      "\n",
      "Fold: 5  Epoch: 340  Training loss = 1.8075  Validation loss = 4.0971  \n",
      "\n",
      "Fold: 5  Epoch: 341  Training loss = 1.8073  Validation loss = 4.0962  \n",
      "\n",
      "Fold: 5  Epoch: 342  Training loss = 1.8071  Validation loss = 4.0943  \n",
      "\n",
      "Fold: 5  Epoch: 343  Training loss = 1.8069  Validation loss = 4.0928  \n",
      "\n",
      "Fold: 5  Epoch: 344  Training loss = 1.8068  Validation loss = 4.0930  \n",
      "\n",
      "Fold: 5  Epoch: 345  Training loss = 1.8066  Validation loss = 4.0919  \n",
      "\n",
      "Fold: 5  Epoch: 346  Training loss = 1.8064  Validation loss = 4.0908  \n",
      "\n",
      "Fold: 5  Epoch: 347  Training loss = 1.8064  Validation loss = 4.0912  \n",
      "\n",
      "Fold: 5  Epoch: 348  Training loss = 1.8063  Validation loss = 4.0901  \n",
      "\n",
      "Fold: 5  Epoch: 349  Training loss = 1.8062  Validation loss = 4.0902  \n",
      "\n",
      "Fold: 5  Epoch: 350  Training loss = 1.8061  Validation loss = 4.0903  \n",
      "\n",
      "Fold: 5  Epoch: 351  Training loss = 1.8059  Validation loss = 4.0889  \n",
      "\n",
      "Fold: 5  Epoch: 352  Training loss = 1.8057  Validation loss = 4.0875  \n",
      "\n",
      "Fold: 5  Epoch: 353  Training loss = 1.8056  Validation loss = 4.0865  \n",
      "\n",
      "Fold: 5  Epoch: 354  Training loss = 1.8055  Validation loss = 4.0864  \n",
      "\n",
      "Fold: 5  Epoch: 355  Training loss = 1.8054  Validation loss = 4.0861  \n",
      "\n",
      "Fold: 5  Epoch: 356  Training loss = 1.8053  Validation loss = 4.0856  \n",
      "\n",
      "Fold: 5  Epoch: 357  Training loss = 1.8052  Validation loss = 4.0851  \n",
      "\n",
      "Fold: 5  Epoch: 358  Training loss = 1.8051  Validation loss = 4.0850  \n",
      "\n",
      "Fold: 5  Epoch: 359  Training loss = 1.8049  Validation loss = 4.0841  \n",
      "\n",
      "Fold: 5  Epoch: 360  Training loss = 1.8048  Validation loss = 4.0838  \n",
      "\n",
      "Fold: 5  Epoch: 361  Training loss = 1.8047  Validation loss = 4.0836  \n",
      "\n",
      "Fold: 5  Epoch: 362  Training loss = 1.8046  Validation loss = 4.0832  \n",
      "\n",
      "Fold: 5  Epoch: 363  Training loss = 1.8046  Validation loss = 4.0831  \n",
      "\n",
      "Fold: 5  Epoch: 364  Training loss = 1.8044  Validation loss = 4.0822  \n",
      "\n",
      "Fold: 5  Epoch: 365  Training loss = 1.8042  Validation loss = 4.0802  \n",
      "\n",
      "Fold: 5  Epoch: 366  Training loss = 1.8040  Validation loss = 4.0793  \n",
      "\n",
      "Fold: 5  Epoch: 367  Training loss = 1.8038  Validation loss = 4.0777  \n",
      "\n",
      "Fold: 5  Epoch: 368  Training loss = 1.8037  Validation loss = 4.0775  \n",
      "\n",
      "Fold: 5  Epoch: 369  Training loss = 1.8036  Validation loss = 4.0772  \n",
      "\n",
      "Fold: 5  Epoch: 370  Training loss = 1.8034  Validation loss = 4.0758  \n",
      "\n",
      "Fold: 5  Epoch: 371  Training loss = 1.8032  Validation loss = 4.0746  \n",
      "\n",
      "Fold: 5  Epoch: 372  Training loss = 1.8030  Validation loss = 4.0744  \n",
      "\n",
      "Fold: 5  Epoch: 373  Training loss = 1.8029  Validation loss = 4.0739  \n",
      "\n",
      "Fold: 5  Epoch: 374  Training loss = 1.8028  Validation loss = 4.0733  \n",
      "\n",
      "Fold: 5  Epoch: 375  Training loss = 1.8028  Validation loss = 4.0736  \n",
      "\n",
      "Fold: 5  Epoch: 376  Training loss = 1.8026  Validation loss = 4.0724  \n",
      "\n",
      "Fold: 5  Epoch: 377  Training loss = 1.8024  Validation loss = 4.0712  \n",
      "\n",
      "Fold: 5  Epoch: 378  Training loss = 1.8022  Validation loss = 4.0692  \n",
      "\n",
      "Fold: 5  Epoch: 379  Training loss = 1.8021  Validation loss = 4.0693  \n",
      "\n",
      "Fold: 5  Epoch: 380  Training loss = 1.8020  Validation loss = 4.0689  \n",
      "\n",
      "Fold: 5  Epoch: 381  Training loss = 1.8018  Validation loss = 4.0680  \n",
      "\n",
      "Fold: 5  Epoch: 382  Training loss = 1.8018  Validation loss = 4.0681  \n",
      "\n",
      "Fold: 5  Epoch: 383  Training loss = 1.8015  Validation loss = 4.0666  \n",
      "\n",
      "Fold: 5  Epoch: 384  Training loss = 1.8015  Validation loss = 4.0672  \n",
      "\n",
      "Fold: 5  Epoch: 385  Training loss = 1.8013  Validation loss = 4.0662  \n",
      "\n",
      "Fold: 5  Epoch: 386  Training loss = 1.8012  Validation loss = 4.0653  \n",
      "\n",
      "Fold: 5  Epoch: 387  Training loss = 1.8011  Validation loss = 4.0646  \n",
      "\n",
      "Fold: 5  Epoch: 388  Training loss = 1.8009  Validation loss = 4.0638  \n",
      "\n",
      "Fold: 5  Epoch: 389  Training loss = 1.8007  Validation loss = 4.0633  \n",
      "\n",
      "Fold: 5  Epoch: 390  Training loss = 1.8006  Validation loss = 4.0626  \n",
      "\n",
      "Fold: 5  Epoch: 391  Training loss = 1.8005  Validation loss = 4.0626  \n",
      "\n",
      "Fold: 5  Epoch: 392  Training loss = 1.8005  Validation loss = 4.0630  \n",
      "\n",
      "Fold: 5  Epoch: 393  Training loss = 1.8004  Validation loss = 4.0627  \n",
      "\n",
      "Fold: 5  Epoch: 394  Training loss = 1.8002  Validation loss = 4.0617  \n",
      "\n",
      "Fold: 5  Epoch: 395  Training loss = 1.8001  Validation loss = 4.0613  \n",
      "\n",
      "Fold: 5  Epoch: 396  Training loss = 1.7999  Validation loss = 4.0601  \n",
      "\n",
      "Fold: 5  Epoch: 397  Training loss = 1.7998  Validation loss = 4.0590  \n",
      "\n",
      "Fold: 5  Epoch: 398  Training loss = 1.7996  Validation loss = 4.0582  \n",
      "\n",
      "Fold: 5  Epoch: 399  Training loss = 1.7995  Validation loss = 4.0572  \n",
      "\n",
      "Fold: 5  Epoch: 400  Training loss = 1.7993  Validation loss = 4.0559  \n",
      "\n",
      "Fold: 5  Epoch: 401  Training loss = 1.7992  Validation loss = 4.0558  \n",
      "\n",
      "Fold: 5  Epoch: 402  Training loss = 1.7990  Validation loss = 4.0546  \n",
      "\n",
      "Fold: 5  Epoch: 403  Training loss = 1.7989  Validation loss = 4.0539  \n",
      "\n",
      "Fold: 5  Epoch: 404  Training loss = 1.7989  Validation loss = 4.0545  \n",
      "\n",
      "Fold: 5  Epoch: 405  Training loss = 1.7988  Validation loss = 4.0544  \n",
      "\n",
      "Fold: 5  Epoch: 406  Training loss = 1.7987  Validation loss = 4.0543  \n",
      "\n",
      "Fold: 5  Epoch: 407  Training loss = 1.7986  Validation loss = 4.0540  \n",
      "\n",
      "Fold: 5  Epoch: 408  Training loss = 1.7984  Validation loss = 4.0525  \n",
      "\n",
      "Fold: 5  Epoch: 409  Training loss = 1.7982  Validation loss = 4.0509  \n",
      "\n",
      "Fold: 5  Epoch: 410  Training loss = 1.7980  Validation loss = 4.0495  \n",
      "\n",
      "Fold: 5  Epoch: 411  Training loss = 1.7979  Validation loss = 4.0494  \n",
      "\n",
      "Fold: 5  Epoch: 412  Training loss = 1.7979  Validation loss = 4.0488  \n",
      "\n",
      "Fold: 5  Epoch: 413  Training loss = 1.7978  Validation loss = 4.0486  \n",
      "\n",
      "Fold: 5  Epoch: 414  Training loss = 1.7977  Validation loss = 4.0485  \n",
      "\n",
      "Fold: 5  Epoch: 415  Training loss = 1.7975  Validation loss = 4.0474  \n",
      "\n",
      "Fold: 5  Epoch: 416  Training loss = 1.7975  Validation loss = 4.0470  \n",
      "\n",
      "Fold: 5  Epoch: 417  Training loss = 1.7973  Validation loss = 4.0462  \n",
      "\n",
      "Fold: 5  Epoch: 418  Training loss = 1.7972  Validation loss = 4.0454  \n",
      "\n",
      "Fold: 5  Epoch: 419  Training loss = 1.7971  Validation loss = 4.0461  \n",
      "\n",
      "Fold: 5  Epoch: 420  Training loss = 1.7970  Validation loss = 4.0462  \n",
      "\n",
      "Fold: 5  Epoch: 421  Training loss = 1.7968  Validation loss = 4.0447  \n",
      "\n",
      "Fold: 5  Epoch: 422  Training loss = 1.7966  Validation loss = 4.0434  \n",
      "\n",
      "Fold: 5  Epoch: 423  Training loss = 1.7964  Validation loss = 4.0412  \n",
      "\n",
      "Fold: 5  Epoch: 424  Training loss = 1.7963  Validation loss = 4.0416  \n",
      "\n",
      "Fold: 5  Epoch: 425  Training loss = 1.7962  Validation loss = 4.0411  \n",
      "\n",
      "Fold: 5  Epoch: 426  Training loss = 1.7961  Validation loss = 4.0406  \n",
      "\n",
      "Fold: 5  Epoch: 427  Training loss = 1.7960  Validation loss = 4.0396  \n",
      "\n",
      "Fold: 5  Epoch: 428  Training loss = 1.7958  Validation loss = 4.0382  \n",
      "\n",
      "Fold: 5  Epoch: 429  Training loss = 1.7956  Validation loss = 4.0375  \n",
      "\n",
      "Fold: 5  Epoch: 430  Training loss = 1.7955  Validation loss = 4.0363  \n",
      "\n",
      "Fold: 5  Epoch: 431  Training loss = 1.7953  Validation loss = 4.0351  \n",
      "\n",
      "Fold: 5  Epoch: 432  Training loss = 1.7951  Validation loss = 4.0334  \n",
      "\n",
      "Fold: 5  Epoch: 433  Training loss = 1.7950  Validation loss = 4.0321  \n",
      "\n",
      "Fold: 5  Epoch: 434  Training loss = 1.7949  Validation loss = 4.0324  \n",
      "\n",
      "Fold: 5  Epoch: 435  Training loss = 1.7948  Validation loss = 4.0315  \n",
      "\n",
      "Fold: 5  Epoch: 436  Training loss = 1.7946  Validation loss = 4.0314  \n",
      "\n",
      "Fold: 5  Epoch: 437  Training loss = 1.7945  Validation loss = 4.0303  \n",
      "\n",
      "Fold: 5  Epoch: 438  Training loss = 1.7943  Validation loss = 4.0300  \n",
      "\n",
      "Fold: 5  Epoch: 439  Training loss = 1.7942  Validation loss = 4.0295  \n",
      "\n",
      "Fold: 5  Epoch: 440  Training loss = 1.7942  Validation loss = 4.0297  \n",
      "\n",
      "Fold: 5  Epoch: 441  Training loss = 1.7940  Validation loss = 4.0289  \n",
      "\n",
      "Fold: 5  Epoch: 442  Training loss = 1.7939  Validation loss = 4.0285  \n",
      "\n",
      "Fold: 5  Epoch: 443  Training loss = 1.7938  Validation loss = 4.0284  \n",
      "\n",
      "Fold: 5  Epoch: 444  Training loss = 1.7937  Validation loss = 4.0271  \n",
      "\n",
      "Fold: 5  Epoch: 445  Training loss = 1.7936  Validation loss = 4.0275  \n",
      "\n",
      "Fold: 5  Epoch: 446  Training loss = 1.7936  Validation loss = 4.0278  \n",
      "\n",
      "Fold: 5  Epoch: 447  Training loss = 1.7935  Validation loss = 4.0275  \n",
      "\n",
      "Fold: 5  Epoch: 448  Training loss = 1.7934  Validation loss = 4.0280  \n",
      "\n",
      "Fold: 5  Epoch: 449  Training loss = 1.7934  Validation loss = 4.0280  \n",
      "\n",
      "Fold: 5  Epoch: 450  Training loss = 1.7934  Validation loss = 4.0289  \n",
      "\n",
      "Check model:  Fold: 5  Epoch: 444  Training loss = 1.7934  Validation loss = 4.0289  \n",
      "\n",
      "Fold: 6  Epoch: 1  Training loss = 2.0157  Validation loss = 1.7706  \n",
      "\n",
      "Fold: 6  Epoch: 2  Training loss = 2.0155  Validation loss = 1.7702  \n",
      "\n",
      "Fold: 6  Epoch: 3  Training loss = 2.0151  Validation loss = 1.7686  \n",
      "\n",
      "Fold: 6  Epoch: 4  Training loss = 2.0147  Validation loss = 1.7671  \n",
      "\n",
      "Fold: 6  Epoch: 5  Training loss = 2.0142  Validation loss = 1.7655  \n",
      "\n",
      "Fold: 6  Epoch: 6  Training loss = 2.0137  Validation loss = 1.7637  \n",
      "\n",
      "Fold: 6  Epoch: 7  Training loss = 2.0132  Validation loss = 1.7620  \n",
      "\n",
      "Fold: 6  Epoch: 8  Training loss = 2.0129  Validation loss = 1.7611  \n",
      "\n",
      "Fold: 6  Epoch: 9  Training loss = 2.0126  Validation loss = 1.7600  \n",
      "\n",
      "Fold: 6  Epoch: 10  Training loss = 2.0120  Validation loss = 1.7578  \n",
      "\n",
      "Fold: 6  Epoch: 11  Training loss = 2.0117  Validation loss = 1.7566  \n",
      "\n",
      "Fold: 6  Epoch: 12  Training loss = 2.0111  Validation loss = 1.7539  \n",
      "\n",
      "Fold: 6  Epoch: 13  Training loss = 2.0109  Validation loss = 1.7538  \n",
      "\n",
      "Fold: 6  Epoch: 14  Training loss = 2.0102  Validation loss = 1.7508  \n",
      "\n",
      "Fold: 6  Epoch: 15  Training loss = 2.0097  Validation loss = 1.7489  \n",
      "\n",
      "Fold: 6  Epoch: 16  Training loss = 2.0093  Validation loss = 1.7473  \n",
      "\n",
      "Fold: 6  Epoch: 17  Training loss = 2.0087  Validation loss = 1.7452  \n",
      "\n",
      "Fold: 6  Epoch: 18  Training loss = 2.0082  Validation loss = 1.7432  \n",
      "\n",
      "Fold: 6  Epoch: 19  Training loss = 2.0078  Validation loss = 1.7419  \n",
      "\n",
      "Fold: 6  Epoch: 20  Training loss = 2.0073  Validation loss = 1.7399  \n",
      "\n",
      "Fold: 6  Epoch: 21  Training loss = 2.0069  Validation loss = 1.7385  \n",
      "\n",
      "Fold: 6  Epoch: 22  Training loss = 2.0065  Validation loss = 1.7372  \n",
      "\n",
      "Fold: 6  Epoch: 23  Training loss = 2.0064  Validation loss = 1.7366  \n",
      "\n",
      "Fold: 6  Epoch: 24  Training loss = 2.0059  Validation loss = 1.7350  \n",
      "\n",
      "Fold: 6  Epoch: 25  Training loss = 2.0057  Validation loss = 1.7342  \n",
      "\n",
      "Fold: 6  Epoch: 26  Training loss = 2.0050  Validation loss = 1.7315  \n",
      "\n",
      "Fold: 6  Epoch: 27  Training loss = 2.0044  Validation loss = 1.7293  \n",
      "\n",
      "Fold: 6  Epoch: 28  Training loss = 2.0042  Validation loss = 1.7286  \n",
      "\n",
      "Fold: 6  Epoch: 29  Training loss = 2.0039  Validation loss = 1.7276  \n",
      "\n",
      "Fold: 6  Epoch: 30  Training loss = 2.0036  Validation loss = 1.7268  \n",
      "\n",
      "Fold: 6  Epoch: 31  Training loss = 2.0032  Validation loss = 1.7251  \n",
      "\n",
      "Fold: 6  Epoch: 32  Training loss = 2.0027  Validation loss = 1.7232  \n",
      "\n",
      "Fold: 6  Epoch: 33  Training loss = 2.0023  Validation loss = 1.7218  \n",
      "\n",
      "Fold: 6  Epoch: 34  Training loss = 2.0018  Validation loss = 1.7197  \n",
      "\n",
      "Fold: 6  Epoch: 35  Training loss = 2.0014  Validation loss = 1.7179  \n",
      "\n",
      "Fold: 6  Epoch: 36  Training loss = 2.0010  Validation loss = 1.7164  \n",
      "\n",
      "Fold: 6  Epoch: 37  Training loss = 2.0006  Validation loss = 1.7151  \n",
      "\n",
      "Fold: 6  Epoch: 38  Training loss = 2.0004  Validation loss = 1.7149  \n",
      "\n",
      "Fold: 6  Epoch: 39  Training loss = 1.9999  Validation loss = 1.7127  \n",
      "\n",
      "Fold: 6  Epoch: 40  Training loss = 1.9995  Validation loss = 1.7115  \n",
      "\n",
      "Fold: 6  Epoch: 41  Training loss = 1.9990  Validation loss = 1.7095  \n",
      "\n",
      "Fold: 6  Epoch: 42  Training loss = 1.9989  Validation loss = 1.7093  \n",
      "\n",
      "Fold: 6  Epoch: 43  Training loss = 1.9988  Validation loss = 1.7092  \n",
      "\n",
      "Fold: 6  Epoch: 44  Training loss = 1.9982  Validation loss = 1.7067  \n",
      "\n",
      "Fold: 6  Epoch: 45  Training loss = 1.9978  Validation loss = 1.7051  \n",
      "\n",
      "Fold: 6  Epoch: 46  Training loss = 1.9973  Validation loss = 1.7031  \n",
      "\n",
      "Fold: 6  Epoch: 47  Training loss = 1.9968  Validation loss = 1.7011  \n",
      "\n",
      "Fold: 6  Epoch: 48  Training loss = 1.9966  Validation loss = 1.7006  \n",
      "\n",
      "Fold: 6  Epoch: 49  Training loss = 1.9963  Validation loss = 1.6997  \n",
      "\n",
      "Fold: 6  Epoch: 50  Training loss = 1.9962  Validation loss = 1.6993  \n",
      "\n",
      "Fold: 6  Epoch: 51  Training loss = 1.9958  Validation loss = 1.6980  \n",
      "\n",
      "Fold: 6  Epoch: 52  Training loss = 1.9953  Validation loss = 1.6959  \n",
      "\n",
      "Fold: 6  Epoch: 53  Training loss = 1.9946  Validation loss = 1.6932  \n",
      "\n",
      "Fold: 6  Epoch: 54  Training loss = 1.9940  Validation loss = 1.6908  \n",
      "\n",
      "Fold: 6  Epoch: 55  Training loss = 1.9935  Validation loss = 1.6887  \n",
      "\n",
      "Fold: 6  Epoch: 56  Training loss = 1.9933  Validation loss = 1.6881  \n",
      "\n",
      "Fold: 6  Epoch: 57  Training loss = 1.9928  Validation loss = 1.6859  \n",
      "\n",
      "Fold: 6  Epoch: 58  Training loss = 1.9925  Validation loss = 1.6851  \n",
      "\n",
      "Fold: 6  Epoch: 59  Training loss = 1.9919  Validation loss = 1.6828  \n",
      "\n",
      "Fold: 6  Epoch: 60  Training loss = 1.9917  Validation loss = 1.6820  \n",
      "\n",
      "Fold: 6  Epoch: 61  Training loss = 1.9914  Validation loss = 1.6810  \n",
      "\n",
      "Fold: 6  Epoch: 62  Training loss = 1.9912  Validation loss = 1.6804  \n",
      "\n",
      "Fold: 6  Epoch: 63  Training loss = 1.9907  Validation loss = 1.6787  \n",
      "\n",
      "Fold: 6  Epoch: 64  Training loss = 1.9903  Validation loss = 1.6767  \n",
      "\n",
      "Fold: 6  Epoch: 65  Training loss = 1.9898  Validation loss = 1.6750  \n",
      "\n",
      "Fold: 6  Epoch: 66  Training loss = 1.9895  Validation loss = 1.6738  \n",
      "\n",
      "Fold: 6  Epoch: 67  Training loss = 1.9892  Validation loss = 1.6724  \n",
      "\n",
      "Fold: 6  Epoch: 68  Training loss = 1.9888  Validation loss = 1.6709  \n",
      "\n",
      "Fold: 6  Epoch: 69  Training loss = 1.9882  Validation loss = 1.6688  \n",
      "\n",
      "Fold: 6  Epoch: 70  Training loss = 1.9879  Validation loss = 1.6677  \n",
      "\n",
      "Fold: 6  Epoch: 71  Training loss = 1.9874  Validation loss = 1.6656  \n",
      "\n",
      "Fold: 6  Epoch: 72  Training loss = 1.9868  Validation loss = 1.6631  \n",
      "\n",
      "Fold: 6  Epoch: 73  Training loss = 1.9863  Validation loss = 1.6612  \n",
      "\n",
      "Fold: 6  Epoch: 74  Training loss = 1.9862  Validation loss = 1.6612  \n",
      "\n",
      "Fold: 6  Epoch: 75  Training loss = 1.9859  Validation loss = 1.6600  \n",
      "\n",
      "Fold: 6  Epoch: 76  Training loss = 1.9853  Validation loss = 1.6574  \n",
      "\n",
      "Fold: 6  Epoch: 77  Training loss = 1.9848  Validation loss = 1.6556  \n",
      "\n",
      "Fold: 6  Epoch: 78  Training loss = 1.9844  Validation loss = 1.6539  \n",
      "\n",
      "Fold: 6  Epoch: 79  Training loss = 1.9840  Validation loss = 1.6520  \n",
      "\n",
      "Fold: 6  Epoch: 80  Training loss = 1.9836  Validation loss = 1.6505  \n",
      "\n",
      "Fold: 6  Epoch: 81  Training loss = 1.9830  Validation loss = 1.6483  \n",
      "\n",
      "Fold: 6  Epoch: 82  Training loss = 1.9827  Validation loss = 1.6468  \n",
      "\n",
      "Fold: 6  Epoch: 83  Training loss = 1.9822  Validation loss = 1.6445  \n",
      "\n",
      "Fold: 6  Epoch: 84  Training loss = 1.9821  Validation loss = 1.6446  \n",
      "\n",
      "Fold: 6  Epoch: 85  Training loss = 1.9815  Validation loss = 1.6424  \n",
      "\n",
      "Fold: 6  Epoch: 86  Training loss = 1.9812  Validation loss = 1.6409  \n",
      "\n",
      "Fold: 6  Epoch: 87  Training loss = 1.9809  Validation loss = 1.6398  \n",
      "\n",
      "Fold: 6  Epoch: 88  Training loss = 1.9802  Validation loss = 1.6367  \n",
      "\n",
      "Fold: 6  Epoch: 89  Training loss = 1.9801  Validation loss = 1.6364  \n",
      "\n",
      "Fold: 6  Epoch: 90  Training loss = 1.9796  Validation loss = 1.6345  \n",
      "\n",
      "Fold: 6  Epoch: 91  Training loss = 1.9792  Validation loss = 1.6328  \n",
      "\n",
      "Fold: 6  Epoch: 92  Training loss = 1.9788  Validation loss = 1.6312  \n",
      "\n",
      "Fold: 6  Epoch: 93  Training loss = 1.9788  Validation loss = 1.6314  \n",
      "\n",
      "Fold: 6  Epoch: 94  Training loss = 1.9784  Validation loss = 1.6302  \n",
      "\n",
      "Fold: 6  Epoch: 95  Training loss = 1.9780  Validation loss = 1.6282  \n",
      "\n",
      "Fold: 6  Epoch: 96  Training loss = 1.9777  Validation loss = 1.6272  \n",
      "\n",
      "Fold: 6  Epoch: 97  Training loss = 1.9773  Validation loss = 1.6254  \n",
      "\n",
      "Fold: 6  Epoch: 98  Training loss = 1.9769  Validation loss = 1.6238  \n",
      "\n",
      "Fold: 6  Epoch: 99  Training loss = 1.9765  Validation loss = 1.6221  \n",
      "\n",
      "Fold: 6  Epoch: 100  Training loss = 1.9762  Validation loss = 1.6213  \n",
      "\n",
      "Fold: 6  Epoch: 101  Training loss = 1.9760  Validation loss = 1.6205  \n",
      "\n",
      "Fold: 6  Epoch: 102  Training loss = 1.9755  Validation loss = 1.6184  \n",
      "\n",
      "Fold: 6  Epoch: 103  Training loss = 1.9752  Validation loss = 1.6170  \n",
      "\n",
      "Fold: 6  Epoch: 104  Training loss = 1.9746  Validation loss = 1.6139  \n",
      "\n",
      "Fold: 6  Epoch: 105  Training loss = 1.9743  Validation loss = 1.6127  \n",
      "\n",
      "Fold: 6  Epoch: 106  Training loss = 1.9737  Validation loss = 1.6103  \n",
      "\n",
      "Fold: 6  Epoch: 107  Training loss = 1.9734  Validation loss = 1.6089  \n",
      "\n",
      "Fold: 6  Epoch: 108  Training loss = 1.9729  Validation loss = 1.6067  \n",
      "\n",
      "Fold: 6  Epoch: 109  Training loss = 1.9726  Validation loss = 1.6051  \n",
      "\n",
      "Fold: 6  Epoch: 110  Training loss = 1.9722  Validation loss = 1.6036  \n",
      "\n",
      "Fold: 6  Epoch: 111  Training loss = 1.9720  Validation loss = 1.6030  \n",
      "\n",
      "Fold: 6  Epoch: 112  Training loss = 1.9719  Validation loss = 1.6030  \n",
      "\n",
      "Fold: 6  Epoch: 113  Training loss = 1.9712  Validation loss = 1.5994  \n",
      "\n",
      "Fold: 6  Epoch: 114  Training loss = 1.9710  Validation loss = 1.5986  \n",
      "\n",
      "Fold: 6  Epoch: 115  Training loss = 1.9705  Validation loss = 1.5962  \n",
      "\n",
      "Fold: 6  Epoch: 116  Training loss = 1.9701  Validation loss = 1.5948  \n",
      "\n",
      "Fold: 6  Epoch: 117  Training loss = 1.9697  Validation loss = 1.5932  \n",
      "\n",
      "Fold: 6  Epoch: 118  Training loss = 1.9693  Validation loss = 1.5913  \n",
      "\n",
      "Fold: 6  Epoch: 119  Training loss = 1.9690  Validation loss = 1.5902  \n",
      "\n",
      "Fold: 6  Epoch: 120  Training loss = 1.9685  Validation loss = 1.5882  \n",
      "\n",
      "Fold: 6  Epoch: 121  Training loss = 1.9681  Validation loss = 1.5866  \n",
      "\n",
      "Fold: 6  Epoch: 122  Training loss = 1.9679  Validation loss = 1.5855  \n",
      "\n",
      "Fold: 6  Epoch: 123  Training loss = 1.9675  Validation loss = 1.5840  \n",
      "\n",
      "Fold: 6  Epoch: 124  Training loss = 1.9671  Validation loss = 1.5823  \n",
      "\n",
      "Fold: 6  Epoch: 125  Training loss = 1.9667  Validation loss = 1.5803  \n",
      "\n",
      "Fold: 6  Epoch: 126  Training loss = 1.9664  Validation loss = 1.5793  \n",
      "\n",
      "Fold: 6  Epoch: 127  Training loss = 1.9662  Validation loss = 1.5786  \n",
      "\n",
      "Fold: 6  Epoch: 128  Training loss = 1.9659  Validation loss = 1.5772  \n",
      "\n",
      "Fold: 6  Epoch: 129  Training loss = 1.9655  Validation loss = 1.5756  \n",
      "\n",
      "Fold: 6  Epoch: 130  Training loss = 1.9652  Validation loss = 1.5740  \n",
      "\n",
      "Fold: 6  Epoch: 131  Training loss = 1.9650  Validation loss = 1.5735  \n",
      "\n",
      "Fold: 6  Epoch: 132  Training loss = 1.9648  Validation loss = 1.5729  \n",
      "\n",
      "Fold: 6  Epoch: 133  Training loss = 1.9645  Validation loss = 1.5719  \n",
      "\n",
      "Fold: 6  Epoch: 134  Training loss = 1.9642  Validation loss = 1.5707  \n",
      "\n",
      "Fold: 6  Epoch: 135  Training loss = 1.9639  Validation loss = 1.5693  \n",
      "\n",
      "Fold: 6  Epoch: 136  Training loss = 1.9639  Validation loss = 1.5698  \n",
      "\n",
      "Fold: 6  Epoch: 137  Training loss = 1.9635  Validation loss = 1.5678  \n",
      "\n",
      "Fold: 6  Epoch: 138  Training loss = 1.9631  Validation loss = 1.5665  \n",
      "\n",
      "Fold: 6  Epoch: 139  Training loss = 1.9628  Validation loss = 1.5649  \n",
      "\n",
      "Fold: 6  Epoch: 140  Training loss = 1.9626  Validation loss = 1.5645  \n",
      "\n",
      "Fold: 6  Epoch: 141  Training loss = 1.9622  Validation loss = 1.5627  \n",
      "\n",
      "Fold: 6  Epoch: 142  Training loss = 1.9619  Validation loss = 1.5613  \n",
      "\n",
      "Fold: 6  Epoch: 143  Training loss = 1.9615  Validation loss = 1.5593  \n",
      "\n",
      "Fold: 6  Epoch: 144  Training loss = 1.9611  Validation loss = 1.5574  \n",
      "\n",
      "Fold: 6  Epoch: 145  Training loss = 1.9606  Validation loss = 1.5547  \n",
      "\n",
      "Fold: 6  Epoch: 146  Training loss = 1.9602  Validation loss = 1.5532  \n",
      "\n",
      "Fold: 6  Epoch: 147  Training loss = 1.9600  Validation loss = 1.5521  \n",
      "\n",
      "Fold: 6  Epoch: 148  Training loss = 1.9597  Validation loss = 1.5508  \n",
      "\n",
      "Fold: 6  Epoch: 149  Training loss = 1.9592  Validation loss = 1.5486  \n",
      "\n",
      "Fold: 6  Epoch: 150  Training loss = 1.9587  Validation loss = 1.5459  \n",
      "\n",
      "Fold: 6  Epoch: 151  Training loss = 1.9582  Validation loss = 1.5435  \n",
      "\n",
      "Fold: 6  Epoch: 152  Training loss = 1.9579  Validation loss = 1.5421  \n",
      "\n",
      "Fold: 6  Epoch: 153  Training loss = 1.9577  Validation loss = 1.5411  \n",
      "\n",
      "Fold: 6  Epoch: 154  Training loss = 1.9571  Validation loss = 1.5383  \n",
      "\n",
      "Fold: 6  Epoch: 155  Training loss = 1.9569  Validation loss = 1.5379  \n",
      "\n",
      "Fold: 6  Epoch: 156  Training loss = 1.9567  Validation loss = 1.5374  \n",
      "\n",
      "Fold: 6  Epoch: 157  Training loss = 1.9564  Validation loss = 1.5358  \n",
      "\n",
      "Fold: 6  Epoch: 158  Training loss = 1.9560  Validation loss = 1.5343  \n",
      "\n",
      "Fold: 6  Epoch: 159  Training loss = 1.9558  Validation loss = 1.5336  \n",
      "\n",
      "Fold: 6  Epoch: 160  Training loss = 1.9556  Validation loss = 1.5329  \n",
      "\n",
      "Fold: 6  Epoch: 161  Training loss = 1.9553  Validation loss = 1.5315  \n",
      "\n",
      "Fold: 6  Epoch: 162  Training loss = 1.9551  Validation loss = 1.5306  \n",
      "\n",
      "Fold: 6  Epoch: 163  Training loss = 1.9548  Validation loss = 1.5297  \n",
      "\n",
      "Fold: 6  Epoch: 164  Training loss = 1.9546  Validation loss = 1.5290  \n",
      "\n",
      "Fold: 6  Epoch: 165  Training loss = 1.9543  Validation loss = 1.5282  \n",
      "\n",
      "Fold: 6  Epoch: 166  Training loss = 1.9541  Validation loss = 1.5271  \n",
      "\n",
      "Fold: 6  Epoch: 167  Training loss = 1.9538  Validation loss = 1.5262  \n",
      "\n",
      "Fold: 6  Epoch: 168  Training loss = 1.9534  Validation loss = 1.5247  \n",
      "\n",
      "Fold: 6  Epoch: 169  Training loss = 1.9531  Validation loss = 1.5235  \n",
      "\n",
      "Fold: 6  Epoch: 170  Training loss = 1.9529  Validation loss = 1.5226  \n",
      "\n",
      "Fold: 6  Epoch: 171  Training loss = 1.9528  Validation loss = 1.5227  \n",
      "\n",
      "Fold: 6  Epoch: 172  Training loss = 1.9526  Validation loss = 1.5222  \n",
      "\n",
      "Fold: 6  Epoch: 173  Training loss = 1.9523  Validation loss = 1.5210  \n",
      "\n",
      "Fold: 6  Epoch: 174  Training loss = 1.9520  Validation loss = 1.5195  \n",
      "\n",
      "Fold: 6  Epoch: 175  Training loss = 1.9517  Validation loss = 1.5180  \n",
      "\n",
      "Fold: 6  Epoch: 176  Training loss = 1.9513  Validation loss = 1.5163  \n",
      "\n",
      "Fold: 6  Epoch: 177  Training loss = 1.9510  Validation loss = 1.5151  \n",
      "\n",
      "Fold: 6  Epoch: 178  Training loss = 1.9506  Validation loss = 1.5126  \n",
      "\n",
      "Fold: 6  Epoch: 179  Training loss = 1.9501  Validation loss = 1.5106  \n",
      "\n",
      "Fold: 6  Epoch: 180  Training loss = 1.9498  Validation loss = 1.5085  \n",
      "\n",
      "Fold: 6  Epoch: 181  Training loss = 1.9496  Validation loss = 1.5084  \n",
      "\n",
      "Fold: 6  Epoch: 182  Training loss = 1.9495  Validation loss = 1.5081  \n",
      "\n",
      "Fold: 6  Epoch: 183  Training loss = 1.9490  Validation loss = 1.5056  \n",
      "\n",
      "Fold: 6  Epoch: 184  Training loss = 1.9486  Validation loss = 1.5042  \n",
      "\n",
      "Fold: 6  Epoch: 185  Training loss = 1.9484  Validation loss = 1.5035  \n",
      "\n",
      "Fold: 6  Epoch: 186  Training loss = 1.9482  Validation loss = 1.5024  \n",
      "\n",
      "Fold: 6  Epoch: 187  Training loss = 1.9480  Validation loss = 1.5015  \n",
      "\n",
      "Fold: 6  Epoch: 188  Training loss = 1.9478  Validation loss = 1.5012  \n",
      "\n",
      "Fold: 6  Epoch: 189  Training loss = 1.9475  Validation loss = 1.4995  \n",
      "\n",
      "Fold: 6  Epoch: 190  Training loss = 1.9472  Validation loss = 1.4984  \n",
      "\n",
      "Fold: 6  Epoch: 191  Training loss = 1.9470  Validation loss = 1.4975  \n",
      "\n",
      "Fold: 6  Epoch: 192  Training loss = 1.9466  Validation loss = 1.4952  \n",
      "\n",
      "Fold: 6  Epoch: 193  Training loss = 1.9461  Validation loss = 1.4928  \n",
      "\n",
      "Fold: 6  Epoch: 194  Training loss = 1.9458  Validation loss = 1.4916  \n",
      "\n",
      "Fold: 6  Epoch: 195  Training loss = 1.9456  Validation loss = 1.4911  \n",
      "\n",
      "Fold: 6  Epoch: 196  Training loss = 1.9455  Validation loss = 1.4908  \n",
      "\n",
      "Fold: 6  Epoch: 197  Training loss = 1.9451  Validation loss = 1.4892  \n",
      "\n",
      "Fold: 6  Epoch: 198  Training loss = 1.9449  Validation loss = 1.4883  \n",
      "\n",
      "Fold: 6  Epoch: 199  Training loss = 1.9448  Validation loss = 1.4885  \n",
      "\n",
      "Fold: 6  Epoch: 200  Training loss = 1.9445  Validation loss = 1.4867  \n",
      "\n",
      "Fold: 6  Epoch: 201  Training loss = 1.9441  Validation loss = 1.4850  \n",
      "\n",
      "Fold: 6  Epoch: 202  Training loss = 1.9439  Validation loss = 1.4842  \n",
      "\n",
      "Fold: 6  Epoch: 203  Training loss = 1.9436  Validation loss = 1.4829  \n",
      "\n",
      "Fold: 6  Epoch: 204  Training loss = 1.9433  Validation loss = 1.4815  \n",
      "\n",
      "Fold: 6  Epoch: 205  Training loss = 1.9431  Validation loss = 1.4806  \n",
      "\n",
      "Fold: 6  Epoch: 206  Training loss = 1.9427  Validation loss = 1.4784  \n",
      "\n",
      "Fold: 6  Epoch: 207  Training loss = 1.9423  Validation loss = 1.4766  \n",
      "\n",
      "Fold: 6  Epoch: 208  Training loss = 1.9419  Validation loss = 1.4744  \n",
      "\n",
      "Fold: 6  Epoch: 209  Training loss = 1.9415  Validation loss = 1.4732  \n",
      "\n",
      "Fold: 6  Epoch: 210  Training loss = 1.9414  Validation loss = 1.4732  \n",
      "\n",
      "Fold: 6  Epoch: 211  Training loss = 1.9412  Validation loss = 1.4727  \n",
      "\n",
      "Fold: 6  Epoch: 212  Training loss = 1.9409  Validation loss = 1.4710  \n",
      "\n",
      "Fold: 6  Epoch: 213  Training loss = 1.9406  Validation loss = 1.4699  \n",
      "\n",
      "Fold: 6  Epoch: 214  Training loss = 1.9404  Validation loss = 1.4694  \n",
      "\n",
      "Fold: 6  Epoch: 215  Training loss = 1.9403  Validation loss = 1.4695  \n",
      "\n",
      "Fold: 6  Epoch: 216  Training loss = 1.9400  Validation loss = 1.4681  \n",
      "\n",
      "Fold: 6  Epoch: 217  Training loss = 1.9399  Validation loss = 1.4683  \n",
      "\n",
      "Fold: 6  Epoch: 218  Training loss = 1.9398  Validation loss = 1.4681  \n",
      "\n",
      "Fold: 6  Epoch: 219  Training loss = 1.9395  Validation loss = 1.4664  \n",
      "\n",
      "Fold: 6  Epoch: 220  Training loss = 1.9391  Validation loss = 1.4648  \n",
      "\n",
      "Fold: 6  Epoch: 221  Training loss = 1.9389  Validation loss = 1.4640  \n",
      "\n",
      "Fold: 6  Epoch: 222  Training loss = 1.9387  Validation loss = 1.4634  \n",
      "\n",
      "Fold: 6  Epoch: 223  Training loss = 1.9384  Validation loss = 1.4624  \n",
      "\n",
      "Fold: 6  Epoch: 224  Training loss = 1.9382  Validation loss = 1.4614  \n",
      "\n",
      "Fold: 6  Epoch: 225  Training loss = 1.9381  Validation loss = 1.4613  \n",
      "\n",
      "Fold: 6  Epoch: 226  Training loss = 1.9376  Validation loss = 1.4587  \n",
      "\n",
      "Fold: 6  Epoch: 227  Training loss = 1.9374  Validation loss = 1.4578  \n",
      "\n",
      "Fold: 6  Epoch: 228  Training loss = 1.9372  Validation loss = 1.4572  \n",
      "\n",
      "Fold: 6  Epoch: 229  Training loss = 1.9369  Validation loss = 1.4560  \n",
      "\n",
      "Fold: 6  Epoch: 230  Training loss = 1.9368  Validation loss = 1.4563  \n",
      "\n",
      "Fold: 6  Epoch: 231  Training loss = 1.9364  Validation loss = 1.4546  \n",
      "\n",
      "Fold: 6  Epoch: 232  Training loss = 1.9361  Validation loss = 1.4529  \n",
      "\n",
      "Fold: 6  Epoch: 233  Training loss = 1.9359  Validation loss = 1.4521  \n",
      "\n",
      "Fold: 6  Epoch: 234  Training loss = 1.9357  Validation loss = 1.4518  \n",
      "\n",
      "Fold: 6  Epoch: 235  Training loss = 1.9356  Validation loss = 1.4516  \n",
      "\n",
      "Fold: 6  Epoch: 236  Training loss = 1.9353  Validation loss = 1.4507  \n",
      "\n",
      "Fold: 6  Epoch: 237  Training loss = 1.9350  Validation loss = 1.4487  \n",
      "\n",
      "Fold: 6  Epoch: 238  Training loss = 1.9347  Validation loss = 1.4474  \n",
      "\n",
      "Fold: 6  Epoch: 239  Training loss = 1.9343  Validation loss = 1.4453  \n",
      "\n",
      "Fold: 6  Epoch: 240  Training loss = 1.9341  Validation loss = 1.4446  \n",
      "\n",
      "Fold: 6  Epoch: 241  Training loss = 1.9337  Validation loss = 1.4423  \n",
      "\n",
      "Fold: 6  Epoch: 242  Training loss = 1.9336  Validation loss = 1.4426  \n",
      "\n",
      "Fold: 6  Epoch: 243  Training loss = 1.9334  Validation loss = 1.4416  \n",
      "\n",
      "Fold: 6  Epoch: 244  Training loss = 1.9330  Validation loss = 1.4396  \n",
      "\n",
      "Fold: 6  Epoch: 245  Training loss = 1.9328  Validation loss = 1.4392  \n",
      "\n",
      "Fold: 6  Epoch: 246  Training loss = 1.9326  Validation loss = 1.4385  \n",
      "\n",
      "Fold: 6  Epoch: 247  Training loss = 1.9324  Validation loss = 1.4381  \n",
      "\n",
      "Fold: 6  Epoch: 248  Training loss = 1.9322  Validation loss = 1.4368  \n",
      "\n",
      "Fold: 6  Epoch: 249  Training loss = 1.9318  Validation loss = 1.4346  \n",
      "\n",
      "Fold: 6  Epoch: 250  Training loss = 1.9316  Validation loss = 1.4339  \n",
      "\n",
      "Fold: 6  Epoch: 251  Training loss = 1.9312  Validation loss = 1.4317  \n",
      "\n",
      "Fold: 6  Epoch: 252  Training loss = 1.9310  Validation loss = 1.4305  \n",
      "\n",
      "Fold: 6  Epoch: 253  Training loss = 1.9308  Validation loss = 1.4299  \n",
      "\n",
      "Fold: 6  Epoch: 254  Training loss = 1.9307  Validation loss = 1.4297  \n",
      "\n",
      "Fold: 6  Epoch: 255  Training loss = 1.9303  Validation loss = 1.4271  \n",
      "\n",
      "Fold: 6  Epoch: 256  Training loss = 1.9301  Validation loss = 1.4262  \n",
      "\n",
      "Fold: 6  Epoch: 257  Training loss = 1.9299  Validation loss = 1.4256  \n",
      "\n",
      "Fold: 6  Epoch: 258  Training loss = 1.9299  Validation loss = 1.4265  \n",
      "\n",
      "Fold: 6  Epoch: 259  Training loss = 1.9294  Validation loss = 1.4235  \n",
      "\n",
      "Fold: 6  Epoch: 260  Training loss = 1.9291  Validation loss = 1.4220  \n",
      "\n",
      "Fold: 6  Epoch: 261  Training loss = 1.9290  Validation loss = 1.4217  \n",
      "\n",
      "Fold: 6  Epoch: 262  Training loss = 1.9289  Validation loss = 1.4215  \n",
      "\n",
      "Fold: 6  Epoch: 263  Training loss = 1.9287  Validation loss = 1.4210  \n",
      "\n",
      "Fold: 6  Epoch: 264  Training loss = 1.9284  Validation loss = 1.4197  \n",
      "\n",
      "Fold: 6  Epoch: 265  Training loss = 1.9283  Validation loss = 1.4197  \n",
      "\n",
      "Fold: 6  Epoch: 266  Training loss = 1.9280  Validation loss = 1.4181  \n",
      "\n",
      "Fold: 6  Epoch: 267  Training loss = 1.9277  Validation loss = 1.4171  \n",
      "\n",
      "Fold: 6  Epoch: 268  Training loss = 1.9274  Validation loss = 1.4155  \n",
      "\n",
      "Fold: 6  Epoch: 269  Training loss = 1.9272  Validation loss = 1.4143  \n",
      "\n",
      "Fold: 6  Epoch: 270  Training loss = 1.9271  Validation loss = 1.4146  \n",
      "\n",
      "Fold: 6  Epoch: 271  Training loss = 1.9269  Validation loss = 1.4138  \n",
      "\n",
      "Fold: 6  Epoch: 272  Training loss = 1.9266  Validation loss = 1.4120  \n",
      "\n",
      "Fold: 6  Epoch: 273  Training loss = 1.9265  Validation loss = 1.4115  \n",
      "\n",
      "Fold: 6  Epoch: 274  Training loss = 1.9262  Validation loss = 1.4099  \n",
      "\n",
      "Fold: 6  Epoch: 275  Training loss = 1.9261  Validation loss = 1.4102  \n",
      "\n",
      "Fold: 6  Epoch: 276  Training loss = 1.9257  Validation loss = 1.4078  \n",
      "\n",
      "Fold: 6  Epoch: 277  Training loss = 1.9255  Validation loss = 1.4071  \n",
      "\n",
      "Fold: 6  Epoch: 278  Training loss = 1.9254  Validation loss = 1.4071  \n",
      "\n",
      "Fold: 6  Epoch: 279  Training loss = 1.9251  Validation loss = 1.4058  \n",
      "\n",
      "Fold: 6  Epoch: 280  Training loss = 1.9249  Validation loss = 1.4048  \n",
      "\n",
      "Fold: 6  Epoch: 281  Training loss = 1.9248  Validation loss = 1.4054  \n",
      "\n",
      "Fold: 6  Epoch: 282  Training loss = 1.9246  Validation loss = 1.4043  \n",
      "\n",
      "Fold: 6  Epoch: 283  Training loss = 1.9244  Validation loss = 1.4037  \n",
      "\n",
      "Fold: 6  Epoch: 284  Training loss = 1.9241  Validation loss = 1.4020  \n",
      "\n",
      "Fold: 6  Epoch: 285  Training loss = 1.9240  Validation loss = 1.4017  \n",
      "\n",
      "Fold: 6  Epoch: 286  Training loss = 1.9238  Validation loss = 1.4012  \n",
      "\n",
      "Fold: 6  Epoch: 287  Training loss = 1.9236  Validation loss = 1.4005  \n",
      "\n",
      "Fold: 6  Epoch: 288  Training loss = 1.9233  Validation loss = 1.3988  \n",
      "\n",
      "Fold: 6  Epoch: 289  Training loss = 1.9228  Validation loss = 1.3955  \n",
      "\n",
      "Fold: 6  Epoch: 290  Training loss = 1.9225  Validation loss = 1.3943  \n",
      "\n",
      "Fold: 6  Epoch: 291  Training loss = 1.9223  Validation loss = 1.3934  \n",
      "\n",
      "Fold: 6  Epoch: 292  Training loss = 1.9223  Validation loss = 1.3942  \n",
      "\n",
      "Fold: 6  Epoch: 293  Training loss = 1.9221  Validation loss = 1.3932  \n",
      "\n",
      "Fold: 6  Epoch: 294  Training loss = 1.9219  Validation loss = 1.3926  \n",
      "\n",
      "Fold: 6  Epoch: 295  Training loss = 1.9218  Validation loss = 1.3930  \n",
      "\n",
      "Fold: 6  Epoch: 296  Training loss = 1.9214  Validation loss = 1.3906  \n",
      "\n",
      "Fold: 6  Epoch: 297  Training loss = 1.9214  Validation loss = 1.3911  \n",
      "\n",
      "Fold: 6  Epoch: 298  Training loss = 1.9212  Validation loss = 1.3912  \n",
      "\n",
      "Fold: 6  Epoch: 299  Training loss = 1.9212  Validation loss = 1.3916  \n",
      "\n",
      "Fold: 6  Epoch: 300  Training loss = 1.9210  Validation loss = 1.3910  \n",
      "\n",
      "Fold: 6  Epoch: 301  Training loss = 1.9206  Validation loss = 1.3882  \n",
      "\n",
      "Fold: 6  Epoch: 302  Training loss = 1.9206  Validation loss = 1.3883  \n",
      "\n",
      "Fold: 6  Epoch: 303  Training loss = 1.9202  Validation loss = 1.3862  \n",
      "\n",
      "Fold: 6  Epoch: 304  Training loss = 1.9199  Validation loss = 1.3842  \n",
      "\n",
      "Fold: 6  Epoch: 305  Training loss = 1.9197  Validation loss = 1.3834  \n",
      "\n",
      "Fold: 6  Epoch: 306  Training loss = 1.9195  Validation loss = 1.3830  \n",
      "\n",
      "Fold: 6  Epoch: 307  Training loss = 1.9191  Validation loss = 1.3799  \n",
      "\n",
      "Fold: 6  Epoch: 308  Training loss = 1.9188  Validation loss = 1.3790  \n",
      "\n",
      "Fold: 6  Epoch: 309  Training loss = 1.9186  Validation loss = 1.3784  \n",
      "\n",
      "Fold: 6  Epoch: 310  Training loss = 1.9186  Validation loss = 1.3789  \n",
      "\n",
      "Fold: 6  Epoch: 311  Training loss = 1.9185  Validation loss = 1.3793  \n",
      "\n",
      "Fold: 6  Epoch: 312  Training loss = 1.9184  Validation loss = 1.3789  \n",
      "\n",
      "Fold: 6  Epoch: 313  Training loss = 1.9181  Validation loss = 1.3776  \n",
      "\n",
      "Fold: 6  Epoch: 314  Training loss = 1.9179  Validation loss = 1.3773  \n",
      "\n",
      "Fold: 6  Epoch: 315  Training loss = 1.9177  Validation loss = 1.3766  \n",
      "\n",
      "Fold: 6  Epoch: 316  Training loss = 1.9175  Validation loss = 1.3760  \n",
      "\n",
      "Fold: 6  Epoch: 317  Training loss = 1.9172  Validation loss = 1.3743  \n",
      "\n",
      "Fold: 6  Epoch: 318  Training loss = 1.9169  Validation loss = 1.3727  \n",
      "\n",
      "Fold: 6  Epoch: 319  Training loss = 1.9167  Validation loss = 1.3717  \n",
      "\n",
      "Fold: 6  Epoch: 320  Training loss = 1.9166  Validation loss = 1.3717  \n",
      "\n",
      "Fold: 6  Epoch: 321  Training loss = 1.9164  Validation loss = 1.3714  \n",
      "\n",
      "Fold: 6  Epoch: 322  Training loss = 1.9161  Validation loss = 1.3689  \n",
      "\n",
      "Fold: 6  Epoch: 323  Training loss = 1.9159  Validation loss = 1.3683  \n",
      "\n",
      "Fold: 6  Epoch: 324  Training loss = 1.9157  Validation loss = 1.3676  \n",
      "\n",
      "Fold: 6  Epoch: 325  Training loss = 1.9155  Validation loss = 1.3673  \n",
      "\n",
      "Fold: 6  Epoch: 326  Training loss = 1.9152  Validation loss = 1.3653  \n",
      "\n",
      "Fold: 6  Epoch: 327  Training loss = 1.9150  Validation loss = 1.3645  \n",
      "\n",
      "Fold: 6  Epoch: 328  Training loss = 1.9148  Validation loss = 1.3639  \n",
      "\n",
      "Fold: 6  Epoch: 329  Training loss = 1.9147  Validation loss = 1.3633  \n",
      "\n",
      "Fold: 6  Epoch: 330  Training loss = 1.9145  Validation loss = 1.3628  \n",
      "\n",
      "Fold: 6  Epoch: 331  Training loss = 1.9142  Validation loss = 1.3604  \n",
      "\n",
      "Fold: 6  Epoch: 332  Training loss = 1.9140  Validation loss = 1.3597  \n",
      "\n",
      "Fold: 6  Epoch: 333  Training loss = 1.9138  Validation loss = 1.3593  \n",
      "\n",
      "Fold: 6  Epoch: 334  Training loss = 1.9135  Validation loss = 1.3572  \n",
      "\n",
      "Fold: 6  Epoch: 335  Training loss = 1.9134  Validation loss = 1.3575  \n",
      "\n",
      "Fold: 6  Epoch: 336  Training loss = 1.9131  Validation loss = 1.3566  \n",
      "\n",
      "Fold: 6  Epoch: 337  Training loss = 1.9130  Validation loss = 1.3557  \n",
      "\n",
      "Fold: 6  Epoch: 338  Training loss = 1.9130  Validation loss = 1.3566  \n",
      "\n",
      "Fold: 6  Epoch: 339  Training loss = 1.9126  Validation loss = 1.3546  \n",
      "\n",
      "Fold: 6  Epoch: 340  Training loss = 1.9124  Validation loss = 1.3538  \n",
      "\n",
      "Fold: 6  Epoch: 341  Training loss = 1.9122  Validation loss = 1.3527  \n",
      "\n",
      "Fold: 6  Epoch: 342  Training loss = 1.9120  Validation loss = 1.3520  \n",
      "\n",
      "Fold: 6  Epoch: 343  Training loss = 1.9116  Validation loss = 1.3502  \n",
      "\n",
      "Fold: 6  Epoch: 344  Training loss = 1.9113  Validation loss = 1.3476  \n",
      "\n",
      "Fold: 6  Epoch: 345  Training loss = 1.9111  Validation loss = 1.3474  \n",
      "\n",
      "Fold: 6  Epoch: 346  Training loss = 1.9109  Validation loss = 1.3458  \n",
      "\n",
      "Fold: 6  Epoch: 347  Training loss = 1.9108  Validation loss = 1.3456  \n",
      "\n",
      "Fold: 6  Epoch: 348  Training loss = 1.9105  Validation loss = 1.3449  \n",
      "\n",
      "Fold: 6  Epoch: 349  Training loss = 1.9104  Validation loss = 1.3447  \n",
      "\n",
      "Fold: 6  Epoch: 350  Training loss = 1.9100  Validation loss = 1.3420  \n",
      "\n",
      "Fold: 6  Epoch: 351  Training loss = 1.9097  Validation loss = 1.3400  \n",
      "\n",
      "Fold: 6  Epoch: 352  Training loss = 1.9094  Validation loss = 1.3387  \n",
      "\n",
      "Fold: 6  Epoch: 353  Training loss = 1.9091  Validation loss = 1.3370  \n",
      "\n",
      "Fold: 6  Epoch: 354  Training loss = 1.9090  Validation loss = 1.3368  \n",
      "\n",
      "Fold: 6  Epoch: 355  Training loss = 1.9088  Validation loss = 1.3358  \n",
      "\n",
      "Fold: 6  Epoch: 356  Training loss = 1.9086  Validation loss = 1.3345  \n",
      "\n",
      "Fold: 6  Epoch: 357  Training loss = 1.9084  Validation loss = 1.3343  \n",
      "\n",
      "Fold: 6  Epoch: 358  Training loss = 1.9083  Validation loss = 1.3343  \n",
      "\n",
      "Fold: 6  Epoch: 359  Training loss = 1.9080  Validation loss = 1.3328  \n",
      "\n",
      "Fold: 6  Epoch: 360  Training loss = 1.9077  Validation loss = 1.3312  \n",
      "\n",
      "Fold: 6  Epoch: 361  Training loss = 1.9076  Validation loss = 1.3308  \n",
      "\n",
      "Fold: 6  Epoch: 362  Training loss = 1.9073  Validation loss = 1.3288  \n",
      "\n",
      "Fold: 6  Epoch: 363  Training loss = 1.9071  Validation loss = 1.3288  \n",
      "\n",
      "Fold: 6  Epoch: 364  Training loss = 1.9069  Validation loss = 1.3274  \n",
      "\n",
      "Fold: 6  Epoch: 365  Training loss = 1.9065  Validation loss = 1.3251  \n",
      "\n",
      "Fold: 6  Epoch: 366  Training loss = 1.9062  Validation loss = 1.3234  \n",
      "\n",
      "Fold: 6  Epoch: 367  Training loss = 1.9061  Validation loss = 1.3237  \n",
      "\n",
      "Fold: 6  Epoch: 368  Training loss = 1.9061  Validation loss = 1.3244  \n",
      "\n",
      "Fold: 6  Epoch: 369  Training loss = 1.9059  Validation loss = 1.3236  \n",
      "\n",
      "Fold: 6  Epoch: 370  Training loss = 1.9058  Validation loss = 1.3240  \n",
      "\n",
      "Fold: 6  Epoch: 371  Training loss = 1.9055  Validation loss = 1.3216  \n",
      "\n",
      "Fold: 6  Epoch: 372  Training loss = 1.9051  Validation loss = 1.3182  \n",
      "\n",
      "Fold: 6  Epoch: 373  Training loss = 1.9049  Validation loss = 1.3173  \n",
      "\n",
      "Fold: 6  Epoch: 374  Training loss = 1.9047  Validation loss = 1.3163  \n",
      "\n",
      "Fold: 6  Epoch: 375  Training loss = 1.9045  Validation loss = 1.3157  \n",
      "\n",
      "Fold: 6  Epoch: 376  Training loss = 1.9044  Validation loss = 1.3159  \n",
      "\n",
      "Fold: 6  Epoch: 377  Training loss = 1.9042  Validation loss = 1.3158  \n",
      "\n",
      "Fold: 6  Epoch: 378  Training loss = 1.9041  Validation loss = 1.3158  \n",
      "\n",
      "Fold: 6  Epoch: 379  Training loss = 1.9041  Validation loss = 1.3163  \n",
      "\n",
      "Fold: 6  Epoch: 380  Training loss = 1.9040  Validation loss = 1.3175  \n",
      "\n",
      "Fold: 6  Epoch: 381  Training loss = 1.9037  Validation loss = 1.3156  \n",
      "\n",
      "Fold: 6  Epoch: 382  Training loss = 1.9035  Validation loss = 1.3144  \n",
      "\n",
      "Fold: 6  Epoch: 383  Training loss = 1.9033  Validation loss = 1.3138  \n",
      "\n",
      "Fold: 6  Epoch: 384  Training loss = 1.9031  Validation loss = 1.3125  \n",
      "\n",
      "Fold: 6  Epoch: 385  Training loss = 1.9029  Validation loss = 1.3120  \n",
      "\n",
      "Fold: 6  Epoch: 386  Training loss = 1.9027  Validation loss = 1.3103  \n",
      "\n",
      "Fold: 6  Epoch: 387  Training loss = 1.9024  Validation loss = 1.3096  \n",
      "\n",
      "Fold: 6  Epoch: 388  Training loss = 1.9022  Validation loss = 1.3091  \n",
      "\n",
      "Fold: 6  Epoch: 389  Training loss = 1.9021  Validation loss = 1.3082  \n",
      "\n",
      "Fold: 6  Epoch: 390  Training loss = 1.9018  Validation loss = 1.3070  \n",
      "\n",
      "Fold: 6  Epoch: 391  Training loss = 1.9017  Validation loss = 1.3065  \n",
      "\n",
      "Fold: 6  Epoch: 392  Training loss = 1.9014  Validation loss = 1.3045  \n",
      "\n",
      "Fold: 6  Epoch: 393  Training loss = 1.9012  Validation loss = 1.3036  \n",
      "\n",
      "Fold: 6  Epoch: 394  Training loss = 1.9011  Validation loss = 1.3032  \n",
      "\n",
      "Fold: 6  Epoch: 395  Training loss = 1.9009  Validation loss = 1.3031  \n",
      "\n",
      "Fold: 6  Epoch: 396  Training loss = 1.9008  Validation loss = 1.3032  \n",
      "\n",
      "Fold: 6  Epoch: 397  Training loss = 1.9005  Validation loss = 1.3025  \n",
      "\n",
      "Fold: 6  Epoch: 398  Training loss = 1.9002  Validation loss = 1.3008  \n",
      "\n",
      "Fold: 6  Epoch: 399  Training loss = 1.9000  Validation loss = 1.2989  \n",
      "\n",
      "Fold: 6  Epoch: 400  Training loss = 1.8997  Validation loss = 1.2980  \n",
      "\n",
      "Fold: 6  Epoch: 401  Training loss = 1.8996  Validation loss = 1.2976  \n",
      "\n",
      "Fold: 6  Epoch: 402  Training loss = 1.8994  Validation loss = 1.2973  \n",
      "\n",
      "Fold: 6  Epoch: 403  Training loss = 1.8992  Validation loss = 1.2965  \n",
      "\n",
      "Fold: 6  Epoch: 404  Training loss = 1.8992  Validation loss = 1.2968  \n",
      "\n",
      "Fold: 6  Epoch: 405  Training loss = 1.8989  Validation loss = 1.2949  \n",
      "\n",
      "Fold: 6  Epoch: 406  Training loss = 1.8986  Validation loss = 1.2939  \n",
      "\n",
      "Fold: 6  Epoch: 407  Training loss = 1.8987  Validation loss = 1.2959  \n",
      "\n",
      "Fold: 6  Epoch: 408  Training loss = 1.8986  Validation loss = 1.2959  \n",
      "\n",
      "Fold: 6  Epoch: 409  Training loss = 1.8984  Validation loss = 1.2957  \n",
      "\n",
      "Fold: 6  Epoch: 410  Training loss = 1.8982  Validation loss = 1.2944  \n",
      "\n",
      "Fold: 6  Epoch: 411  Training loss = 1.8980  Validation loss = 1.2936  \n",
      "\n",
      "Fold: 6  Epoch: 412  Training loss = 1.8978  Validation loss = 1.2926  \n",
      "\n",
      "Fold: 6  Epoch: 413  Training loss = 1.8975  Validation loss = 1.2912  \n",
      "\n",
      "Fold: 6  Epoch: 414  Training loss = 1.8974  Validation loss = 1.2906  \n",
      "\n",
      "Fold: 6  Epoch: 415  Training loss = 1.8972  Validation loss = 1.2900  \n",
      "\n",
      "Fold: 6  Epoch: 416  Training loss = 1.8970  Validation loss = 1.2895  \n",
      "\n",
      "Fold: 6  Epoch: 417  Training loss = 1.8969  Validation loss = 1.2890  \n",
      "\n",
      "Fold: 6  Epoch: 418  Training loss = 1.8966  Validation loss = 1.2881  \n",
      "\n",
      "Fold: 6  Epoch: 419  Training loss = 1.8965  Validation loss = 1.2883  \n",
      "\n",
      "Fold: 6  Epoch: 420  Training loss = 1.8964  Validation loss = 1.2879  \n",
      "\n",
      "Fold: 6  Epoch: 421  Training loss = 1.8962  Validation loss = 1.2879  \n",
      "\n",
      "Fold: 6  Epoch: 422  Training loss = 1.8960  Validation loss = 1.2869  \n",
      "\n",
      "Fold: 6  Epoch: 423  Training loss = 1.8959  Validation loss = 1.2869  \n",
      "\n",
      "Fold: 6  Epoch: 424  Training loss = 1.8957  Validation loss = 1.2855  \n",
      "\n",
      "Fold: 6  Epoch: 425  Training loss = 1.8955  Validation loss = 1.2847  \n",
      "\n",
      "Fold: 6  Epoch: 426  Training loss = 1.8953  Validation loss = 1.2838  \n",
      "\n",
      "Fold: 6  Epoch: 427  Training loss = 1.8950  Validation loss = 1.2823  \n",
      "\n",
      "Fold: 6  Epoch: 428  Training loss = 1.8947  Validation loss = 1.2806  \n",
      "\n",
      "Fold: 6  Epoch: 429  Training loss = 1.8944  Validation loss = 1.2785  \n",
      "\n",
      "Fold: 6  Epoch: 430  Training loss = 1.8943  Validation loss = 1.2783  \n",
      "\n",
      "Fold: 6  Epoch: 431  Training loss = 1.8940  Validation loss = 1.2768  \n",
      "\n",
      "Fold: 6  Epoch: 432  Training loss = 1.8939  Validation loss = 1.2764  \n",
      "\n",
      "Fold: 6  Epoch: 433  Training loss = 1.8937  Validation loss = 1.2757  \n",
      "\n",
      "Fold: 6  Epoch: 434  Training loss = 1.8934  Validation loss = 1.2734  \n",
      "\n",
      "Fold: 6  Epoch: 435  Training loss = 1.8932  Validation loss = 1.2725  \n",
      "\n",
      "Fold: 6  Epoch: 436  Training loss = 1.8930  Validation loss = 1.2712  \n",
      "\n",
      "Fold: 6  Epoch: 437  Training loss = 1.8929  Validation loss = 1.2718  \n",
      "\n",
      "Fold: 6  Epoch: 438  Training loss = 1.8927  Validation loss = 1.2706  \n",
      "\n",
      "Fold: 6  Epoch: 439  Training loss = 1.8924  Validation loss = 1.2690  \n",
      "\n",
      "Fold: 6  Epoch: 440  Training loss = 1.8922  Validation loss = 1.2679  \n",
      "\n",
      "Fold: 6  Epoch: 441  Training loss = 1.8920  Validation loss = 1.2672  \n",
      "\n",
      "Fold: 6  Epoch: 442  Training loss = 1.8918  Validation loss = 1.2661  \n",
      "\n",
      "Fold: 6  Epoch: 443  Training loss = 1.8916  Validation loss = 1.2660  \n",
      "\n",
      "Fold: 6  Epoch: 444  Training loss = 1.8914  Validation loss = 1.2651  \n",
      "\n",
      "Fold: 6  Epoch: 445  Training loss = 1.8913  Validation loss = 1.2651  \n",
      "\n",
      "Fold: 6  Epoch: 446  Training loss = 1.8911  Validation loss = 1.2641  \n",
      "\n",
      "Fold: 6  Epoch: 447  Training loss = 1.8908  Validation loss = 1.2623  \n",
      "\n",
      "Fold: 6  Epoch: 448  Training loss = 1.8907  Validation loss = 1.2626  \n",
      "\n",
      "Fold: 6  Epoch: 449  Training loss = 1.8905  Validation loss = 1.2616  \n",
      "\n",
      "Fold: 6  Epoch: 450  Training loss = 1.8904  Validation loss = 1.2625  \n",
      "\n",
      "Fold: 6  Epoch: 451  Training loss = 1.8903  Validation loss = 1.2618  \n",
      "\n",
      "Fold: 6  Epoch: 452  Training loss = 1.8901  Validation loss = 1.2617  \n",
      "\n",
      "Fold: 6  Epoch: 453  Training loss = 1.8900  Validation loss = 1.2619  \n",
      "\n",
      "Fold: 6  Epoch: 454  Training loss = 1.8898  Validation loss = 1.2613  \n",
      "\n",
      "Fold: 6  Epoch: 455  Training loss = 1.8896  Validation loss = 1.2602  \n",
      "\n",
      "Fold: 6  Epoch: 456  Training loss = 1.8893  Validation loss = 1.2581  \n",
      "\n",
      "Fold: 6  Epoch: 457  Training loss = 1.8893  Validation loss = 1.2602  \n",
      "\n",
      "Fold: 6  Epoch: 458  Training loss = 1.8891  Validation loss = 1.2594  \n",
      "\n",
      "Fold: 6  Epoch: 459  Training loss = 1.8888  Validation loss = 1.2574  \n",
      "\n",
      "Fold: 6  Epoch: 460  Training loss = 1.8886  Validation loss = 1.2565  \n",
      "\n",
      "Fold: 6  Epoch: 461  Training loss = 1.8884  Validation loss = 1.2554  \n",
      "\n",
      "Fold: 6  Epoch: 462  Training loss = 1.8883  Validation loss = 1.2560  \n",
      "\n",
      "Fold: 6  Epoch: 463  Training loss = 1.8883  Validation loss = 1.2564  \n",
      "\n",
      "Fold: 6  Epoch: 464  Training loss = 1.8880  Validation loss = 1.2548  \n",
      "\n",
      "Fold: 6  Epoch: 465  Training loss = 1.8878  Validation loss = 1.2531  \n",
      "\n",
      "Fold: 6  Epoch: 466  Training loss = 1.8876  Validation loss = 1.2527  \n",
      "\n",
      "Fold: 6  Epoch: 467  Training loss = 1.8873  Validation loss = 1.2507  \n",
      "\n",
      "Fold: 6  Epoch: 468  Training loss = 1.8870  Validation loss = 1.2487  \n",
      "\n",
      "Fold: 6  Epoch: 469  Training loss = 1.8869  Validation loss = 1.2483  \n",
      "\n",
      "Fold: 6  Epoch: 470  Training loss = 1.8866  Validation loss = 1.2469  \n",
      "\n",
      "Fold: 6  Epoch: 471  Training loss = 1.8865  Validation loss = 1.2466  \n",
      "\n",
      "Fold: 6  Epoch: 472  Training loss = 1.8863  Validation loss = 1.2453  \n",
      "\n",
      "Fold: 6  Epoch: 473  Training loss = 1.8862  Validation loss = 1.2455  \n",
      "\n",
      "Fold: 6  Epoch: 474  Training loss = 1.8859  Validation loss = 1.2440  \n",
      "\n",
      "Fold: 6  Epoch: 475  Training loss = 1.8856  Validation loss = 1.2419  \n",
      "\n",
      "Fold: 6  Epoch: 476  Training loss = 1.8854  Validation loss = 1.2416  \n",
      "\n",
      "Fold: 6  Epoch: 477  Training loss = 1.8853  Validation loss = 1.2410  \n",
      "\n",
      "Fold: 6  Epoch: 478  Training loss = 1.8851  Validation loss = 1.2411  \n",
      "\n",
      "Fold: 6  Epoch: 479  Training loss = 1.8849  Validation loss = 1.2409  \n",
      "\n",
      "Fold: 6  Epoch: 480  Training loss = 1.8848  Validation loss = 1.2407  \n",
      "\n",
      "Fold: 6  Epoch: 481  Training loss = 1.8846  Validation loss = 1.2402  \n",
      "\n",
      "Fold: 6  Epoch: 482  Training loss = 1.8843  Validation loss = 1.2383  \n",
      "\n",
      "Fold: 6  Epoch: 483  Training loss = 1.8841  Validation loss = 1.2371  \n",
      "\n",
      "Fold: 6  Epoch: 484  Training loss = 1.8840  Validation loss = 1.2361  \n",
      "\n",
      "Fold: 6  Epoch: 485  Training loss = 1.8838  Validation loss = 1.2358  \n",
      "\n",
      "Fold: 6  Epoch: 486  Training loss = 1.8837  Validation loss = 1.2361  \n",
      "\n",
      "Fold: 6  Epoch: 487  Training loss = 1.8835  Validation loss = 1.2350  \n",
      "\n",
      "Fold: 6  Epoch: 488  Training loss = 1.8834  Validation loss = 1.2352  \n",
      "\n",
      "Fold: 6  Epoch: 489  Training loss = 1.8834  Validation loss = 1.2364  \n",
      "\n",
      "Fold: 6  Epoch: 490  Training loss = 1.8833  Validation loss = 1.2363  \n",
      "\n",
      "Fold: 6  Epoch: 491  Training loss = 1.8830  Validation loss = 1.2345  \n",
      "\n",
      "Fold: 6  Epoch: 492  Training loss = 1.8827  Validation loss = 1.2327  \n",
      "\n",
      "Fold: 6  Epoch: 493  Training loss = 1.8825  Validation loss = 1.2320  \n",
      "\n",
      "Fold: 6  Epoch: 494  Training loss = 1.8824  Validation loss = 1.2311  \n",
      "\n",
      "Fold: 6  Epoch: 495  Training loss = 1.8822  Validation loss = 1.2312  \n",
      "\n",
      "Fold: 6  Epoch: 496  Training loss = 1.8821  Validation loss = 1.2312  \n",
      "\n",
      "Fold: 6  Epoch: 497  Training loss = 1.8819  Validation loss = 1.2303  \n",
      "\n",
      "Fold: 6  Epoch: 498  Training loss = 1.8817  Validation loss = 1.2292  \n",
      "\n",
      "Fold: 6  Epoch: 499  Training loss = 1.8815  Validation loss = 1.2278  \n",
      "\n",
      "Fold: 6  Epoch: 500  Training loss = 1.8813  Validation loss = 1.2269  \n",
      "\n",
      "Check model:  Fold: 6  Epoch: 500  Training loss = 1.8813  Validation loss = 1.2269  \n",
      "\n",
      "Fold: 7  Epoch: 1  Training loss = 1.8433  Validation loss = 1.0610  \n",
      "\n",
      "Fold: 7  Epoch: 2  Training loss = 1.8428  Validation loss = 1.0591  \n",
      "\n",
      "Fold: 7  Epoch: 3  Training loss = 1.8425  Validation loss = 1.0580  \n",
      "\n",
      "Fold: 7  Epoch: 4  Training loss = 1.8422  Validation loss = 1.0576  \n",
      "\n",
      "Fold: 7  Epoch: 5  Training loss = 1.8420  Validation loss = 1.0568  \n",
      "\n",
      "Fold: 7  Epoch: 6  Training loss = 1.8418  Validation loss = 1.0564  \n",
      "\n",
      "Fold: 7  Epoch: 7  Training loss = 1.8411  Validation loss = 1.0529  \n",
      "\n",
      "Fold: 7  Epoch: 8  Training loss = 1.8406  Validation loss = 1.0513  \n",
      "\n",
      "Fold: 7  Epoch: 9  Training loss = 1.8402  Validation loss = 1.0500  \n",
      "\n",
      "Fold: 7  Epoch: 10  Training loss = 1.8397  Validation loss = 1.0481  \n",
      "\n",
      "Fold: 7  Epoch: 11  Training loss = 1.8395  Validation loss = 1.0476  \n",
      "\n",
      "Fold: 7  Epoch: 12  Training loss = 1.8390  Validation loss = 1.0452  \n",
      "\n",
      "Fold: 7  Epoch: 13  Training loss = 1.8385  Validation loss = 1.0433  \n",
      "\n",
      "Fold: 7  Epoch: 14  Training loss = 1.8382  Validation loss = 1.0425  \n",
      "\n",
      "Fold: 7  Epoch: 15  Training loss = 1.8378  Validation loss = 1.0410  \n",
      "\n",
      "Fold: 7  Epoch: 16  Training loss = 1.8374  Validation loss = 1.0391  \n",
      "\n",
      "Fold: 7  Epoch: 17  Training loss = 1.8368  Validation loss = 1.0369  \n",
      "\n",
      "Fold: 7  Epoch: 18  Training loss = 1.8367  Validation loss = 1.0369  \n",
      "\n",
      "Fold: 7  Epoch: 19  Training loss = 1.8363  Validation loss = 1.0350  \n",
      "\n",
      "Fold: 7  Epoch: 20  Training loss = 1.8363  Validation loss = 1.0356  \n",
      "\n",
      "Fold: 7  Epoch: 21  Training loss = 1.8359  Validation loss = 1.0340  \n",
      "\n",
      "Fold: 7  Epoch: 22  Training loss = 1.8355  Validation loss = 1.0323  \n",
      "\n",
      "Fold: 7  Epoch: 23  Training loss = 1.8353  Validation loss = 1.0320  \n",
      "\n",
      "Fold: 7  Epoch: 24  Training loss = 1.8349  Validation loss = 1.0303  \n",
      "\n",
      "Fold: 7  Epoch: 25  Training loss = 1.8344  Validation loss = 1.0281  \n",
      "\n",
      "Fold: 7  Epoch: 26  Training loss = 1.8340  Validation loss = 1.0263  \n",
      "\n",
      "Fold: 7  Epoch: 27  Training loss = 1.8336  Validation loss = 1.0254  \n",
      "\n",
      "Fold: 7  Epoch: 28  Training loss = 1.8333  Validation loss = 1.0237  \n",
      "\n",
      "Fold: 7  Epoch: 29  Training loss = 1.8330  Validation loss = 1.0225  \n",
      "\n",
      "Fold: 7  Epoch: 30  Training loss = 1.8326  Validation loss = 1.0208  \n",
      "\n",
      "Fold: 7  Epoch: 31  Training loss = 1.8323  Validation loss = 1.0203  \n",
      "\n",
      "Fold: 7  Epoch: 32  Training loss = 1.8319  Validation loss = 1.0186  \n",
      "\n",
      "Fold: 7  Epoch: 33  Training loss = 1.8314  Validation loss = 1.0165  \n",
      "\n",
      "Fold: 7  Epoch: 34  Training loss = 1.8310  Validation loss = 1.0147  \n",
      "\n",
      "Fold: 7  Epoch: 35  Training loss = 1.8308  Validation loss = 1.0140  \n",
      "\n",
      "Fold: 7  Epoch: 36  Training loss = 1.8304  Validation loss = 1.0127  \n",
      "\n",
      "Fold: 7  Epoch: 37  Training loss = 1.8302  Validation loss = 1.0123  \n",
      "\n",
      "Fold: 7  Epoch: 38  Training loss = 1.8298  Validation loss = 1.0111  \n",
      "\n",
      "Fold: 7  Epoch: 39  Training loss = 1.8296  Validation loss = 1.0108  \n",
      "\n",
      "Fold: 7  Epoch: 40  Training loss = 1.8293  Validation loss = 1.0094  \n",
      "\n",
      "Fold: 7  Epoch: 41  Training loss = 1.8290  Validation loss = 1.0086  \n",
      "\n",
      "Fold: 7  Epoch: 42  Training loss = 1.8286  Validation loss = 1.0069  \n",
      "\n",
      "Fold: 7  Epoch: 43  Training loss = 1.8285  Validation loss = 1.0068  \n",
      "\n",
      "Fold: 7  Epoch: 44  Training loss = 1.8281  Validation loss = 1.0050  \n",
      "\n",
      "Fold: 7  Epoch: 45  Training loss = 1.8277  Validation loss = 1.0035  \n",
      "\n",
      "Fold: 7  Epoch: 46  Training loss = 1.8274  Validation loss = 1.0023  \n",
      "\n",
      "Fold: 7  Epoch: 47  Training loss = 1.8269  Validation loss = 1.0004  \n",
      "\n",
      "Fold: 7  Epoch: 48  Training loss = 1.8267  Validation loss = 0.9996  \n",
      "\n",
      "Fold: 7  Epoch: 49  Training loss = 1.8264  Validation loss = 0.9987  \n",
      "\n",
      "Fold: 7  Epoch: 50  Training loss = 1.8260  Validation loss = 0.9968  \n",
      "\n",
      "Fold: 7  Epoch: 51  Training loss = 1.8256  Validation loss = 0.9953  \n",
      "\n",
      "Fold: 7  Epoch: 52  Training loss = 1.8254  Validation loss = 0.9946  \n",
      "\n",
      "Fold: 7  Epoch: 53  Training loss = 1.8249  Validation loss = 0.9926  \n",
      "\n",
      "Fold: 7  Epoch: 54  Training loss = 1.8246  Validation loss = 0.9918  \n",
      "\n",
      "Fold: 7  Epoch: 55  Training loss = 1.8243  Validation loss = 0.9910  \n",
      "\n",
      "Fold: 7  Epoch: 56  Training loss = 1.8237  Validation loss = 0.9883  \n",
      "\n",
      "Fold: 7  Epoch: 57  Training loss = 1.8237  Validation loss = 0.9884  \n",
      "\n",
      "Fold: 7  Epoch: 58  Training loss = 1.8234  Validation loss = 0.9876  \n",
      "\n",
      "Fold: 7  Epoch: 59  Training loss = 1.8231  Validation loss = 0.9866  \n",
      "\n",
      "Fold: 7  Epoch: 60  Training loss = 1.8229  Validation loss = 0.9859  \n",
      "\n",
      "Fold: 7  Epoch: 61  Training loss = 1.8225  Validation loss = 0.9844  \n",
      "\n",
      "Fold: 7  Epoch: 62  Training loss = 1.8220  Validation loss = 0.9822  \n",
      "\n",
      "Fold: 7  Epoch: 63  Training loss = 1.8216  Validation loss = 0.9811  \n",
      "\n",
      "Fold: 7  Epoch: 64  Training loss = 1.8211  Validation loss = 0.9784  \n",
      "\n",
      "Fold: 7  Epoch: 65  Training loss = 1.8209  Validation loss = 0.9784  \n",
      "\n",
      "Fold: 7  Epoch: 66  Training loss = 1.8205  Validation loss = 0.9765  \n",
      "\n",
      "Fold: 7  Epoch: 67  Training loss = 1.8201  Validation loss = 0.9748  \n",
      "\n",
      "Fold: 7  Epoch: 68  Training loss = 1.8198  Validation loss = 0.9731  \n",
      "\n",
      "Fold: 7  Epoch: 69  Training loss = 1.8194  Validation loss = 0.9713  \n",
      "\n",
      "Fold: 7  Epoch: 70  Training loss = 1.8187  Validation loss = 0.9682  \n",
      "\n",
      "Fold: 7  Epoch: 71  Training loss = 1.8184  Validation loss = 0.9664  \n",
      "\n",
      "Fold: 7  Epoch: 72  Training loss = 1.8181  Validation loss = 0.9658  \n",
      "\n",
      "Fold: 7  Epoch: 73  Training loss = 1.8180  Validation loss = 0.9662  \n",
      "\n",
      "Fold: 7  Epoch: 74  Training loss = 1.8177  Validation loss = 0.9644  \n",
      "\n",
      "Fold: 7  Epoch: 75  Training loss = 1.8174  Validation loss = 0.9631  \n",
      "\n",
      "Fold: 7  Epoch: 76  Training loss = 1.8171  Validation loss = 0.9618  \n",
      "\n",
      "Fold: 7  Epoch: 77  Training loss = 1.8168  Validation loss = 0.9608  \n",
      "\n",
      "Fold: 7  Epoch: 78  Training loss = 1.8165  Validation loss = 0.9592  \n",
      "\n",
      "Fold: 7  Epoch: 79  Training loss = 1.8162  Validation loss = 0.9579  \n",
      "\n",
      "Fold: 7  Epoch: 80  Training loss = 1.8160  Validation loss = 0.9582  \n",
      "\n",
      "Fold: 7  Epoch: 81  Training loss = 1.8157  Validation loss = 0.9563  \n",
      "\n",
      "Fold: 7  Epoch: 82  Training loss = 1.8153  Validation loss = 0.9550  \n",
      "\n",
      "Fold: 7  Epoch: 83  Training loss = 1.8151  Validation loss = 0.9544  \n",
      "\n",
      "Fold: 7  Epoch: 84  Training loss = 1.8147  Validation loss = 0.9528  \n",
      "\n",
      "Fold: 7  Epoch: 85  Training loss = 1.8144  Validation loss = 0.9515  \n",
      "\n",
      "Fold: 7  Epoch: 86  Training loss = 1.8142  Validation loss = 0.9511  \n",
      "\n",
      "Fold: 7  Epoch: 87  Training loss = 1.8139  Validation loss = 0.9498  \n",
      "\n",
      "Fold: 7  Epoch: 88  Training loss = 1.8137  Validation loss = 0.9495  \n",
      "\n",
      "Fold: 7  Epoch: 89  Training loss = 1.8135  Validation loss = 0.9487  \n",
      "\n",
      "Fold: 7  Epoch: 90  Training loss = 1.8131  Validation loss = 0.9472  \n",
      "\n",
      "Fold: 7  Epoch: 91  Training loss = 1.8128  Validation loss = 0.9455  \n",
      "\n",
      "Fold: 7  Epoch: 92  Training loss = 1.8126  Validation loss = 0.9451  \n",
      "\n",
      "Fold: 7  Epoch: 93  Training loss = 1.8124  Validation loss = 0.9445  \n",
      "\n",
      "Fold: 7  Epoch: 94  Training loss = 1.8120  Validation loss = 0.9433  \n",
      "\n",
      "Fold: 7  Epoch: 95  Training loss = 1.8118  Validation loss = 0.9426  \n",
      "\n",
      "Fold: 7  Epoch: 96  Training loss = 1.8114  Validation loss = 0.9409  \n",
      "\n",
      "Fold: 7  Epoch: 97  Training loss = 1.8111  Validation loss = 0.9398  \n",
      "\n",
      "Fold: 7  Epoch: 98  Training loss = 1.8108  Validation loss = 0.9388  \n",
      "\n",
      "Fold: 7  Epoch: 99  Training loss = 1.8106  Validation loss = 0.9378  \n",
      "\n",
      "Fold: 7  Epoch: 100  Training loss = 1.8102  Validation loss = 0.9363  \n",
      "\n",
      "Fold: 7  Epoch: 101  Training loss = 1.8099  Validation loss = 0.9350  \n",
      "\n",
      "Fold: 7  Epoch: 102  Training loss = 1.8098  Validation loss = 0.9354  \n",
      "\n",
      "Fold: 7  Epoch: 103  Training loss = 1.8096  Validation loss = 0.9352  \n",
      "\n",
      "Fold: 7  Epoch: 104  Training loss = 1.8091  Validation loss = 0.9330  \n",
      "\n",
      "Fold: 7  Epoch: 105  Training loss = 1.8089  Validation loss = 0.9323  \n",
      "\n",
      "Fold: 7  Epoch: 106  Training loss = 1.8086  Validation loss = 0.9313  \n",
      "\n",
      "Fold: 7  Epoch: 107  Training loss = 1.8083  Validation loss = 0.9298  \n",
      "\n",
      "Fold: 7  Epoch: 108  Training loss = 1.8080  Validation loss = 0.9290  \n",
      "\n",
      "Fold: 7  Epoch: 109  Training loss = 1.8078  Validation loss = 0.9283  \n",
      "\n",
      "Fold: 7  Epoch: 110  Training loss = 1.8075  Validation loss = 0.9269  \n",
      "\n",
      "Fold: 7  Epoch: 111  Training loss = 1.8072  Validation loss = 0.9260  \n",
      "\n",
      "Fold: 7  Epoch: 112  Training loss = 1.8070  Validation loss = 0.9254  \n",
      "\n",
      "Fold: 7  Epoch: 113  Training loss = 1.8067  Validation loss = 0.9242  \n",
      "\n",
      "Fold: 7  Epoch: 114  Training loss = 1.8064  Validation loss = 0.9232  \n",
      "\n",
      "Fold: 7  Epoch: 115  Training loss = 1.8063  Validation loss = 0.9234  \n",
      "\n",
      "Fold: 7  Epoch: 116  Training loss = 1.8060  Validation loss = 0.9222  \n",
      "\n",
      "Fold: 7  Epoch: 117  Training loss = 1.8057  Validation loss = 0.9209  \n",
      "\n",
      "Fold: 7  Epoch: 118  Training loss = 1.8055  Validation loss = 0.9207  \n",
      "\n",
      "Fold: 7  Epoch: 119  Training loss = 1.8054  Validation loss = 0.9208  \n",
      "\n",
      "Fold: 7  Epoch: 120  Training loss = 1.8052  Validation loss = 0.9205  \n",
      "\n",
      "Fold: 7  Epoch: 121  Training loss = 1.8049  Validation loss = 0.9202  \n",
      "\n",
      "Fold: 7  Epoch: 122  Training loss = 1.8048  Validation loss = 0.9204  \n",
      "\n",
      "Fold: 7  Epoch: 123  Training loss = 1.8047  Validation loss = 0.9203  \n",
      "\n",
      "Fold: 7  Epoch: 124  Training loss = 1.8043  Validation loss = 0.9186  \n",
      "\n",
      "Fold: 7  Epoch: 125  Training loss = 1.8042  Validation loss = 0.9193  \n",
      "\n",
      "Fold: 7  Epoch: 126  Training loss = 1.8041  Validation loss = 0.9195  \n",
      "\n",
      "Fold: 7  Epoch: 127  Training loss = 1.8038  Validation loss = 0.9186  \n",
      "\n",
      "Fold: 7  Epoch: 128  Training loss = 1.8035  Validation loss = 0.9173  \n",
      "\n",
      "Fold: 7  Epoch: 129  Training loss = 1.8033  Validation loss = 0.9169  \n",
      "\n",
      "Fold: 7  Epoch: 130  Training loss = 1.8031  Validation loss = 0.9158  \n",
      "\n",
      "Fold: 7  Epoch: 131  Training loss = 1.8028  Validation loss = 0.9150  \n",
      "\n",
      "Fold: 7  Epoch: 132  Training loss = 1.8025  Validation loss = 0.9132  \n",
      "\n",
      "Fold: 7  Epoch: 133  Training loss = 1.8023  Validation loss = 0.9126  \n",
      "\n",
      "Fold: 7  Epoch: 134  Training loss = 1.8021  Validation loss = 0.9114  \n",
      "\n",
      "Fold: 7  Epoch: 135  Training loss = 1.8017  Validation loss = 0.9093  \n",
      "\n",
      "Fold: 7  Epoch: 136  Training loss = 1.8014  Validation loss = 0.9085  \n",
      "\n",
      "Fold: 7  Epoch: 137  Training loss = 1.8011  Validation loss = 0.9074  \n",
      "\n",
      "Fold: 7  Epoch: 138  Training loss = 1.8010  Validation loss = 0.9076  \n",
      "\n",
      "Fold: 7  Epoch: 139  Training loss = 1.8007  Validation loss = 0.9064  \n",
      "\n",
      "Fold: 7  Epoch: 140  Training loss = 1.8005  Validation loss = 0.9059  \n",
      "\n",
      "Fold: 7  Epoch: 141  Training loss = 1.8003  Validation loss = 0.9052  \n",
      "\n",
      "Fold: 7  Epoch: 142  Training loss = 1.7999  Validation loss = 0.9032  \n",
      "\n",
      "Fold: 7  Epoch: 143  Training loss = 1.7995  Validation loss = 0.9017  \n",
      "\n",
      "Fold: 7  Epoch: 144  Training loss = 1.7994  Validation loss = 0.9015  \n",
      "\n",
      "Fold: 7  Epoch: 145  Training loss = 1.7992  Validation loss = 0.9011  \n",
      "\n",
      "Fold: 7  Epoch: 146  Training loss = 1.7990  Validation loss = 0.9002  \n",
      "\n",
      "Fold: 7  Epoch: 147  Training loss = 1.7987  Validation loss = 0.8991  \n",
      "\n",
      "Fold: 7  Epoch: 148  Training loss = 1.7984  Validation loss = 0.8979  \n",
      "\n",
      "Fold: 7  Epoch: 149  Training loss = 1.7982  Validation loss = 0.8971  \n",
      "\n",
      "Fold: 7  Epoch: 150  Training loss = 1.7980  Validation loss = 0.8964  \n",
      "\n",
      "Fold: 7  Epoch: 151  Training loss = 1.7977  Validation loss = 0.8950  \n",
      "\n",
      "Fold: 7  Epoch: 152  Training loss = 1.7974  Validation loss = 0.8940  \n",
      "\n",
      "Fold: 7  Epoch: 153  Training loss = 1.7971  Validation loss = 0.8935  \n",
      "\n",
      "Fold: 7  Epoch: 154  Training loss = 1.7968  Validation loss = 0.8919  \n",
      "\n",
      "Fold: 7  Epoch: 155  Training loss = 1.7965  Validation loss = 0.8908  \n",
      "\n",
      "Fold: 7  Epoch: 156  Training loss = 1.7963  Validation loss = 0.8902  \n",
      "\n",
      "Fold: 7  Epoch: 157  Training loss = 1.7961  Validation loss = 0.8895  \n",
      "\n",
      "Fold: 7  Epoch: 158  Training loss = 1.7959  Validation loss = 0.8893  \n",
      "\n",
      "Fold: 7  Epoch: 159  Training loss = 1.7957  Validation loss = 0.8883  \n",
      "\n",
      "Fold: 7  Epoch: 160  Training loss = 1.7955  Validation loss = 0.8883  \n",
      "\n",
      "Fold: 7  Epoch: 161  Training loss = 1.7953  Validation loss = 0.8879  \n",
      "\n",
      "Fold: 7  Epoch: 162  Training loss = 1.7951  Validation loss = 0.8875  \n",
      "\n",
      "Fold: 7  Epoch: 163  Training loss = 1.7948  Validation loss = 0.8862  \n",
      "\n",
      "Fold: 7  Epoch: 164  Training loss = 1.7945  Validation loss = 0.8846  \n",
      "\n",
      "Fold: 7  Epoch: 165  Training loss = 1.7943  Validation loss = 0.8840  \n",
      "\n",
      "Fold: 7  Epoch: 166  Training loss = 1.7941  Validation loss = 0.8839  \n",
      "\n",
      "Fold: 7  Epoch: 167  Training loss = 1.7938  Validation loss = 0.8829  \n",
      "\n",
      "Fold: 7  Epoch: 168  Training loss = 1.7936  Validation loss = 0.8823  \n",
      "\n",
      "Fold: 7  Epoch: 169  Training loss = 1.7935  Validation loss = 0.8821  \n",
      "\n",
      "Fold: 7  Epoch: 170  Training loss = 1.7933  Validation loss = 0.8819  \n",
      "\n",
      "Fold: 7  Epoch: 171  Training loss = 1.7931  Validation loss = 0.8819  \n",
      "\n",
      "Fold: 7  Epoch: 172  Training loss = 1.7928  Validation loss = 0.8808  \n",
      "\n",
      "Fold: 7  Epoch: 173  Training loss = 1.7925  Validation loss = 0.8796  \n",
      "\n",
      "Fold: 7  Epoch: 174  Training loss = 1.7922  Validation loss = 0.8780  \n",
      "\n",
      "Fold: 7  Epoch: 175  Training loss = 1.7921  Validation loss = 0.8777  \n",
      "\n",
      "Fold: 7  Epoch: 176  Training loss = 1.7919  Validation loss = 0.8767  \n",
      "\n",
      "Fold: 7  Epoch: 177  Training loss = 1.7916  Validation loss = 0.8757  \n",
      "\n",
      "Fold: 7  Epoch: 178  Training loss = 1.7914  Validation loss = 0.8748  \n",
      "\n",
      "Fold: 7  Epoch: 179  Training loss = 1.7912  Validation loss = 0.8743  \n",
      "\n",
      "Fold: 7  Epoch: 180  Training loss = 1.7909  Validation loss = 0.8734  \n",
      "\n",
      "Fold: 7  Epoch: 181  Training loss = 1.7906  Validation loss = 0.8716  \n",
      "\n",
      "Fold: 7  Epoch: 182  Training loss = 1.7903  Validation loss = 0.8704  \n",
      "\n",
      "Fold: 7  Epoch: 183  Training loss = 1.7900  Validation loss = 0.8694  \n",
      "\n",
      "Fold: 7  Epoch: 184  Training loss = 1.7899  Validation loss = 0.8694  \n",
      "\n",
      "Fold: 7  Epoch: 185  Training loss = 1.7896  Validation loss = 0.8681  \n",
      "\n",
      "Fold: 7  Epoch: 186  Training loss = 1.7893  Validation loss = 0.8668  \n",
      "\n",
      "Fold: 7  Epoch: 187  Training loss = 1.7889  Validation loss = 0.8652  \n",
      "\n",
      "Fold: 7  Epoch: 188  Training loss = 1.7887  Validation loss = 0.8638  \n",
      "\n",
      "Fold: 7  Epoch: 189  Training loss = 1.7884  Validation loss = 0.8623  \n",
      "\n",
      "Fold: 7  Epoch: 190  Training loss = 1.7881  Validation loss = 0.8613  \n",
      "\n",
      "Fold: 7  Epoch: 191  Training loss = 1.7879  Validation loss = 0.8609  \n",
      "\n",
      "Fold: 7  Epoch: 192  Training loss = 1.7877  Validation loss = 0.8598  \n",
      "\n",
      "Fold: 7  Epoch: 193  Training loss = 1.7875  Validation loss = 0.8595  \n",
      "\n",
      "Fold: 7  Epoch: 194  Training loss = 1.7871  Validation loss = 0.8578  \n",
      "\n",
      "Fold: 7  Epoch: 195  Training loss = 1.7869  Validation loss = 0.8575  \n",
      "\n",
      "Fold: 7  Epoch: 196  Training loss = 1.7867  Validation loss = 0.8564  \n",
      "\n",
      "Fold: 7  Epoch: 197  Training loss = 1.7866  Validation loss = 0.8571  \n",
      "\n",
      "Fold: 7  Epoch: 198  Training loss = 1.7865  Validation loss = 0.8572  \n",
      "\n",
      "Fold: 7  Epoch: 199  Training loss = 1.7862  Validation loss = 0.8560  \n",
      "\n",
      "Fold: 7  Epoch: 200  Training loss = 1.7861  Validation loss = 0.8559  \n",
      "\n",
      "Fold: 7  Epoch: 201  Training loss = 1.7859  Validation loss = 0.8559  \n",
      "\n",
      "Fold: 7  Epoch: 202  Training loss = 1.7858  Validation loss = 0.8559  \n",
      "\n",
      "Fold: 7  Epoch: 203  Training loss = 1.7856  Validation loss = 0.8553  \n",
      "\n",
      "Fold: 7  Epoch: 204  Training loss = 1.7854  Validation loss = 0.8545  \n",
      "\n",
      "Fold: 7  Epoch: 205  Training loss = 1.7850  Validation loss = 0.8526  \n",
      "\n",
      "Fold: 7  Epoch: 206  Training loss = 1.7848  Validation loss = 0.8523  \n",
      "\n",
      "Fold: 7  Epoch: 207  Training loss = 1.7846  Validation loss = 0.8510  \n",
      "\n",
      "Fold: 7  Epoch: 208  Training loss = 1.7845  Validation loss = 0.8514  \n",
      "\n",
      "Fold: 7  Epoch: 209  Training loss = 1.7844  Validation loss = 0.8522  \n",
      "\n",
      "Fold: 7  Epoch: 210  Training loss = 1.7840  Validation loss = 0.8506  \n",
      "\n",
      "Fold: 7  Epoch: 211  Training loss = 1.7838  Validation loss = 0.8499  \n",
      "\n",
      "Fold: 7  Epoch: 212  Training loss = 1.7836  Validation loss = 0.8491  \n",
      "\n",
      "Fold: 7  Epoch: 213  Training loss = 1.7835  Validation loss = 0.8491  \n",
      "\n",
      "Fold: 7  Epoch: 214  Training loss = 1.7832  Validation loss = 0.8480  \n",
      "\n",
      "Fold: 7  Epoch: 215  Training loss = 1.7830  Validation loss = 0.8475  \n",
      "\n",
      "Fold: 7  Epoch: 216  Training loss = 1.7829  Validation loss = 0.8475  \n",
      "\n",
      "Fold: 7  Epoch: 217  Training loss = 1.7826  Validation loss = 0.8465  \n",
      "\n",
      "Fold: 7  Epoch: 218  Training loss = 1.7825  Validation loss = 0.8463  \n",
      "\n",
      "Fold: 7  Epoch: 219  Training loss = 1.7822  Validation loss = 0.8454  \n",
      "\n",
      "Fold: 7  Epoch: 220  Training loss = 1.7821  Validation loss = 0.8455  \n",
      "\n",
      "Fold: 7  Epoch: 221  Training loss = 1.7818  Validation loss = 0.8444  \n",
      "\n",
      "Fold: 7  Epoch: 222  Training loss = 1.7817  Validation loss = 0.8438  \n",
      "\n",
      "Fold: 7  Epoch: 223  Training loss = 1.7814  Validation loss = 0.8426  \n",
      "\n",
      "Fold: 7  Epoch: 224  Training loss = 1.7811  Validation loss = 0.8417  \n",
      "\n",
      "Fold: 7  Epoch: 225  Training loss = 1.7810  Validation loss = 0.8426  \n",
      "\n",
      "Fold: 7  Epoch: 226  Training loss = 1.7809  Validation loss = 0.8421  \n",
      "\n",
      "Fold: 7  Epoch: 227  Training loss = 1.7806  Validation loss = 0.8414  \n",
      "\n",
      "Fold: 7  Epoch: 228  Training loss = 1.7805  Validation loss = 0.8420  \n",
      "\n",
      "Fold: 7  Epoch: 229  Training loss = 1.7804  Validation loss = 0.8428  \n",
      "\n",
      "Fold: 7  Epoch: 230  Training loss = 1.7803  Validation loss = 0.8428  \n",
      "\n",
      "Fold: 7  Epoch: 231  Training loss = 1.7801  Validation loss = 0.8416  \n",
      "\n",
      "Fold: 7  Epoch: 232  Training loss = 1.7798  Validation loss = 0.8404  \n",
      "\n",
      "Fold: 7  Epoch: 233  Training loss = 1.7795  Validation loss = 0.8389  \n",
      "\n",
      "Fold: 7  Epoch: 234  Training loss = 1.7793  Validation loss = 0.8382  \n",
      "\n",
      "Fold: 7  Epoch: 235  Training loss = 1.7792  Validation loss = 0.8384  \n",
      "\n",
      "Fold: 7  Epoch: 236  Training loss = 1.7791  Validation loss = 0.8385  \n",
      "\n",
      "Fold: 7  Epoch: 237  Training loss = 1.7789  Validation loss = 0.8377  \n",
      "\n",
      "Fold: 7  Epoch: 238  Training loss = 1.7786  Validation loss = 0.8362  \n",
      "\n",
      "Fold: 7  Epoch: 239  Training loss = 1.7785  Validation loss = 0.8365  \n",
      "\n",
      "Fold: 7  Epoch: 240  Training loss = 1.7782  Validation loss = 0.8354  \n",
      "\n",
      "Fold: 7  Epoch: 241  Training loss = 1.7779  Validation loss = 0.8334  \n",
      "\n",
      "Fold: 7  Epoch: 242  Training loss = 1.7776  Validation loss = 0.8324  \n",
      "\n",
      "Fold: 7  Epoch: 243  Training loss = 1.7774  Validation loss = 0.8314  \n",
      "\n",
      "Fold: 7  Epoch: 244  Training loss = 1.7771  Validation loss = 0.8305  \n",
      "\n",
      "Fold: 7  Epoch: 245  Training loss = 1.7770  Validation loss = 0.8297  \n",
      "\n",
      "Fold: 7  Epoch: 246  Training loss = 1.7768  Validation loss = 0.8287  \n",
      "\n",
      "Fold: 7  Epoch: 247  Training loss = 1.7766  Validation loss = 0.8286  \n",
      "\n",
      "Fold: 7  Epoch: 248  Training loss = 1.7765  Validation loss = 0.8281  \n",
      "\n",
      "Fold: 7  Epoch: 249  Training loss = 1.7763  Validation loss = 0.8275  \n",
      "\n",
      "Fold: 7  Epoch: 250  Training loss = 1.7761  Validation loss = 0.8275  \n",
      "\n",
      "Fold: 7  Epoch: 251  Training loss = 1.7760  Validation loss = 0.8274  \n",
      "\n",
      "Fold: 7  Epoch: 252  Training loss = 1.7757  Validation loss = 0.8262  \n",
      "\n",
      "Fold: 7  Epoch: 253  Training loss = 1.7756  Validation loss = 0.8262  \n",
      "\n",
      "Fold: 7  Epoch: 254  Training loss = 1.7755  Validation loss = 0.8266  \n",
      "\n",
      "Fold: 7  Epoch: 255  Training loss = 1.7751  Validation loss = 0.8249  \n",
      "\n",
      "Fold: 7  Epoch: 256  Training loss = 1.7750  Validation loss = 0.8245  \n",
      "\n",
      "Fold: 7  Epoch: 257  Training loss = 1.7748  Validation loss = 0.8249  \n",
      "\n",
      "Fold: 7  Epoch: 258  Training loss = 1.7746  Validation loss = 0.8235  \n",
      "\n",
      "Fold: 7  Epoch: 259  Training loss = 1.7744  Validation loss = 0.8231  \n",
      "\n",
      "Fold: 7  Epoch: 260  Training loss = 1.7742  Validation loss = 0.8233  \n",
      "\n",
      "Fold: 7  Epoch: 261  Training loss = 1.7740  Validation loss = 0.8225  \n",
      "\n",
      "Fold: 7  Epoch: 262  Training loss = 1.7739  Validation loss = 0.8223  \n",
      "\n",
      "Fold: 7  Epoch: 263  Training loss = 1.7738  Validation loss = 0.8228  \n",
      "\n",
      "Fold: 7  Epoch: 264  Training loss = 1.7736  Validation loss = 0.8223  \n",
      "\n",
      "Fold: 7  Epoch: 265  Training loss = 1.7734  Validation loss = 0.8222  \n",
      "\n",
      "Fold: 7  Epoch: 266  Training loss = 1.7731  Validation loss = 0.8207  \n",
      "\n",
      "Fold: 7  Epoch: 267  Training loss = 1.7730  Validation loss = 0.8206  \n",
      "\n",
      "Fold: 7  Epoch: 268  Training loss = 1.7730  Validation loss = 0.8216  \n",
      "\n",
      "Fold: 7  Epoch: 269  Training loss = 1.7728  Validation loss = 0.8212  \n",
      "\n",
      "Fold: 7  Epoch: 270  Training loss = 1.7727  Validation loss = 0.8217  \n",
      "\n",
      "Fold: 7  Epoch: 271  Training loss = 1.7725  Validation loss = 0.8209  \n",
      "\n",
      "Fold: 7  Epoch: 272  Training loss = 1.7724  Validation loss = 0.8214  \n",
      "\n",
      "Fold: 7  Epoch: 273  Training loss = 1.7723  Validation loss = 0.8206  \n",
      "\n",
      "Fold: 7  Epoch: 274  Training loss = 1.7719  Validation loss = 0.8186  \n",
      "\n",
      "Fold: 7  Epoch: 275  Training loss = 1.7717  Validation loss = 0.8180  \n",
      "\n",
      "Fold: 7  Epoch: 276  Training loss = 1.7716  Validation loss = 0.8175  \n",
      "\n",
      "Fold: 7  Epoch: 277  Training loss = 1.7714  Validation loss = 0.8165  \n",
      "\n",
      "Fold: 7  Epoch: 278  Training loss = 1.7711  Validation loss = 0.8151  \n",
      "\n",
      "Fold: 7  Epoch: 279  Training loss = 1.7709  Validation loss = 0.8149  \n",
      "\n",
      "Fold: 7  Epoch: 280  Training loss = 1.7707  Validation loss = 0.8142  \n",
      "\n",
      "Fold: 7  Epoch: 281  Training loss = 1.7706  Validation loss = 0.8149  \n",
      "\n",
      "Fold: 7  Epoch: 282  Training loss = 1.7704  Validation loss = 0.8136  \n",
      "\n",
      "Fold: 7  Epoch: 283  Training loss = 1.7702  Validation loss = 0.8126  \n",
      "\n",
      "Fold: 7  Epoch: 284  Training loss = 1.7701  Validation loss = 0.8130  \n",
      "\n",
      "Fold: 7  Epoch: 285  Training loss = 1.7699  Validation loss = 0.8128  \n",
      "\n",
      "Fold: 7  Epoch: 286  Training loss = 1.7697  Validation loss = 0.8122  \n",
      "\n",
      "Fold: 7  Epoch: 287  Training loss = 1.7696  Validation loss = 0.8117  \n",
      "\n",
      "Fold: 7  Epoch: 288  Training loss = 1.7694  Validation loss = 0.8109  \n",
      "\n",
      "Fold: 7  Epoch: 289  Training loss = 1.7692  Validation loss = 0.8107  \n",
      "\n",
      "Fold: 7  Epoch: 290  Training loss = 1.7690  Validation loss = 0.8102  \n",
      "\n",
      "Fold: 7  Epoch: 291  Training loss = 1.7689  Validation loss = 0.8100  \n",
      "\n",
      "Fold: 7  Epoch: 292  Training loss = 1.7687  Validation loss = 0.8095  \n",
      "\n",
      "Fold: 7  Epoch: 293  Training loss = 1.7684  Validation loss = 0.8084  \n",
      "\n",
      "Fold: 7  Epoch: 294  Training loss = 1.7683  Validation loss = 0.8082  \n",
      "\n",
      "Fold: 7  Epoch: 295  Training loss = 1.7682  Validation loss = 0.8087  \n",
      "\n",
      "Fold: 7  Epoch: 296  Training loss = 1.7680  Validation loss = 0.8078  \n",
      "\n",
      "Fold: 7  Epoch: 297  Training loss = 1.7678  Validation loss = 0.8068  \n",
      "\n",
      "Fold: 7  Epoch: 298  Training loss = 1.7676  Validation loss = 0.8064  \n",
      "\n",
      "Fold: 7  Epoch: 299  Training loss = 1.7676  Validation loss = 0.8070  \n",
      "\n",
      "Fold: 7  Epoch: 300  Training loss = 1.7673  Validation loss = 0.8055  \n",
      "\n",
      "Fold: 7  Epoch: 301  Training loss = 1.7670  Validation loss = 0.8042  \n",
      "\n",
      "Fold: 7  Epoch: 302  Training loss = 1.7669  Validation loss = 0.8036  \n",
      "\n",
      "Fold: 7  Epoch: 303  Training loss = 1.7667  Validation loss = 0.8025  \n",
      "\n",
      "Fold: 7  Epoch: 304  Training loss = 1.7665  Validation loss = 0.8018  \n",
      "\n",
      "Fold: 7  Epoch: 305  Training loss = 1.7663  Validation loss = 0.8017  \n",
      "\n",
      "Fold: 7  Epoch: 306  Training loss = 1.7662  Validation loss = 0.8018  \n",
      "\n",
      "Fold: 7  Epoch: 307  Training loss = 1.7660  Validation loss = 0.8015  \n",
      "\n",
      "Fold: 7  Epoch: 308  Training loss = 1.7658  Validation loss = 0.8004  \n",
      "\n",
      "Fold: 7  Epoch: 309  Training loss = 1.7656  Validation loss = 0.7990  \n",
      "\n",
      "Fold: 7  Epoch: 310  Training loss = 1.7653  Validation loss = 0.7977  \n",
      "\n",
      "Fold: 7  Epoch: 311  Training loss = 1.7651  Validation loss = 0.7966  \n",
      "\n",
      "Fold: 7  Epoch: 312  Training loss = 1.7649  Validation loss = 0.7960  \n",
      "\n",
      "Fold: 7  Epoch: 313  Training loss = 1.7646  Validation loss = 0.7948  \n",
      "\n",
      "Fold: 7  Epoch: 314  Training loss = 1.7644  Validation loss = 0.7946  \n",
      "\n",
      "Fold: 7  Epoch: 315  Training loss = 1.7643  Validation loss = 0.7943  \n",
      "\n",
      "Fold: 7  Epoch: 316  Training loss = 1.7642  Validation loss = 0.7945  \n",
      "\n",
      "Fold: 7  Epoch: 317  Training loss = 1.7639  Validation loss = 0.7938  \n",
      "\n",
      "Fold: 7  Epoch: 318  Training loss = 1.7638  Validation loss = 0.7940  \n",
      "\n",
      "Fold: 7  Epoch: 319  Training loss = 1.7637  Validation loss = 0.7934  \n",
      "\n",
      "Fold: 7  Epoch: 320  Training loss = 1.7636  Validation loss = 0.7940  \n",
      "\n",
      "Fold: 7  Epoch: 321  Training loss = 1.7634  Validation loss = 0.7936  \n",
      "\n",
      "Fold: 7  Epoch: 322  Training loss = 1.7631  Validation loss = 0.7928  \n",
      "\n",
      "Fold: 7  Epoch: 323  Training loss = 1.7630  Validation loss = 0.7926  \n",
      "\n",
      "Fold: 7  Epoch: 324  Training loss = 1.7628  Validation loss = 0.7917  \n",
      "\n",
      "Fold: 7  Epoch: 325  Training loss = 1.7625  Validation loss = 0.7901  \n",
      "\n",
      "Fold: 7  Epoch: 326  Training loss = 1.7624  Validation loss = 0.7906  \n",
      "\n",
      "Fold: 7  Epoch: 327  Training loss = 1.7621  Validation loss = 0.7885  \n",
      "\n",
      "Fold: 7  Epoch: 328  Training loss = 1.7620  Validation loss = 0.7888  \n",
      "\n",
      "Fold: 7  Epoch: 329  Training loss = 1.7618  Validation loss = 0.7879  \n",
      "\n",
      "Fold: 7  Epoch: 330  Training loss = 1.7617  Validation loss = 0.7884  \n",
      "\n",
      "Fold: 7  Epoch: 331  Training loss = 1.7615  Validation loss = 0.7868  \n",
      "\n",
      "Fold: 7  Epoch: 332  Training loss = 1.7613  Validation loss = 0.7868  \n",
      "\n",
      "Fold: 7  Epoch: 333  Training loss = 1.7611  Validation loss = 0.7855  \n",
      "\n",
      "Fold: 7  Epoch: 334  Training loss = 1.7609  Validation loss = 0.7848  \n",
      "\n",
      "Fold: 7  Epoch: 335  Training loss = 1.7607  Validation loss = 0.7843  \n",
      "\n",
      "Fold: 7  Epoch: 336  Training loss = 1.7605  Validation loss = 0.7838  \n",
      "\n",
      "Fold: 7  Epoch: 337  Training loss = 1.7603  Validation loss = 0.7829  \n",
      "\n",
      "Fold: 7  Epoch: 338  Training loss = 1.7603  Validation loss = 0.7838  \n",
      "\n",
      "Fold: 7  Epoch: 339  Training loss = 1.7602  Validation loss = 0.7836  \n",
      "\n",
      "Fold: 7  Epoch: 340  Training loss = 1.7600  Validation loss = 0.7828  \n",
      "\n",
      "Fold: 7  Epoch: 341  Training loss = 1.7598  Validation loss = 0.7828  \n",
      "\n",
      "Fold: 7  Epoch: 342  Training loss = 1.7595  Validation loss = 0.7814  \n",
      "\n",
      "Fold: 7  Epoch: 343  Training loss = 1.7594  Validation loss = 0.7820  \n",
      "\n",
      "Fold: 7  Epoch: 344  Training loss = 1.7592  Validation loss = 0.7817  \n",
      "\n",
      "Fold: 7  Epoch: 345  Training loss = 1.7591  Validation loss = 0.7821  \n",
      "\n",
      "Fold: 7  Epoch: 346  Training loss = 1.7590  Validation loss = 0.7818  \n",
      "\n",
      "Fold: 7  Epoch: 347  Training loss = 1.7587  Validation loss = 0.7805  \n",
      "\n",
      "Fold: 7  Epoch: 348  Training loss = 1.7587  Validation loss = 0.7815  \n",
      "\n",
      "Fold: 7  Epoch: 349  Training loss = 1.7585  Validation loss = 0.7805  \n",
      "\n",
      "Fold: 7  Epoch: 350  Training loss = 1.7582  Validation loss = 0.7802  \n",
      "\n",
      "Fold: 7  Epoch: 351  Training loss = 1.7580  Validation loss = 0.7797  \n",
      "\n",
      "Fold: 7  Epoch: 352  Training loss = 1.7578  Validation loss = 0.7786  \n",
      "\n",
      "Fold: 7  Epoch: 353  Training loss = 1.7576  Validation loss = 0.7783  \n",
      "\n",
      "Fold: 7  Epoch: 354  Training loss = 1.7575  Validation loss = 0.7778  \n",
      "\n",
      "Fold: 7  Epoch: 355  Training loss = 1.7573  Validation loss = 0.7779  \n",
      "\n",
      "Fold: 7  Epoch: 356  Training loss = 1.7571  Validation loss = 0.7766  \n",
      "\n",
      "Fold: 7  Epoch: 357  Training loss = 1.7569  Validation loss = 0.7745  \n",
      "\n",
      "Fold: 7  Epoch: 358  Training loss = 1.7568  Validation loss = 0.7751  \n",
      "\n",
      "Fold: 7  Epoch: 359  Training loss = 1.7565  Validation loss = 0.7739  \n",
      "\n",
      "Fold: 7  Epoch: 360  Training loss = 1.7563  Validation loss = 0.7733  \n",
      "\n",
      "Fold: 7  Epoch: 361  Training loss = 1.7563  Validation loss = 0.7739  \n",
      "\n",
      "Fold: 7  Epoch: 362  Training loss = 1.7560  Validation loss = 0.7725  \n",
      "\n",
      "Fold: 7  Epoch: 363  Training loss = 1.7560  Validation loss = 0.7731  \n",
      "\n",
      "Fold: 7  Epoch: 364  Training loss = 1.7558  Validation loss = 0.7721  \n",
      "\n",
      "Fold: 7  Epoch: 365  Training loss = 1.7557  Validation loss = 0.7724  \n",
      "\n",
      "Fold: 7  Epoch: 366  Training loss = 1.7555  Validation loss = 0.7727  \n",
      "\n",
      "Fold: 7  Epoch: 367  Training loss = 1.7553  Validation loss = 0.7719  \n",
      "\n",
      "Fold: 7  Epoch: 368  Training loss = 1.7551  Validation loss = 0.7709  \n",
      "\n",
      "Fold: 7  Epoch: 369  Training loss = 1.7550  Validation loss = 0.7719  \n",
      "\n",
      "Fold: 7  Epoch: 370  Training loss = 1.7549  Validation loss = 0.7712  \n",
      "\n",
      "Fold: 7  Epoch: 371  Training loss = 1.7547  Validation loss = 0.7702  \n",
      "\n",
      "Fold: 7  Epoch: 372  Training loss = 1.7545  Validation loss = 0.7693  \n",
      "\n",
      "Fold: 7  Epoch: 373  Training loss = 1.7543  Validation loss = 0.7685  \n",
      "\n",
      "Fold: 7  Epoch: 374  Training loss = 1.7541  Validation loss = 0.7674  \n",
      "\n",
      "Fold: 7  Epoch: 375  Training loss = 1.7539  Validation loss = 0.7670  \n",
      "\n",
      "Fold: 7  Epoch: 376  Training loss = 1.7537  Validation loss = 0.7668  \n",
      "\n",
      "Fold: 7  Epoch: 377  Training loss = 1.7535  Validation loss = 0.7659  \n",
      "\n",
      "Fold: 7  Epoch: 378  Training loss = 1.7533  Validation loss = 0.7658  \n",
      "\n",
      "Fold: 7  Epoch: 379  Training loss = 1.7531  Validation loss = 0.7652  \n",
      "\n",
      "Fold: 7  Epoch: 380  Training loss = 1.7529  Validation loss = 0.7645  \n",
      "\n",
      "Fold: 7  Epoch: 381  Training loss = 1.7527  Validation loss = 0.7637  \n",
      "\n",
      "Fold: 7  Epoch: 382  Training loss = 1.7526  Validation loss = 0.7633  \n",
      "\n",
      "Fold: 7  Epoch: 383  Training loss = 1.7524  Validation loss = 0.7624  \n",
      "\n",
      "Fold: 7  Epoch: 384  Training loss = 1.7522  Validation loss = 0.7623  \n",
      "\n",
      "Fold: 7  Epoch: 385  Training loss = 1.7520  Validation loss = 0.7610  \n",
      "\n",
      "Fold: 7  Epoch: 386  Training loss = 1.7518  Validation loss = 0.7605  \n",
      "\n",
      "Fold: 7  Epoch: 387  Training loss = 1.7517  Validation loss = 0.7602  \n",
      "\n",
      "Fold: 7  Epoch: 388  Training loss = 1.7515  Validation loss = 0.7599  \n",
      "\n",
      "Fold: 7  Epoch: 389  Training loss = 1.7513  Validation loss = 0.7586  \n",
      "\n",
      "Fold: 7  Epoch: 390  Training loss = 1.7512  Validation loss = 0.7585  \n",
      "\n",
      "Fold: 7  Epoch: 391  Training loss = 1.7511  Validation loss = 0.7588  \n",
      "\n",
      "Fold: 7  Epoch: 392  Training loss = 1.7508  Validation loss = 0.7577  \n",
      "\n",
      "Fold: 7  Epoch: 393  Training loss = 1.7507  Validation loss = 0.7576  \n",
      "\n",
      "Fold: 7  Epoch: 394  Training loss = 1.7505  Validation loss = 0.7572  \n",
      "\n",
      "Fold: 7  Epoch: 395  Training loss = 1.7504  Validation loss = 0.7578  \n",
      "\n",
      "Fold: 7  Epoch: 396  Training loss = 1.7502  Validation loss = 0.7577  \n",
      "\n",
      "Fold: 7  Epoch: 397  Training loss = 1.7499  Validation loss = 0.7567  \n",
      "\n",
      "Fold: 7  Epoch: 398  Training loss = 1.7498  Validation loss = 0.7575  \n",
      "\n",
      "Fold: 7  Epoch: 399  Training loss = 1.7496  Validation loss = 0.7561  \n",
      "\n",
      "Fold: 7  Epoch: 400  Training loss = 1.7495  Validation loss = 0.7562  \n",
      "\n",
      "Fold: 7  Epoch: 401  Training loss = 1.7493  Validation loss = 0.7555  \n",
      "\n",
      "Fold: 7  Epoch: 402  Training loss = 1.7490  Validation loss = 0.7535  \n",
      "\n",
      "Fold: 7  Epoch: 403  Training loss = 1.7488  Validation loss = 0.7534  \n",
      "\n",
      "Fold: 7  Epoch: 404  Training loss = 1.7486  Validation loss = 0.7531  \n",
      "\n",
      "Fold: 7  Epoch: 405  Training loss = 1.7484  Validation loss = 0.7523  \n",
      "\n",
      "Fold: 7  Epoch: 406  Training loss = 1.7482  Validation loss = 0.7513  \n",
      "\n",
      "Fold: 7  Epoch: 407  Training loss = 1.7480  Validation loss = 0.7506  \n",
      "\n",
      "Fold: 7  Epoch: 408  Training loss = 1.7478  Validation loss = 0.7505  \n",
      "\n",
      "Fold: 7  Epoch: 409  Training loss = 1.7477  Validation loss = 0.7502  \n",
      "\n",
      "Fold: 7  Epoch: 410  Training loss = 1.7475  Validation loss = 0.7487  \n",
      "\n",
      "Fold: 7  Epoch: 411  Training loss = 1.7472  Validation loss = 0.7485  \n",
      "\n",
      "Fold: 7  Epoch: 412  Training loss = 1.7472  Validation loss = 0.7498  \n",
      "\n",
      "Fold: 7  Epoch: 413  Training loss = 1.7469  Validation loss = 0.7481  \n",
      "\n",
      "Fold: 7  Epoch: 414  Training loss = 1.7468  Validation loss = 0.7480  \n",
      "\n",
      "Fold: 7  Epoch: 415  Training loss = 1.7467  Validation loss = 0.7482  \n",
      "\n",
      "Fold: 7  Epoch: 416  Training loss = 1.7464  Validation loss = 0.7471  \n",
      "\n",
      "Fold: 7  Epoch: 417  Training loss = 1.7462  Validation loss = 0.7465  \n",
      "\n",
      "Fold: 7  Epoch: 418  Training loss = 1.7460  Validation loss = 0.7454  \n",
      "\n",
      "Fold: 7  Epoch: 419  Training loss = 1.7458  Validation loss = 0.7447  \n",
      "\n",
      "Fold: 7  Epoch: 420  Training loss = 1.7456  Validation loss = 0.7445  \n",
      "\n",
      "Fold: 7  Epoch: 421  Training loss = 1.7454  Validation loss = 0.7438  \n",
      "\n",
      "Fold: 7  Epoch: 422  Training loss = 1.7453  Validation loss = 0.7436  \n",
      "\n",
      "Fold: 7  Epoch: 423  Training loss = 1.7452  Validation loss = 0.7442  \n",
      "\n",
      "Fold: 7  Epoch: 424  Training loss = 1.7451  Validation loss = 0.7443  \n",
      "\n",
      "Fold: 7  Epoch: 425  Training loss = 1.7448  Validation loss = 0.7435  \n",
      "\n",
      "Fold: 7  Epoch: 426  Training loss = 1.7446  Validation loss = 0.7427  \n",
      "\n",
      "Fold: 7  Epoch: 427  Training loss = 1.7445  Validation loss = 0.7429  \n",
      "\n",
      "Fold: 7  Epoch: 428  Training loss = 1.7443  Validation loss = 0.7427  \n",
      "\n",
      "Fold: 7  Epoch: 429  Training loss = 1.7441  Validation loss = 0.7418  \n",
      "\n",
      "Fold: 7  Epoch: 430  Training loss = 1.7439  Validation loss = 0.7417  \n",
      "\n",
      "Fold: 7  Epoch: 431  Training loss = 1.7438  Validation loss = 0.7416  \n",
      "\n",
      "Fold: 7  Epoch: 432  Training loss = 1.7435  Validation loss = 0.7398  \n",
      "\n",
      "Fold: 7  Epoch: 433  Training loss = 1.7433  Validation loss = 0.7394  \n",
      "\n",
      "Fold: 7  Epoch: 434  Training loss = 1.7432  Validation loss = 0.7388  \n",
      "\n",
      "Fold: 7  Epoch: 435  Training loss = 1.7430  Validation loss = 0.7391  \n",
      "\n",
      "Fold: 7  Epoch: 436  Training loss = 1.7430  Validation loss = 0.7402  \n",
      "\n",
      "Fold: 7  Epoch: 437  Training loss = 1.7427  Validation loss = 0.7391  \n",
      "\n",
      "Fold: 7  Epoch: 438  Training loss = 1.7426  Validation loss = 0.7390  \n",
      "\n",
      "Fold: 7  Epoch: 439  Training loss = 1.7425  Validation loss = 0.7395  \n",
      "\n",
      "Fold: 7  Epoch: 440  Training loss = 1.7423  Validation loss = 0.7394  \n",
      "\n",
      "Fold: 7  Epoch: 441  Training loss = 1.7422  Validation loss = 0.7390  \n",
      "\n",
      "Fold: 7  Epoch: 442  Training loss = 1.7421  Validation loss = 0.7386  \n",
      "\n",
      "Fold: 7  Epoch: 443  Training loss = 1.7419  Validation loss = 0.7383  \n",
      "\n",
      "Fold: 7  Epoch: 444  Training loss = 1.7418  Validation loss = 0.7391  \n",
      "\n",
      "Fold: 7  Epoch: 445  Training loss = 1.7417  Validation loss = 0.7391  \n",
      "\n",
      "Fold: 7  Epoch: 446  Training loss = 1.7415  Validation loss = 0.7382  \n",
      "\n",
      "Fold: 7  Epoch: 447  Training loss = 1.7413  Validation loss = 0.7368  \n",
      "\n",
      "Fold: 7  Epoch: 448  Training loss = 1.7411  Validation loss = 0.7362  \n",
      "\n",
      "Fold: 7  Epoch: 449  Training loss = 1.7409  Validation loss = 0.7361  \n",
      "\n",
      "Fold: 7  Epoch: 450  Training loss = 1.7407  Validation loss = 0.7353  \n",
      "\n",
      "Fold: 7  Epoch: 451  Training loss = 1.7405  Validation loss = 0.7343  \n",
      "\n",
      "Fold: 7  Epoch: 452  Training loss = 1.7403  Validation loss = 0.7332  \n",
      "\n",
      "Fold: 7  Epoch: 453  Training loss = 1.7401  Validation loss = 0.7326  \n",
      "\n",
      "Fold: 7  Epoch: 454  Training loss = 1.7399  Validation loss = 0.7329  \n",
      "\n",
      "Fold: 7  Epoch: 455  Training loss = 1.7398  Validation loss = 0.7336  \n",
      "\n",
      "Fold: 7  Epoch: 456  Training loss = 1.7397  Validation loss = 0.7332  \n",
      "\n",
      "Fold: 7  Epoch: 457  Training loss = 1.7396  Validation loss = 0.7342  \n",
      "\n",
      "Fold: 7  Epoch: 458  Training loss = 1.7395  Validation loss = 0.7343  \n",
      "\n",
      "Fold: 7  Epoch: 459  Training loss = 1.7393  Validation loss = 0.7340  \n",
      "\n",
      "Fold: 7  Epoch: 460  Training loss = 1.7393  Validation loss = 0.7342  \n",
      "\n",
      "Fold: 7  Epoch: 461  Training loss = 1.7391  Validation loss = 0.7346  \n",
      "\n",
      "Check model:  Fold: 7  Epoch: 453  Training loss = 1.7391  Validation loss = 0.7346  \n",
      "\n",
      "Fold: 8  Epoch: 1  Training loss = 1.6922  Validation loss = 5.7527  \n",
      "\n",
      "Fold: 8  Epoch: 2  Training loss = 1.6921  Validation loss = 5.7528  \n",
      "\n",
      "Fold: 8  Epoch: 3  Training loss = 1.6919  Validation loss = 5.7537  \n",
      "\n",
      "Fold: 8  Epoch: 4  Training loss = 1.6917  Validation loss = 5.7535  \n",
      "\n",
      "Fold: 8  Epoch: 5  Training loss = 1.6914  Validation loss = 5.7516  \n",
      "\n",
      "Fold: 8  Epoch: 6  Training loss = 1.6911  Validation loss = 5.7502  \n",
      "\n",
      "Fold: 8  Epoch: 7  Training loss = 1.6909  Validation loss = 5.7499  \n",
      "\n",
      "Fold: 8  Epoch: 8  Training loss = 1.6908  Validation loss = 5.7500  \n",
      "\n",
      "Fold: 8  Epoch: 9  Training loss = 1.6906  Validation loss = 5.7501  \n",
      "\n",
      "Fold: 8  Epoch: 10  Training loss = 1.6904  Validation loss = 5.7487  \n",
      "\n",
      "Fold: 8  Epoch: 11  Training loss = 1.6903  Validation loss = 5.7499  \n",
      "\n",
      "Fold: 8  Epoch: 12  Training loss = 1.6901  Validation loss = 5.7500  \n",
      "\n",
      "Fold: 8  Epoch: 13  Training loss = 1.6899  Validation loss = 5.7493  \n",
      "\n",
      "Fold: 8  Epoch: 14  Training loss = 1.6896  Validation loss = 5.7477  \n",
      "\n",
      "Fold: 8  Epoch: 15  Training loss = 1.6895  Validation loss = 5.7477  \n",
      "\n",
      "Fold: 8  Epoch: 16  Training loss = 1.6894  Validation loss = 5.7475  \n",
      "\n",
      "Fold: 8  Epoch: 17  Training loss = 1.6891  Validation loss = 5.7460  \n",
      "\n",
      "Fold: 8  Epoch: 18  Training loss = 1.6890  Validation loss = 5.7455  \n",
      "\n",
      "Fold: 8  Epoch: 19  Training loss = 1.6887  Validation loss = 5.7452  \n",
      "\n",
      "Fold: 8  Epoch: 20  Training loss = 1.6886  Validation loss = 5.7451  \n",
      "\n",
      "Fold: 8  Epoch: 21  Training loss = 1.6883  Validation loss = 5.7442  \n",
      "\n",
      "Fold: 8  Epoch: 22  Training loss = 1.6880  Validation loss = 5.7428  \n",
      "\n",
      "Fold: 8  Epoch: 23  Training loss = 1.6878  Validation loss = 5.7419  \n",
      "\n",
      "Fold: 8  Epoch: 24  Training loss = 1.6875  Validation loss = 5.7405  \n",
      "\n",
      "Fold: 8  Epoch: 25  Training loss = 1.6873  Validation loss = 5.7399  \n",
      "\n",
      "Fold: 8  Epoch: 26  Training loss = 1.6871  Validation loss = 5.7397  \n",
      "\n",
      "Fold: 8  Epoch: 27  Training loss = 1.6869  Validation loss = 5.7395  \n",
      "\n",
      "Fold: 8  Epoch: 28  Training loss = 1.6868  Validation loss = 5.7397  \n",
      "\n",
      "Fold: 8  Epoch: 29  Training loss = 1.6867  Validation loss = 5.7396  \n",
      "\n",
      "Fold: 8  Epoch: 30  Training loss = 1.6865  Validation loss = 5.7396  \n",
      "\n",
      "Fold: 8  Epoch: 31  Training loss = 1.6864  Validation loss = 5.7401  \n",
      "\n",
      "Fold: 8  Epoch: 32  Training loss = 1.6861  Validation loss = 5.7390  \n",
      "\n",
      "Fold: 8  Epoch: 33  Training loss = 1.6860  Validation loss = 5.7390  \n",
      "\n",
      "Fold: 8  Epoch: 34  Training loss = 1.6858  Validation loss = 5.7394  \n",
      "\n",
      "Fold: 8  Epoch: 35  Training loss = 1.6856  Validation loss = 5.7387  \n",
      "\n",
      "Fold: 8  Epoch: 36  Training loss = 1.6854  Validation loss = 5.7378  \n",
      "\n",
      "Fold: 8  Epoch: 37  Training loss = 1.6851  Validation loss = 5.7367  \n",
      "\n",
      "Fold: 8  Epoch: 38  Training loss = 1.6849  Validation loss = 5.7362  \n",
      "\n",
      "Fold: 8  Epoch: 39  Training loss = 1.6846  Validation loss = 5.7348  \n",
      "\n",
      "Fold: 8  Epoch: 40  Training loss = 1.6844  Validation loss = 5.7345  \n",
      "\n",
      "Fold: 8  Epoch: 41  Training loss = 1.6842  Validation loss = 5.7339  \n",
      "\n",
      "Fold: 8  Epoch: 42  Training loss = 1.6841  Validation loss = 5.7339  \n",
      "\n",
      "Fold: 8  Epoch: 43  Training loss = 1.6841  Validation loss = 5.7345  \n",
      "\n",
      "Fold: 8  Epoch: 44  Training loss = 1.6839  Validation loss = 5.7344  \n",
      "\n",
      "Fold: 8  Epoch: 45  Training loss = 1.6837  Validation loss = 5.7340  \n",
      "\n",
      "Fold: 8  Epoch: 46  Training loss = 1.6837  Validation loss = 5.7351  \n",
      "\n",
      "Fold: 8  Epoch: 47  Training loss = 1.6835  Validation loss = 5.7352  \n",
      "\n",
      "Fold: 8  Epoch: 48  Training loss = 1.6834  Validation loss = 5.7351  \n",
      "\n",
      "Fold: 8  Epoch: 49  Training loss = 1.6832  Validation loss = 5.7346  \n",
      "\n",
      "Fold: 8  Epoch: 50  Training loss = 1.6830  Validation loss = 5.7350  \n",
      "\n",
      "Fold: 8  Epoch: 51  Training loss = 1.6829  Validation loss = 5.7348  \n",
      "\n",
      "Fold: 8  Epoch: 52  Training loss = 1.6827  Validation loss = 5.7345  \n",
      "\n",
      "Fold: 8  Epoch: 53  Training loss = 1.6826  Validation loss = 5.7351  \n",
      "\n",
      "Fold: 8  Epoch: 54  Training loss = 1.6825  Validation loss = 5.7356  \n",
      "\n",
      "Check model:  Fold: 8  Epoch: 42  Training loss = 1.6825  Validation loss = 5.7356  \n",
      "\n",
      "Fold: 9  Epoch: 1  Training loss = 2.1803  Validation loss = 9.0886  \n",
      "\n",
      "Fold: 9  Epoch: 2  Training loss = 2.1800  Validation loss = 9.0876  \n",
      "\n",
      "Fold: 9  Epoch: 3  Training loss = 2.1794  Validation loss = 9.0848  \n",
      "\n",
      "Fold: 9  Epoch: 4  Training loss = 2.1793  Validation loss = 9.0845  \n",
      "\n",
      "Fold: 9  Epoch: 5  Training loss = 2.1787  Validation loss = 9.0816  \n",
      "\n",
      "Fold: 9  Epoch: 6  Training loss = 2.1781  Validation loss = 9.0787  \n",
      "\n",
      "Fold: 9  Epoch: 7  Training loss = 2.1780  Validation loss = 9.0785  \n",
      "\n",
      "Fold: 9  Epoch: 8  Training loss = 2.1776  Validation loss = 9.0770  \n",
      "\n",
      "Fold: 9  Epoch: 9  Training loss = 2.1775  Validation loss = 9.0765  \n",
      "\n",
      "Fold: 9  Epoch: 10  Training loss = 2.1772  Validation loss = 9.0754  \n",
      "\n",
      "Fold: 9  Epoch: 11  Training loss = 2.1766  Validation loss = 9.0727  \n",
      "\n",
      "Fold: 9  Epoch: 12  Training loss = 2.1763  Validation loss = 9.0715  \n",
      "\n",
      "Fold: 9  Epoch: 13  Training loss = 2.1759  Validation loss = 9.0693  \n",
      "\n",
      "Fold: 9  Epoch: 14  Training loss = 2.1757  Validation loss = 9.0691  \n",
      "\n",
      "Fold: 9  Epoch: 15  Training loss = 2.1755  Validation loss = 9.0681  \n",
      "\n",
      "Fold: 9  Epoch: 16  Training loss = 2.1754  Validation loss = 9.0682  \n",
      "\n",
      "Fold: 9  Epoch: 17  Training loss = 2.1751  Validation loss = 9.0669  \n",
      "\n",
      "Fold: 9  Epoch: 18  Training loss = 2.1747  Validation loss = 9.0648  \n",
      "\n",
      "Fold: 9  Epoch: 19  Training loss = 2.1744  Validation loss = 9.0639  \n",
      "\n",
      "Fold: 9  Epoch: 20  Training loss = 2.1740  Validation loss = 9.0621  \n",
      "\n",
      "Fold: 9  Epoch: 21  Training loss = 2.1737  Validation loss = 9.0610  \n",
      "\n",
      "Fold: 9  Epoch: 22  Training loss = 2.1733  Validation loss = 9.0589  \n",
      "\n",
      "Fold: 9  Epoch: 23  Training loss = 2.1730  Validation loss = 9.0578  \n",
      "\n",
      "Fold: 9  Epoch: 24  Training loss = 2.1725  Validation loss = 9.0553  \n",
      "\n",
      "Fold: 9  Epoch: 25  Training loss = 2.1722  Validation loss = 9.0540  \n",
      "\n",
      "Fold: 9  Epoch: 26  Training loss = 2.1719  Validation loss = 9.0525  \n",
      "\n",
      "Fold: 9  Epoch: 27  Training loss = 2.1712  Validation loss = 9.0495  \n",
      "\n",
      "Fold: 9  Epoch: 28  Training loss = 2.1708  Validation loss = 9.0477  \n",
      "\n",
      "Fold: 9  Epoch: 29  Training loss = 2.1709  Validation loss = 9.0485  \n",
      "\n",
      "Fold: 9  Epoch: 30  Training loss = 2.1706  Validation loss = 9.0469  \n",
      "\n",
      "Fold: 9  Epoch: 31  Training loss = 2.1701  Validation loss = 9.0445  \n",
      "\n",
      "Fold: 9  Epoch: 32  Training loss = 2.1695  Validation loss = 9.0416  \n",
      "\n",
      "Fold: 9  Epoch: 33  Training loss = 2.1692  Validation loss = 9.0404  \n",
      "\n",
      "Fold: 9  Epoch: 34  Training loss = 2.1688  Validation loss = 9.0384  \n",
      "\n",
      "Fold: 9  Epoch: 35  Training loss = 2.1681  Validation loss = 9.0351  \n",
      "\n",
      "Fold: 9  Epoch: 36  Training loss = 2.1679  Validation loss = 9.0343  \n",
      "\n",
      "Fold: 9  Epoch: 37  Training loss = 2.1677  Validation loss = 9.0333  \n",
      "\n",
      "Fold: 9  Epoch: 38  Training loss = 2.1672  Validation loss = 9.0312  \n",
      "\n",
      "Fold: 9  Epoch: 39  Training loss = 2.1666  Validation loss = 9.0283  \n",
      "\n",
      "Fold: 9  Epoch: 40  Training loss = 2.1662  Validation loss = 9.0265  \n",
      "\n",
      "Fold: 9  Epoch: 41  Training loss = 2.1657  Validation loss = 9.0240  \n",
      "\n",
      "Fold: 9  Epoch: 42  Training loss = 2.1656  Validation loss = 9.0233  \n",
      "\n",
      "Fold: 9  Epoch: 43  Training loss = 2.1649  Validation loss = 9.0200  \n",
      "\n",
      "Fold: 9  Epoch: 44  Training loss = 2.1646  Validation loss = 9.0183  \n",
      "\n",
      "Fold: 9  Epoch: 45  Training loss = 2.1644  Validation loss = 9.0177  \n",
      "\n",
      "Fold: 9  Epoch: 46  Training loss = 2.1640  Validation loss = 9.0159  \n",
      "\n",
      "Fold: 9  Epoch: 47  Training loss = 2.1636  Validation loss = 9.0142  \n",
      "\n",
      "Fold: 9  Epoch: 48  Training loss = 2.1634  Validation loss = 9.0135  \n",
      "\n",
      "Fold: 9  Epoch: 49  Training loss = 2.1632  Validation loss = 9.0126  \n",
      "\n",
      "Fold: 9  Epoch: 50  Training loss = 2.1629  Validation loss = 9.0110  \n",
      "\n",
      "Fold: 9  Epoch: 51  Training loss = 2.1624  Validation loss = 9.0088  \n",
      "\n",
      "Fold: 9  Epoch: 52  Training loss = 2.1622  Validation loss = 9.0077  \n",
      "\n",
      "Fold: 9  Epoch: 53  Training loss = 2.1617  Validation loss = 9.0052  \n",
      "\n",
      "Fold: 9  Epoch: 54  Training loss = 2.1613  Validation loss = 9.0036  \n",
      "\n",
      "Fold: 9  Epoch: 55  Training loss = 2.1609  Validation loss = 9.0014  \n",
      "\n",
      "Fold: 9  Epoch: 56  Training loss = 2.1603  Validation loss = 8.9981  \n",
      "\n",
      "Fold: 9  Epoch: 57  Training loss = 2.1599  Validation loss = 8.9959  \n",
      "\n",
      "Fold: 9  Epoch: 58  Training loss = 2.1595  Validation loss = 8.9939  \n",
      "\n",
      "Fold: 9  Epoch: 59  Training loss = 2.1587  Validation loss = 8.9895  \n",
      "\n",
      "Fold: 9  Epoch: 60  Training loss = 2.1584  Validation loss = 8.9876  \n",
      "\n",
      "Fold: 9  Epoch: 61  Training loss = 2.1578  Validation loss = 8.9843  \n",
      "\n",
      "Fold: 9  Epoch: 62  Training loss = 2.1575  Validation loss = 8.9827  \n",
      "\n",
      "Fold: 9  Epoch: 63  Training loss = 2.1571  Validation loss = 8.9806  \n",
      "\n",
      "Fold: 9  Epoch: 64  Training loss = 2.1568  Validation loss = 8.9790  \n",
      "\n",
      "Fold: 9  Epoch: 65  Training loss = 2.1564  Validation loss = 8.9774  \n",
      "\n",
      "Fold: 9  Epoch: 66  Training loss = 2.1563  Validation loss = 8.9769  \n",
      "\n",
      "Fold: 9  Epoch: 67  Training loss = 2.1558  Validation loss = 8.9743  \n",
      "\n",
      "Fold: 9  Epoch: 68  Training loss = 2.1554  Validation loss = 8.9721  \n",
      "\n",
      "Fold: 9  Epoch: 69  Training loss = 2.1552  Validation loss = 8.9712  \n",
      "\n",
      "Fold: 9  Epoch: 70  Training loss = 2.1550  Validation loss = 8.9705  \n",
      "\n",
      "Fold: 9  Epoch: 71  Training loss = 2.1546  Validation loss = 8.9683  \n",
      "\n",
      "Fold: 9  Epoch: 72  Training loss = 2.1543  Validation loss = 8.9672  \n",
      "\n",
      "Fold: 9  Epoch: 73  Training loss = 2.1543  Validation loss = 8.9674  \n",
      "\n",
      "Fold: 9  Epoch: 74  Training loss = 2.1542  Validation loss = 8.9675  \n",
      "\n",
      "Fold: 9  Epoch: 75  Training loss = 2.1541  Validation loss = 8.9672  \n",
      "\n",
      "Fold: 9  Epoch: 76  Training loss = 2.1538  Validation loss = 8.9659  \n",
      "\n",
      "Fold: 9  Epoch: 77  Training loss = 2.1535  Validation loss = 8.9645  \n",
      "\n",
      "Fold: 9  Epoch: 78  Training loss = 2.1532  Validation loss = 8.9626  \n",
      "\n",
      "Fold: 9  Epoch: 79  Training loss = 2.1531  Validation loss = 8.9626  \n",
      "\n",
      "Fold: 9  Epoch: 80  Training loss = 2.1526  Validation loss = 8.9596  \n",
      "\n",
      "Fold: 9  Epoch: 81  Training loss = 2.1524  Validation loss = 8.9591  \n",
      "\n",
      "Fold: 9  Epoch: 82  Training loss = 2.1520  Validation loss = 8.9567  \n",
      "\n",
      "Fold: 9  Epoch: 83  Training loss = 2.1519  Validation loss = 8.9566  \n",
      "\n",
      "Fold: 9  Epoch: 84  Training loss = 2.1517  Validation loss = 8.9555  \n",
      "\n",
      "Fold: 9  Epoch: 85  Training loss = 2.1516  Validation loss = 8.9551  \n",
      "\n",
      "Fold: 9  Epoch: 86  Training loss = 2.1513  Validation loss = 8.9538  \n",
      "\n",
      "Fold: 9  Epoch: 87  Training loss = 2.1511  Validation loss = 8.9532  \n",
      "\n",
      "Fold: 9  Epoch: 88  Training loss = 2.1507  Validation loss = 8.9511  \n",
      "\n",
      "Fold: 9  Epoch: 89  Training loss = 2.1505  Validation loss = 8.9501  \n",
      "\n",
      "Fold: 9  Epoch: 90  Training loss = 2.1503  Validation loss = 8.9495  \n",
      "\n",
      "Fold: 9  Epoch: 91  Training loss = 2.1502  Validation loss = 8.9495  \n",
      "\n",
      "Fold: 9  Epoch: 92  Training loss = 2.1499  Validation loss = 8.9482  \n",
      "\n",
      "Fold: 9  Epoch: 93  Training loss = 2.1497  Validation loss = 8.9468  \n",
      "\n",
      "Fold: 9  Epoch: 94  Training loss = 2.1494  Validation loss = 8.9450  \n",
      "\n",
      "Fold: 9  Epoch: 95  Training loss = 2.1490  Validation loss = 8.9430  \n",
      "\n",
      "Fold: 9  Epoch: 96  Training loss = 2.1488  Validation loss = 8.9421  \n",
      "\n",
      "Fold: 9  Epoch: 97  Training loss = 2.1485  Validation loss = 8.9406  \n",
      "\n",
      "Fold: 9  Epoch: 98  Training loss = 2.1483  Validation loss = 8.9400  \n",
      "\n",
      "Fold: 9  Epoch: 99  Training loss = 2.1482  Validation loss = 8.9398  \n",
      "\n",
      "Fold: 9  Epoch: 100  Training loss = 2.1481  Validation loss = 8.9395  \n",
      "\n",
      "Fold: 9  Epoch: 101  Training loss = 2.1478  Validation loss = 8.9381  \n",
      "\n",
      "Fold: 9  Epoch: 102  Training loss = 2.1474  Validation loss = 8.9357  \n",
      "\n",
      "Fold: 9  Epoch: 103  Training loss = 2.1472  Validation loss = 8.9352  \n",
      "\n",
      "Fold: 9  Epoch: 104  Training loss = 2.1470  Validation loss = 8.9341  \n",
      "\n",
      "Fold: 9  Epoch: 105  Training loss = 2.1468  Validation loss = 8.9331  \n",
      "\n",
      "Fold: 9  Epoch: 106  Training loss = 2.1465  Validation loss = 8.9320  \n",
      "\n",
      "Fold: 9  Epoch: 107  Training loss = 2.1464  Validation loss = 8.9318  \n",
      "\n",
      "Fold: 9  Epoch: 108  Training loss = 2.1459  Validation loss = 8.9289  \n",
      "\n",
      "Fold: 9  Epoch: 109  Training loss = 2.1457  Validation loss = 8.9277  \n",
      "\n",
      "Fold: 9  Epoch: 110  Training loss = 2.1456  Validation loss = 8.9276  \n",
      "\n",
      "Fold: 9  Epoch: 111  Training loss = 2.1453  Validation loss = 8.9260  \n",
      "\n",
      "Fold: 9  Epoch: 112  Training loss = 2.1451  Validation loss = 8.9251  \n",
      "\n",
      "Fold: 9  Epoch: 113  Training loss = 2.1448  Validation loss = 8.9238  \n",
      "\n",
      "Fold: 9  Epoch: 114  Training loss = 2.1446  Validation loss = 8.9226  \n",
      "\n",
      "Fold: 9  Epoch: 115  Training loss = 2.1443  Validation loss = 8.9205  \n",
      "\n",
      "Fold: 9  Epoch: 116  Training loss = 2.1440  Validation loss = 8.9195  \n",
      "\n",
      "Fold: 9  Epoch: 117  Training loss = 2.1437  Validation loss = 8.9174  \n",
      "\n",
      "Fold: 9  Epoch: 118  Training loss = 2.1435  Validation loss = 8.9170  \n",
      "\n",
      "Fold: 9  Epoch: 119  Training loss = 2.1430  Validation loss = 8.9136  \n",
      "\n",
      "Fold: 9  Epoch: 120  Training loss = 2.1430  Validation loss = 8.9144  \n",
      "\n",
      "Fold: 9  Epoch: 121  Training loss = 2.1428  Validation loss = 8.9135  \n",
      "\n",
      "Fold: 9  Epoch: 122  Training loss = 2.1424  Validation loss = 8.9111  \n",
      "\n",
      "Fold: 9  Epoch: 123  Training loss = 2.1422  Validation loss = 8.9103  \n",
      "\n",
      "Fold: 9  Epoch: 124  Training loss = 2.1420  Validation loss = 8.9090  \n",
      "\n",
      "Fold: 9  Epoch: 125  Training loss = 2.1417  Validation loss = 8.9074  \n",
      "\n",
      "Fold: 9  Epoch: 126  Training loss = 2.1414  Validation loss = 8.9058  \n",
      "\n",
      "Fold: 9  Epoch: 127  Training loss = 2.1412  Validation loss = 8.9058  \n",
      "\n",
      "Fold: 9  Epoch: 128  Training loss = 2.1411  Validation loss = 8.9054  \n",
      "\n",
      "Fold: 9  Epoch: 129  Training loss = 2.1411  Validation loss = 8.9056  \n",
      "\n",
      "Fold: 9  Epoch: 130  Training loss = 2.1408  Validation loss = 8.9037  \n",
      "\n",
      "Fold: 9  Epoch: 131  Training loss = 2.1405  Validation loss = 8.9027  \n",
      "\n",
      "Fold: 9  Epoch: 132  Training loss = 2.1405  Validation loss = 8.9031  \n",
      "\n",
      "Fold: 9  Epoch: 133  Training loss = 2.1403  Validation loss = 8.9028  \n",
      "\n",
      "Fold: 9  Epoch: 134  Training loss = 2.1400  Validation loss = 8.9009  \n",
      "\n",
      "Fold: 9  Epoch: 135  Training loss = 2.1398  Validation loss = 8.8999  \n",
      "\n",
      "Fold: 9  Epoch: 136  Training loss = 2.1396  Validation loss = 8.8995  \n",
      "\n",
      "Fold: 9  Epoch: 137  Training loss = 2.1394  Validation loss = 8.8983  \n",
      "\n",
      "Fold: 9  Epoch: 138  Training loss = 2.1391  Validation loss = 8.8963  \n",
      "\n",
      "Fold: 9  Epoch: 139  Training loss = 2.1389  Validation loss = 8.8954  \n",
      "\n",
      "Fold: 9  Epoch: 140  Training loss = 2.1387  Validation loss = 8.8950  \n",
      "\n",
      "Fold: 9  Epoch: 141  Training loss = 2.1386  Validation loss = 8.8944  \n",
      "\n",
      "Fold: 9  Epoch: 142  Training loss = 2.1382  Validation loss = 8.8922  \n",
      "\n",
      "Fold: 9  Epoch: 143  Training loss = 2.1382  Validation loss = 8.8927  \n",
      "\n",
      "Fold: 9  Epoch: 144  Training loss = 2.1379  Validation loss = 8.8906  \n",
      "\n",
      "Fold: 9  Epoch: 145  Training loss = 2.1378  Validation loss = 8.8912  \n",
      "\n",
      "Fold: 9  Epoch: 146  Training loss = 2.1378  Validation loss = 8.8914  \n",
      "\n",
      "Fold: 9  Epoch: 147  Training loss = 2.1377  Validation loss = 8.8915  \n",
      "\n",
      "Fold: 9  Epoch: 148  Training loss = 2.1375  Validation loss = 8.8906  \n",
      "\n",
      "Fold: 9  Epoch: 149  Training loss = 2.1372  Validation loss = 8.8882  \n",
      "\n",
      "Fold: 9  Epoch: 150  Training loss = 2.1369  Validation loss = 8.8871  \n",
      "\n",
      "Fold: 9  Epoch: 151  Training loss = 2.1368  Validation loss = 8.8865  \n",
      "\n",
      "Fold: 9  Epoch: 152  Training loss = 2.1366  Validation loss = 8.8854  \n",
      "\n",
      "Fold: 9  Epoch: 153  Training loss = 2.1365  Validation loss = 8.8859  \n",
      "\n",
      "Fold: 9  Epoch: 154  Training loss = 2.1362  Validation loss = 8.8838  \n",
      "\n",
      "Fold: 9  Epoch: 155  Training loss = 2.1359  Validation loss = 8.8822  \n",
      "\n",
      "Fold: 9  Epoch: 156  Training loss = 2.1358  Validation loss = 8.8814  \n",
      "\n",
      "Fold: 9  Epoch: 157  Training loss = 2.1357  Validation loss = 8.8816  \n",
      "\n",
      "Fold: 9  Epoch: 158  Training loss = 2.1356  Validation loss = 8.8814  \n",
      "\n",
      "Fold: 9  Epoch: 159  Training loss = 2.1355  Validation loss = 8.8813  \n",
      "\n",
      "Fold: 9  Epoch: 160  Training loss = 2.1352  Validation loss = 8.8795  \n",
      "\n",
      "Fold: 9  Epoch: 161  Training loss = 2.1351  Validation loss = 8.8790  \n",
      "\n",
      "Fold: 9  Epoch: 162  Training loss = 2.1347  Validation loss = 8.8772  \n",
      "\n",
      "Fold: 9  Epoch: 163  Training loss = 2.1345  Validation loss = 8.8761  \n",
      "\n",
      "Fold: 9  Epoch: 164  Training loss = 2.1343  Validation loss = 8.8748  \n",
      "\n",
      "Fold: 9  Epoch: 165  Training loss = 2.1339  Validation loss = 8.8725  \n",
      "\n",
      "Fold: 9  Epoch: 166  Training loss = 2.1337  Validation loss = 8.8711  \n",
      "\n",
      "Fold: 9  Epoch: 167  Training loss = 2.1336  Validation loss = 8.8714  \n",
      "\n",
      "Fold: 9  Epoch: 168  Training loss = 2.1332  Validation loss = 8.8692  \n",
      "\n",
      "Fold: 9  Epoch: 169  Training loss = 2.1330  Validation loss = 8.8686  \n",
      "\n",
      "Fold: 9  Epoch: 170  Training loss = 2.1330  Validation loss = 8.8688  \n",
      "\n",
      "Fold: 9  Epoch: 171  Training loss = 2.1329  Validation loss = 8.8690  \n",
      "\n",
      "Fold: 9  Epoch: 172  Training loss = 2.1327  Validation loss = 8.8678  \n",
      "\n",
      "Fold: 9  Epoch: 173  Training loss = 2.1324  Validation loss = 8.8662  \n",
      "\n",
      "Fold: 9  Epoch: 174  Training loss = 2.1322  Validation loss = 8.8652  \n",
      "\n",
      "Fold: 9  Epoch: 175  Training loss = 2.1321  Validation loss = 8.8646  \n",
      "\n",
      "Fold: 9  Epoch: 176  Training loss = 2.1317  Validation loss = 8.8622  \n",
      "\n",
      "Fold: 9  Epoch: 177  Training loss = 2.1314  Validation loss = 8.8608  \n",
      "\n",
      "Fold: 9  Epoch: 178  Training loss = 2.1311  Validation loss = 8.8592  \n",
      "\n",
      "Fold: 9  Epoch: 179  Training loss = 2.1308  Validation loss = 8.8567  \n",
      "\n",
      "Fold: 9  Epoch: 180  Training loss = 2.1304  Validation loss = 8.8541  \n",
      "\n",
      "Fold: 9  Epoch: 181  Training loss = 2.1302  Validation loss = 8.8530  \n",
      "\n",
      "Fold: 9  Epoch: 182  Training loss = 2.1298  Validation loss = 8.8509  \n",
      "\n",
      "Fold: 9  Epoch: 183  Training loss = 2.1297  Validation loss = 8.8504  \n",
      "\n",
      "Fold: 9  Epoch: 184  Training loss = 2.1295  Validation loss = 8.8490  \n",
      "\n",
      "Fold: 9  Epoch: 185  Training loss = 2.1292  Validation loss = 8.8477  \n",
      "\n",
      "Fold: 9  Epoch: 186  Training loss = 2.1291  Validation loss = 8.8469  \n",
      "\n",
      "Fold: 9  Epoch: 187  Training loss = 2.1288  Validation loss = 8.8448  \n",
      "\n",
      "Fold: 9  Epoch: 188  Training loss = 2.1286  Validation loss = 8.8438  \n",
      "\n",
      "Fold: 9  Epoch: 189  Training loss = 2.1284  Validation loss = 8.8427  \n",
      "\n",
      "Fold: 9  Epoch: 190  Training loss = 2.1280  Validation loss = 8.8396  \n",
      "\n",
      "Fold: 9  Epoch: 191  Training loss = 2.1276  Validation loss = 8.8374  \n",
      "\n",
      "Fold: 9  Epoch: 192  Training loss = 2.1274  Validation loss = 8.8363  \n",
      "\n",
      "Fold: 9  Epoch: 193  Training loss = 2.1272  Validation loss = 8.8348  \n",
      "\n",
      "Fold: 9  Epoch: 194  Training loss = 2.1269  Validation loss = 8.8328  \n",
      "\n",
      "Fold: 9  Epoch: 195  Training loss = 2.1267  Validation loss = 8.8316  \n",
      "\n",
      "Fold: 9  Epoch: 196  Training loss = 2.1265  Validation loss = 8.8312  \n",
      "\n",
      "Fold: 9  Epoch: 197  Training loss = 2.1264  Validation loss = 8.8304  \n",
      "\n",
      "Fold: 9  Epoch: 198  Training loss = 2.1259  Validation loss = 8.8262  \n",
      "\n",
      "Fold: 9  Epoch: 199  Training loss = 2.1256  Validation loss = 8.8248  \n",
      "\n",
      "Fold: 9  Epoch: 200  Training loss = 2.1252  Validation loss = 8.8215  \n",
      "\n",
      "Fold: 9  Epoch: 201  Training loss = 2.1251  Validation loss = 8.8216  \n",
      "\n",
      "Fold: 9  Epoch: 202  Training loss = 2.1249  Validation loss = 8.8208  \n",
      "\n",
      "Fold: 9  Epoch: 203  Training loss = 2.1247  Validation loss = 8.8194  \n",
      "\n",
      "Fold: 9  Epoch: 204  Training loss = 2.1244  Validation loss = 8.8177  \n",
      "\n",
      "Fold: 9  Epoch: 205  Training loss = 2.1244  Validation loss = 8.8178  \n",
      "\n",
      "Fold: 9  Epoch: 206  Training loss = 2.1241  Validation loss = 8.8162  \n",
      "\n",
      "Fold: 9  Epoch: 207  Training loss = 2.1238  Validation loss = 8.8136  \n",
      "\n",
      "Fold: 9  Epoch: 208  Training loss = 2.1236  Validation loss = 8.8124  \n",
      "\n",
      "Fold: 9  Epoch: 209  Training loss = 2.1234  Validation loss = 8.8113  \n",
      "\n",
      "Fold: 9  Epoch: 210  Training loss = 2.1234  Validation loss = 8.8118  \n",
      "\n",
      "Fold: 9  Epoch: 211  Training loss = 2.1232  Validation loss = 8.8107  \n",
      "\n",
      "Fold: 9  Epoch: 212  Training loss = 2.1231  Validation loss = 8.8110  \n",
      "\n",
      "Fold: 9  Epoch: 213  Training loss = 2.1227  Validation loss = 8.8074  \n",
      "\n",
      "Fold: 9  Epoch: 214  Training loss = 2.1223  Validation loss = 8.8048  \n",
      "\n",
      "Fold: 9  Epoch: 215  Training loss = 2.1222  Validation loss = 8.8045  \n",
      "\n",
      "Fold: 9  Epoch: 216  Training loss = 2.1222  Validation loss = 8.8059  \n",
      "\n",
      "Fold: 9  Epoch: 217  Training loss = 2.1223  Validation loss = 8.8080  \n",
      "\n",
      "Fold: 9  Epoch: 218  Training loss = 2.1221  Validation loss = 8.8072  \n",
      "\n",
      "Fold: 9  Epoch: 219  Training loss = 2.1219  Validation loss = 8.8058  \n",
      "\n",
      "Fold: 9  Epoch: 220  Training loss = 2.1218  Validation loss = 8.8058  \n",
      "\n",
      "Fold: 9  Epoch: 221  Training loss = 2.1216  Validation loss = 8.8051  \n",
      "\n",
      "Fold: 9  Epoch: 222  Training loss = 2.1213  Validation loss = 8.8028  \n",
      "\n",
      "Fold: 9  Epoch: 223  Training loss = 2.1212  Validation loss = 8.8029  \n",
      "\n",
      "Fold: 9  Epoch: 224  Training loss = 2.1210  Validation loss = 8.8022  \n",
      "\n",
      "Fold: 9  Epoch: 225  Training loss = 2.1209  Validation loss = 8.8016  \n",
      "\n",
      "Fold: 9  Epoch: 226  Training loss = 2.1206  Validation loss = 8.8002  \n",
      "\n",
      "Fold: 9  Epoch: 227  Training loss = 2.1204  Validation loss = 8.7987  \n",
      "\n",
      "Fold: 9  Epoch: 228  Training loss = 2.1201  Validation loss = 8.7965  \n",
      "\n",
      "Fold: 9  Epoch: 229  Training loss = 2.1200  Validation loss = 8.7966  \n",
      "\n",
      "Fold: 9  Epoch: 230  Training loss = 2.1199  Validation loss = 8.7967  \n",
      "\n",
      "Fold: 9  Epoch: 231  Training loss = 2.1197  Validation loss = 8.7957  \n",
      "\n",
      "Fold: 9  Epoch: 232  Training loss = 2.1194  Validation loss = 8.7941  \n",
      "\n",
      "Fold: 9  Epoch: 233  Training loss = 2.1192  Validation loss = 8.7931  \n",
      "\n",
      "Fold: 9  Epoch: 234  Training loss = 2.1190  Validation loss = 8.7916  \n",
      "\n",
      "Fold: 9  Epoch: 235  Training loss = 2.1187  Validation loss = 8.7900  \n",
      "\n",
      "Fold: 9  Epoch: 236  Training loss = 2.1187  Validation loss = 8.7903  \n",
      "\n",
      "Fold: 9  Epoch: 237  Training loss = 2.1184  Validation loss = 8.7882  \n",
      "\n",
      "Fold: 9  Epoch: 238  Training loss = 2.1181  Validation loss = 8.7857  \n",
      "\n",
      "Fold: 9  Epoch: 239  Training loss = 2.1179  Validation loss = 8.7855  \n",
      "\n",
      "Fold: 9  Epoch: 240  Training loss = 2.1178  Validation loss = 8.7850  \n",
      "\n",
      "Fold: 9  Epoch: 241  Training loss = 2.1176  Validation loss = 8.7846  \n",
      "\n",
      "Fold: 9  Epoch: 242  Training loss = 2.1175  Validation loss = 8.7843  \n",
      "\n",
      "Fold: 9  Epoch: 243  Training loss = 2.1174  Validation loss = 8.7838  \n",
      "\n",
      "Fold: 9  Epoch: 244  Training loss = 2.1171  Validation loss = 8.7817  \n",
      "\n",
      "Fold: 9  Epoch: 245  Training loss = 2.1169  Validation loss = 8.7799  \n",
      "\n",
      "Fold: 9  Epoch: 246  Training loss = 2.1167  Validation loss = 8.7798  \n",
      "\n",
      "Fold: 9  Epoch: 247  Training loss = 2.1165  Validation loss = 8.7786  \n",
      "\n",
      "Fold: 9  Epoch: 248  Training loss = 2.1162  Validation loss = 8.7755  \n",
      "\n",
      "Fold: 9  Epoch: 249  Training loss = 2.1161  Validation loss = 8.7754  \n",
      "\n",
      "Fold: 9  Epoch: 250  Training loss = 2.1160  Validation loss = 8.7757  \n",
      "\n",
      "Fold: 9  Epoch: 251  Training loss = 2.1156  Validation loss = 8.7718  \n",
      "\n",
      "Fold: 9  Epoch: 252  Training loss = 2.1156  Validation loss = 8.7729  \n",
      "\n",
      "Fold: 9  Epoch: 253  Training loss = 2.1155  Validation loss = 8.7736  \n",
      "\n",
      "Fold: 9  Epoch: 254  Training loss = 2.1155  Validation loss = 8.7742  \n",
      "\n",
      "Fold: 9  Epoch: 255  Training loss = 2.1154  Validation loss = 8.7748  \n",
      "\n",
      "Fold: 9  Epoch: 256  Training loss = 2.1154  Validation loss = 8.7756  \n",
      "\n",
      "Fold: 9  Epoch: 257  Training loss = 2.1153  Validation loss = 8.7758  \n",
      "\n",
      "Check model:  Fold: 9  Epoch: 251  Training loss = 2.1153  Validation loss = 8.7758  \n",
      "\n",
      "Fold: 10  Epoch: 1  Training loss = 3.0043  Validation loss = 5.0975  \n",
      "\n",
      "Fold: 10  Epoch: 2  Training loss = 3.0032  Validation loss = 5.0950  \n",
      "\n",
      "Fold: 10  Epoch: 3  Training loss = 3.0025  Validation loss = 5.0936  \n",
      "\n",
      "Fold: 10  Epoch: 4  Training loss = 3.0017  Validation loss = 5.0915  \n",
      "\n",
      "Fold: 10  Epoch: 5  Training loss = 3.0009  Validation loss = 5.0894  \n",
      "\n",
      "Fold: 10  Epoch: 6  Training loss = 2.9999  Validation loss = 5.0866  \n",
      "\n",
      "Fold: 10  Epoch: 7  Training loss = 2.9992  Validation loss = 5.0846  \n",
      "\n",
      "Fold: 10  Epoch: 8  Training loss = 2.9987  Validation loss = 5.0830  \n",
      "\n",
      "Fold: 10  Epoch: 9  Training loss = 2.9983  Validation loss = 5.0816  \n",
      "\n",
      "Fold: 10  Epoch: 10  Training loss = 2.9980  Validation loss = 5.0809  \n",
      "\n",
      "Fold: 10  Epoch: 11  Training loss = 2.9973  Validation loss = 5.0786  \n",
      "\n",
      "Fold: 10  Epoch: 12  Training loss = 2.9967  Validation loss = 5.0765  \n",
      "\n",
      "Fold: 10  Epoch: 13  Training loss = 2.9964  Validation loss = 5.0756  \n",
      "\n",
      "Fold: 10  Epoch: 14  Training loss = 2.9954  Validation loss = 5.0726  \n",
      "\n",
      "Fold: 10  Epoch: 15  Training loss = 2.9946  Validation loss = 5.0699  \n",
      "\n",
      "Fold: 10  Epoch: 16  Training loss = 2.9937  Validation loss = 5.0675  \n",
      "\n",
      "Fold: 10  Epoch: 17  Training loss = 2.9929  Validation loss = 5.0659  \n",
      "\n",
      "Fold: 10  Epoch: 18  Training loss = 2.9919  Validation loss = 5.0620  \n",
      "\n",
      "Fold: 10  Epoch: 19  Training loss = 2.9912  Validation loss = 5.0600  \n",
      "\n",
      "Fold: 10  Epoch: 20  Training loss = 2.9902  Validation loss = 5.0569  \n",
      "\n",
      "Fold: 10  Epoch: 21  Training loss = 2.9899  Validation loss = 5.0560  \n",
      "\n",
      "Fold: 10  Epoch: 22  Training loss = 2.9892  Validation loss = 5.0542  \n",
      "\n",
      "Fold: 10  Epoch: 23  Training loss = 2.9881  Validation loss = 5.0513  \n",
      "\n",
      "Fold: 10  Epoch: 24  Training loss = 2.9874  Validation loss = 5.0489  \n",
      "\n",
      "Fold: 10  Epoch: 25  Training loss = 2.9867  Validation loss = 5.0455  \n",
      "\n",
      "Fold: 10  Epoch: 26  Training loss = 2.9862  Validation loss = 5.0443  \n",
      "\n",
      "Fold: 10  Epoch: 27  Training loss = 2.9854  Validation loss = 5.0421  \n",
      "\n",
      "Fold: 10  Epoch: 28  Training loss = 2.9843  Validation loss = 5.0381  \n",
      "\n",
      "Fold: 10  Epoch: 29  Training loss = 2.9836  Validation loss = 5.0365  \n",
      "\n",
      "Fold: 10  Epoch: 30  Training loss = 2.9822  Validation loss = 5.0322  \n",
      "\n",
      "Fold: 10  Epoch: 31  Training loss = 2.9811  Validation loss = 5.0294  \n",
      "\n",
      "Fold: 10  Epoch: 32  Training loss = 2.9802  Validation loss = 5.0265  \n",
      "\n",
      "Fold: 10  Epoch: 33  Training loss = 2.9793  Validation loss = 5.0229  \n",
      "\n",
      "Fold: 10  Epoch: 34  Training loss = 2.9783  Validation loss = 5.0202  \n",
      "\n",
      "Fold: 10  Epoch: 35  Training loss = 2.9773  Validation loss = 5.0166  \n",
      "\n",
      "Fold: 10  Epoch: 36  Training loss = 2.9768  Validation loss = 5.0149  \n",
      "\n",
      "Fold: 10  Epoch: 37  Training loss = 2.9761  Validation loss = 5.0132  \n",
      "\n",
      "Fold: 10  Epoch: 38  Training loss = 2.9757  Validation loss = 5.0119  \n",
      "\n",
      "Fold: 10  Epoch: 39  Training loss = 2.9743  Validation loss = 5.0069  \n",
      "\n",
      "Fold: 10  Epoch: 40  Training loss = 2.9732  Validation loss = 5.0030  \n",
      "\n",
      "Fold: 10  Epoch: 41  Training loss = 2.9728  Validation loss = 5.0014  \n",
      "\n",
      "Fold: 10  Epoch: 42  Training loss = 2.9717  Validation loss = 4.9970  \n",
      "\n",
      "Fold: 10  Epoch: 43  Training loss = 2.9710  Validation loss = 4.9944  \n",
      "\n",
      "Fold: 10  Epoch: 44  Training loss = 2.9703  Validation loss = 4.9917  \n",
      "\n",
      "Fold: 10  Epoch: 45  Training loss = 2.9697  Validation loss = 4.9895  \n",
      "\n",
      "Fold: 10  Epoch: 46  Training loss = 2.9693  Validation loss = 4.9876  \n",
      "\n",
      "Fold: 10  Epoch: 47  Training loss = 2.9687  Validation loss = 4.9853  \n",
      "\n",
      "Fold: 10  Epoch: 48  Training loss = 2.9676  Validation loss = 4.9818  \n",
      "\n",
      "Fold: 10  Epoch: 49  Training loss = 2.9668  Validation loss = 4.9777  \n",
      "\n",
      "Fold: 10  Epoch: 50  Training loss = 2.9662  Validation loss = 4.9758  \n",
      "\n",
      "Fold: 10  Epoch: 51  Training loss = 2.9655  Validation loss = 4.9738  \n",
      "\n",
      "Fold: 10  Epoch: 52  Training loss = 2.9649  Validation loss = 4.9697  \n",
      "\n",
      "Fold: 10  Epoch: 53  Training loss = 2.9645  Validation loss = 4.9684  \n",
      "\n",
      "Fold: 10  Epoch: 54  Training loss = 2.9639  Validation loss = 4.9640  \n",
      "\n",
      "Fold: 10  Epoch: 55  Training loss = 2.9629  Validation loss = 4.9568  \n",
      "\n",
      "Fold: 10  Epoch: 56  Training loss = 2.9623  Validation loss = 4.9517  \n",
      "\n",
      "Fold: 10  Epoch: 57  Training loss = 2.9614  Validation loss = 4.9467  \n",
      "\n",
      "Fold: 10  Epoch: 58  Training loss = 2.9606  Validation loss = 4.9432  \n",
      "\n",
      "Fold: 10  Epoch: 59  Training loss = 2.9598  Validation loss = 4.9357  \n",
      "\n",
      "Fold: 10  Epoch: 60  Training loss = 2.9588  Validation loss = 4.9300  \n",
      "\n",
      "Fold: 10  Epoch: 61  Training loss = 2.9580  Validation loss = 4.9146  \n",
      "\n",
      "Fold: 10  Epoch: 62  Training loss = 2.9576  Validation loss = 4.9123  \n",
      "\n",
      "Fold: 10  Epoch: 63  Training loss = 2.9570  Validation loss = 4.9088  \n",
      "\n",
      "Fold: 10  Epoch: 64  Training loss = 2.9568  Validation loss = 4.8957  \n",
      "\n",
      "Fold: 10  Epoch: 65  Training loss = 2.9558  Validation loss = 4.8767  \n",
      "\n",
      "Fold: 10  Epoch: 66  Training loss = 2.9556  Validation loss = 4.8706  \n",
      "\n",
      "Fold: 10  Epoch: 67  Training loss = 2.9548  Validation loss = 4.8632  \n",
      "\n",
      "Fold: 10  Epoch: 68  Training loss = 2.9542  Validation loss = 4.8560  \n",
      "\n",
      "Fold: 10  Epoch: 69  Training loss = 2.9534  Validation loss = 4.8408  \n",
      "\n",
      "Fold: 10  Epoch: 70  Training loss = 2.9529  Validation loss = 4.8317  \n",
      "\n",
      "Fold: 10  Epoch: 71  Training loss = 2.9524  Validation loss = 4.8237  \n",
      "\n",
      "Fold: 10  Epoch: 72  Training loss = 2.9519  Validation loss = 4.8220  \n",
      "\n",
      "Fold: 10  Epoch: 73  Training loss = 2.9511  Validation loss = 4.8126  \n",
      "\n",
      "Fold: 10  Epoch: 74  Training loss = 2.9508  Validation loss = 4.8110  \n",
      "\n",
      "Fold: 10  Epoch: 75  Training loss = 2.9503  Validation loss = 4.8099  \n",
      "\n",
      "Fold: 10  Epoch: 76  Training loss = 2.9499  Validation loss = 4.8070  \n",
      "\n",
      "Fold: 10  Epoch: 77  Training loss = 2.9493  Validation loss = 4.8008  \n",
      "\n",
      "Fold: 10  Epoch: 78  Training loss = 2.9487  Validation loss = 4.7937  \n",
      "\n",
      "Fold: 10  Epoch: 79  Training loss = 2.9482  Validation loss = 4.7904  \n",
      "\n",
      "Fold: 10  Epoch: 80  Training loss = 2.9479  Validation loss = 4.7883  \n",
      "\n",
      "Fold: 10  Epoch: 81  Training loss = 2.9463  Validation loss = 4.7805  \n",
      "\n",
      "Fold: 10  Epoch: 82  Training loss = 2.9458  Validation loss = 4.7785  \n",
      "\n",
      "Fold: 10  Epoch: 83  Training loss = 2.9455  Validation loss = 4.7766  \n",
      "\n",
      "Fold: 10  Epoch: 84  Training loss = 2.9453  Validation loss = 4.7762  \n",
      "\n",
      "Fold: 10  Epoch: 85  Training loss = 2.9450  Validation loss = 4.7751  \n",
      "\n",
      "Fold: 10  Epoch: 86  Training loss = 2.9443  Validation loss = 4.7713  \n",
      "\n",
      "Fold: 10  Epoch: 87  Training loss = 2.9433  Validation loss = 4.7681  \n",
      "\n",
      "Fold: 10  Epoch: 88  Training loss = 2.9427  Validation loss = 4.7667  \n",
      "\n",
      "Fold: 10  Epoch: 89  Training loss = 2.9421  Validation loss = 4.7647  \n",
      "\n",
      "Fold: 10  Epoch: 90  Training loss = 2.9408  Validation loss = 4.7586  \n",
      "\n",
      "Fold: 10  Epoch: 91  Training loss = 2.9401  Validation loss = 4.7562  \n",
      "\n",
      "Fold: 10  Epoch: 92  Training loss = 2.9394  Validation loss = 4.7536  \n",
      "\n",
      "Fold: 10  Epoch: 93  Training loss = 2.9386  Validation loss = 4.7508  \n",
      "\n",
      "Fold: 10  Epoch: 94  Training loss = 2.9379  Validation loss = 4.7479  \n",
      "\n",
      "Fold: 10  Epoch: 95  Training loss = 2.9369  Validation loss = 4.7435  \n",
      "\n",
      "Fold: 10  Epoch: 96  Training loss = 2.9360  Validation loss = 4.7407  \n",
      "\n",
      "Fold: 10  Epoch: 97  Training loss = 2.9355  Validation loss = 4.7388  \n",
      "\n",
      "Fold: 10  Epoch: 98  Training loss = 2.9349  Validation loss = 4.7371  \n",
      "\n",
      "Fold: 10  Epoch: 99  Training loss = 2.9339  Validation loss = 4.7336  \n",
      "\n",
      "Fold: 10  Epoch: 100  Training loss = 2.9330  Validation loss = 4.7305  \n",
      "\n",
      "Fold: 10  Epoch: 101  Training loss = 2.9326  Validation loss = 4.7289  \n",
      "\n",
      "Fold: 10  Epoch: 102  Training loss = 2.9322  Validation loss = 4.7280  \n",
      "\n",
      "Fold: 10  Epoch: 103  Training loss = 2.9318  Validation loss = 4.7269  \n",
      "\n",
      "Fold: 10  Epoch: 104  Training loss = 2.9316  Validation loss = 4.7265  \n",
      "\n",
      "Fold: 10  Epoch: 105  Training loss = 2.9312  Validation loss = 4.7249  \n",
      "\n",
      "Fold: 10  Epoch: 106  Training loss = 2.9307  Validation loss = 4.7230  \n",
      "\n",
      "Fold: 10  Epoch: 107  Training loss = 2.9297  Validation loss = 4.7186  \n",
      "\n",
      "Fold: 10  Epoch: 108  Training loss = 2.9288  Validation loss = 4.7149  \n",
      "\n",
      "Fold: 10  Epoch: 109  Training loss = 2.9279  Validation loss = 4.7118  \n",
      "\n",
      "Fold: 10  Epoch: 110  Training loss = 2.9273  Validation loss = 4.7093  \n",
      "\n",
      "Fold: 10  Epoch: 111  Training loss = 2.9268  Validation loss = 4.7085  \n",
      "\n",
      "Fold: 10  Epoch: 112  Training loss = 2.9258  Validation loss = 4.7041  \n",
      "\n",
      "Fold: 10  Epoch: 113  Training loss = 2.9251  Validation loss = 4.7016  \n",
      "\n",
      "Fold: 10  Epoch: 114  Training loss = 2.9241  Validation loss = 4.6984  \n",
      "\n",
      "Fold: 10  Epoch: 115  Training loss = 2.9238  Validation loss = 4.6973  \n",
      "\n",
      "Fold: 10  Epoch: 116  Training loss = 2.9236  Validation loss = 4.6969  \n",
      "\n",
      "Fold: 10  Epoch: 117  Training loss = 2.9228  Validation loss = 4.6941  \n",
      "\n",
      "Fold: 10  Epoch: 118  Training loss = 2.9219  Validation loss = 4.6908  \n",
      "\n",
      "Fold: 10  Epoch: 119  Training loss = 2.9213  Validation loss = 4.6884  \n",
      "\n",
      "Fold: 10  Epoch: 120  Training loss = 2.9207  Validation loss = 4.6867  \n",
      "\n",
      "Fold: 10  Epoch: 121  Training loss = 2.9197  Validation loss = 4.6830  \n",
      "\n",
      "Fold: 10  Epoch: 122  Training loss = 2.9195  Validation loss = 4.6825  \n",
      "\n",
      "Fold: 10  Epoch: 123  Training loss = 2.9193  Validation loss = 4.6821  \n",
      "\n",
      "Fold: 10  Epoch: 124  Training loss = 2.9188  Validation loss = 4.6808  \n",
      "\n",
      "Fold: 10  Epoch: 125  Training loss = 2.9189  Validation loss = 4.6822  \n",
      "\n",
      "Fold: 10  Epoch: 126  Training loss = 2.9181  Validation loss = 4.6795  \n",
      "\n",
      "Fold: 10  Epoch: 127  Training loss = 2.9176  Validation loss = 4.6771  \n",
      "\n",
      "Fold: 10  Epoch: 128  Training loss = 2.9172  Validation loss = 4.6758  \n",
      "\n",
      "Fold: 10  Epoch: 129  Training loss = 2.9168  Validation loss = 4.6743  \n",
      "\n",
      "Fold: 10  Epoch: 130  Training loss = 2.9164  Validation loss = 4.6727  \n",
      "\n",
      "Fold: 10  Epoch: 131  Training loss = 2.9159  Validation loss = 4.6707  \n",
      "\n",
      "Fold: 10  Epoch: 132  Training loss = 2.9151  Validation loss = 4.6676  \n",
      "\n",
      "Fold: 10  Epoch: 133  Training loss = 2.9145  Validation loss = 4.6651  \n",
      "\n",
      "Fold: 10  Epoch: 134  Training loss = 2.9132  Validation loss = 4.6605  \n",
      "\n",
      "Fold: 10  Epoch: 135  Training loss = 2.9124  Validation loss = 4.6575  \n",
      "\n",
      "Fold: 10  Epoch: 136  Training loss = 2.9117  Validation loss = 4.6550  \n",
      "\n",
      "Fold: 10  Epoch: 137  Training loss = 2.9111  Validation loss = 4.6529  \n",
      "\n",
      "Fold: 10  Epoch: 138  Training loss = 2.9104  Validation loss = 4.6506  \n",
      "\n",
      "Fold: 10  Epoch: 139  Training loss = 2.9100  Validation loss = 4.6492  \n",
      "\n",
      "Fold: 10  Epoch: 140  Training loss = 2.9098  Validation loss = 4.6492  \n",
      "\n",
      "Fold: 10  Epoch: 141  Training loss = 2.9096  Validation loss = 4.6483  \n",
      "\n",
      "Fold: 10  Epoch: 142  Training loss = 2.9088  Validation loss = 4.6450  \n",
      "\n",
      "Fold: 10  Epoch: 143  Training loss = 2.9080  Validation loss = 4.6424  \n",
      "\n",
      "Fold: 10  Epoch: 144  Training loss = 2.9077  Validation loss = 4.6412  \n",
      "\n",
      "Fold: 10  Epoch: 145  Training loss = 2.9072  Validation loss = 4.6397  \n",
      "\n",
      "Fold: 10  Epoch: 146  Training loss = 2.9067  Validation loss = 4.6378  \n",
      "\n",
      "Fold: 10  Epoch: 147  Training loss = 2.9064  Validation loss = 4.6366  \n",
      "\n",
      "Fold: 10  Epoch: 148  Training loss = 2.9060  Validation loss = 4.6354  \n",
      "\n",
      "Fold: 10  Epoch: 149  Training loss = 2.9054  Validation loss = 4.6330  \n",
      "\n",
      "Fold: 10  Epoch: 150  Training loss = 2.9048  Validation loss = 4.6306  \n",
      "\n",
      "Fold: 10  Epoch: 151  Training loss = 2.9040  Validation loss = 4.6276  \n",
      "\n",
      "Fold: 10  Epoch: 152  Training loss = 2.9035  Validation loss = 4.6267  \n",
      "\n",
      "Fold: 10  Epoch: 153  Training loss = 2.9032  Validation loss = 4.6256  \n",
      "\n",
      "Fold: 10  Epoch: 154  Training loss = 2.9028  Validation loss = 4.6242  \n",
      "\n",
      "Fold: 10  Epoch: 155  Training loss = 2.9022  Validation loss = 4.6223  \n",
      "\n",
      "Fold: 10  Epoch: 156  Training loss = 2.9013  Validation loss = 4.6191  \n",
      "\n",
      "Fold: 10  Epoch: 157  Training loss = 2.9010  Validation loss = 4.6180  \n",
      "\n",
      "Fold: 10  Epoch: 158  Training loss = 2.9002  Validation loss = 4.6154  \n",
      "\n",
      "Fold: 10  Epoch: 159  Training loss = 2.8998  Validation loss = 4.6141  \n",
      "\n",
      "Fold: 10  Epoch: 160  Training loss = 2.8993  Validation loss = 4.6117  \n",
      "\n",
      "Fold: 10  Epoch: 161  Training loss = 2.8988  Validation loss = 4.6096  \n",
      "\n",
      "Fold: 10  Epoch: 162  Training loss = 2.8987  Validation loss = 4.6096  \n",
      "\n",
      "Fold: 10  Epoch: 163  Training loss = 2.8986  Validation loss = 4.6096  \n",
      "\n",
      "Fold: 10  Epoch: 164  Training loss = 2.8981  Validation loss = 4.6080  \n",
      "\n",
      "Fold: 10  Epoch: 165  Training loss = 2.8974  Validation loss = 4.6046  \n",
      "\n",
      "Fold: 10  Epoch: 166  Training loss = 2.8969  Validation loss = 4.6025  \n",
      "\n",
      "Fold: 10  Epoch: 167  Training loss = 2.8966  Validation loss = 4.6019  \n",
      "\n",
      "Fold: 10  Epoch: 168  Training loss = 2.8963  Validation loss = 4.6008  \n",
      "\n",
      "Fold: 10  Epoch: 169  Training loss = 2.8955  Validation loss = 4.5975  \n",
      "\n",
      "Fold: 10  Epoch: 170  Training loss = 2.8948  Validation loss = 4.5948  \n",
      "\n",
      "Fold: 10  Epoch: 171  Training loss = 2.8941  Validation loss = 4.5925  \n",
      "\n",
      "Fold: 10  Epoch: 172  Training loss = 2.8937  Validation loss = 4.5910  \n",
      "\n",
      "Fold: 10  Epoch: 173  Training loss = 2.8932  Validation loss = 4.5901  \n",
      "\n",
      "Fold: 10  Epoch: 174  Training loss = 2.8922  Validation loss = 4.5858  \n",
      "\n",
      "Fold: 10  Epoch: 175  Training loss = 2.8918  Validation loss = 4.5845  \n",
      "\n",
      "Fold: 10  Epoch: 176  Training loss = 2.8915  Validation loss = 4.5838  \n",
      "\n",
      "Fold: 10  Epoch: 177  Training loss = 2.8912  Validation loss = 4.5835  \n",
      "\n",
      "Fold: 10  Epoch: 178  Training loss = 2.8909  Validation loss = 4.5825  \n",
      "\n",
      "Fold: 10  Epoch: 179  Training loss = 2.8903  Validation loss = 4.5809  \n",
      "\n",
      "Fold: 10  Epoch: 180  Training loss = 2.8896  Validation loss = 4.5787  \n",
      "\n",
      "Fold: 10  Epoch: 181  Training loss = 2.8891  Validation loss = 4.5766  \n",
      "\n",
      "Fold: 10  Epoch: 182  Training loss = 2.8888  Validation loss = 4.5753  \n",
      "\n",
      "Fold: 10  Epoch: 183  Training loss = 2.8880  Validation loss = 4.5719  \n",
      "\n",
      "Fold: 10  Epoch: 184  Training loss = 2.8876  Validation loss = 4.5703  \n",
      "\n",
      "Fold: 10  Epoch: 185  Training loss = 2.8872  Validation loss = 4.5691  \n",
      "\n",
      "Fold: 10  Epoch: 186  Training loss = 2.8868  Validation loss = 4.5677  \n",
      "\n",
      "Fold: 10  Epoch: 187  Training loss = 2.8862  Validation loss = 4.5659  \n",
      "\n",
      "Fold: 10  Epoch: 188  Training loss = 2.8857  Validation loss = 4.5637  \n",
      "\n",
      "Fold: 10  Epoch: 189  Training loss = 2.8854  Validation loss = 4.5632  \n",
      "\n",
      "Fold: 10  Epoch: 190  Training loss = 2.8846  Validation loss = 4.5600  \n",
      "\n",
      "Fold: 10  Epoch: 191  Training loss = 2.8841  Validation loss = 4.5581  \n",
      "\n",
      "Fold: 10  Epoch: 192  Training loss = 2.8835  Validation loss = 4.5554  \n",
      "\n",
      "Fold: 10  Epoch: 193  Training loss = 2.8832  Validation loss = 4.5548  \n",
      "\n",
      "Fold: 10  Epoch: 194  Training loss = 2.8828  Validation loss = 4.5541  \n",
      "\n",
      "Fold: 10  Epoch: 195  Training loss = 2.8827  Validation loss = 4.5540  \n",
      "\n",
      "Fold: 10  Epoch: 196  Training loss = 2.8824  Validation loss = 4.5536  \n",
      "\n",
      "Fold: 10  Epoch: 197  Training loss = 2.8819  Validation loss = 4.5518  \n",
      "\n",
      "Fold: 10  Epoch: 198  Training loss = 2.8817  Validation loss = 4.5515  \n",
      "\n",
      "Fold: 10  Epoch: 199  Training loss = 2.8815  Validation loss = 4.5507  \n",
      "\n",
      "Fold: 10  Epoch: 200  Training loss = 2.8815  Validation loss = 4.5514  \n",
      "\n",
      "Fold: 10  Epoch: 201  Training loss = 2.8809  Validation loss = 4.5490  \n",
      "\n",
      "Fold: 10  Epoch: 202  Training loss = 2.8806  Validation loss = 4.5481  \n",
      "\n",
      "Fold: 10  Epoch: 203  Training loss = 2.8802  Validation loss = 4.5471  \n",
      "\n",
      "Fold: 10  Epoch: 204  Training loss = 2.8802  Validation loss = 4.5474  \n",
      "\n",
      "Fold: 10  Epoch: 205  Training loss = 2.8799  Validation loss = 4.5467  \n",
      "\n",
      "Fold: 10  Epoch: 206  Training loss = 2.8793  Validation loss = 4.5447  \n",
      "\n",
      "Fold: 10  Epoch: 207  Training loss = 2.8793  Validation loss = 4.5456  \n",
      "\n",
      "Fold: 10  Epoch: 208  Training loss = 2.8788  Validation loss = 4.5438  \n",
      "\n",
      "Fold: 10  Epoch: 209  Training loss = 2.8782  Validation loss = 4.5416  \n",
      "\n",
      "Fold: 10  Epoch: 210  Training loss = 2.8779  Validation loss = 4.5408  \n",
      "\n",
      "Fold: 10  Epoch: 211  Training loss = 2.8772  Validation loss = 4.5385  \n",
      "\n",
      "Fold: 10  Epoch: 212  Training loss = 2.8770  Validation loss = 4.5378  \n",
      "\n",
      "Fold: 10  Epoch: 213  Training loss = 2.8767  Validation loss = 4.5367  \n",
      "\n",
      "Fold: 10  Epoch: 214  Training loss = 2.8764  Validation loss = 4.5365  \n",
      "\n",
      "Fold: 10  Epoch: 215  Training loss = 2.8762  Validation loss = 4.5363  \n",
      "\n",
      "Fold: 10  Epoch: 216  Training loss = 2.8761  Validation loss = 4.5361  \n",
      "\n",
      "Fold: 10  Epoch: 217  Training loss = 2.8757  Validation loss = 4.5350  \n",
      "\n",
      "Fold: 10  Epoch: 218  Training loss = 2.8754  Validation loss = 4.5344  \n",
      "\n",
      "Fold: 10  Epoch: 219  Training loss = 2.8749  Validation loss = 4.5328  \n",
      "\n",
      "Fold: 10  Epoch: 220  Training loss = 2.8745  Validation loss = 4.5318  \n",
      "\n",
      "Fold: 10  Epoch: 221  Training loss = 2.8737  Validation loss = 4.5280  \n",
      "\n",
      "Fold: 10  Epoch: 222  Training loss = 2.8731  Validation loss = 4.5252  \n",
      "\n",
      "Fold: 10  Epoch: 223  Training loss = 2.8726  Validation loss = 4.5234  \n",
      "\n",
      "Fold: 10  Epoch: 224  Training loss = 2.8722  Validation loss = 4.5216  \n",
      "\n",
      "Fold: 10  Epoch: 225  Training loss = 2.8720  Validation loss = 4.5212  \n",
      "\n",
      "Fold: 10  Epoch: 226  Training loss = 2.8715  Validation loss = 4.5190  \n",
      "\n",
      "Fold: 10  Epoch: 227  Training loss = 2.8711  Validation loss = 4.5180  \n",
      "\n",
      "Fold: 10  Epoch: 228  Training loss = 2.8710  Validation loss = 4.5181  \n",
      "\n",
      "Fold: 10  Epoch: 229  Training loss = 2.8707  Validation loss = 4.5175  \n",
      "\n",
      "Fold: 10  Epoch: 230  Training loss = 2.8701  Validation loss = 4.5148  \n",
      "\n",
      "Fold: 10  Epoch: 231  Training loss = 2.8699  Validation loss = 4.5142  \n",
      "\n",
      "Fold: 10  Epoch: 232  Training loss = 2.8695  Validation loss = 4.5131  \n",
      "\n",
      "Fold: 10  Epoch: 233  Training loss = 2.8691  Validation loss = 4.5122  \n",
      "\n",
      "Fold: 10  Epoch: 234  Training loss = 2.8688  Validation loss = 4.5110  \n",
      "\n",
      "Fold: 10  Epoch: 235  Training loss = 2.8684  Validation loss = 4.5093  \n",
      "\n",
      "Fold: 10  Epoch: 236  Training loss = 2.8679  Validation loss = 4.5071  \n",
      "\n",
      "Fold: 10  Epoch: 237  Training loss = 2.8675  Validation loss = 4.5062  \n",
      "\n",
      "Fold: 10  Epoch: 238  Training loss = 2.8670  Validation loss = 4.5040  \n",
      "\n",
      "Fold: 10  Epoch: 239  Training loss = 2.8670  Validation loss = 4.5050  \n",
      "\n",
      "Fold: 10  Epoch: 240  Training loss = 2.8666  Validation loss = 4.5035  \n",
      "\n",
      "Fold: 10  Epoch: 241  Training loss = 2.8662  Validation loss = 4.5027  \n",
      "\n",
      "Fold: 10  Epoch: 242  Training loss = 2.8661  Validation loss = 4.5026  \n",
      "\n",
      "Fold: 10  Epoch: 243  Training loss = 2.8660  Validation loss = 4.5028  \n",
      "\n",
      "Fold: 10  Epoch: 244  Training loss = 2.8656  Validation loss = 4.5012  \n",
      "\n",
      "Fold: 10  Epoch: 245  Training loss = 2.8652  Validation loss = 4.4994  \n",
      "\n",
      "Fold: 10  Epoch: 246  Training loss = 2.8646  Validation loss = 4.4969  \n",
      "\n",
      "Fold: 10  Epoch: 247  Training loss = 2.8639  Validation loss = 4.4940  \n",
      "\n",
      "Fold: 10  Epoch: 248  Training loss = 2.8634  Validation loss = 4.4923  \n",
      "\n",
      "Fold: 10  Epoch: 249  Training loss = 2.8630  Validation loss = 4.4905  \n",
      "\n",
      "Fold: 10  Epoch: 250  Training loss = 2.8628  Validation loss = 4.4900  \n",
      "\n",
      "Fold: 10  Epoch: 251  Training loss = 2.8623  Validation loss = 4.4876  \n",
      "\n",
      "Fold: 10  Epoch: 252  Training loss = 2.8619  Validation loss = 4.4872  \n",
      "\n",
      "Fold: 10  Epoch: 253  Training loss = 2.8615  Validation loss = 4.4858  \n",
      "\n",
      "Fold: 10  Epoch: 254  Training loss = 2.8611  Validation loss = 4.4838  \n",
      "\n",
      "Fold: 10  Epoch: 255  Training loss = 2.8607  Validation loss = 4.4823  \n",
      "\n",
      "Fold: 10  Epoch: 256  Training loss = 2.8606  Validation loss = 4.4822  \n",
      "\n",
      "Fold: 10  Epoch: 257  Training loss = 2.8603  Validation loss = 4.4815  \n",
      "\n",
      "Fold: 10  Epoch: 258  Training loss = 2.8599  Validation loss = 4.4802  \n",
      "\n",
      "Fold: 10  Epoch: 259  Training loss = 2.8596  Validation loss = 4.4799  \n",
      "\n",
      "Fold: 10  Epoch: 260  Training loss = 2.8592  Validation loss = 4.4786  \n",
      "\n",
      "Fold: 10  Epoch: 261  Training loss = 2.8589  Validation loss = 4.4785  \n",
      "\n",
      "Fold: 10  Epoch: 262  Training loss = 2.8581  Validation loss = 4.4751  \n",
      "\n",
      "Fold: 10  Epoch: 263  Training loss = 2.8579  Validation loss = 4.4746  \n",
      "\n",
      "Fold: 10  Epoch: 264  Training loss = 2.8575  Validation loss = 4.4728  \n",
      "\n",
      "Fold: 10  Epoch: 265  Training loss = 2.8570  Validation loss = 4.4718  \n",
      "\n",
      "Fold: 10  Epoch: 266  Training loss = 2.8569  Validation loss = 4.4727  \n",
      "\n",
      "Fold: 10  Epoch: 267  Training loss = 2.8567  Validation loss = 4.4724  \n",
      "\n",
      "Fold: 10  Epoch: 268  Training loss = 2.8562  Validation loss = 4.4704  \n",
      "\n",
      "Fold: 10  Epoch: 269  Training loss = 2.8555  Validation loss = 4.4671  \n",
      "\n",
      "Fold: 10  Epoch: 270  Training loss = 2.8550  Validation loss = 4.4647  \n",
      "\n",
      "Fold: 10  Epoch: 271  Training loss = 2.8548  Validation loss = 4.4644  \n",
      "\n",
      "Fold: 10  Epoch: 272  Training loss = 2.8545  Validation loss = 4.4641  \n",
      "\n",
      "Fold: 10  Epoch: 273  Training loss = 2.8540  Validation loss = 4.4628  \n",
      "\n",
      "Fold: 10  Epoch: 274  Training loss = 2.8535  Validation loss = 4.4608  \n",
      "\n",
      "Fold: 10  Epoch: 275  Training loss = 2.8530  Validation loss = 4.4597  \n",
      "\n",
      "Fold: 10  Epoch: 276  Training loss = 2.8529  Validation loss = 4.4601  \n",
      "\n",
      "Fold: 10  Epoch: 277  Training loss = 2.8525  Validation loss = 4.4591  \n",
      "\n",
      "Fold: 10  Epoch: 278  Training loss = 2.8520  Validation loss = 4.4576  \n",
      "\n",
      "Fold: 10  Epoch: 279  Training loss = 2.8517  Validation loss = 4.4572  \n",
      "\n",
      "Fold: 10  Epoch: 280  Training loss = 2.8512  Validation loss = 4.4551  \n",
      "\n",
      "Fold: 10  Epoch: 281  Training loss = 2.8509  Validation loss = 4.4539  \n",
      "\n",
      "Fold: 10  Epoch: 282  Training loss = 2.8505  Validation loss = 4.4532  \n",
      "\n",
      "Fold: 10  Epoch: 283  Training loss = 2.8504  Validation loss = 4.4532  \n",
      "\n",
      "Fold: 10  Epoch: 284  Training loss = 2.8503  Validation loss = 4.4538  \n",
      "\n",
      "Fold: 10  Epoch: 285  Training loss = 2.8500  Validation loss = 4.4531  \n",
      "\n",
      "Fold: 10  Epoch: 286  Training loss = 2.8494  Validation loss = 4.4502  \n",
      "\n",
      "Fold: 10  Epoch: 287  Training loss = 2.8488  Validation loss = 4.4474  \n",
      "\n",
      "Fold: 10  Epoch: 288  Training loss = 2.8484  Validation loss = 4.4462  \n",
      "\n",
      "Fold: 10  Epoch: 289  Training loss = 2.8480  Validation loss = 4.4448  \n",
      "\n",
      "Fold: 10  Epoch: 290  Training loss = 2.8478  Validation loss = 4.4444  \n",
      "\n",
      "Fold: 10  Epoch: 291  Training loss = 2.8475  Validation loss = 4.4435  \n",
      "\n",
      "Fold: 10  Epoch: 292  Training loss = 2.8473  Validation loss = 4.4435  \n",
      "\n",
      "Fold: 10  Epoch: 293  Training loss = 2.8469  Validation loss = 4.4426  \n",
      "\n",
      "Fold: 10  Epoch: 294  Training loss = 2.8466  Validation loss = 4.4422  \n",
      "\n",
      "Fold: 10  Epoch: 295  Training loss = 2.8460  Validation loss = 4.4401  \n",
      "\n",
      "Fold: 10  Epoch: 296  Training loss = 2.8452  Validation loss = 4.4365  \n",
      "\n",
      "Fold: 10  Epoch: 297  Training loss = 2.8450  Validation loss = 4.4364  \n",
      "\n",
      "Fold: 10  Epoch: 298  Training loss = 2.8448  Validation loss = 4.4357  \n",
      "\n",
      "Fold: 10  Epoch: 299  Training loss = 2.8448  Validation loss = 4.4367  \n",
      "\n",
      "Fold: 10  Epoch: 300  Training loss = 2.8440  Validation loss = 4.4328  \n",
      "\n",
      "Fold: 10  Epoch: 301  Training loss = 2.8436  Validation loss = 4.4315  \n",
      "\n",
      "Fold: 10  Epoch: 302  Training loss = 2.8432  Validation loss = 4.4309  \n",
      "\n",
      "Fold: 10  Epoch: 303  Training loss = 2.8427  Validation loss = 4.4288  \n",
      "\n",
      "Fold: 10  Epoch: 304  Training loss = 2.8425  Validation loss = 4.4292  \n",
      "\n",
      "Fold: 10  Epoch: 305  Training loss = 2.8424  Validation loss = 4.4296  \n",
      "\n",
      "Fold: 10  Epoch: 306  Training loss = 2.8421  Validation loss = 4.4288  \n",
      "\n",
      "Fold: 10  Epoch: 307  Training loss = 2.8416  Validation loss = 4.4270  \n",
      "\n",
      "Fold: 10  Epoch: 308  Training loss = 2.8413  Validation loss = 4.4261  \n",
      "\n",
      "Fold: 10  Epoch: 309  Training loss = 2.8407  Validation loss = 4.4240  \n",
      "\n",
      "Fold: 10  Epoch: 310  Training loss = 2.8404  Validation loss = 4.4228  \n",
      "\n",
      "Fold: 10  Epoch: 311  Training loss = 2.8399  Validation loss = 4.4210  \n",
      "\n",
      "Fold: 10  Epoch: 312  Training loss = 2.8396  Validation loss = 4.4199  \n",
      "\n",
      "Fold: 10  Epoch: 313  Training loss = 2.8391  Validation loss = 4.4185  \n",
      "\n",
      "Fold: 10  Epoch: 314  Training loss = 2.8388  Validation loss = 4.4174  \n",
      "\n",
      "Fold: 10  Epoch: 315  Training loss = 2.8385  Validation loss = 4.4169  \n",
      "\n",
      "Fold: 10  Epoch: 316  Training loss = 2.8379  Validation loss = 4.4144  \n",
      "\n",
      "Fold: 10  Epoch: 317  Training loss = 2.8375  Validation loss = 4.4126  \n",
      "\n",
      "Fold: 10  Epoch: 318  Training loss = 2.8372  Validation loss = 4.4122  \n",
      "\n",
      "Fold: 10  Epoch: 319  Training loss = 2.8369  Validation loss = 4.4114  \n",
      "\n",
      "Fold: 10  Epoch: 320  Training loss = 2.8364  Validation loss = 4.4098  \n",
      "\n",
      "Fold: 10  Epoch: 321  Training loss = 2.8363  Validation loss = 4.4104  \n",
      "\n",
      "Fold: 10  Epoch: 322  Training loss = 2.8360  Validation loss = 4.4096  \n",
      "\n",
      "Fold: 10  Epoch: 323  Training loss = 2.8355  Validation loss = 4.4078  \n",
      "\n",
      "Fold: 10  Epoch: 324  Training loss = 2.8350  Validation loss = 4.4055  \n",
      "\n",
      "Fold: 10  Epoch: 325  Training loss = 2.8346  Validation loss = 4.4037  \n",
      "\n",
      "Fold: 10  Epoch: 326  Training loss = 2.8345  Validation loss = 4.4047  \n",
      "\n",
      "Fold: 10  Epoch: 327  Training loss = 2.8340  Validation loss = 4.4033  \n",
      "\n",
      "Fold: 10  Epoch: 328  Training loss = 2.8338  Validation loss = 4.4032  \n",
      "\n",
      "Fold: 10  Epoch: 329  Training loss = 2.8335  Validation loss = 4.4018  \n",
      "\n",
      "Fold: 10  Epoch: 330  Training loss = 2.8332  Validation loss = 4.4016  \n",
      "\n",
      "Fold: 10  Epoch: 331  Training loss = 2.8329  Validation loss = 4.4000  \n",
      "\n",
      "Fold: 10  Epoch: 332  Training loss = 2.8325  Validation loss = 4.3985  \n",
      "\n",
      "Fold: 10  Epoch: 333  Training loss = 2.8322  Validation loss = 4.3980  \n",
      "\n",
      "Fold: 10  Epoch: 334  Training loss = 2.8319  Validation loss = 4.3975  \n",
      "\n",
      "Fold: 10  Epoch: 335  Training loss = 2.8314  Validation loss = 4.3955  \n",
      "\n",
      "Fold: 10  Epoch: 336  Training loss = 2.8312  Validation loss = 4.3955  \n",
      "\n",
      "Fold: 10  Epoch: 337  Training loss = 2.8305  Validation loss = 4.3925  \n",
      "\n",
      "Fold: 10  Epoch: 338  Training loss = 2.8301  Validation loss = 4.3909  \n",
      "\n",
      "Fold: 10  Epoch: 339  Training loss = 2.8299  Validation loss = 4.3903  \n",
      "\n",
      "Fold: 10  Epoch: 340  Training loss = 2.8294  Validation loss = 4.3876  \n",
      "\n",
      "Fold: 10  Epoch: 341  Training loss = 2.8288  Validation loss = 4.3855  \n",
      "\n",
      "Fold: 10  Epoch: 342  Training loss = 2.8285  Validation loss = 4.3847  \n",
      "\n",
      "Fold: 10  Epoch: 343  Training loss = 2.8283  Validation loss = 4.3847  \n",
      "\n",
      "Fold: 10  Epoch: 344  Training loss = 2.8279  Validation loss = 4.3827  \n",
      "\n",
      "Fold: 10  Epoch: 345  Training loss = 2.8273  Validation loss = 4.3800  \n",
      "\n",
      "Fold: 10  Epoch: 346  Training loss = 2.8269  Validation loss = 4.3780  \n",
      "\n",
      "Fold: 10  Epoch: 347  Training loss = 2.8267  Validation loss = 4.3775  \n",
      "\n",
      "Fold: 10  Epoch: 348  Training loss = 2.8264  Validation loss = 4.3766  \n",
      "\n",
      "Fold: 10  Epoch: 349  Training loss = 2.8261  Validation loss = 4.3761  \n",
      "\n",
      "Fold: 10  Epoch: 350  Training loss = 2.8258  Validation loss = 4.3750  \n",
      "\n",
      "Fold: 10  Epoch: 351  Training loss = 2.8254  Validation loss = 4.3743  \n",
      "\n",
      "Fold: 10  Epoch: 352  Training loss = 2.8247  Validation loss = 4.3706  \n",
      "\n",
      "Fold: 10  Epoch: 353  Training loss = 2.8246  Validation loss = 4.3717  \n",
      "\n",
      "Fold: 10  Epoch: 354  Training loss = 2.8242  Validation loss = 4.3696  \n",
      "\n",
      "Fold: 10  Epoch: 355  Training loss = 2.8241  Validation loss = 4.3707  \n",
      "\n",
      "Fold: 10  Epoch: 356  Training loss = 2.8238  Validation loss = 4.3706  \n",
      "\n",
      "Fold: 10  Epoch: 357  Training loss = 2.8236  Validation loss = 4.3703  \n",
      "\n",
      "Fold: 10  Epoch: 358  Training loss = 2.8232  Validation loss = 4.3686  \n",
      "\n",
      "Fold: 10  Epoch: 359  Training loss = 2.8228  Validation loss = 4.3670  \n",
      "\n",
      "Fold: 10  Epoch: 360  Training loss = 2.8224  Validation loss = 4.3653  \n",
      "\n",
      "Fold: 10  Epoch: 361  Training loss = 2.8219  Validation loss = 4.3627  \n",
      "\n",
      "Fold: 10  Epoch: 362  Training loss = 2.8216  Validation loss = 4.3622  \n",
      "\n",
      "Fold: 10  Epoch: 363  Training loss = 2.8214  Validation loss = 4.3612  \n",
      "\n",
      "Fold: 10  Epoch: 364  Training loss = 2.8210  Validation loss = 4.3594  \n",
      "\n",
      "Fold: 10  Epoch: 365  Training loss = 2.8205  Validation loss = 4.3569  \n",
      "\n",
      "Fold: 10  Epoch: 366  Training loss = 2.8203  Validation loss = 4.3574  \n",
      "\n",
      "Fold: 10  Epoch: 367  Training loss = 2.8200  Validation loss = 4.3563  \n",
      "\n",
      "Fold: 10  Epoch: 368  Training loss = 2.8196  Validation loss = 4.3555  \n",
      "\n",
      "Fold: 10  Epoch: 369  Training loss = 2.8189  Validation loss = 4.3522  \n",
      "\n",
      "Fold: 10  Epoch: 370  Training loss = 2.8187  Validation loss = 4.3512  \n",
      "\n",
      "Fold: 10  Epoch: 371  Training loss = 2.8182  Validation loss = 4.3494  \n",
      "\n",
      "Fold: 10  Epoch: 372  Training loss = 2.8178  Validation loss = 4.3480  \n",
      "\n",
      "Fold: 10  Epoch: 373  Training loss = 2.8173  Validation loss = 4.3463  \n",
      "\n",
      "Fold: 10  Epoch: 374  Training loss = 2.8170  Validation loss = 4.3452  \n",
      "\n",
      "Fold: 10  Epoch: 375  Training loss = 2.8164  Validation loss = 4.3421  \n",
      "\n",
      "Fold: 10  Epoch: 376  Training loss = 2.8160  Validation loss = 4.3414  \n",
      "\n",
      "Fold: 10  Epoch: 377  Training loss = 2.8157  Validation loss = 4.3408  \n",
      "\n",
      "Fold: 10  Epoch: 378  Training loss = 2.8153  Validation loss = 4.3397  \n",
      "\n",
      "Fold: 10  Epoch: 379  Training loss = 2.8149  Validation loss = 4.3385  \n",
      "\n",
      "Fold: 10  Epoch: 380  Training loss = 2.8146  Validation loss = 4.3373  \n",
      "\n",
      "Fold: 10  Epoch: 381  Training loss = 2.8143  Validation loss = 4.3367  \n",
      "\n",
      "Fold: 10  Epoch: 382  Training loss = 2.8140  Validation loss = 4.3364  \n",
      "\n",
      "Fold: 10  Epoch: 383  Training loss = 2.8134  Validation loss = 4.3326  \n",
      "\n",
      "Fold: 10  Epoch: 384  Training loss = 2.8131  Validation loss = 4.3324  \n",
      "\n",
      "Fold: 10  Epoch: 385  Training loss = 2.8128  Validation loss = 4.3319  \n",
      "\n",
      "Fold: 10  Epoch: 386  Training loss = 2.8125  Validation loss = 4.3312  \n",
      "\n",
      "Fold: 10  Epoch: 387  Training loss = 2.8121  Validation loss = 4.3303  \n",
      "\n",
      "Fold: 10  Epoch: 388  Training loss = 2.8118  Validation loss = 4.3291  \n",
      "\n",
      "Fold: 10  Epoch: 389  Training loss = 2.8116  Validation loss = 4.3283  \n",
      "\n",
      "Fold: 10  Epoch: 390  Training loss = 2.8114  Validation loss = 4.3286  \n",
      "\n",
      "Fold: 10  Epoch: 391  Training loss = 2.8113  Validation loss = 4.3294  \n",
      "\n",
      "Fold: 10  Epoch: 392  Training loss = 2.8109  Validation loss = 4.3283  \n",
      "\n",
      "Fold: 10  Epoch: 393  Training loss = 2.8104  Validation loss = 4.3259  \n",
      "\n",
      "Fold: 10  Epoch: 394  Training loss = 2.8099  Validation loss = 4.3238  \n",
      "\n",
      "Fold: 10  Epoch: 395  Training loss = 2.8094  Validation loss = 4.3218  \n",
      "\n",
      "Fold: 10  Epoch: 396  Training loss = 2.8092  Validation loss = 4.3220  \n",
      "\n",
      "Fold: 10  Epoch: 397  Training loss = 2.8088  Validation loss = 4.3205  \n",
      "\n",
      "Fold: 10  Epoch: 398  Training loss = 2.8084  Validation loss = 4.3194  \n",
      "\n",
      "Fold: 10  Epoch: 399  Training loss = 2.8083  Validation loss = 4.3210  \n",
      "\n",
      "Fold: 10  Epoch: 400  Training loss = 2.8080  Validation loss = 4.3205  \n",
      "\n",
      "Fold: 10  Epoch: 401  Training loss = 2.8078  Validation loss = 4.3207  \n",
      "\n",
      "Fold: 10  Epoch: 402  Training loss = 2.8075  Validation loss = 4.3198  \n",
      "\n",
      "Fold: 10  Epoch: 403  Training loss = 2.8070  Validation loss = 4.3168  \n",
      "\n",
      "Fold: 10  Epoch: 404  Training loss = 2.8068  Validation loss = 4.3163  \n",
      "\n",
      "Fold: 10  Epoch: 405  Training loss = 2.8065  Validation loss = 4.3162  \n",
      "\n",
      "Fold: 10  Epoch: 406  Training loss = 2.8060  Validation loss = 4.3148  \n",
      "\n",
      "Fold: 10  Epoch: 407  Training loss = 2.8054  Validation loss = 4.3118  \n",
      "\n",
      "Fold: 10  Epoch: 408  Training loss = 2.8052  Validation loss = 4.3113  \n",
      "\n",
      "Fold: 10  Epoch: 409  Training loss = 2.8050  Validation loss = 4.3111  \n",
      "\n",
      "Fold: 10  Epoch: 410  Training loss = 2.8046  Validation loss = 4.3100  \n",
      "\n",
      "Fold: 10  Epoch: 411  Training loss = 2.8044  Validation loss = 4.3102  \n",
      "\n",
      "Fold: 10  Epoch: 412  Training loss = 2.8040  Validation loss = 4.3082  \n",
      "\n",
      "Fold: 10  Epoch: 413  Training loss = 2.8037  Validation loss = 4.3071  \n",
      "\n",
      "Fold: 10  Epoch: 414  Training loss = 2.8033  Validation loss = 4.3057  \n",
      "\n",
      "Fold: 10  Epoch: 415  Training loss = 2.8030  Validation loss = 4.3046  \n",
      "\n",
      "Fold: 10  Epoch: 416  Training loss = 2.8027  Validation loss = 4.3044  \n",
      "\n",
      "Fold: 10  Epoch: 417  Training loss = 2.8023  Validation loss = 4.3029  \n",
      "\n",
      "Fold: 10  Epoch: 418  Training loss = 2.8020  Validation loss = 4.3026  \n",
      "\n",
      "Fold: 10  Epoch: 419  Training loss = 2.8016  Validation loss = 4.3009  \n",
      "\n",
      "Fold: 10  Epoch: 420  Training loss = 2.8014  Validation loss = 4.3008  \n",
      "\n",
      "Fold: 10  Epoch: 421  Training loss = 2.8011  Validation loss = 4.3007  \n",
      "\n",
      "Fold: 10  Epoch: 422  Training loss = 2.8007  Validation loss = 4.3008  \n",
      "\n",
      "Fold: 10  Epoch: 423  Training loss = 2.8003  Validation loss = 4.2993  \n",
      "\n",
      "Fold: 10  Epoch: 424  Training loss = 2.7999  Validation loss = 4.2977  \n",
      "\n",
      "Fold: 10  Epoch: 425  Training loss = 2.7994  Validation loss = 4.2956  \n",
      "\n",
      "Fold: 10  Epoch: 426  Training loss = 2.7991  Validation loss = 4.2951  \n",
      "\n",
      "Fold: 10  Epoch: 427  Training loss = 2.7989  Validation loss = 4.2955  \n",
      "\n",
      "Fold: 10  Epoch: 428  Training loss = 2.7986  Validation loss = 4.2952  \n",
      "\n",
      "Fold: 10  Epoch: 429  Training loss = 2.7983  Validation loss = 4.2949  \n",
      "\n",
      "Fold: 10  Epoch: 430  Training loss = 2.7980  Validation loss = 4.2942  \n",
      "\n",
      "Fold: 10  Epoch: 431  Training loss = 2.7977  Validation loss = 4.2940  \n",
      "\n",
      "Fold: 10  Epoch: 432  Training loss = 2.7973  Validation loss = 4.2926  \n",
      "\n",
      "Fold: 10  Epoch: 433  Training loss = 2.7969  Validation loss = 4.2904  \n",
      "\n",
      "Fold: 10  Epoch: 434  Training loss = 2.7963  Validation loss = 4.2874  \n",
      "\n",
      "Fold: 10  Epoch: 435  Training loss = 2.7959  Validation loss = 4.2854  \n",
      "\n",
      "Fold: 10  Epoch: 436  Training loss = 2.7958  Validation loss = 4.2871  \n",
      "\n",
      "Fold: 10  Epoch: 437  Training loss = 2.7954  Validation loss = 4.2862  \n",
      "\n",
      "Fold: 10  Epoch: 438  Training loss = 2.7949  Validation loss = 4.2833  \n",
      "\n",
      "Fold: 10  Epoch: 439  Training loss = 2.7944  Validation loss = 4.2808  \n",
      "\n",
      "Fold: 10  Epoch: 440  Training loss = 2.7941  Validation loss = 4.2807  \n",
      "\n",
      "Fold: 10  Epoch: 441  Training loss = 2.7938  Validation loss = 4.2795  \n",
      "\n",
      "Fold: 10  Epoch: 442  Training loss = 2.7935  Validation loss = 4.2780  \n",
      "\n",
      "Fold: 10  Epoch: 443  Training loss = 2.7931  Validation loss = 4.2756  \n",
      "\n",
      "Fold: 10  Epoch: 444  Training loss = 2.7928  Validation loss = 4.2746  \n",
      "\n",
      "Fold: 10  Epoch: 445  Training loss = 2.7924  Validation loss = 4.2732  \n",
      "\n",
      "Fold: 10  Epoch: 446  Training loss = 2.7921  Validation loss = 4.2721  \n",
      "\n",
      "Fold: 10  Epoch: 447  Training loss = 2.7919  Validation loss = 4.2715  \n",
      "\n",
      "Fold: 10  Epoch: 448  Training loss = 2.7915  Validation loss = 4.2698  \n",
      "\n",
      "Fold: 10  Epoch: 449  Training loss = 2.7911  Validation loss = 4.2687  \n",
      "\n",
      "Fold: 10  Epoch: 450  Training loss = 2.7908  Validation loss = 4.2676  \n",
      "\n",
      "Fold: 10  Epoch: 451  Training loss = 2.7905  Validation loss = 4.2672  \n",
      "\n",
      "Fold: 10  Epoch: 452  Training loss = 2.7902  Validation loss = 4.2662  \n",
      "\n",
      "Fold: 10  Epoch: 453  Training loss = 2.7898  Validation loss = 4.2648  \n",
      "\n",
      "Fold: 10  Epoch: 454  Training loss = 2.7896  Validation loss = 4.2639  \n",
      "\n",
      "Fold: 10  Epoch: 455  Training loss = 2.7892  Validation loss = 4.2625  \n",
      "\n",
      "Fold: 10  Epoch: 456  Training loss = 2.7891  Validation loss = 4.2632  \n",
      "\n",
      "Fold: 10  Epoch: 457  Training loss = 2.7888  Validation loss = 4.2623  \n",
      "\n",
      "Fold: 10  Epoch: 458  Training loss = 2.7884  Validation loss = 4.2600  \n",
      "\n",
      "Fold: 10  Epoch: 459  Training loss = 2.7879  Validation loss = 4.2577  \n",
      "\n",
      "Fold: 10  Epoch: 460  Training loss = 2.7874  Validation loss = 4.2561  \n",
      "\n",
      "Fold: 10  Epoch: 461  Training loss = 2.7872  Validation loss = 4.2569  \n",
      "\n",
      "Fold: 10  Epoch: 462  Training loss = 2.7867  Validation loss = 4.2543  \n",
      "\n",
      "Fold: 10  Epoch: 463  Training loss = 2.7865  Validation loss = 4.2560  \n",
      "\n",
      "Fold: 10  Epoch: 464  Training loss = 2.7864  Validation loss = 4.2558  \n",
      "\n",
      "Fold: 10  Epoch: 465  Training loss = 2.7862  Validation loss = 4.2558  \n",
      "\n",
      "Fold: 10  Epoch: 466  Training loss = 2.7861  Validation loss = 4.2576  \n",
      "\n",
      "Fold: 10  Epoch: 467  Training loss = 2.7859  Validation loss = 4.2583  \n",
      "\n",
      "Fold: 10  Epoch: 468  Training loss = 2.7857  Validation loss = 4.2586  \n",
      "\n",
      "Check model:  Fold: 10  Epoch: 462  Training loss = 2.7857  Validation loss = 4.2586  \n",
      "\n",
      "Fold: 11  Epoch: 1  Training loss = 2.9034  Validation loss = 1.5293  \n",
      "\n",
      "Fold: 11  Epoch: 2  Training loss = 2.9025  Validation loss = 1.5279  \n",
      "\n",
      "Fold: 11  Epoch: 3  Training loss = 2.9013  Validation loss = 1.5259  \n",
      "\n",
      "Fold: 11  Epoch: 4  Training loss = 2.9005  Validation loss = 1.5250  \n",
      "\n",
      "Fold: 11  Epoch: 5  Training loss = 2.8990  Validation loss = 1.5225  \n",
      "\n",
      "Fold: 11  Epoch: 6  Training loss = 2.8978  Validation loss = 1.5207  \n",
      "\n",
      "Fold: 11  Epoch: 7  Training loss = 2.8966  Validation loss = 1.5188  \n",
      "\n",
      "Fold: 11  Epoch: 8  Training loss = 2.8958  Validation loss = 1.5178  \n",
      "\n",
      "Fold: 11  Epoch: 9  Training loss = 2.8954  Validation loss = 1.5174  \n",
      "\n",
      "Fold: 11  Epoch: 10  Training loss = 2.8945  Validation loss = 1.5163  \n",
      "\n",
      "Fold: 11  Epoch: 11  Training loss = 2.8932  Validation loss = 1.5146  \n",
      "\n",
      "Fold: 11  Epoch: 12  Training loss = 2.8921  Validation loss = 1.5133  \n",
      "\n",
      "Fold: 11  Epoch: 13  Training loss = 2.8914  Validation loss = 1.5123  \n",
      "\n",
      "Fold: 11  Epoch: 14  Training loss = 2.8899  Validation loss = 1.5096  \n",
      "\n",
      "Fold: 11  Epoch: 15  Training loss = 2.8889  Validation loss = 1.5083  \n",
      "\n",
      "Fold: 11  Epoch: 16  Training loss = 2.8879  Validation loss = 1.5067  \n",
      "\n",
      "Fold: 11  Epoch: 17  Training loss = 2.8869  Validation loss = 1.5050  \n",
      "\n",
      "Fold: 11  Epoch: 18  Training loss = 2.8863  Validation loss = 1.5044  \n",
      "\n",
      "Fold: 11  Epoch: 19  Training loss = 2.8858  Validation loss = 1.5039  \n",
      "\n",
      "Fold: 11  Epoch: 20  Training loss = 2.8850  Validation loss = 1.5027  \n",
      "\n",
      "Fold: 11  Epoch: 21  Training loss = 2.8842  Validation loss = 1.5015  \n",
      "\n",
      "Fold: 11  Epoch: 22  Training loss = 2.8832  Validation loss = 1.5002  \n",
      "\n",
      "Fold: 11  Epoch: 23  Training loss = 2.8822  Validation loss = 1.4987  \n",
      "\n",
      "Fold: 11  Epoch: 24  Training loss = 2.8812  Validation loss = 1.4976  \n",
      "\n",
      "Fold: 11  Epoch: 25  Training loss = 2.8805  Validation loss = 1.4967  \n",
      "\n",
      "Fold: 11  Epoch: 26  Training loss = 2.8800  Validation loss = 1.4964  \n",
      "\n",
      "Fold: 11  Epoch: 27  Training loss = 2.8795  Validation loss = 1.4959  \n",
      "\n",
      "Fold: 11  Epoch: 28  Training loss = 2.8787  Validation loss = 1.4950  \n",
      "\n",
      "Fold: 11  Epoch: 29  Training loss = 2.8782  Validation loss = 1.4942  \n",
      "\n",
      "Fold: 11  Epoch: 30  Training loss = 2.8769  Validation loss = 1.4926  \n",
      "\n",
      "Fold: 11  Epoch: 31  Training loss = 2.8756  Validation loss = 1.4912  \n",
      "\n",
      "Fold: 11  Epoch: 32  Training loss = 2.8745  Validation loss = 1.4897  \n",
      "\n",
      "Fold: 11  Epoch: 33  Training loss = 2.8737  Validation loss = 1.4884  \n",
      "\n",
      "Fold: 11  Epoch: 34  Training loss = 2.8731  Validation loss = 1.4875  \n",
      "\n",
      "Fold: 11  Epoch: 35  Training loss = 2.8723  Validation loss = 1.4863  \n",
      "\n",
      "Fold: 11  Epoch: 36  Training loss = 2.8715  Validation loss = 1.4852  \n",
      "\n",
      "Fold: 11  Epoch: 37  Training loss = 2.8705  Validation loss = 1.4838  \n",
      "\n",
      "Fold: 11  Epoch: 38  Training loss = 2.8698  Validation loss = 1.4828  \n",
      "\n",
      "Fold: 11  Epoch: 39  Training loss = 2.8690  Validation loss = 1.4821  \n",
      "\n",
      "Fold: 11  Epoch: 40  Training loss = 2.8681  Validation loss = 1.4809  \n",
      "\n",
      "Fold: 11  Epoch: 41  Training loss = 2.8669  Validation loss = 1.4794  \n",
      "\n",
      "Fold: 11  Epoch: 42  Training loss = 2.8661  Validation loss = 1.4782  \n",
      "\n",
      "Fold: 11  Epoch: 43  Training loss = 2.8653  Validation loss = 1.4769  \n",
      "\n",
      "Fold: 11  Epoch: 44  Training loss = 2.8644  Validation loss = 1.4757  \n",
      "\n",
      "Fold: 11  Epoch: 45  Training loss = 2.8638  Validation loss = 1.4750  \n",
      "\n",
      "Fold: 11  Epoch: 46  Training loss = 2.8628  Validation loss = 1.4740  \n",
      "\n",
      "Fold: 11  Epoch: 47  Training loss = 2.8618  Validation loss = 1.4726  \n",
      "\n",
      "Fold: 11  Epoch: 48  Training loss = 2.8615  Validation loss = 1.4726  \n",
      "\n",
      "Fold: 11  Epoch: 49  Training loss = 2.8606  Validation loss = 1.4714  \n",
      "\n",
      "Fold: 11  Epoch: 50  Training loss = 2.8602  Validation loss = 1.4710  \n",
      "\n",
      "Fold: 11  Epoch: 51  Training loss = 2.8597  Validation loss = 1.4706  \n",
      "\n",
      "Fold: 11  Epoch: 52  Training loss = 2.8587  Validation loss = 1.4693  \n",
      "\n",
      "Fold: 11  Epoch: 53  Training loss = 2.8572  Validation loss = 1.4682  \n",
      "\n",
      "Fold: 11  Epoch: 54  Training loss = 2.8524  Validation loss = 1.4672  \n",
      "\n",
      "Fold: 11  Epoch: 55  Training loss = 2.8514  Validation loss = 1.4659  \n",
      "\n",
      "Fold: 11  Epoch: 56  Training loss = 2.8506  Validation loss = 1.4652  \n",
      "\n",
      "Fold: 11  Epoch: 57  Training loss = 2.8498  Validation loss = 1.4641  \n",
      "\n",
      "Fold: 11  Epoch: 58  Training loss = 2.8488  Validation loss = 1.4628  \n",
      "\n",
      "Fold: 11  Epoch: 59  Training loss = 2.8477  Validation loss = 1.4612  \n",
      "\n",
      "Fold: 11  Epoch: 60  Training loss = 2.8470  Validation loss = 1.4603  \n",
      "\n",
      "Fold: 11  Epoch: 61  Training loss = 2.8460  Validation loss = 1.4590  \n",
      "\n",
      "Fold: 11  Epoch: 62  Training loss = 2.8453  Validation loss = 1.4581  \n",
      "\n",
      "Fold: 11  Epoch: 63  Training loss = 2.8445  Validation loss = 1.4570  \n",
      "\n",
      "Fold: 11  Epoch: 64  Training loss = 2.8438  Validation loss = 1.4562  \n",
      "\n",
      "Fold: 11  Epoch: 65  Training loss = 2.8434  Validation loss = 1.4558  \n",
      "\n",
      "Fold: 11  Epoch: 66  Training loss = 2.8424  Validation loss = 1.4545  \n",
      "\n",
      "Fold: 11  Epoch: 67  Training loss = 2.8418  Validation loss = 1.4540  \n",
      "\n",
      "Fold: 11  Epoch: 68  Training loss = 2.8415  Validation loss = 1.4536  \n",
      "\n",
      "Fold: 11  Epoch: 69  Training loss = 2.8409  Validation loss = 1.4530  \n",
      "\n",
      "Fold: 11  Epoch: 70  Training loss = 2.8404  Validation loss = 1.4525  \n",
      "\n",
      "Fold: 11  Epoch: 71  Training loss = 2.8394  Validation loss = 1.4512  \n",
      "\n",
      "Fold: 11  Epoch: 72  Training loss = 2.8388  Validation loss = 1.4506  \n",
      "\n",
      "Fold: 11  Epoch: 73  Training loss = 2.8379  Validation loss = 1.4491  \n",
      "\n",
      "Fold: 11  Epoch: 74  Training loss = 2.8373  Validation loss = 1.4487  \n",
      "\n",
      "Fold: 11  Epoch: 75  Training loss = 2.8361  Validation loss = 1.4476  \n",
      "\n",
      "Fold: 11  Epoch: 76  Training loss = 2.8354  Validation loss = 1.4470  \n",
      "\n",
      "Fold: 11  Epoch: 77  Training loss = 2.8349  Validation loss = 1.4467  \n",
      "\n",
      "Fold: 11  Epoch: 78  Training loss = 2.8344  Validation loss = 1.4463  \n",
      "\n",
      "Fold: 11  Epoch: 79  Training loss = 2.8341  Validation loss = 1.4461  \n",
      "\n",
      "Fold: 11  Epoch: 80  Training loss = 2.8336  Validation loss = 1.4458  \n",
      "\n",
      "Fold: 11  Epoch: 81  Training loss = 2.8327  Validation loss = 1.4448  \n",
      "\n",
      "Fold: 11  Epoch: 82  Training loss = 2.8320  Validation loss = 1.4439  \n",
      "\n",
      "Fold: 11  Epoch: 83  Training loss = 2.8309  Validation loss = 1.4427  \n",
      "\n",
      "Fold: 11  Epoch: 84  Training loss = 2.8302  Validation loss = 1.4419  \n",
      "\n",
      "Fold: 11  Epoch: 85  Training loss = 2.8297  Validation loss = 1.4415  \n",
      "\n",
      "Fold: 11  Epoch: 86  Training loss = 2.8291  Validation loss = 1.4412  \n",
      "\n",
      "Fold: 11  Epoch: 87  Training loss = 2.8283  Validation loss = 1.4406  \n",
      "\n",
      "Fold: 11  Epoch: 88  Training loss = 2.8278  Validation loss = 1.4402  \n",
      "\n",
      "Fold: 11  Epoch: 89  Training loss = 2.8270  Validation loss = 1.4395  \n",
      "\n",
      "Fold: 11  Epoch: 90  Training loss = 2.8265  Validation loss = 1.4391  \n",
      "\n",
      "Fold: 11  Epoch: 91  Training loss = 2.8259  Validation loss = 1.4385  \n",
      "\n",
      "Fold: 11  Epoch: 92  Training loss = 2.8251  Validation loss = 1.4379  \n",
      "\n",
      "Fold: 11  Epoch: 93  Training loss = 2.8243  Validation loss = 1.4366  \n",
      "\n",
      "Fold: 11  Epoch: 94  Training loss = 2.8235  Validation loss = 1.4356  \n",
      "\n",
      "Fold: 11  Epoch: 95  Training loss = 2.8231  Validation loss = 1.4354  \n",
      "\n",
      "Fold: 11  Epoch: 96  Training loss = 2.8222  Validation loss = 1.4345  \n",
      "\n",
      "Fold: 11  Epoch: 97  Training loss = 2.8215  Validation loss = 1.4340  \n",
      "\n",
      "Fold: 11  Epoch: 98  Training loss = 2.8207  Validation loss = 1.4332  \n",
      "\n",
      "Fold: 11  Epoch: 99  Training loss = 2.8198  Validation loss = 1.4321  \n",
      "\n",
      "Fold: 11  Epoch: 100  Training loss = 2.8193  Validation loss = 1.4315  \n",
      "\n",
      "Fold: 11  Epoch: 101  Training loss = 2.8184  Validation loss = 1.4308  \n",
      "\n",
      "Fold: 11  Epoch: 102  Training loss = 2.8176  Validation loss = 1.4301  \n",
      "\n",
      "Fold: 11  Epoch: 103  Training loss = 2.8170  Validation loss = 1.4297  \n",
      "\n",
      "Fold: 11  Epoch: 104  Training loss = 2.8161  Validation loss = 1.4287  \n",
      "\n",
      "Fold: 11  Epoch: 105  Training loss = 2.8154  Validation loss = 1.4283  \n",
      "\n",
      "Fold: 11  Epoch: 106  Training loss = 2.8149  Validation loss = 1.4279  \n",
      "\n",
      "Fold: 11  Epoch: 107  Training loss = 2.8139  Validation loss = 1.4271  \n",
      "\n",
      "Fold: 11  Epoch: 108  Training loss = 2.8135  Validation loss = 1.4267  \n",
      "\n",
      "Fold: 11  Epoch: 109  Training loss = 2.8129  Validation loss = 1.4260  \n",
      "\n",
      "Fold: 11  Epoch: 110  Training loss = 2.8120  Validation loss = 1.4254  \n",
      "\n",
      "Fold: 11  Epoch: 111  Training loss = 2.8115  Validation loss = 1.4250  \n",
      "\n",
      "Fold: 11  Epoch: 112  Training loss = 2.8107  Validation loss = 1.4242  \n",
      "\n",
      "Fold: 11  Epoch: 113  Training loss = 2.8105  Validation loss = 1.4243  \n",
      "\n",
      "Fold: 11  Epoch: 114  Training loss = 2.8098  Validation loss = 1.4239  \n",
      "\n",
      "Fold: 11  Epoch: 115  Training loss = 2.8092  Validation loss = 1.4235  \n",
      "\n",
      "Fold: 11  Epoch: 116  Training loss = 2.8089  Validation loss = 1.4237  \n",
      "\n",
      "Fold: 11  Epoch: 117  Training loss = 2.8085  Validation loss = 1.4237  \n",
      "\n",
      "Fold: 11  Epoch: 118  Training loss = 2.8080  Validation loss = 1.4235  \n",
      "\n",
      "Fold: 11  Epoch: 119  Training loss = 2.8071  Validation loss = 1.4228  \n",
      "\n",
      "Fold: 11  Epoch: 120  Training loss = 2.8067  Validation loss = 1.4226  \n",
      "\n",
      "Fold: 11  Epoch: 121  Training loss = 2.8062  Validation loss = 1.4223  \n",
      "\n",
      "Fold: 11  Epoch: 122  Training loss = 2.8053  Validation loss = 1.4216  \n",
      "\n",
      "Fold: 11  Epoch: 123  Training loss = 2.8046  Validation loss = 1.4212  \n",
      "\n",
      "Fold: 11  Epoch: 124  Training loss = 2.8040  Validation loss = 1.4207  \n",
      "\n",
      "Fold: 11  Epoch: 125  Training loss = 2.8030  Validation loss = 1.4201  \n",
      "\n",
      "Fold: 11  Epoch: 126  Training loss = 2.8024  Validation loss = 1.4199  \n",
      "\n",
      "Fold: 11  Epoch: 127  Training loss = 2.8019  Validation loss = 1.4194  \n",
      "\n",
      "Fold: 11  Epoch: 128  Training loss = 2.8013  Validation loss = 1.4192  \n",
      "\n",
      "Fold: 11  Epoch: 129  Training loss = 2.8006  Validation loss = 1.4186  \n",
      "\n",
      "Fold: 11  Epoch: 130  Training loss = 2.7998  Validation loss = 1.4178  \n",
      "\n",
      "Fold: 11  Epoch: 131  Training loss = 2.7993  Validation loss = 1.4175  \n",
      "\n",
      "Fold: 11  Epoch: 132  Training loss = 2.7985  Validation loss = 1.4168  \n",
      "\n",
      "Fold: 11  Epoch: 133  Training loss = 2.7977  Validation loss = 1.4160  \n",
      "\n",
      "Fold: 11  Epoch: 134  Training loss = 2.7973  Validation loss = 1.4159  \n",
      "\n",
      "Fold: 11  Epoch: 135  Training loss = 2.7965  Validation loss = 1.4149  \n",
      "\n",
      "Fold: 11  Epoch: 136  Training loss = 2.7959  Validation loss = 1.4144  \n",
      "\n",
      "Fold: 11  Epoch: 137  Training loss = 2.7951  Validation loss = 1.4139  \n",
      "\n",
      "Fold: 11  Epoch: 138  Training loss = 2.7945  Validation loss = 1.4135  \n",
      "\n",
      "Fold: 11  Epoch: 139  Training loss = 2.7938  Validation loss = 1.4128  \n",
      "\n",
      "Fold: 11  Epoch: 140  Training loss = 2.7933  Validation loss = 1.4122  \n",
      "\n",
      "Fold: 11  Epoch: 141  Training loss = 2.7927  Validation loss = 1.4118  \n",
      "\n",
      "Fold: 11  Epoch: 142  Training loss = 2.7916  Validation loss = 1.4111  \n",
      "\n",
      "Fold: 11  Epoch: 143  Training loss = 2.7901  Validation loss = 1.4105  \n",
      "\n",
      "Fold: 11  Epoch: 144  Training loss = 2.7895  Validation loss = 1.4104  \n",
      "\n",
      "Fold: 11  Epoch: 145  Training loss = 2.7889  Validation loss = 1.4102  \n",
      "\n",
      "Fold: 11  Epoch: 146  Training loss = 2.7882  Validation loss = 1.4098  \n",
      "\n",
      "Fold: 11  Epoch: 147  Training loss = 2.7875  Validation loss = 1.4097  \n",
      "\n",
      "Fold: 11  Epoch: 148  Training loss = 2.7842  Validation loss = 1.4093  \n",
      "\n",
      "Fold: 11  Epoch: 149  Training loss = 2.7837  Validation loss = 1.4091  \n",
      "\n",
      "Fold: 11  Epoch: 150  Training loss = 2.7830  Validation loss = 1.4081  \n",
      "\n",
      "Fold: 11  Epoch: 151  Training loss = 2.7825  Validation loss = 1.4076  \n",
      "\n",
      "Fold: 11  Epoch: 152  Training loss = 2.7818  Validation loss = 1.4075  \n",
      "\n",
      "Fold: 11  Epoch: 153  Training loss = 2.7814  Validation loss = 1.4075  \n",
      "\n",
      "Fold: 11  Epoch: 154  Training loss = 2.7806  Validation loss = 1.4073  \n",
      "\n",
      "Fold: 11  Epoch: 155  Training loss = 2.7801  Validation loss = 1.4070  \n",
      "\n",
      "Fold: 11  Epoch: 156  Training loss = 2.7795  Validation loss = 1.4067  \n",
      "\n",
      "Fold: 11  Epoch: 157  Training loss = 2.7785  Validation loss = 1.4064  \n",
      "\n",
      "Fold: 11  Epoch: 158  Training loss = 2.7778  Validation loss = 1.4063  \n",
      "\n",
      "Fold: 11  Epoch: 159  Training loss = 2.7768  Validation loss = 1.4055  \n",
      "\n",
      "Fold: 11  Epoch: 160  Training loss = 2.7761  Validation loss = 1.4049  \n",
      "\n",
      "Fold: 11  Epoch: 161  Training loss = 2.7753  Validation loss = 1.4045  \n",
      "\n",
      "Fold: 11  Epoch: 162  Training loss = 2.7748  Validation loss = 1.4044  \n",
      "\n",
      "Fold: 11  Epoch: 163  Training loss = 2.7743  Validation loss = 1.4040  \n",
      "\n",
      "Fold: 11  Epoch: 164  Training loss = 2.7736  Validation loss = 1.4039  \n",
      "\n",
      "Fold: 11  Epoch: 165  Training loss = 2.7731  Validation loss = 1.4037  \n",
      "\n",
      "Fold: 11  Epoch: 166  Training loss = 2.7723  Validation loss = 1.4033  \n",
      "\n",
      "Fold: 11  Epoch: 167  Training loss = 2.7717  Validation loss = 1.4029  \n",
      "\n",
      "Fold: 11  Epoch: 168  Training loss = 2.7710  Validation loss = 1.4023  \n",
      "\n",
      "Fold: 11  Epoch: 169  Training loss = 2.7707  Validation loss = 1.4025  \n",
      "\n",
      "Fold: 11  Epoch: 170  Training loss = 2.7701  Validation loss = 1.4023  \n",
      "\n",
      "Fold: 11  Epoch: 171  Training loss = 2.7694  Validation loss = 1.4020  \n",
      "\n",
      "Fold: 11  Epoch: 172  Training loss = 2.7686  Validation loss = 1.4019  \n",
      "\n",
      "Fold: 11  Epoch: 173  Training loss = 2.7679  Validation loss = 1.4017  \n",
      "\n",
      "Fold: 11  Epoch: 174  Training loss = 2.7672  Validation loss = 1.4019  \n",
      "\n",
      "Fold: 11  Epoch: 175  Training loss = 2.7665  Validation loss = 1.4017  \n",
      "\n",
      "Fold: 11  Epoch: 176  Training loss = 2.7658  Validation loss = 1.4015  \n",
      "\n",
      "Fold: 11  Epoch: 177  Training loss = 2.7652  Validation loss = 1.4013  \n",
      "\n",
      "Fold: 11  Epoch: 178  Training loss = 2.7646  Validation loss = 1.4008  \n",
      "\n",
      "Fold: 11  Epoch: 179  Training loss = 2.7637  Validation loss = 1.4007  \n",
      "\n",
      "Fold: 11  Epoch: 180  Training loss = 2.7630  Validation loss = 1.4006  \n",
      "\n",
      "Fold: 11  Epoch: 181  Training loss = 2.7620  Validation loss = 1.4003  \n",
      "\n",
      "Fold: 11  Epoch: 182  Training loss = 2.7613  Validation loss = 1.4002  \n",
      "\n",
      "Fold: 11  Epoch: 183  Training loss = 2.7605  Validation loss = 1.3997  \n",
      "\n",
      "Fold: 11  Epoch: 184  Training loss = 2.7598  Validation loss = 1.3997  \n",
      "\n",
      "Fold: 11  Epoch: 185  Training loss = 2.7592  Validation loss = 1.3992  \n",
      "\n",
      "Fold: 11  Epoch: 186  Training loss = 2.7587  Validation loss = 1.3993  \n",
      "\n",
      "Fold: 11  Epoch: 187  Training loss = 2.7581  Validation loss = 1.3992  \n",
      "\n",
      "Fold: 11  Epoch: 188  Training loss = 2.7575  Validation loss = 1.3990  \n",
      "\n",
      "Fold: 11  Epoch: 189  Training loss = 2.7570  Validation loss = 1.3991  \n",
      "\n",
      "Fold: 11  Epoch: 190  Training loss = 2.7560  Validation loss = 1.3986  \n",
      "\n",
      "Fold: 11  Epoch: 191  Training loss = 2.7551  Validation loss = 1.3983  \n",
      "\n",
      "Fold: 11  Epoch: 192  Training loss = 2.7546  Validation loss = 1.3980  \n",
      "\n",
      "Fold: 11  Epoch: 193  Training loss = 2.7537  Validation loss = 1.3975  \n",
      "\n",
      "Fold: 11  Epoch: 194  Training loss = 2.7528  Validation loss = 1.3974  \n",
      "\n",
      "Fold: 11  Epoch: 195  Training loss = 2.7520  Validation loss = 1.3973  \n",
      "\n",
      "Fold: 11  Epoch: 196  Training loss = 2.7517  Validation loss = 1.3974  \n",
      "\n",
      "Fold: 11  Epoch: 197  Training loss = 2.7511  Validation loss = 1.3970  \n",
      "\n",
      "Fold: 11  Epoch: 198  Training loss = 2.7506  Validation loss = 1.3971  \n",
      "\n",
      "Fold: 11  Epoch: 199  Training loss = 2.7498  Validation loss = 1.3970  \n",
      "\n",
      "Fold: 11  Epoch: 200  Training loss = 2.7494  Validation loss = 1.3970  \n",
      "\n",
      "Fold: 11  Epoch: 201  Training loss = 2.7489  Validation loss = 1.3967  \n",
      "\n",
      "Fold: 11  Epoch: 202  Training loss = 2.7484  Validation loss = 1.3966  \n",
      "\n",
      "Fold: 11  Epoch: 203  Training loss = 2.7478  Validation loss = 1.3962  \n",
      "\n",
      "Fold: 11  Epoch: 204  Training loss = 2.7471  Validation loss = 1.3958  \n",
      "\n",
      "Fold: 11  Epoch: 205  Training loss = 2.7466  Validation loss = 1.3957  \n",
      "\n",
      "Fold: 11  Epoch: 206  Training loss = 2.7462  Validation loss = 1.3957  \n",
      "\n",
      "Fold: 11  Epoch: 207  Training loss = 2.7459  Validation loss = 1.3958  \n",
      "\n",
      "Fold: 11  Epoch: 208  Training loss = 2.7455  Validation loss = 1.3955  \n",
      "\n",
      "Fold: 11  Epoch: 209  Training loss = 2.7450  Validation loss = 1.3950  \n",
      "\n",
      "Fold: 11  Epoch: 210  Training loss = 2.7446  Validation loss = 1.3948  \n",
      "\n",
      "Fold: 11  Epoch: 211  Training loss = 2.7441  Validation loss = 1.3945  \n",
      "\n",
      "Fold: 11  Epoch: 212  Training loss = 2.7433  Validation loss = 1.3948  \n",
      "\n",
      "Fold: 11  Epoch: 213  Training loss = 2.7428  Validation loss = 1.3946  \n",
      "\n",
      "Fold: 11  Epoch: 214  Training loss = 2.7423  Validation loss = 1.3944  \n",
      "\n",
      "Fold: 11  Epoch: 215  Training loss = 2.7415  Validation loss = 1.3944  \n",
      "\n",
      "Fold: 11  Epoch: 216  Training loss = 2.7408  Validation loss = 1.3945  \n",
      "\n",
      "Fold: 11  Epoch: 217  Training loss = 2.7400  Validation loss = 1.3945  \n",
      "\n",
      "Fold: 11  Epoch: 218  Training loss = 2.7395  Validation loss = 1.3945  \n",
      "\n",
      "Fold: 11  Epoch: 219  Training loss = 2.7390  Validation loss = 1.3943  \n",
      "\n",
      "Fold: 11  Epoch: 220  Training loss = 2.7385  Validation loss = 1.3944  \n",
      "\n",
      "Fold: 11  Epoch: 221  Training loss = 2.7377  Validation loss = 1.3945  \n",
      "\n",
      "Fold: 11  Epoch: 222  Training loss = 2.7375  Validation loss = 1.3944  \n",
      "\n",
      "Fold: 11  Epoch: 223  Training loss = 2.7368  Validation loss = 1.3944  \n",
      "\n",
      "Fold: 11  Epoch: 224  Training loss = 2.7363  Validation loss = 1.3945  \n",
      "\n",
      "Fold: 11  Epoch: 225  Training loss = 2.7356  Validation loss = 1.3946  \n",
      "\n",
      "Check model:  Fold: 11  Epoch: 219  Training loss = 2.7356  Validation loss = 1.3946  \n",
      "\n",
      "Fold: 12  Epoch: 1  Training loss = 2.7218  Validation loss = 1.6725  \n",
      "\n",
      "Fold: 12  Epoch: 2  Training loss = 2.7210  Validation loss = 1.6683  \n",
      "\n",
      "Fold: 12  Epoch: 3  Training loss = 2.7204  Validation loss = 1.6662  \n",
      "\n",
      "Fold: 12  Epoch: 4  Training loss = 2.7198  Validation loss = 1.6646  \n",
      "\n",
      "Fold: 12  Epoch: 5  Training loss = 2.7190  Validation loss = 1.6606  \n",
      "\n",
      "Fold: 12  Epoch: 6  Training loss = 2.7183  Validation loss = 1.6586  \n",
      "\n",
      "Fold: 12  Epoch: 7  Training loss = 2.7174  Validation loss = 1.6541  \n",
      "\n",
      "Fold: 12  Epoch: 8  Training loss = 2.7168  Validation loss = 1.6541  \n",
      "\n",
      "Fold: 12  Epoch: 9  Training loss = 2.7159  Validation loss = 1.6494  \n",
      "\n",
      "Fold: 12  Epoch: 10  Training loss = 2.7159  Validation loss = 1.6511  \n",
      "\n",
      "Fold: 12  Epoch: 11  Training loss = 2.7132  Validation loss = 1.6486  \n",
      "\n",
      "Fold: 12  Epoch: 12  Training loss = 2.7127  Validation loss = 1.6477  \n",
      "\n",
      "Fold: 12  Epoch: 13  Training loss = 2.7122  Validation loss = 1.6462  \n",
      "\n",
      "Fold: 12  Epoch: 14  Training loss = 2.7117  Validation loss = 1.6447  \n",
      "\n",
      "Fold: 12  Epoch: 15  Training loss = 2.7108  Validation loss = 1.6414  \n",
      "\n",
      "Fold: 12  Epoch: 16  Training loss = 2.7100  Validation loss = 1.6399  \n",
      "\n",
      "Fold: 12  Epoch: 17  Training loss = 2.7091  Validation loss = 1.6370  \n",
      "\n",
      "Fold: 12  Epoch: 18  Training loss = 2.7087  Validation loss = 1.6356  \n",
      "\n",
      "Fold: 12  Epoch: 19  Training loss = 2.7080  Validation loss = 1.6322  \n",
      "\n",
      "Fold: 12  Epoch: 20  Training loss = 2.7077  Validation loss = 1.6319  \n",
      "\n",
      "Fold: 12  Epoch: 21  Training loss = 2.7072  Validation loss = 1.6297  \n",
      "\n",
      "Fold: 12  Epoch: 22  Training loss = 2.7066  Validation loss = 1.6262  \n",
      "\n",
      "Fold: 12  Epoch: 23  Training loss = 2.7061  Validation loss = 1.6251  \n",
      "\n",
      "Fold: 12  Epoch: 24  Training loss = 2.7055  Validation loss = 1.6233  \n",
      "\n",
      "Fold: 12  Epoch: 25  Training loss = 2.7048  Validation loss = 1.6201  \n",
      "\n",
      "Fold: 12  Epoch: 26  Training loss = 2.7043  Validation loss = 1.6186  \n",
      "\n",
      "Fold: 12  Epoch: 27  Training loss = 2.7037  Validation loss = 1.6155  \n",
      "\n",
      "Fold: 12  Epoch: 28  Training loss = 2.7029  Validation loss = 1.6107  \n",
      "\n",
      "Fold: 12  Epoch: 29  Training loss = 2.7023  Validation loss = 1.6079  \n",
      "\n",
      "Fold: 12  Epoch: 30  Training loss = 2.7017  Validation loss = 1.6063  \n",
      "\n",
      "Fold: 12  Epoch: 31  Training loss = 2.7011  Validation loss = 1.6046  \n",
      "\n",
      "Fold: 12  Epoch: 32  Training loss = 2.7010  Validation loss = 1.6065  \n",
      "\n",
      "Fold: 12  Epoch: 33  Training loss = 2.7009  Validation loss = 1.6080  \n",
      "\n",
      "Fold: 12  Epoch: 34  Training loss = 2.7001  Validation loss = 1.6040  \n",
      "\n",
      "Fold: 12  Epoch: 35  Training loss = 2.6996  Validation loss = 1.6030  \n",
      "\n",
      "Fold: 12  Epoch: 36  Training loss = 2.6991  Validation loss = 1.6010  \n",
      "\n",
      "Fold: 12  Epoch: 37  Training loss = 2.6986  Validation loss = 1.5989  \n",
      "\n",
      "Fold: 12  Epoch: 38  Training loss = 2.6980  Validation loss = 1.5960  \n",
      "\n",
      "Fold: 12  Epoch: 39  Training loss = 2.6976  Validation loss = 1.5951  \n",
      "\n",
      "Fold: 12  Epoch: 40  Training loss = 2.6972  Validation loss = 1.5935  \n",
      "\n",
      "Fold: 12  Epoch: 41  Training loss = 2.6968  Validation loss = 1.5929  \n",
      "\n",
      "Fold: 12  Epoch: 42  Training loss = 2.6963  Validation loss = 1.5913  \n",
      "\n",
      "Fold: 12  Epoch: 43  Training loss = 2.6959  Validation loss = 1.5899  \n",
      "\n",
      "Fold: 12  Epoch: 44  Training loss = 2.6951  Validation loss = 1.5865  \n",
      "\n",
      "Fold: 12  Epoch: 45  Training loss = 2.6950  Validation loss = 1.5864  \n",
      "\n",
      "Fold: 12  Epoch: 46  Training loss = 2.6944  Validation loss = 1.5832  \n",
      "\n",
      "Fold: 12  Epoch: 47  Training loss = 2.6938  Validation loss = 1.5806  \n",
      "\n",
      "Fold: 12  Epoch: 48  Training loss = 2.6934  Validation loss = 1.5791  \n",
      "\n",
      "Fold: 12  Epoch: 49  Training loss = 2.6925  Validation loss = 1.5748  \n",
      "\n",
      "Fold: 12  Epoch: 50  Training loss = 2.6918  Validation loss = 1.5715  \n",
      "\n",
      "Fold: 12  Epoch: 51  Training loss = 2.6912  Validation loss = 1.5693  \n",
      "\n",
      "Fold: 12  Epoch: 52  Training loss = 2.6909  Validation loss = 1.5701  \n",
      "\n",
      "Fold: 12  Epoch: 53  Training loss = 2.6907  Validation loss = 1.5695  \n",
      "\n",
      "Fold: 12  Epoch: 54  Training loss = 2.6901  Validation loss = 1.5655  \n",
      "\n",
      "Fold: 12  Epoch: 55  Training loss = 2.6892  Validation loss = 1.5601  \n",
      "\n",
      "Fold: 12  Epoch: 56  Training loss = 2.6887  Validation loss = 1.5593  \n",
      "\n",
      "Fold: 12  Epoch: 57  Training loss = 2.6883  Validation loss = 1.5589  \n",
      "\n",
      "Fold: 12  Epoch: 58  Training loss = 2.6880  Validation loss = 1.5574  \n",
      "\n",
      "Fold: 12  Epoch: 59  Training loss = 2.6878  Validation loss = 1.5587  \n",
      "\n",
      "Fold: 12  Epoch: 60  Training loss = 2.6870  Validation loss = 1.5598  \n",
      "\n",
      "Fold: 12  Epoch: 61  Training loss = 2.6842  Validation loss = 1.5583  \n",
      "\n",
      "Fold: 12  Epoch: 62  Training loss = 2.6835  Validation loss = 1.5556  \n",
      "\n",
      "Fold: 12  Epoch: 63  Training loss = 2.6826  Validation loss = 1.5524  \n",
      "\n",
      "Fold: 12  Epoch: 64  Training loss = 2.6820  Validation loss = 1.5492  \n",
      "\n",
      "Fold: 12  Epoch: 65  Training loss = 2.6816  Validation loss = 1.5477  \n",
      "\n",
      "Fold: 12  Epoch: 66  Training loss = 2.6807  Validation loss = 1.5428  \n",
      "\n",
      "Fold: 12  Epoch: 67  Training loss = 2.6801  Validation loss = 1.5396  \n",
      "\n",
      "Fold: 12  Epoch: 68  Training loss = 2.6790  Validation loss = 1.5332  \n",
      "\n",
      "Fold: 12  Epoch: 69  Training loss = 2.6784  Validation loss = 1.5302  \n",
      "\n",
      "Fold: 12  Epoch: 70  Training loss = 2.6777  Validation loss = 1.5274  \n",
      "\n",
      "Fold: 12  Epoch: 71  Training loss = 2.6769  Validation loss = 1.5228  \n",
      "\n",
      "Fold: 12  Epoch: 72  Training loss = 2.6764  Validation loss = 1.5205  \n",
      "\n",
      "Fold: 12  Epoch: 73  Training loss = 2.6761  Validation loss = 1.5201  \n",
      "\n",
      "Fold: 12  Epoch: 74  Training loss = 2.6758  Validation loss = 1.5203  \n",
      "\n",
      "Fold: 12  Epoch: 75  Training loss = 2.6752  Validation loss = 1.5166  \n",
      "\n",
      "Fold: 12  Epoch: 76  Training loss = 2.6750  Validation loss = 1.5179  \n",
      "\n",
      "Fold: 12  Epoch: 77  Training loss = 2.6745  Validation loss = 1.5162  \n",
      "\n",
      "Fold: 12  Epoch: 78  Training loss = 2.6738  Validation loss = 1.5128  \n",
      "\n",
      "Fold: 12  Epoch: 79  Training loss = 2.6732  Validation loss = 1.5083  \n",
      "\n",
      "Fold: 12  Epoch: 80  Training loss = 2.6727  Validation loss = 1.5064  \n",
      "\n",
      "Fold: 12  Epoch: 81  Training loss = 2.6722  Validation loss = 1.5043  \n",
      "\n",
      "Fold: 12  Epoch: 82  Training loss = 2.6715  Validation loss = 1.4998  \n",
      "\n",
      "Fold: 12  Epoch: 83  Training loss = 2.6713  Validation loss = 1.5009  \n",
      "\n",
      "Fold: 12  Epoch: 84  Training loss = 2.6710  Validation loss = 1.5013  \n",
      "\n",
      "Fold: 12  Epoch: 85  Training loss = 2.6701  Validation loss = 1.4965  \n",
      "\n",
      "Fold: 12  Epoch: 86  Training loss = 2.6696  Validation loss = 1.4956  \n",
      "\n",
      "Fold: 12  Epoch: 87  Training loss = 2.6692  Validation loss = 1.4936  \n",
      "\n",
      "Fold: 12  Epoch: 88  Training loss = 2.6686  Validation loss = 1.4916  \n",
      "\n",
      "Fold: 12  Epoch: 89  Training loss = 2.6684  Validation loss = 1.4928  \n",
      "\n",
      "Fold: 12  Epoch: 90  Training loss = 2.6679  Validation loss = 1.4913  \n",
      "\n",
      "Fold: 12  Epoch: 91  Training loss = 2.6670  Validation loss = 1.4870  \n",
      "\n",
      "Fold: 12  Epoch: 92  Training loss = 2.6666  Validation loss = 1.4860  \n",
      "\n",
      "Fold: 12  Epoch: 93  Training loss = 2.6661  Validation loss = 1.4853  \n",
      "\n",
      "Fold: 12  Epoch: 94  Training loss = 2.6658  Validation loss = 1.4849  \n",
      "\n",
      "Fold: 12  Epoch: 95  Training loss = 2.6649  Validation loss = 1.4803  \n",
      "\n",
      "Fold: 12  Epoch: 96  Training loss = 2.6642  Validation loss = 1.4776  \n",
      "\n",
      "Fold: 12  Epoch: 97  Training loss = 2.6637  Validation loss = 1.4755  \n",
      "\n",
      "Fold: 12  Epoch: 98  Training loss = 2.6632  Validation loss = 1.4716  \n",
      "\n",
      "Fold: 12  Epoch: 99  Training loss = 2.6627  Validation loss = 1.4691  \n",
      "\n",
      "Fold: 12  Epoch: 100  Training loss = 2.6623  Validation loss = 1.4675  \n",
      "\n",
      "Fold: 12  Epoch: 101  Training loss = 2.6617  Validation loss = 1.4659  \n",
      "\n",
      "Fold: 12  Epoch: 102  Training loss = 2.6613  Validation loss = 1.4673  \n",
      "\n",
      "Fold: 12  Epoch: 103  Training loss = 2.6607  Validation loss = 1.4649  \n",
      "\n",
      "Fold: 12  Epoch: 104  Training loss = 2.6600  Validation loss = 1.4606  \n",
      "\n",
      "Fold: 12  Epoch: 105  Training loss = 2.6595  Validation loss = 1.4603  \n",
      "\n",
      "Fold: 12  Epoch: 106  Training loss = 2.6588  Validation loss = 1.4579  \n",
      "\n",
      "Fold: 12  Epoch: 107  Training loss = 2.6583  Validation loss = 1.4569  \n",
      "\n",
      "Fold: 12  Epoch: 108  Training loss = 2.6576  Validation loss = 1.4538  \n",
      "\n",
      "Fold: 12  Epoch: 109  Training loss = 2.6571  Validation loss = 1.4526  \n",
      "\n",
      "Fold: 12  Epoch: 110  Training loss = 2.6564  Validation loss = 1.4480  \n",
      "\n",
      "Fold: 12  Epoch: 111  Training loss = 2.6558  Validation loss = 1.4454  \n",
      "\n",
      "Fold: 12  Epoch: 112  Training loss = 2.6551  Validation loss = 1.4424  \n",
      "\n",
      "Fold: 12  Epoch: 113  Training loss = 2.6546  Validation loss = 1.4402  \n",
      "\n",
      "Fold: 12  Epoch: 114  Training loss = 2.6542  Validation loss = 1.4392  \n",
      "\n",
      "Fold: 12  Epoch: 115  Training loss = 2.6538  Validation loss = 1.4388  \n",
      "\n",
      "Fold: 12  Epoch: 116  Training loss = 2.6532  Validation loss = 1.4357  \n",
      "\n",
      "Fold: 12  Epoch: 117  Training loss = 2.6527  Validation loss = 1.4339  \n",
      "\n",
      "Fold: 12  Epoch: 118  Training loss = 2.6521  Validation loss = 1.4317  \n",
      "\n",
      "Fold: 12  Epoch: 119  Training loss = 2.6517  Validation loss = 1.4312  \n",
      "\n",
      "Fold: 12  Epoch: 120  Training loss = 2.6513  Validation loss = 1.4294  \n",
      "\n",
      "Fold: 12  Epoch: 121  Training loss = 2.6512  Validation loss = 1.4306  \n",
      "\n",
      "Fold: 12  Epoch: 122  Training loss = 2.6509  Validation loss = 1.4309  \n",
      "\n",
      "Fold: 12  Epoch: 123  Training loss = 2.6504  Validation loss = 1.4300  \n",
      "\n",
      "Fold: 12  Epoch: 124  Training loss = 2.6499  Validation loss = 1.4276  \n",
      "\n",
      "Fold: 12  Epoch: 125  Training loss = 2.6495  Validation loss = 1.4259  \n",
      "\n",
      "Fold: 12  Epoch: 126  Training loss = 2.6490  Validation loss = 1.4256  \n",
      "\n",
      "Fold: 12  Epoch: 127  Training loss = 2.6485  Validation loss = 1.4243  \n",
      "\n",
      "Fold: 12  Epoch: 128  Training loss = 2.6479  Validation loss = 1.4214  \n",
      "\n",
      "Fold: 12  Epoch: 129  Training loss = 2.6473  Validation loss = 1.4182  \n",
      "\n",
      "Fold: 12  Epoch: 130  Training loss = 2.6467  Validation loss = 1.4157  \n",
      "\n",
      "Fold: 12  Epoch: 131  Training loss = 2.6463  Validation loss = 1.4147  \n",
      "\n",
      "Fold: 12  Epoch: 132  Training loss = 2.6461  Validation loss = 1.4141  \n",
      "\n",
      "Fold: 12  Epoch: 133  Training loss = 2.6457  Validation loss = 1.4132  \n",
      "\n",
      "Fold: 12  Epoch: 134  Training loss = 2.6453  Validation loss = 1.4116  \n",
      "\n",
      "Fold: 12  Epoch: 135  Training loss = 2.6447  Validation loss = 1.4083  \n",
      "\n",
      "Fold: 12  Epoch: 136  Training loss = 2.6441  Validation loss = 1.4063  \n",
      "\n",
      "Fold: 12  Epoch: 137  Training loss = 2.6436  Validation loss = 1.4028  \n",
      "\n",
      "Fold: 12  Epoch: 138  Training loss = 2.6431  Validation loss = 1.4017  \n",
      "\n",
      "Fold: 12  Epoch: 139  Training loss = 2.6426  Validation loss = 1.3997  \n",
      "\n",
      "Fold: 12  Epoch: 140  Training loss = 2.6419  Validation loss = 1.3948  \n",
      "\n",
      "Fold: 12  Epoch: 141  Training loss = 2.6415  Validation loss = 1.3924  \n",
      "\n",
      "Fold: 12  Epoch: 142  Training loss = 2.6408  Validation loss = 1.3881  \n",
      "\n",
      "Fold: 12  Epoch: 143  Training loss = 2.6403  Validation loss = 1.3866  \n",
      "\n",
      "Fold: 12  Epoch: 144  Training loss = 2.6399  Validation loss = 1.3864  \n",
      "\n",
      "Fold: 12  Epoch: 145  Training loss = 2.6392  Validation loss = 1.3830  \n",
      "\n",
      "Fold: 12  Epoch: 146  Training loss = 2.6387  Validation loss = 1.3819  \n",
      "\n",
      "Fold: 12  Epoch: 147  Training loss = 2.6380  Validation loss = 1.3783  \n",
      "\n",
      "Fold: 12  Epoch: 148  Training loss = 2.6371  Validation loss = 1.3740  \n",
      "\n",
      "Fold: 12  Epoch: 149  Training loss = 2.6368  Validation loss = 1.3755  \n",
      "\n",
      "Fold: 12  Epoch: 150  Training loss = 2.6364  Validation loss = 1.3726  \n",
      "\n",
      "Fold: 12  Epoch: 151  Training loss = 2.6358  Validation loss = 1.3696  \n",
      "\n",
      "Fold: 12  Epoch: 152  Training loss = 2.6354  Validation loss = 1.3679  \n",
      "\n",
      "Fold: 12  Epoch: 153  Training loss = 2.6350  Validation loss = 1.3641  \n",
      "\n",
      "Fold: 12  Epoch: 154  Training loss = 2.6348  Validation loss = 1.3657  \n",
      "\n",
      "Fold: 12  Epoch: 155  Training loss = 2.6344  Validation loss = 1.3649  \n",
      "\n",
      "Fold: 12  Epoch: 156  Training loss = 2.6341  Validation loss = 1.3642  \n",
      "\n",
      "Fold: 12  Epoch: 157  Training loss = 2.6336  Validation loss = 1.3630  \n",
      "\n",
      "Fold: 12  Epoch: 158  Training loss = 2.6331  Validation loss = 1.3612  \n",
      "\n",
      "Fold: 12  Epoch: 159  Training loss = 2.6325  Validation loss = 1.3584  \n",
      "\n",
      "Fold: 12  Epoch: 160  Training loss = 2.6317  Validation loss = 1.3551  \n",
      "\n",
      "Fold: 12  Epoch: 161  Training loss = 2.6314  Validation loss = 1.3558  \n",
      "\n",
      "Fold: 12  Epoch: 162  Training loss = 2.6309  Validation loss = 1.3554  \n",
      "\n",
      "Fold: 12  Epoch: 163  Training loss = 2.6304  Validation loss = 1.3525  \n",
      "\n",
      "Fold: 12  Epoch: 164  Training loss = 2.6299  Validation loss = 1.3504  \n",
      "\n",
      "Fold: 12  Epoch: 165  Training loss = 2.6295  Validation loss = 1.3513  \n",
      "\n",
      "Fold: 12  Epoch: 166  Training loss = 2.6292  Validation loss = 1.3526  \n",
      "\n",
      "Fold: 12  Epoch: 167  Training loss = 2.6287  Validation loss = 1.3504  \n",
      "\n",
      "Fold: 12  Epoch: 168  Training loss = 2.6281  Validation loss = 1.3471  \n",
      "\n",
      "Fold: 12  Epoch: 169  Training loss = 2.6277  Validation loss = 1.3463  \n",
      "\n",
      "Fold: 12  Epoch: 170  Training loss = 2.6271  Validation loss = 1.3432  \n",
      "\n",
      "Fold: 12  Epoch: 171  Training loss = 2.6268  Validation loss = 1.3451  \n",
      "\n",
      "Fold: 12  Epoch: 172  Training loss = 2.6264  Validation loss = 1.3430  \n",
      "\n",
      "Fold: 12  Epoch: 173  Training loss = 2.6257  Validation loss = 1.3403  \n",
      "\n",
      "Fold: 12  Epoch: 174  Training loss = 2.6255  Validation loss = 1.3410  \n",
      "\n",
      "Fold: 12  Epoch: 175  Training loss = 2.6248  Validation loss = 1.3378  \n",
      "\n",
      "Fold: 12  Epoch: 176  Training loss = 2.6242  Validation loss = 1.3331  \n",
      "\n",
      "Fold: 12  Epoch: 177  Training loss = 2.6239  Validation loss = 1.3310  \n",
      "\n",
      "Fold: 12  Epoch: 178  Training loss = 2.6233  Validation loss = 1.3287  \n",
      "\n",
      "Fold: 12  Epoch: 179  Training loss = 2.6231  Validation loss = 1.3292  \n",
      "\n",
      "Fold: 12  Epoch: 180  Training loss = 2.6226  Validation loss = 1.3286  \n",
      "\n",
      "Fold: 12  Epoch: 181  Training loss = 2.6222  Validation loss = 1.3273  \n",
      "\n",
      "Fold: 12  Epoch: 182  Training loss = 2.6217  Validation loss = 1.3261  \n",
      "\n",
      "Fold: 12  Epoch: 183  Training loss = 2.6213  Validation loss = 1.3254  \n",
      "\n",
      "Fold: 12  Epoch: 184  Training loss = 2.6207  Validation loss = 1.3208  \n",
      "\n",
      "Fold: 12  Epoch: 185  Training loss = 2.6201  Validation loss = 1.3172  \n",
      "\n",
      "Fold: 12  Epoch: 186  Training loss = 2.6196  Validation loss = 1.3157  \n",
      "\n",
      "Fold: 12  Epoch: 187  Training loss = 2.6191  Validation loss = 1.3135  \n",
      "\n",
      "Fold: 12  Epoch: 188  Training loss = 2.6188  Validation loss = 1.3136  \n",
      "\n",
      "Fold: 12  Epoch: 189  Training loss = 2.6186  Validation loss = 1.3143  \n",
      "\n",
      "Fold: 12  Epoch: 190  Training loss = 2.6182  Validation loss = 1.3119  \n",
      "\n",
      "Fold: 12  Epoch: 191  Training loss = 2.6179  Validation loss = 1.3123  \n",
      "\n",
      "Fold: 12  Epoch: 192  Training loss = 2.6174  Validation loss = 1.3115  \n",
      "\n",
      "Fold: 12  Epoch: 193  Training loss = 2.6172  Validation loss = 1.3126  \n",
      "\n",
      "Fold: 12  Epoch: 194  Training loss = 2.6169  Validation loss = 1.3123  \n",
      "\n",
      "Fold: 12  Epoch: 195  Training loss = 2.6164  Validation loss = 1.3103  \n",
      "\n",
      "Fold: 12  Epoch: 196  Training loss = 2.6159  Validation loss = 1.3088  \n",
      "\n",
      "Fold: 12  Epoch: 197  Training loss = 2.6154  Validation loss = 1.3059  \n",
      "\n",
      "Fold: 12  Epoch: 198  Training loss = 2.6151  Validation loss = 1.3057  \n",
      "\n",
      "Fold: 12  Epoch: 199  Training loss = 2.6151  Validation loss = 1.3083  \n",
      "\n",
      "Fold: 12  Epoch: 200  Training loss = 2.6145  Validation loss = 1.3059  \n",
      "\n",
      "Fold: 12  Epoch: 201  Training loss = 2.6141  Validation loss = 1.3041  \n",
      "\n",
      "Fold: 12  Epoch: 202  Training loss = 2.6136  Validation loss = 1.3019  \n",
      "\n",
      "Fold: 12  Epoch: 203  Training loss = 2.6130  Validation loss = 1.3000  \n",
      "\n",
      "Fold: 12  Epoch: 204  Training loss = 2.6126  Validation loss = 1.2985  \n",
      "\n",
      "Fold: 12  Epoch: 205  Training loss = 2.6120  Validation loss = 1.2968  \n",
      "\n",
      "Fold: 12  Epoch: 206  Training loss = 2.6117  Validation loss = 1.2966  \n",
      "\n",
      "Fold: 12  Epoch: 207  Training loss = 2.6113  Validation loss = 1.2973  \n",
      "\n",
      "Fold: 12  Epoch: 208  Training loss = 2.6106  Validation loss = 1.2931  \n",
      "\n",
      "Fold: 12  Epoch: 209  Training loss = 2.6102  Validation loss = 1.2911  \n",
      "\n",
      "Fold: 12  Epoch: 210  Training loss = 2.6098  Validation loss = 1.2902  \n",
      "\n",
      "Fold: 12  Epoch: 211  Training loss = 2.6092  Validation loss = 1.2866  \n",
      "\n",
      "Fold: 12  Epoch: 212  Training loss = 2.6090  Validation loss = 1.2866  \n",
      "\n",
      "Fold: 12  Epoch: 213  Training loss = 2.6086  Validation loss = 1.2850  \n",
      "\n",
      "Fold: 12  Epoch: 214  Training loss = 2.6081  Validation loss = 1.2816  \n",
      "\n",
      "Fold: 12  Epoch: 215  Training loss = 2.6078  Validation loss = 1.2829  \n",
      "\n",
      "Fold: 12  Epoch: 216  Training loss = 2.6073  Validation loss = 1.2801  \n",
      "\n",
      "Fold: 12  Epoch: 217  Training loss = 2.6069  Validation loss = 1.2788  \n",
      "\n",
      "Fold: 12  Epoch: 218  Training loss = 2.6065  Validation loss = 1.2751  \n",
      "\n",
      "Fold: 12  Epoch: 219  Training loss = 2.6060  Validation loss = 1.2729  \n",
      "\n",
      "Fold: 12  Epoch: 220  Training loss = 2.6056  Validation loss = 1.2735  \n",
      "\n",
      "Fold: 12  Epoch: 221  Training loss = 2.6049  Validation loss = 1.2685  \n",
      "\n",
      "Fold: 12  Epoch: 222  Training loss = 2.6044  Validation loss = 1.2670  \n",
      "\n",
      "Fold: 12  Epoch: 223  Training loss = 2.6039  Validation loss = 1.2640  \n",
      "\n",
      "Fold: 12  Epoch: 224  Training loss = 2.6034  Validation loss = 1.2625  \n",
      "\n",
      "Fold: 12  Epoch: 225  Training loss = 2.6034  Validation loss = 1.2636  \n",
      "\n",
      "Fold: 12  Epoch: 226  Training loss = 2.6031  Validation loss = 1.2647  \n",
      "\n",
      "Fold: 12  Epoch: 227  Training loss = 2.6027  Validation loss = 1.2636  \n",
      "\n",
      "Fold: 12  Epoch: 228  Training loss = 2.6023  Validation loss = 1.2631  \n",
      "\n",
      "Fold: 12  Epoch: 229  Training loss = 2.6018  Validation loss = 1.2619  \n",
      "\n",
      "Fold: 12  Epoch: 230  Training loss = 2.6010  Validation loss = 1.2554  \n",
      "\n",
      "Fold: 12  Epoch: 231  Training loss = 2.6007  Validation loss = 1.2541  \n",
      "\n",
      "Fold: 12  Epoch: 232  Training loss = 2.6002  Validation loss = 1.2503  \n",
      "\n",
      "Fold: 12  Epoch: 233  Training loss = 2.5997  Validation loss = 1.2479  \n",
      "\n",
      "Fold: 12  Epoch: 234  Training loss = 2.5993  Validation loss = 1.2463  \n",
      "\n",
      "Fold: 12  Epoch: 235  Training loss = 2.5991  Validation loss = 1.2457  \n",
      "\n",
      "Fold: 12  Epoch: 236  Training loss = 2.5986  Validation loss = 1.2448  \n",
      "\n",
      "Fold: 12  Epoch: 237  Training loss = 2.5982  Validation loss = 1.2419  \n",
      "\n",
      "Fold: 12  Epoch: 238  Training loss = 2.5977  Validation loss = 1.2418  \n",
      "\n",
      "Fold: 12  Epoch: 239  Training loss = 2.5974  Validation loss = 1.2398  \n",
      "\n",
      "Fold: 12  Epoch: 240  Training loss = 2.5968  Validation loss = 1.2372  \n",
      "\n",
      "Fold: 12  Epoch: 241  Training loss = 2.5966  Validation loss = 1.2374  \n",
      "\n",
      "Fold: 12  Epoch: 242  Training loss = 2.5962  Validation loss = 1.2368  \n",
      "\n",
      "Fold: 12  Epoch: 243  Training loss = 2.5958  Validation loss = 1.2351  \n",
      "\n",
      "Fold: 12  Epoch: 244  Training loss = 2.5954  Validation loss = 1.2335  \n",
      "\n",
      "Fold: 12  Epoch: 245  Training loss = 2.5952  Validation loss = 1.2346  \n",
      "\n",
      "Fold: 12  Epoch: 246  Training loss = 2.5948  Validation loss = 1.2328  \n",
      "\n",
      "Fold: 12  Epoch: 247  Training loss = 2.5945  Validation loss = 1.2350  \n",
      "\n",
      "Fold: 12  Epoch: 248  Training loss = 2.5941  Validation loss = 1.2345  \n",
      "\n",
      "Fold: 12  Epoch: 249  Training loss = 2.5937  Validation loss = 1.2314  \n",
      "\n",
      "Fold: 12  Epoch: 250  Training loss = 2.5932  Validation loss = 1.2308  \n",
      "\n",
      "Fold: 12  Epoch: 251  Training loss = 2.5926  Validation loss = 1.2283  \n",
      "\n",
      "Fold: 12  Epoch: 252  Training loss = 2.5922  Validation loss = 1.2295  \n",
      "\n",
      "Fold: 12  Epoch: 253  Training loss = 2.5919  Validation loss = 1.2292  \n",
      "\n",
      "Fold: 12  Epoch: 254  Training loss = 2.5916  Validation loss = 1.2300  \n",
      "\n",
      "Fold: 12  Epoch: 255  Training loss = 2.5913  Validation loss = 1.2290  \n",
      "\n",
      "Fold: 12  Epoch: 256  Training loss = 2.5906  Validation loss = 1.2260  \n",
      "\n",
      "Fold: 12  Epoch: 257  Training loss = 2.5904  Validation loss = 1.2252  \n",
      "\n",
      "Fold: 12  Epoch: 258  Training loss = 2.5899  Validation loss = 1.2228  \n",
      "\n",
      "Fold: 12  Epoch: 259  Training loss = 2.5896  Validation loss = 1.2232  \n",
      "\n",
      "Fold: 12  Epoch: 260  Training loss = 2.5892  Validation loss = 1.2237  \n",
      "\n",
      "Fold: 12  Epoch: 261  Training loss = 2.5886  Validation loss = 1.2217  \n",
      "\n",
      "Fold: 12  Epoch: 262  Training loss = 2.5881  Validation loss = 1.2204  \n",
      "\n",
      "Fold: 12  Epoch: 263  Training loss = 2.5875  Validation loss = 1.2175  \n",
      "\n",
      "Fold: 12  Epoch: 264  Training loss = 2.5873  Validation loss = 1.2171  \n",
      "\n",
      "Fold: 12  Epoch: 265  Training loss = 2.5870  Validation loss = 1.2168  \n",
      "\n",
      "Fold: 12  Epoch: 266  Training loss = 2.5865  Validation loss = 1.2145  \n",
      "\n",
      "Fold: 12  Epoch: 267  Training loss = 2.5860  Validation loss = 1.2139  \n",
      "\n",
      "Fold: 12  Epoch: 268  Training loss = 2.5855  Validation loss = 1.2124  \n",
      "\n",
      "Fold: 12  Epoch: 269  Training loss = 2.5851  Validation loss = 1.2120  \n",
      "\n",
      "Fold: 12  Epoch: 270  Training loss = 2.5845  Validation loss = 1.2088  \n",
      "\n",
      "Fold: 12  Epoch: 271  Training loss = 2.5839  Validation loss = 1.2074  \n",
      "\n",
      "Fold: 12  Epoch: 272  Training loss = 2.5834  Validation loss = 1.2046  \n",
      "\n",
      "Fold: 12  Epoch: 273  Training loss = 2.5828  Validation loss = 1.2002  \n",
      "\n",
      "Fold: 12  Epoch: 274  Training loss = 2.5825  Validation loss = 1.1989  \n",
      "\n",
      "Fold: 12  Epoch: 275  Training loss = 2.5819  Validation loss = 1.1976  \n",
      "\n",
      "Fold: 12  Epoch: 276  Training loss = 2.5817  Validation loss = 1.1974  \n",
      "\n",
      "Fold: 12  Epoch: 277  Training loss = 2.5813  Validation loss = 1.1951  \n",
      "\n",
      "Fold: 12  Epoch: 278  Training loss = 2.5810  Validation loss = 1.1948  \n",
      "\n",
      "Fold: 12  Epoch: 279  Training loss = 2.5808  Validation loss = 1.1958  \n",
      "\n",
      "Fold: 12  Epoch: 280  Training loss = 2.5806  Validation loss = 1.1962  \n",
      "\n",
      "Fold: 12  Epoch: 281  Training loss = 2.5803  Validation loss = 1.1972  \n",
      "\n",
      "Fold: 12  Epoch: 282  Training loss = 2.5799  Validation loss = 1.1964  \n",
      "\n",
      "Fold: 12  Epoch: 283  Training loss = 2.5794  Validation loss = 1.1945  \n",
      "\n",
      "Fold: 12  Epoch: 284  Training loss = 2.5790  Validation loss = 1.1932  \n",
      "\n",
      "Fold: 12  Epoch: 285  Training loss = 2.5787  Validation loss = 1.1932  \n",
      "\n",
      "Fold: 12  Epoch: 286  Training loss = 2.5783  Validation loss = 1.1900  \n",
      "\n",
      "Fold: 12  Epoch: 287  Training loss = 2.5776  Validation loss = 1.1865  \n",
      "\n",
      "Fold: 12  Epoch: 288  Training loss = 2.5772  Validation loss = 1.1834  \n",
      "\n",
      "Fold: 12  Epoch: 289  Training loss = 2.5769  Validation loss = 1.1835  \n",
      "\n",
      "Fold: 12  Epoch: 290  Training loss = 2.5767  Validation loss = 1.1851  \n",
      "\n",
      "Fold: 12  Epoch: 291  Training loss = 2.5764  Validation loss = 1.1853  \n",
      "\n",
      "Fold: 12  Epoch: 292  Training loss = 2.5759  Validation loss = 1.1819  \n",
      "\n",
      "Fold: 12  Epoch: 293  Training loss = 2.5755  Validation loss = 1.1800  \n",
      "\n",
      "Fold: 12  Epoch: 294  Training loss = 2.5750  Validation loss = 1.1775  \n",
      "\n",
      "Fold: 12  Epoch: 295  Training loss = 2.5746  Validation loss = 1.1784  \n",
      "\n",
      "Fold: 12  Epoch: 296  Training loss = 2.5741  Validation loss = 1.1755  \n",
      "\n",
      "Fold: 12  Epoch: 297  Training loss = 2.5736  Validation loss = 1.1732  \n",
      "\n",
      "Fold: 12  Epoch: 298  Training loss = 2.5734  Validation loss = 1.1729  \n",
      "\n",
      "Fold: 12  Epoch: 299  Training loss = 2.5731  Validation loss = 1.1719  \n",
      "\n",
      "Fold: 12  Epoch: 300  Training loss = 2.5726  Validation loss = 1.1708  \n",
      "\n",
      "Fold: 12  Epoch: 301  Training loss = 2.5724  Validation loss = 1.1697  \n",
      "\n",
      "Fold: 12  Epoch: 302  Training loss = 2.5718  Validation loss = 1.1670  \n",
      "\n",
      "Fold: 12  Epoch: 303  Training loss = 2.5715  Validation loss = 1.1666  \n",
      "\n",
      "Fold: 12  Epoch: 304  Training loss = 2.5711  Validation loss = 1.1648  \n",
      "\n",
      "Fold: 12  Epoch: 305  Training loss = 2.5708  Validation loss = 1.1647  \n",
      "\n",
      "Fold: 12  Epoch: 306  Training loss = 2.5703  Validation loss = 1.1616  \n",
      "\n",
      "Fold: 12  Epoch: 307  Training loss = 2.5699  Validation loss = 1.1611  \n",
      "\n",
      "Fold: 12  Epoch: 308  Training loss = 2.5697  Validation loss = 1.1606  \n",
      "\n",
      "Fold: 12  Epoch: 309  Training loss = 2.5693  Validation loss = 1.1594  \n",
      "\n",
      "Fold: 12  Epoch: 310  Training loss = 2.5688  Validation loss = 1.1573  \n",
      "\n",
      "Fold: 12  Epoch: 311  Training loss = 2.5684  Validation loss = 1.1568  \n",
      "\n",
      "Fold: 12  Epoch: 312  Training loss = 2.5680  Validation loss = 1.1550  \n",
      "\n",
      "Fold: 12  Epoch: 313  Training loss = 2.5674  Validation loss = 1.1507  \n",
      "\n",
      "Fold: 12  Epoch: 314  Training loss = 2.5673  Validation loss = 1.1527  \n",
      "\n",
      "Fold: 12  Epoch: 315  Training loss = 2.5670  Validation loss = 1.1525  \n",
      "\n",
      "Fold: 12  Epoch: 316  Training loss = 2.5667  Validation loss = 1.1512  \n",
      "\n",
      "Fold: 12  Epoch: 317  Training loss = 2.5664  Validation loss = 1.1508  \n",
      "\n",
      "Fold: 12  Epoch: 318  Training loss = 2.5660  Validation loss = 1.1474  \n",
      "\n",
      "Fold: 12  Epoch: 319  Training loss = 2.5657  Validation loss = 1.1452  \n",
      "\n",
      "Fold: 12  Epoch: 320  Training loss = 2.5655  Validation loss = 1.1454  \n",
      "\n",
      "Fold: 12  Epoch: 321  Training loss = 2.5650  Validation loss = 1.1429  \n",
      "\n",
      "Fold: 12  Epoch: 322  Training loss = 2.5647  Validation loss = 1.1432  \n",
      "\n",
      "Fold: 12  Epoch: 323  Training loss = 2.5646  Validation loss = 1.1441  \n",
      "\n",
      "Fold: 12  Epoch: 324  Training loss = 2.5643  Validation loss = 1.1445  \n",
      "\n",
      "Fold: 12  Epoch: 325  Training loss = 2.5640  Validation loss = 1.1430  \n",
      "\n",
      "Fold: 12  Epoch: 326  Training loss = 2.5635  Validation loss = 1.1412  \n",
      "\n",
      "Fold: 12  Epoch: 327  Training loss = 2.5634  Validation loss = 1.1427  \n",
      "\n",
      "Fold: 12  Epoch: 328  Training loss = 2.5632  Validation loss = 1.1443  \n",
      "\n",
      "Fold: 12  Epoch: 329  Training loss = 2.5626  Validation loss = 1.1426  \n",
      "\n",
      "Fold: 12  Epoch: 330  Training loss = 2.5624  Validation loss = 1.1434  \n",
      "\n",
      "Fold: 12  Epoch: 331  Training loss = 2.5623  Validation loss = 1.1452  \n",
      "\n",
      "Check model:  Fold: 12  Epoch: 326  Training loss = 2.5623  Validation loss = 1.1452  \n",
      "\n",
      "Fold: 13  Epoch: 1  Training loss = 2.5129  Validation loss = 3.5986  \n",
      "\n",
      "Fold: 13  Epoch: 2  Training loss = 2.5121  Validation loss = 3.5969  \n",
      "\n",
      "Fold: 13  Epoch: 3  Training loss = 2.5117  Validation loss = 3.5943  \n",
      "\n",
      "Fold: 13  Epoch: 4  Training loss = 2.5107  Validation loss = 3.5898  \n",
      "\n",
      "Fold: 13  Epoch: 5  Training loss = 2.5103  Validation loss = 3.5877  \n",
      "\n",
      "Fold: 13  Epoch: 6  Training loss = 2.5099  Validation loss = 3.5856  \n",
      "\n",
      "Fold: 13  Epoch: 7  Training loss = 2.5100  Validation loss = 3.5871  \n",
      "\n",
      "Fold: 13  Epoch: 8  Training loss = 2.5097  Validation loss = 3.5871  \n",
      "\n",
      "Fold: 13  Epoch: 9  Training loss = 2.5092  Validation loss = 3.5836  \n",
      "\n",
      "Fold: 13  Epoch: 10  Training loss = 2.5084  Validation loss = 3.5794  \n",
      "\n",
      "Fold: 13  Epoch: 11  Training loss = 2.5073  Validation loss = 3.5729  \n",
      "\n",
      "Fold: 13  Epoch: 12  Training loss = 2.5068  Validation loss = 3.5706  \n",
      "\n",
      "Fold: 13  Epoch: 13  Training loss = 2.5060  Validation loss = 3.5656  \n",
      "\n",
      "Fold: 13  Epoch: 14  Training loss = 2.5057  Validation loss = 3.5650  \n",
      "\n",
      "Fold: 13  Epoch: 15  Training loss = 2.5051  Validation loss = 3.5612  \n",
      "\n",
      "Fold: 13  Epoch: 16  Training loss = 2.5047  Validation loss = 3.5598  \n",
      "\n",
      "Fold: 13  Epoch: 17  Training loss = 2.5041  Validation loss = 3.5563  \n",
      "\n",
      "Fold: 13  Epoch: 18  Training loss = 2.5037  Validation loss = 3.5534  \n",
      "\n",
      "Fold: 13  Epoch: 19  Training loss = 2.5033  Validation loss = 3.5524  \n",
      "\n",
      "Fold: 13  Epoch: 20  Training loss = 2.5028  Validation loss = 3.5496  \n",
      "\n",
      "Fold: 13  Epoch: 21  Training loss = 2.5022  Validation loss = 3.5468  \n",
      "\n",
      "Fold: 13  Epoch: 22  Training loss = 2.5014  Validation loss = 3.5420  \n",
      "\n",
      "Fold: 13  Epoch: 23  Training loss = 2.5010  Validation loss = 3.5396  \n",
      "\n",
      "Fold: 13  Epoch: 24  Training loss = 2.5005  Validation loss = 3.5359  \n",
      "\n",
      "Fold: 13  Epoch: 25  Training loss = 2.5000  Validation loss = 3.5341  \n",
      "\n",
      "Fold: 13  Epoch: 26  Training loss = 2.4995  Validation loss = 3.5318  \n",
      "\n",
      "Fold: 13  Epoch: 27  Training loss = 2.4991  Validation loss = 3.5297  \n",
      "\n",
      "Fold: 13  Epoch: 28  Training loss = 2.4986  Validation loss = 3.5276  \n",
      "\n",
      "Fold: 13  Epoch: 29  Training loss = 2.4983  Validation loss = 3.5267  \n",
      "\n",
      "Fold: 13  Epoch: 30  Training loss = 2.4980  Validation loss = 3.5258  \n",
      "\n",
      "Fold: 13  Epoch: 31  Training loss = 2.4973  Validation loss = 3.5208  \n",
      "\n",
      "Fold: 13  Epoch: 32  Training loss = 2.4970  Validation loss = 3.5190  \n",
      "\n",
      "Fold: 13  Epoch: 33  Training loss = 2.4967  Validation loss = 3.5170  \n",
      "\n",
      "Fold: 13  Epoch: 34  Training loss = 2.4964  Validation loss = 3.5165  \n",
      "\n",
      "Fold: 13  Epoch: 35  Training loss = 2.4959  Validation loss = 3.5137  \n",
      "\n",
      "Fold: 13  Epoch: 36  Training loss = 2.4956  Validation loss = 3.5117  \n",
      "\n",
      "Fold: 13  Epoch: 37  Training loss = 2.4949  Validation loss = 3.5066  \n",
      "\n",
      "Fold: 13  Epoch: 38  Training loss = 2.4945  Validation loss = 3.5050  \n",
      "\n",
      "Fold: 13  Epoch: 39  Training loss = 2.4941  Validation loss = 3.5027  \n",
      "\n",
      "Fold: 13  Epoch: 40  Training loss = 2.4936  Validation loss = 3.5007  \n",
      "\n",
      "Fold: 13  Epoch: 41  Training loss = 2.4928  Validation loss = 3.4947  \n",
      "\n",
      "Fold: 13  Epoch: 42  Training loss = 2.4925  Validation loss = 3.4944  \n",
      "\n",
      "Fold: 13  Epoch: 43  Training loss = 2.4921  Validation loss = 3.4920  \n",
      "\n",
      "Fold: 13  Epoch: 44  Training loss = 2.4919  Validation loss = 3.4921  \n",
      "\n",
      "Fold: 13  Epoch: 45  Training loss = 2.4916  Validation loss = 3.4916  \n",
      "\n",
      "Fold: 13  Epoch: 46  Training loss = 2.4914  Validation loss = 3.4907  \n",
      "\n",
      "Fold: 13  Epoch: 47  Training loss = 2.4911  Validation loss = 3.4897  \n",
      "\n",
      "Fold: 13  Epoch: 48  Training loss = 2.4905  Validation loss = 3.4859  \n",
      "\n",
      "Fold: 13  Epoch: 49  Training loss = 2.4903  Validation loss = 3.4856  \n",
      "\n",
      "Fold: 13  Epoch: 50  Training loss = 2.4901  Validation loss = 3.4853  \n",
      "\n",
      "Fold: 13  Epoch: 51  Training loss = 2.4895  Validation loss = 3.4813  \n",
      "\n",
      "Fold: 13  Epoch: 52  Training loss = 2.4892  Validation loss = 3.4798  \n",
      "\n",
      "Fold: 13  Epoch: 53  Training loss = 2.4889  Validation loss = 3.4771  \n",
      "\n",
      "Fold: 13  Epoch: 54  Training loss = 2.4887  Validation loss = 3.4759  \n",
      "\n",
      "Fold: 13  Epoch: 55  Training loss = 2.4883  Validation loss = 3.4744  \n",
      "\n",
      "Fold: 13  Epoch: 56  Training loss = 2.4880  Validation loss = 3.4719  \n",
      "\n",
      "Fold: 13  Epoch: 57  Training loss = 2.4875  Validation loss = 3.4693  \n",
      "\n",
      "Fold: 13  Epoch: 58  Training loss = 2.4867  Validation loss = 3.4623  \n",
      "\n",
      "Fold: 13  Epoch: 59  Training loss = 2.4861  Validation loss = 3.4565  \n",
      "\n",
      "Fold: 13  Epoch: 60  Training loss = 2.4858  Validation loss = 3.4543  \n",
      "\n",
      "Fold: 13  Epoch: 61  Training loss = 2.4854  Validation loss = 3.4531  \n",
      "\n",
      "Fold: 13  Epoch: 62  Training loss = 2.4849  Validation loss = 3.4503  \n",
      "\n",
      "Fold: 13  Epoch: 63  Training loss = 2.4847  Validation loss = 3.4497  \n",
      "\n",
      "Fold: 13  Epoch: 64  Training loss = 2.4842  Validation loss = 3.4461  \n",
      "\n",
      "Fold: 13  Epoch: 65  Training loss = 2.4839  Validation loss = 3.4447  \n",
      "\n",
      "Fold: 13  Epoch: 66  Training loss = 2.4835  Validation loss = 3.4429  \n",
      "\n",
      "Fold: 13  Epoch: 67  Training loss = 2.4831  Validation loss = 3.4407  \n",
      "\n",
      "Fold: 13  Epoch: 68  Training loss = 2.4829  Validation loss = 3.4403  \n",
      "\n",
      "Fold: 13  Epoch: 69  Training loss = 2.4826  Validation loss = 3.4398  \n",
      "\n",
      "Fold: 13  Epoch: 70  Training loss = 2.4823  Validation loss = 3.4392  \n",
      "\n",
      "Fold: 13  Epoch: 71  Training loss = 2.4817  Validation loss = 3.4337  \n",
      "\n",
      "Fold: 13  Epoch: 72  Training loss = 2.4814  Validation loss = 3.4327  \n",
      "\n",
      "Fold: 13  Epoch: 73  Training loss = 2.4813  Validation loss = 3.4332  \n",
      "\n",
      "Fold: 13  Epoch: 74  Training loss = 2.4808  Validation loss = 3.4313  \n",
      "\n",
      "Fold: 13  Epoch: 75  Training loss = 2.4805  Validation loss = 3.4301  \n",
      "\n",
      "Fold: 13  Epoch: 76  Training loss = 2.4802  Validation loss = 3.4290  \n",
      "\n",
      "Fold: 13  Epoch: 77  Training loss = 2.4799  Validation loss = 3.4280  \n",
      "\n",
      "Fold: 13  Epoch: 78  Training loss = 2.4798  Validation loss = 3.4291  \n",
      "\n",
      "Fold: 13  Epoch: 79  Training loss = 2.4793  Validation loss = 3.4270  \n",
      "\n",
      "Fold: 13  Epoch: 80  Training loss = 2.4792  Validation loss = 3.4281  \n",
      "\n",
      "Fold: 13  Epoch: 81  Training loss = 2.4787  Validation loss = 3.4253  \n",
      "\n",
      "Fold: 13  Epoch: 82  Training loss = 2.4782  Validation loss = 3.4208  \n",
      "\n",
      "Fold: 13  Epoch: 83  Training loss = 2.4778  Validation loss = 3.4187  \n",
      "\n",
      "Fold: 13  Epoch: 84  Training loss = 2.4776  Validation loss = 3.4196  \n",
      "\n",
      "Fold: 13  Epoch: 85  Training loss = 2.4771  Validation loss = 3.4161  \n",
      "\n",
      "Fold: 13  Epoch: 86  Training loss = 2.4769  Validation loss = 3.4159  \n",
      "\n",
      "Fold: 13  Epoch: 87  Training loss = 2.4764  Validation loss = 3.4138  \n",
      "\n",
      "Fold: 13  Epoch: 88  Training loss = 2.4759  Validation loss = 3.4103  \n",
      "\n",
      "Fold: 13  Epoch: 89  Training loss = 2.4754  Validation loss = 3.4061  \n",
      "\n",
      "Fold: 13  Epoch: 90  Training loss = 2.4751  Validation loss = 3.4038  \n",
      "\n",
      "Fold: 13  Epoch: 91  Training loss = 2.4748  Validation loss = 3.4032  \n",
      "\n",
      "Fold: 13  Epoch: 92  Training loss = 2.4747  Validation loss = 3.4041  \n",
      "\n",
      "Fold: 13  Epoch: 93  Training loss = 2.4745  Validation loss = 3.4053  \n",
      "\n",
      "Fold: 13  Epoch: 94  Training loss = 2.4743  Validation loss = 3.4052  \n",
      "\n",
      "Fold: 13  Epoch: 95  Training loss = 2.4740  Validation loss = 3.4037  \n",
      "\n",
      "Fold: 13  Epoch: 96  Training loss = 2.4736  Validation loss = 3.4009  \n",
      "\n",
      "Fold: 13  Epoch: 97  Training loss = 2.4731  Validation loss = 3.3996  \n",
      "\n",
      "Fold: 13  Epoch: 98  Training loss = 2.4730  Validation loss = 3.3974  \n",
      "\n",
      "Fold: 13  Epoch: 99  Training loss = 2.4726  Validation loss = 3.3950  \n",
      "\n",
      "Fold: 13  Epoch: 100  Training loss = 2.4722  Validation loss = 3.3941  \n",
      "\n",
      "Fold: 13  Epoch: 101  Training loss = 2.4719  Validation loss = 3.3927  \n",
      "\n",
      "Fold: 13  Epoch: 102  Training loss = 2.4717  Validation loss = 3.3928  \n",
      "\n",
      "Fold: 13  Epoch: 103  Training loss = 2.4713  Validation loss = 3.3918  \n",
      "\n",
      "Fold: 13  Epoch: 104  Training loss = 2.4710  Validation loss = 3.3889  \n",
      "\n",
      "Fold: 13  Epoch: 105  Training loss = 2.4707  Validation loss = 3.3873  \n",
      "\n",
      "Fold: 13  Epoch: 106  Training loss = 2.4704  Validation loss = 3.3866  \n",
      "\n",
      "Fold: 13  Epoch: 107  Training loss = 2.4702  Validation loss = 3.3874  \n",
      "\n",
      "Fold: 13  Epoch: 108  Training loss = 2.4701  Validation loss = 3.3899  \n",
      "\n",
      "Fold: 13  Epoch: 109  Training loss = 2.4697  Validation loss = 3.3888  \n",
      "\n",
      "Fold: 13  Epoch: 110  Training loss = 2.4695  Validation loss = 3.3876  \n",
      "\n",
      "Fold: 13  Epoch: 111  Training loss = 2.4693  Validation loss = 3.3873  \n",
      "\n",
      "Fold: 13  Epoch: 112  Training loss = 2.4687  Validation loss = 3.3828  \n",
      "\n",
      "Fold: 13  Epoch: 113  Training loss = 2.4684  Validation loss = 3.3805  \n",
      "\n",
      "Fold: 13  Epoch: 114  Training loss = 2.4682  Validation loss = 3.3806  \n",
      "\n",
      "Fold: 13  Epoch: 115  Training loss = 2.4680  Validation loss = 3.3800  \n",
      "\n",
      "Fold: 13  Epoch: 116  Training loss = 2.4674  Validation loss = 3.3743  \n",
      "\n",
      "Fold: 13  Epoch: 117  Training loss = 2.4669  Validation loss = 3.3713  \n",
      "\n",
      "Fold: 13  Epoch: 118  Training loss = 2.4668  Validation loss = 3.3727  \n",
      "\n",
      "Fold: 13  Epoch: 119  Training loss = 2.4667  Validation loss = 3.3751  \n",
      "\n",
      "Fold: 13  Epoch: 120  Training loss = 2.4664  Validation loss = 3.3744  \n",
      "\n",
      "Fold: 13  Epoch: 121  Training loss = 2.4659  Validation loss = 3.3721  \n",
      "\n",
      "Fold: 13  Epoch: 122  Training loss = 2.4656  Validation loss = 3.3685  \n",
      "\n",
      "Fold: 13  Epoch: 123  Training loss = 2.4652  Validation loss = 3.3670  \n",
      "\n",
      "Fold: 13  Epoch: 124  Training loss = 2.4651  Validation loss = 3.3679  \n",
      "\n",
      "Fold: 13  Epoch: 125  Training loss = 2.4650  Validation loss = 3.3695  \n",
      "\n",
      "Fold: 13  Epoch: 126  Training loss = 2.4647  Validation loss = 3.3686  \n",
      "\n",
      "Fold: 13  Epoch: 127  Training loss = 2.4643  Validation loss = 3.3669  \n",
      "\n",
      "Fold: 13  Epoch: 128  Training loss = 2.4640  Validation loss = 3.3644  \n",
      "\n",
      "Fold: 13  Epoch: 129  Training loss = 2.4638  Validation loss = 3.3657  \n",
      "\n",
      "Fold: 13  Epoch: 130  Training loss = 2.4636  Validation loss = 3.3644  \n",
      "\n",
      "Fold: 13  Epoch: 131  Training loss = 2.4633  Validation loss = 3.3651  \n",
      "\n",
      "Fold: 13  Epoch: 132  Training loss = 2.4631  Validation loss = 3.3641  \n",
      "\n",
      "Fold: 13  Epoch: 133  Training loss = 2.4630  Validation loss = 3.3655  \n",
      "\n",
      "Fold: 13  Epoch: 134  Training loss = 2.4627  Validation loss = 3.3643  \n",
      "\n",
      "Fold: 13  Epoch: 135  Training loss = 2.4626  Validation loss = 3.3647  \n",
      "\n",
      "Fold: 13  Epoch: 136  Training loss = 2.4624  Validation loss = 3.3645  \n",
      "\n",
      "Fold: 13  Epoch: 137  Training loss = 2.4620  Validation loss = 3.3617  \n",
      "\n",
      "Fold: 13  Epoch: 138  Training loss = 2.4618  Validation loss = 3.3605  \n",
      "\n",
      "Fold: 13  Epoch: 139  Training loss = 2.4617  Validation loss = 3.3607  \n",
      "\n",
      "Fold: 13  Epoch: 140  Training loss = 2.4615  Validation loss = 3.3614  \n",
      "\n",
      "Fold: 13  Epoch: 141  Training loss = 2.4613  Validation loss = 3.3620  \n",
      "\n",
      "Fold: 13  Epoch: 142  Training loss = 2.4610  Validation loss = 3.3612  \n",
      "\n",
      "Fold: 13  Epoch: 143  Training loss = 2.4608  Validation loss = 3.3596  \n",
      "\n",
      "Fold: 13  Epoch: 144  Training loss = 2.4604  Validation loss = 3.3589  \n",
      "\n",
      "Fold: 13  Epoch: 145  Training loss = 2.4603  Validation loss = 3.3587  \n",
      "\n",
      "Fold: 13  Epoch: 146  Training loss = 2.4602  Validation loss = 3.3607  \n",
      "\n",
      "Fold: 13  Epoch: 147  Training loss = 2.4597  Validation loss = 3.3567  \n",
      "\n",
      "Fold: 13  Epoch: 148  Training loss = 2.4593  Validation loss = 3.3545  \n",
      "\n",
      "Fold: 13  Epoch: 149  Training loss = 2.4589  Validation loss = 3.3521  \n",
      "\n",
      "Fold: 13  Epoch: 150  Training loss = 2.4586  Validation loss = 3.3506  \n",
      "\n",
      "Fold: 13  Epoch: 151  Training loss = 2.4583  Validation loss = 3.3478  \n",
      "\n",
      "Fold: 13  Epoch: 152  Training loss = 2.4580  Validation loss = 3.3466  \n",
      "\n",
      "Fold: 13  Epoch: 153  Training loss = 2.4578  Validation loss = 3.3467  \n",
      "\n",
      "Fold: 13  Epoch: 154  Training loss = 2.4576  Validation loss = 3.3457  \n",
      "\n",
      "Fold: 13  Epoch: 155  Training loss = 2.4575  Validation loss = 3.3459  \n",
      "\n",
      "Fold: 13  Epoch: 156  Training loss = 2.4572  Validation loss = 3.3437  \n",
      "\n",
      "Fold: 13  Epoch: 157  Training loss = 2.4568  Validation loss = 3.3425  \n",
      "\n",
      "Fold: 13  Epoch: 158  Training loss = 2.4566  Validation loss = 3.3429  \n",
      "\n",
      "Fold: 13  Epoch: 159  Training loss = 2.4565  Validation loss = 3.3444  \n",
      "\n",
      "Fold: 13  Epoch: 160  Training loss = 2.4560  Validation loss = 3.3399  \n",
      "\n",
      "Fold: 13  Epoch: 161  Training loss = 2.4556  Validation loss = 3.3381  \n",
      "\n",
      "Fold: 13  Epoch: 162  Training loss = 2.4554  Validation loss = 3.3376  \n",
      "\n",
      "Fold: 13  Epoch: 163  Training loss = 2.4552  Validation loss = 3.3393  \n",
      "\n",
      "Fold: 13  Epoch: 164  Training loss = 2.4551  Validation loss = 3.3405  \n",
      "\n",
      "Fold: 13  Epoch: 165  Training loss = 2.4548  Validation loss = 3.3396  \n",
      "\n",
      "Fold: 13  Epoch: 166  Training loss = 2.4545  Validation loss = 3.3384  \n",
      "\n",
      "Fold: 13  Epoch: 167  Training loss = 2.4542  Validation loss = 3.3367  \n",
      "\n",
      "Fold: 13  Epoch: 168  Training loss = 2.4540  Validation loss = 3.3382  \n",
      "\n",
      "Fold: 13  Epoch: 169  Training loss = 2.4538  Validation loss = 3.3374  \n",
      "\n",
      "Fold: 13  Epoch: 170  Training loss = 2.4535  Validation loss = 3.3366  \n",
      "\n",
      "Fold: 13  Epoch: 171  Training loss = 2.4533  Validation loss = 3.3358  \n",
      "\n",
      "Fold: 13  Epoch: 172  Training loss = 2.4531  Validation loss = 3.3344  \n",
      "\n",
      "Fold: 13  Epoch: 173  Training loss = 2.4530  Validation loss = 3.3349  \n",
      "\n",
      "Fold: 13  Epoch: 174  Training loss = 2.4527  Validation loss = 3.3343  \n",
      "\n",
      "Fold: 13  Epoch: 175  Training loss = 2.4526  Validation loss = 3.3349  \n",
      "\n",
      "Fold: 13  Epoch: 176  Training loss = 2.4521  Validation loss = 3.3315  \n",
      "\n",
      "Fold: 13  Epoch: 177  Training loss = 2.4519  Validation loss = 3.3317  \n",
      "\n",
      "Fold: 13  Epoch: 178  Training loss = 2.4515  Validation loss = 3.3293  \n",
      "\n",
      "Fold: 13  Epoch: 179  Training loss = 2.4512  Validation loss = 3.3272  \n",
      "\n",
      "Fold: 13  Epoch: 180  Training loss = 2.4511  Validation loss = 3.3271  \n",
      "\n",
      "Fold: 13  Epoch: 181  Training loss = 2.4505  Validation loss = 3.3220  \n",
      "\n",
      "Fold: 13  Epoch: 182  Training loss = 2.4503  Validation loss = 3.3214  \n",
      "\n",
      "Fold: 13  Epoch: 183  Training loss = 2.4500  Validation loss = 3.3199  \n",
      "\n",
      "Fold: 13  Epoch: 184  Training loss = 2.4498  Validation loss = 3.3170  \n",
      "\n",
      "Fold: 13  Epoch: 185  Training loss = 2.4495  Validation loss = 3.3156  \n",
      "\n",
      "Fold: 13  Epoch: 186  Training loss = 2.4492  Validation loss = 3.3147  \n",
      "\n",
      "Fold: 13  Epoch: 187  Training loss = 2.4489  Validation loss = 3.3128  \n",
      "\n",
      "Fold: 13  Epoch: 188  Training loss = 2.4487  Validation loss = 3.3130  \n",
      "\n",
      "Fold: 13  Epoch: 189  Training loss = 2.4483  Validation loss = 3.3098  \n",
      "\n",
      "Fold: 13  Epoch: 190  Training loss = 2.4479  Validation loss = 3.3080  \n",
      "\n",
      "Fold: 13  Epoch: 191  Training loss = 2.4476  Validation loss = 3.3056  \n",
      "\n",
      "Fold: 13  Epoch: 192  Training loss = 2.4474  Validation loss = 3.3038  \n",
      "\n",
      "Fold: 13  Epoch: 193  Training loss = 2.4473  Validation loss = 3.3073  \n",
      "\n",
      "Fold: 13  Epoch: 194  Training loss = 2.4466  Validation loss = 3.2999  \n",
      "\n",
      "Fold: 13  Epoch: 195  Training loss = 2.4464  Validation loss = 3.2996  \n",
      "\n",
      "Fold: 13  Epoch: 196  Training loss = 2.4462  Validation loss = 3.2974  \n",
      "\n",
      "Fold: 13  Epoch: 197  Training loss = 2.4459  Validation loss = 3.2970  \n",
      "\n",
      "Fold: 13  Epoch: 198  Training loss = 2.4457  Validation loss = 3.2962  \n",
      "\n",
      "Fold: 13  Epoch: 199  Training loss = 2.4455  Validation loss = 3.2979  \n",
      "\n",
      "Fold: 13  Epoch: 200  Training loss = 2.4452  Validation loss = 3.2959  \n",
      "\n",
      "Fold: 13  Epoch: 201  Training loss = 2.4449  Validation loss = 3.2954  \n",
      "\n",
      "Fold: 13  Epoch: 202  Training loss = 2.4448  Validation loss = 3.2985  \n",
      "\n",
      "Fold: 13  Epoch: 203  Training loss = 2.4446  Validation loss = 3.2963  \n",
      "\n",
      "Fold: 13  Epoch: 204  Training loss = 2.4442  Validation loss = 3.2922  \n",
      "\n",
      "Fold: 13  Epoch: 205  Training loss = 2.4439  Validation loss = 3.2915  \n",
      "\n",
      "Fold: 13  Epoch: 206  Training loss = 2.4437  Validation loss = 3.2895  \n",
      "\n",
      "Fold: 13  Epoch: 207  Training loss = 2.4434  Validation loss = 3.2890  \n",
      "\n",
      "Fold: 13  Epoch: 208  Training loss = 2.4431  Validation loss = 3.2868  \n",
      "\n",
      "Fold: 13  Epoch: 209  Training loss = 2.4430  Validation loss = 3.2883  \n",
      "\n",
      "Fold: 13  Epoch: 210  Training loss = 2.4428  Validation loss = 3.2883  \n",
      "\n",
      "Fold: 13  Epoch: 211  Training loss = 2.4425  Validation loss = 3.2870  \n",
      "\n",
      "Fold: 13  Epoch: 212  Training loss = 2.4420  Validation loss = 3.2862  \n",
      "\n",
      "Fold: 13  Epoch: 213  Training loss = 2.4417  Validation loss = 3.2850  \n",
      "\n",
      "Fold: 13  Epoch: 214  Training loss = 2.4417  Validation loss = 3.2875  \n",
      "\n",
      "Fold: 13  Epoch: 215  Training loss = 2.4414  Validation loss = 3.2870  \n",
      "\n",
      "Fold: 13  Epoch: 216  Training loss = 2.4412  Validation loss = 3.2869  \n",
      "\n",
      "Fold: 13  Epoch: 217  Training loss = 2.4409  Validation loss = 3.2853  \n",
      "\n",
      "Fold: 13  Epoch: 218  Training loss = 2.4408  Validation loss = 3.2848  \n",
      "\n",
      "Fold: 13  Epoch: 219  Training loss = 2.4403  Validation loss = 3.2803  \n",
      "\n",
      "Fold: 13  Epoch: 220  Training loss = 2.4400  Validation loss = 3.2783  \n",
      "\n",
      "Fold: 13  Epoch: 221  Training loss = 2.4396  Validation loss = 3.2741  \n",
      "\n",
      "Fold: 13  Epoch: 222  Training loss = 2.4395  Validation loss = 3.2760  \n",
      "\n",
      "Fold: 13  Epoch: 223  Training loss = 2.4392  Validation loss = 3.2777  \n",
      "\n",
      "Fold: 13  Epoch: 224  Training loss = 2.4390  Validation loss = 3.2772  \n",
      "\n",
      "Fold: 13  Epoch: 225  Training loss = 2.4386  Validation loss = 3.2725  \n",
      "\n",
      "Fold: 13  Epoch: 226  Training loss = 2.4384  Validation loss = 3.2746  \n",
      "\n",
      "Fold: 13  Epoch: 227  Training loss = 2.4381  Validation loss = 3.2732  \n",
      "\n",
      "Fold: 13  Epoch: 228  Training loss = 2.4380  Validation loss = 3.2748  \n",
      "\n",
      "Fold: 13  Epoch: 229  Training loss = 2.4379  Validation loss = 3.2761  \n",
      "\n",
      "Fold: 13  Epoch: 230  Training loss = 2.4376  Validation loss = 3.2745  \n",
      "\n",
      "Fold: 13  Epoch: 231  Training loss = 2.4372  Validation loss = 3.2711  \n",
      "\n",
      "Fold: 13  Epoch: 232  Training loss = 2.4369  Validation loss = 3.2706  \n",
      "\n",
      "Fold: 13  Epoch: 233  Training loss = 2.4368  Validation loss = 3.2721  \n",
      "\n",
      "Fold: 13  Epoch: 234  Training loss = 2.4367  Validation loss = 3.2724  \n",
      "\n",
      "Fold: 13  Epoch: 235  Training loss = 2.4363  Validation loss = 3.2686  \n",
      "\n",
      "Fold: 13  Epoch: 236  Training loss = 2.4360  Validation loss = 3.2671  \n",
      "\n",
      "Fold: 13  Epoch: 237  Training loss = 2.4356  Validation loss = 3.2641  \n",
      "\n",
      "Fold: 13  Epoch: 238  Training loss = 2.4355  Validation loss = 3.2652  \n",
      "\n",
      "Fold: 13  Epoch: 239  Training loss = 2.4351  Validation loss = 3.2619  \n",
      "\n",
      "Fold: 13  Epoch: 240  Training loss = 2.4348  Validation loss = 3.2592  \n",
      "\n",
      "Fold: 13  Epoch: 241  Training loss = 2.4346  Validation loss = 3.2624  \n",
      "\n",
      "Fold: 13  Epoch: 242  Training loss = 2.4344  Validation loss = 3.2602  \n",
      "\n",
      "Fold: 13  Epoch: 243  Training loss = 2.4342  Validation loss = 3.2617  \n",
      "\n",
      "Fold: 13  Epoch: 244  Training loss = 2.4341  Validation loss = 3.2625  \n",
      "\n",
      "Fold: 13  Epoch: 245  Training loss = 2.4338  Validation loss = 3.2611  \n",
      "\n",
      "Fold: 13  Epoch: 246  Training loss = 2.4337  Validation loss = 3.2631  \n",
      "\n",
      "Fold: 13  Epoch: 247  Training loss = 2.4334  Validation loss = 3.2607  \n",
      "\n",
      "Fold: 13  Epoch: 248  Training loss = 2.4332  Validation loss = 3.2607  \n",
      "\n",
      "Fold: 13  Epoch: 249  Training loss = 2.4329  Validation loss = 3.2563  \n",
      "\n",
      "Fold: 13  Epoch: 250  Training loss = 2.4325  Validation loss = 3.2526  \n",
      "\n",
      "Fold: 13  Epoch: 251  Training loss = 2.4323  Validation loss = 3.2527  \n",
      "\n",
      "Fold: 13  Epoch: 252  Training loss = 2.4321  Validation loss = 3.2516  \n",
      "\n",
      "Fold: 13  Epoch: 253  Training loss = 2.4319  Validation loss = 3.2527  \n",
      "\n",
      "Fold: 13  Epoch: 254  Training loss = 2.4316  Validation loss = 3.2518  \n",
      "\n",
      "Fold: 13  Epoch: 255  Training loss = 2.4312  Validation loss = 3.2468  \n",
      "\n",
      "Fold: 13  Epoch: 256  Training loss = 2.4308  Validation loss = 3.2448  \n",
      "\n",
      "Fold: 13  Epoch: 257  Training loss = 2.4304  Validation loss = 3.2419  \n",
      "\n",
      "Fold: 13  Epoch: 258  Training loss = 2.4301  Validation loss = 3.2397  \n",
      "\n",
      "Fold: 13  Epoch: 259  Training loss = 2.4298  Validation loss = 3.2361  \n",
      "\n",
      "Fold: 13  Epoch: 260  Training loss = 2.4296  Validation loss = 3.2362  \n",
      "\n",
      "Fold: 13  Epoch: 261  Training loss = 2.4292  Validation loss = 3.2340  \n",
      "\n",
      "Fold: 13  Epoch: 262  Training loss = 2.4290  Validation loss = 3.2356  \n",
      "\n",
      "Fold: 13  Epoch: 263  Training loss = 2.4286  Validation loss = 3.2302  \n",
      "\n",
      "Fold: 13  Epoch: 264  Training loss = 2.4285  Validation loss = 3.2321  \n",
      "\n",
      "Fold: 13  Epoch: 265  Training loss = 2.4283  Validation loss = 3.2328  \n",
      "\n",
      "Fold: 13  Epoch: 266  Training loss = 2.4279  Validation loss = 3.2306  \n",
      "\n",
      "Fold: 13  Epoch: 267  Training loss = 2.4277  Validation loss = 3.2323  \n",
      "\n",
      "Fold: 13  Epoch: 268  Training loss = 2.4276  Validation loss = 3.2339  \n",
      "\n",
      "Fold: 13  Epoch: 269  Training loss = 2.4273  Validation loss = 3.2305  \n",
      "\n",
      "Fold: 13  Epoch: 270  Training loss = 2.4270  Validation loss = 3.2293  \n",
      "\n",
      "Fold: 13  Epoch: 271  Training loss = 2.4269  Validation loss = 3.2305  \n",
      "\n",
      "Fold: 13  Epoch: 272  Training loss = 2.4267  Validation loss = 3.2304  \n",
      "\n",
      "Fold: 13  Epoch: 273  Training loss = 2.4263  Validation loss = 3.2282  \n",
      "\n",
      "Fold: 13  Epoch: 274  Training loss = 2.4262  Validation loss = 3.2308  \n",
      "\n",
      "Fold: 13  Epoch: 275  Training loss = 2.4259  Validation loss = 3.2287  \n",
      "\n",
      "Fold: 13  Epoch: 276  Training loss = 2.4256  Validation loss = 3.2257  \n",
      "\n",
      "Fold: 13  Epoch: 277  Training loss = 2.4253  Validation loss = 3.2221  \n",
      "\n",
      "Fold: 13  Epoch: 278  Training loss = 2.4251  Validation loss = 3.2238  \n",
      "\n",
      "Fold: 13  Epoch: 279  Training loss = 2.4248  Validation loss = 3.2221  \n",
      "\n",
      "Fold: 13  Epoch: 280  Training loss = 2.4244  Validation loss = 3.2175  \n",
      "\n",
      "Fold: 13  Epoch: 281  Training loss = 2.4244  Validation loss = 3.2182  \n",
      "\n",
      "Fold: 13  Epoch: 282  Training loss = 2.4242  Validation loss = 3.2170  \n",
      "\n",
      "Fold: 13  Epoch: 283  Training loss = 2.4241  Validation loss = 3.2173  \n",
      "\n",
      "Fold: 13  Epoch: 284  Training loss = 2.4238  Validation loss = 3.2170  \n",
      "\n",
      "Fold: 13  Epoch: 285  Training loss = 2.4236  Validation loss = 3.2152  \n",
      "\n",
      "Fold: 13  Epoch: 286  Training loss = 2.4235  Validation loss = 3.2171  \n",
      "\n",
      "Fold: 13  Epoch: 287  Training loss = 2.4233  Validation loss = 3.2179  \n",
      "\n",
      "Fold: 13  Epoch: 288  Training loss = 2.4230  Validation loss = 3.2161  \n",
      "\n",
      "Fold: 13  Epoch: 289  Training loss = 2.4228  Validation loss = 3.2160  \n",
      "\n",
      "Fold: 13  Epoch: 290  Training loss = 2.4223  Validation loss = 3.2122  \n",
      "\n",
      "Fold: 13  Epoch: 291  Training loss = 2.4221  Validation loss = 3.2112  \n",
      "\n",
      "Fold: 13  Epoch: 292  Training loss = 2.4219  Validation loss = 3.2118  \n",
      "\n",
      "Fold: 13  Epoch: 293  Training loss = 2.4217  Validation loss = 3.2100  \n",
      "\n",
      "Fold: 13  Epoch: 294  Training loss = 2.4213  Validation loss = 3.2058  \n",
      "\n",
      "Fold: 13  Epoch: 295  Training loss = 2.4211  Validation loss = 3.2047  \n",
      "\n",
      "Fold: 13  Epoch: 296  Training loss = 2.4211  Validation loss = 3.2072  \n",
      "\n",
      "Fold: 13  Epoch: 297  Training loss = 2.4209  Validation loss = 3.2059  \n",
      "\n",
      "Fold: 13  Epoch: 298  Training loss = 2.4207  Validation loss = 3.2087  \n",
      "\n",
      "Fold: 13  Epoch: 299  Training loss = 2.4206  Validation loss = 3.2107  \n",
      "\n",
      "Fold: 13  Epoch: 300  Training loss = 2.4204  Validation loss = 3.2113  \n",
      "\n",
      "Fold: 13  Epoch: 301  Training loss = 2.4202  Validation loss = 3.2114  \n",
      "\n",
      "Fold: 13  Epoch: 302  Training loss = 2.4200  Validation loss = 3.2116  \n",
      "\n",
      "Check model:  Fold: 13  Epoch: 295  Training loss = 2.4200  Validation loss = 3.2116  \n",
      "\n",
      "Fold: 14  Epoch: 1  Training loss = 2.5138  Validation loss = 6.3420  \n",
      "\n",
      "Fold: 14  Epoch: 2  Training loss = 2.5135  Validation loss = 6.3401  \n",
      "\n",
      "Fold: 14  Epoch: 3  Training loss = 2.5129  Validation loss = 6.3373  \n",
      "\n",
      "Fold: 14  Epoch: 4  Training loss = 2.5120  Validation loss = 6.3322  \n",
      "\n",
      "Fold: 14  Epoch: 5  Training loss = 2.5120  Validation loss = 6.3323  \n",
      "\n",
      "Fold: 14  Epoch: 6  Training loss = 2.5114  Validation loss = 6.3293  \n",
      "\n",
      "Fold: 14  Epoch: 7  Training loss = 2.5106  Validation loss = 6.3255  \n",
      "\n",
      "Fold: 14  Epoch: 8  Training loss = 2.5099  Validation loss = 6.3213  \n",
      "\n",
      "Fold: 14  Epoch: 9  Training loss = 2.5096  Validation loss = 6.3200  \n",
      "\n",
      "Fold: 14  Epoch: 10  Training loss = 2.5085  Validation loss = 6.3131  \n",
      "\n",
      "Fold: 14  Epoch: 11  Training loss = 2.5082  Validation loss = 6.3123  \n",
      "\n",
      "Fold: 14  Epoch: 12  Training loss = 2.5077  Validation loss = 6.3097  \n",
      "\n",
      "Fold: 14  Epoch: 13  Training loss = 2.5068  Validation loss = 6.3045  \n",
      "\n",
      "Fold: 14  Epoch: 14  Training loss = 2.5059  Validation loss = 6.2988  \n",
      "\n",
      "Fold: 14  Epoch: 15  Training loss = 2.5055  Validation loss = 6.2972  \n",
      "\n",
      "Fold: 14  Epoch: 16  Training loss = 2.5050  Validation loss = 6.2947  \n",
      "\n",
      "Fold: 14  Epoch: 17  Training loss = 2.5045  Validation loss = 6.2921  \n",
      "\n",
      "Fold: 14  Epoch: 18  Training loss = 2.5041  Validation loss = 6.2897  \n",
      "\n",
      "Fold: 14  Epoch: 19  Training loss = 2.5031  Validation loss = 6.2836  \n",
      "\n",
      "Fold: 14  Epoch: 20  Training loss = 2.5024  Validation loss = 6.2792  \n",
      "\n",
      "Fold: 14  Epoch: 21  Training loss = 2.5022  Validation loss = 6.2783  \n",
      "\n",
      "Fold: 14  Epoch: 22  Training loss = 2.5019  Validation loss = 6.2773  \n",
      "\n",
      "Fold: 14  Epoch: 23  Training loss = 2.5014  Validation loss = 6.2740  \n",
      "\n",
      "Fold: 14  Epoch: 24  Training loss = 2.5007  Validation loss = 6.2705  \n",
      "\n",
      "Fold: 14  Epoch: 25  Training loss = 2.5007  Validation loss = 6.2708  \n",
      "\n",
      "Fold: 14  Epoch: 26  Training loss = 2.5002  Validation loss = 6.2683  \n",
      "\n",
      "Fold: 14  Epoch: 27  Training loss = 2.4996  Validation loss = 6.2645  \n",
      "\n",
      "Fold: 14  Epoch: 28  Training loss = 2.4990  Validation loss = 6.2606  \n",
      "\n",
      "Fold: 14  Epoch: 29  Training loss = 2.4985  Validation loss = 6.2583  \n",
      "\n",
      "Fold: 14  Epoch: 30  Training loss = 2.4980  Validation loss = 6.2548  \n",
      "\n",
      "Fold: 14  Epoch: 31  Training loss = 2.4974  Validation loss = 6.2506  \n",
      "\n",
      "Fold: 14  Epoch: 32  Training loss = 2.4970  Validation loss = 6.2485  \n",
      "\n",
      "Fold: 14  Epoch: 33  Training loss = 2.4968  Validation loss = 6.2477  \n",
      "\n",
      "Fold: 14  Epoch: 34  Training loss = 2.4965  Validation loss = 6.2461  \n",
      "\n",
      "Fold: 14  Epoch: 35  Training loss = 2.4966  Validation loss = 6.2473  \n",
      "\n",
      "Fold: 14  Epoch: 36  Training loss = 2.4959  Validation loss = 6.2433  \n",
      "\n",
      "Fold: 14  Epoch: 37  Training loss = 2.4954  Validation loss = 6.2398  \n",
      "\n",
      "Fold: 14  Epoch: 38  Training loss = 2.4947  Validation loss = 6.2354  \n",
      "\n",
      "Fold: 14  Epoch: 39  Training loss = 2.4945  Validation loss = 6.2344  \n",
      "\n",
      "Fold: 14  Epoch: 40  Training loss = 2.4940  Validation loss = 6.2315  \n",
      "\n",
      "Fold: 14  Epoch: 41  Training loss = 2.4936  Validation loss = 6.2293  \n",
      "\n",
      "Fold: 14  Epoch: 42  Training loss = 2.4936  Validation loss = 6.2298  \n",
      "\n",
      "Fold: 14  Epoch: 43  Training loss = 2.4934  Validation loss = 6.2283  \n",
      "\n",
      "Fold: 14  Epoch: 44  Training loss = 2.4928  Validation loss = 6.2244  \n",
      "\n",
      "Fold: 14  Epoch: 45  Training loss = 2.4924  Validation loss = 6.2217  \n",
      "\n",
      "Fold: 14  Epoch: 46  Training loss = 2.4921  Validation loss = 6.2200  \n",
      "\n",
      "Fold: 14  Epoch: 47  Training loss = 2.4917  Validation loss = 6.2180  \n",
      "\n",
      "Fold: 14  Epoch: 48  Training loss = 2.4916  Validation loss = 6.2175  \n",
      "\n",
      "Fold: 14  Epoch: 49  Training loss = 2.4910  Validation loss = 6.2140  \n",
      "\n",
      "Fold: 14  Epoch: 50  Training loss = 2.4906  Validation loss = 6.2115  \n",
      "\n",
      "Fold: 14  Epoch: 51  Training loss = 2.4902  Validation loss = 6.2090  \n",
      "\n",
      "Fold: 14  Epoch: 52  Training loss = 2.4900  Validation loss = 6.2084  \n",
      "\n",
      "Fold: 14  Epoch: 53  Training loss = 2.4896  Validation loss = 6.2054  \n",
      "\n",
      "Fold: 14  Epoch: 54  Training loss = 2.4893  Validation loss = 6.2032  \n",
      "\n",
      "Fold: 14  Epoch: 55  Training loss = 2.4886  Validation loss = 6.1987  \n",
      "\n",
      "Fold: 14  Epoch: 56  Training loss = 2.4883  Validation loss = 6.1971  \n",
      "\n",
      "Fold: 14  Epoch: 57  Training loss = 2.4878  Validation loss = 6.1935  \n",
      "\n",
      "Fold: 14  Epoch: 58  Training loss = 2.4870  Validation loss = 6.1882  \n",
      "\n",
      "Fold: 14  Epoch: 59  Training loss = 2.4870  Validation loss = 6.1891  \n",
      "\n",
      "Fold: 14  Epoch: 60  Training loss = 2.4868  Validation loss = 6.1884  \n",
      "\n",
      "Fold: 14  Epoch: 61  Training loss = 2.4869  Validation loss = 6.1908  \n",
      "\n",
      "Fold: 14  Epoch: 62  Training loss = 2.4867  Validation loss = 6.1898  \n",
      "\n",
      "Fold: 14  Epoch: 63  Training loss = 2.4863  Validation loss = 6.1876  \n",
      "\n",
      "Fold: 14  Epoch: 64  Training loss = 2.4863  Validation loss = 6.1883  \n",
      "\n",
      "Fold: 14  Epoch: 65  Training loss = 2.4862  Validation loss = 6.1881  \n",
      "\n",
      "Fold: 14  Epoch: 66  Training loss = 2.4862  Validation loss = 6.1892  \n",
      "\n",
      "Fold: 14  Epoch: 67  Training loss = 2.4861  Validation loss = 6.1889  \n",
      "\n",
      "Fold: 14  Epoch: 68  Training loss = 2.4855  Validation loss = 6.1846  \n",
      "\n",
      "Fold: 14  Epoch: 69  Training loss = 2.4852  Validation loss = 6.1838  \n",
      "\n",
      "Fold: 14  Epoch: 70  Training loss = 2.4850  Validation loss = 6.1820  \n",
      "\n",
      "Fold: 14  Epoch: 71  Training loss = 2.4845  Validation loss = 6.1787  \n",
      "\n",
      "Fold: 14  Epoch: 72  Training loss = 2.4846  Validation loss = 6.1810  \n",
      "\n",
      "Fold: 14  Epoch: 73  Training loss = 2.4841  Validation loss = 6.1776  \n",
      "\n",
      "Fold: 14  Epoch: 74  Training loss = 2.4838  Validation loss = 6.1760  \n",
      "\n",
      "Fold: 14  Epoch: 75  Training loss = 2.4835  Validation loss = 6.1743  \n",
      "\n",
      "Fold: 14  Epoch: 76  Training loss = 2.4834  Validation loss = 6.1745  \n",
      "\n",
      "Fold: 14  Epoch: 77  Training loss = 2.4831  Validation loss = 6.1729  \n",
      "\n",
      "Fold: 14  Epoch: 78  Training loss = 2.4829  Validation loss = 6.1720  \n",
      "\n",
      "Fold: 14  Epoch: 79  Training loss = 2.4824  Validation loss = 6.1685  \n",
      "\n",
      "Fold: 14  Epoch: 80  Training loss = 2.4822  Validation loss = 6.1675  \n",
      "\n",
      "Fold: 14  Epoch: 81  Training loss = 2.4817  Validation loss = 6.1637  \n",
      "\n",
      "Fold: 14  Epoch: 82  Training loss = 2.4811  Validation loss = 6.1589  \n",
      "\n",
      "Fold: 14  Epoch: 83  Training loss = 2.4808  Validation loss = 6.1575  \n",
      "\n",
      "Fold: 14  Epoch: 84  Training loss = 2.4804  Validation loss = 6.1547  \n",
      "\n",
      "Fold: 14  Epoch: 85  Training loss = 2.4801  Validation loss = 6.1527  \n",
      "\n",
      "Fold: 14  Epoch: 86  Training loss = 2.4798  Validation loss = 6.1508  \n",
      "\n",
      "Fold: 14  Epoch: 87  Training loss = 2.4795  Validation loss = 6.1487  \n",
      "\n",
      "Fold: 14  Epoch: 88  Training loss = 2.4794  Validation loss = 6.1487  \n",
      "\n",
      "Fold: 14  Epoch: 89  Training loss = 2.4794  Validation loss = 6.1493  \n",
      "\n",
      "Fold: 14  Epoch: 90  Training loss = 2.4788  Validation loss = 6.1453  \n",
      "\n",
      "Fold: 14  Epoch: 91  Training loss = 2.4783  Validation loss = 6.1412  \n",
      "\n",
      "Fold: 14  Epoch: 92  Training loss = 2.4781  Validation loss = 6.1397  \n",
      "\n",
      "Fold: 14  Epoch: 93  Training loss = 2.4777  Validation loss = 6.1372  \n",
      "\n",
      "Fold: 14  Epoch: 94  Training loss = 2.4774  Validation loss = 6.1360  \n",
      "\n",
      "Fold: 14  Epoch: 95  Training loss = 2.4770  Validation loss = 6.1324  \n",
      "\n",
      "Fold: 14  Epoch: 96  Training loss = 2.4766  Validation loss = 6.1299  \n",
      "\n",
      "Fold: 14  Epoch: 97  Training loss = 2.4764  Validation loss = 6.1293  \n",
      "\n",
      "Fold: 14  Epoch: 98  Training loss = 2.4758  Validation loss = 6.1249  \n",
      "\n",
      "Fold: 14  Epoch: 99  Training loss = 2.4753  Validation loss = 6.1206  \n",
      "\n",
      "Fold: 14  Epoch: 100  Training loss = 2.4750  Validation loss = 6.1177  \n",
      "\n",
      "Fold: 14  Epoch: 101  Training loss = 2.4745  Validation loss = 6.1139  \n",
      "\n",
      "Fold: 14  Epoch: 102  Training loss = 2.4739  Validation loss = 6.1084  \n",
      "\n",
      "Fold: 14  Epoch: 103  Training loss = 2.4735  Validation loss = 6.1056  \n",
      "\n",
      "Fold: 14  Epoch: 104  Training loss = 2.4732  Validation loss = 6.1030  \n",
      "\n",
      "Fold: 14  Epoch: 105  Training loss = 2.4728  Validation loss = 6.1007  \n",
      "\n",
      "Fold: 14  Epoch: 106  Training loss = 2.4725  Validation loss = 6.1000  \n",
      "\n",
      "Fold: 14  Epoch: 107  Training loss = 2.4724  Validation loss = 6.0996  \n",
      "\n",
      "Fold: 14  Epoch: 108  Training loss = 2.4723  Validation loss = 6.1001  \n",
      "\n",
      "Fold: 14  Epoch: 109  Training loss = 2.4720  Validation loss = 6.0981  \n",
      "\n",
      "Fold: 14  Epoch: 110  Training loss = 2.4720  Validation loss = 6.0990  \n",
      "\n",
      "Fold: 14  Epoch: 111  Training loss = 2.4715  Validation loss = 6.0951  \n",
      "\n",
      "Fold: 14  Epoch: 112  Training loss = 2.4712  Validation loss = 6.0931  \n",
      "\n",
      "Fold: 14  Epoch: 113  Training loss = 2.4710  Validation loss = 6.0917  \n",
      "\n",
      "Fold: 14  Epoch: 114  Training loss = 2.4705  Validation loss = 6.0883  \n",
      "\n",
      "Fold: 14  Epoch: 115  Training loss = 2.4701  Validation loss = 6.0854  \n",
      "\n",
      "Fold: 14  Epoch: 116  Training loss = 2.4701  Validation loss = 6.0854  \n",
      "\n",
      "Fold: 14  Epoch: 117  Training loss = 2.4697  Validation loss = 6.0829  \n",
      "\n",
      "Fold: 14  Epoch: 118  Training loss = 2.4695  Validation loss = 6.0815  \n",
      "\n",
      "Fold: 14  Epoch: 119  Training loss = 2.4691  Validation loss = 6.0786  \n",
      "\n",
      "Fold: 14  Epoch: 120  Training loss = 2.4687  Validation loss = 6.0741  \n",
      "\n",
      "Fold: 14  Epoch: 121  Training loss = 2.4681  Validation loss = 6.0685  \n",
      "\n",
      "Fold: 14  Epoch: 122  Training loss = 2.4679  Validation loss = 6.0673  \n",
      "\n",
      "Fold: 14  Epoch: 123  Training loss = 2.4678  Validation loss = 6.0677  \n",
      "\n",
      "Fold: 14  Epoch: 124  Training loss = 2.4677  Validation loss = 6.0662  \n",
      "\n",
      "Fold: 14  Epoch: 125  Training loss = 2.4675  Validation loss = 6.0658  \n",
      "\n",
      "Fold: 14  Epoch: 126  Training loss = 2.4675  Validation loss = 6.0671  \n",
      "\n",
      "Fold: 14  Epoch: 127  Training loss = 2.4675  Validation loss = 6.0679  \n",
      "\n",
      "Fold: 14  Epoch: 128  Training loss = 2.4672  Validation loss = 6.0657  \n",
      "\n",
      "Fold: 14  Epoch: 129  Training loss = 2.4672  Validation loss = 6.0668  \n",
      "\n",
      "Fold: 14  Epoch: 130  Training loss = 2.4668  Validation loss = 6.0640  \n",
      "\n",
      "Fold: 14  Epoch: 131  Training loss = 2.4667  Validation loss = 6.0631  \n",
      "\n",
      "Fold: 14  Epoch: 132  Training loss = 2.4664  Validation loss = 6.0616  \n",
      "\n",
      "Fold: 14  Epoch: 133  Training loss = 2.4662  Validation loss = 6.0599  \n",
      "\n",
      "Fold: 14  Epoch: 134  Training loss = 2.4660  Validation loss = 6.0583  \n",
      "\n",
      "Fold: 14  Epoch: 135  Training loss = 2.4658  Validation loss = 6.0573  \n",
      "\n",
      "Fold: 14  Epoch: 136  Training loss = 2.4652  Validation loss = 6.0514  \n",
      "\n",
      "Fold: 14  Epoch: 137  Training loss = 2.4651  Validation loss = 6.0510  \n",
      "\n",
      "Fold: 14  Epoch: 138  Training loss = 2.4650  Validation loss = 6.0506  \n",
      "\n",
      "Fold: 14  Epoch: 139  Training loss = 2.4651  Validation loss = 6.0526  \n",
      "\n",
      "Fold: 14  Epoch: 140  Training loss = 2.4647  Validation loss = 6.0487  \n",
      "\n",
      "Fold: 14  Epoch: 141  Training loss = 2.4645  Validation loss = 6.0480  \n",
      "\n",
      "Fold: 14  Epoch: 142  Training loss = 2.4644  Validation loss = 6.0485  \n",
      "\n",
      "Fold: 14  Epoch: 143  Training loss = 2.4642  Validation loss = 6.0465  \n",
      "\n",
      "Fold: 14  Epoch: 144  Training loss = 2.4642  Validation loss = 6.0482  \n",
      "\n",
      "Fold: 14  Epoch: 145  Training loss = 2.4642  Validation loss = 6.0501  \n",
      "\n",
      "Fold: 14  Epoch: 146  Training loss = 2.4639  Validation loss = 6.0479  \n",
      "\n",
      "Fold: 14  Epoch: 147  Training loss = 2.4639  Validation loss = 6.0484  \n",
      "\n",
      "Fold: 14  Epoch: 148  Training loss = 2.4637  Validation loss = 6.0478  \n",
      "\n",
      "Fold: 14  Epoch: 149  Training loss = 2.4636  Validation loss = 6.0482  \n",
      "\n",
      "Fold: 14  Epoch: 150  Training loss = 2.4635  Validation loss = 6.0487  \n",
      "\n",
      "Fold: 14  Epoch: 151  Training loss = 2.4629  Validation loss = 6.0427  \n",
      "\n",
      "Fold: 14  Epoch: 152  Training loss = 2.4627  Validation loss = 6.0411  \n",
      "\n",
      "Fold: 14  Epoch: 153  Training loss = 2.4625  Validation loss = 6.0396  \n",
      "\n",
      "Fold: 14  Epoch: 154  Training loss = 2.4622  Validation loss = 6.0366  \n",
      "\n",
      "Fold: 14  Epoch: 155  Training loss = 2.4623  Validation loss = 6.0388  \n",
      "\n",
      "Fold: 14  Epoch: 156  Training loss = 2.4620  Validation loss = 6.0366  \n",
      "\n",
      "Fold: 14  Epoch: 157  Training loss = 2.4618  Validation loss = 6.0358  \n",
      "\n",
      "Fold: 14  Epoch: 158  Training loss = 2.4618  Validation loss = 6.0360  \n",
      "\n",
      "Fold: 14  Epoch: 159  Training loss = 2.4614  Validation loss = 6.0336  \n",
      "\n",
      "Fold: 14  Epoch: 160  Training loss = 2.4610  Validation loss = 6.0295  \n",
      "\n",
      "Fold: 14  Epoch: 161  Training loss = 2.4608  Validation loss = 6.0281  \n",
      "\n",
      "Fold: 14  Epoch: 162  Training loss = 2.4606  Validation loss = 6.0266  \n",
      "\n",
      "Fold: 14  Epoch: 163  Training loss = 2.4603  Validation loss = 6.0255  \n",
      "\n",
      "Fold: 14  Epoch: 164  Training loss = 2.4599  Validation loss = 6.0210  \n",
      "\n",
      "Fold: 14  Epoch: 165  Training loss = 2.4597  Validation loss = 6.0194  \n",
      "\n",
      "Fold: 14  Epoch: 166  Training loss = 2.4596  Validation loss = 6.0202  \n",
      "\n",
      "Fold: 14  Epoch: 167  Training loss = 2.4594  Validation loss = 6.0187  \n",
      "\n",
      "Fold: 14  Epoch: 168  Training loss = 2.4591  Validation loss = 6.0166  \n",
      "\n",
      "Fold: 14  Epoch: 169  Training loss = 2.4589  Validation loss = 6.0146  \n",
      "\n",
      "Fold: 14  Epoch: 170  Training loss = 2.4588  Validation loss = 6.0132  \n",
      "\n",
      "Fold: 14  Epoch: 171  Training loss = 2.4586  Validation loss = 6.0128  \n",
      "\n",
      "Fold: 14  Epoch: 172  Training loss = 2.4585  Validation loss = 6.0122  \n",
      "\n",
      "Fold: 14  Epoch: 173  Training loss = 2.4581  Validation loss = 6.0090  \n",
      "\n",
      "Fold: 14  Epoch: 174  Training loss = 2.4580  Validation loss = 6.0081  \n",
      "\n",
      "Fold: 14  Epoch: 175  Training loss = 2.4576  Validation loss = 6.0053  \n",
      "\n",
      "Fold: 14  Epoch: 176  Training loss = 2.4575  Validation loss = 6.0053  \n",
      "\n",
      "Fold: 14  Epoch: 177  Training loss = 2.4575  Validation loss = 6.0063  \n",
      "\n",
      "Fold: 14  Epoch: 178  Training loss = 2.4573  Validation loss = 6.0045  \n",
      "\n",
      "Fold: 14  Epoch: 179  Training loss = 2.4572  Validation loss = 6.0045  \n",
      "\n",
      "Fold: 14  Epoch: 180  Training loss = 2.4571  Validation loss = 6.0052  \n",
      "\n",
      "Fold: 14  Epoch: 181  Training loss = 2.4572  Validation loss = 6.0080  \n",
      "\n",
      "Fold: 14  Epoch: 182  Training loss = 2.4573  Validation loss = 6.0111  \n",
      "\n",
      "Check model:  Fold: 14  Epoch: 179  Training loss = 2.4573  Validation loss = 6.0111  \n",
      "\n",
      "Fold: 15  Epoch: 1  Training loss = 2.8489  Validation loss = 6.6336  \n",
      "\n",
      "Fold: 15  Epoch: 2  Training loss = 2.8474  Validation loss = 6.6275  \n",
      "\n",
      "Fold: 15  Epoch: 3  Training loss = 2.8474  Validation loss = 6.6276  \n",
      "\n",
      "Fold: 15  Epoch: 4  Training loss = 2.8457  Validation loss = 6.6217  \n",
      "\n",
      "Fold: 15  Epoch: 5  Training loss = 2.8457  Validation loss = 6.6218  \n",
      "\n",
      "Fold: 15  Epoch: 6  Training loss = 2.8443  Validation loss = 6.6166  \n",
      "\n",
      "Fold: 15  Epoch: 7  Training loss = 2.8439  Validation loss = 6.6150  \n",
      "\n",
      "Fold: 15  Epoch: 8  Training loss = 2.8431  Validation loss = 6.6118  \n",
      "\n",
      "Fold: 15  Epoch: 9  Training loss = 2.8423  Validation loss = 6.6085  \n",
      "\n",
      "Fold: 15  Epoch: 10  Training loss = 2.8414  Validation loss = 6.6054  \n",
      "\n",
      "Fold: 15  Epoch: 11  Training loss = 2.8405  Validation loss = 6.6018  \n",
      "\n",
      "Fold: 15  Epoch: 12  Training loss = 2.8400  Validation loss = 6.6000  \n",
      "\n",
      "Fold: 15  Epoch: 13  Training loss = 2.8388  Validation loss = 6.5953  \n",
      "\n",
      "Fold: 15  Epoch: 14  Training loss = 2.8389  Validation loss = 6.5959  \n",
      "\n",
      "Fold: 15  Epoch: 15  Training loss = 2.8384  Validation loss = 6.5937  \n",
      "\n",
      "Fold: 15  Epoch: 16  Training loss = 2.8375  Validation loss = 6.5904  \n",
      "\n",
      "Fold: 15  Epoch: 17  Training loss = 2.8372  Validation loss = 6.5892  \n",
      "\n",
      "Fold: 15  Epoch: 18  Training loss = 2.8357  Validation loss = 6.5838  \n",
      "\n",
      "Fold: 15  Epoch: 19  Training loss = 2.8349  Validation loss = 6.5806  \n",
      "\n",
      "Fold: 15  Epoch: 20  Training loss = 2.8348  Validation loss = 6.5804  \n",
      "\n",
      "Fold: 15  Epoch: 21  Training loss = 2.8337  Validation loss = 6.5759  \n",
      "\n",
      "Fold: 15  Epoch: 22  Training loss = 2.8334  Validation loss = 6.5751  \n",
      "\n",
      "Fold: 15  Epoch: 23  Training loss = 2.8330  Validation loss = 6.5738  \n",
      "\n",
      "Fold: 15  Epoch: 24  Training loss = 2.8320  Validation loss = 6.5698  \n",
      "\n",
      "Fold: 15  Epoch: 25  Training loss = 2.8310  Validation loss = 6.5658  \n",
      "\n",
      "Fold: 15  Epoch: 26  Training loss = 2.8291  Validation loss = 6.5584  \n",
      "\n",
      "Fold: 15  Epoch: 27  Training loss = 2.8276  Validation loss = 6.5524  \n",
      "\n",
      "Fold: 15  Epoch: 28  Training loss = 2.8266  Validation loss = 6.5487  \n",
      "\n",
      "Fold: 15  Epoch: 29  Training loss = 2.8251  Validation loss = 6.5419  \n",
      "\n",
      "Fold: 15  Epoch: 30  Training loss = 2.8248  Validation loss = 6.5405  \n",
      "\n",
      "Fold: 15  Epoch: 31  Training loss = 2.8237  Validation loss = 6.5359  \n",
      "\n",
      "Fold: 15  Epoch: 32  Training loss = 2.8230  Validation loss = 6.5331  \n",
      "\n",
      "Fold: 15  Epoch: 33  Training loss = 2.8214  Validation loss = 6.5255  \n",
      "\n",
      "Fold: 15  Epoch: 34  Training loss = 2.8198  Validation loss = 6.5183  \n",
      "\n",
      "Fold: 15  Epoch: 35  Training loss = 2.8184  Validation loss = 6.5123  \n",
      "\n",
      "Fold: 15  Epoch: 36  Training loss = 2.8181  Validation loss = 6.5108  \n",
      "\n",
      "Fold: 15  Epoch: 37  Training loss = 2.8175  Validation loss = 6.5082  \n",
      "\n",
      "Fold: 15  Epoch: 38  Training loss = 2.8175  Validation loss = 6.5086  \n",
      "\n",
      "Fold: 15  Epoch: 39  Training loss = 2.8161  Validation loss = 6.5020  \n",
      "\n",
      "Fold: 15  Epoch: 40  Training loss = 2.8155  Validation loss = 6.4992  \n",
      "\n",
      "Fold: 15  Epoch: 41  Training loss = 2.8151  Validation loss = 6.4980  \n",
      "\n",
      "Fold: 15  Epoch: 42  Training loss = 2.8141  Validation loss = 6.4930  \n",
      "\n",
      "Fold: 15  Epoch: 43  Training loss = 2.8134  Validation loss = 6.4904  \n",
      "\n",
      "Fold: 15  Epoch: 44  Training loss = 2.8125  Validation loss = 6.4867  \n",
      "\n",
      "Fold: 15  Epoch: 45  Training loss = 2.8110  Validation loss = 6.4805  \n",
      "\n",
      "Fold: 15  Epoch: 46  Training loss = 2.8100  Validation loss = 6.4774  \n",
      "\n",
      "Fold: 15  Epoch: 47  Training loss = 2.8078  Validation loss = 6.4775  \n",
      "\n",
      "Fold: 15  Epoch: 48  Training loss = 2.8050  Validation loss = 6.4739  \n",
      "\n",
      "Fold: 15  Epoch: 49  Training loss = 2.8044  Validation loss = 6.4715  \n",
      "\n",
      "Fold: 15  Epoch: 50  Training loss = 2.8038  Validation loss = 6.4707  \n",
      "\n",
      "Fold: 15  Epoch: 51  Training loss = 2.8035  Validation loss = 6.4693  \n",
      "\n",
      "Fold: 15  Epoch: 52  Training loss = 2.8026  Validation loss = 6.4652  \n",
      "\n",
      "Fold: 15  Epoch: 53  Training loss = 2.8021  Validation loss = 6.4633  \n",
      "\n",
      "Fold: 15  Epoch: 54  Training loss = 2.8017  Validation loss = 6.4614  \n",
      "\n",
      "Fold: 15  Epoch: 55  Training loss = 2.8016  Validation loss = 6.4611  \n",
      "\n",
      "Fold: 15  Epoch: 56  Training loss = 2.8005  Validation loss = 6.4555  \n",
      "\n",
      "Fold: 15  Epoch: 57  Training loss = 2.8005  Validation loss = 6.4562  \n",
      "\n",
      "Fold: 15  Epoch: 58  Training loss = 2.8004  Validation loss = 6.4557  \n",
      "\n",
      "Fold: 15  Epoch: 59  Training loss = 2.7998  Validation loss = 6.4532  \n",
      "\n",
      "Fold: 15  Epoch: 60  Training loss = 2.7991  Validation loss = 6.4502  \n",
      "\n",
      "Fold: 15  Epoch: 61  Training loss = 2.7990  Validation loss = 6.4500  \n",
      "\n",
      "Fold: 15  Epoch: 62  Training loss = 2.7981  Validation loss = 6.4456  \n",
      "\n",
      "Fold: 15  Epoch: 63  Training loss = 2.7976  Validation loss = 6.4431  \n",
      "\n",
      "Fold: 15  Epoch: 64  Training loss = 2.7974  Validation loss = 6.4423  \n",
      "\n",
      "Fold: 15  Epoch: 65  Training loss = 2.7965  Validation loss = 6.4377  \n",
      "\n",
      "Fold: 15  Epoch: 66  Training loss = 2.7954  Validation loss = 6.4324  \n",
      "\n",
      "Fold: 15  Epoch: 67  Training loss = 2.7948  Validation loss = 6.4295  \n",
      "\n",
      "Fold: 15  Epoch: 68  Training loss = 2.7946  Validation loss = 6.4289  \n",
      "\n",
      "Fold: 15  Epoch: 69  Training loss = 2.7945  Validation loss = 6.4287  \n",
      "\n",
      "Fold: 15  Epoch: 70  Training loss = 2.7942  Validation loss = 6.4271  \n",
      "\n",
      "Fold: 15  Epoch: 71  Training loss = 2.7938  Validation loss = 6.4254  \n",
      "\n",
      "Fold: 15  Epoch: 72  Training loss = 2.7932  Validation loss = 6.4228  \n",
      "\n",
      "Fold: 15  Epoch: 73  Training loss = 2.7923  Validation loss = 6.4181  \n",
      "\n",
      "Fold: 15  Epoch: 74  Training loss = 2.7912  Validation loss = 6.4126  \n",
      "\n",
      "Fold: 15  Epoch: 75  Training loss = 2.7903  Validation loss = 6.4077  \n",
      "\n",
      "Fold: 15  Epoch: 76  Training loss = 2.7894  Validation loss = 6.4033  \n",
      "\n",
      "Fold: 15  Epoch: 77  Training loss = 2.7885  Validation loss = 6.3982  \n",
      "\n",
      "Fold: 15  Epoch: 78  Training loss = 2.7880  Validation loss = 6.3958  \n",
      "\n",
      "Fold: 15  Epoch: 79  Training loss = 2.7880  Validation loss = 6.3960  \n",
      "\n",
      "Fold: 15  Epoch: 80  Training loss = 2.7869  Validation loss = 6.3901  \n",
      "\n",
      "Fold: 15  Epoch: 81  Training loss = 2.7868  Validation loss = 6.3897  \n",
      "\n",
      "Fold: 15  Epoch: 82  Training loss = 2.7863  Validation loss = 6.3874  \n",
      "\n",
      "Fold: 15  Epoch: 83  Training loss = 2.7861  Validation loss = 6.3861  \n",
      "\n",
      "Fold: 15  Epoch: 84  Training loss = 2.7859  Validation loss = 6.3855  \n",
      "\n",
      "Fold: 15  Epoch: 85  Training loss = 2.7856  Validation loss = 6.3840  \n",
      "\n",
      "Fold: 15  Epoch: 86  Training loss = 2.7850  Validation loss = 6.3815  \n",
      "\n",
      "Fold: 15  Epoch: 87  Training loss = 2.7848  Validation loss = 6.3811  \n",
      "\n",
      "Fold: 15  Epoch: 88  Training loss = 2.7842  Validation loss = 6.3775  \n",
      "\n",
      "Fold: 15  Epoch: 89  Training loss = 2.7841  Validation loss = 6.3774  \n",
      "\n",
      "Fold: 15  Epoch: 90  Training loss = 2.7839  Validation loss = 6.3763  \n",
      "\n",
      "Fold: 15  Epoch: 91  Training loss = 2.7826  Validation loss = 6.3693  \n",
      "\n",
      "Fold: 15  Epoch: 92  Training loss = 2.7821  Validation loss = 6.3666  \n",
      "\n",
      "Fold: 15  Epoch: 93  Training loss = 2.7818  Validation loss = 6.3654  \n",
      "\n",
      "Fold: 15  Epoch: 94  Training loss = 2.7814  Validation loss = 6.3640  \n",
      "\n",
      "Fold: 15  Epoch: 95  Training loss = 2.7808  Validation loss = 6.3602  \n",
      "\n",
      "Fold: 15  Epoch: 96  Training loss = 2.7804  Validation loss = 6.3579  \n",
      "\n",
      "Fold: 15  Epoch: 97  Training loss = 2.7801  Validation loss = 6.3571  \n",
      "\n",
      "Fold: 15  Epoch: 98  Training loss = 2.7793  Validation loss = 6.3525  \n",
      "\n",
      "Fold: 15  Epoch: 99  Training loss = 2.7789  Validation loss = 6.3497  \n",
      "\n",
      "Fold: 15  Epoch: 100  Training loss = 2.7788  Validation loss = 6.3498  \n",
      "\n",
      "Fold: 15  Epoch: 101  Training loss = 2.7786  Validation loss = 6.3490  \n",
      "\n",
      "Fold: 15  Epoch: 102  Training loss = 2.7777  Validation loss = 6.3438  \n",
      "\n",
      "Fold: 15  Epoch: 103  Training loss = 2.7774  Validation loss = 6.3423  \n",
      "\n",
      "Fold: 15  Epoch: 104  Training loss = 2.7770  Validation loss = 6.3406  \n",
      "\n",
      "Fold: 15  Epoch: 105  Training loss = 2.7766  Validation loss = 6.3386  \n",
      "\n",
      "Fold: 15  Epoch: 106  Training loss = 2.7766  Validation loss = 6.3391  \n",
      "\n",
      "Fold: 15  Epoch: 107  Training loss = 2.7767  Validation loss = 6.3405  \n",
      "\n",
      "Fold: 15  Epoch: 108  Training loss = 2.7761  Validation loss = 6.3371  \n",
      "\n",
      "Fold: 15  Epoch: 109  Training loss = 2.7756  Validation loss = 6.3343  \n",
      "\n",
      "Fold: 15  Epoch: 110  Training loss = 2.7752  Validation loss = 6.3324  \n",
      "\n",
      "Fold: 15  Epoch: 111  Training loss = 2.7750  Validation loss = 6.3316  \n",
      "\n",
      "Fold: 15  Epoch: 112  Training loss = 2.7744  Validation loss = 6.3285  \n",
      "\n",
      "Fold: 15  Epoch: 113  Training loss = 2.7736  Validation loss = 6.3236  \n",
      "\n",
      "Fold: 15  Epoch: 114  Training loss = 2.7734  Validation loss = 6.3229  \n",
      "\n",
      "Fold: 15  Epoch: 115  Training loss = 2.7731  Validation loss = 6.3218  \n",
      "\n",
      "Fold: 15  Epoch: 116  Training loss = 2.7728  Validation loss = 6.3206  \n",
      "\n",
      "Fold: 15  Epoch: 117  Training loss = 2.7724  Validation loss = 6.3182  \n",
      "\n",
      "Fold: 15  Epoch: 118  Training loss = 2.7724  Validation loss = 6.3192  \n",
      "\n",
      "Fold: 15  Epoch: 119  Training loss = 2.7718  Validation loss = 6.3157  \n",
      "\n",
      "Fold: 15  Epoch: 120  Training loss = 2.7714  Validation loss = 6.3136  \n",
      "\n",
      "Fold: 15  Epoch: 121  Training loss = 2.7713  Validation loss = 6.3141  \n",
      "\n",
      "Fold: 15  Epoch: 122  Training loss = 2.7709  Validation loss = 6.3117  \n",
      "\n",
      "Fold: 15  Epoch: 123  Training loss = 2.7706  Validation loss = 6.3101  \n",
      "\n",
      "Fold: 15  Epoch: 124  Training loss = 2.7702  Validation loss = 6.3081  \n",
      "\n",
      "Fold: 15  Epoch: 125  Training loss = 2.7699  Validation loss = 6.3063  \n",
      "\n",
      "Fold: 15  Epoch: 126  Training loss = 2.7692  Validation loss = 6.3021  \n",
      "\n",
      "Fold: 15  Epoch: 127  Training loss = 2.7689  Validation loss = 6.3007  \n",
      "\n",
      "Fold: 15  Epoch: 128  Training loss = 2.7683  Validation loss = 6.2976  \n",
      "\n",
      "Fold: 15  Epoch: 129  Training loss = 2.7680  Validation loss = 6.2957  \n",
      "\n",
      "Fold: 15  Epoch: 130  Training loss = 2.7678  Validation loss = 6.2952  \n",
      "\n",
      "Fold: 15  Epoch: 131  Training loss = 2.7673  Validation loss = 6.2923  \n",
      "\n",
      "Fold: 15  Epoch: 132  Training loss = 2.7673  Validation loss = 6.2936  \n",
      "\n",
      "Fold: 15  Epoch: 133  Training loss = 2.7670  Validation loss = 6.2914  \n",
      "\n",
      "Fold: 15  Epoch: 134  Training loss = 2.7661  Validation loss = 6.2856  \n",
      "\n",
      "Fold: 15  Epoch: 135  Training loss = 2.7663  Validation loss = 6.2870  \n",
      "\n",
      "Fold: 15  Epoch: 136  Training loss = 2.7661  Validation loss = 6.2863  \n",
      "\n",
      "Fold: 15  Epoch: 137  Training loss = 2.7650  Validation loss = 6.2794  \n",
      "\n",
      "Fold: 15  Epoch: 138  Training loss = 2.7647  Validation loss = 6.2780  \n",
      "\n",
      "Fold: 15  Epoch: 139  Training loss = 2.7646  Validation loss = 6.2780  \n",
      "\n",
      "Fold: 15  Epoch: 140  Training loss = 2.7647  Validation loss = 6.2787  \n",
      "\n",
      "Fold: 15  Epoch: 141  Training loss = 2.7639  Validation loss = 6.2734  \n",
      "\n",
      "Fold: 15  Epoch: 142  Training loss = 2.7639  Validation loss = 6.2742  \n",
      "\n",
      "Fold: 15  Epoch: 143  Training loss = 2.7638  Validation loss = 6.2738  \n",
      "\n",
      "Fold: 15  Epoch: 144  Training loss = 2.7633  Validation loss = 6.2706  \n",
      "\n",
      "Fold: 15  Epoch: 145  Training loss = 2.7627  Validation loss = 6.2664  \n",
      "\n",
      "Fold: 15  Epoch: 146  Training loss = 2.7625  Validation loss = 6.2658  \n",
      "\n",
      "Fold: 15  Epoch: 147  Training loss = 2.7621  Validation loss = 6.2635  \n",
      "\n",
      "Fold: 15  Epoch: 148  Training loss = 2.7621  Validation loss = 6.2640  \n",
      "\n",
      "Fold: 15  Epoch: 149  Training loss = 2.7616  Validation loss = 6.2614  \n",
      "\n",
      "Fold: 15  Epoch: 150  Training loss = 2.7613  Validation loss = 6.2596  \n",
      "\n",
      "Fold: 15  Epoch: 151  Training loss = 2.7608  Validation loss = 6.2568  \n",
      "\n",
      "Fold: 15  Epoch: 152  Training loss = 2.7606  Validation loss = 6.2563  \n",
      "\n",
      "Fold: 15  Epoch: 153  Training loss = 2.7606  Validation loss = 6.2574  \n",
      "\n",
      "Fold: 15  Epoch: 154  Training loss = 2.7601  Validation loss = 6.2545  \n",
      "\n",
      "Fold: 15  Epoch: 155  Training loss = 2.7601  Validation loss = 6.2547  \n",
      "\n",
      "Fold: 15  Epoch: 156  Training loss = 2.7594  Validation loss = 6.2504  \n",
      "\n",
      "Fold: 15  Epoch: 157  Training loss = 2.7591  Validation loss = 6.2481  \n",
      "\n",
      "Fold: 15  Epoch: 158  Training loss = 2.7590  Validation loss = 6.2488  \n",
      "\n",
      "Fold: 15  Epoch: 159  Training loss = 2.7592  Validation loss = 6.2503  \n",
      "\n",
      "Fold: 15  Epoch: 160  Training loss = 2.7588  Validation loss = 6.2487  \n",
      "\n",
      "Fold: 15  Epoch: 161  Training loss = 2.7585  Validation loss = 6.2471  \n",
      "\n",
      "Fold: 15  Epoch: 162  Training loss = 2.7580  Validation loss = 6.2434  \n",
      "\n",
      "Fold: 15  Epoch: 163  Training loss = 2.7575  Validation loss = 6.2400  \n",
      "\n",
      "Fold: 15  Epoch: 164  Training loss = 2.7571  Validation loss = 6.2380  \n",
      "\n",
      "Fold: 15  Epoch: 165  Training loss = 2.7570  Validation loss = 6.2375  \n",
      "\n",
      "Fold: 15  Epoch: 166  Training loss = 2.7565  Validation loss = 6.2346  \n",
      "\n",
      "Fold: 15  Epoch: 167  Training loss = 2.7560  Validation loss = 6.2309  \n",
      "\n",
      "Fold: 15  Epoch: 168  Training loss = 2.7556  Validation loss = 6.2281  \n",
      "\n",
      "Fold: 15  Epoch: 169  Training loss = 2.7552  Validation loss = 6.2256  \n",
      "\n",
      "Fold: 15  Epoch: 170  Training loss = 2.7548  Validation loss = 6.2230  \n",
      "\n",
      "Fold: 15  Epoch: 171  Training loss = 2.7546  Validation loss = 6.2223  \n",
      "\n",
      "Fold: 15  Epoch: 172  Training loss = 2.7544  Validation loss = 6.2211  \n",
      "\n",
      "Fold: 15  Epoch: 173  Training loss = 2.7539  Validation loss = 6.2179  \n",
      "\n",
      "Fold: 15  Epoch: 174  Training loss = 2.7537  Validation loss = 6.2171  \n",
      "\n",
      "Fold: 15  Epoch: 175  Training loss = 2.7537  Validation loss = 6.2177  \n",
      "\n",
      "Fold: 15  Epoch: 176  Training loss = 2.7535  Validation loss = 6.2171  \n",
      "\n",
      "Fold: 15  Epoch: 177  Training loss = 2.7532  Validation loss = 6.2154  \n",
      "\n",
      "Fold: 15  Epoch: 178  Training loss = 2.7526  Validation loss = 6.2116  \n",
      "\n",
      "Fold: 15  Epoch: 179  Training loss = 2.7523  Validation loss = 6.2098  \n",
      "\n",
      "Fold: 15  Epoch: 180  Training loss = 2.7519  Validation loss = 6.2068  \n",
      "\n",
      "Fold: 15  Epoch: 181  Training loss = 2.7517  Validation loss = 6.2063  \n",
      "\n",
      "Fold: 15  Epoch: 182  Training loss = 2.7511  Validation loss = 6.2019  \n",
      "\n",
      "Fold: 15  Epoch: 183  Training loss = 2.7510  Validation loss = 6.2015  \n",
      "\n",
      "Fold: 15  Epoch: 184  Training loss = 2.7501  Validation loss = 6.1945  \n",
      "\n",
      "Fold: 15  Epoch: 185  Training loss = 2.7497  Validation loss = 6.1917  \n",
      "\n",
      "Fold: 15  Epoch: 186  Training loss = 2.7493  Validation loss = 6.1890  \n",
      "\n",
      "Fold: 15  Epoch: 187  Training loss = 2.7487  Validation loss = 6.1844  \n",
      "\n",
      "Fold: 15  Epoch: 188  Training loss = 2.7482  Validation loss = 6.1810  \n",
      "\n",
      "Fold: 15  Epoch: 189  Training loss = 2.7479  Validation loss = 6.1794  \n",
      "\n",
      "Fold: 15  Epoch: 190  Training loss = 2.7474  Validation loss = 6.1751  \n",
      "\n",
      "Fold: 15  Epoch: 191  Training loss = 2.7469  Validation loss = 6.1712  \n",
      "\n",
      "Fold: 15  Epoch: 192  Training loss = 2.7466  Validation loss = 6.1698  \n",
      "\n",
      "Fold: 15  Epoch: 193  Training loss = 2.7462  Validation loss = 6.1680  \n",
      "\n",
      "Fold: 15  Epoch: 194  Training loss = 2.7458  Validation loss = 6.1651  \n",
      "\n",
      "Fold: 15  Epoch: 195  Training loss = 2.7455  Validation loss = 6.1617  \n",
      "\n",
      "Fold: 15  Epoch: 196  Training loss = 2.7449  Validation loss = 6.1570  \n",
      "\n",
      "Fold: 15  Epoch: 197  Training loss = 2.7447  Validation loss = 6.1562  \n",
      "\n",
      "Fold: 15  Epoch: 198  Training loss = 2.7445  Validation loss = 6.1555  \n",
      "\n",
      "Fold: 15  Epoch: 199  Training loss = 2.7442  Validation loss = 6.1533  \n",
      "\n",
      "Fold: 15  Epoch: 200  Training loss = 2.7437  Validation loss = 6.1493  \n",
      "\n",
      "Fold: 15  Epoch: 201  Training loss = 2.7436  Validation loss = 6.1499  \n",
      "\n",
      "Fold: 15  Epoch: 202  Training loss = 2.7431  Validation loss = 6.1452  \n",
      "\n",
      "Fold: 15  Epoch: 203  Training loss = 2.7427  Validation loss = 6.1418  \n",
      "\n",
      "Fold: 15  Epoch: 204  Training loss = 2.7422  Validation loss = 6.1367  \n",
      "\n",
      "Fold: 15  Epoch: 205  Training loss = 2.7423  Validation loss = 6.1391  \n",
      "\n",
      "Fold: 15  Epoch: 206  Training loss = 2.7417  Validation loss = 6.1340  \n",
      "\n",
      "Fold: 15  Epoch: 207  Training loss = 2.7413  Validation loss = 6.1296  \n",
      "\n",
      "Fold: 15  Epoch: 208  Training loss = 2.7414  Validation loss = 6.1334  \n",
      "\n",
      "Fold: 15  Epoch: 209  Training loss = 2.7412  Validation loss = 6.1317  \n",
      "\n",
      "Fold: 15  Epoch: 210  Training loss = 2.7410  Validation loss = 6.1311  \n",
      "\n",
      "Fold: 15  Epoch: 211  Training loss = 2.7406  Validation loss = 6.1281  \n",
      "\n",
      "Fold: 15  Epoch: 212  Training loss = 2.7402  Validation loss = 6.1247  \n",
      "\n",
      "Fold: 15  Epoch: 213  Training loss = 2.7398  Validation loss = 6.1204  \n",
      "\n",
      "Fold: 15  Epoch: 214  Training loss = 2.7395  Validation loss = 6.1175  \n",
      "\n",
      "Fold: 15  Epoch: 215  Training loss = 2.7395  Validation loss = 6.1182  \n",
      "\n",
      "Fold: 15  Epoch: 216  Training loss = 2.7394  Validation loss = 6.1183  \n",
      "\n",
      "Fold: 15  Epoch: 217  Training loss = 2.7391  Validation loss = 6.1165  \n",
      "\n",
      "Fold: 15  Epoch: 218  Training loss = 2.7389  Validation loss = 6.1162  \n",
      "\n",
      "Fold: 15  Epoch: 219  Training loss = 2.7385  Validation loss = 6.1119  \n",
      "\n",
      "Fold: 15  Epoch: 220  Training loss = 2.7380  Validation loss = 6.1071  \n",
      "\n",
      "Fold: 15  Epoch: 221  Training loss = 2.7379  Validation loss = 6.1079  \n",
      "\n",
      "Fold: 15  Epoch: 222  Training loss = 2.7377  Validation loss = 6.1097  \n",
      "\n",
      "Fold: 15  Epoch: 223  Training loss = 2.7374  Validation loss = 6.1073  \n",
      "\n",
      "Fold: 15  Epoch: 224  Training loss = 2.7352  Validation loss = 6.1068  \n",
      "\n",
      "Fold: 15  Epoch: 225  Training loss = 2.7318  Validation loss = 6.1053  \n",
      "\n",
      "Fold: 15  Epoch: 226  Training loss = 2.7317  Validation loss = 6.1060  \n",
      "\n",
      "Fold: 15  Epoch: 227  Training loss = 2.7313  Validation loss = 6.1025  \n",
      "\n",
      "Fold: 15  Epoch: 228  Training loss = 2.7311  Validation loss = 6.1016  \n",
      "\n",
      "Fold: 15  Epoch: 229  Training loss = 2.7310  Validation loss = 6.1030  \n",
      "\n",
      "Fold: 15  Epoch: 230  Training loss = 2.7308  Validation loss = 6.1012  \n",
      "\n",
      "Fold: 15  Epoch: 231  Training loss = 2.7303  Validation loss = 6.0962  \n",
      "\n",
      "Fold: 15  Epoch: 232  Training loss = 2.7301  Validation loss = 6.0943  \n",
      "\n",
      "Fold: 15  Epoch: 233  Training loss = 2.7298  Validation loss = 6.0928  \n",
      "\n",
      "Fold: 15  Epoch: 234  Training loss = 2.7295  Validation loss = 6.0892  \n",
      "\n",
      "Fold: 15  Epoch: 235  Training loss = 2.7293  Validation loss = 6.0878  \n",
      "\n",
      "Fold: 15  Epoch: 236  Training loss = 2.7290  Validation loss = 6.0862  \n",
      "\n",
      "Fold: 15  Epoch: 237  Training loss = 2.7285  Validation loss = 6.0833  \n",
      "\n",
      "Fold: 15  Epoch: 238  Training loss = 2.7282  Validation loss = 6.0825  \n",
      "\n",
      "Fold: 15  Epoch: 239  Training loss = 2.7279  Validation loss = 6.0794  \n",
      "\n",
      "Fold: 15  Epoch: 240  Training loss = 2.7276  Validation loss = 6.0741  \n",
      "\n",
      "Fold: 15  Epoch: 241  Training loss = 2.7274  Validation loss = 6.0741  \n",
      "\n",
      "Fold: 15  Epoch: 242  Training loss = 2.7272  Validation loss = 6.0714  \n",
      "\n",
      "Fold: 15  Epoch: 243  Training loss = 2.7270  Validation loss = 6.0706  \n",
      "\n",
      "Fold: 15  Epoch: 244  Training loss = 2.7268  Validation loss = 6.0704  \n",
      "\n",
      "Fold: 15  Epoch: 245  Training loss = 2.7266  Validation loss = 6.0701  \n",
      "\n",
      "Fold: 15  Epoch: 246  Training loss = 2.7265  Validation loss = 6.0700  \n",
      "\n",
      "Fold: 15  Epoch: 247  Training loss = 2.7262  Validation loss = 6.0656  \n",
      "\n",
      "Fold: 15  Epoch: 248  Training loss = 2.7257  Validation loss = 6.0604  \n",
      "\n",
      "Fold: 15  Epoch: 249  Training loss = 2.7256  Validation loss = 6.0621  \n",
      "\n",
      "Fold: 15  Epoch: 250  Training loss = 2.7254  Validation loss = 6.0582  \n",
      "\n",
      "Fold: 15  Epoch: 251  Training loss = 2.7253  Validation loss = 6.0583  \n",
      "\n",
      "Fold: 15  Epoch: 252  Training loss = 2.7251  Validation loss = 6.0596  \n",
      "\n",
      "Fold: 15  Epoch: 253  Training loss = 2.7248  Validation loss = 6.0580  \n",
      "\n",
      "Fold: 15  Epoch: 254  Training loss = 2.7246  Validation loss = 6.0556  \n",
      "\n",
      "Fold: 15  Epoch: 255  Training loss = 2.7245  Validation loss = 6.0555  \n",
      "\n",
      "Fold: 15  Epoch: 256  Training loss = 2.7242  Validation loss = 6.0542  \n",
      "\n",
      "Fold: 15  Epoch: 257  Training loss = 2.7239  Validation loss = 6.0531  \n",
      "\n",
      "Fold: 15  Epoch: 258  Training loss = 2.7237  Validation loss = 6.0512  \n",
      "\n",
      "Fold: 15  Epoch: 259  Training loss = 2.7235  Validation loss = 6.0510  \n",
      "\n",
      "Fold: 15  Epoch: 260  Training loss = 2.7233  Validation loss = 6.0490  \n",
      "\n",
      "Fold: 15  Epoch: 261  Training loss = 2.7230  Validation loss = 6.0478  \n",
      "\n",
      "Fold: 15  Epoch: 262  Training loss = 2.7228  Validation loss = 6.0459  \n",
      "\n",
      "Fold: 15  Epoch: 263  Training loss = 2.7226  Validation loss = 6.0472  \n",
      "\n",
      "Fold: 15  Epoch: 264  Training loss = 2.7225  Validation loss = 6.0466  \n",
      "\n",
      "Fold: 15  Epoch: 265  Training loss = 2.7223  Validation loss = 6.0452  \n",
      "\n",
      "Fold: 15  Epoch: 266  Training loss = 2.7221  Validation loss = 6.0450  \n",
      "\n",
      "Fold: 15  Epoch: 267  Training loss = 2.7219  Validation loss = 6.0446  \n",
      "\n",
      "Fold: 15  Epoch: 268  Training loss = 2.7217  Validation loss = 6.0434  \n",
      "\n",
      "Fold: 15  Epoch: 269  Training loss = 2.7217  Validation loss = 6.0455  \n",
      "\n",
      "Fold: 15  Epoch: 270  Training loss = 2.7214  Validation loss = 6.0448  \n",
      "\n",
      "Fold: 15  Epoch: 271  Training loss = 2.7212  Validation loss = 6.0435  \n",
      "\n",
      "Fold: 15  Epoch: 272  Training loss = 2.7210  Validation loss = 6.0432  \n",
      "\n",
      "Fold: 15  Epoch: 273  Training loss = 2.7208  Validation loss = 6.0410  \n",
      "\n",
      "Fold: 15  Epoch: 274  Training loss = 2.7206  Validation loss = 6.0397  \n",
      "\n",
      "Fold: 15  Epoch: 275  Training loss = 2.7204  Validation loss = 6.0400  \n",
      "\n",
      "Fold: 15  Epoch: 276  Training loss = 2.7202  Validation loss = 6.0394  \n",
      "\n",
      "Fold: 15  Epoch: 277  Training loss = 2.7201  Validation loss = 6.0397  \n",
      "\n",
      "Fold: 15  Epoch: 278  Training loss = 2.7199  Validation loss = 6.0388  \n",
      "\n",
      "Fold: 15  Epoch: 279  Training loss = 2.7198  Validation loss = 6.0417  \n",
      "\n",
      "Fold: 15  Epoch: 280  Training loss = 2.7196  Validation loss = 6.0413  \n",
      "\n",
      "Fold: 15  Epoch: 281  Training loss = 2.7194  Validation loss = 6.0410  \n",
      "\n",
      "Fold: 15  Epoch: 282  Training loss = 2.7193  Validation loss = 6.0409  \n",
      "\n",
      "Fold: 15  Epoch: 283  Training loss = 2.7192  Validation loss = 6.0407  \n",
      "\n",
      "Fold: 15  Epoch: 284  Training loss = 2.7190  Validation loss = 6.0410  \n",
      "\n",
      "Fold: 15  Epoch: 285  Training loss = 2.7187  Validation loss = 6.0363  \n",
      "\n",
      "Fold: 15  Epoch: 286  Training loss = 2.7186  Validation loss = 6.0367  \n",
      "\n",
      "Fold: 15  Epoch: 287  Training loss = 2.7182  Validation loss = 6.0328  \n",
      "\n",
      "Fold: 15  Epoch: 288  Training loss = 2.7181  Validation loss = 6.0330  \n",
      "\n",
      "Fold: 15  Epoch: 289  Training loss = 2.7181  Validation loss = 6.0342  \n",
      "\n",
      "Fold: 15  Epoch: 290  Training loss = 2.7177  Validation loss = 6.0298  \n",
      "\n",
      "Fold: 15  Epoch: 291  Training loss = 2.7177  Validation loss = 6.0310  \n",
      "\n",
      "Fold: 15  Epoch: 292  Training loss = 2.7174  Validation loss = 6.0263  \n",
      "\n",
      "Fold: 15  Epoch: 293  Training loss = 2.7172  Validation loss = 6.0250  \n",
      "\n",
      "Fold: 15  Epoch: 294  Training loss = 2.7170  Validation loss = 6.0214  \n",
      "\n",
      "Fold: 15  Epoch: 295  Training loss = 2.7167  Validation loss = 6.0182  \n",
      "\n",
      "Fold: 15  Epoch: 296  Training loss = 2.7166  Validation loss = 6.0192  \n",
      "\n",
      "Fold: 15  Epoch: 297  Training loss = 2.7169  Validation loss = 6.0195  \n",
      "\n",
      "Fold: 15  Epoch: 298  Training loss = 2.7163  Validation loss = 6.0208  \n",
      "\n",
      "Fold: 15  Epoch: 299  Training loss = 2.7162  Validation loss = 6.0209  \n",
      "\n",
      "Fold: 15  Epoch: 300  Training loss = 2.7160  Validation loss = 6.0174  \n",
      "\n",
      "Fold: 15  Epoch: 301  Training loss = 2.7158  Validation loss = 6.0186  \n",
      "\n",
      "Fold: 15  Epoch: 302  Training loss = 2.7156  Validation loss = 6.0168  \n",
      "\n",
      "Fold: 15  Epoch: 303  Training loss = 2.7155  Validation loss = 6.0198  \n",
      "\n",
      "Fold: 15  Epoch: 304  Training loss = 2.7154  Validation loss = 6.0205  \n",
      "\n",
      "Fold: 15  Epoch: 305  Training loss = 2.7152  Validation loss = 6.0198  \n",
      "\n",
      "Fold: 15  Epoch: 306  Training loss = 2.7150  Validation loss = 6.0184  \n",
      "\n",
      "Fold: 15  Epoch: 307  Training loss = 2.7148  Validation loss = 6.0167  \n",
      "\n",
      "Fold: 15  Epoch: 308  Training loss = 2.7147  Validation loss = 6.0181  \n",
      "\n",
      "Fold: 15  Epoch: 309  Training loss = 2.7144  Validation loss = 6.0132  \n",
      "\n",
      "Fold: 15  Epoch: 310  Training loss = 2.7143  Validation loss = 6.0136  \n",
      "\n",
      "Fold: 15  Epoch: 311  Training loss = 2.7142  Validation loss = 6.0142  \n",
      "\n",
      "Fold: 15  Epoch: 312  Training loss = 2.7140  Validation loss = 6.0119  \n",
      "\n",
      "Fold: 15  Epoch: 313  Training loss = 2.7138  Validation loss = 6.0107  \n",
      "\n",
      "Fold: 15  Epoch: 314  Training loss = 2.7137  Validation loss = 6.0105  \n",
      "\n",
      "Fold: 15  Epoch: 315  Training loss = 2.7134  Validation loss = 6.0071  \n",
      "\n",
      "Fold: 15  Epoch: 316  Training loss = 2.7130  Validation loss = 6.0029  \n",
      "\n",
      "Fold: 15  Epoch: 317  Training loss = 2.7129  Validation loss = 6.0044  \n",
      "\n",
      "Fold: 15  Epoch: 318  Training loss = 2.7128  Validation loss = 6.0055  \n",
      "\n",
      "Fold: 15  Epoch: 319  Training loss = 2.7127  Validation loss = 6.0059  \n",
      "\n",
      "Fold: 15  Epoch: 320  Training loss = 2.7126  Validation loss = 6.0082  \n",
      "\n",
      "Fold: 15  Epoch: 321  Training loss = 2.7125  Validation loss = 6.0080  \n",
      "\n",
      "Fold: 15  Epoch: 322  Training loss = 2.7122  Validation loss = 6.0072  \n",
      "\n",
      "Fold: 15  Epoch: 323  Training loss = 2.7119  Validation loss = 6.0022  \n",
      "\n",
      "Fold: 15  Epoch: 324  Training loss = 2.7116  Validation loss = 6.0010  \n",
      "\n",
      "Fold: 15  Epoch: 325  Training loss = 2.7115  Validation loss = 6.0005  \n",
      "\n",
      "Fold: 15  Epoch: 326  Training loss = 2.7113  Validation loss = 5.9987  \n",
      "\n",
      "Fold: 15  Epoch: 327  Training loss = 2.7109  Validation loss = 5.9943  \n",
      "\n",
      "Fold: 15  Epoch: 328  Training loss = 2.7109  Validation loss = 5.9980  \n",
      "\n",
      "Fold: 15  Epoch: 329  Training loss = 2.7110  Validation loss = 6.0032  \n",
      "\n",
      "Fold: 15  Epoch: 330  Training loss = 2.7108  Validation loss = 6.0028  \n",
      "\n",
      "Fold: 15  Epoch: 331  Training loss = 2.7107  Validation loss = 6.0022  \n",
      "\n",
      "Fold: 15  Epoch: 332  Training loss = 2.7105  Validation loss = 5.9997  \n",
      "\n",
      "Fold: 15  Epoch: 333  Training loss = 2.7105  Validation loss = 6.0023  \n",
      "\n",
      "Fold: 15  Epoch: 334  Training loss = 2.7104  Validation loss = 6.0025  \n",
      "\n",
      "Fold: 15  Epoch: 335  Training loss = 2.7103  Validation loss = 6.0031  \n",
      "\n",
      "Fold: 15  Epoch: 336  Training loss = 2.7101  Validation loss = 6.0017  \n",
      "\n",
      "Fold: 15  Epoch: 337  Training loss = 2.7099  Validation loss = 6.0016  \n",
      "\n",
      "Fold: 15  Epoch: 338  Training loss = 2.7098  Validation loss = 6.0002  \n",
      "\n",
      "Fold: 15  Epoch: 339  Training loss = 2.7097  Validation loss = 6.0023  \n",
      "\n",
      "Fold: 15  Epoch: 340  Training loss = 2.7093  Validation loss = 5.9970  \n",
      "\n",
      "Fold: 15  Epoch: 341  Training loss = 2.7091  Validation loss = 5.9937  \n",
      "\n",
      "Fold: 15  Epoch: 342  Training loss = 2.7088  Validation loss = 5.9926  \n",
      "\n",
      "Fold: 15  Epoch: 343  Training loss = 2.7090  Validation loss = 5.9986  \n",
      "\n",
      "Fold: 15  Epoch: 344  Training loss = 2.7088  Validation loss = 5.9975  \n",
      "\n",
      "Fold: 15  Epoch: 345  Training loss = 2.7089  Validation loss = 6.0019  \n",
      "\n",
      "Fold: 15  Epoch: 346  Training loss = 2.7088  Validation loss = 6.0022  \n",
      "\n",
      "Fold: 15  Epoch: 347  Training loss = 2.7087  Validation loss = 6.0037  \n",
      "\n",
      "Check model:  Fold: 15  Epoch: 342  Training loss = 2.7087  Validation loss = 6.0037  \n",
      "\n",
      "Fold: 16  Epoch: 1  Training loss = 3.0525  Validation loss = 4.4884  \n",
      "\n",
      "Fold: 16  Epoch: 2  Training loss = 3.0514  Validation loss = 4.4832  \n",
      "\n",
      "Fold: 16  Epoch: 3  Training loss = 3.0511  Validation loss = 4.4799  \n",
      "\n",
      "Fold: 16  Epoch: 4  Training loss = 3.0510  Validation loss = 4.4827  \n",
      "\n",
      "Fold: 16  Epoch: 5  Training loss = 3.0497  Validation loss = 4.4726  \n",
      "\n",
      "Fold: 16  Epoch: 6  Training loss = 3.0493  Validation loss = 4.4779  \n",
      "\n",
      "Fold: 16  Epoch: 7  Training loss = 3.0488  Validation loss = 4.4723  \n",
      "\n",
      "Fold: 16  Epoch: 8  Training loss = 3.0487  Validation loss = 4.4720  \n",
      "\n",
      "Fold: 16  Epoch: 9  Training loss = 3.0480  Validation loss = 4.4663  \n",
      "\n",
      "Fold: 16  Epoch: 10  Training loss = 3.0479  Validation loss = 4.4665  \n",
      "\n",
      "Fold: 16  Epoch: 11  Training loss = 3.0477  Validation loss = 4.4647  \n",
      "\n",
      "Fold: 16  Epoch: 12  Training loss = 3.0470  Validation loss = 4.4619  \n",
      "\n",
      "Fold: 16  Epoch: 13  Training loss = 3.0463  Validation loss = 4.4598  \n",
      "\n",
      "Fold: 16  Epoch: 14  Training loss = 3.0455  Validation loss = 4.4522  \n",
      "\n",
      "Fold: 16  Epoch: 15  Training loss = 3.0446  Validation loss = 4.4431  \n",
      "\n",
      "Fold: 16  Epoch: 16  Training loss = 3.0445  Validation loss = 4.4456  \n",
      "\n",
      "Fold: 16  Epoch: 17  Training loss = 3.0450  Validation loss = 4.4472  \n",
      "\n",
      "Fold: 16  Epoch: 18  Training loss = 3.0443  Validation loss = 4.4408  \n",
      "\n",
      "Fold: 16  Epoch: 19  Training loss = 3.0432  Validation loss = 4.4347  \n",
      "\n",
      "Fold: 16  Epoch: 20  Training loss = 3.0433  Validation loss = 4.4376  \n",
      "\n",
      "Fold: 16  Epoch: 21  Training loss = 3.0429  Validation loss = 4.4345  \n",
      "\n",
      "Fold: 16  Epoch: 22  Training loss = 3.0421  Validation loss = 4.4295  \n",
      "\n",
      "Fold: 16  Epoch: 23  Training loss = 3.0410  Validation loss = 4.4224  \n",
      "\n",
      "Fold: 16  Epoch: 24  Training loss = 3.0398  Validation loss = 4.4162  \n",
      "\n",
      "Fold: 16  Epoch: 25  Training loss = 3.0394  Validation loss = 4.4119  \n",
      "\n",
      "Fold: 16  Epoch: 26  Training loss = 3.0393  Validation loss = 4.4131  \n",
      "\n",
      "Fold: 16  Epoch: 27  Training loss = 3.0378  Validation loss = 4.4046  \n",
      "\n",
      "Fold: 16  Epoch: 28  Training loss = 3.0369  Validation loss = 4.4013  \n",
      "\n",
      "Fold: 16  Epoch: 29  Training loss = 3.0370  Validation loss = 4.4059  \n",
      "\n",
      "Fold: 16  Epoch: 30  Training loss = 3.0370  Validation loss = 4.4056  \n",
      "\n",
      "Fold: 16  Epoch: 31  Training loss = 3.0364  Validation loss = 4.4012  \n",
      "\n",
      "Fold: 16  Epoch: 32  Training loss = 3.0354  Validation loss = 4.3991  \n",
      "\n",
      "Fold: 16  Epoch: 33  Training loss = 3.0345  Validation loss = 4.3960  \n",
      "\n",
      "Fold: 16  Epoch: 34  Training loss = 3.0337  Validation loss = 4.3822  \n",
      "\n",
      "Fold: 16  Epoch: 35  Training loss = 3.0334  Validation loss = 4.3811  \n",
      "\n",
      "Fold: 16  Epoch: 36  Training loss = 3.0326  Validation loss = 4.3811  \n",
      "\n",
      "Fold: 16  Epoch: 37  Training loss = 3.0320  Validation loss = 4.3789  \n",
      "\n",
      "Fold: 16  Epoch: 38  Training loss = 3.0310  Validation loss = 4.3742  \n",
      "\n",
      "Fold: 16  Epoch: 39  Training loss = 3.0313  Validation loss = 4.3761  \n",
      "\n",
      "Fold: 16  Epoch: 40  Training loss = 3.0309  Validation loss = 4.3705  \n",
      "\n",
      "Fold: 16  Epoch: 41  Training loss = 3.0303  Validation loss = 4.3684  \n",
      "\n",
      "Fold: 16  Epoch: 42  Training loss = 3.0301  Validation loss = 4.3698  \n",
      "\n",
      "Fold: 16  Epoch: 43  Training loss = 3.0300  Validation loss = 4.3766  \n",
      "\n",
      "Fold: 16  Epoch: 44  Training loss = 3.0293  Validation loss = 4.3716  \n",
      "\n",
      "Fold: 16  Epoch: 45  Training loss = 3.0292  Validation loss = 4.3726  \n",
      "\n",
      "Fold: 16  Epoch: 46  Training loss = 3.0289  Validation loss = 4.3700  \n",
      "\n",
      "Fold: 16  Epoch: 47  Training loss = 3.0288  Validation loss = 4.3669  \n",
      "\n",
      "Fold: 16  Epoch: 48  Training loss = 3.0281  Validation loss = 4.3618  \n",
      "\n",
      "Fold: 16  Epoch: 49  Training loss = 3.0272  Validation loss = 4.3542  \n",
      "\n",
      "Fold: 16  Epoch: 50  Training loss = 3.0271  Validation loss = 4.3574  \n",
      "\n",
      "Fold: 16  Epoch: 51  Training loss = 3.0270  Validation loss = 4.3566  \n",
      "\n",
      "Fold: 16  Epoch: 52  Training loss = 3.0258  Validation loss = 4.3517  \n",
      "\n",
      "Fold: 16  Epoch: 53  Training loss = 3.0248  Validation loss = 4.3376  \n",
      "\n",
      "Fold: 16  Epoch: 54  Training loss = 3.0245  Validation loss = 4.3359  \n",
      "\n",
      "Fold: 16  Epoch: 55  Training loss = 3.0240  Validation loss = 4.3331  \n",
      "\n",
      "Fold: 16  Epoch: 56  Training loss = 3.0241  Validation loss = 4.3433  \n",
      "\n",
      "Fold: 16  Epoch: 57  Training loss = 3.0236  Validation loss = 4.3425  \n",
      "\n",
      "Fold: 16  Epoch: 58  Training loss = 3.0225  Validation loss = 4.3301  \n",
      "\n",
      "Fold: 16  Epoch: 59  Training loss = 3.0216  Validation loss = 4.3229  \n",
      "\n",
      "Fold: 16  Epoch: 60  Training loss = 3.0209  Validation loss = 4.3221  \n",
      "\n",
      "Fold: 16  Epoch: 61  Training loss = 3.0204  Validation loss = 4.3226  \n",
      "\n",
      "Fold: 16  Epoch: 62  Training loss = 3.0199  Validation loss = 4.3194  \n",
      "\n",
      "Fold: 16  Epoch: 63  Training loss = 3.0196  Validation loss = 4.3195  \n",
      "\n",
      "Fold: 16  Epoch: 64  Training loss = 3.0190  Validation loss = 4.3107  \n",
      "\n",
      "Fold: 16  Epoch: 65  Training loss = 3.0185  Validation loss = 4.3064  \n",
      "\n",
      "Fold: 16  Epoch: 66  Training loss = 3.0176  Validation loss = 4.2983  \n",
      "\n",
      "Fold: 16  Epoch: 67  Training loss = 3.0170  Validation loss = 4.2945  \n",
      "\n",
      "Fold: 16  Epoch: 68  Training loss = 3.0169  Validation loss = 4.2883  \n",
      "\n",
      "Fold: 16  Epoch: 69  Training loss = 3.0165  Validation loss = 4.2892  \n",
      "\n",
      "Fold: 16  Epoch: 70  Training loss = 3.0162  Validation loss = 4.2911  \n",
      "\n",
      "Fold: 16  Epoch: 71  Training loss = 3.0160  Validation loss = 4.2880  \n",
      "\n",
      "Fold: 16  Epoch: 72  Training loss = 3.0159  Validation loss = 4.2930  \n",
      "\n",
      "Fold: 16  Epoch: 73  Training loss = 3.0153  Validation loss = 4.2868  \n",
      "\n",
      "Fold: 16  Epoch: 74  Training loss = 3.0149  Validation loss = 4.2852  \n",
      "\n",
      "Fold: 16  Epoch: 75  Training loss = 3.0149  Validation loss = 4.2914  \n",
      "\n",
      "Fold: 16  Epoch: 76  Training loss = 3.0143  Validation loss = 4.2888  \n",
      "\n",
      "Fold: 16  Epoch: 77  Training loss = 3.0138  Validation loss = 4.2918  \n",
      "\n",
      "Fold: 16  Epoch: 78  Training loss = 3.0134  Validation loss = 4.2924  \n",
      "\n",
      "Fold: 16  Epoch: 79  Training loss = 3.0129  Validation loss = 4.2817  \n",
      "\n",
      "Fold: 16  Epoch: 80  Training loss = 3.0127  Validation loss = 4.2836  \n",
      "\n",
      "Fold: 16  Epoch: 81  Training loss = 3.0121  Validation loss = 4.2829  \n",
      "\n",
      "Fold: 16  Epoch: 82  Training loss = 3.0119  Validation loss = 4.2822  \n",
      "\n",
      "Fold: 16  Epoch: 83  Training loss = 3.0118  Validation loss = 4.2804  \n",
      "\n",
      "Fold: 16  Epoch: 84  Training loss = 3.0115  Validation loss = 4.2766  \n",
      "\n",
      "Fold: 16  Epoch: 85  Training loss = 3.0111  Validation loss = 4.2741  \n",
      "\n",
      "Fold: 16  Epoch: 86  Training loss = 3.0103  Validation loss = 4.2714  \n",
      "\n",
      "Fold: 16  Epoch: 87  Training loss = 3.0098  Validation loss = 4.2658  \n",
      "\n",
      "Fold: 16  Epoch: 88  Training loss = 3.0096  Validation loss = 4.2680  \n",
      "\n",
      "Fold: 16  Epoch: 89  Training loss = 3.0094  Validation loss = 4.2690  \n",
      "\n",
      "Fold: 16  Epoch: 90  Training loss = 3.0088  Validation loss = 4.2662  \n",
      "\n",
      "Fold: 16  Epoch: 91  Training loss = 3.0087  Validation loss = 4.2651  \n",
      "\n",
      "Fold: 16  Epoch: 92  Training loss = 3.0085  Validation loss = 4.2679  \n",
      "\n",
      "Fold: 16  Epoch: 93  Training loss = 3.0080  Validation loss = 4.2670  \n",
      "\n",
      "Fold: 16  Epoch: 94  Training loss = 3.0074  Validation loss = 4.2617  \n",
      "\n",
      "Fold: 16  Epoch: 95  Training loss = 3.0072  Validation loss = 4.2625  \n",
      "\n",
      "Fold: 16  Epoch: 96  Training loss = 3.0073  Validation loss = 4.2642  \n",
      "\n",
      "Fold: 16  Epoch: 97  Training loss = 3.0069  Validation loss = 4.2624  \n",
      "\n",
      "Fold: 16  Epoch: 98  Training loss = 3.0065  Validation loss = 4.2598  \n",
      "\n",
      "Fold: 16  Epoch: 99  Training loss = 3.0064  Validation loss = 4.2572  \n",
      "\n",
      "Fold: 16  Epoch: 100  Training loss = 3.0062  Validation loss = 4.2621  \n",
      "\n",
      "Fold: 16  Epoch: 101  Training loss = 3.0058  Validation loss = 4.2560  \n",
      "\n",
      "Fold: 16  Epoch: 102  Training loss = 3.0056  Validation loss = 4.2593  \n",
      "\n",
      "Fold: 16  Epoch: 103  Training loss = 3.0050  Validation loss = 4.2566  \n",
      "\n",
      "Fold: 16  Epoch: 104  Training loss = 3.0046  Validation loss = 4.2616  \n",
      "\n",
      "Fold: 16  Epoch: 105  Training loss = 3.0038  Validation loss = 4.2520  \n",
      "\n",
      "Fold: 16  Epoch: 106  Training loss = 3.0038  Validation loss = 4.2518  \n",
      "\n",
      "Fold: 16  Epoch: 107  Training loss = 3.0034  Validation loss = 4.2487  \n",
      "\n",
      "Fold: 16  Epoch: 108  Training loss = 3.0033  Validation loss = 4.2462  \n",
      "\n",
      "Fold: 16  Epoch: 109  Training loss = 3.0031  Validation loss = 4.2458  \n",
      "\n",
      "Fold: 16  Epoch: 110  Training loss = 3.0026  Validation loss = 4.2391  \n",
      "\n",
      "Fold: 16  Epoch: 111  Training loss = 3.0022  Validation loss = 4.2379  \n",
      "\n",
      "Fold: 16  Epoch: 112  Training loss = 3.0021  Validation loss = 4.2318  \n",
      "\n",
      "Fold: 16  Epoch: 113  Training loss = 3.0020  Validation loss = 4.2343  \n",
      "\n",
      "Fold: 16  Epoch: 114  Training loss = 3.0014  Validation loss = 4.2344  \n",
      "\n",
      "Fold: 16  Epoch: 115  Training loss = 3.0014  Validation loss = 4.2394  \n",
      "\n",
      "Fold: 16  Epoch: 116  Training loss = 3.0008  Validation loss = 4.2364  \n",
      "\n",
      "Fold: 16  Epoch: 117  Training loss = 3.0005  Validation loss = 4.2288  \n",
      "\n",
      "Fold: 16  Epoch: 118  Training loss = 3.0004  Validation loss = 4.2290  \n",
      "\n",
      "Fold: 16  Epoch: 119  Training loss = 3.0002  Validation loss = 4.2296  \n",
      "\n",
      "Fold: 16  Epoch: 120  Training loss = 2.9996  Validation loss = 4.2256  \n",
      "\n",
      "Fold: 16  Epoch: 121  Training loss = 2.9989  Validation loss = 4.2244  \n",
      "\n",
      "Fold: 16  Epoch: 122  Training loss = 2.9991  Validation loss = 4.2274  \n",
      "\n",
      "Fold: 16  Epoch: 123  Training loss = 2.9990  Validation loss = 4.2389  \n",
      "\n",
      "Fold: 16  Epoch: 124  Training loss = 2.9982  Validation loss = 4.2328  \n",
      "\n",
      "Fold: 16  Epoch: 125  Training loss = 2.9978  Validation loss = 4.2263  \n",
      "\n",
      "Fold: 16  Epoch: 126  Training loss = 2.9972  Validation loss = 4.2196  \n",
      "\n",
      "Fold: 16  Epoch: 127  Training loss = 2.9970  Validation loss = 4.2212  \n",
      "\n",
      "Fold: 16  Epoch: 128  Training loss = 2.9965  Validation loss = 4.2174  \n",
      "\n",
      "Fold: 16  Epoch: 129  Training loss = 2.9963  Validation loss = 4.2159  \n",
      "\n",
      "Fold: 16  Epoch: 130  Training loss = 2.9961  Validation loss = 4.2192  \n",
      "\n",
      "Fold: 16  Epoch: 131  Training loss = 2.9960  Validation loss = 4.2214  \n",
      "\n",
      "Fold: 16  Epoch: 132  Training loss = 2.9955  Validation loss = 4.2171  \n",
      "\n",
      "Fold: 16  Epoch: 133  Training loss = 2.9954  Validation loss = 4.2226  \n",
      "\n",
      "Fold: 16  Epoch: 134  Training loss = 2.9953  Validation loss = 4.2218  \n",
      "\n",
      "Fold: 16  Epoch: 135  Training loss = 2.9952  Validation loss = 4.2278  \n",
      "\n",
      "Check model:  Fold: 16  Epoch: 129  Training loss = 2.9952  Validation loss = 4.2278  \n",
      "\n",
      "Fold: 17  Epoch: 1  Training loss = 3.1493  Validation loss = 3.9386  \n",
      "\n",
      "Fold: 17  Epoch: 2  Training loss = 3.1466  Validation loss = 3.9438  \n",
      "\n",
      "Fold: 17  Epoch: 3  Training loss = 3.1462  Validation loss = 3.9446  \n",
      "\n",
      "Fold: 17  Epoch: 4  Training loss = 3.1448  Validation loss = 3.9479  \n",
      "\n",
      "Fold: 17  Epoch: 5  Training loss = 3.1436  Validation loss = 3.9492  \n",
      "\n",
      "Fold: 17  Epoch: 6  Training loss = 3.1432  Validation loss = 3.9496  \n",
      "\n",
      "Fold: 17  Epoch: 7  Training loss = 3.1407  Validation loss = 3.9546  \n",
      "\n",
      "Fold: 17  Epoch: 8  Training loss = 3.1382  Validation loss = 3.9586  \n",
      "\n",
      "Fold: 17  Epoch: 9  Training loss = 3.1376  Validation loss = 3.9598  \n",
      "\n",
      "Fold: 17  Epoch: 10  Training loss = 3.1366  Validation loss = 3.9626  \n",
      "\n",
      "Fold: 17  Epoch: 11  Training loss = 3.1361  Validation loss = 3.9639  \n",
      "\n",
      "Check model:  Fold: 17  Epoch: 1  Training loss = 3.1361  Validation loss = 3.9639  \n",
      "\n",
      "Fold: 18  Epoch: 1  Training loss = 3.2797  Validation loss = 2.2468  \n",
      "\n",
      "Fold: 18  Epoch: 2  Training loss = 3.2789  Validation loss = 2.2458  \n",
      "\n",
      "Fold: 18  Epoch: 3  Training loss = 3.2777  Validation loss = 2.2453  \n",
      "\n",
      "Fold: 18  Epoch: 4  Training loss = 3.2764  Validation loss = 2.2449  \n",
      "\n",
      "Fold: 18  Epoch: 5  Training loss = 3.2747  Validation loss = 2.2469  \n",
      "\n",
      "Fold: 18  Epoch: 6  Training loss = 3.2741  Validation loss = 2.2489  \n",
      "\n",
      "Fold: 18  Epoch: 7  Training loss = 3.2738  Validation loss = 2.2480  \n",
      "\n",
      "Fold: 18  Epoch: 8  Training loss = 3.2725  Validation loss = 2.2479  \n",
      "\n",
      "Fold: 18  Epoch: 9  Training loss = 3.2706  Validation loss = 2.2508  \n",
      "\n",
      "Fold: 18  Epoch: 10  Training loss = 3.2697  Validation loss = 2.2509  \n",
      "\n",
      "Fold: 18  Epoch: 11  Training loss = 3.2696  Validation loss = 2.2506  \n",
      "\n",
      "Fold: 18  Epoch: 12  Training loss = 3.2690  Validation loss = 2.2513  \n",
      "\n",
      "Check model:  Fold: 18  Epoch: 4  Training loss = 3.2690  Validation loss = 2.2513  \n",
      "\n",
      "Fold: 19  Epoch: 1  Training loss = 3.2593  Validation loss = 1.0152  \n",
      "\n",
      "Fold: 19  Epoch: 2  Training loss = 3.2586  Validation loss = 1.0155  \n",
      "\n",
      "Fold: 19  Epoch: 3  Training loss = 3.2574  Validation loss = 1.0100  \n",
      "\n",
      "Fold: 19  Epoch: 4  Training loss = 3.2565  Validation loss = 1.0089  \n",
      "\n",
      "Fold: 19  Epoch: 5  Training loss = 3.2555  Validation loss = 1.0082  \n",
      "\n",
      "Fold: 19  Epoch: 6  Training loss = 3.2543  Validation loss = 1.0093  \n",
      "\n",
      "Fold: 19  Epoch: 7  Training loss = 3.2536  Validation loss = 1.0079  \n",
      "\n",
      "Fold: 19  Epoch: 8  Training loss = 3.2524  Validation loss = 1.0080  \n",
      "\n",
      "Fold: 19  Epoch: 9  Training loss = 3.2519  Validation loss = 1.0087  \n",
      "\n",
      "Fold: 19  Epoch: 10  Training loss = 3.2507  Validation loss = 1.0057  \n",
      "\n",
      "Fold: 19  Epoch: 11  Training loss = 3.2495  Validation loss = 1.0040  \n",
      "\n",
      "Fold: 19  Epoch: 12  Training loss = 3.2485  Validation loss = 1.0020  \n",
      "\n",
      "Fold: 19  Epoch: 13  Training loss = 3.2476  Validation loss = 1.0016  \n",
      "\n",
      "Fold: 19  Epoch: 14  Training loss = 3.2474  Validation loss = 1.0042  \n",
      "\n",
      "Fold: 19  Epoch: 15  Training loss = 3.2465  Validation loss = 1.0011  \n",
      "\n",
      "Fold: 19  Epoch: 16  Training loss = 3.2456  Validation loss = 0.9998  \n",
      "\n",
      "Fold: 19  Epoch: 17  Training loss = 3.2443  Validation loss = 0.9957  \n",
      "\n",
      "Fold: 19  Epoch: 18  Training loss = 3.2432  Validation loss = 0.9941  \n",
      "\n",
      "Fold: 19  Epoch: 19  Training loss = 3.2426  Validation loss = 0.9953  \n",
      "\n",
      "Fold: 19  Epoch: 20  Training loss = 3.2422  Validation loss = 0.9936  \n",
      "\n",
      "Fold: 19  Epoch: 21  Training loss = 3.2414  Validation loss = 0.9966  \n",
      "\n",
      "Fold: 19  Epoch: 22  Training loss = 3.2396  Validation loss = 0.9925  \n",
      "\n",
      "Fold: 19  Epoch: 23  Training loss = 3.2388  Validation loss = 0.9904  \n",
      "\n",
      "Fold: 19  Epoch: 24  Training loss = 3.2388  Validation loss = 0.9936  \n",
      "\n",
      "Fold: 19  Epoch: 25  Training loss = 3.2380  Validation loss = 0.9898  \n",
      "\n",
      "Fold: 19  Epoch: 26  Training loss = 3.2375  Validation loss = 0.9893  \n",
      "\n",
      "Fold: 19  Epoch: 27  Training loss = 3.2364  Validation loss = 0.9861  \n",
      "\n",
      "Fold: 19  Epoch: 28  Training loss = 3.2364  Validation loss = 0.9874  \n",
      "\n",
      "Fold: 19  Epoch: 29  Training loss = 3.2360  Validation loss = 0.9893  \n",
      "\n",
      "Fold: 19  Epoch: 30  Training loss = 3.2349  Validation loss = 0.9865  \n",
      "\n",
      "Fold: 19  Epoch: 31  Training loss = 3.2348  Validation loss = 0.9862  \n",
      "\n",
      "Fold: 19  Epoch: 32  Training loss = 3.2334  Validation loss = 0.9856  \n",
      "\n",
      "Fold: 19  Epoch: 33  Training loss = 3.2327  Validation loss = 0.9881  \n",
      "\n",
      "Fold: 19  Epoch: 34  Training loss = 3.2330  Validation loss = 0.9913  \n",
      "\n",
      "Check model:  Fold: 19  Epoch: 32  Training loss = 3.2330  Validation loss = 0.9913  \n",
      "\n",
      "Fold: 20  Epoch: 1  Training loss = 3.2165  Validation loss = 2.2974  \n",
      "\n",
      "Fold: 20  Epoch: 2  Training loss = 3.2156  Validation loss = 2.3021  \n",
      "\n",
      "Fold: 20  Epoch: 3  Training loss = 3.2159  Validation loss = 2.2970  \n",
      "\n",
      "Fold: 20  Epoch: 4  Training loss = 3.2142  Validation loss = 2.3061  \n",
      "\n",
      "Fold: 20  Epoch: 5  Training loss = 3.2144  Validation loss = 2.3017  \n",
      "\n",
      "Fold: 20  Epoch: 6  Training loss = 3.2133  Validation loss = 2.3054  \n",
      "\n",
      "Fold: 20  Epoch: 7  Training loss = 3.2123  Validation loss = 2.3103  \n",
      "\n",
      "Fold: 20  Epoch: 8  Training loss = 3.2115  Validation loss = 2.3205  \n",
      "\n",
      "Fold: 20  Epoch: 9  Training loss = 3.2110  Validation loss = 2.3214  \n",
      "\n",
      "Fold: 20  Epoch: 10  Training loss = 3.2105  Validation loss = 2.3217  \n",
      "\n",
      "Fold: 20  Epoch: 11  Training loss = 3.2087  Validation loss = 2.3297  \n",
      "\n",
      "Check model:  Fold: 20  Epoch: 3  Training loss = 3.2087  Validation loss = 2.3297  \n",
      "\n",
      "Fold: 21  Epoch: 1  Training loss = 3.2507  Validation loss = 2.4857  \n",
      "\n",
      "Fold: 21  Epoch: 2  Training loss = 3.2503  Validation loss = 2.4856  \n",
      "\n",
      "Fold: 21  Epoch: 3  Training loss = 3.2495  Validation loss = 2.4867  \n",
      "\n",
      "Fold: 21  Epoch: 4  Training loss = 3.2488  Validation loss = 2.4822  \n",
      "\n",
      "Fold: 21  Epoch: 5  Training loss = 3.2479  Validation loss = 2.4849  \n",
      "\n",
      "Fold: 21  Epoch: 6  Training loss = 3.2473  Validation loss = 2.4848  \n",
      "\n",
      "Fold: 21  Epoch: 7  Training loss = 3.2465  Validation loss = 2.4880  \n",
      "\n",
      "Fold: 21  Epoch: 8  Training loss = 3.2460  Validation loss = 2.4882  \n",
      "\n",
      "Fold: 21  Epoch: 9  Training loss = 3.2457  Validation loss = 2.4884  \n",
      "\n",
      "Fold: 21  Epoch: 10  Training loss = 3.2448  Validation loss = 2.4916  \n",
      "\n",
      "Fold: 21  Epoch: 11  Training loss = 3.2442  Validation loss = 2.4908  \n",
      "\n",
      "Fold: 21  Epoch: 12  Training loss = 3.2435  Validation loss = 2.4908  \n",
      "\n",
      "Fold: 21  Epoch: 13  Training loss = 3.2424  Validation loss = 2.4919  \n",
      "\n",
      "Check model:  Fold: 21  Epoch: 4  Training loss = 3.2424  Validation loss = 2.4919  \n",
      "\n",
      "Fold: 22  Epoch: 1  Training loss = 3.2797  Validation loss = 1.5870  \n",
      "\n",
      "Fold: 22  Epoch: 2  Training loss = 3.2781  Validation loss = 1.5897  \n",
      "\n",
      "Fold: 22  Epoch: 3  Training loss = 3.2773  Validation loss = 1.5905  \n",
      "\n",
      "Fold: 22  Epoch: 4  Training loss = 3.2761  Validation loss = 1.5927  \n",
      "\n",
      "Fold: 22  Epoch: 5  Training loss = 3.2752  Validation loss = 1.5903  \n",
      "\n",
      "Fold: 22  Epoch: 6  Training loss = 3.2742  Validation loss = 1.5938  \n",
      "\n",
      "Fold: 22  Epoch: 7  Training loss = 3.2728  Validation loss = 1.5931  \n",
      "\n",
      "Fold: 22  Epoch: 8  Training loss = 3.2716  Validation loss = 1.5943  \n",
      "\n",
      "Fold: 22  Epoch: 9  Training loss = 3.2704  Validation loss = 1.5927  \n",
      "\n",
      "Fold: 22  Epoch: 10  Training loss = 3.2698  Validation loss = 1.5946  \n",
      "\n",
      "Fold: 22  Epoch: 11  Training loss = 3.2690  Validation loss = 1.5955  \n",
      "\n",
      "Check model:  Fold: 22  Epoch: 1  Training loss = 3.2690  Validation loss = 1.5955  \n",
      "\n",
      "Fold: 23  Epoch: 1  Training loss = 3.2071  Validation loss = 1.2749  \n",
      "\n",
      "Fold: 23  Epoch: 2  Training loss = 3.2063  Validation loss = 1.2682  \n",
      "\n",
      "Fold: 23  Epoch: 3  Training loss = 3.2054  Validation loss = 1.2706  \n",
      "\n",
      "Fold: 23  Epoch: 4  Training loss = 3.2041  Validation loss = 1.2619  \n",
      "\n",
      "Fold: 23  Epoch: 5  Training loss = 3.2034  Validation loss = 1.2486  \n",
      "\n",
      "Fold: 23  Epoch: 6  Training loss = 3.2026  Validation loss = 1.2594  \n",
      "\n",
      "Fold: 23  Epoch: 7  Training loss = 3.2016  Validation loss = 1.2599  \n",
      "\n",
      "Fold: 23  Epoch: 8  Training loss = 3.2009  Validation loss = 1.2591  \n",
      "\n",
      "Fold: 23  Epoch: 9  Training loss = 3.1997  Validation loss = 1.2644  \n",
      "\n",
      "Fold: 23  Epoch: 10  Training loss = 3.1981  Validation loss = 1.2566  \n",
      "\n",
      "Fold: 23  Epoch: 11  Training loss = 3.1983  Validation loss = 1.2192  \n",
      "\n",
      "Fold: 23  Epoch: 12  Training loss = 3.1968  Validation loss = 1.2394  \n",
      "\n",
      "Fold: 23  Epoch: 13  Training loss = 3.1955  Validation loss = 1.2480  \n",
      "\n",
      "Fold: 23  Epoch: 14  Training loss = 3.1946  Validation loss = 1.2495  \n",
      "\n",
      "Fold: 23  Epoch: 15  Training loss = 3.1930  Validation loss = 1.2584  \n",
      "\n",
      "Fold: 23  Epoch: 16  Training loss = 3.1920  Validation loss = 1.2561  \n",
      "\n",
      "Fold: 23  Epoch: 17  Training loss = 3.1906  Validation loss = 1.2564  \n",
      "\n",
      "Fold: 23  Epoch: 18  Training loss = 3.1899  Validation loss = 1.2316  \n",
      "\n",
      "Fold: 23  Epoch: 19  Training loss = 3.1892  Validation loss = 1.2248  \n",
      "\n",
      "Fold: 23  Epoch: 20  Training loss = 3.1882  Validation loss = 1.2141  \n",
      "\n",
      "Fold: 23  Epoch: 21  Training loss = 3.1869  Validation loss = 1.2236  \n",
      "\n",
      "Fold: 23  Epoch: 22  Training loss = 3.1859  Validation loss = 1.2236  \n",
      "\n",
      "Fold: 23  Epoch: 23  Training loss = 3.1849  Validation loss = 1.2033  \n",
      "\n",
      "Fold: 23  Epoch: 24  Training loss = 3.1850  Validation loss = 1.2648  \n",
      "\n",
      "Check model:  Fold: 23  Epoch: 23  Training loss = 3.1850  Validation loss = 1.2648  \n",
      "\n",
      "Fold: 24  Epoch: 1  Training loss = 3.0421  Validation loss = 2.1097  \n",
      "\n",
      "Fold: 24  Epoch: 2  Training loss = 3.0409  Validation loss = 2.1065  \n",
      "\n",
      "Fold: 24  Epoch: 3  Training loss = 3.0397  Validation loss = 2.1038  \n",
      "\n",
      "Fold: 24  Epoch: 4  Training loss = 3.0375  Validation loss = 2.1029  \n",
      "\n",
      "Fold: 24  Epoch: 5  Training loss = 3.0367  Validation loss = 2.1005  \n",
      "\n",
      "Fold: 24  Epoch: 6  Training loss = 3.0352  Validation loss = 2.0983  \n",
      "\n",
      "Fold: 24  Epoch: 7  Training loss = 3.0332  Validation loss = 2.0992  \n",
      "\n",
      "Fold: 24  Epoch: 8  Training loss = 3.0319  Validation loss = 2.0979  \n",
      "\n",
      "Fold: 24  Epoch: 9  Training loss = 3.0302  Validation loss = 2.0971  \n",
      "\n",
      "Fold: 24  Epoch: 10  Training loss = 3.0284  Validation loss = 2.0968  \n",
      "\n",
      "Fold: 24  Epoch: 11  Training loss = 3.0267  Validation loss = 2.0941  \n",
      "\n",
      "Fold: 24  Epoch: 12  Training loss = 3.0257  Validation loss = 2.0924  \n",
      "\n",
      "Fold: 24  Epoch: 13  Training loss = 3.0244  Validation loss = 2.0919  \n",
      "\n",
      "Fold: 24  Epoch: 14  Training loss = 3.0230  Validation loss = 2.0928  \n",
      "\n",
      "Fold: 24  Epoch: 15  Training loss = 3.0211  Validation loss = 2.0905  \n",
      "\n",
      "Fold: 24  Epoch: 16  Training loss = 3.0196  Validation loss = 2.0909  \n",
      "\n",
      "Fold: 24  Epoch: 17  Training loss = 3.0173  Validation loss = 2.0880  \n",
      "\n",
      "Fold: 24  Epoch: 18  Training loss = 3.0149  Validation loss = 2.0859  \n",
      "\n",
      "Fold: 24  Epoch: 19  Training loss = 3.0130  Validation loss = 2.0841  \n",
      "\n",
      "Fold: 24  Epoch: 20  Training loss = 3.0117  Validation loss = 2.0829  \n",
      "\n",
      "Fold: 24  Epoch: 21  Training loss = 3.0112  Validation loss = 2.0828  \n",
      "\n",
      "Fold: 24  Epoch: 22  Training loss = 3.0091  Validation loss = 2.0806  \n",
      "\n",
      "Fold: 24  Epoch: 23  Training loss = 3.0070  Validation loss = 2.0771  \n",
      "\n",
      "Fold: 24  Epoch: 24  Training loss = 3.0064  Validation loss = 2.0734  \n",
      "\n",
      "Fold: 24  Epoch: 25  Training loss = 3.0048  Validation loss = 2.0745  \n",
      "\n",
      "Fold: 24  Epoch: 26  Training loss = 3.0039  Validation loss = 2.0733  \n",
      "\n",
      "Fold: 24  Epoch: 27  Training loss = 3.0027  Validation loss = 2.0695  \n",
      "\n",
      "Fold: 24  Epoch: 28  Training loss = 3.0012  Validation loss = 2.0700  \n",
      "\n",
      "Fold: 24  Epoch: 29  Training loss = 2.9996  Validation loss = 2.0700  \n",
      "\n",
      "Fold: 24  Epoch: 30  Training loss = 3.0008  Validation loss = 2.0697  \n",
      "\n",
      "Fold: 24  Epoch: 31  Training loss = 2.9999  Validation loss = 2.0659  \n",
      "\n",
      "Fold: 24  Epoch: 32  Training loss = 2.9984  Validation loss = 2.0655  \n",
      "\n",
      "Fold: 24  Epoch: 33  Training loss = 2.9974  Validation loss = 2.0680  \n",
      "\n",
      "Fold: 24  Epoch: 34  Training loss = 2.9963  Validation loss = 2.0650  \n",
      "\n",
      "Fold: 24  Epoch: 35  Training loss = 2.9947  Validation loss = 2.0637  \n",
      "\n",
      "Fold: 24  Epoch: 36  Training loss = 2.9950  Validation loss = 2.0635  \n",
      "\n",
      "Fold: 24  Epoch: 37  Training loss = 2.9929  Validation loss = 2.0633  \n",
      "\n",
      "Fold: 24  Epoch: 38  Training loss = 2.9919  Validation loss = 2.0621  \n",
      "\n",
      "Fold: 24  Epoch: 39  Training loss = 2.9900  Validation loss = 2.0605  \n",
      "\n",
      "Fold: 24  Epoch: 40  Training loss = 2.9885  Validation loss = 2.0605  \n",
      "\n",
      "Fold: 24  Epoch: 41  Training loss = 2.9869  Validation loss = 2.0598  \n",
      "\n",
      "Fold: 24  Epoch: 42  Training loss = 2.9850  Validation loss = 2.0592  \n",
      "\n",
      "Fold: 24  Epoch: 43  Training loss = 2.9838  Validation loss = 2.0586  \n",
      "\n",
      "Fold: 24  Epoch: 44  Training loss = 2.9826  Validation loss = 2.0570  \n",
      "\n",
      "Fold: 24  Epoch: 45  Training loss = 2.9811  Validation loss = 2.0558  \n",
      "\n",
      "Fold: 24  Epoch: 46  Training loss = 2.9800  Validation loss = 2.0553  \n",
      "\n",
      "Fold: 24  Epoch: 47  Training loss = 2.9790  Validation loss = 2.0552  \n",
      "\n",
      "Fold: 24  Epoch: 48  Training loss = 2.9774  Validation loss = 2.0542  \n",
      "\n",
      "Fold: 24  Epoch: 49  Training loss = 2.9755  Validation loss = 2.0513  \n",
      "\n",
      "Fold: 24  Epoch: 50  Training loss = 2.9741  Validation loss = 2.0499  \n",
      "\n",
      "Fold: 24  Epoch: 51  Training loss = 2.9735  Validation loss = 2.0506  \n",
      "\n",
      "Fold: 24  Epoch: 52  Training loss = 2.9721  Validation loss = 2.0496  \n",
      "\n",
      "Fold: 24  Epoch: 53  Training loss = 2.9713  Validation loss = 2.0479  \n",
      "\n",
      "Fold: 24  Epoch: 54  Training loss = 2.9705  Validation loss = 2.0476  \n",
      "\n",
      "Fold: 24  Epoch: 55  Training loss = 2.9688  Validation loss = 2.0476  \n",
      "\n",
      "Fold: 24  Epoch: 56  Training loss = 2.9675  Validation loss = 2.0488  \n",
      "\n",
      "Fold: 24  Epoch: 57  Training loss = 2.9670  Validation loss = 2.0490  \n",
      "\n",
      "Fold: 24  Epoch: 58  Training loss = 2.9653  Validation loss = 2.0478  \n",
      "\n",
      "Fold: 24  Epoch: 59  Training loss = 2.9640  Validation loss = 2.0480  \n",
      "\n",
      "Fold: 24  Epoch: 60  Training loss = 2.9630  Validation loss = 2.0453  \n",
      "\n",
      "Fold: 24  Epoch: 61  Training loss = 2.9620  Validation loss = 2.0456  \n",
      "\n",
      "Fold: 24  Epoch: 62  Training loss = 2.9607  Validation loss = 2.0447  \n",
      "\n",
      "Fold: 24  Epoch: 63  Training loss = 2.9597  Validation loss = 2.0466  \n",
      "\n",
      "Fold: 24  Epoch: 64  Training loss = 2.9586  Validation loss = 2.0454  \n",
      "\n",
      "Fold: 24  Epoch: 65  Training loss = 2.9580  Validation loss = 2.0454  \n",
      "\n",
      "Fold: 24  Epoch: 66  Training loss = 2.9562  Validation loss = 2.0445  \n",
      "\n",
      "Fold: 24  Epoch: 67  Training loss = 2.9554  Validation loss = 2.0446  \n",
      "\n",
      "Fold: 24  Epoch: 68  Training loss = 2.9542  Validation loss = 2.0450  \n",
      "\n",
      "Fold: 24  Epoch: 69  Training loss = 2.9526  Validation loss = 2.0434  \n",
      "\n",
      "Fold: 24  Epoch: 70  Training loss = 2.9513  Validation loss = 2.0417  \n",
      "\n",
      "Fold: 24  Epoch: 71  Training loss = 2.9493  Validation loss = 2.0400  \n",
      "\n",
      "Fold: 24  Epoch: 72  Training loss = 2.9483  Validation loss = 2.0390  \n",
      "\n",
      "Fold: 24  Epoch: 73  Training loss = 2.9470  Validation loss = 2.0371  \n",
      "\n",
      "Fold: 24  Epoch: 74  Training loss = 2.9455  Validation loss = 2.0347  \n",
      "\n",
      "Fold: 24  Epoch: 75  Training loss = 2.9439  Validation loss = 2.0343  \n",
      "\n",
      "Fold: 24  Epoch: 76  Training loss = 2.9434  Validation loss = 2.0332  \n",
      "\n",
      "Fold: 24  Epoch: 77  Training loss = 2.9408  Validation loss = 2.0320  \n",
      "\n",
      "Fold: 24  Epoch: 78  Training loss = 2.9396  Validation loss = 2.0311  \n",
      "\n",
      "Fold: 24  Epoch: 79  Training loss = 2.9384  Validation loss = 2.0299  \n",
      "\n",
      "Fold: 24  Epoch: 80  Training loss = 2.9375  Validation loss = 2.0266  \n",
      "\n",
      "Fold: 24  Epoch: 81  Training loss = 2.9369  Validation loss = 2.0261  \n",
      "\n",
      "Fold: 24  Epoch: 82  Training loss = 2.9351  Validation loss = 2.0244  \n",
      "\n",
      "Fold: 24  Epoch: 83  Training loss = 2.9336  Validation loss = 2.0260  \n",
      "\n",
      "Fold: 24  Epoch: 84  Training loss = 2.9319  Validation loss = 2.0249  \n",
      "\n",
      "Fold: 24  Epoch: 85  Training loss = 2.9309  Validation loss = 2.0233  \n",
      "\n",
      "Fold: 24  Epoch: 86  Training loss = 2.9297  Validation loss = 2.0229  \n",
      "\n",
      "Fold: 24  Epoch: 87  Training loss = 2.9288  Validation loss = 2.0227  \n",
      "\n",
      "Fold: 24  Epoch: 88  Training loss = 2.9273  Validation loss = 2.0209  \n",
      "\n",
      "Fold: 24  Epoch: 89  Training loss = 2.9259  Validation loss = 2.0196  \n",
      "\n",
      "Fold: 24  Epoch: 90  Training loss = 2.9242  Validation loss = 2.0203  \n",
      "\n",
      "Fold: 24  Epoch: 91  Training loss = 2.9230  Validation loss = 2.0208  \n",
      "\n",
      "Fold: 24  Epoch: 92  Training loss = 2.9230  Validation loss = 2.0193  \n",
      "\n",
      "Fold: 24  Epoch: 93  Training loss = 2.9228  Validation loss = 2.0166  \n",
      "\n",
      "Fold: 24  Epoch: 94  Training loss = 2.9219  Validation loss = 2.0157  \n",
      "\n",
      "Fold: 24  Epoch: 95  Training loss = 2.9206  Validation loss = 2.0146  \n",
      "\n",
      "Fold: 24  Epoch: 96  Training loss = 2.9195  Validation loss = 2.0162  \n",
      "\n",
      "Fold: 24  Epoch: 97  Training loss = 2.9179  Validation loss = 2.0144  \n",
      "\n",
      "Fold: 24  Epoch: 98  Training loss = 2.9164  Validation loss = 2.0135  \n",
      "\n",
      "Fold: 24  Epoch: 99  Training loss = 2.9155  Validation loss = 2.0149  \n",
      "\n",
      "Fold: 24  Epoch: 100  Training loss = 2.9151  Validation loss = 2.0152  \n",
      "\n",
      "Fold: 24  Epoch: 101  Training loss = 2.9130  Validation loss = 2.0149  \n",
      "\n",
      "Fold: 24  Epoch: 102  Training loss = 2.9119  Validation loss = 2.0137  \n",
      "\n",
      "Fold: 24  Epoch: 103  Training loss = 2.9106  Validation loss = 2.0118  \n",
      "\n",
      "Fold: 24  Epoch: 104  Training loss = 2.9094  Validation loss = 2.0126  \n",
      "\n",
      "Fold: 24  Epoch: 105  Training loss = 2.9079  Validation loss = 2.0117  \n",
      "\n",
      "Fold: 24  Epoch: 106  Training loss = 2.9062  Validation loss = 2.0104  \n",
      "\n",
      "Fold: 24  Epoch: 107  Training loss = 2.9049  Validation loss = 2.0107  \n",
      "\n",
      "Fold: 24  Epoch: 108  Training loss = 2.9034  Validation loss = 2.0101  \n",
      "\n",
      "Fold: 24  Epoch: 109  Training loss = 2.9023  Validation loss = 2.0121  \n",
      "\n",
      "Fold: 24  Epoch: 110  Training loss = 2.9010  Validation loss = 2.0133  \n",
      "\n",
      "Fold: 24  Epoch: 111  Training loss = 2.9008  Validation loss = 2.0128  \n",
      "\n",
      "Fold: 24  Epoch: 112  Training loss = 2.8982  Validation loss = 2.0131  \n",
      "\n",
      "Fold: 24  Epoch: 113  Training loss = 2.8977  Validation loss = 2.0130  \n",
      "\n",
      "Fold: 24  Epoch: 114  Training loss = 2.8965  Validation loss = 2.0132  \n",
      "\n",
      "Fold: 24  Epoch: 115  Training loss = 2.8954  Validation loss = 2.0122  \n",
      "\n",
      "Fold: 24  Epoch: 116  Training loss = 2.8940  Validation loss = 2.0125  \n",
      "\n",
      "Fold: 24  Epoch: 117  Training loss = 2.8933  Validation loss = 2.0117  \n",
      "\n",
      "Fold: 24  Epoch: 118  Training loss = 2.8918  Validation loss = 2.0097  \n",
      "\n",
      "Fold: 24  Epoch: 119  Training loss = 2.8906  Validation loss = 2.0079  \n",
      "\n",
      "Fold: 24  Epoch: 120  Training loss = 2.8891  Validation loss = 2.0069  \n",
      "\n",
      "Fold: 24  Epoch: 121  Training loss = 2.8885  Validation loss = 2.0067  \n",
      "\n",
      "Fold: 24  Epoch: 122  Training loss = 2.8869  Validation loss = 2.0064  \n",
      "\n",
      "Fold: 24  Epoch: 123  Training loss = 2.8857  Validation loss = 2.0034  \n",
      "\n",
      "Fold: 24  Epoch: 124  Training loss = 2.8851  Validation loss = 2.0024  \n",
      "\n",
      "Fold: 24  Epoch: 125  Training loss = 2.8837  Validation loss = 2.0005  \n",
      "\n",
      "Fold: 24  Epoch: 126  Training loss = 2.8827  Validation loss = 2.0017  \n",
      "\n",
      "Fold: 24  Epoch: 127  Training loss = 2.8819  Validation loss = 2.0019  \n",
      "\n",
      "Fold: 24  Epoch: 128  Training loss = 2.8809  Validation loss = 2.0014  \n",
      "\n",
      "Fold: 24  Epoch: 129  Training loss = 2.8798  Validation loss = 2.0014  \n",
      "\n",
      "Fold: 24  Epoch: 130  Training loss = 2.8788  Validation loss = 2.0024  \n",
      "\n",
      "Fold: 24  Epoch: 131  Training loss = 2.8775  Validation loss = 2.0060  \n",
      "\n",
      "Fold: 24  Epoch: 132  Training loss = 2.8763  Validation loss = 2.0046  \n",
      "\n",
      "Fold: 24  Epoch: 133  Training loss = 2.8750  Validation loss = 2.0055  \n",
      "\n",
      "Fold: 24  Epoch: 134  Training loss = 2.8739  Validation loss = 2.0025  \n",
      "\n",
      "Fold: 24  Epoch: 135  Training loss = 2.8739  Validation loss = 2.0010  \n",
      "\n",
      "Fold: 24  Epoch: 136  Training loss = 2.8734  Validation loss = 1.9990  \n",
      "\n",
      "Fold: 24  Epoch: 137  Training loss = 2.8721  Validation loss = 1.9960  \n",
      "\n",
      "Fold: 24  Epoch: 138  Training loss = 2.8720  Validation loss = 1.9962  \n",
      "\n",
      "Fold: 24  Epoch: 139  Training loss = 2.8720  Validation loss = 1.9954  \n",
      "\n",
      "Fold: 24  Epoch: 140  Training loss = 2.8696  Validation loss = 1.9970  \n",
      "\n",
      "Fold: 24  Epoch: 141  Training loss = 2.8690  Validation loss = 1.9949  \n",
      "\n",
      "Fold: 24  Epoch: 142  Training loss = 2.8682  Validation loss = 1.9954  \n",
      "\n",
      "Fold: 24  Epoch: 143  Training loss = 2.8671  Validation loss = 1.9952  \n",
      "\n",
      "Fold: 24  Epoch: 144  Training loss = 2.8662  Validation loss = 1.9950  \n",
      "\n",
      "Fold: 24  Epoch: 145  Training loss = 2.8647  Validation loss = 1.9945  \n",
      "\n",
      "Fold: 24  Epoch: 146  Training loss = 2.8639  Validation loss = 1.9945  \n",
      "\n",
      "Fold: 24  Epoch: 147  Training loss = 2.8626  Validation loss = 1.9935  \n",
      "\n",
      "Fold: 24  Epoch: 148  Training loss = 2.8619  Validation loss = 1.9926  \n",
      "\n",
      "Fold: 24  Epoch: 149  Training loss = 2.8602  Validation loss = 1.9929  \n",
      "\n",
      "Fold: 24  Epoch: 150  Training loss = 2.8590  Validation loss = 1.9962  \n",
      "\n",
      "Check model:  Fold: 24  Epoch: 148  Training loss = 2.8590  Validation loss = 1.9962  \n",
      "\n",
      "Fold: 25  Epoch: 1  Training loss = 2.8495  Validation loss = 2.2440  \n",
      "\n",
      "Fold: 25  Epoch: 2  Training loss = 2.8485  Validation loss = 2.2096  \n",
      "\n",
      "Fold: 25  Epoch: 3  Training loss = 2.8473  Validation loss = 2.2139  \n",
      "\n",
      "Fold: 25  Epoch: 4  Training loss = 2.8463  Validation loss = 2.1934  \n",
      "\n",
      "Fold: 25  Epoch: 5  Training loss = 2.8451  Validation loss = 2.2115  \n",
      "\n",
      "Fold: 25  Epoch: 6  Training loss = 2.8437  Validation loss = 2.1800  \n",
      "\n",
      "Fold: 25  Epoch: 7  Training loss = 2.8422  Validation loss = 2.1993  \n",
      "\n",
      "Fold: 25  Epoch: 8  Training loss = 2.8410  Validation loss = 2.2077  \n",
      "\n",
      "Fold: 25  Epoch: 9  Training loss = 2.8396  Validation loss = 2.1854  \n",
      "\n",
      "Fold: 25  Epoch: 10  Training loss = 2.8383  Validation loss = 2.1977  \n",
      "\n",
      "Fold: 25  Epoch: 11  Training loss = 2.8374  Validation loss = 2.2092  \n",
      "\n",
      "Fold: 25  Epoch: 12  Training loss = 2.8365  Validation loss = 2.2002  \n",
      "\n",
      "Fold: 25  Epoch: 13  Training loss = 2.8358  Validation loss = 2.1753  \n",
      "\n",
      "Fold: 25  Epoch: 14  Training loss = 2.8344  Validation loss = 2.1742  \n",
      "\n",
      "Fold: 25  Epoch: 15  Training loss = 2.8334  Validation loss = 2.1811  \n",
      "\n",
      "Fold: 25  Epoch: 16  Training loss = 2.8322  Validation loss = 2.1834  \n",
      "\n",
      "Fold: 25  Epoch: 17  Training loss = 2.8314  Validation loss = 2.1749  \n",
      "\n",
      "Fold: 25  Epoch: 18  Training loss = 2.8305  Validation loss = 2.1582  \n",
      "\n",
      "Fold: 25  Epoch: 19  Training loss = 2.8297  Validation loss = 2.1556  \n",
      "\n",
      "Fold: 25  Epoch: 20  Training loss = 2.8288  Validation loss = 2.1706  \n",
      "\n",
      "Fold: 25  Epoch: 21  Training loss = 2.8281  Validation loss = 2.1668  \n",
      "\n",
      "Fold: 25  Epoch: 22  Training loss = 2.8276  Validation loss = 2.1315  \n",
      "\n",
      "Fold: 25  Epoch: 23  Training loss = 2.8259  Validation loss = 2.1994  \n",
      "\n",
      "Check model:  Fold: 25  Epoch: 22  Training loss = 2.8259  Validation loss = 2.1994  \n",
      "\n",
      "Fold: 26  Epoch: 1  Training loss = 2.6418  Validation loss = 2.8648  \n",
      "\n",
      "Fold: 26  Epoch: 2  Training loss = 2.6406  Validation loss = 2.8643  \n",
      "\n",
      "Fold: 26  Epoch: 3  Training loss = 2.6382  Validation loss = 2.8974  \n",
      "\n",
      "Fold: 26  Epoch: 4  Training loss = 2.6352  Validation loss = 2.9808  \n",
      "\n",
      "Fold: 26  Epoch: 5  Training loss = 2.6347  Validation loss = 2.9611  \n",
      "\n",
      "Fold: 26  Epoch: 6  Training loss = 2.6326  Validation loss = 3.0087  \n",
      "\n",
      "Fold: 26  Epoch: 7  Training loss = 2.6314  Validation loss = 3.0179  \n",
      "\n",
      "Fold: 26  Epoch: 8  Training loss = 2.6298  Validation loss = 3.0296  \n",
      "\n",
      "Fold: 26  Epoch: 9  Training loss = 2.6250  Validation loss = 3.0879  \n",
      "\n",
      "Fold: 26  Epoch: 10  Training loss = 2.6236  Validation loss = 3.0975  \n",
      "\n",
      "Fold: 26  Epoch: 11  Training loss = 2.6233  Validation loss = 3.1408  \n",
      "\n",
      "Check model:  Fold: 26  Epoch: 2  Training loss = 2.6233  Validation loss = 3.1408  \n",
      "\n",
      "Fold: 27  Epoch: 1  Training loss = 2.6457  Validation loss = 1.7231  \n",
      "\n",
      "Fold: 27  Epoch: 2  Training loss = 2.6464  Validation loss = 1.7555  \n",
      "\n",
      "Fold: 27  Epoch: 3  Training loss = 2.6468  Validation loss = 1.7703  \n",
      "\n",
      "Fold: 27  Epoch: 4  Training loss = 2.6462  Validation loss = 1.7761  \n",
      "\n",
      "Fold: 27  Epoch: 5  Training loss = 2.6438  Validation loss = 1.7575  \n",
      "\n",
      "Fold: 27  Epoch: 6  Training loss = 2.6431  Validation loss = 1.7608  \n",
      "\n",
      "Fold: 27  Epoch: 7  Training loss = 2.6413  Validation loss = 1.7518  \n",
      "\n",
      "Fold: 27  Epoch: 8  Training loss = 2.6391  Validation loss = 1.7430  \n",
      "\n",
      "Fold: 27  Epoch: 9  Training loss = 2.6369  Validation loss = 1.7282  \n",
      "\n",
      "Fold: 27  Epoch: 10  Training loss = 2.6367  Validation loss = 1.6773  \n",
      "\n",
      "Fold: 27  Epoch: 11  Training loss = 2.6372  Validation loss = 1.7037  \n",
      "\n",
      "Fold: 27  Epoch: 12  Training loss = 2.6355  Validation loss = 1.6953  \n",
      "\n",
      "Fold: 27  Epoch: 13  Training loss = 2.6280  Validation loss = 1.5382  \n",
      "\n",
      "Fold: 27  Epoch: 14  Training loss = 2.6257  Validation loss = 1.5246  \n",
      "\n",
      "Fold: 27  Epoch: 15  Training loss = 2.6252  Validation loss = 1.5574  \n",
      "\n",
      "Fold: 27  Epoch: 16  Training loss = 2.6292  Validation loss = 1.6691  \n",
      "\n",
      "Fold: 27  Epoch: 17  Training loss = 2.6305  Validation loss = 1.7197  \n",
      "\n",
      "Fold: 27  Epoch: 18  Training loss = 2.6218  Validation loss = 1.6438  \n",
      "\n",
      "Fold: 27  Epoch: 19  Training loss = 2.6170  Validation loss = 1.5327  \n",
      "\n",
      "Fold: 27  Epoch: 20  Training loss = 2.6161  Validation loss = 1.5125  \n",
      "\n",
      "Fold: 27  Epoch: 21  Training loss = 2.6145  Validation loss = 1.5485  \n",
      "\n",
      "Fold: 27  Epoch: 22  Training loss = 2.6136  Validation loss = 1.5535  \n",
      "\n",
      "Fold: 27  Epoch: 23  Training loss = 2.6131  Validation loss = 1.4922  \n",
      "\n",
      "Fold: 27  Epoch: 24  Training loss = 2.6117  Validation loss = 1.5052  \n",
      "\n",
      "Fold: 27  Epoch: 25  Training loss = 2.6100  Validation loss = 1.5313  \n",
      "\n",
      "Fold: 27  Epoch: 26  Training loss = 2.6112  Validation loss = 1.5993  \n",
      "\n",
      "Fold: 27  Epoch: 27  Training loss = 2.6095  Validation loss = 1.5915  \n",
      "\n",
      "Fold: 27  Epoch: 28  Training loss = 2.6079  Validation loss = 1.5392  \n",
      "\n",
      "Fold: 27  Epoch: 29  Training loss = 2.6074  Validation loss = 1.5745  \n",
      "\n",
      "Fold: 27  Epoch: 30  Training loss = 2.6060  Validation loss = 1.5135  \n",
      "\n",
      "Fold: 27  Epoch: 31  Training loss = 2.6050  Validation loss = 1.5284  \n",
      "\n",
      "Fold: 27  Epoch: 32  Training loss = 2.6068  Validation loss = 1.6171  \n",
      "\n",
      "Check model:  Fold: 27  Epoch: 23  Training loss = 2.6068  Validation loss = 1.6171  \n",
      "\n",
      "Fold: 28  Epoch: 1  Training loss = 2.4841  Validation loss = 1.7500  \n",
      "\n",
      "Fold: 28  Epoch: 2  Training loss = 2.4838  Validation loss = 1.7501  \n",
      "\n",
      "Fold: 28  Epoch: 3  Training loss = 2.4820  Validation loss = 1.7345  \n",
      "\n",
      "Fold: 28  Epoch: 4  Training loss = 2.4800  Validation loss = 1.7357  \n",
      "\n",
      "Fold: 28  Epoch: 5  Training loss = 2.4783  Validation loss = 1.7282  \n",
      "\n",
      "Fold: 28  Epoch: 6  Training loss = 2.4794  Validation loss = 1.7213  \n",
      "\n",
      "Fold: 28  Epoch: 7  Training loss = 2.4791  Validation loss = 1.7160  \n",
      "\n",
      "Fold: 28  Epoch: 8  Training loss = 2.4756  Validation loss = 1.7243  \n",
      "\n",
      "Fold: 28  Epoch: 9  Training loss = 2.4759  Validation loss = 1.7324  \n",
      "\n",
      "Fold: 28  Epoch: 10  Training loss = 2.4729  Validation loss = 1.7211  \n",
      "\n",
      "Fold: 28  Epoch: 11  Training loss = 2.4721  Validation loss = 1.7115  \n",
      "\n",
      "Fold: 28  Epoch: 12  Training loss = 2.4688  Validation loss = 1.7166  \n",
      "\n",
      "Fold: 28  Epoch: 13  Training loss = 2.4707  Validation loss = 1.6978  \n",
      "\n",
      "Fold: 28  Epoch: 14  Training loss = 2.4659  Validation loss = 1.7011  \n",
      "\n",
      "Fold: 28  Epoch: 15  Training loss = 2.4675  Validation loss = 1.7200  \n",
      "\n",
      "Fold: 28  Epoch: 16  Training loss = 2.4691  Validation loss = 1.7287  \n",
      "\n",
      "Fold: 28  Epoch: 17  Training loss = 2.4706  Validation loss = 1.7299  \n",
      "\n",
      "Fold: 28  Epoch: 18  Training loss = 2.4710  Validation loss = 1.7320  \n",
      "\n",
      "Fold: 28  Epoch: 19  Training loss = 2.4620  Validation loss = 1.7161  \n",
      "\n",
      "Fold: 28  Epoch: 20  Training loss = 2.4597  Validation loss = 1.7092  \n",
      "\n",
      "Fold: 28  Epoch: 21  Training loss = 2.4573  Validation loss = 1.7009  \n",
      "\n",
      "Fold: 28  Epoch: 22  Training loss = 2.4570  Validation loss = 1.6962  \n",
      "\n",
      "Fold: 28  Epoch: 23  Training loss = 2.4556  Validation loss = 1.7006  \n",
      "\n",
      "Fold: 28  Epoch: 24  Training loss = 2.4555  Validation loss = 1.7101  \n",
      "\n",
      "Fold: 28  Epoch: 25  Training loss = 2.4554  Validation loss = 1.7090  \n",
      "\n",
      "Fold: 28  Epoch: 26  Training loss = 2.4540  Validation loss = 1.6927  \n",
      "\n",
      "Fold: 28  Epoch: 27  Training loss = 2.4549  Validation loss = 1.6903  \n",
      "\n",
      "Fold: 28  Epoch: 28  Training loss = 2.4508  Validation loss = 1.7008  \n",
      "\n",
      "Fold: 28  Epoch: 29  Training loss = 2.4500  Validation loss = 1.6998  \n",
      "\n",
      "Fold: 28  Epoch: 30  Training loss = 2.4507  Validation loss = 1.6860  \n",
      "\n",
      "Fold: 28  Epoch: 31  Training loss = 2.4487  Validation loss = 1.7034  \n",
      "\n",
      "Fold: 28  Epoch: 32  Training loss = 2.4481  Validation loss = 1.6894  \n",
      "\n",
      "Fold: 28  Epoch: 33  Training loss = 2.4458  Validation loss = 1.6877  \n",
      "\n",
      "Fold: 28  Epoch: 34  Training loss = 2.4470  Validation loss = 1.6774  \n",
      "\n",
      "Fold: 28  Epoch: 35  Training loss = 2.4464  Validation loss = 1.6758  \n",
      "\n",
      "Fold: 28  Epoch: 36  Training loss = 2.4476  Validation loss = 1.6709  \n",
      "\n",
      "Fold: 28  Epoch: 37  Training loss = 2.4454  Validation loss = 1.6984  \n",
      "\n",
      "Fold: 28  Epoch: 38  Training loss = 2.4408  Validation loss = 1.6828  \n",
      "\n",
      "Fold: 28  Epoch: 39  Training loss = 2.4399  Validation loss = 1.6817  \n",
      "\n",
      "Fold: 28  Epoch: 40  Training loss = 2.4411  Validation loss = 1.6721  \n",
      "\n",
      "Fold: 28  Epoch: 41  Training loss = 2.4379  Validation loss = 1.6845  \n",
      "\n",
      "Fold: 28  Epoch: 42  Training loss = 2.4376  Validation loss = 1.6872  \n",
      "\n",
      "Fold: 28  Epoch: 43  Training loss = 2.4409  Validation loss = 1.6969  \n",
      "\n",
      "Fold: 28  Epoch: 44  Training loss = 2.4356  Validation loss = 1.6837  \n",
      "\n",
      "Fold: 28  Epoch: 45  Training loss = 2.4345  Validation loss = 1.6858  \n",
      "\n",
      "Fold: 28  Epoch: 46  Training loss = 2.4332  Validation loss = 1.6709  \n",
      "\n",
      "Fold: 28  Epoch: 47  Training loss = 2.4322  Validation loss = 1.6698  \n",
      "\n",
      "Fold: 28  Epoch: 48  Training loss = 2.4380  Validation loss = 1.6915  \n",
      "\n",
      "Fold: 28  Epoch: 49  Training loss = 2.4303  Validation loss = 1.6803  \n",
      "\n",
      "Fold: 28  Epoch: 50  Training loss = 2.4278  Validation loss = 1.6739  \n",
      "\n",
      "Fold: 28  Epoch: 51  Training loss = 2.4284  Validation loss = 1.6813  \n",
      "\n",
      "Fold: 28  Epoch: 52  Training loss = 2.4259  Validation loss = 1.6670  \n",
      "\n",
      "Fold: 28  Epoch: 53  Training loss = 2.4242  Validation loss = 1.6776  \n",
      "\n",
      "Fold: 28  Epoch: 54  Training loss = 2.4220  Validation loss = 1.6713  \n",
      "\n",
      "Fold: 28  Epoch: 55  Training loss = 2.4237  Validation loss = 1.6548  \n",
      "\n",
      "Fold: 28  Epoch: 56  Training loss = 2.4194  Validation loss = 1.6606  \n",
      "\n",
      "Fold: 28  Epoch: 57  Training loss = 2.4220  Validation loss = 1.6760  \n",
      "\n",
      "Fold: 28  Epoch: 58  Training loss = 2.4169  Validation loss = 1.6649  \n",
      "\n",
      "Fold: 28  Epoch: 59  Training loss = 2.4152  Validation loss = 1.6579  \n",
      "\n",
      "Fold: 28  Epoch: 60  Training loss = 2.4144  Validation loss = 1.6620  \n",
      "\n",
      "Fold: 28  Epoch: 61  Training loss = 2.4125  Validation loss = 1.6577  \n",
      "\n",
      "Fold: 28  Epoch: 62  Training loss = 2.4107  Validation loss = 1.6457  \n",
      "\n",
      "Fold: 28  Epoch: 63  Training loss = 2.4094  Validation loss = 1.6495  \n",
      "\n",
      "Fold: 28  Epoch: 64  Training loss = 2.4098  Validation loss = 1.6359  \n",
      "\n",
      "Fold: 28  Epoch: 65  Training loss = 2.4075  Validation loss = 1.6396  \n",
      "\n",
      "Fold: 28  Epoch: 66  Training loss = 2.4062  Validation loss = 1.6366  \n",
      "\n",
      "Fold: 28  Epoch: 67  Training loss = 2.4038  Validation loss = 1.6420  \n",
      "\n",
      "Fold: 28  Epoch: 68  Training loss = 2.4031  Validation loss = 1.6472  \n",
      "\n",
      "Fold: 28  Epoch: 69  Training loss = 2.4017  Validation loss = 1.6479  \n",
      "\n",
      "Fold: 28  Epoch: 70  Training loss = 2.4009  Validation loss = 1.6507  \n",
      "\n",
      "Fold: 28  Epoch: 71  Training loss = 2.3991  Validation loss = 1.6473  \n",
      "\n",
      "Fold: 28  Epoch: 72  Training loss = 2.3980  Validation loss = 1.6450  \n",
      "\n",
      "Fold: 28  Epoch: 73  Training loss = 2.3966  Validation loss = 1.6306  \n",
      "\n",
      "Fold: 28  Epoch: 74  Training loss = 2.3955  Validation loss = 1.6299  \n",
      "\n",
      "Fold: 28  Epoch: 75  Training loss = 2.3941  Validation loss = 1.6273  \n",
      "\n",
      "Fold: 28  Epoch: 76  Training loss = 2.3929  Validation loss = 1.6279  \n",
      "\n",
      "Fold: 28  Epoch: 77  Training loss = 2.3927  Validation loss = 1.6384  \n",
      "\n",
      "Fold: 28  Epoch: 78  Training loss = 2.3912  Validation loss = 1.6346  \n",
      "\n",
      "Fold: 28  Epoch: 79  Training loss = 2.3900  Validation loss = 1.6303  \n",
      "\n",
      "Fold: 28  Epoch: 80  Training loss = 2.3890  Validation loss = 1.6226  \n",
      "\n",
      "Fold: 28  Epoch: 81  Training loss = 2.3877  Validation loss = 1.6269  \n",
      "\n",
      "Fold: 28  Epoch: 82  Training loss = 2.3868  Validation loss = 1.6230  \n",
      "\n",
      "Fold: 28  Epoch: 83  Training loss = 2.3862  Validation loss = 1.6182  \n",
      "\n",
      "Fold: 28  Epoch: 84  Training loss = 2.3859  Validation loss = 1.6312  \n",
      "\n",
      "Fold: 28  Epoch: 85  Training loss = 2.3845  Validation loss = 1.6241  \n",
      "\n",
      "Fold: 28  Epoch: 86  Training loss = 2.3837  Validation loss = 1.6237  \n",
      "\n",
      "Fold: 28  Epoch: 87  Training loss = 2.3826  Validation loss = 1.6195  \n",
      "\n",
      "Fold: 28  Epoch: 88  Training loss = 2.3816  Validation loss = 1.6095  \n",
      "\n",
      "Fold: 28  Epoch: 89  Training loss = 2.3812  Validation loss = 1.6063  \n",
      "\n",
      "Fold: 28  Epoch: 90  Training loss = 2.3809  Validation loss = 1.5993  \n",
      "\n",
      "Fold: 28  Epoch: 91  Training loss = 2.3810  Validation loss = 1.5971  \n",
      "\n",
      "Fold: 28  Epoch: 92  Training loss = 2.3776  Validation loss = 1.6092  \n",
      "\n",
      "Fold: 28  Epoch: 93  Training loss = 2.3763  Validation loss = 1.6085  \n",
      "\n",
      "Fold: 28  Epoch: 94  Training loss = 2.3751  Validation loss = 1.6083  \n",
      "\n",
      "Fold: 28  Epoch: 95  Training loss = 2.3746  Validation loss = 1.6000  \n",
      "\n",
      "Fold: 28  Epoch: 96  Training loss = 2.3739  Validation loss = 1.5972  \n",
      "\n",
      "Fold: 28  Epoch: 97  Training loss = 2.3734  Validation loss = 1.5916  \n",
      "\n",
      "Fold: 28  Epoch: 98  Training loss = 2.3717  Validation loss = 1.5952  \n",
      "\n",
      "Fold: 28  Epoch: 99  Training loss = 2.3705  Validation loss = 1.5960  \n",
      "\n",
      "Fold: 28  Epoch: 100  Training loss = 2.3691  Validation loss = 1.5966  \n",
      "\n",
      "Fold: 28  Epoch: 101  Training loss = 2.3679  Validation loss = 1.5915  \n",
      "\n",
      "Fold: 28  Epoch: 102  Training loss = 2.3673  Validation loss = 1.5892  \n",
      "\n",
      "Fold: 28  Epoch: 103  Training loss = 2.3666  Validation loss = 1.5914  \n",
      "\n",
      "Fold: 28  Epoch: 104  Training loss = 2.3653  Validation loss = 1.5948  \n",
      "\n",
      "Fold: 28  Epoch: 105  Training loss = 2.3636  Validation loss = 1.5961  \n",
      "\n",
      "Fold: 28  Epoch: 106  Training loss = 2.3630  Validation loss = 1.6013  \n",
      "\n",
      "Check model:  Fold: 28  Epoch: 102  Training loss = 2.3630  Validation loss = 1.6013  \n",
      "\n",
      "Fold: 29  Epoch: 1  Training loss = 2.3539  Validation loss = 2.5563  \n",
      "\n",
      "Fold: 29  Epoch: 2  Training loss = 2.3535  Validation loss = 2.5587  \n",
      "\n",
      "Fold: 29  Epoch: 3  Training loss = 2.3510  Validation loss = 2.5517  \n",
      "\n",
      "Fold: 29  Epoch: 4  Training loss = 2.3519  Validation loss = 2.5449  \n",
      "\n",
      "Fold: 29  Epoch: 5  Training loss = 2.3501  Validation loss = 2.5449  \n",
      "\n",
      "Fold: 29  Epoch: 6  Training loss = 2.3486  Validation loss = 2.5456  \n",
      "\n",
      "Fold: 29  Epoch: 7  Training loss = 2.3469  Validation loss = 2.5505  \n",
      "\n",
      "Fold: 29  Epoch: 8  Training loss = 2.3474  Validation loss = 2.5583  \n",
      "\n",
      "Fold: 29  Epoch: 9  Training loss = 2.3474  Validation loss = 2.5601  \n",
      "\n",
      "Fold: 29  Epoch: 10  Training loss = 2.3447  Validation loss = 2.5551  \n",
      "\n",
      "Fold: 29  Epoch: 11  Training loss = 2.3433  Validation loss = 2.5564  \n",
      "\n",
      "Fold: 29  Epoch: 12  Training loss = 2.3426  Validation loss = 2.5564  \n",
      "\n",
      "Fold: 29  Epoch: 13  Training loss = 2.3412  Validation loss = 2.5552  \n",
      "\n",
      "Fold: 29  Epoch: 14  Training loss = 2.3404  Validation loss = 2.5570  \n",
      "\n",
      "Fold: 29  Epoch: 15  Training loss = 2.3406  Validation loss = 2.5595  \n",
      "\n",
      "Fold: 29  Epoch: 16  Training loss = 2.3385  Validation loss = 2.5559  \n",
      "\n",
      "Fold: 29  Epoch: 17  Training loss = 2.3374  Validation loss = 2.5527  \n",
      "\n",
      "Fold: 29  Epoch: 18  Training loss = 2.3362  Validation loss = 2.5557  \n",
      "\n",
      "Fold: 29  Epoch: 19  Training loss = 2.3357  Validation loss = 2.5569  \n",
      "\n",
      "Fold: 29  Epoch: 20  Training loss = 2.3342  Validation loss = 2.5540  \n",
      "\n",
      "Fold: 29  Epoch: 21  Training loss = 2.3334  Validation loss = 2.5496  \n",
      "\n",
      "Fold: 29  Epoch: 22  Training loss = 2.3325  Validation loss = 2.5497  \n",
      "\n",
      "Fold: 29  Epoch: 23  Training loss = 2.3312  Validation loss = 2.5522  \n",
      "\n",
      "Fold: 29  Epoch: 24  Training loss = 2.3310  Validation loss = 2.5492  \n",
      "\n",
      "Fold: 29  Epoch: 25  Training loss = 2.3316  Validation loss = 2.5449  \n",
      "\n",
      "Fold: 29  Epoch: 26  Training loss = 2.3303  Validation loss = 2.5456  \n",
      "\n",
      "Fold: 29  Epoch: 27  Training loss = 2.3286  Validation loss = 2.5452  \n",
      "\n",
      "Fold: 29  Epoch: 28  Training loss = 2.3270  Validation loss = 2.5482  \n",
      "\n",
      "Fold: 29  Epoch: 29  Training loss = 2.3261  Validation loss = 2.5476  \n",
      "\n",
      "Fold: 29  Epoch: 30  Training loss = 2.3260  Validation loss = 2.5425  \n",
      "\n",
      "Fold: 29  Epoch: 31  Training loss = 2.3245  Validation loss = 2.5446  \n",
      "\n",
      "Fold: 29  Epoch: 32  Training loss = 2.3230  Validation loss = 2.5469  \n",
      "\n",
      "Fold: 29  Epoch: 33  Training loss = 2.3233  Validation loss = 2.5423  \n",
      "\n",
      "Fold: 29  Epoch: 34  Training loss = 2.3225  Validation loss = 2.5485  \n",
      "\n",
      "Check model:  Fold: 29  Epoch: 33  Training loss = 2.3225  Validation loss = 2.5485  \n",
      "\n",
      "Fold: 30  Epoch: 1  Training loss = 2.3841  Validation loss = 1.8049  \n",
      "\n",
      "Fold: 30  Epoch: 2  Training loss = 2.3856  Validation loss = 1.8086  \n",
      "\n",
      "Fold: 30  Epoch: 3  Training loss = 2.3822  Validation loss = 1.8095  \n",
      "\n",
      "Fold: 30  Epoch: 4  Training loss = 2.3811  Validation loss = 1.8063  \n",
      "\n",
      "Fold: 30  Epoch: 5  Training loss = 2.3801  Validation loss = 1.8072  \n",
      "\n",
      "Fold: 30  Epoch: 6  Training loss = 2.3800  Validation loss = 1.8030  \n",
      "\n",
      "Fold: 30  Epoch: 7  Training loss = 2.3778  Validation loss = 1.8026  \n",
      "\n",
      "Fold: 30  Epoch: 8  Training loss = 2.3771  Validation loss = 1.8003  \n",
      "\n",
      "Fold: 30  Epoch: 9  Training loss = 2.3766  Validation loss = 1.8001  \n",
      "\n",
      "Fold: 30  Epoch: 10  Training loss = 2.3756  Validation loss = 1.7985  \n",
      "\n",
      "Fold: 30  Epoch: 11  Training loss = 2.3751  Validation loss = 1.7927  \n",
      "\n",
      "Fold: 30  Epoch: 12  Training loss = 2.3751  Validation loss = 1.7932  \n",
      "\n",
      "Fold: 30  Epoch: 13  Training loss = 2.3731  Validation loss = 1.7947  \n",
      "\n",
      "Fold: 30  Epoch: 14  Training loss = 2.3725  Validation loss = 1.7918  \n",
      "\n",
      "Fold: 30  Epoch: 15  Training loss = 2.3707  Validation loss = 1.7909  \n",
      "\n",
      "Fold: 30  Epoch: 16  Training loss = 2.3698  Validation loss = 1.7892  \n",
      "\n",
      "Fold: 30  Epoch: 17  Training loss = 2.3688  Validation loss = 1.7847  \n",
      "\n",
      "Fold: 30  Epoch: 18  Training loss = 2.3683  Validation loss = 1.7838  \n",
      "\n",
      "Fold: 30  Epoch: 19  Training loss = 2.3679  Validation loss = 1.7835  \n",
      "\n",
      "Fold: 30  Epoch: 20  Training loss = 2.3666  Validation loss = 1.7822  \n",
      "\n",
      "Fold: 30  Epoch: 21  Training loss = 2.3677  Validation loss = 1.7822  \n",
      "\n",
      "Fold: 30  Epoch: 22  Training loss = 2.3645  Validation loss = 1.7799  \n",
      "\n",
      "Fold: 30  Epoch: 23  Training loss = 2.3636  Validation loss = 1.7779  \n",
      "\n",
      "Fold: 30  Epoch: 24  Training loss = 2.3623  Validation loss = 1.7762  \n",
      "\n",
      "Fold: 30  Epoch: 25  Training loss = 2.3618  Validation loss = 1.7769  \n",
      "\n",
      "Fold: 30  Epoch: 26  Training loss = 2.3612  Validation loss = 1.7786  \n",
      "\n",
      "Fold: 30  Epoch: 27  Training loss = 2.3604  Validation loss = 1.7764  \n",
      "\n",
      "Fold: 30  Epoch: 28  Training loss = 2.3594  Validation loss = 1.7747  \n",
      "\n",
      "Fold: 30  Epoch: 29  Training loss = 2.3586  Validation loss = 1.7745  \n",
      "\n",
      "Fold: 30  Epoch: 30  Training loss = 2.3583  Validation loss = 1.7721  \n",
      "\n",
      "Fold: 30  Epoch: 31  Training loss = 2.3576  Validation loss = 1.7746  \n",
      "\n",
      "Fold: 30  Epoch: 32  Training loss = 2.3569  Validation loss = 1.7772  \n",
      "\n",
      "Fold: 30  Epoch: 33  Training loss = 2.3565  Validation loss = 1.7759  \n",
      "\n",
      "Fold: 30  Epoch: 34  Training loss = 2.3550  Validation loss = 1.7740  \n",
      "\n",
      "Fold: 30  Epoch: 35  Training loss = 2.3544  Validation loss = 1.7739  \n",
      "\n",
      "Fold: 30  Epoch: 36  Training loss = 2.3543  Validation loss = 1.7739  \n",
      "\n",
      "Fold: 30  Epoch: 37  Training loss = 2.3525  Validation loss = 1.7695  \n",
      "\n",
      "Fold: 30  Epoch: 38  Training loss = 2.3518  Validation loss = 1.7659  \n",
      "\n",
      "Fold: 30  Epoch: 39  Training loss = 2.3509  Validation loss = 1.7649  \n",
      "\n",
      "Fold: 30  Epoch: 40  Training loss = 2.3503  Validation loss = 1.7574  \n",
      "\n",
      "Fold: 30  Epoch: 41  Training loss = 2.3491  Validation loss = 1.7622  \n",
      "\n",
      "Fold: 30  Epoch: 42  Training loss = 2.3482  Validation loss = 1.7609  \n",
      "\n",
      "Fold: 30  Epoch: 43  Training loss = 2.3475  Validation loss = 1.7596  \n",
      "\n",
      "Fold: 30  Epoch: 44  Training loss = 2.3469  Validation loss = 1.7614  \n",
      "\n",
      "Fold: 30  Epoch: 45  Training loss = 2.3462  Validation loss = 1.7614  \n",
      "\n",
      "Fold: 30  Epoch: 46  Training loss = 2.3459  Validation loss = 1.7608  \n",
      "\n",
      "Fold: 30  Epoch: 47  Training loss = 2.3444  Validation loss = 1.7600  \n",
      "\n",
      "Fold: 30  Epoch: 48  Training loss = 2.3438  Validation loss = 1.7592  \n",
      "\n",
      "Fold: 30  Epoch: 49  Training loss = 2.3436  Validation loss = 1.7568  \n",
      "\n",
      "Fold: 30  Epoch: 50  Training loss = 2.3431  Validation loss = 1.7550  \n",
      "\n",
      "Fold: 30  Epoch: 51  Training loss = 2.3412  Validation loss = 1.7540  \n",
      "\n",
      "Fold: 30  Epoch: 52  Training loss = 2.3402  Validation loss = 1.7535  \n",
      "\n",
      "Fold: 30  Epoch: 53  Training loss = 2.3392  Validation loss = 1.7523  \n",
      "\n",
      "Fold: 30  Epoch: 54  Training loss = 2.3385  Validation loss = 1.7506  \n",
      "\n",
      "Fold: 30  Epoch: 55  Training loss = 2.3380  Validation loss = 1.7505  \n",
      "\n",
      "Fold: 30  Epoch: 56  Training loss = 2.3369  Validation loss = 1.7497  \n",
      "\n",
      "Fold: 30  Epoch: 57  Training loss = 2.3363  Validation loss = 1.7511  \n",
      "\n",
      "Fold: 30  Epoch: 58  Training loss = 2.3360  Validation loss = 1.7522  \n",
      "\n",
      "Fold: 30  Epoch: 59  Training loss = 2.3346  Validation loss = 1.7510  \n",
      "\n",
      "Fold: 30  Epoch: 60  Training loss = 2.3350  Validation loss = 1.7476  \n",
      "\n",
      "Fold: 30  Epoch: 61  Training loss = 2.3333  Validation loss = 1.7431  \n",
      "\n",
      "Fold: 30  Epoch: 62  Training loss = 2.3348  Validation loss = 1.7435  \n",
      "\n",
      "Fold: 30  Epoch: 63  Training loss = 2.3334  Validation loss = 1.7415  \n",
      "\n",
      "Fold: 30  Epoch: 64  Training loss = 2.3312  Validation loss = 1.7393  \n",
      "\n",
      "Fold: 30  Epoch: 65  Training loss = 2.3302  Validation loss = 1.7389  \n",
      "\n",
      "Fold: 30  Epoch: 66  Training loss = 2.3297  Validation loss = 1.7409  \n",
      "\n",
      "Fold: 30  Epoch: 67  Training loss = 2.3286  Validation loss = 1.7421  \n",
      "\n",
      "Fold: 30  Epoch: 68  Training loss = 2.3280  Validation loss = 1.7436  \n",
      "\n",
      "Fold: 30  Epoch: 69  Training loss = 2.3275  Validation loss = 1.7423  \n",
      "\n",
      "Fold: 30  Epoch: 70  Training loss = 2.3270  Validation loss = 1.7479  \n",
      "\n",
      "Check model:  Fold: 30  Epoch: 65  Training loss = 2.3270  Validation loss = 1.7479  \n",
      "\n",
      "Fold: 31  Epoch: 1  Training loss = 2.2310  Validation loss = 1.4250  \n",
      "\n",
      "Fold: 31  Epoch: 2  Training loss = 2.2298  Validation loss = 1.4207  \n",
      "\n",
      "Fold: 31  Epoch: 3  Training loss = 2.2288  Validation loss = 1.4263  \n",
      "\n",
      "Fold: 31  Epoch: 4  Training loss = 2.2325  Validation loss = 1.4615  \n",
      "\n",
      "Fold: 31  Epoch: 5  Training loss = 2.2272  Validation loss = 1.4280  \n",
      "\n",
      "Fold: 31  Epoch: 6  Training loss = 2.2273  Validation loss = 1.4372  \n",
      "\n",
      "Fold: 31  Epoch: 7  Training loss = 2.2267  Validation loss = 1.4422  \n",
      "\n",
      "Fold: 31  Epoch: 8  Training loss = 2.2243  Validation loss = 1.4215  \n",
      "\n",
      "Fold: 31  Epoch: 9  Training loss = 2.2235  Validation loss = 1.4164  \n",
      "\n",
      "Fold: 31  Epoch: 10  Training loss = 2.2222  Validation loss = 1.3925  \n",
      "\n",
      "Fold: 31  Epoch: 11  Training loss = 2.2205  Validation loss = 1.4065  \n",
      "\n",
      "Fold: 31  Epoch: 12  Training loss = 2.2196  Validation loss = 1.3857  \n",
      "\n",
      "Fold: 31  Epoch: 13  Training loss = 2.2186  Validation loss = 1.3655  \n",
      "\n",
      "Fold: 31  Epoch: 14  Training loss = 2.2190  Validation loss = 1.3496  \n",
      "\n",
      "Fold: 31  Epoch: 15  Training loss = 2.2162  Validation loss = 1.3549  \n",
      "\n",
      "Fold: 31  Epoch: 16  Training loss = 2.2169  Validation loss = 1.3405  \n",
      "\n",
      "Fold: 31  Epoch: 17  Training loss = 2.2143  Validation loss = 1.3598  \n",
      "\n",
      "Fold: 31  Epoch: 18  Training loss = 2.2135  Validation loss = 1.3492  \n",
      "\n",
      "Fold: 31  Epoch: 19  Training loss = 2.2129  Validation loss = 1.3447  \n",
      "\n",
      "Fold: 31  Epoch: 20  Training loss = 2.2114  Validation loss = 1.3716  \n",
      "\n",
      "Fold: 31  Epoch: 21  Training loss = 2.2117  Validation loss = 1.3884  \n",
      "\n",
      "Check model:  Fold: 31  Epoch: 16  Training loss = 2.2117  Validation loss = 1.3884  \n",
      "\n",
      "Fold: 32  Epoch: 1  Training loss = 1.9058  Validation loss = 3.0035  \n",
      "\n",
      "Fold: 32  Epoch: 2  Training loss = 1.9037  Validation loss = 2.9805  \n",
      "\n",
      "Fold: 32  Epoch: 3  Training loss = 1.9018  Validation loss = 2.9770  \n",
      "\n",
      "Fold: 32  Epoch: 4  Training loss = 1.9013  Validation loss = 2.9830  \n",
      "\n",
      "Fold: 32  Epoch: 5  Training loss = 1.8999  Validation loss = 2.9310  \n",
      "\n",
      "Fold: 32  Epoch: 6  Training loss = 1.9006  Validation loss = 2.9012  \n",
      "\n",
      "Fold: 32  Epoch: 7  Training loss = 1.8972  Validation loss = 2.9225  \n",
      "\n",
      "Fold: 32  Epoch: 8  Training loss = 1.8947  Validation loss = 2.9254  \n",
      "\n",
      "Fold: 32  Epoch: 9  Training loss = 1.8943  Validation loss = 2.9483  \n",
      "\n",
      "Fold: 32  Epoch: 10  Training loss = 1.8931  Validation loss = 2.9637  \n",
      "\n",
      "Fold: 32  Epoch: 11  Training loss = 1.8912  Validation loss = 2.9062  \n",
      "\n",
      "Fold: 32  Epoch: 12  Training loss = 1.8894  Validation loss = 2.9179  \n",
      "\n",
      "Fold: 32  Epoch: 13  Training loss = 1.8886  Validation loss = 2.9286  \n",
      "\n",
      "Fold: 32  Epoch: 14  Training loss = 1.8875  Validation loss = 2.9007  \n",
      "\n",
      "Fold: 32  Epoch: 15  Training loss = 1.8857  Validation loss = 2.9157  \n",
      "\n",
      "Fold: 32  Epoch: 16  Training loss = 1.8846  Validation loss = 2.9443  \n",
      "\n",
      "Fold: 32  Epoch: 17  Training loss = 1.8828  Validation loss = 2.9310  \n",
      "\n",
      "Fold: 32  Epoch: 18  Training loss = 1.8812  Validation loss = 2.8997  \n",
      "\n",
      "Fold: 32  Epoch: 19  Training loss = 1.8801  Validation loss = 2.8693  \n",
      "\n",
      "Fold: 32  Epoch: 20  Training loss = 1.8779  Validation loss = 2.9006  \n",
      "\n",
      "Fold: 32  Epoch: 21  Training loss = 1.8789  Validation loss = 2.9557  \n",
      "\n",
      "Check model:  Fold: 32  Epoch: 19  Training loss = 1.8789  Validation loss = 2.9557  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 2. Train model\n",
    "# ==================================\n",
    "sess = tf.InteractiveSession()  # Launch Graph\n",
    "sess.run(tf.global_variables_initializer())  # Initialise all variables\n",
    "\n",
    "print(\"Start training\", \n",
    "      \"\\nHyperparameters:\",\n",
    "      \"\\nDimension of recurrent unit =\", n_hidden,\n",
    "      \"\\nLearning rate =\", learning_rate,\n",
    "      \"\\nEpochs =\", epochs,\n",
    "      \"\\nBatch size =\", batch_size,\n",
    "      \"\\nEarly stopping epochs =\", early_stop_iters,\n",
    "      \"\\nLearning rate =\", learning_rate)\n",
    "\n",
    "total_batch = int(window_length / batch_size)\n",
    "validation_fold_error = [] # store validation error of each fold\n",
    "optimal_epochs = []\n",
    "\n",
    "# loop through folds\n",
    "for fold in range(1, len(valIndex)):\n",
    "    validx = train_features[valIndex[fold-1]:valIndex[fold]]\n",
    "    validy = train_target[valIndex[fold-1]:valIndex[fold]]\n",
    "    trainx = train_features[(fold-1)*4:valIndex[(fold-1)]]\n",
    "    trainy = train_target[(fold-1)*4:valIndex[(fold-1)]]\n",
    "\n",
    "    loss_list = [] # store validation loss after each epoch for early stopping\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i in range(total_batch):\n",
    "            # Backprop\n",
    "            batch_xs, batch_ys = next_batch(num=batch_size, data=trainx, labels=trainy)\n",
    "            optimizer.run(feed_dict={x:batch_xs, y:batch_ys, lr:learning_rate})\n",
    "\n",
    "        # Loss\n",
    "        loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "        loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "        loss_list.append(loss_valid)\n",
    "\n",
    "        print(\"Fold: {0:d}\".format(fold),\n",
    "              \" Epoch: {0:d}\".format(epoch+1),\n",
    "              \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "              \" Validation loss = {0:.4f}\".format(np.sqrt(loss_valid)),\n",
    "              \" \\n\")\n",
    "\n",
    "        if all(j <= loss_valid for j in loss_list[-early_stop_iters:]) and len(loss_list)>early_stop_iters:\n",
    "            break\n",
    "    \n",
    "    # Load model with lowest validation error for each fold\n",
    "    epoch_hat = np.argmin(loss_list) + 1\n",
    "    optimal_epochs.append(epoch_hat) # store optimal number of epochs for each fold\n",
    "    \n",
    "    # RMSE\n",
    "    loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "    loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "    validation_fold_error.append(np.sqrt(loss_valid))\n",
    "    \n",
    "    print(\"Check model:\",\n",
    "          \" Fold: {0:d}\".format(fold),\n",
    "          \" Epoch: {0:d}\".format(epoch_hat),\n",
    "          \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "          \" Validation loss = {0:.4f}\".format(np.sqrt(loss_valid)),\n",
    "          \" \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average number of epochs: 170\n",
      "Average validation error: 2.89472\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 3. Optimal epoch choice\n",
    "# ==================================\n",
    "# Pick number of epochs to train model for out-of-sample testing\n",
    "epoch_hat = int(np.mean(optimal_epochs))\n",
    "print(\"\\nAverage number of epochs:\", epoch_hat)\n",
    "# Average validation error\n",
    "print(\"Average validation error:\", np.mean(validation_fold_error))\n",
    "\n",
    "# Save validated model\n",
    "saveModel(sess, \n",
    "          MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + str(epoch_hat) + \"_validated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fixed scheme:\n",
      "Epoch: 1  Training loss = 1.8905  Test loss = 2.9856  \n",
      "\n",
      "Epoch: 2  Training loss = 1.8889  Test loss = 2.9803  \n",
      "\n",
      "Epoch: 3  Training loss = 1.8874  Test loss = 2.9752  \n",
      "\n",
      "Epoch: 4  Training loss = 1.8860  Test loss = 2.9703  \n",
      "\n",
      "Epoch: 5  Training loss = 1.8846  Test loss = 2.9657  \n",
      "\n",
      "Epoch: 6  Training loss = 1.8833  Test loss = 2.9612  \n",
      "\n",
      "Epoch: 7  Training loss = 1.8820  Test loss = 2.9569  \n",
      "\n",
      "Epoch: 8  Training loss = 1.8808  Test loss = 2.9527  \n",
      "\n",
      "Epoch: 9  Training loss = 1.8796  Test loss = 2.9487  \n",
      "\n",
      "Epoch: 10  Training loss = 1.8784  Test loss = 2.9448  \n",
      "\n",
      "Epoch: 11  Training loss = 1.8773  Test loss = 2.9411  \n",
      "\n",
      "Epoch: 12  Training loss = 1.8762  Test loss = 2.9374  \n",
      "\n",
      "Epoch: 13  Training loss = 1.8752  Test loss = 2.9339  \n",
      "\n",
      "Epoch: 14  Training loss = 1.8741  Test loss = 2.9305  \n",
      "\n",
      "Epoch: 15  Training loss = 1.8731  Test loss = 2.9272  \n",
      "\n",
      "Epoch: 16  Training loss = 1.8722  Test loss = 2.9240  \n",
      "\n",
      "Epoch: 17  Training loss = 1.8712  Test loss = 2.9209  \n",
      "\n",
      "Epoch: 18  Training loss = 1.8703  Test loss = 2.9178  \n",
      "\n",
      "Epoch: 19  Training loss = 1.8694  Test loss = 2.9149  \n",
      "\n",
      "Epoch: 20  Training loss = 1.8685  Test loss = 2.9120  \n",
      "\n",
      "Epoch: 21  Training loss = 1.8676  Test loss = 2.9092  \n",
      "\n",
      "Epoch: 22  Training loss = 1.8667  Test loss = 2.9064  \n",
      "\n",
      "Epoch: 23  Training loss = 1.8659  Test loss = 2.9038  \n",
      "\n",
      "Epoch: 24  Training loss = 1.8650  Test loss = 2.9012  \n",
      "\n",
      "Epoch: 25  Training loss = 1.8642  Test loss = 2.8986  \n",
      "\n",
      "Epoch: 26  Training loss = 1.8634  Test loss = 2.8961  \n",
      "\n",
      "Epoch: 27  Training loss = 1.8626  Test loss = 2.8937  \n",
      "\n",
      "Epoch: 28  Training loss = 1.8618  Test loss = 2.8913  \n",
      "\n",
      "Epoch: 29  Training loss = 1.8610  Test loss = 2.8890  \n",
      "\n",
      "Epoch: 30  Training loss = 1.8603  Test loss = 2.8867  \n",
      "\n",
      "Epoch: 31  Training loss = 1.8595  Test loss = 2.8845  \n",
      "\n",
      "Epoch: 32  Training loss = 1.8588  Test loss = 2.8823  \n",
      "\n",
      "Epoch: 33  Training loss = 1.8580  Test loss = 2.8802  \n",
      "\n",
      "Epoch: 34  Training loss = 1.8573  Test loss = 2.8781  \n",
      "\n",
      "Epoch: 35  Training loss = 1.8566  Test loss = 2.8760  \n",
      "\n",
      "Epoch: 36  Training loss = 1.8559  Test loss = 2.8740  \n",
      "\n",
      "Epoch: 37  Training loss = 1.8552  Test loss = 2.8720  \n",
      "\n",
      "Epoch: 38  Training loss = 1.8545  Test loss = 2.8700  \n",
      "\n",
      "Epoch: 39  Training loss = 1.8538  Test loss = 2.8681  \n",
      "\n",
      "Epoch: 40  Training loss = 1.8531  Test loss = 2.8662  \n",
      "\n",
      "Epoch: 41  Training loss = 1.8525  Test loss = 2.8644  \n",
      "\n",
      "Epoch: 42  Training loss = 1.8518  Test loss = 2.8626  \n",
      "\n",
      "Epoch: 43  Training loss = 1.8512  Test loss = 2.8608  \n",
      "\n",
      "Epoch: 44  Training loss = 1.8505  Test loss = 2.8590  \n",
      "\n",
      "Epoch: 45  Training loss = 1.8499  Test loss = 2.8573  \n",
      "\n",
      "Epoch: 46  Training loss = 1.8493  Test loss = 2.8556  \n",
      "\n",
      "Epoch: 47  Training loss = 1.8486  Test loss = 2.8539  \n",
      "\n",
      "Epoch: 48  Training loss = 1.8480  Test loss = 2.8522  \n",
      "\n",
      "Epoch: 49  Training loss = 1.8474  Test loss = 2.8506  \n",
      "\n",
      "Epoch: 50  Training loss = 1.8468  Test loss = 2.8490  \n",
      "\n",
      "Epoch: 51  Training loss = 1.8462  Test loss = 2.8474  \n",
      "\n",
      "Epoch: 52  Training loss = 1.8456  Test loss = 2.8458  \n",
      "\n",
      "Epoch: 53  Training loss = 1.8450  Test loss = 2.8443  \n",
      "\n",
      "Epoch: 54  Training loss = 1.8444  Test loss = 2.8428  \n",
      "\n",
      "Epoch: 55  Training loss = 1.8439  Test loss = 2.8413  \n",
      "\n",
      "Epoch: 56  Training loss = 1.8433  Test loss = 2.8398  \n",
      "\n",
      "Epoch: 57  Training loss = 1.8427  Test loss = 2.8383  \n",
      "\n",
      "Epoch: 58  Training loss = 1.8422  Test loss = 2.8369  \n",
      "\n",
      "Epoch: 59  Training loss = 1.8416  Test loss = 2.8354  \n",
      "\n",
      "Epoch: 60  Training loss = 1.8411  Test loss = 2.8340  \n",
      "\n",
      "Epoch: 61  Training loss = 1.8405  Test loss = 2.8326  \n",
      "\n",
      "Epoch: 62  Training loss = 1.8400  Test loss = 2.8313  \n",
      "\n",
      "Epoch: 63  Training loss = 1.8394  Test loss = 2.8299  \n",
      "\n",
      "Epoch: 64  Training loss = 1.8389  Test loss = 2.8285  \n",
      "\n",
      "Epoch: 65  Training loss = 1.8384  Test loss = 2.8272  \n",
      "\n",
      "Epoch: 66  Training loss = 1.8378  Test loss = 2.8259  \n",
      "\n",
      "Epoch: 67  Training loss = 1.8373  Test loss = 2.8246  \n",
      "\n",
      "Epoch: 68  Training loss = 1.8368  Test loss = 2.8233  \n",
      "\n",
      "Epoch: 69  Training loss = 1.8363  Test loss = 2.8220  \n",
      "\n",
      "Epoch: 70  Training loss = 1.8358  Test loss = 2.8208  \n",
      "\n",
      "Epoch: 71  Training loss = 1.8353  Test loss = 2.8195  \n",
      "\n",
      "Epoch: 72  Training loss = 1.8348  Test loss = 2.8183  \n",
      "\n",
      "Epoch: 73  Training loss = 1.8343  Test loss = 2.8170  \n",
      "\n",
      "Epoch: 74  Training loss = 1.8338  Test loss = 2.8158  \n",
      "\n",
      "Epoch: 75  Training loss = 1.8333  Test loss = 2.8146  \n",
      "\n",
      "Epoch: 76  Training loss = 1.8328  Test loss = 2.8134  \n",
      "\n",
      "Epoch: 77  Training loss = 1.8323  Test loss = 2.8122  \n",
      "\n",
      "Epoch: 78  Training loss = 1.8319  Test loss = 2.8111  \n",
      "\n",
      "Epoch: 79  Training loss = 1.8314  Test loss = 2.8099  \n",
      "\n",
      "Epoch: 80  Training loss = 1.8309  Test loss = 2.8088  \n",
      "\n",
      "Epoch: 81  Training loss = 1.8304  Test loss = 2.8076  \n",
      "\n",
      "Epoch: 82  Training loss = 1.8300  Test loss = 2.8065  \n",
      "\n",
      "Epoch: 83  Training loss = 1.8295  Test loss = 2.8054  \n",
      "\n",
      "Epoch: 84  Training loss = 1.8291  Test loss = 2.8043  \n",
      "\n",
      "Epoch: 85  Training loss = 1.8286  Test loss = 2.8031  \n",
      "\n",
      "Epoch: 86  Training loss = 1.8281  Test loss = 2.8021  \n",
      "\n",
      "Epoch: 87  Training loss = 1.8277  Test loss = 2.8010  \n",
      "\n",
      "Epoch: 88  Training loss = 1.8272  Test loss = 2.7999  \n",
      "\n",
      "Epoch: 89  Training loss = 1.8268  Test loss = 2.7988  \n",
      "\n",
      "Epoch: 90  Training loss = 1.8264  Test loss = 2.7978  \n",
      "\n",
      "Epoch: 91  Training loss = 1.8259  Test loss = 2.7967  \n",
      "\n",
      "Epoch: 92  Training loss = 1.8255  Test loss = 2.7957  \n",
      "\n",
      "Epoch: 93  Training loss = 1.8250  Test loss = 2.7946  \n",
      "\n",
      "Epoch: 94  Training loss = 1.8246  Test loss = 2.7936  \n",
      "\n",
      "Epoch: 95  Training loss = 1.8242  Test loss = 2.7926  \n",
      "\n",
      "Epoch: 96  Training loss = 1.8238  Test loss = 2.7916  \n",
      "\n",
      "Epoch: 97  Training loss = 1.8233  Test loss = 2.7905  \n",
      "\n",
      "Epoch: 98  Training loss = 1.8229  Test loss = 2.7895  \n",
      "\n",
      "Epoch: 99  Training loss = 1.8225  Test loss = 2.7886  \n",
      "\n",
      "Epoch: 100  Training loss = 1.8221  Test loss = 2.7876  \n",
      "\n",
      "Epoch: 101  Training loss = 1.8217  Test loss = 2.7866  \n",
      "\n",
      "Epoch: 102  Training loss = 1.8212  Test loss = 2.7856  \n",
      "\n",
      "Epoch: 103  Training loss = 1.8208  Test loss = 2.7846  \n",
      "\n",
      "Epoch: 104  Training loss = 1.8204  Test loss = 2.7837  \n",
      "\n",
      "Epoch: 105  Training loss = 1.8200  Test loss = 2.7827  \n",
      "\n",
      "Epoch: 106  Training loss = 1.8196  Test loss = 2.7818  \n",
      "\n",
      "Epoch: 107  Training loss = 1.8192  Test loss = 2.7808  \n",
      "\n",
      "Epoch: 108  Training loss = 1.8188  Test loss = 2.7799  \n",
      "\n",
      "Epoch: 109  Training loss = 1.8184  Test loss = 2.7790  \n",
      "\n",
      "Epoch: 110  Training loss = 1.8180  Test loss = 2.7780  \n",
      "\n",
      "Epoch: 111  Training loss = 1.8176  Test loss = 2.7771  \n",
      "\n",
      "Epoch: 112  Training loss = 1.8172  Test loss = 2.7762  \n",
      "\n",
      "Epoch: 113  Training loss = 1.8168  Test loss = 2.7753  \n",
      "\n",
      "Epoch: 114  Training loss = 1.8164  Test loss = 2.7744  \n",
      "\n",
      "Epoch: 115  Training loss = 1.8161  Test loss = 2.7735  \n",
      "\n",
      "Epoch: 116  Training loss = 1.8157  Test loss = 2.7726  \n",
      "\n",
      "Epoch: 117  Training loss = 1.8153  Test loss = 2.7717  \n",
      "\n",
      "Epoch: 118  Training loss = 1.8149  Test loss = 2.7709  \n",
      "\n",
      "Epoch: 119  Training loss = 1.8145  Test loss = 2.7700  \n",
      "\n",
      "Epoch: 120  Training loss = 1.8141  Test loss = 2.7691  \n",
      "\n",
      "Epoch: 121  Training loss = 1.8138  Test loss = 2.7682  \n",
      "\n",
      "Epoch: 122  Training loss = 1.8134  Test loss = 2.7674  \n",
      "\n",
      "Epoch: 123  Training loss = 1.8130  Test loss = 2.7665  \n",
      "\n",
      "Epoch: 124  Training loss = 1.8126  Test loss = 2.7657  \n",
      "\n",
      "Epoch: 125  Training loss = 1.8123  Test loss = 2.7648  \n",
      "\n",
      "Epoch: 126  Training loss = 1.8119  Test loss = 2.7640  \n",
      "\n",
      "Epoch: 127  Training loss = 1.8115  Test loss = 2.7632  \n",
      "\n",
      "Epoch: 128  Training loss = 1.8112  Test loss = 2.7623  \n",
      "\n",
      "Epoch: 129  Training loss = 1.8108  Test loss = 2.7615  \n",
      "\n",
      "Epoch: 130  Training loss = 1.8104  Test loss = 2.7607  \n",
      "\n",
      "Epoch: 131  Training loss = 1.8101  Test loss = 2.7599  \n",
      "\n",
      "Epoch: 132  Training loss = 1.8097  Test loss = 2.7591  \n",
      "\n",
      "Epoch: 133  Training loss = 1.8094  Test loss = 2.7583  \n",
      "\n",
      "Epoch: 134  Training loss = 1.8090  Test loss = 2.7575  \n",
      "\n",
      "Epoch: 135  Training loss = 1.8086  Test loss = 2.7567  \n",
      "\n",
      "Epoch: 136  Training loss = 1.8083  Test loss = 2.7559  \n",
      "\n",
      "Epoch: 137  Training loss = 1.8079  Test loss = 2.7551  \n",
      "\n",
      "Epoch: 138  Training loss = 1.8076  Test loss = 2.7543  \n",
      "\n",
      "Epoch: 139  Training loss = 1.8072  Test loss = 2.7536  \n",
      "\n",
      "Epoch: 140  Training loss = 1.8069  Test loss = 2.7528  \n",
      "\n",
      "Epoch: 141  Training loss = 1.8065  Test loss = 2.7520  \n",
      "\n",
      "Epoch: 142  Training loss = 1.8062  Test loss = 2.7513  \n",
      "\n",
      "Epoch: 143  Training loss = 1.8058  Test loss = 2.7505  \n",
      "\n",
      "Epoch: 144  Training loss = 1.8055  Test loss = 2.7497  \n",
      "\n",
      "Epoch: 145  Training loss = 1.8052  Test loss = 2.7490  \n",
      "\n",
      "Epoch: 146  Training loss = 1.8048  Test loss = 2.7483  \n",
      "\n",
      "Epoch: 147  Training loss = 1.8045  Test loss = 2.7475  \n",
      "\n",
      "Epoch: 148  Training loss = 1.8041  Test loss = 2.7468  \n",
      "\n",
      "Epoch: 149  Training loss = 1.8038  Test loss = 2.7460  \n",
      "\n",
      "Epoch: 150  Training loss = 1.8035  Test loss = 2.7453  \n",
      "\n",
      "Epoch: 151  Training loss = 1.8031  Test loss = 2.7446  \n",
      "\n",
      "Epoch: 152  Training loss = 1.8028  Test loss = 2.7439  \n",
      "\n",
      "Epoch: 153  Training loss = 1.8025  Test loss = 2.7432  \n",
      "\n",
      "Epoch: 154  Training loss = 1.8021  Test loss = 2.7425  \n",
      "\n",
      "Epoch: 155  Training loss = 1.8018  Test loss = 2.7418  \n",
      "\n",
      "Epoch: 156  Training loss = 1.8015  Test loss = 2.7411  \n",
      "\n",
      "Epoch: 157  Training loss = 1.8011  Test loss = 2.7404  \n",
      "\n",
      "Epoch: 158  Training loss = 1.8008  Test loss = 2.7397  \n",
      "\n",
      "Epoch: 159  Training loss = 1.8005  Test loss = 2.7390  \n",
      "\n",
      "Epoch: 160  Training loss = 1.8002  Test loss = 2.7383  \n",
      "\n",
      "Epoch: 161  Training loss = 1.7998  Test loss = 2.7376  \n",
      "\n",
      "Epoch: 162  Training loss = 1.7995  Test loss = 2.7369  \n",
      "\n",
      "Epoch: 163  Training loss = 1.7992  Test loss = 2.7363  \n",
      "\n",
      "Epoch: 164  Training loss = 1.7989  Test loss = 2.7356  \n",
      "\n",
      "Epoch: 165  Training loss = 1.7986  Test loss = 2.7349  \n",
      "\n",
      "Epoch: 166  Training loss = 1.7983  Test loss = 2.7343  \n",
      "\n",
      "Epoch: 167  Training loss = 1.7979  Test loss = 2.7336  \n",
      "\n",
      "Epoch: 168  Training loss = 1.7976  Test loss = 2.7330  \n",
      "\n",
      "Epoch: 169  Training loss = 1.7973  Test loss = 2.7323  \n",
      "\n",
      "Epoch: 170  Training loss = 1.7970  Test loss = 2.7317  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 4. Fixed scheme\n",
    "# ==================================\n",
    "print(\"\\nFixed scheme:\")\n",
    "for epoch in range(epoch_hat):\n",
    "    x_train = train_features[-window_length:]\n",
    "    y_train = train_target[-window_length:]\n",
    "    optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:test_features, y:test_target})\n",
    "    print(\"Epoch: {0:d}\".format(epoch+1),\n",
    "          \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "          \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "          \" \\n\")\n",
    "\n",
    "# Forecasts\n",
    "yhat_test_fixed = pred.eval(feed_dict={x:test_features})\n",
    "yhat_train_fixed = pred.eval(feed_dict={x:x_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x48b8208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train set\n",
    "plt.plot(y_train, 'black')\n",
    "plt.plot(yhat_train_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGDNaYW80Go0xoxX2RqPRGDP+Bu/INItkkC3BAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xcc23f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: fixed scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_test_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed scheme RMSE: 2.73170125531 \n",
      "Fixed scheme MAE:  1.92920057884\n"
     ]
    }
   ],
   "source": [
    "rmse_fixed = np.sqrt(np.mean((yhat_test_fixed[:,0]-test_target)**2))\n",
    "mae_fixed = np.mean(np.abs((yhat_test_fixed[:,0]-test_target)))\n",
    "print(\"Fixed scheme RMSE:\", rmse_fixed,\n",
    "     \"\\nFixed scheme MAE: \", mae_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Stack training and test set, this makes updating scheme easier to train\n",
    "all_features = np.concatenate((train_features[-window_length:], test_features), axis=0)\n",
    "all_target = np.concatenate((train_target[-window_length:], test_target), axis=0)\n",
    "\n",
    "# Vectors to store loss and forecasts\n",
    "test_loss = np.zeros(len(test_target))\n",
    "yhat_update = np.zeros(len(test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test period = 1  Training loss = 1.7970  Test loss = 3.5613  Model updated 0 times  \n",
      "\n",
      "Test period = 2  Training loss = 1.8504  Test loss = 2.9938  Model updated 0 times  \n",
      "\n",
      "Test period = 3  Training loss = 1.8554  Test loss = 0.6428  Model updated 0 times  \n",
      "\n",
      "Test period = 4  Training loss = 1.8469  Test loss = 0.5559  Model updated 0 times  \n",
      "\n",
      "Test period = 5  Training loss = 1.6121  Test loss = 0.3529  Model updated 1 times  \n",
      "\n",
      "Test period = 6  Training loss = 1.4945  Test loss = 1.1797  Model updated 1 times  \n",
      "\n",
      "Test period = 7  Training loss = 1.4701  Test loss = 1.6437  Model updated 1 times  \n",
      "\n",
      "Test period = 8  Training loss = 1.4793  Test loss = 1.9254  Model updated 1 times  \n",
      "\n",
      "Test period = 9  Training loss = 1.4114  Test loss = 2.5459  Model updated 2 times  \n",
      "\n",
      "Test period = 10  Training loss = 1.4396  Test loss = 1.0257  Model updated 2 times  \n",
      "\n",
      "Test period = 11  Training loss = 1.4078  Test loss = 0.9731  Model updated 2 times  \n",
      "\n",
      "Test period = 12  Training loss = 1.4121  Test loss = 0.8882  Model updated 2 times  \n",
      "\n",
      "Test period = 13  Training loss = 1.3064  Test loss = 0.3052  Model updated 3 times  \n",
      "\n",
      "Test period = 14  Training loss = 1.3035  Test loss = 1.2474  Model updated 3 times  \n",
      "\n",
      "Test period = 15  Training loss = 1.3094  Test loss = 2.8383  Model updated 3 times  \n",
      "\n",
      "Test period = 16  Training loss = 1.3546  Test loss = 4.4541  Model updated 3 times  \n",
      "\n",
      "Test period = 17  Training loss = 1.3864  Test loss = 2.9886  Model updated 4 times  \n",
      "\n",
      "Test period = 18  Training loss = 1.4351  Test loss = 0.1395  Model updated 4 times  \n",
      "\n",
      "Test period = 19  Training loss = 1.4351  Test loss = 0.0497  Model updated 4 times  \n",
      "\n",
      "Test period = 20  Training loss = 1.3569  Test loss = 0.8351  Model updated 4 times  \n",
      "\n",
      "Test period = 21  Training loss = 1.3013  Test loss = 2.2021  Model updated 5 times  \n",
      "\n",
      "Test period = 22  Training loss = 1.3197  Test loss = 3.1415  Model updated 5 times  \n",
      "\n",
      "Test period = 23  Training loss = 1.3717  Test loss = 0.4936  Model updated 5 times  \n",
      "\n",
      "Test period = 24  Training loss = 1.3710  Test loss = 0.9737  Model updated 5 times  \n",
      "\n",
      "Test period = 25  Training loss = 1.3394  Test loss = 0.5249  Model updated 6 times  \n",
      "\n",
      "Test period = 26  Training loss = 1.3380  Test loss = 0.8922  Model updated 6 times  \n",
      "\n",
      "Test period = 27  Training loss = 1.3417  Test loss = 0.8074  Model updated 6 times  \n",
      "\n",
      "Test period = 28  Training loss = 1.3383  Test loss = 1.8133  Model updated 6 times  \n",
      "\n",
      "Test period = 29  Training loss = 1.3042  Test loss = 0.3202  Model updated 7 times  \n",
      "\n",
      "Test period = 30  Training loss = 1.2981  Test loss = 0.0319  Model updated 7 times  \n",
      "\n",
      "Test period = 31  Training loss = 1.2933  Test loss = 3.6111  Model updated 7 times  \n",
      "\n",
      "Test period = 32  Training loss = 1.3291  Test loss = 1.1350  Model updated 7 times  \n",
      "\n",
      "Test period = 33  Training loss = 1.2955  Test loss = 0.2976  Model updated 8 times  \n",
      "\n",
      "Test period = 34  Training loss = 1.2940  Test loss = 0.9991  Model updated 8 times  \n",
      "\n",
      "Test period = 35  Training loss = 1.2622  Test loss = 1.4703  Model updated 8 times  \n",
      "\n",
      "Test period = 36  Training loss = 1.2744  Test loss = 4.3124  Model updated 8 times  \n",
      "\n",
      "Test period = 37  Training loss = 1.3050  Test loss = 1.5587  Model updated 9 times  \n",
      "\n",
      "Test period = 38  Training loss = 1.2380  Test loss = 1.7473  Model updated 9 times  \n",
      "\n",
      "Test period = 39  Training loss = 1.2566  Test loss = 0.2354  Model updated 9 times  \n",
      "\n",
      "Test period = 40  Training loss = 1.2532  Test loss = 2.4930  Model updated 9 times  \n",
      "\n",
      "Test period = 41  Training loss = 1.2679  Test loss = 1.6487  Model updated 10 times  \n",
      "\n",
      "Test period = 42  Training loss = 1.2839  Test loss = 2.1098  Model updated 10 times  \n",
      "\n",
      "Test period = 43  Training loss = 1.3103  Test loss = 3.7777  Model updated 10 times  \n",
      "\n",
      "Test period = 44  Training loss = 1.3899  Test loss = 11.8641  Model updated 10 times  \n",
      "\n",
      "Test period = 45  Training loss = 2.0390  Test loss = 5.5458  Model updated 11 times  \n",
      "\n",
      "Test period = 46  Training loss = 2.1515  Test loss = 0.8783  Model updated 11 times  \n",
      "\n",
      "Test period = 47  Training loss = 2.1542  Test loss = 0.2015  Model updated 11 times  \n",
      "\n",
      "Test period = 48  Training loss = 2.1542  Test loss = 0.2661  Model updated 11 times  \n",
      "\n",
      "Test period = 49  Training loss = 2.0702  Test loss = 2.1794  Model updated 12 times  \n",
      "\n",
      "Test period = 50  Training loss = 2.0830  Test loss = 3.3052  Model updated 12 times  \n",
      "\n",
      "Test period = 51  Training loss = 2.1221  Test loss = 1.3906  Model updated 12 times  \n",
      "\n",
      "Test period = 52  Training loss = 2.1277  Test loss = 0.9141  Model updated 12 times  \n",
      "\n",
      "Test period = 53  Training loss = 2.0779  Test loss = 1.0607  Model updated 13 times  \n",
      "\n",
      "Test period = 54  Training loss = 2.0817  Test loss = 2.2295  Model updated 13 times  \n",
      "\n",
      "Test period = 55  Training loss = 2.0995  Test loss = 0.2423  Model updated 13 times  \n",
      "\n",
      "Test period = 56  Training loss = 2.0986  Test loss = 0.8766  Model updated 13 times  \n",
      "\n",
      "Test period = 57  Training loss = 2.0657  Test loss = 0.1506  Model updated 14 times  \n",
      "\n",
      "Test period = 58  Training loss = 2.0651  Test loss = 1.0620  Model updated 14 times  \n",
      "\n",
      "Test period = 59  Training loss = 2.0680  Test loss = 0.8385  Model updated 14 times  \n",
      "\n",
      "Test period = 60  Training loss = 2.0696  Test loss = 0.0952  Model updated 14 times  \n",
      "\n",
      "Test period = 61  Training loss = 2.0487  Test loss = 1.0406  Model updated 15 times  \n",
      "\n",
      "Test period = 62  Training loss = 2.0514  Test loss = 2.6048  Model updated 15 times  \n",
      "\n",
      "Test period = 63  Training loss = 2.0765  Test loss = 0.4633  Model updated 15 times  \n",
      "\n",
      "Test period = 64  Training loss = 2.0757  Test loss = 1.0220  Model updated 15 times  \n",
      "\n",
      "Test period = 65  Training loss = 2.0574  Test loss = 0.3787  Model updated 16 times  \n",
      "\n",
      "Test period = 66  Training loss = 2.0579  Test loss = 0.3013  Model updated 16 times  \n",
      "\n",
      "Test period = 67  Training loss = 2.0493  Test loss = 0.1744  Model updated 16 times  \n",
      "\n",
      "Test period = 68  Training loss = 2.0433  Test loss = 3.0516  Model updated 16 times  \n",
      "\n",
      "Test period = 69  Training loss = 2.0600  Test loss = 4.2220  Model updated 17 times  \n",
      "\n",
      "Test period = 70  Training loss = 2.1223  Test loss = 0.2984  Model updated 17 times  \n",
      "\n",
      "Test period = 71  Training loss = 2.1159  Test loss = 0.6427  Model updated 17 times  \n",
      "\n",
      "Test period = 72  Training loss = 2.1169  Test loss = 2.5996  Model updated 17 times  \n",
      "\n",
      "Test period = 73  Training loss = 2.1172  Test loss = 2.3420  Model updated 18 times  \n",
      "\n",
      "Test period = 74  Training loss = 2.1370  Test loss = 0.3939  Model updated 18 times  \n",
      "\n",
      "Test period = 75  Training loss = 2.1328  Test loss = 0.4660  Model updated 18 times  \n",
      "\n",
      "Test period = 76  Training loss = 2.1270  Test loss = 1.1724  Model updated 18 times  \n",
      "\n",
      "Test period = 77  Training loss = 2.0863  Test loss = 1.2336  Model updated 19 times  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "retrain_count = 0\n",
    "for t in range(len(test_target)):\n",
    "    x_test = np.reshape(test_features[t], newshape=(1,4,3))\n",
    "    y_test = test_target[t]\n",
    "    test_loss[t] = np.sqrt(sess.run(loss, feed_dict={x:x_test, y:y_test}))\n",
    "    yhat_update[t] = pred.eval(feed_dict={x:x_test})\n",
    "\n",
    "    x_train = all_features[t:(window_length+t)]\n",
    "    y_train = all_target[t:(window_length+t)]\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:x_test, y:y_test})\n",
    "    \n",
    "    print(\"Test period = {0:d}\".format(t+1),\n",
    "      \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "      \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "      \" Model updated {0:d} times\".format(retrain_count),\n",
    "      \" \\n\")\n",
    "\n",
    "    if (t+1)%4==0:\n",
    "        retrain_count += 1\n",
    "        for epoch in range(epoch_hat):\n",
    "            for i in range(total_batch):\n",
    "                optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd6281d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: updating scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_update, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating scheme RMSE: 2.33915735961 \n",
      "Updating scheme MAE:  1.60066257729\n"
     ]
    }
   ],
   "source": [
    "rmse_update = np.sqrt(np.mean((yhat_update-test_target)**2))\n",
    "mae_update = np.mean(np.abs((yhat_update-test_target)))\n",
    "print(\"Updating scheme RMSE:\", rmse_update,\n",
    "     \"\\nUpdating scheme MAE: \", mae_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + \"yhat_test_fixed.csv\", yhat_test_fixed)\n",
    "np.savetxt(MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + \"yhat_update.csv\", yhat_update)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
