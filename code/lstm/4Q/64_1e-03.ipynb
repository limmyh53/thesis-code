{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Directories\n",
    "MODEL_FOLDER = \"../../../models/lstm/\"\n",
    "MODEL_FILENAME = MODEL_FOLDER + \"4Q/64_units/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: model saver\n",
    "def saveModel(sess, MODEL_FILENAME):\n",
    "    if not os.path.exists(MODEL_FOLDER):\n",
    "        print('Creating path where to save model: ' + MODEL_FOLDER)\n",
    "        os.mkdir(MODEL_FOLDER)\n",
    "\n",
    "    #print('Saving model at: ' + MODEL_FILENAME)\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, MODEL_FILENAME)\n",
    "    #print('Model successfully saved.\\n')\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: model loader\n",
    "def loadModel(sess, MODEL_FILENAME):\n",
    "    if os.path.exists(MODEL_FILENAME + \".index\"):\n",
    "        print('Loading save model from: ' + MODEL_FILENAME)\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, MODEL_FILENAME)\n",
    "        print('Model successfully loaded.\\n')\n",
    "        return True\n",
    "    else:\n",
    "        print('Model file <<' + MODEL_FILENAME + '>> does not exists!')\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Hyperparameters\n",
    "epochs = 500\n",
    "learning_rate = 1e-3\n",
    "batch_size = 5\n",
    "early_stop_iters = 10\n",
    "folds = 32\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 3  # data input\n",
    "n_steps = 4  # timesteps\n",
    "n_hidden = 64 # dimension of recurrent unit\n",
    "\n",
    "# (REPRODUCIBILITY) set random seeds\n",
    "tf.set_random_seed(123)\n",
    "\n",
    "# Define weights and biases\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.truncated_normal([n_hidden, 1], stddev = 1.0 / tf.sqrt(float(n_hidden))),\n",
    "        name='out_weight')\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.zeros([1]),\n",
    "        name='out_bias')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: Build model\n",
    "def RNN(X, weights, biases, n_hidden):\n",
    "\n",
    "    # Define a LSTM cell with tensorflow\n",
    "    lstm_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden, state_is_tuple=True)\n",
    "    outputs, _ = tf.nn.dynamic_rnn(lstm_cell, X, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    out_layer = tf.matmul(outputs[:,-1,:], weights['out']) + biases['out']\n",
    "\n",
    "    return out_layer\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: select batch\n",
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the data...\n",
      "Finished: data loaded. Stats below: \n",
      "Nr of training samples: 193\n",
      "Nr of testing  samples: 77\n",
      "Number of variables: 3\n",
      "Number of lags: 4\n",
      "Window length: 65\n",
      "Number of validation folds: 32\n"
     ]
    }
   ],
   "source": [
    "# =================================\n",
    "# 0. Load dataset\n",
    "# =================================\n",
    "print(\"Loading the data...\")\n",
    "# Training set pre-processing\n",
    "train = pd.read_csv('../../../Data/train.csv')\n",
    "train_4lag_inflation = np.array(train[['inflation.lag4',\n",
    "                                       'inflation.lag5',\n",
    "                                       'inflation.lag6',\n",
    "                                       'inflation.lag7']])\n",
    "train_4lag_unemp = np.array(train[['unemp.lag4',\n",
    "                                   'unemp.lag5',\n",
    "                                   'unemp.lag6',\n",
    "                                   'unemp.lag7']])\n",
    "train_4lag_oil = np.array(train[['oil.lag4',\n",
    "                                 'oil.lag5',\n",
    "                                 'oil.lag6',\n",
    "                                 'oil.lag7']])\n",
    "train_features = np.concatenate((train_4lag_inflation[:,:,np.newaxis], \n",
    "\t                             train_4lag_unemp[:,:,np.newaxis],\n",
    "\t                             train_4lag_oil[:,:,np.newaxis]),\n",
    "\t                             axis=2)\n",
    "train_target = np.array(train['inflation.target'])\n",
    "\n",
    "# Test set pre-processing\n",
    "test = pd.read_csv('../../../Data/test.csv')\n",
    "test_4lag_inflation = np.array(test[['inflation.lag4',\n",
    "                                     'inflation.lag5',\n",
    "                                     'inflation.lag6',\n",
    "                                     'inflation.lag7']])\n",
    "test_4lag_unemp = np.array(test[['unemp.lag4',\n",
    "                                 'unemp.lag5',\n",
    "                                 'unemp.lag6',\n",
    "                                 'unemp.lag7']])\n",
    "test_4lag_oil = np.array(test[['oil.lag4',\n",
    "                               'oil.lag5',\n",
    "                               'oil.lag6',\n",
    "                               'oil.lag7']])\n",
    "test_features = np.concatenate((test_4lag_inflation[:,:,np.newaxis], \n",
    "\t                            test_4lag_unemp[:,:,np.newaxis],\n",
    "\t                            test_4lag_oil[:,:,np.newaxis]),\n",
    "\t                            axis=2)\n",
    "test_target = np.array(test['inflation.target'])\n",
    "\n",
    "(nrTrainSamples, timesteps, variables) = train_features.shape\n",
    "(nrTestSamples, _, _) = test_features.shape\n",
    "\n",
    "# Window length and validation fold index\n",
    "window_length = 65\n",
    "valIndex = np.linspace(start=window_length, stop=nrTrainSamples, \n",
    "                       endpoint=True, num=folds+1, dtype=np.int)\n",
    "\n",
    "print(\"Finished: data loaded. Stats below: \")\n",
    "print(\"Nr of training samples: %d\" % nrTrainSamples)\n",
    "print(\"Nr of testing  samples: %d\" % nrTestSamples)\n",
    "print(\"Number of variables: %d\" % variables)\n",
    "print(\"Number of lags: %d\" % timesteps)\n",
    "print(\"Window length: %d\" % window_length)\n",
    "print(\"Number of validation folds: %d\" % folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 1. Build model\n",
    "# ==================================\n",
    "# tf graph input\n",
    "x = tf.placeholder(\"float\", [None, n_steps, n_input], name='Batch')\n",
    "y = tf.placeholder(\"float\", name='True_labels_of_batch')\n",
    "lr = tf.placeholder(\"float\", name='Learning_rate')\n",
    "\n",
    "# Make predictions with the model\n",
    "pred = RNN(x, weights, biases, n_hidden)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss = tf.reduce_mean(tf.diag_part(tf.square(tf.subtract(x=pred, y=y))))\n",
    "optimizer = tf.train.GradientDescentOptimizer(lr).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training \n",
      "Hyperparameters: \n",
      "Dimension of recurrent unit = 64 \n",
      "Learning rate = 0.001 \n",
      "Epochs = 500 \n",
      "Batch size = 5 \n",
      "Early stopping epochs = 10 \n",
      "Learning rate = 0.001\n",
      "Fold: 1  Epoch: 1  Training loss = 3.1229  Validation loss = 3.1991  \n",
      "\n",
      "Fold: 1  Epoch: 2  Training loss = 2.9559  Validation loss = 2.8565  \n",
      "\n",
      "Fold: 1  Epoch: 3  Training loss = 2.8774  Validation loss = 2.6688  \n",
      "\n",
      "Fold: 1  Epoch: 4  Training loss = 2.7915  Validation loss = 2.4286  \n",
      "\n",
      "Fold: 1  Epoch: 5  Training loss = 2.7199  Validation loss = 2.2142  \n",
      "\n",
      "Fold: 1  Epoch: 6  Training loss = 2.6610  Validation loss = 1.9704  \n",
      "\n",
      "Fold: 1  Epoch: 7  Training loss = 2.6408  Validation loss = 1.8883  \n",
      "\n",
      "Fold: 1  Epoch: 8  Training loss = 2.6259  Validation loss = 1.8328  \n",
      "\n",
      "Fold: 1  Epoch: 9  Training loss = 2.6069  Validation loss = 1.7337  \n",
      "\n",
      "Fold: 1  Epoch: 10  Training loss = 2.6021  Validation loss = 1.6634  \n",
      "\n",
      "Fold: 1  Epoch: 11  Training loss = 2.5958  Validation loss = 1.7003  \n",
      "\n",
      "Fold: 1  Epoch: 12  Training loss = 2.5830  Validation loss = 1.6180  \n",
      "\n",
      "Fold: 1  Epoch: 13  Training loss = 2.5740  Validation loss = 1.6133  \n",
      "\n",
      "Fold: 1  Epoch: 14  Training loss = 2.5672  Validation loss = 1.6080  \n",
      "\n",
      "Fold: 1  Epoch: 15  Training loss = 2.5646  Validation loss = 1.6162  \n",
      "\n",
      "Fold: 1  Epoch: 16  Training loss = 2.5621  Validation loss = 1.6105  \n",
      "\n",
      "Fold: 1  Epoch: 17  Training loss = 2.5632  Validation loss = 1.7561  \n",
      "\n",
      "Fold: 1  Epoch: 18  Training loss = 2.5588  Validation loss = 1.7436  \n",
      "\n",
      "Fold: 1  Epoch: 19  Training loss = 2.5557  Validation loss = 1.7623  \n",
      "\n",
      "Check model:  Fold: 1  Epoch: 14  Training loss = 2.5557  Validation loss = 1.7623  \n",
      "\n",
      "Fold: 2  Epoch: 1  Training loss = 2.4547  Validation loss = 2.0731  \n",
      "\n",
      "Fold: 2  Epoch: 2  Training loss = 2.4538  Validation loss = 2.0625  \n",
      "\n",
      "Fold: 2  Epoch: 3  Training loss = 2.4496  Validation loss = 2.0377  \n",
      "\n",
      "Fold: 2  Epoch: 4  Training loss = 2.4491  Validation loss = 2.0274  \n",
      "\n",
      "Fold: 2  Epoch: 5  Training loss = 2.4448  Validation loss = 2.0093  \n",
      "\n",
      "Fold: 2  Epoch: 6  Training loss = 2.4419  Validation loss = 1.9944  \n",
      "\n",
      "Fold: 2  Epoch: 7  Training loss = 2.4386  Validation loss = 2.0402  \n",
      "\n",
      "Fold: 2  Epoch: 8  Training loss = 2.4370  Validation loss = 1.9922  \n",
      "\n",
      "Fold: 2  Epoch: 9  Training loss = 2.4320  Validation loss = 2.0197  \n",
      "\n",
      "Fold: 2  Epoch: 10  Training loss = 2.4270  Validation loss = 2.0429  \n",
      "\n",
      "Fold: 2  Epoch: 11  Training loss = 2.4230  Validation loss = 2.0597  \n",
      "\n",
      "Fold: 2  Epoch: 12  Training loss = 2.4207  Validation loss = 2.0904  \n",
      "\n",
      "Check model:  Fold: 2  Epoch: 8  Training loss = 2.4207  Validation loss = 2.0904  \n",
      "\n",
      "Fold: 3  Epoch: 1  Training loss = 1.5240  Validation loss = 3.3619  \n",
      "\n",
      "Fold: 3  Epoch: 2  Training loss = 1.5115  Validation loss = 3.3881  \n",
      "\n",
      "Fold: 3  Epoch: 3  Training loss = 1.5080  Validation loss = 3.4616  \n",
      "\n",
      "Fold: 3  Epoch: 4  Training loss = 1.5038  Validation loss = 3.4048  \n",
      "\n",
      "Fold: 3  Epoch: 5  Training loss = 1.4981  Validation loss = 3.4460  \n",
      "\n",
      "Fold: 3  Epoch: 6  Training loss = 1.4947  Validation loss = 3.4504  \n",
      "\n",
      "Fold: 3  Epoch: 7  Training loss = 1.4893  Validation loss = 3.4075  \n",
      "\n",
      "Fold: 3  Epoch: 8  Training loss = 1.4869  Validation loss = 3.3884  \n",
      "\n",
      "Fold: 3  Epoch: 9  Training loss = 1.4829  Validation loss = 3.3150  \n",
      "\n",
      "Fold: 3  Epoch: 10  Training loss = 1.4800  Validation loss = 3.2898  \n",
      "\n",
      "Fold: 3  Epoch: 11  Training loss = 1.4770  Validation loss = 3.3123  \n",
      "\n",
      "Fold: 3  Epoch: 12  Training loss = 1.4758  Validation loss = 3.2808  \n",
      "\n",
      "Fold: 3  Epoch: 13  Training loss = 1.4727  Validation loss = 3.2892  \n",
      "\n",
      "Fold: 3  Epoch: 14  Training loss = 1.4754  Validation loss = 3.2124  \n",
      "\n",
      "Fold: 3  Epoch: 15  Training loss = 1.4698  Validation loss = 3.2463  \n",
      "\n",
      "Fold: 3  Epoch: 16  Training loss = 1.4663  Validation loss = 3.2666  \n",
      "\n",
      "Fold: 3  Epoch: 17  Training loss = 1.4646  Validation loss = 3.2773  \n",
      "\n",
      "Fold: 3  Epoch: 18  Training loss = 1.4636  Validation loss = 3.3329  \n",
      "\n",
      "Check model:  Fold: 3  Epoch: 14  Training loss = 1.4636  Validation loss = 3.3329  \n",
      "\n",
      "Fold: 4  Epoch: 1  Training loss = 1.5753  Validation loss = 4.4654  \n",
      "\n",
      "Fold: 4  Epoch: 2  Training loss = 1.5676  Validation loss = 4.3976  \n",
      "\n",
      "Fold: 4  Epoch: 3  Training loss = 1.5658  Validation loss = 4.3980  \n",
      "\n",
      "Fold: 4  Epoch: 4  Training loss = 1.5612  Validation loss = 4.3780  \n",
      "\n",
      "Fold: 4  Epoch: 5  Training loss = 1.5648  Validation loss = 4.4387  \n",
      "\n",
      "Fold: 4  Epoch: 6  Training loss = 1.5613  Validation loss = 4.4197  \n",
      "\n",
      "Fold: 4  Epoch: 7  Training loss = 1.5577  Validation loss = 4.4047  \n",
      "\n",
      "Fold: 4  Epoch: 8  Training loss = 1.5598  Validation loss = 4.4287  \n",
      "\n",
      "Fold: 4  Epoch: 9  Training loss = 1.5492  Validation loss = 4.3501  \n",
      "\n",
      "Fold: 4  Epoch: 10  Training loss = 1.5447  Validation loss = 4.3153  \n",
      "\n",
      "Fold: 4  Epoch: 11  Training loss = 1.5395  Validation loss = 4.2682  \n",
      "\n",
      "Fold: 4  Epoch: 12  Training loss = 1.5390  Validation loss = 4.2750  \n",
      "\n",
      "Fold: 4  Epoch: 13  Training loss = 1.5363  Validation loss = 4.2477  \n",
      "\n",
      "Fold: 4  Epoch: 14  Training loss = 1.5340  Validation loss = 4.2392  \n",
      "\n",
      "Fold: 4  Epoch: 15  Training loss = 1.5309  Validation loss = 4.2076  \n",
      "\n",
      "Fold: 4  Epoch: 16  Training loss = 1.5302  Validation loss = 4.2192  \n",
      "\n",
      "Fold: 4  Epoch: 17  Training loss = 1.5299  Validation loss = 4.2300  \n",
      "\n",
      "Fold: 4  Epoch: 18  Training loss = 1.5300  Validation loss = 4.2419  \n",
      "\n",
      "Fold: 4  Epoch: 19  Training loss = 1.5272  Validation loss = 4.2186  \n",
      "\n",
      "Fold: 4  Epoch: 20  Training loss = 1.5209  Validation loss = 4.1458  \n",
      "\n",
      "Fold: 4  Epoch: 21  Training loss = 1.5163  Validation loss = 4.0787  \n",
      "\n",
      "Fold: 4  Epoch: 22  Training loss = 1.5138  Validation loss = 4.0442  \n",
      "\n",
      "Fold: 4  Epoch: 23  Training loss = 1.5129  Validation loss = 3.9883  \n",
      "\n",
      "Fold: 4  Epoch: 24  Training loss = 1.5104  Validation loss = 4.0241  \n",
      "\n",
      "Fold: 4  Epoch: 25  Training loss = 1.5108  Validation loss = 4.1050  \n",
      "\n",
      "Fold: 4  Epoch: 26  Training loss = 1.5106  Validation loss = 4.1175  \n",
      "\n",
      "Fold: 4  Epoch: 27  Training loss = 1.5060  Validation loss = 4.0628  \n",
      "\n",
      "Fold: 4  Epoch: 28  Training loss = 1.5020  Validation loss = 4.0013  \n",
      "\n",
      "Fold: 4  Epoch: 29  Training loss = 1.5011  Validation loss = 3.9812  \n",
      "\n",
      "Fold: 4  Epoch: 30  Training loss = 1.4991  Validation loss = 4.0236  \n",
      "\n",
      "Fold: 4  Epoch: 31  Training loss = 1.4961  Validation loss = 3.9948  \n",
      "\n",
      "Fold: 4  Epoch: 32  Training loss = 1.4940  Validation loss = 3.9245  \n",
      "\n",
      "Fold: 4  Epoch: 33  Training loss = 1.4964  Validation loss = 3.8404  \n",
      "\n",
      "Fold: 4  Epoch: 34  Training loss = 1.4930  Validation loss = 3.8277  \n",
      "\n",
      "Fold: 4  Epoch: 35  Training loss = 1.4882  Validation loss = 3.8761  \n",
      "\n",
      "Fold: 4  Epoch: 36  Training loss = 1.4882  Validation loss = 3.7996  \n",
      "\n",
      "Fold: 4  Epoch: 37  Training loss = 1.4867  Validation loss = 3.7834  \n",
      "\n",
      "Fold: 4  Epoch: 38  Training loss = 1.4832  Validation loss = 3.7940  \n",
      "\n",
      "Fold: 4  Epoch: 39  Training loss = 1.4803  Validation loss = 3.8267  \n",
      "\n",
      "Fold: 4  Epoch: 40  Training loss = 1.4792  Validation loss = 3.7890  \n",
      "\n",
      "Fold: 4  Epoch: 41  Training loss = 1.4745  Validation loss = 3.8336  \n",
      "\n",
      "Fold: 4  Epoch: 42  Training loss = 1.4701  Validation loss = 3.8708  \n",
      "\n",
      "Fold: 4  Epoch: 43  Training loss = 1.4686  Validation loss = 3.8879  \n",
      "\n",
      "Check model:  Fold: 4  Epoch: 37  Training loss = 1.4686  Validation loss = 3.8879  \n",
      "\n",
      "Fold: 5  Epoch: 1  Training loss = 1.6856  Validation loss = 4.0144  \n",
      "\n",
      "Fold: 5  Epoch: 2  Training loss = 1.6713  Validation loss = 3.9574  \n",
      "\n",
      "Fold: 5  Epoch: 3  Training loss = 1.6495  Validation loss = 3.7956  \n",
      "\n",
      "Fold: 5  Epoch: 4  Training loss = 1.6462  Validation loss = 3.8608  \n",
      "\n",
      "Fold: 5  Epoch: 5  Training loss = 1.6309  Validation loss = 3.7293  \n",
      "\n",
      "Fold: 5  Epoch: 6  Training loss = 1.6204  Validation loss = 3.6683  \n",
      "\n",
      "Fold: 5  Epoch: 7  Training loss = 1.6096  Validation loss = 3.5778  \n",
      "\n",
      "Fold: 5  Epoch: 8  Training loss = 1.5984  Validation loss = 3.6302  \n",
      "\n",
      "Fold: 5  Epoch: 9  Training loss = 1.5888  Validation loss = 3.5719  \n",
      "\n",
      "Fold: 5  Epoch: 10  Training loss = 1.5796  Validation loss = 3.5723  \n",
      "\n",
      "Fold: 5  Epoch: 11  Training loss = 1.5712  Validation loss = 3.5357  \n",
      "\n",
      "Fold: 5  Epoch: 12  Training loss = 1.5717  Validation loss = 3.6010  \n",
      "\n",
      "Fold: 5  Epoch: 13  Training loss = 1.5652  Validation loss = 3.5843  \n",
      "\n",
      "Fold: 5  Epoch: 14  Training loss = 1.5465  Validation loss = 3.4864  \n",
      "\n",
      "Fold: 5  Epoch: 15  Training loss = 1.5408  Validation loss = 3.4641  \n",
      "\n",
      "Fold: 5  Epoch: 16  Training loss = 1.5332  Validation loss = 3.4552  \n",
      "\n",
      "Fold: 5  Epoch: 17  Training loss = 1.5237  Validation loss = 3.4295  \n",
      "\n",
      "Fold: 5  Epoch: 18  Training loss = 1.5096  Validation loss = 3.2855  \n",
      "\n",
      "Fold: 5  Epoch: 19  Training loss = 1.5067  Validation loss = 3.1744  \n",
      "\n",
      "Fold: 5  Epoch: 20  Training loss = 1.4892  Validation loss = 3.1417  \n",
      "\n",
      "Fold: 5  Epoch: 21  Training loss = 1.4848  Validation loss = 3.0925  \n",
      "\n",
      "Fold: 5  Epoch: 22  Training loss = 1.4700  Validation loss = 3.1186  \n",
      "\n",
      "Fold: 5  Epoch: 23  Training loss = 1.4648  Validation loss = 3.1134  \n",
      "\n",
      "Fold: 5  Epoch: 24  Training loss = 1.4678  Validation loss = 3.1888  \n",
      "\n",
      "Fold: 5  Epoch: 25  Training loss = 1.4517  Validation loss = 3.1145  \n",
      "\n",
      "Fold: 5  Epoch: 26  Training loss = 1.4467  Validation loss = 3.1400  \n",
      "\n",
      "Fold: 5  Epoch: 27  Training loss = 1.4369  Validation loss = 2.9496  \n",
      "\n",
      "Fold: 5  Epoch: 28  Training loss = 1.4250  Validation loss = 3.0626  \n",
      "\n",
      "Fold: 5  Epoch: 29  Training loss = 1.4195  Validation loss = 3.0818  \n",
      "\n",
      "Fold: 5  Epoch: 30  Training loss = 1.4114  Validation loss = 3.0553  \n",
      "\n",
      "Fold: 5  Epoch: 31  Training loss = 1.4094  Validation loss = 2.9478  \n",
      "\n",
      "Fold: 5  Epoch: 32  Training loss = 1.3958  Validation loss = 3.0567  \n",
      "\n",
      "Fold: 5  Epoch: 33  Training loss = 1.3880  Validation loss = 2.9209  \n",
      "\n",
      "Fold: 5  Epoch: 34  Training loss = 1.3807  Validation loss = 2.9450  \n",
      "\n",
      "Fold: 5  Epoch: 35  Training loss = 1.3909  Validation loss = 3.0584  \n",
      "\n",
      "Fold: 5  Epoch: 36  Training loss = 1.3827  Validation loss = 3.0225  \n",
      "\n",
      "Fold: 5  Epoch: 37  Training loss = 1.3733  Validation loss = 2.9623  \n",
      "\n",
      "Fold: 5  Epoch: 38  Training loss = 1.3606  Validation loss = 2.8837  \n",
      "\n",
      "Fold: 5  Epoch: 39  Training loss = 1.3544  Validation loss = 2.7830  \n",
      "\n",
      "Fold: 5  Epoch: 40  Training loss = 1.3507  Validation loss = 2.7856  \n",
      "\n",
      "Fold: 5  Epoch: 41  Training loss = 1.3464  Validation loss = 2.7308  \n",
      "\n",
      "Fold: 5  Epoch: 42  Training loss = 1.3397  Validation loss = 2.6764  \n",
      "\n",
      "Fold: 5  Epoch: 43  Training loss = 1.3341  Validation loss = 2.7169  \n",
      "\n",
      "Fold: 5  Epoch: 44  Training loss = 1.3402  Validation loss = 2.8371  \n",
      "\n",
      "Fold: 5  Epoch: 45  Training loss = 1.3268  Validation loss = 2.7515  \n",
      "\n",
      "Fold: 5  Epoch: 46  Training loss = 1.3229  Validation loss = 2.7866  \n",
      "\n",
      "Fold: 5  Epoch: 47  Training loss = 1.3140  Validation loss = 2.6843  \n",
      "\n",
      "Fold: 5  Epoch: 48  Training loss = 1.3079  Validation loss = 2.6335  \n",
      "\n",
      "Fold: 5  Epoch: 49  Training loss = 1.3071  Validation loss = 2.5612  \n",
      "\n",
      "Fold: 5  Epoch: 50  Training loss = 1.3010  Validation loss = 2.6056  \n",
      "\n",
      "Fold: 5  Epoch: 51  Training loss = 1.3008  Validation loss = 2.5510  \n",
      "\n",
      "Fold: 5  Epoch: 52  Training loss = 1.2991  Validation loss = 2.5006  \n",
      "\n",
      "Fold: 5  Epoch: 53  Training loss = 1.2879  Validation loss = 2.5310  \n",
      "\n",
      "Fold: 5  Epoch: 54  Training loss = 1.2840  Validation loss = 2.5693  \n",
      "\n",
      "Fold: 5  Epoch: 55  Training loss = 1.2815  Validation loss = 2.5651  \n",
      "\n",
      "Fold: 5  Epoch: 56  Training loss = 1.2765  Validation loss = 2.4971  \n",
      "\n",
      "Fold: 5  Epoch: 57  Training loss = 1.2733  Validation loss = 2.4736  \n",
      "\n",
      "Fold: 5  Epoch: 58  Training loss = 1.2705  Validation loss = 2.3722  \n",
      "\n",
      "Fold: 5  Epoch: 59  Training loss = 1.2704  Validation loss = 2.6554  \n",
      "\n",
      "Check model:  Fold: 5  Epoch: 58  Training loss = 1.2704  Validation loss = 2.6554  \n",
      "\n",
      "Fold: 6  Epoch: 1  Training loss = 1.3433  Validation loss = 1.0174  \n",
      "\n",
      "Fold: 6  Epoch: 2  Training loss = 1.3301  Validation loss = 1.0060  \n",
      "\n",
      "Fold: 6  Epoch: 3  Training loss = 1.3277  Validation loss = 1.0279  \n",
      "\n",
      "Fold: 6  Epoch: 4  Training loss = 1.3185  Validation loss = 0.9872  \n",
      "\n",
      "Fold: 6  Epoch: 5  Training loss = 1.3011  Validation loss = 0.9866  \n",
      "\n",
      "Fold: 6  Epoch: 6  Training loss = 1.2864  Validation loss = 0.9736  \n",
      "\n",
      "Fold: 6  Epoch: 7  Training loss = 1.2793  Validation loss = 0.9038  \n",
      "\n",
      "Fold: 6  Epoch: 8  Training loss = 1.2645  Validation loss = 0.9427  \n",
      "\n",
      "Fold: 6  Epoch: 9  Training loss = 1.2604  Validation loss = 0.9240  \n",
      "\n",
      "Fold: 6  Epoch: 10  Training loss = 1.2547  Validation loss = 0.9814  \n",
      "\n",
      "Fold: 6  Epoch: 11  Training loss = 1.2473  Validation loss = 0.9117  \n",
      "\n",
      "Fold: 6  Epoch: 12  Training loss = 1.2510  Validation loss = 0.8764  \n",
      "\n",
      "Fold: 6  Epoch: 13  Training loss = 1.2556  Validation loss = 0.8755  \n",
      "\n",
      "Fold: 6  Epoch: 14  Training loss = 1.2342  Validation loss = 1.0205  \n",
      "\n",
      "Check model:  Fold: 6  Epoch: 13  Training loss = 1.2342  Validation loss = 1.0205  \n",
      "\n",
      "Fold: 7  Epoch: 1  Training loss = 1.2329  Validation loss = 1.3908  \n",
      "\n",
      "Fold: 7  Epoch: 2  Training loss = 1.2282  Validation loss = 1.3647  \n",
      "\n",
      "Fold: 7  Epoch: 3  Training loss = 1.2231  Validation loss = 1.3850  \n",
      "\n",
      "Fold: 7  Epoch: 4  Training loss = 1.2195  Validation loss = 1.4417  \n",
      "\n",
      "Fold: 7  Epoch: 5  Training loss = 1.2259  Validation loss = 1.5376  \n",
      "\n",
      "Fold: 7  Epoch: 6  Training loss = 1.2224  Validation loss = 1.5783  \n",
      "\n",
      "Fold: 7  Epoch: 7  Training loss = 1.2094  Validation loss = 1.4927  \n",
      "\n",
      "Fold: 7  Epoch: 8  Training loss = 1.2083  Validation loss = 1.5628  \n",
      "\n",
      "Fold: 7  Epoch: 9  Training loss = 1.2042  Validation loss = 1.5538  \n",
      "\n",
      "Fold: 7  Epoch: 10  Training loss = 1.1994  Validation loss = 1.5296  \n",
      "\n",
      "Fold: 7  Epoch: 11  Training loss = 1.1968  Validation loss = 1.5176  \n",
      "\n",
      "Fold: 7  Epoch: 12  Training loss = 1.1910  Validation loss = 1.4804  \n",
      "\n",
      "Fold: 7  Epoch: 13  Training loss = 1.1882  Validation loss = 1.5075  \n",
      "\n",
      "Fold: 7  Epoch: 14  Training loss = 1.1885  Validation loss = 1.4949  \n",
      "\n",
      "Fold: 7  Epoch: 15  Training loss = 1.1823  Validation loss = 1.5256  \n",
      "\n",
      "Fold: 7  Epoch: 16  Training loss = 1.1838  Validation loss = 1.5852  \n",
      "\n",
      "Check model:  Fold: 7  Epoch: 2  Training loss = 1.1838  Validation loss = 1.5852  \n",
      "\n",
      "Fold: 8  Epoch: 1  Training loss = 1.1644  Validation loss = 6.2737  \n",
      "\n",
      "Fold: 8  Epoch: 2  Training loss = 1.1616  Validation loss = 6.4487  \n",
      "\n",
      "Fold: 8  Epoch: 3  Training loss = 1.1612  Validation loss = 6.4239  \n",
      "\n",
      "Fold: 8  Epoch: 4  Training loss = 1.1557  Validation loss = 6.4215  \n",
      "\n",
      "Fold: 8  Epoch: 5  Training loss = 1.1528  Validation loss = 6.3445  \n",
      "\n",
      "Fold: 8  Epoch: 6  Training loss = 1.1495  Validation loss = 6.3946  \n",
      "\n",
      "Fold: 8  Epoch: 7  Training loss = 1.1492  Validation loss = 6.3244  \n",
      "\n",
      "Fold: 8  Epoch: 8  Training loss = 1.1443  Validation loss = 6.3790  \n",
      "\n",
      "Fold: 8  Epoch: 9  Training loss = 1.1482  Validation loss = 6.2597  \n",
      "\n",
      "Fold: 8  Epoch: 10  Training loss = 1.1401  Validation loss = 6.4105  \n",
      "\n",
      "Fold: 8  Epoch: 11  Training loss = 1.1462  Validation loss = 6.3656  \n",
      "\n",
      "Fold: 8  Epoch: 12  Training loss = 1.1416  Validation loss = 6.4280  \n",
      "\n",
      "Check model:  Fold: 8  Epoch: 9  Training loss = 1.1416  Validation loss = 6.4280  \n",
      "\n",
      "Fold: 9  Epoch: 1  Training loss = 1.9348  Validation loss = 8.0368  \n",
      "\n",
      "Fold: 9  Epoch: 2  Training loss = 1.8591  Validation loss = 7.7887  \n",
      "\n",
      "Fold: 9  Epoch: 3  Training loss = 1.8337  Validation loss = 7.6479  \n",
      "\n",
      "Fold: 9  Epoch: 4  Training loss = 1.8254  Validation loss = 7.4587  \n",
      "\n",
      "Fold: 9  Epoch: 5  Training loss = 1.8225  Validation loss = 7.5203  \n",
      "\n",
      "Fold: 9  Epoch: 6  Training loss = 1.8043  Validation loss = 7.4585  \n",
      "\n",
      "Fold: 9  Epoch: 7  Training loss = 1.7886  Validation loss = 7.5918  \n",
      "\n",
      "Fold: 9  Epoch: 8  Training loss = 1.7907  Validation loss = 7.7358  \n",
      "\n",
      "Fold: 9  Epoch: 9  Training loss = 1.8229  Validation loss = 7.9264  \n",
      "\n",
      "Fold: 9  Epoch: 10  Training loss = 1.7866  Validation loss = 7.6218  \n",
      "\n",
      "Fold: 9  Epoch: 11  Training loss = 1.7585  Validation loss = 7.1784  \n",
      "\n",
      "Fold: 9  Epoch: 12  Training loss = 1.7001  Validation loss = 7.4027  \n",
      "\n",
      "Fold: 9  Epoch: 13  Training loss = 1.7121  Validation loss = 7.3668  \n",
      "\n",
      "Fold: 9  Epoch: 14  Training loss = 1.6732  Validation loss = 7.4224  \n",
      "\n",
      "Fold: 9  Epoch: 15  Training loss = 1.7207  Validation loss = 7.8487  \n",
      "\n",
      "Fold: 9  Epoch: 16  Training loss = 1.6615  Validation loss = 7.6824  \n",
      "\n",
      "Fold: 9  Epoch: 17  Training loss = 1.6634  Validation loss = 7.7378  \n",
      "\n",
      "Fold: 9  Epoch: 18  Training loss = 1.6552  Validation loss = 7.5369  \n",
      "\n",
      "Fold: 9  Epoch: 19  Training loss = 1.6593  Validation loss = 7.3525  \n",
      "\n",
      "Fold: 9  Epoch: 20  Training loss = 1.6793  Validation loss = 7.5461  \n",
      "\n",
      "Fold: 9  Epoch: 21  Training loss = 1.6555  Validation loss = 7.3068  \n",
      "\n",
      "Fold: 9  Epoch: 22  Training loss = 1.6325  Validation loss = 7.6068  \n",
      "\n",
      "Fold: 9  Epoch: 23  Training loss = 1.6339  Validation loss = 7.6991  \n",
      "\n",
      "Fold: 9  Epoch: 24  Training loss = 1.6632  Validation loss = 7.6942  \n",
      "\n",
      "Fold: 9  Epoch: 25  Training loss = 1.7921  Validation loss = 7.9058  \n",
      "\n",
      "Check model:  Fold: 9  Epoch: 11  Training loss = 1.7921  Validation loss = 7.9058  \n",
      "\n",
      "Fold: 10  Epoch: 1  Training loss = 2.4352  Validation loss = 6.2190  \n",
      "\n",
      "Fold: 10  Epoch: 2  Training loss = 2.3658  Validation loss = 5.6926  \n",
      "\n",
      "Fold: 10  Epoch: 3  Training loss = 2.3682  Validation loss = 5.6712  \n",
      "\n",
      "Fold: 10  Epoch: 4  Training loss = 2.3230  Validation loss = 5.6484  \n",
      "\n",
      "Fold: 10  Epoch: 5  Training loss = 2.3070  Validation loss = 5.3289  \n",
      "\n",
      "Fold: 10  Epoch: 6  Training loss = 2.2962  Validation loss = 4.7819  \n",
      "\n",
      "Fold: 10  Epoch: 7  Training loss = 2.2547  Validation loss = 5.2159  \n",
      "\n",
      "Fold: 10  Epoch: 8  Training loss = 2.2409  Validation loss = 5.2571  \n",
      "\n",
      "Fold: 10  Epoch: 9  Training loss = 2.2100  Validation loss = 5.0484  \n",
      "\n",
      "Fold: 10  Epoch: 10  Training loss = 2.1959  Validation loss = 5.1460  \n",
      "\n",
      "Fold: 10  Epoch: 11  Training loss = 2.2337  Validation loss = 5.1416  \n",
      "\n",
      "Fold: 10  Epoch: 12  Training loss = 2.2921  Validation loss = 5.2844  \n",
      "\n",
      "Fold: 10  Epoch: 13  Training loss = 2.1789  Validation loss = 5.1504  \n",
      "\n",
      "Fold: 10  Epoch: 14  Training loss = 2.1803  Validation loss = 5.2188  \n",
      "\n",
      "Fold: 10  Epoch: 15  Training loss = 2.1609  Validation loss = 5.2571  \n",
      "\n",
      "Fold: 10  Epoch: 16  Training loss = 2.1582  Validation loss = 5.0445  \n",
      "\n",
      "Fold: 10  Epoch: 17  Training loss = 2.2117  Validation loss = 5.2715  \n",
      "\n",
      "Fold: 10  Epoch: 18  Training loss = 2.1520  Validation loss = 5.1987  \n",
      "\n",
      "Fold: 10  Epoch: 19  Training loss = 2.1353  Validation loss = 4.8437  \n",
      "\n",
      "Fold: 10  Epoch: 20  Training loss = 2.1251  Validation loss = 4.8135  \n",
      "\n",
      "Fold: 10  Epoch: 21  Training loss = 2.1403  Validation loss = 4.6167  \n",
      "\n",
      "Fold: 10  Epoch: 22  Training loss = 2.0932  Validation loss = 4.5198  \n",
      "\n",
      "Fold: 10  Epoch: 23  Training loss = 2.0961  Validation loss = 4.3207  \n",
      "\n",
      "Fold: 10  Epoch: 24  Training loss = 2.1190  Validation loss = 4.8610  \n",
      "\n",
      "Fold: 10  Epoch: 25  Training loss = 2.1141  Validation loss = 4.8806  \n",
      "\n",
      "Fold: 10  Epoch: 26  Training loss = 2.0850  Validation loss = 4.8443  \n",
      "\n",
      "Fold: 10  Epoch: 27  Training loss = 2.1058  Validation loss = 4.9252  \n",
      "\n",
      "Fold: 10  Epoch: 28  Training loss = 2.1410  Validation loss = 4.8603  \n",
      "\n",
      "Fold: 10  Epoch: 29  Training loss = 2.0819  Validation loss = 4.4145  \n",
      "\n",
      "Fold: 10  Epoch: 30  Training loss = 2.1033  Validation loss = 4.5274  \n",
      "\n",
      "Fold: 10  Epoch: 31  Training loss = 2.0747  Validation loss = 4.7928  \n",
      "\n",
      "Fold: 10  Epoch: 32  Training loss = 2.0625  Validation loss = 4.4510  \n",
      "\n",
      "Fold: 10  Epoch: 33  Training loss = 2.0560  Validation loss = 4.4736  \n",
      "\n",
      "Fold: 10  Epoch: 34  Training loss = 2.0944  Validation loss = 4.6186  \n",
      "\n",
      "Fold: 10  Epoch: 35  Training loss = 2.0630  Validation loss = 4.7454  \n",
      "\n",
      "Fold: 10  Epoch: 36  Training loss = 2.0526  Validation loss = 4.7306  \n",
      "\n",
      "Fold: 10  Epoch: 37  Training loss = 2.0799  Validation loss = 4.6479  \n",
      "\n",
      "Fold: 10  Epoch: 38  Training loss = 2.0570  Validation loss = 4.4730  \n",
      "\n",
      "Fold: 10  Epoch: 39  Training loss = 2.0270  Validation loss = 4.3479  \n",
      "\n",
      "Fold: 10  Epoch: 40  Training loss = 2.0226  Validation loss = 4.3344  \n",
      "\n",
      "Fold: 10  Epoch: 41  Training loss = 2.0626  Validation loss = 4.0107  \n",
      "\n",
      "Fold: 10  Epoch: 42  Training loss = 2.0187  Validation loss = 4.1615  \n",
      "\n",
      "Fold: 10  Epoch: 43  Training loss = 2.0777  Validation loss = 4.6807  \n",
      "\n",
      "Fold: 10  Epoch: 44  Training loss = 2.0147  Validation loss = 4.5425  \n",
      "\n",
      "Fold: 10  Epoch: 45  Training loss = 2.0390  Validation loss = 4.6466  \n",
      "\n",
      "Fold: 10  Epoch: 46  Training loss = 2.0117  Validation loss = 4.4287  \n",
      "\n",
      "Fold: 10  Epoch: 47  Training loss = 2.0178  Validation loss = 4.4193  \n",
      "\n",
      "Fold: 10  Epoch: 48  Training loss = 1.9857  Validation loss = 4.2178  \n",
      "\n",
      "Fold: 10  Epoch: 49  Training loss = 2.0167  Validation loss = 3.9101  \n",
      "\n",
      "Fold: 10  Epoch: 50  Training loss = 1.9946  Validation loss = 3.4563  \n",
      "\n",
      "Fold: 10  Epoch: 51  Training loss = 1.9671  Validation loss = 3.6752  \n",
      "\n",
      "Fold: 10  Epoch: 52  Training loss = 1.9649  Validation loss = 3.6015  \n",
      "\n",
      "Fold: 10  Epoch: 53  Training loss = 2.0263  Validation loss = 3.4086  \n",
      "\n",
      "Fold: 10  Epoch: 54  Training loss = 2.0894  Validation loss = 4.2969  \n",
      "\n",
      "Fold: 10  Epoch: 55  Training loss = 1.9785  Validation loss = 4.0663  \n",
      "\n",
      "Fold: 10  Epoch: 56  Training loss = 2.0033  Validation loss = 4.1895  \n",
      "\n",
      "Fold: 10  Epoch: 57  Training loss = 1.9935  Validation loss = 4.0688  \n",
      "\n",
      "Fold: 10  Epoch: 58  Training loss = 1.9638  Validation loss = 4.3383  \n",
      "\n",
      "Check model:  Fold: 10  Epoch: 53  Training loss = 1.9638  Validation loss = 4.3383  \n",
      "\n",
      "Fold: 11  Epoch: 1  Training loss = 2.0719  Validation loss = 2.9965  \n",
      "\n",
      "Fold: 11  Epoch: 2  Training loss = 1.9983  Validation loss = 3.2706  \n",
      "\n",
      "Fold: 11  Epoch: 3  Training loss = 1.9303  Validation loss = 3.2980  \n",
      "\n",
      "Fold: 11  Epoch: 4  Training loss = 1.9118  Validation loss = 3.2185  \n",
      "\n",
      "Fold: 11  Epoch: 5  Training loss = 1.9619  Validation loss = 2.6517  \n",
      "\n",
      "Fold: 11  Epoch: 6  Training loss = 1.9237  Validation loss = 3.1250  \n",
      "\n",
      "Fold: 11  Epoch: 7  Training loss = 1.9101  Validation loss = 3.0091  \n",
      "\n",
      "Fold: 11  Epoch: 8  Training loss = 1.8786  Validation loss = 3.0475  \n",
      "\n",
      "Fold: 11  Epoch: 9  Training loss = 1.8763  Validation loss = 3.1675  \n",
      "\n",
      "Fold: 11  Epoch: 10  Training loss = 1.9649  Validation loss = 2.9825  \n",
      "\n",
      "Fold: 11  Epoch: 11  Training loss = 1.8964  Validation loss = 2.5531  \n",
      "\n",
      "Fold: 11  Epoch: 12  Training loss = 1.8529  Validation loss = 3.2395  \n",
      "\n",
      "Fold: 11  Epoch: 13  Training loss = 1.8394  Validation loss = 3.3717  \n",
      "\n",
      "Check model:  Fold: 11  Epoch: 11  Training loss = 1.8394  Validation loss = 3.3717  \n",
      "\n",
      "Fold: 12  Epoch: 1  Training loss = 2.0409  Validation loss = 1.8812  \n",
      "\n",
      "Fold: 12  Epoch: 2  Training loss = 1.9833  Validation loss = 0.6668  \n",
      "\n",
      "Fold: 12  Epoch: 3  Training loss = 1.9752  Validation loss = 1.2496  \n",
      "\n",
      "Fold: 12  Epoch: 4  Training loss = 1.9270  Validation loss = 0.9479  \n",
      "\n",
      "Fold: 12  Epoch: 5  Training loss = 1.9136  Validation loss = 1.6077  \n",
      "\n",
      "Fold: 12  Epoch: 6  Training loss = 1.9346  Validation loss = 1.6265  \n",
      "\n",
      "Fold: 12  Epoch: 7  Training loss = 1.9078  Validation loss = 0.6958  \n",
      "\n",
      "Fold: 12  Epoch: 8  Training loss = 1.8732  Validation loss = 1.3455  \n",
      "\n",
      "Fold: 12  Epoch: 9  Training loss = 2.0423  Validation loss = 1.1679  \n",
      "\n",
      "Fold: 12  Epoch: 10  Training loss = 1.8615  Validation loss = 1.4353  \n",
      "\n",
      "Fold: 12  Epoch: 11  Training loss = 2.0429  Validation loss = 0.6618  \n",
      "\n",
      "Fold: 12  Epoch: 12  Training loss = 1.9066  Validation loss = 0.5418  \n",
      "\n",
      "Fold: 12  Epoch: 13  Training loss = 1.8827  Validation loss = 0.5132  \n",
      "\n",
      "Fold: 12  Epoch: 14  Training loss = 1.8577  Validation loss = 0.5494  \n",
      "\n",
      "Fold: 12  Epoch: 15  Training loss = 1.8761  Validation loss = 0.5276  \n",
      "\n",
      "Fold: 12  Epoch: 16  Training loss = 1.8348  Validation loss = 0.5343  \n",
      "\n",
      "Fold: 12  Epoch: 17  Training loss = 1.8257  Validation loss = 0.6961  \n",
      "\n",
      "Fold: 12  Epoch: 18  Training loss = 1.8337  Validation loss = 0.4144  \n",
      "\n",
      "Fold: 12  Epoch: 19  Training loss = 1.8099  Validation loss = 0.4307  \n",
      "\n",
      "Fold: 12  Epoch: 20  Training loss = 1.8032  Validation loss = 0.6096  \n",
      "\n",
      "Fold: 12  Epoch: 21  Training loss = 1.7963  Validation loss = 0.4551  \n",
      "\n",
      "Fold: 12  Epoch: 22  Training loss = 1.7836  Validation loss = 0.3890  \n",
      "\n",
      "Fold: 12  Epoch: 23  Training loss = 1.7676  Validation loss = 0.4236  \n",
      "\n",
      "Fold: 12  Epoch: 24  Training loss = 1.7504  Validation loss = 0.3932  \n",
      "\n",
      "Fold: 12  Epoch: 25  Training loss = 1.7485  Validation loss = 0.3864  \n",
      "\n",
      "Fold: 12  Epoch: 26  Training loss = 1.7641  Validation loss = 0.6432  \n",
      "\n",
      "Fold: 12  Epoch: 27  Training loss = 1.7398  Validation loss = 0.3666  \n",
      "\n",
      "Fold: 12  Epoch: 28  Training loss = 1.7305  Validation loss = 0.4629  \n",
      "\n",
      "Fold: 12  Epoch: 29  Training loss = 1.7389  Validation loss = 0.5333  \n",
      "\n",
      "Fold: 12  Epoch: 30  Training loss = 1.7333  Validation loss = 0.3994  \n",
      "\n",
      "Fold: 12  Epoch: 31  Training loss = 1.7128  Validation loss = 0.5413  \n",
      "\n",
      "Fold: 12  Epoch: 32  Training loss = 1.7408  Validation loss = 0.9096  \n",
      "\n",
      "Check model:  Fold: 12  Epoch: 27  Training loss = 1.7408  Validation loss = 0.9096  \n",
      "\n",
      "Fold: 13  Epoch: 1  Training loss = 1.9106  Validation loss = 3.6856  \n",
      "\n",
      "Fold: 13  Epoch: 2  Training loss = 1.6559  Validation loss = 2.9444  \n",
      "\n",
      "Fold: 13  Epoch: 3  Training loss = 1.6384  Validation loss = 2.9279  \n",
      "\n",
      "Fold: 13  Epoch: 4  Training loss = 1.6925  Validation loss = 2.7263  \n",
      "\n",
      "Fold: 13  Epoch: 5  Training loss = 1.6487  Validation loss = 2.7610  \n",
      "\n",
      "Fold: 13  Epoch: 6  Training loss = 1.6162  Validation loss = 2.9203  \n",
      "\n",
      "Fold: 13  Epoch: 7  Training loss = 1.6241  Validation loss = 2.8281  \n",
      "\n",
      "Fold: 13  Epoch: 8  Training loss = 1.6501  Validation loss = 3.1069  \n",
      "\n",
      "Fold: 13  Epoch: 9  Training loss = 1.6406  Validation loss = 2.7574  \n",
      "\n",
      "Fold: 13  Epoch: 10  Training loss = 1.6788  Validation loss = 3.4470  \n",
      "\n",
      "Fold: 13  Epoch: 11  Training loss = 1.6657  Validation loss = 3.4677  \n",
      "\n",
      "Check model:  Fold: 13  Epoch: 4  Training loss = 1.6657  Validation loss = 3.4677  \n",
      "\n",
      "Fold: 14  Epoch: 1  Training loss = 1.8163  Validation loss = 5.6049  \n",
      "\n",
      "Fold: 14  Epoch: 2  Training loss = 1.7439  Validation loss = 6.1367  \n",
      "\n",
      "Fold: 14  Epoch: 3  Training loss = 1.7635  Validation loss = 5.7938  \n",
      "\n",
      "Fold: 14  Epoch: 4  Training loss = 1.7403  Validation loss = 6.3633  \n",
      "\n",
      "Fold: 14  Epoch: 5  Training loss = 1.7261  Validation loss = 6.1209  \n",
      "\n",
      "Fold: 14  Epoch: 6  Training loss = 1.7315  Validation loss = 5.3397  \n",
      "\n",
      "Fold: 14  Epoch: 7  Training loss = 1.6864  Validation loss = 5.9639  \n",
      "\n",
      "Fold: 14  Epoch: 8  Training loss = 1.6860  Validation loss = 5.6876  \n",
      "\n",
      "Fold: 14  Epoch: 9  Training loss = 1.6546  Validation loss = 5.8643  \n",
      "\n",
      "Fold: 14  Epoch: 10  Training loss = 1.6674  Validation loss = 5.6583  \n",
      "\n",
      "Fold: 14  Epoch: 11  Training loss = 1.7690  Validation loss = 5.3297  \n",
      "\n",
      "Fold: 14  Epoch: 12  Training loss = 1.7397  Validation loss = 5.3112  \n",
      "\n",
      "Fold: 14  Epoch: 13  Training loss = 1.7124  Validation loss = 5.2900  \n",
      "\n",
      "Fold: 14  Epoch: 14  Training loss = 1.6490  Validation loss = 5.4370  \n",
      "\n",
      "Fold: 14  Epoch: 15  Training loss = 1.6452  Validation loss = 5.6406  \n",
      "\n",
      "Fold: 14  Epoch: 16  Training loss = 1.6094  Validation loss = 5.8662  \n",
      "\n",
      "Fold: 14  Epoch: 17  Training loss = 1.7206  Validation loss = 6.6230  \n",
      "\n",
      "Check model:  Fold: 14  Epoch: 13  Training loss = 1.7206  Validation loss = 6.6230  \n",
      "\n",
      "Fold: 15  Epoch: 1  Training loss = 2.0726  Validation loss = 6.3925  \n",
      "\n",
      "Fold: 15  Epoch: 2  Training loss = 2.0680  Validation loss = 6.5783  \n",
      "\n",
      "Fold: 15  Epoch: 3  Training loss = 2.0460  Validation loss = 5.9560  \n",
      "\n",
      "Fold: 15  Epoch: 4  Training loss = 2.0637  Validation loss = 6.2717  \n",
      "\n",
      "Fold: 15  Epoch: 5  Training loss = 2.2895  Validation loss = 7.6890  \n",
      "\n",
      "Fold: 15  Epoch: 6  Training loss = 2.0231  Validation loss = 5.8571  \n",
      "\n",
      "Fold: 15  Epoch: 7  Training loss = 2.0583  Validation loss = 5.9256  \n",
      "\n",
      "Fold: 15  Epoch: 8  Training loss = 1.9460  Validation loss = 6.2394  \n",
      "\n",
      "Fold: 15  Epoch: 9  Training loss = 1.9346  Validation loss = 6.3084  \n",
      "\n",
      "Fold: 15  Epoch: 10  Training loss = 1.9180  Validation loss = 6.4565  \n",
      "\n",
      "Fold: 15  Epoch: 11  Training loss = 1.9768  Validation loss = 5.7497  \n",
      "\n",
      "Fold: 15  Epoch: 12  Training loss = 1.9805  Validation loss = 6.0813  \n",
      "\n",
      "Fold: 15  Epoch: 13  Training loss = 1.8937  Validation loss = 6.0014  \n",
      "\n",
      "Fold: 15  Epoch: 14  Training loss = 1.9373  Validation loss = 5.8019  \n",
      "\n",
      "Fold: 15  Epoch: 15  Training loss = 2.1001  Validation loss = 5.2591  \n",
      "\n",
      "Fold: 15  Epoch: 16  Training loss = 1.8497  Validation loss = 6.0206  \n",
      "\n",
      "Fold: 15  Epoch: 17  Training loss = 1.9737  Validation loss = 5.3185  \n",
      "\n",
      "Fold: 15  Epoch: 18  Training loss = 1.8382  Validation loss = 6.2315  \n",
      "\n",
      "Fold: 15  Epoch: 19  Training loss = 1.8164  Validation loss = 5.9475  \n",
      "\n",
      "Fold: 15  Epoch: 20  Training loss = 1.8621  Validation loss = 6.6378  \n",
      "\n",
      "Check model:  Fold: 15  Epoch: 15  Training loss = 1.8621  Validation loss = 6.6378  \n",
      "\n",
      "Fold: 16  Epoch: 1  Training loss = 2.3642  Validation loss = 6.2203  \n",
      "\n",
      "Fold: 16  Epoch: 2  Training loss = 2.2392  Validation loss = 4.7651  \n",
      "\n",
      "Fold: 16  Epoch: 3  Training loss = 2.2709  Validation loss = 6.6939  \n",
      "\n",
      "Fold: 16  Epoch: 4  Training loss = 2.4099  Validation loss = 6.3121  \n",
      "\n",
      "Fold: 16  Epoch: 5  Training loss = 2.1630  Validation loss = 6.0673  \n",
      "\n",
      "Fold: 16  Epoch: 6  Training loss = 2.1601  Validation loss = 5.7872  \n",
      "\n",
      "Fold: 16  Epoch: 7  Training loss = 2.3891  Validation loss = 5.3121  \n",
      "\n",
      "Fold: 16  Epoch: 8  Training loss = 2.0886  Validation loss = 5.1114  \n",
      "\n",
      "Fold: 16  Epoch: 9  Training loss = 2.0820  Validation loss = 4.9209  \n",
      "\n",
      "Fold: 16  Epoch: 10  Training loss = 2.1801  Validation loss = 5.0225  \n",
      "\n",
      "Fold: 16  Epoch: 11  Training loss = 2.1680  Validation loss = 5.7378  \n",
      "\n",
      "Fold: 16  Epoch: 12  Training loss = 2.2604  Validation loss = 5.8183  \n",
      "\n",
      "Fold: 16  Epoch: 13  Training loss = 2.0125  Validation loss = 5.7074  \n",
      "\n",
      "Fold: 16  Epoch: 14  Training loss = 2.0174  Validation loss = 5.1065  \n",
      "\n",
      "Fold: 16  Epoch: 15  Training loss = 2.1726  Validation loss = 5.6896  \n",
      "\n",
      "Fold: 16  Epoch: 16  Training loss = 2.1011  Validation loss = 5.0884  \n",
      "\n",
      "Fold: 16  Epoch: 17  Training loss = 1.9788  Validation loss = 5.4717  \n",
      "\n",
      "Fold: 16  Epoch: 18  Training loss = 1.9303  Validation loss = 5.3089  \n",
      "\n",
      "Fold: 16  Epoch: 19  Training loss = 1.9250  Validation loss = 4.8752  \n",
      "\n",
      "Fold: 16  Epoch: 20  Training loss = 2.0125  Validation loss = 5.0648  \n",
      "\n",
      "Fold: 16  Epoch: 21  Training loss = 2.0430  Validation loss = 5.6350  \n",
      "\n",
      "Fold: 16  Epoch: 22  Training loss = 1.9639  Validation loss = 4.8541  \n",
      "\n",
      "Fold: 16  Epoch: 23  Training loss = 2.2183  Validation loss = 4.8292  \n",
      "\n",
      "Fold: 16  Epoch: 24  Training loss = 2.0325  Validation loss = 4.7052  \n",
      "\n",
      "Fold: 16  Epoch: 25  Training loss = 2.2057  Validation loss = 4.8658  \n",
      "\n",
      "Fold: 16  Epoch: 26  Training loss = 1.9176  Validation loss = 5.5131  \n",
      "\n",
      "Fold: 16  Epoch: 27  Training loss = 1.8507  Validation loss = 5.2066  \n",
      "\n",
      "Fold: 16  Epoch: 28  Training loss = 2.0156  Validation loss = 5.6887  \n",
      "\n",
      "Check model:  Fold: 16  Epoch: 24  Training loss = 2.0156  Validation loss = 5.6887  \n",
      "\n",
      "Fold: 17  Epoch: 1  Training loss = 2.1671  Validation loss = 4.5222  \n",
      "\n",
      "Fold: 17  Epoch: 2  Training loss = 1.9391  Validation loss = 4.5693  \n",
      "\n",
      "Fold: 17  Epoch: 3  Training loss = 2.0818  Validation loss = 4.3850  \n",
      "\n",
      "Fold: 17  Epoch: 4  Training loss = 2.0005  Validation loss = 4.4414  \n",
      "\n",
      "Fold: 17  Epoch: 5  Training loss = 2.1699  Validation loss = 4.7019  \n",
      "\n",
      "Fold: 17  Epoch: 6  Training loss = 2.0390  Validation loss = 4.8915  \n",
      "\n",
      "Fold: 17  Epoch: 7  Training loss = 2.0470  Validation loss = 4.8031  \n",
      "\n",
      "Fold: 17  Epoch: 8  Training loss = 2.2979  Validation loss = 4.7500  \n",
      "\n",
      "Fold: 17  Epoch: 9  Training loss = 1.9217  Validation loss = 4.8372  \n",
      "\n",
      "Fold: 17  Epoch: 10  Training loss = 1.9065  Validation loss = 4.7808  \n",
      "\n",
      "Fold: 17  Epoch: 11  Training loss = 2.2245  Validation loss = 4.4381  \n",
      "\n",
      "Fold: 17  Epoch: 12  Training loss = 1.9315  Validation loss = 4.8831  \n",
      "\n",
      "Fold: 17  Epoch: 13  Training loss = 1.9262  Validation loss = 4.7566  \n",
      "\n",
      "Fold: 17  Epoch: 14  Training loss = 1.8896  Validation loss = 4.8287  \n",
      "\n",
      "Fold: 17  Epoch: 15  Training loss = 1.8647  Validation loss = 4.9788  \n",
      "\n",
      "Check model:  Fold: 17  Epoch: 3  Training loss = 1.8647  Validation loss = 4.9788  \n",
      "\n",
      "Fold: 18  Epoch: 1  Training loss = 2.1741  Validation loss = 3.0678  \n",
      "\n",
      "Fold: 18  Epoch: 2  Training loss = 2.1708  Validation loss = 3.0931  \n",
      "\n",
      "Fold: 18  Epoch: 3  Training loss = 2.0943  Validation loss = 2.8108  \n",
      "\n",
      "Fold: 18  Epoch: 4  Training loss = 1.9924  Validation loss = 2.8044  \n",
      "\n",
      "Fold: 18  Epoch: 5  Training loss = 2.3013  Validation loss = 3.0453  \n",
      "\n",
      "Fold: 18  Epoch: 6  Training loss = 2.0687  Validation loss = 2.7857  \n",
      "\n",
      "Fold: 18  Epoch: 7  Training loss = 1.9913  Validation loss = 2.8637  \n",
      "\n",
      "Fold: 18  Epoch: 8  Training loss = 2.0084  Validation loss = 2.7706  \n",
      "\n",
      "Fold: 18  Epoch: 9  Training loss = 1.9409  Validation loss = 2.6520  \n",
      "\n",
      "Fold: 18  Epoch: 10  Training loss = 2.0875  Validation loss = 2.6951  \n",
      "\n",
      "Fold: 18  Epoch: 11  Training loss = 1.8815  Validation loss = 2.7605  \n",
      "\n",
      "Fold: 18  Epoch: 12  Training loss = 1.9233  Validation loss = 2.6816  \n",
      "\n",
      "Fold: 18  Epoch: 13  Training loss = 1.9305  Validation loss = 2.5668  \n",
      "\n",
      "Fold: 18  Epoch: 14  Training loss = 1.8518  Validation loss = 2.3197  \n",
      "\n",
      "Fold: 18  Epoch: 15  Training loss = 2.0432  Validation loss = 2.3070  \n",
      "\n",
      "Fold: 18  Epoch: 16  Training loss = 1.9739  Validation loss = 2.5146  \n",
      "\n",
      "Fold: 18  Epoch: 17  Training loss = 1.8512  Validation loss = 2.5529  \n",
      "\n",
      "Fold: 18  Epoch: 18  Training loss = 1.7802  Validation loss = 2.5941  \n",
      "\n",
      "Fold: 18  Epoch: 19  Training loss = 1.9111  Validation loss = 2.7132  \n",
      "\n",
      "Fold: 18  Epoch: 20  Training loss = 1.8367  Validation loss = 2.5126  \n",
      "\n",
      "Fold: 18  Epoch: 21  Training loss = 1.8422  Validation loss = 2.4562  \n",
      "\n",
      "Fold: 18  Epoch: 22  Training loss = 1.7476  Validation loss = 2.3156  \n",
      "\n",
      "Fold: 18  Epoch: 23  Training loss = 2.0042  Validation loss = 2.4665  \n",
      "\n",
      "Fold: 18  Epoch: 24  Training loss = 1.7884  Validation loss = 2.3494  \n",
      "\n",
      "Fold: 18  Epoch: 25  Training loss = 1.7922  Validation loss = 2.3663  \n",
      "\n",
      "Fold: 18  Epoch: 26  Training loss = 1.9447  Validation loss = 2.4237  \n",
      "\n",
      "Fold: 18  Epoch: 27  Training loss = 1.8872  Validation loss = 2.4004  \n",
      "\n",
      "Fold: 18  Epoch: 28  Training loss = 1.8570  Validation loss = 2.4240  \n",
      "\n",
      "Fold: 18  Epoch: 29  Training loss = 1.7014  Validation loss = 2.2902  \n",
      "\n",
      "Fold: 18  Epoch: 30  Training loss = 1.7470  Validation loss = 2.2888  \n",
      "\n",
      "Fold: 18  Epoch: 31  Training loss = 1.7374  Validation loss = 2.3950  \n",
      "\n",
      "Fold: 18  Epoch: 32  Training loss = 1.6592  Validation loss = 2.2001  \n",
      "\n",
      "Fold: 18  Epoch: 33  Training loss = 1.7182  Validation loss = 2.0537  \n",
      "\n",
      "Fold: 18  Epoch: 34  Training loss = 1.6914  Validation loss = 2.2487  \n",
      "\n",
      "Fold: 18  Epoch: 35  Training loss = 1.7926  Validation loss = 2.2143  \n",
      "\n",
      "Fold: 18  Epoch: 36  Training loss = 1.6664  Validation loss = 2.1042  \n",
      "\n",
      "Fold: 18  Epoch: 37  Training loss = 1.6571  Validation loss = 2.1519  \n",
      "\n",
      "Fold: 18  Epoch: 38  Training loss = 1.6054  Validation loss = 2.1273  \n",
      "\n",
      "Fold: 18  Epoch: 39  Training loss = 1.6514  Validation loss = 2.0479  \n",
      "\n",
      "Fold: 18  Epoch: 40  Training loss = 2.1420  Validation loss = 2.0983  \n",
      "\n",
      "Fold: 18  Epoch: 41  Training loss = 1.8803  Validation loss = 2.0599  \n",
      "\n",
      "Fold: 18  Epoch: 42  Training loss = 1.6624  Validation loss = 2.1128  \n",
      "\n",
      "Fold: 18  Epoch: 43  Training loss = 1.5700  Validation loss = 2.0527  \n",
      "\n",
      "Fold: 18  Epoch: 44  Training loss = 1.5726  Validation loss = 2.1751  \n",
      "\n",
      "Fold: 18  Epoch: 45  Training loss = 2.0116  Validation loss = 2.0579  \n",
      "\n",
      "Fold: 18  Epoch: 46  Training loss = 1.5662  Validation loss = 2.0849  \n",
      "\n",
      "Fold: 18  Epoch: 47  Training loss = 1.5889  Validation loss = 2.0014  \n",
      "\n",
      "Fold: 18  Epoch: 48  Training loss = 1.5590  Validation loss = 2.0336  \n",
      "\n",
      "Fold: 18  Epoch: 49  Training loss = 1.9730  Validation loss = 2.0042  \n",
      "\n",
      "Fold: 18  Epoch: 50  Training loss = 1.7212  Validation loss = 1.9849  \n",
      "\n",
      "Fold: 18  Epoch: 51  Training loss = 1.7700  Validation loss = 2.0032  \n",
      "\n",
      "Fold: 18  Epoch: 52  Training loss = 1.5559  Validation loss = 2.0574  \n",
      "\n",
      "Fold: 18  Epoch: 53  Training loss = 1.5824  Validation loss = 1.9193  \n",
      "\n",
      "Fold: 18  Epoch: 54  Training loss = 1.6650  Validation loss = 2.0469  \n",
      "\n",
      "Fold: 18  Epoch: 55  Training loss = 1.8017  Validation loss = 2.0010  \n",
      "\n",
      "Fold: 18  Epoch: 56  Training loss = 1.5966  Validation loss = 1.8781  \n",
      "\n",
      "Fold: 18  Epoch: 57  Training loss = 1.5020  Validation loss = 1.8855  \n",
      "\n",
      "Fold: 18  Epoch: 58  Training loss = 1.7158  Validation loss = 1.8702  \n",
      "\n",
      "Fold: 18  Epoch: 59  Training loss = 1.7673  Validation loss = 1.9641  \n",
      "\n",
      "Fold: 18  Epoch: 60  Training loss = 1.5028  Validation loss = 1.9228  \n",
      "\n",
      "Fold: 18  Epoch: 61  Training loss = 1.5426  Validation loss = 1.9667  \n",
      "\n",
      "Fold: 18  Epoch: 62  Training loss = 1.4808  Validation loss = 2.0325  \n",
      "\n",
      "Fold: 18  Epoch: 63  Training loss = 1.6329  Validation loss = 1.9382  \n",
      "\n",
      "Fold: 18  Epoch: 64  Training loss = 1.5152  Validation loss = 1.9483  \n",
      "\n",
      "Fold: 18  Epoch: 65  Training loss = 1.4647  Validation loss = 1.9807  \n",
      "\n",
      "Fold: 18  Epoch: 66  Training loss = 1.6766  Validation loss = 1.9829  \n",
      "\n",
      "Fold: 18  Epoch: 67  Training loss = 1.7545  Validation loss = 1.9080  \n",
      "\n",
      "Fold: 18  Epoch: 68  Training loss = 1.4270  Validation loss = 1.9134  \n",
      "\n",
      "Fold: 18  Epoch: 69  Training loss = 2.0773  Validation loss = 1.8415  \n",
      "\n",
      "Fold: 18  Epoch: 70  Training loss = 1.4016  Validation loss = 1.8822  \n",
      "\n",
      "Fold: 18  Epoch: 71  Training loss = 1.7517  Validation loss = 1.7960  \n",
      "\n",
      "Fold: 18  Epoch: 72  Training loss = 1.4316  Validation loss = 1.8219  \n",
      "\n",
      "Fold: 18  Epoch: 73  Training loss = 1.5716  Validation loss = 1.9191  \n",
      "\n",
      "Fold: 18  Epoch: 74  Training loss = 1.5099  Validation loss = 1.9624  \n",
      "\n",
      "Fold: 18  Epoch: 75  Training loss = 1.4488  Validation loss = 1.9819  \n",
      "\n",
      "Fold: 18  Epoch: 76  Training loss = 1.3729  Validation loss = 1.9130  \n",
      "\n",
      "Fold: 18  Epoch: 77  Training loss = 1.6773  Validation loss = 1.8746  \n",
      "\n",
      "Fold: 18  Epoch: 78  Training loss = 2.1311  Validation loss = 1.8574  \n",
      "\n",
      "Fold: 18  Epoch: 79  Training loss = 1.3942  Validation loss = 2.0051  \n",
      "\n",
      "Check model:  Fold: 18  Epoch: 71  Training loss = 1.3942  Validation loss = 2.0051  \n",
      "\n",
      "Fold: 19  Epoch: 1  Training loss = 1.3428  Validation loss = 2.1204  \n",
      "\n",
      "Fold: 19  Epoch: 2  Training loss = 1.2923  Validation loss = 1.8383  \n",
      "\n",
      "Fold: 19  Epoch: 3  Training loss = 1.3492  Validation loss = 1.8341  \n",
      "\n",
      "Fold: 19  Epoch: 4  Training loss = 1.3573  Validation loss = 2.1512  \n",
      "\n",
      "Fold: 19  Epoch: 5  Training loss = 1.2972  Validation loss = 1.8410  \n",
      "\n",
      "Fold: 19  Epoch: 6  Training loss = 1.3843  Validation loss = 1.8898  \n",
      "\n",
      "Fold: 19  Epoch: 7  Training loss = 1.3814  Validation loss = 1.6335  \n",
      "\n",
      "Fold: 19  Epoch: 8  Training loss = 1.3953  Validation loss = 2.3185  \n",
      "\n",
      "Fold: 19  Epoch: 9  Training loss = 1.3954  Validation loss = 2.1455  \n",
      "\n",
      "Fold: 19  Epoch: 10  Training loss = 1.2727  Validation loss = 2.1260  \n",
      "\n",
      "Fold: 19  Epoch: 11  Training loss = 1.5095  Validation loss = 2.1011  \n",
      "\n",
      "Fold: 19  Epoch: 12  Training loss = 1.2018  Validation loss = 1.7365  \n",
      "\n",
      "Fold: 19  Epoch: 13  Training loss = 1.2241  Validation loss = 1.9399  \n",
      "\n",
      "Fold: 19  Epoch: 14  Training loss = 1.2750  Validation loss = 1.8368  \n",
      "\n",
      "Fold: 19  Epoch: 15  Training loss = 1.3717  Validation loss = 1.6221  \n",
      "\n",
      "Fold: 19  Epoch: 16  Training loss = 1.1916  Validation loss = 1.8242  \n",
      "\n",
      "Fold: 19  Epoch: 17  Training loss = 1.3687  Validation loss = 1.8878  \n",
      "\n",
      "Fold: 19  Epoch: 18  Training loss = 1.1660  Validation loss = 1.8284  \n",
      "\n",
      "Fold: 19  Epoch: 19  Training loss = 1.1799  Validation loss = 1.8631  \n",
      "\n",
      "Fold: 19  Epoch: 20  Training loss = 1.2736  Validation loss = 1.7117  \n",
      "\n",
      "Fold: 19  Epoch: 21  Training loss = 1.2559  Validation loss = 2.3476  \n",
      "\n",
      "Check model:  Fold: 19  Epoch: 15  Training loss = 1.2559  Validation loss = 2.3476  \n",
      "\n",
      "Fold: 20  Epoch: 1  Training loss = 1.2134  Validation loss = 3.2243  \n",
      "\n",
      "Fold: 20  Epoch: 2  Training loss = 1.2314  Validation loss = 3.4321  \n",
      "\n",
      "Fold: 20  Epoch: 3  Training loss = 1.2067  Validation loss = 3.3320  \n",
      "\n",
      "Fold: 20  Epoch: 4  Training loss = 1.3356  Validation loss = 3.4842  \n",
      "\n",
      "Fold: 20  Epoch: 5  Training loss = 1.3415  Validation loss = 3.0058  \n",
      "\n",
      "Fold: 20  Epoch: 6  Training loss = 1.1859  Validation loss = 3.1201  \n",
      "\n",
      "Fold: 20  Epoch: 7  Training loss = 1.3028  Validation loss = 2.9875  \n",
      "\n",
      "Fold: 20  Epoch: 8  Training loss = 1.2170  Validation loss = 3.1002  \n",
      "\n",
      "Fold: 20  Epoch: 9  Training loss = 1.4751  Validation loss = 2.8681  \n",
      "\n",
      "Fold: 20  Epoch: 10  Training loss = 1.2420  Validation loss = 3.4327  \n",
      "\n",
      "Fold: 20  Epoch: 11  Training loss = 1.1501  Validation loss = 3.1659  \n",
      "\n",
      "Fold: 20  Epoch: 12  Training loss = 1.1534  Validation loss = 3.1238  \n",
      "\n",
      "Fold: 20  Epoch: 13  Training loss = 1.1811  Validation loss = 3.0692  \n",
      "\n",
      "Fold: 20  Epoch: 14  Training loss = 1.0926  Validation loss = 3.1993  \n",
      "\n",
      "Fold: 20  Epoch: 15  Training loss = 1.0865  Validation loss = 2.9825  \n",
      "\n",
      "Fold: 20  Epoch: 16  Training loss = 1.2681  Validation loss = 2.8143  \n",
      "\n",
      "Fold: 20  Epoch: 17  Training loss = 1.1052  Validation loss = 3.0668  \n",
      "\n",
      "Fold: 20  Epoch: 18  Training loss = 1.1373  Validation loss = 3.3028  \n",
      "\n",
      "Fold: 20  Epoch: 19  Training loss = 1.1828  Validation loss = 2.9950  \n",
      "\n",
      "Fold: 20  Epoch: 20  Training loss = 1.2058  Validation loss = 3.3645  \n",
      "\n",
      "Check model:  Fold: 20  Epoch: 16  Training loss = 1.2058  Validation loss = 3.3645  \n",
      "\n",
      "Fold: 21  Epoch: 1  Training loss = 1.2642  Validation loss = 3.7187  \n",
      "\n",
      "Fold: 21  Epoch: 2  Training loss = 1.2107  Validation loss = 3.8523  \n",
      "\n",
      "Fold: 21  Epoch: 3  Training loss = 1.2685  Validation loss = 3.9114  \n",
      "\n",
      "Fold: 21  Epoch: 4  Training loss = 1.4369  Validation loss = 3.8397  \n",
      "\n",
      "Fold: 21  Epoch: 5  Training loss = 1.3406  Validation loss = 3.5913  \n",
      "\n",
      "Fold: 21  Epoch: 6  Training loss = 1.2033  Validation loss = 3.4949  \n",
      "\n",
      "Fold: 21  Epoch: 7  Training loss = 1.2414  Validation loss = 3.4807  \n",
      "\n",
      "Fold: 21  Epoch: 8  Training loss = 1.2712  Validation loss = 3.3779  \n",
      "\n",
      "Fold: 21  Epoch: 9  Training loss = 1.1660  Validation loss = 3.3865  \n",
      "\n",
      "Fold: 21  Epoch: 10  Training loss = 1.1502  Validation loss = 3.5878  \n",
      "\n",
      "Fold: 21  Epoch: 11  Training loss = 1.1732  Validation loss = 3.5977  \n",
      "\n",
      "Fold: 21  Epoch: 12  Training loss = 1.0926  Validation loss = 3.3100  \n",
      "\n",
      "Fold: 21  Epoch: 13  Training loss = 1.0796  Validation loss = 3.3088  \n",
      "\n",
      "Fold: 21  Epoch: 14  Training loss = 1.0966  Validation loss = 3.3366  \n",
      "\n",
      "Fold: 21  Epoch: 15  Training loss = 1.1332  Validation loss = 3.1910  \n",
      "\n",
      "Fold: 21  Epoch: 16  Training loss = 1.1108  Validation loss = 3.0871  \n",
      "\n",
      "Fold: 21  Epoch: 17  Training loss = 1.1476  Validation loss = 3.0659  \n",
      "\n",
      "Fold: 21  Epoch: 18  Training loss = 1.1347  Validation loss = 3.0243  \n",
      "\n",
      "Fold: 21  Epoch: 19  Training loss = 1.0254  Validation loss = 3.1407  \n",
      "\n",
      "Fold: 21  Epoch: 20  Training loss = 1.1493  Validation loss = 3.1550  \n",
      "\n",
      "Fold: 21  Epoch: 21  Training loss = 1.1549  Validation loss = 3.3378  \n",
      "\n",
      "Check model:  Fold: 21  Epoch: 18  Training loss = 1.1549  Validation loss = 3.3378  \n",
      "\n",
      "Fold: 22  Epoch: 1  Training loss = 1.2110  Validation loss = 2.0746  \n",
      "\n",
      "Fold: 22  Epoch: 2  Training loss = 1.1714  Validation loss = 1.9716  \n",
      "\n",
      "Fold: 22  Epoch: 3  Training loss = 1.2710  Validation loss = 2.1204  \n",
      "\n",
      "Fold: 22  Epoch: 4  Training loss = 1.2278  Validation loss = 1.6866  \n",
      "\n",
      "Fold: 22  Epoch: 5  Training loss = 1.1618  Validation loss = 2.3267  \n",
      "\n",
      "Fold: 22  Epoch: 6  Training loss = 1.1710  Validation loss = 2.2933  \n",
      "\n",
      "Fold: 22  Epoch: 7  Training loss = 1.1259  Validation loss = 2.3669  \n",
      "\n",
      "Fold: 22  Epoch: 8  Training loss = 1.1113  Validation loss = 2.1466  \n",
      "\n",
      "Fold: 22  Epoch: 9  Training loss = 1.4667  Validation loss = 1.7576  \n",
      "\n",
      "Fold: 22  Epoch: 10  Training loss = 1.1152  Validation loss = 1.6524  \n",
      "\n",
      "Fold: 22  Epoch: 11  Training loss = 1.1622  Validation loss = 1.4286  \n",
      "\n",
      "Fold: 22  Epoch: 12  Training loss = 1.0933  Validation loss = 1.6376  \n",
      "\n",
      "Fold: 22  Epoch: 13  Training loss = 1.1282  Validation loss = 1.7557  \n",
      "\n",
      "Fold: 22  Epoch: 14  Training loss = 1.1803  Validation loss = 1.9613  \n",
      "\n",
      "Fold: 22  Epoch: 15  Training loss = 1.0602  Validation loss = 1.4993  \n",
      "\n",
      "Fold: 22  Epoch: 16  Training loss = 1.0599  Validation loss = 1.6922  \n",
      "\n",
      "Fold: 22  Epoch: 17  Training loss = 1.0073  Validation loss = 1.9474  \n",
      "\n",
      "Fold: 22  Epoch: 18  Training loss = 1.0123  Validation loss = 1.7527  \n",
      "\n",
      "Fold: 22  Epoch: 19  Training loss = 1.0289  Validation loss = 1.6960  \n",
      "\n",
      "Fold: 22  Epoch: 20  Training loss = 1.0968  Validation loss = 1.7289  \n",
      "\n",
      "Fold: 22  Epoch: 21  Training loss = 1.0329  Validation loss = 1.7734  \n",
      "\n",
      "Fold: 22  Epoch: 22  Training loss = 1.1822  Validation loss = 1.4228  \n",
      "\n",
      "Fold: 22  Epoch: 23  Training loss = 1.0046  Validation loss = 1.7910  \n",
      "\n",
      "Fold: 22  Epoch: 24  Training loss = 1.0306  Validation loss = 1.9717  \n",
      "\n",
      "Check model:  Fold: 22  Epoch: 22  Training loss = 1.0306  Validation loss = 1.9717  \n",
      "\n",
      "Fold: 23  Epoch: 1  Training loss = 1.0402  Validation loss = 3.3179  \n",
      "\n",
      "Fold: 23  Epoch: 2  Training loss = 0.9915  Validation loss = 3.5170  \n",
      "\n",
      "Fold: 23  Epoch: 3  Training loss = 0.9933  Validation loss = 2.8079  \n",
      "\n",
      "Fold: 23  Epoch: 4  Training loss = 0.9703  Validation loss = 3.6178  \n",
      "\n",
      "Fold: 23  Epoch: 5  Training loss = 0.9326  Validation loss = 3.3414  \n",
      "\n",
      "Fold: 23  Epoch: 6  Training loss = 1.0026  Validation loss = 2.6987  \n",
      "\n",
      "Fold: 23  Epoch: 7  Training loss = 0.9127  Validation loss = 3.5103  \n",
      "\n",
      "Fold: 23  Epoch: 8  Training loss = 0.9019  Validation loss = 2.9381  \n",
      "\n",
      "Fold: 23  Epoch: 9  Training loss = 0.9260  Validation loss = 3.1628  \n",
      "\n",
      "Fold: 23  Epoch: 10  Training loss = 0.8926  Validation loss = 3.7489  \n",
      "\n",
      "Fold: 23  Epoch: 11  Training loss = 0.8827  Validation loss = 3.6500  \n",
      "\n",
      "Fold: 23  Epoch: 12  Training loss = 0.9639  Validation loss = 3.1297  \n",
      "\n",
      "Fold: 23  Epoch: 13  Training loss = 1.0012  Validation loss = 2.8552  \n",
      "\n",
      "Fold: 23  Epoch: 14  Training loss = 1.0396  Validation loss = 2.9377  \n",
      "\n",
      "Fold: 23  Epoch: 15  Training loss = 0.8696  Validation loss = 3.4213  \n",
      "\n",
      "Fold: 23  Epoch: 16  Training loss = 1.0380  Validation loss = 3.8119  \n",
      "\n",
      "Check model:  Fold: 23  Epoch: 6  Training loss = 1.0380  Validation loss = 3.8119  \n",
      "\n",
      "Fold: 24  Epoch: 1  Training loss = 1.1070  Validation loss = 2.0209  \n",
      "\n",
      "Fold: 24  Epoch: 2  Training loss = 1.3187  Validation loss = 1.9528  \n",
      "\n",
      "Fold: 24  Epoch: 3  Training loss = 1.0139  Validation loss = 1.8828  \n",
      "\n",
      "Fold: 24  Epoch: 4  Training loss = 1.2379  Validation loss = 1.9495  \n",
      "\n",
      "Fold: 24  Epoch: 5  Training loss = 1.3342  Validation loss = 1.8718  \n",
      "\n",
      "Fold: 24  Epoch: 6  Training loss = 1.2251  Validation loss = 1.8286  \n",
      "\n",
      "Fold: 24  Epoch: 7  Training loss = 1.1645  Validation loss = 1.9230  \n",
      "\n",
      "Fold: 24  Epoch: 8  Training loss = 1.1680  Validation loss = 1.7955  \n",
      "\n",
      "Fold: 24  Epoch: 9  Training loss = 1.1818  Validation loss = 1.8595  \n",
      "\n",
      "Fold: 24  Epoch: 10  Training loss = 1.1136  Validation loss = 1.8028  \n",
      "\n",
      "Fold: 24  Epoch: 11  Training loss = 1.0803  Validation loss = 1.8390  \n",
      "\n",
      "Fold: 24  Epoch: 12  Training loss = 1.1085  Validation loss = 1.8027  \n",
      "\n",
      "Fold: 24  Epoch: 13  Training loss = 1.0387  Validation loss = 1.7721  \n",
      "\n",
      "Fold: 24  Epoch: 14  Training loss = 1.0678  Validation loss = 1.7916  \n",
      "\n",
      "Fold: 24  Epoch: 15  Training loss = 1.0133  Validation loss = 1.7601  \n",
      "\n",
      "Fold: 24  Epoch: 16  Training loss = 1.0244  Validation loss = 1.7488  \n",
      "\n",
      "Fold: 24  Epoch: 17  Training loss = 1.0195  Validation loss = 1.9128  \n",
      "\n",
      "Check model:  Fold: 24  Epoch: 16  Training loss = 1.0195  Validation loss = 1.9128  \n",
      "\n",
      "Fold: 25  Epoch: 1  Training loss = 1.2552  Validation loss = 2.5622  \n",
      "\n",
      "Fold: 25  Epoch: 2  Training loss = 1.0753  Validation loss = 2.0327  \n",
      "\n",
      "Fold: 25  Epoch: 3  Training loss = 1.1250  Validation loss = 2.2850  \n",
      "\n",
      "Fold: 25  Epoch: 4  Training loss = 1.1391  Validation loss = 2.3054  \n",
      "\n",
      "Fold: 25  Epoch: 5  Training loss = 1.1415  Validation loss = 2.1035  \n",
      "\n",
      "Fold: 25  Epoch: 6  Training loss = 1.0689  Validation loss = 1.8766  \n",
      "\n",
      "Fold: 25  Epoch: 7  Training loss = 1.0541  Validation loss = 1.9729  \n",
      "\n",
      "Fold: 25  Epoch: 8  Training loss = 0.9782  Validation loss = 1.8998  \n",
      "\n",
      "Fold: 25  Epoch: 9  Training loss = 0.9431  Validation loss = 1.9012  \n",
      "\n",
      "Fold: 25  Epoch: 10  Training loss = 0.9643  Validation loss = 1.9599  \n",
      "\n",
      "Fold: 25  Epoch: 11  Training loss = 1.0052  Validation loss = 1.8276  \n",
      "\n",
      "Fold: 25  Epoch: 12  Training loss = 0.9616  Validation loss = 2.0350  \n",
      "\n",
      "Fold: 25  Epoch: 13  Training loss = 0.8891  Validation loss = 2.0898  \n",
      "\n",
      "Fold: 25  Epoch: 14  Training loss = 0.9150  Validation loss = 2.0274  \n",
      "\n",
      "Fold: 25  Epoch: 15  Training loss = 0.9217  Validation loss = 1.8239  \n",
      "\n",
      "Fold: 25  Epoch: 16  Training loss = 0.9115  Validation loss = 1.8973  \n",
      "\n",
      "Fold: 25  Epoch: 17  Training loss = 0.8911  Validation loss = 2.1106  \n",
      "\n",
      "Check model:  Fold: 25  Epoch: 15  Training loss = 0.8911  Validation loss = 2.1106  \n",
      "\n",
      "Fold: 26  Epoch: 1  Training loss = 0.9830  Validation loss = 2.2216  \n",
      "\n",
      "Fold: 26  Epoch: 2  Training loss = 1.0037  Validation loss = 2.1967  \n",
      "\n",
      "Fold: 26  Epoch: 3  Training loss = 0.9273  Validation loss = 2.3847  \n",
      "\n",
      "Fold: 26  Epoch: 4  Training loss = 0.9710  Validation loss = 3.2071  \n",
      "\n",
      "Fold: 26  Epoch: 5  Training loss = 0.8816  Validation loss = 2.9543  \n",
      "\n",
      "Fold: 26  Epoch: 6  Training loss = 0.8788  Validation loss = 2.8185  \n",
      "\n",
      "Fold: 26  Epoch: 7  Training loss = 0.8844  Validation loss = 2.4922  \n",
      "\n",
      "Fold: 26  Epoch: 8  Training loss = 0.8915  Validation loss = 3.2117  \n",
      "\n",
      "Fold: 26  Epoch: 9  Training loss = 0.8893  Validation loss = 2.7279  \n",
      "\n",
      "Fold: 26  Epoch: 10  Training loss = 0.8740  Validation loss = 2.4042  \n",
      "\n",
      "Fold: 26  Epoch: 11  Training loss = 0.8405  Validation loss = 2.9603  \n",
      "\n",
      "Fold: 26  Epoch: 12  Training loss = 0.8560  Validation loss = 3.1714  \n",
      "\n",
      "Fold: 26  Epoch: 13  Training loss = 0.9156  Validation loss = 3.5857  \n",
      "\n",
      "Check model:  Fold: 26  Epoch: 2  Training loss = 0.9156  Validation loss = 3.5857  \n",
      "\n",
      "Fold: 27  Epoch: 1  Training loss = 1.0788  Validation loss = 1.4976  \n",
      "\n",
      "Fold: 27  Epoch: 2  Training loss = 1.3388  Validation loss = 1.1700  \n",
      "\n",
      "Fold: 27  Epoch: 3  Training loss = 0.9445  Validation loss = 1.4056  \n",
      "\n",
      "Fold: 27  Epoch: 4  Training loss = 0.9815  Validation loss = 1.4294  \n",
      "\n",
      "Fold: 27  Epoch: 5  Training loss = 0.9844  Validation loss = 1.5308  \n",
      "\n",
      "Fold: 27  Epoch: 6  Training loss = 0.9824  Validation loss = 1.3867  \n",
      "\n",
      "Fold: 27  Epoch: 7  Training loss = 0.9337  Validation loss = 1.4981  \n",
      "\n",
      "Fold: 27  Epoch: 8  Training loss = 0.9319  Validation loss = 1.3853  \n",
      "\n",
      "Fold: 27  Epoch: 9  Training loss = 0.9240  Validation loss = 1.2981  \n",
      "\n",
      "Fold: 27  Epoch: 10  Training loss = 0.9384  Validation loss = 1.4869  \n",
      "\n",
      "Fold: 27  Epoch: 11  Training loss = 0.9101  Validation loss = 1.3288  \n",
      "\n",
      "Fold: 27  Epoch: 12  Training loss = 0.8862  Validation loss = 1.4080  \n",
      "\n",
      "Fold: 27  Epoch: 13  Training loss = 0.9042  Validation loss = 1.2882  \n",
      "\n",
      "Fold: 27  Epoch: 14  Training loss = 0.8523  Validation loss = 1.2812  \n",
      "\n",
      "Fold: 27  Epoch: 15  Training loss = 0.8713  Validation loss = 1.4156  \n",
      "\n",
      "Fold: 27  Epoch: 16  Training loss = 0.9115  Validation loss = 1.1057  \n",
      "\n",
      "Fold: 27  Epoch: 17  Training loss = 0.8731  Validation loss = 1.1462  \n",
      "\n",
      "Fold: 27  Epoch: 18  Training loss = 0.9277  Validation loss = 1.4956  \n",
      "\n",
      "Check model:  Fold: 27  Epoch: 16  Training loss = 0.9277  Validation loss = 1.4956  \n",
      "\n",
      "Fold: 28  Epoch: 1  Training loss = 0.8707  Validation loss = 2.7668  \n",
      "\n",
      "Fold: 28  Epoch: 2  Training loss = 0.9044  Validation loss = 2.9358  \n",
      "\n",
      "Fold: 28  Epoch: 3  Training loss = 0.8511  Validation loss = 2.8091  \n",
      "\n",
      "Fold: 28  Epoch: 4  Training loss = 0.8400  Validation loss = 2.7217  \n",
      "\n",
      "Fold: 28  Epoch: 5  Training loss = 0.8225  Validation loss = 2.7900  \n",
      "\n",
      "Fold: 28  Epoch: 6  Training loss = 0.8263  Validation loss = 2.7026  \n",
      "\n",
      "Fold: 28  Epoch: 7  Training loss = 0.8735  Validation loss = 2.8868  \n",
      "\n",
      "Fold: 28  Epoch: 8  Training loss = 0.8064  Validation loss = 2.8809  \n",
      "\n",
      "Fold: 28  Epoch: 9  Training loss = 0.8301  Validation loss = 2.9387  \n",
      "\n",
      "Fold: 28  Epoch: 10  Training loss = 0.8605  Validation loss = 2.7063  \n",
      "\n",
      "Fold: 28  Epoch: 11  Training loss = 0.8119  Validation loss = 2.6248  \n",
      "\n",
      "Fold: 28  Epoch: 12  Training loss = 0.7631  Validation loss = 2.7025  \n",
      "\n",
      "Fold: 28  Epoch: 13  Training loss = 0.7662  Validation loss = 2.7611  \n",
      "\n",
      "Fold: 28  Epoch: 14  Training loss = 0.7582  Validation loss = 2.7485  \n",
      "\n",
      "Fold: 28  Epoch: 15  Training loss = 0.9157  Validation loss = 2.9122  \n",
      "\n",
      "Fold: 28  Epoch: 16  Training loss = 0.8794  Validation loss = 2.4871  \n",
      "\n",
      "Fold: 28  Epoch: 17  Training loss = 0.8319  Validation loss = 2.7849  \n",
      "\n",
      "Fold: 28  Epoch: 18  Training loss = 0.7534  Validation loss = 2.8136  \n",
      "\n",
      "Fold: 28  Epoch: 19  Training loss = 0.7302  Validation loss = 2.6810  \n",
      "\n",
      "Fold: 28  Epoch: 20  Training loss = 0.7143  Validation loss = 2.7885  \n",
      "\n",
      "Fold: 28  Epoch: 21  Training loss = 0.8404  Validation loss = 2.5039  \n",
      "\n",
      "Fold: 28  Epoch: 22  Training loss = 0.6869  Validation loss = 2.7431  \n",
      "\n",
      "Fold: 28  Epoch: 23  Training loss = 0.7442  Validation loss = 2.6504  \n",
      "\n",
      "Fold: 28  Epoch: 24  Training loss = 0.7189  Validation loss = 2.8141  \n",
      "\n",
      "Fold: 28  Epoch: 25  Training loss = 0.7932  Validation loss = 2.4131  \n",
      "\n",
      "Fold: 28  Epoch: 26  Training loss = 0.7937  Validation loss = 2.7388  \n",
      "\n",
      "Fold: 28  Epoch: 27  Training loss = 0.6886  Validation loss = 2.7739  \n",
      "\n",
      "Fold: 28  Epoch: 28  Training loss = 0.6636  Validation loss = 2.4858  \n",
      "\n",
      "Fold: 28  Epoch: 29  Training loss = 0.6909  Validation loss = 2.6184  \n",
      "\n",
      "Fold: 28  Epoch: 30  Training loss = 0.6636  Validation loss = 2.7513  \n",
      "\n",
      "Fold: 28  Epoch: 31  Training loss = 0.7997  Validation loss = 2.4764  \n",
      "\n",
      "Fold: 28  Epoch: 32  Training loss = 0.7171  Validation loss = 2.6632  \n",
      "\n",
      "Fold: 28  Epoch: 33  Training loss = 0.7962  Validation loss = 2.4118  \n",
      "\n",
      "Fold: 28  Epoch: 34  Training loss = 0.6601  Validation loss = 2.6860  \n",
      "\n",
      "Fold: 28  Epoch: 35  Training loss = 0.6334  Validation loss = 2.5449  \n",
      "\n",
      "Fold: 28  Epoch: 36  Training loss = 0.7274  Validation loss = 2.6308  \n",
      "\n",
      "Fold: 28  Epoch: 37  Training loss = 0.7416  Validation loss = 2.5061  \n",
      "\n",
      "Fold: 28  Epoch: 38  Training loss = 0.6321  Validation loss = 2.5008  \n",
      "\n",
      "Fold: 28  Epoch: 39  Training loss = 0.6725  Validation loss = 2.6096  \n",
      "\n",
      "Fold: 28  Epoch: 40  Training loss = 0.7500  Validation loss = 1.9776  \n",
      "\n",
      "Fold: 28  Epoch: 41  Training loss = 0.6361  Validation loss = 2.4487  \n",
      "\n",
      "Fold: 28  Epoch: 42  Training loss = 0.6525  Validation loss = 2.3882  \n",
      "\n",
      "Fold: 28  Epoch: 43  Training loss = 0.6577  Validation loss = 2.7460  \n",
      "\n",
      "Check model:  Fold: 28  Epoch: 40  Training loss = 0.6577  Validation loss = 2.7460  \n",
      "\n",
      "Fold: 29  Epoch: 1  Training loss = 0.8605  Validation loss = 1.9796  \n",
      "\n",
      "Fold: 29  Epoch: 2  Training loss = 0.9976  Validation loss = 2.5352  \n",
      "\n",
      "Fold: 29  Epoch: 3  Training loss = 0.8118  Validation loss = 2.3995  \n",
      "\n",
      "Fold: 29  Epoch: 4  Training loss = 0.8326  Validation loss = 2.0204  \n",
      "\n",
      "Fold: 29  Epoch: 5  Training loss = 0.7505  Validation loss = 2.2747  \n",
      "\n",
      "Fold: 29  Epoch: 6  Training loss = 0.7204  Validation loss = 2.2881  \n",
      "\n",
      "Fold: 29  Epoch: 7  Training loss = 0.7728  Validation loss = 2.3213  \n",
      "\n",
      "Fold: 29  Epoch: 8  Training loss = 0.6712  Validation loss = 2.2171  \n",
      "\n",
      "Fold: 29  Epoch: 9  Training loss = 0.7098  Validation loss = 2.3840  \n",
      "\n",
      "Fold: 29  Epoch: 10  Training loss = 0.6783  Validation loss = 2.1596  \n",
      "\n",
      "Fold: 29  Epoch: 11  Training loss = 0.6515  Validation loss = 2.3085  \n",
      "\n",
      "Fold: 29  Epoch: 12  Training loss = 0.6691  Validation loss = 2.3935  \n",
      "\n",
      "Fold: 29  Epoch: 13  Training loss = 0.6495  Validation loss = 2.1509  \n",
      "\n",
      "Fold: 29  Epoch: 14  Training loss = 0.8996  Validation loss = 1.8533  \n",
      "\n",
      "Fold: 29  Epoch: 15  Training loss = 0.6586  Validation loss = 2.1856  \n",
      "\n",
      "Fold: 29  Epoch: 16  Training loss = 0.6895  Validation loss = 1.8878  \n",
      "\n",
      "Fold: 29  Epoch: 17  Training loss = 0.7448  Validation loss = 1.9631  \n",
      "\n",
      "Fold: 29  Epoch: 18  Training loss = 0.7242  Validation loss = 2.4321  \n",
      "\n",
      "Check model:  Fold: 29  Epoch: 14  Training loss = 0.7242  Validation loss = 2.4321  \n",
      "\n",
      "Fold: 30  Epoch: 1  Training loss = 0.9637  Validation loss = 0.9118  \n",
      "\n",
      "Fold: 30  Epoch: 2  Training loss = 0.8570  Validation loss = 1.2420  \n",
      "\n",
      "Fold: 30  Epoch: 3  Training loss = 0.8132  Validation loss = 1.5372  \n",
      "\n",
      "Fold: 30  Epoch: 4  Training loss = 0.8710  Validation loss = 1.0414  \n",
      "\n",
      "Fold: 30  Epoch: 5  Training loss = 0.9595  Validation loss = 1.3561  \n",
      "\n",
      "Fold: 30  Epoch: 6  Training loss = 0.7749  Validation loss = 1.3569  \n",
      "\n",
      "Fold: 30  Epoch: 7  Training loss = 0.8321  Validation loss = 1.2562  \n",
      "\n",
      "Fold: 30  Epoch: 8  Training loss = 0.8902  Validation loss = 1.1596  \n",
      "\n",
      "Fold: 30  Epoch: 9  Training loss = 0.8193  Validation loss = 1.0929  \n",
      "\n",
      "Fold: 30  Epoch: 10  Training loss = 0.7968  Validation loss = 1.1521  \n",
      "\n",
      "Fold: 30  Epoch: 11  Training loss = 0.7742  Validation loss = 1.1067  \n",
      "\n",
      "Fold: 30  Epoch: 12  Training loss = 0.8774  Validation loss = 1.0242  \n",
      "\n",
      "Fold: 30  Epoch: 13  Training loss = 0.7870  Validation loss = 1.1505  \n",
      "\n",
      "Fold: 30  Epoch: 14  Training loss = 0.7457  Validation loss = 1.1021  \n",
      "\n",
      "Fold: 30  Epoch: 15  Training loss = 0.7435  Validation loss = 1.0696  \n",
      "\n",
      "Fold: 30  Epoch: 16  Training loss = 0.7681  Validation loss = 1.0840  \n",
      "\n",
      "Fold: 30  Epoch: 17  Training loss = 0.8126  Validation loss = 1.1850  \n",
      "\n",
      "Check model:  Fold: 30  Epoch: 1  Training loss = 0.8126  Validation loss = 1.1850  \n",
      "\n",
      "Fold: 31  Epoch: 1  Training loss = 0.7434  Validation loss = 0.2626  \n",
      "\n",
      "Fold: 31  Epoch: 2  Training loss = 0.8753  Validation loss = 0.6628  \n",
      "\n",
      "Fold: 31  Epoch: 3  Training loss = 0.7404  Validation loss = 0.3438  \n",
      "\n",
      "Fold: 31  Epoch: 4  Training loss = 0.7383  Validation loss = 0.4665  \n",
      "\n",
      "Fold: 31  Epoch: 5  Training loss = 0.7897  Validation loss = 0.7633  \n",
      "\n",
      "Fold: 31  Epoch: 6  Training loss = 0.7159  Validation loss = 0.4333  \n",
      "\n",
      "Fold: 31  Epoch: 7  Training loss = 0.7554  Validation loss = 0.7347  \n",
      "\n",
      "Fold: 31  Epoch: 8  Training loss = 0.7470  Validation loss = 0.6848  \n",
      "\n",
      "Fold: 31  Epoch: 9  Training loss = 0.7936  Validation loss = 0.8811  \n",
      "\n",
      "Fold: 31  Epoch: 10  Training loss = 0.6829  Validation loss = 0.7090  \n",
      "\n",
      "Fold: 31  Epoch: 11  Training loss = 0.7540  Validation loss = 0.8350  \n",
      "\n",
      "Fold: 31  Epoch: 12  Training loss = 0.6625  Validation loss = 0.8216  \n",
      "\n",
      "Fold: 31  Epoch: 13  Training loss = 0.6620  Validation loss = 0.7632  \n",
      "\n",
      "Fold: 31  Epoch: 14  Training loss = 0.7039  Validation loss = 0.8613  \n",
      "\n",
      "Fold: 31  Epoch: 15  Training loss = 0.6457  Validation loss = 0.6749  \n",
      "\n",
      "Fold: 31  Epoch: 16  Training loss = 0.6322  Validation loss = 0.7670  \n",
      "\n",
      "Fold: 31  Epoch: 17  Training loss = 0.7414  Validation loss = 0.8356  \n",
      "\n",
      "Fold: 31  Epoch: 18  Training loss = 0.6162  Validation loss = 0.7427  \n",
      "\n",
      "Fold: 31  Epoch: 19  Training loss = 0.6743  Validation loss = 0.8537  \n",
      "\n",
      "Fold: 31  Epoch: 20  Training loss = 0.7206  Validation loss = 0.9512  \n",
      "\n",
      "Check model:  Fold: 31  Epoch: 1  Training loss = 0.7206  Validation loss = 0.9512  \n",
      "\n",
      "Fold: 32  Epoch: 1  Training loss = 0.6248  Validation loss = 2.4266  \n",
      "\n",
      "Fold: 32  Epoch: 2  Training loss = 0.7589  Validation loss = 3.2663  \n",
      "\n",
      "Fold: 32  Epoch: 3  Training loss = 0.5994  Validation loss = 2.8248  \n",
      "\n",
      "Fold: 32  Epoch: 4  Training loss = 0.5900  Validation loss = 2.8347  \n",
      "\n",
      "Fold: 32  Epoch: 5  Training loss = 0.6043  Validation loss = 2.7175  \n",
      "\n",
      "Fold: 32  Epoch: 6  Training loss = 0.5817  Validation loss = 2.7970  \n",
      "\n",
      "Fold: 32  Epoch: 7  Training loss = 0.6279  Validation loss = 3.0103  \n",
      "\n",
      "Fold: 32  Epoch: 8  Training loss = 0.5713  Validation loss = 2.5935  \n",
      "\n",
      "Fold: 32  Epoch: 9  Training loss = 0.5669  Validation loss = 2.5712  \n",
      "\n",
      "Fold: 32  Epoch: 10  Training loss = 0.5692  Validation loss = 2.6761  \n",
      "\n",
      "Fold: 32  Epoch: 11  Training loss = 0.5840  Validation loss = 2.7694  \n",
      "\n",
      "Fold: 32  Epoch: 12  Training loss = 0.6006  Validation loss = 2.5308  \n",
      "\n",
      "Fold: 32  Epoch: 13  Training loss = 0.5648  Validation loss = 2.8115  \n",
      "\n",
      "Fold: 32  Epoch: 14  Training loss = 0.5612  Validation loss = 2.7401  \n",
      "\n",
      "Fold: 32  Epoch: 15  Training loss = 0.5835  Validation loss = 2.8174  \n",
      "\n",
      "Fold: 32  Epoch: 16  Training loss = 0.5409  Validation loss = 2.6249  \n",
      "\n",
      "Fold: 32  Epoch: 17  Training loss = 0.8184  Validation loss = 2.4064  \n",
      "\n",
      "Fold: 32  Epoch: 18  Training loss = 0.5932  Validation loss = 2.5416  \n",
      "\n",
      "Fold: 32  Epoch: 19  Training loss = 0.5760  Validation loss = 2.5723  \n",
      "\n",
      "Fold: 32  Epoch: 20  Training loss = 0.5826  Validation loss = 2.9615  \n",
      "\n",
      "Check model:  Fold: 32  Epoch: 17  Training loss = 0.5826  Validation loss = 2.9615  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 2. Train model\n",
    "# ==================================\n",
    "sess = tf.InteractiveSession()  # Launch Graph\n",
    "sess.run(tf.global_variables_initializer())  # Initialise all variables\n",
    "\n",
    "print(\"Start training\", \n",
    "      \"\\nHyperparameters:\",\n",
    "      \"\\nDimension of recurrent unit =\", n_hidden,\n",
    "      \"\\nLearning rate =\", learning_rate,\n",
    "      \"\\nEpochs =\", epochs,\n",
    "      \"\\nBatch size =\", batch_size,\n",
    "      \"\\nEarly stopping epochs =\", early_stop_iters,\n",
    "      \"\\nLearning rate =\", learning_rate)\n",
    "\n",
    "total_batch = int(window_length / batch_size)\n",
    "validation_fold_error = [] # store validation error of each fold\n",
    "optimal_epochs = []\n",
    "\n",
    "# loop through folds\n",
    "for fold in range(1, len(valIndex)):\n",
    "    validx = train_features[valIndex[fold-1]:valIndex[fold]]\n",
    "    validy = train_target[valIndex[fold-1]:valIndex[fold]]\n",
    "    trainx = train_features[(fold-1)*4:valIndex[(fold-1)]]\n",
    "    trainy = train_target[(fold-1)*4:valIndex[(fold-1)]]\n",
    "\n",
    "    loss_list = [] # store validation loss after each epoch for early stopping\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i in range(total_batch):\n",
    "            # Backprop\n",
    "            batch_xs, batch_ys = next_batch(num=batch_size, data=trainx, labels=trainy)\n",
    "            optimizer.run(feed_dict={x:batch_xs, y:batch_ys, lr:learning_rate})\n",
    "\n",
    "        # Loss\n",
    "        loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "        loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "        loss_list.append(loss_valid)\n",
    "\n",
    "        print(\"Fold: {0:d}\".format(fold),\n",
    "              \" Epoch: {0:d}\".format(epoch+1),\n",
    "              \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "              \" Validation loss = {0:.4f}\".format(np.sqrt(loss_valid)),\n",
    "              \" \\n\")\n",
    "\n",
    "        if all(j <= loss_valid for j in loss_list[-early_stop_iters:]) and len(loss_list)>early_stop_iters:\n",
    "            break\n",
    "    \n",
    "    # Load model with lowest validation error for each fold\n",
    "    epoch_hat = np.argmin(loss_list) + 1\n",
    "    optimal_epochs.append(epoch_hat) # store optimal number of epochs for each fold\n",
    "    \n",
    "    # RMSE\n",
    "    loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "    loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "    validation_fold_error.append(np.sqrt(loss_valid))\n",
    "    \n",
    "    print(\"Check model:\",\n",
    "          \" Fold: {0:d}\".format(fold),\n",
    "          \" Epoch: {0:d}\".format(epoch_hat),\n",
    "          \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "          \" Validation loss = {0:.4f}\".format(np.sqrt(loss_valid)),\n",
    "          \" \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average number of epochs: 18\n",
      "Average validation error: 3.21574\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 3. Optimal epoch choice\n",
    "# ==================================\n",
    "# Pick number of epochs to train model for out-of-sample testing\n",
    "epoch_hat = int(np.mean(optimal_epochs))\n",
    "print(\"\\nAverage number of epochs:\", epoch_hat)\n",
    "# Average validation error\n",
    "print(\"Average validation error:\", np.mean(validation_fold_error))\n",
    "\n",
    "# Save validated model\n",
    "saveModel(sess, \n",
    "          MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + str(epoch_hat) + \"_validated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fixed scheme:\n",
      "Epoch: 1  Training loss = 0.8338  Test loss = 3.3759  \n",
      "\n",
      "Epoch: 2  Training loss = 0.8069  Test loss = 3.3025  \n",
      "\n",
      "Epoch: 3  Training loss = 0.7912  Test loss = 3.2631  \n",
      "\n",
      "Epoch: 4  Training loss = 0.7790  Test loss = 3.2392  \n",
      "\n",
      "Epoch: 5  Training loss = 0.7685  Test loss = 3.2230  \n",
      "\n",
      "Epoch: 6  Training loss = 0.7590  Test loss = 3.2110  \n",
      "\n",
      "Epoch: 7  Training loss = 0.7503  Test loss = 3.2016  \n",
      "\n",
      "Epoch: 8  Training loss = 0.7422  Test loss = 3.1939  \n",
      "\n",
      "Epoch: 9  Training loss = 0.7346  Test loss = 3.1876  \n",
      "\n",
      "Epoch: 10  Training loss = 0.7274  Test loss = 3.1824  \n",
      "\n",
      "Epoch: 11  Training loss = 0.7206  Test loss = 3.1780  \n",
      "\n",
      "Epoch: 12  Training loss = 0.7141  Test loss = 3.1744  \n",
      "\n",
      "Epoch: 13  Training loss = 0.7080  Test loss = 3.1714  \n",
      "\n",
      "Epoch: 14  Training loss = 0.7022  Test loss = 3.1690  \n",
      "\n",
      "Epoch: 15  Training loss = 0.6968  Test loss = 3.1670  \n",
      "\n",
      "Epoch: 16  Training loss = 0.6916  Test loss = 3.1653  \n",
      "\n",
      "Epoch: 17  Training loss = 0.6867  Test loss = 3.1638  \n",
      "\n",
      "Epoch: 18  Training loss = 0.6821  Test loss = 3.1626  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 4. Fixed scheme\n",
    "# ==================================\n",
    "print(\"\\nFixed scheme:\")\n",
    "for epoch in range(epoch_hat):\n",
    "    x_train = train_features[-window_length:]\n",
    "    y_train = train_target[-window_length:]\n",
    "    optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:test_features, y:test_target})\n",
    "    print(\"Epoch: {0:d}\".format(epoch+1),\n",
    "          \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "          \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "          \" \\n\")\n",
    "\n",
    "# Forecasts\n",
    "yhat_test_fixed = pred.eval(feed_dict={x:test_features})\n",
    "yhat_train_fixed = pred.eval(feed_dict={x:x_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc207518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train set\n",
    "plt.plot(y_train, 'black')\n",
    "plt.plot(yhat_train_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xccdde10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: fixed scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_test_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed scheme RMSE: 3.16261552134 \n",
      "Fixed scheme MAE:  2.22603447009\n"
     ]
    }
   ],
   "source": [
    "rmse_fixed = np.sqrt(np.mean((yhat_test_fixed[:,0]-test_target)**2))\n",
    "mae_fixed = np.mean(np.abs((yhat_test_fixed[:,0]-test_target)))\n",
    "print(\"Fixed scheme RMSE:\", rmse_fixed,\n",
    "     \"\\nFixed scheme MAE: \", mae_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Stack training and test set, this makes updating scheme easier to train\n",
    "all_features = np.concatenate((train_features[-window_length:], test_features), axis=0)\n",
    "all_target = np.concatenate((train_target[-window_length:], test_target), axis=0)\n",
    "\n",
    "# Vectors to store loss and forecasts\n",
    "test_loss = np.zeros(len(test_target))\n",
    "yhat_update = np.zeros(len(test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test period = 1  Training loss = 0.6821  Test loss = 2.9040  Model updated 0 times  \n",
      "\n",
      "Test period = 2  Training loss = 0.7705  Test loss = 2.6734  Model updated 0 times  \n",
      "\n",
      "Test period = 3  Training loss = 0.8384  Test loss = 1.0547  Model updated 0 times  \n",
      "\n",
      "Test period = 4  Training loss = 0.8483  Test loss = 0.8336  Model updated 0 times  \n",
      "\n",
      "Test period = 5  Training loss = 0.5355  Test loss = 2.2310  Model updated 1 times  \n",
      "\n",
      "Test period = 6  Training loss = 0.6025  Test loss = 0.8749  Model updated 1 times  \n",
      "\n",
      "Test period = 7  Training loss = 0.6118  Test loss = 0.8441  Model updated 1 times  \n",
      "\n",
      "Test period = 8  Training loss = 0.6194  Test loss = 0.4641  Model updated 1 times  \n",
      "\n",
      "Test period = 9  Training loss = 0.5323  Test loss = 2.0760  Model updated 2 times  \n",
      "\n",
      "Test period = 10  Training loss = 0.5911  Test loss = 0.9420  Model updated 2 times  \n",
      "\n",
      "Test period = 11  Training loss = 0.6026  Test loss = 1.2133  Model updated 2 times  \n",
      "\n",
      "Test period = 12  Training loss = 0.6207  Test loss = 3.0840  Model updated 2 times  \n",
      "\n",
      "Test period = 13  Training loss = 0.6653  Test loss = 2.6966  Model updated 3 times  \n",
      "\n",
      "Test period = 14  Training loss = 0.7432  Test loss = 4.0874  Model updated 3 times  \n",
      "\n",
      "Test period = 15  Training loss = 0.8996  Test loss = 5.2166  Model updated 3 times  \n",
      "\n",
      "Test period = 16  Training loss = 1.1081  Test loss = 8.4105  Model updated 3 times  \n",
      "\n",
      "Test period = 17  Training loss = 0.8801  Test loss = 0.9453  Model updated 4 times  \n",
      "\n",
      "Test period = 18  Training loss = 0.8879  Test loss = 0.2008  Model updated 4 times  \n",
      "\n",
      "Test period = 19  Training loss = 0.8881  Test loss = 0.6380  Model updated 4 times  \n",
      "\n",
      "Test period = 20  Training loss = 0.8644  Test loss = 0.0632  Model updated 4 times  \n",
      "\n",
      "Test period = 21  Training loss = 0.5591  Test loss = 1.5374  Model updated 5 times  \n",
      "\n",
      "Test period = 22  Training loss = 0.5903  Test loss = 3.3571  Model updated 5 times  \n",
      "\n",
      "Test period = 23  Training loss = 0.7222  Test loss = 0.4433  Model updated 5 times  \n",
      "\n",
      "Test period = 24  Training loss = 0.7243  Test loss = 0.6282  Model updated 5 times  \n",
      "\n",
      "Test period = 25  Training loss = 0.6064  Test loss = 0.0317  Model updated 6 times  \n",
      "\n",
      "Test period = 26  Training loss = 0.6031  Test loss = 2.0326  Model updated 6 times  \n",
      "\n",
      "Test period = 27  Training loss = 0.6536  Test loss = 2.8956  Model updated 6 times  \n",
      "\n",
      "Test period = 28  Training loss = 0.7450  Test loss = 0.8756  Model updated 6 times  \n",
      "\n",
      "Test period = 29  Training loss = 0.6002  Test loss = 0.0947  Model updated 7 times  \n",
      "\n",
      "Test period = 30  Training loss = 0.5996  Test loss = 0.3768  Model updated 7 times  \n",
      "\n",
      "Test period = 31  Training loss = 0.6014  Test loss = 3.5791  Model updated 7 times  \n",
      "\n",
      "Test period = 32  Training loss = 0.7459  Test loss = 0.4554  Model updated 7 times  \n",
      "\n",
      "Test period = 33  Training loss = 0.6393  Test loss = 0.9286  Model updated 8 times  \n",
      "\n",
      "Test period = 34  Training loss = 0.6494  Test loss = 0.5581  Model updated 8 times  \n",
      "\n",
      "Test period = 35  Training loss = 0.6499  Test loss = 1.0595  Model updated 8 times  \n",
      "\n",
      "Test period = 36  Training loss = 0.6629  Test loss = 3.3873  Model updated 8 times  \n",
      "\n",
      "Test period = 37  Training loss = 0.7523  Test loss = 1.0711  Model updated 9 times  \n",
      "\n",
      "Test period = 38  Training loss = 0.7536  Test loss = 0.3186  Model updated 9 times  \n",
      "\n",
      "Test period = 39  Training loss = 0.7513  Test loss = 0.5490  Model updated 9 times  \n",
      "\n",
      "Test period = 40  Training loss = 0.7544  Test loss = 3.1618  Model updated 9 times  \n",
      "\n",
      "Test period = 41  Training loss = 0.7416  Test loss = 0.5344  Model updated 10 times  \n",
      "\n",
      "Test period = 42  Training loss = 0.7439  Test loss = 1.2057  Model updated 10 times  \n",
      "\n",
      "Test period = 43  Training loss = 0.7585  Test loss = 3.3548  Model updated 10 times  \n",
      "\n",
      "Test period = 44  Training loss = 0.8648  Test loss = 13.2846  Model updated 10 times  \n",
      "\n",
      "Test period = 45  Training loss = 1.8545  Test loss = 7.5098  Model updated 11 times  \n",
      "\n",
      "Test period = 46  Training loss = 2.0750  Test loss = 2.1730  Model updated 11 times  \n",
      "\n",
      "Test period = 47  Training loss = 2.0925  Test loss = 1.0605  Model updated 11 times  \n",
      "\n",
      "Test period = 48  Training loss = 2.0962  Test loss = 0.3388  Model updated 11 times  \n",
      "\n",
      "Test period = 49  Training loss = 1.3596  Test loss = 2.0060  Model updated 12 times  \n",
      "\n",
      "Test period = 50  Training loss = 1.3821  Test loss = 3.0056  Model updated 12 times  \n",
      "\n",
      "Test period = 51  Training loss = 1.4296  Test loss = 2.8251  Model updated 12 times  \n",
      "\n",
      "Test period = 52  Training loss = 1.4717  Test loss = 0.9378  Model updated 12 times  \n",
      "\n",
      "Test period = 53  Training loss = 1.2460  Test loss = 1.3632  Model updated 13 times  \n",
      "\n",
      "Test period = 54  Training loss = 1.2570  Test loss = 2.0993  Model updated 13 times  \n",
      "\n",
      "Test period = 55  Training loss = 1.2836  Test loss = 1.1973  Model updated 13 times  \n",
      "\n",
      "Test period = 56  Training loss = 1.2907  Test loss = 0.7706  Model updated 13 times  \n",
      "\n",
      "Test period = 57  Training loss = 1.1807  Test loss = 2.9252  Model updated 14 times  \n",
      "\n",
      "Test period = 58  Training loss = 1.2348  Test loss = 5.2469  Model updated 14 times  \n",
      "\n",
      "Test period = 59  Training loss = 1.3955  Test loss = 1.2784  Model updated 14 times  \n",
      "\n",
      "Test period = 60  Training loss = 1.4041  Test loss = 0.2822  Model updated 14 times  \n",
      "\n",
      "Test period = 61  Training loss = 1.1552  Test loss = 1.8392  Model updated 15 times  \n",
      "\n",
      "Test period = 62  Training loss = 1.1724  Test loss = 3.8780  Model updated 15 times  \n",
      "\n",
      "Test period = 63  Training loss = 1.2658  Test loss = 1.1607  Model updated 15 times  \n",
      "\n",
      "Test period = 64  Training loss = 1.2739  Test loss = 1.8676  Model updated 15 times  \n",
      "\n",
      "Test period = 65  Training loss = 1.0686  Test loss = 0.8528  Model updated 16 times  \n",
      "\n",
      "Test period = 66  Training loss = 1.0703  Test loss = 0.7852  Model updated 16 times  \n",
      "\n",
      "Test period = 67  Training loss = 1.0745  Test loss = 1.3780  Model updated 16 times  \n",
      "\n",
      "Test period = 68  Training loss = 1.0858  Test loss = 4.3297  Model updated 16 times  \n",
      "\n",
      "Test period = 69  Training loss = 1.1307  Test loss = 4.8132  Model updated 17 times  \n",
      "\n",
      "Test period = 70  Training loss = 1.2787  Test loss = 0.6924  Model updated 17 times  \n",
      "\n",
      "Test period = 71  Training loss = 1.2792  Test loss = 0.2494  Model updated 17 times  \n",
      "\n",
      "Test period = 72  Training loss = 1.2795  Test loss = 0.8285  Model updated 17 times  \n",
      "\n",
      "Test period = 73  Training loss = 1.0378  Test loss = 1.6951  Model updated 18 times  \n",
      "\n",
      "Test period = 74  Training loss = 1.0589  Test loss = 1.8822  Model updated 18 times  \n",
      "\n",
      "Test period = 75  Training loss = 1.0841  Test loss = 1.4334  Model updated 18 times  \n",
      "\n",
      "Test period = 76  Training loss = 1.0910  Test loss = 0.3177  Model updated 18 times  \n",
      "\n",
      "Test period = 77  Training loss = 0.8963  Test loss = 3.4254  Model updated 19 times  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "retrain_count = 0\n",
    "for t in range(len(test_target)):\n",
    "    x_test = np.reshape(test_features[t], newshape=(1,4,3))\n",
    "    y_test = test_target[t]\n",
    "    test_loss[t] = np.sqrt(sess.run(loss, feed_dict={x:x_test, y:y_test}))\n",
    "    yhat_update[t] = pred.eval(feed_dict={x:x_test})\n",
    "\n",
    "    x_train = all_features[t:(window_length+t)]\n",
    "    y_train = all_target[t:(window_length+t)]\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:x_test, y:y_test})\n",
    "    \n",
    "    print(\"Test period = {0:d}\".format(t+1),\n",
    "      \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "      \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "      \" Model updated {0:d} times\".format(retrain_count),\n",
    "      \" \\n\")\n",
    "\n",
    "    if (t+1)%4==0:\n",
    "        retrain_count += 1\n",
    "        for epoch in range(epoch_hat):\n",
    "            for i in range(total_batch):\n",
    "                optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xcd59668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: updating scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_update, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating scheme RMSE: 2.8814147789 \n",
      "Updating scheme MAE:  1.99510441974\n"
     ]
    }
   ],
   "source": [
    "rmse_update = np.sqrt(np.mean((yhat_update-test_target)**2))\n",
    "mae_update = np.mean(np.abs((yhat_update-test_target)))\n",
    "print(\"Updating scheme RMSE:\", rmse_update,\n",
    "     \"\\nUpdating scheme MAE: \", mae_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + \"yhat_test_fixed.csv\", yhat_test_fixed)\n",
    "np.savetxt(MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + \"yhat_update.csv\", yhat_update)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
