{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Directories\n",
    "MODEL_FOLDER = \"../../../models/lstm/\"\n",
    "MODEL_FILENAME = MODEL_FOLDER + \"4Q/32_units/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: model saver\n",
    "def saveModel(sess, MODEL_FILENAME):\n",
    "    if not os.path.exists(MODEL_FOLDER):\n",
    "        print('Creating path where to save model: ' + MODEL_FOLDER)\n",
    "        os.mkdir(MODEL_FOLDER)\n",
    "\n",
    "    #print('Saving model at: ' + MODEL_FILENAME)\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, MODEL_FILENAME)\n",
    "    #print('Model successfully saved.\\n')\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: model loader\n",
    "def loadModel(sess, MODEL_FILENAME):\n",
    "    if os.path.exists(MODEL_FILENAME + \".index\"):\n",
    "        print('Loading save model from: ' + MODEL_FILENAME)\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, MODEL_FILENAME)\n",
    "        print('Model successfully loaded.\\n')\n",
    "        return True\n",
    "    else:\n",
    "        print('Model file <<' + MODEL_FILENAME + '>> does not exists!')\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Hyperparameters\n",
    "epochs = 500\n",
    "learning_rate = 1e-2\n",
    "batch_size = 5\n",
    "early_stop_iters = 10\n",
    "folds = 32\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 3  # data input\n",
    "n_steps = 4  # timesteps\n",
    "n_hidden = 32 # dimension of recurrent unit\n",
    "\n",
    "# (REPRODUCIBILITY) set random seeds\n",
    "tf.set_random_seed(123)\n",
    "\n",
    "# Define weights and biases\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.truncated_normal([n_hidden, 1], stddev = 1.0 / tf.sqrt(float(n_hidden))),\n",
    "        name='out_weight')\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.zeros([1]),\n",
    "        name='out_bias')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: Build model\n",
    "def RNN(X, weights, biases, n_hidden):\n",
    "\n",
    "    # Define a LSTM cell with tensorflow\n",
    "    lstm_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden, state_is_tuple=True)\n",
    "    outputs, _ = tf.nn.dynamic_rnn(lstm_cell, X, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    out_layer = tf.matmul(outputs[:,-1,:], weights['out']) + biases['out']\n",
    "\n",
    "    return out_layer\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: select batch\n",
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the data...\n",
      "Finished: data loaded. Stats below: \n",
      "Nr of training samples: 193\n",
      "Nr of testing  samples: 77\n",
      "Number of variables: 3\n",
      "Number of lags: 4\n",
      "Window length: 65\n",
      "Number of validation folds: 32\n"
     ]
    }
   ],
   "source": [
    "# =================================\n",
    "# 0. Load dataset\n",
    "# =================================\n",
    "print(\"Loading the data...\")\n",
    "# Training set pre-processing\n",
    "train = pd.read_csv('../../../Data/train.csv')\n",
    "train_4lag_inflation = np.array(train[['inflation.lag4',\n",
    "                                       'inflation.lag5',\n",
    "                                       'inflation.lag6',\n",
    "                                       'inflation.lag7']])\n",
    "train_4lag_unemp = np.array(train[['unemp.lag4',\n",
    "                                   'unemp.lag5',\n",
    "                                   'unemp.lag6',\n",
    "                                   'unemp.lag7']])\n",
    "train_4lag_oil = np.array(train[['oil.lag4',\n",
    "                                 'oil.lag5',\n",
    "                                 'oil.lag6',\n",
    "                                 'oil.lag7']])\n",
    "train_features = np.concatenate((train_4lag_inflation[:,:,np.newaxis], \n",
    "\t                             train_4lag_unemp[:,:,np.newaxis],\n",
    "\t                             train_4lag_oil[:,:,np.newaxis]),\n",
    "\t                             axis=2)\n",
    "train_target = np.array(train['inflation.target'])\n",
    "\n",
    "# Test set pre-processing\n",
    "test = pd.read_csv('../../../Data/test.csv')\n",
    "test_4lag_inflation = np.array(test[['inflation.lag4',\n",
    "                                     'inflation.lag5',\n",
    "                                     'inflation.lag6',\n",
    "                                     'inflation.lag7']])\n",
    "test_4lag_unemp = np.array(test[['unemp.lag4',\n",
    "                                 'unemp.lag5',\n",
    "                                 'unemp.lag6',\n",
    "                                 'unemp.lag7']])\n",
    "test_4lag_oil = np.array(test[['oil.lag4',\n",
    "                               'oil.lag5',\n",
    "                               'oil.lag6',\n",
    "                               'oil.lag7']])\n",
    "test_features = np.concatenate((test_4lag_inflation[:,:,np.newaxis], \n",
    "\t                            test_4lag_unemp[:,:,np.newaxis],\n",
    "\t                            test_4lag_oil[:,:,np.newaxis]),\n",
    "\t                            axis=2)\n",
    "test_target = np.array(test['inflation.target'])\n",
    "\n",
    "(nrTrainSamples, timesteps, variables) = train_features.shape\n",
    "(nrTestSamples, _, _) = test_features.shape\n",
    "\n",
    "# Window length and validation fold index\n",
    "window_length = 65\n",
    "valIndex = np.linspace(start=window_length, stop=nrTrainSamples, \n",
    "                       endpoint=True, num=folds+1, dtype=np.int)\n",
    "\n",
    "print(\"Finished: data loaded. Stats below: \")\n",
    "print(\"Nr of training samples: %d\" % nrTrainSamples)\n",
    "print(\"Nr of testing  samples: %d\" % nrTestSamples)\n",
    "print(\"Number of variables: %d\" % variables)\n",
    "print(\"Number of lags: %d\" % timesteps)\n",
    "print(\"Window length: %d\" % window_length)\n",
    "print(\"Number of validation folds: %d\" % folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 1. Build model\n",
    "# ==================================\n",
    "# tf graph input\n",
    "x = tf.placeholder(\"float\", [None, n_steps, n_input], name='Batch')\n",
    "y = tf.placeholder(\"float\", name='True_labels_of_batch')\n",
    "lr = tf.placeholder(\"float\", name='Learning_rate')\n",
    "\n",
    "# Make predictions with the model\n",
    "pred = RNN(x, weights, biases, n_hidden)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss = tf.reduce_mean(tf.diag_part(tf.square(tf.subtract(x=pred, y=y))))\n",
    "optimizer = tf.train.GradientDescentOptimizer(lr).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training \n",
      "Hyperparameters: \n",
      "Dimension of recurrent unit = 32 \n",
      "Learning rate = 0.01 \n",
      "Epochs = 500 \n",
      "Batch size = 5 \n",
      "Early stopping epochs = 10 \n",
      "Learning rate = 0.01\n",
      "Fold: 1  Epoch: 1  Training loss = 2.7568  Validation loss = 2.3341  \n",
      "\n",
      "Fold: 1  Epoch: 2  Training loss = 2.5618  Validation loss = 1.2994  \n",
      "\n",
      "Fold: 1  Epoch: 3  Training loss = 2.5949  Validation loss = 1.8265  \n",
      "\n",
      "Fold: 1  Epoch: 4  Training loss = 2.6067  Validation loss = 1.9836  \n",
      "\n",
      "Fold: 1  Epoch: 5  Training loss = 2.4985  Validation loss = 1.4848  \n",
      "\n",
      "Fold: 1  Epoch: 6  Training loss = 2.4493  Validation loss = 1.5534  \n",
      "\n",
      "Fold: 1  Epoch: 7  Training loss = 2.4548  Validation loss = 1.8659  \n",
      "\n",
      "Fold: 1  Epoch: 8  Training loss = 2.4019  Validation loss = 1.8107  \n",
      "\n",
      "Fold: 1  Epoch: 9  Training loss = 2.3502  Validation loss = 1.8368  \n",
      "\n",
      "Fold: 1  Epoch: 10  Training loss = 2.3989  Validation loss = 2.1288  \n",
      "\n",
      "Fold: 1  Epoch: 11  Training loss = 2.3356  Validation loss = 2.0433  \n",
      "\n",
      "Fold: 1  Epoch: 12  Training loss = 2.2936  Validation loss = 1.7551  \n",
      "\n",
      "Fold: 1  Epoch: 13  Training loss = 2.3107  Validation loss = 2.1616  \n",
      "\n",
      "Check model:  Fold: 1  Optimal epoch: 2  \n",
      "\n",
      "Fold: 2  Epoch: 1  Training loss = 2.2787  Validation loss = 2.3549  \n",
      "\n",
      "Fold: 2  Epoch: 2  Training loss = 2.1784  Validation loss = 2.2352  \n",
      "\n",
      "Fold: 2  Epoch: 3  Training loss = 2.1571  Validation loss = 2.3454  \n",
      "\n",
      "Fold: 2  Epoch: 4  Training loss = 2.1784  Validation loss = 2.3845  \n",
      "\n",
      "Fold: 2  Epoch: 5  Training loss = 2.2722  Validation loss = 2.0666  \n",
      "\n",
      "Fold: 2  Epoch: 6  Training loss = 2.1538  Validation loss = 2.0483  \n",
      "\n",
      "Fold: 2  Epoch: 7  Training loss = 2.1403  Validation loss = 2.2024  \n",
      "\n",
      "Fold: 2  Epoch: 8  Training loss = 2.1341  Validation loss = 2.5914  \n",
      "\n",
      "Fold: 2  Epoch: 9  Training loss = 2.1269  Validation loss = 2.1371  \n",
      "\n",
      "Fold: 2  Epoch: 10  Training loss = 2.0603  Validation loss = 2.3064  \n",
      "\n",
      "Fold: 2  Epoch: 11  Training loss = 2.0703  Validation loss = 2.4917  \n",
      "\n",
      "Fold: 2  Epoch: 12  Training loss = 2.0154  Validation loss = 2.2740  \n",
      "\n",
      "Fold: 2  Epoch: 13  Training loss = 2.1075  Validation loss = 2.0811  \n",
      "\n",
      "Fold: 2  Epoch: 14  Training loss = 2.0755  Validation loss = 2.0894  \n",
      "\n",
      "Fold: 2  Epoch: 15  Training loss = 1.9969  Validation loss = 1.8390  \n",
      "\n",
      "Fold: 2  Epoch: 16  Training loss = 1.9857  Validation loss = 2.2375  \n",
      "\n",
      "Fold: 2  Epoch: 17  Training loss = 2.0827  Validation loss = 1.8842  \n",
      "\n",
      "Fold: 2  Epoch: 18  Training loss = 1.9291  Validation loss = 2.1289  \n",
      "\n",
      "Fold: 2  Epoch: 19  Training loss = 2.0243  Validation loss = 1.8263  \n",
      "\n",
      "Fold: 2  Epoch: 20  Training loss = 2.0758  Validation loss = 2.1788  \n",
      "\n",
      "Fold: 2  Epoch: 21  Training loss = 2.0641  Validation loss = 2.3066  \n",
      "\n",
      "Check model:  Fold: 2  Optimal epoch: 19  \n",
      "\n",
      "Fold: 3  Epoch: 1  Training loss = 1.3169  Validation loss = 3.7288  \n",
      "\n",
      "Fold: 3  Epoch: 2  Training loss = 1.3143  Validation loss = 3.6679  \n",
      "\n",
      "Fold: 3  Epoch: 3  Training loss = 1.3097  Validation loss = 3.6379  \n",
      "\n",
      "Fold: 3  Epoch: 4  Training loss = 1.2972  Validation loss = 3.3728  \n",
      "\n",
      "Fold: 3  Epoch: 5  Training loss = 1.2925  Validation loss = 3.4397  \n",
      "\n",
      "Fold: 3  Epoch: 6  Training loss = 1.2884  Validation loss = 3.3394  \n",
      "\n",
      "Fold: 3  Epoch: 7  Training loss = 1.2799  Validation loss = 3.4086  \n",
      "\n",
      "Fold: 3  Epoch: 8  Training loss = 1.2700  Validation loss = 3.4835  \n",
      "\n",
      "Fold: 3  Epoch: 9  Training loss = 1.2732  Validation loss = 3.4489  \n",
      "\n",
      "Fold: 3  Epoch: 10  Training loss = 1.3195  Validation loss = 3.6060  \n",
      "\n",
      "Fold: 3  Epoch: 11  Training loss = 1.2626  Validation loss = 3.1616  \n",
      "\n",
      "Fold: 3  Epoch: 12  Training loss = 1.2741  Validation loss = 3.1573  \n",
      "\n",
      "Fold: 3  Epoch: 13  Training loss = 1.2520  Validation loss = 3.2456  \n",
      "\n",
      "Fold: 3  Epoch: 14  Training loss = 1.2302  Validation loss = 3.2758  \n",
      "\n",
      "Fold: 3  Epoch: 15  Training loss = 1.2186  Validation loss = 3.3099  \n",
      "\n",
      "Fold: 3  Epoch: 16  Training loss = 1.2142  Validation loss = 3.1343  \n",
      "\n",
      "Fold: 3  Epoch: 17  Training loss = 1.2787  Validation loss = 3.8249  \n",
      "\n",
      "Check model:  Fold: 3  Optimal epoch: 16  \n",
      "\n",
      "Fold: 4  Epoch: 1  Training loss = 1.3884  Validation loss = 3.9217  \n",
      "\n",
      "Fold: 4  Epoch: 2  Training loss = 1.3193  Validation loss = 3.4256  \n",
      "\n",
      "Fold: 4  Epoch: 3  Training loss = 1.3077  Validation loss = 3.4139  \n",
      "\n",
      "Fold: 4  Epoch: 4  Training loss = 1.2771  Validation loss = 3.3394  \n",
      "\n",
      "Fold: 4  Epoch: 5  Training loss = 1.2777  Validation loss = 2.6431  \n",
      "\n",
      "Fold: 4  Epoch: 6  Training loss = 1.2220  Validation loss = 2.7851  \n",
      "\n",
      "Fold: 4  Epoch: 7  Training loss = 1.2156  Validation loss = 2.7765  \n",
      "\n",
      "Fold: 4  Epoch: 8  Training loss = 1.1950  Validation loss = 2.6180  \n",
      "\n",
      "Fold: 4  Epoch: 9  Training loss = 1.3492  Validation loss = 2.6763  \n",
      "\n",
      "Fold: 4  Epoch: 10  Training loss = 1.2362  Validation loss = 2.2412  \n",
      "\n",
      "Fold: 4  Epoch: 11  Training loss = 1.1602  Validation loss = 2.4218  \n",
      "\n",
      "Fold: 4  Epoch: 12  Training loss = 1.1939  Validation loss = 2.2616  \n",
      "\n",
      "Fold: 4  Epoch: 13  Training loss = 1.2818  Validation loss = 2.3908  \n",
      "\n",
      "Fold: 4  Epoch: 14  Training loss = 1.1660  Validation loss = 1.9733  \n",
      "\n",
      "Fold: 4  Epoch: 15  Training loss = 1.1385  Validation loss = 3.0097  \n",
      "\n",
      "Check model:  Fold: 4  Optimal epoch: 14  \n",
      "\n",
      "Fold: 5  Epoch: 1  Training loss = 1.1352  Validation loss = 2.7347  \n",
      "\n",
      "Fold: 5  Epoch: 2  Training loss = 1.0910  Validation loss = 2.5130  \n",
      "\n",
      "Fold: 5  Epoch: 3  Training loss = 1.0483  Validation loss = 2.5952  \n",
      "\n",
      "Fold: 5  Epoch: 4  Training loss = 1.0493  Validation loss = 2.5320  \n",
      "\n",
      "Fold: 5  Epoch: 5  Training loss = 1.0564  Validation loss = 2.7871  \n",
      "\n",
      "Fold: 5  Epoch: 6  Training loss = 1.0292  Validation loss = 2.7322  \n",
      "\n",
      "Fold: 5  Epoch: 7  Training loss = 1.0205  Validation loss = 2.5057  \n",
      "\n",
      "Fold: 5  Epoch: 8  Training loss = 1.0106  Validation loss = 2.5367  \n",
      "\n",
      "Fold: 5  Epoch: 9  Training loss = 1.0331  Validation loss = 2.6041  \n",
      "\n",
      "Fold: 5  Epoch: 10  Training loss = 1.0415  Validation loss = 2.6858  \n",
      "\n",
      "Fold: 5  Epoch: 11  Training loss = 1.0071  Validation loss = 2.1190  \n",
      "\n",
      "Fold: 5  Epoch: 12  Training loss = 1.0062  Validation loss = 2.1242  \n",
      "\n",
      "Fold: 5  Epoch: 13  Training loss = 0.9814  Validation loss = 2.6353  \n",
      "\n",
      "Fold: 5  Epoch: 14  Training loss = 1.0491  Validation loss = 2.3635  \n",
      "\n",
      "Fold: 5  Epoch: 15  Training loss = 0.9709  Validation loss = 2.4304  \n",
      "\n",
      "Fold: 5  Epoch: 16  Training loss = 1.0134  Validation loss = 2.0958  \n",
      "\n",
      "Fold: 5  Epoch: 17  Training loss = 1.0132  Validation loss = 2.1333  \n",
      "\n",
      "Fold: 5  Epoch: 18  Training loss = 0.9790  Validation loss = 2.0867  \n",
      "\n",
      "Fold: 5  Epoch: 19  Training loss = 0.9999  Validation loss = 1.9689  \n",
      "\n",
      "Fold: 5  Epoch: 20  Training loss = 0.9542  Validation loss = 2.1123  \n",
      "\n",
      "Fold: 5  Epoch: 21  Training loss = 0.9780  Validation loss = 2.0441  \n",
      "\n",
      "Fold: 5  Epoch: 22  Training loss = 0.9496  Validation loss = 2.4443  \n",
      "\n",
      "Fold: 5  Epoch: 23  Training loss = 0.9501  Validation loss = 2.5127  \n",
      "\n",
      "Check model:  Fold: 5  Optimal epoch: 19  \n",
      "\n",
      "Fold: 6  Epoch: 1  Training loss = 1.0120  Validation loss = 1.4402  \n",
      "\n",
      "Fold: 6  Epoch: 2  Training loss = 1.2247  Validation loss = 1.9130  \n",
      "\n",
      "Fold: 6  Epoch: 3  Training loss = 1.0395  Validation loss = 1.6446  \n",
      "\n",
      "Fold: 6  Epoch: 4  Training loss = 1.0091  Validation loss = 1.4621  \n",
      "\n",
      "Fold: 6  Epoch: 5  Training loss = 0.9690  Validation loss = 1.3448  \n",
      "\n",
      "Fold: 6  Epoch: 6  Training loss = 0.9594  Validation loss = 1.3050  \n",
      "\n",
      "Fold: 6  Epoch: 7  Training loss = 1.0005  Validation loss = 1.2870  \n",
      "\n",
      "Fold: 6  Epoch: 8  Training loss = 0.9260  Validation loss = 1.8089  \n",
      "\n",
      "Fold: 6  Epoch: 9  Training loss = 0.9115  Validation loss = 1.5878  \n",
      "\n",
      "Fold: 6  Epoch: 10  Training loss = 1.0585  Validation loss = 1.4617  \n",
      "\n",
      "Fold: 6  Epoch: 11  Training loss = 0.9324  Validation loss = 1.2974  \n",
      "\n",
      "Fold: 6  Epoch: 12  Training loss = 0.9309  Validation loss = 1.5954  \n",
      "\n",
      "Fold: 6  Epoch: 13  Training loss = 0.8789  Validation loss = 1.5319  \n",
      "\n",
      "Fold: 6  Epoch: 14  Training loss = 0.8690  Validation loss = 1.4287  \n",
      "\n",
      "Fold: 6  Epoch: 15  Training loss = 0.9078  Validation loss = 1.5028  \n",
      "\n",
      "Fold: 6  Epoch: 16  Training loss = 0.9335  Validation loss = 1.2140  \n",
      "\n",
      "Fold: 6  Epoch: 17  Training loss = 0.8920  Validation loss = 1.4586  \n",
      "\n",
      "Fold: 6  Epoch: 18  Training loss = 0.8502  Validation loss = 1.4701  \n",
      "\n",
      "Fold: 6  Epoch: 19  Training loss = 0.8640  Validation loss = 1.8335  \n",
      "\n",
      "Check model:  Fold: 6  Optimal epoch: 16  \n",
      "\n",
      "Fold: 7  Epoch: 1  Training loss = 0.9699  Validation loss = 2.7443  \n",
      "\n",
      "Fold: 7  Epoch: 2  Training loss = 1.0934  Validation loss = 2.8210  \n",
      "\n",
      "Fold: 7  Epoch: 3  Training loss = 0.9321  Validation loss = 2.7503  \n",
      "\n",
      "Fold: 7  Epoch: 4  Training loss = 0.8969  Validation loss = 2.6561  \n",
      "\n",
      "Fold: 7  Epoch: 5  Training loss = 0.9403  Validation loss = 2.6113  \n",
      "\n",
      "Fold: 7  Epoch: 6  Training loss = 0.9795  Validation loss = 2.5349  \n",
      "\n",
      "Fold: 7  Epoch: 7  Training loss = 0.9050  Validation loss = 2.5300  \n",
      "\n",
      "Fold: 7  Epoch: 8  Training loss = 0.9307  Validation loss = 2.4741  \n",
      "\n",
      "Fold: 7  Epoch: 9  Training loss = 0.8949  Validation loss = 2.5163  \n",
      "\n",
      "Fold: 7  Epoch: 10  Training loss = 0.9047  Validation loss = 2.5466  \n",
      "\n",
      "Fold: 7  Epoch: 11  Training loss = 0.9085  Validation loss = 2.5898  \n",
      "\n",
      "Fold: 7  Epoch: 12  Training loss = 0.8888  Validation loss = 2.5669  \n",
      "\n",
      "Fold: 7  Epoch: 13  Training loss = 0.8698  Validation loss = 2.6193  \n",
      "\n",
      "Fold: 7  Epoch: 14  Training loss = 0.9707  Validation loss = 2.6813  \n",
      "\n",
      "Check model:  Fold: 7  Optimal epoch: 8  \n",
      "\n",
      "Fold: 8  Epoch: 1  Training loss = 1.0474  Validation loss = 7.2683  \n",
      "\n",
      "Fold: 8  Epoch: 2  Training loss = 1.0296  Validation loss = 7.1188  \n",
      "\n",
      "Fold: 8  Epoch: 3  Training loss = 1.0177  Validation loss = 7.0608  \n",
      "\n",
      "Fold: 8  Epoch: 4  Training loss = 1.0199  Validation loss = 7.1064  \n",
      "\n",
      "Fold: 8  Epoch: 5  Training loss = 1.0276  Validation loss = 7.2351  \n",
      "\n",
      "Fold: 8  Epoch: 6  Training loss = 1.0531  Validation loss = 7.3307  \n",
      "\n",
      "Fold: 8  Epoch: 7  Training loss = 1.0087  Validation loss = 7.2490  \n",
      "\n",
      "Fold: 8  Epoch: 8  Training loss = 0.9954  Validation loss = 7.2288  \n",
      "\n",
      "Fold: 8  Epoch: 9  Training loss = 0.9874  Validation loss = 7.2754  \n",
      "\n",
      "Fold: 8  Epoch: 10  Training loss = 1.1528  Validation loss = 6.0260  \n",
      "\n",
      "Fold: 8  Epoch: 11  Training loss = 1.0482  Validation loss = 7.4378  \n",
      "\n",
      "Check model:  Fold: 8  Optimal epoch: 10  \n",
      "\n",
      "Fold: 9  Epoch: 1  Training loss = 1.8963  Validation loss = 7.7512  \n",
      "\n",
      "Fold: 9  Epoch: 2  Training loss = 1.7549  Validation loss = 7.5758  \n",
      "\n",
      "Fold: 9  Epoch: 3  Training loss = 1.6820  Validation loss = 7.0163  \n",
      "\n",
      "Fold: 9  Epoch: 4  Training loss = 1.6962  Validation loss = 7.5716  \n",
      "\n",
      "Fold: 9  Epoch: 5  Training loss = 1.6332  Validation loss = 7.7345  \n",
      "\n",
      "Fold: 9  Epoch: 6  Training loss = 1.7013  Validation loss = 7.6179  \n",
      "\n",
      "Fold: 9  Epoch: 7  Training loss = 1.6253  Validation loss = 7.3847  \n",
      "\n",
      "Fold: 9  Epoch: 8  Training loss = 1.7682  Validation loss = 6.6168  \n",
      "\n",
      "Fold: 9  Epoch: 9  Training loss = 1.5412  Validation loss = 6.9081  \n",
      "\n",
      "Fold: 9  Epoch: 10  Training loss = 1.6176  Validation loss = 6.9947  \n",
      "\n",
      "Fold: 9  Epoch: 11  Training loss = 1.4864  Validation loss = 7.0858  \n",
      "\n",
      "Fold: 9  Epoch: 12  Training loss = 1.6356  Validation loss = 7.2772  \n",
      "\n",
      "Fold: 9  Epoch: 13  Training loss = 1.5135  Validation loss = 7.4514  \n",
      "\n",
      "Fold: 9  Epoch: 14  Training loss = 1.4973  Validation loss = 6.9523  \n",
      "\n",
      "Fold: 9  Epoch: 15  Training loss = 1.4891  Validation loss = 7.3140  \n",
      "\n",
      "Fold: 9  Epoch: 16  Training loss = 1.4324  Validation loss = 7.5123  \n",
      "\n",
      "Check model:  Fold: 9  Optimal epoch: 8  \n",
      "\n",
      "Fold: 10  Epoch: 1  Training loss = 2.1983  Validation loss = 4.3778  \n",
      "\n",
      "Fold: 10  Epoch: 2  Training loss = 2.0163  Validation loss = 3.4710  \n",
      "\n",
      "Fold: 10  Epoch: 3  Training loss = 2.0746  Validation loss = 3.8759  \n",
      "\n",
      "Fold: 10  Epoch: 4  Training loss = 2.4037  Validation loss = 3.5947  \n",
      "\n",
      "Fold: 10  Epoch: 5  Training loss = 2.0681  Validation loss = 4.2395  \n",
      "\n",
      "Fold: 10  Epoch: 6  Training loss = 2.0152  Validation loss = 4.7280  \n",
      "\n",
      "Fold: 10  Epoch: 7  Training loss = 2.0299  Validation loss = 4.7973  \n",
      "\n",
      "Fold: 10  Epoch: 8  Training loss = 2.1959  Validation loss = 4.8022  \n",
      "\n",
      "Fold: 10  Epoch: 9  Training loss = 2.0119  Validation loss = 4.0287  \n",
      "\n",
      "Fold: 10  Epoch: 10  Training loss = 1.9481  Validation loss = 4.1574  \n",
      "\n",
      "Fold: 10  Epoch: 11  Training loss = 2.0532  Validation loss = 4.1837  \n",
      "\n",
      "Fold: 10  Epoch: 12  Training loss = 1.8000  Validation loss = 4.0221  \n",
      "\n",
      "Fold: 10  Epoch: 13  Training loss = 1.9095  Validation loss = 4.1069  \n",
      "\n",
      "Fold: 10  Epoch: 14  Training loss = 1.8079  Validation loss = 4.1508  \n",
      "\n",
      "Fold: 10  Epoch: 15  Training loss = 1.7506  Validation loss = 3.8341  \n",
      "\n",
      "Fold: 10  Epoch: 16  Training loss = 1.9544  Validation loss = 4.1112  \n",
      "\n",
      "Fold: 10  Epoch: 17  Training loss = 1.7747  Validation loss = 4.5755  \n",
      "\n",
      "Fold: 10  Epoch: 18  Training loss = 1.7639  Validation loss = 4.0724  \n",
      "\n",
      "Fold: 10  Epoch: 19  Training loss = 1.8248  Validation loss = 4.1242  \n",
      "\n",
      "Fold: 10  Epoch: 20  Training loss = 2.0491  Validation loss = 3.7974  \n",
      "\n",
      "Fold: 10  Epoch: 21  Training loss = 1.7423  Validation loss = 4.1354  \n",
      "\n",
      "Fold: 10  Epoch: 22  Training loss = 1.5896  Validation loss = 3.4712  \n",
      "\n",
      "Fold: 10  Epoch: 23  Training loss = 1.5729  Validation loss = 3.2510  \n",
      "\n",
      "Fold: 10  Epoch: 24  Training loss = 1.5920  Validation loss = 3.5089  \n",
      "\n",
      "Fold: 10  Epoch: 25  Training loss = 1.6698  Validation loss = 3.1077  \n",
      "\n",
      "Fold: 10  Epoch: 26  Training loss = 1.5326  Validation loss = 3.4956  \n",
      "\n",
      "Fold: 10  Epoch: 27  Training loss = 1.7323  Validation loss = 3.0641  \n",
      "\n",
      "Fold: 10  Epoch: 28  Training loss = 1.9447  Validation loss = 2.4669  \n",
      "\n",
      "Fold: 10  Epoch: 29  Training loss = 1.6722  Validation loss = 3.3530  \n",
      "\n",
      "Fold: 10  Epoch: 30  Training loss = 1.5856  Validation loss = 3.8465  \n",
      "\n",
      "Fold: 10  Epoch: 31  Training loss = 1.6114  Validation loss = 4.0049  \n",
      "\n",
      "Check model:  Fold: 10  Optimal epoch: 28  \n",
      "\n",
      "Fold: 11  Epoch: 1  Training loss = 1.5420  Validation loss = 1.2685  \n",
      "\n",
      "Fold: 11  Epoch: 2  Training loss = 1.7139  Validation loss = 2.6626  \n",
      "\n",
      "Fold: 11  Epoch: 3  Training loss = 1.5441  Validation loss = 2.3589  \n",
      "\n",
      "Fold: 11  Epoch: 4  Training loss = 1.4997  Validation loss = 2.5982  \n",
      "\n",
      "Fold: 11  Epoch: 5  Training loss = 1.5275  Validation loss = 2.9696  \n",
      "\n",
      "Fold: 11  Epoch: 6  Training loss = 1.4564  Validation loss = 2.4974  \n",
      "\n",
      "Fold: 11  Epoch: 7  Training loss = 1.5963  Validation loss = 2.5085  \n",
      "\n",
      "Fold: 11  Epoch: 8  Training loss = 1.5729  Validation loss = 2.3638  \n",
      "\n",
      "Fold: 11  Epoch: 9  Training loss = 1.6474  Validation loss = 3.3226  \n",
      "\n",
      "Fold: 11  Epoch: 10  Training loss = 1.4209  Validation loss = 2.7859  \n",
      "\n",
      "Fold: 11  Epoch: 11  Training loss = 1.3305  Validation loss = 2.8240  \n",
      "\n",
      "Fold: 11  Epoch: 12  Training loss = 1.5662  Validation loss = 2.9673  \n",
      "\n",
      "Fold: 11  Epoch: 13  Training loss = 1.3036  Validation loss = 2.2640  \n",
      "\n",
      "Fold: 11  Epoch: 14  Training loss = 1.4816  Validation loss = 2.6365  \n",
      "\n",
      "Fold: 11  Epoch: 15  Training loss = 1.2991  Validation loss = 3.2867  \n",
      "\n",
      "Fold: 11  Epoch: 16  Training loss = 1.3006  Validation loss = 2.6231  \n",
      "\n",
      "Fold: 11  Epoch: 17  Training loss = 1.2185  Validation loss = 2.9218  \n",
      "\n",
      "Fold: 11  Epoch: 18  Training loss = 1.3040  Validation loss = 2.2873  \n",
      "\n",
      "Fold: 11  Epoch: 19  Training loss = 1.2796  Validation loss = 2.3711  \n",
      "\n",
      "Fold: 11  Epoch: 20  Training loss = 1.5093  Validation loss = 3.1106  \n",
      "\n",
      "Fold: 11  Epoch: 21  Training loss = 1.4550  Validation loss = 2.7127  \n",
      "\n",
      "Fold: 11  Epoch: 22  Training loss = 1.2080  Validation loss = 2.7002  \n",
      "\n",
      "Fold: 11  Epoch: 23  Training loss = 1.4266  Validation loss = 2.2515  \n",
      "\n",
      "Fold: 11  Epoch: 24  Training loss = 1.7382  Validation loss = 2.3206  \n",
      "\n",
      "Fold: 11  Epoch: 25  Training loss = 1.4031  Validation loss = 2.2299  \n",
      "\n",
      "Fold: 11  Epoch: 26  Training loss = 1.5360  Validation loss = 3.6430  \n",
      "\n",
      "Check model:  Fold: 11  Optimal epoch: 1  \n",
      "\n",
      "Fold: 12  Epoch: 1  Training loss = 1.4162  Validation loss = 4.7231  \n",
      "\n",
      "Fold: 12  Epoch: 2  Training loss = 1.3436  Validation loss = 4.3847  \n",
      "\n",
      "Fold: 12  Epoch: 3  Training loss = 1.4111  Validation loss = 3.7703  \n",
      "\n",
      "Fold: 12  Epoch: 4  Training loss = 1.2470  Validation loss = 3.9565  \n",
      "\n",
      "Fold: 12  Epoch: 5  Training loss = 1.5217  Validation loss = 4.7391  \n",
      "\n",
      "Fold: 12  Epoch: 6  Training loss = 1.1712  Validation loss = 4.8606  \n",
      "\n",
      "Fold: 12  Epoch: 7  Training loss = 1.1812  Validation loss = 4.5457  \n",
      "\n",
      "Fold: 12  Epoch: 8  Training loss = 1.2752  Validation loss = 4.4718  \n",
      "\n",
      "Fold: 12  Epoch: 9  Training loss = 1.2272  Validation loss = 3.6847  \n",
      "\n",
      "Fold: 12  Epoch: 10  Training loss = 1.1133  Validation loss = 4.2195  \n",
      "\n",
      "Fold: 12  Epoch: 11  Training loss = 1.3852  Validation loss = 4.2883  \n",
      "\n",
      "Fold: 12  Epoch: 12  Training loss = 1.2627  Validation loss = 4.0342  \n",
      "\n",
      "Fold: 12  Epoch: 13  Training loss = 1.3166  Validation loss = 4.5082  \n",
      "\n",
      "Fold: 12  Epoch: 14  Training loss = 1.1187  Validation loss = 3.9815  \n",
      "\n",
      "Fold: 12  Epoch: 15  Training loss = 1.0915  Validation loss = 3.8812  \n",
      "\n",
      "Fold: 12  Epoch: 16  Training loss = 1.0866  Validation loss = 4.3514  \n",
      "\n",
      "Fold: 12  Epoch: 17  Training loss = 1.1943  Validation loss = 4.1461  \n",
      "\n",
      "Fold: 12  Epoch: 18  Training loss = 1.4102  Validation loss = 3.0433  \n",
      "\n",
      "Fold: 12  Epoch: 19  Training loss = 1.2873  Validation loss = 4.2152  \n",
      "\n",
      "Fold: 12  Epoch: 20  Training loss = 1.5140  Validation loss = 4.0595  \n",
      "\n",
      "Fold: 12  Epoch: 21  Training loss = 1.2259  Validation loss = 3.6994  \n",
      "\n",
      "Fold: 12  Epoch: 22  Training loss = 1.2591  Validation loss = 4.4846  \n",
      "\n",
      "Fold: 12  Epoch: 23  Training loss = 1.2140  Validation loss = 3.9579  \n",
      "\n",
      "Fold: 12  Epoch: 24  Training loss = 1.1291  Validation loss = 3.4370  \n",
      "\n",
      "Fold: 12  Epoch: 25  Training loss = 1.1682  Validation loss = 3.1153  \n",
      "\n",
      "Fold: 12  Epoch: 26  Training loss = 1.2230  Validation loss = 3.0833  \n",
      "\n",
      "Fold: 12  Epoch: 27  Training loss = 1.0294  Validation loss = 3.4518  \n",
      "\n",
      "Fold: 12  Epoch: 28  Training loss = 1.3485  Validation loss = 3.4955  \n",
      "\n",
      "Fold: 12  Epoch: 29  Training loss = 1.1336  Validation loss = 3.9036  \n",
      "\n",
      "Fold: 12  Epoch: 30  Training loss = 0.9609  Validation loss = 3.5183  \n",
      "\n",
      "Fold: 12  Epoch: 31  Training loss = 0.9445  Validation loss = 3.7514  \n",
      "\n",
      "Fold: 12  Epoch: 32  Training loss = 1.0841  Validation loss = 4.3117  \n",
      "\n",
      "Check model:  Fold: 12  Optimal epoch: 18  \n",
      "\n",
      "Fold: 13  Epoch: 1  Training loss = 1.8118  Validation loss = 6.4583  \n",
      "\n",
      "Fold: 13  Epoch: 2  Training loss = 1.6129  Validation loss = 4.5500  \n",
      "\n",
      "Fold: 13  Epoch: 3  Training loss = 1.4517  Validation loss = 3.5348  \n",
      "\n",
      "Fold: 13  Epoch: 4  Training loss = 1.4915  Validation loss = 3.5216  \n",
      "\n",
      "Fold: 13  Epoch: 5  Training loss = 1.3629  Validation loss = 4.2815  \n",
      "\n",
      "Fold: 13  Epoch: 6  Training loss = 1.2894  Validation loss = 2.8876  \n",
      "\n",
      "Fold: 13  Epoch: 7  Training loss = 1.2501  Validation loss = 3.1225  \n",
      "\n",
      "Fold: 13  Epoch: 8  Training loss = 1.4695  Validation loss = 2.6639  \n",
      "\n",
      "Fold: 13  Epoch: 9  Training loss = 1.1658  Validation loss = 3.6772  \n",
      "\n",
      "Fold: 13  Epoch: 10  Training loss = 1.4533  Validation loss = 2.5259  \n",
      "\n",
      "Fold: 13  Epoch: 11  Training loss = 1.1621  Validation loss = 4.1764  \n",
      "\n",
      "Fold: 13  Epoch: 12  Training loss = 1.3794  Validation loss = 2.8971  \n",
      "\n",
      "Fold: 13  Epoch: 13  Training loss = 1.2533  Validation loss = 3.3183  \n",
      "\n",
      "Fold: 13  Epoch: 14  Training loss = 1.4872  Validation loss = 3.6972  \n",
      "\n",
      "Fold: 13  Epoch: 15  Training loss = 1.2338  Validation loss = 3.5143  \n",
      "\n",
      "Fold: 13  Epoch: 16  Training loss = 1.1053  Validation loss = 3.4854  \n",
      "\n",
      "Fold: 13  Epoch: 17  Training loss = 1.0166  Validation loss = 3.3880  \n",
      "\n",
      "Fold: 13  Epoch: 18  Training loss = 1.4551  Validation loss = 2.5650  \n",
      "\n",
      "Fold: 13  Epoch: 19  Training loss = 1.1093  Validation loss = 2.6051  \n",
      "\n",
      "Fold: 13  Epoch: 20  Training loss = 0.9344  Validation loss = 3.1918  \n",
      "\n",
      "Fold: 13  Epoch: 21  Training loss = 1.2126  Validation loss = 2.7751  \n",
      "\n",
      "Fold: 13  Epoch: 22  Training loss = 1.0006  Validation loss = 2.9246  \n",
      "\n",
      "Fold: 13  Epoch: 23  Training loss = 1.1641  Validation loss = 3.6630  \n",
      "\n",
      "Fold: 13  Epoch: 24  Training loss = 1.0580  Validation loss = 3.5449  \n",
      "\n",
      "Fold: 13  Epoch: 25  Training loss = 0.9228  Validation loss = 3.2422  \n",
      "\n",
      "Fold: 13  Epoch: 26  Training loss = 0.8586  Validation loss = 3.1867  \n",
      "\n",
      "Fold: 13  Epoch: 27  Training loss = 0.8900  Validation loss = 3.2605  \n",
      "\n",
      "Fold: 13  Epoch: 28  Training loss = 0.9094  Validation loss = 3.0055  \n",
      "\n",
      "Fold: 13  Epoch: 29  Training loss = 0.8977  Validation loss = 3.2489  \n",
      "\n",
      "Fold: 13  Epoch: 30  Training loss = 1.0470  Validation loss = 3.5342  \n",
      "\n",
      "Fold: 13  Epoch: 31  Training loss = 0.8167  Validation loss = 3.2200  \n",
      "\n",
      "Fold: 13  Epoch: 32  Training loss = 0.7847  Validation loss = 2.8598  \n",
      "\n",
      "Fold: 13  Epoch: 33  Training loss = 0.7798  Validation loss = 2.8795  \n",
      "\n",
      "Fold: 13  Epoch: 34  Training loss = 0.8770  Validation loss = 2.7415  \n",
      "\n",
      "Fold: 13  Epoch: 35  Training loss = 0.7540  Validation loss = 3.1137  \n",
      "\n",
      "Fold: 13  Epoch: 36  Training loss = 1.0558  Validation loss = 3.3265  \n",
      "\n",
      "Fold: 13  Epoch: 37  Training loss = 0.9147  Validation loss = 3.8753  \n",
      "\n",
      "Check model:  Fold: 13  Optimal epoch: 10  \n",
      "\n",
      "Fold: 14  Epoch: 1  Training loss = 1.6228  Validation loss = 5.9670  \n",
      "\n",
      "Fold: 14  Epoch: 2  Training loss = 1.1828  Validation loss = 3.9616  \n",
      "\n",
      "Fold: 14  Epoch: 3  Training loss = 1.0377  Validation loss = 4.7864  \n",
      "\n",
      "Fold: 14  Epoch: 4  Training loss = 1.5206  Validation loss = 6.0564  \n",
      "\n",
      "Fold: 14  Epoch: 5  Training loss = 1.1367  Validation loss = 4.0689  \n",
      "\n",
      "Fold: 14  Epoch: 6  Training loss = 1.1633  Validation loss = 3.4784  \n",
      "\n",
      "Fold: 14  Epoch: 7  Training loss = 1.0912  Validation loss = 3.6540  \n",
      "\n",
      "Fold: 14  Epoch: 8  Training loss = 0.9523  Validation loss = 4.1046  \n",
      "\n",
      "Fold: 14  Epoch: 9  Training loss = 0.9010  Validation loss = 4.1699  \n",
      "\n",
      "Fold: 14  Epoch: 10  Training loss = 1.3393  Validation loss = 3.4471  \n",
      "\n",
      "Fold: 14  Epoch: 11  Training loss = 1.0032  Validation loss = 3.9263  \n",
      "\n",
      "Fold: 14  Epoch: 12  Training loss = 0.9139  Validation loss = 4.1377  \n",
      "\n",
      "Fold: 14  Epoch: 13  Training loss = 1.1915  Validation loss = 5.3805  \n",
      "\n",
      "Fold: 14  Epoch: 14  Training loss = 1.4871  Validation loss = 3.3558  \n",
      "\n",
      "Fold: 14  Epoch: 15  Training loss = 0.9994  Validation loss = 4.6712  \n",
      "\n",
      "Fold: 14  Epoch: 16  Training loss = 0.9495  Validation loss = 4.7630  \n",
      "\n",
      "Fold: 14  Epoch: 17  Training loss = 0.9796  Validation loss = 4.7168  \n",
      "\n",
      "Fold: 14  Epoch: 18  Training loss = 0.9108  Validation loss = 3.8739  \n",
      "\n",
      "Fold: 14  Epoch: 19  Training loss = 1.0683  Validation loss = 5.5686  \n",
      "\n",
      "Check model:  Fold: 14  Optimal epoch: 14  \n",
      "\n",
      "Fold: 15  Epoch: 1  Training loss = 1.2855  Validation loss = 6.2904  \n",
      "\n",
      "Fold: 15  Epoch: 2  Training loss = 1.4370  Validation loss = 7.3062  \n",
      "\n",
      "Fold: 15  Epoch: 3  Training loss = 1.2762  Validation loss = 6.9148  \n",
      "\n",
      "Fold: 15  Epoch: 4  Training loss = 1.3105  Validation loss = 6.5926  \n",
      "\n",
      "Fold: 15  Epoch: 5  Training loss = 1.2694  Validation loss = 6.1424  \n",
      "\n",
      "Fold: 15  Epoch: 6  Training loss = 1.2572  Validation loss = 6.4262  \n",
      "\n",
      "Fold: 15  Epoch: 7  Training loss = 1.3155  Validation loss = 5.5424  \n",
      "\n",
      "Fold: 15  Epoch: 8  Training loss = 1.2612  Validation loss = 6.7494  \n",
      "\n",
      "Fold: 15  Epoch: 9  Training loss = 1.2392  Validation loss = 6.2573  \n",
      "\n",
      "Fold: 15  Epoch: 10  Training loss = 1.1034  Validation loss = 6.0752  \n",
      "\n",
      "Fold: 15  Epoch: 11  Training loss = 1.1378  Validation loss = 6.9730  \n",
      "\n",
      "Fold: 15  Epoch: 12  Training loss = 1.2735  Validation loss = 7.1343  \n",
      "\n",
      "Check model:  Fold: 15  Optimal epoch: 7  \n",
      "\n",
      "Fold: 16  Epoch: 1  Training loss = 1.9938  Validation loss = 6.6815  \n",
      "\n",
      "Fold: 16  Epoch: 2  Training loss = 1.9170  Validation loss = 6.2489  \n",
      "\n",
      "Fold: 16  Epoch: 3  Training loss = 2.3613  Validation loss = 6.7343  \n",
      "\n",
      "Fold: 16  Epoch: 4  Training loss = 1.8358  Validation loss = 5.9844  \n",
      "\n",
      "Fold: 16  Epoch: 5  Training loss = 1.6325  Validation loss = 6.4906  \n",
      "\n",
      "Fold: 16  Epoch: 6  Training loss = 1.8358  Validation loss = 5.2840  \n",
      "\n",
      "Fold: 16  Epoch: 7  Training loss = 1.9304  Validation loss = 5.3745  \n",
      "\n",
      "Fold: 16  Epoch: 8  Training loss = 2.1246  Validation loss = 6.1472  \n",
      "\n",
      "Fold: 16  Epoch: 9  Training loss = 1.7027  Validation loss = 6.1918  \n",
      "\n",
      "Fold: 16  Epoch: 10  Training loss = 1.6345  Validation loss = 5.7940  \n",
      "\n",
      "Fold: 16  Epoch: 11  Training loss = 1.5257  Validation loss = 5.9491  \n",
      "\n",
      "Fold: 16  Epoch: 12  Training loss = 1.6113  Validation loss = 5.9311  \n",
      "\n",
      "Fold: 16  Epoch: 13  Training loss = 1.4275  Validation loss = 5.8165  \n",
      "\n",
      "Fold: 16  Epoch: 14  Training loss = 1.5739  Validation loss = 5.7539  \n",
      "\n",
      "Fold: 16  Epoch: 15  Training loss = 1.7835  Validation loss = 7.1778  \n",
      "\n",
      "Check model:  Fold: 16  Optimal epoch: 6  \n",
      "\n",
      "Fold: 17  Epoch: 1  Training loss = 2.2889  Validation loss = 3.4828  \n",
      "\n",
      "Fold: 17  Epoch: 2  Training loss = 2.2233  Validation loss = 4.7843  \n",
      "\n",
      "Fold: 17  Epoch: 3  Training loss = 2.0288  Validation loss = 3.9410  \n",
      "\n",
      "Fold: 17  Epoch: 4  Training loss = 1.9516  Validation loss = 3.6048  \n",
      "\n",
      "Fold: 17  Epoch: 5  Training loss = 2.0922  Validation loss = 3.4519  \n",
      "\n",
      "Fold: 17  Epoch: 6  Training loss = 1.7546  Validation loss = 2.7054  \n",
      "\n",
      "Fold: 17  Epoch: 7  Training loss = 1.6796  Validation loss = 3.3787  \n",
      "\n",
      "Fold: 17  Epoch: 8  Training loss = 1.6745  Validation loss = 3.1891  \n",
      "\n",
      "Fold: 17  Epoch: 9  Training loss = 1.8184  Validation loss = 3.9350  \n",
      "\n",
      "Fold: 17  Epoch: 10  Training loss = 1.9560  Validation loss = 2.6292  \n",
      "\n",
      "Fold: 17  Epoch: 11  Training loss = 1.8346  Validation loss = 2.9419  \n",
      "\n",
      "Fold: 17  Epoch: 12  Training loss = 2.1945  Validation loss = 3.4300  \n",
      "\n",
      "Fold: 17  Epoch: 13  Training loss = 1.6309  Validation loss = 3.6240  \n",
      "\n",
      "Fold: 17  Epoch: 14  Training loss = 1.7395  Validation loss = 3.1119  \n",
      "\n",
      "Fold: 17  Epoch: 15  Training loss = 1.5109  Validation loss = 3.3035  \n",
      "\n",
      "Fold: 17  Epoch: 16  Training loss = 1.5604  Validation loss = 3.7494  \n",
      "\n",
      "Fold: 17  Epoch: 17  Training loss = 1.6154  Validation loss = 4.2560  \n",
      "\n",
      "Check model:  Fold: 17  Optimal epoch: 10  \n",
      "\n",
      "Fold: 18  Epoch: 1  Training loss = 1.6384  Validation loss = 2.5909  \n",
      "\n",
      "Fold: 18  Epoch: 2  Training loss = 1.7081  Validation loss = 2.3478  \n",
      "\n",
      "Fold: 18  Epoch: 3  Training loss = 1.7811  Validation loss = 2.4378  \n",
      "\n",
      "Fold: 18  Epoch: 4  Training loss = 1.6563  Validation loss = 2.5582  \n",
      "\n",
      "Fold: 18  Epoch: 5  Training loss = 1.6589  Validation loss = 2.6256  \n",
      "\n",
      "Fold: 18  Epoch: 6  Training loss = 1.5199  Validation loss = 2.7006  \n",
      "\n",
      "Fold: 18  Epoch: 7  Training loss = 1.5178  Validation loss = 2.7469  \n",
      "\n",
      "Fold: 18  Epoch: 8  Training loss = 1.5354  Validation loss = 2.3840  \n",
      "\n",
      "Fold: 18  Epoch: 9  Training loss = 1.9379  Validation loss = 2.3618  \n",
      "\n",
      "Fold: 18  Epoch: 10  Training loss = 1.7968  Validation loss = 2.3836  \n",
      "\n",
      "Fold: 18  Epoch: 11  Training loss = 2.3002  Validation loss = 2.9949  \n",
      "\n",
      "Check model:  Fold: 18  Optimal epoch: 2  \n",
      "\n",
      "Fold: 19  Epoch: 1  Training loss = 2.5584  Validation loss = 1.7954  \n",
      "\n",
      "Fold: 19  Epoch: 2  Training loss = 2.1598  Validation loss = 1.9180  \n",
      "\n",
      "Fold: 19  Epoch: 3  Training loss = 1.7284  Validation loss = 2.7881  \n",
      "\n",
      "Fold: 19  Epoch: 4  Training loss = 1.6277  Validation loss = 2.5017  \n",
      "\n",
      "Fold: 19  Epoch: 5  Training loss = 1.5679  Validation loss = 2.0338  \n",
      "\n",
      "Fold: 19  Epoch: 6  Training loss = 1.9199  Validation loss = 2.1153  \n",
      "\n",
      "Fold: 19  Epoch: 7  Training loss = 1.8449  Validation loss = 2.3663  \n",
      "\n",
      "Fold: 19  Epoch: 8  Training loss = 1.5178  Validation loss = 2.2515  \n",
      "\n",
      "Fold: 19  Epoch: 9  Training loss = 1.7017  Validation loss = 1.9681  \n",
      "\n",
      "Fold: 19  Epoch: 10  Training loss = 1.6451  Validation loss = 2.6719  \n",
      "\n",
      "Fold: 19  Epoch: 11  Training loss = 1.5158  Validation loss = 2.7919  \n",
      "\n",
      "Check model:  Fold: 19  Optimal epoch: 1  \n",
      "\n",
      "Fold: 20  Epoch: 1  Training loss = 1.6127  Validation loss = 4.3348  \n",
      "\n",
      "Fold: 20  Epoch: 2  Training loss = 1.7328  Validation loss = 4.5326  \n",
      "\n",
      "Fold: 20  Epoch: 3  Training loss = 1.5656  Validation loss = 3.9968  \n",
      "\n",
      "Fold: 20  Epoch: 4  Training loss = 1.6501  Validation loss = 3.5436  \n",
      "\n",
      "Fold: 20  Epoch: 5  Training loss = 1.8805  Validation loss = 3.7416  \n",
      "\n",
      "Fold: 20  Epoch: 6  Training loss = 1.6707  Validation loss = 4.2306  \n",
      "\n",
      "Fold: 20  Epoch: 7  Training loss = 1.5681  Validation loss = 4.0939  \n",
      "\n",
      "Fold: 20  Epoch: 8  Training loss = 1.4441  Validation loss = 3.8745  \n",
      "\n",
      "Fold: 20  Epoch: 9  Training loss = 1.6637  Validation loss = 4.7926  \n",
      "\n",
      "Fold: 20  Epoch: 10  Training loss = 1.4429  Validation loss = 4.5022  \n",
      "\n",
      "Fold: 20  Epoch: 11  Training loss = 1.6917  Validation loss = 4.2288  \n",
      "\n",
      "Fold: 20  Epoch: 12  Training loss = 1.6817  Validation loss = 3.1420  \n",
      "\n",
      "Fold: 20  Epoch: 13  Training loss = 1.6678  Validation loss = 3.4622  \n",
      "\n",
      "Fold: 20  Epoch: 14  Training loss = 1.4796  Validation loss = 3.2362  \n",
      "\n",
      "Fold: 20  Epoch: 15  Training loss = 1.5984  Validation loss = 3.8611  \n",
      "\n",
      "Fold: 20  Epoch: 16  Training loss = 1.4587  Validation loss = 4.6787  \n",
      "\n",
      "Fold: 20  Epoch: 17  Training loss = 1.5914  Validation loss = 4.3696  \n",
      "\n",
      "Fold: 20  Epoch: 18  Training loss = 1.5584  Validation loss = 4.6763  \n",
      "\n",
      "Fold: 20  Epoch: 19  Training loss = 1.7537  Validation loss = 3.6785  \n",
      "\n",
      "Fold: 20  Epoch: 20  Training loss = 1.5262  Validation loss = 4.3356  \n",
      "\n",
      "Fold: 20  Epoch: 21  Training loss = 1.6786  Validation loss = 3.9325  \n",
      "\n",
      "Fold: 20  Epoch: 22  Training loss = 1.4369  Validation loss = 4.4293  \n",
      "\n",
      "Fold: 20  Epoch: 23  Training loss = 1.3963  Validation loss = 4.4211  \n",
      "\n",
      "Fold: 20  Epoch: 24  Training loss = 1.3670  Validation loss = 4.2977  \n",
      "\n",
      "Fold: 20  Epoch: 25  Training loss = 1.3683  Validation loss = 4.8888  \n",
      "\n",
      "Check model:  Fold: 20  Optimal epoch: 12  \n",
      "\n",
      "Fold: 21  Epoch: 1  Training loss = 1.5512  Validation loss = 3.8777  \n",
      "\n",
      "Fold: 21  Epoch: 2  Training loss = 1.5227  Validation loss = 4.2889  \n",
      "\n",
      "Fold: 21  Epoch: 3  Training loss = 1.5566  Validation loss = 4.5430  \n",
      "\n",
      "Fold: 21  Epoch: 4  Training loss = 1.4425  Validation loss = 4.3779  \n",
      "\n",
      "Fold: 21  Epoch: 5  Training loss = 1.3118  Validation loss = 3.9637  \n",
      "\n",
      "Fold: 21  Epoch: 6  Training loss = 1.2897  Validation loss = 4.0013  \n",
      "\n",
      "Fold: 21  Epoch: 7  Training loss = 1.3869  Validation loss = 3.6704  \n",
      "\n",
      "Fold: 21  Epoch: 8  Training loss = 1.3706  Validation loss = 4.1370  \n",
      "\n",
      "Fold: 21  Epoch: 9  Training loss = 1.3812  Validation loss = 4.1358  \n",
      "\n",
      "Fold: 21  Epoch: 10  Training loss = 1.5670  Validation loss = 5.0949  \n",
      "\n",
      "Fold: 21  Epoch: 11  Training loss = 1.2949  Validation loss = 4.3978  \n",
      "\n",
      "Fold: 21  Epoch: 12  Training loss = 1.3730  Validation loss = 4.2568  \n",
      "\n",
      "Fold: 21  Epoch: 13  Training loss = 1.3029  Validation loss = 4.1450  \n",
      "\n",
      "Fold: 21  Epoch: 14  Training loss = 1.1748  Validation loss = 4.1060  \n",
      "\n",
      "Fold: 21  Epoch: 15  Training loss = 1.2170  Validation loss = 3.9932  \n",
      "\n",
      "Fold: 21  Epoch: 16  Training loss = 1.5742  Validation loss = 4.0876  \n",
      "\n",
      "Fold: 21  Epoch: 17  Training loss = 1.1289  Validation loss = 4.0356  \n",
      "\n",
      "Fold: 21  Epoch: 18  Training loss = 1.2489  Validation loss = 4.4463  \n",
      "\n",
      "Fold: 21  Epoch: 19  Training loss = 1.1144  Validation loss = 4.1078  \n",
      "\n",
      "Fold: 21  Epoch: 20  Training loss = 1.0813  Validation loss = 4.0873  \n",
      "\n",
      "Fold: 21  Epoch: 21  Training loss = 1.0643  Validation loss = 4.2274  \n",
      "\n",
      "Fold: 21  Epoch: 22  Training loss = 1.2259  Validation loss = 4.0824  \n",
      "\n",
      "Fold: 21  Epoch: 23  Training loss = 1.2954  Validation loss = 4.1406  \n",
      "\n",
      "Fold: 21  Epoch: 24  Training loss = 1.0758  Validation loss = 4.0591  \n",
      "\n",
      "Fold: 21  Epoch: 25  Training loss = 1.1395  Validation loss = 4.2702  \n",
      "\n",
      "Fold: 21  Epoch: 26  Training loss = 1.0775  Validation loss = 4.2767  \n",
      "\n",
      "Fold: 21  Epoch: 27  Training loss = 1.0231  Validation loss = 4.1326  \n",
      "\n",
      "Fold: 21  Epoch: 28  Training loss = 1.0267  Validation loss = 4.0304  \n",
      "\n",
      "Fold: 21  Epoch: 29  Training loss = 1.3766  Validation loss = 4.5613  \n",
      "\n",
      "Check model:  Fold: 21  Optimal epoch: 7  \n",
      "\n",
      "Fold: 22  Epoch: 1  Training loss = 1.7888  Validation loss = 2.6235  \n",
      "\n",
      "Fold: 22  Epoch: 2  Training loss = 1.5775  Validation loss = 2.5334  \n",
      "\n",
      "Fold: 22  Epoch: 3  Training loss = 1.4424  Validation loss = 2.3185  \n",
      "\n",
      "Fold: 22  Epoch: 4  Training loss = 1.4771  Validation loss = 2.3760  \n",
      "\n",
      "Fold: 22  Epoch: 5  Training loss = 1.6492  Validation loss = 2.0853  \n",
      "\n",
      "Fold: 22  Epoch: 6  Training loss = 1.4505  Validation loss = 2.0251  \n",
      "\n",
      "Fold: 22  Epoch: 7  Training loss = 1.4196  Validation loss = 1.9996  \n",
      "\n",
      "Fold: 22  Epoch: 8  Training loss = 1.3406  Validation loss = 2.0704  \n",
      "\n",
      "Fold: 22  Epoch: 9  Training loss = 1.4480  Validation loss = 2.0965  \n",
      "\n",
      "Fold: 22  Epoch: 10  Training loss = 1.3537  Validation loss = 2.0267  \n",
      "\n",
      "Fold: 22  Epoch: 11  Training loss = 1.3460  Validation loss = 2.2431  \n",
      "\n",
      "Fold: 22  Epoch: 12  Training loss = 1.3029  Validation loss = 2.0773  \n",
      "\n",
      "Fold: 22  Epoch: 13  Training loss = 1.4086  Validation loss = 1.9219  \n",
      "\n",
      "Fold: 22  Epoch: 14  Training loss = 1.3372  Validation loss = 2.0481  \n",
      "\n",
      "Fold: 22  Epoch: 15  Training loss = 1.3936  Validation loss = 2.0570  \n",
      "\n",
      "Fold: 22  Epoch: 16  Training loss = 1.3290  Validation loss = 2.2098  \n",
      "\n",
      "Fold: 22  Epoch: 17  Training loss = 1.3550  Validation loss = 1.7632  \n",
      "\n",
      "Fold: 22  Epoch: 18  Training loss = 1.3165  Validation loss = 1.9755  \n",
      "\n",
      "Fold: 22  Epoch: 19  Training loss = 1.2858  Validation loss = 1.9682  \n",
      "\n",
      "Fold: 22  Epoch: 20  Training loss = 1.4039  Validation loss = 1.9474  \n",
      "\n",
      "Fold: 22  Epoch: 21  Training loss = 1.2844  Validation loss = 1.9365  \n",
      "\n",
      "Fold: 22  Epoch: 22  Training loss = 1.2781  Validation loss = 1.9768  \n",
      "\n",
      "Fold: 22  Epoch: 23  Training loss = 1.1974  Validation loss = 2.1096  \n",
      "\n",
      "Fold: 22  Epoch: 24  Training loss = 1.2189  Validation loss = 1.7956  \n",
      "\n",
      "Fold: 22  Epoch: 25  Training loss = 1.2207  Validation loss = 2.1664  \n",
      "\n",
      "Fold: 22  Epoch: 26  Training loss = 1.1634  Validation loss = 1.9583  \n",
      "\n",
      "Fold: 22  Epoch: 27  Training loss = 1.1731  Validation loss = 2.1000  \n",
      "\n",
      "Fold: 22  Epoch: 28  Training loss = 1.1447  Validation loss = 1.9367  \n",
      "\n",
      "Fold: 22  Epoch: 29  Training loss = 1.1375  Validation loss = 1.9725  \n",
      "\n",
      "Fold: 22  Epoch: 30  Training loss = 1.1313  Validation loss = 2.1564  \n",
      "\n",
      "Fold: 22  Epoch: 31  Training loss = 1.0883  Validation loss = 2.1501  \n",
      "\n",
      "Fold: 22  Epoch: 32  Training loss = 1.1108  Validation loss = 2.0023  \n",
      "\n",
      "Fold: 22  Epoch: 33  Training loss = 1.0380  Validation loss = 2.2006  \n",
      "\n",
      "Check model:  Fold: 22  Optimal epoch: 17  \n",
      "\n",
      "Fold: 23  Epoch: 1  Training loss = 1.2611  Validation loss = 2.0312  \n",
      "\n",
      "Fold: 23  Epoch: 2  Training loss = 1.2924  Validation loss = 2.8954  \n",
      "\n",
      "Fold: 23  Epoch: 3  Training loss = 1.1554  Validation loss = 2.7227  \n",
      "\n",
      "Fold: 23  Epoch: 4  Training loss = 1.0794  Validation loss = 2.3980  \n",
      "\n",
      "Fold: 23  Epoch: 5  Training loss = 1.0650  Validation loss = 2.3422  \n",
      "\n",
      "Fold: 23  Epoch: 6  Training loss = 1.0575  Validation loss = 2.3813  \n",
      "\n",
      "Fold: 23  Epoch: 7  Training loss = 1.1023  Validation loss = 2.3778  \n",
      "\n",
      "Fold: 23  Epoch: 8  Training loss = 1.0114  Validation loss = 2.4974  \n",
      "\n",
      "Fold: 23  Epoch: 9  Training loss = 1.0695  Validation loss = 2.2204  \n",
      "\n",
      "Fold: 23  Epoch: 10  Training loss = 0.9760  Validation loss = 2.2859  \n",
      "\n",
      "Fold: 23  Epoch: 11  Training loss = 1.0097  Validation loss = 2.2838  \n",
      "\n",
      "Fold: 23  Epoch: 12  Training loss = 0.9993  Validation loss = 1.9239  \n",
      "\n",
      "Fold: 23  Epoch: 13  Training loss = 0.9813  Validation loss = 2.0279  \n",
      "\n",
      "Fold: 23  Epoch: 14  Training loss = 0.9736  Validation loss = 2.1377  \n",
      "\n",
      "Fold: 23  Epoch: 15  Training loss = 0.9850  Validation loss = 1.8779  \n",
      "\n",
      "Fold: 23  Epoch: 16  Training loss = 0.9865  Validation loss = 2.0574  \n",
      "\n",
      "Fold: 23  Epoch: 17  Training loss = 0.9726  Validation loss = 1.7833  \n",
      "\n",
      "Fold: 23  Epoch: 18  Training loss = 0.9800  Validation loss = 1.6638  \n",
      "\n",
      "Fold: 23  Epoch: 19  Training loss = 0.9767  Validation loss = 2.3896  \n",
      "\n",
      "Check model:  Fold: 23  Optimal epoch: 18  \n",
      "\n",
      "Fold: 24  Epoch: 1  Training loss = 1.1869  Validation loss = 1.5202  \n",
      "\n",
      "Fold: 24  Epoch: 2  Training loss = 1.0764  Validation loss = 2.1537  \n",
      "\n",
      "Fold: 24  Epoch: 3  Training loss = 1.4796  Validation loss = 2.4384  \n",
      "\n",
      "Fold: 24  Epoch: 4  Training loss = 1.4786  Validation loss = 2.2372  \n",
      "\n",
      "Fold: 24  Epoch: 5  Training loss = 1.3720  Validation loss = 2.2769  \n",
      "\n",
      "Fold: 24  Epoch: 6  Training loss = 1.4587  Validation loss = 1.4975  \n",
      "\n",
      "Fold: 24  Epoch: 7  Training loss = 1.3366  Validation loss = 1.7340  \n",
      "\n",
      "Fold: 24  Epoch: 8  Training loss = 1.3064  Validation loss = 1.8287  \n",
      "\n",
      "Fold: 24  Epoch: 9  Training loss = 1.2868  Validation loss = 1.6999  \n",
      "\n",
      "Fold: 24  Epoch: 10  Training loss = 1.2444  Validation loss = 1.5516  \n",
      "\n",
      "Fold: 24  Epoch: 11  Training loss = 1.2627  Validation loss = 1.5350  \n",
      "\n",
      "Fold: 24  Epoch: 12  Training loss = 1.2007  Validation loss = 1.4738  \n",
      "\n",
      "Fold: 24  Epoch: 13  Training loss = 1.2374  Validation loss = 1.4953  \n",
      "\n",
      "Fold: 24  Epoch: 14  Training loss = 1.1410  Validation loss = 1.7456  \n",
      "\n",
      "Fold: 24  Epoch: 15  Training loss = 1.3192  Validation loss = 1.8657  \n",
      "\n",
      "Check model:  Fold: 24  Optimal epoch: 12  \n",
      "\n",
      "Fold: 25  Epoch: 1  Training loss = 1.2523  Validation loss = 2.0348  \n",
      "\n",
      "Fold: 25  Epoch: 2  Training loss = 1.2676  Validation loss = 2.3267  \n",
      "\n",
      "Fold: 25  Epoch: 3  Training loss = 1.2013  Validation loss = 2.2407  \n",
      "\n",
      "Fold: 25  Epoch: 4  Training loss = 1.2117  Validation loss = 2.0684  \n",
      "\n",
      "Fold: 25  Epoch: 5  Training loss = 1.2079  Validation loss = 2.3279  \n",
      "\n",
      "Fold: 25  Epoch: 6  Training loss = 1.2312  Validation loss = 2.4017  \n",
      "\n",
      "Fold: 25  Epoch: 7  Training loss = 1.1971  Validation loss = 2.1818  \n",
      "\n",
      "Fold: 25  Epoch: 8  Training loss = 1.1663  Validation loss = 1.9927  \n",
      "\n",
      "Fold: 25  Epoch: 9  Training loss = 1.2425  Validation loss = 1.4617  \n",
      "\n",
      "Fold: 25  Epoch: 10  Training loss = 1.2275  Validation loss = 1.7220  \n",
      "\n",
      "Fold: 25  Epoch: 11  Training loss = 1.2094  Validation loss = 2.2652  \n",
      "\n",
      "Fold: 25  Epoch: 12  Training loss = 1.2773  Validation loss = 1.2771  \n",
      "\n",
      "Fold: 25  Epoch: 13  Training loss = 1.1813  Validation loss = 1.5997  \n",
      "\n",
      "Fold: 25  Epoch: 14  Training loss = 1.1713  Validation loss = 2.1771  \n",
      "\n",
      "Fold: 25  Epoch: 15  Training loss = 1.2366  Validation loss = 2.3470  \n",
      "\n",
      "Fold: 25  Epoch: 16  Training loss = 1.2312  Validation loss = 2.0669  \n",
      "\n",
      "Fold: 25  Epoch: 17  Training loss = 1.1508  Validation loss = 2.2081  \n",
      "\n",
      "Fold: 25  Epoch: 18  Training loss = 1.1973  Validation loss = 2.2693  \n",
      "\n",
      "Fold: 25  Epoch: 19  Training loss = 1.1523  Validation loss = 2.5352  \n",
      "\n",
      "Check model:  Fold: 25  Optimal epoch: 12  \n",
      "\n",
      "Fold: 26  Epoch: 1  Training loss = 1.2558  Validation loss = 2.4388  \n",
      "\n",
      "Fold: 26  Epoch: 2  Training loss = 1.2505  Validation loss = 2.7149  \n",
      "\n",
      "Fold: 26  Epoch: 3  Training loss = 1.2481  Validation loss = 2.6059  \n",
      "\n",
      "Fold: 26  Epoch: 4  Training loss = 1.2540  Validation loss = 2.6345  \n",
      "\n",
      "Fold: 26  Epoch: 5  Training loss = 1.2285  Validation loss = 3.1054  \n",
      "\n",
      "Fold: 26  Epoch: 6  Training loss = 1.2257  Validation loss = 2.9594  \n",
      "\n",
      "Fold: 26  Epoch: 7  Training loss = 1.2170  Validation loss = 2.7145  \n",
      "\n",
      "Fold: 26  Epoch: 8  Training loss = 1.2062  Validation loss = 2.6836  \n",
      "\n",
      "Fold: 26  Epoch: 9  Training loss = 1.2094  Validation loss = 2.5831  \n",
      "\n",
      "Fold: 26  Epoch: 10  Training loss = 1.1767  Validation loss = 2.3875  \n",
      "\n",
      "Fold: 26  Epoch: 11  Training loss = 1.1558  Validation loss = 2.2106  \n",
      "\n",
      "Fold: 26  Epoch: 12  Training loss = 1.1976  Validation loss = 3.0683  \n",
      "\n",
      "Fold: 26  Epoch: 13  Training loss = 1.2330  Validation loss = 2.7948  \n",
      "\n",
      "Fold: 26  Epoch: 14  Training loss = 1.2916  Validation loss = 2.2513  \n",
      "\n",
      "Fold: 26  Epoch: 15  Training loss = 1.1822  Validation loss = 2.8290  \n",
      "\n",
      "Fold: 26  Epoch: 16  Training loss = 1.1446  Validation loss = 2.4011  \n",
      "\n",
      "Fold: 26  Epoch: 17  Training loss = 1.1925  Validation loss = 2.0330  \n",
      "\n",
      "Fold: 26  Epoch: 18  Training loss = 1.1093  Validation loss = 2.5242  \n",
      "\n",
      "Fold: 26  Epoch: 19  Training loss = 1.0764  Validation loss = 2.6099  \n",
      "\n",
      "Fold: 26  Epoch: 20  Training loss = 1.1442  Validation loss = 2.7998  \n",
      "\n",
      "Fold: 26  Epoch: 21  Training loss = 1.0896  Validation loss = 2.5526  \n",
      "\n",
      "Fold: 26  Epoch: 22  Training loss = 1.0838  Validation loss = 2.3127  \n",
      "\n",
      "Fold: 26  Epoch: 23  Training loss = 1.0888  Validation loss = 2.7294  \n",
      "\n",
      "Fold: 26  Epoch: 24  Training loss = 1.0479  Validation loss = 2.3669  \n",
      "\n",
      "Fold: 26  Epoch: 25  Training loss = 1.0370  Validation loss = 2.9183  \n",
      "\n",
      "Check model:  Fold: 26  Optimal epoch: 17  \n",
      "\n",
      "Fold: 27  Epoch: 1  Training loss = 1.2804  Validation loss = 2.5645  \n",
      "\n",
      "Fold: 27  Epoch: 2  Training loss = 1.2449  Validation loss = 2.1341  \n",
      "\n",
      "Fold: 27  Epoch: 3  Training loss = 1.2601  Validation loss = 2.1896  \n",
      "\n",
      "Fold: 27  Epoch: 4  Training loss = 1.3031  Validation loss = 2.8009  \n",
      "\n",
      "Fold: 27  Epoch: 5  Training loss = 1.2669  Validation loss = 2.5933  \n",
      "\n",
      "Fold: 27  Epoch: 6  Training loss = 1.3262  Validation loss = 2.9200  \n",
      "\n",
      "Fold: 27  Epoch: 7  Training loss = 1.2279  Validation loss = 2.4693  \n",
      "\n",
      "Fold: 27  Epoch: 8  Training loss = 1.2265  Validation loss = 2.3636  \n",
      "\n",
      "Fold: 27  Epoch: 9  Training loss = 1.2216  Validation loss = 2.4490  \n",
      "\n",
      "Fold: 27  Epoch: 10  Training loss = 1.7562  Validation loss = 3.8985  \n",
      "\n",
      "Fold: 27  Epoch: 11  Training loss = 1.1894  Validation loss = 2.5625  \n",
      "\n",
      "Fold: 27  Epoch: 12  Training loss = 1.0615  Validation loss = 1.8709  \n",
      "\n",
      "Fold: 27  Epoch: 13  Training loss = 1.0970  Validation loss = 1.7048  \n",
      "\n",
      "Fold: 27  Epoch: 14  Training loss = 1.1536  Validation loss = 3.4474  \n",
      "\n",
      "Fold: 27  Epoch: 15  Training loss = 1.4635  Validation loss = 3.0028  \n",
      "\n",
      "Fold: 27  Epoch: 16  Training loss = 1.0777  Validation loss = 2.5297  \n",
      "\n",
      "Fold: 27  Epoch: 17  Training loss = 1.4387  Validation loss = 1.2830  \n",
      "\n",
      "Fold: 27  Epoch: 18  Training loss = 0.9852  Validation loss = 1.5743  \n",
      "\n",
      "Fold: 27  Epoch: 19  Training loss = 1.2194  Validation loss = 2.6754  \n",
      "\n",
      "Fold: 27  Epoch: 20  Training loss = 1.0928  Validation loss = 1.2090  \n",
      "\n",
      "Fold: 27  Epoch: 21  Training loss = 1.1701  Validation loss = 1.3399  \n",
      "\n",
      "Fold: 27  Epoch: 22  Training loss = 1.0698  Validation loss = 2.2931  \n",
      "\n",
      "Fold: 27  Epoch: 23  Training loss = 0.9736  Validation loss = 1.6170  \n",
      "\n",
      "Fold: 27  Epoch: 24  Training loss = 1.3541  Validation loss = 2.8242  \n",
      "\n",
      "Fold: 27  Epoch: 25  Training loss = 1.0453  Validation loss = 2.2542  \n",
      "\n",
      "Fold: 27  Epoch: 26  Training loss = 0.9982  Validation loss = 2.6094  \n",
      "\n",
      "Fold: 27  Epoch: 27  Training loss = 1.2295  Validation loss = 1.5764  \n",
      "\n",
      "Fold: 27  Epoch: 28  Training loss = 1.1845  Validation loss = 1.8994  \n",
      "\n",
      "Fold: 27  Epoch: 29  Training loss = 1.1305  Validation loss = 3.1501  \n",
      "\n",
      "Check model:  Fold: 27  Optimal epoch: 20  \n",
      "\n",
      "Fold: 28  Epoch: 1  Training loss = 1.0592  Validation loss = 1.5144  \n",
      "\n",
      "Fold: 28  Epoch: 2  Training loss = 1.3060  Validation loss = 1.5536  \n",
      "\n",
      "Fold: 28  Epoch: 3  Training loss = 1.3156  Validation loss = 1.6338  \n",
      "\n",
      "Fold: 28  Epoch: 4  Training loss = 1.3160  Validation loss = 1.4315  \n",
      "\n",
      "Fold: 28  Epoch: 5  Training loss = 1.2735  Validation loss = 1.7936  \n",
      "\n",
      "Fold: 28  Epoch: 6  Training loss = 1.2573  Validation loss = 1.4712  \n",
      "\n",
      "Fold: 28  Epoch: 7  Training loss = 1.2370  Validation loss = 1.7707  \n",
      "\n",
      "Fold: 28  Epoch: 8  Training loss = 1.0805  Validation loss = 1.8365  \n",
      "\n",
      "Fold: 28  Epoch: 9  Training loss = 1.0504  Validation loss = 1.6478  \n",
      "\n",
      "Fold: 28  Epoch: 10  Training loss = 0.9971  Validation loss = 1.3094  \n",
      "\n",
      "Fold: 28  Epoch: 11  Training loss = 1.4720  Validation loss = 1.2365  \n",
      "\n",
      "Fold: 28  Epoch: 12  Training loss = 1.3045  Validation loss = 0.9058  \n",
      "\n",
      "Fold: 28  Epoch: 13  Training loss = 1.3038  Validation loss = 0.7496  \n",
      "\n",
      "Fold: 28  Epoch: 14  Training loss = 1.2867  Validation loss = 0.6537  \n",
      "\n",
      "Fold: 28  Epoch: 15  Training loss = 1.2999  Validation loss = 0.9681  \n",
      "\n",
      "Fold: 28  Epoch: 16  Training loss = 1.2548  Validation loss = 0.9305  \n",
      "\n",
      "Fold: 28  Epoch: 17  Training loss = 1.2607  Validation loss = 0.7057  \n",
      "\n",
      "Fold: 28  Epoch: 18  Training loss = 1.2568  Validation loss = 0.8528  \n",
      "\n",
      "Fold: 28  Epoch: 19  Training loss = 1.2696  Validation loss = 0.8010  \n",
      "\n",
      "Fold: 28  Epoch: 20  Training loss = 1.2898  Validation loss = 0.7981  \n",
      "\n",
      "Fold: 28  Epoch: 21  Training loss = 1.2554  Validation loss = 0.8210  \n",
      "\n",
      "Fold: 28  Epoch: 22  Training loss = 1.2952  Validation loss = 1.3156  \n",
      "\n",
      "Check model:  Fold: 28  Optimal epoch: 14  \n",
      "\n",
      "Fold: 29  Epoch: 1  Training loss = 1.3044  Validation loss = 1.9862  \n",
      "\n",
      "Fold: 29  Epoch: 2  Training loss = 1.4605  Validation loss = 1.6433  \n",
      "\n",
      "Fold: 29  Epoch: 3  Training loss = 1.2760  Validation loss = 1.7701  \n",
      "\n",
      "Fold: 29  Epoch: 4  Training loss = 1.2632  Validation loss = 1.7425  \n",
      "\n",
      "Fold: 29  Epoch: 5  Training loss = 1.2829  Validation loss = 1.9321  \n",
      "\n",
      "Fold: 29  Epoch: 6  Training loss = 1.2594  Validation loss = 2.0439  \n",
      "\n",
      "Fold: 29  Epoch: 7  Training loss = 1.4460  Validation loss = 2.0725  \n",
      "\n",
      "Fold: 29  Epoch: 8  Training loss = 1.2242  Validation loss = 1.7738  \n",
      "\n",
      "Fold: 29  Epoch: 9  Training loss = 1.2267  Validation loss = 1.6613  \n",
      "\n",
      "Fold: 29  Epoch: 10  Training loss = 1.2154  Validation loss = 1.9768  \n",
      "\n",
      "Fold: 29  Epoch: 11  Training loss = 1.2517  Validation loss = 1.7923  \n",
      "\n",
      "Fold: 29  Epoch: 12  Training loss = 1.2358  Validation loss = 1.8139  \n",
      "\n",
      "Fold: 29  Epoch: 13  Training loss = 1.2372  Validation loss = 2.1410  \n",
      "\n",
      "Check model:  Fold: 29  Optimal epoch: 2  \n",
      "\n",
      "Fold: 30  Epoch: 1  Training loss = 1.3252  Validation loss = 2.2080  \n",
      "\n",
      "Fold: 30  Epoch: 2  Training loss = 1.2230  Validation loss = 2.0703  \n",
      "\n",
      "Fold: 30  Epoch: 3  Training loss = 1.2585  Validation loss = 2.0023  \n",
      "\n",
      "Fold: 30  Epoch: 4  Training loss = 1.1966  Validation loss = 1.6665  \n",
      "\n",
      "Fold: 30  Epoch: 5  Training loss = 1.2090  Validation loss = 1.7637  \n",
      "\n",
      "Fold: 30  Epoch: 6  Training loss = 1.2103  Validation loss = 1.9651  \n",
      "\n",
      "Fold: 30  Epoch: 7  Training loss = 1.1689  Validation loss = 1.9779  \n",
      "\n",
      "Fold: 30  Epoch: 8  Training loss = 1.2194  Validation loss = 2.1600  \n",
      "\n",
      "Fold: 30  Epoch: 9  Training loss = 1.2293  Validation loss = 1.8832  \n",
      "\n",
      "Fold: 30  Epoch: 10  Training loss = 1.1705  Validation loss = 2.0317  \n",
      "\n",
      "Fold: 30  Epoch: 11  Training loss = 1.1476  Validation loss = 2.0126  \n",
      "\n",
      "Fold: 30  Epoch: 12  Training loss = 1.2708  Validation loss = 1.7145  \n",
      "\n",
      "Fold: 30  Epoch: 13  Training loss = 1.1844  Validation loss = 2.1332  \n",
      "\n",
      "Fold: 30  Epoch: 14  Training loss = 1.1989  Validation loss = 2.0963  \n",
      "\n",
      "Fold: 30  Epoch: 15  Training loss = 1.1766  Validation loss = 2.0968  \n",
      "\n",
      "Fold: 30  Epoch: 16  Training loss = 1.1953  Validation loss = 2.0448  \n",
      "\n",
      "Fold: 30  Epoch: 17  Training loss = 1.1579  Validation loss = 2.0617  \n",
      "\n",
      "Fold: 30  Epoch: 18  Training loss = 1.1560  Validation loss = 1.8503  \n",
      "\n",
      "Fold: 30  Epoch: 19  Training loss = 1.1934  Validation loss = 1.8643  \n",
      "\n",
      "Fold: 30  Epoch: 20  Training loss = 1.1562  Validation loss = 2.2029  \n",
      "\n",
      "Check model:  Fold: 30  Optimal epoch: 4  \n",
      "\n",
      "Fold: 31  Epoch: 1  Training loss = 1.1825  Validation loss = 1.1903  \n",
      "\n",
      "Fold: 31  Epoch: 2  Training loss = 1.1511  Validation loss = 1.2723  \n",
      "\n",
      "Fold: 31  Epoch: 3  Training loss = 1.1450  Validation loss = 1.0639  \n",
      "\n",
      "Fold: 31  Epoch: 4  Training loss = 1.1702  Validation loss = 0.7337  \n",
      "\n",
      "Fold: 31  Epoch: 5  Training loss = 1.1356  Validation loss = 1.1687  \n",
      "\n",
      "Fold: 31  Epoch: 6  Training loss = 1.1523  Validation loss = 1.3219  \n",
      "\n",
      "Fold: 31  Epoch: 7  Training loss = 1.1364  Validation loss = 1.1927  \n",
      "\n",
      "Fold: 31  Epoch: 8  Training loss = 1.1357  Validation loss = 1.0822  \n",
      "\n",
      "Fold: 31  Epoch: 9  Training loss = 1.1176  Validation loss = 1.0666  \n",
      "\n",
      "Fold: 31  Epoch: 10  Training loss = 1.0942  Validation loss = 1.3083  \n",
      "\n",
      "Fold: 31  Epoch: 11  Training loss = 1.1169  Validation loss = 1.6757  \n",
      "\n",
      "Check model:  Fold: 31  Optimal epoch: 4  \n",
      "\n",
      "Fold: 32  Epoch: 1  Training loss = 1.1283  Validation loss = 4.0084  \n",
      "\n",
      "Fold: 32  Epoch: 2  Training loss = 1.1276  Validation loss = 3.9059  \n",
      "\n",
      "Fold: 32  Epoch: 3  Training loss = 1.1313  Validation loss = 3.5364  \n",
      "\n",
      "Fold: 32  Epoch: 4  Training loss = 1.1327  Validation loss = 3.8449  \n",
      "\n",
      "Fold: 32  Epoch: 5  Training loss = 1.1449  Validation loss = 4.0360  \n",
      "\n",
      "Fold: 32  Epoch: 6  Training loss = 1.2077  Validation loss = 4.3676  \n",
      "\n",
      "Fold: 32  Epoch: 7  Training loss = 1.1334  Validation loss = 3.9314  \n",
      "\n",
      "Fold: 32  Epoch: 8  Training loss = 1.1255  Validation loss = 3.9109  \n",
      "\n",
      "Fold: 32  Epoch: 9  Training loss = 1.1369  Validation loss = 3.6953  \n",
      "\n",
      "Fold: 32  Epoch: 10  Training loss = 1.1197  Validation loss = 3.8490  \n",
      "\n",
      "Fold: 32  Epoch: 11  Training loss = 1.1120  Validation loss = 3.8864  \n",
      "\n",
      "Fold: 32  Epoch: 12  Training loss = 1.1113  Validation loss = 4.0390  \n",
      "\n",
      "Fold: 32  Epoch: 13  Training loss = 1.1145  Validation loss = 3.7839  \n",
      "\n",
      "Fold: 32  Epoch: 14  Training loss = 1.1228  Validation loss = 3.7513  \n",
      "\n",
      "Fold: 32  Epoch: 15  Training loss = 1.1039  Validation loss = 3.9789  \n",
      "\n",
      "Fold: 32  Epoch: 16  Training loss = 1.1077  Validation loss = 3.9054  \n",
      "\n",
      "Fold: 32  Epoch: 17  Training loss = 1.1286  Validation loss = 3.8189  \n",
      "\n",
      "Fold: 32  Epoch: 18  Training loss = 1.1055  Validation loss = 3.9619  \n",
      "\n",
      "Fold: 32  Epoch: 19  Training loss = 1.1244  Validation loss = 3.6809  \n",
      "\n",
      "Fold: 32  Epoch: 20  Training loss = 1.1212  Validation loss = 3.7765  \n",
      "\n",
      "Fold: 32  Epoch: 21  Training loss = 1.1113  Validation loss = 3.8465  \n",
      "\n",
      "Fold: 32  Epoch: 22  Training loss = 1.1018  Validation loss = 4.0340  \n",
      "\n",
      "Check model:  Fold: 32  Optimal epoch: 3  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 2. Train model\n",
    "# ==================================\n",
    "sess = tf.InteractiveSession()  # Launch Graph\n",
    "sess.run(tf.global_variables_initializer())  # Initialise all variables\n",
    "\n",
    "print(\"Start training\", \n",
    "      \"\\nHyperparameters:\",\n",
    "      \"\\nDimension of recurrent unit =\", n_hidden,\n",
    "      \"\\nLearning rate =\", learning_rate,\n",
    "      \"\\nEpochs =\", epochs,\n",
    "      \"\\nBatch size =\", batch_size,\n",
    "      \"\\nEarly stopping epochs =\", early_stop_iters,\n",
    "      \"\\nLearning rate =\", learning_rate)\n",
    "\n",
    "total_batch = int(window_length / batch_size)\n",
    "validation_fold_error = [] # store validation error of each fold\n",
    "optimal_epochs = []\n",
    "\n",
    "# loop through folds\n",
    "for fold in range(1, len(valIndex)):\n",
    "    validx = train_features[valIndex[fold-1]:valIndex[fold]]\n",
    "    validy = train_target[valIndex[fold-1]:valIndex[fold]]\n",
    "    trainx = train_features[(fold-1)*4:valIndex[(fold-1)]]\n",
    "    trainy = train_target[(fold-1)*4:valIndex[(fold-1)]]\n",
    "\n",
    "    loss_list = [] # store validation loss after each epoch for early stopping\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i in range(total_batch):\n",
    "            # Backprop\n",
    "            batch_xs, batch_ys = next_batch(num=batch_size, data=trainx, labels=trainy)\n",
    "            optimizer.run(feed_dict={x:batch_xs, y:batch_ys, lr:learning_rate})\n",
    "\n",
    "        # Loss\n",
    "        loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "        loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "        loss_list.append(loss_valid)\n",
    "\n",
    "        print(\"Fold: {0:d}\".format(fold),\n",
    "              \" Epoch: {0:d}\".format(epoch+1),\n",
    "              \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "              \" Validation loss = {0:.4f}\".format(np.sqrt(loss_valid)),\n",
    "              \" \\n\")\n",
    "\n",
    "        if all(j <= loss_valid for j in loss_list[-early_stop_iters:]) and len(loss_list)>early_stop_iters:\n",
    "            break\n",
    "    \n",
    "    # Load model with lowest validation error for each fold\n",
    "    epoch_hat = np.argmin(loss_list) + 1\n",
    "    optimal_epochs.append(epoch_hat) # store optimal number of epochs for each fold\n",
    "    \n",
    "    # RMSE\n",
    "    loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "    loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "    validation_fold_error.append(np.sqrt(loss_valid))\n",
    "    \n",
    "    print(\"Check model:\",\n",
    "          \" Fold: {0:d}\".format(fold),\n",
    "          \" Optimal epoch: {0:d}\".format(epoch_hat),\n",
    "          \" \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average number of epochs: 10\n",
      "Average validation error: 3.59118\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 3. Optimal epoch choice\n",
    "# ==================================\n",
    "# Pick number of epochs to train model for out-of-sample testing\n",
    "epoch_hat = int(np.mean(optimal_epochs))\n",
    "print(\"\\nAverage number of epochs:\", epoch_hat)\n",
    "# Average validation error\n",
    "print(\"Average validation error:\", np.mean(validation_fold_error))\n",
    "\n",
    "# Save validated model\n",
    "saveModel(sess, \n",
    "          MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + str(epoch_hat) + \"_validated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fixed scheme:\n",
      "Epoch: 1  Training loss = 1.2870  Test loss = 3.9305  \n",
      "\n",
      "Epoch: 2  Training loss = 1.2646  Test loss = 3.8880  \n",
      "\n",
      "Epoch: 3  Training loss = 1.2465  Test loss = 3.8532  \n",
      "\n",
      "Epoch: 4  Training loss = 1.2307  Test loss = 3.8234  \n",
      "\n",
      "Epoch: 5  Training loss = 1.2163  Test loss = 3.7973  \n",
      "\n",
      "Epoch: 6  Training loss = 1.2025  Test loss = 3.7742  \n",
      "\n",
      "Epoch: 7  Training loss = 1.1888  Test loss = 3.7535  \n",
      "\n",
      "Epoch: 8  Training loss = 1.1746  Test loss = 3.7347  \n",
      "\n",
      "Epoch: 9  Training loss = 1.1597  Test loss = 3.7176  \n",
      "\n",
      "Epoch: 10  Training loss = 1.1446  Test loss = 3.7019  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 4. Fixed scheme\n",
    "# ==================================\n",
    "print(\"\\nFixed scheme:\")\n",
    "for epoch in range(epoch_hat):\n",
    "    x_train = train_features[-window_length:]\n",
    "    y_train = train_target[-window_length:]\n",
    "    optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:test_features, y:test_target})\n",
    "    print(\"Epoch: {0:d}\".format(epoch+1),\n",
    "          \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "          \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "          \" \\n\")\n",
    "\n",
    "# Forecasts\n",
    "yhat_test_fixed = pred.eval(feed_dict={x:test_features})\n",
    "yhat_train_fixed = pred.eval(feed_dict={x:x_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmZXM/wC8yB1/Na0bbwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd08d2b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train set\n",
    "plt.plot(y_train, 'black')\n",
    "plt.plot(yhat_train_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzsnXlclNX+xz8HhhkQRBxEUUBERRAXXFAR1FJzTa3M1LLM\nTM2yTNPSe+2Wt8V+WrbbZqm3vOWWenPXFBAzd8UNUXEFRVYB2Zn5/v448wyzPLMPi/i8Xy9eA888\n2wwz53O+62FEBAkJCQmJBw+X2r4BCQkJCYnaQRIACQkJiQcUSQAkJCQkHlAkAZCQkJB4QJEEQEJC\nQuIBRRIACQkJiQcUSQAkJCQkHlAkAZCQkJB4QJEEQEJCQuIBRVbbN2COJk2aUKtWrWr7NiQkJCTu\nG44fP55NRH7W7FunBaBVq1Y4duxYbd+GhISExH0DY+y6tftKLiAJCQmJBxRJACQkJCQeUCQBkJCQ\nkHhAkQRAQkJC4gFFEgAJCQmJBxRJACQkJCQeUCQBkJCQkHhAkQTgfmDvXiApqbbvQkJCop4hCUBd\nhwgYPRqIjgY2b67tu5GQkKhHSAJQ17lxAygoANzcgCefBL79trbvSEJCop5gkwAwxlYwxjIZY2d1\ntikZY3sYY5c0j41NHPu8Zp9LjLHnHb3xB4Zz5/jjhg3A8OHAK68ACxZwy0BCQkLCAWy1AFYBGGqw\nbT6AvUQUCmCv5m89GGNKAO8C6AWgJ4B3TQmFhAFnNVrbsyewaRMwdSqwaBHw0Ue1e18SEhL3PTYJ\nABHtB5BrsPkxAP/R/P4fAI+LHDoEwB4iyiWiPAB7YCwkEmKcOwcEBAA+PoBMBnz/PdC3L7BuXW3f\nmYSExH2OM2IAzYjotub3DADNRPYJAHBT5+80zTYJS5w9C3ToUPU3Y8CQITwrKCen9u5LQkLivsep\nQWAiIgAOOacZY9MYY8cYY8eysrKcdGf3KSoVkJwMdOyov33AAP4YH1/jtyQhIVF/cIYA3GGMNQcA\nzWOmyD7pAIJ0/g7UbDOCiH4goigiivLzs2pNg/rL1atASYm+BQAAUVGApyewb1/t3JeEhES9wBkC\n8AcAIavneQD/E9lnF4DBjLHGmuDvYM02CXMIGUCGFoCbG9CvnyQAEhISDmFrGuhvAP4GEMYYS2OM\nvQjg/wAMYoxdAvCI5m8wxqIYYz8CABHlAngfwFHNz3uabRLmEDKAIiKMnxswALhwAbh92/g5CQkJ\nCSuwaUlIInraxFMDRfY9BmCKzt8rAKyw6e4edM6dA1q1Ary8jJ8T4gBxccAzz9TobUlISNQPpErg\nuoxhBpAukZE8NVRyA0lISNiJJAB1lYoKICXF2P8v4OoKPPywJAASEhJ2IwlAXeXyZaC83LQFAHA3\n0NWrwLVrNXZbEhIS9QdJAOoqpjKAdNGNA0hISEjYiCQAdZWzZwEXFyA83PQ+ERFA06aSG0hCQsIu\nJAGoq5w7B7RpA3h4mN6HMaB/f24BSN1BJSQkbEQSgLqKuQwgXQYMANLTgUuXqv+eJCQk6hWSANRF\nysr4gG6tAACSG0hCQsJmJAGoi6Sk8EZw5gLAAm3a8DjA0aPVf18SEhL1CkkA6iJCBpA1FgBjgJ8f\nkJ9fvfckISFR75AEoC5y9ixf/CUszLr9vb35usESEhISNiAJQF3k3DkgNBSQy63bXxIACQkJO5AE\noC5ibQaQQMOGdUsArl2r2dXKpk/n8ZJnnwWWLuUB8StXgMxMoLj4/kuRfestoEkT/Z833qjZe7jf\n3jMJu5AEoK6RmwukpgLdull/TF2xAFQq4P/+j1svr7xSM9csKwNWreIL58THA3PnAgMH8uB4s2Z8\n4RyZjHdUVSoBf3+gZUtg8eKauT972LCBx3XGj+c/zZsDv/1Wc9efORN4XGxpb4n6hk3toCVqgCNH\n+GOvXtYf4+0NFBZWz/1YS1oa8NxzfBD29gYOHKiZ6x47xkVg6VI+aGVlASdP8nUS7t3jP4WFQGkp\n761UXg5s3Qps2QLMm1cz92gLJSXcgnr3Xf4DAJ99xi2AjAwuYNXN8ePAwYPAzZtAUJDl/SXuWyQB\nqGscPswze6KirD9GEAC1mrePqGl27AAmTOCD64oV3BqZNYsXqAUEVO+1BaGJjeWPfn7A4MHmj3n6\naS4cdZGUFO5+0W0B0rUrfzx5Ehg2rPrvIVezVtO6dcCcOdV/PYlaQ3IB1TUOH+Y9fry9rT/G25sP\nGkVF1Xdf5pg1i9cinDwJvPBClfUiWDPVSWIiHyxtWT+6WTM+m66LJCfzx/btq7Z16cIfT56smXsQ\nBKAm3U4StYLDAsAYC2OMndL5KWCMzTLY52HGWL7OPu84et16CREfNG1x/wA8CAzUXhwgIwMYMoT7\n/gE+YMlk1V+cplYDf/0F9O1r23H+/tw1VFxcPfflCBcucCuuXbuqbT4+QEhIzQgAERcAHx/uCpJa\njNRrHBYAIkohoi5E1AVAdwDFADaJ7Joo7EdE7zl63XpJairPnrFVAARroTYEoKKCX7dJk6pt7u58\nxbLqtgDOnQPu3gX69LHtuGbN+OOdO86/J0dJTuaDvbu7/vauXWtGAO7dAyorgeef53+vXVv915So\nNZztAhoIIJWIrjv5vA8Ghw/zR3sFoDYCwYK7wNdXf3vPntwCUKur79qJifzRVgtAEIC66AZKTtZ3\n/wh07conCNVd8S38Pzt35u/rmjXVez2JWsXZAjAegCnHYW/GWBJjbAdjzGSSO2NsGmPsGGPsWFZW\nlpNvr45z+DDQoIFtNQBA7VoA2dn8UUwACgqAixer79qJiUCLFkCrVrYdJ2TS1DULoLKSv1+mBAAA\nTp+u3nsQBECp5Cmo587xuhSJeonTBIAxJgcwCsB6kadPAAgmokgAXwHYbOo8RPQDEUURUZSfLYG9\n+sDhwzz7R2ZjclZtCoBQ8KXrAgK4AADV5wYi4gLQty/PmrKFuuoCunqVZ1KZE4DqdgMJ/0+lEhgz\nhscjpGBwvcWZFsAwACeIyOhbRUQFRHRP8/t2AG6MsSaG+z3QlJUBp07Z7v4BajcIbMoCCAvj91Vd\nAnD9Ok8ztdX9A/CMJcB5LqCUFL6Gs6OIZQAJNG9elWlVnehaAE2b8qK6NWukyuB6ijMF4GmYcP8w\nxvwZ49M0xlhPzXVrsFfAfcCpU3z2Z48A1AULwFAAXF25NVNdAiD4/20NAAOAmxu/X2dZAC+8AEyd\n6vh5zAkAYzUTCNYVAIDXTFy5UnfrJiQcwikCwBjzBDAIwEadbdMZY9M1f44BcJYxlgTgSwDjiaQp\nhR72BoCBKgugNoLApgQA4G6gU6e4deNsDhwAGjWybs0EMZo1c54AXL0KnDnj+HkuXOAz/UaNxJ/v\n2pX75Kvj/RQwFIAnnuCCKQWD6yVOqQQmoiIAvgbbvtP5/WsAXzvjWvWWw4d5QDMw0PZj5XKeNlhb\nLiAPDx68NqRHD54mmpRUFRNwFomJvPrX1dW+450lAOXl/DxEvA2FI3Gr5GT9CmBDunblgeJz52zr\nFWULubn8fymkofr48FXn9uypnutJ1CpSJXBd4fBh+2b/ArXVEC4nxzgALFBdgeDsbD5Y2uP+EfD3\nd04M4PbtKv+44MKxByLTKaACNREIzs2tmv0LhIdzK0cy2usdkgDUBbKzeY63IwJQWy2hc3LE3T8A\nt2b8/Z0vAEL/H3sCwALOsgDS0qp+P3/e/vPcvs3/f+YEoE0b/n+uaQFo1YoXiNVki2+JGkESgLqA\nPR1ADaktCyA727QAMMatgOoQALnctoZ5hjRrxgc1R/sn6QqAIxaAuQCwgIsLr7CuaQEICeGPV69W\n33UlagVJAOoChw/zL7cjA1pttYQ25wICuACkpPCWDc4iPp6f17Bdgi04qxZAEIC2batfAADuBkpK\n4msvVAfmBODateq5pkStIQlAXeDwYV796+Vl/zlqMwZgygIAquIAzkojvHyZNykbNcqx8zirGjgt\njS86Ex3tuAB4e/MsIHN07cqtFmfUHYhhygUESBZAPUQSgLrAyZOOzf6B2hEAlYoPGOYEQHhdznID\n/fordy2NH+/YeZxpAQQG8pl7WppVVlhqaiquGg6mFy7wc1iqaq7OQDARF3RDAfD25tskAah3SAJQ\n21RU8LVrW7Z07Dy1EQS+e5cPGuZcQI0b8zbRx487fj0iLgD9+jm+UpWzGsKlp1cJAMAHcjMQEYYN\nG4ZXDJfMtJQBJBARwfPyq0MAiot5WquYoIeESAJQD5EEoLYRZqCWTH9L1IYFYK4ITJeICIsDo1Wc\nOAGkpODHkhLMnz/fsXMJ7SCcZQFERPC/LbiBEhMTcenSJRTo/q/y83kWkDUCIJfz4rcTJxy4aRMY\nFoHpEhIixQDqIZIA1DbCDNTRtV69vXmFaHm54/dkLab6ABkSFsZ91pWVjl3vv/8F3NzwydWr2LFj\nh2PnckY7CJUKuHWLC0CbNvycFlJBV6xYAQAo063mFUTDXBGYLr168biRswPB5gSgVSsuANXZ3lui\nxpEEoLa5fZs/OsMCAGo2E8hUJ1BDwsK4MDkyg1SpgDVroBo6FClZWUhJSUGlo4Li6NKQd+7w+woM\n5B1cQ0PNWgCFhYVYv543yxUVAGssAIBXQBcW8opgZ2LJAigrq5trKEjYjSQAtY0zLQCgZt1A1rqA\nhJltSor914qPB27fRtagQQD4AGoUSLUVf3/HLAAhBVRo39G+vVkBWLduHYqLixESEoJyXUstOZm7\ndoR0S0vExPDHv/6y46bNYEkAAMkNVM+QBKC2ESwAIShpL7XRElpwAVljAQCOxQF+/RVo2BAXddbK\nTXYk7RJwvBpYTABSU002a1uxYgXCw8PRr18/YwugXTvr14EICeHiVZMCIKWC1kskAahtMjL4F06h\ncOw8tWUBuLlZrl/w9eUiYa8FUFoKbNgAjB6N65mZ2s3nHWm9ADjuAhITALVadCH1Cxcu4ODBg5g8\neTIUCoW+AAgpoNbCGHcDSQIg4SCSANQ2t2877v8Hak8AfH2tW5ErLMx+Adi2jb+uCRNw8+ZNAICv\nr6/jFoC/Py+qsrcdRFoaF27BBSYM4iL3tXLlSri6uuK5556DXC6vcgGVlvJ++7YIAMAF4No1HoR2\nFrm5/PV4eBg/5+HB3y9JAOoVkgDUNhkZjvv/gdoJAmdnW3b/CISH2+8C+vVXPlsfMAA3b96EUqlE\nt27dnGMBAPa7gYQUUEEAw8L47wYCUFFRgf/85z949NFH4e/vr28BXL7MrQZrM4AEhDjAwYP23bsY\nQhWwKUGXUkHrHZIA2MO77wJ79zrnXPXBArCGsDBe8JaXZ/t1Dh0ChgwBXF1x8+ZNBAUFISIiAsnJ\nyVA7kpboaDGYIAACDRoAwcFGArBz507cuXMHkydPBgB9C8DWDCCBrl15LyRnuoEs/T9btZIsgHqG\nMxeFv8YYO8MYO8UYM2r8wjhfMsYuM8ZOM8aqaUWLaiYzE3jvPeD77x0/F5HzLIDaCgLbIgCA7W6g\nkhLu5mjbFgD0BKCoqAhput04bcXRfkCGAgDwgdzAMvnpp5/QtGlTDB8+HACgUChQUVHBxevCBT7j\n1gluW4VczvssOVMAxPoA6RISAty44Xg9h0SdwdkWQH8i6kJEYo1thgEI1fxMA/Ctk69dM+zbxx/P\nnnX8XHfv8owRZ1gAnp58IKlpC8AWFxBguwBcucIf27QBUCUA7TUzZofcQI64gNTqqjYQurRvz1+j\npkjr4sWL+OOPPzBlyhS4ubkB4AIAgFsBycncahBbUc0SsbG8JURxse3HimGNAKhU+i2wJe5ratIF\n9BiAn4lzCIAPY8wJI18NI7h+Ll50fG1WZ9UAALyddE32AxIah1lrAYSE8DRHWwUgNZU/tmmDoqIi\n5OXlaS0AwEEBEJZvtEcAsrN5cZuhAERE8M+Fxlf+2Wefwc3NDa+99pp2F7lcDkAjABcu2O7/F4iN\n5bPxo0ftO94QSwIgZAI5GgfYsQNYuFBaYKYO4EwBIAC7GWPHGWPTRJ4PAHBT5+80zbb7i717eUaE\nSuVYYRPgvCpggZpcE6CggA8+1gqAmxt349gaCNYRACEDKCgoCL6+vmjatKljmUBubtyCsScGoJMC\nmpSUhNOnT/O/dTKBMjMzsWrVKkycOBH+OiIvWABlJSW2p4Dq0rs3f3SWG8gaCwBwPA7w8cfAv//N\nrbrFi7mbT6JWcKYA9CGibuCunhmMsX72nIQxNo0xdowxdiwrK8uJt+cErlzhH/6JE/nfjrqBnGkB\nADXbEM7aNhC62JMKmprKX5evr54AAED79u2dkwlkaAF89RXw88/mj0tP54+BgXjhhRfw8MMP49q1\na3oCsGzZMpSWlmLOnDl6hwoCUHn1Kh/87LUAlEp+PWdkApWU8B9zAhAUxC1NRwXg+nW+nnPfvsD8\n+byFxh9/OHZOCbtwmgAQUbrmMRPAJgA9DXZJB6DbwzdQs83wPD8QURQRRfkJJnpdQXD/vPwyd2c4\nSwCcZQHUpAvI2jYQuoSH8yIpW4KIqal8psiYkQBERETg/PnzIEcWKzcUgPx84K23gE8/NX+cxgJQ\nNW+O8+fPIy8vD+PGjUO5pyfQrBkqz5zBsmXLMGrUKIQbDPCCC8juDCBdYmO5ADjapE3IzjInAHI5\nEBDgmACo1cDNmzyNdcsWICEB8PEBJk+uvlXOJEziFAFgjHkyxhoKvwMYDMBwdPwDwERNNlA0gHwi\nuu2M64tSHV0L9+7lg3Xnzjxrw9FmXLdv88KbRo2cc381aQFY2wlUl7Awvv6BLT5kQQAArQAEBHDP\nYUREBO7evYs7jrRz8PfXdwGtX8+Ls5KTtUKVn5+PQkPXWloaIJPhWnExysrKMGrUKBw5cgRvvfUW\n0LEjcuPjkZOTgzfffNPokoIFwC5e5BvstQAALgB5eY632zZTBaxSqVAiuGkcrQXIyOCfgeBg/ne/\nfsCCBXxC4Yw1IyRswlkWQDMABxhjSQCOANhGRDsZY9MZY9M1+2wHcAXAZQDLAbwifioHqazkpup7\n7zn3vGo1zwAaOJBn23Ts6BwLoHlz6yppreF+cAEB1g9WKhUfbHQEoFmzZtoB1GmZQLoCIrh+ysuB\nS5dQUVGB3r1747nnntM/Li0NCAjAec1rmT9/Pl5//XV88cUXOO/tDeXNm3i4Rw/ExsYaXVK4f9ml\nS1xAHbF0hfM7GgcwIQDJyckICwvDY489xjc4ujDM9ev8URAAABg0iH8HHG3xLWEzThEAIrpCRJGa\nnw5E9KFm+3dE9J3mdyKiGUTUhog6EZGTFok1QCbjpqqjbQIMOXsWyMriAgBwAbhyxf42AoDzisAE\najIIbI8LyNZagJs3+WzRIAVUwCmZQM2a8f/hvXv8/5mYCIwdy587cwbfffcdkpOTcfDgQX1Xk0YA\nhCB0+/btsWTJEvTs2RPz//c/yAD8e+RIMBFxF1xA8itXHJv9Azyw7ufneBxA5P+5Y8cOREdHIzU1\nFfv370dFRQUXgFu37M+AExOAJk14TcPOnXbevIS91M9KYEfaDphC8P/rCgBgcQEQszirCEzAWgug\nstJxF1l2Ng8I+vhYf4yJpnBXr14Vd+PoZAABxgLg7+8PHx8fxzKBdIvBfv6Zz0Q//BBwcUHJ0aNY\nuHAh5HI5srKykKHrKtIUgZ0/fx7NmzeHj48P5HI51q5di3Oaorw+LuJfL8ECcL961TH/P8Dvt2dP\nx1cI07EAiAifffYZRowYgdatW2Px4sUoKyvjQtuqFU8BFgZyW7lxgz8aLoE6dChf5EZKDa1R6qcA\ntG/P8/SdGVTau5dnKwgDkCAAjriBnG0BCEFgc0FRtRro3h2YMcOxawmLh5sY5EwiIs7Dhg3DDLH7\n0REAIjISAMaY45lAuu0gfv6ZC3zbtkBoKC5v3oy8vDx88sknAICkpCS+L5FWAJKTk7WWCAC0atUK\nf548iYrWreFy+LDoJeVyOZQA5HfvOm4BADwedfmy+f+7JXQE4N1338Ubb7yBxx9/HAcOHMDjjz8O\nADhx4oTj6wJcv84nDULrEoFhw/j979lj33kl7KJ+CkB4OA/k2TtLMaSigmcrCLN/AGjdmvdisVcA\nysr4l87ZFgCRebdUYiJw+jTw008mO0meOHEC1y29d7YUgelikAqamZmJlJQUnBRb5Dw1lefqBwYi\nPz8f9+7d0xMAANqeQHYjCMDvv+ul+N5r3RoNLl/GpEmTtP7/U6dO8X3v3gWKi0EaF1B7g1l8SEgI\n3Pr2Bf7+W3RQVigU0A77jloAAJ+YFBc71hk0Nxdwc0MRePHak08+ifXr18PT0xNt27aFl5eXvgDY\nGwe4fl3f/SMQFcU/T1IcoEapnwIgfKmc5QY6epT7iHUFwNWVX8deAXDWYvC6WNMQbsUK3jZCpeL5\n7gYQEYYNG4a3337b/LVs6QSqi0FTuMOaWfLVq1dRbNjSIDWVDziaJnAARAXgzp07yLHXdSAI8A8/\n8HUNRo8GAGy7cQMhAD785z/h4+ODVq1aVQmAJgU0t0EDFBYW6lkAWmJi+HskWDE6KBQKaId9Z1kA\nALd67UVTBPb7xo24d+8eZs6cCReNdefi4oKuXbtyAWjRgouyswXA1RUYPJjHAaR1h2uM+ikAwpfK\nWYHgvXu5r7V/f/3tJjKBXn/9dWzYsMH8OZ1dBAZYbgldUMDTHJ99FnjiCeC777iw6XDlyhVkZmbi\nlqXZpL0WgEFPoL///hsAFx6jmbxICqihAAizb7utAD8//r8tKgLGjAE8PXHw4EGsPXcOLgCaa4Sq\nS5cuVS4gjQBcLi3Vuwc9hCpdzevTRS6XIxxApZub+GBoK6Gh/FFkIRqr0QjAypUr0bZtW/Tt21fv\n6W7duuHUqVNQAdx/b68A3Lhh+jUPG8YnB4LQSlQ79VMAhGCjtRZASYnp4qTcXGDrVqBLF+MBr2NH\nbnbrtDg+ffo0vvzyS8yePVt/3VdDzLSBOHLkiH1dLi1ZAGvX8tc6eTIwZw53ZaxcqbfLoUOHAADZ\nQp6/KRxxAQHa/82hQ4fgqznPOd26CiKrBECYfdstADJZ1evQuH8++OAD3BFSM8+cAcAFICUlBUVF\nRVoBOHv3rt49GNwYj8mIZOcIFkCBvz+f+TpKYCB3RzooAKUNGiA+Ph6TJk0yyl7q3r07iouLkZKS\nYn8twN27/LNpSgAGD+aPkhuoxqifAgBw94w1AnDxIv9A+voCI0cCS5cCR44A//kP8Oij3Ed85Ajw\n9NPGxwqBYJ2Ba6VmQE1LS8Nvv/1m+romLID8/Hz0798fL730kuV7N8RSS+gVK4AOHYAePfgMNSYG\n+OwzvWC5IAAW23DY6wIKCeEuhJQUqFQqHDlyBGPHjoVcLsdZXWsqO5tbMjoC4OLiguYGghkUFARP\nT0+rAsEqlQqbN2/G0KFD8dlnn1U94e/PPwMPPQSAW0FBDz3Eez5p7ikyMhJExO8xLQ1wccGx9HQo\nlUqIVqy7ugK9eolaAEIMIM/RdaAFXFz4++SgC+haQQEYY5gotDrRoVs33r39xIkTXHDsmaAIcSXD\nDCCBZs14gkJNp4P++988C+kBpP4KQHi4ZRfQ7dt8oREAGDeOf4HmzuVf3EmT+MA+ezaPAcyda3y8\nQSZQeXk5Vq9ejdGjR6Nz585YvHix6IIly5cvx63jx7nroWlTved+/fVXFBcXY+fOnbh928ZCaXMW\nQHIyX1hl8uSqwrM5c7gpv2mTdjfBJZOdnW26xUJxMQ+y22MBuLkBnToBy5fj+g8/oKioCH369EF4\neLi+BSCSAtqiRQvIDBZOd3FxQURERJV/XoSCggJ8/vnnCA0NxRNPPIFdu3bhf//7X9UOS5ZwcdT4\nvHNzc9G4SRM+i9exAABNIDgtDfD3x7mUFERERIjm+gPgAnvmjJFLTq5SIQRAjjNbnbRrZ9oCOH7c\nYnYN5ebizK1bGDRokJGVBQBhYWHw8PDgAhAQwCcwtq4LIFYDYMjQoVw0NdZVjbBvH39/DNyhDwL1\nVwDat+duClOujIICYPhwXty1fTsPAqak8C/32rV8sLx6lQ8OUVHi1bpBQXzWrRGArVu3Ijs7G5Mn\nT8Zbb72F5ORkbN26Ve+Q1atXY9q0adi/fj2oSRM+IOqwfPlyBAUFQa1WY/Xq1ba9ZnMCsHIld3c8\n+2zVtsce4wPs0qUAgOLiYiQlJaFhw4aoqKhAfn6++HXsKQLT5bffgObNETJjBt4FEN2jBzp06GBR\nAMQGJgCIiYnB4cOHeaGSCE888QRmz56NgIAAbNiwASNHjtQPGg8bBgwYAIDHInJzc6FUKrlQaQQg\nODgYjRo14nEAnRoAUf+/QO/ePKBp0K7ZIy0NLgAy7X3/xAgN5e+ZWOrzyy9z98q8eSZTo1VZWbhR\nVKRdtcwQmUyGyMjIKgFQq21vo22NAAwbxu/xzz9tO7cjCMtyPoCxh/orAEKwUcwNVF7Osz3OngU2\nbOADvEBAAK8E7dXLcosGxrhLRSMAK1euRPPmzTFkyBCMGzcOwcHBWLx4sXb3S5cu4eWXX0bz5s3h\ncfcu8g0WATlx4gROnjyJefPmISYmBqtWrbKt0ZmpIHBFBc9xHzFC3+JwdeUWzqFDwMGDOHHiBCor\nKzFEYxWZdAMJomqPCwjgs9XDh3GwdWssBBAyYwZ6tGqF69evV/XcEQRAk3ZoTgD69OmDkpISUSvg\n7t27iI+Px7x585CYmIgnn3wSTZs2Ra6Q925AYWEhVCpVlQDcuQNkZYExhi5duuDysWNAYiJKwsOR\nk5Mj7v8X6NWLPxq4geSa13ancWPTx5rhzp07xtZhaCj/XAuFVgJlZXxgCwrik5lHHzVelrO8HLKS\nEpS4u1e1fBChW7duOHHiBNSCGy7dqJejeW7c4LEKA6tXj169eJ1ATcUBioqq0mdrqhdRSYn5greC\nAueu9WyG+i8AYm6gadN4Zs+PPzru+9NkAmXcvo0dO3Zg4sSJkMlkkMlkmDNnDg4ePIgDBw6grKwM\n48aNg1wux99//41WCgWS8/L0Bvjly5fD3d0dEyZMwKRJk3D+/HkcO2ZDxwxTMYAdO/hAJja7mzQJ\naNwY+Pr7E1IUAAAgAElEQVRrrf9/5MiRAMwEgi1YAIsWLcKCBQt4wNQUDRpgikyGrzt3Btu/H89o\nvvBaX35qKhdjDw8QEdLS0tDShO9Y6Ldz4MABo+cSExOhVqsxVOf/7Ovri5ycHFFxFYRBqVQaufgi\nIyPRKSkJKCnBec01zVoAjRuLtmuWpaZCDSDDsBjKSkaPHo2wsDDs1V2XWkgFNXQDnT7NJwCffsqt\n3H37eOWwTswkX5PR07ZnT7i7u5u8brdu3VBYWIg04X2zte7g+nXu/zc3sZLJuLWybZv1hZx//gm8\n/7596zoIK84BpgXgf/8D3njDsbYvusyZw9NpFy3i/xtdduzgn7tRo5x3PTPUXwEIDuazDUMLID2d\nB3jnzAGef97x63TsCOTkYOO330KlUmHqoEFcYHbuxOTJk+Hr64vFixfjrbfewsmTJ7Fq1SoEBwej\njacnUgoKsHv3bgBAUVER/vvf/+Kpp56Cj48Pxo4dC3d3d6xatcr6e1EoeB8kQwFYsYIHOocNMz7G\n0xN46ilgyxac+OsvtG7dWjurtccCqKysxAcffIBFixahY8eO2LVrl+gp8vLycCElBYXjxwMLF6LZ\nqVOIhE4m0JUrWvdPdnY2SktLTVoAzZs3R+vWrUUFID4+HgqFAtHR0dptSqUSZWVlVR0uddATgE6d\n+EYhDhAZiRfKy1HasSOOamI7Zi0AgMcBDh3SKwhzOX0aVwEU2ZHvfufOHRw8eBDl5eUYOnQofvnl\nF/6EqVRQYQIRFQVMnQrEx3MLccQI7eCz89dfAQA9hHiYCbp37w4AOJmZyTfYagEIAmCJJ5/kE5bE\nRMv7EgGvvgq88w7/zk+dalv9z+XL/DEwsOq9MuSjj3iyRJ8+jheXEvG1Dzw8eBfUnj35sp45OTwL\nbfhwwMsLtGUL/25WM/VXAFxceMqh4Ydhyxb+aMLXaTOaWeLplSvxfVAQ2owYASxfDnz5JTw9PfHa\na69h69at+PLLLzFr1iw+uyaCZ2Ehiho2xKJFiwAA69evR2FhIaZOnQoAaNSoEUaPHo3ffvsNpZp8\nc6sw7AdUWQn17t0oGzmSz67EGDMGuHcP7vv3Izo6WpvVYlIAzFgA58+fR0lJCWbOnAl3d3cMHToU\nEyZMMDrXkSNHAIAPzNOng7y8MM/FpUoArEgB1aVPnz44cOCA0aw+Li4OvXv31pvZKjUdL8XcQHoC\n4O/PX6PGAohlDB0BnOnTB+fPn4eXlxcCDZeENKR3b55KfPEiD55PmQJs2oQEmcx8mrAJtm/fDgDY\ntWsX+vbti4kTJ+Kjjz4CNWvGC9kMBeDoUS7Ugt89JoZPCK5e1aYA/605Z2tdV6gIERER3IJNTeWf\nJXsEwJq6h0cf5QPk+vWW9z1+nMfu/vUv4MUXgdWrudU1c6Z19yQIwNixfKwwDAQXFHBhGDyYT0p6\n9ABEJhpWk5LC37clS4CNG7nV0qMHH6t++w0lc+bg7UcfxaPvv+/YOhfWQkR19qd79+7kEOPHE4WE\n6G8bNoyoTRsitdqxcwtkZBABVMK1neipp4gee4yocWMilYqys7PJ09OTunXrRqWlpfyY7GwigOKf\neIIAUGJiIsXExFB4eDipde5r9+7dBIDWrVtn/f20bk00YULV36dPEwH0eVSU6WPKy6nSx4d+BujL\nL7+koqIiAkAfffSR+P7//jd/rRUVRk/9+OOPBIBSUlKotLSUFi5cSHK5nKKioqhCZ/93332XXFxc\nqKCggG+YPZsqAJrQrx9RURE//wcfEBHR5s2bCQAdPXrU5Ev4/vvvCQBdunRJuy03N5cYY7Rw4UK9\nfX///XcCQKdOnTI6z9q1awkAnT17lm946CGi6GgiIqp8+mm6C9C7c+fSI488Qj169DB5P1rOneOv\nZf58oo4diRgj+uc/ya9xY3r11VctH2/A6NGjKSAggNRqNZWWltLTTz9NAOjdd98l6tKFf7516djR\neJtazV9TUBCpS0poQsOG/B6PHbN4/e7du9MjjzxCFBRENHGi9TdeUsKv8d571u0/ZgxRs2ZElZXm\n95s5k0ihIMrL439nZhI9+yy/VkqK5etMnUrk50e0ZQs/Zv9+/ee3buXb9+4lSk4mateOyM2N6Jdf\nrHsdhnz5JT9fair/OzeXaMoUqoiNpW+nTydvb29ijNHTTz9NxcXFdl0CwDGycoyt9UHe3I/DArBw\nIf/CCW9kYSGRXE40e7ZNp3n77bdpzJgxNHnyZJo9ezYtXLiQPv30U/rpp59o/bp1lO7lRcmM0b3N\nm/kBP/3E39rkZCIiunTpEuXn51ed8OxZLhqrVlGTJk2oU6dOBIA++eQTvetWVlZSYGAgDR8+3Pqb\n7dKFaNQo7Z+5S5cSAdTexYVu375t8rAr/fvTXYCOHjhAREQeHh70xhtviO6bMmQIlXt5iT43ffp0\natSoEalUKu02YVD9+OOPtduGDBlCnTt3rjrw2jWqZIy+9/IiOnOGv3+//UZERF999RUBoIyMDJP3\nf+7cOQJAK1eu1G4ThCMhIUFv37i4OAJA+/btMzrPt99+SwDo1q1bfMOrrxJ5eRFlZREpFPSrUknD\nhw+nFi1a0ERrBkCVisjHh78ePz+iXbuIiKh58+Y0depUy8frUFpaSl5eXvTSSy/pnF5FgwcPpjZt\n2hCNHUvUtm3VAffuEbm4EP3rX8Yn27OHCKDc99+n54XJy5UrFu9h6tSp1LhxY1JHRxMNHGj9zV+8\nyK/xn/9Yt//atXz/uDjT+5SX8/d0zBj97bdv80H69dctX6d/f6LevYlu3eLX++wz/efnzOECI4wh\neXlEPXoQBQRY9zoMGTWKT9J02L59OymVSgJATzzxBJ05c8a+c2uQBEBgzRr+EpOS+N8bNvC/4+Ot\nPkVmZiYBIH9/fwoICCAvLy8CoPfjDtDk55+vOuj8eX6dFSvET6r58lFCAn3wwQcEgNzc3CgzM9No\n13/+85/k4uJSNSBZol8/oocf1v6ZOnQo5QPEAPq///s/k4ctHz2aCKDyTZuIiKhly5b03HPPie77\nu7s73XR3F32ue/fuNGDAAL1tarWaHn/8cXJ3d6eLFy+SSqUiHx8fmjZtmt5+ZyMjqQCge99+y9+f\nI0eIiOitt94iuVyuJyqGqFQqUiqV9OKLL2q3zZo1i9zd3assLw2nT58mALR+/Xqj83z44YcEgEpK\nSviG77/n9/Laa0QA/WPECGrcuDHBwvupx+uvEw0fTpSert0UHBxMz+t+Zqxgz549BIC2bNmit33h\nwoXEGKPyt94icnXlAyMRUWIiv/c//jA+mVpN1LcvlSiV9E9BAO7etXgPgkDeGzqUKDxcfKd584hG\njza8ecsDui737hF5eBC98orpfbZt4+f83/+Mnxs/nqhRI34ecwQFEQmf8xYtuPWgS7duet8nIuLW\nnJub7V6Eigqihg2JDD73vXr1ojZt2tAxKywwa7BFAOpvDADQW6AbAA++NG5ctYqSFSQkJAAANm7c\niLS0NBQWFqKyshJ5eXm4du0akpKS8OeBA/ji66+rDgoL46lsIlWgAPTWAp4xY4bW3y9WUfr888/b\nVhNgsC6wPCkJJxhDVI8e+Omnn7jqi7D69m0UurrCTVMg5efnJ5oFVFFRgQalpbhVWooCg2BzWVkZ\nTp8+jR49euhtZ4xh2bJlUCgUmDJlCi5cuIC7d++it9AvR0P2pEloCMBVWM1NJwYQGBiobU4mhouL\nC2JiYvQCwXFxcYiJidH23xewFANo0KBBVcxAyAT65hsgJgZN+vdHniaN0mwGkC6ff86zWlq00G5S\nKBQos3FRla1bt8Ld3R0DNDULAhERESAi3BKa/Al9eoT6AzHfPmPA++/DPTcXrwEgV1fjFs0iCIHg\n2y4upmMAu3dz/7ZuwNSaGgBdPD15LOD3301nA/3yC4/RiGXyzZjB13fWBLhFKSnhiw61bcv/7t5d\nPxCcm8sDtIY9wPz8eADdVJ2MKY4c4QH4Rx7RbkpPT8fhw4cxefJk7XtbkzgsAIyxIMZYHGPsPGPs\nHGPsdZF9HmaM5TPGTml+3nH0ulYRGso/6Bcu8KrFbdv4h8pUMFSE+Ph4eHp6IkrnS+Tq6gofHx8E\nBwejc+fOiI2NhZeXV9VBLi5AdLRpARByuDULmpw8eRLff/+96K7t2rVDZGSkyWwaI3SDwOXlaJqR\ngWt+fpgxYwYuXbqERJHMivLychw6cQIpYWHA5s1AeTn8/PxEg8AZGRloAiALwP79+/WeS0pKQkVF\nhZEAAECLFi2wdOlS7N+/H9On81VCdTNzAKDlY4/hTwDut29zAdUM1Ddu3DAbABbo06cPUlJSkJWV\nhdzcXJw+fRr9Db+8sCwASt1lEQUBUKmAl17SVgQDVmQAmcFWASAibNmyBQMGDEADg/oR4T5SBHEX\nAsFHj/JUWlMdZx96CKebNoU/AKZUWrU0aadOneDq6orUkhI+mBnWnBBVXX/duqrtN27w74WloLku\nTz1lOhuooIB/VseN45lvhsTG8rW7ly0zvU6CIJSCAERF8SCt8Jr27+fHGgiuNvvNUr8sQ/78k7/H\nOufbvHkzAJ7aWxs4wwKoBDCHiCIARAOYwRgT+2YkElEXzY+TF+w1gYcHLyS6cIHnYufk8PxaG4iL\ni0OfPn3gZlCxa5HoaN5KQmyWkJHBZziavP2QkBA0MrMwfJ8+fXDo0CFUWlN6ryMAdPo05EQo69gR\nY8aMgbe3N3788UejQ5KSklBWVsYzhe7eBeLiTApA3r596AzgIoA/Dao1j2pmnGICAACTJ0/GwIED\nkZiYCB8fH7QTctc1BAcH4ythtt66tfbeDh48aCQWYvTp0wcAcPDgQSQkJICI8PDDDxvt5+HhAQ8P\nD9EW0rm5udrmdAD4+xkczC3Hp55CZGQkAD6Ahwi98e1ALpfblAWUkpKCK1euYMSIEUbPhYaGwtXV\nFceEz5owAB87xjNMzPCBMHiKLAYvhru7Ozp06IBTwmfD0Aq4c6cqk2bNmqrt169XtZI2YO3atfji\niy+ML2YuG2jjRt6ORLeyXcPKlSsxb/58bgUkJZkuqhIygHQtACI+6wd4zUSDBjxVUxfBUrfUL8uQ\nP/8EunXTy57buHEjwsPDEe6MtuB24LAAENFtIjqh+b0QQDKAAEfP6zSEnkB//MFnCjYUfmVmZuL8\n+fOig4hFevfmHyZNuqMet2/b1Aa6T58+KCoqwunTpy3vrLMucJYmva/RI4/A09MTzzzzDDZs2IC7\nBn1WhAKw4ClTuCht2IAmTZoYC0BJCYLffhtZAH5o2lS/EAlcAJo2bWpyts4Yw/Lly9GgQQNER0cb\nuXRcXFxwq2NHnGvUCOjdG0SEN954A40bN8a8efMsvvSoqCgoFAocOHAA8fHx8PDwQE/DL68GpVJp\nnQUA8BTDL78EPDzg6+uLwMBAhIWFwdWBTp62WgBCS5FHH33U6Dm5XI7Q0FAcu3qVW06XLnEhv3TJ\nrAAUFhZiQ3o6znfoUFXzYAVDhgzBHqGQzFAAhEF18GC+TKXQoM5ECmhhYSFefvllzJ0717i62Zwb\n6JdfuIvQYGKgVqvxr3/9C0uWLMGpDh2ARo24FSCGcK9CDYXgghEKwuLieO6/oYVhjwAUFnKPgI77\nJycnBwkJCbU2+wecXAfAGGsFoCsAsbXwejPGkhhjOxhjHcycYxpj7Bhj7JjFjpTWEB7OzbrNm7kv\nT6iWtYL4+HgAEHUjWERoJSHmBsrIsGkhGKHS9a+//rK8s7c3921WVKAwLg7ZAMI1ovfiiy+ipKTE\nqEvpoUOHEBAQgMC2bXlH1E2b0FSpRHFxsf4iLf/4BxqlpWESgBETJ+Ls2bN66+QePXoUPXr0MN0c\nDdzaSUhIwNe6MRMdOnTsiMHu7sBXX2Hr1q3Yt28fFi5ciMZWtE1QKBSIiorCgQMHEBcXh9jYWO0C\n7IYI1cCG5OTkGAvAiy/qzTTnzZuHmdbmmZtALpfbJADbtm1Dp06dTFZDR0RE4HxyMh/MLl7ULwAz\nwZkzZ0BESP3wQ313jQVmz56NO4Ib1VAABOtjwQL++V+7lv9togjs22+/RV5eHiorK/HTTz8ZX0zM\nDZSWxgfnZ581clslJCQgXXNPH37+Oa9037BBvG/R5cvc8hE+W/7+3GV2/Dhfl+DsWWP/P2CfAOzf\nz93QgwZpN23ZsgUqlQpPPPGE9edxMk4TAMaYF4DfAcwiIsNuZCcABBNRJICvAGw2dR4i+oGIoogo\nSrTNrq20b89NxdRUm90/8fHx8PLysi8406gR7yYpJgA2WgBBQUEICgoSrXQ1QhC4wkK4nzuHEy4u\n6KDxY3fv3h2RkZFaN1BhYSHeeecdbNy4USsyGDMGyMlBZ02gUyvCe/YAX3yBA926IVGhwNixYwEA\n+/btAwDcu3cPycnJJt0/ukRFRaGNJsBrSIcOHXDrzh3cyczE3LlzERYWpo0ZWEOfPn1w7NgxnDlz\nxqxw22QBGPDqq6/ixRdftPqexFAoFFa7gO7evYvExERR949AREQELl++DFWbNnwQtkIAhAVuIrt2\ntcr/L9C8eXMM1bz+XMMFkS5d4jG2mBigb1/e+E+l4sFWAwugpKQEn376KQYNGoRBgwbh+++/N3Zz\nCm6gxYt5Ne577wHTp3PrWsT9s3r1ajRs2BCzZ8/G77//jtQhQ3jAdvly4xdy+XKV+0dACARrJn/o\n3x87d+7EkiVLqvaxUQBSU1NxY8UK3plAJwFl06ZNCAoKqpXgrxZr04XM/QBwA7ALwBtW7n8NQBNL\n+zmcBkpUlQoHEN28adOh4eHhNMywiMYWpkzhOeC66YuXL/NUvX/+06ZTjR8/XlsAZJYVK/hrPXeO\nKgBaaZCv/OWXXxIAmjdvHvn5+REAGjduHKULKYrFxUSennSvaVP6AKDzP//MC9datCBq354mPvUU\ntW7dmiorK8nHx4cmT55MREQJCQkEgLZt22bT6zJk+/btBIDGjBkjmvJoiS1btmjTc//66y+T+40e\nPZoiIiL0tqnVapLL5TRv3jy77t0WRo0aRV26dLFq3zVr1lh8Pb/++iuvlXj5ZV77Mnw4L3g0w7Rp\n03hOvx1FkWlpaZQH0F6D95DGjCF1aCgVFRURffMN/yzu2MEfv/1Wb1ehviM+Pp42bdpEAGizUEuj\ni1DYJfy4uxvn/hNRcXExeXt70wsvvECZmZnk4eHBU20feYQoONg4bTMkhOiZZ/S3vfcef/8mTOAp\nmxUV9OSTTxoXDjZoQGSiTsaQ8ePH0xmAcnXGs8LCQlIoFDRz5kyrzmELqMk6AAAMwM8APjezjz8A\npvm9J4Abwt/mfpwiAJqqW+rWzabDbt++TQBoyZIl9l/boCCMiPiH2cODF57YgPBluXbtmvkdNbUO\nlcuWEQH0w6OP6j2dk5NDCoWCANDDDz9MRzS59nps2UJ3u3WjCt0vnExGdPw49evXj/r27UtEfBBt\n2bIlqdVq+uSTTwgA3blzx6bXZcj169e1A/gjjzxi8+CUk5NDAKhBgwZULuTDizB16lTy9/fX23bv\n3j0CQIsXL7br3m1hzJgxRgJkiueee458fX2p0kxV7KlTpwgAHXz1Vf4/c3PjufBm6NmzJ/Xv39+m\n+9blVuPGtIkxvc9kaUQExXl6UkxMDNGdO3yy8/DD/J62b9fuV1ZWRkFBQRQbG0tqtZoqKiooMDCQ\nBg8ebHyhigo+ecvLI6qooK1bt9JnhgVbRLRu3ToCQHv37iUiotdff51cXV0pa8kSfv3jx6t2Livj\nRXLvvKN/EqG2QCYj0nx3HnroIQJAY8eOrdqvZcuq+gEL9G3blgig9xs21BYzrl+/Xit+zsYWAXCG\nCygWwHMABuikeQ5njE1njAm2+xgAZxljSQC+BDBec6PVj68v9+NpVtiqrKzEsGHDMG7cOO2C5GII\n/n+7AsAChuvCnjsH/Pe/vHmVjYvBWx0H0ORyF/7xBwBAKSyzp0GpVGLDhg3YuXMn9u3bJ+6yGTEC\nmWvWoBmAv6ZN43GBb78FunVDenq6tv/NwIEDcePGDaSmpuLo0aNo2bIlmppr9WsFQUFBaNiwIVxc\nXLB06VKz8QQxlEolunbtigEDBpjN3BJcQLofQ70+QNWMLUHgCxcuoHv37maDzu3atYOLiwtOC32j\nKirMun9UKhXOnDmjzWqyh8YdO6IFoG15fuL4cVQmJyOpqAgHDx7E9ZISYODAKneKjgto9erVuHnz\nJhYsWADGGGQyGaZOnYrdu3fjshCcFZDJePqojw8gk+HTTz/F7NmzsdNg5bDVq1cjICAAD2lWdpsz\nZw5cXFzw8YULPAV148aqna9d42sAiLmAAO6v17gQBTfo+vXr+ZKYAHcDWZEGWlpaihBN++9tZWV4\n9tlnoVKpsHHjRjRp0kSbuVZrWKsUtfHjFAvAgB9++EE7QwRAsbGxtHHjRqPZ1UsvvUTe3t56/Wts\nRmgDIJT8jx7NzcrsbJtPVVFRQV5eXvSKucpIIqJDh4gAKvbyonSALly4YMeN8z46AGjp0qXabWq1\nmhQKBc2dO5eIiC5cuEAA6LvvvqPWrVvTk08+ade1DJk+fTotWLDA7uMzMjIoNzfX7D5LliwhAFRY\nWKjdJsyif//9d7uvbS2TJ0+mwMBAq/YNCQmhZw0rVEVo27YtTXzssSpXiUELDF2Sk5MJAK1atcrq\nezZi0iTK9fQkuVxOK1asoDYNGhABdGrqVAJAX3/9dZVLEuCtWIi3OAkNDaVu3brpWXjp6ekkk8m0\nny9TBAQEEAAKDAyku5rq5aysLJLJZPTmm2/q7fviiy+SQqGg0pgYIl2LS5jpHzxofIHAQP7ciRNE\nROTn50ejR4+ucikREQ0dSmSuv5aG48eP008AlXp50XJNv6oFCxaQt7e3XtW6M4HUCkKc4uJiCggI\noN69e1NBQQF98cUXFBISQgDo8ccf1xvs27VrR48auE/sYuhQ3pDr2DH+dr/7rt2nGjRoEEVGRprf\nSWg+BtA2mcxs+wRzqNVqkslkNH/+fO227OxsAqA1v9VqNQUGBtKAAQNsa41QBxCa1l2/fl27bd++\nfQSA4qxtV+AA06dPp6ZNm1q1b8OGDWnWrFkW9xs1ahR3K/n5cT+2jrgZ8ttvvxn7tW1lwQJSu7qS\n3NWVANCkNm34Z2/nTgoNDaUhQ4Zwt42bG5FSaXTtDRs2GJ1yzJgxpFQqTTZCKywsJAD02GOPkYuL\nC02ZMoWIiJYtW0YAKElo+6Lh4sWL5OLiQpsHDuT3JkyIvviC/y3SfoWeeILfr0pFKpWKXFxcaMGC\nBTRr1ixydXWlK1eucPdPcLDFt2jVqlWUBFBh376kVqtpwoQJWhfn1q1bLR5vD7YIQP1uBWHAN998\ng/T0dCxatAgNGzbEzJkzcenSJSxZsgSbN2/Giy++CLVajVu3buHixYv2pX8a0rt31drCSiVfWMJO\nYmNjcebMGdNLNQJ65fyZQUFm2yeYgzFmVAuQplkIXHABMcYwcOBAbSaQNRlAdQXBzaObCloXXUBl\nZWUoLCxEEytWX4uIiMDFixehDgvjGWi61ekGJCUlwc3Nzfp2FmIEBICpVFj0+usYO3Ysvpk9m29v\n2xYjRoxAXFwc7slkPJWza1cAfML5ySefIDw8XDT98eWXX0Zubi7Wm2gFfUmTZjphwgS8+eab+PHH\nH7Fr1y6sXr0anTp1QufOnfX2Dw0Nxbhx4/CWUAwmrH99+TL/roi9r0uX8oVZXFyQl5cHtVoNPz8/\nzJ07F66urtzl5ednVRZQ8vHjiADQoE8fMMbw3XffISwsDN7e3hg4cKDF46ubB0YA8vPzsWjRIgwZ\nMkTPr+/q6oo333wT7733Hn7++WfMmjXLsfx/Q4SCsMREviarnatAAVwA1Gq1tnBLFJ3zqx1MLzPs\nByTkVwcEVNX5PaJT2FKr6Ww2IlT76qaC1kUBEN5/a1KiIyIiUFlZiWtvvskLpcxw6tQpbX9/u9F8\nDuaMH4+1a9fCIy2N++uDgzFy5EiUl5djz549wKpV2iUejxw5guPHj+O1114TnZz0798fYWFhohXr\nALQ++LCwMCxcuBDh4eGYOHEi/v77bzwrkhYKAAsXLkRqeTluNGumLwBt24qnv4aEaKt/hQmQn58f\nAgIC8MILL2DlypXIl8v5+g66dTIilBw6BBkAF83kyMvLC/v27UNcXJzZ1ddqigdGAJYuXYrc3Fzt\nAiyGvP3223jjjTfw1VdfYc6cOfDx8XEoQKZFKAjz9+fBX4dO1QsuLi7mA8E6sz4/sRXAbMCwHYSY\nAAiNycLCwsy2s6hr1LYFYG0rCOH9t9YCAICTFRXaGbcpkpKSHP98C58DoRjs8mXewkMmQ58+fdCo\nUSNs2bKFt3/QBOSXLVuGhg0b4rnnnhM9JWMMw4cPx9GjR0Vbn1zUVBaHhobC3d0dK1euRHZ2Nhhj\nePrpp0XP2a5dO0yaNAk/ZGfzyvy0NPEaABF0BQDgRYAqlQo7hDoLC1aAp7AglU5AvkWLFujWrZvF\na9cED4QAZGZm4tNPP8VTTz1l8o1njOGTTz7B5MmTkZGRgX79+jlU6q/F2xv4xz94Fo1BEy9badiw\nISIjI80LgIsLyt3dcQ1ApM7s3B7EXECMMTTXyWBq0aIFevfujcEG2UZ1HVMWgEKhgIeHR7VfX6FQ\nQK1WW+zvZIsFIPSTOa+z3q8YwqLyuo3t7ELobioIwKVL2kHVzc0NQ4cOxbZt26DWLH2ZlZWFtWvX\nYuLEiWhopiI/MjISpaWlWnePLikpKWjZsqX2fxQdHY3FixfjtddeM9sw8J133sEfgsWxYQNvBGeD\nAAgCHBISgvHjx2OzUJRpJhMoMzMToYWFKPbysq0JXg3yQAjAhx9+iNLSUrz//vtm92OM4YcffsD7\n77+Pt99+25k3ADz+uFNOFRsbi8OHD5sdOPJlMiQpFFZ10DSHmAXQrFkzo/TK/fv34/PPP3foWjWN\nWEpf3AEAABo7SURBVEdQoQrY1tRTexBcL5bcQIIAWGMBeHp6olWrVhYFQKgAdlgAmjYFXF25ABDx\nWbXQVwfAyJEjkZmZqW0S+NNPP6G8vByvvPKK2dMKlolwn7qkpKQgLCxMb9vcuXPFm8np0LJlSwyc\nMQPJAMo//ZSneVohAGIC/Oyzz+KGkG5rxgI4c+YMugMobt/epkrrmqTeC8D+/fvxzTffYPLkyUYf\nHDFcXV3x9ttv19mAZmxsLIqKikS/HAKv+vlhU2yswwOZn58f7t69iwrN4uG6NQC6yGQyu4PNtYVC\noYCnp6eRC6gm3D/C9QFYdAPZ4gICND2BrBQAh11Arq68niU9nfe3KirSE4Bhw4bB1dVV2/Pmu+++\nQ//+/S220W7fvj1kMpnRZ5yIcPHiRau+x2L84x//wFY3N8g1a0zbYwEAvP6lXIi1mRGA88eOIQKA\nhw3rj9Q099e31kbS0tLw1FNPoXXr1vj4449r+3acglA4YsoNlJ2djXVXr6KdEzIMhFmPMEimpaXp\n+f/vdwz7AdWGAFhjATDGrL6viIgIpKSkmLUQT548iaCgIOe81oAA4NatqiZwOoOqUqlEbGwstm7d\nim3btuH69euYMWOGxVMqFAq0b9/eSAAyMjJQWFho1EbcWpo2bYqGEydWbbBSALy8vPQCtm5ubuip\n6cpaadjBVIf8/fshA+CpKUyri9RbASgrK8OYMWNQXFyMTZs23VcBSnMEBgYiODhYm6lkiLBIi0MV\nzBoEARBmQenp6fVOAGrLAhBcQNZYAEql0up4VEREBMrKynBVWOzEACJCXFycVesrWEVAALcABAHQ\nsQAAYMSIEUhKSsI777yDgIAAPPbYY1adNjIy0kgAdDOA7OXpTz5BmosLSl1drWrImJ2dLRp/GTFh\nAioAXNddQcwA+Zkz/Jc6nB1XbwVg5syZOHz4MFatWuXQyk11kUGDBmHfvn2iszyhD36UmTYA1qIr\nAMXFxcjLyxN1Ad2v+Pr63hcWgC1dcYXPuik30KlTp5CRkSG6roBdCAJw+TLP9DFo+Txy5EgA3O30\n0ksvQWblanyRkZG4deuWXhqykAHkiAA08vHB0X798DMRyjWuTXNkZWWJvv8DH3kEOYwh/dQp0eNU\nKhX8b91CoYdHnQ0AA/VUAH788Uf88MMPmD9/Pp588snavh2nM3jwYOTn52uDa7okJCSY7YNvC4Lf\nMysrSzQF9H6nNi0AawUgKyvLav8/ULVOsSkB2LZtGwBgqA0LI5klIICvQHfyJM+fNxjgw8LC0LZt\nW7i5uWHq1KlWn1YsEJySkgJ3d3eHkxvUr76Kl9Rqs3E0AVMCoFAoUN6oEQqvXhW14i5fvowuKhXy\nTdUa1BHqnQDk5ORg9uzZGDx4MD744IPavp1qYeDAgWCMYffu3Xrbc3JycPr0aW0zLEfRtQDqowDo\nWgClpaUoLi7WXw6yGrHWBWSrBeDt7Y3AwECTArB9+3ZERUWhWbNm1t+sOYTPw19/Gbl/AJ5Z99FH\nH+HTTz+Fvw1rYJgSgNDQUIcTDgT3l9mCSg3mBNijZUv4VFYiLi7O6LlzR48iAoCsVy+H7rW6qXcC\n4Ovri127duHXX391Th5/HUSpVKJHjx5GAiAs+O4M/z9QlSuflZVl1AaiPqDbETRPswBOXbMAsrOz\nbbIAAJ7emZCQYOQizM7OxqFDh5zn/gGqBODePZNB1TFjxuBVG4sgmzZtCn9/fz0BcCQDSJeAgAAE\nBARYFAAiMivAynbt0Iwx0bYV2Xv3QgZAqbMCWF2k3gkAAMTExNTYTK62GDx4MA4fPqy3vm98fDzc\n3d2dlsIqk8mgVCqRnZ1dLy0ApVKJyspKFBYW1mgVMGBdHYAwANkqAC+88AJu3rzJq3B12L17N4gI\nw4cPt/2GTaH7eRCxABxBNxBcXl6OK1eu2J0BZEh0dLRFASgqKkJpaalJAXD190dzNzds2rRJmyqt\nRbOusFxoCV9HqZcC8CAwZMgQqFQqPfMzISEBMTEx2tmlMxCKwdLT09GoUSN4mWkwdr+hWw1c0wJg\nTR1Afn4+KisrbXIBAcCoUaMQFBSEr776Sm/79u3b4efn55QEAS3VLADnz5/XDv4qlcopFgDABeDK\nlSswt+64YRsII/z84FlejoLcXCQkJOg9pbx6FfkKRZ0OAAOSANy39OrVCw0bNsSuXbsAAHl5eUhK\nSnKa/19AaAdR32oAAP1+QLUlAOYsAFuLwARkMhleeeUVxMXF4axmzV6VSoWdO3di2LBhzi3a8/Tk\n618DVuXV20JkZCQqKipw4cIFp2QA6SLEAcwtCmXx/dcIQ3CDBnpuoMLCQrS7dw9ZwcF1OgAMOEkA\nGGNDGWMpjLHLjLH5Is8rGGNrNc8fZoy1csZ1H2Tc3NwwYMAA7Nq1C0SExMREEJHT/P8CuhZAfRMA\nXQtAyAaqSy4gW/oAGTJlyhQoFAp8/fXXAHgXzpycHOe6fwQCAkRTQB1FNxAs1AA4ywXUrVs3yGQy\ns24gi++/RhjGDhiA5cuXY9q0abhz5462AljtaKuNGsBhAWCMuQJYBmAYgAgATzPGDBPvXwSQR0Rt\nAXwGYLGj15XgcYBr164hNTUV8fHxUCgU6KlpY+ssBAFIS0urVwFgoG5YAOZcQPZaAMIxzzzzDH75\n5Rfk5eVh+/btcHV1rZ6mfS1bAm3aGKWAOkpYWBgUCoVWAPz8/NC4cWOnnLtBgwbo3LmzWQGwxgUE\nAAumTcPs2bOxcuVKhIaG4td58yAD4FMH+v1bwhkWQE8Al4noChGVA1gDwLDc7zEA/9H8vgHAQFYT\nHbfqOcKXeffu3UhISEDv3r2d3mNcWBMgIyOj3lkAug3hcnNzIZPJaizGYY0LyJZGcGK89tprKC4u\nxsqVK7F9+3bExMQ4bQDV4+OPec9/JyOTydCxY0ckJSXh4sWLTpv9C0RHR+PIkSNQqVSiz1srAJ7F\nxVi6dCnOnTuHhx9+GCpNfY6fs2otqhFnCEAAgJs6f6dptonuQ0SVAPIB1O80nRqgTZs2CAkJwbp1\n63Dy5Emn+/8B/uFXq9VQq9X1XgBqqhMoUP0uIADo2rUrYmNjsXTpUpw4caJ63D8A0LEjX/eiGhAy\ngcS6gDpKdHQ0CgsLkZycLPp8VlYW3NzcTLeuFv4vGqFo164d/vjjDywYPBhljRqBOViwVhPUuSAw\nY2waY+wYY+yYuQi9BC+yGTx4MBISEqrF/w/oDz71zQUkl8vh5eWldQHVlPsHsN4F5O7ujgYOrCPx\n2muv4datWwBQfQJQjURGRiIrKwuZmZnVIgCA6YIwoQbA5KTA15cHeQ3GqebXrkHRr1+dDwADzhGA\ndAC6Uheo2Sa6D2NMBqARgByIQEQ/EFEUEUXZO/N5kBDcQHK5HL2qYRam636obxYAUFUNXFsCYMkC\nMDsAWcHo0aPRokULBAQEoFOnTnafp7bQbVntbBdQ27ZtoVQqTQqAqTYQWlxd+TrfugKQkwNcvAjE\nxDj1XqsLZ0RtjgIIZYyFgA/04wE8Y7DPHwCeB/A3gDEA9mlWr5dwkAEDBsDV1RXR0dHVspJVfbYA\ngKp+QLm5uTUqcNa0grC1D5AYbm5uWLNmDSoqKmrMveVMdBd5d7YFwBhDdHS0yVRQq97/Jk30BUAQ\nkzpeACbgsAAQUSVj7FUAuwC4AlhBROcYY+8BOEZEfwD4CcAvjLHLAHLBRULCCfj4+ODDDz+sttmd\nIAByudzhwaguIrSDyM3NrdEZskwmA2PMKgvAUfr27evwOWqLxo0bo2XLlkhLS0ObNm2cfv5evXph\nx44dKCgogLewyIuGrKwstGrVyvwJ/Pz0l4X8+29uGTiz2K4acUreFhFtB7DdYNs7Or+XAnjKGdeS\nMGbevHnVdm5hAGrRosV9OYO0hK+vL27evFnjLiDGGORyucVCsOoY9O43evToAU9PT6d0uDUkOjoa\nRISjR49ioEHaplUC7OfHXT4Cf/8NREbyArn7gDoXBJaoW7i7u8PLy6teun8AbgHcuXMHhYWFNSoA\ngKalsBkXkD19gOojy5Ytw9atW6vl3ELdjGEcoLy8HPn5+dYJgOACUqmAI0fuG/cP4CQLQKJ+07Jl\nS7R1cpl/XcHX1xf5+fkAaq4ITEChUJi0AMrLy1FQUOAUF9D9jtNaV4vg4+OD9u3bGwmA1TUYfn48\n8KtWA2fP8q6okgBI1Ce2bdtmOhf6Pkd30K9pATDnAnK0CEzCeqKjo7FlyxYQkdbNaXUNhp8fn/nn\n5XH3D3DfZAABkgtIwgpatWpVb9tr16YAmHMBOVoEJmE90dHRyM7OxpUrV7TbLFYBCwgCnZUFHDwI\nNGsGWAoc1yEkAZB4oNEVtrrkAnKkD5CEbQgFYX8LM3jYIADC89nZ3ALo3fu+KAATkARA4oFGd9Cv\naSvHGheQZAFUPx06dICXl5deHMBqARb+P8nJwOXL95X/H5AEQOIBp7YtAFMuIMkCqDlcXV3Rs2dP\nPQsgOzsbjDHLkwJBAITV1yQBkJC4fxAGfRcXF6NCoOrGnAtIsABqWpQeVHr37o2kpCQUFxcD4AKs\nVCotrysuCMCePbwd9n1SACYgCYDEA43QHrlx48bOXSnLCuRyudkgsFKphMzJPfYlxImOjoZKpcKx\nY8cAWNEHSEChABo2BEpLga5dgWpox1KdSAIg8UDj5uYGb2/vWplpWwoCS+6fmsOwM6hN77+w333m\n/gEkAZCQgFKprBUBsBQElgLANUeTJk3Qtm1bbRzApvdf2E8SAAmJ+4/g4GAE1cLiHZaCwJIFULP0\n7t0bhw4dAhFZ7wICJAGQkLifWbNmDb799tsav66lILAkADVLdHQ0MjIycPXqVeTk5Fj//rdpA7Ru\nzddGvs+QBEDigcff379WBltTLiAiklxAtUBvzQx+x44dUKlU1r//ixbxIrD7qABMQEoxkJCoJUy5\ngAoKClBRUSFZADVMp06d0KBBA2zR5PRbLQCenvdN+2dDJAtAQqKWMOUCkqqAaweZTIYePXogLi4O\nwIPx/ksCICFRS5hyAUlVwLVHdHS01ip7EN5/h1xAjLGPAYwEUA4gFcALRHRXZL9rAAoBqABUEtH9\nVS4nIVENKBQKVFRU6LUhBiQLoDbprZPJ8yC8/45aAHsAdCSizgAuAviHmX37E/1/e3cXY0ddh3H8\n+9Blh7JtuiJQXkqkFgLhwhbYVIjVSHlJbQigMQoxBiJJvYAEkiYE0sTopUbEJhJMRfSGABFFCCDQ\nIgnBRMoWChZKBbGGLvQ1u62RbKHrz4szp54cztltmWX+s2eeT3Ky88aZHzvbffb/m5kzscS//M0a\nuj0Y3iOAdJo3hIEDYEoR8UxEHMpn/wr05nMDzT4FWZYBHw8APwwmnfnz57Nw4ULmzJnDcccdl7qc\nT910ngP4HvCnLusCeEbSJkmrJnsTSaskDUsabv4lZNaLmgHQfh5g7969ZFnGnDlzUpRVe8uXL2fR\nokWpyyjFlOcAJG0ATumwak1EPJpvswY4BNzf5W2WRcSIpJOB9ZLejIjnO20YEeuAdQBDQ0NxBP8P\nZjNSswXUHgDNu4A1A68r7wVr165lfHw8dRmlmDIAIuKyydZLugG4Erg0Ijr+wo6IkfzrbkmPAEuB\njgFgVheTtYDq0H+uqoGBAQZm6HX9R6tQC0jSCuA24KqI+KDLNgOS5jangSuALUX2a9YLJmsB9eoz\nmK1aip4D+AUwl0ZbZ7OkXwJIOk3Sk/k284EXJL0KbASeiIinCu7XbMbr1gIaGxs7/JwCs09TofsA\nIuKsLsvfA1bm0+8Ai4vsx6wXdWsBjY6OMjg4mKIkqxnfCWyWSLcWkEcAVhYHgFkinVpA4+PjjI+P\nOwCsFA4As0Q6tYBGR0cB3AKyUjgAzBLpNAIYG2t8lJZHAFYGB4BZIh4BWGoOALNEOp0E9gjAyuQA\nMEukUwuoOQJwAFgZHABmibgFZKk5AMwSmawF5ACwMjgAzBLp1gI6/vjjD68z+zQ5AMwS6dQC8l3A\nViYHgFkixxxzDH19fR8bATgArCwOALOE+vv7PxYA7v9bWRwAZgllWeYWkCXjADBLqNMIwAFgZXEA\nmCXUaQTgFpCVpegjIX8oaSR/GthmSSu7bLdC0jZJb0u6vcg+zXpJlmWHRwATExPs37/fIwArTaEn\nguXuioifdlspaRZwN3A5sAN4SdJjEfHGNOzbbEZrbQHt378f8E1gVp4yWkBLgbcj4p2I+BB4ELi6\nhP2aVV5rC8gfBGdlm44AuFnSa5Luk9TpJ/d04N2W+R35MrPaa20B+YPgrGxTBoCkDZK2dHhdDdwD\nLAKWAO8DdxYtSNIqScOShvfs2VP07cwqrbUF5M8BsrJNeQ4gIi47kjeS9Cvg8Q6rRoAzWuYX5Mu6\n7W8dsA5gaGgojmTfZjNVlmUcOHAA8AjAylf0KqBTW2a/DmzpsNlLwNmSFkrqB64FHiuyX7Ne0ToC\n8EdBW9mKXgX0E0lLgAC2A98HkHQacG9ErIyIQ5JuBp4GZgH3RcTrBfdr1hNazwH4JLCVrVAARMR3\nuyx/D1jZMv8k8GSRfZn1otargEZHR+nr62NgYCBxVVYXvhPYLKH2FtDg4CCSEldldeEAMEuo/T4A\nt3+sTA4As4Ta7wPwCWArkwPALKH2+wA8ArAyOQDMEmo/CewAsDI5AMwSyrKMiYkJJiYm3AKy0jkA\nzBLq7+8H4ODBg24BWekcAGYJZVkGNNo/H330kQPASuUAMEuoOQLYtWsX4I+BsHI5AMwSao4AmgHg\nEYCVyQFgllAzAHbu3Al4BGDlcgCYJdTeAvIIwMrkADBLyC0gS8kBYJZQewC4BWRlcgCYJdTeApo3\nb17KcqxmHABmCbWeBJ47dy59fUWf0WR25BwAZgm1toDc/7eyFfpzQ9JDwDn57CAwFhFLOmy3Hfg3\nMAEcioihIvs16xXNFtC+fftYsGBB4mqsboo+EvLbzWlJdwL7J9n8kojYW2R/Zr2mOQIAnwC28k1L\nw1GNZ9h9C1g+He9nVhfNEQD4ElAr33SdA/gysCsi3uqyPoBnJG2StGqyN5K0StKwpOE9e/ZMU3lm\n1dQ6AnAAWNmmHAFI2gCc0mHVmoh4NJ++DnhgkrdZFhEjkk4G1kt6MyKe77RhRKwD1gEMDQ3FVPWZ\nzWRuAVlKUwZARFw22XpJfcA3gAsneY+R/OtuSY8AS4GOAWBWJ24BWUrT0QK6DHgzInZ0WilpQNLc\n5jRwBbBlGvZrNuN5BGApTUcAXEtb+0fSaZKezGfnAy9IehXYCDwREU9Nw37NZrxjjz328LRHAFa2\nwlcBRcQNHZa9B6zMp98BFhfdj1kvkkR/fz8ffvihA8BK5zuBzRJrtoHcArKyOQDMEmueCPYIwMrm\nADBLzCMAS8UBYJZYMwA8ArCyOQDMEuvv7yfLMmbPnp26FKsZB4BZYlmWuf1jSTgAzBLLssztH0vC\njx8ySyzLMmbNmpW6DKshB4BZYqtXr05dgtWUA8AssWuuuSZ1CVZTPgdgZlZTDgAzs5pyAJiZ1ZQD\nwMysphwAZmY15QAwM6spB4CZWU05AMzMakoRkbqGriTtAf71Cf/zE4G901jOdHN9xbi+YlxfMVWu\n73MRcdKRbFjpAChC0nBEDKWuoxvXV4zrK8b1FVP1+o6UW0BmZjXlADAzq6leDoB1qQuYgusrxvUV\n4/qKqXp9R6RnzwGYmdnkenkEYGZmk+i5AJC0QtI2SW9Luj11PQCS7pO0W9KWlmUnSFov6a38a5Jn\nAko6Q9Jzkt6Q9LqkWypW33GSNkp6Na/vR/nyhZJezI/zQ5L6U9TXUucsSa9Ieryi9W2X9DdJmyUN\n58sqcYzzWgYlPSzpTUlbJV1clfoknZN/35qvA5JurUp9RfRUAEiaBdwNfA04D7hO0nlpqwLgt8CK\ntmW3A89GxNnAs/l8CoeA1RFxHnARcFP+PatKfQeB5RGxGFgCrJB0EfBj4K6IOAsYBW5MVF/TLcDW\nlvmq1QdwSUQsabl8sSrHGGAt8FREnAsspvG9rER9EbEt/74tAS4EPgAeqUp9hUREz7yAi4GnW+bv\nAO5IXVdey5nAlpb5bcCp+fSpwLbUNea1PApcXsX6gOOBl4Ev0rgJp6/TcU9Q1wIavwCWA48DqlJ9\neQ3bgRPbllXiGAPzgH+Sn5OsWn1tNV0B/KWq9R3tq6dGAMDpwLst8zvyZVU0PyLez6d3AvNTFgMg\n6UzgfOBFKlRf3l7ZDOwG1gP/AMYi4lC+Serj/HPgNuC/+fxnqVZ9AAE8I2mTpFX5sqoc44XAHuA3\neRvtXkkDFaqv1bXAA/l0Fes7Kr0WADNSNP6ESHo5lqQ5wO+BWyPiQOu61PVFxEQ0ht8LgKXAualq\naSfpSmB3RGxKXcsUlkXEBTTaozdJ+krrysTHuA+4ALgnIs4H/kNbOyX1zyBAfh7nKuB37euqUN8n\n0WsBMAKc0TK/IF9WRbsknQqQf92dqhBJx9L45X9/RPyhavU1RcQY8ByNlsqgpL58Vcrj/CXgKknb\ngQdptIHWUp36AIiIkfzrbhr966VU5xjvAHZExIv5/MM0AqEq9TV9DXg5Inbl81Wr76j1WgC8BJyd\nX4HRT2O49ljimrp5DLg+n76eRu+9dJIE/BrYGhE/a1lVlfpOkjSYT8+mcX5iK40g+Gbq+iLijohY\nEBFn0vh5+3NEfKcq9QFIGpA0tzlNo4+9hYoc44jYCbwr6Zx80aXAG1SkvhbX8f/2D1SvvqOX+iTE\ndL+AlcDfafSJ16SuJ6/pAeB94CMaf+3cSKNP/CzwFrABOCFRbctoDF1fAzbnr5UVqu8LwCt5fVuA\nH+TLPw9sBN6mMSTPKnCcvwo8XrX68lpezV+vN/9dVOUY57UsAYbz4/xH4DMVq28A2AfMa1lWmfo+\n6ct3ApuZ1VSvtYDMzOwIOQDMzGrKAWBmVlMOADOzmnIAmJnVlAPAzKymHABmZjXlADAzq6n/AUIl\nd51zzK0bAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc8c0ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: fixed scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_test_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed scheme RMSE: 3.70191620377 \n",
      "Fixed scheme MAE:  2.59936396798\n"
     ]
    }
   ],
   "source": [
    "rmse_fixed = np.sqrt(np.mean((yhat_test_fixed[:,0]-test_target)**2))\n",
    "mae_fixed = np.mean(np.abs((yhat_test_fixed[:,0]-test_target)))\n",
    "print(\"Fixed scheme RMSE:\", rmse_fixed,\n",
    "     \"\\nFixed scheme MAE: \", mae_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Stack training and test set, this makes updating scheme easier to train\n",
    "all_features = np.concatenate((train_features[-window_length:], test_features), axis=0)\n",
    "all_target = np.concatenate((train_target[-window_length:], test_target), axis=0)\n",
    "\n",
    "# Vectors to store loss and forecasts\n",
    "test_loss = np.zeros(len(test_target))\n",
    "yhat_update = np.zeros(len(test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test period = 1  Training loss = 1.1446  Test loss = 3.7928  Model updated 0 times  \n",
      "\n",
      "Test period = 2  Training loss = 1.2278  Test loss = 0.8052  Model updated 0 times  \n",
      "\n",
      "Test period = 3  Training loss = 1.2299  Test loss = 1.3464  Model updated 0 times  \n",
      "\n",
      "Test period = 4  Training loss = 1.2412  Test loss = 1.9615  Model updated 0 times  \n",
      "\n",
      "Test period = 5  Training loss = 0.7720  Test loss = 2.3226  Model updated 1 times  \n",
      "\n",
      "Test period = 6  Training loss = 0.8240  Test loss = 0.8585  Model updated 1 times  \n",
      "\n",
      "Test period = 7  Training loss = 0.8302  Test loss = 2.0073  Model updated 1 times  \n",
      "\n",
      "Test period = 8  Training loss = 0.8667  Test loss = 0.0901  Model updated 1 times  \n",
      "\n",
      "Test period = 9  Training loss = 0.7761  Test loss = 1.1259  Model updated 2 times  \n",
      "\n",
      "Test period = 10  Training loss = 0.7862  Test loss = 1.7115  Model updated 2 times  \n",
      "\n",
      "Test period = 11  Training loss = 0.8125  Test loss = 1.4187  Model updated 2 times  \n",
      "\n",
      "Test period = 12  Training loss = 0.8309  Test loss = 0.7710  Model updated 2 times  \n",
      "\n",
      "Test period = 13  Training loss = 0.7360  Test loss = 1.4124  Model updated 3 times  \n",
      "\n",
      "Test period = 14  Training loss = 0.7563  Test loss = 4.5534  Model updated 3 times  \n",
      "\n",
      "Test period = 15  Training loss = 0.9434  Test loss = 5.9202  Model updated 3 times  \n",
      "\n",
      "Test period = 16  Training loss = 1.1955  Test loss = 6.4646  Model updated 3 times  \n",
      "\n",
      "Test period = 17  Training loss = 0.8041  Test loss = 1.7731  Model updated 4 times  \n",
      "\n",
      "Test period = 18  Training loss = 0.8335  Test loss = 0.9400  Model updated 4 times  \n",
      "\n",
      "Test period = 19  Training loss = 0.8409  Test loss = 2.2189  Model updated 4 times  \n",
      "\n",
      "Test period = 20  Training loss = 0.8797  Test loss = 0.7053  Model updated 4 times  \n",
      "\n",
      "Test period = 21  Training loss = 0.6760  Test loss = 0.8525  Model updated 5 times  \n",
      "\n",
      "Test period = 22  Training loss = 0.6842  Test loss = 3.6474  Model updated 5 times  \n",
      "\n",
      "Test period = 23  Training loss = 0.8188  Test loss = 0.3053  Model updated 5 times  \n",
      "\n",
      "Test period = 24  Training loss = 0.8183  Test loss = 1.6537  Model updated 5 times  \n",
      "\n",
      "Test period = 25  Training loss = 0.7188  Test loss = 0.6415  Model updated 6 times  \n",
      "\n",
      "Test period = 26  Training loss = 0.7149  Test loss = 1.2984  Model updated 6 times  \n",
      "\n",
      "Test period = 27  Training loss = 0.7326  Test loss = 1.7681  Model updated 6 times  \n",
      "\n",
      "Test period = 28  Training loss = 0.7647  Test loss = 1.8139  Model updated 6 times  \n",
      "\n",
      "Test period = 29  Training loss = 0.6398  Test loss = 0.8552  Model updated 7 times  \n",
      "\n",
      "Test period = 30  Training loss = 0.6484  Test loss = 0.1512  Model updated 7 times  \n",
      "\n",
      "Test period = 31  Training loss = 0.6439  Test loss = 3.4470  Model updated 7 times  \n",
      "\n",
      "Test period = 32  Training loss = 0.7715  Test loss = 0.4949  Model updated 7 times  \n",
      "\n",
      "Test period = 33  Training loss = 0.6137  Test loss = 0.6069  Model updated 8 times  \n",
      "\n",
      "Test period = 34  Training loss = 0.6157  Test loss = 0.7994  Model updated 8 times  \n",
      "\n",
      "Test period = 35  Training loss = 0.6195  Test loss = 1.3568  Model updated 8 times  \n",
      "\n",
      "Test period = 36  Training loss = 0.6420  Test loss = 5.3865  Model updated 8 times  \n",
      "\n",
      "Test period = 37  Training loss = 0.8639  Test loss = 1.3004  Model updated 9 times  \n",
      "\n",
      "Test period = 38  Training loss = 0.8258  Test loss = 1.8926  Model updated 9 times  \n",
      "\n",
      "Test period = 39  Training loss = 0.8585  Test loss = 3.0457  Model updated 9 times  \n",
      "\n",
      "Test period = 40  Training loss = 0.9379  Test loss = 2.2493  Model updated 9 times  \n",
      "\n",
      "Test period = 41  Training loss = 0.7150  Test loss = 1.4027  Model updated 10 times  \n",
      "\n",
      "Test period = 42  Training loss = 0.7359  Test loss = 3.1513  Model updated 10 times  \n",
      "\n",
      "Test period = 43  Training loss = 0.8327  Test loss = 3.5862  Model updated 10 times  \n",
      "\n",
      "Test period = 44  Training loss = 0.9393  Test loss = 13.9549  Model updated 10 times  \n",
      "\n",
      "Test period = 45  Training loss = 1.8087  Test loss = 7.2183  Model updated 11 times  \n",
      "\n",
      "Test period = 46  Training loss = 2.0175  Test loss = 2.3320  Model updated 11 times  \n",
      "\n",
      "Test period = 47  Training loss = 2.0381  Test loss = 0.9918  Model updated 11 times  \n",
      "\n",
      "Test period = 48  Training loss = 2.0418  Test loss = 2.0803  Model updated 11 times  \n",
      "\n",
      "Test period = 49  Training loss = 1.2231  Test loss = 2.1587  Model updated 12 times  \n",
      "\n",
      "Test period = 50  Training loss = 1.2518  Test loss = 3.4209  Model updated 12 times  \n",
      "\n",
      "Test period = 51  Training loss = 1.3217  Test loss = 3.1874  Model updated 12 times  \n",
      "\n",
      "Test period = 52  Training loss = 1.3795  Test loss = 0.7700  Model updated 12 times  \n",
      "\n",
      "Test period = 53  Training loss = 1.1754  Test loss = 1.1409  Model updated 13 times  \n",
      "\n",
      "Test period = 54  Training loss = 1.1836  Test loss = 0.0024  Model updated 13 times  \n",
      "\n",
      "Test period = 55  Training loss = 1.1836  Test loss = 3.5136  Model updated 13 times  \n",
      "\n",
      "Test period = 56  Training loss = 1.2603  Test loss = 1.9639  Model updated 13 times  \n",
      "\n",
      "Test period = 57  Training loss = 1.0968  Test loss = 3.2582  Model updated 14 times  \n",
      "\n",
      "Test period = 58  Training loss = 1.1677  Test loss = 4.2512  Model updated 14 times  \n",
      "\n",
      "Test period = 59  Training loss = 1.2798  Test loss = 0.6397  Model updated 14 times  \n",
      "\n",
      "Test period = 60  Training loss = 1.2798  Test loss = 1.1833  Model updated 14 times  \n",
      "\n",
      "Test period = 61  Training loss = 1.0734  Test loss = 0.9976  Model updated 15 times  \n",
      "\n",
      "Test period = 62  Training loss = 1.0791  Test loss = 2.7442  Model updated 15 times  \n",
      "\n",
      "Test period = 63  Training loss = 1.1304  Test loss = 0.5412  Model updated 15 times  \n",
      "\n",
      "Test period = 64  Training loss = 1.1323  Test loss = 0.7036  Model updated 15 times  \n",
      "\n",
      "Test period = 65  Training loss = 1.0029  Test loss = 1.3107  Model updated 16 times  \n",
      "\n",
      "Test period = 66  Training loss = 1.0130  Test loss = 1.2763  Model updated 16 times  \n",
      "\n",
      "Test period = 67  Training loss = 1.0242  Test loss = 1.1607  Model updated 16 times  \n",
      "\n",
      "Test period = 68  Training loss = 1.0312  Test loss = 6.5729  Model updated 16 times  \n",
      "\n",
      "Test period = 69  Training loss = 1.3990  Test loss = 6.9947  Model updated 17 times  \n",
      "\n",
      "Test period = 70  Training loss = 1.6437  Test loss = 0.6785  Model updated 17 times  \n",
      "\n",
      "Test period = 71  Training loss = 1.6419  Test loss = 2.4001  Model updated 17 times  \n",
      "\n",
      "Test period = 72  Training loss = 1.6687  Test loss = 3.5495  Model updated 17 times  \n",
      "\n",
      "Test period = 73  Training loss = 0.9421  Test loss = 2.5759  Model updated 18 times  \n",
      "\n",
      "Test period = 74  Training loss = 0.9946  Test loss = 1.2122  Model updated 18 times  \n",
      "\n",
      "Test period = 75  Training loss = 1.0043  Test loss = 3.7880  Model updated 18 times  \n",
      "\n",
      "Test period = 76  Training loss = 1.1080  Test loss = 2.3404  Model updated 18 times  \n",
      "\n",
      "Test period = 77  Training loss = 0.9712  Test loss = 0.0538  Model updated 19 times  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "retrain_count = 0\n",
    "for t in range(len(test_target)):\n",
    "    x_test = np.reshape(test_features[t], newshape=(1,4,3))\n",
    "    y_test = test_target[t]\n",
    "    test_loss[t] = np.sqrt(sess.run(loss, feed_dict={x:x_test, y:y_test}))\n",
    "    yhat_update[t] = pred.eval(feed_dict={x:x_test})\n",
    "\n",
    "    x_train = all_features[t:(window_length+t)]\n",
    "    y_train = all_target[t:(window_length+t)]\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:x_test, y:y_test})\n",
    "    \n",
    "    print(\"Test period = {0:d}\".format(t+1),\n",
    "      \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "      \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "      \" Model updated {0:d} times\".format(retrain_count),\n",
    "      \" \\n\")\n",
    "\n",
    "    if (t+1)%4==0:\n",
    "        retrain_count += 1\n",
    "        for epoch in range(epoch_hat):\n",
    "            for i in range(total_batch):\n",
    "                optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\neA+85gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd055400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: updating scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_update, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating scheme RMSE: 3.11420891814 \n",
      "Updating scheme MAE:  2.27109803991\n"
     ]
    }
   ],
   "source": [
    "rmse_update = np.sqrt(np.mean((yhat_update-test_target)**2))\n",
    "mae_update = np.mean(np.abs((yhat_update-test_target)))\n",
    "print(\"Updating scheme RMSE:\", rmse_update,\n",
    "     \"\\nUpdating scheme MAE: \", mae_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + \"yhat_test_fixed.csv\", yhat_test_fixed)\n",
    "np.savetxt(MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + \"yhat_update.csv\", yhat_update)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
