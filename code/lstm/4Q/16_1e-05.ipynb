{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Directories\n",
    "MODEL_FOLDER = \"../../../models/lstm/\"\n",
    "MODEL_FILENAME = MODEL_FOLDER + \"4Q/16_units/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: model saver\n",
    "def saveModel(sess, MODEL_FILENAME):\n",
    "    if not os.path.exists(MODEL_FOLDER):\n",
    "        print('Creating path where to save model: ' + MODEL_FOLDER)\n",
    "        os.mkdir(MODEL_FOLDER)\n",
    "\n",
    "    #print('Saving model at: ' + MODEL_FILENAME)\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, MODEL_FILENAME)\n",
    "    #print('Model successfully saved.\\n')\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: model loader\n",
    "def loadModel(sess, MODEL_FILENAME):\n",
    "    if os.path.exists(MODEL_FILENAME + \".index\"):\n",
    "        print('Loading save model from: ' + MODEL_FILENAME)\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, MODEL_FILENAME)\n",
    "        print('Model successfully loaded.\\n')\n",
    "        return True\n",
    "    else:\n",
    "        print('Model file <<' + MODEL_FILENAME + '>> does not exists!')\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Hyperparameters\n",
    "epochs = 500\n",
    "learning_rate = 1e-5\n",
    "batch_size = 5\n",
    "early_stop_iters = 10\n",
    "folds = 32\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 3  # data input\n",
    "n_steps = 4  # timesteps\n",
    "n_hidden = 16 # dimension of recurrent unit\n",
    "\n",
    "# (REPRODUCIBILITY) set random seeds\n",
    "tf.set_random_seed(123)\n",
    "\n",
    "# Define weights and biases\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.truncated_normal([n_hidden, 1], stddev = 1.0 / tf.sqrt(float(n_hidden))),\n",
    "        name='out_weight')\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.zeros([1]),\n",
    "        name='out_bias')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: Build model\n",
    "def RNN(X, weights, biases, n_hidden):\n",
    "\n",
    "    # Define a LSTM cell with tensorflow\n",
    "    lstm_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden, state_is_tuple=True)\n",
    "    outputs, _ = tf.nn.dynamic_rnn(lstm_cell, X, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    out_layer = tf.matmul(outputs[:,-1,:], weights['out']) + biases['out']\n",
    "\n",
    "    return out_layer\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: select batch\n",
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the data...\n",
      "Finished: data loaded. Stats below: \n",
      "Nr of training samples: 193\n",
      "Nr of testing  samples: 77\n",
      "Number of variables: 3\n",
      "Number of lags: 4\n",
      "Window length: 65\n",
      "Number of validation folds: 32\n"
     ]
    }
   ],
   "source": [
    "# =================================\n",
    "# 0. Load dataset\n",
    "# =================================\n",
    "print(\"Loading the data...\")\n",
    "# Training set pre-processing\n",
    "train = pd.read_csv('../../../Data/train.csv')\n",
    "train_4lag_inflation = np.array(train[['inflation.lag4',\n",
    "                                       'inflation.lag5',\n",
    "                                       'inflation.lag6',\n",
    "                                       'inflation.lag7']])\n",
    "train_4lag_unemp = np.array(train[['unemp.lag4',\n",
    "                                   'unemp.lag5',\n",
    "                                   'unemp.lag6',\n",
    "                                   'unemp.lag7']])\n",
    "train_4lag_oil = np.array(train[['oil.lag4',\n",
    "                                 'oil.lag5',\n",
    "                                 'oil.lag6',\n",
    "                                 'oil.lag7']])\n",
    "train_features = np.concatenate((train_4lag_inflation[:,:,np.newaxis], \n",
    "\t                             train_4lag_unemp[:,:,np.newaxis],\n",
    "\t                             train_4lag_oil[:,:,np.newaxis]),\n",
    "\t                             axis=2)\n",
    "train_target = np.array(train['inflation.target'])\n",
    "\n",
    "# Test set pre-processing\n",
    "test = pd.read_csv('../../../Data/test.csv')\n",
    "test_4lag_inflation = np.array(test[['inflation.lag4',\n",
    "                                     'inflation.lag5',\n",
    "                                     'inflation.lag6',\n",
    "                                     'inflation.lag7']])\n",
    "test_4lag_unemp = np.array(test[['unemp.lag4',\n",
    "                                 'unemp.lag5',\n",
    "                                 'unemp.lag6',\n",
    "                                 'unemp.lag7']])\n",
    "test_4lag_oil = np.array(test[['oil.lag4',\n",
    "                               'oil.lag5',\n",
    "                               'oil.lag6',\n",
    "                               'oil.lag7']])\n",
    "test_features = np.concatenate((test_4lag_inflation[:,:,np.newaxis], \n",
    "\t                            test_4lag_unemp[:,:,np.newaxis],\n",
    "\t                            test_4lag_oil[:,:,np.newaxis]),\n",
    "\t                            axis=2)\n",
    "test_target = np.array(test['inflation.target'])\n",
    "\n",
    "(nrTrainSamples, timesteps, variables) = train_features.shape\n",
    "(nrTestSamples, _, _) = test_features.shape\n",
    "\n",
    "# Window length and validation fold index\n",
    "window_length = 65\n",
    "valIndex = np.linspace(start=window_length, stop=nrTrainSamples, \n",
    "                       endpoint=True, num=folds+1, dtype=np.int)\n",
    "\n",
    "print(\"Finished: data loaded. Stats below: \")\n",
    "print(\"Nr of training samples: %d\" % nrTrainSamples)\n",
    "print(\"Nr of testing  samples: %d\" % nrTestSamples)\n",
    "print(\"Number of variables: %d\" % variables)\n",
    "print(\"Number of lags: %d\" % timesteps)\n",
    "print(\"Window length: %d\" % window_length)\n",
    "print(\"Number of validation folds: %d\" % folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 1. Build model\n",
    "# ==================================\n",
    "# tf graph input\n",
    "x = tf.placeholder(\"float\", [None, n_steps, n_input], name='Batch')\n",
    "y = tf.placeholder(\"float\", name='True_labels_of_batch')\n",
    "lr = tf.placeholder(\"float\", name='Learning_rate')\n",
    "\n",
    "# Make predictions with the model\n",
    "pred = RNN(x, weights, biases, n_hidden)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss = tf.reduce_mean(tf.diag_part(tf.square(tf.subtract(x=pred, y=y))))\n",
    "optimizer = tf.train.GradientDescentOptimizer(lr).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training \n",
      "Hyperparameters: \n",
      "Dimension of recurrent unit = 16 \n",
      "Learning rate = 1e-05 \n",
      "Epochs = 500 \n",
      "Batch size = 5 \n",
      "Early stopping epochs = 10 \n",
      "Learning rate = 1e-05\n",
      "Fold: 1  Epoch: 1  Training loss = 3.2094  Validation loss = 3.4296  \n",
      "\n",
      "Fold: 1  Epoch: 2  Training loss = 3.2079  Validation loss = 3.4268  \n",
      "\n",
      "Fold: 1  Epoch: 3  Training loss = 3.2067  Validation loss = 3.4246  \n",
      "\n",
      "Fold: 1  Epoch: 4  Training loss = 3.2052  Validation loss = 3.4220  \n",
      "\n",
      "Fold: 1  Epoch: 5  Training loss = 3.2040  Validation loss = 3.4198  \n",
      "\n",
      "Fold: 1  Epoch: 6  Training loss = 3.2030  Validation loss = 3.4179  \n",
      "\n",
      "Fold: 1  Epoch: 7  Training loss = 3.2016  Validation loss = 3.4154  \n",
      "\n",
      "Fold: 1  Epoch: 8  Training loss = 3.2006  Validation loss = 3.4134  \n",
      "\n",
      "Fold: 1  Epoch: 9  Training loss = 3.1995  Validation loss = 3.4114  \n",
      "\n",
      "Fold: 1  Epoch: 10  Training loss = 3.1977  Validation loss = 3.4082  \n",
      "\n",
      "Fold: 1  Epoch: 11  Training loss = 3.1964  Validation loss = 3.4057  \n",
      "\n",
      "Fold: 1  Epoch: 12  Training loss = 3.1950  Validation loss = 3.4032  \n",
      "\n",
      "Fold: 1  Epoch: 13  Training loss = 3.1934  Validation loss = 3.4002  \n",
      "\n",
      "Fold: 1  Epoch: 14  Training loss = 3.1920  Validation loss = 3.3976  \n",
      "\n",
      "Fold: 1  Epoch: 15  Training loss = 3.1908  Validation loss = 3.3954  \n",
      "\n",
      "Fold: 1  Epoch: 16  Training loss = 3.1893  Validation loss = 3.3927  \n",
      "\n",
      "Fold: 1  Epoch: 17  Training loss = 3.1880  Validation loss = 3.3903  \n",
      "\n",
      "Fold: 1  Epoch: 18  Training loss = 3.1864  Validation loss = 3.3874  \n",
      "\n",
      "Fold: 1  Epoch: 19  Training loss = 3.1852  Validation loss = 3.3850  \n",
      "\n",
      "Fold: 1  Epoch: 20  Training loss = 3.1838  Validation loss = 3.3825  \n",
      "\n",
      "Fold: 1  Epoch: 21  Training loss = 3.1824  Validation loss = 3.3801  \n",
      "\n",
      "Fold: 1  Epoch: 22  Training loss = 3.1809  Validation loss = 3.3773  \n",
      "\n",
      "Fold: 1  Epoch: 23  Training loss = 3.1800  Validation loss = 3.3757  \n",
      "\n",
      "Fold: 1  Epoch: 24  Training loss = 3.1786  Validation loss = 3.3731  \n",
      "\n",
      "Fold: 1  Epoch: 25  Training loss = 3.1774  Validation loss = 3.3709  \n",
      "\n",
      "Fold: 1  Epoch: 26  Training loss = 3.1762  Validation loss = 3.3688  \n",
      "\n",
      "Fold: 1  Epoch: 27  Training loss = 3.1750  Validation loss = 3.3665  \n",
      "\n",
      "Fold: 1  Epoch: 28  Training loss = 3.1730  Validation loss = 3.3629  \n",
      "\n",
      "Fold: 1  Epoch: 29  Training loss = 3.1720  Validation loss = 3.3610  \n",
      "\n",
      "Fold: 1  Epoch: 30  Training loss = 3.1708  Validation loss = 3.3586  \n",
      "\n",
      "Fold: 1  Epoch: 31  Training loss = 3.1698  Validation loss = 3.3567  \n",
      "\n",
      "Fold: 1  Epoch: 32  Training loss = 3.1689  Validation loss = 3.3549  \n",
      "\n",
      "Fold: 1  Epoch: 33  Training loss = 3.1674  Validation loss = 3.3521  \n",
      "\n",
      "Fold: 1  Epoch: 34  Training loss = 3.1664  Validation loss = 3.3503  \n",
      "\n",
      "Fold: 1  Epoch: 35  Training loss = 3.1651  Validation loss = 3.3480  \n",
      "\n",
      "Fold: 1  Epoch: 36  Training loss = 3.1640  Validation loss = 3.3460  \n",
      "\n",
      "Fold: 1  Epoch: 37  Training loss = 3.1626  Validation loss = 3.3433  \n",
      "\n",
      "Fold: 1  Epoch: 38  Training loss = 3.1611  Validation loss = 3.3404  \n",
      "\n",
      "Fold: 1  Epoch: 39  Training loss = 3.1595  Validation loss = 3.3376  \n",
      "\n",
      "Fold: 1  Epoch: 40  Training loss = 3.1582  Validation loss = 3.3350  \n",
      "\n",
      "Fold: 1  Epoch: 41  Training loss = 3.1568  Validation loss = 3.3325  \n",
      "\n",
      "Fold: 1  Epoch: 42  Training loss = 3.1554  Validation loss = 3.3298  \n",
      "\n",
      "Fold: 1  Epoch: 43  Training loss = 3.1541  Validation loss = 3.3274  \n",
      "\n",
      "Fold: 1  Epoch: 44  Training loss = 3.1527  Validation loss = 3.3247  \n",
      "\n",
      "Fold: 1  Epoch: 45  Training loss = 3.1517  Validation loss = 3.3228  \n",
      "\n",
      "Fold: 1  Epoch: 46  Training loss = 3.1504  Validation loss = 3.3204  \n",
      "\n",
      "Fold: 1  Epoch: 47  Training loss = 3.1493  Validation loss = 3.3183  \n",
      "\n",
      "Fold: 1  Epoch: 48  Training loss = 3.1485  Validation loss = 3.3167  \n",
      "\n",
      "Fold: 1  Epoch: 49  Training loss = 3.1475  Validation loss = 3.3147  \n",
      "\n",
      "Fold: 1  Epoch: 50  Training loss = 3.1461  Validation loss = 3.3121  \n",
      "\n",
      "Fold: 1  Epoch: 51  Training loss = 3.1451  Validation loss = 3.3102  \n",
      "\n",
      "Fold: 1  Epoch: 52  Training loss = 3.1441  Validation loss = 3.3083  \n",
      "\n",
      "Fold: 1  Epoch: 53  Training loss = 3.1432  Validation loss = 3.3065  \n",
      "\n",
      "Fold: 1  Epoch: 54  Training loss = 3.1419  Validation loss = 3.3039  \n",
      "\n",
      "Fold: 1  Epoch: 55  Training loss = 3.1410  Validation loss = 3.3023  \n",
      "\n",
      "Fold: 1  Epoch: 56  Training loss = 3.1402  Validation loss = 3.3007  \n",
      "\n",
      "Fold: 1  Epoch: 57  Training loss = 3.1393  Validation loss = 3.2989  \n",
      "\n",
      "Fold: 1  Epoch: 58  Training loss = 3.1380  Validation loss = 3.2966  \n",
      "\n",
      "Fold: 1  Epoch: 59  Training loss = 3.1368  Validation loss = 3.2942  \n",
      "\n",
      "Fold: 1  Epoch: 60  Training loss = 3.1355  Validation loss = 3.2919  \n",
      "\n",
      "Fold: 1  Epoch: 61  Training loss = 3.1343  Validation loss = 3.2896  \n",
      "\n",
      "Fold: 1  Epoch: 62  Training loss = 3.1333  Validation loss = 3.2877  \n",
      "\n",
      "Fold: 1  Epoch: 63  Training loss = 3.1321  Validation loss = 3.2856  \n",
      "\n",
      "Fold: 1  Epoch: 64  Training loss = 3.1312  Validation loss = 3.2839  \n",
      "\n",
      "Fold: 1  Epoch: 65  Training loss = 3.1302  Validation loss = 3.2819  \n",
      "\n",
      "Fold: 1  Epoch: 66  Training loss = 3.1286  Validation loss = 3.2790  \n",
      "\n",
      "Fold: 1  Epoch: 67  Training loss = 3.1275  Validation loss = 3.2768  \n",
      "\n",
      "Fold: 1  Epoch: 68  Training loss = 3.1265  Validation loss = 3.2749  \n",
      "\n",
      "Fold: 1  Epoch: 69  Training loss = 3.1252  Validation loss = 3.2726  \n",
      "\n",
      "Fold: 1  Epoch: 70  Training loss = 3.1244  Validation loss = 3.2710  \n",
      "\n",
      "Fold: 1  Epoch: 71  Training loss = 3.1234  Validation loss = 3.2691  \n",
      "\n",
      "Fold: 1  Epoch: 72  Training loss = 3.1224  Validation loss = 3.2671  \n",
      "\n",
      "Fold: 1  Epoch: 73  Training loss = 3.1211  Validation loss = 3.2647  \n",
      "\n",
      "Fold: 1  Epoch: 74  Training loss = 3.1201  Validation loss = 3.2629  \n",
      "\n",
      "Fold: 1  Epoch: 75  Training loss = 3.1193  Validation loss = 3.2613  \n",
      "\n",
      "Fold: 1  Epoch: 76  Training loss = 3.1182  Validation loss = 3.2591  \n",
      "\n",
      "Fold: 1  Epoch: 77  Training loss = 3.1172  Validation loss = 3.2574  \n",
      "\n",
      "Fold: 1  Epoch: 78  Training loss = 3.1165  Validation loss = 3.2558  \n",
      "\n",
      "Fold: 1  Epoch: 79  Training loss = 3.1155  Validation loss = 3.2539  \n",
      "\n",
      "Fold: 1  Epoch: 80  Training loss = 3.1140  Validation loss = 3.2513  \n",
      "\n",
      "Fold: 1  Epoch: 81  Training loss = 3.1130  Validation loss = 3.2493  \n",
      "\n",
      "Fold: 1  Epoch: 82  Training loss = 3.1122  Validation loss = 3.2476  \n",
      "\n",
      "Fold: 1  Epoch: 83  Training loss = 3.1110  Validation loss = 3.2454  \n",
      "\n",
      "Fold: 1  Epoch: 84  Training loss = 3.1099  Validation loss = 3.2431  \n",
      "\n",
      "Fold: 1  Epoch: 85  Training loss = 3.1092  Validation loss = 3.2419  \n",
      "\n",
      "Fold: 1  Epoch: 86  Training loss = 3.1082  Validation loss = 3.2399  \n",
      "\n",
      "Fold: 1  Epoch: 87  Training loss = 3.1071  Validation loss = 3.2377  \n",
      "\n",
      "Fold: 1  Epoch: 88  Training loss = 3.1062  Validation loss = 3.2360  \n",
      "\n",
      "Fold: 1  Epoch: 89  Training loss = 3.1052  Validation loss = 3.2342  \n",
      "\n",
      "Fold: 1  Epoch: 90  Training loss = 3.1042  Validation loss = 3.2322  \n",
      "\n",
      "Fold: 1  Epoch: 91  Training loss = 3.1030  Validation loss = 3.2298  \n",
      "\n",
      "Fold: 1  Epoch: 92  Training loss = 3.1019  Validation loss = 3.2277  \n",
      "\n",
      "Fold: 1  Epoch: 93  Training loss = 3.1006  Validation loss = 3.2253  \n",
      "\n",
      "Fold: 1  Epoch: 94  Training loss = 3.0996  Validation loss = 3.2234  \n",
      "\n",
      "Fold: 1  Epoch: 95  Training loss = 3.0985  Validation loss = 3.2213  \n",
      "\n",
      "Fold: 1  Epoch: 96  Training loss = 3.0972  Validation loss = 3.2189  \n",
      "\n",
      "Fold: 1  Epoch: 97  Training loss = 3.0962  Validation loss = 3.2170  \n",
      "\n",
      "Fold: 1  Epoch: 98  Training loss = 3.0954  Validation loss = 3.2154  \n",
      "\n",
      "Fold: 1  Epoch: 99  Training loss = 3.0943  Validation loss = 3.2133  \n",
      "\n",
      "Fold: 1  Epoch: 100  Training loss = 3.0930  Validation loss = 3.2109  \n",
      "\n",
      "Fold: 1  Epoch: 101  Training loss = 3.0924  Validation loss = 3.2097  \n",
      "\n",
      "Fold: 1  Epoch: 102  Training loss = 3.0915  Validation loss = 3.2079  \n",
      "\n",
      "Fold: 1  Epoch: 103  Training loss = 3.0906  Validation loss = 3.2061  \n",
      "\n",
      "Fold: 1  Epoch: 104  Training loss = 3.0892  Validation loss = 3.2035  \n",
      "\n",
      "Fold: 1  Epoch: 105  Training loss = 3.0879  Validation loss = 3.2011  \n",
      "\n",
      "Fold: 1  Epoch: 106  Training loss = 3.0870  Validation loss = 3.1991  \n",
      "\n",
      "Fold: 1  Epoch: 107  Training loss = 3.0863  Validation loss = 3.1978  \n",
      "\n",
      "Fold: 1  Epoch: 108  Training loss = 3.0853  Validation loss = 3.1959  \n",
      "\n",
      "Fold: 1  Epoch: 109  Training loss = 3.0844  Validation loss = 3.1941  \n",
      "\n",
      "Fold: 1  Epoch: 110  Training loss = 3.0838  Validation loss = 3.1928  \n",
      "\n",
      "Fold: 1  Epoch: 111  Training loss = 3.0826  Validation loss = 3.1906  \n",
      "\n",
      "Fold: 1  Epoch: 112  Training loss = 3.0818  Validation loss = 3.1890  \n",
      "\n",
      "Fold: 1  Epoch: 113  Training loss = 3.0811  Validation loss = 3.1875  \n",
      "\n",
      "Fold: 1  Epoch: 114  Training loss = 3.0801  Validation loss = 3.1856  \n",
      "\n",
      "Fold: 1  Epoch: 115  Training loss = 3.0788  Validation loss = 3.1831  \n",
      "\n",
      "Fold: 1  Epoch: 116  Training loss = 3.0781  Validation loss = 3.1817  \n",
      "\n",
      "Fold: 1  Epoch: 117  Training loss = 3.0772  Validation loss = 3.1799  \n",
      "\n",
      "Fold: 1  Epoch: 118  Training loss = 3.0760  Validation loss = 3.1776  \n",
      "\n",
      "Fold: 1  Epoch: 119  Training loss = 3.0752  Validation loss = 3.1760  \n",
      "\n",
      "Fold: 1  Epoch: 120  Training loss = 3.0741  Validation loss = 3.1740  \n",
      "\n",
      "Fold: 1  Epoch: 121  Training loss = 3.0729  Validation loss = 3.1716  \n",
      "\n",
      "Fold: 1  Epoch: 122  Training loss = 3.0718  Validation loss = 3.1695  \n",
      "\n",
      "Fold: 1  Epoch: 123  Training loss = 3.0707  Validation loss = 3.1675  \n",
      "\n",
      "Fold: 1  Epoch: 124  Training loss = 3.0698  Validation loss = 3.1657  \n",
      "\n",
      "Fold: 1  Epoch: 125  Training loss = 3.0690  Validation loss = 3.1641  \n",
      "\n",
      "Fold: 1  Epoch: 126  Training loss = 3.0680  Validation loss = 3.1623  \n",
      "\n",
      "Fold: 1  Epoch: 127  Training loss = 3.0668  Validation loss = 3.1599  \n",
      "\n",
      "Fold: 1  Epoch: 128  Training loss = 3.0657  Validation loss = 3.1579  \n",
      "\n",
      "Fold: 1  Epoch: 129  Training loss = 3.0644  Validation loss = 3.1555  \n",
      "\n",
      "Fold: 1  Epoch: 130  Training loss = 3.0636  Validation loss = 3.1539  \n",
      "\n",
      "Fold: 1  Epoch: 131  Training loss = 3.0629  Validation loss = 3.1525  \n",
      "\n",
      "Fold: 1  Epoch: 132  Training loss = 3.0617  Validation loss = 3.1503  \n",
      "\n",
      "Fold: 1  Epoch: 133  Training loss = 3.0611  Validation loss = 3.1489  \n",
      "\n",
      "Fold: 1  Epoch: 134  Training loss = 3.0601  Validation loss = 3.1468  \n",
      "\n",
      "Fold: 1  Epoch: 135  Training loss = 3.0594  Validation loss = 3.1455  \n",
      "\n",
      "Fold: 1  Epoch: 136  Training loss = 3.0586  Validation loss = 3.1440  \n",
      "\n",
      "Fold: 1  Epoch: 137  Training loss = 3.0578  Validation loss = 3.1423  \n",
      "\n",
      "Fold: 1  Epoch: 138  Training loss = 3.0571  Validation loss = 3.1410  \n",
      "\n",
      "Fold: 1  Epoch: 139  Training loss = 3.0563  Validation loss = 3.1393  \n",
      "\n",
      "Fold: 1  Epoch: 140  Training loss = 3.0556  Validation loss = 3.1379  \n",
      "\n",
      "Fold: 1  Epoch: 141  Training loss = 3.0548  Validation loss = 3.1363  \n",
      "\n",
      "Fold: 1  Epoch: 142  Training loss = 3.0540  Validation loss = 3.1349  \n",
      "\n",
      "Fold: 1  Epoch: 143  Training loss = 3.0533  Validation loss = 3.1334  \n",
      "\n",
      "Fold: 1  Epoch: 144  Training loss = 3.0526  Validation loss = 3.1319  \n",
      "\n",
      "Fold: 1  Epoch: 145  Training loss = 3.0516  Validation loss = 3.1299  \n",
      "\n",
      "Fold: 1  Epoch: 146  Training loss = 3.0507  Validation loss = 3.1282  \n",
      "\n",
      "Fold: 1  Epoch: 147  Training loss = 3.0501  Validation loss = 3.1270  \n",
      "\n",
      "Fold: 1  Epoch: 148  Training loss = 3.0490  Validation loss = 3.1248  \n",
      "\n",
      "Fold: 1  Epoch: 149  Training loss = 3.0482  Validation loss = 3.1233  \n",
      "\n",
      "Fold: 1  Epoch: 150  Training loss = 3.0473  Validation loss = 3.1214  \n",
      "\n",
      "Fold: 1  Epoch: 151  Training loss = 3.0466  Validation loss = 3.1200  \n",
      "\n",
      "Fold: 1  Epoch: 152  Training loss = 3.0461  Validation loss = 3.1188  \n",
      "\n",
      "Fold: 1  Epoch: 153  Training loss = 3.0453  Validation loss = 3.1172  \n",
      "\n",
      "Fold: 1  Epoch: 154  Training loss = 3.0448  Validation loss = 3.1163  \n",
      "\n",
      "Fold: 1  Epoch: 155  Training loss = 3.0438  Validation loss = 3.1143  \n",
      "\n",
      "Fold: 1  Epoch: 156  Training loss = 3.0428  Validation loss = 3.1125  \n",
      "\n",
      "Fold: 1  Epoch: 157  Training loss = 3.0416  Validation loss = 3.1101  \n",
      "\n",
      "Fold: 1  Epoch: 158  Training loss = 3.0408  Validation loss = 3.1084  \n",
      "\n",
      "Fold: 1  Epoch: 159  Training loss = 3.0403  Validation loss = 3.1074  \n",
      "\n",
      "Fold: 1  Epoch: 160  Training loss = 3.0394  Validation loss = 3.1057  \n",
      "\n",
      "Fold: 1  Epoch: 161  Training loss = 3.0385  Validation loss = 3.1039  \n",
      "\n",
      "Fold: 1  Epoch: 162  Training loss = 3.0374  Validation loss = 3.1016  \n",
      "\n",
      "Fold: 1  Epoch: 163  Training loss = 3.0365  Validation loss = 3.1000  \n",
      "\n",
      "Fold: 1  Epoch: 164  Training loss = 3.0355  Validation loss = 3.0980  \n",
      "\n",
      "Fold: 1  Epoch: 165  Training loss = 3.0345  Validation loss = 3.0962  \n",
      "\n",
      "Fold: 1  Epoch: 166  Training loss = 3.0339  Validation loss = 3.0950  \n",
      "\n",
      "Fold: 1  Epoch: 167  Training loss = 3.0331  Validation loss = 3.0932  \n",
      "\n",
      "Fold: 1  Epoch: 168  Training loss = 3.0321  Validation loss = 3.0914  \n",
      "\n",
      "Fold: 1  Epoch: 169  Training loss = 3.0310  Validation loss = 3.0892  \n",
      "\n",
      "Fold: 1  Epoch: 170  Training loss = 3.0303  Validation loss = 3.0876  \n",
      "\n",
      "Fold: 1  Epoch: 171  Training loss = 3.0291  Validation loss = 3.0853  \n",
      "\n",
      "Fold: 1  Epoch: 172  Training loss = 3.0283  Validation loss = 3.0838  \n",
      "\n",
      "Fold: 1  Epoch: 173  Training loss = 3.0273  Validation loss = 3.0818  \n",
      "\n",
      "Fold: 1  Epoch: 174  Training loss = 3.0260  Validation loss = 3.0794  \n",
      "\n",
      "Fold: 1  Epoch: 175  Training loss = 3.0254  Validation loss = 3.0782  \n",
      "\n",
      "Fold: 1  Epoch: 176  Training loss = 3.0244  Validation loss = 3.0761  \n",
      "\n",
      "Fold: 1  Epoch: 177  Training loss = 3.0236  Validation loss = 3.0746  \n",
      "\n",
      "Fold: 1  Epoch: 178  Training loss = 3.0227  Validation loss = 3.0728  \n",
      "\n",
      "Fold: 1  Epoch: 179  Training loss = 3.0222  Validation loss = 3.0717  \n",
      "\n",
      "Fold: 1  Epoch: 180  Training loss = 3.0212  Validation loss = 3.0699  \n",
      "\n",
      "Fold: 1  Epoch: 181  Training loss = 3.0204  Validation loss = 3.0682  \n",
      "\n",
      "Fold: 1  Epoch: 182  Training loss = 3.0199  Validation loss = 3.0671  \n",
      "\n",
      "Fold: 1  Epoch: 183  Training loss = 3.0192  Validation loss = 3.0656  \n",
      "\n",
      "Fold: 1  Epoch: 184  Training loss = 3.0183  Validation loss = 3.0638  \n",
      "\n",
      "Fold: 1  Epoch: 185  Training loss = 3.0179  Validation loss = 3.0629  \n",
      "\n",
      "Fold: 1  Epoch: 186  Training loss = 3.0169  Validation loss = 3.0609  \n",
      "\n",
      "Fold: 1  Epoch: 187  Training loss = 3.0164  Validation loss = 3.0599  \n",
      "\n",
      "Fold: 1  Epoch: 188  Training loss = 3.0155  Validation loss = 3.0580  \n",
      "\n",
      "Fold: 1  Epoch: 189  Training loss = 3.0146  Validation loss = 3.0563  \n",
      "\n",
      "Fold: 1  Epoch: 190  Training loss = 3.0140  Validation loss = 3.0550  \n",
      "\n",
      "Fold: 1  Epoch: 191  Training loss = 3.0130  Validation loss = 3.0530  \n",
      "\n",
      "Fold: 1  Epoch: 192  Training loss = 3.0115  Validation loss = 3.0502  \n",
      "\n",
      "Fold: 1  Epoch: 193  Training loss = 3.0109  Validation loss = 3.0488  \n",
      "\n",
      "Fold: 1  Epoch: 194  Training loss = 3.0101  Validation loss = 3.0472  \n",
      "\n",
      "Fold: 1  Epoch: 195  Training loss = 3.0094  Validation loss = 3.0458  \n",
      "\n",
      "Fold: 1  Epoch: 196  Training loss = 3.0085  Validation loss = 3.0439  \n",
      "\n",
      "Fold: 1  Epoch: 197  Training loss = 3.0077  Validation loss = 3.0423  \n",
      "\n",
      "Fold: 1  Epoch: 198  Training loss = 3.0071  Validation loss = 3.0412  \n",
      "\n",
      "Fold: 1  Epoch: 199  Training loss = 3.0064  Validation loss = 3.0398  \n",
      "\n",
      "Fold: 1  Epoch: 200  Training loss = 3.0055  Validation loss = 3.0379  \n",
      "\n",
      "Fold: 1  Epoch: 201  Training loss = 3.0046  Validation loss = 3.0361  \n",
      "\n",
      "Fold: 1  Epoch: 202  Training loss = 3.0036  Validation loss = 3.0341  \n",
      "\n",
      "Fold: 1  Epoch: 203  Training loss = 3.0029  Validation loss = 3.0327  \n",
      "\n",
      "Fold: 1  Epoch: 204  Training loss = 3.0021  Validation loss = 3.0309  \n",
      "\n",
      "Fold: 1  Epoch: 205  Training loss = 3.0011  Validation loss = 3.0290  \n",
      "\n",
      "Fold: 1  Epoch: 206  Training loss = 3.0001  Validation loss = 3.0269  \n",
      "\n",
      "Fold: 1  Epoch: 207  Training loss = 2.9991  Validation loss = 3.0249  \n",
      "\n",
      "Fold: 1  Epoch: 208  Training loss = 2.9983  Validation loss = 3.0233  \n",
      "\n",
      "Fold: 1  Epoch: 209  Training loss = 2.9976  Validation loss = 3.0217  \n",
      "\n",
      "Fold: 1  Epoch: 210  Training loss = 2.9967  Validation loss = 3.0200  \n",
      "\n",
      "Fold: 1  Epoch: 211  Training loss = 2.9962  Validation loss = 3.0188  \n",
      "\n",
      "Fold: 1  Epoch: 212  Training loss = 2.9953  Validation loss = 3.0171  \n",
      "\n",
      "Fold: 1  Epoch: 213  Training loss = 2.9945  Validation loss = 3.0154  \n",
      "\n",
      "Fold: 1  Epoch: 214  Training loss = 2.9940  Validation loss = 3.0143  \n",
      "\n",
      "Fold: 1  Epoch: 215  Training loss = 2.9931  Validation loss = 3.0126  \n",
      "\n",
      "Fold: 1  Epoch: 216  Training loss = 2.9926  Validation loss = 3.0115  \n",
      "\n",
      "Fold: 1  Epoch: 217  Training loss = 2.9920  Validation loss = 3.0102  \n",
      "\n",
      "Fold: 1  Epoch: 218  Training loss = 2.9912  Validation loss = 3.0086  \n",
      "\n",
      "Fold: 1  Epoch: 219  Training loss = 2.9902  Validation loss = 3.0066  \n",
      "\n",
      "Fold: 1  Epoch: 220  Training loss = 2.9893  Validation loss = 3.0046  \n",
      "\n",
      "Fold: 1  Epoch: 221  Training loss = 2.9886  Validation loss = 3.0032  \n",
      "\n",
      "Fold: 1  Epoch: 222  Training loss = 2.9879  Validation loss = 3.0017  \n",
      "\n",
      "Fold: 1  Epoch: 223  Training loss = 2.9871  Validation loss = 3.0000  \n",
      "\n",
      "Fold: 1  Epoch: 224  Training loss = 2.9862  Validation loss = 2.9982  \n",
      "\n",
      "Fold: 1  Epoch: 225  Training loss = 2.9856  Validation loss = 2.9969  \n",
      "\n",
      "Fold: 1  Epoch: 226  Training loss = 2.9846  Validation loss = 2.9948  \n",
      "\n",
      "Fold: 1  Epoch: 227  Training loss = 2.9840  Validation loss = 2.9936  \n",
      "\n",
      "Fold: 1  Epoch: 228  Training loss = 2.9833  Validation loss = 2.9920  \n",
      "\n",
      "Fold: 1  Epoch: 229  Training loss = 2.9824  Validation loss = 2.9902  \n",
      "\n",
      "Fold: 1  Epoch: 230  Training loss = 2.9816  Validation loss = 2.9887  \n",
      "\n",
      "Fold: 1  Epoch: 231  Training loss = 2.9807  Validation loss = 2.9869  \n",
      "\n",
      "Fold: 1  Epoch: 232  Training loss = 2.9800  Validation loss = 2.9853  \n",
      "\n",
      "Fold: 1  Epoch: 233  Training loss = 2.9793  Validation loss = 2.9838  \n",
      "\n",
      "Fold: 1  Epoch: 234  Training loss = 2.9787  Validation loss = 2.9824  \n",
      "\n",
      "Fold: 1  Epoch: 235  Training loss = 2.9779  Validation loss = 2.9808  \n",
      "\n",
      "Fold: 1  Epoch: 236  Training loss = 2.9773  Validation loss = 2.9794  \n",
      "\n",
      "Fold: 1  Epoch: 237  Training loss = 2.9764  Validation loss = 2.9775  \n",
      "\n",
      "Fold: 1  Epoch: 238  Training loss = 2.9757  Validation loss = 2.9761  \n",
      "\n",
      "Fold: 1  Epoch: 239  Training loss = 2.9751  Validation loss = 2.9748  \n",
      "\n",
      "Fold: 1  Epoch: 240  Training loss = 2.9744  Validation loss = 2.9734  \n",
      "\n",
      "Fold: 1  Epoch: 241  Training loss = 2.9737  Validation loss = 2.9719  \n",
      "\n",
      "Fold: 1  Epoch: 242  Training loss = 2.9730  Validation loss = 2.9702  \n",
      "\n",
      "Fold: 1  Epoch: 243  Training loss = 2.9723  Validation loss = 2.9690  \n",
      "\n",
      "Fold: 1  Epoch: 244  Training loss = 2.9714  Validation loss = 2.9670  \n",
      "\n",
      "Fold: 1  Epoch: 245  Training loss = 2.9708  Validation loss = 2.9658  \n",
      "\n",
      "Fold: 1  Epoch: 246  Training loss = 2.9698  Validation loss = 2.9636  \n",
      "\n",
      "Fold: 1  Epoch: 247  Training loss = 2.9690  Validation loss = 2.9620  \n",
      "\n",
      "Fold: 1  Epoch: 248  Training loss = 2.9682  Validation loss = 2.9604  \n",
      "\n",
      "Fold: 1  Epoch: 249  Training loss = 2.9675  Validation loss = 2.9589  \n",
      "\n",
      "Fold: 1  Epoch: 250  Training loss = 2.9669  Validation loss = 2.9576  \n",
      "\n",
      "Fold: 1  Epoch: 251  Training loss = 2.9660  Validation loss = 2.9557  \n",
      "\n",
      "Fold: 1  Epoch: 252  Training loss = 2.9653  Validation loss = 2.9543  \n",
      "\n",
      "Fold: 1  Epoch: 253  Training loss = 2.9648  Validation loss = 2.9529  \n",
      "\n",
      "Fold: 1  Epoch: 254  Training loss = 2.9642  Validation loss = 2.9518  \n",
      "\n",
      "Fold: 1  Epoch: 255  Training loss = 2.9635  Validation loss = 2.9502  \n",
      "\n",
      "Fold: 1  Epoch: 256  Training loss = 2.9625  Validation loss = 2.9481  \n",
      "\n",
      "Fold: 1  Epoch: 257  Training loss = 2.9615  Validation loss = 2.9460  \n",
      "\n",
      "Fold: 1  Epoch: 258  Training loss = 2.9608  Validation loss = 2.9446  \n",
      "\n",
      "Fold: 1  Epoch: 259  Training loss = 2.9602  Validation loss = 2.9433  \n",
      "\n",
      "Fold: 1  Epoch: 260  Training loss = 2.9594  Validation loss = 2.9417  \n",
      "\n",
      "Fold: 1  Epoch: 261  Training loss = 2.9590  Validation loss = 2.9406  \n",
      "\n",
      "Fold: 1  Epoch: 262  Training loss = 2.9580  Validation loss = 2.9386  \n",
      "\n",
      "Fold: 1  Epoch: 263  Training loss = 2.9574  Validation loss = 2.9373  \n",
      "\n",
      "Fold: 1  Epoch: 264  Training loss = 2.9566  Validation loss = 2.9356  \n",
      "\n",
      "Fold: 1  Epoch: 265  Training loss = 2.9560  Validation loss = 2.9343  \n",
      "\n",
      "Fold: 1  Epoch: 266  Training loss = 2.9555  Validation loss = 2.9332  \n",
      "\n",
      "Fold: 1  Epoch: 267  Training loss = 2.9550  Validation loss = 2.9320  \n",
      "\n",
      "Fold: 1  Epoch: 268  Training loss = 2.9542  Validation loss = 2.9304  \n",
      "\n",
      "Fold: 1  Epoch: 269  Training loss = 2.9531  Validation loss = 2.9280  \n",
      "\n",
      "Fold: 1  Epoch: 270  Training loss = 2.9524  Validation loss = 2.9265  \n",
      "\n",
      "Fold: 1  Epoch: 271  Training loss = 2.9516  Validation loss = 2.9247  \n",
      "\n",
      "Fold: 1  Epoch: 272  Training loss = 2.9509  Validation loss = 2.9233  \n",
      "\n",
      "Fold: 1  Epoch: 273  Training loss = 2.9504  Validation loss = 2.9221  \n",
      "\n",
      "Fold: 1  Epoch: 274  Training loss = 2.9497  Validation loss = 2.9207  \n",
      "\n",
      "Fold: 1  Epoch: 275  Training loss = 2.9492  Validation loss = 2.9196  \n",
      "\n",
      "Fold: 1  Epoch: 276  Training loss = 2.9485  Validation loss = 2.9181  \n",
      "\n",
      "Fold: 1  Epoch: 277  Training loss = 2.9481  Validation loss = 2.9170  \n",
      "\n",
      "Fold: 1  Epoch: 278  Training loss = 2.9475  Validation loss = 2.9157  \n",
      "\n",
      "Fold: 1  Epoch: 279  Training loss = 2.9470  Validation loss = 2.9145  \n",
      "\n",
      "Fold: 1  Epoch: 280  Training loss = 2.9463  Validation loss = 2.9132  \n",
      "\n",
      "Fold: 1  Epoch: 281  Training loss = 2.9458  Validation loss = 2.9121  \n",
      "\n",
      "Fold: 1  Epoch: 282  Training loss = 2.9453  Validation loss = 2.9109  \n",
      "\n",
      "Fold: 1  Epoch: 283  Training loss = 2.9443  Validation loss = 2.9087  \n",
      "\n",
      "Fold: 1  Epoch: 284  Training loss = 2.9438  Validation loss = 2.9076  \n",
      "\n",
      "Fold: 1  Epoch: 285  Training loss = 2.9433  Validation loss = 2.9065  \n",
      "\n",
      "Fold: 1  Epoch: 286  Training loss = 2.9427  Validation loss = 2.9051  \n",
      "\n",
      "Fold: 1  Epoch: 287  Training loss = 2.9422  Validation loss = 2.9040  \n",
      "\n",
      "Fold: 1  Epoch: 288  Training loss = 2.9417  Validation loss = 2.9028  \n",
      "\n",
      "Fold: 1  Epoch: 289  Training loss = 2.9412  Validation loss = 2.9017  \n",
      "\n",
      "Fold: 1  Epoch: 290  Training loss = 2.9409  Validation loss = 2.9010  \n",
      "\n",
      "Fold: 1  Epoch: 291  Training loss = 2.9405  Validation loss = 2.9001  \n",
      "\n",
      "Fold: 1  Epoch: 292  Training loss = 2.9397  Validation loss = 2.8984  \n",
      "\n",
      "Fold: 1  Epoch: 293  Training loss = 2.9392  Validation loss = 2.8973  \n",
      "\n",
      "Fold: 1  Epoch: 294  Training loss = 2.9385  Validation loss = 2.8958  \n",
      "\n",
      "Fold: 1  Epoch: 295  Training loss = 2.9381  Validation loss = 2.8947  \n",
      "\n",
      "Fold: 1  Epoch: 296  Training loss = 2.9373  Validation loss = 2.8931  \n",
      "\n",
      "Fold: 1  Epoch: 297  Training loss = 2.9367  Validation loss = 2.8917  \n",
      "\n",
      "Fold: 1  Epoch: 298  Training loss = 2.9361  Validation loss = 2.8903  \n",
      "\n",
      "Fold: 1  Epoch: 299  Training loss = 2.9357  Validation loss = 2.8893  \n",
      "\n",
      "Fold: 1  Epoch: 300  Training loss = 2.9349  Validation loss = 2.8877  \n",
      "\n",
      "Fold: 1  Epoch: 301  Training loss = 2.9342  Validation loss = 2.8862  \n",
      "\n",
      "Fold: 1  Epoch: 302  Training loss = 2.9337  Validation loss = 2.8849  \n",
      "\n",
      "Fold: 1  Epoch: 303  Training loss = 2.9331  Validation loss = 2.8836  \n",
      "\n",
      "Fold: 1  Epoch: 304  Training loss = 2.9325  Validation loss = 2.8822  \n",
      "\n",
      "Fold: 1  Epoch: 305  Training loss = 2.9317  Validation loss = 2.8805  \n",
      "\n",
      "Fold: 1  Epoch: 306  Training loss = 2.9309  Validation loss = 2.8788  \n",
      "\n",
      "Fold: 1  Epoch: 307  Training loss = 2.9304  Validation loss = 2.8776  \n",
      "\n",
      "Fold: 1  Epoch: 308  Training loss = 2.9297  Validation loss = 2.8761  \n",
      "\n",
      "Fold: 1  Epoch: 309  Training loss = 2.9292  Validation loss = 2.8749  \n",
      "\n",
      "Fold: 1  Epoch: 310  Training loss = 2.9283  Validation loss = 2.8729  \n",
      "\n",
      "Fold: 1  Epoch: 311  Training loss = 2.9276  Validation loss = 2.8713  \n",
      "\n",
      "Fold: 1  Epoch: 312  Training loss = 2.9269  Validation loss = 2.8698  \n",
      "\n",
      "Fold: 1  Epoch: 313  Training loss = 2.9260  Validation loss = 2.8679  \n",
      "\n",
      "Fold: 1  Epoch: 314  Training loss = 2.9252  Validation loss = 2.8661  \n",
      "\n",
      "Fold: 1  Epoch: 315  Training loss = 2.9245  Validation loss = 2.8645  \n",
      "\n",
      "Fold: 1  Epoch: 316  Training loss = 2.9239  Validation loss = 2.8631  \n",
      "\n",
      "Fold: 1  Epoch: 317  Training loss = 2.9231  Validation loss = 2.8613  \n",
      "\n",
      "Fold: 1  Epoch: 318  Training loss = 2.9225  Validation loss = 2.8599  \n",
      "\n",
      "Fold: 1  Epoch: 319  Training loss = 2.9216  Validation loss = 2.8580  \n",
      "\n",
      "Fold: 1  Epoch: 320  Training loss = 2.9210  Validation loss = 2.8568  \n",
      "\n",
      "Fold: 1  Epoch: 321  Training loss = 2.9205  Validation loss = 2.8555  \n",
      "\n",
      "Fold: 1  Epoch: 322  Training loss = 2.9196  Validation loss = 2.8536  \n",
      "\n",
      "Fold: 1  Epoch: 323  Training loss = 2.9189  Validation loss = 2.8521  \n",
      "\n",
      "Fold: 1  Epoch: 324  Training loss = 2.9184  Validation loss = 2.8507  \n",
      "\n",
      "Fold: 1  Epoch: 325  Training loss = 2.9177  Validation loss = 2.8492  \n",
      "\n",
      "Fold: 1  Epoch: 326  Training loss = 2.9169  Validation loss = 2.8475  \n",
      "\n",
      "Fold: 1  Epoch: 327  Training loss = 2.9160  Validation loss = 2.8453  \n",
      "\n",
      "Fold: 1  Epoch: 328  Training loss = 2.9155  Validation loss = 2.8443  \n",
      "\n",
      "Fold: 1  Epoch: 329  Training loss = 2.9151  Validation loss = 2.8433  \n",
      "\n",
      "Fold: 1  Epoch: 330  Training loss = 2.9145  Validation loss = 2.8419  \n",
      "\n",
      "Fold: 1  Epoch: 331  Training loss = 2.9139  Validation loss = 2.8406  \n",
      "\n",
      "Fold: 1  Epoch: 332  Training loss = 2.9135  Validation loss = 2.8396  \n",
      "\n",
      "Fold: 1  Epoch: 333  Training loss = 2.9128  Validation loss = 2.8380  \n",
      "\n",
      "Fold: 1  Epoch: 334  Training loss = 2.9120  Validation loss = 2.8362  \n",
      "\n",
      "Fold: 1  Epoch: 335  Training loss = 2.9114  Validation loss = 2.8348  \n",
      "\n",
      "Fold: 1  Epoch: 336  Training loss = 2.9108  Validation loss = 2.8335  \n",
      "\n",
      "Fold: 1  Epoch: 337  Training loss = 2.9105  Validation loss = 2.8327  \n",
      "\n",
      "Fold: 1  Epoch: 338  Training loss = 2.9100  Validation loss = 2.8315  \n",
      "\n",
      "Fold: 1  Epoch: 339  Training loss = 2.9095  Validation loss = 2.8303  \n",
      "\n",
      "Fold: 1  Epoch: 340  Training loss = 2.9090  Validation loss = 2.8292  \n",
      "\n",
      "Fold: 1  Epoch: 341  Training loss = 2.9085  Validation loss = 2.8280  \n",
      "\n",
      "Fold: 1  Epoch: 342  Training loss = 2.9081  Validation loss = 2.8270  \n",
      "\n",
      "Fold: 1  Epoch: 343  Training loss = 2.9076  Validation loss = 2.8259  \n",
      "\n",
      "Fold: 1  Epoch: 344  Training loss = 2.9070  Validation loss = 2.8246  \n",
      "\n",
      "Fold: 1  Epoch: 345  Training loss = 2.9067  Validation loss = 2.8237  \n",
      "\n",
      "Fold: 1  Epoch: 346  Training loss = 2.9062  Validation loss = 2.8227  \n",
      "\n",
      "Fold: 1  Epoch: 347  Training loss = 2.9058  Validation loss = 2.8218  \n",
      "\n",
      "Fold: 1  Epoch: 348  Training loss = 2.9052  Validation loss = 2.8204  \n",
      "\n",
      "Fold: 1  Epoch: 349  Training loss = 2.9043  Validation loss = 2.8183  \n",
      "\n",
      "Fold: 1  Epoch: 350  Training loss = 2.9036  Validation loss = 2.8169  \n",
      "\n",
      "Fold: 1  Epoch: 351  Training loss = 2.9030  Validation loss = 2.8154  \n",
      "\n",
      "Fold: 1  Epoch: 352  Training loss = 2.9021  Validation loss = 2.8133  \n",
      "\n",
      "Fold: 1  Epoch: 353  Training loss = 2.9014  Validation loss = 2.8117  \n",
      "\n",
      "Fold: 1  Epoch: 354  Training loss = 2.9008  Validation loss = 2.8105  \n",
      "\n",
      "Fold: 1  Epoch: 355  Training loss = 2.8999  Validation loss = 2.8085  \n",
      "\n",
      "Fold: 1  Epoch: 356  Training loss = 2.8994  Validation loss = 2.8071  \n",
      "\n",
      "Fold: 1  Epoch: 357  Training loss = 2.8987  Validation loss = 2.8055  \n",
      "\n",
      "Fold: 1  Epoch: 358  Training loss = 2.8981  Validation loss = 2.8041  \n",
      "\n",
      "Fold: 1  Epoch: 359  Training loss = 2.8974  Validation loss = 2.8025  \n",
      "\n",
      "Fold: 1  Epoch: 360  Training loss = 2.8968  Validation loss = 2.8012  \n",
      "\n",
      "Fold: 1  Epoch: 361  Training loss = 2.8961  Validation loss = 2.7996  \n",
      "\n",
      "Fold: 1  Epoch: 362  Training loss = 2.8956  Validation loss = 2.7985  \n",
      "\n",
      "Fold: 1  Epoch: 363  Training loss = 2.8951  Validation loss = 2.7971  \n",
      "\n",
      "Fold: 1  Epoch: 364  Training loss = 2.8943  Validation loss = 2.7954  \n",
      "\n",
      "Fold: 1  Epoch: 365  Training loss = 2.8938  Validation loss = 2.7943  \n",
      "\n",
      "Fold: 1  Epoch: 366  Training loss = 2.8933  Validation loss = 2.7931  \n",
      "\n",
      "Fold: 1  Epoch: 367  Training loss = 2.8928  Validation loss = 2.7919  \n",
      "\n",
      "Fold: 1  Epoch: 368  Training loss = 2.8923  Validation loss = 2.7906  \n",
      "\n",
      "Fold: 1  Epoch: 369  Training loss = 2.8917  Validation loss = 2.7893  \n",
      "\n",
      "Fold: 1  Epoch: 370  Training loss = 2.8911  Validation loss = 2.7880  \n",
      "\n",
      "Fold: 1  Epoch: 371  Training loss = 2.8903  Validation loss = 2.7862  \n",
      "\n",
      "Fold: 1  Epoch: 372  Training loss = 2.8901  Validation loss = 2.7856  \n",
      "\n",
      "Fold: 1  Epoch: 373  Training loss = 2.8897  Validation loss = 2.7846  \n",
      "\n",
      "Fold: 1  Epoch: 374  Training loss = 2.8894  Validation loss = 2.7839  \n",
      "\n",
      "Fold: 1  Epoch: 375  Training loss = 2.8890  Validation loss = 2.7830  \n",
      "\n",
      "Fold: 1  Epoch: 376  Training loss = 2.8884  Validation loss = 2.7815  \n",
      "\n",
      "Fold: 1  Epoch: 377  Training loss = 2.8878  Validation loss = 2.7802  \n",
      "\n",
      "Fold: 1  Epoch: 378  Training loss = 2.8872  Validation loss = 2.7786  \n",
      "\n",
      "Fold: 1  Epoch: 379  Training loss = 2.8866  Validation loss = 2.7773  \n",
      "\n",
      "Fold: 1  Epoch: 380  Training loss = 2.8862  Validation loss = 2.7762  \n",
      "\n",
      "Fold: 1  Epoch: 381  Training loss = 2.8857  Validation loss = 2.7749  \n",
      "\n",
      "Fold: 1  Epoch: 382  Training loss = 2.8851  Validation loss = 2.7735  \n",
      "\n",
      "Fold: 1  Epoch: 383  Training loss = 2.8845  Validation loss = 2.7721  \n",
      "\n",
      "Fold: 1  Epoch: 384  Training loss = 2.8840  Validation loss = 2.7711  \n",
      "\n",
      "Fold: 1  Epoch: 385  Training loss = 2.8836  Validation loss = 2.7700  \n",
      "\n",
      "Fold: 1  Epoch: 386  Training loss = 2.8830  Validation loss = 2.7686  \n",
      "\n",
      "Fold: 1  Epoch: 387  Training loss = 2.8827  Validation loss = 2.7679  \n",
      "\n",
      "Fold: 1  Epoch: 388  Training loss = 2.8820  Validation loss = 2.7663  \n",
      "\n",
      "Fold: 1  Epoch: 389  Training loss = 2.8816  Validation loss = 2.7653  \n",
      "\n",
      "Fold: 1  Epoch: 390  Training loss = 2.8811  Validation loss = 2.7641  \n",
      "\n",
      "Fold: 1  Epoch: 391  Training loss = 2.8805  Validation loss = 2.7626  \n",
      "\n",
      "Fold: 1  Epoch: 392  Training loss = 2.8797  Validation loss = 2.7609  \n",
      "\n",
      "Fold: 1  Epoch: 393  Training loss = 2.8793  Validation loss = 2.7598  \n",
      "\n",
      "Fold: 1  Epoch: 394  Training loss = 2.8788  Validation loss = 2.7586  \n",
      "\n",
      "Fold: 1  Epoch: 395  Training loss = 2.8784  Validation loss = 2.7576  \n",
      "\n",
      "Fold: 1  Epoch: 396  Training loss = 2.8780  Validation loss = 2.7566  \n",
      "\n",
      "Fold: 1  Epoch: 397  Training loss = 2.8775  Validation loss = 2.7555  \n",
      "\n",
      "Fold: 1  Epoch: 398  Training loss = 2.8771  Validation loss = 2.7546  \n",
      "\n",
      "Fold: 1  Epoch: 399  Training loss = 2.8764  Validation loss = 2.7530  \n",
      "\n",
      "Fold: 1  Epoch: 400  Training loss = 2.8760  Validation loss = 2.7517  \n",
      "\n",
      "Fold: 1  Epoch: 401  Training loss = 2.8754  Validation loss = 2.7505  \n",
      "\n",
      "Fold: 1  Epoch: 402  Training loss = 2.8750  Validation loss = 2.7496  \n",
      "\n",
      "Fold: 1  Epoch: 403  Training loss = 2.8747  Validation loss = 2.7487  \n",
      "\n",
      "Fold: 1  Epoch: 404  Training loss = 2.8742  Validation loss = 2.7476  \n",
      "\n",
      "Fold: 1  Epoch: 405  Training loss = 2.8739  Validation loss = 2.7468  \n",
      "\n",
      "Fold: 1  Epoch: 406  Training loss = 2.8735  Validation loss = 2.7458  \n",
      "\n",
      "Fold: 1  Epoch: 407  Training loss = 2.8732  Validation loss = 2.7451  \n",
      "\n",
      "Fold: 1  Epoch: 408  Training loss = 2.8725  Validation loss = 2.7434  \n",
      "\n",
      "Fold: 1  Epoch: 409  Training loss = 2.8721  Validation loss = 2.7424  \n",
      "\n",
      "Fold: 1  Epoch: 410  Training loss = 2.8716  Validation loss = 2.7411  \n",
      "\n",
      "Fold: 1  Epoch: 411  Training loss = 2.8712  Validation loss = 2.7401  \n",
      "\n",
      "Fold: 1  Epoch: 412  Training loss = 2.8706  Validation loss = 2.7387  \n",
      "\n",
      "Fold: 1  Epoch: 413  Training loss = 2.8700  Validation loss = 2.7374  \n",
      "\n",
      "Fold: 1  Epoch: 414  Training loss = 2.8693  Validation loss = 2.7356  \n",
      "\n",
      "Fold: 1  Epoch: 415  Training loss = 2.8689  Validation loss = 2.7345  \n",
      "\n",
      "Fold: 1  Epoch: 416  Training loss = 2.8683  Validation loss = 2.7331  \n",
      "\n",
      "Fold: 1  Epoch: 417  Training loss = 2.8680  Validation loss = 2.7324  \n",
      "\n",
      "Fold: 1  Epoch: 418  Training loss = 2.8675  Validation loss = 2.7312  \n",
      "\n",
      "Fold: 1  Epoch: 419  Training loss = 2.8668  Validation loss = 2.7296  \n",
      "\n",
      "Fold: 1  Epoch: 420  Training loss = 2.8663  Validation loss = 2.7281  \n",
      "\n",
      "Fold: 1  Epoch: 421  Training loss = 2.8657  Validation loss = 2.7267  \n",
      "\n",
      "Fold: 1  Epoch: 422  Training loss = 2.8651  Validation loss = 2.7254  \n",
      "\n",
      "Fold: 1  Epoch: 423  Training loss = 2.8646  Validation loss = 2.7241  \n",
      "\n",
      "Fold: 1  Epoch: 424  Training loss = 2.8644  Validation loss = 2.7234  \n",
      "\n",
      "Fold: 1  Epoch: 425  Training loss = 2.8640  Validation loss = 2.7225  \n",
      "\n",
      "Fold: 1  Epoch: 426  Training loss = 2.8637  Validation loss = 2.7215  \n",
      "\n",
      "Fold: 1  Epoch: 427  Training loss = 2.8632  Validation loss = 2.7205  \n",
      "\n",
      "Fold: 1  Epoch: 428  Training loss = 2.8626  Validation loss = 2.7191  \n",
      "\n",
      "Fold: 1  Epoch: 429  Training loss = 2.8619  Validation loss = 2.7174  \n",
      "\n",
      "Fold: 1  Epoch: 430  Training loss = 2.8615  Validation loss = 2.7163  \n",
      "\n",
      "Fold: 1  Epoch: 431  Training loss = 2.8609  Validation loss = 2.7150  \n",
      "\n",
      "Fold: 1  Epoch: 432  Training loss = 2.8605  Validation loss = 2.7138  \n",
      "\n",
      "Fold: 1  Epoch: 433  Training loss = 2.8601  Validation loss = 2.7128  \n",
      "\n",
      "Fold: 1  Epoch: 434  Training loss = 2.8597  Validation loss = 2.7120  \n",
      "\n",
      "Fold: 1  Epoch: 435  Training loss = 2.8593  Validation loss = 2.7109  \n",
      "\n",
      "Fold: 1  Epoch: 436  Training loss = 2.8588  Validation loss = 2.7098  \n",
      "\n",
      "Fold: 1  Epoch: 437  Training loss = 2.8582  Validation loss = 2.7083  \n",
      "\n",
      "Fold: 1  Epoch: 438  Training loss = 2.8579  Validation loss = 2.7074  \n",
      "\n",
      "Fold: 1  Epoch: 439  Training loss = 2.8575  Validation loss = 2.7064  \n",
      "\n",
      "Fold: 1  Epoch: 440  Training loss = 2.8570  Validation loss = 2.7053  \n",
      "\n",
      "Fold: 1  Epoch: 441  Training loss = 2.8566  Validation loss = 2.7043  \n",
      "\n",
      "Fold: 1  Epoch: 442  Training loss = 2.8562  Validation loss = 2.7031  \n",
      "\n",
      "Fold: 1  Epoch: 443  Training loss = 2.8558  Validation loss = 2.7023  \n",
      "\n",
      "Fold: 1  Epoch: 444  Training loss = 2.8552  Validation loss = 2.7006  \n",
      "\n",
      "Fold: 1  Epoch: 445  Training loss = 2.8547  Validation loss = 2.6995  \n",
      "\n",
      "Fold: 1  Epoch: 446  Training loss = 2.8542  Validation loss = 2.6981  \n",
      "\n",
      "Fold: 1  Epoch: 447  Training loss = 2.8536  Validation loss = 2.6966  \n",
      "\n",
      "Fold: 1  Epoch: 448  Training loss = 2.8530  Validation loss = 2.6952  \n",
      "\n",
      "Fold: 1  Epoch: 449  Training loss = 2.8525  Validation loss = 2.6939  \n",
      "\n",
      "Fold: 1  Epoch: 450  Training loss = 2.8520  Validation loss = 2.6927  \n",
      "\n",
      "Fold: 1  Epoch: 451  Training loss = 2.8514  Validation loss = 2.6912  \n",
      "\n",
      "Fold: 1  Epoch: 452  Training loss = 2.8510  Validation loss = 2.6901  \n",
      "\n",
      "Fold: 1  Epoch: 453  Training loss = 2.8506  Validation loss = 2.6893  \n",
      "\n",
      "Fold: 1  Epoch: 454  Training loss = 2.8502  Validation loss = 2.6882  \n",
      "\n",
      "Fold: 1  Epoch: 455  Training loss = 2.8498  Validation loss = 2.6872  \n",
      "\n",
      "Fold: 1  Epoch: 456  Training loss = 2.8493  Validation loss = 2.6859  \n",
      "\n",
      "Fold: 1  Epoch: 457  Training loss = 2.8488  Validation loss = 2.6847  \n",
      "\n",
      "Fold: 1  Epoch: 458  Training loss = 2.8484  Validation loss = 2.6837  \n",
      "\n",
      "Fold: 1  Epoch: 459  Training loss = 2.8479  Validation loss = 2.6825  \n",
      "\n",
      "Fold: 1  Epoch: 460  Training loss = 2.8475  Validation loss = 2.6814  \n",
      "\n",
      "Fold: 1  Epoch: 461  Training loss = 2.8471  Validation loss = 2.6803  \n",
      "\n",
      "Fold: 1  Epoch: 462  Training loss = 2.8464  Validation loss = 2.6786  \n",
      "\n",
      "Fold: 1  Epoch: 463  Training loss = 2.8460  Validation loss = 2.6778  \n",
      "\n",
      "Fold: 1  Epoch: 464  Training loss = 2.8457  Validation loss = 2.6768  \n",
      "\n",
      "Fold: 1  Epoch: 465  Training loss = 2.8450  Validation loss = 2.6753  \n",
      "\n",
      "Fold: 1  Epoch: 466  Training loss = 2.8444  Validation loss = 2.6737  \n",
      "\n",
      "Fold: 1  Epoch: 467  Training loss = 2.8440  Validation loss = 2.6728  \n",
      "\n",
      "Fold: 1  Epoch: 468  Training loss = 2.8434  Validation loss = 2.6713  \n",
      "\n",
      "Fold: 1  Epoch: 469  Training loss = 2.8427  Validation loss = 2.6696  \n",
      "\n",
      "Fold: 1  Epoch: 470  Training loss = 2.8421  Validation loss = 2.6681  \n",
      "\n",
      "Fold: 1  Epoch: 471  Training loss = 2.8418  Validation loss = 2.6673  \n",
      "\n",
      "Fold: 1  Epoch: 472  Training loss = 2.8416  Validation loss = 2.6666  \n",
      "\n",
      "Fold: 1  Epoch: 473  Training loss = 2.8410  Validation loss = 2.6652  \n",
      "\n",
      "Fold: 1  Epoch: 474  Training loss = 2.8404  Validation loss = 2.6637  \n",
      "\n",
      "Fold: 1  Epoch: 475  Training loss = 2.8398  Validation loss = 2.6621  \n",
      "\n",
      "Fold: 1  Epoch: 476  Training loss = 2.8391  Validation loss = 2.6605  \n",
      "\n",
      "Fold: 1  Epoch: 477  Training loss = 2.8389  Validation loss = 2.6599  \n",
      "\n",
      "Fold: 1  Epoch: 478  Training loss = 2.8386  Validation loss = 2.6591  \n",
      "\n",
      "Fold: 1  Epoch: 479  Training loss = 2.8383  Validation loss = 2.6582  \n",
      "\n",
      "Fold: 1  Epoch: 480  Training loss = 2.8377  Validation loss = 2.6567  \n",
      "\n",
      "Fold: 1  Epoch: 481  Training loss = 2.8372  Validation loss = 2.6554  \n",
      "\n",
      "Fold: 1  Epoch: 482  Training loss = 2.8367  Validation loss = 2.6542  \n",
      "\n",
      "Fold: 1  Epoch: 483  Training loss = 2.8363  Validation loss = 2.6532  \n",
      "\n",
      "Fold: 1  Epoch: 484  Training loss = 2.8359  Validation loss = 2.6522  \n",
      "\n",
      "Fold: 1  Epoch: 485  Training loss = 2.8354  Validation loss = 2.6509  \n",
      "\n",
      "Fold: 1  Epoch: 486  Training loss = 2.8349  Validation loss = 2.6495  \n",
      "\n",
      "Fold: 1  Epoch: 487  Training loss = 2.8344  Validation loss = 2.6482  \n",
      "\n",
      "Fold: 1  Epoch: 488  Training loss = 2.8338  Validation loss = 2.6468  \n",
      "\n",
      "Fold: 1  Epoch: 489  Training loss = 2.8334  Validation loss = 2.6457  \n",
      "\n",
      "Fold: 1  Epoch: 490  Training loss = 2.8332  Validation loss = 2.6450  \n",
      "\n",
      "Fold: 1  Epoch: 491  Training loss = 2.8327  Validation loss = 2.6438  \n",
      "\n",
      "Fold: 1  Epoch: 492  Training loss = 2.8323  Validation loss = 2.6428  \n",
      "\n",
      "Fold: 1  Epoch: 493  Training loss = 2.8320  Validation loss = 2.6420  \n",
      "\n",
      "Fold: 1  Epoch: 494  Training loss = 2.8315  Validation loss = 2.6408  \n",
      "\n",
      "Fold: 1  Epoch: 495  Training loss = 2.8312  Validation loss = 2.6400  \n",
      "\n",
      "Fold: 1  Epoch: 496  Training loss = 2.8308  Validation loss = 2.6389  \n",
      "\n",
      "Fold: 1  Epoch: 497  Training loss = 2.8304  Validation loss = 2.6377  \n",
      "\n",
      "Fold: 1  Epoch: 498  Training loss = 2.8301  Validation loss = 2.6370  \n",
      "\n",
      "Fold: 1  Epoch: 499  Training loss = 2.8297  Validation loss = 2.6359  \n",
      "\n",
      "Fold: 1  Epoch: 500  Training loss = 2.8294  Validation loss = 2.6353  \n",
      "\n",
      "Check model:  Fold: 1  Optimal epoch: 500  \n",
      "\n",
      "Fold: 2  Epoch: 1  Training loss = 2.7648  Validation loss = 2.8109  \n",
      "\n",
      "Fold: 2  Epoch: 2  Training loss = 2.7643  Validation loss = 2.8100  \n",
      "\n",
      "Fold: 2  Epoch: 3  Training loss = 2.7636  Validation loss = 2.8087  \n",
      "\n",
      "Fold: 2  Epoch: 4  Training loss = 2.7632  Validation loss = 2.8077  \n",
      "\n",
      "Fold: 2  Epoch: 5  Training loss = 2.7625  Validation loss = 2.8065  \n",
      "\n",
      "Fold: 2  Epoch: 6  Training loss = 2.7620  Validation loss = 2.8055  \n",
      "\n",
      "Fold: 2  Epoch: 7  Training loss = 2.7615  Validation loss = 2.8047  \n",
      "\n",
      "Fold: 2  Epoch: 8  Training loss = 2.7611  Validation loss = 2.8038  \n",
      "\n",
      "Fold: 2  Epoch: 9  Training loss = 2.7603  Validation loss = 2.8024  \n",
      "\n",
      "Fold: 2  Epoch: 10  Training loss = 2.7598  Validation loss = 2.8011  \n",
      "\n",
      "Fold: 2  Epoch: 11  Training loss = 2.7594  Validation loss = 2.8005  \n",
      "\n",
      "Fold: 2  Epoch: 12  Training loss = 2.7586  Validation loss = 2.7989  \n",
      "\n",
      "Fold: 2  Epoch: 13  Training loss = 2.7581  Validation loss = 2.7977  \n",
      "\n",
      "Fold: 2  Epoch: 14  Training loss = 2.7576  Validation loss = 2.7966  \n",
      "\n",
      "Fold: 2  Epoch: 15  Training loss = 2.7573  Validation loss = 2.7959  \n",
      "\n",
      "Fold: 2  Epoch: 16  Training loss = 2.7567  Validation loss = 2.7948  \n",
      "\n",
      "Fold: 2  Epoch: 17  Training loss = 2.7562  Validation loss = 2.7939  \n",
      "\n",
      "Fold: 2  Epoch: 18  Training loss = 2.7558  Validation loss = 2.7932  \n",
      "\n",
      "Fold: 2  Epoch: 19  Training loss = 2.7554  Validation loss = 2.7922  \n",
      "\n",
      "Fold: 2  Epoch: 20  Training loss = 2.7549  Validation loss = 2.7911  \n",
      "\n",
      "Fold: 2  Epoch: 21  Training loss = 2.7545  Validation loss = 2.7904  \n",
      "\n",
      "Fold: 2  Epoch: 22  Training loss = 2.7539  Validation loss = 2.7894  \n",
      "\n",
      "Fold: 2  Epoch: 23  Training loss = 2.7535  Validation loss = 2.7885  \n",
      "\n",
      "Fold: 2  Epoch: 24  Training loss = 2.7530  Validation loss = 2.7875  \n",
      "\n",
      "Fold: 2  Epoch: 25  Training loss = 2.7525  Validation loss = 2.7867  \n",
      "\n",
      "Fold: 2  Epoch: 26  Training loss = 2.7517  Validation loss = 2.7853  \n",
      "\n",
      "Fold: 2  Epoch: 27  Training loss = 2.7511  Validation loss = 2.7842  \n",
      "\n",
      "Fold: 2  Epoch: 28  Training loss = 2.7506  Validation loss = 2.7832  \n",
      "\n",
      "Fold: 2  Epoch: 29  Training loss = 2.7502  Validation loss = 2.7826  \n",
      "\n",
      "Fold: 2  Epoch: 30  Training loss = 2.7496  Validation loss = 2.7813  \n",
      "\n",
      "Fold: 2  Epoch: 31  Training loss = 2.7492  Validation loss = 2.7806  \n",
      "\n",
      "Fold: 2  Epoch: 32  Training loss = 2.7489  Validation loss = 2.7801  \n",
      "\n",
      "Fold: 2  Epoch: 33  Training loss = 2.7481  Validation loss = 2.7787  \n",
      "\n",
      "Fold: 2  Epoch: 34  Training loss = 2.7476  Validation loss = 2.7777  \n",
      "\n",
      "Fold: 2  Epoch: 35  Training loss = 2.7472  Validation loss = 2.7768  \n",
      "\n",
      "Fold: 2  Epoch: 36  Training loss = 2.7464  Validation loss = 2.7754  \n",
      "\n",
      "Fold: 2  Epoch: 37  Training loss = 2.7460  Validation loss = 2.7747  \n",
      "\n",
      "Fold: 2  Epoch: 38  Training loss = 2.7455  Validation loss = 2.7738  \n",
      "\n",
      "Fold: 2  Epoch: 39  Training loss = 2.7449  Validation loss = 2.7725  \n",
      "\n",
      "Fold: 2  Epoch: 40  Training loss = 2.7444  Validation loss = 2.7712  \n",
      "\n",
      "Fold: 2  Epoch: 41  Training loss = 2.7436  Validation loss = 2.7700  \n",
      "\n",
      "Fold: 2  Epoch: 42  Training loss = 2.7432  Validation loss = 2.7694  \n",
      "\n",
      "Fold: 2  Epoch: 43  Training loss = 2.7428  Validation loss = 2.7684  \n",
      "\n",
      "Fold: 2  Epoch: 44  Training loss = 2.7421  Validation loss = 2.7671  \n",
      "\n",
      "Fold: 2  Epoch: 45  Training loss = 2.7418  Validation loss = 2.7663  \n",
      "\n",
      "Fold: 2  Epoch: 46  Training loss = 2.7412  Validation loss = 2.7652  \n",
      "\n",
      "Fold: 2  Epoch: 47  Training loss = 2.7408  Validation loss = 2.7642  \n",
      "\n",
      "Fold: 2  Epoch: 48  Training loss = 2.7406  Validation loss = 2.7637  \n",
      "\n",
      "Fold: 2  Epoch: 49  Training loss = 2.7400  Validation loss = 2.7626  \n",
      "\n",
      "Fold: 2  Epoch: 50  Training loss = 2.7395  Validation loss = 2.7614  \n",
      "\n",
      "Fold: 2  Epoch: 51  Training loss = 2.7390  Validation loss = 2.7603  \n",
      "\n",
      "Fold: 2  Epoch: 52  Training loss = 2.7386  Validation loss = 2.7593  \n",
      "\n",
      "Fold: 2  Epoch: 53  Training loss = 2.7382  Validation loss = 2.7584  \n",
      "\n",
      "Fold: 2  Epoch: 54  Training loss = 2.7378  Validation loss = 2.7575  \n",
      "\n",
      "Fold: 2  Epoch: 55  Training loss = 2.7374  Validation loss = 2.7566  \n",
      "\n",
      "Fold: 2  Epoch: 56  Training loss = 2.7368  Validation loss = 2.7555  \n",
      "\n",
      "Fold: 2  Epoch: 57  Training loss = 2.7364  Validation loss = 2.7545  \n",
      "\n",
      "Fold: 2  Epoch: 58  Training loss = 2.7359  Validation loss = 2.7538  \n",
      "\n",
      "Fold: 2  Epoch: 59  Training loss = 2.7354  Validation loss = 2.7528  \n",
      "\n",
      "Fold: 2  Epoch: 60  Training loss = 2.7347  Validation loss = 2.7510  \n",
      "\n",
      "Fold: 2  Epoch: 61  Training loss = 2.7341  Validation loss = 2.7495  \n",
      "\n",
      "Fold: 2  Epoch: 62  Training loss = 2.7335  Validation loss = 2.7482  \n",
      "\n",
      "Fold: 2  Epoch: 63  Training loss = 2.7327  Validation loss = 2.7467  \n",
      "\n",
      "Fold: 2  Epoch: 64  Training loss = 2.7319  Validation loss = 2.7451  \n",
      "\n",
      "Fold: 2  Epoch: 65  Training loss = 2.7312  Validation loss = 2.7436  \n",
      "\n",
      "Fold: 2  Epoch: 66  Training loss = 2.7305  Validation loss = 2.7423  \n",
      "\n",
      "Fold: 2  Epoch: 67  Training loss = 2.7301  Validation loss = 2.7413  \n",
      "\n",
      "Fold: 2  Epoch: 68  Training loss = 2.7297  Validation loss = 2.7404  \n",
      "\n",
      "Fold: 2  Epoch: 69  Training loss = 2.7289  Validation loss = 2.7387  \n",
      "\n",
      "Fold: 2  Epoch: 70  Training loss = 2.7286  Validation loss = 2.7382  \n",
      "\n",
      "Fold: 2  Epoch: 71  Training loss = 2.7282  Validation loss = 2.7374  \n",
      "\n",
      "Fold: 2  Epoch: 72  Training loss = 2.7274  Validation loss = 2.7357  \n",
      "\n",
      "Fold: 2  Epoch: 73  Training loss = 2.7268  Validation loss = 2.7342  \n",
      "\n",
      "Fold: 2  Epoch: 74  Training loss = 2.7263  Validation loss = 2.7333  \n",
      "\n",
      "Fold: 2  Epoch: 75  Training loss = 2.7258  Validation loss = 2.7326  \n",
      "\n",
      "Fold: 2  Epoch: 76  Training loss = 2.7254  Validation loss = 2.7315  \n",
      "\n",
      "Fold: 2  Epoch: 77  Training loss = 2.7249  Validation loss = 2.7306  \n",
      "\n",
      "Fold: 2  Epoch: 78  Training loss = 2.7245  Validation loss = 2.7298  \n",
      "\n",
      "Fold: 2  Epoch: 79  Training loss = 2.7242  Validation loss = 2.7290  \n",
      "\n",
      "Fold: 2  Epoch: 80  Training loss = 2.7236  Validation loss = 2.7280  \n",
      "\n",
      "Fold: 2  Epoch: 81  Training loss = 2.7232  Validation loss = 2.7271  \n",
      "\n",
      "Fold: 2  Epoch: 82  Training loss = 2.7228  Validation loss = 2.7265  \n",
      "\n",
      "Fold: 2  Epoch: 83  Training loss = 2.7223  Validation loss = 2.7252  \n",
      "\n",
      "Fold: 2  Epoch: 84  Training loss = 2.7217  Validation loss = 2.7242  \n",
      "\n",
      "Fold: 2  Epoch: 85  Training loss = 2.7211  Validation loss = 2.7232  \n",
      "\n",
      "Fold: 2  Epoch: 86  Training loss = 2.7207  Validation loss = 2.7220  \n",
      "\n",
      "Fold: 2  Epoch: 87  Training loss = 2.7202  Validation loss = 2.7210  \n",
      "\n",
      "Fold: 2  Epoch: 88  Training loss = 2.7197  Validation loss = 2.7201  \n",
      "\n",
      "Fold: 2  Epoch: 89  Training loss = 2.7193  Validation loss = 2.7191  \n",
      "\n",
      "Fold: 2  Epoch: 90  Training loss = 2.7188  Validation loss = 2.7182  \n",
      "\n",
      "Fold: 2  Epoch: 91  Training loss = 2.7182  Validation loss = 2.7167  \n",
      "\n",
      "Fold: 2  Epoch: 92  Training loss = 2.7177  Validation loss = 2.7157  \n",
      "\n",
      "Fold: 2  Epoch: 93  Training loss = 2.7172  Validation loss = 2.7146  \n",
      "\n",
      "Fold: 2  Epoch: 94  Training loss = 2.7168  Validation loss = 2.7138  \n",
      "\n",
      "Fold: 2  Epoch: 95  Training loss = 2.7165  Validation loss = 2.7135  \n",
      "\n",
      "Fold: 2  Epoch: 96  Training loss = 2.7158  Validation loss = 2.7123  \n",
      "\n",
      "Fold: 2  Epoch: 97  Training loss = 2.7153  Validation loss = 2.7111  \n",
      "\n",
      "Fold: 2  Epoch: 98  Training loss = 2.7146  Validation loss = 2.7095  \n",
      "\n",
      "Fold: 2  Epoch: 99  Training loss = 2.7139  Validation loss = 2.7079  \n",
      "\n",
      "Fold: 2  Epoch: 100  Training loss = 2.7134  Validation loss = 2.7067  \n",
      "\n",
      "Fold: 2  Epoch: 101  Training loss = 2.7131  Validation loss = 2.7060  \n",
      "\n",
      "Fold: 2  Epoch: 102  Training loss = 2.7128  Validation loss = 2.7051  \n",
      "\n",
      "Fold: 2  Epoch: 103  Training loss = 2.7123  Validation loss = 2.7039  \n",
      "\n",
      "Fold: 2  Epoch: 104  Training loss = 2.7119  Validation loss = 2.7030  \n",
      "\n",
      "Fold: 2  Epoch: 105  Training loss = 2.7112  Validation loss = 2.7017  \n",
      "\n",
      "Fold: 2  Epoch: 106  Training loss = 2.7108  Validation loss = 2.7006  \n",
      "\n",
      "Fold: 2  Epoch: 107  Training loss = 2.7104  Validation loss = 2.6996  \n",
      "\n",
      "Fold: 2  Epoch: 108  Training loss = 2.7100  Validation loss = 2.6988  \n",
      "\n",
      "Fold: 2  Epoch: 109  Training loss = 2.7095  Validation loss = 2.6979  \n",
      "\n",
      "Fold: 2  Epoch: 110  Training loss = 2.7090  Validation loss = 2.6969  \n",
      "\n",
      "Fold: 2  Epoch: 111  Training loss = 2.7086  Validation loss = 2.6958  \n",
      "\n",
      "Fold: 2  Epoch: 112  Training loss = 2.7082  Validation loss = 2.6948  \n",
      "\n",
      "Fold: 2  Epoch: 113  Training loss = 2.7079  Validation loss = 2.6943  \n",
      "\n",
      "Fold: 2  Epoch: 114  Training loss = 2.7073  Validation loss = 2.6932  \n",
      "\n",
      "Fold: 2  Epoch: 115  Training loss = 2.7069  Validation loss = 2.6923  \n",
      "\n",
      "Fold: 2  Epoch: 116  Training loss = 2.7066  Validation loss = 2.6915  \n",
      "\n",
      "Fold: 2  Epoch: 117  Training loss = 2.7062  Validation loss = 2.6909  \n",
      "\n",
      "Fold: 2  Epoch: 118  Training loss = 2.7059  Validation loss = 2.6902  \n",
      "\n",
      "Fold: 2  Epoch: 119  Training loss = 2.7055  Validation loss = 2.6893  \n",
      "\n",
      "Fold: 2  Epoch: 120  Training loss = 2.7052  Validation loss = 2.6886  \n",
      "\n",
      "Fold: 2  Epoch: 121  Training loss = 2.7048  Validation loss = 2.6879  \n",
      "\n",
      "Fold: 2  Epoch: 122  Training loss = 2.7044  Validation loss = 2.6871  \n",
      "\n",
      "Fold: 2  Epoch: 123  Training loss = 2.7038  Validation loss = 2.6857  \n",
      "\n",
      "Fold: 2  Epoch: 124  Training loss = 2.7035  Validation loss = 2.6848  \n",
      "\n",
      "Fold: 2  Epoch: 125  Training loss = 2.7030  Validation loss = 2.6837  \n",
      "\n",
      "Fold: 2  Epoch: 126  Training loss = 2.7026  Validation loss = 2.6829  \n",
      "\n",
      "Fold: 2  Epoch: 127  Training loss = 2.7023  Validation loss = 2.6824  \n",
      "\n",
      "Fold: 2  Epoch: 128  Training loss = 2.7019  Validation loss = 2.6814  \n",
      "\n",
      "Fold: 2  Epoch: 129  Training loss = 2.7013  Validation loss = 2.6803  \n",
      "\n",
      "Fold: 2  Epoch: 130  Training loss = 2.7008  Validation loss = 2.6791  \n",
      "\n",
      "Fold: 2  Epoch: 131  Training loss = 2.7004  Validation loss = 2.6781  \n",
      "\n",
      "Fold: 2  Epoch: 132  Training loss = 2.7000  Validation loss = 2.6771  \n",
      "\n",
      "Fold: 2  Epoch: 133  Training loss = 2.6997  Validation loss = 2.6762  \n",
      "\n",
      "Fold: 2  Epoch: 134  Training loss = 2.6993  Validation loss = 2.6754  \n",
      "\n",
      "Fold: 2  Epoch: 135  Training loss = 2.6988  Validation loss = 2.6743  \n",
      "\n",
      "Fold: 2  Epoch: 136  Training loss = 2.6983  Validation loss = 2.6733  \n",
      "\n",
      "Fold: 2  Epoch: 137  Training loss = 2.6978  Validation loss = 2.6722  \n",
      "\n",
      "Fold: 2  Epoch: 138  Training loss = 2.6974  Validation loss = 2.6715  \n",
      "\n",
      "Fold: 2  Epoch: 139  Training loss = 2.6970  Validation loss = 2.6703  \n",
      "\n",
      "Fold: 2  Epoch: 140  Training loss = 2.6964  Validation loss = 2.6690  \n",
      "\n",
      "Fold: 2  Epoch: 141  Training loss = 2.6959  Validation loss = 2.6675  \n",
      "\n",
      "Fold: 2  Epoch: 142  Training loss = 2.6953  Validation loss = 2.6665  \n",
      "\n",
      "Fold: 2  Epoch: 143  Training loss = 2.6949  Validation loss = 2.6657  \n",
      "\n",
      "Fold: 2  Epoch: 144  Training loss = 2.6945  Validation loss = 2.6647  \n",
      "\n",
      "Fold: 2  Epoch: 145  Training loss = 2.6943  Validation loss = 2.6642  \n",
      "\n",
      "Fold: 2  Epoch: 146  Training loss = 2.6938  Validation loss = 2.6631  \n",
      "\n",
      "Fold: 2  Epoch: 147  Training loss = 2.6935  Validation loss = 2.6624  \n",
      "\n",
      "Fold: 2  Epoch: 148  Training loss = 2.6932  Validation loss = 2.6618  \n",
      "\n",
      "Fold: 2  Epoch: 149  Training loss = 2.6928  Validation loss = 2.6607  \n",
      "\n",
      "Fold: 2  Epoch: 150  Training loss = 2.6925  Validation loss = 2.6599  \n",
      "\n",
      "Fold: 2  Epoch: 151  Training loss = 2.6920  Validation loss = 2.6590  \n",
      "\n",
      "Fold: 2  Epoch: 152  Training loss = 2.6918  Validation loss = 2.6587  \n",
      "\n",
      "Fold: 2  Epoch: 153  Training loss = 2.6911  Validation loss = 2.6573  \n",
      "\n",
      "Fold: 2  Epoch: 154  Training loss = 2.6907  Validation loss = 2.6562  \n",
      "\n",
      "Fold: 2  Epoch: 155  Training loss = 2.6901  Validation loss = 2.6551  \n",
      "\n",
      "Fold: 2  Epoch: 156  Training loss = 2.6899  Validation loss = 2.6544  \n",
      "\n",
      "Fold: 2  Epoch: 157  Training loss = 2.6895  Validation loss = 2.6538  \n",
      "\n",
      "Fold: 2  Epoch: 158  Training loss = 2.6893  Validation loss = 2.6531  \n",
      "\n",
      "Fold: 2  Epoch: 159  Training loss = 2.6885  Validation loss = 2.6518  \n",
      "\n",
      "Fold: 2  Epoch: 160  Training loss = 2.6883  Validation loss = 2.6512  \n",
      "\n",
      "Fold: 2  Epoch: 161  Training loss = 2.6880  Validation loss = 2.6505  \n",
      "\n",
      "Fold: 2  Epoch: 162  Training loss = 2.6878  Validation loss = 2.6500  \n",
      "\n",
      "Fold: 2  Epoch: 163  Training loss = 2.6873  Validation loss = 2.6489  \n",
      "\n",
      "Fold: 2  Epoch: 164  Training loss = 2.6867  Validation loss = 2.6476  \n",
      "\n",
      "Fold: 2  Epoch: 165  Training loss = 2.6861  Validation loss = 2.6462  \n",
      "\n",
      "Fold: 2  Epoch: 166  Training loss = 2.6855  Validation loss = 2.6452  \n",
      "\n",
      "Fold: 2  Epoch: 167  Training loss = 2.6852  Validation loss = 2.6441  \n",
      "\n",
      "Fold: 2  Epoch: 168  Training loss = 2.6847  Validation loss = 2.6430  \n",
      "\n",
      "Fold: 2  Epoch: 169  Training loss = 2.6842  Validation loss = 2.6420  \n",
      "\n",
      "Fold: 2  Epoch: 170  Training loss = 2.6837  Validation loss = 2.6405  \n",
      "\n",
      "Fold: 2  Epoch: 171  Training loss = 2.6832  Validation loss = 2.6394  \n",
      "\n",
      "Fold: 2  Epoch: 172  Training loss = 2.6830  Validation loss = 2.6389  \n",
      "\n",
      "Fold: 2  Epoch: 173  Training loss = 2.6827  Validation loss = 2.6380  \n",
      "\n",
      "Fold: 2  Epoch: 174  Training loss = 2.6823  Validation loss = 2.6372  \n",
      "\n",
      "Fold: 2  Epoch: 175  Training loss = 2.6821  Validation loss = 2.6367  \n",
      "\n",
      "Fold: 2  Epoch: 176  Training loss = 2.6815  Validation loss = 2.6358  \n",
      "\n",
      "Fold: 2  Epoch: 177  Training loss = 2.6812  Validation loss = 2.6352  \n",
      "\n",
      "Fold: 2  Epoch: 178  Training loss = 2.6807  Validation loss = 2.6342  \n",
      "\n",
      "Fold: 2  Epoch: 179  Training loss = 2.6805  Validation loss = 2.6338  \n",
      "\n",
      "Fold: 2  Epoch: 180  Training loss = 2.6801  Validation loss = 2.6331  \n",
      "\n",
      "Fold: 2  Epoch: 181  Training loss = 2.6797  Validation loss = 2.6316  \n",
      "\n",
      "Fold: 2  Epoch: 182  Training loss = 2.6794  Validation loss = 2.6309  \n",
      "\n",
      "Fold: 2  Epoch: 183  Training loss = 2.6790  Validation loss = 2.6298  \n",
      "\n",
      "Fold: 2  Epoch: 184  Training loss = 2.6785  Validation loss = 2.6288  \n",
      "\n",
      "Fold: 2  Epoch: 185  Training loss = 2.6783  Validation loss = 2.6281  \n",
      "\n",
      "Fold: 2  Epoch: 186  Training loss = 2.6780  Validation loss = 2.6278  \n",
      "\n",
      "Fold: 2  Epoch: 187  Training loss = 2.6777  Validation loss = 2.6272  \n",
      "\n",
      "Fold: 2  Epoch: 188  Training loss = 2.6771  Validation loss = 2.6256  \n",
      "\n",
      "Fold: 2  Epoch: 189  Training loss = 2.6768  Validation loss = 2.6249  \n",
      "\n",
      "Fold: 2  Epoch: 190  Training loss = 2.6761  Validation loss = 2.6233  \n",
      "\n",
      "Fold: 2  Epoch: 191  Training loss = 2.6757  Validation loss = 2.6223  \n",
      "\n",
      "Fold: 2  Epoch: 192  Training loss = 2.6754  Validation loss = 2.6215  \n",
      "\n",
      "Fold: 2  Epoch: 193  Training loss = 2.6749  Validation loss = 2.6201  \n",
      "\n",
      "Fold: 2  Epoch: 194  Training loss = 2.6744  Validation loss = 2.6191  \n",
      "\n",
      "Fold: 2  Epoch: 195  Training loss = 2.6742  Validation loss = 2.6184  \n",
      "\n",
      "Fold: 2  Epoch: 196  Training loss = 2.6737  Validation loss = 2.6173  \n",
      "\n",
      "Fold: 2  Epoch: 197  Training loss = 2.6736  Validation loss = 2.6169  \n",
      "\n",
      "Fold: 2  Epoch: 198  Training loss = 2.6729  Validation loss = 2.6157  \n",
      "\n",
      "Fold: 2  Epoch: 199  Training loss = 2.6725  Validation loss = 2.6150  \n",
      "\n",
      "Fold: 2  Epoch: 200  Training loss = 2.6721  Validation loss = 2.6138  \n",
      "\n",
      "Fold: 2  Epoch: 201  Training loss = 2.6719  Validation loss = 2.6134  \n",
      "\n",
      "Fold: 2  Epoch: 202  Training loss = 2.6715  Validation loss = 2.6125  \n",
      "\n",
      "Fold: 2  Epoch: 203  Training loss = 2.6708  Validation loss = 2.6110  \n",
      "\n",
      "Fold: 2  Epoch: 204  Training loss = 2.6705  Validation loss = 2.6101  \n",
      "\n",
      "Fold: 2  Epoch: 205  Training loss = 2.6701  Validation loss = 2.6089  \n",
      "\n",
      "Fold: 2  Epoch: 206  Training loss = 2.6697  Validation loss = 2.6076  \n",
      "\n",
      "Fold: 2  Epoch: 207  Training loss = 2.6693  Validation loss = 2.6067  \n",
      "\n",
      "Fold: 2  Epoch: 208  Training loss = 2.6688  Validation loss = 2.6058  \n",
      "\n",
      "Fold: 2  Epoch: 209  Training loss = 2.6685  Validation loss = 2.6052  \n",
      "\n",
      "Fold: 2  Epoch: 210  Training loss = 2.6679  Validation loss = 2.6035  \n",
      "\n",
      "Fold: 2  Epoch: 211  Training loss = 2.6676  Validation loss = 2.6024  \n",
      "\n",
      "Fold: 2  Epoch: 212  Training loss = 2.6674  Validation loss = 2.6019  \n",
      "\n",
      "Fold: 2  Epoch: 213  Training loss = 2.6670  Validation loss = 2.6010  \n",
      "\n",
      "Fold: 2  Epoch: 214  Training loss = 2.6668  Validation loss = 2.6004  \n",
      "\n",
      "Fold: 2  Epoch: 215  Training loss = 2.6664  Validation loss = 2.5993  \n",
      "\n",
      "Fold: 2  Epoch: 216  Training loss = 2.6661  Validation loss = 2.5986  \n",
      "\n",
      "Fold: 2  Epoch: 217  Training loss = 2.6658  Validation loss = 2.5978  \n",
      "\n",
      "Fold: 2  Epoch: 218  Training loss = 2.6654  Validation loss = 2.5967  \n",
      "\n",
      "Fold: 2  Epoch: 219  Training loss = 2.6651  Validation loss = 2.5958  \n",
      "\n",
      "Fold: 2  Epoch: 220  Training loss = 2.6648  Validation loss = 2.5950  \n",
      "\n",
      "Fold: 2  Epoch: 221  Training loss = 2.6644  Validation loss = 2.5940  \n",
      "\n",
      "Fold: 2  Epoch: 222  Training loss = 2.6640  Validation loss = 2.5930  \n",
      "\n",
      "Fold: 2  Epoch: 223  Training loss = 2.6636  Validation loss = 2.5920  \n",
      "\n",
      "Fold: 2  Epoch: 224  Training loss = 2.6632  Validation loss = 2.5910  \n",
      "\n",
      "Fold: 2  Epoch: 225  Training loss = 2.6631  Validation loss = 2.5908  \n",
      "\n",
      "Fold: 2  Epoch: 226  Training loss = 2.6627  Validation loss = 2.5901  \n",
      "\n",
      "Fold: 2  Epoch: 227  Training loss = 2.6621  Validation loss = 2.5890  \n",
      "\n",
      "Fold: 2  Epoch: 228  Training loss = 2.6618  Validation loss = 2.5884  \n",
      "\n",
      "Fold: 2  Epoch: 229  Training loss = 2.6615  Validation loss = 2.5875  \n",
      "\n",
      "Fold: 2  Epoch: 230  Training loss = 2.6612  Validation loss = 2.5865  \n",
      "\n",
      "Fold: 2  Epoch: 231  Training loss = 2.6606  Validation loss = 2.5854  \n",
      "\n",
      "Fold: 2  Epoch: 232  Training loss = 2.6604  Validation loss = 2.5848  \n",
      "\n",
      "Fold: 2  Epoch: 233  Training loss = 2.6598  Validation loss = 2.5835  \n",
      "\n",
      "Fold: 2  Epoch: 234  Training loss = 2.6595  Validation loss = 2.5825  \n",
      "\n",
      "Fold: 2  Epoch: 235  Training loss = 2.6589  Validation loss = 2.5810  \n",
      "\n",
      "Fold: 2  Epoch: 236  Training loss = 2.6586  Validation loss = 2.5803  \n",
      "\n",
      "Fold: 2  Epoch: 237  Training loss = 2.6582  Validation loss = 2.5794  \n",
      "\n",
      "Fold: 2  Epoch: 238  Training loss = 2.6578  Validation loss = 2.5779  \n",
      "\n",
      "Fold: 2  Epoch: 239  Training loss = 2.6575  Validation loss = 2.5771  \n",
      "\n",
      "Fold: 2  Epoch: 240  Training loss = 2.6571  Validation loss = 2.5761  \n",
      "\n",
      "Fold: 2  Epoch: 241  Training loss = 2.6568  Validation loss = 2.5757  \n",
      "\n",
      "Fold: 2  Epoch: 242  Training loss = 2.6564  Validation loss = 2.5747  \n",
      "\n",
      "Fold: 2  Epoch: 243  Training loss = 2.6557  Validation loss = 2.5733  \n",
      "\n",
      "Fold: 2  Epoch: 244  Training loss = 2.6556  Validation loss = 2.5729  \n",
      "\n",
      "Fold: 2  Epoch: 245  Training loss = 2.6554  Validation loss = 2.5723  \n",
      "\n",
      "Fold: 2  Epoch: 246  Training loss = 2.6549  Validation loss = 2.5712  \n",
      "\n",
      "Fold: 2  Epoch: 247  Training loss = 2.6545  Validation loss = 2.5701  \n",
      "\n",
      "Fold: 2  Epoch: 248  Training loss = 2.6538  Validation loss = 2.5684  \n",
      "\n",
      "Fold: 2  Epoch: 249  Training loss = 2.6536  Validation loss = 2.5678  \n",
      "\n",
      "Fold: 2  Epoch: 250  Training loss = 2.6534  Validation loss = 2.5675  \n",
      "\n",
      "Fold: 2  Epoch: 251  Training loss = 2.6533  Validation loss = 2.5671  \n",
      "\n",
      "Fold: 2  Epoch: 252  Training loss = 2.6529  Validation loss = 2.5659  \n",
      "\n",
      "Fold: 2  Epoch: 253  Training loss = 2.6524  Validation loss = 2.5647  \n",
      "\n",
      "Fold: 2  Epoch: 254  Training loss = 2.6520  Validation loss = 2.5636  \n",
      "\n",
      "Fold: 2  Epoch: 255  Training loss = 2.6513  Validation loss = 2.5620  \n",
      "\n",
      "Fold: 2  Epoch: 256  Training loss = 2.6509  Validation loss = 2.5610  \n",
      "\n",
      "Fold: 2  Epoch: 257  Training loss = 2.6506  Validation loss = 2.5602  \n",
      "\n",
      "Fold: 2  Epoch: 258  Training loss = 2.6503  Validation loss = 2.5592  \n",
      "\n",
      "Fold: 2  Epoch: 259  Training loss = 2.6500  Validation loss = 2.5584  \n",
      "\n",
      "Fold: 2  Epoch: 260  Training loss = 2.6498  Validation loss = 2.5578  \n",
      "\n",
      "Fold: 2  Epoch: 261  Training loss = 2.6495  Validation loss = 2.5570  \n",
      "\n",
      "Fold: 2  Epoch: 262  Training loss = 2.6491  Validation loss = 2.5562  \n",
      "\n",
      "Fold: 2  Epoch: 263  Training loss = 2.6489  Validation loss = 2.5554  \n",
      "\n",
      "Fold: 2  Epoch: 264  Training loss = 2.6486  Validation loss = 2.5545  \n",
      "\n",
      "Fold: 2  Epoch: 265  Training loss = 2.6483  Validation loss = 2.5537  \n",
      "\n",
      "Fold: 2  Epoch: 266  Training loss = 2.6479  Validation loss = 2.5528  \n",
      "\n",
      "Fold: 2  Epoch: 267  Training loss = 2.6476  Validation loss = 2.5521  \n",
      "\n",
      "Fold: 2  Epoch: 268  Training loss = 2.6475  Validation loss = 2.5517  \n",
      "\n",
      "Fold: 2  Epoch: 269  Training loss = 2.6469  Validation loss = 2.5507  \n",
      "\n",
      "Fold: 2  Epoch: 270  Training loss = 2.6465  Validation loss = 2.5495  \n",
      "\n",
      "Fold: 2  Epoch: 271  Training loss = 2.6461  Validation loss = 2.5490  \n",
      "\n",
      "Fold: 2  Epoch: 272  Training loss = 2.6457  Validation loss = 2.5483  \n",
      "\n",
      "Fold: 2  Epoch: 273  Training loss = 2.6455  Validation loss = 2.5476  \n",
      "\n",
      "Fold: 2  Epoch: 274  Training loss = 2.6452  Validation loss = 2.5470  \n",
      "\n",
      "Fold: 2  Epoch: 275  Training loss = 2.6450  Validation loss = 2.5463  \n",
      "\n",
      "Fold: 2  Epoch: 276  Training loss = 2.6446  Validation loss = 2.5450  \n",
      "\n",
      "Fold: 2  Epoch: 277  Training loss = 2.6440  Validation loss = 2.5437  \n",
      "\n",
      "Fold: 2  Epoch: 278  Training loss = 2.6437  Validation loss = 2.5430  \n",
      "\n",
      "Fold: 2  Epoch: 279  Training loss = 2.6435  Validation loss = 2.5423  \n",
      "\n",
      "Fold: 2  Epoch: 280  Training loss = 2.6434  Validation loss = 2.5423  \n",
      "\n",
      "Fold: 2  Epoch: 281  Training loss = 2.6430  Validation loss = 2.5412  \n",
      "\n",
      "Fold: 2  Epoch: 282  Training loss = 2.6428  Validation loss = 2.5405  \n",
      "\n",
      "Fold: 2  Epoch: 283  Training loss = 2.6424  Validation loss = 2.5396  \n",
      "\n",
      "Fold: 2  Epoch: 284  Training loss = 2.6420  Validation loss = 2.5386  \n",
      "\n",
      "Fold: 2  Epoch: 285  Training loss = 2.6418  Validation loss = 2.5380  \n",
      "\n",
      "Fold: 2  Epoch: 286  Training loss = 2.6414  Validation loss = 2.5369  \n",
      "\n",
      "Fold: 2  Epoch: 287  Training loss = 2.6411  Validation loss = 2.5360  \n",
      "\n",
      "Fold: 2  Epoch: 288  Training loss = 2.6409  Validation loss = 2.5353  \n",
      "\n",
      "Fold: 2  Epoch: 289  Training loss = 2.6406  Validation loss = 2.5344  \n",
      "\n",
      "Fold: 2  Epoch: 290  Training loss = 2.6403  Validation loss = 2.5337  \n",
      "\n",
      "Fold: 2  Epoch: 291  Training loss = 2.6398  Validation loss = 2.5325  \n",
      "\n",
      "Fold: 2  Epoch: 292  Training loss = 2.6395  Validation loss = 2.5318  \n",
      "\n",
      "Fold: 2  Epoch: 293  Training loss = 2.6392  Validation loss = 2.5309  \n",
      "\n",
      "Fold: 2  Epoch: 294  Training loss = 2.6389  Validation loss = 2.5301  \n",
      "\n",
      "Fold: 2  Epoch: 295  Training loss = 2.6385  Validation loss = 2.5287  \n",
      "\n",
      "Fold: 2  Epoch: 296  Training loss = 2.6381  Validation loss = 2.5278  \n",
      "\n",
      "Fold: 2  Epoch: 297  Training loss = 2.6380  Validation loss = 2.5275  \n",
      "\n",
      "Fold: 2  Epoch: 298  Training loss = 2.6376  Validation loss = 2.5262  \n",
      "\n",
      "Fold: 2  Epoch: 299  Training loss = 2.6370  Validation loss = 2.5249  \n",
      "\n",
      "Fold: 2  Epoch: 300  Training loss = 2.6366  Validation loss = 2.5238  \n",
      "\n",
      "Fold: 2  Epoch: 301  Training loss = 2.6362  Validation loss = 2.5230  \n",
      "\n",
      "Fold: 2  Epoch: 302  Training loss = 2.6359  Validation loss = 2.5222  \n",
      "\n",
      "Fold: 2  Epoch: 303  Training loss = 2.6356  Validation loss = 2.5215  \n",
      "\n",
      "Fold: 2  Epoch: 304  Training loss = 2.6353  Validation loss = 2.5210  \n",
      "\n",
      "Fold: 2  Epoch: 305  Training loss = 2.6349  Validation loss = 2.5199  \n",
      "\n",
      "Fold: 2  Epoch: 306  Training loss = 2.6346  Validation loss = 2.5190  \n",
      "\n",
      "Fold: 2  Epoch: 307  Training loss = 2.6343  Validation loss = 2.5184  \n",
      "\n",
      "Fold: 2  Epoch: 308  Training loss = 2.6339  Validation loss = 2.5178  \n",
      "\n",
      "Fold: 2  Epoch: 309  Training loss = 2.6337  Validation loss = 2.5171  \n",
      "\n",
      "Fold: 2  Epoch: 310  Training loss = 2.6332  Validation loss = 2.5157  \n",
      "\n",
      "Fold: 2  Epoch: 311  Training loss = 2.6328  Validation loss = 2.5144  \n",
      "\n",
      "Fold: 2  Epoch: 312  Training loss = 2.6325  Validation loss = 2.5137  \n",
      "\n",
      "Fold: 2  Epoch: 313  Training loss = 2.6323  Validation loss = 2.5130  \n",
      "\n",
      "Fold: 2  Epoch: 314  Training loss = 2.6318  Validation loss = 2.5121  \n",
      "\n",
      "Fold: 2  Epoch: 315  Training loss = 2.6317  Validation loss = 2.5117  \n",
      "\n",
      "Fold: 2  Epoch: 316  Training loss = 2.6314  Validation loss = 2.5110  \n",
      "\n",
      "Fold: 2  Epoch: 317  Training loss = 2.6311  Validation loss = 2.5101  \n",
      "\n",
      "Fold: 2  Epoch: 318  Training loss = 2.6308  Validation loss = 2.5090  \n",
      "\n",
      "Fold: 2  Epoch: 319  Training loss = 2.6305  Validation loss = 2.5081  \n",
      "\n",
      "Fold: 2  Epoch: 320  Training loss = 2.6302  Validation loss = 2.5070  \n",
      "\n",
      "Fold: 2  Epoch: 321  Training loss = 2.6298  Validation loss = 2.5061  \n",
      "\n",
      "Fold: 2  Epoch: 322  Training loss = 2.6293  Validation loss = 2.5049  \n",
      "\n",
      "Fold: 2  Epoch: 323  Training loss = 2.6291  Validation loss = 2.5045  \n",
      "\n",
      "Fold: 2  Epoch: 324  Training loss = 2.6288  Validation loss = 2.5036  \n",
      "\n",
      "Fold: 2  Epoch: 325  Training loss = 2.6284  Validation loss = 2.5028  \n",
      "\n",
      "Fold: 2  Epoch: 326  Training loss = 2.6280  Validation loss = 2.5017  \n",
      "\n",
      "Fold: 2  Epoch: 327  Training loss = 2.6276  Validation loss = 2.5008  \n",
      "\n",
      "Fold: 2  Epoch: 328  Training loss = 2.6275  Validation loss = 2.5003  \n",
      "\n",
      "Fold: 2  Epoch: 329  Training loss = 2.6273  Validation loss = 2.4998  \n",
      "\n",
      "Fold: 2  Epoch: 330  Training loss = 2.6268  Validation loss = 2.4988  \n",
      "\n",
      "Fold: 2  Epoch: 331  Training loss = 2.6264  Validation loss = 2.4981  \n",
      "\n",
      "Fold: 2  Epoch: 332  Training loss = 2.6259  Validation loss = 2.4969  \n",
      "\n",
      "Fold: 2  Epoch: 333  Training loss = 2.6256  Validation loss = 2.4960  \n",
      "\n",
      "Fold: 2  Epoch: 334  Training loss = 2.6254  Validation loss = 2.4954  \n",
      "\n",
      "Fold: 2  Epoch: 335  Training loss = 2.6251  Validation loss = 2.4947  \n",
      "\n",
      "Fold: 2  Epoch: 336  Training loss = 2.6247  Validation loss = 2.4937  \n",
      "\n",
      "Fold: 2  Epoch: 337  Training loss = 2.6244  Validation loss = 2.4931  \n",
      "\n",
      "Fold: 2  Epoch: 338  Training loss = 2.6242  Validation loss = 2.4925  \n",
      "\n",
      "Fold: 2  Epoch: 339  Training loss = 2.6240  Validation loss = 2.4918  \n",
      "\n",
      "Fold: 2  Epoch: 340  Training loss = 2.6235  Validation loss = 2.4908  \n",
      "\n",
      "Fold: 2  Epoch: 341  Training loss = 2.6232  Validation loss = 2.4899  \n",
      "\n",
      "Fold: 2  Epoch: 342  Training loss = 2.6230  Validation loss = 2.4891  \n",
      "\n",
      "Fold: 2  Epoch: 343  Training loss = 2.6228  Validation loss = 2.4886  \n",
      "\n",
      "Fold: 2  Epoch: 344  Training loss = 2.6225  Validation loss = 2.4877  \n",
      "\n",
      "Fold: 2  Epoch: 345  Training loss = 2.6221  Validation loss = 2.4863  \n",
      "\n",
      "Fold: 2  Epoch: 346  Training loss = 2.6219  Validation loss = 2.4858  \n",
      "\n",
      "Fold: 2  Epoch: 347  Training loss = 2.6216  Validation loss = 2.4849  \n",
      "\n",
      "Fold: 2  Epoch: 348  Training loss = 2.6213  Validation loss = 2.4843  \n",
      "\n",
      "Fold: 2  Epoch: 349  Training loss = 2.6210  Validation loss = 2.4833  \n",
      "\n",
      "Fold: 2  Epoch: 350  Training loss = 2.6206  Validation loss = 2.4825  \n",
      "\n",
      "Fold: 2  Epoch: 351  Training loss = 2.6205  Validation loss = 2.4823  \n",
      "\n",
      "Fold: 2  Epoch: 352  Training loss = 2.6201  Validation loss = 2.4814  \n",
      "\n",
      "Fold: 2  Epoch: 353  Training loss = 2.6200  Validation loss = 2.4810  \n",
      "\n",
      "Fold: 2  Epoch: 354  Training loss = 2.6198  Validation loss = 2.4803  \n",
      "\n",
      "Fold: 2  Epoch: 355  Training loss = 2.6196  Validation loss = 2.4798  \n",
      "\n",
      "Fold: 2  Epoch: 356  Training loss = 2.6195  Validation loss = 2.4793  \n",
      "\n",
      "Fold: 2  Epoch: 357  Training loss = 2.6193  Validation loss = 2.4788  \n",
      "\n",
      "Fold: 2  Epoch: 358  Training loss = 2.6187  Validation loss = 2.4777  \n",
      "\n",
      "Fold: 2  Epoch: 359  Training loss = 2.6184  Validation loss = 2.4768  \n",
      "\n",
      "Fold: 2  Epoch: 360  Training loss = 2.6183  Validation loss = 2.4764  \n",
      "\n",
      "Fold: 2  Epoch: 361  Training loss = 2.6178  Validation loss = 2.4752  \n",
      "\n",
      "Fold: 2  Epoch: 362  Training loss = 2.6176  Validation loss = 2.4746  \n",
      "\n",
      "Fold: 2  Epoch: 363  Training loss = 2.6172  Validation loss = 2.4736  \n",
      "\n",
      "Fold: 2  Epoch: 364  Training loss = 2.6168  Validation loss = 2.4725  \n",
      "\n",
      "Fold: 2  Epoch: 365  Training loss = 2.6164  Validation loss = 2.4714  \n",
      "\n",
      "Fold: 2  Epoch: 366  Training loss = 2.6160  Validation loss = 2.4703  \n",
      "\n",
      "Fold: 2  Epoch: 367  Training loss = 2.6158  Validation loss = 2.4698  \n",
      "\n",
      "Fold: 2  Epoch: 368  Training loss = 2.6155  Validation loss = 2.4692  \n",
      "\n",
      "Fold: 2  Epoch: 369  Training loss = 2.6152  Validation loss = 2.4685  \n",
      "\n",
      "Fold: 2  Epoch: 370  Training loss = 2.6149  Validation loss = 2.4676  \n",
      "\n",
      "Fold: 2  Epoch: 371  Training loss = 2.6145  Validation loss = 2.4665  \n",
      "\n",
      "Fold: 2  Epoch: 372  Training loss = 2.6141  Validation loss = 2.4653  \n",
      "\n",
      "Fold: 2  Epoch: 373  Training loss = 2.6139  Validation loss = 2.4649  \n",
      "\n",
      "Fold: 2  Epoch: 374  Training loss = 2.6134  Validation loss = 2.4638  \n",
      "\n",
      "Fold: 2  Epoch: 375  Training loss = 2.6130  Validation loss = 2.4629  \n",
      "\n",
      "Fold: 2  Epoch: 376  Training loss = 2.6128  Validation loss = 2.4623  \n",
      "\n",
      "Fold: 2  Epoch: 377  Training loss = 2.6127  Validation loss = 2.4619  \n",
      "\n",
      "Fold: 2  Epoch: 378  Training loss = 2.6123  Validation loss = 2.4609  \n",
      "\n",
      "Fold: 2  Epoch: 379  Training loss = 2.6121  Validation loss = 2.4603  \n",
      "\n",
      "Fold: 2  Epoch: 380  Training loss = 2.6116  Validation loss = 2.4592  \n",
      "\n",
      "Fold: 2  Epoch: 381  Training loss = 2.6114  Validation loss = 2.4586  \n",
      "\n",
      "Fold: 2  Epoch: 382  Training loss = 2.6112  Validation loss = 2.4579  \n",
      "\n",
      "Fold: 2  Epoch: 383  Training loss = 2.6109  Validation loss = 2.4568  \n",
      "\n",
      "Fold: 2  Epoch: 384  Training loss = 2.6107  Validation loss = 2.4562  \n",
      "\n",
      "Fold: 2  Epoch: 385  Training loss = 2.6103  Validation loss = 2.4551  \n",
      "\n",
      "Fold: 2  Epoch: 386  Training loss = 2.6101  Validation loss = 2.4543  \n",
      "\n",
      "Fold: 2  Epoch: 387  Training loss = 2.6098  Validation loss = 2.4536  \n",
      "\n",
      "Fold: 2  Epoch: 388  Training loss = 2.6095  Validation loss = 2.4526  \n",
      "\n",
      "Fold: 2  Epoch: 389  Training loss = 2.6094  Validation loss = 2.4522  \n",
      "\n",
      "Fold: 2  Epoch: 390  Training loss = 2.6091  Validation loss = 2.4513  \n",
      "\n",
      "Fold: 2  Epoch: 391  Training loss = 2.6089  Validation loss = 2.4503  \n",
      "\n",
      "Fold: 2  Epoch: 392  Training loss = 2.6088  Validation loss = 2.4500  \n",
      "\n",
      "Fold: 2  Epoch: 393  Training loss = 2.6084  Validation loss = 2.4490  \n",
      "\n",
      "Fold: 2  Epoch: 394  Training loss = 2.6082  Validation loss = 2.4484  \n",
      "\n",
      "Fold: 2  Epoch: 395  Training loss = 2.6079  Validation loss = 2.4478  \n",
      "\n",
      "Fold: 2  Epoch: 396  Training loss = 2.6076  Validation loss = 2.4470  \n",
      "\n",
      "Fold: 2  Epoch: 397  Training loss = 2.6072  Validation loss = 2.4456  \n",
      "\n",
      "Fold: 2  Epoch: 398  Training loss = 2.6070  Validation loss = 2.4448  \n",
      "\n",
      "Fold: 2  Epoch: 399  Training loss = 2.6067  Validation loss = 2.4440  \n",
      "\n",
      "Fold: 2  Epoch: 400  Training loss = 2.6063  Validation loss = 2.4431  \n",
      "\n",
      "Fold: 2  Epoch: 401  Training loss = 2.6059  Validation loss = 2.4422  \n",
      "\n",
      "Fold: 2  Epoch: 402  Training loss = 2.6056  Validation loss = 2.4411  \n",
      "\n",
      "Fold: 2  Epoch: 403  Training loss = 2.6054  Validation loss = 2.4407  \n",
      "\n",
      "Fold: 2  Epoch: 404  Training loss = 2.6050  Validation loss = 2.4397  \n",
      "\n",
      "Fold: 2  Epoch: 405  Training loss = 2.6045  Validation loss = 2.4383  \n",
      "\n",
      "Fold: 2  Epoch: 406  Training loss = 2.6039  Validation loss = 2.4366  \n",
      "\n",
      "Fold: 2  Epoch: 407  Training loss = 2.6037  Validation loss = 2.4359  \n",
      "\n",
      "Fold: 2  Epoch: 408  Training loss = 2.6033  Validation loss = 2.4351  \n",
      "\n",
      "Fold: 2  Epoch: 409  Training loss = 2.6029  Validation loss = 2.4339  \n",
      "\n",
      "Fold: 2  Epoch: 410  Training loss = 2.6026  Validation loss = 2.4331  \n",
      "\n",
      "Fold: 2  Epoch: 411  Training loss = 2.6024  Validation loss = 2.4325  \n",
      "\n",
      "Fold: 2  Epoch: 412  Training loss = 2.6020  Validation loss = 2.4318  \n",
      "\n",
      "Fold: 2  Epoch: 413  Training loss = 2.6017  Validation loss = 2.4308  \n",
      "\n",
      "Fold: 2  Epoch: 414  Training loss = 2.6013  Validation loss = 2.4300  \n",
      "\n",
      "Fold: 2  Epoch: 415  Training loss = 2.6011  Validation loss = 2.4295  \n",
      "\n",
      "Fold: 2  Epoch: 416  Training loss = 2.6010  Validation loss = 2.4290  \n",
      "\n",
      "Fold: 2  Epoch: 417  Training loss = 2.6005  Validation loss = 2.4278  \n",
      "\n",
      "Fold: 2  Epoch: 418  Training loss = 2.6004  Validation loss = 2.4274  \n",
      "\n",
      "Fold: 2  Epoch: 419  Training loss = 2.6001  Validation loss = 2.4267  \n",
      "\n",
      "Fold: 2  Epoch: 420  Training loss = 2.5999  Validation loss = 2.4261  \n",
      "\n",
      "Fold: 2  Epoch: 421  Training loss = 2.5998  Validation loss = 2.4259  \n",
      "\n",
      "Fold: 2  Epoch: 422  Training loss = 2.5993  Validation loss = 2.4249  \n",
      "\n",
      "Fold: 2  Epoch: 423  Training loss = 2.5991  Validation loss = 2.4242  \n",
      "\n",
      "Fold: 2  Epoch: 424  Training loss = 2.5990  Validation loss = 2.4237  \n",
      "\n",
      "Fold: 2  Epoch: 425  Training loss = 2.5986  Validation loss = 2.4229  \n",
      "\n",
      "Fold: 2  Epoch: 426  Training loss = 2.5982  Validation loss = 2.4219  \n",
      "\n",
      "Fold: 2  Epoch: 427  Training loss = 2.5980  Validation loss = 2.4211  \n",
      "\n",
      "Fold: 2  Epoch: 428  Training loss = 2.5979  Validation loss = 2.4206  \n",
      "\n",
      "Fold: 2  Epoch: 429  Training loss = 2.5976  Validation loss = 2.4198  \n",
      "\n",
      "Fold: 2  Epoch: 430  Training loss = 2.5973  Validation loss = 2.4185  \n",
      "\n",
      "Fold: 2  Epoch: 431  Training loss = 2.5970  Validation loss = 2.4179  \n",
      "\n",
      "Fold: 2  Epoch: 432  Training loss = 2.5967  Validation loss = 2.4172  \n",
      "\n",
      "Fold: 2  Epoch: 433  Training loss = 2.5963  Validation loss = 2.4162  \n",
      "\n",
      "Fold: 2  Epoch: 434  Training loss = 2.5960  Validation loss = 2.4153  \n",
      "\n",
      "Fold: 2  Epoch: 435  Training loss = 2.5958  Validation loss = 2.4145  \n",
      "\n",
      "Fold: 2  Epoch: 436  Training loss = 2.5956  Validation loss = 2.4141  \n",
      "\n",
      "Fold: 2  Epoch: 437  Training loss = 2.5955  Validation loss = 2.4137  \n",
      "\n",
      "Fold: 2  Epoch: 438  Training loss = 2.5954  Validation loss = 2.4131  \n",
      "\n",
      "Fold: 2  Epoch: 439  Training loss = 2.5951  Validation loss = 2.4126  \n",
      "\n",
      "Fold: 2  Epoch: 440  Training loss = 2.5949  Validation loss = 2.4121  \n",
      "\n",
      "Fold: 2  Epoch: 441  Training loss = 2.5945  Validation loss = 2.4112  \n",
      "\n",
      "Fold: 2  Epoch: 442  Training loss = 2.5941  Validation loss = 2.4099  \n",
      "\n",
      "Fold: 2  Epoch: 443  Training loss = 2.5940  Validation loss = 2.4095  \n",
      "\n",
      "Fold: 2  Epoch: 444  Training loss = 2.5937  Validation loss = 2.4087  \n",
      "\n",
      "Fold: 2  Epoch: 445  Training loss = 2.5934  Validation loss = 2.4079  \n",
      "\n",
      "Fold: 2  Epoch: 446  Training loss = 2.5931  Validation loss = 2.4071  \n",
      "\n",
      "Fold: 2  Epoch: 447  Training loss = 2.5928  Validation loss = 2.4062  \n",
      "\n",
      "Fold: 2  Epoch: 448  Training loss = 2.5925  Validation loss = 2.4056  \n",
      "\n",
      "Fold: 2  Epoch: 449  Training loss = 2.5923  Validation loss = 2.4051  \n",
      "\n",
      "Fold: 2  Epoch: 450  Training loss = 2.5919  Validation loss = 2.4041  \n",
      "\n",
      "Fold: 2  Epoch: 451  Training loss = 2.5918  Validation loss = 2.4034  \n",
      "\n",
      "Fold: 2  Epoch: 452  Training loss = 2.5917  Validation loss = 2.4032  \n",
      "\n",
      "Fold: 2  Epoch: 453  Training loss = 2.5913  Validation loss = 2.4021  \n",
      "\n",
      "Fold: 2  Epoch: 454  Training loss = 2.5911  Validation loss = 2.4014  \n",
      "\n",
      "Fold: 2  Epoch: 455  Training loss = 2.5907  Validation loss = 2.4001  \n",
      "\n",
      "Fold: 2  Epoch: 456  Training loss = 2.5903  Validation loss = 2.3995  \n",
      "\n",
      "Fold: 2  Epoch: 457  Training loss = 2.5901  Validation loss = 2.3985  \n",
      "\n",
      "Fold: 2  Epoch: 458  Training loss = 2.5898  Validation loss = 2.3975  \n",
      "\n",
      "Fold: 2  Epoch: 459  Training loss = 2.5894  Validation loss = 2.3963  \n",
      "\n",
      "Fold: 2  Epoch: 460  Training loss = 2.5892  Validation loss = 2.3958  \n",
      "\n",
      "Fold: 2  Epoch: 461  Training loss = 2.5890  Validation loss = 2.3951  \n",
      "\n",
      "Fold: 2  Epoch: 462  Training loss = 2.5886  Validation loss = 2.3942  \n",
      "\n",
      "Fold: 2  Epoch: 463  Training loss = 2.5884  Validation loss = 2.3933  \n",
      "\n",
      "Fold: 2  Epoch: 464  Training loss = 2.5883  Validation loss = 2.3929  \n",
      "\n",
      "Fold: 2  Epoch: 465  Training loss = 2.5882  Validation loss = 2.3925  \n",
      "\n",
      "Fold: 2  Epoch: 466  Training loss = 2.5880  Validation loss = 2.3918  \n",
      "\n",
      "Fold: 2  Epoch: 467  Training loss = 2.5875  Validation loss = 2.3909  \n",
      "\n",
      "Fold: 2  Epoch: 468  Training loss = 2.5873  Validation loss = 2.3900  \n",
      "\n",
      "Fold: 2  Epoch: 469  Training loss = 2.5870  Validation loss = 2.3891  \n",
      "\n",
      "Fold: 2  Epoch: 470  Training loss = 2.5868  Validation loss = 2.3890  \n",
      "\n",
      "Fold: 2  Epoch: 471  Training loss = 2.5866  Validation loss = 2.3885  \n",
      "\n",
      "Fold: 2  Epoch: 472  Training loss = 2.5863  Validation loss = 2.3878  \n",
      "\n",
      "Fold: 2  Epoch: 473  Training loss = 2.5862  Validation loss = 2.3875  \n",
      "\n",
      "Fold: 2  Epoch: 474  Training loss = 2.5860  Validation loss = 2.3867  \n",
      "\n",
      "Fold: 2  Epoch: 475  Training loss = 2.5857  Validation loss = 2.3858  \n",
      "\n",
      "Fold: 2  Epoch: 476  Training loss = 2.5855  Validation loss = 2.3850  \n",
      "\n",
      "Fold: 2  Epoch: 477  Training loss = 2.5853  Validation loss = 2.3847  \n",
      "\n",
      "Fold: 2  Epoch: 478  Training loss = 2.5848  Validation loss = 2.3834  \n",
      "\n",
      "Fold: 2  Epoch: 479  Training loss = 2.5846  Validation loss = 2.3828  \n",
      "\n",
      "Fold: 2  Epoch: 480  Training loss = 2.5845  Validation loss = 2.3825  \n",
      "\n",
      "Fold: 2  Epoch: 481  Training loss = 2.5844  Validation loss = 2.3819  \n",
      "\n",
      "Fold: 2  Epoch: 482  Training loss = 2.5843  Validation loss = 2.3814  \n",
      "\n",
      "Fold: 2  Epoch: 483  Training loss = 2.5841  Validation loss = 2.3807  \n",
      "\n",
      "Fold: 2  Epoch: 484  Training loss = 2.5840  Validation loss = 2.3800  \n",
      "\n",
      "Fold: 2  Epoch: 485  Training loss = 2.5838  Validation loss = 2.3794  \n",
      "\n",
      "Fold: 2  Epoch: 486  Training loss = 2.5835  Validation loss = 2.3787  \n",
      "\n",
      "Fold: 2  Epoch: 487  Training loss = 2.5832  Validation loss = 2.3779  \n",
      "\n",
      "Fold: 2  Epoch: 488  Training loss = 2.5830  Validation loss = 2.3773  \n",
      "\n",
      "Fold: 2  Epoch: 489  Training loss = 2.5829  Validation loss = 2.3771  \n",
      "\n",
      "Fold: 2  Epoch: 490  Training loss = 2.5829  Validation loss = 2.3768  \n",
      "\n",
      "Fold: 2  Epoch: 491  Training loss = 2.5828  Validation loss = 2.3763  \n",
      "\n",
      "Fold: 2  Epoch: 492  Training loss = 2.5827  Validation loss = 2.3758  \n",
      "\n",
      "Fold: 2  Epoch: 493  Training loss = 2.5823  Validation loss = 2.3746  \n",
      "\n",
      "Fold: 2  Epoch: 494  Training loss = 2.5820  Validation loss = 2.3742  \n",
      "\n",
      "Fold: 2  Epoch: 495  Training loss = 2.5818  Validation loss = 2.3736  \n",
      "\n",
      "Fold: 2  Epoch: 496  Training loss = 2.5815  Validation loss = 2.3729  \n",
      "\n",
      "Fold: 2  Epoch: 497  Training loss = 2.5813  Validation loss = 2.3720  \n",
      "\n",
      "Fold: 2  Epoch: 498  Training loss = 2.5811  Validation loss = 2.3714  \n",
      "\n",
      "Fold: 2  Epoch: 499  Training loss = 2.5807  Validation loss = 2.3700  \n",
      "\n",
      "Fold: 2  Epoch: 500  Training loss = 2.5805  Validation loss = 2.3697  \n",
      "\n",
      "Check model:  Fold: 2  Optimal epoch: 500  \n",
      "\n",
      "Fold: 3  Epoch: 1  Training loss = 1.5637  Validation loss = 3.8460  \n",
      "\n",
      "Fold: 3  Epoch: 2  Training loss = 1.5636  Validation loss = 3.8455  \n",
      "\n",
      "Fold: 3  Epoch: 3  Training loss = 1.5632  Validation loss = 3.8442  \n",
      "\n",
      "Fold: 3  Epoch: 4  Training loss = 1.5630  Validation loss = 3.8434  \n",
      "\n",
      "Fold: 3  Epoch: 5  Training loss = 1.5628  Validation loss = 3.8427  \n",
      "\n",
      "Fold: 3  Epoch: 6  Training loss = 1.5626  Validation loss = 3.8421  \n",
      "\n",
      "Fold: 3  Epoch: 7  Training loss = 1.5622  Validation loss = 3.8407  \n",
      "\n",
      "Fold: 3  Epoch: 8  Training loss = 1.5621  Validation loss = 3.8403  \n",
      "\n",
      "Fold: 3  Epoch: 9  Training loss = 1.5619  Validation loss = 3.8395  \n",
      "\n",
      "Fold: 3  Epoch: 10  Training loss = 1.5615  Validation loss = 3.8379  \n",
      "\n",
      "Fold: 3  Epoch: 11  Training loss = 1.5613  Validation loss = 3.8373  \n",
      "\n",
      "Fold: 3  Epoch: 12  Training loss = 1.5610  Validation loss = 3.8361  \n",
      "\n",
      "Fold: 3  Epoch: 13  Training loss = 1.5607  Validation loss = 3.8351  \n",
      "\n",
      "Fold: 3  Epoch: 14  Training loss = 1.5605  Validation loss = 3.8344  \n",
      "\n",
      "Fold: 3  Epoch: 15  Training loss = 1.5602  Validation loss = 3.8333  \n",
      "\n",
      "Fold: 3  Epoch: 16  Training loss = 1.5600  Validation loss = 3.8324  \n",
      "\n",
      "Fold: 3  Epoch: 17  Training loss = 1.5598  Validation loss = 3.8315  \n",
      "\n",
      "Fold: 3  Epoch: 18  Training loss = 1.5596  Validation loss = 3.8307  \n",
      "\n",
      "Fold: 3  Epoch: 19  Training loss = 1.5594  Validation loss = 3.8304  \n",
      "\n",
      "Fold: 3  Epoch: 20  Training loss = 1.5593  Validation loss = 3.8297  \n",
      "\n",
      "Fold: 3  Epoch: 21  Training loss = 1.5590  Validation loss = 3.8291  \n",
      "\n",
      "Fold: 3  Epoch: 22  Training loss = 1.5589  Validation loss = 3.8286  \n",
      "\n",
      "Fold: 3  Epoch: 23  Training loss = 1.5586  Validation loss = 3.8276  \n",
      "\n",
      "Fold: 3  Epoch: 24  Training loss = 1.5584  Validation loss = 3.8269  \n",
      "\n",
      "Fold: 3  Epoch: 25  Training loss = 1.5581  Validation loss = 3.8258  \n",
      "\n",
      "Fold: 3  Epoch: 26  Training loss = 1.5579  Validation loss = 3.8249  \n",
      "\n",
      "Fold: 3  Epoch: 27  Training loss = 1.5577  Validation loss = 3.8243  \n",
      "\n",
      "Fold: 3  Epoch: 28  Training loss = 1.5575  Validation loss = 3.8236  \n",
      "\n",
      "Fold: 3  Epoch: 29  Training loss = 1.5573  Validation loss = 3.8227  \n",
      "\n",
      "Fold: 3  Epoch: 30  Training loss = 1.5572  Validation loss = 3.8223  \n",
      "\n",
      "Fold: 3  Epoch: 31  Training loss = 1.5570  Validation loss = 3.8219  \n",
      "\n",
      "Fold: 3  Epoch: 32  Training loss = 1.5569  Validation loss = 3.8214  \n",
      "\n",
      "Fold: 3  Epoch: 33  Training loss = 1.5567  Validation loss = 3.8203  \n",
      "\n",
      "Fold: 3  Epoch: 34  Training loss = 1.5564  Validation loss = 3.8195  \n",
      "\n",
      "Fold: 3  Epoch: 35  Training loss = 1.5563  Validation loss = 3.8193  \n",
      "\n",
      "Fold: 3  Epoch: 36  Training loss = 1.5562  Validation loss = 3.8188  \n",
      "\n",
      "Fold: 3  Epoch: 37  Training loss = 1.5561  Validation loss = 3.8185  \n",
      "\n",
      "Fold: 3  Epoch: 38  Training loss = 1.5559  Validation loss = 3.8177  \n",
      "\n",
      "Fold: 3  Epoch: 39  Training loss = 1.5555  Validation loss = 3.8162  \n",
      "\n",
      "Fold: 3  Epoch: 40  Training loss = 1.5553  Validation loss = 3.8153  \n",
      "\n",
      "Fold: 3  Epoch: 41  Training loss = 1.5551  Validation loss = 3.8146  \n",
      "\n",
      "Fold: 3  Epoch: 42  Training loss = 1.5549  Validation loss = 3.8138  \n",
      "\n",
      "Fold: 3  Epoch: 43  Training loss = 1.5548  Validation loss = 3.8134  \n",
      "\n",
      "Fold: 3  Epoch: 44  Training loss = 1.5547  Validation loss = 3.8129  \n",
      "\n",
      "Fold: 3  Epoch: 45  Training loss = 1.5544  Validation loss = 3.8120  \n",
      "\n",
      "Fold: 3  Epoch: 46  Training loss = 1.5543  Validation loss = 3.8116  \n",
      "\n",
      "Fold: 3  Epoch: 47  Training loss = 1.5542  Validation loss = 3.8113  \n",
      "\n",
      "Fold: 3  Epoch: 48  Training loss = 1.5541  Validation loss = 3.8106  \n",
      "\n",
      "Fold: 3  Epoch: 49  Training loss = 1.5537  Validation loss = 3.8093  \n",
      "\n",
      "Fold: 3  Epoch: 50  Training loss = 1.5535  Validation loss = 3.8085  \n",
      "\n",
      "Fold: 3  Epoch: 51  Training loss = 1.5534  Validation loss = 3.8081  \n",
      "\n",
      "Fold: 3  Epoch: 52  Training loss = 1.5533  Validation loss = 3.8073  \n",
      "\n",
      "Fold: 3  Epoch: 53  Training loss = 1.5531  Validation loss = 3.8066  \n",
      "\n",
      "Fold: 3  Epoch: 54  Training loss = 1.5529  Validation loss = 3.8055  \n",
      "\n",
      "Fold: 3  Epoch: 55  Training loss = 1.5525  Validation loss = 3.8040  \n",
      "\n",
      "Fold: 3  Epoch: 56  Training loss = 1.5524  Validation loss = 3.8036  \n",
      "\n",
      "Fold: 3  Epoch: 57  Training loss = 1.5523  Validation loss = 3.8032  \n",
      "\n",
      "Fold: 3  Epoch: 58  Training loss = 1.5521  Validation loss = 3.8026  \n",
      "\n",
      "Fold: 3  Epoch: 59  Training loss = 1.5519  Validation loss = 3.8018  \n",
      "\n",
      "Fold: 3  Epoch: 60  Training loss = 1.5516  Validation loss = 3.8004  \n",
      "\n",
      "Fold: 3  Epoch: 61  Training loss = 1.5513  Validation loss = 3.7995  \n",
      "\n",
      "Fold: 3  Epoch: 62  Training loss = 1.5512  Validation loss = 3.7989  \n",
      "\n",
      "Fold: 3  Epoch: 63  Training loss = 1.5510  Validation loss = 3.7984  \n",
      "\n",
      "Fold: 3  Epoch: 64  Training loss = 1.5508  Validation loss = 3.7975  \n",
      "\n",
      "Fold: 3  Epoch: 65  Training loss = 1.5505  Validation loss = 3.7964  \n",
      "\n",
      "Fold: 3  Epoch: 66  Training loss = 1.5503  Validation loss = 3.7956  \n",
      "\n",
      "Fold: 3  Epoch: 67  Training loss = 1.5501  Validation loss = 3.7945  \n",
      "\n",
      "Fold: 3  Epoch: 68  Training loss = 1.5500  Validation loss = 3.7940  \n",
      "\n",
      "Fold: 3  Epoch: 69  Training loss = 1.5499  Validation loss = 3.7935  \n",
      "\n",
      "Fold: 3  Epoch: 70  Training loss = 1.5496  Validation loss = 3.7924  \n",
      "\n",
      "Fold: 3  Epoch: 71  Training loss = 1.5495  Validation loss = 3.7917  \n",
      "\n",
      "Fold: 3  Epoch: 72  Training loss = 1.5493  Validation loss = 3.7909  \n",
      "\n",
      "Fold: 3  Epoch: 73  Training loss = 1.5490  Validation loss = 3.7896  \n",
      "\n",
      "Fold: 3  Epoch: 74  Training loss = 1.5488  Validation loss = 3.7887  \n",
      "\n",
      "Fold: 3  Epoch: 75  Training loss = 1.5486  Validation loss = 3.7878  \n",
      "\n",
      "Fold: 3  Epoch: 76  Training loss = 1.5484  Validation loss = 3.7871  \n",
      "\n",
      "Fold: 3  Epoch: 77  Training loss = 1.5482  Validation loss = 3.7862  \n",
      "\n",
      "Fold: 3  Epoch: 78  Training loss = 1.5481  Validation loss = 3.7856  \n",
      "\n",
      "Fold: 3  Epoch: 79  Training loss = 1.5478  Validation loss = 3.7846  \n",
      "\n",
      "Fold: 3  Epoch: 80  Training loss = 1.5476  Validation loss = 3.7836  \n",
      "\n",
      "Fold: 3  Epoch: 81  Training loss = 1.5475  Validation loss = 3.7829  \n",
      "\n",
      "Fold: 3  Epoch: 82  Training loss = 1.5474  Validation loss = 3.7826  \n",
      "\n",
      "Fold: 3  Epoch: 83  Training loss = 1.5471  Validation loss = 3.7814  \n",
      "\n",
      "Fold: 3  Epoch: 84  Training loss = 1.5470  Validation loss = 3.7810  \n",
      "\n",
      "Fold: 3  Epoch: 85  Training loss = 1.5468  Validation loss = 3.7800  \n",
      "\n",
      "Fold: 3  Epoch: 86  Training loss = 1.5466  Validation loss = 3.7793  \n",
      "\n",
      "Fold: 3  Epoch: 87  Training loss = 1.5464  Validation loss = 3.7787  \n",
      "\n",
      "Fold: 3  Epoch: 88  Training loss = 1.5464  Validation loss = 3.7786  \n",
      "\n",
      "Fold: 3  Epoch: 89  Training loss = 1.5462  Validation loss = 3.7776  \n",
      "\n",
      "Fold: 3  Epoch: 90  Training loss = 1.5459  Validation loss = 3.7767  \n",
      "\n",
      "Fold: 3  Epoch: 91  Training loss = 1.5458  Validation loss = 3.7759  \n",
      "\n",
      "Fold: 3  Epoch: 92  Training loss = 1.5456  Validation loss = 3.7754  \n",
      "\n",
      "Fold: 3  Epoch: 93  Training loss = 1.5454  Validation loss = 3.7747  \n",
      "\n",
      "Fold: 3  Epoch: 94  Training loss = 1.5452  Validation loss = 3.7739  \n",
      "\n",
      "Fold: 3  Epoch: 95  Training loss = 1.5452  Validation loss = 3.7735  \n",
      "\n",
      "Fold: 3  Epoch: 96  Training loss = 1.5449  Validation loss = 3.7723  \n",
      "\n",
      "Fold: 3  Epoch: 97  Training loss = 1.5447  Validation loss = 3.7715  \n",
      "\n",
      "Fold: 3  Epoch: 98  Training loss = 1.5445  Validation loss = 3.7703  \n",
      "\n",
      "Fold: 3  Epoch: 99  Training loss = 1.5443  Validation loss = 3.7696  \n",
      "\n",
      "Fold: 3  Epoch: 100  Training loss = 1.5440  Validation loss = 3.7683  \n",
      "\n",
      "Fold: 3  Epoch: 101  Training loss = 1.5439  Validation loss = 3.7675  \n",
      "\n",
      "Fold: 3  Epoch: 102  Training loss = 1.5437  Validation loss = 3.7665  \n",
      "\n",
      "Fold: 3  Epoch: 103  Training loss = 1.5435  Validation loss = 3.7654  \n",
      "\n",
      "Fold: 3  Epoch: 104  Training loss = 1.5433  Validation loss = 3.7647  \n",
      "\n",
      "Fold: 3  Epoch: 105  Training loss = 1.5432  Validation loss = 3.7643  \n",
      "\n",
      "Fold: 3  Epoch: 106  Training loss = 1.5429  Validation loss = 3.7627  \n",
      "\n",
      "Fold: 3  Epoch: 107  Training loss = 1.5428  Validation loss = 3.7622  \n",
      "\n",
      "Fold: 3  Epoch: 108  Training loss = 1.5425  Validation loss = 3.7612  \n",
      "\n",
      "Fold: 3  Epoch: 109  Training loss = 1.5424  Validation loss = 3.7607  \n",
      "\n",
      "Fold: 3  Epoch: 110  Training loss = 1.5422  Validation loss = 3.7598  \n",
      "\n",
      "Fold: 3  Epoch: 111  Training loss = 1.5420  Validation loss = 3.7590  \n",
      "\n",
      "Fold: 3  Epoch: 112  Training loss = 1.5419  Validation loss = 3.7584  \n",
      "\n",
      "Fold: 3  Epoch: 113  Training loss = 1.5418  Validation loss = 3.7580  \n",
      "\n",
      "Fold: 3  Epoch: 114  Training loss = 1.5417  Validation loss = 3.7575  \n",
      "\n",
      "Fold: 3  Epoch: 115  Training loss = 1.5414  Validation loss = 3.7566  \n",
      "\n",
      "Fold: 3  Epoch: 116  Training loss = 1.5412  Validation loss = 3.7555  \n",
      "\n",
      "Fold: 3  Epoch: 117  Training loss = 1.5410  Validation loss = 3.7550  \n",
      "\n",
      "Fold: 3  Epoch: 118  Training loss = 1.5408  Validation loss = 3.7538  \n",
      "\n",
      "Fold: 3  Epoch: 119  Training loss = 1.5405  Validation loss = 3.7529  \n",
      "\n",
      "Fold: 3  Epoch: 120  Training loss = 1.5403  Validation loss = 3.7519  \n",
      "\n",
      "Fold: 3  Epoch: 121  Training loss = 1.5401  Validation loss = 3.7507  \n",
      "\n",
      "Fold: 3  Epoch: 122  Training loss = 1.5400  Validation loss = 3.7506  \n",
      "\n",
      "Fold: 3  Epoch: 123  Training loss = 1.5399  Validation loss = 3.7499  \n",
      "\n",
      "Fold: 3  Epoch: 124  Training loss = 1.5398  Validation loss = 3.7497  \n",
      "\n",
      "Fold: 3  Epoch: 125  Training loss = 1.5396  Validation loss = 3.7486  \n",
      "\n",
      "Fold: 3  Epoch: 126  Training loss = 1.5395  Validation loss = 3.7482  \n",
      "\n",
      "Fold: 3  Epoch: 127  Training loss = 1.5394  Validation loss = 3.7479  \n",
      "\n",
      "Fold: 3  Epoch: 128  Training loss = 1.5393  Validation loss = 3.7476  \n",
      "\n",
      "Fold: 3  Epoch: 129  Training loss = 1.5392  Validation loss = 3.7469  \n",
      "\n",
      "Fold: 3  Epoch: 130  Training loss = 1.5389  Validation loss = 3.7455  \n",
      "\n",
      "Fold: 3  Epoch: 131  Training loss = 1.5387  Validation loss = 3.7446  \n",
      "\n",
      "Fold: 3  Epoch: 132  Training loss = 1.5385  Validation loss = 3.7440  \n",
      "\n",
      "Fold: 3  Epoch: 133  Training loss = 1.5384  Validation loss = 3.7435  \n",
      "\n",
      "Fold: 3  Epoch: 134  Training loss = 1.5382  Validation loss = 3.7424  \n",
      "\n",
      "Fold: 3  Epoch: 135  Training loss = 1.5379  Validation loss = 3.7413  \n",
      "\n",
      "Fold: 3  Epoch: 136  Training loss = 1.5377  Validation loss = 3.7403  \n",
      "\n",
      "Fold: 3  Epoch: 137  Training loss = 1.5376  Validation loss = 3.7396  \n",
      "\n",
      "Fold: 3  Epoch: 138  Training loss = 1.5374  Validation loss = 3.7387  \n",
      "\n",
      "Fold: 3  Epoch: 139  Training loss = 1.5374  Validation loss = 3.7385  \n",
      "\n",
      "Fold: 3  Epoch: 140  Training loss = 1.5373  Validation loss = 3.7382  \n",
      "\n",
      "Fold: 3  Epoch: 141  Training loss = 1.5371  Validation loss = 3.7376  \n",
      "\n",
      "Fold: 3  Epoch: 142  Training loss = 1.5370  Validation loss = 3.7373  \n",
      "\n",
      "Fold: 3  Epoch: 143  Training loss = 1.5368  Validation loss = 3.7363  \n",
      "\n",
      "Fold: 3  Epoch: 144  Training loss = 1.5365  Validation loss = 3.7351  \n",
      "\n",
      "Fold: 3  Epoch: 145  Training loss = 1.5363  Validation loss = 3.7341  \n",
      "\n",
      "Fold: 3  Epoch: 146  Training loss = 1.5361  Validation loss = 3.7331  \n",
      "\n",
      "Fold: 3  Epoch: 147  Training loss = 1.5360  Validation loss = 3.7326  \n",
      "\n",
      "Fold: 3  Epoch: 148  Training loss = 1.5359  Validation loss = 3.7320  \n",
      "\n",
      "Fold: 3  Epoch: 149  Training loss = 1.5358  Validation loss = 3.7312  \n",
      "\n",
      "Fold: 3  Epoch: 150  Training loss = 1.5357  Validation loss = 3.7310  \n",
      "\n",
      "Fold: 3  Epoch: 151  Training loss = 1.5356  Validation loss = 3.7308  \n",
      "\n",
      "Fold: 3  Epoch: 152  Training loss = 1.5355  Validation loss = 3.7304  \n",
      "\n",
      "Fold: 3  Epoch: 153  Training loss = 1.5354  Validation loss = 3.7298  \n",
      "\n",
      "Fold: 3  Epoch: 154  Training loss = 1.5353  Validation loss = 3.7294  \n",
      "\n",
      "Fold: 3  Epoch: 155  Training loss = 1.5351  Validation loss = 3.7286  \n",
      "\n",
      "Fold: 3  Epoch: 156  Training loss = 1.5350  Validation loss = 3.7278  \n",
      "\n",
      "Fold: 3  Epoch: 157  Training loss = 1.5348  Validation loss = 3.7271  \n",
      "\n",
      "Fold: 3  Epoch: 158  Training loss = 1.5347  Validation loss = 3.7266  \n",
      "\n",
      "Fold: 3  Epoch: 159  Training loss = 1.5346  Validation loss = 3.7260  \n",
      "\n",
      "Fold: 3  Epoch: 160  Training loss = 1.5344  Validation loss = 3.7250  \n",
      "\n",
      "Fold: 3  Epoch: 161  Training loss = 1.5343  Validation loss = 3.7245  \n",
      "\n",
      "Fold: 3  Epoch: 162  Training loss = 1.5341  Validation loss = 3.7237  \n",
      "\n",
      "Fold: 3  Epoch: 163  Training loss = 1.5340  Validation loss = 3.7231  \n",
      "\n",
      "Fold: 3  Epoch: 164  Training loss = 1.5336  Validation loss = 3.7215  \n",
      "\n",
      "Fold: 3  Epoch: 165  Training loss = 1.5335  Validation loss = 3.7210  \n",
      "\n",
      "Fold: 3  Epoch: 166  Training loss = 1.5334  Validation loss = 3.7205  \n",
      "\n",
      "Fold: 3  Epoch: 167  Training loss = 1.5333  Validation loss = 3.7195  \n",
      "\n",
      "Fold: 3  Epoch: 168  Training loss = 1.5330  Validation loss = 3.7185  \n",
      "\n",
      "Fold: 3  Epoch: 169  Training loss = 1.5329  Validation loss = 3.7180  \n",
      "\n",
      "Fold: 3  Epoch: 170  Training loss = 1.5327  Validation loss = 3.7169  \n",
      "\n",
      "Fold: 3  Epoch: 171  Training loss = 1.5326  Validation loss = 3.7166  \n",
      "\n",
      "Fold: 3  Epoch: 172  Training loss = 1.5324  Validation loss = 3.7154  \n",
      "\n",
      "Fold: 3  Epoch: 173  Training loss = 1.5323  Validation loss = 3.7151  \n",
      "\n",
      "Fold: 3  Epoch: 174  Training loss = 1.5320  Validation loss = 3.7138  \n",
      "\n",
      "Fold: 3  Epoch: 175  Training loss = 1.5319  Validation loss = 3.7132  \n",
      "\n",
      "Fold: 3  Epoch: 176  Training loss = 1.5317  Validation loss = 3.7123  \n",
      "\n",
      "Fold: 3  Epoch: 177  Training loss = 1.5316  Validation loss = 3.7118  \n",
      "\n",
      "Fold: 3  Epoch: 178  Training loss = 1.5316  Validation loss = 3.7116  \n",
      "\n",
      "Fold: 3  Epoch: 179  Training loss = 1.5315  Validation loss = 3.7112  \n",
      "\n",
      "Fold: 3  Epoch: 180  Training loss = 1.5314  Validation loss = 3.7106  \n",
      "\n",
      "Fold: 3  Epoch: 181  Training loss = 1.5313  Validation loss = 3.7100  \n",
      "\n",
      "Fold: 3  Epoch: 182  Training loss = 1.5310  Validation loss = 3.7086  \n",
      "\n",
      "Fold: 3  Epoch: 183  Training loss = 1.5308  Validation loss = 3.7079  \n",
      "\n",
      "Fold: 3  Epoch: 184  Training loss = 1.5307  Validation loss = 3.7072  \n",
      "\n",
      "Fold: 3  Epoch: 185  Training loss = 1.5306  Validation loss = 3.7068  \n",
      "\n",
      "Fold: 3  Epoch: 186  Training loss = 1.5304  Validation loss = 3.7060  \n",
      "\n",
      "Fold: 3  Epoch: 187  Training loss = 1.5303  Validation loss = 3.7055  \n",
      "\n",
      "Fold: 3  Epoch: 188  Training loss = 1.5301  Validation loss = 3.7041  \n",
      "\n",
      "Fold: 3  Epoch: 189  Training loss = 1.5300  Validation loss = 3.7035  \n",
      "\n",
      "Fold: 3  Epoch: 190  Training loss = 1.5298  Validation loss = 3.7025  \n",
      "\n",
      "Fold: 3  Epoch: 191  Training loss = 1.5296  Validation loss = 3.7010  \n",
      "\n",
      "Fold: 3  Epoch: 192  Training loss = 1.5295  Validation loss = 3.7005  \n",
      "\n",
      "Fold: 3  Epoch: 193  Training loss = 1.5294  Validation loss = 3.6999  \n",
      "\n",
      "Fold: 3  Epoch: 194  Training loss = 1.5293  Validation loss = 3.6993  \n",
      "\n",
      "Fold: 3  Epoch: 195  Training loss = 1.5292  Validation loss = 3.6992  \n",
      "\n",
      "Fold: 3  Epoch: 196  Training loss = 1.5290  Validation loss = 3.6980  \n",
      "\n",
      "Fold: 3  Epoch: 197  Training loss = 1.5288  Validation loss = 3.6970  \n",
      "\n",
      "Fold: 3  Epoch: 198  Training loss = 1.5286  Validation loss = 3.6961  \n",
      "\n",
      "Fold: 3  Epoch: 199  Training loss = 1.5285  Validation loss = 3.6956  \n",
      "\n",
      "Fold: 3  Epoch: 200  Training loss = 1.5284  Validation loss = 3.6951  \n",
      "\n",
      "Fold: 3  Epoch: 201  Training loss = 1.5284  Validation loss = 3.6948  \n",
      "\n",
      "Fold: 3  Epoch: 202  Training loss = 1.5282  Validation loss = 3.6940  \n",
      "\n",
      "Fold: 3  Epoch: 203  Training loss = 1.5281  Validation loss = 3.6936  \n",
      "\n",
      "Fold: 3  Epoch: 204  Training loss = 1.5279  Validation loss = 3.6925  \n",
      "\n",
      "Fold: 3  Epoch: 205  Training loss = 1.5278  Validation loss = 3.6921  \n",
      "\n",
      "Fold: 3  Epoch: 206  Training loss = 1.5277  Validation loss = 3.6914  \n",
      "\n",
      "Fold: 3  Epoch: 207  Training loss = 1.5276  Validation loss = 3.6910  \n",
      "\n",
      "Fold: 3  Epoch: 208  Training loss = 1.5273  Validation loss = 3.6895  \n",
      "\n",
      "Fold: 3  Epoch: 209  Training loss = 1.5271  Validation loss = 3.6885  \n",
      "\n",
      "Fold: 3  Epoch: 210  Training loss = 1.5269  Validation loss = 3.6876  \n",
      "\n",
      "Fold: 3  Epoch: 211  Training loss = 1.5268  Validation loss = 3.6869  \n",
      "\n",
      "Fold: 3  Epoch: 212  Training loss = 1.5266  Validation loss = 3.6859  \n",
      "\n",
      "Fold: 3  Epoch: 213  Training loss = 1.5265  Validation loss = 3.6854  \n",
      "\n",
      "Fold: 3  Epoch: 214  Training loss = 1.5265  Validation loss = 3.6852  \n",
      "\n",
      "Fold: 3  Epoch: 215  Training loss = 1.5263  Validation loss = 3.6841  \n",
      "\n",
      "Fold: 3  Epoch: 216  Training loss = 1.5261  Validation loss = 3.6834  \n",
      "\n",
      "Fold: 3  Epoch: 217  Training loss = 1.5261  Validation loss = 3.6832  \n",
      "\n",
      "Fold: 3  Epoch: 218  Training loss = 1.5260  Validation loss = 3.6829  \n",
      "\n",
      "Fold: 3  Epoch: 219  Training loss = 1.5259  Validation loss = 3.6823  \n",
      "\n",
      "Fold: 3  Epoch: 220  Training loss = 1.5258  Validation loss = 3.6819  \n",
      "\n",
      "Fold: 3  Epoch: 221  Training loss = 1.5257  Validation loss = 3.6815  \n",
      "\n",
      "Fold: 3  Epoch: 222  Training loss = 1.5256  Validation loss = 3.6807  \n",
      "\n",
      "Fold: 3  Epoch: 223  Training loss = 1.5255  Validation loss = 3.6802  \n",
      "\n",
      "Fold: 3  Epoch: 224  Training loss = 1.5253  Validation loss = 3.6793  \n",
      "\n",
      "Fold: 3  Epoch: 225  Training loss = 1.5252  Validation loss = 3.6789  \n",
      "\n",
      "Fold: 3  Epoch: 226  Training loss = 1.5250  Validation loss = 3.6780  \n",
      "\n",
      "Fold: 3  Epoch: 227  Training loss = 1.5249  Validation loss = 3.6774  \n",
      "\n",
      "Fold: 3  Epoch: 228  Training loss = 1.5248  Validation loss = 3.6771  \n",
      "\n",
      "Fold: 3  Epoch: 229  Training loss = 1.5248  Validation loss = 3.6771  \n",
      "\n",
      "Fold: 3  Epoch: 230  Training loss = 1.5247  Validation loss = 3.6761  \n",
      "\n",
      "Fold: 3  Epoch: 231  Training loss = 1.5247  Validation loss = 3.6759  \n",
      "\n",
      "Fold: 3  Epoch: 232  Training loss = 1.5246  Validation loss = 3.6752  \n",
      "\n",
      "Fold: 3  Epoch: 233  Training loss = 1.5245  Validation loss = 3.6748  \n",
      "\n",
      "Fold: 3  Epoch: 234  Training loss = 1.5243  Validation loss = 3.6738  \n",
      "\n",
      "Fold: 3  Epoch: 235  Training loss = 1.5242  Validation loss = 3.6734  \n",
      "\n",
      "Fold: 3  Epoch: 236  Training loss = 1.5240  Validation loss = 3.6723  \n",
      "\n",
      "Fold: 3  Epoch: 237  Training loss = 1.5240  Validation loss = 3.6720  \n",
      "\n",
      "Fold: 3  Epoch: 238  Training loss = 1.5238  Validation loss = 3.6710  \n",
      "\n",
      "Fold: 3  Epoch: 239  Training loss = 1.5237  Validation loss = 3.6708  \n",
      "\n",
      "Fold: 3  Epoch: 240  Training loss = 1.5236  Validation loss = 3.6706  \n",
      "\n",
      "Fold: 3  Epoch: 241  Training loss = 1.5234  Validation loss = 3.6692  \n",
      "\n",
      "Fold: 3  Epoch: 242  Training loss = 1.5233  Validation loss = 3.6684  \n",
      "\n",
      "Fold: 3  Epoch: 243  Training loss = 1.5232  Validation loss = 3.6681  \n",
      "\n",
      "Fold: 3  Epoch: 244  Training loss = 1.5230  Validation loss = 3.6674  \n",
      "\n",
      "Fold: 3  Epoch: 245  Training loss = 1.5230  Validation loss = 3.6670  \n",
      "\n",
      "Fold: 3  Epoch: 246  Training loss = 1.5228  Validation loss = 3.6661  \n",
      "\n",
      "Fold: 3  Epoch: 247  Training loss = 1.5225  Validation loss = 3.6647  \n",
      "\n",
      "Fold: 3  Epoch: 248  Training loss = 1.5224  Validation loss = 3.6641  \n",
      "\n",
      "Fold: 3  Epoch: 249  Training loss = 1.5224  Validation loss = 3.6637  \n",
      "\n",
      "Fold: 3  Epoch: 250  Training loss = 1.5222  Validation loss = 3.6626  \n",
      "\n",
      "Fold: 3  Epoch: 251  Training loss = 1.5220  Validation loss = 3.6620  \n",
      "\n",
      "Fold: 3  Epoch: 252  Training loss = 1.5218  Validation loss = 3.6609  \n",
      "\n",
      "Fold: 3  Epoch: 253  Training loss = 1.5217  Validation loss = 3.6603  \n",
      "\n",
      "Fold: 3  Epoch: 254  Training loss = 1.5215  Validation loss = 3.6596  \n",
      "\n",
      "Fold: 3  Epoch: 255  Training loss = 1.5215  Validation loss = 3.6594  \n",
      "\n",
      "Fold: 3  Epoch: 256  Training loss = 1.5214  Validation loss = 3.6589  \n",
      "\n",
      "Fold: 3  Epoch: 257  Training loss = 1.5213  Validation loss = 3.6583  \n",
      "\n",
      "Fold: 3  Epoch: 258  Training loss = 1.5212  Validation loss = 3.6580  \n",
      "\n",
      "Fold: 3  Epoch: 259  Training loss = 1.5211  Validation loss = 3.6576  \n",
      "\n",
      "Fold: 3  Epoch: 260  Training loss = 1.5209  Validation loss = 3.6561  \n",
      "\n",
      "Fold: 3  Epoch: 261  Training loss = 1.5208  Validation loss = 3.6554  \n",
      "\n",
      "Fold: 3  Epoch: 262  Training loss = 1.5207  Validation loss = 3.6547  \n",
      "\n",
      "Fold: 3  Epoch: 263  Training loss = 1.5205  Validation loss = 3.6537  \n",
      "\n",
      "Fold: 3  Epoch: 264  Training loss = 1.5205  Validation loss = 3.6536  \n",
      "\n",
      "Fold: 3  Epoch: 265  Training loss = 1.5204  Validation loss = 3.6529  \n",
      "\n",
      "Fold: 3  Epoch: 266  Training loss = 1.5203  Validation loss = 3.6523  \n",
      "\n",
      "Fold: 3  Epoch: 267  Training loss = 1.5202  Validation loss = 3.6518  \n",
      "\n",
      "Fold: 3  Epoch: 268  Training loss = 1.5201  Validation loss = 3.6510  \n",
      "\n",
      "Fold: 3  Epoch: 269  Training loss = 1.5199  Validation loss = 3.6496  \n",
      "\n",
      "Fold: 3  Epoch: 270  Training loss = 1.5198  Validation loss = 3.6493  \n",
      "\n",
      "Fold: 3  Epoch: 271  Training loss = 1.5198  Validation loss = 3.6487  \n",
      "\n",
      "Fold: 3  Epoch: 272  Training loss = 1.5198  Validation loss = 3.6488  \n",
      "\n",
      "Fold: 3  Epoch: 273  Training loss = 1.5196  Validation loss = 3.6477  \n",
      "\n",
      "Fold: 3  Epoch: 274  Training loss = 1.5194  Validation loss = 3.6467  \n",
      "\n",
      "Fold: 3  Epoch: 275  Training loss = 1.5193  Validation loss = 3.6458  \n",
      "\n",
      "Fold: 3  Epoch: 276  Training loss = 1.5191  Validation loss = 3.6450  \n",
      "\n",
      "Fold: 3  Epoch: 277  Training loss = 1.5190  Validation loss = 3.6440  \n",
      "\n",
      "Fold: 3  Epoch: 278  Training loss = 1.5189  Validation loss = 3.6433  \n",
      "\n",
      "Fold: 3  Epoch: 279  Training loss = 1.5188  Validation loss = 3.6431  \n",
      "\n",
      "Fold: 3  Epoch: 280  Training loss = 1.5186  Validation loss = 3.6423  \n",
      "\n",
      "Fold: 3  Epoch: 281  Training loss = 1.5186  Validation loss = 3.6419  \n",
      "\n",
      "Fold: 3  Epoch: 282  Training loss = 1.5184  Validation loss = 3.6409  \n",
      "\n",
      "Fold: 3  Epoch: 283  Training loss = 1.5184  Validation loss = 3.6406  \n",
      "\n",
      "Fold: 3  Epoch: 284  Training loss = 1.5183  Validation loss = 3.6403  \n",
      "\n",
      "Fold: 3  Epoch: 285  Training loss = 1.5181  Validation loss = 3.6393  \n",
      "\n",
      "Fold: 3  Epoch: 286  Training loss = 1.5180  Validation loss = 3.6389  \n",
      "\n",
      "Fold: 3  Epoch: 287  Training loss = 1.5180  Validation loss = 3.6385  \n",
      "\n",
      "Fold: 3  Epoch: 288  Training loss = 1.5178  Validation loss = 3.6377  \n",
      "\n",
      "Fold: 3  Epoch: 289  Training loss = 1.5177  Validation loss = 3.6372  \n",
      "\n",
      "Fold: 3  Epoch: 290  Training loss = 1.5176  Validation loss = 3.6365  \n",
      "\n",
      "Fold: 3  Epoch: 291  Training loss = 1.5175  Validation loss = 3.6361  \n",
      "\n",
      "Fold: 3  Epoch: 292  Training loss = 1.5175  Validation loss = 3.6358  \n",
      "\n",
      "Fold: 3  Epoch: 293  Training loss = 1.5174  Validation loss = 3.6352  \n",
      "\n",
      "Fold: 3  Epoch: 294  Training loss = 1.5172  Validation loss = 3.6343  \n",
      "\n",
      "Fold: 3  Epoch: 295  Training loss = 1.5171  Validation loss = 3.6333  \n",
      "\n",
      "Fold: 3  Epoch: 296  Training loss = 1.5169  Validation loss = 3.6323  \n",
      "\n",
      "Fold: 3  Epoch: 297  Training loss = 1.5168  Validation loss = 3.6318  \n",
      "\n",
      "Fold: 3  Epoch: 298  Training loss = 1.5167  Validation loss = 3.6315  \n",
      "\n",
      "Fold: 3  Epoch: 299  Training loss = 1.5166  Validation loss = 3.6311  \n",
      "\n",
      "Fold: 3  Epoch: 300  Training loss = 1.5165  Validation loss = 3.6302  \n",
      "\n",
      "Fold: 3  Epoch: 301  Training loss = 1.5164  Validation loss = 3.6297  \n",
      "\n",
      "Fold: 3  Epoch: 302  Training loss = 1.5162  Validation loss = 3.6285  \n",
      "\n",
      "Fold: 3  Epoch: 303  Training loss = 1.5161  Validation loss = 3.6281  \n",
      "\n",
      "Fold: 3  Epoch: 304  Training loss = 1.5160  Validation loss = 3.6277  \n",
      "\n",
      "Fold: 3  Epoch: 305  Training loss = 1.5159  Validation loss = 3.6267  \n",
      "\n",
      "Fold: 3  Epoch: 306  Training loss = 1.5158  Validation loss = 3.6262  \n",
      "\n",
      "Fold: 3  Epoch: 307  Training loss = 1.5157  Validation loss = 3.6259  \n",
      "\n",
      "Fold: 3  Epoch: 308  Training loss = 1.5158  Validation loss = 3.6264  \n",
      "\n",
      "Fold: 3  Epoch: 309  Training loss = 1.5159  Validation loss = 3.6269  \n",
      "\n",
      "Fold: 3  Epoch: 310  Training loss = 1.5157  Validation loss = 3.6260  \n",
      "\n",
      "Fold: 3  Epoch: 311  Training loss = 1.5157  Validation loss = 3.6258  \n",
      "\n",
      "Fold: 3  Epoch: 312  Training loss = 1.5156  Validation loss = 3.6250  \n",
      "\n",
      "Fold: 3  Epoch: 313  Training loss = 1.5154  Validation loss = 3.6237  \n",
      "\n",
      "Fold: 3  Epoch: 314  Training loss = 1.5151  Validation loss = 3.6224  \n",
      "\n",
      "Fold: 3  Epoch: 315  Training loss = 1.5150  Validation loss = 3.6218  \n",
      "\n",
      "Fold: 3  Epoch: 316  Training loss = 1.5149  Validation loss = 3.6209  \n",
      "\n",
      "Fold: 3  Epoch: 317  Training loss = 1.5148  Validation loss = 3.6204  \n",
      "\n",
      "Fold: 3  Epoch: 318  Training loss = 1.5148  Validation loss = 3.6201  \n",
      "\n",
      "Fold: 3  Epoch: 319  Training loss = 1.5147  Validation loss = 3.6200  \n",
      "\n",
      "Fold: 3  Epoch: 320  Training loss = 1.5146  Validation loss = 3.6193  \n",
      "\n",
      "Fold: 3  Epoch: 321  Training loss = 1.5145  Validation loss = 3.6190  \n",
      "\n",
      "Fold: 3  Epoch: 322  Training loss = 1.5145  Validation loss = 3.6188  \n",
      "\n",
      "Fold: 3  Epoch: 323  Training loss = 1.5144  Validation loss = 3.6182  \n",
      "\n",
      "Fold: 3  Epoch: 324  Training loss = 1.5144  Validation loss = 3.6179  \n",
      "\n",
      "Fold: 3  Epoch: 325  Training loss = 1.5143  Validation loss = 3.6174  \n",
      "\n",
      "Fold: 3  Epoch: 326  Training loss = 1.5143  Validation loss = 3.6175  \n",
      "\n",
      "Fold: 3  Epoch: 327  Training loss = 1.5142  Validation loss = 3.6167  \n",
      "\n",
      "Fold: 3  Epoch: 328  Training loss = 1.5141  Validation loss = 3.6162  \n",
      "\n",
      "Fold: 3  Epoch: 329  Training loss = 1.5140  Validation loss = 3.6158  \n",
      "\n",
      "Fold: 3  Epoch: 330  Training loss = 1.5140  Validation loss = 3.6155  \n",
      "\n",
      "Fold: 3  Epoch: 331  Training loss = 1.5139  Validation loss = 3.6150  \n",
      "\n",
      "Fold: 3  Epoch: 332  Training loss = 1.5138  Validation loss = 3.6146  \n",
      "\n",
      "Fold: 3  Epoch: 333  Training loss = 1.5137  Validation loss = 3.6141  \n",
      "\n",
      "Fold: 3  Epoch: 334  Training loss = 1.5136  Validation loss = 3.6134  \n",
      "\n",
      "Fold: 3  Epoch: 335  Training loss = 1.5134  Validation loss = 3.6125  \n",
      "\n",
      "Fold: 3  Epoch: 336  Training loss = 1.5134  Validation loss = 3.6122  \n",
      "\n",
      "Fold: 3  Epoch: 337  Training loss = 1.5132  Validation loss = 3.6112  \n",
      "\n",
      "Fold: 3  Epoch: 338  Training loss = 1.5132  Validation loss = 3.6109  \n",
      "\n",
      "Fold: 3  Epoch: 339  Training loss = 1.5130  Validation loss = 3.6099  \n",
      "\n",
      "Fold: 3  Epoch: 340  Training loss = 1.5130  Validation loss = 3.6095  \n",
      "\n",
      "Fold: 3  Epoch: 341  Training loss = 1.5129  Validation loss = 3.6093  \n",
      "\n",
      "Fold: 3  Epoch: 342  Training loss = 1.5128  Validation loss = 3.6086  \n",
      "\n",
      "Fold: 3  Epoch: 343  Training loss = 1.5126  Validation loss = 3.6074  \n",
      "\n",
      "Fold: 3  Epoch: 344  Training loss = 1.5124  Validation loss = 3.6062  \n",
      "\n",
      "Fold: 3  Epoch: 345  Training loss = 1.5123  Validation loss = 3.6055  \n",
      "\n",
      "Fold: 3  Epoch: 346  Training loss = 1.5122  Validation loss = 3.6050  \n",
      "\n",
      "Fold: 3  Epoch: 347  Training loss = 1.5120  Validation loss = 3.6040  \n",
      "\n",
      "Fold: 3  Epoch: 348  Training loss = 1.5119  Validation loss = 3.6038  \n",
      "\n",
      "Fold: 3  Epoch: 349  Training loss = 1.5118  Validation loss = 3.6030  \n",
      "\n",
      "Fold: 3  Epoch: 350  Training loss = 1.5117  Validation loss = 3.6020  \n",
      "\n",
      "Fold: 3  Epoch: 351  Training loss = 1.5116  Validation loss = 3.6015  \n",
      "\n",
      "Fold: 3  Epoch: 352  Training loss = 1.5115  Validation loss = 3.6011  \n",
      "\n",
      "Fold: 3  Epoch: 353  Training loss = 1.5114  Validation loss = 3.6007  \n",
      "\n",
      "Fold: 3  Epoch: 354  Training loss = 1.5112  Validation loss = 3.5999  \n",
      "\n",
      "Fold: 3  Epoch: 355  Training loss = 1.5111  Validation loss = 3.5987  \n",
      "\n",
      "Fold: 3  Epoch: 356  Training loss = 1.5110  Validation loss = 3.5984  \n",
      "\n",
      "Fold: 3  Epoch: 357  Training loss = 1.5109  Validation loss = 3.5979  \n",
      "\n",
      "Fold: 3  Epoch: 358  Training loss = 1.5108  Validation loss = 3.5974  \n",
      "\n",
      "Fold: 3  Epoch: 359  Training loss = 1.5107  Validation loss = 3.5964  \n",
      "\n",
      "Fold: 3  Epoch: 360  Training loss = 1.5106  Validation loss = 3.5959  \n",
      "\n",
      "Fold: 3  Epoch: 361  Training loss = 1.5105  Validation loss = 3.5953  \n",
      "\n",
      "Fold: 3  Epoch: 362  Training loss = 1.5103  Validation loss = 3.5946  \n",
      "\n",
      "Fold: 3  Epoch: 363  Training loss = 1.5103  Validation loss = 3.5944  \n",
      "\n",
      "Fold: 3  Epoch: 364  Training loss = 1.5103  Validation loss = 3.5939  \n",
      "\n",
      "Fold: 3  Epoch: 365  Training loss = 1.5102  Validation loss = 3.5935  \n",
      "\n",
      "Fold: 3  Epoch: 366  Training loss = 1.5100  Validation loss = 3.5922  \n",
      "\n",
      "Fold: 3  Epoch: 367  Training loss = 1.5100  Validation loss = 3.5920  \n",
      "\n",
      "Fold: 3  Epoch: 368  Training loss = 1.5099  Validation loss = 3.5916  \n",
      "\n",
      "Fold: 3  Epoch: 369  Training loss = 1.5098  Validation loss = 3.5909  \n",
      "\n",
      "Fold: 3  Epoch: 370  Training loss = 1.5097  Validation loss = 3.5902  \n",
      "\n",
      "Fold: 3  Epoch: 371  Training loss = 1.5096  Validation loss = 3.5897  \n",
      "\n",
      "Fold: 3  Epoch: 372  Training loss = 1.5095  Validation loss = 3.5892  \n",
      "\n",
      "Fold: 3  Epoch: 373  Training loss = 1.5094  Validation loss = 3.5890  \n",
      "\n",
      "Fold: 3  Epoch: 374  Training loss = 1.5093  Validation loss = 3.5881  \n",
      "\n",
      "Fold: 3  Epoch: 375  Training loss = 1.5093  Validation loss = 3.5878  \n",
      "\n",
      "Fold: 3  Epoch: 376  Training loss = 1.5092  Validation loss = 3.5878  \n",
      "\n",
      "Fold: 3  Epoch: 377  Training loss = 1.5091  Validation loss = 3.5871  \n",
      "\n",
      "Fold: 3  Epoch: 378  Training loss = 1.5090  Validation loss = 3.5864  \n",
      "\n",
      "Fold: 3  Epoch: 379  Training loss = 1.5089  Validation loss = 3.5858  \n",
      "\n",
      "Fold: 3  Epoch: 380  Training loss = 1.5089  Validation loss = 3.5856  \n",
      "\n",
      "Fold: 3  Epoch: 381  Training loss = 1.5088  Validation loss = 3.5851  \n",
      "\n",
      "Fold: 3  Epoch: 382  Training loss = 1.5088  Validation loss = 3.5847  \n",
      "\n",
      "Fold: 3  Epoch: 383  Training loss = 1.5087  Validation loss = 3.5842  \n",
      "\n",
      "Fold: 3  Epoch: 384  Training loss = 1.5086  Validation loss = 3.5836  \n",
      "\n",
      "Fold: 3  Epoch: 385  Training loss = 1.5084  Validation loss = 3.5823  \n",
      "\n",
      "Fold: 3  Epoch: 386  Training loss = 1.5084  Validation loss = 3.5817  \n",
      "\n",
      "Fold: 3  Epoch: 387  Training loss = 1.5082  Validation loss = 3.5809  \n",
      "\n",
      "Fold: 3  Epoch: 388  Training loss = 1.5082  Validation loss = 3.5806  \n",
      "\n",
      "Fold: 3  Epoch: 389  Training loss = 1.5081  Validation loss = 3.5800  \n",
      "\n",
      "Fold: 3  Epoch: 390  Training loss = 1.5080  Validation loss = 3.5798  \n",
      "\n",
      "Fold: 3  Epoch: 391  Training loss = 1.5080  Validation loss = 3.5794  \n",
      "\n",
      "Fold: 3  Epoch: 392  Training loss = 1.5079  Validation loss = 3.5792  \n",
      "\n",
      "Fold: 3  Epoch: 393  Training loss = 1.5078  Validation loss = 3.5788  \n",
      "\n",
      "Fold: 3  Epoch: 394  Training loss = 1.5077  Validation loss = 3.5783  \n",
      "\n",
      "Fold: 3  Epoch: 395  Training loss = 1.5077  Validation loss = 3.5777  \n",
      "\n",
      "Fold: 3  Epoch: 396  Training loss = 1.5076  Validation loss = 3.5770  \n",
      "\n",
      "Fold: 3  Epoch: 397  Training loss = 1.5075  Validation loss = 3.5768  \n",
      "\n",
      "Fold: 3  Epoch: 398  Training loss = 1.5075  Validation loss = 3.5765  \n",
      "\n",
      "Fold: 3  Epoch: 399  Training loss = 1.5075  Validation loss = 3.5768  \n",
      "\n",
      "Fold: 3  Epoch: 400  Training loss = 1.5074  Validation loss = 3.5764  \n",
      "\n",
      "Fold: 3  Epoch: 401  Training loss = 1.5072  Validation loss = 3.5753  \n",
      "\n",
      "Fold: 3  Epoch: 402  Training loss = 1.5072  Validation loss = 3.5749  \n",
      "\n",
      "Fold: 3  Epoch: 403  Training loss = 1.5071  Validation loss = 3.5744  \n",
      "\n",
      "Fold: 3  Epoch: 404  Training loss = 1.5071  Validation loss = 3.5742  \n",
      "\n",
      "Fold: 3  Epoch: 405  Training loss = 1.5070  Validation loss = 3.5737  \n",
      "\n",
      "Fold: 3  Epoch: 406  Training loss = 1.5070  Validation loss = 3.5734  \n",
      "\n",
      "Fold: 3  Epoch: 407  Training loss = 1.5068  Validation loss = 3.5727  \n",
      "\n",
      "Fold: 3  Epoch: 408  Training loss = 1.5068  Validation loss = 3.5727  \n",
      "\n",
      "Fold: 3  Epoch: 409  Training loss = 1.5067  Validation loss = 3.5723  \n",
      "\n",
      "Fold: 3  Epoch: 410  Training loss = 1.5066  Validation loss = 3.5715  \n",
      "\n",
      "Fold: 3  Epoch: 411  Training loss = 1.5066  Validation loss = 3.5714  \n",
      "\n",
      "Fold: 3  Epoch: 412  Training loss = 1.5065  Validation loss = 3.5707  \n",
      "\n",
      "Fold: 3  Epoch: 413  Training loss = 1.5064  Validation loss = 3.5704  \n",
      "\n",
      "Fold: 3  Epoch: 414  Training loss = 1.5063  Validation loss = 3.5695  \n",
      "\n",
      "Fold: 3  Epoch: 415  Training loss = 1.5061  Validation loss = 3.5686  \n",
      "\n",
      "Fold: 3  Epoch: 416  Training loss = 1.5060  Validation loss = 3.5678  \n",
      "\n",
      "Fold: 3  Epoch: 417  Training loss = 1.5060  Validation loss = 3.5679  \n",
      "\n",
      "Fold: 3  Epoch: 418  Training loss = 1.5058  Validation loss = 3.5668  \n",
      "\n",
      "Fold: 3  Epoch: 419  Training loss = 1.5058  Validation loss = 3.5664  \n",
      "\n",
      "Fold: 3  Epoch: 420  Training loss = 1.5057  Validation loss = 3.5660  \n",
      "\n",
      "Fold: 3  Epoch: 421  Training loss = 1.5057  Validation loss = 3.5657  \n",
      "\n",
      "Fold: 3  Epoch: 422  Training loss = 1.5056  Validation loss = 3.5654  \n",
      "\n",
      "Fold: 3  Epoch: 423  Training loss = 1.5055  Validation loss = 3.5651  \n",
      "\n",
      "Fold: 3  Epoch: 424  Training loss = 1.5056  Validation loss = 3.5652  \n",
      "\n",
      "Fold: 3  Epoch: 425  Training loss = 1.5054  Validation loss = 3.5643  \n",
      "\n",
      "Fold: 3  Epoch: 426  Training loss = 1.5054  Validation loss = 3.5637  \n",
      "\n",
      "Fold: 3  Epoch: 427  Training loss = 1.5053  Validation loss = 3.5633  \n",
      "\n",
      "Fold: 3  Epoch: 428  Training loss = 1.5053  Validation loss = 3.5634  \n",
      "\n",
      "Fold: 3  Epoch: 429  Training loss = 1.5052  Validation loss = 3.5628  \n",
      "\n",
      "Fold: 3  Epoch: 430  Training loss = 1.5052  Validation loss = 3.5626  \n",
      "\n",
      "Fold: 3  Epoch: 431  Training loss = 1.5051  Validation loss = 3.5620  \n",
      "\n",
      "Fold: 3  Epoch: 432  Training loss = 1.5049  Validation loss = 3.5613  \n",
      "\n",
      "Fold: 3  Epoch: 433  Training loss = 1.5049  Validation loss = 3.5611  \n",
      "\n",
      "Fold: 3  Epoch: 434  Training loss = 1.5048  Validation loss = 3.5604  \n",
      "\n",
      "Fold: 3  Epoch: 435  Training loss = 1.5047  Validation loss = 3.5597  \n",
      "\n",
      "Fold: 3  Epoch: 436  Training loss = 1.5046  Validation loss = 3.5591  \n",
      "\n",
      "Fold: 3  Epoch: 437  Training loss = 1.5045  Validation loss = 3.5586  \n",
      "\n",
      "Fold: 3  Epoch: 438  Training loss = 1.5044  Validation loss = 3.5583  \n",
      "\n",
      "Fold: 3  Epoch: 439  Training loss = 1.5043  Validation loss = 3.5575  \n",
      "\n",
      "Fold: 3  Epoch: 440  Training loss = 1.5043  Validation loss = 3.5572  \n",
      "\n",
      "Fold: 3  Epoch: 441  Training loss = 1.5042  Validation loss = 3.5566  \n",
      "\n",
      "Fold: 3  Epoch: 442  Training loss = 1.5041  Validation loss = 3.5563  \n",
      "\n",
      "Fold: 3  Epoch: 443  Training loss = 1.5041  Validation loss = 3.5562  \n",
      "\n",
      "Fold: 3  Epoch: 444  Training loss = 1.5040  Validation loss = 3.5557  \n",
      "\n",
      "Fold: 3  Epoch: 445  Training loss = 1.5039  Validation loss = 3.5554  \n",
      "\n",
      "Fold: 3  Epoch: 446  Training loss = 1.5038  Validation loss = 3.5550  \n",
      "\n",
      "Fold: 3  Epoch: 447  Training loss = 1.5038  Validation loss = 3.5543  \n",
      "\n",
      "Fold: 3  Epoch: 448  Training loss = 1.5037  Validation loss = 3.5539  \n",
      "\n",
      "Fold: 3  Epoch: 449  Training loss = 1.5036  Validation loss = 3.5529  \n",
      "\n",
      "Fold: 3  Epoch: 450  Training loss = 1.5035  Validation loss = 3.5524  \n",
      "\n",
      "Fold: 3  Epoch: 451  Training loss = 1.5035  Validation loss = 3.5522  \n",
      "\n",
      "Fold: 3  Epoch: 452  Training loss = 1.5034  Validation loss = 3.5514  \n",
      "\n",
      "Fold: 3  Epoch: 453  Training loss = 1.5033  Validation loss = 3.5507  \n",
      "\n",
      "Fold: 3  Epoch: 454  Training loss = 1.5032  Validation loss = 3.5500  \n",
      "\n",
      "Fold: 3  Epoch: 455  Training loss = 1.5031  Validation loss = 3.5494  \n",
      "\n",
      "Fold: 3  Epoch: 456  Training loss = 1.5030  Validation loss = 3.5488  \n",
      "\n",
      "Fold: 3  Epoch: 457  Training loss = 1.5029  Validation loss = 3.5480  \n",
      "\n",
      "Fold: 3  Epoch: 458  Training loss = 1.5029  Validation loss = 3.5477  \n",
      "\n",
      "Fold: 3  Epoch: 459  Training loss = 1.5028  Validation loss = 3.5475  \n",
      "\n",
      "Fold: 3  Epoch: 460  Training loss = 1.5028  Validation loss = 3.5473  \n",
      "\n",
      "Fold: 3  Epoch: 461  Training loss = 1.5027  Validation loss = 3.5472  \n",
      "\n",
      "Fold: 3  Epoch: 462  Training loss = 1.5027  Validation loss = 3.5473  \n",
      "\n",
      "Fold: 3  Epoch: 463  Training loss = 1.5027  Validation loss = 3.5468  \n",
      "\n",
      "Fold: 3  Epoch: 464  Training loss = 1.5026  Validation loss = 3.5461  \n",
      "\n",
      "Fold: 3  Epoch: 465  Training loss = 1.5025  Validation loss = 3.5456  \n",
      "\n",
      "Fold: 3  Epoch: 466  Training loss = 1.5025  Validation loss = 3.5456  \n",
      "\n",
      "Fold: 3  Epoch: 467  Training loss = 1.5023  Validation loss = 3.5446  \n",
      "\n",
      "Fold: 3  Epoch: 468  Training loss = 1.5023  Validation loss = 3.5439  \n",
      "\n",
      "Fold: 3  Epoch: 469  Training loss = 1.5022  Validation loss = 3.5433  \n",
      "\n",
      "Fold: 3  Epoch: 470  Training loss = 1.5021  Validation loss = 3.5427  \n",
      "\n",
      "Fold: 3  Epoch: 471  Training loss = 1.5020  Validation loss = 3.5420  \n",
      "\n",
      "Fold: 3  Epoch: 472  Training loss = 1.5019  Validation loss = 3.5410  \n",
      "\n",
      "Fold: 3  Epoch: 473  Training loss = 1.5018  Validation loss = 3.5402  \n",
      "\n",
      "Fold: 3  Epoch: 474  Training loss = 1.5017  Validation loss = 3.5397  \n",
      "\n",
      "Fold: 3  Epoch: 475  Training loss = 1.5016  Validation loss = 3.5387  \n",
      "\n",
      "Fold: 3  Epoch: 476  Training loss = 1.5015  Validation loss = 3.5382  \n",
      "\n",
      "Fold: 3  Epoch: 477  Training loss = 1.5014  Validation loss = 3.5377  \n",
      "\n",
      "Fold: 3  Epoch: 478  Training loss = 1.5014  Validation loss = 3.5375  \n",
      "\n",
      "Fold: 3  Epoch: 479  Training loss = 1.5013  Validation loss = 3.5372  \n",
      "\n",
      "Fold: 3  Epoch: 480  Training loss = 1.5013  Validation loss = 3.5369  \n",
      "\n",
      "Fold: 3  Epoch: 481  Training loss = 1.5012  Validation loss = 3.5367  \n",
      "\n",
      "Fold: 3  Epoch: 482  Training loss = 1.5012  Validation loss = 3.5365  \n",
      "\n",
      "Fold: 3  Epoch: 483  Training loss = 1.5011  Validation loss = 3.5356  \n",
      "\n",
      "Fold: 3  Epoch: 484  Training loss = 1.5010  Validation loss = 3.5353  \n",
      "\n",
      "Fold: 3  Epoch: 485  Training loss = 1.5009  Validation loss = 3.5350  \n",
      "\n",
      "Fold: 3  Epoch: 486  Training loss = 1.5008  Validation loss = 3.5344  \n",
      "\n",
      "Fold: 3  Epoch: 487  Training loss = 1.5008  Validation loss = 3.5339  \n",
      "\n",
      "Fold: 3  Epoch: 488  Training loss = 1.5007  Validation loss = 3.5333  \n",
      "\n",
      "Fold: 3  Epoch: 489  Training loss = 1.5006  Validation loss = 3.5330  \n",
      "\n",
      "Fold: 3  Epoch: 490  Training loss = 1.5006  Validation loss = 3.5326  \n",
      "\n",
      "Fold: 3  Epoch: 491  Training loss = 1.5005  Validation loss = 3.5324  \n",
      "\n",
      "Fold: 3  Epoch: 492  Training loss = 1.5004  Validation loss = 3.5320  \n",
      "\n",
      "Fold: 3  Epoch: 493  Training loss = 1.5004  Validation loss = 3.5313  \n",
      "\n",
      "Fold: 3  Epoch: 494  Training loss = 1.5003  Validation loss = 3.5312  \n",
      "\n",
      "Fold: 3  Epoch: 495  Training loss = 1.5002  Validation loss = 3.5306  \n",
      "\n",
      "Fold: 3  Epoch: 496  Training loss = 1.5001  Validation loss = 3.5300  \n",
      "\n",
      "Fold: 3  Epoch: 497  Training loss = 1.5000  Validation loss = 3.5293  \n",
      "\n",
      "Fold: 3  Epoch: 498  Training loss = 1.4999  Validation loss = 3.5284  \n",
      "\n",
      "Fold: 3  Epoch: 499  Training loss = 1.4998  Validation loss = 3.5278  \n",
      "\n",
      "Fold: 3  Epoch: 500  Training loss = 1.4998  Validation loss = 3.5274  \n",
      "\n",
      "Check model:  Fold: 3  Optimal epoch: 500  \n",
      "\n",
      "Fold: 4  Epoch: 1  Training loss = 1.6199  Validation loss = 4.6493  \n",
      "\n",
      "Fold: 4  Epoch: 2  Training loss = 1.6197  Validation loss = 4.6485  \n",
      "\n",
      "Fold: 4  Epoch: 3  Training loss = 1.6194  Validation loss = 4.6470  \n",
      "\n",
      "Fold: 4  Epoch: 4  Training loss = 1.6191  Validation loss = 4.6458  \n",
      "\n",
      "Fold: 4  Epoch: 5  Training loss = 1.6188  Validation loss = 4.6443  \n",
      "\n",
      "Fold: 4  Epoch: 6  Training loss = 1.6186  Validation loss = 4.6433  \n",
      "\n",
      "Fold: 4  Epoch: 7  Training loss = 1.6185  Validation loss = 4.6426  \n",
      "\n",
      "Fold: 4  Epoch: 8  Training loss = 1.6183  Validation loss = 4.6418  \n",
      "\n",
      "Fold: 4  Epoch: 9  Training loss = 1.6181  Validation loss = 4.6408  \n",
      "\n",
      "Fold: 4  Epoch: 10  Training loss = 1.6179  Validation loss = 4.6399  \n",
      "\n",
      "Fold: 4  Epoch: 11  Training loss = 1.6178  Validation loss = 4.6395  \n",
      "\n",
      "Fold: 4  Epoch: 12  Training loss = 1.6175  Validation loss = 4.6382  \n",
      "\n",
      "Fold: 4  Epoch: 13  Training loss = 1.6173  Validation loss = 4.6372  \n",
      "\n",
      "Fold: 4  Epoch: 14  Training loss = 1.6171  Validation loss = 4.6362  \n",
      "\n",
      "Fold: 4  Epoch: 15  Training loss = 1.6170  Validation loss = 4.6359  \n",
      "\n",
      "Fold: 4  Epoch: 16  Training loss = 1.6168  Validation loss = 4.6350  \n",
      "\n",
      "Fold: 4  Epoch: 17  Training loss = 1.6166  Validation loss = 4.6340  \n",
      "\n",
      "Fold: 4  Epoch: 18  Training loss = 1.6163  Validation loss = 4.6327  \n",
      "\n",
      "Fold: 4  Epoch: 19  Training loss = 1.6162  Validation loss = 4.6319  \n",
      "\n",
      "Fold: 4  Epoch: 20  Training loss = 1.6160  Validation loss = 4.6311  \n",
      "\n",
      "Fold: 4  Epoch: 21  Training loss = 1.6157  Validation loss = 4.6297  \n",
      "\n",
      "Fold: 4  Epoch: 22  Training loss = 1.6155  Validation loss = 4.6287  \n",
      "\n",
      "Fold: 4  Epoch: 23  Training loss = 1.6152  Validation loss = 4.6276  \n",
      "\n",
      "Fold: 4  Epoch: 24  Training loss = 1.6150  Validation loss = 4.6265  \n",
      "\n",
      "Fold: 4  Epoch: 25  Training loss = 1.6149  Validation loss = 4.6262  \n",
      "\n",
      "Fold: 4  Epoch: 26  Training loss = 1.6148  Validation loss = 4.6254  \n",
      "\n",
      "Fold: 4  Epoch: 27  Training loss = 1.6147  Validation loss = 4.6250  \n",
      "\n",
      "Fold: 4  Epoch: 28  Training loss = 1.6145  Validation loss = 4.6243  \n",
      "\n",
      "Fold: 4  Epoch: 29  Training loss = 1.6143  Validation loss = 4.6235  \n",
      "\n",
      "Fold: 4  Epoch: 30  Training loss = 1.6143  Validation loss = 4.6233  \n",
      "\n",
      "Fold: 4  Epoch: 31  Training loss = 1.6141  Validation loss = 4.6226  \n",
      "\n",
      "Fold: 4  Epoch: 32  Training loss = 1.6139  Validation loss = 4.6216  \n",
      "\n",
      "Fold: 4  Epoch: 33  Training loss = 1.6137  Validation loss = 4.6206  \n",
      "\n",
      "Fold: 4  Epoch: 34  Training loss = 1.6135  Validation loss = 4.6197  \n",
      "\n",
      "Fold: 4  Epoch: 35  Training loss = 1.6132  Validation loss = 4.6183  \n",
      "\n",
      "Fold: 4  Epoch: 36  Training loss = 1.6130  Validation loss = 4.6170  \n",
      "\n",
      "Fold: 4  Epoch: 37  Training loss = 1.6128  Validation loss = 4.6163  \n",
      "\n",
      "Fold: 4  Epoch: 38  Training loss = 1.6126  Validation loss = 4.6152  \n",
      "\n",
      "Fold: 4  Epoch: 39  Training loss = 1.6123  Validation loss = 4.6139  \n",
      "\n",
      "Fold: 4  Epoch: 40  Training loss = 1.6123  Validation loss = 4.6137  \n",
      "\n",
      "Fold: 4  Epoch: 41  Training loss = 1.6121  Validation loss = 4.6130  \n",
      "\n",
      "Fold: 4  Epoch: 42  Training loss = 1.6121  Validation loss = 4.6126  \n",
      "\n",
      "Fold: 4  Epoch: 43  Training loss = 1.6119  Validation loss = 4.6121  \n",
      "\n",
      "Fold: 4  Epoch: 44  Training loss = 1.6117  Validation loss = 4.6111  \n",
      "\n",
      "Fold: 4  Epoch: 45  Training loss = 1.6117  Validation loss = 4.6110  \n",
      "\n",
      "Fold: 4  Epoch: 46  Training loss = 1.6116  Validation loss = 4.6104  \n",
      "\n",
      "Fold: 4  Epoch: 47  Training loss = 1.6114  Validation loss = 4.6093  \n",
      "\n",
      "Fold: 4  Epoch: 48  Training loss = 1.6111  Validation loss = 4.6078  \n",
      "\n",
      "Fold: 4  Epoch: 49  Training loss = 1.6108  Validation loss = 4.6066  \n",
      "\n",
      "Fold: 4  Epoch: 50  Training loss = 1.6106  Validation loss = 4.6057  \n",
      "\n",
      "Fold: 4  Epoch: 51  Training loss = 1.6105  Validation loss = 4.6049  \n",
      "\n",
      "Fold: 4  Epoch: 52  Training loss = 1.6102  Validation loss = 4.6036  \n",
      "\n",
      "Fold: 4  Epoch: 53  Training loss = 1.6098  Validation loss = 4.6019  \n",
      "\n",
      "Fold: 4  Epoch: 54  Training loss = 1.6097  Validation loss = 4.6011  \n",
      "\n",
      "Fold: 4  Epoch: 55  Training loss = 1.6095  Validation loss = 4.6002  \n",
      "\n",
      "Fold: 4  Epoch: 56  Training loss = 1.6093  Validation loss = 4.5995  \n",
      "\n",
      "Fold: 4  Epoch: 57  Training loss = 1.6092  Validation loss = 4.5989  \n",
      "\n",
      "Fold: 4  Epoch: 58  Training loss = 1.6091  Validation loss = 4.5984  \n",
      "\n",
      "Fold: 4  Epoch: 59  Training loss = 1.6088  Validation loss = 4.5968  \n",
      "\n",
      "Fold: 4  Epoch: 60  Training loss = 1.6086  Validation loss = 4.5959  \n",
      "\n",
      "Fold: 4  Epoch: 61  Training loss = 1.6084  Validation loss = 4.5950  \n",
      "\n",
      "Fold: 4  Epoch: 62  Training loss = 1.6082  Validation loss = 4.5941  \n",
      "\n",
      "Fold: 4  Epoch: 63  Training loss = 1.6079  Validation loss = 4.5926  \n",
      "\n",
      "Fold: 4  Epoch: 64  Training loss = 1.6077  Validation loss = 4.5915  \n",
      "\n",
      "Fold: 4  Epoch: 65  Training loss = 1.6076  Validation loss = 4.5907  \n",
      "\n",
      "Fold: 4  Epoch: 66  Training loss = 1.6074  Validation loss = 4.5898  \n",
      "\n",
      "Fold: 4  Epoch: 67  Training loss = 1.6072  Validation loss = 4.5888  \n",
      "\n",
      "Fold: 4  Epoch: 68  Training loss = 1.6071  Validation loss = 4.5886  \n",
      "\n",
      "Fold: 4  Epoch: 69  Training loss = 1.6071  Validation loss = 4.5883  \n",
      "\n",
      "Fold: 4  Epoch: 70  Training loss = 1.6068  Validation loss = 4.5870  \n",
      "\n",
      "Fold: 4  Epoch: 71  Training loss = 1.6066  Validation loss = 4.5862  \n",
      "\n",
      "Fold: 4  Epoch: 72  Training loss = 1.6066  Validation loss = 4.5859  \n",
      "\n",
      "Fold: 4  Epoch: 73  Training loss = 1.6065  Validation loss = 4.5853  \n",
      "\n",
      "Fold: 4  Epoch: 74  Training loss = 1.6063  Validation loss = 4.5848  \n",
      "\n",
      "Fold: 4  Epoch: 75  Training loss = 1.6063  Validation loss = 4.5845  \n",
      "\n",
      "Fold: 4  Epoch: 76  Training loss = 1.6061  Validation loss = 4.5835  \n",
      "\n",
      "Fold: 4  Epoch: 77  Training loss = 1.6059  Validation loss = 4.5827  \n",
      "\n",
      "Fold: 4  Epoch: 78  Training loss = 1.6058  Validation loss = 4.5822  \n",
      "\n",
      "Fold: 4  Epoch: 79  Training loss = 1.6057  Validation loss = 4.5818  \n",
      "\n",
      "Fold: 4  Epoch: 80  Training loss = 1.6055  Validation loss = 4.5808  \n",
      "\n",
      "Fold: 4  Epoch: 81  Training loss = 1.6055  Validation loss = 4.5805  \n",
      "\n",
      "Fold: 4  Epoch: 82  Training loss = 1.6053  Validation loss = 4.5797  \n",
      "\n",
      "Fold: 4  Epoch: 83  Training loss = 1.6052  Validation loss = 4.5794  \n",
      "\n",
      "Fold: 4  Epoch: 84  Training loss = 1.6051  Validation loss = 4.5787  \n",
      "\n",
      "Fold: 4  Epoch: 85  Training loss = 1.6047  Validation loss = 4.5768  \n",
      "\n",
      "Fold: 4  Epoch: 86  Training loss = 1.6047  Validation loss = 4.5767  \n",
      "\n",
      "Fold: 4  Epoch: 87  Training loss = 1.6046  Validation loss = 4.5764  \n",
      "\n",
      "Fold: 4  Epoch: 88  Training loss = 1.6044  Validation loss = 4.5752  \n",
      "\n",
      "Fold: 4  Epoch: 89  Training loss = 1.6043  Validation loss = 4.5744  \n",
      "\n",
      "Fold: 4  Epoch: 90  Training loss = 1.6041  Validation loss = 4.5733  \n",
      "\n",
      "Fold: 4  Epoch: 91  Training loss = 1.6040  Validation loss = 4.5729  \n",
      "\n",
      "Fold: 4  Epoch: 92  Training loss = 1.6038  Validation loss = 4.5719  \n",
      "\n",
      "Fold: 4  Epoch: 93  Training loss = 1.6036  Validation loss = 4.5709  \n",
      "\n",
      "Fold: 4  Epoch: 94  Training loss = 1.6033  Validation loss = 4.5696  \n",
      "\n",
      "Fold: 4  Epoch: 95  Training loss = 1.6033  Validation loss = 4.5694  \n",
      "\n",
      "Fold: 4  Epoch: 96  Training loss = 1.6032  Validation loss = 4.5692  \n",
      "\n",
      "Fold: 4  Epoch: 97  Training loss = 1.6031  Validation loss = 4.5688  \n",
      "\n",
      "Fold: 4  Epoch: 98  Training loss = 1.6030  Validation loss = 4.5681  \n",
      "\n",
      "Fold: 4  Epoch: 99  Training loss = 1.6028  Validation loss = 4.5673  \n",
      "\n",
      "Fold: 4  Epoch: 100  Training loss = 1.6027  Validation loss = 4.5663  \n",
      "\n",
      "Fold: 4  Epoch: 101  Training loss = 1.6024  Validation loss = 4.5652  \n",
      "\n",
      "Fold: 4  Epoch: 102  Training loss = 1.6023  Validation loss = 4.5645  \n",
      "\n",
      "Fold: 4  Epoch: 103  Training loss = 1.6022  Validation loss = 4.5637  \n",
      "\n",
      "Fold: 4  Epoch: 104  Training loss = 1.6020  Validation loss = 4.5627  \n",
      "\n",
      "Fold: 4  Epoch: 105  Training loss = 1.6018  Validation loss = 4.5617  \n",
      "\n",
      "Fold: 4  Epoch: 106  Training loss = 1.6016  Validation loss = 4.5607  \n",
      "\n",
      "Fold: 4  Epoch: 107  Training loss = 1.6014  Validation loss = 4.5598  \n",
      "\n",
      "Fold: 4  Epoch: 108  Training loss = 1.6013  Validation loss = 4.5591  \n",
      "\n",
      "Fold: 4  Epoch: 109  Training loss = 1.6012  Validation loss = 4.5586  \n",
      "\n",
      "Fold: 4  Epoch: 110  Training loss = 1.6011  Validation loss = 4.5581  \n",
      "\n",
      "Fold: 4  Epoch: 111  Training loss = 1.6009  Validation loss = 4.5573  \n",
      "\n",
      "Fold: 4  Epoch: 112  Training loss = 1.6009  Validation loss = 4.5570  \n",
      "\n",
      "Fold: 4  Epoch: 113  Training loss = 1.6007  Validation loss = 4.5564  \n",
      "\n",
      "Fold: 4  Epoch: 114  Training loss = 1.6006  Validation loss = 4.5556  \n",
      "\n",
      "Fold: 4  Epoch: 115  Training loss = 1.6004  Validation loss = 4.5543  \n",
      "\n",
      "Fold: 4  Epoch: 116  Training loss = 1.6002  Validation loss = 4.5535  \n",
      "\n",
      "Fold: 4  Epoch: 117  Training loss = 1.6000  Validation loss = 4.5526  \n",
      "\n",
      "Fold: 4  Epoch: 118  Training loss = 1.5998  Validation loss = 4.5514  \n",
      "\n",
      "Fold: 4  Epoch: 119  Training loss = 1.5997  Validation loss = 4.5506  \n",
      "\n",
      "Fold: 4  Epoch: 120  Training loss = 1.5994  Validation loss = 4.5495  \n",
      "\n",
      "Fold: 4  Epoch: 121  Training loss = 1.5992  Validation loss = 4.5481  \n",
      "\n",
      "Fold: 4  Epoch: 122  Training loss = 1.5991  Validation loss = 4.5478  \n",
      "\n",
      "Fold: 4  Epoch: 123  Training loss = 1.5990  Validation loss = 4.5472  \n",
      "\n",
      "Fold: 4  Epoch: 124  Training loss = 1.5990  Validation loss = 4.5471  \n",
      "\n",
      "Fold: 4  Epoch: 125  Training loss = 1.5989  Validation loss = 4.5464  \n",
      "\n",
      "Fold: 4  Epoch: 126  Training loss = 1.5988  Validation loss = 4.5460  \n",
      "\n",
      "Fold: 4  Epoch: 127  Training loss = 1.5986  Validation loss = 4.5450  \n",
      "\n",
      "Fold: 4  Epoch: 128  Training loss = 1.5984  Validation loss = 4.5440  \n",
      "\n",
      "Fold: 4  Epoch: 129  Training loss = 1.5982  Validation loss = 4.5431  \n",
      "\n",
      "Fold: 4  Epoch: 130  Training loss = 1.5982  Validation loss = 4.5427  \n",
      "\n",
      "Fold: 4  Epoch: 131  Training loss = 1.5981  Validation loss = 4.5422  \n",
      "\n",
      "Fold: 4  Epoch: 132  Training loss = 1.5979  Validation loss = 4.5414  \n",
      "\n",
      "Fold: 4  Epoch: 133  Training loss = 1.5977  Validation loss = 4.5405  \n",
      "\n",
      "Fold: 4  Epoch: 134  Training loss = 1.5976  Validation loss = 4.5400  \n",
      "\n",
      "Fold: 4  Epoch: 135  Training loss = 1.5975  Validation loss = 4.5392  \n",
      "\n",
      "Fold: 4  Epoch: 136  Training loss = 1.5973  Validation loss = 4.5384  \n",
      "\n",
      "Fold: 4  Epoch: 137  Training loss = 1.5971  Validation loss = 4.5367  \n",
      "\n",
      "Fold: 4  Epoch: 138  Training loss = 1.5969  Validation loss = 4.5361  \n",
      "\n",
      "Fold: 4  Epoch: 139  Training loss = 1.5968  Validation loss = 4.5351  \n",
      "\n",
      "Fold: 4  Epoch: 140  Training loss = 1.5966  Validation loss = 4.5343  \n",
      "\n",
      "Fold: 4  Epoch: 141  Training loss = 1.5965  Validation loss = 4.5336  \n",
      "\n",
      "Fold: 4  Epoch: 142  Training loss = 1.5963  Validation loss = 4.5323  \n",
      "\n",
      "Fold: 4  Epoch: 143  Training loss = 1.5960  Validation loss = 4.5311  \n",
      "\n",
      "Fold: 4  Epoch: 144  Training loss = 1.5959  Validation loss = 4.5303  \n",
      "\n",
      "Fold: 4  Epoch: 145  Training loss = 1.5958  Validation loss = 4.5297  \n",
      "\n",
      "Fold: 4  Epoch: 146  Training loss = 1.5957  Validation loss = 4.5291  \n",
      "\n",
      "Fold: 4  Epoch: 147  Training loss = 1.5956  Validation loss = 4.5285  \n",
      "\n",
      "Fold: 4  Epoch: 148  Training loss = 1.5955  Validation loss = 4.5280  \n",
      "\n",
      "Fold: 4  Epoch: 149  Training loss = 1.5953  Validation loss = 4.5273  \n",
      "\n",
      "Fold: 4  Epoch: 150  Training loss = 1.5952  Validation loss = 4.5267  \n",
      "\n",
      "Fold: 4  Epoch: 151  Training loss = 1.5952  Validation loss = 4.5265  \n",
      "\n",
      "Fold: 4  Epoch: 152  Training loss = 1.5950  Validation loss = 4.5254  \n",
      "\n",
      "Fold: 4  Epoch: 153  Training loss = 1.5949  Validation loss = 4.5250  \n",
      "\n",
      "Fold: 4  Epoch: 154  Training loss = 1.5948  Validation loss = 4.5243  \n",
      "\n",
      "Fold: 4  Epoch: 155  Training loss = 1.5947  Validation loss = 4.5238  \n",
      "\n",
      "Fold: 4  Epoch: 156  Training loss = 1.5945  Validation loss = 4.5229  \n",
      "\n",
      "Fold: 4  Epoch: 157  Training loss = 1.5942  Validation loss = 4.5209  \n",
      "\n",
      "Fold: 4  Epoch: 158  Training loss = 1.5940  Validation loss = 4.5198  \n",
      "\n",
      "Fold: 4  Epoch: 159  Training loss = 1.5939  Validation loss = 4.5190  \n",
      "\n",
      "Fold: 4  Epoch: 160  Training loss = 1.5938  Validation loss = 4.5187  \n",
      "\n",
      "Fold: 4  Epoch: 161  Training loss = 1.5937  Validation loss = 4.5182  \n",
      "\n",
      "Fold: 4  Epoch: 162  Training loss = 1.5935  Validation loss = 4.5169  \n",
      "\n",
      "Fold: 4  Epoch: 163  Training loss = 1.5934  Validation loss = 4.5168  \n",
      "\n",
      "Fold: 4  Epoch: 164  Training loss = 1.5933  Validation loss = 4.5160  \n",
      "\n",
      "Fold: 4  Epoch: 165  Training loss = 1.5932  Validation loss = 4.5153  \n",
      "\n",
      "Fold: 4  Epoch: 166  Training loss = 1.5930  Validation loss = 4.5143  \n",
      "\n",
      "Fold: 4  Epoch: 167  Training loss = 1.5929  Validation loss = 4.5139  \n",
      "\n",
      "Fold: 4  Epoch: 168  Training loss = 1.5929  Validation loss = 4.5137  \n",
      "\n",
      "Fold: 4  Epoch: 169  Training loss = 1.5928  Validation loss = 4.5134  \n",
      "\n",
      "Fold: 4  Epoch: 170  Training loss = 1.5928  Validation loss = 4.5133  \n",
      "\n",
      "Fold: 4  Epoch: 171  Training loss = 1.5927  Validation loss = 4.5125  \n",
      "\n",
      "Fold: 4  Epoch: 172  Training loss = 1.5925  Validation loss = 4.5115  \n",
      "\n",
      "Fold: 4  Epoch: 173  Training loss = 1.5924  Validation loss = 4.5109  \n",
      "\n",
      "Fold: 4  Epoch: 174  Training loss = 1.5922  Validation loss = 4.5100  \n",
      "\n",
      "Fold: 4  Epoch: 175  Training loss = 1.5921  Validation loss = 4.5093  \n",
      "\n",
      "Fold: 4  Epoch: 176  Training loss = 1.5919  Validation loss = 4.5084  \n",
      "\n",
      "Fold: 4  Epoch: 177  Training loss = 1.5918  Validation loss = 4.5077  \n",
      "\n",
      "Fold: 4  Epoch: 178  Training loss = 1.5918  Validation loss = 4.5076  \n",
      "\n",
      "Fold: 4  Epoch: 179  Training loss = 1.5917  Validation loss = 4.5072  \n",
      "\n",
      "Fold: 4  Epoch: 180  Training loss = 1.5915  Validation loss = 4.5062  \n",
      "\n",
      "Fold: 4  Epoch: 181  Training loss = 1.5914  Validation loss = 4.5053  \n",
      "\n",
      "Fold: 4  Epoch: 182  Training loss = 1.5914  Validation loss = 4.5054  \n",
      "\n",
      "Fold: 4  Epoch: 183  Training loss = 1.5912  Validation loss = 4.5045  \n",
      "\n",
      "Fold: 4  Epoch: 184  Training loss = 1.5912  Validation loss = 4.5043  \n",
      "\n",
      "Fold: 4  Epoch: 185  Training loss = 1.5911  Validation loss = 4.5042  \n",
      "\n",
      "Fold: 4  Epoch: 186  Training loss = 1.5911  Validation loss = 4.5038  \n",
      "\n",
      "Fold: 4  Epoch: 187  Training loss = 1.5909  Validation loss = 4.5029  \n",
      "\n",
      "Fold: 4  Epoch: 188  Training loss = 1.5908  Validation loss = 4.5025  \n",
      "\n",
      "Fold: 4  Epoch: 189  Training loss = 1.5907  Validation loss = 4.5016  \n",
      "\n",
      "Fold: 4  Epoch: 190  Training loss = 1.5905  Validation loss = 4.5008  \n",
      "\n",
      "Fold: 4  Epoch: 191  Training loss = 1.5904  Validation loss = 4.4998  \n",
      "\n",
      "Fold: 4  Epoch: 192  Training loss = 1.5902  Validation loss = 4.4991  \n",
      "\n",
      "Fold: 4  Epoch: 193  Training loss = 1.5901  Validation loss = 4.4985  \n",
      "\n",
      "Fold: 4  Epoch: 194  Training loss = 1.5900  Validation loss = 4.4975  \n",
      "\n",
      "Fold: 4  Epoch: 195  Training loss = 1.5899  Validation loss = 4.4971  \n",
      "\n",
      "Fold: 4  Epoch: 196  Training loss = 1.5899  Validation loss = 4.4969  \n",
      "\n",
      "Fold: 4  Epoch: 197  Training loss = 1.5898  Validation loss = 4.4965  \n",
      "\n",
      "Fold: 4  Epoch: 198  Training loss = 1.5897  Validation loss = 4.4963  \n",
      "\n",
      "Fold: 4  Epoch: 199  Training loss = 1.5897  Validation loss = 4.4962  \n",
      "\n",
      "Fold: 4  Epoch: 200  Training loss = 1.5896  Validation loss = 4.4955  \n",
      "\n",
      "Fold: 4  Epoch: 201  Training loss = 1.5894  Validation loss = 4.4944  \n",
      "\n",
      "Fold: 4  Epoch: 202  Training loss = 1.5893  Validation loss = 4.4938  \n",
      "\n",
      "Fold: 4  Epoch: 203  Training loss = 1.5891  Validation loss = 4.4926  \n",
      "\n",
      "Fold: 4  Epoch: 204  Training loss = 1.5890  Validation loss = 4.4920  \n",
      "\n",
      "Fold: 4  Epoch: 205  Training loss = 1.5889  Validation loss = 4.4911  \n",
      "\n",
      "Fold: 4  Epoch: 206  Training loss = 1.5888  Validation loss = 4.4909  \n",
      "\n",
      "Fold: 4  Epoch: 207  Training loss = 1.5886  Validation loss = 4.4896  \n",
      "\n",
      "Fold: 4  Epoch: 208  Training loss = 1.5885  Validation loss = 4.4891  \n",
      "\n",
      "Fold: 4  Epoch: 209  Training loss = 1.5884  Validation loss = 4.4884  \n",
      "\n",
      "Fold: 4  Epoch: 210  Training loss = 1.5884  Validation loss = 4.4883  \n",
      "\n",
      "Fold: 4  Epoch: 211  Training loss = 1.5883  Validation loss = 4.4879  \n",
      "\n",
      "Fold: 4  Epoch: 212  Training loss = 1.5882  Validation loss = 4.4874  \n",
      "\n",
      "Fold: 4  Epoch: 213  Training loss = 1.5881  Validation loss = 4.4867  \n",
      "\n",
      "Fold: 4  Epoch: 214  Training loss = 1.5880  Validation loss = 4.4863  \n",
      "\n",
      "Fold: 4  Epoch: 215  Training loss = 1.5880  Validation loss = 4.4860  \n",
      "\n",
      "Fold: 4  Epoch: 216  Training loss = 1.5878  Validation loss = 4.4853  \n",
      "\n",
      "Fold: 4  Epoch: 217  Training loss = 1.5878  Validation loss = 4.4852  \n",
      "\n",
      "Fold: 4  Epoch: 218  Training loss = 1.5877  Validation loss = 4.4847  \n",
      "\n",
      "Fold: 4  Epoch: 219  Training loss = 1.5877  Validation loss = 4.4843  \n",
      "\n",
      "Fold: 4  Epoch: 220  Training loss = 1.5876  Validation loss = 4.4838  \n",
      "\n",
      "Fold: 4  Epoch: 221  Training loss = 1.5875  Validation loss = 4.4834  \n",
      "\n",
      "Fold: 4  Epoch: 222  Training loss = 1.5873  Validation loss = 4.4825  \n",
      "\n",
      "Fold: 4  Epoch: 223  Training loss = 1.5872  Validation loss = 4.4818  \n",
      "\n",
      "Fold: 4  Epoch: 224  Training loss = 1.5872  Validation loss = 4.4816  \n",
      "\n",
      "Fold: 4  Epoch: 225  Training loss = 1.5871  Validation loss = 4.4808  \n",
      "\n",
      "Fold: 4  Epoch: 226  Training loss = 1.5870  Validation loss = 4.4805  \n",
      "\n",
      "Fold: 4  Epoch: 227  Training loss = 1.5869  Validation loss = 4.4801  \n",
      "\n",
      "Fold: 4  Epoch: 228  Training loss = 1.5869  Validation loss = 4.4799  \n",
      "\n",
      "Fold: 4  Epoch: 229  Training loss = 1.5867  Validation loss = 4.4788  \n",
      "\n",
      "Fold: 4  Epoch: 230  Training loss = 1.5866  Validation loss = 4.4781  \n",
      "\n",
      "Fold: 4  Epoch: 231  Training loss = 1.5866  Validation loss = 4.4779  \n",
      "\n",
      "Fold: 4  Epoch: 232  Training loss = 1.5866  Validation loss = 4.4779  \n",
      "\n",
      "Fold: 4  Epoch: 233  Training loss = 1.5864  Validation loss = 4.4772  \n",
      "\n",
      "Fold: 4  Epoch: 234  Training loss = 1.5864  Validation loss = 4.4769  \n",
      "\n",
      "Fold: 4  Epoch: 235  Training loss = 1.5863  Validation loss = 4.4766  \n",
      "\n",
      "Fold: 4  Epoch: 236  Training loss = 1.5861  Validation loss = 4.4755  \n",
      "\n",
      "Fold: 4  Epoch: 237  Training loss = 1.5861  Validation loss = 4.4752  \n",
      "\n",
      "Fold: 4  Epoch: 238  Training loss = 1.5860  Validation loss = 4.4747  \n",
      "\n",
      "Fold: 4  Epoch: 239  Training loss = 1.5859  Validation loss = 4.4738  \n",
      "\n",
      "Fold: 4  Epoch: 240  Training loss = 1.5857  Validation loss = 4.4732  \n",
      "\n",
      "Fold: 4  Epoch: 241  Training loss = 1.5856  Validation loss = 4.4724  \n",
      "\n",
      "Fold: 4  Epoch: 242  Training loss = 1.5856  Validation loss = 4.4721  \n",
      "\n",
      "Fold: 4  Epoch: 243  Training loss = 1.5855  Validation loss = 4.4717  \n",
      "\n",
      "Fold: 4  Epoch: 244  Training loss = 1.5853  Validation loss = 4.4705  \n",
      "\n",
      "Fold: 4  Epoch: 245  Training loss = 1.5852  Validation loss = 4.4702  \n",
      "\n",
      "Fold: 4  Epoch: 246  Training loss = 1.5851  Validation loss = 4.4696  \n",
      "\n",
      "Fold: 4  Epoch: 247  Training loss = 1.5850  Validation loss = 4.4686  \n",
      "\n",
      "Fold: 4  Epoch: 248  Training loss = 1.5848  Validation loss = 4.4677  \n",
      "\n",
      "Fold: 4  Epoch: 249  Training loss = 1.5848  Validation loss = 4.4675  \n",
      "\n",
      "Fold: 4  Epoch: 250  Training loss = 1.5847  Validation loss = 4.4667  \n",
      "\n",
      "Fold: 4  Epoch: 251  Training loss = 1.5846  Validation loss = 4.4664  \n",
      "\n",
      "Fold: 4  Epoch: 252  Training loss = 1.5845  Validation loss = 4.4658  \n",
      "\n",
      "Fold: 4  Epoch: 253  Training loss = 1.5843  Validation loss = 4.4643  \n",
      "\n",
      "Fold: 4  Epoch: 254  Training loss = 1.5842  Validation loss = 4.4638  \n",
      "\n",
      "Fold: 4  Epoch: 255  Training loss = 1.5842  Validation loss = 4.4639  \n",
      "\n",
      "Fold: 4  Epoch: 256  Training loss = 1.5841  Validation loss = 4.4633  \n",
      "\n",
      "Fold: 4  Epoch: 257  Training loss = 1.5840  Validation loss = 4.4630  \n",
      "\n",
      "Fold: 4  Epoch: 258  Training loss = 1.5839  Validation loss = 4.4624  \n",
      "\n",
      "Fold: 4  Epoch: 259  Training loss = 1.5839  Validation loss = 4.4620  \n",
      "\n",
      "Fold: 4  Epoch: 260  Training loss = 1.5838  Validation loss = 4.4613  \n",
      "\n",
      "Fold: 4  Epoch: 261  Training loss = 1.5837  Validation loss = 4.4607  \n",
      "\n",
      "Fold: 4  Epoch: 262  Training loss = 1.5836  Validation loss = 4.4602  \n",
      "\n",
      "Fold: 4  Epoch: 263  Training loss = 1.5836  Validation loss = 4.4603  \n",
      "\n",
      "Fold: 4  Epoch: 264  Training loss = 1.5835  Validation loss = 4.4600  \n",
      "\n",
      "Fold: 4  Epoch: 265  Training loss = 1.5834  Validation loss = 4.4593  \n",
      "\n",
      "Fold: 4  Epoch: 266  Training loss = 1.5834  Validation loss = 4.4592  \n",
      "\n",
      "Fold: 4  Epoch: 267  Training loss = 1.5833  Validation loss = 4.4584  \n",
      "\n",
      "Fold: 4  Epoch: 268  Training loss = 1.5831  Validation loss = 4.4577  \n",
      "\n",
      "Fold: 4  Epoch: 269  Training loss = 1.5830  Validation loss = 4.4570  \n",
      "\n",
      "Fold: 4  Epoch: 270  Training loss = 1.5828  Validation loss = 4.4557  \n",
      "\n",
      "Fold: 4  Epoch: 271  Training loss = 1.5826  Validation loss = 4.4546  \n",
      "\n",
      "Fold: 4  Epoch: 272  Training loss = 1.5825  Validation loss = 4.4539  \n",
      "\n",
      "Fold: 4  Epoch: 273  Training loss = 1.5825  Validation loss = 4.4533  \n",
      "\n",
      "Fold: 4  Epoch: 274  Training loss = 1.5824  Validation loss = 4.4528  \n",
      "\n",
      "Fold: 4  Epoch: 275  Training loss = 1.5822  Validation loss = 4.4521  \n",
      "\n",
      "Fold: 4  Epoch: 276  Training loss = 1.5822  Validation loss = 4.4519  \n",
      "\n",
      "Fold: 4  Epoch: 277  Training loss = 1.5821  Validation loss = 4.4514  \n",
      "\n",
      "Fold: 4  Epoch: 278  Training loss = 1.5820  Validation loss = 4.4508  \n",
      "\n",
      "Fold: 4  Epoch: 279  Training loss = 1.5820  Validation loss = 4.4507  \n",
      "\n",
      "Fold: 4  Epoch: 280  Training loss = 1.5819  Validation loss = 4.4499  \n",
      "\n",
      "Fold: 4  Epoch: 281  Training loss = 1.5819  Validation loss = 4.4499  \n",
      "\n",
      "Fold: 4  Epoch: 282  Training loss = 1.5818  Validation loss = 4.4491  \n",
      "\n",
      "Fold: 4  Epoch: 283  Training loss = 1.5818  Validation loss = 4.4496  \n",
      "\n",
      "Fold: 4  Epoch: 284  Training loss = 1.5818  Validation loss = 4.4493  \n",
      "\n",
      "Fold: 4  Epoch: 285  Training loss = 1.5816  Validation loss = 4.4480  \n",
      "\n",
      "Fold: 4  Epoch: 286  Training loss = 1.5815  Validation loss = 4.4477  \n",
      "\n",
      "Fold: 4  Epoch: 287  Training loss = 1.5815  Validation loss = 4.4475  \n",
      "\n",
      "Fold: 4  Epoch: 288  Training loss = 1.5815  Validation loss = 4.4474  \n",
      "\n",
      "Fold: 4  Epoch: 289  Training loss = 1.5814  Validation loss = 4.4470  \n",
      "\n",
      "Fold: 4  Epoch: 290  Training loss = 1.5813  Validation loss = 4.4466  \n",
      "\n",
      "Fold: 4  Epoch: 291  Training loss = 1.5813  Validation loss = 4.4467  \n",
      "\n",
      "Fold: 4  Epoch: 292  Training loss = 1.5813  Validation loss = 4.4468  \n",
      "\n",
      "Fold: 4  Epoch: 293  Training loss = 1.5813  Validation loss = 4.4462  \n",
      "\n",
      "Fold: 4  Epoch: 294  Training loss = 1.5812  Validation loss = 4.4457  \n",
      "\n",
      "Fold: 4  Epoch: 295  Training loss = 1.5810  Validation loss = 4.4448  \n",
      "\n",
      "Fold: 4  Epoch: 296  Training loss = 1.5809  Validation loss = 4.4438  \n",
      "\n",
      "Fold: 4  Epoch: 297  Training loss = 1.5808  Validation loss = 4.4432  \n",
      "\n",
      "Fold: 4  Epoch: 298  Training loss = 1.5807  Validation loss = 4.4428  \n",
      "\n",
      "Fold: 4  Epoch: 299  Training loss = 1.5806  Validation loss = 4.4421  \n",
      "\n",
      "Fold: 4  Epoch: 300  Training loss = 1.5806  Validation loss = 4.4417  \n",
      "\n",
      "Fold: 4  Epoch: 301  Training loss = 1.5805  Validation loss = 4.4413  \n",
      "\n",
      "Fold: 4  Epoch: 302  Training loss = 1.5804  Validation loss = 4.4409  \n",
      "\n",
      "Fold: 4  Epoch: 303  Training loss = 1.5804  Validation loss = 4.4405  \n",
      "\n",
      "Fold: 4  Epoch: 304  Training loss = 1.5803  Validation loss = 4.4403  \n",
      "\n",
      "Fold: 4  Epoch: 305  Training loss = 1.5802  Validation loss = 4.4398  \n",
      "\n",
      "Fold: 4  Epoch: 306  Training loss = 1.5802  Validation loss = 4.4394  \n",
      "\n",
      "Fold: 4  Epoch: 307  Training loss = 1.5801  Validation loss = 4.4387  \n",
      "\n",
      "Fold: 4  Epoch: 308  Training loss = 1.5800  Validation loss = 4.4383  \n",
      "\n",
      "Fold: 4  Epoch: 309  Training loss = 1.5799  Validation loss = 4.4380  \n",
      "\n",
      "Fold: 4  Epoch: 310  Training loss = 1.5799  Validation loss = 4.4377  \n",
      "\n",
      "Fold: 4  Epoch: 311  Training loss = 1.5798  Validation loss = 4.4374  \n",
      "\n",
      "Fold: 4  Epoch: 312  Training loss = 1.5798  Validation loss = 4.4372  \n",
      "\n",
      "Fold: 4  Epoch: 313  Training loss = 1.5797  Validation loss = 4.4362  \n",
      "\n",
      "Fold: 4  Epoch: 314  Training loss = 1.5796  Validation loss = 4.4359  \n",
      "\n",
      "Fold: 4  Epoch: 315  Training loss = 1.5796  Validation loss = 4.4362  \n",
      "\n",
      "Fold: 4  Epoch: 316  Training loss = 1.5796  Validation loss = 4.4361  \n",
      "\n",
      "Fold: 4  Epoch: 317  Training loss = 1.5795  Validation loss = 4.4357  \n",
      "\n",
      "Fold: 4  Epoch: 318  Training loss = 1.5794  Validation loss = 4.4350  \n",
      "\n",
      "Fold: 4  Epoch: 319  Training loss = 1.5794  Validation loss = 4.4346  \n",
      "\n",
      "Fold: 4  Epoch: 320  Training loss = 1.5793  Validation loss = 4.4344  \n",
      "\n",
      "Fold: 4  Epoch: 321  Training loss = 1.5793  Validation loss = 4.4340  \n",
      "\n",
      "Fold: 4  Epoch: 322  Training loss = 1.5793  Validation loss = 4.4344  \n",
      "\n",
      "Fold: 4  Epoch: 323  Training loss = 1.5792  Validation loss = 4.4341  \n",
      "\n",
      "Fold: 4  Epoch: 324  Training loss = 1.5791  Validation loss = 4.4334  \n",
      "\n",
      "Fold: 4  Epoch: 325  Training loss = 1.5791  Validation loss = 4.4334  \n",
      "\n",
      "Fold: 4  Epoch: 326  Training loss = 1.5791  Validation loss = 4.4334  \n",
      "\n",
      "Fold: 4  Epoch: 327  Training loss = 1.5791  Validation loss = 4.4331  \n",
      "\n",
      "Fold: 4  Epoch: 328  Training loss = 1.5790  Validation loss = 4.4326  \n",
      "\n",
      "Fold: 4  Epoch: 329  Training loss = 1.5789  Validation loss = 4.4319  \n",
      "\n",
      "Fold: 4  Epoch: 330  Training loss = 1.5789  Validation loss = 4.4319  \n",
      "\n",
      "Fold: 4  Epoch: 331  Training loss = 1.5788  Validation loss = 4.4317  \n",
      "\n",
      "Fold: 4  Epoch: 332  Training loss = 1.5788  Validation loss = 4.4312  \n",
      "\n",
      "Fold: 4  Epoch: 333  Training loss = 1.5787  Validation loss = 4.4310  \n",
      "\n",
      "Fold: 4  Epoch: 334  Training loss = 1.5786  Validation loss = 4.4304  \n",
      "\n",
      "Fold: 4  Epoch: 335  Training loss = 1.5785  Validation loss = 4.4295  \n",
      "\n",
      "Fold: 4  Epoch: 336  Training loss = 1.5784  Validation loss = 4.4291  \n",
      "\n",
      "Fold: 4  Epoch: 337  Training loss = 1.5783  Validation loss = 4.4279  \n",
      "\n",
      "Fold: 4  Epoch: 338  Training loss = 1.5782  Validation loss = 4.4273  \n",
      "\n",
      "Fold: 4  Epoch: 339  Training loss = 1.5781  Validation loss = 4.4271  \n",
      "\n",
      "Fold: 4  Epoch: 340  Training loss = 1.5781  Validation loss = 4.4266  \n",
      "\n",
      "Fold: 4  Epoch: 341  Training loss = 1.5779  Validation loss = 4.4252  \n",
      "\n",
      "Fold: 4  Epoch: 342  Training loss = 1.5778  Validation loss = 4.4247  \n",
      "\n",
      "Fold: 4  Epoch: 343  Training loss = 1.5777  Validation loss = 4.4244  \n",
      "\n",
      "Fold: 4  Epoch: 344  Training loss = 1.5777  Validation loss = 4.4239  \n",
      "\n",
      "Fold: 4  Epoch: 345  Training loss = 1.5776  Validation loss = 4.4235  \n",
      "\n",
      "Fold: 4  Epoch: 346  Training loss = 1.5775  Validation loss = 4.4232  \n",
      "\n",
      "Fold: 4  Epoch: 347  Training loss = 1.5774  Validation loss = 4.4226  \n",
      "\n",
      "Fold: 4  Epoch: 348  Training loss = 1.5774  Validation loss = 4.4222  \n",
      "\n",
      "Fold: 4  Epoch: 349  Training loss = 1.5773  Validation loss = 4.4215  \n",
      "\n",
      "Fold: 4  Epoch: 350  Training loss = 1.5772  Validation loss = 4.4210  \n",
      "\n",
      "Fold: 4  Epoch: 351  Training loss = 1.5771  Validation loss = 4.4205  \n",
      "\n",
      "Fold: 4  Epoch: 352  Training loss = 1.5770  Validation loss = 4.4196  \n",
      "\n",
      "Fold: 4  Epoch: 353  Training loss = 1.5769  Validation loss = 4.4189  \n",
      "\n",
      "Fold: 4  Epoch: 354  Training loss = 1.5769  Validation loss = 4.4190  \n",
      "\n",
      "Fold: 4  Epoch: 355  Training loss = 1.5768  Validation loss = 4.4184  \n",
      "\n",
      "Fold: 4  Epoch: 356  Training loss = 1.5767  Validation loss = 4.4179  \n",
      "\n",
      "Fold: 4  Epoch: 357  Training loss = 1.5767  Validation loss = 4.4174  \n",
      "\n",
      "Fold: 4  Epoch: 358  Training loss = 1.5766  Validation loss = 4.4174  \n",
      "\n",
      "Fold: 4  Epoch: 359  Training loss = 1.5765  Validation loss = 4.4167  \n",
      "\n",
      "Fold: 4  Epoch: 360  Training loss = 1.5765  Validation loss = 4.4164  \n",
      "\n",
      "Fold: 4  Epoch: 361  Training loss = 1.5764  Validation loss = 4.4162  \n",
      "\n",
      "Fold: 4  Epoch: 362  Training loss = 1.5764  Validation loss = 4.4158  \n",
      "\n",
      "Fold: 4  Epoch: 363  Training loss = 1.5764  Validation loss = 4.4158  \n",
      "\n",
      "Fold: 4  Epoch: 364  Training loss = 1.5763  Validation loss = 4.4155  \n",
      "\n",
      "Fold: 4  Epoch: 365  Training loss = 1.5762  Validation loss = 4.4150  \n",
      "\n",
      "Fold: 4  Epoch: 366  Training loss = 1.5761  Validation loss = 4.4143  \n",
      "\n",
      "Fold: 4  Epoch: 367  Training loss = 1.5760  Validation loss = 4.4137  \n",
      "\n",
      "Fold: 4  Epoch: 368  Training loss = 1.5760  Validation loss = 4.4136  \n",
      "\n",
      "Fold: 4  Epoch: 369  Training loss = 1.5760  Validation loss = 4.4132  \n",
      "\n",
      "Fold: 4  Epoch: 370  Training loss = 1.5759  Validation loss = 4.4126  \n",
      "\n",
      "Fold: 4  Epoch: 371  Training loss = 1.5758  Validation loss = 4.4125  \n",
      "\n",
      "Fold: 4  Epoch: 372  Training loss = 1.5758  Validation loss = 4.4119  \n",
      "\n",
      "Fold: 4  Epoch: 373  Training loss = 1.5757  Validation loss = 4.4117  \n",
      "\n",
      "Fold: 4  Epoch: 374  Training loss = 1.5757  Validation loss = 4.4115  \n",
      "\n",
      "Fold: 4  Epoch: 375  Training loss = 1.5756  Validation loss = 4.4112  \n",
      "\n",
      "Fold: 4  Epoch: 376  Training loss = 1.5755  Validation loss = 4.4101  \n",
      "\n",
      "Fold: 4  Epoch: 377  Training loss = 1.5754  Validation loss = 4.4100  \n",
      "\n",
      "Fold: 4  Epoch: 378  Training loss = 1.5754  Validation loss = 4.4100  \n",
      "\n",
      "Fold: 4  Epoch: 379  Training loss = 1.5754  Validation loss = 4.4099  \n",
      "\n",
      "Fold: 4  Epoch: 380  Training loss = 1.5753  Validation loss = 4.4089  \n",
      "\n",
      "Fold: 4  Epoch: 381  Training loss = 1.5752  Validation loss = 4.4084  \n",
      "\n",
      "Fold: 4  Epoch: 382  Training loss = 1.5752  Validation loss = 4.4082  \n",
      "\n",
      "Fold: 4  Epoch: 383  Training loss = 1.5751  Validation loss = 4.4078  \n",
      "\n",
      "Fold: 4  Epoch: 384  Training loss = 1.5751  Validation loss = 4.4079  \n",
      "\n",
      "Fold: 4  Epoch: 385  Training loss = 1.5751  Validation loss = 4.4075  \n",
      "\n",
      "Fold: 4  Epoch: 386  Training loss = 1.5750  Validation loss = 4.4072  \n",
      "\n",
      "Fold: 4  Epoch: 387  Training loss = 1.5750  Validation loss = 4.4068  \n",
      "\n",
      "Fold: 4  Epoch: 388  Training loss = 1.5749  Validation loss = 4.4067  \n",
      "\n",
      "Fold: 4  Epoch: 389  Training loss = 1.5749  Validation loss = 4.4066  \n",
      "\n",
      "Fold: 4  Epoch: 390  Training loss = 1.5749  Validation loss = 4.4064  \n",
      "\n",
      "Fold: 4  Epoch: 391  Training loss = 1.5748  Validation loss = 4.4058  \n",
      "\n",
      "Fold: 4  Epoch: 392  Training loss = 1.5748  Validation loss = 4.4056  \n",
      "\n",
      "Fold: 4  Epoch: 393  Training loss = 1.5747  Validation loss = 4.4054  \n",
      "\n",
      "Fold: 4  Epoch: 394  Training loss = 1.5747  Validation loss = 4.4050  \n",
      "\n",
      "Fold: 4  Epoch: 395  Training loss = 1.5746  Validation loss = 4.4049  \n",
      "\n",
      "Fold: 4  Epoch: 396  Training loss = 1.5746  Validation loss = 4.4044  \n",
      "\n",
      "Fold: 4  Epoch: 397  Training loss = 1.5745  Validation loss = 4.4040  \n",
      "\n",
      "Fold: 4  Epoch: 398  Training loss = 1.5744  Validation loss = 4.4036  \n",
      "\n",
      "Fold: 4  Epoch: 399  Training loss = 1.5744  Validation loss = 4.4037  \n",
      "\n",
      "Fold: 4  Epoch: 400  Training loss = 1.5744  Validation loss = 4.4034  \n",
      "\n",
      "Fold: 4  Epoch: 401  Training loss = 1.5743  Validation loss = 4.4030  \n",
      "\n",
      "Fold: 4  Epoch: 402  Training loss = 1.5742  Validation loss = 4.4024  \n",
      "\n",
      "Fold: 4  Epoch: 403  Training loss = 1.5742  Validation loss = 4.4024  \n",
      "\n",
      "Fold: 4  Epoch: 404  Training loss = 1.5740  Validation loss = 4.4012  \n",
      "\n",
      "Fold: 4  Epoch: 405  Training loss = 1.5740  Validation loss = 4.4012  \n",
      "\n",
      "Fold: 4  Epoch: 406  Training loss = 1.5740  Validation loss = 4.4007  \n",
      "\n",
      "Fold: 4  Epoch: 407  Training loss = 1.5739  Validation loss = 4.4003  \n",
      "\n",
      "Fold: 4  Epoch: 408  Training loss = 1.5739  Validation loss = 4.4002  \n",
      "\n",
      "Fold: 4  Epoch: 409  Training loss = 1.5738  Validation loss = 4.4002  \n",
      "\n",
      "Fold: 4  Epoch: 410  Training loss = 1.5738  Validation loss = 4.3998  \n",
      "\n",
      "Fold: 4  Epoch: 411  Training loss = 1.5737  Validation loss = 4.3991  \n",
      "\n",
      "Fold: 4  Epoch: 412  Training loss = 1.5736  Validation loss = 4.3986  \n",
      "\n",
      "Fold: 4  Epoch: 413  Training loss = 1.5736  Validation loss = 4.3982  \n",
      "\n",
      "Fold: 4  Epoch: 414  Training loss = 1.5735  Validation loss = 4.3977  \n",
      "\n",
      "Fold: 4  Epoch: 415  Training loss = 1.5734  Validation loss = 4.3974  \n",
      "\n",
      "Fold: 4  Epoch: 416  Training loss = 1.5734  Validation loss = 4.3970  \n",
      "\n",
      "Fold: 4  Epoch: 417  Training loss = 1.5733  Validation loss = 4.3968  \n",
      "\n",
      "Fold: 4  Epoch: 418  Training loss = 1.5732  Validation loss = 4.3961  \n",
      "\n",
      "Fold: 4  Epoch: 419  Training loss = 1.5732  Validation loss = 4.3961  \n",
      "\n",
      "Fold: 4  Epoch: 420  Training loss = 1.5732  Validation loss = 4.3957  \n",
      "\n",
      "Fold: 4  Epoch: 421  Training loss = 1.5731  Validation loss = 4.3956  \n",
      "\n",
      "Fold: 4  Epoch: 422  Training loss = 1.5732  Validation loss = 4.3963  \n",
      "\n",
      "Fold: 4  Epoch: 423  Training loss = 1.5731  Validation loss = 4.3957  \n",
      "\n",
      "Fold: 4  Epoch: 424  Training loss = 1.5731  Validation loss = 4.3953  \n",
      "\n",
      "Fold: 4  Epoch: 425  Training loss = 1.5730  Validation loss = 4.3952  \n",
      "\n",
      "Fold: 4  Epoch: 426  Training loss = 1.5730  Validation loss = 4.3950  \n",
      "\n",
      "Fold: 4  Epoch: 427  Training loss = 1.5729  Validation loss = 4.3941  \n",
      "\n",
      "Fold: 4  Epoch: 428  Training loss = 1.5728  Validation loss = 4.3938  \n",
      "\n",
      "Fold: 4  Epoch: 429  Training loss = 1.5728  Validation loss = 4.3939  \n",
      "\n",
      "Fold: 4  Epoch: 430  Training loss = 1.5728  Validation loss = 4.3937  \n",
      "\n",
      "Fold: 4  Epoch: 431  Training loss = 1.5727  Validation loss = 4.3933  \n",
      "\n",
      "Fold: 4  Epoch: 432  Training loss = 1.5726  Validation loss = 4.3927  \n",
      "\n",
      "Fold: 4  Epoch: 433  Training loss = 1.5726  Validation loss = 4.3923  \n",
      "\n",
      "Fold: 4  Epoch: 434  Training loss = 1.5726  Validation loss = 4.3923  \n",
      "\n",
      "Fold: 4  Epoch: 435  Training loss = 1.5725  Validation loss = 4.3919  \n",
      "\n",
      "Fold: 4  Epoch: 436  Training loss = 1.5724  Validation loss = 4.3911  \n",
      "\n",
      "Fold: 4  Epoch: 437  Training loss = 1.5724  Validation loss = 4.3911  \n",
      "\n",
      "Fold: 4  Epoch: 438  Training loss = 1.5723  Validation loss = 4.3903  \n",
      "\n",
      "Fold: 4  Epoch: 439  Training loss = 1.5722  Validation loss = 4.3894  \n",
      "\n",
      "Fold: 4  Epoch: 440  Training loss = 1.5721  Validation loss = 4.3890  \n",
      "\n",
      "Fold: 4  Epoch: 441  Training loss = 1.5720  Validation loss = 4.3882  \n",
      "\n",
      "Fold: 4  Epoch: 442  Training loss = 1.5719  Validation loss = 4.3879  \n",
      "\n",
      "Fold: 4  Epoch: 443  Training loss = 1.5719  Validation loss = 4.3874  \n",
      "\n",
      "Fold: 4  Epoch: 444  Training loss = 1.5718  Validation loss = 4.3870  \n",
      "\n",
      "Fold: 4  Epoch: 445  Training loss = 1.5717  Validation loss = 4.3861  \n",
      "\n",
      "Fold: 4  Epoch: 446  Training loss = 1.5716  Validation loss = 4.3856  \n",
      "\n",
      "Fold: 4  Epoch: 447  Training loss = 1.5715  Validation loss = 4.3849  \n",
      "\n",
      "Fold: 4  Epoch: 448  Training loss = 1.5714  Validation loss = 4.3843  \n",
      "\n",
      "Fold: 4  Epoch: 449  Training loss = 1.5713  Validation loss = 4.3837  \n",
      "\n",
      "Fold: 4  Epoch: 450  Training loss = 1.5712  Validation loss = 4.3830  \n",
      "\n",
      "Fold: 4  Epoch: 451  Training loss = 1.5712  Validation loss = 4.3826  \n",
      "\n",
      "Fold: 4  Epoch: 452  Training loss = 1.5711  Validation loss = 4.3820  \n",
      "\n",
      "Fold: 4  Epoch: 453  Training loss = 1.5710  Validation loss = 4.3815  \n",
      "\n",
      "Fold: 4  Epoch: 454  Training loss = 1.5710  Validation loss = 4.3816  \n",
      "\n",
      "Fold: 4  Epoch: 455  Training loss = 1.5710  Validation loss = 4.3813  \n",
      "\n",
      "Fold: 4  Epoch: 456  Training loss = 1.5709  Validation loss = 4.3806  \n",
      "\n",
      "Fold: 4  Epoch: 457  Training loss = 1.5708  Validation loss = 4.3802  \n",
      "\n",
      "Fold: 4  Epoch: 458  Training loss = 1.5708  Validation loss = 4.3801  \n",
      "\n",
      "Fold: 4  Epoch: 459  Training loss = 1.5707  Validation loss = 4.3795  \n",
      "\n",
      "Fold: 4  Epoch: 460  Training loss = 1.5707  Validation loss = 4.3794  \n",
      "\n",
      "Fold: 4  Epoch: 461  Training loss = 1.5706  Validation loss = 4.3789  \n",
      "\n",
      "Fold: 4  Epoch: 462  Training loss = 1.5706  Validation loss = 4.3785  \n",
      "\n",
      "Fold: 4  Epoch: 463  Training loss = 1.5706  Validation loss = 4.3787  \n",
      "\n",
      "Fold: 4  Epoch: 464  Training loss = 1.5705  Validation loss = 4.3781  \n",
      "\n",
      "Fold: 4  Epoch: 465  Training loss = 1.5705  Validation loss = 4.3782  \n",
      "\n",
      "Fold: 4  Epoch: 466  Training loss = 1.5704  Validation loss = 4.3777  \n",
      "\n",
      "Fold: 4  Epoch: 467  Training loss = 1.5703  Validation loss = 4.3771  \n",
      "\n",
      "Fold: 4  Epoch: 468  Training loss = 1.5704  Validation loss = 4.3772  \n",
      "\n",
      "Fold: 4  Epoch: 469  Training loss = 1.5703  Validation loss = 4.3771  \n",
      "\n",
      "Fold: 4  Epoch: 470  Training loss = 1.5703  Validation loss = 4.3771  \n",
      "\n",
      "Fold: 4  Epoch: 471  Training loss = 1.5703  Validation loss = 4.3767  \n",
      "\n",
      "Fold: 4  Epoch: 472  Training loss = 1.5702  Validation loss = 4.3765  \n",
      "\n",
      "Fold: 4  Epoch: 473  Training loss = 1.5702  Validation loss = 4.3762  \n",
      "\n",
      "Fold: 4  Epoch: 474  Training loss = 1.5702  Validation loss = 4.3762  \n",
      "\n",
      "Fold: 4  Epoch: 475  Training loss = 1.5701  Validation loss = 4.3756  \n",
      "\n",
      "Fold: 4  Epoch: 476  Training loss = 1.5701  Validation loss = 4.3756  \n",
      "\n",
      "Fold: 4  Epoch: 477  Training loss = 1.5700  Validation loss = 4.3751  \n",
      "\n",
      "Fold: 4  Epoch: 478  Training loss = 1.5700  Validation loss = 4.3750  \n",
      "\n",
      "Fold: 4  Epoch: 479  Training loss = 1.5699  Validation loss = 4.3741  \n",
      "\n",
      "Fold: 4  Epoch: 480  Training loss = 1.5698  Validation loss = 4.3736  \n",
      "\n",
      "Fold: 4  Epoch: 481  Training loss = 1.5698  Validation loss = 4.3736  \n",
      "\n",
      "Fold: 4  Epoch: 482  Training loss = 1.5698  Validation loss = 4.3734  \n",
      "\n",
      "Fold: 4  Epoch: 483  Training loss = 1.5698  Validation loss = 4.3736  \n",
      "\n",
      "Fold: 4  Epoch: 484  Training loss = 1.5697  Validation loss = 4.3732  \n",
      "\n",
      "Fold: 4  Epoch: 485  Training loss = 1.5697  Validation loss = 4.3731  \n",
      "\n",
      "Fold: 4  Epoch: 486  Training loss = 1.5697  Validation loss = 4.3731  \n",
      "\n",
      "Fold: 4  Epoch: 487  Training loss = 1.5696  Validation loss = 4.3730  \n",
      "\n",
      "Fold: 4  Epoch: 488  Training loss = 1.5696  Validation loss = 4.3726  \n",
      "\n",
      "Fold: 4  Epoch: 489  Training loss = 1.5695  Validation loss = 4.3722  \n",
      "\n",
      "Fold: 4  Epoch: 490  Training loss = 1.5695  Validation loss = 4.3721  \n",
      "\n",
      "Fold: 4  Epoch: 491  Training loss = 1.5694  Validation loss = 4.3716  \n",
      "\n",
      "Fold: 4  Epoch: 492  Training loss = 1.5694  Validation loss = 4.3714  \n",
      "\n",
      "Fold: 4  Epoch: 493  Training loss = 1.5693  Validation loss = 4.3709  \n",
      "\n",
      "Fold: 4  Epoch: 494  Training loss = 1.5693  Validation loss = 4.3706  \n",
      "\n",
      "Fold: 4  Epoch: 495  Training loss = 1.5692  Validation loss = 4.3704  \n",
      "\n",
      "Fold: 4  Epoch: 496  Training loss = 1.5692  Validation loss = 4.3699  \n",
      "\n",
      "Fold: 4  Epoch: 497  Training loss = 1.5691  Validation loss = 4.3690  \n",
      "\n",
      "Fold: 4  Epoch: 498  Training loss = 1.5690  Validation loss = 4.3690  \n",
      "\n",
      "Fold: 4  Epoch: 499  Training loss = 1.5689  Validation loss = 4.3684  \n",
      "\n",
      "Fold: 4  Epoch: 500  Training loss = 1.5689  Validation loss = 4.3682  \n",
      "\n",
      "Check model:  Fold: 4  Optimal epoch: 500  \n",
      "\n",
      "Fold: 5  Epoch: 1  Training loss = 1.8632  Validation loss = 4.5434  \n",
      "\n",
      "Fold: 5  Epoch: 2  Training loss = 1.8629  Validation loss = 4.5422  \n",
      "\n",
      "Fold: 5  Epoch: 3  Training loss = 1.8627  Validation loss = 4.5417  \n",
      "\n",
      "Fold: 5  Epoch: 4  Training loss = 1.8625  Validation loss = 4.5411  \n",
      "\n",
      "Fold: 5  Epoch: 5  Training loss = 1.8623  Validation loss = 4.5404  \n",
      "\n",
      "Fold: 5  Epoch: 6  Training loss = 1.8620  Validation loss = 4.5393  \n",
      "\n",
      "Fold: 5  Epoch: 7  Training loss = 1.8618  Validation loss = 4.5384  \n",
      "\n",
      "Fold: 5  Epoch: 8  Training loss = 1.8615  Validation loss = 4.5376  \n",
      "\n",
      "Fold: 5  Epoch: 9  Training loss = 1.8613  Validation loss = 4.5370  \n",
      "\n",
      "Fold: 5  Epoch: 10  Training loss = 1.8611  Validation loss = 4.5361  \n",
      "\n",
      "Fold: 5  Epoch: 11  Training loss = 1.8608  Validation loss = 4.5348  \n",
      "\n",
      "Fold: 5  Epoch: 12  Training loss = 1.8604  Validation loss = 4.5335  \n",
      "\n",
      "Fold: 5  Epoch: 13  Training loss = 1.8602  Validation loss = 4.5325  \n",
      "\n",
      "Fold: 5  Epoch: 14  Training loss = 1.8599  Validation loss = 4.5317  \n",
      "\n",
      "Fold: 5  Epoch: 15  Training loss = 1.8596  Validation loss = 4.5308  \n",
      "\n",
      "Fold: 5  Epoch: 16  Training loss = 1.8593  Validation loss = 4.5294  \n",
      "\n",
      "Fold: 5  Epoch: 17  Training loss = 1.8589  Validation loss = 4.5281  \n",
      "\n",
      "Fold: 5  Epoch: 18  Training loss = 1.8584  Validation loss = 4.5262  \n",
      "\n",
      "Fold: 5  Epoch: 19  Training loss = 1.8580  Validation loss = 4.5247  \n",
      "\n",
      "Fold: 5  Epoch: 20  Training loss = 1.8576  Validation loss = 4.5230  \n",
      "\n",
      "Fold: 5  Epoch: 21  Training loss = 1.8574  Validation loss = 4.5224  \n",
      "\n",
      "Fold: 5  Epoch: 22  Training loss = 1.8571  Validation loss = 4.5212  \n",
      "\n",
      "Fold: 5  Epoch: 23  Training loss = 1.8569  Validation loss = 4.5206  \n",
      "\n",
      "Fold: 5  Epoch: 24  Training loss = 1.8566  Validation loss = 4.5195  \n",
      "\n",
      "Fold: 5  Epoch: 25  Training loss = 1.8563  Validation loss = 4.5182  \n",
      "\n",
      "Fold: 5  Epoch: 26  Training loss = 1.8560  Validation loss = 4.5173  \n",
      "\n",
      "Fold: 5  Epoch: 27  Training loss = 1.8557  Validation loss = 4.5160  \n",
      "\n",
      "Fold: 5  Epoch: 28  Training loss = 1.8555  Validation loss = 4.5153  \n",
      "\n",
      "Fold: 5  Epoch: 29  Training loss = 1.8553  Validation loss = 4.5147  \n",
      "\n",
      "Fold: 5  Epoch: 30  Training loss = 1.8551  Validation loss = 4.5138  \n",
      "\n",
      "Fold: 5  Epoch: 31  Training loss = 1.8546  Validation loss = 4.5120  \n",
      "\n",
      "Fold: 5  Epoch: 32  Training loss = 1.8544  Validation loss = 4.5115  \n",
      "\n",
      "Fold: 5  Epoch: 33  Training loss = 1.8542  Validation loss = 4.5105  \n",
      "\n",
      "Fold: 5  Epoch: 34  Training loss = 1.8539  Validation loss = 4.5096  \n",
      "\n",
      "Fold: 5  Epoch: 35  Training loss = 1.8535  Validation loss = 4.5082  \n",
      "\n",
      "Fold: 5  Epoch: 36  Training loss = 1.8534  Validation loss = 4.5078  \n",
      "\n",
      "Fold: 5  Epoch: 37  Training loss = 1.8533  Validation loss = 4.5077  \n",
      "\n",
      "Fold: 5  Epoch: 38  Training loss = 1.8530  Validation loss = 4.5062  \n",
      "\n",
      "Fold: 5  Epoch: 39  Training loss = 1.8526  Validation loss = 4.5048  \n",
      "\n",
      "Fold: 5  Epoch: 40  Training loss = 1.8525  Validation loss = 4.5046  \n",
      "\n",
      "Fold: 5  Epoch: 41  Training loss = 1.8522  Validation loss = 4.5035  \n",
      "\n",
      "Fold: 5  Epoch: 42  Training loss = 1.8520  Validation loss = 4.5027  \n",
      "\n",
      "Fold: 5  Epoch: 43  Training loss = 1.8515  Validation loss = 4.5006  \n",
      "\n",
      "Fold: 5  Epoch: 44  Training loss = 1.8512  Validation loss = 4.4996  \n",
      "\n",
      "Fold: 5  Epoch: 45  Training loss = 1.8510  Validation loss = 4.4988  \n",
      "\n",
      "Fold: 5  Epoch: 46  Training loss = 1.8507  Validation loss = 4.4979  \n",
      "\n",
      "Fold: 5  Epoch: 47  Training loss = 1.8505  Validation loss = 4.4971  \n",
      "\n",
      "Fold: 5  Epoch: 48  Training loss = 1.8502  Validation loss = 4.4961  \n",
      "\n",
      "Fold: 5  Epoch: 49  Training loss = 1.8500  Validation loss = 4.4954  \n",
      "\n",
      "Fold: 5  Epoch: 50  Training loss = 1.8499  Validation loss = 4.4951  \n",
      "\n",
      "Fold: 5  Epoch: 51  Training loss = 1.8496  Validation loss = 4.4938  \n",
      "\n",
      "Fold: 5  Epoch: 52  Training loss = 1.8492  Validation loss = 4.4926  \n",
      "\n",
      "Fold: 5  Epoch: 53  Training loss = 1.8488  Validation loss = 4.4908  \n",
      "\n",
      "Fold: 5  Epoch: 54  Training loss = 1.8485  Validation loss = 4.4898  \n",
      "\n",
      "Fold: 5  Epoch: 55  Training loss = 1.8484  Validation loss = 4.4895  \n",
      "\n",
      "Fold: 5  Epoch: 56  Training loss = 1.8482  Validation loss = 4.4889  \n",
      "\n",
      "Fold: 5  Epoch: 57  Training loss = 1.8478  Validation loss = 4.4875  \n",
      "\n",
      "Fold: 5  Epoch: 58  Training loss = 1.8477  Validation loss = 4.4873  \n",
      "\n",
      "Fold: 5  Epoch: 59  Training loss = 1.8474  Validation loss = 4.4858  \n",
      "\n",
      "Fold: 5  Epoch: 60  Training loss = 1.8472  Validation loss = 4.4848  \n",
      "\n",
      "Fold: 5  Epoch: 61  Training loss = 1.8469  Validation loss = 4.4839  \n",
      "\n",
      "Fold: 5  Epoch: 62  Training loss = 1.8468  Validation loss = 4.4834  \n",
      "\n",
      "Fold: 5  Epoch: 63  Training loss = 1.8466  Validation loss = 4.4825  \n",
      "\n",
      "Fold: 5  Epoch: 64  Training loss = 1.8463  Validation loss = 4.4815  \n",
      "\n",
      "Fold: 5  Epoch: 65  Training loss = 1.8462  Validation loss = 4.4812  \n",
      "\n",
      "Fold: 5  Epoch: 66  Training loss = 1.8460  Validation loss = 4.4806  \n",
      "\n",
      "Fold: 5  Epoch: 67  Training loss = 1.8459  Validation loss = 4.4802  \n",
      "\n",
      "Fold: 5  Epoch: 68  Training loss = 1.8457  Validation loss = 4.4798  \n",
      "\n",
      "Fold: 5  Epoch: 69  Training loss = 1.8456  Validation loss = 4.4794  \n",
      "\n",
      "Fold: 5  Epoch: 70  Training loss = 1.8454  Validation loss = 4.4786  \n",
      "\n",
      "Fold: 5  Epoch: 71  Training loss = 1.8451  Validation loss = 4.4772  \n",
      "\n",
      "Fold: 5  Epoch: 72  Training loss = 1.8449  Validation loss = 4.4768  \n",
      "\n",
      "Fold: 5  Epoch: 73  Training loss = 1.8448  Validation loss = 4.4761  \n",
      "\n",
      "Fold: 5  Epoch: 74  Training loss = 1.8445  Validation loss = 4.4752  \n",
      "\n",
      "Fold: 5  Epoch: 75  Training loss = 1.8444  Validation loss = 4.4749  \n",
      "\n",
      "Fold: 5  Epoch: 76  Training loss = 1.8441  Validation loss = 4.4738  \n",
      "\n",
      "Fold: 5  Epoch: 77  Training loss = 1.8441  Validation loss = 4.4739  \n",
      "\n",
      "Fold: 5  Epoch: 78  Training loss = 1.8440  Validation loss = 4.4734  \n",
      "\n",
      "Fold: 5  Epoch: 79  Training loss = 1.8437  Validation loss = 4.4722  \n",
      "\n",
      "Fold: 5  Epoch: 80  Training loss = 1.8435  Validation loss = 4.4713  \n",
      "\n",
      "Fold: 5  Epoch: 81  Training loss = 1.8432  Validation loss = 4.4702  \n",
      "\n",
      "Fold: 5  Epoch: 82  Training loss = 1.8430  Validation loss = 4.4694  \n",
      "\n",
      "Fold: 5  Epoch: 83  Training loss = 1.8426  Validation loss = 4.4682  \n",
      "\n",
      "Fold: 5  Epoch: 84  Training loss = 1.8425  Validation loss = 4.4677  \n",
      "\n",
      "Fold: 5  Epoch: 85  Training loss = 1.8424  Validation loss = 4.4675  \n",
      "\n",
      "Fold: 5  Epoch: 86  Training loss = 1.8423  Validation loss = 4.4674  \n",
      "\n",
      "Fold: 5  Epoch: 87  Training loss = 1.8423  Validation loss = 4.4672  \n",
      "\n",
      "Fold: 5  Epoch: 88  Training loss = 1.8421  Validation loss = 4.4666  \n",
      "\n",
      "Fold: 5  Epoch: 89  Training loss = 1.8420  Validation loss = 4.4664  \n",
      "\n",
      "Fold: 5  Epoch: 90  Training loss = 1.8417  Validation loss = 4.4652  \n",
      "\n",
      "Fold: 5  Epoch: 91  Training loss = 1.8417  Validation loss = 4.4656  \n",
      "\n",
      "Fold: 5  Epoch: 92  Training loss = 1.8416  Validation loss = 4.4649  \n",
      "\n",
      "Fold: 5  Epoch: 93  Training loss = 1.8414  Validation loss = 4.4646  \n",
      "\n",
      "Fold: 5  Epoch: 94  Training loss = 1.8411  Validation loss = 4.4633  \n",
      "\n",
      "Fold: 5  Epoch: 95  Training loss = 1.8408  Validation loss = 4.4625  \n",
      "\n",
      "Fold: 5  Epoch: 96  Training loss = 1.8407  Validation loss = 4.4620  \n",
      "\n",
      "Fold: 5  Epoch: 97  Training loss = 1.8403  Validation loss = 4.4609  \n",
      "\n",
      "Fold: 5  Epoch: 98  Training loss = 1.8401  Validation loss = 4.4599  \n",
      "\n",
      "Fold: 5  Epoch: 99  Training loss = 1.8400  Validation loss = 4.4597  \n",
      "\n",
      "Fold: 5  Epoch: 100  Training loss = 1.8396  Validation loss = 4.4586  \n",
      "\n",
      "Fold: 5  Epoch: 101  Training loss = 1.8396  Validation loss = 4.4585  \n",
      "\n",
      "Fold: 5  Epoch: 102  Training loss = 1.8394  Validation loss = 4.4576  \n",
      "\n",
      "Fold: 5  Epoch: 103  Training loss = 1.8392  Validation loss = 4.4569  \n",
      "\n",
      "Fold: 5  Epoch: 104  Training loss = 1.8390  Validation loss = 4.4562  \n",
      "\n",
      "Fold: 5  Epoch: 105  Training loss = 1.8389  Validation loss = 4.4560  \n",
      "\n",
      "Fold: 5  Epoch: 106  Training loss = 1.8387  Validation loss = 4.4555  \n",
      "\n",
      "Fold: 5  Epoch: 107  Training loss = 1.8385  Validation loss = 4.4547  \n",
      "\n",
      "Fold: 5  Epoch: 108  Training loss = 1.8381  Validation loss = 4.4533  \n",
      "\n",
      "Fold: 5  Epoch: 109  Training loss = 1.8379  Validation loss = 4.4525  \n",
      "\n",
      "Fold: 5  Epoch: 110  Training loss = 1.8377  Validation loss = 4.4515  \n",
      "\n",
      "Fold: 5  Epoch: 111  Training loss = 1.8373  Validation loss = 4.4502  \n",
      "\n",
      "Fold: 5  Epoch: 112  Training loss = 1.8371  Validation loss = 4.4498  \n",
      "\n",
      "Fold: 5  Epoch: 113  Training loss = 1.8370  Validation loss = 4.4490  \n",
      "\n",
      "Fold: 5  Epoch: 114  Training loss = 1.8368  Validation loss = 4.4485  \n",
      "\n",
      "Fold: 5  Epoch: 115  Training loss = 1.8366  Validation loss = 4.4479  \n",
      "\n",
      "Fold: 5  Epoch: 116  Training loss = 1.8363  Validation loss = 4.4466  \n",
      "\n",
      "Fold: 5  Epoch: 117  Training loss = 1.8360  Validation loss = 4.4456  \n",
      "\n",
      "Fold: 5  Epoch: 118  Training loss = 1.8357  Validation loss = 4.4445  \n",
      "\n",
      "Fold: 5  Epoch: 119  Training loss = 1.8356  Validation loss = 4.4439  \n",
      "\n",
      "Fold: 5  Epoch: 120  Training loss = 1.8352  Validation loss = 4.4425  \n",
      "\n",
      "Fold: 5  Epoch: 121  Training loss = 1.8350  Validation loss = 4.4417  \n",
      "\n",
      "Fold: 5  Epoch: 122  Training loss = 1.8347  Validation loss = 4.4408  \n",
      "\n",
      "Fold: 5  Epoch: 123  Training loss = 1.8344  Validation loss = 4.4393  \n",
      "\n",
      "Fold: 5  Epoch: 124  Training loss = 1.8342  Validation loss = 4.4385  \n",
      "\n",
      "Fold: 5  Epoch: 125  Training loss = 1.8340  Validation loss = 4.4380  \n",
      "\n",
      "Fold: 5  Epoch: 126  Training loss = 1.8338  Validation loss = 4.4372  \n",
      "\n",
      "Fold: 5  Epoch: 127  Training loss = 1.8337  Validation loss = 4.4370  \n",
      "\n",
      "Fold: 5  Epoch: 128  Training loss = 1.8334  Validation loss = 4.4358  \n",
      "\n",
      "Fold: 5  Epoch: 129  Training loss = 1.8332  Validation loss = 4.4350  \n",
      "\n",
      "Fold: 5  Epoch: 130  Training loss = 1.8330  Validation loss = 4.4344  \n",
      "\n",
      "Fold: 5  Epoch: 131  Training loss = 1.8328  Validation loss = 4.4335  \n",
      "\n",
      "Fold: 5  Epoch: 132  Training loss = 1.8326  Validation loss = 4.4325  \n",
      "\n",
      "Fold: 5  Epoch: 133  Training loss = 1.8324  Validation loss = 4.4317  \n",
      "\n",
      "Fold: 5  Epoch: 134  Training loss = 1.8321  Validation loss = 4.4309  \n",
      "\n",
      "Fold: 5  Epoch: 135  Training loss = 1.8319  Validation loss = 4.4300  \n",
      "\n",
      "Fold: 5  Epoch: 136  Training loss = 1.8317  Validation loss = 4.4290  \n",
      "\n",
      "Fold: 5  Epoch: 137  Training loss = 1.8313  Validation loss = 4.4274  \n",
      "\n",
      "Fold: 5  Epoch: 138  Training loss = 1.8311  Validation loss = 4.4265  \n",
      "\n",
      "Fold: 5  Epoch: 139  Training loss = 1.8310  Validation loss = 4.4259  \n",
      "\n",
      "Fold: 5  Epoch: 140  Training loss = 1.8307  Validation loss = 4.4247  \n",
      "\n",
      "Fold: 5  Epoch: 141  Training loss = 1.8306  Validation loss = 4.4242  \n",
      "\n",
      "Fold: 5  Epoch: 142  Training loss = 1.8305  Validation loss = 4.4239  \n",
      "\n",
      "Fold: 5  Epoch: 143  Training loss = 1.8302  Validation loss = 4.4227  \n",
      "\n",
      "Fold: 5  Epoch: 144  Training loss = 1.8301  Validation loss = 4.4221  \n",
      "\n",
      "Fold: 5  Epoch: 145  Training loss = 1.8299  Validation loss = 4.4210  \n",
      "\n",
      "Fold: 5  Epoch: 146  Training loss = 1.8298  Validation loss = 4.4205  \n",
      "\n",
      "Fold: 5  Epoch: 147  Training loss = 1.8296  Validation loss = 4.4200  \n",
      "\n",
      "Fold: 5  Epoch: 148  Training loss = 1.8293  Validation loss = 4.4187  \n",
      "\n",
      "Fold: 5  Epoch: 149  Training loss = 1.8291  Validation loss = 4.4182  \n",
      "\n",
      "Fold: 5  Epoch: 150  Training loss = 1.8291  Validation loss = 4.4182  \n",
      "\n",
      "Fold: 5  Epoch: 151  Training loss = 1.8291  Validation loss = 4.4182  \n",
      "\n",
      "Fold: 5  Epoch: 152  Training loss = 1.8290  Validation loss = 4.4179  \n",
      "\n",
      "Fold: 5  Epoch: 153  Training loss = 1.8287  Validation loss = 4.4165  \n",
      "\n",
      "Fold: 5  Epoch: 154  Training loss = 1.8285  Validation loss = 4.4160  \n",
      "\n",
      "Fold: 5  Epoch: 155  Training loss = 1.8283  Validation loss = 4.4153  \n",
      "\n",
      "Fold: 5  Epoch: 156  Training loss = 1.8282  Validation loss = 4.4151  \n",
      "\n",
      "Fold: 5  Epoch: 157  Training loss = 1.8281  Validation loss = 4.4146  \n",
      "\n",
      "Fold: 5  Epoch: 158  Training loss = 1.8278  Validation loss = 4.4136  \n",
      "\n",
      "Fold: 5  Epoch: 159  Training loss = 1.8277  Validation loss = 4.4131  \n",
      "\n",
      "Fold: 5  Epoch: 160  Training loss = 1.8275  Validation loss = 4.4124  \n",
      "\n",
      "Fold: 5  Epoch: 161  Training loss = 1.8273  Validation loss = 4.4117  \n",
      "\n",
      "Fold: 5  Epoch: 162  Training loss = 1.8272  Validation loss = 4.4112  \n",
      "\n",
      "Fold: 5  Epoch: 163  Training loss = 1.8271  Validation loss = 4.4109  \n",
      "\n",
      "Fold: 5  Epoch: 164  Training loss = 1.8268  Validation loss = 4.4098  \n",
      "\n",
      "Fold: 5  Epoch: 165  Training loss = 1.8265  Validation loss = 4.4086  \n",
      "\n",
      "Fold: 5  Epoch: 166  Training loss = 1.8264  Validation loss = 4.4082  \n",
      "\n",
      "Fold: 5  Epoch: 167  Training loss = 1.8264  Validation loss = 4.4080  \n",
      "\n",
      "Fold: 5  Epoch: 168  Training loss = 1.8262  Validation loss = 4.4073  \n",
      "\n",
      "Fold: 5  Epoch: 169  Training loss = 1.8261  Validation loss = 4.4070  \n",
      "\n",
      "Fold: 5  Epoch: 170  Training loss = 1.8260  Validation loss = 4.4070  \n",
      "\n",
      "Fold: 5  Epoch: 171  Training loss = 1.8258  Validation loss = 4.4062  \n",
      "\n",
      "Fold: 5  Epoch: 172  Training loss = 1.8254  Validation loss = 4.4047  \n",
      "\n",
      "Fold: 5  Epoch: 173  Training loss = 1.8252  Validation loss = 4.4039  \n",
      "\n",
      "Fold: 5  Epoch: 174  Training loss = 1.8250  Validation loss = 4.4033  \n",
      "\n",
      "Fold: 5  Epoch: 175  Training loss = 1.8247  Validation loss = 4.4022  \n",
      "\n",
      "Fold: 5  Epoch: 176  Training loss = 1.8246  Validation loss = 4.4014  \n",
      "\n",
      "Fold: 5  Epoch: 177  Training loss = 1.8244  Validation loss = 4.4009  \n",
      "\n",
      "Fold: 5  Epoch: 178  Training loss = 1.8242  Validation loss = 4.4004  \n",
      "\n",
      "Fold: 5  Epoch: 179  Training loss = 1.8241  Validation loss = 4.4000  \n",
      "\n",
      "Fold: 5  Epoch: 180  Training loss = 1.8238  Validation loss = 4.3987  \n",
      "\n",
      "Fold: 5  Epoch: 181  Training loss = 1.8236  Validation loss = 4.3977  \n",
      "\n",
      "Fold: 5  Epoch: 182  Training loss = 1.8234  Validation loss = 4.3973  \n",
      "\n",
      "Fold: 5  Epoch: 183  Training loss = 1.8233  Validation loss = 4.3964  \n",
      "\n",
      "Fold: 5  Epoch: 184  Training loss = 1.8231  Validation loss = 4.3957  \n",
      "\n",
      "Fold: 5  Epoch: 185  Training loss = 1.8230  Validation loss = 4.3952  \n",
      "\n",
      "Fold: 5  Epoch: 186  Training loss = 1.8228  Validation loss = 4.3944  \n",
      "\n",
      "Fold: 5  Epoch: 187  Training loss = 1.8226  Validation loss = 4.3935  \n",
      "\n",
      "Fold: 5  Epoch: 188  Training loss = 1.8224  Validation loss = 4.3927  \n",
      "\n",
      "Fold: 5  Epoch: 189  Training loss = 1.8222  Validation loss = 4.3918  \n",
      "\n",
      "Fold: 5  Epoch: 190  Training loss = 1.8220  Validation loss = 4.3911  \n",
      "\n",
      "Fold: 5  Epoch: 191  Training loss = 1.8219  Validation loss = 4.3908  \n",
      "\n",
      "Fold: 5  Epoch: 192  Training loss = 1.8218  Validation loss = 4.3905  \n",
      "\n",
      "Fold: 5  Epoch: 193  Training loss = 1.8218  Validation loss = 4.3906  \n",
      "\n",
      "Fold: 5  Epoch: 194  Training loss = 1.8216  Validation loss = 4.3898  \n",
      "\n",
      "Fold: 5  Epoch: 195  Training loss = 1.8213  Validation loss = 4.3885  \n",
      "\n",
      "Fold: 5  Epoch: 196  Training loss = 1.8213  Validation loss = 4.3888  \n",
      "\n",
      "Fold: 5  Epoch: 197  Training loss = 1.8212  Validation loss = 4.3889  \n",
      "\n",
      "Fold: 5  Epoch: 198  Training loss = 1.8210  Validation loss = 4.3881  \n",
      "\n",
      "Fold: 5  Epoch: 199  Training loss = 1.8210  Validation loss = 4.3882  \n",
      "\n",
      "Fold: 5  Epoch: 200  Training loss = 1.8208  Validation loss = 4.3874  \n",
      "\n",
      "Fold: 5  Epoch: 201  Training loss = 1.8206  Validation loss = 4.3868  \n",
      "\n",
      "Fold: 5  Epoch: 202  Training loss = 1.8204  Validation loss = 4.3860  \n",
      "\n",
      "Fold: 5  Epoch: 203  Training loss = 1.8202  Validation loss = 4.3850  \n",
      "\n",
      "Fold: 5  Epoch: 204  Training loss = 1.8201  Validation loss = 4.3845  \n",
      "\n",
      "Fold: 5  Epoch: 205  Training loss = 1.8198  Validation loss = 4.3836  \n",
      "\n",
      "Fold: 5  Epoch: 206  Training loss = 1.8196  Validation loss = 4.3827  \n",
      "\n",
      "Fold: 5  Epoch: 207  Training loss = 1.8194  Validation loss = 4.3821  \n",
      "\n",
      "Fold: 5  Epoch: 208  Training loss = 1.8192  Validation loss = 4.3816  \n",
      "\n",
      "Fold: 5  Epoch: 209  Training loss = 1.8191  Validation loss = 4.3813  \n",
      "\n",
      "Fold: 5  Epoch: 210  Training loss = 1.8189  Validation loss = 4.3805  \n",
      "\n",
      "Fold: 5  Epoch: 211  Training loss = 1.8188  Validation loss = 4.3802  \n",
      "\n",
      "Fold: 5  Epoch: 212  Training loss = 1.8185  Validation loss = 4.3793  \n",
      "\n",
      "Fold: 5  Epoch: 213  Training loss = 1.8184  Validation loss = 4.3787  \n",
      "\n",
      "Fold: 5  Epoch: 214  Training loss = 1.8182  Validation loss = 4.3780  \n",
      "\n",
      "Fold: 5  Epoch: 215  Training loss = 1.8180  Validation loss = 4.3774  \n",
      "\n",
      "Fold: 5  Epoch: 216  Training loss = 1.8179  Validation loss = 4.3768  \n",
      "\n",
      "Fold: 5  Epoch: 217  Training loss = 1.8177  Validation loss = 4.3764  \n",
      "\n",
      "Fold: 5  Epoch: 218  Training loss = 1.8175  Validation loss = 4.3754  \n",
      "\n",
      "Fold: 5  Epoch: 219  Training loss = 1.8173  Validation loss = 4.3744  \n",
      "\n",
      "Fold: 5  Epoch: 220  Training loss = 1.8172  Validation loss = 4.3739  \n",
      "\n",
      "Fold: 5  Epoch: 221  Training loss = 1.8171  Validation loss = 4.3737  \n",
      "\n",
      "Fold: 5  Epoch: 222  Training loss = 1.8169  Validation loss = 4.3728  \n",
      "\n",
      "Fold: 5  Epoch: 223  Training loss = 1.8167  Validation loss = 4.3719  \n",
      "\n",
      "Fold: 5  Epoch: 224  Training loss = 1.8165  Validation loss = 4.3711  \n",
      "\n",
      "Fold: 5  Epoch: 225  Training loss = 1.8164  Validation loss = 4.3707  \n",
      "\n",
      "Fold: 5  Epoch: 226  Training loss = 1.8163  Validation loss = 4.3705  \n",
      "\n",
      "Fold: 5  Epoch: 227  Training loss = 1.8162  Validation loss = 4.3700  \n",
      "\n",
      "Fold: 5  Epoch: 228  Training loss = 1.8160  Validation loss = 4.3695  \n",
      "\n",
      "Fold: 5  Epoch: 229  Training loss = 1.8159  Validation loss = 4.3689  \n",
      "\n",
      "Fold: 5  Epoch: 230  Training loss = 1.8156  Validation loss = 4.3680  \n",
      "\n",
      "Fold: 5  Epoch: 231  Training loss = 1.8154  Validation loss = 4.3675  \n",
      "\n",
      "Fold: 5  Epoch: 232  Training loss = 1.8152  Validation loss = 4.3662  \n",
      "\n",
      "Fold: 5  Epoch: 233  Training loss = 1.8149  Validation loss = 4.3648  \n",
      "\n",
      "Fold: 5  Epoch: 234  Training loss = 1.8147  Validation loss = 4.3639  \n",
      "\n",
      "Fold: 5  Epoch: 235  Training loss = 1.8145  Validation loss = 4.3633  \n",
      "\n",
      "Fold: 5  Epoch: 236  Training loss = 1.8143  Validation loss = 4.3625  \n",
      "\n",
      "Fold: 5  Epoch: 237  Training loss = 1.8141  Validation loss = 4.3617  \n",
      "\n",
      "Fold: 5  Epoch: 238  Training loss = 1.8139  Validation loss = 4.3611  \n",
      "\n",
      "Fold: 5  Epoch: 239  Training loss = 1.8139  Validation loss = 4.3609  \n",
      "\n",
      "Fold: 5  Epoch: 240  Training loss = 1.8137  Validation loss = 4.3602  \n",
      "\n",
      "Fold: 5  Epoch: 241  Training loss = 1.8135  Validation loss = 4.3595  \n",
      "\n",
      "Fold: 5  Epoch: 242  Training loss = 1.8132  Validation loss = 4.3585  \n",
      "\n",
      "Fold: 5  Epoch: 243  Training loss = 1.8131  Validation loss = 4.3583  \n",
      "\n",
      "Fold: 5  Epoch: 244  Training loss = 1.8130  Validation loss = 4.3577  \n",
      "\n",
      "Fold: 5  Epoch: 245  Training loss = 1.8129  Validation loss = 4.3574  \n",
      "\n",
      "Fold: 5  Epoch: 246  Training loss = 1.8127  Validation loss = 4.3568  \n",
      "\n",
      "Fold: 5  Epoch: 247  Training loss = 1.8126  Validation loss = 4.3567  \n",
      "\n",
      "Fold: 5  Epoch: 248  Training loss = 1.8124  Validation loss = 4.3558  \n",
      "\n",
      "Fold: 5  Epoch: 249  Training loss = 1.8123  Validation loss = 4.3555  \n",
      "\n",
      "Fold: 5  Epoch: 250  Training loss = 1.8119  Validation loss = 4.3539  \n",
      "\n",
      "Fold: 5  Epoch: 251  Training loss = 1.8118  Validation loss = 4.3533  \n",
      "\n",
      "Fold: 5  Epoch: 252  Training loss = 1.8117  Validation loss = 4.3532  \n",
      "\n",
      "Fold: 5  Epoch: 253  Training loss = 1.8115  Validation loss = 4.3521  \n",
      "\n",
      "Fold: 5  Epoch: 254  Training loss = 1.8114  Validation loss = 4.3519  \n",
      "\n",
      "Fold: 5  Epoch: 255  Training loss = 1.8112  Validation loss = 4.3510  \n",
      "\n",
      "Fold: 5  Epoch: 256  Training loss = 1.8110  Validation loss = 4.3504  \n",
      "\n",
      "Fold: 5  Epoch: 257  Training loss = 1.8109  Validation loss = 4.3498  \n",
      "\n",
      "Fold: 5  Epoch: 258  Training loss = 1.8108  Validation loss = 4.3494  \n",
      "\n",
      "Fold: 5  Epoch: 259  Training loss = 1.8106  Validation loss = 4.3487  \n",
      "\n",
      "Fold: 5  Epoch: 260  Training loss = 1.8104  Validation loss = 4.3479  \n",
      "\n",
      "Fold: 5  Epoch: 261  Training loss = 1.8104  Validation loss = 4.3479  \n",
      "\n",
      "Fold: 5  Epoch: 262  Training loss = 1.8102  Validation loss = 4.3474  \n",
      "\n",
      "Fold: 5  Epoch: 263  Training loss = 1.8101  Validation loss = 4.3471  \n",
      "\n",
      "Fold: 5  Epoch: 264  Training loss = 1.8100  Validation loss = 4.3463  \n",
      "\n",
      "Fold: 5  Epoch: 265  Training loss = 1.8097  Validation loss = 4.3453  \n",
      "\n",
      "Fold: 5  Epoch: 266  Training loss = 1.8095  Validation loss = 4.3445  \n",
      "\n",
      "Fold: 5  Epoch: 267  Training loss = 1.8093  Validation loss = 4.3435  \n",
      "\n",
      "Fold: 5  Epoch: 268  Training loss = 1.8091  Validation loss = 4.3427  \n",
      "\n",
      "Fold: 5  Epoch: 269  Training loss = 1.8090  Validation loss = 4.3420  \n",
      "\n",
      "Fold: 5  Epoch: 270  Training loss = 1.8089  Validation loss = 4.3418  \n",
      "\n",
      "Fold: 5  Epoch: 271  Training loss = 1.8087  Validation loss = 4.3411  \n",
      "\n",
      "Fold: 5  Epoch: 272  Training loss = 1.8087  Validation loss = 4.3410  \n",
      "\n",
      "Fold: 5  Epoch: 273  Training loss = 1.8085  Validation loss = 4.3407  \n",
      "\n",
      "Fold: 5  Epoch: 274  Training loss = 1.8084  Validation loss = 4.3405  \n",
      "\n",
      "Fold: 5  Epoch: 275  Training loss = 1.8082  Validation loss = 4.3402  \n",
      "\n",
      "Fold: 5  Epoch: 276  Training loss = 1.8082  Validation loss = 4.3398  \n",
      "\n",
      "Fold: 5  Epoch: 277  Training loss = 1.8080  Validation loss = 4.3392  \n",
      "\n",
      "Fold: 5  Epoch: 278  Training loss = 1.8077  Validation loss = 4.3379  \n",
      "\n",
      "Fold: 5  Epoch: 279  Training loss = 1.8074  Validation loss = 4.3366  \n",
      "\n",
      "Fold: 5  Epoch: 280  Training loss = 1.8073  Validation loss = 4.3360  \n",
      "\n",
      "Fold: 5  Epoch: 281  Training loss = 1.8072  Validation loss = 4.3357  \n",
      "\n",
      "Fold: 5  Epoch: 282  Training loss = 1.8069  Validation loss = 4.3347  \n",
      "\n",
      "Fold: 5  Epoch: 283  Training loss = 1.8068  Validation loss = 4.3343  \n",
      "\n",
      "Fold: 5  Epoch: 284  Training loss = 1.8066  Validation loss = 4.3336  \n",
      "\n",
      "Fold: 5  Epoch: 285  Training loss = 1.8065  Validation loss = 4.3332  \n",
      "\n",
      "Fold: 5  Epoch: 286  Training loss = 1.8064  Validation loss = 4.3332  \n",
      "\n",
      "Fold: 5  Epoch: 287  Training loss = 1.8062  Validation loss = 4.3321  \n",
      "\n",
      "Fold: 5  Epoch: 288  Training loss = 1.8060  Validation loss = 4.3312  \n",
      "\n",
      "Fold: 5  Epoch: 289  Training loss = 1.8059  Validation loss = 4.3310  \n",
      "\n",
      "Fold: 5  Epoch: 290  Training loss = 1.8058  Validation loss = 4.3304  \n",
      "\n",
      "Fold: 5  Epoch: 291  Training loss = 1.8056  Validation loss = 4.3297  \n",
      "\n",
      "Fold: 5  Epoch: 292  Training loss = 1.8055  Validation loss = 4.3293  \n",
      "\n",
      "Fold: 5  Epoch: 293  Training loss = 1.8053  Validation loss = 4.3283  \n",
      "\n",
      "Fold: 5  Epoch: 294  Training loss = 1.8052  Validation loss = 4.3276  \n",
      "\n",
      "Fold: 5  Epoch: 295  Training loss = 1.8050  Validation loss = 4.3269  \n",
      "\n",
      "Fold: 5  Epoch: 296  Training loss = 1.8049  Validation loss = 4.3266  \n",
      "\n",
      "Fold: 5  Epoch: 297  Training loss = 1.8049  Validation loss = 4.3268  \n",
      "\n",
      "Fold: 5  Epoch: 298  Training loss = 1.8047  Validation loss = 4.3259  \n",
      "\n",
      "Fold: 5  Epoch: 299  Training loss = 1.8045  Validation loss = 4.3255  \n",
      "\n",
      "Fold: 5  Epoch: 300  Training loss = 1.8043  Validation loss = 4.3244  \n",
      "\n",
      "Fold: 5  Epoch: 301  Training loss = 1.8042  Validation loss = 4.3236  \n",
      "\n",
      "Fold: 5  Epoch: 302  Training loss = 1.8041  Validation loss = 4.3234  \n",
      "\n",
      "Fold: 5  Epoch: 303  Training loss = 1.8039  Validation loss = 4.3228  \n",
      "\n",
      "Fold: 5  Epoch: 304  Training loss = 1.8037  Validation loss = 4.3217  \n",
      "\n",
      "Fold: 5  Epoch: 305  Training loss = 1.8036  Validation loss = 4.3210  \n",
      "\n",
      "Fold: 5  Epoch: 306  Training loss = 1.8034  Validation loss = 4.3204  \n",
      "\n",
      "Fold: 5  Epoch: 307  Training loss = 1.8033  Validation loss = 4.3201  \n",
      "\n",
      "Fold: 5  Epoch: 308  Training loss = 1.8030  Validation loss = 4.3188  \n",
      "\n",
      "Fold: 5  Epoch: 309  Training loss = 1.8029  Validation loss = 4.3183  \n",
      "\n",
      "Fold: 5  Epoch: 310  Training loss = 1.8028  Validation loss = 4.3182  \n",
      "\n",
      "Fold: 5  Epoch: 311  Training loss = 1.8026  Validation loss = 4.3171  \n",
      "\n",
      "Fold: 5  Epoch: 312  Training loss = 1.8024  Validation loss = 4.3161  \n",
      "\n",
      "Fold: 5  Epoch: 313  Training loss = 1.8022  Validation loss = 4.3157  \n",
      "\n",
      "Fold: 5  Epoch: 314  Training loss = 1.8021  Validation loss = 4.3152  \n",
      "\n",
      "Fold: 5  Epoch: 315  Training loss = 1.8019  Validation loss = 4.3146  \n",
      "\n",
      "Fold: 5  Epoch: 316  Training loss = 1.8017  Validation loss = 4.3139  \n",
      "\n",
      "Fold: 5  Epoch: 317  Training loss = 1.8016  Validation loss = 4.3134  \n",
      "\n",
      "Fold: 5  Epoch: 318  Training loss = 1.8013  Validation loss = 4.3120  \n",
      "\n",
      "Fold: 5  Epoch: 319  Training loss = 1.8012  Validation loss = 4.3113  \n",
      "\n",
      "Fold: 5  Epoch: 320  Training loss = 1.8011  Validation loss = 4.3110  \n",
      "\n",
      "Fold: 5  Epoch: 321  Training loss = 1.8010  Validation loss = 4.3108  \n",
      "\n",
      "Fold: 5  Epoch: 322  Training loss = 1.8009  Validation loss = 4.3104  \n",
      "\n",
      "Fold: 5  Epoch: 323  Training loss = 1.8007  Validation loss = 4.3097  \n",
      "\n",
      "Fold: 5  Epoch: 324  Training loss = 1.8005  Validation loss = 4.3090  \n",
      "\n",
      "Fold: 5  Epoch: 325  Training loss = 1.8003  Validation loss = 4.3075  \n",
      "\n",
      "Fold: 5  Epoch: 326  Training loss = 1.8002  Validation loss = 4.3073  \n",
      "\n",
      "Fold: 5  Epoch: 327  Training loss = 1.8001  Validation loss = 4.3073  \n",
      "\n",
      "Fold: 5  Epoch: 328  Training loss = 1.8000  Validation loss = 4.3069  \n",
      "\n",
      "Fold: 5  Epoch: 329  Training loss = 1.7998  Validation loss = 4.3061  \n",
      "\n",
      "Fold: 5  Epoch: 330  Training loss = 1.7997  Validation loss = 4.3057  \n",
      "\n",
      "Fold: 5  Epoch: 331  Training loss = 1.7996  Validation loss = 4.3051  \n",
      "\n",
      "Fold: 5  Epoch: 332  Training loss = 1.7995  Validation loss = 4.3048  \n",
      "\n",
      "Fold: 5  Epoch: 333  Training loss = 1.7994  Validation loss = 4.3047  \n",
      "\n",
      "Fold: 5  Epoch: 334  Training loss = 1.7993  Validation loss = 4.3040  \n",
      "\n",
      "Fold: 5  Epoch: 335  Training loss = 1.7992  Validation loss = 4.3039  \n",
      "\n",
      "Fold: 5  Epoch: 336  Training loss = 1.7991  Validation loss = 4.3036  \n",
      "\n",
      "Fold: 5  Epoch: 337  Training loss = 1.7989  Validation loss = 4.3028  \n",
      "\n",
      "Fold: 5  Epoch: 338  Training loss = 1.7988  Validation loss = 4.3024  \n",
      "\n",
      "Fold: 5  Epoch: 339  Training loss = 1.7986  Validation loss = 4.3013  \n",
      "\n",
      "Fold: 5  Epoch: 340  Training loss = 1.7984  Validation loss = 4.3004  \n",
      "\n",
      "Fold: 5  Epoch: 341  Training loss = 1.7983  Validation loss = 4.3001  \n",
      "\n",
      "Fold: 5  Epoch: 342  Training loss = 1.7982  Validation loss = 4.3000  \n",
      "\n",
      "Fold: 5  Epoch: 343  Training loss = 1.7981  Validation loss = 4.2995  \n",
      "\n",
      "Fold: 5  Epoch: 344  Training loss = 1.7981  Validation loss = 4.2996  \n",
      "\n",
      "Fold: 5  Epoch: 345  Training loss = 1.7980  Validation loss = 4.2995  \n",
      "\n",
      "Fold: 5  Epoch: 346  Training loss = 1.7979  Validation loss = 4.2992  \n",
      "\n",
      "Fold: 5  Epoch: 347  Training loss = 1.7977  Validation loss = 4.2985  \n",
      "\n",
      "Fold: 5  Epoch: 348  Training loss = 1.7975  Validation loss = 4.2979  \n",
      "\n",
      "Fold: 5  Epoch: 349  Training loss = 1.7974  Validation loss = 4.2973  \n",
      "\n",
      "Fold: 5  Epoch: 350  Training loss = 1.7972  Validation loss = 4.2967  \n",
      "\n",
      "Fold: 5  Epoch: 351  Training loss = 1.7970  Validation loss = 4.2956  \n",
      "\n",
      "Fold: 5  Epoch: 352  Training loss = 1.7969  Validation loss = 4.2950  \n",
      "\n",
      "Fold: 5  Epoch: 353  Training loss = 1.7966  Validation loss = 4.2939  \n",
      "\n",
      "Fold: 5  Epoch: 354  Training loss = 1.7965  Validation loss = 4.2932  \n",
      "\n",
      "Fold: 5  Epoch: 355  Training loss = 1.7964  Validation loss = 4.2931  \n",
      "\n",
      "Fold: 5  Epoch: 356  Training loss = 1.7964  Validation loss = 4.2933  \n",
      "\n",
      "Fold: 5  Epoch: 357  Training loss = 1.7963  Validation loss = 4.2927  \n",
      "\n",
      "Fold: 5  Epoch: 358  Training loss = 1.7962  Validation loss = 4.2922  \n",
      "\n",
      "Fold: 5  Epoch: 359  Training loss = 1.7961  Validation loss = 4.2923  \n",
      "\n",
      "Fold: 5  Epoch: 360  Training loss = 1.7959  Validation loss = 4.2916  \n",
      "\n",
      "Fold: 5  Epoch: 361  Training loss = 1.7958  Validation loss = 4.2909  \n",
      "\n",
      "Fold: 5  Epoch: 362  Training loss = 1.7957  Validation loss = 4.2907  \n",
      "\n",
      "Fold: 5  Epoch: 363  Training loss = 1.7955  Validation loss = 4.2897  \n",
      "\n",
      "Fold: 5  Epoch: 364  Training loss = 1.7954  Validation loss = 4.2897  \n",
      "\n",
      "Fold: 5  Epoch: 365  Training loss = 1.7953  Validation loss = 4.2891  \n",
      "\n",
      "Fold: 5  Epoch: 366  Training loss = 1.7951  Validation loss = 4.2883  \n",
      "\n",
      "Fold: 5  Epoch: 367  Training loss = 1.7949  Validation loss = 4.2875  \n",
      "\n",
      "Fold: 5  Epoch: 368  Training loss = 1.7948  Validation loss = 4.2874  \n",
      "\n",
      "Fold: 5  Epoch: 369  Training loss = 1.7947  Validation loss = 4.2874  \n",
      "\n",
      "Fold: 5  Epoch: 370  Training loss = 1.7946  Validation loss = 4.2867  \n",
      "\n",
      "Fold: 5  Epoch: 371  Training loss = 1.7945  Validation loss = 4.2863  \n",
      "\n",
      "Fold: 5  Epoch: 372  Training loss = 1.7944  Validation loss = 4.2859  \n",
      "\n",
      "Fold: 5  Epoch: 373  Training loss = 1.7943  Validation loss = 4.2857  \n",
      "\n",
      "Fold: 5  Epoch: 374  Training loss = 1.7941  Validation loss = 4.2846  \n",
      "\n",
      "Fold: 5  Epoch: 375  Training loss = 1.7939  Validation loss = 4.2838  \n",
      "\n",
      "Fold: 5  Epoch: 376  Training loss = 1.7937  Validation loss = 4.2828  \n",
      "\n",
      "Fold: 5  Epoch: 377  Training loss = 1.7936  Validation loss = 4.2823  \n",
      "\n",
      "Fold: 5  Epoch: 378  Training loss = 1.7934  Validation loss = 4.2810  \n",
      "\n",
      "Fold: 5  Epoch: 379  Training loss = 1.7933  Validation loss = 4.2807  \n",
      "\n",
      "Fold: 5  Epoch: 380  Training loss = 1.7931  Validation loss = 4.2800  \n",
      "\n",
      "Fold: 5  Epoch: 381  Training loss = 1.7929  Validation loss = 4.2791  \n",
      "\n",
      "Fold: 5  Epoch: 382  Training loss = 1.7928  Validation loss = 4.2788  \n",
      "\n",
      "Fold: 5  Epoch: 383  Training loss = 1.7927  Validation loss = 4.2788  \n",
      "\n",
      "Fold: 5  Epoch: 384  Training loss = 1.7927  Validation loss = 4.2790  \n",
      "\n",
      "Fold: 5  Epoch: 385  Training loss = 1.7926  Validation loss = 4.2784  \n",
      "\n",
      "Fold: 5  Epoch: 386  Training loss = 1.7925  Validation loss = 4.2777  \n",
      "\n",
      "Fold: 5  Epoch: 387  Training loss = 1.7924  Validation loss = 4.2777  \n",
      "\n",
      "Fold: 5  Epoch: 388  Training loss = 1.7922  Validation loss = 4.2769  \n",
      "\n",
      "Fold: 5  Epoch: 389  Training loss = 1.7922  Validation loss = 4.2767  \n",
      "\n",
      "Fold: 5  Epoch: 390  Training loss = 1.7920  Validation loss = 4.2759  \n",
      "\n",
      "Fold: 5  Epoch: 391  Training loss = 1.7917  Validation loss = 4.2745  \n",
      "\n",
      "Fold: 5  Epoch: 392  Training loss = 1.7916  Validation loss = 4.2740  \n",
      "\n",
      "Fold: 5  Epoch: 393  Training loss = 1.7915  Validation loss = 4.2740  \n",
      "\n",
      "Fold: 5  Epoch: 394  Training loss = 1.7914  Validation loss = 4.2741  \n",
      "\n",
      "Fold: 5  Epoch: 395  Training loss = 1.7913  Validation loss = 4.2734  \n",
      "\n",
      "Fold: 5  Epoch: 396  Training loss = 1.7912  Validation loss = 4.2730  \n",
      "\n",
      "Fold: 5  Epoch: 397  Training loss = 1.7910  Validation loss = 4.2720  \n",
      "\n",
      "Fold: 5  Epoch: 398  Training loss = 1.7909  Validation loss = 4.2721  \n",
      "\n",
      "Fold: 5  Epoch: 399  Training loss = 1.7908  Validation loss = 4.2716  \n",
      "\n",
      "Fold: 5  Epoch: 400  Training loss = 1.7906  Validation loss = 4.2711  \n",
      "\n",
      "Fold: 5  Epoch: 401  Training loss = 1.7905  Validation loss = 4.2703  \n",
      "\n",
      "Fold: 5  Epoch: 402  Training loss = 1.7903  Validation loss = 4.2697  \n",
      "\n",
      "Fold: 5  Epoch: 403  Training loss = 1.7903  Validation loss = 4.2698  \n",
      "\n",
      "Fold: 5  Epoch: 404  Training loss = 1.7902  Validation loss = 4.2695  \n",
      "\n",
      "Fold: 5  Epoch: 405  Training loss = 1.7900  Validation loss = 4.2686  \n",
      "\n",
      "Fold: 5  Epoch: 406  Training loss = 1.7899  Validation loss = 4.2686  \n",
      "\n",
      "Fold: 5  Epoch: 407  Training loss = 1.7898  Validation loss = 4.2680  \n",
      "\n",
      "Fold: 5  Epoch: 408  Training loss = 1.7897  Validation loss = 4.2682  \n",
      "\n",
      "Fold: 5  Epoch: 409  Training loss = 1.7897  Validation loss = 4.2680  \n",
      "\n",
      "Fold: 5  Epoch: 410  Training loss = 1.7895  Validation loss = 4.2672  \n",
      "\n",
      "Fold: 5  Epoch: 411  Training loss = 1.7894  Validation loss = 4.2666  \n",
      "\n",
      "Fold: 5  Epoch: 412  Training loss = 1.7893  Validation loss = 4.2662  \n",
      "\n",
      "Fold: 5  Epoch: 413  Training loss = 1.7892  Validation loss = 4.2657  \n",
      "\n",
      "Fold: 5  Epoch: 414  Training loss = 1.7890  Validation loss = 4.2652  \n",
      "\n",
      "Fold: 5  Epoch: 415  Training loss = 1.7888  Validation loss = 4.2640  \n",
      "\n",
      "Fold: 5  Epoch: 416  Training loss = 1.7886  Validation loss = 4.2633  \n",
      "\n",
      "Fold: 5  Epoch: 417  Training loss = 1.7885  Validation loss = 4.2630  \n",
      "\n",
      "Fold: 5  Epoch: 418  Training loss = 1.7884  Validation loss = 4.2624  \n",
      "\n",
      "Fold: 5  Epoch: 419  Training loss = 1.7883  Validation loss = 4.2621  \n",
      "\n",
      "Fold: 5  Epoch: 420  Training loss = 1.7881  Validation loss = 4.2614  \n",
      "\n",
      "Fold: 5  Epoch: 421  Training loss = 1.7879  Validation loss = 4.2605  \n",
      "\n",
      "Fold: 5  Epoch: 422  Training loss = 1.7878  Validation loss = 4.2604  \n",
      "\n",
      "Fold: 5  Epoch: 423  Training loss = 1.7877  Validation loss = 4.2601  \n",
      "\n",
      "Fold: 5  Epoch: 424  Training loss = 1.7876  Validation loss = 4.2596  \n",
      "\n",
      "Fold: 5  Epoch: 425  Training loss = 1.7874  Validation loss = 4.2592  \n",
      "\n",
      "Fold: 5  Epoch: 426  Training loss = 1.7873  Validation loss = 4.2586  \n",
      "\n",
      "Fold: 5  Epoch: 427  Training loss = 1.7872  Validation loss = 4.2584  \n",
      "\n",
      "Fold: 5  Epoch: 428  Training loss = 1.7871  Validation loss = 4.2580  \n",
      "\n",
      "Fold: 5  Epoch: 429  Training loss = 1.7869  Validation loss = 4.2572  \n",
      "\n",
      "Fold: 5  Epoch: 430  Training loss = 1.7868  Validation loss = 4.2568  \n",
      "\n",
      "Fold: 5  Epoch: 431  Training loss = 1.7867  Validation loss = 4.2567  \n",
      "\n",
      "Fold: 5  Epoch: 432  Training loss = 1.7865  Validation loss = 4.2559  \n",
      "\n",
      "Fold: 5  Epoch: 433  Training loss = 1.7864  Validation loss = 4.2552  \n",
      "\n",
      "Fold: 5  Epoch: 434  Training loss = 1.7863  Validation loss = 4.2549  \n",
      "\n",
      "Fold: 5  Epoch: 435  Training loss = 1.7862  Validation loss = 4.2547  \n",
      "\n",
      "Fold: 5  Epoch: 436  Training loss = 1.7860  Validation loss = 4.2534  \n",
      "\n",
      "Fold: 5  Epoch: 437  Training loss = 1.7858  Validation loss = 4.2528  \n",
      "\n",
      "Fold: 5  Epoch: 438  Training loss = 1.7857  Validation loss = 4.2527  \n",
      "\n",
      "Fold: 5  Epoch: 439  Training loss = 1.7855  Validation loss = 4.2519  \n",
      "\n",
      "Fold: 5  Epoch: 440  Training loss = 1.7853  Validation loss = 4.2509  \n",
      "\n",
      "Fold: 5  Epoch: 441  Training loss = 1.7853  Validation loss = 4.2509  \n",
      "\n",
      "Fold: 5  Epoch: 442  Training loss = 1.7850  Validation loss = 4.2500  \n",
      "\n",
      "Fold: 5  Epoch: 443  Training loss = 1.7849  Validation loss = 4.2494  \n",
      "\n",
      "Fold: 5  Epoch: 444  Training loss = 1.7848  Validation loss = 4.2494  \n",
      "\n",
      "Fold: 5  Epoch: 445  Training loss = 1.7846  Validation loss = 4.2481  \n",
      "\n",
      "Fold: 5  Epoch: 446  Training loss = 1.7845  Validation loss = 4.2480  \n",
      "\n",
      "Fold: 5  Epoch: 447  Training loss = 1.7844  Validation loss = 4.2478  \n",
      "\n",
      "Fold: 5  Epoch: 448  Training loss = 1.7843  Validation loss = 4.2477  \n",
      "\n",
      "Fold: 5  Epoch: 449  Training loss = 1.7842  Validation loss = 4.2473  \n",
      "\n",
      "Fold: 5  Epoch: 450  Training loss = 1.7842  Validation loss = 4.2473  \n",
      "\n",
      "Fold: 5  Epoch: 451  Training loss = 1.7840  Validation loss = 4.2465  \n",
      "\n",
      "Fold: 5  Epoch: 452  Training loss = 1.7840  Validation loss = 4.2467  \n",
      "\n",
      "Fold: 5  Epoch: 453  Training loss = 1.7839  Validation loss = 4.2465  \n",
      "\n",
      "Fold: 5  Epoch: 454  Training loss = 1.7838  Validation loss = 4.2465  \n",
      "\n",
      "Fold: 5  Epoch: 455  Training loss = 1.7837  Validation loss = 4.2461  \n",
      "\n",
      "Fold: 5  Epoch: 456  Training loss = 1.7836  Validation loss = 4.2463  \n",
      "\n",
      "Fold: 5  Epoch: 457  Training loss = 1.7835  Validation loss = 4.2462  \n",
      "\n",
      "Fold: 5  Epoch: 458  Training loss = 1.7834  Validation loss = 4.2455  \n",
      "\n",
      "Fold: 5  Epoch: 459  Training loss = 1.7833  Validation loss = 4.2456  \n",
      "\n",
      "Fold: 5  Epoch: 460  Training loss = 1.7832  Validation loss = 4.2450  \n",
      "\n",
      "Fold: 5  Epoch: 461  Training loss = 1.7831  Validation loss = 4.2450  \n",
      "\n",
      "Fold: 5  Epoch: 462  Training loss = 1.7829  Validation loss = 4.2440  \n",
      "\n",
      "Fold: 5  Epoch: 463  Training loss = 1.7827  Validation loss = 4.2431  \n",
      "\n",
      "Fold: 5  Epoch: 464  Training loss = 1.7826  Validation loss = 4.2424  \n",
      "\n",
      "Fold: 5  Epoch: 465  Training loss = 1.7825  Validation loss = 4.2420  \n",
      "\n",
      "Fold: 5  Epoch: 466  Training loss = 1.7824  Validation loss = 4.2416  \n",
      "\n",
      "Fold: 5  Epoch: 467  Training loss = 1.7823  Validation loss = 4.2416  \n",
      "\n",
      "Fold: 5  Epoch: 468  Training loss = 1.7823  Validation loss = 4.2416  \n",
      "\n",
      "Fold: 5  Epoch: 469  Training loss = 1.7821  Validation loss = 4.2408  \n",
      "\n",
      "Fold: 5  Epoch: 470  Training loss = 1.7820  Validation loss = 4.2401  \n",
      "\n",
      "Fold: 5  Epoch: 471  Training loss = 1.7820  Validation loss = 4.2405  \n",
      "\n",
      "Fold: 5  Epoch: 472  Training loss = 1.7818  Validation loss = 4.2393  \n",
      "\n",
      "Fold: 5  Epoch: 473  Training loss = 1.7816  Validation loss = 4.2386  \n",
      "\n",
      "Fold: 5  Epoch: 474  Training loss = 1.7815  Validation loss = 4.2379  \n",
      "\n",
      "Fold: 5  Epoch: 475  Training loss = 1.7813  Validation loss = 4.2375  \n",
      "\n",
      "Fold: 5  Epoch: 476  Training loss = 1.7812  Validation loss = 4.2372  \n",
      "\n",
      "Fold: 5  Epoch: 477  Training loss = 1.7811  Validation loss = 4.2372  \n",
      "\n",
      "Fold: 5  Epoch: 478  Training loss = 1.7810  Validation loss = 4.2366  \n",
      "\n",
      "Fold: 5  Epoch: 479  Training loss = 1.7810  Validation loss = 4.2365  \n",
      "\n",
      "Fold: 5  Epoch: 480  Training loss = 1.7808  Validation loss = 4.2355  \n",
      "\n",
      "Fold: 5  Epoch: 481  Training loss = 1.7806  Validation loss = 4.2350  \n",
      "\n",
      "Fold: 5  Epoch: 482  Training loss = 1.7805  Validation loss = 4.2343  \n",
      "\n",
      "Fold: 5  Epoch: 483  Training loss = 1.7804  Validation loss = 4.2339  \n",
      "\n",
      "Fold: 5  Epoch: 484  Training loss = 1.7802  Validation loss = 4.2333  \n",
      "\n",
      "Fold: 5  Epoch: 485  Training loss = 1.7801  Validation loss = 4.2331  \n",
      "\n",
      "Fold: 5  Epoch: 486  Training loss = 1.7800  Validation loss = 4.2325  \n",
      "\n",
      "Fold: 5  Epoch: 487  Training loss = 1.7799  Validation loss = 4.2321  \n",
      "\n",
      "Fold: 5  Epoch: 488  Training loss = 1.7798  Validation loss = 4.2316  \n",
      "\n",
      "Fold: 5  Epoch: 489  Training loss = 1.7797  Validation loss = 4.2313  \n",
      "\n",
      "Fold: 5  Epoch: 490  Training loss = 1.7795  Validation loss = 4.2300  \n",
      "\n",
      "Fold: 5  Epoch: 491  Training loss = 1.7794  Validation loss = 4.2298  \n",
      "\n",
      "Fold: 5  Epoch: 492  Training loss = 1.7792  Validation loss = 4.2286  \n",
      "\n",
      "Fold: 5  Epoch: 493  Training loss = 1.7791  Validation loss = 4.2287  \n",
      "\n",
      "Fold: 5  Epoch: 494  Training loss = 1.7790  Validation loss = 4.2283  \n",
      "\n",
      "Fold: 5  Epoch: 495  Training loss = 1.7789  Validation loss = 4.2280  \n",
      "\n",
      "Fold: 5  Epoch: 496  Training loss = 1.7787  Validation loss = 4.2272  \n",
      "\n",
      "Fold: 5  Epoch: 497  Training loss = 1.7785  Validation loss = 4.2265  \n",
      "\n",
      "Fold: 5  Epoch: 498  Training loss = 1.7784  Validation loss = 4.2260  \n",
      "\n",
      "Fold: 5  Epoch: 499  Training loss = 1.7783  Validation loss = 4.2254  \n",
      "\n",
      "Fold: 5  Epoch: 500  Training loss = 1.7783  Validation loss = 4.2251  \n",
      "\n",
      "Check model:  Fold: 5  Optimal epoch: 500  \n",
      "\n",
      "Fold: 6  Epoch: 1  Training loss = 2.0242  Validation loss = 1.9696  \n",
      "\n",
      "Fold: 6  Epoch: 2  Training loss = 2.0240  Validation loss = 1.9690  \n",
      "\n",
      "Fold: 6  Epoch: 3  Training loss = 2.0236  Validation loss = 1.9684  \n",
      "\n",
      "Fold: 6  Epoch: 4  Training loss = 2.0230  Validation loss = 1.9670  \n",
      "\n",
      "Fold: 6  Epoch: 5  Training loss = 2.0226  Validation loss = 1.9662  \n",
      "\n",
      "Fold: 6  Epoch: 6  Training loss = 2.0220  Validation loss = 1.9648  \n",
      "\n",
      "Fold: 6  Epoch: 7  Training loss = 2.0216  Validation loss = 1.9638  \n",
      "\n",
      "Fold: 6  Epoch: 8  Training loss = 2.0212  Validation loss = 1.9630  \n",
      "\n",
      "Fold: 6  Epoch: 9  Training loss = 2.0210  Validation loss = 1.9625  \n",
      "\n",
      "Fold: 6  Epoch: 10  Training loss = 2.0206  Validation loss = 1.9618  \n",
      "\n",
      "Fold: 6  Epoch: 11  Training loss = 2.0203  Validation loss = 1.9612  \n",
      "\n",
      "Fold: 6  Epoch: 12  Training loss = 2.0201  Validation loss = 1.9606  \n",
      "\n",
      "Fold: 6  Epoch: 13  Training loss = 2.0197  Validation loss = 1.9597  \n",
      "\n",
      "Fold: 6  Epoch: 14  Training loss = 2.0194  Validation loss = 1.9590  \n",
      "\n",
      "Fold: 6  Epoch: 15  Training loss = 2.0189  Validation loss = 1.9580  \n",
      "\n",
      "Fold: 6  Epoch: 16  Training loss = 2.0184  Validation loss = 1.9569  \n",
      "\n",
      "Fold: 6  Epoch: 17  Training loss = 2.0180  Validation loss = 1.9560  \n",
      "\n",
      "Fold: 6  Epoch: 18  Training loss = 2.0175  Validation loss = 1.9549  \n",
      "\n",
      "Fold: 6  Epoch: 19  Training loss = 2.0172  Validation loss = 1.9539  \n",
      "\n",
      "Fold: 6  Epoch: 20  Training loss = 2.0168  Validation loss = 1.9529  \n",
      "\n",
      "Fold: 6  Epoch: 21  Training loss = 2.0162  Validation loss = 1.9516  \n",
      "\n",
      "Fold: 6  Epoch: 22  Training loss = 2.0159  Validation loss = 1.9511  \n",
      "\n",
      "Fold: 6  Epoch: 23  Training loss = 2.0153  Validation loss = 1.9498  \n",
      "\n",
      "Fold: 6  Epoch: 24  Training loss = 2.0150  Validation loss = 1.9492  \n",
      "\n",
      "Fold: 6  Epoch: 25  Training loss = 2.0145  Validation loss = 1.9480  \n",
      "\n",
      "Fold: 6  Epoch: 26  Training loss = 2.0139  Validation loss = 1.9465  \n",
      "\n",
      "Fold: 6  Epoch: 27  Training loss = 2.0135  Validation loss = 1.9457  \n",
      "\n",
      "Fold: 6  Epoch: 28  Training loss = 2.0130  Validation loss = 1.9444  \n",
      "\n",
      "Fold: 6  Epoch: 29  Training loss = 2.0125  Validation loss = 1.9433  \n",
      "\n",
      "Fold: 6  Epoch: 30  Training loss = 2.0122  Validation loss = 1.9424  \n",
      "\n",
      "Fold: 6  Epoch: 31  Training loss = 2.0117  Validation loss = 1.9413  \n",
      "\n",
      "Fold: 6  Epoch: 32  Training loss = 2.0114  Validation loss = 1.9404  \n",
      "\n",
      "Fold: 6  Epoch: 33  Training loss = 2.0110  Validation loss = 1.9397  \n",
      "\n",
      "Fold: 6  Epoch: 34  Training loss = 2.0108  Validation loss = 1.9391  \n",
      "\n",
      "Fold: 6  Epoch: 35  Training loss = 2.0101  Validation loss = 1.9374  \n",
      "\n",
      "Fold: 6  Epoch: 36  Training loss = 2.0097  Validation loss = 1.9364  \n",
      "\n",
      "Fold: 6  Epoch: 37  Training loss = 2.0096  Validation loss = 1.9361  \n",
      "\n",
      "Fold: 6  Epoch: 38  Training loss = 2.0090  Validation loss = 1.9348  \n",
      "\n",
      "Fold: 6  Epoch: 39  Training loss = 2.0087  Validation loss = 1.9341  \n",
      "\n",
      "Fold: 6  Epoch: 40  Training loss = 2.0083  Validation loss = 1.9331  \n",
      "\n",
      "Fold: 6  Epoch: 41  Training loss = 2.0080  Validation loss = 1.9324  \n",
      "\n",
      "Fold: 6  Epoch: 42  Training loss = 2.0077  Validation loss = 1.9316  \n",
      "\n",
      "Fold: 6  Epoch: 43  Training loss = 2.0074  Validation loss = 1.9308  \n",
      "\n",
      "Fold: 6  Epoch: 44  Training loss = 2.0069  Validation loss = 1.9298  \n",
      "\n",
      "Fold: 6  Epoch: 45  Training loss = 2.0065  Validation loss = 1.9288  \n",
      "\n",
      "Fold: 6  Epoch: 46  Training loss = 2.0059  Validation loss = 1.9275  \n",
      "\n",
      "Fold: 6  Epoch: 47  Training loss = 2.0057  Validation loss = 1.9270  \n",
      "\n",
      "Fold: 6  Epoch: 48  Training loss = 2.0054  Validation loss = 1.9262  \n",
      "\n",
      "Fold: 6  Epoch: 49  Training loss = 2.0052  Validation loss = 1.9256  \n",
      "\n",
      "Fold: 6  Epoch: 50  Training loss = 2.0049  Validation loss = 1.9248  \n",
      "\n",
      "Fold: 6  Epoch: 51  Training loss = 2.0044  Validation loss = 1.9240  \n",
      "\n",
      "Fold: 6  Epoch: 52  Training loss = 2.0043  Validation loss = 1.9236  \n",
      "\n",
      "Fold: 6  Epoch: 53  Training loss = 2.0039  Validation loss = 1.9227  \n",
      "\n",
      "Fold: 6  Epoch: 54  Training loss = 2.0036  Validation loss = 1.9220  \n",
      "\n",
      "Fold: 6  Epoch: 55  Training loss = 2.0032  Validation loss = 1.9210  \n",
      "\n",
      "Fold: 6  Epoch: 56  Training loss = 2.0028  Validation loss = 1.9198  \n",
      "\n",
      "Fold: 6  Epoch: 57  Training loss = 2.0025  Validation loss = 1.9189  \n",
      "\n",
      "Fold: 6  Epoch: 58  Training loss = 2.0021  Validation loss = 1.9180  \n",
      "\n",
      "Fold: 6  Epoch: 59  Training loss = 2.0020  Validation loss = 1.9179  \n",
      "\n",
      "Fold: 6  Epoch: 60  Training loss = 2.0016  Validation loss = 1.9169  \n",
      "\n",
      "Fold: 6  Epoch: 61  Training loss = 2.0011  Validation loss = 1.9157  \n",
      "\n",
      "Fold: 6  Epoch: 62  Training loss = 2.0006  Validation loss = 1.9145  \n",
      "\n",
      "Fold: 6  Epoch: 63  Training loss = 2.0002  Validation loss = 1.9136  \n",
      "\n",
      "Fold: 6  Epoch: 64  Training loss = 1.9998  Validation loss = 1.9127  \n",
      "\n",
      "Fold: 6  Epoch: 65  Training loss = 1.9996  Validation loss = 1.9121  \n",
      "\n",
      "Fold: 6  Epoch: 66  Training loss = 1.9992  Validation loss = 1.9114  \n",
      "\n",
      "Fold: 6  Epoch: 67  Training loss = 1.9990  Validation loss = 1.9106  \n",
      "\n",
      "Fold: 6  Epoch: 68  Training loss = 1.9987  Validation loss = 1.9097  \n",
      "\n",
      "Fold: 6  Epoch: 69  Training loss = 1.9984  Validation loss = 1.9091  \n",
      "\n",
      "Fold: 6  Epoch: 70  Training loss = 1.9978  Validation loss = 1.9076  \n",
      "\n",
      "Fold: 6  Epoch: 71  Training loss = 1.9974  Validation loss = 1.9067  \n",
      "\n",
      "Fold: 6  Epoch: 72  Training loss = 1.9970  Validation loss = 1.9057  \n",
      "\n",
      "Fold: 6  Epoch: 73  Training loss = 1.9967  Validation loss = 1.9051  \n",
      "\n",
      "Fold: 6  Epoch: 74  Training loss = 1.9964  Validation loss = 1.9043  \n",
      "\n",
      "Fold: 6  Epoch: 75  Training loss = 1.9958  Validation loss = 1.9028  \n",
      "\n",
      "Fold: 6  Epoch: 76  Training loss = 1.9955  Validation loss = 1.9019  \n",
      "\n",
      "Fold: 6  Epoch: 77  Training loss = 1.9952  Validation loss = 1.9013  \n",
      "\n",
      "Fold: 6  Epoch: 78  Training loss = 1.9950  Validation loss = 1.9008  \n",
      "\n",
      "Fold: 6  Epoch: 79  Training loss = 1.9945  Validation loss = 1.8996  \n",
      "\n",
      "Fold: 6  Epoch: 80  Training loss = 1.9940  Validation loss = 1.8982  \n",
      "\n",
      "Fold: 6  Epoch: 81  Training loss = 1.9935  Validation loss = 1.8967  \n",
      "\n",
      "Fold: 6  Epoch: 82  Training loss = 1.9932  Validation loss = 1.8960  \n",
      "\n",
      "Fold: 6  Epoch: 83  Training loss = 1.9926  Validation loss = 1.8947  \n",
      "\n",
      "Fold: 6  Epoch: 84  Training loss = 1.9921  Validation loss = 1.8934  \n",
      "\n",
      "Fold: 6  Epoch: 85  Training loss = 1.9917  Validation loss = 1.8922  \n",
      "\n",
      "Fold: 6  Epoch: 86  Training loss = 1.9911  Validation loss = 1.8906  \n",
      "\n",
      "Fold: 6  Epoch: 87  Training loss = 1.9908  Validation loss = 1.8898  \n",
      "\n",
      "Fold: 6  Epoch: 88  Training loss = 1.9907  Validation loss = 1.8897  \n",
      "\n",
      "Fold: 6  Epoch: 89  Training loss = 1.9904  Validation loss = 1.8890  \n",
      "\n",
      "Fold: 6  Epoch: 90  Training loss = 1.9901  Validation loss = 1.8880  \n",
      "\n",
      "Fold: 6  Epoch: 91  Training loss = 1.9896  Validation loss = 1.8868  \n",
      "\n",
      "Fold: 6  Epoch: 92  Training loss = 1.9891  Validation loss = 1.8854  \n",
      "\n",
      "Fold: 6  Epoch: 93  Training loss = 1.9886  Validation loss = 1.8842  \n",
      "\n",
      "Fold: 6  Epoch: 94  Training loss = 1.9884  Validation loss = 1.8837  \n",
      "\n",
      "Fold: 6  Epoch: 95  Training loss = 1.9881  Validation loss = 1.8831  \n",
      "\n",
      "Fold: 6  Epoch: 96  Training loss = 1.9879  Validation loss = 1.8827  \n",
      "\n",
      "Fold: 6  Epoch: 97  Training loss = 1.9877  Validation loss = 1.8821  \n",
      "\n",
      "Fold: 6  Epoch: 98  Training loss = 1.9873  Validation loss = 1.8814  \n",
      "\n",
      "Fold: 6  Epoch: 99  Training loss = 1.9869  Validation loss = 1.8803  \n",
      "\n",
      "Fold: 6  Epoch: 100  Training loss = 1.9867  Validation loss = 1.8798  \n",
      "\n",
      "Fold: 6  Epoch: 101  Training loss = 1.9865  Validation loss = 1.8794  \n",
      "\n",
      "Fold: 6  Epoch: 102  Training loss = 1.9861  Validation loss = 1.8784  \n",
      "\n",
      "Fold: 6  Epoch: 103  Training loss = 1.9858  Validation loss = 1.8776  \n",
      "\n",
      "Fold: 6  Epoch: 104  Training loss = 1.9854  Validation loss = 1.8766  \n",
      "\n",
      "Fold: 6  Epoch: 105  Training loss = 1.9851  Validation loss = 1.8758  \n",
      "\n",
      "Fold: 6  Epoch: 106  Training loss = 1.9847  Validation loss = 1.8748  \n",
      "\n",
      "Fold: 6  Epoch: 107  Training loss = 1.9843  Validation loss = 1.8734  \n",
      "\n",
      "Fold: 6  Epoch: 108  Training loss = 1.9838  Validation loss = 1.8724  \n",
      "\n",
      "Fold: 6  Epoch: 109  Training loss = 1.9833  Validation loss = 1.8711  \n",
      "\n",
      "Fold: 6  Epoch: 110  Training loss = 1.9831  Validation loss = 1.8705  \n",
      "\n",
      "Fold: 6  Epoch: 111  Training loss = 1.9828  Validation loss = 1.8699  \n",
      "\n",
      "Fold: 6  Epoch: 112  Training loss = 1.9824  Validation loss = 1.8687  \n",
      "\n",
      "Fold: 6  Epoch: 113  Training loss = 1.9820  Validation loss = 1.8680  \n",
      "\n",
      "Fold: 6  Epoch: 114  Training loss = 1.9817  Validation loss = 1.8670  \n",
      "\n",
      "Fold: 6  Epoch: 115  Training loss = 1.9813  Validation loss = 1.8660  \n",
      "\n",
      "Fold: 6  Epoch: 116  Training loss = 1.9809  Validation loss = 1.8648  \n",
      "\n",
      "Fold: 6  Epoch: 117  Training loss = 1.9804  Validation loss = 1.8637  \n",
      "\n",
      "Fold: 6  Epoch: 118  Training loss = 1.9799  Validation loss = 1.8623  \n",
      "\n",
      "Fold: 6  Epoch: 119  Training loss = 1.9795  Validation loss = 1.8612  \n",
      "\n",
      "Fold: 6  Epoch: 120  Training loss = 1.9792  Validation loss = 1.8605  \n",
      "\n",
      "Fold: 6  Epoch: 121  Training loss = 1.9790  Validation loss = 1.8598  \n",
      "\n",
      "Fold: 6  Epoch: 122  Training loss = 1.9784  Validation loss = 1.8584  \n",
      "\n",
      "Fold: 6  Epoch: 123  Training loss = 1.9782  Validation loss = 1.8578  \n",
      "\n",
      "Fold: 6  Epoch: 124  Training loss = 1.9779  Validation loss = 1.8572  \n",
      "\n",
      "Fold: 6  Epoch: 125  Training loss = 1.9776  Validation loss = 1.8563  \n",
      "\n",
      "Fold: 6  Epoch: 126  Training loss = 1.9773  Validation loss = 1.8558  \n",
      "\n",
      "Fold: 6  Epoch: 127  Training loss = 1.9769  Validation loss = 1.8545  \n",
      "\n",
      "Fold: 6  Epoch: 128  Training loss = 1.9765  Validation loss = 1.8537  \n",
      "\n",
      "Fold: 6  Epoch: 129  Training loss = 1.9761  Validation loss = 1.8528  \n",
      "\n",
      "Fold: 6  Epoch: 130  Training loss = 1.9757  Validation loss = 1.8516  \n",
      "\n",
      "Fold: 6  Epoch: 131  Training loss = 1.9754  Validation loss = 1.8508  \n",
      "\n",
      "Fold: 6  Epoch: 132  Training loss = 1.9752  Validation loss = 1.8503  \n",
      "\n",
      "Fold: 6  Epoch: 133  Training loss = 1.9748  Validation loss = 1.8492  \n",
      "\n",
      "Fold: 6  Epoch: 134  Training loss = 1.9745  Validation loss = 1.8485  \n",
      "\n",
      "Fold: 6  Epoch: 135  Training loss = 1.9742  Validation loss = 1.8475  \n",
      "\n",
      "Fold: 6  Epoch: 136  Training loss = 1.9740  Validation loss = 1.8470  \n",
      "\n",
      "Fold: 6  Epoch: 137  Training loss = 1.9737  Validation loss = 1.8461  \n",
      "\n",
      "Fold: 6  Epoch: 138  Training loss = 1.9734  Validation loss = 1.8455  \n",
      "\n",
      "Fold: 6  Epoch: 139  Training loss = 1.9731  Validation loss = 1.8447  \n",
      "\n",
      "Fold: 6  Epoch: 140  Training loss = 1.9730  Validation loss = 1.8443  \n",
      "\n",
      "Fold: 6  Epoch: 141  Training loss = 1.9728  Validation loss = 1.8437  \n",
      "\n",
      "Fold: 6  Epoch: 142  Training loss = 1.9726  Validation loss = 1.8435  \n",
      "\n",
      "Fold: 6  Epoch: 143  Training loss = 1.9722  Validation loss = 1.8424  \n",
      "\n",
      "Fold: 6  Epoch: 144  Training loss = 1.9718  Validation loss = 1.8413  \n",
      "\n",
      "Fold: 6  Epoch: 145  Training loss = 1.9714  Validation loss = 1.8399  \n",
      "\n",
      "Fold: 6  Epoch: 146  Training loss = 1.9713  Validation loss = 1.8396  \n",
      "\n",
      "Fold: 6  Epoch: 147  Training loss = 1.9710  Validation loss = 1.8389  \n",
      "\n",
      "Fold: 6  Epoch: 148  Training loss = 1.9708  Validation loss = 1.8384  \n",
      "\n",
      "Fold: 6  Epoch: 149  Training loss = 1.9705  Validation loss = 1.8375  \n",
      "\n",
      "Fold: 6  Epoch: 150  Training loss = 1.9702  Validation loss = 1.8366  \n",
      "\n",
      "Fold: 6  Epoch: 151  Training loss = 1.9700  Validation loss = 1.8361  \n",
      "\n",
      "Fold: 6  Epoch: 152  Training loss = 1.9697  Validation loss = 1.8353  \n",
      "\n",
      "Fold: 6  Epoch: 153  Training loss = 1.9696  Validation loss = 1.8352  \n",
      "\n",
      "Fold: 6  Epoch: 154  Training loss = 1.9695  Validation loss = 1.8347  \n",
      "\n",
      "Fold: 6  Epoch: 155  Training loss = 1.9692  Validation loss = 1.8338  \n",
      "\n",
      "Fold: 6  Epoch: 156  Training loss = 1.9689  Validation loss = 1.8333  \n",
      "\n",
      "Fold: 6  Epoch: 157  Training loss = 1.9688  Validation loss = 1.8329  \n",
      "\n",
      "Fold: 6  Epoch: 158  Training loss = 1.9683  Validation loss = 1.8314  \n",
      "\n",
      "Fold: 6  Epoch: 159  Training loss = 1.9680  Validation loss = 1.8303  \n",
      "\n",
      "Fold: 6  Epoch: 160  Training loss = 1.9676  Validation loss = 1.8293  \n",
      "\n",
      "Fold: 6  Epoch: 161  Training loss = 1.9672  Validation loss = 1.8283  \n",
      "\n",
      "Fold: 6  Epoch: 162  Training loss = 1.9668  Validation loss = 1.8273  \n",
      "\n",
      "Fold: 6  Epoch: 163  Training loss = 1.9666  Validation loss = 1.8266  \n",
      "\n",
      "Fold: 6  Epoch: 164  Training loss = 1.9662  Validation loss = 1.8257  \n",
      "\n",
      "Fold: 6  Epoch: 165  Training loss = 1.9658  Validation loss = 1.8246  \n",
      "\n",
      "Fold: 6  Epoch: 166  Training loss = 1.9655  Validation loss = 1.8238  \n",
      "\n",
      "Fold: 6  Epoch: 167  Training loss = 1.9652  Validation loss = 1.8228  \n",
      "\n",
      "Fold: 6  Epoch: 168  Training loss = 1.9648  Validation loss = 1.8215  \n",
      "\n",
      "Fold: 6  Epoch: 169  Training loss = 1.9644  Validation loss = 1.8205  \n",
      "\n",
      "Fold: 6  Epoch: 170  Training loss = 1.9639  Validation loss = 1.8192  \n",
      "\n",
      "Fold: 6  Epoch: 171  Training loss = 1.9634  Validation loss = 1.8179  \n",
      "\n",
      "Fold: 6  Epoch: 172  Training loss = 1.9631  Validation loss = 1.8173  \n",
      "\n",
      "Fold: 6  Epoch: 173  Training loss = 1.9629  Validation loss = 1.8170  \n",
      "\n",
      "Fold: 6  Epoch: 174  Training loss = 1.9627  Validation loss = 1.8164  \n",
      "\n",
      "Fold: 6  Epoch: 175  Training loss = 1.9622  Validation loss = 1.8150  \n",
      "\n",
      "Fold: 6  Epoch: 176  Training loss = 1.9618  Validation loss = 1.8136  \n",
      "\n",
      "Fold: 6  Epoch: 177  Training loss = 1.9615  Validation loss = 1.8127  \n",
      "\n",
      "Fold: 6  Epoch: 178  Training loss = 1.9611  Validation loss = 1.8114  \n",
      "\n",
      "Fold: 6  Epoch: 179  Training loss = 1.9607  Validation loss = 1.8104  \n",
      "\n",
      "Fold: 6  Epoch: 180  Training loss = 1.9606  Validation loss = 1.8101  \n",
      "\n",
      "Fold: 6  Epoch: 181  Training loss = 1.9604  Validation loss = 1.8094  \n",
      "\n",
      "Fold: 6  Epoch: 182  Training loss = 1.9601  Validation loss = 1.8089  \n",
      "\n",
      "Fold: 6  Epoch: 183  Training loss = 1.9599  Validation loss = 1.8083  \n",
      "\n",
      "Fold: 6  Epoch: 184  Training loss = 1.9595  Validation loss = 1.8070  \n",
      "\n",
      "Fold: 6  Epoch: 185  Training loss = 1.9593  Validation loss = 1.8065  \n",
      "\n",
      "Fold: 6  Epoch: 186  Training loss = 1.9591  Validation loss = 1.8059  \n",
      "\n",
      "Fold: 6  Epoch: 187  Training loss = 1.9589  Validation loss = 1.8055  \n",
      "\n",
      "Fold: 6  Epoch: 188  Training loss = 1.9585  Validation loss = 1.8043  \n",
      "\n",
      "Fold: 6  Epoch: 189  Training loss = 1.9583  Validation loss = 1.8037  \n",
      "\n",
      "Fold: 6  Epoch: 190  Training loss = 1.9581  Validation loss = 1.8032  \n",
      "\n",
      "Fold: 6  Epoch: 191  Training loss = 1.9579  Validation loss = 1.8025  \n",
      "\n",
      "Fold: 6  Epoch: 192  Training loss = 1.9577  Validation loss = 1.8019  \n",
      "\n",
      "Fold: 6  Epoch: 193  Training loss = 1.9576  Validation loss = 1.8018  \n",
      "\n",
      "Fold: 6  Epoch: 194  Training loss = 1.9574  Validation loss = 1.8013  \n",
      "\n",
      "Fold: 6  Epoch: 195  Training loss = 1.9571  Validation loss = 1.8004  \n",
      "\n",
      "Fold: 6  Epoch: 196  Training loss = 1.9569  Validation loss = 1.8000  \n",
      "\n",
      "Fold: 6  Epoch: 197  Training loss = 1.9566  Validation loss = 1.7990  \n",
      "\n",
      "Fold: 6  Epoch: 198  Training loss = 1.9564  Validation loss = 1.7982  \n",
      "\n",
      "Fold: 6  Epoch: 199  Training loss = 1.9560  Validation loss = 1.7969  \n",
      "\n",
      "Fold: 6  Epoch: 200  Training loss = 1.9556  Validation loss = 1.7957  \n",
      "\n",
      "Fold: 6  Epoch: 201  Training loss = 1.9552  Validation loss = 1.7946  \n",
      "\n",
      "Fold: 6  Epoch: 202  Training loss = 1.9550  Validation loss = 1.7941  \n",
      "\n",
      "Fold: 6  Epoch: 203  Training loss = 1.9547  Validation loss = 1.7933  \n",
      "\n",
      "Fold: 6  Epoch: 204  Training loss = 1.9546  Validation loss = 1.7930  \n",
      "\n",
      "Fold: 6  Epoch: 205  Training loss = 1.9542  Validation loss = 1.7917  \n",
      "\n",
      "Fold: 6  Epoch: 206  Training loss = 1.9539  Validation loss = 1.7910  \n",
      "\n",
      "Fold: 6  Epoch: 207  Training loss = 1.9536  Validation loss = 1.7898  \n",
      "\n",
      "Fold: 6  Epoch: 208  Training loss = 1.9533  Validation loss = 1.7891  \n",
      "\n",
      "Fold: 6  Epoch: 209  Training loss = 1.9530  Validation loss = 1.7883  \n",
      "\n",
      "Fold: 6  Epoch: 210  Training loss = 1.9527  Validation loss = 1.7877  \n",
      "\n",
      "Fold: 6  Epoch: 211  Training loss = 1.9523  Validation loss = 1.7866  \n",
      "\n",
      "Fold: 6  Epoch: 212  Training loss = 1.9519  Validation loss = 1.7854  \n",
      "\n",
      "Fold: 6  Epoch: 213  Training loss = 1.9517  Validation loss = 1.7846  \n",
      "\n",
      "Fold: 6  Epoch: 214  Training loss = 1.9515  Validation loss = 1.7843  \n",
      "\n",
      "Fold: 6  Epoch: 215  Training loss = 1.9511  Validation loss = 1.7830  \n",
      "\n",
      "Fold: 6  Epoch: 216  Training loss = 1.9509  Validation loss = 1.7824  \n",
      "\n",
      "Fold: 6  Epoch: 217  Training loss = 1.9504  Validation loss = 1.7810  \n",
      "\n",
      "Fold: 6  Epoch: 218  Training loss = 1.9501  Validation loss = 1.7801  \n",
      "\n",
      "Fold: 6  Epoch: 219  Training loss = 1.9499  Validation loss = 1.7796  \n",
      "\n",
      "Fold: 6  Epoch: 220  Training loss = 1.9496  Validation loss = 1.7789  \n",
      "\n",
      "Fold: 6  Epoch: 221  Training loss = 1.9494  Validation loss = 1.7783  \n",
      "\n",
      "Fold: 6  Epoch: 222  Training loss = 1.9491  Validation loss = 1.7775  \n",
      "\n",
      "Fold: 6  Epoch: 223  Training loss = 1.9488  Validation loss = 1.7765  \n",
      "\n",
      "Fold: 6  Epoch: 224  Training loss = 1.9486  Validation loss = 1.7758  \n",
      "\n",
      "Fold: 6  Epoch: 225  Training loss = 1.9483  Validation loss = 1.7749  \n",
      "\n",
      "Fold: 6  Epoch: 226  Training loss = 1.9479  Validation loss = 1.7737  \n",
      "\n",
      "Fold: 6  Epoch: 227  Training loss = 1.9476  Validation loss = 1.7726  \n",
      "\n",
      "Fold: 6  Epoch: 228  Training loss = 1.9474  Validation loss = 1.7723  \n",
      "\n",
      "Fold: 6  Epoch: 229  Training loss = 1.9471  Validation loss = 1.7714  \n",
      "\n",
      "Fold: 6  Epoch: 230  Training loss = 1.9470  Validation loss = 1.7714  \n",
      "\n",
      "Fold: 6  Epoch: 231  Training loss = 1.9467  Validation loss = 1.7706  \n",
      "\n",
      "Fold: 6  Epoch: 232  Training loss = 1.9465  Validation loss = 1.7699  \n",
      "\n",
      "Fold: 6  Epoch: 233  Training loss = 1.9463  Validation loss = 1.7694  \n",
      "\n",
      "Fold: 6  Epoch: 234  Training loss = 1.9460  Validation loss = 1.7688  \n",
      "\n",
      "Fold: 6  Epoch: 235  Training loss = 1.9460  Validation loss = 1.7687  \n",
      "\n",
      "Fold: 6  Epoch: 236  Training loss = 1.9457  Validation loss = 1.7680  \n",
      "\n",
      "Fold: 6  Epoch: 237  Training loss = 1.9454  Validation loss = 1.7669  \n",
      "\n",
      "Fold: 6  Epoch: 238  Training loss = 1.9450  Validation loss = 1.7660  \n",
      "\n",
      "Fold: 6  Epoch: 239  Training loss = 1.9448  Validation loss = 1.7652  \n",
      "\n",
      "Fold: 6  Epoch: 240  Training loss = 1.9446  Validation loss = 1.7646  \n",
      "\n",
      "Fold: 6  Epoch: 241  Training loss = 1.9443  Validation loss = 1.7639  \n",
      "\n",
      "Fold: 6  Epoch: 242  Training loss = 1.9442  Validation loss = 1.7634  \n",
      "\n",
      "Fold: 6  Epoch: 243  Training loss = 1.9439  Validation loss = 1.7628  \n",
      "\n",
      "Fold: 6  Epoch: 244  Training loss = 1.9437  Validation loss = 1.7622  \n",
      "\n",
      "Fold: 6  Epoch: 245  Training loss = 1.9434  Validation loss = 1.7613  \n",
      "\n",
      "Fold: 6  Epoch: 246  Training loss = 1.9434  Validation loss = 1.7615  \n",
      "\n",
      "Fold: 6  Epoch: 247  Training loss = 1.9431  Validation loss = 1.7608  \n",
      "\n",
      "Fold: 6  Epoch: 248  Training loss = 1.9429  Validation loss = 1.7601  \n",
      "\n",
      "Fold: 6  Epoch: 249  Training loss = 1.9428  Validation loss = 1.7598  \n",
      "\n",
      "Fold: 6  Epoch: 250  Training loss = 1.9424  Validation loss = 1.7587  \n",
      "\n",
      "Fold: 6  Epoch: 251  Training loss = 1.9422  Validation loss = 1.7582  \n",
      "\n",
      "Fold: 6  Epoch: 252  Training loss = 1.9418  Validation loss = 1.7571  \n",
      "\n",
      "Fold: 6  Epoch: 253  Training loss = 1.9417  Validation loss = 1.7566  \n",
      "\n",
      "Fold: 6  Epoch: 254  Training loss = 1.9413  Validation loss = 1.7555  \n",
      "\n",
      "Fold: 6  Epoch: 255  Training loss = 1.9410  Validation loss = 1.7545  \n",
      "\n",
      "Fold: 6  Epoch: 256  Training loss = 1.9407  Validation loss = 1.7535  \n",
      "\n",
      "Fold: 6  Epoch: 257  Training loss = 1.9404  Validation loss = 1.7527  \n",
      "\n",
      "Fold: 6  Epoch: 258  Training loss = 1.9401  Validation loss = 1.7518  \n",
      "\n",
      "Fold: 6  Epoch: 259  Training loss = 1.9397  Validation loss = 1.7507  \n",
      "\n",
      "Fold: 6  Epoch: 260  Training loss = 1.9395  Validation loss = 1.7500  \n",
      "\n",
      "Fold: 6  Epoch: 261  Training loss = 1.9393  Validation loss = 1.7493  \n",
      "\n",
      "Fold: 6  Epoch: 262  Training loss = 1.9391  Validation loss = 1.7488  \n",
      "\n",
      "Fold: 6  Epoch: 263  Training loss = 1.9389  Validation loss = 1.7483  \n",
      "\n",
      "Fold: 6  Epoch: 264  Training loss = 1.9386  Validation loss = 1.7473  \n",
      "\n",
      "Fold: 6  Epoch: 265  Training loss = 1.9383  Validation loss = 1.7464  \n",
      "\n",
      "Fold: 6  Epoch: 266  Training loss = 1.9379  Validation loss = 1.7451  \n",
      "\n",
      "Fold: 6  Epoch: 267  Training loss = 1.9375  Validation loss = 1.7436  \n",
      "\n",
      "Fold: 6  Epoch: 268  Training loss = 1.9373  Validation loss = 1.7433  \n",
      "\n",
      "Fold: 6  Epoch: 269  Training loss = 1.9371  Validation loss = 1.7426  \n",
      "\n",
      "Fold: 6  Epoch: 270  Training loss = 1.9368  Validation loss = 1.7416  \n",
      "\n",
      "Fold: 6  Epoch: 271  Training loss = 1.9364  Validation loss = 1.7403  \n",
      "\n",
      "Fold: 6  Epoch: 272  Training loss = 1.9360  Validation loss = 1.7393  \n",
      "\n",
      "Fold: 6  Epoch: 273  Training loss = 1.9356  Validation loss = 1.7379  \n",
      "\n",
      "Fold: 6  Epoch: 274  Training loss = 1.9352  Validation loss = 1.7368  \n",
      "\n",
      "Fold: 6  Epoch: 275  Training loss = 1.9349  Validation loss = 1.7360  \n",
      "\n",
      "Fold: 6  Epoch: 276  Training loss = 1.9346  Validation loss = 1.7351  \n",
      "\n",
      "Fold: 6  Epoch: 277  Training loss = 1.9344  Validation loss = 1.7345  \n",
      "\n",
      "Fold: 6  Epoch: 278  Training loss = 1.9343  Validation loss = 1.7343  \n",
      "\n",
      "Fold: 6  Epoch: 279  Training loss = 1.9341  Validation loss = 1.7339  \n",
      "\n",
      "Fold: 6  Epoch: 280  Training loss = 1.9338  Validation loss = 1.7330  \n",
      "\n",
      "Fold: 6  Epoch: 281  Training loss = 1.9334  Validation loss = 1.7317  \n",
      "\n",
      "Fold: 6  Epoch: 282  Training loss = 1.9332  Validation loss = 1.7311  \n",
      "\n",
      "Fold: 6  Epoch: 283  Training loss = 1.9328  Validation loss = 1.7300  \n",
      "\n",
      "Fold: 6  Epoch: 284  Training loss = 1.9325  Validation loss = 1.7290  \n",
      "\n",
      "Fold: 6  Epoch: 285  Training loss = 1.9323  Validation loss = 1.7284  \n",
      "\n",
      "Fold: 6  Epoch: 286  Training loss = 1.9321  Validation loss = 1.7279  \n",
      "\n",
      "Fold: 6  Epoch: 287  Training loss = 1.9319  Validation loss = 1.7272  \n",
      "\n",
      "Fold: 6  Epoch: 288  Training loss = 1.9317  Validation loss = 1.7264  \n",
      "\n",
      "Fold: 6  Epoch: 289  Training loss = 1.9314  Validation loss = 1.7258  \n",
      "\n",
      "Fold: 6  Epoch: 290  Training loss = 1.9311  Validation loss = 1.7249  \n",
      "\n",
      "Fold: 6  Epoch: 291  Training loss = 1.9309  Validation loss = 1.7241  \n",
      "\n",
      "Fold: 6  Epoch: 292  Training loss = 1.9308  Validation loss = 1.7238  \n",
      "\n",
      "Fold: 6  Epoch: 293  Training loss = 1.9305  Validation loss = 1.7228  \n",
      "\n",
      "Fold: 6  Epoch: 294  Training loss = 1.9301  Validation loss = 1.7215  \n",
      "\n",
      "Fold: 6  Epoch: 295  Training loss = 1.9298  Validation loss = 1.7206  \n",
      "\n",
      "Fold: 6  Epoch: 296  Training loss = 1.9294  Validation loss = 1.7193  \n",
      "\n",
      "Fold: 6  Epoch: 297  Training loss = 1.9293  Validation loss = 1.7190  \n",
      "\n",
      "Fold: 6  Epoch: 298  Training loss = 1.9290  Validation loss = 1.7181  \n",
      "\n",
      "Fold: 6  Epoch: 299  Training loss = 1.9287  Validation loss = 1.7171  \n",
      "\n",
      "Fold: 6  Epoch: 300  Training loss = 1.9284  Validation loss = 1.7161  \n",
      "\n",
      "Fold: 6  Epoch: 301  Training loss = 1.9282  Validation loss = 1.7155  \n",
      "\n",
      "Fold: 6  Epoch: 302  Training loss = 1.9281  Validation loss = 1.7155  \n",
      "\n",
      "Fold: 6  Epoch: 303  Training loss = 1.9278  Validation loss = 1.7143  \n",
      "\n",
      "Fold: 6  Epoch: 304  Training loss = 1.9276  Validation loss = 1.7139  \n",
      "\n",
      "Fold: 6  Epoch: 305  Training loss = 1.9275  Validation loss = 1.7136  \n",
      "\n",
      "Fold: 6  Epoch: 306  Training loss = 1.9272  Validation loss = 1.7126  \n",
      "\n",
      "Fold: 6  Epoch: 307  Training loss = 1.9270  Validation loss = 1.7116  \n",
      "\n",
      "Fold: 6  Epoch: 308  Training loss = 1.9268  Validation loss = 1.7113  \n",
      "\n",
      "Fold: 6  Epoch: 309  Training loss = 1.9265  Validation loss = 1.7101  \n",
      "\n",
      "Fold: 6  Epoch: 310  Training loss = 1.9261  Validation loss = 1.7091  \n",
      "\n",
      "Fold: 6  Epoch: 311  Training loss = 1.9260  Validation loss = 1.7089  \n",
      "\n",
      "Fold: 6  Epoch: 312  Training loss = 1.9259  Validation loss = 1.7083  \n",
      "\n",
      "Fold: 6  Epoch: 313  Training loss = 1.9257  Validation loss = 1.7077  \n",
      "\n",
      "Fold: 6  Epoch: 314  Training loss = 1.9253  Validation loss = 1.7065  \n",
      "\n",
      "Fold: 6  Epoch: 315  Training loss = 1.9250  Validation loss = 1.7057  \n",
      "\n",
      "Fold: 6  Epoch: 316  Training loss = 1.9249  Validation loss = 1.7053  \n",
      "\n",
      "Fold: 6  Epoch: 317  Training loss = 1.9248  Validation loss = 1.7050  \n",
      "\n",
      "Fold: 6  Epoch: 318  Training loss = 1.9246  Validation loss = 1.7045  \n",
      "\n",
      "Fold: 6  Epoch: 319  Training loss = 1.9245  Validation loss = 1.7040  \n",
      "\n",
      "Fold: 6  Epoch: 320  Training loss = 1.9244  Validation loss = 1.7038  \n",
      "\n",
      "Fold: 6  Epoch: 321  Training loss = 1.9242  Validation loss = 1.7034  \n",
      "\n",
      "Fold: 6  Epoch: 322  Training loss = 1.9241  Validation loss = 1.7032  \n",
      "\n",
      "Fold: 6  Epoch: 323  Training loss = 1.9238  Validation loss = 1.7021  \n",
      "\n",
      "Fold: 6  Epoch: 324  Training loss = 1.9237  Validation loss = 1.7017  \n",
      "\n",
      "Fold: 6  Epoch: 325  Training loss = 1.9234  Validation loss = 1.7007  \n",
      "\n",
      "Fold: 6  Epoch: 326  Training loss = 1.9231  Validation loss = 1.6997  \n",
      "\n",
      "Fold: 6  Epoch: 327  Training loss = 1.9228  Validation loss = 1.6987  \n",
      "\n",
      "Fold: 6  Epoch: 328  Training loss = 1.9224  Validation loss = 1.6976  \n",
      "\n",
      "Fold: 6  Epoch: 329  Training loss = 1.9223  Validation loss = 1.6974  \n",
      "\n",
      "Fold: 6  Epoch: 330  Training loss = 1.9221  Validation loss = 1.6967  \n",
      "\n",
      "Fold: 6  Epoch: 331  Training loss = 1.9219  Validation loss = 1.6963  \n",
      "\n",
      "Fold: 6  Epoch: 332  Training loss = 1.9218  Validation loss = 1.6959  \n",
      "\n",
      "Fold: 6  Epoch: 333  Training loss = 1.9215  Validation loss = 1.6951  \n",
      "\n",
      "Fold: 6  Epoch: 334  Training loss = 1.9214  Validation loss = 1.6950  \n",
      "\n",
      "Fold: 6  Epoch: 335  Training loss = 1.9212  Validation loss = 1.6942  \n",
      "\n",
      "Fold: 6  Epoch: 336  Training loss = 1.9209  Validation loss = 1.6934  \n",
      "\n",
      "Fold: 6  Epoch: 337  Training loss = 1.9207  Validation loss = 1.6928  \n",
      "\n",
      "Fold: 6  Epoch: 338  Training loss = 1.9205  Validation loss = 1.6920  \n",
      "\n",
      "Fold: 6  Epoch: 339  Training loss = 1.9203  Validation loss = 1.6914  \n",
      "\n",
      "Fold: 6  Epoch: 340  Training loss = 1.9201  Validation loss = 1.6909  \n",
      "\n",
      "Fold: 6  Epoch: 341  Training loss = 1.9199  Validation loss = 1.6904  \n",
      "\n",
      "Fold: 6  Epoch: 342  Training loss = 1.9196  Validation loss = 1.6893  \n",
      "\n",
      "Fold: 6  Epoch: 343  Training loss = 1.9194  Validation loss = 1.6886  \n",
      "\n",
      "Fold: 6  Epoch: 344  Training loss = 1.9191  Validation loss = 1.6875  \n",
      "\n",
      "Fold: 6  Epoch: 345  Training loss = 1.9190  Validation loss = 1.6873  \n",
      "\n",
      "Fold: 6  Epoch: 346  Training loss = 1.9186  Validation loss = 1.6859  \n",
      "\n",
      "Fold: 6  Epoch: 347  Training loss = 1.9183  Validation loss = 1.6850  \n",
      "\n",
      "Fold: 6  Epoch: 348  Training loss = 1.9182  Validation loss = 1.6848  \n",
      "\n",
      "Fold: 6  Epoch: 349  Training loss = 1.9178  Validation loss = 1.6838  \n",
      "\n",
      "Fold: 6  Epoch: 350  Training loss = 1.9175  Validation loss = 1.6831  \n",
      "\n",
      "Fold: 6  Epoch: 351  Training loss = 1.9173  Validation loss = 1.6824  \n",
      "\n",
      "Fold: 6  Epoch: 352  Training loss = 1.9172  Validation loss = 1.6821  \n",
      "\n",
      "Fold: 6  Epoch: 353  Training loss = 1.9169  Validation loss = 1.6812  \n",
      "\n",
      "Fold: 6  Epoch: 354  Training loss = 1.9168  Validation loss = 1.6806  \n",
      "\n",
      "Fold: 6  Epoch: 355  Training loss = 1.9166  Validation loss = 1.6801  \n",
      "\n",
      "Fold: 6  Epoch: 356  Training loss = 1.9165  Validation loss = 1.6797  \n",
      "\n",
      "Fold: 6  Epoch: 357  Training loss = 1.9162  Validation loss = 1.6787  \n",
      "\n",
      "Fold: 6  Epoch: 358  Training loss = 1.9159  Validation loss = 1.6780  \n",
      "\n",
      "Fold: 6  Epoch: 359  Training loss = 1.9158  Validation loss = 1.6776  \n",
      "\n",
      "Fold: 6  Epoch: 360  Training loss = 1.9156  Validation loss = 1.6771  \n",
      "\n",
      "Fold: 6  Epoch: 361  Training loss = 1.9153  Validation loss = 1.6761  \n",
      "\n",
      "Fold: 6  Epoch: 362  Training loss = 1.9151  Validation loss = 1.6758  \n",
      "\n",
      "Fold: 6  Epoch: 363  Training loss = 1.9149  Validation loss = 1.6749  \n",
      "\n",
      "Fold: 6  Epoch: 364  Training loss = 1.9148  Validation loss = 1.6746  \n",
      "\n",
      "Fold: 6  Epoch: 365  Training loss = 1.9147  Validation loss = 1.6743  \n",
      "\n",
      "Fold: 6  Epoch: 366  Training loss = 1.9145  Validation loss = 1.6738  \n",
      "\n",
      "Fold: 6  Epoch: 367  Training loss = 1.9143  Validation loss = 1.6734  \n",
      "\n",
      "Fold: 6  Epoch: 368  Training loss = 1.9141  Validation loss = 1.6728  \n",
      "\n",
      "Fold: 6  Epoch: 369  Training loss = 1.9139  Validation loss = 1.6720  \n",
      "\n",
      "Fold: 6  Epoch: 370  Training loss = 1.9137  Validation loss = 1.6717  \n",
      "\n",
      "Fold: 6  Epoch: 371  Training loss = 1.9135  Validation loss = 1.6712  \n",
      "\n",
      "Fold: 6  Epoch: 372  Training loss = 1.9135  Validation loss = 1.6710  \n",
      "\n",
      "Fold: 6  Epoch: 373  Training loss = 1.9132  Validation loss = 1.6704  \n",
      "\n",
      "Fold: 6  Epoch: 374  Training loss = 1.9129  Validation loss = 1.6694  \n",
      "\n",
      "Fold: 6  Epoch: 375  Training loss = 1.9128  Validation loss = 1.6690  \n",
      "\n",
      "Fold: 6  Epoch: 376  Training loss = 1.9124  Validation loss = 1.6676  \n",
      "\n",
      "Fold: 6  Epoch: 377  Training loss = 1.9122  Validation loss = 1.6670  \n",
      "\n",
      "Fold: 6  Epoch: 378  Training loss = 1.9120  Validation loss = 1.6666  \n",
      "\n",
      "Fold: 6  Epoch: 379  Training loss = 1.9119  Validation loss = 1.6663  \n",
      "\n",
      "Fold: 6  Epoch: 380  Training loss = 1.9117  Validation loss = 1.6657  \n",
      "\n",
      "Fold: 6  Epoch: 381  Training loss = 1.9117  Validation loss = 1.6657  \n",
      "\n",
      "Fold: 6  Epoch: 382  Training loss = 1.9114  Validation loss = 1.6649  \n",
      "\n",
      "Fold: 6  Epoch: 383  Training loss = 1.9113  Validation loss = 1.6643  \n",
      "\n",
      "Fold: 6  Epoch: 384  Training loss = 1.9110  Validation loss = 1.6635  \n",
      "\n",
      "Fold: 6  Epoch: 385  Training loss = 1.9108  Validation loss = 1.6629  \n",
      "\n",
      "Fold: 6  Epoch: 386  Training loss = 1.9105  Validation loss = 1.6617  \n",
      "\n",
      "Fold: 6  Epoch: 387  Training loss = 1.9103  Validation loss = 1.6613  \n",
      "\n",
      "Fold: 6  Epoch: 388  Training loss = 1.9100  Validation loss = 1.6602  \n",
      "\n",
      "Fold: 6  Epoch: 389  Training loss = 1.9099  Validation loss = 1.6598  \n",
      "\n",
      "Fold: 6  Epoch: 390  Training loss = 1.9098  Validation loss = 1.6594  \n",
      "\n",
      "Fold: 6  Epoch: 391  Training loss = 1.9096  Validation loss = 1.6588  \n",
      "\n",
      "Fold: 6  Epoch: 392  Training loss = 1.9095  Validation loss = 1.6586  \n",
      "\n",
      "Fold: 6  Epoch: 393  Training loss = 1.9093  Validation loss = 1.6578  \n",
      "\n",
      "Fold: 6  Epoch: 394  Training loss = 1.9090  Validation loss = 1.6569  \n",
      "\n",
      "Fold: 6  Epoch: 395  Training loss = 1.9089  Validation loss = 1.6566  \n",
      "\n",
      "Fold: 6  Epoch: 396  Training loss = 1.9086  Validation loss = 1.6557  \n",
      "\n",
      "Fold: 6  Epoch: 397  Training loss = 1.9083  Validation loss = 1.6546  \n",
      "\n",
      "Fold: 6  Epoch: 398  Training loss = 1.9080  Validation loss = 1.6538  \n",
      "\n",
      "Fold: 6  Epoch: 399  Training loss = 1.9079  Validation loss = 1.6535  \n",
      "\n",
      "Fold: 6  Epoch: 400  Training loss = 1.9077  Validation loss = 1.6530  \n",
      "\n",
      "Fold: 6  Epoch: 401  Training loss = 1.9074  Validation loss = 1.6521  \n",
      "\n",
      "Fold: 6  Epoch: 402  Training loss = 1.9072  Validation loss = 1.6512  \n",
      "\n",
      "Fold: 6  Epoch: 403  Training loss = 1.9070  Validation loss = 1.6508  \n",
      "\n",
      "Fold: 6  Epoch: 404  Training loss = 1.9070  Validation loss = 1.6507  \n",
      "\n",
      "Fold: 6  Epoch: 405  Training loss = 1.9067  Validation loss = 1.6496  \n",
      "\n",
      "Fold: 6  Epoch: 406  Training loss = 1.9065  Validation loss = 1.6493  \n",
      "\n",
      "Fold: 6  Epoch: 407  Training loss = 1.9065  Validation loss = 1.6493  \n",
      "\n",
      "Fold: 6  Epoch: 408  Training loss = 1.9063  Validation loss = 1.6487  \n",
      "\n",
      "Fold: 6  Epoch: 409  Training loss = 1.9061  Validation loss = 1.6483  \n",
      "\n",
      "Fold: 6  Epoch: 410  Training loss = 1.9060  Validation loss = 1.6478  \n",
      "\n",
      "Fold: 6  Epoch: 411  Training loss = 1.9057  Validation loss = 1.6467  \n",
      "\n",
      "Fold: 6  Epoch: 412  Training loss = 1.9056  Validation loss = 1.6465  \n",
      "\n",
      "Fold: 6  Epoch: 413  Training loss = 1.9052  Validation loss = 1.6454  \n",
      "\n",
      "Fold: 6  Epoch: 414  Training loss = 1.9052  Validation loss = 1.6452  \n",
      "\n",
      "Fold: 6  Epoch: 415  Training loss = 1.9049  Validation loss = 1.6444  \n",
      "\n",
      "Fold: 6  Epoch: 416  Training loss = 1.9048  Validation loss = 1.6439  \n",
      "\n",
      "Fold: 6  Epoch: 417  Training loss = 1.9047  Validation loss = 1.6438  \n",
      "\n",
      "Fold: 6  Epoch: 418  Training loss = 1.9045  Validation loss = 1.6431  \n",
      "\n",
      "Fold: 6  Epoch: 419  Training loss = 1.9043  Validation loss = 1.6425  \n",
      "\n",
      "Fold: 6  Epoch: 420  Training loss = 1.9041  Validation loss = 1.6420  \n",
      "\n",
      "Fold: 6  Epoch: 421  Training loss = 1.9039  Validation loss = 1.6412  \n",
      "\n",
      "Fold: 6  Epoch: 422  Training loss = 1.9037  Validation loss = 1.6406  \n",
      "\n",
      "Fold: 6  Epoch: 423  Training loss = 1.9035  Validation loss = 1.6402  \n",
      "\n",
      "Fold: 6  Epoch: 424  Training loss = 1.9033  Validation loss = 1.6396  \n",
      "\n",
      "Fold: 6  Epoch: 425  Training loss = 1.9031  Validation loss = 1.6390  \n",
      "\n",
      "Fold: 6  Epoch: 426  Training loss = 1.9030  Validation loss = 1.6388  \n",
      "\n",
      "Fold: 6  Epoch: 427  Training loss = 1.9028  Validation loss = 1.6383  \n",
      "\n",
      "Fold: 6  Epoch: 428  Training loss = 1.9027  Validation loss = 1.6379  \n",
      "\n",
      "Fold: 6  Epoch: 429  Training loss = 1.9025  Validation loss = 1.6376  \n",
      "\n",
      "Fold: 6  Epoch: 430  Training loss = 1.9024  Validation loss = 1.6374  \n",
      "\n",
      "Fold: 6  Epoch: 431  Training loss = 1.9023  Validation loss = 1.6369  \n",
      "\n",
      "Fold: 6  Epoch: 432  Training loss = 1.9020  Validation loss = 1.6361  \n",
      "\n",
      "Fold: 6  Epoch: 433  Training loss = 1.9019  Validation loss = 1.6358  \n",
      "\n",
      "Fold: 6  Epoch: 434  Training loss = 1.9017  Validation loss = 1.6349  \n",
      "\n",
      "Fold: 6  Epoch: 435  Training loss = 1.9015  Validation loss = 1.6341  \n",
      "\n",
      "Fold: 6  Epoch: 436  Training loss = 1.9013  Validation loss = 1.6337  \n",
      "\n",
      "Fold: 6  Epoch: 437  Training loss = 1.9011  Validation loss = 1.6329  \n",
      "\n",
      "Fold: 6  Epoch: 438  Training loss = 1.9009  Validation loss = 1.6322  \n",
      "\n",
      "Fold: 6  Epoch: 439  Training loss = 1.9007  Validation loss = 1.6315  \n",
      "\n",
      "Fold: 6  Epoch: 440  Training loss = 1.9004  Validation loss = 1.6307  \n",
      "\n",
      "Fold: 6  Epoch: 441  Training loss = 1.9001  Validation loss = 1.6295  \n",
      "\n",
      "Fold: 6  Epoch: 442  Training loss = 1.8999  Validation loss = 1.6287  \n",
      "\n",
      "Fold: 6  Epoch: 443  Training loss = 1.8998  Validation loss = 1.6284  \n",
      "\n",
      "Fold: 6  Epoch: 444  Training loss = 1.8994  Validation loss = 1.6270  \n",
      "\n",
      "Fold: 6  Epoch: 445  Training loss = 1.8992  Validation loss = 1.6264  \n",
      "\n",
      "Fold: 6  Epoch: 446  Training loss = 1.8990  Validation loss = 1.6256  \n",
      "\n",
      "Fold: 6  Epoch: 447  Training loss = 1.8987  Validation loss = 1.6248  \n",
      "\n",
      "Fold: 6  Epoch: 448  Training loss = 1.8984  Validation loss = 1.6237  \n",
      "\n",
      "Fold: 6  Epoch: 449  Training loss = 1.8981  Validation loss = 1.6225  \n",
      "\n",
      "Fold: 6  Epoch: 450  Training loss = 1.8979  Validation loss = 1.6219  \n",
      "\n",
      "Fold: 6  Epoch: 451  Training loss = 1.8977  Validation loss = 1.6213  \n",
      "\n",
      "Fold: 6  Epoch: 452  Training loss = 1.8977  Validation loss = 1.6214  \n",
      "\n",
      "Fold: 6  Epoch: 453  Training loss = 1.8975  Validation loss = 1.6209  \n",
      "\n",
      "Fold: 6  Epoch: 454  Training loss = 1.8973  Validation loss = 1.6201  \n",
      "\n",
      "Fold: 6  Epoch: 455  Training loss = 1.8972  Validation loss = 1.6197  \n",
      "\n",
      "Fold: 6  Epoch: 456  Training loss = 1.8970  Validation loss = 1.6193  \n",
      "\n",
      "Fold: 6  Epoch: 457  Training loss = 1.8968  Validation loss = 1.6184  \n",
      "\n",
      "Fold: 6  Epoch: 458  Training loss = 1.8967  Validation loss = 1.6182  \n",
      "\n",
      "Fold: 6  Epoch: 459  Training loss = 1.8965  Validation loss = 1.6176  \n",
      "\n",
      "Fold: 6  Epoch: 460  Training loss = 1.8964  Validation loss = 1.6174  \n",
      "\n",
      "Fold: 6  Epoch: 461  Training loss = 1.8962  Validation loss = 1.6169  \n",
      "\n",
      "Fold: 6  Epoch: 462  Training loss = 1.8961  Validation loss = 1.6165  \n",
      "\n",
      "Fold: 6  Epoch: 463  Training loss = 1.8959  Validation loss = 1.6156  \n",
      "\n",
      "Fold: 6  Epoch: 464  Training loss = 1.8957  Validation loss = 1.6151  \n",
      "\n",
      "Fold: 6  Epoch: 465  Training loss = 1.8955  Validation loss = 1.6146  \n",
      "\n",
      "Fold: 6  Epoch: 466  Training loss = 1.8953  Validation loss = 1.6138  \n",
      "\n",
      "Fold: 6  Epoch: 467  Training loss = 1.8951  Validation loss = 1.6131  \n",
      "\n",
      "Fold: 6  Epoch: 468  Training loss = 1.8948  Validation loss = 1.6120  \n",
      "\n",
      "Fold: 6  Epoch: 469  Training loss = 1.8948  Validation loss = 1.6122  \n",
      "\n",
      "Fold: 6  Epoch: 470  Training loss = 1.8946  Validation loss = 1.6114  \n",
      "\n",
      "Fold: 6  Epoch: 471  Training loss = 1.8943  Validation loss = 1.6104  \n",
      "\n",
      "Fold: 6  Epoch: 472  Training loss = 1.8943  Validation loss = 1.6104  \n",
      "\n",
      "Fold: 6  Epoch: 473  Training loss = 1.8941  Validation loss = 1.6097  \n",
      "\n",
      "Fold: 6  Epoch: 474  Training loss = 1.8939  Validation loss = 1.6091  \n",
      "\n",
      "Fold: 6  Epoch: 475  Training loss = 1.8938  Validation loss = 1.6090  \n",
      "\n",
      "Fold: 6  Epoch: 476  Training loss = 1.8936  Validation loss = 1.6084  \n",
      "\n",
      "Fold: 6  Epoch: 477  Training loss = 1.8935  Validation loss = 1.6078  \n",
      "\n",
      "Fold: 6  Epoch: 478  Training loss = 1.8932  Validation loss = 1.6071  \n",
      "\n",
      "Fold: 6  Epoch: 479  Training loss = 1.8930  Validation loss = 1.6060  \n",
      "\n",
      "Fold: 6  Epoch: 480  Training loss = 1.8928  Validation loss = 1.6055  \n",
      "\n",
      "Fold: 6  Epoch: 481  Training loss = 1.8925  Validation loss = 1.6043  \n",
      "\n",
      "Fold: 6  Epoch: 482  Training loss = 1.8923  Validation loss = 1.6036  \n",
      "\n",
      "Fold: 6  Epoch: 483  Training loss = 1.8921  Validation loss = 1.6031  \n",
      "\n",
      "Fold: 6  Epoch: 484  Training loss = 1.8921  Validation loss = 1.6029  \n",
      "\n",
      "Fold: 6  Epoch: 485  Training loss = 1.8919  Validation loss = 1.6023  \n",
      "\n",
      "Fold: 6  Epoch: 486  Training loss = 1.8916  Validation loss = 1.6015  \n",
      "\n",
      "Fold: 6  Epoch: 487  Training loss = 1.8915  Validation loss = 1.6010  \n",
      "\n",
      "Fold: 6  Epoch: 488  Training loss = 1.8913  Validation loss = 1.6006  \n",
      "\n",
      "Fold: 6  Epoch: 489  Training loss = 1.8911  Validation loss = 1.5998  \n",
      "\n",
      "Fold: 6  Epoch: 490  Training loss = 1.8909  Validation loss = 1.5990  \n",
      "\n",
      "Fold: 6  Epoch: 491  Training loss = 1.8907  Validation loss = 1.5984  \n",
      "\n",
      "Fold: 6  Epoch: 492  Training loss = 1.8907  Validation loss = 1.5986  \n",
      "\n",
      "Fold: 6  Epoch: 493  Training loss = 1.8905  Validation loss = 1.5977  \n",
      "\n",
      "Fold: 6  Epoch: 494  Training loss = 1.8902  Validation loss = 1.5967  \n",
      "\n",
      "Fold: 6  Epoch: 495  Training loss = 1.8901  Validation loss = 1.5968  \n",
      "\n",
      "Fold: 6  Epoch: 496  Training loss = 1.8900  Validation loss = 1.5965  \n",
      "\n",
      "Fold: 6  Epoch: 497  Training loss = 1.8900  Validation loss = 1.5968  \n",
      "\n",
      "Fold: 6  Epoch: 498  Training loss = 1.8897  Validation loss = 1.5958  \n",
      "\n",
      "Fold: 6  Epoch: 499  Training loss = 1.8895  Validation loss = 1.5948  \n",
      "\n",
      "Fold: 6  Epoch: 500  Training loss = 1.8892  Validation loss = 1.5939  \n",
      "\n",
      "Check model:  Fold: 6  Optimal epoch: 500  \n",
      "\n",
      "Fold: 7  Epoch: 1  Training loss = 1.8794  Validation loss = 1.4727  \n",
      "\n",
      "Fold: 7  Epoch: 2  Training loss = 1.8791  Validation loss = 1.4718  \n",
      "\n",
      "Fold: 7  Epoch: 3  Training loss = 1.8788  Validation loss = 1.4708  \n",
      "\n",
      "Fold: 7  Epoch: 4  Training loss = 1.8785  Validation loss = 1.4695  \n",
      "\n",
      "Fold: 7  Epoch: 5  Training loss = 1.8783  Validation loss = 1.4690  \n",
      "\n",
      "Fold: 7  Epoch: 6  Training loss = 1.8779  Validation loss = 1.4676  \n",
      "\n",
      "Fold: 7  Epoch: 7  Training loss = 1.8777  Validation loss = 1.4668  \n",
      "\n",
      "Fold: 7  Epoch: 8  Training loss = 1.8774  Validation loss = 1.4657  \n",
      "\n",
      "Fold: 7  Epoch: 9  Training loss = 1.8772  Validation loss = 1.4651  \n",
      "\n",
      "Fold: 7  Epoch: 10  Training loss = 1.8769  Validation loss = 1.4639  \n",
      "\n",
      "Fold: 7  Epoch: 11  Training loss = 1.8768  Validation loss = 1.4636  \n",
      "\n",
      "Fold: 7  Epoch: 12  Training loss = 1.8766  Validation loss = 1.4629  \n",
      "\n",
      "Fold: 7  Epoch: 13  Training loss = 1.8764  Validation loss = 1.4621  \n",
      "\n",
      "Fold: 7  Epoch: 14  Training loss = 1.8761  Validation loss = 1.4602  \n",
      "\n",
      "Fold: 7  Epoch: 15  Training loss = 1.8758  Validation loss = 1.4589  \n",
      "\n",
      "Fold: 7  Epoch: 16  Training loss = 1.8755  Validation loss = 1.4570  \n",
      "\n",
      "Fold: 7  Epoch: 17  Training loss = 1.8752  Validation loss = 1.4562  \n",
      "\n",
      "Fold: 7  Epoch: 18  Training loss = 1.8748  Validation loss = 1.4542  \n",
      "\n",
      "Fold: 7  Epoch: 19  Training loss = 1.8745  Validation loss = 1.4527  \n",
      "\n",
      "Fold: 7  Epoch: 20  Training loss = 1.8742  Validation loss = 1.4516  \n",
      "\n",
      "Fold: 7  Epoch: 21  Training loss = 1.8740  Validation loss = 1.4510  \n",
      "\n",
      "Fold: 7  Epoch: 22  Training loss = 1.8738  Validation loss = 1.4496  \n",
      "\n",
      "Fold: 7  Epoch: 23  Training loss = 1.8733  Validation loss = 1.4476  \n",
      "\n",
      "Fold: 7  Epoch: 24  Training loss = 1.8730  Validation loss = 1.4460  \n",
      "\n",
      "Fold: 7  Epoch: 25  Training loss = 1.8726  Validation loss = 1.4447  \n",
      "\n",
      "Fold: 7  Epoch: 26  Training loss = 1.8723  Validation loss = 1.4436  \n",
      "\n",
      "Fold: 7  Epoch: 27  Training loss = 1.8721  Validation loss = 1.4426  \n",
      "\n",
      "Fold: 7  Epoch: 28  Training loss = 1.8719  Validation loss = 1.4420  \n",
      "\n",
      "Fold: 7  Epoch: 29  Training loss = 1.8717  Validation loss = 1.4410  \n",
      "\n",
      "Fold: 7  Epoch: 30  Training loss = 1.8714  Validation loss = 1.4395  \n",
      "\n",
      "Fold: 7  Epoch: 31  Training loss = 1.8713  Validation loss = 1.4389  \n",
      "\n",
      "Fold: 7  Epoch: 32  Training loss = 1.8710  Validation loss = 1.4374  \n",
      "\n",
      "Fold: 7  Epoch: 33  Training loss = 1.8708  Validation loss = 1.4366  \n",
      "\n",
      "Fold: 7  Epoch: 34  Training loss = 1.8706  Validation loss = 1.4352  \n",
      "\n",
      "Fold: 7  Epoch: 35  Training loss = 1.8703  Validation loss = 1.4341  \n",
      "\n",
      "Fold: 7  Epoch: 36  Training loss = 1.8699  Validation loss = 1.4322  \n",
      "\n",
      "Fold: 7  Epoch: 37  Training loss = 1.8697  Validation loss = 1.4310  \n",
      "\n",
      "Fold: 7  Epoch: 38  Training loss = 1.8693  Validation loss = 1.4290  \n",
      "\n",
      "Fold: 7  Epoch: 39  Training loss = 1.8690  Validation loss = 1.4278  \n",
      "\n",
      "Fold: 7  Epoch: 40  Training loss = 1.8688  Validation loss = 1.4269  \n",
      "\n",
      "Fold: 7  Epoch: 41  Training loss = 1.8686  Validation loss = 1.4261  \n",
      "\n",
      "Fold: 7  Epoch: 42  Training loss = 1.8683  Validation loss = 1.4243  \n",
      "\n",
      "Fold: 7  Epoch: 43  Training loss = 1.8681  Validation loss = 1.4236  \n",
      "\n",
      "Fold: 7  Epoch: 44  Training loss = 1.8678  Validation loss = 1.4223  \n",
      "\n",
      "Fold: 7  Epoch: 45  Training loss = 1.8676  Validation loss = 1.4217  \n",
      "\n",
      "Fold: 7  Epoch: 46  Training loss = 1.8673  Validation loss = 1.4200  \n",
      "\n",
      "Fold: 7  Epoch: 47  Training loss = 1.8670  Validation loss = 1.4186  \n",
      "\n",
      "Fold: 7  Epoch: 48  Training loss = 1.8666  Validation loss = 1.4164  \n",
      "\n",
      "Fold: 7  Epoch: 49  Training loss = 1.8665  Validation loss = 1.4162  \n",
      "\n",
      "Fold: 7  Epoch: 50  Training loss = 1.8662  Validation loss = 1.4152  \n",
      "\n",
      "Fold: 7  Epoch: 51  Training loss = 1.8659  Validation loss = 1.4139  \n",
      "\n",
      "Fold: 7  Epoch: 52  Training loss = 1.8659  Validation loss = 1.4137  \n",
      "\n",
      "Fold: 7  Epoch: 53  Training loss = 1.8656  Validation loss = 1.4124  \n",
      "\n",
      "Fold: 7  Epoch: 54  Training loss = 1.8652  Validation loss = 1.4105  \n",
      "\n",
      "Fold: 7  Epoch: 55  Training loss = 1.8648  Validation loss = 1.4084  \n",
      "\n",
      "Fold: 7  Epoch: 56  Training loss = 1.8647  Validation loss = 1.4081  \n",
      "\n",
      "Fold: 7  Epoch: 57  Training loss = 1.8644  Validation loss = 1.4064  \n",
      "\n",
      "Fold: 7  Epoch: 58  Training loss = 1.8641  Validation loss = 1.4046  \n",
      "\n",
      "Fold: 7  Epoch: 59  Training loss = 1.8638  Validation loss = 1.4033  \n",
      "\n",
      "Fold: 7  Epoch: 60  Training loss = 1.8635  Validation loss = 1.4023  \n",
      "\n",
      "Fold: 7  Epoch: 61  Training loss = 1.8631  Validation loss = 1.4006  \n",
      "\n",
      "Fold: 7  Epoch: 62  Training loss = 1.8628  Validation loss = 1.3991  \n",
      "\n",
      "Fold: 7  Epoch: 63  Training loss = 1.8626  Validation loss = 1.3982  \n",
      "\n",
      "Fold: 7  Epoch: 64  Training loss = 1.8624  Validation loss = 1.3976  \n",
      "\n",
      "Fold: 7  Epoch: 65  Training loss = 1.8622  Validation loss = 1.3967  \n",
      "\n",
      "Fold: 7  Epoch: 66  Training loss = 1.8618  Validation loss = 1.3952  \n",
      "\n",
      "Fold: 7  Epoch: 67  Training loss = 1.8615  Validation loss = 1.3941  \n",
      "\n",
      "Fold: 7  Epoch: 68  Training loss = 1.8614  Validation loss = 1.3938  \n",
      "\n",
      "Fold: 7  Epoch: 69  Training loss = 1.8612  Validation loss = 1.3929  \n",
      "\n",
      "Fold: 7  Epoch: 70  Training loss = 1.8610  Validation loss = 1.3923  \n",
      "\n",
      "Fold: 7  Epoch: 71  Training loss = 1.8609  Validation loss = 1.3919  \n",
      "\n",
      "Fold: 7  Epoch: 72  Training loss = 1.8607  Validation loss = 1.3907  \n",
      "\n",
      "Fold: 7  Epoch: 73  Training loss = 1.8603  Validation loss = 1.3891  \n",
      "\n",
      "Fold: 7  Epoch: 74  Training loss = 1.8601  Validation loss = 1.3882  \n",
      "\n",
      "Fold: 7  Epoch: 75  Training loss = 1.8597  Validation loss = 1.3863  \n",
      "\n",
      "Fold: 7  Epoch: 76  Training loss = 1.8593  Validation loss = 1.3837  \n",
      "\n",
      "Fold: 7  Epoch: 77  Training loss = 1.8590  Validation loss = 1.3822  \n",
      "\n",
      "Fold: 7  Epoch: 78  Training loss = 1.8587  Validation loss = 1.3815  \n",
      "\n",
      "Fold: 7  Epoch: 79  Training loss = 1.8586  Validation loss = 1.3811  \n",
      "\n",
      "Fold: 7  Epoch: 80  Training loss = 1.8583  Validation loss = 1.3803  \n",
      "\n",
      "Fold: 7  Epoch: 81  Training loss = 1.8581  Validation loss = 1.3787  \n",
      "\n",
      "Fold: 7  Epoch: 82  Training loss = 1.8578  Validation loss = 1.3777  \n",
      "\n",
      "Fold: 7  Epoch: 83  Training loss = 1.8577  Validation loss = 1.3774  \n",
      "\n",
      "Fold: 7  Epoch: 84  Training loss = 1.8574  Validation loss = 1.3762  \n",
      "\n",
      "Fold: 7  Epoch: 85  Training loss = 1.8574  Validation loss = 1.3759  \n",
      "\n",
      "Fold: 7  Epoch: 86  Training loss = 1.8572  Validation loss = 1.3749  \n",
      "\n",
      "Fold: 7  Epoch: 87  Training loss = 1.8569  Validation loss = 1.3735  \n",
      "\n",
      "Fold: 7  Epoch: 88  Training loss = 1.8566  Validation loss = 1.3715  \n",
      "\n",
      "Fold: 7  Epoch: 89  Training loss = 1.8564  Validation loss = 1.3704  \n",
      "\n",
      "Fold: 7  Epoch: 90  Training loss = 1.8562  Validation loss = 1.3693  \n",
      "\n",
      "Fold: 7  Epoch: 91  Training loss = 1.8557  Validation loss = 1.3669  \n",
      "\n",
      "Fold: 7  Epoch: 92  Training loss = 1.8556  Validation loss = 1.3662  \n",
      "\n",
      "Fold: 7  Epoch: 93  Training loss = 1.8555  Validation loss = 1.3658  \n",
      "\n",
      "Fold: 7  Epoch: 94  Training loss = 1.8552  Validation loss = 1.3648  \n",
      "\n",
      "Fold: 7  Epoch: 95  Training loss = 1.8550  Validation loss = 1.3639  \n",
      "\n",
      "Fold: 7  Epoch: 96  Training loss = 1.8548  Validation loss = 1.3625  \n",
      "\n",
      "Fold: 7  Epoch: 97  Training loss = 1.8547  Validation loss = 1.3628  \n",
      "\n",
      "Fold: 7  Epoch: 98  Training loss = 1.8545  Validation loss = 1.3618  \n",
      "\n",
      "Fold: 7  Epoch: 99  Training loss = 1.8542  Validation loss = 1.3604  \n",
      "\n",
      "Fold: 7  Epoch: 100  Training loss = 1.8540  Validation loss = 1.3590  \n",
      "\n",
      "Fold: 7  Epoch: 101  Training loss = 1.8537  Validation loss = 1.3582  \n",
      "\n",
      "Fold: 7  Epoch: 102  Training loss = 1.8534  Validation loss = 1.3569  \n",
      "\n",
      "Fold: 7  Epoch: 103  Training loss = 1.8532  Validation loss = 1.3557  \n",
      "\n",
      "Fold: 7  Epoch: 104  Training loss = 1.8530  Validation loss = 1.3547  \n",
      "\n",
      "Fold: 7  Epoch: 105  Training loss = 1.8527  Validation loss = 1.3534  \n",
      "\n",
      "Fold: 7  Epoch: 106  Training loss = 1.8524  Validation loss = 1.3520  \n",
      "\n",
      "Fold: 7  Epoch: 107  Training loss = 1.8521  Validation loss = 1.3509  \n",
      "\n",
      "Fold: 7  Epoch: 108  Training loss = 1.8519  Validation loss = 1.3499  \n",
      "\n",
      "Fold: 7  Epoch: 109  Training loss = 1.8516  Validation loss = 1.3485  \n",
      "\n",
      "Fold: 7  Epoch: 110  Training loss = 1.8515  Validation loss = 1.3482  \n",
      "\n",
      "Fold: 7  Epoch: 111  Training loss = 1.8513  Validation loss = 1.3474  \n",
      "\n",
      "Fold: 7  Epoch: 112  Training loss = 1.8510  Validation loss = 1.3459  \n",
      "\n",
      "Fold: 7  Epoch: 113  Training loss = 1.8509  Validation loss = 1.3456  \n",
      "\n",
      "Fold: 7  Epoch: 114  Training loss = 1.8506  Validation loss = 1.3439  \n",
      "\n",
      "Fold: 7  Epoch: 115  Training loss = 1.8503  Validation loss = 1.3426  \n",
      "\n",
      "Fold: 7  Epoch: 116  Training loss = 1.8501  Validation loss = 1.3415  \n",
      "\n",
      "Fold: 7  Epoch: 117  Training loss = 1.8499  Validation loss = 1.3409  \n",
      "\n",
      "Fold: 7  Epoch: 118  Training loss = 1.8497  Validation loss = 1.3401  \n",
      "\n",
      "Fold: 7  Epoch: 119  Training loss = 1.8495  Validation loss = 1.3393  \n",
      "\n",
      "Fold: 7  Epoch: 120  Training loss = 1.8494  Validation loss = 1.3391  \n",
      "\n",
      "Fold: 7  Epoch: 121  Training loss = 1.8491  Validation loss = 1.3372  \n",
      "\n",
      "Fold: 7  Epoch: 122  Training loss = 1.8489  Validation loss = 1.3361  \n",
      "\n",
      "Fold: 7  Epoch: 123  Training loss = 1.8487  Validation loss = 1.3353  \n",
      "\n",
      "Fold: 7  Epoch: 124  Training loss = 1.8486  Validation loss = 1.3354  \n",
      "\n",
      "Fold: 7  Epoch: 125  Training loss = 1.8485  Validation loss = 1.3347  \n",
      "\n",
      "Fold: 7  Epoch: 126  Training loss = 1.8484  Validation loss = 1.3343  \n",
      "\n",
      "Fold: 7  Epoch: 127  Training loss = 1.8484  Validation loss = 1.3346  \n",
      "\n",
      "Fold: 7  Epoch: 128  Training loss = 1.8482  Validation loss = 1.3338  \n",
      "\n",
      "Fold: 7  Epoch: 129  Training loss = 1.8480  Validation loss = 1.3325  \n",
      "\n",
      "Fold: 7  Epoch: 130  Training loss = 1.8478  Validation loss = 1.3318  \n",
      "\n",
      "Fold: 7  Epoch: 131  Training loss = 1.8474  Validation loss = 1.3305  \n",
      "\n",
      "Fold: 7  Epoch: 132  Training loss = 1.8472  Validation loss = 1.3292  \n",
      "\n",
      "Fold: 7  Epoch: 133  Training loss = 1.8470  Validation loss = 1.3284  \n",
      "\n",
      "Fold: 7  Epoch: 134  Training loss = 1.8468  Validation loss = 1.3279  \n",
      "\n",
      "Fold: 7  Epoch: 135  Training loss = 1.8465  Validation loss = 1.3265  \n",
      "\n",
      "Fold: 7  Epoch: 136  Training loss = 1.8464  Validation loss = 1.3261  \n",
      "\n",
      "Fold: 7  Epoch: 137  Training loss = 1.8461  Validation loss = 1.3248  \n",
      "\n",
      "Fold: 7  Epoch: 138  Training loss = 1.8459  Validation loss = 1.3231  \n",
      "\n",
      "Fold: 7  Epoch: 139  Training loss = 1.8457  Validation loss = 1.3222  \n",
      "\n",
      "Fold: 7  Epoch: 140  Training loss = 1.8454  Validation loss = 1.3212  \n",
      "\n",
      "Fold: 7  Epoch: 141  Training loss = 1.8452  Validation loss = 1.3205  \n",
      "\n",
      "Fold: 7  Epoch: 142  Training loss = 1.8449  Validation loss = 1.3190  \n",
      "\n",
      "Fold: 7  Epoch: 143  Training loss = 1.8447  Validation loss = 1.3182  \n",
      "\n",
      "Fold: 7  Epoch: 144  Training loss = 1.8444  Validation loss = 1.3171  \n",
      "\n",
      "Fold: 7  Epoch: 145  Training loss = 1.8442  Validation loss = 1.3161  \n",
      "\n",
      "Fold: 7  Epoch: 146  Training loss = 1.8440  Validation loss = 1.3151  \n",
      "\n",
      "Fold: 7  Epoch: 147  Training loss = 1.8436  Validation loss = 1.3132  \n",
      "\n",
      "Fold: 7  Epoch: 148  Training loss = 1.8433  Validation loss = 1.3117  \n",
      "\n",
      "Fold: 7  Epoch: 149  Training loss = 1.8431  Validation loss = 1.3104  \n",
      "\n",
      "Fold: 7  Epoch: 150  Training loss = 1.8428  Validation loss = 1.3084  \n",
      "\n",
      "Fold: 7  Epoch: 151  Training loss = 1.8425  Validation loss = 1.3067  \n",
      "\n",
      "Fold: 7  Epoch: 152  Training loss = 1.8423  Validation loss = 1.3057  \n",
      "\n",
      "Fold: 7  Epoch: 153  Training loss = 1.8420  Validation loss = 1.3039  \n",
      "\n",
      "Fold: 7  Epoch: 154  Training loss = 1.8418  Validation loss = 1.3030  \n",
      "\n",
      "Fold: 7  Epoch: 155  Training loss = 1.8417  Validation loss = 1.3026  \n",
      "\n",
      "Fold: 7  Epoch: 156  Training loss = 1.8415  Validation loss = 1.3013  \n",
      "\n",
      "Fold: 7  Epoch: 157  Training loss = 1.8414  Validation loss = 1.3007  \n",
      "\n",
      "Fold: 7  Epoch: 158  Training loss = 1.8412  Validation loss = 1.2997  \n",
      "\n",
      "Fold: 7  Epoch: 159  Training loss = 1.8410  Validation loss = 1.2987  \n",
      "\n",
      "Fold: 7  Epoch: 160  Training loss = 1.8408  Validation loss = 1.2984  \n",
      "\n",
      "Fold: 7  Epoch: 161  Training loss = 1.8407  Validation loss = 1.2978  \n",
      "\n",
      "Fold: 7  Epoch: 162  Training loss = 1.8405  Validation loss = 1.2969  \n",
      "\n",
      "Fold: 7  Epoch: 163  Training loss = 1.8403  Validation loss = 1.2962  \n",
      "\n",
      "Fold: 7  Epoch: 164  Training loss = 1.8401  Validation loss = 1.2953  \n",
      "\n",
      "Fold: 7  Epoch: 165  Training loss = 1.8400  Validation loss = 1.2951  \n",
      "\n",
      "Fold: 7  Epoch: 166  Training loss = 1.8399  Validation loss = 1.2939  \n",
      "\n",
      "Fold: 7  Epoch: 167  Training loss = 1.8396  Validation loss = 1.2926  \n",
      "\n",
      "Fold: 7  Epoch: 168  Training loss = 1.8393  Validation loss = 1.2916  \n",
      "\n",
      "Fold: 7  Epoch: 169  Training loss = 1.8392  Validation loss = 1.2912  \n",
      "\n",
      "Fold: 7  Epoch: 170  Training loss = 1.8390  Validation loss = 1.2900  \n",
      "\n",
      "Fold: 7  Epoch: 171  Training loss = 1.8388  Validation loss = 1.2892  \n",
      "\n",
      "Fold: 7  Epoch: 172  Training loss = 1.8386  Validation loss = 1.2880  \n",
      "\n",
      "Fold: 7  Epoch: 173  Training loss = 1.8385  Validation loss = 1.2873  \n",
      "\n",
      "Fold: 7  Epoch: 174  Training loss = 1.8383  Validation loss = 1.2869  \n",
      "\n",
      "Fold: 7  Epoch: 175  Training loss = 1.8382  Validation loss = 1.2868  \n",
      "\n",
      "Fold: 7  Epoch: 176  Training loss = 1.8381  Validation loss = 1.2860  \n",
      "\n",
      "Fold: 7  Epoch: 177  Training loss = 1.8378  Validation loss = 1.2842  \n",
      "\n",
      "Fold: 7  Epoch: 178  Training loss = 1.8374  Validation loss = 1.2823  \n",
      "\n",
      "Fold: 7  Epoch: 179  Training loss = 1.8371  Validation loss = 1.2807  \n",
      "\n",
      "Fold: 7  Epoch: 180  Training loss = 1.8368  Validation loss = 1.2795  \n",
      "\n",
      "Fold: 7  Epoch: 181  Training loss = 1.8367  Validation loss = 1.2794  \n",
      "\n",
      "Fold: 7  Epoch: 182  Training loss = 1.8364  Validation loss = 1.2780  \n",
      "\n",
      "Fold: 7  Epoch: 183  Training loss = 1.8363  Validation loss = 1.2776  \n",
      "\n",
      "Fold: 7  Epoch: 184  Training loss = 1.8360  Validation loss = 1.2762  \n",
      "\n",
      "Fold: 7  Epoch: 185  Training loss = 1.8358  Validation loss = 1.2750  \n",
      "\n",
      "Fold: 7  Epoch: 186  Training loss = 1.8355  Validation loss = 1.2739  \n",
      "\n",
      "Fold: 7  Epoch: 187  Training loss = 1.8352  Validation loss = 1.2721  \n",
      "\n",
      "Fold: 7  Epoch: 188  Training loss = 1.8350  Validation loss = 1.2717  \n",
      "\n",
      "Fold: 7  Epoch: 189  Training loss = 1.8349  Validation loss = 1.2717  \n",
      "\n",
      "Fold: 7  Epoch: 190  Training loss = 1.8346  Validation loss = 1.2699  \n",
      "\n",
      "Fold: 7  Epoch: 191  Training loss = 1.8344  Validation loss = 1.2691  \n",
      "\n",
      "Fold: 7  Epoch: 192  Training loss = 1.8341  Validation loss = 1.2675  \n",
      "\n",
      "Fold: 7  Epoch: 193  Training loss = 1.8339  Validation loss = 1.2668  \n",
      "\n",
      "Fold: 7  Epoch: 194  Training loss = 1.8337  Validation loss = 1.2658  \n",
      "\n",
      "Fold: 7  Epoch: 195  Training loss = 1.8334  Validation loss = 1.2645  \n",
      "\n",
      "Fold: 7  Epoch: 196  Training loss = 1.8332  Validation loss = 1.2635  \n",
      "\n",
      "Fold: 7  Epoch: 197  Training loss = 1.8330  Validation loss = 1.2628  \n",
      "\n",
      "Fold: 7  Epoch: 198  Training loss = 1.8327  Validation loss = 1.2609  \n",
      "\n",
      "Fold: 7  Epoch: 199  Training loss = 1.8325  Validation loss = 1.2597  \n",
      "\n",
      "Fold: 7  Epoch: 200  Training loss = 1.8322  Validation loss = 1.2581  \n",
      "\n",
      "Fold: 7  Epoch: 201  Training loss = 1.8320  Validation loss = 1.2572  \n",
      "\n",
      "Fold: 7  Epoch: 202  Training loss = 1.8317  Validation loss = 1.2561  \n",
      "\n",
      "Fold: 7  Epoch: 203  Training loss = 1.8316  Validation loss = 1.2556  \n",
      "\n",
      "Fold: 7  Epoch: 204  Training loss = 1.8312  Validation loss = 1.2542  \n",
      "\n",
      "Fold: 7  Epoch: 205  Training loss = 1.8312  Validation loss = 1.2541  \n",
      "\n",
      "Fold: 7  Epoch: 206  Training loss = 1.8309  Validation loss = 1.2528  \n",
      "\n",
      "Fold: 7  Epoch: 207  Training loss = 1.8307  Validation loss = 1.2518  \n",
      "\n",
      "Fold: 7  Epoch: 208  Training loss = 1.8306  Validation loss = 1.2518  \n",
      "\n",
      "Fold: 7  Epoch: 209  Training loss = 1.8305  Validation loss = 1.2507  \n",
      "\n",
      "Fold: 7  Epoch: 210  Training loss = 1.8304  Validation loss = 1.2502  \n",
      "\n",
      "Fold: 7  Epoch: 211  Training loss = 1.8301  Validation loss = 1.2490  \n",
      "\n",
      "Fold: 7  Epoch: 212  Training loss = 1.8299  Validation loss = 1.2479  \n",
      "\n",
      "Fold: 7  Epoch: 213  Training loss = 1.8299  Validation loss = 1.2480  \n",
      "\n",
      "Fold: 7  Epoch: 214  Training loss = 1.8297  Validation loss = 1.2472  \n",
      "\n",
      "Fold: 7  Epoch: 215  Training loss = 1.8294  Validation loss = 1.2457  \n",
      "\n",
      "Fold: 7  Epoch: 216  Training loss = 1.8292  Validation loss = 1.2446  \n",
      "\n",
      "Fold: 7  Epoch: 217  Training loss = 1.8289  Validation loss = 1.2431  \n",
      "\n",
      "Fold: 7  Epoch: 218  Training loss = 1.8287  Validation loss = 1.2430  \n",
      "\n",
      "Fold: 7  Epoch: 219  Training loss = 1.8286  Validation loss = 1.2427  \n",
      "\n",
      "Fold: 7  Epoch: 220  Training loss = 1.8285  Validation loss = 1.2420  \n",
      "\n",
      "Fold: 7  Epoch: 221  Training loss = 1.8283  Validation loss = 1.2412  \n",
      "\n",
      "Fold: 7  Epoch: 222  Training loss = 1.8281  Validation loss = 1.2401  \n",
      "\n",
      "Fold: 7  Epoch: 223  Training loss = 1.8280  Validation loss = 1.2400  \n",
      "\n",
      "Fold: 7  Epoch: 224  Training loss = 1.8279  Validation loss = 1.2397  \n",
      "\n",
      "Fold: 7  Epoch: 225  Training loss = 1.8278  Validation loss = 1.2391  \n",
      "\n",
      "Fold: 7  Epoch: 226  Training loss = 1.8275  Validation loss = 1.2375  \n",
      "\n",
      "Fold: 7  Epoch: 227  Training loss = 1.8274  Validation loss = 1.2374  \n",
      "\n",
      "Fold: 7  Epoch: 228  Training loss = 1.8272  Validation loss = 1.2368  \n",
      "\n",
      "Fold: 7  Epoch: 229  Training loss = 1.8270  Validation loss = 1.2357  \n",
      "\n",
      "Fold: 7  Epoch: 230  Training loss = 1.8268  Validation loss = 1.2349  \n",
      "\n",
      "Fold: 7  Epoch: 231  Training loss = 1.8267  Validation loss = 1.2342  \n",
      "\n",
      "Fold: 7  Epoch: 232  Training loss = 1.8266  Validation loss = 1.2334  \n",
      "\n",
      "Fold: 7  Epoch: 233  Training loss = 1.8264  Validation loss = 1.2325  \n",
      "\n",
      "Fold: 7  Epoch: 234  Training loss = 1.8264  Validation loss = 1.2326  \n",
      "\n",
      "Fold: 7  Epoch: 235  Training loss = 1.8262  Validation loss = 1.2324  \n",
      "\n",
      "Fold: 7  Epoch: 236  Training loss = 1.8261  Validation loss = 1.2317  \n",
      "\n",
      "Fold: 7  Epoch: 237  Training loss = 1.8259  Validation loss = 1.2310  \n",
      "\n",
      "Fold: 7  Epoch: 238  Training loss = 1.8256  Validation loss = 1.2293  \n",
      "\n",
      "Fold: 7  Epoch: 239  Training loss = 1.8254  Validation loss = 1.2284  \n",
      "\n",
      "Fold: 7  Epoch: 240  Training loss = 1.8252  Validation loss = 1.2280  \n",
      "\n",
      "Fold: 7  Epoch: 241  Training loss = 1.8249  Validation loss = 1.2265  \n",
      "\n",
      "Fold: 7  Epoch: 242  Training loss = 1.8247  Validation loss = 1.2256  \n",
      "\n",
      "Fold: 7  Epoch: 243  Training loss = 1.8245  Validation loss = 1.2247  \n",
      "\n",
      "Fold: 7  Epoch: 244  Training loss = 1.8244  Validation loss = 1.2245  \n",
      "\n",
      "Fold: 7  Epoch: 245  Training loss = 1.8240  Validation loss = 1.2226  \n",
      "\n",
      "Fold: 7  Epoch: 246  Training loss = 1.8239  Validation loss = 1.2217  \n",
      "\n",
      "Fold: 7  Epoch: 247  Training loss = 1.8239  Validation loss = 1.2220  \n",
      "\n",
      "Fold: 7  Epoch: 248  Training loss = 1.8238  Validation loss = 1.2213  \n",
      "\n",
      "Fold: 7  Epoch: 249  Training loss = 1.8236  Validation loss = 1.2208  \n",
      "\n",
      "Fold: 7  Epoch: 250  Training loss = 1.8234  Validation loss = 1.2195  \n",
      "\n",
      "Fold: 7  Epoch: 251  Training loss = 1.8233  Validation loss = 1.2190  \n",
      "\n",
      "Fold: 7  Epoch: 252  Training loss = 1.8231  Validation loss = 1.2181  \n",
      "\n",
      "Fold: 7  Epoch: 253  Training loss = 1.8228  Validation loss = 1.2167  \n",
      "\n",
      "Fold: 7  Epoch: 254  Training loss = 1.8226  Validation loss = 1.2155  \n",
      "\n",
      "Fold: 7  Epoch: 255  Training loss = 1.8223  Validation loss = 1.2145  \n",
      "\n",
      "Fold: 7  Epoch: 256  Training loss = 1.8222  Validation loss = 1.2140  \n",
      "\n",
      "Fold: 7  Epoch: 257  Training loss = 1.8219  Validation loss = 1.2127  \n",
      "\n",
      "Fold: 7  Epoch: 258  Training loss = 1.8217  Validation loss = 1.2120  \n",
      "\n",
      "Fold: 7  Epoch: 259  Training loss = 1.8215  Validation loss = 1.2108  \n",
      "\n",
      "Fold: 7  Epoch: 260  Training loss = 1.8213  Validation loss = 1.2100  \n",
      "\n",
      "Fold: 7  Epoch: 261  Training loss = 1.8211  Validation loss = 1.2086  \n",
      "\n",
      "Fold: 7  Epoch: 262  Training loss = 1.8208  Validation loss = 1.2074  \n",
      "\n",
      "Fold: 7  Epoch: 263  Training loss = 1.8206  Validation loss = 1.2063  \n",
      "\n",
      "Fold: 7  Epoch: 264  Training loss = 1.8205  Validation loss = 1.2058  \n",
      "\n",
      "Fold: 7  Epoch: 265  Training loss = 1.8204  Validation loss = 1.2056  \n",
      "\n",
      "Fold: 7  Epoch: 266  Training loss = 1.8201  Validation loss = 1.2040  \n",
      "\n",
      "Fold: 7  Epoch: 267  Training loss = 1.8200  Validation loss = 1.2034  \n",
      "\n",
      "Fold: 7  Epoch: 268  Training loss = 1.8198  Validation loss = 1.2027  \n",
      "\n",
      "Fold: 7  Epoch: 269  Training loss = 1.8197  Validation loss = 1.2022  \n",
      "\n",
      "Fold: 7  Epoch: 270  Training loss = 1.8195  Validation loss = 1.2016  \n",
      "\n",
      "Fold: 7  Epoch: 271  Training loss = 1.8194  Validation loss = 1.2009  \n",
      "\n",
      "Fold: 7  Epoch: 272  Training loss = 1.8191  Validation loss = 1.1995  \n",
      "\n",
      "Fold: 7  Epoch: 273  Training loss = 1.8189  Validation loss = 1.1987  \n",
      "\n",
      "Fold: 7  Epoch: 274  Training loss = 1.8188  Validation loss = 1.1980  \n",
      "\n",
      "Fold: 7  Epoch: 275  Training loss = 1.8187  Validation loss = 1.1968  \n",
      "\n",
      "Fold: 7  Epoch: 276  Training loss = 1.8186  Validation loss = 1.1969  \n",
      "\n",
      "Fold: 7  Epoch: 277  Training loss = 1.8184  Validation loss = 1.1960  \n",
      "\n",
      "Fold: 7  Epoch: 278  Training loss = 1.8183  Validation loss = 1.1956  \n",
      "\n",
      "Fold: 7  Epoch: 279  Training loss = 1.8181  Validation loss = 1.1950  \n",
      "\n",
      "Fold: 7  Epoch: 280  Training loss = 1.8180  Validation loss = 1.1947  \n",
      "\n",
      "Fold: 7  Epoch: 281  Training loss = 1.8179  Validation loss = 1.1946  \n",
      "\n",
      "Fold: 7  Epoch: 282  Training loss = 1.8177  Validation loss = 1.1937  \n",
      "\n",
      "Fold: 7  Epoch: 283  Training loss = 1.8176  Validation loss = 1.1931  \n",
      "\n",
      "Fold: 7  Epoch: 284  Training loss = 1.8174  Validation loss = 1.1918  \n",
      "\n",
      "Fold: 7  Epoch: 285  Training loss = 1.8172  Validation loss = 1.1909  \n",
      "\n",
      "Fold: 7  Epoch: 286  Training loss = 1.8171  Validation loss = 1.1905  \n",
      "\n",
      "Fold: 7  Epoch: 287  Training loss = 1.8169  Validation loss = 1.1898  \n",
      "\n",
      "Fold: 7  Epoch: 288  Training loss = 1.8167  Validation loss = 1.1885  \n",
      "\n",
      "Fold: 7  Epoch: 289  Training loss = 1.8166  Validation loss = 1.1878  \n",
      "\n",
      "Fold: 7  Epoch: 290  Training loss = 1.8165  Validation loss = 1.1876  \n",
      "\n",
      "Fold: 7  Epoch: 291  Training loss = 1.8163  Validation loss = 1.1873  \n",
      "\n",
      "Fold: 7  Epoch: 292  Training loss = 1.8161  Validation loss = 1.1860  \n",
      "\n",
      "Fold: 7  Epoch: 293  Training loss = 1.8159  Validation loss = 1.1848  \n",
      "\n",
      "Fold: 7  Epoch: 294  Training loss = 1.8156  Validation loss = 1.1831  \n",
      "\n",
      "Fold: 7  Epoch: 295  Training loss = 1.8154  Validation loss = 1.1820  \n",
      "\n",
      "Fold: 7  Epoch: 296  Training loss = 1.8153  Validation loss = 1.1817  \n",
      "\n",
      "Fold: 7  Epoch: 297  Training loss = 1.8152  Validation loss = 1.1812  \n",
      "\n",
      "Fold: 7  Epoch: 298  Training loss = 1.8149  Validation loss = 1.1800  \n",
      "\n",
      "Fold: 7  Epoch: 299  Training loss = 1.8148  Validation loss = 1.1794  \n",
      "\n",
      "Fold: 7  Epoch: 300  Training loss = 1.8147  Validation loss = 1.1790  \n",
      "\n",
      "Fold: 7  Epoch: 301  Training loss = 1.8146  Validation loss = 1.1786  \n",
      "\n",
      "Fold: 7  Epoch: 302  Training loss = 1.8144  Validation loss = 1.1783  \n",
      "\n",
      "Fold: 7  Epoch: 303  Training loss = 1.8141  Validation loss = 1.1765  \n",
      "\n",
      "Fold: 7  Epoch: 304  Training loss = 1.8138  Validation loss = 1.1745  \n",
      "\n",
      "Fold: 7  Epoch: 305  Training loss = 1.8135  Validation loss = 1.1728  \n",
      "\n",
      "Fold: 7  Epoch: 306  Training loss = 1.8133  Validation loss = 1.1722  \n",
      "\n",
      "Fold: 7  Epoch: 307  Training loss = 1.8131  Validation loss = 1.1707  \n",
      "\n",
      "Fold: 7  Epoch: 308  Training loss = 1.8129  Validation loss = 1.1700  \n",
      "\n",
      "Fold: 7  Epoch: 309  Training loss = 1.8127  Validation loss = 1.1691  \n",
      "\n",
      "Fold: 7  Epoch: 310  Training loss = 1.8125  Validation loss = 1.1684  \n",
      "\n",
      "Fold: 7  Epoch: 311  Training loss = 1.8124  Validation loss = 1.1681  \n",
      "\n",
      "Fold: 7  Epoch: 312  Training loss = 1.8121  Validation loss = 1.1664  \n",
      "\n",
      "Fold: 7  Epoch: 313  Training loss = 1.8120  Validation loss = 1.1659  \n",
      "\n",
      "Fold: 7  Epoch: 314  Training loss = 1.8118  Validation loss = 1.1649  \n",
      "\n",
      "Fold: 7  Epoch: 315  Training loss = 1.8115  Validation loss = 1.1640  \n",
      "\n",
      "Fold: 7  Epoch: 316  Training loss = 1.8114  Validation loss = 1.1635  \n",
      "\n",
      "Fold: 7  Epoch: 317  Training loss = 1.8112  Validation loss = 1.1627  \n",
      "\n",
      "Fold: 7  Epoch: 318  Training loss = 1.8111  Validation loss = 1.1620  \n",
      "\n",
      "Fold: 7  Epoch: 319  Training loss = 1.8110  Validation loss = 1.1619  \n",
      "\n",
      "Fold: 7  Epoch: 320  Training loss = 1.8108  Validation loss = 1.1607  \n",
      "\n",
      "Fold: 7  Epoch: 321  Training loss = 1.8106  Validation loss = 1.1595  \n",
      "\n",
      "Fold: 7  Epoch: 322  Training loss = 1.8104  Validation loss = 1.1582  \n",
      "\n",
      "Fold: 7  Epoch: 323  Training loss = 1.8102  Validation loss = 1.1570  \n",
      "\n",
      "Fold: 7  Epoch: 324  Training loss = 1.8101  Validation loss = 1.1568  \n",
      "\n",
      "Fold: 7  Epoch: 325  Training loss = 1.8099  Validation loss = 1.1563  \n",
      "\n",
      "Fold: 7  Epoch: 326  Training loss = 1.8098  Validation loss = 1.1550  \n",
      "\n",
      "Fold: 7  Epoch: 327  Training loss = 1.8096  Validation loss = 1.1541  \n",
      "\n",
      "Fold: 7  Epoch: 328  Training loss = 1.8094  Validation loss = 1.1529  \n",
      "\n",
      "Fold: 7  Epoch: 329  Training loss = 1.8092  Validation loss = 1.1520  \n",
      "\n",
      "Fold: 7  Epoch: 330  Training loss = 1.8089  Validation loss = 1.1508  \n",
      "\n",
      "Fold: 7  Epoch: 331  Training loss = 1.8088  Validation loss = 1.1505  \n",
      "\n",
      "Fold: 7  Epoch: 332  Training loss = 1.8087  Validation loss = 1.1500  \n",
      "\n",
      "Fold: 7  Epoch: 333  Training loss = 1.8087  Validation loss = 1.1500  \n",
      "\n",
      "Fold: 7  Epoch: 334  Training loss = 1.8085  Validation loss = 1.1491  \n",
      "\n",
      "Fold: 7  Epoch: 335  Training loss = 1.8083  Validation loss = 1.1482  \n",
      "\n",
      "Fold: 7  Epoch: 336  Training loss = 1.8082  Validation loss = 1.1469  \n",
      "\n",
      "Fold: 7  Epoch: 337  Training loss = 1.8080  Validation loss = 1.1467  \n",
      "\n",
      "Fold: 7  Epoch: 338  Training loss = 1.8078  Validation loss = 1.1455  \n",
      "\n",
      "Fold: 7  Epoch: 339  Training loss = 1.8075  Validation loss = 1.1441  \n",
      "\n",
      "Fold: 7  Epoch: 340  Training loss = 1.8074  Validation loss = 1.1436  \n",
      "\n",
      "Fold: 7  Epoch: 341  Training loss = 1.8073  Validation loss = 1.1436  \n",
      "\n",
      "Fold: 7  Epoch: 342  Training loss = 1.8069  Validation loss = 1.1413  \n",
      "\n",
      "Fold: 7  Epoch: 343  Training loss = 1.8068  Validation loss = 1.1406  \n",
      "\n",
      "Fold: 7  Epoch: 344  Training loss = 1.8065  Validation loss = 1.1393  \n",
      "\n",
      "Fold: 7  Epoch: 345  Training loss = 1.8063  Validation loss = 1.1382  \n",
      "\n",
      "Fold: 7  Epoch: 346  Training loss = 1.8062  Validation loss = 1.1380  \n",
      "\n",
      "Fold: 7  Epoch: 347  Training loss = 1.8062  Validation loss = 1.1377  \n",
      "\n",
      "Fold: 7  Epoch: 348  Training loss = 1.8058  Validation loss = 1.1356  \n",
      "\n",
      "Fold: 7  Epoch: 349  Training loss = 1.8057  Validation loss = 1.1353  \n",
      "\n",
      "Fold: 7  Epoch: 350  Training loss = 1.8056  Validation loss = 1.1346  \n",
      "\n",
      "Fold: 7  Epoch: 351  Training loss = 1.8055  Validation loss = 1.1341  \n",
      "\n",
      "Fold: 7  Epoch: 352  Training loss = 1.8053  Validation loss = 1.1337  \n",
      "\n",
      "Fold: 7  Epoch: 353  Training loss = 1.8052  Validation loss = 1.1330  \n",
      "\n",
      "Fold: 7  Epoch: 354  Training loss = 1.8050  Validation loss = 1.1320  \n",
      "\n",
      "Fold: 7  Epoch: 355  Training loss = 1.8048  Validation loss = 1.1311  \n",
      "\n",
      "Fold: 7  Epoch: 356  Training loss = 1.8048  Validation loss = 1.1309  \n",
      "\n",
      "Fold: 7  Epoch: 357  Training loss = 1.8046  Validation loss = 1.1303  \n",
      "\n",
      "Fold: 7  Epoch: 358  Training loss = 1.8045  Validation loss = 1.1299  \n",
      "\n",
      "Fold: 7  Epoch: 359  Training loss = 1.8043  Validation loss = 1.1289  \n",
      "\n",
      "Fold: 7  Epoch: 360  Training loss = 1.8040  Validation loss = 1.1276  \n",
      "\n",
      "Fold: 7  Epoch: 361  Training loss = 1.8038  Validation loss = 1.1267  \n",
      "\n",
      "Fold: 7  Epoch: 362  Training loss = 1.8037  Validation loss = 1.1263  \n",
      "\n",
      "Fold: 7  Epoch: 363  Training loss = 1.8036  Validation loss = 1.1256  \n",
      "\n",
      "Fold: 7  Epoch: 364  Training loss = 1.8034  Validation loss = 1.1251  \n",
      "\n",
      "Fold: 7  Epoch: 365  Training loss = 1.8033  Validation loss = 1.1249  \n",
      "\n",
      "Fold: 7  Epoch: 366  Training loss = 1.8032  Validation loss = 1.1238  \n",
      "\n",
      "Fold: 7  Epoch: 367  Training loss = 1.8030  Validation loss = 1.1233  \n",
      "\n",
      "Fold: 7  Epoch: 368  Training loss = 1.8028  Validation loss = 1.1223  \n",
      "\n",
      "Fold: 7  Epoch: 369  Training loss = 1.8027  Validation loss = 1.1221  \n",
      "\n",
      "Fold: 7  Epoch: 370  Training loss = 1.8026  Validation loss = 1.1214  \n",
      "\n",
      "Fold: 7  Epoch: 371  Training loss = 1.8025  Validation loss = 1.1210  \n",
      "\n",
      "Fold: 7  Epoch: 372  Training loss = 1.8023  Validation loss = 1.1204  \n",
      "\n",
      "Fold: 7  Epoch: 373  Training loss = 1.8021  Validation loss = 1.1196  \n",
      "\n",
      "Fold: 7  Epoch: 374  Training loss = 1.8018  Validation loss = 1.1178  \n",
      "\n",
      "Fold: 7  Epoch: 375  Training loss = 1.8017  Validation loss = 1.1173  \n",
      "\n",
      "Fold: 7  Epoch: 376  Training loss = 1.8016  Validation loss = 1.1164  \n",
      "\n",
      "Fold: 7  Epoch: 377  Training loss = 1.8014  Validation loss = 1.1153  \n",
      "\n",
      "Fold: 7  Epoch: 378  Training loss = 1.8013  Validation loss = 1.1146  \n",
      "\n",
      "Fold: 7  Epoch: 379  Training loss = 1.8011  Validation loss = 1.1142  \n",
      "\n",
      "Fold: 7  Epoch: 380  Training loss = 1.8010  Validation loss = 1.1135  \n",
      "\n",
      "Fold: 7  Epoch: 381  Training loss = 1.8008  Validation loss = 1.1123  \n",
      "\n",
      "Fold: 7  Epoch: 382  Training loss = 1.8006  Validation loss = 1.1112  \n",
      "\n",
      "Fold: 7  Epoch: 383  Training loss = 1.8005  Validation loss = 1.1107  \n",
      "\n",
      "Fold: 7  Epoch: 384  Training loss = 1.8004  Validation loss = 1.1099  \n",
      "\n",
      "Fold: 7  Epoch: 385  Training loss = 1.8003  Validation loss = 1.1098  \n",
      "\n",
      "Fold: 7  Epoch: 386  Training loss = 1.8001  Validation loss = 1.1092  \n",
      "\n",
      "Fold: 7  Epoch: 387  Training loss = 1.8000  Validation loss = 1.1086  \n",
      "\n",
      "Fold: 7  Epoch: 388  Training loss = 1.7999  Validation loss = 1.1082  \n",
      "\n",
      "Fold: 7  Epoch: 389  Training loss = 1.7997  Validation loss = 1.1071  \n",
      "\n",
      "Fold: 7  Epoch: 390  Training loss = 1.7995  Validation loss = 1.1061  \n",
      "\n",
      "Fold: 7  Epoch: 391  Training loss = 1.7993  Validation loss = 1.1053  \n",
      "\n",
      "Fold: 7  Epoch: 392  Training loss = 1.7991  Validation loss = 1.1043  \n",
      "\n",
      "Fold: 7  Epoch: 393  Training loss = 1.7990  Validation loss = 1.1043  \n",
      "\n",
      "Fold: 7  Epoch: 394  Training loss = 1.7989  Validation loss = 1.1036  \n",
      "\n",
      "Fold: 7  Epoch: 395  Training loss = 1.7987  Validation loss = 1.1027  \n",
      "\n",
      "Fold: 7  Epoch: 396  Training loss = 1.7986  Validation loss = 1.1019  \n",
      "\n",
      "Fold: 7  Epoch: 397  Training loss = 1.7984  Validation loss = 1.1010  \n",
      "\n",
      "Fold: 7  Epoch: 398  Training loss = 1.7981  Validation loss = 1.1001  \n",
      "\n",
      "Fold: 7  Epoch: 399  Training loss = 1.7980  Validation loss = 1.0997  \n",
      "\n",
      "Fold: 7  Epoch: 400  Training loss = 1.7979  Validation loss = 1.0993  \n",
      "\n",
      "Fold: 7  Epoch: 401  Training loss = 1.7977  Validation loss = 1.0985  \n",
      "\n",
      "Fold: 7  Epoch: 402  Training loss = 1.7975  Validation loss = 1.0980  \n",
      "\n",
      "Fold: 7  Epoch: 403  Training loss = 1.7974  Validation loss = 1.0973  \n",
      "\n",
      "Fold: 7  Epoch: 404  Training loss = 1.7973  Validation loss = 1.0971  \n",
      "\n",
      "Fold: 7  Epoch: 405  Training loss = 1.7971  Validation loss = 1.0959  \n",
      "\n",
      "Fold: 7  Epoch: 406  Training loss = 1.7970  Validation loss = 1.0956  \n",
      "\n",
      "Fold: 7  Epoch: 407  Training loss = 1.7969  Validation loss = 1.0952  \n",
      "\n",
      "Fold: 7  Epoch: 408  Training loss = 1.7967  Validation loss = 1.0942  \n",
      "\n",
      "Fold: 7  Epoch: 409  Training loss = 1.7966  Validation loss = 1.0944  \n",
      "\n",
      "Fold: 7  Epoch: 410  Training loss = 1.7964  Validation loss = 1.0934  \n",
      "\n",
      "Fold: 7  Epoch: 411  Training loss = 1.7963  Validation loss = 1.0932  \n",
      "\n",
      "Fold: 7  Epoch: 412  Training loss = 1.7961  Validation loss = 1.0921  \n",
      "\n",
      "Fold: 7  Epoch: 413  Training loss = 1.7960  Validation loss = 1.0917  \n",
      "\n",
      "Fold: 7  Epoch: 414  Training loss = 1.7958  Validation loss = 1.0907  \n",
      "\n",
      "Fold: 7  Epoch: 415  Training loss = 1.7956  Validation loss = 1.0896  \n",
      "\n",
      "Fold: 7  Epoch: 416  Training loss = 1.7956  Validation loss = 1.0895  \n",
      "\n",
      "Fold: 7  Epoch: 417  Training loss = 1.7953  Validation loss = 1.0879  \n",
      "\n",
      "Fold: 7  Epoch: 418  Training loss = 1.7952  Validation loss = 1.0872  \n",
      "\n",
      "Fold: 7  Epoch: 419  Training loss = 1.7951  Validation loss = 1.0865  \n",
      "\n",
      "Fold: 7  Epoch: 420  Training loss = 1.7948  Validation loss = 1.0848  \n",
      "\n",
      "Fold: 7  Epoch: 421  Training loss = 1.7948  Validation loss = 1.0848  \n",
      "\n",
      "Fold: 7  Epoch: 422  Training loss = 1.7946  Validation loss = 1.0842  \n",
      "\n",
      "Fold: 7  Epoch: 423  Training loss = 1.7945  Validation loss = 1.0837  \n",
      "\n",
      "Fold: 7  Epoch: 424  Training loss = 1.7944  Validation loss = 1.0832  \n",
      "\n",
      "Fold: 7  Epoch: 425  Training loss = 1.7943  Validation loss = 1.0828  \n",
      "\n",
      "Fold: 7  Epoch: 426  Training loss = 1.7941  Validation loss = 1.0819  \n",
      "\n",
      "Fold: 7  Epoch: 427  Training loss = 1.7941  Validation loss = 1.0825  \n",
      "\n",
      "Fold: 7  Epoch: 428  Training loss = 1.7940  Validation loss = 1.0818  \n",
      "\n",
      "Fold: 7  Epoch: 429  Training loss = 1.7938  Validation loss = 1.0810  \n",
      "\n",
      "Fold: 7  Epoch: 430  Training loss = 1.7937  Validation loss = 1.0808  \n",
      "\n",
      "Fold: 7  Epoch: 431  Training loss = 1.7936  Validation loss = 1.0808  \n",
      "\n",
      "Fold: 7  Epoch: 432  Training loss = 1.7936  Validation loss = 1.0810  \n",
      "\n",
      "Fold: 7  Epoch: 433  Training loss = 1.7934  Validation loss = 1.0800  \n",
      "\n",
      "Fold: 7  Epoch: 434  Training loss = 1.7933  Validation loss = 1.0791  \n",
      "\n",
      "Fold: 7  Epoch: 435  Training loss = 1.7930  Validation loss = 1.0779  \n",
      "\n",
      "Fold: 7  Epoch: 436  Training loss = 1.7929  Validation loss = 1.0773  \n",
      "\n",
      "Fold: 7  Epoch: 437  Training loss = 1.7927  Validation loss = 1.0765  \n",
      "\n",
      "Fold: 7  Epoch: 438  Training loss = 1.7926  Validation loss = 1.0759  \n",
      "\n",
      "Fold: 7  Epoch: 439  Training loss = 1.7925  Validation loss = 1.0753  \n",
      "\n",
      "Fold: 7  Epoch: 440  Training loss = 1.7922  Validation loss = 1.0736  \n",
      "\n",
      "Fold: 7  Epoch: 441  Training loss = 1.7921  Validation loss = 1.0733  \n",
      "\n",
      "Fold: 7  Epoch: 442  Training loss = 1.7920  Validation loss = 1.0726  \n",
      "\n",
      "Fold: 7  Epoch: 443  Training loss = 1.7918  Validation loss = 1.0716  \n",
      "\n",
      "Fold: 7  Epoch: 444  Training loss = 1.7916  Validation loss = 1.0709  \n",
      "\n",
      "Fold: 7  Epoch: 445  Training loss = 1.7915  Validation loss = 1.0705  \n",
      "\n",
      "Fold: 7  Epoch: 446  Training loss = 1.7913  Validation loss = 1.0694  \n",
      "\n",
      "Fold: 7  Epoch: 447  Training loss = 1.7912  Validation loss = 1.0692  \n",
      "\n",
      "Fold: 7  Epoch: 448  Training loss = 1.7911  Validation loss = 1.0687  \n",
      "\n",
      "Fold: 7  Epoch: 449  Training loss = 1.7908  Validation loss = 1.0672  \n",
      "\n",
      "Fold: 7  Epoch: 450  Training loss = 1.7908  Validation loss = 1.0673  \n",
      "\n",
      "Fold: 7  Epoch: 451  Training loss = 1.7907  Validation loss = 1.0668  \n",
      "\n",
      "Fold: 7  Epoch: 452  Training loss = 1.7906  Validation loss = 1.0662  \n",
      "\n",
      "Fold: 7  Epoch: 453  Training loss = 1.7904  Validation loss = 1.0658  \n",
      "\n",
      "Fold: 7  Epoch: 454  Training loss = 1.7903  Validation loss = 1.0652  \n",
      "\n",
      "Fold: 7  Epoch: 455  Training loss = 1.7902  Validation loss = 1.0651  \n",
      "\n",
      "Fold: 7  Epoch: 456  Training loss = 1.7900  Validation loss = 1.0640  \n",
      "\n",
      "Fold: 7  Epoch: 457  Training loss = 1.7899  Validation loss = 1.0639  \n",
      "\n",
      "Fold: 7  Epoch: 458  Training loss = 1.7898  Validation loss = 1.0633  \n",
      "\n",
      "Fold: 7  Epoch: 459  Training loss = 1.7896  Validation loss = 1.0623  \n",
      "\n",
      "Fold: 7  Epoch: 460  Training loss = 1.7894  Validation loss = 1.0611  \n",
      "\n",
      "Fold: 7  Epoch: 461  Training loss = 1.7893  Validation loss = 1.0611  \n",
      "\n",
      "Fold: 7  Epoch: 462  Training loss = 1.7891  Validation loss = 1.0603  \n",
      "\n",
      "Fold: 7  Epoch: 463  Training loss = 1.7890  Validation loss = 1.0597  \n",
      "\n",
      "Fold: 7  Epoch: 464  Training loss = 1.7889  Validation loss = 1.0594  \n",
      "\n",
      "Fold: 7  Epoch: 465  Training loss = 1.7888  Validation loss = 1.0590  \n",
      "\n",
      "Fold: 7  Epoch: 466  Training loss = 1.7886  Validation loss = 1.0582  \n",
      "\n",
      "Fold: 7  Epoch: 467  Training loss = 1.7885  Validation loss = 1.0579  \n",
      "\n",
      "Fold: 7  Epoch: 468  Training loss = 1.7884  Validation loss = 1.0575  \n",
      "\n",
      "Fold: 7  Epoch: 469  Training loss = 1.7882  Validation loss = 1.0573  \n",
      "\n",
      "Fold: 7  Epoch: 470  Training loss = 1.7880  Validation loss = 1.0559  \n",
      "\n",
      "Fold: 7  Epoch: 471  Training loss = 1.7878  Validation loss = 1.0550  \n",
      "\n",
      "Fold: 7  Epoch: 472  Training loss = 1.7877  Validation loss = 1.0543  \n",
      "\n",
      "Fold: 7  Epoch: 473  Training loss = 1.7876  Validation loss = 1.0538  \n",
      "\n",
      "Fold: 7  Epoch: 474  Training loss = 1.7873  Validation loss = 1.0521  \n",
      "\n",
      "Fold: 7  Epoch: 475  Training loss = 1.7873  Validation loss = 1.0522  \n",
      "\n",
      "Fold: 7  Epoch: 476  Training loss = 1.7872  Validation loss = 1.0520  \n",
      "\n",
      "Fold: 7  Epoch: 477  Training loss = 1.7870  Validation loss = 1.0513  \n",
      "\n",
      "Fold: 7  Epoch: 478  Training loss = 1.7868  Validation loss = 1.0505  \n",
      "\n",
      "Fold: 7  Epoch: 479  Training loss = 1.7867  Validation loss = 1.0490  \n",
      "\n",
      "Fold: 7  Epoch: 480  Training loss = 1.7865  Validation loss = 1.0482  \n",
      "\n",
      "Fold: 7  Epoch: 481  Training loss = 1.7863  Validation loss = 1.0469  \n",
      "\n",
      "Fold: 7  Epoch: 482  Training loss = 1.7862  Validation loss = 1.0465  \n",
      "\n",
      "Fold: 7  Epoch: 483  Training loss = 1.7860  Validation loss = 1.0458  \n",
      "\n",
      "Fold: 7  Epoch: 484  Training loss = 1.7860  Validation loss = 1.0457  \n",
      "\n",
      "Fold: 7  Epoch: 485  Training loss = 1.7859  Validation loss = 1.0461  \n",
      "\n",
      "Fold: 7  Epoch: 486  Training loss = 1.7858  Validation loss = 1.0454  \n",
      "\n",
      "Fold: 7  Epoch: 487  Training loss = 1.7855  Validation loss = 1.0439  \n",
      "\n",
      "Fold: 7  Epoch: 488  Training loss = 1.7854  Validation loss = 1.0432  \n",
      "\n",
      "Fold: 7  Epoch: 489  Training loss = 1.7854  Validation loss = 1.0433  \n",
      "\n",
      "Fold: 7  Epoch: 490  Training loss = 1.7852  Validation loss = 1.0424  \n",
      "\n",
      "Fold: 7  Epoch: 491  Training loss = 1.7850  Validation loss = 1.0418  \n",
      "\n",
      "Fold: 7  Epoch: 492  Training loss = 1.7849  Validation loss = 1.0405  \n",
      "\n",
      "Fold: 7  Epoch: 493  Training loss = 1.7847  Validation loss = 1.0393  \n",
      "\n",
      "Fold: 7  Epoch: 494  Training loss = 1.7845  Validation loss = 1.0379  \n",
      "\n",
      "Fold: 7  Epoch: 495  Training loss = 1.7843  Validation loss = 1.0372  \n",
      "\n",
      "Fold: 7  Epoch: 496  Training loss = 1.7841  Validation loss = 1.0361  \n",
      "\n",
      "Fold: 7  Epoch: 497  Training loss = 1.7841  Validation loss = 1.0362  \n",
      "\n",
      "Fold: 7  Epoch: 498  Training loss = 1.7839  Validation loss = 1.0353  \n",
      "\n",
      "Fold: 7  Epoch: 499  Training loss = 1.7838  Validation loss = 1.0347  \n",
      "\n",
      "Fold: 7  Epoch: 500  Training loss = 1.7835  Validation loss = 1.0336  \n",
      "\n",
      "Check model:  Fold: 7  Optimal epoch: 500  \n",
      "\n",
      "Fold: 8  Epoch: 1  Training loss = 1.7469  Validation loss = 5.9514  \n",
      "\n",
      "Fold: 8  Epoch: 2  Training loss = 1.7467  Validation loss = 5.9511  \n",
      "\n",
      "Fold: 8  Epoch: 3  Training loss = 1.7465  Validation loss = 5.9508  \n",
      "\n",
      "Fold: 8  Epoch: 4  Training loss = 1.7462  Validation loss = 5.9502  \n",
      "\n",
      "Fold: 8  Epoch: 5  Training loss = 1.7461  Validation loss = 5.9498  \n",
      "\n",
      "Fold: 8  Epoch: 6  Training loss = 1.7460  Validation loss = 5.9504  \n",
      "\n",
      "Fold: 8  Epoch: 7  Training loss = 1.7457  Validation loss = 5.9496  \n",
      "\n",
      "Fold: 8  Epoch: 8  Training loss = 1.7457  Validation loss = 5.9496  \n",
      "\n",
      "Fold: 8  Epoch: 9  Training loss = 1.7454  Validation loss = 5.9490  \n",
      "\n",
      "Fold: 8  Epoch: 10  Training loss = 1.7452  Validation loss = 5.9484  \n",
      "\n",
      "Fold: 8  Epoch: 11  Training loss = 1.7450  Validation loss = 5.9482  \n",
      "\n",
      "Fold: 8  Epoch: 12  Training loss = 1.7448  Validation loss = 5.9472  \n",
      "\n",
      "Fold: 8  Epoch: 13  Training loss = 1.7446  Validation loss = 5.9465  \n",
      "\n",
      "Fold: 8  Epoch: 14  Training loss = 1.7444  Validation loss = 5.9458  \n",
      "\n",
      "Fold: 8  Epoch: 15  Training loss = 1.7441  Validation loss = 5.9447  \n",
      "\n",
      "Fold: 8  Epoch: 16  Training loss = 1.7438  Validation loss = 5.9438  \n",
      "\n",
      "Fold: 8  Epoch: 17  Training loss = 1.7435  Validation loss = 5.9428  \n",
      "\n",
      "Fold: 8  Epoch: 18  Training loss = 1.7434  Validation loss = 5.9426  \n",
      "\n",
      "Fold: 8  Epoch: 19  Training loss = 1.7431  Validation loss = 5.9416  \n",
      "\n",
      "Fold: 8  Epoch: 20  Training loss = 1.7430  Validation loss = 5.9412  \n",
      "\n",
      "Fold: 8  Epoch: 21  Training loss = 1.7427  Validation loss = 5.9406  \n",
      "\n",
      "Fold: 8  Epoch: 22  Training loss = 1.7424  Validation loss = 5.9399  \n",
      "\n",
      "Fold: 8  Epoch: 23  Training loss = 1.7424  Validation loss = 5.9398  \n",
      "\n",
      "Fold: 8  Epoch: 24  Training loss = 1.7422  Validation loss = 5.9395  \n",
      "\n",
      "Fold: 8  Epoch: 25  Training loss = 1.7419  Validation loss = 5.9388  \n",
      "\n",
      "Fold: 8  Epoch: 26  Training loss = 1.7418  Validation loss = 5.9390  \n",
      "\n",
      "Fold: 8  Epoch: 27  Training loss = 1.7416  Validation loss = 5.9388  \n",
      "\n",
      "Fold: 8  Epoch: 28  Training loss = 1.7414  Validation loss = 5.9386  \n",
      "\n",
      "Fold: 8  Epoch: 29  Training loss = 1.7413  Validation loss = 5.9381  \n",
      "\n",
      "Fold: 8  Epoch: 30  Training loss = 1.7411  Validation loss = 5.9378  \n",
      "\n",
      "Fold: 8  Epoch: 31  Training loss = 1.7408  Validation loss = 5.9368  \n",
      "\n",
      "Fold: 8  Epoch: 32  Training loss = 1.7406  Validation loss = 5.9362  \n",
      "\n",
      "Fold: 8  Epoch: 33  Training loss = 1.7405  Validation loss = 5.9364  \n",
      "\n",
      "Fold: 8  Epoch: 34  Training loss = 1.7404  Validation loss = 5.9366  \n",
      "\n",
      "Fold: 8  Epoch: 35  Training loss = 1.7401  Validation loss = 5.9364  \n",
      "\n",
      "Fold: 8  Epoch: 36  Training loss = 1.7399  Validation loss = 5.9357  \n",
      "\n",
      "Fold: 8  Epoch: 37  Training loss = 1.7397  Validation loss = 5.9355  \n",
      "\n",
      "Fold: 8  Epoch: 38  Training loss = 1.7396  Validation loss = 5.9352  \n",
      "\n",
      "Fold: 8  Epoch: 39  Training loss = 1.7394  Validation loss = 5.9347  \n",
      "\n",
      "Fold: 8  Epoch: 40  Training loss = 1.7392  Validation loss = 5.9345  \n",
      "\n",
      "Fold: 8  Epoch: 41  Training loss = 1.7391  Validation loss = 5.9344  \n",
      "\n",
      "Fold: 8  Epoch: 42  Training loss = 1.7389  Validation loss = 5.9336  \n",
      "\n",
      "Fold: 8  Epoch: 43  Training loss = 1.7389  Validation loss = 5.9341  \n",
      "\n",
      "Fold: 8  Epoch: 44  Training loss = 1.7388  Validation loss = 5.9339  \n",
      "\n",
      "Fold: 8  Epoch: 45  Training loss = 1.7385  Validation loss = 5.9334  \n",
      "\n",
      "Fold: 8  Epoch: 46  Training loss = 1.7384  Validation loss = 5.9330  \n",
      "\n",
      "Fold: 8  Epoch: 47  Training loss = 1.7382  Validation loss = 5.9323  \n",
      "\n",
      "Fold: 8  Epoch: 48  Training loss = 1.7380  Validation loss = 5.9320  \n",
      "\n",
      "Fold: 8  Epoch: 49  Training loss = 1.7378  Validation loss = 5.9317  \n",
      "\n",
      "Fold: 8  Epoch: 50  Training loss = 1.7377  Validation loss = 5.9316  \n",
      "\n",
      "Fold: 8  Epoch: 51  Training loss = 1.7375  Validation loss = 5.9316  \n",
      "\n",
      "Fold: 8  Epoch: 52  Training loss = 1.7373  Validation loss = 5.9310  \n",
      "\n",
      "Fold: 8  Epoch: 53  Training loss = 1.7370  Validation loss = 5.9301  \n",
      "\n",
      "Fold: 8  Epoch: 54  Training loss = 1.7367  Validation loss = 5.9293  \n",
      "\n",
      "Fold: 8  Epoch: 55  Training loss = 1.7366  Validation loss = 5.9287  \n",
      "\n",
      "Fold: 8  Epoch: 56  Training loss = 1.7363  Validation loss = 5.9279  \n",
      "\n",
      "Fold: 8  Epoch: 57  Training loss = 1.7361  Validation loss = 5.9277  \n",
      "\n",
      "Fold: 8  Epoch: 58  Training loss = 1.7360  Validation loss = 5.9276  \n",
      "\n",
      "Fold: 8  Epoch: 59  Training loss = 1.7358  Validation loss = 5.9268  \n",
      "\n",
      "Fold: 8  Epoch: 60  Training loss = 1.7356  Validation loss = 5.9266  \n",
      "\n",
      "Fold: 8  Epoch: 61  Training loss = 1.7354  Validation loss = 5.9258  \n",
      "\n",
      "Fold: 8  Epoch: 62  Training loss = 1.7353  Validation loss = 5.9262  \n",
      "\n",
      "Fold: 8  Epoch: 63  Training loss = 1.7351  Validation loss = 5.9255  \n",
      "\n",
      "Fold: 8  Epoch: 64  Training loss = 1.7349  Validation loss = 5.9249  \n",
      "\n",
      "Fold: 8  Epoch: 65  Training loss = 1.7348  Validation loss = 5.9249  \n",
      "\n",
      "Fold: 8  Epoch: 66  Training loss = 1.7346  Validation loss = 5.9244  \n",
      "\n",
      "Fold: 8  Epoch: 67  Training loss = 1.7344  Validation loss = 5.9243  \n",
      "\n",
      "Fold: 8  Epoch: 68  Training loss = 1.7343  Validation loss = 5.9243  \n",
      "\n",
      "Fold: 8  Epoch: 69  Training loss = 1.7341  Validation loss = 5.9242  \n",
      "\n",
      "Fold: 8  Epoch: 70  Training loss = 1.7340  Validation loss = 5.9237  \n",
      "\n",
      "Fold: 8  Epoch: 71  Training loss = 1.7339  Validation loss = 5.9234  \n",
      "\n",
      "Fold: 8  Epoch: 72  Training loss = 1.7337  Validation loss = 5.9231  \n",
      "\n",
      "Fold: 8  Epoch: 73  Training loss = 1.7337  Validation loss = 5.9236  \n",
      "\n",
      "Fold: 8  Epoch: 74  Training loss = 1.7335  Validation loss = 5.9228  \n",
      "\n",
      "Fold: 8  Epoch: 75  Training loss = 1.7333  Validation loss = 5.9225  \n",
      "\n",
      "Fold: 8  Epoch: 76  Training loss = 1.7331  Validation loss = 5.9219  \n",
      "\n",
      "Fold: 8  Epoch: 77  Training loss = 1.7328  Validation loss = 5.9216  \n",
      "\n",
      "Fold: 8  Epoch: 78  Training loss = 1.7326  Validation loss = 5.9212  \n",
      "\n",
      "Fold: 8  Epoch: 79  Training loss = 1.7325  Validation loss = 5.9211  \n",
      "\n",
      "Fold: 8  Epoch: 80  Training loss = 1.7322  Validation loss = 5.9202  \n",
      "\n",
      "Fold: 8  Epoch: 81  Training loss = 1.7321  Validation loss = 5.9199  \n",
      "\n",
      "Fold: 8  Epoch: 82  Training loss = 1.7320  Validation loss = 5.9200  \n",
      "\n",
      "Fold: 8  Epoch: 83  Training loss = 1.7318  Validation loss = 5.9192  \n",
      "\n",
      "Fold: 8  Epoch: 84  Training loss = 1.7316  Validation loss = 5.9183  \n",
      "\n",
      "Fold: 8  Epoch: 85  Training loss = 1.7313  Validation loss = 5.9174  \n",
      "\n",
      "Fold: 8  Epoch: 86  Training loss = 1.7312  Validation loss = 5.9178  \n",
      "\n",
      "Fold: 8  Epoch: 87  Training loss = 1.7311  Validation loss = 5.9175  \n",
      "\n",
      "Fold: 8  Epoch: 88  Training loss = 1.7309  Validation loss = 5.9170  \n",
      "\n",
      "Fold: 8  Epoch: 89  Training loss = 1.7308  Validation loss = 5.9171  \n",
      "\n",
      "Fold: 8  Epoch: 90  Training loss = 1.7306  Validation loss = 5.9168  \n",
      "\n",
      "Fold: 8  Epoch: 91  Training loss = 1.7305  Validation loss = 5.9163  \n",
      "\n",
      "Fold: 8  Epoch: 92  Training loss = 1.7305  Validation loss = 5.9172  \n",
      "\n",
      "Fold: 8  Epoch: 93  Training loss = 1.7303  Validation loss = 5.9166  \n",
      "\n",
      "Fold: 8  Epoch: 94  Training loss = 1.7301  Validation loss = 5.9160  \n",
      "\n",
      "Fold: 8  Epoch: 95  Training loss = 1.7300  Validation loss = 5.9162  \n",
      "\n",
      "Fold: 8  Epoch: 96  Training loss = 1.7300  Validation loss = 5.9166  \n",
      "\n",
      "Fold: 8  Epoch: 97  Training loss = 1.7297  Validation loss = 5.9157  \n",
      "\n",
      "Fold: 8  Epoch: 98  Training loss = 1.7296  Validation loss = 5.9156  \n",
      "\n",
      "Fold: 8  Epoch: 99  Training loss = 1.7295  Validation loss = 5.9153  \n",
      "\n",
      "Fold: 8  Epoch: 100  Training loss = 1.7293  Validation loss = 5.9146  \n",
      "\n",
      "Fold: 8  Epoch: 101  Training loss = 1.7291  Validation loss = 5.9146  \n",
      "\n",
      "Fold: 8  Epoch: 102  Training loss = 1.7290  Validation loss = 5.9146  \n",
      "\n",
      "Fold: 8  Epoch: 103  Training loss = 1.7288  Validation loss = 5.9139  \n",
      "\n",
      "Fold: 8  Epoch: 104  Training loss = 1.7287  Validation loss = 5.9137  \n",
      "\n",
      "Fold: 8  Epoch: 105  Training loss = 1.7285  Validation loss = 5.9137  \n",
      "\n",
      "Fold: 8  Epoch: 106  Training loss = 1.7283  Validation loss = 5.9132  \n",
      "\n",
      "Fold: 8  Epoch: 107  Training loss = 1.7282  Validation loss = 5.9134  \n",
      "\n",
      "Fold: 8  Epoch: 108  Training loss = 1.7280  Validation loss = 5.9128  \n",
      "\n",
      "Fold: 8  Epoch: 109  Training loss = 1.7278  Validation loss = 5.9122  \n",
      "\n",
      "Fold: 8  Epoch: 110  Training loss = 1.7276  Validation loss = 5.9113  \n",
      "\n",
      "Fold: 8  Epoch: 111  Training loss = 1.7275  Validation loss = 5.9113  \n",
      "\n",
      "Fold: 8  Epoch: 112  Training loss = 1.7273  Validation loss = 5.9111  \n",
      "\n",
      "Fold: 8  Epoch: 113  Training loss = 1.7271  Validation loss = 5.9104  \n",
      "\n",
      "Fold: 8  Epoch: 114  Training loss = 1.7270  Validation loss = 5.9105  \n",
      "\n",
      "Fold: 8  Epoch: 115  Training loss = 1.7268  Validation loss = 5.9102  \n",
      "\n",
      "Fold: 8  Epoch: 116  Training loss = 1.7267  Validation loss = 5.9100  \n",
      "\n",
      "Fold: 8  Epoch: 117  Training loss = 1.7265  Validation loss = 5.9093  \n",
      "\n",
      "Fold: 8  Epoch: 118  Training loss = 1.7263  Validation loss = 5.9087  \n",
      "\n",
      "Fold: 8  Epoch: 119  Training loss = 1.7262  Validation loss = 5.9087  \n",
      "\n",
      "Fold: 8  Epoch: 120  Training loss = 1.7260  Validation loss = 5.9083  \n",
      "\n",
      "Fold: 8  Epoch: 121  Training loss = 1.7259  Validation loss = 5.9083  \n",
      "\n",
      "Fold: 8  Epoch: 122  Training loss = 1.7258  Validation loss = 5.9082  \n",
      "\n",
      "Fold: 8  Epoch: 123  Training loss = 1.7257  Validation loss = 5.9082  \n",
      "\n",
      "Fold: 8  Epoch: 124  Training loss = 1.7256  Validation loss = 5.9077  \n",
      "\n",
      "Fold: 8  Epoch: 125  Training loss = 1.7255  Validation loss = 5.9076  \n",
      "\n",
      "Fold: 8  Epoch: 126  Training loss = 1.7253  Validation loss = 5.9072  \n",
      "\n",
      "Fold: 8  Epoch: 127  Training loss = 1.7252  Validation loss = 5.9070  \n",
      "\n",
      "Fold: 8  Epoch: 128  Training loss = 1.7251  Validation loss = 5.9070  \n",
      "\n",
      "Fold: 8  Epoch: 129  Training loss = 1.7250  Validation loss = 5.9069  \n",
      "\n",
      "Fold: 8  Epoch: 130  Training loss = 1.7249  Validation loss = 5.9069  \n",
      "\n",
      "Fold: 8  Epoch: 131  Training loss = 1.7248  Validation loss = 5.9067  \n",
      "\n",
      "Fold: 8  Epoch: 132  Training loss = 1.7246  Validation loss = 5.9062  \n",
      "\n",
      "Fold: 8  Epoch: 133  Training loss = 1.7244  Validation loss = 5.9055  \n",
      "\n",
      "Fold: 8  Epoch: 134  Training loss = 1.7244  Validation loss = 5.9062  \n",
      "\n",
      "Fold: 8  Epoch: 135  Training loss = 1.7241  Validation loss = 5.9059  \n",
      "\n",
      "Fold: 8  Epoch: 136  Training loss = 1.7239  Validation loss = 5.9055  \n",
      "\n",
      "Fold: 8  Epoch: 137  Training loss = 1.7237  Validation loss = 5.9047  \n",
      "\n",
      "Fold: 8  Epoch: 138  Training loss = 1.7235  Validation loss = 5.9038  \n",
      "\n",
      "Fold: 8  Epoch: 139  Training loss = 1.7233  Validation loss = 5.9039  \n",
      "\n",
      "Fold: 8  Epoch: 140  Training loss = 1.7232  Validation loss = 5.9035  \n",
      "\n",
      "Fold: 8  Epoch: 141  Training loss = 1.7231  Validation loss = 5.9034  \n",
      "\n",
      "Fold: 8  Epoch: 142  Training loss = 1.7229  Validation loss = 5.9033  \n",
      "\n",
      "Fold: 8  Epoch: 143  Training loss = 1.7228  Validation loss = 5.9031  \n",
      "\n",
      "Fold: 8  Epoch: 144  Training loss = 1.7227  Validation loss = 5.9027  \n",
      "\n",
      "Fold: 8  Epoch: 145  Training loss = 1.7225  Validation loss = 5.9020  \n",
      "\n",
      "Fold: 8  Epoch: 146  Training loss = 1.7224  Validation loss = 5.9026  \n",
      "\n",
      "Fold: 8  Epoch: 147  Training loss = 1.7223  Validation loss = 5.9025  \n",
      "\n",
      "Fold: 8  Epoch: 148  Training loss = 1.7221  Validation loss = 5.9018  \n",
      "\n",
      "Fold: 8  Epoch: 149  Training loss = 1.7218  Validation loss = 5.9008  \n",
      "\n",
      "Fold: 8  Epoch: 150  Training loss = 1.7217  Validation loss = 5.9006  \n",
      "\n",
      "Fold: 8  Epoch: 151  Training loss = 1.7215  Validation loss = 5.9002  \n",
      "\n",
      "Fold: 8  Epoch: 152  Training loss = 1.7214  Validation loss = 5.8999  \n",
      "\n",
      "Fold: 8  Epoch: 153  Training loss = 1.7212  Validation loss = 5.8995  \n",
      "\n",
      "Fold: 8  Epoch: 154  Training loss = 1.7211  Validation loss = 5.8995  \n",
      "\n",
      "Fold: 8  Epoch: 155  Training loss = 1.7211  Validation loss = 5.8999  \n",
      "\n",
      "Fold: 8  Epoch: 156  Training loss = 1.7209  Validation loss = 5.8996  \n",
      "\n",
      "Fold: 8  Epoch: 157  Training loss = 1.7207  Validation loss = 5.8989  \n",
      "\n",
      "Fold: 8  Epoch: 158  Training loss = 1.7206  Validation loss = 5.8990  \n",
      "\n",
      "Fold: 8  Epoch: 159  Training loss = 1.7205  Validation loss = 5.8985  \n",
      "\n",
      "Fold: 8  Epoch: 160  Training loss = 1.7203  Validation loss = 5.8983  \n",
      "\n",
      "Fold: 8  Epoch: 161  Training loss = 1.7201  Validation loss = 5.8978  \n",
      "\n",
      "Fold: 8  Epoch: 162  Training loss = 1.7200  Validation loss = 5.8977  \n",
      "\n",
      "Fold: 8  Epoch: 163  Training loss = 1.7199  Validation loss = 5.8972  \n",
      "\n",
      "Fold: 8  Epoch: 164  Training loss = 1.7197  Validation loss = 5.8966  \n",
      "\n",
      "Fold: 8  Epoch: 165  Training loss = 1.7195  Validation loss = 5.8957  \n",
      "\n",
      "Fold: 8  Epoch: 166  Training loss = 1.7193  Validation loss = 5.8949  \n",
      "\n",
      "Fold: 8  Epoch: 167  Training loss = 1.7193  Validation loss = 5.8955  \n",
      "\n",
      "Fold: 8  Epoch: 168  Training loss = 1.7190  Validation loss = 5.8950  \n",
      "\n",
      "Fold: 8  Epoch: 169  Training loss = 1.7189  Validation loss = 5.8953  \n",
      "\n",
      "Fold: 8  Epoch: 170  Training loss = 1.7188  Validation loss = 5.8955  \n",
      "\n",
      "Fold: 8  Epoch: 171  Training loss = 1.7187  Validation loss = 5.8951  \n",
      "\n",
      "Fold: 8  Epoch: 172  Training loss = 1.7186  Validation loss = 5.8949  \n",
      "\n",
      "Fold: 8  Epoch: 173  Training loss = 1.7184  Validation loss = 5.8943  \n",
      "\n",
      "Fold: 8  Epoch: 174  Training loss = 1.7181  Validation loss = 5.8932  \n",
      "\n",
      "Fold: 8  Epoch: 175  Training loss = 1.7179  Validation loss = 5.8930  \n",
      "\n",
      "Fold: 8  Epoch: 176  Training loss = 1.7179  Validation loss = 5.8930  \n",
      "\n",
      "Fold: 8  Epoch: 177  Training loss = 1.7176  Validation loss = 5.8921  \n",
      "\n",
      "Fold: 8  Epoch: 178  Training loss = 1.7175  Validation loss = 5.8918  \n",
      "\n",
      "Fold: 8  Epoch: 179  Training loss = 1.7175  Validation loss = 5.8918  \n",
      "\n",
      "Fold: 8  Epoch: 180  Training loss = 1.7173  Validation loss = 5.8914  \n",
      "\n",
      "Fold: 8  Epoch: 181  Training loss = 1.7172  Validation loss = 5.8914  \n",
      "\n",
      "Fold: 8  Epoch: 182  Training loss = 1.7171  Validation loss = 5.8911  \n",
      "\n",
      "Fold: 8  Epoch: 183  Training loss = 1.7170  Validation loss = 5.8906  \n",
      "\n",
      "Fold: 8  Epoch: 184  Training loss = 1.7169  Validation loss = 5.8911  \n",
      "\n",
      "Fold: 8  Epoch: 185  Training loss = 1.7169  Validation loss = 5.8913  \n",
      "\n",
      "Fold: 8  Epoch: 186  Training loss = 1.7167  Validation loss = 5.8904  \n",
      "\n",
      "Fold: 8  Epoch: 187  Training loss = 1.7166  Validation loss = 5.8903  \n",
      "\n",
      "Fold: 8  Epoch: 188  Training loss = 1.7165  Validation loss = 5.8908  \n",
      "\n",
      "Fold: 8  Epoch: 189  Training loss = 1.7164  Validation loss = 5.8909  \n",
      "\n",
      "Fold: 8  Epoch: 190  Training loss = 1.7162  Validation loss = 5.8903  \n",
      "\n",
      "Fold: 8  Epoch: 191  Training loss = 1.7161  Validation loss = 5.8898  \n",
      "\n",
      "Fold: 8  Epoch: 192  Training loss = 1.7159  Validation loss = 5.8894  \n",
      "\n",
      "Fold: 8  Epoch: 193  Training loss = 1.7157  Validation loss = 5.8893  \n",
      "\n",
      "Fold: 8  Epoch: 194  Training loss = 1.7156  Validation loss = 5.8890  \n",
      "\n",
      "Fold: 8  Epoch: 195  Training loss = 1.7155  Validation loss = 5.8890  \n",
      "\n",
      "Fold: 8  Epoch: 196  Training loss = 1.7155  Validation loss = 5.8895  \n",
      "\n",
      "Fold: 8  Epoch: 197  Training loss = 1.7153  Validation loss = 5.8892  \n",
      "\n",
      "Fold: 8  Epoch: 198  Training loss = 1.7152  Validation loss = 5.8889  \n",
      "\n",
      "Fold: 8  Epoch: 199  Training loss = 1.7151  Validation loss = 5.8886  \n",
      "\n",
      "Fold: 8  Epoch: 200  Training loss = 1.7150  Validation loss = 5.8888  \n",
      "\n",
      "Fold: 8  Epoch: 201  Training loss = 1.7148  Validation loss = 5.8884  \n",
      "\n",
      "Fold: 8  Epoch: 202  Training loss = 1.7146  Validation loss = 5.8878  \n",
      "\n",
      "Fold: 8  Epoch: 203  Training loss = 1.7145  Validation loss = 5.8876  \n",
      "\n",
      "Fold: 8  Epoch: 204  Training loss = 1.7143  Validation loss = 5.8870  \n",
      "\n",
      "Fold: 8  Epoch: 205  Training loss = 1.7143  Validation loss = 5.8871  \n",
      "\n",
      "Fold: 8  Epoch: 206  Training loss = 1.7141  Validation loss = 5.8867  \n",
      "\n",
      "Fold: 8  Epoch: 207  Training loss = 1.7140  Validation loss = 5.8865  \n",
      "\n",
      "Fold: 8  Epoch: 208  Training loss = 1.7139  Validation loss = 5.8864  \n",
      "\n",
      "Fold: 8  Epoch: 209  Training loss = 1.7138  Validation loss = 5.8865  \n",
      "\n",
      "Fold: 8  Epoch: 210  Training loss = 1.7137  Validation loss = 5.8869  \n",
      "\n",
      "Fold: 8  Epoch: 211  Training loss = 1.7136  Validation loss = 5.8868  \n",
      "\n",
      "Fold: 8  Epoch: 212  Training loss = 1.7135  Validation loss = 5.8867  \n",
      "\n",
      "Fold: 8  Epoch: 213  Training loss = 1.7135  Validation loss = 5.8868  \n",
      "\n",
      "Fold: 8  Epoch: 214  Training loss = 1.7133  Validation loss = 5.8862  \n",
      "\n",
      "Fold: 8  Epoch: 215  Training loss = 1.7132  Validation loss = 5.8863  \n",
      "\n",
      "Fold: 8  Epoch: 216  Training loss = 1.7132  Validation loss = 5.8868  \n",
      "\n",
      "Fold: 8  Epoch: 217  Training loss = 1.7131  Validation loss = 5.8868  \n",
      "\n",
      "Fold: 8  Epoch: 218  Training loss = 1.7130  Validation loss = 5.8870  \n",
      "\n",
      "Check model:  Fold: 8  Optimal epoch: 214  \n",
      "\n",
      "Fold: 9  Epoch: 1  Training loss = 2.2315  Validation loss = 9.4038  \n",
      "\n",
      "Fold: 9  Epoch: 2  Training loss = 2.2312  Validation loss = 9.4024  \n",
      "\n",
      "Fold: 9  Epoch: 3  Training loss = 2.2310  Validation loss = 9.4018  \n",
      "\n",
      "Fold: 9  Epoch: 4  Training loss = 2.2307  Validation loss = 9.4003  \n",
      "\n",
      "Fold: 9  Epoch: 5  Training loss = 2.2305  Validation loss = 9.3999  \n",
      "\n",
      "Fold: 9  Epoch: 6  Training loss = 2.2301  Validation loss = 9.3987  \n",
      "\n",
      "Fold: 9  Epoch: 7  Training loss = 2.2297  Validation loss = 9.3972  \n",
      "\n",
      "Fold: 9  Epoch: 8  Training loss = 2.2296  Validation loss = 9.3969  \n",
      "\n",
      "Fold: 9  Epoch: 9  Training loss = 2.2293  Validation loss = 9.3956  \n",
      "\n",
      "Fold: 9  Epoch: 10  Training loss = 2.2291  Validation loss = 9.3950  \n",
      "\n",
      "Fold: 9  Epoch: 11  Training loss = 2.2289  Validation loss = 9.3943  \n",
      "\n",
      "Fold: 9  Epoch: 12  Training loss = 2.2285  Validation loss = 9.3931  \n",
      "\n",
      "Fold: 9  Epoch: 13  Training loss = 2.2282  Validation loss = 9.3916  \n",
      "\n",
      "Fold: 9  Epoch: 14  Training loss = 2.2279  Validation loss = 9.3909  \n",
      "\n",
      "Fold: 9  Epoch: 15  Training loss = 2.2277  Validation loss = 9.3898  \n",
      "\n",
      "Fold: 9  Epoch: 16  Training loss = 2.2275  Validation loss = 9.3893  \n",
      "\n",
      "Fold: 9  Epoch: 17  Training loss = 2.2273  Validation loss = 9.3884  \n",
      "\n",
      "Fold: 9  Epoch: 18  Training loss = 2.2270  Validation loss = 9.3875  \n",
      "\n",
      "Fold: 9  Epoch: 19  Training loss = 2.2267  Validation loss = 9.3864  \n",
      "\n",
      "Fold: 9  Epoch: 20  Training loss = 2.2265  Validation loss = 9.3855  \n",
      "\n",
      "Fold: 9  Epoch: 21  Training loss = 2.2262  Validation loss = 9.3843  \n",
      "\n",
      "Fold: 9  Epoch: 22  Training loss = 2.2260  Validation loss = 9.3836  \n",
      "\n",
      "Fold: 9  Epoch: 23  Training loss = 2.2256  Validation loss = 9.3819  \n",
      "\n",
      "Fold: 9  Epoch: 24  Training loss = 2.2254  Validation loss = 9.3810  \n",
      "\n",
      "Fold: 9  Epoch: 25  Training loss = 2.2252  Validation loss = 9.3803  \n",
      "\n",
      "Fold: 9  Epoch: 26  Training loss = 2.2248  Validation loss = 9.3790  \n",
      "\n",
      "Fold: 9  Epoch: 27  Training loss = 2.2245  Validation loss = 9.3777  \n",
      "\n",
      "Fold: 9  Epoch: 28  Training loss = 2.2242  Validation loss = 9.3766  \n",
      "\n",
      "Fold: 9  Epoch: 29  Training loss = 2.2239  Validation loss = 9.3756  \n",
      "\n",
      "Fold: 9  Epoch: 30  Training loss = 2.2235  Validation loss = 9.3740  \n",
      "\n",
      "Fold: 9  Epoch: 31  Training loss = 2.2232  Validation loss = 9.3729  \n",
      "\n",
      "Fold: 9  Epoch: 32  Training loss = 2.2231  Validation loss = 9.3726  \n",
      "\n",
      "Fold: 9  Epoch: 33  Training loss = 2.2229  Validation loss = 9.3718  \n",
      "\n",
      "Fold: 9  Epoch: 34  Training loss = 2.2224  Validation loss = 9.3700  \n",
      "\n",
      "Fold: 9  Epoch: 35  Training loss = 2.2222  Validation loss = 9.3689  \n",
      "\n",
      "Fold: 9  Epoch: 36  Training loss = 2.2221  Validation loss = 9.3686  \n",
      "\n",
      "Fold: 9  Epoch: 37  Training loss = 2.2219  Validation loss = 9.3680  \n",
      "\n",
      "Fold: 9  Epoch: 38  Training loss = 2.2216  Validation loss = 9.3668  \n",
      "\n",
      "Fold: 9  Epoch: 39  Training loss = 2.2212  Validation loss = 9.3651  \n",
      "\n",
      "Fold: 9  Epoch: 40  Training loss = 2.2209  Validation loss = 9.3639  \n",
      "\n",
      "Fold: 9  Epoch: 41  Training loss = 2.2206  Validation loss = 9.3625  \n",
      "\n",
      "Fold: 9  Epoch: 42  Training loss = 2.2206  Validation loss = 9.3627  \n",
      "\n",
      "Fold: 9  Epoch: 43  Training loss = 2.2205  Validation loss = 9.3621  \n",
      "\n",
      "Fold: 9  Epoch: 44  Training loss = 2.2201  Validation loss = 9.3606  \n",
      "\n",
      "Fold: 9  Epoch: 45  Training loss = 2.2199  Validation loss = 9.3603  \n",
      "\n",
      "Fold: 9  Epoch: 46  Training loss = 2.2198  Validation loss = 9.3599  \n",
      "\n",
      "Fold: 9  Epoch: 47  Training loss = 2.2193  Validation loss = 9.3577  \n",
      "\n",
      "Fold: 9  Epoch: 48  Training loss = 2.2192  Validation loss = 9.3571  \n",
      "\n",
      "Fold: 9  Epoch: 49  Training loss = 2.2191  Validation loss = 9.3568  \n",
      "\n",
      "Fold: 9  Epoch: 50  Training loss = 2.2188  Validation loss = 9.3560  \n",
      "\n",
      "Fold: 9  Epoch: 51  Training loss = 2.2185  Validation loss = 9.3544  \n",
      "\n",
      "Fold: 9  Epoch: 52  Training loss = 2.2182  Validation loss = 9.3535  \n",
      "\n",
      "Fold: 9  Epoch: 53  Training loss = 2.2178  Validation loss = 9.3518  \n",
      "\n",
      "Fold: 9  Epoch: 54  Training loss = 2.2178  Validation loss = 9.3517  \n",
      "\n",
      "Fold: 9  Epoch: 55  Training loss = 2.2177  Validation loss = 9.3516  \n",
      "\n",
      "Fold: 9  Epoch: 56  Training loss = 2.2173  Validation loss = 9.3499  \n",
      "\n",
      "Fold: 9  Epoch: 57  Training loss = 2.2169  Validation loss = 9.3483  \n",
      "\n",
      "Fold: 9  Epoch: 58  Training loss = 2.2166  Validation loss = 9.3469  \n",
      "\n",
      "Fold: 9  Epoch: 59  Training loss = 2.2163  Validation loss = 9.3461  \n",
      "\n",
      "Fold: 9  Epoch: 60  Training loss = 2.2161  Validation loss = 9.3450  \n",
      "\n",
      "Fold: 9  Epoch: 61  Training loss = 2.2159  Validation loss = 9.3443  \n",
      "\n",
      "Fold: 9  Epoch: 62  Training loss = 2.2156  Validation loss = 9.3431  \n",
      "\n",
      "Fold: 9  Epoch: 63  Training loss = 2.2153  Validation loss = 9.3423  \n",
      "\n",
      "Fold: 9  Epoch: 64  Training loss = 2.2152  Validation loss = 9.3416  \n",
      "\n",
      "Fold: 9  Epoch: 65  Training loss = 2.2148  Validation loss = 9.3400  \n",
      "\n",
      "Fold: 9  Epoch: 66  Training loss = 2.2144  Validation loss = 9.3384  \n",
      "\n",
      "Fold: 9  Epoch: 67  Training loss = 2.2141  Validation loss = 9.3372  \n",
      "\n",
      "Fold: 9  Epoch: 68  Training loss = 2.2137  Validation loss = 9.3353  \n",
      "\n",
      "Fold: 9  Epoch: 69  Training loss = 2.2136  Validation loss = 9.3349  \n",
      "\n",
      "Fold: 9  Epoch: 70  Training loss = 2.2133  Validation loss = 9.3340  \n",
      "\n",
      "Fold: 9  Epoch: 71  Training loss = 2.2132  Validation loss = 9.3336  \n",
      "\n",
      "Fold: 9  Epoch: 72  Training loss = 2.2131  Validation loss = 9.3334  \n",
      "\n",
      "Fold: 9  Epoch: 73  Training loss = 2.2129  Validation loss = 9.3327  \n",
      "\n",
      "Fold: 9  Epoch: 74  Training loss = 2.2126  Validation loss = 9.3313  \n",
      "\n",
      "Fold: 9  Epoch: 75  Training loss = 2.2123  Validation loss = 9.3303  \n",
      "\n",
      "Fold: 9  Epoch: 76  Training loss = 2.2120  Validation loss = 9.3289  \n",
      "\n",
      "Fold: 9  Epoch: 77  Training loss = 2.2118  Validation loss = 9.3280  \n",
      "\n",
      "Fold: 9  Epoch: 78  Training loss = 2.2117  Validation loss = 9.3278  \n",
      "\n",
      "Fold: 9  Epoch: 79  Training loss = 2.2115  Validation loss = 9.3268  \n",
      "\n",
      "Fold: 9  Epoch: 80  Training loss = 2.2115  Validation loss = 9.3270  \n",
      "\n",
      "Fold: 9  Epoch: 81  Training loss = 2.2114  Validation loss = 9.3266  \n",
      "\n",
      "Fold: 9  Epoch: 82  Training loss = 2.2111  Validation loss = 9.3253  \n",
      "\n",
      "Fold: 9  Epoch: 83  Training loss = 2.2108  Validation loss = 9.3246  \n",
      "\n",
      "Fold: 9  Epoch: 84  Training loss = 2.2106  Validation loss = 9.3238  \n",
      "\n",
      "Fold: 9  Epoch: 85  Training loss = 2.2104  Validation loss = 9.3229  \n",
      "\n",
      "Fold: 9  Epoch: 86  Training loss = 2.2102  Validation loss = 9.3221  \n",
      "\n",
      "Fold: 9  Epoch: 87  Training loss = 2.2101  Validation loss = 9.3218  \n",
      "\n",
      "Fold: 9  Epoch: 88  Training loss = 2.2099  Validation loss = 9.3212  \n",
      "\n",
      "Fold: 9  Epoch: 89  Training loss = 2.2097  Validation loss = 9.3205  \n",
      "\n",
      "Fold: 9  Epoch: 90  Training loss = 2.2096  Validation loss = 9.3197  \n",
      "\n",
      "Fold: 9  Epoch: 91  Training loss = 2.2092  Validation loss = 9.3181  \n",
      "\n",
      "Fold: 9  Epoch: 92  Training loss = 2.2090  Validation loss = 9.3175  \n",
      "\n",
      "Fold: 9  Epoch: 93  Training loss = 2.2087  Validation loss = 9.3162  \n",
      "\n",
      "Fold: 9  Epoch: 94  Training loss = 2.2086  Validation loss = 9.3155  \n",
      "\n",
      "Fold: 9  Epoch: 95  Training loss = 2.2084  Validation loss = 9.3147  \n",
      "\n",
      "Fold: 9  Epoch: 96  Training loss = 2.2081  Validation loss = 9.3134  \n",
      "\n",
      "Fold: 9  Epoch: 97  Training loss = 2.2079  Validation loss = 9.3127  \n",
      "\n",
      "Fold: 9  Epoch: 98  Training loss = 2.2077  Validation loss = 9.3123  \n",
      "\n",
      "Fold: 9  Epoch: 99  Training loss = 2.2076  Validation loss = 9.3117  \n",
      "\n",
      "Fold: 9  Epoch: 100  Training loss = 2.2075  Validation loss = 9.3117  \n",
      "\n",
      "Fold: 9  Epoch: 101  Training loss = 2.2072  Validation loss = 9.3105  \n",
      "\n",
      "Fold: 9  Epoch: 102  Training loss = 2.2071  Validation loss = 9.3099  \n",
      "\n",
      "Fold: 9  Epoch: 103  Training loss = 2.2069  Validation loss = 9.3089  \n",
      "\n",
      "Fold: 9  Epoch: 104  Training loss = 2.2068  Validation loss = 9.3087  \n",
      "\n",
      "Fold: 9  Epoch: 105  Training loss = 2.2066  Validation loss = 9.3082  \n",
      "\n",
      "Fold: 9  Epoch: 106  Training loss = 2.2062  Validation loss = 9.3064  \n",
      "\n",
      "Fold: 9  Epoch: 107  Training loss = 2.2059  Validation loss = 9.3051  \n",
      "\n",
      "Fold: 9  Epoch: 108  Training loss = 2.2058  Validation loss = 9.3045  \n",
      "\n",
      "Fold: 9  Epoch: 109  Training loss = 2.2055  Validation loss = 9.3034  \n",
      "\n",
      "Fold: 9  Epoch: 110  Training loss = 2.2050  Validation loss = 9.3012  \n",
      "\n",
      "Fold: 9  Epoch: 111  Training loss = 2.2050  Validation loss = 9.3013  \n",
      "\n",
      "Fold: 9  Epoch: 112  Training loss = 2.2048  Validation loss = 9.3009  \n",
      "\n",
      "Fold: 9  Epoch: 113  Training loss = 2.2046  Validation loss = 9.3001  \n",
      "\n",
      "Fold: 9  Epoch: 114  Training loss = 2.2045  Validation loss = 9.2995  \n",
      "\n",
      "Fold: 9  Epoch: 115  Training loss = 2.2043  Validation loss = 9.2987  \n",
      "\n",
      "Fold: 9  Epoch: 116  Training loss = 2.2040  Validation loss = 9.2978  \n",
      "\n",
      "Fold: 9  Epoch: 117  Training loss = 2.2039  Validation loss = 9.2974  \n",
      "\n",
      "Fold: 9  Epoch: 118  Training loss = 2.2038  Validation loss = 9.2969  \n",
      "\n",
      "Fold: 9  Epoch: 119  Training loss = 2.2037  Validation loss = 9.2966  \n",
      "\n",
      "Fold: 9  Epoch: 120  Training loss = 2.2033  Validation loss = 9.2953  \n",
      "\n",
      "Fold: 9  Epoch: 121  Training loss = 2.2031  Validation loss = 9.2943  \n",
      "\n",
      "Fold: 9  Epoch: 122  Training loss = 2.2028  Validation loss = 9.2928  \n",
      "\n",
      "Fold: 9  Epoch: 123  Training loss = 2.2024  Validation loss = 9.2914  \n",
      "\n",
      "Fold: 9  Epoch: 124  Training loss = 2.2022  Validation loss = 9.2905  \n",
      "\n",
      "Fold: 9  Epoch: 125  Training loss = 2.2020  Validation loss = 9.2892  \n",
      "\n",
      "Fold: 9  Epoch: 126  Training loss = 2.2017  Validation loss = 9.2881  \n",
      "\n",
      "Fold: 9  Epoch: 127  Training loss = 2.2015  Validation loss = 9.2873  \n",
      "\n",
      "Fold: 9  Epoch: 128  Training loss = 2.2011  Validation loss = 9.2857  \n",
      "\n",
      "Fold: 9  Epoch: 129  Training loss = 2.2010  Validation loss = 9.2854  \n",
      "\n",
      "Fold: 9  Epoch: 130  Training loss = 2.2008  Validation loss = 9.2842  \n",
      "\n",
      "Fold: 9  Epoch: 131  Training loss = 2.2005  Validation loss = 9.2829  \n",
      "\n",
      "Fold: 9  Epoch: 132  Training loss = 2.2002  Validation loss = 9.2816  \n",
      "\n",
      "Fold: 9  Epoch: 133  Training loss = 2.2000  Validation loss = 9.2811  \n",
      "\n",
      "Fold: 9  Epoch: 134  Training loss = 2.1998  Validation loss = 9.2802  \n",
      "\n",
      "Fold: 9  Epoch: 135  Training loss = 2.1998  Validation loss = 9.2803  \n",
      "\n",
      "Fold: 9  Epoch: 136  Training loss = 2.1996  Validation loss = 9.2793  \n",
      "\n",
      "Fold: 9  Epoch: 137  Training loss = 2.1994  Validation loss = 9.2782  \n",
      "\n",
      "Fold: 9  Epoch: 138  Training loss = 2.1993  Validation loss = 9.2782  \n",
      "\n",
      "Fold: 9  Epoch: 139  Training loss = 2.1991  Validation loss = 9.2775  \n",
      "\n",
      "Fold: 9  Epoch: 140  Training loss = 2.1989  Validation loss = 9.2764  \n",
      "\n",
      "Fold: 9  Epoch: 141  Training loss = 2.1987  Validation loss = 9.2759  \n",
      "\n",
      "Fold: 9  Epoch: 142  Training loss = 2.1985  Validation loss = 9.2745  \n",
      "\n",
      "Fold: 9  Epoch: 143  Training loss = 2.1981  Validation loss = 9.2729  \n",
      "\n",
      "Fold: 9  Epoch: 144  Training loss = 2.1978  Validation loss = 9.2716  \n",
      "\n",
      "Fold: 9  Epoch: 145  Training loss = 2.1976  Validation loss = 9.2703  \n",
      "\n",
      "Fold: 9  Epoch: 146  Training loss = 2.1973  Validation loss = 9.2688  \n",
      "\n",
      "Fold: 9  Epoch: 147  Training loss = 2.1972  Validation loss = 9.2683  \n",
      "\n",
      "Fold: 9  Epoch: 148  Training loss = 2.1970  Validation loss = 9.2680  \n",
      "\n",
      "Fold: 9  Epoch: 149  Training loss = 2.1967  Validation loss = 9.2667  \n",
      "\n",
      "Fold: 9  Epoch: 150  Training loss = 2.1966  Validation loss = 9.2660  \n",
      "\n",
      "Fold: 9  Epoch: 151  Training loss = 2.1964  Validation loss = 9.2653  \n",
      "\n",
      "Fold: 9  Epoch: 152  Training loss = 2.1964  Validation loss = 9.2653  \n",
      "\n",
      "Fold: 9  Epoch: 153  Training loss = 2.1961  Validation loss = 9.2641  \n",
      "\n",
      "Fold: 9  Epoch: 154  Training loss = 2.1959  Validation loss = 9.2634  \n",
      "\n",
      "Fold: 9  Epoch: 155  Training loss = 2.1959  Validation loss = 9.2635  \n",
      "\n",
      "Fold: 9  Epoch: 156  Training loss = 2.1957  Validation loss = 9.2624  \n",
      "\n",
      "Fold: 9  Epoch: 157  Training loss = 2.1956  Validation loss = 9.2621  \n",
      "\n",
      "Fold: 9  Epoch: 158  Training loss = 2.1953  Validation loss = 9.2607  \n",
      "\n",
      "Fold: 9  Epoch: 159  Training loss = 2.1951  Validation loss = 9.2597  \n",
      "\n",
      "Fold: 9  Epoch: 160  Training loss = 2.1949  Validation loss = 9.2588  \n",
      "\n",
      "Fold: 9  Epoch: 161  Training loss = 2.1947  Validation loss = 9.2579  \n",
      "\n",
      "Fold: 9  Epoch: 162  Training loss = 2.1944  Validation loss = 9.2569  \n",
      "\n",
      "Fold: 9  Epoch: 163  Training loss = 2.1944  Validation loss = 9.2566  \n",
      "\n",
      "Fold: 9  Epoch: 164  Training loss = 2.1941  Validation loss = 9.2555  \n",
      "\n",
      "Fold: 9  Epoch: 165  Training loss = 2.1941  Validation loss = 9.2551  \n",
      "\n",
      "Fold: 9  Epoch: 166  Training loss = 2.1938  Validation loss = 9.2541  \n",
      "\n",
      "Fold: 9  Epoch: 167  Training loss = 2.1935  Validation loss = 9.2526  \n",
      "\n",
      "Fold: 9  Epoch: 168  Training loss = 2.1935  Validation loss = 9.2526  \n",
      "\n",
      "Fold: 9  Epoch: 169  Training loss = 2.1933  Validation loss = 9.2521  \n",
      "\n",
      "Fold: 9  Epoch: 170  Training loss = 2.1931  Validation loss = 9.2508  \n",
      "\n",
      "Fold: 9  Epoch: 171  Training loss = 2.1927  Validation loss = 9.2490  \n",
      "\n",
      "Fold: 9  Epoch: 172  Training loss = 2.1925  Validation loss = 9.2478  \n",
      "\n",
      "Fold: 9  Epoch: 173  Training loss = 2.1922  Validation loss = 9.2466  \n",
      "\n",
      "Fold: 9  Epoch: 174  Training loss = 2.1919  Validation loss = 9.2453  \n",
      "\n",
      "Fold: 9  Epoch: 175  Training loss = 2.1917  Validation loss = 9.2438  \n",
      "\n",
      "Fold: 9  Epoch: 176  Training loss = 2.1915  Validation loss = 9.2434  \n",
      "\n",
      "Fold: 9  Epoch: 177  Training loss = 2.1914  Validation loss = 9.2428  \n",
      "\n",
      "Fold: 9  Epoch: 178  Training loss = 2.1912  Validation loss = 9.2422  \n",
      "\n",
      "Fold: 9  Epoch: 179  Training loss = 2.1910  Validation loss = 9.2413  \n",
      "\n",
      "Fold: 9  Epoch: 180  Training loss = 2.1907  Validation loss = 9.2396  \n",
      "\n",
      "Fold: 9  Epoch: 181  Training loss = 2.1906  Validation loss = 9.2391  \n",
      "\n",
      "Fold: 9  Epoch: 182  Training loss = 2.1905  Validation loss = 9.2387  \n",
      "\n",
      "Fold: 9  Epoch: 183  Training loss = 2.1905  Validation loss = 9.2392  \n",
      "\n",
      "Fold: 9  Epoch: 184  Training loss = 2.1904  Validation loss = 9.2388  \n",
      "\n",
      "Fold: 9  Epoch: 185  Training loss = 2.1901  Validation loss = 9.2378  \n",
      "\n",
      "Fold: 9  Epoch: 186  Training loss = 2.1899  Validation loss = 9.2371  \n",
      "\n",
      "Fold: 9  Epoch: 187  Training loss = 2.1897  Validation loss = 9.2360  \n",
      "\n",
      "Fold: 9  Epoch: 188  Training loss = 2.1896  Validation loss = 9.2356  \n",
      "\n",
      "Fold: 9  Epoch: 189  Training loss = 2.1894  Validation loss = 9.2349  \n",
      "\n",
      "Fold: 9  Epoch: 190  Training loss = 2.1892  Validation loss = 9.2341  \n",
      "\n",
      "Fold: 9  Epoch: 191  Training loss = 2.1890  Validation loss = 9.2328  \n",
      "\n",
      "Fold: 9  Epoch: 192  Training loss = 2.1887  Validation loss = 9.2316  \n",
      "\n",
      "Fold: 9  Epoch: 193  Training loss = 2.1886  Validation loss = 9.2312  \n",
      "\n",
      "Fold: 9  Epoch: 194  Training loss = 2.1884  Validation loss = 9.2299  \n",
      "\n",
      "Fold: 9  Epoch: 195  Training loss = 2.1882  Validation loss = 9.2289  \n",
      "\n",
      "Fold: 9  Epoch: 196  Training loss = 2.1880  Validation loss = 9.2283  \n",
      "\n",
      "Fold: 9  Epoch: 197  Training loss = 2.1878  Validation loss = 9.2271  \n",
      "\n",
      "Fold: 9  Epoch: 198  Training loss = 2.1874  Validation loss = 9.2252  \n",
      "\n",
      "Fold: 9  Epoch: 199  Training loss = 2.1874  Validation loss = 9.2251  \n",
      "\n",
      "Fold: 9  Epoch: 200  Training loss = 2.1872  Validation loss = 9.2247  \n",
      "\n",
      "Fold: 9  Epoch: 201  Training loss = 2.1870  Validation loss = 9.2234  \n",
      "\n",
      "Fold: 9  Epoch: 202  Training loss = 2.1868  Validation loss = 9.2227  \n",
      "\n",
      "Fold: 9  Epoch: 203  Training loss = 2.1867  Validation loss = 9.2220  \n",
      "\n",
      "Fold: 9  Epoch: 204  Training loss = 2.1864  Validation loss = 9.2203  \n",
      "\n",
      "Fold: 9  Epoch: 205  Training loss = 2.1862  Validation loss = 9.2194  \n",
      "\n",
      "Fold: 9  Epoch: 206  Training loss = 2.1859  Validation loss = 9.2180  \n",
      "\n",
      "Fold: 9  Epoch: 207  Training loss = 2.1858  Validation loss = 9.2173  \n",
      "\n",
      "Fold: 9  Epoch: 208  Training loss = 2.1857  Validation loss = 9.2168  \n",
      "\n",
      "Fold: 9  Epoch: 209  Training loss = 2.1855  Validation loss = 9.2160  \n",
      "\n",
      "Fold: 9  Epoch: 210  Training loss = 2.1854  Validation loss = 9.2157  \n",
      "\n",
      "Fold: 9  Epoch: 211  Training loss = 2.1852  Validation loss = 9.2150  \n",
      "\n",
      "Fold: 9  Epoch: 212  Training loss = 2.1850  Validation loss = 9.2141  \n",
      "\n",
      "Fold: 9  Epoch: 213  Training loss = 2.1848  Validation loss = 9.2131  \n",
      "\n",
      "Fold: 9  Epoch: 214  Training loss = 2.1846  Validation loss = 9.2118  \n",
      "\n",
      "Fold: 9  Epoch: 215  Training loss = 2.1844  Validation loss = 9.2110  \n",
      "\n",
      "Fold: 9  Epoch: 216  Training loss = 2.1841  Validation loss = 9.2094  \n",
      "\n",
      "Fold: 9  Epoch: 217  Training loss = 2.1838  Validation loss = 9.2081  \n",
      "\n",
      "Fold: 9  Epoch: 218  Training loss = 2.1835  Validation loss = 9.2060  \n",
      "\n",
      "Fold: 9  Epoch: 219  Training loss = 2.1833  Validation loss = 9.2051  \n",
      "\n",
      "Fold: 9  Epoch: 220  Training loss = 2.1830  Validation loss = 9.2039  \n",
      "\n",
      "Fold: 9  Epoch: 221  Training loss = 2.1827  Validation loss = 9.2022  \n",
      "\n",
      "Fold: 9  Epoch: 222  Training loss = 2.1825  Validation loss = 9.2009  \n",
      "\n",
      "Fold: 9  Epoch: 223  Training loss = 2.1823  Validation loss = 9.2001  \n",
      "\n",
      "Fold: 9  Epoch: 224  Training loss = 2.1822  Validation loss = 9.1999  \n",
      "\n",
      "Fold: 9  Epoch: 225  Training loss = 2.1820  Validation loss = 9.1989  \n",
      "\n",
      "Fold: 9  Epoch: 226  Training loss = 2.1819  Validation loss = 9.1986  \n",
      "\n",
      "Fold: 9  Epoch: 227  Training loss = 2.1818  Validation loss = 9.1982  \n",
      "\n",
      "Fold: 9  Epoch: 228  Training loss = 2.1817  Validation loss = 9.1982  \n",
      "\n",
      "Fold: 9  Epoch: 229  Training loss = 2.1815  Validation loss = 9.1970  \n",
      "\n",
      "Fold: 9  Epoch: 230  Training loss = 2.1815  Validation loss = 9.1973  \n",
      "\n",
      "Fold: 9  Epoch: 231  Training loss = 2.1812  Validation loss = 9.1960  \n",
      "\n",
      "Fold: 9  Epoch: 232  Training loss = 2.1809  Validation loss = 9.1941  \n",
      "\n",
      "Fold: 9  Epoch: 233  Training loss = 2.1808  Validation loss = 9.1937  \n",
      "\n",
      "Fold: 9  Epoch: 234  Training loss = 2.1806  Validation loss = 9.1928  \n",
      "\n",
      "Fold: 9  Epoch: 235  Training loss = 2.1805  Validation loss = 9.1922  \n",
      "\n",
      "Fold: 9  Epoch: 236  Training loss = 2.1803  Validation loss = 9.1918  \n",
      "\n",
      "Fold: 9  Epoch: 237  Training loss = 2.1802  Validation loss = 9.1913  \n",
      "\n",
      "Fold: 9  Epoch: 238  Training loss = 2.1800  Validation loss = 9.1903  \n",
      "\n",
      "Fold: 9  Epoch: 239  Training loss = 2.1799  Validation loss = 9.1897  \n",
      "\n",
      "Fold: 9  Epoch: 240  Training loss = 2.1797  Validation loss = 9.1886  \n",
      "\n",
      "Fold: 9  Epoch: 241  Training loss = 2.1795  Validation loss = 9.1877  \n",
      "\n",
      "Fold: 9  Epoch: 242  Training loss = 2.1793  Validation loss = 9.1869  \n",
      "\n",
      "Fold: 9  Epoch: 243  Training loss = 2.1791  Validation loss = 9.1860  \n",
      "\n",
      "Fold: 9  Epoch: 244  Training loss = 2.1791  Validation loss = 9.1862  \n",
      "\n",
      "Fold: 9  Epoch: 245  Training loss = 2.1791  Validation loss = 9.1859  \n",
      "\n",
      "Fold: 9  Epoch: 246  Training loss = 2.1788  Validation loss = 9.1846  \n",
      "\n",
      "Fold: 9  Epoch: 247  Training loss = 2.1785  Validation loss = 9.1832  \n",
      "\n",
      "Fold: 9  Epoch: 248  Training loss = 2.1784  Validation loss = 9.1825  \n",
      "\n",
      "Fold: 9  Epoch: 249  Training loss = 2.1782  Validation loss = 9.1814  \n",
      "\n",
      "Fold: 9  Epoch: 250  Training loss = 2.1780  Validation loss = 9.1804  \n",
      "\n",
      "Fold: 9  Epoch: 251  Training loss = 2.1779  Validation loss = 9.1803  \n",
      "\n",
      "Fold: 9  Epoch: 252  Training loss = 2.1778  Validation loss = 9.1799  \n",
      "\n",
      "Fold: 9  Epoch: 253  Training loss = 2.1777  Validation loss = 9.1796  \n",
      "\n",
      "Fold: 9  Epoch: 254  Training loss = 2.1776  Validation loss = 9.1790  \n",
      "\n",
      "Fold: 9  Epoch: 255  Training loss = 2.1774  Validation loss = 9.1781  \n",
      "\n",
      "Fold: 9  Epoch: 256  Training loss = 2.1771  Validation loss = 9.1770  \n",
      "\n",
      "Fold: 9  Epoch: 257  Training loss = 2.1769  Validation loss = 9.1761  \n",
      "\n",
      "Fold: 9  Epoch: 258  Training loss = 2.1767  Validation loss = 9.1749  \n",
      "\n",
      "Fold: 9  Epoch: 259  Training loss = 2.1765  Validation loss = 9.1739  \n",
      "\n",
      "Fold: 9  Epoch: 260  Training loss = 2.1763  Validation loss = 9.1731  \n",
      "\n",
      "Fold: 9  Epoch: 261  Training loss = 2.1761  Validation loss = 9.1721  \n",
      "\n",
      "Fold: 9  Epoch: 262  Training loss = 2.1760  Validation loss = 9.1718  \n",
      "\n",
      "Fold: 9  Epoch: 263  Training loss = 2.1759  Validation loss = 9.1709  \n",
      "\n",
      "Fold: 9  Epoch: 264  Training loss = 2.1757  Validation loss = 9.1706  \n",
      "\n",
      "Fold: 9  Epoch: 265  Training loss = 2.1756  Validation loss = 9.1698  \n",
      "\n",
      "Fold: 9  Epoch: 266  Training loss = 2.1755  Validation loss = 9.1695  \n",
      "\n",
      "Fold: 9  Epoch: 267  Training loss = 2.1752  Validation loss = 9.1683  \n",
      "\n",
      "Fold: 9  Epoch: 268  Training loss = 2.1750  Validation loss = 9.1670  \n",
      "\n",
      "Fold: 9  Epoch: 269  Training loss = 2.1748  Validation loss = 9.1660  \n",
      "\n",
      "Fold: 9  Epoch: 270  Training loss = 2.1747  Validation loss = 9.1657  \n",
      "\n",
      "Fold: 9  Epoch: 271  Training loss = 2.1744  Validation loss = 9.1638  \n",
      "\n",
      "Fold: 9  Epoch: 272  Training loss = 2.1742  Validation loss = 9.1634  \n",
      "\n",
      "Fold: 9  Epoch: 273  Training loss = 2.1740  Validation loss = 9.1622  \n",
      "\n",
      "Fold: 9  Epoch: 274  Training loss = 2.1740  Validation loss = 9.1620  \n",
      "\n",
      "Fold: 9  Epoch: 275  Training loss = 2.1739  Validation loss = 9.1615  \n",
      "\n",
      "Fold: 9  Epoch: 276  Training loss = 2.1737  Validation loss = 9.1608  \n",
      "\n",
      "Fold: 9  Epoch: 277  Training loss = 2.1736  Validation loss = 9.1608  \n",
      "\n",
      "Fold: 9  Epoch: 278  Training loss = 2.1735  Validation loss = 9.1601  \n",
      "\n",
      "Fold: 9  Epoch: 279  Training loss = 2.1733  Validation loss = 9.1594  \n",
      "\n",
      "Fold: 9  Epoch: 280  Training loss = 2.1733  Validation loss = 9.1591  \n",
      "\n",
      "Fold: 9  Epoch: 281  Training loss = 2.1732  Validation loss = 9.1592  \n",
      "\n",
      "Fold: 9  Epoch: 282  Training loss = 2.1731  Validation loss = 9.1586  \n",
      "\n",
      "Fold: 9  Epoch: 283  Training loss = 2.1730  Validation loss = 9.1583  \n",
      "\n",
      "Fold: 9  Epoch: 284  Training loss = 2.1729  Validation loss = 9.1580  \n",
      "\n",
      "Fold: 9  Epoch: 285  Training loss = 2.1729  Validation loss = 9.1576  \n",
      "\n",
      "Fold: 9  Epoch: 286  Training loss = 2.1727  Validation loss = 9.1566  \n",
      "\n",
      "Fold: 9  Epoch: 287  Training loss = 2.1725  Validation loss = 9.1554  \n",
      "\n",
      "Fold: 9  Epoch: 288  Training loss = 2.1723  Validation loss = 9.1548  \n",
      "\n",
      "Fold: 9  Epoch: 289  Training loss = 2.1722  Validation loss = 9.1543  \n",
      "\n",
      "Fold: 9  Epoch: 290  Training loss = 2.1721  Validation loss = 9.1541  \n",
      "\n",
      "Fold: 9  Epoch: 291  Training loss = 2.1720  Validation loss = 9.1531  \n",
      "\n",
      "Fold: 9  Epoch: 292  Training loss = 2.1717  Validation loss = 9.1520  \n",
      "\n",
      "Fold: 9  Epoch: 293  Training loss = 2.1716  Validation loss = 9.1514  \n",
      "\n",
      "Fold: 9  Epoch: 294  Training loss = 2.1715  Validation loss = 9.1513  \n",
      "\n",
      "Fold: 9  Epoch: 295  Training loss = 2.1714  Validation loss = 9.1510  \n",
      "\n",
      "Fold: 9  Epoch: 296  Training loss = 2.1713  Validation loss = 9.1504  \n",
      "\n",
      "Fold: 9  Epoch: 297  Training loss = 2.1711  Validation loss = 9.1493  \n",
      "\n",
      "Fold: 9  Epoch: 298  Training loss = 2.1710  Validation loss = 9.1494  \n",
      "\n",
      "Fold: 9  Epoch: 299  Training loss = 2.1709  Validation loss = 9.1490  \n",
      "\n",
      "Fold: 9  Epoch: 300  Training loss = 2.1708  Validation loss = 9.1488  \n",
      "\n",
      "Fold: 9  Epoch: 301  Training loss = 2.1705  Validation loss = 9.1471  \n",
      "\n",
      "Fold: 9  Epoch: 302  Training loss = 2.1704  Validation loss = 9.1463  \n",
      "\n",
      "Fold: 9  Epoch: 303  Training loss = 2.1702  Validation loss = 9.1453  \n",
      "\n",
      "Fold: 9  Epoch: 304  Training loss = 2.1701  Validation loss = 9.1451  \n",
      "\n",
      "Fold: 9  Epoch: 305  Training loss = 2.1701  Validation loss = 9.1451  \n",
      "\n",
      "Fold: 9  Epoch: 306  Training loss = 2.1701  Validation loss = 9.1459  \n",
      "\n",
      "Fold: 9  Epoch: 307  Training loss = 2.1699  Validation loss = 9.1451  \n",
      "\n",
      "Fold: 9  Epoch: 308  Training loss = 2.1698  Validation loss = 9.1443  \n",
      "\n",
      "Fold: 9  Epoch: 309  Training loss = 2.1697  Validation loss = 9.1440  \n",
      "\n",
      "Fold: 9  Epoch: 310  Training loss = 2.1695  Validation loss = 9.1434  \n",
      "\n",
      "Fold: 9  Epoch: 311  Training loss = 2.1693  Validation loss = 9.1422  \n",
      "\n",
      "Fold: 9  Epoch: 312  Training loss = 2.1692  Validation loss = 9.1414  \n",
      "\n",
      "Fold: 9  Epoch: 313  Training loss = 2.1690  Validation loss = 9.1407  \n",
      "\n",
      "Fold: 9  Epoch: 314  Training loss = 2.1690  Validation loss = 9.1406  \n",
      "\n",
      "Fold: 9  Epoch: 315  Training loss = 2.1687  Validation loss = 9.1394  \n",
      "\n",
      "Fold: 9  Epoch: 316  Training loss = 2.1686  Validation loss = 9.1388  \n",
      "\n",
      "Fold: 9  Epoch: 317  Training loss = 2.1684  Validation loss = 9.1370  \n",
      "\n",
      "Fold: 9  Epoch: 318  Training loss = 2.1683  Validation loss = 9.1370  \n",
      "\n",
      "Fold: 9  Epoch: 319  Training loss = 2.1682  Validation loss = 9.1365  \n",
      "\n",
      "Fold: 9  Epoch: 320  Training loss = 2.1680  Validation loss = 9.1356  \n",
      "\n",
      "Fold: 9  Epoch: 321  Training loss = 2.1679  Validation loss = 9.1350  \n",
      "\n",
      "Fold: 9  Epoch: 322  Training loss = 2.1678  Validation loss = 9.1350  \n",
      "\n",
      "Fold: 9  Epoch: 323  Training loss = 2.1676  Validation loss = 9.1339  \n",
      "\n",
      "Fold: 9  Epoch: 324  Training loss = 2.1674  Validation loss = 9.1326  \n",
      "\n",
      "Fold: 9  Epoch: 325  Training loss = 2.1672  Validation loss = 9.1316  \n",
      "\n",
      "Fold: 9  Epoch: 326  Training loss = 2.1670  Validation loss = 9.1302  \n",
      "\n",
      "Fold: 9  Epoch: 327  Training loss = 2.1669  Validation loss = 9.1296  \n",
      "\n",
      "Fold: 9  Epoch: 328  Training loss = 2.1667  Validation loss = 9.1287  \n",
      "\n",
      "Fold: 9  Epoch: 329  Training loss = 2.1666  Validation loss = 9.1275  \n",
      "\n",
      "Fold: 9  Epoch: 330  Training loss = 2.1664  Validation loss = 9.1266  \n",
      "\n",
      "Fold: 9  Epoch: 331  Training loss = 2.1663  Validation loss = 9.1260  \n",
      "\n",
      "Fold: 9  Epoch: 332  Training loss = 2.1663  Validation loss = 9.1263  \n",
      "\n",
      "Fold: 9  Epoch: 333  Training loss = 2.1663  Validation loss = 9.1268  \n",
      "\n",
      "Fold: 9  Epoch: 334  Training loss = 2.1661  Validation loss = 9.1258  \n",
      "\n",
      "Fold: 9  Epoch: 335  Training loss = 2.1659  Validation loss = 9.1250  \n",
      "\n",
      "Fold: 9  Epoch: 336  Training loss = 2.1657  Validation loss = 9.1239  \n",
      "\n",
      "Fold: 9  Epoch: 337  Training loss = 2.1656  Validation loss = 9.1233  \n",
      "\n",
      "Fold: 9  Epoch: 338  Training loss = 2.1655  Validation loss = 9.1231  \n",
      "\n",
      "Fold: 9  Epoch: 339  Training loss = 2.1654  Validation loss = 9.1225  \n",
      "\n",
      "Fold: 9  Epoch: 340  Training loss = 2.1652  Validation loss = 9.1214  \n",
      "\n",
      "Fold: 9  Epoch: 341  Training loss = 2.1650  Validation loss = 9.1209  \n",
      "\n",
      "Fold: 9  Epoch: 342  Training loss = 2.1651  Validation loss = 9.1216  \n",
      "\n",
      "Fold: 9  Epoch: 343  Training loss = 2.1650  Validation loss = 9.1213  \n",
      "\n",
      "Fold: 9  Epoch: 344  Training loss = 2.1648  Validation loss = 9.1203  \n",
      "\n",
      "Fold: 9  Epoch: 345  Training loss = 2.1647  Validation loss = 9.1197  \n",
      "\n",
      "Fold: 9  Epoch: 346  Training loss = 2.1645  Validation loss = 9.1188  \n",
      "\n",
      "Fold: 9  Epoch: 347  Training loss = 2.1643  Validation loss = 9.1175  \n",
      "\n",
      "Fold: 9  Epoch: 348  Training loss = 2.1642  Validation loss = 9.1168  \n",
      "\n",
      "Fold: 9  Epoch: 349  Training loss = 2.1640  Validation loss = 9.1157  \n",
      "\n",
      "Fold: 9  Epoch: 350  Training loss = 2.1638  Validation loss = 9.1148  \n",
      "\n",
      "Fold: 9  Epoch: 351  Training loss = 2.1637  Validation loss = 9.1139  \n",
      "\n",
      "Fold: 9  Epoch: 352  Training loss = 2.1636  Validation loss = 9.1141  \n",
      "\n",
      "Fold: 9  Epoch: 353  Training loss = 2.1634  Validation loss = 9.1132  \n",
      "\n",
      "Fold: 9  Epoch: 354  Training loss = 2.1633  Validation loss = 9.1124  \n",
      "\n",
      "Fold: 9  Epoch: 355  Training loss = 2.1631  Validation loss = 9.1118  \n",
      "\n",
      "Fold: 9  Epoch: 356  Training loss = 2.1630  Validation loss = 9.1109  \n",
      "\n",
      "Fold: 9  Epoch: 357  Training loss = 2.1629  Validation loss = 9.1106  \n",
      "\n",
      "Fold: 9  Epoch: 358  Training loss = 2.1627  Validation loss = 9.1101  \n",
      "\n",
      "Fold: 9  Epoch: 359  Training loss = 2.1626  Validation loss = 9.1093  \n",
      "\n",
      "Fold: 9  Epoch: 360  Training loss = 2.1625  Validation loss = 9.1091  \n",
      "\n",
      "Fold: 9  Epoch: 361  Training loss = 2.1624  Validation loss = 9.1085  \n",
      "\n",
      "Fold: 9  Epoch: 362  Training loss = 2.1623  Validation loss = 9.1083  \n",
      "\n",
      "Fold: 9  Epoch: 363  Training loss = 2.1621  Validation loss = 9.1071  \n",
      "\n",
      "Fold: 9  Epoch: 364  Training loss = 2.1619  Validation loss = 9.1059  \n",
      "\n",
      "Fold: 9  Epoch: 365  Training loss = 2.1617  Validation loss = 9.1048  \n",
      "\n",
      "Fold: 9  Epoch: 366  Training loss = 2.1616  Validation loss = 9.1042  \n",
      "\n",
      "Fold: 9  Epoch: 367  Training loss = 2.1616  Validation loss = 9.1045  \n",
      "\n",
      "Fold: 9  Epoch: 368  Training loss = 2.1615  Validation loss = 9.1038  \n",
      "\n",
      "Fold: 9  Epoch: 369  Training loss = 2.1614  Validation loss = 9.1041  \n",
      "\n",
      "Fold: 9  Epoch: 370  Training loss = 2.1613  Validation loss = 9.1029  \n",
      "\n",
      "Fold: 9  Epoch: 371  Training loss = 2.1611  Validation loss = 9.1020  \n",
      "\n",
      "Fold: 9  Epoch: 372  Training loss = 2.1611  Validation loss = 9.1019  \n",
      "\n",
      "Fold: 9  Epoch: 373  Training loss = 2.1609  Validation loss = 9.1013  \n",
      "\n",
      "Fold: 9  Epoch: 374  Training loss = 2.1608  Validation loss = 9.1009  \n",
      "\n",
      "Fold: 9  Epoch: 375  Training loss = 2.1607  Validation loss = 9.1004  \n",
      "\n",
      "Fold: 9  Epoch: 376  Training loss = 2.1606  Validation loss = 9.1001  \n",
      "\n",
      "Fold: 9  Epoch: 377  Training loss = 2.1605  Validation loss = 9.0996  \n",
      "\n",
      "Fold: 9  Epoch: 378  Training loss = 2.1605  Validation loss = 9.1002  \n",
      "\n",
      "Fold: 9  Epoch: 379  Training loss = 2.1604  Validation loss = 9.0995  \n",
      "\n",
      "Fold: 9  Epoch: 380  Training loss = 2.1603  Validation loss = 9.0990  \n",
      "\n",
      "Fold: 9  Epoch: 381  Training loss = 2.1601  Validation loss = 9.0983  \n",
      "\n",
      "Fold: 9  Epoch: 382  Training loss = 2.1600  Validation loss = 9.0977  \n",
      "\n",
      "Fold: 9  Epoch: 383  Training loss = 2.1598  Validation loss = 9.0966  \n",
      "\n",
      "Fold: 9  Epoch: 384  Training loss = 2.1597  Validation loss = 9.0959  \n",
      "\n",
      "Fold: 9  Epoch: 385  Training loss = 2.1596  Validation loss = 9.0953  \n",
      "\n",
      "Fold: 9  Epoch: 386  Training loss = 2.1595  Validation loss = 9.0951  \n",
      "\n",
      "Fold: 9  Epoch: 387  Training loss = 2.1593  Validation loss = 9.0941  \n",
      "\n",
      "Fold: 9  Epoch: 388  Training loss = 2.1593  Validation loss = 9.0944  \n",
      "\n",
      "Fold: 9  Epoch: 389  Training loss = 2.1592  Validation loss = 9.0938  \n",
      "\n",
      "Fold: 9  Epoch: 390  Training loss = 2.1591  Validation loss = 9.0930  \n",
      "\n",
      "Fold: 9  Epoch: 391  Training loss = 2.1589  Validation loss = 9.0923  \n",
      "\n",
      "Fold: 9  Epoch: 392  Training loss = 2.1588  Validation loss = 9.0915  \n",
      "\n",
      "Fold: 9  Epoch: 393  Training loss = 2.1588  Validation loss = 9.0923  \n",
      "\n",
      "Fold: 9  Epoch: 394  Training loss = 2.1587  Validation loss = 9.0917  \n",
      "\n",
      "Fold: 9  Epoch: 395  Training loss = 2.1585  Validation loss = 9.0905  \n",
      "\n",
      "Fold: 9  Epoch: 396  Training loss = 2.1584  Validation loss = 9.0901  \n",
      "\n",
      "Fold: 9  Epoch: 397  Training loss = 2.1582  Validation loss = 9.0891  \n",
      "\n",
      "Fold: 9  Epoch: 398  Training loss = 2.1580  Validation loss = 9.0884  \n",
      "\n",
      "Fold: 9  Epoch: 399  Training loss = 2.1579  Validation loss = 9.0879  \n",
      "\n",
      "Fold: 9  Epoch: 400  Training loss = 2.1578  Validation loss = 9.0878  \n",
      "\n",
      "Fold: 9  Epoch: 401  Training loss = 2.1576  Validation loss = 9.0868  \n",
      "\n",
      "Fold: 9  Epoch: 402  Training loss = 2.1575  Validation loss = 9.0865  \n",
      "\n",
      "Fold: 9  Epoch: 403  Training loss = 2.1573  Validation loss = 9.0849  \n",
      "\n",
      "Fold: 9  Epoch: 404  Training loss = 2.1572  Validation loss = 9.0839  \n",
      "\n",
      "Fold: 9  Epoch: 405  Training loss = 2.1571  Validation loss = 9.0840  \n",
      "\n",
      "Fold: 9  Epoch: 406  Training loss = 2.1570  Validation loss = 9.0831  \n",
      "\n",
      "Fold: 9  Epoch: 407  Training loss = 2.1569  Validation loss = 9.0834  \n",
      "\n",
      "Fold: 9  Epoch: 408  Training loss = 2.1568  Validation loss = 9.0824  \n",
      "\n",
      "Fold: 9  Epoch: 409  Training loss = 2.1566  Validation loss = 9.0814  \n",
      "\n",
      "Fold: 9  Epoch: 410  Training loss = 2.1565  Validation loss = 9.0807  \n",
      "\n",
      "Fold: 9  Epoch: 411  Training loss = 2.1564  Validation loss = 9.0809  \n",
      "\n",
      "Fold: 9  Epoch: 412  Training loss = 2.1563  Validation loss = 9.0805  \n",
      "\n",
      "Fold: 9  Epoch: 413  Training loss = 2.1562  Validation loss = 9.0799  \n",
      "\n",
      "Fold: 9  Epoch: 414  Training loss = 2.1560  Validation loss = 9.0790  \n",
      "\n",
      "Fold: 9  Epoch: 415  Training loss = 2.1560  Validation loss = 9.0791  \n",
      "\n",
      "Fold: 9  Epoch: 416  Training loss = 2.1559  Validation loss = 9.0787  \n",
      "\n",
      "Fold: 9  Epoch: 417  Training loss = 2.1557  Validation loss = 9.0772  \n",
      "\n",
      "Fold: 9  Epoch: 418  Training loss = 2.1556  Validation loss = 9.0769  \n",
      "\n",
      "Fold: 9  Epoch: 419  Training loss = 2.1555  Validation loss = 9.0763  \n",
      "\n",
      "Fold: 9  Epoch: 420  Training loss = 2.1554  Validation loss = 9.0763  \n",
      "\n",
      "Fold: 9  Epoch: 421  Training loss = 2.1552  Validation loss = 9.0753  \n",
      "\n",
      "Fold: 9  Epoch: 422  Training loss = 2.1551  Validation loss = 9.0740  \n",
      "\n",
      "Fold: 9  Epoch: 423  Training loss = 2.1549  Validation loss = 9.0732  \n",
      "\n",
      "Fold: 9  Epoch: 424  Training loss = 2.1549  Validation loss = 9.0737  \n",
      "\n",
      "Fold: 9  Epoch: 425  Training loss = 2.1546  Validation loss = 9.0722  \n",
      "\n",
      "Fold: 9  Epoch: 426  Training loss = 2.1545  Validation loss = 9.0716  \n",
      "\n",
      "Fold: 9  Epoch: 427  Training loss = 2.1544  Validation loss = 9.0714  \n",
      "\n",
      "Fold: 9  Epoch: 428  Training loss = 2.1542  Validation loss = 9.0696  \n",
      "\n",
      "Fold: 9  Epoch: 429  Training loss = 2.1541  Validation loss = 9.0691  \n",
      "\n",
      "Fold: 9  Epoch: 430  Training loss = 2.1539  Validation loss = 9.0678  \n",
      "\n",
      "Fold: 9  Epoch: 431  Training loss = 2.1538  Validation loss = 9.0674  \n",
      "\n",
      "Fold: 9  Epoch: 432  Training loss = 2.1536  Validation loss = 9.0661  \n",
      "\n",
      "Fold: 9  Epoch: 433  Training loss = 2.1535  Validation loss = 9.0653  \n",
      "\n",
      "Fold: 9  Epoch: 434  Training loss = 2.1533  Validation loss = 9.0644  \n",
      "\n",
      "Fold: 9  Epoch: 435  Training loss = 2.1532  Validation loss = 9.0639  \n",
      "\n",
      "Fold: 9  Epoch: 436  Training loss = 2.1532  Validation loss = 9.0649  \n",
      "\n",
      "Fold: 9  Epoch: 437  Training loss = 2.1531  Validation loss = 9.0648  \n",
      "\n",
      "Fold: 9  Epoch: 438  Training loss = 2.1530  Validation loss = 9.0637  \n",
      "\n",
      "Fold: 9  Epoch: 439  Training loss = 2.1529  Validation loss = 9.0637  \n",
      "\n",
      "Fold: 9  Epoch: 440  Training loss = 2.1529  Validation loss = 9.0640  \n",
      "\n",
      "Fold: 9  Epoch: 441  Training loss = 2.1527  Validation loss = 9.0625  \n",
      "\n",
      "Fold: 9  Epoch: 442  Training loss = 2.1525  Validation loss = 9.0622  \n",
      "\n",
      "Fold: 9  Epoch: 443  Training loss = 2.1524  Validation loss = 9.0616  \n",
      "\n",
      "Fold: 9  Epoch: 444  Training loss = 2.1523  Validation loss = 9.0612  \n",
      "\n",
      "Fold: 9  Epoch: 445  Training loss = 2.1521  Validation loss = 9.0600  \n",
      "\n",
      "Fold: 9  Epoch: 446  Training loss = 2.1520  Validation loss = 9.0594  \n",
      "\n",
      "Fold: 9  Epoch: 447  Training loss = 2.1519  Validation loss = 9.0587  \n",
      "\n",
      "Fold: 9  Epoch: 448  Training loss = 2.1518  Validation loss = 9.0581  \n",
      "\n",
      "Fold: 9  Epoch: 449  Training loss = 2.1516  Validation loss = 9.0574  \n",
      "\n",
      "Fold: 9  Epoch: 450  Training loss = 2.1516  Validation loss = 9.0576  \n",
      "\n",
      "Fold: 9  Epoch: 451  Training loss = 2.1515  Validation loss = 9.0569  \n",
      "\n",
      "Fold: 9  Epoch: 452  Training loss = 2.1513  Validation loss = 9.0559  \n",
      "\n",
      "Fold: 9  Epoch: 453  Training loss = 2.1513  Validation loss = 9.0564  \n",
      "\n",
      "Fold: 9  Epoch: 454  Training loss = 2.1511  Validation loss = 9.0557  \n",
      "\n",
      "Fold: 9  Epoch: 455  Training loss = 2.1510  Validation loss = 9.0542  \n",
      "\n",
      "Fold: 9  Epoch: 456  Training loss = 2.1509  Validation loss = 9.0544  \n",
      "\n",
      "Fold: 9  Epoch: 457  Training loss = 2.1508  Validation loss = 9.0544  \n",
      "\n",
      "Fold: 9  Epoch: 458  Training loss = 2.1506  Validation loss = 9.0532  \n",
      "\n",
      "Fold: 9  Epoch: 459  Training loss = 2.1505  Validation loss = 9.0520  \n",
      "\n",
      "Fold: 9  Epoch: 460  Training loss = 2.1504  Validation loss = 9.0517  \n",
      "\n",
      "Fold: 9  Epoch: 461  Training loss = 2.1502  Validation loss = 9.0502  \n",
      "\n",
      "Fold: 9  Epoch: 462  Training loss = 2.1501  Validation loss = 9.0499  \n",
      "\n",
      "Fold: 9  Epoch: 463  Training loss = 2.1501  Validation loss = 9.0497  \n",
      "\n",
      "Fold: 9  Epoch: 464  Training loss = 2.1500  Validation loss = 9.0496  \n",
      "\n",
      "Fold: 9  Epoch: 465  Training loss = 2.1499  Validation loss = 9.0493  \n",
      "\n",
      "Fold: 9  Epoch: 466  Training loss = 2.1499  Validation loss = 9.0504  \n",
      "\n",
      "Fold: 9  Epoch: 467  Training loss = 2.1499  Validation loss = 9.0503  \n",
      "\n",
      "Fold: 9  Epoch: 468  Training loss = 2.1498  Validation loss = 9.0504  \n",
      "\n",
      "Fold: 9  Epoch: 469  Training loss = 2.1497  Validation loss = 9.0502  \n",
      "\n",
      "Fold: 9  Epoch: 470  Training loss = 2.1496  Validation loss = 9.0495  \n",
      "\n",
      "Fold: 9  Epoch: 471  Training loss = 2.1495  Validation loss = 9.0489  \n",
      "\n",
      "Fold: 9  Epoch: 472  Training loss = 2.1494  Validation loss = 9.0482  \n",
      "\n",
      "Fold: 9  Epoch: 473  Training loss = 2.1493  Validation loss = 9.0479  \n",
      "\n",
      "Fold: 9  Epoch: 474  Training loss = 2.1492  Validation loss = 9.0480  \n",
      "\n",
      "Fold: 9  Epoch: 475  Training loss = 2.1491  Validation loss = 9.0471  \n",
      "\n",
      "Fold: 9  Epoch: 476  Training loss = 2.1489  Validation loss = 9.0460  \n",
      "\n",
      "Fold: 9  Epoch: 477  Training loss = 2.1488  Validation loss = 9.0455  \n",
      "\n",
      "Fold: 9  Epoch: 478  Training loss = 2.1486  Validation loss = 9.0444  \n",
      "\n",
      "Fold: 9  Epoch: 479  Training loss = 2.1485  Validation loss = 9.0440  \n",
      "\n",
      "Fold: 9  Epoch: 480  Training loss = 2.1484  Validation loss = 9.0443  \n",
      "\n",
      "Fold: 9  Epoch: 481  Training loss = 2.1483  Validation loss = 9.0439  \n",
      "\n",
      "Fold: 9  Epoch: 482  Training loss = 2.1482  Validation loss = 9.0431  \n",
      "\n",
      "Fold: 9  Epoch: 483  Training loss = 2.1481  Validation loss = 9.0426  \n",
      "\n",
      "Fold: 9  Epoch: 484  Training loss = 2.1480  Validation loss = 9.0428  \n",
      "\n",
      "Fold: 9  Epoch: 485  Training loss = 2.1478  Validation loss = 9.0414  \n",
      "\n",
      "Fold: 9  Epoch: 486  Training loss = 2.1477  Validation loss = 9.0406  \n",
      "\n",
      "Fold: 9  Epoch: 487  Training loss = 2.1476  Validation loss = 9.0404  \n",
      "\n",
      "Fold: 9  Epoch: 488  Training loss = 2.1476  Validation loss = 9.0406  \n",
      "\n",
      "Fold: 9  Epoch: 489  Training loss = 2.1475  Validation loss = 9.0402  \n",
      "\n",
      "Fold: 9  Epoch: 490  Training loss = 2.1474  Validation loss = 9.0398  \n",
      "\n",
      "Fold: 9  Epoch: 491  Training loss = 2.1472  Validation loss = 9.0392  \n",
      "\n",
      "Fold: 9  Epoch: 492  Training loss = 2.1472  Validation loss = 9.0392  \n",
      "\n",
      "Fold: 9  Epoch: 493  Training loss = 2.1471  Validation loss = 9.0387  \n",
      "\n",
      "Fold: 9  Epoch: 494  Training loss = 2.1468  Validation loss = 9.0368  \n",
      "\n",
      "Fold: 9  Epoch: 495  Training loss = 2.1468  Validation loss = 9.0370  \n",
      "\n",
      "Fold: 9  Epoch: 496  Training loss = 2.1467  Validation loss = 9.0365  \n",
      "\n",
      "Fold: 9  Epoch: 497  Training loss = 2.1466  Validation loss = 9.0366  \n",
      "\n",
      "Fold: 9  Epoch: 498  Training loss = 2.1464  Validation loss = 9.0352  \n",
      "\n",
      "Fold: 9  Epoch: 499  Training loss = 2.1462  Validation loss = 9.0342  \n",
      "\n",
      "Fold: 9  Epoch: 500  Training loss = 2.1461  Validation loss = 9.0336  \n",
      "\n",
      "Check model:  Fold: 9  Optimal epoch: 500  \n",
      "\n",
      "Fold: 10  Epoch: 1  Training loss = 3.0745  Validation loss = 5.4367  \n",
      "\n",
      "Fold: 10  Epoch: 2  Training loss = 3.0740  Validation loss = 5.4344  \n",
      "\n",
      "Fold: 10  Epoch: 3  Training loss = 3.0734  Validation loss = 5.4323  \n",
      "\n",
      "Fold: 10  Epoch: 4  Training loss = 3.0727  Validation loss = 5.4302  \n",
      "\n",
      "Fold: 10  Epoch: 5  Training loss = 3.0722  Validation loss = 5.4281  \n",
      "\n",
      "Fold: 10  Epoch: 6  Training loss = 3.0718  Validation loss = 5.4266  \n",
      "\n",
      "Fold: 10  Epoch: 7  Training loss = 3.0711  Validation loss = 5.4247  \n",
      "\n",
      "Fold: 10  Epoch: 8  Training loss = 3.0709  Validation loss = 5.4247  \n",
      "\n",
      "Fold: 10  Epoch: 9  Training loss = 3.0703  Validation loss = 5.4224  \n",
      "\n",
      "Fold: 10  Epoch: 10  Training loss = 3.0699  Validation loss = 5.4213  \n",
      "\n",
      "Fold: 10  Epoch: 11  Training loss = 3.0694  Validation loss = 5.4185  \n",
      "\n",
      "Fold: 10  Epoch: 12  Training loss = 3.0688  Validation loss = 5.4159  \n",
      "\n",
      "Fold: 10  Epoch: 13  Training loss = 3.0684  Validation loss = 5.4160  \n",
      "\n",
      "Fold: 10  Epoch: 14  Training loss = 3.0678  Validation loss = 5.4147  \n",
      "\n",
      "Fold: 10  Epoch: 15  Training loss = 3.0674  Validation loss = 5.4137  \n",
      "\n",
      "Fold: 10  Epoch: 16  Training loss = 3.0670  Validation loss = 5.4124  \n",
      "\n",
      "Fold: 10  Epoch: 17  Training loss = 3.0667  Validation loss = 5.4110  \n",
      "\n",
      "Fold: 10  Epoch: 18  Training loss = 3.0661  Validation loss = 5.4083  \n",
      "\n",
      "Fold: 10  Epoch: 19  Training loss = 3.0657  Validation loss = 5.4077  \n",
      "\n",
      "Fold: 10  Epoch: 20  Training loss = 3.0654  Validation loss = 5.4062  \n",
      "\n",
      "Fold: 10  Epoch: 21  Training loss = 3.0648  Validation loss = 5.4054  \n",
      "\n",
      "Fold: 10  Epoch: 22  Training loss = 3.0644  Validation loss = 5.4035  \n",
      "\n",
      "Fold: 10  Epoch: 23  Training loss = 3.0637  Validation loss = 5.4010  \n",
      "\n",
      "Fold: 10  Epoch: 24  Training loss = 3.0629  Validation loss = 5.3973  \n",
      "\n",
      "Fold: 10  Epoch: 25  Training loss = 3.0624  Validation loss = 5.3952  \n",
      "\n",
      "Fold: 10  Epoch: 26  Training loss = 3.0621  Validation loss = 5.3946  \n",
      "\n",
      "Fold: 10  Epoch: 27  Training loss = 3.0613  Validation loss = 5.3919  \n",
      "\n",
      "Fold: 10  Epoch: 28  Training loss = 3.0609  Validation loss = 5.3910  \n",
      "\n",
      "Fold: 10  Epoch: 29  Training loss = 3.0603  Validation loss = 5.3885  \n",
      "\n",
      "Fold: 10  Epoch: 30  Training loss = 3.0601  Validation loss = 5.3865  \n",
      "\n",
      "Fold: 10  Epoch: 31  Training loss = 3.0598  Validation loss = 5.3855  \n",
      "\n",
      "Fold: 10  Epoch: 32  Training loss = 3.0591  Validation loss = 5.3831  \n",
      "\n",
      "Fold: 10  Epoch: 33  Training loss = 3.0587  Validation loss = 5.3805  \n",
      "\n",
      "Fold: 10  Epoch: 34  Training loss = 3.0580  Validation loss = 5.3775  \n",
      "\n",
      "Fold: 10  Epoch: 35  Training loss = 3.0575  Validation loss = 5.3745  \n",
      "\n",
      "Fold: 10  Epoch: 36  Training loss = 3.0567  Validation loss = 5.3718  \n",
      "\n",
      "Fold: 10  Epoch: 37  Training loss = 3.0564  Validation loss = 5.3699  \n",
      "\n",
      "Fold: 10  Epoch: 38  Training loss = 3.0558  Validation loss = 5.3680  \n",
      "\n",
      "Fold: 10  Epoch: 39  Training loss = 3.0555  Validation loss = 5.3659  \n",
      "\n",
      "Fold: 10  Epoch: 40  Training loss = 3.0555  Validation loss = 5.3658  \n",
      "\n",
      "Fold: 10  Epoch: 41  Training loss = 3.0552  Validation loss = 5.3643  \n",
      "\n",
      "Fold: 10  Epoch: 42  Training loss = 3.0547  Validation loss = 5.3622  \n",
      "\n",
      "Fold: 10  Epoch: 43  Training loss = 3.0544  Validation loss = 5.3600  \n",
      "\n",
      "Fold: 10  Epoch: 44  Training loss = 3.0537  Validation loss = 5.3588  \n",
      "\n",
      "Fold: 10  Epoch: 45  Training loss = 3.0531  Validation loss = 5.3573  \n",
      "\n",
      "Fold: 10  Epoch: 46  Training loss = 3.0528  Validation loss = 5.3571  \n",
      "\n",
      "Fold: 10  Epoch: 47  Training loss = 3.0523  Validation loss = 5.3551  \n",
      "\n",
      "Fold: 10  Epoch: 48  Training loss = 3.0518  Validation loss = 5.3539  \n",
      "\n",
      "Fold: 10  Epoch: 49  Training loss = 3.0514  Validation loss = 5.3520  \n",
      "\n",
      "Fold: 10  Epoch: 50  Training loss = 3.0509  Validation loss = 5.3508  \n",
      "\n",
      "Fold: 10  Epoch: 51  Training loss = 3.0505  Validation loss = 5.3493  \n",
      "\n",
      "Fold: 10  Epoch: 52  Training loss = 3.0504  Validation loss = 5.3491  \n",
      "\n",
      "Fold: 10  Epoch: 53  Training loss = 3.0498  Validation loss = 5.3476  \n",
      "\n",
      "Fold: 10  Epoch: 54  Training loss = 3.0491  Validation loss = 5.3447  \n",
      "\n",
      "Fold: 10  Epoch: 55  Training loss = 3.0484  Validation loss = 5.3431  \n",
      "\n",
      "Fold: 10  Epoch: 56  Training loss = 3.0478  Validation loss = 5.3413  \n",
      "\n",
      "Fold: 10  Epoch: 57  Training loss = 3.0470  Validation loss = 5.3385  \n",
      "\n",
      "Fold: 10  Epoch: 58  Training loss = 3.0465  Validation loss = 5.3364  \n",
      "\n",
      "Fold: 10  Epoch: 59  Training loss = 3.0461  Validation loss = 5.3358  \n",
      "\n",
      "Fold: 10  Epoch: 60  Training loss = 3.0457  Validation loss = 5.3342  \n",
      "\n",
      "Fold: 10  Epoch: 61  Training loss = 3.0451  Validation loss = 5.3318  \n",
      "\n",
      "Fold: 10  Epoch: 62  Training loss = 3.0444  Validation loss = 5.3293  \n",
      "\n",
      "Fold: 10  Epoch: 63  Training loss = 3.0441  Validation loss = 5.3270  \n",
      "\n",
      "Fold: 10  Epoch: 64  Training loss = 3.0436  Validation loss = 5.3252  \n",
      "\n",
      "Fold: 10  Epoch: 65  Training loss = 3.0434  Validation loss = 5.3240  \n",
      "\n",
      "Fold: 10  Epoch: 66  Training loss = 3.0429  Validation loss = 5.3220  \n",
      "\n",
      "Fold: 10  Epoch: 67  Training loss = 3.0428  Validation loss = 5.3222  \n",
      "\n",
      "Fold: 10  Epoch: 68  Training loss = 3.0424  Validation loss = 5.3207  \n",
      "\n",
      "Fold: 10  Epoch: 69  Training loss = 3.0422  Validation loss = 5.3199  \n",
      "\n",
      "Fold: 10  Epoch: 70  Training loss = 3.0417  Validation loss = 5.3194  \n",
      "\n",
      "Fold: 10  Epoch: 71  Training loss = 3.0410  Validation loss = 5.3181  \n",
      "\n",
      "Fold: 10  Epoch: 72  Training loss = 3.0403  Validation loss = 5.3151  \n",
      "\n",
      "Fold: 10  Epoch: 73  Training loss = 3.0399  Validation loss = 5.3125  \n",
      "\n",
      "Fold: 10  Epoch: 74  Training loss = 3.0394  Validation loss = 5.3113  \n",
      "\n",
      "Fold: 10  Epoch: 75  Training loss = 3.0388  Validation loss = 5.3093  \n",
      "\n",
      "Fold: 10  Epoch: 76  Training loss = 3.0387  Validation loss = 5.3085  \n",
      "\n",
      "Fold: 10  Epoch: 77  Training loss = 3.0382  Validation loss = 5.3055  \n",
      "\n",
      "Fold: 10  Epoch: 78  Training loss = 3.0376  Validation loss = 5.3037  \n",
      "\n",
      "Fold: 10  Epoch: 79  Training loss = 3.0375  Validation loss = 5.3033  \n",
      "\n",
      "Fold: 10  Epoch: 80  Training loss = 3.0369  Validation loss = 5.3006  \n",
      "\n",
      "Fold: 10  Epoch: 81  Training loss = 3.0368  Validation loss = 5.3002  \n",
      "\n",
      "Fold: 10  Epoch: 82  Training loss = 3.0364  Validation loss = 5.2995  \n",
      "\n",
      "Fold: 10  Epoch: 83  Training loss = 3.0359  Validation loss = 5.2974  \n",
      "\n",
      "Fold: 10  Epoch: 84  Training loss = 3.0357  Validation loss = 5.2969  \n",
      "\n",
      "Fold: 10  Epoch: 85  Training loss = 3.0350  Validation loss = 5.2938  \n",
      "\n",
      "Fold: 10  Epoch: 86  Training loss = 3.0344  Validation loss = 5.2918  \n",
      "\n",
      "Fold: 10  Epoch: 87  Training loss = 3.0340  Validation loss = 5.2900  \n",
      "\n",
      "Fold: 10  Epoch: 88  Training loss = 3.0336  Validation loss = 5.2885  \n",
      "\n",
      "Fold: 10  Epoch: 89  Training loss = 3.0335  Validation loss = 5.2878  \n",
      "\n",
      "Fold: 10  Epoch: 90  Training loss = 3.0333  Validation loss = 5.2862  \n",
      "\n",
      "Fold: 10  Epoch: 91  Training loss = 3.0329  Validation loss = 5.2843  \n",
      "\n",
      "Fold: 10  Epoch: 92  Training loss = 3.0326  Validation loss = 5.2841  \n",
      "\n",
      "Fold: 10  Epoch: 93  Training loss = 3.0322  Validation loss = 5.2818  \n",
      "\n",
      "Fold: 10  Epoch: 94  Training loss = 3.0319  Validation loss = 5.2822  \n",
      "\n",
      "Fold: 10  Epoch: 95  Training loss = 3.0314  Validation loss = 5.2791  \n",
      "\n",
      "Fold: 10  Epoch: 96  Training loss = 3.0309  Validation loss = 5.2774  \n",
      "\n",
      "Fold: 10  Epoch: 97  Training loss = 3.0309  Validation loss = 5.2761  \n",
      "\n",
      "Fold: 10  Epoch: 98  Training loss = 3.0307  Validation loss = 5.2759  \n",
      "\n",
      "Fold: 10  Epoch: 99  Training loss = 3.0304  Validation loss = 5.2745  \n",
      "\n",
      "Fold: 10  Epoch: 100  Training loss = 3.0297  Validation loss = 5.2729  \n",
      "\n",
      "Fold: 10  Epoch: 101  Training loss = 3.0291  Validation loss = 5.2710  \n",
      "\n",
      "Fold: 10  Epoch: 102  Training loss = 3.0283  Validation loss = 5.2683  \n",
      "\n",
      "Fold: 10  Epoch: 103  Training loss = 3.0280  Validation loss = 5.2660  \n",
      "\n",
      "Fold: 10  Epoch: 104  Training loss = 3.0275  Validation loss = 5.2646  \n",
      "\n",
      "Fold: 10  Epoch: 105  Training loss = 3.0272  Validation loss = 5.2633  \n",
      "\n",
      "Fold: 10  Epoch: 106  Training loss = 3.0268  Validation loss = 5.2624  \n",
      "\n",
      "Fold: 10  Epoch: 107  Training loss = 3.0265  Validation loss = 5.2623  \n",
      "\n",
      "Fold: 10  Epoch: 108  Training loss = 3.0262  Validation loss = 5.2606  \n",
      "\n",
      "Fold: 10  Epoch: 109  Training loss = 3.0256  Validation loss = 5.2584  \n",
      "\n",
      "Fold: 10  Epoch: 110  Training loss = 3.0253  Validation loss = 5.2575  \n",
      "\n",
      "Fold: 10  Epoch: 111  Training loss = 3.0246  Validation loss = 5.2556  \n",
      "\n",
      "Fold: 10  Epoch: 112  Training loss = 3.0243  Validation loss = 5.2543  \n",
      "\n",
      "Fold: 10  Epoch: 113  Training loss = 3.0238  Validation loss = 5.2516  \n",
      "\n",
      "Fold: 10  Epoch: 114  Training loss = 3.0234  Validation loss = 5.2504  \n",
      "\n",
      "Fold: 10  Epoch: 115  Training loss = 3.0230  Validation loss = 5.2496  \n",
      "\n",
      "Fold: 10  Epoch: 116  Training loss = 3.0225  Validation loss = 5.2471  \n",
      "\n",
      "Fold: 10  Epoch: 117  Training loss = 3.0221  Validation loss = 5.2457  \n",
      "\n",
      "Fold: 10  Epoch: 118  Training loss = 3.0215  Validation loss = 5.2444  \n",
      "\n",
      "Fold: 10  Epoch: 119  Training loss = 3.0209  Validation loss = 5.2433  \n",
      "\n",
      "Fold: 10  Epoch: 120  Training loss = 3.0207  Validation loss = 5.2427  \n",
      "\n",
      "Fold: 10  Epoch: 121  Training loss = 3.0202  Validation loss = 5.2404  \n",
      "\n",
      "Fold: 10  Epoch: 122  Training loss = 3.0199  Validation loss = 5.2385  \n",
      "\n",
      "Fold: 10  Epoch: 123  Training loss = 3.0194  Validation loss = 5.2385  \n",
      "\n",
      "Fold: 10  Epoch: 124  Training loss = 3.0188  Validation loss = 5.2360  \n",
      "\n",
      "Fold: 10  Epoch: 125  Training loss = 3.0187  Validation loss = 5.2356  \n",
      "\n",
      "Fold: 10  Epoch: 126  Training loss = 3.0184  Validation loss = 5.2351  \n",
      "\n",
      "Fold: 10  Epoch: 127  Training loss = 3.0178  Validation loss = 5.2329  \n",
      "\n",
      "Fold: 10  Epoch: 128  Training loss = 3.0175  Validation loss = 5.2316  \n",
      "\n",
      "Fold: 10  Epoch: 129  Training loss = 3.0172  Validation loss = 5.2299  \n",
      "\n",
      "Fold: 10  Epoch: 130  Training loss = 3.0168  Validation loss = 5.2284  \n",
      "\n",
      "Fold: 10  Epoch: 131  Training loss = 3.0166  Validation loss = 5.2280  \n",
      "\n",
      "Fold: 10  Epoch: 132  Training loss = 3.0165  Validation loss = 5.2282  \n",
      "\n",
      "Fold: 10  Epoch: 133  Training loss = 3.0160  Validation loss = 5.2274  \n",
      "\n",
      "Fold: 10  Epoch: 134  Training loss = 3.0156  Validation loss = 5.2264  \n",
      "\n",
      "Fold: 10  Epoch: 135  Training loss = 3.0152  Validation loss = 5.2248  \n",
      "\n",
      "Fold: 10  Epoch: 136  Training loss = 3.0149  Validation loss = 5.2233  \n",
      "\n",
      "Fold: 10  Epoch: 137  Training loss = 3.0147  Validation loss = 5.2224  \n",
      "\n",
      "Fold: 10  Epoch: 138  Training loss = 3.0140  Validation loss = 5.2193  \n",
      "\n",
      "Fold: 10  Epoch: 139  Training loss = 3.0137  Validation loss = 5.2192  \n",
      "\n",
      "Fold: 10  Epoch: 140  Training loss = 3.0132  Validation loss = 5.2173  \n",
      "\n",
      "Fold: 10  Epoch: 141  Training loss = 3.0130  Validation loss = 5.2164  \n",
      "\n",
      "Fold: 10  Epoch: 142  Training loss = 3.0122  Validation loss = 5.2125  \n",
      "\n",
      "Fold: 10  Epoch: 143  Training loss = 3.0119  Validation loss = 5.2121  \n",
      "\n",
      "Fold: 10  Epoch: 144  Training loss = 3.0117  Validation loss = 5.2117  \n",
      "\n",
      "Fold: 10  Epoch: 145  Training loss = 3.0112  Validation loss = 5.2097  \n",
      "\n",
      "Fold: 10  Epoch: 146  Training loss = 3.0107  Validation loss = 5.2081  \n",
      "\n",
      "Fold: 10  Epoch: 147  Training loss = 3.0104  Validation loss = 5.2056  \n",
      "\n",
      "Fold: 10  Epoch: 148  Training loss = 3.0098  Validation loss = 5.2035  \n",
      "\n",
      "Fold: 10  Epoch: 149  Training loss = 3.0095  Validation loss = 5.2030  \n",
      "\n",
      "Fold: 10  Epoch: 150  Training loss = 3.0088  Validation loss = 5.2010  \n",
      "\n",
      "Fold: 10  Epoch: 151  Training loss = 3.0081  Validation loss = 5.1991  \n",
      "\n",
      "Fold: 10  Epoch: 152  Training loss = 3.0077  Validation loss = 5.1979  \n",
      "\n",
      "Fold: 10  Epoch: 153  Training loss = 3.0074  Validation loss = 5.1974  \n",
      "\n",
      "Fold: 10  Epoch: 154  Training loss = 3.0070  Validation loss = 5.1964  \n",
      "\n",
      "Fold: 10  Epoch: 155  Training loss = 3.0067  Validation loss = 5.1953  \n",
      "\n",
      "Fold: 10  Epoch: 156  Training loss = 3.0065  Validation loss = 5.1945  \n",
      "\n",
      "Fold: 10  Epoch: 157  Training loss = 3.0060  Validation loss = 5.1934  \n",
      "\n",
      "Fold: 10  Epoch: 158  Training loss = 3.0057  Validation loss = 5.1925  \n",
      "\n",
      "Fold: 10  Epoch: 159  Training loss = 3.0057  Validation loss = 5.1928  \n",
      "\n",
      "Fold: 10  Epoch: 160  Training loss = 3.0054  Validation loss = 5.1917  \n",
      "\n",
      "Fold: 10  Epoch: 161  Training loss = 3.0053  Validation loss = 5.1924  \n",
      "\n",
      "Fold: 10  Epoch: 162  Training loss = 3.0051  Validation loss = 5.1907  \n",
      "\n",
      "Fold: 10  Epoch: 163  Training loss = 3.0051  Validation loss = 5.1913  \n",
      "\n",
      "Fold: 10  Epoch: 164  Training loss = 3.0048  Validation loss = 5.1896  \n",
      "\n",
      "Fold: 10  Epoch: 165  Training loss = 3.0046  Validation loss = 5.1882  \n",
      "\n",
      "Fold: 10  Epoch: 166  Training loss = 3.0044  Validation loss = 5.1881  \n",
      "\n",
      "Fold: 10  Epoch: 167  Training loss = 3.0037  Validation loss = 5.1851  \n",
      "\n",
      "Fold: 10  Epoch: 168  Training loss = 3.0032  Validation loss = 5.1830  \n",
      "\n",
      "Fold: 10  Epoch: 169  Training loss = 3.0031  Validation loss = 5.1814  \n",
      "\n",
      "Fold: 10  Epoch: 170  Training loss = 3.0029  Validation loss = 5.1809  \n",
      "\n",
      "Fold: 10  Epoch: 171  Training loss = 3.0025  Validation loss = 5.1788  \n",
      "\n",
      "Fold: 10  Epoch: 172  Training loss = 3.0021  Validation loss = 5.1781  \n",
      "\n",
      "Fold: 10  Epoch: 173  Training loss = 3.0017  Validation loss = 5.1777  \n",
      "\n",
      "Fold: 10  Epoch: 174  Training loss = 3.0013  Validation loss = 5.1769  \n",
      "\n",
      "Fold: 10  Epoch: 175  Training loss = 3.0008  Validation loss = 5.1763  \n",
      "\n",
      "Fold: 10  Epoch: 176  Training loss = 3.0005  Validation loss = 5.1763  \n",
      "\n",
      "Fold: 10  Epoch: 177  Training loss = 3.0000  Validation loss = 5.1744  \n",
      "\n",
      "Fold: 10  Epoch: 178  Training loss = 2.9997  Validation loss = 5.1724  \n",
      "\n",
      "Fold: 10  Epoch: 179  Training loss = 2.9993  Validation loss = 5.1717  \n",
      "\n",
      "Fold: 10  Epoch: 180  Training loss = 2.9992  Validation loss = 5.1720  \n",
      "\n",
      "Fold: 10  Epoch: 181  Training loss = 2.9990  Validation loss = 5.1710  \n",
      "\n",
      "Fold: 10  Epoch: 182  Training loss = 2.9987  Validation loss = 5.1696  \n",
      "\n",
      "Fold: 10  Epoch: 183  Training loss = 2.9982  Validation loss = 5.1676  \n",
      "\n",
      "Fold: 10  Epoch: 184  Training loss = 2.9979  Validation loss = 5.1667  \n",
      "\n",
      "Fold: 10  Epoch: 185  Training loss = 2.9976  Validation loss = 5.1648  \n",
      "\n",
      "Fold: 10  Epoch: 186  Training loss = 2.9970  Validation loss = 5.1629  \n",
      "\n",
      "Fold: 10  Epoch: 187  Training loss = 2.9968  Validation loss = 5.1615  \n",
      "\n",
      "Fold: 10  Epoch: 188  Training loss = 2.9964  Validation loss = 5.1602  \n",
      "\n",
      "Fold: 10  Epoch: 189  Training loss = 2.9959  Validation loss = 5.1578  \n",
      "\n",
      "Fold: 10  Epoch: 190  Training loss = 2.9956  Validation loss = 5.1560  \n",
      "\n",
      "Fold: 10  Epoch: 191  Training loss = 2.9951  Validation loss = 5.1539  \n",
      "\n",
      "Fold: 10  Epoch: 192  Training loss = 2.9949  Validation loss = 5.1526  \n",
      "\n",
      "Fold: 10  Epoch: 193  Training loss = 2.9946  Validation loss = 5.1520  \n",
      "\n",
      "Fold: 10  Epoch: 194  Training loss = 2.9942  Validation loss = 5.1498  \n",
      "\n",
      "Fold: 10  Epoch: 195  Training loss = 2.9942  Validation loss = 5.1502  \n",
      "\n",
      "Fold: 10  Epoch: 196  Training loss = 2.9941  Validation loss = 5.1490  \n",
      "\n",
      "Fold: 10  Epoch: 197  Training loss = 2.9937  Validation loss = 5.1481  \n",
      "\n",
      "Fold: 10  Epoch: 198  Training loss = 2.9934  Validation loss = 5.1466  \n",
      "\n",
      "Fold: 10  Epoch: 199  Training loss = 2.9932  Validation loss = 5.1468  \n",
      "\n",
      "Fold: 10  Epoch: 200  Training loss = 2.9929  Validation loss = 5.1467  \n",
      "\n",
      "Fold: 10  Epoch: 201  Training loss = 2.9927  Validation loss = 5.1452  \n",
      "\n",
      "Fold: 10  Epoch: 202  Training loss = 2.9923  Validation loss = 5.1441  \n",
      "\n",
      "Fold: 10  Epoch: 203  Training loss = 2.9921  Validation loss = 5.1432  \n",
      "\n",
      "Fold: 10  Epoch: 204  Training loss = 2.9916  Validation loss = 5.1401  \n",
      "\n",
      "Fold: 10  Epoch: 205  Training loss = 2.9912  Validation loss = 5.1383  \n",
      "\n",
      "Fold: 10  Epoch: 206  Training loss = 2.9909  Validation loss = 5.1369  \n",
      "\n",
      "Fold: 10  Epoch: 207  Training loss = 2.9908  Validation loss = 5.1380  \n",
      "\n",
      "Fold: 10  Epoch: 208  Training loss = 2.9903  Validation loss = 5.1360  \n",
      "\n",
      "Fold: 10  Epoch: 209  Training loss = 2.9901  Validation loss = 5.1357  \n",
      "\n",
      "Fold: 10  Epoch: 210  Training loss = 2.9897  Validation loss = 5.1343  \n",
      "\n",
      "Fold: 10  Epoch: 211  Training loss = 2.9897  Validation loss = 5.1351  \n",
      "\n",
      "Fold: 10  Epoch: 212  Training loss = 2.9893  Validation loss = 5.1338  \n",
      "\n",
      "Fold: 10  Epoch: 213  Training loss = 2.9891  Validation loss = 5.1345  \n",
      "\n",
      "Fold: 10  Epoch: 214  Training loss = 2.9889  Validation loss = 5.1328  \n",
      "\n",
      "Fold: 10  Epoch: 215  Training loss = 2.9889  Validation loss = 5.1329  \n",
      "\n",
      "Fold: 10  Epoch: 216  Training loss = 2.9883  Validation loss = 5.1310  \n",
      "\n",
      "Fold: 10  Epoch: 217  Training loss = 2.9880  Validation loss = 5.1299  \n",
      "\n",
      "Fold: 10  Epoch: 218  Training loss = 2.9879  Validation loss = 5.1288  \n",
      "\n",
      "Fold: 10  Epoch: 219  Training loss = 2.9877  Validation loss = 5.1278  \n",
      "\n",
      "Fold: 10  Epoch: 220  Training loss = 2.9872  Validation loss = 5.1259  \n",
      "\n",
      "Fold: 10  Epoch: 221  Training loss = 2.9870  Validation loss = 5.1255  \n",
      "\n",
      "Fold: 10  Epoch: 222  Training loss = 2.9865  Validation loss = 5.1230  \n",
      "\n",
      "Fold: 10  Epoch: 223  Training loss = 2.9859  Validation loss = 5.1200  \n",
      "\n",
      "Fold: 10  Epoch: 224  Training loss = 2.9854  Validation loss = 5.1176  \n",
      "\n",
      "Fold: 10  Epoch: 225  Training loss = 2.9852  Validation loss = 5.1166  \n",
      "\n",
      "Fold: 10  Epoch: 226  Training loss = 2.9849  Validation loss = 5.1132  \n",
      "\n",
      "Fold: 10  Epoch: 227  Training loss = 2.9847  Validation loss = 5.1122  \n",
      "\n",
      "Fold: 10  Epoch: 228  Training loss = 2.9844  Validation loss = 5.1103  \n",
      "\n",
      "Fold: 10  Epoch: 229  Training loss = 2.9841  Validation loss = 5.1103  \n",
      "\n",
      "Fold: 10  Epoch: 230  Training loss = 2.9838  Validation loss = 5.1100  \n",
      "\n",
      "Fold: 10  Epoch: 231  Training loss = 2.9836  Validation loss = 5.1114  \n",
      "\n",
      "Fold: 10  Epoch: 232  Training loss = 2.9833  Validation loss = 5.1101  \n",
      "\n",
      "Fold: 10  Epoch: 233  Training loss = 2.9830  Validation loss = 5.1102  \n",
      "\n",
      "Fold: 10  Epoch: 234  Training loss = 2.9826  Validation loss = 5.1081  \n",
      "\n",
      "Fold: 10  Epoch: 235  Training loss = 2.9819  Validation loss = 5.1042  \n",
      "\n",
      "Fold: 10  Epoch: 236  Training loss = 2.9815  Validation loss = 5.1008  \n",
      "\n",
      "Fold: 10  Epoch: 237  Training loss = 2.9811  Validation loss = 5.0994  \n",
      "\n",
      "Fold: 10  Epoch: 238  Training loss = 2.9806  Validation loss = 5.0981  \n",
      "\n",
      "Fold: 10  Epoch: 239  Training loss = 2.9802  Validation loss = 5.0966  \n",
      "\n",
      "Fold: 10  Epoch: 240  Training loss = 2.9800  Validation loss = 5.0955  \n",
      "\n",
      "Fold: 10  Epoch: 241  Training loss = 2.9799  Validation loss = 5.0941  \n",
      "\n",
      "Fold: 10  Epoch: 242  Training loss = 2.9795  Validation loss = 5.0919  \n",
      "\n",
      "Fold: 10  Epoch: 243  Training loss = 2.9791  Validation loss = 5.0909  \n",
      "\n",
      "Fold: 10  Epoch: 244  Training loss = 2.9788  Validation loss = 5.0893  \n",
      "\n",
      "Fold: 10  Epoch: 245  Training loss = 2.9789  Validation loss = 5.0893  \n",
      "\n",
      "Fold: 10  Epoch: 246  Training loss = 2.9785  Validation loss = 5.0893  \n",
      "\n",
      "Fold: 10  Epoch: 247  Training loss = 2.9782  Validation loss = 5.0887  \n",
      "\n",
      "Fold: 10  Epoch: 248  Training loss = 2.9777  Validation loss = 5.0881  \n",
      "\n",
      "Fold: 10  Epoch: 249  Training loss = 2.9776  Validation loss = 5.0880  \n",
      "\n",
      "Fold: 10  Epoch: 250  Training loss = 2.9774  Validation loss = 5.0874  \n",
      "\n",
      "Fold: 10  Epoch: 251  Training loss = 2.9772  Validation loss = 5.0867  \n",
      "\n",
      "Fold: 10  Epoch: 252  Training loss = 2.9771  Validation loss = 5.0864  \n",
      "\n",
      "Fold: 10  Epoch: 253  Training loss = 2.9773  Validation loss = 5.0871  \n",
      "\n",
      "Fold: 10  Epoch: 254  Training loss = 2.9771  Validation loss = 5.0863  \n",
      "\n",
      "Fold: 10  Epoch: 255  Training loss = 2.9768  Validation loss = 5.0848  \n",
      "\n",
      "Fold: 10  Epoch: 256  Training loss = 2.9764  Validation loss = 5.0827  \n",
      "\n",
      "Fold: 10  Epoch: 257  Training loss = 2.9761  Validation loss = 5.0816  \n",
      "\n",
      "Fold: 10  Epoch: 258  Training loss = 2.9757  Validation loss = 5.0800  \n",
      "\n",
      "Fold: 10  Epoch: 259  Training loss = 2.9754  Validation loss = 5.0782  \n",
      "\n",
      "Fold: 10  Epoch: 260  Training loss = 2.9752  Validation loss = 5.0782  \n",
      "\n",
      "Fold: 10  Epoch: 261  Training loss = 2.9748  Validation loss = 5.0785  \n",
      "\n",
      "Fold: 10  Epoch: 262  Training loss = 2.9746  Validation loss = 5.0782  \n",
      "\n",
      "Fold: 10  Epoch: 263  Training loss = 2.9743  Validation loss = 5.0780  \n",
      "\n",
      "Fold: 10  Epoch: 264  Training loss = 2.9743  Validation loss = 5.0789  \n",
      "\n",
      "Fold: 10  Epoch: 265  Training loss = 2.9737  Validation loss = 5.0771  \n",
      "\n",
      "Fold: 10  Epoch: 266  Training loss = 2.9734  Validation loss = 5.0763  \n",
      "\n",
      "Fold: 10  Epoch: 267  Training loss = 2.9731  Validation loss = 5.0744  \n",
      "\n",
      "Fold: 10  Epoch: 268  Training loss = 2.9728  Validation loss = 5.0745  \n",
      "\n",
      "Fold: 10  Epoch: 269  Training loss = 2.9728  Validation loss = 5.0752  \n",
      "\n",
      "Fold: 10  Epoch: 270  Training loss = 2.9727  Validation loss = 5.0769  \n",
      "\n",
      "Fold: 10  Epoch: 271  Training loss = 2.9727  Validation loss = 5.0775  \n",
      "\n",
      "Fold: 10  Epoch: 272  Training loss = 2.9724  Validation loss = 5.0757  \n",
      "\n",
      "Fold: 10  Epoch: 273  Training loss = 2.9722  Validation loss = 5.0752  \n",
      "\n",
      "Fold: 10  Epoch: 274  Training loss = 2.9718  Validation loss = 5.0730  \n",
      "\n",
      "Fold: 10  Epoch: 275  Training loss = 2.9716  Validation loss = 5.0728  \n",
      "\n",
      "Fold: 10  Epoch: 276  Training loss = 2.9711  Validation loss = 5.0725  \n",
      "\n",
      "Fold: 10  Epoch: 277  Training loss = 2.9710  Validation loss = 5.0722  \n",
      "\n",
      "Fold: 10  Epoch: 278  Training loss = 2.9707  Validation loss = 5.0697  \n",
      "\n",
      "Fold: 10  Epoch: 279  Training loss = 2.9706  Validation loss = 5.0703  \n",
      "\n",
      "Fold: 10  Epoch: 280  Training loss = 2.9702  Validation loss = 5.0705  \n",
      "\n",
      "Fold: 10  Epoch: 281  Training loss = 2.9699  Validation loss = 5.0688  \n",
      "\n",
      "Fold: 10  Epoch: 282  Training loss = 2.9693  Validation loss = 5.0661  \n",
      "\n",
      "Fold: 10  Epoch: 283  Training loss = 2.9693  Validation loss = 5.0669  \n",
      "\n",
      "Fold: 10  Epoch: 284  Training loss = 2.9689  Validation loss = 5.0656  \n",
      "\n",
      "Fold: 10  Epoch: 285  Training loss = 2.9688  Validation loss = 5.0647  \n",
      "\n",
      "Fold: 10  Epoch: 286  Training loss = 2.9685  Validation loss = 5.0644  \n",
      "\n",
      "Fold: 10  Epoch: 287  Training loss = 2.9684  Validation loss = 5.0641  \n",
      "\n",
      "Fold: 10  Epoch: 288  Training loss = 2.9682  Validation loss = 5.0617  \n",
      "\n",
      "Fold: 10  Epoch: 289  Training loss = 2.9676  Validation loss = 5.0590  \n",
      "\n",
      "Fold: 10  Epoch: 290  Training loss = 2.9675  Validation loss = 5.0583  \n",
      "\n",
      "Fold: 10  Epoch: 291  Training loss = 2.9672  Validation loss = 5.0574  \n",
      "\n",
      "Fold: 10  Epoch: 292  Training loss = 2.9668  Validation loss = 5.0560  \n",
      "\n",
      "Fold: 10  Epoch: 293  Training loss = 2.9667  Validation loss = 5.0557  \n",
      "\n",
      "Fold: 10  Epoch: 294  Training loss = 2.9666  Validation loss = 5.0558  \n",
      "\n",
      "Fold: 10  Epoch: 295  Training loss = 2.9663  Validation loss = 5.0549  \n",
      "\n",
      "Fold: 10  Epoch: 296  Training loss = 2.9661  Validation loss = 5.0552  \n",
      "\n",
      "Fold: 10  Epoch: 297  Training loss = 2.9656  Validation loss = 5.0544  \n",
      "\n",
      "Fold: 10  Epoch: 298  Training loss = 2.9654  Validation loss = 5.0528  \n",
      "\n",
      "Fold: 10  Epoch: 299  Training loss = 2.9649  Validation loss = 5.0515  \n",
      "\n",
      "Fold: 10  Epoch: 300  Training loss = 2.9649  Validation loss = 5.0514  \n",
      "\n",
      "Fold: 10  Epoch: 301  Training loss = 2.9648  Validation loss = 5.0518  \n",
      "\n",
      "Fold: 10  Epoch: 302  Training loss = 2.9646  Validation loss = 5.0523  \n",
      "\n",
      "Fold: 10  Epoch: 303  Training loss = 2.9641  Validation loss = 5.0525  \n",
      "\n",
      "Fold: 10  Epoch: 304  Training loss = 2.9638  Validation loss = 5.0516  \n",
      "\n",
      "Fold: 10  Epoch: 305  Training loss = 2.9635  Validation loss = 5.0517  \n",
      "\n",
      "Fold: 10  Epoch: 306  Training loss = 2.9633  Validation loss = 5.0515  \n",
      "\n",
      "Fold: 10  Epoch: 307  Training loss = 2.9629  Validation loss = 5.0503  \n",
      "\n",
      "Fold: 10  Epoch: 308  Training loss = 2.9627  Validation loss = 5.0490  \n",
      "\n",
      "Fold: 10  Epoch: 309  Training loss = 2.9624  Validation loss = 5.0474  \n",
      "\n",
      "Fold: 10  Epoch: 310  Training loss = 2.9620  Validation loss = 5.0444  \n",
      "\n",
      "Fold: 10  Epoch: 311  Training loss = 2.9615  Validation loss = 5.0421  \n",
      "\n",
      "Fold: 10  Epoch: 312  Training loss = 2.9612  Validation loss = 5.0410  \n",
      "\n",
      "Fold: 10  Epoch: 313  Training loss = 2.9608  Validation loss = 5.0401  \n",
      "\n",
      "Fold: 10  Epoch: 314  Training loss = 2.9603  Validation loss = 5.0366  \n",
      "\n",
      "Fold: 10  Epoch: 315  Training loss = 2.9601  Validation loss = 5.0361  \n",
      "\n",
      "Fold: 10  Epoch: 316  Training loss = 2.9598  Validation loss = 5.0348  \n",
      "\n",
      "Fold: 10  Epoch: 317  Training loss = 2.9595  Validation loss = 5.0329  \n",
      "\n",
      "Fold: 10  Epoch: 318  Training loss = 2.9594  Validation loss = 5.0327  \n",
      "\n",
      "Fold: 10  Epoch: 319  Training loss = 2.9592  Validation loss = 5.0316  \n",
      "\n",
      "Fold: 10  Epoch: 320  Training loss = 2.9591  Validation loss = 5.0331  \n",
      "\n",
      "Fold: 10  Epoch: 321  Training loss = 2.9588  Validation loss = 5.0333  \n",
      "\n",
      "Fold: 10  Epoch: 322  Training loss = 2.9584  Validation loss = 5.0321  \n",
      "\n",
      "Fold: 10  Epoch: 323  Training loss = 2.9581  Validation loss = 5.0308  \n",
      "\n",
      "Fold: 10  Epoch: 324  Training loss = 2.9579  Validation loss = 5.0294  \n",
      "\n",
      "Fold: 10  Epoch: 325  Training loss = 2.9575  Validation loss = 5.0270  \n",
      "\n",
      "Fold: 10  Epoch: 326  Training loss = 2.9572  Validation loss = 5.0262  \n",
      "\n",
      "Fold: 10  Epoch: 327  Training loss = 2.9568  Validation loss = 5.0245  \n",
      "\n",
      "Fold: 10  Epoch: 328  Training loss = 2.9563  Validation loss = 5.0231  \n",
      "\n",
      "Fold: 10  Epoch: 329  Training loss = 2.9560  Validation loss = 5.0221  \n",
      "\n",
      "Fold: 10  Epoch: 330  Training loss = 2.9557  Validation loss = 5.0212  \n",
      "\n",
      "Fold: 10  Epoch: 331  Training loss = 2.9554  Validation loss = 5.0207  \n",
      "\n",
      "Fold: 10  Epoch: 332  Training loss = 2.9551  Validation loss = 5.0194  \n",
      "\n",
      "Fold: 10  Epoch: 333  Training loss = 2.9548  Validation loss = 5.0187  \n",
      "\n",
      "Fold: 10  Epoch: 334  Training loss = 2.9545  Validation loss = 5.0181  \n",
      "\n",
      "Fold: 10  Epoch: 335  Training loss = 2.9539  Validation loss = 5.0151  \n",
      "\n",
      "Fold: 10  Epoch: 336  Training loss = 2.9535  Validation loss = 5.0138  \n",
      "\n",
      "Fold: 10  Epoch: 337  Training loss = 2.9532  Validation loss = 5.0123  \n",
      "\n",
      "Fold: 10  Epoch: 338  Training loss = 2.9530  Validation loss = 5.0114  \n",
      "\n",
      "Fold: 10  Epoch: 339  Training loss = 2.9526  Validation loss = 5.0091  \n",
      "\n",
      "Fold: 10  Epoch: 340  Training loss = 2.9524  Validation loss = 5.0080  \n",
      "\n",
      "Fold: 10  Epoch: 341  Training loss = 2.9521  Validation loss = 5.0071  \n",
      "\n",
      "Fold: 10  Epoch: 342  Training loss = 2.9519  Validation loss = 5.0065  \n",
      "\n",
      "Fold: 10  Epoch: 343  Training loss = 2.9516  Validation loss = 5.0084  \n",
      "\n",
      "Fold: 10  Epoch: 344  Training loss = 2.9512  Validation loss = 5.0055  \n",
      "\n",
      "Fold: 10  Epoch: 345  Training loss = 2.9507  Validation loss = 5.0041  \n",
      "\n",
      "Fold: 10  Epoch: 346  Training loss = 2.9503  Validation loss = 5.0025  \n",
      "\n",
      "Fold: 10  Epoch: 347  Training loss = 2.9500  Validation loss = 5.0007  \n",
      "\n",
      "Fold: 10  Epoch: 348  Training loss = 2.9495  Validation loss = 5.0003  \n",
      "\n",
      "Fold: 10  Epoch: 349  Training loss = 2.9491  Validation loss = 4.9986  \n",
      "\n",
      "Fold: 10  Epoch: 350  Training loss = 2.9488  Validation loss = 4.9974  \n",
      "\n",
      "Fold: 10  Epoch: 351  Training loss = 2.9485  Validation loss = 4.9967  \n",
      "\n",
      "Fold: 10  Epoch: 352  Training loss = 2.9484  Validation loss = 4.9969  \n",
      "\n",
      "Fold: 10  Epoch: 353  Training loss = 2.9482  Validation loss = 4.9960  \n",
      "\n",
      "Fold: 10  Epoch: 354  Training loss = 2.9479  Validation loss = 4.9946  \n",
      "\n",
      "Fold: 10  Epoch: 355  Training loss = 2.9475  Validation loss = 4.9932  \n",
      "\n",
      "Fold: 10  Epoch: 356  Training loss = 2.9472  Validation loss = 4.9912  \n",
      "\n",
      "Fold: 10  Epoch: 357  Training loss = 2.9466  Validation loss = 4.9868  \n",
      "\n",
      "Fold: 10  Epoch: 358  Training loss = 2.9465  Validation loss = 4.9859  \n",
      "\n",
      "Fold: 10  Epoch: 359  Training loss = 2.9465  Validation loss = 4.9859  \n",
      "\n",
      "Fold: 10  Epoch: 360  Training loss = 2.9461  Validation loss = 4.9836  \n",
      "\n",
      "Fold: 10  Epoch: 361  Training loss = 2.9458  Validation loss = 4.9822  \n",
      "\n",
      "Fold: 10  Epoch: 362  Training loss = 2.9457  Validation loss = 4.9817  \n",
      "\n",
      "Fold: 10  Epoch: 363  Training loss = 2.9454  Validation loss = 4.9814  \n",
      "\n",
      "Fold: 10  Epoch: 364  Training loss = 2.9451  Validation loss = 4.9797  \n",
      "\n",
      "Fold: 10  Epoch: 365  Training loss = 2.9449  Validation loss = 4.9788  \n",
      "\n",
      "Fold: 10  Epoch: 366  Training loss = 2.9445  Validation loss = 4.9764  \n",
      "\n",
      "Fold: 10  Epoch: 367  Training loss = 2.9442  Validation loss = 4.9748  \n",
      "\n",
      "Fold: 10  Epoch: 368  Training loss = 2.9439  Validation loss = 4.9741  \n",
      "\n",
      "Fold: 10  Epoch: 369  Training loss = 2.9436  Validation loss = 4.9746  \n",
      "\n",
      "Fold: 10  Epoch: 370  Training loss = 2.9433  Validation loss = 4.9732  \n",
      "\n",
      "Fold: 10  Epoch: 371  Training loss = 2.9429  Validation loss = 4.9724  \n",
      "\n",
      "Fold: 10  Epoch: 372  Training loss = 2.9427  Validation loss = 4.9715  \n",
      "\n",
      "Fold: 10  Epoch: 373  Training loss = 2.9422  Validation loss = 4.9704  \n",
      "\n",
      "Fold: 10  Epoch: 374  Training loss = 2.9421  Validation loss = 4.9697  \n",
      "\n",
      "Fold: 10  Epoch: 375  Training loss = 2.9421  Validation loss = 4.9700  \n",
      "\n",
      "Fold: 10  Epoch: 376  Training loss = 2.9418  Validation loss = 4.9692  \n",
      "\n",
      "Fold: 10  Epoch: 377  Training loss = 2.9417  Validation loss = 4.9686  \n",
      "\n",
      "Fold: 10  Epoch: 378  Training loss = 2.9413  Validation loss = 4.9670  \n",
      "\n",
      "Fold: 10  Epoch: 379  Training loss = 2.9411  Validation loss = 4.9673  \n",
      "\n",
      "Fold: 10  Epoch: 380  Training loss = 2.9409  Validation loss = 4.9671  \n",
      "\n",
      "Fold: 10  Epoch: 381  Training loss = 2.9408  Validation loss = 4.9671  \n",
      "\n",
      "Fold: 10  Epoch: 382  Training loss = 2.9405  Validation loss = 4.9664  \n",
      "\n",
      "Fold: 10  Epoch: 383  Training loss = 2.9403  Validation loss = 4.9653  \n",
      "\n",
      "Fold: 10  Epoch: 384  Training loss = 2.9402  Validation loss = 4.9654  \n",
      "\n",
      "Fold: 10  Epoch: 385  Training loss = 2.9399  Validation loss = 4.9638  \n",
      "\n",
      "Fold: 10  Epoch: 386  Training loss = 2.9396  Validation loss = 4.9631  \n",
      "\n",
      "Fold: 10  Epoch: 387  Training loss = 2.9395  Validation loss = 4.9640  \n",
      "\n",
      "Fold: 10  Epoch: 388  Training loss = 2.9393  Validation loss = 4.9632  \n",
      "\n",
      "Fold: 10  Epoch: 389  Training loss = 2.9390  Validation loss = 4.9614  \n",
      "\n",
      "Fold: 10  Epoch: 390  Training loss = 2.9387  Validation loss = 4.9606  \n",
      "\n",
      "Fold: 10  Epoch: 391  Training loss = 2.9384  Validation loss = 4.9595  \n",
      "\n",
      "Fold: 10  Epoch: 392  Training loss = 2.9381  Validation loss = 4.9589  \n",
      "\n",
      "Fold: 10  Epoch: 393  Training loss = 2.9379  Validation loss = 4.9575  \n",
      "\n",
      "Fold: 10  Epoch: 394  Training loss = 2.9374  Validation loss = 4.9562  \n",
      "\n",
      "Fold: 10  Epoch: 395  Training loss = 2.9371  Validation loss = 4.9561  \n",
      "\n",
      "Fold: 10  Epoch: 396  Training loss = 2.9370  Validation loss = 4.9551  \n",
      "\n",
      "Fold: 10  Epoch: 397  Training loss = 2.9368  Validation loss = 4.9544  \n",
      "\n",
      "Fold: 10  Epoch: 398  Training loss = 2.9366  Validation loss = 4.9551  \n",
      "\n",
      "Fold: 10  Epoch: 399  Training loss = 2.9364  Validation loss = 4.9533  \n",
      "\n",
      "Fold: 10  Epoch: 400  Training loss = 2.9360  Validation loss = 4.9510  \n",
      "\n",
      "Fold: 10  Epoch: 401  Training loss = 2.9358  Validation loss = 4.9501  \n",
      "\n",
      "Fold: 10  Epoch: 402  Training loss = 2.9354  Validation loss = 4.9477  \n",
      "\n",
      "Fold: 10  Epoch: 403  Training loss = 2.9350  Validation loss = 4.9459  \n",
      "\n",
      "Fold: 10  Epoch: 404  Training loss = 2.9348  Validation loss = 4.9448  \n",
      "\n",
      "Fold: 10  Epoch: 405  Training loss = 2.9346  Validation loss = 4.9438  \n",
      "\n",
      "Fold: 10  Epoch: 406  Training loss = 2.9341  Validation loss = 4.9424  \n",
      "\n",
      "Fold: 10  Epoch: 407  Training loss = 2.9340  Validation loss = 4.9437  \n",
      "\n",
      "Fold: 10  Epoch: 408  Training loss = 2.9338  Validation loss = 4.9436  \n",
      "\n",
      "Fold: 10  Epoch: 409  Training loss = 2.9335  Validation loss = 4.9429  \n",
      "\n",
      "Fold: 10  Epoch: 410  Training loss = 2.9333  Validation loss = 4.9432  \n",
      "\n",
      "Fold: 10  Epoch: 411  Training loss = 2.9330  Validation loss = 4.9423  \n",
      "\n",
      "Fold: 10  Epoch: 412  Training loss = 2.9327  Validation loss = 4.9417  \n",
      "\n",
      "Fold: 10  Epoch: 413  Training loss = 2.9324  Validation loss = 4.9403  \n",
      "\n",
      "Fold: 10  Epoch: 414  Training loss = 2.9322  Validation loss = 4.9400  \n",
      "\n",
      "Fold: 10  Epoch: 415  Training loss = 2.9320  Validation loss = 4.9384  \n",
      "\n",
      "Fold: 10  Epoch: 416  Training loss = 2.9317  Validation loss = 4.9379  \n",
      "\n",
      "Fold: 10  Epoch: 417  Training loss = 2.9313  Validation loss = 4.9366  \n",
      "\n",
      "Fold: 10  Epoch: 418  Training loss = 2.9312  Validation loss = 4.9362  \n",
      "\n",
      "Fold: 10  Epoch: 419  Training loss = 2.9311  Validation loss = 4.9359  \n",
      "\n",
      "Fold: 10  Epoch: 420  Training loss = 2.9310  Validation loss = 4.9355  \n",
      "\n",
      "Fold: 10  Epoch: 421  Training loss = 2.9306  Validation loss = 4.9337  \n",
      "\n",
      "Fold: 10  Epoch: 422  Training loss = 2.9304  Validation loss = 4.9339  \n",
      "\n",
      "Fold: 10  Epoch: 423  Training loss = 2.9301  Validation loss = 4.9315  \n",
      "\n",
      "Fold: 10  Epoch: 424  Training loss = 2.9298  Validation loss = 4.9309  \n",
      "\n",
      "Fold: 10  Epoch: 425  Training loss = 2.9296  Validation loss = 4.9295  \n",
      "\n",
      "Fold: 10  Epoch: 426  Training loss = 2.9292  Validation loss = 4.9286  \n",
      "\n",
      "Fold: 10  Epoch: 427  Training loss = 2.9289  Validation loss = 4.9282  \n",
      "\n",
      "Fold: 10  Epoch: 428  Training loss = 2.9287  Validation loss = 4.9281  \n",
      "\n",
      "Fold: 10  Epoch: 429  Training loss = 2.9287  Validation loss = 4.9290  \n",
      "\n",
      "Fold: 10  Epoch: 430  Training loss = 2.9283  Validation loss = 4.9280  \n",
      "\n",
      "Fold: 10  Epoch: 431  Training loss = 2.9281  Validation loss = 4.9283  \n",
      "\n",
      "Fold: 10  Epoch: 432  Training loss = 2.9279  Validation loss = 4.9279  \n",
      "\n",
      "Fold: 10  Epoch: 433  Training loss = 2.9275  Validation loss = 4.9253  \n",
      "\n",
      "Fold: 10  Epoch: 434  Training loss = 2.9271  Validation loss = 4.9231  \n",
      "\n",
      "Fold: 10  Epoch: 435  Training loss = 2.9269  Validation loss = 4.9217  \n",
      "\n",
      "Fold: 10  Epoch: 436  Training loss = 2.9266  Validation loss = 4.9194  \n",
      "\n",
      "Fold: 10  Epoch: 437  Training loss = 2.9262  Validation loss = 4.9177  \n",
      "\n",
      "Fold: 10  Epoch: 438  Training loss = 2.9261  Validation loss = 4.9184  \n",
      "\n",
      "Fold: 10  Epoch: 439  Training loss = 2.9258  Validation loss = 4.9171  \n",
      "\n",
      "Fold: 10  Epoch: 440  Training loss = 2.9255  Validation loss = 4.9162  \n",
      "\n",
      "Fold: 10  Epoch: 441  Training loss = 2.9252  Validation loss = 4.9152  \n",
      "\n",
      "Fold: 10  Epoch: 442  Training loss = 2.9251  Validation loss = 4.9150  \n",
      "\n",
      "Fold: 10  Epoch: 443  Training loss = 2.9247  Validation loss = 4.9126  \n",
      "\n",
      "Fold: 10  Epoch: 444  Training loss = 2.9244  Validation loss = 4.9119  \n",
      "\n",
      "Fold: 10  Epoch: 445  Training loss = 2.9242  Validation loss = 4.9110  \n",
      "\n",
      "Fold: 10  Epoch: 446  Training loss = 2.9239  Validation loss = 4.9093  \n",
      "\n",
      "Fold: 10  Epoch: 447  Training loss = 2.9236  Validation loss = 4.9083  \n",
      "\n",
      "Fold: 10  Epoch: 448  Training loss = 2.9232  Validation loss = 4.9073  \n",
      "\n",
      "Fold: 10  Epoch: 449  Training loss = 2.9231  Validation loss = 4.9082  \n",
      "\n",
      "Fold: 10  Epoch: 450  Training loss = 2.9229  Validation loss = 4.9068  \n",
      "\n",
      "Fold: 10  Epoch: 451  Training loss = 2.9227  Validation loss = 4.9063  \n",
      "\n",
      "Fold: 10  Epoch: 452  Training loss = 2.9223  Validation loss = 4.9047  \n",
      "\n",
      "Fold: 10  Epoch: 453  Training loss = 2.9220  Validation loss = 4.9026  \n",
      "\n",
      "Fold: 10  Epoch: 454  Training loss = 2.9218  Validation loss = 4.9022  \n",
      "\n",
      "Fold: 10  Epoch: 455  Training loss = 2.9215  Validation loss = 4.9006  \n",
      "\n",
      "Fold: 10  Epoch: 456  Training loss = 2.9212  Validation loss = 4.8981  \n",
      "\n",
      "Fold: 10  Epoch: 457  Training loss = 2.9211  Validation loss = 4.8977  \n",
      "\n",
      "Fold: 10  Epoch: 458  Training loss = 2.9207  Validation loss = 4.8954  \n",
      "\n",
      "Fold: 10  Epoch: 459  Training loss = 2.9205  Validation loss = 4.8960  \n",
      "\n",
      "Fold: 10  Epoch: 460  Training loss = 2.9202  Validation loss = 4.8939  \n",
      "\n",
      "Fold: 10  Epoch: 461  Training loss = 2.9201  Validation loss = 4.8934  \n",
      "\n",
      "Fold: 10  Epoch: 462  Training loss = 2.9197  Validation loss = 4.8910  \n",
      "\n",
      "Fold: 10  Epoch: 463  Training loss = 2.9195  Validation loss = 4.8906  \n",
      "\n",
      "Fold: 10  Epoch: 464  Training loss = 2.9193  Validation loss = 4.8899  \n",
      "\n",
      "Fold: 10  Epoch: 465  Training loss = 2.9191  Validation loss = 4.8890  \n",
      "\n",
      "Fold: 10  Epoch: 466  Training loss = 2.9190  Validation loss = 4.8884  \n",
      "\n",
      "Fold: 10  Epoch: 467  Training loss = 2.9190  Validation loss = 4.8902  \n",
      "\n",
      "Fold: 10  Epoch: 468  Training loss = 2.9186  Validation loss = 4.8885  \n",
      "\n",
      "Fold: 10  Epoch: 469  Training loss = 2.9184  Validation loss = 4.8869  \n",
      "\n",
      "Fold: 10  Epoch: 470  Training loss = 2.9183  Validation loss = 4.8874  \n",
      "\n",
      "Fold: 10  Epoch: 471  Training loss = 2.9181  Validation loss = 4.8867  \n",
      "\n",
      "Fold: 10  Epoch: 472  Training loss = 2.9179  Validation loss = 4.8861  \n",
      "\n",
      "Fold: 10  Epoch: 473  Training loss = 2.9177  Validation loss = 4.8862  \n",
      "\n",
      "Fold: 10  Epoch: 474  Training loss = 2.9175  Validation loss = 4.8865  \n",
      "\n",
      "Fold: 10  Epoch: 475  Training loss = 2.9171  Validation loss = 4.8840  \n",
      "\n",
      "Fold: 10  Epoch: 476  Training loss = 2.9170  Validation loss = 4.8850  \n",
      "\n",
      "Fold: 10  Epoch: 477  Training loss = 2.9167  Validation loss = 4.8844  \n",
      "\n",
      "Fold: 10  Epoch: 478  Training loss = 2.9166  Validation loss = 4.8847  \n",
      "\n",
      "Fold: 10  Epoch: 479  Training loss = 2.9164  Validation loss = 4.8845  \n",
      "\n",
      "Fold: 10  Epoch: 480  Training loss = 2.9161  Validation loss = 4.8829  \n",
      "\n",
      "Fold: 10  Epoch: 481  Training loss = 2.9159  Validation loss = 4.8834  \n",
      "\n",
      "Fold: 10  Epoch: 482  Training loss = 2.9156  Validation loss = 4.8824  \n",
      "\n",
      "Fold: 10  Epoch: 483  Training loss = 2.9153  Validation loss = 4.8804  \n",
      "\n",
      "Fold: 10  Epoch: 484  Training loss = 2.9151  Validation loss = 4.8789  \n",
      "\n",
      "Fold: 10  Epoch: 485  Training loss = 2.9148  Validation loss = 4.8777  \n",
      "\n",
      "Fold: 10  Epoch: 486  Training loss = 2.9145  Validation loss = 4.8773  \n",
      "\n",
      "Fold: 10  Epoch: 487  Training loss = 2.9145  Validation loss = 4.8784  \n",
      "\n",
      "Fold: 10  Epoch: 488  Training loss = 2.9143  Validation loss = 4.8783  \n",
      "\n",
      "Fold: 10  Epoch: 489  Training loss = 2.9140  Validation loss = 4.8768  \n",
      "\n",
      "Fold: 10  Epoch: 490  Training loss = 2.9137  Validation loss = 4.8745  \n",
      "\n",
      "Fold: 10  Epoch: 491  Training loss = 2.9136  Validation loss = 4.8757  \n",
      "\n",
      "Fold: 10  Epoch: 492  Training loss = 2.9133  Validation loss = 4.8737  \n",
      "\n",
      "Fold: 10  Epoch: 493  Training loss = 2.9131  Validation loss = 4.8728  \n",
      "\n",
      "Fold: 10  Epoch: 494  Training loss = 2.9128  Validation loss = 4.8710  \n",
      "\n",
      "Fold: 10  Epoch: 495  Training loss = 2.9128  Validation loss = 4.8710  \n",
      "\n",
      "Fold: 10  Epoch: 496  Training loss = 2.9126  Validation loss = 4.8733  \n",
      "\n",
      "Fold: 10  Epoch: 497  Training loss = 2.9125  Validation loss = 4.8733  \n",
      "\n",
      "Fold: 10  Epoch: 498  Training loss = 2.9123  Validation loss = 4.8723  \n",
      "\n",
      "Fold: 10  Epoch: 499  Training loss = 2.9121  Validation loss = 4.8724  \n",
      "\n",
      "Fold: 10  Epoch: 500  Training loss = 2.9119  Validation loss = 4.8710  \n",
      "\n",
      "Check model:  Fold: 10  Optimal epoch: 500  \n",
      "\n",
      "Fold: 11  Epoch: 1  Training loss = 3.0914  Validation loss = 1.9283  \n",
      "\n",
      "Fold: 11  Epoch: 2  Training loss = 3.0904  Validation loss = 1.9223  \n",
      "\n",
      "Fold: 11  Epoch: 3  Training loss = 3.0893  Validation loss = 1.9162  \n",
      "\n",
      "Fold: 11  Epoch: 4  Training loss = 3.0888  Validation loss = 1.9148  \n",
      "\n",
      "Fold: 11  Epoch: 5  Training loss = 3.0878  Validation loss = 1.9095  \n",
      "\n",
      "Fold: 11  Epoch: 6  Training loss = 3.0872  Validation loss = 1.9047  \n",
      "\n",
      "Fold: 11  Epoch: 7  Training loss = 3.0866  Validation loss = 1.9005  \n",
      "\n",
      "Fold: 11  Epoch: 8  Training loss = 3.0858  Validation loss = 1.8934  \n",
      "\n",
      "Fold: 11  Epoch: 9  Training loss = 3.0851  Validation loss = 1.8913  \n",
      "\n",
      "Fold: 11  Epoch: 10  Training loss = 3.0837  Validation loss = 1.8807  \n",
      "\n",
      "Fold: 11  Epoch: 11  Training loss = 3.0826  Validation loss = 1.8727  \n",
      "\n",
      "Fold: 11  Epoch: 12  Training loss = 3.0814  Validation loss = 1.8632  \n",
      "\n",
      "Fold: 11  Epoch: 13  Training loss = 3.0811  Validation loss = 1.8592  \n",
      "\n",
      "Fold: 11  Epoch: 14  Training loss = 3.0802  Validation loss = 1.8527  \n",
      "\n",
      "Fold: 11  Epoch: 15  Training loss = 3.0796  Validation loss = 1.8481  \n",
      "\n",
      "Fold: 11  Epoch: 16  Training loss = 3.0787  Validation loss = 1.8408  \n",
      "\n",
      "Fold: 11  Epoch: 17  Training loss = 3.0781  Validation loss = 1.8387  \n",
      "\n",
      "Fold: 11  Epoch: 18  Training loss = 3.0774  Validation loss = 1.8345  \n",
      "\n",
      "Fold: 11  Epoch: 19  Training loss = 3.0768  Validation loss = 1.8318  \n",
      "\n",
      "Fold: 11  Epoch: 20  Training loss = 3.0754  Validation loss = 1.8240  \n",
      "\n",
      "Fold: 11  Epoch: 21  Training loss = 3.0744  Validation loss = 1.8166  \n",
      "\n",
      "Fold: 11  Epoch: 22  Training loss = 3.0737  Validation loss = 1.8126  \n",
      "\n",
      "Fold: 11  Epoch: 23  Training loss = 3.0723  Validation loss = 1.8028  \n",
      "\n",
      "Fold: 11  Epoch: 24  Training loss = 3.0717  Validation loss = 1.7992  \n",
      "\n",
      "Fold: 11  Epoch: 25  Training loss = 3.0709  Validation loss = 1.7948  \n",
      "\n",
      "Fold: 11  Epoch: 26  Training loss = 3.0698  Validation loss = 1.7874  \n",
      "\n",
      "Fold: 11  Epoch: 27  Training loss = 3.0689  Validation loss = 1.7826  \n",
      "\n",
      "Fold: 11  Epoch: 28  Training loss = 3.0679  Validation loss = 1.7774  \n",
      "\n",
      "Fold: 11  Epoch: 29  Training loss = 3.0671  Validation loss = 1.7728  \n",
      "\n",
      "Fold: 11  Epoch: 30  Training loss = 3.0663  Validation loss = 1.7688  \n",
      "\n",
      "Fold: 11  Epoch: 31  Training loss = 3.0655  Validation loss = 1.7635  \n",
      "\n",
      "Fold: 11  Epoch: 32  Training loss = 3.0652  Validation loss = 1.7625  \n",
      "\n",
      "Fold: 11  Epoch: 33  Training loss = 3.0641  Validation loss = 1.7571  \n",
      "\n",
      "Fold: 11  Epoch: 34  Training loss = 3.0631  Validation loss = 1.7506  \n",
      "\n",
      "Fold: 11  Epoch: 35  Training loss = 3.0626  Validation loss = 1.7485  \n",
      "\n",
      "Fold: 11  Epoch: 36  Training loss = 3.0621  Validation loss = 1.7463  \n",
      "\n",
      "Fold: 11  Epoch: 37  Training loss = 3.0613  Validation loss = 1.7416  \n",
      "\n",
      "Fold: 11  Epoch: 38  Training loss = 3.0604  Validation loss = 1.7376  \n",
      "\n",
      "Fold: 11  Epoch: 39  Training loss = 3.0595  Validation loss = 1.7329  \n",
      "\n",
      "Fold: 11  Epoch: 40  Training loss = 3.0588  Validation loss = 1.7298  \n",
      "\n",
      "Fold: 11  Epoch: 41  Training loss = 3.0579  Validation loss = 1.7263  \n",
      "\n",
      "Fold: 11  Epoch: 42  Training loss = 3.0568  Validation loss = 1.7214  \n",
      "\n",
      "Fold: 11  Epoch: 43  Training loss = 3.0562  Validation loss = 1.7193  \n",
      "\n",
      "Fold: 11  Epoch: 44  Training loss = 3.0557  Validation loss = 1.7177  \n",
      "\n",
      "Fold: 11  Epoch: 45  Training loss = 3.0543  Validation loss = 1.7116  \n",
      "\n",
      "Fold: 11  Epoch: 46  Training loss = 3.0532  Validation loss = 1.7071  \n",
      "\n",
      "Fold: 11  Epoch: 47  Training loss = 3.0520  Validation loss = 1.7028  \n",
      "\n",
      "Fold: 11  Epoch: 48  Training loss = 3.0513  Validation loss = 1.7004  \n",
      "\n",
      "Fold: 11  Epoch: 49  Training loss = 3.0506  Validation loss = 1.6980  \n",
      "\n",
      "Fold: 11  Epoch: 50  Training loss = 3.0496  Validation loss = 1.6951  \n",
      "\n",
      "Fold: 11  Epoch: 51  Training loss = 3.0486  Validation loss = 1.6919  \n",
      "\n",
      "Fold: 11  Epoch: 52  Training loss = 3.0473  Validation loss = 1.6882  \n",
      "\n",
      "Fold: 11  Epoch: 53  Training loss = 3.0457  Validation loss = 1.6840  \n",
      "\n",
      "Fold: 11  Epoch: 54  Training loss = 3.0441  Validation loss = 1.6802  \n",
      "\n",
      "Fold: 11  Epoch: 55  Training loss = 3.0427  Validation loss = 1.6769  \n",
      "\n",
      "Fold: 11  Epoch: 56  Training loss = 3.0419  Validation loss = 1.6754  \n",
      "\n",
      "Fold: 11  Epoch: 57  Training loss = 3.0406  Validation loss = 1.6727  \n",
      "\n",
      "Fold: 11  Epoch: 58  Training loss = 3.0400  Validation loss = 1.6714  \n",
      "\n",
      "Fold: 11  Epoch: 59  Training loss = 3.0391  Validation loss = 1.6701  \n",
      "\n",
      "Fold: 11  Epoch: 60  Training loss = 3.0375  Validation loss = 1.6677  \n",
      "\n",
      "Fold: 11  Epoch: 61  Training loss = 3.0359  Validation loss = 1.6651  \n",
      "\n",
      "Fold: 11  Epoch: 62  Training loss = 3.0344  Validation loss = 1.6632  \n",
      "\n",
      "Fold: 11  Epoch: 63  Training loss = 3.0328  Validation loss = 1.6614  \n",
      "\n",
      "Fold: 11  Epoch: 64  Training loss = 3.0312  Validation loss = 1.6593  \n",
      "\n",
      "Fold: 11  Epoch: 65  Training loss = 3.0288  Validation loss = 1.6565  \n",
      "\n",
      "Fold: 11  Epoch: 66  Training loss = 3.0264  Validation loss = 1.6541  \n",
      "\n",
      "Fold: 11  Epoch: 67  Training loss = 3.0238  Validation loss = 1.6513  \n",
      "\n",
      "Fold: 11  Epoch: 68  Training loss = 3.0229  Validation loss = 1.6505  \n",
      "\n",
      "Fold: 11  Epoch: 69  Training loss = 3.0220  Validation loss = 1.6496  \n",
      "\n",
      "Fold: 11  Epoch: 70  Training loss = 3.0195  Validation loss = 1.6472  \n",
      "\n",
      "Fold: 11  Epoch: 71  Training loss = 3.0186  Validation loss = 1.6462  \n",
      "\n",
      "Fold: 11  Epoch: 72  Training loss = 3.0173  Validation loss = 1.6443  \n",
      "\n",
      "Fold: 11  Epoch: 73  Training loss = 3.0160  Validation loss = 1.6425  \n",
      "\n",
      "Fold: 11  Epoch: 74  Training loss = 3.0151  Validation loss = 1.6409  \n",
      "\n",
      "Fold: 11  Epoch: 75  Training loss = 3.0137  Validation loss = 1.6389  \n",
      "\n",
      "Fold: 11  Epoch: 76  Training loss = 3.0133  Validation loss = 1.6381  \n",
      "\n",
      "Fold: 11  Epoch: 77  Training loss = 3.0122  Validation loss = 1.6372  \n",
      "\n",
      "Fold: 11  Epoch: 78  Training loss = 3.0110  Validation loss = 1.6352  \n",
      "\n",
      "Fold: 11  Epoch: 79  Training loss = 3.0102  Validation loss = 1.6342  \n",
      "\n",
      "Fold: 11  Epoch: 80  Training loss = 3.0094  Validation loss = 1.6329  \n",
      "\n",
      "Fold: 11  Epoch: 81  Training loss = 3.0088  Validation loss = 1.6319  \n",
      "\n",
      "Fold: 11  Epoch: 82  Training loss = 3.0080  Validation loss = 1.6310  \n",
      "\n",
      "Fold: 11  Epoch: 83  Training loss = 3.0040  Validation loss = 1.6303  \n",
      "\n",
      "Fold: 11  Epoch: 84  Training loss = 3.0033  Validation loss = 1.6288  \n",
      "\n",
      "Fold: 11  Epoch: 85  Training loss = 3.0030  Validation loss = 1.6282  \n",
      "\n",
      "Fold: 11  Epoch: 86  Training loss = 3.0026  Validation loss = 1.6272  \n",
      "\n",
      "Fold: 11  Epoch: 87  Training loss = 3.0022  Validation loss = 1.6264  \n",
      "\n",
      "Fold: 11  Epoch: 88  Training loss = 3.0017  Validation loss = 1.6255  \n",
      "\n",
      "Fold: 11  Epoch: 89  Training loss = 3.0012  Validation loss = 1.6249  \n",
      "\n",
      "Fold: 11  Epoch: 90  Training loss = 3.0008  Validation loss = 1.6241  \n",
      "\n",
      "Fold: 11  Epoch: 91  Training loss = 3.0000  Validation loss = 1.6222  \n",
      "\n",
      "Fold: 11  Epoch: 92  Training loss = 2.9995  Validation loss = 1.6209  \n",
      "\n",
      "Fold: 11  Epoch: 93  Training loss = 2.9987  Validation loss = 1.6193  \n",
      "\n",
      "Fold: 11  Epoch: 94  Training loss = 2.9984  Validation loss = 1.6187  \n",
      "\n",
      "Fold: 11  Epoch: 95  Training loss = 2.9978  Validation loss = 1.6176  \n",
      "\n",
      "Fold: 11  Epoch: 96  Training loss = 2.9973  Validation loss = 1.6162  \n",
      "\n",
      "Fold: 11  Epoch: 97  Training loss = 2.9970  Validation loss = 1.6160  \n",
      "\n",
      "Fold: 11  Epoch: 98  Training loss = 2.9964  Validation loss = 1.6146  \n",
      "\n",
      "Fold: 11  Epoch: 99  Training loss = 2.9958  Validation loss = 1.6135  \n",
      "\n",
      "Fold: 11  Epoch: 100  Training loss = 2.9953  Validation loss = 1.6127  \n",
      "\n",
      "Fold: 11  Epoch: 101  Training loss = 2.9947  Validation loss = 1.6116  \n",
      "\n",
      "Fold: 11  Epoch: 102  Training loss = 2.9942  Validation loss = 1.6104  \n",
      "\n",
      "Fold: 11  Epoch: 103  Training loss = 2.9937  Validation loss = 1.6094  \n",
      "\n",
      "Fold: 11  Epoch: 104  Training loss = 2.9930  Validation loss = 1.6079  \n",
      "\n",
      "Fold: 11  Epoch: 105  Training loss = 2.9929  Validation loss = 1.6080  \n",
      "\n",
      "Fold: 11  Epoch: 106  Training loss = 2.9922  Validation loss = 1.6064  \n",
      "\n",
      "Fold: 11  Epoch: 107  Training loss = 2.9914  Validation loss = 1.6043  \n",
      "\n",
      "Fold: 11  Epoch: 108  Training loss = 2.9909  Validation loss = 1.6033  \n",
      "\n",
      "Fold: 11  Epoch: 109  Training loss = 2.9905  Validation loss = 1.6026  \n",
      "\n",
      "Fold: 11  Epoch: 110  Training loss = 2.9903  Validation loss = 1.6025  \n",
      "\n",
      "Fold: 11  Epoch: 111  Training loss = 2.9901  Validation loss = 1.6024  \n",
      "\n",
      "Fold: 11  Epoch: 112  Training loss = 2.9896  Validation loss = 1.6015  \n",
      "\n",
      "Fold: 11  Epoch: 113  Training loss = 2.9893  Validation loss = 1.6011  \n",
      "\n",
      "Fold: 11  Epoch: 114  Training loss = 2.9888  Validation loss = 1.5998  \n",
      "\n",
      "Fold: 11  Epoch: 115  Training loss = 2.9883  Validation loss = 1.5990  \n",
      "\n",
      "Fold: 11  Epoch: 116  Training loss = 2.9880  Validation loss = 1.5985  \n",
      "\n",
      "Fold: 11  Epoch: 117  Training loss = 2.9875  Validation loss = 1.5976  \n",
      "\n",
      "Fold: 11  Epoch: 118  Training loss = 2.9870  Validation loss = 1.5966  \n",
      "\n",
      "Fold: 11  Epoch: 119  Training loss = 2.9866  Validation loss = 1.5957  \n",
      "\n",
      "Fold: 11  Epoch: 120  Training loss = 2.9863  Validation loss = 1.5953  \n",
      "\n",
      "Fold: 11  Epoch: 121  Training loss = 2.9858  Validation loss = 1.5944  \n",
      "\n",
      "Fold: 11  Epoch: 122  Training loss = 2.9857  Validation loss = 1.5942  \n",
      "\n",
      "Fold: 11  Epoch: 123  Training loss = 2.9852  Validation loss = 1.5936  \n",
      "\n",
      "Fold: 11  Epoch: 124  Training loss = 2.9850  Validation loss = 1.5933  \n",
      "\n",
      "Fold: 11  Epoch: 125  Training loss = 2.9848  Validation loss = 1.5932  \n",
      "\n",
      "Fold: 11  Epoch: 126  Training loss = 2.9844  Validation loss = 1.5924  \n",
      "\n",
      "Fold: 11  Epoch: 127  Training loss = 2.9842  Validation loss = 1.5923  \n",
      "\n",
      "Fold: 11  Epoch: 128  Training loss = 2.9840  Validation loss = 1.5920  \n",
      "\n",
      "Fold: 11  Epoch: 129  Training loss = 2.9836  Validation loss = 1.5913  \n",
      "\n",
      "Fold: 11  Epoch: 130  Training loss = 2.9831  Validation loss = 1.5902  \n",
      "\n",
      "Fold: 11  Epoch: 131  Training loss = 2.9826  Validation loss = 1.5891  \n",
      "\n",
      "Fold: 11  Epoch: 132  Training loss = 2.9822  Validation loss = 1.5882  \n",
      "\n",
      "Fold: 11  Epoch: 133  Training loss = 2.9813  Validation loss = 1.5859  \n",
      "\n",
      "Fold: 11  Epoch: 134  Training loss = 2.9807  Validation loss = 1.5847  \n",
      "\n",
      "Fold: 11  Epoch: 135  Training loss = 2.9800  Validation loss = 1.5830  \n",
      "\n",
      "Fold: 11  Epoch: 136  Training loss = 2.9795  Validation loss = 1.5813  \n",
      "\n",
      "Fold: 11  Epoch: 137  Training loss = 2.9789  Validation loss = 1.5796  \n",
      "\n",
      "Fold: 11  Epoch: 138  Training loss = 2.9785  Validation loss = 1.5787  \n",
      "\n",
      "Fold: 11  Epoch: 139  Training loss = 2.9780  Validation loss = 1.5780  \n",
      "\n",
      "Fold: 11  Epoch: 140  Training loss = 2.9776  Validation loss = 1.5767  \n",
      "\n",
      "Fold: 11  Epoch: 141  Training loss = 2.9769  Validation loss = 1.5753  \n",
      "\n",
      "Fold: 11  Epoch: 142  Training loss = 2.9765  Validation loss = 1.5747  \n",
      "\n",
      "Fold: 11  Epoch: 143  Training loss = 2.9761  Validation loss = 1.5738  \n",
      "\n",
      "Fold: 11  Epoch: 144  Training loss = 2.9755  Validation loss = 1.5722  \n",
      "\n",
      "Fold: 11  Epoch: 145  Training loss = 2.9750  Validation loss = 1.5713  \n",
      "\n",
      "Fold: 11  Epoch: 146  Training loss = 2.9744  Validation loss = 1.5697  \n",
      "\n",
      "Fold: 11  Epoch: 147  Training loss = 2.9739  Validation loss = 1.5684  \n",
      "\n",
      "Fold: 11  Epoch: 148  Training loss = 2.9733  Validation loss = 1.5666  \n",
      "\n",
      "Fold: 11  Epoch: 149  Training loss = 2.9729  Validation loss = 1.5659  \n",
      "\n",
      "Fold: 11  Epoch: 150  Training loss = 2.9722  Validation loss = 1.5637  \n",
      "\n",
      "Fold: 11  Epoch: 151  Training loss = 2.9716  Validation loss = 1.5623  \n",
      "\n",
      "Fold: 11  Epoch: 152  Training loss = 2.9711  Validation loss = 1.5613  \n",
      "\n",
      "Fold: 11  Epoch: 153  Training loss = 2.9703  Validation loss = 1.5595  \n",
      "\n",
      "Fold: 11  Epoch: 154  Training loss = 2.9698  Validation loss = 1.5582  \n",
      "\n",
      "Fold: 11  Epoch: 155  Training loss = 2.9694  Validation loss = 1.5575  \n",
      "\n",
      "Fold: 11  Epoch: 156  Training loss = 2.9690  Validation loss = 1.5565  \n",
      "\n",
      "Fold: 11  Epoch: 157  Training loss = 2.9687  Validation loss = 1.5561  \n",
      "\n",
      "Fold: 11  Epoch: 158  Training loss = 2.9685  Validation loss = 1.5558  \n",
      "\n",
      "Fold: 11  Epoch: 159  Training loss = 2.9678  Validation loss = 1.5540  \n",
      "\n",
      "Fold: 11  Epoch: 160  Training loss = 2.9672  Validation loss = 1.5530  \n",
      "\n",
      "Fold: 11  Epoch: 161  Training loss = 2.9669  Validation loss = 1.5526  \n",
      "\n",
      "Fold: 11  Epoch: 162  Training loss = 2.9663  Validation loss = 1.5513  \n",
      "\n",
      "Fold: 11  Epoch: 163  Training loss = 2.9657  Validation loss = 1.5498  \n",
      "\n",
      "Fold: 11  Epoch: 164  Training loss = 2.9653  Validation loss = 1.5488  \n",
      "\n",
      "Fold: 11  Epoch: 165  Training loss = 2.9651  Validation loss = 1.5487  \n",
      "\n",
      "Fold: 11  Epoch: 166  Training loss = 2.9647  Validation loss = 1.5476  \n",
      "\n",
      "Fold: 11  Epoch: 167  Training loss = 2.9642  Validation loss = 1.5468  \n",
      "\n",
      "Fold: 11  Epoch: 168  Training loss = 2.9636  Validation loss = 1.5454  \n",
      "\n",
      "Fold: 11  Epoch: 169  Training loss = 2.9632  Validation loss = 1.5446  \n",
      "\n",
      "Fold: 11  Epoch: 170  Training loss = 2.9626  Validation loss = 1.5429  \n",
      "\n",
      "Fold: 11  Epoch: 171  Training loss = 2.9622  Validation loss = 1.5416  \n",
      "\n",
      "Fold: 11  Epoch: 172  Training loss = 2.9616  Validation loss = 1.5404  \n",
      "\n",
      "Fold: 11  Epoch: 173  Training loss = 2.9608  Validation loss = 1.5375  \n",
      "\n",
      "Fold: 11  Epoch: 174  Training loss = 2.9606  Validation loss = 1.5369  \n",
      "\n",
      "Fold: 11  Epoch: 175  Training loss = 2.9601  Validation loss = 1.5360  \n",
      "\n",
      "Fold: 11  Epoch: 176  Training loss = 2.9598  Validation loss = 1.5356  \n",
      "\n",
      "Fold: 11  Epoch: 177  Training loss = 2.9594  Validation loss = 1.5345  \n",
      "\n",
      "Fold: 11  Epoch: 178  Training loss = 2.9592  Validation loss = 1.5339  \n",
      "\n",
      "Fold: 11  Epoch: 179  Training loss = 2.9585  Validation loss = 1.5324  \n",
      "\n",
      "Fold: 11  Epoch: 180  Training loss = 2.9579  Validation loss = 1.5301  \n",
      "\n",
      "Fold: 11  Epoch: 181  Training loss = 2.9575  Validation loss = 1.5288  \n",
      "\n",
      "Fold: 11  Epoch: 182  Training loss = 2.9571  Validation loss = 1.5284  \n",
      "\n",
      "Fold: 11  Epoch: 183  Training loss = 2.9568  Validation loss = 1.5282  \n",
      "\n",
      "Fold: 11  Epoch: 184  Training loss = 2.9564  Validation loss = 1.5273  \n",
      "\n",
      "Fold: 11  Epoch: 185  Training loss = 2.9558  Validation loss = 1.5246  \n",
      "\n",
      "Fold: 11  Epoch: 186  Training loss = 2.9553  Validation loss = 1.5236  \n",
      "\n",
      "Fold: 11  Epoch: 187  Training loss = 2.9550  Validation loss = 1.5224  \n",
      "\n",
      "Fold: 11  Epoch: 188  Training loss = 2.9546  Validation loss = 1.5213  \n",
      "\n",
      "Fold: 11  Epoch: 189  Training loss = 2.9542  Validation loss = 1.5209  \n",
      "\n",
      "Fold: 11  Epoch: 190  Training loss = 2.9538  Validation loss = 1.5197  \n",
      "\n",
      "Fold: 11  Epoch: 191  Training loss = 2.9534  Validation loss = 1.5179  \n",
      "\n",
      "Fold: 11  Epoch: 192  Training loss = 2.9530  Validation loss = 1.5176  \n",
      "\n",
      "Fold: 11  Epoch: 193  Training loss = 2.9526  Validation loss = 1.5160  \n",
      "\n",
      "Fold: 11  Epoch: 194  Training loss = 2.9520  Validation loss = 1.5144  \n",
      "\n",
      "Fold: 11  Epoch: 195  Training loss = 2.9517  Validation loss = 1.5138  \n",
      "\n",
      "Fold: 11  Epoch: 196  Training loss = 2.9511  Validation loss = 1.5130  \n",
      "\n",
      "Fold: 11  Epoch: 197  Training loss = 2.9506  Validation loss = 1.5114  \n",
      "\n",
      "Fold: 11  Epoch: 198  Training loss = 2.9498  Validation loss = 1.5096  \n",
      "\n",
      "Fold: 11  Epoch: 199  Training loss = 2.9492  Validation loss = 1.5081  \n",
      "\n",
      "Fold: 11  Epoch: 200  Training loss = 2.9488  Validation loss = 1.5076  \n",
      "\n",
      "Fold: 11  Epoch: 201  Training loss = 2.9484  Validation loss = 1.5072  \n",
      "\n",
      "Fold: 11  Epoch: 202  Training loss = 2.9480  Validation loss = 1.5059  \n",
      "\n",
      "Fold: 11  Epoch: 203  Training loss = 2.9478  Validation loss = 1.5058  \n",
      "\n",
      "Fold: 11  Epoch: 204  Training loss = 2.9472  Validation loss = 1.5048  \n",
      "\n",
      "Fold: 11  Epoch: 205  Training loss = 2.9468  Validation loss = 1.5042  \n",
      "\n",
      "Fold: 11  Epoch: 206  Training loss = 2.9463  Validation loss = 1.5026  \n",
      "\n",
      "Fold: 11  Epoch: 207  Training loss = 2.9459  Validation loss = 1.5019  \n",
      "\n",
      "Fold: 11  Epoch: 208  Training loss = 2.9452  Validation loss = 1.4994  \n",
      "\n",
      "Fold: 11  Epoch: 209  Training loss = 2.9448  Validation loss = 1.4984  \n",
      "\n",
      "Fold: 11  Epoch: 210  Training loss = 2.9444  Validation loss = 1.4974  \n",
      "\n",
      "Fold: 11  Epoch: 211  Training loss = 2.9441  Validation loss = 1.4961  \n",
      "\n",
      "Fold: 11  Epoch: 212  Training loss = 2.9438  Validation loss = 1.4955  \n",
      "\n",
      "Fold: 11  Epoch: 213  Training loss = 2.9434  Validation loss = 1.4944  \n",
      "\n",
      "Fold: 11  Epoch: 214  Training loss = 2.9431  Validation loss = 1.4937  \n",
      "\n",
      "Fold: 11  Epoch: 215  Training loss = 2.9424  Validation loss = 1.4920  \n",
      "\n",
      "Fold: 11  Epoch: 216  Training loss = 2.9422  Validation loss = 1.4917  \n",
      "\n",
      "Fold: 11  Epoch: 217  Training loss = 2.9418  Validation loss = 1.4901  \n",
      "\n",
      "Fold: 11  Epoch: 218  Training loss = 2.9414  Validation loss = 1.4887  \n",
      "\n",
      "Fold: 11  Epoch: 219  Training loss = 2.9410  Validation loss = 1.4884  \n",
      "\n",
      "Fold: 11  Epoch: 220  Training loss = 2.9404  Validation loss = 1.4865  \n",
      "\n",
      "Fold: 11  Epoch: 221  Training loss = 2.9401  Validation loss = 1.4853  \n",
      "\n",
      "Fold: 11  Epoch: 222  Training loss = 2.9397  Validation loss = 1.4838  \n",
      "\n",
      "Fold: 11  Epoch: 223  Training loss = 2.9393  Validation loss = 1.4822  \n",
      "\n",
      "Fold: 11  Epoch: 224  Training loss = 2.9388  Validation loss = 1.4805  \n",
      "\n",
      "Fold: 11  Epoch: 225  Training loss = 2.9385  Validation loss = 1.4798  \n",
      "\n",
      "Fold: 11  Epoch: 226  Training loss = 2.9380  Validation loss = 1.4784  \n",
      "\n",
      "Fold: 11  Epoch: 227  Training loss = 2.9375  Validation loss = 1.4777  \n",
      "\n",
      "Fold: 11  Epoch: 228  Training loss = 2.9369  Validation loss = 1.4761  \n",
      "\n",
      "Fold: 11  Epoch: 229  Training loss = 2.9363  Validation loss = 1.4736  \n",
      "\n",
      "Fold: 11  Epoch: 230  Training loss = 2.9359  Validation loss = 1.4720  \n",
      "\n",
      "Fold: 11  Epoch: 231  Training loss = 2.9355  Validation loss = 1.4711  \n",
      "\n",
      "Fold: 11  Epoch: 232  Training loss = 2.9349  Validation loss = 1.4692  \n",
      "\n",
      "Fold: 11  Epoch: 233  Training loss = 2.9344  Validation loss = 1.4670  \n",
      "\n",
      "Fold: 11  Epoch: 234  Training loss = 2.9340  Validation loss = 1.4661  \n",
      "\n",
      "Fold: 11  Epoch: 235  Training loss = 2.9334  Validation loss = 1.4651  \n",
      "\n",
      "Fold: 11  Epoch: 236  Training loss = 2.9328  Validation loss = 1.4623  \n",
      "\n",
      "Fold: 11  Epoch: 237  Training loss = 2.9321  Validation loss = 1.4602  \n",
      "\n",
      "Fold: 11  Epoch: 238  Training loss = 2.9316  Validation loss = 1.4580  \n",
      "\n",
      "Fold: 11  Epoch: 239  Training loss = 2.9307  Validation loss = 1.4554  \n",
      "\n",
      "Fold: 11  Epoch: 240  Training loss = 2.9303  Validation loss = 1.4543  \n",
      "\n",
      "Fold: 11  Epoch: 241  Training loss = 2.9300  Validation loss = 1.4535  \n",
      "\n",
      "Fold: 11  Epoch: 242  Training loss = 2.9298  Validation loss = 1.4533  \n",
      "\n",
      "Fold: 11  Epoch: 243  Training loss = 2.9293  Validation loss = 1.4525  \n",
      "\n",
      "Fold: 11  Epoch: 244  Training loss = 2.9289  Validation loss = 1.4512  \n",
      "\n",
      "Fold: 11  Epoch: 245  Training loss = 2.9285  Validation loss = 1.4496  \n",
      "\n",
      "Fold: 11  Epoch: 246  Training loss = 2.9279  Validation loss = 1.4474  \n",
      "\n",
      "Fold: 11  Epoch: 247  Training loss = 2.9269  Validation loss = 1.4444  \n",
      "\n",
      "Fold: 11  Epoch: 248  Training loss = 2.9267  Validation loss = 1.4440  \n",
      "\n",
      "Fold: 11  Epoch: 249  Training loss = 2.9263  Validation loss = 1.4429  \n",
      "\n",
      "Fold: 11  Epoch: 250  Training loss = 2.9257  Validation loss = 1.4417  \n",
      "\n",
      "Fold: 11  Epoch: 251  Training loss = 2.9252  Validation loss = 1.4400  \n",
      "\n",
      "Fold: 11  Epoch: 252  Training loss = 2.9248  Validation loss = 1.4391  \n",
      "\n",
      "Fold: 11  Epoch: 253  Training loss = 2.9246  Validation loss = 1.4387  \n",
      "\n",
      "Fold: 11  Epoch: 254  Training loss = 2.9242  Validation loss = 1.4380  \n",
      "\n",
      "Fold: 11  Epoch: 255  Training loss = 2.9236  Validation loss = 1.4356  \n",
      "\n",
      "Fold: 11  Epoch: 256  Training loss = 2.9231  Validation loss = 1.4343  \n",
      "\n",
      "Fold: 11  Epoch: 257  Training loss = 2.9226  Validation loss = 1.4323  \n",
      "\n",
      "Fold: 11  Epoch: 258  Training loss = 2.9222  Validation loss = 1.4310  \n",
      "\n",
      "Fold: 11  Epoch: 259  Training loss = 2.9217  Validation loss = 1.4287  \n",
      "\n",
      "Fold: 11  Epoch: 260  Training loss = 2.9213  Validation loss = 1.4279  \n",
      "\n",
      "Fold: 11  Epoch: 261  Training loss = 2.9208  Validation loss = 1.4262  \n",
      "\n",
      "Fold: 11  Epoch: 262  Training loss = 2.9206  Validation loss = 1.4255  \n",
      "\n",
      "Fold: 11  Epoch: 263  Training loss = 2.9201  Validation loss = 1.4243  \n",
      "\n",
      "Fold: 11  Epoch: 264  Training loss = 2.9197  Validation loss = 1.4231  \n",
      "\n",
      "Fold: 11  Epoch: 265  Training loss = 2.9192  Validation loss = 1.4216  \n",
      "\n",
      "Fold: 11  Epoch: 266  Training loss = 2.9188  Validation loss = 1.4207  \n",
      "\n",
      "Fold: 11  Epoch: 267  Training loss = 2.9185  Validation loss = 1.4197  \n",
      "\n",
      "Fold: 11  Epoch: 268  Training loss = 2.9180  Validation loss = 1.4188  \n",
      "\n",
      "Fold: 11  Epoch: 269  Training loss = 2.9177  Validation loss = 1.4176  \n",
      "\n",
      "Fold: 11  Epoch: 270  Training loss = 2.9174  Validation loss = 1.4172  \n",
      "\n",
      "Fold: 11  Epoch: 271  Training loss = 2.9168  Validation loss = 1.4153  \n",
      "\n",
      "Fold: 11  Epoch: 272  Training loss = 2.9164  Validation loss = 1.4140  \n",
      "\n",
      "Fold: 11  Epoch: 273  Training loss = 2.9160  Validation loss = 1.4125  \n",
      "\n",
      "Fold: 11  Epoch: 274  Training loss = 2.9158  Validation loss = 1.4125  \n",
      "\n",
      "Fold: 11  Epoch: 275  Training loss = 2.9156  Validation loss = 1.4121  \n",
      "\n",
      "Fold: 11  Epoch: 276  Training loss = 2.9152  Validation loss = 1.4110  \n",
      "\n",
      "Fold: 11  Epoch: 277  Training loss = 2.9148  Validation loss = 1.4097  \n",
      "\n",
      "Fold: 11  Epoch: 278  Training loss = 2.9143  Validation loss = 1.4086  \n",
      "\n",
      "Fold: 11  Epoch: 279  Training loss = 2.9139  Validation loss = 1.4071  \n",
      "\n",
      "Fold: 11  Epoch: 280  Training loss = 2.9136  Validation loss = 1.4068  \n",
      "\n",
      "Fold: 11  Epoch: 281  Training loss = 2.9132  Validation loss = 1.4057  \n",
      "\n",
      "Fold: 11  Epoch: 282  Training loss = 2.9129  Validation loss = 1.4047  \n",
      "\n",
      "Fold: 11  Epoch: 283  Training loss = 2.9126  Validation loss = 1.4043  \n",
      "\n",
      "Fold: 11  Epoch: 284  Training loss = 2.9121  Validation loss = 1.4030  \n",
      "\n",
      "Fold: 11  Epoch: 285  Training loss = 2.9117  Validation loss = 1.4020  \n",
      "\n",
      "Fold: 11  Epoch: 286  Training loss = 2.9114  Validation loss = 1.4015  \n",
      "\n",
      "Fold: 11  Epoch: 287  Training loss = 2.9109  Validation loss = 1.3998  \n",
      "\n",
      "Fold: 11  Epoch: 288  Training loss = 2.9103  Validation loss = 1.3978  \n",
      "\n",
      "Fold: 11  Epoch: 289  Training loss = 2.9098  Validation loss = 1.3962  \n",
      "\n",
      "Fold: 11  Epoch: 290  Training loss = 2.9095  Validation loss = 1.3957  \n",
      "\n",
      "Fold: 11  Epoch: 291  Training loss = 2.9090  Validation loss = 1.3939  \n",
      "\n",
      "Fold: 11  Epoch: 292  Training loss = 2.9086  Validation loss = 1.3927  \n",
      "\n",
      "Fold: 11  Epoch: 293  Training loss = 2.9082  Validation loss = 1.3919  \n",
      "\n",
      "Fold: 11  Epoch: 294  Training loss = 2.9078  Validation loss = 1.3909  \n",
      "\n",
      "Fold: 11  Epoch: 295  Training loss = 2.9074  Validation loss = 1.3899  \n",
      "\n",
      "Fold: 11  Epoch: 296  Training loss = 2.9069  Validation loss = 1.3888  \n",
      "\n",
      "Fold: 11  Epoch: 297  Training loss = 2.9065  Validation loss = 1.3876  \n",
      "\n",
      "Fold: 11  Epoch: 298  Training loss = 2.9060  Validation loss = 1.3866  \n",
      "\n",
      "Fold: 11  Epoch: 299  Training loss = 2.9053  Validation loss = 1.3846  \n",
      "\n",
      "Fold: 11  Epoch: 300  Training loss = 2.9050  Validation loss = 1.3841  \n",
      "\n",
      "Fold: 11  Epoch: 301  Training loss = 2.9045  Validation loss = 1.3828  \n",
      "\n",
      "Fold: 11  Epoch: 302  Training loss = 2.9041  Validation loss = 1.3821  \n",
      "\n",
      "Fold: 11  Epoch: 303  Training loss = 2.9037  Validation loss = 1.3811  \n",
      "\n",
      "Fold: 11  Epoch: 304  Training loss = 2.9034  Validation loss = 1.3808  \n",
      "\n",
      "Fold: 11  Epoch: 305  Training loss = 2.9030  Validation loss = 1.3799  \n",
      "\n",
      "Fold: 11  Epoch: 306  Training loss = 2.9026  Validation loss = 1.3790  \n",
      "\n",
      "Fold: 11  Epoch: 307  Training loss = 2.9020  Validation loss = 1.3778  \n",
      "\n",
      "Fold: 11  Epoch: 308  Training loss = 2.9017  Validation loss = 1.3773  \n",
      "\n",
      "Fold: 11  Epoch: 309  Training loss = 2.9014  Validation loss = 1.3770  \n",
      "\n",
      "Fold: 11  Epoch: 310  Training loss = 2.9011  Validation loss = 1.3765  \n",
      "\n",
      "Fold: 11  Epoch: 311  Training loss = 2.9006  Validation loss = 1.3756  \n",
      "\n",
      "Fold: 11  Epoch: 312  Training loss = 2.9003  Validation loss = 1.3753  \n",
      "\n",
      "Fold: 11  Epoch: 313  Training loss = 2.8998  Validation loss = 1.3744  \n",
      "\n",
      "Fold: 11  Epoch: 314  Training loss = 2.8992  Validation loss = 1.3730  \n",
      "\n",
      "Fold: 11  Epoch: 315  Training loss = 2.8987  Validation loss = 1.3716  \n",
      "\n",
      "Fold: 11  Epoch: 316  Training loss = 2.8982  Validation loss = 1.3706  \n",
      "\n",
      "Fold: 11  Epoch: 317  Training loss = 2.8977  Validation loss = 1.3697  \n",
      "\n",
      "Fold: 11  Epoch: 318  Training loss = 2.8971  Validation loss = 1.3686  \n",
      "\n",
      "Fold: 11  Epoch: 319  Training loss = 2.8966  Validation loss = 1.3676  \n",
      "\n",
      "Fold: 11  Epoch: 320  Training loss = 2.8960  Validation loss = 1.3661  \n",
      "\n",
      "Fold: 11  Epoch: 321  Training loss = 2.8955  Validation loss = 1.3655  \n",
      "\n",
      "Fold: 11  Epoch: 322  Training loss = 2.8949  Validation loss = 1.3641  \n",
      "\n",
      "Fold: 11  Epoch: 323  Training loss = 2.8944  Validation loss = 1.3635  \n",
      "\n",
      "Fold: 11  Epoch: 324  Training loss = 2.8938  Validation loss = 1.3621  \n",
      "\n",
      "Fold: 11  Epoch: 325  Training loss = 2.8934  Validation loss = 1.3616  \n",
      "\n",
      "Fold: 11  Epoch: 326  Training loss = 2.8931  Validation loss = 1.3610  \n",
      "\n",
      "Fold: 11  Epoch: 327  Training loss = 2.8929  Validation loss = 1.3610  \n",
      "\n",
      "Fold: 11  Epoch: 328  Training loss = 2.8923  Validation loss = 1.3598  \n",
      "\n",
      "Fold: 11  Epoch: 329  Training loss = 2.8920  Validation loss = 1.3593  \n",
      "\n",
      "Fold: 11  Epoch: 330  Training loss = 2.8914  Validation loss = 1.3584  \n",
      "\n",
      "Fold: 11  Epoch: 331  Training loss = 2.8910  Validation loss = 1.3578  \n",
      "\n",
      "Fold: 11  Epoch: 332  Training loss = 2.8905  Validation loss = 1.3571  \n",
      "\n",
      "Fold: 11  Epoch: 333  Training loss = 2.8900  Validation loss = 1.3564  \n",
      "\n",
      "Fold: 11  Epoch: 334  Training loss = 2.8897  Validation loss = 1.3560  \n",
      "\n",
      "Fold: 11  Epoch: 335  Training loss = 2.8891  Validation loss = 1.3551  \n",
      "\n",
      "Fold: 11  Epoch: 336  Training loss = 2.8886  Validation loss = 1.3545  \n",
      "\n",
      "Fold: 11  Epoch: 337  Training loss = 2.8884  Validation loss = 1.3546  \n",
      "\n",
      "Fold: 11  Epoch: 338  Training loss = 2.8879  Validation loss = 1.3539  \n",
      "\n",
      "Fold: 11  Epoch: 339  Training loss = 2.8875  Validation loss = 1.3535  \n",
      "\n",
      "Fold: 11  Epoch: 340  Training loss = 2.8872  Validation loss = 1.3533  \n",
      "\n",
      "Fold: 11  Epoch: 341  Training loss = 2.8868  Validation loss = 1.3528  \n",
      "\n",
      "Fold: 11  Epoch: 342  Training loss = 2.8862  Validation loss = 1.3520  \n",
      "\n",
      "Fold: 11  Epoch: 343  Training loss = 2.8858  Validation loss = 1.3515  \n",
      "\n",
      "Fold: 11  Epoch: 344  Training loss = 2.8854  Validation loss = 1.3508  \n",
      "\n",
      "Fold: 11  Epoch: 345  Training loss = 2.8851  Validation loss = 1.3503  \n",
      "\n",
      "Fold: 11  Epoch: 346  Training loss = 2.8846  Validation loss = 1.3497  \n",
      "\n",
      "Fold: 11  Epoch: 347  Training loss = 2.8842  Validation loss = 1.3494  \n",
      "\n",
      "Fold: 11  Epoch: 348  Training loss = 2.8839  Validation loss = 1.3489  \n",
      "\n",
      "Fold: 11  Epoch: 349  Training loss = 2.8833  Validation loss = 1.3482  \n",
      "\n",
      "Fold: 11  Epoch: 350  Training loss = 2.8829  Validation loss = 1.3477  \n",
      "\n",
      "Fold: 11  Epoch: 351  Training loss = 2.8824  Validation loss = 1.3471  \n",
      "\n",
      "Fold: 11  Epoch: 352  Training loss = 2.8821  Validation loss = 1.3470  \n",
      "\n",
      "Fold: 11  Epoch: 353  Training loss = 2.8816  Validation loss = 1.3467  \n",
      "\n",
      "Fold: 11  Epoch: 354  Training loss = 2.8810  Validation loss = 1.3458  \n",
      "\n",
      "Fold: 11  Epoch: 355  Training loss = 2.8804  Validation loss = 1.3453  \n",
      "\n",
      "Fold: 11  Epoch: 356  Training loss = 2.8798  Validation loss = 1.3447  \n",
      "\n",
      "Fold: 11  Epoch: 357  Training loss = 2.8794  Validation loss = 1.3442  \n",
      "\n",
      "Fold: 11  Epoch: 358  Training loss = 2.8791  Validation loss = 1.3442  \n",
      "\n",
      "Fold: 11  Epoch: 359  Training loss = 2.8784  Validation loss = 1.3434  \n",
      "\n",
      "Fold: 11  Epoch: 360  Training loss = 2.8780  Validation loss = 1.3430  \n",
      "\n",
      "Fold: 11  Epoch: 361  Training loss = 2.8776  Validation loss = 1.3427  \n",
      "\n",
      "Fold: 11  Epoch: 362  Training loss = 2.8769  Validation loss = 1.3421  \n",
      "\n",
      "Fold: 11  Epoch: 363  Training loss = 2.8766  Validation loss = 1.3419  \n",
      "\n",
      "Fold: 11  Epoch: 364  Training loss = 2.8762  Validation loss = 1.3418  \n",
      "\n",
      "Fold: 11  Epoch: 365  Training loss = 2.8756  Validation loss = 1.3410  \n",
      "\n",
      "Fold: 11  Epoch: 366  Training loss = 2.8749  Validation loss = 1.3400  \n",
      "\n",
      "Fold: 11  Epoch: 367  Training loss = 2.8746  Validation loss = 1.3400  \n",
      "\n",
      "Fold: 11  Epoch: 368  Training loss = 2.8740  Validation loss = 1.3391  \n",
      "\n",
      "Fold: 11  Epoch: 369  Training loss = 2.8737  Validation loss = 1.3390  \n",
      "\n",
      "Fold: 11  Epoch: 370  Training loss = 2.8732  Validation loss = 1.3384  \n",
      "\n",
      "Fold: 11  Epoch: 371  Training loss = 2.8729  Validation loss = 1.3385  \n",
      "\n",
      "Fold: 11  Epoch: 372  Training loss = 2.8725  Validation loss = 1.3379  \n",
      "\n",
      "Fold: 11  Epoch: 373  Training loss = 2.8721  Validation loss = 1.3376  \n",
      "\n",
      "Fold: 11  Epoch: 374  Training loss = 2.8718  Validation loss = 1.3374  \n",
      "\n",
      "Fold: 11  Epoch: 375  Training loss = 2.8715  Validation loss = 1.3372  \n",
      "\n",
      "Fold: 11  Epoch: 376  Training loss = 2.8710  Validation loss = 1.3368  \n",
      "\n",
      "Fold: 11  Epoch: 377  Training loss = 2.8706  Validation loss = 1.3365  \n",
      "\n",
      "Fold: 11  Epoch: 378  Training loss = 2.8700  Validation loss = 1.3359  \n",
      "\n",
      "Fold: 11  Epoch: 379  Training loss = 2.8695  Validation loss = 1.3351  \n",
      "\n",
      "Fold: 11  Epoch: 380  Training loss = 2.8693  Validation loss = 1.3354  \n",
      "\n",
      "Fold: 11  Epoch: 381  Training loss = 2.8689  Validation loss = 1.3351  \n",
      "\n",
      "Fold: 11  Epoch: 382  Training loss = 2.8683  Validation loss = 1.3347  \n",
      "\n",
      "Fold: 11  Epoch: 383  Training loss = 2.8678  Validation loss = 1.3343  \n",
      "\n",
      "Fold: 11  Epoch: 384  Training loss = 2.8675  Validation loss = 1.3342  \n",
      "\n",
      "Fold: 11  Epoch: 385  Training loss = 2.8671  Validation loss = 1.3339  \n",
      "\n",
      "Fold: 11  Epoch: 386  Training loss = 2.8667  Validation loss = 1.3339  \n",
      "\n",
      "Fold: 11  Epoch: 387  Training loss = 2.8662  Validation loss = 1.3335  \n",
      "\n",
      "Fold: 11  Epoch: 388  Training loss = 2.8658  Validation loss = 1.3333  \n",
      "\n",
      "Fold: 11  Epoch: 389  Training loss = 2.8656  Validation loss = 1.3333  \n",
      "\n",
      "Fold: 11  Epoch: 390  Training loss = 2.8652  Validation loss = 1.3330  \n",
      "\n",
      "Fold: 11  Epoch: 391  Training loss = 2.8648  Validation loss = 1.3328  \n",
      "\n",
      "Fold: 11  Epoch: 392  Training loss = 2.8643  Validation loss = 1.3327  \n",
      "\n",
      "Fold: 11  Epoch: 393  Training loss = 2.8637  Validation loss = 1.3320  \n",
      "\n",
      "Fold: 11  Epoch: 394  Training loss = 2.8634  Validation loss = 1.3319  \n",
      "\n",
      "Fold: 11  Epoch: 395  Training loss = 2.8629  Validation loss = 1.3315  \n",
      "\n",
      "Fold: 11  Epoch: 396  Training loss = 2.8627  Validation loss = 1.3316  \n",
      "\n",
      "Fold: 11  Epoch: 397  Training loss = 2.8624  Validation loss = 1.3315  \n",
      "\n",
      "Fold: 11  Epoch: 398  Training loss = 2.8621  Validation loss = 1.3314  \n",
      "\n",
      "Fold: 11  Epoch: 399  Training loss = 2.8618  Validation loss = 1.3314  \n",
      "\n",
      "Fold: 11  Epoch: 400  Training loss = 2.8613  Validation loss = 1.3311  \n",
      "\n",
      "Fold: 11  Epoch: 401  Training loss = 2.8609  Validation loss = 1.3309  \n",
      "\n",
      "Fold: 11  Epoch: 402  Training loss = 2.8606  Validation loss = 1.3307  \n",
      "\n",
      "Fold: 11  Epoch: 403  Training loss = 2.8602  Validation loss = 1.3307  \n",
      "\n",
      "Fold: 11  Epoch: 404  Training loss = 2.8598  Validation loss = 1.3306  \n",
      "\n",
      "Fold: 11  Epoch: 405  Training loss = 2.8594  Validation loss = 1.3305  \n",
      "\n",
      "Fold: 11  Epoch: 406  Training loss = 2.8591  Validation loss = 1.3303  \n",
      "\n",
      "Fold: 11  Epoch: 407  Training loss = 2.8585  Validation loss = 1.3300  \n",
      "\n",
      "Fold: 11  Epoch: 408  Training loss = 2.8582  Validation loss = 1.3298  \n",
      "\n",
      "Fold: 11  Epoch: 409  Training loss = 2.8578  Validation loss = 1.3297  \n",
      "\n",
      "Fold: 11  Epoch: 410  Training loss = 2.8574  Validation loss = 1.3296  \n",
      "\n",
      "Fold: 11  Epoch: 411  Training loss = 2.8569  Validation loss = 1.3293  \n",
      "\n",
      "Fold: 11  Epoch: 412  Training loss = 2.8566  Validation loss = 1.3293  \n",
      "\n",
      "Fold: 11  Epoch: 413  Training loss = 2.8563  Validation loss = 1.3290  \n",
      "\n",
      "Fold: 11  Epoch: 414  Training loss = 2.8559  Validation loss = 1.3289  \n",
      "\n",
      "Fold: 11  Epoch: 415  Training loss = 2.8555  Validation loss = 1.3288  \n",
      "\n",
      "Fold: 11  Epoch: 416  Training loss = 2.8551  Validation loss = 1.3287  \n",
      "\n",
      "Fold: 11  Epoch: 417  Training loss = 2.8547  Validation loss = 1.3284  \n",
      "\n",
      "Fold: 11  Epoch: 418  Training loss = 2.8543  Validation loss = 1.3282  \n",
      "\n",
      "Fold: 11  Epoch: 419  Training loss = 2.8539  Validation loss = 1.3280  \n",
      "\n",
      "Fold: 11  Epoch: 420  Training loss = 2.8535  Validation loss = 1.3278  \n",
      "\n",
      "Fold: 11  Epoch: 421  Training loss = 2.8532  Validation loss = 1.3278  \n",
      "\n",
      "Fold: 11  Epoch: 422  Training loss = 2.8529  Validation loss = 1.3279  \n",
      "\n",
      "Fold: 11  Epoch: 423  Training loss = 2.8525  Validation loss = 1.3277  \n",
      "\n",
      "Fold: 11  Epoch: 424  Training loss = 2.8520  Validation loss = 1.3273  \n",
      "\n",
      "Fold: 11  Epoch: 425  Training loss = 2.8516  Validation loss = 1.3272  \n",
      "\n",
      "Fold: 11  Epoch: 426  Training loss = 2.8513  Validation loss = 1.3271  \n",
      "\n",
      "Fold: 11  Epoch: 427  Training loss = 2.8507  Validation loss = 1.3270  \n",
      "\n",
      "Fold: 11  Epoch: 428  Training loss = 2.8504  Validation loss = 1.3272  \n",
      "\n",
      "Fold: 11  Epoch: 429  Training loss = 2.8502  Validation loss = 1.3272  \n",
      "\n",
      "Fold: 11  Epoch: 430  Training loss = 2.8499  Validation loss = 1.3273  \n",
      "\n",
      "Fold: 11  Epoch: 431  Training loss = 2.8496  Validation loss = 1.3272  \n",
      "\n",
      "Fold: 11  Epoch: 432  Training loss = 2.8490  Validation loss = 1.3267  \n",
      "\n",
      "Fold: 11  Epoch: 433  Training loss = 2.8486  Validation loss = 1.3263  \n",
      "\n",
      "Fold: 11  Epoch: 434  Training loss = 2.8482  Validation loss = 1.3261  \n",
      "\n",
      "Fold: 11  Epoch: 435  Training loss = 2.8477  Validation loss = 1.3256  \n",
      "\n",
      "Fold: 11  Epoch: 436  Training loss = 2.8475  Validation loss = 1.3255  \n",
      "\n",
      "Fold: 11  Epoch: 437  Training loss = 2.8471  Validation loss = 1.3253  \n",
      "\n",
      "Fold: 11  Epoch: 438  Training loss = 2.8465  Validation loss = 1.3248  \n",
      "\n",
      "Fold: 11  Epoch: 439  Training loss = 2.8461  Validation loss = 1.3246  \n",
      "\n",
      "Fold: 11  Epoch: 440  Training loss = 2.8458  Validation loss = 1.3246  \n",
      "\n",
      "Fold: 11  Epoch: 441  Training loss = 2.8453  Validation loss = 1.3240  \n",
      "\n",
      "Fold: 11  Epoch: 442  Training loss = 2.8449  Validation loss = 1.3238  \n",
      "\n",
      "Fold: 11  Epoch: 443  Training loss = 2.8445  Validation loss = 1.3238  \n",
      "\n",
      "Fold: 11  Epoch: 444  Training loss = 2.8441  Validation loss = 1.3237  \n",
      "\n",
      "Fold: 11  Epoch: 445  Training loss = 2.8438  Validation loss = 1.3236  \n",
      "\n",
      "Fold: 11  Epoch: 446  Training loss = 2.8434  Validation loss = 1.3233  \n",
      "\n",
      "Fold: 11  Epoch: 447  Training loss = 2.8432  Validation loss = 1.3231  \n",
      "\n",
      "Fold: 11  Epoch: 448  Training loss = 2.8428  Validation loss = 1.3230  \n",
      "\n",
      "Fold: 11  Epoch: 449  Training loss = 2.8426  Validation loss = 1.3230  \n",
      "\n",
      "Fold: 11  Epoch: 450  Training loss = 2.8422  Validation loss = 1.3228  \n",
      "\n",
      "Fold: 11  Epoch: 451  Training loss = 2.8418  Validation loss = 1.3226  \n",
      "\n",
      "Fold: 11  Epoch: 452  Training loss = 2.8414  Validation loss = 1.3225  \n",
      "\n",
      "Fold: 11  Epoch: 453  Training loss = 2.8408  Validation loss = 1.3219  \n",
      "\n",
      "Fold: 11  Epoch: 454  Training loss = 2.8404  Validation loss = 1.3219  \n",
      "\n",
      "Fold: 11  Epoch: 455  Training loss = 2.8399  Validation loss = 1.3217  \n",
      "\n",
      "Fold: 11  Epoch: 456  Training loss = 2.8393  Validation loss = 1.3215  \n",
      "\n",
      "Fold: 11  Epoch: 457  Training loss = 2.8391  Validation loss = 1.3217  \n",
      "\n",
      "Fold: 11  Epoch: 458  Training loss = 2.8387  Validation loss = 1.3215  \n",
      "\n",
      "Fold: 11  Epoch: 459  Training loss = 2.8384  Validation loss = 1.3214  \n",
      "\n",
      "Fold: 11  Epoch: 460  Training loss = 2.8379  Validation loss = 1.3212  \n",
      "\n",
      "Fold: 11  Epoch: 461  Training loss = 2.8376  Validation loss = 1.3213  \n",
      "\n",
      "Fold: 11  Epoch: 462  Training loss = 2.8372  Validation loss = 1.3210  \n",
      "\n",
      "Fold: 11  Epoch: 463  Training loss = 2.8368  Validation loss = 1.3211  \n",
      "\n",
      "Fold: 11  Epoch: 464  Training loss = 2.8365  Validation loss = 1.3211  \n",
      "\n",
      "Fold: 11  Epoch: 465  Training loss = 2.8361  Validation loss = 1.3210  \n",
      "\n",
      "Fold: 11  Epoch: 466  Training loss = 2.8357  Validation loss = 1.3209  \n",
      "\n",
      "Fold: 11  Epoch: 467  Training loss = 2.8354  Validation loss = 1.3209  \n",
      "\n",
      "Fold: 11  Epoch: 468  Training loss = 2.8351  Validation loss = 1.3210  \n",
      "\n",
      "Fold: 11  Epoch: 469  Training loss = 2.8347  Validation loss = 1.3208  \n",
      "\n",
      "Fold: 11  Epoch: 470  Training loss = 2.8343  Validation loss = 1.3206  \n",
      "\n",
      "Fold: 11  Epoch: 471  Training loss = 2.8338  Validation loss = 1.3201  \n",
      "\n",
      "Fold: 11  Epoch: 472  Training loss = 2.8334  Validation loss = 1.3201  \n",
      "\n",
      "Fold: 11  Epoch: 473  Training loss = 2.8329  Validation loss = 1.3201  \n",
      "\n",
      "Fold: 11  Epoch: 474  Training loss = 2.8325  Validation loss = 1.3200  \n",
      "\n",
      "Fold: 11  Epoch: 475  Training loss = 2.8323  Validation loss = 1.3200  \n",
      "\n",
      "Fold: 11  Epoch: 476  Training loss = 2.8320  Validation loss = 1.3201  \n",
      "\n",
      "Fold: 11  Epoch: 477  Training loss = 2.8318  Validation loss = 1.3201  \n",
      "\n",
      "Fold: 11  Epoch: 478  Training loss = 2.8315  Validation loss = 1.3204  \n",
      "\n",
      "Fold: 11  Epoch: 479  Training loss = 2.8312  Validation loss = 1.3202  \n",
      "\n",
      "Fold: 11  Epoch: 480  Training loss = 2.8305  Validation loss = 1.3200  \n",
      "\n",
      "Fold: 11  Epoch: 481  Training loss = 2.8301  Validation loss = 1.3199  \n",
      "\n",
      "Fold: 11  Epoch: 482  Training loss = 2.8298  Validation loss = 1.3197  \n",
      "\n",
      "Fold: 11  Epoch: 483  Training loss = 2.8295  Validation loss = 1.3199  \n",
      "\n",
      "Fold: 11  Epoch: 484  Training loss = 2.8293  Validation loss = 1.3199  \n",
      "\n",
      "Fold: 11  Epoch: 485  Training loss = 2.8288  Validation loss = 1.3196  \n",
      "\n",
      "Fold: 11  Epoch: 486  Training loss = 2.8286  Validation loss = 1.3199  \n",
      "\n",
      "Fold: 11  Epoch: 487  Training loss = 2.8284  Validation loss = 1.3198  \n",
      "\n",
      "Fold: 11  Epoch: 488  Training loss = 2.8282  Validation loss = 1.3199  \n",
      "\n",
      "Fold: 11  Epoch: 489  Training loss = 2.8279  Validation loss = 1.3199  \n",
      "\n",
      "Fold: 11  Epoch: 490  Training loss = 2.8275  Validation loss = 1.3195  \n",
      "\n",
      "Fold: 11  Epoch: 491  Training loss = 2.8271  Validation loss = 1.3194  \n",
      "\n",
      "Fold: 11  Epoch: 492  Training loss = 2.8267  Validation loss = 1.3194  \n",
      "\n",
      "Fold: 11  Epoch: 493  Training loss = 2.8263  Validation loss = 1.3193  \n",
      "\n",
      "Fold: 11  Epoch: 494  Training loss = 2.8260  Validation loss = 1.3195  \n",
      "\n",
      "Fold: 11  Epoch: 495  Training loss = 2.8257  Validation loss = 1.3194  \n",
      "\n",
      "Fold: 11  Epoch: 496  Training loss = 2.8254  Validation loss = 1.3194  \n",
      "\n",
      "Fold: 11  Epoch: 497  Training loss = 2.8250  Validation loss = 1.3195  \n",
      "\n",
      "Fold: 11  Epoch: 498  Training loss = 2.8245  Validation loss = 1.3195  \n",
      "\n",
      "Fold: 11  Epoch: 499  Training loss = 2.8243  Validation loss = 1.3195  \n",
      "\n",
      "Fold: 11  Epoch: 500  Training loss = 2.8240  Validation loss = 1.3194  \n",
      "\n",
      "Check model:  Fold: 11  Optimal epoch: 493  \n",
      "\n",
      "Fold: 12  Epoch: 1  Training loss = 2.8030  Validation loss = 1.9678  \n",
      "\n",
      "Fold: 12  Epoch: 2  Training loss = 2.8025  Validation loss = 1.9653  \n",
      "\n",
      "Fold: 12  Epoch: 3  Training loss = 2.8022  Validation loss = 1.9640  \n",
      "\n",
      "Fold: 12  Epoch: 4  Training loss = 2.8018  Validation loss = 1.9619  \n",
      "\n",
      "Fold: 12  Epoch: 5  Training loss = 2.8013  Validation loss = 1.9597  \n",
      "\n",
      "Fold: 12  Epoch: 6  Training loss = 2.8011  Validation loss = 1.9591  \n",
      "\n",
      "Fold: 12  Epoch: 7  Training loss = 2.8007  Validation loss = 1.9579  \n",
      "\n",
      "Fold: 12  Epoch: 8  Training loss = 2.8005  Validation loss = 1.9566  \n",
      "\n",
      "Fold: 12  Epoch: 9  Training loss = 2.8000  Validation loss = 1.9546  \n",
      "\n",
      "Fold: 12  Epoch: 10  Training loss = 2.7996  Validation loss = 1.9529  \n",
      "\n",
      "Fold: 12  Epoch: 11  Training loss = 2.7992  Validation loss = 1.9503  \n",
      "\n",
      "Fold: 12  Epoch: 12  Training loss = 2.7987  Validation loss = 1.9479  \n",
      "\n",
      "Fold: 12  Epoch: 13  Training loss = 2.7983  Validation loss = 1.9468  \n",
      "\n",
      "Fold: 12  Epoch: 14  Training loss = 2.7976  Validation loss = 1.9428  \n",
      "\n",
      "Fold: 12  Epoch: 15  Training loss = 2.7972  Validation loss = 1.9404  \n",
      "\n",
      "Fold: 12  Epoch: 16  Training loss = 2.7967  Validation loss = 1.9382  \n",
      "\n",
      "Fold: 12  Epoch: 17  Training loss = 2.7962  Validation loss = 1.9361  \n",
      "\n",
      "Fold: 12  Epoch: 18  Training loss = 2.7958  Validation loss = 1.9344  \n",
      "\n",
      "Fold: 12  Epoch: 19  Training loss = 2.7955  Validation loss = 1.9341  \n",
      "\n",
      "Fold: 12  Epoch: 20  Training loss = 2.7951  Validation loss = 1.9327  \n",
      "\n",
      "Fold: 12  Epoch: 21  Training loss = 2.7948  Validation loss = 1.9322  \n",
      "\n",
      "Fold: 12  Epoch: 22  Training loss = 2.7943  Validation loss = 1.9294  \n",
      "\n",
      "Fold: 12  Epoch: 23  Training loss = 2.7939  Validation loss = 1.9275  \n",
      "\n",
      "Fold: 12  Epoch: 24  Training loss = 2.7935  Validation loss = 1.9256  \n",
      "\n",
      "Fold: 12  Epoch: 25  Training loss = 2.7932  Validation loss = 1.9245  \n",
      "\n",
      "Fold: 12  Epoch: 26  Training loss = 2.7926  Validation loss = 1.9211  \n",
      "\n",
      "Fold: 12  Epoch: 27  Training loss = 2.7923  Validation loss = 1.9196  \n",
      "\n",
      "Fold: 12  Epoch: 28  Training loss = 2.7919  Validation loss = 1.9180  \n",
      "\n",
      "Fold: 12  Epoch: 29  Training loss = 2.7914  Validation loss = 1.9159  \n",
      "\n",
      "Fold: 12  Epoch: 30  Training loss = 2.7911  Validation loss = 1.9157  \n",
      "\n",
      "Fold: 12  Epoch: 31  Training loss = 2.7909  Validation loss = 1.9152  \n",
      "\n",
      "Fold: 12  Epoch: 32  Training loss = 2.7906  Validation loss = 1.9138  \n",
      "\n",
      "Fold: 12  Epoch: 33  Training loss = 2.7903  Validation loss = 1.9131  \n",
      "\n",
      "Fold: 12  Epoch: 34  Training loss = 2.7899  Validation loss = 1.9113  \n",
      "\n",
      "Fold: 12  Epoch: 35  Training loss = 2.7895  Validation loss = 1.9092  \n",
      "\n",
      "Fold: 12  Epoch: 36  Training loss = 2.7890  Validation loss = 1.9072  \n",
      "\n",
      "Fold: 12  Epoch: 37  Training loss = 2.7886  Validation loss = 1.9054  \n",
      "\n",
      "Fold: 12  Epoch: 38  Training loss = 2.7883  Validation loss = 1.9048  \n",
      "\n",
      "Fold: 12  Epoch: 39  Training loss = 2.7878  Validation loss = 1.9017  \n",
      "\n",
      "Fold: 12  Epoch: 40  Training loss = 2.7876  Validation loss = 1.9020  \n",
      "\n",
      "Fold: 12  Epoch: 41  Training loss = 2.7871  Validation loss = 1.8984  \n",
      "\n",
      "Fold: 12  Epoch: 42  Training loss = 2.7867  Validation loss = 1.8965  \n",
      "\n",
      "Fold: 12  Epoch: 43  Training loss = 2.7864  Validation loss = 1.8958  \n",
      "\n",
      "Fold: 12  Epoch: 44  Training loss = 2.7860  Validation loss = 1.8944  \n",
      "\n",
      "Fold: 12  Epoch: 45  Training loss = 2.7857  Validation loss = 1.8936  \n",
      "\n",
      "Fold: 12  Epoch: 46  Training loss = 2.7852  Validation loss = 1.8919  \n",
      "\n",
      "Fold: 12  Epoch: 47  Training loss = 2.7848  Validation loss = 1.8887  \n",
      "\n",
      "Fold: 12  Epoch: 48  Training loss = 2.7845  Validation loss = 1.8878  \n",
      "\n",
      "Fold: 12  Epoch: 49  Training loss = 2.7839  Validation loss = 1.8843  \n",
      "\n",
      "Fold: 12  Epoch: 50  Training loss = 2.7835  Validation loss = 1.8829  \n",
      "\n",
      "Fold: 12  Epoch: 51  Training loss = 2.7833  Validation loss = 1.8825  \n",
      "\n",
      "Fold: 12  Epoch: 52  Training loss = 2.7829  Validation loss = 1.8805  \n",
      "\n",
      "Fold: 12  Epoch: 53  Training loss = 2.7826  Validation loss = 1.8790  \n",
      "\n",
      "Fold: 12  Epoch: 54  Training loss = 2.7822  Validation loss = 1.8771  \n",
      "\n",
      "Fold: 12  Epoch: 55  Training loss = 2.7819  Validation loss = 1.8770  \n",
      "\n",
      "Fold: 12  Epoch: 56  Training loss = 2.7815  Validation loss = 1.8753  \n",
      "\n",
      "Fold: 12  Epoch: 57  Training loss = 2.7814  Validation loss = 1.8758  \n",
      "\n",
      "Fold: 12  Epoch: 58  Training loss = 2.7811  Validation loss = 1.8743  \n",
      "\n",
      "Fold: 12  Epoch: 59  Training loss = 2.7807  Validation loss = 1.8742  \n",
      "\n",
      "Fold: 12  Epoch: 60  Training loss = 2.7804  Validation loss = 1.8735  \n",
      "\n",
      "Fold: 12  Epoch: 61  Training loss = 2.7801  Validation loss = 1.8725  \n",
      "\n",
      "Fold: 12  Epoch: 62  Training loss = 2.7799  Validation loss = 1.8715  \n",
      "\n",
      "Fold: 12  Epoch: 63  Training loss = 2.7795  Validation loss = 1.8699  \n",
      "\n",
      "Fold: 12  Epoch: 64  Training loss = 2.7792  Validation loss = 1.8687  \n",
      "\n",
      "Fold: 12  Epoch: 65  Training loss = 2.7789  Validation loss = 1.8691  \n",
      "\n",
      "Fold: 12  Epoch: 66  Training loss = 2.7786  Validation loss = 1.8672  \n",
      "\n",
      "Fold: 12  Epoch: 67  Training loss = 2.7783  Validation loss = 1.8671  \n",
      "\n",
      "Fold: 12  Epoch: 68  Training loss = 2.7779  Validation loss = 1.8651  \n",
      "\n",
      "Fold: 12  Epoch: 69  Training loss = 2.7775  Validation loss = 1.8643  \n",
      "\n",
      "Fold: 12  Epoch: 70  Training loss = 2.7773  Validation loss = 1.8638  \n",
      "\n",
      "Fold: 12  Epoch: 71  Training loss = 2.7771  Validation loss = 1.8633  \n",
      "\n",
      "Fold: 12  Epoch: 72  Training loss = 2.7765  Validation loss = 1.8603  \n",
      "\n",
      "Fold: 12  Epoch: 73  Training loss = 2.7763  Validation loss = 1.8608  \n",
      "\n",
      "Fold: 12  Epoch: 74  Training loss = 2.7759  Validation loss = 1.8588  \n",
      "\n",
      "Fold: 12  Epoch: 75  Training loss = 2.7754  Validation loss = 1.8572  \n",
      "\n",
      "Fold: 12  Epoch: 76  Training loss = 2.7749  Validation loss = 1.8543  \n",
      "\n",
      "Fold: 12  Epoch: 77  Training loss = 2.7746  Validation loss = 1.8543  \n",
      "\n",
      "Fold: 12  Epoch: 78  Training loss = 2.7743  Validation loss = 1.8538  \n",
      "\n",
      "Fold: 12  Epoch: 79  Training loss = 2.7739  Validation loss = 1.8513  \n",
      "\n",
      "Fold: 12  Epoch: 80  Training loss = 2.7735  Validation loss = 1.8506  \n",
      "\n",
      "Fold: 12  Epoch: 81  Training loss = 2.7730  Validation loss = 1.8473  \n",
      "\n",
      "Fold: 12  Epoch: 82  Training loss = 2.7726  Validation loss = 1.8456  \n",
      "\n",
      "Fold: 12  Epoch: 83  Training loss = 2.7722  Validation loss = 1.8441  \n",
      "\n",
      "Fold: 12  Epoch: 84  Training loss = 2.7718  Validation loss = 1.8426  \n",
      "\n",
      "Fold: 12  Epoch: 85  Training loss = 2.7715  Validation loss = 1.8414  \n",
      "\n",
      "Fold: 12  Epoch: 86  Training loss = 2.7712  Validation loss = 1.8406  \n",
      "\n",
      "Fold: 12  Epoch: 87  Training loss = 2.7709  Validation loss = 1.8394  \n",
      "\n",
      "Fold: 12  Epoch: 88  Training loss = 2.7704  Validation loss = 1.8375  \n",
      "\n",
      "Fold: 12  Epoch: 89  Training loss = 2.7698  Validation loss = 1.8338  \n",
      "\n",
      "Fold: 12  Epoch: 90  Training loss = 2.7693  Validation loss = 1.8307  \n",
      "\n",
      "Fold: 12  Epoch: 91  Training loss = 2.7690  Validation loss = 1.8298  \n",
      "\n",
      "Fold: 12  Epoch: 92  Training loss = 2.7687  Validation loss = 1.8301  \n",
      "\n",
      "Fold: 12  Epoch: 93  Training loss = 2.7683  Validation loss = 1.8291  \n",
      "\n",
      "Fold: 12  Epoch: 94  Training loss = 2.7679  Validation loss = 1.8286  \n",
      "\n",
      "Fold: 12  Epoch: 95  Training loss = 2.7674  Validation loss = 1.8277  \n",
      "\n",
      "Fold: 12  Epoch: 96  Training loss = 2.7669  Validation loss = 1.8256  \n",
      "\n",
      "Fold: 12  Epoch: 97  Training loss = 2.7661  Validation loss = 1.8262  \n",
      "\n",
      "Fold: 12  Epoch: 98  Training loss = 2.7654  Validation loss = 1.8239  \n",
      "\n",
      "Fold: 12  Epoch: 99  Training loss = 2.7649  Validation loss = 1.8224  \n",
      "\n",
      "Fold: 12  Epoch: 100  Training loss = 2.7646  Validation loss = 1.8217  \n",
      "\n",
      "Fold: 12  Epoch: 101  Training loss = 2.7642  Validation loss = 1.8197  \n",
      "\n",
      "Fold: 12  Epoch: 102  Training loss = 2.7638  Validation loss = 1.8174  \n",
      "\n",
      "Fold: 12  Epoch: 103  Training loss = 2.7633  Validation loss = 1.8158  \n",
      "\n",
      "Fold: 12  Epoch: 104  Training loss = 2.7631  Validation loss = 1.8162  \n",
      "\n",
      "Fold: 12  Epoch: 105  Training loss = 2.7630  Validation loss = 1.8167  \n",
      "\n",
      "Fold: 12  Epoch: 106  Training loss = 2.7627  Validation loss = 1.8159  \n",
      "\n",
      "Fold: 12  Epoch: 107  Training loss = 2.7624  Validation loss = 1.8147  \n",
      "\n",
      "Fold: 12  Epoch: 108  Training loss = 2.7621  Validation loss = 1.8136  \n",
      "\n",
      "Fold: 12  Epoch: 109  Training loss = 2.7617  Validation loss = 1.8127  \n",
      "\n",
      "Fold: 12  Epoch: 110  Training loss = 2.7614  Validation loss = 1.8117  \n",
      "\n",
      "Fold: 12  Epoch: 111  Training loss = 2.7611  Validation loss = 1.8103  \n",
      "\n",
      "Fold: 12  Epoch: 112  Training loss = 2.7607  Validation loss = 1.8095  \n",
      "\n",
      "Fold: 12  Epoch: 113  Training loss = 2.7604  Validation loss = 1.8086  \n",
      "\n",
      "Fold: 12  Epoch: 114  Training loss = 2.7600  Validation loss = 1.8071  \n",
      "\n",
      "Fold: 12  Epoch: 115  Training loss = 2.7597  Validation loss = 1.8070  \n",
      "\n",
      "Fold: 12  Epoch: 116  Training loss = 2.7593  Validation loss = 1.8058  \n",
      "\n",
      "Fold: 12  Epoch: 117  Training loss = 2.7589  Validation loss = 1.8045  \n",
      "\n",
      "Fold: 12  Epoch: 118  Training loss = 2.7585  Validation loss = 1.8018  \n",
      "\n",
      "Fold: 12  Epoch: 119  Training loss = 2.7582  Validation loss = 1.8014  \n",
      "\n",
      "Fold: 12  Epoch: 120  Training loss = 2.7578  Validation loss = 1.7988  \n",
      "\n",
      "Fold: 12  Epoch: 121  Training loss = 2.7573  Validation loss = 1.7975  \n",
      "\n",
      "Fold: 12  Epoch: 122  Training loss = 2.7571  Validation loss = 1.7980  \n",
      "\n",
      "Fold: 12  Epoch: 123  Training loss = 2.7565  Validation loss = 1.7947  \n",
      "\n",
      "Fold: 12  Epoch: 124  Training loss = 2.7562  Validation loss = 1.7939  \n",
      "\n",
      "Fold: 12  Epoch: 125  Training loss = 2.7558  Validation loss = 1.7929  \n",
      "\n",
      "Fold: 12  Epoch: 126  Training loss = 2.7555  Validation loss = 1.7918  \n",
      "\n",
      "Fold: 12  Epoch: 127  Training loss = 2.7552  Validation loss = 1.7901  \n",
      "\n",
      "Fold: 12  Epoch: 128  Training loss = 2.7549  Validation loss = 1.7897  \n",
      "\n",
      "Fold: 12  Epoch: 129  Training loss = 2.7545  Validation loss = 1.7878  \n",
      "\n",
      "Fold: 12  Epoch: 130  Training loss = 2.7542  Validation loss = 1.7869  \n",
      "\n",
      "Fold: 12  Epoch: 131  Training loss = 2.7538  Validation loss = 1.7847  \n",
      "\n",
      "Fold: 12  Epoch: 132  Training loss = 2.7535  Validation loss = 1.7835  \n",
      "\n",
      "Fold: 12  Epoch: 133  Training loss = 2.7531  Validation loss = 1.7821  \n",
      "\n",
      "Fold: 12  Epoch: 134  Training loss = 2.7528  Validation loss = 1.7814  \n",
      "\n",
      "Fold: 12  Epoch: 135  Training loss = 2.7525  Validation loss = 1.7792  \n",
      "\n",
      "Fold: 12  Epoch: 136  Training loss = 2.7522  Validation loss = 1.7781  \n",
      "\n",
      "Fold: 12  Epoch: 137  Training loss = 2.7518  Validation loss = 1.7770  \n",
      "\n",
      "Fold: 12  Epoch: 138  Training loss = 2.7515  Validation loss = 1.7759  \n",
      "\n",
      "Fold: 12  Epoch: 139  Training loss = 2.7510  Validation loss = 1.7726  \n",
      "\n",
      "Fold: 12  Epoch: 140  Training loss = 2.7508  Validation loss = 1.7712  \n",
      "\n",
      "Fold: 12  Epoch: 141  Training loss = 2.7505  Validation loss = 1.7705  \n",
      "\n",
      "Fold: 12  Epoch: 142  Training loss = 2.7501  Validation loss = 1.7680  \n",
      "\n",
      "Fold: 12  Epoch: 143  Training loss = 2.7498  Validation loss = 1.7665  \n",
      "\n",
      "Fold: 12  Epoch: 144  Training loss = 2.7495  Validation loss = 1.7647  \n",
      "\n",
      "Fold: 12  Epoch: 145  Training loss = 2.7492  Validation loss = 1.7642  \n",
      "\n",
      "Fold: 12  Epoch: 146  Training loss = 2.7487  Validation loss = 1.7617  \n",
      "\n",
      "Fold: 12  Epoch: 147  Training loss = 2.7483  Validation loss = 1.7596  \n",
      "\n",
      "Fold: 12  Epoch: 148  Training loss = 2.7478  Validation loss = 1.7571  \n",
      "\n",
      "Fold: 12  Epoch: 149  Training loss = 2.7475  Validation loss = 1.7568  \n",
      "\n",
      "Fold: 12  Epoch: 150  Training loss = 2.7472  Validation loss = 1.7562  \n",
      "\n",
      "Fold: 12  Epoch: 151  Training loss = 2.7469  Validation loss = 1.7560  \n",
      "\n",
      "Fold: 12  Epoch: 152  Training loss = 2.7466  Validation loss = 1.7554  \n",
      "\n",
      "Fold: 12  Epoch: 153  Training loss = 2.7461  Validation loss = 1.7549  \n",
      "\n",
      "Fold: 12  Epoch: 154  Training loss = 2.7458  Validation loss = 1.7552  \n",
      "\n",
      "Fold: 12  Epoch: 155  Training loss = 2.7455  Validation loss = 1.7559  \n",
      "\n",
      "Fold: 12  Epoch: 156  Training loss = 2.7452  Validation loss = 1.7543  \n",
      "\n",
      "Fold: 12  Epoch: 157  Training loss = 2.7449  Validation loss = 1.7541  \n",
      "\n",
      "Fold: 12  Epoch: 158  Training loss = 2.7443  Validation loss = 1.7523  \n",
      "\n",
      "Fold: 12  Epoch: 159  Training loss = 2.7439  Validation loss = 1.7511  \n",
      "\n",
      "Fold: 12  Epoch: 160  Training loss = 2.7437  Validation loss = 1.7521  \n",
      "\n",
      "Fold: 12  Epoch: 161  Training loss = 2.7434  Validation loss = 1.7511  \n",
      "\n",
      "Fold: 12  Epoch: 162  Training loss = 2.7429  Validation loss = 1.7486  \n",
      "\n",
      "Fold: 12  Epoch: 163  Training loss = 2.7425  Validation loss = 1.7461  \n",
      "\n",
      "Fold: 12  Epoch: 164  Training loss = 2.7422  Validation loss = 1.7456  \n",
      "\n",
      "Fold: 12  Epoch: 165  Training loss = 2.7417  Validation loss = 1.7427  \n",
      "\n",
      "Fold: 12  Epoch: 166  Training loss = 2.7413  Validation loss = 1.7413  \n",
      "\n",
      "Fold: 12  Epoch: 167  Training loss = 2.7409  Validation loss = 1.7410  \n",
      "\n",
      "Fold: 12  Epoch: 168  Training loss = 2.7407  Validation loss = 1.7407  \n",
      "\n",
      "Fold: 12  Epoch: 169  Training loss = 2.7405  Validation loss = 1.7408  \n",
      "\n",
      "Fold: 12  Epoch: 170  Training loss = 2.7402  Validation loss = 1.7407  \n",
      "\n",
      "Fold: 12  Epoch: 171  Training loss = 2.7398  Validation loss = 1.7396  \n",
      "\n",
      "Fold: 12  Epoch: 172  Training loss = 2.7395  Validation loss = 1.7391  \n",
      "\n",
      "Fold: 12  Epoch: 173  Training loss = 2.7391  Validation loss = 1.7383  \n",
      "\n",
      "Fold: 12  Epoch: 174  Training loss = 2.7387  Validation loss = 1.7375  \n",
      "\n",
      "Fold: 12  Epoch: 175  Training loss = 2.7385  Validation loss = 1.7373  \n",
      "\n",
      "Fold: 12  Epoch: 176  Training loss = 2.7381  Validation loss = 1.7368  \n",
      "\n",
      "Fold: 12  Epoch: 177  Training loss = 2.7377  Validation loss = 1.7359  \n",
      "\n",
      "Fold: 12  Epoch: 178  Training loss = 2.7372  Validation loss = 1.7343  \n",
      "\n",
      "Fold: 12  Epoch: 179  Training loss = 2.7368  Validation loss = 1.7332  \n",
      "\n",
      "Fold: 12  Epoch: 180  Training loss = 2.7363  Validation loss = 1.7304  \n",
      "\n",
      "Fold: 12  Epoch: 181  Training loss = 2.7358  Validation loss = 1.7271  \n",
      "\n",
      "Fold: 12  Epoch: 182  Training loss = 2.7355  Validation loss = 1.7255  \n",
      "\n",
      "Fold: 12  Epoch: 183  Training loss = 2.7352  Validation loss = 1.7252  \n",
      "\n",
      "Fold: 12  Epoch: 184  Training loss = 2.7348  Validation loss = 1.7237  \n",
      "\n",
      "Fold: 12  Epoch: 185  Training loss = 2.7343  Validation loss = 1.7215  \n",
      "\n",
      "Fold: 12  Epoch: 186  Training loss = 2.7340  Validation loss = 1.7201  \n",
      "\n",
      "Fold: 12  Epoch: 187  Training loss = 2.7337  Validation loss = 1.7194  \n",
      "\n",
      "Fold: 12  Epoch: 188  Training loss = 2.7332  Validation loss = 1.7174  \n",
      "\n",
      "Fold: 12  Epoch: 189  Training loss = 2.7328  Validation loss = 1.7151  \n",
      "\n",
      "Fold: 12  Epoch: 190  Training loss = 2.7323  Validation loss = 1.7132  \n",
      "\n",
      "Fold: 12  Epoch: 191  Training loss = 2.7317  Validation loss = 1.7096  \n",
      "\n",
      "Fold: 12  Epoch: 192  Training loss = 2.7312  Validation loss = 1.7085  \n",
      "\n",
      "Fold: 12  Epoch: 193  Training loss = 2.7310  Validation loss = 1.7090  \n",
      "\n",
      "Fold: 12  Epoch: 194  Training loss = 2.7307  Validation loss = 1.7089  \n",
      "\n",
      "Fold: 12  Epoch: 195  Training loss = 2.7303  Validation loss = 1.7069  \n",
      "\n",
      "Fold: 12  Epoch: 196  Training loss = 2.7300  Validation loss = 1.7062  \n",
      "\n",
      "Fold: 12  Epoch: 197  Training loss = 2.7296  Validation loss = 1.7045  \n",
      "\n",
      "Fold: 12  Epoch: 198  Training loss = 2.7292  Validation loss = 1.7040  \n",
      "\n",
      "Fold: 12  Epoch: 199  Training loss = 2.7290  Validation loss = 1.7035  \n",
      "\n",
      "Fold: 12  Epoch: 200  Training loss = 2.7285  Validation loss = 1.7016  \n",
      "\n",
      "Fold: 12  Epoch: 201  Training loss = 2.7281  Validation loss = 1.7003  \n",
      "\n",
      "Fold: 12  Epoch: 202  Training loss = 2.7277  Validation loss = 1.6995  \n",
      "\n",
      "Fold: 12  Epoch: 203  Training loss = 2.7275  Validation loss = 1.7010  \n",
      "\n",
      "Fold: 12  Epoch: 204  Training loss = 2.7272  Validation loss = 1.6988  \n",
      "\n",
      "Fold: 12  Epoch: 205  Training loss = 2.7267  Validation loss = 1.6976  \n",
      "\n",
      "Fold: 12  Epoch: 206  Training loss = 2.7264  Validation loss = 1.6955  \n",
      "\n",
      "Fold: 12  Epoch: 207  Training loss = 2.7260  Validation loss = 1.6967  \n",
      "\n",
      "Fold: 12  Epoch: 208  Training loss = 2.7255  Validation loss = 1.6932  \n",
      "\n",
      "Fold: 12  Epoch: 209  Training loss = 2.7253  Validation loss = 1.6937  \n",
      "\n",
      "Fold: 12  Epoch: 210  Training loss = 2.7249  Validation loss = 1.6933  \n",
      "\n",
      "Fold: 12  Epoch: 211  Training loss = 2.7245  Validation loss = 1.6909  \n",
      "\n",
      "Fold: 12  Epoch: 212  Training loss = 2.7243  Validation loss = 1.6912  \n",
      "\n",
      "Fold: 12  Epoch: 213  Training loss = 2.7239  Validation loss = 1.6906  \n",
      "\n",
      "Fold: 12  Epoch: 214  Training loss = 2.7235  Validation loss = 1.6910  \n",
      "\n",
      "Fold: 12  Epoch: 215  Training loss = 2.7231  Validation loss = 1.6897  \n",
      "\n",
      "Fold: 12  Epoch: 216  Training loss = 2.7226  Validation loss = 1.6889  \n",
      "\n",
      "Fold: 12  Epoch: 217  Training loss = 2.7224  Validation loss = 1.6893  \n",
      "\n",
      "Fold: 12  Epoch: 218  Training loss = 2.7219  Validation loss = 1.6884  \n",
      "\n",
      "Fold: 12  Epoch: 219  Training loss = 2.7215  Validation loss = 1.6866  \n",
      "\n",
      "Fold: 12  Epoch: 220  Training loss = 2.7211  Validation loss = 1.6870  \n",
      "\n",
      "Fold: 12  Epoch: 221  Training loss = 2.7206  Validation loss = 1.6851  \n",
      "\n",
      "Fold: 12  Epoch: 222  Training loss = 2.7202  Validation loss = 1.6844  \n",
      "\n",
      "Fold: 12  Epoch: 223  Training loss = 2.7198  Validation loss = 1.6839  \n",
      "\n",
      "Fold: 12  Epoch: 224  Training loss = 2.7195  Validation loss = 1.6833  \n",
      "\n",
      "Fold: 12  Epoch: 225  Training loss = 2.7190  Validation loss = 1.6821  \n",
      "\n",
      "Fold: 12  Epoch: 226  Training loss = 2.7187  Validation loss = 1.6797  \n",
      "\n",
      "Fold: 12  Epoch: 227  Training loss = 2.7183  Validation loss = 1.6781  \n",
      "\n",
      "Fold: 12  Epoch: 228  Training loss = 2.7179  Validation loss = 1.6773  \n",
      "\n",
      "Fold: 12  Epoch: 229  Training loss = 2.7176  Validation loss = 1.6761  \n",
      "\n",
      "Fold: 12  Epoch: 230  Training loss = 2.7172  Validation loss = 1.6746  \n",
      "\n",
      "Fold: 12  Epoch: 231  Training loss = 2.7167  Validation loss = 1.6733  \n",
      "\n",
      "Fold: 12  Epoch: 232  Training loss = 2.7163  Validation loss = 1.6719  \n",
      "\n",
      "Fold: 12  Epoch: 233  Training loss = 2.7159  Validation loss = 1.6715  \n",
      "\n",
      "Fold: 12  Epoch: 234  Training loss = 2.7155  Validation loss = 1.6712  \n",
      "\n",
      "Fold: 12  Epoch: 235  Training loss = 2.7151  Validation loss = 1.6693  \n",
      "\n",
      "Fold: 12  Epoch: 236  Training loss = 2.7147  Validation loss = 1.6680  \n",
      "\n",
      "Fold: 12  Epoch: 237  Training loss = 2.7143  Validation loss = 1.6655  \n",
      "\n",
      "Fold: 12  Epoch: 238  Training loss = 2.7139  Validation loss = 1.6649  \n",
      "\n",
      "Fold: 12  Epoch: 239  Training loss = 2.7134  Validation loss = 1.6631  \n",
      "\n",
      "Fold: 12  Epoch: 240  Training loss = 2.7130  Validation loss = 1.6609  \n",
      "\n",
      "Fold: 12  Epoch: 241  Training loss = 2.7124  Validation loss = 1.6584  \n",
      "\n",
      "Fold: 12  Epoch: 242  Training loss = 2.7120  Validation loss = 1.6589  \n",
      "\n",
      "Fold: 12  Epoch: 243  Training loss = 2.7116  Validation loss = 1.6570  \n",
      "\n",
      "Fold: 12  Epoch: 244  Training loss = 2.7113  Validation loss = 1.6563  \n",
      "\n",
      "Fold: 12  Epoch: 245  Training loss = 2.7109  Validation loss = 1.6551  \n",
      "\n",
      "Fold: 12  Epoch: 246  Training loss = 2.7104  Validation loss = 1.6547  \n",
      "\n",
      "Fold: 12  Epoch: 247  Training loss = 2.7101  Validation loss = 1.6544  \n",
      "\n",
      "Fold: 12  Epoch: 248  Training loss = 2.7097  Validation loss = 1.6533  \n",
      "\n",
      "Fold: 12  Epoch: 249  Training loss = 2.7094  Validation loss = 1.6533  \n",
      "\n",
      "Fold: 12  Epoch: 250  Training loss = 2.7089  Validation loss = 1.6520  \n",
      "\n",
      "Fold: 12  Epoch: 251  Training loss = 2.7085  Validation loss = 1.6522  \n",
      "\n",
      "Fold: 12  Epoch: 252  Training loss = 2.7081  Validation loss = 1.6525  \n",
      "\n",
      "Fold: 12  Epoch: 253  Training loss = 2.7078  Validation loss = 1.6524  \n",
      "\n",
      "Fold: 12  Epoch: 254  Training loss = 2.7074  Validation loss = 1.6530  \n",
      "\n",
      "Fold: 12  Epoch: 255  Training loss = 2.7070  Validation loss = 1.6524  \n",
      "\n",
      "Fold: 12  Epoch: 256  Training loss = 2.7065  Validation loss = 1.6521  \n",
      "\n",
      "Fold: 12  Epoch: 257  Training loss = 2.7061  Validation loss = 1.6496  \n",
      "\n",
      "Fold: 12  Epoch: 258  Training loss = 2.7058  Validation loss = 1.6499  \n",
      "\n",
      "Fold: 12  Epoch: 259  Training loss = 2.7053  Validation loss = 1.6483  \n",
      "\n",
      "Fold: 12  Epoch: 260  Training loss = 2.7049  Validation loss = 1.6479  \n",
      "\n",
      "Fold: 12  Epoch: 261  Training loss = 2.7044  Validation loss = 1.6461  \n",
      "\n",
      "Fold: 12  Epoch: 262  Training loss = 2.7040  Validation loss = 1.6445  \n",
      "\n",
      "Fold: 12  Epoch: 263  Training loss = 2.7036  Validation loss = 1.6434  \n",
      "\n",
      "Fold: 12  Epoch: 264  Training loss = 2.7031  Validation loss = 1.6417  \n",
      "\n",
      "Fold: 12  Epoch: 265  Training loss = 2.7024  Validation loss = 1.6395  \n",
      "\n",
      "Fold: 12  Epoch: 266  Training loss = 2.7020  Validation loss = 1.6389  \n",
      "\n",
      "Fold: 12  Epoch: 267  Training loss = 2.7015  Validation loss = 1.6389  \n",
      "\n",
      "Fold: 12  Epoch: 268  Training loss = 2.7012  Validation loss = 1.6382  \n",
      "\n",
      "Fold: 12  Epoch: 269  Training loss = 2.7008  Validation loss = 1.6383  \n",
      "\n",
      "Fold: 12  Epoch: 270  Training loss = 2.7005  Validation loss = 1.6382  \n",
      "\n",
      "Fold: 12  Epoch: 271  Training loss = 2.7002  Validation loss = 1.6364  \n",
      "\n",
      "Fold: 12  Epoch: 272  Training loss = 2.6998  Validation loss = 1.6358  \n",
      "\n",
      "Fold: 12  Epoch: 273  Training loss = 2.6995  Validation loss = 1.6348  \n",
      "\n",
      "Fold: 12  Epoch: 274  Training loss = 2.6990  Validation loss = 1.6337  \n",
      "\n",
      "Fold: 12  Epoch: 275  Training loss = 2.6986  Validation loss = 1.6321  \n",
      "\n",
      "Fold: 12  Epoch: 276  Training loss = 2.6983  Validation loss = 1.6318  \n",
      "\n",
      "Fold: 12  Epoch: 277  Training loss = 2.6978  Validation loss = 1.6294  \n",
      "\n",
      "Fold: 12  Epoch: 278  Training loss = 2.6974  Validation loss = 1.6284  \n",
      "\n",
      "Fold: 12  Epoch: 279  Training loss = 2.6971  Validation loss = 1.6284  \n",
      "\n",
      "Fold: 12  Epoch: 280  Training loss = 2.6966  Validation loss = 1.6267  \n",
      "\n",
      "Fold: 12  Epoch: 281  Training loss = 2.6961  Validation loss = 1.6243  \n",
      "\n",
      "Fold: 12  Epoch: 282  Training loss = 2.6956  Validation loss = 1.6229  \n",
      "\n",
      "Fold: 12  Epoch: 283  Training loss = 2.6952  Validation loss = 1.6217  \n",
      "\n",
      "Fold: 12  Epoch: 284  Training loss = 2.6949  Validation loss = 1.6225  \n",
      "\n",
      "Fold: 12  Epoch: 285  Training loss = 2.6945  Validation loss = 1.6218  \n",
      "\n",
      "Fold: 12  Epoch: 286  Training loss = 2.6942  Validation loss = 1.6200  \n",
      "\n",
      "Fold: 12  Epoch: 287  Training loss = 2.6938  Validation loss = 1.6189  \n",
      "\n",
      "Fold: 12  Epoch: 288  Training loss = 2.6934  Validation loss = 1.6174  \n",
      "\n",
      "Fold: 12  Epoch: 289  Training loss = 2.6930  Validation loss = 1.6172  \n",
      "\n",
      "Fold: 12  Epoch: 290  Training loss = 2.6925  Validation loss = 1.6149  \n",
      "\n",
      "Fold: 12  Epoch: 291  Training loss = 2.6920  Validation loss = 1.6135  \n",
      "\n",
      "Fold: 12  Epoch: 292  Training loss = 2.6916  Validation loss = 1.6113  \n",
      "\n",
      "Fold: 12  Epoch: 293  Training loss = 2.6912  Validation loss = 1.6093  \n",
      "\n",
      "Fold: 12  Epoch: 294  Training loss = 2.6910  Validation loss = 1.6082  \n",
      "\n",
      "Fold: 12  Epoch: 295  Training loss = 2.6907  Validation loss = 1.6092  \n",
      "\n",
      "Fold: 12  Epoch: 296  Training loss = 2.6904  Validation loss = 1.6083  \n",
      "\n",
      "Fold: 12  Epoch: 297  Training loss = 2.6900  Validation loss = 1.6091  \n",
      "\n",
      "Fold: 12  Epoch: 298  Training loss = 2.6895  Validation loss = 1.6084  \n",
      "\n",
      "Fold: 12  Epoch: 299  Training loss = 2.6892  Validation loss = 1.6104  \n",
      "\n",
      "Fold: 12  Epoch: 300  Training loss = 2.6889  Validation loss = 1.6108  \n",
      "\n",
      "Fold: 12  Epoch: 301  Training loss = 2.6884  Validation loss = 1.6107  \n",
      "\n",
      "Fold: 12  Epoch: 302  Training loss = 2.6880  Validation loss = 1.6089  \n",
      "\n",
      "Fold: 12  Epoch: 303  Training loss = 2.6877  Validation loss = 1.6078  \n",
      "\n",
      "Fold: 12  Epoch: 304  Training loss = 2.6873  Validation loss = 1.6052  \n",
      "\n",
      "Fold: 12  Epoch: 305  Training loss = 2.6868  Validation loss = 1.6034  \n",
      "\n",
      "Fold: 12  Epoch: 306  Training loss = 2.6863  Validation loss = 1.6011  \n",
      "\n",
      "Fold: 12  Epoch: 307  Training loss = 2.6858  Validation loss = 1.5997  \n",
      "\n",
      "Fold: 12  Epoch: 308  Training loss = 2.6854  Validation loss = 1.5985  \n",
      "\n",
      "Fold: 12  Epoch: 309  Training loss = 2.6849  Validation loss = 1.5973  \n",
      "\n",
      "Fold: 12  Epoch: 310  Training loss = 2.6844  Validation loss = 1.5955  \n",
      "\n",
      "Fold: 12  Epoch: 311  Training loss = 2.6839  Validation loss = 1.5956  \n",
      "\n",
      "Fold: 12  Epoch: 312  Training loss = 2.6835  Validation loss = 1.5937  \n",
      "\n",
      "Fold: 12  Epoch: 313  Training loss = 2.6831  Validation loss = 1.5933  \n",
      "\n",
      "Fold: 12  Epoch: 314  Training loss = 2.6826  Validation loss = 1.5927  \n",
      "\n",
      "Fold: 12  Epoch: 315  Training loss = 2.6823  Validation loss = 1.5933  \n",
      "\n",
      "Fold: 12  Epoch: 316  Training loss = 2.6819  Validation loss = 1.5937  \n",
      "\n",
      "Fold: 12  Epoch: 317  Training loss = 2.6816  Validation loss = 1.5929  \n",
      "\n",
      "Fold: 12  Epoch: 318  Training loss = 2.6812  Validation loss = 1.5917  \n",
      "\n",
      "Fold: 12  Epoch: 319  Training loss = 2.6808  Validation loss = 1.5919  \n",
      "\n",
      "Fold: 12  Epoch: 320  Training loss = 2.6803  Validation loss = 1.5903  \n",
      "\n",
      "Fold: 12  Epoch: 321  Training loss = 2.6799  Validation loss = 1.5886  \n",
      "\n",
      "Fold: 12  Epoch: 322  Training loss = 2.6794  Validation loss = 1.5880  \n",
      "\n",
      "Fold: 12  Epoch: 323  Training loss = 2.6790  Validation loss = 1.5871  \n",
      "\n",
      "Fold: 12  Epoch: 324  Training loss = 2.6785  Validation loss = 1.5838  \n",
      "\n",
      "Fold: 12  Epoch: 325  Training loss = 2.6781  Validation loss = 1.5824  \n",
      "\n",
      "Fold: 12  Epoch: 326  Training loss = 2.6775  Validation loss = 1.5818  \n",
      "\n",
      "Fold: 12  Epoch: 327  Training loss = 2.6771  Validation loss = 1.5821  \n",
      "\n",
      "Fold: 12  Epoch: 328  Training loss = 2.6767  Validation loss = 1.5796  \n",
      "\n",
      "Fold: 12  Epoch: 329  Training loss = 2.6762  Validation loss = 1.5795  \n",
      "\n",
      "Fold: 12  Epoch: 330  Training loss = 2.6756  Validation loss = 1.5769  \n",
      "\n",
      "Fold: 12  Epoch: 331  Training loss = 2.6750  Validation loss = 1.5750  \n",
      "\n",
      "Fold: 12  Epoch: 332  Training loss = 2.6744  Validation loss = 1.5743  \n",
      "\n",
      "Fold: 12  Epoch: 333  Training loss = 2.6740  Validation loss = 1.5742  \n",
      "\n",
      "Fold: 12  Epoch: 334  Training loss = 2.6735  Validation loss = 1.5720  \n",
      "\n",
      "Fold: 12  Epoch: 335  Training loss = 2.6731  Validation loss = 1.5721  \n",
      "\n",
      "Fold: 12  Epoch: 336  Training loss = 2.6727  Validation loss = 1.5708  \n",
      "\n",
      "Fold: 12  Epoch: 337  Training loss = 2.6724  Validation loss = 1.5727  \n",
      "\n",
      "Fold: 12  Epoch: 338  Training loss = 2.6720  Validation loss = 1.5713  \n",
      "\n",
      "Fold: 12  Epoch: 339  Training loss = 2.6718  Validation loss = 1.5719  \n",
      "\n",
      "Fold: 12  Epoch: 340  Training loss = 2.6713  Validation loss = 1.5705  \n",
      "\n",
      "Fold: 12  Epoch: 341  Training loss = 2.6709  Validation loss = 1.5674  \n",
      "\n",
      "Fold: 12  Epoch: 342  Training loss = 2.6705  Validation loss = 1.5670  \n",
      "\n",
      "Fold: 12  Epoch: 343  Training loss = 2.6701  Validation loss = 1.5678  \n",
      "\n",
      "Fold: 12  Epoch: 344  Training loss = 2.6696  Validation loss = 1.5658  \n",
      "\n",
      "Fold: 12  Epoch: 345  Training loss = 2.6691  Validation loss = 1.5654  \n",
      "\n",
      "Fold: 12  Epoch: 346  Training loss = 2.6687  Validation loss = 1.5653  \n",
      "\n",
      "Fold: 12  Epoch: 347  Training loss = 2.6683  Validation loss = 1.5639  \n",
      "\n",
      "Fold: 12  Epoch: 348  Training loss = 2.6679  Validation loss = 1.5622  \n",
      "\n",
      "Fold: 12  Epoch: 349  Training loss = 2.6677  Validation loss = 1.5627  \n",
      "\n",
      "Fold: 12  Epoch: 350  Training loss = 2.6670  Validation loss = 1.5618  \n",
      "\n",
      "Fold: 12  Epoch: 351  Training loss = 2.6666  Validation loss = 1.5603  \n",
      "\n",
      "Fold: 12  Epoch: 352  Training loss = 2.6662  Validation loss = 1.5586  \n",
      "\n",
      "Fold: 12  Epoch: 353  Training loss = 2.6657  Validation loss = 1.5576  \n",
      "\n",
      "Fold: 12  Epoch: 354  Training loss = 2.6651  Validation loss = 1.5556  \n",
      "\n",
      "Fold: 12  Epoch: 355  Training loss = 2.6647  Validation loss = 1.5534  \n",
      "\n",
      "Fold: 12  Epoch: 356  Training loss = 2.6643  Validation loss = 1.5539  \n",
      "\n",
      "Fold: 12  Epoch: 357  Training loss = 2.6640  Validation loss = 1.5530  \n",
      "\n",
      "Fold: 12  Epoch: 358  Training loss = 2.6638  Validation loss = 1.5526  \n",
      "\n",
      "Fold: 12  Epoch: 359  Training loss = 2.6633  Validation loss = 1.5519  \n",
      "\n",
      "Fold: 12  Epoch: 360  Training loss = 2.6629  Validation loss = 1.5509  \n",
      "\n",
      "Fold: 12  Epoch: 361  Training loss = 2.6625  Validation loss = 1.5503  \n",
      "\n",
      "Fold: 12  Epoch: 362  Training loss = 2.6621  Validation loss = 1.5489  \n",
      "\n",
      "Fold: 12  Epoch: 363  Training loss = 2.6617  Validation loss = 1.5456  \n",
      "\n",
      "Fold: 12  Epoch: 364  Training loss = 2.6615  Validation loss = 1.5451  \n",
      "\n",
      "Fold: 12  Epoch: 365  Training loss = 2.6611  Validation loss = 1.5450  \n",
      "\n",
      "Fold: 12  Epoch: 366  Training loss = 2.6608  Validation loss = 1.5448  \n",
      "\n",
      "Fold: 12  Epoch: 367  Training loss = 2.6604  Validation loss = 1.5445  \n",
      "\n",
      "Fold: 12  Epoch: 368  Training loss = 2.6602  Validation loss = 1.5439  \n",
      "\n",
      "Fold: 12  Epoch: 369  Training loss = 2.6598  Validation loss = 1.5435  \n",
      "\n",
      "Fold: 12  Epoch: 370  Training loss = 2.6593  Validation loss = 1.5421  \n",
      "\n",
      "Fold: 12  Epoch: 371  Training loss = 2.6590  Validation loss = 1.5424  \n",
      "\n",
      "Fold: 12  Epoch: 372  Training loss = 2.6586  Validation loss = 1.5401  \n",
      "\n",
      "Fold: 12  Epoch: 373  Training loss = 2.6581  Validation loss = 1.5386  \n",
      "\n",
      "Fold: 12  Epoch: 374  Training loss = 2.6577  Validation loss = 1.5376  \n",
      "\n",
      "Fold: 12  Epoch: 375  Training loss = 2.6574  Validation loss = 1.5374  \n",
      "\n",
      "Fold: 12  Epoch: 376  Training loss = 2.6572  Validation loss = 1.5384  \n",
      "\n",
      "Fold: 12  Epoch: 377  Training loss = 2.6567  Validation loss = 1.5366  \n",
      "\n",
      "Fold: 12  Epoch: 378  Training loss = 2.6565  Validation loss = 1.5372  \n",
      "\n",
      "Fold: 12  Epoch: 379  Training loss = 2.6561  Validation loss = 1.5360  \n",
      "\n",
      "Fold: 12  Epoch: 380  Training loss = 2.6557  Validation loss = 1.5356  \n",
      "\n",
      "Fold: 12  Epoch: 381  Training loss = 2.6553  Validation loss = 1.5341  \n",
      "\n",
      "Fold: 12  Epoch: 382  Training loss = 2.6548  Validation loss = 1.5325  \n",
      "\n",
      "Fold: 12  Epoch: 383  Training loss = 2.6543  Validation loss = 1.5306  \n",
      "\n",
      "Fold: 12  Epoch: 384  Training loss = 2.6540  Validation loss = 1.5289  \n",
      "\n",
      "Fold: 12  Epoch: 385  Training loss = 2.6536  Validation loss = 1.5282  \n",
      "\n",
      "Fold: 12  Epoch: 386  Training loss = 2.6530  Validation loss = 1.5262  \n",
      "\n",
      "Fold: 12  Epoch: 387  Training loss = 2.6525  Validation loss = 1.5249  \n",
      "\n",
      "Fold: 12  Epoch: 388  Training loss = 2.6522  Validation loss = 1.5245  \n",
      "\n",
      "Fold: 12  Epoch: 389  Training loss = 2.6517  Validation loss = 1.5222  \n",
      "\n",
      "Fold: 12  Epoch: 390  Training loss = 2.6514  Validation loss = 1.5221  \n",
      "\n",
      "Fold: 12  Epoch: 391  Training loss = 2.6509  Validation loss = 1.5199  \n",
      "\n",
      "Fold: 12  Epoch: 392  Training loss = 2.6505  Validation loss = 1.5191  \n",
      "\n",
      "Fold: 12  Epoch: 393  Training loss = 2.6499  Validation loss = 1.5191  \n",
      "\n",
      "Fold: 12  Epoch: 394  Training loss = 2.6493  Validation loss = 1.5174  \n",
      "\n",
      "Fold: 12  Epoch: 395  Training loss = 2.6490  Validation loss = 1.5180  \n",
      "\n",
      "Fold: 12  Epoch: 396  Training loss = 2.6487  Validation loss = 1.5194  \n",
      "\n",
      "Fold: 12  Epoch: 397  Training loss = 2.6482  Validation loss = 1.5180  \n",
      "\n",
      "Fold: 12  Epoch: 398  Training loss = 2.6480  Validation loss = 1.5188  \n",
      "\n",
      "Fold: 12  Epoch: 399  Training loss = 2.6476  Validation loss = 1.5171  \n",
      "\n",
      "Fold: 12  Epoch: 400  Training loss = 2.6473  Validation loss = 1.5172  \n",
      "\n",
      "Fold: 12  Epoch: 401  Training loss = 2.6467  Validation loss = 1.5159  \n",
      "\n",
      "Fold: 12  Epoch: 402  Training loss = 2.6463  Validation loss = 1.5141  \n",
      "\n",
      "Fold: 12  Epoch: 403  Training loss = 2.6459  Validation loss = 1.5135  \n",
      "\n",
      "Fold: 12  Epoch: 404  Training loss = 2.6453  Validation loss = 1.5103  \n",
      "\n",
      "Fold: 12  Epoch: 405  Training loss = 2.6449  Validation loss = 1.5090  \n",
      "\n",
      "Fold: 12  Epoch: 406  Training loss = 2.6444  Validation loss = 1.5061  \n",
      "\n",
      "Fold: 12  Epoch: 407  Training loss = 2.6439  Validation loss = 1.5026  \n",
      "\n",
      "Fold: 12  Epoch: 408  Training loss = 2.6435  Validation loss = 1.5008  \n",
      "\n",
      "Fold: 12  Epoch: 409  Training loss = 2.6431  Validation loss = 1.4994  \n",
      "\n",
      "Fold: 12  Epoch: 410  Training loss = 2.6427  Validation loss = 1.4995  \n",
      "\n",
      "Fold: 12  Epoch: 411  Training loss = 2.6424  Validation loss = 1.4977  \n",
      "\n",
      "Fold: 12  Epoch: 412  Training loss = 2.6420  Validation loss = 1.4966  \n",
      "\n",
      "Fold: 12  Epoch: 413  Training loss = 2.6417  Validation loss = 1.4964  \n",
      "\n",
      "Fold: 12  Epoch: 414  Training loss = 2.6413  Validation loss = 1.4967  \n",
      "\n",
      "Fold: 12  Epoch: 415  Training loss = 2.6409  Validation loss = 1.4964  \n",
      "\n",
      "Fold: 12  Epoch: 416  Training loss = 2.6406  Validation loss = 1.4952  \n",
      "\n",
      "Fold: 12  Epoch: 417  Training loss = 2.6404  Validation loss = 1.4954  \n",
      "\n",
      "Fold: 12  Epoch: 418  Training loss = 2.6401  Validation loss = 1.4945  \n",
      "\n",
      "Fold: 12  Epoch: 419  Training loss = 2.6397  Validation loss = 1.4932  \n",
      "\n",
      "Fold: 12  Epoch: 420  Training loss = 2.6394  Validation loss = 1.4932  \n",
      "\n",
      "Fold: 12  Epoch: 421  Training loss = 2.6391  Validation loss = 1.4937  \n",
      "\n",
      "Fold: 12  Epoch: 422  Training loss = 2.6387  Validation loss = 1.4932  \n",
      "\n",
      "Fold: 12  Epoch: 423  Training loss = 2.6383  Validation loss = 1.4931  \n",
      "\n",
      "Fold: 12  Epoch: 424  Training loss = 2.6378  Validation loss = 1.4912  \n",
      "\n",
      "Fold: 12  Epoch: 425  Training loss = 2.6375  Validation loss = 1.4901  \n",
      "\n",
      "Fold: 12  Epoch: 426  Training loss = 2.6373  Validation loss = 1.4909  \n",
      "\n",
      "Fold: 12  Epoch: 427  Training loss = 2.6370  Validation loss = 1.4897  \n",
      "\n",
      "Fold: 12  Epoch: 428  Training loss = 2.6368  Validation loss = 1.4888  \n",
      "\n",
      "Fold: 12  Epoch: 429  Training loss = 2.6363  Validation loss = 1.4859  \n",
      "\n",
      "Fold: 12  Epoch: 430  Training loss = 2.6359  Validation loss = 1.4857  \n",
      "\n",
      "Fold: 12  Epoch: 431  Training loss = 2.6356  Validation loss = 1.4847  \n",
      "\n",
      "Fold: 12  Epoch: 432  Training loss = 2.6353  Validation loss = 1.4839  \n",
      "\n",
      "Fold: 12  Epoch: 433  Training loss = 2.6349  Validation loss = 1.4819  \n",
      "\n",
      "Fold: 12  Epoch: 434  Training loss = 2.6347  Validation loss = 1.4824  \n",
      "\n",
      "Fold: 12  Epoch: 435  Training loss = 2.6345  Validation loss = 1.4821  \n",
      "\n",
      "Fold: 12  Epoch: 436  Training loss = 2.6342  Validation loss = 1.4826  \n",
      "\n",
      "Fold: 12  Epoch: 437  Training loss = 2.6337  Validation loss = 1.4808  \n",
      "\n",
      "Fold: 12  Epoch: 438  Training loss = 2.6334  Validation loss = 1.4813  \n",
      "\n",
      "Fold: 12  Epoch: 439  Training loss = 2.6332  Validation loss = 1.4814  \n",
      "\n",
      "Fold: 12  Epoch: 440  Training loss = 2.6328  Validation loss = 1.4803  \n",
      "\n",
      "Fold: 12  Epoch: 441  Training loss = 2.6324  Validation loss = 1.4771  \n",
      "\n",
      "Fold: 12  Epoch: 442  Training loss = 2.6321  Validation loss = 1.4765  \n",
      "\n",
      "Fold: 12  Epoch: 443  Training loss = 2.6318  Validation loss = 1.4777  \n",
      "\n",
      "Fold: 12  Epoch: 444  Training loss = 2.6315  Validation loss = 1.4768  \n",
      "\n",
      "Fold: 12  Epoch: 445  Training loss = 2.6311  Validation loss = 1.4752  \n",
      "\n",
      "Fold: 12  Epoch: 446  Training loss = 2.6306  Validation loss = 1.4735  \n",
      "\n",
      "Fold: 12  Epoch: 447  Training loss = 2.6302  Validation loss = 1.4736  \n",
      "\n",
      "Fold: 12  Epoch: 448  Training loss = 2.6298  Validation loss = 1.4720  \n",
      "\n",
      "Fold: 12  Epoch: 449  Training loss = 2.6295  Validation loss = 1.4719  \n",
      "\n",
      "Fold: 12  Epoch: 450  Training loss = 2.6290  Validation loss = 1.4699  \n",
      "\n",
      "Fold: 12  Epoch: 451  Training loss = 2.6286  Validation loss = 1.4689  \n",
      "\n",
      "Fold: 12  Epoch: 452  Training loss = 2.6283  Validation loss = 1.4679  \n",
      "\n",
      "Fold: 12  Epoch: 453  Training loss = 2.6280  Validation loss = 1.4668  \n",
      "\n",
      "Fold: 12  Epoch: 454  Training loss = 2.6277  Validation loss = 1.4644  \n",
      "\n",
      "Fold: 12  Epoch: 455  Training loss = 2.6273  Validation loss = 1.4630  \n",
      "\n",
      "Fold: 12  Epoch: 456  Training loss = 2.6269  Validation loss = 1.4612  \n",
      "\n",
      "Fold: 12  Epoch: 457  Training loss = 2.6264  Validation loss = 1.4586  \n",
      "\n",
      "Fold: 12  Epoch: 458  Training loss = 2.6260  Validation loss = 1.4579  \n",
      "\n",
      "Fold: 12  Epoch: 459  Training loss = 2.6257  Validation loss = 1.4577  \n",
      "\n",
      "Fold: 12  Epoch: 460  Training loss = 2.6253  Validation loss = 1.4568  \n",
      "\n",
      "Fold: 12  Epoch: 461  Training loss = 2.6249  Validation loss = 1.4572  \n",
      "\n",
      "Fold: 12  Epoch: 462  Training loss = 2.6247  Validation loss = 1.4586  \n",
      "\n",
      "Fold: 12  Epoch: 463  Training loss = 2.6244  Validation loss = 1.4575  \n",
      "\n",
      "Fold: 12  Epoch: 464  Training loss = 2.6241  Validation loss = 1.4563  \n",
      "\n",
      "Fold: 12  Epoch: 465  Training loss = 2.6238  Validation loss = 1.4560  \n",
      "\n",
      "Fold: 12  Epoch: 466  Training loss = 2.6233  Validation loss = 1.4542  \n",
      "\n",
      "Fold: 12  Epoch: 467  Training loss = 2.6231  Validation loss = 1.4539  \n",
      "\n",
      "Fold: 12  Epoch: 468  Training loss = 2.6227  Validation loss = 1.4524  \n",
      "\n",
      "Fold: 12  Epoch: 469  Training loss = 2.6223  Validation loss = 1.4498  \n",
      "\n",
      "Fold: 12  Epoch: 470  Training loss = 2.6220  Validation loss = 1.4487  \n",
      "\n",
      "Fold: 12  Epoch: 471  Training loss = 2.6217  Validation loss = 1.4470  \n",
      "\n",
      "Fold: 12  Epoch: 472  Training loss = 2.6213  Validation loss = 1.4468  \n",
      "\n",
      "Fold: 12  Epoch: 473  Training loss = 2.6210  Validation loss = 1.4449  \n",
      "\n",
      "Fold: 12  Epoch: 474  Training loss = 2.6209  Validation loss = 1.4444  \n",
      "\n",
      "Fold: 12  Epoch: 475  Training loss = 2.6206  Validation loss = 1.4448  \n",
      "\n",
      "Fold: 12  Epoch: 476  Training loss = 2.6203  Validation loss = 1.4440  \n",
      "\n",
      "Fold: 12  Epoch: 477  Training loss = 2.6200  Validation loss = 1.4427  \n",
      "\n",
      "Fold: 12  Epoch: 478  Training loss = 2.6197  Validation loss = 1.4428  \n",
      "\n",
      "Fold: 12  Epoch: 479  Training loss = 2.6194  Validation loss = 1.4428  \n",
      "\n",
      "Fold: 12  Epoch: 480  Training loss = 2.6190  Validation loss = 1.4417  \n",
      "\n",
      "Fold: 12  Epoch: 481  Training loss = 2.6188  Validation loss = 1.4427  \n",
      "\n",
      "Fold: 12  Epoch: 482  Training loss = 2.6185  Validation loss = 1.4421  \n",
      "\n",
      "Fold: 12  Epoch: 483  Training loss = 2.6181  Validation loss = 1.4400  \n",
      "\n",
      "Fold: 12  Epoch: 484  Training loss = 2.6177  Validation loss = 1.4384  \n",
      "\n",
      "Fold: 12  Epoch: 485  Training loss = 2.6175  Validation loss = 1.4386  \n",
      "\n",
      "Fold: 12  Epoch: 486  Training loss = 2.6173  Validation loss = 1.4376  \n",
      "\n",
      "Fold: 12  Epoch: 487  Training loss = 2.6170  Validation loss = 1.4374  \n",
      "\n",
      "Fold: 12  Epoch: 488  Training loss = 2.6167  Validation loss = 1.4372  \n",
      "\n",
      "Fold: 12  Epoch: 489  Training loss = 2.6163  Validation loss = 1.4366  \n",
      "\n",
      "Fold: 12  Epoch: 490  Training loss = 2.6159  Validation loss = 1.4357  \n",
      "\n",
      "Fold: 12  Epoch: 491  Training loss = 2.6156  Validation loss = 1.4346  \n",
      "\n",
      "Fold: 12  Epoch: 492  Training loss = 2.6154  Validation loss = 1.4342  \n",
      "\n",
      "Fold: 12  Epoch: 493  Training loss = 2.6152  Validation loss = 1.4343  \n",
      "\n",
      "Fold: 12  Epoch: 494  Training loss = 2.6148  Validation loss = 1.4334  \n",
      "\n",
      "Fold: 12  Epoch: 495  Training loss = 2.6146  Validation loss = 1.4340  \n",
      "\n",
      "Fold: 12  Epoch: 496  Training loss = 2.6142  Validation loss = 1.4322  \n",
      "\n",
      "Fold: 12  Epoch: 497  Training loss = 2.6139  Validation loss = 1.4311  \n",
      "\n",
      "Fold: 12  Epoch: 498  Training loss = 2.6135  Validation loss = 1.4305  \n",
      "\n",
      "Fold: 12  Epoch: 499  Training loss = 2.6133  Validation loss = 1.4302  \n",
      "\n",
      "Fold: 12  Epoch: 500  Training loss = 2.6130  Validation loss = 1.4296  \n",
      "\n",
      "Check model:  Fold: 12  Optimal epoch: 500  \n",
      "\n",
      "Fold: 13  Epoch: 1  Training loss = 2.5774  Validation loss = 3.7907  \n",
      "\n",
      "Fold: 13  Epoch: 2  Training loss = 2.5768  Validation loss = 3.7885  \n",
      "\n",
      "Fold: 13  Epoch: 3  Training loss = 2.5764  Validation loss = 3.7874  \n",
      "\n",
      "Fold: 13  Epoch: 4  Training loss = 2.5759  Validation loss = 3.7861  \n",
      "\n",
      "Fold: 13  Epoch: 5  Training loss = 2.5756  Validation loss = 3.7851  \n",
      "\n",
      "Fold: 13  Epoch: 6  Training loss = 2.5750  Validation loss = 3.7831  \n",
      "\n",
      "Fold: 13  Epoch: 7  Training loss = 2.5741  Validation loss = 3.7807  \n",
      "\n",
      "Fold: 13  Epoch: 8  Training loss = 2.5737  Validation loss = 3.7793  \n",
      "\n",
      "Fold: 13  Epoch: 9  Training loss = 2.5737  Validation loss = 3.7796  \n",
      "\n",
      "Fold: 13  Epoch: 10  Training loss = 2.5735  Validation loss = 3.7784  \n",
      "\n",
      "Fold: 13  Epoch: 11  Training loss = 2.5732  Validation loss = 3.7776  \n",
      "\n",
      "Fold: 13  Epoch: 12  Training loss = 2.5728  Validation loss = 3.7766  \n",
      "\n",
      "Fold: 13  Epoch: 13  Training loss = 2.5726  Validation loss = 3.7763  \n",
      "\n",
      "Fold: 13  Epoch: 14  Training loss = 2.5724  Validation loss = 3.7758  \n",
      "\n",
      "Fold: 13  Epoch: 15  Training loss = 2.5717  Validation loss = 3.7740  \n",
      "\n",
      "Fold: 13  Epoch: 16  Training loss = 2.5713  Validation loss = 3.7730  \n",
      "\n",
      "Fold: 13  Epoch: 17  Training loss = 2.5709  Validation loss = 3.7717  \n",
      "\n",
      "Fold: 13  Epoch: 18  Training loss = 2.5706  Validation loss = 3.7711  \n",
      "\n",
      "Fold: 13  Epoch: 19  Training loss = 2.5577  Validation loss = 3.7686  \n",
      "\n",
      "Fold: 13  Epoch: 20  Training loss = 2.5574  Validation loss = 3.7678  \n",
      "\n",
      "Fold: 13  Epoch: 21  Training loss = 2.5570  Validation loss = 3.7666  \n",
      "\n",
      "Fold: 13  Epoch: 22  Training loss = 2.5568  Validation loss = 3.7660  \n",
      "\n",
      "Fold: 13  Epoch: 23  Training loss = 2.5564  Validation loss = 3.7647  \n",
      "\n",
      "Fold: 13  Epoch: 24  Training loss = 2.5557  Validation loss = 3.7629  \n",
      "\n",
      "Fold: 13  Epoch: 25  Training loss = 2.5553  Validation loss = 3.7617  \n",
      "\n",
      "Fold: 13  Epoch: 26  Training loss = 2.5547  Validation loss = 3.7599  \n",
      "\n",
      "Fold: 13  Epoch: 27  Training loss = 2.5541  Validation loss = 3.7583  \n",
      "\n",
      "Fold: 13  Epoch: 28  Training loss = 2.5538  Validation loss = 3.7577  \n",
      "\n",
      "Fold: 13  Epoch: 29  Training loss = 2.5535  Validation loss = 3.7570  \n",
      "\n",
      "Fold: 13  Epoch: 30  Training loss = 2.5531  Validation loss = 3.7557  \n",
      "\n",
      "Fold: 13  Epoch: 31  Training loss = 2.5528  Validation loss = 3.7546  \n",
      "\n",
      "Fold: 13  Epoch: 32  Training loss = 2.5521  Validation loss = 3.7525  \n",
      "\n",
      "Fold: 13  Epoch: 33  Training loss = 2.5518  Validation loss = 3.7518  \n",
      "\n",
      "Fold: 13  Epoch: 34  Training loss = 2.5516  Validation loss = 3.7513  \n",
      "\n",
      "Fold: 13  Epoch: 35  Training loss = 2.5512  Validation loss = 3.7500  \n",
      "\n",
      "Fold: 13  Epoch: 36  Training loss = 2.5507  Validation loss = 3.7483  \n",
      "\n",
      "Fold: 13  Epoch: 37  Training loss = 2.5506  Validation loss = 3.7486  \n",
      "\n",
      "Fold: 13  Epoch: 38  Training loss = 2.5503  Validation loss = 3.7475  \n",
      "\n",
      "Fold: 13  Epoch: 39  Training loss = 2.5499  Validation loss = 3.7458  \n",
      "\n",
      "Fold: 13  Epoch: 40  Training loss = 2.5497  Validation loss = 3.7456  \n",
      "\n",
      "Fold: 13  Epoch: 41  Training loss = 2.5493  Validation loss = 3.7450  \n",
      "\n",
      "Fold: 13  Epoch: 42  Training loss = 2.5487  Validation loss = 3.7434  \n",
      "\n",
      "Fold: 13  Epoch: 43  Training loss = 2.5482  Validation loss = 3.7415  \n",
      "\n",
      "Fold: 13  Epoch: 44  Training loss = 2.5477  Validation loss = 3.7403  \n",
      "\n",
      "Fold: 13  Epoch: 45  Training loss = 2.5472  Validation loss = 3.7387  \n",
      "\n",
      "Fold: 13  Epoch: 46  Training loss = 2.5466  Validation loss = 3.7368  \n",
      "\n",
      "Fold: 13  Epoch: 47  Training loss = 2.5461  Validation loss = 3.7351  \n",
      "\n",
      "Fold: 13  Epoch: 48  Training loss = 2.5458  Validation loss = 3.7339  \n",
      "\n",
      "Fold: 13  Epoch: 49  Training loss = 2.5452  Validation loss = 3.7315  \n",
      "\n",
      "Fold: 13  Epoch: 50  Training loss = 2.5450  Validation loss = 3.7309  \n",
      "\n",
      "Fold: 13  Epoch: 51  Training loss = 2.5448  Validation loss = 3.7304  \n",
      "\n",
      "Fold: 13  Epoch: 52  Training loss = 2.5444  Validation loss = 3.7292  \n",
      "\n",
      "Fold: 13  Epoch: 53  Training loss = 2.5444  Validation loss = 3.7295  \n",
      "\n",
      "Fold: 13  Epoch: 54  Training loss = 2.5439  Validation loss = 3.7282  \n",
      "\n",
      "Fold: 13  Epoch: 55  Training loss = 2.5438  Validation loss = 3.7277  \n",
      "\n",
      "Fold: 13  Epoch: 56  Training loss = 2.5431  Validation loss = 3.7254  \n",
      "\n",
      "Fold: 13  Epoch: 57  Training loss = 2.5427  Validation loss = 3.7243  \n",
      "\n",
      "Fold: 13  Epoch: 58  Training loss = 2.5422  Validation loss = 3.7225  \n",
      "\n",
      "Fold: 13  Epoch: 59  Training loss = 2.5418  Validation loss = 3.7216  \n",
      "\n",
      "Fold: 13  Epoch: 60  Training loss = 2.5411  Validation loss = 3.7192  \n",
      "\n",
      "Fold: 13  Epoch: 61  Training loss = 2.5405  Validation loss = 3.7173  \n",
      "\n",
      "Fold: 13  Epoch: 62  Training loss = 2.5398  Validation loss = 3.7148  \n",
      "\n",
      "Fold: 13  Epoch: 63  Training loss = 2.5392  Validation loss = 3.7124  \n",
      "\n",
      "Fold: 13  Epoch: 64  Training loss = 2.5388  Validation loss = 3.7109  \n",
      "\n",
      "Fold: 13  Epoch: 65  Training loss = 2.5386  Validation loss = 3.7110  \n",
      "\n",
      "Fold: 13  Epoch: 66  Training loss = 2.5384  Validation loss = 3.7106  \n",
      "\n",
      "Fold: 13  Epoch: 67  Training loss = 2.5379  Validation loss = 3.7093  \n",
      "\n",
      "Fold: 13  Epoch: 68  Training loss = 2.5375  Validation loss = 3.7078  \n",
      "\n",
      "Fold: 13  Epoch: 69  Training loss = 2.5373  Validation loss = 3.7082  \n",
      "\n",
      "Fold: 13  Epoch: 70  Training loss = 2.5370  Validation loss = 3.7069  \n",
      "\n",
      "Fold: 13  Epoch: 71  Training loss = 2.5369  Validation loss = 3.7071  \n",
      "\n",
      "Fold: 13  Epoch: 72  Training loss = 2.5365  Validation loss = 3.7061  \n",
      "\n",
      "Fold: 13  Epoch: 73  Training loss = 2.5359  Validation loss = 3.7044  \n",
      "\n",
      "Fold: 13  Epoch: 74  Training loss = 2.5355  Validation loss = 3.7030  \n",
      "\n",
      "Fold: 13  Epoch: 75  Training loss = 2.5352  Validation loss = 3.7020  \n",
      "\n",
      "Fold: 13  Epoch: 76  Training loss = 2.5346  Validation loss = 3.7000  \n",
      "\n",
      "Fold: 13  Epoch: 77  Training loss = 2.5343  Validation loss = 3.6996  \n",
      "\n",
      "Fold: 13  Epoch: 78  Training loss = 2.5343  Validation loss = 3.7000  \n",
      "\n",
      "Fold: 13  Epoch: 79  Training loss = 2.5341  Validation loss = 3.6995  \n",
      "\n",
      "Fold: 13  Epoch: 80  Training loss = 2.5339  Validation loss = 3.6994  \n",
      "\n",
      "Fold: 13  Epoch: 81  Training loss = 2.5336  Validation loss = 3.6985  \n",
      "\n",
      "Fold: 13  Epoch: 82  Training loss = 2.5331  Validation loss = 3.6969  \n",
      "\n",
      "Fold: 13  Epoch: 83  Training loss = 2.5325  Validation loss = 3.6950  \n",
      "\n",
      "Fold: 13  Epoch: 84  Training loss = 2.5322  Validation loss = 3.6944  \n",
      "\n",
      "Fold: 13  Epoch: 85  Training loss = 2.5319  Validation loss = 3.6933  \n",
      "\n",
      "Fold: 13  Epoch: 86  Training loss = 2.5314  Validation loss = 3.6918  \n",
      "\n",
      "Fold: 13  Epoch: 87  Training loss = 2.5310  Validation loss = 3.6905  \n",
      "\n",
      "Fold: 13  Epoch: 88  Training loss = 2.5309  Validation loss = 3.6909  \n",
      "\n",
      "Fold: 13  Epoch: 89  Training loss = 2.5307  Validation loss = 3.6905  \n",
      "\n",
      "Fold: 13  Epoch: 90  Training loss = 2.5304  Validation loss = 3.6898  \n",
      "\n",
      "Fold: 13  Epoch: 91  Training loss = 2.5302  Validation loss = 3.6892  \n",
      "\n",
      "Fold: 13  Epoch: 92  Training loss = 2.5297  Validation loss = 3.6875  \n",
      "\n",
      "Fold: 13  Epoch: 93  Training loss = 2.5292  Validation loss = 3.6857  \n",
      "\n",
      "Fold: 13  Epoch: 94  Training loss = 2.5288  Validation loss = 3.6843  \n",
      "\n",
      "Fold: 13  Epoch: 95  Training loss = 2.5286  Validation loss = 3.6845  \n",
      "\n",
      "Fold: 13  Epoch: 96  Training loss = 2.5283  Validation loss = 3.6841  \n",
      "\n",
      "Fold: 13  Epoch: 97  Training loss = 2.5282  Validation loss = 3.6836  \n",
      "\n",
      "Fold: 13  Epoch: 98  Training loss = 2.5278  Validation loss = 3.6822  \n",
      "\n",
      "Fold: 13  Epoch: 99  Training loss = 2.5275  Validation loss = 3.6818  \n",
      "\n",
      "Fold: 13  Epoch: 100  Training loss = 2.5274  Validation loss = 3.6813  \n",
      "\n",
      "Fold: 13  Epoch: 101  Training loss = 2.5271  Validation loss = 3.6803  \n",
      "\n",
      "Fold: 13  Epoch: 102  Training loss = 2.5267  Validation loss = 3.6795  \n",
      "\n",
      "Fold: 13  Epoch: 103  Training loss = 2.5264  Validation loss = 3.6788  \n",
      "\n",
      "Fold: 13  Epoch: 104  Training loss = 2.5261  Validation loss = 3.6780  \n",
      "\n",
      "Fold: 13  Epoch: 105  Training loss = 2.5258  Validation loss = 3.6770  \n",
      "\n",
      "Fold: 13  Epoch: 106  Training loss = 2.5252  Validation loss = 3.6749  \n",
      "\n",
      "Fold: 13  Epoch: 107  Training loss = 2.5249  Validation loss = 3.6739  \n",
      "\n",
      "Fold: 13  Epoch: 108  Training loss = 2.5246  Validation loss = 3.6732  \n",
      "\n",
      "Fold: 13  Epoch: 109  Training loss = 2.5243  Validation loss = 3.6723  \n",
      "\n",
      "Fold: 13  Epoch: 110  Training loss = 2.5242  Validation loss = 3.6728  \n",
      "\n",
      "Fold: 13  Epoch: 111  Training loss = 2.5240  Validation loss = 3.6723  \n",
      "\n",
      "Fold: 13  Epoch: 112  Training loss = 2.5236  Validation loss = 3.6713  \n",
      "\n",
      "Fold: 13  Epoch: 113  Training loss = 2.5232  Validation loss = 3.6701  \n",
      "\n",
      "Fold: 13  Epoch: 114  Training loss = 2.5227  Validation loss = 3.6685  \n",
      "\n",
      "Fold: 13  Epoch: 115  Training loss = 2.5225  Validation loss = 3.6676  \n",
      "\n",
      "Fold: 13  Epoch: 116  Training loss = 2.5220  Validation loss = 3.6661  \n",
      "\n",
      "Fold: 13  Epoch: 117  Training loss = 2.5215  Validation loss = 3.6648  \n",
      "\n",
      "Fold: 13  Epoch: 118  Training loss = 2.5211  Validation loss = 3.6636  \n",
      "\n",
      "Fold: 13  Epoch: 119  Training loss = 2.5208  Validation loss = 3.6629  \n",
      "\n",
      "Fold: 13  Epoch: 120  Training loss = 2.5206  Validation loss = 3.6621  \n",
      "\n",
      "Fold: 13  Epoch: 121  Training loss = 2.5203  Validation loss = 3.6616  \n",
      "\n",
      "Fold: 13  Epoch: 122  Training loss = 2.5198  Validation loss = 3.6597  \n",
      "\n",
      "Fold: 13  Epoch: 123  Training loss = 2.5195  Validation loss = 3.6587  \n",
      "\n",
      "Fold: 13  Epoch: 124  Training loss = 2.5192  Validation loss = 3.6581  \n",
      "\n",
      "Fold: 13  Epoch: 125  Training loss = 2.5189  Validation loss = 3.6574  \n",
      "\n",
      "Fold: 13  Epoch: 126  Training loss = 2.5186  Validation loss = 3.6569  \n",
      "\n",
      "Fold: 13  Epoch: 127  Training loss = 2.5184  Validation loss = 3.6564  \n",
      "\n",
      "Fold: 13  Epoch: 128  Training loss = 2.5180  Validation loss = 3.6549  \n",
      "\n",
      "Fold: 13  Epoch: 129  Training loss = 2.5177  Validation loss = 3.6542  \n",
      "\n",
      "Fold: 13  Epoch: 130  Training loss = 2.5172  Validation loss = 3.6523  \n",
      "\n",
      "Fold: 13  Epoch: 131  Training loss = 2.5169  Validation loss = 3.6516  \n",
      "\n",
      "Fold: 13  Epoch: 132  Training loss = 2.5165  Validation loss = 3.6507  \n",
      "\n",
      "Fold: 13  Epoch: 133  Training loss = 2.5161  Validation loss = 3.6492  \n",
      "\n",
      "Fold: 13  Epoch: 134  Training loss = 2.5156  Validation loss = 3.6479  \n",
      "\n",
      "Fold: 13  Epoch: 135  Training loss = 2.5153  Validation loss = 3.6471  \n",
      "\n",
      "Fold: 13  Epoch: 136  Training loss = 2.5151  Validation loss = 3.6465  \n",
      "\n",
      "Fold: 13  Epoch: 137  Training loss = 2.5146  Validation loss = 3.6452  \n",
      "\n",
      "Fold: 13  Epoch: 138  Training loss = 2.5140  Validation loss = 3.6429  \n",
      "\n",
      "Fold: 13  Epoch: 139  Training loss = 2.5137  Validation loss = 3.6419  \n",
      "\n",
      "Fold: 13  Epoch: 140  Training loss = 2.5135  Validation loss = 3.6410  \n",
      "\n",
      "Fold: 13  Epoch: 141  Training loss = 2.5131  Validation loss = 3.6402  \n",
      "\n",
      "Fold: 13  Epoch: 142  Training loss = 2.5130  Validation loss = 3.6407  \n",
      "\n",
      "Fold: 13  Epoch: 143  Training loss = 2.5127  Validation loss = 3.6397  \n",
      "\n",
      "Fold: 13  Epoch: 144  Training loss = 2.5124  Validation loss = 3.6384  \n",
      "\n",
      "Fold: 13  Epoch: 145  Training loss = 2.5123  Validation loss = 3.6386  \n",
      "\n",
      "Fold: 13  Epoch: 146  Training loss = 2.5119  Validation loss = 3.6377  \n",
      "\n",
      "Fold: 13  Epoch: 147  Training loss = 2.5116  Validation loss = 3.6364  \n",
      "\n",
      "Fold: 13  Epoch: 148  Training loss = 2.5113  Validation loss = 3.6356  \n",
      "\n",
      "Fold: 13  Epoch: 149  Training loss = 2.5107  Validation loss = 3.6331  \n",
      "\n",
      "Fold: 13  Epoch: 150  Training loss = 2.5104  Validation loss = 3.6320  \n",
      "\n",
      "Fold: 13  Epoch: 151  Training loss = 2.5099  Validation loss = 3.6304  \n",
      "\n",
      "Fold: 13  Epoch: 152  Training loss = 2.5095  Validation loss = 3.6293  \n",
      "\n",
      "Fold: 13  Epoch: 153  Training loss = 2.5090  Validation loss = 3.6268  \n",
      "\n",
      "Fold: 13  Epoch: 154  Training loss = 2.5086  Validation loss = 3.6254  \n",
      "\n",
      "Fold: 13  Epoch: 155  Training loss = 2.5084  Validation loss = 3.6258  \n",
      "\n",
      "Fold: 13  Epoch: 156  Training loss = 2.5080  Validation loss = 3.6244  \n",
      "\n",
      "Fold: 13  Epoch: 157  Training loss = 2.5077  Validation loss = 3.6239  \n",
      "\n",
      "Fold: 13  Epoch: 158  Training loss = 2.5076  Validation loss = 3.6239  \n",
      "\n",
      "Fold: 13  Epoch: 159  Training loss = 2.5071  Validation loss = 3.6221  \n",
      "\n",
      "Fold: 13  Epoch: 160  Training loss = 2.5068  Validation loss = 3.6210  \n",
      "\n",
      "Fold: 13  Epoch: 161  Training loss = 2.5065  Validation loss = 3.6204  \n",
      "\n",
      "Fold: 13  Epoch: 162  Training loss = 2.5062  Validation loss = 3.6196  \n",
      "\n",
      "Fold: 13  Epoch: 163  Training loss = 2.5059  Validation loss = 3.6193  \n",
      "\n",
      "Fold: 13  Epoch: 164  Training loss = 2.5055  Validation loss = 3.6175  \n",
      "\n",
      "Fold: 13  Epoch: 165  Training loss = 2.5053  Validation loss = 3.6172  \n",
      "\n",
      "Fold: 13  Epoch: 166  Training loss = 2.5050  Validation loss = 3.6162  \n",
      "\n",
      "Fold: 13  Epoch: 167  Training loss = 2.5048  Validation loss = 3.6162  \n",
      "\n",
      "Fold: 13  Epoch: 168  Training loss = 2.5046  Validation loss = 3.6160  \n",
      "\n",
      "Fold: 13  Epoch: 169  Training loss = 2.5044  Validation loss = 3.6156  \n",
      "\n",
      "Fold: 13  Epoch: 170  Training loss = 2.5041  Validation loss = 3.6147  \n",
      "\n",
      "Fold: 13  Epoch: 171  Training loss = 2.5037  Validation loss = 3.6136  \n",
      "\n",
      "Fold: 13  Epoch: 172  Training loss = 2.5035  Validation loss = 3.6133  \n",
      "\n",
      "Fold: 13  Epoch: 173  Training loss = 2.5032  Validation loss = 3.6121  \n",
      "\n",
      "Fold: 13  Epoch: 174  Training loss = 2.5028  Validation loss = 3.6111  \n",
      "\n",
      "Fold: 13  Epoch: 175  Training loss = 2.5026  Validation loss = 3.6106  \n",
      "\n",
      "Fold: 13  Epoch: 176  Training loss = 2.5023  Validation loss = 3.6102  \n",
      "\n",
      "Fold: 13  Epoch: 177  Training loss = 2.5019  Validation loss = 3.6089  \n",
      "\n",
      "Fold: 13  Epoch: 178  Training loss = 2.5017  Validation loss = 3.6084  \n",
      "\n",
      "Fold: 13  Epoch: 179  Training loss = 2.5015  Validation loss = 3.6081  \n",
      "\n",
      "Fold: 13  Epoch: 180  Training loss = 2.5012  Validation loss = 3.6074  \n",
      "\n",
      "Fold: 13  Epoch: 181  Training loss = 2.5007  Validation loss = 3.6054  \n",
      "\n",
      "Fold: 13  Epoch: 182  Training loss = 2.5005  Validation loss = 3.6048  \n",
      "\n",
      "Fold: 13  Epoch: 183  Training loss = 2.5001  Validation loss = 3.6034  \n",
      "\n",
      "Fold: 13  Epoch: 184  Training loss = 2.4998  Validation loss = 3.6030  \n",
      "\n",
      "Fold: 13  Epoch: 185  Training loss = 2.4994  Validation loss = 3.6012  \n",
      "\n",
      "Fold: 13  Epoch: 186  Training loss = 2.4991  Validation loss = 3.6008  \n",
      "\n",
      "Fold: 13  Epoch: 187  Training loss = 2.4987  Validation loss = 3.5993  \n",
      "\n",
      "Fold: 13  Epoch: 188  Training loss = 2.4983  Validation loss = 3.5988  \n",
      "\n",
      "Fold: 13  Epoch: 189  Training loss = 2.4982  Validation loss = 3.5985  \n",
      "\n",
      "Fold: 13  Epoch: 190  Training loss = 2.4979  Validation loss = 3.5975  \n",
      "\n",
      "Fold: 13  Epoch: 191  Training loss = 2.4977  Validation loss = 3.5976  \n",
      "\n",
      "Fold: 13  Epoch: 192  Training loss = 2.4973  Validation loss = 3.5959  \n",
      "\n",
      "Fold: 13  Epoch: 193  Training loss = 2.4970  Validation loss = 3.5952  \n",
      "\n",
      "Fold: 13  Epoch: 194  Training loss = 2.4965  Validation loss = 3.5932  \n",
      "\n",
      "Fold: 13  Epoch: 195  Training loss = 2.4962  Validation loss = 3.5921  \n",
      "\n",
      "Fold: 13  Epoch: 196  Training loss = 2.4958  Validation loss = 3.5905  \n",
      "\n",
      "Fold: 13  Epoch: 197  Training loss = 2.4954  Validation loss = 3.5892  \n",
      "\n",
      "Fold: 13  Epoch: 198  Training loss = 2.4952  Validation loss = 3.5886  \n",
      "\n",
      "Fold: 13  Epoch: 199  Training loss = 2.4949  Validation loss = 3.5881  \n",
      "\n",
      "Fold: 13  Epoch: 200  Training loss = 2.4946  Validation loss = 3.5872  \n",
      "\n",
      "Fold: 13  Epoch: 201  Training loss = 2.4942  Validation loss = 3.5861  \n",
      "\n",
      "Fold: 13  Epoch: 202  Training loss = 2.4939  Validation loss = 3.5858  \n",
      "\n",
      "Fold: 13  Epoch: 203  Training loss = 2.4935  Validation loss = 3.5848  \n",
      "\n",
      "Fold: 13  Epoch: 204  Training loss = 2.4932  Validation loss = 3.5838  \n",
      "\n",
      "Fold: 13  Epoch: 205  Training loss = 2.4927  Validation loss = 3.5818  \n",
      "\n",
      "Fold: 13  Epoch: 206  Training loss = 2.4924  Validation loss = 3.5810  \n",
      "\n",
      "Fold: 13  Epoch: 207  Training loss = 2.4920  Validation loss = 3.5795  \n",
      "\n",
      "Fold: 13  Epoch: 208  Training loss = 2.4917  Validation loss = 3.5795  \n",
      "\n",
      "Fold: 13  Epoch: 209  Training loss = 2.4914  Validation loss = 3.5780  \n",
      "\n",
      "Fold: 13  Epoch: 210  Training loss = 2.4908  Validation loss = 3.5755  \n",
      "\n",
      "Fold: 13  Epoch: 211  Training loss = 2.4905  Validation loss = 3.5748  \n",
      "\n",
      "Fold: 13  Epoch: 212  Training loss = 2.4902  Validation loss = 3.5742  \n",
      "\n",
      "Fold: 13  Epoch: 213  Training loss = 2.4898  Validation loss = 3.5726  \n",
      "\n",
      "Fold: 13  Epoch: 214  Training loss = 2.4897  Validation loss = 3.5723  \n",
      "\n",
      "Fold: 13  Epoch: 215  Training loss = 2.4893  Validation loss = 3.5712  \n",
      "\n",
      "Fold: 13  Epoch: 216  Training loss = 2.4890  Validation loss = 3.5710  \n",
      "\n",
      "Fold: 13  Epoch: 217  Training loss = 2.4887  Validation loss = 3.5700  \n",
      "\n",
      "Fold: 13  Epoch: 218  Training loss = 2.4882  Validation loss = 3.5679  \n",
      "\n",
      "Fold: 13  Epoch: 219  Training loss = 2.4879  Validation loss = 3.5665  \n",
      "\n",
      "Fold: 13  Epoch: 220  Training loss = 2.4875  Validation loss = 3.5652  \n",
      "\n",
      "Fold: 13  Epoch: 221  Training loss = 2.4871  Validation loss = 3.5640  \n",
      "\n",
      "Fold: 13  Epoch: 222  Training loss = 2.4869  Validation loss = 3.5637  \n",
      "\n",
      "Fold: 13  Epoch: 223  Training loss = 2.4865  Validation loss = 3.5623  \n",
      "\n",
      "Fold: 13  Epoch: 224  Training loss = 2.4861  Validation loss = 3.5612  \n",
      "\n",
      "Fold: 13  Epoch: 225  Training loss = 2.4858  Validation loss = 3.5605  \n",
      "\n",
      "Fold: 13  Epoch: 226  Training loss = 2.4854  Validation loss = 3.5598  \n",
      "\n",
      "Fold: 13  Epoch: 227  Training loss = 2.4851  Validation loss = 3.5599  \n",
      "\n",
      "Fold: 13  Epoch: 228  Training loss = 2.4849  Validation loss = 3.5596  \n",
      "\n",
      "Fold: 13  Epoch: 229  Training loss = 2.4845  Validation loss = 3.5587  \n",
      "\n",
      "Fold: 13  Epoch: 230  Training loss = 2.4841  Validation loss = 3.5570  \n",
      "\n",
      "Fold: 13  Epoch: 231  Training loss = 2.4837  Validation loss = 3.5564  \n",
      "\n",
      "Fold: 13  Epoch: 232  Training loss = 2.4833  Validation loss = 3.5550  \n",
      "\n",
      "Fold: 13  Epoch: 233  Training loss = 2.4830  Validation loss = 3.5542  \n",
      "\n",
      "Fold: 13  Epoch: 234  Training loss = 2.4825  Validation loss = 3.5521  \n",
      "\n",
      "Fold: 13  Epoch: 235  Training loss = 2.4822  Validation loss = 3.5513  \n",
      "\n",
      "Fold: 13  Epoch: 236  Training loss = 2.4818  Validation loss = 3.5509  \n",
      "\n",
      "Fold: 13  Epoch: 237  Training loss = 2.4814  Validation loss = 3.5494  \n",
      "\n",
      "Fold: 13  Epoch: 238  Training loss = 2.4811  Validation loss = 3.5483  \n",
      "\n",
      "Fold: 13  Epoch: 239  Training loss = 2.4806  Validation loss = 3.5464  \n",
      "\n",
      "Fold: 13  Epoch: 240  Training loss = 2.4802  Validation loss = 3.5455  \n",
      "\n",
      "Fold: 13  Epoch: 241  Training loss = 2.4799  Validation loss = 3.5444  \n",
      "\n",
      "Fold: 13  Epoch: 242  Training loss = 2.4794  Validation loss = 3.5425  \n",
      "\n",
      "Fold: 13  Epoch: 243  Training loss = 2.4792  Validation loss = 3.5423  \n",
      "\n",
      "Fold: 13  Epoch: 244  Training loss = 2.4788  Validation loss = 3.5412  \n",
      "\n",
      "Fold: 13  Epoch: 245  Training loss = 2.4784  Validation loss = 3.5401  \n",
      "\n",
      "Fold: 13  Epoch: 246  Training loss = 2.4780  Validation loss = 3.5390  \n",
      "\n",
      "Fold: 13  Epoch: 247  Training loss = 2.4777  Validation loss = 3.5385  \n",
      "\n",
      "Fold: 13  Epoch: 248  Training loss = 2.4772  Validation loss = 3.5362  \n",
      "\n",
      "Fold: 13  Epoch: 249  Training loss = 2.4768  Validation loss = 3.5345  \n",
      "\n",
      "Fold: 13  Epoch: 250  Training loss = 2.4767  Validation loss = 3.5351  \n",
      "\n",
      "Fold: 13  Epoch: 251  Training loss = 2.4763  Validation loss = 3.5337  \n",
      "\n",
      "Fold: 13  Epoch: 252  Training loss = 2.4759  Validation loss = 3.5330  \n",
      "\n",
      "Fold: 13  Epoch: 253  Training loss = 2.4756  Validation loss = 3.5327  \n",
      "\n",
      "Fold: 13  Epoch: 254  Training loss = 2.4754  Validation loss = 3.5332  \n",
      "\n",
      "Fold: 13  Epoch: 255  Training loss = 2.4749  Validation loss = 3.5315  \n",
      "\n",
      "Fold: 13  Epoch: 256  Training loss = 2.4747  Validation loss = 3.5312  \n",
      "\n",
      "Fold: 13  Epoch: 257  Training loss = 2.4744  Validation loss = 3.5304  \n",
      "\n",
      "Fold: 13  Epoch: 258  Training loss = 2.4741  Validation loss = 3.5303  \n",
      "\n",
      "Fold: 13  Epoch: 259  Training loss = 2.4736  Validation loss = 3.5295  \n",
      "\n",
      "Fold: 13  Epoch: 260  Training loss = 2.4733  Validation loss = 3.5287  \n",
      "\n",
      "Fold: 13  Epoch: 261  Training loss = 2.4731  Validation loss = 3.5284  \n",
      "\n",
      "Fold: 13  Epoch: 262  Training loss = 2.4727  Validation loss = 3.5276  \n",
      "\n",
      "Fold: 13  Epoch: 263  Training loss = 2.4724  Validation loss = 3.5266  \n",
      "\n",
      "Fold: 13  Epoch: 264  Training loss = 2.4721  Validation loss = 3.5257  \n",
      "\n",
      "Fold: 13  Epoch: 265  Training loss = 2.4718  Validation loss = 3.5251  \n",
      "\n",
      "Fold: 13  Epoch: 266  Training loss = 2.4716  Validation loss = 3.5249  \n",
      "\n",
      "Fold: 13  Epoch: 267  Training loss = 2.4714  Validation loss = 3.5246  \n",
      "\n",
      "Fold: 13  Epoch: 268  Training loss = 2.4709  Validation loss = 3.5217  \n",
      "\n",
      "Fold: 13  Epoch: 269  Training loss = 2.4707  Validation loss = 3.5219  \n",
      "\n",
      "Fold: 13  Epoch: 270  Training loss = 2.4705  Validation loss = 3.5219  \n",
      "\n",
      "Fold: 13  Epoch: 271  Training loss = 2.4703  Validation loss = 3.5215  \n",
      "\n",
      "Fold: 13  Epoch: 272  Training loss = 2.4701  Validation loss = 3.5208  \n",
      "\n",
      "Fold: 13  Epoch: 273  Training loss = 2.4698  Validation loss = 3.5200  \n",
      "\n",
      "Fold: 13  Epoch: 274  Training loss = 2.4694  Validation loss = 3.5184  \n",
      "\n",
      "Fold: 13  Epoch: 275  Training loss = 2.4694  Validation loss = 3.5181  \n",
      "\n",
      "Fold: 13  Epoch: 276  Training loss = 2.4689  Validation loss = 3.5174  \n",
      "\n",
      "Fold: 13  Epoch: 277  Training loss = 2.4686  Validation loss = 3.5156  \n",
      "\n",
      "Fold: 13  Epoch: 278  Training loss = 2.4681  Validation loss = 3.5156  \n",
      "\n",
      "Fold: 13  Epoch: 279  Training loss = 2.4678  Validation loss = 3.5147  \n",
      "\n",
      "Fold: 13  Epoch: 280  Training loss = 2.4675  Validation loss = 3.5134  \n",
      "\n",
      "Fold: 13  Epoch: 281  Training loss = 2.4673  Validation loss = 3.5132  \n",
      "\n",
      "Fold: 13  Epoch: 282  Training loss = 2.4668  Validation loss = 3.5118  \n",
      "\n",
      "Fold: 13  Epoch: 283  Training loss = 2.4663  Validation loss = 3.5098  \n",
      "\n",
      "Fold: 13  Epoch: 284  Training loss = 2.4660  Validation loss = 3.5089  \n",
      "\n",
      "Fold: 13  Epoch: 285  Training loss = 2.4655  Validation loss = 3.5070  \n",
      "\n",
      "Fold: 13  Epoch: 286  Training loss = 2.4653  Validation loss = 3.5069  \n",
      "\n",
      "Fold: 13  Epoch: 287  Training loss = 2.4651  Validation loss = 3.5065  \n",
      "\n",
      "Fold: 13  Epoch: 288  Training loss = 2.4649  Validation loss = 3.5060  \n",
      "\n",
      "Fold: 13  Epoch: 289  Training loss = 2.4647  Validation loss = 3.5073  \n",
      "\n",
      "Fold: 13  Epoch: 290  Training loss = 2.4645  Validation loss = 3.5061  \n",
      "\n",
      "Fold: 13  Epoch: 291  Training loss = 2.4642  Validation loss = 3.5056  \n",
      "\n",
      "Fold: 13  Epoch: 292  Training loss = 2.4640  Validation loss = 3.5047  \n",
      "\n",
      "Fold: 13  Epoch: 293  Training loss = 2.4638  Validation loss = 3.5039  \n",
      "\n",
      "Fold: 13  Epoch: 294  Training loss = 2.4634  Validation loss = 3.5025  \n",
      "\n",
      "Fold: 13  Epoch: 295  Training loss = 2.4630  Validation loss = 3.5013  \n",
      "\n",
      "Fold: 13  Epoch: 296  Training loss = 2.4626  Validation loss = 3.5009  \n",
      "\n",
      "Fold: 13  Epoch: 297  Training loss = 2.4624  Validation loss = 3.5014  \n",
      "\n",
      "Fold: 13  Epoch: 298  Training loss = 2.4619  Validation loss = 3.4994  \n",
      "\n",
      "Fold: 13  Epoch: 299  Training loss = 2.4614  Validation loss = 3.4985  \n",
      "\n",
      "Fold: 13  Epoch: 300  Training loss = 2.4612  Validation loss = 3.4981  \n",
      "\n",
      "Fold: 13  Epoch: 301  Training loss = 2.4609  Validation loss = 3.4975  \n",
      "\n",
      "Fold: 13  Epoch: 302  Training loss = 2.4607  Validation loss = 3.4979  \n",
      "\n",
      "Fold: 13  Epoch: 303  Training loss = 2.4604  Validation loss = 3.4967  \n",
      "\n",
      "Fold: 13  Epoch: 304  Training loss = 2.4602  Validation loss = 3.4963  \n",
      "\n",
      "Fold: 13  Epoch: 305  Training loss = 2.4600  Validation loss = 3.4968  \n",
      "\n",
      "Fold: 13  Epoch: 306  Training loss = 2.4598  Validation loss = 3.4969  \n",
      "\n",
      "Fold: 13  Epoch: 307  Training loss = 2.4595  Validation loss = 3.4956  \n",
      "\n",
      "Fold: 13  Epoch: 308  Training loss = 2.4591  Validation loss = 3.4951  \n",
      "\n",
      "Fold: 13  Epoch: 309  Training loss = 2.4589  Validation loss = 3.4947  \n",
      "\n",
      "Fold: 13  Epoch: 310  Training loss = 2.4583  Validation loss = 3.4928  \n",
      "\n",
      "Fold: 13  Epoch: 311  Training loss = 2.4581  Validation loss = 3.4919  \n",
      "\n",
      "Fold: 13  Epoch: 312  Training loss = 2.4577  Validation loss = 3.4908  \n",
      "\n",
      "Fold: 13  Epoch: 313  Training loss = 2.4574  Validation loss = 3.4899  \n",
      "\n",
      "Fold: 13  Epoch: 314  Training loss = 2.4572  Validation loss = 3.4894  \n",
      "\n",
      "Fold: 13  Epoch: 315  Training loss = 2.4569  Validation loss = 3.4888  \n",
      "\n",
      "Fold: 13  Epoch: 316  Training loss = 2.4566  Validation loss = 3.4876  \n",
      "\n",
      "Fold: 13  Epoch: 317  Training loss = 2.4562  Validation loss = 3.4862  \n",
      "\n",
      "Fold: 13  Epoch: 318  Training loss = 2.4559  Validation loss = 3.4854  \n",
      "\n",
      "Fold: 13  Epoch: 319  Training loss = 2.4556  Validation loss = 3.4854  \n",
      "\n",
      "Fold: 13  Epoch: 320  Training loss = 2.4555  Validation loss = 3.4851  \n",
      "\n",
      "Fold: 13  Epoch: 321  Training loss = 2.4552  Validation loss = 3.4846  \n",
      "\n",
      "Fold: 13  Epoch: 322  Training loss = 2.4548  Validation loss = 3.4835  \n",
      "\n",
      "Fold: 13  Epoch: 323  Training loss = 2.4545  Validation loss = 3.4830  \n",
      "\n",
      "Fold: 13  Epoch: 324  Training loss = 2.4543  Validation loss = 3.4830  \n",
      "\n",
      "Fold: 13  Epoch: 325  Training loss = 2.4542  Validation loss = 3.4833  \n",
      "\n",
      "Fold: 13  Epoch: 326  Training loss = 2.4539  Validation loss = 3.4821  \n",
      "\n",
      "Fold: 13  Epoch: 327  Training loss = 2.4535  Validation loss = 3.4808  \n",
      "\n",
      "Fold: 13  Epoch: 328  Training loss = 2.4531  Validation loss = 3.4794  \n",
      "\n",
      "Fold: 13  Epoch: 329  Training loss = 2.4528  Validation loss = 3.4782  \n",
      "\n",
      "Fold: 13  Epoch: 330  Training loss = 2.4523  Validation loss = 3.4766  \n",
      "\n",
      "Fold: 13  Epoch: 331  Training loss = 2.4520  Validation loss = 3.4760  \n",
      "\n",
      "Fold: 13  Epoch: 332  Training loss = 2.4517  Validation loss = 3.4751  \n",
      "\n",
      "Fold: 13  Epoch: 333  Training loss = 2.4513  Validation loss = 3.4738  \n",
      "\n",
      "Fold: 13  Epoch: 334  Training loss = 2.4510  Validation loss = 3.4736  \n",
      "\n",
      "Fold: 13  Epoch: 335  Training loss = 2.4507  Validation loss = 3.4728  \n",
      "\n",
      "Fold: 13  Epoch: 336  Training loss = 2.4505  Validation loss = 3.4724  \n",
      "\n",
      "Fold: 13  Epoch: 337  Training loss = 2.4503  Validation loss = 3.4722  \n",
      "\n",
      "Fold: 13  Epoch: 338  Training loss = 2.4499  Validation loss = 3.4699  \n",
      "\n",
      "Fold: 13  Epoch: 339  Training loss = 2.4495  Validation loss = 3.4691  \n",
      "\n",
      "Fold: 13  Epoch: 340  Training loss = 2.4492  Validation loss = 3.4680  \n",
      "\n",
      "Fold: 13  Epoch: 341  Training loss = 2.4489  Validation loss = 3.4676  \n",
      "\n",
      "Fold: 13  Epoch: 342  Training loss = 2.4487  Validation loss = 3.4675  \n",
      "\n",
      "Fold: 13  Epoch: 343  Training loss = 2.4485  Validation loss = 3.4673  \n",
      "\n",
      "Fold: 13  Epoch: 344  Training loss = 2.4481  Validation loss = 3.4660  \n",
      "\n",
      "Fold: 13  Epoch: 345  Training loss = 2.4479  Validation loss = 3.4658  \n",
      "\n",
      "Fold: 13  Epoch: 346  Training loss = 2.4476  Validation loss = 3.4645  \n",
      "\n",
      "Fold: 13  Epoch: 347  Training loss = 2.4473  Validation loss = 3.4644  \n",
      "\n",
      "Fold: 13  Epoch: 348  Training loss = 2.4469  Validation loss = 3.4637  \n",
      "\n",
      "Fold: 13  Epoch: 349  Training loss = 2.4464  Validation loss = 3.4622  \n",
      "\n",
      "Fold: 13  Epoch: 350  Training loss = 2.4460  Validation loss = 3.4611  \n",
      "\n",
      "Fold: 13  Epoch: 351  Training loss = 2.4456  Validation loss = 3.4590  \n",
      "\n",
      "Fold: 13  Epoch: 352  Training loss = 2.4454  Validation loss = 3.4586  \n",
      "\n",
      "Fold: 13  Epoch: 353  Training loss = 2.4451  Validation loss = 3.4581  \n",
      "\n",
      "Fold: 13  Epoch: 354  Training loss = 2.4450  Validation loss = 3.4577  \n",
      "\n",
      "Fold: 13  Epoch: 355  Training loss = 2.4445  Validation loss = 3.4567  \n",
      "\n",
      "Fold: 13  Epoch: 356  Training loss = 2.4443  Validation loss = 3.4561  \n",
      "\n",
      "Fold: 13  Epoch: 357  Training loss = 2.4439  Validation loss = 3.4550  \n",
      "\n",
      "Fold: 13  Epoch: 358  Training loss = 2.4437  Validation loss = 3.4550  \n",
      "\n",
      "Fold: 13  Epoch: 359  Training loss = 2.4435  Validation loss = 3.4554  \n",
      "\n",
      "Fold: 13  Epoch: 360  Training loss = 2.4433  Validation loss = 3.4546  \n",
      "\n",
      "Fold: 13  Epoch: 361  Training loss = 2.4429  Validation loss = 3.4533  \n",
      "\n",
      "Fold: 13  Epoch: 362  Training loss = 2.4425  Validation loss = 3.4523  \n",
      "\n",
      "Fold: 13  Epoch: 363  Training loss = 2.4423  Validation loss = 3.4526  \n",
      "\n",
      "Fold: 13  Epoch: 364  Training loss = 2.4419  Validation loss = 3.4517  \n",
      "\n",
      "Fold: 13  Epoch: 365  Training loss = 2.4415  Validation loss = 3.4503  \n",
      "\n",
      "Fold: 13  Epoch: 366  Training loss = 2.4410  Validation loss = 3.4484  \n",
      "\n",
      "Fold: 13  Epoch: 367  Training loss = 2.4408  Validation loss = 3.4484  \n",
      "\n",
      "Fold: 13  Epoch: 368  Training loss = 2.4405  Validation loss = 3.4479  \n",
      "\n",
      "Fold: 13  Epoch: 369  Training loss = 2.4403  Validation loss = 3.4476  \n",
      "\n",
      "Fold: 13  Epoch: 370  Training loss = 2.4400  Validation loss = 3.4472  \n",
      "\n",
      "Fold: 13  Epoch: 371  Training loss = 2.4397  Validation loss = 3.4465  \n",
      "\n",
      "Fold: 13  Epoch: 372  Training loss = 2.4394  Validation loss = 3.4456  \n",
      "\n",
      "Fold: 13  Epoch: 373  Training loss = 2.4388  Validation loss = 3.4432  \n",
      "\n",
      "Fold: 13  Epoch: 374  Training loss = 2.4386  Validation loss = 3.4431  \n",
      "\n",
      "Fold: 13  Epoch: 375  Training loss = 2.4382  Validation loss = 3.4417  \n",
      "\n",
      "Fold: 13  Epoch: 376  Training loss = 2.4377  Validation loss = 3.4399  \n",
      "\n",
      "Fold: 13  Epoch: 377  Training loss = 2.4374  Validation loss = 3.4395  \n",
      "\n",
      "Fold: 13  Epoch: 378  Training loss = 2.4371  Validation loss = 3.4393  \n",
      "\n",
      "Fold: 13  Epoch: 379  Training loss = 2.4370  Validation loss = 3.4396  \n",
      "\n",
      "Fold: 13  Epoch: 380  Training loss = 2.4367  Validation loss = 3.4385  \n",
      "\n",
      "Fold: 13  Epoch: 381  Training loss = 2.4364  Validation loss = 3.4372  \n",
      "\n",
      "Fold: 13  Epoch: 382  Training loss = 2.4362  Validation loss = 3.4365  \n",
      "\n",
      "Fold: 13  Epoch: 383  Training loss = 2.4357  Validation loss = 3.4349  \n",
      "\n",
      "Fold: 13  Epoch: 384  Training loss = 2.4354  Validation loss = 3.4344  \n",
      "\n",
      "Fold: 13  Epoch: 385  Training loss = 2.4351  Validation loss = 3.4340  \n",
      "\n",
      "Fold: 13  Epoch: 386  Training loss = 2.4350  Validation loss = 3.4339  \n",
      "\n",
      "Fold: 13  Epoch: 387  Training loss = 2.4347  Validation loss = 3.4331  \n",
      "\n",
      "Fold: 13  Epoch: 388  Training loss = 2.4346  Validation loss = 3.4335  \n",
      "\n",
      "Fold: 13  Epoch: 389  Training loss = 2.4342  Validation loss = 3.4328  \n",
      "\n",
      "Fold: 13  Epoch: 390  Training loss = 2.4340  Validation loss = 3.4326  \n",
      "\n",
      "Fold: 13  Epoch: 391  Training loss = 2.4335  Validation loss = 3.4307  \n",
      "\n",
      "Fold: 13  Epoch: 392  Training loss = 2.4330  Validation loss = 3.4295  \n",
      "\n",
      "Fold: 13  Epoch: 393  Training loss = 2.4329  Validation loss = 3.4303  \n",
      "\n",
      "Fold: 13  Epoch: 394  Training loss = 2.4328  Validation loss = 3.4303  \n",
      "\n",
      "Fold: 13  Epoch: 395  Training loss = 2.4325  Validation loss = 3.4302  \n",
      "\n",
      "Fold: 13  Epoch: 396  Training loss = 2.4323  Validation loss = 3.4299  \n",
      "\n",
      "Fold: 13  Epoch: 397  Training loss = 2.4318  Validation loss = 3.4279  \n",
      "\n",
      "Fold: 13  Epoch: 398  Training loss = 2.4315  Validation loss = 3.4270  \n",
      "\n",
      "Fold: 13  Epoch: 399  Training loss = 2.4312  Validation loss = 3.4265  \n",
      "\n",
      "Fold: 13  Epoch: 400  Training loss = 2.4312  Validation loss = 3.4275  \n",
      "\n",
      "Fold: 13  Epoch: 401  Training loss = 2.4310  Validation loss = 3.4281  \n",
      "\n",
      "Fold: 13  Epoch: 402  Training loss = 2.4308  Validation loss = 3.4281  \n",
      "\n",
      "Fold: 13  Epoch: 403  Training loss = 2.4305  Validation loss = 3.4272  \n",
      "\n",
      "Fold: 13  Epoch: 404  Training loss = 2.4300  Validation loss = 3.4255  \n",
      "\n",
      "Fold: 13  Epoch: 405  Training loss = 2.4297  Validation loss = 3.4247  \n",
      "\n",
      "Fold: 13  Epoch: 406  Training loss = 2.4293  Validation loss = 3.4239  \n",
      "\n",
      "Fold: 13  Epoch: 407  Training loss = 2.4289  Validation loss = 3.4230  \n",
      "\n",
      "Fold: 13  Epoch: 408  Training loss = 2.4287  Validation loss = 3.4219  \n",
      "\n",
      "Fold: 13  Epoch: 409  Training loss = 2.4285  Validation loss = 3.4218  \n",
      "\n",
      "Fold: 13  Epoch: 410  Training loss = 2.4283  Validation loss = 3.4216  \n",
      "\n",
      "Fold: 13  Epoch: 411  Training loss = 2.4280  Validation loss = 3.4213  \n",
      "\n",
      "Fold: 13  Epoch: 412  Training loss = 2.4278  Validation loss = 3.4214  \n",
      "\n",
      "Fold: 13  Epoch: 413  Training loss = 2.4276  Validation loss = 3.4205  \n",
      "\n",
      "Fold: 13  Epoch: 414  Training loss = 2.4271  Validation loss = 3.4188  \n",
      "\n",
      "Fold: 13  Epoch: 415  Training loss = 2.4269  Validation loss = 3.4184  \n",
      "\n",
      "Fold: 13  Epoch: 416  Training loss = 2.4264  Validation loss = 3.4173  \n",
      "\n",
      "Fold: 13  Epoch: 417  Training loss = 2.4260  Validation loss = 3.4156  \n",
      "\n",
      "Fold: 13  Epoch: 418  Training loss = 2.4256  Validation loss = 3.4153  \n",
      "\n",
      "Fold: 13  Epoch: 419  Training loss = 2.4254  Validation loss = 3.4153  \n",
      "\n",
      "Fold: 13  Epoch: 420  Training loss = 2.4253  Validation loss = 3.4153  \n",
      "\n",
      "Fold: 13  Epoch: 421  Training loss = 2.4247  Validation loss = 3.4132  \n",
      "\n",
      "Fold: 13  Epoch: 422  Training loss = 2.4245  Validation loss = 3.4130  \n",
      "\n",
      "Fold: 13  Epoch: 423  Training loss = 2.4243  Validation loss = 3.4127  \n",
      "\n",
      "Fold: 13  Epoch: 424  Training loss = 2.4241  Validation loss = 3.4124  \n",
      "\n",
      "Fold: 13  Epoch: 425  Training loss = 2.4239  Validation loss = 3.4118  \n",
      "\n",
      "Fold: 13  Epoch: 426  Training loss = 2.4237  Validation loss = 3.4108  \n",
      "\n",
      "Fold: 13  Epoch: 427  Training loss = 2.4232  Validation loss = 3.4091  \n",
      "\n",
      "Fold: 13  Epoch: 428  Training loss = 2.4230  Validation loss = 3.4089  \n",
      "\n",
      "Fold: 13  Epoch: 429  Training loss = 2.4227  Validation loss = 3.4084  \n",
      "\n",
      "Fold: 13  Epoch: 430  Training loss = 2.4223  Validation loss = 3.4071  \n",
      "\n",
      "Fold: 13  Epoch: 431  Training loss = 2.4220  Validation loss = 3.4064  \n",
      "\n",
      "Fold: 13  Epoch: 432  Training loss = 2.4217  Validation loss = 3.4052  \n",
      "\n",
      "Fold: 13  Epoch: 433  Training loss = 2.4213  Validation loss = 3.4041  \n",
      "\n",
      "Fold: 13  Epoch: 434  Training loss = 2.4209  Validation loss = 3.4024  \n",
      "\n",
      "Fold: 13  Epoch: 435  Training loss = 2.4205  Validation loss = 3.4007  \n",
      "\n",
      "Fold: 13  Epoch: 436  Training loss = 2.4201  Validation loss = 3.3995  \n",
      "\n",
      "Fold: 13  Epoch: 437  Training loss = 2.4196  Validation loss = 3.3972  \n",
      "\n",
      "Fold: 13  Epoch: 438  Training loss = 2.4193  Validation loss = 3.3963  \n",
      "\n",
      "Fold: 13  Epoch: 439  Training loss = 2.4189  Validation loss = 3.3964  \n",
      "\n",
      "Fold: 13  Epoch: 440  Training loss = 2.4187  Validation loss = 3.3953  \n",
      "\n",
      "Fold: 13  Epoch: 441  Training loss = 2.4185  Validation loss = 3.3954  \n",
      "\n",
      "Fold: 13  Epoch: 442  Training loss = 2.4183  Validation loss = 3.3946  \n",
      "\n",
      "Fold: 13  Epoch: 443  Training loss = 2.4182  Validation loss = 3.3952  \n",
      "\n",
      "Fold: 13  Epoch: 444  Training loss = 2.4178  Validation loss = 3.3936  \n",
      "\n",
      "Fold: 13  Epoch: 445  Training loss = 2.4175  Validation loss = 3.3925  \n",
      "\n",
      "Fold: 13  Epoch: 446  Training loss = 2.4172  Validation loss = 3.3911  \n",
      "\n",
      "Fold: 13  Epoch: 447  Training loss = 2.4170  Validation loss = 3.3910  \n",
      "\n",
      "Fold: 13  Epoch: 448  Training loss = 2.4167  Validation loss = 3.3912  \n",
      "\n",
      "Fold: 13  Epoch: 449  Training loss = 2.4166  Validation loss = 3.3913  \n",
      "\n",
      "Fold: 13  Epoch: 450  Training loss = 2.4163  Validation loss = 3.3895  \n",
      "\n",
      "Fold: 13  Epoch: 451  Training loss = 2.4161  Validation loss = 3.3900  \n",
      "\n",
      "Fold: 13  Epoch: 452  Training loss = 2.4160  Validation loss = 3.3905  \n",
      "\n",
      "Fold: 13  Epoch: 453  Training loss = 2.4157  Validation loss = 3.3900  \n",
      "\n",
      "Fold: 13  Epoch: 454  Training loss = 2.4155  Validation loss = 3.3890  \n",
      "\n",
      "Fold: 13  Epoch: 455  Training loss = 2.4154  Validation loss = 3.3894  \n",
      "\n",
      "Fold: 13  Epoch: 456  Training loss = 2.4151  Validation loss = 3.3888  \n",
      "\n",
      "Fold: 13  Epoch: 457  Training loss = 2.4147  Validation loss = 3.3875  \n",
      "\n",
      "Fold: 13  Epoch: 458  Training loss = 2.4145  Validation loss = 3.3871  \n",
      "\n",
      "Fold: 13  Epoch: 459  Training loss = 2.4143  Validation loss = 3.3864  \n",
      "\n",
      "Fold: 13  Epoch: 460  Training loss = 2.4141  Validation loss = 3.3860  \n",
      "\n",
      "Fold: 13  Epoch: 461  Training loss = 2.4138  Validation loss = 3.3852  \n",
      "\n",
      "Fold: 13  Epoch: 462  Training loss = 2.4135  Validation loss = 3.3847  \n",
      "\n",
      "Fold: 13  Epoch: 463  Training loss = 2.4132  Validation loss = 3.3837  \n",
      "\n",
      "Fold: 13  Epoch: 464  Training loss = 2.4129  Validation loss = 3.3822  \n",
      "\n",
      "Fold: 13  Epoch: 465  Training loss = 2.4128  Validation loss = 3.3822  \n",
      "\n",
      "Fold: 13  Epoch: 466  Training loss = 2.4124  Validation loss = 3.3811  \n",
      "\n",
      "Fold: 13  Epoch: 467  Training loss = 2.4121  Validation loss = 3.3805  \n",
      "\n",
      "Fold: 13  Epoch: 468  Training loss = 2.4120  Validation loss = 3.3804  \n",
      "\n",
      "Fold: 13  Epoch: 469  Training loss = 2.4117  Validation loss = 3.3798  \n",
      "\n",
      "Fold: 13  Epoch: 470  Training loss = 2.4114  Validation loss = 3.3792  \n",
      "\n",
      "Fold: 13  Epoch: 471  Training loss = 2.4111  Validation loss = 3.3786  \n",
      "\n",
      "Fold: 13  Epoch: 472  Training loss = 2.4107  Validation loss = 3.3770  \n",
      "\n",
      "Fold: 13  Epoch: 473  Training loss = 2.4104  Validation loss = 3.3752  \n",
      "\n",
      "Fold: 13  Epoch: 474  Training loss = 2.4101  Validation loss = 3.3752  \n",
      "\n",
      "Fold: 13  Epoch: 475  Training loss = 2.4098  Validation loss = 3.3752  \n",
      "\n",
      "Fold: 13  Epoch: 476  Training loss = 2.4096  Validation loss = 3.3745  \n",
      "\n",
      "Fold: 13  Epoch: 477  Training loss = 2.4093  Validation loss = 3.3743  \n",
      "\n",
      "Fold: 13  Epoch: 478  Training loss = 2.4091  Validation loss = 3.3728  \n",
      "\n",
      "Fold: 13  Epoch: 479  Training loss = 2.4088  Validation loss = 3.3724  \n",
      "\n",
      "Fold: 13  Epoch: 480  Training loss = 2.4086  Validation loss = 3.3719  \n",
      "\n",
      "Fold: 13  Epoch: 481  Training loss = 2.4082  Validation loss = 3.3710  \n",
      "\n",
      "Fold: 13  Epoch: 482  Training loss = 2.4079  Validation loss = 3.3710  \n",
      "\n",
      "Fold: 13  Epoch: 483  Training loss = 2.4076  Validation loss = 3.3694  \n",
      "\n",
      "Fold: 13  Epoch: 484  Training loss = 2.4073  Validation loss = 3.3692  \n",
      "\n",
      "Fold: 13  Epoch: 485  Training loss = 2.4070  Validation loss = 3.3685  \n",
      "\n",
      "Fold: 13  Epoch: 486  Training loss = 2.4068  Validation loss = 3.3689  \n",
      "\n",
      "Fold: 13  Epoch: 487  Training loss = 2.4065  Validation loss = 3.3674  \n",
      "\n",
      "Fold: 13  Epoch: 488  Training loss = 2.4062  Validation loss = 3.3664  \n",
      "\n",
      "Fold: 13  Epoch: 489  Training loss = 2.4060  Validation loss = 3.3657  \n",
      "\n",
      "Fold: 13  Epoch: 490  Training loss = 2.4058  Validation loss = 3.3658  \n",
      "\n",
      "Fold: 13  Epoch: 491  Training loss = 2.4056  Validation loss = 3.3654  \n",
      "\n",
      "Fold: 13  Epoch: 492  Training loss = 2.4053  Validation loss = 3.3645  \n",
      "\n",
      "Fold: 13  Epoch: 493  Training loss = 2.4053  Validation loss = 3.3653  \n",
      "\n",
      "Fold: 13  Epoch: 494  Training loss = 2.4050  Validation loss = 3.3643  \n",
      "\n",
      "Fold: 13  Epoch: 495  Training loss = 2.4048  Validation loss = 3.3636  \n",
      "\n",
      "Fold: 13  Epoch: 496  Training loss = 2.4046  Validation loss = 3.3632  \n",
      "\n",
      "Fold: 13  Epoch: 497  Training loss = 2.4043  Validation loss = 3.3622  \n",
      "\n",
      "Fold: 13  Epoch: 498  Training loss = 2.4040  Validation loss = 3.3621  \n",
      "\n",
      "Fold: 13  Epoch: 499  Training loss = 2.4037  Validation loss = 3.3615  \n",
      "\n",
      "Fold: 13  Epoch: 500  Training loss = 2.4036  Validation loss = 3.3622  \n",
      "\n",
      "Check model:  Fold: 13  Optimal epoch: 499  \n",
      "\n",
      "Fold: 14  Epoch: 1  Training loss = 2.5223  Validation loss = 6.7317  \n",
      "\n",
      "Fold: 14  Epoch: 2  Training loss = 2.5217  Validation loss = 6.7304  \n",
      "\n",
      "Fold: 14  Epoch: 3  Training loss = 2.5213  Validation loss = 6.7286  \n",
      "\n",
      "Fold: 14  Epoch: 4  Training loss = 2.5211  Validation loss = 6.7281  \n",
      "\n",
      "Fold: 14  Epoch: 5  Training loss = 2.5208  Validation loss = 6.7272  \n",
      "\n",
      "Fold: 14  Epoch: 6  Training loss = 2.5205  Validation loss = 6.7259  \n",
      "\n",
      "Fold: 14  Epoch: 7  Training loss = 2.5200  Validation loss = 6.7237  \n",
      "\n",
      "Fold: 14  Epoch: 8  Training loss = 2.5200  Validation loss = 6.7235  \n",
      "\n",
      "Fold: 14  Epoch: 9  Training loss = 2.5197  Validation loss = 6.7218  \n",
      "\n",
      "Fold: 14  Epoch: 10  Training loss = 2.5192  Validation loss = 6.7203  \n",
      "\n",
      "Fold: 14  Epoch: 11  Training loss = 2.5188  Validation loss = 6.7192  \n",
      "\n",
      "Fold: 14  Epoch: 12  Training loss = 2.5184  Validation loss = 6.7176  \n",
      "\n",
      "Fold: 14  Epoch: 13  Training loss = 2.5178  Validation loss = 6.7155  \n",
      "\n",
      "Fold: 14  Epoch: 14  Training loss = 2.5169  Validation loss = 6.7118  \n",
      "\n",
      "Fold: 14  Epoch: 15  Training loss = 2.5166  Validation loss = 6.7106  \n",
      "\n",
      "Fold: 14  Epoch: 16  Training loss = 2.5161  Validation loss = 6.7084  \n",
      "\n",
      "Fold: 14  Epoch: 17  Training loss = 2.5161  Validation loss = 6.7080  \n",
      "\n",
      "Fold: 14  Epoch: 18  Training loss = 2.5158  Validation loss = 6.7068  \n",
      "\n",
      "Fold: 14  Epoch: 19  Training loss = 2.5154  Validation loss = 6.7050  \n",
      "\n",
      "Fold: 14  Epoch: 20  Training loss = 2.5147  Validation loss = 6.7023  \n",
      "\n",
      "Fold: 14  Epoch: 21  Training loss = 2.5141  Validation loss = 6.7000  \n",
      "\n",
      "Fold: 14  Epoch: 22  Training loss = 2.5137  Validation loss = 6.6988  \n",
      "\n",
      "Fold: 14  Epoch: 23  Training loss = 2.5133  Validation loss = 6.6973  \n",
      "\n",
      "Fold: 14  Epoch: 24  Training loss = 2.5136  Validation loss = 6.6985  \n",
      "\n",
      "Fold: 14  Epoch: 25  Training loss = 2.5132  Validation loss = 6.6967  \n",
      "\n",
      "Fold: 14  Epoch: 26  Training loss = 2.5124  Validation loss = 6.6933  \n",
      "\n",
      "Fold: 14  Epoch: 27  Training loss = 2.5119  Validation loss = 6.6916  \n",
      "\n",
      "Fold: 14  Epoch: 28  Training loss = 2.5116  Validation loss = 6.6901  \n",
      "\n",
      "Fold: 14  Epoch: 29  Training loss = 2.5112  Validation loss = 6.6886  \n",
      "\n",
      "Fold: 14  Epoch: 30  Training loss = 2.5108  Validation loss = 6.6865  \n",
      "\n",
      "Fold: 14  Epoch: 31  Training loss = 2.5107  Validation loss = 6.6857  \n",
      "\n",
      "Fold: 14  Epoch: 32  Training loss = 2.5104  Validation loss = 6.6843  \n",
      "\n",
      "Fold: 14  Epoch: 33  Training loss = 2.5100  Validation loss = 6.6828  \n",
      "\n",
      "Fold: 14  Epoch: 34  Training loss = 2.5097  Validation loss = 6.6815  \n",
      "\n",
      "Fold: 14  Epoch: 35  Training loss = 2.5093  Validation loss = 6.6799  \n",
      "\n",
      "Fold: 14  Epoch: 36  Training loss = 2.5093  Validation loss = 6.6799  \n",
      "\n",
      "Fold: 14  Epoch: 37  Training loss = 2.5086  Validation loss = 6.6769  \n",
      "\n",
      "Fold: 14  Epoch: 38  Training loss = 2.5083  Validation loss = 6.6762  \n",
      "\n",
      "Fold: 14  Epoch: 39  Training loss = 2.5082  Validation loss = 6.6756  \n",
      "\n",
      "Fold: 14  Epoch: 40  Training loss = 2.5079  Validation loss = 6.6746  \n",
      "\n",
      "Fold: 14  Epoch: 41  Training loss = 2.5079  Validation loss = 6.6744  \n",
      "\n",
      "Fold: 14  Epoch: 42  Training loss = 2.5074  Validation loss = 6.6722  \n",
      "\n",
      "Fold: 14  Epoch: 43  Training loss = 2.5073  Validation loss = 6.6716  \n",
      "\n",
      "Fold: 14  Epoch: 44  Training loss = 2.5068  Validation loss = 6.6689  \n",
      "\n",
      "Fold: 14  Epoch: 45  Training loss = 2.5062  Validation loss = 6.6666  \n",
      "\n",
      "Fold: 14  Epoch: 46  Training loss = 2.5060  Validation loss = 6.6652  \n",
      "\n",
      "Fold: 14  Epoch: 47  Training loss = 2.5058  Validation loss = 6.6645  \n",
      "\n",
      "Fold: 14  Epoch: 48  Training loss = 2.5055  Validation loss = 6.6625  \n",
      "\n",
      "Fold: 14  Epoch: 49  Training loss = 2.5050  Validation loss = 6.6607  \n",
      "\n",
      "Fold: 14  Epoch: 50  Training loss = 2.5044  Validation loss = 6.6579  \n",
      "\n",
      "Fold: 14  Epoch: 51  Training loss = 2.5042  Validation loss = 6.6573  \n",
      "\n",
      "Fold: 14  Epoch: 52  Training loss = 2.5036  Validation loss = 6.6545  \n",
      "\n",
      "Fold: 14  Epoch: 53  Training loss = 2.5032  Validation loss = 6.6526  \n",
      "\n",
      "Fold: 14  Epoch: 54  Training loss = 2.5027  Validation loss = 6.6506  \n",
      "\n",
      "Fold: 14  Epoch: 55  Training loss = 2.5024  Validation loss = 6.6495  \n",
      "\n",
      "Fold: 14  Epoch: 56  Training loss = 2.5024  Validation loss = 6.6495  \n",
      "\n",
      "Fold: 14  Epoch: 57  Training loss = 2.5021  Validation loss = 6.6480  \n",
      "\n",
      "Fold: 14  Epoch: 58  Training loss = 2.5018  Validation loss = 6.6466  \n",
      "\n",
      "Fold: 14  Epoch: 59  Training loss = 2.5014  Validation loss = 6.6448  \n",
      "\n",
      "Fold: 14  Epoch: 60  Training loss = 2.5009  Validation loss = 6.6431  \n",
      "\n",
      "Fold: 14  Epoch: 61  Training loss = 2.5005  Validation loss = 6.6415  \n",
      "\n",
      "Fold: 14  Epoch: 62  Training loss = 2.5003  Validation loss = 6.6410  \n",
      "\n",
      "Fold: 14  Epoch: 63  Training loss = 2.5000  Validation loss = 6.6397  \n",
      "\n",
      "Fold: 14  Epoch: 64  Training loss = 2.4994  Validation loss = 6.6373  \n",
      "\n",
      "Fold: 14  Epoch: 65  Training loss = 2.4984  Validation loss = 6.6366  \n",
      "\n",
      "Fold: 14  Epoch: 66  Training loss = 2.4981  Validation loss = 6.6354  \n",
      "\n",
      "Fold: 14  Epoch: 67  Training loss = 2.4980  Validation loss = 6.6350  \n",
      "\n",
      "Fold: 14  Epoch: 68  Training loss = 2.4977  Validation loss = 6.6341  \n",
      "\n",
      "Fold: 14  Epoch: 69  Training loss = 2.4973  Validation loss = 6.6324  \n",
      "\n",
      "Fold: 14  Epoch: 70  Training loss = 2.4969  Validation loss = 6.6309  \n",
      "\n",
      "Fold: 14  Epoch: 71  Training loss = 2.4963  Validation loss = 6.6283  \n",
      "\n",
      "Fold: 14  Epoch: 72  Training loss = 2.4963  Validation loss = 6.6277  \n",
      "\n",
      "Fold: 14  Epoch: 73  Training loss = 2.4961  Validation loss = 6.6271  \n",
      "\n",
      "Fold: 14  Epoch: 74  Training loss = 2.4957  Validation loss = 6.6253  \n",
      "\n",
      "Fold: 14  Epoch: 75  Training loss = 2.4953  Validation loss = 6.6236  \n",
      "\n",
      "Fold: 14  Epoch: 76  Training loss = 2.4949  Validation loss = 6.6213  \n",
      "\n",
      "Fold: 14  Epoch: 77  Training loss = 2.4947  Validation loss = 6.6207  \n",
      "\n",
      "Fold: 14  Epoch: 78  Training loss = 2.4944  Validation loss = 6.6196  \n",
      "\n",
      "Fold: 14  Epoch: 79  Training loss = 2.4939  Validation loss = 6.6170  \n",
      "\n",
      "Fold: 14  Epoch: 80  Training loss = 2.4935  Validation loss = 6.6151  \n",
      "\n",
      "Fold: 14  Epoch: 81  Training loss = 2.4934  Validation loss = 6.6152  \n",
      "\n",
      "Fold: 14  Epoch: 82  Training loss = 2.4930  Validation loss = 6.6136  \n",
      "\n",
      "Fold: 14  Epoch: 83  Training loss = 2.4926  Validation loss = 6.6118  \n",
      "\n",
      "Fold: 14  Epoch: 84  Training loss = 2.4925  Validation loss = 6.6111  \n",
      "\n",
      "Fold: 14  Epoch: 85  Training loss = 2.4922  Validation loss = 6.6100  \n",
      "\n",
      "Fold: 14  Epoch: 86  Training loss = 2.4919  Validation loss = 6.6088  \n",
      "\n",
      "Fold: 14  Epoch: 87  Training loss = 2.4915  Validation loss = 6.6068  \n",
      "\n",
      "Fold: 14  Epoch: 88  Training loss = 2.4913  Validation loss = 6.6054  \n",
      "\n",
      "Fold: 14  Epoch: 89  Training loss = 2.4913  Validation loss = 6.6059  \n",
      "\n",
      "Fold: 14  Epoch: 90  Training loss = 2.4910  Validation loss = 6.6049  \n",
      "\n",
      "Fold: 14  Epoch: 91  Training loss = 2.4909  Validation loss = 6.6048  \n",
      "\n",
      "Fold: 14  Epoch: 92  Training loss = 2.4907  Validation loss = 6.6042  \n",
      "\n",
      "Fold: 14  Epoch: 93  Training loss = 2.4903  Validation loss = 6.6021  \n",
      "\n",
      "Fold: 14  Epoch: 94  Training loss = 2.4900  Validation loss = 6.6004  \n",
      "\n",
      "Fold: 14  Epoch: 95  Training loss = 2.4893  Validation loss = 6.5969  \n",
      "\n",
      "Fold: 14  Epoch: 96  Training loss = 2.4891  Validation loss = 6.5958  \n",
      "\n",
      "Fold: 14  Epoch: 97  Training loss = 2.4890  Validation loss = 6.5957  \n",
      "\n",
      "Fold: 14  Epoch: 98  Training loss = 2.4886  Validation loss = 6.5938  \n",
      "\n",
      "Fold: 14  Epoch: 99  Training loss = 2.4886  Validation loss = 6.5944  \n",
      "\n",
      "Fold: 14  Epoch: 100  Training loss = 2.4884  Validation loss = 6.5937  \n",
      "\n",
      "Fold: 14  Epoch: 101  Training loss = 2.4881  Validation loss = 6.5915  \n",
      "\n",
      "Fold: 14  Epoch: 102  Training loss = 2.4877  Validation loss = 6.5899  \n",
      "\n",
      "Fold: 14  Epoch: 103  Training loss = 2.4872  Validation loss = 6.5871  \n",
      "\n",
      "Fold: 14  Epoch: 104  Training loss = 2.4870  Validation loss = 6.5859  \n",
      "\n",
      "Fold: 14  Epoch: 105  Training loss = 2.4868  Validation loss = 6.5851  \n",
      "\n",
      "Fold: 14  Epoch: 106  Training loss = 2.4863  Validation loss = 6.5823  \n",
      "\n",
      "Fold: 14  Epoch: 107  Training loss = 2.4860  Validation loss = 6.5809  \n",
      "\n",
      "Fold: 14  Epoch: 108  Training loss = 2.4858  Validation loss = 6.5795  \n",
      "\n",
      "Fold: 14  Epoch: 109  Training loss = 2.4856  Validation loss = 6.5784  \n",
      "\n",
      "Fold: 14  Epoch: 110  Training loss = 2.4853  Validation loss = 6.5764  \n",
      "\n",
      "Fold: 14  Epoch: 111  Training loss = 2.4850  Validation loss = 6.5755  \n",
      "\n",
      "Fold: 14  Epoch: 112  Training loss = 2.4847  Validation loss = 6.5733  \n",
      "\n",
      "Fold: 14  Epoch: 113  Training loss = 2.4842  Validation loss = 6.5706  \n",
      "\n",
      "Fold: 14  Epoch: 114  Training loss = 2.4838  Validation loss = 6.5684  \n",
      "\n",
      "Fold: 14  Epoch: 115  Training loss = 2.4834  Validation loss = 6.5659  \n",
      "\n",
      "Fold: 14  Epoch: 116  Training loss = 2.4831  Validation loss = 6.5641  \n",
      "\n",
      "Fold: 14  Epoch: 117  Training loss = 2.4831  Validation loss = 6.5641  \n",
      "\n",
      "Fold: 14  Epoch: 118  Training loss = 2.4828  Validation loss = 6.5630  \n",
      "\n",
      "Fold: 14  Epoch: 119  Training loss = 2.4825  Validation loss = 6.5612  \n",
      "\n",
      "Fold: 14  Epoch: 120  Training loss = 2.4824  Validation loss = 6.5614  \n",
      "\n",
      "Fold: 14  Epoch: 121  Training loss = 2.4822  Validation loss = 6.5601  \n",
      "\n",
      "Fold: 14  Epoch: 122  Training loss = 2.4820  Validation loss = 6.5594  \n",
      "\n",
      "Fold: 14  Epoch: 123  Training loss = 2.4817  Validation loss = 6.5580  \n",
      "\n",
      "Fold: 14  Epoch: 124  Training loss = 2.4813  Validation loss = 6.5553  \n",
      "\n",
      "Fold: 14  Epoch: 125  Training loss = 2.4811  Validation loss = 6.5538  \n",
      "\n",
      "Fold: 14  Epoch: 126  Training loss = 2.4808  Validation loss = 6.5536  \n",
      "\n",
      "Fold: 14  Epoch: 127  Training loss = 2.4804  Validation loss = 6.5516  \n",
      "\n",
      "Fold: 14  Epoch: 128  Training loss = 2.4801  Validation loss = 6.5504  \n",
      "\n",
      "Fold: 14  Epoch: 129  Training loss = 2.4798  Validation loss = 6.5491  \n",
      "\n",
      "Fold: 14  Epoch: 130  Training loss = 2.4796  Validation loss = 6.5483  \n",
      "\n",
      "Fold: 14  Epoch: 131  Training loss = 2.4793  Validation loss = 6.5465  \n",
      "\n",
      "Fold: 14  Epoch: 132  Training loss = 2.4791  Validation loss = 6.5458  \n",
      "\n",
      "Fold: 14  Epoch: 133  Training loss = 2.4789  Validation loss = 6.5455  \n",
      "\n",
      "Fold: 14  Epoch: 134  Training loss = 2.4786  Validation loss = 6.5437  \n",
      "\n",
      "Fold: 14  Epoch: 135  Training loss = 2.4785  Validation loss = 6.5434  \n",
      "\n",
      "Fold: 14  Epoch: 136  Training loss = 2.4782  Validation loss = 6.5423  \n",
      "\n",
      "Fold: 14  Epoch: 137  Training loss = 2.4780  Validation loss = 6.5419  \n",
      "\n",
      "Fold: 14  Epoch: 138  Training loss = 2.4779  Validation loss = 6.5416  \n",
      "\n",
      "Fold: 14  Epoch: 139  Training loss = 2.4778  Validation loss = 6.5419  \n",
      "\n",
      "Fold: 14  Epoch: 140  Training loss = 2.4776  Validation loss = 6.5413  \n",
      "\n",
      "Fold: 14  Epoch: 141  Training loss = 2.4773  Validation loss = 6.5404  \n",
      "\n",
      "Fold: 14  Epoch: 142  Training loss = 2.4771  Validation loss = 6.5402  \n",
      "\n",
      "Fold: 14  Epoch: 143  Training loss = 2.4768  Validation loss = 6.5382  \n",
      "\n",
      "Fold: 14  Epoch: 144  Training loss = 2.4764  Validation loss = 6.5361  \n",
      "\n",
      "Fold: 14  Epoch: 145  Training loss = 2.4762  Validation loss = 6.5354  \n",
      "\n",
      "Fold: 14  Epoch: 146  Training loss = 2.4761  Validation loss = 6.5353  \n",
      "\n",
      "Fold: 14  Epoch: 147  Training loss = 2.4760  Validation loss = 6.5352  \n",
      "\n",
      "Fold: 14  Epoch: 148  Training loss = 2.4760  Validation loss = 6.5353  \n",
      "\n",
      "Fold: 14  Epoch: 149  Training loss = 2.4759  Validation loss = 6.5352  \n",
      "\n",
      "Fold: 14  Epoch: 150  Training loss = 2.4756  Validation loss = 6.5347  \n",
      "\n",
      "Fold: 14  Epoch: 151  Training loss = 2.4754  Validation loss = 6.5340  \n",
      "\n",
      "Fold: 14  Epoch: 152  Training loss = 2.4752  Validation loss = 6.5332  \n",
      "\n",
      "Fold: 14  Epoch: 153  Training loss = 2.4750  Validation loss = 6.5321  \n",
      "\n",
      "Fold: 14  Epoch: 154  Training loss = 2.4749  Validation loss = 6.5321  \n",
      "\n",
      "Fold: 14  Epoch: 155  Training loss = 2.4748  Validation loss = 6.5318  \n",
      "\n",
      "Fold: 14  Epoch: 156  Training loss = 2.4745  Validation loss = 6.5300  \n",
      "\n",
      "Fold: 14  Epoch: 157  Training loss = 2.4741  Validation loss = 6.5283  \n",
      "\n",
      "Fold: 14  Epoch: 158  Training loss = 2.4739  Validation loss = 6.5270  \n",
      "\n",
      "Fold: 14  Epoch: 159  Training loss = 2.4737  Validation loss = 6.5263  \n",
      "\n",
      "Fold: 14  Epoch: 160  Training loss = 2.4733  Validation loss = 6.5243  \n",
      "\n",
      "Fold: 14  Epoch: 161  Training loss = 2.4730  Validation loss = 6.5230  \n",
      "\n",
      "Fold: 14  Epoch: 162  Training loss = 2.4730  Validation loss = 6.5236  \n",
      "\n",
      "Fold: 14  Epoch: 163  Training loss = 2.4727  Validation loss = 6.5216  \n",
      "\n",
      "Fold: 14  Epoch: 164  Training loss = 2.4722  Validation loss = 6.5188  \n",
      "\n",
      "Fold: 14  Epoch: 165  Training loss = 2.4720  Validation loss = 6.5181  \n",
      "\n",
      "Fold: 14  Epoch: 166  Training loss = 2.4717  Validation loss = 6.5163  \n",
      "\n",
      "Fold: 14  Epoch: 167  Training loss = 2.4714  Validation loss = 6.5152  \n",
      "\n",
      "Fold: 14  Epoch: 168  Training loss = 2.4713  Validation loss = 6.5153  \n",
      "\n",
      "Fold: 14  Epoch: 169  Training loss = 2.4713  Validation loss = 6.5161  \n",
      "\n",
      "Fold: 14  Epoch: 170  Training loss = 2.4711  Validation loss = 6.5154  \n",
      "\n",
      "Fold: 14  Epoch: 171  Training loss = 2.4709  Validation loss = 6.5148  \n",
      "\n",
      "Fold: 14  Epoch: 172  Training loss = 2.4709  Validation loss = 6.5149  \n",
      "\n",
      "Fold: 14  Epoch: 173  Training loss = 2.4707  Validation loss = 6.5143  \n",
      "\n",
      "Fold: 14  Epoch: 174  Training loss = 2.4705  Validation loss = 6.5134  \n",
      "\n",
      "Fold: 14  Epoch: 175  Training loss = 2.4703  Validation loss = 6.5133  \n",
      "\n",
      "Fold: 14  Epoch: 176  Training loss = 2.4701  Validation loss = 6.5122  \n",
      "\n",
      "Fold: 14  Epoch: 177  Training loss = 2.4700  Validation loss = 6.5123  \n",
      "\n",
      "Fold: 14  Epoch: 178  Training loss = 2.4696  Validation loss = 6.5104  \n",
      "\n",
      "Fold: 14  Epoch: 179  Training loss = 2.4696  Validation loss = 6.5107  \n",
      "\n",
      "Fold: 14  Epoch: 180  Training loss = 2.4690  Validation loss = 6.5077  \n",
      "\n",
      "Fold: 14  Epoch: 181  Training loss = 2.4688  Validation loss = 6.5060  \n",
      "\n",
      "Fold: 14  Epoch: 182  Training loss = 2.4686  Validation loss = 6.5054  \n",
      "\n",
      "Fold: 14  Epoch: 183  Training loss = 2.4684  Validation loss = 6.5042  \n",
      "\n",
      "Fold: 14  Epoch: 184  Training loss = 2.4682  Validation loss = 6.5037  \n",
      "\n",
      "Fold: 14  Epoch: 185  Training loss = 2.4681  Validation loss = 6.5029  \n",
      "\n",
      "Fold: 14  Epoch: 186  Training loss = 2.4678  Validation loss = 6.5017  \n",
      "\n",
      "Fold: 14  Epoch: 187  Training loss = 2.4674  Validation loss = 6.4994  \n",
      "\n",
      "Fold: 14  Epoch: 188  Training loss = 2.4672  Validation loss = 6.4986  \n",
      "\n",
      "Fold: 14  Epoch: 189  Training loss = 2.4671  Validation loss = 6.4979  \n",
      "\n",
      "Fold: 14  Epoch: 190  Training loss = 2.4669  Validation loss = 6.4972  \n",
      "\n",
      "Fold: 14  Epoch: 191  Training loss = 2.4669  Validation loss = 6.4973  \n",
      "\n",
      "Fold: 14  Epoch: 192  Training loss = 2.4666  Validation loss = 6.4959  \n",
      "\n",
      "Fold: 14  Epoch: 193  Training loss = 2.4662  Validation loss = 6.4942  \n",
      "\n",
      "Fold: 14  Epoch: 194  Training loss = 2.4661  Validation loss = 6.4940  \n",
      "\n",
      "Fold: 14  Epoch: 195  Training loss = 2.4658  Validation loss = 6.4926  \n",
      "\n",
      "Fold: 14  Epoch: 196  Training loss = 2.4656  Validation loss = 6.4915  \n",
      "\n",
      "Fold: 14  Epoch: 197  Training loss = 2.4654  Validation loss = 6.4910  \n",
      "\n",
      "Fold: 14  Epoch: 198  Training loss = 2.4652  Validation loss = 6.4896  \n",
      "\n",
      "Fold: 14  Epoch: 199  Training loss = 2.4649  Validation loss = 6.4887  \n",
      "\n",
      "Fold: 14  Epoch: 200  Training loss = 2.4648  Validation loss = 6.4884  \n",
      "\n",
      "Fold: 14  Epoch: 201  Training loss = 2.4646  Validation loss = 6.4872  \n",
      "\n",
      "Fold: 14  Epoch: 202  Training loss = 2.4641  Validation loss = 6.4846  \n",
      "\n",
      "Fold: 14  Epoch: 203  Training loss = 2.4638  Validation loss = 6.4826  \n",
      "\n",
      "Fold: 14  Epoch: 204  Training loss = 2.4637  Validation loss = 6.4825  \n",
      "\n",
      "Fold: 14  Epoch: 205  Training loss = 2.4634  Validation loss = 6.4809  \n",
      "\n",
      "Fold: 14  Epoch: 206  Training loss = 2.4633  Validation loss = 6.4799  \n",
      "\n",
      "Fold: 14  Epoch: 207  Training loss = 2.4631  Validation loss = 6.4792  \n",
      "\n",
      "Fold: 14  Epoch: 208  Training loss = 2.4629  Validation loss = 6.4780  \n",
      "\n",
      "Fold: 14  Epoch: 209  Training loss = 2.4625  Validation loss = 6.4757  \n",
      "\n",
      "Fold: 14  Epoch: 210  Training loss = 2.4621  Validation loss = 6.4738  \n",
      "\n",
      "Fold: 14  Epoch: 211  Training loss = 2.4618  Validation loss = 6.4724  \n",
      "\n",
      "Fold: 14  Epoch: 212  Training loss = 2.4616  Validation loss = 6.4705  \n",
      "\n",
      "Fold: 14  Epoch: 213  Training loss = 2.4615  Validation loss = 6.4703  \n",
      "\n",
      "Fold: 14  Epoch: 214  Training loss = 2.4612  Validation loss = 6.4693  \n",
      "\n",
      "Fold: 14  Epoch: 215  Training loss = 2.4608  Validation loss = 6.4671  \n",
      "\n",
      "Fold: 14  Epoch: 216  Training loss = 2.4607  Validation loss = 6.4663  \n",
      "\n",
      "Fold: 14  Epoch: 217  Training loss = 2.4604  Validation loss = 6.4649  \n",
      "\n",
      "Fold: 14  Epoch: 218  Training loss = 2.4600  Validation loss = 6.4623  \n",
      "\n",
      "Fold: 14  Epoch: 219  Training loss = 2.4597  Validation loss = 6.4607  \n",
      "\n",
      "Fold: 14  Epoch: 220  Training loss = 2.4595  Validation loss = 6.4599  \n",
      "\n",
      "Fold: 14  Epoch: 221  Training loss = 2.4592  Validation loss = 6.4584  \n",
      "\n",
      "Fold: 14  Epoch: 222  Training loss = 2.4591  Validation loss = 6.4581  \n",
      "\n",
      "Fold: 14  Epoch: 223  Training loss = 2.4590  Validation loss = 6.4572  \n",
      "\n",
      "Fold: 14  Epoch: 224  Training loss = 2.4588  Validation loss = 6.4562  \n",
      "\n",
      "Fold: 14  Epoch: 225  Training loss = 2.4585  Validation loss = 6.4548  \n",
      "\n",
      "Fold: 14  Epoch: 226  Training loss = 2.4583  Validation loss = 6.4544  \n",
      "\n",
      "Fold: 14  Epoch: 227  Training loss = 2.4582  Validation loss = 6.4543  \n",
      "\n",
      "Fold: 14  Epoch: 228  Training loss = 2.4579  Validation loss = 6.4520  \n",
      "\n",
      "Fold: 14  Epoch: 229  Training loss = 2.4576  Validation loss = 6.4502  \n",
      "\n",
      "Fold: 14  Epoch: 230  Training loss = 2.4574  Validation loss = 6.4493  \n",
      "\n",
      "Fold: 14  Epoch: 231  Training loss = 2.4573  Validation loss = 6.4483  \n",
      "\n",
      "Fold: 14  Epoch: 232  Training loss = 2.4571  Validation loss = 6.4480  \n",
      "\n",
      "Fold: 14  Epoch: 233  Training loss = 2.4567  Validation loss = 6.4463  \n",
      "\n",
      "Fold: 14  Epoch: 234  Training loss = 2.4565  Validation loss = 6.4448  \n",
      "\n",
      "Fold: 14  Epoch: 235  Training loss = 2.4563  Validation loss = 6.4442  \n",
      "\n",
      "Fold: 14  Epoch: 236  Training loss = 2.4561  Validation loss = 6.4434  \n",
      "\n",
      "Fold: 14  Epoch: 237  Training loss = 2.4559  Validation loss = 6.4428  \n",
      "\n",
      "Fold: 14  Epoch: 238  Training loss = 2.4557  Validation loss = 6.4417  \n",
      "\n",
      "Fold: 14  Epoch: 239  Training loss = 2.4556  Validation loss = 6.4412  \n",
      "\n",
      "Fold: 14  Epoch: 240  Training loss = 2.4554  Validation loss = 6.4396  \n",
      "\n",
      "Fold: 14  Epoch: 241  Training loss = 2.4553  Validation loss = 6.4397  \n",
      "\n",
      "Fold: 14  Epoch: 242  Training loss = 2.4551  Validation loss = 6.4387  \n",
      "\n",
      "Fold: 14  Epoch: 243  Training loss = 2.4548  Validation loss = 6.4365  \n",
      "\n",
      "Fold: 14  Epoch: 244  Training loss = 2.4545  Validation loss = 6.4341  \n",
      "\n",
      "Fold: 14  Epoch: 245  Training loss = 2.4542  Validation loss = 6.4319  \n",
      "\n",
      "Fold: 14  Epoch: 246  Training loss = 2.4540  Validation loss = 6.4307  \n",
      "\n",
      "Fold: 14  Epoch: 247  Training loss = 2.4538  Validation loss = 6.4309  \n",
      "\n",
      "Fold: 14  Epoch: 248  Training loss = 2.4536  Validation loss = 6.4300  \n",
      "\n",
      "Fold: 14  Epoch: 249  Training loss = 2.4534  Validation loss = 6.4292  \n",
      "\n",
      "Fold: 14  Epoch: 250  Training loss = 2.4531  Validation loss = 6.4271  \n",
      "\n",
      "Fold: 14  Epoch: 251  Training loss = 2.4529  Validation loss = 6.4262  \n",
      "\n",
      "Fold: 14  Epoch: 252  Training loss = 2.4526  Validation loss = 6.4243  \n",
      "\n",
      "Fold: 14  Epoch: 253  Training loss = 2.4525  Validation loss = 6.4232  \n",
      "\n",
      "Fold: 14  Epoch: 254  Training loss = 2.4524  Validation loss = 6.4237  \n",
      "\n",
      "Fold: 14  Epoch: 255  Training loss = 2.4521  Validation loss = 6.4226  \n",
      "\n",
      "Fold: 14  Epoch: 256  Training loss = 2.4519  Validation loss = 6.4212  \n",
      "\n",
      "Fold: 14  Epoch: 257  Training loss = 2.4518  Validation loss = 6.4205  \n",
      "\n",
      "Fold: 14  Epoch: 258  Training loss = 2.4517  Validation loss = 6.4208  \n",
      "\n",
      "Fold: 14  Epoch: 259  Training loss = 2.4515  Validation loss = 6.4187  \n",
      "\n",
      "Fold: 14  Epoch: 260  Training loss = 2.4513  Validation loss = 6.4171  \n",
      "\n",
      "Fold: 14  Epoch: 261  Training loss = 2.4511  Validation loss = 6.4171  \n",
      "\n",
      "Fold: 14  Epoch: 262  Training loss = 2.4509  Validation loss = 6.4159  \n",
      "\n",
      "Fold: 14  Epoch: 263  Training loss = 2.4507  Validation loss = 6.4148  \n",
      "\n",
      "Fold: 14  Epoch: 264  Training loss = 2.4505  Validation loss = 6.4144  \n",
      "\n",
      "Fold: 14  Epoch: 265  Training loss = 2.4502  Validation loss = 6.4129  \n",
      "\n",
      "Fold: 14  Epoch: 266  Training loss = 2.4500  Validation loss = 6.4115  \n",
      "\n",
      "Fold: 14  Epoch: 267  Training loss = 2.4497  Validation loss = 6.4104  \n",
      "\n",
      "Fold: 14  Epoch: 268  Training loss = 2.4494  Validation loss = 6.4090  \n",
      "\n",
      "Fold: 14  Epoch: 269  Training loss = 2.4492  Validation loss = 6.4086  \n",
      "\n",
      "Fold: 14  Epoch: 270  Training loss = 2.4492  Validation loss = 6.4085  \n",
      "\n",
      "Fold: 14  Epoch: 271  Training loss = 2.4490  Validation loss = 6.4081  \n",
      "\n",
      "Fold: 14  Epoch: 272  Training loss = 2.4489  Validation loss = 6.4074  \n",
      "\n",
      "Fold: 14  Epoch: 273  Training loss = 2.4487  Validation loss = 6.4060  \n",
      "\n",
      "Fold: 14  Epoch: 274  Training loss = 2.4484  Validation loss = 6.4050  \n",
      "\n",
      "Fold: 14  Epoch: 275  Training loss = 2.4482  Validation loss = 6.4037  \n",
      "\n",
      "Fold: 14  Epoch: 276  Training loss = 2.4481  Validation loss = 6.4032  \n",
      "\n",
      "Fold: 14  Epoch: 277  Training loss = 2.4479  Validation loss = 6.4022  \n",
      "\n",
      "Fold: 14  Epoch: 278  Training loss = 2.4476  Validation loss = 6.4009  \n",
      "\n",
      "Fold: 14  Epoch: 279  Training loss = 2.4475  Validation loss = 6.4015  \n",
      "\n",
      "Fold: 14  Epoch: 280  Training loss = 2.4473  Validation loss = 6.4000  \n",
      "\n",
      "Fold: 14  Epoch: 281  Training loss = 2.4472  Validation loss = 6.3990  \n",
      "\n",
      "Fold: 14  Epoch: 282  Training loss = 2.4470  Validation loss = 6.3983  \n",
      "\n",
      "Fold: 14  Epoch: 283  Training loss = 2.4467  Validation loss = 6.3963  \n",
      "\n",
      "Fold: 14  Epoch: 284  Training loss = 2.4465  Validation loss = 6.3959  \n",
      "\n",
      "Fold: 14  Epoch: 285  Training loss = 2.4464  Validation loss = 6.3953  \n",
      "\n",
      "Fold: 14  Epoch: 286  Training loss = 2.4463  Validation loss = 6.3951  \n",
      "\n",
      "Fold: 14  Epoch: 287  Training loss = 2.4462  Validation loss = 6.3940  \n",
      "\n",
      "Fold: 14  Epoch: 288  Training loss = 2.4459  Validation loss = 6.3923  \n",
      "\n",
      "Fold: 14  Epoch: 289  Training loss = 2.4456  Validation loss = 6.3904  \n",
      "\n",
      "Fold: 14  Epoch: 290  Training loss = 2.4456  Validation loss = 6.3906  \n",
      "\n",
      "Fold: 14  Epoch: 291  Training loss = 2.4454  Validation loss = 6.3897  \n",
      "\n",
      "Fold: 14  Epoch: 292  Training loss = 2.4451  Validation loss = 6.3875  \n",
      "\n",
      "Fold: 14  Epoch: 293  Training loss = 2.4451  Validation loss = 6.3865  \n",
      "\n",
      "Fold: 14  Epoch: 294  Training loss = 2.4450  Validation loss = 6.3861  \n",
      "\n",
      "Fold: 14  Epoch: 295  Training loss = 2.4447  Validation loss = 6.3836  \n",
      "\n",
      "Fold: 14  Epoch: 296  Training loss = 2.4445  Validation loss = 6.3824  \n",
      "\n",
      "Fold: 14  Epoch: 297  Training loss = 2.4443  Validation loss = 6.3803  \n",
      "\n",
      "Fold: 14  Epoch: 298  Training loss = 2.4442  Validation loss = 6.3804  \n",
      "\n",
      "Fold: 14  Epoch: 299  Training loss = 2.4439  Validation loss = 6.3784  \n",
      "\n",
      "Fold: 14  Epoch: 300  Training loss = 2.4438  Validation loss = 6.3781  \n",
      "\n",
      "Fold: 14  Epoch: 301  Training loss = 2.4436  Validation loss = 6.3748  \n",
      "\n",
      "Fold: 14  Epoch: 302  Training loss = 2.4434  Validation loss = 6.3750  \n",
      "\n",
      "Fold: 14  Epoch: 303  Training loss = 2.4433  Validation loss = 6.3750  \n",
      "\n",
      "Fold: 14  Epoch: 304  Training loss = 2.4431  Validation loss = 6.3735  \n",
      "\n",
      "Fold: 14  Epoch: 305  Training loss = 2.4429  Validation loss = 6.3730  \n",
      "\n",
      "Fold: 14  Epoch: 306  Training loss = 2.4428  Validation loss = 6.3738  \n",
      "\n",
      "Fold: 14  Epoch: 307  Training loss = 2.4426  Validation loss = 6.3739  \n",
      "\n",
      "Fold: 14  Epoch: 308  Training loss = 2.4425  Validation loss = 6.3747  \n",
      "\n",
      "Fold: 14  Epoch: 309  Training loss = 2.4423  Validation loss = 6.3740  \n",
      "\n",
      "Fold: 14  Epoch: 310  Training loss = 2.4423  Validation loss = 6.3748  \n",
      "\n",
      "Fold: 14  Epoch: 311  Training loss = 2.4422  Validation loss = 6.3753  \n",
      "\n",
      "Check model:  Fold: 14  Optimal epoch: 305  \n",
      "\n",
      "Fold: 15  Epoch: 1  Training loss = 2.8957  Validation loss = 6.8924  \n",
      "\n",
      "Fold: 15  Epoch: 2  Training loss = 2.8950  Validation loss = 6.8902  \n",
      "\n",
      "Fold: 15  Epoch: 3  Training loss = 2.8945  Validation loss = 6.8882  \n",
      "\n",
      "Fold: 15  Epoch: 4  Training loss = 2.8940  Validation loss = 6.8863  \n",
      "\n",
      "Fold: 15  Epoch: 5  Training loss = 2.8935  Validation loss = 6.8845  \n",
      "\n",
      "Fold: 15  Epoch: 6  Training loss = 2.8927  Validation loss = 6.8816  \n",
      "\n",
      "Fold: 15  Epoch: 7  Training loss = 2.8923  Validation loss = 6.8803  \n",
      "\n",
      "Fold: 15  Epoch: 8  Training loss = 2.8919  Validation loss = 6.8787  \n",
      "\n",
      "Fold: 15  Epoch: 9  Training loss = 2.8914  Validation loss = 6.8770  \n",
      "\n",
      "Fold: 15  Epoch: 10  Training loss = 2.8907  Validation loss = 6.8746  \n",
      "\n",
      "Fold: 15  Epoch: 11  Training loss = 2.8905  Validation loss = 6.8738  \n",
      "\n",
      "Fold: 15  Epoch: 12  Training loss = 2.8902  Validation loss = 6.8725  \n",
      "\n",
      "Fold: 15  Epoch: 13  Training loss = 2.8896  Validation loss = 6.8699  \n",
      "\n",
      "Fold: 15  Epoch: 14  Training loss = 2.8886  Validation loss = 6.8666  \n",
      "\n",
      "Fold: 15  Epoch: 15  Training loss = 2.8877  Validation loss = 6.8628  \n",
      "\n",
      "Fold: 15  Epoch: 16  Training loss = 2.8876  Validation loss = 6.8624  \n",
      "\n",
      "Fold: 15  Epoch: 17  Training loss = 2.8872  Validation loss = 6.8610  \n",
      "\n",
      "Fold: 15  Epoch: 18  Training loss = 2.8867  Validation loss = 6.8588  \n",
      "\n",
      "Fold: 15  Epoch: 19  Training loss = 2.8860  Validation loss = 6.8560  \n",
      "\n",
      "Fold: 15  Epoch: 20  Training loss = 2.8854  Validation loss = 6.8540  \n",
      "\n",
      "Fold: 15  Epoch: 21  Training loss = 2.8847  Validation loss = 6.8513  \n",
      "\n",
      "Fold: 15  Epoch: 22  Training loss = 2.8840  Validation loss = 6.8488  \n",
      "\n",
      "Fold: 15  Epoch: 23  Training loss = 2.8835  Validation loss = 6.8467  \n",
      "\n",
      "Fold: 15  Epoch: 24  Training loss = 2.8832  Validation loss = 6.8456  \n",
      "\n",
      "Fold: 15  Epoch: 25  Training loss = 2.8825  Validation loss = 6.8427  \n",
      "\n",
      "Fold: 15  Epoch: 26  Training loss = 2.8826  Validation loss = 6.8425  \n",
      "\n",
      "Fold: 15  Epoch: 27  Training loss = 2.8820  Validation loss = 6.8408  \n",
      "\n",
      "Fold: 15  Epoch: 28  Training loss = 2.8818  Validation loss = 6.8401  \n",
      "\n",
      "Fold: 15  Epoch: 29  Training loss = 2.8816  Validation loss = 6.8395  \n",
      "\n",
      "Fold: 15  Epoch: 30  Training loss = 2.8816  Validation loss = 6.8394  \n",
      "\n",
      "Fold: 15  Epoch: 31  Training loss = 2.8811  Validation loss = 6.8372  \n",
      "\n",
      "Fold: 15  Epoch: 32  Training loss = 2.8803  Validation loss = 6.8345  \n",
      "\n",
      "Fold: 15  Epoch: 33  Training loss = 2.8797  Validation loss = 6.8323  \n",
      "\n",
      "Fold: 15  Epoch: 34  Training loss = 2.8789  Validation loss = 6.8295  \n",
      "\n",
      "Fold: 15  Epoch: 35  Training loss = 2.8787  Validation loss = 6.8287  \n",
      "\n",
      "Fold: 15  Epoch: 36  Training loss = 2.8785  Validation loss = 6.8281  \n",
      "\n",
      "Fold: 15  Epoch: 37  Training loss = 2.8778  Validation loss = 6.8254  \n",
      "\n",
      "Fold: 15  Epoch: 38  Training loss = 2.8770  Validation loss = 6.8225  \n",
      "\n",
      "Fold: 15  Epoch: 39  Training loss = 2.8769  Validation loss = 6.8220  \n",
      "\n",
      "Fold: 15  Epoch: 40  Training loss = 2.8764  Validation loss = 6.8203  \n",
      "\n",
      "Fold: 15  Epoch: 41  Training loss = 2.8760  Validation loss = 6.8189  \n",
      "\n",
      "Fold: 15  Epoch: 42  Training loss = 2.8753  Validation loss = 6.8164  \n",
      "\n",
      "Fold: 15  Epoch: 43  Training loss = 2.8750  Validation loss = 6.8153  \n",
      "\n",
      "Fold: 15  Epoch: 44  Training loss = 2.8744  Validation loss = 6.8128  \n",
      "\n",
      "Fold: 15  Epoch: 45  Training loss = 2.8740  Validation loss = 6.8111  \n",
      "\n",
      "Fold: 15  Epoch: 46  Training loss = 2.8736  Validation loss = 6.8094  \n",
      "\n",
      "Fold: 15  Epoch: 47  Training loss = 2.8729  Validation loss = 6.8066  \n",
      "\n",
      "Fold: 15  Epoch: 48  Training loss = 2.8721  Validation loss = 6.8030  \n",
      "\n",
      "Fold: 15  Epoch: 49  Training loss = 2.8717  Validation loss = 6.8014  \n",
      "\n",
      "Fold: 15  Epoch: 50  Training loss = 2.8710  Validation loss = 6.7986  \n",
      "\n",
      "Fold: 15  Epoch: 51  Training loss = 2.8706  Validation loss = 6.7971  \n",
      "\n",
      "Fold: 15  Epoch: 52  Training loss = 2.8701  Validation loss = 6.7951  \n",
      "\n",
      "Fold: 15  Epoch: 53  Training loss = 2.8693  Validation loss = 6.7919  \n",
      "\n",
      "Fold: 15  Epoch: 54  Training loss = 2.8689  Validation loss = 6.7900  \n",
      "\n",
      "Fold: 15  Epoch: 55  Training loss = 2.8686  Validation loss = 6.7890  \n",
      "\n",
      "Fold: 15  Epoch: 56  Training loss = 2.8685  Validation loss = 6.7885  \n",
      "\n",
      "Fold: 15  Epoch: 57  Training loss = 2.8681  Validation loss = 6.7872  \n",
      "\n",
      "Fold: 15  Epoch: 58  Training loss = 2.8678  Validation loss = 6.7859  \n",
      "\n",
      "Fold: 15  Epoch: 59  Training loss = 2.8672  Validation loss = 6.7835  \n",
      "\n",
      "Fold: 15  Epoch: 60  Training loss = 2.8671  Validation loss = 6.7834  \n",
      "\n",
      "Fold: 15  Epoch: 61  Training loss = 2.8668  Validation loss = 6.7823  \n",
      "\n",
      "Fold: 15  Epoch: 62  Training loss = 2.8663  Validation loss = 6.7800  \n",
      "\n",
      "Fold: 15  Epoch: 63  Training loss = 2.8659  Validation loss = 6.7788  \n",
      "\n",
      "Fold: 15  Epoch: 64  Training loss = 2.8653  Validation loss = 6.7762  \n",
      "\n",
      "Fold: 15  Epoch: 65  Training loss = 2.8649  Validation loss = 6.7746  \n",
      "\n",
      "Fold: 15  Epoch: 66  Training loss = 2.8646  Validation loss = 6.7732  \n",
      "\n",
      "Fold: 15  Epoch: 67  Training loss = 2.8644  Validation loss = 6.7722  \n",
      "\n",
      "Fold: 15  Epoch: 68  Training loss = 2.8637  Validation loss = 6.7695  \n",
      "\n",
      "Fold: 15  Epoch: 69  Training loss = 2.8631  Validation loss = 6.7673  \n",
      "\n",
      "Fold: 15  Epoch: 70  Training loss = 2.8631  Validation loss = 6.7677  \n",
      "\n",
      "Fold: 15  Epoch: 71  Training loss = 2.8626  Validation loss = 6.7651  \n",
      "\n",
      "Fold: 15  Epoch: 72  Training loss = 2.8620  Validation loss = 6.7628  \n",
      "\n",
      "Fold: 15  Epoch: 73  Training loss = 2.8617  Validation loss = 6.7614  \n",
      "\n",
      "Fold: 15  Epoch: 74  Training loss = 2.8616  Validation loss = 6.7612  \n",
      "\n",
      "Fold: 15  Epoch: 75  Training loss = 2.8612  Validation loss = 6.7597  \n",
      "\n",
      "Fold: 15  Epoch: 76  Training loss = 2.8610  Validation loss = 6.7590  \n",
      "\n",
      "Fold: 15  Epoch: 77  Training loss = 2.8605  Validation loss = 6.7568  \n",
      "\n",
      "Fold: 15  Epoch: 78  Training loss = 2.8600  Validation loss = 6.7550  \n",
      "\n",
      "Fold: 15  Epoch: 79  Training loss = 2.8596  Validation loss = 6.7534  \n",
      "\n",
      "Fold: 15  Epoch: 80  Training loss = 2.8592  Validation loss = 6.7517  \n",
      "\n",
      "Fold: 15  Epoch: 81  Training loss = 2.8588  Validation loss = 6.7500  \n",
      "\n",
      "Fold: 15  Epoch: 82  Training loss = 2.8584  Validation loss = 6.7481  \n",
      "\n",
      "Fold: 15  Epoch: 83  Training loss = 2.8581  Validation loss = 6.7472  \n",
      "\n",
      "Fold: 15  Epoch: 84  Training loss = 2.8577  Validation loss = 6.7458  \n",
      "\n",
      "Fold: 15  Epoch: 85  Training loss = 2.8574  Validation loss = 6.7446  \n",
      "\n",
      "Fold: 15  Epoch: 86  Training loss = 2.8571  Validation loss = 6.7432  \n",
      "\n",
      "Fold: 15  Epoch: 87  Training loss = 2.8568  Validation loss = 6.7420  \n",
      "\n",
      "Fold: 15  Epoch: 88  Training loss = 2.8566  Validation loss = 6.7412  \n",
      "\n",
      "Fold: 15  Epoch: 89  Training loss = 2.8558  Validation loss = 6.7377  \n",
      "\n",
      "Fold: 15  Epoch: 90  Training loss = 2.8558  Validation loss = 6.7382  \n",
      "\n",
      "Fold: 15  Epoch: 91  Training loss = 2.8554  Validation loss = 6.7365  \n",
      "\n",
      "Fold: 15  Epoch: 92  Training loss = 2.8551  Validation loss = 6.7353  \n",
      "\n",
      "Fold: 15  Epoch: 93  Training loss = 2.8548  Validation loss = 6.7341  \n",
      "\n",
      "Fold: 15  Epoch: 94  Training loss = 2.8545  Validation loss = 6.7328  \n",
      "\n",
      "Fold: 15  Epoch: 95  Training loss = 2.8545  Validation loss = 6.7332  \n",
      "\n",
      "Fold: 15  Epoch: 96  Training loss = 2.8541  Validation loss = 6.7315  \n",
      "\n",
      "Fold: 15  Epoch: 97  Training loss = 2.8539  Validation loss = 6.7308  \n",
      "\n",
      "Fold: 15  Epoch: 98  Training loss = 2.8537  Validation loss = 6.7299  \n",
      "\n",
      "Fold: 15  Epoch: 99  Training loss = 2.8533  Validation loss = 6.7286  \n",
      "\n",
      "Fold: 15  Epoch: 100  Training loss = 2.8525  Validation loss = 6.7249  \n",
      "\n",
      "Fold: 15  Epoch: 101  Training loss = 2.8518  Validation loss = 6.7213  \n",
      "\n",
      "Fold: 15  Epoch: 102  Training loss = 2.8516  Validation loss = 6.7208  \n",
      "\n",
      "Fold: 15  Epoch: 103  Training loss = 2.8518  Validation loss = 6.7220  \n",
      "\n",
      "Fold: 15  Epoch: 104  Training loss = 2.8514  Validation loss = 6.7207  \n",
      "\n",
      "Fold: 15  Epoch: 105  Training loss = 2.8510  Validation loss = 6.7187  \n",
      "\n",
      "Fold: 15  Epoch: 106  Training loss = 2.8510  Validation loss = 6.7188  \n",
      "\n",
      "Fold: 15  Epoch: 107  Training loss = 2.8509  Validation loss = 6.7187  \n",
      "\n",
      "Fold: 15  Epoch: 108  Training loss = 2.8505  Validation loss = 6.7173  \n",
      "\n",
      "Fold: 15  Epoch: 109  Training loss = 2.8501  Validation loss = 6.7155  \n",
      "\n",
      "Fold: 15  Epoch: 110  Training loss = 2.8495  Validation loss = 6.7129  \n",
      "\n",
      "Fold: 15  Epoch: 111  Training loss = 2.8492  Validation loss = 6.7111  \n",
      "\n",
      "Fold: 15  Epoch: 112  Training loss = 2.8490  Validation loss = 6.7103  \n",
      "\n",
      "Fold: 15  Epoch: 113  Training loss = 2.8487  Validation loss = 6.7092  \n",
      "\n",
      "Fold: 15  Epoch: 114  Training loss = 2.8484  Validation loss = 6.7079  \n",
      "\n",
      "Fold: 15  Epoch: 115  Training loss = 2.8483  Validation loss = 6.7075  \n",
      "\n",
      "Fold: 15  Epoch: 116  Training loss = 2.8483  Validation loss = 6.7072  \n",
      "\n",
      "Fold: 15  Epoch: 117  Training loss = 2.8477  Validation loss = 6.7053  \n",
      "\n",
      "Fold: 15  Epoch: 118  Training loss = 2.8476  Validation loss = 6.7053  \n",
      "\n",
      "Fold: 15  Epoch: 119  Training loss = 2.8473  Validation loss = 6.7040  \n",
      "\n",
      "Fold: 15  Epoch: 120  Training loss = 2.8470  Validation loss = 6.7028  \n",
      "\n",
      "Fold: 15  Epoch: 121  Training loss = 2.8466  Validation loss = 6.7009  \n",
      "\n",
      "Fold: 15  Epoch: 122  Training loss = 2.8463  Validation loss = 6.6994  \n",
      "\n",
      "Fold: 15  Epoch: 123  Training loss = 2.8458  Validation loss = 6.6973  \n",
      "\n",
      "Fold: 15  Epoch: 124  Training loss = 2.8451  Validation loss = 6.6943  \n",
      "\n",
      "Fold: 15  Epoch: 125  Training loss = 2.8447  Validation loss = 6.6925  \n",
      "\n",
      "Fold: 15  Epoch: 126  Training loss = 2.8442  Validation loss = 6.6901  \n",
      "\n",
      "Fold: 15  Epoch: 127  Training loss = 2.8439  Validation loss = 6.6888  \n",
      "\n",
      "Fold: 15  Epoch: 128  Training loss = 2.8433  Validation loss = 6.6861  \n",
      "\n",
      "Fold: 15  Epoch: 129  Training loss = 2.8431  Validation loss = 6.6846  \n",
      "\n",
      "Fold: 15  Epoch: 130  Training loss = 2.8425  Validation loss = 6.6815  \n",
      "\n",
      "Fold: 15  Epoch: 131  Training loss = 2.8421  Validation loss = 6.6801  \n",
      "\n",
      "Fold: 15  Epoch: 132  Training loss = 2.8417  Validation loss = 6.6785  \n",
      "\n",
      "Fold: 15  Epoch: 133  Training loss = 2.8413  Validation loss = 6.6768  \n",
      "\n",
      "Fold: 15  Epoch: 134  Training loss = 2.8412  Validation loss = 6.6767  \n",
      "\n",
      "Fold: 15  Epoch: 135  Training loss = 2.8411  Validation loss = 6.6762  \n",
      "\n",
      "Fold: 15  Epoch: 136  Training loss = 2.8407  Validation loss = 6.6751  \n",
      "\n",
      "Fold: 15  Epoch: 137  Training loss = 2.8403  Validation loss = 6.6729  \n",
      "\n",
      "Fold: 15  Epoch: 138  Training loss = 2.8398  Validation loss = 6.6706  \n",
      "\n",
      "Fold: 15  Epoch: 139  Training loss = 2.8395  Validation loss = 6.6691  \n",
      "\n",
      "Fold: 15  Epoch: 140  Training loss = 2.8391  Validation loss = 6.6673  \n",
      "\n",
      "Fold: 15  Epoch: 141  Training loss = 2.8389  Validation loss = 6.6667  \n",
      "\n",
      "Fold: 15  Epoch: 142  Training loss = 2.8387  Validation loss = 6.6659  \n",
      "\n",
      "Fold: 15  Epoch: 143  Training loss = 2.8383  Validation loss = 6.6644  \n",
      "\n",
      "Fold: 15  Epoch: 144  Training loss = 2.8383  Validation loss = 6.6648  \n",
      "\n",
      "Fold: 15  Epoch: 145  Training loss = 2.8382  Validation loss = 6.6643  \n",
      "\n",
      "Fold: 15  Epoch: 146  Training loss = 2.8379  Validation loss = 6.6626  \n",
      "\n",
      "Fold: 15  Epoch: 147  Training loss = 2.8379  Validation loss = 6.6632  \n",
      "\n",
      "Fold: 15  Epoch: 148  Training loss = 2.8376  Validation loss = 6.6615  \n",
      "\n",
      "Fold: 15  Epoch: 149  Training loss = 2.8373  Validation loss = 6.6597  \n",
      "\n",
      "Fold: 15  Epoch: 150  Training loss = 2.8371  Validation loss = 6.6587  \n",
      "\n",
      "Fold: 15  Epoch: 151  Training loss = 2.8366  Validation loss = 6.6567  \n",
      "\n",
      "Fold: 15  Epoch: 152  Training loss = 2.8360  Validation loss = 6.6533  \n",
      "\n",
      "Fold: 15  Epoch: 153  Training loss = 2.8357  Validation loss = 6.6518  \n",
      "\n",
      "Fold: 15  Epoch: 154  Training loss = 2.8354  Validation loss = 6.6508  \n",
      "\n",
      "Fold: 15  Epoch: 155  Training loss = 2.8347  Validation loss = 6.6473  \n",
      "\n",
      "Fold: 15  Epoch: 156  Training loss = 2.8341  Validation loss = 6.6444  \n",
      "\n",
      "Fold: 15  Epoch: 157  Training loss = 2.8338  Validation loss = 6.6432  \n",
      "\n",
      "Fold: 15  Epoch: 158  Training loss = 2.8333  Validation loss = 6.6413  \n",
      "\n",
      "Fold: 15  Epoch: 159  Training loss = 2.8331  Validation loss = 6.6405  \n",
      "\n",
      "Fold: 15  Epoch: 160  Training loss = 2.8330  Validation loss = 6.6398  \n",
      "\n",
      "Fold: 15  Epoch: 161  Training loss = 2.8325  Validation loss = 6.6374  \n",
      "\n",
      "Fold: 15  Epoch: 162  Training loss = 2.8324  Validation loss = 6.6367  \n",
      "\n",
      "Fold: 15  Epoch: 163  Training loss = 2.8320  Validation loss = 6.6353  \n",
      "\n",
      "Fold: 15  Epoch: 164  Training loss = 2.8319  Validation loss = 6.6352  \n",
      "\n",
      "Fold: 15  Epoch: 165  Training loss = 2.8318  Validation loss = 6.6350  \n",
      "\n",
      "Fold: 15  Epoch: 166  Training loss = 2.8315  Validation loss = 6.6337  \n",
      "\n",
      "Fold: 15  Epoch: 167  Training loss = 2.8312  Validation loss = 6.6319  \n",
      "\n",
      "Fold: 15  Epoch: 168  Training loss = 2.8307  Validation loss = 6.6296  \n",
      "\n",
      "Fold: 15  Epoch: 169  Training loss = 2.8304  Validation loss = 6.6277  \n",
      "\n",
      "Fold: 15  Epoch: 170  Training loss = 2.8301  Validation loss = 6.6265  \n",
      "\n",
      "Fold: 15  Epoch: 171  Training loss = 2.8297  Validation loss = 6.6245  \n",
      "\n",
      "Fold: 15  Epoch: 172  Training loss = 2.8295  Validation loss = 6.6234  \n",
      "\n",
      "Fold: 15  Epoch: 173  Training loss = 2.8292  Validation loss = 6.6225  \n",
      "\n",
      "Fold: 15  Epoch: 174  Training loss = 2.8288  Validation loss = 6.6203  \n",
      "\n",
      "Fold: 15  Epoch: 175  Training loss = 2.8288  Validation loss = 6.6206  \n",
      "\n",
      "Fold: 15  Epoch: 176  Training loss = 2.8284  Validation loss = 6.6190  \n",
      "\n",
      "Fold: 15  Epoch: 177  Training loss = 2.8281  Validation loss = 6.6172  \n",
      "\n",
      "Fold: 15  Epoch: 178  Training loss = 2.8276  Validation loss = 6.6149  \n",
      "\n",
      "Fold: 15  Epoch: 179  Training loss = 2.8271  Validation loss = 6.6123  \n",
      "\n",
      "Fold: 15  Epoch: 180  Training loss = 2.8268  Validation loss = 6.6107  \n",
      "\n",
      "Fold: 15  Epoch: 181  Training loss = 2.8265  Validation loss = 6.6092  \n",
      "\n",
      "Fold: 15  Epoch: 182  Training loss = 2.8262  Validation loss = 6.6075  \n",
      "\n",
      "Fold: 15  Epoch: 183  Training loss = 2.8259  Validation loss = 6.6060  \n",
      "\n",
      "Fold: 15  Epoch: 184  Training loss = 2.8255  Validation loss = 6.6035  \n",
      "\n",
      "Fold: 15  Epoch: 185  Training loss = 2.8254  Validation loss = 6.6034  \n",
      "\n",
      "Fold: 15  Epoch: 186  Training loss = 2.8250  Validation loss = 6.6014  \n",
      "\n",
      "Fold: 15  Epoch: 187  Training loss = 2.8246  Validation loss = 6.5993  \n",
      "\n",
      "Fold: 15  Epoch: 188  Training loss = 2.8244  Validation loss = 6.5981  \n",
      "\n",
      "Fold: 15  Epoch: 189  Training loss = 2.8242  Validation loss = 6.5970  \n",
      "\n",
      "Fold: 15  Epoch: 190  Training loss = 2.8240  Validation loss = 6.5960  \n",
      "\n",
      "Fold: 15  Epoch: 191  Training loss = 2.8237  Validation loss = 6.5948  \n",
      "\n",
      "Fold: 15  Epoch: 192  Training loss = 2.8236  Validation loss = 6.5946  \n",
      "\n",
      "Fold: 15  Epoch: 193  Training loss = 2.8233  Validation loss = 6.5930  \n",
      "\n",
      "Fold: 15  Epoch: 194  Training loss = 2.8230  Validation loss = 6.5922  \n",
      "\n",
      "Fold: 15  Epoch: 195  Training loss = 2.8230  Validation loss = 6.5927  \n",
      "\n",
      "Fold: 15  Epoch: 196  Training loss = 2.8226  Validation loss = 6.5908  \n",
      "\n",
      "Fold: 15  Epoch: 197  Training loss = 2.8222  Validation loss = 6.5886  \n",
      "\n",
      "Fold: 15  Epoch: 198  Training loss = 2.8220  Validation loss = 6.5875  \n",
      "\n",
      "Fold: 15  Epoch: 199  Training loss = 2.8218  Validation loss = 6.5868  \n",
      "\n",
      "Fold: 15  Epoch: 200  Training loss = 2.8216  Validation loss = 6.5860  \n",
      "\n",
      "Fold: 15  Epoch: 201  Training loss = 2.8213  Validation loss = 6.5842  \n",
      "\n",
      "Fold: 15  Epoch: 202  Training loss = 2.8211  Validation loss = 6.5833  \n",
      "\n",
      "Fold: 15  Epoch: 203  Training loss = 2.8212  Validation loss = 6.5848  \n",
      "\n",
      "Fold: 15  Epoch: 204  Training loss = 2.8209  Validation loss = 6.5829  \n",
      "\n",
      "Fold: 15  Epoch: 205  Training loss = 2.8209  Validation loss = 6.5831  \n",
      "\n",
      "Fold: 15  Epoch: 206  Training loss = 2.8208  Validation loss = 6.5826  \n",
      "\n",
      "Fold: 15  Epoch: 207  Training loss = 2.8206  Validation loss = 6.5825  \n",
      "\n",
      "Fold: 15  Epoch: 208  Training loss = 2.8201  Validation loss = 6.5796  \n",
      "\n",
      "Fold: 15  Epoch: 209  Training loss = 2.8201  Validation loss = 6.5800  \n",
      "\n",
      "Fold: 15  Epoch: 210  Training loss = 2.8201  Validation loss = 6.5801  \n",
      "\n",
      "Fold: 15  Epoch: 211  Training loss = 2.8199  Validation loss = 6.5791  \n",
      "\n",
      "Fold: 15  Epoch: 212  Training loss = 2.8197  Validation loss = 6.5786  \n",
      "\n",
      "Fold: 15  Epoch: 213  Training loss = 2.8194  Validation loss = 6.5772  \n",
      "\n",
      "Fold: 15  Epoch: 214  Training loss = 2.8190  Validation loss = 6.5750  \n",
      "\n",
      "Fold: 15  Epoch: 215  Training loss = 2.8187  Validation loss = 6.5736  \n",
      "\n",
      "Fold: 15  Epoch: 216  Training loss = 2.8187  Validation loss = 6.5737  \n",
      "\n",
      "Fold: 15  Epoch: 217  Training loss = 2.8183  Validation loss = 6.5716  \n",
      "\n",
      "Fold: 15  Epoch: 218  Training loss = 2.8181  Validation loss = 6.5704  \n",
      "\n",
      "Fold: 15  Epoch: 219  Training loss = 2.8176  Validation loss = 6.5681  \n",
      "\n",
      "Fold: 15  Epoch: 220  Training loss = 2.8173  Validation loss = 6.5658  \n",
      "\n",
      "Fold: 15  Epoch: 221  Training loss = 2.8170  Validation loss = 6.5639  \n",
      "\n",
      "Fold: 15  Epoch: 222  Training loss = 2.8167  Validation loss = 6.5629  \n",
      "\n",
      "Fold: 15  Epoch: 223  Training loss = 2.8167  Validation loss = 6.5632  \n",
      "\n",
      "Fold: 15  Epoch: 224  Training loss = 2.8166  Validation loss = 6.5627  \n",
      "\n",
      "Fold: 15  Epoch: 225  Training loss = 2.8161  Validation loss = 6.5603  \n",
      "\n",
      "Fold: 15  Epoch: 226  Training loss = 2.8159  Validation loss = 6.5588  \n",
      "\n",
      "Fold: 15  Epoch: 227  Training loss = 2.8157  Validation loss = 6.5580  \n",
      "\n",
      "Fold: 15  Epoch: 228  Training loss = 2.8152  Validation loss = 6.5554  \n",
      "\n",
      "Fold: 15  Epoch: 229  Training loss = 2.8151  Validation loss = 6.5547  \n",
      "\n",
      "Fold: 15  Epoch: 230  Training loss = 2.8149  Validation loss = 6.5536  \n",
      "\n",
      "Fold: 15  Epoch: 231  Training loss = 2.8148  Validation loss = 6.5534  \n",
      "\n",
      "Fold: 15  Epoch: 232  Training loss = 2.8145  Validation loss = 6.5516  \n",
      "\n",
      "Fold: 15  Epoch: 233  Training loss = 2.8144  Validation loss = 6.5516  \n",
      "\n",
      "Fold: 15  Epoch: 234  Training loss = 2.8143  Validation loss = 6.5513  \n",
      "\n",
      "Fold: 15  Epoch: 235  Training loss = 2.8141  Validation loss = 6.5500  \n",
      "\n",
      "Fold: 15  Epoch: 236  Training loss = 2.8140  Validation loss = 6.5493  \n",
      "\n",
      "Fold: 15  Epoch: 237  Training loss = 2.8139  Validation loss = 6.5493  \n",
      "\n",
      "Fold: 15  Epoch: 238  Training loss = 2.8135  Validation loss = 6.5473  \n",
      "\n",
      "Fold: 15  Epoch: 239  Training loss = 2.8133  Validation loss = 6.5464  \n",
      "\n",
      "Fold: 15  Epoch: 240  Training loss = 2.8133  Validation loss = 6.5468  \n",
      "\n",
      "Fold: 15  Epoch: 241  Training loss = 2.8129  Validation loss = 6.5447  \n",
      "\n",
      "Fold: 15  Epoch: 242  Training loss = 2.8127  Validation loss = 6.5437  \n",
      "\n",
      "Fold: 15  Epoch: 243  Training loss = 2.8124  Validation loss = 6.5426  \n",
      "\n",
      "Fold: 15  Epoch: 244  Training loss = 2.8124  Validation loss = 6.5427  \n",
      "\n",
      "Fold: 15  Epoch: 245  Training loss = 2.8125  Validation loss = 6.5436  \n",
      "\n",
      "Fold: 15  Epoch: 246  Training loss = 2.8123  Validation loss = 6.5423  \n",
      "\n",
      "Fold: 15  Epoch: 247  Training loss = 2.8122  Validation loss = 6.5417  \n",
      "\n",
      "Fold: 15  Epoch: 248  Training loss = 2.8121  Validation loss = 6.5416  \n",
      "\n",
      "Fold: 15  Epoch: 249  Training loss = 2.8119  Validation loss = 6.5403  \n",
      "\n",
      "Fold: 15  Epoch: 250  Training loss = 2.8116  Validation loss = 6.5389  \n",
      "\n",
      "Fold: 15  Epoch: 251  Training loss = 2.8115  Validation loss = 6.5381  \n",
      "\n",
      "Fold: 15  Epoch: 252  Training loss = 2.8113  Validation loss = 6.5377  \n",
      "\n",
      "Fold: 15  Epoch: 253  Training loss = 2.8112  Validation loss = 6.5372  \n",
      "\n",
      "Fold: 15  Epoch: 254  Training loss = 2.8108  Validation loss = 6.5351  \n",
      "\n",
      "Fold: 15  Epoch: 255  Training loss = 2.8109  Validation loss = 6.5357  \n",
      "\n",
      "Fold: 15  Epoch: 256  Training loss = 2.8107  Validation loss = 6.5354  \n",
      "\n",
      "Fold: 15  Epoch: 257  Training loss = 2.8105  Validation loss = 6.5339  \n",
      "\n",
      "Fold: 15  Epoch: 258  Training loss = 2.8101  Validation loss = 6.5321  \n",
      "\n",
      "Fold: 15  Epoch: 259  Training loss = 2.8098  Validation loss = 6.5301  \n",
      "\n",
      "Fold: 15  Epoch: 260  Training loss = 2.8097  Validation loss = 6.5295  \n",
      "\n",
      "Fold: 15  Epoch: 261  Training loss = 2.8095  Validation loss = 6.5287  \n",
      "\n",
      "Fold: 15  Epoch: 262  Training loss = 2.8095  Validation loss = 6.5290  \n",
      "\n",
      "Fold: 15  Epoch: 263  Training loss = 2.8093  Validation loss = 6.5280  \n",
      "\n",
      "Fold: 15  Epoch: 264  Training loss = 2.8090  Validation loss = 6.5256  \n",
      "\n",
      "Fold: 15  Epoch: 265  Training loss = 2.8087  Validation loss = 6.5241  \n",
      "\n",
      "Fold: 15  Epoch: 266  Training loss = 2.8086  Validation loss = 6.5236  \n",
      "\n",
      "Fold: 15  Epoch: 267  Training loss = 2.8085  Validation loss = 6.5234  \n",
      "\n",
      "Fold: 15  Epoch: 268  Training loss = 2.8083  Validation loss = 6.5222  \n",
      "\n",
      "Fold: 15  Epoch: 269  Training loss = 2.8077  Validation loss = 6.5188  \n",
      "\n",
      "Fold: 15  Epoch: 270  Training loss = 2.8074  Validation loss = 6.5170  \n",
      "\n",
      "Fold: 15  Epoch: 271  Training loss = 2.8074  Validation loss = 6.5175  \n",
      "\n",
      "Fold: 15  Epoch: 272  Training loss = 2.8071  Validation loss = 6.5152  \n",
      "\n",
      "Fold: 15  Epoch: 273  Training loss = 2.8068  Validation loss = 6.5136  \n",
      "\n",
      "Fold: 15  Epoch: 274  Training loss = 2.8068  Validation loss = 6.5136  \n",
      "\n",
      "Fold: 15  Epoch: 275  Training loss = 2.8065  Validation loss = 6.5118  \n",
      "\n",
      "Fold: 15  Epoch: 276  Training loss = 2.8064  Validation loss = 6.5120  \n",
      "\n",
      "Fold: 15  Epoch: 277  Training loss = 2.8063  Validation loss = 6.5115  \n",
      "\n",
      "Fold: 15  Epoch: 278  Training loss = 2.8060  Validation loss = 6.5096  \n",
      "\n",
      "Fold: 15  Epoch: 279  Training loss = 2.8055  Validation loss = 6.5066  \n",
      "\n",
      "Fold: 15  Epoch: 280  Training loss = 2.8052  Validation loss = 6.5042  \n",
      "\n",
      "Fold: 15  Epoch: 281  Training loss = 2.8049  Validation loss = 6.5026  \n",
      "\n",
      "Fold: 15  Epoch: 282  Training loss = 2.8049  Validation loss = 6.5027  \n",
      "\n",
      "Fold: 15  Epoch: 283  Training loss = 2.8046  Validation loss = 6.5016  \n",
      "\n",
      "Fold: 15  Epoch: 284  Training loss = 2.8045  Validation loss = 6.5010  \n",
      "\n",
      "Fold: 15  Epoch: 285  Training loss = 2.8043  Validation loss = 6.5002  \n",
      "\n",
      "Fold: 15  Epoch: 286  Training loss = 2.8044  Validation loss = 6.5012  \n",
      "\n",
      "Fold: 15  Epoch: 287  Training loss = 2.8043  Validation loss = 6.5006  \n",
      "\n",
      "Fold: 15  Epoch: 288  Training loss = 2.8042  Validation loss = 6.5000  \n",
      "\n",
      "Fold: 15  Epoch: 289  Training loss = 2.8040  Validation loss = 6.4994  \n",
      "\n",
      "Fold: 15  Epoch: 290  Training loss = 2.8040  Validation loss = 6.4991  \n",
      "\n",
      "Fold: 15  Epoch: 291  Training loss = 2.8038  Validation loss = 6.4980  \n",
      "\n",
      "Fold: 15  Epoch: 292  Training loss = 2.8036  Validation loss = 6.4966  \n",
      "\n",
      "Fold: 15  Epoch: 293  Training loss = 2.8032  Validation loss = 6.4949  \n",
      "\n",
      "Fold: 15  Epoch: 294  Training loss = 2.8029  Validation loss = 6.4932  \n",
      "\n",
      "Fold: 15  Epoch: 295  Training loss = 2.8026  Validation loss = 6.4915  \n",
      "\n",
      "Fold: 15  Epoch: 296  Training loss = 2.8024  Validation loss = 6.4903  \n",
      "\n",
      "Fold: 15  Epoch: 297  Training loss = 2.8022  Validation loss = 6.4892  \n",
      "\n",
      "Fold: 15  Epoch: 298  Training loss = 2.8022  Validation loss = 6.4894  \n",
      "\n",
      "Fold: 15  Epoch: 299  Training loss = 2.8020  Validation loss = 6.4890  \n",
      "\n",
      "Fold: 15  Epoch: 300  Training loss = 2.8019  Validation loss = 6.4884  \n",
      "\n",
      "Fold: 15  Epoch: 301  Training loss = 2.8018  Validation loss = 6.4886  \n",
      "\n",
      "Fold: 15  Epoch: 302  Training loss = 2.8017  Validation loss = 6.4880  \n",
      "\n",
      "Fold: 15  Epoch: 303  Training loss = 2.8016  Validation loss = 6.4876  \n",
      "\n",
      "Fold: 15  Epoch: 304  Training loss = 2.8014  Validation loss = 6.4867  \n",
      "\n",
      "Fold: 15  Epoch: 305  Training loss = 2.8011  Validation loss = 6.4847  \n",
      "\n",
      "Fold: 15  Epoch: 306  Training loss = 2.8007  Validation loss = 6.4823  \n",
      "\n",
      "Fold: 15  Epoch: 307  Training loss = 2.8006  Validation loss = 6.4816  \n",
      "\n",
      "Fold: 15  Epoch: 308  Training loss = 2.8004  Validation loss = 6.4799  \n",
      "\n",
      "Fold: 15  Epoch: 309  Training loss = 2.8002  Validation loss = 6.4790  \n",
      "\n",
      "Fold: 15  Epoch: 310  Training loss = 2.8002  Validation loss = 6.4790  \n",
      "\n",
      "Fold: 15  Epoch: 311  Training loss = 2.8002  Validation loss = 6.4793  \n",
      "\n",
      "Fold: 15  Epoch: 312  Training loss = 2.8000  Validation loss = 6.4782  \n",
      "\n",
      "Fold: 15  Epoch: 313  Training loss = 2.7997  Validation loss = 6.4769  \n",
      "\n",
      "Fold: 15  Epoch: 314  Training loss = 2.7997  Validation loss = 6.4774  \n",
      "\n",
      "Fold: 15  Epoch: 315  Training loss = 2.7994  Validation loss = 6.4752  \n",
      "\n",
      "Fold: 15  Epoch: 316  Training loss = 2.7993  Validation loss = 6.4746  \n",
      "\n",
      "Fold: 15  Epoch: 317  Training loss = 2.7991  Validation loss = 6.4734  \n",
      "\n",
      "Fold: 15  Epoch: 318  Training loss = 2.7990  Validation loss = 6.4733  \n",
      "\n",
      "Fold: 15  Epoch: 319  Training loss = 2.7990  Validation loss = 6.4733  \n",
      "\n",
      "Fold: 15  Epoch: 320  Training loss = 2.7987  Validation loss = 6.4719  \n",
      "\n",
      "Fold: 15  Epoch: 321  Training loss = 2.7985  Validation loss = 6.4702  \n",
      "\n",
      "Fold: 15  Epoch: 322  Training loss = 2.7984  Validation loss = 6.4692  \n",
      "\n",
      "Fold: 15  Epoch: 323  Training loss = 2.7979  Validation loss = 6.4657  \n",
      "\n",
      "Fold: 15  Epoch: 324  Training loss = 2.7978  Validation loss = 6.4659  \n",
      "\n",
      "Fold: 15  Epoch: 325  Training loss = 2.7976  Validation loss = 6.4647  \n",
      "\n",
      "Fold: 15  Epoch: 326  Training loss = 2.7975  Validation loss = 6.4642  \n",
      "\n",
      "Fold: 15  Epoch: 327  Training loss = 2.7973  Validation loss = 6.4635  \n",
      "\n",
      "Fold: 15  Epoch: 328  Training loss = 2.7972  Validation loss = 6.4630  \n",
      "\n",
      "Fold: 15  Epoch: 329  Training loss = 2.7969  Validation loss = 6.4604  \n",
      "\n",
      "Fold: 15  Epoch: 330  Training loss = 2.7968  Validation loss = 6.4597  \n",
      "\n",
      "Fold: 15  Epoch: 331  Training loss = 2.7968  Validation loss = 6.4597  \n",
      "\n",
      "Fold: 15  Epoch: 332  Training loss = 2.7966  Validation loss = 6.4588  \n",
      "\n",
      "Fold: 15  Epoch: 333  Training loss = 2.7966  Validation loss = 6.4588  \n",
      "\n",
      "Fold: 15  Epoch: 334  Training loss = 2.7964  Validation loss = 6.4569  \n",
      "\n",
      "Fold: 15  Epoch: 335  Training loss = 2.7961  Validation loss = 6.4556  \n",
      "\n",
      "Fold: 15  Epoch: 336  Training loss = 2.7960  Validation loss = 6.4555  \n",
      "\n",
      "Fold: 15  Epoch: 337  Training loss = 2.7959  Validation loss = 6.4549  \n",
      "\n",
      "Fold: 15  Epoch: 338  Training loss = 2.7959  Validation loss = 6.4554  \n",
      "\n",
      "Fold: 15  Epoch: 339  Training loss = 2.7956  Validation loss = 6.4539  \n",
      "\n",
      "Fold: 15  Epoch: 340  Training loss = 2.7955  Validation loss = 6.4538  \n",
      "\n",
      "Fold: 15  Epoch: 341  Training loss = 2.7955  Validation loss = 6.4537  \n",
      "\n",
      "Fold: 15  Epoch: 342  Training loss = 2.7953  Validation loss = 6.4530  \n",
      "\n",
      "Fold: 15  Epoch: 343  Training loss = 2.7952  Validation loss = 6.4522  \n",
      "\n",
      "Fold: 15  Epoch: 344  Training loss = 2.7950  Validation loss = 6.4520  \n",
      "\n",
      "Fold: 15  Epoch: 345  Training loss = 2.7950  Validation loss = 6.4519  \n",
      "\n",
      "Fold: 15  Epoch: 346  Training loss = 2.7947  Validation loss = 6.4493  \n",
      "\n",
      "Fold: 15  Epoch: 347  Training loss = 2.7948  Validation loss = 6.4504  \n",
      "\n",
      "Fold: 15  Epoch: 348  Training loss = 2.7947  Validation loss = 6.4494  \n",
      "\n",
      "Fold: 15  Epoch: 349  Training loss = 2.7945  Validation loss = 6.4484  \n",
      "\n",
      "Fold: 15  Epoch: 350  Training loss = 2.7946  Validation loss = 6.4493  \n",
      "\n",
      "Fold: 15  Epoch: 351  Training loss = 2.7943  Validation loss = 6.4472  \n",
      "\n",
      "Fold: 15  Epoch: 352  Training loss = 2.7942  Validation loss = 6.4461  \n",
      "\n",
      "Fold: 15  Epoch: 353  Training loss = 2.7941  Validation loss = 6.4458  \n",
      "\n",
      "Fold: 15  Epoch: 354  Training loss = 2.7940  Validation loss = 6.4446  \n",
      "\n",
      "Fold: 15  Epoch: 355  Training loss = 2.7938  Validation loss = 6.4436  \n",
      "\n",
      "Fold: 15  Epoch: 356  Training loss = 2.7936  Validation loss = 6.4418  \n",
      "\n",
      "Fold: 15  Epoch: 357  Training loss = 2.7933  Validation loss = 6.4397  \n",
      "\n",
      "Fold: 15  Epoch: 358  Training loss = 2.7931  Validation loss = 6.4387  \n",
      "\n",
      "Fold: 15  Epoch: 359  Training loss = 2.7929  Validation loss = 6.4375  \n",
      "\n",
      "Fold: 15  Epoch: 360  Training loss = 2.7927  Validation loss = 6.4357  \n",
      "\n",
      "Fold: 15  Epoch: 361  Training loss = 2.7924  Validation loss = 6.4349  \n",
      "\n",
      "Fold: 15  Epoch: 362  Training loss = 2.7923  Validation loss = 6.4344  \n",
      "\n",
      "Fold: 15  Epoch: 363  Training loss = 2.7921  Validation loss = 6.4325  \n",
      "\n",
      "Fold: 15  Epoch: 364  Training loss = 2.7919  Validation loss = 6.4319  \n",
      "\n",
      "Fold: 15  Epoch: 365  Training loss = 2.7918  Validation loss = 6.4306  \n",
      "\n",
      "Fold: 15  Epoch: 366  Training loss = 2.7918  Validation loss = 6.4318  \n",
      "\n",
      "Fold: 15  Epoch: 367  Training loss = 2.7916  Validation loss = 6.4307  \n",
      "\n",
      "Fold: 15  Epoch: 368  Training loss = 2.7915  Validation loss = 6.4315  \n",
      "\n",
      "Fold: 15  Epoch: 369  Training loss = 2.7913  Validation loss = 6.4293  \n",
      "\n",
      "Fold: 15  Epoch: 370  Training loss = 2.7911  Validation loss = 6.4282  \n",
      "\n",
      "Fold: 15  Epoch: 371  Training loss = 2.7910  Validation loss = 6.4279  \n",
      "\n",
      "Fold: 15  Epoch: 372  Training loss = 2.7909  Validation loss = 6.4270  \n",
      "\n",
      "Fold: 15  Epoch: 373  Training loss = 2.7906  Validation loss = 6.4251  \n",
      "\n",
      "Fold: 15  Epoch: 374  Training loss = 2.7905  Validation loss = 6.4242  \n",
      "\n",
      "Fold: 15  Epoch: 375  Training loss = 2.7903  Validation loss = 6.4224  \n",
      "\n",
      "Fold: 15  Epoch: 376  Training loss = 2.7903  Validation loss = 6.4231  \n",
      "\n",
      "Fold: 15  Epoch: 377  Training loss = 2.7902  Validation loss = 6.4232  \n",
      "\n",
      "Fold: 15  Epoch: 378  Training loss = 2.7900  Validation loss = 6.4221  \n",
      "\n",
      "Fold: 15  Epoch: 379  Training loss = 2.7897  Validation loss = 6.4199  \n",
      "\n",
      "Fold: 15  Epoch: 380  Training loss = 2.7895  Validation loss = 6.4186  \n",
      "\n",
      "Fold: 15  Epoch: 381  Training loss = 2.7893  Validation loss = 6.4170  \n",
      "\n",
      "Fold: 15  Epoch: 382  Training loss = 2.7889  Validation loss = 6.4149  \n",
      "\n",
      "Fold: 15  Epoch: 383  Training loss = 2.7888  Validation loss = 6.4136  \n",
      "\n",
      "Fold: 15  Epoch: 384  Training loss = 2.7887  Validation loss = 6.4125  \n",
      "\n",
      "Fold: 15  Epoch: 385  Training loss = 2.7886  Validation loss = 6.4125  \n",
      "\n",
      "Fold: 15  Epoch: 386  Training loss = 2.7884  Validation loss = 6.4111  \n",
      "\n",
      "Fold: 15  Epoch: 387  Training loss = 2.7883  Validation loss = 6.4109  \n",
      "\n",
      "Fold: 15  Epoch: 388  Training loss = 2.7881  Validation loss = 6.4101  \n",
      "\n",
      "Fold: 15  Epoch: 389  Training loss = 2.7881  Validation loss = 6.4108  \n",
      "\n",
      "Fold: 15  Epoch: 390  Training loss = 2.7882  Validation loss = 6.4115  \n",
      "\n",
      "Fold: 15  Epoch: 391  Training loss = 2.7880  Validation loss = 6.4104  \n",
      "\n",
      "Fold: 15  Epoch: 392  Training loss = 2.7878  Validation loss = 6.4090  \n",
      "\n",
      "Fold: 15  Epoch: 393  Training loss = 2.7877  Validation loss = 6.4082  \n",
      "\n",
      "Fold: 15  Epoch: 394  Training loss = 2.7875  Validation loss = 6.4072  \n",
      "\n",
      "Fold: 15  Epoch: 395  Training loss = 2.7874  Validation loss = 6.4064  \n",
      "\n",
      "Fold: 15  Epoch: 396  Training loss = 2.7872  Validation loss = 6.4047  \n",
      "\n",
      "Fold: 15  Epoch: 397  Training loss = 2.7869  Validation loss = 6.4030  \n",
      "\n",
      "Fold: 15  Epoch: 398  Training loss = 2.7868  Validation loss = 6.4016  \n",
      "\n",
      "Fold: 15  Epoch: 399  Training loss = 2.7865  Validation loss = 6.4001  \n",
      "\n",
      "Fold: 15  Epoch: 400  Training loss = 2.7863  Validation loss = 6.3979  \n",
      "\n",
      "Fold: 15  Epoch: 401  Training loss = 2.7862  Validation loss = 6.3978  \n",
      "\n",
      "Fold: 15  Epoch: 402  Training loss = 2.7860  Validation loss = 6.3969  \n",
      "\n",
      "Fold: 15  Epoch: 403  Training loss = 2.7859  Validation loss = 6.3957  \n",
      "\n",
      "Fold: 15  Epoch: 404  Training loss = 2.7858  Validation loss = 6.3953  \n",
      "\n",
      "Fold: 15  Epoch: 405  Training loss = 2.7858  Validation loss = 6.3949  \n",
      "\n",
      "Fold: 15  Epoch: 406  Training loss = 2.7856  Validation loss = 6.3942  \n",
      "\n",
      "Fold: 15  Epoch: 407  Training loss = 2.7855  Validation loss = 6.3938  \n",
      "\n",
      "Fold: 15  Epoch: 408  Training loss = 2.7855  Validation loss = 6.3941  \n",
      "\n",
      "Fold: 15  Epoch: 409  Training loss = 2.7853  Validation loss = 6.3927  \n",
      "\n",
      "Fold: 15  Epoch: 410  Training loss = 2.7853  Validation loss = 6.3922  \n",
      "\n",
      "Fold: 15  Epoch: 411  Training loss = 2.7852  Validation loss = 6.3917  \n",
      "\n",
      "Fold: 15  Epoch: 412  Training loss = 2.7852  Validation loss = 6.3917  \n",
      "\n",
      "Fold: 15  Epoch: 413  Training loss = 2.7849  Validation loss = 6.3903  \n",
      "\n",
      "Fold: 15  Epoch: 414  Training loss = 2.7847  Validation loss = 6.3890  \n",
      "\n",
      "Fold: 15  Epoch: 415  Training loss = 2.7847  Validation loss = 6.3892  \n",
      "\n",
      "Fold: 15  Epoch: 416  Training loss = 2.7846  Validation loss = 6.3894  \n",
      "\n",
      "Fold: 15  Epoch: 417  Training loss = 2.7844  Validation loss = 6.3870  \n",
      "\n",
      "Fold: 15  Epoch: 418  Training loss = 2.7844  Validation loss = 6.3882  \n",
      "\n",
      "Fold: 15  Epoch: 419  Training loss = 2.7844  Validation loss = 6.3887  \n",
      "\n",
      "Fold: 15  Epoch: 420  Training loss = 2.7844  Validation loss = 6.3894  \n",
      "\n",
      "Fold: 15  Epoch: 421  Training loss = 2.7842  Validation loss = 6.3878  \n",
      "\n",
      "Fold: 15  Epoch: 422  Training loss = 2.7840  Validation loss = 6.3860  \n",
      "\n",
      "Fold: 15  Epoch: 423  Training loss = 2.7840  Validation loss = 6.3860  \n",
      "\n",
      "Fold: 15  Epoch: 424  Training loss = 2.7839  Validation loss = 6.3853  \n",
      "\n",
      "Fold: 15  Epoch: 425  Training loss = 2.7838  Validation loss = 6.3845  \n",
      "\n",
      "Fold: 15  Epoch: 426  Training loss = 2.7835  Validation loss = 6.3818  \n",
      "\n",
      "Fold: 15  Epoch: 427  Training loss = 2.7834  Validation loss = 6.3811  \n",
      "\n",
      "Fold: 15  Epoch: 428  Training loss = 2.7833  Validation loss = 6.3805  \n",
      "\n",
      "Fold: 15  Epoch: 429  Training loss = 2.7833  Validation loss = 6.3808  \n",
      "\n",
      "Fold: 15  Epoch: 430  Training loss = 2.7832  Validation loss = 6.3807  \n",
      "\n",
      "Fold: 15  Epoch: 431  Training loss = 2.7831  Validation loss = 6.3806  \n",
      "\n",
      "Fold: 15  Epoch: 432  Training loss = 2.7829  Validation loss = 6.3792  \n",
      "\n",
      "Fold: 15  Epoch: 433  Training loss = 2.7828  Validation loss = 6.3779  \n",
      "\n",
      "Fold: 15  Epoch: 434  Training loss = 2.7827  Validation loss = 6.3774  \n",
      "\n",
      "Fold: 15  Epoch: 435  Training loss = 2.7826  Validation loss = 6.3769  \n",
      "\n",
      "Fold: 15  Epoch: 436  Training loss = 2.7825  Validation loss = 6.3767  \n",
      "\n",
      "Fold: 15  Epoch: 437  Training loss = 2.7824  Validation loss = 6.3762  \n",
      "\n",
      "Fold: 15  Epoch: 438  Training loss = 2.7824  Validation loss = 6.3765  \n",
      "\n",
      "Fold: 15  Epoch: 439  Training loss = 2.7823  Validation loss = 6.3757  \n",
      "\n",
      "Fold: 15  Epoch: 440  Training loss = 2.7821  Validation loss = 6.3742  \n",
      "\n",
      "Fold: 15  Epoch: 441  Training loss = 2.7820  Validation loss = 6.3730  \n",
      "\n",
      "Fold: 15  Epoch: 442  Training loss = 2.7820  Validation loss = 6.3726  \n",
      "\n",
      "Fold: 15  Epoch: 443  Training loss = 2.7818  Validation loss = 6.3715  \n",
      "\n",
      "Fold: 15  Epoch: 444  Training loss = 2.7817  Validation loss = 6.3712  \n",
      "\n",
      "Fold: 15  Epoch: 445  Training loss = 2.7815  Validation loss = 6.3700  \n",
      "\n",
      "Fold: 15  Epoch: 446  Training loss = 2.7815  Validation loss = 6.3695  \n",
      "\n",
      "Fold: 15  Epoch: 447  Training loss = 2.7813  Validation loss = 6.3683  \n",
      "\n",
      "Fold: 15  Epoch: 448  Training loss = 2.7813  Validation loss = 6.3685  \n",
      "\n",
      "Fold: 15  Epoch: 449  Training loss = 2.7811  Validation loss = 6.3672  \n",
      "\n",
      "Fold: 15  Epoch: 450  Training loss = 2.7811  Validation loss = 6.3674  \n",
      "\n",
      "Fold: 15  Epoch: 451  Training loss = 2.7810  Validation loss = 6.3668  \n",
      "\n",
      "Fold: 15  Epoch: 452  Training loss = 2.7809  Validation loss = 6.3665  \n",
      "\n",
      "Fold: 15  Epoch: 453  Training loss = 2.7810  Validation loss = 6.3674  \n",
      "\n",
      "Fold: 15  Epoch: 454  Training loss = 2.7809  Validation loss = 6.3665  \n",
      "\n",
      "Fold: 15  Epoch: 455  Training loss = 2.7810  Validation loss = 6.3671  \n",
      "\n",
      "Fold: 15  Epoch: 456  Training loss = 2.7809  Validation loss = 6.3672  \n",
      "\n",
      "Fold: 15  Epoch: 457  Training loss = 2.7808  Validation loss = 6.3658  \n",
      "\n",
      "Fold: 15  Epoch: 458  Training loss = 2.7807  Validation loss = 6.3657  \n",
      "\n",
      "Fold: 15  Epoch: 459  Training loss = 2.7810  Validation loss = 6.3673  \n",
      "\n",
      "Fold: 15  Epoch: 460  Training loss = 2.7809  Validation loss = 6.3665  \n",
      "\n",
      "Fold: 15  Epoch: 461  Training loss = 2.7806  Validation loss = 6.3654  \n",
      "\n",
      "Fold: 15  Epoch: 462  Training loss = 2.7804  Validation loss = 6.3637  \n",
      "\n",
      "Fold: 15  Epoch: 463  Training loss = 2.7804  Validation loss = 6.3641  \n",
      "\n",
      "Fold: 15  Epoch: 464  Training loss = 2.7804  Validation loss = 6.3636  \n",
      "\n",
      "Fold: 15  Epoch: 465  Training loss = 2.7801  Validation loss = 6.3616  \n",
      "\n",
      "Fold: 15  Epoch: 466  Training loss = 2.7800  Validation loss = 6.3612  \n",
      "\n",
      "Fold: 15  Epoch: 467  Training loss = 2.7800  Validation loss = 6.3617  \n",
      "\n",
      "Fold: 15  Epoch: 468  Training loss = 2.7797  Validation loss = 6.3594  \n",
      "\n",
      "Fold: 15  Epoch: 469  Training loss = 2.7794  Validation loss = 6.3570  \n",
      "\n",
      "Fold: 15  Epoch: 470  Training loss = 2.7794  Validation loss = 6.3564  \n",
      "\n",
      "Fold: 15  Epoch: 471  Training loss = 2.7794  Validation loss = 6.3566  \n",
      "\n",
      "Fold: 15  Epoch: 472  Training loss = 2.7793  Validation loss = 6.3566  \n",
      "\n",
      "Fold: 15  Epoch: 473  Training loss = 2.7793  Validation loss = 6.3564  \n",
      "\n",
      "Fold: 15  Epoch: 474  Training loss = 2.7792  Validation loss = 6.3561  \n",
      "\n",
      "Fold: 15  Epoch: 475  Training loss = 2.7792  Validation loss = 6.3563  \n",
      "\n",
      "Fold: 15  Epoch: 476  Training loss = 2.7793  Validation loss = 6.3577  \n",
      "\n",
      "Fold: 15  Epoch: 477  Training loss = 2.7791  Validation loss = 6.3566  \n",
      "\n",
      "Fold: 15  Epoch: 478  Training loss = 2.7791  Validation loss = 6.3568  \n",
      "\n",
      "Fold: 15  Epoch: 479  Training loss = 2.7791  Validation loss = 6.3564  \n",
      "\n",
      "Fold: 15  Epoch: 480  Training loss = 2.7791  Validation loss = 6.3567  \n",
      "\n",
      "Fold: 15  Epoch: 481  Training loss = 2.7789  Validation loss = 6.3564  \n",
      "\n",
      "Fold: 15  Epoch: 482  Training loss = 2.7789  Validation loss = 6.3569  \n",
      "\n",
      "Fold: 15  Epoch: 483  Training loss = 2.7790  Validation loss = 6.3573  \n",
      "\n",
      "Fold: 15  Epoch: 484  Training loss = 2.7789  Validation loss = 6.3572  \n",
      "\n",
      "Fold: 15  Epoch: 485  Training loss = 2.7788  Validation loss = 6.3562  \n",
      "\n",
      "Fold: 15  Epoch: 486  Training loss = 2.7787  Validation loss = 6.3556  \n",
      "\n",
      "Fold: 15  Epoch: 487  Training loss = 2.7784  Validation loss = 6.3535  \n",
      "\n",
      "Fold: 15  Epoch: 488  Training loss = 2.7783  Validation loss = 6.3521  \n",
      "\n",
      "Fold: 15  Epoch: 489  Training loss = 2.7782  Validation loss = 6.3519  \n",
      "\n",
      "Fold: 15  Epoch: 490  Training loss = 2.7781  Validation loss = 6.3518  \n",
      "\n",
      "Fold: 15  Epoch: 491  Training loss = 2.7781  Validation loss = 6.3521  \n",
      "\n",
      "Fold: 15  Epoch: 492  Training loss = 2.7779  Validation loss = 6.3502  \n",
      "\n",
      "Fold: 15  Epoch: 493  Training loss = 2.7777  Validation loss = 6.3491  \n",
      "\n",
      "Fold: 15  Epoch: 494  Training loss = 2.7777  Validation loss = 6.3493  \n",
      "\n",
      "Fold: 15  Epoch: 495  Training loss = 2.7774  Validation loss = 6.3469  \n",
      "\n",
      "Fold: 15  Epoch: 496  Training loss = 2.7773  Validation loss = 6.3461  \n",
      "\n",
      "Fold: 15  Epoch: 497  Training loss = 2.7772  Validation loss = 6.3465  \n",
      "\n",
      "Fold: 15  Epoch: 498  Training loss = 2.7770  Validation loss = 6.3445  \n",
      "\n",
      "Fold: 15  Epoch: 499  Training loss = 2.7768  Validation loss = 6.3425  \n",
      "\n",
      "Fold: 15  Epoch: 500  Training loss = 2.7766  Validation loss = 6.3405  \n",
      "\n",
      "Check model:  Fold: 15  Optimal epoch: 500  \n",
      "\n",
      "Fold: 16  Epoch: 1  Training loss = 3.1739  Validation loss = 4.5465  \n",
      "\n",
      "Fold: 16  Epoch: 2  Training loss = 3.1736  Validation loss = 4.5441  \n",
      "\n",
      "Fold: 16  Epoch: 3  Training loss = 3.1733  Validation loss = 4.5446  \n",
      "\n",
      "Fold: 16  Epoch: 4  Training loss = 3.1730  Validation loss = 4.5398  \n",
      "\n",
      "Fold: 16  Epoch: 5  Training loss = 3.1724  Validation loss = 4.5359  \n",
      "\n",
      "Fold: 16  Epoch: 6  Training loss = 3.1723  Validation loss = 4.5346  \n",
      "\n",
      "Fold: 16  Epoch: 7  Training loss = 3.1719  Validation loss = 4.5331  \n",
      "\n",
      "Fold: 16  Epoch: 8  Training loss = 3.1715  Validation loss = 4.5314  \n",
      "\n",
      "Fold: 16  Epoch: 9  Training loss = 3.1712  Validation loss = 4.5310  \n",
      "\n",
      "Fold: 16  Epoch: 10  Training loss = 3.1709  Validation loss = 4.5300  \n",
      "\n",
      "Fold: 16  Epoch: 11  Training loss = 3.1707  Validation loss = 4.5305  \n",
      "\n",
      "Fold: 16  Epoch: 12  Training loss = 3.1708  Validation loss = 4.5301  \n",
      "\n",
      "Fold: 16  Epoch: 13  Training loss = 3.1698  Validation loss = 4.5259  \n",
      "\n",
      "Fold: 16  Epoch: 14  Training loss = 3.1694  Validation loss = 4.5206  \n",
      "\n",
      "Fold: 16  Epoch: 15  Training loss = 3.1691  Validation loss = 4.5199  \n",
      "\n",
      "Fold: 16  Epoch: 16  Training loss = 3.1690  Validation loss = 4.5173  \n",
      "\n",
      "Fold: 16  Epoch: 17  Training loss = 3.1687  Validation loss = 4.5161  \n",
      "\n",
      "Fold: 16  Epoch: 18  Training loss = 3.1683  Validation loss = 4.5147  \n",
      "\n",
      "Fold: 16  Epoch: 19  Training loss = 3.1681  Validation loss = 4.5111  \n",
      "\n",
      "Fold: 16  Epoch: 20  Training loss = 3.1679  Validation loss = 4.5072  \n",
      "\n",
      "Fold: 16  Epoch: 21  Training loss = 3.1678  Validation loss = 4.5076  \n",
      "\n",
      "Fold: 16  Epoch: 22  Training loss = 3.1677  Validation loss = 4.5080  \n",
      "\n",
      "Fold: 16  Epoch: 23  Training loss = 3.1669  Validation loss = 4.5050  \n",
      "\n",
      "Fold: 16  Epoch: 24  Training loss = 3.1664  Validation loss = 4.5040  \n",
      "\n",
      "Fold: 16  Epoch: 25  Training loss = 3.1655  Validation loss = 4.5013  \n",
      "\n",
      "Fold: 16  Epoch: 26  Training loss = 3.1647  Validation loss = 4.4966  \n",
      "\n",
      "Fold: 16  Epoch: 27  Training loss = 3.1650  Validation loss = 4.4966  \n",
      "\n",
      "Fold: 16  Epoch: 28  Training loss = 3.1649  Validation loss = 4.4965  \n",
      "\n",
      "Fold: 16  Epoch: 29  Training loss = 3.1642  Validation loss = 4.4894  \n",
      "\n",
      "Fold: 16  Epoch: 30  Training loss = 3.1639  Validation loss = 4.4865  \n",
      "\n",
      "Fold: 16  Epoch: 31  Training loss = 3.1639  Validation loss = 4.4854  \n",
      "\n",
      "Fold: 16  Epoch: 32  Training loss = 3.1637  Validation loss = 4.4839  \n",
      "\n",
      "Fold: 16  Epoch: 33  Training loss = 3.1632  Validation loss = 4.4802  \n",
      "\n",
      "Fold: 16  Epoch: 34  Training loss = 3.1628  Validation loss = 4.4784  \n",
      "\n",
      "Fold: 16  Epoch: 35  Training loss = 3.1622  Validation loss = 4.4746  \n",
      "\n",
      "Fold: 16  Epoch: 36  Training loss = 3.1622  Validation loss = 4.4725  \n",
      "\n",
      "Fold: 16  Epoch: 37  Training loss = 3.1619  Validation loss = 4.4691  \n",
      "\n",
      "Fold: 16  Epoch: 38  Training loss = 3.1618  Validation loss = 4.4697  \n",
      "\n",
      "Fold: 16  Epoch: 39  Training loss = 3.1610  Validation loss = 4.4665  \n",
      "\n",
      "Fold: 16  Epoch: 40  Training loss = 3.1610  Validation loss = 4.4676  \n",
      "\n",
      "Fold: 16  Epoch: 41  Training loss = 3.1612  Validation loss = 4.4696  \n",
      "\n",
      "Fold: 16  Epoch: 42  Training loss = 3.1610  Validation loss = 4.4711  \n",
      "\n",
      "Fold: 16  Epoch: 43  Training loss = 3.1602  Validation loss = 4.4679  \n",
      "\n",
      "Fold: 16  Epoch: 44  Training loss = 3.1598  Validation loss = 4.4640  \n",
      "\n",
      "Fold: 16  Epoch: 45  Training loss = 3.1594  Validation loss = 4.4607  \n",
      "\n",
      "Fold: 16  Epoch: 46  Training loss = 3.1586  Validation loss = 4.4538  \n",
      "\n",
      "Fold: 16  Epoch: 47  Training loss = 3.1583  Validation loss = 4.4515  \n",
      "\n",
      "Fold: 16  Epoch: 48  Training loss = 3.1583  Validation loss = 4.4505  \n",
      "\n",
      "Fold: 16  Epoch: 49  Training loss = 3.1580  Validation loss = 4.4501  \n",
      "\n",
      "Fold: 16  Epoch: 50  Training loss = 3.1575  Validation loss = 4.4480  \n",
      "\n",
      "Fold: 16  Epoch: 51  Training loss = 3.1574  Validation loss = 4.4491  \n",
      "\n",
      "Fold: 16  Epoch: 52  Training loss = 3.1573  Validation loss = 4.4487  \n",
      "\n",
      "Fold: 16  Epoch: 53  Training loss = 3.1571  Validation loss = 4.4491  \n",
      "\n",
      "Fold: 16  Epoch: 54  Training loss = 3.1567  Validation loss = 4.4450  \n",
      "\n",
      "Fold: 16  Epoch: 55  Training loss = 3.1567  Validation loss = 4.4451  \n",
      "\n",
      "Fold: 16  Epoch: 56  Training loss = 3.1564  Validation loss = 4.4426  \n",
      "\n",
      "Fold: 16  Epoch: 57  Training loss = 3.1560  Validation loss = 4.4388  \n",
      "\n",
      "Fold: 16  Epoch: 58  Training loss = 3.1558  Validation loss = 4.4399  \n",
      "\n",
      "Fold: 16  Epoch: 59  Training loss = 3.1555  Validation loss = 4.4389  \n",
      "\n",
      "Fold: 16  Epoch: 60  Training loss = 3.1551  Validation loss = 4.4398  \n",
      "\n",
      "Fold: 16  Epoch: 61  Training loss = 3.1549  Validation loss = 4.4383  \n",
      "\n",
      "Fold: 16  Epoch: 62  Training loss = 3.1551  Validation loss = 4.4390  \n",
      "\n",
      "Fold: 16  Epoch: 63  Training loss = 3.1545  Validation loss = 4.4354  \n",
      "\n",
      "Fold: 16  Epoch: 64  Training loss = 3.1538  Validation loss = 4.4293  \n",
      "\n",
      "Fold: 16  Epoch: 65  Training loss = 3.1539  Validation loss = 4.4298  \n",
      "\n",
      "Fold: 16  Epoch: 66  Training loss = 3.1541  Validation loss = 4.4313  \n",
      "\n",
      "Fold: 16  Epoch: 67  Training loss = 3.1540  Validation loss = 4.4311  \n",
      "\n",
      "Fold: 16  Epoch: 68  Training loss = 3.1537  Validation loss = 4.4309  \n",
      "\n",
      "Fold: 16  Epoch: 69  Training loss = 3.1537  Validation loss = 4.4324  \n",
      "\n",
      "Fold: 16  Epoch: 70  Training loss = 3.1534  Validation loss = 4.4302  \n",
      "\n",
      "Fold: 16  Epoch: 71  Training loss = 3.1530  Validation loss = 4.4271  \n",
      "\n",
      "Fold: 16  Epoch: 72  Training loss = 3.1530  Validation loss = 4.4299  \n",
      "\n",
      "Fold: 16  Epoch: 73  Training loss = 3.1525  Validation loss = 4.4309  \n",
      "\n",
      "Fold: 16  Epoch: 74  Training loss = 3.1521  Validation loss = 4.4285  \n",
      "\n",
      "Fold: 16  Epoch: 75  Training loss = 3.1516  Validation loss = 4.4260  \n",
      "\n",
      "Fold: 16  Epoch: 76  Training loss = 3.1512  Validation loss = 4.4232  \n",
      "\n",
      "Fold: 16  Epoch: 77  Training loss = 3.1510  Validation loss = 4.4227  \n",
      "\n",
      "Fold: 16  Epoch: 78  Training loss = 3.1504  Validation loss = 4.4198  \n",
      "\n",
      "Fold: 16  Epoch: 79  Training loss = 3.1503  Validation loss = 4.4190  \n",
      "\n",
      "Fold: 16  Epoch: 80  Training loss = 3.1501  Validation loss = 4.4189  \n",
      "\n",
      "Fold: 16  Epoch: 81  Training loss = 3.1499  Validation loss = 4.4198  \n",
      "\n",
      "Fold: 16  Epoch: 82  Training loss = 3.1494  Validation loss = 4.4175  \n",
      "\n",
      "Fold: 16  Epoch: 83  Training loss = 3.1493  Validation loss = 4.4175  \n",
      "\n",
      "Fold: 16  Epoch: 84  Training loss = 3.1496  Validation loss = 4.4192  \n",
      "\n",
      "Fold: 16  Epoch: 85  Training loss = 3.1488  Validation loss = 4.4154  \n",
      "\n",
      "Fold: 16  Epoch: 86  Training loss = 3.1485  Validation loss = 4.4123  \n",
      "\n",
      "Fold: 16  Epoch: 87  Training loss = 3.1480  Validation loss = 4.4092  \n",
      "\n",
      "Fold: 16  Epoch: 88  Training loss = 3.1477  Validation loss = 4.4097  \n",
      "\n",
      "Fold: 16  Epoch: 89  Training loss = 3.1476  Validation loss = 4.4089  \n",
      "\n",
      "Fold: 16  Epoch: 90  Training loss = 3.1470  Validation loss = 4.4077  \n",
      "\n",
      "Fold: 16  Epoch: 91  Training loss = 3.1469  Validation loss = 4.4106  \n",
      "\n",
      "Fold: 16  Epoch: 92  Training loss = 3.1466  Validation loss = 4.4069  \n",
      "\n",
      "Fold: 16  Epoch: 93  Training loss = 3.1465  Validation loss = 4.4056  \n",
      "\n",
      "Fold: 16  Epoch: 94  Training loss = 3.1463  Validation loss = 4.4055  \n",
      "\n",
      "Fold: 16  Epoch: 95  Training loss = 3.1463  Validation loss = 4.4039  \n",
      "\n",
      "Fold: 16  Epoch: 96  Training loss = 3.1465  Validation loss = 4.4047  \n",
      "\n",
      "Fold: 16  Epoch: 97  Training loss = 3.1460  Validation loss = 4.4010  \n",
      "\n",
      "Fold: 16  Epoch: 98  Training loss = 3.1459  Validation loss = 4.4000  \n",
      "\n",
      "Fold: 16  Epoch: 99  Training loss = 3.1458  Validation loss = 4.3999  \n",
      "\n",
      "Fold: 16  Epoch: 100  Training loss = 3.1452  Validation loss = 4.3941  \n",
      "\n",
      "Fold: 16  Epoch: 101  Training loss = 3.1450  Validation loss = 4.3936  \n",
      "\n",
      "Fold: 16  Epoch: 102  Training loss = 3.1446  Validation loss = 4.3905  \n",
      "\n",
      "Fold: 16  Epoch: 103  Training loss = 3.1448  Validation loss = 4.3977  \n",
      "\n",
      "Fold: 16  Epoch: 104  Training loss = 3.1441  Validation loss = 4.3933  \n",
      "\n",
      "Fold: 16  Epoch: 105  Training loss = 3.1437  Validation loss = 4.3906  \n",
      "\n",
      "Fold: 16  Epoch: 106  Training loss = 3.1434  Validation loss = 4.3884  \n",
      "\n",
      "Fold: 16  Epoch: 107  Training loss = 3.1432  Validation loss = 4.3852  \n",
      "\n",
      "Fold: 16  Epoch: 108  Training loss = 3.1432  Validation loss = 4.3862  \n",
      "\n",
      "Fold: 16  Epoch: 109  Training loss = 3.1433  Validation loss = 4.3906  \n",
      "\n",
      "Fold: 16  Epoch: 110  Training loss = 3.1431  Validation loss = 4.3883  \n",
      "\n",
      "Fold: 16  Epoch: 111  Training loss = 3.1429  Validation loss = 4.3875  \n",
      "\n",
      "Fold: 16  Epoch: 112  Training loss = 3.1426  Validation loss = 4.3886  \n",
      "\n",
      "Fold: 16  Epoch: 113  Training loss = 3.1425  Validation loss = 4.3908  \n",
      "\n",
      "Fold: 16  Epoch: 114  Training loss = 3.1422  Validation loss = 4.3886  \n",
      "\n",
      "Fold: 16  Epoch: 115  Training loss = 3.1420  Validation loss = 4.3885  \n",
      "\n",
      "Fold: 16  Epoch: 116  Training loss = 3.1421  Validation loss = 4.3927  \n",
      "\n",
      "Check model:  Fold: 16  Optimal epoch: 107  \n",
      "\n",
      "Fold: 17  Epoch: 1  Training loss = 3.3120  Validation loss = 3.1258  \n",
      "\n",
      "Fold: 17  Epoch: 2  Training loss = 3.3097  Validation loss = 3.1264  \n",
      "\n",
      "Fold: 17  Epoch: 3  Training loss = 3.3085  Validation loss = 3.1258  \n",
      "\n",
      "Fold: 17  Epoch: 4  Training loss = 3.3057  Validation loss = 3.1282  \n",
      "\n",
      "Fold: 17  Epoch: 5  Training loss = 3.3035  Validation loss = 3.1295  \n",
      "\n",
      "Fold: 17  Epoch: 6  Training loss = 3.3017  Validation loss = 3.1319  \n",
      "\n",
      "Fold: 17  Epoch: 7  Training loss = 3.2990  Validation loss = 3.1360  \n",
      "\n",
      "Fold: 17  Epoch: 8  Training loss = 3.2988  Validation loss = 3.1371  \n",
      "\n",
      "Fold: 17  Epoch: 9  Training loss = 3.2978  Validation loss = 3.1396  \n",
      "\n",
      "Fold: 17  Epoch: 10  Training loss = 3.2961  Validation loss = 3.1442  \n",
      "\n",
      "Fold: 17  Epoch: 11  Training loss = 3.2949  Validation loss = 3.1457  \n",
      "\n",
      "Check model:  Fold: 17  Optimal epoch: 1  \n",
      "\n",
      "Fold: 18  Epoch: 1  Training loss = 3.3787  Validation loss = 1.9439  \n",
      "\n",
      "Fold: 18  Epoch: 2  Training loss = 3.3775  Validation loss = 1.9436  \n",
      "\n",
      "Fold: 18  Epoch: 3  Training loss = 3.3770  Validation loss = 1.9462  \n",
      "\n",
      "Fold: 18  Epoch: 4  Training loss = 3.3760  Validation loss = 1.9484  \n",
      "\n",
      "Fold: 18  Epoch: 5  Training loss = 3.3752  Validation loss = 1.9499  \n",
      "\n",
      "Fold: 18  Epoch: 6  Training loss = 3.3744  Validation loss = 1.9501  \n",
      "\n",
      "Fold: 18  Epoch: 7  Training loss = 3.3737  Validation loss = 1.9504  \n",
      "\n",
      "Fold: 18  Epoch: 8  Training loss = 3.3726  Validation loss = 1.9536  \n",
      "\n",
      "Fold: 18  Epoch: 9  Training loss = 3.3719  Validation loss = 1.9538  \n",
      "\n",
      "Fold: 18  Epoch: 10  Training loss = 3.3710  Validation loss = 1.9545  \n",
      "\n",
      "Fold: 18  Epoch: 11  Training loss = 3.3702  Validation loss = 1.9546  \n",
      "\n",
      "Check model:  Fold: 18  Optimal epoch: 2  \n",
      "\n",
      "Fold: 19  Epoch: 1  Training loss = 3.3451  Validation loss = 0.6572  \n",
      "\n",
      "Fold: 19  Epoch: 2  Training loss = 3.3448  Validation loss = 0.6563  \n",
      "\n",
      "Fold: 19  Epoch: 3  Training loss = 3.3436  Validation loss = 0.6528  \n",
      "\n",
      "Fold: 19  Epoch: 4  Training loss = 3.3427  Validation loss = 0.6510  \n",
      "\n",
      "Fold: 19  Epoch: 5  Training loss = 3.3420  Validation loss = 0.6510  \n",
      "\n",
      "Fold: 19  Epoch: 6  Training loss = 3.3412  Validation loss = 0.6514  \n",
      "\n",
      "Fold: 19  Epoch: 7  Training loss = 3.3400  Validation loss = 0.6495  \n",
      "\n",
      "Fold: 19  Epoch: 8  Training loss = 3.3385  Validation loss = 0.6479  \n",
      "\n",
      "Fold: 19  Epoch: 9  Training loss = 3.3284  Validation loss = 0.6458  \n",
      "\n",
      "Fold: 19  Epoch: 10  Training loss = 3.3258  Validation loss = 0.6518  \n",
      "\n",
      "Fold: 19  Epoch: 11  Training loss = 3.3254  Validation loss = 0.6562  \n",
      "\n",
      "Fold: 19  Epoch: 12  Training loss = 3.3246  Validation loss = 0.6528  \n",
      "\n",
      "Fold: 19  Epoch: 13  Training loss = 3.3238  Validation loss = 0.6507  \n",
      "\n",
      "Fold: 19  Epoch: 14  Training loss = 3.3237  Validation loss = 0.6528  \n",
      "\n",
      "Fold: 19  Epoch: 15  Training loss = 3.3229  Validation loss = 0.6507  \n",
      "\n",
      "Fold: 19  Epoch: 16  Training loss = 3.3222  Validation loss = 0.6537  \n",
      "\n",
      "Fold: 19  Epoch: 17  Training loss = 3.3213  Validation loss = 0.6506  \n",
      "\n",
      "Fold: 19  Epoch: 18  Training loss = 3.3210  Validation loss = 0.6543  \n",
      "\n",
      "Fold: 19  Epoch: 19  Training loss = 3.3200  Validation loss = 0.6520  \n",
      "\n",
      "Fold: 19  Epoch: 20  Training loss = 3.3193  Validation loss = 0.6487  \n",
      "\n",
      "Fold: 19  Epoch: 21  Training loss = 3.3189  Validation loss = 0.6534  \n",
      "\n",
      "Fold: 19  Epoch: 22  Training loss = 3.3182  Validation loss = 0.6485  \n",
      "\n",
      "Fold: 19  Epoch: 23  Training loss = 3.3177  Validation loss = 0.6511  \n",
      "\n",
      "Fold: 19  Epoch: 24  Training loss = 3.3169  Validation loss = 0.6472  \n",
      "\n",
      "Fold: 19  Epoch: 25  Training loss = 3.3167  Validation loss = 0.6478  \n",
      "\n",
      "Fold: 19  Epoch: 26  Training loss = 3.3162  Validation loss = 0.6499  \n",
      "\n",
      "Fold: 19  Epoch: 27  Training loss = 3.3155  Validation loss = 0.6487  \n",
      "\n",
      "Fold: 19  Epoch: 28  Training loss = 3.3144  Validation loss = 0.6516  \n",
      "\n",
      "Fold: 19  Epoch: 29  Training loss = 3.3139  Validation loss = 0.6514  \n",
      "\n",
      "Fold: 19  Epoch: 30  Training loss = 3.3134  Validation loss = 0.6539  \n",
      "\n",
      "Check model:  Fold: 19  Optimal epoch: 9  \n",
      "\n",
      "Fold: 20  Epoch: 1  Training loss = 3.2801  Validation loss = 2.2957  \n",
      "\n",
      "Fold: 20  Epoch: 2  Training loss = 3.2795  Validation loss = 2.2989  \n",
      "\n",
      "Fold: 20  Epoch: 3  Training loss = 3.2784  Validation loss = 2.3064  \n",
      "\n",
      "Fold: 20  Epoch: 4  Training loss = 3.2774  Validation loss = 2.3136  \n",
      "\n",
      "Fold: 20  Epoch: 5  Training loss = 3.2770  Validation loss = 2.3122  \n",
      "\n",
      "Fold: 20  Epoch: 6  Training loss = 3.2763  Validation loss = 2.3152  \n",
      "\n",
      "Fold: 20  Epoch: 7  Training loss = 3.2756  Validation loss = 2.3199  \n",
      "\n",
      "Fold: 20  Epoch: 8  Training loss = 3.2746  Validation loss = 2.3245  \n",
      "\n",
      "Fold: 20  Epoch: 9  Training loss = 3.2733  Validation loss = 2.3367  \n",
      "\n",
      "Fold: 20  Epoch: 10  Training loss = 3.2726  Validation loss = 2.3448  \n",
      "\n",
      "Fold: 20  Epoch: 11  Training loss = 3.2724  Validation loss = 2.3478  \n",
      "\n",
      "Check model:  Fold: 20  Optimal epoch: 1  \n",
      "\n",
      "Fold: 21  Epoch: 1  Training loss = 3.3132  Validation loss = 2.8604  \n",
      "\n",
      "Fold: 21  Epoch: 2  Training loss = 3.3119  Validation loss = 2.8628  \n",
      "\n",
      "Fold: 21  Epoch: 3  Training loss = 3.3113  Validation loss = 2.8632  \n",
      "\n",
      "Fold: 21  Epoch: 4  Training loss = 3.3104  Validation loss = 2.8638  \n",
      "\n",
      "Fold: 21  Epoch: 5  Training loss = 3.3094  Validation loss = 2.8586  \n",
      "\n",
      "Fold: 21  Epoch: 6  Training loss = 3.3085  Validation loss = 2.8584  \n",
      "\n",
      "Fold: 21  Epoch: 7  Training loss = 3.3078  Validation loss = 2.8570  \n",
      "\n",
      "Fold: 21  Epoch: 8  Training loss = 3.3074  Validation loss = 2.8580  \n",
      "\n",
      "Fold: 21  Epoch: 9  Training loss = 3.3017  Validation loss = 2.8638  \n",
      "\n",
      "Fold: 21  Epoch: 10  Training loss = 3.2915  Validation loss = 2.8652  \n",
      "\n",
      "Fold: 21  Epoch: 11  Training loss = 3.2912  Validation loss = 2.8633  \n",
      "\n",
      "Fold: 21  Epoch: 12  Training loss = 3.2905  Validation loss = 2.8657  \n",
      "\n",
      "Check model:  Fold: 21  Optimal epoch: 7  \n",
      "\n",
      "Fold: 22  Epoch: 1  Training loss = 3.3467  Validation loss = 1.1840  \n",
      "\n",
      "Fold: 22  Epoch: 2  Training loss = 3.3455  Validation loss = 1.1810  \n",
      "\n",
      "Fold: 22  Epoch: 3  Training loss = 3.3442  Validation loss = 1.1798  \n",
      "\n",
      "Fold: 22  Epoch: 4  Training loss = 3.3436  Validation loss = 1.1741  \n",
      "\n",
      "Fold: 22  Epoch: 5  Training loss = 3.3425  Validation loss = 1.1732  \n",
      "\n",
      "Fold: 22  Epoch: 6  Training loss = 3.3415  Validation loss = 1.1699  \n",
      "\n",
      "Fold: 22  Epoch: 7  Training loss = 3.3403  Validation loss = 1.1638  \n",
      "\n",
      "Fold: 22  Epoch: 8  Training loss = 3.3393  Validation loss = 1.1578  \n",
      "\n",
      "Fold: 22  Epoch: 9  Training loss = 3.3381  Validation loss = 1.1561  \n",
      "\n",
      "Fold: 22  Epoch: 10  Training loss = 3.3370  Validation loss = 1.1524  \n",
      "\n",
      "Fold: 22  Epoch: 11  Training loss = 3.3364  Validation loss = 1.1537  \n",
      "\n",
      "Fold: 22  Epoch: 12  Training loss = 3.3356  Validation loss = 1.1523  \n",
      "\n",
      "Fold: 22  Epoch: 13  Training loss = 3.3350  Validation loss = 1.1529  \n",
      "\n",
      "Fold: 22  Epoch: 14  Training loss = 3.3344  Validation loss = 1.1505  \n",
      "\n",
      "Fold: 22  Epoch: 15  Training loss = 3.3333  Validation loss = 1.1514  \n",
      "\n",
      "Fold: 22  Epoch: 16  Training loss = 3.3321  Validation loss = 1.1476  \n",
      "\n",
      "Fold: 22  Epoch: 17  Training loss = 3.3313  Validation loss = 1.1510  \n",
      "\n",
      "Fold: 22  Epoch: 18  Training loss = 3.3307  Validation loss = 1.1416  \n",
      "\n",
      "Fold: 22  Epoch: 19  Training loss = 3.3301  Validation loss = 1.1409  \n",
      "\n",
      "Fold: 22  Epoch: 20  Training loss = 3.3289  Validation loss = 1.1402  \n",
      "\n",
      "Fold: 22  Epoch: 21  Training loss = 3.3288  Validation loss = 1.1359  \n",
      "\n",
      "Fold: 22  Epoch: 22  Training loss = 3.3284  Validation loss = 1.1345  \n",
      "\n",
      "Fold: 22  Epoch: 23  Training loss = 3.3271  Validation loss = 1.1348  \n",
      "\n",
      "Fold: 22  Epoch: 24  Training loss = 3.3260  Validation loss = 1.1276  \n",
      "\n",
      "Fold: 22  Epoch: 25  Training loss = 3.3252  Validation loss = 1.1242  \n",
      "\n",
      "Fold: 22  Epoch: 26  Training loss = 3.3243  Validation loss = 1.1242  \n",
      "\n",
      "Fold: 22  Epoch: 27  Training loss = 3.3227  Validation loss = 1.1159  \n",
      "\n",
      "Fold: 22  Epoch: 28  Training loss = 3.3220  Validation loss = 1.1172  \n",
      "\n",
      "Fold: 22  Epoch: 29  Training loss = 3.3208  Validation loss = 1.1153  \n",
      "\n",
      "Fold: 22  Epoch: 30  Training loss = 3.3197  Validation loss = 1.1136  \n",
      "\n",
      "Fold: 22  Epoch: 31  Training loss = 3.3185  Validation loss = 1.1076  \n",
      "\n",
      "Fold: 22  Epoch: 32  Training loss = 3.3174  Validation loss = 1.1036  \n",
      "\n",
      "Fold: 22  Epoch: 33  Training loss = 3.3160  Validation loss = 1.0976  \n",
      "\n",
      "Fold: 22  Epoch: 34  Training loss = 3.3152  Validation loss = 1.0996  \n",
      "\n",
      "Fold: 22  Epoch: 35  Training loss = 3.3144  Validation loss = 1.0977  \n",
      "\n",
      "Fold: 22  Epoch: 36  Training loss = 3.3133  Validation loss = 1.0960  \n",
      "\n",
      "Fold: 22  Epoch: 37  Training loss = 3.3126  Validation loss = 1.0915  \n",
      "\n",
      "Fold: 22  Epoch: 38  Training loss = 3.3121  Validation loss = 1.0891  \n",
      "\n",
      "Fold: 22  Epoch: 39  Training loss = 3.3115  Validation loss = 1.0902  \n",
      "\n",
      "Fold: 22  Epoch: 40  Training loss = 3.3105  Validation loss = 1.0916  \n",
      "\n",
      "Fold: 22  Epoch: 41  Training loss = 3.3095  Validation loss = 1.0908  \n",
      "\n",
      "Fold: 22  Epoch: 42  Training loss = 3.3086  Validation loss = 1.0920  \n",
      "\n",
      "Fold: 22  Epoch: 43  Training loss = 3.3077  Validation loss = 1.0923  \n",
      "\n",
      "Fold: 22  Epoch: 44  Training loss = 3.3069  Validation loss = 1.0933  \n",
      "\n",
      "Fold: 22  Epoch: 45  Training loss = 3.3062  Validation loss = 1.0929  \n",
      "\n",
      "Fold: 22  Epoch: 46  Training loss = 3.3053  Validation loss = 1.0949  \n",
      "\n",
      "Check model:  Fold: 22  Optimal epoch: 38  \n",
      "\n",
      "Fold: 23  Epoch: 1  Training loss = 3.2369  Validation loss = 0.6497  \n",
      "\n",
      "Fold: 23  Epoch: 2  Training loss = 3.2359  Validation loss = 0.6513  \n",
      "\n",
      "Fold: 23  Epoch: 3  Training loss = 3.2343  Validation loss = 0.6580  \n",
      "\n",
      "Fold: 23  Epoch: 4  Training loss = 3.2329  Validation loss = 0.6579  \n",
      "\n",
      "Fold: 23  Epoch: 5  Training loss = 3.2311  Validation loss = 0.6656  \n",
      "\n",
      "Fold: 23  Epoch: 6  Training loss = 3.2294  Validation loss = 0.6547  \n",
      "\n",
      "Fold: 23  Epoch: 7  Training loss = 3.2285  Validation loss = 0.6397  \n",
      "\n",
      "Fold: 23  Epoch: 8  Training loss = 3.2244  Validation loss = 0.6577  \n",
      "\n",
      "Fold: 23  Epoch: 9  Training loss = 3.2194  Validation loss = 0.6838  \n",
      "\n",
      "Fold: 23  Epoch: 10  Training loss = 3.2183  Validation loss = 0.6806  \n",
      "\n",
      "Fold: 23  Epoch: 11  Training loss = 3.2172  Validation loss = 0.6826  \n",
      "\n",
      "Fold: 23  Epoch: 12  Training loss = 3.2159  Validation loss = 0.6810  \n",
      "\n",
      "Fold: 23  Epoch: 13  Training loss = 3.2150  Validation loss = 0.6782  \n",
      "\n",
      "Fold: 23  Epoch: 14  Training loss = 3.2146  Validation loss = 0.6890  \n",
      "\n",
      "Check model:  Fold: 23  Optimal epoch: 7  \n",
      "\n",
      "Fold: 24  Epoch: 1  Training loss = 3.0768  Validation loss = 1.3020  \n",
      "\n",
      "Fold: 24  Epoch: 2  Training loss = 3.0754  Validation loss = 1.3016  \n",
      "\n",
      "Fold: 24  Epoch: 3  Training loss = 3.0739  Validation loss = 1.3005  \n",
      "\n",
      "Fold: 24  Epoch: 4  Training loss = 3.0726  Validation loss = 1.2996  \n",
      "\n",
      "Fold: 24  Epoch: 5  Training loss = 3.0717  Validation loss = 1.2990  \n",
      "\n",
      "Fold: 24  Epoch: 6  Training loss = 3.0703  Validation loss = 1.2972  \n",
      "\n",
      "Fold: 24  Epoch: 7  Training loss = 3.0692  Validation loss = 1.2977  \n",
      "\n",
      "Fold: 24  Epoch: 8  Training loss = 3.0675  Validation loss = 1.2983  \n",
      "\n",
      "Fold: 24  Epoch: 9  Training loss = 3.0662  Validation loss = 1.2999  \n",
      "\n",
      "Fold: 24  Epoch: 10  Training loss = 3.0650  Validation loss = 1.3001  \n",
      "\n",
      "Fold: 24  Epoch: 11  Training loss = 3.0636  Validation loss = 1.2985  \n",
      "\n",
      "Fold: 24  Epoch: 12  Training loss = 3.0621  Validation loss = 1.2962  \n",
      "\n",
      "Fold: 24  Epoch: 13  Training loss = 3.0607  Validation loss = 1.2943  \n",
      "\n",
      "Fold: 24  Epoch: 14  Training loss = 3.0592  Validation loss = 1.2935  \n",
      "\n",
      "Fold: 24  Epoch: 15  Training loss = 3.0579  Validation loss = 1.2934  \n",
      "\n",
      "Fold: 24  Epoch: 16  Training loss = 3.0570  Validation loss = 1.2932  \n",
      "\n",
      "Fold: 24  Epoch: 17  Training loss = 3.0560  Validation loss = 1.2930  \n",
      "\n",
      "Fold: 24  Epoch: 18  Training loss = 3.0545  Validation loss = 1.2922  \n",
      "\n",
      "Fold: 24  Epoch: 19  Training loss = 3.0528  Validation loss = 1.2927  \n",
      "\n",
      "Fold: 24  Epoch: 20  Training loss = 3.0516  Validation loss = 1.2915  \n",
      "\n",
      "Fold: 24  Epoch: 21  Training loss = 3.0505  Validation loss = 1.2905  \n",
      "\n",
      "Fold: 24  Epoch: 22  Training loss = 3.0494  Validation loss = 1.2904  \n",
      "\n",
      "Fold: 24  Epoch: 23  Training loss = 3.0482  Validation loss = 1.2907  \n",
      "\n",
      "Fold: 24  Epoch: 24  Training loss = 3.0475  Validation loss = 1.2907  \n",
      "\n",
      "Fold: 24  Epoch: 25  Training loss = 3.0454  Validation loss = 1.2907  \n",
      "\n",
      "Fold: 24  Epoch: 26  Training loss = 3.0442  Validation loss = 1.2916  \n",
      "\n",
      "Fold: 24  Epoch: 27  Training loss = 3.0439  Validation loss = 1.2914  \n",
      "\n",
      "Fold: 24  Epoch: 28  Training loss = 3.0422  Validation loss = 1.2893  \n",
      "\n",
      "Fold: 24  Epoch: 29  Training loss = 3.0406  Validation loss = 1.2902  \n",
      "\n",
      "Fold: 24  Epoch: 30  Training loss = 3.0384  Validation loss = 1.2890  \n",
      "\n",
      "Fold: 24  Epoch: 31  Training loss = 3.0367  Validation loss = 1.2878  \n",
      "\n",
      "Fold: 24  Epoch: 32  Training loss = 3.0354  Validation loss = 1.2873  \n",
      "\n",
      "Fold: 24  Epoch: 33  Training loss = 3.0339  Validation loss = 1.2862  \n",
      "\n",
      "Fold: 24  Epoch: 34  Training loss = 3.0324  Validation loss = 1.2868  \n",
      "\n",
      "Fold: 24  Epoch: 35  Training loss = 3.0316  Validation loss = 1.2883  \n",
      "\n",
      "Fold: 24  Epoch: 36  Training loss = 3.0296  Validation loss = 1.2865  \n",
      "\n",
      "Fold: 24  Epoch: 37  Training loss = 3.0284  Validation loss = 1.2876  \n",
      "\n",
      "Fold: 24  Epoch: 38  Training loss = 3.0267  Validation loss = 1.2870  \n",
      "\n",
      "Fold: 24  Epoch: 39  Training loss = 3.0257  Validation loss = 1.2865  \n",
      "\n",
      "Fold: 24  Epoch: 40  Training loss = 3.0244  Validation loss = 1.2870  \n",
      "\n",
      "Fold: 24  Epoch: 41  Training loss = 3.0233  Validation loss = 1.2865  \n",
      "\n",
      "Fold: 24  Epoch: 42  Training loss = 3.0219  Validation loss = 1.2855  \n",
      "\n",
      "Fold: 24  Epoch: 43  Training loss = 3.0205  Validation loss = 1.2840  \n",
      "\n",
      "Fold: 24  Epoch: 44  Training loss = 3.0192  Validation loss = 1.2839  \n",
      "\n",
      "Fold: 24  Epoch: 45  Training loss = 3.0179  Validation loss = 1.2838  \n",
      "\n",
      "Fold: 24  Epoch: 46  Training loss = 3.0168  Validation loss = 1.2830  \n",
      "\n",
      "Fold: 24  Epoch: 47  Training loss = 3.0157  Validation loss = 1.2816  \n",
      "\n",
      "Fold: 24  Epoch: 48  Training loss = 3.0141  Validation loss = 1.2820  \n",
      "\n",
      "Fold: 24  Epoch: 49  Training loss = 3.0127  Validation loss = 1.2805  \n",
      "\n",
      "Fold: 24  Epoch: 50  Training loss = 3.0122  Validation loss = 1.2805  \n",
      "\n",
      "Fold: 24  Epoch: 51  Training loss = 3.0113  Validation loss = 1.2800  \n",
      "\n",
      "Fold: 24  Epoch: 52  Training loss = 3.0101  Validation loss = 1.2805  \n",
      "\n",
      "Fold: 24  Epoch: 53  Training loss = 3.0097  Validation loss = 1.2806  \n",
      "\n",
      "Fold: 24  Epoch: 54  Training loss = 3.0082  Validation loss = 1.2791  \n",
      "\n",
      "Fold: 24  Epoch: 55  Training loss = 3.0077  Validation loss = 1.2785  \n",
      "\n",
      "Fold: 24  Epoch: 56  Training loss = 3.0068  Validation loss = 1.2788  \n",
      "\n",
      "Fold: 24  Epoch: 57  Training loss = 3.0058  Validation loss = 1.2787  \n",
      "\n",
      "Fold: 24  Epoch: 58  Training loss = 3.0051  Validation loss = 1.2795  \n",
      "\n",
      "Fold: 24  Epoch: 59  Training loss = 3.0049  Validation loss = 1.2833  \n",
      "\n",
      "Check model:  Fold: 24  Optimal epoch: 55  \n",
      "\n",
      "Fold: 25  Epoch: 1  Training loss = 2.9698  Validation loss = 2.0178  \n",
      "\n",
      "Fold: 25  Epoch: 2  Training loss = 2.9680  Validation loss = 2.0012  \n",
      "\n",
      "Fold: 25  Epoch: 3  Training loss = 2.9667  Validation loss = 1.9954  \n",
      "\n",
      "Fold: 25  Epoch: 4  Training loss = 2.9658  Validation loss = 1.9915  \n",
      "\n",
      "Fold: 25  Epoch: 5  Training loss = 2.9652  Validation loss = 1.9954  \n",
      "\n",
      "Fold: 25  Epoch: 6  Training loss = 2.9639  Validation loss = 1.9932  \n",
      "\n",
      "Fold: 25  Epoch: 7  Training loss = 2.9630  Validation loss = 1.9983  \n",
      "\n",
      "Fold: 25  Epoch: 8  Training loss = 2.9615  Validation loss = 1.9993  \n",
      "\n",
      "Fold: 25  Epoch: 9  Training loss = 2.9599  Validation loss = 1.9961  \n",
      "\n",
      "Fold: 25  Epoch: 10  Training loss = 2.9590  Validation loss = 2.0020  \n",
      "\n",
      "Fold: 25  Epoch: 11  Training loss = 2.9585  Validation loss = 2.0223  \n",
      "\n",
      "Check model:  Fold: 25  Optimal epoch: 4  \n",
      "\n",
      "Fold: 26  Epoch: 1  Training loss = 2.7387  Validation loss = 2.8735  \n",
      "\n",
      "Fold: 26  Epoch: 2  Training loss = 2.7370  Validation loss = 2.8842  \n",
      "\n",
      "Fold: 26  Epoch: 3  Training loss = 2.7345  Validation loss = 2.9083  \n",
      "\n",
      "Fold: 26  Epoch: 4  Training loss = 2.7326  Validation loss = 2.9260  \n",
      "\n",
      "Fold: 26  Epoch: 5  Training loss = 2.7302  Validation loss = 2.9512  \n",
      "\n",
      "Fold: 26  Epoch: 6  Training loss = 2.7283  Validation loss = 2.9681  \n",
      "\n",
      "Fold: 26  Epoch: 7  Training loss = 2.7264  Validation loss = 2.9673  \n",
      "\n",
      "Fold: 26  Epoch: 8  Training loss = 2.7246  Validation loss = 2.9723  \n",
      "\n",
      "Fold: 26  Epoch: 9  Training loss = 2.7223  Validation loss = 3.0005  \n",
      "\n",
      "Fold: 26  Epoch: 10  Training loss = 2.7198  Validation loss = 3.0226  \n",
      "\n",
      "Fold: 26  Epoch: 11  Training loss = 2.7183  Validation loss = 3.0152  \n",
      "\n",
      "Fold: 26  Epoch: 12  Training loss = 2.7176  Validation loss = 3.0040  \n",
      "\n",
      "Fold: 26  Epoch: 13  Training loss = 2.7158  Validation loss = 3.0170  \n",
      "\n",
      "Fold: 26  Epoch: 14  Training loss = 2.7143  Validation loss = 3.0317  \n",
      "\n",
      "Check model:  Fold: 26  Optimal epoch: 1  \n",
      "\n",
      "Fold: 27  Epoch: 1  Training loss = 2.7148  Validation loss = 1.2756  \n",
      "\n",
      "Fold: 27  Epoch: 2  Training loss = 2.7114  Validation loss = 1.2444  \n",
      "\n",
      "Fold: 27  Epoch: 3  Training loss = 2.7094  Validation loss = 1.2355  \n",
      "\n",
      "Fold: 27  Epoch: 4  Training loss = 2.7076  Validation loss = 1.2292  \n",
      "\n",
      "Fold: 27  Epoch: 5  Training loss = 2.7057  Validation loss = 1.2359  \n",
      "\n",
      "Fold: 27  Epoch: 6  Training loss = 2.7053  Validation loss = 1.2335  \n",
      "\n",
      "Fold: 27  Epoch: 7  Training loss = 2.7044  Validation loss = 1.2534  \n",
      "\n",
      "Fold: 27  Epoch: 8  Training loss = 2.7022  Validation loss = 1.2187  \n",
      "\n",
      "Fold: 27  Epoch: 9  Training loss = 2.7017  Validation loss = 1.2248  \n",
      "\n",
      "Fold: 27  Epoch: 10  Training loss = 2.7001  Validation loss = 1.2098  \n",
      "\n",
      "Fold: 27  Epoch: 11  Training loss = 2.6972  Validation loss = 1.1771  \n",
      "\n",
      "Fold: 27  Epoch: 12  Training loss = 2.6968  Validation loss = 1.1897  \n",
      "\n",
      "Fold: 27  Epoch: 13  Training loss = 2.6954  Validation loss = 1.1854  \n",
      "\n",
      "Fold: 27  Epoch: 14  Training loss = 2.6944  Validation loss = 1.1770  \n",
      "\n",
      "Fold: 27  Epoch: 15  Training loss = 2.6934  Validation loss = 1.1929  \n",
      "\n",
      "Fold: 27  Epoch: 16  Training loss = 2.6929  Validation loss = 1.2192  \n",
      "\n",
      "Fold: 27  Epoch: 17  Training loss = 2.6900  Validation loss = 1.2037  \n",
      "\n",
      "Fold: 27  Epoch: 18  Training loss = 2.6888  Validation loss = 1.2210  \n",
      "\n",
      "Fold: 27  Epoch: 19  Training loss = 2.6873  Validation loss = 1.2067  \n",
      "\n",
      "Fold: 27  Epoch: 20  Training loss = 2.6868  Validation loss = 1.1869  \n",
      "\n",
      "Fold: 27  Epoch: 21  Training loss = 2.6860  Validation loss = 1.1768  \n",
      "\n",
      "Fold: 27  Epoch: 22  Training loss = 2.6862  Validation loss = 1.1677  \n",
      "\n",
      "Fold: 27  Epoch: 23  Training loss = 2.6836  Validation loss = 1.1916  \n",
      "\n",
      "Fold: 27  Epoch: 24  Training loss = 2.6820  Validation loss = 1.2044  \n",
      "\n",
      "Fold: 27  Epoch: 25  Training loss = 2.6803  Validation loss = 1.1990  \n",
      "\n",
      "Fold: 27  Epoch: 26  Training loss = 2.6798  Validation loss = 1.2389  \n",
      "\n",
      "Check model:  Fold: 27  Optimal epoch: 22  \n",
      "\n",
      "Fold: 28  Epoch: 1  Training loss = 2.6049  Validation loss = 2.1272  \n",
      "\n",
      "Fold: 28  Epoch: 2  Training loss = 2.6028  Validation loss = 2.1153  \n",
      "\n",
      "Fold: 28  Epoch: 3  Training loss = 2.6019  Validation loss = 2.1195  \n",
      "\n",
      "Fold: 28  Epoch: 4  Training loss = 2.6013  Validation loss = 2.1201  \n",
      "\n",
      "Fold: 28  Epoch: 5  Training loss = 2.6005  Validation loss = 2.1160  \n",
      "\n",
      "Fold: 28  Epoch: 6  Training loss = 2.5987  Validation loss = 2.1065  \n",
      "\n",
      "Fold: 28  Epoch: 7  Training loss = 2.5976  Validation loss = 2.1083  \n",
      "\n",
      "Fold: 28  Epoch: 8  Training loss = 2.5971  Validation loss = 2.1149  \n",
      "\n",
      "Fold: 28  Epoch: 9  Training loss = 2.5969  Validation loss = 2.1175  \n",
      "\n",
      "Fold: 28  Epoch: 10  Training loss = 2.5949  Validation loss = 2.1159  \n",
      "\n",
      "Fold: 28  Epoch: 11  Training loss = 2.5928  Validation loss = 2.1081  \n",
      "\n",
      "Fold: 28  Epoch: 12  Training loss = 2.5921  Validation loss = 2.1024  \n",
      "\n",
      "Fold: 28  Epoch: 13  Training loss = 2.5897  Validation loss = 2.0970  \n",
      "\n",
      "Fold: 28  Epoch: 14  Training loss = 2.5878  Validation loss = 2.0995  \n",
      "\n",
      "Fold: 28  Epoch: 15  Training loss = 2.5861  Validation loss = 2.0913  \n",
      "\n",
      "Fold: 28  Epoch: 16  Training loss = 2.5861  Validation loss = 2.1011  \n",
      "\n",
      "Fold: 28  Epoch: 17  Training loss = 2.5842  Validation loss = 2.0984  \n",
      "\n",
      "Fold: 28  Epoch: 18  Training loss = 2.5832  Validation loss = 2.0955  \n",
      "\n",
      "Fold: 28  Epoch: 19  Training loss = 2.5815  Validation loss = 2.0839  \n",
      "\n",
      "Fold: 28  Epoch: 20  Training loss = 2.5800  Validation loss = 2.0782  \n",
      "\n",
      "Fold: 28  Epoch: 21  Training loss = 2.5788  Validation loss = 2.0684  \n",
      "\n",
      "Fold: 28  Epoch: 22  Training loss = 2.5781  Validation loss = 2.0483  \n",
      "\n",
      "Fold: 28  Epoch: 23  Training loss = 2.5773  Validation loss = 2.0513  \n",
      "\n",
      "Fold: 28  Epoch: 24  Training loss = 2.5762  Validation loss = 2.0621  \n",
      "\n",
      "Fold: 28  Epoch: 25  Training loss = 2.5747  Validation loss = 2.0562  \n",
      "\n",
      "Fold: 28  Epoch: 26  Training loss = 2.5734  Validation loss = 2.0528  \n",
      "\n",
      "Fold: 28  Epoch: 27  Training loss = 2.5729  Validation loss = 2.0677  \n",
      "\n",
      "Fold: 28  Epoch: 28  Training loss = 2.5715  Validation loss = 2.0600  \n",
      "\n",
      "Fold: 28  Epoch: 29  Training loss = 2.5707  Validation loss = 2.0695  \n",
      "\n",
      "Fold: 28  Epoch: 30  Training loss = 2.5699  Validation loss = 2.0751  \n",
      "\n",
      "Check model:  Fold: 28  Optimal epoch: 22  \n",
      "\n",
      "Fold: 29  Epoch: 1  Training loss = 2.6003  Validation loss = 1.9988  \n",
      "\n",
      "Fold: 29  Epoch: 2  Training loss = 2.5990  Validation loss = 1.9941  \n",
      "\n",
      "Fold: 29  Epoch: 3  Training loss = 2.5973  Validation loss = 1.9928  \n",
      "\n",
      "Fold: 29  Epoch: 4  Training loss = 2.5959  Validation loss = 1.9889  \n",
      "\n",
      "Fold: 29  Epoch: 5  Training loss = 2.5946  Validation loss = 1.9882  \n",
      "\n",
      "Fold: 29  Epoch: 6  Training loss = 2.5939  Validation loss = 1.9791  \n",
      "\n",
      "Fold: 29  Epoch: 7  Training loss = 2.5921  Validation loss = 1.9702  \n",
      "\n",
      "Fold: 29  Epoch: 8  Training loss = 2.5911  Validation loss = 1.9723  \n",
      "\n",
      "Fold: 29  Epoch: 9  Training loss = 2.5902  Validation loss = 1.9628  \n",
      "\n",
      "Fold: 29  Epoch: 10  Training loss = 2.5892  Validation loss = 1.9632  \n",
      "\n",
      "Fold: 29  Epoch: 11  Training loss = 2.5874  Validation loss = 1.9469  \n",
      "\n",
      "Fold: 29  Epoch: 12  Training loss = 2.5870  Validation loss = 1.9494  \n",
      "\n",
      "Fold: 29  Epoch: 13  Training loss = 2.5860  Validation loss = 1.9505  \n",
      "\n",
      "Fold: 29  Epoch: 14  Training loss = 2.5854  Validation loss = 1.9564  \n",
      "\n",
      "Fold: 29  Epoch: 15  Training loss = 2.5840  Validation loss = 1.9505  \n",
      "\n",
      "Fold: 29  Epoch: 16  Training loss = 2.5832  Validation loss = 1.9449  \n",
      "\n",
      "Fold: 29  Epoch: 17  Training loss = 2.5823  Validation loss = 1.9488  \n",
      "\n",
      "Fold: 29  Epoch: 18  Training loss = 2.5819  Validation loss = 1.9469  \n",
      "\n",
      "Fold: 29  Epoch: 19  Training loss = 2.5806  Validation loss = 1.9440  \n",
      "\n",
      "Fold: 29  Epoch: 20  Training loss = 2.5798  Validation loss = 1.9379  \n",
      "\n",
      "Fold: 29  Epoch: 21  Training loss = 2.5785  Validation loss = 1.9364  \n",
      "\n",
      "Fold: 29  Epoch: 22  Training loss = 2.5780  Validation loss = 1.9435  \n",
      "\n",
      "Fold: 29  Epoch: 23  Training loss = 2.5775  Validation loss = 1.9521  \n",
      "\n",
      "Fold: 29  Epoch: 24  Training loss = 2.5780  Validation loss = 1.9587  \n",
      "\n",
      "Check model:  Fold: 29  Optimal epoch: 21  \n",
      "\n",
      "Fold: 30  Epoch: 1  Training loss = 2.5974  Validation loss = 0.9995  \n",
      "\n",
      "Fold: 30  Epoch: 2  Training loss = 2.5960  Validation loss = 0.9984  \n",
      "\n",
      "Fold: 30  Epoch: 3  Training loss = 2.5948  Validation loss = 0.9992  \n",
      "\n",
      "Fold: 30  Epoch: 4  Training loss = 2.5928  Validation loss = 1.0009  \n",
      "\n",
      "Fold: 30  Epoch: 5  Training loss = 2.5904  Validation loss = 1.0008  \n",
      "\n",
      "Fold: 30  Epoch: 6  Training loss = 2.5889  Validation loss = 1.0014  \n",
      "\n",
      "Fold: 30  Epoch: 7  Training loss = 2.5862  Validation loss = 1.0009  \n",
      "\n",
      "Fold: 30  Epoch: 8  Training loss = 2.5847  Validation loss = 1.0018  \n",
      "\n",
      "Fold: 30  Epoch: 9  Training loss = 2.5836  Validation loss = 1.0006  \n",
      "\n",
      "Fold: 30  Epoch: 10  Training loss = 2.5824  Validation loss = 1.0003  \n",
      "\n",
      "Fold: 30  Epoch: 11  Training loss = 2.5809  Validation loss = 1.0002  \n",
      "\n",
      "Fold: 30  Epoch: 12  Training loss = 2.5795  Validation loss = 1.0021  \n",
      "\n",
      "Check model:  Fold: 30  Optimal epoch: 2  \n",
      "\n",
      "Fold: 31  Epoch: 1  Training loss = 2.3711  Validation loss = 1.6432  \n",
      "\n",
      "Fold: 31  Epoch: 2  Training loss = 2.3704  Validation loss = 1.6458  \n",
      "\n",
      "Fold: 31  Epoch: 3  Training loss = 2.3709  Validation loss = 1.6677  \n",
      "\n",
      "Fold: 31  Epoch: 4  Training loss = 2.3694  Validation loss = 1.6505  \n",
      "\n",
      "Fold: 31  Epoch: 5  Training loss = 2.3697  Validation loss = 1.6785  \n",
      "\n",
      "Fold: 31  Epoch: 6  Training loss = 2.3709  Validation loss = 1.7190  \n",
      "\n",
      "Fold: 31  Epoch: 7  Training loss = 2.3699  Validation loss = 1.7100  \n",
      "\n",
      "Fold: 31  Epoch: 8  Training loss = 2.3681  Validation loss = 1.6881  \n",
      "\n",
      "Fold: 31  Epoch: 9  Training loss = 2.3664  Validation loss = 1.6668  \n",
      "\n",
      "Fold: 31  Epoch: 10  Training loss = 2.3650  Validation loss = 1.6395  \n",
      "\n",
      "Fold: 31  Epoch: 11  Training loss = 2.3640  Validation loss = 1.6135  \n",
      "\n",
      "Fold: 31  Epoch: 12  Training loss = 2.3629  Validation loss = 1.6104  \n",
      "\n",
      "Fold: 31  Epoch: 13  Training loss = 2.3624  Validation loss = 1.6166  \n",
      "\n",
      "Fold: 31  Epoch: 14  Training loss = 2.3619  Validation loss = 1.6261  \n",
      "\n",
      "Fold: 31  Epoch: 15  Training loss = 2.3611  Validation loss = 1.6149  \n",
      "\n",
      "Fold: 31  Epoch: 16  Training loss = 2.3603  Validation loss = 1.6013  \n",
      "\n",
      "Fold: 31  Epoch: 17  Training loss = 2.3596  Validation loss = 1.5952  \n",
      "\n",
      "Fold: 31  Epoch: 18  Training loss = 2.3584  Validation loss = 1.5841  \n",
      "\n",
      "Fold: 31  Epoch: 19  Training loss = 2.3588  Validation loss = 1.5404  \n",
      "\n",
      "Fold: 31  Epoch: 20  Training loss = 2.3603  Validation loss = 1.5322  \n",
      "\n",
      "Fold: 31  Epoch: 21  Training loss = 2.3576  Validation loss = 1.5520  \n",
      "\n",
      "Fold: 31  Epoch: 22  Training loss = 2.3570  Validation loss = 1.5828  \n",
      "\n",
      "Fold: 31  Epoch: 23  Training loss = 2.3573  Validation loss = 1.5831  \n",
      "\n",
      "Fold: 31  Epoch: 24  Training loss = 2.3570  Validation loss = 1.5808  \n",
      "\n",
      "Fold: 31  Epoch: 25  Training loss = 2.3558  Validation loss = 1.6017  \n",
      "\n",
      "Check model:  Fold: 31  Optimal epoch: 20  \n",
      "\n",
      "Fold: 32  Epoch: 1  Training loss = 1.8902  Validation loss = 3.2781  \n",
      "\n",
      "Fold: 32  Epoch: 2  Training loss = 1.8867  Validation loss = 3.2750  \n",
      "\n",
      "Fold: 32  Epoch: 3  Training loss = 1.8862  Validation loss = 3.2699  \n",
      "\n",
      "Fold: 32  Epoch: 4  Training loss = 1.8840  Validation loss = 3.2381  \n",
      "\n",
      "Fold: 32  Epoch: 5  Training loss = 1.8814  Validation loss = 3.2379  \n",
      "\n",
      "Fold: 32  Epoch: 6  Training loss = 1.8802  Validation loss = 3.2328  \n",
      "\n",
      "Fold: 32  Epoch: 7  Training loss = 1.8799  Validation loss = 3.2494  \n",
      "\n",
      "Fold: 32  Epoch: 8  Training loss = 1.8785  Validation loss = 3.2439  \n",
      "\n",
      "Fold: 32  Epoch: 9  Training loss = 1.8779  Validation loss = 3.2429  \n",
      "\n",
      "Fold: 32  Epoch: 10  Training loss = 1.8769  Validation loss = 3.2227  \n",
      "\n",
      "Fold: 32  Epoch: 11  Training loss = 1.8759  Validation loss = 3.2331  \n",
      "\n",
      "Fold: 32  Epoch: 12  Training loss = 1.8758  Validation loss = 3.2465  \n",
      "\n",
      "Fold: 32  Epoch: 13  Training loss = 1.8737  Validation loss = 3.2096  \n",
      "\n",
      "Fold: 32  Epoch: 14  Training loss = 1.8752  Validation loss = 3.2073  \n",
      "\n",
      "Fold: 32  Epoch: 15  Training loss = 1.8735  Validation loss = 3.2299  \n",
      "\n",
      "Fold: 32  Epoch: 16  Training loss = 1.8726  Validation loss = 3.2268  \n",
      "\n",
      "Fold: 32  Epoch: 17  Training loss = 1.8733  Validation loss = 3.2397  \n",
      "\n",
      "Fold: 32  Epoch: 18  Training loss = 1.8722  Validation loss = 3.2486  \n",
      "\n",
      "Check model:  Fold: 32  Optimal epoch: 14  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 2. Train model\n",
    "# ==================================\n",
    "sess = tf.InteractiveSession()  # Launch Graph\n",
    "sess.run(tf.global_variables_initializer())  # Initialise all variables\n",
    "\n",
    "print(\"Start training\", \n",
    "      \"\\nHyperparameters:\",\n",
    "      \"\\nDimension of recurrent unit =\", n_hidden,\n",
    "      \"\\nLearning rate =\", learning_rate,\n",
    "      \"\\nEpochs =\", epochs,\n",
    "      \"\\nBatch size =\", batch_size,\n",
    "      \"\\nEarly stopping epochs =\", early_stop_iters,\n",
    "      \"\\nLearning rate =\", learning_rate)\n",
    "\n",
    "total_batch = int(window_length / batch_size)\n",
    "validation_fold_error = [] # store validation error of each fold\n",
    "optimal_epochs = []\n",
    "\n",
    "# loop through folds\n",
    "for fold in range(1, len(valIndex)):\n",
    "    validx = train_features[valIndex[fold-1]:valIndex[fold]]\n",
    "    validy = train_target[valIndex[fold-1]:valIndex[fold]]\n",
    "    trainx = train_features[(fold-1)*4:valIndex[(fold-1)]]\n",
    "    trainy = train_target[(fold-1)*4:valIndex[(fold-1)]]\n",
    "\n",
    "    loss_list = [] # store validation loss after each epoch for early stopping\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i in range(total_batch):\n",
    "            # Backprop\n",
    "            batch_xs, batch_ys = next_batch(num=batch_size, data=trainx, labels=trainy)\n",
    "            optimizer.run(feed_dict={x:batch_xs, y:batch_ys, lr:learning_rate})\n",
    "\n",
    "        # Loss\n",
    "        loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "        loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "        loss_list.append(loss_valid)\n",
    "\n",
    "        print(\"Fold: {0:d}\".format(fold),\n",
    "              \" Epoch: {0:d}\".format(epoch+1),\n",
    "              \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "              \" Validation loss = {0:.4f}\".format(np.sqrt(loss_valid)),\n",
    "              \" \\n\")\n",
    "\n",
    "        if all(j <= loss_valid for j in loss_list[-early_stop_iters:]) and len(loss_list)>early_stop_iters:\n",
    "            break\n",
    "    \n",
    "    # Load model with lowest validation error for each fold\n",
    "    epoch_hat = np.argmin(loss_list) + 1\n",
    "    optimal_epochs.append(epoch_hat) # store optimal number of epochs for each fold\n",
    "    \n",
    "    # RMSE\n",
    "    loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "    loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "    validation_fold_error.append(np.sqrt(loss_valid))\n",
    "    \n",
    "    print(\"Check model:\",\n",
    "          \" Fold: {0:d}\".format(fold),\n",
    "          \" Optimal epoch: {0:d}\".format(epoch_hat),\n",
    "          \" \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average number of epochs: 229\n",
      "Average validation error: 2.90558\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 3. Optimal epoch choice\n",
    "# ==================================\n",
    "# Pick number of epochs to train model for out-of-sample testing\n",
    "epoch_hat = int(np.mean(optimal_epochs))\n",
    "print(\"\\nAverage number of epochs:\", epoch_hat)\n",
    "# Average validation error\n",
    "print(\"Average validation error:\", np.mean(validation_fold_error))\n",
    "\n",
    "# Save validated model\n",
    "saveModel(sess, \n",
    "          MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + str(epoch_hat) + \"_validated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fixed scheme:\n",
      "Epoch: 1  Training loss = 1.8351  Test loss = 3.0350  \n",
      "\n",
      "Epoch: 2  Training loss = 1.8342  Test loss = 3.0332  \n",
      "\n",
      "Epoch: 3  Training loss = 1.8333  Test loss = 3.0314  \n",
      "\n",
      "Epoch: 4  Training loss = 1.8324  Test loss = 3.0297  \n",
      "\n",
      "Epoch: 5  Training loss = 1.8315  Test loss = 3.0279  \n",
      "\n",
      "Epoch: 6  Training loss = 1.8306  Test loss = 3.0262  \n",
      "\n",
      "Epoch: 7  Training loss = 1.8297  Test loss = 3.0244  \n",
      "\n",
      "Epoch: 8  Training loss = 1.8289  Test loss = 3.0227  \n",
      "\n",
      "Epoch: 9  Training loss = 1.8280  Test loss = 3.0210  \n",
      "\n",
      "Epoch: 10  Training loss = 1.8271  Test loss = 3.0193  \n",
      "\n",
      "Epoch: 11  Training loss = 1.8263  Test loss = 3.0176  \n",
      "\n",
      "Epoch: 12  Training loss = 1.8254  Test loss = 3.0160  \n",
      "\n",
      "Epoch: 13  Training loss = 1.8246  Test loss = 3.0143  \n",
      "\n",
      "Epoch: 14  Training loss = 1.8237  Test loss = 3.0126  \n",
      "\n",
      "Epoch: 15  Training loss = 1.8229  Test loss = 3.0110  \n",
      "\n",
      "Epoch: 16  Training loss = 1.8220  Test loss = 3.0094  \n",
      "\n",
      "Epoch: 17  Training loss = 1.8212  Test loss = 3.0077  \n",
      "\n",
      "Epoch: 18  Training loss = 1.8203  Test loss = 3.0061  \n",
      "\n",
      "Epoch: 19  Training loss = 1.8195  Test loss = 3.0045  \n",
      "\n",
      "Epoch: 20  Training loss = 1.8187  Test loss = 3.0029  \n",
      "\n",
      "Epoch: 21  Training loss = 1.8178  Test loss = 3.0013  \n",
      "\n",
      "Epoch: 22  Training loss = 1.8170  Test loss = 2.9997  \n",
      "\n",
      "Epoch: 23  Training loss = 1.8162  Test loss = 2.9981  \n",
      "\n",
      "Epoch: 24  Training loss = 1.8154  Test loss = 2.9965  \n",
      "\n",
      "Epoch: 25  Training loss = 1.8146  Test loss = 2.9950  \n",
      "\n",
      "Epoch: 26  Training loss = 1.8138  Test loss = 2.9934  \n",
      "\n",
      "Epoch: 27  Training loss = 1.8129  Test loss = 2.9918  \n",
      "\n",
      "Epoch: 28  Training loss = 1.8121  Test loss = 2.9903  \n",
      "\n",
      "Epoch: 29  Training loss = 1.8113  Test loss = 2.9887  \n",
      "\n",
      "Epoch: 30  Training loss = 1.8105  Test loss = 2.9872  \n",
      "\n",
      "Epoch: 31  Training loss = 1.8097  Test loss = 2.9857  \n",
      "\n",
      "Epoch: 32  Training loss = 1.8089  Test loss = 2.9841  \n",
      "\n",
      "Epoch: 33  Training loss = 1.8082  Test loss = 2.9826  \n",
      "\n",
      "Epoch: 34  Training loss = 1.8074  Test loss = 2.9810  \n",
      "\n",
      "Epoch: 35  Training loss = 1.8066  Test loss = 2.9795  \n",
      "\n",
      "Epoch: 36  Training loss = 1.8058  Test loss = 2.9780  \n",
      "\n",
      "Epoch: 37  Training loss = 1.8050  Test loss = 2.9765  \n",
      "\n",
      "Epoch: 38  Training loss = 1.8042  Test loss = 2.9749  \n",
      "\n",
      "Epoch: 39  Training loss = 1.8035  Test loss = 2.9734  \n",
      "\n",
      "Epoch: 40  Training loss = 1.8027  Test loss = 2.9719  \n",
      "\n",
      "Epoch: 41  Training loss = 1.8019  Test loss = 2.9704  \n",
      "\n",
      "Epoch: 42  Training loss = 1.8011  Test loss = 2.9689  \n",
      "\n",
      "Epoch: 43  Training loss = 1.8004  Test loss = 2.9674  \n",
      "\n",
      "Epoch: 44  Training loss = 1.7996  Test loss = 2.9659  \n",
      "\n",
      "Epoch: 45  Training loss = 1.7989  Test loss = 2.9644  \n",
      "\n",
      "Epoch: 46  Training loss = 1.7981  Test loss = 2.9629  \n",
      "\n",
      "Epoch: 47  Training loss = 1.7973  Test loss = 2.9613  \n",
      "\n",
      "Epoch: 48  Training loss = 1.7966  Test loss = 2.9598  \n",
      "\n",
      "Epoch: 49  Training loss = 1.7958  Test loss = 2.9583  \n",
      "\n",
      "Epoch: 50  Training loss = 1.7951  Test loss = 2.9568  \n",
      "\n",
      "Epoch: 51  Training loss = 1.7943  Test loss = 2.9553  \n",
      "\n",
      "Epoch: 52  Training loss = 1.7936  Test loss = 2.9538  \n",
      "\n",
      "Epoch: 53  Training loss = 1.7928  Test loss = 2.9523  \n",
      "\n",
      "Epoch: 54  Training loss = 1.7921  Test loss = 2.9508  \n",
      "\n",
      "Epoch: 55  Training loss = 1.7914  Test loss = 2.9493  \n",
      "\n",
      "Epoch: 56  Training loss = 1.7906  Test loss = 2.9478  \n",
      "\n",
      "Epoch: 57  Training loss = 1.7899  Test loss = 2.9462  \n",
      "\n",
      "Epoch: 58  Training loss = 1.7892  Test loss = 2.9447  \n",
      "\n",
      "Epoch: 59  Training loss = 1.7884  Test loss = 2.9432  \n",
      "\n",
      "Epoch: 60  Training loss = 1.7877  Test loss = 2.9417  \n",
      "\n",
      "Epoch: 61  Training loss = 1.7870  Test loss = 2.9402  \n",
      "\n",
      "Epoch: 62  Training loss = 1.7863  Test loss = 2.9386  \n",
      "\n",
      "Epoch: 63  Training loss = 1.7856  Test loss = 2.9371  \n",
      "\n",
      "Epoch: 64  Training loss = 1.7849  Test loss = 2.9356  \n",
      "\n",
      "Epoch: 65  Training loss = 1.7841  Test loss = 2.9341  \n",
      "\n",
      "Epoch: 66  Training loss = 1.7834  Test loss = 2.9325  \n",
      "\n",
      "Epoch: 67  Training loss = 1.7827  Test loss = 2.9310  \n",
      "\n",
      "Epoch: 68  Training loss = 1.7820  Test loss = 2.9295  \n",
      "\n",
      "Epoch: 69  Training loss = 1.7813  Test loss = 2.9279  \n",
      "\n",
      "Epoch: 70  Training loss = 1.7806  Test loss = 2.9264  \n",
      "\n",
      "Epoch: 71  Training loss = 1.7799  Test loss = 2.9248  \n",
      "\n",
      "Epoch: 72  Training loss = 1.7793  Test loss = 2.9233  \n",
      "\n",
      "Epoch: 73  Training loss = 1.7786  Test loss = 2.9217  \n",
      "\n",
      "Epoch: 74  Training loss = 1.7779  Test loss = 2.9202  \n",
      "\n",
      "Epoch: 75  Training loss = 1.7772  Test loss = 2.9187  \n",
      "\n",
      "Epoch: 76  Training loss = 1.7766  Test loss = 2.9171  \n",
      "\n",
      "Epoch: 77  Training loss = 1.7759  Test loss = 2.9156  \n",
      "\n",
      "Epoch: 78  Training loss = 1.7752  Test loss = 2.9140  \n",
      "\n",
      "Epoch: 79  Training loss = 1.7746  Test loss = 2.9125  \n",
      "\n",
      "Epoch: 80  Training loss = 1.7739  Test loss = 2.9109  \n",
      "\n",
      "Epoch: 81  Training loss = 1.7733  Test loss = 2.9094  \n",
      "\n",
      "Epoch: 82  Training loss = 1.7726  Test loss = 2.9078  \n",
      "\n",
      "Epoch: 83  Training loss = 1.7720  Test loss = 2.9063  \n",
      "\n",
      "Epoch: 84  Training loss = 1.7713  Test loss = 2.9048  \n",
      "\n",
      "Epoch: 85  Training loss = 1.7707  Test loss = 2.9033  \n",
      "\n",
      "Epoch: 86  Training loss = 1.7701  Test loss = 2.9017  \n",
      "\n",
      "Epoch: 87  Training loss = 1.7695  Test loss = 2.9002  \n",
      "\n",
      "Epoch: 88  Training loss = 1.7689  Test loss = 2.8987  \n",
      "\n",
      "Epoch: 89  Training loss = 1.7682  Test loss = 2.8972  \n",
      "\n",
      "Epoch: 90  Training loss = 1.7676  Test loss = 2.8957  \n",
      "\n",
      "Epoch: 91  Training loss = 1.7670  Test loss = 2.8942  \n",
      "\n",
      "Epoch: 92  Training loss = 1.7665  Test loss = 2.8927  \n",
      "\n",
      "Epoch: 93  Training loss = 1.7659  Test loss = 2.8912  \n",
      "\n",
      "Epoch: 94  Training loss = 1.7653  Test loss = 2.8898  \n",
      "\n",
      "Epoch: 95  Training loss = 1.7647  Test loss = 2.8883  \n",
      "\n",
      "Epoch: 96  Training loss = 1.7642  Test loss = 2.8869  \n",
      "\n",
      "Epoch: 97  Training loss = 1.7636  Test loss = 2.8854  \n",
      "\n",
      "Epoch: 98  Training loss = 1.7630  Test loss = 2.8840  \n",
      "\n",
      "Epoch: 99  Training loss = 1.7625  Test loss = 2.8826  \n",
      "\n",
      "Epoch: 100  Training loss = 1.7620  Test loss = 2.8812  \n",
      "\n",
      "Epoch: 101  Training loss = 1.7614  Test loss = 2.8798  \n",
      "\n",
      "Epoch: 102  Training loss = 1.7609  Test loss = 2.8784  \n",
      "\n",
      "Epoch: 103  Training loss = 1.7604  Test loss = 2.8770  \n",
      "\n",
      "Epoch: 104  Training loss = 1.7599  Test loss = 2.8756  \n",
      "\n",
      "Epoch: 105  Training loss = 1.7594  Test loss = 2.8743  \n",
      "\n",
      "Epoch: 106  Training loss = 1.7589  Test loss = 2.8730  \n",
      "\n",
      "Epoch: 107  Training loss = 1.7584  Test loss = 2.8716  \n",
      "\n",
      "Epoch: 108  Training loss = 1.7579  Test loss = 2.8703  \n",
      "\n",
      "Epoch: 109  Training loss = 1.7574  Test loss = 2.8690  \n",
      "\n",
      "Epoch: 110  Training loss = 1.7569  Test loss = 2.8677  \n",
      "\n",
      "Epoch: 111  Training loss = 1.7565  Test loss = 2.8665  \n",
      "\n",
      "Epoch: 112  Training loss = 1.7560  Test loss = 2.8652  \n",
      "\n",
      "Epoch: 113  Training loss = 1.7556  Test loss = 2.8639  \n",
      "\n",
      "Epoch: 114  Training loss = 1.7551  Test loss = 2.8627  \n",
      "\n",
      "Epoch: 115  Training loss = 1.7547  Test loss = 2.8615  \n",
      "\n",
      "Epoch: 116  Training loss = 1.7542  Test loss = 2.8603  \n",
      "\n",
      "Epoch: 117  Training loss = 1.7538  Test loss = 2.8591  \n",
      "\n",
      "Epoch: 118  Training loss = 1.7534  Test loss = 2.8579  \n",
      "\n",
      "Epoch: 119  Training loss = 1.7529  Test loss = 2.8567  \n",
      "\n",
      "Epoch: 120  Training loss = 1.7525  Test loss = 2.8555  \n",
      "\n",
      "Epoch: 121  Training loss = 1.7521  Test loss = 2.8544  \n",
      "\n",
      "Epoch: 122  Training loss = 1.7517  Test loss = 2.8532  \n",
      "\n",
      "Epoch: 123  Training loss = 1.7513  Test loss = 2.8521  \n",
      "\n",
      "Epoch: 124  Training loss = 1.7509  Test loss = 2.8509  \n",
      "\n",
      "Epoch: 125  Training loss = 1.7505  Test loss = 2.8498  \n",
      "\n",
      "Epoch: 126  Training loss = 1.7501  Test loss = 2.8487  \n",
      "\n",
      "Epoch: 127  Training loss = 1.7497  Test loss = 2.8476  \n",
      "\n",
      "Epoch: 128  Training loss = 1.7494  Test loss = 2.8465  \n",
      "\n",
      "Epoch: 129  Training loss = 1.7490  Test loss = 2.8455  \n",
      "\n",
      "Epoch: 130  Training loss = 1.7486  Test loss = 2.8444  \n",
      "\n",
      "Epoch: 131  Training loss = 1.7483  Test loss = 2.8433  \n",
      "\n",
      "Epoch: 132  Training loss = 1.7479  Test loss = 2.8423  \n",
      "\n",
      "Epoch: 133  Training loss = 1.7475  Test loss = 2.8412  \n",
      "\n",
      "Epoch: 134  Training loss = 1.7472  Test loss = 2.8402  \n",
      "\n",
      "Epoch: 135  Training loss = 1.7468  Test loss = 2.8392  \n",
      "\n",
      "Epoch: 136  Training loss = 1.7465  Test loss = 2.8381  \n",
      "\n",
      "Epoch: 137  Training loss = 1.7461  Test loss = 2.8371  \n",
      "\n",
      "Epoch: 138  Training loss = 1.7458  Test loss = 2.8361  \n",
      "\n",
      "Epoch: 139  Training loss = 1.7454  Test loss = 2.8351  \n",
      "\n",
      "Epoch: 140  Training loss = 1.7451  Test loss = 2.8341  \n",
      "\n",
      "Epoch: 141  Training loss = 1.7448  Test loss = 2.8331  \n",
      "\n",
      "Epoch: 142  Training loss = 1.7444  Test loss = 2.8321  \n",
      "\n",
      "Epoch: 143  Training loss = 1.7441  Test loss = 2.8311  \n",
      "\n",
      "Epoch: 144  Training loss = 1.7438  Test loss = 2.8301  \n",
      "\n",
      "Epoch: 145  Training loss = 1.7435  Test loss = 2.8291  \n",
      "\n",
      "Epoch: 146  Training loss = 1.7431  Test loss = 2.8281  \n",
      "\n",
      "Epoch: 147  Training loss = 1.7428  Test loss = 2.8271  \n",
      "\n",
      "Epoch: 148  Training loss = 1.7425  Test loss = 2.8262  \n",
      "\n",
      "Epoch: 149  Training loss = 1.7422  Test loss = 2.8252  \n",
      "\n",
      "Epoch: 150  Training loss = 1.7419  Test loss = 2.8242  \n",
      "\n",
      "Epoch: 151  Training loss = 1.7416  Test loss = 2.8232  \n",
      "\n",
      "Epoch: 152  Training loss = 1.7412  Test loss = 2.8222  \n",
      "\n",
      "Epoch: 153  Training loss = 1.7409  Test loss = 2.8212  \n",
      "\n",
      "Epoch: 154  Training loss = 1.7406  Test loss = 2.8202  \n",
      "\n",
      "Epoch: 155  Training loss = 1.7403  Test loss = 2.8192  \n",
      "\n",
      "Epoch: 156  Training loss = 1.7400  Test loss = 2.8182  \n",
      "\n",
      "Epoch: 157  Training loss = 1.7397  Test loss = 2.8172  \n",
      "\n",
      "Epoch: 158  Training loss = 1.7394  Test loss = 2.8162  \n",
      "\n",
      "Epoch: 159  Training loss = 1.7391  Test loss = 2.8151  \n",
      "\n",
      "Epoch: 160  Training loss = 1.7388  Test loss = 2.8141  \n",
      "\n",
      "Epoch: 161  Training loss = 1.7385  Test loss = 2.8130  \n",
      "\n",
      "Epoch: 162  Training loss = 1.7381  Test loss = 2.8119  \n",
      "\n",
      "Epoch: 163  Training loss = 1.7378  Test loss = 2.8108  \n",
      "\n",
      "Epoch: 164  Training loss = 1.7375  Test loss = 2.8097  \n",
      "\n",
      "Epoch: 165  Training loss = 1.7372  Test loss = 2.8086  \n",
      "\n",
      "Epoch: 166  Training loss = 1.7369  Test loss = 2.8075  \n",
      "\n",
      "Epoch: 167  Training loss = 1.7365  Test loss = 2.8063  \n",
      "\n",
      "Epoch: 168  Training loss = 1.7362  Test loss = 2.8051  \n",
      "\n",
      "Epoch: 169  Training loss = 1.7359  Test loss = 2.8039  \n",
      "\n",
      "Epoch: 170  Training loss = 1.7355  Test loss = 2.8026  \n",
      "\n",
      "Epoch: 171  Training loss = 1.7352  Test loss = 2.8013  \n",
      "\n",
      "Epoch: 172  Training loss = 1.7348  Test loss = 2.8000  \n",
      "\n",
      "Epoch: 173  Training loss = 1.7345  Test loss = 2.7986  \n",
      "\n",
      "Epoch: 174  Training loss = 1.7341  Test loss = 2.7971  \n",
      "\n",
      "Epoch: 175  Training loss = 1.7337  Test loss = 2.7957  \n",
      "\n",
      "Epoch: 176  Training loss = 1.7333  Test loss = 2.7941  \n",
      "\n",
      "Epoch: 177  Training loss = 1.7329  Test loss = 2.7925  \n",
      "\n",
      "Epoch: 178  Training loss = 1.7325  Test loss = 2.7909  \n",
      "\n",
      "Epoch: 179  Training loss = 1.7320  Test loss = 2.7891  \n",
      "\n",
      "Epoch: 180  Training loss = 1.7315  Test loss = 2.7873  \n",
      "\n",
      "Epoch: 181  Training loss = 1.7310  Test loss = 2.7854  \n",
      "\n",
      "Epoch: 182  Training loss = 1.7305  Test loss = 2.7835  \n",
      "\n",
      "Epoch: 183  Training loss = 1.7300  Test loss = 2.7815  \n",
      "\n",
      "Epoch: 184  Training loss = 1.7294  Test loss = 2.7794  \n",
      "\n",
      "Epoch: 185  Training loss = 1.7288  Test loss = 2.7772  \n",
      "\n",
      "Epoch: 186  Training loss = 1.7282  Test loss = 2.7750  \n",
      "\n",
      "Epoch: 187  Training loss = 1.7276  Test loss = 2.7728  \n",
      "\n",
      "Epoch: 188  Training loss = 1.7270  Test loss = 2.7706  \n",
      "\n",
      "Epoch: 189  Training loss = 1.7264  Test loss = 2.7684  \n",
      "\n",
      "Epoch: 190  Training loss = 1.7259  Test loss = 2.7662  \n",
      "\n",
      "Epoch: 191  Training loss = 1.7253  Test loss = 2.7640  \n",
      "\n",
      "Epoch: 192  Training loss = 1.7248  Test loss = 2.7619  \n",
      "\n",
      "Epoch: 193  Training loss = 1.7243  Test loss = 2.7599  \n",
      "\n",
      "Epoch: 194  Training loss = 1.7239  Test loss = 2.7580  \n",
      "\n",
      "Epoch: 195  Training loss = 1.7235  Test loss = 2.7561  \n",
      "\n",
      "Epoch: 196  Training loss = 1.7231  Test loss = 2.7544  \n",
      "\n",
      "Epoch: 197  Training loss = 1.7227  Test loss = 2.7527  \n",
      "\n",
      "Epoch: 198  Training loss = 1.7224  Test loss = 2.7512  \n",
      "\n",
      "Epoch: 199  Training loss = 1.7221  Test loss = 2.7497  \n",
      "\n",
      "Epoch: 200  Training loss = 1.7219  Test loss = 2.7483  \n",
      "\n",
      "Epoch: 201  Training loss = 1.7216  Test loss = 2.7471  \n",
      "\n",
      "Epoch: 202  Training loss = 1.7214  Test loss = 2.7458  \n",
      "\n",
      "Epoch: 203  Training loss = 1.7212  Test loss = 2.7447  \n",
      "\n",
      "Epoch: 204  Training loss = 1.7210  Test loss = 2.7436  \n",
      "\n",
      "Epoch: 205  Training loss = 1.7208  Test loss = 2.7426  \n",
      "\n",
      "Epoch: 206  Training loss = 1.7206  Test loss = 2.7417  \n",
      "\n",
      "Epoch: 207  Training loss = 1.7204  Test loss = 2.7408  \n",
      "\n",
      "Epoch: 208  Training loss = 1.7202  Test loss = 2.7399  \n",
      "\n",
      "Epoch: 209  Training loss = 1.7201  Test loss = 2.7391  \n",
      "\n",
      "Epoch: 210  Training loss = 1.7199  Test loss = 2.7383  \n",
      "\n",
      "Epoch: 211  Training loss = 1.7197  Test loss = 2.7376  \n",
      "\n",
      "Epoch: 212  Training loss = 1.7196  Test loss = 2.7369  \n",
      "\n",
      "Epoch: 213  Training loss = 1.7194  Test loss = 2.7362  \n",
      "\n",
      "Epoch: 214  Training loss = 1.7193  Test loss = 2.7356  \n",
      "\n",
      "Epoch: 215  Training loss = 1.7191  Test loss = 2.7350  \n",
      "\n",
      "Epoch: 216  Training loss = 1.7190  Test loss = 2.7344  \n",
      "\n",
      "Epoch: 217  Training loss = 1.7189  Test loss = 2.7339  \n",
      "\n",
      "Epoch: 218  Training loss = 1.7187  Test loss = 2.7333  \n",
      "\n",
      "Epoch: 219  Training loss = 1.7186  Test loss = 2.7328  \n",
      "\n",
      "Epoch: 220  Training loss = 1.7185  Test loss = 2.7323  \n",
      "\n",
      "Epoch: 221  Training loss = 1.7183  Test loss = 2.7319  \n",
      "\n",
      "Epoch: 222  Training loss = 1.7182  Test loss = 2.7314  \n",
      "\n",
      "Epoch: 223  Training loss = 1.7181  Test loss = 2.7310  \n",
      "\n",
      "Epoch: 224  Training loss = 1.7179  Test loss = 2.7305  \n",
      "\n",
      "Epoch: 225  Training loss = 1.7178  Test loss = 2.7301  \n",
      "\n",
      "Epoch: 226  Training loss = 1.7177  Test loss = 2.7297  \n",
      "\n",
      "Epoch: 227  Training loss = 1.7176  Test loss = 2.7293  \n",
      "\n",
      "Epoch: 228  Training loss = 1.7174  Test loss = 2.7290  \n",
      "\n",
      "Epoch: 229  Training loss = 1.7173  Test loss = 2.7286  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 4. Fixed scheme\n",
    "# ==================================\n",
    "print(\"\\nFixed scheme:\")\n",
    "for epoch in range(epoch_hat):\n",
    "    x_train = train_features[-window_length:]\n",
    "    y_train = train_target[-window_length:]\n",
    "    optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:test_features, y:test_target})\n",
    "    print(\"Epoch: {0:d}\".format(epoch+1),\n",
    "          \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "          \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "          \" \\n\")\n",
    "\n",
    "# Forecasts\n",
    "yhat_test_fixed = pred.eval(feed_dict={x:test_features})\n",
    "yhat_train_fixed = pred.eval(feed_dict={x:x_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n5VSQkZJzywAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc207908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train set\n",
    "plt.plot(y_train, 'black')\n",
    "plt.plot(yhat_train_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n2uxb0gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd2d6a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: fixed scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_test_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed scheme RMSE: 2.72859846321 \n",
      "Fixed scheme MAE:  1.86874062394\n"
     ]
    }
   ],
   "source": [
    "rmse_fixed = np.sqrt(np.mean((yhat_test_fixed[:,0]-test_target)**2))\n",
    "mae_fixed = np.mean(np.abs((yhat_test_fixed[:,0]-test_target)))\n",
    "print(\"Fixed scheme RMSE:\", rmse_fixed,\n",
    "     \"\\nFixed scheme MAE: \", mae_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Stack training and test set, this makes updating scheme easier to train\n",
    "all_features = np.concatenate((train_features[-window_length:], test_features), axis=0)\n",
    "all_target = np.concatenate((train_target[-window_length:], test_target), axis=0)\n",
    "\n",
    "# Vectors to store loss and forecasts\n",
    "test_loss = np.zeros(len(test_target))\n",
    "yhat_update = np.zeros(len(test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test period = 1  Training loss = 1.7173  Test loss = 3.8935  Model updated 0 times  \n",
      "\n",
      "Test period = 2  Training loss = 1.7821  Test loss = 2.6497  Model updated 0 times  \n",
      "\n",
      "Test period = 3  Training loss = 1.7847  Test loss = 1.1854  Model updated 0 times  \n",
      "\n",
      "Test period = 4  Training loss = 1.7780  Test loss = 0.0578  Model updated 0 times  \n",
      "\n",
      "Test period = 5  Training loss = 1.5202  Test loss = 0.6390  Model updated 1 times  \n",
      "\n",
      "Test period = 6  Training loss = 1.4960  Test loss = 0.5273  Model updated 1 times  \n",
      "\n",
      "Test period = 7  Training loss = 1.4822  Test loss = 0.4189  Model updated 1 times  \n",
      "\n",
      "Test period = 8  Training loss = 1.4645  Test loss = 1.7511  Model updated 1 times  \n",
      "\n",
      "Test period = 9  Training loss = 1.4425  Test loss = 1.5990  Model updated 2 times  \n",
      "\n",
      "Test period = 10  Training loss = 1.4481  Test loss = 0.2622  Model updated 2 times  \n",
      "\n",
      "Test period = 11  Training loss = 1.4104  Test loss = 0.1902  Model updated 2 times  \n",
      "\n",
      "Test period = 12  Training loss = 1.4099  Test loss = 1.9136  Model updated 2 times  \n",
      "\n",
      "Test period = 13  Training loss = 1.4101  Test loss = 0.5097  Model updated 3 times  \n",
      "\n",
      "Test period = 14  Training loss = 1.4111  Test loss = 2.0062  Model updated 3 times  \n",
      "\n",
      "Test period = 15  Training loss = 1.4317  Test loss = 3.6611  Model updated 3 times  \n",
      "\n",
      "Test period = 16  Training loss = 1.5018  Test loss = 5.3342  Model updated 3 times  \n",
      "\n",
      "Test period = 17  Training loss = 1.5916  Test loss = 2.6296  Model updated 4 times  \n",
      "\n",
      "Test period = 18  Training loss = 1.6245  Test loss = 0.2378  Model updated 4 times  \n",
      "\n",
      "Test period = 19  Training loss = 1.6245  Test loss = 0.3520  Model updated 4 times  \n",
      "\n",
      "Test period = 20  Training loss = 1.5410  Test loss = 0.9419  Model updated 4 times  \n",
      "\n",
      "Test period = 21  Training loss = 1.4525  Test loss = 1.4108  Model updated 5 times  \n",
      "\n",
      "Test period = 22  Training loss = 1.4612  Test loss = 3.8451  Model updated 5 times  \n",
      "\n",
      "Test period = 23  Training loss = 1.5278  Test loss = 0.1876  Model updated 5 times  \n",
      "\n",
      "Test period = 24  Training loss = 1.5121  Test loss = 1.5133  Model updated 5 times  \n",
      "\n",
      "Test period = 25  Training loss = 1.4944  Test loss = 0.4246  Model updated 6 times  \n",
      "\n",
      "Test period = 26  Training loss = 1.4931  Test loss = 0.4185  Model updated 6 times  \n",
      "\n",
      "Test period = 27  Training loss = 1.4936  Test loss = 0.5167  Model updated 6 times  \n",
      "\n",
      "Test period = 28  Training loss = 1.4901  Test loss = 1.6646  Model updated 6 times  \n",
      "\n",
      "Test period = 29  Training loss = 1.4682  Test loss = 0.7166  Model updated 7 times  \n",
      "\n",
      "Test period = 30  Training loss = 1.4591  Test loss = 1.1856  Model updated 7 times  \n",
      "\n",
      "Test period = 31  Training loss = 1.4537  Test loss = 2.8361  Model updated 7 times  \n",
      "\n",
      "Test period = 32  Training loss = 1.4328  Test loss = 0.9935  Model updated 7 times  \n",
      "\n",
      "Test period = 33  Training loss = 1.4054  Test loss = 0.7944  Model updated 8 times  \n",
      "\n",
      "Test period = 34  Training loss = 1.3989  Test loss = 0.8349  Model updated 8 times  \n",
      "\n",
      "Test period = 35  Training loss = 1.3396  Test loss = 0.4364  Model updated 8 times  \n",
      "\n",
      "Test period = 36  Training loss = 1.3402  Test loss = 4.9034  Model updated 8 times  \n",
      "\n",
      "Test period = 37  Training loss = 1.3745  Test loss = 1.1875  Model updated 9 times  \n",
      "\n",
      "Test period = 38  Training loss = 1.3056  Test loss = 1.5833  Model updated 9 times  \n",
      "\n",
      "Test period = 39  Training loss = 1.3201  Test loss = 0.6738  Model updated 9 times  \n",
      "\n",
      "Test period = 40  Training loss = 1.3189  Test loss = 2.5378  Model updated 9 times  \n",
      "\n",
      "Test period = 41  Training loss = 1.3251  Test loss = 2.1164  Model updated 10 times  \n",
      "\n",
      "Test period = 42  Training loss = 1.3509  Test loss = 2.2055  Model updated 10 times  \n",
      "\n",
      "Test period = 43  Training loss = 1.3777  Test loss = 3.7629  Model updated 10 times  \n",
      "\n",
      "Test period = 44  Training loss = 1.4546  Test loss = 12.6702  Model updated 10 times  \n",
      "\n",
      "Test period = 45  Training loss = 2.1419  Test loss = 6.0521  Model updated 11 times  \n",
      "\n",
      "Test period = 46  Training loss = 2.2691  Test loss = 0.9044  Model updated 11 times  \n",
      "\n",
      "Test period = 47  Training loss = 2.2718  Test loss = 0.2243  Model updated 11 times  \n",
      "\n",
      "Test period = 48  Training loss = 2.2719  Test loss = 0.1387  Model updated 11 times  \n",
      "\n",
      "Test period = 49  Training loss = 2.1879  Test loss = 1.5688  Model updated 12 times  \n",
      "\n",
      "Test period = 50  Training loss = 2.1946  Test loss = 3.1390  Model updated 12 times  \n",
      "\n",
      "Test period = 51  Training loss = 2.2288  Test loss = 0.5898  Model updated 12 times  \n",
      "\n",
      "Test period = 52  Training loss = 2.2290  Test loss = 1.0151  Model updated 12 times  \n",
      "\n",
      "Test period = 53  Training loss = 2.1978  Test loss = 1.3538  Model updated 13 times  \n",
      "\n",
      "Test period = 54  Training loss = 2.2042  Test loss = 2.1269  Model updated 13 times  \n",
      "\n",
      "Test period = 55  Training loss = 2.2179  Test loss = 0.4345  Model updated 13 times  \n",
      "\n",
      "Test period = 56  Training loss = 2.2177  Test loss = 0.6990  Model updated 13 times  \n",
      "\n",
      "Test period = 57  Training loss = 2.1885  Test loss = 0.1759  Model updated 14 times  \n",
      "\n",
      "Test period = 58  Training loss = 2.1880  Test loss = 1.5867  Model updated 14 times  \n",
      "\n",
      "Test period = 59  Training loss = 2.1922  Test loss = 0.4982  Model updated 14 times  \n",
      "\n",
      "Test period = 60  Training loss = 2.1906  Test loss = 0.2911  Model updated 14 times  \n",
      "\n",
      "Test period = 61  Training loss = 2.1677  Test loss = 0.7072  Model updated 15 times  \n",
      "\n",
      "Test period = 62  Training loss = 2.1643  Test loss = 3.1576  Model updated 15 times  \n",
      "\n",
      "Test period = 63  Training loss = 2.1994  Test loss = 0.1421  Model updated 15 times  \n",
      "\n",
      "Test period = 64  Training loss = 2.1873  Test loss = 0.3769  Model updated 15 times  \n",
      "\n",
      "Test period = 65  Training loss = 2.1614  Test loss = 0.1940  Model updated 16 times  \n",
      "\n",
      "Test period = 66  Training loss = 2.1592  Test loss = 0.5058  Model updated 16 times  \n",
      "\n",
      "Test period = 67  Training loss = 2.1519  Test loss = 1.3767  Model updated 16 times  \n",
      "\n",
      "Test period = 68  Training loss = 2.1557  Test loss = 2.8346  Model updated 16 times  \n",
      "\n",
      "Test period = 69  Training loss = 2.1575  Test loss = 4.4363  Model updated 17 times  \n",
      "\n",
      "Test period = 70  Training loss = 2.2258  Test loss = 0.0579  Model updated 17 times  \n",
      "\n",
      "Test period = 71  Training loss = 2.2245  Test loss = 0.9383  Model updated 17 times  \n",
      "\n",
      "Test period = 72  Training loss = 2.2254  Test loss = 2.0997  Model updated 17 times  \n",
      "\n",
      "Test period = 73  Training loss = 2.2014  Test loss = 1.7092  Model updated 18 times  \n",
      "\n",
      "Test period = 74  Training loss = 2.2067  Test loss = 0.2177  Model updated 18 times  \n",
      "\n",
      "Test period = 75  Training loss = 2.1957  Test loss = 0.0755  Model updated 18 times  \n",
      "\n",
      "Test period = 76  Training loss = 2.1950  Test loss = 1.3483  Model updated 18 times  \n",
      "\n",
      "Test period = 77  Training loss = 2.1551  Test loss = 0.8639  Model updated 19 times  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "retrain_count = 0\n",
    "for t in range(len(test_target)):\n",
    "    x_test = np.reshape(test_features[t], newshape=(1,4,3))\n",
    "    y_test = test_target[t]\n",
    "    test_loss[t] = np.sqrt(sess.run(loss, feed_dict={x:x_test, y:y_test}))\n",
    "    yhat_update[t] = pred.eval(feed_dict={x:x_test})\n",
    "\n",
    "    x_train = all_features[t:(window_length+t)]\n",
    "    y_train = all_target[t:(window_length+t)]\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:x_test, y:y_test})\n",
    "    \n",
    "    print(\"Test period = {0:d}\".format(t+1),\n",
    "      \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "      \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "      \" Model updated {0:d} times\".format(retrain_count),\n",
    "      \" \\n\")\n",
    "\n",
    "    if (t+1)%4==0:\n",
    "        retrain_count += 1\n",
    "        for epoch in range(epoch_hat):\n",
    "            for i in range(total_batch):\n",
    "                optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xea7f048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: updating scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_update, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating scheme RMSE: 2.42902557431 \n",
      "Updating scheme MAE:  1.58467757936\n"
     ]
    }
   ],
   "source": [
    "rmse_update = np.sqrt(np.mean((yhat_update-test_target)**2))\n",
    "mae_update = np.mean(np.abs((yhat_update-test_target)))\n",
    "print(\"Updating scheme RMSE:\", rmse_update,\n",
    "     \"\\nUpdating scheme MAE: \", mae_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + \"yhat_test_fixed.csv\", yhat_test_fixed)\n",
    "np.savetxt(MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + \"yhat_update.csv\", yhat_update)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
