{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Directories\n",
    "MODEL_FOLDER = \"../../../models/lstm/\"\n",
    "MODEL_FILENAME = MODEL_FOLDER + \"4Q/64_units/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: model saver\n",
    "def saveModel(sess, MODEL_FILENAME):\n",
    "    if not os.path.exists(MODEL_FOLDER):\n",
    "        print('Creating path where to save model: ' + MODEL_FOLDER)\n",
    "        os.mkdir(MODEL_FOLDER)\n",
    "\n",
    "    #print('Saving model at: ' + MODEL_FILENAME)\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, MODEL_FILENAME)\n",
    "    #print('Model successfully saved.\\n')\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: model loader\n",
    "def loadModel(sess, MODEL_FILENAME):\n",
    "    if os.path.exists(MODEL_FILENAME + \".index\"):\n",
    "        print('Loading save model from: ' + MODEL_FILENAME)\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, MODEL_FILENAME)\n",
    "        print('Model successfully loaded.\\n')\n",
    "        return True\n",
    "    else:\n",
    "        print('Model file <<' + MODEL_FILENAME + '>> does not exists!')\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Hyperparameters\n",
    "epochs = 500\n",
    "learning_rate = 1e-2\n",
    "batch_size = 5\n",
    "early_stop_iters = 10\n",
    "folds = 32\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 3  # data input\n",
    "n_steps = 4  # timesteps\n",
    "n_hidden = 64 # dimension of recurrent unit\n",
    "\n",
    "# (REPRODUCIBILITY) set random seeds\n",
    "tf.set_random_seed(123)\n",
    "\n",
    "# Define weights and biases\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.truncated_normal([n_hidden, 1], stddev = 1.0 / tf.sqrt(float(n_hidden))),\n",
    "        name='out_weight')\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.zeros([1]),\n",
    "        name='out_bias')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: Build model\n",
    "def RNN(X, weights, biases, n_hidden):\n",
    "\n",
    "    # Define a LSTM cell with tensorflow\n",
    "    lstm_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden, state_is_tuple=True)\n",
    "    outputs, _ = tf.nn.dynamic_rnn(lstm_cell, X, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    out_layer = tf.matmul(outputs[:,-1,:], weights['out']) + biases['out']\n",
    "\n",
    "    return out_layer\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: select batch\n",
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the data...\n",
      "Finished: data loaded. Stats below: \n",
      "Nr of training samples: 193\n",
      "Nr of testing  samples: 77\n",
      "Number of variables: 3\n",
      "Number of lags: 4\n",
      "Window length: 65\n",
      "Number of validation folds: 32\n"
     ]
    }
   ],
   "source": [
    "# =================================\n",
    "# 0. Load dataset\n",
    "# =================================\n",
    "print(\"Loading the data...\")\n",
    "# Training set pre-processing\n",
    "train = pd.read_csv('../../../Data/train.csv')\n",
    "train_4lag_inflation = np.array(train[['inflation.lag4',\n",
    "                                       'inflation.lag5',\n",
    "                                       'inflation.lag6',\n",
    "                                       'inflation.lag7']])\n",
    "train_4lag_unemp = np.array(train[['unemp.lag4',\n",
    "                                   'unemp.lag5',\n",
    "                                   'unemp.lag6',\n",
    "                                   'unemp.lag7']])\n",
    "train_4lag_oil = np.array(train[['oil.lag4',\n",
    "                                 'oil.lag5',\n",
    "                                 'oil.lag6',\n",
    "                                 'oil.lag7']])\n",
    "train_features = np.concatenate((train_4lag_inflation[:,:,np.newaxis], \n",
    "\t                             train_4lag_unemp[:,:,np.newaxis],\n",
    "\t                             train_4lag_oil[:,:,np.newaxis]),\n",
    "\t                             axis=2)\n",
    "train_target = np.array(train['inflation.target'])\n",
    "\n",
    "# Test set pre-processing\n",
    "test = pd.read_csv('../../../Data/test.csv')\n",
    "test_4lag_inflation = np.array(test[['inflation.lag4',\n",
    "                                     'inflation.lag5',\n",
    "                                     'inflation.lag6',\n",
    "                                     'inflation.lag7']])\n",
    "test_4lag_unemp = np.array(test[['unemp.lag4',\n",
    "                                 'unemp.lag5',\n",
    "                                 'unemp.lag6',\n",
    "                                 'unemp.lag7']])\n",
    "test_4lag_oil = np.array(test[['oil.lag4',\n",
    "                               'oil.lag5',\n",
    "                               'oil.lag6',\n",
    "                               'oil.lag7']])\n",
    "test_features = np.concatenate((test_4lag_inflation[:,:,np.newaxis], \n",
    "\t                            test_4lag_unemp[:,:,np.newaxis],\n",
    "\t                            test_4lag_oil[:,:,np.newaxis]),\n",
    "\t                            axis=2)\n",
    "test_target = np.array(test['inflation.target'])\n",
    "\n",
    "(nrTrainSamples, timesteps, variables) = train_features.shape\n",
    "(nrTestSamples, _, _) = test_features.shape\n",
    "\n",
    "# Window length and validation fold index\n",
    "window_length = 65\n",
    "valIndex = np.linspace(start=window_length, stop=nrTrainSamples, \n",
    "                       endpoint=True, num=folds+1, dtype=np.int)\n",
    "\n",
    "print(\"Finished: data loaded. Stats below: \")\n",
    "print(\"Nr of training samples: %d\" % nrTrainSamples)\n",
    "print(\"Nr of testing  samples: %d\" % nrTestSamples)\n",
    "print(\"Number of variables: %d\" % variables)\n",
    "print(\"Number of lags: %d\" % timesteps)\n",
    "print(\"Window length: %d\" % window_length)\n",
    "print(\"Number of validation folds: %d\" % folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 1. Build model\n",
    "# ==================================\n",
    "# tf graph input\n",
    "x = tf.placeholder(\"float\", [None, n_steps, n_input], name='Batch')\n",
    "y = tf.placeholder(\"float\", name='True_labels_of_batch')\n",
    "lr = tf.placeholder(\"float\", name='Learning_rate')\n",
    "\n",
    "# Make predictions with the model\n",
    "pred = RNN(x, weights, biases, n_hidden)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss = tf.reduce_mean(tf.diag_part(tf.square(tf.subtract(x=pred, y=y))))\n",
    "optimizer = tf.train.GradientDescentOptimizer(lr).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training \n",
      "Hyperparameters: \n",
      "Dimension of recurrent unit = 64 \n",
      "Learning rate = 0.01 \n",
      "Epochs = 500 \n",
      "Batch size = 5 \n",
      "Early stopping epochs = 10 \n",
      "Learning rate = 0.01\n",
      "Fold: 1  Epoch: 1  Training loss = 2.5869  Validation loss = 1.7393  \n",
      "\n",
      "Fold: 1  Epoch: 2  Training loss = 2.5935  Validation loss = 1.9245  \n",
      "\n",
      "Fold: 1  Epoch: 3  Training loss = 2.5153  Validation loss = 1.1287  \n",
      "\n",
      "Fold: 1  Epoch: 4  Training loss = 2.4495  Validation loss = 1.6459  \n",
      "\n",
      "Fold: 1  Epoch: 5  Training loss = 2.3963  Validation loss = 1.4550  \n",
      "\n",
      "Fold: 1  Epoch: 6  Training loss = 2.3646  Validation loss = 1.5963  \n",
      "\n",
      "Fold: 1  Epoch: 7  Training loss = 2.3993  Validation loss = 1.8338  \n",
      "\n",
      "Fold: 1  Epoch: 8  Training loss = 2.3687  Validation loss = 2.0107  \n",
      "\n",
      "Fold: 1  Epoch: 9  Training loss = 2.2375  Validation loss = 1.8239  \n",
      "\n",
      "Fold: 1  Epoch: 10  Training loss = 2.2205  Validation loss = 2.0747  \n",
      "\n",
      "Fold: 1  Epoch: 11  Training loss = 2.4217  Validation loss = 2.5343  \n",
      "\n",
      "Check model:  Fold: 1  Optimal epoch: 3  \n",
      "\n",
      "Fold: 2  Epoch: 1  Training loss = 2.6383  Validation loss = 2.1380  \n",
      "\n",
      "Fold: 2  Epoch: 2  Training loss = 2.1854  Validation loss = 2.2020  \n",
      "\n",
      "Fold: 2  Epoch: 3  Training loss = 2.2215  Validation loss = 2.2194  \n",
      "\n",
      "Fold: 2  Epoch: 4  Training loss = 2.2218  Validation loss = 1.9459  \n",
      "\n",
      "Fold: 2  Epoch: 5  Training loss = 2.1725  Validation loss = 2.2432  \n",
      "\n",
      "Fold: 2  Epoch: 6  Training loss = 2.1673  Validation loss = 1.9648  \n",
      "\n",
      "Fold: 2  Epoch: 7  Training loss = 2.1049  Validation loss = 2.5040  \n",
      "\n",
      "Fold: 2  Epoch: 8  Training loss = 2.0447  Validation loss = 2.1297  \n",
      "\n",
      "Fold: 2  Epoch: 9  Training loss = 2.3969  Validation loss = 2.0079  \n",
      "\n",
      "Fold: 2  Epoch: 10  Training loss = 2.2062  Validation loss = 2.2923  \n",
      "\n",
      "Fold: 2  Epoch: 11  Training loss = 2.2058  Validation loss = 2.4021  \n",
      "\n",
      "Fold: 2  Epoch: 12  Training loss = 2.1454  Validation loss = 2.2468  \n",
      "\n",
      "Fold: 2  Epoch: 13  Training loss = 2.0524  Validation loss = 2.1848  \n",
      "\n",
      "Fold: 2  Epoch: 14  Training loss = 2.0912  Validation loss = 2.2827  \n",
      "\n",
      "Fold: 2  Epoch: 15  Training loss = 2.0391  Validation loss = 1.9383  \n",
      "\n",
      "Fold: 2  Epoch: 16  Training loss = 2.3903  Validation loss = 1.8501  \n",
      "\n",
      "Fold: 2  Epoch: 17  Training loss = 1.8993  Validation loss = 2.1565  \n",
      "\n",
      "Fold: 2  Epoch: 18  Training loss = 2.5948  Validation loss = 2.2672  \n",
      "\n",
      "Fold: 2  Epoch: 19  Training loss = 2.1005  Validation loss = 2.7135  \n",
      "\n",
      "Check model:  Fold: 2  Optimal epoch: 16  \n",
      "\n",
      "Fold: 3  Epoch: 1  Training loss = 1.4043  Validation loss = 3.8268  \n",
      "\n",
      "Fold: 3  Epoch: 2  Training loss = 1.4345  Validation loss = 3.7767  \n",
      "\n",
      "Fold: 3  Epoch: 3  Training loss = 1.3418  Validation loss = 3.2960  \n",
      "\n",
      "Fold: 3  Epoch: 4  Training loss = 1.3264  Validation loss = 3.2972  \n",
      "\n",
      "Fold: 3  Epoch: 5  Training loss = 1.3542  Validation loss = 3.5121  \n",
      "\n",
      "Fold: 3  Epoch: 6  Training loss = 1.4044  Validation loss = 2.9655  \n",
      "\n",
      "Fold: 3  Epoch: 7  Training loss = 1.3135  Validation loss = 3.1346  \n",
      "\n",
      "Fold: 3  Epoch: 8  Training loss = 1.3047  Validation loss = 3.2608  \n",
      "\n",
      "Fold: 3  Epoch: 9  Training loss = 1.3224  Validation loss = 3.0680  \n",
      "\n",
      "Fold: 3  Epoch: 10  Training loss = 1.4370  Validation loss = 2.7207  \n",
      "\n",
      "Fold: 3  Epoch: 11  Training loss = 1.3138  Validation loss = 3.4149  \n",
      "\n",
      "Fold: 3  Epoch: 12  Training loss = 1.3060  Validation loss = 3.3280  \n",
      "\n",
      "Fold: 3  Epoch: 13  Training loss = 1.2752  Validation loss = 3.1908  \n",
      "\n",
      "Fold: 3  Epoch: 14  Training loss = 1.2768  Validation loss = 3.1458  \n",
      "\n",
      "Fold: 3  Epoch: 15  Training loss = 1.2723  Validation loss = 3.1964  \n",
      "\n",
      "Fold: 3  Epoch: 16  Training loss = 1.2933  Validation loss = 3.3691  \n",
      "\n",
      "Fold: 3  Epoch: 17  Training loss = 1.2721  Validation loss = 3.0609  \n",
      "\n",
      "Fold: 3  Epoch: 18  Training loss = 1.2772  Validation loss = 2.8282  \n",
      "\n",
      "Fold: 3  Epoch: 19  Training loss = 1.2711  Validation loss = 3.0025  \n",
      "\n",
      "Fold: 3  Epoch: 20  Training loss = 1.2547  Validation loss = 3.0089  \n",
      "\n",
      "Fold: 3  Epoch: 21  Training loss = 1.2554  Validation loss = 2.9631  \n",
      "\n",
      "Fold: 3  Epoch: 22  Training loss = 1.2438  Validation loss = 3.0425  \n",
      "\n",
      "Fold: 3  Epoch: 23  Training loss = 1.2327  Validation loss = 3.0802  \n",
      "\n",
      "Fold: 3  Epoch: 24  Training loss = 1.2288  Validation loss = 3.0902  \n",
      "\n",
      "Fold: 3  Epoch: 25  Training loss = 1.2217  Validation loss = 3.0569  \n",
      "\n",
      "Fold: 3  Epoch: 26  Training loss = 1.2151  Validation loss = 3.0765  \n",
      "\n",
      "Fold: 3  Epoch: 27  Training loss = 1.2581  Validation loss = 3.4624  \n",
      "\n",
      "Check model:  Fold: 3  Optimal epoch: 10  \n",
      "\n",
      "Fold: 4  Epoch: 1  Training loss = 1.3347  Validation loss = 3.2882  \n",
      "\n",
      "Fold: 4  Epoch: 2  Training loss = 1.2918  Validation loss = 3.2642  \n",
      "\n",
      "Fold: 4  Epoch: 3  Training loss = 1.3383  Validation loss = 3.0553  \n",
      "\n",
      "Fold: 4  Epoch: 4  Training loss = 1.3617  Validation loss = 3.6621  \n",
      "\n",
      "Fold: 4  Epoch: 5  Training loss = 1.2901  Validation loss = 3.4062  \n",
      "\n",
      "Fold: 4  Epoch: 6  Training loss = 1.2864  Validation loss = 3.0710  \n",
      "\n",
      "Fold: 4  Epoch: 7  Training loss = 1.2288  Validation loss = 2.9253  \n",
      "\n",
      "Fold: 4  Epoch: 8  Training loss = 1.2251  Validation loss = 3.1397  \n",
      "\n",
      "Fold: 4  Epoch: 9  Training loss = 1.1945  Validation loss = 2.8358  \n",
      "\n",
      "Fold: 4  Epoch: 10  Training loss = 1.1780  Validation loss = 2.7342  \n",
      "\n",
      "Fold: 4  Epoch: 11  Training loss = 1.3362  Validation loss = 2.0293  \n",
      "\n",
      "Fold: 4  Epoch: 12  Training loss = 1.1739  Validation loss = 2.5629  \n",
      "\n",
      "Fold: 4  Epoch: 13  Training loss = 1.1426  Validation loss = 2.7017  \n",
      "\n",
      "Fold: 4  Epoch: 14  Training loss = 1.1398  Validation loss = 2.9851  \n",
      "\n",
      "Fold: 4  Epoch: 15  Training loss = 1.1511  Validation loss = 3.3067  \n",
      "\n",
      "Check model:  Fold: 4  Optimal epoch: 11  \n",
      "\n",
      "Fold: 5  Epoch: 1  Training loss = 1.1460  Validation loss = 2.8362  \n",
      "\n",
      "Fold: 5  Epoch: 2  Training loss = 1.1546  Validation loss = 2.5023  \n",
      "\n",
      "Fold: 5  Epoch: 3  Training loss = 1.1005  Validation loss = 2.8001  \n",
      "\n",
      "Fold: 5  Epoch: 4  Training loss = 1.1777  Validation loss = 2.6126  \n",
      "\n",
      "Fold: 5  Epoch: 5  Training loss = 1.0687  Validation loss = 2.2020  \n",
      "\n",
      "Fold: 5  Epoch: 6  Training loss = 1.0750  Validation loss = 2.3337  \n",
      "\n",
      "Fold: 5  Epoch: 7  Training loss = 1.0695  Validation loss = 2.5581  \n",
      "\n",
      "Fold: 5  Epoch: 8  Training loss = 1.0235  Validation loss = 2.3995  \n",
      "\n",
      "Fold: 5  Epoch: 9  Training loss = 1.0246  Validation loss = 2.2472  \n",
      "\n",
      "Fold: 5  Epoch: 10  Training loss = 1.0409  Validation loss = 2.1968  \n",
      "\n",
      "Fold: 5  Epoch: 11  Training loss = 1.0358  Validation loss = 2.2513  \n",
      "\n",
      "Fold: 5  Epoch: 12  Training loss = 1.0794  Validation loss = 2.2954  \n",
      "\n",
      "Fold: 5  Epoch: 13  Training loss = 1.1275  Validation loss = 2.3836  \n",
      "\n",
      "Fold: 5  Epoch: 14  Training loss = 1.0411  Validation loss = 2.2354  \n",
      "\n",
      "Fold: 5  Epoch: 15  Training loss = 1.0465  Validation loss = 2.2935  \n",
      "\n",
      "Fold: 5  Epoch: 16  Training loss = 1.0846  Validation loss = 2.1578  \n",
      "\n",
      "Fold: 5  Epoch: 17  Training loss = 1.1102  Validation loss = 2.4976  \n",
      "\n",
      "Check model:  Fold: 5  Optimal epoch: 16  \n",
      "\n",
      "Fold: 6  Epoch: 1  Training loss = 1.0485  Validation loss = 1.1129  \n",
      "\n",
      "Fold: 6  Epoch: 2  Training loss = 1.0014  Validation loss = 1.2490  \n",
      "\n",
      "Fold: 6  Epoch: 3  Training loss = 0.9901  Validation loss = 1.4020  \n",
      "\n",
      "Fold: 6  Epoch: 4  Training loss = 0.9470  Validation loss = 1.4190  \n",
      "\n",
      "Fold: 6  Epoch: 5  Training loss = 1.0730  Validation loss = 1.0454  \n",
      "\n",
      "Fold: 6  Epoch: 6  Training loss = 0.9166  Validation loss = 1.3032  \n",
      "\n",
      "Fold: 6  Epoch: 7  Training loss = 0.9341  Validation loss = 1.2668  \n",
      "\n",
      "Fold: 6  Epoch: 8  Training loss = 0.9064  Validation loss = 1.1147  \n",
      "\n",
      "Fold: 6  Epoch: 9  Training loss = 0.9672  Validation loss = 1.1909  \n",
      "\n",
      "Fold: 6  Epoch: 10  Training loss = 0.9055  Validation loss = 1.3290  \n",
      "\n",
      "Fold: 6  Epoch: 11  Training loss = 0.9141  Validation loss = 1.1266  \n",
      "\n",
      "Fold: 6  Epoch: 12  Training loss = 0.9048  Validation loss = 1.1568  \n",
      "\n",
      "Fold: 6  Epoch: 13  Training loss = 0.8982  Validation loss = 1.0427  \n",
      "\n",
      "Fold: 6  Epoch: 14  Training loss = 0.8772  Validation loss = 1.1668  \n",
      "\n",
      "Fold: 6  Epoch: 15  Training loss = 0.9424  Validation loss = 1.0901  \n",
      "\n",
      "Fold: 6  Epoch: 16  Training loss = 0.9111  Validation loss = 1.0084  \n",
      "\n",
      "Fold: 6  Epoch: 17  Training loss = 0.8793  Validation loss = 1.1168  \n",
      "\n",
      "Fold: 6  Epoch: 18  Training loss = 0.8749  Validation loss = 1.2488  \n",
      "\n",
      "Fold: 6  Epoch: 19  Training loss = 0.8530  Validation loss = 1.3607  \n",
      "\n",
      "Check model:  Fold: 6  Optimal epoch: 16  \n",
      "\n",
      "Fold: 7  Epoch: 1  Training loss = 0.9257  Validation loss = 2.3924  \n",
      "\n",
      "Fold: 7  Epoch: 2  Training loss = 0.9542  Validation loss = 2.3288  \n",
      "\n",
      "Fold: 7  Epoch: 3  Training loss = 0.8890  Validation loss = 2.4728  \n",
      "\n",
      "Fold: 7  Epoch: 4  Training loss = 0.8942  Validation loss = 2.4761  \n",
      "\n",
      "Fold: 7  Epoch: 5  Training loss = 0.9065  Validation loss = 2.3904  \n",
      "\n",
      "Fold: 7  Epoch: 6  Training loss = 0.8832  Validation loss = 2.4563  \n",
      "\n",
      "Fold: 7  Epoch: 7  Training loss = 0.9210  Validation loss = 2.4207  \n",
      "\n",
      "Fold: 7  Epoch: 8  Training loss = 0.9336  Validation loss = 2.3081  \n",
      "\n",
      "Fold: 7  Epoch: 9  Training loss = 0.8554  Validation loss = 2.4140  \n",
      "\n",
      "Fold: 7  Epoch: 10  Training loss = 0.9277  Validation loss = 2.4916  \n",
      "\n",
      "Fold: 7  Epoch: 11  Training loss = 1.0015  Validation loss = 2.5772  \n",
      "\n",
      "Check model:  Fold: 7  Optimal epoch: 8  \n",
      "\n",
      "Fold: 8  Epoch: 1  Training loss = 0.9931  Validation loss = 7.0507  \n",
      "\n",
      "Fold: 8  Epoch: 2  Training loss = 1.0356  Validation loss = 7.4082  \n",
      "\n",
      "Fold: 8  Epoch: 3  Training loss = 0.9764  Validation loss = 7.2773  \n",
      "\n",
      "Fold: 8  Epoch: 4  Training loss = 0.9864  Validation loss = 7.3825  \n",
      "\n",
      "Fold: 8  Epoch: 5  Training loss = 0.9407  Validation loss = 7.2369  \n",
      "\n",
      "Fold: 8  Epoch: 6  Training loss = 0.9498  Validation loss = 7.4185  \n",
      "\n",
      "Fold: 8  Epoch: 7  Training loss = 0.9202  Validation loss = 7.2363  \n",
      "\n",
      "Fold: 8  Epoch: 8  Training loss = 0.9225  Validation loss = 7.3631  \n",
      "\n",
      "Fold: 8  Epoch: 9  Training loss = 0.9149  Validation loss = 7.1901  \n",
      "\n",
      "Fold: 8  Epoch: 10  Training loss = 0.9038  Validation loss = 6.9955  \n",
      "\n",
      "Fold: 8  Epoch: 11  Training loss = 0.8940  Validation loss = 7.1109  \n",
      "\n",
      "Fold: 8  Epoch: 12  Training loss = 0.8931  Validation loss = 7.3401  \n",
      "\n",
      "Fold: 8  Epoch: 13  Training loss = 0.9364  Validation loss = 7.3481  \n",
      "\n",
      "Fold: 8  Epoch: 14  Training loss = 0.8690  Validation loss = 7.1961  \n",
      "\n",
      "Fold: 8  Epoch: 15  Training loss = 0.8770  Validation loss = 7.3887  \n",
      "\n",
      "Fold: 8  Epoch: 16  Training loss = 0.8975  Validation loss = 7.1193  \n",
      "\n",
      "Fold: 8  Epoch: 17  Training loss = 0.9281  Validation loss = 7.6300  \n",
      "\n",
      "Check model:  Fold: 8  Optimal epoch: 10  \n",
      "\n",
      "Fold: 9  Epoch: 1  Training loss = 1.8806  Validation loss = 8.0057  \n",
      "\n",
      "Fold: 9  Epoch: 2  Training loss = 1.9008  Validation loss = 7.8150  \n",
      "\n",
      "Fold: 9  Epoch: 3  Training loss = 1.8970  Validation loss = 8.2049  \n",
      "\n",
      "Fold: 9  Epoch: 4  Training loss = 1.7487  Validation loss = 7.8499  \n",
      "\n",
      "Fold: 9  Epoch: 5  Training loss = 1.7236  Validation loss = 7.5320  \n",
      "\n",
      "Fold: 9  Epoch: 6  Training loss = 1.8118  Validation loss = 7.8767  \n",
      "\n",
      "Fold: 9  Epoch: 7  Training loss = 1.5968  Validation loss = 7.1969  \n",
      "\n",
      "Fold: 9  Epoch: 8  Training loss = 1.5767  Validation loss = 6.8931  \n",
      "\n",
      "Fold: 9  Epoch: 9  Training loss = 1.5616  Validation loss = 6.5565  \n",
      "\n",
      "Fold: 9  Epoch: 10  Training loss = 1.6205  Validation loss = 7.1444  \n",
      "\n",
      "Fold: 9  Epoch: 11  Training loss = 1.6207  Validation loss = 7.5216  \n",
      "\n",
      "Fold: 9  Epoch: 12  Training loss = 1.5559  Validation loss = 7.1797  \n",
      "\n",
      "Fold: 9  Epoch: 13  Training loss = 1.5861  Validation loss = 7.0784  \n",
      "\n",
      "Fold: 9  Epoch: 14  Training loss = 1.5068  Validation loss = 6.9984  \n",
      "\n",
      "Fold: 9  Epoch: 15  Training loss = 1.5106  Validation loss = 6.8811  \n",
      "\n",
      "Fold: 9  Epoch: 16  Training loss = 1.5154  Validation loss = 6.7664  \n",
      "\n",
      "Fold: 9  Epoch: 17  Training loss = 1.5310  Validation loss = 6.6159  \n",
      "\n",
      "Fold: 9  Epoch: 18  Training loss = 1.4826  Validation loss = 6.8329  \n",
      "\n",
      "Fold: 9  Epoch: 19  Training loss = 1.5587  Validation loss = 6.8131  \n",
      "\n",
      "Fold: 9  Epoch: 20  Training loss = 1.4477  Validation loss = 6.6668  \n",
      "\n",
      "Fold: 9  Epoch: 21  Training loss = 1.7272  Validation loss = 5.8782  \n",
      "\n",
      "Fold: 9  Epoch: 22  Training loss = 1.4775  Validation loss = 6.5216  \n",
      "\n",
      "Fold: 9  Epoch: 23  Training loss = 1.5647  Validation loss = 6.9514  \n",
      "\n",
      "Fold: 9  Epoch: 24  Training loss = 1.5498  Validation loss = 6.0855  \n",
      "\n",
      "Fold: 9  Epoch: 25  Training loss = 1.4158  Validation loss = 6.2702  \n",
      "\n",
      "Fold: 9  Epoch: 26  Training loss = 1.3660  Validation loss = 6.6134  \n",
      "\n",
      "Fold: 9  Epoch: 27  Training loss = 1.3508  Validation loss = 6.3846  \n",
      "\n",
      "Fold: 9  Epoch: 28  Training loss = 1.5805  Validation loss = 5.8196  \n",
      "\n",
      "Fold: 9  Epoch: 29  Training loss = 1.4710  Validation loss = 6.8375  \n",
      "\n",
      "Fold: 9  Epoch: 30  Training loss = 1.3504  Validation loss = 6.4620  \n",
      "\n",
      "Fold: 9  Epoch: 31  Training loss = 1.5623  Validation loss = 5.8472  \n",
      "\n",
      "Fold: 9  Epoch: 32  Training loss = 1.4239  Validation loss = 5.9055  \n",
      "\n",
      "Fold: 9  Epoch: 33  Training loss = 1.4600  Validation loss = 5.8529  \n",
      "\n",
      "Fold: 9  Epoch: 34  Training loss = 1.3273  Validation loss = 6.2555  \n",
      "\n",
      "Fold: 9  Epoch: 35  Training loss = 1.3130  Validation loss = 6.0388  \n",
      "\n",
      "Fold: 9  Epoch: 36  Training loss = 1.4122  Validation loss = 6.3433  \n",
      "\n",
      "Fold: 9  Epoch: 37  Training loss = 1.8524  Validation loss = 7.0107  \n",
      "\n",
      "Check model:  Fold: 9  Optimal epoch: 28  \n",
      "\n",
      "Fold: 10  Epoch: 1  Training loss = 1.8958  Validation loss = 4.3603  \n",
      "\n",
      "Fold: 10  Epoch: 2  Training loss = 1.9333  Validation loss = 3.9866  \n",
      "\n",
      "Fold: 10  Epoch: 3  Training loss = 2.0568  Validation loss = 4.8585  \n",
      "\n",
      "Fold: 10  Epoch: 4  Training loss = 1.8346  Validation loss = 3.0519  \n",
      "\n",
      "Fold: 10  Epoch: 5  Training loss = 1.8067  Validation loss = 3.4114  \n",
      "\n",
      "Fold: 10  Epoch: 6  Training loss = 1.6866  Validation loss = 2.7826  \n",
      "\n",
      "Fold: 10  Epoch: 7  Training loss = 1.5553  Validation loss = 2.6582  \n",
      "\n",
      "Fold: 10  Epoch: 8  Training loss = 2.1659  Validation loss = 2.2208  \n",
      "\n",
      "Fold: 10  Epoch: 9  Training loss = 1.6620  Validation loss = 3.5805  \n",
      "\n",
      "Fold: 10  Epoch: 10  Training loss = 1.7054  Validation loss = 2.7264  \n",
      "\n",
      "Fold: 10  Epoch: 11  Training loss = 1.6761  Validation loss = 2.5008  \n",
      "\n",
      "Fold: 10  Epoch: 12  Training loss = 2.1804  Validation loss = 3.2431  \n",
      "\n",
      "Fold: 10  Epoch: 13  Training loss = 1.7793  Validation loss = 2.2832  \n",
      "\n",
      "Fold: 10  Epoch: 14  Training loss = 1.8371  Validation loss = 2.3937  \n",
      "\n",
      "Fold: 10  Epoch: 15  Training loss = 1.5312  Validation loss = 2.0136  \n",
      "\n",
      "Fold: 10  Epoch: 16  Training loss = 1.5173  Validation loss = 3.1047  \n",
      "\n",
      "Fold: 10  Epoch: 17  Training loss = 1.5960  Validation loss = 2.5337  \n",
      "\n",
      "Fold: 10  Epoch: 18  Training loss = 1.7827  Validation loss = 1.4944  \n",
      "\n",
      "Fold: 10  Epoch: 19  Training loss = 1.5361  Validation loss = 3.1600  \n",
      "\n",
      "Fold: 10  Epoch: 20  Training loss = 1.4553  Validation loss = 2.5987  \n",
      "\n",
      "Fold: 10  Epoch: 21  Training loss = 1.5603  Validation loss = 3.1750  \n",
      "\n",
      "Fold: 10  Epoch: 22  Training loss = 1.5150  Validation loss = 3.7476  \n",
      "\n",
      "Check model:  Fold: 10  Optimal epoch: 18  \n",
      "\n",
      "Fold: 11  Epoch: 1  Training loss = 1.3288  Validation loss = 3.0335  \n",
      "\n",
      "Fold: 11  Epoch: 2  Training loss = 1.4459  Validation loss = 2.8096  \n",
      "\n",
      "Fold: 11  Epoch: 3  Training loss = 1.4256  Validation loss = 2.6305  \n",
      "\n",
      "Fold: 11  Epoch: 4  Training loss = 1.3387  Validation loss = 2.1653  \n",
      "\n",
      "Fold: 11  Epoch: 5  Training loss = 1.2285  Validation loss = 2.8229  \n",
      "\n",
      "Fold: 11  Epoch: 6  Training loss = 1.3425  Validation loss = 2.5696  \n",
      "\n",
      "Fold: 11  Epoch: 7  Training loss = 1.2058  Validation loss = 2.8333  \n",
      "\n",
      "Fold: 11  Epoch: 8  Training loss = 1.1730  Validation loss = 3.0312  \n",
      "\n",
      "Fold: 11  Epoch: 9  Training loss = 1.1877  Validation loss = 2.9062  \n",
      "\n",
      "Fold: 11  Epoch: 10  Training loss = 1.1635  Validation loss = 2.6576  \n",
      "\n",
      "Fold: 11  Epoch: 11  Training loss = 1.1250  Validation loss = 2.9302  \n",
      "\n",
      "Fold: 11  Epoch: 12  Training loss = 1.1437  Validation loss = 2.8395  \n",
      "\n",
      "Fold: 11  Epoch: 13  Training loss = 1.2515  Validation loss = 2.6996  \n",
      "\n",
      "Fold: 11  Epoch: 14  Training loss = 1.2565  Validation loss = 2.9754  \n",
      "\n",
      "Fold: 11  Epoch: 15  Training loss = 1.1847  Validation loss = 2.7609  \n",
      "\n",
      "Fold: 11  Epoch: 16  Training loss = 1.1145  Validation loss = 2.6651  \n",
      "\n",
      "Fold: 11  Epoch: 17  Training loss = 1.0638  Validation loss = 2.7317  \n",
      "\n",
      "Fold: 11  Epoch: 18  Training loss = 1.4274  Validation loss = 3.6871  \n",
      "\n",
      "Check model:  Fold: 11  Optimal epoch: 4  \n",
      "\n",
      "Fold: 12  Epoch: 1  Training loss = 1.3619  Validation loss = 2.1767  \n",
      "\n",
      "Fold: 12  Epoch: 2  Training loss = 1.4739  Validation loss = 3.3740  \n",
      "\n",
      "Fold: 12  Epoch: 3  Training loss = 1.1910  Validation loss = 2.3124  \n",
      "\n",
      "Fold: 12  Epoch: 4  Training loss = 1.3029  Validation loss = 2.4257  \n",
      "\n",
      "Fold: 12  Epoch: 5  Training loss = 1.1592  Validation loss = 2.2771  \n",
      "\n",
      "Fold: 12  Epoch: 6  Training loss = 1.5705  Validation loss = 1.4779  \n",
      "\n",
      "Fold: 12  Epoch: 7  Training loss = 1.0866  Validation loss = 1.9748  \n",
      "\n",
      "Fold: 12  Epoch: 8  Training loss = 1.0753  Validation loss = 2.2728  \n",
      "\n",
      "Fold: 12  Epoch: 9  Training loss = 1.1045  Validation loss = 2.3132  \n",
      "\n",
      "Fold: 12  Epoch: 10  Training loss = 1.0667  Validation loss = 2.5229  \n",
      "\n",
      "Fold: 12  Epoch: 11  Training loss = 1.4106  Validation loss = 1.5149  \n",
      "\n",
      "Fold: 12  Epoch: 12  Training loss = 1.1428  Validation loss = 2.6558  \n",
      "\n",
      "Check model:  Fold: 12  Optimal epoch: 6  \n",
      "\n",
      "Fold: 13  Epoch: 1  Training loss = 1.0923  Validation loss = 3.7365  \n",
      "\n",
      "Fold: 13  Epoch: 2  Training loss = 1.0433  Validation loss = 3.8065  \n",
      "\n",
      "Fold: 13  Epoch: 3  Training loss = 1.0811  Validation loss = 3.8533  \n",
      "\n",
      "Fold: 13  Epoch: 4  Training loss = 0.9937  Validation loss = 3.5378  \n",
      "\n",
      "Fold: 13  Epoch: 5  Training loss = 1.2602  Validation loss = 3.4944  \n",
      "\n",
      "Fold: 13  Epoch: 6  Training loss = 1.2055  Validation loss = 3.8262  \n",
      "\n",
      "Fold: 13  Epoch: 7  Training loss = 1.0820  Validation loss = 3.5603  \n",
      "\n",
      "Fold: 13  Epoch: 8  Training loss = 1.0163  Validation loss = 3.9061  \n",
      "\n",
      "Fold: 13  Epoch: 9  Training loss = 1.1070  Validation loss = 4.2381  \n",
      "\n",
      "Fold: 13  Epoch: 10  Training loss = 0.9238  Validation loss = 2.8022  \n",
      "\n",
      "Fold: 13  Epoch: 11  Training loss = 1.0503  Validation loss = 3.6623  \n",
      "\n",
      "Fold: 13  Epoch: 12  Training loss = 0.9278  Validation loss = 4.1024  \n",
      "\n",
      "Fold: 13  Epoch: 13  Training loss = 0.9595  Validation loss = 3.4755  \n",
      "\n",
      "Fold: 13  Epoch: 14  Training loss = 0.9635  Validation loss = 3.7418  \n",
      "\n",
      "Fold: 13  Epoch: 15  Training loss = 1.0422  Validation loss = 2.9539  \n",
      "\n",
      "Fold: 13  Epoch: 16  Training loss = 0.9351  Validation loss = 3.7939  \n",
      "\n",
      "Fold: 13  Epoch: 17  Training loss = 0.8805  Validation loss = 3.6120  \n",
      "\n",
      "Fold: 13  Epoch: 18  Training loss = 0.8553  Validation loss = 4.0868  \n",
      "\n",
      "Fold: 13  Epoch: 19  Training loss = 0.8656  Validation loss = 3.9501  \n",
      "\n",
      "Fold: 13  Epoch: 20  Training loss = 0.9404  Validation loss = 2.8402  \n",
      "\n",
      "Fold: 13  Epoch: 21  Training loss = 0.9365  Validation loss = 3.0041  \n",
      "\n",
      "Fold: 13  Epoch: 22  Training loss = 0.9282  Validation loss = 3.1431  \n",
      "\n",
      "Fold: 13  Epoch: 23  Training loss = 0.8762  Validation loss = 3.4327  \n",
      "\n",
      "Fold: 13  Epoch: 24  Training loss = 0.8944  Validation loss = 3.3933  \n",
      "\n",
      "Fold: 13  Epoch: 25  Training loss = 1.0472  Validation loss = 2.6718  \n",
      "\n",
      "Fold: 13  Epoch: 26  Training loss = 0.9609  Validation loss = 3.4354  \n",
      "\n",
      "Fold: 13  Epoch: 27  Training loss = 1.0023  Validation loss = 3.7361  \n",
      "\n",
      "Fold: 13  Epoch: 28  Training loss = 0.9186  Validation loss = 3.3928  \n",
      "\n",
      "Fold: 13  Epoch: 29  Training loss = 0.8288  Validation loss = 3.4967  \n",
      "\n",
      "Fold: 13  Epoch: 30  Training loss = 0.9620  Validation loss = 3.4661  \n",
      "\n",
      "Fold: 13  Epoch: 31  Training loss = 0.8146  Validation loss = 4.0110  \n",
      "\n",
      "Check model:  Fold: 13  Optimal epoch: 25  \n",
      "\n",
      "Fold: 14  Epoch: 1  Training loss = 1.2551  Validation loss = 6.5293  \n",
      "\n",
      "Fold: 14  Epoch: 2  Training loss = 1.1623  Validation loss = 5.9349  \n",
      "\n",
      "Fold: 14  Epoch: 3  Training loss = 1.1136  Validation loss = 5.8085  \n",
      "\n",
      "Fold: 14  Epoch: 4  Training loss = 1.0395  Validation loss = 6.0638  \n",
      "\n",
      "Fold: 14  Epoch: 5  Training loss = 1.0278  Validation loss = 6.0764  \n",
      "\n",
      "Fold: 14  Epoch: 6  Training loss = 1.1238  Validation loss = 6.2187  \n",
      "\n",
      "Fold: 14  Epoch: 7  Training loss = 1.2384  Validation loss = 6.5207  \n",
      "\n",
      "Fold: 14  Epoch: 8  Training loss = 1.0362  Validation loss = 5.6307  \n",
      "\n",
      "Fold: 14  Epoch: 9  Training loss = 1.0935  Validation loss = 5.0497  \n",
      "\n",
      "Fold: 14  Epoch: 10  Training loss = 1.0869  Validation loss = 5.0729  \n",
      "\n",
      "Fold: 14  Epoch: 11  Training loss = 0.9750  Validation loss = 5.1053  \n",
      "\n",
      "Fold: 14  Epoch: 12  Training loss = 0.9717  Validation loss = 5.5983  \n",
      "\n",
      "Fold: 14  Epoch: 13  Training loss = 1.0296  Validation loss = 6.2846  \n",
      "\n",
      "Fold: 14  Epoch: 14  Training loss = 1.0092  Validation loss = 5.6118  \n",
      "\n",
      "Fold: 14  Epoch: 15  Training loss = 1.2435  Validation loss = 5.6664  \n",
      "\n",
      "Fold: 14  Epoch: 16  Training loss = 1.0094  Validation loss = 5.9644  \n",
      "\n",
      "Fold: 14  Epoch: 17  Training loss = 1.2375  Validation loss = 5.3428  \n",
      "\n",
      "Fold: 14  Epoch: 18  Training loss = 1.1213  Validation loss = 6.0344  \n",
      "\n",
      "Fold: 14  Epoch: 19  Training loss = 0.9616  Validation loss = 5.7761  \n",
      "\n",
      "Fold: 14  Epoch: 20  Training loss = 1.0458  Validation loss = 5.1161  \n",
      "\n",
      "Fold: 14  Epoch: 21  Training loss = 0.9070  Validation loss = 5.8029  \n",
      "\n",
      "Fold: 14  Epoch: 22  Training loss = 0.9393  Validation loss = 5.6827  \n",
      "\n",
      "Fold: 14  Epoch: 23  Training loss = 0.8577  Validation loss = 5.8059  \n",
      "\n",
      "Fold: 14  Epoch: 24  Training loss = 0.7998  Validation loss = 5.7339  \n",
      "\n",
      "Fold: 14  Epoch: 25  Training loss = 1.0445  Validation loss = 4.9790  \n",
      "\n",
      "Fold: 14  Epoch: 26  Training loss = 0.8110  Validation loss = 6.2435  \n",
      "\n",
      "Check model:  Fold: 14  Optimal epoch: 25  \n",
      "\n",
      "Fold: 15  Epoch: 1  Training loss = 1.4283  Validation loss = 5.6064  \n",
      "\n",
      "Fold: 15  Epoch: 2  Training loss = 1.3030  Validation loss = 6.9889  \n",
      "\n",
      "Fold: 15  Epoch: 3  Training loss = 1.1305  Validation loss = 6.0098  \n",
      "\n",
      "Fold: 15  Epoch: 4  Training loss = 1.3803  Validation loss = 6.7885  \n",
      "\n",
      "Fold: 15  Epoch: 5  Training loss = 1.3870  Validation loss = 5.2773  \n",
      "\n",
      "Fold: 15  Epoch: 6  Training loss = 1.2342  Validation loss = 5.3661  \n",
      "\n",
      "Fold: 15  Epoch: 7  Training loss = 1.2315  Validation loss = 5.6644  \n",
      "\n",
      "Fold: 15  Epoch: 8  Training loss = 1.1159  Validation loss = 5.9297  \n",
      "\n",
      "Fold: 15  Epoch: 9  Training loss = 1.1183  Validation loss = 5.3044  \n",
      "\n",
      "Fold: 15  Epoch: 10  Training loss = 0.9863  Validation loss = 5.7596  \n",
      "\n",
      "Fold: 15  Epoch: 11  Training loss = 1.5722  Validation loss = 4.9741  \n",
      "\n",
      "Fold: 15  Epoch: 12  Training loss = 1.9592  Validation loss = 4.6554  \n",
      "\n",
      "Fold: 15  Epoch: 13  Training loss = 1.2593  Validation loss = 7.7431  \n",
      "\n",
      "Check model:  Fold: 15  Optimal epoch: 12  \n",
      "\n",
      "Fold: 16  Epoch: 1  Training loss = 1.8629  Validation loss = 3.1960  \n",
      "\n",
      "Fold: 16  Epoch: 2  Training loss = 2.3949  Validation loss = 5.1171  \n",
      "\n",
      "Fold: 16  Epoch: 3  Training loss = 1.9630  Validation loss = 3.8507  \n",
      "\n",
      "Fold: 16  Epoch: 4  Training loss = 1.9088  Validation loss = 5.2468  \n",
      "\n",
      "Fold: 16  Epoch: 5  Training loss = 1.9010  Validation loss = 5.6618  \n",
      "\n",
      "Fold: 16  Epoch: 6  Training loss = 1.8388  Validation loss = 5.1799  \n",
      "\n",
      "Fold: 16  Epoch: 7  Training loss = 1.7231  Validation loss = 5.7892  \n",
      "\n",
      "Fold: 16  Epoch: 8  Training loss = 1.7759  Validation loss = 4.8240  \n",
      "\n",
      "Fold: 16  Epoch: 9  Training loss = 1.8320  Validation loss = 5.0792  \n",
      "\n",
      "Fold: 16  Epoch: 10  Training loss = 1.8415  Validation loss = 6.3365  \n",
      "\n",
      "Fold: 16  Epoch: 11  Training loss = 1.6970  Validation loss = 3.9731  \n",
      "\n",
      "Fold: 16  Epoch: 12  Training loss = 1.7530  Validation loss = 3.6247  \n",
      "\n",
      "Fold: 16  Epoch: 13  Training loss = 1.7801  Validation loss = 4.9731  \n",
      "\n",
      "Fold: 16  Epoch: 14  Training loss = 2.0493  Validation loss = 6.0314  \n",
      "\n",
      "Fold: 16  Epoch: 15  Training loss = 2.0043  Validation loss = 3.7182  \n",
      "\n",
      "Fold: 16  Epoch: 16  Training loss = 1.6257  Validation loss = 5.6680  \n",
      "\n",
      "Fold: 16  Epoch: 17  Training loss = 1.5320  Validation loss = 5.0430  \n",
      "\n",
      "Fold: 16  Epoch: 18  Training loss = 1.6468  Validation loss = 5.1213  \n",
      "\n",
      "Fold: 16  Epoch: 19  Training loss = 2.7578  Validation loss = 6.0212  \n",
      "\n",
      "Fold: 16  Epoch: 20  Training loss = 1.4098  Validation loss = 5.4844  \n",
      "\n",
      "Fold: 16  Epoch: 21  Training loss = 1.3961  Validation loss = 5.2481  \n",
      "\n",
      "Fold: 16  Epoch: 22  Training loss = 1.3972  Validation loss = 5.1024  \n",
      "\n",
      "Fold: 16  Epoch: 23  Training loss = 1.8137  Validation loss = 4.9286  \n",
      "\n",
      "Fold: 16  Epoch: 24  Training loss = 1.9808  Validation loss = 6.0437  \n",
      "\n",
      "Check model:  Fold: 16  Optimal epoch: 1  \n",
      "\n",
      "Fold: 17  Epoch: 1  Training loss = 1.7937  Validation loss = 4.2028  \n",
      "\n",
      "Fold: 17  Epoch: 2  Training loss = 1.8560  Validation loss = 4.3940  \n",
      "\n",
      "Fold: 17  Epoch: 3  Training loss = 1.8033  Validation loss = 4.8208  \n",
      "\n",
      "Fold: 17  Epoch: 4  Training loss = 1.7899  Validation loss = 5.0400  \n",
      "\n",
      "Fold: 17  Epoch: 5  Training loss = 1.5289  Validation loss = 4.9742  \n",
      "\n",
      "Fold: 17  Epoch: 6  Training loss = 1.4404  Validation loss = 4.6577  \n",
      "\n",
      "Fold: 17  Epoch: 7  Training loss = 1.5282  Validation loss = 4.6944  \n",
      "\n",
      "Fold: 17  Epoch: 8  Training loss = 1.4743  Validation loss = 4.8940  \n",
      "\n",
      "Fold: 17  Epoch: 9  Training loss = 1.4183  Validation loss = 4.6823  \n",
      "\n",
      "Fold: 17  Epoch: 10  Training loss = 1.7849  Validation loss = 4.7210  \n",
      "\n",
      "Fold: 17  Epoch: 11  Training loss = 1.5509  Validation loss = 4.3587  \n",
      "\n",
      "Fold: 17  Epoch: 12  Training loss = 1.5293  Validation loss = 4.4997  \n",
      "\n",
      "Fold: 17  Epoch: 13  Training loss = 1.3138  Validation loss = 4.7973  \n",
      "\n",
      "Fold: 17  Epoch: 14  Training loss = 1.3467  Validation loss = 4.8223  \n",
      "\n",
      "Fold: 17  Epoch: 15  Training loss = 1.5449  Validation loss = 4.7224  \n",
      "\n",
      "Fold: 17  Epoch: 16  Training loss = 1.3602  Validation loss = 4.4857  \n",
      "\n",
      "Fold: 17  Epoch: 17  Training loss = 1.4788  Validation loss = 4.6965  \n",
      "\n",
      "Fold: 17  Epoch: 18  Training loss = 1.2108  Validation loss = 4.3368  \n",
      "\n",
      "Fold: 17  Epoch: 19  Training loss = 1.2016  Validation loss = 4.1223  \n",
      "\n",
      "Fold: 17  Epoch: 20  Training loss = 2.4053  Validation loss = 3.9109  \n",
      "\n",
      "Fold: 17  Epoch: 21  Training loss = 2.6375  Validation loss = 4.1066  \n",
      "\n",
      "Fold: 17  Epoch: 22  Training loss = 1.2469  Validation loss = 4.4355  \n",
      "\n",
      "Fold: 17  Epoch: 23  Training loss = 1.2424  Validation loss = 4.6905  \n",
      "\n",
      "Fold: 17  Epoch: 24  Training loss = 1.0491  Validation loss = 4.9265  \n",
      "\n",
      "Check model:  Fold: 17  Optimal epoch: 20  \n",
      "\n",
      "Fold: 18  Epoch: 1  Training loss = 1.3703  Validation loss = 3.6165  \n",
      "\n",
      "Fold: 18  Epoch: 2  Training loss = 1.6991  Validation loss = 2.3104  \n",
      "\n",
      "Fold: 18  Epoch: 3  Training loss = 1.5867  Validation loss = 2.6677  \n",
      "\n",
      "Fold: 18  Epoch: 4  Training loss = 1.2789  Validation loss = 2.4418  \n",
      "\n",
      "Fold: 18  Epoch: 5  Training loss = 1.2549  Validation loss = 2.3906  \n",
      "\n",
      "Fold: 18  Epoch: 6  Training loss = 1.3327  Validation loss = 2.6519  \n",
      "\n",
      "Fold: 18  Epoch: 7  Training loss = 1.4322  Validation loss = 2.4979  \n",
      "\n",
      "Fold: 18  Epoch: 8  Training loss = 1.3757  Validation loss = 2.7662  \n",
      "\n",
      "Fold: 18  Epoch: 9  Training loss = 2.0986  Validation loss = 2.6052  \n",
      "\n",
      "Fold: 18  Epoch: 10  Training loss = 1.1635  Validation loss = 2.4346  \n",
      "\n",
      "Fold: 18  Epoch: 11  Training loss = 1.2760  Validation loss = 2.3687  \n",
      "\n",
      "Fold: 18  Epoch: 12  Training loss = 1.2297  Validation loss = 2.3703  \n",
      "\n",
      "Fold: 18  Epoch: 13  Training loss = 1.1121  Validation loss = 2.9474  \n",
      "\n",
      "Check model:  Fold: 18  Optimal epoch: 2  \n",
      "\n",
      "Fold: 19  Epoch: 1  Training loss = 1.0552  Validation loss = 2.1301  \n",
      "\n",
      "Fold: 19  Epoch: 2  Training loss = 1.0456  Validation loss = 2.1674  \n",
      "\n",
      "Fold: 19  Epoch: 3  Training loss = 1.0019  Validation loss = 2.1868  \n",
      "\n",
      "Fold: 19  Epoch: 4  Training loss = 1.1359  Validation loss = 2.0139  \n",
      "\n",
      "Fold: 19  Epoch: 5  Training loss = 1.0032  Validation loss = 2.0410  \n",
      "\n",
      "Fold: 19  Epoch: 6  Training loss = 1.0332  Validation loss = 2.1127  \n",
      "\n",
      "Fold: 19  Epoch: 7  Training loss = 0.9412  Validation loss = 2.1215  \n",
      "\n",
      "Fold: 19  Epoch: 8  Training loss = 0.8439  Validation loss = 2.0075  \n",
      "\n",
      "Fold: 19  Epoch: 9  Training loss = 1.0440  Validation loss = 2.1642  \n",
      "\n",
      "Fold: 19  Epoch: 10  Training loss = 0.8942  Validation loss = 1.9965  \n",
      "\n",
      "Fold: 19  Epoch: 11  Training loss = 1.1233  Validation loss = 1.8958  \n",
      "\n",
      "Fold: 19  Epoch: 12  Training loss = 0.9500  Validation loss = 1.9307  \n",
      "\n",
      "Fold: 19  Epoch: 13  Training loss = 0.8905  Validation loss = 1.9078  \n",
      "\n",
      "Fold: 19  Epoch: 14  Training loss = 0.8986  Validation loss = 2.0555  \n",
      "\n",
      "Fold: 19  Epoch: 15  Training loss = 0.9263  Validation loss = 2.0608  \n",
      "\n",
      "Fold: 19  Epoch: 16  Training loss = 0.8542  Validation loss = 2.1359  \n",
      "\n",
      "Fold: 19  Epoch: 17  Training loss = 0.9208  Validation loss = 1.8921  \n",
      "\n",
      "Fold: 19  Epoch: 18  Training loss = 1.5576  Validation loss = 1.7970  \n",
      "\n",
      "Fold: 19  Epoch: 19  Training loss = 1.0398  Validation loss = 1.9149  \n",
      "\n",
      "Fold: 19  Epoch: 20  Training loss = 0.9921  Validation loss = 1.8159  \n",
      "\n",
      "Fold: 19  Epoch: 21  Training loss = 0.9306  Validation loss = 2.1204  \n",
      "\n",
      "Fold: 19  Epoch: 22  Training loss = 0.9739  Validation loss = 2.0274  \n",
      "\n",
      "Fold: 19  Epoch: 23  Training loss = 0.9069  Validation loss = 2.4185  \n",
      "\n",
      "Check model:  Fold: 19  Optimal epoch: 18  \n",
      "\n",
      "Fold: 20  Epoch: 1  Training loss = 1.1243  Validation loss = 4.6742  \n",
      "\n",
      "Fold: 20  Epoch: 2  Training loss = 0.8832  Validation loss = 4.5127  \n",
      "\n",
      "Fold: 20  Epoch: 3  Training loss = 0.8829  Validation loss = 4.4107  \n",
      "\n",
      "Fold: 20  Epoch: 4  Training loss = 0.9704  Validation loss = 4.6472  \n",
      "\n",
      "Fold: 20  Epoch: 5  Training loss = 0.8589  Validation loss = 4.1904  \n",
      "\n",
      "Fold: 20  Epoch: 6  Training loss = 0.8176  Validation loss = 4.4147  \n",
      "\n",
      "Fold: 20  Epoch: 7  Training loss = 0.7906  Validation loss = 3.9251  \n",
      "\n",
      "Fold: 20  Epoch: 8  Training loss = 0.8478  Validation loss = 4.4523  \n",
      "\n",
      "Fold: 20  Epoch: 9  Training loss = 0.8671  Validation loss = 3.8136  \n",
      "\n",
      "Fold: 20  Epoch: 10  Training loss = 0.8408  Validation loss = 4.6811  \n",
      "\n",
      "Fold: 20  Epoch: 11  Training loss = 0.7230  Validation loss = 4.3755  \n",
      "\n",
      "Fold: 20  Epoch: 12  Training loss = 1.3228  Validation loss = 5.4390  \n",
      "\n",
      "Check model:  Fold: 20  Optimal epoch: 9  \n",
      "\n",
      "Fold: 21  Epoch: 1  Training loss = 1.0906  Validation loss = 3.5182  \n",
      "\n",
      "Fold: 21  Epoch: 2  Training loss = 1.5575  Validation loss = 3.1464  \n",
      "\n",
      "Fold: 21  Epoch: 3  Training loss = 1.0149  Validation loss = 3.3279  \n",
      "\n",
      "Fold: 21  Epoch: 4  Training loss = 0.9235  Validation loss = 3.4768  \n",
      "\n",
      "Fold: 21  Epoch: 5  Training loss = 0.9769  Validation loss = 3.0396  \n",
      "\n",
      "Fold: 21  Epoch: 6  Training loss = 0.9630  Validation loss = 2.8441  \n",
      "\n",
      "Fold: 21  Epoch: 7  Training loss = 1.0889  Validation loss = 2.8748  \n",
      "\n",
      "Fold: 21  Epoch: 8  Training loss = 0.9686  Validation loss = 2.7972  \n",
      "\n",
      "Fold: 21  Epoch: 9  Training loss = 1.0531  Validation loss = 2.7158  \n",
      "\n",
      "Fold: 21  Epoch: 10  Training loss = 0.9006  Validation loss = 2.7481  \n",
      "\n",
      "Fold: 21  Epoch: 11  Training loss = 1.0541  Validation loss = 2.7889  \n",
      "\n",
      "Fold: 21  Epoch: 12  Training loss = 1.0070  Validation loss = 2.4896  \n",
      "\n",
      "Fold: 21  Epoch: 13  Training loss = 0.8284  Validation loss = 2.5608  \n",
      "\n",
      "Fold: 21  Epoch: 14  Training loss = 0.8329  Validation loss = 2.3377  \n",
      "\n",
      "Fold: 21  Epoch: 15  Training loss = 0.7359  Validation loss = 2.4209  \n",
      "\n",
      "Fold: 21  Epoch: 16  Training loss = 0.7223  Validation loss = 2.4675  \n",
      "\n",
      "Fold: 21  Epoch: 17  Training loss = 0.6855  Validation loss = 2.5440  \n",
      "\n",
      "Fold: 21  Epoch: 18  Training loss = 0.6965  Validation loss = 2.5671  \n",
      "\n",
      "Fold: 21  Epoch: 19  Training loss = 0.7842  Validation loss = 2.4250  \n",
      "\n",
      "Fold: 21  Epoch: 20  Training loss = 0.8123  Validation loss = 2.6533  \n",
      "\n",
      "Fold: 21  Epoch: 21  Training loss = 0.6720  Validation loss = 2.4920  \n",
      "\n",
      "Fold: 21  Epoch: 22  Training loss = 0.6299  Validation loss = 2.4523  \n",
      "\n",
      "Fold: 21  Epoch: 23  Training loss = 0.6620  Validation loss = 2.4925  \n",
      "\n",
      "Fold: 21  Epoch: 24  Training loss = 0.7060  Validation loss = 2.5921  \n",
      "\n",
      "Fold: 21  Epoch: 25  Training loss = 0.6877  Validation loss = 2.4599  \n",
      "\n",
      "Fold: 21  Epoch: 26  Training loss = 0.7255  Validation loss = 2.5650  \n",
      "\n",
      "Fold: 21  Epoch: 27  Training loss = 0.6760  Validation loss = 2.5471  \n",
      "\n",
      "Fold: 21  Epoch: 28  Training loss = 0.6294  Validation loss = 2.6612  \n",
      "\n",
      "Check model:  Fold: 21  Optimal epoch: 14  \n",
      "\n",
      "Fold: 22  Epoch: 1  Training loss = 0.8557  Validation loss = 0.9228  \n",
      "\n",
      "Fold: 22  Epoch: 2  Training loss = 0.8574  Validation loss = 0.8939  \n",
      "\n",
      "Fold: 22  Epoch: 3  Training loss = 0.8181  Validation loss = 0.9127  \n",
      "\n",
      "Fold: 22  Epoch: 4  Training loss = 1.3771  Validation loss = 1.2526  \n",
      "\n",
      "Fold: 22  Epoch: 5  Training loss = 0.7847  Validation loss = 0.8724  \n",
      "\n",
      "Fold: 22  Epoch: 6  Training loss = 0.7854  Validation loss = 1.0491  \n",
      "\n",
      "Fold: 22  Epoch: 7  Training loss = 0.9134  Validation loss = 0.9156  \n",
      "\n",
      "Fold: 22  Epoch: 8  Training loss = 0.6890  Validation loss = 0.8573  \n",
      "\n",
      "Fold: 22  Epoch: 9  Training loss = 0.7100  Validation loss = 0.9375  \n",
      "\n",
      "Fold: 22  Epoch: 10  Training loss = 0.6674  Validation loss = 1.0062  \n",
      "\n",
      "Fold: 22  Epoch: 11  Training loss = 0.6506  Validation loss = 0.9093  \n",
      "\n",
      "Fold: 22  Epoch: 12  Training loss = 0.7480  Validation loss = 0.9486  \n",
      "\n",
      "Fold: 22  Epoch: 13  Training loss = 0.6649  Validation loss = 0.8809  \n",
      "\n",
      "Fold: 22  Epoch: 14  Training loss = 0.6384  Validation loss = 0.9840  \n",
      "\n",
      "Fold: 22  Epoch: 15  Training loss = 0.6559  Validation loss = 0.8529  \n",
      "\n",
      "Fold: 22  Epoch: 16  Training loss = 0.7291  Validation loss = 0.6516  \n",
      "\n",
      "Fold: 22  Epoch: 17  Training loss = 0.5961  Validation loss = 0.8276  \n",
      "\n",
      "Fold: 22  Epoch: 18  Training loss = 0.5975  Validation loss = 0.8048  \n",
      "\n",
      "Fold: 22  Epoch: 19  Training loss = 0.7045  Validation loss = 0.7357  \n",
      "\n",
      "Fold: 22  Epoch: 20  Training loss = 0.6381  Validation loss = 0.8918  \n",
      "\n",
      "Fold: 22  Epoch: 21  Training loss = 0.6779  Validation loss = 1.0401  \n",
      "\n",
      "Check model:  Fold: 22  Optimal epoch: 16  \n",
      "\n",
      "Fold: 23  Epoch: 1  Training loss = 0.7178  Validation loss = 3.5604  \n",
      "\n",
      "Fold: 23  Epoch: 2  Training loss = 0.7312  Validation loss = 3.2244  \n",
      "\n",
      "Fold: 23  Epoch: 3  Training loss = 0.7501  Validation loss = 3.1387  \n",
      "\n",
      "Fold: 23  Epoch: 4  Training loss = 0.6358  Validation loss = 3.6164  \n",
      "\n",
      "Fold: 23  Epoch: 5  Training loss = 0.6771  Validation loss = 3.7299  \n",
      "\n",
      "Fold: 23  Epoch: 6  Training loss = 0.7102  Validation loss = 3.8546  \n",
      "\n",
      "Fold: 23  Epoch: 7  Training loss = 0.6970  Validation loss = 3.7003  \n",
      "\n",
      "Fold: 23  Epoch: 8  Training loss = 0.7369  Validation loss = 3.5894  \n",
      "\n",
      "Fold: 23  Epoch: 9  Training loss = 0.7060  Validation loss = 3.4888  \n",
      "\n",
      "Fold: 23  Epoch: 10  Training loss = 0.6251  Validation loss = 3.8033  \n",
      "\n",
      "Fold: 23  Epoch: 11  Training loss = 0.5971  Validation loss = 3.7381  \n",
      "\n",
      "Fold: 23  Epoch: 12  Training loss = 0.5837  Validation loss = 3.5165  \n",
      "\n",
      "Fold: 23  Epoch: 13  Training loss = 0.6781  Validation loss = 2.7072  \n",
      "\n",
      "Fold: 23  Epoch: 14  Training loss = 0.5993  Validation loss = 2.5137  \n",
      "\n",
      "Fold: 23  Epoch: 15  Training loss = 0.6545  Validation loss = 3.4195  \n",
      "\n",
      "Fold: 23  Epoch: 16  Training loss = 0.6201  Validation loss = 3.6388  \n",
      "\n",
      "Fold: 23  Epoch: 17  Training loss = 0.5566  Validation loss = 3.6354  \n",
      "\n",
      "Fold: 23  Epoch: 18  Training loss = 0.5618  Validation loss = 3.6477  \n",
      "\n",
      "Fold: 23  Epoch: 19  Training loss = 0.6089  Validation loss = 3.7414  \n",
      "\n",
      "Fold: 23  Epoch: 20  Training loss = 0.5420  Validation loss = 3.7095  \n",
      "\n",
      "Fold: 23  Epoch: 21  Training loss = 0.6278  Validation loss = 3.7661  \n",
      "\n",
      "Check model:  Fold: 23  Optimal epoch: 14  \n",
      "\n",
      "Fold: 24  Epoch: 1  Training loss = 1.0630  Validation loss = 1.9660  \n",
      "\n",
      "Fold: 24  Epoch: 2  Training loss = 1.0040  Validation loss = 1.8283  \n",
      "\n",
      "Fold: 24  Epoch: 3  Training loss = 1.0629  Validation loss = 1.6205  \n",
      "\n",
      "Fold: 24  Epoch: 4  Training loss = 1.0281  Validation loss = 1.6232  \n",
      "\n",
      "Fold: 24  Epoch: 5  Training loss = 1.0489  Validation loss = 2.0751  \n",
      "\n",
      "Fold: 24  Epoch: 6  Training loss = 1.1339  Validation loss = 1.8077  \n",
      "\n",
      "Fold: 24  Epoch: 7  Training loss = 1.2055  Validation loss = 2.4182  \n",
      "\n",
      "Fold: 24  Epoch: 8  Training loss = 1.1696  Validation loss = 1.9762  \n",
      "\n",
      "Fold: 24  Epoch: 9  Training loss = 1.0806  Validation loss = 1.6594  \n",
      "\n",
      "Fold: 24  Epoch: 10  Training loss = 1.1956  Validation loss = 1.9828  \n",
      "\n",
      "Fold: 24  Epoch: 11  Training loss = 1.0151  Validation loss = 1.9174  \n",
      "\n",
      "Fold: 24  Epoch: 12  Training loss = 1.0048  Validation loss = 1.7689  \n",
      "\n",
      "Fold: 24  Epoch: 13  Training loss = 1.0724  Validation loss = 1.9074  \n",
      "\n",
      "Fold: 24  Epoch: 14  Training loss = 1.0100  Validation loss = 1.4829  \n",
      "\n",
      "Fold: 24  Epoch: 15  Training loss = 1.0629  Validation loss = 1.8404  \n",
      "\n",
      "Fold: 24  Epoch: 16  Training loss = 1.0191  Validation loss = 1.9569  \n",
      "\n",
      "Fold: 24  Epoch: 17  Training loss = 0.9803  Validation loss = 1.6582  \n",
      "\n",
      "Fold: 24  Epoch: 18  Training loss = 0.9188  Validation loss = 1.7507  \n",
      "\n",
      "Fold: 24  Epoch: 19  Training loss = 0.8940  Validation loss = 1.6006  \n",
      "\n",
      "Fold: 24  Epoch: 20  Training loss = 0.7953  Validation loss = 1.6787  \n",
      "\n",
      "Fold: 24  Epoch: 21  Training loss = 1.1012  Validation loss = 1.7908  \n",
      "\n",
      "Fold: 24  Epoch: 22  Training loss = 1.0868  Validation loss = 1.7462  \n",
      "\n",
      "Fold: 24  Epoch: 23  Training loss = 1.0221  Validation loss = 1.8533  \n",
      "\n",
      "Fold: 24  Epoch: 24  Training loss = 0.9477  Validation loss = 1.8644  \n",
      "\n",
      "Fold: 24  Epoch: 25  Training loss = 0.9019  Validation loss = 1.7992  \n",
      "\n",
      "Fold: 24  Epoch: 26  Training loss = 0.8900  Validation loss = 1.8300  \n",
      "\n",
      "Fold: 24  Epoch: 27  Training loss = 0.9938  Validation loss = 1.7074  \n",
      "\n",
      "Fold: 24  Epoch: 28  Training loss = 0.9929  Validation loss = 1.7320  \n",
      "\n",
      "Fold: 24  Epoch: 29  Training loss = 0.9490  Validation loss = 1.7957  \n",
      "\n",
      "Fold: 24  Epoch: 30  Training loss = 0.8882  Validation loss = 1.8624  \n",
      "\n",
      "Fold: 24  Epoch: 31  Training loss = 0.9501  Validation loss = 1.8255  \n",
      "\n",
      "Fold: 24  Epoch: 32  Training loss = 0.9655  Validation loss = 1.8826  \n",
      "\n",
      "Check model:  Fold: 24  Optimal epoch: 14  \n",
      "\n",
      "Fold: 25  Epoch: 1  Training loss = 1.0090  Validation loss = 2.1843  \n",
      "\n",
      "Fold: 25  Epoch: 2  Training loss = 0.9830  Validation loss = 2.4349  \n",
      "\n",
      "Fold: 25  Epoch: 3  Training loss = 0.9771  Validation loss = 2.1142  \n",
      "\n",
      "Fold: 25  Epoch: 4  Training loss = 0.9660  Validation loss = 2.3619  \n",
      "\n",
      "Fold: 25  Epoch: 5  Training loss = 0.8970  Validation loss = 2.2692  \n",
      "\n",
      "Fold: 25  Epoch: 6  Training loss = 0.9455  Validation loss = 2.1174  \n",
      "\n",
      "Fold: 25  Epoch: 7  Training loss = 0.8550  Validation loss = 2.0658  \n",
      "\n",
      "Fold: 25  Epoch: 8  Training loss = 0.8970  Validation loss = 2.0617  \n",
      "\n",
      "Fold: 25  Epoch: 9  Training loss = 0.9351  Validation loss = 2.4244  \n",
      "\n",
      "Fold: 25  Epoch: 10  Training loss = 1.0896  Validation loss = 1.9026  \n",
      "\n",
      "Fold: 25  Epoch: 11  Training loss = 0.9336  Validation loss = 1.9265  \n",
      "\n",
      "Fold: 25  Epoch: 12  Training loss = 0.9642  Validation loss = 2.4103  \n",
      "\n",
      "Fold: 25  Epoch: 13  Training loss = 0.9559  Validation loss = 2.2184  \n",
      "\n",
      "Fold: 25  Epoch: 14  Training loss = 0.9004  Validation loss = 2.1039  \n",
      "\n",
      "Fold: 25  Epoch: 15  Training loss = 0.9438  Validation loss = 2.1940  \n",
      "\n",
      "Fold: 25  Epoch: 16  Training loss = 1.0453  Validation loss = 2.1009  \n",
      "\n",
      "Fold: 25  Epoch: 17  Training loss = 0.9778  Validation loss = 2.1675  \n",
      "\n",
      "Fold: 25  Epoch: 18  Training loss = 0.9144  Validation loss = 2.2338  \n",
      "\n",
      "Fold: 25  Epoch: 19  Training loss = 0.9015  Validation loss = 1.9756  \n",
      "\n",
      "Fold: 25  Epoch: 20  Training loss = 1.0078  Validation loss = 2.0168  \n",
      "\n",
      "Fold: 25  Epoch: 21  Training loss = 0.9255  Validation loss = 2.1168  \n",
      "\n",
      "Fold: 25  Epoch: 22  Training loss = 0.9480  Validation loss = 2.3398  \n",
      "\n",
      "Check model:  Fold: 25  Optimal epoch: 10  \n",
      "\n",
      "Fold: 26  Epoch: 1  Training loss = 1.0207  Validation loss = 3.0730  \n",
      "\n",
      "Fold: 26  Epoch: 2  Training loss = 1.0773  Validation loss = 3.5463  \n",
      "\n",
      "Fold: 26  Epoch: 3  Training loss = 1.0386  Validation loss = 2.3421  \n",
      "\n",
      "Fold: 26  Epoch: 4  Training loss = 1.6706  Validation loss = 2.5540  \n",
      "\n",
      "Fold: 26  Epoch: 5  Training loss = 1.1455  Validation loss = 2.2822  \n",
      "\n",
      "Fold: 26  Epoch: 6  Training loss = 1.0273  Validation loss = 2.1367  \n",
      "\n",
      "Fold: 26  Epoch: 7  Training loss = 1.0318  Validation loss = 3.1451  \n",
      "\n",
      "Fold: 26  Epoch: 8  Training loss = 0.8545  Validation loss = 2.5129  \n",
      "\n",
      "Fold: 26  Epoch: 9  Training loss = 0.9066  Validation loss = 2.0681  \n",
      "\n",
      "Fold: 26  Epoch: 10  Training loss = 0.8623  Validation loss = 2.8284  \n",
      "\n",
      "Fold: 26  Epoch: 11  Training loss = 0.8500  Validation loss = 2.9080  \n",
      "\n",
      "Fold: 26  Epoch: 12  Training loss = 0.8768  Validation loss = 2.8872  \n",
      "\n",
      "Fold: 26  Epoch: 13  Training loss = 0.8371  Validation loss = 2.2461  \n",
      "\n",
      "Fold: 26  Epoch: 14  Training loss = 0.8064  Validation loss = 2.9949  \n",
      "\n",
      "Fold: 26  Epoch: 15  Training loss = 0.7645  Validation loss = 2.8015  \n",
      "\n",
      "Fold: 26  Epoch: 16  Training loss = 0.8055  Validation loss = 2.2729  \n",
      "\n",
      "Fold: 26  Epoch: 17  Training loss = 0.7819  Validation loss = 2.8108  \n",
      "\n",
      "Fold: 26  Epoch: 18  Training loss = 0.8076  Validation loss = 3.6307  \n",
      "\n",
      "Check model:  Fold: 26  Optimal epoch: 9  \n",
      "\n",
      "Fold: 27  Epoch: 1  Training loss = 1.2905  Validation loss = 1.1680  \n",
      "\n",
      "Fold: 27  Epoch: 2  Training loss = 1.0135  Validation loss = 1.9894  \n",
      "\n",
      "Fold: 27  Epoch: 3  Training loss = 1.0469  Validation loss = 1.6675  \n",
      "\n",
      "Fold: 27  Epoch: 4  Training loss = 1.1073  Validation loss = 1.7846  \n",
      "\n",
      "Fold: 27  Epoch: 5  Training loss = 0.9803  Validation loss = 2.3344  \n",
      "\n",
      "Fold: 27  Epoch: 6  Training loss = 0.9990  Validation loss = 2.2134  \n",
      "\n",
      "Fold: 27  Epoch: 7  Training loss = 0.9918  Validation loss = 2.6740  \n",
      "\n",
      "Fold: 27  Epoch: 8  Training loss = 1.0558  Validation loss = 2.4820  \n",
      "\n",
      "Fold: 27  Epoch: 9  Training loss = 0.9946  Validation loss = 2.7436  \n",
      "\n",
      "Fold: 27  Epoch: 10  Training loss = 1.3202  Validation loss = 2.1055  \n",
      "\n",
      "Fold: 27  Epoch: 11  Training loss = 0.8593  Validation loss = 2.2747  \n",
      "\n",
      "Fold: 27  Epoch: 12  Training loss = 0.8452  Validation loss = 2.7074  \n",
      "\n",
      "Fold: 27  Epoch: 13  Training loss = 0.8545  Validation loss = 2.2944  \n",
      "\n",
      "Fold: 27  Epoch: 14  Training loss = 0.8047  Validation loss = 2.8193  \n",
      "\n",
      "Check model:  Fold: 27  Optimal epoch: 1  \n",
      "\n",
      "Fold: 28  Epoch: 1  Training loss = 0.9601  Validation loss = 1.5862  \n",
      "\n",
      "Fold: 28  Epoch: 2  Training loss = 0.9888  Validation loss = 1.4057  \n",
      "\n",
      "Fold: 28  Epoch: 3  Training loss = 0.9505  Validation loss = 1.4650  \n",
      "\n",
      "Fold: 28  Epoch: 4  Training loss = 0.9790  Validation loss = 1.7309  \n",
      "\n",
      "Fold: 28  Epoch: 5  Training loss = 1.1343  Validation loss = 1.3253  \n",
      "\n",
      "Fold: 28  Epoch: 6  Training loss = 0.8956  Validation loss = 1.7043  \n",
      "\n",
      "Fold: 28  Epoch: 7  Training loss = 0.9781  Validation loss = 1.2290  \n",
      "\n",
      "Fold: 28  Epoch: 8  Training loss = 0.9770  Validation loss = 1.5547  \n",
      "\n",
      "Fold: 28  Epoch: 9  Training loss = 0.9859  Validation loss = 1.1947  \n",
      "\n",
      "Fold: 28  Epoch: 10  Training loss = 1.3657  Validation loss = 1.0326  \n",
      "\n",
      "Fold: 28  Epoch: 11  Training loss = 0.9631  Validation loss = 1.7121  \n",
      "\n",
      "Fold: 28  Epoch: 12  Training loss = 0.9501  Validation loss = 1.3836  \n",
      "\n",
      "Fold: 28  Epoch: 13  Training loss = 0.9161  Validation loss = 1.5777  \n",
      "\n",
      "Fold: 28  Epoch: 14  Training loss = 0.9960  Validation loss = 1.2068  \n",
      "\n",
      "Fold: 28  Epoch: 15  Training loss = 1.1655  Validation loss = 1.4129  \n",
      "\n",
      "Fold: 28  Epoch: 16  Training loss = 1.1546  Validation loss = 1.3999  \n",
      "\n",
      "Fold: 28  Epoch: 17  Training loss = 1.1372  Validation loss = 1.1690  \n",
      "\n",
      "Fold: 28  Epoch: 18  Training loss = 1.0323  Validation loss = 1.5296  \n",
      "\n",
      "Fold: 28  Epoch: 19  Training loss = 0.9916  Validation loss = 1.3490  \n",
      "\n",
      "Fold: 28  Epoch: 20  Training loss = 0.9930  Validation loss = 1.3947  \n",
      "\n",
      "Fold: 28  Epoch: 21  Training loss = 1.0007  Validation loss = 0.9970  \n",
      "\n",
      "Fold: 28  Epoch: 22  Training loss = 1.0214  Validation loss = 1.2792  \n",
      "\n",
      "Fold: 28  Epoch: 23  Training loss = 0.9893  Validation loss = 1.0877  \n",
      "\n",
      "Fold: 28  Epoch: 24  Training loss = 0.9891  Validation loss = 1.6956  \n",
      "\n",
      "Check model:  Fold: 28  Optimal epoch: 21  \n",
      "\n",
      "Fold: 29  Epoch: 1  Training loss = 0.9870  Validation loss = 2.5225  \n",
      "\n",
      "Fold: 29  Epoch: 2  Training loss = 0.9583  Validation loss = 2.7545  \n",
      "\n",
      "Fold: 29  Epoch: 3  Training loss = 0.9163  Validation loss = 2.6650  \n",
      "\n",
      "Fold: 29  Epoch: 4  Training loss = 0.9683  Validation loss = 3.1506  \n",
      "\n",
      "Fold: 29  Epoch: 5  Training loss = 0.9216  Validation loss = 2.9912  \n",
      "\n",
      "Fold: 29  Epoch: 6  Training loss = 0.8987  Validation loss = 2.4736  \n",
      "\n",
      "Fold: 29  Epoch: 7  Training loss = 0.8925  Validation loss = 2.5363  \n",
      "\n",
      "Fold: 29  Epoch: 8  Training loss = 0.9563  Validation loss = 2.7229  \n",
      "\n",
      "Fold: 29  Epoch: 9  Training loss = 0.8846  Validation loss = 2.4100  \n",
      "\n",
      "Fold: 29  Epoch: 10  Training loss = 0.8733  Validation loss = 2.5249  \n",
      "\n",
      "Fold: 29  Epoch: 11  Training loss = 0.8725  Validation loss = 2.3770  \n",
      "\n",
      "Fold: 29  Epoch: 12  Training loss = 1.0110  Validation loss = 3.3025  \n",
      "\n",
      "Check model:  Fold: 29  Optimal epoch: 11  \n",
      "\n",
      "Fold: 30  Epoch: 1  Training loss = 1.2567  Validation loss = 0.8065  \n",
      "\n",
      "Fold: 30  Epoch: 2  Training loss = 0.9786  Validation loss = 0.8508  \n",
      "\n",
      "Fold: 30  Epoch: 3  Training loss = 0.9809  Validation loss = 0.8257  \n",
      "\n",
      "Fold: 30  Epoch: 4  Training loss = 1.1133  Validation loss = 1.0876  \n",
      "\n",
      "Fold: 30  Epoch: 5  Training loss = 1.2351  Validation loss = 0.6842  \n",
      "\n",
      "Fold: 30  Epoch: 6  Training loss = 1.1047  Validation loss = 0.6474  \n",
      "\n",
      "Fold: 30  Epoch: 7  Training loss = 1.1448  Validation loss = 0.9428  \n",
      "\n",
      "Fold: 30  Epoch: 8  Training loss = 1.1473  Validation loss = 0.5976  \n",
      "\n",
      "Fold: 30  Epoch: 9  Training loss = 0.9462  Validation loss = 0.8990  \n",
      "\n",
      "Fold: 30  Epoch: 10  Training loss = 0.9343  Validation loss = 0.7516  \n",
      "\n",
      "Fold: 30  Epoch: 11  Training loss = 1.1831  Validation loss = 0.9570  \n",
      "\n",
      "Fold: 30  Epoch: 12  Training loss = 1.0050  Validation loss = 0.7259  \n",
      "\n",
      "Fold: 30  Epoch: 13  Training loss = 1.0333  Validation loss = 0.9173  \n",
      "\n",
      "Fold: 30  Epoch: 14  Training loss = 0.8647  Validation loss = 0.8174  \n",
      "\n",
      "Fold: 30  Epoch: 15  Training loss = 0.8678  Validation loss = 0.8642  \n",
      "\n",
      "Fold: 30  Epoch: 16  Training loss = 0.9043  Validation loss = 1.0117  \n",
      "\n",
      "Check model:  Fold: 30  Optimal epoch: 8  \n",
      "\n",
      "Fold: 31  Epoch: 1  Training loss = 0.8920  Validation loss = 0.4513  \n",
      "\n",
      "Fold: 31  Epoch: 2  Training loss = 0.9104  Validation loss = 0.9753  \n",
      "\n",
      "Fold: 31  Epoch: 3  Training loss = 0.8737  Validation loss = 0.4390  \n",
      "\n",
      "Fold: 31  Epoch: 4  Training loss = 0.8457  Validation loss = 0.4617  \n",
      "\n",
      "Fold: 31  Epoch: 5  Training loss = 0.8857  Validation loss = 0.7066  \n",
      "\n",
      "Fold: 31  Epoch: 6  Training loss = 0.8906  Validation loss = 0.5917  \n",
      "\n",
      "Fold: 31  Epoch: 7  Training loss = 0.8442  Validation loss = 0.6018  \n",
      "\n",
      "Fold: 31  Epoch: 8  Training loss = 0.8551  Validation loss = 0.6778  \n",
      "\n",
      "Fold: 31  Epoch: 9  Training loss = 0.8346  Validation loss = 0.8415  \n",
      "\n",
      "Fold: 31  Epoch: 10  Training loss = 0.9152  Validation loss = 0.8485  \n",
      "\n",
      "Fold: 31  Epoch: 11  Training loss = 0.8681  Validation loss = 0.6066  \n",
      "\n",
      "Fold: 31  Epoch: 12  Training loss = 0.8942  Validation loss = 0.4982  \n",
      "\n",
      "Fold: 31  Epoch: 13  Training loss = 0.8661  Validation loss = 0.6907  \n",
      "\n",
      "Fold: 31  Epoch: 14  Training loss = 0.8556  Validation loss = 0.8079  \n",
      "\n",
      "Fold: 31  Epoch: 15  Training loss = 0.9217  Validation loss = 1.1922  \n",
      "\n",
      "Check model:  Fold: 31  Optimal epoch: 3  \n",
      "\n",
      "Fold: 32  Epoch: 1  Training loss = 0.8977  Validation loss = 3.6618  \n",
      "\n",
      "Fold: 32  Epoch: 2  Training loss = 0.9300  Validation loss = 3.7562  \n",
      "\n",
      "Fold: 32  Epoch: 3  Training loss = 0.8625  Validation loss = 3.5078  \n",
      "\n",
      "Fold: 32  Epoch: 4  Training loss = 0.9915  Validation loss = 4.0718  \n",
      "\n",
      "Fold: 32  Epoch: 5  Training loss = 0.8675  Validation loss = 3.3775  \n",
      "\n",
      "Fold: 32  Epoch: 6  Training loss = 0.9251  Validation loss = 3.9972  \n",
      "\n",
      "Fold: 32  Epoch: 7  Training loss = 0.8891  Validation loss = 3.7990  \n",
      "\n",
      "Fold: 32  Epoch: 8  Training loss = 0.8912  Validation loss = 3.8149  \n",
      "\n",
      "Fold: 32  Epoch: 9  Training loss = 0.8946  Validation loss = 4.1206  \n",
      "\n",
      "Fold: 32  Epoch: 10  Training loss = 0.8905  Validation loss = 4.1653  \n",
      "\n",
      "Fold: 32  Epoch: 11  Training loss = 0.9943  Validation loss = 4.2437  \n",
      "\n",
      "Check model:  Fold: 32  Optimal epoch: 5  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 2. Train model\n",
    "# ==================================\n",
    "sess = tf.InteractiveSession()  # Launch Graph\n",
    "sess.run(tf.global_variables_initializer())  # Initialise all variables\n",
    "\n",
    "print(\"Start training\", \n",
    "      \"\\nHyperparameters:\",\n",
    "      \"\\nDimension of recurrent unit =\", n_hidden,\n",
    "      \"\\nLearning rate =\", learning_rate,\n",
    "      \"\\nEpochs =\", epochs,\n",
    "      \"\\nBatch size =\", batch_size,\n",
    "      \"\\nEarly stopping epochs =\", early_stop_iters,\n",
    "      \"\\nLearning rate =\", learning_rate)\n",
    "\n",
    "total_batch = int(window_length / batch_size)\n",
    "validation_fold_error = [] # store validation error of each fold\n",
    "optimal_epochs = []\n",
    "\n",
    "# loop through folds\n",
    "for fold in range(1, len(valIndex)):\n",
    "    validx = train_features[valIndex[fold-1]:valIndex[fold]]\n",
    "    validy = train_target[valIndex[fold-1]:valIndex[fold]]\n",
    "    trainx = train_features[(fold-1)*4:valIndex[(fold-1)]]\n",
    "    trainy = train_target[(fold-1)*4:valIndex[(fold-1)]]\n",
    "\n",
    "    loss_list = [] # store validation loss after each epoch for early stopping\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i in range(total_batch):\n",
    "            # Backprop\n",
    "            batch_xs, batch_ys = next_batch(num=batch_size, data=trainx, labels=trainy)\n",
    "            optimizer.run(feed_dict={x:batch_xs, y:batch_ys, lr:learning_rate})\n",
    "\n",
    "        # Loss\n",
    "        loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "        loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "        loss_list.append(loss_valid)\n",
    "\n",
    "        print(\"Fold: {0:d}\".format(fold),\n",
    "              \" Epoch: {0:d}\".format(epoch+1),\n",
    "              \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "              \" Validation loss = {0:.4f}\".format(np.sqrt(loss_valid)),\n",
    "              \" \\n\")\n",
    "\n",
    "        if all(j <= loss_valid for j in loss_list[-early_stop_iters:]) and len(loss_list)>early_stop_iters:\n",
    "            break\n",
    "    \n",
    "    # Load model with lowest validation error for each fold\n",
    "    epoch_hat = np.argmin(loss_list) + 1\n",
    "    optimal_epochs.append(epoch_hat) # store optimal number of epochs for each fold\n",
    "    \n",
    "    # RMSE\n",
    "    loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "    loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "    validation_fold_error.append(np.sqrt(loss_valid))\n",
    "    \n",
    "    print(\"Check model:\",\n",
    "          \" Fold: {0:d}\".format(fold),\n",
    "          \" Optimal epoch: {0:d}\".format(epoch_hat),\n",
    "          \" \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average number of epochs: 12\n",
      "Average validation error: 3.51694\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 3. Optimal epoch choice\n",
    "# ==================================\n",
    "# Pick number of epochs to train model for out-of-sample testing\n",
    "epoch_hat = int(np.mean(optimal_epochs))\n",
    "print(\"\\nAverage number of epochs:\", epoch_hat)\n",
    "# Average validation error\n",
    "print(\"Average validation error:\", np.mean(validation_fold_error))\n",
    "\n",
    "# Save validated model\n",
    "saveModel(sess, \n",
    "          MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + str(epoch_hat) + \"_validated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fixed scheme:\n",
      "Epoch: 1  Training loss = 1.0826  Test loss = 4.1745  \n",
      "\n",
      "Epoch: 2  Training loss = 0.9863  Test loss = 3.9889  \n",
      "\n",
      "Epoch: 3  Training loss = 0.9707  Test loss = 3.9570  \n",
      "\n",
      "Epoch: 4  Training loss = 0.9570  Test loss = 3.9440  \n",
      "\n",
      "Epoch: 5  Training loss = 0.9446  Test loss = 3.9322  \n",
      "\n",
      "Epoch: 6  Training loss = 0.9332  Test loss = 3.9236  \n",
      "\n",
      "Epoch: 7  Training loss = 0.9225  Test loss = 3.9159  \n",
      "\n",
      "Epoch: 8  Training loss = 0.9125  Test loss = 3.9087  \n",
      "\n",
      "Epoch: 9  Training loss = 0.9029  Test loss = 3.9016  \n",
      "\n",
      "Epoch: 10  Training loss = 0.8936  Test loss = 3.8945  \n",
      "\n",
      "Epoch: 11  Training loss = 0.8847  Test loss = 3.8874  \n",
      "\n",
      "Epoch: 12  Training loss = 0.8761  Test loss = 3.8801  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 4. Fixed scheme\n",
    "# ==================================\n",
    "print(\"\\nFixed scheme:\")\n",
    "for epoch in range(epoch_hat):\n",
    "    x_train = train_features[-window_length:]\n",
    "    y_train = train_target[-window_length:]\n",
    "    optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:test_features, y:test_target})\n",
    "    print(\"Epoch: {0:d}\".format(epoch+1),\n",
    "          \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "          \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "          \" \\n\")\n",
    "\n",
    "# Forecasts\n",
    "yhat_test_fixed = pred.eval(feed_dict={x:test_features})\n",
    "yhat_train_fixed = pred.eval(feed_dict={x:x_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc2089e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train set\n",
    "plt.plot(y_train, 'black')\n",
    "plt.plot(yhat_train_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0QFEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xcc32278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: fixed scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_test_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed scheme RMSE: 3.88007280667 \n",
      "Fixed scheme MAE:  2.81460437584\n"
     ]
    }
   ],
   "source": [
    "rmse_fixed = np.sqrt(np.mean((yhat_test_fixed[:,0]-test_target)**2))\n",
    "mae_fixed = np.mean(np.abs((yhat_test_fixed[:,0]-test_target)))\n",
    "print(\"Fixed scheme RMSE:\", rmse_fixed,\n",
    "     \"\\nFixed scheme MAE: \", mae_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Stack training and test set, this makes updating scheme easier to train\n",
    "all_features = np.concatenate((train_features[-window_length:], test_features), axis=0)\n",
    "all_target = np.concatenate((train_target[-window_length:], test_target), axis=0)\n",
    "\n",
    "# Vectors to store loss and forecasts\n",
    "test_loss = np.zeros(len(test_target))\n",
    "yhat_update = np.zeros(len(test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test period = 1  Training loss = 0.8761  Test loss = 1.0780  Model updated 0 times  \n",
      "\n",
      "Test period = 2  Training loss = 0.8862  Test loss = 2.3217  Model updated 0 times  \n",
      "\n",
      "Test period = 3  Training loss = 0.9316  Test loss = 1.3081  Model updated 0 times  \n",
      "\n",
      "Test period = 4  Training loss = 0.9455  Test loss = 3.2363  Model updated 0 times  \n",
      "\n",
      "Test period = 5  Training loss = 0.6846  Test loss = 3.8836  Model updated 1 times  \n",
      "\n",
      "Test period = 6  Training loss = 0.8370  Test loss = 2.9353  Model updated 1 times  \n",
      "\n",
      "Test period = 7  Training loss = 0.9127  Test loss = 0.8821  Model updated 1 times  \n",
      "\n",
      "Test period = 8  Training loss = 0.9189  Test loss = 0.6648  Model updated 1 times  \n",
      "\n",
      "Test period = 9  Training loss = 0.6249  Test loss = 2.2989  Model updated 2 times  \n",
      "\n",
      "Test period = 10  Training loss = 0.6866  Test loss = 2.9801  Model updated 2 times  \n",
      "\n",
      "Test period = 11  Training loss = 0.7797  Test loss = 1.8545  Model updated 2 times  \n",
      "\n",
      "Test period = 12  Training loss = 0.8129  Test loss = 0.2556  Model updated 2 times  \n",
      "\n",
      "Test period = 13  Training loss = 0.5356  Test loss = 3.9202  Model updated 3 times  \n",
      "\n",
      "Test period = 14  Training loss = 0.7212  Test loss = 6.0872  Model updated 3 times  \n",
      "\n",
      "Test period = 15  Training loss = 1.0440  Test loss = 6.5773  Model updated 3 times  \n",
      "\n",
      "Test period = 16  Training loss = 1.3249  Test loss = 9.5003  Model updated 3 times  \n",
      "\n",
      "Test period = 17  Training loss = 0.6292  Test loss = 2.5764  Model updated 4 times  \n",
      "\n",
      "Test period = 18  Training loss = 0.7056  Test loss = 1.9493  Model updated 4 times  \n",
      "\n",
      "Test period = 19  Training loss = 0.7459  Test loss = 1.4247  Model updated 4 times  \n",
      "\n",
      "Test period = 20  Training loss = 0.7629  Test loss = 0.8821  Model updated 4 times  \n",
      "\n",
      "Test period = 21  Training loss = 0.4603  Test loss = 0.8868  Model updated 5 times  \n",
      "\n",
      "Test period = 22  Training loss = 0.4733  Test loss = 3.1411  Model updated 5 times  \n",
      "\n",
      "Test period = 23  Training loss = 0.6130  Test loss = 0.6091  Model updated 5 times  \n",
      "\n",
      "Test period = 24  Training loss = 0.6176  Test loss = 3.0796  Model updated 5 times  \n",
      "\n",
      "Test period = 25  Training loss = 0.5735  Test loss = 0.3432  Model updated 6 times  \n",
      "\n",
      "Test period = 26  Training loss = 0.5747  Test loss = 0.4013  Model updated 6 times  \n",
      "\n",
      "Test period = 27  Training loss = 0.5768  Test loss = 1.4883  Model updated 6 times  \n",
      "\n",
      "Test period = 28  Training loss = 0.6056  Test loss = 1.8256  Model updated 6 times  \n",
      "\n",
      "Test period = 29  Training loss = 0.4032  Test loss = 0.1122  Model updated 7 times  \n",
      "\n",
      "Test period = 30  Training loss = 0.4033  Test loss = 0.6541  Model updated 7 times  \n",
      "\n",
      "Test period = 31  Training loss = 0.4111  Test loss = 5.6090  Model updated 7 times  \n",
      "\n",
      "Test period = 32  Training loss = 0.8055  Test loss = 0.5158  Model updated 7 times  \n",
      "\n",
      "Test period = 33  Training loss = 0.4542  Test loss = 0.6667  Model updated 8 times  \n",
      "\n",
      "Test period = 34  Training loss = 0.4616  Test loss = 0.2509  Model updated 8 times  \n",
      "\n",
      "Test period = 35  Training loss = 0.4620  Test loss = 0.7936  Model updated 8 times  \n",
      "\n",
      "Test period = 36  Training loss = 0.4724  Test loss = 3.5982  Model updated 8 times  \n",
      "\n",
      "Test period = 37  Training loss = 0.5954  Test loss = 1.7772  Model updated 9 times  \n",
      "\n",
      "Test period = 38  Training loss = 0.6135  Test loss = 0.6781  Model updated 9 times  \n",
      "\n",
      "Test period = 39  Training loss = 0.6193  Test loss = 0.6362  Model updated 9 times  \n",
      "\n",
      "Test period = 40  Training loss = 0.6241  Test loss = 4.0992  Model updated 9 times  \n",
      "\n",
      "Test period = 41  Training loss = 0.6423  Test loss = 1.7507  Model updated 10 times  \n",
      "\n",
      "Test period = 42  Training loss = 0.6778  Test loss = 0.7234  Model updated 10 times  \n",
      "\n",
      "Test period = 43  Training loss = 0.6837  Test loss = 0.5973  Model updated 10 times  \n",
      "\n",
      "Test period = 44  Training loss = 0.6872  Test loss = 14.9880  Model updated 10 times  \n",
      "\n",
      "Test period = 45  Training loss = 1.9737  Test loss = 7.1438  Model updated 11 times  \n",
      "\n",
      "Test period = 46  Training loss = 2.1635  Test loss = 2.3263  Model updated 11 times  \n",
      "\n",
      "Test period = 47  Training loss = 2.1826  Test loss = 2.7225  Model updated 11 times  \n",
      "\n",
      "Test period = 48  Training loss = 2.2085  Test loss = 0.6318  Model updated 11 times  \n",
      "\n",
      "Test period = 49  Training loss = 1.0502  Test loss = 2.6235  Model updated 12 times  \n",
      "\n",
      "Test period = 50  Training loss = 1.0985  Test loss = 2.5632  Model updated 12 times  \n",
      "\n",
      "Test period = 51  Training loss = 1.1422  Test loss = 3.6484  Model updated 12 times  \n",
      "\n",
      "Test period = 52  Training loss = 1.2285  Test loss = 0.3436  Model updated 12 times  \n",
      "\n",
      "Test period = 53  Training loss = 0.9531  Test loss = 1.8940  Model updated 13 times  \n",
      "\n",
      "Test period = 54  Training loss = 0.9813  Test loss = 2.9155  Model updated 13 times  \n",
      "\n",
      "Test period = 55  Training loss = 1.0455  Test loss = 0.2179  Model updated 13 times  \n",
      "\n",
      "Test period = 56  Training loss = 1.0441  Test loss = 1.1344  Model updated 13 times  \n",
      "\n",
      "Test period = 57  Training loss = 0.8634  Test loss = 2.4476  Model updated 14 times  \n",
      "\n",
      "Test period = 58  Training loss = 0.9137  Test loss = 5.3719  Model updated 14 times  \n",
      "\n",
      "Test period = 59  Training loss = 1.1308  Test loss = 1.1279  Model updated 14 times  \n",
      "\n",
      "Test period = 60  Training loss = 1.1378  Test loss = 0.6677  Model updated 14 times  \n",
      "\n",
      "Test period = 61  Training loss = 0.8272  Test loss = 0.4905  Model updated 15 times  \n",
      "\n",
      "Test period = 62  Training loss = 0.8293  Test loss = 3.6214  Model updated 15 times  \n",
      "\n",
      "Test period = 63  Training loss = 0.9425  Test loss = 0.3976  Model updated 15 times  \n",
      "\n",
      "Test period = 64  Training loss = 0.9438  Test loss = 0.2587  Model updated 15 times  \n",
      "\n",
      "Test period = 65  Training loss = 0.7911  Test loss = 0.0599  Model updated 16 times  \n",
      "\n",
      "Test period = 66  Training loss = 0.7908  Test loss = 3.6004  Model updated 16 times  \n",
      "\n",
      "Test period = 67  Training loss = 0.9079  Test loss = 3.9590  Model updated 16 times  \n",
      "\n",
      "Test period = 68  Training loss = 1.0309  Test loss = 2.3424  Model updated 16 times  \n",
      "\n",
      "Test period = 69  Training loss = 0.8114  Test loss = 2.6995  Model updated 17 times  \n",
      "\n",
      "Test period = 70  Training loss = 0.8777  Test loss = 0.3659  Model updated 17 times  \n",
      "\n",
      "Test period = 71  Training loss = 0.8778  Test loss = 0.7125  Model updated 17 times  \n",
      "\n",
      "Test period = 72  Training loss = 0.8813  Test loss = 0.0889  Model updated 17 times  \n",
      "\n",
      "Test period = 73  Training loss = 0.6863  Test loss = 4.9168  Model updated 18 times  \n",
      "\n",
      "Test period = 74  Training loss = 0.9161  Test loss = 4.0254  Model updated 18 times  \n",
      "\n",
      "Test period = 75  Training loss = 1.0433  Test loss = 1.8036  Model updated 18 times  \n",
      "\n",
      "Test period = 76  Training loss = 1.0670  Test loss = 1.8494  Model updated 18 times  \n",
      "\n",
      "Test period = 77  Training loss = 0.7000  Test loss = 0.2737  Model updated 19 times  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "retrain_count = 0\n",
    "for t in range(len(test_target)):\n",
    "    x_test = np.reshape(test_features[t], newshape=(1,4,3))\n",
    "    y_test = test_target[t]\n",
    "    test_loss[t] = np.sqrt(sess.run(loss, feed_dict={x:x_test, y:y_test}))\n",
    "    yhat_update[t] = pred.eval(feed_dict={x:x_test})\n",
    "\n",
    "    x_train = all_features[t:(window_length+t)]\n",
    "    y_train = all_target[t:(window_length+t)]\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:x_test, y:y_test})\n",
    "    \n",
    "    print(\"Test period = {0:d}\".format(t+1),\n",
    "      \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "      \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "      \" Model updated {0:d} times\".format(retrain_count),\n",
    "      \" \\n\")\n",
    "\n",
    "    if (t+1)%4==0:\n",
    "        retrain_count += 1\n",
    "        for epoch in range(epoch_hat):\n",
    "            for i in range(total_batch):\n",
    "                optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nA8DMrKUcAGZmLeUAMDNrqf8Dk9sSA17RnsYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd2dab00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: updating scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_update, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating scheme RMSE: 3.27604935442 \n",
      "Updating scheme MAE:  2.27386221431\n"
     ]
    }
   ],
   "source": [
    "rmse_update = np.sqrt(np.mean((yhat_update-test_target)**2))\n",
    "mae_update = np.mean(np.abs((yhat_update-test_target)))\n",
    "print(\"Updating scheme RMSE:\", rmse_update,\n",
    "     \"\\nUpdating scheme MAE: \", mae_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + \"yhat_test_fixed.csv\", yhat_test_fixed)\n",
    "np.savetxt(MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + \"yhat_update.csv\", yhat_update)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
