{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Directories\n",
    "MODEL_FOLDER = \"../../../models/lstm/\"\n",
    "MODEL_FILENAME = MODEL_FOLDER + \"4Q/32_units/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: model saver\n",
    "def saveModel(sess, MODEL_FILENAME):\n",
    "    if not os.path.exists(MODEL_FOLDER):\n",
    "        print('Creating path where to save model: ' + MODEL_FOLDER)\n",
    "        os.mkdir(MODEL_FOLDER)\n",
    "\n",
    "    #print('Saving model at: ' + MODEL_FILENAME)\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, MODEL_FILENAME)\n",
    "    #print('Model successfully saved.\\n')\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: model loader\n",
    "def loadModel(sess, MODEL_FILENAME):\n",
    "    if os.path.exists(MODEL_FILENAME + \".index\"):\n",
    "        print('Loading save model from: ' + MODEL_FILENAME)\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, MODEL_FILENAME)\n",
    "        print('Model successfully loaded.\\n')\n",
    "        return True\n",
    "    else:\n",
    "        print('Model file <<' + MODEL_FILENAME + '>> does not exists!')\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Hyperparameters\n",
    "epochs = 500\n",
    "learning_rate = 1e-1\n",
    "batch_size = 5\n",
    "early_stop_iters = 10\n",
    "folds = 32\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 3  # data input\n",
    "n_steps = 4  # timesteps\n",
    "n_hidden = 32 # dimension of recurrent unit\n",
    "\n",
    "# (REPRODUCIBILITY) set random seeds\n",
    "tf.set_random_seed(123)\n",
    "\n",
    "# Define weights and biases\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.truncated_normal([n_hidden, 1], stddev = 1.0 / tf.sqrt(float(n_hidden))),\n",
    "        name='out_weight')\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.zeros([1]),\n",
    "        name='out_bias')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: Build model\n",
    "def RNN(X, weights, biases, n_hidden):\n",
    "\n",
    "    # Define a LSTM cell with tensorflow\n",
    "    lstm_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden, state_is_tuple=True)\n",
    "    outputs, _ = tf.nn.dynamic_rnn(lstm_cell, X, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    out_layer = tf.matmul(outputs[:,-1,:], weights['out']) + biases['out']\n",
    "\n",
    "    return out_layer\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: select batch\n",
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the data...\n",
      "Finished: data loaded. Stats below: \n",
      "Nr of training samples: 193\n",
      "Nr of testing  samples: 77\n",
      "Number of variables: 3\n",
      "Number of lags: 4\n",
      "Window length: 65\n",
      "Number of validation folds: 32\n"
     ]
    }
   ],
   "source": [
    "# =================================\n",
    "# 0. Load dataset\n",
    "# =================================\n",
    "print(\"Loading the data...\")\n",
    "# Training set pre-processing\n",
    "train = pd.read_csv('../../../Data/train.csv')\n",
    "train_4lag_inflation = np.array(train[['inflation.lag4',\n",
    "                                       'inflation.lag5',\n",
    "                                       'inflation.lag6',\n",
    "                                       'inflation.lag7']])\n",
    "train_4lag_unemp = np.array(train[['unemp.lag4',\n",
    "                                   'unemp.lag5',\n",
    "                                   'unemp.lag6',\n",
    "                                   'unemp.lag7']])\n",
    "train_4lag_oil = np.array(train[['oil.lag4',\n",
    "                                 'oil.lag5',\n",
    "                                 'oil.lag6',\n",
    "                                 'oil.lag7']])\n",
    "train_features = np.concatenate((train_4lag_inflation[:,:,np.newaxis], \n",
    "\t                             train_4lag_unemp[:,:,np.newaxis],\n",
    "\t                             train_4lag_oil[:,:,np.newaxis]),\n",
    "\t                             axis=2)\n",
    "train_target = np.array(train['inflation.target'])\n",
    "\n",
    "# Test set pre-processing\n",
    "test = pd.read_csv('../../../Data/test.csv')\n",
    "test_4lag_inflation = np.array(test[['inflation.lag4',\n",
    "                                     'inflation.lag5',\n",
    "                                     'inflation.lag6',\n",
    "                                     'inflation.lag7']])\n",
    "test_4lag_unemp = np.array(test[['unemp.lag4',\n",
    "                                 'unemp.lag5',\n",
    "                                 'unemp.lag6',\n",
    "                                 'unemp.lag7']])\n",
    "test_4lag_oil = np.array(test[['oil.lag4',\n",
    "                               'oil.lag5',\n",
    "                               'oil.lag6',\n",
    "                               'oil.lag7']])\n",
    "test_features = np.concatenate((test_4lag_inflation[:,:,np.newaxis], \n",
    "\t                            test_4lag_unemp[:,:,np.newaxis],\n",
    "\t                            test_4lag_oil[:,:,np.newaxis]),\n",
    "\t                            axis=2)\n",
    "test_target = np.array(test['inflation.target'])\n",
    "\n",
    "(nrTrainSamples, timesteps, variables) = train_features.shape\n",
    "(nrTestSamples, _, _) = test_features.shape\n",
    "\n",
    "# Window length and validation fold index\n",
    "window_length = 65\n",
    "valIndex = np.linspace(start=window_length, stop=nrTrainSamples, \n",
    "                       endpoint=True, num=folds+1, dtype=np.int)\n",
    "\n",
    "print(\"Finished: data loaded. Stats below: \")\n",
    "print(\"Nr of training samples: %d\" % nrTrainSamples)\n",
    "print(\"Nr of testing  samples: %d\" % nrTestSamples)\n",
    "print(\"Number of variables: %d\" % variables)\n",
    "print(\"Number of lags: %d\" % timesteps)\n",
    "print(\"Window length: %d\" % window_length)\n",
    "print(\"Number of validation folds: %d\" % folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 1. Build model\n",
    "# ==================================\n",
    "# tf graph input\n",
    "x = tf.placeholder(\"float\", [None, n_steps, n_input], name='Batch')\n",
    "y = tf.placeholder(\"float\", name='True_labels_of_batch')\n",
    "lr = tf.placeholder(\"float\", name='Learning_rate')\n",
    "\n",
    "# Make predictions with the model\n",
    "pred = RNN(x, weights, biases, n_hidden)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss = tf.reduce_mean(tf.diag_part(tf.square(tf.subtract(x=pred, y=y))))\n",
    "optimizer = tf.train.GradientDescentOptimizer(lr).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training \n",
      "Hyperparameters: \n",
      "Dimension of recurrent unit = 32 \n",
      "Learning rate = 0.1 \n",
      "Epochs = 500 \n",
      "Batch size = 5 \n",
      "Early stopping epochs = 10 \n",
      "Learning rate = 0.1\n",
      "Fold: 1  Epoch: 1  Training loss = 2.4033  Validation loss = 1.8084  \n",
      "\n",
      "Fold: 1  Epoch: 2  Training loss = 4.8784  Validation loss = 2.9836  \n",
      "\n",
      "Fold: 1  Epoch: 3  Training loss = 2.6180  Validation loss = 1.9858  \n",
      "\n",
      "Fold: 1  Epoch: 4  Training loss = 2.3401  Validation loss = 1.9939  \n",
      "\n",
      "Fold: 1  Epoch: 5  Training loss = 2.2640  Validation loss = 2.2436  \n",
      "\n",
      "Fold: 1  Epoch: 6  Training loss = 2.3172  Validation loss = 2.5302  \n",
      "\n",
      "Fold: 1  Epoch: 7  Training loss = 2.2378  Validation loss = 2.4766  \n",
      "\n",
      "Fold: 1  Epoch: 8  Training loss = 2.2994  Validation loss = 2.0972  \n",
      "\n",
      "Fold: 1  Epoch: 9  Training loss = 2.2337  Validation loss = 1.8161  \n",
      "\n",
      "Fold: 1  Epoch: 10  Training loss = 2.2407  Validation loss = 2.1223  \n",
      "\n",
      "Fold: 1  Epoch: 11  Training loss = 2.1737  Validation loss = 2.0731  \n",
      "\n",
      "Fold: 1  Epoch: 12  Training loss = 2.2528  Validation loss = 1.6989  \n",
      "\n",
      "Fold: 1  Epoch: 13  Training loss = 5.2303  Validation loss = 1.0663  \n",
      "\n",
      "Fold: 1  Epoch: 14  Training loss = 4.4118  Validation loss = 0.9224  \n",
      "\n",
      "Fold: 1  Epoch: 15  Training loss = 2.2328  Validation loss = 1.6184  \n",
      "\n",
      "Fold: 1  Epoch: 16  Training loss = 2.2784  Validation loss = 2.3506  \n",
      "\n",
      "Fold: 1  Epoch: 17  Training loss = 3.5561  Validation loss = 0.6251  \n",
      "\n",
      "Fold: 1  Epoch: 18  Training loss = 2.1952  Validation loss = 2.3180  \n",
      "\n",
      "Fold: 1  Epoch: 19  Training loss = 2.1855  Validation loss = 2.6914  \n",
      "\n",
      "Check model:  Fold: 1  Optimal epoch: 17  \n",
      "\n",
      "Fold: 2  Epoch: 1  Training loss = 2.1893  Validation loss = 2.3679  \n",
      "\n",
      "Fold: 2  Epoch: 2  Training loss = 2.0755  Validation loss = 1.8864  \n",
      "\n",
      "Fold: 2  Epoch: 3  Training loss = 2.1145  Validation loss = 1.9935  \n",
      "\n",
      "Fold: 2  Epoch: 4  Training loss = 2.3373  Validation loss = 1.6919  \n",
      "\n",
      "Fold: 2  Epoch: 5  Training loss = 2.3094  Validation loss = 2.4026  \n",
      "\n",
      "Fold: 2  Epoch: 6  Training loss = 2.0430  Validation loss = 1.9186  \n",
      "\n",
      "Fold: 2  Epoch: 7  Training loss = 2.3460  Validation loss = 1.8672  \n",
      "\n",
      "Fold: 2  Epoch: 8  Training loss = 2.1029  Validation loss = 1.8647  \n",
      "\n",
      "Fold: 2  Epoch: 9  Training loss = 2.0600  Validation loss = 1.8458  \n",
      "\n",
      "Fold: 2  Epoch: 10  Training loss = 2.1401  Validation loss = 1.8517  \n",
      "\n",
      "Fold: 2  Epoch: 11  Training loss = 2.2630  Validation loss = 2.4013  \n",
      "\n",
      "Fold: 2  Epoch: 12  Training loss = 2.1126  Validation loss = 1.7296  \n",
      "\n",
      "Fold: 2  Epoch: 13  Training loss = 2.1381  Validation loss = 1.9041  \n",
      "\n",
      "Fold: 2  Epoch: 14  Training loss = 2.6235  Validation loss = 1.7065  \n",
      "\n",
      "Fold: 2  Epoch: 15  Training loss = 2.8928  Validation loss = 1.9147  \n",
      "\n",
      "Fold: 2  Epoch: 16  Training loss = 2.1623  Validation loss = 1.9214  \n",
      "\n",
      "Fold: 2  Epoch: 17  Training loss = 2.0828  Validation loss = 2.0380  \n",
      "\n",
      "Fold: 2  Epoch: 18  Training loss = 2.0849  Validation loss = 1.9174  \n",
      "\n",
      "Fold: 2  Epoch: 19  Training loss = 2.1150  Validation loss = 1.9323  \n",
      "\n",
      "Fold: 2  Epoch: 20  Training loss = 2.0103  Validation loss = 1.9716  \n",
      "\n",
      "Fold: 2  Epoch: 21  Training loss = 2.0274  Validation loss = 1.7101  \n",
      "\n",
      "Fold: 2  Epoch: 22  Training loss = 2.1480  Validation loss = 1.9507  \n",
      "\n",
      "Fold: 2  Epoch: 23  Training loss = 2.1633  Validation loss = 1.6999  \n",
      "\n",
      "Fold: 2  Epoch: 24  Training loss = 1.9816  Validation loss = 1.9320  \n",
      "\n",
      "Fold: 2  Epoch: 25  Training loss = 1.9924  Validation loss = 1.8648  \n",
      "\n",
      "Fold: 2  Epoch: 26  Training loss = 2.1187  Validation loss = 2.0424  \n",
      "\n",
      "Check model:  Fold: 2  Optimal epoch: 4  \n",
      "\n",
      "Fold: 3  Epoch: 1  Training loss = 1.2815  Validation loss = 3.4148  \n",
      "\n",
      "Fold: 3  Epoch: 2  Training loss = 1.2355  Validation loss = 3.1254  \n",
      "\n",
      "Fold: 3  Epoch: 3  Training loss = 1.2008  Validation loss = 3.0797  \n",
      "\n",
      "Fold: 3  Epoch: 4  Training loss = 1.2055  Validation loss = 3.1303  \n",
      "\n",
      "Fold: 3  Epoch: 5  Training loss = 1.2034  Validation loss = 2.8508  \n",
      "\n",
      "Fold: 3  Epoch: 6  Training loss = 1.1761  Validation loss = 2.7851  \n",
      "\n",
      "Fold: 3  Epoch: 7  Training loss = 1.1674  Validation loss = 2.8908  \n",
      "\n",
      "Fold: 3  Epoch: 8  Training loss = 1.1593  Validation loss = 3.1459  \n",
      "\n",
      "Fold: 3  Epoch: 9  Training loss = 1.1505  Validation loss = 3.0406  \n",
      "\n",
      "Fold: 3  Epoch: 10  Training loss = 1.1055  Validation loss = 3.0324  \n",
      "\n",
      "Fold: 3  Epoch: 11  Training loss = 1.1789  Validation loss = 2.5666  \n",
      "\n",
      "Fold: 3  Epoch: 12  Training loss = 1.1292  Validation loss = 3.0420  \n",
      "\n",
      "Fold: 3  Epoch: 13  Training loss = 1.1299  Validation loss = 3.0523  \n",
      "\n",
      "Fold: 3  Epoch: 14  Training loss = 1.1136  Validation loss = 2.8524  \n",
      "\n",
      "Fold: 3  Epoch: 15  Training loss = 1.0897  Validation loss = 2.8902  \n",
      "\n",
      "Fold: 3  Epoch: 16  Training loss = 1.2039  Validation loss = 3.3209  \n",
      "\n",
      "Check model:  Fold: 3  Optimal epoch: 11  \n",
      "\n",
      "Fold: 4  Epoch: 1  Training loss = 1.3872  Validation loss = 3.0676  \n",
      "\n",
      "Fold: 4  Epoch: 2  Training loss = 1.2387  Validation loss = 3.0487  \n",
      "\n",
      "Fold: 4  Epoch: 3  Training loss = 1.1549  Validation loss = 3.0783  \n",
      "\n",
      "Fold: 4  Epoch: 4  Training loss = 1.1991  Validation loss = 2.9497  \n",
      "\n",
      "Fold: 4  Epoch: 5  Training loss = 1.1560  Validation loss = 3.1121  \n",
      "\n",
      "Fold: 4  Epoch: 6  Training loss = 1.2426  Validation loss = 3.1417  \n",
      "\n",
      "Fold: 4  Epoch: 7  Training loss = 1.1279  Validation loss = 3.0905  \n",
      "\n",
      "Fold: 4  Epoch: 8  Training loss = 1.1521  Validation loss = 2.8134  \n",
      "\n",
      "Fold: 4  Epoch: 9  Training loss = 1.1082  Validation loss = 2.3902  \n",
      "\n",
      "Fold: 4  Epoch: 10  Training loss = 1.0186  Validation loss = 2.4361  \n",
      "\n",
      "Fold: 4  Epoch: 11  Training loss = 1.0494  Validation loss = 2.1174  \n",
      "\n",
      "Fold: 4  Epoch: 12  Training loss = 1.0392  Validation loss = 3.0117  \n",
      "\n",
      "Fold: 4  Epoch: 13  Training loss = 1.0049  Validation loss = 2.8245  \n",
      "\n",
      "Fold: 4  Epoch: 14  Training loss = 1.0387  Validation loss = 3.3270  \n",
      "\n",
      "Check model:  Fold: 4  Optimal epoch: 11  \n",
      "\n",
      "Fold: 5  Epoch: 1  Training loss = 1.3059  Validation loss = 3.6529  \n",
      "\n",
      "Fold: 5  Epoch: 2  Training loss = 1.0836  Validation loss = 2.0395  \n",
      "\n",
      "Fold: 5  Epoch: 3  Training loss = 1.0499  Validation loss = 1.9513  \n",
      "\n",
      "Fold: 5  Epoch: 4  Training loss = 1.0952  Validation loss = 2.1385  \n",
      "\n",
      "Fold: 5  Epoch: 5  Training loss = 1.0161  Validation loss = 1.4897  \n",
      "\n",
      "Fold: 5  Epoch: 6  Training loss = 1.0553  Validation loss = 1.6165  \n",
      "\n",
      "Fold: 5  Epoch: 7  Training loss = 1.6764  Validation loss = 1.2876  \n",
      "\n",
      "Fold: 5  Epoch: 8  Training loss = 0.9905  Validation loss = 1.4594  \n",
      "\n",
      "Fold: 5  Epoch: 9  Training loss = 0.9853  Validation loss = 1.3933  \n",
      "\n",
      "Fold: 5  Epoch: 10  Training loss = 0.9751  Validation loss = 1.5264  \n",
      "\n",
      "Fold: 5  Epoch: 11  Training loss = 0.9867  Validation loss = 1.7213  \n",
      "\n",
      "Fold: 5  Epoch: 12  Training loss = 0.9908  Validation loss = 1.4338  \n",
      "\n",
      "Fold: 5  Epoch: 13  Training loss = 1.0536  Validation loss = 1.7113  \n",
      "\n",
      "Fold: 5  Epoch: 14  Training loss = 1.0437  Validation loss = 1.4781  \n",
      "\n",
      "Fold: 5  Epoch: 15  Training loss = 0.9832  Validation loss = 1.5204  \n",
      "\n",
      "Fold: 5  Epoch: 16  Training loss = 1.0127  Validation loss = 1.4323  \n",
      "\n",
      "Fold: 5  Epoch: 17  Training loss = 0.9146  Validation loss = 1.3844  \n",
      "\n",
      "Fold: 5  Epoch: 18  Training loss = 1.4022  Validation loss = 1.2168  \n",
      "\n",
      "Fold: 5  Epoch: 19  Training loss = 0.9321  Validation loss = 1.3884  \n",
      "\n",
      "Fold: 5  Epoch: 20  Training loss = 0.9476  Validation loss = 1.2974  \n",
      "\n",
      "Fold: 5  Epoch: 21  Training loss = 0.9891  Validation loss = 1.0693  \n",
      "\n",
      "Fold: 5  Epoch: 22  Training loss = 0.9951  Validation loss = 1.4139  \n",
      "\n",
      "Fold: 5  Epoch: 23  Training loss = 0.9429  Validation loss = 1.1105  \n",
      "\n",
      "Fold: 5  Epoch: 24  Training loss = 0.9902  Validation loss = 1.6135  \n",
      "\n",
      "Check model:  Fold: 5  Optimal epoch: 21  \n",
      "\n",
      "Fold: 6  Epoch: 1  Training loss = 0.9464  Validation loss = 1.8349  \n",
      "\n",
      "Fold: 6  Epoch: 2  Training loss = 0.9791  Validation loss = 1.7001  \n",
      "\n",
      "Fold: 6  Epoch: 3  Training loss = 0.9661  Validation loss = 2.0048  \n",
      "\n",
      "Fold: 6  Epoch: 4  Training loss = 0.9190  Validation loss = 2.0642  \n",
      "\n",
      "Fold: 6  Epoch: 5  Training loss = 0.9179  Validation loss = 1.9095  \n",
      "\n",
      "Fold: 6  Epoch: 6  Training loss = 0.9395  Validation loss = 2.1670  \n",
      "\n",
      "Fold: 6  Epoch: 7  Training loss = 0.9047  Validation loss = 2.3052  \n",
      "\n",
      "Fold: 6  Epoch: 8  Training loss = 1.0006  Validation loss = 1.9528  \n",
      "\n",
      "Fold: 6  Epoch: 9  Training loss = 0.8474  Validation loss = 2.0666  \n",
      "\n",
      "Fold: 6  Epoch: 10  Training loss = 0.9002  Validation loss = 2.0335  \n",
      "\n",
      "Fold: 6  Epoch: 11  Training loss = 0.9521  Validation loss = 1.8172  \n",
      "\n",
      "Fold: 6  Epoch: 12  Training loss = 1.0254  Validation loss = 2.3576  \n",
      "\n",
      "Check model:  Fold: 6  Optimal epoch: 2  \n",
      "\n",
      "Fold: 7  Epoch: 1  Training loss = 1.0210  Validation loss = 2.2435  \n",
      "\n",
      "Fold: 7  Epoch: 2  Training loss = 0.9880  Validation loss = 2.0352  \n",
      "\n",
      "Fold: 7  Epoch: 3  Training loss = 0.9044  Validation loss = 1.8047  \n",
      "\n",
      "Fold: 7  Epoch: 4  Training loss = 0.9210  Validation loss = 2.0164  \n",
      "\n",
      "Fold: 7  Epoch: 5  Training loss = 0.9217  Validation loss = 1.9113  \n",
      "\n",
      "Fold: 7  Epoch: 6  Training loss = 0.9622  Validation loss = 2.3315  \n",
      "\n",
      "Fold: 7  Epoch: 7  Training loss = 0.9129  Validation loss = 1.8654  \n",
      "\n",
      "Fold: 7  Epoch: 8  Training loss = 0.9071  Validation loss = 2.0333  \n",
      "\n",
      "Fold: 7  Epoch: 9  Training loss = 0.8868  Validation loss = 2.1738  \n",
      "\n",
      "Fold: 7  Epoch: 10  Training loss = 0.8818  Validation loss = 1.9608  \n",
      "\n",
      "Fold: 7  Epoch: 11  Training loss = 0.9249  Validation loss = 2.1472  \n",
      "\n",
      "Fold: 7  Epoch: 12  Training loss = 0.8935  Validation loss = 2.2515  \n",
      "\n",
      "Fold: 7  Epoch: 13  Training loss = 0.8773  Validation loss = 1.9972  \n",
      "\n",
      "Fold: 7  Epoch: 14  Training loss = 0.8510  Validation loss = 2.1155  \n",
      "\n",
      "Fold: 7  Epoch: 15  Training loss = 0.8798  Validation loss = 2.1539  \n",
      "\n",
      "Fold: 7  Epoch: 16  Training loss = 0.8983  Validation loss = 2.0903  \n",
      "\n",
      "Fold: 7  Epoch: 17  Training loss = 0.8846  Validation loss = 1.7619  \n",
      "\n",
      "Fold: 7  Epoch: 18  Training loss = 0.8910  Validation loss = 1.8238  \n",
      "\n",
      "Fold: 7  Epoch: 19  Training loss = 0.9140  Validation loss = 2.1682  \n",
      "\n",
      "Fold: 7  Epoch: 20  Training loss = 0.9228  Validation loss = 2.4140  \n",
      "\n",
      "Check model:  Fold: 7  Optimal epoch: 17  \n",
      "\n",
      "Fold: 8  Epoch: 1  Training loss = 1.0838  Validation loss = 7.3731  \n",
      "\n",
      "Fold: 8  Epoch: 2  Training loss = 0.9284  Validation loss = 7.4036  \n",
      "\n",
      "Fold: 8  Epoch: 3  Training loss = 1.0201  Validation loss = 7.0842  \n",
      "\n",
      "Fold: 8  Epoch: 4  Training loss = 0.9498  Validation loss = 7.3904  \n",
      "\n",
      "Fold: 8  Epoch: 5  Training loss = 0.9349  Validation loss = 7.5042  \n",
      "\n",
      "Fold: 8  Epoch: 6  Training loss = 1.0365  Validation loss = 7.2851  \n",
      "\n",
      "Fold: 8  Epoch: 7  Training loss = 0.9201  Validation loss = 7.3428  \n",
      "\n",
      "Fold: 8  Epoch: 8  Training loss = 0.9920  Validation loss = 7.5357  \n",
      "\n",
      "Fold: 8  Epoch: 9  Training loss = 0.9487  Validation loss = 7.6112  \n",
      "\n",
      "Fold: 8  Epoch: 10  Training loss = 0.9166  Validation loss = 7.2672  \n",
      "\n",
      "Fold: 8  Epoch: 11  Training loss = 0.9166  Validation loss = 7.0482  \n",
      "\n",
      "Fold: 8  Epoch: 12  Training loss = 0.9361  Validation loss = 7.0129  \n",
      "\n",
      "Fold: 8  Epoch: 13  Training loss = 0.8759  Validation loss = 7.2475  \n",
      "\n",
      "Fold: 8  Epoch: 14  Training loss = 0.9203  Validation loss = 6.9589  \n",
      "\n",
      "Fold: 8  Epoch: 15  Training loss = 0.9289  Validation loss = 7.3666  \n",
      "\n",
      "Fold: 8  Epoch: 16  Training loss = 0.8778  Validation loss = 6.9936  \n",
      "\n",
      "Fold: 8  Epoch: 17  Training loss = 0.8609  Validation loss = 7.0919  \n",
      "\n",
      "Fold: 8  Epoch: 18  Training loss = 0.8843  Validation loss = 7.1495  \n",
      "\n",
      "Fold: 8  Epoch: 19  Training loss = 0.8764  Validation loss = 7.2907  \n",
      "\n",
      "Fold: 8  Epoch: 20  Training loss = 0.8507  Validation loss = 7.3171  \n",
      "\n",
      "Fold: 8  Epoch: 21  Training loss = 0.8492  Validation loss = 7.2033  \n",
      "\n",
      "Fold: 8  Epoch: 22  Training loss = 0.8610  Validation loss = 7.1577  \n",
      "\n",
      "Fold: 8  Epoch: 23  Training loss = 0.9720  Validation loss = 7.3880  \n",
      "\n",
      "Check model:  Fold: 8  Optimal epoch: 14  \n",
      "\n",
      "Fold: 9  Epoch: 1  Training loss = 1.7398  Validation loss = 7.1803  \n",
      "\n",
      "Fold: 9  Epoch: 2  Training loss = 1.7268  Validation loss = 7.6972  \n",
      "\n",
      "Fold: 9  Epoch: 3  Training loss = 1.6064  Validation loss = 7.4248  \n",
      "\n",
      "Fold: 9  Epoch: 4  Training loss = 1.7375  Validation loss = 7.7087  \n",
      "\n",
      "Fold: 9  Epoch: 5  Training loss = 1.4291  Validation loss = 7.3027  \n",
      "\n",
      "Fold: 9  Epoch: 6  Training loss = 1.3889  Validation loss = 7.1752  \n",
      "\n",
      "Fold: 9  Epoch: 7  Training loss = 1.3603  Validation loss = 7.1355  \n",
      "\n",
      "Fold: 9  Epoch: 8  Training loss = 1.5758  Validation loss = 7.3803  \n",
      "\n",
      "Fold: 9  Epoch: 9  Training loss = 1.3276  Validation loss = 6.9970  \n",
      "\n",
      "Fold: 9  Epoch: 10  Training loss = 1.3642  Validation loss = 6.8346  \n",
      "\n",
      "Fold: 9  Epoch: 11  Training loss = 1.5762  Validation loss = 7.2601  \n",
      "\n",
      "Fold: 9  Epoch: 12  Training loss = 1.5181  Validation loss = 7.1026  \n",
      "\n",
      "Fold: 9  Epoch: 13  Training loss = 1.2951  Validation loss = 6.9125  \n",
      "\n",
      "Fold: 9  Epoch: 14  Training loss = 1.3111  Validation loss = 6.7759  \n",
      "\n",
      "Fold: 9  Epoch: 15  Training loss = 1.3118  Validation loss = 6.6058  \n",
      "\n",
      "Fold: 9  Epoch: 16  Training loss = 1.2790  Validation loss = 6.4506  \n",
      "\n",
      "Fold: 9  Epoch: 17  Training loss = 1.2977  Validation loss = 6.5977  \n",
      "\n",
      "Fold: 9  Epoch: 18  Training loss = 1.2802  Validation loss = 6.5517  \n",
      "\n",
      "Fold: 9  Epoch: 19  Training loss = 1.5393  Validation loss = 6.9638  \n",
      "\n",
      "Fold: 9  Epoch: 20  Training loss = 1.5455  Validation loss = 6.2473  \n",
      "\n",
      "Fold: 9  Epoch: 21  Training loss = 1.3297  Validation loss = 6.4406  \n",
      "\n",
      "Fold: 9  Epoch: 22  Training loss = 1.2337  Validation loss = 6.5507  \n",
      "\n",
      "Fold: 9  Epoch: 23  Training loss = 1.2532  Validation loss = 6.4217  \n",
      "\n",
      "Fold: 9  Epoch: 24  Training loss = 1.3549  Validation loss = 6.8046  \n",
      "\n",
      "Fold: 9  Epoch: 25  Training loss = 1.2058  Validation loss = 6.5980  \n",
      "\n",
      "Fold: 9  Epoch: 26  Training loss = 1.1343  Validation loss = 6.2059  \n",
      "\n",
      "Fold: 9  Epoch: 27  Training loss = 1.2975  Validation loss = 6.1686  \n",
      "\n",
      "Fold: 9  Epoch: 28  Training loss = 1.1493  Validation loss = 5.7942  \n",
      "\n",
      "Fold: 9  Epoch: 29  Training loss = 1.0572  Validation loss = 6.2252  \n",
      "\n",
      "Fold: 9  Epoch: 30  Training loss = 1.0989  Validation loss = 6.1781  \n",
      "\n",
      "Fold: 9  Epoch: 31  Training loss = 1.0597  Validation loss = 5.7206  \n",
      "\n",
      "Fold: 9  Epoch: 32  Training loss = 1.1458  Validation loss = 5.6856  \n",
      "\n",
      "Fold: 9  Epoch: 33  Training loss = 1.1145  Validation loss = 5.8240  \n",
      "\n",
      "Fold: 9  Epoch: 34  Training loss = 1.0949  Validation loss = 6.1560  \n",
      "\n",
      "Fold: 9  Epoch: 35  Training loss = 1.0594  Validation loss = 5.7994  \n",
      "\n",
      "Fold: 9  Epoch: 36  Training loss = 1.0243  Validation loss = 6.1125  \n",
      "\n",
      "Fold: 9  Epoch: 37  Training loss = 1.0302  Validation loss = 6.0826  \n",
      "\n",
      "Fold: 9  Epoch: 38  Training loss = 1.0072  Validation loss = 6.1208  \n",
      "\n",
      "Fold: 9  Epoch: 39  Training loss = 1.0189  Validation loss = 6.2528  \n",
      "\n",
      "Check model:  Fold: 9  Optimal epoch: 32  \n",
      "\n",
      "Fold: 10  Epoch: 1  Training loss = 1.7314  Validation loss = 4.2804  \n",
      "\n",
      "Fold: 10  Epoch: 2  Training loss = 1.5735  Validation loss = 3.9880  \n",
      "\n",
      "Fold: 10  Epoch: 3  Training loss = 1.6257  Validation loss = 5.3238  \n",
      "\n",
      "Fold: 10  Epoch: 4  Training loss = 2.0254  Validation loss = 5.1129  \n",
      "\n",
      "Fold: 10  Epoch: 5  Training loss = 1.8052  Validation loss = 5.3954  \n",
      "\n",
      "Fold: 10  Epoch: 6  Training loss = 2.0625  Validation loss = 5.0284  \n",
      "\n",
      "Fold: 10  Epoch: 7  Training loss = 1.9937  Validation loss = 3.7685  \n",
      "\n",
      "Fold: 10  Epoch: 8  Training loss = 1.7959  Validation loss = 4.9871  \n",
      "\n",
      "Fold: 10  Epoch: 9  Training loss = 1.7500  Validation loss = 4.7752  \n",
      "\n",
      "Fold: 10  Epoch: 10  Training loss = 1.7453  Validation loss = 4.6785  \n",
      "\n",
      "Fold: 10  Epoch: 11  Training loss = 1.5968  Validation loss = 4.3604  \n",
      "\n",
      "Fold: 10  Epoch: 12  Training loss = 1.6029  Validation loss = 4.1633  \n",
      "\n",
      "Fold: 10  Epoch: 13  Training loss = 1.7618  Validation loss = 3.7629  \n",
      "\n",
      "Fold: 10  Epoch: 14  Training loss = 1.7128  Validation loss = 4.4726  \n",
      "\n",
      "Fold: 10  Epoch: 15  Training loss = 1.6987  Validation loss = 4.8490  \n",
      "\n",
      "Fold: 10  Epoch: 16  Training loss = 2.0408  Validation loss = 3.9669  \n",
      "\n",
      "Fold: 10  Epoch: 17  Training loss = 1.7269  Validation loss = 4.6076  \n",
      "\n",
      "Fold: 10  Epoch: 18  Training loss = 1.6746  Validation loss = 5.3207  \n",
      "\n",
      "Check model:  Fold: 10  Optimal epoch: 13  \n",
      "\n",
      "Fold: 11  Epoch: 1  Training loss = 1.9253  Validation loss = 2.7365  \n",
      "\n",
      "Fold: 11  Epoch: 2  Training loss = 1.8608  Validation loss = 2.0381  \n",
      "\n",
      "Fold: 11  Epoch: 3  Training loss = 2.1405  Validation loss = 2.0124  \n",
      "\n",
      "Fold: 11  Epoch: 4  Training loss = 1.5253  Validation loss = 3.1252  \n",
      "\n",
      "Fold: 11  Epoch: 5  Training loss = 1.3634  Validation loss = 2.7348  \n",
      "\n",
      "Fold: 11  Epoch: 6  Training loss = 1.3806  Validation loss = 3.0838  \n",
      "\n",
      "Fold: 11  Epoch: 7  Training loss = 1.3332  Validation loss = 3.2867  \n",
      "\n",
      "Fold: 11  Epoch: 8  Training loss = 1.3526  Validation loss = 4.0097  \n",
      "\n",
      "Fold: 11  Epoch: 9  Training loss = 1.3837  Validation loss = 3.1302  \n",
      "\n",
      "Fold: 11  Epoch: 10  Training loss = 1.3765  Validation loss = 2.4803  \n",
      "\n",
      "Fold: 11  Epoch: 11  Training loss = 1.2464  Validation loss = 2.9127  \n",
      "\n",
      "Fold: 11  Epoch: 12  Training loss = 1.4039  Validation loss = 3.6159  \n",
      "\n",
      "Fold: 11  Epoch: 13  Training loss = 1.3515  Validation loss = 2.6989  \n",
      "\n",
      "Fold: 11  Epoch: 14  Training loss = 1.3257  Validation loss = 2.7091  \n",
      "\n",
      "Fold: 11  Epoch: 15  Training loss = 1.5100  Validation loss = 3.6741  \n",
      "\n",
      "Fold: 11  Epoch: 16  Training loss = 1.3166  Validation loss = 2.8074  \n",
      "\n",
      "Fold: 11  Epoch: 17  Training loss = 1.5570  Validation loss = 2.3858  \n",
      "\n",
      "Fold: 11  Epoch: 18  Training loss = 1.3436  Validation loss = 2.5740  \n",
      "\n",
      "Fold: 11  Epoch: 19  Training loss = 1.3944  Validation loss = 3.5051  \n",
      "\n",
      "Fold: 11  Epoch: 20  Training loss = 1.2580  Validation loss = 2.9722  \n",
      "\n",
      "Fold: 11  Epoch: 21  Training loss = 1.4989  Validation loss = 2.6694  \n",
      "\n",
      "Fold: 11  Epoch: 22  Training loss = 1.3318  Validation loss = 2.7382  \n",
      "\n",
      "Fold: 11  Epoch: 23  Training loss = 1.3837  Validation loss = 2.4796  \n",
      "\n",
      "Fold: 11  Epoch: 24  Training loss = 1.3553  Validation loss = 3.3446  \n",
      "\n",
      "Fold: 11  Epoch: 25  Training loss = 1.3185  Validation loss = 3.9858  \n",
      "\n",
      "Check model:  Fold: 11  Optimal epoch: 3  \n",
      "\n",
      "Fold: 12  Epoch: 1  Training loss = 1.4781  Validation loss = 3.6736  \n",
      "\n",
      "Fold: 12  Epoch: 2  Training loss = 1.9237  Validation loss = 2.1242  \n",
      "\n",
      "Fold: 12  Epoch: 3  Training loss = 1.3915  Validation loss = 1.7853  \n",
      "\n",
      "Fold: 12  Epoch: 4  Training loss = 1.9050  Validation loss = 3.8158  \n",
      "\n",
      "Fold: 12  Epoch: 5  Training loss = 1.3990  Validation loss = 3.1909  \n",
      "\n",
      "Fold: 12  Epoch: 6  Training loss = 1.2938  Validation loss = 2.9571  \n",
      "\n",
      "Fold: 12  Epoch: 7  Training loss = 1.3037  Validation loss = 2.8155  \n",
      "\n",
      "Fold: 12  Epoch: 8  Training loss = 1.4545  Validation loss = 3.1953  \n",
      "\n",
      "Fold: 12  Epoch: 9  Training loss = 1.5140  Validation loss = 2.4010  \n",
      "\n",
      "Fold: 12  Epoch: 10  Training loss = 1.5016  Validation loss = 2.7697  \n",
      "\n",
      "Fold: 12  Epoch: 11  Training loss = 1.4715  Validation loss = 3.1263  \n",
      "\n",
      "Fold: 12  Epoch: 12  Training loss = 1.3211  Validation loss = 2.3485  \n",
      "\n",
      "Fold: 12  Epoch: 13  Training loss = 1.2782  Validation loss = 2.3412  \n",
      "\n",
      "Fold: 12  Epoch: 14  Training loss = 1.3131  Validation loss = 2.5243  \n",
      "\n",
      "Fold: 12  Epoch: 15  Training loss = 1.3408  Validation loss = 2.8042  \n",
      "\n",
      "Fold: 12  Epoch: 16  Training loss = 1.2480  Validation loss = 2.3791  \n",
      "\n",
      "Fold: 12  Epoch: 17  Training loss = 1.3319  Validation loss = 2.6631  \n",
      "\n",
      "Fold: 12  Epoch: 18  Training loss = 1.2253  Validation loss = 2.3350  \n",
      "\n",
      "Fold: 12  Epoch: 19  Training loss = 1.2215  Validation loss = 3.1516  \n",
      "\n",
      "Check model:  Fold: 12  Optimal epoch: 3  \n",
      "\n",
      "Fold: 13  Epoch: 1  Training loss = 1.3989  Validation loss = 6.4115  \n",
      "\n",
      "Fold: 13  Epoch: 2  Training loss = 1.3462  Validation loss = 6.0612  \n",
      "\n",
      "Fold: 13  Epoch: 3  Training loss = 1.3569  Validation loss = 5.8816  \n",
      "\n",
      "Fold: 13  Epoch: 4  Training loss = 1.2490  Validation loss = 4.4969  \n",
      "\n",
      "Fold: 13  Epoch: 5  Training loss = 1.2301  Validation loss = 4.6057  \n",
      "\n",
      "Fold: 13  Epoch: 6  Training loss = 1.4246  Validation loss = 4.6125  \n",
      "\n",
      "Fold: 13  Epoch: 7  Training loss = 1.3877  Validation loss = 4.6010  \n",
      "\n",
      "Fold: 13  Epoch: 8  Training loss = 1.2878  Validation loss = 3.6007  \n",
      "\n",
      "Fold: 13  Epoch: 9  Training loss = 1.2956  Validation loss = 3.7051  \n",
      "\n",
      "Fold: 13  Epoch: 10  Training loss = 1.2690  Validation loss = 4.4467  \n",
      "\n",
      "Fold: 13  Epoch: 11  Training loss = 1.2409  Validation loss = 2.9588  \n",
      "\n",
      "Fold: 13  Epoch: 12  Training loss = 1.2703  Validation loss = 4.2087  \n",
      "\n",
      "Fold: 13  Epoch: 13  Training loss = 1.2232  Validation loss = 4.4397  \n",
      "\n",
      "Fold: 13  Epoch: 14  Training loss = 1.2183  Validation loss = 3.8095  \n",
      "\n",
      "Fold: 13  Epoch: 15  Training loss = 1.3035  Validation loss = 3.7899  \n",
      "\n",
      "Fold: 13  Epoch: 16  Training loss = 1.4685  Validation loss = 4.3766  \n",
      "\n",
      "Fold: 13  Epoch: 17  Training loss = 1.5876  Validation loss = 2.9029  \n",
      "\n",
      "Fold: 13  Epoch: 18  Training loss = 1.3875  Validation loss = 3.6700  \n",
      "\n",
      "Fold: 13  Epoch: 19  Training loss = 1.2968  Validation loss = 3.2967  \n",
      "\n",
      "Fold: 13  Epoch: 20  Training loss = 1.4518  Validation loss = 3.6623  \n",
      "\n",
      "Fold: 13  Epoch: 21  Training loss = 1.2862  Validation loss = 5.0286  \n",
      "\n",
      "Check model:  Fold: 13  Optimal epoch: 17  \n",
      "\n",
      "Fold: 14  Epoch: 1  Training loss = 1.5502  Validation loss = 6.2025  \n",
      "\n",
      "Fold: 14  Epoch: 2  Training loss = 2.3903  Validation loss = 5.0198  \n",
      "\n",
      "Fold: 14  Epoch: 3  Training loss = 1.6538  Validation loss = 7.7273  \n",
      "\n",
      "Fold: 14  Epoch: 4  Training loss = 1.5099  Validation loss = 6.8988  \n",
      "\n",
      "Fold: 14  Epoch: 5  Training loss = 1.6134  Validation loss = 6.4003  \n",
      "\n",
      "Fold: 14  Epoch: 6  Training loss = 1.5781  Validation loss = 5.3863  \n",
      "\n",
      "Fold: 14  Epoch: 7  Training loss = 1.8290  Validation loss = 5.9437  \n",
      "\n",
      "Fold: 14  Epoch: 8  Training loss = 1.4890  Validation loss = 6.9464  \n",
      "\n",
      "Fold: 14  Epoch: 9  Training loss = 1.6905  Validation loss = 5.9028  \n",
      "\n",
      "Fold: 14  Epoch: 10  Training loss = 1.7166  Validation loss = 5.0199  \n",
      "\n",
      "Fold: 14  Epoch: 11  Training loss = 1.4952  Validation loss = 5.9140  \n",
      "\n",
      "Fold: 14  Epoch: 12  Training loss = 1.4502  Validation loss = 6.2342  \n",
      "\n",
      "Fold: 14  Epoch: 13  Training loss = 2.4621  Validation loss = 3.8997  \n",
      "\n",
      "Fold: 14  Epoch: 14  Training loss = 1.4547  Validation loss = 5.3616  \n",
      "\n",
      "Fold: 14  Epoch: 15  Training loss = 1.4546  Validation loss = 5.9387  \n",
      "\n",
      "Fold: 14  Epoch: 16  Training loss = 2.2494  Validation loss = 3.8138  \n",
      "\n",
      "Fold: 14  Epoch: 17  Training loss = 1.6615  Validation loss = 5.9572  \n",
      "\n",
      "Fold: 14  Epoch: 18  Training loss = 1.6494  Validation loss = 5.7584  \n",
      "\n",
      "Fold: 14  Epoch: 19  Training loss = 1.5448  Validation loss = 6.3097  \n",
      "\n",
      "Check model:  Fold: 14  Optimal epoch: 16  \n",
      "\n",
      "Fold: 15  Epoch: 1  Training loss = 2.2361  Validation loss = 6.7279  \n",
      "\n",
      "Fold: 15  Epoch: 2  Training loss = 2.0832  Validation loss = 6.3552  \n",
      "\n",
      "Fold: 15  Epoch: 3  Training loss = 2.5670  Validation loss = 6.7641  \n",
      "\n",
      "Fold: 15  Epoch: 4  Training loss = 2.3225  Validation loss = 5.1380  \n",
      "\n",
      "Fold: 15  Epoch: 5  Training loss = 2.1891  Validation loss = 6.1320  \n",
      "\n",
      "Fold: 15  Epoch: 6  Training loss = 2.0795  Validation loss = 6.7427  \n",
      "\n",
      "Fold: 15  Epoch: 7  Training loss = 2.1787  Validation loss = 6.2543  \n",
      "\n",
      "Fold: 15  Epoch: 8  Training loss = 2.4094  Validation loss = 5.0825  \n",
      "\n",
      "Fold: 15  Epoch: 9  Training loss = 2.5846  Validation loss = 9.4303  \n",
      "\n",
      "Fold: 15  Epoch: 10  Training loss = 2.1876  Validation loss = 6.2361  \n",
      "\n",
      "Fold: 15  Epoch: 11  Training loss = 2.3732  Validation loss = 5.1223  \n",
      "\n",
      "Fold: 15  Epoch: 12  Training loss = 2.1692  Validation loss = 7.4557  \n",
      "\n",
      "Fold: 15  Epoch: 13  Training loss = 2.0256  Validation loss = 7.2466  \n",
      "\n",
      "Fold: 15  Epoch: 14  Training loss = 2.1020  Validation loss = 7.1368  \n",
      "\n",
      "Fold: 15  Epoch: 15  Training loss = 2.0628  Validation loss = 7.3864  \n",
      "\n",
      "Fold: 15  Epoch: 16  Training loss = 2.0712  Validation loss = 7.6515  \n",
      "\n",
      "Fold: 15  Epoch: 17  Training loss = 2.0610  Validation loss = 6.8089  \n",
      "\n",
      "Fold: 15  Epoch: 18  Training loss = 1.9588  Validation loss = 6.0902  \n",
      "\n",
      "Fold: 15  Epoch: 19  Training loss = 1.9888  Validation loss = 6.8324  \n",
      "\n",
      "Fold: 15  Epoch: 20  Training loss = 2.0136  Validation loss = 6.0579  \n",
      "\n",
      "Fold: 15  Epoch: 21  Training loss = 2.3345  Validation loss = 7.4642  \n",
      "\n",
      "Fold: 15  Epoch: 22  Training loss = 1.8766  Validation loss = 5.3699  \n",
      "\n",
      "Fold: 15  Epoch: 23  Training loss = 1.7546  Validation loss = 5.5936  \n",
      "\n",
      "Fold: 15  Epoch: 24  Training loss = 1.9630  Validation loss = 5.1358  \n",
      "\n",
      "Fold: 15  Epoch: 25  Training loss = 2.9314  Validation loss = 7.3926  \n",
      "\n",
      "Fold: 15  Epoch: 26  Training loss = 3.0379  Validation loss = 4.3514  \n",
      "\n",
      "Fold: 15  Epoch: 27  Training loss = 2.1714  Validation loss = 6.6496  \n",
      "\n",
      "Fold: 15  Epoch: 28  Training loss = 1.8995  Validation loss = 6.3280  \n",
      "\n",
      "Fold: 15  Epoch: 29  Training loss = 1.9839  Validation loss = 6.2341  \n",
      "\n",
      "Fold: 15  Epoch: 30  Training loss = 1.9980  Validation loss = 5.0794  \n",
      "\n",
      "Fold: 15  Epoch: 31  Training loss = 1.9463  Validation loss = 5.4444  \n",
      "\n",
      "Fold: 15  Epoch: 32  Training loss = 2.3545  Validation loss = 7.6449  \n",
      "\n",
      "Check model:  Fold: 15  Optimal epoch: 26  \n",
      "\n",
      "Fold: 16  Epoch: 1  Training loss = 2.4958  Validation loss = 4.5113  \n",
      "\n",
      "Fold: 16  Epoch: 2  Training loss = 2.9572  Validation loss = 5.0572  \n",
      "\n",
      "Fold: 16  Epoch: 3  Training loss = 2.7162  Validation loss = 3.9374  \n",
      "\n",
      "Fold: 16  Epoch: 4  Training loss = 2.9279  Validation loss = 4.1943  \n",
      "\n",
      "Fold: 16  Epoch: 5  Training loss = 3.0514  Validation loss = 5.3320  \n",
      "\n",
      "Fold: 16  Epoch: 6  Training loss = 2.8066  Validation loss = 4.1545  \n",
      "\n",
      "Fold: 16  Epoch: 7  Training loss = 2.6451  Validation loss = 3.5738  \n",
      "\n",
      "Fold: 16  Epoch: 8  Training loss = 2.8147  Validation loss = 2.7918  \n",
      "\n",
      "Fold: 16  Epoch: 9  Training loss = 2.6630  Validation loss = 2.8852  \n",
      "\n",
      "Fold: 16  Epoch: 10  Training loss = 2.7509  Validation loss = 3.5104  \n",
      "\n",
      "Fold: 16  Epoch: 11  Training loss = 3.0188  Validation loss = 5.2877  \n",
      "\n",
      "Fold: 16  Epoch: 12  Training loss = 3.6107  Validation loss = 2.1647  \n",
      "\n",
      "Fold: 16  Epoch: 13  Training loss = 3.2767  Validation loss = 4.3618  \n",
      "\n",
      "Fold: 16  Epoch: 14  Training loss = 2.6441  Validation loss = 3.9403  \n",
      "\n",
      "Fold: 16  Epoch: 15  Training loss = 2.6465  Validation loss = 4.3362  \n",
      "\n",
      "Fold: 16  Epoch: 16  Training loss = 2.7360  Validation loss = 4.1728  \n",
      "\n",
      "Fold: 16  Epoch: 17  Training loss = 2.5616  Validation loss = 3.1790  \n",
      "\n",
      "Fold: 16  Epoch: 18  Training loss = 2.8113  Validation loss = 2.4112  \n",
      "\n",
      "Fold: 16  Epoch: 19  Training loss = 2.8312  Validation loss = 2.8265  \n",
      "\n",
      "Fold: 16  Epoch: 20  Training loss = 2.8923  Validation loss = 4.1032  \n",
      "\n",
      "Fold: 16  Epoch: 21  Training loss = 2.5707  Validation loss = 3.5419  \n",
      "\n",
      "Fold: 16  Epoch: 22  Training loss = 2.6087  Validation loss = 3.8216  \n",
      "\n",
      "Fold: 16  Epoch: 23  Training loss = 2.5367  Validation loss = 3.7757  \n",
      "\n",
      "Fold: 16  Epoch: 24  Training loss = 2.9310  Validation loss = 2.3723  \n",
      "\n",
      "Fold: 16  Epoch: 25  Training loss = 2.6598  Validation loss = 2.5908  \n",
      "\n",
      "Fold: 16  Epoch: 26  Training loss = 2.6552  Validation loss = 2.6304  \n",
      "\n",
      "Fold: 16  Epoch: 27  Training loss = 2.7641  Validation loss = 2.1015  \n",
      "\n",
      "Fold: 16  Epoch: 28  Training loss = 2.7913  Validation loss = 2.0007  \n",
      "\n",
      "Fold: 16  Epoch: 29  Training loss = 2.8795  Validation loss = 2.0696  \n",
      "\n",
      "Fold: 16  Epoch: 30  Training loss = 2.9673  Validation loss = 3.3304  \n",
      "\n",
      "Fold: 16  Epoch: 31  Training loss = 2.8800  Validation loss = 2.0172  \n",
      "\n",
      "Fold: 16  Epoch: 32  Training loss = 2.8751  Validation loss = 3.1323  \n",
      "\n",
      "Fold: 16  Epoch: 33  Training loss = 2.6065  Validation loss = 2.1443  \n",
      "\n",
      "Fold: 16  Epoch: 34  Training loss = 2.6153  Validation loss = 2.7735  \n",
      "\n",
      "Fold: 16  Epoch: 35  Training loss = 2.5651  Validation loss = 2.3292  \n",
      "\n",
      "Fold: 16  Epoch: 36  Training loss = 2.9709  Validation loss = 2.3018  \n",
      "\n",
      "Fold: 16  Epoch: 37  Training loss = 2.5591  Validation loss = 2.4736  \n",
      "\n",
      "Fold: 16  Epoch: 38  Training loss = 2.5292  Validation loss = 2.7169  \n",
      "\n",
      "Fold: 16  Epoch: 39  Training loss = 2.7118  Validation loss = 3.1399  \n",
      "\n",
      "Fold: 16  Epoch: 40  Training loss = 3.1007  Validation loss = 2.1082  \n",
      "\n",
      "Fold: 16  Epoch: 41  Training loss = 2.6016  Validation loss = 3.0593  \n",
      "\n",
      "Fold: 16  Epoch: 42  Training loss = 2.6560  Validation loss = 2.2546  \n",
      "\n",
      "Fold: 16  Epoch: 43  Training loss = 2.5388  Validation loss = 2.6370  \n",
      "\n",
      "Fold: 16  Epoch: 44  Training loss = 2.6074  Validation loss = 3.7401  \n",
      "\n",
      "Check model:  Fold: 16  Optimal epoch: 28  \n",
      "\n",
      "Fold: 17  Epoch: 1  Training loss = 2.5435  Validation loss = 3.5880  \n",
      "\n",
      "Fold: 17  Epoch: 2  Training loss = 2.9915  Validation loss = 5.2097  \n",
      "\n",
      "Fold: 17  Epoch: 3  Training loss = 2.6902  Validation loss = 5.4623  \n",
      "\n",
      "Fold: 17  Epoch: 4  Training loss = 2.4865  Validation loss = 5.2016  \n",
      "\n",
      "Fold: 17  Epoch: 5  Training loss = 2.6919  Validation loss = 5.2355  \n",
      "\n",
      "Fold: 17  Epoch: 6  Training loss = 2.6624  Validation loss = 5.4577  \n",
      "\n",
      "Fold: 17  Epoch: 7  Training loss = 2.7669  Validation loss = 4.8519  \n",
      "\n",
      "Fold: 17  Epoch: 8  Training loss = 2.7502  Validation loss = 4.3072  \n",
      "\n",
      "Fold: 17  Epoch: 9  Training loss = 2.8484  Validation loss = 4.9009  \n",
      "\n",
      "Fold: 17  Epoch: 10  Training loss = 3.0374  Validation loss = 4.9797  \n",
      "\n",
      "Fold: 17  Epoch: 11  Training loss = 3.1037  Validation loss = 4.3289  \n",
      "\n",
      "Fold: 17  Epoch: 12  Training loss = 3.3663  Validation loss = 4.6711  \n",
      "\n",
      "Fold: 17  Epoch: 13  Training loss = 3.1917  Validation loss = 4.1414  \n",
      "\n",
      "Fold: 17  Epoch: 14  Training loss = 2.8990  Validation loss = 4.4479  \n",
      "\n",
      "Fold: 17  Epoch: 15  Training loss = 2.9717  Validation loss = 5.4621  \n",
      "\n",
      "Check model:  Fold: 17  Optimal epoch: 1  \n",
      "\n",
      "Fold: 18  Epoch: 1  Training loss = 3.1038  Validation loss = 4.0223  \n",
      "\n",
      "Fold: 18  Epoch: 2  Training loss = 3.2162  Validation loss = 3.9633  \n",
      "\n",
      "Fold: 18  Epoch: 3  Training loss = 3.0321  Validation loss = 3.5435  \n",
      "\n",
      "Fold: 18  Epoch: 4  Training loss = 3.0257  Validation loss = 3.1286  \n",
      "\n",
      "Fold: 18  Epoch: 5  Training loss = 3.2078  Validation loss = 3.2180  \n",
      "\n",
      "Fold: 18  Epoch: 6  Training loss = 2.7975  Validation loss = 3.4375  \n",
      "\n",
      "Fold: 18  Epoch: 7  Training loss = 4.2984  Validation loss = 4.2552  \n",
      "\n",
      "Fold: 18  Epoch: 8  Training loss = 2.9981  Validation loss = 4.1652  \n",
      "\n",
      "Fold: 18  Epoch: 9  Training loss = 2.9118  Validation loss = 3.9804  \n",
      "\n",
      "Fold: 18  Epoch: 10  Training loss = 2.9453  Validation loss = 3.6296  \n",
      "\n",
      "Fold: 18  Epoch: 11  Training loss = 3.6167  Validation loss = 4.5747  \n",
      "\n",
      "Check model:  Fold: 18  Optimal epoch: 4  \n",
      "\n",
      "Fold: 19  Epoch: 1  Training loss = 2.9055  Validation loss = 1.3816  \n",
      "\n",
      "Fold: 19  Epoch: 2  Training loss = 2.7405  Validation loss = 1.5624  \n",
      "\n",
      "Fold: 19  Epoch: 3  Training loss = 3.0248  Validation loss = 1.6217  \n",
      "\n",
      "Fold: 19  Epoch: 4  Training loss = 2.7240  Validation loss = 0.9494  \n",
      "\n",
      "Fold: 19  Epoch: 5  Training loss = 3.0534  Validation loss = 1.5995  \n",
      "\n",
      "Fold: 19  Epoch: 6  Training loss = 2.8082  Validation loss = 1.9136  \n",
      "\n",
      "Fold: 19  Epoch: 7  Training loss = 2.7970  Validation loss = 1.6455  \n",
      "\n",
      "Fold: 19  Epoch: 8  Training loss = 2.8422  Validation loss = 1.7574  \n",
      "\n",
      "Fold: 19  Epoch: 9  Training loss = 2.7521  Validation loss = 1.5073  \n",
      "\n",
      "Fold: 19  Epoch: 10  Training loss = 2.7603  Validation loss = 1.5625  \n",
      "\n",
      "Fold: 19  Epoch: 11  Training loss = 2.6776  Validation loss = 1.1311  \n",
      "\n",
      "Fold: 19  Epoch: 12  Training loss = 2.5837  Validation loss = 1.3016  \n",
      "\n",
      "Fold: 19  Epoch: 13  Training loss = 2.4880  Validation loss = 1.4523  \n",
      "\n",
      "Fold: 19  Epoch: 14  Training loss = 2.5833  Validation loss = 1.5098  \n",
      "\n",
      "Fold: 19  Epoch: 15  Training loss = 2.5498  Validation loss = 1.3110  \n",
      "\n",
      "Fold: 19  Epoch: 16  Training loss = 2.6145  Validation loss = 1.3898  \n",
      "\n",
      "Fold: 19  Epoch: 17  Training loss = 2.6349  Validation loss = 1.6574  \n",
      "\n",
      "Fold: 19  Epoch: 18  Training loss = 2.7955  Validation loss = 1.4466  \n",
      "\n",
      "Fold: 19  Epoch: 19  Training loss = 2.7007  Validation loss = 1.5160  \n",
      "\n",
      "Fold: 19  Epoch: 20  Training loss = 2.7052  Validation loss = 1.7637  \n",
      "\n",
      "Check model:  Fold: 19  Optimal epoch: 4  \n",
      "\n",
      "Fold: 20  Epoch: 1  Training loss = 2.4615  Validation loss = 5.2033  \n",
      "\n",
      "Fold: 20  Epoch: 2  Training loss = 2.6046  Validation loss = 5.4156  \n",
      "\n",
      "Fold: 20  Epoch: 3  Training loss = 2.8946  Validation loss = 4.2855  \n",
      "\n",
      "Fold: 20  Epoch: 4  Training loss = 2.8084  Validation loss = 3.2399  \n",
      "\n",
      "Fold: 20  Epoch: 5  Training loss = 3.0001  Validation loss = 3.4810  \n",
      "\n",
      "Fold: 20  Epoch: 6  Training loss = 2.5798  Validation loss = 4.2944  \n",
      "\n",
      "Fold: 20  Epoch: 7  Training loss = 3.0815  Validation loss = 4.1910  \n",
      "\n",
      "Fold: 20  Epoch: 8  Training loss = 2.8920  Validation loss = 3.0802  \n",
      "\n",
      "Fold: 20  Epoch: 9  Training loss = 2.8769  Validation loss = 4.7613  \n",
      "\n",
      "Fold: 20  Epoch: 10  Training loss = 3.5045  Validation loss = 5.9125  \n",
      "\n",
      "Fold: 20  Epoch: 11  Training loss = 2.4971  Validation loss = 3.8832  \n",
      "\n",
      "Fold: 20  Epoch: 12  Training loss = 2.5797  Validation loss = 4.6555  \n",
      "\n",
      "Fold: 20  Epoch: 13  Training loss = 2.8731  Validation loss = 5.0151  \n",
      "\n",
      "Fold: 20  Epoch: 14  Training loss = 2.6062  Validation loss = 3.9288  \n",
      "\n",
      "Fold: 20  Epoch: 15  Training loss = 2.6216  Validation loss = 3.9615  \n",
      "\n",
      "Fold: 20  Epoch: 16  Training loss = 2.8095  Validation loss = 5.2616  \n",
      "\n",
      "Fold: 20  Epoch: 17  Training loss = 2.6650  Validation loss = 4.8691  \n",
      "\n",
      "Fold: 20  Epoch: 18  Training loss = 2.6370  Validation loss = 4.2897  \n",
      "\n",
      "Fold: 20  Epoch: 19  Training loss = 2.8419  Validation loss = 5.1312  \n",
      "\n",
      "Fold: 20  Epoch: 20  Training loss = 2.6539  Validation loss = 4.4157  \n",
      "\n",
      "Fold: 20  Epoch: 21  Training loss = 2.8412  Validation loss = 4.2971  \n",
      "\n",
      "Fold: 20  Epoch: 22  Training loss = 2.6146  Validation loss = 5.8921  \n",
      "\n",
      "Check model:  Fold: 20  Optimal epoch: 8  \n",
      "\n",
      "Fold: 21  Epoch: 1  Training loss = 3.0135  Validation loss = 3.5083  \n",
      "\n",
      "Fold: 21  Epoch: 2  Training loss = 2.8006  Validation loss = 3.6164  \n",
      "\n",
      "Fold: 21  Epoch: 3  Training loss = 3.0118  Validation loss = 3.9321  \n",
      "\n",
      "Fold: 21  Epoch: 4  Training loss = 2.7663  Validation loss = 3.4261  \n",
      "\n",
      "Fold: 21  Epoch: 5  Training loss = 3.0370  Validation loss = 4.8302  \n",
      "\n",
      "Fold: 21  Epoch: 6  Training loss = 2.6966  Validation loss = 4.3750  \n",
      "\n",
      "Fold: 21  Epoch: 7  Training loss = 2.6105  Validation loss = 3.4293  \n",
      "\n",
      "Fold: 21  Epoch: 8  Training loss = 2.9286  Validation loss = 4.1336  \n",
      "\n",
      "Fold: 21  Epoch: 9  Training loss = 2.6622  Validation loss = 4.7484  \n",
      "\n",
      "Fold: 21  Epoch: 10  Training loss = 2.8477  Validation loss = 5.1180  \n",
      "\n",
      "Fold: 21  Epoch: 11  Training loss = 2.7560  Validation loss = 3.9152  \n",
      "\n",
      "Fold: 21  Epoch: 12  Training loss = 2.7821  Validation loss = 5.3208  \n",
      "\n",
      "Check model:  Fold: 21  Optimal epoch: 4  \n",
      "\n",
      "Fold: 22  Epoch: 1  Training loss = 2.6289  Validation loss = 4.3909  \n",
      "\n",
      "Fold: 22  Epoch: 2  Training loss = 2.6706  Validation loss = 4.4745  \n",
      "\n",
      "Fold: 22  Epoch: 3  Training loss = 2.4981  Validation loss = 4.3869  \n",
      "\n",
      "Fold: 22  Epoch: 4  Training loss = 2.7602  Validation loss = 4.5360  \n",
      "\n",
      "Fold: 22  Epoch: 5  Training loss = 2.6572  Validation loss = 4.2319  \n",
      "\n",
      "Fold: 22  Epoch: 6  Training loss = 2.5819  Validation loss = 4.4867  \n",
      "\n",
      "Fold: 22  Epoch: 7  Training loss = 2.8664  Validation loss = 4.4277  \n",
      "\n",
      "Fold: 22  Epoch: 8  Training loss = 2.7813  Validation loss = 4.0546  \n",
      "\n",
      "Fold: 22  Epoch: 9  Training loss = 2.7719  Validation loss = 4.2822  \n",
      "\n",
      "Fold: 22  Epoch: 10  Training loss = 2.9130  Validation loss = 3.6877  \n",
      "\n",
      "Fold: 22  Epoch: 11  Training loss = 2.5695  Validation loss = 4.4703  \n",
      "\n",
      "Fold: 22  Epoch: 12  Training loss = 3.3152  Validation loss = 3.9477  \n",
      "\n",
      "Fold: 22  Epoch: 13  Training loss = 2.5279  Validation loss = 4.0621  \n",
      "\n",
      "Fold: 22  Epoch: 14  Training loss = 2.6945  Validation loss = 2.7483  \n",
      "\n",
      "Fold: 22  Epoch: 15  Training loss = 2.4939  Validation loss = 2.8999  \n",
      "\n",
      "Fold: 22  Epoch: 16  Training loss = 2.5121  Validation loss = 2.7392  \n",
      "\n",
      "Fold: 22  Epoch: 17  Training loss = 2.5437  Validation loss = 3.0412  \n",
      "\n",
      "Fold: 22  Epoch: 18  Training loss = 2.3776  Validation loss = 2.9667  \n",
      "\n",
      "Fold: 22  Epoch: 19  Training loss = 2.5480  Validation loss = 2.9732  \n",
      "\n",
      "Fold: 22  Epoch: 20  Training loss = 2.5026  Validation loss = 3.4628  \n",
      "\n",
      "Fold: 22  Epoch: 21  Training loss = 2.6479  Validation loss = 3.7080  \n",
      "\n",
      "Fold: 22  Epoch: 22  Training loss = 2.5248  Validation loss = 2.4320  \n",
      "\n",
      "Fold: 22  Epoch: 23  Training loss = 2.9032  Validation loss = 3.4553  \n",
      "\n",
      "Fold: 22  Epoch: 24  Training loss = 2.3799  Validation loss = 2.6371  \n",
      "\n",
      "Fold: 22  Epoch: 25  Training loss = 2.7804  Validation loss = 2.2856  \n",
      "\n",
      "Fold: 22  Epoch: 26  Training loss = 2.7635  Validation loss = 2.8009  \n",
      "\n",
      "Fold: 22  Epoch: 27  Training loss = 2.7446  Validation loss = 3.5149  \n",
      "\n",
      "Fold: 22  Epoch: 28  Training loss = 2.6830  Validation loss = 4.0250  \n",
      "\n",
      "Check model:  Fold: 22  Optimal epoch: 25  \n",
      "\n",
      "Fold: 23  Epoch: 1  Training loss = 3.0401  Validation loss = 5.8706  \n",
      "\n",
      "Fold: 23  Epoch: 2  Training loss = 2.6268  Validation loss = 3.4887  \n",
      "\n",
      "Fold: 23  Epoch: 3  Training loss = 2.4231  Validation loss = 3.4960  \n",
      "\n",
      "Fold: 23  Epoch: 4  Training loss = 2.4361  Validation loss = 3.4339  \n",
      "\n",
      "Fold: 23  Epoch: 5  Training loss = 3.2135  Validation loss = 4.7593  \n",
      "\n",
      "Fold: 23  Epoch: 6  Training loss = 2.9023  Validation loss = 4.3437  \n",
      "\n",
      "Fold: 23  Epoch: 7  Training loss = 2.8862  Validation loss = 3.7907  \n",
      "\n",
      "Fold: 23  Epoch: 8  Training loss = 2.9064  Validation loss = 3.1183  \n",
      "\n",
      "Fold: 23  Epoch: 9  Training loss = 2.9967  Validation loss = 2.9302  \n",
      "\n",
      "Fold: 23  Epoch: 10  Training loss = 2.7404  Validation loss = 3.5180  \n",
      "\n",
      "Fold: 23  Epoch: 11  Training loss = 2.6918  Validation loss = 3.6053  \n",
      "\n",
      "Fold: 23  Epoch: 12  Training loss = 2.6431  Validation loss = 3.4150  \n",
      "\n",
      "Fold: 23  Epoch: 13  Training loss = 2.7857  Validation loss = 3.2119  \n",
      "\n",
      "Fold: 23  Epoch: 14  Training loss = 2.7756  Validation loss = 3.8379  \n",
      "\n",
      "Fold: 23  Epoch: 15  Training loss = 2.6576  Validation loss = 4.4039  \n",
      "\n",
      "Check model:  Fold: 23  Optimal epoch: 9  \n",
      "\n",
      "Fold: 24  Epoch: 1  Training loss = 2.9895  Validation loss = 1.4672  \n",
      "\n",
      "Fold: 24  Epoch: 2  Training loss = 2.9018  Validation loss = 1.7457  \n",
      "\n",
      "Fold: 24  Epoch: 3  Training loss = 3.0536  Validation loss = 2.3547  \n",
      "\n",
      "Fold: 24  Epoch: 4  Training loss = 2.9776  Validation loss = 2.1299  \n",
      "\n",
      "Fold: 24  Epoch: 5  Training loss = 3.1001  Validation loss = 1.1471  \n",
      "\n",
      "Fold: 24  Epoch: 6  Training loss = 3.0102  Validation loss = 2.9836  \n",
      "\n",
      "Fold: 24  Epoch: 7  Training loss = 3.1941  Validation loss = 1.1604  \n",
      "\n",
      "Fold: 24  Epoch: 8  Training loss = 2.9966  Validation loss = 1.1694  \n",
      "\n",
      "Fold: 24  Epoch: 9  Training loss = 3.2660  Validation loss = 1.3102  \n",
      "\n",
      "Fold: 24  Epoch: 10  Training loss = 2.8564  Validation loss = 1.7127  \n",
      "\n",
      "Fold: 24  Epoch: 11  Training loss = 2.9572  Validation loss = 2.7886  \n",
      "\n",
      "Fold: 24  Epoch: 12  Training loss = 2.7717  Validation loss = 2.4547  \n",
      "\n",
      "Fold: 24  Epoch: 13  Training loss = 2.6792  Validation loss = 1.6856  \n",
      "\n",
      "Fold: 24  Epoch: 14  Training loss = 2.6055  Validation loss = 2.0231  \n",
      "\n",
      "Fold: 24  Epoch: 15  Training loss = 2.6622  Validation loss = 1.7441  \n",
      "\n",
      "Fold: 24  Epoch: 16  Training loss = 2.7254  Validation loss = 2.0348  \n",
      "\n",
      "Fold: 24  Epoch: 17  Training loss = 2.7313  Validation loss = 3.0851  \n",
      "\n",
      "Check model:  Fold: 24  Optimal epoch: 5  \n",
      "\n",
      "Fold: 25  Epoch: 1  Training loss = 2.6124  Validation loss = 2.6295  \n",
      "\n",
      "Fold: 25  Epoch: 2  Training loss = 2.6221  Validation loss = 2.1157  \n",
      "\n",
      "Fold: 25  Epoch: 3  Training loss = 2.8208  Validation loss = 1.7507  \n",
      "\n",
      "Fold: 25  Epoch: 4  Training loss = 2.6705  Validation loss = 2.8470  \n",
      "\n",
      "Fold: 25  Epoch: 5  Training loss = 2.7182  Validation loss = 2.6657  \n",
      "\n",
      "Fold: 25  Epoch: 6  Training loss = 2.5572  Validation loss = 2.2371  \n",
      "\n",
      "Fold: 25  Epoch: 7  Training loss = 2.5956  Validation loss = 2.3657  \n",
      "\n",
      "Fold: 25  Epoch: 8  Training loss = 2.7598  Validation loss = 2.2837  \n",
      "\n",
      "Fold: 25  Epoch: 9  Training loss = 2.5987  Validation loss = 2.0587  \n",
      "\n",
      "Fold: 25  Epoch: 10  Training loss = 2.8450  Validation loss = 2.1711  \n",
      "\n",
      "Fold: 25  Epoch: 11  Training loss = 2.8086  Validation loss = 3.0817  \n",
      "\n",
      "Check model:  Fold: 25  Optimal epoch: 3  \n",
      "\n",
      "Fold: 26  Epoch: 1  Training loss = 2.6093  Validation loss = 0.8260  \n",
      "\n",
      "Fold: 26  Epoch: 2  Training loss = 3.3010  Validation loss = 1.5002  \n",
      "\n",
      "Fold: 26  Epoch: 3  Training loss = 2.6032  Validation loss = 3.4240  \n",
      "\n",
      "Fold: 26  Epoch: 4  Training loss = 2.9805  Validation loss = 2.1700  \n",
      "\n",
      "Fold: 26  Epoch: 5  Training loss = 3.3035  Validation loss = 3.5529  \n",
      "\n",
      "Fold: 26  Epoch: 6  Training loss = 2.7025  Validation loss = 2.9404  \n",
      "\n",
      "Fold: 26  Epoch: 7  Training loss = 2.8610  Validation loss = 1.3722  \n",
      "\n",
      "Fold: 26  Epoch: 8  Training loss = 2.5584  Validation loss = 2.7147  \n",
      "\n",
      "Fold: 26  Epoch: 9  Training loss = 2.6204  Validation loss = 2.3709  \n",
      "\n",
      "Fold: 26  Epoch: 10  Training loss = 2.6891  Validation loss = 2.4713  \n",
      "\n",
      "Fold: 26  Epoch: 11  Training loss = 2.7731  Validation loss = 1.4500  \n",
      "\n",
      "Fold: 26  Epoch: 12  Training loss = 2.8350  Validation loss = 0.8269  \n",
      "\n",
      "Fold: 26  Epoch: 13  Training loss = 2.6830  Validation loss = 2.2931  \n",
      "\n",
      "Fold: 26  Epoch: 14  Training loss = 2.8282  Validation loss = 4.0271  \n",
      "\n",
      "Check model:  Fold: 26  Optimal epoch: 1  \n",
      "\n",
      "Fold: 27  Epoch: 1  Training loss = 2.6969  Validation loss = 1.9283  \n",
      "\n",
      "Fold: 27  Epoch: 2  Training loss = 3.0517  Validation loss = 2.9673  \n",
      "\n",
      "Fold: 27  Epoch: 3  Training loss = 2.6210  Validation loss = 1.5473  \n",
      "\n",
      "Fold: 27  Epoch: 4  Training loss = 2.8449  Validation loss = 1.4250  \n",
      "\n",
      "Fold: 27  Epoch: 5  Training loss = 2.7952  Validation loss = 1.7189  \n",
      "\n",
      "Fold: 27  Epoch: 6  Training loss = 2.6772  Validation loss = 1.9979  \n",
      "\n",
      "Fold: 27  Epoch: 7  Training loss = 3.2080  Validation loss = 1.5494  \n",
      "\n",
      "Fold: 27  Epoch: 8  Training loss = 2.7582  Validation loss = 2.8721  \n",
      "\n",
      "Fold: 27  Epoch: 9  Training loss = 2.5472  Validation loss = 1.3003  \n",
      "\n",
      "Fold: 27  Epoch: 10  Training loss = 2.5668  Validation loss = 2.1179  \n",
      "\n",
      "Fold: 27  Epoch: 11  Training loss = 2.5510  Validation loss = 1.5609  \n",
      "\n",
      "Fold: 27  Epoch: 12  Training loss = 2.6402  Validation loss = 1.4075  \n",
      "\n",
      "Fold: 27  Epoch: 13  Training loss = 2.4795  Validation loss = 2.1438  \n",
      "\n",
      "Fold: 27  Epoch: 14  Training loss = 2.5245  Validation loss = 2.6456  \n",
      "\n",
      "Fold: 27  Epoch: 15  Training loss = 2.4986  Validation loss = 2.5801  \n",
      "\n",
      "Fold: 27  Epoch: 16  Training loss = 2.7052  Validation loss = 1.5388  \n",
      "\n",
      "Fold: 27  Epoch: 17  Training loss = 2.9736  Validation loss = 1.5181  \n",
      "\n",
      "Fold: 27  Epoch: 18  Training loss = 2.4896  Validation loss = 1.7952  \n",
      "\n",
      "Fold: 27  Epoch: 19  Training loss = 2.5492  Validation loss = 2.2222  \n",
      "\n",
      "Fold: 27  Epoch: 20  Training loss = 2.4921  Validation loss = 1.9235  \n",
      "\n",
      "Fold: 27  Epoch: 21  Training loss = 2.5091  Validation loss = 1.6634  \n",
      "\n",
      "Fold: 27  Epoch: 22  Training loss = 3.1759  Validation loss = 3.4788  \n",
      "\n",
      "Check model:  Fold: 27  Optimal epoch: 9  \n",
      "\n",
      "Fold: 28  Epoch: 1  Training loss = 2.5513  Validation loss = 1.0077  \n",
      "\n",
      "Fold: 28  Epoch: 2  Training loss = 2.3700  Validation loss = 0.9642  \n",
      "\n",
      "Fold: 28  Epoch: 3  Training loss = 2.3553  Validation loss = 2.4548  \n",
      "\n",
      "Fold: 28  Epoch: 4  Training loss = 2.3242  Validation loss = 2.3232  \n",
      "\n",
      "Fold: 28  Epoch: 5  Training loss = 2.7862  Validation loss = 2.3937  \n",
      "\n",
      "Fold: 28  Epoch: 6  Training loss = 2.3991  Validation loss = 1.2916  \n",
      "\n",
      "Fold: 28  Epoch: 7  Training loss = 2.6401  Validation loss = 2.4541  \n",
      "\n",
      "Fold: 28  Epoch: 8  Training loss = 2.3450  Validation loss = 1.6674  \n",
      "\n",
      "Fold: 28  Epoch: 9  Training loss = 2.3914  Validation loss = 1.1245  \n",
      "\n",
      "Fold: 28  Epoch: 10  Training loss = 2.3297  Validation loss = 1.5009  \n",
      "\n",
      "Fold: 28  Epoch: 11  Training loss = 2.4481  Validation loss = 1.1862  \n",
      "\n",
      "Fold: 28  Epoch: 12  Training loss = 2.2996  Validation loss = 1.3426  \n",
      "\n",
      "Fold: 28  Epoch: 13  Training loss = 2.3170  Validation loss = 2.0085  \n",
      "\n",
      "Fold: 28  Epoch: 14  Training loss = 2.6323  Validation loss = 2.2067  \n",
      "\n",
      "Fold: 28  Epoch: 15  Training loss = 2.4652  Validation loss = 1.0098  \n",
      "\n",
      "Fold: 28  Epoch: 16  Training loss = 2.3223  Validation loss = 1.4067  \n",
      "\n",
      "Fold: 28  Epoch: 17  Training loss = 2.7567  Validation loss = 2.7170  \n",
      "\n",
      "Check model:  Fold: 28  Optimal epoch: 2  \n",
      "\n",
      "Fold: 29  Epoch: 1  Training loss = 2.2686  Validation loss = 2.4169  \n",
      "\n",
      "Fold: 29  Epoch: 2  Training loss = 2.3945  Validation loss = 3.3693  \n",
      "\n",
      "Fold: 29  Epoch: 3  Training loss = 2.2282  Validation loss = 2.2370  \n",
      "\n",
      "Fold: 29  Epoch: 4  Training loss = 2.4572  Validation loss = 1.8353  \n",
      "\n",
      "Fold: 29  Epoch: 5  Training loss = 2.0725  Validation loss = 2.1851  \n",
      "\n",
      "Fold: 29  Epoch: 6  Training loss = 2.0325  Validation loss = 2.5124  \n",
      "\n",
      "Fold: 29  Epoch: 7  Training loss = 2.1850  Validation loss = 2.6290  \n",
      "\n",
      "Fold: 29  Epoch: 8  Training loss = 2.2736  Validation loss = 3.0681  \n",
      "\n",
      "Fold: 29  Epoch: 9  Training loss = 2.1956  Validation loss = 2.0627  \n",
      "\n",
      "Fold: 29  Epoch: 10  Training loss = 2.5208  Validation loss = 3.5653  \n",
      "\n",
      "Fold: 29  Epoch: 11  Training loss = 2.0738  Validation loss = 1.7628  \n",
      "\n",
      "Fold: 29  Epoch: 12  Training loss = 2.1306  Validation loss = 1.8458  \n",
      "\n",
      "Fold: 29  Epoch: 13  Training loss = 2.0325  Validation loss = 2.9929  \n",
      "\n",
      "Fold: 29  Epoch: 14  Training loss = 2.0126  Validation loss = 2.0925  \n",
      "\n",
      "Fold: 29  Epoch: 15  Training loss = 1.9695  Validation loss = 2.0794  \n",
      "\n",
      "Fold: 29  Epoch: 16  Training loss = 2.1316  Validation loss = 1.8576  \n",
      "\n",
      "Fold: 29  Epoch: 17  Training loss = 1.9874  Validation loss = 2.4687  \n",
      "\n",
      "Fold: 29  Epoch: 18  Training loss = 1.9430  Validation loss = 2.3192  \n",
      "\n",
      "Fold: 29  Epoch: 19  Training loss = 1.9290  Validation loss = 2.3841  \n",
      "\n",
      "Fold: 29  Epoch: 20  Training loss = 2.0031  Validation loss = 2.0804  \n",
      "\n",
      "Fold: 29  Epoch: 21  Training loss = 1.8936  Validation loss = 2.1746  \n",
      "\n",
      "Fold: 29  Epoch: 22  Training loss = 1.8884  Validation loss = 2.3747  \n",
      "\n",
      "Fold: 29  Epoch: 23  Training loss = 2.1694  Validation loss = 1.6280  \n",
      "\n",
      "Fold: 29  Epoch: 24  Training loss = 2.0344  Validation loss = 1.6946  \n",
      "\n",
      "Fold: 29  Epoch: 25  Training loss = 1.9135  Validation loss = 2.7767  \n",
      "\n",
      "Check model:  Fold: 29  Optimal epoch: 23  \n",
      "\n",
      "Fold: 30  Epoch: 1  Training loss = 1.9161  Validation loss = 1.6018  \n",
      "\n",
      "Fold: 30  Epoch: 2  Training loss = 1.9904  Validation loss = 1.0548  \n",
      "\n",
      "Fold: 30  Epoch: 3  Training loss = 2.2964  Validation loss = 0.9228  \n",
      "\n",
      "Fold: 30  Epoch: 4  Training loss = 2.0404  Validation loss = 1.9748  \n",
      "\n",
      "Fold: 30  Epoch: 5  Training loss = 2.1759  Validation loss = 0.9270  \n",
      "\n",
      "Fold: 30  Epoch: 6  Training loss = 1.8914  Validation loss = 1.5286  \n",
      "\n",
      "Fold: 30  Epoch: 7  Training loss = 2.0185  Validation loss = 1.1514  \n",
      "\n",
      "Fold: 30  Epoch: 8  Training loss = 2.1926  Validation loss = 0.9265  \n",
      "\n",
      "Fold: 30  Epoch: 9  Training loss = 1.9793  Validation loss = 1.5708  \n",
      "\n",
      "Fold: 30  Epoch: 10  Training loss = 1.8634  Validation loss = 1.2943  \n",
      "\n",
      "Fold: 30  Epoch: 11  Training loss = 1.9726  Validation loss = 1.1584  \n",
      "\n",
      "Fold: 30  Epoch: 12  Training loss = 2.1901  Validation loss = 1.6047  \n",
      "\n",
      "Fold: 30  Epoch: 13  Training loss = 2.1860  Validation loss = 0.9379  \n",
      "\n",
      "Fold: 30  Epoch: 14  Training loss = 2.3302  Validation loss = 1.3110  \n",
      "\n",
      "Fold: 30  Epoch: 15  Training loss = 2.6032  Validation loss = 2.2577  \n",
      "\n",
      "Check model:  Fold: 30  Optimal epoch: 3  \n",
      "\n",
      "Fold: 31  Epoch: 1  Training loss = 2.1817  Validation loss = 0.7288  \n",
      "\n",
      "Fold: 31  Epoch: 2  Training loss = 1.8013  Validation loss = 1.1091  \n",
      "\n",
      "Fold: 31  Epoch: 3  Training loss = 1.8468  Validation loss = 1.6698  \n",
      "\n",
      "Fold: 31  Epoch: 4  Training loss = 1.8952  Validation loss = 1.3307  \n",
      "\n",
      "Fold: 31  Epoch: 5  Training loss = 2.4268  Validation loss = 2.9775  \n",
      "\n",
      "Fold: 31  Epoch: 6  Training loss = 1.9026  Validation loss = 1.0063  \n",
      "\n",
      "Fold: 31  Epoch: 7  Training loss = 1.9755  Validation loss = 2.1073  \n",
      "\n",
      "Fold: 31  Epoch: 8  Training loss = 1.9131  Validation loss = 1.3268  \n",
      "\n",
      "Fold: 31  Epoch: 9  Training loss = 2.2156  Validation loss = 1.1508  \n",
      "\n",
      "Fold: 31  Epoch: 10  Training loss = 2.1661  Validation loss = 1.0575  \n",
      "\n",
      "Fold: 31  Epoch: 11  Training loss = 1.8634  Validation loss = 0.6131  \n",
      "\n",
      "Fold: 31  Epoch: 12  Training loss = 1.9398  Validation loss = 0.7382  \n",
      "\n",
      "Fold: 31  Epoch: 13  Training loss = 1.8888  Validation loss = 0.8140  \n",
      "\n",
      "Fold: 31  Epoch: 14  Training loss = 1.8042  Validation loss = 0.7870  \n",
      "\n",
      "Fold: 31  Epoch: 15  Training loss = 1.7903  Validation loss = 0.7536  \n",
      "\n",
      "Fold: 31  Epoch: 16  Training loss = 1.7001  Validation loss = 1.1421  \n",
      "\n",
      "Fold: 31  Epoch: 17  Training loss = 1.7025  Validation loss = 1.7999  \n",
      "\n",
      "Check model:  Fold: 31  Optimal epoch: 11  \n",
      "\n",
      "Fold: 32  Epoch: 1  Training loss = 1.7474  Validation loss = 5.9895  \n",
      "\n",
      "Fold: 32  Epoch: 2  Training loss = 1.6988  Validation loss = 6.0374  \n",
      "\n",
      "Fold: 32  Epoch: 3  Training loss = 1.6125  Validation loss = 4.7447  \n",
      "\n",
      "Fold: 32  Epoch: 4  Training loss = 1.5810  Validation loss = 4.6889  \n",
      "\n",
      "Fold: 32  Epoch: 5  Training loss = 1.8160  Validation loss = 4.1308  \n",
      "\n",
      "Fold: 32  Epoch: 6  Training loss = 1.5288  Validation loss = 4.7372  \n",
      "\n",
      "Fold: 32  Epoch: 7  Training loss = 1.6341  Validation loss = 4.1902  \n",
      "\n",
      "Fold: 32  Epoch: 8  Training loss = 2.1731  Validation loss = 3.3165  \n",
      "\n",
      "Fold: 32  Epoch: 9  Training loss = 1.6722  Validation loss = 5.4179  \n",
      "\n",
      "Fold: 32  Epoch: 10  Training loss = 1.5351  Validation loss = 4.7779  \n",
      "\n",
      "Fold: 32  Epoch: 11  Training loss = 1.5562  Validation loss = 5.2773  \n",
      "\n",
      "Fold: 32  Epoch: 12  Training loss = 1.5734  Validation loss = 4.8764  \n",
      "\n",
      "Fold: 32  Epoch: 13  Training loss = 1.5360  Validation loss = 5.7363  \n",
      "\n",
      "Check model:  Fold: 32  Optimal epoch: 8  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 2. Train model\n",
    "# ==================================\n",
    "sess = tf.InteractiveSession()  # Launch Graph\n",
    "sess.run(tf.global_variables_initializer())  # Initialise all variables\n",
    "\n",
    "print(\"Start training\", \n",
    "      \"\\nHyperparameters:\",\n",
    "      \"\\nDimension of recurrent unit =\", n_hidden,\n",
    "      \"\\nLearning rate =\", learning_rate,\n",
    "      \"\\nEpochs =\", epochs,\n",
    "      \"\\nBatch size =\", batch_size,\n",
    "      \"\\nEarly stopping epochs =\", early_stop_iters,\n",
    "      \"\\nLearning rate =\", learning_rate)\n",
    "\n",
    "total_batch = int(window_length / batch_size)\n",
    "validation_fold_error = [] # store validation error of each fold\n",
    "optimal_epochs = []\n",
    "\n",
    "# loop through folds\n",
    "for fold in range(1, len(valIndex)):\n",
    "    validx = train_features[valIndex[fold-1]:valIndex[fold]]\n",
    "    validy = train_target[valIndex[fold-1]:valIndex[fold]]\n",
    "    trainx = train_features[(fold-1)*4:valIndex[(fold-1)]]\n",
    "    trainy = train_target[(fold-1)*4:valIndex[(fold-1)]]\n",
    "\n",
    "    loss_list = [] # store validation loss after each epoch for early stopping\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i in range(total_batch):\n",
    "            # Backprop\n",
    "            batch_xs, batch_ys = next_batch(num=batch_size, data=trainx, labels=trainy)\n",
    "            optimizer.run(feed_dict={x:batch_xs, y:batch_ys, lr:learning_rate})\n",
    "\n",
    "        # Loss\n",
    "        loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "        loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "        loss_list.append(loss_valid)\n",
    "\n",
    "        print(\"Fold: {0:d}\".format(fold),\n",
    "              \" Epoch: {0:d}\".format(epoch+1),\n",
    "              \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "              \" Validation loss = {0:.4f}\".format(np.sqrt(loss_valid)),\n",
    "              \" \\n\")\n",
    "\n",
    "        if all(j <= loss_valid for j in loss_list[-early_stop_iters:]) and len(loss_list)>early_stop_iters:\n",
    "            break\n",
    "    \n",
    "    # Load model with lowest validation error for each fold\n",
    "    epoch_hat = np.argmin(loss_list) + 1\n",
    "    optimal_epochs.append(epoch_hat) # store optimal number of epochs for each fold\n",
    "    \n",
    "    # RMSE\n",
    "    loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "    loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "    validation_fold_error.append(np.sqrt(loss_valid))\n",
    "    \n",
    "    print(\"Check model:\",\n",
    "          \" Fold: {0:d}\".format(fold),\n",
    "          \" Optimal epoch: {0:d}\".format(epoch_hat),\n",
    "          \" \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average number of epochs: 11\n",
      "Average validation error: 3.96849\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 3. Optimal epoch choice\n",
    "# ==================================\n",
    "# Pick number of epochs to train model for out-of-sample testing\n",
    "epoch_hat = int(np.mean(optimal_epochs))\n",
    "print(\"\\nAverage number of epochs:\", epoch_hat)\n",
    "# Average validation error\n",
    "print(\"Average validation error:\", np.mean(validation_fold_error))\n",
    "\n",
    "# Save validated model\n",
    "saveModel(sess, \n",
    "          MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + str(epoch_hat) + \"_validated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fixed scheme:\n",
      "Epoch: 1  Training loss = 1.6788  Test loss = 3.9409  \n",
      "\n",
      "Epoch: 2  Training loss = 1.6409  Test loss = 3.8422  \n",
      "\n",
      "Epoch: 3  Training loss = 1.6138  Test loss = 3.8398  \n",
      "\n",
      "Epoch: 4  Training loss = 1.5877  Test loss = 3.7862  \n",
      "\n",
      "Epoch: 5  Training loss = 1.5726  Test loss = 3.8192  \n",
      "\n",
      "Epoch: 6  Training loss = 1.5546  Test loss = 3.7645  \n",
      "\n",
      "Epoch: 7  Training loss = 1.5443  Test loss = 3.7972  \n",
      "\n",
      "Epoch: 8  Training loss = 1.5270  Test loss = 3.7604  \n",
      "\n",
      "Epoch: 9  Training loss = 1.5119  Test loss = 3.6927  \n",
      "\n",
      "Epoch: 10  Training loss = 1.5002  Test loss = 3.6766  \n",
      "\n",
      "Epoch: 11  Training loss = 1.4856  Test loss = 3.6825  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 4. Fixed scheme\n",
    "# ==================================\n",
    "print(\"\\nFixed scheme:\")\n",
    "for epoch in range(epoch_hat):\n",
    "    x_train = train_features[-window_length:]\n",
    "    y_train = train_target[-window_length:]\n",
    "    optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:test_features, y:test_target})\n",
    "    print(\"Epoch: {0:d}\".format(epoch+1),\n",
    "          \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "          \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "          \" \\n\")\n",
    "\n",
    "# Forecasts\n",
    "yhat_test_fixed = pred.eval(feed_dict={x:test_features})\n",
    "yhat_train_fixed = pred.eval(feed_dict={x:x_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxoXdzKxiXNjNzCrGhd3MrGJc2M3MKuZfvetEiCdwhVgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc063668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train set\n",
    "plt.plot(y_train, 'black')\n",
    "plt.plot(yhat_train_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1lAuADOzhnIBmJk11H8BOlPLyaSzBLoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xcc4df98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: fixed scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_test_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed scheme RMSE: 3.68252677676 \n",
      "Fixed scheme MAE:  2.67461051337\n"
     ]
    }
   ],
   "source": [
    "rmse_fixed = np.sqrt(np.mean((yhat_test_fixed[:,0]-test_target)**2))\n",
    "mae_fixed = np.mean(np.abs((yhat_test_fixed[:,0]-test_target)))\n",
    "print(\"Fixed scheme RMSE:\", rmse_fixed,\n",
    "     \"\\nFixed scheme MAE: \", mae_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Stack training and test set, this makes updating scheme easier to train\n",
    "all_features = np.concatenate((train_features[-window_length:], test_features), axis=0)\n",
    "all_target = np.concatenate((train_target[-window_length:], test_target), axis=0)\n",
    "\n",
    "# Vectors to store loss and forecasts\n",
    "test_loss = np.zeros(len(test_target))\n",
    "yhat_update = np.zeros(len(test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test period = 1  Training loss = 1.4856  Test loss = 2.2167  Model updated 0 times  \n",
      "\n",
      "Test period = 2  Training loss = 1.4720  Test loss = 2.6778  Model updated 0 times  \n",
      "\n",
      "Test period = 3  Training loss = 1.5086  Test loss = 1.3786  Model updated 0 times  \n",
      "\n",
      "Test period = 4  Training loss = 1.5153  Test loss = 1.6212  Model updated 0 times  \n",
      "\n",
      "Test period = 5  Training loss = 1.1485  Test loss = 2.0190  Model updated 1 times  \n",
      "\n",
      "Test period = 6  Training loss = 1.1650  Test loss = 1.9801  Model updated 1 times  \n",
      "\n",
      "Test period = 7  Training loss = 1.1772  Test loss = 0.8170  Model updated 1 times  \n",
      "\n",
      "Test period = 8  Training loss = 1.1787  Test loss = 3.2083  Model updated 1 times  \n",
      "\n",
      "Test period = 9  Training loss = 1.0982  Test loss = 0.6109  Model updated 2 times  \n",
      "\n",
      "Test period = 10  Training loss = 1.0863  Test loss = 0.3331  Model updated 2 times  \n",
      "\n",
      "Test period = 11  Training loss = 1.0578  Test loss = 1.4021  Model updated 2 times  \n",
      "\n",
      "Test period = 12  Training loss = 1.0718  Test loss = 0.7363  Model updated 2 times  \n",
      "\n",
      "Test period = 13  Training loss = 1.0239  Test loss = 0.1105  Model updated 3 times  \n",
      "\n",
      "Test period = 14  Training loss = 1.0238  Test loss = 1.1759  Model updated 3 times  \n",
      "\n",
      "Test period = 15  Training loss = 1.0335  Test loss = 3.0284  Model updated 3 times  \n",
      "\n",
      "Test period = 16  Training loss = 1.0996  Test loss = 5.4493  Model updated 3 times  \n",
      "\n",
      "Test period = 17  Training loss = 1.1782  Test loss = 5.6219  Model updated 4 times  \n",
      "\n",
      "Test period = 18  Training loss = 1.3691  Test loss = 0.0737  Model updated 4 times  \n",
      "\n",
      "Test period = 19  Training loss = 1.3692  Test loss = 0.9481  Model updated 4 times  \n",
      "\n",
      "Test period = 20  Training loss = 1.3265  Test loss = 2.5892  Model updated 4 times  \n",
      "\n",
      "Test period = 21  Training loss = 1.1618  Test loss = 0.3644  Model updated 5 times  \n",
      "\n",
      "Test period = 22  Training loss = 1.1626  Test loss = 4.1205  Model updated 5 times  \n",
      "\n",
      "Test period = 23  Training loss = 1.2699  Test loss = 0.6156  Model updated 5 times  \n",
      "\n",
      "Test period = 24  Training loss = 1.2678  Test loss = 0.2164  Model updated 5 times  \n",
      "\n",
      "Test period = 25  Training loss = 1.1332  Test loss = 1.3054  Model updated 6 times  \n",
      "\n",
      "Test period = 26  Training loss = 1.1421  Test loss = 0.8680  Model updated 6 times  \n",
      "\n",
      "Test period = 27  Training loss = 1.1471  Test loss = 0.6218  Model updated 6 times  \n",
      "\n",
      "Test period = 28  Training loss = 1.1429  Test loss = 0.9189  Model updated 6 times  \n",
      "\n",
      "Test period = 29  Training loss = 1.0615  Test loss = 0.3089  Model updated 7 times  \n",
      "\n",
      "Test period = 30  Training loss = 1.0518  Test loss = 0.4311  Model updated 7 times  \n",
      "\n",
      "Test period = 31  Training loss = 1.0462  Test loss = 6.8073  Model updated 7 times  \n",
      "\n",
      "Test period = 32  Training loss = 1.3196  Test loss = 0.9759  Model updated 7 times  \n",
      "\n",
      "Test period = 33  Training loss = 1.0898  Test loss = 0.7592  Model updated 8 times  \n",
      "\n",
      "Test period = 34  Training loss = 1.0915  Test loss = 0.8002  Model updated 8 times  \n",
      "\n",
      "Test period = 35  Training loss = 1.0955  Test loss = 0.9713  Model updated 8 times  \n",
      "\n",
      "Test period = 36  Training loss = 1.1017  Test loss = 4.6536  Model updated 8 times  \n",
      "\n",
      "Test period = 37  Training loss = 1.1925  Test loss = 0.8306  Model updated 9 times  \n",
      "\n",
      "Test period = 38  Training loss = 1.0978  Test loss = 1.5225  Model updated 9 times  \n",
      "\n",
      "Test period = 39  Training loss = 1.1139  Test loss = 0.2128  Model updated 9 times  \n",
      "\n",
      "Test period = 40  Training loss = 1.1141  Test loss = 2.7748  Model updated 9 times  \n",
      "\n",
      "Test period = 41  Training loss = 1.0431  Test loss = 2.4367  Model updated 10 times  \n",
      "\n",
      "Test period = 42  Training loss = 1.0860  Test loss = 5.7465  Model updated 10 times  \n",
      "\n",
      "Test period = 43  Training loss = 1.2989  Test loss = 3.9968  Model updated 10 times  \n",
      "\n",
      "Test period = 44  Training loss = 1.3901  Test loss = 13.1034  Model updated 10 times  \n",
      "\n",
      "Test period = 45  Training loss = 1.9264  Test loss = 5.8556  Model updated 11 times  \n",
      "\n",
      "Test period = 46  Training loss = 2.0545  Test loss = 0.9277  Model updated 11 times  \n",
      "\n",
      "Test period = 47  Training loss = 2.0577  Test loss = 0.3190  Model updated 11 times  \n",
      "\n",
      "Test period = 48  Training loss = 2.0508  Test loss = 0.1130  Model updated 11 times  \n",
      "\n",
      "Test period = 49  Training loss = 1.4398  Test loss = 3.3714  Model updated 12 times  \n",
      "\n",
      "Test period = 50  Training loss = 1.4982  Test loss = 2.8068  Model updated 12 times  \n",
      "\n",
      "Test period = 51  Training loss = 1.5377  Test loss = 4.3629  Model updated 12 times  \n",
      "\n",
      "Test period = 52  Training loss = 1.6301  Test loss = 0.7622  Model updated 12 times  \n",
      "\n",
      "Test period = 53  Training loss = 1.2817  Test loss = 1.6131  Model updated 13 times  \n",
      "\n",
      "Test period = 54  Training loss = 1.2972  Test loss = 3.5209  Model updated 13 times  \n",
      "\n",
      "Test period = 55  Training loss = 1.3684  Test loss = 0.1668  Model updated 13 times  \n",
      "\n",
      "Test period = 56  Training loss = 1.3635  Test loss = 1.9098  Model updated 13 times  \n",
      "\n",
      "Test period = 57  Training loss = 1.2484  Test loss = 0.9226  Model updated 14 times  \n",
      "\n",
      "Test period = 58  Training loss = 1.2536  Test loss = 7.6119  Model updated 14 times  \n",
      "\n",
      "Test period = 59  Training loss = 1.5681  Test loss = 1.2347  Model updated 14 times  \n",
      "\n",
      "Test period = 60  Training loss = 1.5747  Test loss = 0.5143  Model updated 14 times  \n",
      "\n",
      "Test period = 61  Training loss = 1.1842  Test loss = 1.8445  Model updated 15 times  \n",
      "\n",
      "Test period = 62  Training loss = 1.1976  Test loss = 2.2539  Model updated 15 times  \n",
      "\n",
      "Test period = 63  Training loss = 1.2276  Test loss = 0.2465  Model updated 15 times  \n",
      "\n",
      "Test period = 64  Training loss = 1.2279  Test loss = 2.0032  Model updated 15 times  \n",
      "\n",
      "Test period = 65  Training loss = 1.1905  Test loss = 2.6440  Model updated 16 times  \n",
      "\n",
      "Test period = 66  Training loss = 1.2318  Test loss = 1.6958  Model updated 16 times  \n",
      "\n",
      "Test period = 67  Training loss = 1.2290  Test loss = 5.6714  Model updated 16 times  \n",
      "\n",
      "Test period = 68  Training loss = 1.4158  Test loss = 3.3339  Model updated 16 times  \n",
      "\n",
      "Test period = 69  Training loss = 1.2416  Test loss = 7.3529  Model updated 17 times  \n",
      "\n",
      "Test period = 70  Training loss = 1.5393  Test loss = 0.9964  Model updated 17 times  \n",
      "\n",
      "Test period = 71  Training loss = 1.5443  Test loss = 0.7824  Model updated 17 times  \n",
      "\n",
      "Test period = 72  Training loss = 1.5469  Test loss = 2.2165  Model updated 17 times  \n",
      "\n",
      "Test period = 73  Training loss = 1.1669  Test loss = 2.3413  Model updated 18 times  \n",
      "\n",
      "Test period = 74  Training loss = 1.2012  Test loss = 1.6129  Model updated 18 times  \n",
      "\n",
      "Test period = 75  Training loss = 1.2177  Test loss = 2.3863  Model updated 18 times  \n",
      "\n",
      "Test period = 76  Training loss = 1.2527  Test loss = 0.1596  Model updated 18 times  \n",
      "\n",
      "Test period = 77  Training loss = 1.2110  Test loss = 2.5073  Model updated 19 times  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "retrain_count = 0\n",
    "for t in range(len(test_target)):\n",
    "    x_test = np.reshape(test_features[t], newshape=(1,4,3))\n",
    "    y_test = test_target[t]\n",
    "    test_loss[t] = np.sqrt(sess.run(loss, feed_dict={x:x_test, y:y_test}))\n",
    "    yhat_update[t] = pred.eval(feed_dict={x:x_test})\n",
    "\n",
    "    x_train = all_features[t:(window_length+t)]\n",
    "    y_train = all_target[t:(window_length+t)]\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:x_test, y:y_test})\n",
    "    \n",
    "    print(\"Test period = {0:d}\".format(t+1),\n",
    "      \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "      \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "      \" Model updated {0:d} times\".format(retrain_count),\n",
    "      \" \\n\")\n",
    "\n",
    "    if (t+1)%4==0:\n",
    "        retrain_count += 1\n",
    "        for epoch in range(epoch_hat):\n",
    "            for i in range(total_batch):\n",
    "                optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xced9b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: updating scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_update, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating scheme RMSE: 3.11634677576 \n",
      "Updating scheme MAE:  2.20028922817\n"
     ]
    }
   ],
   "source": [
    "rmse_update = np.sqrt(np.mean((yhat_update-test_target)**2))\n",
    "mae_update = np.mean(np.abs((yhat_update-test_target)))\n",
    "print(\"Updating scheme RMSE:\", rmse_update,\n",
    "     \"\\nUpdating scheme MAE: \", mae_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + \"yhat_test_fixed.csv\", yhat_test_fixed)\n",
    "np.savetxt(MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + \"yhat_update.csv\", yhat_update)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
