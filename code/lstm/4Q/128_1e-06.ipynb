{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Directories\n",
    "MODEL_FOLDER = \"../../../models/lstm/\"\n",
    "MODEL_FILENAME = MODEL_FOLDER + \"4Q/128_units/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: model saver\n",
    "def saveModel(sess, MODEL_FILENAME):\n",
    "    if not os.path.exists(MODEL_FOLDER):\n",
    "        print('Creating path where to save model: ' + MODEL_FOLDER)\n",
    "        os.mkdir(MODEL_FOLDER)\n",
    "\n",
    "    #print('Saving model at: ' + MODEL_FILENAME)\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, MODEL_FILENAME)\n",
    "    #print('Model successfully saved.\\n')\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: model loader\n",
    "def loadModel(sess, MODEL_FILENAME):\n",
    "    if os.path.exists(MODEL_FILENAME + \".index\"):\n",
    "        print('Loading save model from: ' + MODEL_FILENAME)\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, MODEL_FILENAME)\n",
    "        print('Model successfully loaded.\\n')\n",
    "        return True\n",
    "    else:\n",
    "        print('Model file <<' + MODEL_FILENAME + '>> does not exists!')\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Hyperparameters\n",
    "epochs = 500\n",
    "learning_rate = 1e-6\n",
    "batch_size = 5\n",
    "early_stop_iters = 15\n",
    "folds = 32\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 3  # data input\n",
    "n_steps = 4  # timesteps\n",
    "n_hidden = 128 # dimension of recurrent unit\n",
    "\n",
    "# (REPRODUCIBILITY) set random seeds\n",
    "tf.set_random_seed(123)\n",
    "\n",
    "# Define weights and biases\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.truncated_normal([n_hidden, 1], stddev = 1.0 / tf.sqrt(float(n_hidden))),\n",
    "        name='out_weight')\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.zeros([1]),\n",
    "        name='out_bias')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: Build model\n",
    "def RNN(X, weights, biases, n_hidden):\n",
    "\n",
    "    # Define a LSTM cell with tensorflow\n",
    "    lstm_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden, state_is_tuple=True)\n",
    "    outputs, _ = tf.nn.dynamic_rnn(lstm_cell, X, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    out_layer = tf.matmul(outputs[:,-1,:], weights['out']) + biases['out']\n",
    "\n",
    "    return out_layer\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: select batch\n",
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the data...\n",
      "Finished: data loaded. Stats below: \n",
      "Nr of training samples: 193\n",
      "Nr of testing  samples: 77\n",
      "Number of variables: 3\n",
      "Number of lags: 4\n",
      "Window length: 65\n",
      "Number of validation folds: 32\n"
     ]
    }
   ],
   "source": [
    "# =================================\n",
    "# 0. Load dataset\n",
    "# =================================\n",
    "print(\"Loading the data...\")\n",
    "# Training set pre-processing\n",
    "train = pd.read_csv('../../../Data/train.csv')\n",
    "train_4lag_inflation = np.array(train[['inflation.lag4',\n",
    "                                       'inflation.lag5',\n",
    "                                       'inflation.lag6',\n",
    "                                       'inflation.lag7']])\n",
    "train_4lag_unemp = np.array(train[['unemp.lag4',\n",
    "                                   'unemp.lag5',\n",
    "                                   'unemp.lag6',\n",
    "                                   'unemp.lag7']])\n",
    "train_4lag_oil = np.array(train[['oil.lag4',\n",
    "                                 'oil.lag5',\n",
    "                                 'oil.lag6',\n",
    "                                 'oil.lag7']])\n",
    "train_features = np.concatenate((train_4lag_inflation[:,:,np.newaxis], \n",
    "\t                             train_4lag_unemp[:,:,np.newaxis],\n",
    "\t                             train_4lag_oil[:,:,np.newaxis]),\n",
    "\t                             axis=2)\n",
    "train_target = np.array(train['inflation.target'])\n",
    "\n",
    "# Test set pre-processing\n",
    "test = pd.read_csv('../../../Data/test.csv')\n",
    "test_4lag_inflation = np.array(test[['inflation.lag4',\n",
    "                                     'inflation.lag5',\n",
    "                                     'inflation.lag6',\n",
    "                                     'inflation.lag7']])\n",
    "test_4lag_unemp = np.array(test[['unemp.lag4',\n",
    "                                 'unemp.lag5',\n",
    "                                 'unemp.lag6',\n",
    "                                 'unemp.lag7']])\n",
    "test_4lag_oil = np.array(test[['oil.lag4',\n",
    "                               'oil.lag5',\n",
    "                               'oil.lag6',\n",
    "                               'oil.lag7']])\n",
    "test_features = np.concatenate((test_4lag_inflation[:,:,np.newaxis], \n",
    "\t                            test_4lag_unemp[:,:,np.newaxis],\n",
    "\t                            test_4lag_oil[:,:,np.newaxis]),\n",
    "\t                            axis=2)\n",
    "test_target = np.array(test['inflation.target'])\n",
    "\n",
    "(nrTrainSamples, timesteps, variables) = train_features.shape\n",
    "(nrTestSamples, _, _) = test_features.shape\n",
    "\n",
    "# Window length and validation fold index\n",
    "window_length = 65\n",
    "valIndex = np.linspace(start=window_length, stop=nrTrainSamples, \n",
    "                       endpoint=True, num=folds+1, dtype=np.int)\n",
    "\n",
    "print(\"Finished: data loaded. Stats below: \")\n",
    "print(\"Nr of training samples: %d\" % nrTrainSamples)\n",
    "print(\"Nr of testing  samples: %d\" % nrTestSamples)\n",
    "print(\"Number of variables: %d\" % variables)\n",
    "print(\"Number of lags: %d\" % timesteps)\n",
    "print(\"Window length: %d\" % window_length)\n",
    "print(\"Number of validation folds: %d\" % folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 1. Build model\n",
    "# ==================================\n",
    "# tf graph input\n",
    "x = tf.placeholder(\"float\", [None, n_steps, n_input], name='Batch')\n",
    "y = tf.placeholder(\"float\", name='True_labels_of_batch')\n",
    "lr = tf.placeholder(\"float\", name='Learning_rate')\n",
    "\n",
    "# Make predictions with the model\n",
    "pred = RNN(x, weights, biases, n_hidden)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss = tf.reduce_mean(tf.diag_part(tf.square(tf.subtract(x=pred, y=y))))\n",
    "optimizer = tf.train.GradientDescentOptimizer(lr).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training \n",
      "Hyperparameters: \n",
      "Dimension of recurrent unit = 128 \n",
      "Learning rate = 1e-06 \n",
      "Epochs = 500 \n",
      "Batch size = 5 \n",
      "Early stopping epochs = 15 \n",
      "Learning rate = 1e-06\n",
      "Fold: 1  Epoch: 1  Training loss = 3.3456  Validation loss = 3.5076  \n",
      "\n",
      "Fold: 1  Epoch: 2  Training loss = 3.3453  Validation loss = 3.5071  \n",
      "\n",
      "Fold: 1  Epoch: 3  Training loss = 3.3449  Validation loss = 3.5064  \n",
      "\n",
      "Fold: 1  Epoch: 4  Training loss = 3.3445  Validation loss = 3.5059  \n",
      "\n",
      "Fold: 1  Epoch: 5  Training loss = 3.3441  Validation loss = 3.5053  \n",
      "\n",
      "Fold: 1  Epoch: 6  Training loss = 3.3437  Validation loss = 3.5046  \n",
      "\n",
      "Fold: 1  Epoch: 7  Training loss = 3.3434  Validation loss = 3.5041  \n",
      "\n",
      "Fold: 1  Epoch: 8  Training loss = 3.3429  Validation loss = 3.5034  \n",
      "\n",
      "Fold: 1  Epoch: 9  Training loss = 3.3427  Validation loss = 3.5029  \n",
      "\n",
      "Fold: 1  Epoch: 10  Training loss = 3.3423  Validation loss = 3.5024  \n",
      "\n",
      "Fold: 1  Epoch: 11  Training loss = 3.3419  Validation loss = 3.5018  \n",
      "\n",
      "Fold: 1  Epoch: 12  Training loss = 3.3416  Validation loss = 3.5012  \n",
      "\n",
      "Fold: 1  Epoch: 13  Training loss = 3.3413  Validation loss = 3.5007  \n",
      "\n",
      "Fold: 1  Epoch: 14  Training loss = 3.3410  Validation loss = 3.5003  \n",
      "\n",
      "Fold: 1  Epoch: 15  Training loss = 3.3407  Validation loss = 3.4998  \n",
      "\n",
      "Fold: 1  Epoch: 16  Training loss = 3.3403  Validation loss = 3.4992  \n",
      "\n",
      "Fold: 1  Epoch: 17  Training loss = 3.3400  Validation loss = 3.4986  \n",
      "\n",
      "Fold: 1  Epoch: 18  Training loss = 3.3396  Validation loss = 3.4981  \n",
      "\n",
      "Fold: 1  Epoch: 19  Training loss = 3.3391  Validation loss = 3.4973  \n",
      "\n",
      "Fold: 1  Epoch: 20  Training loss = 3.3388  Validation loss = 3.4968  \n",
      "\n",
      "Fold: 1  Epoch: 21  Training loss = 3.3385  Validation loss = 3.4962  \n",
      "\n",
      "Fold: 1  Epoch: 22  Training loss = 3.3383  Validation loss = 3.4958  \n",
      "\n",
      "Fold: 1  Epoch: 23  Training loss = 3.3379  Validation loss = 3.4952  \n",
      "\n",
      "Fold: 1  Epoch: 24  Training loss = 3.3375  Validation loss = 3.4946  \n",
      "\n",
      "Fold: 1  Epoch: 25  Training loss = 3.3372  Validation loss = 3.4941  \n",
      "\n",
      "Fold: 1  Epoch: 26  Training loss = 3.3368  Validation loss = 3.4935  \n",
      "\n",
      "Fold: 1  Epoch: 27  Training loss = 3.3365  Validation loss = 3.4930  \n",
      "\n",
      "Fold: 1  Epoch: 28  Training loss = 3.3363  Validation loss = 3.4926  \n",
      "\n",
      "Fold: 1  Epoch: 29  Training loss = 3.3358  Validation loss = 3.4919  \n",
      "\n",
      "Fold: 1  Epoch: 30  Training loss = 3.3355  Validation loss = 3.4915  \n",
      "\n",
      "Fold: 1  Epoch: 31  Training loss = 3.3352  Validation loss = 3.4909  \n",
      "\n",
      "Fold: 1  Epoch: 32  Training loss = 3.3348  Validation loss = 3.4903  \n",
      "\n",
      "Fold: 1  Epoch: 33  Training loss = 3.3345  Validation loss = 3.4899  \n",
      "\n",
      "Fold: 1  Epoch: 34  Training loss = 3.3342  Validation loss = 3.4894  \n",
      "\n",
      "Fold: 1  Epoch: 35  Training loss = 3.3339  Validation loss = 3.4889  \n",
      "\n",
      "Fold: 1  Epoch: 36  Training loss = 3.3336  Validation loss = 3.4883  \n",
      "\n",
      "Fold: 1  Epoch: 37  Training loss = 3.3331  Validation loss = 3.4876  \n",
      "\n",
      "Fold: 1  Epoch: 38  Training loss = 3.3328  Validation loss = 3.4871  \n",
      "\n",
      "Fold: 1  Epoch: 39  Training loss = 3.3324  Validation loss = 3.4864  \n",
      "\n",
      "Fold: 1  Epoch: 40  Training loss = 3.3320  Validation loss = 3.4858  \n",
      "\n",
      "Fold: 1  Epoch: 41  Training loss = 3.3318  Validation loss = 3.4854  \n",
      "\n",
      "Fold: 1  Epoch: 42  Training loss = 3.3314  Validation loss = 3.4848  \n",
      "\n",
      "Fold: 1  Epoch: 43  Training loss = 3.3310  Validation loss = 3.4841  \n",
      "\n",
      "Fold: 1  Epoch: 44  Training loss = 3.3307  Validation loss = 3.4836  \n",
      "\n",
      "Fold: 1  Epoch: 45  Training loss = 3.3303  Validation loss = 3.4830  \n",
      "\n",
      "Fold: 1  Epoch: 46  Training loss = 3.3300  Validation loss = 3.4826  \n",
      "\n",
      "Fold: 1  Epoch: 47  Training loss = 3.3297  Validation loss = 3.4821  \n",
      "\n",
      "Fold: 1  Epoch: 48  Training loss = 3.3293  Validation loss = 3.4815  \n",
      "\n",
      "Fold: 1  Epoch: 49  Training loss = 3.3290  Validation loss = 3.4810  \n",
      "\n",
      "Fold: 1  Epoch: 50  Training loss = 3.3286  Validation loss = 3.4803  \n",
      "\n",
      "Fold: 1  Epoch: 51  Training loss = 3.3283  Validation loss = 3.4798  \n",
      "\n",
      "Fold: 1  Epoch: 52  Training loss = 3.3280  Validation loss = 3.4793  \n",
      "\n",
      "Fold: 1  Epoch: 53  Training loss = 3.3276  Validation loss = 3.4787  \n",
      "\n",
      "Fold: 1  Epoch: 54  Training loss = 3.3273  Validation loss = 3.4782  \n",
      "\n",
      "Fold: 1  Epoch: 55  Training loss = 3.3271  Validation loss = 3.4779  \n",
      "\n",
      "Fold: 1  Epoch: 56  Training loss = 3.3268  Validation loss = 3.4774  \n",
      "\n",
      "Fold: 1  Epoch: 57  Training loss = 3.3264  Validation loss = 3.4767  \n",
      "\n",
      "Fold: 1  Epoch: 58  Training loss = 3.3260  Validation loss = 3.4762  \n",
      "\n",
      "Fold: 1  Epoch: 59  Training loss = 3.3257  Validation loss = 3.4757  \n",
      "\n",
      "Fold: 1  Epoch: 60  Training loss = 3.3254  Validation loss = 3.4751  \n",
      "\n",
      "Fold: 1  Epoch: 61  Training loss = 3.3250  Validation loss = 3.4745  \n",
      "\n",
      "Fold: 1  Epoch: 62  Training loss = 3.3246  Validation loss = 3.4739  \n",
      "\n",
      "Fold: 1  Epoch: 63  Training loss = 3.3243  Validation loss = 3.4734  \n",
      "\n",
      "Fold: 1  Epoch: 64  Training loss = 3.3240  Validation loss = 3.4729  \n",
      "\n",
      "Fold: 1  Epoch: 65  Training loss = 3.3237  Validation loss = 3.4725  \n",
      "\n",
      "Fold: 1  Epoch: 66  Training loss = 3.3233  Validation loss = 3.4718  \n",
      "\n",
      "Fold: 1  Epoch: 67  Training loss = 3.3231  Validation loss = 3.4715  \n",
      "\n",
      "Fold: 1  Epoch: 68  Training loss = 3.3228  Validation loss = 3.4710  \n",
      "\n",
      "Fold: 1  Epoch: 69  Training loss = 3.3224  Validation loss = 3.4704  \n",
      "\n",
      "Fold: 1  Epoch: 70  Training loss = 3.3221  Validation loss = 3.4698  \n",
      "\n",
      "Fold: 1  Epoch: 71  Training loss = 3.3218  Validation loss = 3.4693  \n",
      "\n",
      "Fold: 1  Epoch: 72  Training loss = 3.3215  Validation loss = 3.4688  \n",
      "\n",
      "Fold: 1  Epoch: 73  Training loss = 3.3212  Validation loss = 3.4683  \n",
      "\n",
      "Fold: 1  Epoch: 74  Training loss = 3.3208  Validation loss = 3.4677  \n",
      "\n",
      "Fold: 1  Epoch: 75  Training loss = 3.3204  Validation loss = 3.4671  \n",
      "\n",
      "Fold: 1  Epoch: 76  Training loss = 3.3201  Validation loss = 3.4666  \n",
      "\n",
      "Fold: 1  Epoch: 77  Training loss = 3.3198  Validation loss = 3.4661  \n",
      "\n",
      "Fold: 1  Epoch: 78  Training loss = 3.3195  Validation loss = 3.4657  \n",
      "\n",
      "Fold: 1  Epoch: 79  Training loss = 3.3192  Validation loss = 3.4651  \n",
      "\n",
      "Fold: 1  Epoch: 80  Training loss = 3.3189  Validation loss = 3.4646  \n",
      "\n",
      "Fold: 1  Epoch: 81  Training loss = 3.3185  Validation loss = 3.4640  \n",
      "\n",
      "Fold: 1  Epoch: 82  Training loss = 3.3181  Validation loss = 3.4635  \n",
      "\n",
      "Fold: 1  Epoch: 83  Training loss = 3.3177  Validation loss = 3.4628  \n",
      "\n",
      "Fold: 1  Epoch: 84  Training loss = 3.3173  Validation loss = 3.4622  \n",
      "\n",
      "Fold: 1  Epoch: 85  Training loss = 3.3170  Validation loss = 3.4617  \n",
      "\n",
      "Fold: 1  Epoch: 86  Training loss = 3.3167  Validation loss = 3.4611  \n",
      "\n",
      "Fold: 1  Epoch: 87  Training loss = 3.3164  Validation loss = 3.4607  \n",
      "\n",
      "Fold: 1  Epoch: 88  Training loss = 3.3161  Validation loss = 3.4602  \n",
      "\n",
      "Fold: 1  Epoch: 89  Training loss = 3.3158  Validation loss = 3.4597  \n",
      "\n",
      "Fold: 1  Epoch: 90  Training loss = 3.3154  Validation loss = 3.4591  \n",
      "\n",
      "Fold: 1  Epoch: 91  Training loss = 3.3150  Validation loss = 3.4585  \n",
      "\n",
      "Fold: 1  Epoch: 92  Training loss = 3.3148  Validation loss = 3.4580  \n",
      "\n",
      "Fold: 1  Epoch: 93  Training loss = 3.3144  Validation loss = 3.4574  \n",
      "\n",
      "Fold: 1  Epoch: 94  Training loss = 3.3141  Validation loss = 3.4570  \n",
      "\n",
      "Fold: 1  Epoch: 95  Training loss = 3.3138  Validation loss = 3.4565  \n",
      "\n",
      "Fold: 1  Epoch: 96  Training loss = 3.3134  Validation loss = 3.4558  \n",
      "\n",
      "Fold: 1  Epoch: 97  Training loss = 3.3131  Validation loss = 3.4553  \n",
      "\n",
      "Fold: 1  Epoch: 98  Training loss = 3.3128  Validation loss = 3.4549  \n",
      "\n",
      "Fold: 1  Epoch: 99  Training loss = 3.3124  Validation loss = 3.4542  \n",
      "\n",
      "Fold: 1  Epoch: 100  Training loss = 3.3121  Validation loss = 3.4536  \n",
      "\n",
      "Fold: 1  Epoch: 101  Training loss = 3.3118  Validation loss = 3.4532  \n",
      "\n",
      "Fold: 1  Epoch: 102  Training loss = 3.3114  Validation loss = 3.4525  \n",
      "\n",
      "Fold: 1  Epoch: 103  Training loss = 3.3110  Validation loss = 3.4519  \n",
      "\n",
      "Fold: 1  Epoch: 104  Training loss = 3.3107  Validation loss = 3.4514  \n",
      "\n",
      "Fold: 1  Epoch: 105  Training loss = 3.3104  Validation loss = 3.4509  \n",
      "\n",
      "Fold: 1  Epoch: 106  Training loss = 3.3101  Validation loss = 3.4504  \n",
      "\n",
      "Fold: 1  Epoch: 107  Training loss = 3.3098  Validation loss = 3.4499  \n",
      "\n",
      "Fold: 1  Epoch: 108  Training loss = 3.3095  Validation loss = 3.4495  \n",
      "\n",
      "Fold: 1  Epoch: 109  Training loss = 3.3092  Validation loss = 3.4490  \n",
      "\n",
      "Fold: 1  Epoch: 110  Training loss = 3.3089  Validation loss = 3.4485  \n",
      "\n",
      "Fold: 1  Epoch: 111  Training loss = 3.3085  Validation loss = 3.4479  \n",
      "\n",
      "Fold: 1  Epoch: 112  Training loss = 3.3081  Validation loss = 3.4472  \n",
      "\n",
      "Fold: 1  Epoch: 113  Training loss = 3.3079  Validation loss = 3.4469  \n",
      "\n",
      "Fold: 1  Epoch: 114  Training loss = 3.3075  Validation loss = 3.4463  \n",
      "\n",
      "Fold: 1  Epoch: 115  Training loss = 3.3073  Validation loss = 3.4458  \n",
      "\n",
      "Fold: 1  Epoch: 116  Training loss = 3.3069  Validation loss = 3.4453  \n",
      "\n",
      "Fold: 1  Epoch: 117  Training loss = 3.3066  Validation loss = 3.4447  \n",
      "\n",
      "Fold: 1  Epoch: 118  Training loss = 3.3062  Validation loss = 3.4442  \n",
      "\n",
      "Fold: 1  Epoch: 119  Training loss = 3.3059  Validation loss = 3.4436  \n",
      "\n",
      "Fold: 1  Epoch: 120  Training loss = 3.3055  Validation loss = 3.4430  \n",
      "\n",
      "Fold: 1  Epoch: 121  Training loss = 3.3053  Validation loss = 3.4426  \n",
      "\n",
      "Fold: 1  Epoch: 122  Training loss = 3.3049  Validation loss = 3.4420  \n",
      "\n",
      "Fold: 1  Epoch: 123  Training loss = 3.3046  Validation loss = 3.4415  \n",
      "\n",
      "Fold: 1  Epoch: 124  Training loss = 3.3043  Validation loss = 3.4410  \n",
      "\n",
      "Fold: 1  Epoch: 125  Training loss = 3.3040  Validation loss = 3.4405  \n",
      "\n",
      "Fold: 1  Epoch: 126  Training loss = 3.3037  Validation loss = 3.4400  \n",
      "\n",
      "Fold: 1  Epoch: 127  Training loss = 3.3035  Validation loss = 3.4397  \n",
      "\n",
      "Fold: 1  Epoch: 128  Training loss = 3.3031  Validation loss = 3.4390  \n",
      "\n",
      "Fold: 1  Epoch: 129  Training loss = 3.3027  Validation loss = 3.4385  \n",
      "\n",
      "Fold: 1  Epoch: 130  Training loss = 3.3024  Validation loss = 3.4379  \n",
      "\n",
      "Fold: 1  Epoch: 131  Training loss = 3.3020  Validation loss = 3.4373  \n",
      "\n",
      "Fold: 1  Epoch: 132  Training loss = 3.3017  Validation loss = 3.4368  \n",
      "\n",
      "Fold: 1  Epoch: 133  Training loss = 3.3014  Validation loss = 3.4362  \n",
      "\n",
      "Fold: 1  Epoch: 134  Training loss = 3.3010  Validation loss = 3.4356  \n",
      "\n",
      "Fold: 1  Epoch: 135  Training loss = 3.3007  Validation loss = 3.4351  \n",
      "\n",
      "Fold: 1  Epoch: 136  Training loss = 3.3003  Validation loss = 3.4345  \n",
      "\n",
      "Fold: 1  Epoch: 137  Training loss = 3.2999  Validation loss = 3.4339  \n",
      "\n",
      "Fold: 1  Epoch: 138  Training loss = 3.2997  Validation loss = 3.4335  \n",
      "\n",
      "Fold: 1  Epoch: 139  Training loss = 3.2992  Validation loss = 3.4327  \n",
      "\n",
      "Fold: 1  Epoch: 140  Training loss = 3.2988  Validation loss = 3.4320  \n",
      "\n",
      "Fold: 1  Epoch: 141  Training loss = 3.2985  Validation loss = 3.4315  \n",
      "\n",
      "Fold: 1  Epoch: 142  Training loss = 3.2982  Validation loss = 3.4310  \n",
      "\n",
      "Fold: 1  Epoch: 143  Training loss = 3.2979  Validation loss = 3.4306  \n",
      "\n",
      "Fold: 1  Epoch: 144  Training loss = 3.2976  Validation loss = 3.4301  \n",
      "\n",
      "Fold: 1  Epoch: 145  Training loss = 3.2973  Validation loss = 3.4295  \n",
      "\n",
      "Fold: 1  Epoch: 146  Training loss = 3.2968  Validation loss = 3.4288  \n",
      "\n",
      "Fold: 1  Epoch: 147  Training loss = 3.2966  Validation loss = 3.4284  \n",
      "\n",
      "Fold: 1  Epoch: 148  Training loss = 3.2963  Validation loss = 3.4279  \n",
      "\n",
      "Fold: 1  Epoch: 149  Training loss = 3.2960  Validation loss = 3.4274  \n",
      "\n",
      "Fold: 1  Epoch: 150  Training loss = 3.2956  Validation loss = 3.4267  \n",
      "\n",
      "Fold: 1  Epoch: 151  Training loss = 3.2953  Validation loss = 3.4262  \n",
      "\n",
      "Fold: 1  Epoch: 152  Training loss = 3.2950  Validation loss = 3.4257  \n",
      "\n",
      "Fold: 1  Epoch: 153  Training loss = 3.2947  Validation loss = 3.4252  \n",
      "\n",
      "Fold: 1  Epoch: 154  Training loss = 3.2943  Validation loss = 3.4246  \n",
      "\n",
      "Fold: 1  Epoch: 155  Training loss = 3.2940  Validation loss = 3.4241  \n",
      "\n",
      "Fold: 1  Epoch: 156  Training loss = 3.2936  Validation loss = 3.4235  \n",
      "\n",
      "Fold: 1  Epoch: 157  Training loss = 3.2933  Validation loss = 3.4230  \n",
      "\n",
      "Fold: 1  Epoch: 158  Training loss = 3.2930  Validation loss = 3.4224  \n",
      "\n",
      "Fold: 1  Epoch: 159  Training loss = 3.2927  Validation loss = 3.4219  \n",
      "\n",
      "Fold: 1  Epoch: 160  Training loss = 3.2922  Validation loss = 3.4212  \n",
      "\n",
      "Fold: 1  Epoch: 161  Training loss = 3.2919  Validation loss = 3.4206  \n",
      "\n",
      "Fold: 1  Epoch: 162  Training loss = 3.2916  Validation loss = 3.4201  \n",
      "\n",
      "Fold: 1  Epoch: 163  Training loss = 3.2913  Validation loss = 3.4196  \n",
      "\n",
      "Fold: 1  Epoch: 164  Training loss = 3.2909  Validation loss = 3.4191  \n",
      "\n",
      "Fold: 1  Epoch: 165  Training loss = 3.2906  Validation loss = 3.4185  \n",
      "\n",
      "Fold: 1  Epoch: 166  Training loss = 3.2903  Validation loss = 3.4180  \n",
      "\n",
      "Fold: 1  Epoch: 167  Training loss = 3.2899  Validation loss = 3.4174  \n",
      "\n",
      "Fold: 1  Epoch: 168  Training loss = 3.2895  Validation loss = 3.4167  \n",
      "\n",
      "Fold: 1  Epoch: 169  Training loss = 3.2891  Validation loss = 3.4160  \n",
      "\n",
      "Fold: 1  Epoch: 170  Training loss = 3.2887  Validation loss = 3.4155  \n",
      "\n",
      "Fold: 1  Epoch: 171  Training loss = 3.2885  Validation loss = 3.4150  \n",
      "\n",
      "Fold: 1  Epoch: 172  Training loss = 3.2881  Validation loss = 3.4145  \n",
      "\n",
      "Fold: 1  Epoch: 173  Training loss = 3.2878  Validation loss = 3.4139  \n",
      "\n",
      "Fold: 1  Epoch: 174  Training loss = 3.2874  Validation loss = 3.4133  \n",
      "\n",
      "Fold: 1  Epoch: 175  Training loss = 3.2871  Validation loss = 3.4128  \n",
      "\n",
      "Fold: 1  Epoch: 176  Training loss = 3.2868  Validation loss = 3.4123  \n",
      "\n",
      "Fold: 1  Epoch: 177  Training loss = 3.2865  Validation loss = 3.4118  \n",
      "\n",
      "Fold: 1  Epoch: 178  Training loss = 3.2862  Validation loss = 3.4113  \n",
      "\n",
      "Fold: 1  Epoch: 179  Training loss = 3.2858  Validation loss = 3.4106  \n",
      "\n",
      "Fold: 1  Epoch: 180  Training loss = 3.2855  Validation loss = 3.4102  \n",
      "\n",
      "Fold: 1  Epoch: 181  Training loss = 3.2851  Validation loss = 3.4095  \n",
      "\n",
      "Fold: 1  Epoch: 182  Training loss = 3.2847  Validation loss = 3.4089  \n",
      "\n",
      "Fold: 1  Epoch: 183  Training loss = 3.2844  Validation loss = 3.4083  \n",
      "\n",
      "Fold: 1  Epoch: 184  Training loss = 3.2840  Validation loss = 3.4077  \n",
      "\n",
      "Fold: 1  Epoch: 185  Training loss = 3.2837  Validation loss = 3.4072  \n",
      "\n",
      "Fold: 1  Epoch: 186  Training loss = 3.2834  Validation loss = 3.4067  \n",
      "\n",
      "Fold: 1  Epoch: 187  Training loss = 3.2831  Validation loss = 3.4062  \n",
      "\n",
      "Fold: 1  Epoch: 188  Training loss = 3.2828  Validation loss = 3.4057  \n",
      "\n",
      "Fold: 1  Epoch: 189  Training loss = 3.2824  Validation loss = 3.4051  \n",
      "\n",
      "Fold: 1  Epoch: 190  Training loss = 3.2821  Validation loss = 3.4046  \n",
      "\n",
      "Fold: 1  Epoch: 191  Training loss = 3.2818  Validation loss = 3.4042  \n",
      "\n",
      "Fold: 1  Epoch: 192  Training loss = 3.2814  Validation loss = 3.4035  \n",
      "\n",
      "Fold: 1  Epoch: 193  Training loss = 3.2811  Validation loss = 3.4030  \n",
      "\n",
      "Fold: 1  Epoch: 194  Training loss = 3.2808  Validation loss = 3.4025  \n",
      "\n",
      "Fold: 1  Epoch: 195  Training loss = 3.2805  Validation loss = 3.4019  \n",
      "\n",
      "Fold: 1  Epoch: 196  Training loss = 3.2802  Validation loss = 3.4015  \n",
      "\n",
      "Fold: 1  Epoch: 197  Training loss = 3.2799  Validation loss = 3.4009  \n",
      "\n",
      "Fold: 1  Epoch: 198  Training loss = 3.2795  Validation loss = 3.4003  \n",
      "\n",
      "Fold: 1  Epoch: 199  Training loss = 3.2791  Validation loss = 3.3997  \n",
      "\n",
      "Fold: 1  Epoch: 200  Training loss = 3.2789  Validation loss = 3.3993  \n",
      "\n",
      "Fold: 1  Epoch: 201  Training loss = 3.2785  Validation loss = 3.3987  \n",
      "\n",
      "Fold: 1  Epoch: 202  Training loss = 3.2782  Validation loss = 3.3982  \n",
      "\n",
      "Fold: 1  Epoch: 203  Training loss = 3.2779  Validation loss = 3.3977  \n",
      "\n",
      "Fold: 1  Epoch: 204  Training loss = 3.2775  Validation loss = 3.3971  \n",
      "\n",
      "Fold: 1  Epoch: 205  Training loss = 3.2773  Validation loss = 3.3967  \n",
      "\n",
      "Fold: 1  Epoch: 206  Training loss = 3.2771  Validation loss = 3.3963  \n",
      "\n",
      "Fold: 1  Epoch: 207  Training loss = 3.2768  Validation loss = 3.3958  \n",
      "\n",
      "Fold: 1  Epoch: 208  Training loss = 3.2765  Validation loss = 3.3954  \n",
      "\n",
      "Fold: 1  Epoch: 209  Training loss = 3.2761  Validation loss = 3.3947  \n",
      "\n",
      "Fold: 1  Epoch: 210  Training loss = 3.2759  Validation loss = 3.3944  \n",
      "\n",
      "Fold: 1  Epoch: 211  Training loss = 3.2754  Validation loss = 3.3936  \n",
      "\n",
      "Fold: 1  Epoch: 212  Training loss = 3.2751  Validation loss = 3.3931  \n",
      "\n",
      "Fold: 1  Epoch: 213  Training loss = 3.2749  Validation loss = 3.3927  \n",
      "\n",
      "Fold: 1  Epoch: 214  Training loss = 3.2745  Validation loss = 3.3922  \n",
      "\n",
      "Fold: 1  Epoch: 215  Training loss = 3.2743  Validation loss = 3.3917  \n",
      "\n",
      "Fold: 1  Epoch: 216  Training loss = 3.2740  Validation loss = 3.3912  \n",
      "\n",
      "Fold: 1  Epoch: 217  Training loss = 3.2736  Validation loss = 3.3907  \n",
      "\n",
      "Fold: 1  Epoch: 218  Training loss = 3.2734  Validation loss = 3.3903  \n",
      "\n",
      "Fold: 1  Epoch: 219  Training loss = 3.2730  Validation loss = 3.3896  \n",
      "\n",
      "Fold: 1  Epoch: 220  Training loss = 3.2727  Validation loss = 3.3891  \n",
      "\n",
      "Fold: 1  Epoch: 221  Training loss = 3.2724  Validation loss = 3.3887  \n",
      "\n",
      "Fold: 1  Epoch: 222  Training loss = 3.2720  Validation loss = 3.3879  \n",
      "\n",
      "Fold: 1  Epoch: 223  Training loss = 3.2716  Validation loss = 3.3874  \n",
      "\n",
      "Fold: 1  Epoch: 224  Training loss = 3.2714  Validation loss = 3.3869  \n",
      "\n",
      "Fold: 1  Epoch: 225  Training loss = 3.2712  Validation loss = 3.3866  \n",
      "\n",
      "Fold: 1  Epoch: 226  Training loss = 3.2708  Validation loss = 3.3860  \n",
      "\n",
      "Fold: 1  Epoch: 227  Training loss = 3.2705  Validation loss = 3.3854  \n",
      "\n",
      "Fold: 1  Epoch: 228  Training loss = 3.2702  Validation loss = 3.3849  \n",
      "\n",
      "Fold: 1  Epoch: 229  Training loss = 3.2697  Validation loss = 3.3842  \n",
      "\n",
      "Fold: 1  Epoch: 230  Training loss = 3.2695  Validation loss = 3.3838  \n",
      "\n",
      "Fold: 1  Epoch: 231  Training loss = 3.2693  Validation loss = 3.3833  \n",
      "\n",
      "Fold: 1  Epoch: 232  Training loss = 3.2690  Validation loss = 3.3829  \n",
      "\n",
      "Fold: 1  Epoch: 233  Training loss = 3.2687  Validation loss = 3.3825  \n",
      "\n",
      "Fold: 1  Epoch: 234  Training loss = 3.2685  Validation loss = 3.3820  \n",
      "\n",
      "Fold: 1  Epoch: 235  Training loss = 3.2681  Validation loss = 3.3814  \n",
      "\n",
      "Fold: 1  Epoch: 236  Training loss = 3.2677  Validation loss = 3.3808  \n",
      "\n",
      "Fold: 1  Epoch: 237  Training loss = 3.2674  Validation loss = 3.3803  \n",
      "\n",
      "Fold: 1  Epoch: 238  Training loss = 3.2670  Validation loss = 3.3796  \n",
      "\n",
      "Fold: 1  Epoch: 239  Training loss = 3.2667  Validation loss = 3.3790  \n",
      "\n",
      "Fold: 1  Epoch: 240  Training loss = 3.2664  Validation loss = 3.3786  \n",
      "\n",
      "Fold: 1  Epoch: 241  Training loss = 3.2660  Validation loss = 3.3779  \n",
      "\n",
      "Fold: 1  Epoch: 242  Training loss = 3.2657  Validation loss = 3.3775  \n",
      "\n",
      "Fold: 1  Epoch: 243  Training loss = 3.2654  Validation loss = 3.3770  \n",
      "\n",
      "Fold: 1  Epoch: 244  Training loss = 3.2651  Validation loss = 3.3764  \n",
      "\n",
      "Fold: 1  Epoch: 245  Training loss = 3.2648  Validation loss = 3.3759  \n",
      "\n",
      "Fold: 1  Epoch: 246  Training loss = 3.2645  Validation loss = 3.3755  \n",
      "\n",
      "Fold: 1  Epoch: 247  Training loss = 3.2643  Validation loss = 3.3751  \n",
      "\n",
      "Fold: 1  Epoch: 248  Training loss = 3.2639  Validation loss = 3.3744  \n",
      "\n",
      "Fold: 1  Epoch: 249  Training loss = 3.2636  Validation loss = 3.3740  \n",
      "\n",
      "Fold: 1  Epoch: 250  Training loss = 3.2634  Validation loss = 3.3737  \n",
      "\n",
      "Fold: 1  Epoch: 251  Training loss = 3.2632  Validation loss = 3.3732  \n",
      "\n",
      "Fold: 1  Epoch: 252  Training loss = 3.2629  Validation loss = 3.3727  \n",
      "\n",
      "Fold: 1  Epoch: 253  Training loss = 3.2624  Validation loss = 3.3720  \n",
      "\n",
      "Fold: 1  Epoch: 254  Training loss = 3.2622  Validation loss = 3.3716  \n",
      "\n",
      "Fold: 1  Epoch: 255  Training loss = 3.2618  Validation loss = 3.3710  \n",
      "\n",
      "Fold: 1  Epoch: 256  Training loss = 3.2615  Validation loss = 3.3705  \n",
      "\n",
      "Fold: 1  Epoch: 257  Training loss = 3.2612  Validation loss = 3.3699  \n",
      "\n",
      "Fold: 1  Epoch: 258  Training loss = 3.2610  Validation loss = 3.3695  \n",
      "\n",
      "Fold: 1  Epoch: 259  Training loss = 3.2607  Validation loss = 3.3691  \n",
      "\n",
      "Fold: 1  Epoch: 260  Training loss = 3.2605  Validation loss = 3.3687  \n",
      "\n",
      "Fold: 1  Epoch: 261  Training loss = 3.2602  Validation loss = 3.3683  \n",
      "\n",
      "Fold: 1  Epoch: 262  Training loss = 3.2598  Validation loss = 3.3676  \n",
      "\n",
      "Fold: 1  Epoch: 263  Training loss = 3.2595  Validation loss = 3.3672  \n",
      "\n",
      "Fold: 1  Epoch: 264  Training loss = 3.2593  Validation loss = 3.3667  \n",
      "\n",
      "Fold: 1  Epoch: 265  Training loss = 3.2590  Validation loss = 3.3662  \n",
      "\n",
      "Fold: 1  Epoch: 266  Training loss = 3.2587  Validation loss = 3.3658  \n",
      "\n",
      "Fold: 1  Epoch: 267  Training loss = 3.2585  Validation loss = 3.3653  \n",
      "\n",
      "Fold: 1  Epoch: 268  Training loss = 3.2582  Validation loss = 3.3649  \n",
      "\n",
      "Fold: 1  Epoch: 269  Training loss = 3.2579  Validation loss = 3.3644  \n",
      "\n",
      "Fold: 1  Epoch: 270  Training loss = 3.2576  Validation loss = 3.3639  \n",
      "\n",
      "Fold: 1  Epoch: 271  Training loss = 3.2573  Validation loss = 3.3634  \n",
      "\n",
      "Fold: 1  Epoch: 272  Training loss = 3.2570  Validation loss = 3.3629  \n",
      "\n",
      "Fold: 1  Epoch: 273  Training loss = 3.2568  Validation loss = 3.3625  \n",
      "\n",
      "Fold: 1  Epoch: 274  Training loss = 3.2565  Validation loss = 3.3620  \n",
      "\n",
      "Fold: 1  Epoch: 275  Training loss = 3.2561  Validation loss = 3.3615  \n",
      "\n",
      "Fold: 1  Epoch: 276  Training loss = 3.2558  Validation loss = 3.3610  \n",
      "\n",
      "Fold: 1  Epoch: 277  Training loss = 3.2555  Validation loss = 3.3605  \n",
      "\n",
      "Fold: 1  Epoch: 278  Training loss = 3.2552  Validation loss = 3.3600  \n",
      "\n",
      "Fold: 1  Epoch: 279  Training loss = 3.2550  Validation loss = 3.3596  \n",
      "\n",
      "Fold: 1  Epoch: 280  Training loss = 3.2547  Validation loss = 3.3591  \n",
      "\n",
      "Fold: 1  Epoch: 281  Training loss = 3.2544  Validation loss = 3.3586  \n",
      "\n",
      "Fold: 1  Epoch: 282  Training loss = 3.2541  Validation loss = 3.3581  \n",
      "\n",
      "Fold: 1  Epoch: 283  Training loss = 3.2538  Validation loss = 3.3575  \n",
      "\n",
      "Fold: 1  Epoch: 284  Training loss = 3.2535  Validation loss = 3.3571  \n",
      "\n",
      "Fold: 1  Epoch: 285  Training loss = 3.2532  Validation loss = 3.3566  \n",
      "\n",
      "Fold: 1  Epoch: 286  Training loss = 3.2530  Validation loss = 3.3562  \n",
      "\n",
      "Fold: 1  Epoch: 287  Training loss = 3.2527  Validation loss = 3.3557  \n",
      "\n",
      "Fold: 1  Epoch: 288  Training loss = 3.2524  Validation loss = 3.3553  \n",
      "\n",
      "Fold: 1  Epoch: 289  Training loss = 3.2521  Validation loss = 3.3547  \n",
      "\n",
      "Fold: 1  Epoch: 290  Training loss = 3.2518  Validation loss = 3.3542  \n",
      "\n",
      "Fold: 1  Epoch: 291  Training loss = 3.2516  Validation loss = 3.3538  \n",
      "\n",
      "Fold: 1  Epoch: 292  Training loss = 3.2513  Validation loss = 3.3533  \n",
      "\n",
      "Fold: 1  Epoch: 293  Training loss = 3.2510  Validation loss = 3.3529  \n",
      "\n",
      "Fold: 1  Epoch: 294  Training loss = 3.2508  Validation loss = 3.3525  \n",
      "\n",
      "Fold: 1  Epoch: 295  Training loss = 3.2504  Validation loss = 3.3519  \n",
      "\n",
      "Fold: 1  Epoch: 296  Training loss = 3.2502  Validation loss = 3.3516  \n",
      "\n",
      "Fold: 1  Epoch: 297  Training loss = 3.2499  Validation loss = 3.3510  \n",
      "\n",
      "Fold: 1  Epoch: 298  Training loss = 3.2496  Validation loss = 3.3505  \n",
      "\n",
      "Fold: 1  Epoch: 299  Training loss = 3.2494  Validation loss = 3.3502  \n",
      "\n",
      "Fold: 1  Epoch: 300  Training loss = 3.2492  Validation loss = 3.3498  \n",
      "\n",
      "Fold: 1  Epoch: 301  Training loss = 3.2489  Validation loss = 3.3492  \n",
      "\n",
      "Fold: 1  Epoch: 302  Training loss = 3.2486  Validation loss = 3.3488  \n",
      "\n",
      "Fold: 1  Epoch: 303  Training loss = 3.2482  Validation loss = 3.3482  \n",
      "\n",
      "Fold: 1  Epoch: 304  Training loss = 3.2479  Validation loss = 3.3476  \n",
      "\n",
      "Fold: 1  Epoch: 305  Training loss = 3.2476  Validation loss = 3.3471  \n",
      "\n",
      "Fold: 1  Epoch: 306  Training loss = 3.2472  Validation loss = 3.3465  \n",
      "\n",
      "Fold: 1  Epoch: 307  Training loss = 3.2469  Validation loss = 3.3459  \n",
      "\n",
      "Fold: 1  Epoch: 308  Training loss = 3.2465  Validation loss = 3.3453  \n",
      "\n",
      "Fold: 1  Epoch: 309  Training loss = 3.2462  Validation loss = 3.3448  \n",
      "\n",
      "Fold: 1  Epoch: 310  Training loss = 3.2460  Validation loss = 3.3444  \n",
      "\n",
      "Fold: 1  Epoch: 311  Training loss = 3.2457  Validation loss = 3.3439  \n",
      "\n",
      "Fold: 1  Epoch: 312  Training loss = 3.2454  Validation loss = 3.3434  \n",
      "\n",
      "Fold: 1  Epoch: 313  Training loss = 3.2452  Validation loss = 3.3430  \n",
      "\n",
      "Fold: 1  Epoch: 314  Training loss = 3.2449  Validation loss = 3.3425  \n",
      "\n",
      "Fold: 1  Epoch: 315  Training loss = 3.2447  Validation loss = 3.3421  \n",
      "\n",
      "Fold: 1  Epoch: 316  Training loss = 3.2444  Validation loss = 3.3417  \n",
      "\n",
      "Fold: 1  Epoch: 317  Training loss = 3.2442  Validation loss = 3.3414  \n",
      "\n",
      "Fold: 1  Epoch: 318  Training loss = 3.2438  Validation loss = 3.3407  \n",
      "\n",
      "Fold: 1  Epoch: 319  Training loss = 3.2435  Validation loss = 3.3403  \n",
      "\n",
      "Fold: 1  Epoch: 320  Training loss = 3.2433  Validation loss = 3.3398  \n",
      "\n",
      "Fold: 1  Epoch: 321  Training loss = 3.2431  Validation loss = 3.3394  \n",
      "\n",
      "Fold: 1  Epoch: 322  Training loss = 3.2428  Validation loss = 3.3389  \n",
      "\n",
      "Fold: 1  Epoch: 323  Training loss = 3.2425  Validation loss = 3.3385  \n",
      "\n",
      "Fold: 1  Epoch: 324  Training loss = 3.2422  Validation loss = 3.3380  \n",
      "\n",
      "Fold: 1  Epoch: 325  Training loss = 3.2420  Validation loss = 3.3376  \n",
      "\n",
      "Fold: 1  Epoch: 326  Training loss = 3.2417  Validation loss = 3.3371  \n",
      "\n",
      "Fold: 1  Epoch: 327  Training loss = 3.2414  Validation loss = 3.3366  \n",
      "\n",
      "Fold: 1  Epoch: 328  Training loss = 3.2411  Validation loss = 3.3362  \n",
      "\n",
      "Fold: 1  Epoch: 329  Training loss = 3.2409  Validation loss = 3.3357  \n",
      "\n",
      "Fold: 1  Epoch: 330  Training loss = 3.2406  Validation loss = 3.3352  \n",
      "\n",
      "Fold: 1  Epoch: 331  Training loss = 3.2403  Validation loss = 3.3347  \n",
      "\n",
      "Fold: 1  Epoch: 332  Training loss = 3.2399  Validation loss = 3.3341  \n",
      "\n",
      "Fold: 1  Epoch: 333  Training loss = 3.2396  Validation loss = 3.3337  \n",
      "\n",
      "Fold: 1  Epoch: 334  Training loss = 3.2394  Validation loss = 3.3333  \n",
      "\n",
      "Fold: 1  Epoch: 335  Training loss = 3.2391  Validation loss = 3.3327  \n",
      "\n",
      "Fold: 1  Epoch: 336  Training loss = 3.2387  Validation loss = 3.3321  \n",
      "\n",
      "Fold: 1  Epoch: 337  Training loss = 3.2383  Validation loss = 3.3315  \n",
      "\n",
      "Fold: 1  Epoch: 338  Training loss = 3.2380  Validation loss = 3.3308  \n",
      "\n",
      "Fold: 1  Epoch: 339  Training loss = 3.2376  Validation loss = 3.3303  \n",
      "\n",
      "Fold: 1  Epoch: 340  Training loss = 3.2373  Validation loss = 3.3298  \n",
      "\n",
      "Fold: 1  Epoch: 341  Training loss = 3.2371  Validation loss = 3.3293  \n",
      "\n",
      "Fold: 1  Epoch: 342  Training loss = 3.2367  Validation loss = 3.3288  \n",
      "\n",
      "Fold: 1  Epoch: 343  Training loss = 3.2365  Validation loss = 3.3284  \n",
      "\n",
      "Fold: 1  Epoch: 344  Training loss = 3.2362  Validation loss = 3.3278  \n",
      "\n",
      "Fold: 1  Epoch: 345  Training loss = 3.2359  Validation loss = 3.3274  \n",
      "\n",
      "Fold: 1  Epoch: 346  Training loss = 3.2356  Validation loss = 3.3269  \n",
      "\n",
      "Fold: 1  Epoch: 347  Training loss = 3.2354  Validation loss = 3.3265  \n",
      "\n",
      "Fold: 1  Epoch: 348  Training loss = 3.2351  Validation loss = 3.3260  \n",
      "\n",
      "Fold: 1  Epoch: 349  Training loss = 3.2347  Validation loss = 3.3255  \n",
      "\n",
      "Fold: 1  Epoch: 350  Training loss = 3.2345  Validation loss = 3.3250  \n",
      "\n",
      "Fold: 1  Epoch: 351  Training loss = 3.2342  Validation loss = 3.3245  \n",
      "\n",
      "Fold: 1  Epoch: 352  Training loss = 3.2339  Validation loss = 3.3241  \n",
      "\n",
      "Fold: 1  Epoch: 353  Training loss = 3.2337  Validation loss = 3.3236  \n",
      "\n",
      "Fold: 1  Epoch: 354  Training loss = 3.2334  Validation loss = 3.3232  \n",
      "\n",
      "Fold: 1  Epoch: 355  Training loss = 3.2331  Validation loss = 3.3226  \n",
      "\n",
      "Fold: 1  Epoch: 356  Training loss = 3.2328  Validation loss = 3.3221  \n",
      "\n",
      "Fold: 1  Epoch: 357  Training loss = 3.2324  Validation loss = 3.3215  \n",
      "\n",
      "Fold: 1  Epoch: 358  Training loss = 3.2321  Validation loss = 3.3209  \n",
      "\n",
      "Fold: 1  Epoch: 359  Training loss = 3.2317  Validation loss = 3.3203  \n",
      "\n",
      "Fold: 1  Epoch: 360  Training loss = 3.2315  Validation loss = 3.3199  \n",
      "\n",
      "Fold: 1  Epoch: 361  Training loss = 3.2311  Validation loss = 3.3193  \n",
      "\n",
      "Fold: 1  Epoch: 362  Training loss = 3.2309  Validation loss = 3.3189  \n",
      "\n",
      "Fold: 1  Epoch: 363  Training loss = 3.2306  Validation loss = 3.3185  \n",
      "\n",
      "Fold: 1  Epoch: 364  Training loss = 3.2304  Validation loss = 3.3180  \n",
      "\n",
      "Fold: 1  Epoch: 365  Training loss = 3.2301  Validation loss = 3.3175  \n",
      "\n",
      "Fold: 1  Epoch: 366  Training loss = 3.2298  Validation loss = 3.3170  \n",
      "\n",
      "Fold: 1  Epoch: 367  Training loss = 3.2295  Validation loss = 3.3166  \n",
      "\n",
      "Fold: 1  Epoch: 368  Training loss = 3.2293  Validation loss = 3.3162  \n",
      "\n",
      "Fold: 1  Epoch: 369  Training loss = 3.2290  Validation loss = 3.3156  \n",
      "\n",
      "Fold: 1  Epoch: 370  Training loss = 3.2286  Validation loss = 3.3151  \n",
      "\n",
      "Fold: 1  Epoch: 371  Training loss = 3.2283  Validation loss = 3.3145  \n",
      "\n",
      "Fold: 1  Epoch: 372  Training loss = 3.2281  Validation loss = 3.3141  \n",
      "\n",
      "Fold: 1  Epoch: 373  Training loss = 3.2278  Validation loss = 3.3136  \n",
      "\n",
      "Fold: 1  Epoch: 374  Training loss = 3.2275  Validation loss = 3.3132  \n",
      "\n",
      "Fold: 1  Epoch: 375  Training loss = 3.2272  Validation loss = 3.3127  \n",
      "\n",
      "Fold: 1  Epoch: 376  Training loss = 3.2269  Validation loss = 3.3122  \n",
      "\n",
      "Fold: 1  Epoch: 377  Training loss = 3.2265  Validation loss = 3.3115  \n",
      "\n",
      "Fold: 1  Epoch: 378  Training loss = 3.2263  Validation loss = 3.3111  \n",
      "\n",
      "Fold: 1  Epoch: 379  Training loss = 3.2260  Validation loss = 3.3106  \n",
      "\n",
      "Fold: 1  Epoch: 380  Training loss = 3.2256  Validation loss = 3.3100  \n",
      "\n",
      "Fold: 1  Epoch: 381  Training loss = 3.2254  Validation loss = 3.3096  \n",
      "\n",
      "Fold: 1  Epoch: 382  Training loss = 3.2251  Validation loss = 3.3091  \n",
      "\n",
      "Fold: 1  Epoch: 383  Training loss = 3.2247  Validation loss = 3.3085  \n",
      "\n",
      "Fold: 1  Epoch: 384  Training loss = 3.2244  Validation loss = 3.3080  \n",
      "\n",
      "Fold: 1  Epoch: 385  Training loss = 3.2242  Validation loss = 3.3075  \n",
      "\n",
      "Fold: 1  Epoch: 386  Training loss = 3.2239  Validation loss = 3.3071  \n",
      "\n",
      "Fold: 1  Epoch: 387  Training loss = 3.2235  Validation loss = 3.3065  \n",
      "\n",
      "Fold: 1  Epoch: 388  Training loss = 3.2234  Validation loss = 3.3062  \n",
      "\n",
      "Fold: 1  Epoch: 389  Training loss = 3.2230  Validation loss = 3.3055  \n",
      "\n",
      "Fold: 1  Epoch: 390  Training loss = 3.2226  Validation loss = 3.3050  \n",
      "\n",
      "Fold: 1  Epoch: 391  Training loss = 3.2224  Validation loss = 3.3045  \n",
      "\n",
      "Fold: 1  Epoch: 392  Training loss = 3.2221  Validation loss = 3.3041  \n",
      "\n",
      "Fold: 1  Epoch: 393  Training loss = 3.2219  Validation loss = 3.3037  \n",
      "\n",
      "Fold: 1  Epoch: 394  Training loss = 3.2216  Validation loss = 3.3033  \n",
      "\n",
      "Fold: 1  Epoch: 395  Training loss = 3.2213  Validation loss = 3.3027  \n",
      "\n",
      "Fold: 1  Epoch: 396  Training loss = 3.2209  Validation loss = 3.3021  \n",
      "\n",
      "Fold: 1  Epoch: 397  Training loss = 3.2206  Validation loss = 3.3015  \n",
      "\n",
      "Fold: 1  Epoch: 398  Training loss = 3.2202  Validation loss = 3.3009  \n",
      "\n",
      "Fold: 1  Epoch: 399  Training loss = 3.2199  Validation loss = 3.3004  \n",
      "\n",
      "Fold: 1  Epoch: 400  Training loss = 3.2196  Validation loss = 3.2998  \n",
      "\n",
      "Fold: 1  Epoch: 401  Training loss = 3.2193  Validation loss = 3.2993  \n",
      "\n",
      "Fold: 1  Epoch: 402  Training loss = 3.2190  Validation loss = 3.2988  \n",
      "\n",
      "Fold: 1  Epoch: 403  Training loss = 3.2188  Validation loss = 3.2984  \n",
      "\n",
      "Fold: 1  Epoch: 404  Training loss = 3.2185  Validation loss = 3.2979  \n",
      "\n",
      "Fold: 1  Epoch: 405  Training loss = 3.2182  Validation loss = 3.2974  \n",
      "\n",
      "Fold: 1  Epoch: 406  Training loss = 3.2179  Validation loss = 3.2969  \n",
      "\n",
      "Fold: 1  Epoch: 407  Training loss = 3.2177  Validation loss = 3.2966  \n",
      "\n",
      "Fold: 1  Epoch: 408  Training loss = 3.2174  Validation loss = 3.2961  \n",
      "\n",
      "Fold: 1  Epoch: 409  Training loss = 3.2171  Validation loss = 3.2956  \n",
      "\n",
      "Fold: 1  Epoch: 410  Training loss = 3.2168  Validation loss = 3.2951  \n",
      "\n",
      "Fold: 1  Epoch: 411  Training loss = 3.2166  Validation loss = 3.2946  \n",
      "\n",
      "Fold: 1  Epoch: 412  Training loss = 3.2163  Validation loss = 3.2942  \n",
      "\n",
      "Fold: 1  Epoch: 413  Training loss = 3.2161  Validation loss = 3.2938  \n",
      "\n",
      "Fold: 1  Epoch: 414  Training loss = 3.2157  Validation loss = 3.2931  \n",
      "\n",
      "Fold: 1  Epoch: 415  Training loss = 3.2153  Validation loss = 3.2924  \n",
      "\n",
      "Fold: 1  Epoch: 416  Training loss = 3.2150  Validation loss = 3.2919  \n",
      "\n",
      "Fold: 1  Epoch: 417  Training loss = 3.2147  Validation loss = 3.2914  \n",
      "\n",
      "Fold: 1  Epoch: 418  Training loss = 3.2144  Validation loss = 3.2909  \n",
      "\n",
      "Fold: 1  Epoch: 419  Training loss = 3.2141  Validation loss = 3.2903  \n",
      "\n",
      "Fold: 1  Epoch: 420  Training loss = 3.2138  Validation loss = 3.2899  \n",
      "\n",
      "Fold: 1  Epoch: 421  Training loss = 3.2136  Validation loss = 3.2894  \n",
      "\n",
      "Fold: 1  Epoch: 422  Training loss = 3.2133  Validation loss = 3.2890  \n",
      "\n",
      "Fold: 1  Epoch: 423  Training loss = 3.2130  Validation loss = 3.2885  \n",
      "\n",
      "Fold: 1  Epoch: 424  Training loss = 3.2126  Validation loss = 3.2879  \n",
      "\n",
      "Fold: 1  Epoch: 425  Training loss = 3.2124  Validation loss = 3.2874  \n",
      "\n",
      "Fold: 1  Epoch: 426  Training loss = 3.2121  Validation loss = 3.2869  \n",
      "\n",
      "Fold: 1  Epoch: 427  Training loss = 3.2117  Validation loss = 3.2862  \n",
      "\n",
      "Fold: 1  Epoch: 428  Training loss = 3.2114  Validation loss = 3.2858  \n",
      "\n",
      "Fold: 1  Epoch: 429  Training loss = 3.2112  Validation loss = 3.2854  \n",
      "\n",
      "Fold: 1  Epoch: 430  Training loss = 3.2109  Validation loss = 3.2849  \n",
      "\n",
      "Fold: 1  Epoch: 431  Training loss = 3.2107  Validation loss = 3.2845  \n",
      "\n",
      "Fold: 1  Epoch: 432  Training loss = 3.2104  Validation loss = 3.2840  \n",
      "\n",
      "Fold: 1  Epoch: 433  Training loss = 3.2100  Validation loss = 3.2834  \n",
      "\n",
      "Fold: 1  Epoch: 434  Training loss = 3.2098  Validation loss = 3.2829  \n",
      "\n",
      "Fold: 1  Epoch: 435  Training loss = 3.2094  Validation loss = 3.2824  \n",
      "\n",
      "Fold: 1  Epoch: 436  Training loss = 3.2092  Validation loss = 3.2820  \n",
      "\n",
      "Fold: 1  Epoch: 437  Training loss = 3.2090  Validation loss = 3.2817  \n",
      "\n",
      "Fold: 1  Epoch: 438  Training loss = 3.2087  Validation loss = 3.2811  \n",
      "\n",
      "Fold: 1  Epoch: 439  Training loss = 3.2083  Validation loss = 3.2804  \n",
      "\n",
      "Fold: 1  Epoch: 440  Training loss = 3.2078  Validation loss = 3.2797  \n",
      "\n",
      "Fold: 1  Epoch: 441  Training loss = 3.2075  Validation loss = 3.2791  \n",
      "\n",
      "Fold: 1  Epoch: 442  Training loss = 3.2072  Validation loss = 3.2786  \n",
      "\n",
      "Fold: 1  Epoch: 443  Training loss = 3.2070  Validation loss = 3.2782  \n",
      "\n",
      "Fold: 1  Epoch: 444  Training loss = 3.2067  Validation loss = 3.2778  \n",
      "\n",
      "Fold: 1  Epoch: 445  Training loss = 3.2065  Validation loss = 3.2774  \n",
      "\n",
      "Fold: 1  Epoch: 446  Training loss = 3.2062  Validation loss = 3.2768  \n",
      "\n",
      "Fold: 1  Epoch: 447  Training loss = 3.2059  Validation loss = 3.2764  \n",
      "\n",
      "Fold: 1  Epoch: 448  Training loss = 3.2056  Validation loss = 3.2759  \n",
      "\n",
      "Fold: 1  Epoch: 449  Training loss = 3.2053  Validation loss = 3.2753  \n",
      "\n",
      "Fold: 1  Epoch: 450  Training loss = 3.2050  Validation loss = 3.2748  \n",
      "\n",
      "Fold: 1  Epoch: 451  Training loss = 3.2046  Validation loss = 3.2742  \n",
      "\n",
      "Fold: 1  Epoch: 452  Training loss = 3.2044  Validation loss = 3.2739  \n",
      "\n",
      "Fold: 1  Epoch: 453  Training loss = 3.2042  Validation loss = 3.2735  \n",
      "\n",
      "Fold: 1  Epoch: 454  Training loss = 3.2038  Validation loss = 3.2729  \n",
      "\n",
      "Fold: 1  Epoch: 455  Training loss = 3.2035  Validation loss = 3.2723  \n",
      "\n",
      "Fold: 1  Epoch: 456  Training loss = 3.2032  Validation loss = 3.2717  \n",
      "\n",
      "Fold: 1  Epoch: 457  Training loss = 3.2028  Validation loss = 3.2712  \n",
      "\n",
      "Fold: 1  Epoch: 458  Training loss = 3.2026  Validation loss = 3.2708  \n",
      "\n",
      "Fold: 1  Epoch: 459  Training loss = 3.2022  Validation loss = 3.2702  \n",
      "\n",
      "Fold: 1  Epoch: 460  Training loss = 3.2020  Validation loss = 3.2698  \n",
      "\n",
      "Fold: 1  Epoch: 461  Training loss = 3.2017  Validation loss = 3.2693  \n",
      "\n",
      "Fold: 1  Epoch: 462  Training loss = 3.2013  Validation loss = 3.2685  \n",
      "\n",
      "Fold: 1  Epoch: 463  Training loss = 3.2010  Validation loss = 3.2681  \n",
      "\n",
      "Fold: 1  Epoch: 464  Training loss = 3.2008  Validation loss = 3.2678  \n",
      "\n",
      "Fold: 1  Epoch: 465  Training loss = 3.2005  Validation loss = 3.2672  \n",
      "\n",
      "Fold: 1  Epoch: 466  Training loss = 3.2001  Validation loss = 3.2666  \n",
      "\n",
      "Fold: 1  Epoch: 467  Training loss = 3.1998  Validation loss = 3.2660  \n",
      "\n",
      "Fold: 1  Epoch: 468  Training loss = 3.1995  Validation loss = 3.2655  \n",
      "\n",
      "Fold: 1  Epoch: 469  Training loss = 3.1993  Validation loss = 3.2651  \n",
      "\n",
      "Fold: 1  Epoch: 470  Training loss = 3.1991  Validation loss = 3.2647  \n",
      "\n",
      "Fold: 1  Epoch: 471  Training loss = 3.1988  Validation loss = 3.2642  \n",
      "\n",
      "Fold: 1  Epoch: 472  Training loss = 3.1985  Validation loss = 3.2638  \n",
      "\n",
      "Fold: 1  Epoch: 473  Training loss = 3.1983  Validation loss = 3.2633  \n",
      "\n",
      "Fold: 1  Epoch: 474  Training loss = 3.1979  Validation loss = 3.2627  \n",
      "\n",
      "Fold: 1  Epoch: 475  Training loss = 3.1977  Validation loss = 3.2624  \n",
      "\n",
      "Fold: 1  Epoch: 476  Training loss = 3.1974  Validation loss = 3.2619  \n",
      "\n",
      "Fold: 1  Epoch: 477  Training loss = 3.1972  Validation loss = 3.2615  \n",
      "\n",
      "Fold: 1  Epoch: 478  Training loss = 3.1969  Validation loss = 3.2609  \n",
      "\n",
      "Fold: 1  Epoch: 479  Training loss = 3.1966  Validation loss = 3.2605  \n",
      "\n",
      "Fold: 1  Epoch: 480  Training loss = 3.1963  Validation loss = 3.2600  \n",
      "\n",
      "Fold: 1  Epoch: 481  Training loss = 3.1961  Validation loss = 3.2595  \n",
      "\n",
      "Fold: 1  Epoch: 482  Training loss = 3.1958  Validation loss = 3.2590  \n",
      "\n",
      "Fold: 1  Epoch: 483  Training loss = 3.1955  Validation loss = 3.2586  \n",
      "\n",
      "Fold: 1  Epoch: 484  Training loss = 3.1953  Validation loss = 3.2582  \n",
      "\n",
      "Fold: 1  Epoch: 485  Training loss = 3.1950  Validation loss = 3.2577  \n",
      "\n",
      "Fold: 1  Epoch: 486  Training loss = 3.1948  Validation loss = 3.2574  \n",
      "\n",
      "Fold: 1  Epoch: 487  Training loss = 3.1945  Validation loss = 3.2568  \n",
      "\n",
      "Fold: 1  Epoch: 488  Training loss = 3.1942  Validation loss = 3.2563  \n",
      "\n",
      "Fold: 1  Epoch: 489  Training loss = 3.1940  Validation loss = 3.2559  \n",
      "\n",
      "Fold: 1  Epoch: 490  Training loss = 3.1937  Validation loss = 3.2554  \n",
      "\n",
      "Fold: 1  Epoch: 491  Training loss = 3.1934  Validation loss = 3.2549  \n",
      "\n",
      "Fold: 1  Epoch: 492  Training loss = 3.1932  Validation loss = 3.2546  \n",
      "\n",
      "Fold: 1  Epoch: 493  Training loss = 3.1929  Validation loss = 3.2541  \n",
      "\n",
      "Fold: 1  Epoch: 494  Training loss = 3.1926  Validation loss = 3.2536  \n",
      "\n",
      "Fold: 1  Epoch: 495  Training loss = 3.1924  Validation loss = 3.2532  \n",
      "\n",
      "Fold: 1  Epoch: 496  Training loss = 3.1921  Validation loss = 3.2527  \n",
      "\n",
      "Fold: 1  Epoch: 497  Training loss = 3.1918  Validation loss = 3.2521  \n",
      "\n",
      "Fold: 1  Epoch: 498  Training loss = 3.1914  Validation loss = 3.2515  \n",
      "\n",
      "Fold: 1  Epoch: 499  Training loss = 3.1911  Validation loss = 3.2510  \n",
      "\n",
      "Fold: 1  Epoch: 500  Training loss = 3.1908  Validation loss = 3.2505  \n",
      "\n",
      "Check model:  Fold: 1  Optimal epoch: 500  \n",
      "\n",
      "Fold: 2  Epoch: 1  Training loss = 3.1287  Validation loss = 3.0427  \n",
      "\n",
      "Fold: 2  Epoch: 2  Training loss = 3.1282  Validation loss = 3.0422  \n",
      "\n",
      "Fold: 2  Epoch: 3  Training loss = 3.1278  Validation loss = 3.0416  \n",
      "\n",
      "Fold: 2  Epoch: 4  Training loss = 3.1275  Validation loss = 3.0411  \n",
      "\n",
      "Fold: 2  Epoch: 5  Training loss = 3.1272  Validation loss = 3.0407  \n",
      "\n",
      "Fold: 2  Epoch: 6  Training loss = 3.1268  Validation loss = 3.0403  \n",
      "\n",
      "Fold: 2  Epoch: 7  Training loss = 3.1266  Validation loss = 3.0399  \n",
      "\n",
      "Fold: 2  Epoch: 8  Training loss = 3.1263  Validation loss = 3.0395  \n",
      "\n",
      "Fold: 2  Epoch: 9  Training loss = 3.1260  Validation loss = 3.0391  \n",
      "\n",
      "Fold: 2  Epoch: 10  Training loss = 3.1257  Validation loss = 3.0387  \n",
      "\n",
      "Fold: 2  Epoch: 11  Training loss = 3.1254  Validation loss = 3.0383  \n",
      "\n",
      "Fold: 2  Epoch: 12  Training loss = 3.1251  Validation loss = 3.0378  \n",
      "\n",
      "Fold: 2  Epoch: 13  Training loss = 3.1247  Validation loss = 3.0374  \n",
      "\n",
      "Fold: 2  Epoch: 14  Training loss = 3.1244  Validation loss = 3.0370  \n",
      "\n",
      "Fold: 2  Epoch: 15  Training loss = 3.1240  Validation loss = 3.0365  \n",
      "\n",
      "Fold: 2  Epoch: 16  Training loss = 3.1237  Validation loss = 3.0361  \n",
      "\n",
      "Fold: 2  Epoch: 17  Training loss = 3.1233  Validation loss = 3.0356  \n",
      "\n",
      "Fold: 2  Epoch: 18  Training loss = 3.1230  Validation loss = 3.0351  \n",
      "\n",
      "Fold: 2  Epoch: 19  Training loss = 3.1227  Validation loss = 3.0348  \n",
      "\n",
      "Fold: 2  Epoch: 20  Training loss = 3.1225  Validation loss = 3.0344  \n",
      "\n",
      "Fold: 2  Epoch: 21  Training loss = 3.1221  Validation loss = 3.0340  \n",
      "\n",
      "Fold: 2  Epoch: 22  Training loss = 3.1219  Validation loss = 3.0337  \n",
      "\n",
      "Fold: 2  Epoch: 23  Training loss = 3.1217  Validation loss = 3.0333  \n",
      "\n",
      "Fold: 2  Epoch: 24  Training loss = 3.1213  Validation loss = 3.0327  \n",
      "\n",
      "Fold: 2  Epoch: 25  Training loss = 3.1209  Validation loss = 3.0323  \n",
      "\n",
      "Fold: 2  Epoch: 26  Training loss = 3.1206  Validation loss = 3.0319  \n",
      "\n",
      "Fold: 2  Epoch: 27  Training loss = 3.1203  Validation loss = 3.0314  \n",
      "\n",
      "Fold: 2  Epoch: 28  Training loss = 3.1200  Validation loss = 3.0310  \n",
      "\n",
      "Fold: 2  Epoch: 29  Training loss = 3.1197  Validation loss = 3.0306  \n",
      "\n",
      "Fold: 2  Epoch: 30  Training loss = 3.1195  Validation loss = 3.0303  \n",
      "\n",
      "Fold: 2  Epoch: 31  Training loss = 3.1191  Validation loss = 3.0299  \n",
      "\n",
      "Fold: 2  Epoch: 32  Training loss = 3.1189  Validation loss = 3.0296  \n",
      "\n",
      "Fold: 2  Epoch: 33  Training loss = 3.1186  Validation loss = 3.0292  \n",
      "\n",
      "Fold: 2  Epoch: 34  Training loss = 3.1183  Validation loss = 3.0287  \n",
      "\n",
      "Fold: 2  Epoch: 35  Training loss = 3.1180  Validation loss = 3.0284  \n",
      "\n",
      "Fold: 2  Epoch: 36  Training loss = 3.1176  Validation loss = 3.0279  \n",
      "\n",
      "Fold: 2  Epoch: 37  Training loss = 3.1172  Validation loss = 3.0274  \n",
      "\n",
      "Fold: 2  Epoch: 38  Training loss = 3.1170  Validation loss = 3.0270  \n",
      "\n",
      "Fold: 2  Epoch: 39  Training loss = 3.1166  Validation loss = 3.0265  \n",
      "\n",
      "Fold: 2  Epoch: 40  Training loss = 3.1164  Validation loss = 3.0261  \n",
      "\n",
      "Fold: 2  Epoch: 41  Training loss = 3.1160  Validation loss = 3.0257  \n",
      "\n",
      "Fold: 2  Epoch: 42  Training loss = 3.1157  Validation loss = 3.0253  \n",
      "\n",
      "Fold: 2  Epoch: 43  Training loss = 3.1154  Validation loss = 3.0248  \n",
      "\n",
      "Fold: 2  Epoch: 44  Training loss = 3.1151  Validation loss = 3.0244  \n",
      "\n",
      "Fold: 2  Epoch: 45  Training loss = 3.1147  Validation loss = 3.0240  \n",
      "\n",
      "Fold: 2  Epoch: 46  Training loss = 3.1145  Validation loss = 3.0236  \n",
      "\n",
      "Fold: 2  Epoch: 47  Training loss = 3.1142  Validation loss = 3.0232  \n",
      "\n",
      "Fold: 2  Epoch: 48  Training loss = 3.1138  Validation loss = 3.0228  \n",
      "\n",
      "Fold: 2  Epoch: 49  Training loss = 3.1135  Validation loss = 3.0223  \n",
      "\n",
      "Fold: 2  Epoch: 50  Training loss = 3.1132  Validation loss = 3.0219  \n",
      "\n",
      "Fold: 2  Epoch: 51  Training loss = 3.1130  Validation loss = 3.0216  \n",
      "\n",
      "Fold: 2  Epoch: 52  Training loss = 3.1127  Validation loss = 3.0212  \n",
      "\n",
      "Fold: 2  Epoch: 53  Training loss = 3.1124  Validation loss = 3.0209  \n",
      "\n",
      "Fold: 2  Epoch: 54  Training loss = 3.1122  Validation loss = 3.0205  \n",
      "\n",
      "Fold: 2  Epoch: 55  Training loss = 3.1119  Validation loss = 3.0201  \n",
      "\n",
      "Fold: 2  Epoch: 56  Training loss = 3.1116  Validation loss = 3.0197  \n",
      "\n",
      "Fold: 2  Epoch: 57  Training loss = 3.1113  Validation loss = 3.0193  \n",
      "\n",
      "Fold: 2  Epoch: 58  Training loss = 3.1110  Validation loss = 3.0189  \n",
      "\n",
      "Fold: 2  Epoch: 59  Training loss = 3.1107  Validation loss = 3.0184  \n",
      "\n",
      "Fold: 2  Epoch: 60  Training loss = 3.1104  Validation loss = 3.0181  \n",
      "\n",
      "Fold: 2  Epoch: 61  Training loss = 3.1101  Validation loss = 3.0176  \n",
      "\n",
      "Fold: 2  Epoch: 62  Training loss = 3.1097  Validation loss = 3.0172  \n",
      "\n",
      "Fold: 2  Epoch: 63  Training loss = 3.1094  Validation loss = 3.0167  \n",
      "\n",
      "Fold: 2  Epoch: 64  Training loss = 3.1090  Validation loss = 3.0163  \n",
      "\n",
      "Fold: 2  Epoch: 65  Training loss = 3.1086  Validation loss = 3.0157  \n",
      "\n",
      "Fold: 2  Epoch: 66  Training loss = 3.1082  Validation loss = 3.0152  \n",
      "\n",
      "Fold: 2  Epoch: 67  Training loss = 3.1078  Validation loss = 3.0148  \n",
      "\n",
      "Fold: 2  Epoch: 68  Training loss = 3.1075  Validation loss = 3.0142  \n",
      "\n",
      "Fold: 2  Epoch: 69  Training loss = 3.1071  Validation loss = 3.0138  \n",
      "\n",
      "Fold: 2  Epoch: 70  Training loss = 3.1068  Validation loss = 3.0134  \n",
      "\n",
      "Fold: 2  Epoch: 71  Training loss = 3.1066  Validation loss = 3.0131  \n",
      "\n",
      "Fold: 2  Epoch: 72  Training loss = 3.1062  Validation loss = 3.0126  \n",
      "\n",
      "Fold: 2  Epoch: 73  Training loss = 3.1059  Validation loss = 3.0123  \n",
      "\n",
      "Fold: 2  Epoch: 74  Training loss = 3.1056  Validation loss = 3.0119  \n",
      "\n",
      "Fold: 2  Epoch: 75  Training loss = 3.1054  Validation loss = 3.0115  \n",
      "\n",
      "Fold: 2  Epoch: 76  Training loss = 3.1050  Validation loss = 3.0110  \n",
      "\n",
      "Fold: 2  Epoch: 77  Training loss = 3.1047  Validation loss = 3.0105  \n",
      "\n",
      "Fold: 2  Epoch: 78  Training loss = 3.1044  Validation loss = 3.0102  \n",
      "\n",
      "Fold: 2  Epoch: 79  Training loss = 3.1042  Validation loss = 3.0098  \n",
      "\n",
      "Fold: 2  Epoch: 80  Training loss = 3.1038  Validation loss = 3.0094  \n",
      "\n",
      "Fold: 2  Epoch: 81  Training loss = 3.1036  Validation loss = 3.0090  \n",
      "\n",
      "Fold: 2  Epoch: 82  Training loss = 3.1032  Validation loss = 3.0086  \n",
      "\n",
      "Fold: 2  Epoch: 83  Training loss = 3.1029  Validation loss = 3.0082  \n",
      "\n",
      "Fold: 2  Epoch: 84  Training loss = 3.1026  Validation loss = 3.0078  \n",
      "\n",
      "Fold: 2  Epoch: 85  Training loss = 3.1021  Validation loss = 3.0072  \n",
      "\n",
      "Fold: 2  Epoch: 86  Training loss = 3.1018  Validation loss = 3.0067  \n",
      "\n",
      "Fold: 2  Epoch: 87  Training loss = 3.1015  Validation loss = 3.0063  \n",
      "\n",
      "Fold: 2  Epoch: 88  Training loss = 3.1012  Validation loss = 3.0059  \n",
      "\n",
      "Fold: 2  Epoch: 89  Training loss = 3.1009  Validation loss = 3.0054  \n",
      "\n",
      "Fold: 2  Epoch: 90  Training loss = 3.1005  Validation loss = 3.0049  \n",
      "\n",
      "Fold: 2  Epoch: 91  Training loss = 3.1003  Validation loss = 3.0045  \n",
      "\n",
      "Fold: 2  Epoch: 92  Training loss = 3.1001  Validation loss = 3.0042  \n",
      "\n",
      "Fold: 2  Epoch: 93  Training loss = 3.0997  Validation loss = 3.0038  \n",
      "\n",
      "Fold: 2  Epoch: 94  Training loss = 3.0995  Validation loss = 3.0035  \n",
      "\n",
      "Fold: 2  Epoch: 95  Training loss = 3.0992  Validation loss = 3.0031  \n",
      "\n",
      "Fold: 2  Epoch: 96  Training loss = 3.0989  Validation loss = 3.0026  \n",
      "\n",
      "Fold: 2  Epoch: 97  Training loss = 3.0987  Validation loss = 3.0023  \n",
      "\n",
      "Fold: 2  Epoch: 98  Training loss = 3.0984  Validation loss = 3.0019  \n",
      "\n",
      "Fold: 2  Epoch: 99  Training loss = 3.0981  Validation loss = 3.0015  \n",
      "\n",
      "Fold: 2  Epoch: 100  Training loss = 3.0978  Validation loss = 3.0011  \n",
      "\n",
      "Fold: 2  Epoch: 101  Training loss = 3.0975  Validation loss = 3.0007  \n",
      "\n",
      "Fold: 2  Epoch: 102  Training loss = 3.0971  Validation loss = 3.0002  \n",
      "\n",
      "Fold: 2  Epoch: 103  Training loss = 3.0968  Validation loss = 2.9998  \n",
      "\n",
      "Fold: 2  Epoch: 104  Training loss = 3.0965  Validation loss = 2.9995  \n",
      "\n",
      "Fold: 2  Epoch: 105  Training loss = 3.0963  Validation loss = 2.9991  \n",
      "\n",
      "Fold: 2  Epoch: 106  Training loss = 3.0959  Validation loss = 2.9986  \n",
      "\n",
      "Fold: 2  Epoch: 107  Training loss = 3.0956  Validation loss = 2.9982  \n",
      "\n",
      "Fold: 2  Epoch: 108  Training loss = 3.0953  Validation loss = 2.9978  \n",
      "\n",
      "Fold: 2  Epoch: 109  Training loss = 3.0950  Validation loss = 2.9974  \n",
      "\n",
      "Fold: 2  Epoch: 110  Training loss = 3.0947  Validation loss = 2.9969  \n",
      "\n",
      "Fold: 2  Epoch: 111  Training loss = 3.0945  Validation loss = 2.9966  \n",
      "\n",
      "Fold: 2  Epoch: 112  Training loss = 3.0942  Validation loss = 2.9962  \n",
      "\n",
      "Fold: 2  Epoch: 113  Training loss = 3.0939  Validation loss = 2.9957  \n",
      "\n",
      "Fold: 2  Epoch: 114  Training loss = 3.0935  Validation loss = 2.9953  \n",
      "\n",
      "Fold: 2  Epoch: 115  Training loss = 3.0932  Validation loss = 2.9949  \n",
      "\n",
      "Fold: 2  Epoch: 116  Training loss = 3.0929  Validation loss = 2.9945  \n",
      "\n",
      "Fold: 2  Epoch: 117  Training loss = 3.0926  Validation loss = 2.9941  \n",
      "\n",
      "Fold: 2  Epoch: 118  Training loss = 3.0924  Validation loss = 2.9937  \n",
      "\n",
      "Fold: 2  Epoch: 119  Training loss = 3.0921  Validation loss = 2.9934  \n",
      "\n",
      "Fold: 2  Epoch: 120  Training loss = 3.0919  Validation loss = 2.9930  \n",
      "\n",
      "Fold: 2  Epoch: 121  Training loss = 3.0916  Validation loss = 2.9926  \n",
      "\n",
      "Fold: 2  Epoch: 122  Training loss = 3.0911  Validation loss = 2.9920  \n",
      "\n",
      "Fold: 2  Epoch: 123  Training loss = 3.0909  Validation loss = 2.9917  \n",
      "\n",
      "Fold: 2  Epoch: 124  Training loss = 3.0906  Validation loss = 2.9913  \n",
      "\n",
      "Fold: 2  Epoch: 125  Training loss = 3.0903  Validation loss = 2.9909  \n",
      "\n",
      "Fold: 2  Epoch: 126  Training loss = 3.0900  Validation loss = 2.9905  \n",
      "\n",
      "Fold: 2  Epoch: 127  Training loss = 3.0897  Validation loss = 2.9901  \n",
      "\n",
      "Fold: 2  Epoch: 128  Training loss = 3.0896  Validation loss = 2.9898  \n",
      "\n",
      "Fold: 2  Epoch: 129  Training loss = 3.0893  Validation loss = 2.9895  \n",
      "\n",
      "Fold: 2  Epoch: 130  Training loss = 3.0890  Validation loss = 2.9891  \n",
      "\n",
      "Fold: 2  Epoch: 131  Training loss = 3.0887  Validation loss = 2.9887  \n",
      "\n",
      "Fold: 2  Epoch: 132  Training loss = 3.0884  Validation loss = 2.9883  \n",
      "\n",
      "Fold: 2  Epoch: 133  Training loss = 3.0881  Validation loss = 2.9879  \n",
      "\n",
      "Fold: 2  Epoch: 134  Training loss = 3.0877  Validation loss = 2.9874  \n",
      "\n",
      "Fold: 2  Epoch: 135  Training loss = 3.0874  Validation loss = 2.9870  \n",
      "\n",
      "Fold: 2  Epoch: 136  Training loss = 3.0872  Validation loss = 2.9866  \n",
      "\n",
      "Fold: 2  Epoch: 137  Training loss = 3.0868  Validation loss = 2.9860  \n",
      "\n",
      "Fold: 2  Epoch: 138  Training loss = 3.0865  Validation loss = 2.9857  \n",
      "\n",
      "Fold: 2  Epoch: 139  Training loss = 3.0862  Validation loss = 2.9853  \n",
      "\n",
      "Fold: 2  Epoch: 140  Training loss = 3.0860  Validation loss = 2.9850  \n",
      "\n",
      "Fold: 2  Epoch: 141  Training loss = 3.0858  Validation loss = 2.9847  \n",
      "\n",
      "Fold: 2  Epoch: 142  Training loss = 3.0855  Validation loss = 2.9843  \n",
      "\n",
      "Fold: 2  Epoch: 143  Training loss = 3.0853  Validation loss = 2.9840  \n",
      "\n",
      "Fold: 2  Epoch: 144  Training loss = 3.0849  Validation loss = 2.9834  \n",
      "\n",
      "Fold: 2  Epoch: 145  Training loss = 3.0846  Validation loss = 2.9830  \n",
      "\n",
      "Fold: 2  Epoch: 146  Training loss = 3.0844  Validation loss = 2.9827  \n",
      "\n",
      "Fold: 2  Epoch: 147  Training loss = 3.0841  Validation loss = 2.9823  \n",
      "\n",
      "Fold: 2  Epoch: 148  Training loss = 3.0838  Validation loss = 2.9819  \n",
      "\n",
      "Fold: 2  Epoch: 149  Training loss = 3.0835  Validation loss = 2.9815  \n",
      "\n",
      "Fold: 2  Epoch: 150  Training loss = 3.0832  Validation loss = 2.9810  \n",
      "\n",
      "Fold: 2  Epoch: 151  Training loss = 3.0829  Validation loss = 2.9806  \n",
      "\n",
      "Fold: 2  Epoch: 152  Training loss = 3.0826  Validation loss = 2.9802  \n",
      "\n",
      "Fold: 2  Epoch: 153  Training loss = 3.0822  Validation loss = 2.9797  \n",
      "\n",
      "Fold: 2  Epoch: 154  Training loss = 3.0819  Validation loss = 2.9793  \n",
      "\n",
      "Fold: 2  Epoch: 155  Training loss = 3.0817  Validation loss = 2.9790  \n",
      "\n",
      "Fold: 2  Epoch: 156  Training loss = 3.0815  Validation loss = 2.9787  \n",
      "\n",
      "Fold: 2  Epoch: 157  Training loss = 3.0813  Validation loss = 2.9784  \n",
      "\n",
      "Fold: 2  Epoch: 158  Training loss = 3.0809  Validation loss = 2.9779  \n",
      "\n",
      "Fold: 2  Epoch: 159  Training loss = 3.0806  Validation loss = 2.9775  \n",
      "\n",
      "Fold: 2  Epoch: 160  Training loss = 3.0804  Validation loss = 2.9772  \n",
      "\n",
      "Fold: 2  Epoch: 161  Training loss = 3.0802  Validation loss = 2.9768  \n",
      "\n",
      "Fold: 2  Epoch: 162  Training loss = 3.0798  Validation loss = 2.9764  \n",
      "\n",
      "Fold: 2  Epoch: 163  Training loss = 3.0795  Validation loss = 2.9760  \n",
      "\n",
      "Fold: 2  Epoch: 164  Training loss = 3.0792  Validation loss = 2.9756  \n",
      "\n",
      "Fold: 2  Epoch: 165  Training loss = 3.0789  Validation loss = 2.9751  \n",
      "\n",
      "Fold: 2  Epoch: 166  Training loss = 3.0786  Validation loss = 2.9747  \n",
      "\n",
      "Fold: 2  Epoch: 167  Training loss = 3.0783  Validation loss = 2.9743  \n",
      "\n",
      "Fold: 2  Epoch: 168  Training loss = 3.0781  Validation loss = 2.9740  \n",
      "\n",
      "Fold: 2  Epoch: 169  Training loss = 3.0779  Validation loss = 2.9737  \n",
      "\n",
      "Fold: 2  Epoch: 170  Training loss = 3.0775  Validation loss = 2.9732  \n",
      "\n",
      "Fold: 2  Epoch: 171  Training loss = 3.0772  Validation loss = 2.9728  \n",
      "\n",
      "Fold: 2  Epoch: 172  Training loss = 3.0769  Validation loss = 2.9723  \n",
      "\n",
      "Fold: 2  Epoch: 173  Training loss = 3.0765  Validation loss = 2.9718  \n",
      "\n",
      "Fold: 2  Epoch: 174  Training loss = 3.0762  Validation loss = 2.9714  \n",
      "\n",
      "Fold: 2  Epoch: 175  Training loss = 3.0760  Validation loss = 2.9711  \n",
      "\n",
      "Fold: 2  Epoch: 176  Training loss = 3.0757  Validation loss = 2.9707  \n",
      "\n",
      "Fold: 2  Epoch: 177  Training loss = 3.0754  Validation loss = 2.9703  \n",
      "\n",
      "Fold: 2  Epoch: 178  Training loss = 3.0752  Validation loss = 2.9699  \n",
      "\n",
      "Fold: 2  Epoch: 179  Training loss = 3.0749  Validation loss = 2.9695  \n",
      "\n",
      "Fold: 2  Epoch: 180  Training loss = 3.0745  Validation loss = 2.9691  \n",
      "\n",
      "Fold: 2  Epoch: 181  Training loss = 3.0743  Validation loss = 2.9687  \n",
      "\n",
      "Fold: 2  Epoch: 182  Training loss = 3.0740  Validation loss = 2.9683  \n",
      "\n",
      "Fold: 2  Epoch: 183  Training loss = 3.0738  Validation loss = 2.9680  \n",
      "\n",
      "Fold: 2  Epoch: 184  Training loss = 3.0736  Validation loss = 2.9676  \n",
      "\n",
      "Fold: 2  Epoch: 185  Training loss = 3.0733  Validation loss = 2.9673  \n",
      "\n",
      "Fold: 2  Epoch: 186  Training loss = 3.0730  Validation loss = 2.9669  \n",
      "\n",
      "Fold: 2  Epoch: 187  Training loss = 3.0728  Validation loss = 2.9666  \n",
      "\n",
      "Fold: 2  Epoch: 188  Training loss = 3.0725  Validation loss = 2.9662  \n",
      "\n",
      "Fold: 2  Epoch: 189  Training loss = 3.0721  Validation loss = 2.9657  \n",
      "\n",
      "Fold: 2  Epoch: 190  Training loss = 3.0718  Validation loss = 2.9653  \n",
      "\n",
      "Fold: 2  Epoch: 191  Training loss = 3.0716  Validation loss = 2.9649  \n",
      "\n",
      "Fold: 2  Epoch: 192  Training loss = 3.0714  Validation loss = 2.9646  \n",
      "\n",
      "Fold: 2  Epoch: 193  Training loss = 3.0712  Validation loss = 2.9643  \n",
      "\n",
      "Fold: 2  Epoch: 194  Training loss = 3.0709  Validation loss = 2.9639  \n",
      "\n",
      "Fold: 2  Epoch: 195  Training loss = 3.0706  Validation loss = 2.9636  \n",
      "\n",
      "Fold: 2  Epoch: 196  Training loss = 3.0704  Validation loss = 2.9632  \n",
      "\n",
      "Fold: 2  Epoch: 197  Training loss = 3.0701  Validation loss = 2.9628  \n",
      "\n",
      "Fold: 2  Epoch: 198  Training loss = 3.0699  Validation loss = 2.9625  \n",
      "\n",
      "Fold: 2  Epoch: 199  Training loss = 3.0696  Validation loss = 2.9621  \n",
      "\n",
      "Fold: 2  Epoch: 200  Training loss = 3.0693  Validation loss = 2.9617  \n",
      "\n",
      "Fold: 2  Epoch: 201  Training loss = 3.0691  Validation loss = 2.9614  \n",
      "\n",
      "Fold: 2  Epoch: 202  Training loss = 3.0688  Validation loss = 2.9611  \n",
      "\n",
      "Fold: 2  Epoch: 203  Training loss = 3.0686  Validation loss = 2.9607  \n",
      "\n",
      "Fold: 2  Epoch: 204  Training loss = 3.0684  Validation loss = 2.9604  \n",
      "\n",
      "Fold: 2  Epoch: 205  Training loss = 3.0680  Validation loss = 2.9599  \n",
      "\n",
      "Fold: 2  Epoch: 206  Training loss = 3.0678  Validation loss = 2.9595  \n",
      "\n",
      "Fold: 2  Epoch: 207  Training loss = 3.0675  Validation loss = 2.9592  \n",
      "\n",
      "Fold: 2  Epoch: 208  Training loss = 3.0672  Validation loss = 2.9587  \n",
      "\n",
      "Fold: 2  Epoch: 209  Training loss = 3.0668  Validation loss = 2.9583  \n",
      "\n",
      "Fold: 2  Epoch: 210  Training loss = 3.0665  Validation loss = 2.9579  \n",
      "\n",
      "Fold: 2  Epoch: 211  Training loss = 3.0663  Validation loss = 2.9576  \n",
      "\n",
      "Fold: 2  Epoch: 212  Training loss = 3.0661  Validation loss = 2.9573  \n",
      "\n",
      "Fold: 2  Epoch: 213  Training loss = 3.0658  Validation loss = 2.9568  \n",
      "\n",
      "Fold: 2  Epoch: 214  Training loss = 3.0653  Validation loss = 2.9562  \n",
      "\n",
      "Fold: 2  Epoch: 215  Training loss = 3.0650  Validation loss = 2.9558  \n",
      "\n",
      "Fold: 2  Epoch: 216  Training loss = 3.0647  Validation loss = 2.9554  \n",
      "\n",
      "Fold: 2  Epoch: 217  Training loss = 3.0644  Validation loss = 2.9550  \n",
      "\n",
      "Fold: 2  Epoch: 218  Training loss = 3.0642  Validation loss = 2.9546  \n",
      "\n",
      "Fold: 2  Epoch: 219  Training loss = 3.0638  Validation loss = 2.9542  \n",
      "\n",
      "Fold: 2  Epoch: 220  Training loss = 3.0636  Validation loss = 2.9538  \n",
      "\n",
      "Fold: 2  Epoch: 221  Training loss = 3.0632  Validation loss = 2.9533  \n",
      "\n",
      "Fold: 2  Epoch: 222  Training loss = 3.0629  Validation loss = 2.9529  \n",
      "\n",
      "Fold: 2  Epoch: 223  Training loss = 3.0627  Validation loss = 2.9526  \n",
      "\n",
      "Fold: 2  Epoch: 224  Training loss = 3.0623  Validation loss = 2.9521  \n",
      "\n",
      "Fold: 2  Epoch: 225  Training loss = 3.0619  Validation loss = 2.9516  \n",
      "\n",
      "Fold: 2  Epoch: 226  Training loss = 3.0616  Validation loss = 2.9512  \n",
      "\n",
      "Fold: 2  Epoch: 227  Training loss = 3.0613  Validation loss = 2.9508  \n",
      "\n",
      "Fold: 2  Epoch: 228  Training loss = 3.0610  Validation loss = 2.9504  \n",
      "\n",
      "Fold: 2  Epoch: 229  Training loss = 3.0607  Validation loss = 2.9500  \n",
      "\n",
      "Fold: 2  Epoch: 230  Training loss = 3.0604  Validation loss = 2.9496  \n",
      "\n",
      "Fold: 2  Epoch: 231  Training loss = 3.0600  Validation loss = 2.9490  \n",
      "\n",
      "Fold: 2  Epoch: 232  Training loss = 3.0598  Validation loss = 2.9487  \n",
      "\n",
      "Fold: 2  Epoch: 233  Training loss = 3.0595  Validation loss = 2.9483  \n",
      "\n",
      "Fold: 2  Epoch: 234  Training loss = 3.0591  Validation loss = 2.9478  \n",
      "\n",
      "Fold: 2  Epoch: 235  Training loss = 3.0589  Validation loss = 2.9475  \n",
      "\n",
      "Fold: 2  Epoch: 236  Training loss = 3.0587  Validation loss = 2.9472  \n",
      "\n",
      "Fold: 2  Epoch: 237  Training loss = 3.0583  Validation loss = 2.9468  \n",
      "\n",
      "Fold: 2  Epoch: 238  Training loss = 3.0580  Validation loss = 2.9464  \n",
      "\n",
      "Fold: 2  Epoch: 239  Training loss = 3.0577  Validation loss = 2.9459  \n",
      "\n",
      "Fold: 2  Epoch: 240  Training loss = 3.0574  Validation loss = 2.9455  \n",
      "\n",
      "Fold: 2  Epoch: 241  Training loss = 3.0570  Validation loss = 2.9450  \n",
      "\n",
      "Fold: 2  Epoch: 242  Training loss = 3.0568  Validation loss = 2.9446  \n",
      "\n",
      "Fold: 2  Epoch: 243  Training loss = 3.0566  Validation loss = 2.9443  \n",
      "\n",
      "Fold: 2  Epoch: 244  Training loss = 3.0563  Validation loss = 2.9439  \n",
      "\n",
      "Fold: 2  Epoch: 245  Training loss = 3.0561  Validation loss = 2.9436  \n",
      "\n",
      "Fold: 2  Epoch: 246  Training loss = 3.0558  Validation loss = 2.9432  \n",
      "\n",
      "Fold: 2  Epoch: 247  Training loss = 3.0555  Validation loss = 2.9428  \n",
      "\n",
      "Fold: 2  Epoch: 248  Training loss = 3.0552  Validation loss = 2.9424  \n",
      "\n",
      "Fold: 2  Epoch: 249  Training loss = 3.0550  Validation loss = 2.9421  \n",
      "\n",
      "Fold: 2  Epoch: 250  Training loss = 3.0547  Validation loss = 2.9417  \n",
      "\n",
      "Fold: 2  Epoch: 251  Training loss = 3.0544  Validation loss = 2.9412  \n",
      "\n",
      "Fold: 2  Epoch: 252  Training loss = 3.0540  Validation loss = 2.9407  \n",
      "\n",
      "Fold: 2  Epoch: 253  Training loss = 3.0538  Validation loss = 2.9404  \n",
      "\n",
      "Fold: 2  Epoch: 254  Training loss = 3.0535  Validation loss = 2.9400  \n",
      "\n",
      "Fold: 2  Epoch: 255  Training loss = 3.0532  Validation loss = 2.9396  \n",
      "\n",
      "Fold: 2  Epoch: 256  Training loss = 3.0530  Validation loss = 2.9393  \n",
      "\n",
      "Fold: 2  Epoch: 257  Training loss = 3.0527  Validation loss = 2.9389  \n",
      "\n",
      "Fold: 2  Epoch: 258  Training loss = 3.0525  Validation loss = 2.9386  \n",
      "\n",
      "Fold: 2  Epoch: 259  Training loss = 3.0522  Validation loss = 2.9382  \n",
      "\n",
      "Fold: 2  Epoch: 260  Training loss = 3.0519  Validation loss = 2.9377  \n",
      "\n",
      "Fold: 2  Epoch: 261  Training loss = 3.0516  Validation loss = 2.9373  \n",
      "\n",
      "Fold: 2  Epoch: 262  Training loss = 3.0514  Validation loss = 2.9370  \n",
      "\n",
      "Fold: 2  Epoch: 263  Training loss = 3.0512  Validation loss = 2.9367  \n",
      "\n",
      "Fold: 2  Epoch: 264  Training loss = 3.0508  Validation loss = 2.9362  \n",
      "\n",
      "Fold: 2  Epoch: 265  Training loss = 3.0505  Validation loss = 2.9358  \n",
      "\n",
      "Fold: 2  Epoch: 266  Training loss = 3.0502  Validation loss = 2.9353  \n",
      "\n",
      "Fold: 2  Epoch: 267  Training loss = 3.0499  Validation loss = 2.9349  \n",
      "\n",
      "Fold: 2  Epoch: 268  Training loss = 3.0496  Validation loss = 2.9345  \n",
      "\n",
      "Fold: 2  Epoch: 269  Training loss = 3.0495  Validation loss = 2.9343  \n",
      "\n",
      "Fold: 2  Epoch: 270  Training loss = 3.0492  Validation loss = 2.9339  \n",
      "\n",
      "Fold: 2  Epoch: 271  Training loss = 3.0489  Validation loss = 2.9335  \n",
      "\n",
      "Fold: 2  Epoch: 272  Training loss = 3.0486  Validation loss = 2.9331  \n",
      "\n",
      "Fold: 2  Epoch: 273  Training loss = 3.0484  Validation loss = 2.9328  \n",
      "\n",
      "Fold: 2  Epoch: 274  Training loss = 3.0481  Validation loss = 2.9325  \n",
      "\n",
      "Fold: 2  Epoch: 275  Training loss = 3.0480  Validation loss = 2.9322  \n",
      "\n",
      "Fold: 2  Epoch: 276  Training loss = 3.0477  Validation loss = 2.9318  \n",
      "\n",
      "Fold: 2  Epoch: 277  Training loss = 3.0474  Validation loss = 2.9314  \n",
      "\n",
      "Fold: 2  Epoch: 278  Training loss = 3.0472  Validation loss = 2.9311  \n",
      "\n",
      "Fold: 2  Epoch: 279  Training loss = 3.0469  Validation loss = 2.9306  \n",
      "\n",
      "Fold: 2  Epoch: 280  Training loss = 3.0466  Validation loss = 2.9303  \n",
      "\n",
      "Fold: 2  Epoch: 281  Training loss = 3.0463  Validation loss = 2.9299  \n",
      "\n",
      "Fold: 2  Epoch: 282  Training loss = 3.0460  Validation loss = 2.9295  \n",
      "\n",
      "Fold: 2  Epoch: 283  Training loss = 3.0458  Validation loss = 2.9291  \n",
      "\n",
      "Fold: 2  Epoch: 284  Training loss = 3.0456  Validation loss = 2.9288  \n",
      "\n",
      "Fold: 2  Epoch: 285  Training loss = 3.0453  Validation loss = 2.9284  \n",
      "\n",
      "Fold: 2  Epoch: 286  Training loss = 3.0450  Validation loss = 2.9280  \n",
      "\n",
      "Fold: 2  Epoch: 287  Training loss = 3.0448  Validation loss = 2.9276  \n",
      "\n",
      "Fold: 2  Epoch: 288  Training loss = 3.0446  Validation loss = 2.9274  \n",
      "\n",
      "Fold: 2  Epoch: 289  Training loss = 3.0443  Validation loss = 2.9270  \n",
      "\n",
      "Fold: 2  Epoch: 290  Training loss = 3.0440  Validation loss = 2.9266  \n",
      "\n",
      "Fold: 2  Epoch: 291  Training loss = 3.0438  Validation loss = 2.9263  \n",
      "\n",
      "Fold: 2  Epoch: 292  Training loss = 3.0436  Validation loss = 2.9260  \n",
      "\n",
      "Fold: 2  Epoch: 293  Training loss = 3.0433  Validation loss = 2.9256  \n",
      "\n",
      "Fold: 2  Epoch: 294  Training loss = 3.0431  Validation loss = 2.9253  \n",
      "\n",
      "Fold: 2  Epoch: 295  Training loss = 3.0429  Validation loss = 2.9250  \n",
      "\n",
      "Fold: 2  Epoch: 296  Training loss = 3.0426  Validation loss = 2.9245  \n",
      "\n",
      "Fold: 2  Epoch: 297  Training loss = 3.0423  Validation loss = 2.9241  \n",
      "\n",
      "Fold: 2  Epoch: 298  Training loss = 3.0420  Validation loss = 2.9237  \n",
      "\n",
      "Fold: 2  Epoch: 299  Training loss = 3.0418  Validation loss = 2.9234  \n",
      "\n",
      "Fold: 2  Epoch: 300  Training loss = 3.0415  Validation loss = 2.9231  \n",
      "\n",
      "Fold: 2  Epoch: 301  Training loss = 3.0413  Validation loss = 2.9227  \n",
      "\n",
      "Fold: 2  Epoch: 302  Training loss = 3.0410  Validation loss = 2.9223  \n",
      "\n",
      "Fold: 2  Epoch: 303  Training loss = 3.0407  Validation loss = 2.9219  \n",
      "\n",
      "Fold: 2  Epoch: 304  Training loss = 3.0403  Validation loss = 2.9214  \n",
      "\n",
      "Fold: 2  Epoch: 305  Training loss = 3.0401  Validation loss = 2.9211  \n",
      "\n",
      "Fold: 2  Epoch: 306  Training loss = 3.0399  Validation loss = 2.9207  \n",
      "\n",
      "Fold: 2  Epoch: 307  Training loss = 3.0395  Validation loss = 2.9203  \n",
      "\n",
      "Fold: 2  Epoch: 308  Training loss = 3.0393  Validation loss = 2.9199  \n",
      "\n",
      "Fold: 2  Epoch: 309  Training loss = 3.0391  Validation loss = 2.9197  \n",
      "\n",
      "Fold: 2  Epoch: 310  Training loss = 3.0388  Validation loss = 2.9192  \n",
      "\n",
      "Fold: 2  Epoch: 311  Training loss = 3.0386  Validation loss = 2.9189  \n",
      "\n",
      "Fold: 2  Epoch: 312  Training loss = 3.0382  Validation loss = 2.9184  \n",
      "\n",
      "Fold: 2  Epoch: 313  Training loss = 3.0379  Validation loss = 2.9180  \n",
      "\n",
      "Fold: 2  Epoch: 314  Training loss = 3.0377  Validation loss = 2.9176  \n",
      "\n",
      "Fold: 2  Epoch: 315  Training loss = 3.0374  Validation loss = 2.9173  \n",
      "\n",
      "Fold: 2  Epoch: 316  Training loss = 3.0371  Validation loss = 2.9169  \n",
      "\n",
      "Fold: 2  Epoch: 317  Training loss = 3.0369  Validation loss = 2.9166  \n",
      "\n",
      "Fold: 2  Epoch: 318  Training loss = 3.0367  Validation loss = 2.9163  \n",
      "\n",
      "Fold: 2  Epoch: 319  Training loss = 3.0364  Validation loss = 2.9159  \n",
      "\n",
      "Fold: 2  Epoch: 320  Training loss = 3.0362  Validation loss = 2.9156  \n",
      "\n",
      "Fold: 2  Epoch: 321  Training loss = 3.0360  Validation loss = 2.9153  \n",
      "\n",
      "Fold: 2  Epoch: 322  Training loss = 3.0357  Validation loss = 2.9149  \n",
      "\n",
      "Fold: 2  Epoch: 323  Training loss = 3.0354  Validation loss = 2.9145  \n",
      "\n",
      "Fold: 2  Epoch: 324  Training loss = 3.0352  Validation loss = 2.9141  \n",
      "\n",
      "Fold: 2  Epoch: 325  Training loss = 3.0349  Validation loss = 2.9137  \n",
      "\n",
      "Fold: 2  Epoch: 326  Training loss = 3.0346  Validation loss = 2.9133  \n",
      "\n",
      "Fold: 2  Epoch: 327  Training loss = 3.0344  Validation loss = 2.9130  \n",
      "\n",
      "Fold: 2  Epoch: 328  Training loss = 3.0342  Validation loss = 2.9127  \n",
      "\n",
      "Fold: 2  Epoch: 329  Training loss = 3.0338  Validation loss = 2.9122  \n",
      "\n",
      "Fold: 2  Epoch: 330  Training loss = 3.0335  Validation loss = 2.9118  \n",
      "\n",
      "Fold: 2  Epoch: 331  Training loss = 3.0333  Validation loss = 2.9115  \n",
      "\n",
      "Fold: 2  Epoch: 332  Training loss = 3.0330  Validation loss = 2.9111  \n",
      "\n",
      "Fold: 2  Epoch: 333  Training loss = 3.0328  Validation loss = 2.9107  \n",
      "\n",
      "Fold: 2  Epoch: 334  Training loss = 3.0325  Validation loss = 2.9103  \n",
      "\n",
      "Fold: 2  Epoch: 335  Training loss = 3.0323  Validation loss = 2.9100  \n",
      "\n",
      "Fold: 2  Epoch: 336  Training loss = 3.0321  Validation loss = 2.9097  \n",
      "\n",
      "Fold: 2  Epoch: 337  Training loss = 3.0317  Validation loss = 2.9092  \n",
      "\n",
      "Fold: 2  Epoch: 338  Training loss = 3.0315  Validation loss = 2.9089  \n",
      "\n",
      "Fold: 2  Epoch: 339  Training loss = 3.0312  Validation loss = 2.9084  \n",
      "\n",
      "Fold: 2  Epoch: 340  Training loss = 3.0310  Validation loss = 2.9081  \n",
      "\n",
      "Fold: 2  Epoch: 341  Training loss = 3.0308  Validation loss = 2.9078  \n",
      "\n",
      "Fold: 2  Epoch: 342  Training loss = 3.0304  Validation loss = 2.9072  \n",
      "\n",
      "Fold: 2  Epoch: 343  Training loss = 3.0303  Validation loss = 2.9070  \n",
      "\n",
      "Fold: 2  Epoch: 344  Training loss = 3.0300  Validation loss = 2.9066  \n",
      "\n",
      "Fold: 2  Epoch: 345  Training loss = 3.0296  Validation loss = 2.9061  \n",
      "\n",
      "Fold: 2  Epoch: 346  Training loss = 3.0293  Validation loss = 2.9056  \n",
      "\n",
      "Fold: 2  Epoch: 347  Training loss = 3.0290  Validation loss = 2.9053  \n",
      "\n",
      "Fold: 2  Epoch: 348  Training loss = 3.0287  Validation loss = 2.9049  \n",
      "\n",
      "Fold: 2  Epoch: 349  Training loss = 3.0285  Validation loss = 2.9045  \n",
      "\n",
      "Fold: 2  Epoch: 350  Training loss = 3.0282  Validation loss = 2.9041  \n",
      "\n",
      "Fold: 2  Epoch: 351  Training loss = 3.0279  Validation loss = 2.9037  \n",
      "\n",
      "Fold: 2  Epoch: 352  Training loss = 3.0277  Validation loss = 2.9034  \n",
      "\n",
      "Fold: 2  Epoch: 353  Training loss = 3.0273  Validation loss = 2.9029  \n",
      "\n",
      "Fold: 2  Epoch: 354  Training loss = 3.0270  Validation loss = 2.9025  \n",
      "\n",
      "Fold: 2  Epoch: 355  Training loss = 3.0267  Validation loss = 2.9021  \n",
      "\n",
      "Fold: 2  Epoch: 356  Training loss = 3.0265  Validation loss = 2.9017  \n",
      "\n",
      "Fold: 2  Epoch: 357  Training loss = 3.0262  Validation loss = 2.9013  \n",
      "\n",
      "Fold: 2  Epoch: 358  Training loss = 3.0260  Validation loss = 2.9010  \n",
      "\n",
      "Fold: 2  Epoch: 359  Training loss = 3.0258  Validation loss = 2.9007  \n",
      "\n",
      "Fold: 2  Epoch: 360  Training loss = 3.0256  Validation loss = 2.9004  \n",
      "\n",
      "Fold: 2  Epoch: 361  Training loss = 3.0254  Validation loss = 2.9001  \n",
      "\n",
      "Fold: 2  Epoch: 362  Training loss = 3.0252  Validation loss = 2.8997  \n",
      "\n",
      "Fold: 2  Epoch: 363  Training loss = 3.0249  Validation loss = 2.8994  \n",
      "\n",
      "Fold: 2  Epoch: 364  Training loss = 3.0247  Validation loss = 2.8991  \n",
      "\n",
      "Fold: 2  Epoch: 365  Training loss = 3.0244  Validation loss = 2.8986  \n",
      "\n",
      "Fold: 2  Epoch: 366  Training loss = 3.0242  Validation loss = 2.8983  \n",
      "\n",
      "Fold: 2  Epoch: 367  Training loss = 3.0240  Validation loss = 2.8980  \n",
      "\n",
      "Fold: 2  Epoch: 368  Training loss = 3.0237  Validation loss = 2.8975  \n",
      "\n",
      "Fold: 2  Epoch: 369  Training loss = 3.0233  Validation loss = 2.8971  \n",
      "\n",
      "Fold: 2  Epoch: 370  Training loss = 3.0231  Validation loss = 2.8968  \n",
      "\n",
      "Fold: 2  Epoch: 371  Training loss = 3.0229  Validation loss = 2.8965  \n",
      "\n",
      "Fold: 2  Epoch: 372  Training loss = 3.0225  Validation loss = 2.8959  \n",
      "\n",
      "Fold: 2  Epoch: 373  Training loss = 3.0223  Validation loss = 2.8956  \n",
      "\n",
      "Fold: 2  Epoch: 374  Training loss = 3.0219  Validation loss = 2.8952  \n",
      "\n",
      "Fold: 2  Epoch: 375  Training loss = 3.0216  Validation loss = 2.8948  \n",
      "\n",
      "Fold: 2  Epoch: 376  Training loss = 3.0214  Validation loss = 2.8945  \n",
      "\n",
      "Fold: 2  Epoch: 377  Training loss = 3.0212  Validation loss = 2.8942  \n",
      "\n",
      "Fold: 2  Epoch: 378  Training loss = 3.0210  Validation loss = 2.8938  \n",
      "\n",
      "Fold: 2  Epoch: 379  Training loss = 3.0208  Validation loss = 2.8935  \n",
      "\n",
      "Fold: 2  Epoch: 380  Training loss = 3.0205  Validation loss = 2.8932  \n",
      "\n",
      "Fold: 2  Epoch: 381  Training loss = 3.0203  Validation loss = 2.8929  \n",
      "\n",
      "Fold: 2  Epoch: 382  Training loss = 3.0201  Validation loss = 2.8925  \n",
      "\n",
      "Fold: 2  Epoch: 383  Training loss = 3.0199  Validation loss = 2.8922  \n",
      "\n",
      "Fold: 2  Epoch: 384  Training loss = 3.0196  Validation loss = 2.8918  \n",
      "\n",
      "Fold: 2  Epoch: 385  Training loss = 3.0193  Validation loss = 2.8914  \n",
      "\n",
      "Fold: 2  Epoch: 386  Training loss = 3.0191  Validation loss = 2.8911  \n",
      "\n",
      "Fold: 2  Epoch: 387  Training loss = 3.0189  Validation loss = 2.8908  \n",
      "\n",
      "Fold: 2  Epoch: 388  Training loss = 3.0186  Validation loss = 2.8904  \n",
      "\n",
      "Fold: 2  Epoch: 389  Training loss = 3.0184  Validation loss = 2.8901  \n",
      "\n",
      "Fold: 2  Epoch: 390  Training loss = 3.0182  Validation loss = 2.8898  \n",
      "\n",
      "Fold: 2  Epoch: 391  Training loss = 3.0179  Validation loss = 2.8895  \n",
      "\n",
      "Fold: 2  Epoch: 392  Training loss = 3.0176  Validation loss = 2.8890  \n",
      "\n",
      "Fold: 2  Epoch: 393  Training loss = 3.0173  Validation loss = 2.8886  \n",
      "\n",
      "Fold: 2  Epoch: 394  Training loss = 3.0171  Validation loss = 2.8883  \n",
      "\n",
      "Fold: 2  Epoch: 395  Training loss = 3.0168  Validation loss = 2.8879  \n",
      "\n",
      "Fold: 2  Epoch: 396  Training loss = 3.0166  Validation loss = 2.8876  \n",
      "\n",
      "Fold: 2  Epoch: 397  Training loss = 3.0163  Validation loss = 2.8872  \n",
      "\n",
      "Fold: 2  Epoch: 398  Training loss = 3.0161  Validation loss = 2.8868  \n",
      "\n",
      "Fold: 2  Epoch: 399  Training loss = 3.0158  Validation loss = 2.8865  \n",
      "\n",
      "Fold: 2  Epoch: 400  Training loss = 3.0156  Validation loss = 2.8861  \n",
      "\n",
      "Fold: 2  Epoch: 401  Training loss = 3.0152  Validation loss = 2.8856  \n",
      "\n",
      "Fold: 2  Epoch: 402  Training loss = 3.0151  Validation loss = 2.8854  \n",
      "\n",
      "Fold: 2  Epoch: 403  Training loss = 3.0148  Validation loss = 2.8850  \n",
      "\n",
      "Fold: 2  Epoch: 404  Training loss = 3.0144  Validation loss = 2.8845  \n",
      "\n",
      "Fold: 2  Epoch: 405  Training loss = 3.0142  Validation loss = 2.8842  \n",
      "\n",
      "Fold: 2  Epoch: 406  Training loss = 3.0140  Validation loss = 2.8839  \n",
      "\n",
      "Fold: 2  Epoch: 407  Training loss = 3.0138  Validation loss = 2.8836  \n",
      "\n",
      "Fold: 2  Epoch: 408  Training loss = 3.0135  Validation loss = 2.8832  \n",
      "\n",
      "Fold: 2  Epoch: 409  Training loss = 3.0133  Validation loss = 2.8829  \n",
      "\n",
      "Fold: 2  Epoch: 410  Training loss = 3.0131  Validation loss = 2.8826  \n",
      "\n",
      "Fold: 2  Epoch: 411  Training loss = 3.0128  Validation loss = 2.8822  \n",
      "\n",
      "Fold: 2  Epoch: 412  Training loss = 3.0126  Validation loss = 2.8818  \n",
      "\n",
      "Fold: 2  Epoch: 413  Training loss = 3.0123  Validation loss = 2.8814  \n",
      "\n",
      "Fold: 2  Epoch: 414  Training loss = 3.0119  Validation loss = 2.8810  \n",
      "\n",
      "Fold: 2  Epoch: 415  Training loss = 3.0117  Validation loss = 2.8806  \n",
      "\n",
      "Fold: 2  Epoch: 416  Training loss = 3.0114  Validation loss = 2.8802  \n",
      "\n",
      "Fold: 2  Epoch: 417  Training loss = 3.0109  Validation loss = 2.8796  \n",
      "\n",
      "Fold: 2  Epoch: 418  Training loss = 3.0107  Validation loss = 2.8792  \n",
      "\n",
      "Fold: 2  Epoch: 419  Training loss = 3.0104  Validation loss = 2.8789  \n",
      "\n",
      "Fold: 2  Epoch: 420  Training loss = 3.0101  Validation loss = 2.8784  \n",
      "\n",
      "Fold: 2  Epoch: 421  Training loss = 3.0098  Validation loss = 2.8780  \n",
      "\n",
      "Fold: 2  Epoch: 422  Training loss = 3.0096  Validation loss = 2.8777  \n",
      "\n",
      "Fold: 2  Epoch: 423  Training loss = 3.0093  Validation loss = 2.8773  \n",
      "\n",
      "Fold: 2  Epoch: 424  Training loss = 3.0091  Validation loss = 2.8770  \n",
      "\n",
      "Fold: 2  Epoch: 425  Training loss = 3.0088  Validation loss = 2.8766  \n",
      "\n",
      "Fold: 2  Epoch: 426  Training loss = 3.0085  Validation loss = 2.8762  \n",
      "\n",
      "Fold: 2  Epoch: 427  Training loss = 3.0082  Validation loss = 2.8757  \n",
      "\n",
      "Fold: 2  Epoch: 428  Training loss = 3.0080  Validation loss = 2.8754  \n",
      "\n",
      "Fold: 2  Epoch: 429  Training loss = 3.0078  Validation loss = 2.8750  \n",
      "\n",
      "Fold: 2  Epoch: 430  Training loss = 3.0076  Validation loss = 2.8748  \n",
      "\n",
      "Fold: 2  Epoch: 431  Training loss = 3.0073  Validation loss = 2.8744  \n",
      "\n",
      "Fold: 2  Epoch: 432  Training loss = 3.0071  Validation loss = 2.8741  \n",
      "\n",
      "Fold: 2  Epoch: 433  Training loss = 3.0068  Validation loss = 2.8737  \n",
      "\n",
      "Fold: 2  Epoch: 434  Training loss = 3.0066  Validation loss = 2.8734  \n",
      "\n",
      "Fold: 2  Epoch: 435  Training loss = 3.0063  Validation loss = 2.8730  \n",
      "\n",
      "Fold: 2  Epoch: 436  Training loss = 3.0060  Validation loss = 2.8726  \n",
      "\n",
      "Fold: 2  Epoch: 437  Training loss = 3.0058  Validation loss = 2.8723  \n",
      "\n",
      "Fold: 2  Epoch: 438  Training loss = 3.0055  Validation loss = 2.8720  \n",
      "\n",
      "Fold: 2  Epoch: 439  Training loss = 3.0053  Validation loss = 2.8716  \n",
      "\n",
      "Fold: 2  Epoch: 440  Training loss = 3.0051  Validation loss = 2.8713  \n",
      "\n",
      "Fold: 2  Epoch: 441  Training loss = 3.0048  Validation loss = 2.8709  \n",
      "\n",
      "Fold: 2  Epoch: 442  Training loss = 3.0046  Validation loss = 2.8706  \n",
      "\n",
      "Fold: 2  Epoch: 443  Training loss = 3.0044  Validation loss = 2.8703  \n",
      "\n",
      "Fold: 2  Epoch: 444  Training loss = 3.0041  Validation loss = 2.8699  \n",
      "\n",
      "Fold: 2  Epoch: 445  Training loss = 3.0039  Validation loss = 2.8696  \n",
      "\n",
      "Fold: 2  Epoch: 446  Training loss = 3.0037  Validation loss = 2.8692  \n",
      "\n",
      "Fold: 2  Epoch: 447  Training loss = 3.0034  Validation loss = 2.8688  \n",
      "\n",
      "Fold: 2  Epoch: 448  Training loss = 3.0032  Validation loss = 2.8686  \n",
      "\n",
      "Fold: 2  Epoch: 449  Training loss = 3.0029  Validation loss = 2.8682  \n",
      "\n",
      "Fold: 2  Epoch: 450  Training loss = 3.0027  Validation loss = 2.8679  \n",
      "\n",
      "Fold: 2  Epoch: 451  Training loss = 3.0025  Validation loss = 2.8675  \n",
      "\n",
      "Fold: 2  Epoch: 452  Training loss = 3.0022  Validation loss = 2.8671  \n",
      "\n",
      "Fold: 2  Epoch: 453  Training loss = 3.0018  Validation loss = 2.8666  \n",
      "\n",
      "Fold: 2  Epoch: 454  Training loss = 3.0015  Validation loss = 2.8661  \n",
      "\n",
      "Fold: 2  Epoch: 455  Training loss = 3.0012  Validation loss = 2.8657  \n",
      "\n",
      "Fold: 2  Epoch: 456  Training loss = 3.0010  Validation loss = 2.8654  \n",
      "\n",
      "Fold: 2  Epoch: 457  Training loss = 3.0007  Validation loss = 2.8650  \n",
      "\n",
      "Fold: 2  Epoch: 458  Training loss = 3.0004  Validation loss = 2.8646  \n",
      "\n",
      "Fold: 2  Epoch: 459  Training loss = 3.0002  Validation loss = 2.8642  \n",
      "\n",
      "Fold: 2  Epoch: 460  Training loss = 2.9999  Validation loss = 2.8638  \n",
      "\n",
      "Fold: 2  Epoch: 461  Training loss = 2.9996  Validation loss = 2.8634  \n",
      "\n",
      "Fold: 2  Epoch: 462  Training loss = 2.9993  Validation loss = 2.8630  \n",
      "\n",
      "Fold: 2  Epoch: 463  Training loss = 2.9991  Validation loss = 2.8627  \n",
      "\n",
      "Fold: 2  Epoch: 464  Training loss = 2.9988  Validation loss = 2.8623  \n",
      "\n",
      "Fold: 2  Epoch: 465  Training loss = 2.9986  Validation loss = 2.8619  \n",
      "\n",
      "Fold: 2  Epoch: 466  Training loss = 2.9983  Validation loss = 2.8615  \n",
      "\n",
      "Fold: 2  Epoch: 467  Training loss = 2.9981  Validation loss = 2.8613  \n",
      "\n",
      "Fold: 2  Epoch: 468  Training loss = 2.9979  Validation loss = 2.8610  \n",
      "\n",
      "Fold: 2  Epoch: 469  Training loss = 2.9977  Validation loss = 2.8606  \n",
      "\n",
      "Fold: 2  Epoch: 470  Training loss = 2.9974  Validation loss = 2.8603  \n",
      "\n",
      "Fold: 2  Epoch: 471  Training loss = 2.9972  Validation loss = 2.8599  \n",
      "\n",
      "Fold: 2  Epoch: 472  Training loss = 2.9969  Validation loss = 2.8596  \n",
      "\n",
      "Fold: 2  Epoch: 473  Training loss = 2.9965  Validation loss = 2.8590  \n",
      "\n",
      "Fold: 2  Epoch: 474  Training loss = 2.9962  Validation loss = 2.8586  \n",
      "\n",
      "Fold: 2  Epoch: 475  Training loss = 2.9959  Validation loss = 2.8581  \n",
      "\n",
      "Fold: 2  Epoch: 476  Training loss = 2.9956  Validation loss = 2.8577  \n",
      "\n",
      "Fold: 2  Epoch: 477  Training loss = 2.9953  Validation loss = 2.8573  \n",
      "\n",
      "Fold: 2  Epoch: 478  Training loss = 2.9952  Validation loss = 2.8570  \n",
      "\n",
      "Fold: 2  Epoch: 479  Training loss = 2.9949  Validation loss = 2.8566  \n",
      "\n",
      "Fold: 2  Epoch: 480  Training loss = 2.9946  Validation loss = 2.8563  \n",
      "\n",
      "Fold: 2  Epoch: 481  Training loss = 2.9942  Validation loss = 2.8558  \n",
      "\n",
      "Fold: 2  Epoch: 482  Training loss = 2.9940  Validation loss = 2.8555  \n",
      "\n",
      "Fold: 2  Epoch: 483  Training loss = 2.9938  Validation loss = 2.8551  \n",
      "\n",
      "Fold: 2  Epoch: 484  Training loss = 2.9935  Validation loss = 2.8548  \n",
      "\n",
      "Fold: 2  Epoch: 485  Training loss = 2.9933  Validation loss = 2.8544  \n",
      "\n",
      "Fold: 2  Epoch: 486  Training loss = 2.9931  Validation loss = 2.8541  \n",
      "\n",
      "Fold: 2  Epoch: 487  Training loss = 2.9928  Validation loss = 2.8537  \n",
      "\n",
      "Fold: 2  Epoch: 488  Training loss = 2.9925  Validation loss = 2.8533  \n",
      "\n",
      "Fold: 2  Epoch: 489  Training loss = 2.9923  Validation loss = 2.8530  \n",
      "\n",
      "Fold: 2  Epoch: 490  Training loss = 2.9922  Validation loss = 2.8527  \n",
      "\n",
      "Fold: 2  Epoch: 491  Training loss = 2.9919  Validation loss = 2.8523  \n",
      "\n",
      "Fold: 2  Epoch: 492  Training loss = 2.9916  Validation loss = 2.8520  \n",
      "\n",
      "Fold: 2  Epoch: 493  Training loss = 2.9913  Validation loss = 2.8516  \n",
      "\n",
      "Fold: 2  Epoch: 494  Training loss = 2.9911  Validation loss = 2.8513  \n",
      "\n",
      "Fold: 2  Epoch: 495  Training loss = 2.9909  Validation loss = 2.8510  \n",
      "\n",
      "Fold: 2  Epoch: 496  Training loss = 2.9907  Validation loss = 2.8507  \n",
      "\n",
      "Fold: 2  Epoch: 497  Training loss = 2.9904  Validation loss = 2.8502  \n",
      "\n",
      "Fold: 2  Epoch: 498  Training loss = 2.9901  Validation loss = 2.8499  \n",
      "\n",
      "Fold: 2  Epoch: 499  Training loss = 2.9899  Validation loss = 2.8495  \n",
      "\n",
      "Fold: 2  Epoch: 500  Training loss = 2.9896  Validation loss = 2.8491  \n",
      "\n",
      "Check model:  Fold: 2  Optimal epoch: 500  \n",
      "\n",
      "Fold: 3  Epoch: 1  Training loss = 1.9548  Validation loss = 4.3450  \n",
      "\n",
      "Fold: 3  Epoch: 2  Training loss = 1.9545  Validation loss = 4.3446  \n",
      "\n",
      "Fold: 3  Epoch: 3  Training loss = 1.9542  Validation loss = 4.3443  \n",
      "\n",
      "Fold: 3  Epoch: 4  Training loss = 1.9540  Validation loss = 4.3440  \n",
      "\n",
      "Fold: 3  Epoch: 5  Training loss = 1.9538  Validation loss = 4.3436  \n",
      "\n",
      "Fold: 3  Epoch: 6  Training loss = 1.9535  Validation loss = 4.3432  \n",
      "\n",
      "Fold: 3  Epoch: 7  Training loss = 1.9533  Validation loss = 4.3429  \n",
      "\n",
      "Fold: 3  Epoch: 8  Training loss = 1.9530  Validation loss = 4.3425  \n",
      "\n",
      "Fold: 3  Epoch: 9  Training loss = 1.9527  Validation loss = 4.3421  \n",
      "\n",
      "Fold: 3  Epoch: 10  Training loss = 1.9525  Validation loss = 4.3418  \n",
      "\n",
      "Fold: 3  Epoch: 11  Training loss = 1.9523  Validation loss = 4.3415  \n",
      "\n",
      "Fold: 3  Epoch: 12  Training loss = 1.9520  Validation loss = 4.3412  \n",
      "\n",
      "Fold: 3  Epoch: 13  Training loss = 1.9518  Validation loss = 4.3408  \n",
      "\n",
      "Fold: 3  Epoch: 14  Training loss = 1.9516  Validation loss = 4.3405  \n",
      "\n",
      "Fold: 3  Epoch: 15  Training loss = 1.9513  Validation loss = 4.3401  \n",
      "\n",
      "Fold: 3  Epoch: 16  Training loss = 1.9511  Validation loss = 4.3398  \n",
      "\n",
      "Fold: 3  Epoch: 17  Training loss = 1.9509  Validation loss = 4.3395  \n",
      "\n",
      "Fold: 3  Epoch: 18  Training loss = 1.9506  Validation loss = 4.3392  \n",
      "\n",
      "Fold: 3  Epoch: 19  Training loss = 1.9504  Validation loss = 4.3389  \n",
      "\n",
      "Fold: 3  Epoch: 20  Training loss = 1.9502  Validation loss = 4.3386  \n",
      "\n",
      "Fold: 3  Epoch: 21  Training loss = 1.9500  Validation loss = 4.3383  \n",
      "\n",
      "Fold: 3  Epoch: 22  Training loss = 1.9497  Validation loss = 4.3379  \n",
      "\n",
      "Fold: 3  Epoch: 23  Training loss = 1.9496  Validation loss = 4.3377  \n",
      "\n",
      "Fold: 3  Epoch: 24  Training loss = 1.9494  Validation loss = 4.3374  \n",
      "\n",
      "Fold: 3  Epoch: 25  Training loss = 1.9491  Validation loss = 4.3370  \n",
      "\n",
      "Fold: 3  Epoch: 26  Training loss = 1.9489  Validation loss = 4.3367  \n",
      "\n",
      "Fold: 3  Epoch: 27  Training loss = 1.9487  Validation loss = 4.3364  \n",
      "\n",
      "Fold: 3  Epoch: 28  Training loss = 1.9484  Validation loss = 4.3361  \n",
      "\n",
      "Fold: 3  Epoch: 29  Training loss = 1.9482  Validation loss = 4.3357  \n",
      "\n",
      "Fold: 3  Epoch: 30  Training loss = 1.9479  Validation loss = 4.3354  \n",
      "\n",
      "Fold: 3  Epoch: 31  Training loss = 1.9476  Validation loss = 4.3349  \n",
      "\n",
      "Fold: 3  Epoch: 32  Training loss = 1.9474  Validation loss = 4.3346  \n",
      "\n",
      "Fold: 3  Epoch: 33  Training loss = 1.9471  Validation loss = 4.3342  \n",
      "\n",
      "Fold: 3  Epoch: 34  Training loss = 1.9469  Validation loss = 4.3339  \n",
      "\n",
      "Fold: 3  Epoch: 35  Training loss = 1.9466  Validation loss = 4.3335  \n",
      "\n",
      "Fold: 3  Epoch: 36  Training loss = 1.9463  Validation loss = 4.3331  \n",
      "\n",
      "Fold: 3  Epoch: 37  Training loss = 1.9460  Validation loss = 4.3327  \n",
      "\n",
      "Fold: 3  Epoch: 38  Training loss = 1.9458  Validation loss = 4.3323  \n",
      "\n",
      "Fold: 3  Epoch: 39  Training loss = 1.9455  Validation loss = 4.3320  \n",
      "\n",
      "Fold: 3  Epoch: 40  Training loss = 1.9452  Validation loss = 4.3315  \n",
      "\n",
      "Fold: 3  Epoch: 41  Training loss = 1.9451  Validation loss = 4.3313  \n",
      "\n",
      "Fold: 3  Epoch: 42  Training loss = 1.9449  Validation loss = 4.3311  \n",
      "\n",
      "Fold: 3  Epoch: 43  Training loss = 1.9446  Validation loss = 4.3307  \n",
      "\n",
      "Fold: 3  Epoch: 44  Training loss = 1.9444  Validation loss = 4.3304  \n",
      "\n",
      "Fold: 3  Epoch: 45  Training loss = 1.9441  Validation loss = 4.3300  \n",
      "\n",
      "Fold: 3  Epoch: 46  Training loss = 1.9439  Validation loss = 4.3297  \n",
      "\n",
      "Fold: 3  Epoch: 47  Training loss = 1.9437  Validation loss = 4.3294  \n",
      "\n",
      "Fold: 3  Epoch: 48  Training loss = 1.9435  Validation loss = 4.3291  \n",
      "\n",
      "Fold: 3  Epoch: 49  Training loss = 1.9432  Validation loss = 4.3287  \n",
      "\n",
      "Fold: 3  Epoch: 50  Training loss = 1.9430  Validation loss = 4.3284  \n",
      "\n",
      "Fold: 3  Epoch: 51  Training loss = 1.9428  Validation loss = 4.3281  \n",
      "\n",
      "Fold: 3  Epoch: 52  Training loss = 1.9426  Validation loss = 4.3278  \n",
      "\n",
      "Fold: 3  Epoch: 53  Training loss = 1.9423  Validation loss = 4.3273  \n",
      "\n",
      "Fold: 3  Epoch: 54  Training loss = 1.9420  Validation loss = 4.3270  \n",
      "\n",
      "Fold: 3  Epoch: 55  Training loss = 1.9418  Validation loss = 4.3266  \n",
      "\n",
      "Fold: 3  Epoch: 56  Training loss = 1.9415  Validation loss = 4.3263  \n",
      "\n",
      "Fold: 3  Epoch: 57  Training loss = 1.9412  Validation loss = 4.3259  \n",
      "\n",
      "Fold: 3  Epoch: 58  Training loss = 1.9410  Validation loss = 4.3256  \n",
      "\n",
      "Fold: 3  Epoch: 59  Training loss = 1.9408  Validation loss = 4.3254  \n",
      "\n",
      "Fold: 3  Epoch: 60  Training loss = 1.9405  Validation loss = 4.3249  \n",
      "\n",
      "Fold: 3  Epoch: 61  Training loss = 1.9403  Validation loss = 4.3247  \n",
      "\n",
      "Fold: 3  Epoch: 62  Training loss = 1.9400  Validation loss = 4.3242  \n",
      "\n",
      "Fold: 3  Epoch: 63  Training loss = 1.9398  Validation loss = 4.3239  \n",
      "\n",
      "Fold: 3  Epoch: 64  Training loss = 1.9395  Validation loss = 4.3235  \n",
      "\n",
      "Fold: 3  Epoch: 65  Training loss = 1.9393  Validation loss = 4.3232  \n",
      "\n",
      "Fold: 3  Epoch: 66  Training loss = 1.9391  Validation loss = 4.3229  \n",
      "\n",
      "Fold: 3  Epoch: 67  Training loss = 1.9388  Validation loss = 4.3225  \n",
      "\n",
      "Fold: 3  Epoch: 68  Training loss = 1.9386  Validation loss = 4.3222  \n",
      "\n",
      "Fold: 3  Epoch: 69  Training loss = 1.9383  Validation loss = 4.3218  \n",
      "\n",
      "Fold: 3  Epoch: 70  Training loss = 1.9381  Validation loss = 4.3215  \n",
      "\n",
      "Fold: 3  Epoch: 71  Training loss = 1.9379  Validation loss = 4.3211  \n",
      "\n",
      "Fold: 3  Epoch: 72  Training loss = 1.9377  Validation loss = 4.3208  \n",
      "\n",
      "Fold: 3  Epoch: 73  Training loss = 1.9374  Validation loss = 4.3205  \n",
      "\n",
      "Fold: 3  Epoch: 74  Training loss = 1.9372  Validation loss = 4.3201  \n",
      "\n",
      "Fold: 3  Epoch: 75  Training loss = 1.9369  Validation loss = 4.3198  \n",
      "\n",
      "Fold: 3  Epoch: 76  Training loss = 1.9367  Validation loss = 4.3194  \n",
      "\n",
      "Fold: 3  Epoch: 77  Training loss = 1.9364  Validation loss = 4.3190  \n",
      "\n",
      "Fold: 3  Epoch: 78  Training loss = 1.9362  Validation loss = 4.3187  \n",
      "\n",
      "Fold: 3  Epoch: 79  Training loss = 1.9359  Validation loss = 4.3182  \n",
      "\n",
      "Fold: 3  Epoch: 80  Training loss = 1.9357  Validation loss = 4.3179  \n",
      "\n",
      "Fold: 3  Epoch: 81  Training loss = 1.9354  Validation loss = 4.3176  \n",
      "\n",
      "Fold: 3  Epoch: 82  Training loss = 1.9352  Validation loss = 4.3173  \n",
      "\n",
      "Fold: 3  Epoch: 83  Training loss = 1.9350  Validation loss = 4.3170  \n",
      "\n",
      "Fold: 3  Epoch: 84  Training loss = 1.9348  Validation loss = 4.3167  \n",
      "\n",
      "Fold: 3  Epoch: 85  Training loss = 1.9345  Validation loss = 4.3162  \n",
      "\n",
      "Fold: 3  Epoch: 86  Training loss = 1.9342  Validation loss = 4.3158  \n",
      "\n",
      "Fold: 3  Epoch: 87  Training loss = 1.9339  Validation loss = 4.3154  \n",
      "\n",
      "Fold: 3  Epoch: 88  Training loss = 1.9337  Validation loss = 4.3150  \n",
      "\n",
      "Fold: 3  Epoch: 89  Training loss = 1.9335  Validation loss = 4.3148  \n",
      "\n",
      "Fold: 3  Epoch: 90  Training loss = 1.9333  Validation loss = 4.3145  \n",
      "\n",
      "Fold: 3  Epoch: 91  Training loss = 1.9330  Validation loss = 4.3141  \n",
      "\n",
      "Fold: 3  Epoch: 92  Training loss = 1.9328  Validation loss = 4.3137  \n",
      "\n",
      "Fold: 3  Epoch: 93  Training loss = 1.9325  Validation loss = 4.3135  \n",
      "\n",
      "Fold: 3  Epoch: 94  Training loss = 1.9323  Validation loss = 4.3131  \n",
      "\n",
      "Fold: 3  Epoch: 95  Training loss = 1.9321  Validation loss = 4.3128  \n",
      "\n",
      "Fold: 3  Epoch: 96  Training loss = 1.9318  Validation loss = 4.3125  \n",
      "\n",
      "Fold: 3  Epoch: 97  Training loss = 1.9316  Validation loss = 4.3122  \n",
      "\n",
      "Fold: 3  Epoch: 98  Training loss = 1.9314  Validation loss = 4.3119  \n",
      "\n",
      "Fold: 3  Epoch: 99  Training loss = 1.9312  Validation loss = 4.3115  \n",
      "\n",
      "Fold: 3  Epoch: 100  Training loss = 1.9309  Validation loss = 4.3112  \n",
      "\n",
      "Fold: 3  Epoch: 101  Training loss = 1.9307  Validation loss = 4.3109  \n",
      "\n",
      "Fold: 3  Epoch: 102  Training loss = 1.9304  Validation loss = 4.3105  \n",
      "\n",
      "Fold: 3  Epoch: 103  Training loss = 1.9302  Validation loss = 4.3101  \n",
      "\n",
      "Fold: 3  Epoch: 104  Training loss = 1.9299  Validation loss = 4.3098  \n",
      "\n",
      "Fold: 3  Epoch: 105  Training loss = 1.9297  Validation loss = 4.3095  \n",
      "\n",
      "Fold: 3  Epoch: 106  Training loss = 1.9295  Validation loss = 4.3091  \n",
      "\n",
      "Fold: 3  Epoch: 107  Training loss = 1.9293  Validation loss = 4.3088  \n",
      "\n",
      "Fold: 3  Epoch: 108  Training loss = 1.9291  Validation loss = 4.3086  \n",
      "\n",
      "Fold: 3  Epoch: 109  Training loss = 1.9289  Validation loss = 4.3082  \n",
      "\n",
      "Fold: 3  Epoch: 110  Training loss = 1.9286  Validation loss = 4.3079  \n",
      "\n",
      "Fold: 3  Epoch: 111  Training loss = 1.9284  Validation loss = 4.3075  \n",
      "\n",
      "Fold: 3  Epoch: 112  Training loss = 1.9281  Validation loss = 4.3072  \n",
      "\n",
      "Fold: 3  Epoch: 113  Training loss = 1.9279  Validation loss = 4.3068  \n",
      "\n",
      "Fold: 3  Epoch: 114  Training loss = 1.9277  Validation loss = 4.3065  \n",
      "\n",
      "Fold: 3  Epoch: 115  Training loss = 1.9274  Validation loss = 4.3062  \n",
      "\n",
      "Fold: 3  Epoch: 116  Training loss = 1.9272  Validation loss = 4.3059  \n",
      "\n",
      "Fold: 3  Epoch: 117  Training loss = 1.9269  Validation loss = 4.3055  \n",
      "\n",
      "Fold: 3  Epoch: 118  Training loss = 1.9267  Validation loss = 4.3051  \n",
      "\n",
      "Fold: 3  Epoch: 119  Training loss = 1.9265  Validation loss = 4.3048  \n",
      "\n",
      "Fold: 3  Epoch: 120  Training loss = 1.9262  Validation loss = 4.3044  \n",
      "\n",
      "Fold: 3  Epoch: 121  Training loss = 1.9260  Validation loss = 4.3041  \n",
      "\n",
      "Fold: 3  Epoch: 122  Training loss = 1.9258  Validation loss = 4.3038  \n",
      "\n",
      "Fold: 3  Epoch: 123  Training loss = 1.9255  Validation loss = 4.3035  \n",
      "\n",
      "Fold: 3  Epoch: 124  Training loss = 1.9253  Validation loss = 4.3031  \n",
      "\n",
      "Fold: 3  Epoch: 125  Training loss = 1.9250  Validation loss = 4.3027  \n",
      "\n",
      "Fold: 3  Epoch: 126  Training loss = 1.9247  Validation loss = 4.3023  \n",
      "\n",
      "Fold: 3  Epoch: 127  Training loss = 1.9244  Validation loss = 4.3019  \n",
      "\n",
      "Fold: 3  Epoch: 128  Training loss = 1.9242  Validation loss = 4.3015  \n",
      "\n",
      "Fold: 3  Epoch: 129  Training loss = 1.9240  Validation loss = 4.3012  \n",
      "\n",
      "Fold: 3  Epoch: 130  Training loss = 1.9237  Validation loss = 4.3008  \n",
      "\n",
      "Fold: 3  Epoch: 131  Training loss = 1.9235  Validation loss = 4.3005  \n",
      "\n",
      "Fold: 3  Epoch: 132  Training loss = 1.9233  Validation loss = 4.3002  \n",
      "\n",
      "Fold: 3  Epoch: 133  Training loss = 1.9230  Validation loss = 4.2998  \n",
      "\n",
      "Fold: 3  Epoch: 134  Training loss = 1.9228  Validation loss = 4.2995  \n",
      "\n",
      "Fold: 3  Epoch: 135  Training loss = 1.9225  Validation loss = 4.2991  \n",
      "\n",
      "Fold: 3  Epoch: 136  Training loss = 1.9223  Validation loss = 4.2988  \n",
      "\n",
      "Fold: 3  Epoch: 137  Training loss = 1.9221  Validation loss = 4.2985  \n",
      "\n",
      "Fold: 3  Epoch: 138  Training loss = 1.9219  Validation loss = 4.2982  \n",
      "\n",
      "Fold: 3  Epoch: 139  Training loss = 1.9216  Validation loss = 4.2978  \n",
      "\n",
      "Fold: 3  Epoch: 140  Training loss = 1.9214  Validation loss = 4.2974  \n",
      "\n",
      "Fold: 3  Epoch: 141  Training loss = 1.9212  Validation loss = 4.2972  \n",
      "\n",
      "Fold: 3  Epoch: 142  Training loss = 1.9210  Validation loss = 4.2969  \n",
      "\n",
      "Fold: 3  Epoch: 143  Training loss = 1.9207  Validation loss = 4.2965  \n",
      "\n",
      "Fold: 3  Epoch: 144  Training loss = 1.9205  Validation loss = 4.2963  \n",
      "\n",
      "Fold: 3  Epoch: 145  Training loss = 1.9203  Validation loss = 4.2960  \n",
      "\n",
      "Fold: 3  Epoch: 146  Training loss = 1.9201  Validation loss = 4.2956  \n",
      "\n",
      "Fold: 3  Epoch: 147  Training loss = 1.9198  Validation loss = 4.2953  \n",
      "\n",
      "Fold: 3  Epoch: 148  Training loss = 1.9196  Validation loss = 4.2950  \n",
      "\n",
      "Fold: 3  Epoch: 149  Training loss = 1.9194  Validation loss = 4.2947  \n",
      "\n",
      "Fold: 3  Epoch: 150  Training loss = 1.9192  Validation loss = 4.2944  \n",
      "\n",
      "Fold: 3  Epoch: 151  Training loss = 1.9190  Validation loss = 4.2941  \n",
      "\n",
      "Fold: 3  Epoch: 152  Training loss = 1.9187  Validation loss = 4.2937  \n",
      "\n",
      "Fold: 3  Epoch: 153  Training loss = 1.9185  Validation loss = 4.2934  \n",
      "\n",
      "Fold: 3  Epoch: 154  Training loss = 1.9182  Validation loss = 4.2930  \n",
      "\n",
      "Fold: 3  Epoch: 155  Training loss = 1.9180  Validation loss = 4.2927  \n",
      "\n",
      "Fold: 3  Epoch: 156  Training loss = 1.9178  Validation loss = 4.2923  \n",
      "\n",
      "Fold: 3  Epoch: 157  Training loss = 1.9175  Validation loss = 4.2920  \n",
      "\n",
      "Fold: 3  Epoch: 158  Training loss = 1.9173  Validation loss = 4.2917  \n",
      "\n",
      "Fold: 3  Epoch: 159  Training loss = 1.9170  Validation loss = 4.2913  \n",
      "\n",
      "Fold: 3  Epoch: 160  Training loss = 1.9168  Validation loss = 4.2909  \n",
      "\n",
      "Fold: 3  Epoch: 161  Training loss = 1.9166  Validation loss = 4.2906  \n",
      "\n",
      "Fold: 3  Epoch: 162  Training loss = 1.9164  Validation loss = 4.2903  \n",
      "\n",
      "Fold: 3  Epoch: 163  Training loss = 1.9161  Validation loss = 4.2900  \n",
      "\n",
      "Fold: 3  Epoch: 164  Training loss = 1.9159  Validation loss = 4.2897  \n",
      "\n",
      "Fold: 3  Epoch: 165  Training loss = 1.9157  Validation loss = 4.2894  \n",
      "\n",
      "Fold: 3  Epoch: 166  Training loss = 1.9155  Validation loss = 4.2891  \n",
      "\n",
      "Fold: 3  Epoch: 167  Training loss = 1.9153  Validation loss = 4.2888  \n",
      "\n",
      "Fold: 3  Epoch: 168  Training loss = 1.9151  Validation loss = 4.2885  \n",
      "\n",
      "Fold: 3  Epoch: 169  Training loss = 1.9148  Validation loss = 4.2881  \n",
      "\n",
      "Fold: 3  Epoch: 170  Training loss = 1.9146  Validation loss = 4.2878  \n",
      "\n",
      "Fold: 3  Epoch: 171  Training loss = 1.9143  Validation loss = 4.2874  \n",
      "\n",
      "Fold: 3  Epoch: 172  Training loss = 1.9142  Validation loss = 4.2872  \n",
      "\n",
      "Fold: 3  Epoch: 173  Training loss = 1.9139  Validation loss = 4.2868  \n",
      "\n",
      "Fold: 3  Epoch: 174  Training loss = 1.9136  Validation loss = 4.2864  \n",
      "\n",
      "Fold: 3  Epoch: 175  Training loss = 1.9134  Validation loss = 4.2860  \n",
      "\n",
      "Fold: 3  Epoch: 176  Training loss = 1.9132  Validation loss = 4.2858  \n",
      "\n",
      "Fold: 3  Epoch: 177  Training loss = 1.9129  Validation loss = 4.2854  \n",
      "\n",
      "Fold: 3  Epoch: 178  Training loss = 1.9127  Validation loss = 4.2851  \n",
      "\n",
      "Fold: 3  Epoch: 179  Training loss = 1.9125  Validation loss = 4.2848  \n",
      "\n",
      "Fold: 3  Epoch: 180  Training loss = 1.9123  Validation loss = 4.2844  \n",
      "\n",
      "Fold: 3  Epoch: 181  Training loss = 1.9120  Validation loss = 4.2840  \n",
      "\n",
      "Fold: 3  Epoch: 182  Training loss = 1.9118  Validation loss = 4.2837  \n",
      "\n",
      "Fold: 3  Epoch: 183  Training loss = 1.9115  Validation loss = 4.2834  \n",
      "\n",
      "Fold: 3  Epoch: 184  Training loss = 1.9114  Validation loss = 4.2831  \n",
      "\n",
      "Fold: 3  Epoch: 185  Training loss = 1.9112  Validation loss = 4.2829  \n",
      "\n",
      "Fold: 3  Epoch: 186  Training loss = 1.9110  Validation loss = 4.2826  \n",
      "\n",
      "Fold: 3  Epoch: 187  Training loss = 1.9108  Validation loss = 4.2823  \n",
      "\n",
      "Fold: 3  Epoch: 188  Training loss = 1.9106  Validation loss = 4.2820  \n",
      "\n",
      "Fold: 3  Epoch: 189  Training loss = 1.9104  Validation loss = 4.2817  \n",
      "\n",
      "Fold: 3  Epoch: 190  Training loss = 1.9102  Validation loss = 4.2814  \n",
      "\n",
      "Fold: 3  Epoch: 191  Training loss = 1.9100  Validation loss = 4.2812  \n",
      "\n",
      "Fold: 3  Epoch: 192  Training loss = 1.9097  Validation loss = 4.2808  \n",
      "\n",
      "Fold: 3  Epoch: 193  Training loss = 1.9095  Validation loss = 4.2805  \n",
      "\n",
      "Fold: 3  Epoch: 194  Training loss = 1.9093  Validation loss = 4.2802  \n",
      "\n",
      "Fold: 3  Epoch: 195  Training loss = 1.9091  Validation loss = 4.2799  \n",
      "\n",
      "Fold: 3  Epoch: 196  Training loss = 1.9089  Validation loss = 4.2795  \n",
      "\n",
      "Fold: 3  Epoch: 197  Training loss = 1.9086  Validation loss = 4.2792  \n",
      "\n",
      "Fold: 3  Epoch: 198  Training loss = 1.9084  Validation loss = 4.2788  \n",
      "\n",
      "Fold: 3  Epoch: 199  Training loss = 1.9082  Validation loss = 4.2785  \n",
      "\n",
      "Fold: 3  Epoch: 200  Training loss = 1.9080  Validation loss = 4.2782  \n",
      "\n",
      "Fold: 3  Epoch: 201  Training loss = 1.9077  Validation loss = 4.2778  \n",
      "\n",
      "Fold: 3  Epoch: 202  Training loss = 1.9075  Validation loss = 4.2775  \n",
      "\n",
      "Fold: 3  Epoch: 203  Training loss = 1.9073  Validation loss = 4.2772  \n",
      "\n",
      "Fold: 3  Epoch: 204  Training loss = 1.9071  Validation loss = 4.2768  \n",
      "\n",
      "Fold: 3  Epoch: 205  Training loss = 1.9069  Validation loss = 4.2766  \n",
      "\n",
      "Fold: 3  Epoch: 206  Training loss = 1.9067  Validation loss = 4.2763  \n",
      "\n",
      "Fold: 3  Epoch: 207  Training loss = 1.9065  Validation loss = 4.2760  \n",
      "\n",
      "Fold: 3  Epoch: 208  Training loss = 1.9063  Validation loss = 4.2758  \n",
      "\n",
      "Fold: 3  Epoch: 209  Training loss = 1.9061  Validation loss = 4.2754  \n",
      "\n",
      "Fold: 3  Epoch: 210  Training loss = 1.9058  Validation loss = 4.2750  \n",
      "\n",
      "Fold: 3  Epoch: 211  Training loss = 1.9055  Validation loss = 4.2746  \n",
      "\n",
      "Fold: 3  Epoch: 212  Training loss = 1.9053  Validation loss = 4.2742  \n",
      "\n",
      "Fold: 3  Epoch: 213  Training loss = 1.9050  Validation loss = 4.2739  \n",
      "\n",
      "Fold: 3  Epoch: 214  Training loss = 1.9048  Validation loss = 4.2736  \n",
      "\n",
      "Fold: 3  Epoch: 215  Training loss = 1.9046  Validation loss = 4.2733  \n",
      "\n",
      "Fold: 3  Epoch: 216  Training loss = 1.9044  Validation loss = 4.2730  \n",
      "\n",
      "Fold: 3  Epoch: 217  Training loss = 1.9042  Validation loss = 4.2727  \n",
      "\n",
      "Fold: 3  Epoch: 218  Training loss = 1.9040  Validation loss = 4.2724  \n",
      "\n",
      "Fold: 3  Epoch: 219  Training loss = 1.9038  Validation loss = 4.2721  \n",
      "\n",
      "Fold: 3  Epoch: 220  Training loss = 1.9036  Validation loss = 4.2718  \n",
      "\n",
      "Fold: 3  Epoch: 221  Training loss = 1.9034  Validation loss = 4.2715  \n",
      "\n",
      "Fold: 3  Epoch: 222  Training loss = 1.9031  Validation loss = 4.2711  \n",
      "\n",
      "Fold: 3  Epoch: 223  Training loss = 1.9029  Validation loss = 4.2708  \n",
      "\n",
      "Fold: 3  Epoch: 224  Training loss = 1.9027  Validation loss = 4.2705  \n",
      "\n",
      "Fold: 3  Epoch: 225  Training loss = 1.9024  Validation loss = 4.2701  \n",
      "\n",
      "Fold: 3  Epoch: 226  Training loss = 1.9022  Validation loss = 4.2697  \n",
      "\n",
      "Fold: 3  Epoch: 227  Training loss = 1.9019  Validation loss = 4.2694  \n",
      "\n",
      "Fold: 3  Epoch: 228  Training loss = 1.9017  Validation loss = 4.2691  \n",
      "\n",
      "Fold: 3  Epoch: 229  Training loss = 1.9015  Validation loss = 4.2687  \n",
      "\n",
      "Fold: 3  Epoch: 230  Training loss = 1.9013  Validation loss = 4.2684  \n",
      "\n",
      "Fold: 3  Epoch: 231  Training loss = 1.9011  Validation loss = 4.2681  \n",
      "\n",
      "Fold: 3  Epoch: 232  Training loss = 1.9008  Validation loss = 4.2677  \n",
      "\n",
      "Fold: 3  Epoch: 233  Training loss = 1.9006  Validation loss = 4.2674  \n",
      "\n",
      "Fold: 3  Epoch: 234  Training loss = 1.9004  Validation loss = 4.2671  \n",
      "\n",
      "Fold: 3  Epoch: 235  Training loss = 1.9001  Validation loss = 4.2667  \n",
      "\n",
      "Fold: 3  Epoch: 236  Training loss = 1.8999  Validation loss = 4.2664  \n",
      "\n",
      "Fold: 3  Epoch: 237  Training loss = 1.8997  Validation loss = 4.2661  \n",
      "\n",
      "Fold: 3  Epoch: 238  Training loss = 1.8995  Validation loss = 4.2658  \n",
      "\n",
      "Fold: 3  Epoch: 239  Training loss = 1.8992  Validation loss = 4.2655  \n",
      "\n",
      "Fold: 3  Epoch: 240  Training loss = 1.8990  Validation loss = 4.2652  \n",
      "\n",
      "Fold: 3  Epoch: 241  Training loss = 1.8989  Validation loss = 4.2650  \n",
      "\n",
      "Fold: 3  Epoch: 242  Training loss = 1.8986  Validation loss = 4.2646  \n",
      "\n",
      "Fold: 3  Epoch: 243  Training loss = 1.8984  Validation loss = 4.2643  \n",
      "\n",
      "Fold: 3  Epoch: 244  Training loss = 1.8982  Validation loss = 4.2639  \n",
      "\n",
      "Fold: 3  Epoch: 245  Training loss = 1.8980  Validation loss = 4.2636  \n",
      "\n",
      "Fold: 3  Epoch: 246  Training loss = 1.8977  Validation loss = 4.2632  \n",
      "\n",
      "Fold: 3  Epoch: 247  Training loss = 1.8975  Validation loss = 4.2629  \n",
      "\n",
      "Fold: 3  Epoch: 248  Training loss = 1.8973  Validation loss = 4.2625  \n",
      "\n",
      "Fold: 3  Epoch: 249  Training loss = 1.8970  Validation loss = 4.2622  \n",
      "\n",
      "Fold: 3  Epoch: 250  Training loss = 1.8968  Validation loss = 4.2619  \n",
      "\n",
      "Fold: 3  Epoch: 251  Training loss = 1.8967  Validation loss = 4.2617  \n",
      "\n",
      "Fold: 3  Epoch: 252  Training loss = 1.8964  Validation loss = 4.2613  \n",
      "\n",
      "Fold: 3  Epoch: 253  Training loss = 1.8962  Validation loss = 4.2610  \n",
      "\n",
      "Fold: 3  Epoch: 254  Training loss = 1.8960  Validation loss = 4.2607  \n",
      "\n",
      "Fold: 3  Epoch: 255  Training loss = 1.8957  Validation loss = 4.2603  \n",
      "\n",
      "Fold: 3  Epoch: 256  Training loss = 1.8955  Validation loss = 4.2600  \n",
      "\n",
      "Fold: 3  Epoch: 257  Training loss = 1.8952  Validation loss = 4.2596  \n",
      "\n",
      "Fold: 3  Epoch: 258  Training loss = 1.8951  Validation loss = 4.2594  \n",
      "\n",
      "Fold: 3  Epoch: 259  Training loss = 1.8948  Validation loss = 4.2590  \n",
      "\n",
      "Fold: 3  Epoch: 260  Training loss = 1.8946  Validation loss = 4.2586  \n",
      "\n",
      "Fold: 3  Epoch: 261  Training loss = 1.8943  Validation loss = 4.2582  \n",
      "\n",
      "Fold: 3  Epoch: 262  Training loss = 1.8941  Validation loss = 4.2578  \n",
      "\n",
      "Fold: 3  Epoch: 263  Training loss = 1.8939  Validation loss = 4.2576  \n",
      "\n",
      "Fold: 3  Epoch: 264  Training loss = 1.8937  Validation loss = 4.2573  \n",
      "\n",
      "Fold: 3  Epoch: 265  Training loss = 1.8935  Validation loss = 4.2571  \n",
      "\n",
      "Fold: 3  Epoch: 266  Training loss = 1.8933  Validation loss = 4.2568  \n",
      "\n",
      "Fold: 3  Epoch: 267  Training loss = 1.8931  Validation loss = 4.2565  \n",
      "\n",
      "Fold: 3  Epoch: 268  Training loss = 1.8929  Validation loss = 4.2562  \n",
      "\n",
      "Fold: 3  Epoch: 269  Training loss = 1.8927  Validation loss = 4.2559  \n",
      "\n",
      "Fold: 3  Epoch: 270  Training loss = 1.8925  Validation loss = 4.2556  \n",
      "\n",
      "Fold: 3  Epoch: 271  Training loss = 1.8923  Validation loss = 4.2552  \n",
      "\n",
      "Fold: 3  Epoch: 272  Training loss = 1.8920  Validation loss = 4.2549  \n",
      "\n",
      "Fold: 3  Epoch: 273  Training loss = 1.8918  Validation loss = 4.2545  \n",
      "\n",
      "Fold: 3  Epoch: 274  Training loss = 1.8916  Validation loss = 4.2542  \n",
      "\n",
      "Fold: 3  Epoch: 275  Training loss = 1.8913  Validation loss = 4.2539  \n",
      "\n",
      "Fold: 3  Epoch: 276  Training loss = 1.8911  Validation loss = 4.2536  \n",
      "\n",
      "Fold: 3  Epoch: 277  Training loss = 1.8909  Validation loss = 4.2533  \n",
      "\n",
      "Fold: 3  Epoch: 278  Training loss = 1.8907  Validation loss = 4.2530  \n",
      "\n",
      "Fold: 3  Epoch: 279  Training loss = 1.8905  Validation loss = 4.2527  \n",
      "\n",
      "Fold: 3  Epoch: 280  Training loss = 1.8903  Validation loss = 4.2523  \n",
      "\n",
      "Fold: 3  Epoch: 281  Training loss = 1.8901  Validation loss = 4.2520  \n",
      "\n",
      "Fold: 3  Epoch: 282  Training loss = 1.8898  Validation loss = 4.2517  \n",
      "\n",
      "Fold: 3  Epoch: 283  Training loss = 1.8896  Validation loss = 4.2513  \n",
      "\n",
      "Fold: 3  Epoch: 284  Training loss = 1.8893  Validation loss = 4.2510  \n",
      "\n",
      "Fold: 3  Epoch: 285  Training loss = 1.8892  Validation loss = 4.2507  \n",
      "\n",
      "Fold: 3  Epoch: 286  Training loss = 1.8889  Validation loss = 4.2504  \n",
      "\n",
      "Fold: 3  Epoch: 287  Training loss = 1.8887  Validation loss = 4.2500  \n",
      "\n",
      "Fold: 3  Epoch: 288  Training loss = 1.8886  Validation loss = 4.2498  \n",
      "\n",
      "Fold: 3  Epoch: 289  Training loss = 1.8883  Validation loss = 4.2494  \n",
      "\n",
      "Fold: 3  Epoch: 290  Training loss = 1.8881  Validation loss = 4.2491  \n",
      "\n",
      "Fold: 3  Epoch: 291  Training loss = 1.8879  Validation loss = 4.2488  \n",
      "\n",
      "Fold: 3  Epoch: 292  Training loss = 1.8877  Validation loss = 4.2484  \n",
      "\n",
      "Fold: 3  Epoch: 293  Training loss = 1.8874  Validation loss = 4.2481  \n",
      "\n",
      "Fold: 3  Epoch: 294  Training loss = 1.8873  Validation loss = 4.2478  \n",
      "\n",
      "Fold: 3  Epoch: 295  Training loss = 1.8870  Validation loss = 4.2475  \n",
      "\n",
      "Fold: 3  Epoch: 296  Training loss = 1.8868  Validation loss = 4.2472  \n",
      "\n",
      "Fold: 3  Epoch: 297  Training loss = 1.8865  Validation loss = 4.2467  \n",
      "\n",
      "Fold: 3  Epoch: 298  Training loss = 1.8863  Validation loss = 4.2463  \n",
      "\n",
      "Fold: 3  Epoch: 299  Training loss = 1.8861  Validation loss = 4.2460  \n",
      "\n",
      "Fold: 3  Epoch: 300  Training loss = 1.8859  Validation loss = 4.2457  \n",
      "\n",
      "Fold: 3  Epoch: 301  Training loss = 1.8857  Validation loss = 4.2454  \n",
      "\n",
      "Fold: 3  Epoch: 302  Training loss = 1.8854  Validation loss = 4.2451  \n",
      "\n",
      "Fold: 3  Epoch: 303  Training loss = 1.8852  Validation loss = 4.2448  \n",
      "\n",
      "Fold: 3  Epoch: 304  Training loss = 1.8850  Validation loss = 4.2444  \n",
      "\n",
      "Fold: 3  Epoch: 305  Training loss = 1.8848  Validation loss = 4.2442  \n",
      "\n",
      "Fold: 3  Epoch: 306  Training loss = 1.8846  Validation loss = 4.2439  \n",
      "\n",
      "Fold: 3  Epoch: 307  Training loss = 1.8844  Validation loss = 4.2436  \n",
      "\n",
      "Fold: 3  Epoch: 308  Training loss = 1.8842  Validation loss = 4.2433  \n",
      "\n",
      "Fold: 3  Epoch: 309  Training loss = 1.8840  Validation loss = 4.2430  \n",
      "\n",
      "Fold: 3  Epoch: 310  Training loss = 1.8838  Validation loss = 4.2428  \n",
      "\n",
      "Fold: 3  Epoch: 311  Training loss = 1.8836  Validation loss = 4.2424  \n",
      "\n",
      "Fold: 3  Epoch: 312  Training loss = 1.8834  Validation loss = 4.2421  \n",
      "\n",
      "Fold: 3  Epoch: 313  Training loss = 1.8831  Validation loss = 4.2417  \n",
      "\n",
      "Fold: 3  Epoch: 314  Training loss = 1.8829  Validation loss = 4.2414  \n",
      "\n",
      "Fold: 3  Epoch: 315  Training loss = 1.8827  Validation loss = 4.2411  \n",
      "\n",
      "Fold: 3  Epoch: 316  Training loss = 1.8825  Validation loss = 4.2408  \n",
      "\n",
      "Fold: 3  Epoch: 317  Training loss = 1.8822  Validation loss = 4.2404  \n",
      "\n",
      "Fold: 3  Epoch: 318  Training loss = 1.8820  Validation loss = 4.2401  \n",
      "\n",
      "Fold: 3  Epoch: 319  Training loss = 1.8818  Validation loss = 4.2398  \n",
      "\n",
      "Fold: 3  Epoch: 320  Training loss = 1.8815  Validation loss = 4.2394  \n",
      "\n",
      "Fold: 3  Epoch: 321  Training loss = 1.8813  Validation loss = 4.2391  \n",
      "\n",
      "Fold: 3  Epoch: 322  Training loss = 1.8811  Validation loss = 4.2387  \n",
      "\n",
      "Fold: 3  Epoch: 323  Training loss = 1.8809  Validation loss = 4.2384  \n",
      "\n",
      "Fold: 3  Epoch: 324  Training loss = 1.8807  Validation loss = 4.2381  \n",
      "\n",
      "Fold: 3  Epoch: 325  Training loss = 1.8805  Validation loss = 4.2379  \n",
      "\n",
      "Fold: 3  Epoch: 326  Training loss = 1.8803  Validation loss = 4.2375  \n",
      "\n",
      "Fold: 3  Epoch: 327  Training loss = 1.8800  Validation loss = 4.2372  \n",
      "\n",
      "Fold: 3  Epoch: 328  Training loss = 1.8798  Validation loss = 4.2369  \n",
      "\n",
      "Fold: 3  Epoch: 329  Training loss = 1.8796  Validation loss = 4.2366  \n",
      "\n",
      "Fold: 3  Epoch: 330  Training loss = 1.8794  Validation loss = 4.2363  \n",
      "\n",
      "Fold: 3  Epoch: 331  Training loss = 1.8792  Validation loss = 4.2360  \n",
      "\n",
      "Fold: 3  Epoch: 332  Training loss = 1.8790  Validation loss = 4.2357  \n",
      "\n",
      "Fold: 3  Epoch: 333  Training loss = 1.8788  Validation loss = 4.2354  \n",
      "\n",
      "Fold: 3  Epoch: 334  Training loss = 1.8786  Validation loss = 4.2351  \n",
      "\n",
      "Fold: 3  Epoch: 335  Training loss = 1.8784  Validation loss = 4.2348  \n",
      "\n",
      "Fold: 3  Epoch: 336  Training loss = 1.8782  Validation loss = 4.2345  \n",
      "\n",
      "Fold: 3  Epoch: 337  Training loss = 1.8779  Validation loss = 4.2341  \n",
      "\n",
      "Fold: 3  Epoch: 338  Training loss = 1.8777  Validation loss = 4.2337  \n",
      "\n",
      "Fold: 3  Epoch: 339  Training loss = 1.8775  Validation loss = 4.2334  \n",
      "\n",
      "Fold: 3  Epoch: 340  Training loss = 1.8772  Validation loss = 4.2330  \n",
      "\n",
      "Fold: 3  Epoch: 341  Training loss = 1.8770  Validation loss = 4.2328  \n",
      "\n",
      "Fold: 3  Epoch: 342  Training loss = 1.8768  Validation loss = 4.2324  \n",
      "\n",
      "Fold: 3  Epoch: 343  Training loss = 1.8766  Validation loss = 4.2321  \n",
      "\n",
      "Fold: 3  Epoch: 344  Training loss = 1.8763  Validation loss = 4.2317  \n",
      "\n",
      "Fold: 3  Epoch: 345  Training loss = 1.8761  Validation loss = 4.2313  \n",
      "\n",
      "Fold: 3  Epoch: 346  Training loss = 1.8758  Validation loss = 4.2310  \n",
      "\n",
      "Fold: 3  Epoch: 347  Training loss = 1.8757  Validation loss = 4.2308  \n",
      "\n",
      "Fold: 3  Epoch: 348  Training loss = 1.8754  Validation loss = 4.2304  \n",
      "\n",
      "Fold: 3  Epoch: 349  Training loss = 1.8752  Validation loss = 4.2301  \n",
      "\n",
      "Fold: 3  Epoch: 350  Training loss = 1.8750  Validation loss = 4.2298  \n",
      "\n",
      "Fold: 3  Epoch: 351  Training loss = 1.8749  Validation loss = 4.2295  \n",
      "\n",
      "Fold: 3  Epoch: 352  Training loss = 1.8746  Validation loss = 4.2292  \n",
      "\n",
      "Fold: 3  Epoch: 353  Training loss = 1.8744  Validation loss = 4.2288  \n",
      "\n",
      "Fold: 3  Epoch: 354  Training loss = 1.8742  Validation loss = 4.2285  \n",
      "\n",
      "Fold: 3  Epoch: 355  Training loss = 1.8740  Validation loss = 4.2282  \n",
      "\n",
      "Fold: 3  Epoch: 356  Training loss = 1.8737  Validation loss = 4.2279  \n",
      "\n",
      "Fold: 3  Epoch: 357  Training loss = 1.8735  Validation loss = 4.2275  \n",
      "\n",
      "Fold: 3  Epoch: 358  Training loss = 1.8733  Validation loss = 4.2273  \n",
      "\n",
      "Fold: 3  Epoch: 359  Training loss = 1.8731  Validation loss = 4.2270  \n",
      "\n",
      "Fold: 3  Epoch: 360  Training loss = 1.8729  Validation loss = 4.2267  \n",
      "\n",
      "Fold: 3  Epoch: 361  Training loss = 1.8727  Validation loss = 4.2264  \n",
      "\n",
      "Fold: 3  Epoch: 362  Training loss = 1.8725  Validation loss = 4.2260  \n",
      "\n",
      "Fold: 3  Epoch: 363  Training loss = 1.8723  Validation loss = 4.2258  \n",
      "\n",
      "Fold: 3  Epoch: 364  Training loss = 1.8721  Validation loss = 4.2254  \n",
      "\n",
      "Fold: 3  Epoch: 365  Training loss = 1.8719  Validation loss = 4.2251  \n",
      "\n",
      "Fold: 3  Epoch: 366  Training loss = 1.8717  Validation loss = 4.2248  \n",
      "\n",
      "Fold: 3  Epoch: 367  Training loss = 1.8715  Validation loss = 4.2244  \n",
      "\n",
      "Fold: 3  Epoch: 368  Training loss = 1.8713  Validation loss = 4.2242  \n",
      "\n",
      "Fold: 3  Epoch: 369  Training loss = 1.8710  Validation loss = 4.2238  \n",
      "\n",
      "Fold: 3  Epoch: 370  Training loss = 1.8709  Validation loss = 4.2236  \n",
      "\n",
      "Fold: 3  Epoch: 371  Training loss = 1.8707  Validation loss = 4.2233  \n",
      "\n",
      "Fold: 3  Epoch: 372  Training loss = 1.8705  Validation loss = 4.2230  \n",
      "\n",
      "Fold: 3  Epoch: 373  Training loss = 1.8703  Validation loss = 4.2226  \n",
      "\n",
      "Fold: 3  Epoch: 374  Training loss = 1.8701  Validation loss = 4.2223  \n",
      "\n",
      "Fold: 3  Epoch: 375  Training loss = 1.8698  Validation loss = 4.2220  \n",
      "\n",
      "Fold: 3  Epoch: 376  Training loss = 1.8696  Validation loss = 4.2217  \n",
      "\n",
      "Fold: 3  Epoch: 377  Training loss = 1.8694  Validation loss = 4.2214  \n",
      "\n",
      "Fold: 3  Epoch: 378  Training loss = 1.8692  Validation loss = 4.2210  \n",
      "\n",
      "Fold: 3  Epoch: 379  Training loss = 1.8689  Validation loss = 4.2207  \n",
      "\n",
      "Fold: 3  Epoch: 380  Training loss = 1.8687  Validation loss = 4.2203  \n",
      "\n",
      "Fold: 3  Epoch: 381  Training loss = 1.8685  Validation loss = 4.2199  \n",
      "\n",
      "Fold: 3  Epoch: 382  Training loss = 1.8682  Validation loss = 4.2196  \n",
      "\n",
      "Fold: 3  Epoch: 383  Training loss = 1.8681  Validation loss = 4.2193  \n",
      "\n",
      "Fold: 3  Epoch: 384  Training loss = 1.8678  Validation loss = 4.2190  \n",
      "\n",
      "Fold: 3  Epoch: 385  Training loss = 1.8677  Validation loss = 4.2188  \n",
      "\n",
      "Fold: 3  Epoch: 386  Training loss = 1.8675  Validation loss = 4.2185  \n",
      "\n",
      "Fold: 3  Epoch: 387  Training loss = 1.8672  Validation loss = 4.2181  \n",
      "\n",
      "Fold: 3  Epoch: 388  Training loss = 1.8670  Validation loss = 4.2178  \n",
      "\n",
      "Fold: 3  Epoch: 389  Training loss = 1.8668  Validation loss = 4.2175  \n",
      "\n",
      "Fold: 3  Epoch: 390  Training loss = 1.8666  Validation loss = 4.2172  \n",
      "\n",
      "Fold: 3  Epoch: 391  Training loss = 1.8663  Validation loss = 4.2168  \n",
      "\n",
      "Fold: 3  Epoch: 392  Training loss = 1.8661  Validation loss = 4.2165  \n",
      "\n",
      "Fold: 3  Epoch: 393  Training loss = 1.8659  Validation loss = 4.2161  \n",
      "\n",
      "Fold: 3  Epoch: 394  Training loss = 1.8657  Validation loss = 4.2159  \n",
      "\n",
      "Fold: 3  Epoch: 395  Training loss = 1.8655  Validation loss = 4.2156  \n",
      "\n",
      "Fold: 3  Epoch: 396  Training loss = 1.8653  Validation loss = 4.2153  \n",
      "\n",
      "Fold: 3  Epoch: 397  Training loss = 1.8651  Validation loss = 4.2150  \n",
      "\n",
      "Fold: 3  Epoch: 398  Training loss = 1.8649  Validation loss = 4.2146  \n",
      "\n",
      "Fold: 3  Epoch: 399  Training loss = 1.8646  Validation loss = 4.2142  \n",
      "\n",
      "Fold: 3  Epoch: 400  Training loss = 1.8644  Validation loss = 4.2139  \n",
      "\n",
      "Fold: 3  Epoch: 401  Training loss = 1.8642  Validation loss = 4.2136  \n",
      "\n",
      "Fold: 3  Epoch: 402  Training loss = 1.8640  Validation loss = 4.2133  \n",
      "\n",
      "Fold: 3  Epoch: 403  Training loss = 1.8638  Validation loss = 4.2130  \n",
      "\n",
      "Fold: 3  Epoch: 404  Training loss = 1.8636  Validation loss = 4.2127  \n",
      "\n",
      "Fold: 3  Epoch: 405  Training loss = 1.8634  Validation loss = 4.2124  \n",
      "\n",
      "Fold: 3  Epoch: 406  Training loss = 1.8633  Validation loss = 4.2122  \n",
      "\n",
      "Fold: 3  Epoch: 407  Training loss = 1.8631  Validation loss = 4.2118  \n",
      "\n",
      "Fold: 3  Epoch: 408  Training loss = 1.8629  Validation loss = 4.2116  \n",
      "\n",
      "Fold: 3  Epoch: 409  Training loss = 1.8627  Validation loss = 4.2112  \n",
      "\n",
      "Fold: 3  Epoch: 410  Training loss = 1.8624  Validation loss = 4.2109  \n",
      "\n",
      "Fold: 3  Epoch: 411  Training loss = 1.8623  Validation loss = 4.2107  \n",
      "\n",
      "Fold: 3  Epoch: 412  Training loss = 1.8621  Validation loss = 4.2104  \n",
      "\n",
      "Fold: 3  Epoch: 413  Training loss = 1.8619  Validation loss = 4.2101  \n",
      "\n",
      "Fold: 3  Epoch: 414  Training loss = 1.8616  Validation loss = 4.2097  \n",
      "\n",
      "Fold: 3  Epoch: 415  Training loss = 1.8614  Validation loss = 4.2093  \n",
      "\n",
      "Fold: 3  Epoch: 416  Training loss = 1.8612  Validation loss = 4.2090  \n",
      "\n",
      "Fold: 3  Epoch: 417  Training loss = 1.8610  Validation loss = 4.2087  \n",
      "\n",
      "Fold: 3  Epoch: 418  Training loss = 1.8607  Validation loss = 4.2083  \n",
      "\n",
      "Fold: 3  Epoch: 419  Training loss = 1.8605  Validation loss = 4.2080  \n",
      "\n",
      "Fold: 3  Epoch: 420  Training loss = 1.8603  Validation loss = 4.2076  \n",
      "\n",
      "Fold: 3  Epoch: 421  Training loss = 1.8601  Validation loss = 4.2073  \n",
      "\n",
      "Fold: 3  Epoch: 422  Training loss = 1.8599  Validation loss = 4.2070  \n",
      "\n",
      "Fold: 3  Epoch: 423  Training loss = 1.8597  Validation loss = 4.2068  \n",
      "\n",
      "Fold: 3  Epoch: 424  Training loss = 1.8596  Validation loss = 4.2065  \n",
      "\n",
      "Fold: 3  Epoch: 425  Training loss = 1.8593  Validation loss = 4.2062  \n",
      "\n",
      "Fold: 3  Epoch: 426  Training loss = 1.8591  Validation loss = 4.2058  \n",
      "\n",
      "Fold: 3  Epoch: 427  Training loss = 1.8588  Validation loss = 4.2055  \n",
      "\n",
      "Fold: 3  Epoch: 428  Training loss = 1.8586  Validation loss = 4.2051  \n",
      "\n",
      "Fold: 3  Epoch: 429  Training loss = 1.8584  Validation loss = 4.2048  \n",
      "\n",
      "Fold: 3  Epoch: 430  Training loss = 1.8582  Validation loss = 4.2045  \n",
      "\n",
      "Fold: 3  Epoch: 431  Training loss = 1.8580  Validation loss = 4.2042  \n",
      "\n",
      "Fold: 3  Epoch: 432  Training loss = 1.8578  Validation loss = 4.2039  \n",
      "\n",
      "Fold: 3  Epoch: 433  Training loss = 1.8576  Validation loss = 4.2037  \n",
      "\n",
      "Fold: 3  Epoch: 434  Training loss = 1.8575  Validation loss = 4.2034  \n",
      "\n",
      "Fold: 3  Epoch: 435  Training loss = 1.8573  Validation loss = 4.2032  \n",
      "\n",
      "Fold: 3  Epoch: 436  Training loss = 1.8572  Validation loss = 4.2030  \n",
      "\n",
      "Fold: 3  Epoch: 437  Training loss = 1.8570  Validation loss = 4.2027  \n",
      "\n",
      "Fold: 3  Epoch: 438  Training loss = 1.8568  Validation loss = 4.2024  \n",
      "\n",
      "Fold: 3  Epoch: 439  Training loss = 1.8565  Validation loss = 4.2020  \n",
      "\n",
      "Fold: 3  Epoch: 440  Training loss = 1.8563  Validation loss = 4.2016  \n",
      "\n",
      "Fold: 3  Epoch: 441  Training loss = 1.8561  Validation loss = 4.2013  \n",
      "\n",
      "Fold: 3  Epoch: 442  Training loss = 1.8559  Validation loss = 4.2010  \n",
      "\n",
      "Fold: 3  Epoch: 443  Training loss = 1.8557  Validation loss = 4.2007  \n",
      "\n",
      "Fold: 3  Epoch: 444  Training loss = 1.8555  Validation loss = 4.2004  \n",
      "\n",
      "Fold: 3  Epoch: 445  Training loss = 1.8553  Validation loss = 4.2001  \n",
      "\n",
      "Fold: 3  Epoch: 446  Training loss = 1.8550  Validation loss = 4.1997  \n",
      "\n",
      "Fold: 3  Epoch: 447  Training loss = 1.8549  Validation loss = 4.1994  \n",
      "\n",
      "Fold: 3  Epoch: 448  Training loss = 1.8547  Validation loss = 4.1992  \n",
      "\n",
      "Fold: 3  Epoch: 449  Training loss = 1.8545  Validation loss = 4.1988  \n",
      "\n",
      "Fold: 3  Epoch: 450  Training loss = 1.8543  Validation loss = 4.1985  \n",
      "\n",
      "Fold: 3  Epoch: 451  Training loss = 1.8541  Validation loss = 4.1983  \n",
      "\n",
      "Fold: 3  Epoch: 452  Training loss = 1.8539  Validation loss = 4.1980  \n",
      "\n",
      "Fold: 3  Epoch: 453  Training loss = 1.8537  Validation loss = 4.1977  \n",
      "\n",
      "Fold: 3  Epoch: 454  Training loss = 1.8535  Validation loss = 4.1973  \n",
      "\n",
      "Fold: 3  Epoch: 455  Training loss = 1.8533  Validation loss = 4.1971  \n",
      "\n",
      "Fold: 3  Epoch: 456  Training loss = 1.8531  Validation loss = 4.1967  \n",
      "\n",
      "Fold: 3  Epoch: 457  Training loss = 1.8529  Validation loss = 4.1965  \n",
      "\n",
      "Fold: 3  Epoch: 458  Training loss = 1.8527  Validation loss = 4.1962  \n",
      "\n",
      "Fold: 3  Epoch: 459  Training loss = 1.8526  Validation loss = 4.1960  \n",
      "\n",
      "Fold: 3  Epoch: 460  Training loss = 1.8524  Validation loss = 4.1957  \n",
      "\n",
      "Fold: 3  Epoch: 461  Training loss = 1.8522  Validation loss = 4.1954  \n",
      "\n",
      "Fold: 3  Epoch: 462  Training loss = 1.8520  Validation loss = 4.1951  \n",
      "\n",
      "Fold: 3  Epoch: 463  Training loss = 1.8518  Validation loss = 4.1949  \n",
      "\n",
      "Fold: 3  Epoch: 464  Training loss = 1.8516  Validation loss = 4.1944  \n",
      "\n",
      "Fold: 3  Epoch: 465  Training loss = 1.8513  Validation loss = 4.1941  \n",
      "\n",
      "Fold: 3  Epoch: 466  Training loss = 1.8511  Validation loss = 4.1937  \n",
      "\n",
      "Fold: 3  Epoch: 467  Training loss = 1.8509  Validation loss = 4.1934  \n",
      "\n",
      "Fold: 3  Epoch: 468  Training loss = 1.8507  Validation loss = 4.1931  \n",
      "\n",
      "Fold: 3  Epoch: 469  Training loss = 1.8506  Validation loss = 4.1929  \n",
      "\n",
      "Fold: 3  Epoch: 470  Training loss = 1.8504  Validation loss = 4.1926  \n",
      "\n",
      "Fold: 3  Epoch: 471  Training loss = 1.8502  Validation loss = 4.1923  \n",
      "\n",
      "Fold: 3  Epoch: 472  Training loss = 1.8500  Validation loss = 4.1920  \n",
      "\n",
      "Fold: 3  Epoch: 473  Training loss = 1.8498  Validation loss = 4.1917  \n",
      "\n",
      "Fold: 3  Epoch: 474  Training loss = 1.8496  Validation loss = 4.1915  \n",
      "\n",
      "Fold: 3  Epoch: 475  Training loss = 1.8495  Validation loss = 4.1912  \n",
      "\n",
      "Fold: 3  Epoch: 476  Training loss = 1.8493  Validation loss = 4.1909  \n",
      "\n",
      "Fold: 3  Epoch: 477  Training loss = 1.8491  Validation loss = 4.1906  \n",
      "\n",
      "Fold: 3  Epoch: 478  Training loss = 1.8489  Validation loss = 4.1904  \n",
      "\n",
      "Fold: 3  Epoch: 479  Training loss = 1.8487  Validation loss = 4.1900  \n",
      "\n",
      "Fold: 3  Epoch: 480  Training loss = 1.8485  Validation loss = 4.1896  \n",
      "\n",
      "Fold: 3  Epoch: 481  Training loss = 1.8483  Validation loss = 4.1894  \n",
      "\n",
      "Fold: 3  Epoch: 482  Training loss = 1.8481  Validation loss = 4.1891  \n",
      "\n",
      "Fold: 3  Epoch: 483  Training loss = 1.8479  Validation loss = 4.1887  \n",
      "\n",
      "Fold: 3  Epoch: 484  Training loss = 1.8477  Validation loss = 4.1884  \n",
      "\n",
      "Fold: 3  Epoch: 485  Training loss = 1.8475  Validation loss = 4.1881  \n",
      "\n",
      "Fold: 3  Epoch: 486  Training loss = 1.8472  Validation loss = 4.1878  \n",
      "\n",
      "Fold: 3  Epoch: 487  Training loss = 1.8471  Validation loss = 4.1875  \n",
      "\n",
      "Fold: 3  Epoch: 488  Training loss = 1.8468  Validation loss = 4.1872  \n",
      "\n",
      "Fold: 3  Epoch: 489  Training loss = 1.8466  Validation loss = 4.1868  \n",
      "\n",
      "Fold: 3  Epoch: 490  Training loss = 1.8465  Validation loss = 4.1866  \n",
      "\n",
      "Fold: 3  Epoch: 491  Training loss = 1.8463  Validation loss = 4.1863  \n",
      "\n",
      "Fold: 3  Epoch: 492  Training loss = 1.8461  Validation loss = 4.1861  \n",
      "\n",
      "Fold: 3  Epoch: 493  Training loss = 1.8459  Validation loss = 4.1858  \n",
      "\n",
      "Fold: 3  Epoch: 494  Training loss = 1.8457  Validation loss = 4.1854  \n",
      "\n",
      "Fold: 3  Epoch: 495  Training loss = 1.8455  Validation loss = 4.1851  \n",
      "\n",
      "Fold: 3  Epoch: 496  Training loss = 1.8453  Validation loss = 4.1848  \n",
      "\n",
      "Fold: 3  Epoch: 497  Training loss = 1.8451  Validation loss = 4.1845  \n",
      "\n",
      "Fold: 3  Epoch: 498  Training loss = 1.8449  Validation loss = 4.1841  \n",
      "\n",
      "Fold: 3  Epoch: 499  Training loss = 1.8447  Validation loss = 4.1838  \n",
      "\n",
      "Fold: 3  Epoch: 500  Training loss = 1.8445  Validation loss = 4.1835  \n",
      "\n",
      "Check model:  Fold: 3  Optimal epoch: 500  \n",
      "\n",
      "Fold: 4  Epoch: 1  Training loss = 1.9866  Validation loss = 5.2316  \n",
      "\n",
      "Fold: 4  Epoch: 2  Training loss = 1.9864  Validation loss = 5.2312  \n",
      "\n",
      "Fold: 4  Epoch: 3  Training loss = 1.9862  Validation loss = 5.2308  \n",
      "\n",
      "Fold: 4  Epoch: 4  Training loss = 1.9859  Validation loss = 5.2304  \n",
      "\n",
      "Fold: 4  Epoch: 5  Training loss = 1.9858  Validation loss = 5.2302  \n",
      "\n",
      "Fold: 4  Epoch: 6  Training loss = 1.9856  Validation loss = 5.2298  \n",
      "\n",
      "Fold: 4  Epoch: 7  Training loss = 1.9854  Validation loss = 5.2295  \n",
      "\n",
      "Fold: 4  Epoch: 8  Training loss = 1.9852  Validation loss = 5.2292  \n",
      "\n",
      "Fold: 4  Epoch: 9  Training loss = 1.9849  Validation loss = 5.2287  \n",
      "\n",
      "Fold: 4  Epoch: 10  Training loss = 1.9847  Validation loss = 5.2283  \n",
      "\n",
      "Fold: 4  Epoch: 11  Training loss = 1.9844  Validation loss = 5.2279  \n",
      "\n",
      "Fold: 4  Epoch: 12  Training loss = 1.9843  Validation loss = 5.2277  \n",
      "\n",
      "Fold: 4  Epoch: 13  Training loss = 1.9841  Validation loss = 5.2274  \n",
      "\n",
      "Fold: 4  Epoch: 14  Training loss = 1.9839  Validation loss = 5.2271  \n",
      "\n",
      "Fold: 4  Epoch: 15  Training loss = 1.9837  Validation loss = 5.2268  \n",
      "\n",
      "Fold: 4  Epoch: 16  Training loss = 1.9835  Validation loss = 5.2265  \n",
      "\n",
      "Fold: 4  Epoch: 17  Training loss = 1.9833  Validation loss = 5.2262  \n",
      "\n",
      "Fold: 4  Epoch: 18  Training loss = 1.9831  Validation loss = 5.2257  \n",
      "\n",
      "Fold: 4  Epoch: 19  Training loss = 1.9829  Validation loss = 5.2254  \n",
      "\n",
      "Fold: 4  Epoch: 20  Training loss = 1.9826  Validation loss = 5.2250  \n",
      "\n",
      "Fold: 4  Epoch: 21  Training loss = 1.9824  Validation loss = 5.2246  \n",
      "\n",
      "Fold: 4  Epoch: 22  Training loss = 1.9821  Validation loss = 5.2242  \n",
      "\n",
      "Fold: 4  Epoch: 23  Training loss = 1.9819  Validation loss = 5.2238  \n",
      "\n",
      "Fold: 4  Epoch: 24  Training loss = 1.9817  Validation loss = 5.2233  \n",
      "\n",
      "Fold: 4  Epoch: 25  Training loss = 1.9814  Validation loss = 5.2230  \n",
      "\n",
      "Fold: 4  Epoch: 26  Training loss = 1.9812  Validation loss = 5.2225  \n",
      "\n",
      "Fold: 4  Epoch: 27  Training loss = 1.9809  Validation loss = 5.2221  \n",
      "\n",
      "Fold: 4  Epoch: 28  Training loss = 1.9807  Validation loss = 5.2218  \n",
      "\n",
      "Fold: 4  Epoch: 29  Training loss = 1.9805  Validation loss = 5.2214  \n",
      "\n",
      "Fold: 4  Epoch: 30  Training loss = 1.9802  Validation loss = 5.2210  \n",
      "\n",
      "Fold: 4  Epoch: 31  Training loss = 1.9801  Validation loss = 5.2207  \n",
      "\n",
      "Fold: 4  Epoch: 32  Training loss = 1.9799  Validation loss = 5.2204  \n",
      "\n",
      "Fold: 4  Epoch: 33  Training loss = 1.9796  Validation loss = 5.2200  \n",
      "\n",
      "Fold: 4  Epoch: 34  Training loss = 1.9795  Validation loss = 5.2197  \n",
      "\n",
      "Fold: 4  Epoch: 35  Training loss = 1.9792  Validation loss = 5.2193  \n",
      "\n",
      "Fold: 4  Epoch: 36  Training loss = 1.9790  Validation loss = 5.2189  \n",
      "\n",
      "Fold: 4  Epoch: 37  Training loss = 1.9788  Validation loss = 5.2186  \n",
      "\n",
      "Fold: 4  Epoch: 38  Training loss = 1.9786  Validation loss = 5.2183  \n",
      "\n",
      "Fold: 4  Epoch: 39  Training loss = 1.9784  Validation loss = 5.2179  \n",
      "\n",
      "Fold: 4  Epoch: 40  Training loss = 1.9782  Validation loss = 5.2176  \n",
      "\n",
      "Fold: 4  Epoch: 41  Training loss = 1.9779  Validation loss = 5.2170  \n",
      "\n",
      "Fold: 4  Epoch: 42  Training loss = 1.9776  Validation loss = 5.2167  \n",
      "\n",
      "Fold: 4  Epoch: 43  Training loss = 1.9774  Validation loss = 5.2162  \n",
      "\n",
      "Fold: 4  Epoch: 44  Training loss = 1.9772  Validation loss = 5.2159  \n",
      "\n",
      "Fold: 4  Epoch: 45  Training loss = 1.9769  Validation loss = 5.2155  \n",
      "\n",
      "Fold: 4  Epoch: 46  Training loss = 1.9767  Validation loss = 5.2151  \n",
      "\n",
      "Fold: 4  Epoch: 47  Training loss = 1.9764  Validation loss = 5.2146  \n",
      "\n",
      "Fold: 4  Epoch: 48  Training loss = 1.9762  Validation loss = 5.2143  \n",
      "\n",
      "Fold: 4  Epoch: 49  Training loss = 1.9760  Validation loss = 5.2140  \n",
      "\n",
      "Fold: 4  Epoch: 50  Training loss = 1.9759  Validation loss = 5.2137  \n",
      "\n",
      "Fold: 4  Epoch: 51  Training loss = 1.9757  Validation loss = 5.2134  \n",
      "\n",
      "Fold: 4  Epoch: 52  Training loss = 1.9755  Validation loss = 5.2130  \n",
      "\n",
      "Fold: 4  Epoch: 53  Training loss = 1.9752  Validation loss = 5.2127  \n",
      "\n",
      "Fold: 4  Epoch: 54  Training loss = 1.9750  Validation loss = 5.2123  \n",
      "\n",
      "Fold: 4  Epoch: 55  Training loss = 1.9748  Validation loss = 5.2120  \n",
      "\n",
      "Fold: 4  Epoch: 56  Training loss = 1.9746  Validation loss = 5.2116  \n",
      "\n",
      "Fold: 4  Epoch: 57  Training loss = 1.9744  Validation loss = 5.2113  \n",
      "\n",
      "Fold: 4  Epoch: 58  Training loss = 1.9742  Validation loss = 5.2110  \n",
      "\n",
      "Fold: 4  Epoch: 59  Training loss = 1.9740  Validation loss = 5.2107  \n",
      "\n",
      "Fold: 4  Epoch: 60  Training loss = 1.9739  Validation loss = 5.2104  \n",
      "\n",
      "Fold: 4  Epoch: 61  Training loss = 1.9737  Validation loss = 5.2101  \n",
      "\n",
      "Fold: 4  Epoch: 62  Training loss = 1.9735  Validation loss = 5.2098  \n",
      "\n",
      "Fold: 4  Epoch: 63  Training loss = 1.9733  Validation loss = 5.2094  \n",
      "\n",
      "Fold: 4  Epoch: 64  Training loss = 1.9731  Validation loss = 5.2091  \n",
      "\n",
      "Fold: 4  Epoch: 65  Training loss = 1.9728  Validation loss = 5.2087  \n",
      "\n",
      "Fold: 4  Epoch: 66  Training loss = 1.9726  Validation loss = 5.2083  \n",
      "\n",
      "Fold: 4  Epoch: 67  Training loss = 1.9723  Validation loss = 5.2079  \n",
      "\n",
      "Fold: 4  Epoch: 68  Training loss = 1.9722  Validation loss = 5.2076  \n",
      "\n",
      "Fold: 4  Epoch: 69  Training loss = 1.9720  Validation loss = 5.2073  \n",
      "\n",
      "Fold: 4  Epoch: 70  Training loss = 1.9718  Validation loss = 5.2069  \n",
      "\n",
      "Fold: 4  Epoch: 71  Training loss = 1.9715  Validation loss = 5.2066  \n",
      "\n",
      "Fold: 4  Epoch: 72  Training loss = 1.9713  Validation loss = 5.2062  \n",
      "\n",
      "Fold: 4  Epoch: 73  Training loss = 1.9712  Validation loss = 5.2059  \n",
      "\n",
      "Fold: 4  Epoch: 74  Training loss = 1.9709  Validation loss = 5.2055  \n",
      "\n",
      "Fold: 4  Epoch: 75  Training loss = 1.9707  Validation loss = 5.2051  \n",
      "\n",
      "Fold: 4  Epoch: 76  Training loss = 1.9705  Validation loss = 5.2048  \n",
      "\n",
      "Fold: 4  Epoch: 77  Training loss = 1.9702  Validation loss = 5.2044  \n",
      "\n",
      "Fold: 4  Epoch: 78  Training loss = 1.9700  Validation loss = 5.2040  \n",
      "\n",
      "Fold: 4  Epoch: 79  Training loss = 1.9698  Validation loss = 5.2037  \n",
      "\n",
      "Fold: 4  Epoch: 80  Training loss = 1.9695  Validation loss = 5.2033  \n",
      "\n",
      "Fold: 4  Epoch: 81  Training loss = 1.9693  Validation loss = 5.2030  \n",
      "\n",
      "Fold: 4  Epoch: 82  Training loss = 1.9691  Validation loss = 5.2025  \n",
      "\n",
      "Fold: 4  Epoch: 83  Training loss = 1.9689  Validation loss = 5.2022  \n",
      "\n",
      "Fold: 4  Epoch: 84  Training loss = 1.9687  Validation loss = 5.2019  \n",
      "\n",
      "Fold: 4  Epoch: 85  Training loss = 1.9685  Validation loss = 5.2015  \n",
      "\n",
      "Fold: 4  Epoch: 86  Training loss = 1.9682  Validation loss = 5.2011  \n",
      "\n",
      "Fold: 4  Epoch: 87  Training loss = 1.9680  Validation loss = 5.2008  \n",
      "\n",
      "Fold: 4  Epoch: 88  Training loss = 1.9678  Validation loss = 5.2004  \n",
      "\n",
      "Fold: 4  Epoch: 89  Training loss = 1.9676  Validation loss = 5.2000  \n",
      "\n",
      "Fold: 4  Epoch: 90  Training loss = 1.9674  Validation loss = 5.1997  \n",
      "\n",
      "Fold: 4  Epoch: 91  Training loss = 1.9671  Validation loss = 5.1993  \n",
      "\n",
      "Fold: 4  Epoch: 92  Training loss = 1.9669  Validation loss = 5.1989  \n",
      "\n",
      "Fold: 4  Epoch: 93  Training loss = 1.9667  Validation loss = 5.1986  \n",
      "\n",
      "Fold: 4  Epoch: 94  Training loss = 1.9665  Validation loss = 5.1983  \n",
      "\n",
      "Fold: 4  Epoch: 95  Training loss = 1.9662  Validation loss = 5.1978  \n",
      "\n",
      "Fold: 4  Epoch: 96  Training loss = 1.9660  Validation loss = 5.1974  \n",
      "\n",
      "Fold: 4  Epoch: 97  Training loss = 1.9658  Validation loss = 5.1971  \n",
      "\n",
      "Fold: 4  Epoch: 98  Training loss = 1.9656  Validation loss = 5.1968  \n",
      "\n",
      "Fold: 4  Epoch: 99  Training loss = 1.9655  Validation loss = 5.1965  \n",
      "\n",
      "Fold: 4  Epoch: 100  Training loss = 1.9652  Validation loss = 5.1961  \n",
      "\n",
      "Fold: 4  Epoch: 101  Training loss = 1.9651  Validation loss = 5.1958  \n",
      "\n",
      "Fold: 4  Epoch: 102  Training loss = 1.9648  Validation loss = 5.1955  \n",
      "\n",
      "Fold: 4  Epoch: 103  Training loss = 1.9646  Validation loss = 5.1951  \n",
      "\n",
      "Fold: 4  Epoch: 104  Training loss = 1.9644  Validation loss = 5.1948  \n",
      "\n",
      "Fold: 4  Epoch: 105  Training loss = 1.9642  Validation loss = 5.1944  \n",
      "\n",
      "Fold: 4  Epoch: 106  Training loss = 1.9639  Validation loss = 5.1939  \n",
      "\n",
      "Fold: 4  Epoch: 107  Training loss = 1.9637  Validation loss = 5.1935  \n",
      "\n",
      "Fold: 4  Epoch: 108  Training loss = 1.9635  Validation loss = 5.1933  \n",
      "\n",
      "Fold: 4  Epoch: 109  Training loss = 1.9633  Validation loss = 5.1929  \n",
      "\n",
      "Fold: 4  Epoch: 110  Training loss = 1.9631  Validation loss = 5.1925  \n",
      "\n",
      "Fold: 4  Epoch: 111  Training loss = 1.9629  Validation loss = 5.1922  \n",
      "\n",
      "Fold: 4  Epoch: 112  Training loss = 1.9627  Validation loss = 5.1919  \n",
      "\n",
      "Fold: 4  Epoch: 113  Training loss = 1.9625  Validation loss = 5.1915  \n",
      "\n",
      "Fold: 4  Epoch: 114  Training loss = 1.9623  Validation loss = 5.1912  \n",
      "\n",
      "Fold: 4  Epoch: 115  Training loss = 1.9620  Validation loss = 5.1907  \n",
      "\n",
      "Fold: 4  Epoch: 116  Training loss = 1.9618  Validation loss = 5.1904  \n",
      "\n",
      "Fold: 4  Epoch: 117  Training loss = 1.9616  Validation loss = 5.1901  \n",
      "\n",
      "Fold: 4  Epoch: 118  Training loss = 1.9615  Validation loss = 5.1898  \n",
      "\n",
      "Fold: 4  Epoch: 119  Training loss = 1.9613  Validation loss = 5.1895  \n",
      "\n",
      "Fold: 4  Epoch: 120  Training loss = 1.9610  Validation loss = 5.1892  \n",
      "\n",
      "Fold: 4  Epoch: 121  Training loss = 1.9608  Validation loss = 5.1888  \n",
      "\n",
      "Fold: 4  Epoch: 122  Training loss = 1.9606  Validation loss = 5.1884  \n",
      "\n",
      "Fold: 4  Epoch: 123  Training loss = 1.9605  Validation loss = 5.1882  \n",
      "\n",
      "Fold: 4  Epoch: 124  Training loss = 1.9602  Validation loss = 5.1878  \n",
      "\n",
      "Fold: 4  Epoch: 125  Training loss = 1.9600  Validation loss = 5.1874  \n",
      "\n",
      "Fold: 4  Epoch: 126  Training loss = 1.9598  Validation loss = 5.1871  \n",
      "\n",
      "Fold: 4  Epoch: 127  Training loss = 1.9597  Validation loss = 5.1868  \n",
      "\n",
      "Fold: 4  Epoch: 128  Training loss = 1.9594  Validation loss = 5.1865  \n",
      "\n",
      "Fold: 4  Epoch: 129  Training loss = 1.9592  Validation loss = 5.1860  \n",
      "\n",
      "Fold: 4  Epoch: 130  Training loss = 1.9589  Validation loss = 5.1856  \n",
      "\n",
      "Fold: 4  Epoch: 131  Training loss = 1.9587  Validation loss = 5.1853  \n",
      "\n",
      "Fold: 4  Epoch: 132  Training loss = 1.9585  Validation loss = 5.1848  \n",
      "\n",
      "Fold: 4  Epoch: 133  Training loss = 1.9582  Validation loss = 5.1844  \n",
      "\n",
      "Fold: 4  Epoch: 134  Training loss = 1.9580  Validation loss = 5.1840  \n",
      "\n",
      "Fold: 4  Epoch: 135  Training loss = 1.9578  Validation loss = 5.1836  \n",
      "\n",
      "Fold: 4  Epoch: 136  Training loss = 1.9575  Validation loss = 5.1832  \n",
      "\n",
      "Fold: 4  Epoch: 137  Training loss = 1.9573  Validation loss = 5.1829  \n",
      "\n",
      "Fold: 4  Epoch: 138  Training loss = 1.9571  Validation loss = 5.1825  \n",
      "\n",
      "Fold: 4  Epoch: 139  Training loss = 1.9569  Validation loss = 5.1821  \n",
      "\n",
      "Fold: 4  Epoch: 140  Training loss = 1.9566  Validation loss = 5.1817  \n",
      "\n",
      "Fold: 4  Epoch: 141  Training loss = 1.9564  Validation loss = 5.1814  \n",
      "\n",
      "Fold: 4  Epoch: 142  Training loss = 1.9562  Validation loss = 5.1810  \n",
      "\n",
      "Fold: 4  Epoch: 143  Training loss = 1.9560  Validation loss = 5.1807  \n",
      "\n",
      "Fold: 4  Epoch: 144  Training loss = 1.9559  Validation loss = 5.1805  \n",
      "\n",
      "Fold: 4  Epoch: 145  Training loss = 1.9557  Validation loss = 5.1801  \n",
      "\n",
      "Fold: 4  Epoch: 146  Training loss = 1.9554  Validation loss = 5.1797  \n",
      "\n",
      "Fold: 4  Epoch: 147  Training loss = 1.9553  Validation loss = 5.1794  \n",
      "\n",
      "Fold: 4  Epoch: 148  Training loss = 1.9550  Validation loss = 5.1790  \n",
      "\n",
      "Fold: 4  Epoch: 149  Training loss = 1.9548  Validation loss = 5.1786  \n",
      "\n",
      "Fold: 4  Epoch: 150  Training loss = 1.9546  Validation loss = 5.1782  \n",
      "\n",
      "Fold: 4  Epoch: 151  Training loss = 1.9544  Validation loss = 5.1779  \n",
      "\n",
      "Fold: 4  Epoch: 152  Training loss = 1.9542  Validation loss = 5.1776  \n",
      "\n",
      "Fold: 4  Epoch: 153  Training loss = 1.9540  Validation loss = 5.1772  \n",
      "\n",
      "Fold: 4  Epoch: 154  Training loss = 1.9538  Validation loss = 5.1769  \n",
      "\n",
      "Fold: 4  Epoch: 155  Training loss = 1.9536  Validation loss = 5.1766  \n",
      "\n",
      "Fold: 4  Epoch: 156  Training loss = 1.9534  Validation loss = 5.1763  \n",
      "\n",
      "Fold: 4  Epoch: 157  Training loss = 1.9532  Validation loss = 5.1759  \n",
      "\n",
      "Fold: 4  Epoch: 158  Training loss = 1.9530  Validation loss = 5.1755  \n",
      "\n",
      "Fold: 4  Epoch: 159  Training loss = 1.9528  Validation loss = 5.1753  \n",
      "\n",
      "Fold: 4  Epoch: 160  Training loss = 1.9526  Validation loss = 5.1749  \n",
      "\n",
      "Fold: 4  Epoch: 161  Training loss = 1.9524  Validation loss = 5.1745  \n",
      "\n",
      "Fold: 4  Epoch: 162  Training loss = 1.9521  Validation loss = 5.1740  \n",
      "\n",
      "Fold: 4  Epoch: 163  Training loss = 1.9518  Validation loss = 5.1736  \n",
      "\n",
      "Fold: 4  Epoch: 164  Training loss = 1.9517  Validation loss = 5.1733  \n",
      "\n",
      "Fold: 4  Epoch: 165  Training loss = 1.9514  Validation loss = 5.1729  \n",
      "\n",
      "Fold: 4  Epoch: 166  Training loss = 1.9512  Validation loss = 5.1725  \n",
      "\n",
      "Fold: 4  Epoch: 167  Training loss = 1.9510  Validation loss = 5.1723  \n",
      "\n",
      "Fold: 4  Epoch: 168  Training loss = 1.9508  Validation loss = 5.1719  \n",
      "\n",
      "Fold: 4  Epoch: 169  Training loss = 1.9506  Validation loss = 5.1715  \n",
      "\n",
      "Fold: 4  Epoch: 170  Training loss = 1.9504  Validation loss = 5.1713  \n",
      "\n",
      "Fold: 4  Epoch: 171  Training loss = 1.9502  Validation loss = 5.1708  \n",
      "\n",
      "Fold: 4  Epoch: 172  Training loss = 1.9499  Validation loss = 5.1705  \n",
      "\n",
      "Fold: 4  Epoch: 173  Training loss = 1.9498  Validation loss = 5.1702  \n",
      "\n",
      "Fold: 4  Epoch: 174  Training loss = 1.9495  Validation loss = 5.1698  \n",
      "\n",
      "Fold: 4  Epoch: 175  Training loss = 1.9493  Validation loss = 5.1694  \n",
      "\n",
      "Fold: 4  Epoch: 176  Training loss = 1.9491  Validation loss = 5.1691  \n",
      "\n",
      "Fold: 4  Epoch: 177  Training loss = 1.9489  Validation loss = 5.1687  \n",
      "\n",
      "Fold: 4  Epoch: 178  Training loss = 1.9487  Validation loss = 5.1684  \n",
      "\n",
      "Fold: 4  Epoch: 179  Training loss = 1.9485  Validation loss = 5.1680  \n",
      "\n",
      "Fold: 4  Epoch: 180  Training loss = 1.9483  Validation loss = 5.1677  \n",
      "\n",
      "Fold: 4  Epoch: 181  Training loss = 1.9481  Validation loss = 5.1673  \n",
      "\n",
      "Fold: 4  Epoch: 182  Training loss = 1.9479  Validation loss = 5.1670  \n",
      "\n",
      "Fold: 4  Epoch: 183  Training loss = 1.9476  Validation loss = 5.1665  \n",
      "\n",
      "Fold: 4  Epoch: 184  Training loss = 1.9474  Validation loss = 5.1661  \n",
      "\n",
      "Fold: 4  Epoch: 185  Training loss = 1.9472  Validation loss = 5.1658  \n",
      "\n",
      "Fold: 4  Epoch: 186  Training loss = 1.9470  Validation loss = 5.1655  \n",
      "\n",
      "Fold: 4  Epoch: 187  Training loss = 1.9467  Validation loss = 5.1650  \n",
      "\n",
      "Fold: 4  Epoch: 188  Training loss = 1.9465  Validation loss = 5.1646  \n",
      "\n",
      "Fold: 4  Epoch: 189  Training loss = 1.9463  Validation loss = 5.1643  \n",
      "\n",
      "Fold: 4  Epoch: 190  Training loss = 1.9461  Validation loss = 5.1639  \n",
      "\n",
      "Fold: 4  Epoch: 191  Training loss = 1.9459  Validation loss = 5.1635  \n",
      "\n",
      "Fold: 4  Epoch: 192  Training loss = 1.9457  Validation loss = 5.1633  \n",
      "\n",
      "Fold: 4  Epoch: 193  Training loss = 1.9455  Validation loss = 5.1629  \n",
      "\n",
      "Fold: 4  Epoch: 194  Training loss = 1.9453  Validation loss = 5.1625  \n",
      "\n",
      "Fold: 4  Epoch: 195  Training loss = 1.9450  Validation loss = 5.1621  \n",
      "\n",
      "Fold: 4  Epoch: 196  Training loss = 1.9449  Validation loss = 5.1618  \n",
      "\n",
      "Fold: 4  Epoch: 197  Training loss = 1.9447  Validation loss = 5.1615  \n",
      "\n",
      "Fold: 4  Epoch: 198  Training loss = 1.9445  Validation loss = 5.1612  \n",
      "\n",
      "Fold: 4  Epoch: 199  Training loss = 1.9442  Validation loss = 5.1607  \n",
      "\n",
      "Fold: 4  Epoch: 200  Training loss = 1.9440  Validation loss = 5.1604  \n",
      "\n",
      "Fold: 4  Epoch: 201  Training loss = 1.9438  Validation loss = 5.1600  \n",
      "\n",
      "Fold: 4  Epoch: 202  Training loss = 1.9436  Validation loss = 5.1596  \n",
      "\n",
      "Fold: 4  Epoch: 203  Training loss = 1.9434  Validation loss = 5.1593  \n",
      "\n",
      "Fold: 4  Epoch: 204  Training loss = 1.9431  Validation loss = 5.1588  \n",
      "\n",
      "Fold: 4  Epoch: 205  Training loss = 1.9429  Validation loss = 5.1585  \n",
      "\n",
      "Fold: 4  Epoch: 206  Training loss = 1.9428  Validation loss = 5.1582  \n",
      "\n",
      "Fold: 4  Epoch: 207  Training loss = 1.9426  Validation loss = 5.1579  \n",
      "\n",
      "Fold: 4  Epoch: 208  Training loss = 1.9424  Validation loss = 5.1576  \n",
      "\n",
      "Fold: 4  Epoch: 209  Training loss = 1.9421  Validation loss = 5.1571  \n",
      "\n",
      "Fold: 4  Epoch: 210  Training loss = 1.9419  Validation loss = 5.1568  \n",
      "\n",
      "Fold: 4  Epoch: 211  Training loss = 1.9417  Validation loss = 5.1564  \n",
      "\n",
      "Fold: 4  Epoch: 212  Training loss = 1.9415  Validation loss = 5.1561  \n",
      "\n",
      "Fold: 4  Epoch: 213  Training loss = 1.9413  Validation loss = 5.1558  \n",
      "\n",
      "Fold: 4  Epoch: 214  Training loss = 1.9411  Validation loss = 5.1554  \n",
      "\n",
      "Fold: 4  Epoch: 215  Training loss = 1.9409  Validation loss = 5.1550  \n",
      "\n",
      "Fold: 4  Epoch: 216  Training loss = 1.9407  Validation loss = 5.1547  \n",
      "\n",
      "Fold: 4  Epoch: 217  Training loss = 1.9405  Validation loss = 5.1544  \n",
      "\n",
      "Fold: 4  Epoch: 218  Training loss = 1.9403  Validation loss = 5.1541  \n",
      "\n",
      "Fold: 4  Epoch: 219  Training loss = 1.9402  Validation loss = 5.1538  \n",
      "\n",
      "Fold: 4  Epoch: 220  Training loss = 1.9399  Validation loss = 5.1534  \n",
      "\n",
      "Fold: 4  Epoch: 221  Training loss = 1.9397  Validation loss = 5.1530  \n",
      "\n",
      "Fold: 4  Epoch: 222  Training loss = 1.9395  Validation loss = 5.1527  \n",
      "\n",
      "Fold: 4  Epoch: 223  Training loss = 1.9393  Validation loss = 5.1523  \n",
      "\n",
      "Fold: 4  Epoch: 224  Training loss = 1.9391  Validation loss = 5.1520  \n",
      "\n",
      "Fold: 4  Epoch: 225  Training loss = 1.9389  Validation loss = 5.1515  \n",
      "\n",
      "Fold: 4  Epoch: 226  Training loss = 1.9387  Validation loss = 5.1513  \n",
      "\n",
      "Fold: 4  Epoch: 227  Training loss = 1.9385  Validation loss = 5.1508  \n",
      "\n",
      "Fold: 4  Epoch: 228  Training loss = 1.9383  Validation loss = 5.1505  \n",
      "\n",
      "Fold: 4  Epoch: 229  Training loss = 1.9381  Validation loss = 5.1502  \n",
      "\n",
      "Fold: 4  Epoch: 230  Training loss = 1.9379  Validation loss = 5.1498  \n",
      "\n",
      "Fold: 4  Epoch: 231  Training loss = 1.9377  Validation loss = 5.1495  \n",
      "\n",
      "Fold: 4  Epoch: 232  Training loss = 1.9374  Validation loss = 5.1491  \n",
      "\n",
      "Fold: 4  Epoch: 233  Training loss = 1.9372  Validation loss = 5.1487  \n",
      "\n",
      "Fold: 4  Epoch: 234  Training loss = 1.9371  Validation loss = 5.1485  \n",
      "\n",
      "Fold: 4  Epoch: 235  Training loss = 1.9369  Validation loss = 5.1481  \n",
      "\n",
      "Fold: 4  Epoch: 236  Training loss = 1.9367  Validation loss = 5.1478  \n",
      "\n",
      "Fold: 4  Epoch: 237  Training loss = 1.9365  Validation loss = 5.1474  \n",
      "\n",
      "Fold: 4  Epoch: 238  Training loss = 1.9363  Validation loss = 5.1472  \n",
      "\n",
      "Fold: 4  Epoch: 239  Training loss = 1.9362  Validation loss = 5.1469  \n",
      "\n",
      "Fold: 4  Epoch: 240  Training loss = 1.9359  Validation loss = 5.1465  \n",
      "\n",
      "Fold: 4  Epoch: 241  Training loss = 1.9357  Validation loss = 5.1462  \n",
      "\n",
      "Fold: 4  Epoch: 242  Training loss = 1.9355  Validation loss = 5.1458  \n",
      "\n",
      "Fold: 4  Epoch: 243  Training loss = 1.9353  Validation loss = 5.1455  \n",
      "\n",
      "Fold: 4  Epoch: 244  Training loss = 1.9351  Validation loss = 5.1451  \n",
      "\n",
      "Fold: 4  Epoch: 245  Training loss = 1.9350  Validation loss = 5.1448  \n",
      "\n",
      "Fold: 4  Epoch: 246  Training loss = 1.9347  Validation loss = 5.1444  \n",
      "\n",
      "Fold: 4  Epoch: 247  Training loss = 1.9345  Validation loss = 5.1440  \n",
      "\n",
      "Fold: 4  Epoch: 248  Training loss = 1.9343  Validation loss = 5.1437  \n",
      "\n",
      "Fold: 4  Epoch: 249  Training loss = 1.9341  Validation loss = 5.1434  \n",
      "\n",
      "Fold: 4  Epoch: 250  Training loss = 1.9339  Validation loss = 5.1431  \n",
      "\n",
      "Fold: 4  Epoch: 251  Training loss = 1.9337  Validation loss = 5.1428  \n",
      "\n",
      "Fold: 4  Epoch: 252  Training loss = 1.9336  Validation loss = 5.1424  \n",
      "\n",
      "Fold: 4  Epoch: 253  Training loss = 1.9333  Validation loss = 5.1420  \n",
      "\n",
      "Fold: 4  Epoch: 254  Training loss = 1.9331  Validation loss = 5.1417  \n",
      "\n",
      "Fold: 4  Epoch: 255  Training loss = 1.9329  Validation loss = 5.1413  \n",
      "\n",
      "Fold: 4  Epoch: 256  Training loss = 1.9327  Validation loss = 5.1410  \n",
      "\n",
      "Fold: 4  Epoch: 257  Training loss = 1.9325  Validation loss = 5.1406  \n",
      "\n",
      "Fold: 4  Epoch: 258  Training loss = 1.9322  Validation loss = 5.1402  \n",
      "\n",
      "Fold: 4  Epoch: 259  Training loss = 1.9320  Validation loss = 5.1398  \n",
      "\n",
      "Fold: 4  Epoch: 260  Training loss = 1.9318  Validation loss = 5.1394  \n",
      "\n",
      "Fold: 4  Epoch: 261  Training loss = 1.9316  Validation loss = 5.1391  \n",
      "\n",
      "Fold: 4  Epoch: 262  Training loss = 1.9314  Validation loss = 5.1387  \n",
      "\n",
      "Fold: 4  Epoch: 263  Training loss = 1.9313  Validation loss = 5.1385  \n",
      "\n",
      "Fold: 4  Epoch: 264  Training loss = 1.9311  Validation loss = 5.1381  \n",
      "\n",
      "Fold: 4  Epoch: 265  Training loss = 1.9308  Validation loss = 5.1377  \n",
      "\n",
      "Fold: 4  Epoch: 266  Training loss = 1.9306  Validation loss = 5.1374  \n",
      "\n",
      "Fold: 4  Epoch: 267  Training loss = 1.9304  Validation loss = 5.1370  \n",
      "\n",
      "Fold: 4  Epoch: 268  Training loss = 1.9302  Validation loss = 5.1366  \n",
      "\n",
      "Fold: 4  Epoch: 269  Training loss = 1.9300  Validation loss = 5.1363  \n",
      "\n",
      "Fold: 4  Epoch: 270  Training loss = 1.9298  Validation loss = 5.1360  \n",
      "\n",
      "Fold: 4  Epoch: 271  Training loss = 1.9295  Validation loss = 5.1355  \n",
      "\n",
      "Fold: 4  Epoch: 272  Training loss = 1.9294  Validation loss = 5.1351  \n",
      "\n",
      "Fold: 4  Epoch: 273  Training loss = 1.9291  Validation loss = 5.1347  \n",
      "\n",
      "Fold: 4  Epoch: 274  Training loss = 1.9290  Validation loss = 5.1345  \n",
      "\n",
      "Fold: 4  Epoch: 275  Training loss = 1.9288  Validation loss = 5.1342  \n",
      "\n",
      "Fold: 4  Epoch: 276  Training loss = 1.9286  Validation loss = 5.1339  \n",
      "\n",
      "Fold: 4  Epoch: 277  Training loss = 1.9284  Validation loss = 5.1335  \n",
      "\n",
      "Fold: 4  Epoch: 278  Training loss = 1.9282  Validation loss = 5.1331  \n",
      "\n",
      "Fold: 4  Epoch: 279  Training loss = 1.9279  Validation loss = 5.1326  \n",
      "\n",
      "Fold: 4  Epoch: 280  Training loss = 1.9277  Validation loss = 5.1323  \n",
      "\n",
      "Fold: 4  Epoch: 281  Training loss = 1.9275  Validation loss = 5.1320  \n",
      "\n",
      "Fold: 4  Epoch: 282  Training loss = 1.9274  Validation loss = 5.1317  \n",
      "\n",
      "Fold: 4  Epoch: 283  Training loss = 1.9272  Validation loss = 5.1313  \n",
      "\n",
      "Fold: 4  Epoch: 284  Training loss = 1.9269  Validation loss = 5.1309  \n",
      "\n",
      "Fold: 4  Epoch: 285  Training loss = 1.9268  Validation loss = 5.1307  \n",
      "\n",
      "Fold: 4  Epoch: 286  Training loss = 1.9266  Validation loss = 5.1304  \n",
      "\n",
      "Fold: 4  Epoch: 287  Training loss = 1.9264  Validation loss = 5.1301  \n",
      "\n",
      "Fold: 4  Epoch: 288  Training loss = 1.9263  Validation loss = 5.1298  \n",
      "\n",
      "Fold: 4  Epoch: 289  Training loss = 1.9260  Validation loss = 5.1294  \n",
      "\n",
      "Fold: 4  Epoch: 290  Training loss = 1.9258  Validation loss = 5.1291  \n",
      "\n",
      "Fold: 4  Epoch: 291  Training loss = 1.9256  Validation loss = 5.1286  \n",
      "\n",
      "Fold: 4  Epoch: 292  Training loss = 1.9254  Validation loss = 5.1283  \n",
      "\n",
      "Fold: 4  Epoch: 293  Training loss = 1.9252  Validation loss = 5.1280  \n",
      "\n",
      "Fold: 4  Epoch: 294  Training loss = 1.9250  Validation loss = 5.1276  \n",
      "\n",
      "Fold: 4  Epoch: 295  Training loss = 1.9248  Validation loss = 5.1272  \n",
      "\n",
      "Fold: 4  Epoch: 296  Training loss = 1.9246  Validation loss = 5.1269  \n",
      "\n",
      "Fold: 4  Epoch: 297  Training loss = 1.9244  Validation loss = 5.1267  \n",
      "\n",
      "Fold: 4  Epoch: 298  Training loss = 1.9243  Validation loss = 5.1263  \n",
      "\n",
      "Fold: 4  Epoch: 299  Training loss = 1.9241  Validation loss = 5.1261  \n",
      "\n",
      "Fold: 4  Epoch: 300  Training loss = 1.9239  Validation loss = 5.1257  \n",
      "\n",
      "Fold: 4  Epoch: 301  Training loss = 1.9237  Validation loss = 5.1254  \n",
      "\n",
      "Fold: 4  Epoch: 302  Training loss = 1.9235  Validation loss = 5.1250  \n",
      "\n",
      "Fold: 4  Epoch: 303  Training loss = 1.9233  Validation loss = 5.1246  \n",
      "\n",
      "Fold: 4  Epoch: 304  Training loss = 1.9231  Validation loss = 5.1243  \n",
      "\n",
      "Fold: 4  Epoch: 305  Training loss = 1.9229  Validation loss = 5.1240  \n",
      "\n",
      "Fold: 4  Epoch: 306  Training loss = 1.9227  Validation loss = 5.1236  \n",
      "\n",
      "Fold: 4  Epoch: 307  Training loss = 1.9225  Validation loss = 5.1232  \n",
      "\n",
      "Fold: 4  Epoch: 308  Training loss = 1.9223  Validation loss = 5.1229  \n",
      "\n",
      "Fold: 4  Epoch: 309  Training loss = 1.9221  Validation loss = 5.1226  \n",
      "\n",
      "Fold: 4  Epoch: 310  Training loss = 1.9219  Validation loss = 5.1222  \n",
      "\n",
      "Fold: 4  Epoch: 311  Training loss = 1.9218  Validation loss = 5.1220  \n",
      "\n",
      "Fold: 4  Epoch: 312  Training loss = 1.9216  Validation loss = 5.1217  \n",
      "\n",
      "Fold: 4  Epoch: 313  Training loss = 1.9214  Validation loss = 5.1213  \n",
      "\n",
      "Fold: 4  Epoch: 314  Training loss = 1.9212  Validation loss = 5.1210  \n",
      "\n",
      "Fold: 4  Epoch: 315  Training loss = 1.9209  Validation loss = 5.1206  \n",
      "\n",
      "Fold: 4  Epoch: 316  Training loss = 1.9208  Validation loss = 5.1203  \n",
      "\n",
      "Fold: 4  Epoch: 317  Training loss = 1.9206  Validation loss = 5.1200  \n",
      "\n",
      "Fold: 4  Epoch: 318  Training loss = 1.9204  Validation loss = 5.1196  \n",
      "\n",
      "Fold: 4  Epoch: 319  Training loss = 1.9202  Validation loss = 5.1192  \n",
      "\n",
      "Fold: 4  Epoch: 320  Training loss = 1.9200  Validation loss = 5.1189  \n",
      "\n",
      "Fold: 4  Epoch: 321  Training loss = 1.9198  Validation loss = 5.1185  \n",
      "\n",
      "Fold: 4  Epoch: 322  Training loss = 1.9196  Validation loss = 5.1182  \n",
      "\n",
      "Fold: 4  Epoch: 323  Training loss = 1.9194  Validation loss = 5.1179  \n",
      "\n",
      "Fold: 4  Epoch: 324  Training loss = 1.9192  Validation loss = 5.1176  \n",
      "\n",
      "Fold: 4  Epoch: 325  Training loss = 1.9191  Validation loss = 5.1173  \n",
      "\n",
      "Fold: 4  Epoch: 326  Training loss = 1.9189  Validation loss = 5.1169  \n",
      "\n",
      "Fold: 4  Epoch: 327  Training loss = 1.9187  Validation loss = 5.1166  \n",
      "\n",
      "Fold: 4  Epoch: 328  Training loss = 1.9185  Validation loss = 5.1163  \n",
      "\n",
      "Fold: 4  Epoch: 329  Training loss = 1.9183  Validation loss = 5.1159  \n",
      "\n",
      "Fold: 4  Epoch: 330  Training loss = 1.9181  Validation loss = 5.1156  \n",
      "\n",
      "Fold: 4  Epoch: 331  Training loss = 1.9179  Validation loss = 5.1153  \n",
      "\n",
      "Fold: 4  Epoch: 332  Training loss = 1.9177  Validation loss = 5.1150  \n",
      "\n",
      "Fold: 4  Epoch: 333  Training loss = 1.9175  Validation loss = 5.1147  \n",
      "\n",
      "Fold: 4  Epoch: 334  Training loss = 1.9174  Validation loss = 5.1144  \n",
      "\n",
      "Fold: 4  Epoch: 335  Training loss = 1.9172  Validation loss = 5.1142  \n",
      "\n",
      "Fold: 4  Epoch: 336  Training loss = 1.9170  Validation loss = 5.1138  \n",
      "\n",
      "Fold: 4  Epoch: 337  Training loss = 1.9168  Validation loss = 5.1134  \n",
      "\n",
      "Fold: 4  Epoch: 338  Training loss = 1.9166  Validation loss = 5.1131  \n",
      "\n",
      "Fold: 4  Epoch: 339  Training loss = 1.9164  Validation loss = 5.1128  \n",
      "\n",
      "Fold: 4  Epoch: 340  Training loss = 1.9162  Validation loss = 5.1124  \n",
      "\n",
      "Fold: 4  Epoch: 341  Training loss = 1.9161  Validation loss = 5.1121  \n",
      "\n",
      "Fold: 4  Epoch: 342  Training loss = 1.9158  Validation loss = 5.1116  \n",
      "\n",
      "Fold: 4  Epoch: 343  Training loss = 1.9156  Validation loss = 5.1113  \n",
      "\n",
      "Fold: 4  Epoch: 344  Training loss = 1.9154  Validation loss = 5.1109  \n",
      "\n",
      "Fold: 4  Epoch: 345  Training loss = 1.9151  Validation loss = 5.1105  \n",
      "\n",
      "Fold: 4  Epoch: 346  Training loss = 1.9149  Validation loss = 5.1101  \n",
      "\n",
      "Fold: 4  Epoch: 347  Training loss = 1.9147  Validation loss = 5.1097  \n",
      "\n",
      "Fold: 4  Epoch: 348  Training loss = 1.9145  Validation loss = 5.1093  \n",
      "\n",
      "Fold: 4  Epoch: 349  Training loss = 1.9143  Validation loss = 5.1089  \n",
      "\n",
      "Fold: 4  Epoch: 350  Training loss = 1.9141  Validation loss = 5.1086  \n",
      "\n",
      "Fold: 4  Epoch: 351  Training loss = 1.9139  Validation loss = 5.1083  \n",
      "\n",
      "Fold: 4  Epoch: 352  Training loss = 1.9137  Validation loss = 5.1080  \n",
      "\n",
      "Fold: 4  Epoch: 353  Training loss = 1.9136  Validation loss = 5.1077  \n",
      "\n",
      "Fold: 4  Epoch: 354  Training loss = 1.9134  Validation loss = 5.1073  \n",
      "\n",
      "Fold: 4  Epoch: 355  Training loss = 1.9132  Validation loss = 5.1070  \n",
      "\n",
      "Fold: 4  Epoch: 356  Training loss = 1.9130  Validation loss = 5.1066  \n",
      "\n",
      "Fold: 4  Epoch: 357  Training loss = 1.9127  Validation loss = 5.1062  \n",
      "\n",
      "Fold: 4  Epoch: 358  Training loss = 1.9126  Validation loss = 5.1058  \n",
      "\n",
      "Fold: 4  Epoch: 359  Training loss = 1.9123  Validation loss = 5.1055  \n",
      "\n",
      "Fold: 4  Epoch: 360  Training loss = 1.9122  Validation loss = 5.1052  \n",
      "\n",
      "Fold: 4  Epoch: 361  Training loss = 1.9119  Validation loss = 5.1048  \n",
      "\n",
      "Fold: 4  Epoch: 362  Training loss = 1.9118  Validation loss = 5.1045  \n",
      "\n",
      "Fold: 4  Epoch: 363  Training loss = 1.9116  Validation loss = 5.1041  \n",
      "\n",
      "Fold: 4  Epoch: 364  Training loss = 1.9114  Validation loss = 5.1038  \n",
      "\n",
      "Fold: 4  Epoch: 365  Training loss = 1.9112  Validation loss = 5.1035  \n",
      "\n",
      "Fold: 4  Epoch: 366  Training loss = 1.9111  Validation loss = 5.1033  \n",
      "\n",
      "Fold: 4  Epoch: 367  Training loss = 1.9109  Validation loss = 5.1029  \n",
      "\n",
      "Fold: 4  Epoch: 368  Training loss = 1.9107  Validation loss = 5.1024  \n",
      "\n",
      "Fold: 4  Epoch: 369  Training loss = 1.9105  Validation loss = 5.1021  \n",
      "\n",
      "Fold: 4  Epoch: 370  Training loss = 1.9103  Validation loss = 5.1018  \n",
      "\n",
      "Fold: 4  Epoch: 371  Training loss = 1.9101  Validation loss = 5.1015  \n",
      "\n",
      "Fold: 4  Epoch: 372  Training loss = 1.9100  Validation loss = 5.1013  \n",
      "\n",
      "Fold: 4  Epoch: 373  Training loss = 1.9098  Validation loss = 5.1009  \n",
      "\n",
      "Fold: 4  Epoch: 374  Training loss = 1.9096  Validation loss = 5.1006  \n",
      "\n",
      "Fold: 4  Epoch: 375  Training loss = 1.9094  Validation loss = 5.1003  \n",
      "\n",
      "Fold: 4  Epoch: 376  Training loss = 1.9093  Validation loss = 5.1000  \n",
      "\n",
      "Fold: 4  Epoch: 377  Training loss = 1.9091  Validation loss = 5.0996  \n",
      "\n",
      "Fold: 4  Epoch: 378  Training loss = 1.9089  Validation loss = 5.0993  \n",
      "\n",
      "Fold: 4  Epoch: 379  Training loss = 1.9087  Validation loss = 5.0989  \n",
      "\n",
      "Fold: 4  Epoch: 380  Training loss = 1.9085  Validation loss = 5.0987  \n",
      "\n",
      "Fold: 4  Epoch: 381  Training loss = 1.9083  Validation loss = 5.0983  \n",
      "\n",
      "Fold: 4  Epoch: 382  Training loss = 1.9081  Validation loss = 5.0980  \n",
      "\n",
      "Fold: 4  Epoch: 383  Training loss = 1.9079  Validation loss = 5.0976  \n",
      "\n",
      "Fold: 4  Epoch: 384  Training loss = 1.9077  Validation loss = 5.0972  \n",
      "\n",
      "Fold: 4  Epoch: 385  Training loss = 1.9075  Validation loss = 5.0969  \n",
      "\n",
      "Fold: 4  Epoch: 386  Training loss = 1.9074  Validation loss = 5.0967  \n",
      "\n",
      "Fold: 4  Epoch: 387  Training loss = 1.9071  Validation loss = 5.0963  \n",
      "\n",
      "Fold: 4  Epoch: 388  Training loss = 1.9070  Validation loss = 5.0960  \n",
      "\n",
      "Fold: 4  Epoch: 389  Training loss = 1.9068  Validation loss = 5.0957  \n",
      "\n",
      "Fold: 4  Epoch: 390  Training loss = 1.9066  Validation loss = 5.0954  \n",
      "\n",
      "Fold: 4  Epoch: 391  Training loss = 1.9065  Validation loss = 5.0951  \n",
      "\n",
      "Fold: 4  Epoch: 392  Training loss = 1.9063  Validation loss = 5.0949  \n",
      "\n",
      "Fold: 4  Epoch: 393  Training loss = 1.9061  Validation loss = 5.0945  \n",
      "\n",
      "Fold: 4  Epoch: 394  Training loss = 1.9059  Validation loss = 5.0942  \n",
      "\n",
      "Fold: 4  Epoch: 395  Training loss = 1.9057  Validation loss = 5.0938  \n",
      "\n",
      "Fold: 4  Epoch: 396  Training loss = 1.9055  Validation loss = 5.0934  \n",
      "\n",
      "Fold: 4  Epoch: 397  Training loss = 1.9053  Validation loss = 5.0931  \n",
      "\n",
      "Fold: 4  Epoch: 398  Training loss = 1.9052  Validation loss = 5.0929  \n",
      "\n",
      "Fold: 4  Epoch: 399  Training loss = 1.9050  Validation loss = 5.0925  \n",
      "\n",
      "Fold: 4  Epoch: 400  Training loss = 1.9049  Validation loss = 5.0923  \n",
      "\n",
      "Fold: 4  Epoch: 401  Training loss = 1.9047  Validation loss = 5.0919  \n",
      "\n",
      "Fold: 4  Epoch: 402  Training loss = 1.9045  Validation loss = 5.0917  \n",
      "\n",
      "Fold: 4  Epoch: 403  Training loss = 1.9043  Validation loss = 5.0913  \n",
      "\n",
      "Fold: 4  Epoch: 404  Training loss = 1.9041  Validation loss = 5.0909  \n",
      "\n",
      "Fold: 4  Epoch: 405  Training loss = 1.9038  Validation loss = 5.0905  \n",
      "\n",
      "Fold: 4  Epoch: 406  Training loss = 1.9036  Validation loss = 5.0902  \n",
      "\n",
      "Fold: 4  Epoch: 407  Training loss = 1.9034  Validation loss = 5.0898  \n",
      "\n",
      "Fold: 4  Epoch: 408  Training loss = 1.9033  Validation loss = 5.0895  \n",
      "\n",
      "Fold: 4  Epoch: 409  Training loss = 1.9031  Validation loss = 5.0892  \n",
      "\n",
      "Fold: 4  Epoch: 410  Training loss = 1.9029  Validation loss = 5.0888  \n",
      "\n",
      "Fold: 4  Epoch: 411  Training loss = 1.9027  Validation loss = 5.0885  \n",
      "\n",
      "Fold: 4  Epoch: 412  Training loss = 1.9026  Validation loss = 5.0883  \n",
      "\n",
      "Fold: 4  Epoch: 413  Training loss = 1.9024  Validation loss = 5.0880  \n",
      "\n",
      "Fold: 4  Epoch: 414  Training loss = 1.9023  Validation loss = 5.0877  \n",
      "\n",
      "Fold: 4  Epoch: 415  Training loss = 1.9021  Validation loss = 5.0875  \n",
      "\n",
      "Fold: 4  Epoch: 416  Training loss = 1.9019  Validation loss = 5.0870  \n",
      "\n",
      "Fold: 4  Epoch: 417  Training loss = 1.9018  Validation loss = 5.0868  \n",
      "\n",
      "Fold: 4  Epoch: 418  Training loss = 1.9016  Validation loss = 5.0864  \n",
      "\n",
      "Fold: 4  Epoch: 419  Training loss = 1.9014  Validation loss = 5.0862  \n",
      "\n",
      "Fold: 4  Epoch: 420  Training loss = 1.9012  Validation loss = 5.0858  \n",
      "\n",
      "Fold: 4  Epoch: 421  Training loss = 1.9010  Validation loss = 5.0855  \n",
      "\n",
      "Fold: 4  Epoch: 422  Training loss = 1.9008  Validation loss = 5.0850  \n",
      "\n",
      "Fold: 4  Epoch: 423  Training loss = 1.9006  Validation loss = 5.0847  \n",
      "\n",
      "Fold: 4  Epoch: 424  Training loss = 1.9004  Validation loss = 5.0844  \n",
      "\n",
      "Fold: 4  Epoch: 425  Training loss = 1.9002  Validation loss = 5.0840  \n",
      "\n",
      "Fold: 4  Epoch: 426  Training loss = 1.9000  Validation loss = 5.0837  \n",
      "\n",
      "Fold: 4  Epoch: 427  Training loss = 1.8998  Validation loss = 5.0834  \n",
      "\n",
      "Fold: 4  Epoch: 428  Training loss = 1.8997  Validation loss = 5.0831  \n",
      "\n",
      "Fold: 4  Epoch: 429  Training loss = 1.8995  Validation loss = 5.0827  \n",
      "\n",
      "Fold: 4  Epoch: 430  Training loss = 1.8993  Validation loss = 5.0824  \n",
      "\n",
      "Fold: 4  Epoch: 431  Training loss = 1.8990  Validation loss = 5.0819  \n",
      "\n",
      "Fold: 4  Epoch: 432  Training loss = 1.8988  Validation loss = 5.0815  \n",
      "\n",
      "Fold: 4  Epoch: 433  Training loss = 1.8986  Validation loss = 5.0812  \n",
      "\n",
      "Fold: 4  Epoch: 434  Training loss = 1.8985  Validation loss = 5.0810  \n",
      "\n",
      "Fold: 4  Epoch: 435  Training loss = 1.8983  Validation loss = 5.0806  \n",
      "\n",
      "Fold: 4  Epoch: 436  Training loss = 1.8981  Validation loss = 5.0803  \n",
      "\n",
      "Fold: 4  Epoch: 437  Training loss = 1.8980  Validation loss = 5.0801  \n",
      "\n",
      "Fold: 4  Epoch: 438  Training loss = 1.8978  Validation loss = 5.0798  \n",
      "\n",
      "Fold: 4  Epoch: 439  Training loss = 1.8977  Validation loss = 5.0795  \n",
      "\n",
      "Fold: 4  Epoch: 440  Training loss = 1.8975  Validation loss = 5.0792  \n",
      "\n",
      "Fold: 4  Epoch: 441  Training loss = 1.8973  Validation loss = 5.0789  \n",
      "\n",
      "Fold: 4  Epoch: 442  Training loss = 1.8971  Validation loss = 5.0785  \n",
      "\n",
      "Fold: 4  Epoch: 443  Training loss = 1.8969  Validation loss = 5.0782  \n",
      "\n",
      "Fold: 4  Epoch: 444  Training loss = 1.8967  Validation loss = 5.0778  \n",
      "\n",
      "Fold: 4  Epoch: 445  Training loss = 1.8965  Validation loss = 5.0775  \n",
      "\n",
      "Fold: 4  Epoch: 446  Training loss = 1.8963  Validation loss = 5.0771  \n",
      "\n",
      "Fold: 4  Epoch: 447  Training loss = 1.8961  Validation loss = 5.0768  \n",
      "\n",
      "Fold: 4  Epoch: 448  Training loss = 1.8959  Validation loss = 5.0765  \n",
      "\n",
      "Fold: 4  Epoch: 449  Training loss = 1.8957  Validation loss = 5.0761  \n",
      "\n",
      "Fold: 4  Epoch: 450  Training loss = 1.8955  Validation loss = 5.0757  \n",
      "\n",
      "Fold: 4  Epoch: 451  Training loss = 1.8953  Validation loss = 5.0754  \n",
      "\n",
      "Fold: 4  Epoch: 452  Training loss = 1.8952  Validation loss = 5.0751  \n",
      "\n",
      "Fold: 4  Epoch: 453  Training loss = 1.8950  Validation loss = 5.0748  \n",
      "\n",
      "Fold: 4  Epoch: 454  Training loss = 1.8949  Validation loss = 5.0746  \n",
      "\n",
      "Fold: 4  Epoch: 455  Training loss = 1.8947  Validation loss = 5.0743  \n",
      "\n",
      "Fold: 4  Epoch: 456  Training loss = 1.8946  Validation loss = 5.0741  \n",
      "\n",
      "Fold: 4  Epoch: 457  Training loss = 1.8944  Validation loss = 5.0737  \n",
      "\n",
      "Fold: 4  Epoch: 458  Training loss = 1.8942  Validation loss = 5.0733  \n",
      "\n",
      "Fold: 4  Epoch: 459  Training loss = 1.8940  Validation loss = 5.0730  \n",
      "\n",
      "Fold: 4  Epoch: 460  Training loss = 1.8938  Validation loss = 5.0727  \n",
      "\n",
      "Fold: 4  Epoch: 461  Training loss = 1.8937  Validation loss = 5.0724  \n",
      "\n",
      "Fold: 4  Epoch: 462  Training loss = 1.8935  Validation loss = 5.0721  \n",
      "\n",
      "Fold: 4  Epoch: 463  Training loss = 1.8933  Validation loss = 5.0717  \n",
      "\n",
      "Fold: 4  Epoch: 464  Training loss = 1.8930  Validation loss = 5.0713  \n",
      "\n",
      "Fold: 4  Epoch: 465  Training loss = 1.8929  Validation loss = 5.0711  \n",
      "\n",
      "Fold: 4  Epoch: 466  Training loss = 1.8927  Validation loss = 5.0707  \n",
      "\n",
      "Fold: 4  Epoch: 467  Training loss = 1.8925  Validation loss = 5.0704  \n",
      "\n",
      "Fold: 4  Epoch: 468  Training loss = 1.8924  Validation loss = 5.0701  \n",
      "\n",
      "Fold: 4  Epoch: 469  Training loss = 1.8922  Validation loss = 5.0698  \n",
      "\n",
      "Fold: 4  Epoch: 470  Training loss = 1.8920  Validation loss = 5.0695  \n",
      "\n",
      "Fold: 4  Epoch: 471  Training loss = 1.8917  Validation loss = 5.0690  \n",
      "\n",
      "Fold: 4  Epoch: 472  Training loss = 1.8915  Validation loss = 5.0687  \n",
      "\n",
      "Fold: 4  Epoch: 473  Training loss = 1.8913  Validation loss = 5.0683  \n",
      "\n",
      "Fold: 4  Epoch: 474  Training loss = 1.8912  Validation loss = 5.0680  \n",
      "\n",
      "Fold: 4  Epoch: 475  Training loss = 1.8910  Validation loss = 5.0676  \n",
      "\n",
      "Fold: 4  Epoch: 476  Training loss = 1.8908  Validation loss = 5.0672  \n",
      "\n",
      "Fold: 4  Epoch: 477  Training loss = 1.8905  Validation loss = 5.0668  \n",
      "\n",
      "Fold: 4  Epoch: 478  Training loss = 1.8903  Validation loss = 5.0664  \n",
      "\n",
      "Fold: 4  Epoch: 479  Training loss = 1.8901  Validation loss = 5.0660  \n",
      "\n",
      "Fold: 4  Epoch: 480  Training loss = 1.8899  Validation loss = 5.0657  \n",
      "\n",
      "Fold: 4  Epoch: 481  Training loss = 1.8897  Validation loss = 5.0653  \n",
      "\n",
      "Fold: 4  Epoch: 482  Training loss = 1.8895  Validation loss = 5.0650  \n",
      "\n",
      "Fold: 4  Epoch: 483  Training loss = 1.8893  Validation loss = 5.0646  \n",
      "\n",
      "Fold: 4  Epoch: 484  Training loss = 1.8891  Validation loss = 5.0643  \n",
      "\n",
      "Fold: 4  Epoch: 485  Training loss = 1.8890  Validation loss = 5.0641  \n",
      "\n",
      "Fold: 4  Epoch: 486  Training loss = 1.8889  Validation loss = 5.0638  \n",
      "\n",
      "Fold: 4  Epoch: 487  Training loss = 1.8887  Validation loss = 5.0635  \n",
      "\n",
      "Fold: 4  Epoch: 488  Training loss = 1.8885  Validation loss = 5.0633  \n",
      "\n",
      "Fold: 4  Epoch: 489  Training loss = 1.8884  Validation loss = 5.0629  \n",
      "\n",
      "Fold: 4  Epoch: 490  Training loss = 1.8882  Validation loss = 5.0627  \n",
      "\n",
      "Fold: 4  Epoch: 491  Training loss = 1.8881  Validation loss = 5.0624  \n",
      "\n",
      "Fold: 4  Epoch: 492  Training loss = 1.8879  Validation loss = 5.0621  \n",
      "\n",
      "Fold: 4  Epoch: 493  Training loss = 1.8878  Validation loss = 5.0619  \n",
      "\n",
      "Fold: 4  Epoch: 494  Training loss = 1.8876  Validation loss = 5.0617  \n",
      "\n",
      "Fold: 4  Epoch: 495  Training loss = 1.8874  Validation loss = 5.0613  \n",
      "\n",
      "Fold: 4  Epoch: 496  Training loss = 1.8871  Validation loss = 5.0608  \n",
      "\n",
      "Fold: 4  Epoch: 497  Training loss = 1.8869  Validation loss = 5.0603  \n",
      "\n",
      "Fold: 4  Epoch: 498  Training loss = 1.8866  Validation loss = 5.0599  \n",
      "\n",
      "Fold: 4  Epoch: 499  Training loss = 1.8865  Validation loss = 5.0596  \n",
      "\n",
      "Fold: 4  Epoch: 500  Training loss = 1.8863  Validation loss = 5.0593  \n",
      "\n",
      "Check model:  Fold: 4  Optimal epoch: 500  \n",
      "\n",
      "Fold: 5  Epoch: 1  Training loss = 2.2364  Validation loss = 5.0606  \n",
      "\n",
      "Fold: 5  Epoch: 2  Training loss = 2.2362  Validation loss = 5.0602  \n",
      "\n",
      "Fold: 5  Epoch: 3  Training loss = 2.2360  Validation loss = 5.0599  \n",
      "\n",
      "Fold: 5  Epoch: 4  Training loss = 2.2357  Validation loss = 5.0594  \n",
      "\n",
      "Fold: 5  Epoch: 5  Training loss = 2.2354  Validation loss = 5.0589  \n",
      "\n",
      "Fold: 5  Epoch: 6  Training loss = 2.2352  Validation loss = 5.0585  \n",
      "\n",
      "Fold: 5  Epoch: 7  Training loss = 2.2349  Validation loss = 5.0581  \n",
      "\n",
      "Fold: 5  Epoch: 8  Training loss = 2.2347  Validation loss = 5.0577  \n",
      "\n",
      "Fold: 5  Epoch: 9  Training loss = 2.2345  Validation loss = 5.0573  \n",
      "\n",
      "Fold: 5  Epoch: 10  Training loss = 2.2342  Validation loss = 5.0569  \n",
      "\n",
      "Fold: 5  Epoch: 11  Training loss = 2.2340  Validation loss = 5.0564  \n",
      "\n",
      "Fold: 5  Epoch: 12  Training loss = 2.2338  Validation loss = 5.0560  \n",
      "\n",
      "Fold: 5  Epoch: 13  Training loss = 2.2334  Validation loss = 5.0554  \n",
      "\n",
      "Fold: 5  Epoch: 14  Training loss = 2.2332  Validation loss = 5.0550  \n",
      "\n",
      "Fold: 5  Epoch: 15  Training loss = 2.2330  Validation loss = 5.0547  \n",
      "\n",
      "Fold: 5  Epoch: 16  Training loss = 2.2327  Validation loss = 5.0543  \n",
      "\n",
      "Fold: 5  Epoch: 17  Training loss = 2.2325  Validation loss = 5.0538  \n",
      "\n",
      "Fold: 5  Epoch: 18  Training loss = 2.2322  Validation loss = 5.0534  \n",
      "\n",
      "Fold: 5  Epoch: 19  Training loss = 2.2320  Validation loss = 5.0530  \n",
      "\n",
      "Fold: 5  Epoch: 20  Training loss = 2.2317  Validation loss = 5.0526  \n",
      "\n",
      "Fold: 5  Epoch: 21  Training loss = 2.2315  Validation loss = 5.0522  \n",
      "\n",
      "Fold: 5  Epoch: 22  Training loss = 2.2312  Validation loss = 5.0517  \n",
      "\n",
      "Fold: 5  Epoch: 23  Training loss = 2.2309  Validation loss = 5.0513  \n",
      "\n",
      "Fold: 5  Epoch: 24  Training loss = 2.2307  Validation loss = 5.0509  \n",
      "\n",
      "Fold: 5  Epoch: 25  Training loss = 2.2304  Validation loss = 5.0504  \n",
      "\n",
      "Fold: 5  Epoch: 26  Training loss = 2.2302  Validation loss = 5.0500  \n",
      "\n",
      "Fold: 5  Epoch: 27  Training loss = 2.2300  Validation loss = 5.0497  \n",
      "\n",
      "Fold: 5  Epoch: 28  Training loss = 2.2297  Validation loss = 5.0493  \n",
      "\n",
      "Fold: 5  Epoch: 29  Training loss = 2.2295  Validation loss = 5.0489  \n",
      "\n",
      "Fold: 5  Epoch: 30  Training loss = 2.2293  Validation loss = 5.0486  \n",
      "\n",
      "Fold: 5  Epoch: 31  Training loss = 2.2291  Validation loss = 5.0482  \n",
      "\n",
      "Fold: 5  Epoch: 32  Training loss = 2.2288  Validation loss = 5.0476  \n",
      "\n",
      "Fold: 5  Epoch: 33  Training loss = 2.2286  Validation loss = 5.0473  \n",
      "\n",
      "Fold: 5  Epoch: 34  Training loss = 2.2283  Validation loss = 5.0468  \n",
      "\n",
      "Fold: 5  Epoch: 35  Training loss = 2.2280  Validation loss = 5.0464  \n",
      "\n",
      "Fold: 5  Epoch: 36  Training loss = 2.2278  Validation loss = 5.0459  \n",
      "\n",
      "Fold: 5  Epoch: 37  Training loss = 2.2275  Validation loss = 5.0455  \n",
      "\n",
      "Fold: 5  Epoch: 38  Training loss = 2.2272  Validation loss = 5.0450  \n",
      "\n",
      "Fold: 5  Epoch: 39  Training loss = 2.2269  Validation loss = 5.0444  \n",
      "\n",
      "Fold: 5  Epoch: 40  Training loss = 2.2267  Validation loss = 5.0440  \n",
      "\n",
      "Fold: 5  Epoch: 41  Training loss = 2.2264  Validation loss = 5.0435  \n",
      "\n",
      "Fold: 5  Epoch: 42  Training loss = 2.2261  Validation loss = 5.0431  \n",
      "\n",
      "Fold: 5  Epoch: 43  Training loss = 2.2259  Validation loss = 5.0428  \n",
      "\n",
      "Fold: 5  Epoch: 44  Training loss = 2.2256  Validation loss = 5.0423  \n",
      "\n",
      "Fold: 5  Epoch: 45  Training loss = 2.2254  Validation loss = 5.0419  \n",
      "\n",
      "Fold: 5  Epoch: 46  Training loss = 2.2251  Validation loss = 5.0414  \n",
      "\n",
      "Fold: 5  Epoch: 47  Training loss = 2.2249  Validation loss = 5.0410  \n",
      "\n",
      "Fold: 5  Epoch: 48  Training loss = 2.2246  Validation loss = 5.0405  \n",
      "\n",
      "Fold: 5  Epoch: 49  Training loss = 2.2244  Validation loss = 5.0402  \n",
      "\n",
      "Fold: 5  Epoch: 50  Training loss = 2.2242  Validation loss = 5.0398  \n",
      "\n",
      "Fold: 5  Epoch: 51  Training loss = 2.2239  Validation loss = 5.0394  \n",
      "\n",
      "Fold: 5  Epoch: 52  Training loss = 2.2237  Validation loss = 5.0391  \n",
      "\n",
      "Fold: 5  Epoch: 53  Training loss = 2.2234  Validation loss = 5.0386  \n",
      "\n",
      "Fold: 5  Epoch: 54  Training loss = 2.2231  Validation loss = 5.0380  \n",
      "\n",
      "Fold: 5  Epoch: 55  Training loss = 2.2229  Validation loss = 5.0377  \n",
      "\n",
      "Fold: 5  Epoch: 56  Training loss = 2.2227  Validation loss = 5.0373  \n",
      "\n",
      "Fold: 5  Epoch: 57  Training loss = 2.2225  Validation loss = 5.0369  \n",
      "\n",
      "Fold: 5  Epoch: 58  Training loss = 2.2223  Validation loss = 5.0366  \n",
      "\n",
      "Fold: 5  Epoch: 59  Training loss = 2.2221  Validation loss = 5.0363  \n",
      "\n",
      "Fold: 5  Epoch: 60  Training loss = 2.2218  Validation loss = 5.0359  \n",
      "\n",
      "Fold: 5  Epoch: 61  Training loss = 2.2216  Validation loss = 5.0354  \n",
      "\n",
      "Fold: 5  Epoch: 62  Training loss = 2.2213  Validation loss = 5.0349  \n",
      "\n",
      "Fold: 5  Epoch: 63  Training loss = 2.2211  Validation loss = 5.0345  \n",
      "\n",
      "Fold: 5  Epoch: 64  Training loss = 2.2209  Validation loss = 5.0341  \n",
      "\n",
      "Fold: 5  Epoch: 65  Training loss = 2.2207  Validation loss = 5.0338  \n",
      "\n",
      "Fold: 5  Epoch: 66  Training loss = 2.2205  Validation loss = 5.0335  \n",
      "\n",
      "Fold: 5  Epoch: 67  Training loss = 2.2202  Validation loss = 5.0331  \n",
      "\n",
      "Fold: 5  Epoch: 68  Training loss = 2.2200  Validation loss = 5.0327  \n",
      "\n",
      "Fold: 5  Epoch: 69  Training loss = 2.2198  Validation loss = 5.0324  \n",
      "\n",
      "Fold: 5  Epoch: 70  Training loss = 2.2196  Validation loss = 5.0320  \n",
      "\n",
      "Fold: 5  Epoch: 71  Training loss = 2.2193  Validation loss = 5.0315  \n",
      "\n",
      "Fold: 5  Epoch: 72  Training loss = 2.2190  Validation loss = 5.0311  \n",
      "\n",
      "Fold: 5  Epoch: 73  Training loss = 2.2188  Validation loss = 5.0307  \n",
      "\n",
      "Fold: 5  Epoch: 74  Training loss = 2.2185  Validation loss = 5.0302  \n",
      "\n",
      "Fold: 5  Epoch: 75  Training loss = 2.2182  Validation loss = 5.0297  \n",
      "\n",
      "Fold: 5  Epoch: 76  Training loss = 2.2180  Validation loss = 5.0293  \n",
      "\n",
      "Fold: 5  Epoch: 77  Training loss = 2.2177  Validation loss = 5.0289  \n",
      "\n",
      "Fold: 5  Epoch: 78  Training loss = 2.2174  Validation loss = 5.0282  \n",
      "\n",
      "Fold: 5  Epoch: 79  Training loss = 2.2171  Validation loss = 5.0277  \n",
      "\n",
      "Fold: 5  Epoch: 80  Training loss = 2.2168  Validation loss = 5.0273  \n",
      "\n",
      "Fold: 5  Epoch: 81  Training loss = 2.2166  Validation loss = 5.0269  \n",
      "\n",
      "Fold: 5  Epoch: 82  Training loss = 2.2164  Validation loss = 5.0265  \n",
      "\n",
      "Fold: 5  Epoch: 83  Training loss = 2.2161  Validation loss = 5.0261  \n",
      "\n",
      "Fold: 5  Epoch: 84  Training loss = 2.2159  Validation loss = 5.0257  \n",
      "\n",
      "Fold: 5  Epoch: 85  Training loss = 2.2157  Validation loss = 5.0254  \n",
      "\n",
      "Fold: 5  Epoch: 86  Training loss = 2.2155  Validation loss = 5.0250  \n",
      "\n",
      "Fold: 5  Epoch: 87  Training loss = 2.2153  Validation loss = 5.0247  \n",
      "\n",
      "Fold: 5  Epoch: 88  Training loss = 2.2150  Validation loss = 5.0243  \n",
      "\n",
      "Fold: 5  Epoch: 89  Training loss = 2.2148  Validation loss = 5.0238  \n",
      "\n",
      "Fold: 5  Epoch: 90  Training loss = 2.2145  Validation loss = 5.0234  \n",
      "\n",
      "Fold: 5  Epoch: 91  Training loss = 2.2143  Validation loss = 5.0231  \n",
      "\n",
      "Fold: 5  Epoch: 92  Training loss = 2.2141  Validation loss = 5.0226  \n",
      "\n",
      "Fold: 5  Epoch: 93  Training loss = 2.2139  Validation loss = 5.0223  \n",
      "\n",
      "Fold: 5  Epoch: 94  Training loss = 2.2136  Validation loss = 5.0219  \n",
      "\n",
      "Fold: 5  Epoch: 95  Training loss = 2.2133  Validation loss = 5.0214  \n",
      "\n",
      "Fold: 5  Epoch: 96  Training loss = 2.2131  Validation loss = 5.0209  \n",
      "\n",
      "Fold: 5  Epoch: 97  Training loss = 2.2129  Validation loss = 5.0206  \n",
      "\n",
      "Fold: 5  Epoch: 98  Training loss = 2.2126  Validation loss = 5.0202  \n",
      "\n",
      "Fold: 5  Epoch: 99  Training loss = 2.2124  Validation loss = 5.0199  \n",
      "\n",
      "Fold: 5  Epoch: 100  Training loss = 2.2122  Validation loss = 5.0195  \n",
      "\n",
      "Fold: 5  Epoch: 101  Training loss = 2.2119  Validation loss = 5.0190  \n",
      "\n",
      "Fold: 5  Epoch: 102  Training loss = 2.2117  Validation loss = 5.0185  \n",
      "\n",
      "Fold: 5  Epoch: 103  Training loss = 2.2114  Validation loss = 5.0182  \n",
      "\n",
      "Fold: 5  Epoch: 104  Training loss = 2.2112  Validation loss = 5.0178  \n",
      "\n",
      "Fold: 5  Epoch: 105  Training loss = 2.2109  Validation loss = 5.0173  \n",
      "\n",
      "Fold: 5  Epoch: 106  Training loss = 2.2107  Validation loss = 5.0169  \n",
      "\n",
      "Fold: 5  Epoch: 107  Training loss = 2.2104  Validation loss = 5.0165  \n",
      "\n",
      "Fold: 5  Epoch: 108  Training loss = 2.2102  Validation loss = 5.0160  \n",
      "\n",
      "Fold: 5  Epoch: 109  Training loss = 2.2099  Validation loss = 5.0156  \n",
      "\n",
      "Fold: 5  Epoch: 110  Training loss = 2.2097  Validation loss = 5.0151  \n",
      "\n",
      "Fold: 5  Epoch: 111  Training loss = 2.2094  Validation loss = 5.0147  \n",
      "\n",
      "Fold: 5  Epoch: 112  Training loss = 2.2092  Validation loss = 5.0142  \n",
      "\n",
      "Fold: 5  Epoch: 113  Training loss = 2.2089  Validation loss = 5.0138  \n",
      "\n",
      "Fold: 5  Epoch: 114  Training loss = 2.2086  Validation loss = 5.0133  \n",
      "\n",
      "Fold: 5  Epoch: 115  Training loss = 2.2084  Validation loss = 5.0129  \n",
      "\n",
      "Fold: 5  Epoch: 116  Training loss = 2.2081  Validation loss = 5.0125  \n",
      "\n",
      "Fold: 5  Epoch: 117  Training loss = 2.2079  Validation loss = 5.0120  \n",
      "\n",
      "Fold: 5  Epoch: 118  Training loss = 2.2076  Validation loss = 5.0116  \n",
      "\n",
      "Fold: 5  Epoch: 119  Training loss = 2.2075  Validation loss = 5.0113  \n",
      "\n",
      "Fold: 5  Epoch: 120  Training loss = 2.2073  Validation loss = 5.0110  \n",
      "\n",
      "Fold: 5  Epoch: 121  Training loss = 2.2071  Validation loss = 5.0107  \n",
      "\n",
      "Fold: 5  Epoch: 122  Training loss = 2.2068  Validation loss = 5.0102  \n",
      "\n",
      "Fold: 5  Epoch: 123  Training loss = 2.2065  Validation loss = 5.0097  \n",
      "\n",
      "Fold: 5  Epoch: 124  Training loss = 2.2062  Validation loss = 5.0092  \n",
      "\n",
      "Fold: 5  Epoch: 125  Training loss = 2.2060  Validation loss = 5.0088  \n",
      "\n",
      "Fold: 5  Epoch: 126  Training loss = 2.2057  Validation loss = 5.0083  \n",
      "\n",
      "Fold: 5  Epoch: 127  Training loss = 2.2054  Validation loss = 5.0078  \n",
      "\n",
      "Fold: 5  Epoch: 128  Training loss = 2.2051  Validation loss = 5.0073  \n",
      "\n",
      "Fold: 5  Epoch: 129  Training loss = 2.2049  Validation loss = 5.0069  \n",
      "\n",
      "Fold: 5  Epoch: 130  Training loss = 2.2046  Validation loss = 5.0065  \n",
      "\n",
      "Fold: 5  Epoch: 131  Training loss = 2.2044  Validation loss = 5.0060  \n",
      "\n",
      "Fold: 5  Epoch: 132  Training loss = 2.2041  Validation loss = 5.0055  \n",
      "\n",
      "Fold: 5  Epoch: 133  Training loss = 2.2039  Validation loss = 5.0052  \n",
      "\n",
      "Fold: 5  Epoch: 134  Training loss = 2.2036  Validation loss = 5.0048  \n",
      "\n",
      "Fold: 5  Epoch: 135  Training loss = 2.2033  Validation loss = 5.0043  \n",
      "\n",
      "Fold: 5  Epoch: 136  Training loss = 2.2031  Validation loss = 5.0037  \n",
      "\n",
      "Fold: 5  Epoch: 137  Training loss = 2.2029  Validation loss = 5.0035  \n",
      "\n",
      "Fold: 5  Epoch: 138  Training loss = 2.2028  Validation loss = 5.0033  \n",
      "\n",
      "Fold: 5  Epoch: 139  Training loss = 2.2025  Validation loss = 5.0028  \n",
      "\n",
      "Fold: 5  Epoch: 140  Training loss = 2.2022  Validation loss = 5.0024  \n",
      "\n",
      "Fold: 5  Epoch: 141  Training loss = 2.2020  Validation loss = 5.0020  \n",
      "\n",
      "Fold: 5  Epoch: 142  Training loss = 2.2016  Validation loss = 5.0014  \n",
      "\n",
      "Fold: 5  Epoch: 143  Training loss = 2.2014  Validation loss = 5.0009  \n",
      "\n",
      "Fold: 5  Epoch: 144  Training loss = 2.2011  Validation loss = 5.0004  \n",
      "\n",
      "Fold: 5  Epoch: 145  Training loss = 2.2009  Validation loss = 5.0001  \n",
      "\n",
      "Fold: 5  Epoch: 146  Training loss = 2.2006  Validation loss = 4.9996  \n",
      "\n",
      "Fold: 5  Epoch: 147  Training loss = 2.2004  Validation loss = 4.9992  \n",
      "\n",
      "Fold: 5  Epoch: 148  Training loss = 2.2002  Validation loss = 4.9988  \n",
      "\n",
      "Fold: 5  Epoch: 149  Training loss = 2.1998  Validation loss = 4.9980  \n",
      "\n",
      "Fold: 5  Epoch: 150  Training loss = 2.1995  Validation loss = 4.9976  \n",
      "\n",
      "Fold: 5  Epoch: 151  Training loss = 2.1993  Validation loss = 4.9972  \n",
      "\n",
      "Fold: 5  Epoch: 152  Training loss = 2.1991  Validation loss = 4.9968  \n",
      "\n",
      "Fold: 5  Epoch: 153  Training loss = 2.1989  Validation loss = 4.9964  \n",
      "\n",
      "Fold: 5  Epoch: 154  Training loss = 2.1987  Validation loss = 4.9962  \n",
      "\n",
      "Fold: 5  Epoch: 155  Training loss = 2.1985  Validation loss = 4.9958  \n",
      "\n",
      "Fold: 5  Epoch: 156  Training loss = 2.1982  Validation loss = 4.9953  \n",
      "\n",
      "Fold: 5  Epoch: 157  Training loss = 2.1979  Validation loss = 4.9948  \n",
      "\n",
      "Fold: 5  Epoch: 158  Training loss = 2.1977  Validation loss = 4.9945  \n",
      "\n",
      "Fold: 5  Epoch: 159  Training loss = 2.1976  Validation loss = 4.9942  \n",
      "\n",
      "Fold: 5  Epoch: 160  Training loss = 2.1974  Validation loss = 4.9939  \n",
      "\n",
      "Fold: 5  Epoch: 161  Training loss = 2.1971  Validation loss = 4.9934  \n",
      "\n",
      "Fold: 5  Epoch: 162  Training loss = 2.1968  Validation loss = 4.9930  \n",
      "\n",
      "Fold: 5  Epoch: 163  Training loss = 2.1967  Validation loss = 4.9927  \n",
      "\n",
      "Fold: 5  Epoch: 164  Training loss = 2.1965  Validation loss = 4.9923  \n",
      "\n",
      "Fold: 5  Epoch: 165  Training loss = 2.1962  Validation loss = 4.9919  \n",
      "\n",
      "Fold: 5  Epoch: 166  Training loss = 2.1960  Validation loss = 4.9915  \n",
      "\n",
      "Fold: 5  Epoch: 167  Training loss = 2.1958  Validation loss = 4.9911  \n",
      "\n",
      "Fold: 5  Epoch: 168  Training loss = 2.1955  Validation loss = 4.9906  \n",
      "\n",
      "Fold: 5  Epoch: 169  Training loss = 2.1952  Validation loss = 4.9902  \n",
      "\n",
      "Fold: 5  Epoch: 170  Training loss = 2.1950  Validation loss = 4.9899  \n",
      "\n",
      "Fold: 5  Epoch: 171  Training loss = 2.1948  Validation loss = 4.9895  \n",
      "\n",
      "Fold: 5  Epoch: 172  Training loss = 2.1945  Validation loss = 4.9889  \n",
      "\n",
      "Fold: 5  Epoch: 173  Training loss = 2.1943  Validation loss = 4.9885  \n",
      "\n",
      "Fold: 5  Epoch: 174  Training loss = 2.1941  Validation loss = 4.9881  \n",
      "\n",
      "Fold: 5  Epoch: 175  Training loss = 2.1938  Validation loss = 4.9877  \n",
      "\n",
      "Fold: 5  Epoch: 176  Training loss = 2.1936  Validation loss = 4.9872  \n",
      "\n",
      "Fold: 5  Epoch: 177  Training loss = 2.1933  Validation loss = 4.9869  \n",
      "\n",
      "Fold: 5  Epoch: 178  Training loss = 2.1930  Validation loss = 4.9863  \n",
      "\n",
      "Fold: 5  Epoch: 179  Training loss = 2.1928  Validation loss = 4.9858  \n",
      "\n",
      "Fold: 5  Epoch: 180  Training loss = 2.1926  Validation loss = 4.9855  \n",
      "\n",
      "Fold: 5  Epoch: 181  Training loss = 2.1923  Validation loss = 4.9851  \n",
      "\n",
      "Fold: 5  Epoch: 182  Training loss = 2.1921  Validation loss = 4.9846  \n",
      "\n",
      "Fold: 5  Epoch: 183  Training loss = 2.1919  Validation loss = 4.9843  \n",
      "\n",
      "Fold: 5  Epoch: 184  Training loss = 2.1915  Validation loss = 4.9836  \n",
      "\n",
      "Fold: 5  Epoch: 185  Training loss = 2.1913  Validation loss = 4.9832  \n",
      "\n",
      "Fold: 5  Epoch: 186  Training loss = 2.1910  Validation loss = 4.9828  \n",
      "\n",
      "Fold: 5  Epoch: 187  Training loss = 2.1908  Validation loss = 4.9823  \n",
      "\n",
      "Fold: 5  Epoch: 188  Training loss = 2.1905  Validation loss = 4.9819  \n",
      "\n",
      "Fold: 5  Epoch: 189  Training loss = 2.1903  Validation loss = 4.9815  \n",
      "\n",
      "Fold: 5  Epoch: 190  Training loss = 2.1901  Validation loss = 4.9810  \n",
      "\n",
      "Fold: 5  Epoch: 191  Training loss = 2.1899  Validation loss = 4.9808  \n",
      "\n",
      "Fold: 5  Epoch: 192  Training loss = 2.1897  Validation loss = 4.9804  \n",
      "\n",
      "Fold: 5  Epoch: 193  Training loss = 2.1894  Validation loss = 4.9799  \n",
      "\n",
      "Fold: 5  Epoch: 194  Training loss = 2.1892  Validation loss = 4.9795  \n",
      "\n",
      "Fold: 5  Epoch: 195  Training loss = 2.1890  Validation loss = 4.9792  \n",
      "\n",
      "Fold: 5  Epoch: 196  Training loss = 2.1887  Validation loss = 4.9787  \n",
      "\n",
      "Fold: 5  Epoch: 197  Training loss = 2.1885  Validation loss = 4.9784  \n",
      "\n",
      "Fold: 5  Epoch: 198  Training loss = 2.1883  Validation loss = 4.9780  \n",
      "\n",
      "Fold: 5  Epoch: 199  Training loss = 2.1881  Validation loss = 4.9776  \n",
      "\n",
      "Fold: 5  Epoch: 200  Training loss = 2.1878  Validation loss = 4.9772  \n",
      "\n",
      "Fold: 5  Epoch: 201  Training loss = 2.1876  Validation loss = 4.9768  \n",
      "\n",
      "Fold: 5  Epoch: 202  Training loss = 2.1873  Validation loss = 4.9763  \n",
      "\n",
      "Fold: 5  Epoch: 203  Training loss = 2.1871  Validation loss = 4.9760  \n",
      "\n",
      "Fold: 5  Epoch: 204  Training loss = 2.1869  Validation loss = 4.9756  \n",
      "\n",
      "Fold: 5  Epoch: 205  Training loss = 2.1867  Validation loss = 4.9753  \n",
      "\n",
      "Fold: 5  Epoch: 206  Training loss = 2.1864  Validation loss = 4.9748  \n",
      "\n",
      "Fold: 5  Epoch: 207  Training loss = 2.1862  Validation loss = 4.9744  \n",
      "\n",
      "Fold: 5  Epoch: 208  Training loss = 2.1860  Validation loss = 4.9741  \n",
      "\n",
      "Fold: 5  Epoch: 209  Training loss = 2.1857  Validation loss = 4.9735  \n",
      "\n",
      "Fold: 5  Epoch: 210  Training loss = 2.1855  Validation loss = 4.9731  \n",
      "\n",
      "Fold: 5  Epoch: 211  Training loss = 2.1852  Validation loss = 4.9727  \n",
      "\n",
      "Fold: 5  Epoch: 212  Training loss = 2.1849  Validation loss = 4.9722  \n",
      "\n",
      "Fold: 5  Epoch: 213  Training loss = 2.1847  Validation loss = 4.9717  \n",
      "\n",
      "Fold: 5  Epoch: 214  Training loss = 2.1845  Validation loss = 4.9714  \n",
      "\n",
      "Fold: 5  Epoch: 215  Training loss = 2.1842  Validation loss = 4.9709  \n",
      "\n",
      "Fold: 5  Epoch: 216  Training loss = 2.1840  Validation loss = 4.9706  \n",
      "\n",
      "Fold: 5  Epoch: 217  Training loss = 2.1838  Validation loss = 4.9700  \n",
      "\n",
      "Fold: 5  Epoch: 218  Training loss = 2.1835  Validation loss = 4.9696  \n",
      "\n",
      "Fold: 5  Epoch: 219  Training loss = 2.1833  Validation loss = 4.9692  \n",
      "\n",
      "Fold: 5  Epoch: 220  Training loss = 2.1830  Validation loss = 4.9688  \n",
      "\n",
      "Fold: 5  Epoch: 221  Training loss = 2.1827  Validation loss = 4.9683  \n",
      "\n",
      "Fold: 5  Epoch: 222  Training loss = 2.1825  Validation loss = 4.9678  \n",
      "\n",
      "Fold: 5  Epoch: 223  Training loss = 2.1822  Validation loss = 4.9674  \n",
      "\n",
      "Fold: 5  Epoch: 224  Training loss = 2.1820  Validation loss = 4.9670  \n",
      "\n",
      "Fold: 5  Epoch: 225  Training loss = 2.1818  Validation loss = 4.9667  \n",
      "\n",
      "Fold: 5  Epoch: 226  Training loss = 2.1816  Validation loss = 4.9662  \n",
      "\n",
      "Fold: 5  Epoch: 227  Training loss = 2.1813  Validation loss = 4.9658  \n",
      "\n",
      "Fold: 5  Epoch: 228  Training loss = 2.1811  Validation loss = 4.9654  \n",
      "\n",
      "Fold: 5  Epoch: 229  Training loss = 2.1808  Validation loss = 4.9649  \n",
      "\n",
      "Fold: 5  Epoch: 230  Training loss = 2.1806  Validation loss = 4.9645  \n",
      "\n",
      "Fold: 5  Epoch: 231  Training loss = 2.1803  Validation loss = 4.9640  \n",
      "\n",
      "Fold: 5  Epoch: 232  Training loss = 2.1801  Validation loss = 4.9635  \n",
      "\n",
      "Fold: 5  Epoch: 233  Training loss = 2.1798  Validation loss = 4.9631  \n",
      "\n",
      "Fold: 5  Epoch: 234  Training loss = 2.1796  Validation loss = 4.9628  \n",
      "\n",
      "Fold: 5  Epoch: 235  Training loss = 2.1794  Validation loss = 4.9624  \n",
      "\n",
      "Fold: 5  Epoch: 236  Training loss = 2.1792  Validation loss = 4.9621  \n",
      "\n",
      "Fold: 5  Epoch: 237  Training loss = 2.1790  Validation loss = 4.9617  \n",
      "\n",
      "Fold: 5  Epoch: 238  Training loss = 2.1788  Validation loss = 4.9613  \n",
      "\n",
      "Fold: 5  Epoch: 239  Training loss = 2.1786  Validation loss = 4.9609  \n",
      "\n",
      "Fold: 5  Epoch: 240  Training loss = 2.1784  Validation loss = 4.9605  \n",
      "\n",
      "Fold: 5  Epoch: 241  Training loss = 2.1781  Validation loss = 4.9601  \n",
      "\n",
      "Fold: 5  Epoch: 242  Training loss = 2.1779  Validation loss = 4.9597  \n",
      "\n",
      "Fold: 5  Epoch: 243  Training loss = 2.1777  Validation loss = 4.9594  \n",
      "\n",
      "Fold: 5  Epoch: 244  Training loss = 2.1775  Validation loss = 4.9591  \n",
      "\n",
      "Fold: 5  Epoch: 245  Training loss = 2.1773  Validation loss = 4.9588  \n",
      "\n",
      "Fold: 5  Epoch: 246  Training loss = 2.1771  Validation loss = 4.9583  \n",
      "\n",
      "Fold: 5  Epoch: 247  Training loss = 2.1768  Validation loss = 4.9579  \n",
      "\n",
      "Fold: 5  Epoch: 248  Training loss = 2.1766  Validation loss = 4.9575  \n",
      "\n",
      "Fold: 5  Epoch: 249  Training loss = 2.1764  Validation loss = 4.9572  \n",
      "\n",
      "Fold: 5  Epoch: 250  Training loss = 2.1762  Validation loss = 4.9568  \n",
      "\n",
      "Fold: 5  Epoch: 251  Training loss = 2.1760  Validation loss = 4.9564  \n",
      "\n",
      "Fold: 5  Epoch: 252  Training loss = 2.1758  Validation loss = 4.9562  \n",
      "\n",
      "Fold: 5  Epoch: 253  Training loss = 2.1757  Validation loss = 4.9558  \n",
      "\n",
      "Fold: 5  Epoch: 254  Training loss = 2.1754  Validation loss = 4.9555  \n",
      "\n",
      "Fold: 5  Epoch: 255  Training loss = 2.1752  Validation loss = 4.9551  \n",
      "\n",
      "Fold: 5  Epoch: 256  Training loss = 2.1750  Validation loss = 4.9548  \n",
      "\n",
      "Fold: 5  Epoch: 257  Training loss = 2.1747  Validation loss = 4.9541  \n",
      "\n",
      "Fold: 5  Epoch: 258  Training loss = 2.1745  Validation loss = 4.9537  \n",
      "\n",
      "Fold: 5  Epoch: 259  Training loss = 2.1742  Validation loss = 4.9533  \n",
      "\n",
      "Fold: 5  Epoch: 260  Training loss = 2.1740  Validation loss = 4.9528  \n",
      "\n",
      "Fold: 5  Epoch: 261  Training loss = 2.1738  Validation loss = 4.9524  \n",
      "\n",
      "Fold: 5  Epoch: 262  Training loss = 2.1735  Validation loss = 4.9520  \n",
      "\n",
      "Fold: 5  Epoch: 263  Training loss = 2.1733  Validation loss = 4.9516  \n",
      "\n",
      "Fold: 5  Epoch: 264  Training loss = 2.1731  Validation loss = 4.9511  \n",
      "\n",
      "Fold: 5  Epoch: 265  Training loss = 2.1728  Validation loss = 4.9507  \n",
      "\n",
      "Fold: 5  Epoch: 266  Training loss = 2.1726  Validation loss = 4.9502  \n",
      "\n",
      "Fold: 5  Epoch: 267  Training loss = 2.1723  Validation loss = 4.9498  \n",
      "\n",
      "Fold: 5  Epoch: 268  Training loss = 2.1721  Validation loss = 4.9494  \n",
      "\n",
      "Fold: 5  Epoch: 269  Training loss = 2.1719  Validation loss = 4.9490  \n",
      "\n",
      "Fold: 5  Epoch: 270  Training loss = 2.1716  Validation loss = 4.9486  \n",
      "\n",
      "Fold: 5  Epoch: 271  Training loss = 2.1713  Validation loss = 4.9480  \n",
      "\n",
      "Fold: 5  Epoch: 272  Training loss = 2.1710  Validation loss = 4.9476  \n",
      "\n",
      "Fold: 5  Epoch: 273  Training loss = 2.1708  Validation loss = 4.9472  \n",
      "\n",
      "Fold: 5  Epoch: 274  Training loss = 2.1705  Validation loss = 4.9466  \n",
      "\n",
      "Fold: 5  Epoch: 275  Training loss = 2.1703  Validation loss = 4.9462  \n",
      "\n",
      "Fold: 5  Epoch: 276  Training loss = 2.1701  Validation loss = 4.9459  \n",
      "\n",
      "Fold: 5  Epoch: 277  Training loss = 2.1698  Validation loss = 4.9453  \n",
      "\n",
      "Fold: 5  Epoch: 278  Training loss = 2.1696  Validation loss = 4.9449  \n",
      "\n",
      "Fold: 5  Epoch: 279  Training loss = 2.1694  Validation loss = 4.9445  \n",
      "\n",
      "Fold: 5  Epoch: 280  Training loss = 2.1692  Validation loss = 4.9441  \n",
      "\n",
      "Fold: 5  Epoch: 281  Training loss = 2.1689  Validation loss = 4.9437  \n",
      "\n",
      "Fold: 5  Epoch: 282  Training loss = 2.1687  Validation loss = 4.9433  \n",
      "\n",
      "Fold: 5  Epoch: 283  Training loss = 2.1685  Validation loss = 4.9430  \n",
      "\n",
      "Fold: 5  Epoch: 284  Training loss = 2.1683  Validation loss = 4.9425  \n",
      "\n",
      "Fold: 5  Epoch: 285  Training loss = 2.1680  Validation loss = 4.9421  \n",
      "\n",
      "Fold: 5  Epoch: 286  Training loss = 2.1678  Validation loss = 4.9417  \n",
      "\n",
      "Fold: 5  Epoch: 287  Training loss = 2.1676  Validation loss = 4.9413  \n",
      "\n",
      "Fold: 5  Epoch: 288  Training loss = 2.1673  Validation loss = 4.9407  \n",
      "\n",
      "Fold: 5  Epoch: 289  Training loss = 2.1671  Validation loss = 4.9404  \n",
      "\n",
      "Fold: 5  Epoch: 290  Training loss = 2.1669  Validation loss = 4.9401  \n",
      "\n",
      "Fold: 5  Epoch: 291  Training loss = 2.1666  Validation loss = 4.9395  \n",
      "\n",
      "Fold: 5  Epoch: 292  Training loss = 2.1664  Validation loss = 4.9391  \n",
      "\n",
      "Fold: 5  Epoch: 293  Training loss = 2.1661  Validation loss = 4.9386  \n",
      "\n",
      "Fold: 5  Epoch: 294  Training loss = 2.1659  Validation loss = 4.9382  \n",
      "\n",
      "Fold: 5  Epoch: 295  Training loss = 2.1657  Validation loss = 4.9379  \n",
      "\n",
      "Fold: 5  Epoch: 296  Training loss = 2.1655  Validation loss = 4.9374  \n",
      "\n",
      "Fold: 5  Epoch: 297  Training loss = 2.1652  Validation loss = 4.9369  \n",
      "\n",
      "Fold: 5  Epoch: 298  Training loss = 2.1650  Validation loss = 4.9366  \n",
      "\n",
      "Fold: 5  Epoch: 299  Training loss = 2.1647  Validation loss = 4.9361  \n",
      "\n",
      "Fold: 5  Epoch: 300  Training loss = 2.1645  Validation loss = 4.9358  \n",
      "\n",
      "Fold: 5  Epoch: 301  Training loss = 2.1643  Validation loss = 4.9352  \n",
      "\n",
      "Fold: 5  Epoch: 302  Training loss = 2.1640  Validation loss = 4.9348  \n",
      "\n",
      "Fold: 5  Epoch: 303  Training loss = 2.1638  Validation loss = 4.9344  \n",
      "\n",
      "Fold: 5  Epoch: 304  Training loss = 2.1637  Validation loss = 4.9341  \n",
      "\n",
      "Fold: 5  Epoch: 305  Training loss = 2.1634  Validation loss = 4.9337  \n",
      "\n",
      "Fold: 5  Epoch: 306  Training loss = 2.1632  Validation loss = 4.9333  \n",
      "\n",
      "Fold: 5  Epoch: 307  Training loss = 2.1630  Validation loss = 4.9328  \n",
      "\n",
      "Fold: 5  Epoch: 308  Training loss = 2.1627  Validation loss = 4.9323  \n",
      "\n",
      "Fold: 5  Epoch: 309  Training loss = 2.1625  Validation loss = 4.9320  \n",
      "\n",
      "Fold: 5  Epoch: 310  Training loss = 2.1623  Validation loss = 4.9317  \n",
      "\n",
      "Fold: 5  Epoch: 311  Training loss = 2.1620  Validation loss = 4.9311  \n",
      "\n",
      "Fold: 5  Epoch: 312  Training loss = 2.1618  Validation loss = 4.9307  \n",
      "\n",
      "Fold: 5  Epoch: 313  Training loss = 2.1616  Validation loss = 4.9304  \n",
      "\n",
      "Fold: 5  Epoch: 314  Training loss = 2.1614  Validation loss = 4.9299  \n",
      "\n",
      "Fold: 5  Epoch: 315  Training loss = 2.1612  Validation loss = 4.9297  \n",
      "\n",
      "Fold: 5  Epoch: 316  Training loss = 2.1610  Validation loss = 4.9292  \n",
      "\n",
      "Fold: 5  Epoch: 317  Training loss = 2.1607  Validation loss = 4.9287  \n",
      "\n",
      "Fold: 5  Epoch: 318  Training loss = 2.1605  Validation loss = 4.9283  \n",
      "\n",
      "Fold: 5  Epoch: 319  Training loss = 2.1604  Validation loss = 4.9281  \n",
      "\n",
      "Fold: 5  Epoch: 320  Training loss = 2.1602  Validation loss = 4.9277  \n",
      "\n",
      "Fold: 5  Epoch: 321  Training loss = 2.1600  Validation loss = 4.9275  \n",
      "\n",
      "Fold: 5  Epoch: 322  Training loss = 2.1598  Validation loss = 4.9270  \n",
      "\n",
      "Fold: 5  Epoch: 323  Training loss = 2.1596  Validation loss = 4.9267  \n",
      "\n",
      "Fold: 5  Epoch: 324  Training loss = 2.1594  Validation loss = 4.9262  \n",
      "\n",
      "Fold: 5  Epoch: 325  Training loss = 2.1591  Validation loss = 4.9259  \n",
      "\n",
      "Fold: 5  Epoch: 326  Training loss = 2.1589  Validation loss = 4.9255  \n",
      "\n",
      "Fold: 5  Epoch: 327  Training loss = 2.1587  Validation loss = 4.9251  \n",
      "\n",
      "Fold: 5  Epoch: 328  Training loss = 2.1585  Validation loss = 4.9248  \n",
      "\n",
      "Fold: 5  Epoch: 329  Training loss = 2.1583  Validation loss = 4.9243  \n",
      "\n",
      "Fold: 5  Epoch: 330  Training loss = 2.1581  Validation loss = 4.9239  \n",
      "\n",
      "Fold: 5  Epoch: 331  Training loss = 2.1578  Validation loss = 4.9235  \n",
      "\n",
      "Fold: 5  Epoch: 332  Training loss = 2.1576  Validation loss = 4.9231  \n",
      "\n",
      "Fold: 5  Epoch: 333  Training loss = 2.1574  Validation loss = 4.9229  \n",
      "\n",
      "Fold: 5  Epoch: 334  Training loss = 2.1572  Validation loss = 4.9225  \n",
      "\n",
      "Fold: 5  Epoch: 335  Training loss = 2.1570  Validation loss = 4.9221  \n",
      "\n",
      "Fold: 5  Epoch: 336  Training loss = 2.1568  Validation loss = 4.9218  \n",
      "\n",
      "Fold: 5  Epoch: 337  Training loss = 2.1566  Validation loss = 4.9214  \n",
      "\n",
      "Fold: 5  Epoch: 338  Training loss = 2.1563  Validation loss = 4.9209  \n",
      "\n",
      "Fold: 5  Epoch: 339  Training loss = 2.1561  Validation loss = 4.9206  \n",
      "\n",
      "Fold: 5  Epoch: 340  Training loss = 2.1559  Validation loss = 4.9202  \n",
      "\n",
      "Fold: 5  Epoch: 341  Training loss = 2.1557  Validation loss = 4.9198  \n",
      "\n",
      "Fold: 5  Epoch: 342  Training loss = 2.1555  Validation loss = 4.9195  \n",
      "\n",
      "Fold: 5  Epoch: 343  Training loss = 2.1554  Validation loss = 4.9192  \n",
      "\n",
      "Fold: 5  Epoch: 344  Training loss = 2.1552  Validation loss = 4.9189  \n",
      "\n",
      "Fold: 5  Epoch: 345  Training loss = 2.1550  Validation loss = 4.9185  \n",
      "\n",
      "Fold: 5  Epoch: 346  Training loss = 2.1548  Validation loss = 4.9181  \n",
      "\n",
      "Fold: 5  Epoch: 347  Training loss = 2.1546  Validation loss = 4.9178  \n",
      "\n",
      "Fold: 5  Epoch: 348  Training loss = 2.1544  Validation loss = 4.9174  \n",
      "\n",
      "Fold: 5  Epoch: 349  Training loss = 2.1542  Validation loss = 4.9170  \n",
      "\n",
      "Fold: 5  Epoch: 350  Training loss = 2.1539  Validation loss = 4.9166  \n",
      "\n",
      "Fold: 5  Epoch: 351  Training loss = 2.1537  Validation loss = 4.9161  \n",
      "\n",
      "Fold: 5  Epoch: 352  Training loss = 2.1535  Validation loss = 4.9157  \n",
      "\n",
      "Fold: 5  Epoch: 353  Training loss = 2.1533  Validation loss = 4.9154  \n",
      "\n",
      "Fold: 5  Epoch: 354  Training loss = 2.1531  Validation loss = 4.9152  \n",
      "\n",
      "Fold: 5  Epoch: 355  Training loss = 2.1529  Validation loss = 4.9148  \n",
      "\n",
      "Fold: 5  Epoch: 356  Training loss = 2.1527  Validation loss = 4.9145  \n",
      "\n",
      "Fold: 5  Epoch: 357  Training loss = 2.1524  Validation loss = 4.9137  \n",
      "\n",
      "Fold: 5  Epoch: 358  Training loss = 2.1522  Validation loss = 4.9134  \n",
      "\n",
      "Fold: 5  Epoch: 359  Training loss = 2.1520  Validation loss = 4.9130  \n",
      "\n",
      "Fold: 5  Epoch: 360  Training loss = 2.1518  Validation loss = 4.9127  \n",
      "\n",
      "Fold: 5  Epoch: 361  Training loss = 2.1515  Validation loss = 4.9122  \n",
      "\n",
      "Fold: 5  Epoch: 362  Training loss = 2.1513  Validation loss = 4.9118  \n",
      "\n",
      "Fold: 5  Epoch: 363  Training loss = 2.1512  Validation loss = 4.9116  \n",
      "\n",
      "Fold: 5  Epoch: 364  Training loss = 2.1509  Validation loss = 4.9111  \n",
      "\n",
      "Fold: 5  Epoch: 365  Training loss = 2.1507  Validation loss = 4.9107  \n",
      "\n",
      "Fold: 5  Epoch: 366  Training loss = 2.1504  Validation loss = 4.9102  \n",
      "\n",
      "Fold: 5  Epoch: 367  Training loss = 2.1502  Validation loss = 4.9098  \n",
      "\n",
      "Fold: 5  Epoch: 368  Training loss = 2.1498  Validation loss = 4.9091  \n",
      "\n",
      "Fold: 5  Epoch: 369  Training loss = 2.1496  Validation loss = 4.9087  \n",
      "\n",
      "Fold: 5  Epoch: 370  Training loss = 2.1494  Validation loss = 4.9084  \n",
      "\n",
      "Fold: 5  Epoch: 371  Training loss = 2.1492  Validation loss = 4.9079  \n",
      "\n",
      "Fold: 5  Epoch: 372  Training loss = 2.1490  Validation loss = 4.9077  \n",
      "\n",
      "Fold: 5  Epoch: 373  Training loss = 2.1488  Validation loss = 4.9073  \n",
      "\n",
      "Fold: 5  Epoch: 374  Training loss = 2.1486  Validation loss = 4.9069  \n",
      "\n",
      "Fold: 5  Epoch: 375  Training loss = 2.1484  Validation loss = 4.9065  \n",
      "\n",
      "Fold: 5  Epoch: 376  Training loss = 2.1482  Validation loss = 4.9061  \n",
      "\n",
      "Fold: 5  Epoch: 377  Training loss = 2.1479  Validation loss = 4.9057  \n",
      "\n",
      "Fold: 5  Epoch: 378  Training loss = 2.1477  Validation loss = 4.9054  \n",
      "\n",
      "Fold: 5  Epoch: 379  Training loss = 2.1474  Validation loss = 4.9048  \n",
      "\n",
      "Fold: 5  Epoch: 380  Training loss = 2.1473  Validation loss = 4.9046  \n",
      "\n",
      "Fold: 5  Epoch: 381  Training loss = 2.1471  Validation loss = 4.9043  \n",
      "\n",
      "Fold: 5  Epoch: 382  Training loss = 2.1470  Validation loss = 4.9040  \n",
      "\n",
      "Fold: 5  Epoch: 383  Training loss = 2.1467  Validation loss = 4.9035  \n",
      "\n",
      "Fold: 5  Epoch: 384  Training loss = 2.1466  Validation loss = 4.9032  \n",
      "\n",
      "Fold: 5  Epoch: 385  Training loss = 2.1463  Validation loss = 4.9028  \n",
      "\n",
      "Fold: 5  Epoch: 386  Training loss = 2.1461  Validation loss = 4.9024  \n",
      "\n",
      "Fold: 5  Epoch: 387  Training loss = 2.1459  Validation loss = 4.9021  \n",
      "\n",
      "Fold: 5  Epoch: 388  Training loss = 2.1457  Validation loss = 4.9017  \n",
      "\n",
      "Fold: 5  Epoch: 389  Training loss = 2.1455  Validation loss = 4.9013  \n",
      "\n",
      "Fold: 5  Epoch: 390  Training loss = 2.1453  Validation loss = 4.9009  \n",
      "\n",
      "Fold: 5  Epoch: 391  Training loss = 2.1450  Validation loss = 4.9005  \n",
      "\n",
      "Fold: 5  Epoch: 392  Training loss = 2.1448  Validation loss = 4.9001  \n",
      "\n",
      "Fold: 5  Epoch: 393  Training loss = 2.1446  Validation loss = 4.8996  \n",
      "\n",
      "Fold: 5  Epoch: 394  Training loss = 2.1444  Validation loss = 4.8992  \n",
      "\n",
      "Fold: 5  Epoch: 395  Training loss = 2.1442  Validation loss = 4.8990  \n",
      "\n",
      "Fold: 5  Epoch: 396  Training loss = 2.1440  Validation loss = 4.8986  \n",
      "\n",
      "Fold: 5  Epoch: 397  Training loss = 2.1438  Validation loss = 4.8981  \n",
      "\n",
      "Fold: 5  Epoch: 398  Training loss = 2.1435  Validation loss = 4.8976  \n",
      "\n",
      "Fold: 5  Epoch: 399  Training loss = 2.1433  Validation loss = 4.8972  \n",
      "\n",
      "Fold: 5  Epoch: 400  Training loss = 2.1431  Validation loss = 4.8968  \n",
      "\n",
      "Fold: 5  Epoch: 401  Training loss = 2.1428  Validation loss = 4.8964  \n",
      "\n",
      "Fold: 5  Epoch: 402  Training loss = 2.1427  Validation loss = 4.8961  \n",
      "\n",
      "Fold: 5  Epoch: 403  Training loss = 2.1425  Validation loss = 4.8957  \n",
      "\n",
      "Fold: 5  Epoch: 404  Training loss = 2.1422  Validation loss = 4.8952  \n",
      "\n",
      "Fold: 5  Epoch: 405  Training loss = 2.1420  Validation loss = 4.8949  \n",
      "\n",
      "Fold: 5  Epoch: 406  Training loss = 2.1418  Validation loss = 4.8945  \n",
      "\n",
      "Fold: 5  Epoch: 407  Training loss = 2.1416  Validation loss = 4.8942  \n",
      "\n",
      "Fold: 5  Epoch: 408  Training loss = 2.1414  Validation loss = 4.8939  \n",
      "\n",
      "Fold: 5  Epoch: 409  Training loss = 2.1412  Validation loss = 4.8935  \n",
      "\n",
      "Fold: 5  Epoch: 410  Training loss = 2.1410  Validation loss = 4.8930  \n",
      "\n",
      "Fold: 5  Epoch: 411  Training loss = 2.1407  Validation loss = 4.8924  \n",
      "\n",
      "Fold: 5  Epoch: 412  Training loss = 2.1405  Validation loss = 4.8921  \n",
      "\n",
      "Fold: 5  Epoch: 413  Training loss = 2.1403  Validation loss = 4.8918  \n",
      "\n",
      "Fold: 5  Epoch: 414  Training loss = 2.1401  Validation loss = 4.8914  \n",
      "\n",
      "Fold: 5  Epoch: 415  Training loss = 2.1399  Validation loss = 4.8910  \n",
      "\n",
      "Fold: 5  Epoch: 416  Training loss = 2.1397  Validation loss = 4.8905  \n",
      "\n",
      "Fold: 5  Epoch: 417  Training loss = 2.1394  Validation loss = 4.8901  \n",
      "\n",
      "Fold: 5  Epoch: 418  Training loss = 2.1391  Validation loss = 4.8895  \n",
      "\n",
      "Fold: 5  Epoch: 419  Training loss = 2.1389  Validation loss = 4.8892  \n",
      "\n",
      "Fold: 5  Epoch: 420  Training loss = 2.1386  Validation loss = 4.8886  \n",
      "\n",
      "Fold: 5  Epoch: 421  Training loss = 2.1385  Validation loss = 4.8884  \n",
      "\n",
      "Fold: 5  Epoch: 422  Training loss = 2.1382  Validation loss = 4.8878  \n",
      "\n",
      "Fold: 5  Epoch: 423  Training loss = 2.1380  Validation loss = 4.8875  \n",
      "\n",
      "Fold: 5  Epoch: 424  Training loss = 2.1379  Validation loss = 4.8872  \n",
      "\n",
      "Fold: 5  Epoch: 425  Training loss = 2.1377  Validation loss = 4.8869  \n",
      "\n",
      "Fold: 5  Epoch: 426  Training loss = 2.1374  Validation loss = 4.8864  \n",
      "\n",
      "Fold: 5  Epoch: 427  Training loss = 2.1371  Validation loss = 4.8858  \n",
      "\n",
      "Fold: 5  Epoch: 428  Training loss = 2.1369  Validation loss = 4.8854  \n",
      "\n",
      "Fold: 5  Epoch: 429  Training loss = 2.1366  Validation loss = 4.8850  \n",
      "\n",
      "Fold: 5  Epoch: 430  Training loss = 2.1364  Validation loss = 4.8846  \n",
      "\n",
      "Fold: 5  Epoch: 431  Training loss = 2.1362  Validation loss = 4.8842  \n",
      "\n",
      "Fold: 5  Epoch: 432  Training loss = 2.1360  Validation loss = 4.8839  \n",
      "\n",
      "Fold: 5  Epoch: 433  Training loss = 2.1358  Validation loss = 4.8833  \n",
      "\n",
      "Fold: 5  Epoch: 434  Training loss = 2.1355  Validation loss = 4.8829  \n",
      "\n",
      "Fold: 5  Epoch: 435  Training loss = 2.1353  Validation loss = 4.8825  \n",
      "\n",
      "Fold: 5  Epoch: 436  Training loss = 2.1351  Validation loss = 4.8821  \n",
      "\n",
      "Fold: 5  Epoch: 437  Training loss = 2.1349  Validation loss = 4.8816  \n",
      "\n",
      "Fold: 5  Epoch: 438  Training loss = 2.1347  Validation loss = 4.8812  \n",
      "\n",
      "Fold: 5  Epoch: 439  Training loss = 2.1344  Validation loss = 4.8808  \n",
      "\n",
      "Fold: 5  Epoch: 440  Training loss = 2.1343  Validation loss = 4.8805  \n",
      "\n",
      "Fold: 5  Epoch: 441  Training loss = 2.1341  Validation loss = 4.8802  \n",
      "\n",
      "Fold: 5  Epoch: 442  Training loss = 2.1339  Validation loss = 4.8798  \n",
      "\n",
      "Fold: 5  Epoch: 443  Training loss = 2.1336  Validation loss = 4.8794  \n",
      "\n",
      "Fold: 5  Epoch: 444  Training loss = 2.1334  Validation loss = 4.8789  \n",
      "\n",
      "Fold: 5  Epoch: 445  Training loss = 2.1332  Validation loss = 4.8786  \n",
      "\n",
      "Fold: 5  Epoch: 446  Training loss = 2.1330  Validation loss = 4.8781  \n",
      "\n",
      "Fold: 5  Epoch: 447  Training loss = 2.1327  Validation loss = 4.8776  \n",
      "\n",
      "Fold: 5  Epoch: 448  Training loss = 2.1326  Validation loss = 4.8773  \n",
      "\n",
      "Fold: 5  Epoch: 449  Training loss = 2.1323  Validation loss = 4.8769  \n",
      "\n",
      "Fold: 5  Epoch: 450  Training loss = 2.1321  Validation loss = 4.8764  \n",
      "\n",
      "Fold: 5  Epoch: 451  Training loss = 2.1319  Validation loss = 4.8761  \n",
      "\n",
      "Fold: 5  Epoch: 452  Training loss = 2.1316  Validation loss = 4.8756  \n",
      "\n",
      "Fold: 5  Epoch: 453  Training loss = 2.1314  Validation loss = 4.8752  \n",
      "\n",
      "Fold: 5  Epoch: 454  Training loss = 2.1312  Validation loss = 4.8748  \n",
      "\n",
      "Fold: 5  Epoch: 455  Training loss = 2.1310  Validation loss = 4.8744  \n",
      "\n",
      "Fold: 5  Epoch: 456  Training loss = 2.1308  Validation loss = 4.8740  \n",
      "\n",
      "Fold: 5  Epoch: 457  Training loss = 2.1306  Validation loss = 4.8736  \n",
      "\n",
      "Fold: 5  Epoch: 458  Training loss = 2.1304  Validation loss = 4.8732  \n",
      "\n",
      "Fold: 5  Epoch: 459  Training loss = 2.1302  Validation loss = 4.8730  \n",
      "\n",
      "Fold: 5  Epoch: 460  Training loss = 2.1300  Validation loss = 4.8726  \n",
      "\n",
      "Fold: 5  Epoch: 461  Training loss = 2.1298  Validation loss = 4.8722  \n",
      "\n",
      "Fold: 5  Epoch: 462  Training loss = 2.1296  Validation loss = 4.8718  \n",
      "\n",
      "Fold: 5  Epoch: 463  Training loss = 2.1294  Validation loss = 4.8715  \n",
      "\n",
      "Fold: 5  Epoch: 464  Training loss = 2.1292  Validation loss = 4.8710  \n",
      "\n",
      "Fold: 5  Epoch: 465  Training loss = 2.1290  Validation loss = 4.8707  \n",
      "\n",
      "Fold: 5  Epoch: 466  Training loss = 2.1288  Validation loss = 4.8704  \n",
      "\n",
      "Fold: 5  Epoch: 467  Training loss = 2.1286  Validation loss = 4.8700  \n",
      "\n",
      "Fold: 5  Epoch: 468  Training loss = 2.1284  Validation loss = 4.8696  \n",
      "\n",
      "Fold: 5  Epoch: 469  Training loss = 2.1282  Validation loss = 4.8693  \n",
      "\n",
      "Fold: 5  Epoch: 470  Training loss = 2.1281  Validation loss = 4.8691  \n",
      "\n",
      "Fold: 5  Epoch: 471  Training loss = 2.1279  Validation loss = 4.8688  \n",
      "\n",
      "Fold: 5  Epoch: 472  Training loss = 2.1277  Validation loss = 4.8685  \n",
      "\n",
      "Fold: 5  Epoch: 473  Training loss = 2.1275  Validation loss = 4.8680  \n",
      "\n",
      "Fold: 5  Epoch: 474  Training loss = 2.1273  Validation loss = 4.8676  \n",
      "\n",
      "Fold: 5  Epoch: 475  Training loss = 2.1271  Validation loss = 4.8673  \n",
      "\n",
      "Fold: 5  Epoch: 476  Training loss = 2.1268  Validation loss = 4.8667  \n",
      "\n",
      "Fold: 5  Epoch: 477  Training loss = 2.1266  Validation loss = 4.8663  \n",
      "\n",
      "Fold: 5  Epoch: 478  Training loss = 2.1264  Validation loss = 4.8659  \n",
      "\n",
      "Fold: 5  Epoch: 479  Training loss = 2.1262  Validation loss = 4.8655  \n",
      "\n",
      "Fold: 5  Epoch: 480  Training loss = 2.1259  Validation loss = 4.8651  \n",
      "\n",
      "Fold: 5  Epoch: 481  Training loss = 2.1258  Validation loss = 4.8648  \n",
      "\n",
      "Fold: 5  Epoch: 482  Training loss = 2.1255  Validation loss = 4.8644  \n",
      "\n",
      "Fold: 5  Epoch: 483  Training loss = 2.1253  Validation loss = 4.8639  \n",
      "\n",
      "Fold: 5  Epoch: 484  Training loss = 2.1250  Validation loss = 4.8635  \n",
      "\n",
      "Fold: 5  Epoch: 485  Training loss = 2.1248  Validation loss = 4.8630  \n",
      "\n",
      "Fold: 5  Epoch: 486  Training loss = 2.1245  Validation loss = 4.8625  \n",
      "\n",
      "Fold: 5  Epoch: 487  Training loss = 2.1243  Validation loss = 4.8622  \n",
      "\n",
      "Fold: 5  Epoch: 488  Training loss = 2.1241  Validation loss = 4.8617  \n",
      "\n",
      "Fold: 5  Epoch: 489  Training loss = 2.1238  Validation loss = 4.8611  \n",
      "\n",
      "Fold: 5  Epoch: 490  Training loss = 2.1236  Validation loss = 4.8608  \n",
      "\n",
      "Fold: 5  Epoch: 491  Training loss = 2.1234  Validation loss = 4.8605  \n",
      "\n",
      "Fold: 5  Epoch: 492  Training loss = 2.1233  Validation loss = 4.8603  \n",
      "\n",
      "Fold: 5  Epoch: 493  Training loss = 2.1232  Validation loss = 4.8601  \n",
      "\n",
      "Fold: 5  Epoch: 494  Training loss = 2.1230  Validation loss = 4.8597  \n",
      "\n",
      "Fold: 5  Epoch: 495  Training loss = 2.1227  Validation loss = 4.8591  \n",
      "\n",
      "Fold: 5  Epoch: 496  Training loss = 2.1224  Validation loss = 4.8586  \n",
      "\n",
      "Fold: 5  Epoch: 497  Training loss = 2.1222  Validation loss = 4.8582  \n",
      "\n",
      "Fold: 5  Epoch: 498  Training loss = 2.1220  Validation loss = 4.8578  \n",
      "\n",
      "Fold: 5  Epoch: 499  Training loss = 2.1218  Validation loss = 4.8574  \n",
      "\n",
      "Fold: 5  Epoch: 500  Training loss = 2.1216  Validation loss = 4.8570  \n",
      "\n",
      "Check model:  Fold: 5  Optimal epoch: 500  \n",
      "\n",
      "Fold: 6  Epoch: 1  Training loss = 2.4312  Validation loss = 2.5401  \n",
      "\n",
      "Fold: 6  Epoch: 2  Training loss = 2.4308  Validation loss = 2.5394  \n",
      "\n",
      "Fold: 6  Epoch: 3  Training loss = 2.4305  Validation loss = 2.5388  \n",
      "\n",
      "Fold: 6  Epoch: 4  Training loss = 2.4302  Validation loss = 2.5383  \n",
      "\n",
      "Fold: 6  Epoch: 5  Training loss = 2.4299  Validation loss = 2.5378  \n",
      "\n",
      "Fold: 6  Epoch: 6  Training loss = 2.4296  Validation loss = 2.5374  \n",
      "\n",
      "Fold: 6  Epoch: 7  Training loss = 2.4293  Validation loss = 2.5368  \n",
      "\n",
      "Fold: 6  Epoch: 8  Training loss = 2.4290  Validation loss = 2.5363  \n",
      "\n",
      "Fold: 6  Epoch: 9  Training loss = 2.4286  Validation loss = 2.5356  \n",
      "\n",
      "Fold: 6  Epoch: 10  Training loss = 2.4282  Validation loss = 2.5349  \n",
      "\n",
      "Fold: 6  Epoch: 11  Training loss = 2.4278  Validation loss = 2.5342  \n",
      "\n",
      "Fold: 6  Epoch: 12  Training loss = 2.4275  Validation loss = 2.5337  \n",
      "\n",
      "Fold: 6  Epoch: 13  Training loss = 2.4272  Validation loss = 2.5332  \n",
      "\n",
      "Fold: 6  Epoch: 14  Training loss = 2.4270  Validation loss = 2.5328  \n",
      "\n",
      "Fold: 6  Epoch: 15  Training loss = 2.4267  Validation loss = 2.5322  \n",
      "\n",
      "Fold: 6  Epoch: 16  Training loss = 2.4264  Validation loss = 2.5318  \n",
      "\n",
      "Fold: 6  Epoch: 17  Training loss = 2.4261  Validation loss = 2.5311  \n",
      "\n",
      "Fold: 6  Epoch: 18  Training loss = 2.4257  Validation loss = 2.5305  \n",
      "\n",
      "Fold: 6  Epoch: 19  Training loss = 2.4254  Validation loss = 2.5300  \n",
      "\n",
      "Fold: 6  Epoch: 20  Training loss = 2.4251  Validation loss = 2.5294  \n",
      "\n",
      "Fold: 6  Epoch: 21  Training loss = 2.4249  Validation loss = 2.5291  \n",
      "\n",
      "Fold: 6  Epoch: 22  Training loss = 2.4245  Validation loss = 2.5284  \n",
      "\n",
      "Fold: 6  Epoch: 23  Training loss = 2.4243  Validation loss = 2.5280  \n",
      "\n",
      "Fold: 6  Epoch: 24  Training loss = 2.4240  Validation loss = 2.5274  \n",
      "\n",
      "Fold: 6  Epoch: 25  Training loss = 2.4236  Validation loss = 2.5267  \n",
      "\n",
      "Fold: 6  Epoch: 26  Training loss = 2.4232  Validation loss = 2.5261  \n",
      "\n",
      "Fold: 6  Epoch: 27  Training loss = 2.4230  Validation loss = 2.5257  \n",
      "\n",
      "Fold: 6  Epoch: 28  Training loss = 2.4228  Validation loss = 2.5253  \n",
      "\n",
      "Fold: 6  Epoch: 29  Training loss = 2.4225  Validation loss = 2.5248  \n",
      "\n",
      "Fold: 6  Epoch: 30  Training loss = 2.4222  Validation loss = 2.5244  \n",
      "\n",
      "Fold: 6  Epoch: 31  Training loss = 2.4219  Validation loss = 2.5237  \n",
      "\n",
      "Fold: 6  Epoch: 32  Training loss = 2.4217  Validation loss = 2.5233  \n",
      "\n",
      "Fold: 6  Epoch: 33  Training loss = 2.4213  Validation loss = 2.5228  \n",
      "\n",
      "Fold: 6  Epoch: 34  Training loss = 2.4211  Validation loss = 2.5223  \n",
      "\n",
      "Fold: 6  Epoch: 35  Training loss = 2.4208  Validation loss = 2.5218  \n",
      "\n",
      "Fold: 6  Epoch: 36  Training loss = 2.4205  Validation loss = 2.5213  \n",
      "\n",
      "Fold: 6  Epoch: 37  Training loss = 2.4202  Validation loss = 2.5208  \n",
      "\n",
      "Fold: 6  Epoch: 38  Training loss = 2.4199  Validation loss = 2.5202  \n",
      "\n",
      "Fold: 6  Epoch: 39  Training loss = 2.4196  Validation loss = 2.5196  \n",
      "\n",
      "Fold: 6  Epoch: 40  Training loss = 2.4192  Validation loss = 2.5189  \n",
      "\n",
      "Fold: 6  Epoch: 41  Training loss = 2.4189  Validation loss = 2.5184  \n",
      "\n",
      "Fold: 6  Epoch: 42  Training loss = 2.4187  Validation loss = 2.5180  \n",
      "\n",
      "Fold: 6  Epoch: 43  Training loss = 2.4184  Validation loss = 2.5175  \n",
      "\n",
      "Fold: 6  Epoch: 44  Training loss = 2.4181  Validation loss = 2.5170  \n",
      "\n",
      "Fold: 6  Epoch: 45  Training loss = 2.4177  Validation loss = 2.5163  \n",
      "\n",
      "Fold: 6  Epoch: 46  Training loss = 2.4173  Validation loss = 2.5157  \n",
      "\n",
      "Fold: 6  Epoch: 47  Training loss = 2.4171  Validation loss = 2.5152  \n",
      "\n",
      "Fold: 6  Epoch: 48  Training loss = 2.4168  Validation loss = 2.5148  \n",
      "\n",
      "Fold: 6  Epoch: 49  Training loss = 2.4165  Validation loss = 2.5142  \n",
      "\n",
      "Fold: 6  Epoch: 50  Training loss = 2.4162  Validation loss = 2.5136  \n",
      "\n",
      "Fold: 6  Epoch: 51  Training loss = 2.4159  Validation loss = 2.5131  \n",
      "\n",
      "Fold: 6  Epoch: 52  Training loss = 2.4155  Validation loss = 2.5125  \n",
      "\n",
      "Fold: 6  Epoch: 53  Training loss = 2.4153  Validation loss = 2.5120  \n",
      "\n",
      "Fold: 6  Epoch: 54  Training loss = 2.4150  Validation loss = 2.5114  \n",
      "\n",
      "Fold: 6  Epoch: 55  Training loss = 2.4146  Validation loss = 2.5109  \n",
      "\n",
      "Fold: 6  Epoch: 56  Training loss = 2.4143  Validation loss = 2.5103  \n",
      "\n",
      "Fold: 6  Epoch: 57  Training loss = 2.4141  Validation loss = 2.5099  \n",
      "\n",
      "Fold: 6  Epoch: 58  Training loss = 2.4139  Validation loss = 2.5096  \n",
      "\n",
      "Fold: 6  Epoch: 59  Training loss = 2.4137  Validation loss = 2.5092  \n",
      "\n",
      "Fold: 6  Epoch: 60  Training loss = 2.4134  Validation loss = 2.5086  \n",
      "\n",
      "Fold: 6  Epoch: 61  Training loss = 2.4132  Validation loss = 2.5083  \n",
      "\n",
      "Fold: 6  Epoch: 62  Training loss = 2.4130  Validation loss = 2.5079  \n",
      "\n",
      "Fold: 6  Epoch: 63  Training loss = 2.4126  Validation loss = 2.5073  \n",
      "\n",
      "Fold: 6  Epoch: 64  Training loss = 2.4123  Validation loss = 2.5067  \n",
      "\n",
      "Fold: 6  Epoch: 65  Training loss = 2.4120  Validation loss = 2.5063  \n",
      "\n",
      "Fold: 6  Epoch: 66  Training loss = 2.4117  Validation loss = 2.5057  \n",
      "\n",
      "Fold: 6  Epoch: 67  Training loss = 2.4114  Validation loss = 2.5051  \n",
      "\n",
      "Fold: 6  Epoch: 68  Training loss = 2.4111  Validation loss = 2.5047  \n",
      "\n",
      "Fold: 6  Epoch: 69  Training loss = 2.4109  Validation loss = 2.5042  \n",
      "\n",
      "Fold: 6  Epoch: 70  Training loss = 2.4107  Validation loss = 2.5038  \n",
      "\n",
      "Fold: 6  Epoch: 71  Training loss = 2.4104  Validation loss = 2.5033  \n",
      "\n",
      "Fold: 6  Epoch: 72  Training loss = 2.4101  Validation loss = 2.5028  \n",
      "\n",
      "Fold: 6  Epoch: 73  Training loss = 2.4098  Validation loss = 2.5022  \n",
      "\n",
      "Fold: 6  Epoch: 74  Training loss = 2.4095  Validation loss = 2.5017  \n",
      "\n",
      "Fold: 6  Epoch: 75  Training loss = 2.4092  Validation loss = 2.5010  \n",
      "\n",
      "Fold: 6  Epoch: 76  Training loss = 2.4088  Validation loss = 2.5004  \n",
      "\n",
      "Fold: 6  Epoch: 77  Training loss = 2.4085  Validation loss = 2.4999  \n",
      "\n",
      "Fold: 6  Epoch: 78  Training loss = 2.4083  Validation loss = 2.4994  \n",
      "\n",
      "Fold: 6  Epoch: 79  Training loss = 2.4079  Validation loss = 2.4987  \n",
      "\n",
      "Fold: 6  Epoch: 80  Training loss = 2.4075  Validation loss = 2.4981  \n",
      "\n",
      "Fold: 6  Epoch: 81  Training loss = 2.4073  Validation loss = 2.4977  \n",
      "\n",
      "Fold: 6  Epoch: 82  Training loss = 2.4070  Validation loss = 2.4972  \n",
      "\n",
      "Fold: 6  Epoch: 83  Training loss = 2.4068  Validation loss = 2.4968  \n",
      "\n",
      "Fold: 6  Epoch: 84  Training loss = 2.4065  Validation loss = 2.4962  \n",
      "\n",
      "Fold: 6  Epoch: 85  Training loss = 2.4062  Validation loss = 2.4957  \n",
      "\n",
      "Fold: 6  Epoch: 86  Training loss = 2.4059  Validation loss = 2.4951  \n",
      "\n",
      "Fold: 6  Epoch: 87  Training loss = 2.4056  Validation loss = 2.4946  \n",
      "\n",
      "Fold: 6  Epoch: 88  Training loss = 2.4053  Validation loss = 2.4940  \n",
      "\n",
      "Fold: 6  Epoch: 89  Training loss = 2.4050  Validation loss = 2.4936  \n",
      "\n",
      "Fold: 6  Epoch: 90  Training loss = 2.4046  Validation loss = 2.4929  \n",
      "\n",
      "Fold: 6  Epoch: 91  Training loss = 2.4044  Validation loss = 2.4925  \n",
      "\n",
      "Fold: 6  Epoch: 92  Training loss = 2.4042  Validation loss = 2.4921  \n",
      "\n",
      "Fold: 6  Epoch: 93  Training loss = 2.4038  Validation loss = 2.4915  \n",
      "\n",
      "Fold: 6  Epoch: 94  Training loss = 2.4035  Validation loss = 2.4910  \n",
      "\n",
      "Fold: 6  Epoch: 95  Training loss = 2.4032  Validation loss = 2.4904  \n",
      "\n",
      "Fold: 6  Epoch: 96  Training loss = 2.4028  Validation loss = 2.4898  \n",
      "\n",
      "Fold: 6  Epoch: 97  Training loss = 2.4025  Validation loss = 2.4892  \n",
      "\n",
      "Fold: 6  Epoch: 98  Training loss = 2.4022  Validation loss = 2.4886  \n",
      "\n",
      "Fold: 6  Epoch: 99  Training loss = 2.4019  Validation loss = 2.4881  \n",
      "\n",
      "Fold: 6  Epoch: 100  Training loss = 2.4016  Validation loss = 2.4875  \n",
      "\n",
      "Fold: 6  Epoch: 101  Training loss = 2.4014  Validation loss = 2.4870  \n",
      "\n",
      "Fold: 6  Epoch: 102  Training loss = 2.4010  Validation loss = 2.4864  \n",
      "\n",
      "Fold: 6  Epoch: 103  Training loss = 2.4007  Validation loss = 2.4858  \n",
      "\n",
      "Fold: 6  Epoch: 104  Training loss = 2.4004  Validation loss = 2.4854  \n",
      "\n",
      "Fold: 6  Epoch: 105  Training loss = 2.4003  Validation loss = 2.4851  \n",
      "\n",
      "Fold: 6  Epoch: 106  Training loss = 2.4000  Validation loss = 2.4847  \n",
      "\n",
      "Fold: 6  Epoch: 107  Training loss = 2.3997  Validation loss = 2.4841  \n",
      "\n",
      "Fold: 6  Epoch: 108  Training loss = 2.3995  Validation loss = 2.4837  \n",
      "\n",
      "Fold: 6  Epoch: 109  Training loss = 2.3992  Validation loss = 2.4832  \n",
      "\n",
      "Fold: 6  Epoch: 110  Training loss = 2.3989  Validation loss = 2.4827  \n",
      "\n",
      "Fold: 6  Epoch: 111  Training loss = 2.3986  Validation loss = 2.4822  \n",
      "\n",
      "Fold: 6  Epoch: 112  Training loss = 2.3983  Validation loss = 2.4816  \n",
      "\n",
      "Fold: 6  Epoch: 113  Training loss = 2.3980  Validation loss = 2.4811  \n",
      "\n",
      "Fold: 6  Epoch: 114  Training loss = 2.3978  Validation loss = 2.4806  \n",
      "\n",
      "Fold: 6  Epoch: 115  Training loss = 2.3974  Validation loss = 2.4799  \n",
      "\n",
      "Fold: 6  Epoch: 116  Training loss = 2.3970  Validation loss = 2.4793  \n",
      "\n",
      "Fold: 6  Epoch: 117  Training loss = 2.3967  Validation loss = 2.4788  \n",
      "\n",
      "Fold: 6  Epoch: 118  Training loss = 2.3964  Validation loss = 2.4781  \n",
      "\n",
      "Fold: 6  Epoch: 119  Training loss = 2.3961  Validation loss = 2.4775  \n",
      "\n",
      "Fold: 6  Epoch: 120  Training loss = 2.3957  Validation loss = 2.4769  \n",
      "\n",
      "Fold: 6  Epoch: 121  Training loss = 2.3954  Validation loss = 2.4764  \n",
      "\n",
      "Fold: 6  Epoch: 122  Training loss = 2.3951  Validation loss = 2.4758  \n",
      "\n",
      "Fold: 6  Epoch: 123  Training loss = 2.3947  Validation loss = 2.4751  \n",
      "\n",
      "Fold: 6  Epoch: 124  Training loss = 2.3944  Validation loss = 2.4745  \n",
      "\n",
      "Fold: 6  Epoch: 125  Training loss = 2.3942  Validation loss = 2.4741  \n",
      "\n",
      "Fold: 6  Epoch: 126  Training loss = 2.3939  Validation loss = 2.4736  \n",
      "\n",
      "Fold: 6  Epoch: 127  Training loss = 2.3936  Validation loss = 2.4730  \n",
      "\n",
      "Fold: 6  Epoch: 128  Training loss = 2.3932  Validation loss = 2.4724  \n",
      "\n",
      "Fold: 6  Epoch: 129  Training loss = 2.3930  Validation loss = 2.4720  \n",
      "\n",
      "Fold: 6  Epoch: 130  Training loss = 2.3927  Validation loss = 2.4713  \n",
      "\n",
      "Fold: 6  Epoch: 131  Training loss = 2.3923  Validation loss = 2.4708  \n",
      "\n",
      "Fold: 6  Epoch: 132  Training loss = 2.3921  Validation loss = 2.4703  \n",
      "\n",
      "Fold: 6  Epoch: 133  Training loss = 2.3918  Validation loss = 2.4699  \n",
      "\n",
      "Fold: 6  Epoch: 134  Training loss = 2.3915  Validation loss = 2.4693  \n",
      "\n",
      "Fold: 6  Epoch: 135  Training loss = 2.3913  Validation loss = 2.4688  \n",
      "\n",
      "Fold: 6  Epoch: 136  Training loss = 2.3910  Validation loss = 2.4684  \n",
      "\n",
      "Fold: 6  Epoch: 137  Training loss = 2.3907  Validation loss = 2.4679  \n",
      "\n",
      "Fold: 6  Epoch: 138  Training loss = 2.3905  Validation loss = 2.4675  \n",
      "\n",
      "Fold: 6  Epoch: 139  Training loss = 2.3902  Validation loss = 2.4670  \n",
      "\n",
      "Fold: 6  Epoch: 140  Training loss = 2.3900  Validation loss = 2.4666  \n",
      "\n",
      "Fold: 6  Epoch: 141  Training loss = 2.3897  Validation loss = 2.4661  \n",
      "\n",
      "Fold: 6  Epoch: 142  Training loss = 2.3894  Validation loss = 2.4656  \n",
      "\n",
      "Fold: 6  Epoch: 143  Training loss = 2.3891  Validation loss = 2.4649  \n",
      "\n",
      "Fold: 6  Epoch: 144  Training loss = 2.3888  Validation loss = 2.4644  \n",
      "\n",
      "Fold: 6  Epoch: 145  Training loss = 2.3885  Validation loss = 2.4639  \n",
      "\n",
      "Fold: 6  Epoch: 146  Training loss = 2.3882  Validation loss = 2.4634  \n",
      "\n",
      "Fold: 6  Epoch: 147  Training loss = 2.3879  Validation loss = 2.4629  \n",
      "\n",
      "Fold: 6  Epoch: 148  Training loss = 2.3877  Validation loss = 2.4625  \n",
      "\n",
      "Fold: 6  Epoch: 149  Training loss = 2.3874  Validation loss = 2.4620  \n",
      "\n",
      "Fold: 6  Epoch: 150  Training loss = 2.3871  Validation loss = 2.4615  \n",
      "\n",
      "Fold: 6  Epoch: 151  Training loss = 2.3869  Validation loss = 2.4610  \n",
      "\n",
      "Fold: 6  Epoch: 152  Training loss = 2.3866  Validation loss = 2.4605  \n",
      "\n",
      "Fold: 6  Epoch: 153  Training loss = 2.3864  Validation loss = 2.4602  \n",
      "\n",
      "Fold: 6  Epoch: 154  Training loss = 2.3862  Validation loss = 2.4597  \n",
      "\n",
      "Fold: 6  Epoch: 155  Training loss = 2.3859  Validation loss = 2.4593  \n",
      "\n",
      "Fold: 6  Epoch: 156  Training loss = 2.3856  Validation loss = 2.4587  \n",
      "\n",
      "Fold: 6  Epoch: 157  Training loss = 2.3852  Validation loss = 2.4581  \n",
      "\n",
      "Fold: 6  Epoch: 158  Training loss = 2.3849  Validation loss = 2.4575  \n",
      "\n",
      "Fold: 6  Epoch: 159  Training loss = 2.3846  Validation loss = 2.4569  \n",
      "\n",
      "Fold: 6  Epoch: 160  Training loss = 2.3843  Validation loss = 2.4563  \n",
      "\n",
      "Fold: 6  Epoch: 161  Training loss = 2.3841  Validation loss = 2.4559  \n",
      "\n",
      "Fold: 6  Epoch: 162  Training loss = 2.3837  Validation loss = 2.4553  \n",
      "\n",
      "Fold: 6  Epoch: 163  Training loss = 2.3835  Validation loss = 2.4549  \n",
      "\n",
      "Fold: 6  Epoch: 164  Training loss = 2.3833  Validation loss = 2.4545  \n",
      "\n",
      "Fold: 6  Epoch: 165  Training loss = 2.3829  Validation loss = 2.4539  \n",
      "\n",
      "Fold: 6  Epoch: 166  Training loss = 2.3827  Validation loss = 2.4533  \n",
      "\n",
      "Fold: 6  Epoch: 167  Training loss = 2.3823  Validation loss = 2.4528  \n",
      "\n",
      "Fold: 6  Epoch: 168  Training loss = 2.3821  Validation loss = 2.4523  \n",
      "\n",
      "Fold: 6  Epoch: 169  Training loss = 2.3818  Validation loss = 2.4517  \n",
      "\n",
      "Fold: 6  Epoch: 170  Training loss = 2.3815  Validation loss = 2.4513  \n",
      "\n",
      "Fold: 6  Epoch: 171  Training loss = 2.3812  Validation loss = 2.4507  \n",
      "\n",
      "Fold: 6  Epoch: 172  Training loss = 2.3809  Validation loss = 2.4501  \n",
      "\n",
      "Fold: 6  Epoch: 173  Training loss = 2.3805  Validation loss = 2.4495  \n",
      "\n",
      "Fold: 6  Epoch: 174  Training loss = 2.3802  Validation loss = 2.4488  \n",
      "\n",
      "Fold: 6  Epoch: 175  Training loss = 2.3799  Validation loss = 2.4483  \n",
      "\n",
      "Fold: 6  Epoch: 176  Training loss = 2.3796  Validation loss = 2.4478  \n",
      "\n",
      "Fold: 6  Epoch: 177  Training loss = 2.3793  Validation loss = 2.4473  \n",
      "\n",
      "Fold: 6  Epoch: 178  Training loss = 2.3791  Validation loss = 2.4468  \n",
      "\n",
      "Fold: 6  Epoch: 179  Training loss = 2.3788  Validation loss = 2.4464  \n",
      "\n",
      "Fold: 6  Epoch: 180  Training loss = 2.3785  Validation loss = 2.4458  \n",
      "\n",
      "Fold: 6  Epoch: 181  Training loss = 2.3783  Validation loss = 2.4454  \n",
      "\n",
      "Fold: 6  Epoch: 182  Training loss = 2.3780  Validation loss = 2.4448  \n",
      "\n",
      "Fold: 6  Epoch: 183  Training loss = 2.3777  Validation loss = 2.4442  \n",
      "\n",
      "Fold: 6  Epoch: 184  Training loss = 2.3774  Validation loss = 2.4437  \n",
      "\n",
      "Fold: 6  Epoch: 185  Training loss = 2.3770  Validation loss = 2.4431  \n",
      "\n",
      "Fold: 6  Epoch: 186  Training loss = 2.3769  Validation loss = 2.4428  \n",
      "\n",
      "Fold: 6  Epoch: 187  Training loss = 2.3766  Validation loss = 2.4424  \n",
      "\n",
      "Fold: 6  Epoch: 188  Training loss = 2.3764  Validation loss = 2.4419  \n",
      "\n",
      "Fold: 6  Epoch: 189  Training loss = 2.3760  Validation loss = 2.4412  \n",
      "\n",
      "Fold: 6  Epoch: 190  Training loss = 2.3758  Validation loss = 2.4408  \n",
      "\n",
      "Fold: 6  Epoch: 191  Training loss = 2.3755  Validation loss = 2.4403  \n",
      "\n",
      "Fold: 6  Epoch: 192  Training loss = 2.3752  Validation loss = 2.4397  \n",
      "\n",
      "Fold: 6  Epoch: 193  Training loss = 2.3750  Validation loss = 2.4394  \n",
      "\n",
      "Fold: 6  Epoch: 194  Training loss = 2.3748  Validation loss = 2.4389  \n",
      "\n",
      "Fold: 6  Epoch: 195  Training loss = 2.3744  Validation loss = 2.4384  \n",
      "\n",
      "Fold: 6  Epoch: 196  Training loss = 2.3742  Validation loss = 2.4379  \n",
      "\n",
      "Fold: 6  Epoch: 197  Training loss = 2.3740  Validation loss = 2.4376  \n",
      "\n",
      "Fold: 6  Epoch: 198  Training loss = 2.3738  Validation loss = 2.4372  \n",
      "\n",
      "Fold: 6  Epoch: 199  Training loss = 2.3735  Validation loss = 2.4366  \n",
      "\n",
      "Fold: 6  Epoch: 200  Training loss = 2.3732  Validation loss = 2.4361  \n",
      "\n",
      "Fold: 6  Epoch: 201  Training loss = 2.3729  Validation loss = 2.4355  \n",
      "\n",
      "Fold: 6  Epoch: 202  Training loss = 2.3725  Validation loss = 2.4348  \n",
      "\n",
      "Fold: 6  Epoch: 203  Training loss = 2.3723  Validation loss = 2.4344  \n",
      "\n",
      "Fold: 6  Epoch: 204  Training loss = 2.3720  Validation loss = 2.4339  \n",
      "\n",
      "Fold: 6  Epoch: 205  Training loss = 2.3718  Validation loss = 2.4336  \n",
      "\n",
      "Fold: 6  Epoch: 206  Training loss = 2.3715  Validation loss = 2.4330  \n",
      "\n",
      "Fold: 6  Epoch: 207  Training loss = 2.3712  Validation loss = 2.4325  \n",
      "\n",
      "Fold: 6  Epoch: 208  Training loss = 2.3709  Validation loss = 2.4319  \n",
      "\n",
      "Fold: 6  Epoch: 209  Training loss = 2.3706  Validation loss = 2.4314  \n",
      "\n",
      "Fold: 6  Epoch: 210  Training loss = 2.3704  Validation loss = 2.4310  \n",
      "\n",
      "Fold: 6  Epoch: 211  Training loss = 2.3701  Validation loss = 2.4304  \n",
      "\n",
      "Fold: 6  Epoch: 212  Training loss = 2.3698  Validation loss = 2.4299  \n",
      "\n",
      "Fold: 6  Epoch: 213  Training loss = 2.3696  Validation loss = 2.4296  \n",
      "\n",
      "Fold: 6  Epoch: 214  Training loss = 2.3693  Validation loss = 2.4291  \n",
      "\n",
      "Fold: 6  Epoch: 215  Training loss = 2.3691  Validation loss = 2.4286  \n",
      "\n",
      "Fold: 6  Epoch: 216  Training loss = 2.3688  Validation loss = 2.4280  \n",
      "\n",
      "Fold: 6  Epoch: 217  Training loss = 2.3685  Validation loss = 2.4276  \n",
      "\n",
      "Fold: 6  Epoch: 218  Training loss = 2.3683  Validation loss = 2.4272  \n",
      "\n",
      "Fold: 6  Epoch: 219  Training loss = 2.3681  Validation loss = 2.4268  \n",
      "\n",
      "Fold: 6  Epoch: 220  Training loss = 2.3677  Validation loss = 2.4262  \n",
      "\n",
      "Fold: 6  Epoch: 221  Training loss = 2.3674  Validation loss = 2.4256  \n",
      "\n",
      "Fold: 6  Epoch: 222  Training loss = 2.3671  Validation loss = 2.4251  \n",
      "\n",
      "Fold: 6  Epoch: 223  Training loss = 2.3669  Validation loss = 2.4247  \n",
      "\n",
      "Fold: 6  Epoch: 224  Training loss = 2.3667  Validation loss = 2.4242  \n",
      "\n",
      "Fold: 6  Epoch: 225  Training loss = 2.3664  Validation loss = 2.4238  \n",
      "\n",
      "Fold: 6  Epoch: 226  Training loss = 2.3662  Validation loss = 2.4234  \n",
      "\n",
      "Fold: 6  Epoch: 227  Training loss = 2.3659  Validation loss = 2.4228  \n",
      "\n",
      "Fold: 6  Epoch: 228  Training loss = 2.3656  Validation loss = 2.4222  \n",
      "\n",
      "Fold: 6  Epoch: 229  Training loss = 2.3655  Validation loss = 2.4220  \n",
      "\n",
      "Fold: 6  Epoch: 230  Training loss = 2.3652  Validation loss = 2.4214  \n",
      "\n",
      "Fold: 6  Epoch: 231  Training loss = 2.3648  Validation loss = 2.4207  \n",
      "\n",
      "Fold: 6  Epoch: 232  Training loss = 2.3646  Validation loss = 2.4204  \n",
      "\n",
      "Fold: 6  Epoch: 233  Training loss = 2.3643  Validation loss = 2.4197  \n",
      "\n",
      "Fold: 6  Epoch: 234  Training loss = 2.3640  Validation loss = 2.4193  \n",
      "\n",
      "Fold: 6  Epoch: 235  Training loss = 2.3638  Validation loss = 2.4189  \n",
      "\n",
      "Fold: 6  Epoch: 236  Training loss = 2.3635  Validation loss = 2.4184  \n",
      "\n",
      "Fold: 6  Epoch: 237  Training loss = 2.3633  Validation loss = 2.4179  \n",
      "\n",
      "Fold: 6  Epoch: 238  Training loss = 2.3631  Validation loss = 2.4176  \n",
      "\n",
      "Fold: 6  Epoch: 239  Training loss = 2.3628  Validation loss = 2.4170  \n",
      "\n",
      "Fold: 6  Epoch: 240  Training loss = 2.3625  Validation loss = 2.4165  \n",
      "\n",
      "Fold: 6  Epoch: 241  Training loss = 2.3622  Validation loss = 2.4160  \n",
      "\n",
      "Fold: 6  Epoch: 242  Training loss = 2.3620  Validation loss = 2.4156  \n",
      "\n",
      "Fold: 6  Epoch: 243  Training loss = 2.3617  Validation loss = 2.4150  \n",
      "\n",
      "Fold: 6  Epoch: 244  Training loss = 2.3614  Validation loss = 2.4146  \n",
      "\n",
      "Fold: 6  Epoch: 245  Training loss = 2.3612  Validation loss = 2.4141  \n",
      "\n",
      "Fold: 6  Epoch: 246  Training loss = 2.3609  Validation loss = 2.4136  \n",
      "\n",
      "Fold: 6  Epoch: 247  Training loss = 2.3606  Validation loss = 2.4130  \n",
      "\n",
      "Fold: 6  Epoch: 248  Training loss = 2.3604  Validation loss = 2.4125  \n",
      "\n",
      "Fold: 6  Epoch: 249  Training loss = 2.3601  Validation loss = 2.4120  \n",
      "\n",
      "Fold: 6  Epoch: 250  Training loss = 2.3598  Validation loss = 2.4115  \n",
      "\n",
      "Fold: 6  Epoch: 251  Training loss = 2.3596  Validation loss = 2.4111  \n",
      "\n",
      "Fold: 6  Epoch: 252  Training loss = 2.3593  Validation loss = 2.4107  \n",
      "\n",
      "Fold: 6  Epoch: 253  Training loss = 2.3590  Validation loss = 2.4101  \n",
      "\n",
      "Fold: 6  Epoch: 254  Training loss = 2.3588  Validation loss = 2.4098  \n",
      "\n",
      "Fold: 6  Epoch: 255  Training loss = 2.3586  Validation loss = 2.4093  \n",
      "\n",
      "Fold: 6  Epoch: 256  Training loss = 2.3582  Validation loss = 2.4086  \n",
      "\n",
      "Fold: 6  Epoch: 257  Training loss = 2.3579  Validation loss = 2.4081  \n",
      "\n",
      "Fold: 6  Epoch: 258  Training loss = 2.3577  Validation loss = 2.4077  \n",
      "\n",
      "Fold: 6  Epoch: 259  Training loss = 2.3574  Validation loss = 2.4071  \n",
      "\n",
      "Fold: 6  Epoch: 260  Training loss = 2.3572  Validation loss = 2.4067  \n",
      "\n",
      "Fold: 6  Epoch: 261  Training loss = 2.3568  Validation loss = 2.4060  \n",
      "\n",
      "Fold: 6  Epoch: 262  Training loss = 2.3565  Validation loss = 2.4055  \n",
      "\n",
      "Fold: 6  Epoch: 263  Training loss = 2.3562  Validation loss = 2.4048  \n",
      "\n",
      "Fold: 6  Epoch: 264  Training loss = 2.3560  Validation loss = 2.4045  \n",
      "\n",
      "Fold: 6  Epoch: 265  Training loss = 2.3557  Validation loss = 2.4039  \n",
      "\n",
      "Fold: 6  Epoch: 266  Training loss = 2.3554  Validation loss = 2.4034  \n",
      "\n",
      "Fold: 6  Epoch: 267  Training loss = 2.3551  Validation loss = 2.4029  \n",
      "\n",
      "Fold: 6  Epoch: 268  Training loss = 2.3549  Validation loss = 2.4024  \n",
      "\n",
      "Fold: 6  Epoch: 269  Training loss = 2.3546  Validation loss = 2.4019  \n",
      "\n",
      "Fold: 6  Epoch: 270  Training loss = 2.3543  Validation loss = 2.4015  \n",
      "\n",
      "Fold: 6  Epoch: 271  Training loss = 2.3540  Validation loss = 2.4009  \n",
      "\n",
      "Fold: 6  Epoch: 272  Training loss = 2.3538  Validation loss = 2.4004  \n",
      "\n",
      "Fold: 6  Epoch: 273  Training loss = 2.3535  Validation loss = 2.3998  \n",
      "\n",
      "Fold: 6  Epoch: 274  Training loss = 2.3532  Validation loss = 2.3993  \n",
      "\n",
      "Fold: 6  Epoch: 275  Training loss = 2.3529  Validation loss = 2.3989  \n",
      "\n",
      "Fold: 6  Epoch: 276  Training loss = 2.3526  Validation loss = 2.3983  \n",
      "\n",
      "Fold: 6  Epoch: 277  Training loss = 2.3523  Validation loss = 2.3976  \n",
      "\n",
      "Fold: 6  Epoch: 278  Training loss = 2.3520  Validation loss = 2.3972  \n",
      "\n",
      "Fold: 6  Epoch: 279  Training loss = 2.3518  Validation loss = 2.3967  \n",
      "\n",
      "Fold: 6  Epoch: 280  Training loss = 2.3515  Validation loss = 2.3962  \n",
      "\n",
      "Fold: 6  Epoch: 281  Training loss = 2.3513  Validation loss = 2.3957  \n",
      "\n",
      "Fold: 6  Epoch: 282  Training loss = 2.3510  Validation loss = 2.3952  \n",
      "\n",
      "Fold: 6  Epoch: 283  Training loss = 2.3507  Validation loss = 2.3947  \n",
      "\n",
      "Fold: 6  Epoch: 284  Training loss = 2.3505  Validation loss = 2.3943  \n",
      "\n",
      "Fold: 6  Epoch: 285  Training loss = 2.3503  Validation loss = 2.3940  \n",
      "\n",
      "Fold: 6  Epoch: 286  Training loss = 2.3500  Validation loss = 2.3934  \n",
      "\n",
      "Fold: 6  Epoch: 287  Training loss = 2.3498  Validation loss = 2.3930  \n",
      "\n",
      "Fold: 6  Epoch: 288  Training loss = 2.3494  Validation loss = 2.3923  \n",
      "\n",
      "Fold: 6  Epoch: 289  Training loss = 2.3491  Validation loss = 2.3918  \n",
      "\n",
      "Fold: 6  Epoch: 290  Training loss = 2.3489  Validation loss = 2.3913  \n",
      "\n",
      "Fold: 6  Epoch: 291  Training loss = 2.3486  Validation loss = 2.3908  \n",
      "\n",
      "Fold: 6  Epoch: 292  Training loss = 2.3483  Validation loss = 2.3902  \n",
      "\n",
      "Fold: 6  Epoch: 293  Training loss = 2.3480  Validation loss = 2.3897  \n",
      "\n",
      "Fold: 6  Epoch: 294  Training loss = 2.3479  Validation loss = 2.3894  \n",
      "\n",
      "Fold: 6  Epoch: 295  Training loss = 2.3476  Validation loss = 2.3889  \n",
      "\n",
      "Fold: 6  Epoch: 296  Training loss = 2.3472  Validation loss = 2.3882  \n",
      "\n",
      "Fold: 6  Epoch: 297  Training loss = 2.3469  Validation loss = 2.3877  \n",
      "\n",
      "Fold: 6  Epoch: 298  Training loss = 2.3466  Validation loss = 2.3871  \n",
      "\n",
      "Fold: 6  Epoch: 299  Training loss = 2.3464  Validation loss = 2.3866  \n",
      "\n",
      "Fold: 6  Epoch: 300  Training loss = 2.3461  Validation loss = 2.3861  \n",
      "\n",
      "Fold: 6  Epoch: 301  Training loss = 2.3459  Validation loss = 2.3857  \n",
      "\n",
      "Fold: 6  Epoch: 302  Training loss = 2.3457  Validation loss = 2.3853  \n",
      "\n",
      "Fold: 6  Epoch: 303  Training loss = 2.3454  Validation loss = 2.3849  \n",
      "\n",
      "Fold: 6  Epoch: 304  Training loss = 2.3451  Validation loss = 2.3844  \n",
      "\n",
      "Fold: 6  Epoch: 305  Training loss = 2.3448  Validation loss = 2.3838  \n",
      "\n",
      "Fold: 6  Epoch: 306  Training loss = 2.3444  Validation loss = 2.3831  \n",
      "\n",
      "Fold: 6  Epoch: 307  Training loss = 2.3442  Validation loss = 2.3825  \n",
      "\n",
      "Fold: 6  Epoch: 308  Training loss = 2.3439  Validation loss = 2.3820  \n",
      "\n",
      "Fold: 6  Epoch: 309  Training loss = 2.3436  Validation loss = 2.3815  \n",
      "\n",
      "Fold: 6  Epoch: 310  Training loss = 2.3433  Validation loss = 2.3810  \n",
      "\n",
      "Fold: 6  Epoch: 311  Training loss = 2.3430  Validation loss = 2.3804  \n",
      "\n",
      "Fold: 6  Epoch: 312  Training loss = 2.3427  Validation loss = 2.3797  \n",
      "\n",
      "Fold: 6  Epoch: 313  Training loss = 2.3425  Validation loss = 2.3793  \n",
      "\n",
      "Fold: 6  Epoch: 314  Training loss = 2.3422  Validation loss = 2.3788  \n",
      "\n",
      "Fold: 6  Epoch: 315  Training loss = 2.3420  Validation loss = 2.3784  \n",
      "\n",
      "Fold: 6  Epoch: 316  Training loss = 2.3417  Validation loss = 2.3779  \n",
      "\n",
      "Fold: 6  Epoch: 317  Training loss = 2.3414  Validation loss = 2.3774  \n",
      "\n",
      "Fold: 6  Epoch: 318  Training loss = 2.3412  Validation loss = 2.3770  \n",
      "\n",
      "Fold: 6  Epoch: 319  Training loss = 2.3409  Validation loss = 2.3765  \n",
      "\n",
      "Fold: 6  Epoch: 320  Training loss = 2.3407  Validation loss = 2.3760  \n",
      "\n",
      "Fold: 6  Epoch: 321  Training loss = 2.3404  Validation loss = 2.3754  \n",
      "\n",
      "Fold: 6  Epoch: 322  Training loss = 2.3402  Validation loss = 2.3750  \n",
      "\n",
      "Fold: 6  Epoch: 323  Training loss = 2.3399  Validation loss = 2.3746  \n",
      "\n",
      "Fold: 6  Epoch: 324  Training loss = 2.3396  Validation loss = 2.3739  \n",
      "\n",
      "Fold: 6  Epoch: 325  Training loss = 2.3393  Validation loss = 2.3733  \n",
      "\n",
      "Fold: 6  Epoch: 326  Training loss = 2.3390  Validation loss = 2.3728  \n",
      "\n",
      "Fold: 6  Epoch: 327  Training loss = 2.3388  Validation loss = 2.3724  \n",
      "\n",
      "Fold: 6  Epoch: 328  Training loss = 2.3384  Validation loss = 2.3717  \n",
      "\n",
      "Fold: 6  Epoch: 329  Training loss = 2.3382  Validation loss = 2.3712  \n",
      "\n",
      "Fold: 6  Epoch: 330  Training loss = 2.3379  Validation loss = 2.3707  \n",
      "\n",
      "Fold: 6  Epoch: 331  Training loss = 2.3376  Validation loss = 2.3702  \n",
      "\n",
      "Fold: 6  Epoch: 332  Training loss = 2.3374  Validation loss = 2.3696  \n",
      "\n",
      "Fold: 6  Epoch: 333  Training loss = 2.3370  Validation loss = 2.3690  \n",
      "\n",
      "Fold: 6  Epoch: 334  Training loss = 2.3368  Validation loss = 2.3686  \n",
      "\n",
      "Fold: 6  Epoch: 335  Training loss = 2.3365  Validation loss = 2.3681  \n",
      "\n",
      "Fold: 6  Epoch: 336  Training loss = 2.3362  Validation loss = 2.3675  \n",
      "\n",
      "Fold: 6  Epoch: 337  Training loss = 2.3359  Validation loss = 2.3670  \n",
      "\n",
      "Fold: 6  Epoch: 338  Training loss = 2.3357  Validation loss = 2.3665  \n",
      "\n",
      "Fold: 6  Epoch: 339  Training loss = 2.3354  Validation loss = 2.3659  \n",
      "\n",
      "Fold: 6  Epoch: 340  Training loss = 2.3351  Validation loss = 2.3654  \n",
      "\n",
      "Fold: 6  Epoch: 341  Training loss = 2.3348  Validation loss = 2.3648  \n",
      "\n",
      "Fold: 6  Epoch: 342  Training loss = 2.3346  Validation loss = 2.3644  \n",
      "\n",
      "Fold: 6  Epoch: 343  Training loss = 2.3343  Validation loss = 2.3639  \n",
      "\n",
      "Fold: 6  Epoch: 344  Training loss = 2.3341  Validation loss = 2.3634  \n",
      "\n",
      "Fold: 6  Epoch: 345  Training loss = 2.3336  Validation loss = 2.3626  \n",
      "\n",
      "Fold: 6  Epoch: 346  Training loss = 2.3334  Validation loss = 2.3621  \n",
      "\n",
      "Fold: 6  Epoch: 347  Training loss = 2.3331  Validation loss = 2.3615  \n",
      "\n",
      "Fold: 6  Epoch: 348  Training loss = 2.3328  Validation loss = 2.3611  \n",
      "\n",
      "Fold: 6  Epoch: 349  Training loss = 2.3326  Validation loss = 2.3605  \n",
      "\n",
      "Fold: 6  Epoch: 350  Training loss = 2.3323  Validation loss = 2.3601  \n",
      "\n",
      "Fold: 6  Epoch: 351  Training loss = 2.3321  Validation loss = 2.3597  \n",
      "\n",
      "Fold: 6  Epoch: 352  Training loss = 2.3318  Validation loss = 2.3592  \n",
      "\n",
      "Fold: 6  Epoch: 353  Training loss = 2.3316  Validation loss = 2.3588  \n",
      "\n",
      "Fold: 6  Epoch: 354  Training loss = 2.3313  Validation loss = 2.3582  \n",
      "\n",
      "Fold: 6  Epoch: 355  Training loss = 2.3310  Validation loss = 2.3576  \n",
      "\n",
      "Fold: 6  Epoch: 356  Training loss = 2.3308  Validation loss = 2.3572  \n",
      "\n",
      "Fold: 6  Epoch: 357  Training loss = 2.3306  Validation loss = 2.3569  \n",
      "\n",
      "Fold: 6  Epoch: 358  Training loss = 2.3303  Validation loss = 2.3563  \n",
      "\n",
      "Fold: 6  Epoch: 359  Training loss = 2.3300  Validation loss = 2.3558  \n",
      "\n",
      "Fold: 6  Epoch: 360  Training loss = 2.3298  Validation loss = 2.3552  \n",
      "\n",
      "Fold: 6  Epoch: 361  Training loss = 2.3295  Validation loss = 2.3548  \n",
      "\n",
      "Fold: 6  Epoch: 362  Training loss = 2.3292  Validation loss = 2.3542  \n",
      "\n",
      "Fold: 6  Epoch: 363  Training loss = 2.3289  Validation loss = 2.3537  \n",
      "\n",
      "Fold: 6  Epoch: 364  Training loss = 2.3287  Validation loss = 2.3532  \n",
      "\n",
      "Fold: 6  Epoch: 365  Training loss = 2.3284  Validation loss = 2.3526  \n",
      "\n",
      "Fold: 6  Epoch: 366  Training loss = 2.3282  Validation loss = 2.3522  \n",
      "\n",
      "Fold: 6  Epoch: 367  Training loss = 2.3279  Validation loss = 2.3518  \n",
      "\n",
      "Fold: 6  Epoch: 368  Training loss = 2.3276  Validation loss = 2.3512  \n",
      "\n",
      "Fold: 6  Epoch: 369  Training loss = 2.3275  Validation loss = 2.3509  \n",
      "\n",
      "Fold: 6  Epoch: 370  Training loss = 2.3272  Validation loss = 2.3504  \n",
      "\n",
      "Fold: 6  Epoch: 371  Training loss = 2.3269  Validation loss = 2.3498  \n",
      "\n",
      "Fold: 6  Epoch: 372  Training loss = 2.3266  Validation loss = 2.3493  \n",
      "\n",
      "Fold: 6  Epoch: 373  Training loss = 2.3264  Validation loss = 2.3490  \n",
      "\n",
      "Fold: 6  Epoch: 374  Training loss = 2.3262  Validation loss = 2.3485  \n",
      "\n",
      "Fold: 6  Epoch: 375  Training loss = 2.3260  Validation loss = 2.3482  \n",
      "\n",
      "Fold: 6  Epoch: 376  Training loss = 2.3258  Validation loss = 2.3477  \n",
      "\n",
      "Fold: 6  Epoch: 377  Training loss = 2.3255  Validation loss = 2.3472  \n",
      "\n",
      "Fold: 6  Epoch: 378  Training loss = 2.3252  Validation loss = 2.3467  \n",
      "\n",
      "Fold: 6  Epoch: 379  Training loss = 2.3250  Validation loss = 2.3463  \n",
      "\n",
      "Fold: 6  Epoch: 380  Training loss = 2.3248  Validation loss = 2.3458  \n",
      "\n",
      "Fold: 6  Epoch: 381  Training loss = 2.3245  Validation loss = 2.3453  \n",
      "\n",
      "Fold: 6  Epoch: 382  Training loss = 2.3243  Validation loss = 2.3448  \n",
      "\n",
      "Fold: 6  Epoch: 383  Training loss = 2.3240  Validation loss = 2.3443  \n",
      "\n",
      "Fold: 6  Epoch: 384  Training loss = 2.3237  Validation loss = 2.3437  \n",
      "\n",
      "Fold: 6  Epoch: 385  Training loss = 2.3234  Validation loss = 2.3431  \n",
      "\n",
      "Fold: 6  Epoch: 386  Training loss = 2.3232  Validation loss = 2.3428  \n",
      "\n",
      "Fold: 6  Epoch: 387  Training loss = 2.3230  Validation loss = 2.3425  \n",
      "\n",
      "Fold: 6  Epoch: 388  Training loss = 2.3227  Validation loss = 2.3419  \n",
      "\n",
      "Fold: 6  Epoch: 389  Training loss = 2.3225  Validation loss = 2.3414  \n",
      "\n",
      "Fold: 6  Epoch: 390  Training loss = 2.3222  Validation loss = 2.3410  \n",
      "\n",
      "Fold: 6  Epoch: 391  Training loss = 2.3219  Validation loss = 2.3404  \n",
      "\n",
      "Fold: 6  Epoch: 392  Training loss = 2.3217  Validation loss = 2.3399  \n",
      "\n",
      "Fold: 6  Epoch: 393  Training loss = 2.3214  Validation loss = 2.3394  \n",
      "\n",
      "Fold: 6  Epoch: 394  Training loss = 2.3212  Validation loss = 2.3389  \n",
      "\n",
      "Fold: 6  Epoch: 395  Training loss = 2.3209  Validation loss = 2.3384  \n",
      "\n",
      "Fold: 6  Epoch: 396  Training loss = 2.3206  Validation loss = 2.3379  \n",
      "\n",
      "Fold: 6  Epoch: 397  Training loss = 2.3204  Validation loss = 2.3375  \n",
      "\n",
      "Fold: 6  Epoch: 398  Training loss = 2.3201  Validation loss = 2.3369  \n",
      "\n",
      "Fold: 6  Epoch: 399  Training loss = 2.3199  Validation loss = 2.3365  \n",
      "\n",
      "Fold: 6  Epoch: 400  Training loss = 2.3197  Validation loss = 2.3361  \n",
      "\n",
      "Fold: 6  Epoch: 401  Training loss = 2.3195  Validation loss = 2.3357  \n",
      "\n",
      "Fold: 6  Epoch: 402  Training loss = 2.3193  Validation loss = 2.3353  \n",
      "\n",
      "Fold: 6  Epoch: 403  Training loss = 2.3190  Validation loss = 2.3347  \n",
      "\n",
      "Fold: 6  Epoch: 404  Training loss = 2.3187  Validation loss = 2.3343  \n",
      "\n",
      "Fold: 6  Epoch: 405  Training loss = 2.3185  Validation loss = 2.3338  \n",
      "\n",
      "Fold: 6  Epoch: 406  Training loss = 2.3182  Validation loss = 2.3333  \n",
      "\n",
      "Fold: 6  Epoch: 407  Training loss = 2.3180  Validation loss = 2.3328  \n",
      "\n",
      "Fold: 6  Epoch: 408  Training loss = 2.3177  Validation loss = 2.3322  \n",
      "\n",
      "Fold: 6  Epoch: 409  Training loss = 2.3174  Validation loss = 2.3317  \n",
      "\n",
      "Fold: 6  Epoch: 410  Training loss = 2.3172  Validation loss = 2.3313  \n",
      "\n",
      "Fold: 6  Epoch: 411  Training loss = 2.3170  Validation loss = 2.3309  \n",
      "\n",
      "Fold: 6  Epoch: 412  Training loss = 2.3167  Validation loss = 2.3303  \n",
      "\n",
      "Fold: 6  Epoch: 413  Training loss = 2.3164  Validation loss = 2.3298  \n",
      "\n",
      "Fold: 6  Epoch: 414  Training loss = 2.3162  Validation loss = 2.3295  \n",
      "\n",
      "Fold: 6  Epoch: 415  Training loss = 2.3160  Validation loss = 2.3290  \n",
      "\n",
      "Fold: 6  Epoch: 416  Training loss = 2.3157  Validation loss = 2.3284  \n",
      "\n",
      "Fold: 6  Epoch: 417  Training loss = 2.3154  Validation loss = 2.3278  \n",
      "\n",
      "Fold: 6  Epoch: 418  Training loss = 2.3151  Validation loss = 2.3273  \n",
      "\n",
      "Fold: 6  Epoch: 419  Training loss = 2.3149  Validation loss = 2.3269  \n",
      "\n",
      "Fold: 6  Epoch: 420  Training loss = 2.3146  Validation loss = 2.3263  \n",
      "\n",
      "Fold: 6  Epoch: 421  Training loss = 2.3143  Validation loss = 2.3257  \n",
      "\n",
      "Fold: 6  Epoch: 422  Training loss = 2.3140  Validation loss = 2.3253  \n",
      "\n",
      "Fold: 6  Epoch: 423  Training loss = 2.3137  Validation loss = 2.3247  \n",
      "\n",
      "Fold: 6  Epoch: 424  Training loss = 2.3135  Validation loss = 2.3242  \n",
      "\n",
      "Fold: 6  Epoch: 425  Training loss = 2.3132  Validation loss = 2.3236  \n",
      "\n",
      "Fold: 6  Epoch: 426  Training loss = 2.3129  Validation loss = 2.3232  \n",
      "\n",
      "Fold: 6  Epoch: 427  Training loss = 2.3127  Validation loss = 2.3227  \n",
      "\n",
      "Fold: 6  Epoch: 428  Training loss = 2.3124  Validation loss = 2.3223  \n",
      "\n",
      "Fold: 6  Epoch: 429  Training loss = 2.3122  Validation loss = 2.3219  \n",
      "\n",
      "Fold: 6  Epoch: 430  Training loss = 2.3119  Validation loss = 2.3212  \n",
      "\n",
      "Fold: 6  Epoch: 431  Training loss = 2.3116  Validation loss = 2.3207  \n",
      "\n",
      "Fold: 6  Epoch: 432  Training loss = 2.3113  Validation loss = 2.3201  \n",
      "\n",
      "Fold: 6  Epoch: 433  Training loss = 2.3110  Validation loss = 2.3195  \n",
      "\n",
      "Fold: 6  Epoch: 434  Training loss = 2.3108  Validation loss = 2.3191  \n",
      "\n",
      "Fold: 6  Epoch: 435  Training loss = 2.3106  Validation loss = 2.3188  \n",
      "\n",
      "Fold: 6  Epoch: 436  Training loss = 2.3104  Validation loss = 2.3184  \n",
      "\n",
      "Fold: 6  Epoch: 437  Training loss = 2.3102  Validation loss = 2.3179  \n",
      "\n",
      "Fold: 6  Epoch: 438  Training loss = 2.3099  Validation loss = 2.3174  \n",
      "\n",
      "Fold: 6  Epoch: 439  Training loss = 2.3097  Validation loss = 2.3170  \n",
      "\n",
      "Fold: 6  Epoch: 440  Training loss = 2.3094  Validation loss = 2.3165  \n",
      "\n",
      "Fold: 6  Epoch: 441  Training loss = 2.3092  Validation loss = 2.3161  \n",
      "\n",
      "Fold: 6  Epoch: 442  Training loss = 2.3089  Validation loss = 2.3155  \n",
      "\n",
      "Fold: 6  Epoch: 443  Training loss = 2.3088  Validation loss = 2.3152  \n",
      "\n",
      "Fold: 6  Epoch: 444  Training loss = 2.3085  Validation loss = 2.3148  \n",
      "\n",
      "Fold: 6  Epoch: 445  Training loss = 2.3083  Validation loss = 2.3142  \n",
      "\n",
      "Fold: 6  Epoch: 446  Training loss = 2.3080  Validation loss = 2.3138  \n",
      "\n",
      "Fold: 6  Epoch: 447  Training loss = 2.3078  Validation loss = 2.3134  \n",
      "\n",
      "Fold: 6  Epoch: 448  Training loss = 2.3076  Validation loss = 2.3130  \n",
      "\n",
      "Fold: 6  Epoch: 449  Training loss = 2.3073  Validation loss = 2.3124  \n",
      "\n",
      "Fold: 6  Epoch: 450  Training loss = 2.3071  Validation loss = 2.3119  \n",
      "\n",
      "Fold: 6  Epoch: 451  Training loss = 2.3068  Validation loss = 2.3114  \n",
      "\n",
      "Fold: 6  Epoch: 452  Training loss = 2.3065  Validation loss = 2.3108  \n",
      "\n",
      "Fold: 6  Epoch: 453  Training loss = 2.3063  Validation loss = 2.3104  \n",
      "\n",
      "Fold: 6  Epoch: 454  Training loss = 2.3060  Validation loss = 2.3099  \n",
      "\n",
      "Fold: 6  Epoch: 455  Training loss = 2.3058  Validation loss = 2.3095  \n",
      "\n",
      "Fold: 6  Epoch: 456  Training loss = 2.3056  Validation loss = 2.3092  \n",
      "\n",
      "Fold: 6  Epoch: 457  Training loss = 2.3053  Validation loss = 2.3086  \n",
      "\n",
      "Fold: 6  Epoch: 458  Training loss = 2.3052  Validation loss = 2.3083  \n",
      "\n",
      "Fold: 6  Epoch: 459  Training loss = 2.3049  Validation loss = 2.3078  \n",
      "\n",
      "Fold: 6  Epoch: 460  Training loss = 2.3046  Validation loss = 2.3073  \n",
      "\n",
      "Fold: 6  Epoch: 461  Training loss = 2.3044  Validation loss = 2.3067  \n",
      "\n",
      "Fold: 6  Epoch: 462  Training loss = 2.3040  Validation loss = 2.3061  \n",
      "\n",
      "Fold: 6  Epoch: 463  Training loss = 2.3038  Validation loss = 2.3056  \n",
      "\n",
      "Fold: 6  Epoch: 464  Training loss = 2.3035  Validation loss = 2.3052  \n",
      "\n",
      "Fold: 6  Epoch: 465  Training loss = 2.3033  Validation loss = 2.3048  \n",
      "\n",
      "Fold: 6  Epoch: 466  Training loss = 2.3031  Validation loss = 2.3042  \n",
      "\n",
      "Fold: 6  Epoch: 467  Training loss = 2.3028  Validation loss = 2.3038  \n",
      "\n",
      "Fold: 6  Epoch: 468  Training loss = 2.3026  Validation loss = 2.3033  \n",
      "\n",
      "Fold: 6  Epoch: 469  Training loss = 2.3024  Validation loss = 2.3029  \n",
      "\n",
      "Fold: 6  Epoch: 470  Training loss = 2.3022  Validation loss = 2.3025  \n",
      "\n",
      "Fold: 6  Epoch: 471  Training loss = 2.3019  Validation loss = 2.3020  \n",
      "\n",
      "Fold: 6  Epoch: 472  Training loss = 2.3017  Validation loss = 2.3016  \n",
      "\n",
      "Fold: 6  Epoch: 473  Training loss = 2.3015  Validation loss = 2.3012  \n",
      "\n",
      "Fold: 6  Epoch: 474  Training loss = 2.3012  Validation loss = 2.3007  \n",
      "\n",
      "Fold: 6  Epoch: 475  Training loss = 2.3010  Validation loss = 2.3003  \n",
      "\n",
      "Fold: 6  Epoch: 476  Training loss = 2.3008  Validation loss = 2.2999  \n",
      "\n",
      "Fold: 6  Epoch: 477  Training loss = 2.3005  Validation loss = 2.2994  \n",
      "\n",
      "Fold: 6  Epoch: 478  Training loss = 2.3002  Validation loss = 2.2988  \n",
      "\n",
      "Fold: 6  Epoch: 479  Training loss = 2.3000  Validation loss = 2.2983  \n",
      "\n",
      "Fold: 6  Epoch: 480  Training loss = 2.2996  Validation loss = 2.2976  \n",
      "\n",
      "Fold: 6  Epoch: 481  Training loss = 2.2993  Validation loss = 2.2970  \n",
      "\n",
      "Fold: 6  Epoch: 482  Training loss = 2.2991  Validation loss = 2.2966  \n",
      "\n",
      "Fold: 6  Epoch: 483  Training loss = 2.2989  Validation loss = 2.2962  \n",
      "\n",
      "Fold: 6  Epoch: 484  Training loss = 2.2987  Validation loss = 2.2959  \n",
      "\n",
      "Fold: 6  Epoch: 485  Training loss = 2.2984  Validation loss = 2.2954  \n",
      "\n",
      "Fold: 6  Epoch: 486  Training loss = 2.2982  Validation loss = 2.2948  \n",
      "\n",
      "Fold: 6  Epoch: 487  Training loss = 2.2979  Validation loss = 2.2943  \n",
      "\n",
      "Fold: 6  Epoch: 488  Training loss = 2.2976  Validation loss = 2.2938  \n",
      "\n",
      "Fold: 6  Epoch: 489  Training loss = 2.2974  Validation loss = 2.2934  \n",
      "\n",
      "Fold: 6  Epoch: 490  Training loss = 2.2972  Validation loss = 2.2929  \n",
      "\n",
      "Fold: 6  Epoch: 491  Training loss = 2.2969  Validation loss = 2.2923  \n",
      "\n",
      "Fold: 6  Epoch: 492  Training loss = 2.2966  Validation loss = 2.2918  \n",
      "\n",
      "Fold: 6  Epoch: 493  Training loss = 2.2963  Validation loss = 2.2911  \n",
      "\n",
      "Fold: 6  Epoch: 494  Training loss = 2.2961  Validation loss = 2.2909  \n",
      "\n",
      "Fold: 6  Epoch: 495  Training loss = 2.2959  Validation loss = 2.2904  \n",
      "\n",
      "Fold: 6  Epoch: 496  Training loss = 2.2956  Validation loss = 2.2899  \n",
      "\n",
      "Fold: 6  Epoch: 497  Training loss = 2.2953  Validation loss = 2.2893  \n",
      "\n",
      "Fold: 6  Epoch: 498  Training loss = 2.2950  Validation loss = 2.2887  \n",
      "\n",
      "Fold: 6  Epoch: 499  Training loss = 2.2947  Validation loss = 2.2881  \n",
      "\n",
      "Fold: 6  Epoch: 500  Training loss = 2.2946  Validation loss = 2.2878  \n",
      "\n",
      "Check model:  Fold: 6  Optimal epoch: 500  \n",
      "\n",
      "Fold: 7  Epoch: 1  Training loss = 2.3482  Validation loss = 2.2017  \n",
      "\n",
      "Fold: 7  Epoch: 2  Training loss = 2.3478  Validation loss = 2.2010  \n",
      "\n",
      "Fold: 7  Epoch: 3  Training loss = 2.3474  Validation loss = 2.2003  \n",
      "\n",
      "Fold: 7  Epoch: 4  Training loss = 2.3471  Validation loss = 2.1997  \n",
      "\n",
      "Fold: 7  Epoch: 5  Training loss = 2.3469  Validation loss = 2.1993  \n",
      "\n",
      "Fold: 7  Epoch: 6  Training loss = 2.3466  Validation loss = 2.1986  \n",
      "\n",
      "Fold: 7  Epoch: 7  Training loss = 2.3462  Validation loss = 2.1980  \n",
      "\n",
      "Fold: 7  Epoch: 8  Training loss = 2.3460  Validation loss = 2.1975  \n",
      "\n",
      "Fold: 7  Epoch: 9  Training loss = 2.3457  Validation loss = 2.1968  \n",
      "\n",
      "Fold: 7  Epoch: 10  Training loss = 2.3453  Validation loss = 2.1961  \n",
      "\n",
      "Fold: 7  Epoch: 11  Training loss = 2.3450  Validation loss = 2.1956  \n",
      "\n",
      "Fold: 7  Epoch: 12  Training loss = 2.3447  Validation loss = 2.1949  \n",
      "\n",
      "Fold: 7  Epoch: 13  Training loss = 2.3444  Validation loss = 2.1944  \n",
      "\n",
      "Fold: 7  Epoch: 14  Training loss = 2.3441  Validation loss = 2.1937  \n",
      "\n",
      "Fold: 7  Epoch: 15  Training loss = 2.3439  Validation loss = 2.1933  \n",
      "\n",
      "Fold: 7  Epoch: 16  Training loss = 2.3436  Validation loss = 2.1928  \n",
      "\n",
      "Fold: 7  Epoch: 17  Training loss = 2.3433  Validation loss = 2.1922  \n",
      "\n",
      "Fold: 7  Epoch: 18  Training loss = 2.3430  Validation loss = 2.1915  \n",
      "\n",
      "Fold: 7  Epoch: 19  Training loss = 2.3426  Validation loss = 2.1908  \n",
      "\n",
      "Fold: 7  Epoch: 20  Training loss = 2.3423  Validation loss = 2.1902  \n",
      "\n",
      "Fold: 7  Epoch: 21  Training loss = 2.3420  Validation loss = 2.1896  \n",
      "\n",
      "Fold: 7  Epoch: 22  Training loss = 2.3417  Validation loss = 2.1890  \n",
      "\n",
      "Fold: 7  Epoch: 23  Training loss = 2.3413  Validation loss = 2.1881  \n",
      "\n",
      "Fold: 7  Epoch: 24  Training loss = 2.3410  Validation loss = 2.1874  \n",
      "\n",
      "Fold: 7  Epoch: 25  Training loss = 2.3406  Validation loss = 2.1868  \n",
      "\n",
      "Fold: 7  Epoch: 26  Training loss = 2.3404  Validation loss = 2.1863  \n",
      "\n",
      "Fold: 7  Epoch: 27  Training loss = 2.3400  Validation loss = 2.1855  \n",
      "\n",
      "Fold: 7  Epoch: 28  Training loss = 2.3397  Validation loss = 2.1849  \n",
      "\n",
      "Fold: 7  Epoch: 29  Training loss = 2.3394  Validation loss = 2.1843  \n",
      "\n",
      "Fold: 7  Epoch: 30  Training loss = 2.3391  Validation loss = 2.1837  \n",
      "\n",
      "Fold: 7  Epoch: 31  Training loss = 2.3388  Validation loss = 2.1831  \n",
      "\n",
      "Fold: 7  Epoch: 32  Training loss = 2.3385  Validation loss = 2.1825  \n",
      "\n",
      "Fold: 7  Epoch: 33  Training loss = 2.3381  Validation loss = 2.1818  \n",
      "\n",
      "Fold: 7  Epoch: 34  Training loss = 2.3378  Validation loss = 2.1812  \n",
      "\n",
      "Fold: 7  Epoch: 35  Training loss = 2.3375  Validation loss = 2.1805  \n",
      "\n",
      "Fold: 7  Epoch: 36  Training loss = 2.3372  Validation loss = 2.1799  \n",
      "\n",
      "Fold: 7  Epoch: 37  Training loss = 2.3368  Validation loss = 2.1790  \n",
      "\n",
      "Fold: 7  Epoch: 38  Training loss = 2.3365  Validation loss = 2.1784  \n",
      "\n",
      "Fold: 7  Epoch: 39  Training loss = 2.3362  Validation loss = 2.1778  \n",
      "\n",
      "Fold: 7  Epoch: 40  Training loss = 2.3359  Validation loss = 2.1772  \n",
      "\n",
      "Fold: 7  Epoch: 41  Training loss = 2.3355  Validation loss = 2.1765  \n",
      "\n",
      "Fold: 7  Epoch: 42  Training loss = 2.3352  Validation loss = 2.1759  \n",
      "\n",
      "Fold: 7  Epoch: 43  Training loss = 2.3349  Validation loss = 2.1753  \n",
      "\n",
      "Fold: 7  Epoch: 44  Training loss = 2.3346  Validation loss = 2.1746  \n",
      "\n",
      "Fold: 7  Epoch: 45  Training loss = 2.3342  Validation loss = 2.1739  \n",
      "\n",
      "Fold: 7  Epoch: 46  Training loss = 2.3339  Validation loss = 2.1733  \n",
      "\n",
      "Fold: 7  Epoch: 47  Training loss = 2.3336  Validation loss = 2.1726  \n",
      "\n",
      "Fold: 7  Epoch: 48  Training loss = 2.3332  Validation loss = 2.1719  \n",
      "\n",
      "Fold: 7  Epoch: 49  Training loss = 2.3329  Validation loss = 2.1714  \n",
      "\n",
      "Fold: 7  Epoch: 50  Training loss = 2.3326  Validation loss = 2.1707  \n",
      "\n",
      "Fold: 7  Epoch: 51  Training loss = 2.3323  Validation loss = 2.1701  \n",
      "\n",
      "Fold: 7  Epoch: 52  Training loss = 2.3320  Validation loss = 2.1695  \n",
      "\n",
      "Fold: 7  Epoch: 53  Training loss = 2.3316  Validation loss = 2.1686  \n",
      "\n",
      "Fold: 7  Epoch: 54  Training loss = 2.3313  Validation loss = 2.1679  \n",
      "\n",
      "Fold: 7  Epoch: 55  Training loss = 2.3310  Validation loss = 2.1674  \n",
      "\n",
      "Fold: 7  Epoch: 56  Training loss = 2.3307  Validation loss = 2.1669  \n",
      "\n",
      "Fold: 7  Epoch: 57  Training loss = 2.3303  Validation loss = 2.1662  \n",
      "\n",
      "Fold: 7  Epoch: 58  Training loss = 2.3300  Validation loss = 2.1655  \n",
      "\n",
      "Fold: 7  Epoch: 59  Training loss = 2.3297  Validation loss = 2.1647  \n",
      "\n",
      "Fold: 7  Epoch: 60  Training loss = 2.3294  Validation loss = 2.1642  \n",
      "\n",
      "Fold: 7  Epoch: 61  Training loss = 2.3291  Validation loss = 2.1636  \n",
      "\n",
      "Fold: 7  Epoch: 62  Training loss = 2.3288  Validation loss = 2.1631  \n",
      "\n",
      "Fold: 7  Epoch: 63  Training loss = 2.3286  Validation loss = 2.1626  \n",
      "\n",
      "Fold: 7  Epoch: 64  Training loss = 2.3282  Validation loss = 2.1619  \n",
      "\n",
      "Fold: 7  Epoch: 65  Training loss = 2.3280  Validation loss = 2.1613  \n",
      "\n",
      "Fold: 7  Epoch: 66  Training loss = 2.3278  Validation loss = 2.1609  \n",
      "\n",
      "Fold: 7  Epoch: 67  Training loss = 2.3274  Validation loss = 2.1600  \n",
      "\n",
      "Fold: 7  Epoch: 68  Training loss = 2.3270  Validation loss = 2.1594  \n",
      "\n",
      "Fold: 7  Epoch: 69  Training loss = 2.3268  Validation loss = 2.1588  \n",
      "\n",
      "Fold: 7  Epoch: 70  Training loss = 2.3264  Validation loss = 2.1582  \n",
      "\n",
      "Fold: 7  Epoch: 71  Training loss = 2.3261  Validation loss = 2.1574  \n",
      "\n",
      "Fold: 7  Epoch: 72  Training loss = 2.3258  Validation loss = 2.1568  \n",
      "\n",
      "Fold: 7  Epoch: 73  Training loss = 2.3255  Validation loss = 2.1561  \n",
      "\n",
      "Fold: 7  Epoch: 74  Training loss = 2.3252  Validation loss = 2.1556  \n",
      "\n",
      "Fold: 7  Epoch: 75  Training loss = 2.3249  Validation loss = 2.1550  \n",
      "\n",
      "Fold: 7  Epoch: 76  Training loss = 2.3246  Validation loss = 2.1544  \n",
      "\n",
      "Fold: 7  Epoch: 77  Training loss = 2.3242  Validation loss = 2.1537  \n",
      "\n",
      "Fold: 7  Epoch: 78  Training loss = 2.3239  Validation loss = 2.1531  \n",
      "\n",
      "Fold: 7  Epoch: 79  Training loss = 2.3237  Validation loss = 2.1526  \n",
      "\n",
      "Fold: 7  Epoch: 80  Training loss = 2.3235  Validation loss = 2.1521  \n",
      "\n",
      "Fold: 7  Epoch: 81  Training loss = 2.3232  Validation loss = 2.1515  \n",
      "\n",
      "Fold: 7  Epoch: 82  Training loss = 2.3229  Validation loss = 2.1508  \n",
      "\n",
      "Fold: 7  Epoch: 83  Training loss = 2.3225  Validation loss = 2.1501  \n",
      "\n",
      "Fold: 7  Epoch: 84  Training loss = 2.3222  Validation loss = 2.1495  \n",
      "\n",
      "Fold: 7  Epoch: 85  Training loss = 2.3219  Validation loss = 2.1489  \n",
      "\n",
      "Fold: 7  Epoch: 86  Training loss = 2.3217  Validation loss = 2.1484  \n",
      "\n",
      "Fold: 7  Epoch: 87  Training loss = 2.3213  Validation loss = 2.1477  \n",
      "\n",
      "Fold: 7  Epoch: 88  Training loss = 2.3210  Validation loss = 2.1469  \n",
      "\n",
      "Fold: 7  Epoch: 89  Training loss = 2.3206  Validation loss = 2.1462  \n",
      "\n",
      "Fold: 7  Epoch: 90  Training loss = 2.3203  Validation loss = 2.1457  \n",
      "\n",
      "Fold: 7  Epoch: 91  Training loss = 2.3201  Validation loss = 2.1452  \n",
      "\n",
      "Fold: 7  Epoch: 92  Training loss = 2.3198  Validation loss = 2.1447  \n",
      "\n",
      "Fold: 7  Epoch: 93  Training loss = 2.3195  Validation loss = 2.1441  \n",
      "\n",
      "Fold: 7  Epoch: 94  Training loss = 2.3192  Validation loss = 2.1433  \n",
      "\n",
      "Fold: 7  Epoch: 95  Training loss = 2.3189  Validation loss = 2.1428  \n",
      "\n",
      "Fold: 7  Epoch: 96  Training loss = 2.3186  Validation loss = 2.1420  \n",
      "\n",
      "Fold: 7  Epoch: 97  Training loss = 2.3181  Validation loss = 2.1411  \n",
      "\n",
      "Fold: 7  Epoch: 98  Training loss = 2.3178  Validation loss = 2.1405  \n",
      "\n",
      "Fold: 7  Epoch: 99  Training loss = 2.3175  Validation loss = 2.1398  \n",
      "\n",
      "Fold: 7  Epoch: 100  Training loss = 2.3172  Validation loss = 2.1392  \n",
      "\n",
      "Fold: 7  Epoch: 101  Training loss = 2.3168  Validation loss = 2.1385  \n",
      "\n",
      "Fold: 7  Epoch: 102  Training loss = 2.3166  Validation loss = 2.1380  \n",
      "\n",
      "Fold: 7  Epoch: 103  Training loss = 2.3163  Validation loss = 2.1375  \n",
      "\n",
      "Fold: 7  Epoch: 104  Training loss = 2.3159  Validation loss = 2.1368  \n",
      "\n",
      "Fold: 7  Epoch: 105  Training loss = 2.3155  Validation loss = 2.1360  \n",
      "\n",
      "Fold: 7  Epoch: 106  Training loss = 2.3152  Validation loss = 2.1354  \n",
      "\n",
      "Fold: 7  Epoch: 107  Training loss = 2.3149  Validation loss = 2.1348  \n",
      "\n",
      "Fold: 7  Epoch: 108  Training loss = 2.3147  Validation loss = 2.1343  \n",
      "\n",
      "Fold: 7  Epoch: 109  Training loss = 2.3144  Validation loss = 2.1338  \n",
      "\n",
      "Fold: 7  Epoch: 110  Training loss = 2.3141  Validation loss = 2.1333  \n",
      "\n",
      "Fold: 7  Epoch: 111  Training loss = 2.3138  Validation loss = 2.1327  \n",
      "\n",
      "Fold: 7  Epoch: 112  Training loss = 2.3135  Validation loss = 2.1321  \n",
      "\n",
      "Fold: 7  Epoch: 113  Training loss = 2.3132  Validation loss = 2.1315  \n",
      "\n",
      "Fold: 7  Epoch: 114  Training loss = 2.3129  Validation loss = 2.1309  \n",
      "\n",
      "Fold: 7  Epoch: 115  Training loss = 2.3126  Validation loss = 2.1304  \n",
      "\n",
      "Fold: 7  Epoch: 116  Training loss = 2.3123  Validation loss = 2.1297  \n",
      "\n",
      "Fold: 7  Epoch: 117  Training loss = 2.3120  Validation loss = 2.1291  \n",
      "\n",
      "Fold: 7  Epoch: 118  Training loss = 2.3117  Validation loss = 2.1284  \n",
      "\n",
      "Fold: 7  Epoch: 119  Training loss = 2.3113  Validation loss = 2.1277  \n",
      "\n",
      "Fold: 7  Epoch: 120  Training loss = 2.3109  Validation loss = 2.1270  \n",
      "\n",
      "Fold: 7  Epoch: 121  Training loss = 2.3106  Validation loss = 2.1264  \n",
      "\n",
      "Fold: 7  Epoch: 122  Training loss = 2.3103  Validation loss = 2.1256  \n",
      "\n",
      "Fold: 7  Epoch: 123  Training loss = 2.3099  Validation loss = 2.1249  \n",
      "\n",
      "Fold: 7  Epoch: 124  Training loss = 2.3096  Validation loss = 2.1244  \n",
      "\n",
      "Fold: 7  Epoch: 125  Training loss = 2.3094  Validation loss = 2.1240  \n",
      "\n",
      "Fold: 7  Epoch: 126  Training loss = 2.3091  Validation loss = 2.1235  \n",
      "\n",
      "Fold: 7  Epoch: 127  Training loss = 2.3088  Validation loss = 2.1229  \n",
      "\n",
      "Fold: 7  Epoch: 128  Training loss = 2.3086  Validation loss = 2.1224  \n",
      "\n",
      "Fold: 7  Epoch: 129  Training loss = 2.3083  Validation loss = 2.1219  \n",
      "\n",
      "Fold: 7  Epoch: 130  Training loss = 2.3080  Validation loss = 2.1214  \n",
      "\n",
      "Fold: 7  Epoch: 131  Training loss = 2.3077  Validation loss = 2.1207  \n",
      "\n",
      "Fold: 7  Epoch: 132  Training loss = 2.3074  Validation loss = 2.1202  \n",
      "\n",
      "Fold: 7  Epoch: 133  Training loss = 2.3071  Validation loss = 2.1195  \n",
      "\n",
      "Fold: 7  Epoch: 134  Training loss = 2.3069  Validation loss = 2.1190  \n",
      "\n",
      "Fold: 7  Epoch: 135  Training loss = 2.3066  Validation loss = 2.1185  \n",
      "\n",
      "Fold: 7  Epoch: 136  Training loss = 2.3063  Validation loss = 2.1179  \n",
      "\n",
      "Fold: 7  Epoch: 137  Training loss = 2.3061  Validation loss = 2.1174  \n",
      "\n",
      "Fold: 7  Epoch: 138  Training loss = 2.3057  Validation loss = 2.1168  \n",
      "\n",
      "Fold: 7  Epoch: 139  Training loss = 2.3055  Validation loss = 2.1162  \n",
      "\n",
      "Fold: 7  Epoch: 140  Training loss = 2.3052  Validation loss = 2.1156  \n",
      "\n",
      "Fold: 7  Epoch: 141  Training loss = 2.3047  Validation loss = 2.1147  \n",
      "\n",
      "Fold: 7  Epoch: 142  Training loss = 2.3044  Validation loss = 2.1140  \n",
      "\n",
      "Fold: 7  Epoch: 143  Training loss = 2.3040  Validation loss = 2.1132  \n",
      "\n",
      "Fold: 7  Epoch: 144  Training loss = 2.3037  Validation loss = 2.1124  \n",
      "\n",
      "Fold: 7  Epoch: 145  Training loss = 2.3033  Validation loss = 2.1117  \n",
      "\n",
      "Fold: 7  Epoch: 146  Training loss = 2.3031  Validation loss = 2.1112  \n",
      "\n",
      "Fold: 7  Epoch: 147  Training loss = 2.3027  Validation loss = 2.1104  \n",
      "\n",
      "Fold: 7  Epoch: 148  Training loss = 2.3024  Validation loss = 2.1099  \n",
      "\n",
      "Fold: 7  Epoch: 149  Training loss = 2.3020  Validation loss = 2.1091  \n",
      "\n",
      "Fold: 7  Epoch: 150  Training loss = 2.3018  Validation loss = 2.1086  \n",
      "\n",
      "Fold: 7  Epoch: 151  Training loss = 2.3015  Validation loss = 2.1079  \n",
      "\n",
      "Fold: 7  Epoch: 152  Training loss = 2.3012  Validation loss = 2.1074  \n",
      "\n",
      "Fold: 7  Epoch: 153  Training loss = 2.3008  Validation loss = 2.1066  \n",
      "\n",
      "Fold: 7  Epoch: 154  Training loss = 2.3005  Validation loss = 2.1059  \n",
      "\n",
      "Fold: 7  Epoch: 155  Training loss = 2.3001  Validation loss = 2.1052  \n",
      "\n",
      "Fold: 7  Epoch: 156  Training loss = 2.2998  Validation loss = 2.1044  \n",
      "\n",
      "Fold: 7  Epoch: 157  Training loss = 2.2994  Validation loss = 2.1037  \n",
      "\n",
      "Fold: 7  Epoch: 158  Training loss = 2.2991  Validation loss = 2.1031  \n",
      "\n",
      "Fold: 7  Epoch: 159  Training loss = 2.2989  Validation loss = 2.1027  \n",
      "\n",
      "Fold: 7  Epoch: 160  Training loss = 2.2986  Validation loss = 2.1021  \n",
      "\n",
      "Fold: 7  Epoch: 161  Training loss = 2.2982  Validation loss = 2.1013  \n",
      "\n",
      "Fold: 7  Epoch: 162  Training loss = 2.2979  Validation loss = 2.1007  \n",
      "\n",
      "Fold: 7  Epoch: 163  Training loss = 2.2976  Validation loss = 2.1002  \n",
      "\n",
      "Fold: 7  Epoch: 164  Training loss = 2.2973  Validation loss = 2.0996  \n",
      "\n",
      "Fold: 7  Epoch: 165  Training loss = 2.2971  Validation loss = 2.0990  \n",
      "\n",
      "Fold: 7  Epoch: 166  Training loss = 2.2967  Validation loss = 2.0984  \n",
      "\n",
      "Fold: 7  Epoch: 167  Training loss = 2.2964  Validation loss = 2.0978  \n",
      "\n",
      "Fold: 7  Epoch: 168  Training loss = 2.2960  Validation loss = 2.0968  \n",
      "\n",
      "Fold: 7  Epoch: 169  Training loss = 2.2956  Validation loss = 2.0961  \n",
      "\n",
      "Fold: 7  Epoch: 170  Training loss = 2.2954  Validation loss = 2.0956  \n",
      "\n",
      "Fold: 7  Epoch: 171  Training loss = 2.2950  Validation loss = 2.0949  \n",
      "\n",
      "Fold: 7  Epoch: 172  Training loss = 2.2947  Validation loss = 2.0943  \n",
      "\n",
      "Fold: 7  Epoch: 173  Training loss = 2.2944  Validation loss = 2.0937  \n",
      "\n",
      "Fold: 7  Epoch: 174  Training loss = 2.2941  Validation loss = 2.0930  \n",
      "\n",
      "Fold: 7  Epoch: 175  Training loss = 2.2938  Validation loss = 2.0923  \n",
      "\n",
      "Fold: 7  Epoch: 176  Training loss = 2.2934  Validation loss = 2.0916  \n",
      "\n",
      "Fold: 7  Epoch: 177  Training loss = 2.2931  Validation loss = 2.0910  \n",
      "\n",
      "Fold: 7  Epoch: 178  Training loss = 2.2928  Validation loss = 2.0904  \n",
      "\n",
      "Fold: 7  Epoch: 179  Training loss = 2.2924  Validation loss = 2.0896  \n",
      "\n",
      "Fold: 7  Epoch: 180  Training loss = 2.2921  Validation loss = 2.0890  \n",
      "\n",
      "Fold: 7  Epoch: 181  Training loss = 2.2918  Validation loss = 2.0883  \n",
      "\n",
      "Fold: 7  Epoch: 182  Training loss = 2.2914  Validation loss = 2.0876  \n",
      "\n",
      "Fold: 7  Epoch: 183  Training loss = 2.2911  Validation loss = 2.0869  \n",
      "\n",
      "Fold: 7  Epoch: 184  Training loss = 2.2908  Validation loss = 2.0863  \n",
      "\n",
      "Fold: 7  Epoch: 185  Training loss = 2.2906  Validation loss = 2.0858  \n",
      "\n",
      "Fold: 7  Epoch: 186  Training loss = 2.2903  Validation loss = 2.0852  \n",
      "\n",
      "Fold: 7  Epoch: 187  Training loss = 2.2899  Validation loss = 2.0845  \n",
      "\n",
      "Fold: 7  Epoch: 188  Training loss = 2.2896  Validation loss = 2.0838  \n",
      "\n",
      "Fold: 7  Epoch: 189  Training loss = 2.2893  Validation loss = 2.0833  \n",
      "\n",
      "Fold: 7  Epoch: 190  Training loss = 2.2891  Validation loss = 2.0827  \n",
      "\n",
      "Fold: 7  Epoch: 191  Training loss = 2.2888  Validation loss = 2.0821  \n",
      "\n",
      "Fold: 7  Epoch: 192  Training loss = 2.2884  Validation loss = 2.0815  \n",
      "\n",
      "Fold: 7  Epoch: 193  Training loss = 2.2881  Validation loss = 2.0807  \n",
      "\n",
      "Fold: 7  Epoch: 194  Training loss = 2.2878  Validation loss = 2.0801  \n",
      "\n",
      "Fold: 7  Epoch: 195  Training loss = 2.2876  Validation loss = 2.0797  \n",
      "\n",
      "Fold: 7  Epoch: 196  Training loss = 2.2873  Validation loss = 2.0793  \n",
      "\n",
      "Fold: 7  Epoch: 197  Training loss = 2.2871  Validation loss = 2.0787  \n",
      "\n",
      "Fold: 7  Epoch: 198  Training loss = 2.2868  Validation loss = 2.0782  \n",
      "\n",
      "Fold: 7  Epoch: 199  Training loss = 2.2865  Validation loss = 2.0776  \n",
      "\n",
      "Fold: 7  Epoch: 200  Training loss = 2.2862  Validation loss = 2.0770  \n",
      "\n",
      "Fold: 7  Epoch: 201  Training loss = 2.2859  Validation loss = 2.0764  \n",
      "\n",
      "Fold: 7  Epoch: 202  Training loss = 2.2856  Validation loss = 2.0758  \n",
      "\n",
      "Fold: 7  Epoch: 203  Training loss = 2.2853  Validation loss = 2.0752  \n",
      "\n",
      "Fold: 7  Epoch: 204  Training loss = 2.2850  Validation loss = 2.0746  \n",
      "\n",
      "Fold: 7  Epoch: 205  Training loss = 2.2848  Validation loss = 2.0741  \n",
      "\n",
      "Fold: 7  Epoch: 206  Training loss = 2.2845  Validation loss = 2.0736  \n",
      "\n",
      "Fold: 7  Epoch: 207  Training loss = 2.2843  Validation loss = 2.0731  \n",
      "\n",
      "Fold: 7  Epoch: 208  Training loss = 2.2839  Validation loss = 2.0724  \n",
      "\n",
      "Fold: 7  Epoch: 209  Training loss = 2.2836  Validation loss = 2.0717  \n",
      "\n",
      "Fold: 7  Epoch: 210  Training loss = 2.2833  Validation loss = 2.0712  \n",
      "\n",
      "Fold: 7  Epoch: 211  Training loss = 2.2830  Validation loss = 2.0705  \n",
      "\n",
      "Fold: 7  Epoch: 212  Training loss = 2.2828  Validation loss = 2.0700  \n",
      "\n",
      "Fold: 7  Epoch: 213  Training loss = 2.2825  Validation loss = 2.0694  \n",
      "\n",
      "Fold: 7  Epoch: 214  Training loss = 2.2822  Validation loss = 2.0689  \n",
      "\n",
      "Fold: 7  Epoch: 215  Training loss = 2.2819  Validation loss = 2.0683  \n",
      "\n",
      "Fold: 7  Epoch: 216  Training loss = 2.2815  Validation loss = 2.0676  \n",
      "\n",
      "Fold: 7  Epoch: 217  Training loss = 2.2813  Validation loss = 2.0671  \n",
      "\n",
      "Fold: 7  Epoch: 218  Training loss = 2.2811  Validation loss = 2.0666  \n",
      "\n",
      "Fold: 7  Epoch: 219  Training loss = 2.2808  Validation loss = 2.0660  \n",
      "\n",
      "Fold: 7  Epoch: 220  Training loss = 2.2804  Validation loss = 2.0654  \n",
      "\n",
      "Fold: 7  Epoch: 221  Training loss = 2.2801  Validation loss = 2.0647  \n",
      "\n",
      "Fold: 7  Epoch: 222  Training loss = 2.2798  Validation loss = 2.0641  \n",
      "\n",
      "Fold: 7  Epoch: 223  Training loss = 2.2795  Validation loss = 2.0635  \n",
      "\n",
      "Fold: 7  Epoch: 224  Training loss = 2.2793  Validation loss = 2.0631  \n",
      "\n",
      "Fold: 7  Epoch: 225  Training loss = 2.2789  Validation loss = 2.0623  \n",
      "\n",
      "Fold: 7  Epoch: 226  Training loss = 2.2787  Validation loss = 2.0618  \n",
      "\n",
      "Fold: 7  Epoch: 227  Training loss = 2.2784  Validation loss = 2.0612  \n",
      "\n",
      "Fold: 7  Epoch: 228  Training loss = 2.2781  Validation loss = 2.0606  \n",
      "\n",
      "Fold: 7  Epoch: 229  Training loss = 2.2778  Validation loss = 2.0601  \n",
      "\n",
      "Fold: 7  Epoch: 230  Training loss = 2.2775  Validation loss = 2.0595  \n",
      "\n",
      "Fold: 7  Epoch: 231  Training loss = 2.2772  Validation loss = 2.0589  \n",
      "\n",
      "Fold: 7  Epoch: 232  Training loss = 2.2770  Validation loss = 2.0586  \n",
      "\n",
      "Fold: 7  Epoch: 233  Training loss = 2.2768  Validation loss = 2.0581  \n",
      "\n",
      "Fold: 7  Epoch: 234  Training loss = 2.2766  Validation loss = 2.0577  \n",
      "\n",
      "Fold: 7  Epoch: 235  Training loss = 2.2762  Validation loss = 2.0568  \n",
      "\n",
      "Fold: 7  Epoch: 236  Training loss = 2.2759  Validation loss = 2.0563  \n",
      "\n",
      "Fold: 7  Epoch: 237  Training loss = 2.2756  Validation loss = 2.0557  \n",
      "\n",
      "Fold: 7  Epoch: 238  Training loss = 2.2753  Validation loss = 2.0549  \n",
      "\n",
      "Fold: 7  Epoch: 239  Training loss = 2.2750  Validation loss = 2.0543  \n",
      "\n",
      "Fold: 7  Epoch: 240  Training loss = 2.2748  Validation loss = 2.0539  \n",
      "\n",
      "Fold: 7  Epoch: 241  Training loss = 2.2744  Validation loss = 2.0532  \n",
      "\n",
      "Fold: 7  Epoch: 242  Training loss = 2.2741  Validation loss = 2.0526  \n",
      "\n",
      "Fold: 7  Epoch: 243  Training loss = 2.2738  Validation loss = 2.0519  \n",
      "\n",
      "Fold: 7  Epoch: 244  Training loss = 2.2735  Validation loss = 2.0514  \n",
      "\n",
      "Fold: 7  Epoch: 245  Training loss = 2.2732  Validation loss = 2.0507  \n",
      "\n",
      "Fold: 7  Epoch: 246  Training loss = 2.2729  Validation loss = 2.0501  \n",
      "\n",
      "Fold: 7  Epoch: 247  Training loss = 2.2726  Validation loss = 2.0497  \n",
      "\n",
      "Fold: 7  Epoch: 248  Training loss = 2.2724  Validation loss = 2.0492  \n",
      "\n",
      "Fold: 7  Epoch: 249  Training loss = 2.2721  Validation loss = 2.0487  \n",
      "\n",
      "Fold: 7  Epoch: 250  Training loss = 2.2718  Validation loss = 2.0480  \n",
      "\n",
      "Fold: 7  Epoch: 251  Training loss = 2.2716  Validation loss = 2.0476  \n",
      "\n",
      "Fold: 7  Epoch: 252  Training loss = 2.2714  Validation loss = 2.0472  \n",
      "\n",
      "Fold: 7  Epoch: 253  Training loss = 2.2712  Validation loss = 2.0468  \n",
      "\n",
      "Fold: 7  Epoch: 254  Training loss = 2.2710  Validation loss = 2.0464  \n",
      "\n",
      "Fold: 7  Epoch: 255  Training loss = 2.2707  Validation loss = 2.0457  \n",
      "\n",
      "Fold: 7  Epoch: 256  Training loss = 2.2704  Validation loss = 2.0453  \n",
      "\n",
      "Fold: 7  Epoch: 257  Training loss = 2.2702  Validation loss = 2.0448  \n",
      "\n",
      "Fold: 7  Epoch: 258  Training loss = 2.2699  Validation loss = 2.0443  \n",
      "\n",
      "Fold: 7  Epoch: 259  Training loss = 2.2696  Validation loss = 2.0435  \n",
      "\n",
      "Fold: 7  Epoch: 260  Training loss = 2.2693  Validation loss = 2.0429  \n",
      "\n",
      "Fold: 7  Epoch: 261  Training loss = 2.2690  Validation loss = 2.0423  \n",
      "\n",
      "Fold: 7  Epoch: 262  Training loss = 2.2687  Validation loss = 2.0416  \n",
      "\n",
      "Fold: 7  Epoch: 263  Training loss = 2.2684  Validation loss = 2.0409  \n",
      "\n",
      "Fold: 7  Epoch: 264  Training loss = 2.2680  Validation loss = 2.0401  \n",
      "\n",
      "Fold: 7  Epoch: 265  Training loss = 2.2677  Validation loss = 2.0395  \n",
      "\n",
      "Fold: 7  Epoch: 266  Training loss = 2.2674  Validation loss = 2.0391  \n",
      "\n",
      "Fold: 7  Epoch: 267  Training loss = 2.2673  Validation loss = 2.0387  \n",
      "\n",
      "Fold: 7  Epoch: 268  Training loss = 2.2670  Validation loss = 2.0382  \n",
      "\n",
      "Fold: 7  Epoch: 269  Training loss = 2.2667  Validation loss = 2.0375  \n",
      "\n",
      "Fold: 7  Epoch: 270  Training loss = 2.2663  Validation loss = 2.0367  \n",
      "\n",
      "Fold: 7  Epoch: 271  Training loss = 2.2661  Validation loss = 2.0363  \n",
      "\n",
      "Fold: 7  Epoch: 272  Training loss = 2.2658  Validation loss = 2.0357  \n",
      "\n",
      "Fold: 7  Epoch: 273  Training loss = 2.2655  Validation loss = 2.0350  \n",
      "\n",
      "Fold: 7  Epoch: 274  Training loss = 2.2652  Validation loss = 2.0344  \n",
      "\n",
      "Fold: 7  Epoch: 275  Training loss = 2.2649  Validation loss = 2.0338  \n",
      "\n",
      "Fold: 7  Epoch: 276  Training loss = 2.2646  Validation loss = 2.0332  \n",
      "\n",
      "Fold: 7  Epoch: 277  Training loss = 2.2644  Validation loss = 2.0327  \n",
      "\n",
      "Fold: 7  Epoch: 278  Training loss = 2.2640  Validation loss = 2.0321  \n",
      "\n",
      "Fold: 7  Epoch: 279  Training loss = 2.2637  Validation loss = 2.0314  \n",
      "\n",
      "Fold: 7  Epoch: 280  Training loss = 2.2635  Validation loss = 2.0309  \n",
      "\n",
      "Fold: 7  Epoch: 281  Training loss = 2.2632  Validation loss = 2.0304  \n",
      "\n",
      "Fold: 7  Epoch: 282  Training loss = 2.2629  Validation loss = 2.0298  \n",
      "\n",
      "Fold: 7  Epoch: 283  Training loss = 2.2626  Validation loss = 2.0292  \n",
      "\n",
      "Fold: 7  Epoch: 284  Training loss = 2.2623  Validation loss = 2.0286  \n",
      "\n",
      "Fold: 7  Epoch: 285  Training loss = 2.2620  Validation loss = 2.0278  \n",
      "\n",
      "Fold: 7  Epoch: 286  Training loss = 2.2618  Validation loss = 2.0275  \n",
      "\n",
      "Fold: 7  Epoch: 287  Training loss = 2.2615  Validation loss = 2.0268  \n",
      "\n",
      "Fold: 7  Epoch: 288  Training loss = 2.2611  Validation loss = 2.0261  \n",
      "\n",
      "Fold: 7  Epoch: 289  Training loss = 2.2609  Validation loss = 2.0257  \n",
      "\n",
      "Fold: 7  Epoch: 290  Training loss = 2.2607  Validation loss = 2.0253  \n",
      "\n",
      "Fold: 7  Epoch: 291  Training loss = 2.2604  Validation loss = 2.0247  \n",
      "\n",
      "Fold: 7  Epoch: 292  Training loss = 2.2602  Validation loss = 2.0242  \n",
      "\n",
      "Fold: 7  Epoch: 293  Training loss = 2.2599  Validation loss = 2.0236  \n",
      "\n",
      "Fold: 7  Epoch: 294  Training loss = 2.2596  Validation loss = 2.0230  \n",
      "\n",
      "Fold: 7  Epoch: 295  Training loss = 2.2593  Validation loss = 2.0224  \n",
      "\n",
      "Fold: 7  Epoch: 296  Training loss = 2.2590  Validation loss = 2.0218  \n",
      "\n",
      "Fold: 7  Epoch: 297  Training loss = 2.2587  Validation loss = 2.0212  \n",
      "\n",
      "Fold: 7  Epoch: 298  Training loss = 2.2584  Validation loss = 2.0206  \n",
      "\n",
      "Fold: 7  Epoch: 299  Training loss = 2.2581  Validation loss = 2.0200  \n",
      "\n",
      "Fold: 7  Epoch: 300  Training loss = 2.2578  Validation loss = 2.0194  \n",
      "\n",
      "Fold: 7  Epoch: 301  Training loss = 2.2576  Validation loss = 2.0188  \n",
      "\n",
      "Fold: 7  Epoch: 302  Training loss = 2.2572  Validation loss = 2.0181  \n",
      "\n",
      "Fold: 7  Epoch: 303  Training loss = 2.2570  Validation loss = 2.0178  \n",
      "\n",
      "Fold: 7  Epoch: 304  Training loss = 2.2568  Validation loss = 2.0172  \n",
      "\n",
      "Fold: 7  Epoch: 305  Training loss = 2.2565  Validation loss = 2.0166  \n",
      "\n",
      "Fold: 7  Epoch: 306  Training loss = 2.2562  Validation loss = 2.0160  \n",
      "\n",
      "Fold: 7  Epoch: 307  Training loss = 2.2559  Validation loss = 2.0154  \n",
      "\n",
      "Fold: 7  Epoch: 308  Training loss = 2.2556  Validation loss = 2.0149  \n",
      "\n",
      "Fold: 7  Epoch: 309  Training loss = 2.2553  Validation loss = 2.0143  \n",
      "\n",
      "Fold: 7  Epoch: 310  Training loss = 2.2551  Validation loss = 2.0137  \n",
      "\n",
      "Fold: 7  Epoch: 311  Training loss = 2.2548  Validation loss = 2.0132  \n",
      "\n",
      "Fold: 7  Epoch: 312  Training loss = 2.2545  Validation loss = 2.0125  \n",
      "\n",
      "Fold: 7  Epoch: 313  Training loss = 2.2542  Validation loss = 2.0120  \n",
      "\n",
      "Fold: 7  Epoch: 314  Training loss = 2.2539  Validation loss = 2.0114  \n",
      "\n",
      "Fold: 7  Epoch: 315  Training loss = 2.2537  Validation loss = 2.0109  \n",
      "\n",
      "Fold: 7  Epoch: 316  Training loss = 2.2535  Validation loss = 2.0105  \n",
      "\n",
      "Fold: 7  Epoch: 317  Training loss = 2.2532  Validation loss = 2.0099  \n",
      "\n",
      "Fold: 7  Epoch: 318  Training loss = 2.2529  Validation loss = 2.0094  \n",
      "\n",
      "Fold: 7  Epoch: 319  Training loss = 2.2527  Validation loss = 2.0089  \n",
      "\n",
      "Fold: 7  Epoch: 320  Training loss = 2.2524  Validation loss = 2.0083  \n",
      "\n",
      "Fold: 7  Epoch: 321  Training loss = 2.2521  Validation loss = 2.0078  \n",
      "\n",
      "Fold: 7  Epoch: 322  Training loss = 2.2518  Validation loss = 2.0071  \n",
      "\n",
      "Fold: 7  Epoch: 323  Training loss = 2.2515  Validation loss = 2.0066  \n",
      "\n",
      "Fold: 7  Epoch: 324  Training loss = 2.2512  Validation loss = 2.0059  \n",
      "\n",
      "Fold: 7  Epoch: 325  Training loss = 2.2509  Validation loss = 2.0054  \n",
      "\n",
      "Fold: 7  Epoch: 326  Training loss = 2.2506  Validation loss = 2.0047  \n",
      "\n",
      "Fold: 7  Epoch: 327  Training loss = 2.2504  Validation loss = 2.0042  \n",
      "\n",
      "Fold: 7  Epoch: 328  Training loss = 2.2501  Validation loss = 2.0036  \n",
      "\n",
      "Fold: 7  Epoch: 329  Training loss = 2.2498  Validation loss = 2.0029  \n",
      "\n",
      "Fold: 7  Epoch: 330  Training loss = 2.2495  Validation loss = 2.0024  \n",
      "\n",
      "Fold: 7  Epoch: 331  Training loss = 2.2493  Validation loss = 2.0020  \n",
      "\n",
      "Fold: 7  Epoch: 332  Training loss = 2.2490  Validation loss = 2.0014  \n",
      "\n",
      "Fold: 7  Epoch: 333  Training loss = 2.2488  Validation loss = 2.0009  \n",
      "\n",
      "Fold: 7  Epoch: 334  Training loss = 2.2485  Validation loss = 2.0003  \n",
      "\n",
      "Fold: 7  Epoch: 335  Training loss = 2.2483  Validation loss = 1.9999  \n",
      "\n",
      "Fold: 7  Epoch: 336  Training loss = 2.2480  Validation loss = 1.9994  \n",
      "\n",
      "Fold: 7  Epoch: 337  Training loss = 2.2478  Validation loss = 1.9990  \n",
      "\n",
      "Fold: 7  Epoch: 338  Training loss = 2.2476  Validation loss = 1.9985  \n",
      "\n",
      "Fold: 7  Epoch: 339  Training loss = 2.2474  Validation loss = 1.9981  \n",
      "\n",
      "Fold: 7  Epoch: 340  Training loss = 2.2471  Validation loss = 1.9976  \n",
      "\n",
      "Fold: 7  Epoch: 341  Training loss = 2.2468  Validation loss = 1.9969  \n",
      "\n",
      "Fold: 7  Epoch: 342  Training loss = 2.2466  Validation loss = 1.9965  \n",
      "\n",
      "Fold: 7  Epoch: 343  Training loss = 2.2463  Validation loss = 1.9958  \n",
      "\n",
      "Fold: 7  Epoch: 344  Training loss = 2.2459  Validation loss = 1.9951  \n",
      "\n",
      "Fold: 7  Epoch: 345  Training loss = 2.2457  Validation loss = 1.9946  \n",
      "\n",
      "Fold: 7  Epoch: 346  Training loss = 2.2454  Validation loss = 1.9940  \n",
      "\n",
      "Fold: 7  Epoch: 347  Training loss = 2.2451  Validation loss = 1.9934  \n",
      "\n",
      "Fold: 7  Epoch: 348  Training loss = 2.2448  Validation loss = 1.9928  \n",
      "\n",
      "Fold: 7  Epoch: 349  Training loss = 2.2445  Validation loss = 1.9921  \n",
      "\n",
      "Fold: 7  Epoch: 350  Training loss = 2.2442  Validation loss = 1.9916  \n",
      "\n",
      "Fold: 7  Epoch: 351  Training loss = 2.2440  Validation loss = 1.9910  \n",
      "\n",
      "Fold: 7  Epoch: 352  Training loss = 2.2436  Validation loss = 1.9904  \n",
      "\n",
      "Fold: 7  Epoch: 353  Training loss = 2.2433  Validation loss = 1.9896  \n",
      "\n",
      "Fold: 7  Epoch: 354  Training loss = 2.2430  Validation loss = 1.9891  \n",
      "\n",
      "Fold: 7  Epoch: 355  Training loss = 2.2427  Validation loss = 1.9884  \n",
      "\n",
      "Fold: 7  Epoch: 356  Training loss = 2.2424  Validation loss = 1.9878  \n",
      "\n",
      "Fold: 7  Epoch: 357  Training loss = 2.2422  Validation loss = 1.9874  \n",
      "\n",
      "Fold: 7  Epoch: 358  Training loss = 2.2419  Validation loss = 1.9868  \n",
      "\n",
      "Fold: 7  Epoch: 359  Training loss = 2.2416  Validation loss = 1.9862  \n",
      "\n",
      "Fold: 7  Epoch: 360  Training loss = 2.2413  Validation loss = 1.9856  \n",
      "\n",
      "Fold: 7  Epoch: 361  Training loss = 2.2410  Validation loss = 1.9849  \n",
      "\n",
      "Fold: 7  Epoch: 362  Training loss = 2.2406  Validation loss = 1.9842  \n",
      "\n",
      "Fold: 7  Epoch: 363  Training loss = 2.2404  Validation loss = 1.9837  \n",
      "\n",
      "Fold: 7  Epoch: 364  Training loss = 2.2401  Validation loss = 1.9831  \n",
      "\n",
      "Fold: 7  Epoch: 365  Training loss = 2.2398  Validation loss = 1.9825  \n",
      "\n",
      "Fold: 7  Epoch: 366  Training loss = 2.2395  Validation loss = 1.9820  \n",
      "\n",
      "Fold: 7  Epoch: 367  Training loss = 2.2392  Validation loss = 1.9814  \n",
      "\n",
      "Fold: 7  Epoch: 368  Training loss = 2.2390  Validation loss = 1.9809  \n",
      "\n",
      "Fold: 7  Epoch: 369  Training loss = 2.2388  Validation loss = 1.9804  \n",
      "\n",
      "Fold: 7  Epoch: 370  Training loss = 2.2385  Validation loss = 1.9799  \n",
      "\n",
      "Fold: 7  Epoch: 371  Training loss = 2.2383  Validation loss = 1.9794  \n",
      "\n",
      "Fold: 7  Epoch: 372  Training loss = 2.2379  Validation loss = 1.9787  \n",
      "\n",
      "Fold: 7  Epoch: 373  Training loss = 2.2376  Validation loss = 1.9781  \n",
      "\n",
      "Fold: 7  Epoch: 374  Training loss = 2.2373  Validation loss = 1.9775  \n",
      "\n",
      "Fold: 7  Epoch: 375  Training loss = 2.2371  Validation loss = 1.9770  \n",
      "\n",
      "Fold: 7  Epoch: 376  Training loss = 2.2369  Validation loss = 1.9765  \n",
      "\n",
      "Fold: 7  Epoch: 377  Training loss = 2.2366  Validation loss = 1.9760  \n",
      "\n",
      "Fold: 7  Epoch: 378  Training loss = 2.2363  Validation loss = 1.9755  \n",
      "\n",
      "Fold: 7  Epoch: 379  Training loss = 2.2361  Validation loss = 1.9750  \n",
      "\n",
      "Fold: 7  Epoch: 380  Training loss = 2.2358  Validation loss = 1.9743  \n",
      "\n",
      "Fold: 7  Epoch: 381  Training loss = 2.2355  Validation loss = 1.9737  \n",
      "\n",
      "Fold: 7  Epoch: 382  Training loss = 2.2352  Validation loss = 1.9731  \n",
      "\n",
      "Fold: 7  Epoch: 383  Training loss = 2.2349  Validation loss = 1.9725  \n",
      "\n",
      "Fold: 7  Epoch: 384  Training loss = 2.2347  Validation loss = 1.9722  \n",
      "\n",
      "Fold: 7  Epoch: 385  Training loss = 2.2345  Validation loss = 1.9717  \n",
      "\n",
      "Fold: 7  Epoch: 386  Training loss = 2.2343  Validation loss = 1.9713  \n",
      "\n",
      "Fold: 7  Epoch: 387  Training loss = 2.2340  Validation loss = 1.9707  \n",
      "\n",
      "Fold: 7  Epoch: 388  Training loss = 2.2337  Validation loss = 1.9700  \n",
      "\n",
      "Fold: 7  Epoch: 389  Training loss = 2.2334  Validation loss = 1.9695  \n",
      "\n",
      "Fold: 7  Epoch: 390  Training loss = 2.2331  Validation loss = 1.9689  \n",
      "\n",
      "Fold: 7  Epoch: 391  Training loss = 2.2328  Validation loss = 1.9684  \n",
      "\n",
      "Fold: 7  Epoch: 392  Training loss = 2.2326  Validation loss = 1.9678  \n",
      "\n",
      "Fold: 7  Epoch: 393  Training loss = 2.2323  Validation loss = 1.9673  \n",
      "\n",
      "Fold: 7  Epoch: 394  Training loss = 2.2320  Validation loss = 1.9667  \n",
      "\n",
      "Fold: 7  Epoch: 395  Training loss = 2.2316  Validation loss = 1.9659  \n",
      "\n",
      "Fold: 7  Epoch: 396  Training loss = 2.2314  Validation loss = 1.9654  \n",
      "\n",
      "Fold: 7  Epoch: 397  Training loss = 2.2310  Validation loss = 1.9645  \n",
      "\n",
      "Fold: 7  Epoch: 398  Training loss = 2.2308  Validation loss = 1.9641  \n",
      "\n",
      "Fold: 7  Epoch: 399  Training loss = 2.2305  Validation loss = 1.9635  \n",
      "\n",
      "Fold: 7  Epoch: 400  Training loss = 2.2303  Validation loss = 1.9631  \n",
      "\n",
      "Fold: 7  Epoch: 401  Training loss = 2.2300  Validation loss = 1.9625  \n",
      "\n",
      "Fold: 7  Epoch: 402  Training loss = 2.2297  Validation loss = 1.9619  \n",
      "\n",
      "Fold: 7  Epoch: 403  Training loss = 2.2296  Validation loss = 1.9617  \n",
      "\n",
      "Fold: 7  Epoch: 404  Training loss = 2.2293  Validation loss = 1.9611  \n",
      "\n",
      "Fold: 7  Epoch: 405  Training loss = 2.2291  Validation loss = 1.9607  \n",
      "\n",
      "Fold: 7  Epoch: 406  Training loss = 2.2289  Validation loss = 1.9603  \n",
      "\n",
      "Fold: 7  Epoch: 407  Training loss = 2.2287  Validation loss = 1.9599  \n",
      "\n",
      "Fold: 7  Epoch: 408  Training loss = 2.2284  Validation loss = 1.9593  \n",
      "\n",
      "Fold: 7  Epoch: 409  Training loss = 2.2281  Validation loss = 1.9588  \n",
      "\n",
      "Fold: 7  Epoch: 410  Training loss = 2.2279  Validation loss = 1.9582  \n",
      "\n",
      "Fold: 7  Epoch: 411  Training loss = 2.2276  Validation loss = 1.9577  \n",
      "\n",
      "Fold: 7  Epoch: 412  Training loss = 2.2274  Validation loss = 1.9573  \n",
      "\n",
      "Fold: 7  Epoch: 413  Training loss = 2.2272  Validation loss = 1.9569  \n",
      "\n",
      "Fold: 7  Epoch: 414  Training loss = 2.2270  Validation loss = 1.9565  \n",
      "\n",
      "Fold: 7  Epoch: 415  Training loss = 2.2267  Validation loss = 1.9559  \n",
      "\n",
      "Fold: 7  Epoch: 416  Training loss = 2.2265  Validation loss = 1.9555  \n",
      "\n",
      "Fold: 7  Epoch: 417  Training loss = 2.2262  Validation loss = 1.9550  \n",
      "\n",
      "Fold: 7  Epoch: 418  Training loss = 2.2260  Validation loss = 1.9545  \n",
      "\n",
      "Fold: 7  Epoch: 419  Training loss = 2.2257  Validation loss = 1.9539  \n",
      "\n",
      "Fold: 7  Epoch: 420  Training loss = 2.2254  Validation loss = 1.9533  \n",
      "\n",
      "Fold: 7  Epoch: 421  Training loss = 2.2252  Validation loss = 1.9529  \n",
      "\n",
      "Fold: 7  Epoch: 422  Training loss = 2.2249  Validation loss = 1.9522  \n",
      "\n",
      "Fold: 7  Epoch: 423  Training loss = 2.2246  Validation loss = 1.9518  \n",
      "\n",
      "Fold: 7  Epoch: 424  Training loss = 2.2244  Validation loss = 1.9512  \n",
      "\n",
      "Fold: 7  Epoch: 425  Training loss = 2.2241  Validation loss = 1.9506  \n",
      "\n",
      "Fold: 7  Epoch: 426  Training loss = 2.2238  Validation loss = 1.9500  \n",
      "\n",
      "Fold: 7  Epoch: 427  Training loss = 2.2235  Validation loss = 1.9494  \n",
      "\n",
      "Fold: 7  Epoch: 428  Training loss = 2.2232  Validation loss = 1.9489  \n",
      "\n",
      "Fold: 7  Epoch: 429  Training loss = 2.2229  Validation loss = 1.9482  \n",
      "\n",
      "Fold: 7  Epoch: 430  Training loss = 2.2226  Validation loss = 1.9476  \n",
      "\n",
      "Fold: 7  Epoch: 431  Training loss = 2.2224  Validation loss = 1.9471  \n",
      "\n",
      "Fold: 7  Epoch: 432  Training loss = 2.2221  Validation loss = 1.9466  \n",
      "\n",
      "Fold: 7  Epoch: 433  Training loss = 2.2218  Validation loss = 1.9459  \n",
      "\n",
      "Fold: 7  Epoch: 434  Training loss = 2.2216  Validation loss = 1.9456  \n",
      "\n",
      "Fold: 7  Epoch: 435  Training loss = 2.2213  Validation loss = 1.9451  \n",
      "\n",
      "Fold: 7  Epoch: 436  Training loss = 2.2211  Validation loss = 1.9445  \n",
      "\n",
      "Fold: 7  Epoch: 437  Training loss = 2.2208  Validation loss = 1.9440  \n",
      "\n",
      "Fold: 7  Epoch: 438  Training loss = 2.2205  Validation loss = 1.9433  \n",
      "\n",
      "Fold: 7  Epoch: 439  Training loss = 2.2202  Validation loss = 1.9427  \n",
      "\n",
      "Fold: 7  Epoch: 440  Training loss = 2.2201  Validation loss = 1.9424  \n",
      "\n",
      "Fold: 7  Epoch: 441  Training loss = 2.2198  Validation loss = 1.9419  \n",
      "\n",
      "Fold: 7  Epoch: 442  Training loss = 2.2196  Validation loss = 1.9414  \n",
      "\n",
      "Fold: 7  Epoch: 443  Training loss = 2.2193  Validation loss = 1.9408  \n",
      "\n",
      "Fold: 7  Epoch: 444  Training loss = 2.2190  Validation loss = 1.9403  \n",
      "\n",
      "Fold: 7  Epoch: 445  Training loss = 2.2187  Validation loss = 1.9396  \n",
      "\n",
      "Fold: 7  Epoch: 446  Training loss = 2.2185  Validation loss = 1.9392  \n",
      "\n",
      "Fold: 7  Epoch: 447  Training loss = 2.2183  Validation loss = 1.9386  \n",
      "\n",
      "Fold: 7  Epoch: 448  Training loss = 2.2180  Validation loss = 1.9381  \n",
      "\n",
      "Fold: 7  Epoch: 449  Training loss = 2.2178  Validation loss = 1.9377  \n",
      "\n",
      "Fold: 7  Epoch: 450  Training loss = 2.2176  Validation loss = 1.9373  \n",
      "\n",
      "Fold: 7  Epoch: 451  Training loss = 2.2173  Validation loss = 1.9367  \n",
      "\n",
      "Fold: 7  Epoch: 452  Training loss = 2.2171  Validation loss = 1.9361  \n",
      "\n",
      "Fold: 7  Epoch: 453  Training loss = 2.2168  Validation loss = 1.9357  \n",
      "\n",
      "Fold: 7  Epoch: 454  Training loss = 2.2166  Validation loss = 1.9351  \n",
      "\n",
      "Fold: 7  Epoch: 455  Training loss = 2.2164  Validation loss = 1.9347  \n",
      "\n",
      "Fold: 7  Epoch: 456  Training loss = 2.2160  Validation loss = 1.9339  \n",
      "\n",
      "Fold: 7  Epoch: 457  Training loss = 2.2157  Validation loss = 1.9334  \n",
      "\n",
      "Fold: 7  Epoch: 458  Training loss = 2.2155  Validation loss = 1.9328  \n",
      "\n",
      "Fold: 7  Epoch: 459  Training loss = 2.2152  Validation loss = 1.9323  \n",
      "\n",
      "Fold: 7  Epoch: 460  Training loss = 2.2150  Validation loss = 1.9318  \n",
      "\n",
      "Fold: 7  Epoch: 461  Training loss = 2.2147  Validation loss = 1.9312  \n",
      "\n",
      "Fold: 7  Epoch: 462  Training loss = 2.2145  Validation loss = 1.9308  \n",
      "\n",
      "Fold: 7  Epoch: 463  Training loss = 2.2143  Validation loss = 1.9304  \n",
      "\n",
      "Fold: 7  Epoch: 464  Training loss = 2.2140  Validation loss = 1.9298  \n",
      "\n",
      "Fold: 7  Epoch: 465  Training loss = 2.2138  Validation loss = 1.9294  \n",
      "\n",
      "Fold: 7  Epoch: 466  Training loss = 2.2136  Validation loss = 1.9289  \n",
      "\n",
      "Fold: 7  Epoch: 467  Training loss = 2.2133  Validation loss = 1.9283  \n",
      "\n",
      "Fold: 7  Epoch: 468  Training loss = 2.2130  Validation loss = 1.9278  \n",
      "\n",
      "Fold: 7  Epoch: 469  Training loss = 2.2128  Validation loss = 1.9273  \n",
      "\n",
      "Fold: 7  Epoch: 470  Training loss = 2.2126  Validation loss = 1.9268  \n",
      "\n",
      "Fold: 7  Epoch: 471  Training loss = 2.2123  Validation loss = 1.9262  \n",
      "\n",
      "Fold: 7  Epoch: 472  Training loss = 2.2120  Validation loss = 1.9257  \n",
      "\n",
      "Fold: 7  Epoch: 473  Training loss = 2.2118  Validation loss = 1.9252  \n",
      "\n",
      "Fold: 7  Epoch: 474  Training loss = 2.2115  Validation loss = 1.9245  \n",
      "\n",
      "Fold: 7  Epoch: 475  Training loss = 2.2112  Validation loss = 1.9240  \n",
      "\n",
      "Fold: 7  Epoch: 476  Training loss = 2.2109  Validation loss = 1.9234  \n",
      "\n",
      "Fold: 7  Epoch: 477  Training loss = 2.2107  Validation loss = 1.9229  \n",
      "\n",
      "Fold: 7  Epoch: 478  Training loss = 2.2103  Validation loss = 1.9223  \n",
      "\n",
      "Fold: 7  Epoch: 479  Training loss = 2.2101  Validation loss = 1.9216  \n",
      "\n",
      "Fold: 7  Epoch: 480  Training loss = 2.2097  Validation loss = 1.9209  \n",
      "\n",
      "Fold: 7  Epoch: 481  Training loss = 2.2094  Validation loss = 1.9203  \n",
      "\n",
      "Fold: 7  Epoch: 482  Training loss = 2.2092  Validation loss = 1.9198  \n",
      "\n",
      "Fold: 7  Epoch: 483  Training loss = 2.2089  Validation loss = 1.9192  \n",
      "\n",
      "Fold: 7  Epoch: 484  Training loss = 2.2086  Validation loss = 1.9186  \n",
      "\n",
      "Fold: 7  Epoch: 485  Training loss = 2.2083  Validation loss = 1.9180  \n",
      "\n",
      "Fold: 7  Epoch: 486  Training loss = 2.2080  Validation loss = 1.9174  \n",
      "\n",
      "Fold: 7  Epoch: 487  Training loss = 2.2078  Validation loss = 1.9170  \n",
      "\n",
      "Fold: 7  Epoch: 488  Training loss = 2.2074  Validation loss = 1.9162  \n",
      "\n",
      "Fold: 7  Epoch: 489  Training loss = 2.2072  Validation loss = 1.9158  \n",
      "\n",
      "Fold: 7  Epoch: 490  Training loss = 2.2070  Validation loss = 1.9152  \n",
      "\n",
      "Fold: 7  Epoch: 491  Training loss = 2.2067  Validation loss = 1.9146  \n",
      "\n",
      "Fold: 7  Epoch: 492  Training loss = 2.2064  Validation loss = 1.9142  \n",
      "\n",
      "Fold: 7  Epoch: 493  Training loss = 2.2061  Validation loss = 1.9136  \n",
      "\n",
      "Fold: 7  Epoch: 494  Training loss = 2.2059  Validation loss = 1.9131  \n",
      "\n",
      "Fold: 7  Epoch: 495  Training loss = 2.2057  Validation loss = 1.9126  \n",
      "\n",
      "Fold: 7  Epoch: 496  Training loss = 2.2054  Validation loss = 1.9121  \n",
      "\n",
      "Fold: 7  Epoch: 497  Training loss = 2.2051  Validation loss = 1.9113  \n",
      "\n",
      "Fold: 7  Epoch: 498  Training loss = 2.2049  Validation loss = 1.9109  \n",
      "\n",
      "Fold: 7  Epoch: 499  Training loss = 2.2045  Validation loss = 1.9102  \n",
      "\n",
      "Fold: 7  Epoch: 500  Training loss = 2.2043  Validation loss = 1.9097  \n",
      "\n",
      "Check model:  Fold: 7  Optimal epoch: 500  \n",
      "\n",
      "Fold: 8  Epoch: 1  Training loss = 2.2028  Validation loss = 6.8947  \n",
      "\n",
      "Fold: 8  Epoch: 2  Training loss = 2.2026  Validation loss = 6.8943  \n",
      "\n",
      "Fold: 8  Epoch: 3  Training loss = 2.2023  Validation loss = 6.8938  \n",
      "\n",
      "Fold: 8  Epoch: 4  Training loss = 2.2018  Validation loss = 6.8932  \n",
      "\n",
      "Fold: 8  Epoch: 5  Training loss = 2.2015  Validation loss = 6.8927  \n",
      "\n",
      "Fold: 8  Epoch: 6  Training loss = 2.2012  Validation loss = 6.8922  \n",
      "\n",
      "Fold: 8  Epoch: 7  Training loss = 2.2009  Validation loss = 6.8917  \n",
      "\n",
      "Fold: 8  Epoch: 8  Training loss = 2.2006  Validation loss = 6.8913  \n",
      "\n",
      "Fold: 8  Epoch: 9  Training loss = 2.2003  Validation loss = 6.8908  \n",
      "\n",
      "Fold: 8  Epoch: 10  Training loss = 2.2001  Validation loss = 6.8903  \n",
      "\n",
      "Fold: 8  Epoch: 11  Training loss = 2.1997  Validation loss = 6.8898  \n",
      "\n",
      "Fold: 8  Epoch: 12  Training loss = 2.1994  Validation loss = 6.8894  \n",
      "\n",
      "Fold: 8  Epoch: 13  Training loss = 2.1992  Validation loss = 6.8890  \n",
      "\n",
      "Fold: 8  Epoch: 14  Training loss = 2.1988  Validation loss = 6.8884  \n",
      "\n",
      "Fold: 8  Epoch: 15  Training loss = 2.1985  Validation loss = 6.8879  \n",
      "\n",
      "Fold: 8  Epoch: 16  Training loss = 2.1982  Validation loss = 6.8875  \n",
      "\n",
      "Fold: 8  Epoch: 17  Training loss = 2.1979  Validation loss = 6.8869  \n",
      "\n",
      "Fold: 8  Epoch: 18  Training loss = 2.1976  Validation loss = 6.8865  \n",
      "\n",
      "Fold: 8  Epoch: 19  Training loss = 2.1973  Validation loss = 6.8861  \n",
      "\n",
      "Fold: 8  Epoch: 20  Training loss = 2.1971  Validation loss = 6.8858  \n",
      "\n",
      "Fold: 8  Epoch: 21  Training loss = 2.1968  Validation loss = 6.8853  \n",
      "\n",
      "Fold: 8  Epoch: 22  Training loss = 2.1965  Validation loss = 6.8849  \n",
      "\n",
      "Fold: 8  Epoch: 23  Training loss = 2.1962  Validation loss = 6.8844  \n",
      "\n",
      "Fold: 8  Epoch: 24  Training loss = 2.1960  Validation loss = 6.8840  \n",
      "\n",
      "Fold: 8  Epoch: 25  Training loss = 2.1957  Validation loss = 6.8835  \n",
      "\n",
      "Fold: 8  Epoch: 26  Training loss = 2.1955  Validation loss = 6.8831  \n",
      "\n",
      "Fold: 8  Epoch: 27  Training loss = 2.1951  Validation loss = 6.8827  \n",
      "\n",
      "Fold: 8  Epoch: 28  Training loss = 2.1949  Validation loss = 6.8823  \n",
      "\n",
      "Fold: 8  Epoch: 29  Training loss = 2.1946  Validation loss = 6.8818  \n",
      "\n",
      "Fold: 8  Epoch: 30  Training loss = 2.1944  Validation loss = 6.8815  \n",
      "\n",
      "Fold: 8  Epoch: 31  Training loss = 2.1940  Validation loss = 6.8810  \n",
      "\n",
      "Fold: 8  Epoch: 32  Training loss = 2.1937  Validation loss = 6.8804  \n",
      "\n",
      "Fold: 8  Epoch: 33  Training loss = 2.1934  Validation loss = 6.8800  \n",
      "\n",
      "Fold: 8  Epoch: 34  Training loss = 2.1932  Validation loss = 6.8797  \n",
      "\n",
      "Fold: 8  Epoch: 35  Training loss = 2.1929  Validation loss = 6.8792  \n",
      "\n",
      "Fold: 8  Epoch: 36  Training loss = 2.1927  Validation loss = 6.8789  \n",
      "\n",
      "Fold: 8  Epoch: 37  Training loss = 2.1924  Validation loss = 6.8784  \n",
      "\n",
      "Fold: 8  Epoch: 38  Training loss = 2.1921  Validation loss = 6.8779  \n",
      "\n",
      "Fold: 8  Epoch: 39  Training loss = 2.1918  Validation loss = 6.8775  \n",
      "\n",
      "Fold: 8  Epoch: 40  Training loss = 2.1915  Validation loss = 6.8771  \n",
      "\n",
      "Fold: 8  Epoch: 41  Training loss = 2.1913  Validation loss = 6.8767  \n",
      "\n",
      "Fold: 8  Epoch: 42  Training loss = 2.1910  Validation loss = 6.8763  \n",
      "\n",
      "Fold: 8  Epoch: 43  Training loss = 2.1907  Validation loss = 6.8759  \n",
      "\n",
      "Fold: 8  Epoch: 44  Training loss = 2.1903  Validation loss = 6.8753  \n",
      "\n",
      "Fold: 8  Epoch: 45  Training loss = 2.1900  Validation loss = 6.8748  \n",
      "\n",
      "Fold: 8  Epoch: 46  Training loss = 2.1897  Validation loss = 6.8743  \n",
      "\n",
      "Fold: 8  Epoch: 47  Training loss = 2.1893  Validation loss = 6.8737  \n",
      "\n",
      "Fold: 8  Epoch: 48  Training loss = 2.1891  Validation loss = 6.8734  \n",
      "\n",
      "Fold: 8  Epoch: 49  Training loss = 2.1888  Validation loss = 6.8729  \n",
      "\n",
      "Fold: 8  Epoch: 50  Training loss = 2.1885  Validation loss = 6.8725  \n",
      "\n",
      "Fold: 8  Epoch: 51  Training loss = 2.1881  Validation loss = 6.8719  \n",
      "\n",
      "Fold: 8  Epoch: 52  Training loss = 2.1878  Validation loss = 6.8714  \n",
      "\n",
      "Fold: 8  Epoch: 53  Training loss = 2.1874  Validation loss = 6.8708  \n",
      "\n",
      "Fold: 8  Epoch: 54  Training loss = 2.1872  Validation loss = 6.8704  \n",
      "\n",
      "Fold: 8  Epoch: 55  Training loss = 2.1869  Validation loss = 6.8700  \n",
      "\n",
      "Fold: 8  Epoch: 56  Training loss = 2.1866  Validation loss = 6.8696  \n",
      "\n",
      "Fold: 8  Epoch: 57  Training loss = 2.1863  Validation loss = 6.8691  \n",
      "\n",
      "Fold: 8  Epoch: 58  Training loss = 2.1860  Validation loss = 6.8685  \n",
      "\n",
      "Fold: 8  Epoch: 59  Training loss = 2.1857  Validation loss = 6.8680  \n",
      "\n",
      "Fold: 8  Epoch: 60  Training loss = 2.1854  Validation loss = 6.8675  \n",
      "\n",
      "Fold: 8  Epoch: 61  Training loss = 2.1851  Validation loss = 6.8671  \n",
      "\n",
      "Fold: 8  Epoch: 62  Training loss = 2.1848  Validation loss = 6.8667  \n",
      "\n",
      "Fold: 8  Epoch: 63  Training loss = 2.1846  Validation loss = 6.8663  \n",
      "\n",
      "Fold: 8  Epoch: 64  Training loss = 2.1843  Validation loss = 6.8658  \n",
      "\n",
      "Fold: 8  Epoch: 65  Training loss = 2.1839  Validation loss = 6.8653  \n",
      "\n",
      "Fold: 8  Epoch: 66  Training loss = 2.1836  Validation loss = 6.8648  \n",
      "\n",
      "Fold: 8  Epoch: 67  Training loss = 2.1833  Validation loss = 6.8643  \n",
      "\n",
      "Fold: 8  Epoch: 68  Training loss = 2.1830  Validation loss = 6.8638  \n",
      "\n",
      "Fold: 8  Epoch: 69  Training loss = 2.1827  Validation loss = 6.8633  \n",
      "\n",
      "Fold: 8  Epoch: 70  Training loss = 2.1824  Validation loss = 6.8629  \n",
      "\n",
      "Fold: 8  Epoch: 71  Training loss = 2.1820  Validation loss = 6.8623  \n",
      "\n",
      "Fold: 8  Epoch: 72  Training loss = 2.1816  Validation loss = 6.8617  \n",
      "\n",
      "Fold: 8  Epoch: 73  Training loss = 2.1813  Validation loss = 6.8612  \n",
      "\n",
      "Fold: 8  Epoch: 74  Training loss = 2.1810  Validation loss = 6.8608  \n",
      "\n",
      "Fold: 8  Epoch: 75  Training loss = 2.1807  Validation loss = 6.8603  \n",
      "\n",
      "Fold: 8  Epoch: 76  Training loss = 2.1805  Validation loss = 6.8599  \n",
      "\n",
      "Fold: 8  Epoch: 77  Training loss = 2.1802  Validation loss = 6.8593  \n",
      "\n",
      "Fold: 8  Epoch: 78  Training loss = 2.1799  Validation loss = 6.8589  \n",
      "\n",
      "Fold: 8  Epoch: 79  Training loss = 2.1796  Validation loss = 6.8585  \n",
      "\n",
      "Fold: 8  Epoch: 80  Training loss = 2.1794  Validation loss = 6.8581  \n",
      "\n",
      "Fold: 8  Epoch: 81  Training loss = 2.1791  Validation loss = 6.8577  \n",
      "\n",
      "Fold: 8  Epoch: 82  Training loss = 2.1788  Validation loss = 6.8572  \n",
      "\n",
      "Fold: 8  Epoch: 83  Training loss = 2.1786  Validation loss = 6.8568  \n",
      "\n",
      "Fold: 8  Epoch: 84  Training loss = 2.1782  Validation loss = 6.8562  \n",
      "\n",
      "Fold: 8  Epoch: 85  Training loss = 2.1778  Validation loss = 6.8557  \n",
      "\n",
      "Fold: 8  Epoch: 86  Training loss = 2.1775  Validation loss = 6.8551  \n",
      "\n",
      "Fold: 8  Epoch: 87  Training loss = 2.1772  Validation loss = 6.8546  \n",
      "\n",
      "Fold: 8  Epoch: 88  Training loss = 2.1768  Validation loss = 6.8540  \n",
      "\n",
      "Fold: 8  Epoch: 89  Training loss = 2.1766  Validation loss = 6.8536  \n",
      "\n",
      "Fold: 8  Epoch: 90  Training loss = 2.1762  Validation loss = 6.8531  \n",
      "\n",
      "Fold: 8  Epoch: 91  Training loss = 2.1760  Validation loss = 6.8526  \n",
      "\n",
      "Fold: 8  Epoch: 92  Training loss = 2.1756  Validation loss = 6.8522  \n",
      "\n",
      "Fold: 8  Epoch: 93  Training loss = 2.1754  Validation loss = 6.8517  \n",
      "\n",
      "Fold: 8  Epoch: 94  Training loss = 2.1751  Validation loss = 6.8513  \n",
      "\n",
      "Fold: 8  Epoch: 95  Training loss = 2.1748  Validation loss = 6.8509  \n",
      "\n",
      "Fold: 8  Epoch: 96  Training loss = 2.1745  Validation loss = 6.8504  \n",
      "\n",
      "Fold: 8  Epoch: 97  Training loss = 2.1742  Validation loss = 6.8499  \n",
      "\n",
      "Fold: 8  Epoch: 98  Training loss = 2.1739  Validation loss = 6.8494  \n",
      "\n",
      "Fold: 8  Epoch: 99  Training loss = 2.1736  Validation loss = 6.8489  \n",
      "\n",
      "Fold: 8  Epoch: 100  Training loss = 2.1733  Validation loss = 6.8485  \n",
      "\n",
      "Fold: 8  Epoch: 101  Training loss = 2.1729  Validation loss = 6.8479  \n",
      "\n",
      "Fold: 8  Epoch: 102  Training loss = 2.1727  Validation loss = 6.8476  \n",
      "\n",
      "Fold: 8  Epoch: 103  Training loss = 2.1725  Validation loss = 6.8473  \n",
      "\n",
      "Fold: 8  Epoch: 104  Training loss = 2.1722  Validation loss = 6.8467  \n",
      "\n",
      "Fold: 8  Epoch: 105  Training loss = 2.1720  Validation loss = 6.8464  \n",
      "\n",
      "Fold: 8  Epoch: 106  Training loss = 2.1717  Validation loss = 6.8460  \n",
      "\n",
      "Fold: 8  Epoch: 107  Training loss = 2.1714  Validation loss = 6.8456  \n",
      "\n",
      "Fold: 8  Epoch: 108  Training loss = 2.1713  Validation loss = 6.8452  \n",
      "\n",
      "Fold: 8  Epoch: 109  Training loss = 2.1710  Validation loss = 6.8448  \n",
      "\n",
      "Fold: 8  Epoch: 110  Training loss = 2.1707  Validation loss = 6.8443  \n",
      "\n",
      "Fold: 8  Epoch: 111  Training loss = 2.1704  Validation loss = 6.8439  \n",
      "\n",
      "Fold: 8  Epoch: 112  Training loss = 2.1701  Validation loss = 6.8435  \n",
      "\n",
      "Fold: 8  Epoch: 113  Training loss = 2.1698  Validation loss = 6.8429  \n",
      "\n",
      "Fold: 8  Epoch: 114  Training loss = 2.1695  Validation loss = 6.8425  \n",
      "\n",
      "Fold: 8  Epoch: 115  Training loss = 2.1692  Validation loss = 6.8420  \n",
      "\n",
      "Fold: 8  Epoch: 116  Training loss = 2.1689  Validation loss = 6.8416  \n",
      "\n",
      "Fold: 8  Epoch: 117  Training loss = 2.1687  Validation loss = 6.8411  \n",
      "\n",
      "Fold: 8  Epoch: 118  Training loss = 2.1684  Validation loss = 6.8406  \n",
      "\n",
      "Fold: 8  Epoch: 119  Training loss = 2.1681  Validation loss = 6.8402  \n",
      "\n",
      "Fold: 8  Epoch: 120  Training loss = 2.1678  Validation loss = 6.8397  \n",
      "\n",
      "Fold: 8  Epoch: 121  Training loss = 2.1675  Validation loss = 6.8392  \n",
      "\n",
      "Fold: 8  Epoch: 122  Training loss = 2.1673  Validation loss = 6.8388  \n",
      "\n",
      "Fold: 8  Epoch: 123  Training loss = 2.1670  Validation loss = 6.8384  \n",
      "\n",
      "Fold: 8  Epoch: 124  Training loss = 2.1667  Validation loss = 6.8379  \n",
      "\n",
      "Fold: 8  Epoch: 125  Training loss = 2.1664  Validation loss = 6.8374  \n",
      "\n",
      "Fold: 8  Epoch: 126  Training loss = 2.1661  Validation loss = 6.8371  \n",
      "\n",
      "Fold: 8  Epoch: 127  Training loss = 2.1658  Validation loss = 6.8365  \n",
      "\n",
      "Fold: 8  Epoch: 128  Training loss = 2.1656  Validation loss = 6.8362  \n",
      "\n",
      "Fold: 8  Epoch: 129  Training loss = 2.1652  Validation loss = 6.8356  \n",
      "\n",
      "Fold: 8  Epoch: 130  Training loss = 2.1650  Validation loss = 6.8352  \n",
      "\n",
      "Fold: 8  Epoch: 131  Training loss = 2.1647  Validation loss = 6.8347  \n",
      "\n",
      "Fold: 8  Epoch: 132  Training loss = 2.1643  Validation loss = 6.8341  \n",
      "\n",
      "Fold: 8  Epoch: 133  Training loss = 2.1641  Validation loss = 6.8338  \n",
      "\n",
      "Fold: 8  Epoch: 134  Training loss = 2.1638  Validation loss = 6.8334  \n",
      "\n",
      "Fold: 8  Epoch: 135  Training loss = 2.1635  Validation loss = 6.8329  \n",
      "\n",
      "Fold: 8  Epoch: 136  Training loss = 2.1632  Validation loss = 6.8324  \n",
      "\n",
      "Fold: 8  Epoch: 137  Training loss = 2.1629  Validation loss = 6.8320  \n",
      "\n",
      "Fold: 8  Epoch: 138  Training loss = 2.1626  Validation loss = 6.8315  \n",
      "\n",
      "Fold: 8  Epoch: 139  Training loss = 2.1624  Validation loss = 6.8311  \n",
      "\n",
      "Fold: 8  Epoch: 140  Training loss = 2.1621  Validation loss = 6.8306  \n",
      "\n",
      "Fold: 8  Epoch: 141  Training loss = 2.1618  Validation loss = 6.8302  \n",
      "\n",
      "Fold: 8  Epoch: 142  Training loss = 2.1616  Validation loss = 6.8299  \n",
      "\n",
      "Fold: 8  Epoch: 143  Training loss = 2.1613  Validation loss = 6.8294  \n",
      "\n",
      "Fold: 8  Epoch: 144  Training loss = 2.1610  Validation loss = 6.8290  \n",
      "\n",
      "Fold: 8  Epoch: 145  Training loss = 2.1607  Validation loss = 6.8284  \n",
      "\n",
      "Fold: 8  Epoch: 146  Training loss = 2.1604  Validation loss = 6.8280  \n",
      "\n",
      "Fold: 8  Epoch: 147  Training loss = 2.1600  Validation loss = 6.8274  \n",
      "\n",
      "Fold: 8  Epoch: 148  Training loss = 2.1598  Validation loss = 6.8271  \n",
      "\n",
      "Fold: 8  Epoch: 149  Training loss = 2.1596  Validation loss = 6.8266  \n",
      "\n",
      "Fold: 8  Epoch: 150  Training loss = 2.1592  Validation loss = 6.8260  \n",
      "\n",
      "Fold: 8  Epoch: 151  Training loss = 2.1589  Validation loss = 6.8256  \n",
      "\n",
      "Fold: 8  Epoch: 152  Training loss = 2.1586  Validation loss = 6.8251  \n",
      "\n",
      "Fold: 8  Epoch: 153  Training loss = 2.1584  Validation loss = 6.8247  \n",
      "\n",
      "Fold: 8  Epoch: 154  Training loss = 2.1581  Validation loss = 6.8242  \n",
      "\n",
      "Fold: 8  Epoch: 155  Training loss = 2.1578  Validation loss = 6.8238  \n",
      "\n",
      "Fold: 8  Epoch: 156  Training loss = 2.1575  Validation loss = 6.8233  \n",
      "\n",
      "Fold: 8  Epoch: 157  Training loss = 2.1571  Validation loss = 6.8227  \n",
      "\n",
      "Fold: 8  Epoch: 158  Training loss = 2.1569  Validation loss = 6.8223  \n",
      "\n",
      "Fold: 8  Epoch: 159  Training loss = 2.1566  Validation loss = 6.8219  \n",
      "\n",
      "Fold: 8  Epoch: 160  Training loss = 2.1563  Validation loss = 6.8214  \n",
      "\n",
      "Fold: 8  Epoch: 161  Training loss = 2.1561  Validation loss = 6.8211  \n",
      "\n",
      "Fold: 8  Epoch: 162  Training loss = 2.1558  Validation loss = 6.8207  \n",
      "\n",
      "Fold: 8  Epoch: 163  Training loss = 2.1556  Validation loss = 6.8202  \n",
      "\n",
      "Fold: 8  Epoch: 164  Training loss = 2.1553  Validation loss = 6.8198  \n",
      "\n",
      "Fold: 8  Epoch: 165  Training loss = 2.1551  Validation loss = 6.8194  \n",
      "\n",
      "Fold: 8  Epoch: 166  Training loss = 2.1548  Validation loss = 6.8189  \n",
      "\n",
      "Fold: 8  Epoch: 167  Training loss = 2.1546  Validation loss = 6.8186  \n",
      "\n",
      "Fold: 8  Epoch: 168  Training loss = 2.1542  Validation loss = 6.8181  \n",
      "\n",
      "Fold: 8  Epoch: 169  Training loss = 2.1540  Validation loss = 6.8177  \n",
      "\n",
      "Fold: 8  Epoch: 170  Training loss = 2.1537  Validation loss = 6.8173  \n",
      "\n",
      "Fold: 8  Epoch: 171  Training loss = 2.1535  Validation loss = 6.8169  \n",
      "\n",
      "Fold: 8  Epoch: 172  Training loss = 2.1532  Validation loss = 6.8165  \n",
      "\n",
      "Fold: 8  Epoch: 173  Training loss = 2.1529  Validation loss = 6.8160  \n",
      "\n",
      "Fold: 8  Epoch: 174  Training loss = 2.1527  Validation loss = 6.8156  \n",
      "\n",
      "Fold: 8  Epoch: 175  Training loss = 2.1523  Validation loss = 6.8151  \n",
      "\n",
      "Fold: 8  Epoch: 176  Training loss = 2.1521  Validation loss = 6.8146  \n",
      "\n",
      "Fold: 8  Epoch: 177  Training loss = 2.1518  Validation loss = 6.8142  \n",
      "\n",
      "Fold: 8  Epoch: 178  Training loss = 2.1515  Validation loss = 6.8136  \n",
      "\n",
      "Fold: 8  Epoch: 179  Training loss = 2.1512  Validation loss = 6.8131  \n",
      "\n",
      "Fold: 8  Epoch: 180  Training loss = 2.1508  Validation loss = 6.8126  \n",
      "\n",
      "Fold: 8  Epoch: 181  Training loss = 2.1506  Validation loss = 6.8123  \n",
      "\n",
      "Fold: 8  Epoch: 182  Training loss = 2.1503  Validation loss = 6.8119  \n",
      "\n",
      "Fold: 8  Epoch: 183  Training loss = 2.1500  Validation loss = 6.8114  \n",
      "\n",
      "Fold: 8  Epoch: 184  Training loss = 2.1498  Validation loss = 6.8110  \n",
      "\n",
      "Fold: 8  Epoch: 185  Training loss = 2.1495  Validation loss = 6.8105  \n",
      "\n",
      "Fold: 8  Epoch: 186  Training loss = 2.1492  Validation loss = 6.8101  \n",
      "\n",
      "Fold: 8  Epoch: 187  Training loss = 2.1490  Validation loss = 6.8097  \n",
      "\n",
      "Fold: 8  Epoch: 188  Training loss = 2.1487  Validation loss = 6.8093  \n",
      "\n",
      "Fold: 8  Epoch: 189  Training loss = 2.1485  Validation loss = 6.8088  \n",
      "\n",
      "Fold: 8  Epoch: 190  Training loss = 2.1482  Validation loss = 6.8085  \n",
      "\n",
      "Fold: 8  Epoch: 191  Training loss = 2.1480  Validation loss = 6.8080  \n",
      "\n",
      "Fold: 8  Epoch: 192  Training loss = 2.1477  Validation loss = 6.8076  \n",
      "\n",
      "Fold: 8  Epoch: 193  Training loss = 2.1474  Validation loss = 6.8072  \n",
      "\n",
      "Fold: 8  Epoch: 194  Training loss = 2.1471  Validation loss = 6.8067  \n",
      "\n",
      "Fold: 8  Epoch: 195  Training loss = 2.1468  Validation loss = 6.8062  \n",
      "\n",
      "Fold: 8  Epoch: 196  Training loss = 2.1466  Validation loss = 6.8059  \n",
      "\n",
      "Fold: 8  Epoch: 197  Training loss = 2.1464  Validation loss = 6.8055  \n",
      "\n",
      "Fold: 8  Epoch: 198  Training loss = 2.1462  Validation loss = 6.8052  \n",
      "\n",
      "Fold: 8  Epoch: 199  Training loss = 2.1459  Validation loss = 6.8046  \n",
      "\n",
      "Fold: 8  Epoch: 200  Training loss = 2.1456  Validation loss = 6.8041  \n",
      "\n",
      "Fold: 8  Epoch: 201  Training loss = 2.1453  Validation loss = 6.8037  \n",
      "\n",
      "Fold: 8  Epoch: 202  Training loss = 2.1451  Validation loss = 6.8034  \n",
      "\n",
      "Fold: 8  Epoch: 203  Training loss = 2.1449  Validation loss = 6.8030  \n",
      "\n",
      "Fold: 8  Epoch: 204  Training loss = 2.1447  Validation loss = 6.8027  \n",
      "\n",
      "Fold: 8  Epoch: 205  Training loss = 2.1445  Validation loss = 6.8023  \n",
      "\n",
      "Fold: 8  Epoch: 206  Training loss = 2.1443  Validation loss = 6.8019  \n",
      "\n",
      "Fold: 8  Epoch: 207  Training loss = 2.1441  Validation loss = 6.8016  \n",
      "\n",
      "Fold: 8  Epoch: 208  Training loss = 2.1438  Validation loss = 6.8011  \n",
      "\n",
      "Fold: 8  Epoch: 209  Training loss = 2.1435  Validation loss = 6.8007  \n",
      "\n",
      "Fold: 8  Epoch: 210  Training loss = 2.1432  Validation loss = 6.8002  \n",
      "\n",
      "Fold: 8  Epoch: 211  Training loss = 2.1430  Validation loss = 6.7999  \n",
      "\n",
      "Fold: 8  Epoch: 212  Training loss = 2.1426  Validation loss = 6.7993  \n",
      "\n",
      "Fold: 8  Epoch: 213  Training loss = 2.1424  Validation loss = 6.7989  \n",
      "\n",
      "Fold: 8  Epoch: 214  Training loss = 2.1421  Validation loss = 6.7985  \n",
      "\n",
      "Fold: 8  Epoch: 215  Training loss = 2.1419  Validation loss = 6.7981  \n",
      "\n",
      "Fold: 8  Epoch: 216  Training loss = 2.1417  Validation loss = 6.7977  \n",
      "\n",
      "Fold: 8  Epoch: 217  Training loss = 2.1414  Validation loss = 6.7972  \n",
      "\n",
      "Fold: 8  Epoch: 218  Training loss = 2.1412  Validation loss = 6.7968  \n",
      "\n",
      "Fold: 8  Epoch: 219  Training loss = 2.1408  Validation loss = 6.7963  \n",
      "\n",
      "Fold: 8  Epoch: 220  Training loss = 2.1405  Validation loss = 6.7958  \n",
      "\n",
      "Fold: 8  Epoch: 221  Training loss = 2.1403  Validation loss = 6.7954  \n",
      "\n",
      "Fold: 8  Epoch: 222  Training loss = 2.1400  Validation loss = 6.7949  \n",
      "\n",
      "Fold: 8  Epoch: 223  Training loss = 2.1397  Validation loss = 6.7945  \n",
      "\n",
      "Fold: 8  Epoch: 224  Training loss = 2.1395  Validation loss = 6.7940  \n",
      "\n",
      "Fold: 8  Epoch: 225  Training loss = 2.1392  Validation loss = 6.7936  \n",
      "\n",
      "Fold: 8  Epoch: 226  Training loss = 2.1389  Validation loss = 6.7931  \n",
      "\n",
      "Fold: 8  Epoch: 227  Training loss = 2.1386  Validation loss = 6.7926  \n",
      "\n",
      "Fold: 8  Epoch: 228  Training loss = 2.1383  Validation loss = 6.7921  \n",
      "\n",
      "Fold: 8  Epoch: 229  Training loss = 2.1381  Validation loss = 6.7917  \n",
      "\n",
      "Fold: 8  Epoch: 230  Training loss = 2.1378  Validation loss = 6.7912  \n",
      "\n",
      "Fold: 8  Epoch: 231  Training loss = 2.1375  Validation loss = 6.7907  \n",
      "\n",
      "Fold: 8  Epoch: 232  Training loss = 2.1373  Validation loss = 6.7903  \n",
      "\n",
      "Fold: 8  Epoch: 233  Training loss = 2.1370  Validation loss = 6.7899  \n",
      "\n",
      "Fold: 8  Epoch: 234  Training loss = 2.1368  Validation loss = 6.7895  \n",
      "\n",
      "Fold: 8  Epoch: 235  Training loss = 2.1365  Validation loss = 6.7892  \n",
      "\n",
      "Fold: 8  Epoch: 236  Training loss = 2.1362  Validation loss = 6.7887  \n",
      "\n",
      "Fold: 8  Epoch: 237  Training loss = 2.1359  Validation loss = 6.7881  \n",
      "\n",
      "Fold: 8  Epoch: 238  Training loss = 2.1356  Validation loss = 6.7877  \n",
      "\n",
      "Fold: 8  Epoch: 239  Training loss = 2.1354  Validation loss = 6.7874  \n",
      "\n",
      "Fold: 8  Epoch: 240  Training loss = 2.1351  Validation loss = 6.7868  \n",
      "\n",
      "Fold: 8  Epoch: 241  Training loss = 2.1348  Validation loss = 6.7863  \n",
      "\n",
      "Fold: 8  Epoch: 242  Training loss = 2.1346  Validation loss = 6.7859  \n",
      "\n",
      "Fold: 8  Epoch: 243  Training loss = 2.1342  Validation loss = 6.7853  \n",
      "\n",
      "Fold: 8  Epoch: 244  Training loss = 2.1339  Validation loss = 6.7848  \n",
      "\n",
      "Fold: 8  Epoch: 245  Training loss = 2.1336  Validation loss = 6.7843  \n",
      "\n",
      "Fold: 8  Epoch: 246  Training loss = 2.1332  Validation loss = 6.7838  \n",
      "\n",
      "Fold: 8  Epoch: 247  Training loss = 2.1330  Validation loss = 6.7834  \n",
      "\n",
      "Fold: 8  Epoch: 248  Training loss = 2.1328  Validation loss = 6.7830  \n",
      "\n",
      "Fold: 8  Epoch: 249  Training loss = 2.1325  Validation loss = 6.7826  \n",
      "\n",
      "Fold: 8  Epoch: 250  Training loss = 2.1322  Validation loss = 6.7821  \n",
      "\n",
      "Fold: 8  Epoch: 251  Training loss = 2.1320  Validation loss = 6.7817  \n",
      "\n",
      "Fold: 8  Epoch: 252  Training loss = 2.1317  Validation loss = 6.7812  \n",
      "\n",
      "Fold: 8  Epoch: 253  Training loss = 2.1314  Validation loss = 6.7807  \n",
      "\n",
      "Fold: 8  Epoch: 254  Training loss = 2.1311  Validation loss = 6.7802  \n",
      "\n",
      "Fold: 8  Epoch: 255  Training loss = 2.1308  Validation loss = 6.7797  \n",
      "\n",
      "Fold: 8  Epoch: 256  Training loss = 2.1306  Validation loss = 6.7793  \n",
      "\n",
      "Fold: 8  Epoch: 257  Training loss = 2.1302  Validation loss = 6.7788  \n",
      "\n",
      "Fold: 8  Epoch: 258  Training loss = 2.1300  Validation loss = 6.7784  \n",
      "\n",
      "Fold: 8  Epoch: 259  Training loss = 2.1297  Validation loss = 6.7778  \n",
      "\n",
      "Fold: 8  Epoch: 260  Training loss = 2.1294  Validation loss = 6.7773  \n",
      "\n",
      "Fold: 8  Epoch: 261  Training loss = 2.1292  Validation loss = 6.7770  \n",
      "\n",
      "Fold: 8  Epoch: 262  Training loss = 2.1290  Validation loss = 6.7766  \n",
      "\n",
      "Fold: 8  Epoch: 263  Training loss = 2.1287  Validation loss = 6.7761  \n",
      "\n",
      "Fold: 8  Epoch: 264  Training loss = 2.1284  Validation loss = 6.7758  \n",
      "\n",
      "Fold: 8  Epoch: 265  Training loss = 2.1282  Validation loss = 6.7753  \n",
      "\n",
      "Fold: 8  Epoch: 266  Training loss = 2.1280  Validation loss = 6.7750  \n",
      "\n",
      "Fold: 8  Epoch: 267  Training loss = 2.1278  Validation loss = 6.7746  \n",
      "\n",
      "Fold: 8  Epoch: 268  Training loss = 2.1274  Validation loss = 6.7741  \n",
      "\n",
      "Fold: 8  Epoch: 269  Training loss = 2.1272  Validation loss = 6.7737  \n",
      "\n",
      "Fold: 8  Epoch: 270  Training loss = 2.1270  Validation loss = 6.7734  \n",
      "\n",
      "Fold: 8  Epoch: 271  Training loss = 2.1267  Validation loss = 6.7729  \n",
      "\n",
      "Fold: 8  Epoch: 272  Training loss = 2.1263  Validation loss = 6.7723  \n",
      "\n",
      "Fold: 8  Epoch: 273  Training loss = 2.1261  Validation loss = 6.7718  \n",
      "\n",
      "Fold: 8  Epoch: 274  Training loss = 2.1258  Validation loss = 6.7714  \n",
      "\n",
      "Fold: 8  Epoch: 275  Training loss = 2.1255  Validation loss = 6.7709  \n",
      "\n",
      "Fold: 8  Epoch: 276  Training loss = 2.1252  Validation loss = 6.7704  \n",
      "\n",
      "Fold: 8  Epoch: 277  Training loss = 2.1249  Validation loss = 6.7699  \n",
      "\n",
      "Fold: 8  Epoch: 278  Training loss = 2.1246  Validation loss = 6.7695  \n",
      "\n",
      "Fold: 8  Epoch: 279  Training loss = 2.1244  Validation loss = 6.7691  \n",
      "\n",
      "Fold: 8  Epoch: 280  Training loss = 2.1240  Validation loss = 6.7686  \n",
      "\n",
      "Fold: 8  Epoch: 281  Training loss = 2.1238  Validation loss = 6.7681  \n",
      "\n",
      "Fold: 8  Epoch: 282  Training loss = 2.1234  Validation loss = 6.7675  \n",
      "\n",
      "Fold: 8  Epoch: 283  Training loss = 2.1232  Validation loss = 6.7672  \n",
      "\n",
      "Fold: 8  Epoch: 284  Training loss = 2.1229  Validation loss = 6.7668  \n",
      "\n",
      "Fold: 8  Epoch: 285  Training loss = 2.1227  Validation loss = 6.7663  \n",
      "\n",
      "Fold: 8  Epoch: 286  Training loss = 2.1224  Validation loss = 6.7659  \n",
      "\n",
      "Fold: 8  Epoch: 287  Training loss = 2.1222  Validation loss = 6.7655  \n",
      "\n",
      "Fold: 8  Epoch: 288  Training loss = 2.1220  Validation loss = 6.7651  \n",
      "\n",
      "Fold: 8  Epoch: 289  Training loss = 2.1217  Validation loss = 6.7647  \n",
      "\n",
      "Fold: 8  Epoch: 290  Training loss = 2.1215  Validation loss = 6.7643  \n",
      "\n",
      "Fold: 8  Epoch: 291  Training loss = 2.1213  Validation loss = 6.7640  \n",
      "\n",
      "Fold: 8  Epoch: 292  Training loss = 2.1210  Validation loss = 6.7634  \n",
      "\n",
      "Fold: 8  Epoch: 293  Training loss = 2.1207  Validation loss = 6.7630  \n",
      "\n",
      "Fold: 8  Epoch: 294  Training loss = 2.1205  Validation loss = 6.7626  \n",
      "\n",
      "Fold: 8  Epoch: 295  Training loss = 2.1202  Validation loss = 6.7622  \n",
      "\n",
      "Fold: 8  Epoch: 296  Training loss = 2.1199  Validation loss = 6.7617  \n",
      "\n",
      "Fold: 8  Epoch: 297  Training loss = 2.1196  Validation loss = 6.7612  \n",
      "\n",
      "Fold: 8  Epoch: 298  Training loss = 2.1193  Validation loss = 6.7608  \n",
      "\n",
      "Fold: 8  Epoch: 299  Training loss = 2.1190  Validation loss = 6.7602  \n",
      "\n",
      "Fold: 8  Epoch: 300  Training loss = 2.1187  Validation loss = 6.7598  \n",
      "\n",
      "Fold: 8  Epoch: 301  Training loss = 2.1184  Validation loss = 6.7593  \n",
      "\n",
      "Fold: 8  Epoch: 302  Training loss = 2.1182  Validation loss = 6.7589  \n",
      "\n",
      "Fold: 8  Epoch: 303  Training loss = 2.1179  Validation loss = 6.7584  \n",
      "\n",
      "Fold: 8  Epoch: 304  Training loss = 2.1176  Validation loss = 6.7579  \n",
      "\n",
      "Fold: 8  Epoch: 305  Training loss = 2.1174  Validation loss = 6.7575  \n",
      "\n",
      "Fold: 8  Epoch: 306  Training loss = 2.1172  Validation loss = 6.7572  \n",
      "\n",
      "Fold: 8  Epoch: 307  Training loss = 2.1170  Validation loss = 6.7569  \n",
      "\n",
      "Fold: 8  Epoch: 308  Training loss = 2.1167  Validation loss = 6.7564  \n",
      "\n",
      "Fold: 8  Epoch: 309  Training loss = 2.1165  Validation loss = 6.7561  \n",
      "\n",
      "Fold: 8  Epoch: 310  Training loss = 2.1163  Validation loss = 6.7557  \n",
      "\n",
      "Fold: 8  Epoch: 311  Training loss = 2.1160  Validation loss = 6.7552  \n",
      "\n",
      "Fold: 8  Epoch: 312  Training loss = 2.1157  Validation loss = 6.7547  \n",
      "\n",
      "Fold: 8  Epoch: 313  Training loss = 2.1156  Validation loss = 6.7544  \n",
      "\n",
      "Fold: 8  Epoch: 314  Training loss = 2.1153  Validation loss = 6.7541  \n",
      "\n",
      "Fold: 8  Epoch: 315  Training loss = 2.1150  Validation loss = 6.7536  \n",
      "\n",
      "Fold: 8  Epoch: 316  Training loss = 2.1148  Validation loss = 6.7531  \n",
      "\n",
      "Fold: 8  Epoch: 317  Training loss = 2.1146  Validation loss = 6.7528  \n",
      "\n",
      "Fold: 8  Epoch: 318  Training loss = 2.1144  Validation loss = 6.7524  \n",
      "\n",
      "Fold: 8  Epoch: 319  Training loss = 2.1140  Validation loss = 6.7519  \n",
      "\n",
      "Fold: 8  Epoch: 320  Training loss = 2.1137  Validation loss = 6.7515  \n",
      "\n",
      "Fold: 8  Epoch: 321  Training loss = 2.1134  Validation loss = 6.7508  \n",
      "\n",
      "Fold: 8  Epoch: 322  Training loss = 2.1131  Validation loss = 6.7504  \n",
      "\n",
      "Fold: 8  Epoch: 323  Training loss = 2.1128  Validation loss = 6.7500  \n",
      "\n",
      "Fold: 8  Epoch: 324  Training loss = 2.1125  Validation loss = 6.7496  \n",
      "\n",
      "Fold: 8  Epoch: 325  Training loss = 2.1123  Validation loss = 6.7492  \n",
      "\n",
      "Fold: 8  Epoch: 326  Training loss = 2.1120  Validation loss = 6.7487  \n",
      "\n",
      "Fold: 8  Epoch: 327  Training loss = 2.1118  Validation loss = 6.7483  \n",
      "\n",
      "Fold: 8  Epoch: 328  Training loss = 2.1115  Validation loss = 6.7479  \n",
      "\n",
      "Fold: 8  Epoch: 329  Training loss = 2.1113  Validation loss = 6.7475  \n",
      "\n",
      "Fold: 8  Epoch: 330  Training loss = 2.1110  Validation loss = 6.7470  \n",
      "\n",
      "Fold: 8  Epoch: 331  Training loss = 2.1108  Validation loss = 6.7466  \n",
      "\n",
      "Fold: 8  Epoch: 332  Training loss = 2.1106  Validation loss = 6.7463  \n",
      "\n",
      "Fold: 8  Epoch: 333  Training loss = 2.1103  Validation loss = 6.7457  \n",
      "\n",
      "Fold: 8  Epoch: 334  Training loss = 2.1100  Validation loss = 6.7453  \n",
      "\n",
      "Fold: 8  Epoch: 335  Training loss = 2.1097  Validation loss = 6.7449  \n",
      "\n",
      "Fold: 8  Epoch: 336  Training loss = 2.1095  Validation loss = 6.7444  \n",
      "\n",
      "Fold: 8  Epoch: 337  Training loss = 2.1092  Validation loss = 6.7441  \n",
      "\n",
      "Fold: 8  Epoch: 338  Training loss = 2.1090  Validation loss = 6.7437  \n",
      "\n",
      "Fold: 8  Epoch: 339  Training loss = 2.1088  Validation loss = 6.7433  \n",
      "\n",
      "Fold: 8  Epoch: 340  Training loss = 2.1085  Validation loss = 6.7428  \n",
      "\n",
      "Fold: 8  Epoch: 341  Training loss = 2.1082  Validation loss = 6.7423  \n",
      "\n",
      "Fold: 8  Epoch: 342  Training loss = 2.1079  Validation loss = 6.7418  \n",
      "\n",
      "Fold: 8  Epoch: 343  Training loss = 2.1077  Validation loss = 6.7414  \n",
      "\n",
      "Fold: 8  Epoch: 344  Training loss = 2.1074  Validation loss = 6.7409  \n",
      "\n",
      "Fold: 8  Epoch: 345  Training loss = 2.1072  Validation loss = 6.7405  \n",
      "\n",
      "Fold: 8  Epoch: 346  Training loss = 2.1069  Validation loss = 6.7401  \n",
      "\n",
      "Fold: 8  Epoch: 347  Training loss = 2.1066  Validation loss = 6.7396  \n",
      "\n",
      "Fold: 8  Epoch: 348  Training loss = 2.1065  Validation loss = 6.7393  \n",
      "\n",
      "Fold: 8  Epoch: 349  Training loss = 2.1062  Validation loss = 6.7388  \n",
      "\n",
      "Fold: 8  Epoch: 350  Training loss = 2.1059  Validation loss = 6.7384  \n",
      "\n",
      "Fold: 8  Epoch: 351  Training loss = 2.1057  Validation loss = 6.7380  \n",
      "\n",
      "Fold: 8  Epoch: 352  Training loss = 2.1054  Validation loss = 6.7375  \n",
      "\n",
      "Fold: 8  Epoch: 353  Training loss = 2.1052  Validation loss = 6.7372  \n",
      "\n",
      "Fold: 8  Epoch: 354  Training loss = 2.1050  Validation loss = 6.7368  \n",
      "\n",
      "Fold: 8  Epoch: 355  Training loss = 2.1047  Validation loss = 6.7363  \n",
      "\n",
      "Fold: 8  Epoch: 356  Training loss = 2.1045  Validation loss = 6.7359  \n",
      "\n",
      "Fold: 8  Epoch: 357  Training loss = 2.1042  Validation loss = 6.7355  \n",
      "\n",
      "Fold: 8  Epoch: 358  Training loss = 2.1039  Validation loss = 6.7350  \n",
      "\n",
      "Fold: 8  Epoch: 359  Training loss = 2.1036  Validation loss = 6.7345  \n",
      "\n",
      "Fold: 8  Epoch: 360  Training loss = 2.1034  Validation loss = 6.7341  \n",
      "\n",
      "Fold: 8  Epoch: 361  Training loss = 2.1031  Validation loss = 6.7336  \n",
      "\n",
      "Fold: 8  Epoch: 362  Training loss = 2.1029  Validation loss = 6.7333  \n",
      "\n",
      "Fold: 8  Epoch: 363  Training loss = 2.1025  Validation loss = 6.7328  \n",
      "\n",
      "Fold: 8  Epoch: 364  Training loss = 2.1023  Validation loss = 6.7324  \n",
      "\n",
      "Fold: 8  Epoch: 365  Training loss = 2.1021  Validation loss = 6.7320  \n",
      "\n",
      "Fold: 8  Epoch: 366  Training loss = 2.1018  Validation loss = 6.7316  \n",
      "\n",
      "Fold: 8  Epoch: 367  Training loss = 2.1017  Validation loss = 6.7313  \n",
      "\n",
      "Fold: 8  Epoch: 368  Training loss = 2.1014  Validation loss = 6.7309  \n",
      "\n",
      "Fold: 8  Epoch: 369  Training loss = 2.1012  Validation loss = 6.7305  \n",
      "\n",
      "Fold: 8  Epoch: 370  Training loss = 2.1009  Validation loss = 6.7300  \n",
      "\n",
      "Fold: 8  Epoch: 371  Training loss = 2.1006  Validation loss = 6.7295  \n",
      "\n",
      "Fold: 8  Epoch: 372  Training loss = 2.1005  Validation loss = 6.7292  \n",
      "\n",
      "Fold: 8  Epoch: 373  Training loss = 2.1002  Validation loss = 6.7287  \n",
      "\n",
      "Fold: 8  Epoch: 374  Training loss = 2.0999  Validation loss = 6.7281  \n",
      "\n",
      "Fold: 8  Epoch: 375  Training loss = 2.0996  Validation loss = 6.7278  \n",
      "\n",
      "Fold: 8  Epoch: 376  Training loss = 2.0994  Validation loss = 6.7274  \n",
      "\n",
      "Fold: 8  Epoch: 377  Training loss = 2.0992  Validation loss = 6.7270  \n",
      "\n",
      "Fold: 8  Epoch: 378  Training loss = 2.0989  Validation loss = 6.7265  \n",
      "\n",
      "Fold: 8  Epoch: 379  Training loss = 2.0986  Validation loss = 6.7260  \n",
      "\n",
      "Fold: 8  Epoch: 380  Training loss = 2.0984  Validation loss = 6.7257  \n",
      "\n",
      "Fold: 8  Epoch: 381  Training loss = 2.0982  Validation loss = 6.7252  \n",
      "\n",
      "Fold: 8  Epoch: 382  Training loss = 2.0979  Validation loss = 6.7248  \n",
      "\n",
      "Fold: 8  Epoch: 383  Training loss = 2.0978  Validation loss = 6.7245  \n",
      "\n",
      "Fold: 8  Epoch: 384  Training loss = 2.0976  Validation loss = 6.7242  \n",
      "\n",
      "Fold: 8  Epoch: 385  Training loss = 2.0974  Validation loss = 6.7239  \n",
      "\n",
      "Fold: 8  Epoch: 386  Training loss = 2.0971  Validation loss = 6.7235  \n",
      "\n",
      "Fold: 8  Epoch: 387  Training loss = 2.0970  Validation loss = 6.7232  \n",
      "\n",
      "Fold: 8  Epoch: 388  Training loss = 2.0966  Validation loss = 6.7227  \n",
      "\n",
      "Fold: 8  Epoch: 389  Training loss = 2.0964  Validation loss = 6.7224  \n",
      "\n",
      "Fold: 8  Epoch: 390  Training loss = 2.0962  Validation loss = 6.7219  \n",
      "\n",
      "Fold: 8  Epoch: 391  Training loss = 2.0959  Validation loss = 6.7215  \n",
      "\n",
      "Fold: 8  Epoch: 392  Training loss = 2.0957  Validation loss = 6.7211  \n",
      "\n",
      "Fold: 8  Epoch: 393  Training loss = 2.0954  Validation loss = 6.7206  \n",
      "\n",
      "Fold: 8  Epoch: 394  Training loss = 2.0952  Validation loss = 6.7201  \n",
      "\n",
      "Fold: 8  Epoch: 395  Training loss = 2.0949  Validation loss = 6.7196  \n",
      "\n",
      "Fold: 8  Epoch: 396  Training loss = 2.0947  Validation loss = 6.7193  \n",
      "\n",
      "Fold: 8  Epoch: 397  Training loss = 2.0945  Validation loss = 6.7189  \n",
      "\n",
      "Fold: 8  Epoch: 398  Training loss = 2.0942  Validation loss = 6.7185  \n",
      "\n",
      "Fold: 8  Epoch: 399  Training loss = 2.0940  Validation loss = 6.7181  \n",
      "\n",
      "Fold: 8  Epoch: 400  Training loss = 2.0937  Validation loss = 6.7177  \n",
      "\n",
      "Fold: 8  Epoch: 401  Training loss = 2.0935  Validation loss = 6.7173  \n",
      "\n",
      "Fold: 8  Epoch: 402  Training loss = 2.0933  Validation loss = 6.7170  \n",
      "\n",
      "Fold: 8  Epoch: 403  Training loss = 2.0931  Validation loss = 6.7166  \n",
      "\n",
      "Fold: 8  Epoch: 404  Training loss = 2.0928  Validation loss = 6.7162  \n",
      "\n",
      "Fold: 8  Epoch: 405  Training loss = 2.0926  Validation loss = 6.7157  \n",
      "\n",
      "Fold: 8  Epoch: 406  Training loss = 2.0922  Validation loss = 6.7151  \n",
      "\n",
      "Fold: 8  Epoch: 407  Training loss = 2.0919  Validation loss = 6.7146  \n",
      "\n",
      "Fold: 8  Epoch: 408  Training loss = 2.0917  Validation loss = 6.7142  \n",
      "\n",
      "Fold: 8  Epoch: 409  Training loss = 2.0915  Validation loss = 6.7138  \n",
      "\n",
      "Fold: 8  Epoch: 410  Training loss = 2.0913  Validation loss = 6.7135  \n",
      "\n",
      "Fold: 8  Epoch: 411  Training loss = 2.0910  Validation loss = 6.7131  \n",
      "\n",
      "Fold: 8  Epoch: 412  Training loss = 2.0908  Validation loss = 6.7127  \n",
      "\n",
      "Fold: 8  Epoch: 413  Training loss = 2.0905  Validation loss = 6.7122  \n",
      "\n",
      "Fold: 8  Epoch: 414  Training loss = 2.0902  Validation loss = 6.7117  \n",
      "\n",
      "Fold: 8  Epoch: 415  Training loss = 2.0899  Validation loss = 6.7112  \n",
      "\n",
      "Fold: 8  Epoch: 416  Training loss = 2.0896  Validation loss = 6.7107  \n",
      "\n",
      "Fold: 8  Epoch: 417  Training loss = 2.0893  Validation loss = 6.7102  \n",
      "\n",
      "Fold: 8  Epoch: 418  Training loss = 2.0891  Validation loss = 6.7098  \n",
      "\n",
      "Fold: 8  Epoch: 419  Training loss = 2.0889  Validation loss = 6.7093  \n",
      "\n",
      "Fold: 8  Epoch: 420  Training loss = 2.0886  Validation loss = 6.7089  \n",
      "\n",
      "Fold: 8  Epoch: 421  Training loss = 2.0884  Validation loss = 6.7085  \n",
      "\n",
      "Fold: 8  Epoch: 422  Training loss = 2.0881  Validation loss = 6.7081  \n",
      "\n",
      "Fold: 8  Epoch: 423  Training loss = 2.0879  Validation loss = 6.7076  \n",
      "\n",
      "Fold: 8  Epoch: 424  Training loss = 2.0877  Validation loss = 6.7073  \n",
      "\n",
      "Fold: 8  Epoch: 425  Training loss = 2.0875  Validation loss = 6.7070  \n",
      "\n",
      "Fold: 8  Epoch: 426  Training loss = 2.0872  Validation loss = 6.7065  \n",
      "\n",
      "Fold: 8  Epoch: 427  Training loss = 2.0870  Validation loss = 6.7061  \n",
      "\n",
      "Fold: 8  Epoch: 428  Training loss = 2.0868  Validation loss = 6.7058  \n",
      "\n",
      "Fold: 8  Epoch: 429  Training loss = 2.0866  Validation loss = 6.7054  \n",
      "\n",
      "Fold: 8  Epoch: 430  Training loss = 2.0862  Validation loss = 6.7048  \n",
      "\n",
      "Fold: 8  Epoch: 431  Training loss = 2.0860  Validation loss = 6.7044  \n",
      "\n",
      "Fold: 8  Epoch: 432  Training loss = 2.0858  Validation loss = 6.7042  \n",
      "\n",
      "Fold: 8  Epoch: 433  Training loss = 2.0856  Validation loss = 6.7038  \n",
      "\n",
      "Fold: 8  Epoch: 434  Training loss = 2.0853  Validation loss = 6.7032  \n",
      "\n",
      "Fold: 8  Epoch: 435  Training loss = 2.0851  Validation loss = 6.7029  \n",
      "\n",
      "Fold: 8  Epoch: 436  Training loss = 2.0848  Validation loss = 6.7023  \n",
      "\n",
      "Fold: 8  Epoch: 437  Training loss = 2.0846  Validation loss = 6.7020  \n",
      "\n",
      "Fold: 8  Epoch: 438  Training loss = 2.0844  Validation loss = 6.7017  \n",
      "\n",
      "Fold: 8  Epoch: 439  Training loss = 2.0842  Validation loss = 6.7013  \n",
      "\n",
      "Fold: 8  Epoch: 440  Training loss = 2.0840  Validation loss = 6.7010  \n",
      "\n",
      "Fold: 8  Epoch: 441  Training loss = 2.0838  Validation loss = 6.7007  \n",
      "\n",
      "Fold: 8  Epoch: 442  Training loss = 2.0835  Validation loss = 6.7001  \n",
      "\n",
      "Fold: 8  Epoch: 443  Training loss = 2.0834  Validation loss = 6.6999  \n",
      "\n",
      "Fold: 8  Epoch: 444  Training loss = 2.0832  Validation loss = 6.6995  \n",
      "\n",
      "Fold: 8  Epoch: 445  Training loss = 2.0829  Validation loss = 6.6991  \n",
      "\n",
      "Fold: 8  Epoch: 446  Training loss = 2.0827  Validation loss = 6.6987  \n",
      "\n",
      "Fold: 8  Epoch: 447  Training loss = 2.0824  Validation loss = 6.6982  \n",
      "\n",
      "Fold: 8  Epoch: 448  Training loss = 2.0821  Validation loss = 6.6977  \n",
      "\n",
      "Fold: 8  Epoch: 449  Training loss = 2.0818  Validation loss = 6.6972  \n",
      "\n",
      "Fold: 8  Epoch: 450  Training loss = 2.0815  Validation loss = 6.6967  \n",
      "\n",
      "Fold: 8  Epoch: 451  Training loss = 2.0813  Validation loss = 6.6963  \n",
      "\n",
      "Fold: 8  Epoch: 452  Training loss = 2.0812  Validation loss = 6.6961  \n",
      "\n",
      "Fold: 8  Epoch: 453  Training loss = 2.0810  Validation loss = 6.6958  \n",
      "\n",
      "Fold: 8  Epoch: 454  Training loss = 2.0807  Validation loss = 6.6954  \n",
      "\n",
      "Fold: 8  Epoch: 455  Training loss = 2.0806  Validation loss = 6.6950  \n",
      "\n",
      "Fold: 8  Epoch: 456  Training loss = 2.0804  Validation loss = 6.6947  \n",
      "\n",
      "Fold: 8  Epoch: 457  Training loss = 2.0802  Validation loss = 6.6943  \n",
      "\n",
      "Fold: 8  Epoch: 458  Training loss = 2.0800  Validation loss = 6.6939  \n",
      "\n",
      "Fold: 8  Epoch: 459  Training loss = 2.0797  Validation loss = 6.6935  \n",
      "\n",
      "Fold: 8  Epoch: 460  Training loss = 2.0795  Validation loss = 6.6931  \n",
      "\n",
      "Fold: 8  Epoch: 461  Training loss = 2.0792  Validation loss = 6.6927  \n",
      "\n",
      "Fold: 8  Epoch: 462  Training loss = 2.0790  Validation loss = 6.6924  \n",
      "\n",
      "Fold: 8  Epoch: 463  Training loss = 2.0787  Validation loss = 6.6918  \n",
      "\n",
      "Fold: 8  Epoch: 464  Training loss = 2.0784  Validation loss = 6.6913  \n",
      "\n",
      "Fold: 8  Epoch: 465  Training loss = 2.0782  Validation loss = 6.6909  \n",
      "\n",
      "Fold: 8  Epoch: 466  Training loss = 2.0780  Validation loss = 6.6905  \n",
      "\n",
      "Fold: 8  Epoch: 467  Training loss = 2.0777  Validation loss = 6.6901  \n",
      "\n",
      "Fold: 8  Epoch: 468  Training loss = 2.0776  Validation loss = 6.6898  \n",
      "\n",
      "Fold: 8  Epoch: 469  Training loss = 2.0774  Validation loss = 6.6895  \n",
      "\n",
      "Fold: 8  Epoch: 470  Training loss = 2.0772  Validation loss = 6.6891  \n",
      "\n",
      "Fold: 8  Epoch: 471  Training loss = 2.0769  Validation loss = 6.6886  \n",
      "\n",
      "Fold: 8  Epoch: 472  Training loss = 2.0766  Validation loss = 6.6882  \n",
      "\n",
      "Fold: 8  Epoch: 473  Training loss = 2.0764  Validation loss = 6.6877  \n",
      "\n",
      "Fold: 8  Epoch: 474  Training loss = 2.0760  Validation loss = 6.6871  \n",
      "\n",
      "Fold: 8  Epoch: 475  Training loss = 2.0757  Validation loss = 6.6866  \n",
      "\n",
      "Fold: 8  Epoch: 476  Training loss = 2.0755  Validation loss = 6.6861  \n",
      "\n",
      "Fold: 8  Epoch: 477  Training loss = 2.0753  Validation loss = 6.6858  \n",
      "\n",
      "Fold: 8  Epoch: 478  Training loss = 2.0751  Validation loss = 6.6854  \n",
      "\n",
      "Fold: 8  Epoch: 479  Training loss = 2.0748  Validation loss = 6.6851  \n",
      "\n",
      "Fold: 8  Epoch: 480  Training loss = 2.0745  Validation loss = 6.6846  \n",
      "\n",
      "Fold: 8  Epoch: 481  Training loss = 2.0744  Validation loss = 6.6843  \n",
      "\n",
      "Fold: 8  Epoch: 482  Training loss = 2.0741  Validation loss = 6.6839  \n",
      "\n",
      "Fold: 8  Epoch: 483  Training loss = 2.0740  Validation loss = 6.6836  \n",
      "\n",
      "Fold: 8  Epoch: 484  Training loss = 2.0737  Validation loss = 6.6831  \n",
      "\n",
      "Fold: 8  Epoch: 485  Training loss = 2.0735  Validation loss = 6.6828  \n",
      "\n",
      "Fold: 8  Epoch: 486  Training loss = 2.0733  Validation loss = 6.6825  \n",
      "\n",
      "Fold: 8  Epoch: 487  Training loss = 2.0731  Validation loss = 6.6821  \n",
      "\n",
      "Fold: 8  Epoch: 488  Training loss = 2.0729  Validation loss = 6.6817  \n",
      "\n",
      "Fold: 8  Epoch: 489  Training loss = 2.0727  Validation loss = 6.6814  \n",
      "\n",
      "Fold: 8  Epoch: 490  Training loss = 2.0725  Validation loss = 6.6811  \n",
      "\n",
      "Fold: 8  Epoch: 491  Training loss = 2.0722  Validation loss = 6.6806  \n",
      "\n",
      "Fold: 8  Epoch: 492  Training loss = 2.0720  Validation loss = 6.6801  \n",
      "\n",
      "Fold: 8  Epoch: 493  Training loss = 2.0717  Validation loss = 6.6797  \n",
      "\n",
      "Fold: 8  Epoch: 494  Training loss = 2.0715  Validation loss = 6.6794  \n",
      "\n",
      "Fold: 8  Epoch: 495  Training loss = 2.0713  Validation loss = 6.6790  \n",
      "\n",
      "Fold: 8  Epoch: 496  Training loss = 2.0711  Validation loss = 6.6786  \n",
      "\n",
      "Fold: 8  Epoch: 497  Training loss = 2.0709  Validation loss = 6.6783  \n",
      "\n",
      "Fold: 8  Epoch: 498  Training loss = 2.0707  Validation loss = 6.6779  \n",
      "\n",
      "Fold: 8  Epoch: 499  Training loss = 2.0704  Validation loss = 6.6774  \n",
      "\n",
      "Fold: 8  Epoch: 500  Training loss = 2.0701  Validation loss = 6.6769  \n",
      "\n",
      "Check model:  Fold: 8  Optimal epoch: 500  \n",
      "\n",
      "Fold: 9  Epoch: 1  Training loss = 2.5981  Validation loss = 10.1996  \n",
      "\n",
      "Fold: 9  Epoch: 2  Training loss = 2.5978  Validation loss = 10.1990  \n",
      "\n",
      "Fold: 9  Epoch: 3  Training loss = 2.5975  Validation loss = 10.1982  \n",
      "\n",
      "Fold: 9  Epoch: 4  Training loss = 2.5972  Validation loss = 10.1977  \n",
      "\n",
      "Fold: 9  Epoch: 5  Training loss = 2.5969  Validation loss = 10.1971  \n",
      "\n",
      "Fold: 9  Epoch: 6  Training loss = 2.5966  Validation loss = 10.1965  \n",
      "\n",
      "Fold: 9  Epoch: 7  Training loss = 2.5964  Validation loss = 10.1960  \n",
      "\n",
      "Fold: 9  Epoch: 8  Training loss = 2.5960  Validation loss = 10.1953  \n",
      "\n",
      "Fold: 9  Epoch: 9  Training loss = 2.5958  Validation loss = 10.1948  \n",
      "\n",
      "Fold: 9  Epoch: 10  Training loss = 2.5954  Validation loss = 10.1940  \n",
      "\n",
      "Fold: 9  Epoch: 11  Training loss = 2.5951  Validation loss = 10.1935  \n",
      "\n",
      "Fold: 9  Epoch: 12  Training loss = 2.5948  Validation loss = 10.1928  \n",
      "\n",
      "Fold: 9  Epoch: 13  Training loss = 2.5945  Validation loss = 10.1921  \n",
      "\n",
      "Fold: 9  Epoch: 14  Training loss = 2.5942  Validation loss = 10.1915  \n",
      "\n",
      "Fold: 9  Epoch: 15  Training loss = 2.5940  Validation loss = 10.1911  \n",
      "\n",
      "Fold: 9  Epoch: 16  Training loss = 2.5936  Validation loss = 10.1903  \n",
      "\n",
      "Fold: 9  Epoch: 17  Training loss = 2.5934  Validation loss = 10.1898  \n",
      "\n",
      "Fold: 9  Epoch: 18  Training loss = 2.5930  Validation loss = 10.1891  \n",
      "\n",
      "Fold: 9  Epoch: 19  Training loss = 2.5927  Validation loss = 10.1884  \n",
      "\n",
      "Fold: 9  Epoch: 20  Training loss = 2.5924  Validation loss = 10.1877  \n",
      "\n",
      "Fold: 9  Epoch: 21  Training loss = 2.5921  Validation loss = 10.1871  \n",
      "\n",
      "Fold: 9  Epoch: 22  Training loss = 2.5919  Validation loss = 10.1867  \n",
      "\n",
      "Fold: 9  Epoch: 23  Training loss = 2.5916  Validation loss = 10.1861  \n",
      "\n",
      "Fold: 9  Epoch: 24  Training loss = 2.5913  Validation loss = 10.1855  \n",
      "\n",
      "Fold: 9  Epoch: 25  Training loss = 2.5911  Validation loss = 10.1851  \n",
      "\n",
      "Fold: 9  Epoch: 26  Training loss = 2.5909  Validation loss = 10.1847  \n",
      "\n",
      "Fold: 9  Epoch: 27  Training loss = 2.5905  Validation loss = 10.1839  \n",
      "\n",
      "Fold: 9  Epoch: 28  Training loss = 2.5903  Validation loss = 10.1835  \n",
      "\n",
      "Fold: 9  Epoch: 29  Training loss = 2.5900  Validation loss = 10.1828  \n",
      "\n",
      "Fold: 9  Epoch: 30  Training loss = 2.5897  Validation loss = 10.1823  \n",
      "\n",
      "Fold: 9  Epoch: 31  Training loss = 2.5894  Validation loss = 10.1817  \n",
      "\n",
      "Fold: 9  Epoch: 32  Training loss = 2.5891  Validation loss = 10.1810  \n",
      "\n",
      "Fold: 9  Epoch: 33  Training loss = 2.5888  Validation loss = 10.1804  \n",
      "\n",
      "Fold: 9  Epoch: 34  Training loss = 2.5886  Validation loss = 10.1799  \n",
      "\n",
      "Fold: 9  Epoch: 35  Training loss = 2.5882  Validation loss = 10.1792  \n",
      "\n",
      "Fold: 9  Epoch: 36  Training loss = 2.5879  Validation loss = 10.1785  \n",
      "\n",
      "Fold: 9  Epoch: 37  Training loss = 2.5875  Validation loss = 10.1777  \n",
      "\n",
      "Fold: 9  Epoch: 38  Training loss = 2.5873  Validation loss = 10.1772  \n",
      "\n",
      "Fold: 9  Epoch: 39  Training loss = 2.5870  Validation loss = 10.1768  \n",
      "\n",
      "Fold: 9  Epoch: 40  Training loss = 2.5867  Validation loss = 10.1761  \n",
      "\n",
      "Fold: 9  Epoch: 41  Training loss = 2.5865  Validation loss = 10.1756  \n",
      "\n",
      "Fold: 9  Epoch: 42  Training loss = 2.5862  Validation loss = 10.1751  \n",
      "\n",
      "Fold: 9  Epoch: 43  Training loss = 2.5860  Validation loss = 10.1746  \n",
      "\n",
      "Fold: 9  Epoch: 44  Training loss = 2.5857  Validation loss = 10.1741  \n",
      "\n",
      "Fold: 9  Epoch: 45  Training loss = 2.5854  Validation loss = 10.1734  \n",
      "\n",
      "Fold: 9  Epoch: 46  Training loss = 2.5851  Validation loss = 10.1727  \n",
      "\n",
      "Fold: 9  Epoch: 47  Training loss = 2.5849  Validation loss = 10.1724  \n",
      "\n",
      "Fold: 9  Epoch: 48  Training loss = 2.5848  Validation loss = 10.1720  \n",
      "\n",
      "Fold: 9  Epoch: 49  Training loss = 2.5845  Validation loss = 10.1715  \n",
      "\n",
      "Fold: 9  Epoch: 50  Training loss = 2.5842  Validation loss = 10.1709  \n",
      "\n",
      "Fold: 9  Epoch: 51  Training loss = 2.5838  Validation loss = 10.1700  \n",
      "\n",
      "Fold: 9  Epoch: 52  Training loss = 2.5835  Validation loss = 10.1693  \n",
      "\n",
      "Fold: 9  Epoch: 53  Training loss = 2.5833  Validation loss = 10.1689  \n",
      "\n",
      "Fold: 9  Epoch: 54  Training loss = 2.5831  Validation loss = 10.1686  \n",
      "\n",
      "Fold: 9  Epoch: 55  Training loss = 2.5829  Validation loss = 10.1680  \n",
      "\n",
      "Fold: 9  Epoch: 56  Training loss = 2.5825  Validation loss = 10.1674  \n",
      "\n",
      "Fold: 9  Epoch: 57  Training loss = 2.5823  Validation loss = 10.1669  \n",
      "\n",
      "Fold: 9  Epoch: 58  Training loss = 2.5821  Validation loss = 10.1664  \n",
      "\n",
      "Fold: 9  Epoch: 59  Training loss = 2.5818  Validation loss = 10.1658  \n",
      "\n",
      "Fold: 9  Epoch: 60  Training loss = 2.5815  Validation loss = 10.1652  \n",
      "\n",
      "Fold: 9  Epoch: 61  Training loss = 2.5813  Validation loss = 10.1647  \n",
      "\n",
      "Fold: 9  Epoch: 62  Training loss = 2.5811  Validation loss = 10.1643  \n",
      "\n",
      "Fold: 9  Epoch: 63  Training loss = 2.5809  Validation loss = 10.1638  \n",
      "\n",
      "Fold: 9  Epoch: 64  Training loss = 2.5806  Validation loss = 10.1633  \n",
      "\n",
      "Fold: 9  Epoch: 65  Training loss = 2.5803  Validation loss = 10.1626  \n",
      "\n",
      "Fold: 9  Epoch: 66  Training loss = 2.5800  Validation loss = 10.1621  \n",
      "\n",
      "Fold: 9  Epoch: 67  Training loss = 2.5797  Validation loss = 10.1615  \n",
      "\n",
      "Fold: 9  Epoch: 68  Training loss = 2.5794  Validation loss = 10.1608  \n",
      "\n",
      "Fold: 9  Epoch: 69  Training loss = 2.5791  Validation loss = 10.1603  \n",
      "\n",
      "Fold: 9  Epoch: 70  Training loss = 2.5789  Validation loss = 10.1598  \n",
      "\n",
      "Fold: 9  Epoch: 71  Training loss = 2.5786  Validation loss = 10.1592  \n",
      "\n",
      "Fold: 9  Epoch: 72  Training loss = 2.5783  Validation loss = 10.1585  \n",
      "\n",
      "Fold: 9  Epoch: 73  Training loss = 2.5781  Validation loss = 10.1581  \n",
      "\n",
      "Fold: 9  Epoch: 74  Training loss = 2.5779  Validation loss = 10.1576  \n",
      "\n",
      "Fold: 9  Epoch: 75  Training loss = 2.5776  Validation loss = 10.1571  \n",
      "\n",
      "Fold: 9  Epoch: 76  Training loss = 2.5773  Validation loss = 10.1564  \n",
      "\n",
      "Fold: 9  Epoch: 77  Training loss = 2.5770  Validation loss = 10.1558  \n",
      "\n",
      "Fold: 9  Epoch: 78  Training loss = 2.5767  Validation loss = 10.1553  \n",
      "\n",
      "Fold: 9  Epoch: 79  Training loss = 2.5764  Validation loss = 10.1546  \n",
      "\n",
      "Fold: 9  Epoch: 80  Training loss = 2.5762  Validation loss = 10.1541  \n",
      "\n",
      "Fold: 9  Epoch: 81  Training loss = 2.5759  Validation loss = 10.1535  \n",
      "\n",
      "Fold: 9  Epoch: 82  Training loss = 2.5756  Validation loss = 10.1529  \n",
      "\n",
      "Fold: 9  Epoch: 83  Training loss = 2.5753  Validation loss = 10.1522  \n",
      "\n",
      "Fold: 9  Epoch: 84  Training loss = 2.5750  Validation loss = 10.1517  \n",
      "\n",
      "Fold: 9  Epoch: 85  Training loss = 2.5748  Validation loss = 10.1511  \n",
      "\n",
      "Fold: 9  Epoch: 86  Training loss = 2.5745  Validation loss = 10.1504  \n",
      "\n",
      "Fold: 9  Epoch: 87  Training loss = 2.5742  Validation loss = 10.1499  \n",
      "\n",
      "Fold: 9  Epoch: 88  Training loss = 2.5740  Validation loss = 10.1494  \n",
      "\n",
      "Fold: 9  Epoch: 89  Training loss = 2.5735  Validation loss = 10.1485  \n",
      "\n",
      "Fold: 9  Epoch: 90  Training loss = 2.5732  Validation loss = 10.1478  \n",
      "\n",
      "Fold: 9  Epoch: 91  Training loss = 2.5729  Validation loss = 10.1472  \n",
      "\n",
      "Fold: 9  Epoch: 92  Training loss = 2.5727  Validation loss = 10.1467  \n",
      "\n",
      "Fold: 9  Epoch: 93  Training loss = 2.5724  Validation loss = 10.1461  \n",
      "\n",
      "Fold: 9  Epoch: 94  Training loss = 2.5721  Validation loss = 10.1454  \n",
      "\n",
      "Fold: 9  Epoch: 95  Training loss = 2.5718  Validation loss = 10.1450  \n",
      "\n",
      "Fold: 9  Epoch: 96  Training loss = 2.5715  Validation loss = 10.1443  \n",
      "\n",
      "Fold: 9  Epoch: 97  Training loss = 2.5712  Validation loss = 10.1436  \n",
      "\n",
      "Fold: 9  Epoch: 98  Training loss = 2.5710  Validation loss = 10.1430  \n",
      "\n",
      "Fold: 9  Epoch: 99  Training loss = 2.5707  Validation loss = 10.1425  \n",
      "\n",
      "Fold: 9  Epoch: 100  Training loss = 2.5705  Validation loss = 10.1420  \n",
      "\n",
      "Fold: 9  Epoch: 101  Training loss = 2.5703  Validation loss = 10.1416  \n",
      "\n",
      "Fold: 9  Epoch: 102  Training loss = 2.5701  Validation loss = 10.1411  \n",
      "\n",
      "Fold: 9  Epoch: 103  Training loss = 2.5697  Validation loss = 10.1405  \n",
      "\n",
      "Fold: 9  Epoch: 104  Training loss = 2.5694  Validation loss = 10.1398  \n",
      "\n",
      "Fold: 9  Epoch: 105  Training loss = 2.5692  Validation loss = 10.1392  \n",
      "\n",
      "Fold: 9  Epoch: 106  Training loss = 2.5690  Validation loss = 10.1388  \n",
      "\n",
      "Fold: 9  Epoch: 107  Training loss = 2.5687  Validation loss = 10.1382  \n",
      "\n",
      "Fold: 9  Epoch: 108  Training loss = 2.5684  Validation loss = 10.1376  \n",
      "\n",
      "Fold: 9  Epoch: 109  Training loss = 2.5682  Validation loss = 10.1372  \n",
      "\n",
      "Fold: 9  Epoch: 110  Training loss = 2.5678  Validation loss = 10.1364  \n",
      "\n",
      "Fold: 9  Epoch: 111  Training loss = 2.5676  Validation loss = 10.1360  \n",
      "\n",
      "Fold: 9  Epoch: 112  Training loss = 2.5673  Validation loss = 10.1353  \n",
      "\n",
      "Fold: 9  Epoch: 113  Training loss = 2.5671  Validation loss = 10.1348  \n",
      "\n",
      "Fold: 9  Epoch: 114  Training loss = 2.5668  Validation loss = 10.1342  \n",
      "\n",
      "Fold: 9  Epoch: 115  Training loss = 2.5665  Validation loss = 10.1336  \n",
      "\n",
      "Fold: 9  Epoch: 116  Training loss = 2.5662  Validation loss = 10.1330  \n",
      "\n",
      "Fold: 9  Epoch: 117  Training loss = 2.5659  Validation loss = 10.1323  \n",
      "\n",
      "Fold: 9  Epoch: 118  Training loss = 2.5656  Validation loss = 10.1318  \n",
      "\n",
      "Fold: 9  Epoch: 119  Training loss = 2.5653  Validation loss = 10.1312  \n",
      "\n",
      "Fold: 9  Epoch: 120  Training loss = 2.5650  Validation loss = 10.1305  \n",
      "\n",
      "Fold: 9  Epoch: 121  Training loss = 2.5648  Validation loss = 10.1300  \n",
      "\n",
      "Fold: 9  Epoch: 122  Training loss = 2.5645  Validation loss = 10.1294  \n",
      "\n",
      "Fold: 9  Epoch: 123  Training loss = 2.5643  Validation loss = 10.1290  \n",
      "\n",
      "Fold: 9  Epoch: 124  Training loss = 2.5640  Validation loss = 10.1283  \n",
      "\n",
      "Fold: 9  Epoch: 125  Training loss = 2.5637  Validation loss = 10.1277  \n",
      "\n",
      "Fold: 9  Epoch: 126  Training loss = 2.5634  Validation loss = 10.1271  \n",
      "\n",
      "Fold: 9  Epoch: 127  Training loss = 2.5631  Validation loss = 10.1265  \n",
      "\n",
      "Fold: 9  Epoch: 128  Training loss = 2.5628  Validation loss = 10.1258  \n",
      "\n",
      "Fold: 9  Epoch: 129  Training loss = 2.5626  Validation loss = 10.1253  \n",
      "\n",
      "Fold: 9  Epoch: 130  Training loss = 2.5622  Validation loss = 10.1246  \n",
      "\n",
      "Fold: 9  Epoch: 131  Training loss = 2.5619  Validation loss = 10.1238  \n",
      "\n",
      "Fold: 9  Epoch: 132  Training loss = 2.5616  Validation loss = 10.1232  \n",
      "\n",
      "Fold: 9  Epoch: 133  Training loss = 2.5612  Validation loss = 10.1225  \n",
      "\n",
      "Fold: 9  Epoch: 134  Training loss = 2.5609  Validation loss = 10.1219  \n",
      "\n",
      "Fold: 9  Epoch: 135  Training loss = 2.5606  Validation loss = 10.1212  \n",
      "\n",
      "Fold: 9  Epoch: 136  Training loss = 2.5604  Validation loss = 10.1206  \n",
      "\n",
      "Fold: 9  Epoch: 137  Training loss = 2.5601  Validation loss = 10.1200  \n",
      "\n",
      "Fold: 9  Epoch: 138  Training loss = 2.5598  Validation loss = 10.1195  \n",
      "\n",
      "Fold: 9  Epoch: 139  Training loss = 2.5595  Validation loss = 10.1189  \n",
      "\n",
      "Fold: 9  Epoch: 140  Training loss = 2.5593  Validation loss = 10.1183  \n",
      "\n",
      "Fold: 9  Epoch: 141  Training loss = 2.5590  Validation loss = 10.1177  \n",
      "\n",
      "Fold: 9  Epoch: 142  Training loss = 2.5587  Validation loss = 10.1171  \n",
      "\n",
      "Fold: 9  Epoch: 143  Training loss = 2.5583  Validation loss = 10.1163  \n",
      "\n",
      "Fold: 9  Epoch: 144  Training loss = 2.5581  Validation loss = 10.1159  \n",
      "\n",
      "Fold: 9  Epoch: 145  Training loss = 2.5579  Validation loss = 10.1155  \n",
      "\n",
      "Fold: 9  Epoch: 146  Training loss = 2.5576  Validation loss = 10.1149  \n",
      "\n",
      "Fold: 9  Epoch: 147  Training loss = 2.5574  Validation loss = 10.1144  \n",
      "\n",
      "Fold: 9  Epoch: 148  Training loss = 2.5570  Validation loss = 10.1136  \n",
      "\n",
      "Fold: 9  Epoch: 149  Training loss = 2.5568  Validation loss = 10.1132  \n",
      "\n",
      "Fold: 9  Epoch: 150  Training loss = 2.5566  Validation loss = 10.1127  \n",
      "\n",
      "Fold: 9  Epoch: 151  Training loss = 2.5564  Validation loss = 10.1121  \n",
      "\n",
      "Fold: 9  Epoch: 152  Training loss = 2.5561  Validation loss = 10.1116  \n",
      "\n",
      "Fold: 9  Epoch: 153  Training loss = 2.5558  Validation loss = 10.1109  \n",
      "\n",
      "Fold: 9  Epoch: 154  Training loss = 2.5554  Validation loss = 10.1101  \n",
      "\n",
      "Fold: 9  Epoch: 155  Training loss = 2.5551  Validation loss = 10.1095  \n",
      "\n",
      "Fold: 9  Epoch: 156  Training loss = 2.5548  Validation loss = 10.1089  \n",
      "\n",
      "Fold: 9  Epoch: 157  Training loss = 2.5546  Validation loss = 10.1083  \n",
      "\n",
      "Fold: 9  Epoch: 158  Training loss = 2.5543  Validation loss = 10.1078  \n",
      "\n",
      "Fold: 9  Epoch: 159  Training loss = 2.5539  Validation loss = 10.1069  \n",
      "\n",
      "Fold: 9  Epoch: 160  Training loss = 2.5537  Validation loss = 10.1065  \n",
      "\n",
      "Fold: 9  Epoch: 161  Training loss = 2.5534  Validation loss = 10.1058  \n",
      "\n",
      "Fold: 9  Epoch: 162  Training loss = 2.5530  Validation loss = 10.1051  \n",
      "\n",
      "Fold: 9  Epoch: 163  Training loss = 2.5528  Validation loss = 10.1046  \n",
      "\n",
      "Fold: 9  Epoch: 164  Training loss = 2.5525  Validation loss = 10.1040  \n",
      "\n",
      "Fold: 9  Epoch: 165  Training loss = 2.5521  Validation loss = 10.1032  \n",
      "\n",
      "Fold: 9  Epoch: 166  Training loss = 2.5520  Validation loss = 10.1028  \n",
      "\n",
      "Fold: 9  Epoch: 167  Training loss = 2.5518  Validation loss = 10.1024  \n",
      "\n",
      "Fold: 9  Epoch: 168  Training loss = 2.5514  Validation loss = 10.1017  \n",
      "\n",
      "Fold: 9  Epoch: 169  Training loss = 2.5512  Validation loss = 10.1011  \n",
      "\n",
      "Fold: 9  Epoch: 170  Training loss = 2.5510  Validation loss = 10.1007  \n",
      "\n",
      "Fold: 9  Epoch: 171  Training loss = 2.5505  Validation loss = 10.0998  \n",
      "\n",
      "Fold: 9  Epoch: 172  Training loss = 2.5503  Validation loss = 10.0993  \n",
      "\n",
      "Fold: 9  Epoch: 173  Training loss = 2.5500  Validation loss = 10.0987  \n",
      "\n",
      "Fold: 9  Epoch: 174  Training loss = 2.5498  Validation loss = 10.0982  \n",
      "\n",
      "Fold: 9  Epoch: 175  Training loss = 2.5496  Validation loss = 10.0977  \n",
      "\n",
      "Fold: 9  Epoch: 176  Training loss = 2.5493  Validation loss = 10.0971  \n",
      "\n",
      "Fold: 9  Epoch: 177  Training loss = 2.5489  Validation loss = 10.0963  \n",
      "\n",
      "Fold: 9  Epoch: 178  Training loss = 2.5486  Validation loss = 10.0957  \n",
      "\n",
      "Fold: 9  Epoch: 179  Training loss = 2.5483  Validation loss = 10.0950  \n",
      "\n",
      "Fold: 9  Epoch: 180  Training loss = 2.5481  Validation loss = 10.0946  \n",
      "\n",
      "Fold: 9  Epoch: 181  Training loss = 2.5478  Validation loss = 10.0940  \n",
      "\n",
      "Fold: 9  Epoch: 182  Training loss = 2.5477  Validation loss = 10.0937  \n",
      "\n",
      "Fold: 9  Epoch: 183  Training loss = 2.5474  Validation loss = 10.0931  \n",
      "\n",
      "Fold: 9  Epoch: 184  Training loss = 2.5471  Validation loss = 10.0925  \n",
      "\n",
      "Fold: 9  Epoch: 185  Training loss = 2.5468  Validation loss = 10.0919  \n",
      "\n",
      "Fold: 9  Epoch: 186  Training loss = 2.5465  Validation loss = 10.0913  \n",
      "\n",
      "Fold: 9  Epoch: 187  Training loss = 2.5462  Validation loss = 10.0905  \n",
      "\n",
      "Fold: 9  Epoch: 188  Training loss = 2.5459  Validation loss = 10.0898  \n",
      "\n",
      "Fold: 9  Epoch: 189  Training loss = 2.5457  Validation loss = 10.0894  \n",
      "\n",
      "Fold: 9  Epoch: 190  Training loss = 2.5454  Validation loss = 10.0888  \n",
      "\n",
      "Fold: 9  Epoch: 191  Training loss = 2.5452  Validation loss = 10.0883  \n",
      "\n",
      "Fold: 9  Epoch: 192  Training loss = 2.5449  Validation loss = 10.0877  \n",
      "\n",
      "Fold: 9  Epoch: 193  Training loss = 2.5446  Validation loss = 10.0871  \n",
      "\n",
      "Fold: 9  Epoch: 194  Training loss = 2.5444  Validation loss = 10.0867  \n",
      "\n",
      "Fold: 9  Epoch: 195  Training loss = 2.5440  Validation loss = 10.0859  \n",
      "\n",
      "Fold: 9  Epoch: 196  Training loss = 2.5438  Validation loss = 10.0853  \n",
      "\n",
      "Fold: 9  Epoch: 197  Training loss = 2.5435  Validation loss = 10.0846  \n",
      "\n",
      "Fold: 9  Epoch: 198  Training loss = 2.5432  Validation loss = 10.0841  \n",
      "\n",
      "Fold: 9  Epoch: 199  Training loss = 2.5430  Validation loss = 10.0837  \n",
      "\n",
      "Fold: 9  Epoch: 200  Training loss = 2.5428  Validation loss = 10.0832  \n",
      "\n",
      "Fold: 9  Epoch: 201  Training loss = 2.5425  Validation loss = 10.0827  \n",
      "\n",
      "Fold: 9  Epoch: 202  Training loss = 2.5422  Validation loss = 10.0820  \n",
      "\n",
      "Fold: 9  Epoch: 203  Training loss = 2.5419  Validation loss = 10.0814  \n",
      "\n",
      "Fold: 9  Epoch: 204  Training loss = 2.5417  Validation loss = 10.0809  \n",
      "\n",
      "Fold: 9  Epoch: 205  Training loss = 2.5414  Validation loss = 10.0803  \n",
      "\n",
      "Fold: 9  Epoch: 206  Training loss = 2.5411  Validation loss = 10.0796  \n",
      "\n",
      "Fold: 9  Epoch: 207  Training loss = 2.5408  Validation loss = 10.0790  \n",
      "\n",
      "Fold: 9  Epoch: 208  Training loss = 2.5406  Validation loss = 10.0784  \n",
      "\n",
      "Fold: 9  Epoch: 209  Training loss = 2.5403  Validation loss = 10.0778  \n",
      "\n",
      "Fold: 9  Epoch: 210  Training loss = 2.5399  Validation loss = 10.0771  \n",
      "\n",
      "Fold: 9  Epoch: 211  Training loss = 2.5396  Validation loss = 10.0764  \n",
      "\n",
      "Fold: 9  Epoch: 212  Training loss = 2.5395  Validation loss = 10.0761  \n",
      "\n",
      "Fold: 9  Epoch: 213  Training loss = 2.5392  Validation loss = 10.0755  \n",
      "\n",
      "Fold: 9  Epoch: 214  Training loss = 2.5389  Validation loss = 10.0748  \n",
      "\n",
      "Fold: 9  Epoch: 215  Training loss = 2.5386  Validation loss = 10.0743  \n",
      "\n",
      "Fold: 9  Epoch: 216  Training loss = 2.5384  Validation loss = 10.0737  \n",
      "\n",
      "Fold: 9  Epoch: 217  Training loss = 2.5381  Validation loss = 10.0731  \n",
      "\n",
      "Fold: 9  Epoch: 218  Training loss = 2.5379  Validation loss = 10.0726  \n",
      "\n",
      "Fold: 9  Epoch: 219  Training loss = 2.5376  Validation loss = 10.0721  \n",
      "\n",
      "Fold: 9  Epoch: 220  Training loss = 2.5374  Validation loss = 10.0715  \n",
      "\n",
      "Fold: 9  Epoch: 221  Training loss = 2.5371  Validation loss = 10.0709  \n",
      "\n",
      "Fold: 9  Epoch: 222  Training loss = 2.5367  Validation loss = 10.0702  \n",
      "\n",
      "Fold: 9  Epoch: 223  Training loss = 2.5365  Validation loss = 10.0697  \n",
      "\n",
      "Fold: 9  Epoch: 224  Training loss = 2.5363  Validation loss = 10.0692  \n",
      "\n",
      "Fold: 9  Epoch: 225  Training loss = 2.5361  Validation loss = 10.0688  \n",
      "\n",
      "Fold: 9  Epoch: 226  Training loss = 2.5358  Validation loss = 10.0681  \n",
      "\n",
      "Fold: 9  Epoch: 227  Training loss = 2.5355  Validation loss = 10.0675  \n",
      "\n",
      "Fold: 9  Epoch: 228  Training loss = 2.5352  Validation loss = 10.0668  \n",
      "\n",
      "Fold: 9  Epoch: 229  Training loss = 2.5348  Validation loss = 10.0661  \n",
      "\n",
      "Fold: 9  Epoch: 230  Training loss = 2.5345  Validation loss = 10.0654  \n",
      "\n",
      "Fold: 9  Epoch: 231  Training loss = 2.5342  Validation loss = 10.0647  \n",
      "\n",
      "Fold: 9  Epoch: 232  Training loss = 2.5339  Validation loss = 10.0641  \n",
      "\n",
      "Fold: 9  Epoch: 233  Training loss = 2.5337  Validation loss = 10.0635  \n",
      "\n",
      "Fold: 9  Epoch: 234  Training loss = 2.5334  Validation loss = 10.0629  \n",
      "\n",
      "Fold: 9  Epoch: 235  Training loss = 2.5332  Validation loss = 10.0625  \n",
      "\n",
      "Fold: 9  Epoch: 236  Training loss = 2.5330  Validation loss = 10.0620  \n",
      "\n",
      "Fold: 9  Epoch: 237  Training loss = 2.5327  Validation loss = 10.0614  \n",
      "\n",
      "Fold: 9  Epoch: 238  Training loss = 2.5325  Validation loss = 10.0610  \n",
      "\n",
      "Fold: 9  Epoch: 239  Training loss = 2.5322  Validation loss = 10.0603  \n",
      "\n",
      "Fold: 9  Epoch: 240  Training loss = 2.5319  Validation loss = 10.0597  \n",
      "\n",
      "Fold: 9  Epoch: 241  Training loss = 2.5316  Validation loss = 10.0591  \n",
      "\n",
      "Fold: 9  Epoch: 242  Training loss = 2.5313  Validation loss = 10.0585  \n",
      "\n",
      "Fold: 9  Epoch: 243  Training loss = 2.5310  Validation loss = 10.0579  \n",
      "\n",
      "Fold: 9  Epoch: 244  Training loss = 2.5308  Validation loss = 10.0574  \n",
      "\n",
      "Fold: 9  Epoch: 245  Training loss = 2.5305  Validation loss = 10.0567  \n",
      "\n",
      "Fold: 9  Epoch: 246  Training loss = 2.5303  Validation loss = 10.0562  \n",
      "\n",
      "Fold: 9  Epoch: 247  Training loss = 2.5300  Validation loss = 10.0557  \n",
      "\n",
      "Fold: 9  Epoch: 248  Training loss = 2.5298  Validation loss = 10.0552  \n",
      "\n",
      "Fold: 9  Epoch: 249  Training loss = 2.5295  Validation loss = 10.0547  \n",
      "\n",
      "Fold: 9  Epoch: 250  Training loss = 2.5293  Validation loss = 10.0542  \n",
      "\n",
      "Fold: 9  Epoch: 251  Training loss = 2.5291  Validation loss = 10.0537  \n",
      "\n",
      "Fold: 9  Epoch: 252  Training loss = 2.5288  Validation loss = 10.0531  \n",
      "\n",
      "Fold: 9  Epoch: 253  Training loss = 2.5286  Validation loss = 10.0526  \n",
      "\n",
      "Fold: 9  Epoch: 254  Training loss = 2.5283  Validation loss = 10.0521  \n",
      "\n",
      "Fold: 9  Epoch: 255  Training loss = 2.5281  Validation loss = 10.0514  \n",
      "\n",
      "Fold: 9  Epoch: 256  Training loss = 2.5278  Validation loss = 10.0509  \n",
      "\n",
      "Fold: 9  Epoch: 257  Training loss = 2.5275  Validation loss = 10.0502  \n",
      "\n",
      "Fold: 9  Epoch: 258  Training loss = 2.5272  Validation loss = 10.0496  \n",
      "\n",
      "Fold: 9  Epoch: 259  Training loss = 2.5269  Validation loss = 10.0489  \n",
      "\n",
      "Fold: 9  Epoch: 260  Training loss = 2.5267  Validation loss = 10.0485  \n",
      "\n",
      "Fold: 9  Epoch: 261  Training loss = 2.5265  Validation loss = 10.0481  \n",
      "\n",
      "Fold: 9  Epoch: 262  Training loss = 2.5262  Validation loss = 10.0475  \n",
      "\n",
      "Fold: 9  Epoch: 263  Training loss = 2.5260  Validation loss = 10.0471  \n",
      "\n",
      "Fold: 9  Epoch: 264  Training loss = 2.5258  Validation loss = 10.0466  \n",
      "\n",
      "Fold: 9  Epoch: 265  Training loss = 2.5257  Validation loss = 10.0462  \n",
      "\n",
      "Fold: 9  Epoch: 266  Training loss = 2.5254  Validation loss = 10.0456  \n",
      "\n",
      "Fold: 9  Epoch: 267  Training loss = 2.5252  Validation loss = 10.0452  \n",
      "\n",
      "Fold: 9  Epoch: 268  Training loss = 2.5250  Validation loss = 10.0447  \n",
      "\n",
      "Fold: 9  Epoch: 269  Training loss = 2.5248  Validation loss = 10.0444  \n",
      "\n",
      "Fold: 9  Epoch: 270  Training loss = 2.5245  Validation loss = 10.0437  \n",
      "\n",
      "Fold: 9  Epoch: 271  Training loss = 2.5243  Validation loss = 10.0432  \n",
      "\n",
      "Fold: 9  Epoch: 272  Training loss = 2.5240  Validation loss = 10.0427  \n",
      "\n",
      "Fold: 9  Epoch: 273  Training loss = 2.5238  Validation loss = 10.0423  \n",
      "\n",
      "Fold: 9  Epoch: 274  Training loss = 2.5236  Validation loss = 10.0416  \n",
      "\n",
      "Fold: 9  Epoch: 275  Training loss = 2.5233  Validation loss = 10.0410  \n",
      "\n",
      "Fold: 9  Epoch: 276  Training loss = 2.5231  Validation loss = 10.0406  \n",
      "\n",
      "Fold: 9  Epoch: 277  Training loss = 2.5228  Validation loss = 10.0400  \n",
      "\n",
      "Fold: 9  Epoch: 278  Training loss = 2.5226  Validation loss = 10.0395  \n",
      "\n",
      "Fold: 9  Epoch: 279  Training loss = 2.5223  Validation loss = 10.0388  \n",
      "\n",
      "Fold: 9  Epoch: 280  Training loss = 2.5221  Validation loss = 10.0385  \n",
      "\n",
      "Fold: 9  Epoch: 281  Training loss = 2.5217  Validation loss = 10.0377  \n",
      "\n",
      "Fold: 9  Epoch: 282  Training loss = 2.5215  Validation loss = 10.0372  \n",
      "\n",
      "Fold: 9  Epoch: 283  Training loss = 2.5212  Validation loss = 10.0366  \n",
      "\n",
      "Fold: 9  Epoch: 284  Training loss = 2.5209  Validation loss = 10.0359  \n",
      "\n",
      "Fold: 9  Epoch: 285  Training loss = 2.5207  Validation loss = 10.0353  \n",
      "\n",
      "Fold: 9  Epoch: 286  Training loss = 2.5204  Validation loss = 10.0346  \n",
      "\n",
      "Fold: 9  Epoch: 287  Training loss = 2.5202  Validation loss = 10.0341  \n",
      "\n",
      "Fold: 9  Epoch: 288  Training loss = 2.5199  Validation loss = 10.0336  \n",
      "\n",
      "Fold: 9  Epoch: 289  Training loss = 2.5197  Validation loss = 10.0331  \n",
      "\n",
      "Fold: 9  Epoch: 290  Training loss = 2.5194  Validation loss = 10.0324  \n",
      "\n",
      "Fold: 9  Epoch: 291  Training loss = 2.5192  Validation loss = 10.0319  \n",
      "\n",
      "Fold: 9  Epoch: 292  Training loss = 2.5189  Validation loss = 10.0313  \n",
      "\n",
      "Fold: 9  Epoch: 293  Training loss = 2.5186  Validation loss = 10.0308  \n",
      "\n",
      "Fold: 9  Epoch: 294  Training loss = 2.5183  Validation loss = 10.0301  \n",
      "\n",
      "Fold: 9  Epoch: 295  Training loss = 2.5180  Validation loss = 10.0294  \n",
      "\n",
      "Fold: 9  Epoch: 296  Training loss = 2.5178  Validation loss = 10.0290  \n",
      "\n",
      "Fold: 9  Epoch: 297  Training loss = 2.5176  Validation loss = 10.0284  \n",
      "\n",
      "Fold: 9  Epoch: 298  Training loss = 2.5174  Validation loss = 10.0280  \n",
      "\n",
      "Fold: 9  Epoch: 299  Training loss = 2.5171  Validation loss = 10.0275  \n",
      "\n",
      "Fold: 9  Epoch: 300  Training loss = 2.5169  Validation loss = 10.0269  \n",
      "\n",
      "Fold: 9  Epoch: 301  Training loss = 2.5167  Validation loss = 10.0264  \n",
      "\n",
      "Fold: 9  Epoch: 302  Training loss = 2.5163  Validation loss = 10.0257  \n",
      "\n",
      "Fold: 9  Epoch: 303  Training loss = 2.5162  Validation loss = 10.0254  \n",
      "\n",
      "Fold: 9  Epoch: 304  Training loss = 2.5160  Validation loss = 10.0249  \n",
      "\n",
      "Fold: 9  Epoch: 305  Training loss = 2.5158  Validation loss = 10.0245  \n",
      "\n",
      "Fold: 9  Epoch: 306  Training loss = 2.5155  Validation loss = 10.0239  \n",
      "\n",
      "Fold: 9  Epoch: 307  Training loss = 2.5153  Validation loss = 10.0234  \n",
      "\n",
      "Fold: 9  Epoch: 308  Training loss = 2.5150  Validation loss = 10.0226  \n",
      "\n",
      "Fold: 9  Epoch: 309  Training loss = 2.5147  Validation loss = 10.0221  \n",
      "\n",
      "Fold: 9  Epoch: 310  Training loss = 2.5145  Validation loss = 10.0217  \n",
      "\n",
      "Fold: 9  Epoch: 311  Training loss = 2.5143  Validation loss = 10.0211  \n",
      "\n",
      "Fold: 9  Epoch: 312  Training loss = 2.5140  Validation loss = 10.0205  \n",
      "\n",
      "Fold: 9  Epoch: 313  Training loss = 2.5137  Validation loss = 10.0200  \n",
      "\n",
      "Fold: 9  Epoch: 314  Training loss = 2.5134  Validation loss = 10.0192  \n",
      "\n",
      "Fold: 9  Epoch: 315  Training loss = 2.5131  Validation loss = 10.0187  \n",
      "\n",
      "Fold: 9  Epoch: 316  Training loss = 2.5128  Validation loss = 10.0180  \n",
      "\n",
      "Fold: 9  Epoch: 317  Training loss = 2.5126  Validation loss = 10.0174  \n",
      "\n",
      "Fold: 9  Epoch: 318  Training loss = 2.5123  Validation loss = 10.0167  \n",
      "\n",
      "Fold: 9  Epoch: 319  Training loss = 2.5121  Validation loss = 10.0163  \n",
      "\n",
      "Fold: 9  Epoch: 320  Training loss = 2.5119  Validation loss = 10.0159  \n",
      "\n",
      "Fold: 9  Epoch: 321  Training loss = 2.5116  Validation loss = 10.0153  \n",
      "\n",
      "Fold: 9  Epoch: 322  Training loss = 2.5113  Validation loss = 10.0146  \n",
      "\n",
      "Fold: 9  Epoch: 323  Training loss = 2.5111  Validation loss = 10.0141  \n",
      "\n",
      "Fold: 9  Epoch: 324  Training loss = 2.5109  Validation loss = 10.0136  \n",
      "\n",
      "Fold: 9  Epoch: 325  Training loss = 2.5106  Validation loss = 10.0131  \n",
      "\n",
      "Fold: 9  Epoch: 326  Training loss = 2.5104  Validation loss = 10.0126  \n",
      "\n",
      "Fold: 9  Epoch: 327  Training loss = 2.5102  Validation loss = 10.0121  \n",
      "\n",
      "Fold: 9  Epoch: 328  Training loss = 2.5099  Validation loss = 10.0115  \n",
      "\n",
      "Fold: 9  Epoch: 329  Training loss = 2.5098  Validation loss = 10.0112  \n",
      "\n",
      "Fold: 9  Epoch: 330  Training loss = 2.5096  Validation loss = 10.0108  \n",
      "\n",
      "Fold: 9  Epoch: 331  Training loss = 2.5093  Validation loss = 10.0102  \n",
      "\n",
      "Fold: 9  Epoch: 332  Training loss = 2.5089  Validation loss = 10.0094  \n",
      "\n",
      "Fold: 9  Epoch: 333  Training loss = 2.5087  Validation loss = 10.0087  \n",
      "\n",
      "Fold: 9  Epoch: 334  Training loss = 2.5083  Validation loss = 10.0080  \n",
      "\n",
      "Fold: 9  Epoch: 335  Training loss = 2.5081  Validation loss = 10.0075  \n",
      "\n",
      "Fold: 9  Epoch: 336  Training loss = 2.5078  Validation loss = 10.0069  \n",
      "\n",
      "Fold: 9  Epoch: 337  Training loss = 2.5077  Validation loss = 10.0065  \n",
      "\n",
      "Fold: 9  Epoch: 338  Training loss = 2.5074  Validation loss = 10.0060  \n",
      "\n",
      "Fold: 9  Epoch: 339  Training loss = 2.5072  Validation loss = 10.0056  \n",
      "\n",
      "Fold: 9  Epoch: 340  Training loss = 2.5070  Validation loss = 10.0051  \n",
      "\n",
      "Fold: 9  Epoch: 341  Training loss = 2.5068  Validation loss = 10.0046  \n",
      "\n",
      "Fold: 9  Epoch: 342  Training loss = 2.5065  Validation loss = 10.0039  \n",
      "\n",
      "Fold: 9  Epoch: 343  Training loss = 2.5062  Validation loss = 10.0033  \n",
      "\n",
      "Fold: 9  Epoch: 344  Training loss = 2.5060  Validation loss = 10.0029  \n",
      "\n",
      "Fold: 9  Epoch: 345  Training loss = 2.5058  Validation loss = 10.0024  \n",
      "\n",
      "Fold: 9  Epoch: 346  Training loss = 2.5056  Validation loss = 10.0020  \n",
      "\n",
      "Fold: 9  Epoch: 347  Training loss = 2.5053  Validation loss = 10.0014  \n",
      "\n",
      "Fold: 9  Epoch: 348  Training loss = 2.5051  Validation loss = 10.0009  \n",
      "\n",
      "Fold: 9  Epoch: 349  Training loss = 2.5048  Validation loss = 10.0001  \n",
      "\n",
      "Fold: 9  Epoch: 350  Training loss = 2.5045  Validation loss = 9.9996  \n",
      "\n",
      "Fold: 9  Epoch: 351  Training loss = 2.5043  Validation loss = 9.9991  \n",
      "\n",
      "Fold: 9  Epoch: 352  Training loss = 2.5040  Validation loss = 9.9984  \n",
      "\n",
      "Fold: 9  Epoch: 353  Training loss = 2.5037  Validation loss = 9.9978  \n",
      "\n",
      "Fold: 9  Epoch: 354  Training loss = 2.5036  Validation loss = 9.9975  \n",
      "\n",
      "Fold: 9  Epoch: 355  Training loss = 2.5033  Validation loss = 9.9969  \n",
      "\n",
      "Fold: 9  Epoch: 356  Training loss = 2.5030  Validation loss = 9.9963  \n",
      "\n",
      "Fold: 9  Epoch: 357  Training loss = 2.5028  Validation loss = 9.9957  \n",
      "\n",
      "Fold: 9  Epoch: 358  Training loss = 2.5026  Validation loss = 9.9953  \n",
      "\n",
      "Fold: 9  Epoch: 359  Training loss = 2.5023  Validation loss = 9.9947  \n",
      "\n",
      "Fold: 9  Epoch: 360  Training loss = 2.5021  Validation loss = 9.9942  \n",
      "\n",
      "Fold: 9  Epoch: 361  Training loss = 2.5018  Validation loss = 9.9936  \n",
      "\n",
      "Fold: 9  Epoch: 362  Training loss = 2.5017  Validation loss = 9.9933  \n",
      "\n",
      "Fold: 9  Epoch: 363  Training loss = 2.5014  Validation loss = 9.9926  \n",
      "\n",
      "Fold: 9  Epoch: 364  Training loss = 2.5011  Validation loss = 9.9919  \n",
      "\n",
      "Fold: 9  Epoch: 365  Training loss = 2.5009  Validation loss = 9.9914  \n",
      "\n",
      "Fold: 9  Epoch: 366  Training loss = 2.5006  Validation loss = 9.9908  \n",
      "\n",
      "Fold: 9  Epoch: 367  Training loss = 2.5004  Validation loss = 9.9905  \n",
      "\n",
      "Fold: 9  Epoch: 368  Training loss = 2.5002  Validation loss = 9.9900  \n",
      "\n",
      "Fold: 9  Epoch: 369  Training loss = 2.5000  Validation loss = 9.9894  \n",
      "\n",
      "Fold: 9  Epoch: 370  Training loss = 2.4997  Validation loss = 9.9887  \n",
      "\n",
      "Fold: 9  Epoch: 371  Training loss = 2.4994  Validation loss = 9.9882  \n",
      "\n",
      "Fold: 9  Epoch: 372  Training loss = 2.4992  Validation loss = 9.9877  \n",
      "\n",
      "Fold: 9  Epoch: 373  Training loss = 2.4989  Validation loss = 9.9871  \n",
      "\n",
      "Fold: 9  Epoch: 374  Training loss = 2.4988  Validation loss = 9.9868  \n",
      "\n",
      "Fold: 9  Epoch: 375  Training loss = 2.4987  Validation loss = 9.9864  \n",
      "\n",
      "Fold: 9  Epoch: 376  Training loss = 2.4984  Validation loss = 9.9858  \n",
      "\n",
      "Fold: 9  Epoch: 377  Training loss = 2.4981  Validation loss = 9.9851  \n",
      "\n",
      "Fold: 9  Epoch: 378  Training loss = 2.4978  Validation loss = 9.9845  \n",
      "\n",
      "Fold: 9  Epoch: 379  Training loss = 2.4976  Validation loss = 9.9841  \n",
      "\n",
      "Fold: 9  Epoch: 380  Training loss = 2.4973  Validation loss = 9.9834  \n",
      "\n",
      "Fold: 9  Epoch: 381  Training loss = 2.4971  Validation loss = 9.9829  \n",
      "\n",
      "Fold: 9  Epoch: 382  Training loss = 2.4969  Validation loss = 9.9824  \n",
      "\n",
      "Fold: 9  Epoch: 383  Training loss = 2.4966  Validation loss = 9.9819  \n",
      "\n",
      "Fold: 9  Epoch: 384  Training loss = 2.4964  Validation loss = 9.9815  \n",
      "\n",
      "Fold: 9  Epoch: 385  Training loss = 2.4962  Validation loss = 9.9809  \n",
      "\n",
      "Fold: 9  Epoch: 386  Training loss = 2.4959  Validation loss = 9.9802  \n",
      "\n",
      "Fold: 9  Epoch: 387  Training loss = 2.4957  Validation loss = 9.9799  \n",
      "\n",
      "Fold: 9  Epoch: 388  Training loss = 2.4955  Validation loss = 9.9794  \n",
      "\n",
      "Fold: 9  Epoch: 389  Training loss = 2.4953  Validation loss = 9.9790  \n",
      "\n",
      "Fold: 9  Epoch: 390  Training loss = 2.4951  Validation loss = 9.9786  \n",
      "\n",
      "Fold: 9  Epoch: 391  Training loss = 2.4949  Validation loss = 9.9781  \n",
      "\n",
      "Fold: 9  Epoch: 392  Training loss = 2.4947  Validation loss = 9.9776  \n",
      "\n",
      "Fold: 9  Epoch: 393  Training loss = 2.4945  Validation loss = 9.9771  \n",
      "\n",
      "Fold: 9  Epoch: 394  Training loss = 2.4942  Validation loss = 9.9766  \n",
      "\n",
      "Fold: 9  Epoch: 395  Training loss = 2.4940  Validation loss = 9.9761  \n",
      "\n",
      "Fold: 9  Epoch: 396  Training loss = 2.4938  Validation loss = 9.9756  \n",
      "\n",
      "Fold: 9  Epoch: 397  Training loss = 2.4936  Validation loss = 9.9751  \n",
      "\n",
      "Fold: 9  Epoch: 398  Training loss = 2.4933  Validation loss = 9.9745  \n",
      "\n",
      "Fold: 9  Epoch: 399  Training loss = 2.4931  Validation loss = 9.9740  \n",
      "\n",
      "Fold: 9  Epoch: 400  Training loss = 2.4928  Validation loss = 9.9733  \n",
      "\n",
      "Fold: 9  Epoch: 401  Training loss = 2.4926  Validation loss = 9.9729  \n",
      "\n",
      "Fold: 9  Epoch: 402  Training loss = 2.4924  Validation loss = 9.9724  \n",
      "\n",
      "Fold: 9  Epoch: 403  Training loss = 2.4922  Validation loss = 9.9719  \n",
      "\n",
      "Fold: 9  Epoch: 404  Training loss = 2.4919  Validation loss = 9.9713  \n",
      "\n",
      "Fold: 9  Epoch: 405  Training loss = 2.4917  Validation loss = 9.9708  \n",
      "\n",
      "Fold: 9  Epoch: 406  Training loss = 2.4914  Validation loss = 9.9702  \n",
      "\n",
      "Fold: 9  Epoch: 407  Training loss = 2.4911  Validation loss = 9.9695  \n",
      "\n",
      "Fold: 9  Epoch: 408  Training loss = 2.4908  Validation loss = 9.9689  \n",
      "\n",
      "Fold: 9  Epoch: 409  Training loss = 2.4907  Validation loss = 9.9686  \n",
      "\n",
      "Fold: 9  Epoch: 410  Training loss = 2.4904  Validation loss = 9.9680  \n",
      "\n",
      "Fold: 9  Epoch: 411  Training loss = 2.4902  Validation loss = 9.9675  \n",
      "\n",
      "Fold: 9  Epoch: 412  Training loss = 2.4900  Validation loss = 9.9671  \n",
      "\n",
      "Fold: 9  Epoch: 413  Training loss = 2.4898  Validation loss = 9.9667  \n",
      "\n",
      "Fold: 9  Epoch: 414  Training loss = 2.4896  Validation loss = 9.9662  \n",
      "\n",
      "Fold: 9  Epoch: 415  Training loss = 2.4893  Validation loss = 9.9655  \n",
      "\n",
      "Fold: 9  Epoch: 416  Training loss = 2.4891  Validation loss = 9.9649  \n",
      "\n",
      "Fold: 9  Epoch: 417  Training loss = 2.4889  Validation loss = 9.9645  \n",
      "\n",
      "Fold: 9  Epoch: 418  Training loss = 2.4886  Validation loss = 9.9639  \n",
      "\n",
      "Fold: 9  Epoch: 419  Training loss = 2.4883  Validation loss = 9.9633  \n",
      "\n",
      "Fold: 9  Epoch: 420  Training loss = 2.4881  Validation loss = 9.9627  \n",
      "\n",
      "Fold: 9  Epoch: 421  Training loss = 2.4879  Validation loss = 9.9622  \n",
      "\n",
      "Fold: 9  Epoch: 422  Training loss = 2.4877  Validation loss = 9.9617  \n",
      "\n",
      "Fold: 9  Epoch: 423  Training loss = 2.4875  Validation loss = 9.9612  \n",
      "\n",
      "Fold: 9  Epoch: 424  Training loss = 2.4872  Validation loss = 9.9607  \n",
      "\n",
      "Fold: 9  Epoch: 425  Training loss = 2.4870  Validation loss = 9.9601  \n",
      "\n",
      "Fold: 9  Epoch: 426  Training loss = 2.4867  Validation loss = 9.9595  \n",
      "\n",
      "Fold: 9  Epoch: 427  Training loss = 2.4864  Validation loss = 9.9589  \n",
      "\n",
      "Fold: 9  Epoch: 428  Training loss = 2.4862  Validation loss = 9.9584  \n",
      "\n",
      "Fold: 9  Epoch: 429  Training loss = 2.4859  Validation loss = 9.9578  \n",
      "\n",
      "Fold: 9  Epoch: 430  Training loss = 2.4857  Validation loss = 9.9572  \n",
      "\n",
      "Fold: 9  Epoch: 431  Training loss = 2.4854  Validation loss = 9.9566  \n",
      "\n",
      "Fold: 9  Epoch: 432  Training loss = 2.4852  Validation loss = 9.9561  \n",
      "\n",
      "Fold: 9  Epoch: 433  Training loss = 2.4850  Validation loss = 9.9555  \n",
      "\n",
      "Fold: 9  Epoch: 434  Training loss = 2.4848  Validation loss = 9.9551  \n",
      "\n",
      "Fold: 9  Epoch: 435  Training loss = 2.4845  Validation loss = 9.9545  \n",
      "\n",
      "Fold: 9  Epoch: 436  Training loss = 2.4842  Validation loss = 9.9539  \n",
      "\n",
      "Fold: 9  Epoch: 437  Training loss = 2.4840  Validation loss = 9.9534  \n",
      "\n",
      "Fold: 9  Epoch: 438  Training loss = 2.4837  Validation loss = 9.9528  \n",
      "\n",
      "Fold: 9  Epoch: 439  Training loss = 2.4836  Validation loss = 9.9524  \n",
      "\n",
      "Fold: 9  Epoch: 440  Training loss = 2.4834  Validation loss = 9.9520  \n",
      "\n",
      "Fold: 9  Epoch: 441  Training loss = 2.4832  Validation loss = 9.9516  \n",
      "\n",
      "Fold: 9  Epoch: 442  Training loss = 2.4830  Validation loss = 9.9510  \n",
      "\n",
      "Fold: 9  Epoch: 443  Training loss = 2.4828  Validation loss = 9.9506  \n",
      "\n",
      "Fold: 9  Epoch: 444  Training loss = 2.4826  Validation loss = 9.9501  \n",
      "\n",
      "Fold: 9  Epoch: 445  Training loss = 2.4822  Validation loss = 9.9493  \n",
      "\n",
      "Fold: 9  Epoch: 446  Training loss = 2.4818  Validation loss = 9.9484  \n",
      "\n",
      "Fold: 9  Epoch: 447  Training loss = 2.4815  Validation loss = 9.9478  \n",
      "\n",
      "Fold: 9  Epoch: 448  Training loss = 2.4813  Validation loss = 9.9473  \n",
      "\n",
      "Fold: 9  Epoch: 449  Training loss = 2.4810  Validation loss = 9.9467  \n",
      "\n",
      "Fold: 9  Epoch: 450  Training loss = 2.4809  Validation loss = 9.9463  \n",
      "\n",
      "Fold: 9  Epoch: 451  Training loss = 2.4807  Validation loss = 9.9458  \n",
      "\n",
      "Fold: 9  Epoch: 452  Training loss = 2.4804  Validation loss = 9.9452  \n",
      "\n",
      "Fold: 9  Epoch: 453  Training loss = 2.4802  Validation loss = 9.9447  \n",
      "\n",
      "Fold: 9  Epoch: 454  Training loss = 2.4800  Validation loss = 9.9442  \n",
      "\n",
      "Fold: 9  Epoch: 455  Training loss = 2.4797  Validation loss = 9.9436  \n",
      "\n",
      "Fold: 9  Epoch: 456  Training loss = 2.4795  Validation loss = 9.9431  \n",
      "\n",
      "Fold: 9  Epoch: 457  Training loss = 2.4792  Validation loss = 9.9425  \n",
      "\n",
      "Fold: 9  Epoch: 458  Training loss = 2.4789  Validation loss = 9.9419  \n",
      "\n",
      "Fold: 9  Epoch: 459  Training loss = 2.4786  Validation loss = 9.9412  \n",
      "\n",
      "Fold: 9  Epoch: 460  Training loss = 2.4784  Validation loss = 9.9407  \n",
      "\n",
      "Fold: 9  Epoch: 461  Training loss = 2.4782  Validation loss = 9.9402  \n",
      "\n",
      "Fold: 9  Epoch: 462  Training loss = 2.4779  Validation loss = 9.9395  \n",
      "\n",
      "Fold: 9  Epoch: 463  Training loss = 2.4777  Validation loss = 9.9390  \n",
      "\n",
      "Fold: 9  Epoch: 464  Training loss = 2.4774  Validation loss = 9.9384  \n",
      "\n",
      "Fold: 9  Epoch: 465  Training loss = 2.4772  Validation loss = 9.9379  \n",
      "\n",
      "Fold: 9  Epoch: 466  Training loss = 2.4770  Validation loss = 9.9375  \n",
      "\n",
      "Fold: 9  Epoch: 467  Training loss = 2.4768  Validation loss = 9.9369  \n",
      "\n",
      "Fold: 9  Epoch: 468  Training loss = 2.4766  Validation loss = 9.9366  \n",
      "\n",
      "Fold: 9  Epoch: 469  Training loss = 2.4765  Validation loss = 9.9363  \n",
      "\n",
      "Fold: 9  Epoch: 470  Training loss = 2.4763  Validation loss = 9.9357  \n",
      "\n",
      "Fold: 9  Epoch: 471  Training loss = 2.4761  Validation loss = 9.9352  \n",
      "\n",
      "Fold: 9  Epoch: 472  Training loss = 2.4758  Validation loss = 9.9347  \n",
      "\n",
      "Fold: 9  Epoch: 473  Training loss = 2.4755  Validation loss = 9.9340  \n",
      "\n",
      "Fold: 9  Epoch: 474  Training loss = 2.4753  Validation loss = 9.9335  \n",
      "\n",
      "Fold: 9  Epoch: 475  Training loss = 2.4751  Validation loss = 9.9331  \n",
      "\n",
      "Fold: 9  Epoch: 476  Training loss = 2.4748  Validation loss = 9.9325  \n",
      "\n",
      "Fold: 9  Epoch: 477  Training loss = 2.4746  Validation loss = 9.9321  \n",
      "\n",
      "Fold: 9  Epoch: 478  Training loss = 2.4744  Validation loss = 9.9315  \n",
      "\n",
      "Fold: 9  Epoch: 479  Training loss = 2.4741  Validation loss = 9.9309  \n",
      "\n",
      "Fold: 9  Epoch: 480  Training loss = 2.4739  Validation loss = 9.9304  \n",
      "\n",
      "Fold: 9  Epoch: 481  Training loss = 2.4737  Validation loss = 9.9299  \n",
      "\n",
      "Fold: 9  Epoch: 482  Training loss = 2.4735  Validation loss = 9.9294  \n",
      "\n",
      "Fold: 9  Epoch: 483  Training loss = 2.4732  Validation loss = 9.9288  \n",
      "\n",
      "Fold: 9  Epoch: 484  Training loss = 2.4730  Validation loss = 9.9282  \n",
      "\n",
      "Fold: 9  Epoch: 485  Training loss = 2.4726  Validation loss = 9.9274  \n",
      "\n",
      "Fold: 9  Epoch: 486  Training loss = 2.4724  Validation loss = 9.9269  \n",
      "\n",
      "Fold: 9  Epoch: 487  Training loss = 2.4722  Validation loss = 9.9264  \n",
      "\n",
      "Fold: 9  Epoch: 488  Training loss = 2.4720  Validation loss = 9.9261  \n",
      "\n",
      "Fold: 9  Epoch: 489  Training loss = 2.4718  Validation loss = 9.9254  \n",
      "\n",
      "Fold: 9  Epoch: 490  Training loss = 2.4715  Validation loss = 9.9249  \n",
      "\n",
      "Fold: 9  Epoch: 491  Training loss = 2.4714  Validation loss = 9.9245  \n",
      "\n",
      "Fold: 9  Epoch: 492  Training loss = 2.4711  Validation loss = 9.9238  \n",
      "\n",
      "Fold: 9  Epoch: 493  Training loss = 2.4708  Validation loss = 9.9232  \n",
      "\n",
      "Fold: 9  Epoch: 494  Training loss = 2.4706  Validation loss = 9.9227  \n",
      "\n",
      "Fold: 9  Epoch: 495  Training loss = 2.4703  Validation loss = 9.9221  \n",
      "\n",
      "Fold: 9  Epoch: 496  Training loss = 2.4701  Validation loss = 9.9215  \n",
      "\n",
      "Fold: 9  Epoch: 497  Training loss = 2.4698  Validation loss = 9.9210  \n",
      "\n",
      "Fold: 9  Epoch: 498  Training loss = 2.4696  Validation loss = 9.9205  \n",
      "\n",
      "Fold: 9  Epoch: 499  Training loss = 2.4694  Validation loss = 9.9199  \n",
      "\n",
      "Fold: 9  Epoch: 500  Training loss = 2.4692  Validation loss = 9.9196  \n",
      "\n",
      "Check model:  Fold: 9  Optimal epoch: 500  \n",
      "\n",
      "Fold: 10  Epoch: 1  Training loss = 3.4613  Validation loss = 6.3839  \n",
      "\n",
      "Fold: 10  Epoch: 2  Training loss = 3.4610  Validation loss = 6.3832  \n",
      "\n",
      "Fold: 10  Epoch: 3  Training loss = 3.4606  Validation loss = 6.3821  \n",
      "\n",
      "Fold: 10  Epoch: 4  Training loss = 3.4604  Validation loss = 6.3817  \n",
      "\n",
      "Fold: 10  Epoch: 5  Training loss = 3.4601  Validation loss = 6.3811  \n",
      "\n",
      "Fold: 10  Epoch: 6  Training loss = 3.4596  Validation loss = 6.3798  \n",
      "\n",
      "Fold: 10  Epoch: 7  Training loss = 3.4590  Validation loss = 6.3783  \n",
      "\n",
      "Fold: 10  Epoch: 8  Training loss = 3.4584  Validation loss = 6.3773  \n",
      "\n",
      "Fold: 10  Epoch: 9  Training loss = 3.4580  Validation loss = 6.3765  \n",
      "\n",
      "Fold: 10  Epoch: 10  Training loss = 3.4576  Validation loss = 6.3757  \n",
      "\n",
      "Fold: 10  Epoch: 11  Training loss = 3.4573  Validation loss = 6.3750  \n",
      "\n",
      "Fold: 10  Epoch: 12  Training loss = 3.4570  Validation loss = 6.3743  \n",
      "\n",
      "Fold: 10  Epoch: 13  Training loss = 3.4565  Validation loss = 6.3735  \n",
      "\n",
      "Fold: 10  Epoch: 14  Training loss = 3.4561  Validation loss = 6.3725  \n",
      "\n",
      "Fold: 10  Epoch: 15  Training loss = 3.4557  Validation loss = 6.3716  \n",
      "\n",
      "Fold: 10  Epoch: 16  Training loss = 3.4553  Validation loss = 6.3706  \n",
      "\n",
      "Fold: 10  Epoch: 17  Training loss = 3.4550  Validation loss = 6.3701  \n",
      "\n",
      "Fold: 10  Epoch: 18  Training loss = 3.4547  Validation loss = 6.3692  \n",
      "\n",
      "Fold: 10  Epoch: 19  Training loss = 3.4542  Validation loss = 6.3681  \n",
      "\n",
      "Fold: 10  Epoch: 20  Training loss = 3.4538  Validation loss = 6.3672  \n",
      "\n",
      "Fold: 10  Epoch: 21  Training loss = 3.4533  Validation loss = 6.3660  \n",
      "\n",
      "Fold: 10  Epoch: 22  Training loss = 3.4529  Validation loss = 6.3652  \n",
      "\n",
      "Fold: 10  Epoch: 23  Training loss = 3.4527  Validation loss = 6.3647  \n",
      "\n",
      "Fold: 10  Epoch: 24  Training loss = 3.4522  Validation loss = 6.3635  \n",
      "\n",
      "Fold: 10  Epoch: 25  Training loss = 3.4517  Validation loss = 6.3624  \n",
      "\n",
      "Fold: 10  Epoch: 26  Training loss = 3.4511  Validation loss = 6.3606  \n",
      "\n",
      "Fold: 10  Epoch: 27  Training loss = 3.4508  Validation loss = 6.3600  \n",
      "\n",
      "Fold: 10  Epoch: 28  Training loss = 3.4504  Validation loss = 6.3591  \n",
      "\n",
      "Fold: 10  Epoch: 29  Training loss = 3.4500  Validation loss = 6.3581  \n",
      "\n",
      "Fold: 10  Epoch: 30  Training loss = 3.4496  Validation loss = 6.3570  \n",
      "\n",
      "Fold: 10  Epoch: 31  Training loss = 3.4491  Validation loss = 6.3556  \n",
      "\n",
      "Fold: 10  Epoch: 32  Training loss = 3.4487  Validation loss = 6.3545  \n",
      "\n",
      "Fold: 10  Epoch: 33  Training loss = 3.4483  Validation loss = 6.3533  \n",
      "\n",
      "Fold: 10  Epoch: 34  Training loss = 3.4478  Validation loss = 6.3525  \n",
      "\n",
      "Fold: 10  Epoch: 35  Training loss = 3.4474  Validation loss = 6.3517  \n",
      "\n",
      "Fold: 10  Epoch: 36  Training loss = 3.4471  Validation loss = 6.3509  \n",
      "\n",
      "Fold: 10  Epoch: 37  Training loss = 3.4467  Validation loss = 6.3497  \n",
      "\n",
      "Fold: 10  Epoch: 38  Training loss = 3.4463  Validation loss = 6.3489  \n",
      "\n",
      "Fold: 10  Epoch: 39  Training loss = 3.4461  Validation loss = 6.3484  \n",
      "\n",
      "Fold: 10  Epoch: 40  Training loss = 3.4456  Validation loss = 6.3472  \n",
      "\n",
      "Fold: 10  Epoch: 41  Training loss = 3.4453  Validation loss = 6.3466  \n",
      "\n",
      "Fold: 10  Epoch: 42  Training loss = 3.4448  Validation loss = 6.3454  \n",
      "\n",
      "Fold: 10  Epoch: 43  Training loss = 3.4443  Validation loss = 6.3443  \n",
      "\n",
      "Fold: 10  Epoch: 44  Training loss = 3.4438  Validation loss = 6.3432  \n",
      "\n",
      "Fold: 10  Epoch: 45  Training loss = 3.4434  Validation loss = 6.3421  \n",
      "\n",
      "Fold: 10  Epoch: 46  Training loss = 3.4429  Validation loss = 6.3410  \n",
      "\n",
      "Fold: 10  Epoch: 47  Training loss = 3.4424  Validation loss = 6.3396  \n",
      "\n",
      "Fold: 10  Epoch: 48  Training loss = 3.4421  Validation loss = 6.3388  \n",
      "\n",
      "Fold: 10  Epoch: 49  Training loss = 3.4417  Validation loss = 6.3379  \n",
      "\n",
      "Fold: 10  Epoch: 50  Training loss = 3.4413  Validation loss = 6.3370  \n",
      "\n",
      "Fold: 10  Epoch: 51  Training loss = 3.4410  Validation loss = 6.3360  \n",
      "\n",
      "Fold: 10  Epoch: 52  Training loss = 3.4406  Validation loss = 6.3349  \n",
      "\n",
      "Fold: 10  Epoch: 53  Training loss = 3.4402  Validation loss = 6.3337  \n",
      "\n",
      "Fold: 10  Epoch: 54  Training loss = 3.4399  Validation loss = 6.3331  \n",
      "\n",
      "Fold: 10  Epoch: 55  Training loss = 3.4396  Validation loss = 6.3324  \n",
      "\n",
      "Fold: 10  Epoch: 56  Training loss = 3.4391  Validation loss = 6.3311  \n",
      "\n",
      "Fold: 10  Epoch: 57  Training loss = 3.4387  Validation loss = 6.3299  \n",
      "\n",
      "Fold: 10  Epoch: 58  Training loss = 3.4383  Validation loss = 6.3289  \n",
      "\n",
      "Fold: 10  Epoch: 59  Training loss = 3.4380  Validation loss = 6.3284  \n",
      "\n",
      "Fold: 10  Epoch: 60  Training loss = 3.4375  Validation loss = 6.3273  \n",
      "\n",
      "Fold: 10  Epoch: 61  Training loss = 3.4371  Validation loss = 6.3260  \n",
      "\n",
      "Fold: 10  Epoch: 62  Training loss = 3.4368  Validation loss = 6.3254  \n",
      "\n",
      "Fold: 10  Epoch: 63  Training loss = 3.4364  Validation loss = 6.3243  \n",
      "\n",
      "Fold: 10  Epoch: 64  Training loss = 3.4361  Validation loss = 6.3233  \n",
      "\n",
      "Fold: 10  Epoch: 65  Training loss = 3.4356  Validation loss = 6.3218  \n",
      "\n",
      "Fold: 10  Epoch: 66  Training loss = 3.4352  Validation loss = 6.3208  \n",
      "\n",
      "Fold: 10  Epoch: 67  Training loss = 3.4348  Validation loss = 6.3196  \n",
      "\n",
      "Fold: 10  Epoch: 68  Training loss = 3.4342  Validation loss = 6.3182  \n",
      "\n",
      "Fold: 10  Epoch: 69  Training loss = 3.4338  Validation loss = 6.3171  \n",
      "\n",
      "Fold: 10  Epoch: 70  Training loss = 3.4335  Validation loss = 6.3165  \n",
      "\n",
      "Fold: 10  Epoch: 71  Training loss = 3.4331  Validation loss = 6.3152  \n",
      "\n",
      "Fold: 10  Epoch: 72  Training loss = 3.4326  Validation loss = 6.3134  \n",
      "\n",
      "Fold: 10  Epoch: 73  Training loss = 3.4322  Validation loss = 6.3124  \n",
      "\n",
      "Fold: 10  Epoch: 74  Training loss = 3.4318  Validation loss = 6.3113  \n",
      "\n",
      "Fold: 10  Epoch: 75  Training loss = 3.4313  Validation loss = 6.3099  \n",
      "\n",
      "Fold: 10  Epoch: 76  Training loss = 3.4309  Validation loss = 6.3088  \n",
      "\n",
      "Fold: 10  Epoch: 77  Training loss = 3.4306  Validation loss = 6.3081  \n",
      "\n",
      "Fold: 10  Epoch: 78  Training loss = 3.4303  Validation loss = 6.3072  \n",
      "\n",
      "Fold: 10  Epoch: 79  Training loss = 3.4299  Validation loss = 6.3062  \n",
      "\n",
      "Fold: 10  Epoch: 80  Training loss = 3.4294  Validation loss = 6.3045  \n",
      "\n",
      "Fold: 10  Epoch: 81  Training loss = 3.4291  Validation loss = 6.3038  \n",
      "\n",
      "Fold: 10  Epoch: 82  Training loss = 3.4286  Validation loss = 6.3027  \n",
      "\n",
      "Fold: 10  Epoch: 83  Training loss = 3.4282  Validation loss = 6.3014  \n",
      "\n",
      "Fold: 10  Epoch: 84  Training loss = 3.4279  Validation loss = 6.3007  \n",
      "\n",
      "Fold: 10  Epoch: 85  Training loss = 3.4275  Validation loss = 6.3000  \n",
      "\n",
      "Fold: 10  Epoch: 86  Training loss = 3.4272  Validation loss = 6.2991  \n",
      "\n",
      "Fold: 10  Epoch: 87  Training loss = 3.4267  Validation loss = 6.2975  \n",
      "\n",
      "Fold: 10  Epoch: 88  Training loss = 3.4262  Validation loss = 6.2963  \n",
      "\n",
      "Fold: 10  Epoch: 89  Training loss = 3.4257  Validation loss = 6.2947  \n",
      "\n",
      "Fold: 10  Epoch: 90  Training loss = 3.4253  Validation loss = 6.2936  \n",
      "\n",
      "Fold: 10  Epoch: 91  Training loss = 3.4251  Validation loss = 6.2927  \n",
      "\n",
      "Fold: 10  Epoch: 92  Training loss = 3.4247  Validation loss = 6.2917  \n",
      "\n",
      "Fold: 10  Epoch: 93  Training loss = 3.4244  Validation loss = 6.2911  \n",
      "\n",
      "Fold: 10  Epoch: 94  Training loss = 3.4239  Validation loss = 6.2896  \n",
      "\n",
      "Fold: 10  Epoch: 95  Training loss = 3.4234  Validation loss = 6.2885  \n",
      "\n",
      "Fold: 10  Epoch: 96  Training loss = 3.4232  Validation loss = 6.2880  \n",
      "\n",
      "Fold: 10  Epoch: 97  Training loss = 3.4228  Validation loss = 6.2868  \n",
      "\n",
      "Fold: 10  Epoch: 98  Training loss = 3.4223  Validation loss = 6.2859  \n",
      "\n",
      "Fold: 10  Epoch: 99  Training loss = 3.4220  Validation loss = 6.2848  \n",
      "\n",
      "Fold: 10  Epoch: 100  Training loss = 3.4216  Validation loss = 6.2842  \n",
      "\n",
      "Fold: 10  Epoch: 101  Training loss = 3.4212  Validation loss = 6.2830  \n",
      "\n",
      "Fold: 10  Epoch: 102  Training loss = 3.4208  Validation loss = 6.2822  \n",
      "\n",
      "Fold: 10  Epoch: 103  Training loss = 3.4204  Validation loss = 6.2810  \n",
      "\n",
      "Fold: 10  Epoch: 104  Training loss = 3.4201  Validation loss = 6.2804  \n",
      "\n",
      "Fold: 10  Epoch: 105  Training loss = 3.4197  Validation loss = 6.2796  \n",
      "\n",
      "Fold: 10  Epoch: 106  Training loss = 3.4193  Validation loss = 6.2785  \n",
      "\n",
      "Fold: 10  Epoch: 107  Training loss = 3.4189  Validation loss = 6.2772  \n",
      "\n",
      "Fold: 10  Epoch: 108  Training loss = 3.4185  Validation loss = 6.2760  \n",
      "\n",
      "Fold: 10  Epoch: 109  Training loss = 3.4181  Validation loss = 6.2754  \n",
      "\n",
      "Fold: 10  Epoch: 110  Training loss = 3.4178  Validation loss = 6.2747  \n",
      "\n",
      "Fold: 10  Epoch: 111  Training loss = 3.4173  Validation loss = 6.2734  \n",
      "\n",
      "Fold: 10  Epoch: 112  Training loss = 3.4169  Validation loss = 6.2723  \n",
      "\n",
      "Fold: 10  Epoch: 113  Training loss = 3.4165  Validation loss = 6.2714  \n",
      "\n",
      "Fold: 10  Epoch: 114  Training loss = 3.4162  Validation loss = 6.2705  \n",
      "\n",
      "Fold: 10  Epoch: 115  Training loss = 3.4157  Validation loss = 6.2692  \n",
      "\n",
      "Fold: 10  Epoch: 116  Training loss = 3.4154  Validation loss = 6.2683  \n",
      "\n",
      "Fold: 10  Epoch: 117  Training loss = 3.4149  Validation loss = 6.2672  \n",
      "\n",
      "Fold: 10  Epoch: 118  Training loss = 3.4147  Validation loss = 6.2664  \n",
      "\n",
      "Fold: 10  Epoch: 119  Training loss = 3.4144  Validation loss = 6.2654  \n",
      "\n",
      "Fold: 10  Epoch: 120  Training loss = 3.4141  Validation loss = 6.2644  \n",
      "\n",
      "Fold: 10  Epoch: 121  Training loss = 3.4137  Validation loss = 6.2634  \n",
      "\n",
      "Fold: 10  Epoch: 122  Training loss = 3.4134  Validation loss = 6.2623  \n",
      "\n",
      "Fold: 10  Epoch: 123  Training loss = 3.4132  Validation loss = 6.2619  \n",
      "\n",
      "Fold: 10  Epoch: 124  Training loss = 3.4128  Validation loss = 6.2607  \n",
      "\n",
      "Fold: 10  Epoch: 125  Training loss = 3.4124  Validation loss = 6.2595  \n",
      "\n",
      "Fold: 10  Epoch: 126  Training loss = 3.4121  Validation loss = 6.2587  \n",
      "\n",
      "Fold: 10  Epoch: 127  Training loss = 3.4118  Validation loss = 6.2582  \n",
      "\n",
      "Fold: 10  Epoch: 128  Training loss = 3.4115  Validation loss = 6.2574  \n",
      "\n",
      "Fold: 10  Epoch: 129  Training loss = 3.4112  Validation loss = 6.2564  \n",
      "\n",
      "Fold: 10  Epoch: 130  Training loss = 3.4108  Validation loss = 6.2553  \n",
      "\n",
      "Fold: 10  Epoch: 131  Training loss = 3.4105  Validation loss = 6.2544  \n",
      "\n",
      "Fold: 10  Epoch: 132  Training loss = 3.4101  Validation loss = 6.2533  \n",
      "\n",
      "Fold: 10  Epoch: 133  Training loss = 3.4099  Validation loss = 6.2525  \n",
      "\n",
      "Fold: 10  Epoch: 134  Training loss = 3.4094  Validation loss = 6.2510  \n",
      "\n",
      "Fold: 10  Epoch: 135  Training loss = 3.4091  Validation loss = 6.2502  \n",
      "\n",
      "Fold: 10  Epoch: 136  Training loss = 3.4087  Validation loss = 6.2490  \n",
      "\n",
      "Fold: 10  Epoch: 137  Training loss = 3.4084  Validation loss = 6.2479  \n",
      "\n",
      "Fold: 10  Epoch: 138  Training loss = 3.4080  Validation loss = 6.2470  \n",
      "\n",
      "Fold: 10  Epoch: 139  Training loss = 3.4077  Validation loss = 6.2463  \n",
      "\n",
      "Fold: 10  Epoch: 140  Training loss = 3.4074  Validation loss = 6.2452  \n",
      "\n",
      "Fold: 10  Epoch: 141  Training loss = 3.4069  Validation loss = 6.2436  \n",
      "\n",
      "Fold: 10  Epoch: 142  Training loss = 3.4067  Validation loss = 6.2430  \n",
      "\n",
      "Fold: 10  Epoch: 143  Training loss = 3.4064  Validation loss = 6.2419  \n",
      "\n",
      "Fold: 10  Epoch: 144  Training loss = 3.4060  Validation loss = 6.2410  \n",
      "\n",
      "Fold: 10  Epoch: 145  Training loss = 3.4057  Validation loss = 6.2403  \n",
      "\n",
      "Fold: 10  Epoch: 146  Training loss = 3.4053  Validation loss = 6.2392  \n",
      "\n",
      "Fold: 10  Epoch: 147  Training loss = 3.4050  Validation loss = 6.2384  \n",
      "\n",
      "Fold: 10  Epoch: 148  Training loss = 3.4048  Validation loss = 6.2377  \n",
      "\n",
      "Fold: 10  Epoch: 149  Training loss = 3.4044  Validation loss = 6.2368  \n",
      "\n",
      "Fold: 10  Epoch: 150  Training loss = 3.4041  Validation loss = 6.2361  \n",
      "\n",
      "Fold: 10  Epoch: 151  Training loss = 3.4038  Validation loss = 6.2354  \n",
      "\n",
      "Fold: 10  Epoch: 152  Training loss = 3.4034  Validation loss = 6.2344  \n",
      "\n",
      "Fold: 10  Epoch: 153  Training loss = 3.4030  Validation loss = 6.2333  \n",
      "\n",
      "Fold: 10  Epoch: 154  Training loss = 3.4026  Validation loss = 6.2321  \n",
      "\n",
      "Fold: 10  Epoch: 155  Training loss = 3.4020  Validation loss = 6.2305  \n",
      "\n",
      "Fold: 10  Epoch: 156  Training loss = 3.4015  Validation loss = 6.2286  \n",
      "\n",
      "Fold: 10  Epoch: 157  Training loss = 3.4011  Validation loss = 6.2277  \n",
      "\n",
      "Fold: 10  Epoch: 158  Training loss = 3.4006  Validation loss = 6.2265  \n",
      "\n",
      "Fold: 10  Epoch: 159  Training loss = 3.4002  Validation loss = 6.2254  \n",
      "\n",
      "Fold: 10  Epoch: 160  Training loss = 3.4000  Validation loss = 6.2247  \n",
      "\n",
      "Fold: 10  Epoch: 161  Training loss = 3.3996  Validation loss = 6.2238  \n",
      "\n",
      "Fold: 10  Epoch: 162  Training loss = 3.3993  Validation loss = 6.2230  \n",
      "\n",
      "Fold: 10  Epoch: 163  Training loss = 3.3990  Validation loss = 6.2221  \n",
      "\n",
      "Fold: 10  Epoch: 164  Training loss = 3.3987  Validation loss = 6.2211  \n",
      "\n",
      "Fold: 10  Epoch: 165  Training loss = 3.3984  Validation loss = 6.2203  \n",
      "\n",
      "Fold: 10  Epoch: 166  Training loss = 3.3981  Validation loss = 6.2193  \n",
      "\n",
      "Fold: 10  Epoch: 167  Training loss = 3.3976  Validation loss = 6.2176  \n",
      "\n",
      "Fold: 10  Epoch: 168  Training loss = 3.3972  Validation loss = 6.2163  \n",
      "\n",
      "Fold: 10  Epoch: 169  Training loss = 3.3969  Validation loss = 6.2153  \n",
      "\n",
      "Fold: 10  Epoch: 170  Training loss = 3.3965  Validation loss = 6.2141  \n",
      "\n",
      "Fold: 10  Epoch: 171  Training loss = 3.3961  Validation loss = 6.2127  \n",
      "\n",
      "Fold: 10  Epoch: 172  Training loss = 3.3957  Validation loss = 6.2113  \n",
      "\n",
      "Fold: 10  Epoch: 173  Training loss = 3.3954  Validation loss = 6.2104  \n",
      "\n",
      "Fold: 10  Epoch: 174  Training loss = 3.3949  Validation loss = 6.2087  \n",
      "\n",
      "Fold: 10  Epoch: 175  Training loss = 3.3946  Validation loss = 6.2080  \n",
      "\n",
      "Fold: 10  Epoch: 176  Training loss = 3.3943  Validation loss = 6.2071  \n",
      "\n",
      "Fold: 10  Epoch: 177  Training loss = 3.3940  Validation loss = 6.2063  \n",
      "\n",
      "Fold: 10  Epoch: 178  Training loss = 3.3936  Validation loss = 6.2049  \n",
      "\n",
      "Fold: 10  Epoch: 179  Training loss = 3.3932  Validation loss = 6.2034  \n",
      "\n",
      "Fold: 10  Epoch: 180  Training loss = 3.3927  Validation loss = 6.2016  \n",
      "\n",
      "Fold: 10  Epoch: 181  Training loss = 3.3924  Validation loss = 6.2005  \n",
      "\n",
      "Fold: 10  Epoch: 182  Training loss = 3.3921  Validation loss = 6.1994  \n",
      "\n",
      "Fold: 10  Epoch: 183  Training loss = 3.3917  Validation loss = 6.1983  \n",
      "\n",
      "Fold: 10  Epoch: 184  Training loss = 3.3914  Validation loss = 6.1975  \n",
      "\n",
      "Fold: 10  Epoch: 185  Training loss = 3.3911  Validation loss = 6.1959  \n",
      "\n",
      "Fold: 10  Epoch: 186  Training loss = 3.3906  Validation loss = 6.1948  \n",
      "\n",
      "Fold: 10  Epoch: 187  Training loss = 3.3903  Validation loss = 6.1934  \n",
      "\n",
      "Fold: 10  Epoch: 188  Training loss = 3.3899  Validation loss = 6.1923  \n",
      "\n",
      "Fold: 10  Epoch: 189  Training loss = 3.3895  Validation loss = 6.1914  \n",
      "\n",
      "Fold: 10  Epoch: 190  Training loss = 3.3891  Validation loss = 6.1904  \n",
      "\n",
      "Fold: 10  Epoch: 191  Training loss = 3.3889  Validation loss = 6.1898  \n",
      "\n",
      "Fold: 10  Epoch: 192  Training loss = 3.3885  Validation loss = 6.1884  \n",
      "\n",
      "Fold: 10  Epoch: 193  Training loss = 3.3881  Validation loss = 6.1875  \n",
      "\n",
      "Fold: 10  Epoch: 194  Training loss = 3.3877  Validation loss = 6.1864  \n",
      "\n",
      "Fold: 10  Epoch: 195  Training loss = 3.3874  Validation loss = 6.1854  \n",
      "\n",
      "Fold: 10  Epoch: 196  Training loss = 3.3870  Validation loss = 6.1841  \n",
      "\n",
      "Fold: 10  Epoch: 197  Training loss = 3.3866  Validation loss = 6.1830  \n",
      "\n",
      "Fold: 10  Epoch: 198  Training loss = 3.3863  Validation loss = 6.1817  \n",
      "\n",
      "Fold: 10  Epoch: 199  Training loss = 3.3859  Validation loss = 6.1805  \n",
      "\n",
      "Fold: 10  Epoch: 200  Training loss = 3.3854  Validation loss = 6.1795  \n",
      "\n",
      "Fold: 10  Epoch: 201  Training loss = 3.3850  Validation loss = 6.1781  \n",
      "\n",
      "Fold: 10  Epoch: 202  Training loss = 3.3847  Validation loss = 6.1769  \n",
      "\n",
      "Fold: 10  Epoch: 203  Training loss = 3.3842  Validation loss = 6.1757  \n",
      "\n",
      "Fold: 10  Epoch: 204  Training loss = 3.3839  Validation loss = 6.1746  \n",
      "\n",
      "Fold: 10  Epoch: 205  Training loss = 3.3836  Validation loss = 6.1739  \n",
      "\n",
      "Fold: 10  Epoch: 206  Training loss = 3.3833  Validation loss = 6.1730  \n",
      "\n",
      "Fold: 10  Epoch: 207  Training loss = 3.3830  Validation loss = 6.1719  \n",
      "\n",
      "Fold: 10  Epoch: 208  Training loss = 3.3828  Validation loss = 6.1713  \n",
      "\n",
      "Fold: 10  Epoch: 209  Training loss = 3.3825  Validation loss = 6.1701  \n",
      "\n",
      "Fold: 10  Epoch: 210  Training loss = 3.3821  Validation loss = 6.1690  \n",
      "\n",
      "Fold: 10  Epoch: 211  Training loss = 3.3818  Validation loss = 6.1683  \n",
      "\n",
      "Fold: 10  Epoch: 212  Training loss = 3.3814  Validation loss = 6.1672  \n",
      "\n",
      "Fold: 10  Epoch: 213  Training loss = 3.3811  Validation loss = 6.1662  \n",
      "\n",
      "Fold: 10  Epoch: 214  Training loss = 3.3809  Validation loss = 6.1658  \n",
      "\n",
      "Fold: 10  Epoch: 215  Training loss = 3.3806  Validation loss = 6.1642  \n",
      "\n",
      "Fold: 10  Epoch: 216  Training loss = 3.3804  Validation loss = 6.1639  \n",
      "\n",
      "Fold: 10  Epoch: 217  Training loss = 3.3801  Validation loss = 6.1631  \n",
      "\n",
      "Fold: 10  Epoch: 218  Training loss = 3.3797  Validation loss = 6.1617  \n",
      "\n",
      "Fold: 10  Epoch: 219  Training loss = 3.3794  Validation loss = 6.1609  \n",
      "\n",
      "Fold: 10  Epoch: 220  Training loss = 3.3790  Validation loss = 6.1596  \n",
      "\n",
      "Fold: 10  Epoch: 221  Training loss = 3.3787  Validation loss = 6.1586  \n",
      "\n",
      "Fold: 10  Epoch: 222  Training loss = 3.3784  Validation loss = 6.1579  \n",
      "\n",
      "Fold: 10  Epoch: 223  Training loss = 3.3782  Validation loss = 6.1573  \n",
      "\n",
      "Fold: 10  Epoch: 224  Training loss = 3.3778  Validation loss = 6.1563  \n",
      "\n",
      "Fold: 10  Epoch: 225  Training loss = 3.3774  Validation loss = 6.1550  \n",
      "\n",
      "Fold: 10  Epoch: 226  Training loss = 3.3769  Validation loss = 6.1537  \n",
      "\n",
      "Fold: 10  Epoch: 227  Training loss = 3.3766  Validation loss = 6.1524  \n",
      "\n",
      "Fold: 10  Epoch: 228  Training loss = 3.3761  Validation loss = 6.1509  \n",
      "\n",
      "Fold: 10  Epoch: 229  Training loss = 3.3759  Validation loss = 6.1500  \n",
      "\n",
      "Fold: 10  Epoch: 230  Training loss = 3.3756  Validation loss = 6.1493  \n",
      "\n",
      "Fold: 10  Epoch: 231  Training loss = 3.3753  Validation loss = 6.1486  \n",
      "\n",
      "Fold: 10  Epoch: 232  Training loss = 3.3750  Validation loss = 6.1479  \n",
      "\n",
      "Fold: 10  Epoch: 233  Training loss = 3.3746  Validation loss = 6.1469  \n",
      "\n",
      "Fold: 10  Epoch: 234  Training loss = 3.3742  Validation loss = 6.1459  \n",
      "\n",
      "Fold: 10  Epoch: 235  Training loss = 3.3739  Validation loss = 6.1452  \n",
      "\n",
      "Fold: 10  Epoch: 236  Training loss = 3.3735  Validation loss = 6.1437  \n",
      "\n",
      "Fold: 10  Epoch: 237  Training loss = 3.3732  Validation loss = 6.1430  \n",
      "\n",
      "Fold: 10  Epoch: 238  Training loss = 3.3727  Validation loss = 6.1416  \n",
      "\n",
      "Fold: 10  Epoch: 239  Training loss = 3.3723  Validation loss = 6.1407  \n",
      "\n",
      "Fold: 10  Epoch: 240  Training loss = 3.3720  Validation loss = 6.1399  \n",
      "\n",
      "Fold: 10  Epoch: 241  Training loss = 3.3716  Validation loss = 6.1389  \n",
      "\n",
      "Fold: 10  Epoch: 242  Training loss = 3.3713  Validation loss = 6.1382  \n",
      "\n",
      "Fold: 10  Epoch: 243  Training loss = 3.3709  Validation loss = 6.1366  \n",
      "\n",
      "Fold: 10  Epoch: 244  Training loss = 3.3705  Validation loss = 6.1355  \n",
      "\n",
      "Fold: 10  Epoch: 245  Training loss = 3.3702  Validation loss = 6.1343  \n",
      "\n",
      "Fold: 10  Epoch: 246  Training loss = 3.3699  Validation loss = 6.1334  \n",
      "\n",
      "Fold: 10  Epoch: 247  Training loss = 3.3696  Validation loss = 6.1327  \n",
      "\n",
      "Fold: 10  Epoch: 248  Training loss = 3.3692  Validation loss = 6.1315  \n",
      "\n",
      "Fold: 10  Epoch: 249  Training loss = 3.3690  Validation loss = 6.1308  \n",
      "\n",
      "Fold: 10  Epoch: 250  Training loss = 3.3686  Validation loss = 6.1296  \n",
      "\n",
      "Fold: 10  Epoch: 251  Training loss = 3.3683  Validation loss = 6.1289  \n",
      "\n",
      "Fold: 10  Epoch: 252  Training loss = 3.3681  Validation loss = 6.1283  \n",
      "\n",
      "Fold: 10  Epoch: 253  Training loss = 3.3678  Validation loss = 6.1272  \n",
      "\n",
      "Fold: 10  Epoch: 254  Training loss = 3.3674  Validation loss = 6.1263  \n",
      "\n",
      "Fold: 10  Epoch: 255  Training loss = 3.3670  Validation loss = 6.1252  \n",
      "\n",
      "Fold: 10  Epoch: 256  Training loss = 3.3666  Validation loss = 6.1239  \n",
      "\n",
      "Fold: 10  Epoch: 257  Training loss = 3.3663  Validation loss = 6.1231  \n",
      "\n",
      "Fold: 10  Epoch: 258  Training loss = 3.3659  Validation loss = 6.1222  \n",
      "\n",
      "Fold: 10  Epoch: 259  Training loss = 3.3656  Validation loss = 6.1214  \n",
      "\n",
      "Fold: 10  Epoch: 260  Training loss = 3.3654  Validation loss = 6.1208  \n",
      "\n",
      "Fold: 10  Epoch: 261  Training loss = 3.3651  Validation loss = 6.1200  \n",
      "\n",
      "Fold: 10  Epoch: 262  Training loss = 3.3647  Validation loss = 6.1192  \n",
      "\n",
      "Fold: 10  Epoch: 263  Training loss = 3.3645  Validation loss = 6.1186  \n",
      "\n",
      "Fold: 10  Epoch: 264  Training loss = 3.3640  Validation loss = 6.1173  \n",
      "\n",
      "Fold: 10  Epoch: 265  Training loss = 3.3637  Validation loss = 6.1165  \n",
      "\n",
      "Fold: 10  Epoch: 266  Training loss = 3.3633  Validation loss = 6.1153  \n",
      "\n",
      "Fold: 10  Epoch: 267  Training loss = 3.3628  Validation loss = 6.1138  \n",
      "\n",
      "Fold: 10  Epoch: 268  Training loss = 3.3624  Validation loss = 6.1123  \n",
      "\n",
      "Fold: 10  Epoch: 269  Training loss = 3.3621  Validation loss = 6.1117  \n",
      "\n",
      "Fold: 10  Epoch: 270  Training loss = 3.3619  Validation loss = 6.1109  \n",
      "\n",
      "Fold: 10  Epoch: 271  Training loss = 3.3615  Validation loss = 6.1097  \n",
      "\n",
      "Fold: 10  Epoch: 272  Training loss = 3.3612  Validation loss = 6.1089  \n",
      "\n",
      "Fold: 10  Epoch: 273  Training loss = 3.3608  Validation loss = 6.1082  \n",
      "\n",
      "Fold: 10  Epoch: 274  Training loss = 3.3607  Validation loss = 6.1077  \n",
      "\n",
      "Fold: 10  Epoch: 275  Training loss = 3.3602  Validation loss = 6.1065  \n",
      "\n",
      "Fold: 10  Epoch: 276  Training loss = 3.3599  Validation loss = 6.1057  \n",
      "\n",
      "Fold: 10  Epoch: 277  Training loss = 3.3596  Validation loss = 6.1045  \n",
      "\n",
      "Fold: 10  Epoch: 278  Training loss = 3.3592  Validation loss = 6.1030  \n",
      "\n",
      "Fold: 10  Epoch: 279  Training loss = 3.3588  Validation loss = 6.1021  \n",
      "\n",
      "Fold: 10  Epoch: 280  Training loss = 3.3584  Validation loss = 6.1008  \n",
      "\n",
      "Fold: 10  Epoch: 281  Training loss = 3.3581  Validation loss = 6.0999  \n",
      "\n",
      "Fold: 10  Epoch: 282  Training loss = 3.3576  Validation loss = 6.0984  \n",
      "\n",
      "Fold: 10  Epoch: 283  Training loss = 3.3572  Validation loss = 6.0975  \n",
      "\n",
      "Fold: 10  Epoch: 284  Training loss = 3.3570  Validation loss = 6.0967  \n",
      "\n",
      "Fold: 10  Epoch: 285  Training loss = 3.3567  Validation loss = 6.0958  \n",
      "\n",
      "Fold: 10  Epoch: 286  Training loss = 3.3563  Validation loss = 6.0950  \n",
      "\n",
      "Fold: 10  Epoch: 287  Training loss = 3.3561  Validation loss = 6.0945  \n",
      "\n",
      "Fold: 10  Epoch: 288  Training loss = 3.3557  Validation loss = 6.0934  \n",
      "\n",
      "Fold: 10  Epoch: 289  Training loss = 3.3554  Validation loss = 6.0925  \n",
      "\n",
      "Fold: 10  Epoch: 290  Training loss = 3.3549  Validation loss = 6.0911  \n",
      "\n",
      "Fold: 10  Epoch: 291  Training loss = 3.3546  Validation loss = 6.0903  \n",
      "\n",
      "Fold: 10  Epoch: 292  Training loss = 3.3543  Validation loss = 6.0895  \n",
      "\n",
      "Fold: 10  Epoch: 293  Training loss = 3.3541  Validation loss = 6.0890  \n",
      "\n",
      "Fold: 10  Epoch: 294  Training loss = 3.3535  Validation loss = 6.0875  \n",
      "\n",
      "Fold: 10  Epoch: 295  Training loss = 3.3532  Validation loss = 6.0866  \n",
      "\n",
      "Fold: 10  Epoch: 296  Training loss = 3.3528  Validation loss = 6.0855  \n",
      "\n",
      "Fold: 10  Epoch: 297  Training loss = 3.3527  Validation loss = 6.0852  \n",
      "\n",
      "Fold: 10  Epoch: 298  Training loss = 3.3522  Validation loss = 6.0843  \n",
      "\n",
      "Fold: 10  Epoch: 299  Training loss = 3.3517  Validation loss = 6.0830  \n",
      "\n",
      "Fold: 10  Epoch: 300  Training loss = 3.3513  Validation loss = 6.0819  \n",
      "\n",
      "Fold: 10  Epoch: 301  Training loss = 3.3510  Validation loss = 6.0809  \n",
      "\n",
      "Fold: 10  Epoch: 302  Training loss = 3.3506  Validation loss = 6.0798  \n",
      "\n",
      "Fold: 10  Epoch: 303  Training loss = 3.3503  Validation loss = 6.0788  \n",
      "\n",
      "Fold: 10  Epoch: 304  Training loss = 3.3500  Validation loss = 6.0781  \n",
      "\n",
      "Fold: 10  Epoch: 305  Training loss = 3.3497  Validation loss = 6.0774  \n",
      "\n",
      "Fold: 10  Epoch: 306  Training loss = 3.3495  Validation loss = 6.0767  \n",
      "\n",
      "Fold: 10  Epoch: 307  Training loss = 3.3492  Validation loss = 6.0763  \n",
      "\n",
      "Fold: 10  Epoch: 308  Training loss = 3.3489  Validation loss = 6.0757  \n",
      "\n",
      "Fold: 10  Epoch: 309  Training loss = 3.3486  Validation loss = 6.0750  \n",
      "\n",
      "Fold: 10  Epoch: 310  Training loss = 3.3482  Validation loss = 6.0740  \n",
      "\n",
      "Fold: 10  Epoch: 311  Training loss = 3.3478  Validation loss = 6.0729  \n",
      "\n",
      "Fold: 10  Epoch: 312  Training loss = 3.3475  Validation loss = 6.0717  \n",
      "\n",
      "Fold: 10  Epoch: 313  Training loss = 3.3472  Validation loss = 6.0710  \n",
      "\n",
      "Fold: 10  Epoch: 314  Training loss = 3.3468  Validation loss = 6.0700  \n",
      "\n",
      "Fold: 10  Epoch: 315  Training loss = 3.3466  Validation loss = 6.0693  \n",
      "\n",
      "Fold: 10  Epoch: 316  Training loss = 3.3465  Validation loss = 6.0691  \n",
      "\n",
      "Fold: 10  Epoch: 317  Training loss = 3.3461  Validation loss = 6.0679  \n",
      "\n",
      "Fold: 10  Epoch: 318  Training loss = 3.3458  Validation loss = 6.0672  \n",
      "\n",
      "Fold: 10  Epoch: 319  Training loss = 3.3454  Validation loss = 6.0664  \n",
      "\n",
      "Fold: 10  Epoch: 320  Training loss = 3.3452  Validation loss = 6.0658  \n",
      "\n",
      "Fold: 10  Epoch: 321  Training loss = 3.3449  Validation loss = 6.0652  \n",
      "\n",
      "Fold: 10  Epoch: 322  Training loss = 3.3446  Validation loss = 6.0646  \n",
      "\n",
      "Fold: 10  Epoch: 323  Training loss = 3.3442  Validation loss = 6.0638  \n",
      "\n",
      "Fold: 10  Epoch: 324  Training loss = 3.3440  Validation loss = 6.0634  \n",
      "\n",
      "Fold: 10  Epoch: 325  Training loss = 3.3438  Validation loss = 6.0629  \n",
      "\n",
      "Fold: 10  Epoch: 326  Training loss = 3.3435  Validation loss = 6.0620  \n",
      "\n",
      "Fold: 10  Epoch: 327  Training loss = 3.3432  Validation loss = 6.0610  \n",
      "\n",
      "Fold: 10  Epoch: 328  Training loss = 3.3429  Validation loss = 6.0602  \n",
      "\n",
      "Fold: 10  Epoch: 329  Training loss = 3.3427  Validation loss = 6.0595  \n",
      "\n",
      "Fold: 10  Epoch: 330  Training loss = 3.3424  Validation loss = 6.0589  \n",
      "\n",
      "Fold: 10  Epoch: 331  Training loss = 3.3421  Validation loss = 6.0582  \n",
      "\n",
      "Fold: 10  Epoch: 332  Training loss = 3.3418  Validation loss = 6.0577  \n",
      "\n",
      "Fold: 10  Epoch: 333  Training loss = 3.3415  Validation loss = 6.0568  \n",
      "\n",
      "Fold: 10  Epoch: 334  Training loss = 3.3412  Validation loss = 6.0560  \n",
      "\n",
      "Fold: 10  Epoch: 335  Training loss = 3.3409  Validation loss = 6.0552  \n",
      "\n",
      "Fold: 10  Epoch: 336  Training loss = 3.3407  Validation loss = 6.0546  \n",
      "\n",
      "Fold: 10  Epoch: 337  Training loss = 3.3405  Validation loss = 6.0542  \n",
      "\n",
      "Fold: 10  Epoch: 338  Training loss = 3.3403  Validation loss = 6.0537  \n",
      "\n",
      "Fold: 10  Epoch: 339  Training loss = 3.3398  Validation loss = 6.0527  \n",
      "\n",
      "Fold: 10  Epoch: 340  Training loss = 3.3396  Validation loss = 6.0520  \n",
      "\n",
      "Fold: 10  Epoch: 341  Training loss = 3.3393  Validation loss = 6.0514  \n",
      "\n",
      "Fold: 10  Epoch: 342  Training loss = 3.3389  Validation loss = 6.0504  \n",
      "\n",
      "Fold: 10  Epoch: 343  Training loss = 3.3387  Validation loss = 6.0500  \n",
      "\n",
      "Fold: 10  Epoch: 344  Training loss = 3.3383  Validation loss = 6.0490  \n",
      "\n",
      "Fold: 10  Epoch: 345  Training loss = 3.3381  Validation loss = 6.0484  \n",
      "\n",
      "Fold: 10  Epoch: 346  Training loss = 3.3378  Validation loss = 6.0477  \n",
      "\n",
      "Fold: 10  Epoch: 347  Training loss = 3.3374  Validation loss = 6.0468  \n",
      "\n",
      "Fold: 10  Epoch: 348  Training loss = 3.3370  Validation loss = 6.0460  \n",
      "\n",
      "Fold: 10  Epoch: 349  Training loss = 3.3367  Validation loss = 6.0453  \n",
      "\n",
      "Fold: 10  Epoch: 350  Training loss = 3.3364  Validation loss = 6.0447  \n",
      "\n",
      "Fold: 10  Epoch: 351  Training loss = 3.3361  Validation loss = 6.0440  \n",
      "\n",
      "Fold: 10  Epoch: 352  Training loss = 3.3358  Validation loss = 6.0433  \n",
      "\n",
      "Fold: 10  Epoch: 353  Training loss = 3.3355  Validation loss = 6.0427  \n",
      "\n",
      "Fold: 10  Epoch: 354  Training loss = 3.3352  Validation loss = 6.0418  \n",
      "\n",
      "Fold: 10  Epoch: 355  Training loss = 3.3348  Validation loss = 6.0410  \n",
      "\n",
      "Fold: 10  Epoch: 356  Training loss = 3.3346  Validation loss = 6.0405  \n",
      "\n",
      "Fold: 10  Epoch: 357  Training loss = 3.3343  Validation loss = 6.0399  \n",
      "\n",
      "Fold: 10  Epoch: 358  Training loss = 3.3339  Validation loss = 6.0392  \n",
      "\n",
      "Fold: 10  Epoch: 359  Training loss = 3.3337  Validation loss = 6.0385  \n",
      "\n",
      "Fold: 10  Epoch: 360  Training loss = 3.3333  Validation loss = 6.0376  \n",
      "\n",
      "Fold: 10  Epoch: 361  Training loss = 3.3330  Validation loss = 6.0369  \n",
      "\n",
      "Fold: 10  Epoch: 362  Training loss = 3.3328  Validation loss = 6.0364  \n",
      "\n",
      "Fold: 10  Epoch: 363  Training loss = 3.3325  Validation loss = 6.0358  \n",
      "\n",
      "Fold: 10  Epoch: 364  Training loss = 3.3321  Validation loss = 6.0350  \n",
      "\n",
      "Fold: 10  Epoch: 365  Training loss = 3.3318  Validation loss = 6.0341  \n",
      "\n",
      "Fold: 10  Epoch: 366  Training loss = 3.3315  Validation loss = 6.0332  \n",
      "\n",
      "Fold: 10  Epoch: 367  Training loss = 3.3311  Validation loss = 6.0321  \n",
      "\n",
      "Fold: 10  Epoch: 368  Training loss = 3.3309  Validation loss = 6.0315  \n",
      "\n",
      "Fold: 10  Epoch: 369  Training loss = 3.3307  Validation loss = 6.0310  \n",
      "\n",
      "Fold: 10  Epoch: 370  Training loss = 3.3303  Validation loss = 6.0303  \n",
      "\n",
      "Fold: 10  Epoch: 371  Training loss = 3.3301  Validation loss = 6.0297  \n",
      "\n",
      "Fold: 10  Epoch: 372  Training loss = 3.3298  Validation loss = 6.0288  \n",
      "\n",
      "Fold: 10  Epoch: 373  Training loss = 3.3295  Validation loss = 6.0281  \n",
      "\n",
      "Fold: 10  Epoch: 374  Training loss = 3.3292  Validation loss = 6.0274  \n",
      "\n",
      "Fold: 10  Epoch: 375  Training loss = 3.3288  Validation loss = 6.0264  \n",
      "\n",
      "Fold: 10  Epoch: 376  Training loss = 3.3285  Validation loss = 6.0257  \n",
      "\n",
      "Fold: 10  Epoch: 377  Training loss = 3.3282  Validation loss = 6.0249  \n",
      "\n",
      "Fold: 10  Epoch: 378  Training loss = 3.3279  Validation loss = 6.0242  \n",
      "\n",
      "Fold: 10  Epoch: 379  Training loss = 3.3276  Validation loss = 6.0234  \n",
      "\n",
      "Fold: 10  Epoch: 380  Training loss = 3.3272  Validation loss = 6.0223  \n",
      "\n",
      "Fold: 10  Epoch: 381  Training loss = 3.3269  Validation loss = 6.0216  \n",
      "\n",
      "Fold: 10  Epoch: 382  Training loss = 3.3265  Validation loss = 6.0208  \n",
      "\n",
      "Fold: 10  Epoch: 383  Training loss = 3.3262  Validation loss = 6.0203  \n",
      "\n",
      "Fold: 10  Epoch: 384  Training loss = 3.3259  Validation loss = 6.0195  \n",
      "\n",
      "Fold: 10  Epoch: 385  Training loss = 3.3257  Validation loss = 6.0192  \n",
      "\n",
      "Fold: 10  Epoch: 386  Training loss = 3.3254  Validation loss = 6.0184  \n",
      "\n",
      "Fold: 10  Epoch: 387  Training loss = 3.3251  Validation loss = 6.0178  \n",
      "\n",
      "Fold: 10  Epoch: 388  Training loss = 3.3247  Validation loss = 6.0170  \n",
      "\n",
      "Fold: 10  Epoch: 389  Training loss = 3.3244  Validation loss = 6.0161  \n",
      "\n",
      "Fold: 10  Epoch: 390  Training loss = 3.3239  Validation loss = 6.0153  \n",
      "\n",
      "Fold: 10  Epoch: 391  Training loss = 3.3237  Validation loss = 6.0147  \n",
      "\n",
      "Fold: 10  Epoch: 392  Training loss = 3.3233  Validation loss = 6.0138  \n",
      "\n",
      "Fold: 10  Epoch: 393  Training loss = 3.3230  Validation loss = 6.0131  \n",
      "\n",
      "Fold: 10  Epoch: 394  Training loss = 3.3226  Validation loss = 6.0123  \n",
      "\n",
      "Fold: 10  Epoch: 395  Training loss = 3.3223  Validation loss = 6.0115  \n",
      "\n",
      "Fold: 10  Epoch: 396  Training loss = 3.3219  Validation loss = 6.0105  \n",
      "\n",
      "Fold: 10  Epoch: 397  Training loss = 3.3217  Validation loss = 6.0099  \n",
      "\n",
      "Fold: 10  Epoch: 398  Training loss = 3.3214  Validation loss = 6.0091  \n",
      "\n",
      "Fold: 10  Epoch: 399  Training loss = 3.3209  Validation loss = 6.0079  \n",
      "\n",
      "Fold: 10  Epoch: 400  Training loss = 3.3206  Validation loss = 6.0071  \n",
      "\n",
      "Fold: 10  Epoch: 401  Training loss = 3.3203  Validation loss = 6.0063  \n",
      "\n",
      "Fold: 10  Epoch: 402  Training loss = 3.3200  Validation loss = 6.0058  \n",
      "\n",
      "Fold: 10  Epoch: 403  Training loss = 3.3196  Validation loss = 6.0049  \n",
      "\n",
      "Fold: 10  Epoch: 404  Training loss = 3.3192  Validation loss = 6.0039  \n",
      "\n",
      "Fold: 10  Epoch: 405  Training loss = 3.3189  Validation loss = 6.0030  \n",
      "\n",
      "Fold: 10  Epoch: 406  Training loss = 3.3184  Validation loss = 6.0017  \n",
      "\n",
      "Fold: 10  Epoch: 407  Training loss = 3.3181  Validation loss = 6.0012  \n",
      "\n",
      "Fold: 10  Epoch: 408  Training loss = 3.3177  Validation loss = 6.0003  \n",
      "\n",
      "Fold: 10  Epoch: 409  Training loss = 3.3173  Validation loss = 5.9993  \n",
      "\n",
      "Fold: 10  Epoch: 410  Training loss = 3.3170  Validation loss = 5.9985  \n",
      "\n",
      "Fold: 10  Epoch: 411  Training loss = 3.3168  Validation loss = 5.9979  \n",
      "\n",
      "Fold: 10  Epoch: 412  Training loss = 3.3164  Validation loss = 5.9971  \n",
      "\n",
      "Fold: 10  Epoch: 413  Training loss = 3.3160  Validation loss = 5.9961  \n",
      "\n",
      "Fold: 10  Epoch: 414  Training loss = 3.3157  Validation loss = 5.9955  \n",
      "\n",
      "Fold: 10  Epoch: 415  Training loss = 3.3154  Validation loss = 5.9947  \n",
      "\n",
      "Fold: 10  Epoch: 416  Training loss = 3.3151  Validation loss = 5.9939  \n",
      "\n",
      "Fold: 10  Epoch: 417  Training loss = 3.3147  Validation loss = 5.9932  \n",
      "\n",
      "Fold: 10  Epoch: 418  Training loss = 3.3146  Validation loss = 5.9929  \n",
      "\n",
      "Fold: 10  Epoch: 419  Training loss = 3.3142  Validation loss = 5.9918  \n",
      "\n",
      "Fold: 10  Epoch: 420  Training loss = 3.3138  Validation loss = 5.9906  \n",
      "\n",
      "Fold: 10  Epoch: 421  Training loss = 3.3134  Validation loss = 5.9897  \n",
      "\n",
      "Fold: 10  Epoch: 422  Training loss = 3.3133  Validation loss = 5.9892  \n",
      "\n",
      "Fold: 10  Epoch: 423  Training loss = 3.3130  Validation loss = 5.9886  \n",
      "\n",
      "Fold: 10  Epoch: 424  Training loss = 3.3128  Validation loss = 5.9881  \n",
      "\n",
      "Fold: 10  Epoch: 425  Training loss = 3.3125  Validation loss = 5.9876  \n",
      "\n",
      "Fold: 10  Epoch: 426  Training loss = 3.3123  Validation loss = 5.9870  \n",
      "\n",
      "Fold: 10  Epoch: 427  Training loss = 3.3120  Validation loss = 5.9865  \n",
      "\n",
      "Fold: 10  Epoch: 428  Training loss = 3.3116  Validation loss = 5.9856  \n",
      "\n",
      "Fold: 10  Epoch: 429  Training loss = 3.3113  Validation loss = 5.9849  \n",
      "\n",
      "Fold: 10  Epoch: 430  Training loss = 3.3110  Validation loss = 5.9840  \n",
      "\n",
      "Fold: 10  Epoch: 431  Training loss = 3.3108  Validation loss = 5.9834  \n",
      "\n",
      "Fold: 10  Epoch: 432  Training loss = 3.3105  Validation loss = 5.9829  \n",
      "\n",
      "Fold: 10  Epoch: 433  Training loss = 3.3103  Validation loss = 5.9825  \n",
      "\n",
      "Fold: 10  Epoch: 434  Training loss = 3.3101  Validation loss = 5.9818  \n",
      "\n",
      "Fold: 10  Epoch: 435  Training loss = 3.3098  Validation loss = 5.9812  \n",
      "\n",
      "Fold: 10  Epoch: 436  Training loss = 3.3097  Validation loss = 5.9806  \n",
      "\n",
      "Fold: 10  Epoch: 437  Training loss = 3.3095  Validation loss = 5.9802  \n",
      "\n",
      "Fold: 10  Epoch: 438  Training loss = 3.3093  Validation loss = 5.9797  \n",
      "\n",
      "Fold: 10  Epoch: 439  Training loss = 3.3090  Validation loss = 5.9790  \n",
      "\n",
      "Fold: 10  Epoch: 440  Training loss = 3.3087  Validation loss = 5.9782  \n",
      "\n",
      "Fold: 10  Epoch: 441  Training loss = 3.3083  Validation loss = 5.9772  \n",
      "\n",
      "Fold: 10  Epoch: 442  Training loss = 3.3081  Validation loss = 5.9768  \n",
      "\n",
      "Fold: 10  Epoch: 443  Training loss = 3.3078  Validation loss = 5.9761  \n",
      "\n",
      "Fold: 10  Epoch: 444  Training loss = 3.3074  Validation loss = 5.9749  \n",
      "\n",
      "Fold: 10  Epoch: 445  Training loss = 3.3070  Validation loss = 5.9736  \n",
      "\n",
      "Fold: 10  Epoch: 446  Training loss = 3.3067  Validation loss = 5.9728  \n",
      "\n",
      "Fold: 10  Epoch: 447  Training loss = 3.3065  Validation loss = 5.9721  \n",
      "\n",
      "Fold: 10  Epoch: 448  Training loss = 3.3063  Validation loss = 5.9717  \n",
      "\n",
      "Fold: 10  Epoch: 449  Training loss = 3.3060  Validation loss = 5.9711  \n",
      "\n",
      "Fold: 10  Epoch: 450  Training loss = 3.3057  Validation loss = 5.9702  \n",
      "\n",
      "Fold: 10  Epoch: 451  Training loss = 3.3055  Validation loss = 5.9697  \n",
      "\n",
      "Fold: 10  Epoch: 452  Training loss = 3.3051  Validation loss = 5.9687  \n",
      "\n",
      "Fold: 10  Epoch: 453  Training loss = 3.3050  Validation loss = 5.9683  \n",
      "\n",
      "Fold: 10  Epoch: 454  Training loss = 3.3047  Validation loss = 5.9674  \n",
      "\n",
      "Fold: 10  Epoch: 455  Training loss = 3.3043  Validation loss = 5.9665  \n",
      "\n",
      "Fold: 10  Epoch: 456  Training loss = 3.3041  Validation loss = 5.9659  \n",
      "\n",
      "Fold: 10  Epoch: 457  Training loss = 3.3037  Validation loss = 5.9651  \n",
      "\n",
      "Fold: 10  Epoch: 458  Training loss = 3.3034  Validation loss = 5.9643  \n",
      "\n",
      "Fold: 10  Epoch: 459  Training loss = 3.3031  Validation loss = 5.9637  \n",
      "\n",
      "Fold: 10  Epoch: 460  Training loss = 3.3029  Validation loss = 5.9633  \n",
      "\n",
      "Fold: 10  Epoch: 461  Training loss = 3.3026  Validation loss = 5.9624  \n",
      "\n",
      "Fold: 10  Epoch: 462  Training loss = 3.3022  Validation loss = 5.9617  \n",
      "\n",
      "Fold: 10  Epoch: 463  Training loss = 3.3019  Validation loss = 5.9608  \n",
      "\n",
      "Fold: 10  Epoch: 464  Training loss = 3.3016  Validation loss = 5.9599  \n",
      "\n",
      "Fold: 10  Epoch: 465  Training loss = 3.3012  Validation loss = 5.9591  \n",
      "\n",
      "Fold: 10  Epoch: 466  Training loss = 3.3010  Validation loss = 5.9585  \n",
      "\n",
      "Fold: 10  Epoch: 467  Training loss = 3.3006  Validation loss = 5.9577  \n",
      "\n",
      "Fold: 10  Epoch: 468  Training loss = 3.3003  Validation loss = 5.9570  \n",
      "\n",
      "Fold: 10  Epoch: 469  Training loss = 3.3000  Validation loss = 5.9560  \n",
      "\n",
      "Fold: 10  Epoch: 470  Training loss = 3.2996  Validation loss = 5.9551  \n",
      "\n",
      "Fold: 10  Epoch: 471  Training loss = 3.2993  Validation loss = 5.9542  \n",
      "\n",
      "Fold: 10  Epoch: 472  Training loss = 3.2989  Validation loss = 5.9529  \n",
      "\n",
      "Fold: 10  Epoch: 473  Training loss = 3.2985  Validation loss = 5.9521  \n",
      "\n",
      "Fold: 10  Epoch: 474  Training loss = 3.2983  Validation loss = 5.9517  \n",
      "\n",
      "Fold: 10  Epoch: 475  Training loss = 3.2980  Validation loss = 5.9508  \n",
      "\n",
      "Fold: 10  Epoch: 476  Training loss = 3.2976  Validation loss = 5.9500  \n",
      "\n",
      "Fold: 10  Epoch: 477  Training loss = 3.2973  Validation loss = 5.9491  \n",
      "\n",
      "Fold: 10  Epoch: 478  Training loss = 3.2971  Validation loss = 5.9485  \n",
      "\n",
      "Fold: 10  Epoch: 479  Training loss = 3.2968  Validation loss = 5.9478  \n",
      "\n",
      "Fold: 10  Epoch: 480  Training loss = 3.2966  Validation loss = 5.9474  \n",
      "\n",
      "Fold: 10  Epoch: 481  Training loss = 3.2963  Validation loss = 5.9466  \n",
      "\n",
      "Fold: 10  Epoch: 482  Training loss = 3.2962  Validation loss = 5.9459  \n",
      "\n",
      "Fold: 10  Epoch: 483  Training loss = 3.2958  Validation loss = 5.9449  \n",
      "\n",
      "Fold: 10  Epoch: 484  Training loss = 3.2955  Validation loss = 5.9442  \n",
      "\n",
      "Fold: 10  Epoch: 485  Training loss = 3.2953  Validation loss = 5.9435  \n",
      "\n",
      "Fold: 10  Epoch: 486  Training loss = 3.2950  Validation loss = 5.9426  \n",
      "\n",
      "Fold: 10  Epoch: 487  Training loss = 3.2947  Validation loss = 5.9420  \n",
      "\n",
      "Fold: 10  Epoch: 488  Training loss = 3.2943  Validation loss = 5.9409  \n",
      "\n",
      "Fold: 10  Epoch: 489  Training loss = 3.2941  Validation loss = 5.9401  \n",
      "\n",
      "Fold: 10  Epoch: 490  Training loss = 3.2937  Validation loss = 5.9392  \n",
      "\n",
      "Fold: 10  Epoch: 491  Training loss = 3.2934  Validation loss = 5.9383  \n",
      "\n",
      "Fold: 10  Epoch: 492  Training loss = 3.2932  Validation loss = 5.9378  \n",
      "\n",
      "Fold: 10  Epoch: 493  Training loss = 3.2929  Validation loss = 5.9371  \n",
      "\n",
      "Fold: 10  Epoch: 494  Training loss = 3.2926  Validation loss = 5.9361  \n",
      "\n",
      "Fold: 10  Epoch: 495  Training loss = 3.2923  Validation loss = 5.9353  \n",
      "\n",
      "Fold: 10  Epoch: 496  Training loss = 3.2920  Validation loss = 5.9347  \n",
      "\n",
      "Fold: 10  Epoch: 497  Training loss = 3.2918  Validation loss = 5.9340  \n",
      "\n",
      "Fold: 10  Epoch: 498  Training loss = 3.2915  Validation loss = 5.9333  \n",
      "\n",
      "Fold: 10  Epoch: 499  Training loss = 3.2911  Validation loss = 5.9319  \n",
      "\n",
      "Fold: 10  Epoch: 500  Training loss = 3.2907  Validation loss = 5.9306  \n",
      "\n",
      "Check model:  Fold: 10  Optimal epoch: 500  \n",
      "\n",
      "Fold: 11  Epoch: 1  Training loss = 3.5856  Validation loss = 2.6980  \n",
      "\n",
      "Fold: 11  Epoch: 2  Training loss = 3.5841  Validation loss = 2.6970  \n",
      "\n",
      "Fold: 11  Epoch: 3  Training loss = 3.5833  Validation loss = 2.6960  \n",
      "\n",
      "Fold: 11  Epoch: 4  Training loss = 3.5829  Validation loss = 2.6951  \n",
      "\n",
      "Fold: 11  Epoch: 5  Training loss = 3.5823  Validation loss = 2.6941  \n",
      "\n",
      "Fold: 11  Epoch: 6  Training loss = 3.5817  Validation loss = 2.6930  \n",
      "\n",
      "Fold: 11  Epoch: 7  Training loss = 3.5810  Validation loss = 2.6917  \n",
      "\n",
      "Fold: 11  Epoch: 8  Training loss = 3.5805  Validation loss = 2.6908  \n",
      "\n",
      "Fold: 11  Epoch: 9  Training loss = 3.5801  Validation loss = 2.6898  \n",
      "\n",
      "Fold: 11  Epoch: 10  Training loss = 3.5795  Validation loss = 2.6889  \n",
      "\n",
      "Fold: 11  Epoch: 11  Training loss = 3.5791  Validation loss = 2.6881  \n",
      "\n",
      "Fold: 11  Epoch: 12  Training loss = 3.5786  Validation loss = 2.6870  \n",
      "\n",
      "Fold: 11  Epoch: 13  Training loss = 3.5780  Validation loss = 2.6859  \n",
      "\n",
      "Fold: 11  Epoch: 14  Training loss = 3.5774  Validation loss = 2.6848  \n",
      "\n",
      "Fold: 11  Epoch: 15  Training loss = 3.5769  Validation loss = 2.6838  \n",
      "\n",
      "Fold: 11  Epoch: 16  Training loss = 3.5762  Validation loss = 2.6825  \n",
      "\n",
      "Fold: 11  Epoch: 17  Training loss = 3.5759  Validation loss = 2.6818  \n",
      "\n",
      "Fold: 11  Epoch: 18  Training loss = 3.5755  Validation loss = 2.6810  \n",
      "\n",
      "Fold: 11  Epoch: 19  Training loss = 3.5750  Validation loss = 2.6800  \n",
      "\n",
      "Fold: 11  Epoch: 20  Training loss = 3.5747  Validation loss = 2.6794  \n",
      "\n",
      "Fold: 11  Epoch: 21  Training loss = 3.5741  Validation loss = 2.6784  \n",
      "\n",
      "Fold: 11  Epoch: 22  Training loss = 3.5736  Validation loss = 2.6773  \n",
      "\n",
      "Fold: 11  Epoch: 23  Training loss = 3.5731  Validation loss = 2.6763  \n",
      "\n",
      "Fold: 11  Epoch: 24  Training loss = 3.5728  Validation loss = 2.6757  \n",
      "\n",
      "Fold: 11  Epoch: 25  Training loss = 3.5722  Validation loss = 2.6745  \n",
      "\n",
      "Fold: 11  Epoch: 26  Training loss = 3.5718  Validation loss = 2.6738  \n",
      "\n",
      "Fold: 11  Epoch: 27  Training loss = 3.5713  Validation loss = 2.6728  \n",
      "\n",
      "Fold: 11  Epoch: 28  Training loss = 3.5708  Validation loss = 2.6718  \n",
      "\n",
      "Fold: 11  Epoch: 29  Training loss = 3.5705  Validation loss = 2.6711  \n",
      "\n",
      "Fold: 11  Epoch: 30  Training loss = 3.5700  Validation loss = 2.6702  \n",
      "\n",
      "Fold: 11  Epoch: 31  Training loss = 3.5696  Validation loss = 2.6694  \n",
      "\n",
      "Fold: 11  Epoch: 32  Training loss = 3.5691  Validation loss = 2.6684  \n",
      "\n",
      "Fold: 11  Epoch: 33  Training loss = 3.5686  Validation loss = 2.6674  \n",
      "\n",
      "Fold: 11  Epoch: 34  Training loss = 3.5682  Validation loss = 2.6666  \n",
      "\n",
      "Fold: 11  Epoch: 35  Training loss = 3.5677  Validation loss = 2.6656  \n",
      "\n",
      "Fold: 11  Epoch: 36  Training loss = 3.5672  Validation loss = 2.6646  \n",
      "\n",
      "Fold: 11  Epoch: 37  Training loss = 3.5669  Validation loss = 2.6639  \n",
      "\n",
      "Fold: 11  Epoch: 38  Training loss = 3.5664  Validation loss = 2.6631  \n",
      "\n",
      "Fold: 11  Epoch: 39  Training loss = 3.5659  Validation loss = 2.6621  \n",
      "\n",
      "Fold: 11  Epoch: 40  Training loss = 3.5656  Validation loss = 2.6613  \n",
      "\n",
      "Fold: 11  Epoch: 41  Training loss = 3.5651  Validation loss = 2.6603  \n",
      "\n",
      "Fold: 11  Epoch: 42  Training loss = 3.5647  Validation loss = 2.6596  \n",
      "\n",
      "Fold: 11  Epoch: 43  Training loss = 3.5641  Validation loss = 2.6584  \n",
      "\n",
      "Fold: 11  Epoch: 44  Training loss = 3.5637  Validation loss = 2.6576  \n",
      "\n",
      "Fold: 11  Epoch: 45  Training loss = 3.5634  Validation loss = 2.6570  \n",
      "\n",
      "Fold: 11  Epoch: 46  Training loss = 3.5630  Validation loss = 2.6561  \n",
      "\n",
      "Fold: 11  Epoch: 47  Training loss = 3.5624  Validation loss = 2.6549  \n",
      "\n",
      "Fold: 11  Epoch: 48  Training loss = 3.5620  Validation loss = 2.6540  \n",
      "\n",
      "Fold: 11  Epoch: 49  Training loss = 3.5614  Validation loss = 2.6529  \n",
      "\n",
      "Fold: 11  Epoch: 50  Training loss = 3.5610  Validation loss = 2.6520  \n",
      "\n",
      "Fold: 11  Epoch: 51  Training loss = 3.5605  Validation loss = 2.6511  \n",
      "\n",
      "Fold: 11  Epoch: 52  Training loss = 3.5599  Validation loss = 2.6499  \n",
      "\n",
      "Fold: 11  Epoch: 53  Training loss = 3.5595  Validation loss = 2.6490  \n",
      "\n",
      "Fold: 11  Epoch: 54  Training loss = 3.5590  Validation loss = 2.6481  \n",
      "\n",
      "Fold: 11  Epoch: 55  Training loss = 3.5585  Validation loss = 2.6471  \n",
      "\n",
      "Fold: 11  Epoch: 56  Training loss = 3.5579  Validation loss = 2.6459  \n",
      "\n",
      "Fold: 11  Epoch: 57  Training loss = 3.5574  Validation loss = 2.6448  \n",
      "\n",
      "Fold: 11  Epoch: 58  Training loss = 3.5569  Validation loss = 2.6439  \n",
      "\n",
      "Fold: 11  Epoch: 59  Training loss = 3.5566  Validation loss = 2.6431  \n",
      "\n",
      "Fold: 11  Epoch: 60  Training loss = 3.5559  Validation loss = 2.6419  \n",
      "\n",
      "Fold: 11  Epoch: 61  Training loss = 3.5554  Validation loss = 2.6406  \n",
      "\n",
      "Fold: 11  Epoch: 62  Training loss = 3.5549  Validation loss = 2.6396  \n",
      "\n",
      "Fold: 11  Epoch: 63  Training loss = 3.5543  Validation loss = 2.6385  \n",
      "\n",
      "Fold: 11  Epoch: 64  Training loss = 3.5539  Validation loss = 2.6376  \n",
      "\n",
      "Fold: 11  Epoch: 65  Training loss = 3.5535  Validation loss = 2.6368  \n",
      "\n",
      "Fold: 11  Epoch: 66  Training loss = 3.5530  Validation loss = 2.6357  \n",
      "\n",
      "Fold: 11  Epoch: 67  Training loss = 3.5525  Validation loss = 2.6349  \n",
      "\n",
      "Fold: 11  Epoch: 68  Training loss = 3.5521  Validation loss = 2.6340  \n",
      "\n",
      "Fold: 11  Epoch: 69  Training loss = 3.5519  Validation loss = 2.6335  \n",
      "\n",
      "Fold: 11  Epoch: 70  Training loss = 3.5513  Validation loss = 2.6324  \n",
      "\n",
      "Fold: 11  Epoch: 71  Training loss = 3.5509  Validation loss = 2.6315  \n",
      "\n",
      "Fold: 11  Epoch: 72  Training loss = 3.5504  Validation loss = 2.6306  \n",
      "\n",
      "Fold: 11  Epoch: 73  Training loss = 3.5500  Validation loss = 2.6298  \n",
      "\n",
      "Fold: 11  Epoch: 74  Training loss = 3.5494  Validation loss = 2.6286  \n",
      "\n",
      "Fold: 11  Epoch: 75  Training loss = 3.5490  Validation loss = 2.6276  \n",
      "\n",
      "Fold: 11  Epoch: 76  Training loss = 3.5486  Validation loss = 2.6267  \n",
      "\n",
      "Fold: 11  Epoch: 77  Training loss = 3.5481  Validation loss = 2.6257  \n",
      "\n",
      "Fold: 11  Epoch: 78  Training loss = 3.5475  Validation loss = 2.6245  \n",
      "\n",
      "Fold: 11  Epoch: 79  Training loss = 3.5471  Validation loss = 2.6236  \n",
      "\n",
      "Fold: 11  Epoch: 80  Training loss = 3.5466  Validation loss = 2.6228  \n",
      "\n",
      "Fold: 11  Epoch: 81  Training loss = 3.5462  Validation loss = 2.6218  \n",
      "\n",
      "Fold: 11  Epoch: 82  Training loss = 3.5458  Validation loss = 2.6211  \n",
      "\n",
      "Fold: 11  Epoch: 83  Training loss = 3.5453  Validation loss = 2.6200  \n",
      "\n",
      "Fold: 11  Epoch: 84  Training loss = 3.5449  Validation loss = 2.6191  \n",
      "\n",
      "Fold: 11  Epoch: 85  Training loss = 3.5443  Validation loss = 2.6180  \n",
      "\n",
      "Fold: 11  Epoch: 86  Training loss = 3.5439  Validation loss = 2.6170  \n",
      "\n",
      "Fold: 11  Epoch: 87  Training loss = 3.5434  Validation loss = 2.6161  \n",
      "\n",
      "Fold: 11  Epoch: 88  Training loss = 3.5428  Validation loss = 2.6147  \n",
      "\n",
      "Fold: 11  Epoch: 89  Training loss = 3.5422  Validation loss = 2.6136  \n",
      "\n",
      "Fold: 11  Epoch: 90  Training loss = 3.5419  Validation loss = 2.6129  \n",
      "\n",
      "Fold: 11  Epoch: 91  Training loss = 3.5415  Validation loss = 2.6120  \n",
      "\n",
      "Fold: 11  Epoch: 92  Training loss = 3.5410  Validation loss = 2.6110  \n",
      "\n",
      "Fold: 11  Epoch: 93  Training loss = 3.5406  Validation loss = 2.6102  \n",
      "\n",
      "Fold: 11  Epoch: 94  Training loss = 3.5401  Validation loss = 2.6092  \n",
      "\n",
      "Fold: 11  Epoch: 95  Training loss = 3.5396  Validation loss = 2.6081  \n",
      "\n",
      "Fold: 11  Epoch: 96  Training loss = 3.5391  Validation loss = 2.6073  \n",
      "\n",
      "Fold: 11  Epoch: 97  Training loss = 3.5388  Validation loss = 2.6066  \n",
      "\n",
      "Fold: 11  Epoch: 98  Training loss = 3.5384  Validation loss = 2.6057  \n",
      "\n",
      "Fold: 11  Epoch: 99  Training loss = 3.5380  Validation loss = 2.6048  \n",
      "\n",
      "Fold: 11  Epoch: 100  Training loss = 3.5375  Validation loss = 2.6039  \n",
      "\n",
      "Fold: 11  Epoch: 101  Training loss = 3.5371  Validation loss = 2.6030  \n",
      "\n",
      "Fold: 11  Epoch: 102  Training loss = 3.5367  Validation loss = 2.6021  \n",
      "\n",
      "Fold: 11  Epoch: 103  Training loss = 3.5361  Validation loss = 2.6010  \n",
      "\n",
      "Fold: 11  Epoch: 104  Training loss = 3.5357  Validation loss = 2.6001  \n",
      "\n",
      "Fold: 11  Epoch: 105  Training loss = 3.5354  Validation loss = 2.5993  \n",
      "\n",
      "Fold: 11  Epoch: 106  Training loss = 3.5348  Validation loss = 2.5983  \n",
      "\n",
      "Fold: 11  Epoch: 107  Training loss = 3.5344  Validation loss = 2.5972  \n",
      "\n",
      "Fold: 11  Epoch: 108  Training loss = 3.5337  Validation loss = 2.5959  \n",
      "\n",
      "Fold: 11  Epoch: 109  Training loss = 3.5333  Validation loss = 2.5950  \n",
      "\n",
      "Fold: 11  Epoch: 110  Training loss = 3.5328  Validation loss = 2.5940  \n",
      "\n",
      "Fold: 11  Epoch: 111  Training loss = 3.5324  Validation loss = 2.5931  \n",
      "\n",
      "Fold: 11  Epoch: 112  Training loss = 3.5320  Validation loss = 2.5923  \n",
      "\n",
      "Fold: 11  Epoch: 113  Training loss = 3.5316  Validation loss = 2.5915  \n",
      "\n",
      "Fold: 11  Epoch: 114  Training loss = 3.5313  Validation loss = 2.5908  \n",
      "\n",
      "Fold: 11  Epoch: 115  Training loss = 3.5310  Validation loss = 2.5900  \n",
      "\n",
      "Fold: 11  Epoch: 116  Training loss = 3.5306  Validation loss = 2.5893  \n",
      "\n",
      "Fold: 11  Epoch: 117  Training loss = 3.5303  Validation loss = 2.5887  \n",
      "\n",
      "Fold: 11  Epoch: 118  Training loss = 3.5299  Validation loss = 2.5878  \n",
      "\n",
      "Fold: 11  Epoch: 119  Training loss = 3.5294  Validation loss = 2.5868  \n",
      "\n",
      "Fold: 11  Epoch: 120  Training loss = 3.5288  Validation loss = 2.5856  \n",
      "\n",
      "Fold: 11  Epoch: 121  Training loss = 3.5284  Validation loss = 2.5847  \n",
      "\n",
      "Fold: 11  Epoch: 122  Training loss = 3.5280  Validation loss = 2.5839  \n",
      "\n",
      "Fold: 11  Epoch: 123  Training loss = 3.5276  Validation loss = 2.5831  \n",
      "\n",
      "Fold: 11  Epoch: 124  Training loss = 3.5271  Validation loss = 2.5819  \n",
      "\n",
      "Fold: 11  Epoch: 125  Training loss = 3.5266  Validation loss = 2.5809  \n",
      "\n",
      "Fold: 11  Epoch: 126  Training loss = 3.5261  Validation loss = 2.5799  \n",
      "\n",
      "Fold: 11  Epoch: 127  Training loss = 3.5257  Validation loss = 2.5790  \n",
      "\n",
      "Fold: 11  Epoch: 128  Training loss = 3.5254  Validation loss = 2.5784  \n",
      "\n",
      "Fold: 11  Epoch: 129  Training loss = 3.5249  Validation loss = 2.5774  \n",
      "\n",
      "Fold: 11  Epoch: 130  Training loss = 3.5246  Validation loss = 2.5766  \n",
      "\n",
      "Fold: 11  Epoch: 131  Training loss = 3.5242  Validation loss = 2.5758  \n",
      "\n",
      "Fold: 11  Epoch: 132  Training loss = 3.5239  Validation loss = 2.5751  \n",
      "\n",
      "Fold: 11  Epoch: 133  Training loss = 3.5235  Validation loss = 2.5744  \n",
      "\n",
      "Fold: 11  Epoch: 134  Training loss = 3.5230  Validation loss = 2.5734  \n",
      "\n",
      "Fold: 11  Epoch: 135  Training loss = 3.5225  Validation loss = 2.5722  \n",
      "\n",
      "Fold: 11  Epoch: 136  Training loss = 3.5219  Validation loss = 2.5709  \n",
      "\n",
      "Fold: 11  Epoch: 137  Training loss = 3.5214  Validation loss = 2.5699  \n",
      "\n",
      "Fold: 11  Epoch: 138  Training loss = 3.5208  Validation loss = 2.5688  \n",
      "\n",
      "Fold: 11  Epoch: 139  Training loss = 3.5204  Validation loss = 2.5679  \n",
      "\n",
      "Fold: 11  Epoch: 140  Training loss = 3.5201  Validation loss = 2.5671  \n",
      "\n",
      "Fold: 11  Epoch: 141  Training loss = 3.5197  Validation loss = 2.5663  \n",
      "\n",
      "Fold: 11  Epoch: 142  Training loss = 3.5193  Validation loss = 2.5656  \n",
      "\n",
      "Fold: 11  Epoch: 143  Training loss = 3.5189  Validation loss = 2.5648  \n",
      "\n",
      "Fold: 11  Epoch: 144  Training loss = 3.5183  Validation loss = 2.5635  \n",
      "\n",
      "Fold: 11  Epoch: 145  Training loss = 3.5179  Validation loss = 2.5626  \n",
      "\n",
      "Fold: 11  Epoch: 146  Training loss = 3.5173  Validation loss = 2.5613  \n",
      "\n",
      "Fold: 11  Epoch: 147  Training loss = 3.5168  Validation loss = 2.5603  \n",
      "\n",
      "Fold: 11  Epoch: 148  Training loss = 3.5164  Validation loss = 2.5593  \n",
      "\n",
      "Fold: 11  Epoch: 149  Training loss = 3.5161  Validation loss = 2.5586  \n",
      "\n",
      "Fold: 11  Epoch: 150  Training loss = 3.5156  Validation loss = 2.5576  \n",
      "\n",
      "Fold: 11  Epoch: 151  Training loss = 3.5153  Validation loss = 2.5568  \n",
      "\n",
      "Fold: 11  Epoch: 152  Training loss = 3.5148  Validation loss = 2.5559  \n",
      "\n",
      "Fold: 11  Epoch: 153  Training loss = 3.5143  Validation loss = 2.5548  \n",
      "\n",
      "Fold: 11  Epoch: 154  Training loss = 3.5139  Validation loss = 2.5538  \n",
      "\n",
      "Fold: 11  Epoch: 155  Training loss = 3.5134  Validation loss = 2.5528  \n",
      "\n",
      "Fold: 11  Epoch: 156  Training loss = 3.5129  Validation loss = 2.5518  \n",
      "\n",
      "Fold: 11  Epoch: 157  Training loss = 3.5126  Validation loss = 2.5512  \n",
      "\n",
      "Fold: 11  Epoch: 158  Training loss = 3.5121  Validation loss = 2.5500  \n",
      "\n",
      "Fold: 11  Epoch: 159  Training loss = 3.5116  Validation loss = 2.5490  \n",
      "\n",
      "Fold: 11  Epoch: 160  Training loss = 3.5112  Validation loss = 2.5481  \n",
      "\n",
      "Fold: 11  Epoch: 161  Training loss = 3.5106  Validation loss = 2.5470  \n",
      "\n",
      "Fold: 11  Epoch: 162  Training loss = 3.5102  Validation loss = 2.5461  \n",
      "\n",
      "Fold: 11  Epoch: 163  Training loss = 3.5097  Validation loss = 2.5451  \n",
      "\n",
      "Fold: 11  Epoch: 164  Training loss = 3.5093  Validation loss = 2.5441  \n",
      "\n",
      "Fold: 11  Epoch: 165  Training loss = 3.5089  Validation loss = 2.5434  \n",
      "\n",
      "Fold: 11  Epoch: 166  Training loss = 3.5085  Validation loss = 2.5425  \n",
      "\n",
      "Fold: 11  Epoch: 167  Training loss = 3.5080  Validation loss = 2.5414  \n",
      "\n",
      "Fold: 11  Epoch: 168  Training loss = 3.5075  Validation loss = 2.5404  \n",
      "\n",
      "Fold: 11  Epoch: 169  Training loss = 3.5071  Validation loss = 2.5396  \n",
      "\n",
      "Fold: 11  Epoch: 170  Training loss = 3.5060  Validation loss = 2.5386  \n",
      "\n",
      "Fold: 11  Epoch: 171  Training loss = 3.5006  Validation loss = 2.5377  \n",
      "\n",
      "Fold: 11  Epoch: 172  Training loss = 3.5002  Validation loss = 2.5368  \n",
      "\n",
      "Fold: 11  Epoch: 173  Training loss = 3.4997  Validation loss = 2.5358  \n",
      "\n",
      "Fold: 11  Epoch: 174  Training loss = 3.4991  Validation loss = 2.5347  \n",
      "\n",
      "Fold: 11  Epoch: 175  Training loss = 3.4987  Validation loss = 2.5336  \n",
      "\n",
      "Fold: 11  Epoch: 176  Training loss = 3.4981  Validation loss = 2.5324  \n",
      "\n",
      "Fold: 11  Epoch: 177  Training loss = 3.4976  Validation loss = 2.5313  \n",
      "\n",
      "Fold: 11  Epoch: 178  Training loss = 3.4971  Validation loss = 2.5303  \n",
      "\n",
      "Fold: 11  Epoch: 179  Training loss = 3.4967  Validation loss = 2.5292  \n",
      "\n",
      "Fold: 11  Epoch: 180  Training loss = 3.4963  Validation loss = 2.5284  \n",
      "\n",
      "Fold: 11  Epoch: 181  Training loss = 3.4959  Validation loss = 2.5276  \n",
      "\n",
      "Fold: 11  Epoch: 182  Training loss = 3.4954  Validation loss = 2.5266  \n",
      "\n",
      "Fold: 11  Epoch: 183  Training loss = 3.4950  Validation loss = 2.5255  \n",
      "\n",
      "Fold: 11  Epoch: 184  Training loss = 3.4946  Validation loss = 2.5247  \n",
      "\n",
      "Fold: 11  Epoch: 185  Training loss = 3.4942  Validation loss = 2.5238  \n",
      "\n",
      "Fold: 11  Epoch: 186  Training loss = 3.4937  Validation loss = 2.5226  \n",
      "\n",
      "Fold: 11  Epoch: 187  Training loss = 3.4932  Validation loss = 2.5215  \n",
      "\n",
      "Fold: 11  Epoch: 188  Training loss = 3.4927  Validation loss = 2.5205  \n",
      "\n",
      "Fold: 11  Epoch: 189  Training loss = 3.4925  Validation loss = 2.5200  \n",
      "\n",
      "Fold: 11  Epoch: 190  Training loss = 3.4922  Validation loss = 2.5194  \n",
      "\n",
      "Fold: 11  Epoch: 191  Training loss = 3.4917  Validation loss = 2.5183  \n",
      "\n",
      "Fold: 11  Epoch: 192  Training loss = 3.4913  Validation loss = 2.5173  \n",
      "\n",
      "Fold: 11  Epoch: 193  Training loss = 3.4910  Validation loss = 2.5166  \n",
      "\n",
      "Fold: 11  Epoch: 194  Training loss = 3.4907  Validation loss = 2.5160  \n",
      "\n",
      "Fold: 11  Epoch: 195  Training loss = 3.4901  Validation loss = 2.5147  \n",
      "\n",
      "Fold: 11  Epoch: 196  Training loss = 3.4897  Validation loss = 2.5139  \n",
      "\n",
      "Fold: 11  Epoch: 197  Training loss = 3.4894  Validation loss = 2.5132  \n",
      "\n",
      "Fold: 11  Epoch: 198  Training loss = 3.4890  Validation loss = 2.5122  \n",
      "\n",
      "Fold: 11  Epoch: 199  Training loss = 3.4887  Validation loss = 2.5117  \n",
      "\n",
      "Fold: 11  Epoch: 200  Training loss = 3.4883  Validation loss = 2.5108  \n",
      "\n",
      "Fold: 11  Epoch: 201  Training loss = 3.4879  Validation loss = 2.5099  \n",
      "\n",
      "Fold: 11  Epoch: 202  Training loss = 3.4875  Validation loss = 2.5090  \n",
      "\n",
      "Fold: 11  Epoch: 203  Training loss = 3.4870  Validation loss = 2.5078  \n",
      "\n",
      "Fold: 11  Epoch: 204  Training loss = 3.4866  Validation loss = 2.5069  \n",
      "\n",
      "Fold: 11  Epoch: 205  Training loss = 3.4863  Validation loss = 2.5062  \n",
      "\n",
      "Fold: 11  Epoch: 206  Training loss = 3.4859  Validation loss = 2.5053  \n",
      "\n",
      "Fold: 11  Epoch: 207  Training loss = 3.4856  Validation loss = 2.5046  \n",
      "\n",
      "Fold: 11  Epoch: 208  Training loss = 3.4851  Validation loss = 2.5037  \n",
      "\n",
      "Fold: 11  Epoch: 209  Training loss = 3.4847  Validation loss = 2.5028  \n",
      "\n",
      "Fold: 11  Epoch: 210  Training loss = 3.4842  Validation loss = 2.5016  \n",
      "\n",
      "Fold: 11  Epoch: 211  Training loss = 3.4837  Validation loss = 2.5005  \n",
      "\n",
      "Fold: 11  Epoch: 212  Training loss = 3.4832  Validation loss = 2.4994  \n",
      "\n",
      "Fold: 11  Epoch: 213  Training loss = 3.4828  Validation loss = 2.4985  \n",
      "\n",
      "Fold: 11  Epoch: 214  Training loss = 3.4826  Validation loss = 2.4979  \n",
      "\n",
      "Fold: 11  Epoch: 215  Training loss = 3.4822  Validation loss = 2.4971  \n",
      "\n",
      "Fold: 11  Epoch: 216  Training loss = 3.4819  Validation loss = 2.4964  \n",
      "\n",
      "Fold: 11  Epoch: 217  Training loss = 3.4816  Validation loss = 2.4957  \n",
      "\n",
      "Fold: 11  Epoch: 218  Training loss = 3.4811  Validation loss = 2.4947  \n",
      "\n",
      "Fold: 11  Epoch: 219  Training loss = 3.4807  Validation loss = 2.4939  \n",
      "\n",
      "Fold: 11  Epoch: 220  Training loss = 3.4803  Validation loss = 2.4928  \n",
      "\n",
      "Fold: 11  Epoch: 221  Training loss = 3.4798  Validation loss = 2.4917  \n",
      "\n",
      "Fold: 11  Epoch: 222  Training loss = 3.4793  Validation loss = 2.4906  \n",
      "\n",
      "Fold: 11  Epoch: 223  Training loss = 3.4788  Validation loss = 2.4894  \n",
      "\n",
      "Fold: 11  Epoch: 224  Training loss = 3.4784  Validation loss = 2.4885  \n",
      "\n",
      "Fold: 11  Epoch: 225  Training loss = 3.4780  Validation loss = 2.4876  \n",
      "\n",
      "Fold: 11  Epoch: 226  Training loss = 3.4774  Validation loss = 2.4863  \n",
      "\n",
      "Fold: 11  Epoch: 227  Training loss = 3.4767  Validation loss = 2.4849  \n",
      "\n",
      "Fold: 11  Epoch: 228  Training loss = 3.4765  Validation loss = 2.4842  \n",
      "\n",
      "Fold: 11  Epoch: 229  Training loss = 3.4760  Validation loss = 2.4832  \n",
      "\n",
      "Fold: 11  Epoch: 230  Training loss = 3.4757  Validation loss = 2.4825  \n",
      "\n",
      "Fold: 11  Epoch: 231  Training loss = 3.4753  Validation loss = 2.4816  \n",
      "\n",
      "Fold: 11  Epoch: 232  Training loss = 3.4749  Validation loss = 2.4806  \n",
      "\n",
      "Fold: 11  Epoch: 233  Training loss = 3.4745  Validation loss = 2.4798  \n",
      "\n",
      "Fold: 11  Epoch: 234  Training loss = 3.4741  Validation loss = 2.4789  \n",
      "\n",
      "Fold: 11  Epoch: 235  Training loss = 3.4736  Validation loss = 2.4778  \n",
      "\n",
      "Fold: 11  Epoch: 236  Training loss = 3.4732  Validation loss = 2.4767  \n",
      "\n",
      "Fold: 11  Epoch: 237  Training loss = 3.4729  Validation loss = 2.4761  \n",
      "\n",
      "Fold: 11  Epoch: 238  Training loss = 3.4724  Validation loss = 2.4751  \n",
      "\n",
      "Fold: 11  Epoch: 239  Training loss = 3.4720  Validation loss = 2.4742  \n",
      "\n",
      "Fold: 11  Epoch: 240  Training loss = 3.4716  Validation loss = 2.4733  \n",
      "\n",
      "Fold: 11  Epoch: 241  Training loss = 3.4713  Validation loss = 2.4725  \n",
      "\n",
      "Fold: 11  Epoch: 242  Training loss = 3.4709  Validation loss = 2.4715  \n",
      "\n",
      "Fold: 11  Epoch: 243  Training loss = 3.4704  Validation loss = 2.4704  \n",
      "\n",
      "Fold: 11  Epoch: 244  Training loss = 3.4702  Validation loss = 2.4699  \n",
      "\n",
      "Fold: 11  Epoch: 245  Training loss = 3.4699  Validation loss = 2.4693  \n",
      "\n",
      "Fold: 11  Epoch: 246  Training loss = 3.4695  Validation loss = 2.4683  \n",
      "\n",
      "Fold: 11  Epoch: 247  Training loss = 3.4692  Validation loss = 2.4676  \n",
      "\n",
      "Fold: 11  Epoch: 248  Training loss = 3.4689  Validation loss = 2.4669  \n",
      "\n",
      "Fold: 11  Epoch: 249  Training loss = 3.4686  Validation loss = 2.4662  \n",
      "\n",
      "Fold: 11  Epoch: 250  Training loss = 3.4681  Validation loss = 2.4651  \n",
      "\n",
      "Fold: 11  Epoch: 251  Training loss = 3.4676  Validation loss = 2.4640  \n",
      "\n",
      "Fold: 11  Epoch: 252  Training loss = 3.4673  Validation loss = 2.4632  \n",
      "\n",
      "Fold: 11  Epoch: 253  Training loss = 3.4668  Validation loss = 2.4621  \n",
      "\n",
      "Fold: 11  Epoch: 254  Training loss = 3.4664  Validation loss = 2.4612  \n",
      "\n",
      "Fold: 11  Epoch: 255  Training loss = 3.4657  Validation loss = 2.4597  \n",
      "\n",
      "Fold: 11  Epoch: 256  Training loss = 3.4652  Validation loss = 2.4586  \n",
      "\n",
      "Fold: 11  Epoch: 257  Training loss = 3.4649  Validation loss = 2.4578  \n",
      "\n",
      "Fold: 11  Epoch: 258  Training loss = 3.4644  Validation loss = 2.4567  \n",
      "\n",
      "Fold: 11  Epoch: 259  Training loss = 3.4640  Validation loss = 2.4559  \n",
      "\n",
      "Fold: 11  Epoch: 260  Training loss = 3.4637  Validation loss = 2.4551  \n",
      "\n",
      "Fold: 11  Epoch: 261  Training loss = 3.4633  Validation loss = 2.4543  \n",
      "\n",
      "Fold: 11  Epoch: 262  Training loss = 3.4629  Validation loss = 2.4533  \n",
      "\n",
      "Fold: 11  Epoch: 263  Training loss = 3.4625  Validation loss = 2.4524  \n",
      "\n",
      "Fold: 11  Epoch: 264  Training loss = 3.4622  Validation loss = 2.4516  \n",
      "\n",
      "Fold: 11  Epoch: 265  Training loss = 3.4618  Validation loss = 2.4507  \n",
      "\n",
      "Fold: 11  Epoch: 266  Training loss = 3.4615  Validation loss = 2.4500  \n",
      "\n",
      "Fold: 11  Epoch: 267  Training loss = 3.4612  Validation loss = 2.4492  \n",
      "\n",
      "Fold: 11  Epoch: 268  Training loss = 3.4606  Validation loss = 2.4480  \n",
      "\n",
      "Fold: 11  Epoch: 269  Training loss = 3.4603  Validation loss = 2.4471  \n",
      "\n",
      "Fold: 11  Epoch: 270  Training loss = 3.4600  Validation loss = 2.4465  \n",
      "\n",
      "Fold: 11  Epoch: 271  Training loss = 3.4594  Validation loss = 2.4452  \n",
      "\n",
      "Fold: 11  Epoch: 272  Training loss = 3.4593  Validation loss = 2.4448  \n",
      "\n",
      "Fold: 11  Epoch: 273  Training loss = 3.4590  Validation loss = 2.4441  \n",
      "\n",
      "Fold: 11  Epoch: 274  Training loss = 3.4584  Validation loss = 2.4427  \n",
      "\n",
      "Fold: 11  Epoch: 275  Training loss = 3.4579  Validation loss = 2.4417  \n",
      "\n",
      "Fold: 11  Epoch: 276  Training loss = 3.4575  Validation loss = 2.4407  \n",
      "\n",
      "Fold: 11  Epoch: 277  Training loss = 3.4571  Validation loss = 2.4398  \n",
      "\n",
      "Fold: 11  Epoch: 278  Training loss = 3.4567  Validation loss = 2.4389  \n",
      "\n",
      "Fold: 11  Epoch: 279  Training loss = 3.4564  Validation loss = 2.4381  \n",
      "\n",
      "Fold: 11  Epoch: 280  Training loss = 3.4560  Validation loss = 2.4372  \n",
      "\n",
      "Fold: 11  Epoch: 281  Training loss = 3.4557  Validation loss = 2.4364  \n",
      "\n",
      "Fold: 11  Epoch: 282  Training loss = 3.4553  Validation loss = 2.4356  \n",
      "\n",
      "Fold: 11  Epoch: 283  Training loss = 3.4549  Validation loss = 2.4346  \n",
      "\n",
      "Fold: 11  Epoch: 284  Training loss = 3.4545  Validation loss = 2.4337  \n",
      "\n",
      "Fold: 11  Epoch: 285  Training loss = 3.4540  Validation loss = 2.4326  \n",
      "\n",
      "Fold: 11  Epoch: 286  Training loss = 3.4536  Validation loss = 2.4317  \n",
      "\n",
      "Fold: 11  Epoch: 287  Training loss = 3.4531  Validation loss = 2.4305  \n",
      "\n",
      "Fold: 11  Epoch: 288  Training loss = 3.4527  Validation loss = 2.4294  \n",
      "\n",
      "Fold: 11  Epoch: 289  Training loss = 3.4524  Validation loss = 2.4288  \n",
      "\n",
      "Fold: 11  Epoch: 290  Training loss = 3.4521  Validation loss = 2.4280  \n",
      "\n",
      "Fold: 11  Epoch: 291  Training loss = 3.4516  Validation loss = 2.4269  \n",
      "\n",
      "Fold: 11  Epoch: 292  Training loss = 3.4512  Validation loss = 2.4259  \n",
      "\n",
      "Fold: 11  Epoch: 293  Training loss = 3.4509  Validation loss = 2.4253  \n",
      "\n",
      "Fold: 11  Epoch: 294  Training loss = 3.4506  Validation loss = 2.4245  \n",
      "\n",
      "Fold: 11  Epoch: 295  Training loss = 3.4501  Validation loss = 2.4236  \n",
      "\n",
      "Fold: 11  Epoch: 296  Training loss = 3.4498  Validation loss = 2.4228  \n",
      "\n",
      "Fold: 11  Epoch: 297  Training loss = 3.4496  Validation loss = 2.4222  \n",
      "\n",
      "Fold: 11  Epoch: 298  Training loss = 3.4492  Validation loss = 2.4215  \n",
      "\n",
      "Fold: 11  Epoch: 299  Training loss = 3.4489  Validation loss = 2.4206  \n",
      "\n",
      "Fold: 11  Epoch: 300  Training loss = 3.4484  Validation loss = 2.4196  \n",
      "\n",
      "Fold: 11  Epoch: 301  Training loss = 3.4480  Validation loss = 2.4185  \n",
      "\n",
      "Fold: 11  Epoch: 302  Training loss = 3.4476  Validation loss = 2.4176  \n",
      "\n",
      "Fold: 11  Epoch: 303  Training loss = 3.4472  Validation loss = 2.4168  \n",
      "\n",
      "Fold: 11  Epoch: 304  Training loss = 3.4468  Validation loss = 2.4158  \n",
      "\n",
      "Fold: 11  Epoch: 305  Training loss = 3.4463  Validation loss = 2.4147  \n",
      "\n",
      "Fold: 11  Epoch: 306  Training loss = 3.4459  Validation loss = 2.4138  \n",
      "\n",
      "Fold: 11  Epoch: 307  Training loss = 3.4456  Validation loss = 2.4131  \n",
      "\n",
      "Fold: 11  Epoch: 308  Training loss = 3.4452  Validation loss = 2.4122  \n",
      "\n",
      "Fold: 11  Epoch: 309  Training loss = 3.4449  Validation loss = 2.4114  \n",
      "\n",
      "Fold: 11  Epoch: 310  Training loss = 3.4445  Validation loss = 2.4104  \n",
      "\n",
      "Fold: 11  Epoch: 311  Training loss = 3.4440  Validation loss = 2.4093  \n",
      "\n",
      "Fold: 11  Epoch: 312  Training loss = 3.4436  Validation loss = 2.4084  \n",
      "\n",
      "Fold: 11  Epoch: 313  Training loss = 3.4434  Validation loss = 2.4079  \n",
      "\n",
      "Fold: 11  Epoch: 314  Training loss = 3.4430  Validation loss = 2.4070  \n",
      "\n",
      "Fold: 11  Epoch: 315  Training loss = 3.4427  Validation loss = 2.4063  \n",
      "\n",
      "Fold: 11  Epoch: 316  Training loss = 3.4424  Validation loss = 2.4056  \n",
      "\n",
      "Fold: 11  Epoch: 317  Training loss = 3.4419  Validation loss = 2.4045  \n",
      "\n",
      "Fold: 11  Epoch: 318  Training loss = 3.4414  Validation loss = 2.4032  \n",
      "\n",
      "Fold: 11  Epoch: 319  Training loss = 3.4411  Validation loss = 2.4025  \n",
      "\n",
      "Fold: 11  Epoch: 320  Training loss = 3.4406  Validation loss = 2.4014  \n",
      "\n",
      "Fold: 11  Epoch: 321  Training loss = 3.4401  Validation loss = 2.4005  \n",
      "\n",
      "Fold: 11  Epoch: 322  Training loss = 3.4396  Validation loss = 2.3994  \n",
      "\n",
      "Fold: 11  Epoch: 323  Training loss = 3.4387  Validation loss = 2.3984  \n",
      "\n",
      "Fold: 11  Epoch: 324  Training loss = 3.4383  Validation loss = 2.3974  \n",
      "\n",
      "Fold: 11  Epoch: 325  Training loss = 3.4377  Validation loss = 2.3966  \n",
      "\n",
      "Fold: 11  Epoch: 326  Training loss = 3.4370  Validation loss = 2.3957  \n",
      "\n",
      "Fold: 11  Epoch: 327  Training loss = 3.4361  Validation loss = 2.3946  \n",
      "\n",
      "Fold: 11  Epoch: 328  Training loss = 3.4357  Validation loss = 2.3938  \n",
      "\n",
      "Fold: 11  Epoch: 329  Training loss = 3.4352  Validation loss = 2.3928  \n",
      "\n",
      "Fold: 11  Epoch: 330  Training loss = 3.4348  Validation loss = 2.3920  \n",
      "\n",
      "Fold: 11  Epoch: 331  Training loss = 3.4344  Validation loss = 2.3912  \n",
      "\n",
      "Fold: 11  Epoch: 332  Training loss = 3.4339  Validation loss = 2.3900  \n",
      "\n",
      "Fold: 11  Epoch: 333  Training loss = 3.4336  Validation loss = 2.3893  \n",
      "\n",
      "Fold: 11  Epoch: 334  Training loss = 3.4331  Validation loss = 2.3883  \n",
      "\n",
      "Fold: 11  Epoch: 335  Training loss = 3.4326  Validation loss = 2.3871  \n",
      "\n",
      "Fold: 11  Epoch: 336  Training loss = 3.4323  Validation loss = 2.3864  \n",
      "\n",
      "Fold: 11  Epoch: 337  Training loss = 3.4319  Validation loss = 2.3854  \n",
      "\n",
      "Fold: 11  Epoch: 338  Training loss = 3.4316  Validation loss = 2.3847  \n",
      "\n",
      "Fold: 11  Epoch: 339  Training loss = 3.4312  Validation loss = 2.3838  \n",
      "\n",
      "Fold: 11  Epoch: 340  Training loss = 3.4308  Validation loss = 2.3830  \n",
      "\n",
      "Fold: 11  Epoch: 341  Training loss = 3.4305  Validation loss = 2.3822  \n",
      "\n",
      "Fold: 11  Epoch: 342  Training loss = 3.4301  Validation loss = 2.3812  \n",
      "\n",
      "Fold: 11  Epoch: 343  Training loss = 3.4298  Validation loss = 2.3805  \n",
      "\n",
      "Fold: 11  Epoch: 344  Training loss = 3.4294  Validation loss = 2.3797  \n",
      "\n",
      "Fold: 11  Epoch: 345  Training loss = 3.4291  Validation loss = 2.3788  \n",
      "\n",
      "Fold: 11  Epoch: 346  Training loss = 3.4288  Validation loss = 2.3781  \n",
      "\n",
      "Fold: 11  Epoch: 347  Training loss = 3.4284  Validation loss = 2.3772  \n",
      "\n",
      "Fold: 11  Epoch: 348  Training loss = 3.4280  Validation loss = 2.3762  \n",
      "\n",
      "Fold: 11  Epoch: 349  Training loss = 3.4276  Validation loss = 2.3754  \n",
      "\n",
      "Fold: 11  Epoch: 350  Training loss = 3.4271  Validation loss = 2.3741  \n",
      "\n",
      "Fold: 11  Epoch: 351  Training loss = 3.4268  Validation loss = 2.3735  \n",
      "\n",
      "Fold: 11  Epoch: 352  Training loss = 3.4265  Validation loss = 2.3727  \n",
      "\n",
      "Fold: 11  Epoch: 353  Training loss = 3.4261  Validation loss = 2.3719  \n",
      "\n",
      "Fold: 11  Epoch: 354  Training loss = 3.4259  Validation loss = 2.3713  \n",
      "\n",
      "Fold: 11  Epoch: 355  Training loss = 3.4254  Validation loss = 2.3703  \n",
      "\n",
      "Fold: 11  Epoch: 356  Training loss = 3.4249  Validation loss = 2.3691  \n",
      "\n",
      "Fold: 11  Epoch: 357  Training loss = 3.4246  Validation loss = 2.3683  \n",
      "\n",
      "Fold: 11  Epoch: 358  Training loss = 3.4241  Validation loss = 2.3672  \n",
      "\n",
      "Fold: 11  Epoch: 359  Training loss = 3.4237  Validation loss = 2.3661  \n",
      "\n",
      "Fold: 11  Epoch: 360  Training loss = 3.4232  Validation loss = 2.3650  \n",
      "\n",
      "Fold: 11  Epoch: 361  Training loss = 3.4229  Validation loss = 2.3641  \n",
      "\n",
      "Fold: 11  Epoch: 362  Training loss = 3.4226  Validation loss = 2.3635  \n",
      "\n",
      "Fold: 11  Epoch: 363  Training loss = 3.4223  Validation loss = 2.3626  \n",
      "\n",
      "Fold: 11  Epoch: 364  Training loss = 3.4218  Validation loss = 2.3616  \n",
      "\n",
      "Fold: 11  Epoch: 365  Training loss = 3.4215  Validation loss = 2.3608  \n",
      "\n",
      "Fold: 11  Epoch: 366  Training loss = 3.4212  Validation loss = 2.3600  \n",
      "\n",
      "Fold: 11  Epoch: 367  Training loss = 3.4208  Validation loss = 2.3591  \n",
      "\n",
      "Fold: 11  Epoch: 368  Training loss = 3.4204  Validation loss = 2.3582  \n",
      "\n",
      "Fold: 11  Epoch: 369  Training loss = 3.4203  Validation loss = 2.3578  \n",
      "\n",
      "Fold: 11  Epoch: 370  Training loss = 3.4199  Validation loss = 2.3570  \n",
      "\n",
      "Fold: 11  Epoch: 371  Training loss = 3.4197  Validation loss = 2.3563  \n",
      "\n",
      "Fold: 11  Epoch: 372  Training loss = 3.4193  Validation loss = 2.3554  \n",
      "\n",
      "Fold: 11  Epoch: 373  Training loss = 3.4189  Validation loss = 2.3543  \n",
      "\n",
      "Fold: 11  Epoch: 374  Training loss = 3.4185  Validation loss = 2.3533  \n",
      "\n",
      "Fold: 11  Epoch: 375  Training loss = 3.4182  Validation loss = 2.3527  \n",
      "\n",
      "Fold: 11  Epoch: 376  Training loss = 3.4178  Validation loss = 2.3516  \n",
      "\n",
      "Fold: 11  Epoch: 377  Training loss = 3.4173  Validation loss = 2.3505  \n",
      "\n",
      "Fold: 11  Epoch: 378  Training loss = 3.4170  Validation loss = 2.3499  \n",
      "\n",
      "Fold: 11  Epoch: 379  Training loss = 3.4166  Validation loss = 2.3490  \n",
      "\n",
      "Fold: 11  Epoch: 380  Training loss = 3.4162  Validation loss = 2.3480  \n",
      "\n",
      "Fold: 11  Epoch: 381  Training loss = 3.4159  Validation loss = 2.3471  \n",
      "\n",
      "Fold: 11  Epoch: 382  Training loss = 3.4155  Validation loss = 2.3463  \n",
      "\n",
      "Fold: 11  Epoch: 383  Training loss = 3.4151  Validation loss = 2.3453  \n",
      "\n",
      "Fold: 11  Epoch: 384  Training loss = 3.4146  Validation loss = 2.3443  \n",
      "\n",
      "Fold: 11  Epoch: 385  Training loss = 3.4144  Validation loss = 2.3437  \n",
      "\n",
      "Fold: 11  Epoch: 386  Training loss = 3.4139  Validation loss = 2.3428  \n",
      "\n",
      "Fold: 11  Epoch: 387  Training loss = 3.4136  Validation loss = 2.3420  \n",
      "\n",
      "Fold: 11  Epoch: 388  Training loss = 3.4130  Validation loss = 2.3412  \n",
      "\n",
      "Fold: 11  Epoch: 389  Training loss = 3.4076  Validation loss = 2.3404  \n",
      "\n",
      "Fold: 11  Epoch: 390  Training loss = 3.4070  Validation loss = 2.3395  \n",
      "\n",
      "Fold: 11  Epoch: 391  Training loss = 3.4065  Validation loss = 2.3384  \n",
      "\n",
      "Fold: 11  Epoch: 392  Training loss = 3.4062  Validation loss = 2.3376  \n",
      "\n",
      "Fold: 11  Epoch: 393  Training loss = 3.4057  Validation loss = 2.3364  \n",
      "\n",
      "Fold: 11  Epoch: 394  Training loss = 3.4052  Validation loss = 2.3354  \n",
      "\n",
      "Fold: 11  Epoch: 395  Training loss = 3.4051  Validation loss = 2.3351  \n",
      "\n",
      "Fold: 11  Epoch: 396  Training loss = 3.4047  Validation loss = 2.3341  \n",
      "\n",
      "Fold: 11  Epoch: 397  Training loss = 3.4042  Validation loss = 2.3330  \n",
      "\n",
      "Fold: 11  Epoch: 398  Training loss = 3.4039  Validation loss = 2.3322  \n",
      "\n",
      "Fold: 11  Epoch: 399  Training loss = 3.4036  Validation loss = 2.3315  \n",
      "\n",
      "Fold: 11  Epoch: 400  Training loss = 3.4033  Validation loss = 2.3307  \n",
      "\n",
      "Fold: 11  Epoch: 401  Training loss = 3.4028  Validation loss = 2.3296  \n",
      "\n",
      "Fold: 11  Epoch: 402  Training loss = 3.4024  Validation loss = 2.3287  \n",
      "\n",
      "Fold: 11  Epoch: 403  Training loss = 3.4020  Validation loss = 2.3277  \n",
      "\n",
      "Fold: 11  Epoch: 404  Training loss = 3.4017  Validation loss = 2.3268  \n",
      "\n",
      "Fold: 11  Epoch: 405  Training loss = 3.4013  Validation loss = 2.3260  \n",
      "\n",
      "Fold: 11  Epoch: 406  Training loss = 3.4009  Validation loss = 2.3250  \n",
      "\n",
      "Fold: 11  Epoch: 407  Training loss = 3.4005  Validation loss = 2.3240  \n",
      "\n",
      "Fold: 11  Epoch: 408  Training loss = 3.4002  Validation loss = 2.3233  \n",
      "\n",
      "Fold: 11  Epoch: 409  Training loss = 3.3998  Validation loss = 2.3223  \n",
      "\n",
      "Fold: 11  Epoch: 410  Training loss = 3.3997  Validation loss = 2.3219  \n",
      "\n",
      "Fold: 11  Epoch: 411  Training loss = 3.3994  Validation loss = 2.3212  \n",
      "\n",
      "Fold: 11  Epoch: 412  Training loss = 3.3990  Validation loss = 2.3203  \n",
      "\n",
      "Fold: 11  Epoch: 413  Training loss = 3.3987  Validation loss = 2.3196  \n",
      "\n",
      "Fold: 11  Epoch: 414  Training loss = 3.3982  Validation loss = 2.3184  \n",
      "\n",
      "Fold: 11  Epoch: 415  Training loss = 3.3978  Validation loss = 2.3173  \n",
      "\n",
      "Fold: 11  Epoch: 416  Training loss = 3.3973  Validation loss = 2.3163  \n",
      "\n",
      "Fold: 11  Epoch: 417  Training loss = 3.3970  Validation loss = 2.3154  \n",
      "\n",
      "Fold: 11  Epoch: 418  Training loss = 3.3967  Validation loss = 2.3146  \n",
      "\n",
      "Fold: 11  Epoch: 419  Training loss = 3.3963  Validation loss = 2.3138  \n",
      "\n",
      "Fold: 11  Epoch: 420  Training loss = 3.3961  Validation loss = 2.3131  \n",
      "\n",
      "Fold: 11  Epoch: 421  Training loss = 3.3958  Validation loss = 2.3125  \n",
      "\n",
      "Fold: 11  Epoch: 422  Training loss = 3.3955  Validation loss = 2.3117  \n",
      "\n",
      "Fold: 11  Epoch: 423  Training loss = 3.3950  Validation loss = 2.3107  \n",
      "\n",
      "Fold: 11  Epoch: 424  Training loss = 3.3946  Validation loss = 2.3095  \n",
      "\n",
      "Fold: 11  Epoch: 425  Training loss = 3.3943  Validation loss = 2.3087  \n",
      "\n",
      "Fold: 11  Epoch: 426  Training loss = 3.3940  Validation loss = 2.3081  \n",
      "\n",
      "Fold: 11  Epoch: 427  Training loss = 3.3938  Validation loss = 2.3076  \n",
      "\n",
      "Fold: 11  Epoch: 428  Training loss = 3.3935  Validation loss = 2.3067  \n",
      "\n",
      "Fold: 11  Epoch: 429  Training loss = 3.3931  Validation loss = 2.3057  \n",
      "\n",
      "Fold: 11  Epoch: 430  Training loss = 3.3927  Validation loss = 2.3049  \n",
      "\n",
      "Fold: 11  Epoch: 431  Training loss = 3.3924  Validation loss = 2.3041  \n",
      "\n",
      "Fold: 11  Epoch: 432  Training loss = 3.3919  Validation loss = 2.3028  \n",
      "\n",
      "Fold: 11  Epoch: 433  Training loss = 3.3915  Validation loss = 2.3019  \n",
      "\n",
      "Fold: 11  Epoch: 434  Training loss = 3.3911  Validation loss = 2.3009  \n",
      "\n",
      "Fold: 11  Epoch: 435  Training loss = 3.3908  Validation loss = 2.3001  \n",
      "\n",
      "Fold: 11  Epoch: 436  Training loss = 3.3903  Validation loss = 2.2988  \n",
      "\n",
      "Fold: 11  Epoch: 437  Training loss = 3.3897  Validation loss = 2.2974  \n",
      "\n",
      "Fold: 11  Epoch: 438  Training loss = 3.3893  Validation loss = 2.2964  \n",
      "\n",
      "Fold: 11  Epoch: 439  Training loss = 3.3890  Validation loss = 2.2958  \n",
      "\n",
      "Fold: 11  Epoch: 440  Training loss = 3.3886  Validation loss = 2.2947  \n",
      "\n",
      "Fold: 11  Epoch: 441  Training loss = 3.3882  Validation loss = 2.2938  \n",
      "\n",
      "Fold: 11  Epoch: 442  Training loss = 3.3881  Validation loss = 2.2934  \n",
      "\n",
      "Fold: 11  Epoch: 443  Training loss = 3.3877  Validation loss = 2.2925  \n",
      "\n",
      "Fold: 11  Epoch: 444  Training loss = 3.3873  Validation loss = 2.2916  \n",
      "\n",
      "Fold: 11  Epoch: 445  Training loss = 3.3869  Validation loss = 2.2906  \n",
      "\n",
      "Fold: 11  Epoch: 446  Training loss = 3.3866  Validation loss = 2.2897  \n",
      "\n",
      "Fold: 11  Epoch: 447  Training loss = 3.3862  Validation loss = 2.2888  \n",
      "\n",
      "Fold: 11  Epoch: 448  Training loss = 3.3859  Validation loss = 2.2879  \n",
      "\n",
      "Fold: 11  Epoch: 449  Training loss = 3.3856  Validation loss = 2.2873  \n",
      "\n",
      "Fold: 11  Epoch: 450  Training loss = 3.3853  Validation loss = 2.2865  \n",
      "\n",
      "Fold: 11  Epoch: 451  Training loss = 3.3850  Validation loss = 2.2859  \n",
      "\n",
      "Fold: 11  Epoch: 452  Training loss = 3.3846  Validation loss = 2.2847  \n",
      "\n",
      "Fold: 11  Epoch: 453  Training loss = 3.3841  Validation loss = 2.2836  \n",
      "\n",
      "Fold: 11  Epoch: 454  Training loss = 3.3838  Validation loss = 2.2829  \n",
      "\n",
      "Fold: 11  Epoch: 455  Training loss = 3.3835  Validation loss = 2.2821  \n",
      "\n",
      "Fold: 11  Epoch: 456  Training loss = 3.3832  Validation loss = 2.2812  \n",
      "\n",
      "Fold: 11  Epoch: 457  Training loss = 3.3826  Validation loss = 2.2799  \n",
      "\n",
      "Fold: 11  Epoch: 458  Training loss = 3.3824  Validation loss = 2.2792  \n",
      "\n",
      "Fold: 11  Epoch: 459  Training loss = 3.3820  Validation loss = 2.2782  \n",
      "\n",
      "Fold: 11  Epoch: 460  Training loss = 3.3817  Validation loss = 2.2775  \n",
      "\n",
      "Fold: 11  Epoch: 461  Training loss = 3.3812  Validation loss = 2.2763  \n",
      "\n",
      "Fold: 11  Epoch: 462  Training loss = 3.3807  Validation loss = 2.2752  \n",
      "\n",
      "Fold: 11  Epoch: 463  Training loss = 3.3805  Validation loss = 2.2746  \n",
      "\n",
      "Fold: 11  Epoch: 464  Training loss = 3.3802  Validation loss = 2.2738  \n",
      "\n",
      "Fold: 11  Epoch: 465  Training loss = 3.3799  Validation loss = 2.2732  \n",
      "\n",
      "Fold: 11  Epoch: 466  Training loss = 3.3795  Validation loss = 2.2721  \n",
      "\n",
      "Fold: 11  Epoch: 467  Training loss = 3.3792  Validation loss = 2.2712  \n",
      "\n",
      "Fold: 11  Epoch: 468  Training loss = 3.3788  Validation loss = 2.2704  \n",
      "\n",
      "Fold: 11  Epoch: 469  Training loss = 3.3785  Validation loss = 2.2695  \n",
      "\n",
      "Fold: 11  Epoch: 470  Training loss = 3.3781  Validation loss = 2.2687  \n",
      "\n",
      "Fold: 11  Epoch: 471  Training loss = 3.3776  Validation loss = 2.2675  \n",
      "\n",
      "Fold: 11  Epoch: 472  Training loss = 3.3773  Validation loss = 2.2667  \n",
      "\n",
      "Fold: 11  Epoch: 473  Training loss = 3.3770  Validation loss = 2.2659  \n",
      "\n",
      "Fold: 11  Epoch: 474  Training loss = 3.3765  Validation loss = 2.2647  \n",
      "\n",
      "Fold: 11  Epoch: 475  Training loss = 3.3761  Validation loss = 2.2638  \n",
      "\n",
      "Fold: 11  Epoch: 476  Training loss = 3.3758  Validation loss = 2.2630  \n",
      "\n",
      "Fold: 11  Epoch: 477  Training loss = 3.3755  Validation loss = 2.2623  \n",
      "\n",
      "Fold: 11  Epoch: 478  Training loss = 3.3750  Validation loss = 2.2610  \n",
      "\n",
      "Fold: 11  Epoch: 479  Training loss = 3.3747  Validation loss = 2.2603  \n",
      "\n",
      "Fold: 11  Epoch: 480  Training loss = 3.3743  Validation loss = 2.2592  \n",
      "\n",
      "Fold: 11  Epoch: 481  Training loss = 3.3738  Validation loss = 2.2581  \n",
      "\n",
      "Fold: 11  Epoch: 482  Training loss = 3.3737  Validation loss = 2.2576  \n",
      "\n",
      "Fold: 11  Epoch: 483  Training loss = 3.3732  Validation loss = 2.2565  \n",
      "\n",
      "Fold: 11  Epoch: 484  Training loss = 3.3729  Validation loss = 2.2557  \n",
      "\n",
      "Fold: 11  Epoch: 485  Training loss = 3.3726  Validation loss = 2.2549  \n",
      "\n",
      "Fold: 11  Epoch: 486  Training loss = 3.3722  Validation loss = 2.2540  \n",
      "\n",
      "Fold: 11  Epoch: 487  Training loss = 3.3718  Validation loss = 2.2529  \n",
      "\n",
      "Fold: 11  Epoch: 488  Training loss = 3.3715  Validation loss = 2.2522  \n",
      "\n",
      "Fold: 11  Epoch: 489  Training loss = 3.3712  Validation loss = 2.2515  \n",
      "\n",
      "Fold: 11  Epoch: 490  Training loss = 3.3709  Validation loss = 2.2508  \n",
      "\n",
      "Fold: 11  Epoch: 491  Training loss = 3.3705  Validation loss = 2.2498  \n",
      "\n",
      "Fold: 11  Epoch: 492  Training loss = 3.3701  Validation loss = 2.2489  \n",
      "\n",
      "Fold: 11  Epoch: 493  Training loss = 3.3698  Validation loss = 2.2479  \n",
      "\n",
      "Fold: 11  Epoch: 494  Training loss = 3.3693  Validation loss = 2.2468  \n",
      "\n",
      "Fold: 11  Epoch: 495  Training loss = 3.3690  Validation loss = 2.2460  \n",
      "\n",
      "Fold: 11  Epoch: 496  Training loss = 3.3686  Validation loss = 2.2450  \n",
      "\n",
      "Fold: 11  Epoch: 497  Training loss = 3.3681  Validation loss = 2.2437  \n",
      "\n",
      "Fold: 11  Epoch: 498  Training loss = 3.3678  Validation loss = 2.2431  \n",
      "\n",
      "Fold: 11  Epoch: 499  Training loss = 3.3675  Validation loss = 2.2424  \n",
      "\n",
      "Fold: 11  Epoch: 500  Training loss = 3.3672  Validation loss = 2.2416  \n",
      "\n",
      "Check model:  Fold: 11  Optimal epoch: 500  \n",
      "\n",
      "Fold: 12  Epoch: 1  Training loss = 3.3935  Validation loss = 3.5173  \n",
      "\n",
      "Fold: 12  Epoch: 2  Training loss = 3.3931  Validation loss = 3.5163  \n",
      "\n",
      "Fold: 12  Epoch: 3  Training loss = 3.3926  Validation loss = 3.5152  \n",
      "\n",
      "Fold: 12  Epoch: 4  Training loss = 3.3922  Validation loss = 3.5143  \n",
      "\n",
      "Fold: 12  Epoch: 5  Training loss = 3.3919  Validation loss = 3.5136  \n",
      "\n",
      "Fold: 12  Epoch: 6  Training loss = 3.3914  Validation loss = 3.5125  \n",
      "\n",
      "Fold: 12  Epoch: 7  Training loss = 3.3911  Validation loss = 3.5118  \n",
      "\n",
      "Fold: 12  Epoch: 8  Training loss = 3.3908  Validation loss = 3.5110  \n",
      "\n",
      "Fold: 12  Epoch: 9  Training loss = 3.3902  Validation loss = 3.5097  \n",
      "\n",
      "Fold: 12  Epoch: 10  Training loss = 3.3898  Validation loss = 3.5086  \n",
      "\n",
      "Fold: 12  Epoch: 11  Training loss = 3.3893  Validation loss = 3.5076  \n",
      "\n",
      "Fold: 12  Epoch: 12  Training loss = 3.3891  Validation loss = 3.5069  \n",
      "\n",
      "Fold: 12  Epoch: 13  Training loss = 3.3885  Validation loss = 3.5056  \n",
      "\n",
      "Fold: 12  Epoch: 14  Training loss = 3.3880  Validation loss = 3.5045  \n",
      "\n",
      "Fold: 12  Epoch: 15  Training loss = 3.3876  Validation loss = 3.5035  \n",
      "\n",
      "Fold: 12  Epoch: 16  Training loss = 3.3872  Validation loss = 3.5027  \n",
      "\n",
      "Fold: 12  Epoch: 17  Training loss = 3.3869  Validation loss = 3.5018  \n",
      "\n",
      "Fold: 12  Epoch: 18  Training loss = 3.3865  Validation loss = 3.5009  \n",
      "\n",
      "Fold: 12  Epoch: 19  Training loss = 3.3860  Validation loss = 3.5000  \n",
      "\n",
      "Fold: 12  Epoch: 20  Training loss = 3.3854  Validation loss = 3.4986  \n",
      "\n",
      "Fold: 12  Epoch: 21  Training loss = 3.3850  Validation loss = 3.4976  \n",
      "\n",
      "Fold: 12  Epoch: 22  Training loss = 3.3844  Validation loss = 3.4965  \n",
      "\n",
      "Fold: 12  Epoch: 23  Training loss = 3.3834  Validation loss = 3.4954  \n",
      "\n",
      "Fold: 12  Epoch: 24  Training loss = 3.3805  Validation loss = 3.4942  \n",
      "\n",
      "Fold: 12  Epoch: 25  Training loss = 3.3800  Validation loss = 3.4933  \n",
      "\n",
      "Fold: 12  Epoch: 26  Training loss = 3.3795  Validation loss = 3.4923  \n",
      "\n",
      "Fold: 12  Epoch: 27  Training loss = 3.3790  Validation loss = 3.4911  \n",
      "\n",
      "Fold: 12  Epoch: 28  Training loss = 3.3785  Validation loss = 3.4900  \n",
      "\n",
      "Fold: 12  Epoch: 29  Training loss = 3.3781  Validation loss = 3.4890  \n",
      "\n",
      "Fold: 12  Epoch: 30  Training loss = 3.3775  Validation loss = 3.4877  \n",
      "\n",
      "Fold: 12  Epoch: 31  Training loss = 3.3771  Validation loss = 3.4868  \n",
      "\n",
      "Fold: 12  Epoch: 32  Training loss = 3.3767  Validation loss = 3.4858  \n",
      "\n",
      "Fold: 12  Epoch: 33  Training loss = 3.3764  Validation loss = 3.4851  \n",
      "\n",
      "Fold: 12  Epoch: 34  Training loss = 3.3760  Validation loss = 3.4842  \n",
      "\n",
      "Fold: 12  Epoch: 35  Training loss = 3.3756  Validation loss = 3.4832  \n",
      "\n",
      "Fold: 12  Epoch: 36  Training loss = 3.3753  Validation loss = 3.4825  \n",
      "\n",
      "Fold: 12  Epoch: 37  Training loss = 3.3749  Validation loss = 3.4815  \n",
      "\n",
      "Fold: 12  Epoch: 38  Training loss = 3.3744  Validation loss = 3.4804  \n",
      "\n",
      "Fold: 12  Epoch: 39  Training loss = 3.3739  Validation loss = 3.4792  \n",
      "\n",
      "Fold: 12  Epoch: 40  Training loss = 3.3736  Validation loss = 3.4784  \n",
      "\n",
      "Fold: 12  Epoch: 41  Training loss = 3.3731  Validation loss = 3.4772  \n",
      "\n",
      "Fold: 12  Epoch: 42  Training loss = 3.3726  Validation loss = 3.4761  \n",
      "\n",
      "Fold: 12  Epoch: 43  Training loss = 3.3722  Validation loss = 3.4751  \n",
      "\n",
      "Fold: 12  Epoch: 44  Training loss = 3.3717  Validation loss = 3.4740  \n",
      "\n",
      "Fold: 12  Epoch: 45  Training loss = 3.3714  Validation loss = 3.4731  \n",
      "\n",
      "Fold: 12  Epoch: 46  Training loss = 3.3709  Validation loss = 3.4721  \n",
      "\n",
      "Fold: 12  Epoch: 47  Training loss = 3.3704  Validation loss = 3.4708  \n",
      "\n",
      "Fold: 12  Epoch: 48  Training loss = 3.3698  Validation loss = 3.4695  \n",
      "\n",
      "Fold: 12  Epoch: 49  Training loss = 3.3694  Validation loss = 3.4686  \n",
      "\n",
      "Fold: 12  Epoch: 50  Training loss = 3.3692  Validation loss = 3.4680  \n",
      "\n",
      "Fold: 12  Epoch: 51  Training loss = 3.3686  Validation loss = 3.4666  \n",
      "\n",
      "Fold: 12  Epoch: 52  Training loss = 3.3682  Validation loss = 3.4656  \n",
      "\n",
      "Fold: 12  Epoch: 53  Training loss = 3.3678  Validation loss = 3.4648  \n",
      "\n",
      "Fold: 12  Epoch: 54  Training loss = 3.3674  Validation loss = 3.4638  \n",
      "\n",
      "Fold: 12  Epoch: 55  Training loss = 3.3671  Validation loss = 3.4631  \n",
      "\n",
      "Fold: 12  Epoch: 56  Training loss = 3.3667  Validation loss = 3.4621  \n",
      "\n",
      "Fold: 12  Epoch: 57  Training loss = 3.3663  Validation loss = 3.4612  \n",
      "\n",
      "Fold: 12  Epoch: 58  Training loss = 3.3659  Validation loss = 3.4603  \n",
      "\n",
      "Fold: 12  Epoch: 59  Training loss = 3.3655  Validation loss = 3.4593  \n",
      "\n",
      "Fold: 12  Epoch: 60  Training loss = 3.3653  Validation loss = 3.4588  \n",
      "\n",
      "Fold: 12  Epoch: 61  Training loss = 3.3649  Validation loss = 3.4579  \n",
      "\n",
      "Fold: 12  Epoch: 62  Training loss = 3.3645  Validation loss = 3.4568  \n",
      "\n",
      "Fold: 12  Epoch: 63  Training loss = 3.3640  Validation loss = 3.4558  \n",
      "\n",
      "Fold: 12  Epoch: 64  Training loss = 3.3636  Validation loss = 3.4548  \n",
      "\n",
      "Fold: 12  Epoch: 65  Training loss = 3.3632  Validation loss = 3.4539  \n",
      "\n",
      "Fold: 12  Epoch: 66  Training loss = 3.3629  Validation loss = 3.4530  \n",
      "\n",
      "Fold: 12  Epoch: 67  Training loss = 3.3625  Validation loss = 3.4521  \n",
      "\n",
      "Fold: 12  Epoch: 68  Training loss = 3.3620  Validation loss = 3.4510  \n",
      "\n",
      "Fold: 12  Epoch: 69  Training loss = 3.3617  Validation loss = 3.4503  \n",
      "\n",
      "Fold: 12  Epoch: 70  Training loss = 3.3613  Validation loss = 3.4494  \n",
      "\n",
      "Fold: 12  Epoch: 71  Training loss = 3.3608  Validation loss = 3.4482  \n",
      "\n",
      "Fold: 12  Epoch: 72  Training loss = 3.3604  Validation loss = 3.4472  \n",
      "\n",
      "Fold: 12  Epoch: 73  Training loss = 3.3600  Validation loss = 3.4461  \n",
      "\n",
      "Fold: 12  Epoch: 74  Training loss = 3.3595  Validation loss = 3.4451  \n",
      "\n",
      "Fold: 12  Epoch: 75  Training loss = 3.3592  Validation loss = 3.4443  \n",
      "\n",
      "Fold: 12  Epoch: 76  Training loss = 3.3588  Validation loss = 3.4433  \n",
      "\n",
      "Fold: 12  Epoch: 77  Training loss = 3.3585  Validation loss = 3.4426  \n",
      "\n",
      "Fold: 12  Epoch: 78  Training loss = 3.3581  Validation loss = 3.4416  \n",
      "\n",
      "Fold: 12  Epoch: 79  Training loss = 3.3576  Validation loss = 3.4406  \n",
      "\n",
      "Fold: 12  Epoch: 80  Training loss = 3.3573  Validation loss = 3.4398  \n",
      "\n",
      "Fold: 12  Epoch: 81  Training loss = 3.3569  Validation loss = 3.4388  \n",
      "\n",
      "Fold: 12  Epoch: 82  Training loss = 3.3564  Validation loss = 3.4377  \n",
      "\n",
      "Fold: 12  Epoch: 83  Training loss = 3.3561  Validation loss = 3.4369  \n",
      "\n",
      "Fold: 12  Epoch: 84  Training loss = 3.3559  Validation loss = 3.4364  \n",
      "\n",
      "Fold: 12  Epoch: 85  Training loss = 3.3554  Validation loss = 3.4352  \n",
      "\n",
      "Fold: 12  Epoch: 86  Training loss = 3.3550  Validation loss = 3.4343  \n",
      "\n",
      "Fold: 12  Epoch: 87  Training loss = 3.3547  Validation loss = 3.4336  \n",
      "\n",
      "Fold: 12  Epoch: 88  Training loss = 3.3542  Validation loss = 3.4323  \n",
      "\n",
      "Fold: 12  Epoch: 89  Training loss = 3.3537  Validation loss = 3.4312  \n",
      "\n",
      "Fold: 12  Epoch: 90  Training loss = 3.3534  Validation loss = 3.4304  \n",
      "\n",
      "Fold: 12  Epoch: 91  Training loss = 3.3530  Validation loss = 3.4294  \n",
      "\n",
      "Fold: 12  Epoch: 92  Training loss = 3.3526  Validation loss = 3.4285  \n",
      "\n",
      "Fold: 12  Epoch: 93  Training loss = 3.3520  Validation loss = 3.4272  \n",
      "\n",
      "Fold: 12  Epoch: 94  Training loss = 3.3516  Validation loss = 3.4262  \n",
      "\n",
      "Fold: 12  Epoch: 95  Training loss = 3.3512  Validation loss = 3.4252  \n",
      "\n",
      "Fold: 12  Epoch: 96  Training loss = 3.3508  Validation loss = 3.4243  \n",
      "\n",
      "Fold: 12  Epoch: 97  Training loss = 3.3501  Validation loss = 3.4226  \n",
      "\n",
      "Fold: 12  Epoch: 98  Training loss = 3.3497  Validation loss = 3.4215  \n",
      "\n",
      "Fold: 12  Epoch: 99  Training loss = 3.3491  Validation loss = 3.4203  \n",
      "\n",
      "Fold: 12  Epoch: 100  Training loss = 3.3486  Validation loss = 3.4189  \n",
      "\n",
      "Fold: 12  Epoch: 101  Training loss = 3.3481  Validation loss = 3.4177  \n",
      "\n",
      "Fold: 12  Epoch: 102  Training loss = 3.3476  Validation loss = 3.4166  \n",
      "\n",
      "Fold: 12  Epoch: 103  Training loss = 3.3471  Validation loss = 3.4153  \n",
      "\n",
      "Fold: 12  Epoch: 104  Training loss = 3.3465  Validation loss = 3.4140  \n",
      "\n",
      "Fold: 12  Epoch: 105  Training loss = 3.3461  Validation loss = 3.4130  \n",
      "\n",
      "Fold: 12  Epoch: 106  Training loss = 3.3457  Validation loss = 3.4121  \n",
      "\n",
      "Fold: 12  Epoch: 107  Training loss = 3.3452  Validation loss = 3.4108  \n",
      "\n",
      "Fold: 12  Epoch: 108  Training loss = 3.3447  Validation loss = 3.4096  \n",
      "\n",
      "Fold: 12  Epoch: 109  Training loss = 3.3444  Validation loss = 3.4089  \n",
      "\n",
      "Fold: 12  Epoch: 110  Training loss = 3.3441  Validation loss = 3.4082  \n",
      "\n",
      "Fold: 12  Epoch: 111  Training loss = 3.3436  Validation loss = 3.4070  \n",
      "\n",
      "Fold: 12  Epoch: 112  Training loss = 3.3432  Validation loss = 3.4062  \n",
      "\n",
      "Fold: 12  Epoch: 113  Training loss = 3.3430  Validation loss = 3.4056  \n",
      "\n",
      "Fold: 12  Epoch: 114  Training loss = 3.3427  Validation loss = 3.4049  \n",
      "\n",
      "Fold: 12  Epoch: 115  Training loss = 3.3423  Validation loss = 3.4040  \n",
      "\n",
      "Fold: 12  Epoch: 116  Training loss = 3.3420  Validation loss = 3.4031  \n",
      "\n",
      "Fold: 12  Epoch: 117  Training loss = 3.3414  Validation loss = 3.4018  \n",
      "\n",
      "Fold: 12  Epoch: 118  Training loss = 3.3411  Validation loss = 3.4011  \n",
      "\n",
      "Fold: 12  Epoch: 119  Training loss = 3.3407  Validation loss = 3.4001  \n",
      "\n",
      "Fold: 12  Epoch: 120  Training loss = 3.3402  Validation loss = 3.3988  \n",
      "\n",
      "Fold: 12  Epoch: 121  Training loss = 3.3396  Validation loss = 3.3974  \n",
      "\n",
      "Fold: 12  Epoch: 122  Training loss = 3.3390  Validation loss = 3.3961  \n",
      "\n",
      "Fold: 12  Epoch: 123  Training loss = 3.3385  Validation loss = 3.3948  \n",
      "\n",
      "Fold: 12  Epoch: 124  Training loss = 3.3380  Validation loss = 3.3937  \n",
      "\n",
      "Fold: 12  Epoch: 125  Training loss = 3.3376  Validation loss = 3.3926  \n",
      "\n",
      "Fold: 12  Epoch: 126  Training loss = 3.3371  Validation loss = 3.3915  \n",
      "\n",
      "Fold: 12  Epoch: 127  Training loss = 3.3367  Validation loss = 3.3903  \n",
      "\n",
      "Fold: 12  Epoch: 128  Training loss = 3.3361  Validation loss = 3.3891  \n",
      "\n",
      "Fold: 12  Epoch: 129  Training loss = 3.3358  Validation loss = 3.3881  \n",
      "\n",
      "Fold: 12  Epoch: 130  Training loss = 3.3352  Validation loss = 3.3868  \n",
      "\n",
      "Fold: 12  Epoch: 131  Training loss = 3.3348  Validation loss = 3.3857  \n",
      "\n",
      "Fold: 12  Epoch: 132  Training loss = 3.3343  Validation loss = 3.3846  \n",
      "\n",
      "Fold: 12  Epoch: 133  Training loss = 3.3337  Validation loss = 3.3832  \n",
      "\n",
      "Fold: 12  Epoch: 134  Training loss = 3.3333  Validation loss = 3.3822  \n",
      "\n",
      "Fold: 12  Epoch: 135  Training loss = 3.3328  Validation loss = 3.3809  \n",
      "\n",
      "Fold: 12  Epoch: 136  Training loss = 3.3324  Validation loss = 3.3799  \n",
      "\n",
      "Fold: 12  Epoch: 137  Training loss = 3.3319  Validation loss = 3.3787  \n",
      "\n",
      "Fold: 12  Epoch: 138  Training loss = 3.3315  Validation loss = 3.3777  \n",
      "\n",
      "Fold: 12  Epoch: 139  Training loss = 3.3310  Validation loss = 3.3766  \n",
      "\n",
      "Fold: 12  Epoch: 140  Training loss = 3.3306  Validation loss = 3.3756  \n",
      "\n",
      "Fold: 12  Epoch: 141  Training loss = 3.3302  Validation loss = 3.3747  \n",
      "\n",
      "Fold: 12  Epoch: 142  Training loss = 3.3299  Validation loss = 3.3740  \n",
      "\n",
      "Fold: 12  Epoch: 143  Training loss = 3.3296  Validation loss = 3.3731  \n",
      "\n",
      "Fold: 12  Epoch: 144  Training loss = 3.3292  Validation loss = 3.3722  \n",
      "\n",
      "Fold: 12  Epoch: 145  Training loss = 3.3287  Validation loss = 3.3711  \n",
      "\n",
      "Fold: 12  Epoch: 146  Training loss = 3.3282  Validation loss = 3.3698  \n",
      "\n",
      "Fold: 12  Epoch: 147  Training loss = 3.3278  Validation loss = 3.3687  \n",
      "\n",
      "Fold: 12  Epoch: 148  Training loss = 3.3273  Validation loss = 3.3677  \n",
      "\n",
      "Fold: 12  Epoch: 149  Training loss = 3.3271  Validation loss = 3.3670  \n",
      "\n",
      "Fold: 12  Epoch: 150  Training loss = 3.3268  Validation loss = 3.3664  \n",
      "\n",
      "Fold: 12  Epoch: 151  Training loss = 3.3262  Validation loss = 3.3650  \n",
      "\n",
      "Fold: 12  Epoch: 152  Training loss = 3.3259  Validation loss = 3.3642  \n",
      "\n",
      "Fold: 12  Epoch: 153  Training loss = 3.3256  Validation loss = 3.3635  \n",
      "\n",
      "Fold: 12  Epoch: 154  Training loss = 3.3252  Validation loss = 3.3626  \n",
      "\n",
      "Fold: 12  Epoch: 155  Training loss = 3.3249  Validation loss = 3.3617  \n",
      "\n",
      "Fold: 12  Epoch: 156  Training loss = 3.3245  Validation loss = 3.3607  \n",
      "\n",
      "Fold: 12  Epoch: 157  Training loss = 3.3240  Validation loss = 3.3596  \n",
      "\n",
      "Fold: 12  Epoch: 158  Training loss = 3.3235  Validation loss = 3.3585  \n",
      "\n",
      "Fold: 12  Epoch: 159  Training loss = 3.3231  Validation loss = 3.3575  \n",
      "\n",
      "Fold: 12  Epoch: 160  Training loss = 3.3227  Validation loss = 3.3566  \n",
      "\n",
      "Fold: 12  Epoch: 161  Training loss = 3.3223  Validation loss = 3.3555  \n",
      "\n",
      "Fold: 12  Epoch: 162  Training loss = 3.3220  Validation loss = 3.3547  \n",
      "\n",
      "Fold: 12  Epoch: 163  Training loss = 3.3217  Validation loss = 3.3541  \n",
      "\n",
      "Fold: 12  Epoch: 164  Training loss = 3.3213  Validation loss = 3.3531  \n",
      "\n",
      "Fold: 12  Epoch: 165  Training loss = 3.3209  Validation loss = 3.3522  \n",
      "\n",
      "Fold: 12  Epoch: 166  Training loss = 3.3205  Validation loss = 3.3510  \n",
      "\n",
      "Fold: 12  Epoch: 167  Training loss = 3.3201  Validation loss = 3.3501  \n",
      "\n",
      "Fold: 12  Epoch: 168  Training loss = 3.3196  Validation loss = 3.3490  \n",
      "\n",
      "Fold: 12  Epoch: 169  Training loss = 3.3192  Validation loss = 3.3479  \n",
      "\n",
      "Fold: 12  Epoch: 170  Training loss = 3.3188  Validation loss = 3.3469  \n",
      "\n",
      "Fold: 12  Epoch: 171  Training loss = 3.3185  Validation loss = 3.3461  \n",
      "\n",
      "Fold: 12  Epoch: 172  Training loss = 3.3182  Validation loss = 3.3454  \n",
      "\n",
      "Fold: 12  Epoch: 173  Training loss = 3.3179  Validation loss = 3.3447  \n",
      "\n",
      "Fold: 12  Epoch: 174  Training loss = 3.3175  Validation loss = 3.3438  \n",
      "\n",
      "Fold: 12  Epoch: 175  Training loss = 3.3171  Validation loss = 3.3427  \n",
      "\n",
      "Fold: 12  Epoch: 176  Training loss = 3.3167  Validation loss = 3.3418  \n",
      "\n",
      "Fold: 12  Epoch: 177  Training loss = 3.3161  Validation loss = 3.3403  \n",
      "\n",
      "Fold: 12  Epoch: 178  Training loss = 3.3157  Validation loss = 3.3392  \n",
      "\n",
      "Fold: 12  Epoch: 179  Training loss = 3.3152  Validation loss = 3.3382  \n",
      "\n",
      "Fold: 12  Epoch: 180  Training loss = 3.3148  Validation loss = 3.3372  \n",
      "\n",
      "Fold: 12  Epoch: 181  Training loss = 3.3145  Validation loss = 3.3363  \n",
      "\n",
      "Fold: 12  Epoch: 182  Training loss = 3.3140  Validation loss = 3.3353  \n",
      "\n",
      "Fold: 12  Epoch: 183  Training loss = 3.3135  Validation loss = 3.3340  \n",
      "\n",
      "Fold: 12  Epoch: 184  Training loss = 3.3132  Validation loss = 3.3333  \n",
      "\n",
      "Fold: 12  Epoch: 185  Training loss = 3.3128  Validation loss = 3.3323  \n",
      "\n",
      "Fold: 12  Epoch: 186  Training loss = 3.3125  Validation loss = 3.3314  \n",
      "\n",
      "Fold: 12  Epoch: 187  Training loss = 3.3121  Validation loss = 3.3305  \n",
      "\n",
      "Fold: 12  Epoch: 188  Training loss = 3.3117  Validation loss = 3.3297  \n",
      "\n",
      "Fold: 12  Epoch: 189  Training loss = 3.3111  Validation loss = 3.3282  \n",
      "\n",
      "Fold: 12  Epoch: 190  Training loss = 3.3107  Validation loss = 3.3273  \n",
      "\n",
      "Fold: 12  Epoch: 191  Training loss = 3.3103  Validation loss = 3.3261  \n",
      "\n",
      "Fold: 12  Epoch: 192  Training loss = 3.3098  Validation loss = 3.3251  \n",
      "\n",
      "Fold: 12  Epoch: 193  Training loss = 3.3095  Validation loss = 3.3243  \n",
      "\n",
      "Fold: 12  Epoch: 194  Training loss = 3.3091  Validation loss = 3.3234  \n",
      "\n",
      "Fold: 12  Epoch: 195  Training loss = 3.3088  Validation loss = 3.3227  \n",
      "\n",
      "Fold: 12  Epoch: 196  Training loss = 3.3083  Validation loss = 3.3217  \n",
      "\n",
      "Fold: 12  Epoch: 197  Training loss = 3.3024  Validation loss = 3.3200  \n",
      "\n",
      "Fold: 12  Epoch: 198  Training loss = 3.3021  Validation loss = 3.3194  \n",
      "\n",
      "Fold: 12  Epoch: 199  Training loss = 3.3017  Validation loss = 3.3183  \n",
      "\n",
      "Fold: 12  Epoch: 200  Training loss = 3.3013  Validation loss = 3.3174  \n",
      "\n",
      "Fold: 12  Epoch: 201  Training loss = 3.3008  Validation loss = 3.3163  \n",
      "\n",
      "Fold: 12  Epoch: 202  Training loss = 3.3005  Validation loss = 3.3154  \n",
      "\n",
      "Fold: 12  Epoch: 203  Training loss = 3.3001  Validation loss = 3.3146  \n",
      "\n",
      "Fold: 12  Epoch: 204  Training loss = 3.2998  Validation loss = 3.3137  \n",
      "\n",
      "Fold: 12  Epoch: 205  Training loss = 3.2994  Validation loss = 3.3129  \n",
      "\n",
      "Fold: 12  Epoch: 206  Training loss = 3.2991  Validation loss = 3.3121  \n",
      "\n",
      "Fold: 12  Epoch: 207  Training loss = 3.2987  Validation loss = 3.3110  \n",
      "\n",
      "Fold: 12  Epoch: 208  Training loss = 3.2981  Validation loss = 3.3097  \n",
      "\n",
      "Fold: 12  Epoch: 209  Training loss = 3.2977  Validation loss = 3.3087  \n",
      "\n",
      "Fold: 12  Epoch: 210  Training loss = 3.2975  Validation loss = 3.3080  \n",
      "\n",
      "Fold: 12  Epoch: 211  Training loss = 3.2972  Validation loss = 3.3075  \n",
      "\n",
      "Fold: 12  Epoch: 212  Training loss = 3.2967  Validation loss = 3.3062  \n",
      "\n",
      "Fold: 12  Epoch: 213  Training loss = 3.2964  Validation loss = 3.3053  \n",
      "\n",
      "Fold: 12  Epoch: 214  Training loss = 3.2960  Validation loss = 3.3045  \n",
      "\n",
      "Fold: 12  Epoch: 215  Training loss = 3.2957  Validation loss = 3.3037  \n",
      "\n",
      "Fold: 12  Epoch: 216  Training loss = 3.2955  Validation loss = 3.3031  \n",
      "\n",
      "Fold: 12  Epoch: 217  Training loss = 3.2950  Validation loss = 3.3020  \n",
      "\n",
      "Fold: 12  Epoch: 218  Training loss = 3.2945  Validation loss = 3.3009  \n",
      "\n",
      "Fold: 12  Epoch: 219  Training loss = 3.2943  Validation loss = 3.3002  \n",
      "\n",
      "Fold: 12  Epoch: 220  Training loss = 3.2938  Validation loss = 3.2991  \n",
      "\n",
      "Fold: 12  Epoch: 221  Training loss = 3.2935  Validation loss = 3.2982  \n",
      "\n",
      "Fold: 12  Epoch: 222  Training loss = 3.2932  Validation loss = 3.2976  \n",
      "\n",
      "Fold: 12  Epoch: 223  Training loss = 3.2929  Validation loss = 3.2967  \n",
      "\n",
      "Fold: 12  Epoch: 224  Training loss = 3.2924  Validation loss = 3.2956  \n",
      "\n",
      "Fold: 12  Epoch: 225  Training loss = 3.2920  Validation loss = 3.2945  \n",
      "\n",
      "Fold: 12  Epoch: 226  Training loss = 3.2916  Validation loss = 3.2937  \n",
      "\n",
      "Fold: 12  Epoch: 227  Training loss = 3.2913  Validation loss = 3.2928  \n",
      "\n",
      "Fold: 12  Epoch: 228  Training loss = 3.2909  Validation loss = 3.2919  \n",
      "\n",
      "Fold: 12  Epoch: 229  Training loss = 3.2904  Validation loss = 3.2906  \n",
      "\n",
      "Fold: 12  Epoch: 230  Training loss = 3.2900  Validation loss = 3.2895  \n",
      "\n",
      "Fold: 12  Epoch: 231  Training loss = 3.2895  Validation loss = 3.2884  \n",
      "\n",
      "Fold: 12  Epoch: 232  Training loss = 3.2892  Validation loss = 3.2875  \n",
      "\n",
      "Fold: 12  Epoch: 233  Training loss = 3.2887  Validation loss = 3.2864  \n",
      "\n",
      "Fold: 12  Epoch: 234  Training loss = 3.2883  Validation loss = 3.2853  \n",
      "\n",
      "Fold: 12  Epoch: 235  Training loss = 3.2879  Validation loss = 3.2844  \n",
      "\n",
      "Fold: 12  Epoch: 236  Training loss = 3.2876  Validation loss = 3.2835  \n",
      "\n",
      "Fold: 12  Epoch: 237  Training loss = 3.2871  Validation loss = 3.2825  \n",
      "\n",
      "Fold: 12  Epoch: 238  Training loss = 3.2867  Validation loss = 3.2814  \n",
      "\n",
      "Fold: 12  Epoch: 239  Training loss = 3.2863  Validation loss = 3.2803  \n",
      "\n",
      "Fold: 12  Epoch: 240  Training loss = 3.2858  Validation loss = 3.2792  \n",
      "\n",
      "Fold: 12  Epoch: 241  Training loss = 3.2854  Validation loss = 3.2782  \n",
      "\n",
      "Fold: 12  Epoch: 242  Training loss = 3.2851  Validation loss = 3.2774  \n",
      "\n",
      "Fold: 12  Epoch: 243  Training loss = 3.2846  Validation loss = 3.2762  \n",
      "\n",
      "Fold: 12  Epoch: 244  Training loss = 3.2843  Validation loss = 3.2753  \n",
      "\n",
      "Fold: 12  Epoch: 245  Training loss = 3.2839  Validation loss = 3.2745  \n",
      "\n",
      "Fold: 12  Epoch: 246  Training loss = 3.2837  Validation loss = 3.2738  \n",
      "\n",
      "Fold: 12  Epoch: 247  Training loss = 3.2834  Validation loss = 3.2730  \n",
      "\n",
      "Fold: 12  Epoch: 248  Training loss = 3.2830  Validation loss = 3.2721  \n",
      "\n",
      "Fold: 12  Epoch: 249  Training loss = 3.2826  Validation loss = 3.2711  \n",
      "\n",
      "Fold: 12  Epoch: 250  Training loss = 3.2822  Validation loss = 3.2702  \n",
      "\n",
      "Fold: 12  Epoch: 251  Training loss = 3.2818  Validation loss = 3.2690  \n",
      "\n",
      "Fold: 12  Epoch: 252  Training loss = 3.2814  Validation loss = 3.2682  \n",
      "\n",
      "Fold: 12  Epoch: 253  Training loss = 3.2811  Validation loss = 3.2673  \n",
      "\n",
      "Fold: 12  Epoch: 254  Training loss = 3.2807  Validation loss = 3.2664  \n",
      "\n",
      "Fold: 12  Epoch: 255  Training loss = 3.2804  Validation loss = 3.2655  \n",
      "\n",
      "Fold: 12  Epoch: 256  Training loss = 3.2799  Validation loss = 3.2643  \n",
      "\n",
      "Fold: 12  Epoch: 257  Training loss = 3.2797  Validation loss = 3.2637  \n",
      "\n",
      "Fold: 12  Epoch: 258  Training loss = 3.2793  Validation loss = 3.2629  \n",
      "\n",
      "Fold: 12  Epoch: 259  Training loss = 3.2790  Validation loss = 3.2622  \n",
      "\n",
      "Fold: 12  Epoch: 260  Training loss = 3.2787  Validation loss = 3.2614  \n",
      "\n",
      "Fold: 12  Epoch: 261  Training loss = 3.2784  Validation loss = 3.2605  \n",
      "\n",
      "Fold: 12  Epoch: 262  Training loss = 3.2781  Validation loss = 3.2597  \n",
      "\n",
      "Fold: 12  Epoch: 263  Training loss = 3.2778  Validation loss = 3.2590  \n",
      "\n",
      "Fold: 12  Epoch: 264  Training loss = 3.2774  Validation loss = 3.2580  \n",
      "\n",
      "Fold: 12  Epoch: 265  Training loss = 3.2771  Validation loss = 3.2572  \n",
      "\n",
      "Fold: 12  Epoch: 266  Training loss = 3.2768  Validation loss = 3.2565  \n",
      "\n",
      "Fold: 12  Epoch: 267  Training loss = 3.2763  Validation loss = 3.2552  \n",
      "\n",
      "Fold: 12  Epoch: 268  Training loss = 3.2759  Validation loss = 3.2543  \n",
      "\n",
      "Fold: 12  Epoch: 269  Training loss = 3.2756  Validation loss = 3.2535  \n",
      "\n",
      "Fold: 12  Epoch: 270  Training loss = 3.2752  Validation loss = 3.2525  \n",
      "\n",
      "Fold: 12  Epoch: 271  Training loss = 3.2748  Validation loss = 3.2516  \n",
      "\n",
      "Fold: 12  Epoch: 272  Training loss = 3.2742  Validation loss = 3.2500  \n",
      "\n",
      "Fold: 12  Epoch: 273  Training loss = 3.2739  Validation loss = 3.2492  \n",
      "\n",
      "Fold: 12  Epoch: 274  Training loss = 3.2735  Validation loss = 3.2483  \n",
      "\n",
      "Fold: 12  Epoch: 275  Training loss = 3.2732  Validation loss = 3.2475  \n",
      "\n",
      "Fold: 12  Epoch: 276  Training loss = 3.2728  Validation loss = 3.2464  \n",
      "\n",
      "Fold: 12  Epoch: 277  Training loss = 3.2726  Validation loss = 3.2459  \n",
      "\n",
      "Fold: 12  Epoch: 278  Training loss = 3.2723  Validation loss = 3.2451  \n",
      "\n",
      "Fold: 12  Epoch: 279  Training loss = 3.2718  Validation loss = 3.2437  \n",
      "\n",
      "Fold: 12  Epoch: 280  Training loss = 3.2715  Validation loss = 3.2430  \n",
      "\n",
      "Fold: 12  Epoch: 281  Training loss = 3.2710  Validation loss = 3.2418  \n",
      "\n",
      "Fold: 12  Epoch: 282  Training loss = 3.2706  Validation loss = 3.2406  \n",
      "\n",
      "Fold: 12  Epoch: 283  Training loss = 3.2702  Validation loss = 3.2396  \n",
      "\n",
      "Fold: 12  Epoch: 284  Training loss = 3.2699  Validation loss = 3.2390  \n",
      "\n",
      "Fold: 12  Epoch: 285  Training loss = 3.2695  Validation loss = 3.2379  \n",
      "\n",
      "Fold: 12  Epoch: 286  Training loss = 3.2691  Validation loss = 3.2370  \n",
      "\n",
      "Fold: 12  Epoch: 287  Training loss = 3.2688  Validation loss = 3.2362  \n",
      "\n",
      "Fold: 12  Epoch: 288  Training loss = 3.2684  Validation loss = 3.2352  \n",
      "\n",
      "Fold: 12  Epoch: 289  Training loss = 3.2680  Validation loss = 3.2342  \n",
      "\n",
      "Fold: 12  Epoch: 290  Training loss = 3.2674  Validation loss = 3.2326  \n",
      "\n",
      "Fold: 12  Epoch: 291  Training loss = 3.2670  Validation loss = 3.2316  \n",
      "\n",
      "Fold: 12  Epoch: 292  Training loss = 3.2667  Validation loss = 3.2309  \n",
      "\n",
      "Fold: 12  Epoch: 293  Training loss = 3.2664  Validation loss = 3.2300  \n",
      "\n",
      "Fold: 12  Epoch: 294  Training loss = 3.2662  Validation loss = 3.2294  \n",
      "\n",
      "Fold: 12  Epoch: 295  Training loss = 3.2657  Validation loss = 3.2283  \n",
      "\n",
      "Fold: 12  Epoch: 296  Training loss = 3.2653  Validation loss = 3.2273  \n",
      "\n",
      "Fold: 12  Epoch: 297  Training loss = 3.2649  Validation loss = 3.2262  \n",
      "\n",
      "Fold: 12  Epoch: 298  Training loss = 3.2646  Validation loss = 3.2255  \n",
      "\n",
      "Fold: 12  Epoch: 299  Training loss = 3.2644  Validation loss = 3.2249  \n",
      "\n",
      "Fold: 12  Epoch: 300  Training loss = 3.2641  Validation loss = 3.2241  \n",
      "\n",
      "Fold: 12  Epoch: 301  Training loss = 3.2638  Validation loss = 3.2234  \n",
      "\n",
      "Fold: 12  Epoch: 302  Training loss = 3.2635  Validation loss = 3.2226  \n",
      "\n",
      "Fold: 12  Epoch: 303  Training loss = 3.2631  Validation loss = 3.2217  \n",
      "\n",
      "Fold: 12  Epoch: 304  Training loss = 3.2627  Validation loss = 3.2206  \n",
      "\n",
      "Fold: 12  Epoch: 305  Training loss = 3.2623  Validation loss = 3.2197  \n",
      "\n",
      "Fold: 12  Epoch: 306  Training loss = 3.2619  Validation loss = 3.2186  \n",
      "\n",
      "Fold: 12  Epoch: 307  Training loss = 3.2615  Validation loss = 3.2176  \n",
      "\n",
      "Fold: 12  Epoch: 308  Training loss = 3.2611  Validation loss = 3.2167  \n",
      "\n",
      "Fold: 12  Epoch: 309  Training loss = 3.2609  Validation loss = 3.2160  \n",
      "\n",
      "Fold: 12  Epoch: 310  Training loss = 3.2606  Validation loss = 3.2152  \n",
      "\n",
      "Fold: 12  Epoch: 311  Training loss = 3.2601  Validation loss = 3.2141  \n",
      "\n",
      "Fold: 12  Epoch: 312  Training loss = 3.2597  Validation loss = 3.2130  \n",
      "\n",
      "Fold: 12  Epoch: 313  Training loss = 3.2593  Validation loss = 3.2120  \n",
      "\n",
      "Fold: 12  Epoch: 314  Training loss = 3.2588  Validation loss = 3.2107  \n",
      "\n",
      "Fold: 12  Epoch: 315  Training loss = 3.2585  Validation loss = 3.2099  \n",
      "\n",
      "Fold: 12  Epoch: 316  Training loss = 3.2583  Validation loss = 3.2093  \n",
      "\n",
      "Fold: 12  Epoch: 317  Training loss = 3.2579  Validation loss = 3.2084  \n",
      "\n",
      "Fold: 12  Epoch: 318  Training loss = 3.2574  Validation loss = 3.2072  \n",
      "\n",
      "Fold: 12  Epoch: 319  Training loss = 3.2570  Validation loss = 3.2061  \n",
      "\n",
      "Fold: 12  Epoch: 320  Training loss = 3.2566  Validation loss = 3.2052  \n",
      "\n",
      "Fold: 12  Epoch: 321  Training loss = 3.2564  Validation loss = 3.2046  \n",
      "\n",
      "Fold: 12  Epoch: 322  Training loss = 3.2560  Validation loss = 3.2035  \n",
      "\n",
      "Fold: 12  Epoch: 323  Training loss = 3.2557  Validation loss = 3.2027  \n",
      "\n",
      "Fold: 12  Epoch: 324  Training loss = 3.2554  Validation loss = 3.2022  \n",
      "\n",
      "Fold: 12  Epoch: 325  Training loss = 3.2551  Validation loss = 3.2013  \n",
      "\n",
      "Fold: 12  Epoch: 326  Training loss = 3.2546  Validation loss = 3.2000  \n",
      "\n",
      "Fold: 12  Epoch: 327  Training loss = 3.2542  Validation loss = 3.1992  \n",
      "\n",
      "Fold: 12  Epoch: 328  Training loss = 3.2539  Validation loss = 3.1984  \n",
      "\n",
      "Fold: 12  Epoch: 329  Training loss = 3.2534  Validation loss = 3.1971  \n",
      "\n",
      "Fold: 12  Epoch: 330  Training loss = 3.2531  Validation loss = 3.1962  \n",
      "\n",
      "Fold: 12  Epoch: 331  Training loss = 3.2528  Validation loss = 3.1956  \n",
      "\n",
      "Fold: 12  Epoch: 332  Training loss = 3.2524  Validation loss = 3.1945  \n",
      "\n",
      "Fold: 12  Epoch: 333  Training loss = 3.2521  Validation loss = 3.1939  \n",
      "\n",
      "Fold: 12  Epoch: 334  Training loss = 3.2518  Validation loss = 3.1930  \n",
      "\n",
      "Fold: 12  Epoch: 335  Training loss = 3.2514  Validation loss = 3.1920  \n",
      "\n",
      "Fold: 12  Epoch: 336  Training loss = 3.2510  Validation loss = 3.1911  \n",
      "\n",
      "Fold: 12  Epoch: 337  Training loss = 3.2506  Validation loss = 3.1902  \n",
      "\n",
      "Fold: 12  Epoch: 338  Training loss = 3.2503  Validation loss = 3.1892  \n",
      "\n",
      "Fold: 12  Epoch: 339  Training loss = 3.2499  Validation loss = 3.1883  \n",
      "\n",
      "Fold: 12  Epoch: 340  Training loss = 3.2496  Validation loss = 3.1876  \n",
      "\n",
      "Fold: 12  Epoch: 341  Training loss = 3.2492  Validation loss = 3.1865  \n",
      "\n",
      "Fold: 12  Epoch: 342  Training loss = 3.2488  Validation loss = 3.1856  \n",
      "\n",
      "Fold: 12  Epoch: 343  Training loss = 3.2484  Validation loss = 3.1846  \n",
      "\n",
      "Fold: 12  Epoch: 344  Training loss = 3.2482  Validation loss = 3.1840  \n",
      "\n",
      "Fold: 12  Epoch: 345  Training loss = 3.2478  Validation loss = 3.1832  \n",
      "\n",
      "Fold: 12  Epoch: 346  Training loss = 3.2475  Validation loss = 3.1823  \n",
      "\n",
      "Fold: 12  Epoch: 347  Training loss = 3.2471  Validation loss = 3.1815  \n",
      "\n",
      "Fold: 12  Epoch: 348  Training loss = 3.2468  Validation loss = 3.1806  \n",
      "\n",
      "Fold: 12  Epoch: 349  Training loss = 3.2463  Validation loss = 3.1794  \n",
      "\n",
      "Fold: 12  Epoch: 350  Training loss = 3.2461  Validation loss = 3.1788  \n",
      "\n",
      "Fold: 12  Epoch: 351  Training loss = 3.2457  Validation loss = 3.1779  \n",
      "\n",
      "Fold: 12  Epoch: 352  Training loss = 3.2454  Validation loss = 3.1770  \n",
      "\n",
      "Fold: 12  Epoch: 353  Training loss = 3.2449  Validation loss = 3.1759  \n",
      "\n",
      "Fold: 12  Epoch: 354  Training loss = 3.2447  Validation loss = 3.1753  \n",
      "\n",
      "Fold: 12  Epoch: 355  Training loss = 3.2442  Validation loss = 3.1743  \n",
      "\n",
      "Fold: 12  Epoch: 356  Training loss = 3.2437  Validation loss = 3.1731  \n",
      "\n",
      "Fold: 12  Epoch: 357  Training loss = 3.2435  Validation loss = 3.1726  \n",
      "\n",
      "Fold: 12  Epoch: 358  Training loss = 3.2431  Validation loss = 3.1717  \n",
      "\n",
      "Fold: 12  Epoch: 359  Training loss = 3.2428  Validation loss = 3.1711  \n",
      "\n",
      "Fold: 12  Epoch: 360  Training loss = 3.2424  Validation loss = 3.1704  \n",
      "\n",
      "Fold: 12  Epoch: 361  Training loss = 3.2420  Validation loss = 3.1695  \n",
      "\n",
      "Fold: 12  Epoch: 362  Training loss = 3.2418  Validation loss = 3.1689  \n",
      "\n",
      "Fold: 12  Epoch: 363  Training loss = 3.2415  Validation loss = 3.1680  \n",
      "\n",
      "Fold: 12  Epoch: 364  Training loss = 3.2409  Validation loss = 3.1670  \n",
      "\n",
      "Fold: 12  Epoch: 365  Training loss = 3.2404  Validation loss = 3.1660  \n",
      "\n",
      "Fold: 12  Epoch: 366  Training loss = 3.2400  Validation loss = 3.1653  \n",
      "\n",
      "Fold: 12  Epoch: 367  Training loss = 3.2395  Validation loss = 3.1642  \n",
      "\n",
      "Fold: 12  Epoch: 368  Training loss = 3.2391  Validation loss = 3.1631  \n",
      "\n",
      "Fold: 12  Epoch: 369  Training loss = 3.2388  Validation loss = 3.1624  \n",
      "\n",
      "Fold: 12  Epoch: 370  Training loss = 3.2385  Validation loss = 3.1617  \n",
      "\n",
      "Fold: 12  Epoch: 371  Training loss = 3.2381  Validation loss = 3.1608  \n",
      "\n",
      "Fold: 12  Epoch: 372  Training loss = 3.2378  Validation loss = 3.1599  \n",
      "\n",
      "Fold: 12  Epoch: 373  Training loss = 3.2375  Validation loss = 3.1593  \n",
      "\n",
      "Fold: 12  Epoch: 374  Training loss = 3.2372  Validation loss = 3.1585  \n",
      "\n",
      "Fold: 12  Epoch: 375  Training loss = 3.2369  Validation loss = 3.1576  \n",
      "\n",
      "Fold: 12  Epoch: 376  Training loss = 3.2365  Validation loss = 3.1567  \n",
      "\n",
      "Fold: 12  Epoch: 377  Training loss = 3.2361  Validation loss = 3.1558  \n",
      "\n",
      "Fold: 12  Epoch: 378  Training loss = 3.2358  Validation loss = 3.1550  \n",
      "\n",
      "Fold: 12  Epoch: 379  Training loss = 3.2354  Validation loss = 3.1540  \n",
      "\n",
      "Fold: 12  Epoch: 380  Training loss = 3.2351  Validation loss = 3.1533  \n",
      "\n",
      "Fold: 12  Epoch: 381  Training loss = 3.2347  Validation loss = 3.1521  \n",
      "\n",
      "Fold: 12  Epoch: 382  Training loss = 3.2342  Validation loss = 3.1509  \n",
      "\n",
      "Fold: 12  Epoch: 383  Training loss = 3.2338  Validation loss = 3.1499  \n",
      "\n",
      "Fold: 12  Epoch: 384  Training loss = 3.2334  Validation loss = 3.1488  \n",
      "\n",
      "Fold: 12  Epoch: 385  Training loss = 3.2329  Validation loss = 3.1477  \n",
      "\n",
      "Fold: 12  Epoch: 386  Training loss = 3.2325  Validation loss = 3.1466  \n",
      "\n",
      "Fold: 12  Epoch: 387  Training loss = 3.2322  Validation loss = 3.1459  \n",
      "\n",
      "Fold: 12  Epoch: 388  Training loss = 3.2319  Validation loss = 3.1451  \n",
      "\n",
      "Fold: 12  Epoch: 389  Training loss = 3.2316  Validation loss = 3.1442  \n",
      "\n",
      "Fold: 12  Epoch: 390  Training loss = 3.2313  Validation loss = 3.1434  \n",
      "\n",
      "Fold: 12  Epoch: 391  Training loss = 3.2309  Validation loss = 3.1424  \n",
      "\n",
      "Fold: 12  Epoch: 392  Training loss = 3.2306  Validation loss = 3.1416  \n",
      "\n",
      "Fold: 12  Epoch: 393  Training loss = 3.2303  Validation loss = 3.1408  \n",
      "\n",
      "Fold: 12  Epoch: 394  Training loss = 3.2299  Validation loss = 3.1398  \n",
      "\n",
      "Fold: 12  Epoch: 395  Training loss = 3.2296  Validation loss = 3.1390  \n",
      "\n",
      "Fold: 12  Epoch: 396  Training loss = 3.2291  Validation loss = 3.1377  \n",
      "\n",
      "Fold: 12  Epoch: 397  Training loss = 3.2286  Validation loss = 3.1366  \n",
      "\n",
      "Fold: 12  Epoch: 398  Training loss = 3.2284  Validation loss = 3.1359  \n",
      "\n",
      "Fold: 12  Epoch: 399  Training loss = 3.2279  Validation loss = 3.1348  \n",
      "\n",
      "Fold: 12  Epoch: 400  Training loss = 3.2276  Validation loss = 3.1340  \n",
      "\n",
      "Fold: 12  Epoch: 401  Training loss = 3.2274  Validation loss = 3.1333  \n",
      "\n",
      "Fold: 12  Epoch: 402  Training loss = 3.2270  Validation loss = 3.1323  \n",
      "\n",
      "Fold: 12  Epoch: 403  Training loss = 3.2267  Validation loss = 3.1316  \n",
      "\n",
      "Fold: 12  Epoch: 404  Training loss = 3.2264  Validation loss = 3.1309  \n",
      "\n",
      "Fold: 12  Epoch: 405  Training loss = 3.2262  Validation loss = 3.1302  \n",
      "\n",
      "Fold: 12  Epoch: 406  Training loss = 3.2258  Validation loss = 3.1292  \n",
      "\n",
      "Fold: 12  Epoch: 407  Training loss = 3.2253  Validation loss = 3.1279  \n",
      "\n",
      "Fold: 12  Epoch: 408  Training loss = 3.2250  Validation loss = 3.1271  \n",
      "\n",
      "Fold: 12  Epoch: 409  Training loss = 3.2247  Validation loss = 3.1265  \n",
      "\n",
      "Fold: 12  Epoch: 410  Training loss = 3.2243  Validation loss = 3.1253  \n",
      "\n",
      "Fold: 12  Epoch: 411  Training loss = 3.2239  Validation loss = 3.1245  \n",
      "\n",
      "Fold: 12  Epoch: 412  Training loss = 3.2236  Validation loss = 3.1236  \n",
      "\n",
      "Fold: 12  Epoch: 413  Training loss = 3.2232  Validation loss = 3.1226  \n",
      "\n",
      "Fold: 12  Epoch: 414  Training loss = 3.2228  Validation loss = 3.1216  \n",
      "\n",
      "Fold: 12  Epoch: 415  Training loss = 3.2225  Validation loss = 3.1209  \n",
      "\n",
      "Fold: 12  Epoch: 416  Training loss = 3.2222  Validation loss = 3.1200  \n",
      "\n",
      "Fold: 12  Epoch: 417  Training loss = 3.2218  Validation loss = 3.1189  \n",
      "\n",
      "Fold: 12  Epoch: 418  Training loss = 3.2215  Validation loss = 3.1182  \n",
      "\n",
      "Fold: 12  Epoch: 419  Training loss = 3.2212  Validation loss = 3.1174  \n",
      "\n",
      "Fold: 12  Epoch: 420  Training loss = 3.2208  Validation loss = 3.1164  \n",
      "\n",
      "Fold: 12  Epoch: 421  Training loss = 3.2204  Validation loss = 3.1153  \n",
      "\n",
      "Fold: 12  Epoch: 422  Training loss = 3.2200  Validation loss = 3.1143  \n",
      "\n",
      "Fold: 12  Epoch: 423  Training loss = 3.2197  Validation loss = 3.1134  \n",
      "\n",
      "Fold: 12  Epoch: 424  Training loss = 3.2193  Validation loss = 3.1124  \n",
      "\n",
      "Fold: 12  Epoch: 425  Training loss = 3.2188  Validation loss = 3.1113  \n",
      "\n",
      "Fold: 12  Epoch: 426  Training loss = 3.2185  Validation loss = 3.1102  \n",
      "\n",
      "Fold: 12  Epoch: 427  Training loss = 3.2181  Validation loss = 3.1093  \n",
      "\n",
      "Fold: 12  Epoch: 428  Training loss = 3.2177  Validation loss = 3.1083  \n",
      "\n",
      "Fold: 12  Epoch: 429  Training loss = 3.2174  Validation loss = 3.1075  \n",
      "\n",
      "Fold: 12  Epoch: 430  Training loss = 3.2170  Validation loss = 3.1064  \n",
      "\n",
      "Fold: 12  Epoch: 431  Training loss = 3.2165  Validation loss = 3.1053  \n",
      "\n",
      "Fold: 12  Epoch: 432  Training loss = 3.2163  Validation loss = 3.1046  \n",
      "\n",
      "Fold: 12  Epoch: 433  Training loss = 3.2158  Validation loss = 3.1035  \n",
      "\n",
      "Fold: 12  Epoch: 434  Training loss = 3.2154  Validation loss = 3.1024  \n",
      "\n",
      "Fold: 12  Epoch: 435  Training loss = 3.2150  Validation loss = 3.1014  \n",
      "\n",
      "Fold: 12  Epoch: 436  Training loss = 3.2145  Validation loss = 3.1001  \n",
      "\n",
      "Fold: 12  Epoch: 437  Training loss = 3.2142  Validation loss = 3.0995  \n",
      "\n",
      "Fold: 12  Epoch: 438  Training loss = 3.2139  Validation loss = 3.0987  \n",
      "\n",
      "Fold: 12  Epoch: 439  Training loss = 3.2136  Validation loss = 3.0981  \n",
      "\n",
      "Fold: 12  Epoch: 440  Training loss = 3.2132  Validation loss = 3.0971  \n",
      "\n",
      "Fold: 12  Epoch: 441  Training loss = 3.2129  Validation loss = 3.0963  \n",
      "\n",
      "Fold: 12  Epoch: 442  Training loss = 3.2125  Validation loss = 3.0953  \n",
      "\n",
      "Fold: 12  Epoch: 443  Training loss = 3.2120  Validation loss = 3.0942  \n",
      "\n",
      "Fold: 12  Epoch: 444  Training loss = 3.2117  Validation loss = 3.0933  \n",
      "\n",
      "Fold: 12  Epoch: 445  Training loss = 3.2113  Validation loss = 3.0923  \n",
      "\n",
      "Fold: 12  Epoch: 446  Training loss = 3.2109  Validation loss = 3.0913  \n",
      "\n",
      "Fold: 12  Epoch: 447  Training loss = 3.2106  Validation loss = 3.0905  \n",
      "\n",
      "Fold: 12  Epoch: 448  Training loss = 3.2102  Validation loss = 3.0894  \n",
      "\n",
      "Fold: 12  Epoch: 449  Training loss = 3.2099  Validation loss = 3.0887  \n",
      "\n",
      "Fold: 12  Epoch: 450  Training loss = 3.2095  Validation loss = 3.0878  \n",
      "\n",
      "Fold: 12  Epoch: 451  Training loss = 3.2091  Validation loss = 3.0868  \n",
      "\n",
      "Fold: 12  Epoch: 452  Training loss = 3.2088  Validation loss = 3.0859  \n",
      "\n",
      "Fold: 12  Epoch: 453  Training loss = 3.2085  Validation loss = 3.0852  \n",
      "\n",
      "Fold: 12  Epoch: 454  Training loss = 3.2083  Validation loss = 3.0846  \n",
      "\n",
      "Fold: 12  Epoch: 455  Training loss = 3.2080  Validation loss = 3.0839  \n",
      "\n",
      "Fold: 12  Epoch: 456  Training loss = 3.2077  Validation loss = 3.0831  \n",
      "\n",
      "Fold: 12  Epoch: 457  Training loss = 3.2075  Validation loss = 3.0825  \n",
      "\n",
      "Fold: 12  Epoch: 458  Training loss = 3.2070  Validation loss = 3.0813  \n",
      "\n",
      "Fold: 12  Epoch: 459  Training loss = 3.2068  Validation loss = 3.0806  \n",
      "\n",
      "Fold: 12  Epoch: 460  Training loss = 3.2063  Validation loss = 3.0795  \n",
      "\n",
      "Fold: 12  Epoch: 461  Training loss = 3.2060  Validation loss = 3.0787  \n",
      "\n",
      "Fold: 12  Epoch: 462  Training loss = 3.2056  Validation loss = 3.0776  \n",
      "\n",
      "Fold: 12  Epoch: 463  Training loss = 3.2053  Validation loss = 3.0766  \n",
      "\n",
      "Fold: 12  Epoch: 464  Training loss = 3.2048  Validation loss = 3.0755  \n",
      "\n",
      "Fold: 12  Epoch: 465  Training loss = 3.2045  Validation loss = 3.0747  \n",
      "\n",
      "Fold: 12  Epoch: 466  Training loss = 3.2044  Validation loss = 3.0744  \n",
      "\n",
      "Fold: 12  Epoch: 467  Training loss = 3.2041  Validation loss = 3.0736  \n",
      "\n",
      "Fold: 12  Epoch: 468  Training loss = 3.2038  Validation loss = 3.0729  \n",
      "\n",
      "Fold: 12  Epoch: 469  Training loss = 3.2035  Validation loss = 3.0721  \n",
      "\n",
      "Fold: 12  Epoch: 470  Training loss = 3.2032  Validation loss = 3.0712  \n",
      "\n",
      "Fold: 12  Epoch: 471  Training loss = 3.2028  Validation loss = 3.0701  \n",
      "\n",
      "Fold: 12  Epoch: 472  Training loss = 3.2023  Validation loss = 3.0688  \n",
      "\n",
      "Fold: 12  Epoch: 473  Training loss = 3.2020  Validation loss = 3.0680  \n",
      "\n",
      "Fold: 12  Epoch: 474  Training loss = 3.2016  Validation loss = 3.0671  \n",
      "\n",
      "Fold: 12  Epoch: 475  Training loss = 3.2013  Validation loss = 3.0663  \n",
      "\n",
      "Fold: 12  Epoch: 476  Training loss = 3.2009  Validation loss = 3.0651  \n",
      "\n",
      "Fold: 12  Epoch: 477  Training loss = 3.2004  Validation loss = 3.0639  \n",
      "\n",
      "Fold: 12  Epoch: 478  Training loss = 3.2001  Validation loss = 3.0631  \n",
      "\n",
      "Fold: 12  Epoch: 479  Training loss = 3.1998  Validation loss = 3.0623  \n",
      "\n",
      "Fold: 12  Epoch: 480  Training loss = 3.1994  Validation loss = 3.0614  \n",
      "\n",
      "Fold: 12  Epoch: 481  Training loss = 3.1991  Validation loss = 3.0605  \n",
      "\n",
      "Fold: 12  Epoch: 482  Training loss = 3.1989  Validation loss = 3.0598  \n",
      "\n",
      "Fold: 12  Epoch: 483  Training loss = 3.1985  Validation loss = 3.0588  \n",
      "\n",
      "Fold: 12  Epoch: 484  Training loss = 3.1982  Validation loss = 3.0581  \n",
      "\n",
      "Fold: 12  Epoch: 485  Training loss = 3.1980  Validation loss = 3.0575  \n",
      "\n",
      "Fold: 12  Epoch: 486  Training loss = 3.1977  Validation loss = 3.0567  \n",
      "\n",
      "Fold: 12  Epoch: 487  Training loss = 3.1974  Validation loss = 3.0559  \n",
      "\n",
      "Fold: 12  Epoch: 488  Training loss = 3.1969  Validation loss = 3.0548  \n",
      "\n",
      "Fold: 12  Epoch: 489  Training loss = 3.1964  Validation loss = 3.0534  \n",
      "\n",
      "Fold: 12  Epoch: 490  Training loss = 3.1961  Validation loss = 3.0525  \n",
      "\n",
      "Fold: 12  Epoch: 491  Training loss = 3.1958  Validation loss = 3.0517  \n",
      "\n",
      "Fold: 12  Epoch: 492  Training loss = 3.1956  Validation loss = 3.0512  \n",
      "\n",
      "Fold: 12  Epoch: 493  Training loss = 3.1952  Validation loss = 3.0502  \n",
      "\n",
      "Fold: 12  Epoch: 494  Training loss = 3.1949  Validation loss = 3.0494  \n",
      "\n",
      "Fold: 12  Epoch: 495  Training loss = 3.1947  Validation loss = 3.0489  \n",
      "\n",
      "Fold: 12  Epoch: 496  Training loss = 3.1943  Validation loss = 3.0477  \n",
      "\n",
      "Fold: 12  Epoch: 497  Training loss = 3.1940  Validation loss = 3.0470  \n",
      "\n",
      "Fold: 12  Epoch: 498  Training loss = 3.1938  Validation loss = 3.0463  \n",
      "\n",
      "Fold: 12  Epoch: 499  Training loss = 3.1934  Validation loss = 3.0454  \n",
      "\n",
      "Fold: 12  Epoch: 500  Training loss = 3.1930  Validation loss = 3.0443  \n",
      "\n",
      "Check model:  Fold: 12  Optimal epoch: 500  \n",
      "\n",
      "Fold: 13  Epoch: 1  Training loss = 3.2449  Validation loss = 5.4149  \n",
      "\n",
      "Fold: 13  Epoch: 2  Training loss = 3.2444  Validation loss = 5.4136  \n",
      "\n",
      "Fold: 13  Epoch: 3  Training loss = 3.2438  Validation loss = 5.4121  \n",
      "\n",
      "Fold: 13  Epoch: 4  Training loss = 3.2434  Validation loss = 5.4112  \n",
      "\n",
      "Fold: 13  Epoch: 5  Training loss = 3.2428  Validation loss = 5.4097  \n",
      "\n",
      "Fold: 13  Epoch: 6  Training loss = 3.2423  Validation loss = 5.4083  \n",
      "\n",
      "Fold: 13  Epoch: 7  Training loss = 3.2418  Validation loss = 5.4071  \n",
      "\n",
      "Fold: 13  Epoch: 8  Training loss = 3.2415  Validation loss = 5.4063  \n",
      "\n",
      "Fold: 13  Epoch: 9  Training loss = 3.2411  Validation loss = 5.4052  \n",
      "\n",
      "Fold: 13  Epoch: 10  Training loss = 3.2406  Validation loss = 5.4040  \n",
      "\n",
      "Fold: 13  Epoch: 11  Training loss = 3.2397  Validation loss = 5.4019  \n",
      "\n",
      "Fold: 13  Epoch: 12  Training loss = 3.2393  Validation loss = 5.4010  \n",
      "\n",
      "Fold: 13  Epoch: 13  Training loss = 3.2387  Validation loss = 5.3994  \n",
      "\n",
      "Fold: 13  Epoch: 14  Training loss = 3.2382  Validation loss = 5.3983  \n",
      "\n",
      "Fold: 13  Epoch: 15  Training loss = 3.2378  Validation loss = 5.3972  \n",
      "\n",
      "Fold: 13  Epoch: 16  Training loss = 3.2373  Validation loss = 5.3958  \n",
      "\n",
      "Fold: 13  Epoch: 17  Training loss = 3.2367  Validation loss = 5.3942  \n",
      "\n",
      "Fold: 13  Epoch: 18  Training loss = 3.2361  Validation loss = 5.3928  \n",
      "\n",
      "Fold: 13  Epoch: 19  Training loss = 3.2357  Validation loss = 5.3918  \n",
      "\n",
      "Fold: 13  Epoch: 20  Training loss = 3.2352  Validation loss = 5.3904  \n",
      "\n",
      "Fold: 13  Epoch: 21  Training loss = 3.2348  Validation loss = 5.3895  \n",
      "\n",
      "Fold: 13  Epoch: 22  Training loss = 3.2343  Validation loss = 5.3884  \n",
      "\n",
      "Fold: 13  Epoch: 23  Training loss = 3.2340  Validation loss = 5.3875  \n",
      "\n",
      "Fold: 13  Epoch: 24  Training loss = 3.2334  Validation loss = 5.3859  \n",
      "\n",
      "Fold: 13  Epoch: 25  Training loss = 3.2330  Validation loss = 5.3848  \n",
      "\n",
      "Fold: 13  Epoch: 26  Training loss = 3.2326  Validation loss = 5.3838  \n",
      "\n",
      "Fold: 13  Epoch: 27  Training loss = 3.2320  Validation loss = 5.3825  \n",
      "\n",
      "Fold: 13  Epoch: 28  Training loss = 3.2316  Validation loss = 5.3814  \n",
      "\n",
      "Fold: 13  Epoch: 29  Training loss = 3.2312  Validation loss = 5.3805  \n",
      "\n",
      "Fold: 13  Epoch: 30  Training loss = 3.2307  Validation loss = 5.3793  \n",
      "\n",
      "Fold: 13  Epoch: 31  Training loss = 3.2303  Validation loss = 5.3782  \n",
      "\n",
      "Fold: 13  Epoch: 32  Training loss = 3.2298  Validation loss = 5.3771  \n",
      "\n",
      "Fold: 13  Epoch: 33  Training loss = 3.2292  Validation loss = 5.3756  \n",
      "\n",
      "Fold: 13  Epoch: 34  Training loss = 3.2286  Validation loss = 5.3742  \n",
      "\n",
      "Fold: 13  Epoch: 35  Training loss = 3.2282  Validation loss = 5.3731  \n",
      "\n",
      "Fold: 13  Epoch: 36  Training loss = 3.2276  Validation loss = 5.3716  \n",
      "\n",
      "Fold: 13  Epoch: 37  Training loss = 3.2271  Validation loss = 5.3703  \n",
      "\n",
      "Fold: 13  Epoch: 38  Training loss = 3.2265  Validation loss = 5.3691  \n",
      "\n",
      "Fold: 13  Epoch: 39  Training loss = 3.2261  Validation loss = 5.3681  \n",
      "\n",
      "Fold: 13  Epoch: 40  Training loss = 3.2248  Validation loss = 5.3669  \n",
      "\n",
      "Fold: 13  Epoch: 41  Training loss = 3.2218  Validation loss = 5.3659  \n",
      "\n",
      "Fold: 13  Epoch: 42  Training loss = 3.2172  Validation loss = 5.3645  \n",
      "\n",
      "Fold: 13  Epoch: 43  Training loss = 3.2169  Validation loss = 5.3635  \n",
      "\n",
      "Fold: 13  Epoch: 44  Training loss = 3.2164  Validation loss = 5.3624  \n",
      "\n",
      "Fold: 13  Epoch: 45  Training loss = 3.2160  Validation loss = 5.3612  \n",
      "\n",
      "Fold: 13  Epoch: 46  Training loss = 3.2157  Validation loss = 5.3605  \n",
      "\n",
      "Fold: 13  Epoch: 47  Training loss = 3.2153  Validation loss = 5.3595  \n",
      "\n",
      "Fold: 13  Epoch: 48  Training loss = 3.2149  Validation loss = 5.3584  \n",
      "\n",
      "Fold: 13  Epoch: 49  Training loss = 3.2145  Validation loss = 5.3574  \n",
      "\n",
      "Fold: 13  Epoch: 50  Training loss = 3.2141  Validation loss = 5.3566  \n",
      "\n",
      "Fold: 13  Epoch: 51  Training loss = 3.2135  Validation loss = 5.3549  \n",
      "\n",
      "Fold: 13  Epoch: 52  Training loss = 3.2129  Validation loss = 5.3534  \n",
      "\n",
      "Fold: 13  Epoch: 53  Training loss = 3.2125  Validation loss = 5.3524  \n",
      "\n",
      "Fold: 13  Epoch: 54  Training loss = 3.2121  Validation loss = 5.3514  \n",
      "\n",
      "Fold: 13  Epoch: 55  Training loss = 3.2117  Validation loss = 5.3502  \n",
      "\n",
      "Fold: 13  Epoch: 56  Training loss = 3.2113  Validation loss = 5.3493  \n",
      "\n",
      "Fold: 13  Epoch: 57  Training loss = 3.2110  Validation loss = 5.3486  \n",
      "\n",
      "Fold: 13  Epoch: 58  Training loss = 3.2103  Validation loss = 5.3469  \n",
      "\n",
      "Fold: 13  Epoch: 59  Training loss = 3.2100  Validation loss = 5.3460  \n",
      "\n",
      "Fold: 13  Epoch: 60  Training loss = 3.2097  Validation loss = 5.3450  \n",
      "\n",
      "Fold: 13  Epoch: 61  Training loss = 3.2092  Validation loss = 5.3438  \n",
      "\n",
      "Fold: 13  Epoch: 62  Training loss = 3.2088  Validation loss = 5.3428  \n",
      "\n",
      "Fold: 13  Epoch: 63  Training loss = 3.2083  Validation loss = 5.3415  \n",
      "\n",
      "Fold: 13  Epoch: 64  Training loss = 3.2079  Validation loss = 5.3405  \n",
      "\n",
      "Fold: 13  Epoch: 65  Training loss = 3.2075  Validation loss = 5.3393  \n",
      "\n",
      "Fold: 13  Epoch: 66  Training loss = 3.2069  Validation loss = 5.3379  \n",
      "\n",
      "Fold: 13  Epoch: 67  Training loss = 3.2064  Validation loss = 5.3367  \n",
      "\n",
      "Fold: 13  Epoch: 68  Training loss = 3.2059  Validation loss = 5.3354  \n",
      "\n",
      "Fold: 13  Epoch: 69  Training loss = 3.2054  Validation loss = 5.3341  \n",
      "\n",
      "Fold: 13  Epoch: 70  Training loss = 3.2049  Validation loss = 5.3329  \n",
      "\n",
      "Fold: 13  Epoch: 71  Training loss = 3.2044  Validation loss = 5.3316  \n",
      "\n",
      "Fold: 13  Epoch: 72  Training loss = 3.2041  Validation loss = 5.3308  \n",
      "\n",
      "Fold: 13  Epoch: 73  Training loss = 3.2037  Validation loss = 5.3299  \n",
      "\n",
      "Fold: 13  Epoch: 74  Training loss = 3.2031  Validation loss = 5.3286  \n",
      "\n",
      "Fold: 13  Epoch: 75  Training loss = 3.2027  Validation loss = 5.3273  \n",
      "\n",
      "Fold: 13  Epoch: 76  Training loss = 3.2023  Validation loss = 5.3262  \n",
      "\n",
      "Fold: 13  Epoch: 77  Training loss = 3.2018  Validation loss = 5.3250  \n",
      "\n",
      "Fold: 13  Epoch: 78  Training loss = 3.2014  Validation loss = 5.3239  \n",
      "\n",
      "Fold: 13  Epoch: 79  Training loss = 3.2010  Validation loss = 5.3229  \n",
      "\n",
      "Fold: 13  Epoch: 80  Training loss = 3.2006  Validation loss = 5.3217  \n",
      "\n",
      "Fold: 13  Epoch: 81  Training loss = 3.2000  Validation loss = 5.3203  \n",
      "\n",
      "Fold: 13  Epoch: 82  Training loss = 3.1996  Validation loss = 5.3191  \n",
      "\n",
      "Fold: 13  Epoch: 83  Training loss = 3.1991  Validation loss = 5.3179  \n",
      "\n",
      "Fold: 13  Epoch: 84  Training loss = 3.1988  Validation loss = 5.3171  \n",
      "\n",
      "Fold: 13  Epoch: 85  Training loss = 3.1983  Validation loss = 5.3156  \n",
      "\n",
      "Fold: 13  Epoch: 86  Training loss = 3.1979  Validation loss = 5.3147  \n",
      "\n",
      "Fold: 13  Epoch: 87  Training loss = 3.1974  Validation loss = 5.3134  \n",
      "\n",
      "Fold: 13  Epoch: 88  Training loss = 3.1970  Validation loss = 5.3124  \n",
      "\n",
      "Fold: 13  Epoch: 89  Training loss = 3.1966  Validation loss = 5.3112  \n",
      "\n",
      "Fold: 13  Epoch: 90  Training loss = 3.1961  Validation loss = 5.3101  \n",
      "\n",
      "Fold: 13  Epoch: 91  Training loss = 3.1958  Validation loss = 5.3092  \n",
      "\n",
      "Fold: 13  Epoch: 92  Training loss = 3.1953  Validation loss = 5.3080  \n",
      "\n",
      "Fold: 13  Epoch: 93  Training loss = 3.1948  Validation loss = 5.3065  \n",
      "\n",
      "Fold: 13  Epoch: 94  Training loss = 3.1942  Validation loss = 5.3051  \n",
      "\n",
      "Fold: 13  Epoch: 95  Training loss = 3.1939  Validation loss = 5.3042  \n",
      "\n",
      "Fold: 13  Epoch: 96  Training loss = 3.1934  Validation loss = 5.3028  \n",
      "\n",
      "Fold: 13  Epoch: 97  Training loss = 3.1929  Validation loss = 5.3017  \n",
      "\n",
      "Fold: 13  Epoch: 98  Training loss = 3.1925  Validation loss = 5.3005  \n",
      "\n",
      "Fold: 13  Epoch: 99  Training loss = 3.1921  Validation loss = 5.2995  \n",
      "\n",
      "Fold: 13  Epoch: 100  Training loss = 3.1917  Validation loss = 5.2984  \n",
      "\n",
      "Fold: 13  Epoch: 101  Training loss = 3.1911  Validation loss = 5.2970  \n",
      "\n",
      "Fold: 13  Epoch: 102  Training loss = 3.1906  Validation loss = 5.2957  \n",
      "\n",
      "Fold: 13  Epoch: 103  Training loss = 3.1902  Validation loss = 5.2948  \n",
      "\n",
      "Fold: 13  Epoch: 104  Training loss = 3.1897  Validation loss = 5.2934  \n",
      "\n",
      "Fold: 13  Epoch: 105  Training loss = 3.1892  Validation loss = 5.2922  \n",
      "\n",
      "Fold: 13  Epoch: 106  Training loss = 3.1889  Validation loss = 5.2914  \n",
      "\n",
      "Fold: 13  Epoch: 107  Training loss = 3.1883  Validation loss = 5.2899  \n",
      "\n",
      "Fold: 13  Epoch: 108  Training loss = 3.1879  Validation loss = 5.2889  \n",
      "\n",
      "Fold: 13  Epoch: 109  Training loss = 3.1875  Validation loss = 5.2880  \n",
      "\n",
      "Fold: 13  Epoch: 110  Training loss = 3.1871  Validation loss = 5.2869  \n",
      "\n",
      "Fold: 13  Epoch: 111  Training loss = 3.1866  Validation loss = 5.2856  \n",
      "\n",
      "Fold: 13  Epoch: 112  Training loss = 3.1861  Validation loss = 5.2845  \n",
      "\n",
      "Fold: 13  Epoch: 113  Training loss = 3.1857  Validation loss = 5.2833  \n",
      "\n",
      "Fold: 13  Epoch: 114  Training loss = 3.1854  Validation loss = 5.2826  \n",
      "\n",
      "Fold: 13  Epoch: 115  Training loss = 3.1851  Validation loss = 5.2819  \n",
      "\n",
      "Fold: 13  Epoch: 116  Training loss = 3.1847  Validation loss = 5.2808  \n",
      "\n",
      "Fold: 13  Epoch: 117  Training loss = 3.1842  Validation loss = 5.2795  \n",
      "\n",
      "Fold: 13  Epoch: 118  Training loss = 3.1839  Validation loss = 5.2787  \n",
      "\n",
      "Fold: 13  Epoch: 119  Training loss = 3.1836  Validation loss = 5.2778  \n",
      "\n",
      "Fold: 13  Epoch: 120  Training loss = 3.1833  Validation loss = 5.2772  \n",
      "\n",
      "Fold: 13  Epoch: 121  Training loss = 3.1826  Validation loss = 5.2754  \n",
      "\n",
      "Fold: 13  Epoch: 122  Training loss = 3.1823  Validation loss = 5.2746  \n",
      "\n",
      "Fold: 13  Epoch: 123  Training loss = 3.1819  Validation loss = 5.2734  \n",
      "\n",
      "Fold: 13  Epoch: 124  Training loss = 3.1815  Validation loss = 5.2723  \n",
      "\n",
      "Fold: 13  Epoch: 125  Training loss = 3.1811  Validation loss = 5.2714  \n",
      "\n",
      "Fold: 13  Epoch: 126  Training loss = 3.1808  Validation loss = 5.2707  \n",
      "\n",
      "Fold: 13  Epoch: 127  Training loss = 3.1803  Validation loss = 5.2693  \n",
      "\n",
      "Fold: 13  Epoch: 128  Training loss = 3.1800  Validation loss = 5.2685  \n",
      "\n",
      "Fold: 13  Epoch: 129  Training loss = 3.1795  Validation loss = 5.2672  \n",
      "\n",
      "Fold: 13  Epoch: 130  Training loss = 3.1790  Validation loss = 5.2658  \n",
      "\n",
      "Fold: 13  Epoch: 131  Training loss = 3.1786  Validation loss = 5.2648  \n",
      "\n",
      "Fold: 13  Epoch: 132  Training loss = 3.1780  Validation loss = 5.2634  \n",
      "\n",
      "Fold: 13  Epoch: 133  Training loss = 3.1777  Validation loss = 5.2626  \n",
      "\n",
      "Fold: 13  Epoch: 134  Training loss = 3.1774  Validation loss = 5.2616  \n",
      "\n",
      "Fold: 13  Epoch: 135  Training loss = 3.1769  Validation loss = 5.2602  \n",
      "\n",
      "Fold: 13  Epoch: 136  Training loss = 3.1766  Validation loss = 5.2596  \n",
      "\n",
      "Fold: 13  Epoch: 137  Training loss = 3.1761  Validation loss = 5.2580  \n",
      "\n",
      "Fold: 13  Epoch: 138  Training loss = 3.1757  Validation loss = 5.2570  \n",
      "\n",
      "Fold: 13  Epoch: 139  Training loss = 3.1752  Validation loss = 5.2560  \n",
      "\n",
      "Fold: 13  Epoch: 140  Training loss = 3.1748  Validation loss = 5.2548  \n",
      "\n",
      "Fold: 13  Epoch: 141  Training loss = 3.1743  Validation loss = 5.2535  \n",
      "\n",
      "Fold: 13  Epoch: 142  Training loss = 3.1740  Validation loss = 5.2525  \n",
      "\n",
      "Fold: 13  Epoch: 143  Training loss = 3.1736  Validation loss = 5.2515  \n",
      "\n",
      "Fold: 13  Epoch: 144  Training loss = 3.1731  Validation loss = 5.2502  \n",
      "\n",
      "Fold: 13  Epoch: 145  Training loss = 3.1728  Validation loss = 5.2494  \n",
      "\n",
      "Fold: 13  Epoch: 146  Training loss = 3.1725  Validation loss = 5.2486  \n",
      "\n",
      "Fold: 13  Epoch: 147  Training loss = 3.1721  Validation loss = 5.2476  \n",
      "\n",
      "Fold: 13  Epoch: 148  Training loss = 3.1718  Validation loss = 5.2469  \n",
      "\n",
      "Fold: 13  Epoch: 149  Training loss = 3.1714  Validation loss = 5.2460  \n",
      "\n",
      "Fold: 13  Epoch: 150  Training loss = 3.1710  Validation loss = 5.2449  \n",
      "\n",
      "Fold: 13  Epoch: 151  Training loss = 3.1706  Validation loss = 5.2439  \n",
      "\n",
      "Fold: 13  Epoch: 152  Training loss = 3.1702  Validation loss = 5.2429  \n",
      "\n",
      "Fold: 13  Epoch: 153  Training loss = 3.1699  Validation loss = 5.2422  \n",
      "\n",
      "Fold: 13  Epoch: 154  Training loss = 3.1696  Validation loss = 5.2412  \n",
      "\n",
      "Fold: 13  Epoch: 155  Training loss = 3.1689  Validation loss = 5.2396  \n",
      "\n",
      "Fold: 13  Epoch: 156  Training loss = 3.1685  Validation loss = 5.2385  \n",
      "\n",
      "Fold: 13  Epoch: 157  Training loss = 3.1682  Validation loss = 5.2377  \n",
      "\n",
      "Fold: 13  Epoch: 158  Training loss = 3.1677  Validation loss = 5.2366  \n",
      "\n",
      "Fold: 13  Epoch: 159  Training loss = 3.1675  Validation loss = 5.2358  \n",
      "\n",
      "Fold: 13  Epoch: 160  Training loss = 3.1671  Validation loss = 5.2348  \n",
      "\n",
      "Fold: 13  Epoch: 161  Training loss = 3.1668  Validation loss = 5.2340  \n",
      "\n",
      "Fold: 13  Epoch: 162  Training loss = 3.1662  Validation loss = 5.2326  \n",
      "\n",
      "Fold: 13  Epoch: 163  Training loss = 3.1657  Validation loss = 5.2312  \n",
      "\n",
      "Fold: 13  Epoch: 164  Training loss = 3.1652  Validation loss = 5.2301  \n",
      "\n",
      "Fold: 13  Epoch: 165  Training loss = 3.1649  Validation loss = 5.2292  \n",
      "\n",
      "Fold: 13  Epoch: 166  Training loss = 3.1646  Validation loss = 5.2284  \n",
      "\n",
      "Fold: 13  Epoch: 167  Training loss = 3.1643  Validation loss = 5.2276  \n",
      "\n",
      "Fold: 13  Epoch: 168  Training loss = 3.1640  Validation loss = 5.2268  \n",
      "\n",
      "Fold: 13  Epoch: 169  Training loss = 3.1637  Validation loss = 5.2261  \n",
      "\n",
      "Fold: 13  Epoch: 170  Training loss = 3.1633  Validation loss = 5.2251  \n",
      "\n",
      "Fold: 13  Epoch: 171  Training loss = 3.1629  Validation loss = 5.2241  \n",
      "\n",
      "Fold: 13  Epoch: 172  Training loss = 3.1625  Validation loss = 5.2230  \n",
      "\n",
      "Fold: 13  Epoch: 173  Training loss = 3.1621  Validation loss = 5.2222  \n",
      "\n",
      "Fold: 13  Epoch: 174  Training loss = 3.1617  Validation loss = 5.2211  \n",
      "\n",
      "Fold: 13  Epoch: 175  Training loss = 3.1614  Validation loss = 5.2202  \n",
      "\n",
      "Fold: 13  Epoch: 176  Training loss = 3.1609  Validation loss = 5.2190  \n",
      "\n",
      "Fold: 13  Epoch: 177  Training loss = 3.1605  Validation loss = 5.2180  \n",
      "\n",
      "Fold: 13  Epoch: 178  Training loss = 3.1602  Validation loss = 5.2170  \n",
      "\n",
      "Fold: 13  Epoch: 179  Training loss = 3.1598  Validation loss = 5.2160  \n",
      "\n",
      "Fold: 13  Epoch: 180  Training loss = 3.1593  Validation loss = 5.2147  \n",
      "\n",
      "Fold: 13  Epoch: 181  Training loss = 3.1588  Validation loss = 5.2134  \n",
      "\n",
      "Fold: 13  Epoch: 182  Training loss = 3.1584  Validation loss = 5.2124  \n",
      "\n",
      "Fold: 13  Epoch: 183  Training loss = 3.1581  Validation loss = 5.2116  \n",
      "\n",
      "Fold: 13  Epoch: 184  Training loss = 3.1576  Validation loss = 5.2103  \n",
      "\n",
      "Fold: 13  Epoch: 185  Training loss = 3.1573  Validation loss = 5.2094  \n",
      "\n",
      "Fold: 13  Epoch: 186  Training loss = 3.1569  Validation loss = 5.2085  \n",
      "\n",
      "Fold: 13  Epoch: 187  Training loss = 3.1566  Validation loss = 5.2076  \n",
      "\n",
      "Fold: 13  Epoch: 188  Training loss = 3.1563  Validation loss = 5.2069  \n",
      "\n",
      "Fold: 13  Epoch: 189  Training loss = 3.1559  Validation loss = 5.2058  \n",
      "\n",
      "Fold: 13  Epoch: 190  Training loss = 3.1555  Validation loss = 5.2046  \n",
      "\n",
      "Fold: 13  Epoch: 191  Training loss = 3.1551  Validation loss = 5.2038  \n",
      "\n",
      "Fold: 13  Epoch: 192  Training loss = 3.1547  Validation loss = 5.2027  \n",
      "\n",
      "Fold: 13  Epoch: 193  Training loss = 3.1543  Validation loss = 5.2017  \n",
      "\n",
      "Fold: 13  Epoch: 194  Training loss = 3.1539  Validation loss = 5.2008  \n",
      "\n",
      "Fold: 13  Epoch: 195  Training loss = 3.1535  Validation loss = 5.1996  \n",
      "\n",
      "Fold: 13  Epoch: 196  Training loss = 3.1531  Validation loss = 5.1988  \n",
      "\n",
      "Fold: 13  Epoch: 197  Training loss = 3.1529  Validation loss = 5.1980  \n",
      "\n",
      "Fold: 13  Epoch: 198  Training loss = 3.1525  Validation loss = 5.1971  \n",
      "\n",
      "Fold: 13  Epoch: 199  Training loss = 3.1519  Validation loss = 5.1957  \n",
      "\n",
      "Fold: 13  Epoch: 200  Training loss = 3.1515  Validation loss = 5.1945  \n",
      "\n",
      "Fold: 13  Epoch: 201  Training loss = 3.1510  Validation loss = 5.1931  \n",
      "\n",
      "Fold: 13  Epoch: 202  Training loss = 3.1504  Validation loss = 5.1916  \n",
      "\n",
      "Fold: 13  Epoch: 203  Training loss = 3.1499  Validation loss = 5.1901  \n",
      "\n",
      "Fold: 13  Epoch: 204  Training loss = 3.1495  Validation loss = 5.1890  \n",
      "\n",
      "Fold: 13  Epoch: 205  Training loss = 3.1490  Validation loss = 5.1878  \n",
      "\n",
      "Fold: 13  Epoch: 206  Training loss = 3.1486  Validation loss = 5.1868  \n",
      "\n",
      "Fold: 13  Epoch: 207  Training loss = 3.1482  Validation loss = 5.1855  \n",
      "\n",
      "Fold: 13  Epoch: 208  Training loss = 3.1478  Validation loss = 5.1845  \n",
      "\n",
      "Fold: 13  Epoch: 209  Training loss = 3.1474  Validation loss = 5.1836  \n",
      "\n",
      "Fold: 13  Epoch: 210  Training loss = 3.1470  Validation loss = 5.1825  \n",
      "\n",
      "Fold: 13  Epoch: 211  Training loss = 3.1465  Validation loss = 5.1813  \n",
      "\n",
      "Fold: 13  Epoch: 212  Training loss = 3.1462  Validation loss = 5.1804  \n",
      "\n",
      "Fold: 13  Epoch: 213  Training loss = 3.1457  Validation loss = 5.1791  \n",
      "\n",
      "Fold: 13  Epoch: 214  Training loss = 3.1453  Validation loss = 5.1779  \n",
      "\n",
      "Fold: 13  Epoch: 215  Training loss = 3.1449  Validation loss = 5.1769  \n",
      "\n",
      "Fold: 13  Epoch: 216  Training loss = 3.1443  Validation loss = 5.1755  \n",
      "\n",
      "Fold: 13  Epoch: 217  Training loss = 3.1439  Validation loss = 5.1744  \n",
      "\n",
      "Fold: 13  Epoch: 218  Training loss = 3.1433  Validation loss = 5.1730  \n",
      "\n",
      "Fold: 13  Epoch: 219  Training loss = 3.1430  Validation loss = 5.1722  \n",
      "\n",
      "Fold: 13  Epoch: 220  Training loss = 3.1426  Validation loss = 5.1713  \n",
      "\n",
      "Fold: 13  Epoch: 221  Training loss = 3.1422  Validation loss = 5.1702  \n",
      "\n",
      "Fold: 13  Epoch: 222  Training loss = 3.1416  Validation loss = 5.1688  \n",
      "\n",
      "Fold: 13  Epoch: 223  Training loss = 3.1412  Validation loss = 5.1680  \n",
      "\n",
      "Fold: 13  Epoch: 224  Training loss = 3.1407  Validation loss = 5.1667  \n",
      "\n",
      "Fold: 13  Epoch: 225  Training loss = 3.1404  Validation loss = 5.1659  \n",
      "\n",
      "Fold: 13  Epoch: 226  Training loss = 3.1398  Validation loss = 5.1647  \n",
      "\n",
      "Fold: 13  Epoch: 227  Training loss = 3.1393  Validation loss = 5.1635  \n",
      "\n",
      "Fold: 13  Epoch: 228  Training loss = 3.1390  Validation loss = 5.1627  \n",
      "\n",
      "Fold: 13  Epoch: 229  Training loss = 3.1383  Validation loss = 5.1615  \n",
      "\n",
      "Fold: 13  Epoch: 230  Training loss = 3.1366  Validation loss = 5.1600  \n",
      "\n",
      "Fold: 13  Epoch: 231  Training loss = 3.1351  Validation loss = 5.1588  \n",
      "\n",
      "Fold: 13  Epoch: 232  Training loss = 3.1348  Validation loss = 5.1580  \n",
      "\n",
      "Fold: 13  Epoch: 233  Training loss = 3.1343  Validation loss = 5.1568  \n",
      "\n",
      "Fold: 13  Epoch: 234  Training loss = 3.1339  Validation loss = 5.1558  \n",
      "\n",
      "Fold: 13  Epoch: 235  Training loss = 3.1336  Validation loss = 5.1548  \n",
      "\n",
      "Fold: 13  Epoch: 236  Training loss = 3.1331  Validation loss = 5.1539  \n",
      "\n",
      "Fold: 13  Epoch: 237  Training loss = 3.1327  Validation loss = 5.1529  \n",
      "\n",
      "Fold: 13  Epoch: 238  Training loss = 3.1323  Validation loss = 5.1519  \n",
      "\n",
      "Fold: 13  Epoch: 239  Training loss = 3.1318  Validation loss = 5.1507  \n",
      "\n",
      "Fold: 13  Epoch: 240  Training loss = 3.1315  Validation loss = 5.1500  \n",
      "\n",
      "Fold: 13  Epoch: 241  Training loss = 3.1310  Validation loss = 5.1489  \n",
      "\n",
      "Fold: 13  Epoch: 242  Training loss = 3.1305  Validation loss = 5.1476  \n",
      "\n",
      "Fold: 13  Epoch: 243  Training loss = 3.1302  Validation loss = 5.1469  \n",
      "\n",
      "Fold: 13  Epoch: 244  Training loss = 3.1298  Validation loss = 5.1458  \n",
      "\n",
      "Fold: 13  Epoch: 245  Training loss = 3.1294  Validation loss = 5.1447  \n",
      "\n",
      "Fold: 13  Epoch: 246  Training loss = 3.1290  Validation loss = 5.1435  \n",
      "\n",
      "Fold: 13  Epoch: 247  Training loss = 3.1286  Validation loss = 5.1425  \n",
      "\n",
      "Fold: 13  Epoch: 248  Training loss = 3.1281  Validation loss = 5.1413  \n",
      "\n",
      "Fold: 13  Epoch: 249  Training loss = 3.1278  Validation loss = 5.1404  \n",
      "\n",
      "Fold: 13  Epoch: 250  Training loss = 3.1274  Validation loss = 5.1394  \n",
      "\n",
      "Fold: 13  Epoch: 251  Training loss = 3.1269  Validation loss = 5.1382  \n",
      "\n",
      "Fold: 13  Epoch: 252  Training loss = 3.1265  Validation loss = 5.1372  \n",
      "\n",
      "Fold: 13  Epoch: 253  Training loss = 3.1260  Validation loss = 5.1359  \n",
      "\n",
      "Fold: 13  Epoch: 254  Training loss = 3.1254  Validation loss = 5.1342  \n",
      "\n",
      "Fold: 13  Epoch: 255  Training loss = 3.1250  Validation loss = 5.1332  \n",
      "\n",
      "Fold: 13  Epoch: 256  Training loss = 3.1246  Validation loss = 5.1322  \n",
      "\n",
      "Fold: 13  Epoch: 257  Training loss = 3.1242  Validation loss = 5.1310  \n",
      "\n",
      "Fold: 13  Epoch: 258  Training loss = 3.1238  Validation loss = 5.1300  \n",
      "\n",
      "Fold: 13  Epoch: 259  Training loss = 3.1234  Validation loss = 5.1289  \n",
      "\n",
      "Fold: 13  Epoch: 260  Training loss = 3.1230  Validation loss = 5.1279  \n",
      "\n",
      "Fold: 13  Epoch: 261  Training loss = 3.1228  Validation loss = 5.1272  \n",
      "\n",
      "Fold: 13  Epoch: 262  Training loss = 3.1224  Validation loss = 5.1262  \n",
      "\n",
      "Fold: 13  Epoch: 263  Training loss = 3.1219  Validation loss = 5.1250  \n",
      "\n",
      "Fold: 13  Epoch: 264  Training loss = 3.1216  Validation loss = 5.1242  \n",
      "\n",
      "Fold: 13  Epoch: 265  Training loss = 3.1213  Validation loss = 5.1233  \n",
      "\n",
      "Fold: 13  Epoch: 266  Training loss = 3.1208  Validation loss = 5.1221  \n",
      "\n",
      "Fold: 13  Epoch: 267  Training loss = 3.1204  Validation loss = 5.1209  \n",
      "\n",
      "Fold: 13  Epoch: 268  Training loss = 3.1200  Validation loss = 5.1199  \n",
      "\n",
      "Fold: 13  Epoch: 269  Training loss = 3.1197  Validation loss = 5.1191  \n",
      "\n",
      "Fold: 13  Epoch: 270  Training loss = 3.1194  Validation loss = 5.1183  \n",
      "\n",
      "Fold: 13  Epoch: 271  Training loss = 3.1190  Validation loss = 5.1173  \n",
      "\n",
      "Fold: 13  Epoch: 272  Training loss = 3.1185  Validation loss = 5.1159  \n",
      "\n",
      "Fold: 13  Epoch: 273  Training loss = 3.1180  Validation loss = 5.1146  \n",
      "\n",
      "Fold: 13  Epoch: 274  Training loss = 3.1178  Validation loss = 5.1140  \n",
      "\n",
      "Fold: 13  Epoch: 275  Training loss = 3.1174  Validation loss = 5.1131  \n",
      "\n",
      "Fold: 13  Epoch: 276  Training loss = 3.1168  Validation loss = 5.1115  \n",
      "\n",
      "Fold: 13  Epoch: 277  Training loss = 3.1162  Validation loss = 5.1100  \n",
      "\n",
      "Fold: 13  Epoch: 278  Training loss = 3.1160  Validation loss = 5.1093  \n",
      "\n",
      "Fold: 13  Epoch: 279  Training loss = 3.1155  Validation loss = 5.1081  \n",
      "\n",
      "Fold: 13  Epoch: 280  Training loss = 3.1152  Validation loss = 5.1073  \n",
      "\n",
      "Fold: 13  Epoch: 281  Training loss = 3.1148  Validation loss = 5.1062  \n",
      "\n",
      "Fold: 13  Epoch: 282  Training loss = 3.1144  Validation loss = 5.1050  \n",
      "\n",
      "Fold: 13  Epoch: 283  Training loss = 3.1141  Validation loss = 5.1043  \n",
      "\n",
      "Fold: 13  Epoch: 284  Training loss = 3.1136  Validation loss = 5.1031  \n",
      "\n",
      "Fold: 13  Epoch: 285  Training loss = 3.1132  Validation loss = 5.1020  \n",
      "\n",
      "Fold: 13  Epoch: 286  Training loss = 3.1129  Validation loss = 5.1012  \n",
      "\n",
      "Fold: 13  Epoch: 287  Training loss = 3.1125  Validation loss = 5.1000  \n",
      "\n",
      "Fold: 13  Epoch: 288  Training loss = 3.1122  Validation loss = 5.0991  \n",
      "\n",
      "Fold: 13  Epoch: 289  Training loss = 3.1117  Validation loss = 5.0979  \n",
      "\n",
      "Fold: 13  Epoch: 290  Training loss = 3.1112  Validation loss = 5.0966  \n",
      "\n",
      "Fold: 13  Epoch: 291  Training loss = 3.1110  Validation loss = 5.0960  \n",
      "\n",
      "Fold: 13  Epoch: 292  Training loss = 3.1106  Validation loss = 5.0950  \n",
      "\n",
      "Fold: 13  Epoch: 293  Training loss = 3.1102  Validation loss = 5.0939  \n",
      "\n",
      "Fold: 13  Epoch: 294  Training loss = 3.1099  Validation loss = 5.0930  \n",
      "\n",
      "Fold: 13  Epoch: 295  Training loss = 3.1095  Validation loss = 5.0921  \n",
      "\n",
      "Fold: 13  Epoch: 296  Training loss = 3.1091  Validation loss = 5.0911  \n",
      "\n",
      "Fold: 13  Epoch: 297  Training loss = 3.1087  Validation loss = 5.0900  \n",
      "\n",
      "Fold: 13  Epoch: 298  Training loss = 3.1085  Validation loss = 5.0893  \n",
      "\n",
      "Fold: 13  Epoch: 299  Training loss = 3.1081  Validation loss = 5.0882  \n",
      "\n",
      "Fold: 13  Epoch: 300  Training loss = 3.1077  Validation loss = 5.0874  \n",
      "\n",
      "Fold: 13  Epoch: 301  Training loss = 3.1074  Validation loss = 5.0866  \n",
      "\n",
      "Fold: 13  Epoch: 302  Training loss = 3.1072  Validation loss = 5.0859  \n",
      "\n",
      "Fold: 13  Epoch: 303  Training loss = 3.1068  Validation loss = 5.0850  \n",
      "\n",
      "Fold: 13  Epoch: 304  Training loss = 3.1063  Validation loss = 5.0835  \n",
      "\n",
      "Fold: 13  Epoch: 305  Training loss = 3.1059  Validation loss = 5.0824  \n",
      "\n",
      "Fold: 13  Epoch: 306  Training loss = 3.1056  Validation loss = 5.0816  \n",
      "\n",
      "Fold: 13  Epoch: 307  Training loss = 3.1053  Validation loss = 5.0808  \n",
      "\n",
      "Fold: 13  Epoch: 308  Training loss = 3.1049  Validation loss = 5.0797  \n",
      "\n",
      "Fold: 13  Epoch: 309  Training loss = 3.1044  Validation loss = 5.0785  \n",
      "\n",
      "Fold: 13  Epoch: 310  Training loss = 3.1040  Validation loss = 5.0774  \n",
      "\n",
      "Fold: 13  Epoch: 311  Training loss = 3.1037  Validation loss = 5.0766  \n",
      "\n",
      "Fold: 13  Epoch: 312  Training loss = 3.1032  Validation loss = 5.0753  \n",
      "\n",
      "Fold: 13  Epoch: 313  Training loss = 3.1027  Validation loss = 5.0741  \n",
      "\n",
      "Fold: 13  Epoch: 314  Training loss = 3.1022  Validation loss = 5.0729  \n",
      "\n",
      "Fold: 13  Epoch: 315  Training loss = 3.1018  Validation loss = 5.0717  \n",
      "\n",
      "Fold: 13  Epoch: 316  Training loss = 3.1015  Validation loss = 5.0709  \n",
      "\n",
      "Fold: 13  Epoch: 317  Training loss = 3.1011  Validation loss = 5.0698  \n",
      "\n",
      "Fold: 13  Epoch: 318  Training loss = 3.1007  Validation loss = 5.0687  \n",
      "\n",
      "Fold: 13  Epoch: 319  Training loss = 3.1003  Validation loss = 5.0677  \n",
      "\n",
      "Fold: 13  Epoch: 320  Training loss = 3.0998  Validation loss = 5.0663  \n",
      "\n",
      "Fold: 13  Epoch: 321  Training loss = 3.0994  Validation loss = 5.0652  \n",
      "\n",
      "Fold: 13  Epoch: 322  Training loss = 3.0989  Validation loss = 5.0641  \n",
      "\n",
      "Fold: 13  Epoch: 323  Training loss = 3.0986  Validation loss = 5.0632  \n",
      "\n",
      "Fold: 13  Epoch: 324  Training loss = 3.0983  Validation loss = 5.0624  \n",
      "\n",
      "Fold: 13  Epoch: 325  Training loss = 3.0980  Validation loss = 5.0615  \n",
      "\n",
      "Fold: 13  Epoch: 326  Training loss = 3.0977  Validation loss = 5.0607  \n",
      "\n",
      "Fold: 13  Epoch: 327  Training loss = 3.0974  Validation loss = 5.0599  \n",
      "\n",
      "Fold: 13  Epoch: 328  Training loss = 3.0971  Validation loss = 5.0591  \n",
      "\n",
      "Fold: 13  Epoch: 329  Training loss = 3.0969  Validation loss = 5.0584  \n",
      "\n",
      "Fold: 13  Epoch: 330  Training loss = 3.0966  Validation loss = 5.0577  \n",
      "\n",
      "Fold: 13  Epoch: 331  Training loss = 3.0962  Validation loss = 5.0566  \n",
      "\n",
      "Fold: 13  Epoch: 332  Training loss = 3.0957  Validation loss = 5.0553  \n",
      "\n",
      "Fold: 13  Epoch: 333  Training loss = 3.0954  Validation loss = 5.0546  \n",
      "\n",
      "Fold: 13  Epoch: 334  Training loss = 3.0950  Validation loss = 5.0534  \n",
      "\n",
      "Fold: 13  Epoch: 335  Training loss = 3.0946  Validation loss = 5.0523  \n",
      "\n",
      "Fold: 13  Epoch: 336  Training loss = 3.0940  Validation loss = 5.0509  \n",
      "\n",
      "Fold: 13  Epoch: 337  Training loss = 3.0938  Validation loss = 5.0502  \n",
      "\n",
      "Fold: 13  Epoch: 338  Training loss = 3.0935  Validation loss = 5.0494  \n",
      "\n",
      "Fold: 13  Epoch: 339  Training loss = 3.0931  Validation loss = 5.0484  \n",
      "\n",
      "Fold: 13  Epoch: 340  Training loss = 3.0927  Validation loss = 5.0475  \n",
      "\n",
      "Fold: 13  Epoch: 341  Training loss = 3.0923  Validation loss = 5.0463  \n",
      "\n",
      "Fold: 13  Epoch: 342  Training loss = 3.0919  Validation loss = 5.0454  \n",
      "\n",
      "Fold: 13  Epoch: 343  Training loss = 3.0914  Validation loss = 5.0441  \n",
      "\n",
      "Fold: 13  Epoch: 344  Training loss = 3.0912  Validation loss = 5.0434  \n",
      "\n",
      "Fold: 13  Epoch: 345  Training loss = 3.0907  Validation loss = 5.0421  \n",
      "\n",
      "Fold: 13  Epoch: 346  Training loss = 3.0903  Validation loss = 5.0413  \n",
      "\n",
      "Fold: 13  Epoch: 347  Training loss = 3.0900  Validation loss = 5.0405  \n",
      "\n",
      "Fold: 13  Epoch: 348  Training loss = 3.0897  Validation loss = 5.0397  \n",
      "\n",
      "Fold: 13  Epoch: 349  Training loss = 3.0894  Validation loss = 5.0389  \n",
      "\n",
      "Fold: 13  Epoch: 350  Training loss = 3.0890  Validation loss = 5.0379  \n",
      "\n",
      "Fold: 13  Epoch: 351  Training loss = 3.0887  Validation loss = 5.0371  \n",
      "\n",
      "Fold: 13  Epoch: 352  Training loss = 3.0883  Validation loss = 5.0361  \n",
      "\n",
      "Fold: 13  Epoch: 353  Training loss = 3.0879  Validation loss = 5.0351  \n",
      "\n",
      "Fold: 13  Epoch: 354  Training loss = 3.0875  Validation loss = 5.0340  \n",
      "\n",
      "Fold: 13  Epoch: 355  Training loss = 3.0871  Validation loss = 5.0331  \n",
      "\n",
      "Fold: 13  Epoch: 356  Training loss = 3.0866  Validation loss = 5.0318  \n",
      "\n",
      "Fold: 13  Epoch: 357  Training loss = 3.0862  Validation loss = 5.0307  \n",
      "\n",
      "Fold: 13  Epoch: 358  Training loss = 3.0858  Validation loss = 5.0296  \n",
      "\n",
      "Fold: 13  Epoch: 359  Training loss = 3.0853  Validation loss = 5.0284  \n",
      "\n",
      "Fold: 13  Epoch: 360  Training loss = 3.0849  Validation loss = 5.0273  \n",
      "\n",
      "Fold: 13  Epoch: 361  Training loss = 3.0846  Validation loss = 5.0265  \n",
      "\n",
      "Fold: 13  Epoch: 362  Training loss = 3.0843  Validation loss = 5.0259  \n",
      "\n",
      "Fold: 13  Epoch: 363  Training loss = 3.0840  Validation loss = 5.0250  \n",
      "\n",
      "Fold: 13  Epoch: 364  Training loss = 3.0837  Validation loss = 5.0241  \n",
      "\n",
      "Fold: 13  Epoch: 365  Training loss = 3.0833  Validation loss = 5.0231  \n",
      "\n",
      "Fold: 13  Epoch: 366  Training loss = 3.0829  Validation loss = 5.0221  \n",
      "\n",
      "Fold: 13  Epoch: 367  Training loss = 3.0824  Validation loss = 5.0209  \n",
      "\n",
      "Fold: 13  Epoch: 368  Training loss = 3.0821  Validation loss = 5.0200  \n",
      "\n",
      "Fold: 13  Epoch: 369  Training loss = 3.0815  Validation loss = 5.0185  \n",
      "\n",
      "Fold: 13  Epoch: 370  Training loss = 3.0812  Validation loss = 5.0177  \n",
      "\n",
      "Fold: 13  Epoch: 371  Training loss = 3.0809  Validation loss = 5.0169  \n",
      "\n",
      "Fold: 13  Epoch: 372  Training loss = 3.0805  Validation loss = 5.0160  \n",
      "\n",
      "Fold: 13  Epoch: 373  Training loss = 3.0802  Validation loss = 5.0152  \n",
      "\n",
      "Fold: 13  Epoch: 374  Training loss = 3.0801  Validation loss = 5.0147  \n",
      "\n",
      "Fold: 13  Epoch: 375  Training loss = 3.0797  Validation loss = 5.0138  \n",
      "\n",
      "Fold: 13  Epoch: 376  Training loss = 3.0793  Validation loss = 5.0127  \n",
      "\n",
      "Fold: 13  Epoch: 377  Training loss = 3.0789  Validation loss = 5.0116  \n",
      "\n",
      "Fold: 13  Epoch: 378  Training loss = 3.0786  Validation loss = 5.0108  \n",
      "\n",
      "Fold: 13  Epoch: 379  Training loss = 3.0782  Validation loss = 5.0098  \n",
      "\n",
      "Fold: 13  Epoch: 380  Training loss = 3.0777  Validation loss = 5.0084  \n",
      "\n",
      "Fold: 13  Epoch: 381  Training loss = 3.0773  Validation loss = 5.0075  \n",
      "\n",
      "Fold: 13  Epoch: 382  Training loss = 3.0770  Validation loss = 5.0065  \n",
      "\n",
      "Fold: 13  Epoch: 383  Training loss = 3.0766  Validation loss = 5.0055  \n",
      "\n",
      "Fold: 13  Epoch: 384  Training loss = 3.0764  Validation loss = 5.0048  \n",
      "\n",
      "Fold: 13  Epoch: 385  Training loss = 3.0760  Validation loss = 5.0039  \n",
      "\n",
      "Fold: 13  Epoch: 386  Training loss = 3.0756  Validation loss = 5.0028  \n",
      "\n",
      "Fold: 13  Epoch: 387  Training loss = 3.0752  Validation loss = 5.0017  \n",
      "\n",
      "Fold: 13  Epoch: 388  Training loss = 3.0749  Validation loss = 5.0009  \n",
      "\n",
      "Fold: 13  Epoch: 389  Training loss = 3.0746  Validation loss = 5.0000  \n",
      "\n",
      "Fold: 13  Epoch: 390  Training loss = 3.0741  Validation loss = 4.9988  \n",
      "\n",
      "Fold: 13  Epoch: 391  Training loss = 3.0737  Validation loss = 4.9975  \n",
      "\n",
      "Fold: 13  Epoch: 392  Training loss = 3.0734  Validation loss = 4.9966  \n",
      "\n",
      "Fold: 13  Epoch: 393  Training loss = 3.0730  Validation loss = 4.9956  \n",
      "\n",
      "Fold: 13  Epoch: 394  Training loss = 3.0727  Validation loss = 4.9947  \n",
      "\n",
      "Fold: 13  Epoch: 395  Training loss = 3.0724  Validation loss = 4.9940  \n",
      "\n",
      "Fold: 13  Epoch: 396  Training loss = 3.0720  Validation loss = 4.9931  \n",
      "\n",
      "Fold: 13  Epoch: 397  Training loss = 3.0716  Validation loss = 4.9919  \n",
      "\n",
      "Fold: 13  Epoch: 398  Training loss = 3.0713  Validation loss = 4.9909  \n",
      "\n",
      "Fold: 13  Epoch: 399  Training loss = 3.0708  Validation loss = 4.9895  \n",
      "\n",
      "Fold: 13  Epoch: 400  Training loss = 3.0704  Validation loss = 4.9885  \n",
      "\n",
      "Fold: 13  Epoch: 401  Training loss = 3.0701  Validation loss = 4.9877  \n",
      "\n",
      "Fold: 13  Epoch: 402  Training loss = 3.0698  Validation loss = 4.9869  \n",
      "\n",
      "Fold: 13  Epoch: 403  Training loss = 3.0695  Validation loss = 4.9860  \n",
      "\n",
      "Fold: 13  Epoch: 404  Training loss = 3.0690  Validation loss = 4.9849  \n",
      "\n",
      "Fold: 13  Epoch: 405  Training loss = 3.0688  Validation loss = 4.9840  \n",
      "\n",
      "Fold: 13  Epoch: 406  Training loss = 3.0685  Validation loss = 4.9833  \n",
      "\n",
      "Fold: 13  Epoch: 407  Training loss = 3.0682  Validation loss = 4.9826  \n",
      "\n",
      "Fold: 13  Epoch: 408  Training loss = 3.0679  Validation loss = 4.9818  \n",
      "\n",
      "Fold: 13  Epoch: 409  Training loss = 3.0676  Validation loss = 4.9808  \n",
      "\n",
      "Fold: 13  Epoch: 410  Training loss = 3.0672  Validation loss = 4.9798  \n",
      "\n",
      "Fold: 13  Epoch: 411  Training loss = 3.0667  Validation loss = 4.9785  \n",
      "\n",
      "Fold: 13  Epoch: 412  Training loss = 3.0662  Validation loss = 4.9773  \n",
      "\n",
      "Fold: 13  Epoch: 413  Training loss = 3.0659  Validation loss = 4.9764  \n",
      "\n",
      "Fold: 13  Epoch: 414  Training loss = 3.0655  Validation loss = 4.9754  \n",
      "\n",
      "Fold: 13  Epoch: 415  Training loss = 3.0651  Validation loss = 4.9743  \n",
      "\n",
      "Fold: 13  Epoch: 416  Training loss = 3.0648  Validation loss = 4.9735  \n",
      "\n",
      "Fold: 13  Epoch: 417  Training loss = 3.0645  Validation loss = 4.9726  \n",
      "\n",
      "Fold: 13  Epoch: 418  Training loss = 3.0641  Validation loss = 4.9717  \n",
      "\n",
      "Fold: 13  Epoch: 419  Training loss = 3.0638  Validation loss = 4.9707  \n",
      "\n",
      "Fold: 13  Epoch: 420  Training loss = 3.0635  Validation loss = 4.9699  \n",
      "\n",
      "Fold: 13  Epoch: 421  Training loss = 3.0631  Validation loss = 4.9689  \n",
      "\n",
      "Fold: 13  Epoch: 422  Training loss = 3.0629  Validation loss = 4.9681  \n",
      "\n",
      "Fold: 13  Epoch: 423  Training loss = 3.0625  Validation loss = 4.9672  \n",
      "\n",
      "Fold: 13  Epoch: 424  Training loss = 3.0621  Validation loss = 4.9662  \n",
      "\n",
      "Fold: 13  Epoch: 425  Training loss = 3.0617  Validation loss = 4.9650  \n",
      "\n",
      "Fold: 13  Epoch: 426  Training loss = 3.0613  Validation loss = 4.9641  \n",
      "\n",
      "Fold: 13  Epoch: 427  Training loss = 3.0610  Validation loss = 4.9631  \n",
      "\n",
      "Fold: 13  Epoch: 428  Training loss = 3.0607  Validation loss = 4.9622  \n",
      "\n",
      "Fold: 13  Epoch: 429  Training loss = 3.0603  Validation loss = 4.9613  \n",
      "\n",
      "Fold: 13  Epoch: 430  Training loss = 3.0599  Validation loss = 4.9604  \n",
      "\n",
      "Fold: 13  Epoch: 431  Training loss = 3.0596  Validation loss = 4.9595  \n",
      "\n",
      "Fold: 13  Epoch: 432  Training loss = 3.0594  Validation loss = 4.9590  \n",
      "\n",
      "Fold: 13  Epoch: 433  Training loss = 3.0589  Validation loss = 4.9581  \n",
      "\n",
      "Fold: 13  Epoch: 434  Training loss = 3.0576  Validation loss = 4.9569  \n",
      "\n",
      "Fold: 13  Epoch: 435  Training loss = 3.0569  Validation loss = 4.9561  \n",
      "\n",
      "Fold: 13  Epoch: 436  Training loss = 3.0565  Validation loss = 4.9552  \n",
      "\n",
      "Fold: 13  Epoch: 437  Training loss = 3.0560  Validation loss = 4.9541  \n",
      "\n",
      "Fold: 13  Epoch: 438  Training loss = 3.0558  Validation loss = 4.9535  \n",
      "\n",
      "Fold: 13  Epoch: 439  Training loss = 3.0554  Validation loss = 4.9525  \n",
      "\n",
      "Fold: 13  Epoch: 440  Training loss = 3.0551  Validation loss = 4.9516  \n",
      "\n",
      "Fold: 13  Epoch: 441  Training loss = 3.0548  Validation loss = 4.9509  \n",
      "\n",
      "Fold: 13  Epoch: 442  Training loss = 3.0545  Validation loss = 4.9500  \n",
      "\n",
      "Fold: 13  Epoch: 443  Training loss = 3.0543  Validation loss = 4.9493  \n",
      "\n",
      "Fold: 13  Epoch: 444  Training loss = 3.0539  Validation loss = 4.9483  \n",
      "\n",
      "Fold: 13  Epoch: 445  Training loss = 3.0536  Validation loss = 4.9474  \n",
      "\n",
      "Fold: 13  Epoch: 446  Training loss = 3.0532  Validation loss = 4.9462  \n",
      "\n",
      "Fold: 13  Epoch: 447  Training loss = 3.0528  Validation loss = 4.9451  \n",
      "\n",
      "Fold: 13  Epoch: 448  Training loss = 3.0526  Validation loss = 4.9446  \n",
      "\n",
      "Fold: 13  Epoch: 449  Training loss = 3.0522  Validation loss = 4.9435  \n",
      "\n",
      "Fold: 13  Epoch: 450  Training loss = 3.0519  Validation loss = 4.9428  \n",
      "\n",
      "Fold: 13  Epoch: 451  Training loss = 3.0516  Validation loss = 4.9418  \n",
      "\n",
      "Fold: 13  Epoch: 452  Training loss = 3.0512  Validation loss = 4.9407  \n",
      "\n",
      "Fold: 13  Epoch: 453  Training loss = 3.0508  Validation loss = 4.9398  \n",
      "\n",
      "Fold: 13  Epoch: 454  Training loss = 3.0505  Validation loss = 4.9388  \n",
      "\n",
      "Fold: 13  Epoch: 455  Training loss = 3.0501  Validation loss = 4.9379  \n",
      "\n",
      "Fold: 13  Epoch: 456  Training loss = 3.0499  Validation loss = 4.9371  \n",
      "\n",
      "Fold: 13  Epoch: 457  Training loss = 3.0495  Validation loss = 4.9361  \n",
      "\n",
      "Fold: 13  Epoch: 458  Training loss = 3.0493  Validation loss = 4.9355  \n",
      "\n",
      "Fold: 13  Epoch: 459  Training loss = 3.0489  Validation loss = 4.9346  \n",
      "\n",
      "Fold: 13  Epoch: 460  Training loss = 3.0486  Validation loss = 4.9338  \n",
      "\n",
      "Fold: 13  Epoch: 461  Training loss = 3.0482  Validation loss = 4.9327  \n",
      "\n",
      "Fold: 13  Epoch: 462  Training loss = 3.0480  Validation loss = 4.9321  \n",
      "\n",
      "Fold: 13  Epoch: 463  Training loss = 3.0476  Validation loss = 4.9309  \n",
      "\n",
      "Fold: 13  Epoch: 464  Training loss = 3.0473  Validation loss = 4.9301  \n",
      "\n",
      "Fold: 13  Epoch: 465  Training loss = 3.0469  Validation loss = 4.9292  \n",
      "\n",
      "Fold: 13  Epoch: 466  Training loss = 3.0467  Validation loss = 4.9286  \n",
      "\n",
      "Fold: 13  Epoch: 467  Training loss = 3.0464  Validation loss = 4.9278  \n",
      "\n",
      "Fold: 13  Epoch: 468  Training loss = 3.0460  Validation loss = 4.9266  \n",
      "\n",
      "Fold: 13  Epoch: 469  Training loss = 3.0457  Validation loss = 4.9258  \n",
      "\n",
      "Fold: 13  Epoch: 470  Training loss = 3.0455  Validation loss = 4.9252  \n",
      "\n",
      "Fold: 13  Epoch: 471  Training loss = 3.0451  Validation loss = 4.9242  \n",
      "\n",
      "Fold: 13  Epoch: 472  Training loss = 3.0449  Validation loss = 4.9235  \n",
      "\n",
      "Fold: 13  Epoch: 473  Training loss = 3.0445  Validation loss = 4.9223  \n",
      "\n",
      "Fold: 13  Epoch: 474  Training loss = 3.0442  Validation loss = 4.9215  \n",
      "\n",
      "Fold: 13  Epoch: 475  Training loss = 3.0440  Validation loss = 4.9211  \n",
      "\n",
      "Fold: 13  Epoch: 476  Training loss = 3.0437  Validation loss = 4.9201  \n",
      "\n",
      "Fold: 13  Epoch: 477  Training loss = 3.0435  Validation loss = 4.9196  \n",
      "\n",
      "Fold: 13  Epoch: 478  Training loss = 3.0434  Validation loss = 4.9191  \n",
      "\n",
      "Fold: 13  Epoch: 479  Training loss = 3.0430  Validation loss = 4.9182  \n",
      "\n",
      "Fold: 13  Epoch: 480  Training loss = 3.0427  Validation loss = 4.9171  \n",
      "\n",
      "Fold: 13  Epoch: 481  Training loss = 3.0423  Validation loss = 4.9162  \n",
      "\n",
      "Fold: 13  Epoch: 482  Training loss = 3.0419  Validation loss = 4.9152  \n",
      "\n",
      "Fold: 13  Epoch: 483  Training loss = 3.0416  Validation loss = 4.9141  \n",
      "\n",
      "Fold: 13  Epoch: 484  Training loss = 3.0413  Validation loss = 4.9135  \n",
      "\n",
      "Fold: 13  Epoch: 485  Training loss = 3.0410  Validation loss = 4.9126  \n",
      "\n",
      "Fold: 13  Epoch: 486  Training loss = 3.0406  Validation loss = 4.9115  \n",
      "\n",
      "Fold: 13  Epoch: 487  Training loss = 3.0404  Validation loss = 4.9108  \n",
      "\n",
      "Fold: 13  Epoch: 488  Training loss = 3.0400  Validation loss = 4.9099  \n",
      "\n",
      "Fold: 13  Epoch: 489  Training loss = 3.0397  Validation loss = 4.9089  \n",
      "\n",
      "Fold: 13  Epoch: 490  Training loss = 3.0393  Validation loss = 4.9080  \n",
      "\n",
      "Fold: 13  Epoch: 491  Training loss = 3.0390  Validation loss = 4.9071  \n",
      "\n",
      "Fold: 13  Epoch: 492  Training loss = 3.0387  Validation loss = 4.9062  \n",
      "\n",
      "Fold: 13  Epoch: 493  Training loss = 3.0385  Validation loss = 4.9056  \n",
      "\n",
      "Fold: 13  Epoch: 494  Training loss = 3.0382  Validation loss = 4.9047  \n",
      "\n",
      "Fold: 13  Epoch: 495  Training loss = 3.0379  Validation loss = 4.9039  \n",
      "\n",
      "Fold: 13  Epoch: 496  Training loss = 3.0374  Validation loss = 4.9026  \n",
      "\n",
      "Fold: 13  Epoch: 497  Training loss = 3.0371  Validation loss = 4.9018  \n",
      "\n",
      "Fold: 13  Epoch: 498  Training loss = 3.0370  Validation loss = 4.9014  \n",
      "\n",
      "Fold: 13  Epoch: 499  Training loss = 3.0367  Validation loss = 4.9005  \n",
      "\n",
      "Fold: 13  Epoch: 500  Training loss = 3.0363  Validation loss = 4.8995  \n",
      "\n",
      "Check model:  Fold: 13  Optimal epoch: 500  \n",
      "\n",
      "Fold: 14  Epoch: 1  Training loss = 3.2396  Validation loss = 8.5210  \n",
      "\n",
      "Fold: 14  Epoch: 2  Training loss = 3.2391  Validation loss = 8.5199  \n",
      "\n",
      "Fold: 14  Epoch: 3  Training loss = 3.2386  Validation loss = 8.5188  \n",
      "\n",
      "Fold: 14  Epoch: 4  Training loss = 3.2379  Validation loss = 8.5175  \n",
      "\n",
      "Fold: 14  Epoch: 5  Training loss = 3.2374  Validation loss = 8.5164  \n",
      "\n",
      "Fold: 14  Epoch: 6  Training loss = 3.2370  Validation loss = 8.5155  \n",
      "\n",
      "Fold: 14  Epoch: 7  Training loss = 3.2364  Validation loss = 8.5143  \n",
      "\n",
      "Fold: 14  Epoch: 8  Training loss = 3.2358  Validation loss = 8.5131  \n",
      "\n",
      "Fold: 14  Epoch: 9  Training loss = 3.2352  Validation loss = 8.5119  \n",
      "\n",
      "Fold: 14  Epoch: 10  Training loss = 3.2345  Validation loss = 8.5105  \n",
      "\n",
      "Fold: 14  Epoch: 11  Training loss = 3.2339  Validation loss = 8.5092  \n",
      "\n",
      "Fold: 14  Epoch: 12  Training loss = 3.2333  Validation loss = 8.5079  \n",
      "\n",
      "Fold: 14  Epoch: 13  Training loss = 3.2328  Validation loss = 8.5069  \n",
      "\n",
      "Fold: 14  Epoch: 14  Training loss = 3.2323  Validation loss = 8.5059  \n",
      "\n",
      "Fold: 14  Epoch: 15  Training loss = 3.2320  Validation loss = 8.5053  \n",
      "\n",
      "Fold: 14  Epoch: 16  Training loss = 3.2315  Validation loss = 8.5041  \n",
      "\n",
      "Fold: 14  Epoch: 17  Training loss = 3.2310  Validation loss = 8.5032  \n",
      "\n",
      "Fold: 14  Epoch: 18  Training loss = 3.2304  Validation loss = 8.5019  \n",
      "\n",
      "Fold: 14  Epoch: 19  Training loss = 3.2298  Validation loss = 8.5006  \n",
      "\n",
      "Fold: 14  Epoch: 20  Training loss = 3.2292  Validation loss = 8.4995  \n",
      "\n",
      "Fold: 14  Epoch: 21  Training loss = 3.2288  Validation loss = 8.4986  \n",
      "\n",
      "Fold: 14  Epoch: 22  Training loss = 3.2283  Validation loss = 8.4975  \n",
      "\n",
      "Fold: 14  Epoch: 23  Training loss = 3.2276  Validation loss = 8.4961  \n",
      "\n",
      "Fold: 14  Epoch: 24  Training loss = 3.2271  Validation loss = 8.4952  \n",
      "\n",
      "Fold: 14  Epoch: 25  Training loss = 3.2267  Validation loss = 8.4943  \n",
      "\n",
      "Fold: 14  Epoch: 26  Training loss = 3.2260  Validation loss = 8.4930  \n",
      "\n",
      "Fold: 14  Epoch: 27  Training loss = 3.2255  Validation loss = 8.4920  \n",
      "\n",
      "Fold: 14  Epoch: 28  Training loss = 3.2251  Validation loss = 8.4911  \n",
      "\n",
      "Fold: 14  Epoch: 29  Training loss = 3.2244  Validation loss = 8.4897  \n",
      "\n",
      "Fold: 14  Epoch: 30  Training loss = 3.2239  Validation loss = 8.4886  \n",
      "\n",
      "Fold: 14  Epoch: 31  Training loss = 3.2233  Validation loss = 8.4873  \n",
      "\n",
      "Fold: 14  Epoch: 32  Training loss = 3.2228  Validation loss = 8.4863  \n",
      "\n",
      "Fold: 14  Epoch: 33  Training loss = 3.2222  Validation loss = 8.4851  \n",
      "\n",
      "Fold: 14  Epoch: 34  Training loss = 3.2218  Validation loss = 8.4842  \n",
      "\n",
      "Fold: 14  Epoch: 35  Training loss = 3.2213  Validation loss = 8.4831  \n",
      "\n",
      "Fold: 14  Epoch: 36  Training loss = 3.2206  Validation loss = 8.4818  \n",
      "\n",
      "Fold: 14  Epoch: 37  Training loss = 3.2201  Validation loss = 8.4807  \n",
      "\n",
      "Fold: 14  Epoch: 38  Training loss = 3.2196  Validation loss = 8.4796  \n",
      "\n",
      "Fold: 14  Epoch: 39  Training loss = 3.2191  Validation loss = 8.4786  \n",
      "\n",
      "Fold: 14  Epoch: 40  Training loss = 3.2185  Validation loss = 8.4774  \n",
      "\n",
      "Fold: 14  Epoch: 41  Training loss = 3.2179  Validation loss = 8.4761  \n",
      "\n",
      "Fold: 14  Epoch: 42  Training loss = 3.2174  Validation loss = 8.4750  \n",
      "\n",
      "Fold: 14  Epoch: 43  Training loss = 3.2170  Validation loss = 8.4741  \n",
      "\n",
      "Fold: 14  Epoch: 44  Training loss = 3.2165  Validation loss = 8.4732  \n",
      "\n",
      "Fold: 14  Epoch: 45  Training loss = 3.2162  Validation loss = 8.4725  \n",
      "\n",
      "Fold: 14  Epoch: 46  Training loss = 3.2158  Validation loss = 8.4717  \n",
      "\n",
      "Fold: 14  Epoch: 47  Training loss = 3.2152  Validation loss = 8.4705  \n",
      "\n",
      "Fold: 14  Epoch: 48  Training loss = 3.2148  Validation loss = 8.4696  \n",
      "\n",
      "Fold: 14  Epoch: 49  Training loss = 3.2143  Validation loss = 8.4685  \n",
      "\n",
      "Fold: 14  Epoch: 50  Training loss = 3.2137  Validation loss = 8.4672  \n",
      "\n",
      "Fold: 14  Epoch: 51  Training loss = 3.2133  Validation loss = 8.4664  \n",
      "\n",
      "Fold: 14  Epoch: 52  Training loss = 3.2128  Validation loss = 8.4655  \n",
      "\n",
      "Fold: 14  Epoch: 53  Training loss = 3.2124  Validation loss = 8.4644  \n",
      "\n",
      "Fold: 14  Epoch: 54  Training loss = 3.2119  Validation loss = 8.4633  \n",
      "\n",
      "Fold: 14  Epoch: 55  Training loss = 3.2113  Validation loss = 8.4622  \n",
      "\n",
      "Fold: 14  Epoch: 56  Training loss = 3.2108  Validation loss = 8.4611  \n",
      "\n",
      "Fold: 14  Epoch: 57  Training loss = 3.2104  Validation loss = 8.4603  \n",
      "\n",
      "Fold: 14  Epoch: 58  Training loss = 3.2099  Validation loss = 8.4593  \n",
      "\n",
      "Fold: 14  Epoch: 59  Training loss = 3.2093  Validation loss = 8.4580  \n",
      "\n",
      "Fold: 14  Epoch: 60  Training loss = 3.2087  Validation loss = 8.4567  \n",
      "\n",
      "Fold: 14  Epoch: 61  Training loss = 3.2082  Validation loss = 8.4557  \n",
      "\n",
      "Fold: 14  Epoch: 62  Training loss = 3.2078  Validation loss = 8.4548  \n",
      "\n",
      "Fold: 14  Epoch: 63  Training loss = 3.2074  Validation loss = 8.4539  \n",
      "\n",
      "Fold: 14  Epoch: 64  Training loss = 3.2069  Validation loss = 8.4528  \n",
      "\n",
      "Fold: 14  Epoch: 65  Training loss = 3.2063  Validation loss = 8.4515  \n",
      "\n",
      "Fold: 14  Epoch: 66  Training loss = 3.2059  Validation loss = 8.4507  \n",
      "\n",
      "Fold: 14  Epoch: 67  Training loss = 3.2053  Validation loss = 8.4495  \n",
      "\n",
      "Fold: 14  Epoch: 68  Training loss = 3.2048  Validation loss = 8.4484  \n",
      "\n",
      "Fold: 14  Epoch: 69  Training loss = 3.2043  Validation loss = 8.4474  \n",
      "\n",
      "Fold: 14  Epoch: 70  Training loss = 3.2038  Validation loss = 8.4465  \n",
      "\n",
      "Fold: 14  Epoch: 71  Training loss = 3.2034  Validation loss = 8.4455  \n",
      "\n",
      "Fold: 14  Epoch: 72  Training loss = 3.2029  Validation loss = 8.4444  \n",
      "\n",
      "Fold: 14  Epoch: 73  Training loss = 3.2023  Validation loss = 8.4433  \n",
      "\n",
      "Fold: 14  Epoch: 74  Training loss = 3.2017  Validation loss = 8.4421  \n",
      "\n",
      "Fold: 14  Epoch: 75  Training loss = 3.2012  Validation loss = 8.4409  \n",
      "\n",
      "Fold: 14  Epoch: 76  Training loss = 3.2007  Validation loss = 8.4398  \n",
      "\n",
      "Fold: 14  Epoch: 77  Training loss = 3.2001  Validation loss = 8.4385  \n",
      "\n",
      "Fold: 14  Epoch: 78  Training loss = 3.1996  Validation loss = 8.4375  \n",
      "\n",
      "Fold: 14  Epoch: 79  Training loss = 3.1990  Validation loss = 8.4363  \n",
      "\n",
      "Fold: 14  Epoch: 80  Training loss = 3.1985  Validation loss = 8.4353  \n",
      "\n",
      "Fold: 14  Epoch: 81  Training loss = 3.1982  Validation loss = 8.4344  \n",
      "\n",
      "Fold: 14  Epoch: 82  Training loss = 3.1976  Validation loss = 8.4333  \n",
      "\n",
      "Fold: 14  Epoch: 83  Training loss = 3.1971  Validation loss = 8.4322  \n",
      "\n",
      "Fold: 14  Epoch: 84  Training loss = 3.1967  Validation loss = 8.4314  \n",
      "\n",
      "Fold: 14  Epoch: 85  Training loss = 3.1961  Validation loss = 8.4302  \n",
      "\n",
      "Fold: 14  Epoch: 86  Training loss = 3.1957  Validation loss = 8.4292  \n",
      "\n",
      "Fold: 14  Epoch: 87  Training loss = 3.1953  Validation loss = 8.4284  \n",
      "\n",
      "Fold: 14  Epoch: 88  Training loss = 3.1948  Validation loss = 8.4273  \n",
      "\n",
      "Fold: 14  Epoch: 89  Training loss = 3.1943  Validation loss = 8.4264  \n",
      "\n",
      "Fold: 14  Epoch: 90  Training loss = 3.1937  Validation loss = 8.4251  \n",
      "\n",
      "Fold: 14  Epoch: 91  Training loss = 3.1936  Validation loss = 8.4248  \n",
      "\n",
      "Fold: 14  Epoch: 92  Training loss = 3.1930  Validation loss = 8.4236  \n",
      "\n",
      "Fold: 14  Epoch: 93  Training loss = 3.1924  Validation loss = 8.4223  \n",
      "\n",
      "Fold: 14  Epoch: 94  Training loss = 3.1919  Validation loss = 8.4213  \n",
      "\n",
      "Fold: 14  Epoch: 95  Training loss = 3.1915  Validation loss = 8.4204  \n",
      "\n",
      "Fold: 14  Epoch: 96  Training loss = 3.1910  Validation loss = 8.4193  \n",
      "\n",
      "Fold: 14  Epoch: 97  Training loss = 3.1904  Validation loss = 8.4180  \n",
      "\n",
      "Fold: 14  Epoch: 98  Training loss = 3.1900  Validation loss = 8.4171  \n",
      "\n",
      "Fold: 14  Epoch: 99  Training loss = 3.1895  Validation loss = 8.4161  \n",
      "\n",
      "Fold: 14  Epoch: 100  Training loss = 3.1888  Validation loss = 8.4146  \n",
      "\n",
      "Fold: 14  Epoch: 101  Training loss = 3.1882  Validation loss = 8.4135  \n",
      "\n",
      "Fold: 14  Epoch: 102  Training loss = 3.1876  Validation loss = 8.4122  \n",
      "\n",
      "Fold: 14  Epoch: 103  Training loss = 3.1872  Validation loss = 8.4113  \n",
      "\n",
      "Fold: 14  Epoch: 104  Training loss = 3.1869  Validation loss = 8.4106  \n",
      "\n",
      "Fold: 14  Epoch: 105  Training loss = 3.1864  Validation loss = 8.4095  \n",
      "\n",
      "Fold: 14  Epoch: 106  Training loss = 3.1859  Validation loss = 8.4083  \n",
      "\n",
      "Fold: 14  Epoch: 107  Training loss = 3.1855  Validation loss = 8.4076  \n",
      "\n",
      "Fold: 14  Epoch: 108  Training loss = 3.1851  Validation loss = 8.4067  \n",
      "\n",
      "Fold: 14  Epoch: 109  Training loss = 3.1846  Validation loss = 8.4056  \n",
      "\n",
      "Fold: 14  Epoch: 110  Training loss = 3.1841  Validation loss = 8.4045  \n",
      "\n",
      "Fold: 14  Epoch: 111  Training loss = 3.1837  Validation loss = 8.4036  \n",
      "\n",
      "Fold: 14  Epoch: 112  Training loss = 3.1832  Validation loss = 8.4025  \n",
      "\n",
      "Fold: 14  Epoch: 113  Training loss = 3.1826  Validation loss = 8.4014  \n",
      "\n",
      "Fold: 14  Epoch: 114  Training loss = 3.1821  Validation loss = 8.4002  \n",
      "\n",
      "Fold: 14  Epoch: 115  Training loss = 3.1816  Validation loss = 8.3991  \n",
      "\n",
      "Fold: 14  Epoch: 116  Training loss = 3.1811  Validation loss = 8.3980  \n",
      "\n",
      "Fold: 14  Epoch: 117  Training loss = 3.1805  Validation loss = 8.3968  \n",
      "\n",
      "Fold: 14  Epoch: 118  Training loss = 3.1800  Validation loss = 8.3958  \n",
      "\n",
      "Fold: 14  Epoch: 119  Training loss = 3.1796  Validation loss = 8.3949  \n",
      "\n",
      "Fold: 14  Epoch: 120  Training loss = 3.1791  Validation loss = 8.3938  \n",
      "\n",
      "Fold: 14  Epoch: 121  Training loss = 3.1786  Validation loss = 8.3927  \n",
      "\n",
      "Fold: 14  Epoch: 122  Training loss = 3.1782  Validation loss = 8.3919  \n",
      "\n",
      "Fold: 14  Epoch: 123  Training loss = 3.1777  Validation loss = 8.3908  \n",
      "\n",
      "Fold: 14  Epoch: 124  Training loss = 3.1773  Validation loss = 8.3899  \n",
      "\n",
      "Fold: 14  Epoch: 125  Training loss = 3.1769  Validation loss = 8.3890  \n",
      "\n",
      "Fold: 14  Epoch: 126  Training loss = 3.1764  Validation loss = 8.3879  \n",
      "\n",
      "Fold: 14  Epoch: 127  Training loss = 3.1761  Validation loss = 8.3872  \n",
      "\n",
      "Fold: 14  Epoch: 128  Training loss = 3.1756  Validation loss = 8.3863  \n",
      "\n",
      "Fold: 14  Epoch: 129  Training loss = 3.1751  Validation loss = 8.3852  \n",
      "\n",
      "Fold: 14  Epoch: 130  Training loss = 3.1745  Validation loss = 8.3839  \n",
      "\n",
      "Fold: 14  Epoch: 131  Training loss = 3.1741  Validation loss = 8.3830  \n",
      "\n",
      "Fold: 14  Epoch: 132  Training loss = 3.1736  Validation loss = 8.3818  \n",
      "\n",
      "Fold: 14  Epoch: 133  Training loss = 3.1731  Validation loss = 8.3807  \n",
      "\n",
      "Fold: 14  Epoch: 134  Training loss = 3.1727  Validation loss = 8.3798  \n",
      "\n",
      "Fold: 14  Epoch: 135  Training loss = 3.1722  Validation loss = 8.3789  \n",
      "\n",
      "Fold: 14  Epoch: 136  Training loss = 3.1716  Validation loss = 8.3775  \n",
      "\n",
      "Fold: 14  Epoch: 137  Training loss = 3.1711  Validation loss = 8.3764  \n",
      "\n",
      "Fold: 14  Epoch: 138  Training loss = 3.1707  Validation loss = 8.3755  \n",
      "\n",
      "Fold: 14  Epoch: 139  Training loss = 3.1703  Validation loss = 8.3747  \n",
      "\n",
      "Fold: 14  Epoch: 140  Training loss = 3.1697  Validation loss = 8.3733  \n",
      "\n",
      "Fold: 14  Epoch: 141  Training loss = 3.1691  Validation loss = 8.3722  \n",
      "\n",
      "Fold: 14  Epoch: 142  Training loss = 3.1686  Validation loss = 8.3710  \n",
      "\n",
      "Fold: 14  Epoch: 143  Training loss = 3.1681  Validation loss = 8.3700  \n",
      "\n",
      "Fold: 14  Epoch: 144  Training loss = 3.1676  Validation loss = 8.3689  \n",
      "\n",
      "Fold: 14  Epoch: 145  Training loss = 3.1672  Validation loss = 8.3679  \n",
      "\n",
      "Fold: 14  Epoch: 146  Training loss = 3.1667  Validation loss = 8.3670  \n",
      "\n",
      "Fold: 14  Epoch: 147  Training loss = 3.1662  Validation loss = 8.3657  \n",
      "\n",
      "Fold: 14  Epoch: 148  Training loss = 3.1657  Validation loss = 8.3647  \n",
      "\n",
      "Fold: 14  Epoch: 149  Training loss = 3.1651  Validation loss = 8.3633  \n",
      "\n",
      "Fold: 14  Epoch: 150  Training loss = 3.1648  Validation loss = 8.3627  \n",
      "\n",
      "Fold: 14  Epoch: 151  Training loss = 3.1644  Validation loss = 8.3619  \n",
      "\n",
      "Fold: 14  Epoch: 152  Training loss = 3.1639  Validation loss = 8.3607  \n",
      "\n",
      "Fold: 14  Epoch: 153  Training loss = 3.1634  Validation loss = 8.3595  \n",
      "\n",
      "Fold: 14  Epoch: 154  Training loss = 3.1629  Validation loss = 8.3585  \n",
      "\n",
      "Fold: 14  Epoch: 155  Training loss = 3.1624  Validation loss = 8.3575  \n",
      "\n",
      "Fold: 14  Epoch: 156  Training loss = 3.1620  Validation loss = 8.3565  \n",
      "\n",
      "Fold: 14  Epoch: 157  Training loss = 3.1616  Validation loss = 8.3556  \n",
      "\n",
      "Fold: 14  Epoch: 158  Training loss = 3.1611  Validation loss = 8.3545  \n",
      "\n",
      "Fold: 14  Epoch: 159  Training loss = 3.1607  Validation loss = 8.3536  \n",
      "\n",
      "Fold: 14  Epoch: 160  Training loss = 3.1602  Validation loss = 8.3526  \n",
      "\n",
      "Fold: 14  Epoch: 161  Training loss = 3.1596  Validation loss = 8.3512  \n",
      "\n",
      "Fold: 14  Epoch: 162  Training loss = 3.1591  Validation loss = 8.3502  \n",
      "\n",
      "Fold: 14  Epoch: 163  Training loss = 3.1587  Validation loss = 8.3492  \n",
      "\n",
      "Fold: 14  Epoch: 164  Training loss = 3.1581  Validation loss = 8.3479  \n",
      "\n",
      "Fold: 14  Epoch: 165  Training loss = 3.1577  Validation loss = 8.3471  \n",
      "\n",
      "Fold: 14  Epoch: 166  Training loss = 3.1573  Validation loss = 8.3461  \n",
      "\n",
      "Fold: 14  Epoch: 167  Training loss = 3.1567  Validation loss = 8.3450  \n",
      "\n",
      "Fold: 14  Epoch: 168  Training loss = 3.1562  Validation loss = 8.3438  \n",
      "\n",
      "Fold: 14  Epoch: 169  Training loss = 3.1556  Validation loss = 8.3425  \n",
      "\n",
      "Fold: 14  Epoch: 170  Training loss = 3.1552  Validation loss = 8.3416  \n",
      "\n",
      "Fold: 14  Epoch: 171  Training loss = 3.1546  Validation loss = 8.3403  \n",
      "\n",
      "Fold: 14  Epoch: 172  Training loss = 3.1543  Validation loss = 8.3396  \n",
      "\n",
      "Fold: 14  Epoch: 173  Training loss = 3.1538  Validation loss = 8.3385  \n",
      "\n",
      "Fold: 14  Epoch: 174  Training loss = 3.1533  Validation loss = 8.3375  \n",
      "\n",
      "Fold: 14  Epoch: 175  Training loss = 3.1526  Validation loss = 8.3359  \n",
      "\n",
      "Fold: 14  Epoch: 176  Training loss = 3.1522  Validation loss = 8.3350  \n",
      "\n",
      "Fold: 14  Epoch: 177  Training loss = 3.1518  Validation loss = 8.3342  \n",
      "\n",
      "Fold: 14  Epoch: 178  Training loss = 3.1514  Validation loss = 8.3332  \n",
      "\n",
      "Fold: 14  Epoch: 179  Training loss = 3.1509  Validation loss = 8.3322  \n",
      "\n",
      "Fold: 14  Epoch: 180  Training loss = 3.1505  Validation loss = 8.3313  \n",
      "\n",
      "Fold: 14  Epoch: 181  Training loss = 3.1500  Validation loss = 8.3303  \n",
      "\n",
      "Fold: 14  Epoch: 182  Training loss = 3.1496  Validation loss = 8.3292  \n",
      "\n",
      "Fold: 14  Epoch: 183  Training loss = 3.1491  Validation loss = 8.3280  \n",
      "\n",
      "Fold: 14  Epoch: 184  Training loss = 3.1486  Validation loss = 8.3270  \n",
      "\n",
      "Fold: 14  Epoch: 185  Training loss = 3.1482  Validation loss = 8.3261  \n",
      "\n",
      "Fold: 14  Epoch: 186  Training loss = 3.1477  Validation loss = 8.3251  \n",
      "\n",
      "Fold: 14  Epoch: 187  Training loss = 3.1473  Validation loss = 8.3242  \n",
      "\n",
      "Fold: 14  Epoch: 188  Training loss = 3.1469  Validation loss = 8.3233  \n",
      "\n",
      "Fold: 14  Epoch: 189  Training loss = 3.1464  Validation loss = 8.3221  \n",
      "\n",
      "Fold: 14  Epoch: 190  Training loss = 3.1461  Validation loss = 8.3214  \n",
      "\n",
      "Fold: 14  Epoch: 191  Training loss = 3.1457  Validation loss = 8.3205  \n",
      "\n",
      "Fold: 14  Epoch: 192  Training loss = 3.1451  Validation loss = 8.3191  \n",
      "\n",
      "Fold: 14  Epoch: 193  Training loss = 3.1446  Validation loss = 8.3182  \n",
      "\n",
      "Fold: 14  Epoch: 194  Training loss = 3.1443  Validation loss = 8.3175  \n",
      "\n",
      "Fold: 14  Epoch: 195  Training loss = 3.1438  Validation loss = 8.3164  \n",
      "\n",
      "Fold: 14  Epoch: 196  Training loss = 3.1434  Validation loss = 8.3155  \n",
      "\n",
      "Fold: 14  Epoch: 197  Training loss = 3.1430  Validation loss = 8.3146  \n",
      "\n",
      "Fold: 14  Epoch: 198  Training loss = 3.1426  Validation loss = 8.3137  \n",
      "\n",
      "Fold: 14  Epoch: 199  Training loss = 3.1421  Validation loss = 8.3125  \n",
      "\n",
      "Fold: 14  Epoch: 200  Training loss = 3.1417  Validation loss = 8.3116  \n",
      "\n",
      "Fold: 14  Epoch: 201  Training loss = 3.1412  Validation loss = 8.3105  \n",
      "\n",
      "Fold: 14  Epoch: 202  Training loss = 3.1406  Validation loss = 8.3093  \n",
      "\n",
      "Fold: 14  Epoch: 203  Training loss = 3.1400  Validation loss = 8.3079  \n",
      "\n",
      "Fold: 14  Epoch: 204  Training loss = 3.1394  Validation loss = 8.3066  \n",
      "\n",
      "Fold: 14  Epoch: 205  Training loss = 3.1390  Validation loss = 8.3056  \n",
      "\n",
      "Fold: 14  Epoch: 206  Training loss = 3.1386  Validation loss = 8.3047  \n",
      "\n",
      "Fold: 14  Epoch: 207  Training loss = 3.1382  Validation loss = 8.3038  \n",
      "\n",
      "Fold: 14  Epoch: 208  Training loss = 3.1377  Validation loss = 8.3027  \n",
      "\n",
      "Fold: 14  Epoch: 209  Training loss = 3.1373  Validation loss = 8.3019  \n",
      "\n",
      "Fold: 14  Epoch: 210  Training loss = 3.1370  Validation loss = 8.3011  \n",
      "\n",
      "Fold: 14  Epoch: 211  Training loss = 3.1365  Validation loss = 8.3000  \n",
      "\n",
      "Fold: 14  Epoch: 212  Training loss = 3.1363  Validation loss = 8.2996  \n",
      "\n",
      "Fold: 14  Epoch: 213  Training loss = 3.1360  Validation loss = 8.2988  \n",
      "\n",
      "Fold: 14  Epoch: 214  Training loss = 3.1355  Validation loss = 8.2976  \n",
      "\n",
      "Fold: 14  Epoch: 215  Training loss = 3.1350  Validation loss = 8.2965  \n",
      "\n",
      "Fold: 14  Epoch: 216  Training loss = 3.1343  Validation loss = 8.2950  \n",
      "\n",
      "Fold: 14  Epoch: 217  Training loss = 3.1338  Validation loss = 8.2939  \n",
      "\n",
      "Fold: 14  Epoch: 218  Training loss = 3.1334  Validation loss = 8.2930  \n",
      "\n",
      "Fold: 14  Epoch: 219  Training loss = 3.1331  Validation loss = 8.2923  \n",
      "\n",
      "Fold: 14  Epoch: 220  Training loss = 3.1326  Validation loss = 8.2913  \n",
      "\n",
      "Fold: 14  Epoch: 221  Training loss = 3.1322  Validation loss = 8.2903  \n",
      "\n",
      "Fold: 14  Epoch: 222  Training loss = 3.1316  Validation loss = 8.2890  \n",
      "\n",
      "Fold: 14  Epoch: 223  Training loss = 3.1313  Validation loss = 8.2882  \n",
      "\n",
      "Fold: 14  Epoch: 224  Training loss = 3.1309  Validation loss = 8.2872  \n",
      "\n",
      "Fold: 14  Epoch: 225  Training loss = 3.1303  Validation loss = 8.2860  \n",
      "\n",
      "Fold: 14  Epoch: 226  Training loss = 3.1298  Validation loss = 8.2849  \n",
      "\n",
      "Fold: 14  Epoch: 227  Training loss = 3.1293  Validation loss = 8.2837  \n",
      "\n",
      "Fold: 14  Epoch: 228  Training loss = 3.1287  Validation loss = 8.2825  \n",
      "\n",
      "Fold: 14  Epoch: 229  Training loss = 3.1282  Validation loss = 8.2812  \n",
      "\n",
      "Fold: 14  Epoch: 230  Training loss = 3.1277  Validation loss = 8.2801  \n",
      "\n",
      "Fold: 14  Epoch: 231  Training loss = 3.1272  Validation loss = 8.2790  \n",
      "\n",
      "Fold: 14  Epoch: 232  Training loss = 3.1269  Validation loss = 8.2782  \n",
      "\n",
      "Fold: 14  Epoch: 233  Training loss = 3.1264  Validation loss = 8.2771  \n",
      "\n",
      "Fold: 14  Epoch: 234  Training loss = 3.1260  Validation loss = 8.2763  \n",
      "\n",
      "Fold: 14  Epoch: 235  Training loss = 3.1256  Validation loss = 8.2754  \n",
      "\n",
      "Fold: 14  Epoch: 236  Training loss = 3.1251  Validation loss = 8.2741  \n",
      "\n",
      "Fold: 14  Epoch: 237  Training loss = 3.1247  Validation loss = 8.2733  \n",
      "\n",
      "Fold: 14  Epoch: 238  Training loss = 3.1242  Validation loss = 8.2721  \n",
      "\n",
      "Fold: 14  Epoch: 239  Training loss = 3.1238  Validation loss = 8.2712  \n",
      "\n",
      "Fold: 14  Epoch: 240  Training loss = 3.1232  Validation loss = 8.2699  \n",
      "\n",
      "Fold: 14  Epoch: 241  Training loss = 3.1228  Validation loss = 8.2689  \n",
      "\n",
      "Fold: 14  Epoch: 242  Training loss = 3.1223  Validation loss = 8.2677  \n",
      "\n",
      "Fold: 14  Epoch: 243  Training loss = 3.1219  Validation loss = 8.2668  \n",
      "\n",
      "Fold: 14  Epoch: 244  Training loss = 3.1215  Validation loss = 8.2659  \n",
      "\n",
      "Fold: 14  Epoch: 245  Training loss = 3.1210  Validation loss = 8.2648  \n",
      "\n",
      "Fold: 14  Epoch: 246  Training loss = 3.1205  Validation loss = 8.2636  \n",
      "\n",
      "Fold: 14  Epoch: 247  Training loss = 3.1198  Validation loss = 8.2621  \n",
      "\n",
      "Fold: 14  Epoch: 248  Training loss = 3.1193  Validation loss = 8.2608  \n",
      "\n",
      "Fold: 14  Epoch: 249  Training loss = 3.1188  Validation loss = 8.2597  \n",
      "\n",
      "Fold: 14  Epoch: 250  Training loss = 3.1184  Validation loss = 8.2589  \n",
      "\n",
      "Fold: 14  Epoch: 251  Training loss = 3.1180  Validation loss = 8.2579  \n",
      "\n",
      "Fold: 14  Epoch: 252  Training loss = 3.1174  Validation loss = 8.2566  \n",
      "\n",
      "Fold: 14  Epoch: 253  Training loss = 3.1168  Validation loss = 8.2553  \n",
      "\n",
      "Fold: 14  Epoch: 254  Training loss = 3.1163  Validation loss = 8.2540  \n",
      "\n",
      "Fold: 14  Epoch: 255  Training loss = 3.1157  Validation loss = 8.2528  \n",
      "\n",
      "Fold: 14  Epoch: 256  Training loss = 3.1153  Validation loss = 8.2517  \n",
      "\n",
      "Fold: 14  Epoch: 257  Training loss = 3.1148  Validation loss = 8.2505  \n",
      "\n",
      "Fold: 14  Epoch: 258  Training loss = 3.1143  Validation loss = 8.2496  \n",
      "\n",
      "Fold: 14  Epoch: 259  Training loss = 3.1138  Validation loss = 8.2483  \n",
      "\n",
      "Fold: 14  Epoch: 260  Training loss = 3.1132  Validation loss = 8.2469  \n",
      "\n",
      "Fold: 14  Epoch: 261  Training loss = 3.1125  Validation loss = 8.2453  \n",
      "\n",
      "Fold: 14  Epoch: 262  Training loss = 3.1120  Validation loss = 8.2443  \n",
      "\n",
      "Fold: 14  Epoch: 263  Training loss = 3.1114  Validation loss = 8.2428  \n",
      "\n",
      "Fold: 14  Epoch: 264  Training loss = 3.1108  Validation loss = 8.2415  \n",
      "\n",
      "Fold: 14  Epoch: 265  Training loss = 3.1105  Validation loss = 8.2407  \n",
      "\n",
      "Fold: 14  Epoch: 266  Training loss = 3.1100  Validation loss = 8.2396  \n",
      "\n",
      "Fold: 14  Epoch: 267  Training loss = 3.1094  Validation loss = 8.2382  \n",
      "\n",
      "Fold: 14  Epoch: 268  Training loss = 3.1091  Validation loss = 8.2375  \n",
      "\n",
      "Fold: 14  Epoch: 269  Training loss = 3.1087  Validation loss = 8.2366  \n",
      "\n",
      "Fold: 14  Epoch: 270  Training loss = 3.1083  Validation loss = 8.2356  \n",
      "\n",
      "Fold: 14  Epoch: 271  Training loss = 3.1079  Validation loss = 8.2347  \n",
      "\n",
      "Fold: 14  Epoch: 272  Training loss = 3.1076  Validation loss = 8.2340  \n",
      "\n",
      "Fold: 14  Epoch: 273  Training loss = 3.1072  Validation loss = 8.2331  \n",
      "\n",
      "Fold: 14  Epoch: 274  Training loss = 3.1067  Validation loss = 8.2318  \n",
      "\n",
      "Fold: 14  Epoch: 275  Training loss = 3.1062  Validation loss = 8.2307  \n",
      "\n",
      "Fold: 14  Epoch: 276  Training loss = 3.1057  Validation loss = 8.2297  \n",
      "\n",
      "Fold: 14  Epoch: 277  Training loss = 3.1053  Validation loss = 8.2288  \n",
      "\n",
      "Fold: 14  Epoch: 278  Training loss = 3.1049  Validation loss = 8.2277  \n",
      "\n",
      "Fold: 14  Epoch: 279  Training loss = 3.1044  Validation loss = 8.2266  \n",
      "\n",
      "Fold: 14  Epoch: 280  Training loss = 3.1040  Validation loss = 8.2258  \n",
      "\n",
      "Fold: 14  Epoch: 281  Training loss = 3.1035  Validation loss = 8.2245  \n",
      "\n",
      "Fold: 14  Epoch: 282  Training loss = 3.1029  Validation loss = 8.2232  \n",
      "\n",
      "Fold: 14  Epoch: 283  Training loss = 3.1024  Validation loss = 8.2221  \n",
      "\n",
      "Fold: 14  Epoch: 284  Training loss = 3.1021  Validation loss = 8.2212  \n",
      "\n",
      "Fold: 14  Epoch: 285  Training loss = 3.1018  Validation loss = 8.2205  \n",
      "\n",
      "Fold: 14  Epoch: 286  Training loss = 3.1016  Validation loss = 8.2201  \n",
      "\n",
      "Fold: 14  Epoch: 287  Training loss = 3.1012  Validation loss = 8.2192  \n",
      "\n",
      "Fold: 14  Epoch: 288  Training loss = 3.1007  Validation loss = 8.2182  \n",
      "\n",
      "Fold: 14  Epoch: 289  Training loss = 3.1004  Validation loss = 8.2173  \n",
      "\n",
      "Fold: 14  Epoch: 290  Training loss = 3.1002  Validation loss = 8.2170  \n",
      "\n",
      "Fold: 14  Epoch: 291  Training loss = 3.0997  Validation loss = 8.2158  \n",
      "\n",
      "Fold: 14  Epoch: 292  Training loss = 3.0992  Validation loss = 8.2145  \n",
      "\n",
      "Fold: 14  Epoch: 293  Training loss = 3.0989  Validation loss = 8.2140  \n",
      "\n",
      "Fold: 14  Epoch: 294  Training loss = 3.0986  Validation loss = 8.2132  \n",
      "\n",
      "Fold: 14  Epoch: 295  Training loss = 3.0982  Validation loss = 8.2122  \n",
      "\n",
      "Fold: 14  Epoch: 296  Training loss = 3.0977  Validation loss = 8.2111  \n",
      "\n",
      "Fold: 14  Epoch: 297  Training loss = 3.0973  Validation loss = 8.2101  \n",
      "\n",
      "Fold: 14  Epoch: 298  Training loss = 3.0969  Validation loss = 8.2091  \n",
      "\n",
      "Fold: 14  Epoch: 299  Training loss = 3.0964  Validation loss = 8.2081  \n",
      "\n",
      "Fold: 14  Epoch: 300  Training loss = 3.0959  Validation loss = 8.2070  \n",
      "\n",
      "Fold: 14  Epoch: 301  Training loss = 3.0955  Validation loss = 8.2060  \n",
      "\n",
      "Fold: 14  Epoch: 302  Training loss = 3.0952  Validation loss = 8.2053  \n",
      "\n",
      "Fold: 14  Epoch: 303  Training loss = 3.0947  Validation loss = 8.2042  \n",
      "\n",
      "Fold: 14  Epoch: 304  Training loss = 3.0944  Validation loss = 8.2034  \n",
      "\n",
      "Fold: 14  Epoch: 305  Training loss = 3.0939  Validation loss = 8.2022  \n",
      "\n",
      "Fold: 14  Epoch: 306  Training loss = 3.0937  Validation loss = 8.2017  \n",
      "\n",
      "Fold: 14  Epoch: 307  Training loss = 3.0931  Validation loss = 8.2003  \n",
      "\n",
      "Fold: 14  Epoch: 308  Training loss = 3.0927  Validation loss = 8.1994  \n",
      "\n",
      "Fold: 14  Epoch: 309  Training loss = 3.0922  Validation loss = 8.1983  \n",
      "\n",
      "Fold: 14  Epoch: 310  Training loss = 3.0919  Validation loss = 8.1976  \n",
      "\n",
      "Fold: 14  Epoch: 311  Training loss = 3.0914  Validation loss = 8.1965  \n",
      "\n",
      "Fold: 14  Epoch: 312  Training loss = 3.0910  Validation loss = 8.1954  \n",
      "\n",
      "Fold: 14  Epoch: 313  Training loss = 3.0906  Validation loss = 8.1945  \n",
      "\n",
      "Fold: 14  Epoch: 314  Training loss = 3.0901  Validation loss = 8.1933  \n",
      "\n",
      "Fold: 14  Epoch: 315  Training loss = 3.0896  Validation loss = 8.1922  \n",
      "\n",
      "Fold: 14  Epoch: 316  Training loss = 3.0892  Validation loss = 8.1913  \n",
      "\n",
      "Fold: 14  Epoch: 317  Training loss = 3.0889  Validation loss = 8.1904  \n",
      "\n",
      "Fold: 14  Epoch: 318  Training loss = 3.0884  Validation loss = 8.1895  \n",
      "\n",
      "Fold: 14  Epoch: 319  Training loss = 3.0880  Validation loss = 8.1884  \n",
      "\n",
      "Fold: 14  Epoch: 320  Training loss = 3.0875  Validation loss = 8.1872  \n",
      "\n",
      "Fold: 14  Epoch: 321  Training loss = 3.0870  Validation loss = 8.1861  \n",
      "\n",
      "Fold: 14  Epoch: 322  Training loss = 3.0866  Validation loss = 8.1851  \n",
      "\n",
      "Fold: 14  Epoch: 323  Training loss = 3.0861  Validation loss = 8.1839  \n",
      "\n",
      "Fold: 14  Epoch: 324  Training loss = 3.0857  Validation loss = 8.1828  \n",
      "\n",
      "Fold: 14  Epoch: 325  Training loss = 3.0852  Validation loss = 8.1817  \n",
      "\n",
      "Fold: 14  Epoch: 326  Training loss = 3.0848  Validation loss = 8.1809  \n",
      "\n",
      "Fold: 14  Epoch: 327  Training loss = 3.0844  Validation loss = 8.1799  \n",
      "\n",
      "Fold: 14  Epoch: 328  Training loss = 3.0840  Validation loss = 8.1789  \n",
      "\n",
      "Fold: 14  Epoch: 329  Training loss = 3.0837  Validation loss = 8.1782  \n",
      "\n",
      "Fold: 14  Epoch: 330  Training loss = 3.0834  Validation loss = 8.1774  \n",
      "\n",
      "Fold: 14  Epoch: 331  Training loss = 3.0830  Validation loss = 8.1765  \n",
      "\n",
      "Fold: 14  Epoch: 332  Training loss = 3.0826  Validation loss = 8.1756  \n",
      "\n",
      "Fold: 14  Epoch: 333  Training loss = 3.0823  Validation loss = 8.1748  \n",
      "\n",
      "Fold: 14  Epoch: 334  Training loss = 3.0821  Validation loss = 8.1743  \n",
      "\n",
      "Fold: 14  Epoch: 335  Training loss = 3.0815  Validation loss = 8.1730  \n",
      "\n",
      "Fold: 14  Epoch: 336  Training loss = 3.0812  Validation loss = 8.1722  \n",
      "\n",
      "Fold: 14  Epoch: 337  Training loss = 3.0808  Validation loss = 8.1711  \n",
      "\n",
      "Fold: 14  Epoch: 338  Training loss = 3.0804  Validation loss = 8.1702  \n",
      "\n",
      "Fold: 14  Epoch: 339  Training loss = 3.0799  Validation loss = 8.1692  \n",
      "\n",
      "Fold: 14  Epoch: 340  Training loss = 3.0795  Validation loss = 8.1682  \n",
      "\n",
      "Fold: 14  Epoch: 341  Training loss = 3.0791  Validation loss = 8.1672  \n",
      "\n",
      "Fold: 14  Epoch: 342  Training loss = 3.0786  Validation loss = 8.1660  \n",
      "\n",
      "Fold: 14  Epoch: 343  Training loss = 3.0782  Validation loss = 8.1652  \n",
      "\n",
      "Fold: 14  Epoch: 344  Training loss = 3.0779  Validation loss = 8.1645  \n",
      "\n",
      "Fold: 14  Epoch: 345  Training loss = 3.0773  Validation loss = 8.1631  \n",
      "\n",
      "Fold: 14  Epoch: 346  Training loss = 3.0771  Validation loss = 8.1624  \n",
      "\n",
      "Fold: 14  Epoch: 347  Training loss = 3.0766  Validation loss = 8.1614  \n",
      "\n",
      "Fold: 14  Epoch: 348  Training loss = 3.0763  Validation loss = 8.1605  \n",
      "\n",
      "Fold: 14  Epoch: 349  Training loss = 3.0759  Validation loss = 8.1597  \n",
      "\n",
      "Fold: 14  Epoch: 350  Training loss = 3.0756  Validation loss = 8.1589  \n",
      "\n",
      "Fold: 14  Epoch: 351  Training loss = 3.0751  Validation loss = 8.1578  \n",
      "\n",
      "Fold: 14  Epoch: 352  Training loss = 3.0747  Validation loss = 8.1567  \n",
      "\n",
      "Fold: 14  Epoch: 353  Training loss = 3.0742  Validation loss = 8.1555  \n",
      "\n",
      "Fold: 14  Epoch: 354  Training loss = 3.0739  Validation loss = 8.1549  \n",
      "\n",
      "Fold: 14  Epoch: 355  Training loss = 3.0734  Validation loss = 8.1538  \n",
      "\n",
      "Fold: 14  Epoch: 356  Training loss = 3.0730  Validation loss = 8.1527  \n",
      "\n",
      "Fold: 14  Epoch: 357  Training loss = 3.0726  Validation loss = 8.1518  \n",
      "\n",
      "Fold: 14  Epoch: 358  Training loss = 3.0722  Validation loss = 8.1508  \n",
      "\n",
      "Fold: 14  Epoch: 359  Training loss = 3.0717  Validation loss = 8.1498  \n",
      "\n",
      "Fold: 14  Epoch: 360  Training loss = 3.0711  Validation loss = 8.1484  \n",
      "\n",
      "Fold: 14  Epoch: 361  Training loss = 3.0707  Validation loss = 8.1473  \n",
      "\n",
      "Fold: 14  Epoch: 362  Training loss = 3.0702  Validation loss = 8.1463  \n",
      "\n",
      "Fold: 14  Epoch: 363  Training loss = 3.0698  Validation loss = 8.1454  \n",
      "\n",
      "Fold: 14  Epoch: 364  Training loss = 3.0693  Validation loss = 8.1439  \n",
      "\n",
      "Fold: 14  Epoch: 365  Training loss = 3.0688  Validation loss = 8.1430  \n",
      "\n",
      "Fold: 14  Epoch: 366  Training loss = 3.0685  Validation loss = 8.1421  \n",
      "\n",
      "Fold: 14  Epoch: 367  Training loss = 3.0680  Validation loss = 8.1411  \n",
      "\n",
      "Fold: 14  Epoch: 368  Training loss = 3.0677  Validation loss = 8.1404  \n",
      "\n",
      "Fold: 14  Epoch: 369  Training loss = 3.0674  Validation loss = 8.1397  \n",
      "\n",
      "Fold: 14  Epoch: 370  Training loss = 3.0668  Validation loss = 8.1382  \n",
      "\n",
      "Fold: 14  Epoch: 371  Training loss = 3.0663  Validation loss = 8.1371  \n",
      "\n",
      "Fold: 14  Epoch: 372  Training loss = 3.0659  Validation loss = 8.1364  \n",
      "\n",
      "Fold: 14  Epoch: 373  Training loss = 3.0656  Validation loss = 8.1356  \n",
      "\n",
      "Fold: 14  Epoch: 374  Training loss = 3.0651  Validation loss = 8.1344  \n",
      "\n",
      "Fold: 14  Epoch: 375  Training loss = 3.0646  Validation loss = 8.1336  \n",
      "\n",
      "Fold: 14  Epoch: 376  Training loss = 3.0643  Validation loss = 8.1330  \n",
      "\n",
      "Fold: 14  Epoch: 377  Training loss = 3.0640  Validation loss = 8.1323  \n",
      "\n",
      "Fold: 14  Epoch: 378  Training loss = 3.0636  Validation loss = 8.1314  \n",
      "\n",
      "Fold: 14  Epoch: 379  Training loss = 3.0623  Validation loss = 8.1299  \n",
      "\n",
      "Fold: 14  Epoch: 380  Training loss = 3.0613  Validation loss = 8.1291  \n",
      "\n",
      "Fold: 14  Epoch: 381  Training loss = 3.0599  Validation loss = 8.1277  \n",
      "\n",
      "Fold: 14  Epoch: 382  Training loss = 3.0589  Validation loss = 8.1269  \n",
      "\n",
      "Fold: 14  Epoch: 383  Training loss = 3.0581  Validation loss = 8.1258  \n",
      "\n",
      "Fold: 14  Epoch: 384  Training loss = 3.0574  Validation loss = 8.1247  \n",
      "\n",
      "Fold: 14  Epoch: 385  Training loss = 3.0571  Validation loss = 8.1241  \n",
      "\n",
      "Fold: 14  Epoch: 386  Training loss = 3.0566  Validation loss = 8.1231  \n",
      "\n",
      "Fold: 14  Epoch: 387  Training loss = 3.0562  Validation loss = 8.1223  \n",
      "\n",
      "Fold: 14  Epoch: 388  Training loss = 3.0558  Validation loss = 8.1215  \n",
      "\n",
      "Fold: 14  Epoch: 389  Training loss = 3.0553  Validation loss = 8.1204  \n",
      "\n",
      "Fold: 14  Epoch: 390  Training loss = 3.0549  Validation loss = 8.1195  \n",
      "\n",
      "Fold: 14  Epoch: 391  Training loss = 3.0544  Validation loss = 8.1183  \n",
      "\n",
      "Fold: 14  Epoch: 392  Training loss = 3.0539  Validation loss = 8.1171  \n",
      "\n",
      "Fold: 14  Epoch: 393  Training loss = 3.0535  Validation loss = 8.1162  \n",
      "\n",
      "Fold: 14  Epoch: 394  Training loss = 3.0533  Validation loss = 8.1157  \n",
      "\n",
      "Fold: 14  Epoch: 395  Training loss = 3.0531  Validation loss = 8.1152  \n",
      "\n",
      "Fold: 14  Epoch: 396  Training loss = 3.0528  Validation loss = 8.1144  \n",
      "\n",
      "Fold: 14  Epoch: 397  Training loss = 3.0524  Validation loss = 8.1135  \n",
      "\n",
      "Fold: 14  Epoch: 398  Training loss = 3.0520  Validation loss = 8.1125  \n",
      "\n",
      "Fold: 14  Epoch: 399  Training loss = 3.0516  Validation loss = 8.1116  \n",
      "\n",
      "Fold: 14  Epoch: 400  Training loss = 3.0513  Validation loss = 8.1108  \n",
      "\n",
      "Fold: 14  Epoch: 401  Training loss = 3.0508  Validation loss = 8.1097  \n",
      "\n",
      "Fold: 14  Epoch: 402  Training loss = 3.0504  Validation loss = 8.1086  \n",
      "\n",
      "Fold: 14  Epoch: 403  Training loss = 3.0501  Validation loss = 8.1080  \n",
      "\n",
      "Fold: 14  Epoch: 404  Training loss = 3.0497  Validation loss = 8.1070  \n",
      "\n",
      "Fold: 14  Epoch: 405  Training loss = 3.0492  Validation loss = 8.1058  \n",
      "\n",
      "Fold: 14  Epoch: 406  Training loss = 3.0490  Validation loss = 8.1052  \n",
      "\n",
      "Fold: 14  Epoch: 407  Training loss = 3.0487  Validation loss = 8.1046  \n",
      "\n",
      "Fold: 14  Epoch: 408  Training loss = 3.0482  Validation loss = 8.1033  \n",
      "\n",
      "Fold: 14  Epoch: 409  Training loss = 3.0478  Validation loss = 8.1023  \n",
      "\n",
      "Fold: 14  Epoch: 410  Training loss = 3.0475  Validation loss = 8.1015  \n",
      "\n",
      "Fold: 14  Epoch: 411  Training loss = 3.0471  Validation loss = 8.1006  \n",
      "\n",
      "Fold: 14  Epoch: 412  Training loss = 3.0466  Validation loss = 8.0994  \n",
      "\n",
      "Fold: 14  Epoch: 413  Training loss = 3.0462  Validation loss = 8.0984  \n",
      "\n",
      "Fold: 14  Epoch: 414  Training loss = 3.0457  Validation loss = 8.0973  \n",
      "\n",
      "Fold: 14  Epoch: 415  Training loss = 3.0454  Validation loss = 8.0964  \n",
      "\n",
      "Fold: 14  Epoch: 416  Training loss = 3.0450  Validation loss = 8.0955  \n",
      "\n",
      "Fold: 14  Epoch: 417  Training loss = 3.0446  Validation loss = 8.0946  \n",
      "\n",
      "Fold: 14  Epoch: 418  Training loss = 3.0444  Validation loss = 8.0941  \n",
      "\n",
      "Fold: 14  Epoch: 419  Training loss = 3.0439  Validation loss = 8.0929  \n",
      "\n",
      "Fold: 14  Epoch: 420  Training loss = 3.0436  Validation loss = 8.0922  \n",
      "\n",
      "Fold: 14  Epoch: 421  Training loss = 3.0432  Validation loss = 8.0911  \n",
      "\n",
      "Fold: 14  Epoch: 422  Training loss = 3.0427  Validation loss = 8.0900  \n",
      "\n",
      "Fold: 14  Epoch: 423  Training loss = 3.0424  Validation loss = 8.0892  \n",
      "\n",
      "Fold: 14  Epoch: 424  Training loss = 3.0420  Validation loss = 8.0882  \n",
      "\n",
      "Fold: 14  Epoch: 425  Training loss = 3.0416  Validation loss = 8.0872  \n",
      "\n",
      "Fold: 14  Epoch: 426  Training loss = 3.0411  Validation loss = 8.0861  \n",
      "\n",
      "Fold: 14  Epoch: 427  Training loss = 3.0407  Validation loss = 8.0851  \n",
      "\n",
      "Fold: 14  Epoch: 428  Training loss = 3.0403  Validation loss = 8.0842  \n",
      "\n",
      "Fold: 14  Epoch: 429  Training loss = 3.0399  Validation loss = 8.0831  \n",
      "\n",
      "Fold: 14  Epoch: 430  Training loss = 3.0394  Validation loss = 8.0820  \n",
      "\n",
      "Fold: 14  Epoch: 431  Training loss = 3.0391  Validation loss = 8.0811  \n",
      "\n",
      "Fold: 14  Epoch: 432  Training loss = 3.0387  Validation loss = 8.0802  \n",
      "\n",
      "Fold: 14  Epoch: 433  Training loss = 3.0386  Validation loss = 8.0799  \n",
      "\n",
      "Fold: 14  Epoch: 434  Training loss = 3.0383  Validation loss = 8.0793  \n",
      "\n",
      "Fold: 14  Epoch: 435  Training loss = 3.0379  Validation loss = 8.0782  \n",
      "\n",
      "Fold: 14  Epoch: 436  Training loss = 3.0376  Validation loss = 8.0775  \n",
      "\n",
      "Fold: 14  Epoch: 437  Training loss = 3.0372  Validation loss = 8.0766  \n",
      "\n",
      "Fold: 14  Epoch: 438  Training loss = 3.0368  Validation loss = 8.0756  \n",
      "\n",
      "Fold: 14  Epoch: 439  Training loss = 3.0365  Validation loss = 8.0748  \n",
      "\n",
      "Fold: 14  Epoch: 440  Training loss = 3.0363  Validation loss = 8.0742  \n",
      "\n",
      "Fold: 14  Epoch: 441  Training loss = 3.0358  Validation loss = 8.0730  \n",
      "\n",
      "Fold: 14  Epoch: 442  Training loss = 3.0353  Validation loss = 8.0718  \n",
      "\n",
      "Fold: 14  Epoch: 443  Training loss = 3.0349  Validation loss = 8.0709  \n",
      "\n",
      "Fold: 14  Epoch: 444  Training loss = 3.0346  Validation loss = 8.0700  \n",
      "\n",
      "Fold: 14  Epoch: 445  Training loss = 3.0343  Validation loss = 8.0692  \n",
      "\n",
      "Fold: 14  Epoch: 446  Training loss = 3.0338  Validation loss = 8.0681  \n",
      "\n",
      "Fold: 14  Epoch: 447  Training loss = 3.0335  Validation loss = 8.0674  \n",
      "\n",
      "Fold: 14  Epoch: 448  Training loss = 3.0331  Validation loss = 8.0664  \n",
      "\n",
      "Fold: 14  Epoch: 449  Training loss = 3.0327  Validation loss = 8.0654  \n",
      "\n",
      "Fold: 14  Epoch: 450  Training loss = 3.0323  Validation loss = 8.0645  \n",
      "\n",
      "Fold: 14  Epoch: 451  Training loss = 3.0320  Validation loss = 8.0637  \n",
      "\n",
      "Fold: 14  Epoch: 452  Training loss = 3.0318  Validation loss = 8.0631  \n",
      "\n",
      "Fold: 14  Epoch: 453  Training loss = 3.0313  Validation loss = 8.0619  \n",
      "\n",
      "Fold: 14  Epoch: 454  Training loss = 3.0308  Validation loss = 8.0607  \n",
      "\n",
      "Fold: 14  Epoch: 455  Training loss = 3.0305  Validation loss = 8.0600  \n",
      "\n",
      "Fold: 14  Epoch: 456  Training loss = 3.0301  Validation loss = 8.0590  \n",
      "\n",
      "Fold: 14  Epoch: 457  Training loss = 3.0297  Validation loss = 8.0580  \n",
      "\n",
      "Fold: 14  Epoch: 458  Training loss = 3.0293  Validation loss = 8.0569  \n",
      "\n",
      "Fold: 14  Epoch: 459  Training loss = 3.0287  Validation loss = 8.0555  \n",
      "\n",
      "Fold: 14  Epoch: 460  Training loss = 3.0284  Validation loss = 8.0547  \n",
      "\n",
      "Fold: 14  Epoch: 461  Training loss = 3.0281  Validation loss = 8.0541  \n",
      "\n",
      "Fold: 14  Epoch: 462  Training loss = 3.0276  Validation loss = 8.0529  \n",
      "\n",
      "Fold: 14  Epoch: 463  Training loss = 3.0274  Validation loss = 8.0522  \n",
      "\n",
      "Fold: 14  Epoch: 464  Training loss = 3.0271  Validation loss = 8.0515  \n",
      "\n",
      "Fold: 14  Epoch: 465  Training loss = 3.0267  Validation loss = 8.0505  \n",
      "\n",
      "Fold: 14  Epoch: 466  Training loss = 3.0264  Validation loss = 8.0497  \n",
      "\n",
      "Fold: 14  Epoch: 467  Training loss = 3.0261  Validation loss = 8.0491  \n",
      "\n",
      "Fold: 14  Epoch: 468  Training loss = 3.0258  Validation loss = 8.0482  \n",
      "\n",
      "Fold: 14  Epoch: 469  Training loss = 3.0252  Validation loss = 8.0468  \n",
      "\n",
      "Fold: 14  Epoch: 470  Training loss = 3.0248  Validation loss = 8.0459  \n",
      "\n",
      "Fold: 14  Epoch: 471  Training loss = 3.0245  Validation loss = 8.0450  \n",
      "\n",
      "Fold: 14  Epoch: 472  Training loss = 3.0241  Validation loss = 8.0441  \n",
      "\n",
      "Fold: 14  Epoch: 473  Training loss = 3.0238  Validation loss = 8.0435  \n",
      "\n",
      "Fold: 14  Epoch: 474  Training loss = 3.0234  Validation loss = 8.0425  \n",
      "\n",
      "Fold: 14  Epoch: 475  Training loss = 3.0231  Validation loss = 8.0417  \n",
      "\n",
      "Fold: 14  Epoch: 476  Training loss = 3.0226  Validation loss = 8.0405  \n",
      "\n",
      "Fold: 14  Epoch: 477  Training loss = 3.0223  Validation loss = 8.0396  \n",
      "\n",
      "Fold: 14  Epoch: 478  Training loss = 3.0218  Validation loss = 8.0385  \n",
      "\n",
      "Fold: 14  Epoch: 479  Training loss = 3.0216  Validation loss = 8.0379  \n",
      "\n",
      "Fold: 14  Epoch: 480  Training loss = 3.0211  Validation loss = 8.0368  \n",
      "\n",
      "Fold: 14  Epoch: 481  Training loss = 3.0207  Validation loss = 8.0358  \n",
      "\n",
      "Fold: 14  Epoch: 482  Training loss = 3.0203  Validation loss = 8.0349  \n",
      "\n",
      "Fold: 14  Epoch: 483  Training loss = 3.0199  Validation loss = 8.0338  \n",
      "\n",
      "Fold: 14  Epoch: 484  Training loss = 3.0196  Validation loss = 8.0331  \n",
      "\n",
      "Fold: 14  Epoch: 485  Training loss = 3.0191  Validation loss = 8.0321  \n",
      "\n",
      "Fold: 14  Epoch: 486  Training loss = 3.0188  Validation loss = 8.0313  \n",
      "\n",
      "Fold: 14  Epoch: 487  Training loss = 3.0186  Validation loss = 8.0310  \n",
      "\n",
      "Fold: 14  Epoch: 488  Training loss = 3.0183  Validation loss = 8.0303  \n",
      "\n",
      "Fold: 14  Epoch: 489  Training loss = 3.0179  Validation loss = 8.0294  \n",
      "\n",
      "Fold: 14  Epoch: 490  Training loss = 3.0175  Validation loss = 8.0282  \n",
      "\n",
      "Fold: 14  Epoch: 491  Training loss = 3.0170  Validation loss = 8.0273  \n",
      "\n",
      "Fold: 14  Epoch: 492  Training loss = 3.0167  Validation loss = 8.0266  \n",
      "\n",
      "Fold: 14  Epoch: 493  Training loss = 3.0163  Validation loss = 8.0256  \n",
      "\n",
      "Fold: 14  Epoch: 494  Training loss = 3.0160  Validation loss = 8.0248  \n",
      "\n",
      "Fold: 14  Epoch: 495  Training loss = 3.0156  Validation loss = 8.0241  \n",
      "\n",
      "Fold: 14  Epoch: 496  Training loss = 3.0151  Validation loss = 8.0230  \n",
      "\n",
      "Fold: 14  Epoch: 497  Training loss = 3.0147  Validation loss = 8.0221  \n",
      "\n",
      "Fold: 14  Epoch: 498  Training loss = 3.0143  Validation loss = 8.0212  \n",
      "\n",
      "Fold: 14  Epoch: 499  Training loss = 3.0140  Validation loss = 8.0203  \n",
      "\n",
      "Fold: 14  Epoch: 500  Training loss = 3.0136  Validation loss = 8.0192  \n",
      "\n",
      "Check model:  Fold: 14  Optimal epoch: 500  \n",
      "\n",
      "Fold: 15  Epoch: 1  Training loss = 3.5745  Validation loss = 8.6768  \n",
      "\n",
      "Fold: 15  Epoch: 2  Training loss = 3.5737  Validation loss = 8.6751  \n",
      "\n",
      "Fold: 15  Epoch: 3  Training loss = 3.5730  Validation loss = 8.6738  \n",
      "\n",
      "Fold: 15  Epoch: 4  Training loss = 3.5720  Validation loss = 8.6718  \n",
      "\n",
      "Fold: 15  Epoch: 5  Training loss = 3.5712  Validation loss = 8.6703  \n",
      "\n",
      "Fold: 15  Epoch: 6  Training loss = 3.5708  Validation loss = 8.6695  \n",
      "\n",
      "Fold: 15  Epoch: 7  Training loss = 3.5700  Validation loss = 8.6680  \n",
      "\n",
      "Fold: 15  Epoch: 8  Training loss = 3.5692  Validation loss = 8.6665  \n",
      "\n",
      "Fold: 15  Epoch: 9  Training loss = 3.5685  Validation loss = 8.6650  \n",
      "\n",
      "Fold: 15  Epoch: 10  Training loss = 3.5678  Validation loss = 8.6637  \n",
      "\n",
      "Fold: 15  Epoch: 11  Training loss = 3.5672  Validation loss = 8.6624  \n",
      "\n",
      "Fold: 15  Epoch: 12  Training loss = 3.5666  Validation loss = 8.6612  \n",
      "\n",
      "Fold: 15  Epoch: 13  Training loss = 3.5661  Validation loss = 8.6602  \n",
      "\n",
      "Fold: 15  Epoch: 14  Training loss = 3.5654  Validation loss = 8.6588  \n",
      "\n",
      "Fold: 15  Epoch: 15  Training loss = 3.5649  Validation loss = 8.6578  \n",
      "\n",
      "Fold: 15  Epoch: 16  Training loss = 3.5642  Validation loss = 8.6564  \n",
      "\n",
      "Fold: 15  Epoch: 17  Training loss = 3.5634  Validation loss = 8.6548  \n",
      "\n",
      "Fold: 15  Epoch: 18  Training loss = 3.5628  Validation loss = 8.6536  \n",
      "\n",
      "Fold: 15  Epoch: 19  Training loss = 3.5621  Validation loss = 8.6523  \n",
      "\n",
      "Fold: 15  Epoch: 20  Training loss = 3.5612  Validation loss = 8.6505  \n",
      "\n",
      "Fold: 15  Epoch: 21  Training loss = 3.5605  Validation loss = 8.6491  \n",
      "\n",
      "Fold: 15  Epoch: 22  Training loss = 3.5598  Validation loss = 8.6478  \n",
      "\n",
      "Fold: 15  Epoch: 23  Training loss = 3.5592  Validation loss = 8.6464  \n",
      "\n",
      "Fold: 15  Epoch: 24  Training loss = 3.5585  Validation loss = 8.6451  \n",
      "\n",
      "Fold: 15  Epoch: 25  Training loss = 3.5578  Validation loss = 8.6436  \n",
      "\n",
      "Fold: 15  Epoch: 26  Training loss = 3.5571  Validation loss = 8.6423  \n",
      "\n",
      "Fold: 15  Epoch: 27  Training loss = 3.5563  Validation loss = 8.6407  \n",
      "\n",
      "Fold: 15  Epoch: 28  Training loss = 3.5555  Validation loss = 8.6391  \n",
      "\n",
      "Fold: 15  Epoch: 29  Training loss = 3.5550  Validation loss = 8.6379  \n",
      "\n",
      "Fold: 15  Epoch: 30  Training loss = 3.5545  Validation loss = 8.6371  \n",
      "\n",
      "Fold: 15  Epoch: 31  Training loss = 3.5539  Validation loss = 8.6358  \n",
      "\n",
      "Fold: 15  Epoch: 32  Training loss = 3.5532  Validation loss = 8.6344  \n",
      "\n",
      "Fold: 15  Epoch: 33  Training loss = 3.5525  Validation loss = 8.6329  \n",
      "\n",
      "Fold: 15  Epoch: 34  Training loss = 3.5519  Validation loss = 8.6318  \n",
      "\n",
      "Fold: 15  Epoch: 35  Training loss = 3.5512  Validation loss = 8.6304  \n",
      "\n",
      "Fold: 15  Epoch: 36  Training loss = 3.5507  Validation loss = 8.6294  \n",
      "\n",
      "Fold: 15  Epoch: 37  Training loss = 3.5502  Validation loss = 8.6284  \n",
      "\n",
      "Fold: 15  Epoch: 38  Training loss = 3.5495  Validation loss = 8.6270  \n",
      "\n",
      "Fold: 15  Epoch: 39  Training loss = 3.5488  Validation loss = 8.6255  \n",
      "\n",
      "Fold: 15  Epoch: 40  Training loss = 3.5483  Validation loss = 8.6245  \n",
      "\n",
      "Fold: 15  Epoch: 41  Training loss = 3.5476  Validation loss = 8.6232  \n",
      "\n",
      "Fold: 15  Epoch: 42  Training loss = 3.5474  Validation loss = 8.6228  \n",
      "\n",
      "Fold: 15  Epoch: 43  Training loss = 3.5465  Validation loss = 8.6210  \n",
      "\n",
      "Fold: 15  Epoch: 44  Training loss = 3.5459  Validation loss = 8.6197  \n",
      "\n",
      "Fold: 15  Epoch: 45  Training loss = 3.5452  Validation loss = 8.6183  \n",
      "\n",
      "Fold: 15  Epoch: 46  Training loss = 3.5445  Validation loss = 8.6169  \n",
      "\n",
      "Fold: 15  Epoch: 47  Training loss = 3.5439  Validation loss = 8.6157  \n",
      "\n",
      "Fold: 15  Epoch: 48  Training loss = 3.5434  Validation loss = 8.6145  \n",
      "\n",
      "Fold: 15  Epoch: 49  Training loss = 3.5426  Validation loss = 8.6131  \n",
      "\n",
      "Fold: 15  Epoch: 50  Training loss = 3.5419  Validation loss = 8.6117  \n",
      "\n",
      "Fold: 15  Epoch: 51  Training loss = 3.5413  Validation loss = 8.6104  \n",
      "\n",
      "Fold: 15  Epoch: 52  Training loss = 3.5406  Validation loss = 8.6091  \n",
      "\n",
      "Fold: 15  Epoch: 53  Training loss = 3.5399  Validation loss = 8.6076  \n",
      "\n",
      "Fold: 15  Epoch: 54  Training loss = 3.5393  Validation loss = 8.6063  \n",
      "\n",
      "Fold: 15  Epoch: 55  Training loss = 3.5387  Validation loss = 8.6052  \n",
      "\n",
      "Fold: 15  Epoch: 56  Training loss = 3.5381  Validation loss = 8.6040  \n",
      "\n",
      "Fold: 15  Epoch: 57  Training loss = 3.5373  Validation loss = 8.6024  \n",
      "\n",
      "Fold: 15  Epoch: 58  Training loss = 3.5366  Validation loss = 8.6010  \n",
      "\n",
      "Fold: 15  Epoch: 59  Training loss = 3.5359  Validation loss = 8.5994  \n",
      "\n",
      "Fold: 15  Epoch: 60  Training loss = 3.5351  Validation loss = 8.5978  \n",
      "\n",
      "Fold: 15  Epoch: 61  Training loss = 3.5345  Validation loss = 8.5967  \n",
      "\n",
      "Fold: 15  Epoch: 62  Training loss = 3.5341  Validation loss = 8.5959  \n",
      "\n",
      "Fold: 15  Epoch: 63  Training loss = 3.5333  Validation loss = 8.5943  \n",
      "\n",
      "Fold: 15  Epoch: 64  Training loss = 3.5328  Validation loss = 8.5932  \n",
      "\n",
      "Fold: 15  Epoch: 65  Training loss = 3.5321  Validation loss = 8.5918  \n",
      "\n",
      "Fold: 15  Epoch: 66  Training loss = 3.5315  Validation loss = 8.5907  \n",
      "\n",
      "Fold: 15  Epoch: 67  Training loss = 3.5309  Validation loss = 8.5896  \n",
      "\n",
      "Fold: 15  Epoch: 68  Training loss = 3.5301  Validation loss = 8.5878  \n",
      "\n",
      "Fold: 15  Epoch: 69  Training loss = 3.5294  Validation loss = 8.5864  \n",
      "\n",
      "Fold: 15  Epoch: 70  Training loss = 3.5286  Validation loss = 8.5848  \n",
      "\n",
      "Fold: 15  Epoch: 71  Training loss = 3.5279  Validation loss = 8.5833  \n",
      "\n",
      "Fold: 15  Epoch: 72  Training loss = 3.5272  Validation loss = 8.5820  \n",
      "\n",
      "Fold: 15  Epoch: 73  Training loss = 3.5266  Validation loss = 8.5807  \n",
      "\n",
      "Fold: 15  Epoch: 74  Training loss = 3.5260  Validation loss = 8.5795  \n",
      "\n",
      "Fold: 15  Epoch: 75  Training loss = 3.5256  Validation loss = 8.5787  \n",
      "\n",
      "Fold: 15  Epoch: 76  Training loss = 3.5252  Validation loss = 8.5779  \n",
      "\n",
      "Fold: 15  Epoch: 77  Training loss = 3.5245  Validation loss = 8.5764  \n",
      "\n",
      "Fold: 15  Epoch: 78  Training loss = 3.5240  Validation loss = 8.5756  \n",
      "\n",
      "Fold: 15  Epoch: 79  Training loss = 3.5233  Validation loss = 8.5741  \n",
      "\n",
      "Fold: 15  Epoch: 80  Training loss = 3.5228  Validation loss = 8.5730  \n",
      "\n",
      "Fold: 15  Epoch: 81  Training loss = 3.5219  Validation loss = 8.5712  \n",
      "\n",
      "Fold: 15  Epoch: 82  Training loss = 3.5212  Validation loss = 8.5698  \n",
      "\n",
      "Fold: 15  Epoch: 83  Training loss = 3.5206  Validation loss = 8.5688  \n",
      "\n",
      "Fold: 15  Epoch: 84  Training loss = 3.5199  Validation loss = 8.5672  \n",
      "\n",
      "Fold: 15  Epoch: 85  Training loss = 3.5193  Validation loss = 8.5661  \n",
      "\n",
      "Fold: 15  Epoch: 86  Training loss = 3.5186  Validation loss = 8.5647  \n",
      "\n",
      "Fold: 15  Epoch: 87  Training loss = 3.5181  Validation loss = 8.5638  \n",
      "\n",
      "Fold: 15  Epoch: 88  Training loss = 3.5176  Validation loss = 8.5627  \n",
      "\n",
      "Fold: 15  Epoch: 89  Training loss = 3.5168  Validation loss = 8.5611  \n",
      "\n",
      "Fold: 15  Epoch: 90  Training loss = 3.5161  Validation loss = 8.5596  \n",
      "\n",
      "Fold: 15  Epoch: 91  Training loss = 3.5154  Validation loss = 8.5584  \n",
      "\n",
      "Fold: 15  Epoch: 92  Training loss = 3.5150  Validation loss = 8.5575  \n",
      "\n",
      "Fold: 15  Epoch: 93  Training loss = 3.5143  Validation loss = 8.5560  \n",
      "\n",
      "Fold: 15  Epoch: 94  Training loss = 3.5138  Validation loss = 8.5550  \n",
      "\n",
      "Fold: 15  Epoch: 95  Training loss = 3.5131  Validation loss = 8.5536  \n",
      "\n",
      "Fold: 15  Epoch: 96  Training loss = 3.5124  Validation loss = 8.5523  \n",
      "\n",
      "Fold: 15  Epoch: 97  Training loss = 3.5117  Validation loss = 8.5509  \n",
      "\n",
      "Fold: 15  Epoch: 98  Training loss = 3.5110  Validation loss = 8.5495  \n",
      "\n",
      "Fold: 15  Epoch: 99  Training loss = 3.5105  Validation loss = 8.5484  \n",
      "\n",
      "Fold: 15  Epoch: 100  Training loss = 3.5099  Validation loss = 8.5472  \n",
      "\n",
      "Fold: 15  Epoch: 101  Training loss = 3.5094  Validation loss = 8.5461  \n",
      "\n",
      "Fold: 15  Epoch: 102  Training loss = 3.5089  Validation loss = 8.5451  \n",
      "\n",
      "Fold: 15  Epoch: 103  Training loss = 3.5082  Validation loss = 8.5435  \n",
      "\n",
      "Fold: 15  Epoch: 104  Training loss = 3.5074  Validation loss = 8.5420  \n",
      "\n",
      "Fold: 15  Epoch: 105  Training loss = 3.5068  Validation loss = 8.5405  \n",
      "\n",
      "Fold: 15  Epoch: 106  Training loss = 3.5060  Validation loss = 8.5391  \n",
      "\n",
      "Fold: 15  Epoch: 107  Training loss = 3.5056  Validation loss = 8.5382  \n",
      "\n",
      "Fold: 15  Epoch: 108  Training loss = 3.5053  Validation loss = 8.5375  \n",
      "\n",
      "Fold: 15  Epoch: 109  Training loss = 3.5046  Validation loss = 8.5361  \n",
      "\n",
      "Fold: 15  Epoch: 110  Training loss = 3.5041  Validation loss = 8.5351  \n",
      "\n",
      "Fold: 15  Epoch: 111  Training loss = 3.5036  Validation loss = 8.5340  \n",
      "\n",
      "Fold: 15  Epoch: 112  Training loss = 3.5031  Validation loss = 8.5331  \n",
      "\n",
      "Fold: 15  Epoch: 113  Training loss = 3.5026  Validation loss = 8.5320  \n",
      "\n",
      "Fold: 15  Epoch: 114  Training loss = 3.5020  Validation loss = 8.5307  \n",
      "\n",
      "Fold: 15  Epoch: 115  Training loss = 3.5015  Validation loss = 8.5296  \n",
      "\n",
      "Fold: 15  Epoch: 116  Training loss = 3.5008  Validation loss = 8.5284  \n",
      "\n",
      "Fold: 15  Epoch: 117  Training loss = 3.5001  Validation loss = 8.5269  \n",
      "\n",
      "Fold: 15  Epoch: 118  Training loss = 3.4995  Validation loss = 8.5258  \n",
      "\n",
      "Fold: 15  Epoch: 119  Training loss = 3.4990  Validation loss = 8.5248  \n",
      "\n",
      "Fold: 15  Epoch: 120  Training loss = 3.4982  Validation loss = 8.5232  \n",
      "\n",
      "Fold: 15  Epoch: 121  Training loss = 3.4976  Validation loss = 8.5219  \n",
      "\n",
      "Fold: 15  Epoch: 122  Training loss = 3.4967  Validation loss = 8.5201  \n",
      "\n",
      "Fold: 15  Epoch: 123  Training loss = 3.4963  Validation loss = 8.5192  \n",
      "\n",
      "Fold: 15  Epoch: 124  Training loss = 3.4956  Validation loss = 8.5180  \n",
      "\n",
      "Fold: 15  Epoch: 125  Training loss = 3.4948  Validation loss = 8.5164  \n",
      "\n",
      "Fold: 15  Epoch: 126  Training loss = 3.4943  Validation loss = 8.5155  \n",
      "\n",
      "Fold: 15  Epoch: 127  Training loss = 3.4938  Validation loss = 8.5145  \n",
      "\n",
      "Fold: 15  Epoch: 128  Training loss = 3.4933  Validation loss = 8.5134  \n",
      "\n",
      "Fold: 15  Epoch: 129  Training loss = 3.4925  Validation loss = 8.5118  \n",
      "\n",
      "Fold: 15  Epoch: 130  Training loss = 3.4919  Validation loss = 8.5107  \n",
      "\n",
      "Fold: 15  Epoch: 131  Training loss = 3.4911  Validation loss = 8.5090  \n",
      "\n",
      "Fold: 15  Epoch: 132  Training loss = 3.4906  Validation loss = 8.5079  \n",
      "\n",
      "Fold: 15  Epoch: 133  Training loss = 3.4903  Validation loss = 8.5073  \n",
      "\n",
      "Fold: 15  Epoch: 134  Training loss = 3.4897  Validation loss = 8.5060  \n",
      "\n",
      "Fold: 15  Epoch: 135  Training loss = 3.4889  Validation loss = 8.5045  \n",
      "\n",
      "Fold: 15  Epoch: 136  Training loss = 3.4884  Validation loss = 8.5035  \n",
      "\n",
      "Fold: 15  Epoch: 137  Training loss = 3.4878  Validation loss = 8.5021  \n",
      "\n",
      "Fold: 15  Epoch: 138  Training loss = 3.4872  Validation loss = 8.5009  \n",
      "\n",
      "Fold: 15  Epoch: 139  Training loss = 3.4865  Validation loss = 8.4994  \n",
      "\n",
      "Fold: 15  Epoch: 140  Training loss = 3.4861  Validation loss = 8.4984  \n",
      "\n",
      "Fold: 15  Epoch: 141  Training loss = 3.4854  Validation loss = 8.4970  \n",
      "\n",
      "Fold: 15  Epoch: 142  Training loss = 3.4849  Validation loss = 8.4959  \n",
      "\n",
      "Fold: 15  Epoch: 143  Training loss = 3.4844  Validation loss = 8.4949  \n",
      "\n",
      "Fold: 15  Epoch: 144  Training loss = 3.4839  Validation loss = 8.4940  \n",
      "\n",
      "Fold: 15  Epoch: 145  Training loss = 3.4833  Validation loss = 8.4927  \n",
      "\n",
      "Fold: 15  Epoch: 146  Training loss = 3.4826  Validation loss = 8.4912  \n",
      "\n",
      "Fold: 15  Epoch: 147  Training loss = 3.4821  Validation loss = 8.4902  \n",
      "\n",
      "Fold: 15  Epoch: 148  Training loss = 3.4814  Validation loss = 8.4888  \n",
      "\n",
      "Fold: 15  Epoch: 149  Training loss = 3.4809  Validation loss = 8.4876  \n",
      "\n",
      "Fold: 15  Epoch: 150  Training loss = 3.4805  Validation loss = 8.4868  \n",
      "\n",
      "Fold: 15  Epoch: 151  Training loss = 3.4797  Validation loss = 8.4851  \n",
      "\n",
      "Fold: 15  Epoch: 152  Training loss = 3.4791  Validation loss = 8.4839  \n",
      "\n",
      "Fold: 15  Epoch: 153  Training loss = 3.4785  Validation loss = 8.4827  \n",
      "\n",
      "Fold: 15  Epoch: 154  Training loss = 3.4779  Validation loss = 8.4813  \n",
      "\n",
      "Fold: 15  Epoch: 155  Training loss = 3.4772  Validation loss = 8.4800  \n",
      "\n",
      "Fold: 15  Epoch: 156  Training loss = 3.4769  Validation loss = 8.4793  \n",
      "\n",
      "Fold: 15  Epoch: 157  Training loss = 3.4763  Validation loss = 8.4781  \n",
      "\n",
      "Fold: 15  Epoch: 158  Training loss = 3.4756  Validation loss = 8.4766  \n",
      "\n",
      "Fold: 15  Epoch: 159  Training loss = 3.4751  Validation loss = 8.4754  \n",
      "\n",
      "Fold: 15  Epoch: 160  Training loss = 3.4745  Validation loss = 8.4743  \n",
      "\n",
      "Fold: 15  Epoch: 161  Training loss = 3.4740  Validation loss = 8.4732  \n",
      "\n",
      "Fold: 15  Epoch: 162  Training loss = 3.4735  Validation loss = 8.4722  \n",
      "\n",
      "Fold: 15  Epoch: 163  Training loss = 3.4730  Validation loss = 8.4710  \n",
      "\n",
      "Fold: 15  Epoch: 164  Training loss = 3.4725  Validation loss = 8.4700  \n",
      "\n",
      "Fold: 15  Epoch: 165  Training loss = 3.4720  Validation loss = 8.4689  \n",
      "\n",
      "Fold: 15  Epoch: 166  Training loss = 3.4713  Validation loss = 8.4675  \n",
      "\n",
      "Fold: 15  Epoch: 167  Training loss = 3.4707  Validation loss = 8.4662  \n",
      "\n",
      "Fold: 15  Epoch: 168  Training loss = 3.4704  Validation loss = 8.4655  \n",
      "\n",
      "Fold: 15  Epoch: 169  Training loss = 3.4696  Validation loss = 8.4638  \n",
      "\n",
      "Fold: 15  Epoch: 170  Training loss = 3.4693  Validation loss = 8.4632  \n",
      "\n",
      "Fold: 15  Epoch: 171  Training loss = 3.4687  Validation loss = 8.4618  \n",
      "\n",
      "Fold: 15  Epoch: 172  Training loss = 3.4679  Validation loss = 8.4602  \n",
      "\n",
      "Fold: 15  Epoch: 173  Training loss = 3.4673  Validation loss = 8.4588  \n",
      "\n",
      "Fold: 15  Epoch: 174  Training loss = 3.4664  Validation loss = 8.4570  \n",
      "\n",
      "Fold: 15  Epoch: 175  Training loss = 3.4660  Validation loss = 8.4561  \n",
      "\n",
      "Fold: 15  Epoch: 176  Training loss = 3.4654  Validation loss = 8.4550  \n",
      "\n",
      "Fold: 15  Epoch: 177  Training loss = 3.4649  Validation loss = 8.4538  \n",
      "\n",
      "Fold: 15  Epoch: 178  Training loss = 3.4642  Validation loss = 8.4525  \n",
      "\n",
      "Fold: 15  Epoch: 179  Training loss = 3.4636  Validation loss = 8.4511  \n",
      "\n",
      "Fold: 15  Epoch: 180  Training loss = 3.4631  Validation loss = 8.4500  \n",
      "\n",
      "Fold: 15  Epoch: 181  Training loss = 3.4626  Validation loss = 8.4489  \n",
      "\n",
      "Fold: 15  Epoch: 182  Training loss = 3.4621  Validation loss = 8.4480  \n",
      "\n",
      "Fold: 15  Epoch: 183  Training loss = 3.4614  Validation loss = 8.4466  \n",
      "\n",
      "Fold: 15  Epoch: 184  Training loss = 3.4609  Validation loss = 8.4455  \n",
      "\n",
      "Fold: 15  Epoch: 185  Training loss = 3.4604  Validation loss = 8.4443  \n",
      "\n",
      "Fold: 15  Epoch: 186  Training loss = 3.4600  Validation loss = 8.4435  \n",
      "\n",
      "Fold: 15  Epoch: 187  Training loss = 3.4595  Validation loss = 8.4424  \n",
      "\n",
      "Fold: 15  Epoch: 188  Training loss = 3.4591  Validation loss = 8.4415  \n",
      "\n",
      "Fold: 15  Epoch: 189  Training loss = 3.4586  Validation loss = 8.4404  \n",
      "\n",
      "Fold: 15  Epoch: 190  Training loss = 3.4582  Validation loss = 8.4395  \n",
      "\n",
      "Fold: 15  Epoch: 191  Training loss = 3.4577  Validation loss = 8.4385  \n",
      "\n",
      "Fold: 15  Epoch: 192  Training loss = 3.4573  Validation loss = 8.4376  \n",
      "\n",
      "Fold: 15  Epoch: 193  Training loss = 3.4568  Validation loss = 8.4366  \n",
      "\n",
      "Fold: 15  Epoch: 194  Training loss = 3.4563  Validation loss = 8.4355  \n",
      "\n",
      "Fold: 15  Epoch: 195  Training loss = 3.4557  Validation loss = 8.4342  \n",
      "\n",
      "Fold: 15  Epoch: 196  Training loss = 3.4552  Validation loss = 8.4330  \n",
      "\n",
      "Fold: 15  Epoch: 197  Training loss = 3.4547  Validation loss = 8.4320  \n",
      "\n",
      "Fold: 15  Epoch: 198  Training loss = 3.4540  Validation loss = 8.4306  \n",
      "\n",
      "Fold: 15  Epoch: 199  Training loss = 3.4535  Validation loss = 8.4296  \n",
      "\n",
      "Fold: 15  Epoch: 200  Training loss = 3.4530  Validation loss = 8.4284  \n",
      "\n",
      "Fold: 15  Epoch: 201  Training loss = 3.4525  Validation loss = 8.4272  \n",
      "\n",
      "Fold: 15  Epoch: 202  Training loss = 3.4518  Validation loss = 8.4258  \n",
      "\n",
      "Fold: 15  Epoch: 203  Training loss = 3.4510  Validation loss = 8.4240  \n",
      "\n",
      "Fold: 15  Epoch: 204  Training loss = 3.4504  Validation loss = 8.4228  \n",
      "\n",
      "Fold: 15  Epoch: 205  Training loss = 3.4499  Validation loss = 8.4218  \n",
      "\n",
      "Fold: 15  Epoch: 206  Training loss = 3.4493  Validation loss = 8.4204  \n",
      "\n",
      "Fold: 15  Epoch: 207  Training loss = 3.4487  Validation loss = 8.4192  \n",
      "\n",
      "Fold: 15  Epoch: 208  Training loss = 3.4483  Validation loss = 8.4183  \n",
      "\n",
      "Fold: 15  Epoch: 209  Training loss = 3.4478  Validation loss = 8.4172  \n",
      "\n",
      "Fold: 15  Epoch: 210  Training loss = 3.4473  Validation loss = 8.4162  \n",
      "\n",
      "Fold: 15  Epoch: 211  Training loss = 3.4467  Validation loss = 8.4148  \n",
      "\n",
      "Fold: 15  Epoch: 212  Training loss = 3.4462  Validation loss = 8.4137  \n",
      "\n",
      "Fold: 15  Epoch: 213  Training loss = 3.4458  Validation loss = 8.4130  \n",
      "\n",
      "Fold: 15  Epoch: 214  Training loss = 3.4452  Validation loss = 8.4116  \n",
      "\n",
      "Fold: 15  Epoch: 215  Training loss = 3.4446  Validation loss = 8.4103  \n",
      "\n",
      "Fold: 15  Epoch: 216  Training loss = 3.4439  Validation loss = 8.4089  \n",
      "\n",
      "Fold: 15  Epoch: 217  Training loss = 3.4435  Validation loss = 8.4079  \n",
      "\n",
      "Fold: 15  Epoch: 218  Training loss = 3.4429  Validation loss = 8.4068  \n",
      "\n",
      "Fold: 15  Epoch: 219  Training loss = 3.4426  Validation loss = 8.4060  \n",
      "\n",
      "Fold: 15  Epoch: 220  Training loss = 3.4421  Validation loss = 8.4049  \n",
      "\n",
      "Fold: 15  Epoch: 221  Training loss = 3.4416  Validation loss = 8.4037  \n",
      "\n",
      "Fold: 15  Epoch: 222  Training loss = 3.4411  Validation loss = 8.4028  \n",
      "\n",
      "Fold: 15  Epoch: 223  Training loss = 3.4407  Validation loss = 8.4019  \n",
      "\n",
      "Fold: 15  Epoch: 224  Training loss = 3.4402  Validation loss = 8.4009  \n",
      "\n",
      "Fold: 15  Epoch: 225  Training loss = 3.4397  Validation loss = 8.3997  \n",
      "\n",
      "Fold: 15  Epoch: 226  Training loss = 3.4392  Validation loss = 8.3987  \n",
      "\n",
      "Fold: 15  Epoch: 227  Training loss = 3.4387  Validation loss = 8.3976  \n",
      "\n",
      "Fold: 15  Epoch: 228  Training loss = 3.4382  Validation loss = 8.3964  \n",
      "\n",
      "Fold: 15  Epoch: 229  Training loss = 3.4376  Validation loss = 8.3952  \n",
      "\n",
      "Fold: 15  Epoch: 230  Training loss = 3.4371  Validation loss = 8.3941  \n",
      "\n",
      "Fold: 15  Epoch: 231  Training loss = 3.4369  Validation loss = 8.3936  \n",
      "\n",
      "Fold: 15  Epoch: 232  Training loss = 3.4362  Validation loss = 8.3922  \n",
      "\n",
      "Fold: 15  Epoch: 233  Training loss = 3.4357  Validation loss = 8.3912  \n",
      "\n",
      "Fold: 15  Epoch: 234  Training loss = 3.4353  Validation loss = 8.3902  \n",
      "\n",
      "Fold: 15  Epoch: 235  Training loss = 3.4347  Validation loss = 8.3889  \n",
      "\n",
      "Fold: 15  Epoch: 236  Training loss = 3.4341  Validation loss = 8.3877  \n",
      "\n",
      "Fold: 15  Epoch: 237  Training loss = 3.4338  Validation loss = 8.3868  \n",
      "\n",
      "Fold: 15  Epoch: 238  Training loss = 3.4332  Validation loss = 8.3856  \n",
      "\n",
      "Fold: 15  Epoch: 239  Training loss = 3.4325  Validation loss = 8.3841  \n",
      "\n",
      "Fold: 15  Epoch: 240  Training loss = 3.4318  Validation loss = 8.3824  \n",
      "\n",
      "Fold: 15  Epoch: 241  Training loss = 3.4313  Validation loss = 8.3814  \n",
      "\n",
      "Fold: 15  Epoch: 242  Training loss = 3.4308  Validation loss = 8.3803  \n",
      "\n",
      "Fold: 15  Epoch: 243  Training loss = 3.4303  Validation loss = 8.3793  \n",
      "\n",
      "Fold: 15  Epoch: 244  Training loss = 3.4299  Validation loss = 8.3783  \n",
      "\n",
      "Fold: 15  Epoch: 245  Training loss = 3.4295  Validation loss = 8.3775  \n",
      "\n",
      "Fold: 15  Epoch: 246  Training loss = 3.4290  Validation loss = 8.3765  \n",
      "\n",
      "Fold: 15  Epoch: 247  Training loss = 3.4284  Validation loss = 8.3751  \n",
      "\n",
      "Fold: 15  Epoch: 248  Training loss = 3.4280  Validation loss = 8.3744  \n",
      "\n",
      "Fold: 15  Epoch: 249  Training loss = 3.4275  Validation loss = 8.3733  \n",
      "\n",
      "Fold: 15  Epoch: 250  Training loss = 3.4272  Validation loss = 8.3725  \n",
      "\n",
      "Fold: 15  Epoch: 251  Training loss = 3.4268  Validation loss = 8.3716  \n",
      "\n",
      "Fold: 15  Epoch: 252  Training loss = 3.4260  Validation loss = 8.3699  \n",
      "\n",
      "Fold: 15  Epoch: 253  Training loss = 3.4255  Validation loss = 8.3688  \n",
      "\n",
      "Fold: 15  Epoch: 254  Training loss = 3.4250  Validation loss = 8.3679  \n",
      "\n",
      "Fold: 15  Epoch: 255  Training loss = 3.4245  Validation loss = 8.3667  \n",
      "\n",
      "Fold: 15  Epoch: 256  Training loss = 3.4238  Validation loss = 8.3652  \n",
      "\n",
      "Fold: 15  Epoch: 257  Training loss = 3.4230  Validation loss = 8.3636  \n",
      "\n",
      "Fold: 15  Epoch: 258  Training loss = 3.4226  Validation loss = 8.3627  \n",
      "\n",
      "Fold: 15  Epoch: 259  Training loss = 3.4219  Validation loss = 8.3612  \n",
      "\n",
      "Fold: 15  Epoch: 260  Training loss = 3.4213  Validation loss = 8.3600  \n",
      "\n",
      "Fold: 15  Epoch: 261  Training loss = 3.4208  Validation loss = 8.3589  \n",
      "\n",
      "Fold: 15  Epoch: 262  Training loss = 3.4200  Validation loss = 8.3574  \n",
      "\n",
      "Fold: 15  Epoch: 263  Training loss = 3.4191  Validation loss = 8.3553  \n",
      "\n",
      "Fold: 15  Epoch: 264  Training loss = 3.4184  Validation loss = 8.3539  \n",
      "\n",
      "Fold: 15  Epoch: 265  Training loss = 3.4178  Validation loss = 8.3527  \n",
      "\n",
      "Fold: 15  Epoch: 266  Training loss = 3.4173  Validation loss = 8.3518  \n",
      "\n",
      "Fold: 15  Epoch: 267  Training loss = 3.4168  Validation loss = 8.3506  \n",
      "\n",
      "Fold: 15  Epoch: 268  Training loss = 3.4162  Validation loss = 8.3497  \n",
      "\n",
      "Fold: 15  Epoch: 269  Training loss = 3.4156  Validation loss = 8.3487  \n",
      "\n",
      "Fold: 15  Epoch: 270  Training loss = 3.4152  Validation loss = 8.3479  \n",
      "\n",
      "Fold: 15  Epoch: 271  Training loss = 3.4146  Validation loss = 8.3471  \n",
      "\n",
      "Fold: 15  Epoch: 272  Training loss = 3.4142  Validation loss = 8.3462  \n",
      "\n",
      "Fold: 15  Epoch: 273  Training loss = 3.4133  Validation loss = 8.3445  \n",
      "\n",
      "Fold: 15  Epoch: 274  Training loss = 3.4129  Validation loss = 8.3437  \n",
      "\n",
      "Fold: 15  Epoch: 275  Training loss = 3.4125  Validation loss = 8.3428  \n",
      "\n",
      "Fold: 15  Epoch: 276  Training loss = 3.4117  Validation loss = 8.3418  \n",
      "\n",
      "Fold: 15  Epoch: 277  Training loss = 3.4093  Validation loss = 8.3405  \n",
      "\n",
      "Fold: 15  Epoch: 278  Training loss = 3.4080  Validation loss = 8.3396  \n",
      "\n",
      "Fold: 15  Epoch: 279  Training loss = 3.4073  Validation loss = 8.3380  \n",
      "\n",
      "Fold: 15  Epoch: 280  Training loss = 3.4066  Validation loss = 8.3366  \n",
      "\n",
      "Fold: 15  Epoch: 281  Training loss = 3.4060  Validation loss = 8.3353  \n",
      "\n",
      "Fold: 15  Epoch: 282  Training loss = 3.4053  Validation loss = 8.3340  \n",
      "\n",
      "Fold: 15  Epoch: 283  Training loss = 3.4048  Validation loss = 8.3328  \n",
      "\n",
      "Fold: 15  Epoch: 284  Training loss = 3.4044  Validation loss = 8.3319  \n",
      "\n",
      "Fold: 15  Epoch: 285  Training loss = 3.4038  Validation loss = 8.3308  \n",
      "\n",
      "Fold: 15  Epoch: 286  Training loss = 3.4032  Validation loss = 8.3294  \n",
      "\n",
      "Fold: 15  Epoch: 287  Training loss = 3.4027  Validation loss = 8.3282  \n",
      "\n",
      "Fold: 15  Epoch: 288  Training loss = 3.4021  Validation loss = 8.3270  \n",
      "\n",
      "Fold: 15  Epoch: 289  Training loss = 3.4017  Validation loss = 8.3260  \n",
      "\n",
      "Fold: 15  Epoch: 290  Training loss = 3.4011  Validation loss = 8.3247  \n",
      "\n",
      "Fold: 15  Epoch: 291  Training loss = 3.4003  Validation loss = 8.3230  \n",
      "\n",
      "Fold: 15  Epoch: 292  Training loss = 3.3998  Validation loss = 8.3219  \n",
      "\n",
      "Fold: 15  Epoch: 293  Training loss = 3.3993  Validation loss = 8.3208  \n",
      "\n",
      "Fold: 15  Epoch: 294  Training loss = 3.3988  Validation loss = 8.3197  \n",
      "\n",
      "Fold: 15  Epoch: 295  Training loss = 3.3984  Validation loss = 8.3187  \n",
      "\n",
      "Fold: 15  Epoch: 296  Training loss = 3.3977  Validation loss = 8.3172  \n",
      "\n",
      "Fold: 15  Epoch: 297  Training loss = 3.3973  Validation loss = 8.3162  \n",
      "\n",
      "Fold: 15  Epoch: 298  Training loss = 3.3968  Validation loss = 8.3150  \n",
      "\n",
      "Fold: 15  Epoch: 299  Training loss = 3.3962  Validation loss = 8.3138  \n",
      "\n",
      "Fold: 15  Epoch: 300  Training loss = 3.3956  Validation loss = 8.3123  \n",
      "\n",
      "Fold: 15  Epoch: 301  Training loss = 3.3952  Validation loss = 8.3114  \n",
      "\n",
      "Fold: 15  Epoch: 302  Training loss = 3.3945  Validation loss = 8.3101  \n",
      "\n",
      "Fold: 15  Epoch: 303  Training loss = 3.3942  Validation loss = 8.3093  \n",
      "\n",
      "Fold: 15  Epoch: 304  Training loss = 3.3937  Validation loss = 8.3082  \n",
      "\n",
      "Fold: 15  Epoch: 305  Training loss = 3.3932  Validation loss = 8.3070  \n",
      "\n",
      "Fold: 15  Epoch: 306  Training loss = 3.3928  Validation loss = 8.3061  \n",
      "\n",
      "Fold: 15  Epoch: 307  Training loss = 3.3923  Validation loss = 8.3051  \n",
      "\n",
      "Fold: 15  Epoch: 308  Training loss = 3.3919  Validation loss = 8.3041  \n",
      "\n",
      "Fold: 15  Epoch: 309  Training loss = 3.3914  Validation loss = 8.3030  \n",
      "\n",
      "Fold: 15  Epoch: 310  Training loss = 3.3909  Validation loss = 8.3020  \n",
      "\n",
      "Fold: 15  Epoch: 311  Training loss = 3.3903  Validation loss = 8.3006  \n",
      "\n",
      "Fold: 15  Epoch: 312  Training loss = 3.3900  Validation loss = 8.2999  \n",
      "\n",
      "Fold: 15  Epoch: 313  Training loss = 3.3895  Validation loss = 8.2987  \n",
      "\n",
      "Fold: 15  Epoch: 314  Training loss = 3.3888  Validation loss = 8.2972  \n",
      "\n",
      "Fold: 15  Epoch: 315  Training loss = 3.3883  Validation loss = 8.2961  \n",
      "\n",
      "Fold: 15  Epoch: 316  Training loss = 3.3879  Validation loss = 8.2951  \n",
      "\n",
      "Fold: 15  Epoch: 317  Training loss = 3.3875  Validation loss = 8.2943  \n",
      "\n",
      "Fold: 15  Epoch: 318  Training loss = 3.3870  Validation loss = 8.2930  \n",
      "\n",
      "Fold: 15  Epoch: 319  Training loss = 3.3864  Validation loss = 8.2918  \n",
      "\n",
      "Fold: 15  Epoch: 320  Training loss = 3.3860  Validation loss = 8.2907  \n",
      "\n",
      "Fold: 15  Epoch: 321  Training loss = 3.3855  Validation loss = 8.2896  \n",
      "\n",
      "Fold: 15  Epoch: 322  Training loss = 3.3851  Validation loss = 8.2886  \n",
      "\n",
      "Fold: 15  Epoch: 323  Training loss = 3.3845  Validation loss = 8.2874  \n",
      "\n",
      "Fold: 15  Epoch: 324  Training loss = 3.3842  Validation loss = 8.2868  \n",
      "\n",
      "Fold: 15  Epoch: 325  Training loss = 3.3838  Validation loss = 8.2857  \n",
      "\n",
      "Fold: 15  Epoch: 326  Training loss = 3.3832  Validation loss = 8.2844  \n",
      "\n",
      "Fold: 15  Epoch: 327  Training loss = 3.3828  Validation loss = 8.2834  \n",
      "\n",
      "Fold: 15  Epoch: 328  Training loss = 3.3823  Validation loss = 8.2823  \n",
      "\n",
      "Fold: 15  Epoch: 329  Training loss = 3.3819  Validation loss = 8.2814  \n",
      "\n",
      "Fold: 15  Epoch: 330  Training loss = 3.3815  Validation loss = 8.2806  \n",
      "\n",
      "Fold: 15  Epoch: 331  Training loss = 3.3811  Validation loss = 8.2796  \n",
      "\n",
      "Fold: 15  Epoch: 332  Training loss = 3.3807  Validation loss = 8.2787  \n",
      "\n",
      "Fold: 15  Epoch: 333  Training loss = 3.3802  Validation loss = 8.2775  \n",
      "\n",
      "Fold: 15  Epoch: 334  Training loss = 3.3796  Validation loss = 8.2764  \n",
      "\n",
      "Fold: 15  Epoch: 335  Training loss = 3.3791  Validation loss = 8.2750  \n",
      "\n",
      "Fold: 15  Epoch: 336  Training loss = 3.3787  Validation loss = 8.2742  \n",
      "\n",
      "Fold: 15  Epoch: 337  Training loss = 3.3782  Validation loss = 8.2731  \n",
      "\n",
      "Fold: 15  Epoch: 338  Training loss = 3.3779  Validation loss = 8.2724  \n",
      "\n",
      "Fold: 15  Epoch: 339  Training loss = 3.3773  Validation loss = 8.2711  \n",
      "\n",
      "Fold: 15  Epoch: 340  Training loss = 3.3767  Validation loss = 8.2698  \n",
      "\n",
      "Fold: 15  Epoch: 341  Training loss = 3.3762  Validation loss = 8.2687  \n",
      "\n",
      "Fold: 15  Epoch: 342  Training loss = 3.3757  Validation loss = 8.2675  \n",
      "\n",
      "Fold: 15  Epoch: 343  Training loss = 3.3751  Validation loss = 8.2662  \n",
      "\n",
      "Fold: 15  Epoch: 344  Training loss = 3.3747  Validation loss = 8.2652  \n",
      "\n",
      "Fold: 15  Epoch: 345  Training loss = 3.3743  Validation loss = 8.2642  \n",
      "\n",
      "Fold: 15  Epoch: 346  Training loss = 3.3737  Validation loss = 8.2630  \n",
      "\n",
      "Fold: 15  Epoch: 347  Training loss = 3.3731  Validation loss = 8.2615  \n",
      "\n",
      "Fold: 15  Epoch: 348  Training loss = 3.3726  Validation loss = 8.2605  \n",
      "\n",
      "Fold: 15  Epoch: 349  Training loss = 3.3723  Validation loss = 8.2596  \n",
      "\n",
      "Fold: 15  Epoch: 350  Training loss = 3.3716  Validation loss = 8.2582  \n",
      "\n",
      "Fold: 15  Epoch: 351  Training loss = 3.3713  Validation loss = 8.2575  \n",
      "\n",
      "Fold: 15  Epoch: 352  Training loss = 3.3708  Validation loss = 8.2562  \n",
      "\n",
      "Fold: 15  Epoch: 353  Training loss = 3.3703  Validation loss = 8.2551  \n",
      "\n",
      "Fold: 15  Epoch: 354  Training loss = 3.3698  Validation loss = 8.2541  \n",
      "\n",
      "Fold: 15  Epoch: 355  Training loss = 3.3693  Validation loss = 8.2529  \n",
      "\n",
      "Fold: 15  Epoch: 356  Training loss = 3.3688  Validation loss = 8.2518  \n",
      "\n",
      "Fold: 15  Epoch: 357  Training loss = 3.3682  Validation loss = 8.2504  \n",
      "\n",
      "Fold: 15  Epoch: 358  Training loss = 3.3678  Validation loss = 8.2494  \n",
      "\n",
      "Fold: 15  Epoch: 359  Training loss = 3.3674  Validation loss = 8.2486  \n",
      "\n",
      "Fold: 15  Epoch: 360  Training loss = 3.3670  Validation loss = 8.2476  \n",
      "\n",
      "Fold: 15  Epoch: 361  Training loss = 3.3665  Validation loss = 8.2465  \n",
      "\n",
      "Fold: 15  Epoch: 362  Training loss = 3.3660  Validation loss = 8.2454  \n",
      "\n",
      "Fold: 15  Epoch: 363  Training loss = 3.3657  Validation loss = 8.2446  \n",
      "\n",
      "Fold: 15  Epoch: 364  Training loss = 3.3651  Validation loss = 8.2433  \n",
      "\n",
      "Fold: 15  Epoch: 365  Training loss = 3.3647  Validation loss = 8.2424  \n",
      "\n",
      "Fold: 15  Epoch: 366  Training loss = 3.3643  Validation loss = 8.2414  \n",
      "\n",
      "Fold: 15  Epoch: 367  Training loss = 3.3638  Validation loss = 8.2402  \n",
      "\n",
      "Fold: 15  Epoch: 368  Training loss = 3.3633  Validation loss = 8.2392  \n",
      "\n",
      "Fold: 15  Epoch: 369  Training loss = 3.3628  Validation loss = 8.2379  \n",
      "\n",
      "Fold: 15  Epoch: 370  Training loss = 3.3623  Validation loss = 8.2369  \n",
      "\n",
      "Fold: 15  Epoch: 371  Training loss = 3.3617  Validation loss = 8.2356  \n",
      "\n",
      "Fold: 15  Epoch: 372  Training loss = 3.3613  Validation loss = 8.2347  \n",
      "\n",
      "Fold: 15  Epoch: 373  Training loss = 3.3608  Validation loss = 8.2334  \n",
      "\n",
      "Fold: 15  Epoch: 374  Training loss = 3.3603  Validation loss = 8.2323  \n",
      "\n",
      "Fold: 15  Epoch: 375  Training loss = 3.3599  Validation loss = 8.2314  \n",
      "\n",
      "Fold: 15  Epoch: 376  Training loss = 3.3595  Validation loss = 8.2304  \n",
      "\n",
      "Fold: 15  Epoch: 377  Training loss = 3.3592  Validation loss = 8.2297  \n",
      "\n",
      "Fold: 15  Epoch: 378  Training loss = 3.3587  Validation loss = 8.2286  \n",
      "\n",
      "Fold: 15  Epoch: 379  Training loss = 3.3580  Validation loss = 8.2271  \n",
      "\n",
      "Fold: 15  Epoch: 380  Training loss = 3.3578  Validation loss = 8.2266  \n",
      "\n",
      "Fold: 15  Epoch: 381  Training loss = 3.3574  Validation loss = 8.2256  \n",
      "\n",
      "Fold: 15  Epoch: 382  Training loss = 3.3570  Validation loss = 8.2247  \n",
      "\n",
      "Fold: 15  Epoch: 383  Training loss = 3.3564  Validation loss = 8.2233  \n",
      "\n",
      "Fold: 15  Epoch: 384  Training loss = 3.3557  Validation loss = 8.2217  \n",
      "\n",
      "Fold: 15  Epoch: 385  Training loss = 3.3553  Validation loss = 8.2207  \n",
      "\n",
      "Fold: 15  Epoch: 386  Training loss = 3.3548  Validation loss = 8.2196  \n",
      "\n",
      "Fold: 15  Epoch: 387  Training loss = 3.3543  Validation loss = 8.2184  \n",
      "\n",
      "Fold: 15  Epoch: 388  Training loss = 3.3538  Validation loss = 8.2174  \n",
      "\n",
      "Fold: 15  Epoch: 389  Training loss = 3.3533  Validation loss = 8.2160  \n",
      "\n",
      "Fold: 15  Epoch: 390  Training loss = 3.3527  Validation loss = 8.2146  \n",
      "\n",
      "Fold: 15  Epoch: 391  Training loss = 3.3521  Validation loss = 8.2133  \n",
      "\n",
      "Fold: 15  Epoch: 392  Training loss = 3.3516  Validation loss = 8.2122  \n",
      "\n",
      "Fold: 15  Epoch: 393  Training loss = 3.3511  Validation loss = 8.2109  \n",
      "\n",
      "Fold: 15  Epoch: 394  Training loss = 3.3507  Validation loss = 8.2099  \n",
      "\n",
      "Fold: 15  Epoch: 395  Training loss = 3.3502  Validation loss = 8.2089  \n",
      "\n",
      "Fold: 15  Epoch: 396  Training loss = 3.3497  Validation loss = 8.2077  \n",
      "\n",
      "Fold: 15  Epoch: 397  Training loss = 3.3492  Validation loss = 8.2064  \n",
      "\n",
      "Fold: 15  Epoch: 398  Training loss = 3.3489  Validation loss = 8.2058  \n",
      "\n",
      "Fold: 15  Epoch: 399  Training loss = 3.3485  Validation loss = 8.2047  \n",
      "\n",
      "Fold: 15  Epoch: 400  Training loss = 3.3477  Validation loss = 8.2031  \n",
      "\n",
      "Fold: 15  Epoch: 401  Training loss = 3.3473  Validation loss = 8.2021  \n",
      "\n",
      "Fold: 15  Epoch: 402  Training loss = 3.3467  Validation loss = 8.2007  \n",
      "\n",
      "Fold: 15  Epoch: 403  Training loss = 3.3460  Validation loss = 8.1992  \n",
      "\n",
      "Fold: 15  Epoch: 404  Training loss = 3.3456  Validation loss = 8.1981  \n",
      "\n",
      "Fold: 15  Epoch: 405  Training loss = 3.3451  Validation loss = 8.1969  \n",
      "\n",
      "Fold: 15  Epoch: 406  Training loss = 3.3448  Validation loss = 8.1961  \n",
      "\n",
      "Fold: 15  Epoch: 407  Training loss = 3.3444  Validation loss = 8.1953  \n",
      "\n",
      "Fold: 15  Epoch: 408  Training loss = 3.3438  Validation loss = 8.1939  \n",
      "\n",
      "Fold: 15  Epoch: 409  Training loss = 3.3434  Validation loss = 8.1929  \n",
      "\n",
      "Fold: 15  Epoch: 410  Training loss = 3.3430  Validation loss = 8.1919  \n",
      "\n",
      "Fold: 15  Epoch: 411  Training loss = 3.3425  Validation loss = 8.1908  \n",
      "\n",
      "Fold: 15  Epoch: 412  Training loss = 3.3418  Validation loss = 8.1892  \n",
      "\n",
      "Fold: 15  Epoch: 413  Training loss = 3.3414  Validation loss = 8.1881  \n",
      "\n",
      "Fold: 15  Epoch: 414  Training loss = 3.3409  Validation loss = 8.1871  \n",
      "\n",
      "Fold: 15  Epoch: 415  Training loss = 3.3404  Validation loss = 8.1859  \n",
      "\n",
      "Fold: 15  Epoch: 416  Training loss = 3.3401  Validation loss = 8.1852  \n",
      "\n",
      "Fold: 15  Epoch: 417  Training loss = 3.3398  Validation loss = 8.1845  \n",
      "\n",
      "Fold: 15  Epoch: 418  Training loss = 3.3393  Validation loss = 8.1832  \n",
      "\n",
      "Fold: 15  Epoch: 419  Training loss = 3.3388  Validation loss = 8.1822  \n",
      "\n",
      "Fold: 15  Epoch: 420  Training loss = 3.3384  Validation loss = 8.1812  \n",
      "\n",
      "Fold: 15  Epoch: 421  Training loss = 3.3379  Validation loss = 8.1801  \n",
      "\n",
      "Fold: 15  Epoch: 422  Training loss = 3.3375  Validation loss = 8.1790  \n",
      "\n",
      "Fold: 15  Epoch: 423  Training loss = 3.3370  Validation loss = 8.1780  \n",
      "\n",
      "Fold: 15  Epoch: 424  Training loss = 3.3365  Validation loss = 8.1767  \n",
      "\n",
      "Fold: 15  Epoch: 425  Training loss = 3.3361  Validation loss = 8.1758  \n",
      "\n",
      "Fold: 15  Epoch: 426  Training loss = 3.3358  Validation loss = 8.1749  \n",
      "\n",
      "Fold: 15  Epoch: 427  Training loss = 3.3354  Validation loss = 8.1740  \n",
      "\n",
      "Fold: 15  Epoch: 428  Training loss = 3.3350  Validation loss = 8.1732  \n",
      "\n",
      "Fold: 15  Epoch: 429  Training loss = 3.3344  Validation loss = 8.1717  \n",
      "\n",
      "Fold: 15  Epoch: 430  Training loss = 3.3339  Validation loss = 8.1706  \n",
      "\n",
      "Fold: 15  Epoch: 431  Training loss = 3.3334  Validation loss = 8.1693  \n",
      "\n",
      "Fold: 15  Epoch: 432  Training loss = 3.3329  Validation loss = 8.1681  \n",
      "\n",
      "Fold: 15  Epoch: 433  Training loss = 3.3325  Validation loss = 8.1672  \n",
      "\n",
      "Fold: 15  Epoch: 434  Training loss = 3.3320  Validation loss = 8.1661  \n",
      "\n",
      "Fold: 15  Epoch: 435  Training loss = 3.3316  Validation loss = 8.1650  \n",
      "\n",
      "Fold: 15  Epoch: 436  Training loss = 3.3312  Validation loss = 8.1641  \n",
      "\n",
      "Fold: 15  Epoch: 437  Training loss = 3.3307  Validation loss = 8.1628  \n",
      "\n",
      "Fold: 15  Epoch: 438  Training loss = 3.3300  Validation loss = 8.1613  \n",
      "\n",
      "Fold: 15  Epoch: 439  Training loss = 3.3296  Validation loss = 8.1602  \n",
      "\n",
      "Fold: 15  Epoch: 440  Training loss = 3.3291  Validation loss = 8.1591  \n",
      "\n",
      "Fold: 15  Epoch: 441  Training loss = 3.3286  Validation loss = 8.1580  \n",
      "\n",
      "Fold: 15  Epoch: 442  Training loss = 3.3280  Validation loss = 8.1566  \n",
      "\n",
      "Fold: 15  Epoch: 443  Training loss = 3.3276  Validation loss = 8.1556  \n",
      "\n",
      "Fold: 15  Epoch: 444  Training loss = 3.3270  Validation loss = 8.1542  \n",
      "\n",
      "Fold: 15  Epoch: 445  Training loss = 3.3265  Validation loss = 8.1532  \n",
      "\n",
      "Fold: 15  Epoch: 446  Training loss = 3.3260  Validation loss = 8.1519  \n",
      "\n",
      "Fold: 15  Epoch: 447  Training loss = 3.3255  Validation loss = 8.1507  \n",
      "\n",
      "Fold: 15  Epoch: 448  Training loss = 3.3251  Validation loss = 8.1496  \n",
      "\n",
      "Fold: 15  Epoch: 449  Training loss = 3.3245  Validation loss = 8.1482  \n",
      "\n",
      "Fold: 15  Epoch: 450  Training loss = 3.3241  Validation loss = 8.1472  \n",
      "\n",
      "Fold: 15  Epoch: 451  Training loss = 3.3235  Validation loss = 8.1459  \n",
      "\n",
      "Fold: 15  Epoch: 452  Training loss = 3.3231  Validation loss = 8.1448  \n",
      "\n",
      "Fold: 15  Epoch: 453  Training loss = 3.3228  Validation loss = 8.1440  \n",
      "\n",
      "Fold: 15  Epoch: 454  Training loss = 3.3223  Validation loss = 8.1430  \n",
      "\n",
      "Fold: 15  Epoch: 455  Training loss = 3.3219  Validation loss = 8.1419  \n",
      "\n",
      "Fold: 15  Epoch: 456  Training loss = 3.3215  Validation loss = 8.1411  \n",
      "\n",
      "Fold: 15  Epoch: 457  Training loss = 3.3211  Validation loss = 8.1402  \n",
      "\n",
      "Fold: 15  Epoch: 458  Training loss = 3.3205  Validation loss = 8.1388  \n",
      "\n",
      "Fold: 15  Epoch: 459  Training loss = 3.3201  Validation loss = 8.1377  \n",
      "\n",
      "Fold: 15  Epoch: 460  Training loss = 3.3196  Validation loss = 8.1365  \n",
      "\n",
      "Fold: 15  Epoch: 461  Training loss = 3.3190  Validation loss = 8.1352  \n",
      "\n",
      "Fold: 15  Epoch: 462  Training loss = 3.3186  Validation loss = 8.1341  \n",
      "\n",
      "Fold: 15  Epoch: 463  Training loss = 3.3180  Validation loss = 8.1327  \n",
      "\n",
      "Fold: 15  Epoch: 464  Training loss = 3.3175  Validation loss = 8.1316  \n",
      "\n",
      "Fold: 15  Epoch: 465  Training loss = 3.3171  Validation loss = 8.1306  \n",
      "\n",
      "Fold: 15  Epoch: 466  Training loss = 3.3162  Validation loss = 8.1285  \n",
      "\n",
      "Fold: 15  Epoch: 467  Training loss = 3.3158  Validation loss = 8.1276  \n",
      "\n",
      "Fold: 15  Epoch: 468  Training loss = 3.3155  Validation loss = 8.1268  \n",
      "\n",
      "Fold: 15  Epoch: 469  Training loss = 3.3152  Validation loss = 8.1261  \n",
      "\n",
      "Fold: 15  Epoch: 470  Training loss = 3.3150  Validation loss = 8.1257  \n",
      "\n",
      "Fold: 15  Epoch: 471  Training loss = 3.3147  Validation loss = 8.1248  \n",
      "\n",
      "Fold: 15  Epoch: 472  Training loss = 3.3144  Validation loss = 8.1240  \n",
      "\n",
      "Fold: 15  Epoch: 473  Training loss = 3.3139  Validation loss = 8.1229  \n",
      "\n",
      "Fold: 15  Epoch: 474  Training loss = 3.3135  Validation loss = 8.1220  \n",
      "\n",
      "Fold: 15  Epoch: 475  Training loss = 3.3131  Validation loss = 8.1212  \n",
      "\n",
      "Fold: 15  Epoch: 476  Training loss = 3.3128  Validation loss = 8.1202  \n",
      "\n",
      "Fold: 15  Epoch: 477  Training loss = 3.3123  Validation loss = 8.1190  \n",
      "\n",
      "Fold: 15  Epoch: 478  Training loss = 3.3118  Validation loss = 8.1179  \n",
      "\n",
      "Fold: 15  Epoch: 479  Training loss = 3.3113  Validation loss = 8.1168  \n",
      "\n",
      "Fold: 15  Epoch: 480  Training loss = 3.3107  Validation loss = 8.1152  \n",
      "\n",
      "Fold: 15  Epoch: 481  Training loss = 3.3104  Validation loss = 8.1146  \n",
      "\n",
      "Fold: 15  Epoch: 482  Training loss = 3.3099  Validation loss = 8.1134  \n",
      "\n",
      "Fold: 15  Epoch: 483  Training loss = 3.3094  Validation loss = 8.1122  \n",
      "\n",
      "Fold: 15  Epoch: 484  Training loss = 3.3091  Validation loss = 8.1114  \n",
      "\n",
      "Fold: 15  Epoch: 485  Training loss = 3.3087  Validation loss = 8.1104  \n",
      "\n",
      "Fold: 15  Epoch: 486  Training loss = 3.3081  Validation loss = 8.1089  \n",
      "\n",
      "Fold: 15  Epoch: 487  Training loss = 3.3078  Validation loss = 8.1081  \n",
      "\n",
      "Fold: 15  Epoch: 488  Training loss = 3.3072  Validation loss = 8.1069  \n",
      "\n",
      "Fold: 15  Epoch: 489  Training loss = 3.3068  Validation loss = 8.1058  \n",
      "\n",
      "Fold: 15  Epoch: 490  Training loss = 3.3063  Validation loss = 8.1046  \n",
      "\n",
      "Fold: 15  Epoch: 491  Training loss = 3.3058  Validation loss = 8.1036  \n",
      "\n",
      "Fold: 15  Epoch: 492  Training loss = 3.3056  Validation loss = 8.1031  \n",
      "\n",
      "Fold: 15  Epoch: 493  Training loss = 3.3052  Validation loss = 8.1021  \n",
      "\n",
      "Fold: 15  Epoch: 494  Training loss = 3.3049  Validation loss = 8.1012  \n",
      "\n",
      "Fold: 15  Epoch: 495  Training loss = 3.3044  Validation loss = 8.1001  \n",
      "\n",
      "Fold: 15  Epoch: 496  Training loss = 3.3040  Validation loss = 8.0992  \n",
      "\n",
      "Fold: 15  Epoch: 497  Training loss = 3.3035  Validation loss = 8.0979  \n",
      "\n",
      "Fold: 15  Epoch: 498  Training loss = 3.3030  Validation loss = 8.0967  \n",
      "\n",
      "Fold: 15  Epoch: 499  Training loss = 3.3025  Validation loss = 8.0955  \n",
      "\n",
      "Fold: 15  Epoch: 500  Training loss = 3.3020  Validation loss = 8.0942  \n",
      "\n",
      "Check model:  Fold: 15  Optimal epoch: 500  \n",
      "\n",
      "Fold: 16  Epoch: 1  Training loss = 3.8114  Validation loss = 5.2249  \n",
      "\n",
      "Fold: 16  Epoch: 2  Training loss = 3.8107  Validation loss = 5.2237  \n",
      "\n",
      "Fold: 16  Epoch: 3  Training loss = 3.8100  Validation loss = 5.2225  \n",
      "\n",
      "Fold: 16  Epoch: 4  Training loss = 3.8093  Validation loss = 5.2205  \n",
      "\n",
      "Fold: 16  Epoch: 5  Training loss = 3.8085  Validation loss = 5.2191  \n",
      "\n",
      "Fold: 16  Epoch: 6  Training loss = 3.8079  Validation loss = 5.2176  \n",
      "\n",
      "Fold: 16  Epoch: 7  Training loss = 3.8072  Validation loss = 5.2159  \n",
      "\n",
      "Fold: 16  Epoch: 8  Training loss = 3.8064  Validation loss = 5.2143  \n",
      "\n",
      "Fold: 16  Epoch: 9  Training loss = 3.8055  Validation loss = 5.2130  \n",
      "\n",
      "Fold: 16  Epoch: 10  Training loss = 3.8044  Validation loss = 5.2112  \n",
      "\n",
      "Fold: 16  Epoch: 11  Training loss = 3.8036  Validation loss = 5.2098  \n",
      "\n",
      "Fold: 16  Epoch: 12  Training loss = 3.8029  Validation loss = 5.2084  \n",
      "\n",
      "Fold: 16  Epoch: 13  Training loss = 3.8022  Validation loss = 5.2070  \n",
      "\n",
      "Fold: 16  Epoch: 14  Training loss = 3.8014  Validation loss = 5.2056  \n",
      "\n",
      "Fold: 16  Epoch: 15  Training loss = 3.8008  Validation loss = 5.2043  \n",
      "\n",
      "Fold: 16  Epoch: 16  Training loss = 3.7999  Validation loss = 5.2027  \n",
      "\n",
      "Fold: 16  Epoch: 17  Training loss = 3.7992  Validation loss = 5.2011  \n",
      "\n",
      "Fold: 16  Epoch: 18  Training loss = 3.7983  Validation loss = 5.1994  \n",
      "\n",
      "Fold: 16  Epoch: 19  Training loss = 3.7976  Validation loss = 5.1982  \n",
      "\n",
      "Fold: 16  Epoch: 20  Training loss = 3.7969  Validation loss = 5.1963  \n",
      "\n",
      "Fold: 16  Epoch: 21  Training loss = 3.7961  Validation loss = 5.1948  \n",
      "\n",
      "Fold: 16  Epoch: 22  Training loss = 3.7953  Validation loss = 5.1930  \n",
      "\n",
      "Fold: 16  Epoch: 23  Training loss = 3.7946  Validation loss = 5.1907  \n",
      "\n",
      "Fold: 16  Epoch: 24  Training loss = 3.7935  Validation loss = 5.1886  \n",
      "\n",
      "Fold: 16  Epoch: 25  Training loss = 3.7927  Validation loss = 5.1870  \n",
      "\n",
      "Fold: 16  Epoch: 26  Training loss = 3.7917  Validation loss = 5.1853  \n",
      "\n",
      "Fold: 16  Epoch: 27  Training loss = 3.7910  Validation loss = 5.1837  \n",
      "\n",
      "Fold: 16  Epoch: 28  Training loss = 3.7903  Validation loss = 5.1822  \n",
      "\n",
      "Fold: 16  Epoch: 29  Training loss = 3.7896  Validation loss = 5.1804  \n",
      "\n",
      "Fold: 16  Epoch: 30  Training loss = 3.7886  Validation loss = 5.1787  \n",
      "\n",
      "Fold: 16  Epoch: 31  Training loss = 3.7877  Validation loss = 5.1770  \n",
      "\n",
      "Fold: 16  Epoch: 32  Training loss = 3.7869  Validation loss = 5.1757  \n",
      "\n",
      "Fold: 16  Epoch: 33  Training loss = 3.7860  Validation loss = 5.1738  \n",
      "\n",
      "Fold: 16  Epoch: 34  Training loss = 3.7848  Validation loss = 5.1713  \n",
      "\n",
      "Fold: 16  Epoch: 35  Training loss = 3.7839  Validation loss = 5.1695  \n",
      "\n",
      "Fold: 16  Epoch: 36  Training loss = 3.7831  Validation loss = 5.1679  \n",
      "\n",
      "Fold: 16  Epoch: 37  Training loss = 3.7823  Validation loss = 5.1662  \n",
      "\n",
      "Fold: 16  Epoch: 38  Training loss = 3.7815  Validation loss = 5.1648  \n",
      "\n",
      "Fold: 16  Epoch: 39  Training loss = 3.7808  Validation loss = 5.1635  \n",
      "\n",
      "Fold: 16  Epoch: 40  Training loss = 3.7799  Validation loss = 5.1620  \n",
      "\n",
      "Fold: 16  Epoch: 41  Training loss = 3.7791  Validation loss = 5.1607  \n",
      "\n",
      "Fold: 16  Epoch: 42  Training loss = 3.7784  Validation loss = 5.1591  \n",
      "\n",
      "Fold: 16  Epoch: 43  Training loss = 3.7776  Validation loss = 5.1577  \n",
      "\n",
      "Fold: 16  Epoch: 44  Training loss = 3.7767  Validation loss = 5.1560  \n",
      "\n",
      "Fold: 16  Epoch: 45  Training loss = 3.7761  Validation loss = 5.1549  \n",
      "\n",
      "Fold: 16  Epoch: 46  Training loss = 3.7757  Validation loss = 5.1541  \n",
      "\n",
      "Fold: 16  Epoch: 47  Training loss = 3.7750  Validation loss = 5.1524  \n",
      "\n",
      "Fold: 16  Epoch: 48  Training loss = 3.7741  Validation loss = 5.1506  \n",
      "\n",
      "Fold: 16  Epoch: 49  Training loss = 3.7733  Validation loss = 5.1488  \n",
      "\n",
      "Fold: 16  Epoch: 50  Training loss = 3.7725  Validation loss = 5.1473  \n",
      "\n",
      "Fold: 16  Epoch: 51  Training loss = 3.7718  Validation loss = 5.1458  \n",
      "\n",
      "Fold: 16  Epoch: 52  Training loss = 3.7713  Validation loss = 5.1450  \n",
      "\n",
      "Fold: 16  Epoch: 53  Training loss = 3.7705  Validation loss = 5.1429  \n",
      "\n",
      "Fold: 16  Epoch: 54  Training loss = 3.7698  Validation loss = 5.1418  \n",
      "\n",
      "Fold: 16  Epoch: 55  Training loss = 3.7693  Validation loss = 5.1409  \n",
      "\n",
      "Fold: 16  Epoch: 56  Training loss = 3.7687  Validation loss = 5.1401  \n",
      "\n",
      "Fold: 16  Epoch: 57  Training loss = 3.7678  Validation loss = 5.1382  \n",
      "\n",
      "Fold: 16  Epoch: 58  Training loss = 3.7670  Validation loss = 5.1369  \n",
      "\n",
      "Fold: 16  Epoch: 59  Training loss = 3.7664  Validation loss = 5.1356  \n",
      "\n",
      "Fold: 16  Epoch: 60  Training loss = 3.7657  Validation loss = 5.1341  \n",
      "\n",
      "Fold: 16  Epoch: 61  Training loss = 3.7651  Validation loss = 5.1327  \n",
      "\n",
      "Fold: 16  Epoch: 62  Training loss = 3.7647  Validation loss = 5.1315  \n",
      "\n",
      "Fold: 16  Epoch: 63  Training loss = 3.7643  Validation loss = 5.1309  \n",
      "\n",
      "Fold: 16  Epoch: 64  Training loss = 3.7633  Validation loss = 5.1290  \n",
      "\n",
      "Fold: 16  Epoch: 65  Training loss = 3.7626  Validation loss = 5.1278  \n",
      "\n",
      "Fold: 16  Epoch: 66  Training loss = 3.7618  Validation loss = 5.1262  \n",
      "\n",
      "Fold: 16  Epoch: 67  Training loss = 3.7612  Validation loss = 5.1252  \n",
      "\n",
      "Fold: 16  Epoch: 68  Training loss = 3.7607  Validation loss = 5.1241  \n",
      "\n",
      "Fold: 16  Epoch: 69  Training loss = 3.7602  Validation loss = 5.1232  \n",
      "\n",
      "Fold: 16  Epoch: 70  Training loss = 3.7590  Validation loss = 5.1210  \n",
      "\n",
      "Fold: 16  Epoch: 71  Training loss = 3.7586  Validation loss = 5.1200  \n",
      "\n",
      "Fold: 16  Epoch: 72  Training loss = 3.7577  Validation loss = 5.1183  \n",
      "\n",
      "Fold: 16  Epoch: 73  Training loss = 3.7571  Validation loss = 5.1168  \n",
      "\n",
      "Fold: 16  Epoch: 74  Training loss = 3.7563  Validation loss = 5.1150  \n",
      "\n",
      "Fold: 16  Epoch: 75  Training loss = 3.7557  Validation loss = 5.1138  \n",
      "\n",
      "Fold: 16  Epoch: 76  Training loss = 3.7552  Validation loss = 5.1125  \n",
      "\n",
      "Fold: 16  Epoch: 77  Training loss = 3.7545  Validation loss = 5.1114  \n",
      "\n",
      "Fold: 16  Epoch: 78  Training loss = 3.7540  Validation loss = 5.1105  \n",
      "\n",
      "Fold: 16  Epoch: 79  Training loss = 3.7530  Validation loss = 5.1084  \n",
      "\n",
      "Fold: 16  Epoch: 80  Training loss = 3.7523  Validation loss = 5.1069  \n",
      "\n",
      "Fold: 16  Epoch: 81  Training loss = 3.7518  Validation loss = 5.1056  \n",
      "\n",
      "Fold: 16  Epoch: 82  Training loss = 3.7510  Validation loss = 5.1038  \n",
      "\n",
      "Fold: 16  Epoch: 83  Training loss = 3.7503  Validation loss = 5.1026  \n",
      "\n",
      "Fold: 16  Epoch: 84  Training loss = 3.7498  Validation loss = 5.1012  \n",
      "\n",
      "Fold: 16  Epoch: 85  Training loss = 3.7491  Validation loss = 5.0992  \n",
      "\n",
      "Fold: 16  Epoch: 86  Training loss = 3.7480  Validation loss = 5.0971  \n",
      "\n",
      "Fold: 16  Epoch: 87  Training loss = 3.7472  Validation loss = 5.0957  \n",
      "\n",
      "Fold: 16  Epoch: 88  Training loss = 3.7464  Validation loss = 5.0940  \n",
      "\n",
      "Fold: 16  Epoch: 89  Training loss = 3.7458  Validation loss = 5.0927  \n",
      "\n",
      "Fold: 16  Epoch: 90  Training loss = 3.7449  Validation loss = 5.0907  \n",
      "\n",
      "Fold: 16  Epoch: 91  Training loss = 3.7444  Validation loss = 5.0899  \n",
      "\n",
      "Fold: 16  Epoch: 92  Training loss = 3.7437  Validation loss = 5.0880  \n",
      "\n",
      "Fold: 16  Epoch: 93  Training loss = 3.7429  Validation loss = 5.0865  \n",
      "\n",
      "Fold: 16  Epoch: 94  Training loss = 3.7420  Validation loss = 5.0849  \n",
      "\n",
      "Fold: 16  Epoch: 95  Training loss = 3.7410  Validation loss = 5.0829  \n",
      "\n",
      "Fold: 16  Epoch: 96  Training loss = 3.7405  Validation loss = 5.0820  \n",
      "\n",
      "Fold: 16  Epoch: 97  Training loss = 3.7398  Validation loss = 5.0810  \n",
      "\n",
      "Fold: 16  Epoch: 98  Training loss = 3.7390  Validation loss = 5.0794  \n",
      "\n",
      "Fold: 16  Epoch: 99  Training loss = 3.7383  Validation loss = 5.0782  \n",
      "\n",
      "Fold: 16  Epoch: 100  Training loss = 3.7374  Validation loss = 5.0766  \n",
      "\n",
      "Fold: 16  Epoch: 101  Training loss = 3.7367  Validation loss = 5.0755  \n",
      "\n",
      "Fold: 16  Epoch: 102  Training loss = 3.7360  Validation loss = 5.0741  \n",
      "\n",
      "Fold: 16  Epoch: 103  Training loss = 3.7352  Validation loss = 5.0724  \n",
      "\n",
      "Fold: 16  Epoch: 104  Training loss = 3.7346  Validation loss = 5.0711  \n",
      "\n",
      "Fold: 16  Epoch: 105  Training loss = 3.7339  Validation loss = 5.0694  \n",
      "\n",
      "Fold: 16  Epoch: 106  Training loss = 3.7331  Validation loss = 5.0678  \n",
      "\n",
      "Fold: 16  Epoch: 107  Training loss = 3.7323  Validation loss = 5.0666  \n",
      "\n",
      "Fold: 16  Epoch: 108  Training loss = 3.7319  Validation loss = 5.0655  \n",
      "\n",
      "Fold: 16  Epoch: 109  Training loss = 3.7310  Validation loss = 5.0636  \n",
      "\n",
      "Fold: 16  Epoch: 110  Training loss = 3.7304  Validation loss = 5.0625  \n",
      "\n",
      "Fold: 16  Epoch: 111  Training loss = 3.7299  Validation loss = 5.0615  \n",
      "\n",
      "Fold: 16  Epoch: 112  Training loss = 3.7292  Validation loss = 5.0597  \n",
      "\n",
      "Fold: 16  Epoch: 113  Training loss = 3.7286  Validation loss = 5.0585  \n",
      "\n",
      "Fold: 16  Epoch: 114  Training loss = 3.7278  Validation loss = 5.0571  \n",
      "\n",
      "Fold: 16  Epoch: 115  Training loss = 3.7270  Validation loss = 5.0558  \n",
      "\n",
      "Fold: 16  Epoch: 116  Training loss = 3.7266  Validation loss = 5.0549  \n",
      "\n",
      "Fold: 16  Epoch: 117  Training loss = 3.7258  Validation loss = 5.0532  \n",
      "\n",
      "Fold: 16  Epoch: 118  Training loss = 3.7250  Validation loss = 5.0518  \n",
      "\n",
      "Fold: 16  Epoch: 119  Training loss = 3.7241  Validation loss = 5.0500  \n",
      "\n",
      "Fold: 16  Epoch: 120  Training loss = 3.7236  Validation loss = 5.0482  \n",
      "\n",
      "Fold: 16  Epoch: 121  Training loss = 3.7227  Validation loss = 5.0461  \n",
      "\n",
      "Fold: 16  Epoch: 122  Training loss = 3.7218  Validation loss = 5.0442  \n",
      "\n",
      "Fold: 16  Epoch: 123  Training loss = 3.7211  Validation loss = 5.0429  \n",
      "\n",
      "Fold: 16  Epoch: 124  Training loss = 3.7204  Validation loss = 5.0418  \n",
      "\n",
      "Fold: 16  Epoch: 125  Training loss = 3.7198  Validation loss = 5.0407  \n",
      "\n",
      "Fold: 16  Epoch: 126  Training loss = 3.7190  Validation loss = 5.0391  \n",
      "\n",
      "Fold: 16  Epoch: 127  Training loss = 3.7182  Validation loss = 5.0379  \n",
      "\n",
      "Fold: 16  Epoch: 128  Training loss = 3.7177  Validation loss = 5.0371  \n",
      "\n",
      "Fold: 16  Epoch: 129  Training loss = 3.7172  Validation loss = 5.0360  \n",
      "\n",
      "Fold: 16  Epoch: 130  Training loss = 3.7166  Validation loss = 5.0350  \n",
      "\n",
      "Fold: 16  Epoch: 131  Training loss = 3.7156  Validation loss = 5.0327  \n",
      "\n",
      "Fold: 16  Epoch: 132  Training loss = 3.7149  Validation loss = 5.0313  \n",
      "\n",
      "Fold: 16  Epoch: 133  Training loss = 3.7143  Validation loss = 5.0299  \n",
      "\n",
      "Fold: 16  Epoch: 134  Training loss = 3.7136  Validation loss = 5.0285  \n",
      "\n",
      "Fold: 16  Epoch: 135  Training loss = 3.7130  Validation loss = 5.0270  \n",
      "\n",
      "Fold: 16  Epoch: 136  Training loss = 3.7123  Validation loss = 5.0253  \n",
      "\n",
      "Fold: 16  Epoch: 137  Training loss = 3.7117  Validation loss = 5.0243  \n",
      "\n",
      "Fold: 16  Epoch: 138  Training loss = 3.7111  Validation loss = 5.0231  \n",
      "\n",
      "Fold: 16  Epoch: 139  Training loss = 3.7104  Validation loss = 5.0219  \n",
      "\n",
      "Fold: 16  Epoch: 140  Training loss = 3.7097  Validation loss = 5.0205  \n",
      "\n",
      "Fold: 16  Epoch: 141  Training loss = 3.7091  Validation loss = 5.0191  \n",
      "\n",
      "Fold: 16  Epoch: 142  Training loss = 3.7082  Validation loss = 5.0174  \n",
      "\n",
      "Fold: 16  Epoch: 143  Training loss = 3.7076  Validation loss = 5.0162  \n",
      "\n",
      "Fold: 16  Epoch: 144  Training loss = 3.7070  Validation loss = 5.0151  \n",
      "\n",
      "Fold: 16  Epoch: 145  Training loss = 3.7063  Validation loss = 5.0136  \n",
      "\n",
      "Fold: 16  Epoch: 146  Training loss = 3.7057  Validation loss = 5.0122  \n",
      "\n",
      "Fold: 16  Epoch: 147  Training loss = 3.7052  Validation loss = 5.0115  \n",
      "\n",
      "Fold: 16  Epoch: 148  Training loss = 3.7046  Validation loss = 5.0103  \n",
      "\n",
      "Fold: 16  Epoch: 149  Training loss = 3.7038  Validation loss = 5.0088  \n",
      "\n",
      "Fold: 16  Epoch: 150  Training loss = 3.7033  Validation loss = 5.0079  \n",
      "\n",
      "Fold: 16  Epoch: 151  Training loss = 3.7026  Validation loss = 5.0065  \n",
      "\n",
      "Fold: 16  Epoch: 152  Training loss = 3.7022  Validation loss = 5.0057  \n",
      "\n",
      "Fold: 16  Epoch: 153  Training loss = 3.7014  Validation loss = 5.0043  \n",
      "\n",
      "Fold: 16  Epoch: 154  Training loss = 3.7007  Validation loss = 5.0029  \n",
      "\n",
      "Fold: 16  Epoch: 155  Training loss = 3.7001  Validation loss = 5.0017  \n",
      "\n",
      "Fold: 16  Epoch: 156  Training loss = 3.6995  Validation loss = 5.0002  \n",
      "\n",
      "Fold: 16  Epoch: 157  Training loss = 3.6990  Validation loss = 4.9991  \n",
      "\n",
      "Fold: 16  Epoch: 158  Training loss = 3.6983  Validation loss = 4.9977  \n",
      "\n",
      "Fold: 16  Epoch: 159  Training loss = 3.6977  Validation loss = 4.9966  \n",
      "\n",
      "Fold: 16  Epoch: 160  Training loss = 3.6970  Validation loss = 4.9950  \n",
      "\n",
      "Fold: 16  Epoch: 161  Training loss = 3.6964  Validation loss = 4.9940  \n",
      "\n",
      "Fold: 16  Epoch: 162  Training loss = 3.6956  Validation loss = 4.9923  \n",
      "\n",
      "Fold: 16  Epoch: 163  Training loss = 3.6951  Validation loss = 4.9915  \n",
      "\n",
      "Fold: 16  Epoch: 164  Training loss = 3.6946  Validation loss = 4.9905  \n",
      "\n",
      "Fold: 16  Epoch: 165  Training loss = 3.6941  Validation loss = 4.9894  \n",
      "\n",
      "Fold: 16  Epoch: 166  Training loss = 3.6936  Validation loss = 4.9883  \n",
      "\n",
      "Fold: 16  Epoch: 167  Training loss = 3.6931  Validation loss = 4.9876  \n",
      "\n",
      "Fold: 16  Epoch: 168  Training loss = 3.6922  Validation loss = 4.9853  \n",
      "\n",
      "Fold: 16  Epoch: 169  Training loss = 3.6918  Validation loss = 4.9844  \n",
      "\n",
      "Fold: 16  Epoch: 170  Training loss = 3.6911  Validation loss = 4.9830  \n",
      "\n",
      "Fold: 16  Epoch: 171  Training loss = 3.6907  Validation loss = 4.9821  \n",
      "\n",
      "Fold: 16  Epoch: 172  Training loss = 3.6901  Validation loss = 4.9806  \n",
      "\n",
      "Fold: 16  Epoch: 173  Training loss = 3.6893  Validation loss = 4.9790  \n",
      "\n",
      "Fold: 16  Epoch: 174  Training loss = 3.6886  Validation loss = 4.9777  \n",
      "\n",
      "Fold: 16  Epoch: 175  Training loss = 3.6878  Validation loss = 4.9763  \n",
      "\n",
      "Fold: 16  Epoch: 176  Training loss = 3.6873  Validation loss = 4.9754  \n",
      "\n",
      "Fold: 16  Epoch: 177  Training loss = 3.6867  Validation loss = 4.9742  \n",
      "\n",
      "Fold: 16  Epoch: 178  Training loss = 3.6860  Validation loss = 4.9726  \n",
      "\n",
      "Fold: 16  Epoch: 179  Training loss = 3.6854  Validation loss = 4.9716  \n",
      "\n",
      "Fold: 16  Epoch: 180  Training loss = 3.6847  Validation loss = 4.9704  \n",
      "\n",
      "Fold: 16  Epoch: 181  Training loss = 3.6840  Validation loss = 4.9688  \n",
      "\n",
      "Fold: 16  Epoch: 182  Training loss = 3.6834  Validation loss = 4.9678  \n",
      "\n",
      "Fold: 16  Epoch: 183  Training loss = 3.6827  Validation loss = 4.9666  \n",
      "\n",
      "Fold: 16  Epoch: 184  Training loss = 3.6820  Validation loss = 4.9650  \n",
      "\n",
      "Fold: 16  Epoch: 185  Training loss = 3.6817  Validation loss = 4.9644  \n",
      "\n",
      "Fold: 16  Epoch: 186  Training loss = 3.6808  Validation loss = 4.9627  \n",
      "\n",
      "Fold: 16  Epoch: 187  Training loss = 3.6798  Validation loss = 4.9608  \n",
      "\n",
      "Fold: 16  Epoch: 188  Training loss = 3.6792  Validation loss = 4.9595  \n",
      "\n",
      "Fold: 16  Epoch: 189  Training loss = 3.6785  Validation loss = 4.9578  \n",
      "\n",
      "Fold: 16  Epoch: 190  Training loss = 3.6779  Validation loss = 4.9569  \n",
      "\n",
      "Fold: 16  Epoch: 191  Training loss = 3.6771  Validation loss = 4.9552  \n",
      "\n",
      "Fold: 16  Epoch: 192  Training loss = 3.6766  Validation loss = 4.9543  \n",
      "\n",
      "Fold: 16  Epoch: 193  Training loss = 3.6761  Validation loss = 4.9532  \n",
      "\n",
      "Fold: 16  Epoch: 194  Training loss = 3.6754  Validation loss = 4.9518  \n",
      "\n",
      "Fold: 16  Epoch: 195  Training loss = 3.6747  Validation loss = 4.9506  \n",
      "\n",
      "Fold: 16  Epoch: 196  Training loss = 3.6743  Validation loss = 4.9500  \n",
      "\n",
      "Fold: 16  Epoch: 197  Training loss = 3.6737  Validation loss = 4.9486  \n",
      "\n",
      "Fold: 16  Epoch: 198  Training loss = 3.6732  Validation loss = 4.9478  \n",
      "\n",
      "Fold: 16  Epoch: 199  Training loss = 3.6726  Validation loss = 4.9464  \n",
      "\n",
      "Fold: 16  Epoch: 200  Training loss = 3.6722  Validation loss = 4.9455  \n",
      "\n",
      "Fold: 16  Epoch: 201  Training loss = 3.6717  Validation loss = 4.9441  \n",
      "\n",
      "Fold: 16  Epoch: 202  Training loss = 3.6711  Validation loss = 4.9431  \n",
      "\n",
      "Fold: 16  Epoch: 203  Training loss = 3.6706  Validation loss = 4.9422  \n",
      "\n",
      "Fold: 16  Epoch: 204  Training loss = 3.6701  Validation loss = 4.9410  \n",
      "\n",
      "Fold: 16  Epoch: 205  Training loss = 3.6694  Validation loss = 4.9396  \n",
      "\n",
      "Fold: 16  Epoch: 206  Training loss = 3.6687  Validation loss = 4.9381  \n",
      "\n",
      "Fold: 16  Epoch: 207  Training loss = 3.6682  Validation loss = 4.9368  \n",
      "\n",
      "Fold: 16  Epoch: 208  Training loss = 3.6675  Validation loss = 4.9358  \n",
      "\n",
      "Fold: 16  Epoch: 209  Training loss = 3.6668  Validation loss = 4.9344  \n",
      "\n",
      "Fold: 16  Epoch: 210  Training loss = 3.6661  Validation loss = 4.9327  \n",
      "\n",
      "Fold: 16  Epoch: 211  Training loss = 3.6654  Validation loss = 4.9313  \n",
      "\n",
      "Fold: 16  Epoch: 212  Training loss = 3.6650  Validation loss = 4.9302  \n",
      "\n",
      "Fold: 16  Epoch: 213  Training loss = 3.6643  Validation loss = 4.9289  \n",
      "\n",
      "Fold: 16  Epoch: 214  Training loss = 3.6636  Validation loss = 4.9277  \n",
      "\n",
      "Fold: 16  Epoch: 215  Training loss = 3.6629  Validation loss = 4.9263  \n",
      "\n",
      "Fold: 16  Epoch: 216  Training loss = 3.6620  Validation loss = 4.9248  \n",
      "\n",
      "Fold: 16  Epoch: 217  Training loss = 3.6614  Validation loss = 4.9234  \n",
      "\n",
      "Fold: 16  Epoch: 218  Training loss = 3.6608  Validation loss = 4.9222  \n",
      "\n",
      "Fold: 16  Epoch: 219  Training loss = 3.6601  Validation loss = 4.9204  \n",
      "\n",
      "Fold: 16  Epoch: 220  Training loss = 3.6596  Validation loss = 4.9193  \n",
      "\n",
      "Fold: 16  Epoch: 221  Training loss = 3.6589  Validation loss = 4.9177  \n",
      "\n",
      "Fold: 16  Epoch: 222  Training loss = 3.6584  Validation loss = 4.9164  \n",
      "\n",
      "Fold: 16  Epoch: 223  Training loss = 3.6578  Validation loss = 4.9147  \n",
      "\n",
      "Fold: 16  Epoch: 224  Training loss = 3.6575  Validation loss = 4.9136  \n",
      "\n",
      "Fold: 16  Epoch: 225  Training loss = 3.6569  Validation loss = 4.9125  \n",
      "\n",
      "Fold: 16  Epoch: 226  Training loss = 3.6561  Validation loss = 4.9106  \n",
      "\n",
      "Fold: 16  Epoch: 227  Training loss = 3.6555  Validation loss = 4.9093  \n",
      "\n",
      "Fold: 16  Epoch: 228  Training loss = 3.6550  Validation loss = 4.9082  \n",
      "\n",
      "Fold: 16  Epoch: 229  Training loss = 3.6543  Validation loss = 4.9067  \n",
      "\n",
      "Fold: 16  Epoch: 230  Training loss = 3.6537  Validation loss = 4.9056  \n",
      "\n",
      "Fold: 16  Epoch: 231  Training loss = 3.6530  Validation loss = 4.9042  \n",
      "\n",
      "Fold: 16  Epoch: 232  Training loss = 3.6525  Validation loss = 4.9031  \n",
      "\n",
      "Fold: 16  Epoch: 233  Training loss = 3.6520  Validation loss = 4.9020  \n",
      "\n",
      "Fold: 16  Epoch: 234  Training loss = 3.6514  Validation loss = 4.9008  \n",
      "\n",
      "Fold: 16  Epoch: 235  Training loss = 3.6507  Validation loss = 4.8992  \n",
      "\n",
      "Fold: 16  Epoch: 236  Training loss = 3.6501  Validation loss = 4.8979  \n",
      "\n",
      "Fold: 16  Epoch: 237  Training loss = 3.6495  Validation loss = 4.8968  \n",
      "\n",
      "Fold: 16  Epoch: 238  Training loss = 3.6490  Validation loss = 4.8957  \n",
      "\n",
      "Fold: 16  Epoch: 239  Training loss = 3.6481  Validation loss = 4.8941  \n",
      "\n",
      "Fold: 16  Epoch: 240  Training loss = 3.6475  Validation loss = 4.8930  \n",
      "\n",
      "Fold: 16  Epoch: 241  Training loss = 3.6472  Validation loss = 4.8922  \n",
      "\n",
      "Fold: 16  Epoch: 242  Training loss = 3.6466  Validation loss = 4.8906  \n",
      "\n",
      "Fold: 16  Epoch: 243  Training loss = 3.6460  Validation loss = 4.8895  \n",
      "\n",
      "Fold: 16  Epoch: 244  Training loss = 3.6453  Validation loss = 4.8883  \n",
      "\n",
      "Fold: 16  Epoch: 245  Training loss = 3.6446  Validation loss = 4.8867  \n",
      "\n",
      "Fold: 16  Epoch: 246  Training loss = 3.6441  Validation loss = 4.8855  \n",
      "\n",
      "Fold: 16  Epoch: 247  Training loss = 3.6436  Validation loss = 4.8844  \n",
      "\n",
      "Fold: 16  Epoch: 248  Training loss = 3.6428  Validation loss = 4.8830  \n",
      "\n",
      "Fold: 16  Epoch: 249  Training loss = 3.6422  Validation loss = 4.8817  \n",
      "\n",
      "Fold: 16  Epoch: 250  Training loss = 3.6414  Validation loss = 4.8803  \n",
      "\n",
      "Fold: 16  Epoch: 251  Training loss = 3.6411  Validation loss = 4.8794  \n",
      "\n",
      "Fold: 16  Epoch: 252  Training loss = 3.6405  Validation loss = 4.8782  \n",
      "\n",
      "Fold: 16  Epoch: 253  Training loss = 3.6398  Validation loss = 4.8766  \n",
      "\n",
      "Fold: 16  Epoch: 254  Training loss = 3.6392  Validation loss = 4.8757  \n",
      "\n",
      "Fold: 16  Epoch: 255  Training loss = 3.6386  Validation loss = 4.8744  \n",
      "\n",
      "Fold: 16  Epoch: 256  Training loss = 3.6382  Validation loss = 4.8734  \n",
      "\n",
      "Fold: 16  Epoch: 257  Training loss = 3.6376  Validation loss = 4.8723  \n",
      "\n",
      "Fold: 16  Epoch: 258  Training loss = 3.6371  Validation loss = 4.8715  \n",
      "\n",
      "Fold: 16  Epoch: 259  Training loss = 3.6368  Validation loss = 4.8706  \n",
      "\n",
      "Fold: 16  Epoch: 260  Training loss = 3.6363  Validation loss = 4.8694  \n",
      "\n",
      "Fold: 16  Epoch: 261  Training loss = 3.6357  Validation loss = 4.8681  \n",
      "\n",
      "Fold: 16  Epoch: 262  Training loss = 3.6352  Validation loss = 4.8669  \n",
      "\n",
      "Fold: 16  Epoch: 263  Training loss = 3.6348  Validation loss = 4.8659  \n",
      "\n",
      "Fold: 16  Epoch: 264  Training loss = 3.6340  Validation loss = 4.8641  \n",
      "\n",
      "Fold: 16  Epoch: 265  Training loss = 3.6334  Validation loss = 4.8628  \n",
      "\n",
      "Fold: 16  Epoch: 266  Training loss = 3.6328  Validation loss = 4.8614  \n",
      "\n",
      "Fold: 16  Epoch: 267  Training loss = 3.6320  Validation loss = 4.8596  \n",
      "\n",
      "Fold: 16  Epoch: 268  Training loss = 3.6311  Validation loss = 4.8576  \n",
      "\n",
      "Fold: 16  Epoch: 269  Training loss = 3.6304  Validation loss = 4.8559  \n",
      "\n",
      "Fold: 16  Epoch: 270  Training loss = 3.6298  Validation loss = 4.8548  \n",
      "\n",
      "Fold: 16  Epoch: 271  Training loss = 3.6294  Validation loss = 4.8539  \n",
      "\n",
      "Fold: 16  Epoch: 272  Training loss = 3.6290  Validation loss = 4.8532  \n",
      "\n",
      "Fold: 16  Epoch: 273  Training loss = 3.6282  Validation loss = 4.8515  \n",
      "\n",
      "Fold: 16  Epoch: 274  Training loss = 3.6276  Validation loss = 4.8500  \n",
      "\n",
      "Fold: 16  Epoch: 275  Training loss = 3.6270  Validation loss = 4.8487  \n",
      "\n",
      "Fold: 16  Epoch: 276  Training loss = 3.6265  Validation loss = 4.8475  \n",
      "\n",
      "Fold: 16  Epoch: 277  Training loss = 3.6258  Validation loss = 4.8460  \n",
      "\n",
      "Fold: 16  Epoch: 278  Training loss = 3.6252  Validation loss = 4.8447  \n",
      "\n",
      "Fold: 16  Epoch: 279  Training loss = 3.6245  Validation loss = 4.8430  \n",
      "\n",
      "Fold: 16  Epoch: 280  Training loss = 3.6240  Validation loss = 4.8418  \n",
      "\n",
      "Fold: 16  Epoch: 281  Training loss = 3.6233  Validation loss = 4.8404  \n",
      "\n",
      "Fold: 16  Epoch: 282  Training loss = 3.6227  Validation loss = 4.8394  \n",
      "\n",
      "Fold: 16  Epoch: 283  Training loss = 3.6224  Validation loss = 4.8386  \n",
      "\n",
      "Fold: 16  Epoch: 284  Training loss = 3.6215  Validation loss = 4.8366  \n",
      "\n",
      "Fold: 16  Epoch: 285  Training loss = 3.6214  Validation loss = 4.8364  \n",
      "\n",
      "Fold: 16  Epoch: 286  Training loss = 3.6208  Validation loss = 4.8352  \n",
      "\n",
      "Fold: 16  Epoch: 287  Training loss = 3.6202  Validation loss = 4.8336  \n",
      "\n",
      "Fold: 16  Epoch: 288  Training loss = 3.6196  Validation loss = 4.8326  \n",
      "\n",
      "Fold: 16  Epoch: 289  Training loss = 3.6189  Validation loss = 4.8311  \n",
      "\n",
      "Fold: 16  Epoch: 290  Training loss = 3.6185  Validation loss = 4.8302  \n",
      "\n",
      "Fold: 16  Epoch: 291  Training loss = 3.6180  Validation loss = 4.8292  \n",
      "\n",
      "Fold: 16  Epoch: 292  Training loss = 3.6173  Validation loss = 4.8276  \n",
      "\n",
      "Fold: 16  Epoch: 293  Training loss = 3.6168  Validation loss = 4.8261  \n",
      "\n",
      "Fold: 16  Epoch: 294  Training loss = 3.6163  Validation loss = 4.8252  \n",
      "\n",
      "Fold: 16  Epoch: 295  Training loss = 3.6157  Validation loss = 4.8239  \n",
      "\n",
      "Fold: 16  Epoch: 296  Training loss = 3.6153  Validation loss = 4.8232  \n",
      "\n",
      "Fold: 16  Epoch: 297  Training loss = 3.6147  Validation loss = 4.8219  \n",
      "\n",
      "Fold: 16  Epoch: 298  Training loss = 3.6142  Validation loss = 4.8209  \n",
      "\n",
      "Fold: 16  Epoch: 299  Training loss = 3.6139  Validation loss = 4.8202  \n",
      "\n",
      "Fold: 16  Epoch: 300  Training loss = 3.6132  Validation loss = 4.8188  \n",
      "\n",
      "Fold: 16  Epoch: 301  Training loss = 3.6127  Validation loss = 4.8178  \n",
      "\n",
      "Fold: 16  Epoch: 302  Training loss = 3.6121  Validation loss = 4.8166  \n",
      "\n",
      "Fold: 16  Epoch: 303  Training loss = 3.6115  Validation loss = 4.8153  \n",
      "\n",
      "Fold: 16  Epoch: 304  Training loss = 3.6112  Validation loss = 4.8144  \n",
      "\n",
      "Fold: 16  Epoch: 305  Training loss = 3.6104  Validation loss = 4.8129  \n",
      "\n",
      "Fold: 16  Epoch: 306  Training loss = 3.6101  Validation loss = 4.8119  \n",
      "\n",
      "Fold: 16  Epoch: 307  Training loss = 3.6094  Validation loss = 4.8106  \n",
      "\n",
      "Fold: 16  Epoch: 308  Training loss = 3.6088  Validation loss = 4.8090  \n",
      "\n",
      "Fold: 16  Epoch: 309  Training loss = 3.6083  Validation loss = 4.8080  \n",
      "\n",
      "Fold: 16  Epoch: 310  Training loss = 3.6076  Validation loss = 4.8064  \n",
      "\n",
      "Fold: 16  Epoch: 311  Training loss = 3.6071  Validation loss = 4.8051  \n",
      "\n",
      "Fold: 16  Epoch: 312  Training loss = 3.6069  Validation loss = 4.8046  \n",
      "\n",
      "Fold: 16  Epoch: 313  Training loss = 3.6063  Validation loss = 4.8033  \n",
      "\n",
      "Fold: 16  Epoch: 314  Training loss = 3.6057  Validation loss = 4.8022  \n",
      "\n",
      "Fold: 16  Epoch: 315  Training loss = 3.6051  Validation loss = 4.8010  \n",
      "\n",
      "Fold: 16  Epoch: 316  Training loss = 3.6045  Validation loss = 4.7999  \n",
      "\n",
      "Fold: 16  Epoch: 317  Training loss = 3.6039  Validation loss = 4.7984  \n",
      "\n",
      "Fold: 16  Epoch: 318  Training loss = 3.6032  Validation loss = 4.7971  \n",
      "\n",
      "Fold: 16  Epoch: 319  Training loss = 3.6029  Validation loss = 4.7963  \n",
      "\n",
      "Fold: 16  Epoch: 320  Training loss = 3.6021  Validation loss = 4.7944  \n",
      "\n",
      "Fold: 16  Epoch: 321  Training loss = 3.6016  Validation loss = 4.7932  \n",
      "\n",
      "Fold: 16  Epoch: 322  Training loss = 3.6011  Validation loss = 4.7923  \n",
      "\n",
      "Fold: 16  Epoch: 323  Training loss = 3.6007  Validation loss = 4.7912  \n",
      "\n",
      "Fold: 16  Epoch: 324  Training loss = 3.6003  Validation loss = 4.7901  \n",
      "\n",
      "Fold: 16  Epoch: 325  Training loss = 3.5996  Validation loss = 4.7886  \n",
      "\n",
      "Fold: 16  Epoch: 326  Training loss = 3.5990  Validation loss = 4.7869  \n",
      "\n",
      "Fold: 16  Epoch: 327  Training loss = 3.5986  Validation loss = 4.7861  \n",
      "\n",
      "Fold: 16  Epoch: 328  Training loss = 3.5982  Validation loss = 4.7853  \n",
      "\n",
      "Fold: 16  Epoch: 329  Training loss = 3.5974  Validation loss = 4.7835  \n",
      "\n",
      "Fold: 16  Epoch: 330  Training loss = 3.5968  Validation loss = 4.7818  \n",
      "\n",
      "Fold: 16  Epoch: 331  Training loss = 3.5963  Validation loss = 4.7807  \n",
      "\n",
      "Fold: 16  Epoch: 332  Training loss = 3.5957  Validation loss = 4.7794  \n",
      "\n",
      "Fold: 16  Epoch: 333  Training loss = 3.5948  Validation loss = 4.7775  \n",
      "\n",
      "Fold: 16  Epoch: 334  Training loss = 3.5944  Validation loss = 4.7763  \n",
      "\n",
      "Fold: 16  Epoch: 335  Training loss = 3.5938  Validation loss = 4.7750  \n",
      "\n",
      "Fold: 16  Epoch: 336  Training loss = 3.5933  Validation loss = 4.7739  \n",
      "\n",
      "Fold: 16  Epoch: 337  Training loss = 3.5929  Validation loss = 4.7730  \n",
      "\n",
      "Fold: 16  Epoch: 338  Training loss = 3.5927  Validation loss = 4.7725  \n",
      "\n",
      "Fold: 16  Epoch: 339  Training loss = 3.5920  Validation loss = 4.7710  \n",
      "\n",
      "Fold: 16  Epoch: 340  Training loss = 3.5913  Validation loss = 4.7694  \n",
      "\n",
      "Fold: 16  Epoch: 341  Training loss = 3.5908  Validation loss = 4.7685  \n",
      "\n",
      "Fold: 16  Epoch: 342  Training loss = 3.5902  Validation loss = 4.7674  \n",
      "\n",
      "Fold: 16  Epoch: 343  Training loss = 3.5898  Validation loss = 4.7667  \n",
      "\n",
      "Fold: 16  Epoch: 344  Training loss = 3.5892  Validation loss = 4.7650  \n",
      "\n",
      "Fold: 16  Epoch: 345  Training loss = 3.5889  Validation loss = 4.7642  \n",
      "\n",
      "Fold: 16  Epoch: 346  Training loss = 3.5883  Validation loss = 4.7633  \n",
      "\n",
      "Fold: 16  Epoch: 347  Training loss = 3.5879  Validation loss = 4.7624  \n",
      "\n",
      "Fold: 16  Epoch: 348  Training loss = 3.5875  Validation loss = 4.7613  \n",
      "\n",
      "Fold: 16  Epoch: 349  Training loss = 3.5870  Validation loss = 4.7602  \n",
      "\n",
      "Fold: 16  Epoch: 350  Training loss = 3.5863  Validation loss = 4.7585  \n",
      "\n",
      "Fold: 16  Epoch: 351  Training loss = 3.5857  Validation loss = 4.7573  \n",
      "\n",
      "Fold: 16  Epoch: 352  Training loss = 3.5848  Validation loss = 4.7555  \n",
      "\n",
      "Fold: 16  Epoch: 353  Training loss = 3.5841  Validation loss = 4.7546  \n",
      "\n",
      "Fold: 16  Epoch: 354  Training loss = 3.5835  Validation loss = 4.7529  \n",
      "\n",
      "Fold: 16  Epoch: 355  Training loss = 3.5827  Validation loss = 4.7518  \n",
      "\n",
      "Fold: 16  Epoch: 356  Training loss = 3.5823  Validation loss = 4.7511  \n",
      "\n",
      "Fold: 16  Epoch: 357  Training loss = 3.5817  Validation loss = 4.7498  \n",
      "\n",
      "Fold: 16  Epoch: 358  Training loss = 3.5811  Validation loss = 4.7487  \n",
      "\n",
      "Fold: 16  Epoch: 359  Training loss = 3.5806  Validation loss = 4.7473  \n",
      "\n",
      "Fold: 16  Epoch: 360  Training loss = 3.5801  Validation loss = 4.7462  \n",
      "\n",
      "Fold: 16  Epoch: 361  Training loss = 3.5795  Validation loss = 4.7446  \n",
      "\n",
      "Fold: 16  Epoch: 362  Training loss = 3.5790  Validation loss = 4.7437  \n",
      "\n",
      "Fold: 16  Epoch: 363  Training loss = 3.5782  Validation loss = 4.7422  \n",
      "\n",
      "Fold: 16  Epoch: 364  Training loss = 3.5779  Validation loss = 4.7411  \n",
      "\n",
      "Fold: 16  Epoch: 365  Training loss = 3.5775  Validation loss = 4.7402  \n",
      "\n",
      "Fold: 16  Epoch: 366  Training loss = 3.5769  Validation loss = 4.7391  \n",
      "\n",
      "Fold: 16  Epoch: 367  Training loss = 3.5764  Validation loss = 4.7379  \n",
      "\n",
      "Fold: 16  Epoch: 368  Training loss = 3.5760  Validation loss = 4.7371  \n",
      "\n",
      "Fold: 16  Epoch: 369  Training loss = 3.5755  Validation loss = 4.7362  \n",
      "\n",
      "Fold: 16  Epoch: 370  Training loss = 3.5750  Validation loss = 4.7349  \n",
      "\n",
      "Fold: 16  Epoch: 371  Training loss = 3.5745  Validation loss = 4.7336  \n",
      "\n",
      "Fold: 16  Epoch: 372  Training loss = 3.5739  Validation loss = 4.7325  \n",
      "\n",
      "Fold: 16  Epoch: 373  Training loss = 3.5732  Validation loss = 4.7309  \n",
      "\n",
      "Fold: 16  Epoch: 374  Training loss = 3.5723  Validation loss = 4.7290  \n",
      "\n",
      "Fold: 16  Epoch: 375  Training loss = 3.5719  Validation loss = 4.7280  \n",
      "\n",
      "Fold: 16  Epoch: 376  Training loss = 3.5713  Validation loss = 4.7269  \n",
      "\n",
      "Fold: 16  Epoch: 377  Training loss = 3.5709  Validation loss = 4.7259  \n",
      "\n",
      "Fold: 16  Epoch: 378  Training loss = 3.5708  Validation loss = 4.7256  \n",
      "\n",
      "Fold: 16  Epoch: 379  Training loss = 3.5701  Validation loss = 4.7236  \n",
      "\n",
      "Fold: 16  Epoch: 380  Training loss = 3.5697  Validation loss = 4.7225  \n",
      "\n",
      "Fold: 16  Epoch: 381  Training loss = 3.5693  Validation loss = 4.7212  \n",
      "\n",
      "Fold: 16  Epoch: 382  Training loss = 3.5688  Validation loss = 4.7197  \n",
      "\n",
      "Fold: 16  Epoch: 383  Training loss = 3.5683  Validation loss = 4.7189  \n",
      "\n",
      "Fold: 16  Epoch: 384  Training loss = 3.5678  Validation loss = 4.7177  \n",
      "\n",
      "Fold: 16  Epoch: 385  Training loss = 3.5672  Validation loss = 4.7164  \n",
      "\n",
      "Fold: 16  Epoch: 386  Training loss = 3.5667  Validation loss = 4.7153  \n",
      "\n",
      "Fold: 16  Epoch: 387  Training loss = 3.5663  Validation loss = 4.7145  \n",
      "\n",
      "Fold: 16  Epoch: 388  Training loss = 3.5660  Validation loss = 4.7134  \n",
      "\n",
      "Fold: 16  Epoch: 389  Training loss = 3.5655  Validation loss = 4.7124  \n",
      "\n",
      "Fold: 16  Epoch: 390  Training loss = 3.5650  Validation loss = 4.7113  \n",
      "\n",
      "Fold: 16  Epoch: 391  Training loss = 3.5645  Validation loss = 4.7104  \n",
      "\n",
      "Fold: 16  Epoch: 392  Training loss = 3.5640  Validation loss = 4.7093  \n",
      "\n",
      "Fold: 16  Epoch: 393  Training loss = 3.5636  Validation loss = 4.7085  \n",
      "\n",
      "Fold: 16  Epoch: 394  Training loss = 3.5634  Validation loss = 4.7079  \n",
      "\n",
      "Fold: 16  Epoch: 395  Training loss = 3.5629  Validation loss = 4.7066  \n",
      "\n",
      "Fold: 16  Epoch: 396  Training loss = 3.5624  Validation loss = 4.7055  \n",
      "\n",
      "Fold: 16  Epoch: 397  Training loss = 3.5622  Validation loss = 4.7047  \n",
      "\n",
      "Fold: 16  Epoch: 398  Training loss = 3.5616  Validation loss = 4.7032  \n",
      "\n",
      "Fold: 16  Epoch: 399  Training loss = 3.5610  Validation loss = 4.7020  \n",
      "\n",
      "Fold: 16  Epoch: 400  Training loss = 3.5603  Validation loss = 4.7004  \n",
      "\n",
      "Fold: 16  Epoch: 401  Training loss = 3.5598  Validation loss = 4.6993  \n",
      "\n",
      "Fold: 16  Epoch: 402  Training loss = 3.5591  Validation loss = 4.6977  \n",
      "\n",
      "Fold: 16  Epoch: 403  Training loss = 3.5585  Validation loss = 4.6966  \n",
      "\n",
      "Fold: 16  Epoch: 404  Training loss = 3.5581  Validation loss = 4.6955  \n",
      "\n",
      "Fold: 16  Epoch: 405  Training loss = 3.5576  Validation loss = 4.6946  \n",
      "\n",
      "Fold: 16  Epoch: 406  Training loss = 3.5569  Validation loss = 4.6931  \n",
      "\n",
      "Fold: 16  Epoch: 407  Training loss = 3.5565  Validation loss = 4.6923  \n",
      "\n",
      "Fold: 16  Epoch: 408  Training loss = 3.5561  Validation loss = 4.6914  \n",
      "\n",
      "Fold: 16  Epoch: 409  Training loss = 3.5556  Validation loss = 4.6904  \n",
      "\n",
      "Fold: 16  Epoch: 410  Training loss = 3.5552  Validation loss = 4.6898  \n",
      "\n",
      "Fold: 16  Epoch: 411  Training loss = 3.5545  Validation loss = 4.6881  \n",
      "\n",
      "Fold: 16  Epoch: 412  Training loss = 3.5540  Validation loss = 4.6870  \n",
      "\n",
      "Fold: 16  Epoch: 413  Training loss = 3.5536  Validation loss = 4.6861  \n",
      "\n",
      "Fold: 16  Epoch: 414  Training loss = 3.5527  Validation loss = 4.6843  \n",
      "\n",
      "Fold: 16  Epoch: 415  Training loss = 3.5520  Validation loss = 4.6825  \n",
      "\n",
      "Fold: 16  Epoch: 416  Training loss = 3.5512  Validation loss = 4.6811  \n",
      "\n",
      "Fold: 16  Epoch: 417  Training loss = 3.5508  Validation loss = 4.6797  \n",
      "\n",
      "Fold: 16  Epoch: 418  Training loss = 3.5502  Validation loss = 4.6784  \n",
      "\n",
      "Fold: 16  Epoch: 419  Training loss = 3.5497  Validation loss = 4.6772  \n",
      "\n",
      "Fold: 16  Epoch: 420  Training loss = 3.5492  Validation loss = 4.6759  \n",
      "\n",
      "Fold: 16  Epoch: 421  Training loss = 3.5487  Validation loss = 4.6746  \n",
      "\n",
      "Fold: 16  Epoch: 422  Training loss = 3.5481  Validation loss = 4.6733  \n",
      "\n",
      "Fold: 16  Epoch: 423  Training loss = 3.5477  Validation loss = 4.6723  \n",
      "\n",
      "Fold: 16  Epoch: 424  Training loss = 3.5471  Validation loss = 4.6710  \n",
      "\n",
      "Fold: 16  Epoch: 425  Training loss = 3.5463  Validation loss = 4.6691  \n",
      "\n",
      "Fold: 16  Epoch: 426  Training loss = 3.5457  Validation loss = 4.6674  \n",
      "\n",
      "Fold: 16  Epoch: 427  Training loss = 3.5450  Validation loss = 4.6658  \n",
      "\n",
      "Fold: 16  Epoch: 428  Training loss = 3.5446  Validation loss = 4.6649  \n",
      "\n",
      "Fold: 16  Epoch: 429  Training loss = 3.5441  Validation loss = 4.6639  \n",
      "\n",
      "Fold: 16  Epoch: 430  Training loss = 3.5435  Validation loss = 4.6628  \n",
      "\n",
      "Fold: 16  Epoch: 431  Training loss = 3.5430  Validation loss = 4.6615  \n",
      "\n",
      "Fold: 16  Epoch: 432  Training loss = 3.5424  Validation loss = 4.6601  \n",
      "\n",
      "Fold: 16  Epoch: 433  Training loss = 3.5416  Validation loss = 4.6584  \n",
      "\n",
      "Fold: 16  Epoch: 434  Training loss = 3.5412  Validation loss = 4.6574  \n",
      "\n",
      "Fold: 16  Epoch: 435  Training loss = 3.5407  Validation loss = 4.6563  \n",
      "\n",
      "Fold: 16  Epoch: 436  Training loss = 3.5401  Validation loss = 4.6551  \n",
      "\n",
      "Fold: 16  Epoch: 437  Training loss = 3.5395  Validation loss = 4.6532  \n",
      "\n",
      "Fold: 16  Epoch: 438  Training loss = 3.5390  Validation loss = 4.6521  \n",
      "\n",
      "Fold: 16  Epoch: 439  Training loss = 3.5385  Validation loss = 4.6511  \n",
      "\n",
      "Fold: 16  Epoch: 440  Training loss = 3.5380  Validation loss = 4.6499  \n",
      "\n",
      "Fold: 16  Epoch: 441  Training loss = 3.5372  Validation loss = 4.6486  \n",
      "\n",
      "Fold: 16  Epoch: 442  Training loss = 3.5368  Validation loss = 4.6478  \n",
      "\n",
      "Fold: 16  Epoch: 443  Training loss = 3.5362  Validation loss = 4.6466  \n",
      "\n",
      "Fold: 16  Epoch: 444  Training loss = 3.5358  Validation loss = 4.6458  \n",
      "\n",
      "Fold: 16  Epoch: 445  Training loss = 3.5353  Validation loss = 4.6443  \n",
      "\n",
      "Fold: 16  Epoch: 446  Training loss = 3.5347  Validation loss = 4.6424  \n",
      "\n",
      "Fold: 16  Epoch: 447  Training loss = 3.5343  Validation loss = 4.6417  \n",
      "\n",
      "Fold: 16  Epoch: 448  Training loss = 3.5340  Validation loss = 4.6410  \n",
      "\n",
      "Fold: 16  Epoch: 449  Training loss = 3.5335  Validation loss = 4.6395  \n",
      "\n",
      "Fold: 16  Epoch: 450  Training loss = 3.5328  Validation loss = 4.6377  \n",
      "\n",
      "Fold: 16  Epoch: 451  Training loss = 3.5322  Validation loss = 4.6363  \n",
      "\n",
      "Fold: 16  Epoch: 452  Training loss = 3.5317  Validation loss = 4.6353  \n",
      "\n",
      "Fold: 16  Epoch: 453  Training loss = 3.5312  Validation loss = 4.6342  \n",
      "\n",
      "Fold: 16  Epoch: 454  Training loss = 3.5308  Validation loss = 4.6332  \n",
      "\n",
      "Fold: 16  Epoch: 455  Training loss = 3.5302  Validation loss = 4.6316  \n",
      "\n",
      "Fold: 16  Epoch: 456  Training loss = 3.5299  Validation loss = 4.6308  \n",
      "\n",
      "Fold: 16  Epoch: 457  Training loss = 3.5294  Validation loss = 4.6297  \n",
      "\n",
      "Fold: 16  Epoch: 458  Training loss = 3.5288  Validation loss = 4.6284  \n",
      "\n",
      "Fold: 16  Epoch: 459  Training loss = 3.5284  Validation loss = 4.6274  \n",
      "\n",
      "Fold: 16  Epoch: 460  Training loss = 3.5279  Validation loss = 4.6265  \n",
      "\n",
      "Fold: 16  Epoch: 461  Training loss = 3.5275  Validation loss = 4.6253  \n",
      "\n",
      "Fold: 16  Epoch: 462  Training loss = 3.5270  Validation loss = 4.6242  \n",
      "\n",
      "Fold: 16  Epoch: 463  Training loss = 3.5265  Validation loss = 4.6229  \n",
      "\n",
      "Fold: 16  Epoch: 464  Training loss = 3.5259  Validation loss = 4.6211  \n",
      "\n",
      "Fold: 16  Epoch: 465  Training loss = 3.5254  Validation loss = 4.6199  \n",
      "\n",
      "Fold: 16  Epoch: 466  Training loss = 3.5248  Validation loss = 4.6182  \n",
      "\n",
      "Fold: 16  Epoch: 467  Training loss = 3.5243  Validation loss = 4.6172  \n",
      "\n",
      "Fold: 16  Epoch: 468  Training loss = 3.5238  Validation loss = 4.6160  \n",
      "\n",
      "Fold: 16  Epoch: 469  Training loss = 3.5233  Validation loss = 4.6148  \n",
      "\n",
      "Fold: 16  Epoch: 470  Training loss = 3.5228  Validation loss = 4.6135  \n",
      "\n",
      "Fold: 16  Epoch: 471  Training loss = 3.5222  Validation loss = 4.6121  \n",
      "\n",
      "Fold: 16  Epoch: 472  Training loss = 3.5217  Validation loss = 4.6110  \n",
      "\n",
      "Fold: 16  Epoch: 473  Training loss = 3.5213  Validation loss = 4.6099  \n",
      "\n",
      "Fold: 16  Epoch: 474  Training loss = 3.5206  Validation loss = 4.6084  \n",
      "\n",
      "Fold: 16  Epoch: 475  Training loss = 3.5200  Validation loss = 4.6071  \n",
      "\n",
      "Fold: 16  Epoch: 476  Training loss = 3.5197  Validation loss = 4.6062  \n",
      "\n",
      "Fold: 16  Epoch: 477  Training loss = 3.5194  Validation loss = 4.6052  \n",
      "\n",
      "Fold: 16  Epoch: 478  Training loss = 3.5191  Validation loss = 4.6046  \n",
      "\n",
      "Fold: 16  Epoch: 479  Training loss = 3.5186  Validation loss = 4.6030  \n",
      "\n",
      "Fold: 16  Epoch: 480  Training loss = 3.5182  Validation loss = 4.6023  \n",
      "\n",
      "Fold: 16  Epoch: 481  Training loss = 3.5176  Validation loss = 4.6008  \n",
      "\n",
      "Fold: 16  Epoch: 482  Training loss = 3.5170  Validation loss = 4.5996  \n",
      "\n",
      "Fold: 16  Epoch: 483  Training loss = 3.5166  Validation loss = 4.5986  \n",
      "\n",
      "Fold: 16  Epoch: 484  Training loss = 3.5160  Validation loss = 4.5969  \n",
      "\n",
      "Fold: 16  Epoch: 485  Training loss = 3.5155  Validation loss = 4.5955  \n",
      "\n",
      "Fold: 16  Epoch: 486  Training loss = 3.5150  Validation loss = 4.5943  \n",
      "\n",
      "Fold: 16  Epoch: 487  Training loss = 3.5146  Validation loss = 4.5932  \n",
      "\n",
      "Fold: 16  Epoch: 488  Training loss = 3.5140  Validation loss = 4.5919  \n",
      "\n",
      "Fold: 16  Epoch: 489  Training loss = 3.5135  Validation loss = 4.5903  \n",
      "\n",
      "Fold: 16  Epoch: 490  Training loss = 3.5129  Validation loss = 4.5886  \n",
      "\n",
      "Fold: 16  Epoch: 491  Training loss = 3.5123  Validation loss = 4.5871  \n",
      "\n",
      "Fold: 16  Epoch: 492  Training loss = 3.5118  Validation loss = 4.5858  \n",
      "\n",
      "Fold: 16  Epoch: 493  Training loss = 3.5115  Validation loss = 4.5850  \n",
      "\n",
      "Fold: 16  Epoch: 494  Training loss = 3.5110  Validation loss = 4.5842  \n",
      "\n",
      "Fold: 16  Epoch: 495  Training loss = 3.5103  Validation loss = 4.5822  \n",
      "\n",
      "Fold: 16  Epoch: 496  Training loss = 3.5096  Validation loss = 4.5806  \n",
      "\n",
      "Fold: 16  Epoch: 497  Training loss = 3.5086  Validation loss = 4.5778  \n",
      "\n",
      "Fold: 16  Epoch: 498  Training loss = 3.5078  Validation loss = 4.5763  \n",
      "\n",
      "Fold: 16  Epoch: 499  Training loss = 3.5069  Validation loss = 4.5743  \n",
      "\n",
      "Fold: 16  Epoch: 500  Training loss = 3.5063  Validation loss = 4.5728  \n",
      "\n",
      "Check model:  Fold: 16  Optimal epoch: 500  \n",
      "\n",
      "Fold: 17  Epoch: 1  Training loss = 3.6388  Validation loss = 3.1714  \n",
      "\n",
      "Fold: 17  Epoch: 2  Training loss = 3.6378  Validation loss = 3.1722  \n",
      "\n",
      "Fold: 17  Epoch: 3  Training loss = 3.6367  Validation loss = 3.1732  \n",
      "\n",
      "Fold: 17  Epoch: 4  Training loss = 3.6359  Validation loss = 3.1739  \n",
      "\n",
      "Fold: 17  Epoch: 5  Training loss = 3.6349  Validation loss = 3.1748  \n",
      "\n",
      "Fold: 17  Epoch: 6  Training loss = 3.6342  Validation loss = 3.1754  \n",
      "\n",
      "Fold: 17  Epoch: 7  Training loss = 3.6334  Validation loss = 3.1762  \n",
      "\n",
      "Fold: 17  Epoch: 8  Training loss = 3.6328  Validation loss = 3.1768  \n",
      "\n",
      "Fold: 17  Epoch: 9  Training loss = 3.6322  Validation loss = 3.1772  \n",
      "\n",
      "Fold: 17  Epoch: 10  Training loss = 3.6316  Validation loss = 3.1777  \n",
      "\n",
      "Fold: 17  Epoch: 11  Training loss = 3.6308  Validation loss = 3.1785  \n",
      "\n",
      "Fold: 17  Epoch: 12  Training loss = 3.6302  Validation loss = 3.1791  \n",
      "\n",
      "Fold: 17  Epoch: 13  Training loss = 3.6294  Validation loss = 3.1798  \n",
      "\n",
      "Fold: 17  Epoch: 14  Training loss = 3.6288  Validation loss = 3.1803  \n",
      "\n",
      "Fold: 17  Epoch: 15  Training loss = 3.6280  Validation loss = 3.1811  \n",
      "\n",
      "Fold: 17  Epoch: 16  Training loss = 3.6274  Validation loss = 3.1816  \n",
      "\n",
      "Check model:  Fold: 17  Optimal epoch: 1  \n",
      "\n",
      "Fold: 18  Epoch: 1  Training loss = 3.7086  Validation loss = 2.0635  \n",
      "\n",
      "Fold: 18  Epoch: 2  Training loss = 3.7081  Validation loss = 2.0637  \n",
      "\n",
      "Fold: 18  Epoch: 3  Training loss = 3.7077  Validation loss = 2.0638  \n",
      "\n",
      "Fold: 18  Epoch: 4  Training loss = 3.7069  Validation loss = 2.0640  \n",
      "\n",
      "Fold: 18  Epoch: 5  Training loss = 3.7062  Validation loss = 2.0642  \n",
      "\n",
      "Fold: 18  Epoch: 6  Training loss = 3.7055  Validation loss = 2.0645  \n",
      "\n",
      "Fold: 18  Epoch: 7  Training loss = 3.7050  Validation loss = 2.0647  \n",
      "\n",
      "Fold: 18  Epoch: 8  Training loss = 3.7044  Validation loss = 2.0649  \n",
      "\n",
      "Fold: 18  Epoch: 9  Training loss = 3.7039  Validation loss = 2.0651  \n",
      "\n",
      "Fold: 18  Epoch: 10  Training loss = 3.7034  Validation loss = 2.0653  \n",
      "\n",
      "Fold: 18  Epoch: 11  Training loss = 3.7028  Validation loss = 2.0655  \n",
      "\n",
      "Fold: 18  Epoch: 12  Training loss = 3.7024  Validation loss = 2.0656  \n",
      "\n",
      "Fold: 18  Epoch: 13  Training loss = 3.7015  Validation loss = 2.0660  \n",
      "\n",
      "Fold: 18  Epoch: 14  Training loss = 3.7009  Validation loss = 2.0662  \n",
      "\n",
      "Fold: 18  Epoch: 15  Training loss = 3.7003  Validation loss = 2.0664  \n",
      "\n",
      "Fold: 18  Epoch: 16  Training loss = 3.6996  Validation loss = 2.0667  \n",
      "\n",
      "Check model:  Fold: 18  Optimal epoch: 1  \n",
      "\n",
      "Fold: 19  Epoch: 1  Training loss = 3.7038  Validation loss = 0.6571  \n",
      "\n",
      "Fold: 19  Epoch: 2  Training loss = 3.7026  Validation loss = 0.6573  \n",
      "\n",
      "Fold: 19  Epoch: 3  Training loss = 3.7018  Validation loss = 0.6574  \n",
      "\n",
      "Fold: 19  Epoch: 4  Training loss = 3.7012  Validation loss = 0.6576  \n",
      "\n",
      "Fold: 19  Epoch: 5  Training loss = 3.7007  Validation loss = 0.6576  \n",
      "\n",
      "Fold: 19  Epoch: 6  Training loss = 3.6997  Validation loss = 0.6577  \n",
      "\n",
      "Fold: 19  Epoch: 7  Training loss = 3.6992  Validation loss = 0.6578  \n",
      "\n",
      "Fold: 19  Epoch: 8  Training loss = 3.6985  Validation loss = 0.6579  \n",
      "\n",
      "Fold: 19  Epoch: 9  Training loss = 3.6978  Validation loss = 0.6580  \n",
      "\n",
      "Fold: 19  Epoch: 10  Training loss = 3.6972  Validation loss = 0.6581  \n",
      "\n",
      "Fold: 19  Epoch: 11  Training loss = 3.6967  Validation loss = 0.6582  \n",
      "\n",
      "Fold: 19  Epoch: 12  Training loss = 3.6963  Validation loss = 0.6582  \n",
      "\n",
      "Fold: 19  Epoch: 13  Training loss = 3.6956  Validation loss = 0.6583  \n",
      "\n",
      "Fold: 19  Epoch: 14  Training loss = 3.6950  Validation loss = 0.6585  \n",
      "\n",
      "Fold: 19  Epoch: 15  Training loss = 3.6944  Validation loss = 0.6586  \n",
      "\n",
      "Fold: 19  Epoch: 16  Training loss = 3.6938  Validation loss = 0.6587  \n",
      "\n",
      "Check model:  Fold: 19  Optimal epoch: 1  \n",
      "\n",
      "Fold: 20  Epoch: 1  Training loss = 3.6937  Validation loss = 1.6331  \n",
      "\n",
      "Fold: 20  Epoch: 2  Training loss = 3.6930  Validation loss = 1.6342  \n",
      "\n",
      "Fold: 20  Epoch: 3  Training loss = 3.6923  Validation loss = 1.6355  \n",
      "\n",
      "Fold: 20  Epoch: 4  Training loss = 3.6919  Validation loss = 1.6362  \n",
      "\n",
      "Fold: 20  Epoch: 5  Training loss = 3.6914  Validation loss = 1.6371  \n",
      "\n",
      "Fold: 20  Epoch: 6  Training loss = 3.6910  Validation loss = 1.6379  \n",
      "\n",
      "Fold: 20  Epoch: 7  Training loss = 3.6903  Validation loss = 1.6390  \n",
      "\n",
      "Fold: 20  Epoch: 8  Training loss = 3.6896  Validation loss = 1.6403  \n",
      "\n",
      "Fold: 20  Epoch: 9  Training loss = 3.6889  Validation loss = 1.6415  \n",
      "\n",
      "Fold: 20  Epoch: 10  Training loss = 3.6879  Validation loss = 1.6434  \n",
      "\n",
      "Fold: 20  Epoch: 11  Training loss = 3.6871  Validation loss = 1.6448  \n",
      "\n",
      "Fold: 20  Epoch: 12  Training loss = 3.6866  Validation loss = 1.6456  \n",
      "\n",
      "Fold: 20  Epoch: 13  Training loss = 3.6858  Validation loss = 1.6472  \n",
      "\n",
      "Fold: 20  Epoch: 14  Training loss = 3.6852  Validation loss = 1.6483  \n",
      "\n",
      "Fold: 20  Epoch: 15  Training loss = 3.6847  Validation loss = 1.6492  \n",
      "\n",
      "Fold: 20  Epoch: 16  Training loss = 3.6840  Validation loss = 1.6503  \n",
      "\n",
      "Check model:  Fold: 20  Optimal epoch: 1  \n",
      "\n",
      "Fold: 21  Epoch: 1  Training loss = 3.7008  Validation loss = 2.7282  \n",
      "\n",
      "Fold: 21  Epoch: 2  Training loss = 3.7005  Validation loss = 2.7286  \n",
      "\n",
      "Fold: 21  Epoch: 3  Training loss = 3.7002  Validation loss = 2.7291  \n",
      "\n",
      "Fold: 21  Epoch: 4  Training loss = 3.6995  Validation loss = 2.7297  \n",
      "\n",
      "Fold: 21  Epoch: 5  Training loss = 3.6991  Validation loss = 2.7302  \n",
      "\n",
      "Fold: 21  Epoch: 6  Training loss = 3.6987  Validation loss = 2.7304  \n",
      "\n",
      "Fold: 21  Epoch: 7  Training loss = 3.6982  Validation loss = 2.7307  \n",
      "\n",
      "Fold: 21  Epoch: 8  Training loss = 3.6976  Validation loss = 2.7315  \n",
      "\n",
      "Fold: 21  Epoch: 9  Training loss = 3.6970  Validation loss = 2.7322  \n",
      "\n",
      "Fold: 21  Epoch: 10  Training loss = 3.6966  Validation loss = 2.7326  \n",
      "\n",
      "Fold: 21  Epoch: 11  Training loss = 3.6960  Validation loss = 2.7331  \n",
      "\n",
      "Fold: 21  Epoch: 12  Training loss = 3.6953  Validation loss = 2.7337  \n",
      "\n",
      "Fold: 21  Epoch: 13  Training loss = 3.6949  Validation loss = 2.7341  \n",
      "\n",
      "Fold: 21  Epoch: 14  Training loss = 3.6944  Validation loss = 2.7348  \n",
      "\n",
      "Fold: 21  Epoch: 15  Training loss = 3.6938  Validation loss = 2.7353  \n",
      "\n",
      "Fold: 21  Epoch: 16  Training loss = 3.6933  Validation loss = 2.7356  \n",
      "\n",
      "Check model:  Fold: 21  Optimal epoch: 1  \n",
      "\n",
      "Fold: 22  Epoch: 1  Training loss = 3.7407  Validation loss = 1.4708  \n",
      "\n",
      "Fold: 22  Epoch: 2  Training loss = 3.7404  Validation loss = 1.4708  \n",
      "\n",
      "Fold: 22  Epoch: 3  Training loss = 3.7399  Validation loss = 1.4708  \n",
      "\n",
      "Fold: 22  Epoch: 4  Training loss = 3.7395  Validation loss = 1.4708  \n",
      "\n",
      "Fold: 22  Epoch: 5  Training loss = 3.7389  Validation loss = 1.4708  \n",
      "\n",
      "Fold: 22  Epoch: 6  Training loss = 3.7383  Validation loss = 1.4708  \n",
      "\n",
      "Fold: 22  Epoch: 7  Training loss = 3.7380  Validation loss = 1.4707  \n",
      "\n",
      "Fold: 22  Epoch: 8  Training loss = 3.7376  Validation loss = 1.4707  \n",
      "\n",
      "Fold: 22  Epoch: 9  Training loss = 3.7371  Validation loss = 1.4707  \n",
      "\n",
      "Fold: 22  Epoch: 10  Training loss = 3.7368  Validation loss = 1.4707  \n",
      "\n",
      "Fold: 22  Epoch: 11  Training loss = 3.7361  Validation loss = 1.4707  \n",
      "\n",
      "Fold: 22  Epoch: 12  Training loss = 3.7355  Validation loss = 1.4709  \n",
      "\n",
      "Fold: 22  Epoch: 13  Training loss = 3.7349  Validation loss = 1.4709  \n",
      "\n",
      "Fold: 22  Epoch: 14  Training loss = 3.7345  Validation loss = 1.4709  \n",
      "\n",
      "Fold: 22  Epoch: 15  Training loss = 3.7339  Validation loss = 1.4710  \n",
      "\n",
      "Fold: 22  Epoch: 16  Training loss = 3.7337  Validation loss = 1.4710  \n",
      "\n",
      "Fold: 22  Epoch: 17  Training loss = 3.7331  Validation loss = 1.4709  \n",
      "\n",
      "Fold: 22  Epoch: 18  Training loss = 3.7327  Validation loss = 1.4709  \n",
      "\n",
      "Fold: 22  Epoch: 19  Training loss = 3.7321  Validation loss = 1.4708  \n",
      "\n",
      "Fold: 22  Epoch: 20  Training loss = 3.7316  Validation loss = 1.4707  \n",
      "\n",
      "Fold: 22  Epoch: 21  Training loss = 3.7311  Validation loss = 1.4708  \n",
      "\n",
      "Fold: 22  Epoch: 22  Training loss = 3.7307  Validation loss = 1.4707  \n",
      "\n",
      "Fold: 22  Epoch: 23  Training loss = 3.7303  Validation loss = 1.4708  \n",
      "\n",
      "Fold: 22  Epoch: 24  Training loss = 3.7297  Validation loss = 1.4707  \n",
      "\n",
      "Fold: 22  Epoch: 25  Training loss = 3.7292  Validation loss = 1.4707  \n",
      "\n",
      "Fold: 22  Epoch: 26  Training loss = 3.7288  Validation loss = 1.4705  \n",
      "\n",
      "Fold: 22  Epoch: 27  Training loss = 3.7284  Validation loss = 1.4704  \n",
      "\n",
      "Fold: 22  Epoch: 28  Training loss = 3.7282  Validation loss = 1.4704  \n",
      "\n",
      "Fold: 22  Epoch: 29  Training loss = 3.7279  Validation loss = 1.4704  \n",
      "\n",
      "Fold: 22  Epoch: 30  Training loss = 3.7275  Validation loss = 1.4704  \n",
      "\n",
      "Fold: 22  Epoch: 31  Training loss = 3.7272  Validation loss = 1.4706  \n",
      "\n",
      "Fold: 22  Epoch: 32  Training loss = 3.7268  Validation loss = 1.4706  \n",
      "\n",
      "Fold: 22  Epoch: 33  Training loss = 3.7265  Validation loss = 1.4706  \n",
      "\n",
      "Fold: 22  Epoch: 34  Training loss = 3.7260  Validation loss = 1.4706  \n",
      "\n",
      "Fold: 22  Epoch: 35  Training loss = 3.7255  Validation loss = 1.4706  \n",
      "\n",
      "Fold: 22  Epoch: 36  Training loss = 3.7249  Validation loss = 1.4705  \n",
      "\n",
      "Fold: 22  Epoch: 37  Training loss = 3.7244  Validation loss = 1.4705  \n",
      "\n",
      "Fold: 22  Epoch: 38  Training loss = 3.7239  Validation loss = 1.4705  \n",
      "\n",
      "Fold: 22  Epoch: 39  Training loss = 3.7232  Validation loss = 1.4705  \n",
      "\n",
      "Fold: 22  Epoch: 40  Training loss = 3.7227  Validation loss = 1.4706  \n",
      "\n",
      "Fold: 22  Epoch: 41  Training loss = 3.7221  Validation loss = 1.4707  \n",
      "\n",
      "Check model:  Fold: 22  Optimal epoch: 28  \n",
      "\n",
      "Fold: 23  Epoch: 1  Training loss = 3.7191  Validation loss = 1.0725  \n",
      "\n",
      "Fold: 23  Epoch: 2  Training loss = 3.7185  Validation loss = 1.0736  \n",
      "\n",
      "Fold: 23  Epoch: 3  Training loss = 3.7179  Validation loss = 1.0750  \n",
      "\n",
      "Fold: 23  Epoch: 4  Training loss = 3.7173  Validation loss = 1.0758  \n",
      "\n",
      "Fold: 23  Epoch: 5  Training loss = 3.7166  Validation loss = 1.0771  \n",
      "\n",
      "Fold: 23  Epoch: 6  Training loss = 3.7160  Validation loss = 1.0777  \n",
      "\n",
      "Fold: 23  Epoch: 7  Training loss = 3.7154  Validation loss = 1.0790  \n",
      "\n",
      "Fold: 23  Epoch: 8  Training loss = 3.7149  Validation loss = 1.0800  \n",
      "\n",
      "Fold: 23  Epoch: 9  Training loss = 3.7145  Validation loss = 1.0807  \n",
      "\n",
      "Fold: 23  Epoch: 10  Training loss = 3.7138  Validation loss = 1.0817  \n",
      "\n",
      "Fold: 23  Epoch: 11  Training loss = 3.7134  Validation loss = 1.0825  \n",
      "\n",
      "Fold: 23  Epoch: 12  Training loss = 3.7129  Validation loss = 1.0830  \n",
      "\n",
      "Fold: 23  Epoch: 13  Training loss = 3.7125  Validation loss = 1.0834  \n",
      "\n",
      "Fold: 23  Epoch: 14  Training loss = 3.7119  Validation loss = 1.0843  \n",
      "\n",
      "Fold: 23  Epoch: 15  Training loss = 3.7115  Validation loss = 1.0850  \n",
      "\n",
      "Fold: 23  Epoch: 16  Training loss = 3.7106  Validation loss = 1.0866  \n",
      "\n",
      "Check model:  Fold: 23  Optimal epoch: 1  \n",
      "\n",
      "Fold: 24  Epoch: 1  Training loss = 3.6688  Validation loss = 1.9102  \n",
      "\n",
      "Fold: 24  Epoch: 2  Training loss = 3.6683  Validation loss = 1.9100  \n",
      "\n",
      "Fold: 24  Epoch: 3  Training loss = 3.6676  Validation loss = 1.9098  \n",
      "\n",
      "Fold: 24  Epoch: 4  Training loss = 3.6670  Validation loss = 1.9096  \n",
      "\n",
      "Fold: 24  Epoch: 5  Training loss = 3.6665  Validation loss = 1.9094  \n",
      "\n",
      "Fold: 24  Epoch: 6  Training loss = 3.6660  Validation loss = 1.9090  \n",
      "\n",
      "Fold: 24  Epoch: 7  Training loss = 3.6655  Validation loss = 1.9087  \n",
      "\n",
      "Fold: 24  Epoch: 8  Training loss = 3.6651  Validation loss = 1.9085  \n",
      "\n",
      "Fold: 24  Epoch: 9  Training loss = 3.6648  Validation loss = 1.9082  \n",
      "\n",
      "Fold: 24  Epoch: 10  Training loss = 3.6642  Validation loss = 1.9082  \n",
      "\n",
      "Fold: 24  Epoch: 11  Training loss = 3.6637  Validation loss = 1.9076  \n",
      "\n",
      "Fold: 24  Epoch: 12  Training loss = 3.6632  Validation loss = 1.9074  \n",
      "\n",
      "Fold: 24  Epoch: 13  Training loss = 3.6627  Validation loss = 1.9072  \n",
      "\n",
      "Fold: 24  Epoch: 14  Training loss = 3.6621  Validation loss = 1.9068  \n",
      "\n",
      "Fold: 24  Epoch: 15  Training loss = 3.6617  Validation loss = 1.9066  \n",
      "\n",
      "Fold: 24  Epoch: 16  Training loss = 3.6612  Validation loss = 1.9063  \n",
      "\n",
      "Fold: 24  Epoch: 17  Training loss = 3.6605  Validation loss = 1.9059  \n",
      "\n",
      "Fold: 24  Epoch: 18  Training loss = 3.6599  Validation loss = 1.9055  \n",
      "\n",
      "Fold: 24  Epoch: 19  Training loss = 3.6595  Validation loss = 1.9052  \n",
      "\n",
      "Fold: 24  Epoch: 20  Training loss = 3.6588  Validation loss = 1.9050  \n",
      "\n",
      "Fold: 24  Epoch: 21  Training loss = 3.6584  Validation loss = 1.9048  \n",
      "\n",
      "Fold: 24  Epoch: 22  Training loss = 3.6579  Validation loss = 1.9044  \n",
      "\n",
      "Fold: 24  Epoch: 23  Training loss = 3.6574  Validation loss = 1.9041  \n",
      "\n",
      "Fold: 24  Epoch: 24  Training loss = 3.6569  Validation loss = 1.9040  \n",
      "\n",
      "Fold: 24  Epoch: 25  Training loss = 3.6563  Validation loss = 1.9038  \n",
      "\n",
      "Fold: 24  Epoch: 26  Training loss = 3.6559  Validation loss = 1.9036  \n",
      "\n",
      "Fold: 24  Epoch: 27  Training loss = 3.6555  Validation loss = 1.9034  \n",
      "\n",
      "Fold: 24  Epoch: 28  Training loss = 3.6549  Validation loss = 1.9030  \n",
      "\n",
      "Fold: 24  Epoch: 29  Training loss = 3.6544  Validation loss = 1.9028  \n",
      "\n",
      "Fold: 24  Epoch: 30  Training loss = 3.6538  Validation loss = 1.9024  \n",
      "\n",
      "Fold: 24  Epoch: 31  Training loss = 3.6532  Validation loss = 1.9023  \n",
      "\n",
      "Fold: 24  Epoch: 32  Training loss = 3.6527  Validation loss = 1.9020  \n",
      "\n",
      "Fold: 24  Epoch: 33  Training loss = 3.6523  Validation loss = 1.9017  \n",
      "\n",
      "Fold: 24  Epoch: 34  Training loss = 3.6519  Validation loss = 1.9014  \n",
      "\n",
      "Fold: 24  Epoch: 35  Training loss = 3.6514  Validation loss = 1.9010  \n",
      "\n",
      "Fold: 24  Epoch: 36  Training loss = 3.6507  Validation loss = 1.9005  \n",
      "\n",
      "Fold: 24  Epoch: 37  Training loss = 3.6503  Validation loss = 1.9004  \n",
      "\n",
      "Fold: 24  Epoch: 38  Training loss = 3.6500  Validation loss = 1.9000  \n",
      "\n",
      "Fold: 24  Epoch: 39  Training loss = 3.6495  Validation loss = 1.8997  \n",
      "\n",
      "Fold: 24  Epoch: 40  Training loss = 3.6490  Validation loss = 1.8995  \n",
      "\n",
      "Fold: 24  Epoch: 41  Training loss = 3.6484  Validation loss = 1.8991  \n",
      "\n",
      "Fold: 24  Epoch: 42  Training loss = 3.6478  Validation loss = 1.8986  \n",
      "\n",
      "Fold: 24  Epoch: 43  Training loss = 3.6472  Validation loss = 1.8984  \n",
      "\n",
      "Fold: 24  Epoch: 44  Training loss = 3.6464  Validation loss = 1.8980  \n",
      "\n",
      "Fold: 24  Epoch: 45  Training loss = 3.6461  Validation loss = 1.8978  \n",
      "\n",
      "Fold: 24  Epoch: 46  Training loss = 3.6457  Validation loss = 1.8978  \n",
      "\n",
      "Fold: 24  Epoch: 47  Training loss = 3.6452  Validation loss = 1.8976  \n",
      "\n",
      "Fold: 24  Epoch: 48  Training loss = 3.6446  Validation loss = 1.8972  \n",
      "\n",
      "Fold: 24  Epoch: 49  Training loss = 3.6441  Validation loss = 1.8968  \n",
      "\n",
      "Fold: 24  Epoch: 50  Training loss = 3.6435  Validation loss = 1.8964  \n",
      "\n",
      "Fold: 24  Epoch: 51  Training loss = 3.6431  Validation loss = 1.8962  \n",
      "\n",
      "Fold: 24  Epoch: 52  Training loss = 3.6427  Validation loss = 1.8961  \n",
      "\n",
      "Fold: 24  Epoch: 53  Training loss = 3.6420  Validation loss = 1.8959  \n",
      "\n",
      "Fold: 24  Epoch: 54  Training loss = 3.6414  Validation loss = 1.8956  \n",
      "\n",
      "Fold: 24  Epoch: 55  Training loss = 3.6409  Validation loss = 1.8953  \n",
      "\n",
      "Fold: 24  Epoch: 56  Training loss = 3.6404  Validation loss = 1.8947  \n",
      "\n",
      "Fold: 24  Epoch: 57  Training loss = 3.6399  Validation loss = 1.8944  \n",
      "\n",
      "Fold: 24  Epoch: 58  Training loss = 3.6394  Validation loss = 1.8941  \n",
      "\n",
      "Fold: 24  Epoch: 59  Training loss = 3.6391  Validation loss = 1.8941  \n",
      "\n",
      "Fold: 24  Epoch: 60  Training loss = 3.6386  Validation loss = 1.8937  \n",
      "\n",
      "Fold: 24  Epoch: 61  Training loss = 3.6382  Validation loss = 1.8936  \n",
      "\n",
      "Fold: 24  Epoch: 62  Training loss = 3.6378  Validation loss = 1.8935  \n",
      "\n",
      "Fold: 24  Epoch: 63  Training loss = 3.6372  Validation loss = 1.8931  \n",
      "\n",
      "Fold: 24  Epoch: 64  Training loss = 3.6366  Validation loss = 1.8924  \n",
      "\n",
      "Fold: 24  Epoch: 65  Training loss = 3.6360  Validation loss = 1.8924  \n",
      "\n",
      "Fold: 24  Epoch: 66  Training loss = 3.6356  Validation loss = 1.8926  \n",
      "\n",
      "Fold: 24  Epoch: 67  Training loss = 3.6351  Validation loss = 1.8925  \n",
      "\n",
      "Fold: 24  Epoch: 68  Training loss = 3.6346  Validation loss = 1.8921  \n",
      "\n",
      "Fold: 24  Epoch: 69  Training loss = 3.6340  Validation loss = 1.8919  \n",
      "\n",
      "Fold: 24  Epoch: 70  Training loss = 3.6332  Validation loss = 1.8918  \n",
      "\n",
      "Fold: 24  Epoch: 71  Training loss = 3.6326  Validation loss = 1.8915  \n",
      "\n",
      "Fold: 24  Epoch: 72  Training loss = 3.6323  Validation loss = 1.8915  \n",
      "\n",
      "Fold: 24  Epoch: 73  Training loss = 3.6315  Validation loss = 1.8913  \n",
      "\n",
      "Fold: 24  Epoch: 74  Training loss = 3.6309  Validation loss = 1.8911  \n",
      "\n",
      "Fold: 24  Epoch: 75  Training loss = 3.6303  Validation loss = 1.8913  \n",
      "\n",
      "Fold: 24  Epoch: 76  Training loss = 3.6295  Validation loss = 1.8911  \n",
      "\n",
      "Fold: 24  Epoch: 77  Training loss = 3.6288  Validation loss = 1.8909  \n",
      "\n",
      "Fold: 24  Epoch: 78  Training loss = 3.6283  Validation loss = 1.8909  \n",
      "\n",
      "Fold: 24  Epoch: 79  Training loss = 3.6277  Validation loss = 1.8906  \n",
      "\n",
      "Fold: 24  Epoch: 80  Training loss = 3.6271  Validation loss = 1.8904  \n",
      "\n",
      "Fold: 24  Epoch: 81  Training loss = 3.6266  Validation loss = 1.8901  \n",
      "\n",
      "Fold: 24  Epoch: 82  Training loss = 3.6261  Validation loss = 1.8901  \n",
      "\n",
      "Fold: 24  Epoch: 83  Training loss = 3.6254  Validation loss = 1.8898  \n",
      "\n",
      "Fold: 24  Epoch: 84  Training loss = 3.6251  Validation loss = 1.8897  \n",
      "\n",
      "Fold: 24  Epoch: 85  Training loss = 3.6247  Validation loss = 1.8896  \n",
      "\n",
      "Fold: 24  Epoch: 86  Training loss = 3.6241  Validation loss = 1.8892  \n",
      "\n",
      "Fold: 24  Epoch: 87  Training loss = 3.6234  Validation loss = 1.8890  \n",
      "\n",
      "Fold: 24  Epoch: 88  Training loss = 3.6230  Validation loss = 1.8889  \n",
      "\n",
      "Fold: 24  Epoch: 89  Training loss = 3.6224  Validation loss = 1.8884  \n",
      "\n",
      "Fold: 24  Epoch: 90  Training loss = 3.6218  Validation loss = 1.8881  \n",
      "\n",
      "Fold: 24  Epoch: 91  Training loss = 3.6211  Validation loss = 1.8876  \n",
      "\n",
      "Fold: 24  Epoch: 92  Training loss = 3.6204  Validation loss = 1.8871  \n",
      "\n",
      "Fold: 24  Epoch: 93  Training loss = 3.6198  Validation loss = 1.8869  \n",
      "\n",
      "Fold: 24  Epoch: 94  Training loss = 3.6195  Validation loss = 1.8865  \n",
      "\n",
      "Fold: 24  Epoch: 95  Training loss = 3.6191  Validation loss = 1.8862  \n",
      "\n",
      "Fold: 24  Epoch: 96  Training loss = 3.6187  Validation loss = 1.8859  \n",
      "\n",
      "Fold: 24  Epoch: 97  Training loss = 3.6181  Validation loss = 1.8858  \n",
      "\n",
      "Fold: 24  Epoch: 98  Training loss = 3.6175  Validation loss = 1.8856  \n",
      "\n",
      "Fold: 24  Epoch: 99  Training loss = 3.6170  Validation loss = 1.8853  \n",
      "\n",
      "Fold: 24  Epoch: 100  Training loss = 3.6166  Validation loss = 1.8848  \n",
      "\n",
      "Fold: 24  Epoch: 101  Training loss = 3.6164  Validation loss = 1.8849  \n",
      "\n",
      "Fold: 24  Epoch: 102  Training loss = 3.6160  Validation loss = 1.8847  \n",
      "\n",
      "Fold: 24  Epoch: 103  Training loss = 3.6155  Validation loss = 1.8846  \n",
      "\n",
      "Fold: 24  Epoch: 104  Training loss = 3.6151  Validation loss = 1.8844  \n",
      "\n",
      "Fold: 24  Epoch: 105  Training loss = 3.6147  Validation loss = 1.8841  \n",
      "\n",
      "Fold: 24  Epoch: 106  Training loss = 3.6142  Validation loss = 1.8839  \n",
      "\n",
      "Fold: 24  Epoch: 107  Training loss = 3.6137  Validation loss = 1.8835  \n",
      "\n",
      "Fold: 24  Epoch: 108  Training loss = 3.6130  Validation loss = 1.8832  \n",
      "\n",
      "Fold: 24  Epoch: 109  Training loss = 3.6121  Validation loss = 1.8830  \n",
      "\n",
      "Fold: 24  Epoch: 110  Training loss = 3.6115  Validation loss = 1.8829  \n",
      "\n",
      "Fold: 24  Epoch: 111  Training loss = 3.6112  Validation loss = 1.8828  \n",
      "\n",
      "Fold: 24  Epoch: 112  Training loss = 3.6109  Validation loss = 1.8827  \n",
      "\n",
      "Fold: 24  Epoch: 113  Training loss = 3.6106  Validation loss = 1.8827  \n",
      "\n",
      "Fold: 24  Epoch: 114  Training loss = 3.6099  Validation loss = 1.8822  \n",
      "\n",
      "Fold: 24  Epoch: 115  Training loss = 3.6093  Validation loss = 1.8819  \n",
      "\n",
      "Fold: 24  Epoch: 116  Training loss = 3.6088  Validation loss = 1.8817  \n",
      "\n",
      "Fold: 24  Epoch: 117  Training loss = 3.6083  Validation loss = 1.8814  \n",
      "\n",
      "Fold: 24  Epoch: 118  Training loss = 3.6077  Validation loss = 1.8812  \n",
      "\n",
      "Fold: 24  Epoch: 119  Training loss = 3.6072  Validation loss = 1.8809  \n",
      "\n",
      "Fold: 24  Epoch: 120  Training loss = 3.6065  Validation loss = 1.8805  \n",
      "\n",
      "Fold: 24  Epoch: 121  Training loss = 3.6060  Validation loss = 1.8804  \n",
      "\n",
      "Fold: 24  Epoch: 122  Training loss = 3.6056  Validation loss = 1.8804  \n",
      "\n",
      "Fold: 24  Epoch: 123  Training loss = 3.6047  Validation loss = 1.8801  \n",
      "\n",
      "Fold: 24  Epoch: 124  Training loss = 3.6042  Validation loss = 1.8797  \n",
      "\n",
      "Fold: 24  Epoch: 125  Training loss = 3.6038  Validation loss = 1.8795  \n",
      "\n",
      "Fold: 24  Epoch: 126  Training loss = 3.6033  Validation loss = 1.8794  \n",
      "\n",
      "Fold: 24  Epoch: 127  Training loss = 3.6027  Validation loss = 1.8793  \n",
      "\n",
      "Fold: 24  Epoch: 128  Training loss = 3.6022  Validation loss = 1.8792  \n",
      "\n",
      "Fold: 24  Epoch: 129  Training loss = 3.6016  Validation loss = 1.8788  \n",
      "\n",
      "Fold: 24  Epoch: 130  Training loss = 3.6013  Validation loss = 1.8786  \n",
      "\n",
      "Fold: 24  Epoch: 131  Training loss = 3.6010  Validation loss = 1.8785  \n",
      "\n",
      "Fold: 24  Epoch: 132  Training loss = 3.6006  Validation loss = 1.8784  \n",
      "\n",
      "Fold: 24  Epoch: 133  Training loss = 3.6000  Validation loss = 1.8783  \n",
      "\n",
      "Fold: 24  Epoch: 134  Training loss = 3.5996  Validation loss = 1.8781  \n",
      "\n",
      "Fold: 24  Epoch: 135  Training loss = 3.5991  Validation loss = 1.8779  \n",
      "\n",
      "Fold: 24  Epoch: 136  Training loss = 3.5987  Validation loss = 1.8777  \n",
      "\n",
      "Fold: 24  Epoch: 137  Training loss = 3.5984  Validation loss = 1.8775  \n",
      "\n",
      "Fold: 24  Epoch: 138  Training loss = 3.5978  Validation loss = 1.8772  \n",
      "\n",
      "Fold: 24  Epoch: 139  Training loss = 3.5973  Validation loss = 1.8771  \n",
      "\n",
      "Fold: 24  Epoch: 140  Training loss = 3.5969  Validation loss = 1.8770  \n",
      "\n",
      "Fold: 24  Epoch: 141  Training loss = 3.5966  Validation loss = 1.8769  \n",
      "\n",
      "Fold: 24  Epoch: 142  Training loss = 3.5960  Validation loss = 1.8767  \n",
      "\n",
      "Fold: 24  Epoch: 143  Training loss = 3.5954  Validation loss = 1.8761  \n",
      "\n",
      "Fold: 24  Epoch: 144  Training loss = 3.5950  Validation loss = 1.8760  \n",
      "\n",
      "Fold: 24  Epoch: 145  Training loss = 3.5947  Validation loss = 1.8760  \n",
      "\n",
      "Fold: 24  Epoch: 146  Training loss = 3.5944  Validation loss = 1.8760  \n",
      "\n",
      "Fold: 24  Epoch: 147  Training loss = 3.5939  Validation loss = 1.8758  \n",
      "\n",
      "Fold: 24  Epoch: 148  Training loss = 3.5936  Validation loss = 1.8757  \n",
      "\n",
      "Fold: 24  Epoch: 149  Training loss = 3.5932  Validation loss = 1.8754  \n",
      "\n",
      "Fold: 24  Epoch: 150  Training loss = 3.5926  Validation loss = 1.8753  \n",
      "\n",
      "Fold: 24  Epoch: 151  Training loss = 3.5924  Validation loss = 1.8755  \n",
      "\n",
      "Fold: 24  Epoch: 152  Training loss = 3.5919  Validation loss = 1.8751  \n",
      "\n",
      "Fold: 24  Epoch: 153  Training loss = 3.5916  Validation loss = 1.8750  \n",
      "\n",
      "Fold: 24  Epoch: 154  Training loss = 3.5911  Validation loss = 1.8750  \n",
      "\n",
      "Fold: 24  Epoch: 155  Training loss = 3.5905  Validation loss = 1.8746  \n",
      "\n",
      "Fold: 24  Epoch: 156  Training loss = 3.5901  Validation loss = 1.8744  \n",
      "\n",
      "Fold: 24  Epoch: 157  Training loss = 3.5898  Validation loss = 1.8742  \n",
      "\n",
      "Fold: 24  Epoch: 158  Training loss = 3.5892  Validation loss = 1.8738  \n",
      "\n",
      "Fold: 24  Epoch: 159  Training loss = 3.5884  Validation loss = 1.8737  \n",
      "\n",
      "Fold: 24  Epoch: 160  Training loss = 3.5881  Validation loss = 1.8733  \n",
      "\n",
      "Fold: 24  Epoch: 161  Training loss = 3.5877  Validation loss = 1.8732  \n",
      "\n",
      "Fold: 24  Epoch: 162  Training loss = 3.5873  Validation loss = 1.8729  \n",
      "\n",
      "Fold: 24  Epoch: 163  Training loss = 3.5869  Validation loss = 1.8727  \n",
      "\n",
      "Fold: 24  Epoch: 164  Training loss = 3.5862  Validation loss = 1.8723  \n",
      "\n",
      "Fold: 24  Epoch: 165  Training loss = 3.5857  Validation loss = 1.8722  \n",
      "\n",
      "Fold: 24  Epoch: 166  Training loss = 3.5854  Validation loss = 1.8721  \n",
      "\n",
      "Fold: 24  Epoch: 167  Training loss = 3.5849  Validation loss = 1.8720  \n",
      "\n",
      "Fold: 24  Epoch: 168  Training loss = 3.5845  Validation loss = 1.8718  \n",
      "\n",
      "Fold: 24  Epoch: 169  Training loss = 3.5840  Validation loss = 1.8715  \n",
      "\n",
      "Fold: 24  Epoch: 170  Training loss = 3.5836  Validation loss = 1.8713  \n",
      "\n",
      "Fold: 24  Epoch: 171  Training loss = 3.5830  Validation loss = 1.8709  \n",
      "\n",
      "Fold: 24  Epoch: 172  Training loss = 3.5827  Validation loss = 1.8706  \n",
      "\n",
      "Fold: 24  Epoch: 173  Training loss = 3.5821  Validation loss = 1.8703  \n",
      "\n",
      "Fold: 24  Epoch: 174  Training loss = 3.5817  Validation loss = 1.8702  \n",
      "\n",
      "Fold: 24  Epoch: 175  Training loss = 3.5813  Validation loss = 1.8701  \n",
      "\n",
      "Fold: 24  Epoch: 176  Training loss = 3.5809  Validation loss = 1.8702  \n",
      "\n",
      "Fold: 24  Epoch: 177  Training loss = 3.5803  Validation loss = 1.8699  \n",
      "\n",
      "Fold: 24  Epoch: 178  Training loss = 3.5800  Validation loss = 1.8699  \n",
      "\n",
      "Fold: 24  Epoch: 179  Training loss = 3.5795  Validation loss = 1.8697  \n",
      "\n",
      "Fold: 24  Epoch: 180  Training loss = 3.5791  Validation loss = 1.8695  \n",
      "\n",
      "Fold: 24  Epoch: 181  Training loss = 3.5786  Validation loss = 1.8693  \n",
      "\n",
      "Fold: 24  Epoch: 182  Training loss = 3.5782  Validation loss = 1.8692  \n",
      "\n",
      "Fold: 24  Epoch: 183  Training loss = 3.5777  Validation loss = 1.8691  \n",
      "\n",
      "Fold: 24  Epoch: 184  Training loss = 3.5772  Validation loss = 1.8690  \n",
      "\n",
      "Fold: 24  Epoch: 185  Training loss = 3.5766  Validation loss = 1.8690  \n",
      "\n",
      "Fold: 24  Epoch: 186  Training loss = 3.5762  Validation loss = 1.8689  \n",
      "\n",
      "Fold: 24  Epoch: 187  Training loss = 3.5752  Validation loss = 1.8686  \n",
      "\n",
      "Fold: 24  Epoch: 188  Training loss = 3.5745  Validation loss = 1.8682  \n",
      "\n",
      "Fold: 24  Epoch: 189  Training loss = 3.5742  Validation loss = 1.8682  \n",
      "\n",
      "Fold: 24  Epoch: 190  Training loss = 3.5739  Validation loss = 1.8682  \n",
      "\n",
      "Fold: 24  Epoch: 191  Training loss = 3.5734  Validation loss = 1.8681  \n",
      "\n",
      "Fold: 24  Epoch: 192  Training loss = 3.5729  Validation loss = 1.8680  \n",
      "\n",
      "Fold: 24  Epoch: 193  Training loss = 3.5724  Validation loss = 1.8679  \n",
      "\n",
      "Fold: 24  Epoch: 194  Training loss = 3.5719  Validation loss = 1.8678  \n",
      "\n",
      "Fold: 24  Epoch: 195  Training loss = 3.5715  Validation loss = 1.8675  \n",
      "\n",
      "Fold: 24  Epoch: 196  Training loss = 3.5710  Validation loss = 1.8674  \n",
      "\n",
      "Fold: 24  Epoch: 197  Training loss = 3.5704  Validation loss = 1.8670  \n",
      "\n",
      "Fold: 24  Epoch: 198  Training loss = 3.5698  Validation loss = 1.8667  \n",
      "\n",
      "Fold: 24  Epoch: 199  Training loss = 3.5694  Validation loss = 1.8664  \n",
      "\n",
      "Fold: 24  Epoch: 200  Training loss = 3.5688  Validation loss = 1.8661  \n",
      "\n",
      "Fold: 24  Epoch: 201  Training loss = 3.5684  Validation loss = 1.8659  \n",
      "\n",
      "Fold: 24  Epoch: 202  Training loss = 3.5679  Validation loss = 1.8656  \n",
      "\n",
      "Fold: 24  Epoch: 203  Training loss = 3.5673  Validation loss = 1.8654  \n",
      "\n",
      "Fold: 24  Epoch: 204  Training loss = 3.5669  Validation loss = 1.8651  \n",
      "\n",
      "Fold: 24  Epoch: 205  Training loss = 3.5664  Validation loss = 1.8649  \n",
      "\n",
      "Fold: 24  Epoch: 206  Training loss = 3.5661  Validation loss = 1.8648  \n",
      "\n",
      "Fold: 24  Epoch: 207  Training loss = 3.5656  Validation loss = 1.8647  \n",
      "\n",
      "Fold: 24  Epoch: 208  Training loss = 3.5652  Validation loss = 1.8646  \n",
      "\n",
      "Fold: 24  Epoch: 209  Training loss = 3.5647  Validation loss = 1.8645  \n",
      "\n",
      "Fold: 24  Epoch: 210  Training loss = 3.5644  Validation loss = 1.8645  \n",
      "\n",
      "Fold: 24  Epoch: 211  Training loss = 3.5641  Validation loss = 1.8643  \n",
      "\n",
      "Fold: 24  Epoch: 212  Training loss = 3.5635  Validation loss = 1.8640  \n",
      "\n",
      "Fold: 24  Epoch: 213  Training loss = 3.5632  Validation loss = 1.8636  \n",
      "\n",
      "Fold: 24  Epoch: 214  Training loss = 3.5629  Validation loss = 1.8632  \n",
      "\n",
      "Fold: 24  Epoch: 215  Training loss = 3.5626  Validation loss = 1.8632  \n",
      "\n",
      "Fold: 24  Epoch: 216  Training loss = 3.5622  Validation loss = 1.8632  \n",
      "\n",
      "Fold: 24  Epoch: 217  Training loss = 3.5617  Validation loss = 1.8630  \n",
      "\n",
      "Fold: 24  Epoch: 218  Training loss = 3.5614  Validation loss = 1.8630  \n",
      "\n",
      "Fold: 24  Epoch: 219  Training loss = 3.5612  Validation loss = 1.8630  \n",
      "\n",
      "Fold: 24  Epoch: 220  Training loss = 3.5608  Validation loss = 1.8628  \n",
      "\n",
      "Fold: 24  Epoch: 221  Training loss = 3.5604  Validation loss = 1.8628  \n",
      "\n",
      "Fold: 24  Epoch: 222  Training loss = 3.5600  Validation loss = 1.8627  \n",
      "\n",
      "Fold: 24  Epoch: 223  Training loss = 3.5596  Validation loss = 1.8626  \n",
      "\n",
      "Fold: 24  Epoch: 224  Training loss = 3.5591  Validation loss = 1.8624  \n",
      "\n",
      "Fold: 24  Epoch: 225  Training loss = 3.5589  Validation loss = 1.8623  \n",
      "\n",
      "Fold: 24  Epoch: 226  Training loss = 3.5585  Validation loss = 1.8624  \n",
      "\n",
      "Fold: 24  Epoch: 227  Training loss = 3.5581  Validation loss = 1.8624  \n",
      "\n",
      "Fold: 24  Epoch: 228  Training loss = 3.5578  Validation loss = 1.8623  \n",
      "\n",
      "Fold: 24  Epoch: 229  Training loss = 3.5571  Validation loss = 1.8620  \n",
      "\n",
      "Fold: 24  Epoch: 230  Training loss = 3.5567  Validation loss = 1.8616  \n",
      "\n",
      "Fold: 24  Epoch: 231  Training loss = 3.5564  Validation loss = 1.8615  \n",
      "\n",
      "Fold: 24  Epoch: 232  Training loss = 3.5560  Validation loss = 1.8615  \n",
      "\n",
      "Fold: 24  Epoch: 233  Training loss = 3.5557  Validation loss = 1.8613  \n",
      "\n",
      "Fold: 24  Epoch: 234  Training loss = 3.5553  Validation loss = 1.8612  \n",
      "\n",
      "Fold: 24  Epoch: 235  Training loss = 3.5550  Validation loss = 1.8611  \n",
      "\n",
      "Fold: 24  Epoch: 236  Training loss = 3.5544  Validation loss = 1.8612  \n",
      "\n",
      "Fold: 24  Epoch: 237  Training loss = 3.5538  Validation loss = 1.8610  \n",
      "\n",
      "Fold: 24  Epoch: 238  Training loss = 3.5534  Validation loss = 1.8607  \n",
      "\n",
      "Fold: 24  Epoch: 239  Training loss = 3.5529  Validation loss = 1.8605  \n",
      "\n",
      "Fold: 24  Epoch: 240  Training loss = 3.5528  Validation loss = 1.8607  \n",
      "\n",
      "Fold: 24  Epoch: 241  Training loss = 3.5522  Validation loss = 1.8603  \n",
      "\n",
      "Fold: 24  Epoch: 242  Training loss = 3.5518  Validation loss = 1.8601  \n",
      "\n",
      "Fold: 24  Epoch: 243  Training loss = 3.5513  Validation loss = 1.8600  \n",
      "\n",
      "Fold: 24  Epoch: 244  Training loss = 3.5507  Validation loss = 1.8599  \n",
      "\n",
      "Fold: 24  Epoch: 245  Training loss = 3.5503  Validation loss = 1.8596  \n",
      "\n",
      "Fold: 24  Epoch: 246  Training loss = 3.5500  Validation loss = 1.8594  \n",
      "\n",
      "Fold: 24  Epoch: 247  Training loss = 3.5497  Validation loss = 1.8592  \n",
      "\n",
      "Fold: 24  Epoch: 248  Training loss = 3.5492  Validation loss = 1.8589  \n",
      "\n",
      "Fold: 24  Epoch: 249  Training loss = 3.5489  Validation loss = 1.8588  \n",
      "\n",
      "Fold: 24  Epoch: 250  Training loss = 3.5484  Validation loss = 1.8588  \n",
      "\n",
      "Fold: 24  Epoch: 251  Training loss = 3.5481  Validation loss = 1.8587  \n",
      "\n",
      "Fold: 24  Epoch: 252  Training loss = 3.5476  Validation loss = 1.8586  \n",
      "\n",
      "Fold: 24  Epoch: 253  Training loss = 3.5471  Validation loss = 1.8584  \n",
      "\n",
      "Fold: 24  Epoch: 254  Training loss = 3.5466  Validation loss = 1.8580  \n",
      "\n",
      "Fold: 24  Epoch: 255  Training loss = 3.5463  Validation loss = 1.8578  \n",
      "\n",
      "Fold: 24  Epoch: 256  Training loss = 3.5460  Validation loss = 1.8576  \n",
      "\n",
      "Fold: 24  Epoch: 257  Training loss = 3.5456  Validation loss = 1.8574  \n",
      "\n",
      "Fold: 24  Epoch: 258  Training loss = 3.5451  Validation loss = 1.8573  \n",
      "\n",
      "Fold: 24  Epoch: 259  Training loss = 3.5448  Validation loss = 1.8571  \n",
      "\n",
      "Fold: 24  Epoch: 260  Training loss = 3.5442  Validation loss = 1.8569  \n",
      "\n",
      "Fold: 24  Epoch: 261  Training loss = 3.5437  Validation loss = 1.8566  \n",
      "\n",
      "Fold: 24  Epoch: 262  Training loss = 3.5432  Validation loss = 1.8564  \n",
      "\n",
      "Fold: 24  Epoch: 263  Training loss = 3.5429  Validation loss = 1.8562  \n",
      "\n",
      "Fold: 24  Epoch: 264  Training loss = 3.5426  Validation loss = 1.8563  \n",
      "\n",
      "Fold: 24  Epoch: 265  Training loss = 3.5424  Validation loss = 1.8563  \n",
      "\n",
      "Fold: 24  Epoch: 266  Training loss = 3.5421  Validation loss = 1.8561  \n",
      "\n",
      "Fold: 24  Epoch: 267  Training loss = 3.5414  Validation loss = 1.8558  \n",
      "\n",
      "Fold: 24  Epoch: 268  Training loss = 3.5409  Validation loss = 1.8556  \n",
      "\n",
      "Fold: 24  Epoch: 269  Training loss = 3.5403  Validation loss = 1.8553  \n",
      "\n",
      "Fold: 24  Epoch: 270  Training loss = 3.5399  Validation loss = 1.8553  \n",
      "\n",
      "Fold: 24  Epoch: 271  Training loss = 3.5395  Validation loss = 1.8553  \n",
      "\n",
      "Fold: 24  Epoch: 272  Training loss = 3.5389  Validation loss = 1.8550  \n",
      "\n",
      "Fold: 24  Epoch: 273  Training loss = 3.5385  Validation loss = 1.8550  \n",
      "\n",
      "Fold: 24  Epoch: 274  Training loss = 3.5381  Validation loss = 1.8546  \n",
      "\n",
      "Fold: 24  Epoch: 275  Training loss = 3.5377  Validation loss = 1.8544  \n",
      "\n",
      "Fold: 24  Epoch: 276  Training loss = 3.5373  Validation loss = 1.8543  \n",
      "\n",
      "Fold: 24  Epoch: 277  Training loss = 3.5369  Validation loss = 1.8542  \n",
      "\n",
      "Fold: 24  Epoch: 278  Training loss = 3.5365  Validation loss = 1.8541  \n",
      "\n",
      "Fold: 24  Epoch: 279  Training loss = 3.5361  Validation loss = 1.8537  \n",
      "\n",
      "Fold: 24  Epoch: 280  Training loss = 3.5359  Validation loss = 1.8535  \n",
      "\n",
      "Fold: 24  Epoch: 281  Training loss = 3.5355  Validation loss = 1.8533  \n",
      "\n",
      "Fold: 24  Epoch: 282  Training loss = 3.5350  Validation loss = 1.8531  \n",
      "\n",
      "Fold: 24  Epoch: 283  Training loss = 3.5345  Validation loss = 1.8529  \n",
      "\n",
      "Fold: 24  Epoch: 284  Training loss = 3.5343  Validation loss = 1.8529  \n",
      "\n",
      "Fold: 24  Epoch: 285  Training loss = 3.5339  Validation loss = 1.8530  \n",
      "\n",
      "Fold: 24  Epoch: 286  Training loss = 3.5334  Validation loss = 1.8525  \n",
      "\n",
      "Fold: 24  Epoch: 287  Training loss = 3.5329  Validation loss = 1.8523  \n",
      "\n",
      "Fold: 24  Epoch: 288  Training loss = 3.5323  Validation loss = 1.8521  \n",
      "\n",
      "Fold: 24  Epoch: 289  Training loss = 3.5321  Validation loss = 1.8521  \n",
      "\n",
      "Fold: 24  Epoch: 290  Training loss = 3.5316  Validation loss = 1.8519  \n",
      "\n",
      "Fold: 24  Epoch: 291  Training loss = 3.5311  Validation loss = 1.8517  \n",
      "\n",
      "Fold: 24  Epoch: 292  Training loss = 3.5306  Validation loss = 1.8514  \n",
      "\n",
      "Fold: 24  Epoch: 293  Training loss = 3.5302  Validation loss = 1.8513  \n",
      "\n",
      "Fold: 24  Epoch: 294  Training loss = 3.5300  Validation loss = 1.8512  \n",
      "\n",
      "Fold: 24  Epoch: 295  Training loss = 3.5297  Validation loss = 1.8512  \n",
      "\n",
      "Fold: 24  Epoch: 296  Training loss = 3.5293  Validation loss = 1.8512  \n",
      "\n",
      "Fold: 24  Epoch: 297  Training loss = 3.5289  Validation loss = 1.8512  \n",
      "\n",
      "Fold: 24  Epoch: 298  Training loss = 3.5286  Validation loss = 1.8511  \n",
      "\n",
      "Fold: 24  Epoch: 299  Training loss = 3.5281  Validation loss = 1.8508  \n",
      "\n",
      "Fold: 24  Epoch: 300  Training loss = 3.5278  Validation loss = 1.8507  \n",
      "\n",
      "Fold: 24  Epoch: 301  Training loss = 3.5274  Validation loss = 1.8503  \n",
      "\n",
      "Fold: 24  Epoch: 302  Training loss = 3.5271  Validation loss = 1.8501  \n",
      "\n",
      "Fold: 24  Epoch: 303  Training loss = 3.5268  Validation loss = 1.8502  \n",
      "\n",
      "Fold: 24  Epoch: 304  Training loss = 3.5265  Validation loss = 1.8500  \n",
      "\n",
      "Fold: 24  Epoch: 305  Training loss = 3.5262  Validation loss = 1.8498  \n",
      "\n",
      "Fold: 24  Epoch: 306  Training loss = 3.5257  Validation loss = 1.8494  \n",
      "\n",
      "Fold: 24  Epoch: 307  Training loss = 3.5254  Validation loss = 1.8492  \n",
      "\n",
      "Fold: 24  Epoch: 308  Training loss = 3.5251  Validation loss = 1.8491  \n",
      "\n",
      "Fold: 24  Epoch: 309  Training loss = 3.5250  Validation loss = 1.8490  \n",
      "\n",
      "Fold: 24  Epoch: 310  Training loss = 3.5247  Validation loss = 1.8490  \n",
      "\n",
      "Fold: 24  Epoch: 311  Training loss = 3.5244  Validation loss = 1.8488  \n",
      "\n",
      "Fold: 24  Epoch: 312  Training loss = 3.5240  Validation loss = 1.8486  \n",
      "\n",
      "Fold: 24  Epoch: 313  Training loss = 3.5236  Validation loss = 1.8484  \n",
      "\n",
      "Fold: 24  Epoch: 314  Training loss = 3.5230  Validation loss = 1.8482  \n",
      "\n",
      "Fold: 24  Epoch: 315  Training loss = 3.5229  Validation loss = 1.8480  \n",
      "\n",
      "Fold: 24  Epoch: 316  Training loss = 3.5224  Validation loss = 1.8478  \n",
      "\n",
      "Fold: 24  Epoch: 317  Training loss = 3.5218  Validation loss = 1.8476  \n",
      "\n",
      "Fold: 24  Epoch: 318  Training loss = 3.5213  Validation loss = 1.8473  \n",
      "\n",
      "Fold: 24  Epoch: 319  Training loss = 3.5210  Validation loss = 1.8471  \n",
      "\n",
      "Fold: 24  Epoch: 320  Training loss = 3.5205  Validation loss = 1.8467  \n",
      "\n",
      "Fold: 24  Epoch: 321  Training loss = 3.5201  Validation loss = 1.8467  \n",
      "\n",
      "Fold: 24  Epoch: 322  Training loss = 3.5197  Validation loss = 1.8466  \n",
      "\n",
      "Fold: 24  Epoch: 323  Training loss = 3.5193  Validation loss = 1.8464  \n",
      "\n",
      "Fold: 24  Epoch: 324  Training loss = 3.5190  Validation loss = 1.8461  \n",
      "\n",
      "Fold: 24  Epoch: 325  Training loss = 3.5186  Validation loss = 1.8459  \n",
      "\n",
      "Fold: 24  Epoch: 326  Training loss = 3.5184  Validation loss = 1.8458  \n",
      "\n",
      "Fold: 24  Epoch: 327  Training loss = 3.5179  Validation loss = 1.8455  \n",
      "\n",
      "Fold: 24  Epoch: 328  Training loss = 3.5175  Validation loss = 1.8455  \n",
      "\n",
      "Fold: 24  Epoch: 329  Training loss = 3.5172  Validation loss = 1.8453  \n",
      "\n",
      "Fold: 24  Epoch: 330  Training loss = 3.5169  Validation loss = 1.8453  \n",
      "\n",
      "Fold: 24  Epoch: 331  Training loss = 3.5164  Validation loss = 1.8452  \n",
      "\n",
      "Fold: 24  Epoch: 332  Training loss = 3.5159  Validation loss = 1.8450  \n",
      "\n",
      "Fold: 24  Epoch: 333  Training loss = 3.5155  Validation loss = 1.8448  \n",
      "\n",
      "Fold: 24  Epoch: 334  Training loss = 3.5152  Validation loss = 1.8447  \n",
      "\n",
      "Fold: 24  Epoch: 335  Training loss = 3.5149  Validation loss = 1.8447  \n",
      "\n",
      "Fold: 24  Epoch: 336  Training loss = 3.5147  Validation loss = 1.8448  \n",
      "\n",
      "Fold: 24  Epoch: 337  Training loss = 3.5144  Validation loss = 1.8446  \n",
      "\n",
      "Fold: 24  Epoch: 338  Training loss = 3.5139  Validation loss = 1.8445  \n",
      "\n",
      "Fold: 24  Epoch: 339  Training loss = 3.5136  Validation loss = 1.8444  \n",
      "\n",
      "Fold: 24  Epoch: 340  Training loss = 3.5131  Validation loss = 1.8442  \n",
      "\n",
      "Fold: 24  Epoch: 341  Training loss = 3.5126  Validation loss = 1.8443  \n",
      "\n",
      "Fold: 24  Epoch: 342  Training loss = 3.5121  Validation loss = 1.8440  \n",
      "\n",
      "Fold: 24  Epoch: 343  Training loss = 3.5119  Validation loss = 1.8441  \n",
      "\n",
      "Fold: 24  Epoch: 344  Training loss = 3.5115  Validation loss = 1.8441  \n",
      "\n",
      "Fold: 24  Epoch: 345  Training loss = 3.5112  Validation loss = 1.8441  \n",
      "\n",
      "Fold: 24  Epoch: 346  Training loss = 3.5108  Validation loss = 1.8438  \n",
      "\n",
      "Fold: 24  Epoch: 347  Training loss = 3.5106  Validation loss = 1.8439  \n",
      "\n",
      "Fold: 24  Epoch: 348  Training loss = 3.5102  Validation loss = 1.8436  \n",
      "\n",
      "Fold: 24  Epoch: 349  Training loss = 3.5097  Validation loss = 1.8435  \n",
      "\n",
      "Fold: 24  Epoch: 350  Training loss = 3.5092  Validation loss = 1.8431  \n",
      "\n",
      "Fold: 24  Epoch: 351  Training loss = 3.5088  Validation loss = 1.8429  \n",
      "\n",
      "Fold: 24  Epoch: 352  Training loss = 3.5084  Validation loss = 1.8428  \n",
      "\n",
      "Fold: 24  Epoch: 353  Training loss = 3.5081  Validation loss = 1.8428  \n",
      "\n",
      "Fold: 24  Epoch: 354  Training loss = 3.5078  Validation loss = 1.8426  \n",
      "\n",
      "Fold: 24  Epoch: 355  Training loss = 3.5075  Validation loss = 1.8425  \n",
      "\n",
      "Fold: 24  Epoch: 356  Training loss = 3.5069  Validation loss = 1.8422  \n",
      "\n",
      "Fold: 24  Epoch: 357  Training loss = 3.5065  Validation loss = 1.8421  \n",
      "\n",
      "Fold: 24  Epoch: 358  Training loss = 3.5061  Validation loss = 1.8421  \n",
      "\n",
      "Fold: 24  Epoch: 359  Training loss = 3.5058  Validation loss = 1.8420  \n",
      "\n",
      "Fold: 24  Epoch: 360  Training loss = 3.5055  Validation loss = 1.8419  \n",
      "\n",
      "Fold: 24  Epoch: 361  Training loss = 3.5049  Validation loss = 1.8416  \n",
      "\n",
      "Fold: 24  Epoch: 362  Training loss = 3.5043  Validation loss = 1.8416  \n",
      "\n",
      "Fold: 24  Epoch: 363  Training loss = 3.5040  Validation loss = 1.8416  \n",
      "\n",
      "Fold: 24  Epoch: 364  Training loss = 3.5037  Validation loss = 1.8416  \n",
      "\n",
      "Fold: 24  Epoch: 365  Training loss = 3.5034  Validation loss = 1.8416  \n",
      "\n",
      "Fold: 24  Epoch: 366  Training loss = 3.5031  Validation loss = 1.8413  \n",
      "\n",
      "Fold: 24  Epoch: 367  Training loss = 3.5028  Validation loss = 1.8412  \n",
      "\n",
      "Fold: 24  Epoch: 368  Training loss = 3.5023  Validation loss = 1.8409  \n",
      "\n",
      "Fold: 24  Epoch: 369  Training loss = 3.5019  Validation loss = 1.8407  \n",
      "\n",
      "Fold: 24  Epoch: 370  Training loss = 3.5017  Validation loss = 1.8407  \n",
      "\n",
      "Fold: 24  Epoch: 371  Training loss = 3.5014  Validation loss = 1.8406  \n",
      "\n",
      "Fold: 24  Epoch: 372  Training loss = 3.5011  Validation loss = 1.8405  \n",
      "\n",
      "Fold: 24  Epoch: 373  Training loss = 3.5009  Validation loss = 1.8404  \n",
      "\n",
      "Fold: 24  Epoch: 374  Training loss = 3.5006  Validation loss = 1.8403  \n",
      "\n",
      "Fold: 24  Epoch: 375  Training loss = 3.5002  Validation loss = 1.8400  \n",
      "\n",
      "Fold: 24  Epoch: 376  Training loss = 3.5000  Validation loss = 1.8400  \n",
      "\n",
      "Fold: 24  Epoch: 377  Training loss = 3.4996  Validation loss = 1.8398  \n",
      "\n",
      "Fold: 24  Epoch: 378  Training loss = 3.4991  Validation loss = 1.8398  \n",
      "\n",
      "Fold: 24  Epoch: 379  Training loss = 3.4987  Validation loss = 1.8398  \n",
      "\n",
      "Fold: 24  Epoch: 380  Training loss = 3.4984  Validation loss = 1.8396  \n",
      "\n",
      "Fold: 24  Epoch: 381  Training loss = 3.4981  Validation loss = 1.8394  \n",
      "\n",
      "Fold: 24  Epoch: 382  Training loss = 3.4977  Validation loss = 1.8394  \n",
      "\n",
      "Fold: 24  Epoch: 383  Training loss = 3.4974  Validation loss = 1.8393  \n",
      "\n",
      "Fold: 24  Epoch: 384  Training loss = 3.4970  Validation loss = 1.8391  \n",
      "\n",
      "Fold: 24  Epoch: 385  Training loss = 3.4968  Validation loss = 1.8388  \n",
      "\n",
      "Fold: 24  Epoch: 386  Training loss = 3.4965  Validation loss = 1.8385  \n",
      "\n",
      "Fold: 24  Epoch: 387  Training loss = 3.4960  Validation loss = 1.8381  \n",
      "\n",
      "Fold: 24  Epoch: 388  Training loss = 3.4957  Validation loss = 1.8381  \n",
      "\n",
      "Fold: 24  Epoch: 389  Training loss = 3.4953  Validation loss = 1.8379  \n",
      "\n",
      "Fold: 24  Epoch: 390  Training loss = 3.4949  Validation loss = 1.8379  \n",
      "\n",
      "Fold: 24  Epoch: 391  Training loss = 3.4945  Validation loss = 1.8377  \n",
      "\n",
      "Fold: 24  Epoch: 392  Training loss = 3.4942  Validation loss = 1.8376  \n",
      "\n",
      "Fold: 24  Epoch: 393  Training loss = 3.4937  Validation loss = 1.8375  \n",
      "\n",
      "Fold: 24  Epoch: 394  Training loss = 3.4934  Validation loss = 1.8375  \n",
      "\n",
      "Fold: 24  Epoch: 395  Training loss = 3.4929  Validation loss = 1.8373  \n",
      "\n",
      "Fold: 24  Epoch: 396  Training loss = 3.4925  Validation loss = 1.8371  \n",
      "\n",
      "Fold: 24  Epoch: 397  Training loss = 3.4922  Validation loss = 1.8373  \n",
      "\n",
      "Fold: 24  Epoch: 398  Training loss = 3.4918  Validation loss = 1.8370  \n",
      "\n",
      "Fold: 24  Epoch: 399  Training loss = 3.4915  Validation loss = 1.8368  \n",
      "\n",
      "Fold: 24  Epoch: 400  Training loss = 3.4913  Validation loss = 1.8370  \n",
      "\n",
      "Fold: 24  Epoch: 401  Training loss = 3.4912  Validation loss = 1.8368  \n",
      "\n",
      "Fold: 24  Epoch: 402  Training loss = 3.4908  Validation loss = 1.8367  \n",
      "\n",
      "Fold: 24  Epoch: 403  Training loss = 3.4905  Validation loss = 1.8364  \n",
      "\n",
      "Fold: 24  Epoch: 404  Training loss = 3.4901  Validation loss = 1.8361  \n",
      "\n",
      "Fold: 24  Epoch: 405  Training loss = 3.4897  Validation loss = 1.8359  \n",
      "\n",
      "Fold: 24  Epoch: 406  Training loss = 3.4895  Validation loss = 1.8356  \n",
      "\n",
      "Fold: 24  Epoch: 407  Training loss = 3.4892  Validation loss = 1.8356  \n",
      "\n",
      "Fold: 24  Epoch: 408  Training loss = 3.4889  Validation loss = 1.8354  \n",
      "\n",
      "Fold: 24  Epoch: 409  Training loss = 3.4886  Validation loss = 1.8355  \n",
      "\n",
      "Fold: 24  Epoch: 410  Training loss = 3.4882  Validation loss = 1.8352  \n",
      "\n",
      "Fold: 24  Epoch: 411  Training loss = 3.4879  Validation loss = 1.8352  \n",
      "\n",
      "Fold: 24  Epoch: 412  Training loss = 3.4874  Validation loss = 1.8349  \n",
      "\n",
      "Fold: 24  Epoch: 413  Training loss = 3.4871  Validation loss = 1.8346  \n",
      "\n",
      "Fold: 24  Epoch: 414  Training loss = 3.4869  Validation loss = 1.8345  \n",
      "\n",
      "Fold: 24  Epoch: 415  Training loss = 3.4866  Validation loss = 1.8343  \n",
      "\n",
      "Fold: 24  Epoch: 416  Training loss = 3.4863  Validation loss = 1.8342  \n",
      "\n",
      "Fold: 24  Epoch: 417  Training loss = 3.4860  Validation loss = 1.8341  \n",
      "\n",
      "Fold: 24  Epoch: 418  Training loss = 3.4855  Validation loss = 1.8341  \n",
      "\n",
      "Fold: 24  Epoch: 419  Training loss = 3.4851  Validation loss = 1.8342  \n",
      "\n",
      "Fold: 24  Epoch: 420  Training loss = 3.4846  Validation loss = 1.8340  \n",
      "\n",
      "Fold: 24  Epoch: 421  Training loss = 3.4844  Validation loss = 1.8338  \n",
      "\n",
      "Fold: 24  Epoch: 422  Training loss = 3.4839  Validation loss = 1.8335  \n",
      "\n",
      "Fold: 24  Epoch: 423  Training loss = 3.4836  Validation loss = 1.8334  \n",
      "\n",
      "Fold: 24  Epoch: 424  Training loss = 3.4834  Validation loss = 1.8334  \n",
      "\n",
      "Fold: 24  Epoch: 425  Training loss = 3.4830  Validation loss = 1.8334  \n",
      "\n",
      "Fold: 24  Epoch: 426  Training loss = 3.4828  Validation loss = 1.8336  \n",
      "\n",
      "Fold: 24  Epoch: 427  Training loss = 3.4826  Validation loss = 1.8335  \n",
      "\n",
      "Fold: 24  Epoch: 428  Training loss = 3.4822  Validation loss = 1.8336  \n",
      "\n",
      "Fold: 24  Epoch: 429  Training loss = 3.4820  Validation loss = 1.8335  \n",
      "\n",
      "Fold: 24  Epoch: 430  Training loss = 3.4816  Validation loss = 1.8334  \n",
      "\n",
      "Fold: 24  Epoch: 431  Training loss = 3.4813  Validation loss = 1.8335  \n",
      "\n",
      "Fold: 24  Epoch: 432  Training loss = 3.4810  Validation loss = 1.8334  \n",
      "\n",
      "Fold: 24  Epoch: 433  Training loss = 3.4807  Validation loss = 1.8331  \n",
      "\n",
      "Fold: 24  Epoch: 434  Training loss = 3.4802  Validation loss = 1.8331  \n",
      "\n",
      "Fold: 24  Epoch: 435  Training loss = 3.4798  Validation loss = 1.8330  \n",
      "\n",
      "Fold: 24  Epoch: 436  Training loss = 3.4795  Validation loss = 1.8329  \n",
      "\n",
      "Fold: 24  Epoch: 437  Training loss = 3.4792  Validation loss = 1.8328  \n",
      "\n",
      "Fold: 24  Epoch: 438  Training loss = 3.4788  Validation loss = 1.8326  \n",
      "\n",
      "Fold: 24  Epoch: 439  Training loss = 3.4784  Validation loss = 1.8325  \n",
      "\n",
      "Fold: 24  Epoch: 440  Training loss = 3.4780  Validation loss = 1.8324  \n",
      "\n",
      "Fold: 24  Epoch: 441  Training loss = 3.4777  Validation loss = 1.8323  \n",
      "\n",
      "Fold: 24  Epoch: 442  Training loss = 3.4775  Validation loss = 1.8320  \n",
      "\n",
      "Fold: 24  Epoch: 443  Training loss = 3.4770  Validation loss = 1.8318  \n",
      "\n",
      "Fold: 24  Epoch: 444  Training loss = 3.4768  Validation loss = 1.8318  \n",
      "\n",
      "Fold: 24  Epoch: 445  Training loss = 3.4766  Validation loss = 1.8318  \n",
      "\n",
      "Fold: 24  Epoch: 446  Training loss = 3.4763  Validation loss = 1.8316  \n",
      "\n",
      "Fold: 24  Epoch: 447  Training loss = 3.4760  Validation loss = 1.8313  \n",
      "\n",
      "Fold: 24  Epoch: 448  Training loss = 3.4756  Validation loss = 1.8311  \n",
      "\n",
      "Fold: 24  Epoch: 449  Training loss = 3.4754  Validation loss = 1.8312  \n",
      "\n",
      "Fold: 24  Epoch: 450  Training loss = 3.4751  Validation loss = 1.8314  \n",
      "\n",
      "Fold: 24  Epoch: 451  Training loss = 3.4749  Validation loss = 1.8311  \n",
      "\n",
      "Fold: 24  Epoch: 452  Training loss = 3.4745  Validation loss = 1.8311  \n",
      "\n",
      "Fold: 24  Epoch: 453  Training loss = 3.4744  Validation loss = 1.8312  \n",
      "\n",
      "Fold: 24  Epoch: 454  Training loss = 3.4741  Validation loss = 1.8311  \n",
      "\n",
      "Fold: 24  Epoch: 455  Training loss = 3.4738  Validation loss = 1.8309  \n",
      "\n",
      "Fold: 24  Epoch: 456  Training loss = 3.4735  Validation loss = 1.8308  \n",
      "\n",
      "Fold: 24  Epoch: 457  Training loss = 3.4732  Validation loss = 1.8308  \n",
      "\n",
      "Fold: 24  Epoch: 458  Training loss = 3.4728  Validation loss = 1.8306  \n",
      "\n",
      "Fold: 24  Epoch: 459  Training loss = 3.4725  Validation loss = 1.8305  \n",
      "\n",
      "Fold: 24  Epoch: 460  Training loss = 3.4721  Validation loss = 1.8303  \n",
      "\n",
      "Fold: 24  Epoch: 461  Training loss = 3.4717  Validation loss = 1.8304  \n",
      "\n",
      "Fold: 24  Epoch: 462  Training loss = 3.4714  Validation loss = 1.8302  \n",
      "\n",
      "Fold: 24  Epoch: 463  Training loss = 3.4710  Validation loss = 1.8302  \n",
      "\n",
      "Fold: 24  Epoch: 464  Training loss = 3.4708  Validation loss = 1.8302  \n",
      "\n",
      "Fold: 24  Epoch: 465  Training loss = 3.4705  Validation loss = 1.8300  \n",
      "\n",
      "Fold: 24  Epoch: 466  Training loss = 3.4701  Validation loss = 1.8298  \n",
      "\n",
      "Fold: 24  Epoch: 467  Training loss = 3.4698  Validation loss = 1.8299  \n",
      "\n",
      "Fold: 24  Epoch: 468  Training loss = 3.4695  Validation loss = 1.8299  \n",
      "\n",
      "Fold: 24  Epoch: 469  Training loss = 3.4692  Validation loss = 1.8300  \n",
      "\n",
      "Fold: 24  Epoch: 470  Training loss = 3.4687  Validation loss = 1.8299  \n",
      "\n",
      "Fold: 24  Epoch: 471  Training loss = 3.4684  Validation loss = 1.8298  \n",
      "\n",
      "Fold: 24  Epoch: 472  Training loss = 3.4679  Validation loss = 1.8295  \n",
      "\n",
      "Fold: 24  Epoch: 473  Training loss = 3.4679  Validation loss = 1.8295  \n",
      "\n",
      "Fold: 24  Epoch: 474  Training loss = 3.4675  Validation loss = 1.8296  \n",
      "\n",
      "Fold: 24  Epoch: 475  Training loss = 3.4671  Validation loss = 1.8295  \n",
      "\n",
      "Fold: 24  Epoch: 476  Training loss = 3.4668  Validation loss = 1.8297  \n",
      "\n",
      "Fold: 24  Epoch: 477  Training loss = 3.4664  Validation loss = 1.8293  \n",
      "\n",
      "Fold: 24  Epoch: 478  Training loss = 3.4660  Validation loss = 1.8291  \n",
      "\n",
      "Fold: 24  Epoch: 479  Training loss = 3.4657  Validation loss = 1.8292  \n",
      "\n",
      "Fold: 24  Epoch: 480  Training loss = 3.4653  Validation loss = 1.8289  \n",
      "\n",
      "Fold: 24  Epoch: 481  Training loss = 3.4651  Validation loss = 1.8288  \n",
      "\n",
      "Fold: 24  Epoch: 482  Training loss = 3.4647  Validation loss = 1.8287  \n",
      "\n",
      "Fold: 24  Epoch: 483  Training loss = 3.4645  Validation loss = 1.8288  \n",
      "\n",
      "Fold: 24  Epoch: 484  Training loss = 3.4643  Validation loss = 1.8286  \n",
      "\n",
      "Fold: 24  Epoch: 485  Training loss = 3.4639  Validation loss = 1.8286  \n",
      "\n",
      "Fold: 24  Epoch: 486  Training loss = 3.4635  Validation loss = 1.8285  \n",
      "\n",
      "Fold: 24  Epoch: 487  Training loss = 3.4632  Validation loss = 1.8286  \n",
      "\n",
      "Fold: 24  Epoch: 488  Training loss = 3.4628  Validation loss = 1.8285  \n",
      "\n",
      "Fold: 24  Epoch: 489  Training loss = 3.4623  Validation loss = 1.8284  \n",
      "\n",
      "Fold: 24  Epoch: 490  Training loss = 3.4620  Validation loss = 1.8284  \n",
      "\n",
      "Fold: 24  Epoch: 491  Training loss = 3.4617  Validation loss = 1.8286  \n",
      "\n",
      "Fold: 24  Epoch: 492  Training loss = 3.4615  Validation loss = 1.8285  \n",
      "\n",
      "Fold: 24  Epoch: 493  Training loss = 3.4611  Validation loss = 1.8285  \n",
      "\n",
      "Fold: 24  Epoch: 494  Training loss = 3.4607  Validation loss = 1.8284  \n",
      "\n",
      "Fold: 24  Epoch: 495  Training loss = 3.4603  Validation loss = 1.8287  \n",
      "\n",
      "Fold: 24  Epoch: 496  Training loss = 3.4598  Validation loss = 1.8287  \n",
      "\n",
      "Fold: 24  Epoch: 497  Training loss = 3.4596  Validation loss = 1.8286  \n",
      "\n",
      "Fold: 24  Epoch: 498  Training loss = 3.4593  Validation loss = 1.8284  \n",
      "\n",
      "Fold: 24  Epoch: 499  Training loss = 3.4590  Validation loss = 1.8285  \n",
      "\n",
      "Fold: 24  Epoch: 500  Training loss = 3.4586  Validation loss = 1.8284  \n",
      "\n",
      "Check model:  Fold: 24  Optimal epoch: 490  \n",
      "\n",
      "Fold: 25  Epoch: 1  Training loss = 3.4346  Validation loss = 1.9733  \n",
      "\n",
      "Fold: 25  Epoch: 2  Training loss = 3.4343  Validation loss = 1.9728  \n",
      "\n",
      "Fold: 25  Epoch: 3  Training loss = 3.4340  Validation loss = 1.9723  \n",
      "\n",
      "Fold: 25  Epoch: 4  Training loss = 3.4336  Validation loss = 1.9717  \n",
      "\n",
      "Fold: 25  Epoch: 5  Training loss = 3.4335  Validation loss = 1.9715  \n",
      "\n",
      "Fold: 25  Epoch: 6  Training loss = 3.4332  Validation loss = 1.9709  \n",
      "\n",
      "Fold: 25  Epoch: 7  Training loss = 3.4329  Validation loss = 1.9706  \n",
      "\n",
      "Fold: 25  Epoch: 8  Training loss = 3.4329  Validation loss = 1.9705  \n",
      "\n",
      "Fold: 25  Epoch: 9  Training loss = 3.4326  Validation loss = 1.9701  \n",
      "\n",
      "Fold: 25  Epoch: 10  Training loss = 3.4323  Validation loss = 1.9696  \n",
      "\n",
      "Fold: 25  Epoch: 11  Training loss = 3.4319  Validation loss = 1.9691  \n",
      "\n",
      "Fold: 25  Epoch: 12  Training loss = 3.4316  Validation loss = 1.9686  \n",
      "\n",
      "Fold: 25  Epoch: 13  Training loss = 3.4315  Validation loss = 1.9683  \n",
      "\n",
      "Fold: 25  Epoch: 14  Training loss = 3.4310  Validation loss = 1.9676  \n",
      "\n",
      "Fold: 25  Epoch: 15  Training loss = 3.4307  Validation loss = 1.9673  \n",
      "\n",
      "Fold: 25  Epoch: 16  Training loss = 3.4302  Validation loss = 1.9666  \n",
      "\n",
      "Fold: 25  Epoch: 17  Training loss = 3.4296  Validation loss = 1.9657  \n",
      "\n",
      "Fold: 25  Epoch: 18  Training loss = 3.4287  Validation loss = 1.9650  \n",
      "\n",
      "Fold: 25  Epoch: 19  Training loss = 3.4283  Validation loss = 1.9646  \n",
      "\n",
      "Fold: 25  Epoch: 20  Training loss = 3.4280  Validation loss = 1.9641  \n",
      "\n",
      "Fold: 25  Epoch: 21  Training loss = 3.4278  Validation loss = 1.9637  \n",
      "\n",
      "Fold: 25  Epoch: 22  Training loss = 3.4276  Validation loss = 1.9632  \n",
      "\n",
      "Fold: 25  Epoch: 23  Training loss = 3.4269  Validation loss = 1.9624  \n",
      "\n",
      "Fold: 25  Epoch: 24  Training loss = 3.4266  Validation loss = 1.9620  \n",
      "\n",
      "Fold: 25  Epoch: 25  Training loss = 3.4261  Validation loss = 1.9614  \n",
      "\n",
      "Fold: 25  Epoch: 26  Training loss = 3.4259  Validation loss = 1.9612  \n",
      "\n",
      "Fold: 25  Epoch: 27  Training loss = 3.4255  Validation loss = 1.9604  \n",
      "\n",
      "Fold: 25  Epoch: 28  Training loss = 3.4250  Validation loss = 1.9601  \n",
      "\n",
      "Fold: 25  Epoch: 29  Training loss = 3.4247  Validation loss = 1.9597  \n",
      "\n",
      "Fold: 25  Epoch: 30  Training loss = 3.4246  Validation loss = 1.9594  \n",
      "\n",
      "Fold: 25  Epoch: 31  Training loss = 3.4241  Validation loss = 1.9589  \n",
      "\n",
      "Fold: 25  Epoch: 32  Training loss = 3.4237  Validation loss = 1.9582  \n",
      "\n",
      "Fold: 25  Epoch: 33  Training loss = 3.4235  Validation loss = 1.9576  \n",
      "\n",
      "Fold: 25  Epoch: 34  Training loss = 3.4232  Validation loss = 1.9572  \n",
      "\n",
      "Fold: 25  Epoch: 35  Training loss = 3.4230  Validation loss = 1.9567  \n",
      "\n",
      "Fold: 25  Epoch: 36  Training loss = 3.4226  Validation loss = 1.9562  \n",
      "\n",
      "Fold: 25  Epoch: 37  Training loss = 3.4222  Validation loss = 1.9555  \n",
      "\n",
      "Fold: 25  Epoch: 38  Training loss = 3.4219  Validation loss = 1.9550  \n",
      "\n",
      "Fold: 25  Epoch: 39  Training loss = 3.4215  Validation loss = 1.9545  \n",
      "\n",
      "Fold: 25  Epoch: 40  Training loss = 3.4210  Validation loss = 1.9535  \n",
      "\n",
      "Fold: 25  Epoch: 41  Training loss = 3.4205  Validation loss = 1.9528  \n",
      "\n",
      "Fold: 25  Epoch: 42  Training loss = 3.4202  Validation loss = 1.9522  \n",
      "\n",
      "Fold: 25  Epoch: 43  Training loss = 3.4199  Validation loss = 1.9518  \n",
      "\n",
      "Fold: 25  Epoch: 44  Training loss = 3.4196  Validation loss = 1.9512  \n",
      "\n",
      "Fold: 25  Epoch: 45  Training loss = 3.4192  Validation loss = 1.9505  \n",
      "\n",
      "Fold: 25  Epoch: 46  Training loss = 3.4189  Validation loss = 1.9500  \n",
      "\n",
      "Fold: 25  Epoch: 47  Training loss = 3.4187  Validation loss = 1.9495  \n",
      "\n",
      "Fold: 25  Epoch: 48  Training loss = 3.4185  Validation loss = 1.9490  \n",
      "\n",
      "Fold: 25  Epoch: 49  Training loss = 3.4180  Validation loss = 1.9481  \n",
      "\n",
      "Fold: 25  Epoch: 50  Training loss = 3.4178  Validation loss = 1.9478  \n",
      "\n",
      "Fold: 25  Epoch: 51  Training loss = 3.4177  Validation loss = 1.9476  \n",
      "\n",
      "Fold: 25  Epoch: 52  Training loss = 3.4174  Validation loss = 1.9471  \n",
      "\n",
      "Fold: 25  Epoch: 53  Training loss = 3.4171  Validation loss = 1.9466  \n",
      "\n",
      "Fold: 25  Epoch: 54  Training loss = 3.4169  Validation loss = 1.9461  \n",
      "\n",
      "Fold: 25  Epoch: 55  Training loss = 3.4167  Validation loss = 1.9458  \n",
      "\n",
      "Fold: 25  Epoch: 56  Training loss = 3.4166  Validation loss = 1.9458  \n",
      "\n",
      "Fold: 25  Epoch: 57  Training loss = 3.4164  Validation loss = 1.9455  \n",
      "\n",
      "Fold: 25  Epoch: 58  Training loss = 3.4161  Validation loss = 1.9449  \n",
      "\n",
      "Fold: 25  Epoch: 59  Training loss = 3.4160  Validation loss = 1.9449  \n",
      "\n",
      "Fold: 25  Epoch: 60  Training loss = 3.4158  Validation loss = 1.9443  \n",
      "\n",
      "Fold: 25  Epoch: 61  Training loss = 3.4156  Validation loss = 1.9439  \n",
      "\n",
      "Fold: 25  Epoch: 62  Training loss = 3.4153  Validation loss = 1.9438  \n",
      "\n",
      "Fold: 25  Epoch: 63  Training loss = 3.4150  Validation loss = 1.9432  \n",
      "\n",
      "Fold: 25  Epoch: 64  Training loss = 3.4148  Validation loss = 1.9429  \n",
      "\n",
      "Fold: 25  Epoch: 65  Training loss = 3.4144  Validation loss = 1.9424  \n",
      "\n",
      "Fold: 25  Epoch: 66  Training loss = 3.4141  Validation loss = 1.9419  \n",
      "\n",
      "Fold: 25  Epoch: 67  Training loss = 3.4138  Validation loss = 1.9414  \n",
      "\n",
      "Fold: 25  Epoch: 68  Training loss = 3.4136  Validation loss = 1.9413  \n",
      "\n",
      "Fold: 25  Epoch: 69  Training loss = 3.4134  Validation loss = 1.9408  \n",
      "\n",
      "Fold: 25  Epoch: 70  Training loss = 3.4132  Validation loss = 1.9404  \n",
      "\n",
      "Fold: 25  Epoch: 71  Training loss = 3.4129  Validation loss = 1.9397  \n",
      "\n",
      "Fold: 25  Epoch: 72  Training loss = 3.4125  Validation loss = 1.9389  \n",
      "\n",
      "Fold: 25  Epoch: 73  Training loss = 3.4122  Validation loss = 1.9383  \n",
      "\n",
      "Fold: 25  Epoch: 74  Training loss = 3.4119  Validation loss = 1.9378  \n",
      "\n",
      "Fold: 25  Epoch: 75  Training loss = 3.4117  Validation loss = 1.9377  \n",
      "\n",
      "Fold: 25  Epoch: 76  Training loss = 3.4114  Validation loss = 1.9369  \n",
      "\n",
      "Fold: 25  Epoch: 77  Training loss = 3.4109  Validation loss = 1.9359  \n",
      "\n",
      "Fold: 25  Epoch: 78  Training loss = 3.4108  Validation loss = 1.9355  \n",
      "\n",
      "Fold: 25  Epoch: 79  Training loss = 3.4103  Validation loss = 1.9345  \n",
      "\n",
      "Fold: 25  Epoch: 80  Training loss = 3.4102  Validation loss = 1.9344  \n",
      "\n",
      "Fold: 25  Epoch: 81  Training loss = 3.4100  Validation loss = 1.9340  \n",
      "\n",
      "Fold: 25  Epoch: 82  Training loss = 3.4097  Validation loss = 1.9335  \n",
      "\n",
      "Fold: 25  Epoch: 83  Training loss = 3.4094  Validation loss = 1.9330  \n",
      "\n",
      "Fold: 25  Epoch: 84  Training loss = 3.4093  Validation loss = 1.9327  \n",
      "\n",
      "Fold: 25  Epoch: 85  Training loss = 3.4092  Validation loss = 1.9327  \n",
      "\n",
      "Fold: 25  Epoch: 86  Training loss = 3.4089  Validation loss = 1.9323  \n",
      "\n",
      "Fold: 25  Epoch: 87  Training loss = 3.4087  Validation loss = 1.9320  \n",
      "\n",
      "Fold: 25  Epoch: 88  Training loss = 3.4084  Validation loss = 1.9314  \n",
      "\n",
      "Fold: 25  Epoch: 89  Training loss = 3.4082  Validation loss = 1.9309  \n",
      "\n",
      "Fold: 25  Epoch: 90  Training loss = 3.4079  Validation loss = 1.9306  \n",
      "\n",
      "Fold: 25  Epoch: 91  Training loss = 3.4077  Validation loss = 1.9302  \n",
      "\n",
      "Fold: 25  Epoch: 92  Training loss = 3.4076  Validation loss = 1.9300  \n",
      "\n",
      "Fold: 25  Epoch: 93  Training loss = 3.4073  Validation loss = 1.9292  \n",
      "\n",
      "Fold: 25  Epoch: 94  Training loss = 3.4068  Validation loss = 1.9283  \n",
      "\n",
      "Fold: 25  Epoch: 95  Training loss = 3.4065  Validation loss = 1.9276  \n",
      "\n",
      "Fold: 25  Epoch: 96  Training loss = 3.4064  Validation loss = 1.9272  \n",
      "\n",
      "Fold: 25  Epoch: 97  Training loss = 3.4060  Validation loss = 1.9266  \n",
      "\n",
      "Fold: 25  Epoch: 98  Training loss = 3.4058  Validation loss = 1.9263  \n",
      "\n",
      "Fold: 25  Epoch: 99  Training loss = 3.4055  Validation loss = 1.9256  \n",
      "\n",
      "Fold: 25  Epoch: 100  Training loss = 3.4054  Validation loss = 1.9253  \n",
      "\n",
      "Fold: 25  Epoch: 101  Training loss = 3.4052  Validation loss = 1.9249  \n",
      "\n",
      "Fold: 25  Epoch: 102  Training loss = 3.4050  Validation loss = 1.9245  \n",
      "\n",
      "Fold: 25  Epoch: 103  Training loss = 3.4048  Validation loss = 1.9242  \n",
      "\n",
      "Fold: 25  Epoch: 104  Training loss = 3.4044  Validation loss = 1.9233  \n",
      "\n",
      "Fold: 25  Epoch: 105  Training loss = 3.4042  Validation loss = 1.9229  \n",
      "\n",
      "Fold: 25  Epoch: 106  Training loss = 3.4040  Validation loss = 1.9224  \n",
      "\n",
      "Fold: 25  Epoch: 107  Training loss = 3.4037  Validation loss = 1.9219  \n",
      "\n",
      "Fold: 25  Epoch: 108  Training loss = 3.4034  Validation loss = 1.9213  \n",
      "\n",
      "Fold: 25  Epoch: 109  Training loss = 3.4031  Validation loss = 1.9208  \n",
      "\n",
      "Fold: 25  Epoch: 110  Training loss = 3.4029  Validation loss = 1.9204  \n",
      "\n",
      "Fold: 25  Epoch: 111  Training loss = 3.4026  Validation loss = 1.9198  \n",
      "\n",
      "Fold: 25  Epoch: 112  Training loss = 3.4023  Validation loss = 1.9192  \n",
      "\n",
      "Fold: 25  Epoch: 113  Training loss = 3.4019  Validation loss = 1.9185  \n",
      "\n",
      "Fold: 25  Epoch: 114  Training loss = 3.4017  Validation loss = 1.9183  \n",
      "\n",
      "Fold: 25  Epoch: 115  Training loss = 3.4016  Validation loss = 1.9180  \n",
      "\n",
      "Fold: 25  Epoch: 116  Training loss = 3.4015  Validation loss = 1.9180  \n",
      "\n",
      "Fold: 25  Epoch: 117  Training loss = 3.4014  Validation loss = 1.9179  \n",
      "\n",
      "Fold: 25  Epoch: 118  Training loss = 3.4011  Validation loss = 1.9173  \n",
      "\n",
      "Fold: 25  Epoch: 119  Training loss = 3.4007  Validation loss = 1.9164  \n",
      "\n",
      "Fold: 25  Epoch: 120  Training loss = 3.4003  Validation loss = 1.9158  \n",
      "\n",
      "Fold: 25  Epoch: 121  Training loss = 3.4000  Validation loss = 1.9153  \n",
      "\n",
      "Fold: 25  Epoch: 122  Training loss = 3.3997  Validation loss = 1.9150  \n",
      "\n",
      "Fold: 25  Epoch: 123  Training loss = 3.3995  Validation loss = 1.9146  \n",
      "\n",
      "Fold: 25  Epoch: 124  Training loss = 3.3992  Validation loss = 1.9141  \n",
      "\n",
      "Fold: 25  Epoch: 125  Training loss = 3.3990  Validation loss = 1.9139  \n",
      "\n",
      "Fold: 25  Epoch: 126  Training loss = 3.3987  Validation loss = 1.9133  \n",
      "\n",
      "Fold: 25  Epoch: 127  Training loss = 3.3984  Validation loss = 1.9125  \n",
      "\n",
      "Fold: 25  Epoch: 128  Training loss = 3.3981  Validation loss = 1.9121  \n",
      "\n",
      "Fold: 25  Epoch: 129  Training loss = 3.3979  Validation loss = 1.9117  \n",
      "\n",
      "Fold: 25  Epoch: 130  Training loss = 3.3978  Validation loss = 1.9115  \n",
      "\n",
      "Fold: 25  Epoch: 131  Training loss = 3.3975  Validation loss = 1.9109  \n",
      "\n",
      "Fold: 25  Epoch: 132  Training loss = 3.3972  Validation loss = 1.9103  \n",
      "\n",
      "Fold: 25  Epoch: 133  Training loss = 3.3970  Validation loss = 1.9099  \n",
      "\n",
      "Fold: 25  Epoch: 134  Training loss = 3.3967  Validation loss = 1.9095  \n",
      "\n",
      "Fold: 25  Epoch: 135  Training loss = 3.3964  Validation loss = 1.9090  \n",
      "\n",
      "Fold: 25  Epoch: 136  Training loss = 3.3963  Validation loss = 1.9090  \n",
      "\n",
      "Fold: 25  Epoch: 137  Training loss = 3.3960  Validation loss = 1.9084  \n",
      "\n",
      "Fold: 25  Epoch: 138  Training loss = 3.3956  Validation loss = 1.9077  \n",
      "\n",
      "Fold: 25  Epoch: 139  Training loss = 3.3954  Validation loss = 1.9072  \n",
      "\n",
      "Fold: 25  Epoch: 140  Training loss = 3.3951  Validation loss = 1.9066  \n",
      "\n",
      "Fold: 25  Epoch: 141  Training loss = 3.3949  Validation loss = 1.9063  \n",
      "\n",
      "Fold: 25  Epoch: 142  Training loss = 3.3948  Validation loss = 1.9061  \n",
      "\n",
      "Fold: 25  Epoch: 143  Training loss = 3.3946  Validation loss = 1.9060  \n",
      "\n",
      "Fold: 25  Epoch: 144  Training loss = 3.3943  Validation loss = 1.9054  \n",
      "\n",
      "Fold: 25  Epoch: 145  Training loss = 3.3940  Validation loss = 1.9048  \n",
      "\n",
      "Fold: 25  Epoch: 146  Training loss = 3.3937  Validation loss = 1.9041  \n",
      "\n",
      "Fold: 25  Epoch: 147  Training loss = 3.3935  Validation loss = 1.9038  \n",
      "\n",
      "Fold: 25  Epoch: 148  Training loss = 3.3934  Validation loss = 1.9035  \n",
      "\n",
      "Fold: 25  Epoch: 149  Training loss = 3.3933  Validation loss = 1.9035  \n",
      "\n",
      "Fold: 25  Epoch: 150  Training loss = 3.3932  Validation loss = 1.9033  \n",
      "\n",
      "Fold: 25  Epoch: 151  Training loss = 3.3929  Validation loss = 1.9029  \n",
      "\n",
      "Fold: 25  Epoch: 152  Training loss = 3.3927  Validation loss = 1.9025  \n",
      "\n",
      "Fold: 25  Epoch: 153  Training loss = 3.3925  Validation loss = 1.9021  \n",
      "\n",
      "Fold: 25  Epoch: 154  Training loss = 3.3922  Validation loss = 1.9017  \n",
      "\n",
      "Fold: 25  Epoch: 155  Training loss = 3.3921  Validation loss = 1.9015  \n",
      "\n",
      "Fold: 25  Epoch: 156  Training loss = 3.3917  Validation loss = 1.9009  \n",
      "\n",
      "Fold: 25  Epoch: 157  Training loss = 3.3915  Validation loss = 1.9004  \n",
      "\n",
      "Fold: 25  Epoch: 158  Training loss = 3.3914  Validation loss = 1.9004  \n",
      "\n",
      "Fold: 25  Epoch: 159  Training loss = 3.3910  Validation loss = 1.8995  \n",
      "\n",
      "Fold: 25  Epoch: 160  Training loss = 3.3907  Validation loss = 1.8991  \n",
      "\n",
      "Fold: 25  Epoch: 161  Training loss = 3.3905  Validation loss = 1.8985  \n",
      "\n",
      "Fold: 25  Epoch: 162  Training loss = 3.3902  Validation loss = 1.8980  \n",
      "\n",
      "Fold: 25  Epoch: 163  Training loss = 3.3901  Validation loss = 1.8978  \n",
      "\n",
      "Fold: 25  Epoch: 164  Training loss = 3.3899  Validation loss = 1.8974  \n",
      "\n",
      "Fold: 25  Epoch: 165  Training loss = 3.3897  Validation loss = 1.8971  \n",
      "\n",
      "Fold: 25  Epoch: 166  Training loss = 3.3895  Validation loss = 1.8967  \n",
      "\n",
      "Fold: 25  Epoch: 167  Training loss = 3.3893  Validation loss = 1.8963  \n",
      "\n",
      "Fold: 25  Epoch: 168  Training loss = 3.3891  Validation loss = 1.8960  \n",
      "\n",
      "Fold: 25  Epoch: 169  Training loss = 3.3888  Validation loss = 1.8956  \n",
      "\n",
      "Fold: 25  Epoch: 170  Training loss = 3.3885  Validation loss = 1.8950  \n",
      "\n",
      "Fold: 25  Epoch: 171  Training loss = 3.3884  Validation loss = 1.8950  \n",
      "\n",
      "Fold: 25  Epoch: 172  Training loss = 3.3882  Validation loss = 1.8946  \n",
      "\n",
      "Fold: 25  Epoch: 173  Training loss = 3.3881  Validation loss = 1.8945  \n",
      "\n",
      "Fold: 25  Epoch: 174  Training loss = 3.3877  Validation loss = 1.8938  \n",
      "\n",
      "Fold: 25  Epoch: 175  Training loss = 3.3872  Validation loss = 1.8930  \n",
      "\n",
      "Fold: 25  Epoch: 176  Training loss = 3.3871  Validation loss = 1.8926  \n",
      "\n",
      "Fold: 25  Epoch: 177  Training loss = 3.3869  Validation loss = 1.8920  \n",
      "\n",
      "Fold: 25  Epoch: 178  Training loss = 3.3866  Validation loss = 1.8917  \n",
      "\n",
      "Fold: 25  Epoch: 179  Training loss = 3.3864  Validation loss = 1.8914  \n",
      "\n",
      "Fold: 25  Epoch: 180  Training loss = 3.3863  Validation loss = 1.8913  \n",
      "\n",
      "Fold: 25  Epoch: 181  Training loss = 3.3862  Validation loss = 1.8911  \n",
      "\n",
      "Fold: 25  Epoch: 182  Training loss = 3.3860  Validation loss = 1.8907  \n",
      "\n",
      "Fold: 25  Epoch: 183  Training loss = 3.3858  Validation loss = 1.8903  \n",
      "\n",
      "Fold: 25  Epoch: 184  Training loss = 3.3855  Validation loss = 1.8895  \n",
      "\n",
      "Fold: 25  Epoch: 185  Training loss = 3.3852  Validation loss = 1.8890  \n",
      "\n",
      "Fold: 25  Epoch: 186  Training loss = 3.3850  Validation loss = 1.8885  \n",
      "\n",
      "Fold: 25  Epoch: 187  Training loss = 3.3847  Validation loss = 1.8879  \n",
      "\n",
      "Fold: 25  Epoch: 188  Training loss = 3.3844  Validation loss = 1.8874  \n",
      "\n",
      "Fold: 25  Epoch: 189  Training loss = 3.3842  Validation loss = 1.8870  \n",
      "\n",
      "Fold: 25  Epoch: 190  Training loss = 3.3838  Validation loss = 1.8861  \n",
      "\n",
      "Fold: 25  Epoch: 191  Training loss = 3.3836  Validation loss = 1.8858  \n",
      "\n",
      "Fold: 25  Epoch: 192  Training loss = 3.3834  Validation loss = 1.8853  \n",
      "\n",
      "Fold: 25  Epoch: 193  Training loss = 3.3831  Validation loss = 1.8847  \n",
      "\n",
      "Fold: 25  Epoch: 194  Training loss = 3.3828  Validation loss = 1.8843  \n",
      "\n",
      "Fold: 25  Epoch: 195  Training loss = 3.3825  Validation loss = 1.8836  \n",
      "\n",
      "Fold: 25  Epoch: 196  Training loss = 3.3822  Validation loss = 1.8829  \n",
      "\n",
      "Fold: 25  Epoch: 197  Training loss = 3.3820  Validation loss = 1.8824  \n",
      "\n",
      "Fold: 25  Epoch: 198  Training loss = 3.3817  Validation loss = 1.8820  \n",
      "\n",
      "Fold: 25  Epoch: 199  Training loss = 3.3816  Validation loss = 1.8820  \n",
      "\n",
      "Fold: 25  Epoch: 200  Training loss = 3.3814  Validation loss = 1.8817  \n",
      "\n",
      "Fold: 25  Epoch: 201  Training loss = 3.3811  Validation loss = 1.8812  \n",
      "\n",
      "Fold: 25  Epoch: 202  Training loss = 3.3810  Validation loss = 1.8810  \n",
      "\n",
      "Fold: 25  Epoch: 203  Training loss = 3.3808  Validation loss = 1.8808  \n",
      "\n",
      "Fold: 25  Epoch: 204  Training loss = 3.3806  Validation loss = 1.8805  \n",
      "\n",
      "Fold: 25  Epoch: 205  Training loss = 3.3803  Validation loss = 1.8800  \n",
      "\n",
      "Fold: 25  Epoch: 206  Training loss = 3.3801  Validation loss = 1.8795  \n",
      "\n",
      "Fold: 25  Epoch: 207  Training loss = 3.3800  Validation loss = 1.8792  \n",
      "\n",
      "Fold: 25  Epoch: 208  Training loss = 3.3797  Validation loss = 1.8786  \n",
      "\n",
      "Fold: 25  Epoch: 209  Training loss = 3.3795  Validation loss = 1.8785  \n",
      "\n",
      "Fold: 25  Epoch: 210  Training loss = 3.3792  Validation loss = 1.8780  \n",
      "\n",
      "Fold: 25  Epoch: 211  Training loss = 3.3789  Validation loss = 1.8775  \n",
      "\n",
      "Fold: 25  Epoch: 212  Training loss = 3.3786  Validation loss = 1.8768  \n",
      "\n",
      "Fold: 25  Epoch: 213  Training loss = 3.3785  Validation loss = 1.8767  \n",
      "\n",
      "Fold: 25  Epoch: 214  Training loss = 3.3782  Validation loss = 1.8761  \n",
      "\n",
      "Fold: 25  Epoch: 215  Training loss = 3.3781  Validation loss = 1.8759  \n",
      "\n",
      "Fold: 25  Epoch: 216  Training loss = 3.3780  Validation loss = 1.8758  \n",
      "\n",
      "Fold: 25  Epoch: 217  Training loss = 3.3777  Validation loss = 1.8753  \n",
      "\n",
      "Fold: 25  Epoch: 218  Training loss = 3.3774  Validation loss = 1.8750  \n",
      "\n",
      "Fold: 25  Epoch: 219  Training loss = 3.3773  Validation loss = 1.8748  \n",
      "\n",
      "Fold: 25  Epoch: 220  Training loss = 3.3769  Validation loss = 1.8741  \n",
      "\n",
      "Fold: 25  Epoch: 221  Training loss = 3.3767  Validation loss = 1.8738  \n",
      "\n",
      "Fold: 25  Epoch: 222  Training loss = 3.3765  Validation loss = 1.8733  \n",
      "\n",
      "Fold: 25  Epoch: 223  Training loss = 3.3763  Validation loss = 1.8730  \n",
      "\n",
      "Fold: 25  Epoch: 224  Training loss = 3.3759  Validation loss = 1.8721  \n",
      "\n",
      "Fold: 25  Epoch: 225  Training loss = 3.3758  Validation loss = 1.8720  \n",
      "\n",
      "Fold: 25  Epoch: 226  Training loss = 3.3755  Validation loss = 1.8715  \n",
      "\n",
      "Fold: 25  Epoch: 227  Training loss = 3.3752  Validation loss = 1.8710  \n",
      "\n",
      "Fold: 25  Epoch: 228  Training loss = 3.3751  Validation loss = 1.8707  \n",
      "\n",
      "Fold: 25  Epoch: 229  Training loss = 3.3747  Validation loss = 1.8700  \n",
      "\n",
      "Fold: 25  Epoch: 230  Training loss = 3.3746  Validation loss = 1.8697  \n",
      "\n",
      "Fold: 25  Epoch: 231  Training loss = 3.3744  Validation loss = 1.8695  \n",
      "\n",
      "Fold: 25  Epoch: 232  Training loss = 3.3742  Validation loss = 1.8691  \n",
      "\n",
      "Fold: 25  Epoch: 233  Training loss = 3.3739  Validation loss = 1.8686  \n",
      "\n",
      "Fold: 25  Epoch: 234  Training loss = 3.3736  Validation loss = 1.8680  \n",
      "\n",
      "Fold: 25  Epoch: 235  Training loss = 3.3734  Validation loss = 1.8677  \n",
      "\n",
      "Fold: 25  Epoch: 236  Training loss = 3.3730  Validation loss = 1.8670  \n",
      "\n",
      "Fold: 25  Epoch: 237  Training loss = 3.3727  Validation loss = 1.8665  \n",
      "\n",
      "Fold: 25  Epoch: 238  Training loss = 3.3724  Validation loss = 1.8656  \n",
      "\n",
      "Fold: 25  Epoch: 239  Training loss = 3.3721  Validation loss = 1.8651  \n",
      "\n",
      "Fold: 25  Epoch: 240  Training loss = 3.3718  Validation loss = 1.8645  \n",
      "\n",
      "Fold: 25  Epoch: 241  Training loss = 3.3716  Validation loss = 1.8642  \n",
      "\n",
      "Fold: 25  Epoch: 242  Training loss = 3.3715  Validation loss = 1.8641  \n",
      "\n",
      "Fold: 25  Epoch: 243  Training loss = 3.3712  Validation loss = 1.8636  \n",
      "\n",
      "Fold: 25  Epoch: 244  Training loss = 3.3712  Validation loss = 1.8635  \n",
      "\n",
      "Fold: 25  Epoch: 245  Training loss = 3.3709  Validation loss = 1.8627  \n",
      "\n",
      "Fold: 25  Epoch: 246  Training loss = 3.3706  Validation loss = 1.8622  \n",
      "\n",
      "Fold: 25  Epoch: 247  Training loss = 3.3703  Validation loss = 1.8614  \n",
      "\n",
      "Fold: 25  Epoch: 248  Training loss = 3.3701  Validation loss = 1.8612  \n",
      "\n",
      "Fold: 25  Epoch: 249  Training loss = 3.3699  Validation loss = 1.8606  \n",
      "\n",
      "Fold: 25  Epoch: 250  Training loss = 3.3696  Validation loss = 1.8604  \n",
      "\n",
      "Fold: 25  Epoch: 251  Training loss = 3.3692  Validation loss = 1.8596  \n",
      "\n",
      "Fold: 25  Epoch: 252  Training loss = 3.3689  Validation loss = 1.8590  \n",
      "\n",
      "Fold: 25  Epoch: 253  Training loss = 3.3686  Validation loss = 1.8585  \n",
      "\n",
      "Fold: 25  Epoch: 254  Training loss = 3.3684  Validation loss = 1.8579  \n",
      "\n",
      "Fold: 25  Epoch: 255  Training loss = 3.3684  Validation loss = 1.8579  \n",
      "\n",
      "Fold: 25  Epoch: 256  Training loss = 3.3682  Validation loss = 1.8578  \n",
      "\n",
      "Fold: 25  Epoch: 257  Training loss = 3.3680  Validation loss = 1.8573  \n",
      "\n",
      "Fold: 25  Epoch: 258  Training loss = 3.3679  Validation loss = 1.8572  \n",
      "\n",
      "Fold: 25  Epoch: 259  Training loss = 3.3676  Validation loss = 1.8568  \n",
      "\n",
      "Fold: 25  Epoch: 260  Training loss = 3.3674  Validation loss = 1.8565  \n",
      "\n",
      "Fold: 25  Epoch: 261  Training loss = 3.3672  Validation loss = 1.8558  \n",
      "\n",
      "Fold: 25  Epoch: 262  Training loss = 3.3670  Validation loss = 1.8555  \n",
      "\n",
      "Fold: 25  Epoch: 263  Training loss = 3.3668  Validation loss = 1.8551  \n",
      "\n",
      "Fold: 25  Epoch: 264  Training loss = 3.3666  Validation loss = 1.8545  \n",
      "\n",
      "Fold: 25  Epoch: 265  Training loss = 3.3664  Validation loss = 1.8542  \n",
      "\n",
      "Fold: 25  Epoch: 266  Training loss = 3.3663  Validation loss = 1.8540  \n",
      "\n",
      "Fold: 25  Epoch: 267  Training loss = 3.3661  Validation loss = 1.8535  \n",
      "\n",
      "Fold: 25  Epoch: 268  Training loss = 3.3658  Validation loss = 1.8530  \n",
      "\n",
      "Fold: 25  Epoch: 269  Training loss = 3.3656  Validation loss = 1.8528  \n",
      "\n",
      "Fold: 25  Epoch: 270  Training loss = 3.3654  Validation loss = 1.8525  \n",
      "\n",
      "Fold: 25  Epoch: 271  Training loss = 3.3652  Validation loss = 1.8522  \n",
      "\n",
      "Fold: 25  Epoch: 272  Training loss = 3.3651  Validation loss = 1.8522  \n",
      "\n",
      "Fold: 25  Epoch: 273  Training loss = 3.3649  Validation loss = 1.8520  \n",
      "\n",
      "Fold: 25  Epoch: 274  Training loss = 3.3646  Validation loss = 1.8515  \n",
      "\n",
      "Fold: 25  Epoch: 275  Training loss = 3.3644  Validation loss = 1.8511  \n",
      "\n",
      "Fold: 25  Epoch: 276  Training loss = 3.3641  Validation loss = 1.8506  \n",
      "\n",
      "Fold: 25  Epoch: 277  Training loss = 3.3638  Validation loss = 1.8500  \n",
      "\n",
      "Fold: 25  Epoch: 278  Training loss = 3.3635  Validation loss = 1.8494  \n",
      "\n",
      "Fold: 25  Epoch: 279  Training loss = 3.3633  Validation loss = 1.8490  \n",
      "\n",
      "Fold: 25  Epoch: 280  Training loss = 3.3630  Validation loss = 1.8486  \n",
      "\n",
      "Fold: 25  Epoch: 281  Training loss = 3.3629  Validation loss = 1.8485  \n",
      "\n",
      "Fold: 25  Epoch: 282  Training loss = 3.3626  Validation loss = 1.8478  \n",
      "\n",
      "Fold: 25  Epoch: 283  Training loss = 3.3625  Validation loss = 1.8477  \n",
      "\n",
      "Fold: 25  Epoch: 284  Training loss = 3.3624  Validation loss = 1.8478  \n",
      "\n",
      "Fold: 25  Epoch: 285  Training loss = 3.3621  Validation loss = 1.8473  \n",
      "\n",
      "Fold: 25  Epoch: 286  Training loss = 3.3620  Validation loss = 1.8472  \n",
      "\n",
      "Fold: 25  Epoch: 287  Training loss = 3.3617  Validation loss = 1.8466  \n",
      "\n",
      "Fold: 25  Epoch: 288  Training loss = 3.3614  Validation loss = 1.8462  \n",
      "\n",
      "Fold: 25  Epoch: 289  Training loss = 3.3611  Validation loss = 1.8455  \n",
      "\n",
      "Fold: 25  Epoch: 290  Training loss = 3.3609  Validation loss = 1.8452  \n",
      "\n",
      "Fold: 25  Epoch: 291  Training loss = 3.3606  Validation loss = 1.8449  \n",
      "\n",
      "Fold: 25  Epoch: 292  Training loss = 3.3605  Validation loss = 1.8450  \n",
      "\n",
      "Fold: 25  Epoch: 293  Training loss = 3.3603  Validation loss = 1.8446  \n",
      "\n",
      "Fold: 25  Epoch: 294  Training loss = 3.3600  Validation loss = 1.8441  \n",
      "\n",
      "Fold: 25  Epoch: 295  Training loss = 3.3599  Validation loss = 1.8439  \n",
      "\n",
      "Fold: 25  Epoch: 296  Training loss = 3.3596  Validation loss = 1.8436  \n",
      "\n",
      "Fold: 25  Epoch: 297  Training loss = 3.3593  Validation loss = 1.8431  \n",
      "\n",
      "Fold: 25  Epoch: 298  Training loss = 3.3590  Validation loss = 1.8425  \n",
      "\n",
      "Fold: 25  Epoch: 299  Training loss = 3.3587  Validation loss = 1.8420  \n",
      "\n",
      "Fold: 25  Epoch: 300  Training loss = 3.3585  Validation loss = 1.8416  \n",
      "\n",
      "Fold: 25  Epoch: 301  Training loss = 3.3583  Validation loss = 1.8413  \n",
      "\n",
      "Fold: 25  Epoch: 302  Training loss = 3.3581  Validation loss = 1.8410  \n",
      "\n",
      "Fold: 25  Epoch: 303  Training loss = 3.3577  Validation loss = 1.8405  \n",
      "\n",
      "Fold: 25  Epoch: 304  Training loss = 3.3575  Validation loss = 1.8400  \n",
      "\n",
      "Fold: 25  Epoch: 305  Training loss = 3.3572  Validation loss = 1.8394  \n",
      "\n",
      "Fold: 25  Epoch: 306  Training loss = 3.3570  Validation loss = 1.8391  \n",
      "\n",
      "Fold: 25  Epoch: 307  Training loss = 3.3567  Validation loss = 1.8387  \n",
      "\n",
      "Fold: 25  Epoch: 308  Training loss = 3.3565  Validation loss = 1.8383  \n",
      "\n",
      "Fold: 25  Epoch: 309  Training loss = 3.3562  Validation loss = 1.8380  \n",
      "\n",
      "Fold: 25  Epoch: 310  Training loss = 3.3561  Validation loss = 1.8378  \n",
      "\n",
      "Fold: 25  Epoch: 311  Training loss = 3.3560  Validation loss = 1.8376  \n",
      "\n",
      "Fold: 25  Epoch: 312  Training loss = 3.3558  Validation loss = 1.8374  \n",
      "\n",
      "Fold: 25  Epoch: 313  Training loss = 3.3556  Validation loss = 1.8370  \n",
      "\n",
      "Fold: 25  Epoch: 314  Training loss = 3.3554  Validation loss = 1.8366  \n",
      "\n",
      "Fold: 25  Epoch: 315  Training loss = 3.3552  Validation loss = 1.8361  \n",
      "\n",
      "Fold: 25  Epoch: 316  Training loss = 3.3550  Validation loss = 1.8360  \n",
      "\n",
      "Fold: 25  Epoch: 317  Training loss = 3.3548  Validation loss = 1.8355  \n",
      "\n",
      "Fold: 25  Epoch: 318  Training loss = 3.3547  Validation loss = 1.8353  \n",
      "\n",
      "Fold: 25  Epoch: 319  Training loss = 3.3545  Validation loss = 1.8349  \n",
      "\n",
      "Fold: 25  Epoch: 320  Training loss = 3.3543  Validation loss = 1.8346  \n",
      "\n",
      "Fold: 25  Epoch: 321  Training loss = 3.3542  Validation loss = 1.8343  \n",
      "\n",
      "Fold: 25  Epoch: 322  Training loss = 3.3541  Validation loss = 1.8343  \n",
      "\n",
      "Fold: 25  Epoch: 323  Training loss = 3.3539  Validation loss = 1.8339  \n",
      "\n",
      "Fold: 25  Epoch: 324  Training loss = 3.3536  Validation loss = 1.8335  \n",
      "\n",
      "Fold: 25  Epoch: 325  Training loss = 3.3535  Validation loss = 1.8333  \n",
      "\n",
      "Fold: 25  Epoch: 326  Training loss = 3.3534  Validation loss = 1.8331  \n",
      "\n",
      "Fold: 25  Epoch: 327  Training loss = 3.3531  Validation loss = 1.8327  \n",
      "\n",
      "Fold: 25  Epoch: 328  Training loss = 3.3530  Validation loss = 1.8325  \n",
      "\n",
      "Fold: 25  Epoch: 329  Training loss = 3.3528  Validation loss = 1.8320  \n",
      "\n",
      "Fold: 25  Epoch: 330  Training loss = 3.3525  Validation loss = 1.8316  \n",
      "\n",
      "Fold: 25  Epoch: 331  Training loss = 3.3524  Validation loss = 1.8314  \n",
      "\n",
      "Fold: 25  Epoch: 332  Training loss = 3.3522  Validation loss = 1.8311  \n",
      "\n",
      "Fold: 25  Epoch: 333  Training loss = 3.3521  Validation loss = 1.8311  \n",
      "\n",
      "Fold: 25  Epoch: 334  Training loss = 3.3519  Validation loss = 1.8305  \n",
      "\n",
      "Fold: 25  Epoch: 335  Training loss = 3.3518  Validation loss = 1.8305  \n",
      "\n",
      "Fold: 25  Epoch: 336  Training loss = 3.3516  Validation loss = 1.8302  \n",
      "\n",
      "Fold: 25  Epoch: 337  Training loss = 3.3515  Validation loss = 1.8300  \n",
      "\n",
      "Fold: 25  Epoch: 338  Training loss = 3.3515  Validation loss = 1.8300  \n",
      "\n",
      "Fold: 25  Epoch: 339  Training loss = 3.3512  Validation loss = 1.8297  \n",
      "\n",
      "Fold: 25  Epoch: 340  Training loss = 3.3509  Validation loss = 1.8293  \n",
      "\n",
      "Fold: 25  Epoch: 341  Training loss = 3.3509  Validation loss = 1.8292  \n",
      "\n",
      "Fold: 25  Epoch: 342  Training loss = 3.3506  Validation loss = 1.8288  \n",
      "\n",
      "Fold: 25  Epoch: 343  Training loss = 3.3506  Validation loss = 1.8287  \n",
      "\n",
      "Fold: 25  Epoch: 344  Training loss = 3.3505  Validation loss = 1.8286  \n",
      "\n",
      "Fold: 25  Epoch: 345  Training loss = 3.3504  Validation loss = 1.8284  \n",
      "\n",
      "Fold: 25  Epoch: 346  Training loss = 3.3502  Validation loss = 1.8280  \n",
      "\n",
      "Fold: 25  Epoch: 347  Training loss = 3.3500  Validation loss = 1.8275  \n",
      "\n",
      "Fold: 25  Epoch: 348  Training loss = 3.3498  Validation loss = 1.8272  \n",
      "\n",
      "Fold: 25  Epoch: 349  Training loss = 3.3494  Validation loss = 1.8263  \n",
      "\n",
      "Fold: 25  Epoch: 350  Training loss = 3.3493  Validation loss = 1.8259  \n",
      "\n",
      "Fold: 25  Epoch: 351  Training loss = 3.3489  Validation loss = 1.8252  \n",
      "\n",
      "Fold: 25  Epoch: 352  Training loss = 3.3488  Validation loss = 1.8250  \n",
      "\n",
      "Fold: 25  Epoch: 353  Training loss = 3.3487  Validation loss = 1.8251  \n",
      "\n",
      "Fold: 25  Epoch: 354  Training loss = 3.3485  Validation loss = 1.8247  \n",
      "\n",
      "Fold: 25  Epoch: 355  Training loss = 3.3483  Validation loss = 1.8245  \n",
      "\n",
      "Fold: 25  Epoch: 356  Training loss = 3.3480  Validation loss = 1.8239  \n",
      "\n",
      "Fold: 25  Epoch: 357  Training loss = 3.3478  Validation loss = 1.8232  \n",
      "\n",
      "Fold: 25  Epoch: 358  Training loss = 3.3476  Validation loss = 1.8228  \n",
      "\n",
      "Fold: 25  Epoch: 359  Training loss = 3.3475  Validation loss = 1.8226  \n",
      "\n",
      "Fold: 25  Epoch: 360  Training loss = 3.3473  Validation loss = 1.8221  \n",
      "\n",
      "Fold: 25  Epoch: 361  Training loss = 3.3471  Validation loss = 1.8219  \n",
      "\n",
      "Fold: 25  Epoch: 362  Training loss = 3.3470  Validation loss = 1.8216  \n",
      "\n",
      "Fold: 25  Epoch: 363  Training loss = 3.3468  Validation loss = 1.8214  \n",
      "\n",
      "Fold: 25  Epoch: 364  Training loss = 3.3466  Validation loss = 1.8208  \n",
      "\n",
      "Fold: 25  Epoch: 365  Training loss = 3.3464  Validation loss = 1.8207  \n",
      "\n",
      "Fold: 25  Epoch: 366  Training loss = 3.3462  Validation loss = 1.8201  \n",
      "\n",
      "Fold: 25  Epoch: 367  Training loss = 3.3460  Validation loss = 1.8198  \n",
      "\n",
      "Fold: 25  Epoch: 368  Training loss = 3.3458  Validation loss = 1.8194  \n",
      "\n",
      "Fold: 25  Epoch: 369  Training loss = 3.3456  Validation loss = 1.8192  \n",
      "\n",
      "Fold: 25  Epoch: 370  Training loss = 3.3455  Validation loss = 1.8191  \n",
      "\n",
      "Fold: 25  Epoch: 371  Training loss = 3.3454  Validation loss = 1.8189  \n",
      "\n",
      "Fold: 25  Epoch: 372  Training loss = 3.3451  Validation loss = 1.8185  \n",
      "\n",
      "Fold: 25  Epoch: 373  Training loss = 3.3450  Validation loss = 1.8183  \n",
      "\n",
      "Fold: 25  Epoch: 374  Training loss = 3.3449  Validation loss = 1.8182  \n",
      "\n",
      "Fold: 25  Epoch: 375  Training loss = 3.3449  Validation loss = 1.8182  \n",
      "\n",
      "Fold: 25  Epoch: 376  Training loss = 3.3447  Validation loss = 1.8180  \n",
      "\n",
      "Fold: 25  Epoch: 377  Training loss = 3.3444  Validation loss = 1.8176  \n",
      "\n",
      "Fold: 25  Epoch: 378  Training loss = 3.3443  Validation loss = 1.8173  \n",
      "\n",
      "Fold: 25  Epoch: 379  Training loss = 3.3440  Validation loss = 1.8168  \n",
      "\n",
      "Fold: 25  Epoch: 380  Training loss = 3.3438  Validation loss = 1.8165  \n",
      "\n",
      "Fold: 25  Epoch: 381  Training loss = 3.3437  Validation loss = 1.8163  \n",
      "\n",
      "Fold: 25  Epoch: 382  Training loss = 3.3436  Validation loss = 1.8162  \n",
      "\n",
      "Fold: 25  Epoch: 383  Training loss = 3.3434  Validation loss = 1.8158  \n",
      "\n",
      "Fold: 25  Epoch: 384  Training loss = 3.3431  Validation loss = 1.8153  \n",
      "\n",
      "Fold: 25  Epoch: 385  Training loss = 3.3429  Validation loss = 1.8149  \n",
      "\n",
      "Fold: 25  Epoch: 386  Training loss = 3.3427  Validation loss = 1.8145  \n",
      "\n",
      "Fold: 25  Epoch: 387  Training loss = 3.3426  Validation loss = 1.8143  \n",
      "\n",
      "Fold: 25  Epoch: 388  Training loss = 3.3423  Validation loss = 1.8138  \n",
      "\n",
      "Fold: 25  Epoch: 389  Training loss = 3.3421  Validation loss = 1.8135  \n",
      "\n",
      "Fold: 25  Epoch: 390  Training loss = 3.3419  Validation loss = 1.8130  \n",
      "\n",
      "Fold: 25  Epoch: 391  Training loss = 3.3417  Validation loss = 1.8127  \n",
      "\n",
      "Fold: 25  Epoch: 392  Training loss = 3.3415  Validation loss = 1.8122  \n",
      "\n",
      "Fold: 25  Epoch: 393  Training loss = 3.3413  Validation loss = 1.8119  \n",
      "\n",
      "Fold: 25  Epoch: 394  Training loss = 3.3411  Validation loss = 1.8114  \n",
      "\n",
      "Fold: 25  Epoch: 395  Training loss = 3.3409  Validation loss = 1.8111  \n",
      "\n",
      "Fold: 25  Epoch: 396  Training loss = 3.3408  Validation loss = 1.8109  \n",
      "\n",
      "Fold: 25  Epoch: 397  Training loss = 3.3405  Validation loss = 1.8106  \n",
      "\n",
      "Fold: 25  Epoch: 398  Training loss = 3.3403  Validation loss = 1.8099  \n",
      "\n",
      "Fold: 25  Epoch: 399  Training loss = 3.3401  Validation loss = 1.8095  \n",
      "\n",
      "Fold: 25  Epoch: 400  Training loss = 3.3399  Validation loss = 1.8091  \n",
      "\n",
      "Fold: 25  Epoch: 401  Training loss = 3.3397  Validation loss = 1.8087  \n",
      "\n",
      "Fold: 25  Epoch: 402  Training loss = 3.3394  Validation loss = 1.8081  \n",
      "\n",
      "Fold: 25  Epoch: 403  Training loss = 3.3393  Validation loss = 1.8079  \n",
      "\n",
      "Fold: 25  Epoch: 404  Training loss = 3.3391  Validation loss = 1.8076  \n",
      "\n",
      "Fold: 25  Epoch: 405  Training loss = 3.3389  Validation loss = 1.8072  \n",
      "\n",
      "Fold: 25  Epoch: 406  Training loss = 3.3387  Validation loss = 1.8068  \n",
      "\n",
      "Fold: 25  Epoch: 407  Training loss = 3.3383  Validation loss = 1.8061  \n",
      "\n",
      "Fold: 25  Epoch: 408  Training loss = 3.3383  Validation loss = 1.8062  \n",
      "\n",
      "Fold: 25  Epoch: 409  Training loss = 3.3382  Validation loss = 1.8061  \n",
      "\n",
      "Fold: 25  Epoch: 410  Training loss = 3.3378  Validation loss = 1.8052  \n",
      "\n",
      "Fold: 25  Epoch: 411  Training loss = 3.3376  Validation loss = 1.8049  \n",
      "\n",
      "Fold: 25  Epoch: 412  Training loss = 3.3374  Validation loss = 1.8045  \n",
      "\n",
      "Fold: 25  Epoch: 413  Training loss = 3.3372  Validation loss = 1.8040  \n",
      "\n",
      "Fold: 25  Epoch: 414  Training loss = 3.3371  Validation loss = 1.8039  \n",
      "\n",
      "Fold: 25  Epoch: 415  Training loss = 3.3370  Validation loss = 1.8036  \n",
      "\n",
      "Fold: 25  Epoch: 416  Training loss = 3.3368  Validation loss = 1.8033  \n",
      "\n",
      "Fold: 25  Epoch: 417  Training loss = 3.3367  Validation loss = 1.8032  \n",
      "\n",
      "Fold: 25  Epoch: 418  Training loss = 3.3367  Validation loss = 1.8035  \n",
      "\n",
      "Fold: 25  Epoch: 419  Training loss = 3.3365  Validation loss = 1.8031  \n",
      "\n",
      "Fold: 25  Epoch: 420  Training loss = 3.3364  Validation loss = 1.8030  \n",
      "\n",
      "Fold: 25  Epoch: 421  Training loss = 3.3363  Validation loss = 1.8030  \n",
      "\n",
      "Fold: 25  Epoch: 422  Training loss = 3.3362  Validation loss = 1.8031  \n",
      "\n",
      "Fold: 25  Epoch: 423  Training loss = 3.3359  Validation loss = 1.8026  \n",
      "\n",
      "Fold: 25  Epoch: 424  Training loss = 3.3358  Validation loss = 1.8024  \n",
      "\n",
      "Fold: 25  Epoch: 425  Training loss = 3.3356  Validation loss = 1.8019  \n",
      "\n",
      "Fold: 25  Epoch: 426  Training loss = 3.3354  Validation loss = 1.8016  \n",
      "\n",
      "Fold: 25  Epoch: 427  Training loss = 3.3352  Validation loss = 1.8012  \n",
      "\n",
      "Fold: 25  Epoch: 428  Training loss = 3.3351  Validation loss = 1.8011  \n",
      "\n",
      "Fold: 25  Epoch: 429  Training loss = 3.3348  Validation loss = 1.8005  \n",
      "\n",
      "Fold: 25  Epoch: 430  Training loss = 3.3346  Validation loss = 1.7999  \n",
      "\n",
      "Fold: 25  Epoch: 431  Training loss = 3.3345  Validation loss = 1.7996  \n",
      "\n",
      "Fold: 25  Epoch: 432  Training loss = 3.3341  Validation loss = 1.7988  \n",
      "\n",
      "Fold: 25  Epoch: 433  Training loss = 3.3339  Validation loss = 1.7984  \n",
      "\n",
      "Fold: 25  Epoch: 434  Training loss = 3.3338  Validation loss = 1.7984  \n",
      "\n",
      "Fold: 25  Epoch: 435  Training loss = 3.3335  Validation loss = 1.7977  \n",
      "\n",
      "Fold: 25  Epoch: 436  Training loss = 3.3334  Validation loss = 1.7974  \n",
      "\n",
      "Fold: 25  Epoch: 437  Training loss = 3.3333  Validation loss = 1.7973  \n",
      "\n",
      "Fold: 25  Epoch: 438  Training loss = 3.3332  Validation loss = 1.7972  \n",
      "\n",
      "Fold: 25  Epoch: 439  Training loss = 3.3331  Validation loss = 1.7972  \n",
      "\n",
      "Fold: 25  Epoch: 440  Training loss = 3.3328  Validation loss = 1.7969  \n",
      "\n",
      "Fold: 25  Epoch: 441  Training loss = 3.3326  Validation loss = 1.7966  \n",
      "\n",
      "Fold: 25  Epoch: 442  Training loss = 3.3325  Validation loss = 1.7963  \n",
      "\n",
      "Fold: 25  Epoch: 443  Training loss = 3.3323  Validation loss = 1.7958  \n",
      "\n",
      "Fold: 25  Epoch: 444  Training loss = 3.3320  Validation loss = 1.7954  \n",
      "\n",
      "Fold: 25  Epoch: 445  Training loss = 3.3318  Validation loss = 1.7950  \n",
      "\n",
      "Fold: 25  Epoch: 446  Training loss = 3.3316  Validation loss = 1.7946  \n",
      "\n",
      "Fold: 25  Epoch: 447  Training loss = 3.3315  Validation loss = 1.7945  \n",
      "\n",
      "Fold: 25  Epoch: 448  Training loss = 3.3313  Validation loss = 1.7943  \n",
      "\n",
      "Fold: 25  Epoch: 449  Training loss = 3.3312  Validation loss = 1.7939  \n",
      "\n",
      "Fold: 25  Epoch: 450  Training loss = 3.3309  Validation loss = 1.7936  \n",
      "\n",
      "Fold: 25  Epoch: 451  Training loss = 3.3308  Validation loss = 1.7934  \n",
      "\n",
      "Fold: 25  Epoch: 452  Training loss = 3.3308  Validation loss = 1.7934  \n",
      "\n",
      "Fold: 25  Epoch: 453  Training loss = 3.3305  Validation loss = 1.7929  \n",
      "\n",
      "Fold: 25  Epoch: 454  Training loss = 3.3303  Validation loss = 1.7925  \n",
      "\n",
      "Fold: 25  Epoch: 455  Training loss = 3.3301  Validation loss = 1.7920  \n",
      "\n",
      "Fold: 25  Epoch: 456  Training loss = 3.3298  Validation loss = 1.7913  \n",
      "\n",
      "Fold: 25  Epoch: 457  Training loss = 3.3296  Validation loss = 1.7910  \n",
      "\n",
      "Fold: 25  Epoch: 458  Training loss = 3.3294  Validation loss = 1.7907  \n",
      "\n",
      "Fold: 25  Epoch: 459  Training loss = 3.3294  Validation loss = 1.7908  \n",
      "\n",
      "Fold: 25  Epoch: 460  Training loss = 3.3293  Validation loss = 1.7908  \n",
      "\n",
      "Fold: 25  Epoch: 461  Training loss = 3.3292  Validation loss = 1.7907  \n",
      "\n",
      "Fold: 25  Epoch: 462  Training loss = 3.3291  Validation loss = 1.7906  \n",
      "\n",
      "Fold: 25  Epoch: 463  Training loss = 3.3289  Validation loss = 1.7903  \n",
      "\n",
      "Fold: 25  Epoch: 464  Training loss = 3.3288  Validation loss = 1.7899  \n",
      "\n",
      "Fold: 25  Epoch: 465  Training loss = 3.3286  Validation loss = 1.7897  \n",
      "\n",
      "Fold: 25  Epoch: 466  Training loss = 3.3284  Validation loss = 1.7893  \n",
      "\n",
      "Fold: 25  Epoch: 467  Training loss = 3.3282  Validation loss = 1.7889  \n",
      "\n",
      "Fold: 25  Epoch: 468  Training loss = 3.3281  Validation loss = 1.7887  \n",
      "\n",
      "Fold: 25  Epoch: 469  Training loss = 3.3279  Validation loss = 1.7883  \n",
      "\n",
      "Fold: 25  Epoch: 470  Training loss = 3.3278  Validation loss = 1.7880  \n",
      "\n",
      "Fold: 25  Epoch: 471  Training loss = 3.3276  Validation loss = 1.7877  \n",
      "\n",
      "Fold: 25  Epoch: 472  Training loss = 3.3275  Validation loss = 1.7876  \n",
      "\n",
      "Fold: 25  Epoch: 473  Training loss = 3.3273  Validation loss = 1.7875  \n",
      "\n",
      "Fold: 25  Epoch: 474  Training loss = 3.3271  Validation loss = 1.7872  \n",
      "\n",
      "Fold: 25  Epoch: 475  Training loss = 3.3270  Validation loss = 1.7869  \n",
      "\n",
      "Fold: 25  Epoch: 476  Training loss = 3.3268  Validation loss = 1.7866  \n",
      "\n",
      "Fold: 25  Epoch: 477  Training loss = 3.3268  Validation loss = 1.7868  \n",
      "\n",
      "Fold: 25  Epoch: 478  Training loss = 3.3266  Validation loss = 1.7865  \n",
      "\n",
      "Fold: 25  Epoch: 479  Training loss = 3.3265  Validation loss = 1.7863  \n",
      "\n",
      "Fold: 25  Epoch: 480  Training loss = 3.3265  Validation loss = 1.7865  \n",
      "\n",
      "Fold: 25  Epoch: 481  Training loss = 3.3263  Validation loss = 1.7862  \n",
      "\n",
      "Fold: 25  Epoch: 482  Training loss = 3.3261  Validation loss = 1.7856  \n",
      "\n",
      "Fold: 25  Epoch: 483  Training loss = 3.3259  Validation loss = 1.7854  \n",
      "\n",
      "Fold: 25  Epoch: 484  Training loss = 3.3258  Validation loss = 1.7851  \n",
      "\n",
      "Fold: 25  Epoch: 485  Training loss = 3.3256  Validation loss = 1.7846  \n",
      "\n",
      "Fold: 25  Epoch: 486  Training loss = 3.3254  Validation loss = 1.7845  \n",
      "\n",
      "Fold: 25  Epoch: 487  Training loss = 3.3252  Validation loss = 1.7841  \n",
      "\n",
      "Fold: 25  Epoch: 488  Training loss = 3.3251  Validation loss = 1.7842  \n",
      "\n",
      "Fold: 25  Epoch: 489  Training loss = 3.3249  Validation loss = 1.7837  \n",
      "\n",
      "Fold: 25  Epoch: 490  Training loss = 3.3247  Validation loss = 1.7833  \n",
      "\n",
      "Fold: 25  Epoch: 491  Training loss = 3.3244  Validation loss = 1.7828  \n",
      "\n",
      "Fold: 25  Epoch: 492  Training loss = 3.3243  Validation loss = 1.7826  \n",
      "\n",
      "Fold: 25  Epoch: 493  Training loss = 3.3241  Validation loss = 1.7823  \n",
      "\n",
      "Fold: 25  Epoch: 494  Training loss = 3.3240  Validation loss = 1.7820  \n",
      "\n",
      "Fold: 25  Epoch: 495  Training loss = 3.3238  Validation loss = 1.7816  \n",
      "\n",
      "Fold: 25  Epoch: 496  Training loss = 3.3237  Validation loss = 1.7813  \n",
      "\n",
      "Fold: 25  Epoch: 497  Training loss = 3.3234  Validation loss = 1.7807  \n",
      "\n",
      "Fold: 25  Epoch: 498  Training loss = 3.3234  Validation loss = 1.7808  \n",
      "\n",
      "Fold: 25  Epoch: 499  Training loss = 3.3233  Validation loss = 1.7804  \n",
      "\n",
      "Fold: 25  Epoch: 500  Training loss = 3.3231  Validation loss = 1.7802  \n",
      "\n",
      "Check model:  Fold: 25  Optimal epoch: 500  \n",
      "\n",
      "Fold: 26  Epoch: 1  Training loss = 3.0517  Validation loss = 2.8884  \n",
      "\n",
      "Fold: 26  Epoch: 2  Training loss = 3.0515  Validation loss = 2.8893  \n",
      "\n",
      "Fold: 26  Epoch: 3  Training loss = 3.0514  Validation loss = 2.8892  \n",
      "\n",
      "Fold: 26  Epoch: 4  Training loss = 3.0513  Validation loss = 2.8900  \n",
      "\n",
      "Fold: 26  Epoch: 5  Training loss = 3.0512  Validation loss = 2.8900  \n",
      "\n",
      "Fold: 26  Epoch: 6  Training loss = 3.0511  Validation loss = 2.8908  \n",
      "\n",
      "Fold: 26  Epoch: 7  Training loss = 3.0509  Validation loss = 2.8918  \n",
      "\n",
      "Fold: 26  Epoch: 8  Training loss = 3.0507  Validation loss = 2.8922  \n",
      "\n",
      "Fold: 26  Epoch: 9  Training loss = 3.0506  Validation loss = 2.8927  \n",
      "\n",
      "Fold: 26  Epoch: 10  Training loss = 3.0505  Validation loss = 2.8930  \n",
      "\n",
      "Fold: 26  Epoch: 11  Training loss = 3.0503  Validation loss = 2.8933  \n",
      "\n",
      "Fold: 26  Epoch: 12  Training loss = 3.0503  Validation loss = 2.8931  \n",
      "\n",
      "Fold: 26  Epoch: 13  Training loss = 3.0502  Validation loss = 2.8937  \n",
      "\n",
      "Fold: 26  Epoch: 14  Training loss = 3.0501  Validation loss = 2.8939  \n",
      "\n",
      "Fold: 26  Epoch: 15  Training loss = 3.0500  Validation loss = 2.8938  \n",
      "\n",
      "Fold: 26  Epoch: 16  Training loss = 3.0498  Validation loss = 2.8948  \n",
      "\n",
      "Check model:  Fold: 26  Optimal epoch: 1  \n",
      "\n",
      "Fold: 27  Epoch: 1  Training loss = 3.0086  Validation loss = 2.3492  \n",
      "\n",
      "Fold: 27  Epoch: 2  Training loss = 3.0085  Validation loss = 2.3494  \n",
      "\n",
      "Fold: 27  Epoch: 3  Training loss = 3.0084  Validation loss = 2.3495  \n",
      "\n",
      "Fold: 27  Epoch: 4  Training loss = 3.0084  Validation loss = 2.3499  \n",
      "\n",
      "Fold: 27  Epoch: 5  Training loss = 3.0083  Validation loss = 2.3500  \n",
      "\n",
      "Fold: 27  Epoch: 6  Training loss = 3.0082  Validation loss = 2.3504  \n",
      "\n",
      "Fold: 27  Epoch: 7  Training loss = 3.0081  Validation loss = 2.3502  \n",
      "\n",
      "Fold: 27  Epoch: 8  Training loss = 3.0081  Validation loss = 2.3502  \n",
      "\n",
      "Fold: 27  Epoch: 9  Training loss = 3.0080  Validation loss = 2.3503  \n",
      "\n",
      "Fold: 27  Epoch: 10  Training loss = 3.0079  Validation loss = 2.3499  \n",
      "\n",
      "Fold: 27  Epoch: 11  Training loss = 3.0078  Validation loss = 2.3505  \n",
      "\n",
      "Fold: 27  Epoch: 12  Training loss = 3.0077  Validation loss = 2.3508  \n",
      "\n",
      "Fold: 27  Epoch: 13  Training loss = 3.0077  Validation loss = 2.3503  \n",
      "\n",
      "Fold: 27  Epoch: 14  Training loss = 3.0076  Validation loss = 2.3504  \n",
      "\n",
      "Fold: 27  Epoch: 15  Training loss = 3.0076  Validation loss = 2.3505  \n",
      "\n",
      "Fold: 27  Epoch: 16  Training loss = 3.0074  Validation loss = 2.3503  \n",
      "\n",
      "Fold: 27  Epoch: 17  Training loss = 3.0073  Validation loss = 2.3507  \n",
      "\n",
      "Fold: 27  Epoch: 18  Training loss = 3.0073  Validation loss = 2.3504  \n",
      "\n",
      "Fold: 27  Epoch: 19  Training loss = 3.0072  Validation loss = 2.3499  \n",
      "\n",
      "Fold: 27  Epoch: 20  Training loss = 3.0071  Validation loss = 2.3494  \n",
      "\n",
      "Fold: 27  Epoch: 21  Training loss = 3.0071  Validation loss = 2.3488  \n",
      "\n",
      "Fold: 27  Epoch: 22  Training loss = 3.0070  Validation loss = 2.3488  \n",
      "\n",
      "Fold: 27  Epoch: 23  Training loss = 3.0069  Validation loss = 2.3490  \n",
      "\n",
      "Fold: 27  Epoch: 24  Training loss = 3.0069  Validation loss = 2.3488  \n",
      "\n",
      "Fold: 27  Epoch: 25  Training loss = 3.0068  Validation loss = 2.3490  \n",
      "\n",
      "Fold: 27  Epoch: 26  Training loss = 3.0067  Validation loss = 2.3493  \n",
      "\n",
      "Fold: 27  Epoch: 27  Training loss = 3.0066  Validation loss = 2.3489  \n",
      "\n",
      "Fold: 27  Epoch: 28  Training loss = 3.0065  Validation loss = 2.3481  \n",
      "\n",
      "Fold: 27  Epoch: 29  Training loss = 3.0065  Validation loss = 2.3481  \n",
      "\n",
      "Fold: 27  Epoch: 30  Training loss = 3.0064  Validation loss = 2.3474  \n",
      "\n",
      "Fold: 27  Epoch: 31  Training loss = 3.0063  Validation loss = 2.3470  \n",
      "\n",
      "Fold: 27  Epoch: 32  Training loss = 3.0062  Validation loss = 2.3468  \n",
      "\n",
      "Fold: 27  Epoch: 33  Training loss = 3.0062  Validation loss = 2.3461  \n",
      "\n",
      "Fold: 27  Epoch: 34  Training loss = 3.0061  Validation loss = 2.3450  \n",
      "\n",
      "Fold: 27  Epoch: 35  Training loss = 3.0061  Validation loss = 2.3454  \n",
      "\n",
      "Fold: 27  Epoch: 36  Training loss = 3.0060  Validation loss = 2.3455  \n",
      "\n",
      "Fold: 27  Epoch: 37  Training loss = 3.0059  Validation loss = 2.3446  \n",
      "\n",
      "Fold: 27  Epoch: 38  Training loss = 3.0058  Validation loss = 2.3442  \n",
      "\n",
      "Fold: 27  Epoch: 39  Training loss = 3.0057  Validation loss = 2.3438  \n",
      "\n",
      "Fold: 27  Epoch: 40  Training loss = 3.0057  Validation loss = 2.3438  \n",
      "\n",
      "Fold: 27  Epoch: 41  Training loss = 3.0056  Validation loss = 2.3436  \n",
      "\n",
      "Fold: 27  Epoch: 42  Training loss = 3.0055  Validation loss = 2.3436  \n",
      "\n",
      "Fold: 27  Epoch: 43  Training loss = 3.0054  Validation loss = 2.3434  \n",
      "\n",
      "Fold: 27  Epoch: 44  Training loss = 3.0053  Validation loss = 2.3436  \n",
      "\n",
      "Fold: 27  Epoch: 45  Training loss = 3.0053  Validation loss = 2.3432  \n",
      "\n",
      "Fold: 27  Epoch: 46  Training loss = 3.0052  Validation loss = 2.3428  \n",
      "\n",
      "Fold: 27  Epoch: 47  Training loss = 3.0051  Validation loss = 2.3424  \n",
      "\n",
      "Fold: 27  Epoch: 48  Training loss = 3.0051  Validation loss = 2.3421  \n",
      "\n",
      "Fold: 27  Epoch: 49  Training loss = 3.0050  Validation loss = 2.3420  \n",
      "\n",
      "Fold: 27  Epoch: 50  Training loss = 3.0049  Validation loss = 2.3419  \n",
      "\n",
      "Fold: 27  Epoch: 51  Training loss = 3.0049  Validation loss = 2.3426  \n",
      "\n",
      "Fold: 27  Epoch: 52  Training loss = 3.0048  Validation loss = 2.3432  \n",
      "\n",
      "Fold: 27  Epoch: 53  Training loss = 3.0047  Validation loss = 2.3437  \n",
      "\n",
      "Fold: 27  Epoch: 54  Training loss = 3.0047  Validation loss = 2.3436  \n",
      "\n",
      "Fold: 27  Epoch: 55  Training loss = 3.0046  Validation loss = 2.3441  \n",
      "\n",
      "Check model:  Fold: 27  Optimal epoch: 50  \n",
      "\n",
      "Fold: 28  Epoch: 1  Training loss = 3.0093  Validation loss = 2.2783  \n",
      "\n",
      "Fold: 28  Epoch: 2  Training loss = 3.0091  Validation loss = 2.2786  \n",
      "\n",
      "Fold: 28  Epoch: 3  Training loss = 3.0089  Validation loss = 2.2785  \n",
      "\n",
      "Fold: 28  Epoch: 4  Training loss = 3.0088  Validation loss = 2.2784  \n",
      "\n",
      "Fold: 28  Epoch: 5  Training loss = 3.0085  Validation loss = 2.2781  \n",
      "\n",
      "Fold: 28  Epoch: 6  Training loss = 3.0085  Validation loss = 2.2784  \n",
      "\n",
      "Fold: 28  Epoch: 7  Training loss = 3.0084  Validation loss = 2.2784  \n",
      "\n",
      "Fold: 28  Epoch: 8  Training loss = 3.0081  Validation loss = 2.2780  \n",
      "\n",
      "Fold: 28  Epoch: 9  Training loss = 3.0080  Validation loss = 2.2776  \n",
      "\n",
      "Fold: 28  Epoch: 10  Training loss = 3.0078  Validation loss = 2.2774  \n",
      "\n",
      "Fold: 28  Epoch: 11  Training loss = 3.0075  Validation loss = 2.2776  \n",
      "\n",
      "Fold: 28  Epoch: 12  Training loss = 3.0074  Validation loss = 2.2775  \n",
      "\n",
      "Fold: 28  Epoch: 13  Training loss = 3.0072  Validation loss = 2.2773  \n",
      "\n",
      "Fold: 28  Epoch: 14  Training loss = 3.0070  Validation loss = 2.2773  \n",
      "\n",
      "Fold: 28  Epoch: 15  Training loss = 3.0069  Validation loss = 2.2774  \n",
      "\n",
      "Fold: 28  Epoch: 16  Training loss = 3.0067  Validation loss = 2.2771  \n",
      "\n",
      "Fold: 28  Epoch: 17  Training loss = 3.0064  Validation loss = 2.2770  \n",
      "\n",
      "Fold: 28  Epoch: 18  Training loss = 3.0062  Validation loss = 2.2768  \n",
      "\n",
      "Fold: 28  Epoch: 19  Training loss = 3.0061  Validation loss = 2.2766  \n",
      "\n",
      "Fold: 28  Epoch: 20  Training loss = 3.0059  Validation loss = 2.2764  \n",
      "\n",
      "Fold: 28  Epoch: 21  Training loss = 3.0058  Validation loss = 2.2765  \n",
      "\n",
      "Fold: 28  Epoch: 22  Training loss = 3.0055  Validation loss = 2.2764  \n",
      "\n",
      "Fold: 28  Epoch: 23  Training loss = 3.0054  Validation loss = 2.2762  \n",
      "\n",
      "Fold: 28  Epoch: 24  Training loss = 3.0052  Validation loss = 2.2756  \n",
      "\n",
      "Fold: 28  Epoch: 25  Training loss = 3.0050  Validation loss = 2.2756  \n",
      "\n",
      "Fold: 28  Epoch: 26  Training loss = 3.0047  Validation loss = 2.2755  \n",
      "\n",
      "Fold: 28  Epoch: 27  Training loss = 3.0041  Validation loss = 2.2752  \n",
      "\n",
      "Fold: 28  Epoch: 28  Training loss = 3.0040  Validation loss = 2.2749  \n",
      "\n",
      "Fold: 28  Epoch: 29  Training loss = 3.0037  Validation loss = 2.2748  \n",
      "\n",
      "Fold: 28  Epoch: 30  Training loss = 3.0032  Validation loss = 2.2745  \n",
      "\n",
      "Fold: 28  Epoch: 31  Training loss = 3.0031  Validation loss = 2.2744  \n",
      "\n",
      "Fold: 28  Epoch: 32  Training loss = 3.0028  Validation loss = 2.2740  \n",
      "\n",
      "Fold: 28  Epoch: 33  Training loss = 3.0025  Validation loss = 2.2738  \n",
      "\n",
      "Fold: 28  Epoch: 34  Training loss = 3.0024  Validation loss = 2.2740  \n",
      "\n",
      "Fold: 28  Epoch: 35  Training loss = 3.0022  Validation loss = 2.2737  \n",
      "\n",
      "Fold: 28  Epoch: 36  Training loss = 3.0019  Validation loss = 2.2740  \n",
      "\n",
      "Fold: 28  Epoch: 37  Training loss = 3.0018  Validation loss = 2.2738  \n",
      "\n",
      "Fold: 28  Epoch: 38  Training loss = 3.0016  Validation loss = 2.2741  \n",
      "\n",
      "Fold: 28  Epoch: 39  Training loss = 3.0013  Validation loss = 2.2741  \n",
      "\n",
      "Fold: 28  Epoch: 40  Training loss = 3.0010  Validation loss = 2.2738  \n",
      "\n",
      "Fold: 28  Epoch: 41  Training loss = 3.0009  Validation loss = 2.2735  \n",
      "\n",
      "Fold: 28  Epoch: 42  Training loss = 3.0007  Validation loss = 2.2734  \n",
      "\n",
      "Fold: 28  Epoch: 43  Training loss = 3.0005  Validation loss = 2.2728  \n",
      "\n",
      "Fold: 28  Epoch: 44  Training loss = 3.0004  Validation loss = 2.2731  \n",
      "\n",
      "Fold: 28  Epoch: 45  Training loss = 3.0002  Validation loss = 2.2730  \n",
      "\n",
      "Fold: 28  Epoch: 46  Training loss = 2.9998  Validation loss = 2.2729  \n",
      "\n",
      "Fold: 28  Epoch: 47  Training loss = 2.9996  Validation loss = 2.2726  \n",
      "\n",
      "Fold: 28  Epoch: 48  Training loss = 2.9995  Validation loss = 2.2724  \n",
      "\n",
      "Fold: 28  Epoch: 49  Training loss = 2.9993  Validation loss = 2.2725  \n",
      "\n",
      "Fold: 28  Epoch: 50  Training loss = 2.9990  Validation loss = 2.2725  \n",
      "\n",
      "Fold: 28  Epoch: 51  Training loss = 2.9988  Validation loss = 2.2725  \n",
      "\n",
      "Fold: 28  Epoch: 52  Training loss = 2.9986  Validation loss = 2.2726  \n",
      "\n",
      "Fold: 28  Epoch: 53  Training loss = 2.9985  Validation loss = 2.2722  \n",
      "\n",
      "Fold: 28  Epoch: 54  Training loss = 2.9983  Validation loss = 2.2724  \n",
      "\n",
      "Fold: 28  Epoch: 55  Training loss = 2.9982  Validation loss = 2.2720  \n",
      "\n",
      "Fold: 28  Epoch: 56  Training loss = 2.9979  Validation loss = 2.2715  \n",
      "\n",
      "Fold: 28  Epoch: 57  Training loss = 2.9978  Validation loss = 2.2710  \n",
      "\n",
      "Fold: 28  Epoch: 58  Training loss = 2.9976  Validation loss = 2.2711  \n",
      "\n",
      "Fold: 28  Epoch: 59  Training loss = 2.9974  Validation loss = 2.2712  \n",
      "\n",
      "Fold: 28  Epoch: 60  Training loss = 2.9972  Validation loss = 2.2711  \n",
      "\n",
      "Fold: 28  Epoch: 61  Training loss = 2.9971  Validation loss = 2.2711  \n",
      "\n",
      "Fold: 28  Epoch: 62  Training loss = 2.9969  Validation loss = 2.2711  \n",
      "\n",
      "Fold: 28  Epoch: 63  Training loss = 2.9968  Validation loss = 2.2712  \n",
      "\n",
      "Fold: 28  Epoch: 64  Training loss = 2.9967  Validation loss = 2.2710  \n",
      "\n",
      "Fold: 28  Epoch: 65  Training loss = 2.9966  Validation loss = 2.2712  \n",
      "\n",
      "Fold: 28  Epoch: 66  Training loss = 2.9964  Validation loss = 2.2716  \n",
      "\n",
      "Fold: 28  Epoch: 67  Training loss = 2.9963  Validation loss = 2.2717  \n",
      "\n",
      "Fold: 28  Epoch: 68  Training loss = 2.9962  Validation loss = 2.2717  \n",
      "\n",
      "Fold: 28  Epoch: 69  Training loss = 2.9960  Validation loss = 2.2718  \n",
      "\n",
      "Fold: 28  Epoch: 70  Training loss = 2.9959  Validation loss = 2.2717  \n",
      "\n",
      "Fold: 28  Epoch: 71  Training loss = 2.9957  Validation loss = 2.2717  \n",
      "\n",
      "Fold: 28  Epoch: 72  Training loss = 2.9956  Validation loss = 2.2716  \n",
      "\n",
      "Fold: 28  Epoch: 73  Training loss = 2.9955  Validation loss = 2.2714  \n",
      "\n",
      "Fold: 28  Epoch: 74  Training loss = 2.9954  Validation loss = 2.2714  \n",
      "\n",
      "Fold: 28  Epoch: 75  Training loss = 2.9952  Validation loss = 2.2712  \n",
      "\n",
      "Fold: 28  Epoch: 76  Training loss = 2.9951  Validation loss = 2.2709  \n",
      "\n",
      "Fold: 28  Epoch: 77  Training loss = 2.9949  Validation loss = 2.2710  \n",
      "\n",
      "Fold: 28  Epoch: 78  Training loss = 2.9948  Validation loss = 2.2711  \n",
      "\n",
      "Fold: 28  Epoch: 79  Training loss = 2.9946  Validation loss = 2.2710  \n",
      "\n",
      "Fold: 28  Epoch: 80  Training loss = 2.9945  Validation loss = 2.2707  \n",
      "\n",
      "Fold: 28  Epoch: 81  Training loss = 2.9944  Validation loss = 2.2705  \n",
      "\n",
      "Fold: 28  Epoch: 82  Training loss = 2.9943  Validation loss = 2.2708  \n",
      "\n",
      "Fold: 28  Epoch: 83  Training loss = 2.9941  Validation loss = 2.2706  \n",
      "\n",
      "Fold: 28  Epoch: 84  Training loss = 2.9940  Validation loss = 2.2701  \n",
      "\n",
      "Fold: 28  Epoch: 85  Training loss = 2.9938  Validation loss = 2.2696  \n",
      "\n",
      "Fold: 28  Epoch: 86  Training loss = 2.9937  Validation loss = 2.2697  \n",
      "\n",
      "Fold: 28  Epoch: 87  Training loss = 2.9936  Validation loss = 2.2692  \n",
      "\n",
      "Fold: 28  Epoch: 88  Training loss = 2.9935  Validation loss = 2.2689  \n",
      "\n",
      "Fold: 28  Epoch: 89  Training loss = 2.9934  Validation loss = 2.2689  \n",
      "\n",
      "Fold: 28  Epoch: 90  Training loss = 2.9932  Validation loss = 2.2686  \n",
      "\n",
      "Fold: 28  Epoch: 91  Training loss = 2.9930  Validation loss = 2.2685  \n",
      "\n",
      "Fold: 28  Epoch: 92  Training loss = 2.9929  Validation loss = 2.2681  \n",
      "\n",
      "Fold: 28  Epoch: 93  Training loss = 2.9928  Validation loss = 2.2681  \n",
      "\n",
      "Fold: 28  Epoch: 94  Training loss = 2.9927  Validation loss = 2.2681  \n",
      "\n",
      "Fold: 28  Epoch: 95  Training loss = 2.9926  Validation loss = 2.2681  \n",
      "\n",
      "Fold: 28  Epoch: 96  Training loss = 2.9924  Validation loss = 2.2678  \n",
      "\n",
      "Fold: 28  Epoch: 97  Training loss = 2.9922  Validation loss = 2.2678  \n",
      "\n",
      "Fold: 28  Epoch: 98  Training loss = 2.9921  Validation loss = 2.2673  \n",
      "\n",
      "Fold: 28  Epoch: 99  Training loss = 2.9919  Validation loss = 2.2666  \n",
      "\n",
      "Fold: 28  Epoch: 100  Training loss = 2.9919  Validation loss = 2.2666  \n",
      "\n",
      "Fold: 28  Epoch: 101  Training loss = 2.9917  Validation loss = 2.2665  \n",
      "\n",
      "Fold: 28  Epoch: 102  Training loss = 2.9916  Validation loss = 2.2665  \n",
      "\n",
      "Fold: 28  Epoch: 103  Training loss = 2.9915  Validation loss = 2.2667  \n",
      "\n",
      "Fold: 28  Epoch: 104  Training loss = 2.9913  Validation loss = 2.2665  \n",
      "\n",
      "Fold: 28  Epoch: 105  Training loss = 2.9912  Validation loss = 2.2663  \n",
      "\n",
      "Fold: 28  Epoch: 106  Training loss = 2.9911  Validation loss = 2.2658  \n",
      "\n",
      "Fold: 28  Epoch: 107  Training loss = 2.9909  Validation loss = 2.2654  \n",
      "\n",
      "Fold: 28  Epoch: 108  Training loss = 2.9908  Validation loss = 2.2653  \n",
      "\n",
      "Fold: 28  Epoch: 109  Training loss = 2.9906  Validation loss = 2.2651  \n",
      "\n",
      "Fold: 28  Epoch: 110  Training loss = 2.9905  Validation loss = 2.2649  \n",
      "\n",
      "Fold: 28  Epoch: 111  Training loss = 2.9904  Validation loss = 2.2651  \n",
      "\n",
      "Fold: 28  Epoch: 112  Training loss = 2.9902  Validation loss = 2.2644  \n",
      "\n",
      "Fold: 28  Epoch: 113  Training loss = 2.9901  Validation loss = 2.2640  \n",
      "\n",
      "Fold: 28  Epoch: 114  Training loss = 2.9899  Validation loss = 2.2642  \n",
      "\n",
      "Fold: 28  Epoch: 115  Training loss = 2.9898  Validation loss = 2.2647  \n",
      "\n",
      "Fold: 28  Epoch: 116  Training loss = 2.9896  Validation loss = 2.2647  \n",
      "\n",
      "Fold: 28  Epoch: 117  Training loss = 2.9895  Validation loss = 2.2645  \n",
      "\n",
      "Fold: 28  Epoch: 118  Training loss = 2.9893  Validation loss = 2.2646  \n",
      "\n",
      "Fold: 28  Epoch: 119  Training loss = 2.9892  Validation loss = 2.2647  \n",
      "\n",
      "Fold: 28  Epoch: 120  Training loss = 2.9890  Validation loss = 2.2646  \n",
      "\n",
      "Fold: 28  Epoch: 121  Training loss = 2.9889  Validation loss = 2.2646  \n",
      "\n",
      "Fold: 28  Epoch: 122  Training loss = 2.9888  Validation loss = 2.2646  \n",
      "\n",
      "Fold: 28  Epoch: 123  Training loss = 2.9887  Validation loss = 2.2649  \n",
      "\n",
      "Fold: 28  Epoch: 124  Training loss = 2.9885  Validation loss = 2.2649  \n",
      "\n",
      "Fold: 28  Epoch: 125  Training loss = 2.9884  Validation loss = 2.2643  \n",
      "\n",
      "Fold: 28  Epoch: 126  Training loss = 2.9883  Validation loss = 2.2645  \n",
      "\n",
      "Fold: 28  Epoch: 127  Training loss = 2.9881  Validation loss = 2.2643  \n",
      "\n",
      "Fold: 28  Epoch: 128  Training loss = 2.9880  Validation loss = 2.2641  \n",
      "\n",
      "Fold: 28  Epoch: 129  Training loss = 2.9879  Validation loss = 2.2641  \n",
      "\n",
      "Fold: 28  Epoch: 130  Training loss = 2.9877  Validation loss = 2.2638  \n",
      "\n",
      "Fold: 28  Epoch: 131  Training loss = 2.9875  Validation loss = 2.2638  \n",
      "\n",
      "Fold: 28  Epoch: 132  Training loss = 2.9874  Validation loss = 2.2638  \n",
      "\n",
      "Fold: 28  Epoch: 133  Training loss = 2.9873  Validation loss = 2.2638  \n",
      "\n",
      "Fold: 28  Epoch: 134  Training loss = 2.9871  Validation loss = 2.2638  \n",
      "\n",
      "Fold: 28  Epoch: 135  Training loss = 2.9869  Validation loss = 2.2634  \n",
      "\n",
      "Fold: 28  Epoch: 136  Training loss = 2.9868  Validation loss = 2.2634  \n",
      "\n",
      "Fold: 28  Epoch: 137  Training loss = 2.9866  Validation loss = 2.2629  \n",
      "\n",
      "Fold: 28  Epoch: 138  Training loss = 2.9865  Validation loss = 2.2629  \n",
      "\n",
      "Fold: 28  Epoch: 139  Training loss = 2.9863  Validation loss = 2.2625  \n",
      "\n",
      "Fold: 28  Epoch: 140  Training loss = 2.9862  Validation loss = 2.2623  \n",
      "\n",
      "Fold: 28  Epoch: 141  Training loss = 2.9860  Validation loss = 2.2622  \n",
      "\n",
      "Fold: 28  Epoch: 142  Training loss = 2.9859  Validation loss = 2.2619  \n",
      "\n",
      "Fold: 28  Epoch: 143  Training loss = 2.9857  Validation loss = 2.2615  \n",
      "\n",
      "Fold: 28  Epoch: 144  Training loss = 2.9856  Validation loss = 2.2615  \n",
      "\n",
      "Fold: 28  Epoch: 145  Training loss = 2.9854  Validation loss = 2.2616  \n",
      "\n",
      "Fold: 28  Epoch: 146  Training loss = 2.9853  Validation loss = 2.2613  \n",
      "\n",
      "Fold: 28  Epoch: 147  Training loss = 2.9853  Validation loss = 2.2612  \n",
      "\n",
      "Fold: 28  Epoch: 148  Training loss = 2.9851  Validation loss = 2.2611  \n",
      "\n",
      "Fold: 28  Epoch: 149  Training loss = 2.9850  Validation loss = 2.2611  \n",
      "\n",
      "Fold: 28  Epoch: 150  Training loss = 2.9849  Validation loss = 2.2611  \n",
      "\n",
      "Fold: 28  Epoch: 151  Training loss = 2.9847  Validation loss = 2.2605  \n",
      "\n",
      "Fold: 28  Epoch: 152  Training loss = 2.9846  Validation loss = 2.2601  \n",
      "\n",
      "Fold: 28  Epoch: 153  Training loss = 2.9844  Validation loss = 2.2598  \n",
      "\n",
      "Fold: 28  Epoch: 154  Training loss = 2.9842  Validation loss = 2.2596  \n",
      "\n",
      "Fold: 28  Epoch: 155  Training loss = 2.9841  Validation loss = 2.2596  \n",
      "\n",
      "Fold: 28  Epoch: 156  Training loss = 2.9839  Validation loss = 2.2595  \n",
      "\n",
      "Fold: 28  Epoch: 157  Training loss = 2.9838  Validation loss = 2.2590  \n",
      "\n",
      "Fold: 28  Epoch: 158  Training loss = 2.9836  Validation loss = 2.2588  \n",
      "\n",
      "Fold: 28  Epoch: 159  Training loss = 2.9835  Validation loss = 2.2586  \n",
      "\n",
      "Fold: 28  Epoch: 160  Training loss = 2.9833  Validation loss = 2.2586  \n",
      "\n",
      "Fold: 28  Epoch: 161  Training loss = 2.9832  Validation loss = 2.2586  \n",
      "\n",
      "Fold: 28  Epoch: 162  Training loss = 2.9831  Validation loss = 2.2583  \n",
      "\n",
      "Fold: 28  Epoch: 163  Training loss = 2.9829  Validation loss = 2.2582  \n",
      "\n",
      "Fold: 28  Epoch: 164  Training loss = 2.9828  Validation loss = 2.2579  \n",
      "\n",
      "Fold: 28  Epoch: 165  Training loss = 2.9827  Validation loss = 2.2580  \n",
      "\n",
      "Fold: 28  Epoch: 166  Training loss = 2.9826  Validation loss = 2.2582  \n",
      "\n",
      "Fold: 28  Epoch: 167  Training loss = 2.9824  Validation loss = 2.2579  \n",
      "\n",
      "Fold: 28  Epoch: 168  Training loss = 2.9824  Validation loss = 2.2582  \n",
      "\n",
      "Fold: 28  Epoch: 169  Training loss = 2.9823  Validation loss = 2.2578  \n",
      "\n",
      "Fold: 28  Epoch: 170  Training loss = 2.9821  Validation loss = 2.2576  \n",
      "\n",
      "Fold: 28  Epoch: 171  Training loss = 2.9820  Validation loss = 2.2574  \n",
      "\n",
      "Fold: 28  Epoch: 172  Training loss = 2.9819  Validation loss = 2.2576  \n",
      "\n",
      "Fold: 28  Epoch: 173  Training loss = 2.9817  Validation loss = 2.2570  \n",
      "\n",
      "Fold: 28  Epoch: 174  Training loss = 2.9816  Validation loss = 2.2570  \n",
      "\n",
      "Fold: 28  Epoch: 175  Training loss = 2.9815  Validation loss = 2.2569  \n",
      "\n",
      "Fold: 28  Epoch: 176  Training loss = 2.9813  Validation loss = 2.2568  \n",
      "\n",
      "Fold: 28  Epoch: 177  Training loss = 2.9812  Validation loss = 2.2566  \n",
      "\n",
      "Fold: 28  Epoch: 178  Training loss = 2.9811  Validation loss = 2.2566  \n",
      "\n",
      "Fold: 28  Epoch: 179  Training loss = 2.9809  Validation loss = 2.2565  \n",
      "\n",
      "Fold: 28  Epoch: 180  Training loss = 2.9808  Validation loss = 2.2563  \n",
      "\n",
      "Fold: 28  Epoch: 181  Training loss = 2.9807  Validation loss = 2.2567  \n",
      "\n",
      "Fold: 28  Epoch: 182  Training loss = 2.9805  Validation loss = 2.2568  \n",
      "\n",
      "Fold: 28  Epoch: 183  Training loss = 2.9804  Validation loss = 2.2567  \n",
      "\n",
      "Fold: 28  Epoch: 184  Training loss = 2.9803  Validation loss = 2.2569  \n",
      "\n",
      "Fold: 28  Epoch: 185  Training loss = 2.9801  Validation loss = 2.2566  \n",
      "\n",
      "Fold: 28  Epoch: 186  Training loss = 2.9800  Validation loss = 2.2571  \n",
      "\n",
      "Fold: 28  Epoch: 187  Training loss = 2.9799  Validation loss = 2.2575  \n",
      "\n",
      "Check model:  Fold: 28  Optimal epoch: 180  \n",
      "\n",
      "Fold: 29  Epoch: 1  Training loss = 3.0223  Validation loss = 2.7577  \n",
      "\n",
      "Fold: 29  Epoch: 2  Training loss = 3.0222  Validation loss = 2.7573  \n",
      "\n",
      "Fold: 29  Epoch: 3  Training loss = 3.0220  Validation loss = 2.7567  \n",
      "\n",
      "Fold: 29  Epoch: 4  Training loss = 3.0219  Validation loss = 2.7563  \n",
      "\n",
      "Fold: 29  Epoch: 5  Training loss = 3.0218  Validation loss = 2.7561  \n",
      "\n",
      "Fold: 29  Epoch: 6  Training loss = 3.0217  Validation loss = 2.7562  \n",
      "\n",
      "Fold: 29  Epoch: 7  Training loss = 3.0217  Validation loss = 2.7565  \n",
      "\n",
      "Fold: 29  Epoch: 8  Training loss = 3.0215  Validation loss = 2.7562  \n",
      "\n",
      "Fold: 29  Epoch: 9  Training loss = 3.0214  Validation loss = 2.7562  \n",
      "\n",
      "Fold: 29  Epoch: 10  Training loss = 3.0212  Validation loss = 2.7557  \n",
      "\n",
      "Fold: 29  Epoch: 11  Training loss = 3.0210  Validation loss = 2.7554  \n",
      "\n",
      "Fold: 29  Epoch: 12  Training loss = 3.0208  Validation loss = 2.7553  \n",
      "\n",
      "Fold: 29  Epoch: 13  Training loss = 3.0207  Validation loss = 2.7551  \n",
      "\n",
      "Fold: 29  Epoch: 14  Training loss = 3.0206  Validation loss = 2.7554  \n",
      "\n",
      "Fold: 29  Epoch: 15  Training loss = 3.0205  Validation loss = 2.7551  \n",
      "\n",
      "Fold: 29  Epoch: 16  Training loss = 3.0203  Validation loss = 2.7548  \n",
      "\n",
      "Fold: 29  Epoch: 17  Training loss = 3.0201  Validation loss = 2.7547  \n",
      "\n",
      "Fold: 29  Epoch: 18  Training loss = 3.0200  Validation loss = 2.7545  \n",
      "\n",
      "Fold: 29  Epoch: 19  Training loss = 3.0199  Validation loss = 2.7545  \n",
      "\n",
      "Fold: 29  Epoch: 20  Training loss = 3.0197  Validation loss = 2.7544  \n",
      "\n",
      "Fold: 29  Epoch: 21  Training loss = 3.0195  Validation loss = 2.7547  \n",
      "\n",
      "Fold: 29  Epoch: 22  Training loss = 3.0194  Validation loss = 2.7545  \n",
      "\n",
      "Fold: 29  Epoch: 23  Training loss = 3.0193  Validation loss = 2.7544  \n",
      "\n",
      "Fold: 29  Epoch: 24  Training loss = 3.0192  Validation loss = 2.7548  \n",
      "\n",
      "Fold: 29  Epoch: 25  Training loss = 3.0190  Validation loss = 2.7542  \n",
      "\n",
      "Fold: 29  Epoch: 26  Training loss = 3.0188  Validation loss = 2.7537  \n",
      "\n",
      "Fold: 29  Epoch: 27  Training loss = 3.0187  Validation loss = 2.7536  \n",
      "\n",
      "Fold: 29  Epoch: 28  Training loss = 3.0186  Validation loss = 2.7537  \n",
      "\n",
      "Fold: 29  Epoch: 29  Training loss = 3.0184  Validation loss = 2.7536  \n",
      "\n",
      "Fold: 29  Epoch: 30  Training loss = 3.0183  Validation loss = 2.7535  \n",
      "\n",
      "Fold: 29  Epoch: 31  Training loss = 3.0181  Validation loss = 2.7528  \n",
      "\n",
      "Fold: 29  Epoch: 32  Training loss = 3.0180  Validation loss = 2.7525  \n",
      "\n",
      "Fold: 29  Epoch: 33  Training loss = 3.0179  Validation loss = 2.7523  \n",
      "\n",
      "Fold: 29  Epoch: 34  Training loss = 3.0177  Validation loss = 2.7520  \n",
      "\n",
      "Fold: 29  Epoch: 35  Training loss = 3.0176  Validation loss = 2.7518  \n",
      "\n",
      "Fold: 29  Epoch: 36  Training loss = 3.0173  Validation loss = 2.7518  \n",
      "\n",
      "Fold: 29  Epoch: 37  Training loss = 3.0172  Validation loss = 2.7518  \n",
      "\n",
      "Fold: 29  Epoch: 38  Training loss = 3.0170  Validation loss = 2.7514  \n",
      "\n",
      "Fold: 29  Epoch: 39  Training loss = 3.0168  Validation loss = 2.7515  \n",
      "\n",
      "Fold: 29  Epoch: 40  Training loss = 3.0167  Validation loss = 2.7518  \n",
      "\n",
      "Fold: 29  Epoch: 41  Training loss = 3.0166  Validation loss = 2.7519  \n",
      "\n",
      "Fold: 29  Epoch: 42  Training loss = 3.0165  Validation loss = 2.7518  \n",
      "\n",
      "Fold: 29  Epoch: 43  Training loss = 3.0164  Validation loss = 2.7520  \n",
      "\n",
      "Fold: 29  Epoch: 44  Training loss = 3.0163  Validation loss = 2.7516  \n",
      "\n",
      "Fold: 29  Epoch: 45  Training loss = 3.0161  Validation loss = 2.7513  \n",
      "\n",
      "Fold: 29  Epoch: 46  Training loss = 3.0160  Validation loss = 2.7506  \n",
      "\n",
      "Fold: 29  Epoch: 47  Training loss = 3.0158  Validation loss = 2.7499  \n",
      "\n",
      "Fold: 29  Epoch: 48  Training loss = 3.0157  Validation loss = 2.7499  \n",
      "\n",
      "Fold: 29  Epoch: 49  Training loss = 3.0156  Validation loss = 2.7500  \n",
      "\n",
      "Fold: 29  Epoch: 50  Training loss = 3.0155  Validation loss = 2.7503  \n",
      "\n",
      "Fold: 29  Epoch: 51  Training loss = 3.0153  Validation loss = 2.7498  \n",
      "\n",
      "Fold: 29  Epoch: 52  Training loss = 3.0151  Validation loss = 2.7500  \n",
      "\n",
      "Fold: 29  Epoch: 53  Training loss = 3.0150  Validation loss = 2.7497  \n",
      "\n",
      "Fold: 29  Epoch: 54  Training loss = 3.0148  Validation loss = 2.7493  \n",
      "\n",
      "Fold: 29  Epoch: 55  Training loss = 3.0147  Validation loss = 2.7490  \n",
      "\n",
      "Fold: 29  Epoch: 56  Training loss = 3.0145  Validation loss = 2.7490  \n",
      "\n",
      "Fold: 29  Epoch: 57  Training loss = 3.0144  Validation loss = 2.7485  \n",
      "\n",
      "Fold: 29  Epoch: 58  Training loss = 3.0143  Validation loss = 2.7483  \n",
      "\n",
      "Fold: 29  Epoch: 59  Training loss = 3.0142  Validation loss = 2.7483  \n",
      "\n",
      "Fold: 29  Epoch: 60  Training loss = 3.0140  Validation loss = 2.7484  \n",
      "\n",
      "Fold: 29  Epoch: 61  Training loss = 3.0138  Validation loss = 2.7484  \n",
      "\n",
      "Fold: 29  Epoch: 62  Training loss = 3.0137  Validation loss = 2.7484  \n",
      "\n",
      "Fold: 29  Epoch: 63  Training loss = 3.0135  Validation loss = 2.7480  \n",
      "\n",
      "Fold: 29  Epoch: 64  Training loss = 3.0133  Validation loss = 2.7482  \n",
      "\n",
      "Fold: 29  Epoch: 65  Training loss = 3.0130  Validation loss = 2.7476  \n",
      "\n",
      "Fold: 29  Epoch: 66  Training loss = 3.0129  Validation loss = 2.7476  \n",
      "\n",
      "Fold: 29  Epoch: 67  Training loss = 3.0128  Validation loss = 2.7474  \n",
      "\n",
      "Fold: 29  Epoch: 68  Training loss = 3.0125  Validation loss = 2.7472  \n",
      "\n",
      "Fold: 29  Epoch: 69  Training loss = 3.0124  Validation loss = 2.7466  \n",
      "\n",
      "Fold: 29  Epoch: 70  Training loss = 3.0122  Validation loss = 2.7460  \n",
      "\n",
      "Fold: 29  Epoch: 71  Training loss = 3.0120  Validation loss = 2.7452  \n",
      "\n",
      "Fold: 29  Epoch: 72  Training loss = 3.0118  Validation loss = 2.7452  \n",
      "\n",
      "Fold: 29  Epoch: 73  Training loss = 3.0117  Validation loss = 2.7452  \n",
      "\n",
      "Fold: 29  Epoch: 74  Training loss = 3.0115  Validation loss = 2.7450  \n",
      "\n",
      "Fold: 29  Epoch: 75  Training loss = 3.0113  Validation loss = 2.7446  \n",
      "\n",
      "Fold: 29  Epoch: 76  Training loss = 3.0111  Validation loss = 2.7441  \n",
      "\n",
      "Fold: 29  Epoch: 77  Training loss = 3.0109  Validation loss = 2.7435  \n",
      "\n",
      "Fold: 29  Epoch: 78  Training loss = 3.0106  Validation loss = 2.7429  \n",
      "\n",
      "Fold: 29  Epoch: 79  Training loss = 3.0106  Validation loss = 2.7432  \n",
      "\n",
      "Fold: 29  Epoch: 80  Training loss = 3.0104  Validation loss = 2.7428  \n",
      "\n",
      "Fold: 29  Epoch: 81  Training loss = 3.0102  Validation loss = 2.7427  \n",
      "\n",
      "Fold: 29  Epoch: 82  Training loss = 3.0101  Validation loss = 2.7420  \n",
      "\n",
      "Fold: 29  Epoch: 83  Training loss = 3.0099  Validation loss = 2.7415  \n",
      "\n",
      "Fold: 29  Epoch: 84  Training loss = 3.0097  Validation loss = 2.7415  \n",
      "\n",
      "Fold: 29  Epoch: 85  Training loss = 3.0095  Validation loss = 2.7411  \n",
      "\n",
      "Fold: 29  Epoch: 86  Training loss = 3.0094  Validation loss = 2.7412  \n",
      "\n",
      "Fold: 29  Epoch: 87  Training loss = 3.0093  Validation loss = 2.7409  \n",
      "\n",
      "Fold: 29  Epoch: 88  Training loss = 3.0091  Validation loss = 2.7413  \n",
      "\n",
      "Fold: 29  Epoch: 89  Training loss = 3.0088  Validation loss = 2.7410  \n",
      "\n",
      "Fold: 29  Epoch: 90  Training loss = 3.0087  Validation loss = 2.7409  \n",
      "\n",
      "Fold: 29  Epoch: 91  Training loss = 3.0085  Validation loss = 2.7404  \n",
      "\n",
      "Fold: 29  Epoch: 92  Training loss = 3.0083  Validation loss = 2.7399  \n",
      "\n",
      "Fold: 29  Epoch: 93  Training loss = 3.0079  Validation loss = 2.7393  \n",
      "\n",
      "Fold: 29  Epoch: 94  Training loss = 3.0078  Validation loss = 2.7391  \n",
      "\n",
      "Fold: 29  Epoch: 95  Training loss = 3.0076  Validation loss = 2.7393  \n",
      "\n",
      "Fold: 29  Epoch: 96  Training loss = 3.0074  Validation loss = 2.7388  \n",
      "\n",
      "Fold: 29  Epoch: 97  Training loss = 3.0073  Validation loss = 2.7387  \n",
      "\n",
      "Fold: 29  Epoch: 98  Training loss = 3.0070  Validation loss = 2.7381  \n",
      "\n",
      "Fold: 29  Epoch: 99  Training loss = 3.0069  Validation loss = 2.7380  \n",
      "\n",
      "Fold: 29  Epoch: 100  Training loss = 3.0068  Validation loss = 2.7377  \n",
      "\n",
      "Fold: 29  Epoch: 101  Training loss = 3.0066  Validation loss = 2.7374  \n",
      "\n",
      "Fold: 29  Epoch: 102  Training loss = 3.0064  Validation loss = 2.7370  \n",
      "\n",
      "Fold: 29  Epoch: 103  Training loss = 3.0062  Validation loss = 2.7374  \n",
      "\n",
      "Fold: 29  Epoch: 104  Training loss = 3.0059  Validation loss = 2.7374  \n",
      "\n",
      "Fold: 29  Epoch: 105  Training loss = 3.0058  Validation loss = 2.7374  \n",
      "\n",
      "Fold: 29  Epoch: 106  Training loss = 3.0057  Validation loss = 2.7369  \n",
      "\n",
      "Fold: 29  Epoch: 107  Training loss = 3.0057  Validation loss = 2.7374  \n",
      "\n",
      "Fold: 29  Epoch: 108  Training loss = 3.0055  Validation loss = 2.7376  \n",
      "\n",
      "Fold: 29  Epoch: 109  Training loss = 3.0051  Validation loss = 2.7365  \n",
      "\n",
      "Fold: 29  Epoch: 110  Training loss = 3.0049  Validation loss = 2.7360  \n",
      "\n",
      "Fold: 29  Epoch: 111  Training loss = 3.0046  Validation loss = 2.7357  \n",
      "\n",
      "Fold: 29  Epoch: 112  Training loss = 3.0043  Validation loss = 2.7354  \n",
      "\n",
      "Fold: 29  Epoch: 113  Training loss = 3.0038  Validation loss = 2.7342  \n",
      "\n",
      "Fold: 29  Epoch: 114  Training loss = 3.0038  Validation loss = 2.7342  \n",
      "\n",
      "Fold: 29  Epoch: 115  Training loss = 3.0036  Validation loss = 2.7340  \n",
      "\n",
      "Fold: 29  Epoch: 116  Training loss = 3.0034  Validation loss = 2.7336  \n",
      "\n",
      "Fold: 29  Epoch: 117  Training loss = 3.0032  Validation loss = 2.7331  \n",
      "\n",
      "Fold: 29  Epoch: 118  Training loss = 3.0032  Validation loss = 2.7331  \n",
      "\n",
      "Fold: 29  Epoch: 119  Training loss = 3.0030  Validation loss = 2.7330  \n",
      "\n",
      "Fold: 29  Epoch: 120  Training loss = 3.0027  Validation loss = 2.7330  \n",
      "\n",
      "Fold: 29  Epoch: 121  Training loss = 3.0025  Validation loss = 2.7331  \n",
      "\n",
      "Fold: 29  Epoch: 122  Training loss = 3.0023  Validation loss = 2.7332  \n",
      "\n",
      "Fold: 29  Epoch: 123  Training loss = 3.0022  Validation loss = 2.7335  \n",
      "\n",
      "Fold: 29  Epoch: 124  Training loss = 3.0021  Validation loss = 2.7333  \n",
      "\n",
      "Fold: 29  Epoch: 125  Training loss = 3.0019  Validation loss = 2.7332  \n",
      "\n",
      "Fold: 29  Epoch: 126  Training loss = 3.0017  Validation loss = 2.7331  \n",
      "\n",
      "Fold: 29  Epoch: 127  Training loss = 3.0015  Validation loss = 2.7330  \n",
      "\n",
      "Fold: 29  Epoch: 128  Training loss = 3.0013  Validation loss = 2.7326  \n",
      "\n",
      "Fold: 29  Epoch: 129  Training loss = 3.0011  Validation loss = 2.7325  \n",
      "\n",
      "Fold: 29  Epoch: 130  Training loss = 3.0008  Validation loss = 2.7319  \n",
      "\n",
      "Fold: 29  Epoch: 131  Training loss = 3.0007  Validation loss = 2.7319  \n",
      "\n",
      "Fold: 29  Epoch: 132  Training loss = 3.0006  Validation loss = 2.7311  \n",
      "\n",
      "Fold: 29  Epoch: 133  Training loss = 3.0005  Validation loss = 2.7311  \n",
      "\n",
      "Fold: 29  Epoch: 134  Training loss = 3.0003  Validation loss = 2.7306  \n",
      "\n",
      "Fold: 29  Epoch: 135  Training loss = 3.0002  Validation loss = 2.7309  \n",
      "\n",
      "Fold: 29  Epoch: 136  Training loss = 3.0000  Validation loss = 2.7304  \n",
      "\n",
      "Fold: 29  Epoch: 137  Training loss = 2.9999  Validation loss = 2.7305  \n",
      "\n",
      "Fold: 29  Epoch: 138  Training loss = 2.9998  Validation loss = 2.7302  \n",
      "\n",
      "Fold: 29  Epoch: 139  Training loss = 2.9996  Validation loss = 2.7295  \n",
      "\n",
      "Fold: 29  Epoch: 140  Training loss = 2.9995  Validation loss = 2.7290  \n",
      "\n",
      "Fold: 29  Epoch: 141  Training loss = 2.9993  Validation loss = 2.7288  \n",
      "\n",
      "Fold: 29  Epoch: 142  Training loss = 2.9992  Validation loss = 2.7289  \n",
      "\n",
      "Fold: 29  Epoch: 143  Training loss = 2.9989  Validation loss = 2.7288  \n",
      "\n",
      "Fold: 29  Epoch: 144  Training loss = 2.9988  Validation loss = 2.7288  \n",
      "\n",
      "Fold: 29  Epoch: 145  Training loss = 2.9987  Validation loss = 2.7285  \n",
      "\n",
      "Fold: 29  Epoch: 146  Training loss = 2.9985  Validation loss = 2.7283  \n",
      "\n",
      "Fold: 29  Epoch: 147  Training loss = 2.9984  Validation loss = 2.7278  \n",
      "\n",
      "Fold: 29  Epoch: 148  Training loss = 2.9982  Validation loss = 2.7270  \n",
      "\n",
      "Fold: 29  Epoch: 149  Training loss = 2.9980  Validation loss = 2.7270  \n",
      "\n",
      "Fold: 29  Epoch: 150  Training loss = 2.9978  Validation loss = 2.7272  \n",
      "\n",
      "Fold: 29  Epoch: 151  Training loss = 2.9977  Validation loss = 2.7270  \n",
      "\n",
      "Fold: 29  Epoch: 152  Training loss = 2.9975  Validation loss = 2.7270  \n",
      "\n",
      "Fold: 29  Epoch: 153  Training loss = 2.9974  Validation loss = 2.7268  \n",
      "\n",
      "Fold: 29  Epoch: 154  Training loss = 2.9972  Validation loss = 2.7263  \n",
      "\n",
      "Fold: 29  Epoch: 155  Training loss = 2.9970  Validation loss = 2.7260  \n",
      "\n",
      "Fold: 29  Epoch: 156  Training loss = 2.9969  Validation loss = 2.7254  \n",
      "\n",
      "Fold: 29  Epoch: 157  Training loss = 2.9967  Validation loss = 2.7261  \n",
      "\n",
      "Fold: 29  Epoch: 158  Training loss = 2.9965  Validation loss = 2.7264  \n",
      "\n",
      "Fold: 29  Epoch: 159  Training loss = 2.9964  Validation loss = 2.7265  \n",
      "\n",
      "Fold: 29  Epoch: 160  Training loss = 2.9962  Validation loss = 2.7268  \n",
      "\n",
      "Fold: 29  Epoch: 161  Training loss = 2.9961  Validation loss = 2.7273  \n",
      "\n",
      "Fold: 29  Epoch: 162  Training loss = 2.9959  Validation loss = 2.7275  \n",
      "\n",
      "Check model:  Fold: 29  Optimal epoch: 156  \n",
      "\n",
      "Fold: 30  Epoch: 1  Training loss = 3.0469  Validation loss = 1.0210  \n",
      "\n",
      "Fold: 30  Epoch: 2  Training loss = 3.0468  Validation loss = 1.0212  \n",
      "\n",
      "Fold: 30  Epoch: 3  Training loss = 3.0466  Validation loss = 1.0211  \n",
      "\n",
      "Fold: 30  Epoch: 4  Training loss = 3.0464  Validation loss = 1.0210  \n",
      "\n",
      "Fold: 30  Epoch: 5  Training loss = 3.0462  Validation loss = 1.0212  \n",
      "\n",
      "Fold: 30  Epoch: 6  Training loss = 3.0461  Validation loss = 1.0211  \n",
      "\n",
      "Fold: 30  Epoch: 7  Training loss = 3.0461  Validation loss = 1.0211  \n",
      "\n",
      "Fold: 30  Epoch: 8  Training loss = 3.0459  Validation loss = 1.0212  \n",
      "\n",
      "Fold: 30  Epoch: 9  Training loss = 3.0457  Validation loss = 1.0212  \n",
      "\n",
      "Fold: 30  Epoch: 10  Training loss = 3.0454  Validation loss = 1.0209  \n",
      "\n",
      "Fold: 30  Epoch: 11  Training loss = 3.0452  Validation loss = 1.0209  \n",
      "\n",
      "Fold: 30  Epoch: 12  Training loss = 3.0449  Validation loss = 1.0209  \n",
      "\n",
      "Fold: 30  Epoch: 13  Training loss = 3.0448  Validation loss = 1.0208  \n",
      "\n",
      "Fold: 30  Epoch: 14  Training loss = 3.0446  Validation loss = 1.0208  \n",
      "\n",
      "Fold: 30  Epoch: 15  Training loss = 3.0443  Validation loss = 1.0208  \n",
      "\n",
      "Fold: 30  Epoch: 16  Training loss = 3.0442  Validation loss = 1.0207  \n",
      "\n",
      "Fold: 30  Epoch: 17  Training loss = 3.0440  Validation loss = 1.0208  \n",
      "\n",
      "Fold: 30  Epoch: 18  Training loss = 3.0438  Validation loss = 1.0206  \n",
      "\n",
      "Fold: 30  Epoch: 19  Training loss = 3.0437  Validation loss = 1.0206  \n",
      "\n",
      "Fold: 30  Epoch: 20  Training loss = 3.0435  Validation loss = 1.0205  \n",
      "\n",
      "Fold: 30  Epoch: 21  Training loss = 3.0434  Validation loss = 1.0204  \n",
      "\n",
      "Fold: 30  Epoch: 22  Training loss = 3.0432  Validation loss = 1.0202  \n",
      "\n",
      "Fold: 30  Epoch: 23  Training loss = 3.0430  Validation loss = 1.0202  \n",
      "\n",
      "Fold: 30  Epoch: 24  Training loss = 3.0428  Validation loss = 1.0200  \n",
      "\n",
      "Fold: 30  Epoch: 25  Training loss = 3.0426  Validation loss = 1.0198  \n",
      "\n",
      "Fold: 30  Epoch: 26  Training loss = 3.0425  Validation loss = 1.0199  \n",
      "\n",
      "Fold: 30  Epoch: 27  Training loss = 3.0423  Validation loss = 1.0199  \n",
      "\n",
      "Fold: 30  Epoch: 28  Training loss = 3.0422  Validation loss = 1.0199  \n",
      "\n",
      "Fold: 30  Epoch: 29  Training loss = 3.0419  Validation loss = 1.0199  \n",
      "\n",
      "Fold: 30  Epoch: 30  Training loss = 3.0417  Validation loss = 1.0199  \n",
      "\n",
      "Fold: 30  Epoch: 31  Training loss = 3.0416  Validation loss = 1.0199  \n",
      "\n",
      "Fold: 30  Epoch: 32  Training loss = 3.0414  Validation loss = 1.0199  \n",
      "\n",
      "Fold: 30  Epoch: 33  Training loss = 3.0413  Validation loss = 1.0198  \n",
      "\n",
      "Fold: 30  Epoch: 34  Training loss = 3.0410  Validation loss = 1.0198  \n",
      "\n",
      "Fold: 30  Epoch: 35  Training loss = 3.0408  Validation loss = 1.0198  \n",
      "\n",
      "Fold: 30  Epoch: 36  Training loss = 3.0406  Validation loss = 1.0198  \n",
      "\n",
      "Fold: 30  Epoch: 37  Training loss = 3.0404  Validation loss = 1.0198  \n",
      "\n",
      "Fold: 30  Epoch: 38  Training loss = 3.0401  Validation loss = 1.0199  \n",
      "\n",
      "Fold: 30  Epoch: 39  Training loss = 3.0400  Validation loss = 1.0197  \n",
      "\n",
      "Fold: 30  Epoch: 40  Training loss = 3.0397  Validation loss = 1.0197  \n",
      "\n",
      "Fold: 30  Epoch: 41  Training loss = 3.0396  Validation loss = 1.0196  \n",
      "\n",
      "Fold: 30  Epoch: 42  Training loss = 3.0393  Validation loss = 1.0196  \n",
      "\n",
      "Fold: 30  Epoch: 43  Training loss = 3.0391  Validation loss = 1.0195  \n",
      "\n",
      "Fold: 30  Epoch: 44  Training loss = 3.0389  Validation loss = 1.0196  \n",
      "\n",
      "Fold: 30  Epoch: 45  Training loss = 3.0387  Validation loss = 1.0196  \n",
      "\n",
      "Fold: 30  Epoch: 46  Training loss = 3.0385  Validation loss = 1.0199  \n",
      "\n",
      "Fold: 30  Epoch: 47  Training loss = 3.0383  Validation loss = 1.0198  \n",
      "\n",
      "Fold: 30  Epoch: 48  Training loss = 3.0382  Validation loss = 1.0199  \n",
      "\n",
      "Check model:  Fold: 30  Optimal epoch: 43  \n",
      "\n",
      "Fold: 31  Epoch: 1  Training loss = 2.8156  Validation loss = 2.4253  \n",
      "\n",
      "Fold: 31  Epoch: 2  Training loss = 2.8154  Validation loss = 2.4242  \n",
      "\n",
      "Fold: 31  Epoch: 3  Training loss = 2.8151  Validation loss = 2.4221  \n",
      "\n",
      "Fold: 31  Epoch: 4  Training loss = 2.8148  Validation loss = 2.4219  \n",
      "\n",
      "Fold: 31  Epoch: 5  Training loss = 2.8146  Validation loss = 2.4205  \n",
      "\n",
      "Fold: 31  Epoch: 6  Training loss = 2.8143  Validation loss = 2.4188  \n",
      "\n",
      "Fold: 31  Epoch: 7  Training loss = 2.8141  Validation loss = 2.4186  \n",
      "\n",
      "Fold: 31  Epoch: 8  Training loss = 2.8139  Validation loss = 2.4191  \n",
      "\n",
      "Fold: 31  Epoch: 9  Training loss = 2.8137  Validation loss = 2.4183  \n",
      "\n",
      "Fold: 31  Epoch: 10  Training loss = 2.8134  Validation loss = 2.4172  \n",
      "\n",
      "Fold: 31  Epoch: 11  Training loss = 2.8131  Validation loss = 2.4163  \n",
      "\n",
      "Fold: 31  Epoch: 12  Training loss = 2.8129  Validation loss = 2.4153  \n",
      "\n",
      "Fold: 31  Epoch: 13  Training loss = 2.8126  Validation loss = 2.4139  \n",
      "\n",
      "Fold: 31  Epoch: 14  Training loss = 2.8124  Validation loss = 2.4129  \n",
      "\n",
      "Fold: 31  Epoch: 15  Training loss = 2.8122  Validation loss = 2.4125  \n",
      "\n",
      "Fold: 31  Epoch: 16  Training loss = 2.8120  Validation loss = 2.4126  \n",
      "\n",
      "Fold: 31  Epoch: 17  Training loss = 2.8118  Validation loss = 2.4118  \n",
      "\n",
      "Fold: 31  Epoch: 18  Training loss = 2.8115  Validation loss = 2.4104  \n",
      "\n",
      "Fold: 31  Epoch: 19  Training loss = 2.8113  Validation loss = 2.4091  \n",
      "\n",
      "Fold: 31  Epoch: 20  Training loss = 2.8111  Validation loss = 2.4085  \n",
      "\n",
      "Fold: 31  Epoch: 21  Training loss = 2.8109  Validation loss = 2.4093  \n",
      "\n",
      "Fold: 31  Epoch: 22  Training loss = 2.8106  Validation loss = 2.4083  \n",
      "\n",
      "Fold: 31  Epoch: 23  Training loss = 2.8104  Validation loss = 2.4080  \n",
      "\n",
      "Fold: 31  Epoch: 24  Training loss = 2.8102  Validation loss = 2.4069  \n",
      "\n",
      "Fold: 31  Epoch: 25  Training loss = 2.8099  Validation loss = 2.4085  \n",
      "\n",
      "Fold: 31  Epoch: 26  Training loss = 2.8098  Validation loss = 2.4080  \n",
      "\n",
      "Fold: 31  Epoch: 27  Training loss = 2.8096  Validation loss = 2.4074  \n",
      "\n",
      "Fold: 31  Epoch: 28  Training loss = 2.8093  Validation loss = 2.4058  \n",
      "\n",
      "Fold: 31  Epoch: 29  Training loss = 2.8092  Validation loss = 2.4062  \n",
      "\n",
      "Fold: 31  Epoch: 30  Training loss = 2.8090  Validation loss = 2.4044  \n",
      "\n",
      "Fold: 31  Epoch: 31  Training loss = 2.8087  Validation loss = 2.4030  \n",
      "\n",
      "Fold: 31  Epoch: 32  Training loss = 2.8085  Validation loss = 2.4023  \n",
      "\n",
      "Fold: 31  Epoch: 33  Training loss = 2.8082  Validation loss = 2.4007  \n",
      "\n",
      "Fold: 31  Epoch: 34  Training loss = 2.8080  Validation loss = 2.4006  \n",
      "\n",
      "Fold: 31  Epoch: 35  Training loss = 2.8078  Validation loss = 2.4009  \n",
      "\n",
      "Fold: 31  Epoch: 36  Training loss = 2.8075  Validation loss = 2.4003  \n",
      "\n",
      "Fold: 31  Epoch: 37  Training loss = 2.8072  Validation loss = 2.3988  \n",
      "\n",
      "Fold: 31  Epoch: 38  Training loss = 2.8070  Validation loss = 2.3977  \n",
      "\n",
      "Fold: 31  Epoch: 39  Training loss = 2.8068  Validation loss = 2.3962  \n",
      "\n",
      "Fold: 31  Epoch: 40  Training loss = 2.8065  Validation loss = 2.3943  \n",
      "\n",
      "Fold: 31  Epoch: 41  Training loss = 2.8062  Validation loss = 2.3952  \n",
      "\n",
      "Fold: 31  Epoch: 42  Training loss = 2.8061  Validation loss = 2.3954  \n",
      "\n",
      "Fold: 31  Epoch: 43  Training loss = 2.8059  Validation loss = 2.3954  \n",
      "\n",
      "Fold: 31  Epoch: 44  Training loss = 2.8057  Validation loss = 2.3945  \n",
      "\n",
      "Fold: 31  Epoch: 45  Training loss = 2.8055  Validation loss = 2.3942  \n",
      "\n",
      "Fold: 31  Epoch: 46  Training loss = 2.8053  Validation loss = 2.3944  \n",
      "\n",
      "Fold: 31  Epoch: 47  Training loss = 2.8052  Validation loss = 2.3954  \n",
      "\n",
      "Fold: 31  Epoch: 48  Training loss = 2.8049  Validation loss = 2.3944  \n",
      "\n",
      "Fold: 31  Epoch: 49  Training loss = 2.8048  Validation loss = 2.3942  \n",
      "\n",
      "Fold: 31  Epoch: 50  Training loss = 2.8046  Validation loss = 2.3946  \n",
      "\n",
      "Fold: 31  Epoch: 51  Training loss = 2.8044  Validation loss = 2.3937  \n",
      "\n",
      "Fold: 31  Epoch: 52  Training loss = 2.8042  Validation loss = 2.3935  \n",
      "\n",
      "Fold: 31  Epoch: 53  Training loss = 2.8040  Validation loss = 2.3926  \n",
      "\n",
      "Fold: 31  Epoch: 54  Training loss = 2.8038  Validation loss = 2.3919  \n",
      "\n",
      "Fold: 31  Epoch: 55  Training loss = 2.8036  Validation loss = 2.3914  \n",
      "\n",
      "Fold: 31  Epoch: 56  Training loss = 2.8034  Validation loss = 2.3901  \n",
      "\n",
      "Fold: 31  Epoch: 57  Training loss = 2.8032  Validation loss = 2.3888  \n",
      "\n",
      "Fold: 31  Epoch: 58  Training loss = 2.8030  Validation loss = 2.3891  \n",
      "\n",
      "Fold: 31  Epoch: 59  Training loss = 2.8029  Validation loss = 2.3884  \n",
      "\n",
      "Fold: 31  Epoch: 60  Training loss = 2.8027  Validation loss = 2.3880  \n",
      "\n",
      "Fold: 31  Epoch: 61  Training loss = 2.8025  Validation loss = 2.3881  \n",
      "\n",
      "Fold: 31  Epoch: 62  Training loss = 2.8023  Validation loss = 2.3871  \n",
      "\n",
      "Fold: 31  Epoch: 63  Training loss = 2.8021  Validation loss = 2.3865  \n",
      "\n",
      "Fold: 31  Epoch: 64  Training loss = 2.8019  Validation loss = 2.3867  \n",
      "\n",
      "Fold: 31  Epoch: 65  Training loss = 2.8018  Validation loss = 2.3865  \n",
      "\n",
      "Fold: 31  Epoch: 66  Training loss = 2.8017  Validation loss = 2.3866  \n",
      "\n",
      "Fold: 31  Epoch: 67  Training loss = 2.8015  Validation loss = 2.3862  \n",
      "\n",
      "Fold: 31  Epoch: 68  Training loss = 2.8013  Validation loss = 2.3858  \n",
      "\n",
      "Fold: 31  Epoch: 69  Training loss = 2.8013  Validation loss = 2.3865  \n",
      "\n",
      "Fold: 31  Epoch: 70  Training loss = 2.8010  Validation loss = 2.3852  \n",
      "\n",
      "Fold: 31  Epoch: 71  Training loss = 2.8009  Validation loss = 2.3858  \n",
      "\n",
      "Fold: 31  Epoch: 72  Training loss = 2.8009  Validation loss = 2.3863  \n",
      "\n",
      "Fold: 31  Epoch: 73  Training loss = 2.8007  Validation loss = 2.3861  \n",
      "\n",
      "Fold: 31  Epoch: 74  Training loss = 2.8005  Validation loss = 2.3847  \n",
      "\n",
      "Fold: 31  Epoch: 75  Training loss = 2.8004  Validation loss = 2.3853  \n",
      "\n",
      "Fold: 31  Epoch: 76  Training loss = 2.8002  Validation loss = 2.3846  \n",
      "\n",
      "Fold: 31  Epoch: 77  Training loss = 2.7999  Validation loss = 2.3831  \n",
      "\n",
      "Fold: 31  Epoch: 78  Training loss = 2.7997  Validation loss = 2.3820  \n",
      "\n",
      "Fold: 31  Epoch: 79  Training loss = 2.7994  Validation loss = 2.3806  \n",
      "\n",
      "Fold: 31  Epoch: 80  Training loss = 2.7992  Validation loss = 2.3797  \n",
      "\n",
      "Fold: 31  Epoch: 81  Training loss = 2.7991  Validation loss = 2.3797  \n",
      "\n",
      "Fold: 31  Epoch: 82  Training loss = 2.7988  Validation loss = 2.3779  \n",
      "\n",
      "Fold: 31  Epoch: 83  Training loss = 2.7986  Validation loss = 2.3768  \n",
      "\n",
      "Fold: 31  Epoch: 84  Training loss = 2.7985  Validation loss = 2.3772  \n",
      "\n",
      "Fold: 31  Epoch: 85  Training loss = 2.7983  Validation loss = 2.3762  \n",
      "\n",
      "Fold: 31  Epoch: 86  Training loss = 2.7981  Validation loss = 2.3761  \n",
      "\n",
      "Fold: 31  Epoch: 87  Training loss = 2.7978  Validation loss = 2.3742  \n",
      "\n",
      "Fold: 31  Epoch: 88  Training loss = 2.7977  Validation loss = 2.3743  \n",
      "\n",
      "Fold: 31  Epoch: 89  Training loss = 2.7975  Validation loss = 2.3740  \n",
      "\n",
      "Fold: 31  Epoch: 90  Training loss = 2.7973  Validation loss = 2.3733  \n",
      "\n",
      "Fold: 31  Epoch: 91  Training loss = 2.7972  Validation loss = 2.3727  \n",
      "\n",
      "Fold: 31  Epoch: 92  Training loss = 2.7971  Validation loss = 2.3727  \n",
      "\n",
      "Fold: 31  Epoch: 93  Training loss = 2.7970  Validation loss = 2.3728  \n",
      "\n",
      "Fold: 31  Epoch: 94  Training loss = 2.7968  Validation loss = 2.3718  \n",
      "\n",
      "Fold: 31  Epoch: 95  Training loss = 2.7966  Validation loss = 2.3717  \n",
      "\n",
      "Fold: 31  Epoch: 96  Training loss = 2.7963  Validation loss = 2.3692  \n",
      "\n",
      "Fold: 31  Epoch: 97  Training loss = 2.7961  Validation loss = 2.3684  \n",
      "\n",
      "Fold: 31  Epoch: 98  Training loss = 2.7960  Validation loss = 2.3689  \n",
      "\n",
      "Fold: 31  Epoch: 99  Training loss = 2.7958  Validation loss = 2.3683  \n",
      "\n",
      "Fold: 31  Epoch: 100  Training loss = 2.7957  Validation loss = 2.3689  \n",
      "\n",
      "Fold: 31  Epoch: 101  Training loss = 2.7956  Validation loss = 2.3688  \n",
      "\n",
      "Fold: 31  Epoch: 102  Training loss = 2.7954  Validation loss = 2.3678  \n",
      "\n",
      "Fold: 31  Epoch: 103  Training loss = 2.7951  Validation loss = 2.3666  \n",
      "\n",
      "Fold: 31  Epoch: 104  Training loss = 2.7949  Validation loss = 2.3658  \n",
      "\n",
      "Fold: 31  Epoch: 105  Training loss = 2.7949  Validation loss = 2.3670  \n",
      "\n",
      "Fold: 31  Epoch: 106  Training loss = 2.7947  Validation loss = 2.3662  \n",
      "\n",
      "Fold: 31  Epoch: 107  Training loss = 2.7946  Validation loss = 2.3669  \n",
      "\n",
      "Fold: 31  Epoch: 108  Training loss = 2.7943  Validation loss = 2.3657  \n",
      "\n",
      "Fold: 31  Epoch: 109  Training loss = 2.7941  Validation loss = 2.3650  \n",
      "\n",
      "Fold: 31  Epoch: 110  Training loss = 2.7939  Validation loss = 2.3643  \n",
      "\n",
      "Fold: 31  Epoch: 111  Training loss = 2.7937  Validation loss = 2.3633  \n",
      "\n",
      "Fold: 31  Epoch: 112  Training loss = 2.7935  Validation loss = 2.3625  \n",
      "\n",
      "Fold: 31  Epoch: 113  Training loss = 2.7933  Validation loss = 2.3614  \n",
      "\n",
      "Fold: 31  Epoch: 114  Training loss = 2.7931  Validation loss = 2.3610  \n",
      "\n",
      "Fold: 31  Epoch: 115  Training loss = 2.7929  Validation loss = 2.3601  \n",
      "\n",
      "Fold: 31  Epoch: 116  Training loss = 2.7928  Validation loss = 2.3606  \n",
      "\n",
      "Fold: 31  Epoch: 117  Training loss = 2.7926  Validation loss = 2.3603  \n",
      "\n",
      "Fold: 31  Epoch: 118  Training loss = 2.7925  Validation loss = 2.3607  \n",
      "\n",
      "Fold: 31  Epoch: 119  Training loss = 2.7925  Validation loss = 2.3619  \n",
      "\n",
      "Fold: 31  Epoch: 120  Training loss = 2.7923  Validation loss = 2.3609  \n",
      "\n",
      "Fold: 31  Epoch: 121  Training loss = 2.7922  Validation loss = 2.3618  \n",
      "\n",
      "Fold: 31  Epoch: 122  Training loss = 2.7921  Validation loss = 2.3613  \n",
      "\n",
      "Fold: 31  Epoch: 123  Training loss = 2.7919  Validation loss = 2.3602  \n",
      "\n",
      "Fold: 31  Epoch: 124  Training loss = 2.7917  Validation loss = 2.3591  \n",
      "\n",
      "Fold: 31  Epoch: 125  Training loss = 2.7915  Validation loss = 2.3581  \n",
      "\n",
      "Fold: 31  Epoch: 126  Training loss = 2.7913  Validation loss = 2.3571  \n",
      "\n",
      "Fold: 31  Epoch: 127  Training loss = 2.7911  Validation loss = 2.3556  \n",
      "\n",
      "Fold: 31  Epoch: 128  Training loss = 2.7909  Validation loss = 2.3541  \n",
      "\n",
      "Fold: 31  Epoch: 129  Training loss = 2.7907  Validation loss = 2.3545  \n",
      "\n",
      "Fold: 31  Epoch: 130  Training loss = 2.7906  Validation loss = 2.3538  \n",
      "\n",
      "Fold: 31  Epoch: 131  Training loss = 2.7904  Validation loss = 2.3533  \n",
      "\n",
      "Fold: 31  Epoch: 132  Training loss = 2.7901  Validation loss = 2.3521  \n",
      "\n",
      "Fold: 31  Epoch: 133  Training loss = 2.7899  Validation loss = 2.3513  \n",
      "\n",
      "Fold: 31  Epoch: 134  Training loss = 2.7899  Validation loss = 2.3520  \n",
      "\n",
      "Fold: 31  Epoch: 135  Training loss = 2.7897  Validation loss = 2.3507  \n",
      "\n",
      "Fold: 31  Epoch: 136  Training loss = 2.7895  Validation loss = 2.3498  \n",
      "\n",
      "Fold: 31  Epoch: 137  Training loss = 2.7894  Validation loss = 2.3494  \n",
      "\n",
      "Fold: 31  Epoch: 138  Training loss = 2.7891  Validation loss = 2.3481  \n",
      "\n",
      "Fold: 31  Epoch: 139  Training loss = 2.7888  Validation loss = 2.3463  \n",
      "\n",
      "Fold: 31  Epoch: 140  Training loss = 2.7886  Validation loss = 2.3457  \n",
      "\n",
      "Fold: 31  Epoch: 141  Training loss = 2.7884  Validation loss = 2.3452  \n",
      "\n",
      "Fold: 31  Epoch: 142  Training loss = 2.7882  Validation loss = 2.3450  \n",
      "\n",
      "Fold: 31  Epoch: 143  Training loss = 2.7881  Validation loss = 2.3459  \n",
      "\n",
      "Fold: 31  Epoch: 144  Training loss = 2.7878  Validation loss = 2.3438  \n",
      "\n",
      "Fold: 31  Epoch: 145  Training loss = 2.7876  Validation loss = 2.3433  \n",
      "\n",
      "Fold: 31  Epoch: 146  Training loss = 2.7875  Validation loss = 2.3426  \n",
      "\n",
      "Fold: 31  Epoch: 147  Training loss = 2.7873  Validation loss = 2.3419  \n",
      "\n",
      "Fold: 31  Epoch: 148  Training loss = 2.7871  Validation loss = 2.3412  \n",
      "\n",
      "Fold: 31  Epoch: 149  Training loss = 2.7868  Validation loss = 2.3399  \n",
      "\n",
      "Fold: 31  Epoch: 150  Training loss = 2.7866  Validation loss = 2.3396  \n",
      "\n",
      "Fold: 31  Epoch: 151  Training loss = 2.7865  Validation loss = 2.3406  \n",
      "\n",
      "Fold: 31  Epoch: 152  Training loss = 2.7863  Validation loss = 2.3393  \n",
      "\n",
      "Fold: 31  Epoch: 153  Training loss = 2.7860  Validation loss = 2.3382  \n",
      "\n",
      "Fold: 31  Epoch: 154  Training loss = 2.7859  Validation loss = 2.3384  \n",
      "\n",
      "Fold: 31  Epoch: 155  Training loss = 2.7857  Validation loss = 2.3376  \n",
      "\n",
      "Fold: 31  Epoch: 156  Training loss = 2.7856  Validation loss = 2.3378  \n",
      "\n",
      "Fold: 31  Epoch: 157  Training loss = 2.7854  Validation loss = 2.3364  \n",
      "\n",
      "Fold: 31  Epoch: 158  Training loss = 2.7852  Validation loss = 2.3350  \n",
      "\n",
      "Fold: 31  Epoch: 159  Training loss = 2.7850  Validation loss = 2.3339  \n",
      "\n",
      "Fold: 31  Epoch: 160  Training loss = 2.7848  Validation loss = 2.3331  \n",
      "\n",
      "Fold: 31  Epoch: 161  Training loss = 2.7846  Validation loss = 2.3335  \n",
      "\n",
      "Fold: 31  Epoch: 162  Training loss = 2.7844  Validation loss = 2.3318  \n",
      "\n",
      "Fold: 31  Epoch: 163  Training loss = 2.7843  Validation loss = 2.3326  \n",
      "\n",
      "Fold: 31  Epoch: 164  Training loss = 2.7842  Validation loss = 2.3333  \n",
      "\n",
      "Fold: 31  Epoch: 165  Training loss = 2.7841  Validation loss = 2.3329  \n",
      "\n",
      "Fold: 31  Epoch: 166  Training loss = 2.7839  Validation loss = 2.3329  \n",
      "\n",
      "Fold: 31  Epoch: 167  Training loss = 2.7837  Validation loss = 2.3322  \n",
      "\n",
      "Fold: 31  Epoch: 168  Training loss = 2.7836  Validation loss = 2.3323  \n",
      "\n",
      "Fold: 31  Epoch: 169  Training loss = 2.7835  Validation loss = 2.3322  \n",
      "\n",
      "Fold: 31  Epoch: 170  Training loss = 2.7832  Validation loss = 2.3305  \n",
      "\n",
      "Fold: 31  Epoch: 171  Training loss = 2.7830  Validation loss = 2.3289  \n",
      "\n",
      "Fold: 31  Epoch: 172  Training loss = 2.7829  Validation loss = 2.3291  \n",
      "\n",
      "Fold: 31  Epoch: 173  Training loss = 2.7827  Validation loss = 2.3277  \n",
      "\n",
      "Fold: 31  Epoch: 174  Training loss = 2.7826  Validation loss = 2.3274  \n",
      "\n",
      "Fold: 31  Epoch: 175  Training loss = 2.7823  Validation loss = 2.3259  \n",
      "\n",
      "Fold: 31  Epoch: 176  Training loss = 2.7821  Validation loss = 2.3251  \n",
      "\n",
      "Fold: 31  Epoch: 177  Training loss = 2.7819  Validation loss = 2.3243  \n",
      "\n",
      "Fold: 31  Epoch: 178  Training loss = 2.7817  Validation loss = 2.3231  \n",
      "\n",
      "Fold: 31  Epoch: 179  Training loss = 2.7817  Validation loss = 2.3245  \n",
      "\n",
      "Fold: 31  Epoch: 180  Training loss = 2.7815  Validation loss = 2.3238  \n",
      "\n",
      "Fold: 31  Epoch: 181  Training loss = 2.7813  Validation loss = 2.3233  \n",
      "\n",
      "Fold: 31  Epoch: 182  Training loss = 2.7811  Validation loss = 2.3228  \n",
      "\n",
      "Fold: 31  Epoch: 183  Training loss = 2.7807  Validation loss = 2.3208  \n",
      "\n",
      "Fold: 31  Epoch: 184  Training loss = 2.7806  Validation loss = 2.3209  \n",
      "\n",
      "Fold: 31  Epoch: 185  Training loss = 2.7802  Validation loss = 2.3176  \n",
      "\n",
      "Fold: 31  Epoch: 186  Training loss = 2.7799  Validation loss = 2.3172  \n",
      "\n",
      "Fold: 31  Epoch: 187  Training loss = 2.7798  Validation loss = 2.3169  \n",
      "\n",
      "Fold: 31  Epoch: 188  Training loss = 2.7794  Validation loss = 2.3146  \n",
      "\n",
      "Fold: 31  Epoch: 189  Training loss = 2.7792  Validation loss = 2.3132  \n",
      "\n",
      "Fold: 31  Epoch: 190  Training loss = 2.7790  Validation loss = 2.3128  \n",
      "\n",
      "Fold: 31  Epoch: 191  Training loss = 2.7787  Validation loss = 2.3106  \n",
      "\n",
      "Fold: 31  Epoch: 192  Training loss = 2.7785  Validation loss = 2.3107  \n",
      "\n",
      "Fold: 31  Epoch: 193  Training loss = 2.7783  Validation loss = 2.3093  \n",
      "\n",
      "Fold: 31  Epoch: 194  Training loss = 2.7780  Validation loss = 2.3083  \n",
      "\n",
      "Fold: 31  Epoch: 195  Training loss = 2.7778  Validation loss = 2.3070  \n",
      "\n",
      "Fold: 31  Epoch: 196  Training loss = 2.7775  Validation loss = 2.3060  \n",
      "\n",
      "Fold: 31  Epoch: 197  Training loss = 2.7771  Validation loss = 2.3034  \n",
      "\n",
      "Fold: 31  Epoch: 198  Training loss = 2.7769  Validation loss = 2.3025  \n",
      "\n",
      "Fold: 31  Epoch: 199  Training loss = 2.7766  Validation loss = 2.3019  \n",
      "\n",
      "Fold: 31  Epoch: 200  Training loss = 2.7764  Validation loss = 2.3010  \n",
      "\n",
      "Fold: 31  Epoch: 201  Training loss = 2.7762  Validation loss = 2.3007  \n",
      "\n",
      "Fold: 31  Epoch: 202  Training loss = 2.7760  Validation loss = 2.2997  \n",
      "\n",
      "Fold: 31  Epoch: 203  Training loss = 2.7757  Validation loss = 2.2988  \n",
      "\n",
      "Fold: 31  Epoch: 204  Training loss = 2.7756  Validation loss = 2.2988  \n",
      "\n",
      "Fold: 31  Epoch: 205  Training loss = 2.7753  Validation loss = 2.2977  \n",
      "\n",
      "Fold: 31  Epoch: 206  Training loss = 2.7750  Validation loss = 2.2957  \n",
      "\n",
      "Fold: 31  Epoch: 207  Training loss = 2.7748  Validation loss = 2.2951  \n",
      "\n",
      "Fold: 31  Epoch: 208  Training loss = 2.7747  Validation loss = 2.2953  \n",
      "\n",
      "Fold: 31  Epoch: 209  Training loss = 2.7744  Validation loss = 2.2946  \n",
      "\n",
      "Fold: 31  Epoch: 210  Training loss = 2.7742  Validation loss = 2.2945  \n",
      "\n",
      "Fold: 31  Epoch: 211  Training loss = 2.7741  Validation loss = 2.2952  \n",
      "\n",
      "Fold: 31  Epoch: 212  Training loss = 2.7740  Validation loss = 2.2957  \n",
      "\n",
      "Fold: 31  Epoch: 213  Training loss = 2.7739  Validation loss = 2.2969  \n",
      "\n",
      "Fold: 31  Epoch: 214  Training loss = 2.7738  Validation loss = 2.2962  \n",
      "\n",
      "Fold: 31  Epoch: 215  Training loss = 2.7735  Validation loss = 2.2955  \n",
      "\n",
      "Fold: 31  Epoch: 216  Training loss = 2.7732  Validation loss = 2.2937  \n",
      "\n",
      "Fold: 31  Epoch: 217  Training loss = 2.7731  Validation loss = 2.2943  \n",
      "\n",
      "Fold: 31  Epoch: 218  Training loss = 2.7729  Validation loss = 2.2939  \n",
      "\n",
      "Fold: 31  Epoch: 219  Training loss = 2.7728  Validation loss = 2.2937  \n",
      "\n",
      "Fold: 31  Epoch: 220  Training loss = 2.7726  Validation loss = 2.2935  \n",
      "\n",
      "Fold: 31  Epoch: 221  Training loss = 2.7723  Validation loss = 2.2916  \n",
      "\n",
      "Fold: 31  Epoch: 222  Training loss = 2.7721  Validation loss = 2.2906  \n",
      "\n",
      "Fold: 31  Epoch: 223  Training loss = 2.7719  Validation loss = 2.2898  \n",
      "\n",
      "Fold: 31  Epoch: 224  Training loss = 2.7718  Validation loss = 2.2894  \n",
      "\n",
      "Fold: 31  Epoch: 225  Training loss = 2.7715  Validation loss = 2.2877  \n",
      "\n",
      "Fold: 31  Epoch: 226  Training loss = 2.7713  Validation loss = 2.2868  \n",
      "\n",
      "Fold: 31  Epoch: 227  Training loss = 2.7711  Validation loss = 2.2858  \n",
      "\n",
      "Fold: 31  Epoch: 228  Training loss = 2.7709  Validation loss = 2.2853  \n",
      "\n",
      "Fold: 31  Epoch: 229  Training loss = 2.7706  Validation loss = 2.2835  \n",
      "\n",
      "Fold: 31  Epoch: 230  Training loss = 2.7704  Validation loss = 2.2826  \n",
      "\n",
      "Fold: 31  Epoch: 231  Training loss = 2.7703  Validation loss = 2.2815  \n",
      "\n",
      "Fold: 31  Epoch: 232  Training loss = 2.7701  Validation loss = 2.2804  \n",
      "\n",
      "Fold: 31  Epoch: 233  Training loss = 2.7699  Validation loss = 2.2801  \n",
      "\n",
      "Fold: 31  Epoch: 234  Training loss = 2.7697  Validation loss = 2.2776  \n",
      "\n",
      "Fold: 31  Epoch: 235  Training loss = 2.7695  Validation loss = 2.2773  \n",
      "\n",
      "Fold: 31  Epoch: 236  Training loss = 2.7694  Validation loss = 2.2777  \n",
      "\n",
      "Fold: 31  Epoch: 237  Training loss = 2.7691  Validation loss = 2.2768  \n",
      "\n",
      "Fold: 31  Epoch: 238  Training loss = 2.7689  Validation loss = 2.2749  \n",
      "\n",
      "Fold: 31  Epoch: 239  Training loss = 2.7687  Validation loss = 2.2742  \n",
      "\n",
      "Fold: 31  Epoch: 240  Training loss = 2.7684  Validation loss = 2.2713  \n",
      "\n",
      "Fold: 31  Epoch: 241  Training loss = 2.7682  Validation loss = 2.2700  \n",
      "\n",
      "Fold: 31  Epoch: 242  Training loss = 2.7681  Validation loss = 2.2704  \n",
      "\n",
      "Fold: 31  Epoch: 243  Training loss = 2.7680  Validation loss = 2.2701  \n",
      "\n",
      "Fold: 31  Epoch: 244  Training loss = 2.7678  Validation loss = 2.2695  \n",
      "\n",
      "Fold: 31  Epoch: 245  Training loss = 2.7676  Validation loss = 2.2685  \n",
      "\n",
      "Fold: 31  Epoch: 246  Training loss = 2.7674  Validation loss = 2.2685  \n",
      "\n",
      "Fold: 31  Epoch: 247  Training loss = 2.7672  Validation loss = 2.2669  \n",
      "\n",
      "Fold: 31  Epoch: 248  Training loss = 2.7671  Validation loss = 2.2671  \n",
      "\n",
      "Fold: 31  Epoch: 249  Training loss = 2.7668  Validation loss = 2.2666  \n",
      "\n",
      "Fold: 31  Epoch: 250  Training loss = 2.7666  Validation loss = 2.2660  \n",
      "\n",
      "Fold: 31  Epoch: 251  Training loss = 2.7665  Validation loss = 2.2652  \n",
      "\n",
      "Fold: 31  Epoch: 252  Training loss = 2.7663  Validation loss = 2.2636  \n",
      "\n",
      "Fold: 31  Epoch: 253  Training loss = 2.7661  Validation loss = 2.2629  \n",
      "\n",
      "Fold: 31  Epoch: 254  Training loss = 2.7659  Validation loss = 2.2625  \n",
      "\n",
      "Fold: 31  Epoch: 255  Training loss = 2.7657  Validation loss = 2.2611  \n",
      "\n",
      "Fold: 31  Epoch: 256  Training loss = 2.7655  Validation loss = 2.2606  \n",
      "\n",
      "Fold: 31  Epoch: 257  Training loss = 2.7654  Validation loss = 2.2608  \n",
      "\n",
      "Fold: 31  Epoch: 258  Training loss = 2.7652  Validation loss = 2.2595  \n",
      "\n",
      "Fold: 31  Epoch: 259  Training loss = 2.7651  Validation loss = 2.2596  \n",
      "\n",
      "Fold: 31  Epoch: 260  Training loss = 2.7650  Validation loss = 2.2600  \n",
      "\n",
      "Fold: 31  Epoch: 261  Training loss = 2.7648  Validation loss = 2.2577  \n",
      "\n",
      "Fold: 31  Epoch: 262  Training loss = 2.7646  Validation loss = 2.2564  \n",
      "\n",
      "Fold: 31  Epoch: 263  Training loss = 2.7644  Validation loss = 2.2543  \n",
      "\n",
      "Fold: 31  Epoch: 264  Training loss = 2.7642  Validation loss = 2.2538  \n",
      "\n",
      "Fold: 31  Epoch: 265  Training loss = 2.7640  Validation loss = 2.2521  \n",
      "\n",
      "Fold: 31  Epoch: 266  Training loss = 2.7638  Validation loss = 2.2516  \n",
      "\n",
      "Fold: 31  Epoch: 267  Training loss = 2.7636  Validation loss = 2.2492  \n",
      "\n",
      "Fold: 31  Epoch: 268  Training loss = 2.7635  Validation loss = 2.2482  \n",
      "\n",
      "Fold: 31  Epoch: 269  Training loss = 2.7634  Validation loss = 2.2484  \n",
      "\n",
      "Fold: 31  Epoch: 270  Training loss = 2.7632  Validation loss = 2.2484  \n",
      "\n",
      "Fold: 31  Epoch: 271  Training loss = 2.7630  Validation loss = 2.2483  \n",
      "\n",
      "Fold: 31  Epoch: 272  Training loss = 2.7629  Validation loss = 2.2479  \n",
      "\n",
      "Fold: 31  Epoch: 273  Training loss = 2.7627  Validation loss = 2.2474  \n",
      "\n",
      "Fold: 31  Epoch: 274  Training loss = 2.7626  Validation loss = 2.2477  \n",
      "\n",
      "Fold: 31  Epoch: 275  Training loss = 2.7625  Validation loss = 2.2475  \n",
      "\n",
      "Fold: 31  Epoch: 276  Training loss = 2.7623  Validation loss = 2.2463  \n",
      "\n",
      "Fold: 31  Epoch: 277  Training loss = 2.7621  Validation loss = 2.2458  \n",
      "\n",
      "Fold: 31  Epoch: 278  Training loss = 2.7619  Validation loss = 2.2448  \n",
      "\n",
      "Fold: 31  Epoch: 279  Training loss = 2.7618  Validation loss = 2.2452  \n",
      "\n",
      "Fold: 31  Epoch: 280  Training loss = 2.7616  Validation loss = 2.2440  \n",
      "\n",
      "Fold: 31  Epoch: 281  Training loss = 2.7615  Validation loss = 2.2435  \n",
      "\n",
      "Fold: 31  Epoch: 282  Training loss = 2.7613  Validation loss = 2.2438  \n",
      "\n",
      "Fold: 31  Epoch: 283  Training loss = 2.7612  Validation loss = 2.2443  \n",
      "\n",
      "Fold: 31  Epoch: 284  Training loss = 2.7610  Validation loss = 2.2443  \n",
      "\n",
      "Fold: 31  Epoch: 285  Training loss = 2.7609  Validation loss = 2.2445  \n",
      "\n",
      "Fold: 31  Epoch: 286  Training loss = 2.7608  Validation loss = 2.2441  \n",
      "\n",
      "Fold: 31  Epoch: 287  Training loss = 2.7606  Validation loss = 2.2432  \n",
      "\n",
      "Fold: 31  Epoch: 288  Training loss = 2.7604  Validation loss = 2.2425  \n",
      "\n",
      "Fold: 31  Epoch: 289  Training loss = 2.7603  Validation loss = 2.2416  \n",
      "\n",
      "Fold: 31  Epoch: 290  Training loss = 2.7601  Validation loss = 2.2421  \n",
      "\n",
      "Fold: 31  Epoch: 291  Training loss = 2.7600  Validation loss = 2.2413  \n",
      "\n",
      "Fold: 31  Epoch: 292  Training loss = 2.7598  Validation loss = 2.2398  \n",
      "\n",
      "Fold: 31  Epoch: 293  Training loss = 2.7596  Validation loss = 2.2390  \n",
      "\n",
      "Fold: 31  Epoch: 294  Training loss = 2.7595  Validation loss = 2.2384  \n",
      "\n",
      "Fold: 31  Epoch: 295  Training loss = 2.7594  Validation loss = 2.2388  \n",
      "\n",
      "Fold: 31  Epoch: 296  Training loss = 2.7593  Validation loss = 2.2393  \n",
      "\n",
      "Fold: 31  Epoch: 297  Training loss = 2.7592  Validation loss = 2.2390  \n",
      "\n",
      "Fold: 31  Epoch: 298  Training loss = 2.7591  Validation loss = 2.2387  \n",
      "\n",
      "Fold: 31  Epoch: 299  Training loss = 2.7589  Validation loss = 2.2379  \n",
      "\n",
      "Fold: 31  Epoch: 300  Training loss = 2.7588  Validation loss = 2.2379  \n",
      "\n",
      "Fold: 31  Epoch: 301  Training loss = 2.7586  Validation loss = 2.2379  \n",
      "\n",
      "Fold: 31  Epoch: 302  Training loss = 2.7584  Validation loss = 2.2370  \n",
      "\n",
      "Fold: 31  Epoch: 303  Training loss = 2.7582  Validation loss = 2.2357  \n",
      "\n",
      "Fold: 31  Epoch: 304  Training loss = 2.7580  Validation loss = 2.2338  \n",
      "\n",
      "Fold: 31  Epoch: 305  Training loss = 2.7579  Validation loss = 2.2334  \n",
      "\n",
      "Fold: 31  Epoch: 306  Training loss = 2.7577  Validation loss = 2.2322  \n",
      "\n",
      "Fold: 31  Epoch: 307  Training loss = 2.7575  Validation loss = 2.2308  \n",
      "\n",
      "Fold: 31  Epoch: 308  Training loss = 2.7573  Validation loss = 2.2291  \n",
      "\n",
      "Fold: 31  Epoch: 309  Training loss = 2.7572  Validation loss = 2.2285  \n",
      "\n",
      "Fold: 31  Epoch: 310  Training loss = 2.7570  Validation loss = 2.2276  \n",
      "\n",
      "Fold: 31  Epoch: 311  Training loss = 2.7569  Validation loss = 2.2279  \n",
      "\n",
      "Fold: 31  Epoch: 312  Training loss = 2.7567  Validation loss = 2.2264  \n",
      "\n",
      "Fold: 31  Epoch: 313  Training loss = 2.7565  Validation loss = 2.2258  \n",
      "\n",
      "Fold: 31  Epoch: 314  Training loss = 2.7564  Validation loss = 2.2251  \n",
      "\n",
      "Fold: 31  Epoch: 315  Training loss = 2.7563  Validation loss = 2.2242  \n",
      "\n",
      "Fold: 31  Epoch: 316  Training loss = 2.7561  Validation loss = 2.2243  \n",
      "\n",
      "Fold: 31  Epoch: 317  Training loss = 2.7560  Validation loss = 2.2250  \n",
      "\n",
      "Fold: 31  Epoch: 318  Training loss = 2.7559  Validation loss = 2.2253  \n",
      "\n",
      "Fold: 31  Epoch: 319  Training loss = 2.7558  Validation loss = 2.2244  \n",
      "\n",
      "Fold: 31  Epoch: 320  Training loss = 2.7556  Validation loss = 2.2239  \n",
      "\n",
      "Fold: 31  Epoch: 321  Training loss = 2.7554  Validation loss = 2.2217  \n",
      "\n",
      "Fold: 31  Epoch: 322  Training loss = 2.7553  Validation loss = 2.2209  \n",
      "\n",
      "Fold: 31  Epoch: 323  Training loss = 2.7552  Validation loss = 2.2210  \n",
      "\n",
      "Fold: 31  Epoch: 324  Training loss = 2.7551  Validation loss = 2.2217  \n",
      "\n",
      "Fold: 31  Epoch: 325  Training loss = 2.7550  Validation loss = 2.2214  \n",
      "\n",
      "Fold: 31  Epoch: 326  Training loss = 2.7549  Validation loss = 2.2214  \n",
      "\n",
      "Fold: 31  Epoch: 327  Training loss = 2.7547  Validation loss = 2.2213  \n",
      "\n",
      "Fold: 31  Epoch: 328  Training loss = 2.7546  Validation loss = 2.2230  \n",
      "\n",
      "Fold: 31  Epoch: 329  Training loss = 2.7546  Validation loss = 2.2237  \n",
      "\n",
      "Fold: 31  Epoch: 330  Training loss = 2.7545  Validation loss = 2.2244  \n",
      "\n",
      "Fold: 31  Epoch: 331  Training loss = 2.7544  Validation loss = 2.2240  \n",
      "\n",
      "Fold: 31  Epoch: 332  Training loss = 2.7543  Validation loss = 2.2247  \n",
      "\n",
      "Fold: 31  Epoch: 333  Training loss = 2.7542  Validation loss = 2.2242  \n",
      "\n",
      "Fold: 31  Epoch: 334  Training loss = 2.7540  Validation loss = 2.2232  \n",
      "\n",
      "Fold: 31  Epoch: 335  Training loss = 2.7539  Validation loss = 2.2229  \n",
      "\n",
      "Fold: 31  Epoch: 336  Training loss = 2.7537  Validation loss = 2.2226  \n",
      "\n",
      "Fold: 31  Epoch: 337  Training loss = 2.7536  Validation loss = 2.2230  \n",
      "\n",
      "Fold: 31  Epoch: 338  Training loss = 2.7535  Validation loss = 2.2223  \n",
      "\n",
      "Fold: 31  Epoch: 339  Training loss = 2.7535  Validation loss = 2.2227  \n",
      "\n",
      "Fold: 31  Epoch: 340  Training loss = 2.7533  Validation loss = 2.2226  \n",
      "\n",
      "Fold: 31  Epoch: 341  Training loss = 2.7533  Validation loss = 2.2232  \n",
      "\n",
      "Fold: 31  Epoch: 342  Training loss = 2.7531  Validation loss = 2.2226  \n",
      "\n",
      "Fold: 31  Epoch: 343  Training loss = 2.7530  Validation loss = 2.2224  \n",
      "\n",
      "Fold: 31  Epoch: 344  Training loss = 2.7528  Validation loss = 2.2208  \n",
      "\n",
      "Fold: 31  Epoch: 345  Training loss = 2.7526  Validation loss = 2.2189  \n",
      "\n",
      "Fold: 31  Epoch: 346  Training loss = 2.7525  Validation loss = 2.2195  \n",
      "\n",
      "Fold: 31  Epoch: 347  Training loss = 2.7524  Validation loss = 2.2195  \n",
      "\n",
      "Fold: 31  Epoch: 348  Training loss = 2.7523  Validation loss = 2.2201  \n",
      "\n",
      "Fold: 31  Epoch: 349  Training loss = 2.7522  Validation loss = 2.2195  \n",
      "\n",
      "Fold: 31  Epoch: 350  Training loss = 2.7521  Validation loss = 2.2199  \n",
      "\n",
      "Fold: 31  Epoch: 351  Training loss = 2.7519  Validation loss = 2.2192  \n",
      "\n",
      "Fold: 31  Epoch: 352  Training loss = 2.7519  Validation loss = 2.2189  \n",
      "\n",
      "Fold: 31  Epoch: 353  Training loss = 2.7517  Validation loss = 2.2182  \n",
      "\n",
      "Fold: 31  Epoch: 354  Training loss = 2.7516  Validation loss = 2.2183  \n",
      "\n",
      "Fold: 31  Epoch: 355  Training loss = 2.7515  Validation loss = 2.2191  \n",
      "\n",
      "Fold: 31  Epoch: 356  Training loss = 2.7514  Validation loss = 2.2194  \n",
      "\n",
      "Fold: 31  Epoch: 357  Training loss = 2.7511  Validation loss = 2.2171  \n",
      "\n",
      "Fold: 31  Epoch: 358  Training loss = 2.7510  Validation loss = 2.2167  \n",
      "\n",
      "Fold: 31  Epoch: 359  Training loss = 2.7508  Validation loss = 2.2145  \n",
      "\n",
      "Fold: 31  Epoch: 360  Training loss = 2.7506  Validation loss = 2.2131  \n",
      "\n",
      "Fold: 31  Epoch: 361  Training loss = 2.7504  Validation loss = 2.2117  \n",
      "\n",
      "Fold: 31  Epoch: 362  Training loss = 2.7503  Validation loss = 2.2124  \n",
      "\n",
      "Fold: 31  Epoch: 363  Training loss = 2.7502  Validation loss = 2.2121  \n",
      "\n",
      "Fold: 31  Epoch: 364  Training loss = 2.7501  Validation loss = 2.2126  \n",
      "\n",
      "Fold: 31  Epoch: 365  Training loss = 2.7500  Validation loss = 2.2127  \n",
      "\n",
      "Fold: 31  Epoch: 366  Training loss = 2.7499  Validation loss = 2.2128  \n",
      "\n",
      "Fold: 31  Epoch: 367  Training loss = 2.7497  Validation loss = 2.2111  \n",
      "\n",
      "Fold: 31  Epoch: 368  Training loss = 2.7496  Validation loss = 2.2119  \n",
      "\n",
      "Fold: 31  Epoch: 369  Training loss = 2.7495  Validation loss = 2.2113  \n",
      "\n",
      "Fold: 31  Epoch: 370  Training loss = 2.7493  Validation loss = 2.2107  \n",
      "\n",
      "Fold: 31  Epoch: 371  Training loss = 2.7492  Validation loss = 2.2106  \n",
      "\n",
      "Fold: 31  Epoch: 372  Training loss = 2.7490  Validation loss = 2.2101  \n",
      "\n",
      "Fold: 31  Epoch: 373  Training loss = 2.7489  Validation loss = 2.2089  \n",
      "\n",
      "Fold: 31  Epoch: 374  Training loss = 2.7488  Validation loss = 2.2092  \n",
      "\n",
      "Fold: 31  Epoch: 375  Training loss = 2.7486  Validation loss = 2.2064  \n",
      "\n",
      "Fold: 31  Epoch: 376  Training loss = 2.7484  Validation loss = 2.2055  \n",
      "\n",
      "Fold: 31  Epoch: 377  Training loss = 2.7483  Validation loss = 2.2045  \n",
      "\n",
      "Fold: 31  Epoch: 378  Training loss = 2.7481  Validation loss = 2.2042  \n",
      "\n",
      "Fold: 31  Epoch: 379  Training loss = 2.7479  Validation loss = 2.2033  \n",
      "\n",
      "Fold: 31  Epoch: 380  Training loss = 2.7478  Validation loss = 2.2036  \n",
      "\n",
      "Fold: 31  Epoch: 381  Training loss = 2.7476  Validation loss = 2.2016  \n",
      "\n",
      "Fold: 31  Epoch: 382  Training loss = 2.7475  Validation loss = 2.2015  \n",
      "\n",
      "Fold: 31  Epoch: 383  Training loss = 2.7473  Validation loss = 2.2005  \n",
      "\n",
      "Fold: 31  Epoch: 384  Training loss = 2.7472  Validation loss = 2.1997  \n",
      "\n",
      "Fold: 31  Epoch: 385  Training loss = 2.7471  Validation loss = 2.1990  \n",
      "\n",
      "Fold: 31  Epoch: 386  Training loss = 2.7469  Validation loss = 2.1990  \n",
      "\n",
      "Fold: 31  Epoch: 387  Training loss = 2.7468  Validation loss = 2.1985  \n",
      "\n",
      "Fold: 31  Epoch: 388  Training loss = 2.7467  Validation loss = 2.1985  \n",
      "\n",
      "Fold: 31  Epoch: 389  Training loss = 2.7465  Validation loss = 2.1978  \n",
      "\n",
      "Fold: 31  Epoch: 390  Training loss = 2.7464  Validation loss = 2.1973  \n",
      "\n",
      "Fold: 31  Epoch: 391  Training loss = 2.7462  Validation loss = 2.1973  \n",
      "\n",
      "Fold: 31  Epoch: 392  Training loss = 2.7461  Validation loss = 2.1966  \n",
      "\n",
      "Fold: 31  Epoch: 393  Training loss = 2.7460  Validation loss = 2.1976  \n",
      "\n",
      "Fold: 31  Epoch: 394  Training loss = 2.7459  Validation loss = 2.1968  \n",
      "\n",
      "Fold: 31  Epoch: 395  Training loss = 2.7457  Validation loss = 2.1958  \n",
      "\n",
      "Fold: 31  Epoch: 396  Training loss = 2.7456  Validation loss = 2.1953  \n",
      "\n",
      "Fold: 31  Epoch: 397  Training loss = 2.7455  Validation loss = 2.1948  \n",
      "\n",
      "Fold: 31  Epoch: 398  Training loss = 2.7454  Validation loss = 2.1949  \n",
      "\n",
      "Fold: 31  Epoch: 399  Training loss = 2.7452  Validation loss = 2.1936  \n",
      "\n",
      "Fold: 31  Epoch: 400  Training loss = 2.7451  Validation loss = 2.1930  \n",
      "\n",
      "Fold: 31  Epoch: 401  Training loss = 2.7449  Validation loss = 2.1919  \n",
      "\n",
      "Fold: 31  Epoch: 402  Training loss = 2.7447  Validation loss = 2.1910  \n",
      "\n",
      "Fold: 31  Epoch: 403  Training loss = 2.7446  Validation loss = 2.1905  \n",
      "\n",
      "Fold: 31  Epoch: 404  Training loss = 2.7445  Validation loss = 2.1915  \n",
      "\n",
      "Fold: 31  Epoch: 405  Training loss = 2.7444  Validation loss = 2.1922  \n",
      "\n",
      "Fold: 31  Epoch: 406  Training loss = 2.7443  Validation loss = 2.1920  \n",
      "\n",
      "Fold: 31  Epoch: 407  Training loss = 2.7442  Validation loss = 2.1926  \n",
      "\n",
      "Fold: 31  Epoch: 408  Training loss = 2.7440  Validation loss = 2.1913  \n",
      "\n",
      "Fold: 31  Epoch: 409  Training loss = 2.7438  Validation loss = 2.1898  \n",
      "\n",
      "Fold: 31  Epoch: 410  Training loss = 2.7437  Validation loss = 2.1901  \n",
      "\n",
      "Fold: 31  Epoch: 411  Training loss = 2.7435  Validation loss = 2.1883  \n",
      "\n",
      "Fold: 31  Epoch: 412  Training loss = 2.7434  Validation loss = 2.1889  \n",
      "\n",
      "Fold: 31  Epoch: 413  Training loss = 2.7433  Validation loss = 2.1887  \n",
      "\n",
      "Fold: 31  Epoch: 414  Training loss = 2.7432  Validation loss = 2.1878  \n",
      "\n",
      "Fold: 31  Epoch: 415  Training loss = 2.7430  Validation loss = 2.1878  \n",
      "\n",
      "Fold: 31  Epoch: 416  Training loss = 2.7429  Validation loss = 2.1864  \n",
      "\n",
      "Fold: 31  Epoch: 417  Training loss = 2.7428  Validation loss = 2.1874  \n",
      "\n",
      "Fold: 31  Epoch: 418  Training loss = 2.7427  Validation loss = 2.1854  \n",
      "\n",
      "Fold: 31  Epoch: 419  Training loss = 2.7425  Validation loss = 2.1842  \n",
      "\n",
      "Fold: 31  Epoch: 420  Training loss = 2.7424  Validation loss = 2.1837  \n",
      "\n",
      "Fold: 31  Epoch: 421  Training loss = 2.7423  Validation loss = 2.1823  \n",
      "\n",
      "Fold: 31  Epoch: 422  Training loss = 2.7422  Validation loss = 2.1822  \n",
      "\n",
      "Fold: 31  Epoch: 423  Training loss = 2.7420  Validation loss = 2.1817  \n",
      "\n",
      "Fold: 31  Epoch: 424  Training loss = 2.7419  Validation loss = 2.1808  \n",
      "\n",
      "Fold: 31  Epoch: 425  Training loss = 2.7416  Validation loss = 2.1786  \n",
      "\n",
      "Fold: 31  Epoch: 426  Training loss = 2.7416  Validation loss = 2.1785  \n",
      "\n",
      "Fold: 31  Epoch: 427  Training loss = 2.7414  Validation loss = 2.1772  \n",
      "\n",
      "Fold: 31  Epoch: 428  Training loss = 2.7412  Validation loss = 2.1756  \n",
      "\n",
      "Fold: 31  Epoch: 429  Training loss = 2.7410  Validation loss = 2.1744  \n",
      "\n",
      "Fold: 31  Epoch: 430  Training loss = 2.7409  Validation loss = 2.1735  \n",
      "\n",
      "Fold: 31  Epoch: 431  Training loss = 2.7408  Validation loss = 2.1731  \n",
      "\n",
      "Fold: 31  Epoch: 432  Training loss = 2.7407  Validation loss = 2.1727  \n",
      "\n",
      "Fold: 31  Epoch: 433  Training loss = 2.7405  Validation loss = 2.1723  \n",
      "\n",
      "Fold: 31  Epoch: 434  Training loss = 2.7404  Validation loss = 2.1726  \n",
      "\n",
      "Fold: 31  Epoch: 435  Training loss = 2.7402  Validation loss = 2.1714  \n",
      "\n",
      "Fold: 31  Epoch: 436  Training loss = 2.7401  Validation loss = 2.1710  \n",
      "\n",
      "Fold: 31  Epoch: 437  Training loss = 2.7401  Validation loss = 2.1730  \n",
      "\n",
      "Fold: 31  Epoch: 438  Training loss = 2.7400  Validation loss = 2.1727  \n",
      "\n",
      "Fold: 31  Epoch: 439  Training loss = 2.7398  Validation loss = 2.1722  \n",
      "\n",
      "Fold: 31  Epoch: 440  Training loss = 2.7397  Validation loss = 2.1719  \n",
      "\n",
      "Fold: 31  Epoch: 441  Training loss = 2.7396  Validation loss = 2.1720  \n",
      "\n",
      "Fold: 31  Epoch: 442  Training loss = 2.7395  Validation loss = 2.1709  \n",
      "\n",
      "Fold: 31  Epoch: 443  Training loss = 2.7393  Validation loss = 2.1701  \n",
      "\n",
      "Fold: 31  Epoch: 444  Training loss = 2.7393  Validation loss = 2.1706  \n",
      "\n",
      "Fold: 31  Epoch: 445  Training loss = 2.7391  Validation loss = 2.1700  \n",
      "\n",
      "Fold: 31  Epoch: 446  Training loss = 2.7390  Validation loss = 2.1698  \n",
      "\n",
      "Fold: 31  Epoch: 447  Training loss = 2.7388  Validation loss = 2.1683  \n",
      "\n",
      "Fold: 31  Epoch: 448  Training loss = 2.7387  Validation loss = 2.1680  \n",
      "\n",
      "Fold: 31  Epoch: 449  Training loss = 2.7386  Validation loss = 2.1678  \n",
      "\n",
      "Fold: 31  Epoch: 450  Training loss = 2.7384  Validation loss = 2.1649  \n",
      "\n",
      "Fold: 31  Epoch: 451  Training loss = 2.7383  Validation loss = 2.1642  \n",
      "\n",
      "Fold: 31  Epoch: 452  Training loss = 2.7382  Validation loss = 2.1643  \n",
      "\n",
      "Fold: 31  Epoch: 453  Training loss = 2.7380  Validation loss = 2.1633  \n",
      "\n",
      "Fold: 31  Epoch: 454  Training loss = 2.7379  Validation loss = 2.1631  \n",
      "\n",
      "Fold: 31  Epoch: 455  Training loss = 2.7377  Validation loss = 2.1608  \n",
      "\n",
      "Fold: 31  Epoch: 456  Training loss = 2.7375  Validation loss = 2.1602  \n",
      "\n",
      "Fold: 31  Epoch: 457  Training loss = 2.7374  Validation loss = 2.1608  \n",
      "\n",
      "Fold: 31  Epoch: 458  Training loss = 2.7373  Validation loss = 2.1607  \n",
      "\n",
      "Fold: 31  Epoch: 459  Training loss = 2.7372  Validation loss = 2.1609  \n",
      "\n",
      "Fold: 31  Epoch: 460  Training loss = 2.7371  Validation loss = 2.1609  \n",
      "\n",
      "Fold: 31  Epoch: 461  Training loss = 2.7370  Validation loss = 2.1608  \n",
      "\n",
      "Fold: 31  Epoch: 462  Training loss = 2.7369  Validation loss = 2.1598  \n",
      "\n",
      "Fold: 31  Epoch: 463  Training loss = 2.7367  Validation loss = 2.1593  \n",
      "\n",
      "Fold: 31  Epoch: 464  Training loss = 2.7367  Validation loss = 2.1601  \n",
      "\n",
      "Fold: 31  Epoch: 465  Training loss = 2.7365  Validation loss = 2.1592  \n",
      "\n",
      "Fold: 31  Epoch: 466  Training loss = 2.7364  Validation loss = 2.1605  \n",
      "\n",
      "Fold: 31  Epoch: 467  Training loss = 2.7364  Validation loss = 2.1614  \n",
      "\n",
      "Fold: 31  Epoch: 468  Training loss = 2.7362  Validation loss = 2.1591  \n",
      "\n",
      "Fold: 31  Epoch: 469  Training loss = 2.7361  Validation loss = 2.1585  \n",
      "\n",
      "Fold: 31  Epoch: 470  Training loss = 2.7359  Validation loss = 2.1586  \n",
      "\n",
      "Fold: 31  Epoch: 471  Training loss = 2.7358  Validation loss = 2.1584  \n",
      "\n",
      "Fold: 31  Epoch: 472  Training loss = 2.7357  Validation loss = 2.1577  \n",
      "\n",
      "Fold: 31  Epoch: 473  Training loss = 2.7355  Validation loss = 2.1578  \n",
      "\n",
      "Fold: 31  Epoch: 474  Training loss = 2.7354  Validation loss = 2.1574  \n",
      "\n",
      "Fold: 31  Epoch: 475  Training loss = 2.7353  Validation loss = 2.1576  \n",
      "\n",
      "Fold: 31  Epoch: 476  Training loss = 2.7352  Validation loss = 2.1566  \n",
      "\n",
      "Fold: 31  Epoch: 477  Training loss = 2.7351  Validation loss = 2.1553  \n",
      "\n",
      "Fold: 31  Epoch: 478  Training loss = 2.7350  Validation loss = 2.1552  \n",
      "\n",
      "Fold: 31  Epoch: 479  Training loss = 2.7348  Validation loss = 2.1547  \n",
      "\n",
      "Fold: 31  Epoch: 480  Training loss = 2.7347  Validation loss = 2.1538  \n",
      "\n",
      "Fold: 31  Epoch: 481  Training loss = 2.7347  Validation loss = 2.1544  \n",
      "\n",
      "Fold: 31  Epoch: 482  Training loss = 2.7345  Validation loss = 2.1537  \n",
      "\n",
      "Fold: 31  Epoch: 483  Training loss = 2.7344  Validation loss = 2.1543  \n",
      "\n",
      "Fold: 31  Epoch: 484  Training loss = 2.7343  Validation loss = 2.1534  \n",
      "\n",
      "Fold: 31  Epoch: 485  Training loss = 2.7342  Validation loss = 2.1530  \n",
      "\n",
      "Fold: 31  Epoch: 486  Training loss = 2.7340  Validation loss = 2.1524  \n",
      "\n",
      "Fold: 31  Epoch: 487  Training loss = 2.7339  Validation loss = 2.1520  \n",
      "\n",
      "Fold: 31  Epoch: 488  Training loss = 2.7338  Validation loss = 2.1523  \n",
      "\n",
      "Fold: 31  Epoch: 489  Training loss = 2.7337  Validation loss = 2.1512  \n",
      "\n",
      "Fold: 31  Epoch: 490  Training loss = 2.7335  Validation loss = 2.1504  \n",
      "\n",
      "Fold: 31  Epoch: 491  Training loss = 2.7335  Validation loss = 2.1506  \n",
      "\n",
      "Fold: 31  Epoch: 492  Training loss = 2.7334  Validation loss = 2.1503  \n",
      "\n",
      "Fold: 31  Epoch: 493  Training loss = 2.7332  Validation loss = 2.1490  \n",
      "\n",
      "Fold: 31  Epoch: 494  Training loss = 2.7330  Validation loss = 2.1482  \n",
      "\n",
      "Fold: 31  Epoch: 495  Training loss = 2.7328  Validation loss = 2.1471  \n",
      "\n",
      "Fold: 31  Epoch: 496  Training loss = 2.7327  Validation loss = 2.1454  \n",
      "\n",
      "Fold: 31  Epoch: 497  Training loss = 2.7326  Validation loss = 2.1451  \n",
      "\n",
      "Fold: 31  Epoch: 498  Training loss = 2.7325  Validation loss = 2.1453  \n",
      "\n",
      "Fold: 31  Epoch: 499  Training loss = 2.7324  Validation loss = 2.1457  \n",
      "\n",
      "Fold: 31  Epoch: 500  Training loss = 2.7323  Validation loss = 2.1452  \n",
      "\n",
      "Check model:  Fold: 31  Optimal epoch: 497  \n",
      "\n",
      "Fold: 32  Epoch: 1  Training loss = 2.2425  Validation loss = 3.4889  \n",
      "\n",
      "Fold: 32  Epoch: 2  Training loss = 2.2421  Validation loss = 3.4874  \n",
      "\n",
      "Fold: 32  Epoch: 3  Training loss = 2.2420  Validation loss = 3.4874  \n",
      "\n",
      "Fold: 32  Epoch: 4  Training loss = 2.2417  Validation loss = 3.4867  \n",
      "\n",
      "Fold: 32  Epoch: 5  Training loss = 2.2416  Validation loss = 3.4870  \n",
      "\n",
      "Fold: 32  Epoch: 6  Training loss = 2.2413  Validation loss = 3.4862  \n",
      "\n",
      "Fold: 32  Epoch: 7  Training loss = 2.2409  Validation loss = 3.4849  \n",
      "\n",
      "Fold: 32  Epoch: 8  Training loss = 2.2404  Validation loss = 3.4832  \n",
      "\n",
      "Fold: 32  Epoch: 9  Training loss = 2.2401  Validation loss = 3.4826  \n",
      "\n",
      "Fold: 32  Epoch: 10  Training loss = 2.2399  Validation loss = 3.4822  \n",
      "\n",
      "Fold: 32  Epoch: 11  Training loss = 2.2397  Validation loss = 3.4818  \n",
      "\n",
      "Fold: 32  Epoch: 12  Training loss = 2.2393  Validation loss = 3.4800  \n",
      "\n",
      "Fold: 32  Epoch: 13  Training loss = 2.2389  Validation loss = 3.4784  \n",
      "\n",
      "Fold: 32  Epoch: 14  Training loss = 2.2388  Validation loss = 3.4782  \n",
      "\n",
      "Fold: 32  Epoch: 15  Training loss = 2.2384  Validation loss = 3.4768  \n",
      "\n",
      "Fold: 32  Epoch: 16  Training loss = 2.2381  Validation loss = 3.4763  \n",
      "\n",
      "Fold: 32  Epoch: 17  Training loss = 2.2378  Validation loss = 3.4757  \n",
      "\n",
      "Fold: 32  Epoch: 18  Training loss = 2.2374  Validation loss = 3.4743  \n",
      "\n",
      "Fold: 32  Epoch: 19  Training loss = 2.2370  Validation loss = 3.4724  \n",
      "\n",
      "Fold: 32  Epoch: 20  Training loss = 2.2368  Validation loss = 3.4721  \n",
      "\n",
      "Fold: 32  Epoch: 21  Training loss = 2.2365  Validation loss = 3.4711  \n",
      "\n",
      "Fold: 32  Epoch: 22  Training loss = 2.2361  Validation loss = 3.4695  \n",
      "\n",
      "Fold: 32  Epoch: 23  Training loss = 2.2358  Validation loss = 3.4687  \n",
      "\n",
      "Fold: 32  Epoch: 24  Training loss = 2.2356  Validation loss = 3.4683  \n",
      "\n",
      "Fold: 32  Epoch: 25  Training loss = 2.2354  Validation loss = 3.4678  \n",
      "\n",
      "Fold: 32  Epoch: 26  Training loss = 2.2352  Validation loss = 3.4671  \n",
      "\n",
      "Fold: 32  Epoch: 27  Training loss = 2.2348  Validation loss = 3.4651  \n",
      "\n",
      "Fold: 32  Epoch: 28  Training loss = 2.2346  Validation loss = 3.4655  \n",
      "\n",
      "Fold: 32  Epoch: 29  Training loss = 2.2340  Validation loss = 3.4631  \n",
      "\n",
      "Fold: 32  Epoch: 30  Training loss = 2.2338  Validation loss = 3.4629  \n",
      "\n",
      "Fold: 32  Epoch: 31  Training loss = 2.2335  Validation loss = 3.4616  \n",
      "\n",
      "Fold: 32  Epoch: 32  Training loss = 2.2332  Validation loss = 3.4613  \n",
      "\n",
      "Fold: 32  Epoch: 33  Training loss = 2.2330  Validation loss = 3.4606  \n",
      "\n",
      "Fold: 32  Epoch: 34  Training loss = 2.2328  Validation loss = 3.4606  \n",
      "\n",
      "Fold: 32  Epoch: 35  Training loss = 2.2325  Validation loss = 3.4595  \n",
      "\n",
      "Fold: 32  Epoch: 36  Training loss = 2.2324  Validation loss = 3.4599  \n",
      "\n",
      "Fold: 32  Epoch: 37  Training loss = 2.2325  Validation loss = 3.4616  \n",
      "\n",
      "Fold: 32  Epoch: 38  Training loss = 2.2323  Validation loss = 3.4610  \n",
      "\n",
      "Fold: 32  Epoch: 39  Training loss = 2.2319  Validation loss = 3.4594  \n",
      "\n",
      "Fold: 32  Epoch: 40  Training loss = 2.2316  Validation loss = 3.4580  \n",
      "\n",
      "Fold: 32  Epoch: 41  Training loss = 2.2312  Validation loss = 3.4565  \n",
      "\n",
      "Fold: 32  Epoch: 42  Training loss = 2.2309  Validation loss = 3.4561  \n",
      "\n",
      "Fold: 32  Epoch: 43  Training loss = 2.2306  Validation loss = 3.4548  \n",
      "\n",
      "Fold: 32  Epoch: 44  Training loss = 2.2304  Validation loss = 3.4540  \n",
      "\n",
      "Fold: 32  Epoch: 45  Training loss = 2.2305  Validation loss = 3.4554  \n",
      "\n",
      "Fold: 32  Epoch: 46  Training loss = 2.2302  Validation loss = 3.4546  \n",
      "\n",
      "Fold: 32  Epoch: 47  Training loss = 2.2301  Validation loss = 3.4552  \n",
      "\n",
      "Fold: 32  Epoch: 48  Training loss = 2.2299  Validation loss = 3.4545  \n",
      "\n",
      "Fold: 32  Epoch: 49  Training loss = 2.2295  Validation loss = 3.4531  \n",
      "\n",
      "Fold: 32  Epoch: 50  Training loss = 2.2294  Validation loss = 3.4532  \n",
      "\n",
      "Fold: 32  Epoch: 51  Training loss = 2.2290  Validation loss = 3.4515  \n",
      "\n",
      "Fold: 32  Epoch: 52  Training loss = 2.2287  Validation loss = 3.4507  \n",
      "\n",
      "Fold: 32  Epoch: 53  Training loss = 2.2285  Validation loss = 3.4500  \n",
      "\n",
      "Fold: 32  Epoch: 54  Training loss = 2.2284  Validation loss = 3.4507  \n",
      "\n",
      "Fold: 32  Epoch: 55  Training loss = 2.2280  Validation loss = 3.4495  \n",
      "\n",
      "Fold: 32  Epoch: 56  Training loss = 2.2276  Validation loss = 3.4480  \n",
      "\n",
      "Fold: 32  Epoch: 57  Training loss = 2.2274  Validation loss = 3.4478  \n",
      "\n",
      "Fold: 32  Epoch: 58  Training loss = 2.2273  Validation loss = 3.4483  \n",
      "\n",
      "Fold: 32  Epoch: 59  Training loss = 2.2270  Validation loss = 3.4475  \n",
      "\n",
      "Fold: 32  Epoch: 60  Training loss = 2.2267  Validation loss = 3.4467  \n",
      "\n",
      "Fold: 32  Epoch: 61  Training loss = 2.2266  Validation loss = 3.4469  \n",
      "\n",
      "Fold: 32  Epoch: 62  Training loss = 2.2263  Validation loss = 3.4459  \n",
      "\n",
      "Fold: 32  Epoch: 63  Training loss = 2.2259  Validation loss = 3.4435  \n",
      "\n",
      "Fold: 32  Epoch: 64  Training loss = 2.2256  Validation loss = 3.4427  \n",
      "\n",
      "Fold: 32  Epoch: 65  Training loss = 2.2251  Validation loss = 3.4410  \n",
      "\n",
      "Fold: 32  Epoch: 66  Training loss = 2.2248  Validation loss = 3.4406  \n",
      "\n",
      "Fold: 32  Epoch: 67  Training loss = 2.2247  Validation loss = 3.4412  \n",
      "\n",
      "Fold: 32  Epoch: 68  Training loss = 2.2245  Validation loss = 3.4409  \n",
      "\n",
      "Fold: 32  Epoch: 69  Training loss = 2.2245  Validation loss = 3.4412  \n",
      "\n",
      "Fold: 32  Epoch: 70  Training loss = 2.2242  Validation loss = 3.4402  \n",
      "\n",
      "Fold: 32  Epoch: 71  Training loss = 2.2239  Validation loss = 3.4394  \n",
      "\n",
      "Fold: 32  Epoch: 72  Training loss = 2.2237  Validation loss = 3.4390  \n",
      "\n",
      "Fold: 32  Epoch: 73  Training loss = 2.2233  Validation loss = 3.4376  \n",
      "\n",
      "Fold: 32  Epoch: 74  Training loss = 2.2230  Validation loss = 3.4368  \n",
      "\n",
      "Fold: 32  Epoch: 75  Training loss = 2.2229  Validation loss = 3.4374  \n",
      "\n",
      "Fold: 32  Epoch: 76  Training loss = 2.2227  Validation loss = 3.4371  \n",
      "\n",
      "Fold: 32  Epoch: 77  Training loss = 2.2225  Validation loss = 3.4373  \n",
      "\n",
      "Fold: 32  Epoch: 78  Training loss = 2.2221  Validation loss = 3.4351  \n",
      "\n",
      "Fold: 32  Epoch: 79  Training loss = 2.2218  Validation loss = 3.4344  \n",
      "\n",
      "Fold: 32  Epoch: 80  Training loss = 2.2216  Validation loss = 3.4331  \n",
      "\n",
      "Fold: 32  Epoch: 81  Training loss = 2.2215  Validation loss = 3.4330  \n",
      "\n",
      "Fold: 32  Epoch: 82  Training loss = 2.2213  Validation loss = 3.4326  \n",
      "\n",
      "Fold: 32  Epoch: 83  Training loss = 2.2211  Validation loss = 3.4320  \n",
      "\n",
      "Fold: 32  Epoch: 84  Training loss = 2.2209  Validation loss = 3.4324  \n",
      "\n",
      "Fold: 32  Epoch: 85  Training loss = 2.2207  Validation loss = 3.4327  \n",
      "\n",
      "Fold: 32  Epoch: 86  Training loss = 2.2204  Validation loss = 3.4312  \n",
      "\n",
      "Fold: 32  Epoch: 87  Training loss = 2.2204  Validation loss = 3.4317  \n",
      "\n",
      "Fold: 32  Epoch: 88  Training loss = 2.2201  Validation loss = 3.4313  \n",
      "\n",
      "Fold: 32  Epoch: 89  Training loss = 2.2198  Validation loss = 3.4303  \n",
      "\n",
      "Fold: 32  Epoch: 90  Training loss = 2.2197  Validation loss = 3.4305  \n",
      "\n",
      "Fold: 32  Epoch: 91  Training loss = 2.2194  Validation loss = 3.4298  \n",
      "\n",
      "Fold: 32  Epoch: 92  Training loss = 2.2192  Validation loss = 3.4296  \n",
      "\n",
      "Fold: 32  Epoch: 93  Training loss = 2.2190  Validation loss = 3.4297  \n",
      "\n",
      "Fold: 32  Epoch: 94  Training loss = 2.2189  Validation loss = 3.4301  \n",
      "\n",
      "Fold: 32  Epoch: 95  Training loss = 2.2186  Validation loss = 3.4293  \n",
      "\n",
      "Fold: 32  Epoch: 96  Training loss = 2.2184  Validation loss = 3.4287  \n",
      "\n",
      "Fold: 32  Epoch: 97  Training loss = 2.2180  Validation loss = 3.4272  \n",
      "\n",
      "Fold: 32  Epoch: 98  Training loss = 2.2176  Validation loss = 3.4250  \n",
      "\n",
      "Fold: 32  Epoch: 99  Training loss = 2.2173  Validation loss = 3.4252  \n",
      "\n",
      "Fold: 32  Epoch: 100  Training loss = 2.2170  Validation loss = 3.4244  \n",
      "\n",
      "Fold: 32  Epoch: 101  Training loss = 2.2168  Validation loss = 3.4246  \n",
      "\n",
      "Fold: 32  Epoch: 102  Training loss = 2.2167  Validation loss = 3.4250  \n",
      "\n",
      "Fold: 32  Epoch: 103  Training loss = 2.2164  Validation loss = 3.4235  \n",
      "\n",
      "Fold: 32  Epoch: 104  Training loss = 2.2162  Validation loss = 3.4222  \n",
      "\n",
      "Fold: 32  Epoch: 105  Training loss = 2.2158  Validation loss = 3.4209  \n",
      "\n",
      "Fold: 32  Epoch: 106  Training loss = 2.2157  Validation loss = 3.4215  \n",
      "\n",
      "Fold: 32  Epoch: 107  Training loss = 2.2155  Validation loss = 3.4210  \n",
      "\n",
      "Fold: 32  Epoch: 108  Training loss = 2.2152  Validation loss = 3.4206  \n",
      "\n",
      "Fold: 32  Epoch: 109  Training loss = 2.2148  Validation loss = 3.4190  \n",
      "\n",
      "Fold: 32  Epoch: 110  Training loss = 2.2146  Validation loss = 3.4192  \n",
      "\n",
      "Fold: 32  Epoch: 111  Training loss = 2.2145  Validation loss = 3.4198  \n",
      "\n",
      "Fold: 32  Epoch: 112  Training loss = 2.2141  Validation loss = 3.4187  \n",
      "\n",
      "Fold: 32  Epoch: 113  Training loss = 2.2140  Validation loss = 3.4186  \n",
      "\n",
      "Fold: 32  Epoch: 114  Training loss = 2.2137  Validation loss = 3.4173  \n",
      "\n",
      "Fold: 32  Epoch: 115  Training loss = 2.2134  Validation loss = 3.4165  \n",
      "\n",
      "Fold: 32  Epoch: 116  Training loss = 2.2133  Validation loss = 3.4168  \n",
      "\n",
      "Fold: 32  Epoch: 117  Training loss = 2.2130  Validation loss = 3.4159  \n",
      "\n",
      "Fold: 32  Epoch: 118  Training loss = 2.2128  Validation loss = 3.4156  \n",
      "\n",
      "Fold: 32  Epoch: 119  Training loss = 2.2126  Validation loss = 3.4149  \n",
      "\n",
      "Fold: 32  Epoch: 120  Training loss = 2.2123  Validation loss = 3.4140  \n",
      "\n",
      "Fold: 32  Epoch: 121  Training loss = 2.2122  Validation loss = 3.4144  \n",
      "\n",
      "Fold: 32  Epoch: 122  Training loss = 2.2120  Validation loss = 3.4141  \n",
      "\n",
      "Fold: 32  Epoch: 123  Training loss = 2.2118  Validation loss = 3.4127  \n",
      "\n",
      "Fold: 32  Epoch: 124  Training loss = 2.2117  Validation loss = 3.4134  \n",
      "\n",
      "Fold: 32  Epoch: 125  Training loss = 2.2113  Validation loss = 3.4112  \n",
      "\n",
      "Fold: 32  Epoch: 126  Training loss = 2.2110  Validation loss = 3.4099  \n",
      "\n",
      "Fold: 32  Epoch: 127  Training loss = 2.2108  Validation loss = 3.4101  \n",
      "\n",
      "Fold: 32  Epoch: 128  Training loss = 2.2105  Validation loss = 3.4097  \n",
      "\n",
      "Fold: 32  Epoch: 129  Training loss = 2.2104  Validation loss = 3.4099  \n",
      "\n",
      "Fold: 32  Epoch: 130  Training loss = 2.2103  Validation loss = 3.4100  \n",
      "\n",
      "Fold: 32  Epoch: 131  Training loss = 2.2099  Validation loss = 3.4087  \n",
      "\n",
      "Fold: 32  Epoch: 132  Training loss = 2.2096  Validation loss = 3.4075  \n",
      "\n",
      "Fold: 32  Epoch: 133  Training loss = 2.2094  Validation loss = 3.4074  \n",
      "\n",
      "Fold: 32  Epoch: 134  Training loss = 2.2092  Validation loss = 3.4073  \n",
      "\n",
      "Fold: 32  Epoch: 135  Training loss = 2.2090  Validation loss = 3.4068  \n",
      "\n",
      "Fold: 32  Epoch: 136  Training loss = 2.2088  Validation loss = 3.4068  \n",
      "\n",
      "Fold: 32  Epoch: 137  Training loss = 2.2084  Validation loss = 3.4050  \n",
      "\n",
      "Fold: 32  Epoch: 138  Training loss = 2.2082  Validation loss = 3.4043  \n",
      "\n",
      "Fold: 32  Epoch: 139  Training loss = 2.2079  Validation loss = 3.4033  \n",
      "\n",
      "Fold: 32  Epoch: 140  Training loss = 2.2076  Validation loss = 3.4025  \n",
      "\n",
      "Fold: 32  Epoch: 141  Training loss = 2.2072  Validation loss = 3.4020  \n",
      "\n",
      "Fold: 32  Epoch: 142  Training loss = 2.2069  Validation loss = 3.4007  \n",
      "\n",
      "Fold: 32  Epoch: 143  Training loss = 2.2066  Validation loss = 3.3992  \n",
      "\n",
      "Fold: 32  Epoch: 144  Training loss = 2.2065  Validation loss = 3.3995  \n",
      "\n",
      "Fold: 32  Epoch: 145  Training loss = 2.2063  Validation loss = 3.3995  \n",
      "\n",
      "Fold: 32  Epoch: 146  Training loss = 2.2060  Validation loss = 3.3981  \n",
      "\n",
      "Fold: 32  Epoch: 147  Training loss = 2.2058  Validation loss = 3.3975  \n",
      "\n",
      "Fold: 32  Epoch: 148  Training loss = 2.2056  Validation loss = 3.3966  \n",
      "\n",
      "Fold: 32  Epoch: 149  Training loss = 2.2052  Validation loss = 3.3954  \n",
      "\n",
      "Fold: 32  Epoch: 150  Training loss = 2.2050  Validation loss = 3.3947  \n",
      "\n",
      "Fold: 32  Epoch: 151  Training loss = 2.2048  Validation loss = 3.3940  \n",
      "\n",
      "Fold: 32  Epoch: 152  Training loss = 2.2045  Validation loss = 3.3933  \n",
      "\n",
      "Fold: 32  Epoch: 153  Training loss = 2.2042  Validation loss = 3.3922  \n",
      "\n",
      "Fold: 32  Epoch: 154  Training loss = 2.2040  Validation loss = 3.3913  \n",
      "\n",
      "Fold: 32  Epoch: 155  Training loss = 2.2035  Validation loss = 3.3892  \n",
      "\n",
      "Fold: 32  Epoch: 156  Training loss = 2.2034  Validation loss = 3.3904  \n",
      "\n",
      "Fold: 32  Epoch: 157  Training loss = 2.2032  Validation loss = 3.3904  \n",
      "\n",
      "Fold: 32  Epoch: 158  Training loss = 2.2029  Validation loss = 3.3898  \n",
      "\n",
      "Fold: 32  Epoch: 159  Training loss = 2.2027  Validation loss = 3.3895  \n",
      "\n",
      "Fold: 32  Epoch: 160  Training loss = 2.2023  Validation loss = 3.3875  \n",
      "\n",
      "Fold: 32  Epoch: 161  Training loss = 2.2021  Validation loss = 3.3870  \n",
      "\n",
      "Fold: 32  Epoch: 162  Training loss = 2.2019  Validation loss = 3.3855  \n",
      "\n",
      "Fold: 32  Epoch: 163  Training loss = 2.2017  Validation loss = 3.3848  \n",
      "\n",
      "Fold: 32  Epoch: 164  Training loss = 2.2012  Validation loss = 3.3825  \n",
      "\n",
      "Fold: 32  Epoch: 165  Training loss = 2.2011  Validation loss = 3.3826  \n",
      "\n",
      "Fold: 32  Epoch: 166  Training loss = 2.2008  Validation loss = 3.3817  \n",
      "\n",
      "Fold: 32  Epoch: 167  Training loss = 2.2006  Validation loss = 3.3809  \n",
      "\n",
      "Fold: 32  Epoch: 168  Training loss = 2.2004  Validation loss = 3.3806  \n",
      "\n",
      "Fold: 32  Epoch: 169  Training loss = 2.2003  Validation loss = 3.3805  \n",
      "\n",
      "Fold: 32  Epoch: 170  Training loss = 2.2001  Validation loss = 3.3794  \n",
      "\n",
      "Fold: 32  Epoch: 171  Training loss = 2.1999  Validation loss = 3.3794  \n",
      "\n",
      "Fold: 32  Epoch: 172  Training loss = 2.1997  Validation loss = 3.3786  \n",
      "\n",
      "Fold: 32  Epoch: 173  Training loss = 2.1996  Validation loss = 3.3793  \n",
      "\n",
      "Fold: 32  Epoch: 174  Training loss = 2.1994  Validation loss = 3.3788  \n",
      "\n",
      "Fold: 32  Epoch: 175  Training loss = 2.1991  Validation loss = 3.3766  \n",
      "\n",
      "Fold: 32  Epoch: 176  Training loss = 2.1989  Validation loss = 3.3764  \n",
      "\n",
      "Fold: 32  Epoch: 177  Training loss = 2.1987  Validation loss = 3.3756  \n",
      "\n",
      "Fold: 32  Epoch: 178  Training loss = 2.1985  Validation loss = 3.3751  \n",
      "\n",
      "Fold: 32  Epoch: 179  Training loss = 2.1982  Validation loss = 3.3742  \n",
      "\n",
      "Fold: 32  Epoch: 180  Training loss = 2.1980  Validation loss = 3.3738  \n",
      "\n",
      "Fold: 32  Epoch: 181  Training loss = 2.1977  Validation loss = 3.3723  \n",
      "\n",
      "Fold: 32  Epoch: 182  Training loss = 2.1975  Validation loss = 3.3715  \n",
      "\n",
      "Fold: 32  Epoch: 183  Training loss = 2.1973  Validation loss = 3.3710  \n",
      "\n",
      "Fold: 32  Epoch: 184  Training loss = 2.1970  Validation loss = 3.3688  \n",
      "\n",
      "Fold: 32  Epoch: 185  Training loss = 2.1968  Validation loss = 3.3689  \n",
      "\n",
      "Fold: 32  Epoch: 186  Training loss = 2.1964  Validation loss = 3.3658  \n",
      "\n",
      "Fold: 32  Epoch: 187  Training loss = 2.1963  Validation loss = 3.3660  \n",
      "\n",
      "Fold: 32  Epoch: 188  Training loss = 2.1960  Validation loss = 3.3654  \n",
      "\n",
      "Fold: 32  Epoch: 189  Training loss = 2.1959  Validation loss = 3.3645  \n",
      "\n",
      "Fold: 32  Epoch: 190  Training loss = 2.1956  Validation loss = 3.3625  \n",
      "\n",
      "Fold: 32  Epoch: 191  Training loss = 2.1953  Validation loss = 3.3624  \n",
      "\n",
      "Fold: 32  Epoch: 192  Training loss = 2.1950  Validation loss = 3.3617  \n",
      "\n",
      "Fold: 32  Epoch: 193  Training loss = 2.1948  Validation loss = 3.3607  \n",
      "\n",
      "Fold: 32  Epoch: 194  Training loss = 2.1944  Validation loss = 3.3591  \n",
      "\n",
      "Fold: 32  Epoch: 195  Training loss = 2.1942  Validation loss = 3.3586  \n",
      "\n",
      "Fold: 32  Epoch: 196  Training loss = 2.1940  Validation loss = 3.3580  \n",
      "\n",
      "Fold: 32  Epoch: 197  Training loss = 2.1937  Validation loss = 3.3570  \n",
      "\n",
      "Fold: 32  Epoch: 198  Training loss = 2.1935  Validation loss = 3.3552  \n",
      "\n",
      "Fold: 32  Epoch: 199  Training loss = 2.1933  Validation loss = 3.3550  \n",
      "\n",
      "Fold: 32  Epoch: 200  Training loss = 2.1931  Validation loss = 3.3550  \n",
      "\n",
      "Fold: 32  Epoch: 201  Training loss = 2.1930  Validation loss = 3.3547  \n",
      "\n",
      "Fold: 32  Epoch: 202  Training loss = 2.1928  Validation loss = 3.3545  \n",
      "\n",
      "Fold: 32  Epoch: 203  Training loss = 2.1927  Validation loss = 3.3542  \n",
      "\n",
      "Fold: 32  Epoch: 204  Training loss = 2.1923  Validation loss = 3.3527  \n",
      "\n",
      "Fold: 32  Epoch: 205  Training loss = 2.1921  Validation loss = 3.3526  \n",
      "\n",
      "Fold: 32  Epoch: 206  Training loss = 2.1919  Validation loss = 3.3521  \n",
      "\n",
      "Fold: 32  Epoch: 207  Training loss = 2.1917  Validation loss = 3.3506  \n",
      "\n",
      "Fold: 32  Epoch: 208  Training loss = 2.1915  Validation loss = 3.3499  \n",
      "\n",
      "Fold: 32  Epoch: 209  Training loss = 2.1913  Validation loss = 3.3500  \n",
      "\n",
      "Fold: 32  Epoch: 210  Training loss = 2.1911  Validation loss = 3.3500  \n",
      "\n",
      "Fold: 32  Epoch: 211  Training loss = 2.1910  Validation loss = 3.3492  \n",
      "\n",
      "Fold: 32  Epoch: 212  Training loss = 2.1907  Validation loss = 3.3483  \n",
      "\n",
      "Fold: 32  Epoch: 213  Training loss = 2.1905  Validation loss = 3.3480  \n",
      "\n",
      "Fold: 32  Epoch: 214  Training loss = 2.1902  Validation loss = 3.3475  \n",
      "\n",
      "Fold: 32  Epoch: 215  Training loss = 2.1900  Validation loss = 3.3453  \n",
      "\n",
      "Fold: 32  Epoch: 216  Training loss = 2.1898  Validation loss = 3.3448  \n",
      "\n",
      "Fold: 32  Epoch: 217  Training loss = 2.1895  Validation loss = 3.3441  \n",
      "\n",
      "Fold: 32  Epoch: 218  Training loss = 2.1892  Validation loss = 3.3433  \n",
      "\n",
      "Fold: 32  Epoch: 219  Training loss = 2.1890  Validation loss = 3.3430  \n",
      "\n",
      "Fold: 32  Epoch: 220  Training loss = 2.1889  Validation loss = 3.3431  \n",
      "\n",
      "Fold: 32  Epoch: 221  Training loss = 2.1886  Validation loss = 3.3410  \n",
      "\n",
      "Fold: 32  Epoch: 222  Training loss = 2.1883  Validation loss = 3.3388  \n",
      "\n",
      "Fold: 32  Epoch: 223  Training loss = 2.1881  Validation loss = 3.3383  \n",
      "\n",
      "Fold: 32  Epoch: 224  Training loss = 2.1879  Validation loss = 3.3374  \n",
      "\n",
      "Fold: 32  Epoch: 225  Training loss = 2.1877  Validation loss = 3.3373  \n",
      "\n",
      "Fold: 32  Epoch: 226  Training loss = 2.1875  Validation loss = 3.3372  \n",
      "\n",
      "Fold: 32  Epoch: 227  Training loss = 2.1872  Validation loss = 3.3364  \n",
      "\n",
      "Fold: 32  Epoch: 228  Training loss = 2.1870  Validation loss = 3.3349  \n",
      "\n",
      "Fold: 32  Epoch: 229  Training loss = 2.1868  Validation loss = 3.3356  \n",
      "\n",
      "Fold: 32  Epoch: 230  Training loss = 2.1866  Validation loss = 3.3365  \n",
      "\n",
      "Fold: 32  Epoch: 231  Training loss = 2.1862  Validation loss = 3.3354  \n",
      "\n",
      "Fold: 32  Epoch: 232  Training loss = 2.1861  Validation loss = 3.3369  \n",
      "\n",
      "Fold: 32  Epoch: 233  Training loss = 2.1860  Validation loss = 3.3374  \n",
      "\n",
      "Fold: 32  Epoch: 234  Training loss = 2.1858  Validation loss = 3.3370  \n",
      "\n",
      "Fold: 32  Epoch: 235  Training loss = 2.1855  Validation loss = 3.3358  \n",
      "\n",
      "Fold: 32  Epoch: 236  Training loss = 2.1852  Validation loss = 3.3346  \n",
      "\n",
      "Fold: 32  Epoch: 237  Training loss = 2.1851  Validation loss = 3.3336  \n",
      "\n",
      "Fold: 32  Epoch: 238  Training loss = 2.1849  Validation loss = 3.3339  \n",
      "\n",
      "Fold: 32  Epoch: 239  Training loss = 2.1848  Validation loss = 3.3338  \n",
      "\n",
      "Fold: 32  Epoch: 240  Training loss = 2.1846  Validation loss = 3.3333  \n",
      "\n",
      "Fold: 32  Epoch: 241  Training loss = 2.1845  Validation loss = 3.3339  \n",
      "\n",
      "Fold: 32  Epoch: 242  Training loss = 2.1844  Validation loss = 3.3338  \n",
      "\n",
      "Fold: 32  Epoch: 243  Training loss = 2.1842  Validation loss = 3.3337  \n",
      "\n",
      "Fold: 32  Epoch: 244  Training loss = 2.1840  Validation loss = 3.3326  \n",
      "\n",
      "Fold: 32  Epoch: 245  Training loss = 2.1838  Validation loss = 3.3316  \n",
      "\n",
      "Fold: 32  Epoch: 246  Training loss = 2.1836  Validation loss = 3.3307  \n",
      "\n",
      "Fold: 32  Epoch: 247  Training loss = 2.1833  Validation loss = 3.3300  \n",
      "\n",
      "Fold: 32  Epoch: 248  Training loss = 2.1831  Validation loss = 3.3301  \n",
      "\n",
      "Fold: 32  Epoch: 249  Training loss = 2.1829  Validation loss = 3.3291  \n",
      "\n",
      "Fold: 32  Epoch: 250  Training loss = 2.1827  Validation loss = 3.3290  \n",
      "\n",
      "Fold: 32  Epoch: 251  Training loss = 2.1824  Validation loss = 3.3281  \n",
      "\n",
      "Fold: 32  Epoch: 252  Training loss = 2.1823  Validation loss = 3.3274  \n",
      "\n",
      "Fold: 32  Epoch: 253  Training loss = 2.1821  Validation loss = 3.3265  \n",
      "\n",
      "Fold: 32  Epoch: 254  Training loss = 2.1819  Validation loss = 3.3258  \n",
      "\n",
      "Fold: 32  Epoch: 255  Training loss = 2.1818  Validation loss = 3.3266  \n",
      "\n",
      "Fold: 32  Epoch: 256  Training loss = 2.1817  Validation loss = 3.3266  \n",
      "\n",
      "Fold: 32  Epoch: 257  Training loss = 2.1815  Validation loss = 3.3264  \n",
      "\n",
      "Fold: 32  Epoch: 258  Training loss = 2.1813  Validation loss = 3.3252  \n",
      "\n",
      "Fold: 32  Epoch: 259  Training loss = 2.1810  Validation loss = 3.3236  \n",
      "\n",
      "Fold: 32  Epoch: 260  Training loss = 2.1808  Validation loss = 3.3233  \n",
      "\n",
      "Fold: 32  Epoch: 261  Training loss = 2.1805  Validation loss = 3.3219  \n",
      "\n",
      "Fold: 32  Epoch: 262  Training loss = 2.1804  Validation loss = 3.3219  \n",
      "\n",
      "Fold: 32  Epoch: 263  Training loss = 2.1803  Validation loss = 3.3219  \n",
      "\n",
      "Fold: 32  Epoch: 264  Training loss = 2.1801  Validation loss = 3.3211  \n",
      "\n",
      "Fold: 32  Epoch: 265  Training loss = 2.1798  Validation loss = 3.3197  \n",
      "\n",
      "Fold: 32  Epoch: 266  Training loss = 2.1797  Validation loss = 3.3201  \n",
      "\n",
      "Fold: 32  Epoch: 267  Training loss = 2.1794  Validation loss = 3.3196  \n",
      "\n",
      "Fold: 32  Epoch: 268  Training loss = 2.1792  Validation loss = 3.3183  \n",
      "\n",
      "Fold: 32  Epoch: 269  Training loss = 2.1791  Validation loss = 3.3181  \n",
      "\n",
      "Fold: 32  Epoch: 270  Training loss = 2.1788  Validation loss = 3.3169  \n",
      "\n",
      "Fold: 32  Epoch: 271  Training loss = 2.1786  Validation loss = 3.3164  \n",
      "\n",
      "Fold: 32  Epoch: 272  Training loss = 2.1784  Validation loss = 3.3161  \n",
      "\n",
      "Fold: 32  Epoch: 273  Training loss = 2.1783  Validation loss = 3.3176  \n",
      "\n",
      "Fold: 32  Epoch: 274  Training loss = 2.1783  Validation loss = 3.3178  \n",
      "\n",
      "Fold: 32  Epoch: 275  Training loss = 2.1782  Validation loss = 3.3187  \n",
      "\n",
      "Fold: 32  Epoch: 276  Training loss = 2.1780  Validation loss = 3.3178  \n",
      "\n",
      "Fold: 32  Epoch: 277  Training loss = 2.1778  Validation loss = 3.3176  \n",
      "\n",
      "Fold: 32  Epoch: 278  Training loss = 2.1776  Validation loss = 3.3184  \n",
      "\n",
      "Fold: 32  Epoch: 279  Training loss = 2.1774  Validation loss = 3.3174  \n",
      "\n",
      "Fold: 32  Epoch: 280  Training loss = 2.1772  Validation loss = 3.3181  \n",
      "\n",
      "Fold: 32  Epoch: 281  Training loss = 2.1770  Validation loss = 3.3178  \n",
      "\n",
      "Fold: 32  Epoch: 282  Training loss = 2.1767  Validation loss = 3.3176  \n",
      "\n",
      "Fold: 32  Epoch: 283  Training loss = 2.1766  Validation loss = 3.3178  \n",
      "\n",
      "Fold: 32  Epoch: 284  Training loss = 2.1763  Validation loss = 3.3161  \n",
      "\n",
      "Fold: 32  Epoch: 285  Training loss = 2.1762  Validation loss = 3.3158  \n",
      "\n",
      "Fold: 32  Epoch: 286  Training loss = 2.1760  Validation loss = 3.3160  \n",
      "\n",
      "Fold: 32  Epoch: 287  Training loss = 2.1759  Validation loss = 3.3162  \n",
      "\n",
      "Fold: 32  Epoch: 288  Training loss = 2.1756  Validation loss = 3.3150  \n",
      "\n",
      "Fold: 32  Epoch: 289  Training loss = 2.1755  Validation loss = 3.3158  \n",
      "\n",
      "Fold: 32  Epoch: 290  Training loss = 2.1752  Validation loss = 3.3156  \n",
      "\n",
      "Fold: 32  Epoch: 291  Training loss = 2.1750  Validation loss = 3.3141  \n",
      "\n",
      "Fold: 32  Epoch: 292  Training loss = 2.1748  Validation loss = 3.3133  \n",
      "\n",
      "Fold: 32  Epoch: 293  Training loss = 2.1746  Validation loss = 3.3137  \n",
      "\n",
      "Fold: 32  Epoch: 294  Training loss = 2.1743  Validation loss = 3.3120  \n",
      "\n",
      "Fold: 32  Epoch: 295  Training loss = 2.1742  Validation loss = 3.3113  \n",
      "\n",
      "Fold: 32  Epoch: 296  Training loss = 2.1739  Validation loss = 3.3095  \n",
      "\n",
      "Fold: 32  Epoch: 297  Training loss = 2.1737  Validation loss = 3.3092  \n",
      "\n",
      "Fold: 32  Epoch: 298  Training loss = 2.1735  Validation loss = 3.3084  \n",
      "\n",
      "Fold: 32  Epoch: 299  Training loss = 2.1734  Validation loss = 3.3091  \n",
      "\n",
      "Fold: 32  Epoch: 300  Training loss = 2.1734  Validation loss = 3.3096  \n",
      "\n",
      "Fold: 32  Epoch: 301  Training loss = 2.1733  Validation loss = 3.3099  \n",
      "\n",
      "Fold: 32  Epoch: 302  Training loss = 2.1731  Validation loss = 3.3106  \n",
      "\n",
      "Fold: 32  Epoch: 303  Training loss = 2.1729  Validation loss = 3.3097  \n",
      "\n",
      "Fold: 32  Epoch: 304  Training loss = 2.1726  Validation loss = 3.3071  \n",
      "\n",
      "Fold: 32  Epoch: 305  Training loss = 2.1724  Validation loss = 3.3065  \n",
      "\n",
      "Fold: 32  Epoch: 306  Training loss = 2.1722  Validation loss = 3.3051  \n",
      "\n",
      "Fold: 32  Epoch: 307  Training loss = 2.1720  Validation loss = 3.3053  \n",
      "\n",
      "Fold: 32  Epoch: 308  Training loss = 2.1718  Validation loss = 3.3054  \n",
      "\n",
      "Fold: 32  Epoch: 309  Training loss = 2.1716  Validation loss = 3.3051  \n",
      "\n",
      "Fold: 32  Epoch: 310  Training loss = 2.1713  Validation loss = 3.3030  \n",
      "\n",
      "Fold: 32  Epoch: 311  Training loss = 2.1711  Validation loss = 3.3023  \n",
      "\n",
      "Fold: 32  Epoch: 312  Training loss = 2.1709  Validation loss = 3.3012  \n",
      "\n",
      "Fold: 32  Epoch: 313  Training loss = 2.1707  Validation loss = 3.3008  \n",
      "\n",
      "Fold: 32  Epoch: 314  Training loss = 2.1705  Validation loss = 3.3005  \n",
      "\n",
      "Fold: 32  Epoch: 315  Training loss = 2.1704  Validation loss = 3.3002  \n",
      "\n",
      "Fold: 32  Epoch: 316  Training loss = 2.1701  Validation loss = 3.2988  \n",
      "\n",
      "Fold: 32  Epoch: 317  Training loss = 2.1700  Validation loss = 3.2997  \n",
      "\n",
      "Fold: 32  Epoch: 318  Training loss = 2.1698  Validation loss = 3.2999  \n",
      "\n",
      "Fold: 32  Epoch: 319  Training loss = 2.1696  Validation loss = 3.2983  \n",
      "\n",
      "Fold: 32  Epoch: 320  Training loss = 2.1694  Validation loss = 3.2975  \n",
      "\n",
      "Fold: 32  Epoch: 321  Training loss = 2.1692  Validation loss = 3.2978  \n",
      "\n",
      "Fold: 32  Epoch: 322  Training loss = 2.1689  Validation loss = 3.2965  \n",
      "\n",
      "Fold: 32  Epoch: 323  Training loss = 2.1687  Validation loss = 3.2962  \n",
      "\n",
      "Fold: 32  Epoch: 324  Training loss = 2.1685  Validation loss = 3.2956  \n",
      "\n",
      "Fold: 32  Epoch: 325  Training loss = 2.1684  Validation loss = 3.2956  \n",
      "\n",
      "Fold: 32  Epoch: 326  Training loss = 2.1682  Validation loss = 3.2958  \n",
      "\n",
      "Fold: 32  Epoch: 327  Training loss = 2.1680  Validation loss = 3.2950  \n",
      "\n",
      "Fold: 32  Epoch: 328  Training loss = 2.1678  Validation loss = 3.2953  \n",
      "\n",
      "Fold: 32  Epoch: 329  Training loss = 2.1678  Validation loss = 3.2963  \n",
      "\n",
      "Fold: 32  Epoch: 330  Training loss = 2.1676  Validation loss = 3.2960  \n",
      "\n",
      "Fold: 32  Epoch: 331  Training loss = 2.1674  Validation loss = 3.2949  \n",
      "\n",
      "Fold: 32  Epoch: 332  Training loss = 2.1673  Validation loss = 3.2952  \n",
      "\n",
      "Fold: 32  Epoch: 333  Training loss = 2.1672  Validation loss = 3.2964  \n",
      "\n",
      "Fold: 32  Epoch: 334  Training loss = 2.1670  Validation loss = 3.2953  \n",
      "\n",
      "Fold: 32  Epoch: 335  Training loss = 2.1667  Validation loss = 3.2950  \n",
      "\n",
      "Fold: 32  Epoch: 336  Training loss = 2.1665  Validation loss = 3.2939  \n",
      "\n",
      "Fold: 32  Epoch: 337  Training loss = 2.1664  Validation loss = 3.2946  \n",
      "\n",
      "Fold: 32  Epoch: 338  Training loss = 2.1664  Validation loss = 3.2947  \n",
      "\n",
      "Fold: 32  Epoch: 339  Training loss = 2.1662  Validation loss = 3.2945  \n",
      "\n",
      "Fold: 32  Epoch: 340  Training loss = 2.1660  Validation loss = 3.2931  \n",
      "\n",
      "Fold: 32  Epoch: 341  Training loss = 2.1657  Validation loss = 3.2925  \n",
      "\n",
      "Fold: 32  Epoch: 342  Training loss = 2.1656  Validation loss = 3.2921  \n",
      "\n",
      "Fold: 32  Epoch: 343  Training loss = 2.1654  Validation loss = 3.2923  \n",
      "\n",
      "Fold: 32  Epoch: 344  Training loss = 2.1653  Validation loss = 3.2928  \n",
      "\n",
      "Fold: 32  Epoch: 345  Training loss = 2.1651  Validation loss = 3.2925  \n",
      "\n",
      "Fold: 32  Epoch: 346  Training loss = 2.1649  Validation loss = 3.2919  \n",
      "\n",
      "Fold: 32  Epoch: 347  Training loss = 2.1647  Validation loss = 3.2909  \n",
      "\n",
      "Fold: 32  Epoch: 348  Training loss = 2.1645  Validation loss = 3.2908  \n",
      "\n",
      "Fold: 32  Epoch: 349  Training loss = 2.1643  Validation loss = 3.2901  \n",
      "\n",
      "Fold: 32  Epoch: 350  Training loss = 2.1642  Validation loss = 3.2901  \n",
      "\n",
      "Fold: 32  Epoch: 351  Training loss = 2.1640  Validation loss = 3.2909  \n",
      "\n",
      "Fold: 32  Epoch: 352  Training loss = 2.1637  Validation loss = 3.2896  \n",
      "\n",
      "Fold: 32  Epoch: 353  Training loss = 2.1635  Validation loss = 3.2877  \n",
      "\n",
      "Fold: 32  Epoch: 354  Training loss = 2.1633  Validation loss = 3.2870  \n",
      "\n",
      "Fold: 32  Epoch: 355  Training loss = 2.1631  Validation loss = 3.2873  \n",
      "\n",
      "Fold: 32  Epoch: 356  Training loss = 2.1629  Validation loss = 3.2864  \n",
      "\n",
      "Fold: 32  Epoch: 357  Training loss = 2.1627  Validation loss = 3.2853  \n",
      "\n",
      "Fold: 32  Epoch: 358  Training loss = 2.1624  Validation loss = 3.2844  \n",
      "\n",
      "Fold: 32  Epoch: 359  Training loss = 2.1623  Validation loss = 3.2841  \n",
      "\n",
      "Fold: 32  Epoch: 360  Training loss = 2.1622  Validation loss = 3.2858  \n",
      "\n",
      "Fold: 32  Epoch: 361  Training loss = 2.1621  Validation loss = 3.2858  \n",
      "\n",
      "Fold: 32  Epoch: 362  Training loss = 2.1620  Validation loss = 3.2854  \n",
      "\n",
      "Fold: 32  Epoch: 363  Training loss = 2.1619  Validation loss = 3.2853  \n",
      "\n",
      "Fold: 32  Epoch: 364  Training loss = 2.1616  Validation loss = 3.2848  \n",
      "\n",
      "Fold: 32  Epoch: 365  Training loss = 2.1614  Validation loss = 3.2833  \n",
      "\n",
      "Fold: 32  Epoch: 366  Training loss = 2.1611  Validation loss = 3.2825  \n",
      "\n",
      "Fold: 32  Epoch: 367  Training loss = 2.1610  Validation loss = 3.2821  \n",
      "\n",
      "Fold: 32  Epoch: 368  Training loss = 2.1608  Validation loss = 3.2820  \n",
      "\n",
      "Fold: 32  Epoch: 369  Training loss = 2.1607  Validation loss = 3.2811  \n",
      "\n",
      "Fold: 32  Epoch: 370  Training loss = 2.1605  Validation loss = 3.2815  \n",
      "\n",
      "Fold: 32  Epoch: 371  Training loss = 2.1604  Validation loss = 3.2818  \n",
      "\n",
      "Fold: 32  Epoch: 372  Training loss = 2.1603  Validation loss = 3.2813  \n",
      "\n",
      "Fold: 32  Epoch: 373  Training loss = 2.1601  Validation loss = 3.2814  \n",
      "\n",
      "Fold: 32  Epoch: 374  Training loss = 2.1599  Validation loss = 3.2813  \n",
      "\n",
      "Fold: 32  Epoch: 375  Training loss = 2.1597  Validation loss = 3.2810  \n",
      "\n",
      "Fold: 32  Epoch: 376  Training loss = 2.1595  Validation loss = 3.2790  \n",
      "\n",
      "Fold: 32  Epoch: 377  Training loss = 2.1593  Validation loss = 3.2792  \n",
      "\n",
      "Fold: 32  Epoch: 378  Training loss = 2.1591  Validation loss = 3.2788  \n",
      "\n",
      "Fold: 32  Epoch: 379  Training loss = 2.1590  Validation loss = 3.2794  \n",
      "\n",
      "Fold: 32  Epoch: 380  Training loss = 2.1588  Validation loss = 3.2798  \n",
      "\n",
      "Fold: 32  Epoch: 381  Training loss = 2.1586  Validation loss = 3.2787  \n",
      "\n",
      "Fold: 32  Epoch: 382  Training loss = 2.1585  Validation loss = 3.2779  \n",
      "\n",
      "Fold: 32  Epoch: 383  Training loss = 2.1582  Validation loss = 3.2771  \n",
      "\n",
      "Fold: 32  Epoch: 384  Training loss = 2.1581  Validation loss = 3.2776  \n",
      "\n",
      "Fold: 32  Epoch: 385  Training loss = 2.1579  Validation loss = 3.2773  \n",
      "\n",
      "Fold: 32  Epoch: 386  Training loss = 2.1577  Validation loss = 3.2765  \n",
      "\n",
      "Fold: 32  Epoch: 387  Training loss = 2.1575  Validation loss = 3.2758  \n",
      "\n",
      "Fold: 32  Epoch: 388  Training loss = 2.1574  Validation loss = 3.2759  \n",
      "\n",
      "Fold: 32  Epoch: 389  Training loss = 2.1572  Validation loss = 3.2759  \n",
      "\n",
      "Fold: 32  Epoch: 390  Training loss = 2.1571  Validation loss = 3.2761  \n",
      "\n",
      "Fold: 32  Epoch: 391  Training loss = 2.1569  Validation loss = 3.2752  \n",
      "\n",
      "Fold: 32  Epoch: 392  Training loss = 2.1567  Validation loss = 3.2747  \n",
      "\n",
      "Fold: 32  Epoch: 393  Training loss = 2.1565  Validation loss = 3.2746  \n",
      "\n",
      "Fold: 32  Epoch: 394  Training loss = 2.1563  Validation loss = 3.2738  \n",
      "\n",
      "Fold: 32  Epoch: 395  Training loss = 2.1562  Validation loss = 3.2749  \n",
      "\n",
      "Fold: 32  Epoch: 396  Training loss = 2.1560  Validation loss = 3.2748  \n",
      "\n",
      "Fold: 32  Epoch: 397  Training loss = 2.1558  Validation loss = 3.2739  \n",
      "\n",
      "Fold: 32  Epoch: 398  Training loss = 2.1557  Validation loss = 3.2736  \n",
      "\n",
      "Fold: 32  Epoch: 399  Training loss = 2.1556  Validation loss = 3.2732  \n",
      "\n",
      "Fold: 32  Epoch: 400  Training loss = 2.1553  Validation loss = 3.2724  \n",
      "\n",
      "Fold: 32  Epoch: 401  Training loss = 2.1552  Validation loss = 3.2724  \n",
      "\n",
      "Fold: 32  Epoch: 402  Training loss = 2.1550  Validation loss = 3.2718  \n",
      "\n",
      "Fold: 32  Epoch: 403  Training loss = 2.1548  Validation loss = 3.2705  \n",
      "\n",
      "Fold: 32  Epoch: 404  Training loss = 2.1545  Validation loss = 3.2698  \n",
      "\n",
      "Fold: 32  Epoch: 405  Training loss = 2.1543  Validation loss = 3.2690  \n",
      "\n",
      "Fold: 32  Epoch: 406  Training loss = 2.1541  Validation loss = 3.2680  \n",
      "\n",
      "Fold: 32  Epoch: 407  Training loss = 2.1538  Validation loss = 3.2666  \n",
      "\n",
      "Fold: 32  Epoch: 408  Training loss = 2.1537  Validation loss = 3.2659  \n",
      "\n",
      "Fold: 32  Epoch: 409  Training loss = 2.1535  Validation loss = 3.2658  \n",
      "\n",
      "Fold: 32  Epoch: 410  Training loss = 2.1534  Validation loss = 3.2644  \n",
      "\n",
      "Fold: 32  Epoch: 411  Training loss = 2.1532  Validation loss = 3.2631  \n",
      "\n",
      "Fold: 32  Epoch: 412  Training loss = 2.1531  Validation loss = 3.2637  \n",
      "\n",
      "Fold: 32  Epoch: 413  Training loss = 2.1529  Validation loss = 3.2630  \n",
      "\n",
      "Fold: 32  Epoch: 414  Training loss = 2.1527  Validation loss = 3.2626  \n",
      "\n",
      "Fold: 32  Epoch: 415  Training loss = 2.1526  Validation loss = 3.2624  \n",
      "\n",
      "Fold: 32  Epoch: 416  Training loss = 2.1524  Validation loss = 3.2626  \n",
      "\n",
      "Fold: 32  Epoch: 417  Training loss = 2.1522  Validation loss = 3.2629  \n",
      "\n",
      "Fold: 32  Epoch: 418  Training loss = 2.1520  Validation loss = 3.2631  \n",
      "\n",
      "Fold: 32  Epoch: 419  Training loss = 2.1519  Validation loss = 3.2632  \n",
      "\n",
      "Fold: 32  Epoch: 420  Training loss = 2.1517  Validation loss = 3.2629  \n",
      "\n",
      "Fold: 32  Epoch: 421  Training loss = 2.1515  Validation loss = 3.2626  \n",
      "\n",
      "Fold: 32  Epoch: 422  Training loss = 2.1514  Validation loss = 3.2633  \n",
      "\n",
      "Fold: 32  Epoch: 423  Training loss = 2.1513  Validation loss = 3.2633  \n",
      "\n",
      "Fold: 32  Epoch: 424  Training loss = 2.1510  Validation loss = 3.2626  \n",
      "\n",
      "Fold: 32  Epoch: 425  Training loss = 2.1508  Validation loss = 3.2622  \n",
      "\n",
      "Fold: 32  Epoch: 426  Training loss = 2.1507  Validation loss = 3.2625  \n",
      "\n",
      "Fold: 32  Epoch: 427  Training loss = 2.1506  Validation loss = 3.2633  \n",
      "\n",
      "Fold: 32  Epoch: 428  Training loss = 2.1505  Validation loss = 3.2638  \n",
      "\n",
      "Check model:  Fold: 32  Optimal epoch: 425  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 2. Train model\n",
    "# ==================================\n",
    "sess = tf.InteractiveSession()  # Launch Graph\n",
    "sess.run(tf.global_variables_initializer())  # Initialise all variables\n",
    "\n",
    "print(\"Start training\", \n",
    "      \"\\nHyperparameters:\",\n",
    "      \"\\nDimension of recurrent unit =\", n_hidden,\n",
    "      \"\\nLearning rate =\", learning_rate,\n",
    "      \"\\nEpochs =\", epochs,\n",
    "      \"\\nBatch size =\", batch_size,\n",
    "      \"\\nEarly stopping epochs =\", early_stop_iters,\n",
    "      \"\\nLearning rate =\", learning_rate)\n",
    "\n",
    "total_batch = int(window_length / batch_size)\n",
    "validation_fold_error = [] # store validation error of each fold\n",
    "optimal_epochs = []\n",
    "\n",
    "# loop through folds\n",
    "for fold in range(1, len(valIndex)):\n",
    "    validx = train_features[valIndex[fold-1]:valIndex[fold]]\n",
    "    validy = train_target[valIndex[fold-1]:valIndex[fold]]\n",
    "    trainx = train_features[(fold-1)*4:valIndex[(fold-1)]]\n",
    "    trainy = train_target[(fold-1)*4:valIndex[(fold-1)]]\n",
    "\n",
    "    loss_list = [] # store validation loss after each epoch for early stopping\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i in range(total_batch):\n",
    "            # Backprop\n",
    "            batch_xs, batch_ys = next_batch(num=batch_size, data=trainx, labels=trainy)\n",
    "            optimizer.run(feed_dict={x:batch_xs, y:batch_ys, lr:learning_rate})\n",
    "\n",
    "        # Loss\n",
    "        loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "        loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "        loss_list.append(loss_valid)\n",
    "\n",
    "        print(\"Fold: {0:d}\".format(fold),\n",
    "              \" Epoch: {0:d}\".format(epoch+1),\n",
    "              \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "              \" Validation loss = {0:.4f}\".format(np.sqrt(loss_valid)),\n",
    "              \" \\n\")\n",
    "\n",
    "        if all(j <= loss_valid for j in loss_list[-early_stop_iters:]) and len(loss_list)>early_stop_iters:\n",
    "            break\n",
    "    \n",
    "    # Load model with lowest validation error for each fold\n",
    "    epoch_hat = np.argmin(loss_list) + 1\n",
    "    optimal_epochs.append(epoch_hat) # store optimal number of epochs for each fold\n",
    "    \n",
    "    # RMSE\n",
    "    loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "    loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "    validation_fold_error.append(np.sqrt(loss_valid))\n",
    "    \n",
    "    print(\"Check model:\",\n",
    "          \" Fold: {0:d}\".format(fold),\n",
    "          \" Optimal epoch: {0:d}\".format(epoch_hat),\n",
    "          \" \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average number of epochs: 324\n",
      "Average validation error: 3.46586\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 3. Optimal epoch choice\n",
    "# ==================================\n",
    "# Pick number of epochs to train model for out-of-sample testing\n",
    "epoch_hat = int(np.mean(optimal_epochs))\n",
    "print(\"\\nAverage number of epochs:\", epoch_hat)\n",
    "# Average validation error\n",
    "print(\"Average validation error:\", np.mean(validation_fold_error))\n",
    "\n",
    "# Save validated model\n",
    "saveModel(sess, \n",
    "          MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + str(epoch_hat) + \"_validated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fixed scheme:\n",
      "Epoch: 1  Training loss = 2.0137  Test loss = 3.3275  \n",
      "\n",
      "Epoch: 2  Training loss = 2.0136  Test loss = 3.3273  \n",
      "\n",
      "Epoch: 3  Training loss = 2.0135  Test loss = 3.3272  \n",
      "\n",
      "Epoch: 4  Training loss = 2.0134  Test loss = 3.3270  \n",
      "\n",
      "Epoch: 5  Training loss = 2.0134  Test loss = 3.3268  \n",
      "\n",
      "Epoch: 6  Training loss = 2.0133  Test loss = 3.3266  \n",
      "\n",
      "Epoch: 7  Training loss = 2.0132  Test loss = 3.3264  \n",
      "\n",
      "Epoch: 8  Training loss = 2.0131  Test loss = 3.3262  \n",
      "\n",
      "Epoch: 9  Training loss = 2.0131  Test loss = 3.3260  \n",
      "\n",
      "Epoch: 10  Training loss = 2.0130  Test loss = 3.3258  \n",
      "\n",
      "Epoch: 11  Training loss = 2.0129  Test loss = 3.3256  \n",
      "\n",
      "Epoch: 12  Training loss = 2.0128  Test loss = 3.3254  \n",
      "\n",
      "Epoch: 13  Training loss = 2.0127  Test loss = 3.3252  \n",
      "\n",
      "Epoch: 14  Training loss = 2.0127  Test loss = 3.3250  \n",
      "\n",
      "Epoch: 15  Training loss = 2.0126  Test loss = 3.3249  \n",
      "\n",
      "Epoch: 16  Training loss = 2.0125  Test loss = 3.3247  \n",
      "\n",
      "Epoch: 17  Training loss = 2.0124  Test loss = 3.3245  \n",
      "\n",
      "Epoch: 18  Training loss = 2.0124  Test loss = 3.3243  \n",
      "\n",
      "Epoch: 19  Training loss = 2.0123  Test loss = 3.3241  \n",
      "\n",
      "Epoch: 20  Training loss = 2.0122  Test loss = 3.3239  \n",
      "\n",
      "Epoch: 21  Training loss = 2.0121  Test loss = 3.3237  \n",
      "\n",
      "Epoch: 22  Training loss = 2.0121  Test loss = 3.3235  \n",
      "\n",
      "Epoch: 23  Training loss = 2.0120  Test loss = 3.3233  \n",
      "\n",
      "Epoch: 24  Training loss = 2.0119  Test loss = 3.3231  \n",
      "\n",
      "Epoch: 25  Training loss = 2.0118  Test loss = 3.3230  \n",
      "\n",
      "Epoch: 26  Training loss = 2.0118  Test loss = 3.3228  \n",
      "\n",
      "Epoch: 27  Training loss = 2.0117  Test loss = 3.3226  \n",
      "\n",
      "Epoch: 28  Training loss = 2.0116  Test loss = 3.3224  \n",
      "\n",
      "Epoch: 29  Training loss = 2.0115  Test loss = 3.3222  \n",
      "\n",
      "Epoch: 30  Training loss = 2.0114  Test loss = 3.3220  \n",
      "\n",
      "Epoch: 31  Training loss = 2.0114  Test loss = 3.3218  \n",
      "\n",
      "Epoch: 32  Training loss = 2.0113  Test loss = 3.3216  \n",
      "\n",
      "Epoch: 33  Training loss = 2.0112  Test loss = 3.3214  \n",
      "\n",
      "Epoch: 34  Training loss = 2.0111  Test loss = 3.3212  \n",
      "\n",
      "Epoch: 35  Training loss = 2.0111  Test loss = 3.3211  \n",
      "\n",
      "Epoch: 36  Training loss = 2.0110  Test loss = 3.3209  \n",
      "\n",
      "Epoch: 37  Training loss = 2.0109  Test loss = 3.3207  \n",
      "\n",
      "Epoch: 38  Training loss = 2.0108  Test loss = 3.3205  \n",
      "\n",
      "Epoch: 39  Training loss = 2.0108  Test loss = 3.3203  \n",
      "\n",
      "Epoch: 40  Training loss = 2.0107  Test loss = 3.3201  \n",
      "\n",
      "Epoch: 41  Training loss = 2.0106  Test loss = 3.3199  \n",
      "\n",
      "Epoch: 42  Training loss = 2.0105  Test loss = 3.3197  \n",
      "\n",
      "Epoch: 43  Training loss = 2.0105  Test loss = 3.3195  \n",
      "\n",
      "Epoch: 44  Training loss = 2.0104  Test loss = 3.3194  \n",
      "\n",
      "Epoch: 45  Training loss = 2.0103  Test loss = 3.3192  \n",
      "\n",
      "Epoch: 46  Training loss = 2.0102  Test loss = 3.3190  \n",
      "\n",
      "Epoch: 47  Training loss = 2.0102  Test loss = 3.3188  \n",
      "\n",
      "Epoch: 48  Training loss = 2.0101  Test loss = 3.3186  \n",
      "\n",
      "Epoch: 49  Training loss = 2.0100  Test loss = 3.3184  \n",
      "\n",
      "Epoch: 50  Training loss = 2.0099  Test loss = 3.3182  \n",
      "\n",
      "Epoch: 51  Training loss = 2.0099  Test loss = 3.3180  \n",
      "\n",
      "Epoch: 52  Training loss = 2.0098  Test loss = 3.3179  \n",
      "\n",
      "Epoch: 53  Training loss = 2.0097  Test loss = 3.3177  \n",
      "\n",
      "Epoch: 54  Training loss = 2.0096  Test loss = 3.3175  \n",
      "\n",
      "Epoch: 55  Training loss = 2.0096  Test loss = 3.3173  \n",
      "\n",
      "Epoch: 56  Training loss = 2.0095  Test loss = 3.3171  \n",
      "\n",
      "Epoch: 57  Training loss = 2.0094  Test loss = 3.3169  \n",
      "\n",
      "Epoch: 58  Training loss = 2.0093  Test loss = 3.3167  \n",
      "\n",
      "Epoch: 59  Training loss = 2.0093  Test loss = 3.3165  \n",
      "\n",
      "Epoch: 60  Training loss = 2.0092  Test loss = 3.3164  \n",
      "\n",
      "Epoch: 61  Training loss = 2.0091  Test loss = 3.3162  \n",
      "\n",
      "Epoch: 62  Training loss = 2.0090  Test loss = 3.3160  \n",
      "\n",
      "Epoch: 63  Training loss = 2.0090  Test loss = 3.3158  \n",
      "\n",
      "Epoch: 64  Training loss = 2.0089  Test loss = 3.3156  \n",
      "\n",
      "Epoch: 65  Training loss = 2.0088  Test loss = 3.3154  \n",
      "\n",
      "Epoch: 66  Training loss = 2.0087  Test loss = 3.3152  \n",
      "\n",
      "Epoch: 67  Training loss = 2.0087  Test loss = 3.3150  \n",
      "\n",
      "Epoch: 68  Training loss = 2.0086  Test loss = 3.3149  \n",
      "\n",
      "Epoch: 69  Training loss = 2.0085  Test loss = 3.3147  \n",
      "\n",
      "Epoch: 70  Training loss = 2.0084  Test loss = 3.3145  \n",
      "\n",
      "Epoch: 71  Training loss = 2.0084  Test loss = 3.3143  \n",
      "\n",
      "Epoch: 72  Training loss = 2.0083  Test loss = 3.3141  \n",
      "\n",
      "Epoch: 73  Training loss = 2.0082  Test loss = 3.3139  \n",
      "\n",
      "Epoch: 74  Training loss = 2.0081  Test loss = 3.3137  \n",
      "\n",
      "Epoch: 75  Training loss = 2.0081  Test loss = 3.3136  \n",
      "\n",
      "Epoch: 76  Training loss = 2.0080  Test loss = 3.3134  \n",
      "\n",
      "Epoch: 77  Training loss = 2.0079  Test loss = 3.3132  \n",
      "\n",
      "Epoch: 78  Training loss = 2.0078  Test loss = 3.3130  \n",
      "\n",
      "Epoch: 79  Training loss = 2.0078  Test loss = 3.3128  \n",
      "\n",
      "Epoch: 80  Training loss = 2.0077  Test loss = 3.3126  \n",
      "\n",
      "Epoch: 81  Training loss = 2.0076  Test loss = 3.3124  \n",
      "\n",
      "Epoch: 82  Training loss = 2.0075  Test loss = 3.3123  \n",
      "\n",
      "Epoch: 83  Training loss = 2.0075  Test loss = 3.3121  \n",
      "\n",
      "Epoch: 84  Training loss = 2.0074  Test loss = 3.3119  \n",
      "\n",
      "Epoch: 85  Training loss = 2.0073  Test loss = 3.3117  \n",
      "\n",
      "Epoch: 86  Training loss = 2.0072  Test loss = 3.3115  \n",
      "\n",
      "Epoch: 87  Training loss = 2.0072  Test loss = 3.3113  \n",
      "\n",
      "Epoch: 88  Training loss = 2.0071  Test loss = 3.3112  \n",
      "\n",
      "Epoch: 89  Training loss = 2.0070  Test loss = 3.3110  \n",
      "\n",
      "Epoch: 90  Training loss = 2.0070  Test loss = 3.3108  \n",
      "\n",
      "Epoch: 91  Training loss = 2.0069  Test loss = 3.3106  \n",
      "\n",
      "Epoch: 92  Training loss = 2.0068  Test loss = 3.3104  \n",
      "\n",
      "Epoch: 93  Training loss = 2.0067  Test loss = 3.3102  \n",
      "\n",
      "Epoch: 94  Training loss = 2.0067  Test loss = 3.3100  \n",
      "\n",
      "Epoch: 95  Training loss = 2.0066  Test loss = 3.3099  \n",
      "\n",
      "Epoch: 96  Training loss = 2.0065  Test loss = 3.3097  \n",
      "\n",
      "Epoch: 97  Training loss = 2.0064  Test loss = 3.3095  \n",
      "\n",
      "Epoch: 98  Training loss = 2.0064  Test loss = 3.3093  \n",
      "\n",
      "Epoch: 99  Training loss = 2.0063  Test loss = 3.3091  \n",
      "\n",
      "Epoch: 100  Training loss = 2.0062  Test loss = 3.3089  \n",
      "\n",
      "Epoch: 101  Training loss = 2.0061  Test loss = 3.3088  \n",
      "\n",
      "Epoch: 102  Training loss = 2.0061  Test loss = 3.3086  \n",
      "\n",
      "Epoch: 103  Training loss = 2.0060  Test loss = 3.3084  \n",
      "\n",
      "Epoch: 104  Training loss = 2.0059  Test loss = 3.3082  \n",
      "\n",
      "Epoch: 105  Training loss = 2.0059  Test loss = 3.3080  \n",
      "\n",
      "Epoch: 106  Training loss = 2.0058  Test loss = 3.3078  \n",
      "\n",
      "Epoch: 107  Training loss = 2.0057  Test loss = 3.3077  \n",
      "\n",
      "Epoch: 108  Training loss = 2.0056  Test loss = 3.3075  \n",
      "\n",
      "Epoch: 109  Training loss = 2.0056  Test loss = 3.3073  \n",
      "\n",
      "Epoch: 110  Training loss = 2.0055  Test loss = 3.3071  \n",
      "\n",
      "Epoch: 111  Training loss = 2.0054  Test loss = 3.3069  \n",
      "\n",
      "Epoch: 112  Training loss = 2.0053  Test loss = 3.3067  \n",
      "\n",
      "Epoch: 113  Training loss = 2.0053  Test loss = 3.3066  \n",
      "\n",
      "Epoch: 114  Training loss = 2.0052  Test loss = 3.3064  \n",
      "\n",
      "Epoch: 115  Training loss = 2.0051  Test loss = 3.3062  \n",
      "\n",
      "Epoch: 116  Training loss = 2.0050  Test loss = 3.3060  \n",
      "\n",
      "Epoch: 117  Training loss = 2.0050  Test loss = 3.3058  \n",
      "\n",
      "Epoch: 118  Training loss = 2.0049  Test loss = 3.3056  \n",
      "\n",
      "Epoch: 119  Training loss = 2.0048  Test loss = 3.3055  \n",
      "\n",
      "Epoch: 120  Training loss = 2.0048  Test loss = 3.3053  \n",
      "\n",
      "Epoch: 121  Training loss = 2.0047  Test loss = 3.3051  \n",
      "\n",
      "Epoch: 122  Training loss = 2.0046  Test loss = 3.3049  \n",
      "\n",
      "Epoch: 123  Training loss = 2.0045  Test loss = 3.3047  \n",
      "\n",
      "Epoch: 124  Training loss = 2.0045  Test loss = 3.3046  \n",
      "\n",
      "Epoch: 125  Training loss = 2.0044  Test loss = 3.3044  \n",
      "\n",
      "Epoch: 126  Training loss = 2.0043  Test loss = 3.3042  \n",
      "\n",
      "Epoch: 127  Training loss = 2.0043  Test loss = 3.3040  \n",
      "\n",
      "Epoch: 128  Training loss = 2.0042  Test loss = 3.3038  \n",
      "\n",
      "Epoch: 129  Training loss = 2.0041  Test loss = 3.3037  \n",
      "\n",
      "Epoch: 130  Training loss = 2.0040  Test loss = 3.3035  \n",
      "\n",
      "Epoch: 131  Training loss = 2.0040  Test loss = 3.3033  \n",
      "\n",
      "Epoch: 132  Training loss = 2.0039  Test loss = 3.3031  \n",
      "\n",
      "Epoch: 133  Training loss = 2.0038  Test loss = 3.3029  \n",
      "\n",
      "Epoch: 134  Training loss = 2.0037  Test loss = 3.3027  \n",
      "\n",
      "Epoch: 135  Training loss = 2.0037  Test loss = 3.3026  \n",
      "\n",
      "Epoch: 136  Training loss = 2.0036  Test loss = 3.3024  \n",
      "\n",
      "Epoch: 137  Training loss = 2.0035  Test loss = 3.3022  \n",
      "\n",
      "Epoch: 138  Training loss = 2.0035  Test loss = 3.3020  \n",
      "\n",
      "Epoch: 139  Training loss = 2.0034  Test loss = 3.3018  \n",
      "\n",
      "Epoch: 140  Training loss = 2.0033  Test loss = 3.3017  \n",
      "\n",
      "Epoch: 141  Training loss = 2.0032  Test loss = 3.3015  \n",
      "\n",
      "Epoch: 142  Training loss = 2.0032  Test loss = 3.3013  \n",
      "\n",
      "Epoch: 143  Training loss = 2.0031  Test loss = 3.3011  \n",
      "\n",
      "Epoch: 144  Training loss = 2.0030  Test loss = 3.3009  \n",
      "\n",
      "Epoch: 145  Training loss = 2.0030  Test loss = 3.3008  \n",
      "\n",
      "Epoch: 146  Training loss = 2.0029  Test loss = 3.3006  \n",
      "\n",
      "Epoch: 147  Training loss = 2.0028  Test loss = 3.3004  \n",
      "\n",
      "Epoch: 148  Training loss = 2.0027  Test loss = 3.3002  \n",
      "\n",
      "Epoch: 149  Training loss = 2.0027  Test loss = 3.3000  \n",
      "\n",
      "Epoch: 150  Training loss = 2.0026  Test loss = 3.2999  \n",
      "\n",
      "Epoch: 151  Training loss = 2.0025  Test loss = 3.2997  \n",
      "\n",
      "Epoch: 152  Training loss = 2.0025  Test loss = 3.2995  \n",
      "\n",
      "Epoch: 153  Training loss = 2.0024  Test loss = 3.2993  \n",
      "\n",
      "Epoch: 154  Training loss = 2.0023  Test loss = 3.2992  \n",
      "\n",
      "Epoch: 155  Training loss = 2.0022  Test loss = 3.2990  \n",
      "\n",
      "Epoch: 156  Training loss = 2.0022  Test loss = 3.2988  \n",
      "\n",
      "Epoch: 157  Training loss = 2.0021  Test loss = 3.2986  \n",
      "\n",
      "Epoch: 158  Training loss = 2.0020  Test loss = 3.2984  \n",
      "\n",
      "Epoch: 159  Training loss = 2.0020  Test loss = 3.2983  \n",
      "\n",
      "Epoch: 160  Training loss = 2.0019  Test loss = 3.2981  \n",
      "\n",
      "Epoch: 161  Training loss = 2.0018  Test loss = 3.2979  \n",
      "\n",
      "Epoch: 162  Training loss = 2.0017  Test loss = 3.2977  \n",
      "\n",
      "Epoch: 163  Training loss = 2.0017  Test loss = 3.2975  \n",
      "\n",
      "Epoch: 164  Training loss = 2.0016  Test loss = 3.2974  \n",
      "\n",
      "Epoch: 165  Training loss = 2.0015  Test loss = 3.2972  \n",
      "\n",
      "Epoch: 166  Training loss = 2.0015  Test loss = 3.2970  \n",
      "\n",
      "Epoch: 167  Training loss = 2.0014  Test loss = 3.2968  \n",
      "\n",
      "Epoch: 168  Training loss = 2.0013  Test loss = 3.2967  \n",
      "\n",
      "Epoch: 169  Training loss = 2.0012  Test loss = 3.2965  \n",
      "\n",
      "Epoch: 170  Training loss = 2.0012  Test loss = 3.2963  \n",
      "\n",
      "Epoch: 171  Training loss = 2.0011  Test loss = 3.2961  \n",
      "\n",
      "Epoch: 172  Training loss = 2.0010  Test loss = 3.2959  \n",
      "\n",
      "Epoch: 173  Training loss = 2.0010  Test loss = 3.2958  \n",
      "\n",
      "Epoch: 174  Training loss = 2.0009  Test loss = 3.2956  \n",
      "\n",
      "Epoch: 175  Training loss = 2.0008  Test loss = 3.2954  \n",
      "\n",
      "Epoch: 176  Training loss = 2.0008  Test loss = 3.2952  \n",
      "\n",
      "Epoch: 177  Training loss = 2.0007  Test loss = 3.2951  \n",
      "\n",
      "Epoch: 178  Training loss = 2.0006  Test loss = 3.2949  \n",
      "\n",
      "Epoch: 179  Training loss = 2.0005  Test loss = 3.2947  \n",
      "\n",
      "Epoch: 180  Training loss = 2.0005  Test loss = 3.2945  \n",
      "\n",
      "Epoch: 181  Training loss = 2.0004  Test loss = 3.2944  \n",
      "\n",
      "Epoch: 182  Training loss = 2.0003  Test loss = 3.2942  \n",
      "\n",
      "Epoch: 183  Training loss = 2.0003  Test loss = 3.2940  \n",
      "\n",
      "Epoch: 184  Training loss = 2.0002  Test loss = 3.2938  \n",
      "\n",
      "Epoch: 185  Training loss = 2.0001  Test loss = 3.2936  \n",
      "\n",
      "Epoch: 186  Training loss = 2.0000  Test loss = 3.2935  \n",
      "\n",
      "Epoch: 187  Training loss = 2.0000  Test loss = 3.2933  \n",
      "\n",
      "Epoch: 188  Training loss = 1.9999  Test loss = 3.2931  \n",
      "\n",
      "Epoch: 189  Training loss = 1.9998  Test loss = 3.2929  \n",
      "\n",
      "Epoch: 190  Training loss = 1.9998  Test loss = 3.2928  \n",
      "\n",
      "Epoch: 191  Training loss = 1.9997  Test loss = 3.2926  \n",
      "\n",
      "Epoch: 192  Training loss = 1.9996  Test loss = 3.2924  \n",
      "\n",
      "Epoch: 193  Training loss = 1.9996  Test loss = 3.2922  \n",
      "\n",
      "Epoch: 194  Training loss = 1.9995  Test loss = 3.2921  \n",
      "\n",
      "Epoch: 195  Training loss = 1.9994  Test loss = 3.2919  \n",
      "\n",
      "Epoch: 196  Training loss = 1.9994  Test loss = 3.2917  \n",
      "\n",
      "Epoch: 197  Training loss = 1.9993  Test loss = 3.2915  \n",
      "\n",
      "Epoch: 198  Training loss = 1.9992  Test loss = 3.2914  \n",
      "\n",
      "Epoch: 199  Training loss = 1.9991  Test loss = 3.2912  \n",
      "\n",
      "Epoch: 200  Training loss = 1.9991  Test loss = 3.2910  \n",
      "\n",
      "Epoch: 201  Training loss = 1.9990  Test loss = 3.2908  \n",
      "\n",
      "Epoch: 202  Training loss = 1.9989  Test loss = 3.2907  \n",
      "\n",
      "Epoch: 203  Training loss = 1.9989  Test loss = 3.2905  \n",
      "\n",
      "Epoch: 204  Training loss = 1.9988  Test loss = 3.2903  \n",
      "\n",
      "Epoch: 205  Training loss = 1.9987  Test loss = 3.2901  \n",
      "\n",
      "Epoch: 206  Training loss = 1.9987  Test loss = 3.2900  \n",
      "\n",
      "Epoch: 207  Training loss = 1.9986  Test loss = 3.2898  \n",
      "\n",
      "Epoch: 208  Training loss = 1.9985  Test loss = 3.2896  \n",
      "\n",
      "Epoch: 209  Training loss = 1.9984  Test loss = 3.2894  \n",
      "\n",
      "Epoch: 210  Training loss = 1.9984  Test loss = 3.2893  \n",
      "\n",
      "Epoch: 211  Training loss = 1.9983  Test loss = 3.2891  \n",
      "\n",
      "Epoch: 212  Training loss = 1.9982  Test loss = 3.2889  \n",
      "\n",
      "Epoch: 213  Training loss = 1.9982  Test loss = 3.2887  \n",
      "\n",
      "Epoch: 214  Training loss = 1.9981  Test loss = 3.2886  \n",
      "\n",
      "Epoch: 215  Training loss = 1.9980  Test loss = 3.2884  \n",
      "\n",
      "Epoch: 216  Training loss = 1.9980  Test loss = 3.2882  \n",
      "\n",
      "Epoch: 217  Training loss = 1.9979  Test loss = 3.2880  \n",
      "\n",
      "Epoch: 218  Training loss = 1.9978  Test loss = 3.2879  \n",
      "\n",
      "Epoch: 219  Training loss = 1.9978  Test loss = 3.2877  \n",
      "\n",
      "Epoch: 220  Training loss = 1.9977  Test loss = 3.2875  \n",
      "\n",
      "Epoch: 221  Training loss = 1.9976  Test loss = 3.2874  \n",
      "\n",
      "Epoch: 222  Training loss = 1.9975  Test loss = 3.2872  \n",
      "\n",
      "Epoch: 223  Training loss = 1.9975  Test loss = 3.2870  \n",
      "\n",
      "Epoch: 224  Training loss = 1.9974  Test loss = 3.2868  \n",
      "\n",
      "Epoch: 225  Training loss = 1.9973  Test loss = 3.2867  \n",
      "\n",
      "Epoch: 226  Training loss = 1.9973  Test loss = 3.2865  \n",
      "\n",
      "Epoch: 227  Training loss = 1.9972  Test loss = 3.2863  \n",
      "\n",
      "Epoch: 228  Training loss = 1.9971  Test loss = 3.2861  \n",
      "\n",
      "Epoch: 229  Training loss = 1.9971  Test loss = 3.2860  \n",
      "\n",
      "Epoch: 230  Training loss = 1.9970  Test loss = 3.2858  \n",
      "\n",
      "Epoch: 231  Training loss = 1.9969  Test loss = 3.2856  \n",
      "\n",
      "Epoch: 232  Training loss = 1.9969  Test loss = 3.2855  \n",
      "\n",
      "Epoch: 233  Training loss = 1.9968  Test loss = 3.2853  \n",
      "\n",
      "Epoch: 234  Training loss = 1.9967  Test loss = 3.2851  \n",
      "\n",
      "Epoch: 235  Training loss = 1.9967  Test loss = 3.2849  \n",
      "\n",
      "Epoch: 236  Training loss = 1.9966  Test loss = 3.2848  \n",
      "\n",
      "Epoch: 237  Training loss = 1.9965  Test loss = 3.2846  \n",
      "\n",
      "Epoch: 238  Training loss = 1.9965  Test loss = 3.2844  \n",
      "\n",
      "Epoch: 239  Training loss = 1.9964  Test loss = 3.2843  \n",
      "\n",
      "Epoch: 240  Training loss = 1.9963  Test loss = 3.2841  \n",
      "\n",
      "Epoch: 241  Training loss = 1.9962  Test loss = 3.2839  \n",
      "\n",
      "Epoch: 242  Training loss = 1.9962  Test loss = 3.2837  \n",
      "\n",
      "Epoch: 243  Training loss = 1.9961  Test loss = 3.2836  \n",
      "\n",
      "Epoch: 244  Training loss = 1.9960  Test loss = 3.2834  \n",
      "\n",
      "Epoch: 245  Training loss = 1.9960  Test loss = 3.2832  \n",
      "\n",
      "Epoch: 246  Training loss = 1.9959  Test loss = 3.2831  \n",
      "\n",
      "Epoch: 247  Training loss = 1.9958  Test loss = 3.2829  \n",
      "\n",
      "Epoch: 248  Training loss = 1.9958  Test loss = 3.2827  \n",
      "\n",
      "Epoch: 249  Training loss = 1.9957  Test loss = 3.2825  \n",
      "\n",
      "Epoch: 250  Training loss = 1.9956  Test loss = 3.2824  \n",
      "\n",
      "Epoch: 251  Training loss = 1.9956  Test loss = 3.2822  \n",
      "\n",
      "Epoch: 252  Training loss = 1.9955  Test loss = 3.2820  \n",
      "\n",
      "Epoch: 253  Training loss = 1.9954  Test loss = 3.2819  \n",
      "\n",
      "Epoch: 254  Training loss = 1.9954  Test loss = 3.2817  \n",
      "\n",
      "Epoch: 255  Training loss = 1.9953  Test loss = 3.2815  \n",
      "\n",
      "Epoch: 256  Training loss = 1.9952  Test loss = 3.2813  \n",
      "\n",
      "Epoch: 257  Training loss = 1.9952  Test loss = 3.2812  \n",
      "\n",
      "Epoch: 258  Training loss = 1.9951  Test loss = 3.2810  \n",
      "\n",
      "Epoch: 259  Training loss = 1.9950  Test loss = 3.2808  \n",
      "\n",
      "Epoch: 260  Training loss = 1.9950  Test loss = 3.2807  \n",
      "\n",
      "Epoch: 261  Training loss = 1.9949  Test loss = 3.2805  \n",
      "\n",
      "Epoch: 262  Training loss = 1.9948  Test loss = 3.2803  \n",
      "\n",
      "Epoch: 263  Training loss = 1.9948  Test loss = 3.2802  \n",
      "\n",
      "Epoch: 264  Training loss = 1.9947  Test loss = 3.2800  \n",
      "\n",
      "Epoch: 265  Training loss = 1.9946  Test loss = 3.2798  \n",
      "\n",
      "Epoch: 266  Training loss = 1.9946  Test loss = 3.2797  \n",
      "\n",
      "Epoch: 267  Training loss = 1.9945  Test loss = 3.2795  \n",
      "\n",
      "Epoch: 268  Training loss = 1.9944  Test loss = 3.2793  \n",
      "\n",
      "Epoch: 269  Training loss = 1.9944  Test loss = 3.2791  \n",
      "\n",
      "Epoch: 270  Training loss = 1.9943  Test loss = 3.2790  \n",
      "\n",
      "Epoch: 271  Training loss = 1.9942  Test loss = 3.2788  \n",
      "\n",
      "Epoch: 272  Training loss = 1.9941  Test loss = 3.2786  \n",
      "\n",
      "Epoch: 273  Training loss = 1.9941  Test loss = 3.2785  \n",
      "\n",
      "Epoch: 274  Training loss = 1.9940  Test loss = 3.2783  \n",
      "\n",
      "Epoch: 275  Training loss = 1.9939  Test loss = 3.2781  \n",
      "\n",
      "Epoch: 276  Training loss = 1.9939  Test loss = 3.2780  \n",
      "\n",
      "Epoch: 277  Training loss = 1.9938  Test loss = 3.2778  \n",
      "\n",
      "Epoch: 278  Training loss = 1.9937  Test loss = 3.2776  \n",
      "\n",
      "Epoch: 279  Training loss = 1.9937  Test loss = 3.2775  \n",
      "\n",
      "Epoch: 280  Training loss = 1.9936  Test loss = 3.2773  \n",
      "\n",
      "Epoch: 281  Training loss = 1.9935  Test loss = 3.2771  \n",
      "\n",
      "Epoch: 282  Training loss = 1.9935  Test loss = 3.2770  \n",
      "\n",
      "Epoch: 283  Training loss = 1.9934  Test loss = 3.2768  \n",
      "\n",
      "Epoch: 284  Training loss = 1.9933  Test loss = 3.2766  \n",
      "\n",
      "Epoch: 285  Training loss = 1.9933  Test loss = 3.2765  \n",
      "\n",
      "Epoch: 286  Training loss = 1.9932  Test loss = 3.2763  \n",
      "\n",
      "Epoch: 287  Training loss = 1.9931  Test loss = 3.2761  \n",
      "\n",
      "Epoch: 288  Training loss = 1.9931  Test loss = 3.2759  \n",
      "\n",
      "Epoch: 289  Training loss = 1.9930  Test loss = 3.2758  \n",
      "\n",
      "Epoch: 290  Training loss = 1.9929  Test loss = 3.2756  \n",
      "\n",
      "Epoch: 291  Training loss = 1.9929  Test loss = 3.2754  \n",
      "\n",
      "Epoch: 292  Training loss = 1.9928  Test loss = 3.2753  \n",
      "\n",
      "Epoch: 293  Training loss = 1.9927  Test loss = 3.2751  \n",
      "\n",
      "Epoch: 294  Training loss = 1.9927  Test loss = 3.2749  \n",
      "\n",
      "Epoch: 295  Training loss = 1.9926  Test loss = 3.2748  \n",
      "\n",
      "Epoch: 296  Training loss = 1.9925  Test loss = 3.2746  \n",
      "\n",
      "Epoch: 297  Training loss = 1.9925  Test loss = 3.2744  \n",
      "\n",
      "Epoch: 298  Training loss = 1.9924  Test loss = 3.2743  \n",
      "\n",
      "Epoch: 299  Training loss = 1.9923  Test loss = 3.2741  \n",
      "\n",
      "Epoch: 300  Training loss = 1.9923  Test loss = 3.2739  \n",
      "\n",
      "Epoch: 301  Training loss = 1.9922  Test loss = 3.2738  \n",
      "\n",
      "Epoch: 302  Training loss = 1.9921  Test loss = 3.2736  \n",
      "\n",
      "Epoch: 303  Training loss = 1.9921  Test loss = 3.2734  \n",
      "\n",
      "Epoch: 304  Training loss = 1.9920  Test loss = 3.2733  \n",
      "\n",
      "Epoch: 305  Training loss = 1.9920  Test loss = 3.2731  \n",
      "\n",
      "Epoch: 306  Training loss = 1.9919  Test loss = 3.2729  \n",
      "\n",
      "Epoch: 307  Training loss = 1.9918  Test loss = 3.2728  \n",
      "\n",
      "Epoch: 308  Training loss = 1.9918  Test loss = 3.2726  \n",
      "\n",
      "Epoch: 309  Training loss = 1.9917  Test loss = 3.2725  \n",
      "\n",
      "Epoch: 310  Training loss = 1.9916  Test loss = 3.2723  \n",
      "\n",
      "Epoch: 311  Training loss = 1.9916  Test loss = 3.2721  \n",
      "\n",
      "Epoch: 312  Training loss = 1.9915  Test loss = 3.2720  \n",
      "\n",
      "Epoch: 313  Training loss = 1.9914  Test loss = 3.2718  \n",
      "\n",
      "Epoch: 314  Training loss = 1.9914  Test loss = 3.2716  \n",
      "\n",
      "Epoch: 315  Training loss = 1.9913  Test loss = 3.2715  \n",
      "\n",
      "Epoch: 316  Training loss = 1.9912  Test loss = 3.2713  \n",
      "\n",
      "Epoch: 317  Training loss = 1.9912  Test loss = 3.2711  \n",
      "\n",
      "Epoch: 318  Training loss = 1.9911  Test loss = 3.2710  \n",
      "\n",
      "Epoch: 319  Training loss = 1.9910  Test loss = 3.2708  \n",
      "\n",
      "Epoch: 320  Training loss = 1.9910  Test loss = 3.2706  \n",
      "\n",
      "Epoch: 321  Training loss = 1.9909  Test loss = 3.2705  \n",
      "\n",
      "Epoch: 322  Training loss = 1.9908  Test loss = 3.2703  \n",
      "\n",
      "Epoch: 323  Training loss = 1.9908  Test loss = 3.2701  \n",
      "\n",
      "Epoch: 324  Training loss = 1.9907  Test loss = 3.2700  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 4. Fixed scheme\n",
    "# ==================================\n",
    "print(\"\\nFixed scheme:\")\n",
    "for epoch in range(epoch_hat):\n",
    "    x_train = train_features[-window_length:]\n",
    "    y_train = train_target[-window_length:]\n",
    "    optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:test_features, y:test_target})\n",
    "    print(\"Epoch: {0:d}\".format(epoch+1),\n",
    "          \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "          \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "          \" \\n\")\n",
    "\n",
    "# Forecasts\n",
    "yhat_test_fixed = pred.eval(feed_dict={x:test_features})\n",
    "yhat_train_fixed = pred.eval(feed_dict={x:x_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc054e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train set\n",
    "plt.plot(y_train, 'black')\n",
    "plt.plot(yhat_train_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ndjOzhnGxm5k1jIvdzKxhXOxmZg3zL0J2O3SUr6wOAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd046cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: fixed scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_test_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed scheme RMSE: 3.26997901282 \n",
      "Fixed scheme MAE:  2.5030424433\n"
     ]
    }
   ],
   "source": [
    "rmse_fixed = np.sqrt(np.mean((yhat_test_fixed[:,0]-test_target)**2))\n",
    "mae_fixed = np.mean(np.abs((yhat_test_fixed[:,0]-test_target)))\n",
    "print(\"Fixed scheme RMSE:\", rmse_fixed,\n",
    "     \"\\nFixed scheme MAE: \", mae_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Stack training and test set, this makes updating scheme easier to train\n",
    "all_features = np.concatenate((train_features[-window_length:], test_features), axis=0)\n",
    "all_target = np.concatenate((train_target[-window_length:], test_target), axis=0)\n",
    "\n",
    "# Vectors to store loss and forecasts\n",
    "test_loss = np.zeros(len(test_target))\n",
    "yhat_update = np.zeros(len(test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test period = 1  Training loss = 1.9907  Test loss = 4.8840  Model updated 0 times  \n",
      "\n",
      "Test period = 2  Training loss = 2.0807  Test loss = 3.3508  Model updated 0 times  \n",
      "\n",
      "Test period = 3  Training loss = 2.0966  Test loss = 1.3899  Model updated 0 times  \n",
      "\n",
      "Test period = 4  Training loss = 2.0969  Test loss = 0.5033  Model updated 0 times  \n",
      "\n",
      "Test period = 5  Training loss = 1.8823  Test loss = 0.1633  Model updated 1 times  \n",
      "\n",
      "Test period = 6  Training loss = 1.7696  Test loss = 0.6918  Model updated 1 times  \n",
      "\n",
      "Test period = 7  Training loss = 1.7177  Test loss = 1.4691  Model updated 1 times  \n",
      "\n",
      "Test period = 8  Training loss = 1.7260  Test loss = 2.5786  Model updated 1 times  \n",
      "\n",
      "Test period = 9  Training loss = 1.6701  Test loss = 2.9155  Model updated 2 times  \n",
      "\n",
      "Test period = 10  Training loss = 1.7051  Test loss = 0.7621  Model updated 2 times  \n",
      "\n",
      "Test period = 11  Training loss = 1.7040  Test loss = 0.9583  Model updated 2 times  \n",
      "\n",
      "Test period = 12  Training loss = 1.7064  Test loss = 0.8903  Model updated 2 times  \n",
      "\n",
      "Test period = 13  Training loss = 1.6520  Test loss = 0.3462  Model updated 3 times  \n",
      "\n",
      "Test period = 14  Training loss = 1.6523  Test loss = 1.1722  Model updated 3 times  \n",
      "\n",
      "Test period = 15  Training loss = 1.6368  Test loss = 3.0182  Model updated 3 times  \n",
      "\n",
      "Test period = 16  Training loss = 1.6677  Test loss = 4.6358  Model updated 3 times  \n",
      "\n",
      "Test period = 17  Training loss = 1.7130  Test loss = 2.7743  Model updated 4 times  \n",
      "\n",
      "Test period = 18  Training loss = 1.7454  Test loss = 0.0348  Model updated 4 times  \n",
      "\n",
      "Test period = 19  Training loss = 1.7395  Test loss = 0.2654  Model updated 4 times  \n",
      "\n",
      "Test period = 20  Training loss = 1.6430  Test loss = 1.6399  Model updated 4 times  \n",
      "\n",
      "Test period = 21  Training loss = 1.5993  Test loss = 2.2998  Model updated 5 times  \n",
      "\n",
      "Test period = 22  Training loss = 1.5945  Test loss = 3.0928  Model updated 5 times  \n",
      "\n",
      "Test period = 23  Training loss = 1.6399  Test loss = 0.2853  Model updated 5 times  \n",
      "\n",
      "Test period = 24  Training loss = 1.6378  Test loss = 2.3098  Model updated 5 times  \n",
      "\n",
      "Test period = 25  Training loss = 1.6115  Test loss = 0.1580  Model updated 6 times  \n",
      "\n",
      "Test period = 26  Training loss = 1.6078  Test loss = 0.2386  Model updated 6 times  \n",
      "\n",
      "Test period = 27  Training loss = 1.6080  Test loss = 0.9437  Model updated 6 times  \n",
      "\n",
      "Test period = 28  Training loss = 1.6115  Test loss = 1.8424  Model updated 6 times  \n",
      "\n",
      "Test period = 29  Training loss = 1.5845  Test loss = 1.1137  Model updated 7 times  \n",
      "\n",
      "Test period = 30  Training loss = 1.5846  Test loss = 1.3309  Model updated 7 times  \n",
      "\n",
      "Test period = 31  Training loss = 1.5873  Test loss = 2.5563  Model updated 7 times  \n",
      "\n",
      "Test period = 32  Training loss = 1.5596  Test loss = 0.5355  Model updated 7 times  \n",
      "\n",
      "Test period = 33  Training loss = 1.5240  Test loss = 1.2020  Model updated 8 times  \n",
      "\n",
      "Test period = 34  Training loss = 1.5218  Test loss = 0.3704  Model updated 8 times  \n",
      "\n",
      "Test period = 35  Training loss = 1.4650  Test loss = 0.3689  Model updated 8 times  \n",
      "\n",
      "Test period = 36  Training loss = 1.4618  Test loss = 5.1842  Model updated 8 times  \n",
      "\n",
      "Test period = 37  Training loss = 1.4951  Test loss = 0.9338  Model updated 9 times  \n",
      "\n",
      "Test period = 38  Training loss = 1.4208  Test loss = 1.6474  Model updated 9 times  \n",
      "\n",
      "Test period = 39  Training loss = 1.4354  Test loss = 0.8395  Model updated 9 times  \n",
      "\n",
      "Test period = 40  Training loss = 1.4348  Test loss = 1.9314  Model updated 9 times  \n",
      "\n",
      "Test period = 41  Training loss = 1.4224  Test loss = 2.0829  Model updated 10 times  \n",
      "\n",
      "Test period = 42  Training loss = 1.4451  Test loss = 2.3568  Model updated 10 times  \n",
      "\n",
      "Test period = 43  Training loss = 1.4740  Test loss = 3.6699  Model updated 10 times  \n",
      "\n",
      "Test period = 44  Training loss = 1.5418  Test loss = 12.0450  Model updated 10 times  \n",
      "\n",
      "Test period = 45  Training loss = 2.1290  Test loss = 5.6183  Model updated 11 times  \n",
      "\n",
      "Test period = 46  Training loss = 2.2395  Test loss = 0.6883  Model updated 11 times  \n",
      "\n",
      "Test period = 47  Training loss = 2.2407  Test loss = 0.4856  Model updated 11 times  \n",
      "\n",
      "Test period = 48  Training loss = 2.2393  Test loss = 0.4486  Model updated 11 times  \n",
      "\n",
      "Test period = 49  Training loss = 2.1807  Test loss = 1.1248  Model updated 12 times  \n",
      "\n",
      "Test period = 50  Training loss = 2.1841  Test loss = 2.6546  Model updated 12 times  \n",
      "\n",
      "Test period = 51  Training loss = 2.2068  Test loss = 1.0710  Model updated 12 times  \n",
      "\n",
      "Test period = 52  Training loss = 2.2051  Test loss = 1.3372  Model updated 12 times  \n",
      "\n",
      "Test period = 53  Training loss = 2.1656  Test loss = 1.4645  Model updated 13 times  \n",
      "\n",
      "Test period = 54  Training loss = 2.1731  Test loss = 1.7665  Model updated 13 times  \n",
      "\n",
      "Test period = 55  Training loss = 2.1827  Test loss = 0.4729  Model updated 13 times  \n",
      "\n",
      "Test period = 56  Training loss = 2.1789  Test loss = 1.8749  Model updated 13 times  \n",
      "\n",
      "Test period = 57  Training loss = 2.1683  Test loss = 1.1029  Model updated 14 times  \n",
      "\n",
      "Test period = 58  Training loss = 2.1721  Test loss = 1.9198  Model updated 14 times  \n",
      "\n",
      "Test period = 59  Training loss = 2.1831  Test loss = 0.5737  Model updated 14 times  \n",
      "\n",
      "Test period = 60  Training loss = 2.1842  Test loss = 0.1601  Model updated 14 times  \n",
      "\n",
      "Test period = 61  Training loss = 2.1607  Test loss = 0.7326  Model updated 15 times  \n",
      "\n",
      "Test period = 62  Training loss = 2.1615  Test loss = 2.9437  Model updated 15 times  \n",
      "\n",
      "Test period = 63  Training loss = 2.1919  Test loss = 0.3700  Model updated 15 times  \n",
      "\n",
      "Test period = 64  Training loss = 2.1841  Test loss = 0.4320  Model updated 15 times  \n",
      "\n",
      "Test period = 65  Training loss = 2.1681  Test loss = 0.0779  Model updated 16 times  \n",
      "\n",
      "Test period = 66  Training loss = 2.1679  Test loss = 1.3054  Model updated 16 times  \n",
      "\n",
      "Test period = 67  Training loss = 2.1654  Test loss = 1.3093  Model updated 16 times  \n",
      "\n",
      "Test period = 68  Training loss = 2.1678  Test loss = 3.1244  Model updated 16 times  \n",
      "\n",
      "Test period = 69  Training loss = 2.1897  Test loss = 4.8340  Model updated 17 times  \n",
      "\n",
      "Test period = 70  Training loss = 2.2694  Test loss = 0.0085  Model updated 17 times  \n",
      "\n",
      "Test period = 71  Training loss = 2.2655  Test loss = 1.3114  Model updated 17 times  \n",
      "\n",
      "Test period = 72  Training loss = 2.2709  Test loss = 2.8730  Model updated 17 times  \n",
      "\n",
      "Test period = 73  Training loss = 2.2779  Test loss = 1.8496  Model updated 18 times  \n",
      "\n",
      "Test period = 74  Training loss = 2.2852  Test loss = 0.5372  Model updated 18 times  \n",
      "\n",
      "Test period = 75  Training loss = 2.2744  Test loss = 0.0551  Model updated 18 times  \n",
      "\n",
      "Test period = 76  Training loss = 2.2719  Test loss = 1.4689  Model updated 18 times  \n",
      "\n",
      "Test period = 77  Training loss = 2.2526  Test loss = 1.6033  Model updated 19 times  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "retrain_count = 0\n",
    "for t in range(len(test_target)):\n",
    "    x_test = np.reshape(test_features[t], newshape=(1,4,3))\n",
    "    y_test = test_target[t]\n",
    "    test_loss[t] = np.sqrt(sess.run(loss, feed_dict={x:x_test, y:y_test}))\n",
    "    yhat_update[t] = pred.eval(feed_dict={x:x_test})\n",
    "\n",
    "    x_train = all_features[t:(window_length+t)]\n",
    "    y_train = all_target[t:(window_length+t)]\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:x_test, y:y_test})\n",
    "    \n",
    "    print(\"Test period = {0:d}\".format(t+1),\n",
    "      \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "      \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "      \" Model updated {0:d} times\".format(retrain_count),\n",
    "      \" \\n\")\n",
    "\n",
    "    if (t+1)%4==0:\n",
    "        retrain_count += 1\n",
    "        for epoch in range(epoch_hat):\n",
    "            for i in range(total_batch):\n",
    "                optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xeaab0f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: updating scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_update, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating scheme RMSE: 2.44930274 \n",
      "Updating scheme MAE:  1.70626796573\n"
     ]
    }
   ],
   "source": [
    "rmse_update = np.sqrt(np.mean((yhat_update-test_target)**2))\n",
    "mae_update = np.mean(np.abs((yhat_update-test_target)))\n",
    "print(\"Updating scheme RMSE:\", rmse_update,\n",
    "     \"\\nUpdating scheme MAE: \", mae_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + \"yhat_test_fixed.csv\", yhat_test_fixed)\n",
    "np.savetxt(MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + \"yhat_update.csv\", yhat_update)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
