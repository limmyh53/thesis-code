{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Directories\n",
    "MODEL_FOLDER = \"../../../models/lstm/\"\n",
    "MODEL_FILENAME = MODEL_FOLDER + \"4Q/128_units/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: model saver\n",
    "def saveModel(sess, MODEL_FILENAME):\n",
    "    if not os.path.exists(MODEL_FOLDER):\n",
    "        print('Creating path where to save model: ' + MODEL_FOLDER)\n",
    "        os.mkdir(MODEL_FOLDER)\n",
    "\n",
    "    #print('Saving model at: ' + MODEL_FILENAME)\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, MODEL_FILENAME)\n",
    "    #print('Model successfully saved.\\n')\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: model loader\n",
    "def loadModel(sess, MODEL_FILENAME):\n",
    "    if os.path.exists(MODEL_FILENAME + \".index\"):\n",
    "        print('Loading save model from: ' + MODEL_FILENAME)\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, MODEL_FILENAME)\n",
    "        print('Model successfully loaded.\\n')\n",
    "        return True\n",
    "    else:\n",
    "        print('Model file <<' + MODEL_FILENAME + '>> does not exists!')\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Hyperparameters\n",
    "epochs = 500\n",
    "learning_rate = 1e-1\n",
    "batch_size = 5\n",
    "early_stop_iters = 10\n",
    "folds = 32\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 3  # data input\n",
    "n_steps = 4  # timesteps\n",
    "n_hidden = 128 # dimension of recurrent unit\n",
    "\n",
    "# (REPRODUCIBILITY) set random seeds\n",
    "tf.set_random_seed(123)\n",
    "\n",
    "# Define weights and biases\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.truncated_normal([n_hidden, 1], stddev = 1.0 / tf.sqrt(float(n_hidden))),\n",
    "        name='out_weight')\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.zeros([1]),\n",
    "        name='out_bias')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: Build model\n",
    "def RNN(X, weights, biases, n_hidden):\n",
    "\n",
    "    # Define a LSTM cell with tensorflow\n",
    "    lstm_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden, state_is_tuple=True)\n",
    "    outputs, _ = tf.nn.dynamic_rnn(lstm_cell, X, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    out_layer = tf.matmul(outputs[:,-1,:], weights['out']) + biases['out']\n",
    "\n",
    "    return out_layer\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: select batch\n",
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the data...\n",
      "Finished: data loaded. Stats below: \n",
      "Nr of training samples: 193\n",
      "Nr of testing  samples: 77\n",
      "Number of variables: 3\n",
      "Number of lags: 4\n",
      "Window length: 65\n",
      "Number of validation folds: 32\n"
     ]
    }
   ],
   "source": [
    "# =================================\n",
    "# 0. Load dataset\n",
    "# =================================\n",
    "print(\"Loading the data...\")\n",
    "# Training set pre-processing\n",
    "train = pd.read_csv('../../../Data/train.csv')\n",
    "train_4lag_inflation = np.array(train[['inflation.lag4',\n",
    "                                       'inflation.lag5',\n",
    "                                       'inflation.lag6',\n",
    "                                       'inflation.lag7']])\n",
    "train_4lag_unemp = np.array(train[['unemp.lag4',\n",
    "                                   'unemp.lag5',\n",
    "                                   'unemp.lag6',\n",
    "                                   'unemp.lag7']])\n",
    "train_4lag_oil = np.array(train[['oil.lag4',\n",
    "                                 'oil.lag5',\n",
    "                                 'oil.lag6',\n",
    "                                 'oil.lag7']])\n",
    "train_features = np.concatenate((train_4lag_inflation[:,:,np.newaxis], \n",
    "\t                             train_4lag_unemp[:,:,np.newaxis],\n",
    "\t                             train_4lag_oil[:,:,np.newaxis]),\n",
    "\t                             axis=2)\n",
    "train_target = np.array(train['inflation.target'])\n",
    "\n",
    "# Test set pre-processing\n",
    "test = pd.read_csv('../../../Data/test.csv')\n",
    "test_4lag_inflation = np.array(test[['inflation.lag4',\n",
    "                                     'inflation.lag5',\n",
    "                                     'inflation.lag6',\n",
    "                                     'inflation.lag7']])\n",
    "test_4lag_unemp = np.array(test[['unemp.lag4',\n",
    "                                 'unemp.lag5',\n",
    "                                 'unemp.lag6',\n",
    "                                 'unemp.lag7']])\n",
    "test_4lag_oil = np.array(test[['oil.lag4',\n",
    "                               'oil.lag5',\n",
    "                               'oil.lag6',\n",
    "                               'oil.lag7']])\n",
    "test_features = np.concatenate((test_4lag_inflation[:,:,np.newaxis], \n",
    "\t                            test_4lag_unemp[:,:,np.newaxis],\n",
    "\t                            test_4lag_oil[:,:,np.newaxis]),\n",
    "\t                            axis=2)\n",
    "test_target = np.array(test['inflation.target'])\n",
    "\n",
    "(nrTrainSamples, timesteps, variables) = train_features.shape\n",
    "(nrTestSamples, _, _) = test_features.shape\n",
    "\n",
    "# Window length and validation fold index\n",
    "window_length = 65\n",
    "valIndex = np.linspace(start=window_length, stop=nrTrainSamples, \n",
    "                       endpoint=True, num=folds+1, dtype=np.int)\n",
    "\n",
    "print(\"Finished: data loaded. Stats below: \")\n",
    "print(\"Nr of training samples: %d\" % nrTrainSamples)\n",
    "print(\"Nr of testing  samples: %d\" % nrTestSamples)\n",
    "print(\"Number of variables: %d\" % variables)\n",
    "print(\"Number of lags: %d\" % timesteps)\n",
    "print(\"Window length: %d\" % window_length)\n",
    "print(\"Number of validation folds: %d\" % folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 1. Build model\n",
    "# ==================================\n",
    "# tf graph input\n",
    "x = tf.placeholder(\"float\", [None, n_steps, n_input], name='Batch')\n",
    "y = tf.placeholder(\"float\", name='True_labels_of_batch')\n",
    "lr = tf.placeholder(\"float\", name='Learning_rate')\n",
    "\n",
    "# Make predictions with the model\n",
    "pred = RNN(x, weights, biases, n_hidden)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss = tf.reduce_mean(tf.diag_part(tf.square(tf.subtract(x=pred, y=y))))\n",
    "optimizer = tf.train.GradientDescentOptimizer(lr).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training \n",
      "Hyperparameters: \n",
      "Dimension of recurrent unit = 128 \n",
      "Learning rate = 0.1 \n",
      "Epochs = 500 \n",
      "Batch size = 5 \n",
      "Early stopping epochs = 10 \n",
      "Learning rate = 0.1\n",
      "Fold: 1  Epoch: 1  Training loss = 3.7236  Validation loss = 4.0834  \n",
      "\n",
      "Fold: 1  Epoch: 2  Training loss = 2.4922  Validation loss = 1.8719  \n",
      "\n",
      "Fold: 1  Epoch: 3  Training loss = 2.5904  Validation loss = 2.5950  \n",
      "\n",
      "Fold: 1  Epoch: 4  Training loss = 2.2523  Validation loss = 2.3366  \n",
      "\n",
      "Fold: 1  Epoch: 5  Training loss = 2.3343  Validation loss = 2.3671  \n",
      "\n",
      "Fold: 1  Epoch: 6  Training loss = 2.2392  Validation loss = 1.8937  \n",
      "\n",
      "Fold: 1  Epoch: 7  Training loss = 2.2339  Validation loss = 1.4725  \n",
      "\n",
      "Fold: 1  Epoch: 8  Training loss = 2.2274  Validation loss = 1.8069  \n",
      "\n",
      "Fold: 1  Epoch: 9  Training loss = 2.2398  Validation loss = 1.6938  \n",
      "\n",
      "Fold: 1  Epoch: 10  Training loss = 2.2484  Validation loss = 2.0656  \n",
      "\n",
      "Fold: 1  Epoch: 11  Training loss = 2.3567  Validation loss = 2.6286  \n",
      "\n",
      "Check model:  Fold: 1  Optimal epoch: 7  \n",
      "\n",
      "Fold: 2  Epoch: 1  Training loss = 2.2677  Validation loss = 2.5761  \n",
      "\n",
      "Fold: 2  Epoch: 2  Training loss = 2.5562  Validation loss = 2.7218  \n",
      "\n",
      "Fold: 2  Epoch: 3  Training loss = 2.2889  Validation loss = 2.0118  \n",
      "\n",
      "Fold: 2  Epoch: 4  Training loss = 2.2573  Validation loss = 2.3921  \n",
      "\n",
      "Fold: 2  Epoch: 5  Training loss = 2.1806  Validation loss = 1.9899  \n",
      "\n",
      "Fold: 2  Epoch: 6  Training loss = 2.6530  Validation loss = 1.8509  \n",
      "\n",
      "Fold: 2  Epoch: 7  Training loss = 2.1608  Validation loss = 2.3830  \n",
      "\n",
      "Fold: 2  Epoch: 8  Training loss = 2.2836  Validation loss = 1.7863  \n",
      "\n",
      "Fold: 2  Epoch: 9  Training loss = 2.2033  Validation loss = 2.1975  \n",
      "\n",
      "Fold: 2  Epoch: 10  Training loss = 2.1946  Validation loss = 2.1010  \n",
      "\n",
      "Fold: 2  Epoch: 11  Training loss = 2.1786  Validation loss = 2.3739  \n",
      "\n",
      "Fold: 2  Epoch: 12  Training loss = 2.2658  Validation loss = 2.5403  \n",
      "\n",
      "Check model:  Fold: 2  Optimal epoch: 8  \n",
      "\n",
      "Fold: 3  Epoch: 1  Training loss = 1.3568  Validation loss = 3.3132  \n",
      "\n",
      "Fold: 3  Epoch: 2  Training loss = 1.3225  Validation loss = 3.0951  \n",
      "\n",
      "Fold: 3  Epoch: 3  Training loss = 1.3037  Validation loss = 2.7095  \n",
      "\n",
      "Fold: 3  Epoch: 4  Training loss = 1.2852  Validation loss = 2.7274  \n",
      "\n",
      "Fold: 3  Epoch: 5  Training loss = 1.3375  Validation loss = 3.3444  \n",
      "\n",
      "Fold: 3  Epoch: 6  Training loss = 1.3183  Validation loss = 3.3092  \n",
      "\n",
      "Fold: 3  Epoch: 7  Training loss = 1.2683  Validation loss = 2.7830  \n",
      "\n",
      "Fold: 3  Epoch: 8  Training loss = 1.2165  Validation loss = 2.6654  \n",
      "\n",
      "Fold: 3  Epoch: 9  Training loss = 1.3205  Validation loss = 3.1589  \n",
      "\n",
      "Fold: 3  Epoch: 10  Training loss = 1.2399  Validation loss = 2.4091  \n",
      "\n",
      "Fold: 3  Epoch: 11  Training loss = 1.3800  Validation loss = 3.5747  \n",
      "\n",
      "Check model:  Fold: 3  Optimal epoch: 10  \n",
      "\n",
      "Fold: 4  Epoch: 1  Training loss = 1.3585  Validation loss = 2.6886  \n",
      "\n",
      "Fold: 4  Epoch: 2  Training loss = 1.2401  Validation loss = 3.1530  \n",
      "\n",
      "Fold: 4  Epoch: 3  Training loss = 1.1902  Validation loss = 3.0570  \n",
      "\n",
      "Fold: 4  Epoch: 4  Training loss = 1.1450  Validation loss = 2.1054  \n",
      "\n",
      "Fold: 4  Epoch: 5  Training loss = 1.0887  Validation loss = 2.4804  \n",
      "\n",
      "Fold: 4  Epoch: 6  Training loss = 1.1892  Validation loss = 2.5862  \n",
      "\n",
      "Fold: 4  Epoch: 7  Training loss = 1.2562  Validation loss = 2.5560  \n",
      "\n",
      "Fold: 4  Epoch: 8  Training loss = 1.1145  Validation loss = 2.0962  \n",
      "\n",
      "Fold: 4  Epoch: 9  Training loss = 1.1731  Validation loss = 2.1216  \n",
      "\n",
      "Fold: 4  Epoch: 10  Training loss = 1.0680  Validation loss = 2.1829  \n",
      "\n",
      "Fold: 4  Epoch: 11  Training loss = 1.0494  Validation loss = 2.0431  \n",
      "\n",
      "Fold: 4  Epoch: 12  Training loss = 1.1701  Validation loss = 2.0498  \n",
      "\n",
      "Fold: 4  Epoch: 13  Training loss = 1.0079  Validation loss = 2.2567  \n",
      "\n",
      "Fold: 4  Epoch: 14  Training loss = 1.0485  Validation loss = 1.6811  \n",
      "\n",
      "Fold: 4  Epoch: 15  Training loss = 1.0561  Validation loss = 2.3312  \n",
      "\n",
      "Fold: 4  Epoch: 16  Training loss = 1.0070  Validation loss = 1.7147  \n",
      "\n",
      "Fold: 4  Epoch: 17  Training loss = 0.9784  Validation loss = 2.2702  \n",
      "\n",
      "Fold: 4  Epoch: 18  Training loss = 0.9831  Validation loss = 2.0695  \n",
      "\n",
      "Fold: 4  Epoch: 19  Training loss = 1.1252  Validation loss = 1.4514  \n",
      "\n",
      "Fold: 4  Epoch: 20  Training loss = 1.1747  Validation loss = 1.9085  \n",
      "\n",
      "Fold: 4  Epoch: 21  Training loss = 1.0382  Validation loss = 2.2861  \n",
      "\n",
      "Fold: 4  Epoch: 22  Training loss = 0.9677  Validation loss = 2.3287  \n",
      "\n",
      "Fold: 4  Epoch: 23  Training loss = 0.9227  Validation loss = 2.1247  \n",
      "\n",
      "Fold: 4  Epoch: 24  Training loss = 0.9659  Validation loss = 2.2571  \n",
      "\n",
      "Fold: 4  Epoch: 25  Training loss = 0.9254  Validation loss = 2.0707  \n",
      "\n",
      "Fold: 4  Epoch: 26  Training loss = 0.9497  Validation loss = 2.2117  \n",
      "\n",
      "Fold: 4  Epoch: 27  Training loss = 0.9340  Validation loss = 2.1183  \n",
      "\n",
      "Fold: 4  Epoch: 28  Training loss = 1.0175  Validation loss = 2.2456  \n",
      "\n",
      "Fold: 4  Epoch: 29  Training loss = 1.0784  Validation loss = 1.8319  \n",
      "\n",
      "Fold: 4  Epoch: 30  Training loss = 0.9959  Validation loss = 1.9755  \n",
      "\n",
      "Fold: 4  Epoch: 31  Training loss = 0.9624  Validation loss = 2.8152  \n",
      "\n",
      "Check model:  Fold: 4  Optimal epoch: 19  \n",
      "\n",
      "Fold: 5  Epoch: 1  Training loss = 0.9910  Validation loss = 2.7312  \n",
      "\n",
      "Fold: 5  Epoch: 2  Training loss = 1.0442  Validation loss = 1.3120  \n",
      "\n",
      "Fold: 5  Epoch: 3  Training loss = 1.0121  Validation loss = 2.3311  \n",
      "\n",
      "Fold: 5  Epoch: 4  Training loss = 0.9746  Validation loss = 2.0348  \n",
      "\n",
      "Fold: 5  Epoch: 5  Training loss = 1.0321  Validation loss = 2.0140  \n",
      "\n",
      "Fold: 5  Epoch: 6  Training loss = 0.9188  Validation loss = 1.7504  \n",
      "\n",
      "Fold: 5  Epoch: 7  Training loss = 0.9160  Validation loss = 1.4406  \n",
      "\n",
      "Fold: 5  Epoch: 8  Training loss = 1.3127  Validation loss = 3.4633  \n",
      "\n",
      "Fold: 5  Epoch: 9  Training loss = 1.2106  Validation loss = 1.9592  \n",
      "\n",
      "Fold: 5  Epoch: 10  Training loss = 1.1361  Validation loss = 1.9299  \n",
      "\n",
      "Fold: 5  Epoch: 11  Training loss = 0.9505  Validation loss = 1.5181  \n",
      "\n",
      "Fold: 5  Epoch: 12  Training loss = 1.0884  Validation loss = 1.5139  \n",
      "\n",
      "Fold: 5  Epoch: 13  Training loss = 0.9451  Validation loss = 1.7542  \n",
      "\n",
      "Fold: 5  Epoch: 14  Training loss = 1.0907  Validation loss = 1.8147  \n",
      "\n",
      "Fold: 5  Epoch: 15  Training loss = 1.0197  Validation loss = 1.5360  \n",
      "\n",
      "Fold: 5  Epoch: 16  Training loss = 0.8816  Validation loss = 0.8417  \n",
      "\n",
      "Fold: 5  Epoch: 17  Training loss = 0.8815  Validation loss = 0.6175  \n",
      "\n",
      "Fold: 5  Epoch: 18  Training loss = 0.9609  Validation loss = 1.0719  \n",
      "\n",
      "Fold: 5  Epoch: 19  Training loss = 1.0618  Validation loss = 0.9832  \n",
      "\n",
      "Fold: 5  Epoch: 20  Training loss = 0.8886  Validation loss = 1.0750  \n",
      "\n",
      "Fold: 5  Epoch: 21  Training loss = 1.0399  Validation loss = 1.5453  \n",
      "\n",
      "Fold: 5  Epoch: 22  Training loss = 0.8405  Validation loss = 0.7356  \n",
      "\n",
      "Fold: 5  Epoch: 23  Training loss = 0.8554  Validation loss = 1.2277  \n",
      "\n",
      "Fold: 5  Epoch: 24  Training loss = 0.7918  Validation loss = 1.2975  \n",
      "\n",
      "Fold: 5  Epoch: 25  Training loss = 0.7860  Validation loss = 0.9922  \n",
      "\n",
      "Fold: 5  Epoch: 26  Training loss = 0.8287  Validation loss = 1.3923  \n",
      "\n",
      "Fold: 5  Epoch: 27  Training loss = 1.0743  Validation loss = 0.9214  \n",
      "\n",
      "Fold: 5  Epoch: 28  Training loss = 0.8218  Validation loss = 1.2136  \n",
      "\n",
      "Fold: 5  Epoch: 29  Training loss = 1.0561  Validation loss = 1.2865  \n",
      "\n",
      "Fold: 5  Epoch: 30  Training loss = 0.8167  Validation loss = 1.3223  \n",
      "\n",
      "Fold: 5  Epoch: 31  Training loss = 1.0079  Validation loss = 1.3740  \n",
      "\n",
      "Fold: 5  Epoch: 32  Training loss = 1.2127  Validation loss = 0.8199  \n",
      "\n",
      "Fold: 5  Epoch: 33  Training loss = 1.0884  Validation loss = 1.4604  \n",
      "\n",
      "Check model:  Fold: 5  Optimal epoch: 17  \n",
      "\n",
      "Fold: 6  Epoch: 1  Training loss = 0.8225  Validation loss = 1.8248  \n",
      "\n",
      "Fold: 6  Epoch: 2  Training loss = 1.1075  Validation loss = 1.5961  \n",
      "\n",
      "Fold: 6  Epoch: 3  Training loss = 0.8982  Validation loss = 1.8225  \n",
      "\n",
      "Fold: 6  Epoch: 4  Training loss = 0.8619  Validation loss = 1.7971  \n",
      "\n",
      "Fold: 6  Epoch: 5  Training loss = 0.7641  Validation loss = 2.2776  \n",
      "\n",
      "Fold: 6  Epoch: 6  Training loss = 0.7424  Validation loss = 1.9895  \n",
      "\n",
      "Fold: 6  Epoch: 7  Training loss = 0.7520  Validation loss = 2.0617  \n",
      "\n",
      "Fold: 6  Epoch: 8  Training loss = 0.8687  Validation loss = 2.1120  \n",
      "\n",
      "Fold: 6  Epoch: 9  Training loss = 0.7416  Validation loss = 1.9435  \n",
      "\n",
      "Fold: 6  Epoch: 10  Training loss = 0.8316  Validation loss = 1.7432  \n",
      "\n",
      "Fold: 6  Epoch: 11  Training loss = 0.8453  Validation loss = 1.6516  \n",
      "\n",
      "Fold: 6  Epoch: 12  Training loss = 0.7632  Validation loss = 2.0565  \n",
      "\n",
      "Fold: 6  Epoch: 13  Training loss = 1.1198  Validation loss = 1.8519  \n",
      "\n",
      "Fold: 6  Epoch: 14  Training loss = 0.6887  Validation loss = 2.0504  \n",
      "\n",
      "Fold: 6  Epoch: 15  Training loss = 0.9317  Validation loss = 2.1480  \n",
      "\n",
      "Check model:  Fold: 6  Optimal epoch: 2  \n",
      "\n",
      "Fold: 7  Epoch: 1  Training loss = 0.9664  Validation loss = 1.9874  \n",
      "\n",
      "Fold: 7  Epoch: 2  Training loss = 0.7612  Validation loss = 2.3675  \n",
      "\n",
      "Fold: 7  Epoch: 3  Training loss = 0.7294  Validation loss = 2.3139  \n",
      "\n",
      "Fold: 7  Epoch: 4  Training loss = 0.7379  Validation loss = 2.0936  \n",
      "\n",
      "Fold: 7  Epoch: 5  Training loss = 0.7552  Validation loss = 2.0061  \n",
      "\n",
      "Fold: 7  Epoch: 6  Training loss = 0.7197  Validation loss = 2.4899  \n",
      "\n",
      "Fold: 7  Epoch: 7  Training loss = 0.7574  Validation loss = 2.2848  \n",
      "\n",
      "Fold: 7  Epoch: 8  Training loss = 0.7064  Validation loss = 2.2373  \n",
      "\n",
      "Fold: 7  Epoch: 9  Training loss = 0.7515  Validation loss = 2.2834  \n",
      "\n",
      "Fold: 7  Epoch: 10  Training loss = 1.0288  Validation loss = 2.7295  \n",
      "\n",
      "Fold: 7  Epoch: 11  Training loss = 0.7407  Validation loss = 2.6188  \n",
      "\n",
      "Fold: 7  Epoch: 12  Training loss = 0.7887  Validation loss = 2.4437  \n",
      "\n",
      "Fold: 7  Epoch: 13  Training loss = 0.8376  Validation loss = 2.3139  \n",
      "\n",
      "Fold: 7  Epoch: 14  Training loss = 0.8263  Validation loss = 2.4944  \n",
      "\n",
      "Fold: 7  Epoch: 15  Training loss = 0.7947  Validation loss = 2.3869  \n",
      "\n",
      "Fold: 7  Epoch: 16  Training loss = 0.8404  Validation loss = 2.2483  \n",
      "\n",
      "Fold: 7  Epoch: 17  Training loss = 0.8156  Validation loss = 2.1503  \n",
      "\n",
      "Fold: 7  Epoch: 18  Training loss = 0.7382  Validation loss = 2.4375  \n",
      "\n",
      "Fold: 7  Epoch: 19  Training loss = 0.8631  Validation loss = 2.5088  \n",
      "\n",
      "Fold: 7  Epoch: 20  Training loss = 0.6486  Validation loss = 2.1789  \n",
      "\n",
      "Fold: 7  Epoch: 21  Training loss = 0.9913  Validation loss = 1.6363  \n",
      "\n",
      "Fold: 7  Epoch: 22  Training loss = 0.7917  Validation loss = 1.9506  \n",
      "\n",
      "Fold: 7  Epoch: 23  Training loss = 0.7834  Validation loss = 1.7494  \n",
      "\n",
      "Fold: 7  Epoch: 24  Training loss = 0.7362  Validation loss = 2.5935  \n",
      "\n",
      "Check model:  Fold: 7  Optimal epoch: 21  \n",
      "\n",
      "Fold: 8  Epoch: 1  Training loss = 1.0685  Validation loss = 7.9416  \n",
      "\n",
      "Fold: 8  Epoch: 2  Training loss = 0.8472  Validation loss = 7.5917  \n",
      "\n",
      "Fold: 8  Epoch: 3  Training loss = 0.8823  Validation loss = 7.7209  \n",
      "\n",
      "Fold: 8  Epoch: 4  Training loss = 0.6689  Validation loss = 7.9605  \n",
      "\n",
      "Fold: 8  Epoch: 5  Training loss = 0.7959  Validation loss = 7.4402  \n",
      "\n",
      "Fold: 8  Epoch: 6  Training loss = 0.9904  Validation loss = 8.1844  \n",
      "\n",
      "Fold: 8  Epoch: 7  Training loss = 0.8019  Validation loss = 8.1391  \n",
      "\n",
      "Fold: 8  Epoch: 8  Training loss = 0.6095  Validation loss = 7.7971  \n",
      "\n",
      "Fold: 8  Epoch: 9  Training loss = 0.6280  Validation loss = 7.8587  \n",
      "\n",
      "Fold: 8  Epoch: 10  Training loss = 0.6735  Validation loss = 8.2640  \n",
      "\n",
      "Fold: 8  Epoch: 11  Training loss = 0.5547  Validation loss = 7.9895  \n",
      "\n",
      "Fold: 8  Epoch: 12  Training loss = 0.5330  Validation loss = 8.1614  \n",
      "\n",
      "Fold: 8  Epoch: 13  Training loss = 0.5559  Validation loss = 8.0013  \n",
      "\n",
      "Fold: 8  Epoch: 14  Training loss = 0.5025  Validation loss = 8.0820  \n",
      "\n",
      "Fold: 8  Epoch: 15  Training loss = 0.5682  Validation loss = 7.7654  \n",
      "\n",
      "Fold: 8  Epoch: 16  Training loss = 0.6115  Validation loss = 8.1972  \n",
      "\n",
      "Fold: 8  Epoch: 17  Training loss = 0.5032  Validation loss = 8.1492  \n",
      "\n",
      "Fold: 8  Epoch: 18  Training loss = 0.5332  Validation loss = 8.3848  \n",
      "\n",
      "Check model:  Fold: 8  Optimal epoch: 5  \n",
      "\n",
      "Fold: 9  Epoch: 1  Training loss = 2.3298  Validation loss = 10.4262  \n",
      "\n",
      "Fold: 9  Epoch: 2  Training loss = 1.7653  Validation loss = 6.7551  \n",
      "\n",
      "Fold: 9  Epoch: 3  Training loss = 1.6406  Validation loss = 7.5998  \n",
      "\n",
      "Fold: 9  Epoch: 4  Training loss = 2.1101  Validation loss = 8.8299  \n",
      "\n",
      "Fold: 9  Epoch: 5  Training loss = 2.0438  Validation loss = 7.5338  \n",
      "\n",
      "Fold: 9  Epoch: 6  Training loss = 1.9850  Validation loss = 7.4188  \n",
      "\n",
      "Fold: 9  Epoch: 7  Training loss = 1.7443  Validation loss = 8.0887  \n",
      "\n",
      "Fold: 9  Epoch: 8  Training loss = 1.6846  Validation loss = 8.2414  \n",
      "\n",
      "Fold: 9  Epoch: 9  Training loss = 1.8981  Validation loss = 9.0133  \n",
      "\n",
      "Fold: 9  Epoch: 10  Training loss = 1.8022  Validation loss = 6.7917  \n",
      "\n",
      "Fold: 9  Epoch: 11  Training loss = 1.4437  Validation loss = 7.5690  \n",
      "\n",
      "Fold: 9  Epoch: 12  Training loss = 1.5842  Validation loss = 7.3302  \n",
      "\n",
      "Fold: 9  Epoch: 13  Training loss = 2.1243  Validation loss = 8.5936  \n",
      "\n",
      "Fold: 9  Epoch: 14  Training loss = 1.6851  Validation loss = 7.9980  \n",
      "\n",
      "Fold: 9  Epoch: 15  Training loss = 1.5527  Validation loss = 7.5826  \n",
      "\n",
      "Fold: 9  Epoch: 16  Training loss = 2.0511  Validation loss = 8.6261  \n",
      "\n",
      "Fold: 9  Epoch: 17  Training loss = 1.6814  Validation loss = 7.7080  \n",
      "\n",
      "Fold: 9  Epoch: 18  Training loss = 1.5080  Validation loss = 7.6234  \n",
      "\n",
      "Fold: 9  Epoch: 19  Training loss = 1.4992  Validation loss = 7.5751  \n",
      "\n",
      "Fold: 9  Epoch: 20  Training loss = 1.4440  Validation loss = 7.1097  \n",
      "\n",
      "Fold: 9  Epoch: 21  Training loss = 1.4552  Validation loss = 7.8247  \n",
      "\n",
      "Fold: 9  Epoch: 22  Training loss = 2.1140  Validation loss = 5.6335  \n",
      "\n",
      "Fold: 9  Epoch: 23  Training loss = 1.4072  Validation loss = 6.7009  \n",
      "\n",
      "Fold: 9  Epoch: 24  Training loss = 1.5058  Validation loss = 5.8656  \n",
      "\n",
      "Fold: 9  Epoch: 25  Training loss = 1.5539  Validation loss = 6.3809  \n",
      "\n",
      "Fold: 9  Epoch: 26  Training loss = 1.3332  Validation loss = 6.7650  \n",
      "\n",
      "Fold: 9  Epoch: 27  Training loss = 1.3781  Validation loss = 7.1188  \n",
      "\n",
      "Fold: 9  Epoch: 28  Training loss = 1.1773  Validation loss = 6.7526  \n",
      "\n",
      "Fold: 9  Epoch: 29  Training loss = 1.3528  Validation loss = 7.1873  \n",
      "\n",
      "Fold: 9  Epoch: 30  Training loss = 1.3820  Validation loss = 5.6632  \n",
      "\n",
      "Fold: 9  Epoch: 31  Training loss = 1.3125  Validation loss = 6.0619  \n",
      "\n",
      "Fold: 9  Epoch: 32  Training loss = 1.7456  Validation loss = 8.3033  \n",
      "\n",
      "Check model:  Fold: 9  Optimal epoch: 22  \n",
      "\n",
      "Fold: 10  Epoch: 1  Training loss = 2.4501  Validation loss = 2.1173  \n",
      "\n",
      "Fold: 10  Epoch: 2  Training loss = 2.1663  Validation loss = 3.9548  \n",
      "\n",
      "Fold: 10  Epoch: 3  Training loss = 2.4898  Validation loss = 3.3596  \n",
      "\n",
      "Fold: 10  Epoch: 4  Training loss = 2.7832  Validation loss = 2.9696  \n",
      "\n",
      "Fold: 10  Epoch: 5  Training loss = 2.1530  Validation loss = 3.5298  \n",
      "\n",
      "Fold: 10  Epoch: 6  Training loss = 3.2501  Validation loss = 2.4824  \n",
      "\n",
      "Fold: 10  Epoch: 7  Training loss = 2.4261  Validation loss = 2.6013  \n",
      "\n",
      "Fold: 10  Epoch: 8  Training loss = 2.1018  Validation loss = 3.7001  \n",
      "\n",
      "Fold: 10  Epoch: 9  Training loss = 1.8693  Validation loss = 3.0015  \n",
      "\n",
      "Fold: 10  Epoch: 10  Training loss = 2.4136  Validation loss = 2.3006  \n",
      "\n",
      "Fold: 10  Epoch: 11  Training loss = 1.9253  Validation loss = 2.3209  \n",
      "\n",
      "Fold: 10  Epoch: 12  Training loss = 2.1349  Validation loss = 1.0868  \n",
      "\n",
      "Fold: 10  Epoch: 13  Training loss = 2.2153  Validation loss = 1.8914  \n",
      "\n",
      "Fold: 10  Epoch: 14  Training loss = 1.8005  Validation loss = 3.7136  \n",
      "\n",
      "Check model:  Fold: 10  Optimal epoch: 12  \n",
      "\n",
      "Fold: 11  Epoch: 1  Training loss = 1.9163  Validation loss = 1.6943  \n",
      "\n",
      "Fold: 11  Epoch: 2  Training loss = 1.8362  Validation loss = 1.7485  \n",
      "\n",
      "Fold: 11  Epoch: 3  Training loss = 2.2166  Validation loss = 4.1276  \n",
      "\n",
      "Fold: 11  Epoch: 4  Training loss = 2.2305  Validation loss = 3.0645  \n",
      "\n",
      "Fold: 11  Epoch: 5  Training loss = 2.2327  Validation loss = 1.5925  \n",
      "\n",
      "Fold: 11  Epoch: 6  Training loss = 2.5740  Validation loss = 2.4368  \n",
      "\n",
      "Fold: 11  Epoch: 7  Training loss = 1.7315  Validation loss = 2.1671  \n",
      "\n",
      "Fold: 11  Epoch: 8  Training loss = 1.6665  Validation loss = 2.2226  \n",
      "\n",
      "Fold: 11  Epoch: 9  Training loss = 1.7342  Validation loss = 2.0752  \n",
      "\n",
      "Fold: 11  Epoch: 10  Training loss = 1.7018  Validation loss = 2.8310  \n",
      "\n",
      "Fold: 11  Epoch: 11  Training loss = 1.7541  Validation loss = 2.8537  \n",
      "\n",
      "Fold: 11  Epoch: 12  Training loss = 1.7759  Validation loss = 2.9319  \n",
      "\n",
      "Fold: 11  Epoch: 13  Training loss = 1.5105  Validation loss = 2.0618  \n",
      "\n",
      "Fold: 11  Epoch: 14  Training loss = 1.5541  Validation loss = 3.1473  \n",
      "\n",
      "Check model:  Fold: 11  Optimal epoch: 5  \n",
      "\n",
      "Fold: 12  Epoch: 1  Training loss = 1.5044  Validation loss = 2.8116  \n",
      "\n",
      "Fold: 12  Epoch: 2  Training loss = 1.7332  Validation loss = 2.1418  \n",
      "\n",
      "Fold: 12  Epoch: 3  Training loss = 1.4339  Validation loss = 3.4843  \n",
      "\n",
      "Fold: 12  Epoch: 4  Training loss = 1.6355  Validation loss = 2.0151  \n",
      "\n",
      "Fold: 12  Epoch: 5  Training loss = 1.4080  Validation loss = 1.8337  \n",
      "\n",
      "Fold: 12  Epoch: 6  Training loss = 1.6173  Validation loss = 2.3232  \n",
      "\n",
      "Fold: 12  Epoch: 7  Training loss = 1.3714  Validation loss = 2.4950  \n",
      "\n",
      "Fold: 12  Epoch: 8  Training loss = 1.4331  Validation loss = 2.2105  \n",
      "\n",
      "Fold: 12  Epoch: 9  Training loss = 1.4877  Validation loss = 2.6466  \n",
      "\n",
      "Fold: 12  Epoch: 10  Training loss = 1.3639  Validation loss = 2.1808  \n",
      "\n",
      "Fold: 12  Epoch: 11  Training loss = 1.6527  Validation loss = 2.1293  \n",
      "\n",
      "Fold: 12  Epoch: 12  Training loss = 1.3877  Validation loss = 2.0921  \n",
      "\n",
      "Fold: 12  Epoch: 13  Training loss = 1.3135  Validation loss = 2.1600  \n",
      "\n",
      "Fold: 12  Epoch: 14  Training loss = 1.3171  Validation loss = 1.9046  \n",
      "\n",
      "Fold: 12  Epoch: 15  Training loss = 1.2664  Validation loss = 2.0122  \n",
      "\n",
      "Fold: 12  Epoch: 16  Training loss = 1.2200  Validation loss = 2.6683  \n",
      "\n",
      "Check model:  Fold: 12  Optimal epoch: 5  \n",
      "\n",
      "Fold: 13  Epoch: 1  Training loss = 2.3695  Validation loss = 2.4078  \n",
      "\n",
      "Fold: 13  Epoch: 2  Training loss = 1.8643  Validation loss = 4.6915  \n",
      "\n",
      "Fold: 13  Epoch: 3  Training loss = 1.7753  Validation loss = 3.2552  \n",
      "\n",
      "Fold: 13  Epoch: 4  Training loss = 1.8627  Validation loss = 2.6652  \n",
      "\n",
      "Fold: 13  Epoch: 5  Training loss = 1.7389  Validation loss = 2.8755  \n",
      "\n",
      "Fold: 13  Epoch: 6  Training loss = 1.7322  Validation loss = 2.9702  \n",
      "\n",
      "Fold: 13  Epoch: 7  Training loss = 1.7625  Validation loss = 2.0228  \n",
      "\n",
      "Fold: 13  Epoch: 8  Training loss = 1.5432  Validation loss = 2.2361  \n",
      "\n",
      "Fold: 13  Epoch: 9  Training loss = 1.5758  Validation loss = 2.5525  \n",
      "\n",
      "Fold: 13  Epoch: 10  Training loss = 1.4684  Validation loss = 2.6866  \n",
      "\n",
      "Fold: 13  Epoch: 11  Training loss = 1.6974  Validation loss = 2.5558  \n",
      "\n",
      "Fold: 13  Epoch: 12  Training loss = 1.7346  Validation loss = 4.3249  \n",
      "\n",
      "Check model:  Fold: 13  Optimal epoch: 7  \n",
      "\n",
      "Fold: 14  Epoch: 1  Training loss = 1.7281  Validation loss = 6.2428  \n",
      "\n",
      "Fold: 14  Epoch: 2  Training loss = 1.7637  Validation loss = 6.2194  \n",
      "\n",
      "Fold: 14  Epoch: 3  Training loss = 1.7526  Validation loss = 5.8995  \n",
      "\n",
      "Fold: 14  Epoch: 4  Training loss = 1.7431  Validation loss = 4.9692  \n",
      "\n",
      "Fold: 14  Epoch: 5  Training loss = 2.1212  Validation loss = 4.2595  \n",
      "\n",
      "Fold: 14  Epoch: 6  Training loss = 1.5887  Validation loss = 5.9052  \n",
      "\n",
      "Fold: 14  Epoch: 7  Training loss = 1.6900  Validation loss = 6.9384  \n",
      "\n",
      "Fold: 14  Epoch: 8  Training loss = 1.9733  Validation loss = 4.7261  \n",
      "\n",
      "Fold: 14  Epoch: 9  Training loss = 1.7469  Validation loss = 6.7115  \n",
      "\n",
      "Fold: 14  Epoch: 10  Training loss = 1.8551  Validation loss = 6.6368  \n",
      "\n",
      "Fold: 14  Epoch: 11  Training loss = 1.6025  Validation loss = 5.0516  \n",
      "\n",
      "Fold: 14  Epoch: 12  Training loss = 1.5233  Validation loss = 6.1701  \n",
      "\n",
      "Fold: 14  Epoch: 13  Training loss = 1.7432  Validation loss = 4.8795  \n",
      "\n",
      "Fold: 14  Epoch: 14  Training loss = 1.6402  Validation loss = 6.4789  \n",
      "\n",
      "Fold: 14  Epoch: 15  Training loss = 1.8654  Validation loss = 4.8862  \n",
      "\n",
      "Fold: 14  Epoch: 16  Training loss = 2.3057  Validation loss = 7.0166  \n",
      "\n",
      "Check model:  Fold: 14  Optimal epoch: 5  \n",
      "\n",
      "Fold: 15  Epoch: 1  Training loss = 2.1270  Validation loss = 5.2653  \n",
      "\n",
      "Fold: 15  Epoch: 2  Training loss = 2.1914  Validation loss = 6.9220  \n",
      "\n",
      "Fold: 15  Epoch: 3  Training loss = 2.0723  Validation loss = 7.2518  \n",
      "\n",
      "Fold: 15  Epoch: 4  Training loss = 1.9003  Validation loss = 6.8046  \n",
      "\n",
      "Fold: 15  Epoch: 5  Training loss = 2.3587  Validation loss = 7.5757  \n",
      "\n",
      "Fold: 15  Epoch: 6  Training loss = 2.0170  Validation loss = 6.7409  \n",
      "\n",
      "Fold: 15  Epoch: 7  Training loss = 2.0742  Validation loss = 7.3937  \n",
      "\n",
      "Fold: 15  Epoch: 8  Training loss = 2.3329  Validation loss = 4.6370  \n",
      "\n",
      "Fold: 15  Epoch: 9  Training loss = 2.0933  Validation loss = 5.3691  \n",
      "\n",
      "Fold: 15  Epoch: 10  Training loss = 2.0870  Validation loss = 6.3495  \n",
      "\n",
      "Fold: 15  Epoch: 11  Training loss = 2.3211  Validation loss = 7.8016  \n",
      "\n",
      "Check model:  Fold: 15  Optimal epoch: 8  \n",
      "\n",
      "Fold: 16  Epoch: 1  Training loss = 2.7043  Validation loss = 3.3733  \n",
      "\n",
      "Fold: 16  Epoch: 2  Training loss = 2.7151  Validation loss = 5.2881  \n",
      "\n",
      "Fold: 16  Epoch: 3  Training loss = 2.5036  Validation loss = 4.4945  \n",
      "\n",
      "Fold: 16  Epoch: 4  Training loss = 2.6635  Validation loss = 3.8591  \n",
      "\n",
      "Fold: 16  Epoch: 5  Training loss = 2.5768  Validation loss = 5.0739  \n",
      "\n",
      "Fold: 16  Epoch: 6  Training loss = 3.2725  Validation loss = 7.1445  \n",
      "\n",
      "Fold: 16  Epoch: 7  Training loss = 2.4330  Validation loss = 5.8482  \n",
      "\n",
      "Fold: 16  Epoch: 8  Training loss = 2.5102  Validation loss = 5.5969  \n",
      "\n",
      "Fold: 16  Epoch: 9  Training loss = 2.7071  Validation loss = 6.1133  \n",
      "\n",
      "Fold: 16  Epoch: 10  Training loss = 2.5182  Validation loss = 5.8089  \n",
      "\n",
      "Fold: 16  Epoch: 11  Training loss = 2.6204  Validation loss = 4.6518  \n",
      "\n",
      "Fold: 16  Epoch: 12  Training loss = 2.6879  Validation loss = 5.2192  \n",
      "\n",
      "Fold: 16  Epoch: 13  Training loss = 2.4928  Validation loss = 8.2163  \n",
      "\n",
      "Check model:  Fold: 16  Optimal epoch: 1  \n",
      "\n",
      "Fold: 17  Epoch: 1  Training loss = 2.7599  Validation loss = 4.4300  \n",
      "\n",
      "Fold: 17  Epoch: 2  Training loss = 2.7797  Validation loss = 4.6936  \n",
      "\n",
      "Fold: 17  Epoch: 3  Training loss = 2.5683  Validation loss = 5.0146  \n",
      "\n",
      "Fold: 17  Epoch: 4  Training loss = 2.6583  Validation loss = 3.8324  \n",
      "\n",
      "Fold: 17  Epoch: 5  Training loss = 2.5035  Validation loss = 2.3725  \n",
      "\n",
      "Fold: 17  Epoch: 6  Training loss = 2.6563  Validation loss = 1.6221  \n",
      "\n",
      "Fold: 17  Epoch: 7  Training loss = 2.6152  Validation loss = 3.1818  \n",
      "\n",
      "Fold: 17  Epoch: 8  Training loss = 2.7528  Validation loss = 2.7465  \n",
      "\n",
      "Fold: 17  Epoch: 9  Training loss = 2.7698  Validation loss = 2.8335  \n",
      "\n",
      "Fold: 17  Epoch: 10  Training loss = 2.8224  Validation loss = 3.4949  \n",
      "\n",
      "Fold: 17  Epoch: 11  Training loss = 2.6240  Validation loss = 1.7164  \n",
      "\n",
      "Fold: 17  Epoch: 12  Training loss = 2.5163  Validation loss = 3.4067  \n",
      "\n",
      "Fold: 17  Epoch: 13  Training loss = 3.0856  Validation loss = 3.5066  \n",
      "\n",
      "Fold: 17  Epoch: 14  Training loss = 2.8903  Validation loss = 3.7535  \n",
      "\n",
      "Check model:  Fold: 17  Optimal epoch: 6  \n",
      "\n",
      "Fold: 18  Epoch: 1  Training loss = 3.1143  Validation loss = 3.9185  \n",
      "\n",
      "Fold: 18  Epoch: 2  Training loss = 2.9724  Validation loss = 2.1657  \n",
      "\n",
      "Fold: 18  Epoch: 3  Training loss = 2.9963  Validation loss = 3.4964  \n",
      "\n",
      "Fold: 18  Epoch: 4  Training loss = 2.9916  Validation loss = 3.1171  \n",
      "\n",
      "Fold: 18  Epoch: 5  Training loss = 2.7161  Validation loss = 2.7569  \n",
      "\n",
      "Fold: 18  Epoch: 6  Training loss = 2.5982  Validation loss = 3.8046  \n",
      "\n",
      "Fold: 18  Epoch: 7  Training loss = 3.2778  Validation loss = 3.3375  \n",
      "\n",
      "Fold: 18  Epoch: 8  Training loss = 2.5945  Validation loss = 3.7986  \n",
      "\n",
      "Fold: 18  Epoch: 9  Training loss = 3.4629  Validation loss = 2.8451  \n",
      "\n",
      "Fold: 18  Epoch: 10  Training loss = 3.5810  Validation loss = 3.4012  \n",
      "\n",
      "Fold: 18  Epoch: 11  Training loss = 2.5573  Validation loss = 3.8565  \n",
      "\n",
      "Check model:  Fold: 18  Optimal epoch: 2  \n",
      "\n",
      "Fold: 19  Epoch: 1  Training loss = 2.6086  Validation loss = 2.4919  \n",
      "\n",
      "Fold: 19  Epoch: 2  Training loss = 3.8632  Validation loss = 1.5477  \n",
      "\n",
      "Fold: 19  Epoch: 3  Training loss = 2.5759  Validation loss = 3.0919  \n",
      "\n",
      "Fold: 19  Epoch: 4  Training loss = 2.5766  Validation loss = 2.7496  \n",
      "\n",
      "Fold: 19  Epoch: 5  Training loss = 2.6239  Validation loss = 4.0738  \n",
      "\n",
      "Fold: 19  Epoch: 6  Training loss = 2.4031  Validation loss = 2.9475  \n",
      "\n",
      "Fold: 19  Epoch: 7  Training loss = 2.6736  Validation loss = 2.7782  \n",
      "\n",
      "Fold: 19  Epoch: 8  Training loss = 2.7476  Validation loss = 3.6983  \n",
      "\n",
      "Fold: 19  Epoch: 9  Training loss = 2.7625  Validation loss = 4.3711  \n",
      "\n",
      "Fold: 19  Epoch: 10  Training loss = 3.0627  Validation loss = 3.0708  \n",
      "\n",
      "Fold: 19  Epoch: 11  Training loss = 3.0487  Validation loss = 2.8960  \n",
      "\n",
      "Fold: 19  Epoch: 12  Training loss = 2.7270  Validation loss = 4.4906  \n",
      "\n",
      "Check model:  Fold: 19  Optimal epoch: 2  \n",
      "\n",
      "Fold: 20  Epoch: 1  Training loss = 3.2850  Validation loss = 3.1769  \n",
      "\n",
      "Fold: 20  Epoch: 2  Training loss = 2.5665  Validation loss = 2.4550  \n",
      "\n",
      "Fold: 20  Epoch: 3  Training loss = 2.4864  Validation loss = 4.5462  \n",
      "\n",
      "Fold: 20  Epoch: 4  Training loss = 3.0751  Validation loss = 1.7681  \n",
      "\n",
      "Fold: 20  Epoch: 5  Training loss = 2.7284  Validation loss = 3.2517  \n",
      "\n",
      "Fold: 20  Epoch: 6  Training loss = 3.0184  Validation loss = 4.1675  \n",
      "\n",
      "Fold: 20  Epoch: 7  Training loss = 2.6066  Validation loss = 3.4007  \n",
      "\n",
      "Fold: 20  Epoch: 8  Training loss = 2.7578  Validation loss = 4.0275  \n",
      "\n",
      "Fold: 20  Epoch: 9  Training loss = 3.4788  Validation loss = 6.2996  \n",
      "\n",
      "Fold: 20  Epoch: 10  Training loss = 2.6188  Validation loss = 2.9022  \n",
      "\n",
      "Fold: 20  Epoch: 11  Training loss = 2.4786  Validation loss = 4.2698  \n",
      "\n",
      "Fold: 20  Epoch: 12  Training loss = 3.0309  Validation loss = 5.5446  \n",
      "\n",
      "Fold: 20  Epoch: 13  Training loss = 2.4893  Validation loss = 4.3305  \n",
      "\n",
      "Fold: 20  Epoch: 14  Training loss = 2.5563  Validation loss = 3.2673  \n",
      "\n",
      "Fold: 20  Epoch: 15  Training loss = 3.0506  Validation loss = 3.5124  \n",
      "\n",
      "Fold: 20  Epoch: 16  Training loss = 3.0184  Validation loss = 5.9343  \n",
      "\n",
      "Fold: 20  Epoch: 17  Training loss = 2.5547  Validation loss = 6.1405  \n",
      "\n",
      "Fold: 20  Epoch: 18  Training loss = 2.4274  Validation loss = 5.2256  \n",
      "\n",
      "Fold: 20  Epoch: 19  Training loss = 2.5095  Validation loss = 5.6193  \n",
      "\n",
      "Fold: 20  Epoch: 20  Training loss = 2.5051  Validation loss = 5.1515  \n",
      "\n",
      "Fold: 20  Epoch: 21  Training loss = 2.6788  Validation loss = 4.2848  \n",
      "\n",
      "Fold: 20  Epoch: 22  Training loss = 2.7015  Validation loss = 3.6132  \n",
      "\n",
      "Fold: 20  Epoch: 23  Training loss = 2.7578  Validation loss = 2.3138  \n",
      "\n",
      "Fold: 20  Epoch: 24  Training loss = 2.6490  Validation loss = 4.6911  \n",
      "\n",
      "Fold: 20  Epoch: 25  Training loss = 2.8243  Validation loss = 6.7104  \n",
      "\n",
      "Check model:  Fold: 20  Optimal epoch: 4  \n",
      "\n",
      "Fold: 21  Epoch: 1  Training loss = 3.5821  Validation loss = 3.4971  \n",
      "\n",
      "Fold: 21  Epoch: 2  Training loss = 2.7725  Validation loss = 2.3214  \n",
      "\n",
      "Fold: 21  Epoch: 3  Training loss = 2.7006  Validation loss = 3.4809  \n",
      "\n",
      "Fold: 21  Epoch: 4  Training loss = 2.8579  Validation loss = 3.6980  \n",
      "\n",
      "Fold: 21  Epoch: 5  Training loss = 2.7072  Validation loss = 3.7196  \n",
      "\n",
      "Fold: 21  Epoch: 6  Training loss = 2.6692  Validation loss = 2.2433  \n",
      "\n",
      "Fold: 21  Epoch: 7  Training loss = 2.5220  Validation loss = 2.8036  \n",
      "\n",
      "Fold: 21  Epoch: 8  Training loss = 2.8578  Validation loss = 3.1825  \n",
      "\n",
      "Fold: 21  Epoch: 9  Training loss = 2.8062  Validation loss = 2.5830  \n",
      "\n",
      "Fold: 21  Epoch: 10  Training loss = 3.1321  Validation loss = 3.5852  \n",
      "\n",
      "Fold: 21  Epoch: 11  Training loss = 2.5824  Validation loss = 3.6167  \n",
      "\n",
      "Fold: 21  Epoch: 12  Training loss = 2.9045  Validation loss = 2.8378  \n",
      "\n",
      "Fold: 21  Epoch: 13  Training loss = 3.2707  Validation loss = 3.5255  \n",
      "\n",
      "Fold: 21  Epoch: 14  Training loss = 2.7094  Validation loss = 2.3030  \n",
      "\n",
      "Fold: 21  Epoch: 15  Training loss = 3.3408  Validation loss = 4.2290  \n",
      "\n",
      "Check model:  Fold: 21  Optimal epoch: 6  \n",
      "\n",
      "Fold: 22  Epoch: 1  Training loss = 2.6368  Validation loss = 2.6974  \n",
      "\n",
      "Fold: 22  Epoch: 2  Training loss = 2.5183  Validation loss = 2.5336  \n",
      "\n",
      "Fold: 22  Epoch: 3  Training loss = 2.4751  Validation loss = 2.3050  \n",
      "\n",
      "Fold: 22  Epoch: 4  Training loss = 2.5352  Validation loss = 2.5448  \n",
      "\n",
      "Fold: 22  Epoch: 5  Training loss = 2.2996  Validation loss = 2.2406  \n",
      "\n",
      "Fold: 22  Epoch: 6  Training loss = 2.3735  Validation loss = 2.1631  \n",
      "\n",
      "Fold: 22  Epoch: 7  Training loss = 3.5299  Validation loss = 3.1512  \n",
      "\n",
      "Fold: 22  Epoch: 8  Training loss = 3.2747  Validation loss = 4.4689  \n",
      "\n",
      "Fold: 22  Epoch: 9  Training loss = 2.4622  Validation loss = 2.4756  \n",
      "\n",
      "Fold: 22  Epoch: 10  Training loss = 2.3778  Validation loss = 1.6807  \n",
      "\n",
      "Fold: 22  Epoch: 11  Training loss = 2.4577  Validation loss = 1.9594  \n",
      "\n",
      "Fold: 22  Epoch: 12  Training loss = 2.8402  Validation loss = 3.9255  \n",
      "\n",
      "Fold: 22  Epoch: 13  Training loss = 2.3327  Validation loss = 3.3064  \n",
      "\n",
      "Fold: 22  Epoch: 14  Training loss = 3.2033  Validation loss = 2.1007  \n",
      "\n",
      "Fold: 22  Epoch: 15  Training loss = 2.4106  Validation loss = 1.6306  \n",
      "\n",
      "Fold: 22  Epoch: 16  Training loss = 2.6004  Validation loss = 2.4425  \n",
      "\n",
      "Fold: 22  Epoch: 17  Training loss = 2.1458  Validation loss = 2.9695  \n",
      "\n",
      "Fold: 22  Epoch: 18  Training loss = 2.1553  Validation loss = 3.0206  \n",
      "\n",
      "Fold: 22  Epoch: 19  Training loss = 2.2722  Validation loss = 4.9478  \n",
      "\n",
      "Check model:  Fold: 22  Optimal epoch: 15  \n",
      "\n",
      "Fold: 23  Epoch: 1  Training loss = 2.3303  Validation loss = 3.4325  \n",
      "\n",
      "Fold: 23  Epoch: 2  Training loss = 2.0008  Validation loss = 3.5793  \n",
      "\n",
      "Fold: 23  Epoch: 3  Training loss = 1.9957  Validation loss = 3.2538  \n",
      "\n",
      "Fold: 23  Epoch: 4  Training loss = 2.2302  Validation loss = 3.9852  \n",
      "\n",
      "Fold: 23  Epoch: 5  Training loss = 2.5502  Validation loss = 4.5325  \n",
      "\n",
      "Fold: 23  Epoch: 6  Training loss = 2.1177  Validation loss = 4.2680  \n",
      "\n",
      "Fold: 23  Epoch: 7  Training loss = 2.5025  Validation loss = 2.7644  \n",
      "\n",
      "Fold: 23  Epoch: 8  Training loss = 2.3983  Validation loss = 3.4069  \n",
      "\n",
      "Fold: 23  Epoch: 9  Training loss = 2.1022  Validation loss = 3.7146  \n",
      "\n",
      "Fold: 23  Epoch: 10  Training loss = 2.0048  Validation loss = 3.0988  \n",
      "\n",
      "Fold: 23  Epoch: 11  Training loss = 1.9817  Validation loss = 3.1593  \n",
      "\n",
      "Fold: 23  Epoch: 12  Training loss = 2.1870  Validation loss = 2.7335  \n",
      "\n",
      "Fold: 23  Epoch: 13  Training loss = 2.0362  Validation loss = 2.8122  \n",
      "\n",
      "Fold: 23  Epoch: 14  Training loss = 1.8866  Validation loss = 3.2087  \n",
      "\n",
      "Fold: 23  Epoch: 15  Training loss = 2.8469  Validation loss = 6.4365  \n",
      "\n",
      "Check model:  Fold: 23  Optimal epoch: 12  \n",
      "\n",
      "Fold: 24  Epoch: 1  Training loss = 2.2620  Validation loss = 1.8030  \n",
      "\n",
      "Fold: 24  Epoch: 2  Training loss = 2.1982  Validation loss = 1.7432  \n",
      "\n",
      "Fold: 24  Epoch: 3  Training loss = 2.3948  Validation loss = 2.7634  \n",
      "\n",
      "Fold: 24  Epoch: 4  Training loss = 2.0163  Validation loss = 2.4264  \n",
      "\n",
      "Fold: 24  Epoch: 5  Training loss = 3.6552  Validation loss = 2.3410  \n",
      "\n",
      "Fold: 24  Epoch: 6  Training loss = 4.2092  Validation loss = 5.8433  \n",
      "\n",
      "Fold: 24  Epoch: 7  Training loss = 2.8124  Validation loss = 3.3259  \n",
      "\n",
      "Fold: 24  Epoch: 8  Training loss = 2.5502  Validation loss = 1.9771  \n",
      "\n",
      "Fold: 24  Epoch: 9  Training loss = 2.9538  Validation loss = 4.3659  \n",
      "\n",
      "Fold: 24  Epoch: 10  Training loss = 2.7175  Validation loss = 1.1472  \n",
      "\n",
      "Fold: 24  Epoch: 11  Training loss = 2.2952  Validation loss = 1.2254  \n",
      "\n",
      "Fold: 24  Epoch: 12  Training loss = 2.5846  Validation loss = 1.7234  \n",
      "\n",
      "Fold: 24  Epoch: 13  Training loss = 2.8268  Validation loss = 1.2739  \n",
      "\n",
      "Fold: 24  Epoch: 14  Training loss = 2.7057  Validation loss = 3.1600  \n",
      "\n",
      "Fold: 24  Epoch: 15  Training loss = 2.8936  Validation loss = 3.4753  \n",
      "\n",
      "Fold: 24  Epoch: 16  Training loss = 2.3294  Validation loss = 2.3838  \n",
      "\n",
      "Fold: 24  Epoch: 17  Training loss = 2.6866  Validation loss = 1.3797  \n",
      "\n",
      "Fold: 24  Epoch: 18  Training loss = 2.7761  Validation loss = 2.3672  \n",
      "\n",
      "Fold: 24  Epoch: 19  Training loss = 2.4405  Validation loss = 2.7054  \n",
      "\n",
      "Fold: 24  Epoch: 20  Training loss = 2.3121  Validation loss = 2.9226  \n",
      "\n",
      "Fold: 24  Epoch: 21  Training loss = 2.2611  Validation loss = 2.4350  \n",
      "\n",
      "Fold: 24  Epoch: 22  Training loss = 2.5221  Validation loss = 4.0335  \n",
      "\n",
      "Check model:  Fold: 24  Optimal epoch: 10  \n",
      "\n",
      "Fold: 25  Epoch: 1  Training loss = 2.3398  Validation loss = 3.3977  \n",
      "\n",
      "Fold: 25  Epoch: 2  Training loss = 2.6417  Validation loss = 3.0806  \n",
      "\n",
      "Fold: 25  Epoch: 3  Training loss = 2.8429  Validation loss = 2.2538  \n",
      "\n",
      "Fold: 25  Epoch: 4  Training loss = 2.1992  Validation loss = 2.3022  \n",
      "\n",
      "Fold: 25  Epoch: 5  Training loss = 2.3277  Validation loss = 2.7296  \n",
      "\n",
      "Fold: 25  Epoch: 6  Training loss = 2.1444  Validation loss = 2.3367  \n",
      "\n",
      "Fold: 25  Epoch: 7  Training loss = 2.9434  Validation loss = 4.8075  \n",
      "\n",
      "Fold: 25  Epoch: 8  Training loss = 2.0761  Validation loss = 2.1253  \n",
      "\n",
      "Fold: 25  Epoch: 9  Training loss = 2.2659  Validation loss = 1.6856  \n",
      "\n",
      "Fold: 25  Epoch: 10  Training loss = 2.0840  Validation loss = 1.2250  \n",
      "\n",
      "Fold: 25  Epoch: 11  Training loss = 2.0862  Validation loss = 0.7510  \n",
      "\n",
      "Fold: 25  Epoch: 12  Training loss = 2.6057  Validation loss = 3.1130  \n",
      "\n",
      "Fold: 25  Epoch: 13  Training loss = 3.5278  Validation loss = 5.0110  \n",
      "\n",
      "Check model:  Fold: 25  Optimal epoch: 11  \n",
      "\n",
      "Fold: 26  Epoch: 1  Training loss = 2.6069  Validation loss = 1.1924  \n",
      "\n",
      "Fold: 26  Epoch: 2  Training loss = 2.4127  Validation loss = 2.0802  \n",
      "\n",
      "Fold: 26  Epoch: 3  Training loss = 2.3472  Validation loss = 0.5061  \n",
      "\n",
      "Fold: 26  Epoch: 4  Training loss = 3.1591  Validation loss = 1.7536  \n",
      "\n",
      "Fold: 26  Epoch: 5  Training loss = 2.4592  Validation loss = 0.8536  \n",
      "\n",
      "Fold: 26  Epoch: 6  Training loss = 2.2032  Validation loss = 2.4531  \n",
      "\n",
      "Fold: 26  Epoch: 7  Training loss = 2.7120  Validation loss = 1.6707  \n",
      "\n",
      "Fold: 26  Epoch: 8  Training loss = 2.0696  Validation loss = 1.9505  \n",
      "\n",
      "Fold: 26  Epoch: 9  Training loss = 2.8194  Validation loss = 2.2755  \n",
      "\n",
      "Fold: 26  Epoch: 10  Training loss = 2.1236  Validation loss = 1.4913  \n",
      "\n",
      "Fold: 26  Epoch: 11  Training loss = 2.7753  Validation loss = 0.9064  \n",
      "\n",
      "Fold: 26  Epoch: 12  Training loss = 2.5759  Validation loss = 3.9876  \n",
      "\n",
      "Check model:  Fold: 26  Optimal epoch: 3  \n",
      "\n",
      "Fold: 27  Epoch: 1  Training loss = 2.2533  Validation loss = 2.2180  \n",
      "\n",
      "Fold: 27  Epoch: 2  Training loss = 2.4346  Validation loss = 1.4856  \n",
      "\n",
      "Fold: 27  Epoch: 3  Training loss = 2.6820  Validation loss = 0.7343  \n",
      "\n",
      "Fold: 27  Epoch: 4  Training loss = 2.6091  Validation loss = 2.7452  \n",
      "\n",
      "Fold: 27  Epoch: 5  Training loss = 3.6688  Validation loss = 5.0289  \n",
      "\n",
      "Fold: 27  Epoch: 6  Training loss = 2.4870  Validation loss = 2.1275  \n",
      "\n",
      "Fold: 27  Epoch: 7  Training loss = 2.8948  Validation loss = 3.5544  \n",
      "\n",
      "Fold: 27  Epoch: 8  Training loss = 2.4040  Validation loss = 2.3491  \n",
      "\n",
      "Fold: 27  Epoch: 9  Training loss = 2.3386  Validation loss = 0.6098  \n",
      "\n",
      "Fold: 27  Epoch: 10  Training loss = 2.3264  Validation loss = 0.8811  \n",
      "\n",
      "Fold: 27  Epoch: 11  Training loss = 2.3371  Validation loss = 1.3189  \n",
      "\n",
      "Fold: 27  Epoch: 12  Training loss = 3.3171  Validation loss = 3.9116  \n",
      "\n",
      "Fold: 27  Epoch: 13  Training loss = 3.2708  Validation loss = 2.9607  \n",
      "\n",
      "Fold: 27  Epoch: 14  Training loss = 2.2125  Validation loss = 2.1034  \n",
      "\n",
      "Fold: 27  Epoch: 15  Training loss = 2.4679  Validation loss = 2.7268  \n",
      "\n",
      "Fold: 27  Epoch: 16  Training loss = 2.5258  Validation loss = 0.9176  \n",
      "\n",
      "Fold: 27  Epoch: 17  Training loss = 2.8322  Validation loss = 1.8259  \n",
      "\n",
      "Fold: 27  Epoch: 18  Training loss = 2.5154  Validation loss = 2.7341  \n",
      "\n",
      "Fold: 27  Epoch: 19  Training loss = 2.1417  Validation loss = 1.1533  \n",
      "\n",
      "Fold: 27  Epoch: 20  Training loss = 2.0895  Validation loss = 1.1918  \n",
      "\n",
      "Fold: 27  Epoch: 21  Training loss = 2.1893  Validation loss = 1.3333  \n",
      "\n",
      "Fold: 27  Epoch: 22  Training loss = 2.6184  Validation loss = 3.0837  \n",
      "\n",
      "Check model:  Fold: 27  Optimal epoch: 9  \n",
      "\n",
      "Fold: 28  Epoch: 1  Training loss = 1.9812  Validation loss = 1.4491  \n",
      "\n",
      "Fold: 28  Epoch: 2  Training loss = 1.9006  Validation loss = 0.8314  \n",
      "\n",
      "Fold: 28  Epoch: 3  Training loss = 1.9885  Validation loss = 0.4764  \n",
      "\n",
      "Fold: 28  Epoch: 4  Training loss = 2.1100  Validation loss = 0.9595  \n",
      "\n",
      "Fold: 28  Epoch: 5  Training loss = 2.5193  Validation loss = 0.6968  \n",
      "\n",
      "Fold: 28  Epoch: 6  Training loss = 2.0806  Validation loss = 1.4602  \n",
      "\n",
      "Fold: 28  Epoch: 7  Training loss = 3.6248  Validation loss = 3.7654  \n",
      "\n",
      "Fold: 28  Epoch: 8  Training loss = 1.7965  Validation loss = 0.8977  \n",
      "\n",
      "Fold: 28  Epoch: 9  Training loss = 1.8436  Validation loss = 1.5625  \n",
      "\n",
      "Fold: 28  Epoch: 10  Training loss = 2.3056  Validation loss = 2.1256  \n",
      "\n",
      "Fold: 28  Epoch: 11  Training loss = 1.9885  Validation loss = 1.7886  \n",
      "\n",
      "Fold: 28  Epoch: 12  Training loss = 2.0820  Validation loss = 0.5585  \n",
      "\n",
      "Fold: 28  Epoch: 13  Training loss = 2.0149  Validation loss = 0.8296  \n",
      "\n",
      "Fold: 28  Epoch: 14  Training loss = 2.0120  Validation loss = 1.6560  \n",
      "\n",
      "Fold: 28  Epoch: 15  Training loss = 2.6617  Validation loss = 1.2034  \n",
      "\n",
      "Fold: 28  Epoch: 16  Training loss = 2.1502  Validation loss = 2.1839  \n",
      "\n",
      "Fold: 28  Epoch: 17  Training loss = 1.6894  Validation loss = 1.0101  \n",
      "\n",
      "Fold: 28  Epoch: 18  Training loss = 1.7156  Validation loss = 1.2950  \n",
      "\n",
      "Fold: 28  Epoch: 19  Training loss = 3.5336  Validation loss = 2.9529  \n",
      "\n",
      "Check model:  Fold: 28  Optimal epoch: 3  \n",
      "\n",
      "Fold: 29  Epoch: 1  Training loss = 2.7760  Validation loss = 1.6155  \n",
      "\n",
      "Fold: 29  Epoch: 2  Training loss = 2.3615  Validation loss = 3.1740  \n",
      "\n",
      "Fold: 29  Epoch: 3  Training loss = 2.0734  Validation loss = 2.7987  \n",
      "\n",
      "Fold: 29  Epoch: 4  Training loss = 2.2754  Validation loss = 1.8267  \n",
      "\n",
      "Fold: 29  Epoch: 5  Training loss = 2.2501  Validation loss = 4.1230  \n",
      "\n",
      "Fold: 29  Epoch: 6  Training loss = 1.5480  Validation loss = 1.7842  \n",
      "\n",
      "Fold: 29  Epoch: 7  Training loss = 1.5859  Validation loss = 2.3088  \n",
      "\n",
      "Fold: 29  Epoch: 8  Training loss = 1.9039  Validation loss = 2.0085  \n",
      "\n",
      "Fold: 29  Epoch: 9  Training loss = 1.4852  Validation loss = 1.9802  \n",
      "\n",
      "Fold: 29  Epoch: 10  Training loss = 1.7051  Validation loss = 2.1030  \n",
      "\n",
      "Fold: 29  Epoch: 11  Training loss = 1.8726  Validation loss = 2.9559  \n",
      "\n",
      "Fold: 29  Epoch: 12  Training loss = 1.6183  Validation loss = 2.0215  \n",
      "\n",
      "Fold: 29  Epoch: 13  Training loss = 1.6106  Validation loss = 1.6640  \n",
      "\n",
      "Fold: 29  Epoch: 14  Training loss = 1.4692  Validation loss = 1.2721  \n",
      "\n",
      "Fold: 29  Epoch: 15  Training loss = 1.6616  Validation loss = 2.0796  \n",
      "\n",
      "Fold: 29  Epoch: 16  Training loss = 2.4105  Validation loss = 3.5360  \n",
      "\n",
      "Check model:  Fold: 29  Optimal epoch: 14  \n",
      "\n",
      "Fold: 30  Epoch: 1  Training loss = 1.6484  Validation loss = 1.6088  \n",
      "\n",
      "Fold: 30  Epoch: 2  Training loss = 1.7804  Validation loss = 0.9591  \n",
      "\n",
      "Fold: 30  Epoch: 3  Training loss = 1.6739  Validation loss = 1.7115  \n",
      "\n",
      "Fold: 30  Epoch: 4  Training loss = 1.5810  Validation loss = 1.2713  \n",
      "\n",
      "Fold: 30  Epoch: 5  Training loss = 2.5312  Validation loss = 1.4382  \n",
      "\n",
      "Fold: 30  Epoch: 6  Training loss = 1.6913  Validation loss = 1.5012  \n",
      "\n",
      "Fold: 30  Epoch: 7  Training loss = 2.2280  Validation loss = 1.9282  \n",
      "\n",
      "Fold: 30  Epoch: 8  Training loss = 1.6799  Validation loss = 1.7670  \n",
      "\n",
      "Fold: 30  Epoch: 9  Training loss = 1.4723  Validation loss = 1.3544  \n",
      "\n",
      "Fold: 30  Epoch: 10  Training loss = 3.3150  Validation loss = 0.9658  \n",
      "\n",
      "Fold: 30  Epoch: 11  Training loss = 2.3409  Validation loss = 2.1574  \n",
      "\n",
      "Check model:  Fold: 30  Optimal epoch: 2  \n",
      "\n",
      "Fold: 31  Epoch: 1  Training loss = 1.6623  Validation loss = 1.6233  \n",
      "\n",
      "Fold: 31  Epoch: 2  Training loss = 1.6420  Validation loss = 1.5939  \n",
      "\n",
      "Fold: 31  Epoch: 3  Training loss = 2.1363  Validation loss = 1.0458  \n",
      "\n",
      "Fold: 31  Epoch: 4  Training loss = 1.6029  Validation loss = 0.9873  \n",
      "\n",
      "Fold: 31  Epoch: 5  Training loss = 1.2974  Validation loss = 1.2709  \n",
      "\n",
      "Fold: 31  Epoch: 6  Training loss = 3.1406  Validation loss = 5.0092  \n",
      "\n",
      "Fold: 31  Epoch: 7  Training loss = 1.6415  Validation loss = 0.7895  \n",
      "\n",
      "Fold: 31  Epoch: 8  Training loss = 1.9840  Validation loss = 2.2829  \n",
      "\n",
      "Fold: 31  Epoch: 9  Training loss = 1.6723  Validation loss = 2.2225  \n",
      "\n",
      "Fold: 31  Epoch: 10  Training loss = 2.2149  Validation loss = 3.0168  \n",
      "\n",
      "Fold: 31  Epoch: 11  Training loss = 1.3441  Validation loss = 1.2634  \n",
      "\n",
      "Fold: 31  Epoch: 12  Training loss = 1.9505  Validation loss = 1.7459  \n",
      "\n",
      "Fold: 31  Epoch: 13  Training loss = 1.3822  Validation loss = 0.7224  \n",
      "\n",
      "Fold: 31  Epoch: 14  Training loss = 1.5115  Validation loss = 2.0452  \n",
      "\n",
      "Fold: 31  Epoch: 15  Training loss = 1.3739  Validation loss = 1.7243  \n",
      "\n",
      "Fold: 31  Epoch: 16  Training loss = 3.8627  Validation loss = 3.9940  \n",
      "\n",
      "Check model:  Fold: 31  Optimal epoch: 13  \n",
      "\n",
      "Fold: 32  Epoch: 1  Training loss = 3.2137  Validation loss = 6.2000  \n",
      "\n",
      "Fold: 32  Epoch: 2  Training loss = 1.4521  Validation loss = 3.8735  \n",
      "\n",
      "Fold: 32  Epoch: 3  Training loss = 2.7091  Validation loss = 6.8487  \n",
      "\n",
      "Fold: 32  Epoch: 4  Training loss = 1.6627  Validation loss = 5.2037  \n",
      "\n",
      "Fold: 32  Epoch: 5  Training loss = 1.3691  Validation loss = 4.7310  \n",
      "\n",
      "Fold: 32  Epoch: 6  Training loss = 1.4287  Validation loss = 4.9906  \n",
      "\n",
      "Fold: 32  Epoch: 7  Training loss = 1.8697  Validation loss = 4.2313  \n",
      "\n",
      "Fold: 32  Epoch: 8  Training loss = 1.8235  Validation loss = 5.7890  \n",
      "\n",
      "Fold: 32  Epoch: 9  Training loss = 1.3629  Validation loss = 4.4597  \n",
      "\n",
      "Fold: 32  Epoch: 10  Training loss = 2.3960  Validation loss = 6.5204  \n",
      "\n",
      "Fold: 32  Epoch: 11  Training loss = 1.9621  Validation loss = 3.4052  \n",
      "\n",
      "Fold: 32  Epoch: 12  Training loss = 2.2195  Validation loss = 5.9159  \n",
      "\n",
      "Fold: 32  Epoch: 13  Training loss = 2.0383  Validation loss = 3.8464  \n",
      "\n",
      "Fold: 32  Epoch: 14  Training loss = 1.4077  Validation loss = 4.4921  \n",
      "\n",
      "Fold: 32  Epoch: 15  Training loss = 1.4535  Validation loss = 5.0202  \n",
      "\n",
      "Fold: 32  Epoch: 16  Training loss = 1.8664  Validation loss = 6.0564  \n",
      "\n",
      "Fold: 32  Epoch: 17  Training loss = 1.6897  Validation loss = 6.0342  \n",
      "\n",
      "Fold: 32  Epoch: 18  Training loss = 2.6160  Validation loss = 6.7210  \n",
      "\n",
      "Check model:  Fold: 32  Optimal epoch: 11  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 2. Train model\n",
    "# ==================================\n",
    "sess = tf.InteractiveSession()  # Launch Graph\n",
    "sess.run(tf.global_variables_initializer())  # Initialise all variables\n",
    "\n",
    "print(\"Start training\", \n",
    "      \"\\nHyperparameters:\",\n",
    "      \"\\nDimension of recurrent unit =\", n_hidden,\n",
    "      \"\\nLearning rate =\", learning_rate,\n",
    "      \"\\nEpochs =\", epochs,\n",
    "      \"\\nBatch size =\", batch_size,\n",
    "      \"\\nEarly stopping epochs =\", early_stop_iters,\n",
    "      \"\\nLearning rate =\", learning_rate)\n",
    "\n",
    "total_batch = int(window_length / batch_size)\n",
    "validation_fold_error = [] # store validation error of each fold\n",
    "optimal_epochs = []\n",
    "\n",
    "# loop through folds\n",
    "for fold in range(1, len(valIndex)):\n",
    "    validx = train_features[valIndex[fold-1]:valIndex[fold]]\n",
    "    validy = train_target[valIndex[fold-1]:valIndex[fold]]\n",
    "    trainx = train_features[(fold-1)*4:valIndex[(fold-1)]]\n",
    "    trainy = train_target[(fold-1)*4:valIndex[(fold-1)]]\n",
    "\n",
    "    loss_list = [] # store validation loss after each epoch for early stopping\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i in range(total_batch):\n",
    "            # Backprop\n",
    "            batch_xs, batch_ys = next_batch(num=batch_size, data=trainx, labels=trainy)\n",
    "            optimizer.run(feed_dict={x:batch_xs, y:batch_ys, lr:learning_rate})\n",
    "\n",
    "        # Loss\n",
    "        loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "        loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "        loss_list.append(loss_valid)\n",
    "\n",
    "        print(\"Fold: {0:d}\".format(fold),\n",
    "              \" Epoch: {0:d}\".format(epoch+1),\n",
    "              \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "              \" Validation loss = {0:.4f}\".format(np.sqrt(loss_valid)),\n",
    "              \" \\n\")\n",
    "\n",
    "        if all(j <= loss_valid for j in loss_list[-early_stop_iters:]) and len(loss_list)>early_stop_iters:\n",
    "            break\n",
    "    \n",
    "    # Load model with lowest validation error for each fold\n",
    "    epoch_hat = np.argmin(loss_list) + 1\n",
    "    optimal_epochs.append(epoch_hat) # store optimal number of epochs for each fold\n",
    "    \n",
    "    # RMSE\n",
    "    loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "    loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "    validation_fold_error.append(np.sqrt(loss_valid))\n",
    "    \n",
    "    print(\"Check model:\",\n",
    "          \" Fold: {0:d}\".format(fold),\n",
    "          \" Optimal epoch: {0:d}\".format(epoch_hat),\n",
    "          \" \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average number of epochs: 8\n",
      "Average validation error: 4.41371\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 3. Optimal epoch choice\n",
    "# ==================================\n",
    "# Pick number of epochs to train model for out-of-sample testing\n",
    "epoch_hat = int(np.mean(optimal_epochs))\n",
    "print(\"\\nAverage number of epochs:\", epoch_hat)\n",
    "# Average validation error\n",
    "print(\"Average validation error:\", np.mean(validation_fold_error))\n",
    "\n",
    "# Save validated model\n",
    "saveModel(sess, \n",
    "          MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + str(epoch_hat) + \"_validated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fixed scheme:\n",
      "Epoch: 1  Training loss = 1.7627  Test loss = 3.4922  \n",
      "\n",
      "Epoch: 2  Training loss = 1.6522  Test loss = 3.8046  \n",
      "\n",
      "Epoch: 3  Training loss = 1.6013  Test loss = 3.6025  \n",
      "\n",
      "Epoch: 4  Training loss = 1.5630  Test loss = 3.6207  \n",
      "\n",
      "Epoch: 5  Training loss = 1.5296  Test loss = 3.5450  \n",
      "\n",
      "Epoch: 6  Training loss = 1.4990  Test loss = 3.5191  \n",
      "\n",
      "Epoch: 7  Training loss = 1.4704  Test loss = 3.4735  \n",
      "\n",
      "Epoch: 8  Training loss = 1.4437  Test loss = 3.4418  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 4. Fixed scheme\n",
    "# ==================================\n",
    "print(\"\\nFixed scheme:\")\n",
    "for epoch in range(epoch_hat):\n",
    "    x_train = train_features[-window_length:]\n",
    "    y_train = train_target[-window_length:]\n",
    "    optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:test_features, y:test_target})\n",
    "    print(\"Epoch: {0:d}\".format(epoch+1),\n",
    "          \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "          \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "          \" \\n\")\n",
    "\n",
    "# Forecasts\n",
    "yhat_test_fixed = pred.eval(feed_dict={x:test_features})\n",
    "yhat_train_fixed = pred.eval(feed_dict={x:x_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+S/vEZYpUmEMeAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc1ff940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train set\n",
    "plt.plot(y_train, 'black')\n",
    "plt.plot(yhat_train_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWUu5AMzMWuq/mslegVW7syYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd6a4e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: fixed scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_test_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed scheme RMSE: 3.44175255762 \n",
      "Fixed scheme MAE:  2.4629733347\n"
     ]
    }
   ],
   "source": [
    "rmse_fixed = np.sqrt(np.mean((yhat_test_fixed[:,0]-test_target)**2))\n",
    "mae_fixed = np.mean(np.abs((yhat_test_fixed[:,0]-test_target)))\n",
    "print(\"Fixed scheme RMSE:\", rmse_fixed,\n",
    "     \"\\nFixed scheme MAE: \", mae_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Stack training and test set, this makes updating scheme easier to train\n",
    "all_features = np.concatenate((train_features[-window_length:], test_features), axis=0)\n",
    "all_target = np.concatenate((train_target[-window_length:], test_target), axis=0)\n",
    "\n",
    "# Vectors to store loss and forecasts\n",
    "test_loss = np.zeros(len(test_target))\n",
    "yhat_update = np.zeros(len(test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test period = 1  Training loss = 1.4437  Test loss = 2.8179  Model updated 0 times  \n",
      "\n",
      "Test period = 2  Training loss = 1.4846  Test loss = 2.0105  Model updated 0 times  \n",
      "\n",
      "Test period = 3  Training loss = 1.4632  Test loss = 1.2094  Model updated 0 times  \n",
      "\n",
      "Test period = 4  Training loss = 1.4696  Test loss = 0.3308  Model updated 0 times  \n",
      "\n",
      "Test period = 5  Training loss = 1.0056  Test loss = 0.6619  Model updated 1 times  \n",
      "\n",
      "Test period = 6  Training loss = 1.0087  Test loss = 1.1582  Model updated 1 times  \n",
      "\n",
      "Test period = 7  Training loss = 1.0182  Test loss = 1.3593  Model updated 1 times  \n",
      "\n",
      "Test period = 8  Training loss = 1.0320  Test loss = 0.1331  Model updated 1 times  \n",
      "\n",
      "Test period = 9  Training loss = 0.9543  Test loss = 1.9123  Model updated 2 times  \n",
      "\n",
      "Test period = 10  Training loss = 0.9804  Test loss = 2.3344  Model updated 2 times  \n",
      "\n",
      "Test period = 11  Training loss = 1.0187  Test loss = 2.5627  Model updated 2 times  \n",
      "\n",
      "Test period = 12  Training loss = 1.0671  Test loss = 0.6383  Model updated 2 times  \n",
      "\n",
      "Test period = 13  Training loss = 0.9143  Test loss = 0.8594  Model updated 3 times  \n",
      "\n",
      "Test period = 14  Training loss = 0.9204  Test loss = 0.2819  Model updated 3 times  \n",
      "\n",
      "Test period = 15  Training loss = 0.9202  Test loss = 1.5046  Model updated 3 times  \n",
      "\n",
      "Test period = 16  Training loss = 0.9389  Test loss = 3.0143  Model updated 3 times  \n",
      "\n",
      "Test period = 17  Training loss = 0.9013  Test loss = 3.8279  Model updated 4 times  \n",
      "\n",
      "Test period = 18  Training loss = 1.0187  Test loss = 0.2784  Model updated 4 times  \n",
      "\n",
      "Test period = 19  Training loss = 1.0193  Test loss = 2.0171  Model updated 4 times  \n",
      "\n",
      "Test period = 20  Training loss = 1.0326  Test loss = 0.6410  Model updated 4 times  \n",
      "\n",
      "Test period = 21  Training loss = 0.8241  Test loss = 1.3040  Model updated 5 times  \n",
      "\n",
      "Test period = 22  Training loss = 0.8398  Test loss = 3.5683  Model updated 5 times  \n",
      "\n",
      "Test period = 23  Training loss = 0.9492  Test loss = 0.1680  Model updated 5 times  \n",
      "\n",
      "Test period = 24  Training loss = 0.9494  Test loss = 1.8159  Model updated 5 times  \n",
      "\n",
      "Test period = 25  Training loss = 0.9608  Test loss = 0.7653  Model updated 6 times  \n",
      "\n",
      "Test period = 26  Training loss = 0.9578  Test loss = 3.9208  Model updated 6 times  \n",
      "\n",
      "Test period = 27  Training loss = 1.0731  Test loss = 0.1838  Model updated 6 times  \n",
      "\n",
      "Test period = 28  Training loss = 1.0733  Test loss = 1.1874  Model updated 6 times  \n",
      "\n",
      "Test period = 29  Training loss = 0.8618  Test loss = 0.5792  Model updated 7 times  \n",
      "\n",
      "Test period = 30  Training loss = 0.8588  Test loss = 0.8982  Model updated 7 times  \n",
      "\n",
      "Test period = 31  Training loss = 0.8432  Test loss = 3.7941  Model updated 7 times  \n",
      "\n",
      "Test period = 32  Training loss = 0.9413  Test loss = 0.8582  Model updated 7 times  \n",
      "\n",
      "Test period = 33  Training loss = 0.8853  Test loss = 1.0604  Model updated 8 times  \n",
      "\n",
      "Test period = 34  Training loss = 0.8950  Test loss = 0.5008  Model updated 8 times  \n",
      "\n",
      "Test period = 35  Training loss = 0.8773  Test loss = 0.6719  Model updated 8 times  \n",
      "\n",
      "Test period = 36  Training loss = 0.8771  Test loss = 4.7604  Model updated 8 times  \n",
      "\n",
      "Test period = 37  Training loss = 1.0111  Test loss = 0.3859  Model updated 9 times  \n",
      "\n",
      "Test period = 38  Training loss = 0.9196  Test loss = 1.1076  Model updated 9 times  \n",
      "\n",
      "Test period = 39  Training loss = 0.9277  Test loss = 0.4228  Model updated 9 times  \n",
      "\n",
      "Test period = 40  Training loss = 0.9250  Test loss = 1.7858  Model updated 9 times  \n",
      "\n",
      "Test period = 41  Training loss = 0.8591  Test loss = 0.8025  Model updated 10 times  \n",
      "\n",
      "Test period = 42  Training loss = 0.8648  Test loss = 4.2739  Model updated 10 times  \n",
      "\n",
      "Test period = 43  Training loss = 1.0122  Test loss = 3.5108  Model updated 10 times  \n",
      "\n",
      "Test period = 44  Training loss = 1.1018  Test loss = 15.0516  Model updated 10 times  \n",
      "\n",
      "Test period = 45  Training loss = 2.1278  Test loss = 7.6746  Model updated 11 times  \n",
      "\n",
      "Test period = 46  Training loss = 2.3258  Test loss = 2.7402  Model updated 11 times  \n",
      "\n",
      "Test period = 47  Training loss = 2.3495  Test loss = 0.3173  Model updated 11 times  \n",
      "\n",
      "Test period = 48  Training loss = 2.3496  Test loss = 0.9068  Model updated 11 times  \n",
      "\n",
      "Test period = 49  Training loss = 1.1728  Test loss = 1.9370  Model updated 12 times  \n",
      "\n",
      "Test period = 50  Training loss = 1.1951  Test loss = 2.6524  Model updated 12 times  \n",
      "\n",
      "Test period = 51  Training loss = 1.2394  Test loss = 3.7444  Model updated 12 times  \n",
      "\n",
      "Test period = 52  Training loss = 1.3235  Test loss = 0.2007  Model updated 12 times  \n",
      "\n",
      "Test period = 53  Training loss = 1.1790  Test loss = 1.7587  Model updated 13 times  \n",
      "\n",
      "Test period = 54  Training loss = 1.1977  Test loss = 1.2259  Model updated 13 times  \n",
      "\n",
      "Test period = 55  Training loss = 1.2073  Test loss = 0.6569  Model updated 13 times  \n",
      "\n",
      "Test period = 56  Training loss = 1.2031  Test loss = 2.8958  Model updated 13 times  \n",
      "\n",
      "Test period = 57  Training loss = 1.1478  Test loss = 3.8667  Model updated 14 times  \n",
      "\n",
      "Test period = 58  Training loss = 1.2433  Test loss = 5.1827  Model updated 14 times  \n",
      "\n",
      "Test period = 59  Training loss = 1.3853  Test loss = 0.0791  Model updated 14 times  \n",
      "\n",
      "Test period = 60  Training loss = 1.3846  Test loss = 0.6052  Model updated 14 times  \n",
      "\n",
      "Test period = 61  Training loss = 1.0928  Test loss = 0.8377  Model updated 15 times  \n",
      "\n",
      "Test period = 62  Training loss = 1.0729  Test loss = 1.4668  Model updated 15 times  \n",
      "\n",
      "Test period = 63  Training loss = 1.0882  Test loss = 0.3423  Model updated 15 times  \n",
      "\n",
      "Test period = 64  Training loss = 1.0886  Test loss = 1.0261  Model updated 15 times  \n",
      "\n",
      "Test period = 65  Training loss = 1.1525  Test loss = 4.4323  Model updated 16 times  \n",
      "\n",
      "Test period = 66  Training loss = 1.2764  Test loss = 1.3958  Model updated 16 times  \n",
      "\n",
      "Test period = 67  Training loss = 1.2874  Test loss = 0.9579  Model updated 16 times  \n",
      "\n",
      "Test period = 68  Training loss = 1.2724  Test loss = 4.4347  Model updated 16 times  \n",
      "\n",
      "Test period = 69  Training loss = 1.1791  Test loss = 6.3218  Model updated 17 times  \n",
      "\n",
      "Test period = 70  Training loss = 1.4156  Test loss = 0.0608  Model updated 17 times  \n",
      "\n",
      "Test period = 71  Training loss = 1.4154  Test loss = 1.9549  Model updated 17 times  \n",
      "\n",
      "Test period = 72  Training loss = 1.4359  Test loss = 2.9697  Model updated 17 times  \n",
      "\n",
      "Test period = 73  Training loss = 1.2473  Test loss = 0.1357  Model updated 18 times  \n",
      "\n",
      "Test period = 74  Training loss = 1.2469  Test loss = 2.5937  Model updated 18 times  \n",
      "\n",
      "Test period = 75  Training loss = 1.2869  Test loss = 0.2550  Model updated 18 times  \n",
      "\n",
      "Test period = 76  Training loss = 1.2868  Test loss = 1.4084  Model updated 18 times  \n",
      "\n",
      "Test period = 77  Training loss = 1.1734  Test loss = 0.0020  Model updated 19 times  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "retrain_count = 0\n",
    "for t in range(len(test_target)):\n",
    "    x_test = np.reshape(test_features[t], newshape=(1,4,3))\n",
    "    y_test = test_target[t]\n",
    "    test_loss[t] = np.sqrt(sess.run(loss, feed_dict={x:x_test, y:y_test}))\n",
    "    yhat_update[t] = pred.eval(feed_dict={x:x_test})\n",
    "\n",
    "    x_train = all_features[t:(window_length+t)]\n",
    "    y_train = all_target[t:(window_length+t)]\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:x_test, y:y_test})\n",
    "    \n",
    "    print(\"Test period = {0:d}\".format(t+1),\n",
    "      \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "      \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "      \" Model updated {0:d} times\".format(retrain_count),\n",
    "      \" \\n\")\n",
    "\n",
    "    if (t+1)%4==0:\n",
    "        retrain_count += 1\n",
    "        for epoch in range(epoch_hat):\n",
    "            for i in range(total_batch):\n",
    "                optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd619b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: updating scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_update, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating scheme RMSE: 2.9243570534 \n",
      "Updating scheme MAE:  1.94767850536\n"
     ]
    }
   ],
   "source": [
    "rmse_update = np.sqrt(np.mean((yhat_update-test_target)**2))\n",
    "mae_update = np.mean(np.abs((yhat_update-test_target)))\n",
    "print(\"Updating scheme RMSE:\", rmse_update,\n",
    "     \"\\nUpdating scheme MAE: \", mae_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + \"yhat_test_fixed.csv\", yhat_test_fixed)\n",
    "np.savetxt(MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + \"yhat_update.csv\", yhat_update)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
