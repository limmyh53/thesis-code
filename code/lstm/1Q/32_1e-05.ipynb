{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Directories\n",
    "MODEL_FOLDER = \"../../../models/lstm/\"\n",
    "MODEL_FILENAME = MODEL_FOLDER + \"1Q/32_units/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: model saver\n",
    "def saveModel(sess, MODEL_FILENAME):\n",
    "    if not os.path.exists(MODEL_FOLDER):\n",
    "        print('Creating path where to save model: ' + MODEL_FOLDER)\n",
    "        os.mkdir(MODEL_FOLDER)\n",
    "\n",
    "    #print('Saving model at: ' + MODEL_FILENAME)\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, MODEL_FILENAME)\n",
    "    #print('Model successfully saved.\\n')\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: model loader\n",
    "def loadModel(sess, MODEL_FILENAME):\n",
    "    if os.path.exists(MODEL_FILENAME + \".index\"):\n",
    "        print('Loading save model from: ' + MODEL_FILENAME)\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, MODEL_FILENAME)\n",
    "        print('Model successfully loaded.\\n')\n",
    "        return True\n",
    "    else:\n",
    "        print('Model file <<' + MODEL_FILENAME + '>> does not exists!')\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Hyperparameters\n",
    "epochs = 500\n",
    "learning_rate = 1e-5\n",
    "batch_size = 5\n",
    "early_stop_iters = 10\n",
    "folds = 32\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 3  # data input\n",
    "n_steps = 4  # timesteps\n",
    "n_hidden = 32 # dimension of recurrent unit\n",
    "\n",
    "# (REPRODUCIBILITY) set random seeds\n",
    "tf.set_random_seed(123)\n",
    "\n",
    "# Define weights and biases\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.truncated_normal([n_hidden, 1], stddev = 1.0 / tf.sqrt(float(n_hidden))),\n",
    "        name='out_weight')\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.zeros([1]),\n",
    "        name='out_bias')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: Build model\n",
    "def RNN(X, weights, biases, n_hidden):\n",
    "\n",
    "    # Define a LSTM cell with tensorflow\n",
    "    lstm_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden, state_is_tuple=True)\n",
    "    outputs, _ = tf.nn.dynamic_rnn(lstm_cell, X, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    out_layer = tf.matmul(outputs[:,-1,:], weights['out']) + biases['out']\n",
    "\n",
    "    return out_layer\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: select batch\n",
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the data...\n",
      "Finished: data loaded. Stats below: \n",
      "Nr of training samples: 193\n",
      "Nr of testing  samples: 77\n",
      "Number of variables: 3\n",
      "Number of lags: 4\n",
      "Window length: 65\n",
      "Number of validation folds: 32\n"
     ]
    }
   ],
   "source": [
    "# =================================\n",
    "# 0. Load dataset\n",
    "# =================================\n",
    "print(\"Loading the data...\")\n",
    "# Training set pre-processing\n",
    "train = pd.read_csv('../../../Data/train.csv')\n",
    "train_4lag_inflation = np.array(train[['inflation.lag1',\n",
    "                                       'inflation.lag2',\n",
    "                                       'inflation.lag3',\n",
    "                                       'inflation.lag4']])\n",
    "train_4lag_unemp = np.array(train[['unemp.lag1',\n",
    "                                   'unemp.lag2',\n",
    "                                   'unemp.lag3',\n",
    "                                   'unemp.lag4']])\n",
    "train_4lag_oil = np.array(train[['oil.lag1',\n",
    "                                 'oil.lag2',\n",
    "                                 'oil.lag3',\n",
    "                                 'oil.lag4']])\n",
    "train_features = np.concatenate((train_4lag_inflation[:,:,np.newaxis], \n",
    "\t                             train_4lag_unemp[:,:,np.newaxis],\n",
    "\t                             train_4lag_oil[:,:,np.newaxis]),\n",
    "\t                             axis=2)\n",
    "train_target = np.array(train['inflation.target'])\n",
    "\n",
    "# Test set pre-processing\n",
    "test = pd.read_csv('../../../Data/test.csv')\n",
    "test_4lag_inflation = np.array(test[['inflation.lag1',\n",
    "                                     'inflation.lag2',\n",
    "                                     'inflation.lag3',\n",
    "                                     'inflation.lag4']])\n",
    "test_4lag_unemp = np.array(test[['unemp.lag1',\n",
    "                                 'unemp.lag2',\n",
    "                                 'unemp.lag3',\n",
    "                                 'unemp.lag4']])\n",
    "test_4lag_oil = np.array(test[['oil.lag1',\n",
    "                               'oil.lag2',\n",
    "                               'oil.lag3',\n",
    "                               'oil.lag4']])\n",
    "test_features = np.concatenate((test_4lag_inflation[:,:,np.newaxis], \n",
    "\t                            test_4lag_unemp[:,:,np.newaxis],\n",
    "\t                            test_4lag_oil[:,:,np.newaxis]),\n",
    "\t                            axis=2)\n",
    "test_target = np.array(test['inflation.target'])\n",
    "\n",
    "(nrTrainSamples, timesteps, variables) = train_features.shape\n",
    "(nrTestSamples, _, _) = test_features.shape\n",
    "\n",
    "# Window length and validation fold index\n",
    "window_length = 65\n",
    "valIndex = np.linspace(start=window_length, stop=nrTrainSamples, \n",
    "                       endpoint=True, num=folds+1, dtype=np.int)\n",
    "\n",
    "print(\"Finished: data loaded. Stats below: \")\n",
    "print(\"Nr of training samples: %d\" % nrTrainSamples)\n",
    "print(\"Nr of testing  samples: %d\" % nrTestSamples)\n",
    "print(\"Number of variables: %d\" % variables)\n",
    "print(\"Number of lags: %d\" % timesteps)\n",
    "print(\"Window length: %d\" % window_length)\n",
    "print(\"Number of validation folds: %d\" % folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 1. Build model\n",
    "# ==================================\n",
    "# tf graph input\n",
    "x = tf.placeholder(\"float\", [None, n_steps, n_input], name='Batch')\n",
    "y = tf.placeholder(\"float\", name='True_labels_of_batch')\n",
    "lr = tf.placeholder(\"float\", name='Learning_rate')\n",
    "\n",
    "# Make predictions with the model\n",
    "pred = RNN(x, weights, biases, n_hidden)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss = tf.reduce_mean(tf.diag_part(tf.square(tf.subtract(x=pred, y=y))))\n",
    "optimizer = tf.train.GradientDescentOptimizer(lr).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training \n",
      "Hyperparameters: \n",
      "Dimension of recurrent unit = 32 \n",
      "Learning rate = 1e-05 \n",
      "Epochs = 500 \n",
      "Batch size = 5 \n",
      "Early stopping epochs = 10 \n",
      "Learning rate = 1e-05\n",
      "Fold: 1  Epoch: 1  Training loss = 3.5458  Validation loss = 3.9816  \n",
      "\n",
      "Fold: 1  Epoch: 2  Training loss = 3.5430  Validation loss = 3.9769  \n",
      "\n",
      "Fold: 1  Epoch: 3  Training loss = 3.5413  Validation loss = 3.9740  \n",
      "\n",
      "Fold: 1  Epoch: 4  Training loss = 3.5381  Validation loss = 3.9687  \n",
      "\n",
      "Fold: 1  Epoch: 5  Training loss = 3.5353  Validation loss = 3.9641  \n",
      "\n",
      "Fold: 1  Epoch: 6  Training loss = 3.5322  Validation loss = 3.9589  \n",
      "\n",
      "Fold: 1  Epoch: 7  Training loss = 3.5294  Validation loss = 3.9542  \n",
      "\n",
      "Fold: 1  Epoch: 8  Training loss = 3.5269  Validation loss = 3.9500  \n",
      "\n",
      "Fold: 1  Epoch: 9  Training loss = 3.5245  Validation loss = 3.9459  \n",
      "\n",
      "Fold: 1  Epoch: 10  Training loss = 3.5222  Validation loss = 3.9420  \n",
      "\n",
      "Fold: 1  Epoch: 11  Training loss = 3.5197  Validation loss = 3.9377  \n",
      "\n",
      "Fold: 1  Epoch: 12  Training loss = 3.5177  Validation loss = 3.9343  \n",
      "\n",
      "Fold: 1  Epoch: 13  Training loss = 3.5150  Validation loss = 3.9296  \n",
      "\n",
      "Fold: 1  Epoch: 14  Training loss = 3.5128  Validation loss = 3.9259  \n",
      "\n",
      "Fold: 1  Epoch: 15  Training loss = 3.5100  Validation loss = 3.9210  \n",
      "\n",
      "Fold: 1  Epoch: 16  Training loss = 3.5081  Validation loss = 3.9179  \n",
      "\n",
      "Fold: 1  Epoch: 17  Training loss = 3.5054  Validation loss = 3.9133  \n",
      "\n",
      "Fold: 1  Epoch: 18  Training loss = 3.5030  Validation loss = 3.9091  \n",
      "\n",
      "Fold: 1  Epoch: 19  Training loss = 3.5007  Validation loss = 3.9051  \n",
      "\n",
      "Fold: 1  Epoch: 20  Training loss = 3.4982  Validation loss = 3.9008  \n",
      "\n",
      "Fold: 1  Epoch: 21  Training loss = 3.4952  Validation loss = 3.8955  \n",
      "\n",
      "Fold: 1  Epoch: 22  Training loss = 3.4937  Validation loss = 3.8929  \n",
      "\n",
      "Fold: 1  Epoch: 23  Training loss = 3.4915  Validation loss = 3.8892  \n",
      "\n",
      "Fold: 1  Epoch: 24  Training loss = 3.4898  Validation loss = 3.8862  \n",
      "\n",
      "Fold: 1  Epoch: 25  Training loss = 3.4874  Validation loss = 3.8821  \n",
      "\n",
      "Fold: 1  Epoch: 26  Training loss = 3.4851  Validation loss = 3.8781  \n",
      "\n",
      "Fold: 1  Epoch: 27  Training loss = 3.4824  Validation loss = 3.8735  \n",
      "\n",
      "Fold: 1  Epoch: 28  Training loss = 3.4803  Validation loss = 3.8698  \n",
      "\n",
      "Fold: 1  Epoch: 29  Training loss = 3.4782  Validation loss = 3.8662  \n",
      "\n",
      "Fold: 1  Epoch: 30  Training loss = 3.4758  Validation loss = 3.8619  \n",
      "\n",
      "Fold: 1  Epoch: 31  Training loss = 3.4729  Validation loss = 3.8569  \n",
      "\n",
      "Fold: 1  Epoch: 32  Training loss = 3.4702  Validation loss = 3.8521  \n",
      "\n",
      "Fold: 1  Epoch: 33  Training loss = 3.4682  Validation loss = 3.8487  \n",
      "\n",
      "Fold: 1  Epoch: 34  Training loss = 3.4657  Validation loss = 3.8443  \n",
      "\n",
      "Fold: 1  Epoch: 35  Training loss = 3.4636  Validation loss = 3.8406  \n",
      "\n",
      "Fold: 1  Epoch: 36  Training loss = 3.4608  Validation loss = 3.8356  \n",
      "\n",
      "Fold: 1  Epoch: 37  Training loss = 3.4589  Validation loss = 3.8320  \n",
      "\n",
      "Fold: 1  Epoch: 38  Training loss = 3.4568  Validation loss = 3.8283  \n",
      "\n",
      "Fold: 1  Epoch: 39  Training loss = 3.4547  Validation loss = 3.8246  \n",
      "\n",
      "Fold: 1  Epoch: 40  Training loss = 3.4527  Validation loss = 3.8213  \n",
      "\n",
      "Fold: 1  Epoch: 41  Training loss = 3.4502  Validation loss = 3.8168  \n",
      "\n",
      "Fold: 1  Epoch: 42  Training loss = 3.4484  Validation loss = 3.8134  \n",
      "\n",
      "Fold: 1  Epoch: 43  Training loss = 3.4457  Validation loss = 3.8085  \n",
      "\n",
      "Fold: 1  Epoch: 44  Training loss = 3.4433  Validation loss = 3.8039  \n",
      "\n",
      "Fold: 1  Epoch: 45  Training loss = 3.4409  Validation loss = 3.7998  \n",
      "\n",
      "Fold: 1  Epoch: 46  Training loss = 3.4386  Validation loss = 3.7956  \n",
      "\n",
      "Fold: 1  Epoch: 47  Training loss = 3.4366  Validation loss = 3.7918  \n",
      "\n",
      "Fold: 1  Epoch: 48  Training loss = 3.4341  Validation loss = 3.7873  \n",
      "\n",
      "Fold: 1  Epoch: 49  Training loss = 3.4318  Validation loss = 3.7832  \n",
      "\n",
      "Fold: 1  Epoch: 50  Training loss = 3.4298  Validation loss = 3.7797  \n",
      "\n",
      "Fold: 1  Epoch: 51  Training loss = 3.4273  Validation loss = 3.7752  \n",
      "\n",
      "Fold: 1  Epoch: 52  Training loss = 3.4253  Validation loss = 3.7715  \n",
      "\n",
      "Fold: 1  Epoch: 53  Training loss = 3.4232  Validation loss = 3.7678  \n",
      "\n",
      "Fold: 1  Epoch: 54  Training loss = 3.4210  Validation loss = 3.7637  \n",
      "\n",
      "Fold: 1  Epoch: 55  Training loss = 3.4184  Validation loss = 3.7589  \n",
      "\n",
      "Fold: 1  Epoch: 56  Training loss = 3.4158  Validation loss = 3.7541  \n",
      "\n",
      "Fold: 1  Epoch: 57  Training loss = 3.4132  Validation loss = 3.7494  \n",
      "\n",
      "Fold: 1  Epoch: 58  Training loss = 3.4110  Validation loss = 3.7453  \n",
      "\n",
      "Fold: 1  Epoch: 59  Training loss = 3.4082  Validation loss = 3.7400  \n",
      "\n",
      "Fold: 1  Epoch: 60  Training loss = 3.4061  Validation loss = 3.7363  \n",
      "\n",
      "Fold: 1  Epoch: 61  Training loss = 3.4036  Validation loss = 3.7316  \n",
      "\n",
      "Fold: 1  Epoch: 62  Training loss = 3.4017  Validation loss = 3.7282  \n",
      "\n",
      "Fold: 1  Epoch: 63  Training loss = 3.3998  Validation loss = 3.7247  \n",
      "\n",
      "Fold: 1  Epoch: 64  Training loss = 3.3969  Validation loss = 3.7193  \n",
      "\n",
      "Fold: 1  Epoch: 65  Training loss = 3.3945  Validation loss = 3.7149  \n",
      "\n",
      "Fold: 1  Epoch: 66  Training loss = 3.3926  Validation loss = 3.7114  \n",
      "\n",
      "Fold: 1  Epoch: 67  Training loss = 3.3906  Validation loss = 3.7078  \n",
      "\n",
      "Fold: 1  Epoch: 68  Training loss = 3.3886  Validation loss = 3.7041  \n",
      "\n",
      "Fold: 1  Epoch: 69  Training loss = 3.3869  Validation loss = 3.7008  \n",
      "\n",
      "Fold: 1  Epoch: 70  Training loss = 3.3844  Validation loss = 3.6962  \n",
      "\n",
      "Fold: 1  Epoch: 71  Training loss = 3.3824  Validation loss = 3.6925  \n",
      "\n",
      "Fold: 1  Epoch: 72  Training loss = 3.3804  Validation loss = 3.6889  \n",
      "\n",
      "Fold: 1  Epoch: 73  Training loss = 3.3785  Validation loss = 3.6854  \n",
      "\n",
      "Fold: 1  Epoch: 74  Training loss = 3.3763  Validation loss = 3.6813  \n",
      "\n",
      "Fold: 1  Epoch: 75  Training loss = 3.3745  Validation loss = 3.6779  \n",
      "\n",
      "Fold: 1  Epoch: 76  Training loss = 3.3729  Validation loss = 3.6748  \n",
      "\n",
      "Fold: 1  Epoch: 77  Training loss = 3.3703  Validation loss = 3.6700  \n",
      "\n",
      "Fold: 1  Epoch: 78  Training loss = 3.3678  Validation loss = 3.6653  \n",
      "\n",
      "Fold: 1  Epoch: 79  Training loss = 3.3654  Validation loss = 3.6609  \n",
      "\n",
      "Fold: 1  Epoch: 80  Training loss = 3.3637  Validation loss = 3.6577  \n",
      "\n",
      "Fold: 1  Epoch: 81  Training loss = 3.3618  Validation loss = 3.6541  \n",
      "\n",
      "Fold: 1  Epoch: 82  Training loss = 3.3599  Validation loss = 3.6506  \n",
      "\n",
      "Fold: 1  Epoch: 83  Training loss = 3.3579  Validation loss = 3.6468  \n",
      "\n",
      "Fold: 1  Epoch: 84  Training loss = 3.3557  Validation loss = 3.6427  \n",
      "\n",
      "Fold: 1  Epoch: 85  Training loss = 3.3533  Validation loss = 3.6381  \n",
      "\n",
      "Fold: 1  Epoch: 86  Training loss = 3.3514  Validation loss = 3.6345  \n",
      "\n",
      "Fold: 1  Epoch: 87  Training loss = 3.3493  Validation loss = 3.6307  \n",
      "\n",
      "Fold: 1  Epoch: 88  Training loss = 3.3480  Validation loss = 3.6283  \n",
      "\n",
      "Fold: 1  Epoch: 89  Training loss = 3.3460  Validation loss = 3.6246  \n",
      "\n",
      "Fold: 1  Epoch: 90  Training loss = 3.3440  Validation loss = 3.6209  \n",
      "\n",
      "Fold: 1  Epoch: 91  Training loss = 3.3418  Validation loss = 3.6168  \n",
      "\n",
      "Fold: 1  Epoch: 92  Training loss = 3.3398  Validation loss = 3.6129  \n",
      "\n",
      "Fold: 1  Epoch: 93  Training loss = 3.3384  Validation loss = 3.6103  \n",
      "\n",
      "Fold: 1  Epoch: 94  Training loss = 3.3367  Validation loss = 3.6071  \n",
      "\n",
      "Fold: 1  Epoch: 95  Training loss = 3.3344  Validation loss = 3.6028  \n",
      "\n",
      "Fold: 1  Epoch: 96  Training loss = 3.3323  Validation loss = 3.5988  \n",
      "\n",
      "Fold: 1  Epoch: 97  Training loss = 3.3300  Validation loss = 3.5945  \n",
      "\n",
      "Fold: 1  Epoch: 98  Training loss = 3.3278  Validation loss = 3.5903  \n",
      "\n",
      "Fold: 1  Epoch: 99  Training loss = 3.3260  Validation loss = 3.5870  \n",
      "\n",
      "Fold: 1  Epoch: 100  Training loss = 3.3239  Validation loss = 3.5830  \n",
      "\n",
      "Fold: 1  Epoch: 101  Training loss = 3.3219  Validation loss = 3.5793  \n",
      "\n",
      "Fold: 1  Epoch: 102  Training loss = 3.3198  Validation loss = 3.5752  \n",
      "\n",
      "Fold: 1  Epoch: 103  Training loss = 3.3178  Validation loss = 3.5715  \n",
      "\n",
      "Fold: 1  Epoch: 104  Training loss = 3.3153  Validation loss = 3.5668  \n",
      "\n",
      "Fold: 1  Epoch: 105  Training loss = 3.3128  Validation loss = 3.5621  \n",
      "\n",
      "Fold: 1  Epoch: 106  Training loss = 3.3111  Validation loss = 3.5588  \n",
      "\n",
      "Fold: 1  Epoch: 107  Training loss = 3.3084  Validation loss = 3.5537  \n",
      "\n",
      "Fold: 1  Epoch: 108  Training loss = 3.3064  Validation loss = 3.5498  \n",
      "\n",
      "Fold: 1  Epoch: 109  Training loss = 3.3043  Validation loss = 3.5459  \n",
      "\n",
      "Fold: 1  Epoch: 110  Training loss = 3.3026  Validation loss = 3.5427  \n",
      "\n",
      "Fold: 1  Epoch: 111  Training loss = 3.3009  Validation loss = 3.5396  \n",
      "\n",
      "Fold: 1  Epoch: 112  Training loss = 3.2986  Validation loss = 3.5351  \n",
      "\n",
      "Fold: 1  Epoch: 113  Training loss = 3.2955  Validation loss = 3.5292  \n",
      "\n",
      "Fold: 1  Epoch: 114  Training loss = 3.2931  Validation loss = 3.5247  \n",
      "\n",
      "Fold: 1  Epoch: 115  Training loss = 3.2915  Validation loss = 3.5216  \n",
      "\n",
      "Fold: 1  Epoch: 116  Training loss = 3.2899  Validation loss = 3.5187  \n",
      "\n",
      "Fold: 1  Epoch: 117  Training loss = 3.2874  Validation loss = 3.5140  \n",
      "\n",
      "Fold: 1  Epoch: 118  Training loss = 3.2852  Validation loss = 3.5098  \n",
      "\n",
      "Fold: 1  Epoch: 119  Training loss = 3.2835  Validation loss = 3.5065  \n",
      "\n",
      "Fold: 1  Epoch: 120  Training loss = 3.2817  Validation loss = 3.5031  \n",
      "\n",
      "Fold: 1  Epoch: 121  Training loss = 3.2791  Validation loss = 3.4983  \n",
      "\n",
      "Fold: 1  Epoch: 122  Training loss = 3.2775  Validation loss = 3.4951  \n",
      "\n",
      "Fold: 1  Epoch: 123  Training loss = 3.2754  Validation loss = 3.4912  \n",
      "\n",
      "Fold: 1  Epoch: 124  Training loss = 3.2734  Validation loss = 3.4875  \n",
      "\n",
      "Fold: 1  Epoch: 125  Training loss = 3.2714  Validation loss = 3.4836  \n",
      "\n",
      "Fold: 1  Epoch: 126  Training loss = 3.2694  Validation loss = 3.4800  \n",
      "\n",
      "Fold: 1  Epoch: 127  Training loss = 3.2674  Validation loss = 3.4760  \n",
      "\n",
      "Fold: 1  Epoch: 128  Training loss = 3.2649  Validation loss = 3.4713  \n",
      "\n",
      "Fold: 1  Epoch: 129  Training loss = 3.2634  Validation loss = 3.4685  \n",
      "\n",
      "Fold: 1  Epoch: 130  Training loss = 3.2613  Validation loss = 3.4647  \n",
      "\n",
      "Fold: 1  Epoch: 131  Training loss = 3.2599  Validation loss = 3.4620  \n",
      "\n",
      "Fold: 1  Epoch: 132  Training loss = 3.2578  Validation loss = 3.4581  \n",
      "\n",
      "Fold: 1  Epoch: 133  Training loss = 3.2554  Validation loss = 3.4536  \n",
      "\n",
      "Fold: 1  Epoch: 134  Training loss = 3.2538  Validation loss = 3.4507  \n",
      "\n",
      "Fold: 1  Epoch: 135  Training loss = 3.2518  Validation loss = 3.4470  \n",
      "\n",
      "Fold: 1  Epoch: 136  Training loss = 3.2500  Validation loss = 3.4437  \n",
      "\n",
      "Fold: 1  Epoch: 137  Training loss = 3.2486  Validation loss = 3.4410  \n",
      "\n",
      "Fold: 1  Epoch: 138  Training loss = 3.2469  Validation loss = 3.4379  \n",
      "\n",
      "Fold: 1  Epoch: 139  Training loss = 3.2443  Validation loss = 3.4330  \n",
      "\n",
      "Fold: 1  Epoch: 140  Training loss = 3.2421  Validation loss = 3.4287  \n",
      "\n",
      "Fold: 1  Epoch: 141  Training loss = 3.2395  Validation loss = 3.4239  \n",
      "\n",
      "Fold: 1  Epoch: 142  Training loss = 3.2377  Validation loss = 3.4205  \n",
      "\n",
      "Fold: 1  Epoch: 143  Training loss = 3.2356  Validation loss = 3.4166  \n",
      "\n",
      "Fold: 1  Epoch: 144  Training loss = 3.2333  Validation loss = 3.4123  \n",
      "\n",
      "Fold: 1  Epoch: 145  Training loss = 3.2316  Validation loss = 3.4090  \n",
      "\n",
      "Fold: 1  Epoch: 146  Training loss = 3.2299  Validation loss = 3.4059  \n",
      "\n",
      "Fold: 1  Epoch: 147  Training loss = 3.2273  Validation loss = 3.4011  \n",
      "\n",
      "Fold: 1  Epoch: 148  Training loss = 3.2259  Validation loss = 3.3984  \n",
      "\n",
      "Fold: 1  Epoch: 149  Training loss = 3.2243  Validation loss = 3.3953  \n",
      "\n",
      "Fold: 1  Epoch: 150  Training loss = 3.2222  Validation loss = 3.3915  \n",
      "\n",
      "Fold: 1  Epoch: 151  Training loss = 3.2205  Validation loss = 3.3882  \n",
      "\n",
      "Fold: 1  Epoch: 152  Training loss = 3.2186  Validation loss = 3.3847  \n",
      "\n",
      "Fold: 1  Epoch: 153  Training loss = 3.2170  Validation loss = 3.3818  \n",
      "\n",
      "Fold: 1  Epoch: 154  Training loss = 3.2149  Validation loss = 3.3777  \n",
      "\n",
      "Fold: 1  Epoch: 155  Training loss = 3.2128  Validation loss = 3.3738  \n",
      "\n",
      "Fold: 1  Epoch: 156  Training loss = 3.2111  Validation loss = 3.3707  \n",
      "\n",
      "Fold: 1  Epoch: 157  Training loss = 3.2090  Validation loss = 3.3667  \n",
      "\n",
      "Fold: 1  Epoch: 158  Training loss = 3.2071  Validation loss = 3.3630  \n",
      "\n",
      "Fold: 1  Epoch: 159  Training loss = 3.2055  Validation loss = 3.3599  \n",
      "\n",
      "Fold: 1  Epoch: 160  Training loss = 3.2027  Validation loss = 3.3549  \n",
      "\n",
      "Fold: 1  Epoch: 161  Training loss = 3.2010  Validation loss = 3.3516  \n",
      "\n",
      "Fold: 1  Epoch: 162  Training loss = 3.1987  Validation loss = 3.3473  \n",
      "\n",
      "Fold: 1  Epoch: 163  Training loss = 3.1968  Validation loss = 3.3436  \n",
      "\n",
      "Fold: 1  Epoch: 164  Training loss = 3.1946  Validation loss = 3.3394  \n",
      "\n",
      "Fold: 1  Epoch: 165  Training loss = 3.1929  Validation loss = 3.3363  \n",
      "\n",
      "Fold: 1  Epoch: 166  Training loss = 3.1912  Validation loss = 3.3333  \n",
      "\n",
      "Fold: 1  Epoch: 167  Training loss = 3.1896  Validation loss = 3.3303  \n",
      "\n",
      "Fold: 1  Epoch: 168  Training loss = 3.1872  Validation loss = 3.3257  \n",
      "\n",
      "Fold: 1  Epoch: 169  Training loss = 3.1853  Validation loss = 3.3222  \n",
      "\n",
      "Fold: 1  Epoch: 170  Training loss = 3.1839  Validation loss = 3.3196  \n",
      "\n",
      "Fold: 1  Epoch: 171  Training loss = 3.1826  Validation loss = 3.3173  \n",
      "\n",
      "Fold: 1  Epoch: 172  Training loss = 3.1808  Validation loss = 3.3138  \n",
      "\n",
      "Fold: 1  Epoch: 173  Training loss = 3.1789  Validation loss = 3.3101  \n",
      "\n",
      "Fold: 1  Epoch: 174  Training loss = 3.1770  Validation loss = 3.3067  \n",
      "\n",
      "Fold: 1  Epoch: 175  Training loss = 3.1754  Validation loss = 3.3036  \n",
      "\n",
      "Fold: 1  Epoch: 176  Training loss = 3.1741  Validation loss = 3.3014  \n",
      "\n",
      "Fold: 1  Epoch: 177  Training loss = 3.1721  Validation loss = 3.2976  \n",
      "\n",
      "Fold: 1  Epoch: 178  Training loss = 3.1703  Validation loss = 3.2943  \n",
      "\n",
      "Fold: 1  Epoch: 179  Training loss = 3.1684  Validation loss = 3.2906  \n",
      "\n",
      "Fold: 1  Epoch: 180  Training loss = 3.1671  Validation loss = 3.2881  \n",
      "\n",
      "Fold: 1  Epoch: 181  Training loss = 3.1656  Validation loss = 3.2853  \n",
      "\n",
      "Fold: 1  Epoch: 182  Training loss = 3.1637  Validation loss = 3.2817  \n",
      "\n",
      "Fold: 1  Epoch: 183  Training loss = 3.1619  Validation loss = 3.2784  \n",
      "\n",
      "Fold: 1  Epoch: 184  Training loss = 3.1604  Validation loss = 3.2755  \n",
      "\n",
      "Fold: 1  Epoch: 185  Training loss = 3.1586  Validation loss = 3.2723  \n",
      "\n",
      "Fold: 1  Epoch: 186  Training loss = 3.1564  Validation loss = 3.2681  \n",
      "\n",
      "Fold: 1  Epoch: 187  Training loss = 3.1549  Validation loss = 3.2654  \n",
      "\n",
      "Fold: 1  Epoch: 188  Training loss = 3.1535  Validation loss = 3.2628  \n",
      "\n",
      "Fold: 1  Epoch: 189  Training loss = 3.1522  Validation loss = 3.2602  \n",
      "\n",
      "Fold: 1  Epoch: 190  Training loss = 3.1510  Validation loss = 3.2579  \n",
      "\n",
      "Fold: 1  Epoch: 191  Training loss = 3.1495  Validation loss = 3.2551  \n",
      "\n",
      "Fold: 1  Epoch: 192  Training loss = 3.1481  Validation loss = 3.2523  \n",
      "\n",
      "Fold: 1  Epoch: 193  Training loss = 3.1469  Validation loss = 3.2501  \n",
      "\n",
      "Fold: 1  Epoch: 194  Training loss = 3.1454  Validation loss = 3.2473  \n",
      "\n",
      "Fold: 1  Epoch: 195  Training loss = 3.1442  Validation loss = 3.2450  \n",
      "\n",
      "Fold: 1  Epoch: 196  Training loss = 3.1424  Validation loss = 3.2415  \n",
      "\n",
      "Fold: 1  Epoch: 197  Training loss = 3.1408  Validation loss = 3.2384  \n",
      "\n",
      "Fold: 1  Epoch: 198  Training loss = 3.1392  Validation loss = 3.2355  \n",
      "\n",
      "Fold: 1  Epoch: 199  Training loss = 3.1378  Validation loss = 3.2326  \n",
      "\n",
      "Fold: 1  Epoch: 200  Training loss = 3.1361  Validation loss = 3.2294  \n",
      "\n",
      "Fold: 1  Epoch: 201  Training loss = 3.1347  Validation loss = 3.2267  \n",
      "\n",
      "Fold: 1  Epoch: 202  Training loss = 3.1334  Validation loss = 3.2242  \n",
      "\n",
      "Fold: 1  Epoch: 203  Training loss = 3.1320  Validation loss = 3.2214  \n",
      "\n",
      "Fold: 1  Epoch: 204  Training loss = 3.1303  Validation loss = 3.2183  \n",
      "\n",
      "Fold: 1  Epoch: 205  Training loss = 3.1291  Validation loss = 3.2162  \n",
      "\n",
      "Fold: 1  Epoch: 206  Training loss = 3.1281  Validation loss = 3.2142  \n",
      "\n",
      "Fold: 1  Epoch: 207  Training loss = 3.1268  Validation loss = 3.2117  \n",
      "\n",
      "Fold: 1  Epoch: 208  Training loss = 3.1254  Validation loss = 3.2089  \n",
      "\n",
      "Fold: 1  Epoch: 209  Training loss = 3.1235  Validation loss = 3.2053  \n",
      "\n",
      "Fold: 1  Epoch: 210  Training loss = 3.1217  Validation loss = 3.2016  \n",
      "\n",
      "Fold: 1  Epoch: 211  Training loss = 3.1201  Validation loss = 3.1987  \n",
      "\n",
      "Fold: 1  Epoch: 212  Training loss = 3.1190  Validation loss = 3.1964  \n",
      "\n",
      "Fold: 1  Epoch: 213  Training loss = 3.1177  Validation loss = 3.1941  \n",
      "\n",
      "Fold: 1  Epoch: 214  Training loss = 3.1166  Validation loss = 3.1918  \n",
      "\n",
      "Fold: 1  Epoch: 215  Training loss = 3.1151  Validation loss = 3.1888  \n",
      "\n",
      "Fold: 1  Epoch: 216  Training loss = 3.1139  Validation loss = 3.1865  \n",
      "\n",
      "Fold: 1  Epoch: 217  Training loss = 3.1129  Validation loss = 3.1847  \n",
      "\n",
      "Fold: 1  Epoch: 218  Training loss = 3.1118  Validation loss = 3.1824  \n",
      "\n",
      "Fold: 1  Epoch: 219  Training loss = 3.1102  Validation loss = 3.1795  \n",
      "\n",
      "Fold: 1  Epoch: 220  Training loss = 3.1091  Validation loss = 3.1772  \n",
      "\n",
      "Fold: 1  Epoch: 221  Training loss = 3.1078  Validation loss = 3.1747  \n",
      "\n",
      "Fold: 1  Epoch: 222  Training loss = 3.1064  Validation loss = 3.1720  \n",
      "\n",
      "Fold: 1  Epoch: 223  Training loss = 3.1052  Validation loss = 3.1698  \n",
      "\n",
      "Fold: 1  Epoch: 224  Training loss = 3.1040  Validation loss = 3.1674  \n",
      "\n",
      "Fold: 1  Epoch: 225  Training loss = 3.1023  Validation loss = 3.1639  \n",
      "\n",
      "Fold: 1  Epoch: 226  Training loss = 3.1010  Validation loss = 3.1613  \n",
      "\n",
      "Fold: 1  Epoch: 227  Training loss = 3.0996  Validation loss = 3.1586  \n",
      "\n",
      "Fold: 1  Epoch: 228  Training loss = 3.0986  Validation loss = 3.1566  \n",
      "\n",
      "Fold: 1  Epoch: 229  Training loss = 3.0972  Validation loss = 3.1540  \n",
      "\n",
      "Fold: 1  Epoch: 230  Training loss = 3.0958  Validation loss = 3.1512  \n",
      "\n",
      "Fold: 1  Epoch: 231  Training loss = 3.0945  Validation loss = 3.1485  \n",
      "\n",
      "Fold: 1  Epoch: 232  Training loss = 3.0932  Validation loss = 3.1460  \n",
      "\n",
      "Fold: 1  Epoch: 233  Training loss = 3.0911  Validation loss = 3.1420  \n",
      "\n",
      "Fold: 1  Epoch: 234  Training loss = 3.0891  Validation loss = 3.1380  \n",
      "\n",
      "Fold: 1  Epoch: 235  Training loss = 3.0880  Validation loss = 3.1358  \n",
      "\n",
      "Fold: 1  Epoch: 236  Training loss = 3.0866  Validation loss = 3.1330  \n",
      "\n",
      "Fold: 1  Epoch: 237  Training loss = 3.0857  Validation loss = 3.1313  \n",
      "\n",
      "Fold: 1  Epoch: 238  Training loss = 3.0843  Validation loss = 3.1283  \n",
      "\n",
      "Fold: 1  Epoch: 239  Training loss = 3.0828  Validation loss = 3.1255  \n",
      "\n",
      "Fold: 1  Epoch: 240  Training loss = 3.0818  Validation loss = 3.1232  \n",
      "\n",
      "Fold: 1  Epoch: 241  Training loss = 3.0806  Validation loss = 3.1210  \n",
      "\n",
      "Fold: 1  Epoch: 242  Training loss = 3.0796  Validation loss = 3.1189  \n",
      "\n",
      "Fold: 1  Epoch: 243  Training loss = 3.0786  Validation loss = 3.1171  \n",
      "\n",
      "Fold: 1  Epoch: 244  Training loss = 3.0777  Validation loss = 3.1152  \n",
      "\n",
      "Fold: 1  Epoch: 245  Training loss = 3.0763  Validation loss = 3.1123  \n",
      "\n",
      "Fold: 1  Epoch: 246  Training loss = 3.0750  Validation loss = 3.1096  \n",
      "\n",
      "Fold: 1  Epoch: 247  Training loss = 3.0739  Validation loss = 3.1074  \n",
      "\n",
      "Fold: 1  Epoch: 248  Training loss = 3.0726  Validation loss = 3.1048  \n",
      "\n",
      "Fold: 1  Epoch: 249  Training loss = 3.0716  Validation loss = 3.1029  \n",
      "\n",
      "Fold: 1  Epoch: 250  Training loss = 3.0708  Validation loss = 3.1012  \n",
      "\n",
      "Fold: 1  Epoch: 251  Training loss = 3.0689  Validation loss = 3.0974  \n",
      "\n",
      "Fold: 1  Epoch: 252  Training loss = 3.0673  Validation loss = 3.0939  \n",
      "\n",
      "Fold: 1  Epoch: 253  Training loss = 3.0659  Validation loss = 3.0911  \n",
      "\n",
      "Fold: 1  Epoch: 254  Training loss = 3.0644  Validation loss = 3.0881  \n",
      "\n",
      "Fold: 1  Epoch: 255  Training loss = 3.0629  Validation loss = 3.0850  \n",
      "\n",
      "Fold: 1  Epoch: 256  Training loss = 3.0615  Validation loss = 3.0823  \n",
      "\n",
      "Fold: 1  Epoch: 257  Training loss = 3.0607  Validation loss = 3.0807  \n",
      "\n",
      "Fold: 1  Epoch: 258  Training loss = 3.0596  Validation loss = 3.0784  \n",
      "\n",
      "Fold: 1  Epoch: 259  Training loss = 3.0589  Validation loss = 3.0769  \n",
      "\n",
      "Fold: 1  Epoch: 260  Training loss = 3.0572  Validation loss = 3.0736  \n",
      "\n",
      "Fold: 1  Epoch: 261  Training loss = 3.0562  Validation loss = 3.0716  \n",
      "\n",
      "Fold: 1  Epoch: 262  Training loss = 3.0551  Validation loss = 3.0692  \n",
      "\n",
      "Fold: 1  Epoch: 263  Training loss = 3.0536  Validation loss = 3.0660  \n",
      "\n",
      "Fold: 1  Epoch: 264  Training loss = 3.0523  Validation loss = 3.0634  \n",
      "\n",
      "Fold: 1  Epoch: 265  Training loss = 3.0511  Validation loss = 3.0608  \n",
      "\n",
      "Fold: 1  Epoch: 266  Training loss = 3.0497  Validation loss = 3.0580  \n",
      "\n",
      "Fold: 1  Epoch: 267  Training loss = 3.0485  Validation loss = 3.0554  \n",
      "\n",
      "Fold: 1  Epoch: 268  Training loss = 3.0472  Validation loss = 3.0526  \n",
      "\n",
      "Fold: 1  Epoch: 269  Training loss = 3.0461  Validation loss = 3.0502  \n",
      "\n",
      "Fold: 1  Epoch: 270  Training loss = 3.0447  Validation loss = 3.0474  \n",
      "\n",
      "Fold: 1  Epoch: 271  Training loss = 3.0439  Validation loss = 3.0456  \n",
      "\n",
      "Fold: 1  Epoch: 272  Training loss = 3.0428  Validation loss = 3.0434  \n",
      "\n",
      "Fold: 1  Epoch: 273  Training loss = 3.0417  Validation loss = 3.0410  \n",
      "\n",
      "Fold: 1  Epoch: 274  Training loss = 3.0405  Validation loss = 3.0384  \n",
      "\n",
      "Fold: 1  Epoch: 275  Training loss = 3.0395  Validation loss = 3.0365  \n",
      "\n",
      "Fold: 1  Epoch: 276  Training loss = 3.0385  Validation loss = 3.0342  \n",
      "\n",
      "Fold: 1  Epoch: 277  Training loss = 3.0375  Validation loss = 3.0320  \n",
      "\n",
      "Fold: 1  Epoch: 278  Training loss = 3.0364  Validation loss = 3.0297  \n",
      "\n",
      "Fold: 1  Epoch: 279  Training loss = 3.0354  Validation loss = 3.0275  \n",
      "\n",
      "Fold: 1  Epoch: 280  Training loss = 3.0346  Validation loss = 3.0258  \n",
      "\n",
      "Fold: 1  Epoch: 281  Training loss = 3.0336  Validation loss = 3.0236  \n",
      "\n",
      "Fold: 1  Epoch: 282  Training loss = 3.0326  Validation loss = 3.0214  \n",
      "\n",
      "Fold: 1  Epoch: 283  Training loss = 3.0314  Validation loss = 3.0188  \n",
      "\n",
      "Fold: 1  Epoch: 284  Training loss = 3.0299  Validation loss = 3.0156  \n",
      "\n",
      "Fold: 1  Epoch: 285  Training loss = 3.0286  Validation loss = 3.0127  \n",
      "\n",
      "Fold: 1  Epoch: 286  Training loss = 3.0273  Validation loss = 3.0098  \n",
      "\n",
      "Fold: 1  Epoch: 287  Training loss = 3.0263  Validation loss = 3.0076  \n",
      "\n",
      "Fold: 1  Epoch: 288  Training loss = 3.0254  Validation loss = 3.0057  \n",
      "\n",
      "Fold: 1  Epoch: 289  Training loss = 3.0243  Validation loss = 3.0034  \n",
      "\n",
      "Fold: 1  Epoch: 290  Training loss = 3.0229  Validation loss = 3.0003  \n",
      "\n",
      "Fold: 1  Epoch: 291  Training loss = 3.0221  Validation loss = 2.9986  \n",
      "\n",
      "Fold: 1  Epoch: 292  Training loss = 3.0212  Validation loss = 2.9966  \n",
      "\n",
      "Fold: 1  Epoch: 293  Training loss = 3.0204  Validation loss = 2.9949  \n",
      "\n",
      "Fold: 1  Epoch: 294  Training loss = 3.0197  Validation loss = 2.9935  \n",
      "\n",
      "Fold: 1  Epoch: 295  Training loss = 3.0188  Validation loss = 2.9914  \n",
      "\n",
      "Fold: 1  Epoch: 296  Training loss = 3.0180  Validation loss = 2.9896  \n",
      "\n",
      "Fold: 1  Epoch: 297  Training loss = 3.0172  Validation loss = 2.9879  \n",
      "\n",
      "Fold: 1  Epoch: 298  Training loss = 3.0165  Validation loss = 2.9864  \n",
      "\n",
      "Fold: 1  Epoch: 299  Training loss = 3.0155  Validation loss = 2.9842  \n",
      "\n",
      "Fold: 1  Epoch: 300  Training loss = 3.0147  Validation loss = 2.9824  \n",
      "\n",
      "Fold: 1  Epoch: 301  Training loss = 3.0138  Validation loss = 2.9803  \n",
      "\n",
      "Fold: 1  Epoch: 302  Training loss = 3.0126  Validation loss = 2.9777  \n",
      "\n",
      "Fold: 1  Epoch: 303  Training loss = 3.0114  Validation loss = 2.9750  \n",
      "\n",
      "Fold: 1  Epoch: 304  Training loss = 3.0105  Validation loss = 2.9732  \n",
      "\n",
      "Fold: 1  Epoch: 305  Training loss = 3.0092  Validation loss = 2.9703  \n",
      "\n",
      "Fold: 1  Epoch: 306  Training loss = 3.0080  Validation loss = 2.9676  \n",
      "\n",
      "Fold: 1  Epoch: 307  Training loss = 3.0072  Validation loss = 2.9659  \n",
      "\n",
      "Fold: 1  Epoch: 308  Training loss = 3.0057  Validation loss = 2.9626  \n",
      "\n",
      "Fold: 1  Epoch: 309  Training loss = 3.0050  Validation loss = 2.9611  \n",
      "\n",
      "Fold: 1  Epoch: 310  Training loss = 3.0037  Validation loss = 2.9581  \n",
      "\n",
      "Fold: 1  Epoch: 311  Training loss = 3.0029  Validation loss = 2.9564  \n",
      "\n",
      "Fold: 1  Epoch: 312  Training loss = 3.0018  Validation loss = 2.9539  \n",
      "\n",
      "Fold: 1  Epoch: 313  Training loss = 3.0005  Validation loss = 2.9508  \n",
      "\n",
      "Fold: 1  Epoch: 314  Training loss = 2.9995  Validation loss = 2.9486  \n",
      "\n",
      "Fold: 1  Epoch: 315  Training loss = 2.9990  Validation loss = 2.9475  \n",
      "\n",
      "Fold: 1  Epoch: 316  Training loss = 2.9983  Validation loss = 2.9459  \n",
      "\n",
      "Fold: 1  Epoch: 317  Training loss = 2.9974  Validation loss = 2.9439  \n",
      "\n",
      "Fold: 1  Epoch: 318  Training loss = 2.9965  Validation loss = 2.9420  \n",
      "\n",
      "Fold: 1  Epoch: 319  Training loss = 2.9954  Validation loss = 2.9394  \n",
      "\n",
      "Fold: 1  Epoch: 320  Training loss = 2.9944  Validation loss = 2.9370  \n",
      "\n",
      "Fold: 1  Epoch: 321  Training loss = 2.9935  Validation loss = 2.9352  \n",
      "\n",
      "Fold: 1  Epoch: 322  Training loss = 2.9925  Validation loss = 2.9329  \n",
      "\n",
      "Fold: 1  Epoch: 323  Training loss = 2.9915  Validation loss = 2.9305  \n",
      "\n",
      "Fold: 1  Epoch: 324  Training loss = 2.9904  Validation loss = 2.9280  \n",
      "\n",
      "Fold: 1  Epoch: 325  Training loss = 2.9890  Validation loss = 2.9247  \n",
      "\n",
      "Fold: 1  Epoch: 326  Training loss = 2.9880  Validation loss = 2.9224  \n",
      "\n",
      "Fold: 1  Epoch: 327  Training loss = 2.9873  Validation loss = 2.9207  \n",
      "\n",
      "Fold: 1  Epoch: 328  Training loss = 2.9862  Validation loss = 2.9182  \n",
      "\n",
      "Fold: 1  Epoch: 329  Training loss = 2.9852  Validation loss = 2.9160  \n",
      "\n",
      "Fold: 1  Epoch: 330  Training loss = 2.9844  Validation loss = 2.9142  \n",
      "\n",
      "Fold: 1  Epoch: 331  Training loss = 2.9833  Validation loss = 2.9115  \n",
      "\n",
      "Fold: 1  Epoch: 332  Training loss = 2.9824  Validation loss = 2.9095  \n",
      "\n",
      "Fold: 1  Epoch: 333  Training loss = 2.9813  Validation loss = 2.9071  \n",
      "\n",
      "Fold: 1  Epoch: 334  Training loss = 2.9804  Validation loss = 2.9050  \n",
      "\n",
      "Fold: 1  Epoch: 335  Training loss = 2.9793  Validation loss = 2.9024  \n",
      "\n",
      "Fold: 1  Epoch: 336  Training loss = 2.9787  Validation loss = 2.9011  \n",
      "\n",
      "Fold: 1  Epoch: 337  Training loss = 2.9779  Validation loss = 2.8991  \n",
      "\n",
      "Fold: 1  Epoch: 338  Training loss = 2.9770  Validation loss = 2.8970  \n",
      "\n",
      "Fold: 1  Epoch: 339  Training loss = 2.9759  Validation loss = 2.8944  \n",
      "\n",
      "Fold: 1  Epoch: 340  Training loss = 2.9751  Validation loss = 2.8926  \n",
      "\n",
      "Fold: 1  Epoch: 341  Training loss = 2.9738  Validation loss = 2.8897  \n",
      "\n",
      "Fold: 1  Epoch: 342  Training loss = 2.9732  Validation loss = 2.8881  \n",
      "\n",
      "Fold: 1  Epoch: 343  Training loss = 2.9727  Validation loss = 2.8870  \n",
      "\n",
      "Fold: 1  Epoch: 344  Training loss = 2.9717  Validation loss = 2.8846  \n",
      "\n",
      "Fold: 1  Epoch: 345  Training loss = 2.9710  Validation loss = 2.8830  \n",
      "\n",
      "Fold: 1  Epoch: 346  Training loss = 2.9700  Validation loss = 2.8809  \n",
      "\n",
      "Fold: 1  Epoch: 347  Training loss = 2.9694  Validation loss = 2.8794  \n",
      "\n",
      "Fold: 1  Epoch: 348  Training loss = 2.9689  Validation loss = 2.8781  \n",
      "\n",
      "Fold: 1  Epoch: 349  Training loss = 2.9682  Validation loss = 2.8766  \n",
      "\n",
      "Fold: 1  Epoch: 350  Training loss = 2.9677  Validation loss = 2.8752  \n",
      "\n",
      "Fold: 1  Epoch: 351  Training loss = 2.9670  Validation loss = 2.8735  \n",
      "\n",
      "Fold: 1  Epoch: 352  Training loss = 2.9661  Validation loss = 2.8716  \n",
      "\n",
      "Fold: 1  Epoch: 353  Training loss = 2.9652  Validation loss = 2.8695  \n",
      "\n",
      "Fold: 1  Epoch: 354  Training loss = 2.9645  Validation loss = 2.8678  \n",
      "\n",
      "Fold: 1  Epoch: 355  Training loss = 2.9636  Validation loss = 2.8657  \n",
      "\n",
      "Fold: 1  Epoch: 356  Training loss = 2.9630  Validation loss = 2.8642  \n",
      "\n",
      "Fold: 1  Epoch: 357  Training loss = 2.9622  Validation loss = 2.8624  \n",
      "\n",
      "Fold: 1  Epoch: 358  Training loss = 2.9616  Validation loss = 2.8609  \n",
      "\n",
      "Fold: 1  Epoch: 359  Training loss = 2.9606  Validation loss = 2.8585  \n",
      "\n",
      "Fold: 1  Epoch: 360  Training loss = 2.9595  Validation loss = 2.8560  \n",
      "\n",
      "Fold: 1  Epoch: 361  Training loss = 2.9588  Validation loss = 2.8543  \n",
      "\n",
      "Fold: 1  Epoch: 362  Training loss = 2.9583  Validation loss = 2.8530  \n",
      "\n",
      "Fold: 1  Epoch: 363  Training loss = 2.9572  Validation loss = 2.8505  \n",
      "\n",
      "Fold: 1  Epoch: 364  Training loss = 2.9567  Validation loss = 2.8492  \n",
      "\n",
      "Fold: 1  Epoch: 365  Training loss = 2.9563  Validation loss = 2.8483  \n",
      "\n",
      "Fold: 1  Epoch: 366  Training loss = 2.9558  Validation loss = 2.8470  \n",
      "\n",
      "Fold: 1  Epoch: 367  Training loss = 2.9552  Validation loss = 2.8456  \n",
      "\n",
      "Fold: 1  Epoch: 368  Training loss = 2.9547  Validation loss = 2.8442  \n",
      "\n",
      "Fold: 1  Epoch: 369  Training loss = 2.9542  Validation loss = 2.8430  \n",
      "\n",
      "Fold: 1  Epoch: 370  Training loss = 2.9534  Validation loss = 2.8412  \n",
      "\n",
      "Fold: 1  Epoch: 371  Training loss = 2.9526  Validation loss = 2.8392  \n",
      "\n",
      "Fold: 1  Epoch: 372  Training loss = 2.9520  Validation loss = 2.8378  \n",
      "\n",
      "Fold: 1  Epoch: 373  Training loss = 2.9506  Validation loss = 2.8344  \n",
      "\n",
      "Fold: 1  Epoch: 374  Training loss = 2.9497  Validation loss = 2.8321  \n",
      "\n",
      "Fold: 1  Epoch: 375  Training loss = 2.9492  Validation loss = 2.8310  \n",
      "\n",
      "Fold: 1  Epoch: 376  Training loss = 2.9484  Validation loss = 2.8290  \n",
      "\n",
      "Fold: 1  Epoch: 377  Training loss = 2.9477  Validation loss = 2.8273  \n",
      "\n",
      "Fold: 1  Epoch: 378  Training loss = 2.9468  Validation loss = 2.8250  \n",
      "\n",
      "Fold: 1  Epoch: 379  Training loss = 2.9459  Validation loss = 2.8229  \n",
      "\n",
      "Fold: 1  Epoch: 380  Training loss = 2.9453  Validation loss = 2.8215  \n",
      "\n",
      "Fold: 1  Epoch: 381  Training loss = 2.9440  Validation loss = 2.8184  \n",
      "\n",
      "Fold: 1  Epoch: 382  Training loss = 2.9432  Validation loss = 2.8163  \n",
      "\n",
      "Fold: 1  Epoch: 383  Training loss = 2.9422  Validation loss = 2.8138  \n",
      "\n",
      "Fold: 1  Epoch: 384  Training loss = 2.9416  Validation loss = 2.8122  \n",
      "\n",
      "Fold: 1  Epoch: 385  Training loss = 2.9409  Validation loss = 2.8104  \n",
      "\n",
      "Fold: 1  Epoch: 386  Training loss = 2.9400  Validation loss = 2.8085  \n",
      "\n",
      "Fold: 1  Epoch: 387  Training loss = 2.9389  Validation loss = 2.8057  \n",
      "\n",
      "Fold: 1  Epoch: 388  Training loss = 2.9384  Validation loss = 2.8044  \n",
      "\n",
      "Fold: 1  Epoch: 389  Training loss = 2.9374  Validation loss = 2.8019  \n",
      "\n",
      "Fold: 1  Epoch: 390  Training loss = 2.9369  Validation loss = 2.8007  \n",
      "\n",
      "Fold: 1  Epoch: 391  Training loss = 2.9359  Validation loss = 2.7983  \n",
      "\n",
      "Fold: 1  Epoch: 392  Training loss = 2.9351  Validation loss = 2.7963  \n",
      "\n",
      "Fold: 1  Epoch: 393  Training loss = 2.9346  Validation loss = 2.7949  \n",
      "\n",
      "Fold: 1  Epoch: 394  Training loss = 2.9338  Validation loss = 2.7931  \n",
      "\n",
      "Fold: 1  Epoch: 395  Training loss = 2.9333  Validation loss = 2.7917  \n",
      "\n",
      "Fold: 1  Epoch: 396  Training loss = 2.9326  Validation loss = 2.7899  \n",
      "\n",
      "Fold: 1  Epoch: 397  Training loss = 2.9320  Validation loss = 2.7886  \n",
      "\n",
      "Fold: 1  Epoch: 398  Training loss = 2.9309  Validation loss = 2.7857  \n",
      "\n",
      "Fold: 1  Epoch: 399  Training loss = 2.9301  Validation loss = 2.7838  \n",
      "\n",
      "Fold: 1  Epoch: 400  Training loss = 2.9295  Validation loss = 2.7824  \n",
      "\n",
      "Fold: 1  Epoch: 401  Training loss = 2.9286  Validation loss = 2.7800  \n",
      "\n",
      "Fold: 1  Epoch: 402  Training loss = 2.9280  Validation loss = 2.7784  \n",
      "\n",
      "Fold: 1  Epoch: 403  Training loss = 2.9271  Validation loss = 2.7763  \n",
      "\n",
      "Fold: 1  Epoch: 404  Training loss = 2.9266  Validation loss = 2.7749  \n",
      "\n",
      "Fold: 1  Epoch: 405  Training loss = 2.9258  Validation loss = 2.7730  \n",
      "\n",
      "Fold: 1  Epoch: 406  Training loss = 2.9247  Validation loss = 2.7702  \n",
      "\n",
      "Fold: 1  Epoch: 407  Training loss = 2.9242  Validation loss = 2.7691  \n",
      "\n",
      "Fold: 1  Epoch: 408  Training loss = 2.9234  Validation loss = 2.7668  \n",
      "\n",
      "Fold: 1  Epoch: 409  Training loss = 2.9226  Validation loss = 2.7649  \n",
      "\n",
      "Fold: 1  Epoch: 410  Training loss = 2.9217  Validation loss = 2.7624  \n",
      "\n",
      "Fold: 1  Epoch: 411  Training loss = 2.9213  Validation loss = 2.7615  \n",
      "\n",
      "Fold: 1  Epoch: 412  Training loss = 2.9207  Validation loss = 2.7599  \n",
      "\n",
      "Fold: 1  Epoch: 413  Training loss = 2.9203  Validation loss = 2.7588  \n",
      "\n",
      "Fold: 1  Epoch: 414  Training loss = 2.9194  Validation loss = 2.7565  \n",
      "\n",
      "Fold: 1  Epoch: 415  Training loss = 2.9189  Validation loss = 2.7553  \n",
      "\n",
      "Fold: 1  Epoch: 416  Training loss = 2.9182  Validation loss = 2.7533  \n",
      "\n",
      "Fold: 1  Epoch: 417  Training loss = 2.9174  Validation loss = 2.7515  \n",
      "\n",
      "Fold: 1  Epoch: 418  Training loss = 2.9167  Validation loss = 2.7496  \n",
      "\n",
      "Fold: 1  Epoch: 419  Training loss = 2.9161  Validation loss = 2.7480  \n",
      "\n",
      "Fold: 1  Epoch: 420  Training loss = 2.9149  Validation loss = 2.7448  \n",
      "\n",
      "Fold: 1  Epoch: 421  Training loss = 2.9138  Validation loss = 2.7421  \n",
      "\n",
      "Fold: 1  Epoch: 422  Training loss = 2.9135  Validation loss = 2.7412  \n",
      "\n",
      "Fold: 1  Epoch: 423  Training loss = 2.9128  Validation loss = 2.7395  \n",
      "\n",
      "Fold: 1  Epoch: 424  Training loss = 2.9124  Validation loss = 2.7383  \n",
      "\n",
      "Fold: 1  Epoch: 425  Training loss = 2.9115  Validation loss = 2.7360  \n",
      "\n",
      "Fold: 1  Epoch: 426  Training loss = 2.9110  Validation loss = 2.7347  \n",
      "\n",
      "Fold: 1  Epoch: 427  Training loss = 2.9104  Validation loss = 2.7331  \n",
      "\n",
      "Fold: 1  Epoch: 428  Training loss = 2.9096  Validation loss = 2.7309  \n",
      "\n",
      "Fold: 1  Epoch: 429  Training loss = 2.9088  Validation loss = 2.7290  \n",
      "\n",
      "Fold: 1  Epoch: 430  Training loss = 2.9083  Validation loss = 2.7277  \n",
      "\n",
      "Fold: 1  Epoch: 431  Training loss = 2.9079  Validation loss = 2.7266  \n",
      "\n",
      "Fold: 1  Epoch: 432  Training loss = 2.9071  Validation loss = 2.7245  \n",
      "\n",
      "Fold: 1  Epoch: 433  Training loss = 2.9062  Validation loss = 2.7222  \n",
      "\n",
      "Fold: 1  Epoch: 434  Training loss = 2.9060  Validation loss = 2.7214  \n",
      "\n",
      "Fold: 1  Epoch: 435  Training loss = 2.9053  Validation loss = 2.7198  \n",
      "\n",
      "Fold: 1  Epoch: 436  Training loss = 2.9045  Validation loss = 2.7177  \n",
      "\n",
      "Fold: 1  Epoch: 437  Training loss = 2.9039  Validation loss = 2.7159  \n",
      "\n",
      "Fold: 1  Epoch: 438  Training loss = 2.9033  Validation loss = 2.7143  \n",
      "\n",
      "Fold: 1  Epoch: 439  Training loss = 2.9026  Validation loss = 2.7125  \n",
      "\n",
      "Fold: 1  Epoch: 440  Training loss = 2.9017  Validation loss = 2.7102  \n",
      "\n",
      "Fold: 1  Epoch: 441  Training loss = 2.9006  Validation loss = 2.7073  \n",
      "\n",
      "Fold: 1  Epoch: 442  Training loss = 2.9000  Validation loss = 2.7055  \n",
      "\n",
      "Fold: 1  Epoch: 443  Training loss = 2.8996  Validation loss = 2.7046  \n",
      "\n",
      "Fold: 1  Epoch: 444  Training loss = 2.8987  Validation loss = 2.7021  \n",
      "\n",
      "Fold: 1  Epoch: 445  Training loss = 2.8981  Validation loss = 2.7006  \n",
      "\n",
      "Fold: 1  Epoch: 446  Training loss = 2.8975  Validation loss = 2.6989  \n",
      "\n",
      "Fold: 1  Epoch: 447  Training loss = 2.8964  Validation loss = 2.6959  \n",
      "\n",
      "Fold: 1  Epoch: 448  Training loss = 2.8958  Validation loss = 2.6941  \n",
      "\n",
      "Fold: 1  Epoch: 449  Training loss = 2.8952  Validation loss = 2.6926  \n",
      "\n",
      "Fold: 1  Epoch: 450  Training loss = 2.8948  Validation loss = 2.6916  \n",
      "\n",
      "Fold: 1  Epoch: 451  Training loss = 2.8942  Validation loss = 2.6899  \n",
      "\n",
      "Fold: 1  Epoch: 452  Training loss = 2.8936  Validation loss = 2.6885  \n",
      "\n",
      "Fold: 1  Epoch: 453  Training loss = 2.8929  Validation loss = 2.6864  \n",
      "\n",
      "Fold: 1  Epoch: 454  Training loss = 2.8923  Validation loss = 2.6848  \n",
      "\n",
      "Fold: 1  Epoch: 455  Training loss = 2.8917  Validation loss = 2.6833  \n",
      "\n",
      "Fold: 1  Epoch: 456  Training loss = 2.8909  Validation loss = 2.6810  \n",
      "\n",
      "Fold: 1  Epoch: 457  Training loss = 2.8905  Validation loss = 2.6798  \n",
      "\n",
      "Fold: 1  Epoch: 458  Training loss = 2.8898  Validation loss = 2.6779  \n",
      "\n",
      "Fold: 1  Epoch: 459  Training loss = 2.8892  Validation loss = 2.6763  \n",
      "\n",
      "Fold: 1  Epoch: 460  Training loss = 2.8886  Validation loss = 2.6745  \n",
      "\n",
      "Fold: 1  Epoch: 461  Training loss = 2.8880  Validation loss = 2.6730  \n",
      "\n",
      "Fold: 1  Epoch: 462  Training loss = 2.8869  Validation loss = 2.6701  \n",
      "\n",
      "Fold: 1  Epoch: 463  Training loss = 2.8863  Validation loss = 2.6684  \n",
      "\n",
      "Fold: 1  Epoch: 464  Training loss = 2.8858  Validation loss = 2.6670  \n",
      "\n",
      "Fold: 1  Epoch: 465  Training loss = 2.8850  Validation loss = 2.6647  \n",
      "\n",
      "Fold: 1  Epoch: 466  Training loss = 2.8844  Validation loss = 2.6631  \n",
      "\n",
      "Fold: 1  Epoch: 467  Training loss = 2.8837  Validation loss = 2.6612  \n",
      "\n",
      "Fold: 1  Epoch: 468  Training loss = 2.8831  Validation loss = 2.6596  \n",
      "\n",
      "Fold: 1  Epoch: 469  Training loss = 2.8824  Validation loss = 2.6576  \n",
      "\n",
      "Fold: 1  Epoch: 470  Training loss = 2.8816  Validation loss = 2.6553  \n",
      "\n",
      "Fold: 1  Epoch: 471  Training loss = 2.8809  Validation loss = 2.6533  \n",
      "\n",
      "Fold: 1  Epoch: 472  Training loss = 2.8802  Validation loss = 2.6515  \n",
      "\n",
      "Fold: 1  Epoch: 473  Training loss = 2.8794  Validation loss = 2.6493  \n",
      "\n",
      "Fold: 1  Epoch: 474  Training loss = 2.8784  Validation loss = 2.6464  \n",
      "\n",
      "Fold: 1  Epoch: 475  Training loss = 2.8775  Validation loss = 2.6439  \n",
      "\n",
      "Fold: 1  Epoch: 476  Training loss = 2.8769  Validation loss = 2.6423  \n",
      "\n",
      "Fold: 1  Epoch: 477  Training loss = 2.8762  Validation loss = 2.6404  \n",
      "\n",
      "Fold: 1  Epoch: 478  Training loss = 2.8759  Validation loss = 2.6394  \n",
      "\n",
      "Fold: 1  Epoch: 479  Training loss = 2.8753  Validation loss = 2.6378  \n",
      "\n",
      "Fold: 1  Epoch: 480  Training loss = 2.8748  Validation loss = 2.6363  \n",
      "\n",
      "Fold: 1  Epoch: 481  Training loss = 2.8741  Validation loss = 2.6342  \n",
      "\n",
      "Fold: 1  Epoch: 482  Training loss = 2.8736  Validation loss = 2.6330  \n",
      "\n",
      "Fold: 1  Epoch: 483  Training loss = 2.8730  Validation loss = 2.6312  \n",
      "\n",
      "Fold: 1  Epoch: 484  Training loss = 2.8728  Validation loss = 2.6305  \n",
      "\n",
      "Fold: 1  Epoch: 485  Training loss = 2.8719  Validation loss = 2.6282  \n",
      "\n",
      "Fold: 1  Epoch: 486  Training loss = 2.8711  Validation loss = 2.6258  \n",
      "\n",
      "Fold: 1  Epoch: 487  Training loss = 2.8706  Validation loss = 2.6245  \n",
      "\n",
      "Fold: 1  Epoch: 488  Training loss = 2.8702  Validation loss = 2.6234  \n",
      "\n",
      "Fold: 1  Epoch: 489  Training loss = 2.8697  Validation loss = 2.6218  \n",
      "\n",
      "Fold: 1  Epoch: 490  Training loss = 2.8690  Validation loss = 2.6199  \n",
      "\n",
      "Fold: 1  Epoch: 491  Training loss = 2.8687  Validation loss = 2.6189  \n",
      "\n",
      "Fold: 1  Epoch: 492  Training loss = 2.8683  Validation loss = 2.6179  \n",
      "\n",
      "Fold: 1  Epoch: 493  Training loss = 2.8674  Validation loss = 2.6153  \n",
      "\n",
      "Fold: 1  Epoch: 494  Training loss = 2.8666  Validation loss = 2.6131  \n",
      "\n",
      "Fold: 1  Epoch: 495  Training loss = 2.8662  Validation loss = 2.6118  \n",
      "\n",
      "Fold: 1  Epoch: 496  Training loss = 2.8658  Validation loss = 2.6107  \n",
      "\n",
      "Fold: 1  Epoch: 497  Training loss = 2.8654  Validation loss = 2.6094  \n",
      "\n",
      "Fold: 1  Epoch: 498  Training loss = 2.8645  Validation loss = 2.6069  \n",
      "\n",
      "Fold: 1  Epoch: 499  Training loss = 2.8641  Validation loss = 2.6056  \n",
      "\n",
      "Fold: 1  Epoch: 500  Training loss = 2.8635  Validation loss = 2.6040  \n",
      "\n",
      "Check model:  Fold: 1  Optimal epoch: 500  \n",
      "\n",
      "Fold: 2  Epoch: 1  Training loss = 2.7866  Validation loss = 2.7855  \n",
      "\n",
      "Fold: 2  Epoch: 2  Training loss = 2.7861  Validation loss = 2.7843  \n",
      "\n",
      "Fold: 2  Epoch: 3  Training loss = 2.7854  Validation loss = 2.7830  \n",
      "\n",
      "Fold: 2  Epoch: 4  Training loss = 2.7848  Validation loss = 2.7817  \n",
      "\n",
      "Fold: 2  Epoch: 5  Training loss = 2.7841  Validation loss = 2.7802  \n",
      "\n",
      "Fold: 2  Epoch: 6  Training loss = 2.7836  Validation loss = 2.7791  \n",
      "\n",
      "Fold: 2  Epoch: 7  Training loss = 2.7828  Validation loss = 2.7777  \n",
      "\n",
      "Fold: 2  Epoch: 8  Training loss = 2.7820  Validation loss = 2.7760  \n",
      "\n",
      "Fold: 2  Epoch: 9  Training loss = 2.7815  Validation loss = 2.7750  \n",
      "\n",
      "Fold: 2  Epoch: 10  Training loss = 2.7809  Validation loss = 2.7739  \n",
      "\n",
      "Fold: 2  Epoch: 11  Training loss = 2.7801  Validation loss = 2.7722  \n",
      "\n",
      "Fold: 2  Epoch: 12  Training loss = 2.7793  Validation loss = 2.7706  \n",
      "\n",
      "Fold: 2  Epoch: 13  Training loss = 2.7788  Validation loss = 2.7697  \n",
      "\n",
      "Fold: 2  Epoch: 14  Training loss = 2.7783  Validation loss = 2.7687  \n",
      "\n",
      "Fold: 2  Epoch: 15  Training loss = 2.7777  Validation loss = 2.7676  \n",
      "\n",
      "Fold: 2  Epoch: 16  Training loss = 2.7772  Validation loss = 2.7665  \n",
      "\n",
      "Fold: 2  Epoch: 17  Training loss = 2.7764  Validation loss = 2.7649  \n",
      "\n",
      "Fold: 2  Epoch: 18  Training loss = 2.7757  Validation loss = 2.7635  \n",
      "\n",
      "Fold: 2  Epoch: 19  Training loss = 2.7753  Validation loss = 2.7627  \n",
      "\n",
      "Fold: 2  Epoch: 20  Training loss = 2.7748  Validation loss = 2.7616  \n",
      "\n",
      "Fold: 2  Epoch: 21  Training loss = 2.7742  Validation loss = 2.7604  \n",
      "\n",
      "Fold: 2  Epoch: 22  Training loss = 2.7730  Validation loss = 2.7581  \n",
      "\n",
      "Fold: 2  Epoch: 23  Training loss = 2.7721  Validation loss = 2.7563  \n",
      "\n",
      "Fold: 2  Epoch: 24  Training loss = 2.7716  Validation loss = 2.7552  \n",
      "\n",
      "Fold: 2  Epoch: 25  Training loss = 2.7710  Validation loss = 2.7540  \n",
      "\n",
      "Fold: 2  Epoch: 26  Training loss = 2.7702  Validation loss = 2.7525  \n",
      "\n",
      "Fold: 2  Epoch: 27  Training loss = 2.7695  Validation loss = 2.7511  \n",
      "\n",
      "Fold: 2  Epoch: 28  Training loss = 2.7689  Validation loss = 2.7499  \n",
      "\n",
      "Fold: 2  Epoch: 29  Training loss = 2.7686  Validation loss = 2.7492  \n",
      "\n",
      "Fold: 2  Epoch: 30  Training loss = 2.7682  Validation loss = 2.7483  \n",
      "\n",
      "Fold: 2  Epoch: 31  Training loss = 2.7679  Validation loss = 2.7476  \n",
      "\n",
      "Fold: 2  Epoch: 32  Training loss = 2.7669  Validation loss = 2.7456  \n",
      "\n",
      "Fold: 2  Epoch: 33  Training loss = 2.7665  Validation loss = 2.7448  \n",
      "\n",
      "Fold: 2  Epoch: 34  Training loss = 2.7657  Validation loss = 2.7432  \n",
      "\n",
      "Fold: 2  Epoch: 35  Training loss = 2.7652  Validation loss = 2.7421  \n",
      "\n",
      "Fold: 2  Epoch: 36  Training loss = 2.7647  Validation loss = 2.7412  \n",
      "\n",
      "Fold: 2  Epoch: 37  Training loss = 2.7638  Validation loss = 2.7395  \n",
      "\n",
      "Fold: 2  Epoch: 38  Training loss = 2.7629  Validation loss = 2.7376  \n",
      "\n",
      "Fold: 2  Epoch: 39  Training loss = 2.7621  Validation loss = 2.7360  \n",
      "\n",
      "Fold: 2  Epoch: 40  Training loss = 2.7618  Validation loss = 2.7353  \n",
      "\n",
      "Fold: 2  Epoch: 41  Training loss = 2.7617  Validation loss = 2.7349  \n",
      "\n",
      "Fold: 2  Epoch: 42  Training loss = 2.7613  Validation loss = 2.7340  \n",
      "\n",
      "Fold: 2  Epoch: 43  Training loss = 2.7605  Validation loss = 2.7324  \n",
      "\n",
      "Fold: 2  Epoch: 44  Training loss = 2.7594  Validation loss = 2.7303  \n",
      "\n",
      "Fold: 2  Epoch: 45  Training loss = 2.7588  Validation loss = 2.7290  \n",
      "\n",
      "Fold: 2  Epoch: 46  Training loss = 2.7578  Validation loss = 2.7269  \n",
      "\n",
      "Fold: 2  Epoch: 47  Training loss = 2.7570  Validation loss = 2.7253  \n",
      "\n",
      "Fold: 2  Epoch: 48  Training loss = 2.7568  Validation loss = 2.7248  \n",
      "\n",
      "Fold: 2  Epoch: 49  Training loss = 2.7563  Validation loss = 2.7238  \n",
      "\n",
      "Fold: 2  Epoch: 50  Training loss = 2.7553  Validation loss = 2.7218  \n",
      "\n",
      "Fold: 2  Epoch: 51  Training loss = 2.7549  Validation loss = 2.7208  \n",
      "\n",
      "Fold: 2  Epoch: 52  Training loss = 2.7542  Validation loss = 2.7194  \n",
      "\n",
      "Fold: 2  Epoch: 53  Training loss = 2.7538  Validation loss = 2.7184  \n",
      "\n",
      "Fold: 2  Epoch: 54  Training loss = 2.7533  Validation loss = 2.7173  \n",
      "\n",
      "Fold: 2  Epoch: 55  Training loss = 2.7529  Validation loss = 2.7164  \n",
      "\n",
      "Fold: 2  Epoch: 56  Training loss = 2.7524  Validation loss = 2.7152  \n",
      "\n",
      "Fold: 2  Epoch: 57  Training loss = 2.7519  Validation loss = 2.7144  \n",
      "\n",
      "Fold: 2  Epoch: 58  Training loss = 2.7515  Validation loss = 2.7134  \n",
      "\n",
      "Fold: 2  Epoch: 59  Training loss = 2.7507  Validation loss = 2.7118  \n",
      "\n",
      "Fold: 2  Epoch: 60  Training loss = 2.7506  Validation loss = 2.7116  \n",
      "\n",
      "Fold: 2  Epoch: 61  Training loss = 2.7503  Validation loss = 2.7109  \n",
      "\n",
      "Fold: 2  Epoch: 62  Training loss = 2.7497  Validation loss = 2.7095  \n",
      "\n",
      "Fold: 2  Epoch: 63  Training loss = 2.7494  Validation loss = 2.7089  \n",
      "\n",
      "Fold: 2  Epoch: 64  Training loss = 2.7490  Validation loss = 2.7081  \n",
      "\n",
      "Fold: 2  Epoch: 65  Training loss = 2.7487  Validation loss = 2.7075  \n",
      "\n",
      "Fold: 2  Epoch: 66  Training loss = 2.7483  Validation loss = 2.7065  \n",
      "\n",
      "Fold: 2  Epoch: 67  Training loss = 2.7478  Validation loss = 2.7054  \n",
      "\n",
      "Fold: 2  Epoch: 68  Training loss = 2.7473  Validation loss = 2.7044  \n",
      "\n",
      "Fold: 2  Epoch: 69  Training loss = 2.7465  Validation loss = 2.7027  \n",
      "\n",
      "Fold: 2  Epoch: 70  Training loss = 2.7456  Validation loss = 2.7006  \n",
      "\n",
      "Fold: 2  Epoch: 71  Training loss = 2.7454  Validation loss = 2.7000  \n",
      "\n",
      "Fold: 2  Epoch: 72  Training loss = 2.7452  Validation loss = 2.6996  \n",
      "\n",
      "Fold: 2  Epoch: 73  Training loss = 2.7444  Validation loss = 2.6979  \n",
      "\n",
      "Fold: 2  Epoch: 74  Training loss = 2.7439  Validation loss = 2.6969  \n",
      "\n",
      "Fold: 2  Epoch: 75  Training loss = 2.7434  Validation loss = 2.6958  \n",
      "\n",
      "Fold: 2  Epoch: 76  Training loss = 2.7427  Validation loss = 2.6943  \n",
      "\n",
      "Fold: 2  Epoch: 77  Training loss = 2.7420  Validation loss = 2.6929  \n",
      "\n",
      "Fold: 2  Epoch: 78  Training loss = 2.7418  Validation loss = 2.6924  \n",
      "\n",
      "Fold: 2  Epoch: 79  Training loss = 2.7414  Validation loss = 2.6915  \n",
      "\n",
      "Fold: 2  Epoch: 80  Training loss = 2.7409  Validation loss = 2.6903  \n",
      "\n",
      "Fold: 2  Epoch: 81  Training loss = 2.7405  Validation loss = 2.6894  \n",
      "\n",
      "Fold: 2  Epoch: 82  Training loss = 2.7400  Validation loss = 2.6882  \n",
      "\n",
      "Fold: 2  Epoch: 83  Training loss = 2.7397  Validation loss = 2.6876  \n",
      "\n",
      "Fold: 2  Epoch: 84  Training loss = 2.7393  Validation loss = 2.6867  \n",
      "\n",
      "Fold: 2  Epoch: 85  Training loss = 2.7389  Validation loss = 2.6857  \n",
      "\n",
      "Fold: 2  Epoch: 86  Training loss = 2.7386  Validation loss = 2.6849  \n",
      "\n",
      "Fold: 2  Epoch: 87  Training loss = 2.7383  Validation loss = 2.6843  \n",
      "\n",
      "Fold: 2  Epoch: 88  Training loss = 2.7379  Validation loss = 2.6835  \n",
      "\n",
      "Fold: 2  Epoch: 89  Training loss = 2.7373  Validation loss = 2.6821  \n",
      "\n",
      "Fold: 2  Epoch: 90  Training loss = 2.7368  Validation loss = 2.6809  \n",
      "\n",
      "Fold: 2  Epoch: 91  Training loss = 2.7362  Validation loss = 2.6796  \n",
      "\n",
      "Fold: 2  Epoch: 92  Training loss = 2.7356  Validation loss = 2.6784  \n",
      "\n",
      "Fold: 2  Epoch: 93  Training loss = 2.7351  Validation loss = 2.6772  \n",
      "\n",
      "Fold: 2  Epoch: 94  Training loss = 2.7345  Validation loss = 2.6760  \n",
      "\n",
      "Fold: 2  Epoch: 95  Training loss = 2.7337  Validation loss = 2.6743  \n",
      "\n",
      "Fold: 2  Epoch: 96  Training loss = 2.7334  Validation loss = 2.6735  \n",
      "\n",
      "Fold: 2  Epoch: 97  Training loss = 2.7328  Validation loss = 2.6723  \n",
      "\n",
      "Fold: 2  Epoch: 98  Training loss = 2.7325  Validation loss = 2.6715  \n",
      "\n",
      "Fold: 2  Epoch: 99  Training loss = 2.7319  Validation loss = 2.6700  \n",
      "\n",
      "Fold: 2  Epoch: 100  Training loss = 2.7315  Validation loss = 2.6692  \n",
      "\n",
      "Fold: 2  Epoch: 101  Training loss = 2.7312  Validation loss = 2.6686  \n",
      "\n",
      "Fold: 2  Epoch: 102  Training loss = 2.7309  Validation loss = 2.6677  \n",
      "\n",
      "Fold: 2  Epoch: 103  Training loss = 2.7307  Validation loss = 2.6672  \n",
      "\n",
      "Fold: 2  Epoch: 104  Training loss = 2.7301  Validation loss = 2.6659  \n",
      "\n",
      "Fold: 2  Epoch: 105  Training loss = 2.7296  Validation loss = 2.6647  \n",
      "\n",
      "Fold: 2  Epoch: 106  Training loss = 2.7289  Validation loss = 2.6632  \n",
      "\n",
      "Fold: 2  Epoch: 107  Training loss = 2.7279  Validation loss = 2.6611  \n",
      "\n",
      "Fold: 2  Epoch: 108  Training loss = 2.7275  Validation loss = 2.6602  \n",
      "\n",
      "Fold: 2  Epoch: 109  Training loss = 2.7270  Validation loss = 2.6591  \n",
      "\n",
      "Fold: 2  Epoch: 110  Training loss = 2.7268  Validation loss = 2.6586  \n",
      "\n",
      "Fold: 2  Epoch: 111  Training loss = 2.7265  Validation loss = 2.6578  \n",
      "\n",
      "Fold: 2  Epoch: 112  Training loss = 2.7259  Validation loss = 2.6566  \n",
      "\n",
      "Fold: 2  Epoch: 113  Training loss = 2.7256  Validation loss = 2.6558  \n",
      "\n",
      "Fold: 2  Epoch: 114  Training loss = 2.7248  Validation loss = 2.6542  \n",
      "\n",
      "Fold: 2  Epoch: 115  Training loss = 2.7243  Validation loss = 2.6529  \n",
      "\n",
      "Fold: 2  Epoch: 116  Training loss = 2.7240  Validation loss = 2.6522  \n",
      "\n",
      "Fold: 2  Epoch: 117  Training loss = 2.7234  Validation loss = 2.6508  \n",
      "\n",
      "Fold: 2  Epoch: 118  Training loss = 2.7229  Validation loss = 2.6497  \n",
      "\n",
      "Fold: 2  Epoch: 119  Training loss = 2.7222  Validation loss = 2.6480  \n",
      "\n",
      "Fold: 2  Epoch: 120  Training loss = 2.7218  Validation loss = 2.6472  \n",
      "\n",
      "Fold: 2  Epoch: 121  Training loss = 2.7215  Validation loss = 2.6464  \n",
      "\n",
      "Fold: 2  Epoch: 122  Training loss = 2.7212  Validation loss = 2.6458  \n",
      "\n",
      "Fold: 2  Epoch: 123  Training loss = 2.7207  Validation loss = 2.6447  \n",
      "\n",
      "Fold: 2  Epoch: 124  Training loss = 2.7203  Validation loss = 2.6437  \n",
      "\n",
      "Fold: 2  Epoch: 125  Training loss = 2.7197  Validation loss = 2.6425  \n",
      "\n",
      "Fold: 2  Epoch: 126  Training loss = 2.7193  Validation loss = 2.6415  \n",
      "\n",
      "Fold: 2  Epoch: 127  Training loss = 2.7187  Validation loss = 2.6402  \n",
      "\n",
      "Fold: 2  Epoch: 128  Training loss = 2.7180  Validation loss = 2.6386  \n",
      "\n",
      "Fold: 2  Epoch: 129  Training loss = 2.7175  Validation loss = 2.6373  \n",
      "\n",
      "Fold: 2  Epoch: 130  Training loss = 2.7169  Validation loss = 2.6361  \n",
      "\n",
      "Fold: 2  Epoch: 131  Training loss = 2.7166  Validation loss = 2.6351  \n",
      "\n",
      "Fold: 2  Epoch: 132  Training loss = 2.7160  Validation loss = 2.6339  \n",
      "\n",
      "Fold: 2  Epoch: 133  Training loss = 2.7156  Validation loss = 2.6329  \n",
      "\n",
      "Fold: 2  Epoch: 134  Training loss = 2.7149  Validation loss = 2.6315  \n",
      "\n",
      "Fold: 2  Epoch: 135  Training loss = 2.7144  Validation loss = 2.6303  \n",
      "\n",
      "Fold: 2  Epoch: 136  Training loss = 2.7139  Validation loss = 2.6291  \n",
      "\n",
      "Fold: 2  Epoch: 137  Training loss = 2.7134  Validation loss = 2.6278  \n",
      "\n",
      "Fold: 2  Epoch: 138  Training loss = 2.7126  Validation loss = 2.6262  \n",
      "\n",
      "Fold: 2  Epoch: 139  Training loss = 2.7120  Validation loss = 2.6249  \n",
      "\n",
      "Fold: 2  Epoch: 140  Training loss = 2.7119  Validation loss = 2.6245  \n",
      "\n",
      "Fold: 2  Epoch: 141  Training loss = 2.7114  Validation loss = 2.6234  \n",
      "\n",
      "Fold: 2  Epoch: 142  Training loss = 2.7113  Validation loss = 2.6230  \n",
      "\n",
      "Fold: 2  Epoch: 143  Training loss = 2.7108  Validation loss = 2.6220  \n",
      "\n",
      "Fold: 2  Epoch: 144  Training loss = 2.7104  Validation loss = 2.6210  \n",
      "\n",
      "Fold: 2  Epoch: 145  Training loss = 2.7102  Validation loss = 2.6206  \n",
      "\n",
      "Fold: 2  Epoch: 146  Training loss = 2.7100  Validation loss = 2.6201  \n",
      "\n",
      "Fold: 2  Epoch: 147  Training loss = 2.7096  Validation loss = 2.6191  \n",
      "\n",
      "Fold: 2  Epoch: 148  Training loss = 2.7093  Validation loss = 2.6184  \n",
      "\n",
      "Fold: 2  Epoch: 149  Training loss = 2.7091  Validation loss = 2.6178  \n",
      "\n",
      "Fold: 2  Epoch: 150  Training loss = 2.7085  Validation loss = 2.6165  \n",
      "\n",
      "Fold: 2  Epoch: 151  Training loss = 2.7081  Validation loss = 2.6155  \n",
      "\n",
      "Fold: 2  Epoch: 152  Training loss = 2.7077  Validation loss = 2.6146  \n",
      "\n",
      "Fold: 2  Epoch: 153  Training loss = 2.7072  Validation loss = 2.6134  \n",
      "\n",
      "Fold: 2  Epoch: 154  Training loss = 2.7069  Validation loss = 2.6127  \n",
      "\n",
      "Fold: 2  Epoch: 155  Training loss = 2.7065  Validation loss = 2.6117  \n",
      "\n",
      "Fold: 2  Epoch: 156  Training loss = 2.7060  Validation loss = 2.6106  \n",
      "\n",
      "Fold: 2  Epoch: 157  Training loss = 2.7055  Validation loss = 2.6094  \n",
      "\n",
      "Fold: 2  Epoch: 158  Training loss = 2.7051  Validation loss = 2.6085  \n",
      "\n",
      "Fold: 2  Epoch: 159  Training loss = 2.7048  Validation loss = 2.6077  \n",
      "\n",
      "Fold: 2  Epoch: 160  Training loss = 2.7041  Validation loss = 2.6062  \n",
      "\n",
      "Fold: 2  Epoch: 161  Training loss = 2.7038  Validation loss = 2.6054  \n",
      "\n",
      "Fold: 2  Epoch: 162  Training loss = 2.7032  Validation loss = 2.6040  \n",
      "\n",
      "Fold: 2  Epoch: 163  Training loss = 2.7028  Validation loss = 2.6031  \n",
      "\n",
      "Fold: 2  Epoch: 164  Training loss = 2.7027  Validation loss = 2.6029  \n",
      "\n",
      "Fold: 2  Epoch: 165  Training loss = 2.7024  Validation loss = 2.6021  \n",
      "\n",
      "Fold: 2  Epoch: 166  Training loss = 2.7021  Validation loss = 2.6014  \n",
      "\n",
      "Fold: 2  Epoch: 167  Training loss = 2.7017  Validation loss = 2.6005  \n",
      "\n",
      "Fold: 2  Epoch: 168  Training loss = 2.7014  Validation loss = 2.5998  \n",
      "\n",
      "Fold: 2  Epoch: 169  Training loss = 2.7008  Validation loss = 2.5982  \n",
      "\n",
      "Fold: 2  Epoch: 170  Training loss = 2.7005  Validation loss = 2.5976  \n",
      "\n",
      "Fold: 2  Epoch: 171  Training loss = 2.7000  Validation loss = 2.5965  \n",
      "\n",
      "Fold: 2  Epoch: 172  Training loss = 2.6997  Validation loss = 2.5956  \n",
      "\n",
      "Fold: 2  Epoch: 173  Training loss = 2.6994  Validation loss = 2.5949  \n",
      "\n",
      "Fold: 2  Epoch: 174  Training loss = 2.6988  Validation loss = 2.5934  \n",
      "\n",
      "Fold: 2  Epoch: 175  Training loss = 2.6983  Validation loss = 2.5922  \n",
      "\n",
      "Fold: 2  Epoch: 176  Training loss = 2.6980  Validation loss = 2.5914  \n",
      "\n",
      "Fold: 2  Epoch: 177  Training loss = 2.6977  Validation loss = 2.5907  \n",
      "\n",
      "Fold: 2  Epoch: 178  Training loss = 2.6971  Validation loss = 2.5894  \n",
      "\n",
      "Fold: 2  Epoch: 179  Training loss = 2.6967  Validation loss = 2.5883  \n",
      "\n",
      "Fold: 2  Epoch: 180  Training loss = 2.6961  Validation loss = 2.5869  \n",
      "\n",
      "Fold: 2  Epoch: 181  Training loss = 2.6958  Validation loss = 2.5859  \n",
      "\n",
      "Fold: 2  Epoch: 182  Training loss = 2.6954  Validation loss = 2.5851  \n",
      "\n",
      "Fold: 2  Epoch: 183  Training loss = 2.6951  Validation loss = 2.5842  \n",
      "\n",
      "Fold: 2  Epoch: 184  Training loss = 2.6947  Validation loss = 2.5832  \n",
      "\n",
      "Fold: 2  Epoch: 185  Training loss = 2.6943  Validation loss = 2.5825  \n",
      "\n",
      "Fold: 2  Epoch: 186  Training loss = 2.6939  Validation loss = 2.5814  \n",
      "\n",
      "Fold: 2  Epoch: 187  Training loss = 2.6936  Validation loss = 2.5806  \n",
      "\n",
      "Fold: 2  Epoch: 188  Training loss = 2.6933  Validation loss = 2.5798  \n",
      "\n",
      "Fold: 2  Epoch: 189  Training loss = 2.6928  Validation loss = 2.5788  \n",
      "\n",
      "Fold: 2  Epoch: 190  Training loss = 2.6925  Validation loss = 2.5779  \n",
      "\n",
      "Fold: 2  Epoch: 191  Training loss = 2.6921  Validation loss = 2.5770  \n",
      "\n",
      "Fold: 2  Epoch: 192  Training loss = 2.6918  Validation loss = 2.5763  \n",
      "\n",
      "Fold: 2  Epoch: 193  Training loss = 2.6912  Validation loss = 2.5748  \n",
      "\n",
      "Fold: 2  Epoch: 194  Training loss = 2.6908  Validation loss = 2.5739  \n",
      "\n",
      "Fold: 2  Epoch: 195  Training loss = 2.6905  Validation loss = 2.5732  \n",
      "\n",
      "Fold: 2  Epoch: 196  Training loss = 2.6901  Validation loss = 2.5721  \n",
      "\n",
      "Fold: 2  Epoch: 197  Training loss = 2.6897  Validation loss = 2.5712  \n",
      "\n",
      "Fold: 2  Epoch: 198  Training loss = 2.6894  Validation loss = 2.5706  \n",
      "\n",
      "Fold: 2  Epoch: 199  Training loss = 2.6892  Validation loss = 2.5699  \n",
      "\n",
      "Fold: 2  Epoch: 200  Training loss = 2.6886  Validation loss = 2.5686  \n",
      "\n",
      "Fold: 2  Epoch: 201  Training loss = 2.6882  Validation loss = 2.5676  \n",
      "\n",
      "Fold: 2  Epoch: 202  Training loss = 2.6880  Validation loss = 2.5670  \n",
      "\n",
      "Fold: 2  Epoch: 203  Training loss = 2.6874  Validation loss = 2.5657  \n",
      "\n",
      "Fold: 2  Epoch: 204  Training loss = 2.6870  Validation loss = 2.5647  \n",
      "\n",
      "Fold: 2  Epoch: 205  Training loss = 2.6866  Validation loss = 2.5638  \n",
      "\n",
      "Fold: 2  Epoch: 206  Training loss = 2.6861  Validation loss = 2.5624  \n",
      "\n",
      "Fold: 2  Epoch: 207  Training loss = 2.6857  Validation loss = 2.5615  \n",
      "\n",
      "Fold: 2  Epoch: 208  Training loss = 2.6854  Validation loss = 2.5605  \n",
      "\n",
      "Fold: 2  Epoch: 209  Training loss = 2.6853  Validation loss = 2.5604  \n",
      "\n",
      "Fold: 2  Epoch: 210  Training loss = 2.6848  Validation loss = 2.5593  \n",
      "\n",
      "Fold: 2  Epoch: 211  Training loss = 2.6845  Validation loss = 2.5585  \n",
      "\n",
      "Fold: 2  Epoch: 212  Training loss = 2.6841  Validation loss = 2.5574  \n",
      "\n",
      "Fold: 2  Epoch: 213  Training loss = 2.6838  Validation loss = 2.5565  \n",
      "\n",
      "Fold: 2  Epoch: 214  Training loss = 2.6837  Validation loss = 2.5563  \n",
      "\n",
      "Fold: 2  Epoch: 215  Training loss = 2.6834  Validation loss = 2.5556  \n",
      "\n",
      "Fold: 2  Epoch: 216  Training loss = 2.6831  Validation loss = 2.5550  \n",
      "\n",
      "Fold: 2  Epoch: 217  Training loss = 2.6831  Validation loss = 2.5547  \n",
      "\n",
      "Fold: 2  Epoch: 218  Training loss = 2.6826  Validation loss = 2.5534  \n",
      "\n",
      "Fold: 2  Epoch: 219  Training loss = 2.6823  Validation loss = 2.5528  \n",
      "\n",
      "Fold: 2  Epoch: 220  Training loss = 2.6818  Validation loss = 2.5516  \n",
      "\n",
      "Fold: 2  Epoch: 221  Training loss = 2.6813  Validation loss = 2.5502  \n",
      "\n",
      "Fold: 2  Epoch: 222  Training loss = 2.6812  Validation loss = 2.5498  \n",
      "\n",
      "Fold: 2  Epoch: 223  Training loss = 2.6809  Validation loss = 2.5491  \n",
      "\n",
      "Fold: 2  Epoch: 224  Training loss = 2.6806  Validation loss = 2.5482  \n",
      "\n",
      "Fold: 2  Epoch: 225  Training loss = 2.6801  Validation loss = 2.5470  \n",
      "\n",
      "Fold: 2  Epoch: 226  Training loss = 2.6799  Validation loss = 2.5463  \n",
      "\n",
      "Fold: 2  Epoch: 227  Training loss = 2.6796  Validation loss = 2.5457  \n",
      "\n",
      "Fold: 2  Epoch: 228  Training loss = 2.6792  Validation loss = 2.5447  \n",
      "\n",
      "Fold: 2  Epoch: 229  Training loss = 2.6790  Validation loss = 2.5441  \n",
      "\n",
      "Fold: 2  Epoch: 230  Training loss = 2.6785  Validation loss = 2.5429  \n",
      "\n",
      "Fold: 2  Epoch: 231  Training loss = 2.6781  Validation loss = 2.5420  \n",
      "\n",
      "Fold: 2  Epoch: 232  Training loss = 2.6779  Validation loss = 2.5413  \n",
      "\n",
      "Fold: 2  Epoch: 233  Training loss = 2.6776  Validation loss = 2.5405  \n",
      "\n",
      "Fold: 2  Epoch: 234  Training loss = 2.6773  Validation loss = 2.5397  \n",
      "\n",
      "Fold: 2  Epoch: 235  Training loss = 2.6771  Validation loss = 2.5391  \n",
      "\n",
      "Fold: 2  Epoch: 236  Training loss = 2.6769  Validation loss = 2.5386  \n",
      "\n",
      "Fold: 2  Epoch: 237  Training loss = 2.6766  Validation loss = 2.5379  \n",
      "\n",
      "Fold: 2  Epoch: 238  Training loss = 2.6766  Validation loss = 2.5378  \n",
      "\n",
      "Fold: 2  Epoch: 239  Training loss = 2.6762  Validation loss = 2.5366  \n",
      "\n",
      "Fold: 2  Epoch: 240  Training loss = 2.6760  Validation loss = 2.5360  \n",
      "\n",
      "Fold: 2  Epoch: 241  Training loss = 2.6757  Validation loss = 2.5352  \n",
      "\n",
      "Fold: 2  Epoch: 242  Training loss = 2.6753  Validation loss = 2.5341  \n",
      "\n",
      "Fold: 2  Epoch: 243  Training loss = 2.6750  Validation loss = 2.5335  \n",
      "\n",
      "Fold: 2  Epoch: 244  Training loss = 2.6747  Validation loss = 2.5326  \n",
      "\n",
      "Fold: 2  Epoch: 245  Training loss = 2.6744  Validation loss = 2.5318  \n",
      "\n",
      "Fold: 2  Epoch: 246  Training loss = 2.6741  Validation loss = 2.5311  \n",
      "\n",
      "Fold: 2  Epoch: 247  Training loss = 2.6740  Validation loss = 2.5306  \n",
      "\n",
      "Fold: 2  Epoch: 248  Training loss = 2.6734  Validation loss = 2.5291  \n",
      "\n",
      "Fold: 2  Epoch: 249  Training loss = 2.6731  Validation loss = 2.5283  \n",
      "\n",
      "Fold: 2  Epoch: 250  Training loss = 2.6729  Validation loss = 2.5277  \n",
      "\n",
      "Fold: 2  Epoch: 251  Training loss = 2.6724  Validation loss = 2.5265  \n",
      "\n",
      "Fold: 2  Epoch: 252  Training loss = 2.6720  Validation loss = 2.5257  \n",
      "\n",
      "Fold: 2  Epoch: 253  Training loss = 2.6716  Validation loss = 2.5244  \n",
      "\n",
      "Fold: 2  Epoch: 254  Training loss = 2.6713  Validation loss = 2.5237  \n",
      "\n",
      "Fold: 2  Epoch: 255  Training loss = 2.6710  Validation loss = 2.5228  \n",
      "\n",
      "Fold: 2  Epoch: 256  Training loss = 2.6708  Validation loss = 2.5223  \n",
      "\n",
      "Fold: 2  Epoch: 257  Training loss = 2.6707  Validation loss = 2.5219  \n",
      "\n",
      "Fold: 2  Epoch: 258  Training loss = 2.6704  Validation loss = 2.5211  \n",
      "\n",
      "Fold: 2  Epoch: 259  Training loss = 2.6700  Validation loss = 2.5201  \n",
      "\n",
      "Fold: 2  Epoch: 260  Training loss = 2.6694  Validation loss = 2.5186  \n",
      "\n",
      "Fold: 2  Epoch: 261  Training loss = 2.6691  Validation loss = 2.5178  \n",
      "\n",
      "Fold: 2  Epoch: 262  Training loss = 2.6686  Validation loss = 2.5165  \n",
      "\n",
      "Fold: 2  Epoch: 263  Training loss = 2.6683  Validation loss = 2.5158  \n",
      "\n",
      "Fold: 2  Epoch: 264  Training loss = 2.6681  Validation loss = 2.5150  \n",
      "\n",
      "Fold: 2  Epoch: 265  Training loss = 2.6675  Validation loss = 2.5137  \n",
      "\n",
      "Fold: 2  Epoch: 266  Training loss = 2.6674  Validation loss = 2.5133  \n",
      "\n",
      "Fold: 2  Epoch: 267  Training loss = 2.6671  Validation loss = 2.5126  \n",
      "\n",
      "Fold: 2  Epoch: 268  Training loss = 2.6669  Validation loss = 2.5120  \n",
      "\n",
      "Fold: 2  Epoch: 269  Training loss = 2.6668  Validation loss = 2.5119  \n",
      "\n",
      "Fold: 2  Epoch: 270  Training loss = 2.6665  Validation loss = 2.5111  \n",
      "\n",
      "Fold: 2  Epoch: 271  Training loss = 2.6660  Validation loss = 2.5098  \n",
      "\n",
      "Fold: 2  Epoch: 272  Training loss = 2.6658  Validation loss = 2.5089  \n",
      "\n",
      "Fold: 2  Epoch: 273  Training loss = 2.6655  Validation loss = 2.5081  \n",
      "\n",
      "Fold: 2  Epoch: 274  Training loss = 2.6652  Validation loss = 2.5074  \n",
      "\n",
      "Fold: 2  Epoch: 275  Training loss = 2.6644  Validation loss = 2.5055  \n",
      "\n",
      "Fold: 2  Epoch: 276  Training loss = 2.6642  Validation loss = 2.5049  \n",
      "\n",
      "Fold: 2  Epoch: 277  Training loss = 2.6636  Validation loss = 2.5034  \n",
      "\n",
      "Fold: 2  Epoch: 278  Training loss = 2.6635  Validation loss = 2.5032  \n",
      "\n",
      "Fold: 2  Epoch: 279  Training loss = 2.6631  Validation loss = 2.5020  \n",
      "\n",
      "Fold: 2  Epoch: 280  Training loss = 2.6628  Validation loss = 2.5012  \n",
      "\n",
      "Fold: 2  Epoch: 281  Training loss = 2.6625  Validation loss = 2.5004  \n",
      "\n",
      "Fold: 2  Epoch: 282  Training loss = 2.6624  Validation loss = 2.4999  \n",
      "\n",
      "Fold: 2  Epoch: 283  Training loss = 2.6618  Validation loss = 2.4985  \n",
      "\n",
      "Fold: 2  Epoch: 284  Training loss = 2.6616  Validation loss = 2.4979  \n",
      "\n",
      "Fold: 2  Epoch: 285  Training loss = 2.6612  Validation loss = 2.4967  \n",
      "\n",
      "Fold: 2  Epoch: 286  Training loss = 2.6609  Validation loss = 2.4960  \n",
      "\n",
      "Fold: 2  Epoch: 287  Training loss = 2.6605  Validation loss = 2.4949  \n",
      "\n",
      "Fold: 2  Epoch: 288  Training loss = 2.6601  Validation loss = 2.4939  \n",
      "\n",
      "Fold: 2  Epoch: 289  Training loss = 2.6599  Validation loss = 2.4933  \n",
      "\n",
      "Fold: 2  Epoch: 290  Training loss = 2.6596  Validation loss = 2.4925  \n",
      "\n",
      "Fold: 2  Epoch: 291  Training loss = 2.6595  Validation loss = 2.4922  \n",
      "\n",
      "Fold: 2  Epoch: 292  Training loss = 2.6591  Validation loss = 2.4913  \n",
      "\n",
      "Fold: 2  Epoch: 293  Training loss = 2.6589  Validation loss = 2.4907  \n",
      "\n",
      "Fold: 2  Epoch: 294  Training loss = 2.6585  Validation loss = 2.4897  \n",
      "\n",
      "Fold: 2  Epoch: 295  Training loss = 2.6583  Validation loss = 2.4890  \n",
      "\n",
      "Fold: 2  Epoch: 296  Training loss = 2.6581  Validation loss = 2.4887  \n",
      "\n",
      "Fold: 2  Epoch: 297  Training loss = 2.6577  Validation loss = 2.4875  \n",
      "\n",
      "Fold: 2  Epoch: 298  Training loss = 2.6575  Validation loss = 2.4870  \n",
      "\n",
      "Fold: 2  Epoch: 299  Training loss = 2.6570  Validation loss = 2.4857  \n",
      "\n",
      "Fold: 2  Epoch: 300  Training loss = 2.6570  Validation loss = 2.4856  \n",
      "\n",
      "Fold: 2  Epoch: 301  Training loss = 2.6568  Validation loss = 2.4853  \n",
      "\n",
      "Fold: 2  Epoch: 302  Training loss = 2.6567  Validation loss = 2.4848  \n",
      "\n",
      "Fold: 2  Epoch: 303  Training loss = 2.6564  Validation loss = 2.4840  \n",
      "\n",
      "Fold: 2  Epoch: 304  Training loss = 2.6560  Validation loss = 2.4829  \n",
      "\n",
      "Fold: 2  Epoch: 305  Training loss = 2.6556  Validation loss = 2.4818  \n",
      "\n",
      "Fold: 2  Epoch: 306  Training loss = 2.6554  Validation loss = 2.4811  \n",
      "\n",
      "Fold: 2  Epoch: 307  Training loss = 2.6551  Validation loss = 2.4805  \n",
      "\n",
      "Fold: 2  Epoch: 308  Training loss = 2.6550  Validation loss = 2.4801  \n",
      "\n",
      "Fold: 2  Epoch: 309  Training loss = 2.6548  Validation loss = 2.4796  \n",
      "\n",
      "Fold: 2  Epoch: 310  Training loss = 2.6544  Validation loss = 2.4785  \n",
      "\n",
      "Fold: 2  Epoch: 311  Training loss = 2.6540  Validation loss = 2.4774  \n",
      "\n",
      "Fold: 2  Epoch: 312  Training loss = 2.6536  Validation loss = 2.4764  \n",
      "\n",
      "Fold: 2  Epoch: 313  Training loss = 2.6533  Validation loss = 2.4755  \n",
      "\n",
      "Fold: 2  Epoch: 314  Training loss = 2.6531  Validation loss = 2.4749  \n",
      "\n",
      "Fold: 2  Epoch: 315  Training loss = 2.6530  Validation loss = 2.4748  \n",
      "\n",
      "Fold: 2  Epoch: 316  Training loss = 2.6527  Validation loss = 2.4738  \n",
      "\n",
      "Fold: 2  Epoch: 317  Training loss = 2.6524  Validation loss = 2.4731  \n",
      "\n",
      "Fold: 2  Epoch: 318  Training loss = 2.6523  Validation loss = 2.4728  \n",
      "\n",
      "Fold: 2  Epoch: 319  Training loss = 2.6520  Validation loss = 2.4720  \n",
      "\n",
      "Fold: 2  Epoch: 320  Training loss = 2.6517  Validation loss = 2.4712  \n",
      "\n",
      "Fold: 2  Epoch: 321  Training loss = 2.6514  Validation loss = 2.4703  \n",
      "\n",
      "Fold: 2  Epoch: 322  Training loss = 2.6510  Validation loss = 2.4692  \n",
      "\n",
      "Fold: 2  Epoch: 323  Training loss = 2.6505  Validation loss = 2.4680  \n",
      "\n",
      "Fold: 2  Epoch: 324  Training loss = 2.6502  Validation loss = 2.4671  \n",
      "\n",
      "Fold: 2  Epoch: 325  Training loss = 2.6501  Validation loss = 2.4667  \n",
      "\n",
      "Fold: 2  Epoch: 326  Training loss = 2.6501  Validation loss = 2.4666  \n",
      "\n",
      "Fold: 2  Epoch: 327  Training loss = 2.6498  Validation loss = 2.4660  \n",
      "\n",
      "Fold: 2  Epoch: 328  Training loss = 2.6496  Validation loss = 2.4653  \n",
      "\n",
      "Fold: 2  Epoch: 329  Training loss = 2.6493  Validation loss = 2.4645  \n",
      "\n",
      "Fold: 2  Epoch: 330  Training loss = 2.6492  Validation loss = 2.4641  \n",
      "\n",
      "Fold: 2  Epoch: 331  Training loss = 2.6491  Validation loss = 2.4639  \n",
      "\n",
      "Fold: 2  Epoch: 332  Training loss = 2.6489  Validation loss = 2.4632  \n",
      "\n",
      "Fold: 2  Epoch: 333  Training loss = 2.6486  Validation loss = 2.4626  \n",
      "\n",
      "Fold: 2  Epoch: 334  Training loss = 2.6483  Validation loss = 2.4616  \n",
      "\n",
      "Fold: 2  Epoch: 335  Training loss = 2.6479  Validation loss = 2.4607  \n",
      "\n",
      "Fold: 2  Epoch: 336  Training loss = 2.6477  Validation loss = 2.4600  \n",
      "\n",
      "Fold: 2  Epoch: 337  Training loss = 2.6472  Validation loss = 2.4586  \n",
      "\n",
      "Fold: 2  Epoch: 338  Training loss = 2.6472  Validation loss = 2.4585  \n",
      "\n",
      "Fold: 2  Epoch: 339  Training loss = 2.6469  Validation loss = 2.4577  \n",
      "\n",
      "Fold: 2  Epoch: 340  Training loss = 2.6467  Validation loss = 2.4572  \n",
      "\n",
      "Fold: 2  Epoch: 341  Training loss = 2.6466  Validation loss = 2.4569  \n",
      "\n",
      "Fold: 2  Epoch: 342  Training loss = 2.6462  Validation loss = 2.4559  \n",
      "\n",
      "Fold: 2  Epoch: 343  Training loss = 2.6462  Validation loss = 2.4558  \n",
      "\n",
      "Fold: 2  Epoch: 344  Training loss = 2.6460  Validation loss = 2.4555  \n",
      "\n",
      "Fold: 2  Epoch: 345  Training loss = 2.6458  Validation loss = 2.4548  \n",
      "\n",
      "Fold: 2  Epoch: 346  Training loss = 2.6455  Validation loss = 2.4539  \n",
      "\n",
      "Fold: 2  Epoch: 347  Training loss = 2.6452  Validation loss = 2.4531  \n",
      "\n",
      "Fold: 2  Epoch: 348  Training loss = 2.6450  Validation loss = 2.4524  \n",
      "\n",
      "Fold: 2  Epoch: 349  Training loss = 2.6449  Validation loss = 2.4521  \n",
      "\n",
      "Fold: 2  Epoch: 350  Training loss = 2.6448  Validation loss = 2.4518  \n",
      "\n",
      "Fold: 2  Epoch: 351  Training loss = 2.6446  Validation loss = 2.4511  \n",
      "\n",
      "Fold: 2  Epoch: 352  Training loss = 2.6443  Validation loss = 2.4503  \n",
      "\n",
      "Fold: 2  Epoch: 353  Training loss = 2.6441  Validation loss = 2.4497  \n",
      "\n",
      "Fold: 2  Epoch: 354  Training loss = 2.6436  Validation loss = 2.4482  \n",
      "\n",
      "Fold: 2  Epoch: 355  Training loss = 2.6434  Validation loss = 2.4478  \n",
      "\n",
      "Fold: 2  Epoch: 356  Training loss = 2.6431  Validation loss = 2.4468  \n",
      "\n",
      "Fold: 2  Epoch: 357  Training loss = 2.6428  Validation loss = 2.4460  \n",
      "\n",
      "Fold: 2  Epoch: 358  Training loss = 2.6425  Validation loss = 2.4450  \n",
      "\n",
      "Fold: 2  Epoch: 359  Training loss = 2.6423  Validation loss = 2.4443  \n",
      "\n",
      "Fold: 2  Epoch: 360  Training loss = 2.6420  Validation loss = 2.4437  \n",
      "\n",
      "Fold: 2  Epoch: 361  Training loss = 2.6417  Validation loss = 2.4429  \n",
      "\n",
      "Fold: 2  Epoch: 362  Training loss = 2.6416  Validation loss = 2.4425  \n",
      "\n",
      "Fold: 2  Epoch: 363  Training loss = 2.6414  Validation loss = 2.4419  \n",
      "\n",
      "Fold: 2  Epoch: 364  Training loss = 2.6411  Validation loss = 2.4412  \n",
      "\n",
      "Fold: 2  Epoch: 365  Training loss = 2.6409  Validation loss = 2.4405  \n",
      "\n",
      "Fold: 2  Epoch: 366  Training loss = 2.6407  Validation loss = 2.4398  \n",
      "\n",
      "Fold: 2  Epoch: 367  Training loss = 2.6405  Validation loss = 2.4389  \n",
      "\n",
      "Fold: 2  Epoch: 368  Training loss = 2.6402  Validation loss = 2.4381  \n",
      "\n",
      "Fold: 2  Epoch: 369  Training loss = 2.6397  Validation loss = 2.4368  \n",
      "\n",
      "Fold: 2  Epoch: 370  Training loss = 2.6395  Validation loss = 2.4360  \n",
      "\n",
      "Fold: 2  Epoch: 371  Training loss = 2.6393  Validation loss = 2.4354  \n",
      "\n",
      "Fold: 2  Epoch: 372  Training loss = 2.6388  Validation loss = 2.4342  \n",
      "\n",
      "Fold: 2  Epoch: 373  Training loss = 2.6383  Validation loss = 2.4328  \n",
      "\n",
      "Fold: 2  Epoch: 374  Training loss = 2.6382  Validation loss = 2.4323  \n",
      "\n",
      "Fold: 2  Epoch: 375  Training loss = 2.6379  Validation loss = 2.4315  \n",
      "\n",
      "Fold: 2  Epoch: 376  Training loss = 2.6377  Validation loss = 2.4310  \n",
      "\n",
      "Fold: 2  Epoch: 377  Training loss = 2.6375  Validation loss = 2.4303  \n",
      "\n",
      "Fold: 2  Epoch: 378  Training loss = 2.6371  Validation loss = 2.4290  \n",
      "\n",
      "Fold: 2  Epoch: 379  Training loss = 2.6369  Validation loss = 2.4285  \n",
      "\n",
      "Fold: 2  Epoch: 380  Training loss = 2.6366  Validation loss = 2.4277  \n",
      "\n",
      "Fold: 2  Epoch: 381  Training loss = 2.6365  Validation loss = 2.4271  \n",
      "\n",
      "Fold: 2  Epoch: 382  Training loss = 2.6362  Validation loss = 2.4263  \n",
      "\n",
      "Fold: 2  Epoch: 383  Training loss = 2.6360  Validation loss = 2.4256  \n",
      "\n",
      "Fold: 2  Epoch: 384  Training loss = 2.6357  Validation loss = 2.4247  \n",
      "\n",
      "Fold: 2  Epoch: 385  Training loss = 2.6353  Validation loss = 2.4236  \n",
      "\n",
      "Fold: 2  Epoch: 386  Training loss = 2.6352  Validation loss = 2.4231  \n",
      "\n",
      "Fold: 2  Epoch: 387  Training loss = 2.6349  Validation loss = 2.4223  \n",
      "\n",
      "Fold: 2  Epoch: 388  Training loss = 2.6346  Validation loss = 2.4214  \n",
      "\n",
      "Fold: 2  Epoch: 389  Training loss = 2.6345  Validation loss = 2.4209  \n",
      "\n",
      "Fold: 2  Epoch: 390  Training loss = 2.6342  Validation loss = 2.4202  \n",
      "\n",
      "Fold: 2  Epoch: 391  Training loss = 2.6340  Validation loss = 2.4196  \n",
      "\n",
      "Fold: 2  Epoch: 392  Training loss = 2.6338  Validation loss = 2.4189  \n",
      "\n",
      "Fold: 2  Epoch: 393  Training loss = 2.6336  Validation loss = 2.4183  \n",
      "\n",
      "Fold: 2  Epoch: 394  Training loss = 2.6332  Validation loss = 2.4171  \n",
      "\n",
      "Fold: 2  Epoch: 395  Training loss = 2.6331  Validation loss = 2.4167  \n",
      "\n",
      "Fold: 2  Epoch: 396  Training loss = 2.6331  Validation loss = 2.4167  \n",
      "\n",
      "Fold: 2  Epoch: 397  Training loss = 2.6327  Validation loss = 2.4155  \n",
      "\n",
      "Fold: 2  Epoch: 398  Training loss = 2.6325  Validation loss = 2.4149  \n",
      "\n",
      "Fold: 2  Epoch: 399  Training loss = 2.6322  Validation loss = 2.4141  \n",
      "\n",
      "Fold: 2  Epoch: 400  Training loss = 2.6321  Validation loss = 2.4140  \n",
      "\n",
      "Fold: 2  Epoch: 401  Training loss = 2.6321  Validation loss = 2.4137  \n",
      "\n",
      "Fold: 2  Epoch: 402  Training loss = 2.6319  Validation loss = 2.4131  \n",
      "\n",
      "Fold: 2  Epoch: 403  Training loss = 2.6316  Validation loss = 2.4123  \n",
      "\n",
      "Fold: 2  Epoch: 404  Training loss = 2.6314  Validation loss = 2.4118  \n",
      "\n",
      "Fold: 2  Epoch: 405  Training loss = 2.6313  Validation loss = 2.4114  \n",
      "\n",
      "Fold: 2  Epoch: 406  Training loss = 2.6308  Validation loss = 2.4099  \n",
      "\n",
      "Fold: 2  Epoch: 407  Training loss = 2.6307  Validation loss = 2.4095  \n",
      "\n",
      "Fold: 2  Epoch: 408  Training loss = 2.6303  Validation loss = 2.4084  \n",
      "\n",
      "Fold: 2  Epoch: 409  Training loss = 2.6301  Validation loss = 2.4078  \n",
      "\n",
      "Fold: 2  Epoch: 410  Training loss = 2.6298  Validation loss = 2.4068  \n",
      "\n",
      "Fold: 2  Epoch: 411  Training loss = 2.6297  Validation loss = 2.4064  \n",
      "\n",
      "Fold: 2  Epoch: 412  Training loss = 2.6294  Validation loss = 2.4056  \n",
      "\n",
      "Fold: 2  Epoch: 413  Training loss = 2.6291  Validation loss = 2.4047  \n",
      "\n",
      "Fold: 2  Epoch: 414  Training loss = 2.6288  Validation loss = 2.4037  \n",
      "\n",
      "Fold: 2  Epoch: 415  Training loss = 2.6285  Validation loss = 2.4030  \n",
      "\n",
      "Fold: 2  Epoch: 416  Training loss = 2.6285  Validation loss = 2.4028  \n",
      "\n",
      "Fold: 2  Epoch: 417  Training loss = 2.6284  Validation loss = 2.4024  \n",
      "\n",
      "Fold: 2  Epoch: 418  Training loss = 2.6282  Validation loss = 2.4018  \n",
      "\n",
      "Fold: 2  Epoch: 419  Training loss = 2.6281  Validation loss = 2.4015  \n",
      "\n",
      "Fold: 2  Epoch: 420  Training loss = 2.6280  Validation loss = 2.4013  \n",
      "\n",
      "Fold: 2  Epoch: 421  Training loss = 2.6278  Validation loss = 2.4007  \n",
      "\n",
      "Fold: 2  Epoch: 422  Training loss = 2.6275  Validation loss = 2.3998  \n",
      "\n",
      "Fold: 2  Epoch: 423  Training loss = 2.6274  Validation loss = 2.3994  \n",
      "\n",
      "Fold: 2  Epoch: 424  Training loss = 2.6272  Validation loss = 2.3989  \n",
      "\n",
      "Fold: 2  Epoch: 425  Training loss = 2.6270  Validation loss = 2.3982  \n",
      "\n",
      "Fold: 2  Epoch: 426  Training loss = 2.6264  Validation loss = 2.3965  \n",
      "\n",
      "Fold: 2  Epoch: 427  Training loss = 2.6260  Validation loss = 2.3952  \n",
      "\n",
      "Fold: 2  Epoch: 428  Training loss = 2.6258  Validation loss = 2.3944  \n",
      "\n",
      "Fold: 2  Epoch: 429  Training loss = 2.6257  Validation loss = 2.3940  \n",
      "\n",
      "Fold: 2  Epoch: 430  Training loss = 2.6255  Validation loss = 2.3935  \n",
      "\n",
      "Fold: 2  Epoch: 431  Training loss = 2.6254  Validation loss = 2.3934  \n",
      "\n",
      "Fold: 2  Epoch: 432  Training loss = 2.6251  Validation loss = 2.3923  \n",
      "\n",
      "Fold: 2  Epoch: 433  Training loss = 2.6249  Validation loss = 2.3918  \n",
      "\n",
      "Fold: 2  Epoch: 434  Training loss = 2.6248  Validation loss = 2.3915  \n",
      "\n",
      "Fold: 2  Epoch: 435  Training loss = 2.6245  Validation loss = 2.3907  \n",
      "\n",
      "Fold: 2  Epoch: 436  Training loss = 2.6242  Validation loss = 2.3898  \n",
      "\n",
      "Fold: 2  Epoch: 437  Training loss = 2.6239  Validation loss = 2.3887  \n",
      "\n",
      "Fold: 2  Epoch: 438  Training loss = 2.6234  Validation loss = 2.3873  \n",
      "\n",
      "Fold: 2  Epoch: 439  Training loss = 2.6232  Validation loss = 2.3866  \n",
      "\n",
      "Fold: 2  Epoch: 440  Training loss = 2.6229  Validation loss = 2.3857  \n",
      "\n",
      "Fold: 2  Epoch: 441  Training loss = 2.6229  Validation loss = 2.3856  \n",
      "\n",
      "Fold: 2  Epoch: 442  Training loss = 2.6226  Validation loss = 2.3846  \n",
      "\n",
      "Fold: 2  Epoch: 443  Training loss = 2.6224  Validation loss = 2.3841  \n",
      "\n",
      "Fold: 2  Epoch: 444  Training loss = 2.6223  Validation loss = 2.3836  \n",
      "\n",
      "Fold: 2  Epoch: 445  Training loss = 2.6221  Validation loss = 2.3830  \n",
      "\n",
      "Fold: 2  Epoch: 446  Training loss = 2.6219  Validation loss = 2.3825  \n",
      "\n",
      "Fold: 2  Epoch: 447  Training loss = 2.6217  Validation loss = 2.3819  \n",
      "\n",
      "Fold: 2  Epoch: 448  Training loss = 2.6216  Validation loss = 2.3814  \n",
      "\n",
      "Fold: 2  Epoch: 449  Training loss = 2.6215  Validation loss = 2.3810  \n",
      "\n",
      "Fold: 2  Epoch: 450  Training loss = 2.6214  Validation loss = 2.3806  \n",
      "\n",
      "Fold: 2  Epoch: 451  Training loss = 2.6214  Validation loss = 2.3806  \n",
      "\n",
      "Fold: 2  Epoch: 452  Training loss = 2.6211  Validation loss = 2.3799  \n",
      "\n",
      "Fold: 2  Epoch: 453  Training loss = 2.6210  Validation loss = 2.3793  \n",
      "\n",
      "Fold: 2  Epoch: 454  Training loss = 2.6207  Validation loss = 2.3785  \n",
      "\n",
      "Fold: 2  Epoch: 455  Training loss = 2.6205  Validation loss = 2.3780  \n",
      "\n",
      "Fold: 2  Epoch: 456  Training loss = 2.6204  Validation loss = 2.3777  \n",
      "\n",
      "Fold: 2  Epoch: 457  Training loss = 2.6202  Validation loss = 2.3770  \n",
      "\n",
      "Fold: 2  Epoch: 458  Training loss = 2.6200  Validation loss = 2.3764  \n",
      "\n",
      "Fold: 2  Epoch: 459  Training loss = 2.6198  Validation loss = 2.3758  \n",
      "\n",
      "Fold: 2  Epoch: 460  Training loss = 2.6197  Validation loss = 2.3754  \n",
      "\n",
      "Fold: 2  Epoch: 461  Training loss = 2.6196  Validation loss = 2.3752  \n",
      "\n",
      "Fold: 2  Epoch: 462  Training loss = 2.6193  Validation loss = 2.3743  \n",
      "\n",
      "Fold: 2  Epoch: 463  Training loss = 2.6192  Validation loss = 2.3737  \n",
      "\n",
      "Fold: 2  Epoch: 464  Training loss = 2.6189  Validation loss = 2.3728  \n",
      "\n",
      "Fold: 2  Epoch: 465  Training loss = 2.6189  Validation loss = 2.3729  \n",
      "\n",
      "Fold: 2  Epoch: 466  Training loss = 2.6188  Validation loss = 2.3723  \n",
      "\n",
      "Fold: 2  Epoch: 467  Training loss = 2.6183  Validation loss = 2.3708  \n",
      "\n",
      "Fold: 2  Epoch: 468  Training loss = 2.6182  Validation loss = 2.3705  \n",
      "\n",
      "Fold: 2  Epoch: 469  Training loss = 2.6179  Validation loss = 2.3696  \n",
      "\n",
      "Fold: 2  Epoch: 470  Training loss = 2.6178  Validation loss = 2.3692  \n",
      "\n",
      "Fold: 2  Epoch: 471  Training loss = 2.6177  Validation loss = 2.3687  \n",
      "\n",
      "Fold: 2  Epoch: 472  Training loss = 2.6173  Validation loss = 2.3675  \n",
      "\n",
      "Fold: 2  Epoch: 473  Training loss = 2.6171  Validation loss = 2.3669  \n",
      "\n",
      "Fold: 2  Epoch: 474  Training loss = 2.6171  Validation loss = 2.3669  \n",
      "\n",
      "Fold: 2  Epoch: 475  Training loss = 2.6170  Validation loss = 2.3665  \n",
      "\n",
      "Fold: 2  Epoch: 476  Training loss = 2.6167  Validation loss = 2.3656  \n",
      "\n",
      "Fold: 2  Epoch: 477  Training loss = 2.6166  Validation loss = 2.3652  \n",
      "\n",
      "Fold: 2  Epoch: 478  Training loss = 2.6163  Validation loss = 2.3643  \n",
      "\n",
      "Fold: 2  Epoch: 479  Training loss = 2.6160  Validation loss = 2.3634  \n",
      "\n",
      "Fold: 2  Epoch: 480  Training loss = 2.6158  Validation loss = 2.3629  \n",
      "\n",
      "Fold: 2  Epoch: 481  Training loss = 2.6155  Validation loss = 2.3619  \n",
      "\n",
      "Fold: 2  Epoch: 482  Training loss = 2.6153  Validation loss = 2.3613  \n",
      "\n",
      "Fold: 2  Epoch: 483  Training loss = 2.6151  Validation loss = 2.3606  \n",
      "\n",
      "Fold: 2  Epoch: 484  Training loss = 2.6148  Validation loss = 2.3596  \n",
      "\n",
      "Fold: 2  Epoch: 485  Training loss = 2.6146  Validation loss = 2.3588  \n",
      "\n",
      "Fold: 2  Epoch: 486  Training loss = 2.6143  Validation loss = 2.3577  \n",
      "\n",
      "Fold: 2  Epoch: 487  Training loss = 2.6140  Validation loss = 2.3569  \n",
      "\n",
      "Fold: 2  Epoch: 488  Training loss = 2.6136  Validation loss = 2.3558  \n",
      "\n",
      "Fold: 2  Epoch: 489  Training loss = 2.6133  Validation loss = 2.3549  \n",
      "\n",
      "Fold: 2  Epoch: 490  Training loss = 2.6133  Validation loss = 2.3549  \n",
      "\n",
      "Fold: 2  Epoch: 491  Training loss = 2.6131  Validation loss = 2.3542  \n",
      "\n",
      "Fold: 2  Epoch: 492  Training loss = 2.6129  Validation loss = 2.3536  \n",
      "\n",
      "Fold: 2  Epoch: 493  Training loss = 2.6129  Validation loss = 2.3536  \n",
      "\n",
      "Fold: 2  Epoch: 494  Training loss = 2.6126  Validation loss = 2.3527  \n",
      "\n",
      "Fold: 2  Epoch: 495  Training loss = 2.6125  Validation loss = 2.3526  \n",
      "\n",
      "Fold: 2  Epoch: 496  Training loss = 2.6123  Validation loss = 2.3519  \n",
      "\n",
      "Fold: 2  Epoch: 497  Training loss = 2.6122  Validation loss = 2.3514  \n",
      "\n",
      "Fold: 2  Epoch: 498  Training loss = 2.6122  Validation loss = 2.3513  \n",
      "\n",
      "Fold: 2  Epoch: 499  Training loss = 2.6119  Validation loss = 2.3506  \n",
      "\n",
      "Fold: 2  Epoch: 500  Training loss = 2.6117  Validation loss = 2.3498  \n",
      "\n",
      "Check model:  Fold: 2  Optimal epoch: 500  \n",
      "\n",
      "Fold: 3  Epoch: 1  Training loss = 1.6004  Validation loss = 3.4961  \n",
      "\n",
      "Fold: 3  Epoch: 2  Training loss = 1.6003  Validation loss = 3.4954  \n",
      "\n",
      "Fold: 3  Epoch: 3  Training loss = 1.6002  Validation loss = 3.4950  \n",
      "\n",
      "Fold: 3  Epoch: 4  Training loss = 1.6001  Validation loss = 3.4949  \n",
      "\n",
      "Fold: 3  Epoch: 5  Training loss = 1.6001  Validation loss = 3.4947  \n",
      "\n",
      "Fold: 3  Epoch: 6  Training loss = 1.6000  Validation loss = 3.4940  \n",
      "\n",
      "Fold: 3  Epoch: 7  Training loss = 1.5999  Validation loss = 3.4935  \n",
      "\n",
      "Fold: 3  Epoch: 8  Training loss = 1.5997  Validation loss = 3.4926  \n",
      "\n",
      "Fold: 3  Epoch: 9  Training loss = 1.5996  Validation loss = 3.4921  \n",
      "\n",
      "Fold: 3  Epoch: 10  Training loss = 1.5994  Validation loss = 3.4912  \n",
      "\n",
      "Fold: 3  Epoch: 11  Training loss = 1.5993  Validation loss = 3.4908  \n",
      "\n",
      "Fold: 3  Epoch: 12  Training loss = 1.5992  Validation loss = 3.4901  \n",
      "\n",
      "Fold: 3  Epoch: 13  Training loss = 1.5990  Validation loss = 3.4893  \n",
      "\n",
      "Fold: 3  Epoch: 14  Training loss = 1.5989  Validation loss = 3.4888  \n",
      "\n",
      "Fold: 3  Epoch: 15  Training loss = 1.5990  Validation loss = 3.4891  \n",
      "\n",
      "Fold: 3  Epoch: 16  Training loss = 1.5989  Validation loss = 3.4886  \n",
      "\n",
      "Fold: 3  Epoch: 17  Training loss = 1.5987  Validation loss = 3.4879  \n",
      "\n",
      "Fold: 3  Epoch: 18  Training loss = 1.5986  Validation loss = 3.4874  \n",
      "\n",
      "Fold: 3  Epoch: 19  Training loss = 1.5985  Validation loss = 3.4870  \n",
      "\n",
      "Fold: 3  Epoch: 20  Training loss = 1.5985  Validation loss = 3.4870  \n",
      "\n",
      "Fold: 3  Epoch: 21  Training loss = 1.5983  Validation loss = 3.4860  \n",
      "\n",
      "Fold: 3  Epoch: 22  Training loss = 1.5982  Validation loss = 3.4857  \n",
      "\n",
      "Fold: 3  Epoch: 23  Training loss = 1.5981  Validation loss = 3.4849  \n",
      "\n",
      "Fold: 3  Epoch: 24  Training loss = 1.5980  Validation loss = 3.4845  \n",
      "\n",
      "Fold: 3  Epoch: 25  Training loss = 1.5978  Validation loss = 3.4836  \n",
      "\n",
      "Fold: 3  Epoch: 26  Training loss = 1.5977  Validation loss = 3.4831  \n",
      "\n",
      "Fold: 3  Epoch: 27  Training loss = 1.5976  Validation loss = 3.4830  \n",
      "\n",
      "Fold: 3  Epoch: 28  Training loss = 1.5974  Validation loss = 3.4816  \n",
      "\n",
      "Fold: 3  Epoch: 29  Training loss = 1.5973  Validation loss = 3.4812  \n",
      "\n",
      "Fold: 3  Epoch: 30  Training loss = 1.5972  Validation loss = 3.4806  \n",
      "\n",
      "Fold: 3  Epoch: 31  Training loss = 1.5972  Validation loss = 3.4807  \n",
      "\n",
      "Fold: 3  Epoch: 32  Training loss = 1.5971  Validation loss = 3.4804  \n",
      "\n",
      "Fold: 3  Epoch: 33  Training loss = 1.5970  Validation loss = 3.4800  \n",
      "\n",
      "Fold: 3  Epoch: 34  Training loss = 1.5969  Validation loss = 3.4791  \n",
      "\n",
      "Fold: 3  Epoch: 35  Training loss = 1.5968  Validation loss = 3.4786  \n",
      "\n",
      "Fold: 3  Epoch: 36  Training loss = 1.5967  Validation loss = 3.4780  \n",
      "\n",
      "Fold: 3  Epoch: 37  Training loss = 1.5966  Validation loss = 3.4777  \n",
      "\n",
      "Fold: 3  Epoch: 38  Training loss = 1.5966  Validation loss = 3.4777  \n",
      "\n",
      "Fold: 3  Epoch: 39  Training loss = 1.5965  Validation loss = 3.4774  \n",
      "\n",
      "Fold: 3  Epoch: 40  Training loss = 1.5964  Validation loss = 3.4769  \n",
      "\n",
      "Fold: 3  Epoch: 41  Training loss = 1.5962  Validation loss = 3.4759  \n",
      "\n",
      "Fold: 3  Epoch: 42  Training loss = 1.5961  Validation loss = 3.4753  \n",
      "\n",
      "Fold: 3  Epoch: 43  Training loss = 1.5960  Validation loss = 3.4747  \n",
      "\n",
      "Fold: 3  Epoch: 44  Training loss = 1.5960  Validation loss = 3.4748  \n",
      "\n",
      "Fold: 3  Epoch: 45  Training loss = 1.5959  Validation loss = 3.4741  \n",
      "\n",
      "Fold: 3  Epoch: 46  Training loss = 1.5957  Validation loss = 3.4731  \n",
      "\n",
      "Fold: 3  Epoch: 47  Training loss = 1.5956  Validation loss = 3.4727  \n",
      "\n",
      "Fold: 3  Epoch: 48  Training loss = 1.5956  Validation loss = 3.4725  \n",
      "\n",
      "Fold: 3  Epoch: 49  Training loss = 1.5955  Validation loss = 3.4724  \n",
      "\n",
      "Fold: 3  Epoch: 50  Training loss = 1.5954  Validation loss = 3.4715  \n",
      "\n",
      "Fold: 3  Epoch: 51  Training loss = 1.5954  Validation loss = 3.4716  \n",
      "\n",
      "Fold: 3  Epoch: 52  Training loss = 1.5952  Validation loss = 3.4709  \n",
      "\n",
      "Fold: 3  Epoch: 53  Training loss = 1.5951  Validation loss = 3.4702  \n",
      "\n",
      "Fold: 3  Epoch: 54  Training loss = 1.5949  Validation loss = 3.4696  \n",
      "\n",
      "Fold: 3  Epoch: 55  Training loss = 1.5948  Validation loss = 3.4692  \n",
      "\n",
      "Fold: 3  Epoch: 56  Training loss = 1.5947  Validation loss = 3.4685  \n",
      "\n",
      "Fold: 3  Epoch: 57  Training loss = 1.5945  Validation loss = 3.4680  \n",
      "\n",
      "Fold: 3  Epoch: 58  Training loss = 1.5943  Validation loss = 3.4668  \n",
      "\n",
      "Fold: 3  Epoch: 59  Training loss = 1.5942  Validation loss = 3.4661  \n",
      "\n",
      "Fold: 3  Epoch: 60  Training loss = 1.5940  Validation loss = 3.4654  \n",
      "\n",
      "Fold: 3  Epoch: 61  Training loss = 1.5939  Validation loss = 3.4648  \n",
      "\n",
      "Fold: 3  Epoch: 62  Training loss = 1.5938  Validation loss = 3.4645  \n",
      "\n",
      "Fold: 3  Epoch: 63  Training loss = 1.5937  Validation loss = 3.4641  \n",
      "\n",
      "Fold: 3  Epoch: 64  Training loss = 1.5936  Validation loss = 3.4636  \n",
      "\n",
      "Fold: 3  Epoch: 65  Training loss = 1.5936  Validation loss = 3.4634  \n",
      "\n",
      "Fold: 3  Epoch: 66  Training loss = 1.5934  Validation loss = 3.4628  \n",
      "\n",
      "Fold: 3  Epoch: 67  Training loss = 1.5933  Validation loss = 3.4626  \n",
      "\n",
      "Fold: 3  Epoch: 68  Training loss = 1.5932  Validation loss = 3.4619  \n",
      "\n",
      "Fold: 3  Epoch: 69  Training loss = 1.5931  Validation loss = 3.4613  \n",
      "\n",
      "Fold: 3  Epoch: 70  Training loss = 1.5930  Validation loss = 3.4608  \n",
      "\n",
      "Fold: 3  Epoch: 71  Training loss = 1.5928  Validation loss = 3.4597  \n",
      "\n",
      "Fold: 3  Epoch: 72  Training loss = 1.5927  Validation loss = 3.4591  \n",
      "\n",
      "Fold: 3  Epoch: 73  Training loss = 1.5926  Validation loss = 3.4584  \n",
      "\n",
      "Fold: 3  Epoch: 74  Training loss = 1.5925  Validation loss = 3.4578  \n",
      "\n",
      "Fold: 3  Epoch: 75  Training loss = 1.5923  Validation loss = 3.4566  \n",
      "\n",
      "Fold: 3  Epoch: 76  Training loss = 1.5922  Validation loss = 3.4561  \n",
      "\n",
      "Fold: 3  Epoch: 77  Training loss = 1.5921  Validation loss = 3.4557  \n",
      "\n",
      "Fold: 3  Epoch: 78  Training loss = 1.5920  Validation loss = 3.4551  \n",
      "\n",
      "Fold: 3  Epoch: 79  Training loss = 1.5919  Validation loss = 3.4550  \n",
      "\n",
      "Fold: 3  Epoch: 80  Training loss = 1.5917  Validation loss = 3.4540  \n",
      "\n",
      "Fold: 3  Epoch: 81  Training loss = 1.5917  Validation loss = 3.4537  \n",
      "\n",
      "Fold: 3  Epoch: 82  Training loss = 1.5915  Validation loss = 3.4529  \n",
      "\n",
      "Fold: 3  Epoch: 83  Training loss = 1.5914  Validation loss = 3.4524  \n",
      "\n",
      "Fold: 3  Epoch: 84  Training loss = 1.5913  Validation loss = 3.4520  \n",
      "\n",
      "Fold: 3  Epoch: 85  Training loss = 1.5913  Validation loss = 3.4522  \n",
      "\n",
      "Fold: 3  Epoch: 86  Training loss = 1.5912  Validation loss = 3.4518  \n",
      "\n",
      "Fold: 3  Epoch: 87  Training loss = 1.5911  Validation loss = 3.4516  \n",
      "\n",
      "Fold: 3  Epoch: 88  Training loss = 1.5911  Validation loss = 3.4516  \n",
      "\n",
      "Fold: 3  Epoch: 89  Training loss = 1.5910  Validation loss = 3.4516  \n",
      "\n",
      "Fold: 3  Epoch: 90  Training loss = 1.5909  Validation loss = 3.4509  \n",
      "\n",
      "Fold: 3  Epoch: 91  Training loss = 1.5909  Validation loss = 3.4506  \n",
      "\n",
      "Fold: 3  Epoch: 92  Training loss = 1.5907  Validation loss = 3.4499  \n",
      "\n",
      "Fold: 3  Epoch: 93  Training loss = 1.5906  Validation loss = 3.4493  \n",
      "\n",
      "Fold: 3  Epoch: 94  Training loss = 1.5904  Validation loss = 3.4479  \n",
      "\n",
      "Fold: 3  Epoch: 95  Training loss = 1.5903  Validation loss = 3.4475  \n",
      "\n",
      "Fold: 3  Epoch: 96  Training loss = 1.5902  Validation loss = 3.4468  \n",
      "\n",
      "Fold: 3  Epoch: 97  Training loss = 1.5901  Validation loss = 3.4464  \n",
      "\n",
      "Fold: 3  Epoch: 98  Training loss = 1.5900  Validation loss = 3.4459  \n",
      "\n",
      "Fold: 3  Epoch: 99  Training loss = 1.5900  Validation loss = 3.4459  \n",
      "\n",
      "Fold: 3  Epoch: 100  Training loss = 1.5899  Validation loss = 3.4454  \n",
      "\n",
      "Fold: 3  Epoch: 101  Training loss = 1.5898  Validation loss = 3.4448  \n",
      "\n",
      "Fold: 3  Epoch: 102  Training loss = 1.5897  Validation loss = 3.4443  \n",
      "\n",
      "Fold: 3  Epoch: 103  Training loss = 1.5897  Validation loss = 3.4446  \n",
      "\n",
      "Fold: 3  Epoch: 104  Training loss = 1.5896  Validation loss = 3.4442  \n",
      "\n",
      "Fold: 3  Epoch: 105  Training loss = 1.5895  Validation loss = 3.4435  \n",
      "\n",
      "Fold: 3  Epoch: 106  Training loss = 1.5894  Validation loss = 3.4428  \n",
      "\n",
      "Fold: 3  Epoch: 107  Training loss = 1.5893  Validation loss = 3.4426  \n",
      "\n",
      "Fold: 3  Epoch: 108  Training loss = 1.5892  Validation loss = 3.4420  \n",
      "\n",
      "Fold: 3  Epoch: 109  Training loss = 1.5891  Validation loss = 3.4422  \n",
      "\n",
      "Fold: 3  Epoch: 110  Training loss = 1.5891  Validation loss = 3.4419  \n",
      "\n",
      "Fold: 3  Epoch: 111  Training loss = 1.5891  Validation loss = 3.4420  \n",
      "\n",
      "Fold: 3  Epoch: 112  Training loss = 1.5889  Validation loss = 3.4413  \n",
      "\n",
      "Fold: 3  Epoch: 113  Training loss = 1.5889  Validation loss = 3.4407  \n",
      "\n",
      "Fold: 3  Epoch: 114  Training loss = 1.5888  Validation loss = 3.4404  \n",
      "\n",
      "Fold: 3  Epoch: 115  Training loss = 1.5888  Validation loss = 3.4402  \n",
      "\n",
      "Fold: 3  Epoch: 116  Training loss = 1.5887  Validation loss = 3.4398  \n",
      "\n",
      "Fold: 3  Epoch: 117  Training loss = 1.5885  Validation loss = 3.4388  \n",
      "\n",
      "Fold: 3  Epoch: 118  Training loss = 1.5884  Validation loss = 3.4383  \n",
      "\n",
      "Fold: 3  Epoch: 119  Training loss = 1.5884  Validation loss = 3.4383  \n",
      "\n",
      "Fold: 3  Epoch: 120  Training loss = 1.5882  Validation loss = 3.4378  \n",
      "\n",
      "Fold: 3  Epoch: 121  Training loss = 1.5882  Validation loss = 3.4377  \n",
      "\n",
      "Fold: 3  Epoch: 122  Training loss = 1.5881  Validation loss = 3.4371  \n",
      "\n",
      "Fold: 3  Epoch: 123  Training loss = 1.5881  Validation loss = 3.4369  \n",
      "\n",
      "Fold: 3  Epoch: 124  Training loss = 1.5879  Validation loss = 3.4364  \n",
      "\n",
      "Fold: 3  Epoch: 125  Training loss = 1.5879  Validation loss = 3.4363  \n",
      "\n",
      "Fold: 3  Epoch: 126  Training loss = 1.5877  Validation loss = 3.4357  \n",
      "\n",
      "Fold: 3  Epoch: 127  Training loss = 1.5876  Validation loss = 3.4350  \n",
      "\n",
      "Fold: 3  Epoch: 128  Training loss = 1.5875  Validation loss = 3.4344  \n",
      "\n",
      "Fold: 3  Epoch: 129  Training loss = 1.5874  Validation loss = 3.4339  \n",
      "\n",
      "Fold: 3  Epoch: 130  Training loss = 1.5873  Validation loss = 3.4333  \n",
      "\n",
      "Fold: 3  Epoch: 131  Training loss = 1.5872  Validation loss = 3.4328  \n",
      "\n",
      "Fold: 3  Epoch: 132  Training loss = 1.5871  Validation loss = 3.4322  \n",
      "\n",
      "Fold: 3  Epoch: 133  Training loss = 1.5870  Validation loss = 3.4317  \n",
      "\n",
      "Fold: 3  Epoch: 134  Training loss = 1.5869  Validation loss = 3.4312  \n",
      "\n",
      "Fold: 3  Epoch: 135  Training loss = 1.5868  Validation loss = 3.4307  \n",
      "\n",
      "Fold: 3  Epoch: 136  Training loss = 1.5867  Validation loss = 3.4300  \n",
      "\n",
      "Fold: 3  Epoch: 137  Training loss = 1.5866  Validation loss = 3.4294  \n",
      "\n",
      "Fold: 3  Epoch: 138  Training loss = 1.5866  Validation loss = 3.4290  \n",
      "\n",
      "Fold: 3  Epoch: 139  Training loss = 1.5864  Validation loss = 3.4285  \n",
      "\n",
      "Fold: 3  Epoch: 140  Training loss = 1.5864  Validation loss = 3.4283  \n",
      "\n",
      "Fold: 3  Epoch: 141  Training loss = 1.5863  Validation loss = 3.4277  \n",
      "\n",
      "Fold: 3  Epoch: 142  Training loss = 1.5863  Validation loss = 3.4275  \n",
      "\n",
      "Fold: 3  Epoch: 143  Training loss = 1.5862  Validation loss = 3.4274  \n",
      "\n",
      "Fold: 3  Epoch: 144  Training loss = 1.5861  Validation loss = 3.4268  \n",
      "\n",
      "Fold: 3  Epoch: 145  Training loss = 1.5860  Validation loss = 3.4268  \n",
      "\n",
      "Fold: 3  Epoch: 146  Training loss = 1.5859  Validation loss = 3.4259  \n",
      "\n",
      "Fold: 3  Epoch: 147  Training loss = 1.5858  Validation loss = 3.4254  \n",
      "\n",
      "Fold: 3  Epoch: 148  Training loss = 1.5857  Validation loss = 3.4249  \n",
      "\n",
      "Fold: 3  Epoch: 149  Training loss = 1.5856  Validation loss = 3.4245  \n",
      "\n",
      "Fold: 3  Epoch: 150  Training loss = 1.5856  Validation loss = 3.4242  \n",
      "\n",
      "Fold: 3  Epoch: 151  Training loss = 1.5855  Validation loss = 3.4235  \n",
      "\n",
      "Fold: 3  Epoch: 152  Training loss = 1.5854  Validation loss = 3.4230  \n",
      "\n",
      "Fold: 3  Epoch: 153  Training loss = 1.5853  Validation loss = 3.4227  \n",
      "\n",
      "Fold: 3  Epoch: 154  Training loss = 1.5852  Validation loss = 3.4223  \n",
      "\n",
      "Fold: 3  Epoch: 155  Training loss = 1.5852  Validation loss = 3.4223  \n",
      "\n",
      "Fold: 3  Epoch: 156  Training loss = 1.5850  Validation loss = 3.4211  \n",
      "\n",
      "Fold: 3  Epoch: 157  Training loss = 1.5850  Validation loss = 3.4210  \n",
      "\n",
      "Fold: 3  Epoch: 158  Training loss = 1.5849  Validation loss = 3.4207  \n",
      "\n",
      "Fold: 3  Epoch: 159  Training loss = 1.5847  Validation loss = 3.4197  \n",
      "\n",
      "Fold: 3  Epoch: 160  Training loss = 1.5846  Validation loss = 3.4193  \n",
      "\n",
      "Fold: 3  Epoch: 161  Training loss = 1.5846  Validation loss = 3.4192  \n",
      "\n",
      "Fold: 3  Epoch: 162  Training loss = 1.5845  Validation loss = 3.4192  \n",
      "\n",
      "Fold: 3  Epoch: 163  Training loss = 1.5845  Validation loss = 3.4189  \n",
      "\n",
      "Fold: 3  Epoch: 164  Training loss = 1.5844  Validation loss = 3.4184  \n",
      "\n",
      "Fold: 3  Epoch: 165  Training loss = 1.5843  Validation loss = 3.4178  \n",
      "\n",
      "Fold: 3  Epoch: 166  Training loss = 1.5842  Validation loss = 3.4174  \n",
      "\n",
      "Fold: 3  Epoch: 167  Training loss = 1.5841  Validation loss = 3.4171  \n",
      "\n",
      "Fold: 3  Epoch: 168  Training loss = 1.5840  Validation loss = 3.4165  \n",
      "\n",
      "Fold: 3  Epoch: 169  Training loss = 1.5839  Validation loss = 3.4154  \n",
      "\n",
      "Fold: 3  Epoch: 170  Training loss = 1.5838  Validation loss = 3.4152  \n",
      "\n",
      "Fold: 3  Epoch: 171  Training loss = 1.5837  Validation loss = 3.4147  \n",
      "\n",
      "Fold: 3  Epoch: 172  Training loss = 1.5835  Validation loss = 3.4138  \n",
      "\n",
      "Fold: 3  Epoch: 173  Training loss = 1.5835  Validation loss = 3.4139  \n",
      "\n",
      "Fold: 3  Epoch: 174  Training loss = 1.5835  Validation loss = 3.4139  \n",
      "\n",
      "Fold: 3  Epoch: 175  Training loss = 1.5834  Validation loss = 3.4139  \n",
      "\n",
      "Fold: 3  Epoch: 176  Training loss = 1.5833  Validation loss = 3.4133  \n",
      "\n",
      "Fold: 3  Epoch: 177  Training loss = 1.5832  Validation loss = 3.4127  \n",
      "\n",
      "Fold: 3  Epoch: 178  Training loss = 1.5831  Validation loss = 3.4125  \n",
      "\n",
      "Fold: 3  Epoch: 179  Training loss = 1.5830  Validation loss = 3.4117  \n",
      "\n",
      "Fold: 3  Epoch: 180  Training loss = 1.5828  Validation loss = 3.4105  \n",
      "\n",
      "Fold: 3  Epoch: 181  Training loss = 1.5828  Validation loss = 3.4105  \n",
      "\n",
      "Fold: 3  Epoch: 182  Training loss = 1.5827  Validation loss = 3.4099  \n",
      "\n",
      "Fold: 3  Epoch: 183  Training loss = 1.5826  Validation loss = 3.4097  \n",
      "\n",
      "Fold: 3  Epoch: 184  Training loss = 1.5825  Validation loss = 3.4096  \n",
      "\n",
      "Fold: 3  Epoch: 185  Training loss = 1.5825  Validation loss = 3.4091  \n",
      "\n",
      "Fold: 3  Epoch: 186  Training loss = 1.5823  Validation loss = 3.4082  \n",
      "\n",
      "Fold: 3  Epoch: 187  Training loss = 1.5823  Validation loss = 3.4079  \n",
      "\n",
      "Fold: 3  Epoch: 188  Training loss = 1.5822  Validation loss = 3.4077  \n",
      "\n",
      "Fold: 3  Epoch: 189  Training loss = 1.5821  Validation loss = 3.4073  \n",
      "\n",
      "Fold: 3  Epoch: 190  Training loss = 1.5820  Validation loss = 3.4068  \n",
      "\n",
      "Fold: 3  Epoch: 191  Training loss = 1.5820  Validation loss = 3.4069  \n",
      "\n",
      "Fold: 3  Epoch: 192  Training loss = 1.5820  Validation loss = 3.4065  \n",
      "\n",
      "Fold: 3  Epoch: 193  Training loss = 1.5819  Validation loss = 3.4061  \n",
      "\n",
      "Fold: 3  Epoch: 194  Training loss = 1.5818  Validation loss = 3.4061  \n",
      "\n",
      "Fold: 3  Epoch: 195  Training loss = 1.5818  Validation loss = 3.4058  \n",
      "\n",
      "Fold: 3  Epoch: 196  Training loss = 1.5818  Validation loss = 3.4059  \n",
      "\n",
      "Fold: 3  Epoch: 197  Training loss = 1.5817  Validation loss = 3.4057  \n",
      "\n",
      "Fold: 3  Epoch: 198  Training loss = 1.5816  Validation loss = 3.4053  \n",
      "\n",
      "Fold: 3  Epoch: 199  Training loss = 1.5815  Validation loss = 3.4049  \n",
      "\n",
      "Fold: 3  Epoch: 200  Training loss = 1.5814  Validation loss = 3.4042  \n",
      "\n",
      "Fold: 3  Epoch: 201  Training loss = 1.5812  Validation loss = 3.4036  \n",
      "\n",
      "Fold: 3  Epoch: 202  Training loss = 1.5812  Validation loss = 3.4031  \n",
      "\n",
      "Fold: 3  Epoch: 203  Training loss = 1.5811  Validation loss = 3.4026  \n",
      "\n",
      "Fold: 3  Epoch: 204  Training loss = 1.5810  Validation loss = 3.4020  \n",
      "\n",
      "Fold: 3  Epoch: 205  Training loss = 1.5809  Validation loss = 3.4018  \n",
      "\n",
      "Fold: 3  Epoch: 206  Training loss = 1.5809  Validation loss = 3.4019  \n",
      "\n",
      "Fold: 3  Epoch: 207  Training loss = 1.5808  Validation loss = 3.4015  \n",
      "\n",
      "Fold: 3  Epoch: 208  Training loss = 1.5807  Validation loss = 3.4009  \n",
      "\n",
      "Fold: 3  Epoch: 209  Training loss = 1.5806  Validation loss = 3.4002  \n",
      "\n",
      "Fold: 3  Epoch: 210  Training loss = 1.5806  Validation loss = 3.4006  \n",
      "\n",
      "Fold: 3  Epoch: 211  Training loss = 1.5805  Validation loss = 3.4001  \n",
      "\n",
      "Fold: 3  Epoch: 212  Training loss = 1.5805  Validation loss = 3.3999  \n",
      "\n",
      "Fold: 3  Epoch: 213  Training loss = 1.5803  Validation loss = 3.3995  \n",
      "\n",
      "Fold: 3  Epoch: 214  Training loss = 1.5802  Validation loss = 3.3986  \n",
      "\n",
      "Fold: 3  Epoch: 215  Training loss = 1.5800  Validation loss = 3.3980  \n",
      "\n",
      "Fold: 3  Epoch: 216  Training loss = 1.5800  Validation loss = 3.3976  \n",
      "\n",
      "Fold: 3  Epoch: 217  Training loss = 1.5799  Validation loss = 3.3976  \n",
      "\n",
      "Fold: 3  Epoch: 218  Training loss = 1.5798  Validation loss = 3.3972  \n",
      "\n",
      "Fold: 3  Epoch: 219  Training loss = 1.5797  Validation loss = 3.3964  \n",
      "\n",
      "Fold: 3  Epoch: 220  Training loss = 1.5797  Validation loss = 3.3967  \n",
      "\n",
      "Fold: 3  Epoch: 221  Training loss = 1.5795  Validation loss = 3.3961  \n",
      "\n",
      "Fold: 3  Epoch: 222  Training loss = 1.5794  Validation loss = 3.3959  \n",
      "\n",
      "Fold: 3  Epoch: 223  Training loss = 1.5793  Validation loss = 3.3951  \n",
      "\n",
      "Fold: 3  Epoch: 224  Training loss = 1.5793  Validation loss = 3.3949  \n",
      "\n",
      "Fold: 3  Epoch: 225  Training loss = 1.5792  Validation loss = 3.3946  \n",
      "\n",
      "Fold: 3  Epoch: 226  Training loss = 1.5791  Validation loss = 3.3941  \n",
      "\n",
      "Fold: 3  Epoch: 227  Training loss = 1.5790  Validation loss = 3.3935  \n",
      "\n",
      "Fold: 3  Epoch: 228  Training loss = 1.5789  Validation loss = 3.3930  \n",
      "\n",
      "Fold: 3  Epoch: 229  Training loss = 1.5788  Validation loss = 3.3922  \n",
      "\n",
      "Fold: 3  Epoch: 230  Training loss = 1.5787  Validation loss = 3.3918  \n",
      "\n",
      "Fold: 3  Epoch: 231  Training loss = 1.5786  Validation loss = 3.3913  \n",
      "\n",
      "Fold: 3  Epoch: 232  Training loss = 1.5785  Validation loss = 3.3908  \n",
      "\n",
      "Fold: 3  Epoch: 233  Training loss = 1.5784  Validation loss = 3.3903  \n",
      "\n",
      "Fold: 3  Epoch: 234  Training loss = 1.5783  Validation loss = 3.3900  \n",
      "\n",
      "Fold: 3  Epoch: 235  Training loss = 1.5782  Validation loss = 3.3896  \n",
      "\n",
      "Fold: 3  Epoch: 236  Training loss = 1.5781  Validation loss = 3.3889  \n",
      "\n",
      "Fold: 3  Epoch: 237  Training loss = 1.5781  Validation loss = 3.3884  \n",
      "\n",
      "Fold: 3  Epoch: 238  Training loss = 1.5780  Validation loss = 3.3879  \n",
      "\n",
      "Fold: 3  Epoch: 239  Training loss = 1.5779  Validation loss = 3.3877  \n",
      "\n",
      "Fold: 3  Epoch: 240  Training loss = 1.5777  Validation loss = 3.3869  \n",
      "\n",
      "Fold: 3  Epoch: 241  Training loss = 1.5776  Validation loss = 3.3864  \n",
      "\n",
      "Fold: 3  Epoch: 242  Training loss = 1.5775  Validation loss = 3.3859  \n",
      "\n",
      "Fold: 3  Epoch: 243  Training loss = 1.5774  Validation loss = 3.3854  \n",
      "\n",
      "Fold: 3  Epoch: 244  Training loss = 1.5772  Validation loss = 3.3843  \n",
      "\n",
      "Fold: 3  Epoch: 245  Training loss = 1.5771  Validation loss = 3.3839  \n",
      "\n",
      "Fold: 3  Epoch: 246  Training loss = 1.5771  Validation loss = 3.3836  \n",
      "\n",
      "Fold: 3  Epoch: 247  Training loss = 1.5771  Validation loss = 3.3840  \n",
      "\n",
      "Fold: 3  Epoch: 248  Training loss = 1.5769  Validation loss = 3.3832  \n",
      "\n",
      "Fold: 3  Epoch: 249  Training loss = 1.5768  Validation loss = 3.3828  \n",
      "\n",
      "Fold: 3  Epoch: 250  Training loss = 1.5767  Validation loss = 3.3823  \n",
      "\n",
      "Fold: 3  Epoch: 251  Training loss = 1.5767  Validation loss = 3.3821  \n",
      "\n",
      "Fold: 3  Epoch: 252  Training loss = 1.5766  Validation loss = 3.3819  \n",
      "\n",
      "Fold: 3  Epoch: 253  Training loss = 1.5766  Validation loss = 3.3820  \n",
      "\n",
      "Fold: 3  Epoch: 254  Training loss = 1.5766  Validation loss = 3.3822  \n",
      "\n",
      "Fold: 3  Epoch: 255  Training loss = 1.5765  Validation loss = 3.3819  \n",
      "\n",
      "Fold: 3  Epoch: 256  Training loss = 1.5764  Validation loss = 3.3812  \n",
      "\n",
      "Fold: 3  Epoch: 257  Training loss = 1.5763  Validation loss = 3.3809  \n",
      "\n",
      "Fold: 3  Epoch: 258  Training loss = 1.5763  Validation loss = 3.3807  \n",
      "\n",
      "Fold: 3  Epoch: 259  Training loss = 1.5762  Validation loss = 3.3802  \n",
      "\n",
      "Fold: 3  Epoch: 260  Training loss = 1.5761  Validation loss = 3.3801  \n",
      "\n",
      "Fold: 3  Epoch: 261  Training loss = 1.5761  Validation loss = 3.3801  \n",
      "\n",
      "Fold: 3  Epoch: 262  Training loss = 1.5760  Validation loss = 3.3803  \n",
      "\n",
      "Fold: 3  Epoch: 263  Training loss = 1.5760  Validation loss = 3.3802  \n",
      "\n",
      "Fold: 3  Epoch: 264  Training loss = 1.5759  Validation loss = 3.3796  \n",
      "\n",
      "Fold: 3  Epoch: 265  Training loss = 1.5758  Validation loss = 3.3790  \n",
      "\n",
      "Fold: 3  Epoch: 266  Training loss = 1.5757  Validation loss = 3.3788  \n",
      "\n",
      "Fold: 3  Epoch: 267  Training loss = 1.5756  Validation loss = 3.3780  \n",
      "\n",
      "Fold: 3  Epoch: 268  Training loss = 1.5755  Validation loss = 3.3774  \n",
      "\n",
      "Fold: 3  Epoch: 269  Training loss = 1.5753  Validation loss = 3.3765  \n",
      "\n",
      "Fold: 3  Epoch: 270  Training loss = 1.5753  Validation loss = 3.3768  \n",
      "\n",
      "Fold: 3  Epoch: 271  Training loss = 1.5753  Validation loss = 3.3766  \n",
      "\n",
      "Fold: 3  Epoch: 272  Training loss = 1.5752  Validation loss = 3.3763  \n",
      "\n",
      "Fold: 3  Epoch: 273  Training loss = 1.5752  Validation loss = 3.3765  \n",
      "\n",
      "Fold: 3  Epoch: 274  Training loss = 1.5751  Validation loss = 3.3762  \n",
      "\n",
      "Fold: 3  Epoch: 275  Training loss = 1.5751  Validation loss = 3.3763  \n",
      "\n",
      "Fold: 3  Epoch: 276  Training loss = 1.5750  Validation loss = 3.3759  \n",
      "\n",
      "Fold: 3  Epoch: 277  Training loss = 1.5749  Validation loss = 3.3751  \n",
      "\n",
      "Fold: 3  Epoch: 278  Training loss = 1.5749  Validation loss = 3.3757  \n",
      "\n",
      "Fold: 3  Epoch: 279  Training loss = 1.5749  Validation loss = 3.3757  \n",
      "\n",
      "Fold: 3  Epoch: 280  Training loss = 1.5748  Validation loss = 3.3753  \n",
      "\n",
      "Fold: 3  Epoch: 281  Training loss = 1.5747  Validation loss = 3.3751  \n",
      "\n",
      "Fold: 3  Epoch: 282  Training loss = 1.5747  Validation loss = 3.3748  \n",
      "\n",
      "Fold: 3  Epoch: 283  Training loss = 1.5746  Validation loss = 3.3746  \n",
      "\n",
      "Fold: 3  Epoch: 284  Training loss = 1.5746  Validation loss = 3.3744  \n",
      "\n",
      "Fold: 3  Epoch: 285  Training loss = 1.5745  Validation loss = 3.3743  \n",
      "\n",
      "Fold: 3  Epoch: 286  Training loss = 1.5744  Validation loss = 3.3742  \n",
      "\n",
      "Fold: 3  Epoch: 287  Training loss = 1.5742  Validation loss = 3.3729  \n",
      "\n",
      "Fold: 3  Epoch: 288  Training loss = 1.5742  Validation loss = 3.3726  \n",
      "\n",
      "Fold: 3  Epoch: 289  Training loss = 1.5740  Validation loss = 3.3716  \n",
      "\n",
      "Fold: 3  Epoch: 290  Training loss = 1.5739  Validation loss = 3.3709  \n",
      "\n",
      "Fold: 3  Epoch: 291  Training loss = 1.5738  Validation loss = 3.3703  \n",
      "\n",
      "Fold: 3  Epoch: 292  Training loss = 1.5737  Validation loss = 3.3697  \n",
      "\n",
      "Fold: 3  Epoch: 293  Training loss = 1.5736  Validation loss = 3.3693  \n",
      "\n",
      "Fold: 3  Epoch: 294  Training loss = 1.5735  Validation loss = 3.3692  \n",
      "\n",
      "Fold: 3  Epoch: 295  Training loss = 1.5735  Validation loss = 3.3689  \n",
      "\n",
      "Fold: 3  Epoch: 296  Training loss = 1.5734  Validation loss = 3.3684  \n",
      "\n",
      "Fold: 3  Epoch: 297  Training loss = 1.5733  Validation loss = 3.3680  \n",
      "\n",
      "Fold: 3  Epoch: 298  Training loss = 1.5733  Validation loss = 3.3678  \n",
      "\n",
      "Fold: 3  Epoch: 299  Training loss = 1.5732  Validation loss = 3.3673  \n",
      "\n",
      "Fold: 3  Epoch: 300  Training loss = 1.5731  Validation loss = 3.3670  \n",
      "\n",
      "Fold: 3  Epoch: 301  Training loss = 1.5729  Validation loss = 3.3659  \n",
      "\n",
      "Fold: 3  Epoch: 302  Training loss = 1.5729  Validation loss = 3.3658  \n",
      "\n",
      "Fold: 3  Epoch: 303  Training loss = 1.5728  Validation loss = 3.3657  \n",
      "\n",
      "Fold: 3  Epoch: 304  Training loss = 1.5727  Validation loss = 3.3651  \n",
      "\n",
      "Fold: 3  Epoch: 305  Training loss = 1.5727  Validation loss = 3.3650  \n",
      "\n",
      "Fold: 3  Epoch: 306  Training loss = 1.5726  Validation loss = 3.3650  \n",
      "\n",
      "Fold: 3  Epoch: 307  Training loss = 1.5726  Validation loss = 3.3649  \n",
      "\n",
      "Fold: 3  Epoch: 308  Training loss = 1.5725  Validation loss = 3.3647  \n",
      "\n",
      "Fold: 3  Epoch: 309  Training loss = 1.5724  Validation loss = 3.3641  \n",
      "\n",
      "Fold: 3  Epoch: 310  Training loss = 1.5723  Validation loss = 3.3639  \n",
      "\n",
      "Fold: 3  Epoch: 311  Training loss = 1.5723  Validation loss = 3.3638  \n",
      "\n",
      "Fold: 3  Epoch: 312  Training loss = 1.5721  Validation loss = 3.3632  \n",
      "\n",
      "Fold: 3  Epoch: 313  Training loss = 1.5721  Validation loss = 3.3633  \n",
      "\n",
      "Fold: 3  Epoch: 314  Training loss = 1.5720  Validation loss = 3.3632  \n",
      "\n",
      "Fold: 3  Epoch: 315  Training loss = 1.5719  Validation loss = 3.3627  \n",
      "\n",
      "Fold: 3  Epoch: 316  Training loss = 1.5718  Validation loss = 3.3626  \n",
      "\n",
      "Fold: 3  Epoch: 317  Training loss = 1.5718  Validation loss = 3.3625  \n",
      "\n",
      "Fold: 3  Epoch: 318  Training loss = 1.5718  Validation loss = 3.3621  \n",
      "\n",
      "Fold: 3  Epoch: 319  Training loss = 1.5717  Validation loss = 3.3618  \n",
      "\n",
      "Fold: 3  Epoch: 320  Training loss = 1.5717  Validation loss = 3.3621  \n",
      "\n",
      "Fold: 3  Epoch: 321  Training loss = 1.5716  Validation loss = 3.3620  \n",
      "\n",
      "Fold: 3  Epoch: 322  Training loss = 1.5715  Validation loss = 3.3615  \n",
      "\n",
      "Fold: 3  Epoch: 323  Training loss = 1.5715  Validation loss = 3.3615  \n",
      "\n",
      "Fold: 3  Epoch: 324  Training loss = 1.5714  Validation loss = 3.3610  \n",
      "\n",
      "Fold: 3  Epoch: 325  Training loss = 1.5714  Validation loss = 3.3608  \n",
      "\n",
      "Fold: 3  Epoch: 326  Training loss = 1.5713  Validation loss = 3.3605  \n",
      "\n",
      "Fold: 3  Epoch: 327  Training loss = 1.5712  Validation loss = 3.3605  \n",
      "\n",
      "Fold: 3  Epoch: 328  Training loss = 1.5712  Validation loss = 3.3602  \n",
      "\n",
      "Fold: 3  Epoch: 329  Training loss = 1.5711  Validation loss = 3.3600  \n",
      "\n",
      "Fold: 3  Epoch: 330  Training loss = 1.5710  Validation loss = 3.3595  \n",
      "\n",
      "Fold: 3  Epoch: 331  Training loss = 1.5710  Validation loss = 3.3598  \n",
      "\n",
      "Fold: 3  Epoch: 332  Training loss = 1.5710  Validation loss = 3.3593  \n",
      "\n",
      "Fold: 3  Epoch: 333  Training loss = 1.5708  Validation loss = 3.3587  \n",
      "\n",
      "Fold: 3  Epoch: 334  Training loss = 1.5707  Validation loss = 3.3580  \n",
      "\n",
      "Fold: 3  Epoch: 335  Training loss = 1.5705  Validation loss = 3.3573  \n",
      "\n",
      "Fold: 3  Epoch: 336  Training loss = 1.5705  Validation loss = 3.3568  \n",
      "\n",
      "Fold: 3  Epoch: 337  Training loss = 1.5704  Validation loss = 3.3563  \n",
      "\n",
      "Fold: 3  Epoch: 338  Training loss = 1.5702  Validation loss = 3.3556  \n",
      "\n",
      "Fold: 3  Epoch: 339  Training loss = 1.5701  Validation loss = 3.3550  \n",
      "\n",
      "Fold: 3  Epoch: 340  Training loss = 1.5700  Validation loss = 3.3544  \n",
      "\n",
      "Fold: 3  Epoch: 341  Training loss = 1.5700  Validation loss = 3.3542  \n",
      "\n",
      "Fold: 3  Epoch: 342  Training loss = 1.5699  Validation loss = 3.3542  \n",
      "\n",
      "Fold: 3  Epoch: 343  Training loss = 1.5698  Validation loss = 3.3539  \n",
      "\n",
      "Fold: 3  Epoch: 344  Training loss = 1.5698  Validation loss = 3.3534  \n",
      "\n",
      "Fold: 3  Epoch: 345  Training loss = 1.5698  Validation loss = 3.3535  \n",
      "\n",
      "Fold: 3  Epoch: 346  Training loss = 1.5698  Validation loss = 3.3535  \n",
      "\n",
      "Fold: 3  Epoch: 347  Training loss = 1.5696  Validation loss = 3.3530  \n",
      "\n",
      "Fold: 3  Epoch: 348  Training loss = 1.5696  Validation loss = 3.3526  \n",
      "\n",
      "Fold: 3  Epoch: 349  Training loss = 1.5695  Validation loss = 3.3523  \n",
      "\n",
      "Fold: 3  Epoch: 350  Training loss = 1.5694  Validation loss = 3.3514  \n",
      "\n",
      "Fold: 3  Epoch: 351  Training loss = 1.5693  Validation loss = 3.3510  \n",
      "\n",
      "Fold: 3  Epoch: 352  Training loss = 1.5693  Validation loss = 3.3504  \n",
      "\n",
      "Fold: 3  Epoch: 353  Training loss = 1.5692  Validation loss = 3.3498  \n",
      "\n",
      "Fold: 3  Epoch: 354  Training loss = 1.5691  Validation loss = 3.3495  \n",
      "\n",
      "Fold: 3  Epoch: 355  Training loss = 1.5690  Validation loss = 3.3496  \n",
      "\n",
      "Fold: 3  Epoch: 356  Training loss = 1.5690  Validation loss = 3.3490  \n",
      "\n",
      "Fold: 3  Epoch: 357  Training loss = 1.5690  Validation loss = 3.3492  \n",
      "\n",
      "Fold: 3  Epoch: 358  Training loss = 1.5689  Validation loss = 3.3491  \n",
      "\n",
      "Fold: 3  Epoch: 359  Training loss = 1.5688  Validation loss = 3.3490  \n",
      "\n",
      "Fold: 3  Epoch: 360  Training loss = 1.5688  Validation loss = 3.3491  \n",
      "\n",
      "Fold: 3  Epoch: 361  Training loss = 1.5687  Validation loss = 3.3489  \n",
      "\n",
      "Fold: 3  Epoch: 362  Training loss = 1.5687  Validation loss = 3.3488  \n",
      "\n",
      "Fold: 3  Epoch: 363  Training loss = 1.5686  Validation loss = 3.3483  \n",
      "\n",
      "Fold: 3  Epoch: 364  Training loss = 1.5686  Validation loss = 3.3484  \n",
      "\n",
      "Fold: 3  Epoch: 365  Training loss = 1.5685  Validation loss = 3.3482  \n",
      "\n",
      "Fold: 3  Epoch: 366  Training loss = 1.5684  Validation loss = 3.3477  \n",
      "\n",
      "Fold: 3  Epoch: 367  Training loss = 1.5683  Validation loss = 3.3476  \n",
      "\n",
      "Fold: 3  Epoch: 368  Training loss = 1.5683  Validation loss = 3.3477  \n",
      "\n",
      "Fold: 3  Epoch: 369  Training loss = 1.5683  Validation loss = 3.3478  \n",
      "\n",
      "Fold: 3  Epoch: 370  Training loss = 1.5682  Validation loss = 3.3475  \n",
      "\n",
      "Fold: 3  Epoch: 371  Training loss = 1.5681  Validation loss = 3.3468  \n",
      "\n",
      "Fold: 3  Epoch: 372  Training loss = 1.5680  Validation loss = 3.3469  \n",
      "\n",
      "Fold: 3  Epoch: 373  Training loss = 1.5679  Validation loss = 3.3462  \n",
      "\n",
      "Fold: 3  Epoch: 374  Training loss = 1.5678  Validation loss = 3.3459  \n",
      "\n",
      "Fold: 3  Epoch: 375  Training loss = 1.5677  Validation loss = 3.3457  \n",
      "\n",
      "Fold: 3  Epoch: 376  Training loss = 1.5677  Validation loss = 3.3452  \n",
      "\n",
      "Fold: 3  Epoch: 377  Training loss = 1.5676  Validation loss = 3.3447  \n",
      "\n",
      "Fold: 3  Epoch: 378  Training loss = 1.5675  Validation loss = 3.3445  \n",
      "\n",
      "Fold: 3  Epoch: 379  Training loss = 1.5675  Validation loss = 3.3443  \n",
      "\n",
      "Fold: 3  Epoch: 380  Training loss = 1.5674  Validation loss = 3.3437  \n",
      "\n",
      "Fold: 3  Epoch: 381  Training loss = 1.5673  Validation loss = 3.3432  \n",
      "\n",
      "Fold: 3  Epoch: 382  Training loss = 1.5672  Validation loss = 3.3430  \n",
      "\n",
      "Fold: 3  Epoch: 383  Training loss = 1.5672  Validation loss = 3.3429  \n",
      "\n",
      "Fold: 3  Epoch: 384  Training loss = 1.5671  Validation loss = 3.3423  \n",
      "\n",
      "Fold: 3  Epoch: 385  Training loss = 1.5670  Validation loss = 3.3421  \n",
      "\n",
      "Fold: 3  Epoch: 386  Training loss = 1.5669  Validation loss = 3.3418  \n",
      "\n",
      "Fold: 3  Epoch: 387  Training loss = 1.5669  Validation loss = 3.3419  \n",
      "\n",
      "Fold: 3  Epoch: 388  Training loss = 1.5667  Validation loss = 3.3409  \n",
      "\n",
      "Fold: 3  Epoch: 389  Training loss = 1.5666  Validation loss = 3.3403  \n",
      "\n",
      "Fold: 3  Epoch: 390  Training loss = 1.5665  Validation loss = 3.3397  \n",
      "\n",
      "Fold: 3  Epoch: 391  Training loss = 1.5665  Validation loss = 3.3398  \n",
      "\n",
      "Fold: 3  Epoch: 392  Training loss = 1.5664  Validation loss = 3.3397  \n",
      "\n",
      "Fold: 3  Epoch: 393  Training loss = 1.5663  Validation loss = 3.3394  \n",
      "\n",
      "Fold: 3  Epoch: 394  Training loss = 1.5662  Validation loss = 3.3387  \n",
      "\n",
      "Fold: 3  Epoch: 395  Training loss = 1.5662  Validation loss = 3.3388  \n",
      "\n",
      "Fold: 3  Epoch: 396  Training loss = 1.5661  Validation loss = 3.3386  \n",
      "\n",
      "Fold: 3  Epoch: 397  Training loss = 1.5659  Validation loss = 3.3378  \n",
      "\n",
      "Fold: 3  Epoch: 398  Training loss = 1.5658  Validation loss = 3.3368  \n",
      "\n",
      "Fold: 3  Epoch: 399  Training loss = 1.5657  Validation loss = 3.3365  \n",
      "\n",
      "Fold: 3  Epoch: 400  Training loss = 1.5656  Validation loss = 3.3363  \n",
      "\n",
      "Fold: 3  Epoch: 401  Training loss = 1.5656  Validation loss = 3.3356  \n",
      "\n",
      "Fold: 3  Epoch: 402  Training loss = 1.5656  Validation loss = 3.3358  \n",
      "\n",
      "Fold: 3  Epoch: 403  Training loss = 1.5655  Validation loss = 3.3359  \n",
      "\n",
      "Fold: 3  Epoch: 404  Training loss = 1.5654  Validation loss = 3.3354  \n",
      "\n",
      "Fold: 3  Epoch: 405  Training loss = 1.5654  Validation loss = 3.3348  \n",
      "\n",
      "Fold: 3  Epoch: 406  Training loss = 1.5653  Validation loss = 3.3343  \n",
      "\n",
      "Fold: 3  Epoch: 407  Training loss = 1.5652  Validation loss = 3.3342  \n",
      "\n",
      "Fold: 3  Epoch: 408  Training loss = 1.5651  Validation loss = 3.3339  \n",
      "\n",
      "Fold: 3  Epoch: 409  Training loss = 1.5652  Validation loss = 3.3342  \n",
      "\n",
      "Fold: 3  Epoch: 410  Training loss = 1.5650  Validation loss = 3.3335  \n",
      "\n",
      "Fold: 3  Epoch: 411  Training loss = 1.5650  Validation loss = 3.3335  \n",
      "\n",
      "Fold: 3  Epoch: 412  Training loss = 1.5650  Validation loss = 3.3336  \n",
      "\n",
      "Fold: 3  Epoch: 413  Training loss = 1.5648  Validation loss = 3.3330  \n",
      "\n",
      "Fold: 3  Epoch: 414  Training loss = 1.5648  Validation loss = 3.3323  \n",
      "\n",
      "Fold: 3  Epoch: 415  Training loss = 1.5647  Validation loss = 3.3317  \n",
      "\n",
      "Fold: 3  Epoch: 416  Training loss = 1.5646  Validation loss = 3.3311  \n",
      "\n",
      "Fold: 3  Epoch: 417  Training loss = 1.5645  Validation loss = 3.3300  \n",
      "\n",
      "Fold: 3  Epoch: 418  Training loss = 1.5645  Validation loss = 3.3303  \n",
      "\n",
      "Fold: 3  Epoch: 419  Training loss = 1.5643  Validation loss = 3.3298  \n",
      "\n",
      "Fold: 3  Epoch: 420  Training loss = 1.5643  Validation loss = 3.3293  \n",
      "\n",
      "Fold: 3  Epoch: 421  Training loss = 1.5642  Validation loss = 3.3287  \n",
      "\n",
      "Fold: 3  Epoch: 422  Training loss = 1.5641  Validation loss = 3.3283  \n",
      "\n",
      "Fold: 3  Epoch: 423  Training loss = 1.5641  Validation loss = 3.3280  \n",
      "\n",
      "Fold: 3  Epoch: 424  Training loss = 1.5640  Validation loss = 3.3277  \n",
      "\n",
      "Fold: 3  Epoch: 425  Training loss = 1.5640  Validation loss = 3.3276  \n",
      "\n",
      "Fold: 3  Epoch: 426  Training loss = 1.5640  Validation loss = 3.3277  \n",
      "\n",
      "Fold: 3  Epoch: 427  Training loss = 1.5639  Validation loss = 3.3272  \n",
      "\n",
      "Fold: 3  Epoch: 428  Training loss = 1.5639  Validation loss = 3.3267  \n",
      "\n",
      "Fold: 3  Epoch: 429  Training loss = 1.5638  Validation loss = 3.3262  \n",
      "\n",
      "Fold: 3  Epoch: 430  Training loss = 1.5637  Validation loss = 3.3261  \n",
      "\n",
      "Fold: 3  Epoch: 431  Training loss = 1.5637  Validation loss = 3.3261  \n",
      "\n",
      "Fold: 3  Epoch: 432  Training loss = 1.5636  Validation loss = 3.3255  \n",
      "\n",
      "Fold: 3  Epoch: 433  Training loss = 1.5636  Validation loss = 3.3251  \n",
      "\n",
      "Fold: 3  Epoch: 434  Training loss = 1.5636  Validation loss = 3.3250  \n",
      "\n",
      "Fold: 3  Epoch: 435  Training loss = 1.5635  Validation loss = 3.3245  \n",
      "\n",
      "Fold: 3  Epoch: 436  Training loss = 1.5634  Validation loss = 3.3243  \n",
      "\n",
      "Fold: 3  Epoch: 437  Training loss = 1.5634  Validation loss = 3.3238  \n",
      "\n",
      "Fold: 3  Epoch: 438  Training loss = 1.5633  Validation loss = 3.3234  \n",
      "\n",
      "Fold: 3  Epoch: 439  Training loss = 1.5633  Validation loss = 3.3232  \n",
      "\n",
      "Fold: 3  Epoch: 440  Training loss = 1.5633  Validation loss = 3.3232  \n",
      "\n",
      "Fold: 3  Epoch: 441  Training loss = 1.5632  Validation loss = 3.3229  \n",
      "\n",
      "Fold: 3  Epoch: 442  Training loss = 1.5631  Validation loss = 3.3222  \n",
      "\n",
      "Fold: 3  Epoch: 443  Training loss = 1.5631  Validation loss = 3.3222  \n",
      "\n",
      "Fold: 3  Epoch: 444  Training loss = 1.5631  Validation loss = 3.3220  \n",
      "\n",
      "Fold: 3  Epoch: 445  Training loss = 1.5630  Validation loss = 3.3213  \n",
      "\n",
      "Fold: 3  Epoch: 446  Training loss = 1.5629  Validation loss = 3.3213  \n",
      "\n",
      "Fold: 3  Epoch: 447  Training loss = 1.5629  Validation loss = 3.3212  \n",
      "\n",
      "Fold: 3  Epoch: 448  Training loss = 1.5628  Validation loss = 3.3208  \n",
      "\n",
      "Fold: 3  Epoch: 449  Training loss = 1.5627  Validation loss = 3.3204  \n",
      "\n",
      "Fold: 3  Epoch: 450  Training loss = 1.5627  Validation loss = 3.3201  \n",
      "\n",
      "Fold: 3  Epoch: 451  Training loss = 1.5625  Validation loss = 3.3193  \n",
      "\n",
      "Fold: 3  Epoch: 452  Training loss = 1.5625  Validation loss = 3.3188  \n",
      "\n",
      "Fold: 3  Epoch: 453  Training loss = 1.5624  Validation loss = 3.3185  \n",
      "\n",
      "Fold: 3  Epoch: 454  Training loss = 1.5624  Validation loss = 3.3183  \n",
      "\n",
      "Fold: 3  Epoch: 455  Training loss = 1.5623  Validation loss = 3.3178  \n",
      "\n",
      "Fold: 3  Epoch: 456  Training loss = 1.5623  Validation loss = 3.3177  \n",
      "\n",
      "Fold: 3  Epoch: 457  Training loss = 1.5623  Validation loss = 3.3178  \n",
      "\n",
      "Fold: 3  Epoch: 458  Training loss = 1.5621  Validation loss = 3.3171  \n",
      "\n",
      "Fold: 3  Epoch: 459  Training loss = 1.5621  Validation loss = 3.3166  \n",
      "\n",
      "Fold: 3  Epoch: 460  Training loss = 1.5620  Validation loss = 3.3162  \n",
      "\n",
      "Fold: 3  Epoch: 461  Training loss = 1.5620  Validation loss = 3.3158  \n",
      "\n",
      "Fold: 3  Epoch: 462  Training loss = 1.5619  Validation loss = 3.3155  \n",
      "\n",
      "Fold: 3  Epoch: 463  Training loss = 1.5618  Validation loss = 3.3152  \n",
      "\n",
      "Fold: 3  Epoch: 464  Training loss = 1.5617  Validation loss = 3.3145  \n",
      "\n",
      "Fold: 3  Epoch: 465  Training loss = 1.5616  Validation loss = 3.3139  \n",
      "\n",
      "Fold: 3  Epoch: 466  Training loss = 1.5616  Validation loss = 3.3138  \n",
      "\n",
      "Fold: 3  Epoch: 467  Training loss = 1.5615  Validation loss = 3.3134  \n",
      "\n",
      "Fold: 3  Epoch: 468  Training loss = 1.5615  Validation loss = 3.3128  \n",
      "\n",
      "Fold: 3  Epoch: 469  Training loss = 1.5614  Validation loss = 3.3123  \n",
      "\n",
      "Fold: 3  Epoch: 470  Training loss = 1.5613  Validation loss = 3.3124  \n",
      "\n",
      "Fold: 3  Epoch: 471  Training loss = 1.5613  Validation loss = 3.3121  \n",
      "\n",
      "Fold: 3  Epoch: 472  Training loss = 1.5612  Validation loss = 3.3120  \n",
      "\n",
      "Fold: 3  Epoch: 473  Training loss = 1.5612  Validation loss = 3.3123  \n",
      "\n",
      "Fold: 3  Epoch: 474  Training loss = 1.5611  Validation loss = 3.3116  \n",
      "\n",
      "Fold: 3  Epoch: 475  Training loss = 1.5610  Validation loss = 3.3108  \n",
      "\n",
      "Fold: 3  Epoch: 476  Training loss = 1.5609  Validation loss = 3.3102  \n",
      "\n",
      "Fold: 3  Epoch: 477  Training loss = 1.5609  Validation loss = 3.3100  \n",
      "\n",
      "Fold: 3  Epoch: 478  Training loss = 1.5608  Validation loss = 3.3096  \n",
      "\n",
      "Fold: 3  Epoch: 479  Training loss = 1.5607  Validation loss = 3.3090  \n",
      "\n",
      "Fold: 3  Epoch: 480  Training loss = 1.5606  Validation loss = 3.3084  \n",
      "\n",
      "Fold: 3  Epoch: 481  Training loss = 1.5605  Validation loss = 3.3078  \n",
      "\n",
      "Fold: 3  Epoch: 482  Training loss = 1.5605  Validation loss = 3.3074  \n",
      "\n",
      "Fold: 3  Epoch: 483  Training loss = 1.5604  Validation loss = 3.3077  \n",
      "\n",
      "Fold: 3  Epoch: 484  Training loss = 1.5604  Validation loss = 3.3077  \n",
      "\n",
      "Fold: 3  Epoch: 485  Training loss = 1.5604  Validation loss = 3.3071  \n",
      "\n",
      "Fold: 3  Epoch: 486  Training loss = 1.5603  Validation loss = 3.3068  \n",
      "\n",
      "Fold: 3  Epoch: 487  Training loss = 1.5603  Validation loss = 3.3064  \n",
      "\n",
      "Fold: 3  Epoch: 488  Training loss = 1.5602  Validation loss = 3.3060  \n",
      "\n",
      "Fold: 3  Epoch: 489  Training loss = 1.5601  Validation loss = 3.3053  \n",
      "\n",
      "Fold: 3  Epoch: 490  Training loss = 1.5600  Validation loss = 3.3050  \n",
      "\n",
      "Fold: 3  Epoch: 491  Training loss = 1.5600  Validation loss = 3.3050  \n",
      "\n",
      "Fold: 3  Epoch: 492  Training loss = 1.5600  Validation loss = 3.3050  \n",
      "\n",
      "Fold: 3  Epoch: 493  Training loss = 1.5599  Validation loss = 3.3047  \n",
      "\n",
      "Fold: 3  Epoch: 494  Training loss = 1.5598  Validation loss = 3.3044  \n",
      "\n",
      "Fold: 3  Epoch: 495  Training loss = 1.5598  Validation loss = 3.3047  \n",
      "\n",
      "Fold: 3  Epoch: 496  Training loss = 1.5598  Validation loss = 3.3043  \n",
      "\n",
      "Fold: 3  Epoch: 497  Training loss = 1.5597  Validation loss = 3.3037  \n",
      "\n",
      "Fold: 3  Epoch: 498  Training loss = 1.5597  Validation loss = 3.3033  \n",
      "\n",
      "Fold: 3  Epoch: 499  Training loss = 1.5595  Validation loss = 3.3021  \n",
      "\n",
      "Fold: 3  Epoch: 500  Training loss = 1.5594  Validation loss = 3.3018  \n",
      "\n",
      "Check model:  Fold: 3  Optimal epoch: 500  \n",
      "\n",
      "Fold: 4  Epoch: 1  Training loss = 1.6547  Validation loss = 4.4407  \n",
      "\n",
      "Fold: 4  Epoch: 2  Training loss = 1.6545  Validation loss = 4.4400  \n",
      "\n",
      "Fold: 4  Epoch: 3  Training loss = 1.6543  Validation loss = 4.4391  \n",
      "\n",
      "Fold: 4  Epoch: 4  Training loss = 1.6542  Validation loss = 4.4381  \n",
      "\n",
      "Fold: 4  Epoch: 5  Training loss = 1.6540  Validation loss = 4.4374  \n",
      "\n",
      "Fold: 4  Epoch: 6  Training loss = 1.6539  Validation loss = 4.4368  \n",
      "\n",
      "Fold: 4  Epoch: 7  Training loss = 1.6537  Validation loss = 4.4358  \n",
      "\n",
      "Fold: 4  Epoch: 8  Training loss = 1.6536  Validation loss = 4.4352  \n",
      "\n",
      "Fold: 4  Epoch: 9  Training loss = 1.6535  Validation loss = 4.4346  \n",
      "\n",
      "Fold: 4  Epoch: 10  Training loss = 1.6534  Validation loss = 4.4346  \n",
      "\n",
      "Fold: 4  Epoch: 11  Training loss = 1.6533  Validation loss = 4.4340  \n",
      "\n",
      "Fold: 4  Epoch: 12  Training loss = 1.6532  Validation loss = 4.4337  \n",
      "\n",
      "Fold: 4  Epoch: 13  Training loss = 1.6531  Validation loss = 4.4329  \n",
      "\n",
      "Fold: 4  Epoch: 14  Training loss = 1.6529  Validation loss = 4.4324  \n",
      "\n",
      "Fold: 4  Epoch: 15  Training loss = 1.6529  Validation loss = 4.4321  \n",
      "\n",
      "Fold: 4  Epoch: 16  Training loss = 1.6528  Validation loss = 4.4315  \n",
      "\n",
      "Fold: 4  Epoch: 17  Training loss = 1.6526  Validation loss = 4.4304  \n",
      "\n",
      "Fold: 4  Epoch: 18  Training loss = 1.6525  Validation loss = 4.4299  \n",
      "\n",
      "Fold: 4  Epoch: 19  Training loss = 1.6523  Validation loss = 4.4294  \n",
      "\n",
      "Fold: 4  Epoch: 20  Training loss = 1.6522  Validation loss = 4.4290  \n",
      "\n",
      "Fold: 4  Epoch: 21  Training loss = 1.6521  Validation loss = 4.4285  \n",
      "\n",
      "Fold: 4  Epoch: 22  Training loss = 1.6520  Validation loss = 4.4282  \n",
      "\n",
      "Fold: 4  Epoch: 23  Training loss = 1.6518  Validation loss = 4.4272  \n",
      "\n",
      "Fold: 4  Epoch: 24  Training loss = 1.6518  Validation loss = 4.4270  \n",
      "\n",
      "Fold: 4  Epoch: 25  Training loss = 1.6517  Validation loss = 4.4268  \n",
      "\n",
      "Fold: 4  Epoch: 26  Training loss = 1.6516  Validation loss = 4.4264  \n",
      "\n",
      "Fold: 4  Epoch: 27  Training loss = 1.6515  Validation loss = 4.4257  \n",
      "\n",
      "Fold: 4  Epoch: 28  Training loss = 1.6514  Validation loss = 4.4255  \n",
      "\n",
      "Fold: 4  Epoch: 29  Training loss = 1.6513  Validation loss = 4.4251  \n",
      "\n",
      "Fold: 4  Epoch: 30  Training loss = 1.6512  Validation loss = 4.4247  \n",
      "\n",
      "Fold: 4  Epoch: 31  Training loss = 1.6511  Validation loss = 4.4241  \n",
      "\n",
      "Fold: 4  Epoch: 32  Training loss = 1.6510  Validation loss = 4.4238  \n",
      "\n",
      "Fold: 4  Epoch: 33  Training loss = 1.6509  Validation loss = 4.4229  \n",
      "\n",
      "Fold: 4  Epoch: 34  Training loss = 1.6508  Validation loss = 4.4227  \n",
      "\n",
      "Fold: 4  Epoch: 35  Training loss = 1.6507  Validation loss = 4.4218  \n",
      "\n",
      "Fold: 4  Epoch: 36  Training loss = 1.6506  Validation loss = 4.4212  \n",
      "\n",
      "Fold: 4  Epoch: 37  Training loss = 1.6505  Validation loss = 4.4212  \n",
      "\n",
      "Fold: 4  Epoch: 38  Training loss = 1.6505  Validation loss = 4.4211  \n",
      "\n",
      "Fold: 4  Epoch: 39  Training loss = 1.6503  Validation loss = 4.4199  \n",
      "\n",
      "Fold: 4  Epoch: 40  Training loss = 1.6501  Validation loss = 4.4191  \n",
      "\n",
      "Fold: 4  Epoch: 41  Training loss = 1.6500  Validation loss = 4.4188  \n",
      "\n",
      "Fold: 4  Epoch: 42  Training loss = 1.6499  Validation loss = 4.4178  \n",
      "\n",
      "Fold: 4  Epoch: 43  Training loss = 1.6498  Validation loss = 4.4175  \n",
      "\n",
      "Fold: 4  Epoch: 44  Training loss = 1.6497  Validation loss = 4.4166  \n",
      "\n",
      "Fold: 4  Epoch: 45  Training loss = 1.6495  Validation loss = 4.4160  \n",
      "\n",
      "Fold: 4  Epoch: 46  Training loss = 1.6495  Validation loss = 4.4160  \n",
      "\n",
      "Fold: 4  Epoch: 47  Training loss = 1.6494  Validation loss = 4.4153  \n",
      "\n",
      "Fold: 4  Epoch: 48  Training loss = 1.6493  Validation loss = 4.4151  \n",
      "\n",
      "Fold: 4  Epoch: 49  Training loss = 1.6493  Validation loss = 4.4152  \n",
      "\n",
      "Fold: 4  Epoch: 50  Training loss = 1.6491  Validation loss = 4.4144  \n",
      "\n",
      "Fold: 4  Epoch: 51  Training loss = 1.6490  Validation loss = 4.4137  \n",
      "\n",
      "Fold: 4  Epoch: 52  Training loss = 1.6489  Validation loss = 4.4133  \n",
      "\n",
      "Fold: 4  Epoch: 53  Training loss = 1.6488  Validation loss = 4.4130  \n",
      "\n",
      "Fold: 4  Epoch: 54  Training loss = 1.6487  Validation loss = 4.4121  \n",
      "\n",
      "Fold: 4  Epoch: 55  Training loss = 1.6486  Validation loss = 4.4115  \n",
      "\n",
      "Fold: 4  Epoch: 56  Training loss = 1.6485  Validation loss = 4.4109  \n",
      "\n",
      "Fold: 4  Epoch: 57  Training loss = 1.6483  Validation loss = 4.4103  \n",
      "\n",
      "Fold: 4  Epoch: 58  Training loss = 1.6483  Validation loss = 4.4101  \n",
      "\n",
      "Fold: 4  Epoch: 59  Training loss = 1.6481  Validation loss = 4.4095  \n",
      "\n",
      "Fold: 4  Epoch: 60  Training loss = 1.6480  Validation loss = 4.4090  \n",
      "\n",
      "Fold: 4  Epoch: 61  Training loss = 1.6478  Validation loss = 4.4081  \n",
      "\n",
      "Fold: 4  Epoch: 62  Training loss = 1.6477  Validation loss = 4.4073  \n",
      "\n",
      "Fold: 4  Epoch: 63  Training loss = 1.6476  Validation loss = 4.4068  \n",
      "\n",
      "Fold: 4  Epoch: 64  Training loss = 1.6475  Validation loss = 4.4063  \n",
      "\n",
      "Fold: 4  Epoch: 65  Training loss = 1.6474  Validation loss = 4.4062  \n",
      "\n",
      "Fold: 4  Epoch: 66  Training loss = 1.6474  Validation loss = 4.4063  \n",
      "\n",
      "Fold: 4  Epoch: 67  Training loss = 1.6472  Validation loss = 4.4051  \n",
      "\n",
      "Fold: 4  Epoch: 68  Training loss = 1.6470  Validation loss = 4.4044  \n",
      "\n",
      "Fold: 4  Epoch: 69  Training loss = 1.6468  Validation loss = 4.4030  \n",
      "\n",
      "Fold: 4  Epoch: 70  Training loss = 1.6467  Validation loss = 4.4028  \n",
      "\n",
      "Fold: 4  Epoch: 71  Training loss = 1.6466  Validation loss = 4.4026  \n",
      "\n",
      "Fold: 4  Epoch: 72  Training loss = 1.6465  Validation loss = 4.4019  \n",
      "\n",
      "Fold: 4  Epoch: 73  Training loss = 1.6464  Validation loss = 4.4012  \n",
      "\n",
      "Fold: 4  Epoch: 74  Training loss = 1.6462  Validation loss = 4.4002  \n",
      "\n",
      "Fold: 4  Epoch: 75  Training loss = 1.6460  Validation loss = 4.3994  \n",
      "\n",
      "Fold: 4  Epoch: 76  Training loss = 1.6459  Validation loss = 4.3985  \n",
      "\n",
      "Fold: 4  Epoch: 77  Training loss = 1.6457  Validation loss = 4.3976  \n",
      "\n",
      "Fold: 4  Epoch: 78  Training loss = 1.6456  Validation loss = 4.3972  \n",
      "\n",
      "Fold: 4  Epoch: 79  Training loss = 1.6456  Validation loss = 4.3969  \n",
      "\n",
      "Fold: 4  Epoch: 80  Training loss = 1.6455  Validation loss = 4.3969  \n",
      "\n",
      "Fold: 4  Epoch: 81  Training loss = 1.6454  Validation loss = 4.3963  \n",
      "\n",
      "Fold: 4  Epoch: 82  Training loss = 1.6453  Validation loss = 4.3956  \n",
      "\n",
      "Fold: 4  Epoch: 83  Training loss = 1.6452  Validation loss = 4.3956  \n",
      "\n",
      "Fold: 4  Epoch: 84  Training loss = 1.6452  Validation loss = 4.3954  \n",
      "\n",
      "Fold: 4  Epoch: 85  Training loss = 1.6450  Validation loss = 4.3946  \n",
      "\n",
      "Fold: 4  Epoch: 86  Training loss = 1.6450  Validation loss = 4.3944  \n",
      "\n",
      "Fold: 4  Epoch: 87  Training loss = 1.6448  Validation loss = 4.3938  \n",
      "\n",
      "Fold: 4  Epoch: 88  Training loss = 1.6447  Validation loss = 4.3932  \n",
      "\n",
      "Fold: 4  Epoch: 89  Training loss = 1.6446  Validation loss = 4.3928  \n",
      "\n",
      "Fold: 4  Epoch: 90  Training loss = 1.6446  Validation loss = 4.3928  \n",
      "\n",
      "Fold: 4  Epoch: 91  Training loss = 1.6445  Validation loss = 4.3928  \n",
      "\n",
      "Fold: 4  Epoch: 92  Training loss = 1.6444  Validation loss = 4.3920  \n",
      "\n",
      "Fold: 4  Epoch: 93  Training loss = 1.6443  Validation loss = 4.3915  \n",
      "\n",
      "Fold: 4  Epoch: 94  Training loss = 1.6442  Validation loss = 4.3912  \n",
      "\n",
      "Fold: 4  Epoch: 95  Training loss = 1.6441  Validation loss = 4.3908  \n",
      "\n",
      "Fold: 4  Epoch: 96  Training loss = 1.6441  Validation loss = 4.3908  \n",
      "\n",
      "Fold: 4  Epoch: 97  Training loss = 1.6440  Validation loss = 4.3904  \n",
      "\n",
      "Fold: 4  Epoch: 98  Training loss = 1.6438  Validation loss = 4.3894  \n",
      "\n",
      "Fold: 4  Epoch: 99  Training loss = 1.6437  Validation loss = 4.3888  \n",
      "\n",
      "Fold: 4  Epoch: 100  Training loss = 1.6436  Validation loss = 4.3885  \n",
      "\n",
      "Fold: 4  Epoch: 101  Training loss = 1.6435  Validation loss = 4.3882  \n",
      "\n",
      "Fold: 4  Epoch: 102  Training loss = 1.6433  Validation loss = 4.3871  \n",
      "\n",
      "Fold: 4  Epoch: 103  Training loss = 1.6431  Validation loss = 4.3857  \n",
      "\n",
      "Fold: 4  Epoch: 104  Training loss = 1.6430  Validation loss = 4.3855  \n",
      "\n",
      "Fold: 4  Epoch: 105  Training loss = 1.6428  Validation loss = 4.3846  \n",
      "\n",
      "Fold: 4  Epoch: 106  Training loss = 1.6427  Validation loss = 4.3841  \n",
      "\n",
      "Fold: 4  Epoch: 107  Training loss = 1.6426  Validation loss = 4.3834  \n",
      "\n",
      "Fold: 4  Epoch: 108  Training loss = 1.6424  Validation loss = 4.3824  \n",
      "\n",
      "Fold: 4  Epoch: 109  Training loss = 1.6423  Validation loss = 4.3819  \n",
      "\n",
      "Fold: 4  Epoch: 110  Training loss = 1.6422  Validation loss = 4.3816  \n",
      "\n",
      "Fold: 4  Epoch: 111  Training loss = 1.6421  Validation loss = 4.3808  \n",
      "\n",
      "Fold: 4  Epoch: 112  Training loss = 1.6420  Validation loss = 4.3805  \n",
      "\n",
      "Fold: 4  Epoch: 113  Training loss = 1.6419  Validation loss = 4.3799  \n",
      "\n",
      "Fold: 4  Epoch: 114  Training loss = 1.6418  Validation loss = 4.3794  \n",
      "\n",
      "Fold: 4  Epoch: 115  Training loss = 1.6417  Validation loss = 4.3791  \n",
      "\n",
      "Fold: 4  Epoch: 116  Training loss = 1.6417  Validation loss = 4.3787  \n",
      "\n",
      "Fold: 4  Epoch: 117  Training loss = 1.6416  Validation loss = 4.3785  \n",
      "\n",
      "Fold: 4  Epoch: 118  Training loss = 1.6415  Validation loss = 4.3785  \n",
      "\n",
      "Fold: 4  Epoch: 119  Training loss = 1.6416  Validation loss = 4.3789  \n",
      "\n",
      "Fold: 4  Epoch: 120  Training loss = 1.6413  Validation loss = 4.3778  \n",
      "\n",
      "Fold: 4  Epoch: 121  Training loss = 1.6413  Validation loss = 4.3775  \n",
      "\n",
      "Fold: 4  Epoch: 122  Training loss = 1.6412  Validation loss = 4.3775  \n",
      "\n",
      "Fold: 4  Epoch: 123  Training loss = 1.6411  Validation loss = 4.3770  \n",
      "\n",
      "Fold: 4  Epoch: 124  Training loss = 1.6409  Validation loss = 4.3761  \n",
      "\n",
      "Fold: 4  Epoch: 125  Training loss = 1.6409  Validation loss = 4.3763  \n",
      "\n",
      "Fold: 4  Epoch: 126  Training loss = 1.6409  Validation loss = 4.3763  \n",
      "\n",
      "Fold: 4  Epoch: 127  Training loss = 1.6407  Validation loss = 4.3752  \n",
      "\n",
      "Fold: 4  Epoch: 128  Training loss = 1.6406  Validation loss = 4.3746  \n",
      "\n",
      "Fold: 4  Epoch: 129  Training loss = 1.6404  Validation loss = 4.3737  \n",
      "\n",
      "Fold: 4  Epoch: 130  Training loss = 1.6404  Validation loss = 4.3734  \n",
      "\n",
      "Fold: 4  Epoch: 131  Training loss = 1.6403  Validation loss = 4.3734  \n",
      "\n",
      "Fold: 4  Epoch: 132  Training loss = 1.6401  Validation loss = 4.3724  \n",
      "\n",
      "Fold: 4  Epoch: 133  Training loss = 1.6399  Validation loss = 4.3714  \n",
      "\n",
      "Fold: 4  Epoch: 134  Training loss = 1.6399  Validation loss = 4.3714  \n",
      "\n",
      "Fold: 4  Epoch: 135  Training loss = 1.6398  Validation loss = 4.3710  \n",
      "\n",
      "Fold: 4  Epoch: 136  Training loss = 1.6397  Validation loss = 4.3705  \n",
      "\n",
      "Fold: 4  Epoch: 137  Training loss = 1.6395  Validation loss = 4.3696  \n",
      "\n",
      "Fold: 4  Epoch: 138  Training loss = 1.6395  Validation loss = 4.3696  \n",
      "\n",
      "Fold: 4  Epoch: 139  Training loss = 1.6393  Validation loss = 4.3688  \n",
      "\n",
      "Fold: 4  Epoch: 140  Training loss = 1.6392  Validation loss = 4.3681  \n",
      "\n",
      "Fold: 4  Epoch: 141  Training loss = 1.6391  Validation loss = 4.3675  \n",
      "\n",
      "Fold: 4  Epoch: 142  Training loss = 1.6390  Validation loss = 4.3667  \n",
      "\n",
      "Fold: 4  Epoch: 143  Training loss = 1.6389  Validation loss = 4.3661  \n",
      "\n",
      "Fold: 4  Epoch: 144  Training loss = 1.6388  Validation loss = 4.3657  \n",
      "\n",
      "Fold: 4  Epoch: 145  Training loss = 1.6386  Validation loss = 4.3648  \n",
      "\n",
      "Fold: 4  Epoch: 146  Training loss = 1.6385  Validation loss = 4.3645  \n",
      "\n",
      "Fold: 4  Epoch: 147  Training loss = 1.6384  Validation loss = 4.3638  \n",
      "\n",
      "Fold: 4  Epoch: 148  Training loss = 1.6384  Validation loss = 4.3638  \n",
      "\n",
      "Fold: 4  Epoch: 149  Training loss = 1.6383  Validation loss = 4.3636  \n",
      "\n",
      "Fold: 4  Epoch: 150  Training loss = 1.6382  Validation loss = 4.3629  \n",
      "\n",
      "Fold: 4  Epoch: 151  Training loss = 1.6381  Validation loss = 4.3628  \n",
      "\n",
      "Fold: 4  Epoch: 152  Training loss = 1.6380  Validation loss = 4.3624  \n",
      "\n",
      "Fold: 4  Epoch: 153  Training loss = 1.6380  Validation loss = 4.3621  \n",
      "\n",
      "Fold: 4  Epoch: 154  Training loss = 1.6379  Validation loss = 4.3617  \n",
      "\n",
      "Fold: 4  Epoch: 155  Training loss = 1.6378  Validation loss = 4.3612  \n",
      "\n",
      "Fold: 4  Epoch: 156  Training loss = 1.6376  Validation loss = 4.3600  \n",
      "\n",
      "Fold: 4  Epoch: 157  Training loss = 1.6375  Validation loss = 4.3597  \n",
      "\n",
      "Fold: 4  Epoch: 158  Training loss = 1.6374  Validation loss = 4.3590  \n",
      "\n",
      "Fold: 4  Epoch: 159  Training loss = 1.6373  Validation loss = 4.3588  \n",
      "\n",
      "Fold: 4  Epoch: 160  Training loss = 1.6372  Validation loss = 4.3583  \n",
      "\n",
      "Fold: 4  Epoch: 161  Training loss = 1.6371  Validation loss = 4.3576  \n",
      "\n",
      "Fold: 4  Epoch: 162  Training loss = 1.6368  Validation loss = 4.3562  \n",
      "\n",
      "Fold: 4  Epoch: 163  Training loss = 1.6368  Validation loss = 4.3558  \n",
      "\n",
      "Fold: 4  Epoch: 164  Training loss = 1.6367  Validation loss = 4.3552  \n",
      "\n",
      "Fold: 4  Epoch: 165  Training loss = 1.6366  Validation loss = 4.3548  \n",
      "\n",
      "Fold: 4  Epoch: 166  Training loss = 1.6364  Validation loss = 4.3543  \n",
      "\n",
      "Fold: 4  Epoch: 167  Training loss = 1.6363  Validation loss = 4.3537  \n",
      "\n",
      "Fold: 4  Epoch: 168  Training loss = 1.6361  Validation loss = 4.3527  \n",
      "\n",
      "Fold: 4  Epoch: 169  Training loss = 1.6361  Validation loss = 4.3526  \n",
      "\n",
      "Fold: 4  Epoch: 170  Training loss = 1.6360  Validation loss = 4.3522  \n",
      "\n",
      "Fold: 4  Epoch: 171  Training loss = 1.6359  Validation loss = 4.3517  \n",
      "\n",
      "Fold: 4  Epoch: 172  Training loss = 1.6359  Validation loss = 4.3518  \n",
      "\n",
      "Fold: 4  Epoch: 173  Training loss = 1.6358  Validation loss = 4.3514  \n",
      "\n",
      "Fold: 4  Epoch: 174  Training loss = 1.6357  Validation loss = 4.3512  \n",
      "\n",
      "Fold: 4  Epoch: 175  Training loss = 1.6356  Validation loss = 4.3505  \n",
      "\n",
      "Fold: 4  Epoch: 176  Training loss = 1.6355  Validation loss = 4.3499  \n",
      "\n",
      "Fold: 4  Epoch: 177  Training loss = 1.6354  Validation loss = 4.3495  \n",
      "\n",
      "Fold: 4  Epoch: 178  Training loss = 1.6353  Validation loss = 4.3490  \n",
      "\n",
      "Fold: 4  Epoch: 179  Training loss = 1.6352  Validation loss = 4.3485  \n",
      "\n",
      "Fold: 4  Epoch: 180  Training loss = 1.6351  Validation loss = 4.3483  \n",
      "\n",
      "Fold: 4  Epoch: 181  Training loss = 1.6350  Validation loss = 4.3473  \n",
      "\n",
      "Fold: 4  Epoch: 182  Training loss = 1.6349  Validation loss = 4.3470  \n",
      "\n",
      "Fold: 4  Epoch: 183  Training loss = 1.6348  Validation loss = 4.3464  \n",
      "\n",
      "Fold: 4  Epoch: 184  Training loss = 1.6347  Validation loss = 4.3454  \n",
      "\n",
      "Fold: 4  Epoch: 185  Training loss = 1.6346  Validation loss = 4.3449  \n",
      "\n",
      "Fold: 4  Epoch: 186  Training loss = 1.6345  Validation loss = 4.3448  \n",
      "\n",
      "Fold: 4  Epoch: 187  Training loss = 1.6344  Validation loss = 4.3444  \n",
      "\n",
      "Fold: 4  Epoch: 188  Training loss = 1.6343  Validation loss = 4.3436  \n",
      "\n",
      "Fold: 4  Epoch: 189  Training loss = 1.6342  Validation loss = 4.3433  \n",
      "\n",
      "Fold: 4  Epoch: 190  Training loss = 1.6341  Validation loss = 4.3428  \n",
      "\n",
      "Fold: 4  Epoch: 191  Training loss = 1.6340  Validation loss = 4.3423  \n",
      "\n",
      "Fold: 4  Epoch: 192  Training loss = 1.6339  Validation loss = 4.3418  \n",
      "\n",
      "Fold: 4  Epoch: 193  Training loss = 1.6339  Validation loss = 4.3413  \n",
      "\n",
      "Fold: 4  Epoch: 194  Training loss = 1.6338  Validation loss = 4.3413  \n",
      "\n",
      "Fold: 4  Epoch: 195  Training loss = 1.6338  Validation loss = 4.3410  \n",
      "\n",
      "Fold: 4  Epoch: 196  Training loss = 1.6337  Validation loss = 4.3408  \n",
      "\n",
      "Fold: 4  Epoch: 197  Training loss = 1.6336  Validation loss = 4.3405  \n",
      "\n",
      "Fold: 4  Epoch: 198  Training loss = 1.6335  Validation loss = 4.3401  \n",
      "\n",
      "Fold: 4  Epoch: 199  Training loss = 1.6334  Validation loss = 4.3399  \n",
      "\n",
      "Fold: 4  Epoch: 200  Training loss = 1.6334  Validation loss = 4.3396  \n",
      "\n",
      "Fold: 4  Epoch: 201  Training loss = 1.6333  Validation loss = 4.3391  \n",
      "\n",
      "Fold: 4  Epoch: 202  Training loss = 1.6332  Validation loss = 4.3390  \n",
      "\n",
      "Fold: 4  Epoch: 203  Training loss = 1.6331  Validation loss = 4.3384  \n",
      "\n",
      "Fold: 4  Epoch: 204  Training loss = 1.6330  Validation loss = 4.3380  \n",
      "\n",
      "Fold: 4  Epoch: 205  Training loss = 1.6328  Validation loss = 4.3370  \n",
      "\n",
      "Fold: 4  Epoch: 206  Training loss = 1.6327  Validation loss = 4.3365  \n",
      "\n",
      "Fold: 4  Epoch: 207  Training loss = 1.6326  Validation loss = 4.3361  \n",
      "\n",
      "Fold: 4  Epoch: 208  Training loss = 1.6325  Validation loss = 4.3358  \n",
      "\n",
      "Fold: 4  Epoch: 209  Training loss = 1.6324  Validation loss = 4.3353  \n",
      "\n",
      "Fold: 4  Epoch: 210  Training loss = 1.6323  Validation loss = 4.3352  \n",
      "\n",
      "Fold: 4  Epoch: 211  Training loss = 1.6322  Validation loss = 4.3345  \n",
      "\n",
      "Fold: 4  Epoch: 212  Training loss = 1.6321  Validation loss = 4.3342  \n",
      "\n",
      "Fold: 4  Epoch: 213  Training loss = 1.6320  Validation loss = 4.3338  \n",
      "\n",
      "Fold: 4  Epoch: 214  Training loss = 1.6320  Validation loss = 4.3336  \n",
      "\n",
      "Fold: 4  Epoch: 215  Training loss = 1.6318  Validation loss = 4.3329  \n",
      "\n",
      "Fold: 4  Epoch: 216  Training loss = 1.6317  Validation loss = 4.3320  \n",
      "\n",
      "Fold: 4  Epoch: 217  Training loss = 1.6316  Validation loss = 4.3314  \n",
      "\n",
      "Fold: 4  Epoch: 218  Training loss = 1.6314  Validation loss = 4.3309  \n",
      "\n",
      "Fold: 4  Epoch: 219  Training loss = 1.6313  Validation loss = 4.3305  \n",
      "\n",
      "Fold: 4  Epoch: 220  Training loss = 1.6312  Validation loss = 4.3296  \n",
      "\n",
      "Fold: 4  Epoch: 221  Training loss = 1.6311  Validation loss = 4.3290  \n",
      "\n",
      "Fold: 4  Epoch: 222  Training loss = 1.6310  Validation loss = 4.3285  \n",
      "\n",
      "Fold: 4  Epoch: 223  Training loss = 1.6309  Validation loss = 4.3281  \n",
      "\n",
      "Fold: 4  Epoch: 224  Training loss = 1.6308  Validation loss = 4.3273  \n",
      "\n",
      "Fold: 4  Epoch: 225  Training loss = 1.6308  Validation loss = 4.3276  \n",
      "\n",
      "Fold: 4  Epoch: 226  Training loss = 1.6307  Validation loss = 4.3275  \n",
      "\n",
      "Fold: 4  Epoch: 227  Training loss = 1.6306  Validation loss = 4.3270  \n",
      "\n",
      "Fold: 4  Epoch: 228  Training loss = 1.6305  Validation loss = 4.3266  \n",
      "\n",
      "Fold: 4  Epoch: 229  Training loss = 1.6304  Validation loss = 4.3260  \n",
      "\n",
      "Fold: 4  Epoch: 230  Training loss = 1.6304  Validation loss = 4.3261  \n",
      "\n",
      "Fold: 4  Epoch: 231  Training loss = 1.6302  Validation loss = 4.3254  \n",
      "\n",
      "Fold: 4  Epoch: 232  Training loss = 1.6302  Validation loss = 4.3251  \n",
      "\n",
      "Fold: 4  Epoch: 233  Training loss = 1.6301  Validation loss = 4.3247  \n",
      "\n",
      "Fold: 4  Epoch: 234  Training loss = 1.6301  Validation loss = 4.3247  \n",
      "\n",
      "Fold: 4  Epoch: 235  Training loss = 1.6299  Validation loss = 4.3239  \n",
      "\n",
      "Fold: 4  Epoch: 236  Training loss = 1.6298  Validation loss = 4.3236  \n",
      "\n",
      "Fold: 4  Epoch: 237  Training loss = 1.6298  Validation loss = 4.3234  \n",
      "\n",
      "Fold: 4  Epoch: 238  Training loss = 1.6297  Validation loss = 4.3231  \n",
      "\n",
      "Fold: 4  Epoch: 239  Training loss = 1.6296  Validation loss = 4.3229  \n",
      "\n",
      "Fold: 4  Epoch: 240  Training loss = 1.6294  Validation loss = 4.3219  \n",
      "\n",
      "Fold: 4  Epoch: 241  Training loss = 1.6293  Validation loss = 4.3212  \n",
      "\n",
      "Fold: 4  Epoch: 242  Training loss = 1.6293  Validation loss = 4.3210  \n",
      "\n",
      "Fold: 4  Epoch: 243  Training loss = 1.6292  Validation loss = 4.3210  \n",
      "\n",
      "Fold: 4  Epoch: 244  Training loss = 1.6291  Validation loss = 4.3202  \n",
      "\n",
      "Fold: 4  Epoch: 245  Training loss = 1.6290  Validation loss = 4.3197  \n",
      "\n",
      "Fold: 4  Epoch: 246  Training loss = 1.6288  Validation loss = 4.3189  \n",
      "\n",
      "Fold: 4  Epoch: 247  Training loss = 1.6287  Validation loss = 4.3181  \n",
      "\n",
      "Fold: 4  Epoch: 248  Training loss = 1.6287  Validation loss = 4.3180  \n",
      "\n",
      "Fold: 4  Epoch: 249  Training loss = 1.6286  Validation loss = 4.3179  \n",
      "\n",
      "Fold: 4  Epoch: 250  Training loss = 1.6285  Validation loss = 4.3174  \n",
      "\n",
      "Fold: 4  Epoch: 251  Training loss = 1.6284  Validation loss = 4.3166  \n",
      "\n",
      "Fold: 4  Epoch: 252  Training loss = 1.6283  Validation loss = 4.3159  \n",
      "\n",
      "Fold: 4  Epoch: 253  Training loss = 1.6281  Validation loss = 4.3154  \n",
      "\n",
      "Fold: 4  Epoch: 254  Training loss = 1.6281  Validation loss = 4.3149  \n",
      "\n",
      "Fold: 4  Epoch: 255  Training loss = 1.6279  Validation loss = 4.3143  \n",
      "\n",
      "Fold: 4  Epoch: 256  Training loss = 1.6278  Validation loss = 4.3135  \n",
      "\n",
      "Fold: 4  Epoch: 257  Training loss = 1.6277  Validation loss = 4.3133  \n",
      "\n",
      "Fold: 4  Epoch: 258  Training loss = 1.6276  Validation loss = 4.3129  \n",
      "\n",
      "Fold: 4  Epoch: 259  Training loss = 1.6276  Validation loss = 4.3127  \n",
      "\n",
      "Fold: 4  Epoch: 260  Training loss = 1.6275  Validation loss = 4.3126  \n",
      "\n",
      "Fold: 4  Epoch: 261  Training loss = 1.6274  Validation loss = 4.3118  \n",
      "\n",
      "Fold: 4  Epoch: 262  Training loss = 1.6273  Validation loss = 4.3113  \n",
      "\n",
      "Fold: 4  Epoch: 263  Training loss = 1.6273  Validation loss = 4.3113  \n",
      "\n",
      "Fold: 4  Epoch: 264  Training loss = 1.6272  Validation loss = 4.3109  \n",
      "\n",
      "Fold: 4  Epoch: 265  Training loss = 1.6270  Validation loss = 4.3105  \n",
      "\n",
      "Fold: 4  Epoch: 266  Training loss = 1.6269  Validation loss = 4.3100  \n",
      "\n",
      "Fold: 4  Epoch: 267  Training loss = 1.6269  Validation loss = 4.3102  \n",
      "\n",
      "Fold: 4  Epoch: 268  Training loss = 1.6268  Validation loss = 4.3095  \n",
      "\n",
      "Fold: 4  Epoch: 269  Training loss = 1.6266  Validation loss = 4.3085  \n",
      "\n",
      "Fold: 4  Epoch: 270  Training loss = 1.6265  Validation loss = 4.3077  \n",
      "\n",
      "Fold: 4  Epoch: 271  Training loss = 1.6264  Validation loss = 4.3069  \n",
      "\n",
      "Fold: 4  Epoch: 272  Training loss = 1.6263  Validation loss = 4.3062  \n",
      "\n",
      "Fold: 4  Epoch: 273  Training loss = 1.6262  Validation loss = 4.3063  \n",
      "\n",
      "Fold: 4  Epoch: 274  Training loss = 1.6261  Validation loss = 4.3056  \n",
      "\n",
      "Fold: 4  Epoch: 275  Training loss = 1.6260  Validation loss = 4.3051  \n",
      "\n",
      "Fold: 4  Epoch: 276  Training loss = 1.6260  Validation loss = 4.3050  \n",
      "\n",
      "Fold: 4  Epoch: 277  Training loss = 1.6258  Validation loss = 4.3043  \n",
      "\n",
      "Fold: 4  Epoch: 278  Training loss = 1.6258  Validation loss = 4.3041  \n",
      "\n",
      "Fold: 4  Epoch: 279  Training loss = 1.6257  Validation loss = 4.3039  \n",
      "\n",
      "Fold: 4  Epoch: 280  Training loss = 1.6256  Validation loss = 4.3034  \n",
      "\n",
      "Fold: 4  Epoch: 281  Training loss = 1.6255  Validation loss = 4.3029  \n",
      "\n",
      "Fold: 4  Epoch: 282  Training loss = 1.6254  Validation loss = 4.3023  \n",
      "\n",
      "Fold: 4  Epoch: 283  Training loss = 1.6253  Validation loss = 4.3017  \n",
      "\n",
      "Fold: 4  Epoch: 284  Training loss = 1.6252  Validation loss = 4.3012  \n",
      "\n",
      "Fold: 4  Epoch: 285  Training loss = 1.6250  Validation loss = 4.3005  \n",
      "\n",
      "Fold: 4  Epoch: 286  Training loss = 1.6249  Validation loss = 4.2999  \n",
      "\n",
      "Fold: 4  Epoch: 287  Training loss = 1.6249  Validation loss = 4.2997  \n",
      "\n",
      "Fold: 4  Epoch: 288  Training loss = 1.6247  Validation loss = 4.2986  \n",
      "\n",
      "Fold: 4  Epoch: 289  Training loss = 1.6246  Validation loss = 4.2981  \n",
      "\n",
      "Fold: 4  Epoch: 290  Training loss = 1.6245  Validation loss = 4.2979  \n",
      "\n",
      "Fold: 4  Epoch: 291  Training loss = 1.6244  Validation loss = 4.2977  \n",
      "\n",
      "Fold: 4  Epoch: 292  Training loss = 1.6243  Validation loss = 4.2969  \n",
      "\n",
      "Fold: 4  Epoch: 293  Training loss = 1.6242  Validation loss = 4.2969  \n",
      "\n",
      "Fold: 4  Epoch: 294  Training loss = 1.6241  Validation loss = 4.2968  \n",
      "\n",
      "Fold: 4  Epoch: 295  Training loss = 1.6241  Validation loss = 4.2968  \n",
      "\n",
      "Fold: 4  Epoch: 296  Training loss = 1.6240  Validation loss = 4.2964  \n",
      "\n",
      "Fold: 4  Epoch: 297  Training loss = 1.6239  Validation loss = 4.2962  \n",
      "\n",
      "Fold: 4  Epoch: 298  Training loss = 1.6238  Validation loss = 4.2957  \n",
      "\n",
      "Fold: 4  Epoch: 299  Training loss = 1.6237  Validation loss = 4.2955  \n",
      "\n",
      "Fold: 4  Epoch: 300  Training loss = 1.6236  Validation loss = 4.2952  \n",
      "\n",
      "Fold: 4  Epoch: 301  Training loss = 1.6235  Validation loss = 4.2949  \n",
      "\n",
      "Fold: 4  Epoch: 302  Training loss = 1.6235  Validation loss = 4.2949  \n",
      "\n",
      "Fold: 4  Epoch: 303  Training loss = 1.6234  Validation loss = 4.2941  \n",
      "\n",
      "Fold: 4  Epoch: 304  Training loss = 1.6233  Validation loss = 4.2937  \n",
      "\n",
      "Fold: 4  Epoch: 305  Training loss = 1.6232  Validation loss = 4.2929  \n",
      "\n",
      "Fold: 4  Epoch: 306  Training loss = 1.6231  Validation loss = 4.2930  \n",
      "\n",
      "Fold: 4  Epoch: 307  Training loss = 1.6231  Validation loss = 4.2932  \n",
      "\n",
      "Fold: 4  Epoch: 308  Training loss = 1.6231  Validation loss = 4.2928  \n",
      "\n",
      "Fold: 4  Epoch: 309  Training loss = 1.6230  Validation loss = 4.2926  \n",
      "\n",
      "Fold: 4  Epoch: 310  Training loss = 1.6229  Validation loss = 4.2920  \n",
      "\n",
      "Fold: 4  Epoch: 311  Training loss = 1.6228  Validation loss = 4.2921  \n",
      "\n",
      "Fold: 4  Epoch: 312  Training loss = 1.6227  Validation loss = 4.2913  \n",
      "\n",
      "Fold: 4  Epoch: 313  Training loss = 1.6226  Validation loss = 4.2911  \n",
      "\n",
      "Fold: 4  Epoch: 314  Training loss = 1.6225  Validation loss = 4.2907  \n",
      "\n",
      "Fold: 4  Epoch: 315  Training loss = 1.6224  Validation loss = 4.2901  \n",
      "\n",
      "Fold: 4  Epoch: 316  Training loss = 1.6223  Validation loss = 4.2896  \n",
      "\n",
      "Fold: 4  Epoch: 317  Training loss = 1.6223  Validation loss = 4.2896  \n",
      "\n",
      "Fold: 4  Epoch: 318  Training loss = 1.6222  Validation loss = 4.2888  \n",
      "\n",
      "Fold: 4  Epoch: 319  Training loss = 1.6220  Validation loss = 4.2880  \n",
      "\n",
      "Fold: 4  Epoch: 320  Training loss = 1.6219  Validation loss = 4.2875  \n",
      "\n",
      "Fold: 4  Epoch: 321  Training loss = 1.6218  Validation loss = 4.2871  \n",
      "\n",
      "Fold: 4  Epoch: 322  Training loss = 1.6218  Validation loss = 4.2869  \n",
      "\n",
      "Fold: 4  Epoch: 323  Training loss = 1.6216  Validation loss = 4.2859  \n",
      "\n",
      "Fold: 4  Epoch: 324  Training loss = 1.6216  Validation loss = 4.2860  \n",
      "\n",
      "Fold: 4  Epoch: 325  Training loss = 1.6214  Validation loss = 4.2853  \n",
      "\n",
      "Fold: 4  Epoch: 326  Training loss = 1.6213  Validation loss = 4.2849  \n",
      "\n",
      "Fold: 4  Epoch: 327  Training loss = 1.6212  Validation loss = 4.2846  \n",
      "\n",
      "Fold: 4  Epoch: 328  Training loss = 1.6211  Validation loss = 4.2837  \n",
      "\n",
      "Fold: 4  Epoch: 329  Training loss = 1.6210  Validation loss = 4.2835  \n",
      "\n",
      "Fold: 4  Epoch: 330  Training loss = 1.6209  Validation loss = 4.2825  \n",
      "\n",
      "Fold: 4  Epoch: 331  Training loss = 1.6208  Validation loss = 4.2818  \n",
      "\n",
      "Fold: 4  Epoch: 332  Training loss = 1.6207  Validation loss = 4.2815  \n",
      "\n",
      "Fold: 4  Epoch: 333  Training loss = 1.6206  Validation loss = 4.2811  \n",
      "\n",
      "Fold: 4  Epoch: 334  Training loss = 1.6205  Validation loss = 4.2805  \n",
      "\n",
      "Fold: 4  Epoch: 335  Training loss = 1.6204  Validation loss = 4.2799  \n",
      "\n",
      "Fold: 4  Epoch: 336  Training loss = 1.6203  Validation loss = 4.2794  \n",
      "\n",
      "Fold: 4  Epoch: 337  Training loss = 1.6202  Validation loss = 4.2792  \n",
      "\n",
      "Fold: 4  Epoch: 338  Training loss = 1.6201  Validation loss = 4.2788  \n",
      "\n",
      "Fold: 4  Epoch: 339  Training loss = 1.6201  Validation loss = 4.2785  \n",
      "\n",
      "Fold: 4  Epoch: 340  Training loss = 1.6200  Validation loss = 4.2783  \n",
      "\n",
      "Fold: 4  Epoch: 341  Training loss = 1.6199  Validation loss = 4.2779  \n",
      "\n",
      "Fold: 4  Epoch: 342  Training loss = 1.6198  Validation loss = 4.2775  \n",
      "\n",
      "Fold: 4  Epoch: 343  Training loss = 1.6197  Validation loss = 4.2768  \n",
      "\n",
      "Fold: 4  Epoch: 344  Training loss = 1.6197  Validation loss = 4.2765  \n",
      "\n",
      "Fold: 4  Epoch: 345  Training loss = 1.6195  Validation loss = 4.2758  \n",
      "\n",
      "Fold: 4  Epoch: 346  Training loss = 1.6195  Validation loss = 4.2757  \n",
      "\n",
      "Fold: 4  Epoch: 347  Training loss = 1.6194  Validation loss = 4.2754  \n",
      "\n",
      "Fold: 4  Epoch: 348  Training loss = 1.6193  Validation loss = 4.2751  \n",
      "\n",
      "Fold: 4  Epoch: 349  Training loss = 1.6193  Validation loss = 4.2746  \n",
      "\n",
      "Fold: 4  Epoch: 350  Training loss = 1.6191  Validation loss = 4.2739  \n",
      "\n",
      "Fold: 4  Epoch: 351  Training loss = 1.6190  Validation loss = 4.2734  \n",
      "\n",
      "Fold: 4  Epoch: 352  Training loss = 1.6189  Validation loss = 4.2726  \n",
      "\n",
      "Fold: 4  Epoch: 353  Training loss = 1.6188  Validation loss = 4.2725  \n",
      "\n",
      "Fold: 4  Epoch: 354  Training loss = 1.6187  Validation loss = 4.2722  \n",
      "\n",
      "Fold: 4  Epoch: 355  Training loss = 1.6186  Validation loss = 4.2714  \n",
      "\n",
      "Fold: 4  Epoch: 356  Training loss = 1.6186  Validation loss = 4.2712  \n",
      "\n",
      "Fold: 4  Epoch: 357  Training loss = 1.6185  Validation loss = 4.2709  \n",
      "\n",
      "Fold: 4  Epoch: 358  Training loss = 1.6184  Validation loss = 4.2705  \n",
      "\n",
      "Fold: 4  Epoch: 359  Training loss = 1.6183  Validation loss = 4.2698  \n",
      "\n",
      "Fold: 4  Epoch: 360  Training loss = 1.6182  Validation loss = 4.2693  \n",
      "\n",
      "Fold: 4  Epoch: 361  Training loss = 1.6181  Validation loss = 4.2689  \n",
      "\n",
      "Fold: 4  Epoch: 362  Training loss = 1.6181  Validation loss = 4.2686  \n",
      "\n",
      "Fold: 4  Epoch: 363  Training loss = 1.6180  Validation loss = 4.2683  \n",
      "\n",
      "Fold: 4  Epoch: 364  Training loss = 1.6179  Validation loss = 4.2685  \n",
      "\n",
      "Fold: 4  Epoch: 365  Training loss = 1.6179  Validation loss = 4.2683  \n",
      "\n",
      "Fold: 4  Epoch: 366  Training loss = 1.6177  Validation loss = 4.2674  \n",
      "\n",
      "Fold: 4  Epoch: 367  Training loss = 1.6176  Validation loss = 4.2668  \n",
      "\n",
      "Fold: 4  Epoch: 368  Training loss = 1.6175  Validation loss = 4.2662  \n",
      "\n",
      "Fold: 4  Epoch: 369  Training loss = 1.6174  Validation loss = 4.2656  \n",
      "\n",
      "Fold: 4  Epoch: 370  Training loss = 1.6173  Validation loss = 4.2650  \n",
      "\n",
      "Fold: 4  Epoch: 371  Training loss = 1.6172  Validation loss = 4.2642  \n",
      "\n",
      "Fold: 4  Epoch: 372  Training loss = 1.6171  Validation loss = 4.2639  \n",
      "\n",
      "Fold: 4  Epoch: 373  Training loss = 1.6170  Validation loss = 4.2637  \n",
      "\n",
      "Fold: 4  Epoch: 374  Training loss = 1.6169  Validation loss = 4.2631  \n",
      "\n",
      "Fold: 4  Epoch: 375  Training loss = 1.6168  Validation loss = 4.2622  \n",
      "\n",
      "Fold: 4  Epoch: 376  Training loss = 1.6167  Validation loss = 4.2619  \n",
      "\n",
      "Fold: 4  Epoch: 377  Training loss = 1.6166  Validation loss = 4.2614  \n",
      "\n",
      "Fold: 4  Epoch: 378  Training loss = 1.6165  Validation loss = 4.2607  \n",
      "\n",
      "Fold: 4  Epoch: 379  Training loss = 1.6164  Validation loss = 4.2602  \n",
      "\n",
      "Fold: 4  Epoch: 380  Training loss = 1.6163  Validation loss = 4.2602  \n",
      "\n",
      "Fold: 4  Epoch: 381  Training loss = 1.6163  Validation loss = 4.2603  \n",
      "\n",
      "Fold: 4  Epoch: 382  Training loss = 1.6161  Validation loss = 4.2596  \n",
      "\n",
      "Fold: 4  Epoch: 383  Training loss = 1.6160  Validation loss = 4.2588  \n",
      "\n",
      "Fold: 4  Epoch: 384  Training loss = 1.6159  Validation loss = 4.2587  \n",
      "\n",
      "Fold: 4  Epoch: 385  Training loss = 1.6159  Validation loss = 4.2584  \n",
      "\n",
      "Fold: 4  Epoch: 386  Training loss = 1.6157  Validation loss = 4.2577  \n",
      "\n",
      "Fold: 4  Epoch: 387  Training loss = 1.6156  Validation loss = 4.2573  \n",
      "\n",
      "Fold: 4  Epoch: 388  Training loss = 1.6156  Validation loss = 4.2568  \n",
      "\n",
      "Fold: 4  Epoch: 389  Training loss = 1.6155  Validation loss = 4.2564  \n",
      "\n",
      "Fold: 4  Epoch: 390  Training loss = 1.6154  Validation loss = 4.2564  \n",
      "\n",
      "Fold: 4  Epoch: 391  Training loss = 1.6153  Validation loss = 4.2562  \n",
      "\n",
      "Fold: 4  Epoch: 392  Training loss = 1.6153  Validation loss = 4.2561  \n",
      "\n",
      "Fold: 4  Epoch: 393  Training loss = 1.6152  Validation loss = 4.2558  \n",
      "\n",
      "Fold: 4  Epoch: 394  Training loss = 1.6151  Validation loss = 4.2554  \n",
      "\n",
      "Fold: 4  Epoch: 395  Training loss = 1.6150  Validation loss = 4.2547  \n",
      "\n",
      "Fold: 4  Epoch: 396  Training loss = 1.6149  Validation loss = 4.2541  \n",
      "\n",
      "Fold: 4  Epoch: 397  Training loss = 1.6149  Validation loss = 4.2542  \n",
      "\n",
      "Fold: 4  Epoch: 398  Training loss = 1.6148  Validation loss = 4.2542  \n",
      "\n",
      "Fold: 4  Epoch: 399  Training loss = 1.6147  Validation loss = 4.2540  \n",
      "\n",
      "Fold: 4  Epoch: 400  Training loss = 1.6146  Validation loss = 4.2533  \n",
      "\n",
      "Fold: 4  Epoch: 401  Training loss = 1.6145  Validation loss = 4.2530  \n",
      "\n",
      "Fold: 4  Epoch: 402  Training loss = 1.6145  Validation loss = 4.2532  \n",
      "\n",
      "Fold: 4  Epoch: 403  Training loss = 1.6144  Validation loss = 4.2532  \n",
      "\n",
      "Fold: 4  Epoch: 404  Training loss = 1.6143  Validation loss = 4.2532  \n",
      "\n",
      "Fold: 4  Epoch: 405  Training loss = 1.6143  Validation loss = 4.2527  \n",
      "\n",
      "Fold: 4  Epoch: 406  Training loss = 1.6142  Validation loss = 4.2527  \n",
      "\n",
      "Fold: 4  Epoch: 407  Training loss = 1.6141  Validation loss = 4.2522  \n",
      "\n",
      "Fold: 4  Epoch: 408  Training loss = 1.6140  Validation loss = 4.2523  \n",
      "\n",
      "Fold: 4  Epoch: 409  Training loss = 1.6140  Validation loss = 4.2525  \n",
      "\n",
      "Fold: 4  Epoch: 410  Training loss = 1.6139  Validation loss = 4.2520  \n",
      "\n",
      "Fold: 4  Epoch: 411  Training loss = 1.6138  Validation loss = 4.2520  \n",
      "\n",
      "Fold: 4  Epoch: 412  Training loss = 1.6137  Validation loss = 4.2515  \n",
      "\n",
      "Fold: 4  Epoch: 413  Training loss = 1.6137  Validation loss = 4.2515  \n",
      "\n",
      "Fold: 4  Epoch: 414  Training loss = 1.6136  Validation loss = 4.2514  \n",
      "\n",
      "Fold: 4  Epoch: 415  Training loss = 1.6136  Validation loss = 4.2511  \n",
      "\n",
      "Fold: 4  Epoch: 416  Training loss = 1.6135  Validation loss = 4.2515  \n",
      "\n",
      "Fold: 4  Epoch: 417  Training loss = 1.6134  Validation loss = 4.2510  \n",
      "\n",
      "Fold: 4  Epoch: 418  Training loss = 1.6133  Validation loss = 4.2502  \n",
      "\n",
      "Fold: 4  Epoch: 419  Training loss = 1.6132  Validation loss = 4.2498  \n",
      "\n",
      "Fold: 4  Epoch: 420  Training loss = 1.6132  Validation loss = 4.2499  \n",
      "\n",
      "Fold: 4  Epoch: 421  Training loss = 1.6131  Validation loss = 4.2493  \n",
      "\n",
      "Fold: 4  Epoch: 422  Training loss = 1.6130  Validation loss = 4.2491  \n",
      "\n",
      "Fold: 4  Epoch: 423  Training loss = 1.6129  Validation loss = 4.2487  \n",
      "\n",
      "Fold: 4  Epoch: 424  Training loss = 1.6128  Validation loss = 4.2481  \n",
      "\n",
      "Fold: 4  Epoch: 425  Training loss = 1.6127  Validation loss = 4.2483  \n",
      "\n",
      "Fold: 4  Epoch: 426  Training loss = 1.6127  Validation loss = 4.2479  \n",
      "\n",
      "Fold: 4  Epoch: 427  Training loss = 1.6126  Validation loss = 4.2475  \n",
      "\n",
      "Fold: 4  Epoch: 428  Training loss = 1.6125  Validation loss = 4.2473  \n",
      "\n",
      "Fold: 4  Epoch: 429  Training loss = 1.6124  Validation loss = 4.2470  \n",
      "\n",
      "Fold: 4  Epoch: 430  Training loss = 1.6123  Validation loss = 4.2466  \n",
      "\n",
      "Fold: 4  Epoch: 431  Training loss = 1.6122  Validation loss = 4.2461  \n",
      "\n",
      "Fold: 4  Epoch: 432  Training loss = 1.6122  Validation loss = 4.2459  \n",
      "\n",
      "Fold: 4  Epoch: 433  Training loss = 1.6120  Validation loss = 4.2450  \n",
      "\n",
      "Fold: 4  Epoch: 434  Training loss = 1.6120  Validation loss = 4.2446  \n",
      "\n",
      "Fold: 4  Epoch: 435  Training loss = 1.6119  Validation loss = 4.2444  \n",
      "\n",
      "Fold: 4  Epoch: 436  Training loss = 1.6118  Validation loss = 4.2438  \n",
      "\n",
      "Fold: 4  Epoch: 437  Training loss = 1.6117  Validation loss = 4.2436  \n",
      "\n",
      "Fold: 4  Epoch: 438  Training loss = 1.6117  Validation loss = 4.2435  \n",
      "\n",
      "Fold: 4  Epoch: 439  Training loss = 1.6116  Validation loss = 4.2428  \n",
      "\n",
      "Fold: 4  Epoch: 440  Training loss = 1.6115  Validation loss = 4.2425  \n",
      "\n",
      "Fold: 4  Epoch: 441  Training loss = 1.6114  Validation loss = 4.2421  \n",
      "\n",
      "Fold: 4  Epoch: 442  Training loss = 1.6113  Validation loss = 4.2419  \n",
      "\n",
      "Fold: 4  Epoch: 443  Training loss = 1.6113  Validation loss = 4.2415  \n",
      "\n",
      "Fold: 4  Epoch: 444  Training loss = 1.6112  Validation loss = 4.2408  \n",
      "\n",
      "Fold: 4  Epoch: 445  Training loss = 1.6111  Validation loss = 4.2404  \n",
      "\n",
      "Fold: 4  Epoch: 446  Training loss = 1.6110  Validation loss = 4.2399  \n",
      "\n",
      "Fold: 4  Epoch: 447  Training loss = 1.6109  Validation loss = 4.2390  \n",
      "\n",
      "Fold: 4  Epoch: 448  Training loss = 1.6109  Validation loss = 4.2390  \n",
      "\n",
      "Fold: 4  Epoch: 449  Training loss = 1.6107  Validation loss = 4.2381  \n",
      "\n",
      "Fold: 4  Epoch: 450  Training loss = 1.6106  Validation loss = 4.2377  \n",
      "\n",
      "Fold: 4  Epoch: 451  Training loss = 1.6106  Validation loss = 4.2378  \n",
      "\n",
      "Fold: 4  Epoch: 452  Training loss = 1.6105  Validation loss = 4.2375  \n",
      "\n",
      "Fold: 4  Epoch: 453  Training loss = 1.6104  Validation loss = 4.2371  \n",
      "\n",
      "Fold: 4  Epoch: 454  Training loss = 1.6104  Validation loss = 4.2366  \n",
      "\n",
      "Fold: 4  Epoch: 455  Training loss = 1.6103  Validation loss = 4.2365  \n",
      "\n",
      "Fold: 4  Epoch: 456  Training loss = 1.6102  Validation loss = 4.2364  \n",
      "\n",
      "Fold: 4  Epoch: 457  Training loss = 1.6101  Validation loss = 4.2351  \n",
      "\n",
      "Fold: 4  Epoch: 458  Training loss = 1.6100  Validation loss = 4.2346  \n",
      "\n",
      "Fold: 4  Epoch: 459  Training loss = 1.6098  Validation loss = 4.2336  \n",
      "\n",
      "Fold: 4  Epoch: 460  Training loss = 1.6098  Validation loss = 4.2333  \n",
      "\n",
      "Fold: 4  Epoch: 461  Training loss = 1.6097  Validation loss = 4.2331  \n",
      "\n",
      "Fold: 4  Epoch: 462  Training loss = 1.6096  Validation loss = 4.2329  \n",
      "\n",
      "Fold: 4  Epoch: 463  Training loss = 1.6096  Validation loss = 4.2332  \n",
      "\n",
      "Fold: 4  Epoch: 464  Training loss = 1.6095  Validation loss = 4.2327  \n",
      "\n",
      "Fold: 4  Epoch: 465  Training loss = 1.6094  Validation loss = 4.2327  \n",
      "\n",
      "Fold: 4  Epoch: 466  Training loss = 1.6093  Validation loss = 4.2323  \n",
      "\n",
      "Fold: 4  Epoch: 467  Training loss = 1.6092  Validation loss = 4.2318  \n",
      "\n",
      "Fold: 4  Epoch: 468  Training loss = 1.6092  Validation loss = 4.2317  \n",
      "\n",
      "Fold: 4  Epoch: 469  Training loss = 1.6090  Validation loss = 4.2312  \n",
      "\n",
      "Fold: 4  Epoch: 470  Training loss = 1.6090  Validation loss = 4.2313  \n",
      "\n",
      "Fold: 4  Epoch: 471  Training loss = 1.6089  Validation loss = 4.2309  \n",
      "\n",
      "Fold: 4  Epoch: 472  Training loss = 1.6088  Validation loss = 4.2302  \n",
      "\n",
      "Fold: 4  Epoch: 473  Training loss = 1.6086  Validation loss = 4.2294  \n",
      "\n",
      "Fold: 4  Epoch: 474  Training loss = 1.6086  Validation loss = 4.2291  \n",
      "\n",
      "Fold: 4  Epoch: 475  Training loss = 1.6085  Validation loss = 4.2291  \n",
      "\n",
      "Fold: 4  Epoch: 476  Training loss = 1.6084  Validation loss = 4.2286  \n",
      "\n",
      "Fold: 4  Epoch: 477  Training loss = 1.6083  Validation loss = 4.2281  \n",
      "\n",
      "Fold: 4  Epoch: 478  Training loss = 1.6082  Validation loss = 4.2279  \n",
      "\n",
      "Fold: 4  Epoch: 479  Training loss = 1.6081  Validation loss = 4.2280  \n",
      "\n",
      "Fold: 4  Epoch: 480  Training loss = 1.6081  Validation loss = 4.2276  \n",
      "\n",
      "Fold: 4  Epoch: 481  Training loss = 1.6080  Validation loss = 4.2268  \n",
      "\n",
      "Fold: 4  Epoch: 482  Training loss = 1.6079  Validation loss = 4.2261  \n",
      "\n",
      "Fold: 4  Epoch: 483  Training loss = 1.6078  Validation loss = 4.2259  \n",
      "\n",
      "Fold: 4  Epoch: 484  Training loss = 1.6077  Validation loss = 4.2254  \n",
      "\n",
      "Fold: 4  Epoch: 485  Training loss = 1.6076  Validation loss = 4.2254  \n",
      "\n",
      "Fold: 4  Epoch: 486  Training loss = 1.6076  Validation loss = 4.2253  \n",
      "\n",
      "Fold: 4  Epoch: 487  Training loss = 1.6074  Validation loss = 4.2245  \n",
      "\n",
      "Fold: 4  Epoch: 488  Training loss = 1.6074  Validation loss = 4.2242  \n",
      "\n",
      "Fold: 4  Epoch: 489  Training loss = 1.6072  Validation loss = 4.2231  \n",
      "\n",
      "Fold: 4  Epoch: 490  Training loss = 1.6072  Validation loss = 4.2232  \n",
      "\n",
      "Fold: 4  Epoch: 491  Training loss = 1.6071  Validation loss = 4.2228  \n",
      "\n",
      "Fold: 4  Epoch: 492  Training loss = 1.6070  Validation loss = 4.2231  \n",
      "\n",
      "Fold: 4  Epoch: 493  Training loss = 1.6070  Validation loss = 4.2225  \n",
      "\n",
      "Fold: 4  Epoch: 494  Training loss = 1.6069  Validation loss = 4.2221  \n",
      "\n",
      "Fold: 4  Epoch: 495  Training loss = 1.6068  Validation loss = 4.2219  \n",
      "\n",
      "Fold: 4  Epoch: 496  Training loss = 1.6067  Validation loss = 4.2220  \n",
      "\n",
      "Fold: 4  Epoch: 497  Training loss = 1.6067  Validation loss = 4.2215  \n",
      "\n",
      "Fold: 4  Epoch: 498  Training loss = 1.6066  Validation loss = 4.2211  \n",
      "\n",
      "Fold: 4  Epoch: 499  Training loss = 1.6065  Validation loss = 4.2208  \n",
      "\n",
      "Fold: 4  Epoch: 500  Training loss = 1.6063  Validation loss = 4.2200  \n",
      "\n",
      "Check model:  Fold: 4  Optimal epoch: 500  \n",
      "\n",
      "Fold: 5  Epoch: 1  Training loss = 1.8720  Validation loss = 4.1027  \n",
      "\n",
      "Fold: 5  Epoch: 2  Training loss = 1.8717  Validation loss = 4.1016  \n",
      "\n",
      "Fold: 5  Epoch: 3  Training loss = 1.8715  Validation loss = 4.1009  \n",
      "\n",
      "Fold: 5  Epoch: 4  Training loss = 1.8713  Validation loss = 4.1002  \n",
      "\n",
      "Fold: 5  Epoch: 5  Training loss = 1.8710  Validation loss = 4.0992  \n",
      "\n",
      "Fold: 5  Epoch: 6  Training loss = 1.8708  Validation loss = 4.0986  \n",
      "\n",
      "Fold: 5  Epoch: 7  Training loss = 1.8705  Validation loss = 4.0978  \n",
      "\n",
      "Fold: 5  Epoch: 8  Training loss = 1.8704  Validation loss = 4.0974  \n",
      "\n",
      "Fold: 5  Epoch: 9  Training loss = 1.8700  Validation loss = 4.0961  \n",
      "\n",
      "Fold: 5  Epoch: 10  Training loss = 1.8698  Validation loss = 4.0954  \n",
      "\n",
      "Fold: 5  Epoch: 11  Training loss = 1.8696  Validation loss = 4.0948  \n",
      "\n",
      "Fold: 5  Epoch: 12  Training loss = 1.8692  Validation loss = 4.0934  \n",
      "\n",
      "Fold: 5  Epoch: 13  Training loss = 1.8688  Validation loss = 4.0919  \n",
      "\n",
      "Fold: 5  Epoch: 14  Training loss = 1.8685  Validation loss = 4.0910  \n",
      "\n",
      "Fold: 5  Epoch: 15  Training loss = 1.8683  Validation loss = 4.0901  \n",
      "\n",
      "Fold: 5  Epoch: 16  Training loss = 1.8679  Validation loss = 4.0887  \n",
      "\n",
      "Fold: 5  Epoch: 17  Training loss = 1.8677  Validation loss = 4.0880  \n",
      "\n",
      "Fold: 5  Epoch: 18  Training loss = 1.8675  Validation loss = 4.0875  \n",
      "\n",
      "Fold: 5  Epoch: 19  Training loss = 1.8673  Validation loss = 4.0868  \n",
      "\n",
      "Fold: 5  Epoch: 20  Training loss = 1.8671  Validation loss = 4.0860  \n",
      "\n",
      "Fold: 5  Epoch: 21  Training loss = 1.8668  Validation loss = 4.0852  \n",
      "\n",
      "Fold: 5  Epoch: 22  Training loss = 1.8666  Validation loss = 4.0845  \n",
      "\n",
      "Fold: 5  Epoch: 23  Training loss = 1.8663  Validation loss = 4.0833  \n",
      "\n",
      "Fold: 5  Epoch: 24  Training loss = 1.8661  Validation loss = 4.0830  \n",
      "\n",
      "Fold: 5  Epoch: 25  Training loss = 1.8659  Validation loss = 4.0821  \n",
      "\n",
      "Fold: 5  Epoch: 26  Training loss = 1.8657  Validation loss = 4.0812  \n",
      "\n",
      "Fold: 5  Epoch: 27  Training loss = 1.8654  Validation loss = 4.0804  \n",
      "\n",
      "Fold: 5  Epoch: 28  Training loss = 1.8652  Validation loss = 4.0798  \n",
      "\n",
      "Fold: 5  Epoch: 29  Training loss = 1.8650  Validation loss = 4.0791  \n",
      "\n",
      "Fold: 5  Epoch: 30  Training loss = 1.8647  Validation loss = 4.0781  \n",
      "\n",
      "Fold: 5  Epoch: 31  Training loss = 1.8645  Validation loss = 4.0776  \n",
      "\n",
      "Fold: 5  Epoch: 32  Training loss = 1.8639  Validation loss = 4.0753  \n",
      "\n",
      "Fold: 5  Epoch: 33  Training loss = 1.8635  Validation loss = 4.0739  \n",
      "\n",
      "Fold: 5  Epoch: 34  Training loss = 1.8632  Validation loss = 4.0731  \n",
      "\n",
      "Fold: 5  Epoch: 35  Training loss = 1.8628  Validation loss = 4.0717  \n",
      "\n",
      "Fold: 5  Epoch: 36  Training loss = 1.8626  Validation loss = 4.0710  \n",
      "\n",
      "Fold: 5  Epoch: 37  Training loss = 1.8623  Validation loss = 4.0701  \n",
      "\n",
      "Fold: 5  Epoch: 38  Training loss = 1.8622  Validation loss = 4.0699  \n",
      "\n",
      "Fold: 5  Epoch: 39  Training loss = 1.8620  Validation loss = 4.0692  \n",
      "\n",
      "Fold: 5  Epoch: 40  Training loss = 1.8616  Validation loss = 4.0678  \n",
      "\n",
      "Fold: 5  Epoch: 41  Training loss = 1.8614  Validation loss = 4.0670  \n",
      "\n",
      "Fold: 5  Epoch: 42  Training loss = 1.8610  Validation loss = 4.0655  \n",
      "\n",
      "Fold: 5  Epoch: 43  Training loss = 1.8609  Validation loss = 4.0651  \n",
      "\n",
      "Fold: 5  Epoch: 44  Training loss = 1.8606  Validation loss = 4.0640  \n",
      "\n",
      "Fold: 5  Epoch: 45  Training loss = 1.8603  Validation loss = 4.0631  \n",
      "\n",
      "Fold: 5  Epoch: 46  Training loss = 1.8600  Validation loss = 4.0622  \n",
      "\n",
      "Fold: 5  Epoch: 47  Training loss = 1.8597  Validation loss = 4.0611  \n",
      "\n",
      "Fold: 5  Epoch: 48  Training loss = 1.8593  Validation loss = 4.0596  \n",
      "\n",
      "Fold: 5  Epoch: 49  Training loss = 1.8591  Validation loss = 4.0588  \n",
      "\n",
      "Fold: 5  Epoch: 50  Training loss = 1.8588  Validation loss = 4.0580  \n",
      "\n",
      "Fold: 5  Epoch: 51  Training loss = 1.8586  Validation loss = 4.0573  \n",
      "\n",
      "Fold: 5  Epoch: 52  Training loss = 1.8583  Validation loss = 4.0563  \n",
      "\n",
      "Fold: 5  Epoch: 53  Training loss = 1.8581  Validation loss = 4.0556  \n",
      "\n",
      "Fold: 5  Epoch: 54  Training loss = 1.8578  Validation loss = 4.0543  \n",
      "\n",
      "Fold: 5  Epoch: 55  Training loss = 1.8575  Validation loss = 4.0534  \n",
      "\n",
      "Fold: 5  Epoch: 56  Training loss = 1.8573  Validation loss = 4.0530  \n",
      "\n",
      "Fold: 5  Epoch: 57  Training loss = 1.8570  Validation loss = 4.0518  \n",
      "\n",
      "Fold: 5  Epoch: 58  Training loss = 1.8568  Validation loss = 4.0509  \n",
      "\n",
      "Fold: 5  Epoch: 59  Training loss = 1.8565  Validation loss = 4.0499  \n",
      "\n",
      "Fold: 5  Epoch: 60  Training loss = 1.8561  Validation loss = 4.0486  \n",
      "\n",
      "Fold: 5  Epoch: 61  Training loss = 1.8559  Validation loss = 4.0478  \n",
      "\n",
      "Fold: 5  Epoch: 62  Training loss = 1.8558  Validation loss = 4.0479  \n",
      "\n",
      "Fold: 5  Epoch: 63  Training loss = 1.8556  Validation loss = 4.0471  \n",
      "\n",
      "Fold: 5  Epoch: 64  Training loss = 1.8553  Validation loss = 4.0460  \n",
      "\n",
      "Fold: 5  Epoch: 65  Training loss = 1.8551  Validation loss = 4.0455  \n",
      "\n",
      "Fold: 5  Epoch: 66  Training loss = 1.8549  Validation loss = 4.0449  \n",
      "\n",
      "Fold: 5  Epoch: 67  Training loss = 1.8547  Validation loss = 4.0441  \n",
      "\n",
      "Fold: 5  Epoch: 68  Training loss = 1.8544  Validation loss = 4.0432  \n",
      "\n",
      "Fold: 5  Epoch: 69  Training loss = 1.8542  Validation loss = 4.0424  \n",
      "\n",
      "Fold: 5  Epoch: 70  Training loss = 1.8540  Validation loss = 4.0415  \n",
      "\n",
      "Fold: 5  Epoch: 71  Training loss = 1.8537  Validation loss = 4.0408  \n",
      "\n",
      "Fold: 5  Epoch: 72  Training loss = 1.8535  Validation loss = 4.0401  \n",
      "\n",
      "Fold: 5  Epoch: 73  Training loss = 1.8534  Validation loss = 4.0397  \n",
      "\n",
      "Fold: 5  Epoch: 74  Training loss = 1.8531  Validation loss = 4.0387  \n",
      "\n",
      "Fold: 5  Epoch: 75  Training loss = 1.8530  Validation loss = 4.0384  \n",
      "\n",
      "Fold: 5  Epoch: 76  Training loss = 1.8528  Validation loss = 4.0380  \n",
      "\n",
      "Fold: 5  Epoch: 77  Training loss = 1.8525  Validation loss = 4.0369  \n",
      "\n",
      "Fold: 5  Epoch: 78  Training loss = 1.8522  Validation loss = 4.0360  \n",
      "\n",
      "Fold: 5  Epoch: 79  Training loss = 1.8521  Validation loss = 4.0356  \n",
      "\n",
      "Fold: 5  Epoch: 80  Training loss = 1.8518  Validation loss = 4.0346  \n",
      "\n",
      "Fold: 5  Epoch: 81  Training loss = 1.8516  Validation loss = 4.0338  \n",
      "\n",
      "Fold: 5  Epoch: 82  Training loss = 1.8512  Validation loss = 4.0324  \n",
      "\n",
      "Fold: 5  Epoch: 83  Training loss = 1.8509  Validation loss = 4.0313  \n",
      "\n",
      "Fold: 5  Epoch: 84  Training loss = 1.8504  Validation loss = 4.0298  \n",
      "\n",
      "Fold: 5  Epoch: 85  Training loss = 1.8503  Validation loss = 4.0291  \n",
      "\n",
      "Fold: 5  Epoch: 86  Training loss = 1.8500  Validation loss = 4.0283  \n",
      "\n",
      "Fold: 5  Epoch: 87  Training loss = 1.8497  Validation loss = 4.0271  \n",
      "\n",
      "Fold: 5  Epoch: 88  Training loss = 1.8495  Validation loss = 4.0264  \n",
      "\n",
      "Fold: 5  Epoch: 89  Training loss = 1.8493  Validation loss = 4.0257  \n",
      "\n",
      "Fold: 5  Epoch: 90  Training loss = 1.8490  Validation loss = 4.0248  \n",
      "\n",
      "Fold: 5  Epoch: 91  Training loss = 1.8489  Validation loss = 4.0246  \n",
      "\n",
      "Fold: 5  Epoch: 92  Training loss = 1.8486  Validation loss = 4.0235  \n",
      "\n",
      "Fold: 5  Epoch: 93  Training loss = 1.8484  Validation loss = 4.0229  \n",
      "\n",
      "Fold: 5  Epoch: 94  Training loss = 1.8482  Validation loss = 4.0221  \n",
      "\n",
      "Fold: 5  Epoch: 95  Training loss = 1.8480  Validation loss = 4.0218  \n",
      "\n",
      "Fold: 5  Epoch: 96  Training loss = 1.8478  Validation loss = 4.0208  \n",
      "\n",
      "Fold: 5  Epoch: 97  Training loss = 1.8475  Validation loss = 4.0200  \n",
      "\n",
      "Fold: 5  Epoch: 98  Training loss = 1.8474  Validation loss = 4.0195  \n",
      "\n",
      "Fold: 5  Epoch: 99  Training loss = 1.8471  Validation loss = 4.0185  \n",
      "\n",
      "Fold: 5  Epoch: 100  Training loss = 1.8469  Validation loss = 4.0180  \n",
      "\n",
      "Fold: 5  Epoch: 101  Training loss = 1.8466  Validation loss = 4.0170  \n",
      "\n",
      "Fold: 5  Epoch: 102  Training loss = 1.8463  Validation loss = 4.0156  \n",
      "\n",
      "Fold: 5  Epoch: 103  Training loss = 1.8460  Validation loss = 4.0143  \n",
      "\n",
      "Fold: 5  Epoch: 104  Training loss = 1.8458  Validation loss = 4.0140  \n",
      "\n",
      "Fold: 5  Epoch: 105  Training loss = 1.8457  Validation loss = 4.0138  \n",
      "\n",
      "Fold: 5  Epoch: 106  Training loss = 1.8454  Validation loss = 4.0131  \n",
      "\n",
      "Fold: 5  Epoch: 107  Training loss = 1.8452  Validation loss = 4.0125  \n",
      "\n",
      "Fold: 5  Epoch: 108  Training loss = 1.8450  Validation loss = 4.0117  \n",
      "\n",
      "Fold: 5  Epoch: 109  Training loss = 1.8448  Validation loss = 4.0111  \n",
      "\n",
      "Fold: 5  Epoch: 110  Training loss = 1.8445  Validation loss = 4.0098  \n",
      "\n",
      "Fold: 5  Epoch: 111  Training loss = 1.8442  Validation loss = 4.0088  \n",
      "\n",
      "Fold: 5  Epoch: 112  Training loss = 1.8441  Validation loss = 4.0085  \n",
      "\n",
      "Fold: 5  Epoch: 113  Training loss = 1.8439  Validation loss = 4.0078  \n",
      "\n",
      "Fold: 5  Epoch: 114  Training loss = 1.8437  Validation loss = 4.0073  \n",
      "\n",
      "Fold: 5  Epoch: 115  Training loss = 1.8434  Validation loss = 4.0065  \n",
      "\n",
      "Fold: 5  Epoch: 116  Training loss = 1.8433  Validation loss = 4.0061  \n",
      "\n",
      "Fold: 5  Epoch: 117  Training loss = 1.8430  Validation loss = 4.0049  \n",
      "\n",
      "Fold: 5  Epoch: 118  Training loss = 1.8428  Validation loss = 4.0041  \n",
      "\n",
      "Fold: 5  Epoch: 119  Training loss = 1.8425  Validation loss = 4.0033  \n",
      "\n",
      "Fold: 5  Epoch: 120  Training loss = 1.8424  Validation loss = 4.0029  \n",
      "\n",
      "Fold: 5  Epoch: 121  Training loss = 1.8420  Validation loss = 4.0017  \n",
      "\n",
      "Fold: 5  Epoch: 122  Training loss = 1.8417  Validation loss = 4.0005  \n",
      "\n",
      "Fold: 5  Epoch: 123  Training loss = 1.8415  Validation loss = 3.9999  \n",
      "\n",
      "Fold: 5  Epoch: 124  Training loss = 1.8413  Validation loss = 3.9991  \n",
      "\n",
      "Fold: 5  Epoch: 125  Training loss = 1.8412  Validation loss = 3.9987  \n",
      "\n",
      "Fold: 5  Epoch: 126  Training loss = 1.8410  Validation loss = 3.9983  \n",
      "\n",
      "Fold: 5  Epoch: 127  Training loss = 1.8407  Validation loss = 3.9971  \n",
      "\n",
      "Fold: 5  Epoch: 128  Training loss = 1.8405  Validation loss = 3.9961  \n",
      "\n",
      "Fold: 5  Epoch: 129  Training loss = 1.8403  Validation loss = 3.9956  \n",
      "\n",
      "Fold: 5  Epoch: 130  Training loss = 1.8400  Validation loss = 3.9946  \n",
      "\n",
      "Fold: 5  Epoch: 131  Training loss = 1.8398  Validation loss = 3.9941  \n",
      "\n",
      "Fold: 5  Epoch: 132  Training loss = 1.8396  Validation loss = 3.9936  \n",
      "\n",
      "Fold: 5  Epoch: 133  Training loss = 1.8394  Validation loss = 3.9929  \n",
      "\n",
      "Fold: 5  Epoch: 134  Training loss = 1.8392  Validation loss = 3.9925  \n",
      "\n",
      "Fold: 5  Epoch: 135  Training loss = 1.8389  Validation loss = 3.9913  \n",
      "\n",
      "Fold: 5  Epoch: 136  Training loss = 1.8388  Validation loss = 3.9908  \n",
      "\n",
      "Fold: 5  Epoch: 137  Training loss = 1.8386  Validation loss = 3.9903  \n",
      "\n",
      "Fold: 5  Epoch: 138  Training loss = 1.8385  Validation loss = 3.9901  \n",
      "\n",
      "Fold: 5  Epoch: 139  Training loss = 1.8382  Validation loss = 3.9891  \n",
      "\n",
      "Fold: 5  Epoch: 140  Training loss = 1.8380  Validation loss = 3.9882  \n",
      "\n",
      "Fold: 5  Epoch: 141  Training loss = 1.8377  Validation loss = 3.9872  \n",
      "\n",
      "Fold: 5  Epoch: 142  Training loss = 1.8373  Validation loss = 3.9860  \n",
      "\n",
      "Fold: 5  Epoch: 143  Training loss = 1.8371  Validation loss = 3.9852  \n",
      "\n",
      "Fold: 5  Epoch: 144  Training loss = 1.8366  Validation loss = 3.9836  \n",
      "\n",
      "Fold: 5  Epoch: 145  Training loss = 1.8364  Validation loss = 3.9829  \n",
      "\n",
      "Fold: 5  Epoch: 146  Training loss = 1.8362  Validation loss = 3.9821  \n",
      "\n",
      "Fold: 5  Epoch: 147  Training loss = 1.8361  Validation loss = 3.9819  \n",
      "\n",
      "Fold: 5  Epoch: 148  Training loss = 1.8358  Validation loss = 3.9810  \n",
      "\n",
      "Fold: 5  Epoch: 149  Training loss = 1.8356  Validation loss = 3.9803  \n",
      "\n",
      "Fold: 5  Epoch: 150  Training loss = 1.8353  Validation loss = 3.9795  \n",
      "\n",
      "Fold: 5  Epoch: 151  Training loss = 1.8353  Validation loss = 3.9796  \n",
      "\n",
      "Fold: 5  Epoch: 152  Training loss = 1.8350  Validation loss = 3.9788  \n",
      "\n",
      "Fold: 5  Epoch: 153  Training loss = 1.8348  Validation loss = 3.9780  \n",
      "\n",
      "Fold: 5  Epoch: 154  Training loss = 1.8346  Validation loss = 3.9774  \n",
      "\n",
      "Fold: 5  Epoch: 155  Training loss = 1.8344  Validation loss = 3.9766  \n",
      "\n",
      "Fold: 5  Epoch: 156  Training loss = 1.8340  Validation loss = 3.9751  \n",
      "\n",
      "Fold: 5  Epoch: 157  Training loss = 1.8337  Validation loss = 3.9741  \n",
      "\n",
      "Fold: 5  Epoch: 158  Training loss = 1.8336  Validation loss = 3.9737  \n",
      "\n",
      "Fold: 5  Epoch: 159  Training loss = 1.8333  Validation loss = 3.9727  \n",
      "\n",
      "Fold: 5  Epoch: 160  Training loss = 1.8329  Validation loss = 3.9715  \n",
      "\n",
      "Fold: 5  Epoch: 161  Training loss = 1.8328  Validation loss = 3.9710  \n",
      "\n",
      "Fold: 5  Epoch: 162  Training loss = 1.8326  Validation loss = 3.9705  \n",
      "\n",
      "Fold: 5  Epoch: 163  Training loss = 1.8324  Validation loss = 3.9700  \n",
      "\n",
      "Fold: 5  Epoch: 164  Training loss = 1.8321  Validation loss = 3.9687  \n",
      "\n",
      "Fold: 5  Epoch: 165  Training loss = 1.8319  Validation loss = 3.9681  \n",
      "\n",
      "Fold: 5  Epoch: 166  Training loss = 1.8317  Validation loss = 3.9676  \n",
      "\n",
      "Fold: 5  Epoch: 167  Training loss = 1.8314  Validation loss = 3.9667  \n",
      "\n",
      "Fold: 5  Epoch: 168  Training loss = 1.8312  Validation loss = 3.9660  \n",
      "\n",
      "Fold: 5  Epoch: 169  Training loss = 1.8311  Validation loss = 3.9656  \n",
      "\n",
      "Fold: 5  Epoch: 170  Training loss = 1.8308  Validation loss = 3.9648  \n",
      "\n",
      "Fold: 5  Epoch: 171  Training loss = 1.8307  Validation loss = 3.9642  \n",
      "\n",
      "Fold: 5  Epoch: 172  Training loss = 1.8303  Validation loss = 3.9629  \n",
      "\n",
      "Fold: 5  Epoch: 173  Training loss = 1.8302  Validation loss = 3.9625  \n",
      "\n",
      "Fold: 5  Epoch: 174  Training loss = 1.8299  Validation loss = 3.9614  \n",
      "\n",
      "Fold: 5  Epoch: 175  Training loss = 1.8296  Validation loss = 3.9604  \n",
      "\n",
      "Fold: 5  Epoch: 176  Training loss = 1.8295  Validation loss = 3.9601  \n",
      "\n",
      "Fold: 5  Epoch: 177  Training loss = 1.8292  Validation loss = 3.9592  \n",
      "\n",
      "Fold: 5  Epoch: 178  Training loss = 1.8291  Validation loss = 3.9590  \n",
      "\n",
      "Fold: 5  Epoch: 179  Training loss = 1.8290  Validation loss = 3.9588  \n",
      "\n",
      "Fold: 5  Epoch: 180  Training loss = 1.8287  Validation loss = 3.9578  \n",
      "\n",
      "Fold: 5  Epoch: 181  Training loss = 1.8285  Validation loss = 3.9572  \n",
      "\n",
      "Fold: 5  Epoch: 182  Training loss = 1.8283  Validation loss = 3.9568  \n",
      "\n",
      "Fold: 5  Epoch: 183  Training loss = 1.8281  Validation loss = 3.9562  \n",
      "\n",
      "Fold: 5  Epoch: 184  Training loss = 1.8279  Validation loss = 3.9553  \n",
      "\n",
      "Fold: 5  Epoch: 185  Training loss = 1.8276  Validation loss = 3.9542  \n",
      "\n",
      "Fold: 5  Epoch: 186  Training loss = 1.8274  Validation loss = 3.9534  \n",
      "\n",
      "Fold: 5  Epoch: 187  Training loss = 1.8273  Validation loss = 3.9531  \n",
      "\n",
      "Fold: 5  Epoch: 188  Training loss = 1.8270  Validation loss = 3.9525  \n",
      "\n",
      "Fold: 5  Epoch: 189  Training loss = 1.8268  Validation loss = 3.9518  \n",
      "\n",
      "Fold: 5  Epoch: 190  Training loss = 1.8267  Validation loss = 3.9518  \n",
      "\n",
      "Fold: 5  Epoch: 191  Training loss = 1.8265  Validation loss = 3.9511  \n",
      "\n",
      "Fold: 5  Epoch: 192  Training loss = 1.8262  Validation loss = 3.9499  \n",
      "\n",
      "Fold: 5  Epoch: 193  Training loss = 1.8259  Validation loss = 3.9487  \n",
      "\n",
      "Fold: 5  Epoch: 194  Training loss = 1.8257  Validation loss = 3.9483  \n",
      "\n",
      "Fold: 5  Epoch: 195  Training loss = 1.8255  Validation loss = 3.9479  \n",
      "\n",
      "Fold: 5  Epoch: 196  Training loss = 1.8254  Validation loss = 3.9476  \n",
      "\n",
      "Fold: 5  Epoch: 197  Training loss = 1.8251  Validation loss = 3.9468  \n",
      "\n",
      "Fold: 5  Epoch: 198  Training loss = 1.8248  Validation loss = 3.9456  \n",
      "\n",
      "Fold: 5  Epoch: 199  Training loss = 1.8247  Validation loss = 3.9454  \n",
      "\n",
      "Fold: 5  Epoch: 200  Training loss = 1.8245  Validation loss = 3.9448  \n",
      "\n",
      "Fold: 5  Epoch: 201  Training loss = 1.8242  Validation loss = 3.9440  \n",
      "\n",
      "Fold: 5  Epoch: 202  Training loss = 1.8240  Validation loss = 3.9430  \n",
      "\n",
      "Fold: 5  Epoch: 203  Training loss = 1.8238  Validation loss = 3.9422  \n",
      "\n",
      "Fold: 5  Epoch: 204  Training loss = 1.8237  Validation loss = 3.9420  \n",
      "\n",
      "Fold: 5  Epoch: 205  Training loss = 1.8235  Validation loss = 3.9415  \n",
      "\n",
      "Fold: 5  Epoch: 206  Training loss = 1.8233  Validation loss = 3.9410  \n",
      "\n",
      "Fold: 5  Epoch: 207  Training loss = 1.8231  Validation loss = 3.9404  \n",
      "\n",
      "Fold: 5  Epoch: 208  Training loss = 1.8229  Validation loss = 3.9397  \n",
      "\n",
      "Fold: 5  Epoch: 209  Training loss = 1.8227  Validation loss = 3.9389  \n",
      "\n",
      "Fold: 5  Epoch: 210  Training loss = 1.8225  Validation loss = 3.9386  \n",
      "\n",
      "Fold: 5  Epoch: 211  Training loss = 1.8223  Validation loss = 3.9382  \n",
      "\n",
      "Fold: 5  Epoch: 212  Training loss = 1.8221  Validation loss = 3.9375  \n",
      "\n",
      "Fold: 5  Epoch: 213  Training loss = 1.8220  Validation loss = 3.9374  \n",
      "\n",
      "Fold: 5  Epoch: 214  Training loss = 1.8217  Validation loss = 3.9364  \n",
      "\n",
      "Fold: 5  Epoch: 215  Training loss = 1.8214  Validation loss = 3.9353  \n",
      "\n",
      "Fold: 5  Epoch: 216  Training loss = 1.8212  Validation loss = 3.9347  \n",
      "\n",
      "Fold: 5  Epoch: 217  Training loss = 1.8209  Validation loss = 3.9335  \n",
      "\n",
      "Fold: 5  Epoch: 218  Training loss = 1.8206  Validation loss = 3.9330  \n",
      "\n",
      "Fold: 5  Epoch: 219  Training loss = 1.8203  Validation loss = 3.9320  \n",
      "\n",
      "Fold: 5  Epoch: 220  Training loss = 1.8202  Validation loss = 3.9314  \n",
      "\n",
      "Fold: 5  Epoch: 221  Training loss = 1.8200  Validation loss = 3.9311  \n",
      "\n",
      "Fold: 5  Epoch: 222  Training loss = 1.8198  Validation loss = 3.9302  \n",
      "\n",
      "Fold: 5  Epoch: 223  Training loss = 1.8196  Validation loss = 3.9296  \n",
      "\n",
      "Fold: 5  Epoch: 224  Training loss = 1.8194  Validation loss = 3.9290  \n",
      "\n",
      "Fold: 5  Epoch: 225  Training loss = 1.8193  Validation loss = 3.9288  \n",
      "\n",
      "Fold: 5  Epoch: 226  Training loss = 1.8190  Validation loss = 3.9277  \n",
      "\n",
      "Fold: 5  Epoch: 227  Training loss = 1.8187  Validation loss = 3.9263  \n",
      "\n",
      "Fold: 5  Epoch: 228  Training loss = 1.8185  Validation loss = 3.9260  \n",
      "\n",
      "Fold: 5  Epoch: 229  Training loss = 1.8184  Validation loss = 3.9259  \n",
      "\n",
      "Fold: 5  Epoch: 230  Training loss = 1.8181  Validation loss = 3.9252  \n",
      "\n",
      "Fold: 5  Epoch: 231  Training loss = 1.8179  Validation loss = 3.9248  \n",
      "\n",
      "Fold: 5  Epoch: 232  Training loss = 1.8178  Validation loss = 3.9248  \n",
      "\n",
      "Fold: 5  Epoch: 233  Training loss = 1.8176  Validation loss = 3.9242  \n",
      "\n",
      "Fold: 5  Epoch: 234  Training loss = 1.8174  Validation loss = 3.9239  \n",
      "\n",
      "Fold: 5  Epoch: 235  Training loss = 1.8173  Validation loss = 3.9235  \n",
      "\n",
      "Fold: 5  Epoch: 236  Training loss = 1.8171  Validation loss = 3.9228  \n",
      "\n",
      "Fold: 5  Epoch: 237  Training loss = 1.8168  Validation loss = 3.9218  \n",
      "\n",
      "Fold: 5  Epoch: 238  Training loss = 1.8166  Validation loss = 3.9213  \n",
      "\n",
      "Fold: 5  Epoch: 239  Training loss = 1.8164  Validation loss = 3.9207  \n",
      "\n",
      "Fold: 5  Epoch: 240  Training loss = 1.8162  Validation loss = 3.9202  \n",
      "\n",
      "Fold: 5  Epoch: 241  Training loss = 1.8160  Validation loss = 3.9197  \n",
      "\n",
      "Fold: 5  Epoch: 242  Training loss = 1.8158  Validation loss = 3.9193  \n",
      "\n",
      "Fold: 5  Epoch: 243  Training loss = 1.8155  Validation loss = 3.9180  \n",
      "\n",
      "Fold: 5  Epoch: 244  Training loss = 1.8152  Validation loss = 3.9169  \n",
      "\n",
      "Fold: 5  Epoch: 245  Training loss = 1.8151  Validation loss = 3.9170  \n",
      "\n",
      "Fold: 5  Epoch: 246  Training loss = 1.8148  Validation loss = 3.9160  \n",
      "\n",
      "Fold: 5  Epoch: 247  Training loss = 1.8145  Validation loss = 3.9153  \n",
      "\n",
      "Fold: 5  Epoch: 248  Training loss = 1.8143  Validation loss = 3.9150  \n",
      "\n",
      "Fold: 5  Epoch: 249  Training loss = 1.8141  Validation loss = 3.9140  \n",
      "\n",
      "Fold: 5  Epoch: 250  Training loss = 1.8139  Validation loss = 3.9131  \n",
      "\n",
      "Fold: 5  Epoch: 251  Training loss = 1.8136  Validation loss = 3.9123  \n",
      "\n",
      "Fold: 5  Epoch: 252  Training loss = 1.8135  Validation loss = 3.9120  \n",
      "\n",
      "Fold: 5  Epoch: 253  Training loss = 1.8133  Validation loss = 3.9116  \n",
      "\n",
      "Fold: 5  Epoch: 254  Training loss = 1.8131  Validation loss = 3.9111  \n",
      "\n",
      "Fold: 5  Epoch: 255  Training loss = 1.8129  Validation loss = 3.9105  \n",
      "\n",
      "Fold: 5  Epoch: 256  Training loss = 1.8126  Validation loss = 3.9094  \n",
      "\n",
      "Fold: 5  Epoch: 257  Training loss = 1.8124  Validation loss = 3.9084  \n",
      "\n",
      "Fold: 5  Epoch: 258  Training loss = 1.8122  Validation loss = 3.9076  \n",
      "\n",
      "Fold: 5  Epoch: 259  Training loss = 1.8119  Validation loss = 3.9067  \n",
      "\n",
      "Fold: 5  Epoch: 260  Training loss = 1.8117  Validation loss = 3.9060  \n",
      "\n",
      "Fold: 5  Epoch: 261  Training loss = 1.8114  Validation loss = 3.9046  \n",
      "\n",
      "Fold: 5  Epoch: 262  Training loss = 1.8112  Validation loss = 3.9037  \n",
      "\n",
      "Fold: 5  Epoch: 263  Training loss = 1.8110  Validation loss = 3.9031  \n",
      "\n",
      "Fold: 5  Epoch: 264  Training loss = 1.8107  Validation loss = 3.9022  \n",
      "\n",
      "Fold: 5  Epoch: 265  Training loss = 1.8105  Validation loss = 3.9014  \n",
      "\n",
      "Fold: 5  Epoch: 266  Training loss = 1.8102  Validation loss = 3.9007  \n",
      "\n",
      "Fold: 5  Epoch: 267  Training loss = 1.8101  Validation loss = 3.9006  \n",
      "\n",
      "Fold: 5  Epoch: 268  Training loss = 1.8099  Validation loss = 3.8999  \n",
      "\n",
      "Fold: 5  Epoch: 269  Training loss = 1.8097  Validation loss = 3.8993  \n",
      "\n",
      "Fold: 5  Epoch: 270  Training loss = 1.8095  Validation loss = 3.8987  \n",
      "\n",
      "Fold: 5  Epoch: 271  Training loss = 1.8093  Validation loss = 3.8981  \n",
      "\n",
      "Fold: 5  Epoch: 272  Training loss = 1.8091  Validation loss = 3.8972  \n",
      "\n",
      "Fold: 5  Epoch: 273  Training loss = 1.8090  Validation loss = 3.8969  \n",
      "\n",
      "Fold: 5  Epoch: 274  Training loss = 1.8089  Validation loss = 3.8966  \n",
      "\n",
      "Fold: 5  Epoch: 275  Training loss = 1.8085  Validation loss = 3.8950  \n",
      "\n",
      "Fold: 5  Epoch: 276  Training loss = 1.8083  Validation loss = 3.8943  \n",
      "\n",
      "Fold: 5  Epoch: 277  Training loss = 1.8080  Validation loss = 3.8936  \n",
      "\n",
      "Fold: 5  Epoch: 278  Training loss = 1.8077  Validation loss = 3.8924  \n",
      "\n",
      "Fold: 5  Epoch: 279  Training loss = 1.8074  Validation loss = 3.8916  \n",
      "\n",
      "Fold: 5  Epoch: 280  Training loss = 1.8071  Validation loss = 3.8905  \n",
      "\n",
      "Fold: 5  Epoch: 281  Training loss = 1.8070  Validation loss = 3.8902  \n",
      "\n",
      "Fold: 5  Epoch: 282  Training loss = 1.8068  Validation loss = 3.8899  \n",
      "\n",
      "Fold: 5  Epoch: 283  Training loss = 1.8066  Validation loss = 3.8897  \n",
      "\n",
      "Fold: 5  Epoch: 284  Training loss = 1.8064  Validation loss = 3.8889  \n",
      "\n",
      "Fold: 5  Epoch: 285  Training loss = 1.8061  Validation loss = 3.8877  \n",
      "\n",
      "Fold: 5  Epoch: 286  Training loss = 1.8058  Validation loss = 3.8871  \n",
      "\n",
      "Fold: 5  Epoch: 287  Training loss = 1.8057  Validation loss = 3.8866  \n",
      "\n",
      "Fold: 5  Epoch: 288  Training loss = 1.8054  Validation loss = 3.8857  \n",
      "\n",
      "Fold: 5  Epoch: 289  Training loss = 1.8052  Validation loss = 3.8849  \n",
      "\n",
      "Fold: 5  Epoch: 290  Training loss = 1.8049  Validation loss = 3.8842  \n",
      "\n",
      "Fold: 5  Epoch: 291  Training loss = 1.8047  Validation loss = 3.8839  \n",
      "\n",
      "Fold: 5  Epoch: 292  Training loss = 1.8045  Validation loss = 3.8833  \n",
      "\n",
      "Fold: 5  Epoch: 293  Training loss = 1.8041  Validation loss = 3.8819  \n",
      "\n",
      "Fold: 5  Epoch: 294  Training loss = 1.8040  Validation loss = 3.8818  \n",
      "\n",
      "Fold: 5  Epoch: 295  Training loss = 1.8038  Validation loss = 3.8811  \n",
      "\n",
      "Fold: 5  Epoch: 296  Training loss = 1.8036  Validation loss = 3.8805  \n",
      "\n",
      "Fold: 5  Epoch: 297  Training loss = 1.8034  Validation loss = 3.8801  \n",
      "\n",
      "Fold: 5  Epoch: 298  Training loss = 1.8032  Validation loss = 3.8790  \n",
      "\n",
      "Fold: 5  Epoch: 299  Training loss = 1.8030  Validation loss = 3.8784  \n",
      "\n",
      "Fold: 5  Epoch: 300  Training loss = 1.8028  Validation loss = 3.8780  \n",
      "\n",
      "Fold: 5  Epoch: 301  Training loss = 1.8025  Validation loss = 3.8772  \n",
      "\n",
      "Fold: 5  Epoch: 302  Training loss = 1.8024  Validation loss = 3.8770  \n",
      "\n",
      "Fold: 5  Epoch: 303  Training loss = 1.8022  Validation loss = 3.8766  \n",
      "\n",
      "Fold: 5  Epoch: 304  Training loss = 1.8020  Validation loss = 3.8756  \n",
      "\n",
      "Fold: 5  Epoch: 305  Training loss = 1.8018  Validation loss = 3.8755  \n",
      "\n",
      "Fold: 5  Epoch: 306  Training loss = 1.8016  Validation loss = 3.8746  \n",
      "\n",
      "Fold: 5  Epoch: 307  Training loss = 1.8013  Validation loss = 3.8738  \n",
      "\n",
      "Fold: 5  Epoch: 308  Training loss = 1.8011  Validation loss = 3.8734  \n",
      "\n",
      "Fold: 5  Epoch: 309  Training loss = 1.8010  Validation loss = 3.8729  \n",
      "\n",
      "Fold: 5  Epoch: 310  Training loss = 1.8008  Validation loss = 3.8724  \n",
      "\n",
      "Fold: 5  Epoch: 311  Training loss = 1.8006  Validation loss = 3.8720  \n",
      "\n",
      "Fold: 5  Epoch: 312  Training loss = 1.8003  Validation loss = 3.8708  \n",
      "\n",
      "Fold: 5  Epoch: 313  Training loss = 1.8001  Validation loss = 3.8704  \n",
      "\n",
      "Fold: 5  Epoch: 314  Training loss = 1.8000  Validation loss = 3.8703  \n",
      "\n",
      "Fold: 5  Epoch: 315  Training loss = 1.7998  Validation loss = 3.8699  \n",
      "\n",
      "Fold: 5  Epoch: 316  Training loss = 1.7995  Validation loss = 3.8688  \n",
      "\n",
      "Fold: 5  Epoch: 317  Training loss = 1.7993  Validation loss = 3.8682  \n",
      "\n",
      "Fold: 5  Epoch: 318  Training loss = 1.7992  Validation loss = 3.8681  \n",
      "\n",
      "Fold: 5  Epoch: 319  Training loss = 1.7990  Validation loss = 3.8676  \n",
      "\n",
      "Fold: 5  Epoch: 320  Training loss = 1.7987  Validation loss = 3.8665  \n",
      "\n",
      "Fold: 5  Epoch: 321  Training loss = 1.7985  Validation loss = 3.8658  \n",
      "\n",
      "Fold: 5  Epoch: 322  Training loss = 1.7983  Validation loss = 3.8654  \n",
      "\n",
      "Fold: 5  Epoch: 323  Training loss = 1.7980  Validation loss = 3.8647  \n",
      "\n",
      "Fold: 5  Epoch: 324  Training loss = 1.7978  Validation loss = 3.8637  \n",
      "\n",
      "Fold: 5  Epoch: 325  Training loss = 1.7976  Validation loss = 3.8629  \n",
      "\n",
      "Fold: 5  Epoch: 326  Training loss = 1.7973  Validation loss = 3.8619  \n",
      "\n",
      "Fold: 5  Epoch: 327  Training loss = 1.7971  Validation loss = 3.8614  \n",
      "\n",
      "Fold: 5  Epoch: 328  Training loss = 1.7969  Validation loss = 3.8606  \n",
      "\n",
      "Fold: 5  Epoch: 329  Training loss = 1.7966  Validation loss = 3.8599  \n",
      "\n",
      "Fold: 5  Epoch: 330  Training loss = 1.7963  Validation loss = 3.8589  \n",
      "\n",
      "Fold: 5  Epoch: 331  Training loss = 1.7960  Validation loss = 3.8576  \n",
      "\n",
      "Fold: 5  Epoch: 332  Training loss = 1.7959  Validation loss = 3.8575  \n",
      "\n",
      "Fold: 5  Epoch: 333  Training loss = 1.7957  Validation loss = 3.8570  \n",
      "\n",
      "Fold: 5  Epoch: 334  Training loss = 1.7955  Validation loss = 3.8565  \n",
      "\n",
      "Fold: 5  Epoch: 335  Training loss = 1.7953  Validation loss = 3.8565  \n",
      "\n",
      "Fold: 5  Epoch: 336  Training loss = 1.7950  Validation loss = 3.8552  \n",
      "\n",
      "Fold: 5  Epoch: 337  Training loss = 1.7948  Validation loss = 3.8547  \n",
      "\n",
      "Fold: 5  Epoch: 338  Training loss = 1.7945  Validation loss = 3.8541  \n",
      "\n",
      "Fold: 5  Epoch: 339  Training loss = 1.7944  Validation loss = 3.8536  \n",
      "\n",
      "Fold: 5  Epoch: 340  Training loss = 1.7942  Validation loss = 3.8532  \n",
      "\n",
      "Fold: 5  Epoch: 341  Training loss = 1.7939  Validation loss = 3.8518  \n",
      "\n",
      "Fold: 5  Epoch: 342  Training loss = 1.7937  Validation loss = 3.8512  \n",
      "\n",
      "Fold: 5  Epoch: 343  Training loss = 1.7935  Validation loss = 3.8512  \n",
      "\n",
      "Fold: 5  Epoch: 344  Training loss = 1.7933  Validation loss = 3.8501  \n",
      "\n",
      "Fold: 5  Epoch: 345  Training loss = 1.7930  Validation loss = 3.8497  \n",
      "\n",
      "Fold: 5  Epoch: 346  Training loss = 1.7928  Validation loss = 3.8488  \n",
      "\n",
      "Fold: 5  Epoch: 347  Training loss = 1.7926  Validation loss = 3.8483  \n",
      "\n",
      "Fold: 5  Epoch: 348  Training loss = 1.7923  Validation loss = 3.8469  \n",
      "\n",
      "Fold: 5  Epoch: 349  Training loss = 1.7919  Validation loss = 3.8457  \n",
      "\n",
      "Fold: 5  Epoch: 350  Training loss = 1.7918  Validation loss = 3.8457  \n",
      "\n",
      "Fold: 5  Epoch: 351  Training loss = 1.7916  Validation loss = 3.8454  \n",
      "\n",
      "Fold: 5  Epoch: 352  Training loss = 1.7914  Validation loss = 3.8450  \n",
      "\n",
      "Fold: 5  Epoch: 353  Training loss = 1.7914  Validation loss = 3.8454  \n",
      "\n",
      "Fold: 5  Epoch: 354  Training loss = 1.7911  Validation loss = 3.8446  \n",
      "\n",
      "Fold: 5  Epoch: 355  Training loss = 1.7910  Validation loss = 3.8442  \n",
      "\n",
      "Fold: 5  Epoch: 356  Training loss = 1.7907  Validation loss = 3.8437  \n",
      "\n",
      "Fold: 5  Epoch: 357  Training loss = 1.7905  Validation loss = 3.8435  \n",
      "\n",
      "Fold: 5  Epoch: 358  Training loss = 1.7904  Validation loss = 3.8430  \n",
      "\n",
      "Fold: 5  Epoch: 359  Training loss = 1.7902  Validation loss = 3.8422  \n",
      "\n",
      "Fold: 5  Epoch: 360  Training loss = 1.7900  Validation loss = 3.8418  \n",
      "\n",
      "Fold: 5  Epoch: 361  Training loss = 1.7897  Validation loss = 3.8403  \n",
      "\n",
      "Fold: 5  Epoch: 362  Training loss = 1.7895  Validation loss = 3.8396  \n",
      "\n",
      "Fold: 5  Epoch: 363  Training loss = 1.7893  Validation loss = 3.8390  \n",
      "\n",
      "Fold: 5  Epoch: 364  Training loss = 1.7891  Validation loss = 3.8387  \n",
      "\n",
      "Fold: 5  Epoch: 365  Training loss = 1.7889  Validation loss = 3.8384  \n",
      "\n",
      "Fold: 5  Epoch: 366  Training loss = 1.7886  Validation loss = 3.8375  \n",
      "\n",
      "Fold: 5  Epoch: 367  Training loss = 1.7885  Validation loss = 3.8376  \n",
      "\n",
      "Fold: 5  Epoch: 368  Training loss = 1.7883  Validation loss = 3.8371  \n",
      "\n",
      "Fold: 5  Epoch: 369  Training loss = 1.7881  Validation loss = 3.8366  \n",
      "\n",
      "Fold: 5  Epoch: 370  Training loss = 1.7880  Validation loss = 3.8357  \n",
      "\n",
      "Fold: 5  Epoch: 371  Training loss = 1.7878  Validation loss = 3.8355  \n",
      "\n",
      "Fold: 5  Epoch: 372  Training loss = 1.7875  Validation loss = 3.8346  \n",
      "\n",
      "Fold: 5  Epoch: 373  Training loss = 1.7873  Validation loss = 3.8341  \n",
      "\n",
      "Fold: 5  Epoch: 374  Training loss = 1.7871  Validation loss = 3.8334  \n",
      "\n",
      "Fold: 5  Epoch: 375  Training loss = 1.7870  Validation loss = 3.8337  \n",
      "\n",
      "Fold: 5  Epoch: 376  Training loss = 1.7868  Validation loss = 3.8335  \n",
      "\n",
      "Fold: 5  Epoch: 377  Training loss = 1.7865  Validation loss = 3.8326  \n",
      "\n",
      "Fold: 5  Epoch: 378  Training loss = 1.7862  Validation loss = 3.8315  \n",
      "\n",
      "Fold: 5  Epoch: 379  Training loss = 1.7860  Validation loss = 3.8308  \n",
      "\n",
      "Fold: 5  Epoch: 380  Training loss = 1.7857  Validation loss = 3.8294  \n",
      "\n",
      "Fold: 5  Epoch: 381  Training loss = 1.7855  Validation loss = 3.8288  \n",
      "\n",
      "Fold: 5  Epoch: 382  Training loss = 1.7853  Validation loss = 3.8283  \n",
      "\n",
      "Fold: 5  Epoch: 383  Training loss = 1.7851  Validation loss = 3.8279  \n",
      "\n",
      "Fold: 5  Epoch: 384  Training loss = 1.7849  Validation loss = 3.8274  \n",
      "\n",
      "Fold: 5  Epoch: 385  Training loss = 1.7847  Validation loss = 3.8270  \n",
      "\n",
      "Fold: 5  Epoch: 386  Training loss = 1.7845  Validation loss = 3.8264  \n",
      "\n",
      "Fold: 5  Epoch: 387  Training loss = 1.7842  Validation loss = 3.8259  \n",
      "\n",
      "Fold: 5  Epoch: 388  Training loss = 1.7840  Validation loss = 3.8257  \n",
      "\n",
      "Fold: 5  Epoch: 389  Training loss = 1.7837  Validation loss = 3.8246  \n",
      "\n",
      "Fold: 5  Epoch: 390  Training loss = 1.7835  Validation loss = 3.8243  \n",
      "\n",
      "Fold: 5  Epoch: 391  Training loss = 1.7834  Validation loss = 3.8243  \n",
      "\n",
      "Fold: 5  Epoch: 392  Training loss = 1.7831  Validation loss = 3.8232  \n",
      "\n",
      "Fold: 5  Epoch: 393  Training loss = 1.7828  Validation loss = 3.8220  \n",
      "\n",
      "Fold: 5  Epoch: 394  Training loss = 1.7826  Validation loss = 3.8213  \n",
      "\n",
      "Fold: 5  Epoch: 395  Training loss = 1.7824  Validation loss = 3.8206  \n",
      "\n",
      "Fold: 5  Epoch: 396  Training loss = 1.7821  Validation loss = 3.8198  \n",
      "\n",
      "Fold: 5  Epoch: 397  Training loss = 1.7819  Validation loss = 3.8191  \n",
      "\n",
      "Fold: 5  Epoch: 398  Training loss = 1.7817  Validation loss = 3.8182  \n",
      "\n",
      "Fold: 5  Epoch: 399  Training loss = 1.7816  Validation loss = 3.8182  \n",
      "\n",
      "Fold: 5  Epoch: 400  Training loss = 1.7813  Validation loss = 3.8171  \n",
      "\n",
      "Fold: 5  Epoch: 401  Training loss = 1.7811  Validation loss = 3.8170  \n",
      "\n",
      "Fold: 5  Epoch: 402  Training loss = 1.7810  Validation loss = 3.8167  \n",
      "\n",
      "Fold: 5  Epoch: 403  Training loss = 1.7808  Validation loss = 3.8161  \n",
      "\n",
      "Fold: 5  Epoch: 404  Training loss = 1.7806  Validation loss = 3.8155  \n",
      "\n",
      "Fold: 5  Epoch: 405  Training loss = 1.7804  Validation loss = 3.8150  \n",
      "\n",
      "Fold: 5  Epoch: 406  Training loss = 1.7802  Validation loss = 3.8145  \n",
      "\n",
      "Fold: 5  Epoch: 407  Training loss = 1.7799  Validation loss = 3.8133  \n",
      "\n",
      "Fold: 5  Epoch: 408  Training loss = 1.7797  Validation loss = 3.8134  \n",
      "\n",
      "Fold: 5  Epoch: 409  Training loss = 1.7795  Validation loss = 3.8125  \n",
      "\n",
      "Fold: 5  Epoch: 410  Training loss = 1.7793  Validation loss = 3.8123  \n",
      "\n",
      "Fold: 5  Epoch: 411  Training loss = 1.7791  Validation loss = 3.8116  \n",
      "\n",
      "Fold: 5  Epoch: 412  Training loss = 1.7789  Validation loss = 3.8112  \n",
      "\n",
      "Fold: 5  Epoch: 413  Training loss = 1.7787  Validation loss = 3.8105  \n",
      "\n",
      "Fold: 5  Epoch: 414  Training loss = 1.7785  Validation loss = 3.8100  \n",
      "\n",
      "Fold: 5  Epoch: 415  Training loss = 1.7784  Validation loss = 3.8097  \n",
      "\n",
      "Fold: 5  Epoch: 416  Training loss = 1.7781  Validation loss = 3.8084  \n",
      "\n",
      "Fold: 5  Epoch: 417  Training loss = 1.7779  Validation loss = 3.8086  \n",
      "\n",
      "Fold: 5  Epoch: 418  Training loss = 1.7776  Validation loss = 3.8076  \n",
      "\n",
      "Fold: 5  Epoch: 419  Training loss = 1.7774  Validation loss = 3.8080  \n",
      "\n",
      "Fold: 5  Epoch: 420  Training loss = 1.7772  Validation loss = 3.8082  \n",
      "\n",
      "Fold: 5  Epoch: 421  Training loss = 1.7770  Validation loss = 3.8078  \n",
      "\n",
      "Fold: 5  Epoch: 422  Training loss = 1.7767  Validation loss = 3.8070  \n",
      "\n",
      "Fold: 5  Epoch: 423  Training loss = 1.7764  Validation loss = 3.8060  \n",
      "\n",
      "Fold: 5  Epoch: 424  Training loss = 1.7762  Validation loss = 3.8056  \n",
      "\n",
      "Fold: 5  Epoch: 425  Training loss = 1.7759  Validation loss = 3.8046  \n",
      "\n",
      "Fold: 5  Epoch: 426  Training loss = 1.7757  Validation loss = 3.8046  \n",
      "\n",
      "Fold: 5  Epoch: 427  Training loss = 1.7755  Validation loss = 3.8050  \n",
      "\n",
      "Fold: 5  Epoch: 428  Training loss = 1.7752  Validation loss = 3.8036  \n",
      "\n",
      "Fold: 5  Epoch: 429  Training loss = 1.7750  Validation loss = 3.8027  \n",
      "\n",
      "Fold: 5  Epoch: 430  Training loss = 1.7749  Validation loss = 3.8020  \n",
      "\n",
      "Fold: 5  Epoch: 431  Training loss = 1.7746  Validation loss = 3.8017  \n",
      "\n",
      "Fold: 5  Epoch: 432  Training loss = 1.7745  Validation loss = 3.8015  \n",
      "\n",
      "Fold: 5  Epoch: 433  Training loss = 1.7742  Validation loss = 3.8006  \n",
      "\n",
      "Fold: 5  Epoch: 434  Training loss = 1.7741  Validation loss = 3.8008  \n",
      "\n",
      "Fold: 5  Epoch: 435  Training loss = 1.7739  Validation loss = 3.7997  \n",
      "\n",
      "Fold: 5  Epoch: 436  Training loss = 1.7736  Validation loss = 3.7986  \n",
      "\n",
      "Fold: 5  Epoch: 437  Training loss = 1.7734  Validation loss = 3.7986  \n",
      "\n",
      "Fold: 5  Epoch: 438  Training loss = 1.7732  Validation loss = 3.7977  \n",
      "\n",
      "Fold: 5  Epoch: 439  Training loss = 1.7730  Validation loss = 3.7969  \n",
      "\n",
      "Fold: 5  Epoch: 440  Training loss = 1.7728  Validation loss = 3.7966  \n",
      "\n",
      "Fold: 5  Epoch: 441  Training loss = 1.7724  Validation loss = 3.7951  \n",
      "\n",
      "Fold: 5  Epoch: 442  Training loss = 1.7721  Validation loss = 3.7941  \n",
      "\n",
      "Fold: 5  Epoch: 443  Training loss = 1.7718  Validation loss = 3.7926  \n",
      "\n",
      "Fold: 5  Epoch: 444  Training loss = 1.7715  Validation loss = 3.7922  \n",
      "\n",
      "Fold: 5  Epoch: 445  Training loss = 1.7712  Validation loss = 3.7916  \n",
      "\n",
      "Fold: 5  Epoch: 446  Training loss = 1.7710  Validation loss = 3.7911  \n",
      "\n",
      "Fold: 5  Epoch: 447  Training loss = 1.7709  Validation loss = 3.7908  \n",
      "\n",
      "Fold: 5  Epoch: 448  Training loss = 1.7707  Validation loss = 3.7906  \n",
      "\n",
      "Fold: 5  Epoch: 449  Training loss = 1.7705  Validation loss = 3.7901  \n",
      "\n",
      "Fold: 5  Epoch: 450  Training loss = 1.7702  Validation loss = 3.7890  \n",
      "\n",
      "Fold: 5  Epoch: 451  Training loss = 1.7700  Validation loss = 3.7880  \n",
      "\n",
      "Fold: 5  Epoch: 452  Training loss = 1.7698  Validation loss = 3.7874  \n",
      "\n",
      "Fold: 5  Epoch: 453  Training loss = 1.7695  Validation loss = 3.7861  \n",
      "\n",
      "Fold: 5  Epoch: 454  Training loss = 1.7693  Validation loss = 3.7855  \n",
      "\n",
      "Fold: 5  Epoch: 455  Training loss = 1.7691  Validation loss = 3.7849  \n",
      "\n",
      "Fold: 5  Epoch: 456  Training loss = 1.7690  Validation loss = 3.7851  \n",
      "\n",
      "Fold: 5  Epoch: 457  Training loss = 1.7687  Validation loss = 3.7838  \n",
      "\n",
      "Fold: 5  Epoch: 458  Training loss = 1.7684  Validation loss = 3.7829  \n",
      "\n",
      "Fold: 5  Epoch: 459  Training loss = 1.7682  Validation loss = 3.7820  \n",
      "\n",
      "Fold: 5  Epoch: 460  Training loss = 1.7679  Validation loss = 3.7818  \n",
      "\n",
      "Fold: 5  Epoch: 461  Training loss = 1.7677  Validation loss = 3.7811  \n",
      "\n",
      "Fold: 5  Epoch: 462  Training loss = 1.7674  Validation loss = 3.7809  \n",
      "\n",
      "Fold: 5  Epoch: 463  Training loss = 1.7672  Validation loss = 3.7802  \n",
      "\n",
      "Fold: 5  Epoch: 464  Training loss = 1.7670  Validation loss = 3.7801  \n",
      "\n",
      "Fold: 5  Epoch: 465  Training loss = 1.7668  Validation loss = 3.7799  \n",
      "\n",
      "Fold: 5  Epoch: 466  Training loss = 1.7666  Validation loss = 3.7793  \n",
      "\n",
      "Fold: 5  Epoch: 467  Training loss = 1.7663  Validation loss = 3.7782  \n",
      "\n",
      "Fold: 5  Epoch: 468  Training loss = 1.7661  Validation loss = 3.7766  \n",
      "\n",
      "Fold: 5  Epoch: 469  Training loss = 1.7659  Validation loss = 3.7765  \n",
      "\n",
      "Fold: 5  Epoch: 470  Training loss = 1.7657  Validation loss = 3.7758  \n",
      "\n",
      "Fold: 5  Epoch: 471  Training loss = 1.7654  Validation loss = 3.7752  \n",
      "\n",
      "Fold: 5  Epoch: 472  Training loss = 1.7651  Validation loss = 3.7746  \n",
      "\n",
      "Fold: 5  Epoch: 473  Training loss = 1.7649  Validation loss = 3.7740  \n",
      "\n",
      "Fold: 5  Epoch: 474  Training loss = 1.7646  Validation loss = 3.7734  \n",
      "\n",
      "Fold: 5  Epoch: 475  Training loss = 1.7644  Validation loss = 3.7733  \n",
      "\n",
      "Fold: 5  Epoch: 476  Training loss = 1.7641  Validation loss = 3.7721  \n",
      "\n",
      "Fold: 5  Epoch: 477  Training loss = 1.7639  Validation loss = 3.7717  \n",
      "\n",
      "Fold: 5  Epoch: 478  Training loss = 1.7636  Validation loss = 3.7710  \n",
      "\n",
      "Fold: 5  Epoch: 479  Training loss = 1.7633  Validation loss = 3.7700  \n",
      "\n",
      "Fold: 5  Epoch: 480  Training loss = 1.7632  Validation loss = 3.7703  \n",
      "\n",
      "Fold: 5  Epoch: 481  Training loss = 1.7630  Validation loss = 3.7698  \n",
      "\n",
      "Fold: 5  Epoch: 482  Training loss = 1.7628  Validation loss = 3.7690  \n",
      "\n",
      "Fold: 5  Epoch: 483  Training loss = 1.7626  Validation loss = 3.7689  \n",
      "\n",
      "Fold: 5  Epoch: 484  Training loss = 1.7624  Validation loss = 3.7685  \n",
      "\n",
      "Fold: 5  Epoch: 485  Training loss = 1.7622  Validation loss = 3.7679  \n",
      "\n",
      "Fold: 5  Epoch: 486  Training loss = 1.7619  Validation loss = 3.7670  \n",
      "\n",
      "Fold: 5  Epoch: 487  Training loss = 1.7616  Validation loss = 3.7659  \n",
      "\n",
      "Fold: 5  Epoch: 488  Training loss = 1.7614  Validation loss = 3.7654  \n",
      "\n",
      "Fold: 5  Epoch: 489  Training loss = 1.7612  Validation loss = 3.7646  \n",
      "\n",
      "Fold: 5  Epoch: 490  Training loss = 1.7609  Validation loss = 3.7639  \n",
      "\n",
      "Fold: 5  Epoch: 491  Training loss = 1.7606  Validation loss = 3.7627  \n",
      "\n",
      "Fold: 5  Epoch: 492  Training loss = 1.7605  Validation loss = 3.7630  \n",
      "\n",
      "Fold: 5  Epoch: 493  Training loss = 1.7602  Validation loss = 3.7623  \n",
      "\n",
      "Fold: 5  Epoch: 494  Training loss = 1.7600  Validation loss = 3.7615  \n",
      "\n",
      "Fold: 5  Epoch: 495  Training loss = 1.7597  Validation loss = 3.7609  \n",
      "\n",
      "Fold: 5  Epoch: 496  Training loss = 1.7595  Validation loss = 3.7603  \n",
      "\n",
      "Fold: 5  Epoch: 497  Training loss = 1.7593  Validation loss = 3.7599  \n",
      "\n",
      "Fold: 5  Epoch: 498  Training loss = 1.7591  Validation loss = 3.7599  \n",
      "\n",
      "Fold: 5  Epoch: 499  Training loss = 1.7588  Validation loss = 3.7593  \n",
      "\n",
      "Fold: 5  Epoch: 500  Training loss = 1.7586  Validation loss = 3.7586  \n",
      "\n",
      "Check model:  Fold: 5  Optimal epoch: 500  \n",
      "\n",
      "Fold: 6  Epoch: 1  Training loss = 1.9651  Validation loss = 1.4661  \n",
      "\n",
      "Fold: 6  Epoch: 2  Training loss = 1.9645  Validation loss = 1.4643  \n",
      "\n",
      "Fold: 6  Epoch: 3  Training loss = 1.9641  Validation loss = 1.4636  \n",
      "\n",
      "Fold: 6  Epoch: 4  Training loss = 1.9636  Validation loss = 1.4627  \n",
      "\n",
      "Fold: 6  Epoch: 5  Training loss = 1.9630  Validation loss = 1.4610  \n",
      "\n",
      "Fold: 6  Epoch: 6  Training loss = 1.9625  Validation loss = 1.4601  \n",
      "\n",
      "Fold: 6  Epoch: 7  Training loss = 1.9620  Validation loss = 1.4586  \n",
      "\n",
      "Fold: 6  Epoch: 8  Training loss = 1.9614  Validation loss = 1.4570  \n",
      "\n",
      "Fold: 6  Epoch: 9  Training loss = 1.9608  Validation loss = 1.4554  \n",
      "\n",
      "Fold: 6  Epoch: 10  Training loss = 1.9603  Validation loss = 1.4540  \n",
      "\n",
      "Fold: 6  Epoch: 11  Training loss = 1.9599  Validation loss = 1.4529  \n",
      "\n",
      "Fold: 6  Epoch: 12  Training loss = 1.9592  Validation loss = 1.4512  \n",
      "\n",
      "Fold: 6  Epoch: 13  Training loss = 1.9586  Validation loss = 1.4492  \n",
      "\n",
      "Fold: 6  Epoch: 14  Training loss = 1.9581  Validation loss = 1.4482  \n",
      "\n",
      "Fold: 6  Epoch: 15  Training loss = 1.9576  Validation loss = 1.4467  \n",
      "\n",
      "Fold: 6  Epoch: 16  Training loss = 1.9571  Validation loss = 1.4456  \n",
      "\n",
      "Fold: 6  Epoch: 17  Training loss = 1.9566  Validation loss = 1.4447  \n",
      "\n",
      "Fold: 6  Epoch: 18  Training loss = 1.9560  Validation loss = 1.4430  \n",
      "\n",
      "Fold: 6  Epoch: 19  Training loss = 1.9557  Validation loss = 1.4422  \n",
      "\n",
      "Fold: 6  Epoch: 20  Training loss = 1.9553  Validation loss = 1.4415  \n",
      "\n",
      "Fold: 6  Epoch: 21  Training loss = 1.9547  Validation loss = 1.4401  \n",
      "\n",
      "Fold: 6  Epoch: 22  Training loss = 1.9543  Validation loss = 1.4391  \n",
      "\n",
      "Fold: 6  Epoch: 23  Training loss = 1.9541  Validation loss = 1.4388  \n",
      "\n",
      "Fold: 6  Epoch: 24  Training loss = 1.9535  Validation loss = 1.4372  \n",
      "\n",
      "Fold: 6  Epoch: 25  Training loss = 1.9530  Validation loss = 1.4364  \n",
      "\n",
      "Fold: 6  Epoch: 26  Training loss = 1.9527  Validation loss = 1.4356  \n",
      "\n",
      "Fold: 6  Epoch: 27  Training loss = 1.9521  Validation loss = 1.4342  \n",
      "\n",
      "Fold: 6  Epoch: 28  Training loss = 1.9516  Validation loss = 1.4328  \n",
      "\n",
      "Fold: 6  Epoch: 29  Training loss = 1.9511  Validation loss = 1.4315  \n",
      "\n",
      "Fold: 6  Epoch: 30  Training loss = 1.9506  Validation loss = 1.4305  \n",
      "\n",
      "Fold: 6  Epoch: 31  Training loss = 1.9502  Validation loss = 1.4299  \n",
      "\n",
      "Fold: 6  Epoch: 32  Training loss = 1.9497  Validation loss = 1.4290  \n",
      "\n",
      "Fold: 6  Epoch: 33  Training loss = 1.9494  Validation loss = 1.4284  \n",
      "\n",
      "Fold: 6  Epoch: 34  Training loss = 1.9489  Validation loss = 1.4270  \n",
      "\n",
      "Fold: 6  Epoch: 35  Training loss = 1.9485  Validation loss = 1.4263  \n",
      "\n",
      "Fold: 6  Epoch: 36  Training loss = 1.9482  Validation loss = 1.4260  \n",
      "\n",
      "Fold: 6  Epoch: 37  Training loss = 1.9476  Validation loss = 1.4246  \n",
      "\n",
      "Fold: 6  Epoch: 38  Training loss = 1.9472  Validation loss = 1.4241  \n",
      "\n",
      "Fold: 6  Epoch: 39  Training loss = 1.9467  Validation loss = 1.4226  \n",
      "\n",
      "Fold: 6  Epoch: 40  Training loss = 1.9465  Validation loss = 1.4223  \n",
      "\n",
      "Fold: 6  Epoch: 41  Training loss = 1.9461  Validation loss = 1.4217  \n",
      "\n",
      "Fold: 6  Epoch: 42  Training loss = 1.9458  Validation loss = 1.4217  \n",
      "\n",
      "Fold: 6  Epoch: 43  Training loss = 1.9453  Validation loss = 1.4208  \n",
      "\n",
      "Fold: 6  Epoch: 44  Training loss = 1.9447  Validation loss = 1.4189  \n",
      "\n",
      "Fold: 6  Epoch: 45  Training loss = 1.9442  Validation loss = 1.4179  \n",
      "\n",
      "Fold: 6  Epoch: 46  Training loss = 1.9437  Validation loss = 1.4162  \n",
      "\n",
      "Fold: 6  Epoch: 47  Training loss = 1.9431  Validation loss = 1.4149  \n",
      "\n",
      "Fold: 6  Epoch: 48  Training loss = 1.9423  Validation loss = 1.4128  \n",
      "\n",
      "Fold: 6  Epoch: 49  Training loss = 1.9418  Validation loss = 1.4115  \n",
      "\n",
      "Fold: 6  Epoch: 50  Training loss = 1.9413  Validation loss = 1.4104  \n",
      "\n",
      "Fold: 6  Epoch: 51  Training loss = 1.9408  Validation loss = 1.4089  \n",
      "\n",
      "Fold: 6  Epoch: 52  Training loss = 1.9404  Validation loss = 1.4078  \n",
      "\n",
      "Fold: 6  Epoch: 53  Training loss = 1.9400  Validation loss = 1.4069  \n",
      "\n",
      "Fold: 6  Epoch: 54  Training loss = 1.9396  Validation loss = 1.4064  \n",
      "\n",
      "Fold: 6  Epoch: 55  Training loss = 1.9390  Validation loss = 1.4052  \n",
      "\n",
      "Fold: 6  Epoch: 56  Training loss = 1.9387  Validation loss = 1.4045  \n",
      "\n",
      "Fold: 6  Epoch: 57  Training loss = 1.9383  Validation loss = 1.4035  \n",
      "\n",
      "Fold: 6  Epoch: 58  Training loss = 1.9377  Validation loss = 1.4021  \n",
      "\n",
      "Fold: 6  Epoch: 59  Training loss = 1.9374  Validation loss = 1.4012  \n",
      "\n",
      "Fold: 6  Epoch: 60  Training loss = 1.9369  Validation loss = 1.4000  \n",
      "\n",
      "Fold: 6  Epoch: 61  Training loss = 1.9364  Validation loss = 1.3988  \n",
      "\n",
      "Fold: 6  Epoch: 62  Training loss = 1.9359  Validation loss = 1.3973  \n",
      "\n",
      "Fold: 6  Epoch: 63  Training loss = 1.9353  Validation loss = 1.3954  \n",
      "\n",
      "Fold: 6  Epoch: 64  Training loss = 1.9348  Validation loss = 1.3945  \n",
      "\n",
      "Fold: 6  Epoch: 65  Training loss = 1.9343  Validation loss = 1.3931  \n",
      "\n",
      "Fold: 6  Epoch: 66  Training loss = 1.9337  Validation loss = 1.3914  \n",
      "\n",
      "Fold: 6  Epoch: 67  Training loss = 1.9334  Validation loss = 1.3913  \n",
      "\n",
      "Fold: 6  Epoch: 68  Training loss = 1.9327  Validation loss = 1.3900  \n",
      "\n",
      "Fold: 6  Epoch: 69  Training loss = 1.9323  Validation loss = 1.3894  \n",
      "\n",
      "Fold: 6  Epoch: 70  Training loss = 1.9318  Validation loss = 1.3880  \n",
      "\n",
      "Fold: 6  Epoch: 71  Training loss = 1.9312  Validation loss = 1.3865  \n",
      "\n",
      "Fold: 6  Epoch: 72  Training loss = 1.9308  Validation loss = 1.3860  \n",
      "\n",
      "Fold: 6  Epoch: 73  Training loss = 1.9302  Validation loss = 1.3839  \n",
      "\n",
      "Fold: 6  Epoch: 74  Training loss = 1.9297  Validation loss = 1.3828  \n",
      "\n",
      "Fold: 6  Epoch: 75  Training loss = 1.9291  Validation loss = 1.3816  \n",
      "\n",
      "Fold: 6  Epoch: 76  Training loss = 1.9287  Validation loss = 1.3808  \n",
      "\n",
      "Fold: 6  Epoch: 77  Training loss = 1.9281  Validation loss = 1.3793  \n",
      "\n",
      "Fold: 6  Epoch: 78  Training loss = 1.9275  Validation loss = 1.3786  \n",
      "\n",
      "Fold: 6  Epoch: 79  Training loss = 1.9270  Validation loss = 1.3772  \n",
      "\n",
      "Fold: 6  Epoch: 80  Training loss = 1.9264  Validation loss = 1.3761  \n",
      "\n",
      "Fold: 6  Epoch: 81  Training loss = 1.9261  Validation loss = 1.3756  \n",
      "\n",
      "Fold: 6  Epoch: 82  Training loss = 1.9254  Validation loss = 1.3739  \n",
      "\n",
      "Fold: 6  Epoch: 83  Training loss = 1.9249  Validation loss = 1.3724  \n",
      "\n",
      "Fold: 6  Epoch: 84  Training loss = 1.9244  Validation loss = 1.3716  \n",
      "\n",
      "Fold: 6  Epoch: 85  Training loss = 1.9240  Validation loss = 1.3708  \n",
      "\n",
      "Fold: 6  Epoch: 86  Training loss = 1.9234  Validation loss = 1.3699  \n",
      "\n",
      "Fold: 6  Epoch: 87  Training loss = 1.9228  Validation loss = 1.3686  \n",
      "\n",
      "Fold: 6  Epoch: 88  Training loss = 1.9223  Validation loss = 1.3679  \n",
      "\n",
      "Fold: 6  Epoch: 89  Training loss = 1.9218  Validation loss = 1.3665  \n",
      "\n",
      "Fold: 6  Epoch: 90  Training loss = 1.9212  Validation loss = 1.3656  \n",
      "\n",
      "Fold: 6  Epoch: 91  Training loss = 1.9207  Validation loss = 1.3646  \n",
      "\n",
      "Fold: 6  Epoch: 92  Training loss = 1.9202  Validation loss = 1.3638  \n",
      "\n",
      "Fold: 6  Epoch: 93  Training loss = 1.9197  Validation loss = 1.3620  \n",
      "\n",
      "Fold: 6  Epoch: 94  Training loss = 1.9191  Validation loss = 1.3608  \n",
      "\n",
      "Fold: 6  Epoch: 95  Training loss = 1.9184  Validation loss = 1.3587  \n",
      "\n",
      "Fold: 6  Epoch: 96  Training loss = 1.9180  Validation loss = 1.3573  \n",
      "\n",
      "Fold: 6  Epoch: 97  Training loss = 1.9175  Validation loss = 1.3563  \n",
      "\n",
      "Fold: 6  Epoch: 98  Training loss = 1.9169  Validation loss = 1.3550  \n",
      "\n",
      "Fold: 6  Epoch: 99  Training loss = 1.9164  Validation loss = 1.3534  \n",
      "\n",
      "Fold: 6  Epoch: 100  Training loss = 1.9157  Validation loss = 1.3512  \n",
      "\n",
      "Fold: 6  Epoch: 101  Training loss = 1.9152  Validation loss = 1.3501  \n",
      "\n",
      "Fold: 6  Epoch: 102  Training loss = 1.9147  Validation loss = 1.3491  \n",
      "\n",
      "Fold: 6  Epoch: 103  Training loss = 1.9143  Validation loss = 1.3484  \n",
      "\n",
      "Fold: 6  Epoch: 104  Training loss = 1.9140  Validation loss = 1.3484  \n",
      "\n",
      "Fold: 6  Epoch: 105  Training loss = 1.9135  Validation loss = 1.3476  \n",
      "\n",
      "Fold: 6  Epoch: 106  Training loss = 1.9130  Validation loss = 1.3468  \n",
      "\n",
      "Fold: 6  Epoch: 107  Training loss = 1.9126  Validation loss = 1.3450  \n",
      "\n",
      "Fold: 6  Epoch: 108  Training loss = 1.9121  Validation loss = 1.3436  \n",
      "\n",
      "Fold: 6  Epoch: 109  Training loss = 1.9116  Validation loss = 1.3425  \n",
      "\n",
      "Fold: 6  Epoch: 110  Training loss = 1.9110  Validation loss = 1.3411  \n",
      "\n",
      "Fold: 6  Epoch: 111  Training loss = 1.9105  Validation loss = 1.3402  \n",
      "\n",
      "Fold: 6  Epoch: 112  Training loss = 1.9100  Validation loss = 1.3394  \n",
      "\n",
      "Fold: 6  Epoch: 113  Training loss = 1.9093  Validation loss = 1.3376  \n",
      "\n",
      "Fold: 6  Epoch: 114  Training loss = 1.9088  Validation loss = 1.3366  \n",
      "\n",
      "Fold: 6  Epoch: 115  Training loss = 1.9084  Validation loss = 1.3359  \n",
      "\n",
      "Fold: 6  Epoch: 116  Training loss = 1.9078  Validation loss = 1.3352  \n",
      "\n",
      "Fold: 6  Epoch: 117  Training loss = 1.9074  Validation loss = 1.3343  \n",
      "\n",
      "Fold: 6  Epoch: 118  Training loss = 1.9070  Validation loss = 1.3338  \n",
      "\n",
      "Fold: 6  Epoch: 119  Training loss = 1.9064  Validation loss = 1.3328  \n",
      "\n",
      "Fold: 6  Epoch: 120  Training loss = 1.9059  Validation loss = 1.3320  \n",
      "\n",
      "Fold: 6  Epoch: 121  Training loss = 1.9055  Validation loss = 1.3319  \n",
      "\n",
      "Fold: 6  Epoch: 122  Training loss = 1.9051  Validation loss = 1.3310  \n",
      "\n",
      "Fold: 6  Epoch: 123  Training loss = 1.9048  Validation loss = 1.3307  \n",
      "\n",
      "Fold: 6  Epoch: 124  Training loss = 1.9043  Validation loss = 1.3295  \n",
      "\n",
      "Fold: 6  Epoch: 125  Training loss = 1.9037  Validation loss = 1.3291  \n",
      "\n",
      "Fold: 6  Epoch: 126  Training loss = 1.9033  Validation loss = 1.3278  \n",
      "\n",
      "Fold: 6  Epoch: 127  Training loss = 1.9028  Validation loss = 1.3268  \n",
      "\n",
      "Fold: 6  Epoch: 128  Training loss = 1.9024  Validation loss = 1.3259  \n",
      "\n",
      "Fold: 6  Epoch: 129  Training loss = 1.9018  Validation loss = 1.3248  \n",
      "\n",
      "Fold: 6  Epoch: 130  Training loss = 1.9013  Validation loss = 1.3238  \n",
      "\n",
      "Fold: 6  Epoch: 131  Training loss = 1.9008  Validation loss = 1.3228  \n",
      "\n",
      "Fold: 6  Epoch: 132  Training loss = 1.9002  Validation loss = 1.3218  \n",
      "\n",
      "Fold: 6  Epoch: 133  Training loss = 1.8998  Validation loss = 1.3206  \n",
      "\n",
      "Fold: 6  Epoch: 134  Training loss = 1.8994  Validation loss = 1.3203  \n",
      "\n",
      "Fold: 6  Epoch: 135  Training loss = 1.8990  Validation loss = 1.3200  \n",
      "\n",
      "Fold: 6  Epoch: 136  Training loss = 1.8986  Validation loss = 1.3190  \n",
      "\n",
      "Fold: 6  Epoch: 137  Training loss = 1.8980  Validation loss = 1.3177  \n",
      "\n",
      "Fold: 6  Epoch: 138  Training loss = 1.8975  Validation loss = 1.3169  \n",
      "\n",
      "Fold: 6  Epoch: 139  Training loss = 1.8972  Validation loss = 1.3164  \n",
      "\n",
      "Fold: 6  Epoch: 140  Training loss = 1.8967  Validation loss = 1.3155  \n",
      "\n",
      "Fold: 6  Epoch: 141  Training loss = 1.8962  Validation loss = 1.3145  \n",
      "\n",
      "Fold: 6  Epoch: 142  Training loss = 1.8956  Validation loss = 1.3139  \n",
      "\n",
      "Fold: 6  Epoch: 143  Training loss = 1.8953  Validation loss = 1.3137  \n",
      "\n",
      "Fold: 6  Epoch: 144  Training loss = 1.8948  Validation loss = 1.3129  \n",
      "\n",
      "Fold: 6  Epoch: 145  Training loss = 1.8944  Validation loss = 1.3130  \n",
      "\n",
      "Fold: 6  Epoch: 146  Training loss = 1.8939  Validation loss = 1.3120  \n",
      "\n",
      "Fold: 6  Epoch: 147  Training loss = 1.8935  Validation loss = 1.3114  \n",
      "\n",
      "Fold: 6  Epoch: 148  Training loss = 1.8930  Validation loss = 1.3106  \n",
      "\n",
      "Fold: 6  Epoch: 149  Training loss = 1.8925  Validation loss = 1.3096  \n",
      "\n",
      "Fold: 6  Epoch: 150  Training loss = 1.8919  Validation loss = 1.3091  \n",
      "\n",
      "Fold: 6  Epoch: 151  Training loss = 1.8912  Validation loss = 1.3076  \n",
      "\n",
      "Fold: 6  Epoch: 152  Training loss = 1.8907  Validation loss = 1.3076  \n",
      "\n",
      "Fold: 6  Epoch: 153  Training loss = 1.8904  Validation loss = 1.3071  \n",
      "\n",
      "Fold: 6  Epoch: 154  Training loss = 1.8900  Validation loss = 1.3070  \n",
      "\n",
      "Fold: 6  Epoch: 155  Training loss = 1.8896  Validation loss = 1.3057  \n",
      "\n",
      "Fold: 6  Epoch: 156  Training loss = 1.8891  Validation loss = 1.3053  \n",
      "\n",
      "Fold: 6  Epoch: 157  Training loss = 1.8886  Validation loss = 1.3046  \n",
      "\n",
      "Fold: 6  Epoch: 158  Training loss = 1.8882  Validation loss = 1.3050  \n",
      "\n",
      "Fold: 6  Epoch: 159  Training loss = 1.8876  Validation loss = 1.3039  \n",
      "\n",
      "Fold: 6  Epoch: 160  Training loss = 1.8873  Validation loss = 1.3035  \n",
      "\n",
      "Fold: 6  Epoch: 161  Training loss = 1.8868  Validation loss = 1.3025  \n",
      "\n",
      "Fold: 6  Epoch: 162  Training loss = 1.8861  Validation loss = 1.3011  \n",
      "\n",
      "Fold: 6  Epoch: 163  Training loss = 1.8856  Validation loss = 1.2995  \n",
      "\n",
      "Fold: 6  Epoch: 164  Training loss = 1.8851  Validation loss = 1.2986  \n",
      "\n",
      "Fold: 6  Epoch: 165  Training loss = 1.8845  Validation loss = 1.2976  \n",
      "\n",
      "Fold: 6  Epoch: 166  Training loss = 1.8840  Validation loss = 1.2965  \n",
      "\n",
      "Fold: 6  Epoch: 167  Training loss = 1.8834  Validation loss = 1.2955  \n",
      "\n",
      "Fold: 6  Epoch: 168  Training loss = 1.8828  Validation loss = 1.2945  \n",
      "\n",
      "Fold: 6  Epoch: 169  Training loss = 1.8824  Validation loss = 1.2942  \n",
      "\n",
      "Fold: 6  Epoch: 170  Training loss = 1.8817  Validation loss = 1.2929  \n",
      "\n",
      "Fold: 6  Epoch: 171  Training loss = 1.8813  Validation loss = 1.2917  \n",
      "\n",
      "Fold: 6  Epoch: 172  Training loss = 1.8806  Validation loss = 1.2905  \n",
      "\n",
      "Fold: 6  Epoch: 173  Training loss = 1.8801  Validation loss = 1.2899  \n",
      "\n",
      "Fold: 6  Epoch: 174  Training loss = 1.8795  Validation loss = 1.2890  \n",
      "\n",
      "Fold: 6  Epoch: 175  Training loss = 1.8791  Validation loss = 1.2886  \n",
      "\n",
      "Fold: 6  Epoch: 176  Training loss = 1.8787  Validation loss = 1.2877  \n",
      "\n",
      "Fold: 6  Epoch: 177  Training loss = 1.8784  Validation loss = 1.2872  \n",
      "\n",
      "Fold: 6  Epoch: 178  Training loss = 1.8778  Validation loss = 1.2859  \n",
      "\n",
      "Fold: 6  Epoch: 179  Training loss = 1.8774  Validation loss = 1.2847  \n",
      "\n",
      "Fold: 6  Epoch: 180  Training loss = 1.8769  Validation loss = 1.2834  \n",
      "\n",
      "Fold: 6  Epoch: 181  Training loss = 1.8764  Validation loss = 1.2823  \n",
      "\n",
      "Fold: 6  Epoch: 182  Training loss = 1.8759  Validation loss = 1.2819  \n",
      "\n",
      "Fold: 6  Epoch: 183  Training loss = 1.8754  Validation loss = 1.2806  \n",
      "\n",
      "Fold: 6  Epoch: 184  Training loss = 1.8749  Validation loss = 1.2794  \n",
      "\n",
      "Fold: 6  Epoch: 185  Training loss = 1.8745  Validation loss = 1.2789  \n",
      "\n",
      "Fold: 6  Epoch: 186  Training loss = 1.8740  Validation loss = 1.2788  \n",
      "\n",
      "Fold: 6  Epoch: 187  Training loss = 1.8735  Validation loss = 1.2778  \n",
      "\n",
      "Fold: 6  Epoch: 188  Training loss = 1.8729  Validation loss = 1.2773  \n",
      "\n",
      "Fold: 6  Epoch: 189  Training loss = 1.8725  Validation loss = 1.2765  \n",
      "\n",
      "Fold: 6  Epoch: 190  Training loss = 1.8720  Validation loss = 1.2758  \n",
      "\n",
      "Fold: 6  Epoch: 191  Training loss = 1.8717  Validation loss = 1.2760  \n",
      "\n",
      "Fold: 6  Epoch: 192  Training loss = 1.8711  Validation loss = 1.2751  \n",
      "\n",
      "Fold: 6  Epoch: 193  Training loss = 1.8706  Validation loss = 1.2743  \n",
      "\n",
      "Fold: 6  Epoch: 194  Training loss = 1.8702  Validation loss = 1.2731  \n",
      "\n",
      "Fold: 6  Epoch: 195  Training loss = 1.8697  Validation loss = 1.2720  \n",
      "\n",
      "Fold: 6  Epoch: 196  Training loss = 1.8694  Validation loss = 1.2717  \n",
      "\n",
      "Fold: 6  Epoch: 197  Training loss = 1.8690  Validation loss = 1.2707  \n",
      "\n",
      "Fold: 6  Epoch: 198  Training loss = 1.8686  Validation loss = 1.2696  \n",
      "\n",
      "Fold: 6  Epoch: 199  Training loss = 1.8682  Validation loss = 1.2690  \n",
      "\n",
      "Fold: 6  Epoch: 200  Training loss = 1.8678  Validation loss = 1.2686  \n",
      "\n",
      "Fold: 6  Epoch: 201  Training loss = 1.8674  Validation loss = 1.2684  \n",
      "\n",
      "Fold: 6  Epoch: 202  Training loss = 1.8669  Validation loss = 1.2667  \n",
      "\n",
      "Fold: 6  Epoch: 203  Training loss = 1.8663  Validation loss = 1.2658  \n",
      "\n",
      "Fold: 6  Epoch: 204  Training loss = 1.8658  Validation loss = 1.2653  \n",
      "\n",
      "Fold: 6  Epoch: 205  Training loss = 1.8654  Validation loss = 1.2643  \n",
      "\n",
      "Fold: 6  Epoch: 206  Training loss = 1.8647  Validation loss = 1.2633  \n",
      "\n",
      "Fold: 6  Epoch: 207  Training loss = 1.8643  Validation loss = 1.2631  \n",
      "\n",
      "Fold: 6  Epoch: 208  Training loss = 1.8635  Validation loss = 1.2618  \n",
      "\n",
      "Fold: 6  Epoch: 209  Training loss = 1.8628  Validation loss = 1.2601  \n",
      "\n",
      "Fold: 6  Epoch: 210  Training loss = 1.8623  Validation loss = 1.2591  \n",
      "\n",
      "Fold: 6  Epoch: 211  Training loss = 1.8616  Validation loss = 1.2578  \n",
      "\n",
      "Fold: 6  Epoch: 212  Training loss = 1.8610  Validation loss = 1.2573  \n",
      "\n",
      "Fold: 6  Epoch: 213  Training loss = 1.8605  Validation loss = 1.2567  \n",
      "\n",
      "Fold: 6  Epoch: 214  Training loss = 1.8601  Validation loss = 1.2564  \n",
      "\n",
      "Fold: 6  Epoch: 215  Training loss = 1.8596  Validation loss = 1.2548  \n",
      "\n",
      "Fold: 6  Epoch: 216  Training loss = 1.8591  Validation loss = 1.2535  \n",
      "\n",
      "Fold: 6  Epoch: 217  Training loss = 1.8587  Validation loss = 1.2528  \n",
      "\n",
      "Fold: 6  Epoch: 218  Training loss = 1.8581  Validation loss = 1.2510  \n",
      "\n",
      "Fold: 6  Epoch: 219  Training loss = 1.8578  Validation loss = 1.2502  \n",
      "\n",
      "Fold: 6  Epoch: 220  Training loss = 1.8572  Validation loss = 1.2490  \n",
      "\n",
      "Fold: 6  Epoch: 221  Training loss = 1.8567  Validation loss = 1.2482  \n",
      "\n",
      "Fold: 6  Epoch: 222  Training loss = 1.8562  Validation loss = 1.2469  \n",
      "\n",
      "Fold: 6  Epoch: 223  Training loss = 1.8556  Validation loss = 1.2462  \n",
      "\n",
      "Fold: 6  Epoch: 224  Training loss = 1.8550  Validation loss = 1.2450  \n",
      "\n",
      "Fold: 6  Epoch: 225  Training loss = 1.8545  Validation loss = 1.2443  \n",
      "\n",
      "Fold: 6  Epoch: 226  Training loss = 1.8541  Validation loss = 1.2435  \n",
      "\n",
      "Fold: 6  Epoch: 227  Training loss = 1.8534  Validation loss = 1.2424  \n",
      "\n",
      "Fold: 6  Epoch: 228  Training loss = 1.8529  Validation loss = 1.2412  \n",
      "\n",
      "Fold: 6  Epoch: 229  Training loss = 1.8525  Validation loss = 1.2405  \n",
      "\n",
      "Fold: 6  Epoch: 230  Training loss = 1.8520  Validation loss = 1.2404  \n",
      "\n",
      "Fold: 6  Epoch: 231  Training loss = 1.8516  Validation loss = 1.2401  \n",
      "\n",
      "Fold: 6  Epoch: 232  Training loss = 1.8510  Validation loss = 1.2397  \n",
      "\n",
      "Fold: 6  Epoch: 233  Training loss = 1.8504  Validation loss = 1.2384  \n",
      "\n",
      "Fold: 6  Epoch: 234  Training loss = 1.8500  Validation loss = 1.2380  \n",
      "\n",
      "Fold: 6  Epoch: 235  Training loss = 1.8494  Validation loss = 1.2369  \n",
      "\n",
      "Fold: 6  Epoch: 236  Training loss = 1.8490  Validation loss = 1.2356  \n",
      "\n",
      "Fold: 6  Epoch: 237  Training loss = 1.8484  Validation loss = 1.2348  \n",
      "\n",
      "Fold: 6  Epoch: 238  Training loss = 1.8479  Validation loss = 1.2337  \n",
      "\n",
      "Fold: 6  Epoch: 239  Training loss = 1.8473  Validation loss = 1.2326  \n",
      "\n",
      "Fold: 6  Epoch: 240  Training loss = 1.8469  Validation loss = 1.2322  \n",
      "\n",
      "Fold: 6  Epoch: 241  Training loss = 1.8462  Validation loss = 1.2315  \n",
      "\n",
      "Fold: 6  Epoch: 242  Training loss = 1.8457  Validation loss = 1.2308  \n",
      "\n",
      "Fold: 6  Epoch: 243  Training loss = 1.8453  Validation loss = 1.2300  \n",
      "\n",
      "Fold: 6  Epoch: 244  Training loss = 1.8446  Validation loss = 1.2290  \n",
      "\n",
      "Fold: 6  Epoch: 245  Training loss = 1.8441  Validation loss = 1.2282  \n",
      "\n",
      "Fold: 6  Epoch: 246  Training loss = 1.8435  Validation loss = 1.2266  \n",
      "\n",
      "Fold: 6  Epoch: 247  Training loss = 1.8430  Validation loss = 1.2253  \n",
      "\n",
      "Fold: 6  Epoch: 248  Training loss = 1.8424  Validation loss = 1.2250  \n",
      "\n",
      "Fold: 6  Epoch: 249  Training loss = 1.8419  Validation loss = 1.2245  \n",
      "\n",
      "Fold: 6  Epoch: 250  Training loss = 1.8414  Validation loss = 1.2235  \n",
      "\n",
      "Fold: 6  Epoch: 251  Training loss = 1.8409  Validation loss = 1.2226  \n",
      "\n",
      "Fold: 6  Epoch: 252  Training loss = 1.8404  Validation loss = 1.2219  \n",
      "\n",
      "Fold: 6  Epoch: 253  Training loss = 1.8398  Validation loss = 1.2201  \n",
      "\n",
      "Fold: 6  Epoch: 254  Training loss = 1.8393  Validation loss = 1.2191  \n",
      "\n",
      "Fold: 6  Epoch: 255  Training loss = 1.8388  Validation loss = 1.2185  \n",
      "\n",
      "Fold: 6  Epoch: 256  Training loss = 1.8381  Validation loss = 1.2170  \n",
      "\n",
      "Fold: 6  Epoch: 257  Training loss = 1.8377  Validation loss = 1.2162  \n",
      "\n",
      "Fold: 6  Epoch: 258  Training loss = 1.8371  Validation loss = 1.2156  \n",
      "\n",
      "Fold: 6  Epoch: 259  Training loss = 1.8365  Validation loss = 1.2138  \n",
      "\n",
      "Fold: 6  Epoch: 260  Training loss = 1.8359  Validation loss = 1.2130  \n",
      "\n",
      "Fold: 6  Epoch: 261  Training loss = 1.8354  Validation loss = 1.2117  \n",
      "\n",
      "Fold: 6  Epoch: 262  Training loss = 1.8348  Validation loss = 1.2108  \n",
      "\n",
      "Fold: 6  Epoch: 263  Training loss = 1.8343  Validation loss = 1.2099  \n",
      "\n",
      "Fold: 6  Epoch: 264  Training loss = 1.8339  Validation loss = 1.2098  \n",
      "\n",
      "Fold: 6  Epoch: 265  Training loss = 1.8332  Validation loss = 1.2088  \n",
      "\n",
      "Fold: 6  Epoch: 266  Training loss = 1.8327  Validation loss = 1.2077  \n",
      "\n",
      "Fold: 6  Epoch: 267  Training loss = 1.8322  Validation loss = 1.2075  \n",
      "\n",
      "Fold: 6  Epoch: 268  Training loss = 1.8317  Validation loss = 1.2061  \n",
      "\n",
      "Fold: 6  Epoch: 269  Training loss = 1.8311  Validation loss = 1.2049  \n",
      "\n",
      "Fold: 6  Epoch: 270  Training loss = 1.8305  Validation loss = 1.2043  \n",
      "\n",
      "Fold: 6  Epoch: 271  Training loss = 1.8299  Validation loss = 1.2029  \n",
      "\n",
      "Fold: 6  Epoch: 272  Training loss = 1.8294  Validation loss = 1.2022  \n",
      "\n",
      "Fold: 6  Epoch: 273  Training loss = 1.8289  Validation loss = 1.2013  \n",
      "\n",
      "Fold: 6  Epoch: 274  Training loss = 1.8282  Validation loss = 1.1993  \n",
      "\n",
      "Fold: 6  Epoch: 275  Training loss = 1.8278  Validation loss = 1.1987  \n",
      "\n",
      "Fold: 6  Epoch: 276  Training loss = 1.8271  Validation loss = 1.1978  \n",
      "\n",
      "Fold: 6  Epoch: 277  Training loss = 1.8265  Validation loss = 1.1978  \n",
      "\n",
      "Fold: 6  Epoch: 278  Training loss = 1.8261  Validation loss = 1.1974  \n",
      "\n",
      "Fold: 6  Epoch: 279  Training loss = 1.8256  Validation loss = 1.1969  \n",
      "\n",
      "Fold: 6  Epoch: 280  Training loss = 1.8250  Validation loss = 1.1961  \n",
      "\n",
      "Fold: 6  Epoch: 281  Training loss = 1.8245  Validation loss = 1.1951  \n",
      "\n",
      "Fold: 6  Epoch: 282  Training loss = 1.8239  Validation loss = 1.1937  \n",
      "\n",
      "Fold: 6  Epoch: 283  Training loss = 1.8234  Validation loss = 1.1923  \n",
      "\n",
      "Fold: 6  Epoch: 284  Training loss = 1.8230  Validation loss = 1.1919  \n",
      "\n",
      "Fold: 6  Epoch: 285  Training loss = 1.8224  Validation loss = 1.1903  \n",
      "\n",
      "Fold: 6  Epoch: 286  Training loss = 1.8218  Validation loss = 1.1896  \n",
      "\n",
      "Fold: 6  Epoch: 287  Training loss = 1.8212  Validation loss = 1.1882  \n",
      "\n",
      "Fold: 6  Epoch: 288  Training loss = 1.8207  Validation loss = 1.1873  \n",
      "\n",
      "Fold: 6  Epoch: 289  Training loss = 1.8202  Validation loss = 1.1855  \n",
      "\n",
      "Fold: 6  Epoch: 290  Training loss = 1.8197  Validation loss = 1.1845  \n",
      "\n",
      "Fold: 6  Epoch: 291  Training loss = 1.8192  Validation loss = 1.1846  \n",
      "\n",
      "Fold: 6  Epoch: 292  Training loss = 1.8185  Validation loss = 1.1830  \n",
      "\n",
      "Fold: 6  Epoch: 293  Training loss = 1.8179  Validation loss = 1.1818  \n",
      "\n",
      "Fold: 6  Epoch: 294  Training loss = 1.8175  Validation loss = 1.1815  \n",
      "\n",
      "Fold: 6  Epoch: 295  Training loss = 1.8171  Validation loss = 1.1807  \n",
      "\n",
      "Fold: 6  Epoch: 296  Training loss = 1.8165  Validation loss = 1.1804  \n",
      "\n",
      "Fold: 6  Epoch: 297  Training loss = 1.8160  Validation loss = 1.1797  \n",
      "\n",
      "Fold: 6  Epoch: 298  Training loss = 1.8156  Validation loss = 1.1793  \n",
      "\n",
      "Fold: 6  Epoch: 299  Training loss = 1.8149  Validation loss = 1.1775  \n",
      "\n",
      "Fold: 6  Epoch: 300  Training loss = 1.8144  Validation loss = 1.1770  \n",
      "\n",
      "Fold: 6  Epoch: 301  Training loss = 1.8138  Validation loss = 1.1756  \n",
      "\n",
      "Fold: 6  Epoch: 302  Training loss = 1.8131  Validation loss = 1.1745  \n",
      "\n",
      "Fold: 6  Epoch: 303  Training loss = 1.8127  Validation loss = 1.1739  \n",
      "\n",
      "Fold: 6  Epoch: 304  Training loss = 1.8120  Validation loss = 1.1725  \n",
      "\n",
      "Fold: 6  Epoch: 305  Training loss = 1.8115  Validation loss = 1.1715  \n",
      "\n",
      "Fold: 6  Epoch: 306  Training loss = 1.8109  Validation loss = 1.1699  \n",
      "\n",
      "Fold: 6  Epoch: 307  Training loss = 1.8105  Validation loss = 1.1688  \n",
      "\n",
      "Fold: 6  Epoch: 308  Training loss = 1.8101  Validation loss = 1.1678  \n",
      "\n",
      "Fold: 6  Epoch: 309  Training loss = 1.8094  Validation loss = 1.1664  \n",
      "\n",
      "Fold: 6  Epoch: 310  Training loss = 1.8090  Validation loss = 1.1654  \n",
      "\n",
      "Fold: 6  Epoch: 311  Training loss = 1.8085  Validation loss = 1.1653  \n",
      "\n",
      "Fold: 6  Epoch: 312  Training loss = 1.8078  Validation loss = 1.1646  \n",
      "\n",
      "Fold: 6  Epoch: 313  Training loss = 1.8074  Validation loss = 1.1644  \n",
      "\n",
      "Fold: 6  Epoch: 314  Training loss = 1.8068  Validation loss = 1.1626  \n",
      "\n",
      "Fold: 6  Epoch: 315  Training loss = 1.8064  Validation loss = 1.1620  \n",
      "\n",
      "Fold: 6  Epoch: 316  Training loss = 1.8059  Validation loss = 1.1609  \n",
      "\n",
      "Fold: 6  Epoch: 317  Training loss = 1.8055  Validation loss = 1.1601  \n",
      "\n",
      "Fold: 6  Epoch: 318  Training loss = 1.8049  Validation loss = 1.1592  \n",
      "\n",
      "Fold: 6  Epoch: 319  Training loss = 1.8046  Validation loss = 1.1585  \n",
      "\n",
      "Fold: 6  Epoch: 320  Training loss = 1.8042  Validation loss = 1.1576  \n",
      "\n",
      "Fold: 6  Epoch: 321  Training loss = 1.8037  Validation loss = 1.1568  \n",
      "\n",
      "Fold: 6  Epoch: 322  Training loss = 1.8031  Validation loss = 1.1557  \n",
      "\n",
      "Fold: 6  Epoch: 323  Training loss = 1.8025  Validation loss = 1.1546  \n",
      "\n",
      "Fold: 6  Epoch: 324  Training loss = 1.8020  Validation loss = 1.1540  \n",
      "\n",
      "Fold: 6  Epoch: 325  Training loss = 1.8013  Validation loss = 1.1531  \n",
      "\n",
      "Fold: 6  Epoch: 326  Training loss = 1.8008  Validation loss = 1.1523  \n",
      "\n",
      "Fold: 6  Epoch: 327  Training loss = 1.8004  Validation loss = 1.1515  \n",
      "\n",
      "Fold: 6  Epoch: 328  Training loss = 1.7999  Validation loss = 1.1501  \n",
      "\n",
      "Fold: 6  Epoch: 329  Training loss = 1.7995  Validation loss = 1.1495  \n",
      "\n",
      "Fold: 6  Epoch: 330  Training loss = 1.7990  Validation loss = 1.1492  \n",
      "\n",
      "Fold: 6  Epoch: 331  Training loss = 1.7984  Validation loss = 1.1480  \n",
      "\n",
      "Fold: 6  Epoch: 332  Training loss = 1.7979  Validation loss = 1.1472  \n",
      "\n",
      "Fold: 6  Epoch: 333  Training loss = 1.7970  Validation loss = 1.1448  \n",
      "\n",
      "Fold: 6  Epoch: 334  Training loss = 1.7965  Validation loss = 1.1440  \n",
      "\n",
      "Fold: 6  Epoch: 335  Training loss = 1.7961  Validation loss = 1.1437  \n",
      "\n",
      "Fold: 6  Epoch: 336  Training loss = 1.7956  Validation loss = 1.1428  \n",
      "\n",
      "Fold: 6  Epoch: 337  Training loss = 1.7952  Validation loss = 1.1426  \n",
      "\n",
      "Fold: 6  Epoch: 338  Training loss = 1.7945  Validation loss = 1.1410  \n",
      "\n",
      "Fold: 6  Epoch: 339  Training loss = 1.7938  Validation loss = 1.1400  \n",
      "\n",
      "Fold: 6  Epoch: 340  Training loss = 1.7933  Validation loss = 1.1384  \n",
      "\n",
      "Fold: 6  Epoch: 341  Training loss = 1.7929  Validation loss = 1.1375  \n",
      "\n",
      "Fold: 6  Epoch: 342  Training loss = 1.7924  Validation loss = 1.1372  \n",
      "\n",
      "Fold: 6  Epoch: 343  Training loss = 1.7919  Validation loss = 1.1363  \n",
      "\n",
      "Fold: 6  Epoch: 344  Training loss = 1.7914  Validation loss = 1.1347  \n",
      "\n",
      "Fold: 6  Epoch: 345  Training loss = 1.7908  Validation loss = 1.1333  \n",
      "\n",
      "Fold: 6  Epoch: 346  Training loss = 1.7904  Validation loss = 1.1323  \n",
      "\n",
      "Fold: 6  Epoch: 347  Training loss = 1.7899  Validation loss = 1.1311  \n",
      "\n",
      "Fold: 6  Epoch: 348  Training loss = 1.7896  Validation loss = 1.1301  \n",
      "\n",
      "Fold: 6  Epoch: 349  Training loss = 1.7892  Validation loss = 1.1294  \n",
      "\n",
      "Fold: 6  Epoch: 350  Training loss = 1.7886  Validation loss = 1.1278  \n",
      "\n",
      "Fold: 6  Epoch: 351  Training loss = 1.7881  Validation loss = 1.1266  \n",
      "\n",
      "Fold: 6  Epoch: 352  Training loss = 1.7874  Validation loss = 1.1259  \n",
      "\n",
      "Fold: 6  Epoch: 353  Training loss = 1.7870  Validation loss = 1.1249  \n",
      "\n",
      "Fold: 6  Epoch: 354  Training loss = 1.7863  Validation loss = 1.1237  \n",
      "\n",
      "Fold: 6  Epoch: 355  Training loss = 1.7857  Validation loss = 1.1224  \n",
      "\n",
      "Fold: 6  Epoch: 356  Training loss = 1.7852  Validation loss = 1.1215  \n",
      "\n",
      "Fold: 6  Epoch: 357  Training loss = 1.7846  Validation loss = 1.1209  \n",
      "\n",
      "Fold: 6  Epoch: 358  Training loss = 1.7839  Validation loss = 1.1194  \n",
      "\n",
      "Fold: 6  Epoch: 359  Training loss = 1.7833  Validation loss = 1.1185  \n",
      "\n",
      "Fold: 6  Epoch: 360  Training loss = 1.7829  Validation loss = 1.1180  \n",
      "\n",
      "Fold: 6  Epoch: 361  Training loss = 1.7823  Validation loss = 1.1167  \n",
      "\n",
      "Fold: 6  Epoch: 362  Training loss = 1.7819  Validation loss = 1.1162  \n",
      "\n",
      "Fold: 6  Epoch: 363  Training loss = 1.7813  Validation loss = 1.1155  \n",
      "\n",
      "Fold: 6  Epoch: 364  Training loss = 1.7808  Validation loss = 1.1142  \n",
      "\n",
      "Fold: 6  Epoch: 365  Training loss = 1.7803  Validation loss = 1.1136  \n",
      "\n",
      "Fold: 6  Epoch: 366  Training loss = 1.7800  Validation loss = 1.1136  \n",
      "\n",
      "Fold: 6  Epoch: 367  Training loss = 1.7794  Validation loss = 1.1127  \n",
      "\n",
      "Fold: 6  Epoch: 368  Training loss = 1.7791  Validation loss = 1.1121  \n",
      "\n",
      "Fold: 6  Epoch: 369  Training loss = 1.7786  Validation loss = 1.1115  \n",
      "\n",
      "Fold: 6  Epoch: 370  Training loss = 1.7780  Validation loss = 1.1104  \n",
      "\n",
      "Fold: 6  Epoch: 371  Training loss = 1.7775  Validation loss = 1.1098  \n",
      "\n",
      "Fold: 6  Epoch: 372  Training loss = 1.7770  Validation loss = 1.1087  \n",
      "\n",
      "Fold: 6  Epoch: 373  Training loss = 1.7765  Validation loss = 1.1074  \n",
      "\n",
      "Fold: 6  Epoch: 374  Training loss = 1.7759  Validation loss = 1.1063  \n",
      "\n",
      "Fold: 6  Epoch: 375  Training loss = 1.7755  Validation loss = 1.1055  \n",
      "\n",
      "Fold: 6  Epoch: 376  Training loss = 1.7749  Validation loss = 1.1047  \n",
      "\n",
      "Fold: 6  Epoch: 377  Training loss = 1.7744  Validation loss = 1.1040  \n",
      "\n",
      "Fold: 6  Epoch: 378  Training loss = 1.7741  Validation loss = 1.1037  \n",
      "\n",
      "Fold: 6  Epoch: 379  Training loss = 1.7734  Validation loss = 1.1028  \n",
      "\n",
      "Fold: 6  Epoch: 380  Training loss = 1.7729  Validation loss = 1.1025  \n",
      "\n",
      "Fold: 6  Epoch: 381  Training loss = 1.7724  Validation loss = 1.1020  \n",
      "\n",
      "Fold: 6  Epoch: 382  Training loss = 1.7721  Validation loss = 1.1015  \n",
      "\n",
      "Fold: 6  Epoch: 383  Training loss = 1.7718  Validation loss = 1.1012  \n",
      "\n",
      "Fold: 6  Epoch: 384  Training loss = 1.7714  Validation loss = 1.1007  \n",
      "\n",
      "Fold: 6  Epoch: 385  Training loss = 1.7711  Validation loss = 1.0999  \n",
      "\n",
      "Fold: 6  Epoch: 386  Training loss = 1.7708  Validation loss = 1.0995  \n",
      "\n",
      "Fold: 6  Epoch: 387  Training loss = 1.7703  Validation loss = 1.0983  \n",
      "\n",
      "Fold: 6  Epoch: 388  Training loss = 1.7698  Validation loss = 1.0974  \n",
      "\n",
      "Fold: 6  Epoch: 389  Training loss = 1.7694  Validation loss = 1.0959  \n",
      "\n",
      "Fold: 6  Epoch: 390  Training loss = 1.7689  Validation loss = 1.0954  \n",
      "\n",
      "Fold: 6  Epoch: 391  Training loss = 1.7686  Validation loss = 1.0940  \n",
      "\n",
      "Fold: 6  Epoch: 392  Training loss = 1.7681  Validation loss = 1.0927  \n",
      "\n",
      "Fold: 6  Epoch: 393  Training loss = 1.7675  Validation loss = 1.0918  \n",
      "\n",
      "Fold: 6  Epoch: 394  Training loss = 1.7671  Validation loss = 1.0910  \n",
      "\n",
      "Fold: 6  Epoch: 395  Training loss = 1.7666  Validation loss = 1.0897  \n",
      "\n",
      "Fold: 6  Epoch: 396  Training loss = 1.7662  Validation loss = 1.0893  \n",
      "\n",
      "Fold: 6  Epoch: 397  Training loss = 1.7658  Validation loss = 1.0889  \n",
      "\n",
      "Fold: 6  Epoch: 398  Training loss = 1.7652  Validation loss = 1.0878  \n",
      "\n",
      "Fold: 6  Epoch: 399  Training loss = 1.7647  Validation loss = 1.0859  \n",
      "\n",
      "Fold: 6  Epoch: 400  Training loss = 1.7642  Validation loss = 1.0848  \n",
      "\n",
      "Fold: 6  Epoch: 401  Training loss = 1.7637  Validation loss = 1.0832  \n",
      "\n",
      "Fold: 6  Epoch: 402  Training loss = 1.7632  Validation loss = 1.0827  \n",
      "\n",
      "Fold: 6  Epoch: 403  Training loss = 1.7628  Validation loss = 1.0812  \n",
      "\n",
      "Fold: 6  Epoch: 404  Training loss = 1.7624  Validation loss = 1.0805  \n",
      "\n",
      "Fold: 6  Epoch: 405  Training loss = 1.7619  Validation loss = 1.0798  \n",
      "\n",
      "Fold: 6  Epoch: 406  Training loss = 1.7615  Validation loss = 1.0793  \n",
      "\n",
      "Fold: 6  Epoch: 407  Training loss = 1.7611  Validation loss = 1.0785  \n",
      "\n",
      "Fold: 6  Epoch: 408  Training loss = 1.7607  Validation loss = 1.0773  \n",
      "\n",
      "Fold: 6  Epoch: 409  Training loss = 1.7602  Validation loss = 1.0760  \n",
      "\n",
      "Fold: 6  Epoch: 410  Training loss = 1.7599  Validation loss = 1.0753  \n",
      "\n",
      "Fold: 6  Epoch: 411  Training loss = 1.7594  Validation loss = 1.0743  \n",
      "\n",
      "Fold: 6  Epoch: 412  Training loss = 1.7590  Validation loss = 1.0737  \n",
      "\n",
      "Fold: 6  Epoch: 413  Training loss = 1.7583  Validation loss = 1.0726  \n",
      "\n",
      "Fold: 6  Epoch: 414  Training loss = 1.7579  Validation loss = 1.0721  \n",
      "\n",
      "Fold: 6  Epoch: 415  Training loss = 1.7572  Validation loss = 1.0704  \n",
      "\n",
      "Fold: 6  Epoch: 416  Training loss = 1.7568  Validation loss = 1.0696  \n",
      "\n",
      "Fold: 6  Epoch: 417  Training loss = 1.7565  Validation loss = 1.0695  \n",
      "\n",
      "Fold: 6  Epoch: 418  Training loss = 1.7560  Validation loss = 1.0681  \n",
      "\n",
      "Fold: 6  Epoch: 419  Training loss = 1.7555  Validation loss = 1.0674  \n",
      "\n",
      "Fold: 6  Epoch: 420  Training loss = 1.7552  Validation loss = 1.0677  \n",
      "\n",
      "Fold: 6  Epoch: 421  Training loss = 1.7549  Validation loss = 1.0674  \n",
      "\n",
      "Fold: 6  Epoch: 422  Training loss = 1.7543  Validation loss = 1.0656  \n",
      "\n",
      "Fold: 6  Epoch: 423  Training loss = 1.7537  Validation loss = 1.0640  \n",
      "\n",
      "Fold: 6  Epoch: 424  Training loss = 1.7532  Validation loss = 1.0621  \n",
      "\n",
      "Fold: 6  Epoch: 425  Training loss = 1.7526  Validation loss = 1.0607  \n",
      "\n",
      "Fold: 6  Epoch: 426  Training loss = 1.7521  Validation loss = 1.0598  \n",
      "\n",
      "Fold: 6  Epoch: 427  Training loss = 1.7517  Validation loss = 1.0589  \n",
      "\n",
      "Fold: 6  Epoch: 428  Training loss = 1.7513  Validation loss = 1.0588  \n",
      "\n",
      "Fold: 6  Epoch: 429  Training loss = 1.7507  Validation loss = 1.0568  \n",
      "\n",
      "Fold: 6  Epoch: 430  Training loss = 1.7502  Validation loss = 1.0568  \n",
      "\n",
      "Fold: 6  Epoch: 431  Training loss = 1.7499  Validation loss = 1.0558  \n",
      "\n",
      "Fold: 6  Epoch: 432  Training loss = 1.7496  Validation loss = 1.0554  \n",
      "\n",
      "Fold: 6  Epoch: 433  Training loss = 1.7490  Validation loss = 1.0549  \n",
      "\n",
      "Fold: 6  Epoch: 434  Training loss = 1.7485  Validation loss = 1.0538  \n",
      "\n",
      "Fold: 6  Epoch: 435  Training loss = 1.7481  Validation loss = 1.0530  \n",
      "\n",
      "Fold: 6  Epoch: 436  Training loss = 1.7477  Validation loss = 1.0521  \n",
      "\n",
      "Fold: 6  Epoch: 437  Training loss = 1.7472  Validation loss = 1.0512  \n",
      "\n",
      "Fold: 6  Epoch: 438  Training loss = 1.7467  Validation loss = 1.0500  \n",
      "\n",
      "Fold: 6  Epoch: 439  Training loss = 1.7462  Validation loss = 1.0485  \n",
      "\n",
      "Fold: 6  Epoch: 440  Training loss = 1.7459  Validation loss = 1.0480  \n",
      "\n",
      "Fold: 6  Epoch: 441  Training loss = 1.7455  Validation loss = 1.0471  \n",
      "\n",
      "Fold: 6  Epoch: 442  Training loss = 1.7451  Validation loss = 1.0454  \n",
      "\n",
      "Fold: 6  Epoch: 443  Training loss = 1.7448  Validation loss = 1.0447  \n",
      "\n",
      "Fold: 6  Epoch: 444  Training loss = 1.7444  Validation loss = 1.0443  \n",
      "\n",
      "Fold: 6  Epoch: 445  Training loss = 1.7438  Validation loss = 1.0429  \n",
      "\n",
      "Fold: 6  Epoch: 446  Training loss = 1.7434  Validation loss = 1.0417  \n",
      "\n",
      "Fold: 6  Epoch: 447  Training loss = 1.7428  Validation loss = 1.0403  \n",
      "\n",
      "Fold: 6  Epoch: 448  Training loss = 1.7424  Validation loss = 1.0400  \n",
      "\n",
      "Fold: 6  Epoch: 449  Training loss = 1.7418  Validation loss = 1.0390  \n",
      "\n",
      "Fold: 6  Epoch: 450  Training loss = 1.7413  Validation loss = 1.0374  \n",
      "\n",
      "Fold: 6  Epoch: 451  Training loss = 1.7410  Validation loss = 1.0368  \n",
      "\n",
      "Fold: 6  Epoch: 452  Training loss = 1.7406  Validation loss = 1.0366  \n",
      "\n",
      "Fold: 6  Epoch: 453  Training loss = 1.7401  Validation loss = 1.0361  \n",
      "\n",
      "Fold: 6  Epoch: 454  Training loss = 1.7395  Validation loss = 1.0345  \n",
      "\n",
      "Fold: 6  Epoch: 455  Training loss = 1.7390  Validation loss = 1.0328  \n",
      "\n",
      "Fold: 6  Epoch: 456  Training loss = 1.7384  Validation loss = 1.0315  \n",
      "\n",
      "Fold: 6  Epoch: 457  Training loss = 1.7378  Validation loss = 1.0293  \n",
      "\n",
      "Fold: 6  Epoch: 458  Training loss = 1.7373  Validation loss = 1.0280  \n",
      "\n",
      "Fold: 6  Epoch: 459  Training loss = 1.7369  Validation loss = 1.0269  \n",
      "\n",
      "Fold: 6  Epoch: 460  Training loss = 1.7364  Validation loss = 1.0259  \n",
      "\n",
      "Fold: 6  Epoch: 461  Training loss = 1.7360  Validation loss = 1.0255  \n",
      "\n",
      "Fold: 6  Epoch: 462  Training loss = 1.7357  Validation loss = 1.0252  \n",
      "\n",
      "Fold: 6  Epoch: 463  Training loss = 1.7352  Validation loss = 1.0247  \n",
      "\n",
      "Fold: 6  Epoch: 464  Training loss = 1.7348  Validation loss = 1.0237  \n",
      "\n",
      "Fold: 6  Epoch: 465  Training loss = 1.7345  Validation loss = 1.0231  \n",
      "\n",
      "Fold: 6  Epoch: 466  Training loss = 1.7340  Validation loss = 1.0223  \n",
      "\n",
      "Fold: 6  Epoch: 467  Training loss = 1.7337  Validation loss = 1.0214  \n",
      "\n",
      "Fold: 6  Epoch: 468  Training loss = 1.7334  Validation loss = 1.0207  \n",
      "\n",
      "Fold: 6  Epoch: 469  Training loss = 1.7328  Validation loss = 1.0200  \n",
      "\n",
      "Fold: 6  Epoch: 470  Training loss = 1.7324  Validation loss = 1.0187  \n",
      "\n",
      "Fold: 6  Epoch: 471  Training loss = 1.7318  Validation loss = 1.0177  \n",
      "\n",
      "Fold: 6  Epoch: 472  Training loss = 1.7313  Validation loss = 1.0165  \n",
      "\n",
      "Fold: 6  Epoch: 473  Training loss = 1.7308  Validation loss = 1.0156  \n",
      "\n",
      "Fold: 6  Epoch: 474  Training loss = 1.7304  Validation loss = 1.0142  \n",
      "\n",
      "Fold: 6  Epoch: 475  Training loss = 1.7299  Validation loss = 1.0135  \n",
      "\n",
      "Fold: 6  Epoch: 476  Training loss = 1.7297  Validation loss = 1.0128  \n",
      "\n",
      "Fold: 6  Epoch: 477  Training loss = 1.7291  Validation loss = 1.0117  \n",
      "\n",
      "Fold: 6  Epoch: 478  Training loss = 1.7287  Validation loss = 1.0103  \n",
      "\n",
      "Fold: 6  Epoch: 479  Training loss = 1.7282  Validation loss = 1.0098  \n",
      "\n",
      "Fold: 6  Epoch: 480  Training loss = 1.7276  Validation loss = 1.0086  \n",
      "\n",
      "Fold: 6  Epoch: 481  Training loss = 1.7272  Validation loss = 1.0079  \n",
      "\n",
      "Fold: 6  Epoch: 482  Training loss = 1.7269  Validation loss = 1.0074  \n",
      "\n",
      "Fold: 6  Epoch: 483  Training loss = 1.7267  Validation loss = 1.0075  \n",
      "\n",
      "Fold: 6  Epoch: 484  Training loss = 1.7261  Validation loss = 1.0058  \n",
      "\n",
      "Fold: 6  Epoch: 485  Training loss = 1.7259  Validation loss = 1.0056  \n",
      "\n",
      "Fold: 6  Epoch: 486  Training loss = 1.7255  Validation loss = 1.0050  \n",
      "\n",
      "Fold: 6  Epoch: 487  Training loss = 1.7252  Validation loss = 1.0049  \n",
      "\n",
      "Fold: 6  Epoch: 488  Training loss = 1.7247  Validation loss = 1.0040  \n",
      "\n",
      "Fold: 6  Epoch: 489  Training loss = 1.7243  Validation loss = 1.0031  \n",
      "\n",
      "Fold: 6  Epoch: 490  Training loss = 1.7238  Validation loss = 1.0023  \n",
      "\n",
      "Fold: 6  Epoch: 491  Training loss = 1.7233  Validation loss = 1.0009  \n",
      "\n",
      "Fold: 6  Epoch: 492  Training loss = 1.7229  Validation loss = 1.0000  \n",
      "\n",
      "Fold: 6  Epoch: 493  Training loss = 1.7223  Validation loss = 0.9980  \n",
      "\n",
      "Fold: 6  Epoch: 494  Training loss = 1.7219  Validation loss = 0.9976  \n",
      "\n",
      "Fold: 6  Epoch: 495  Training loss = 1.7214  Validation loss = 0.9966  \n",
      "\n",
      "Fold: 6  Epoch: 496  Training loss = 1.7209  Validation loss = 0.9953  \n",
      "\n",
      "Fold: 6  Epoch: 497  Training loss = 1.7204  Validation loss = 0.9939  \n",
      "\n",
      "Fold: 6  Epoch: 498  Training loss = 1.7199  Validation loss = 0.9927  \n",
      "\n",
      "Fold: 6  Epoch: 499  Training loss = 1.7194  Validation loss = 0.9918  \n",
      "\n",
      "Fold: 6  Epoch: 500  Training loss = 1.7189  Validation loss = 0.9908  \n",
      "\n",
      "Check model:  Fold: 6  Optimal epoch: 500  \n",
      "\n",
      "Fold: 7  Epoch: 1  Training loss = 1.6842  Validation loss = 1.0430  \n",
      "\n",
      "Fold: 7  Epoch: 2  Training loss = 1.6837  Validation loss = 1.0424  \n",
      "\n",
      "Fold: 7  Epoch: 3  Training loss = 1.6832  Validation loss = 1.0416  \n",
      "\n",
      "Fold: 7  Epoch: 4  Training loss = 1.6828  Validation loss = 1.0416  \n",
      "\n",
      "Fold: 7  Epoch: 5  Training loss = 1.6823  Validation loss = 1.0404  \n",
      "\n",
      "Fold: 7  Epoch: 6  Training loss = 1.6819  Validation loss = 1.0405  \n",
      "\n",
      "Fold: 7  Epoch: 7  Training loss = 1.6813  Validation loss = 1.0402  \n",
      "\n",
      "Fold: 7  Epoch: 8  Training loss = 1.6808  Validation loss = 1.0394  \n",
      "\n",
      "Fold: 7  Epoch: 9  Training loss = 1.6802  Validation loss = 1.0384  \n",
      "\n",
      "Fold: 7  Epoch: 10  Training loss = 1.6798  Validation loss = 1.0383  \n",
      "\n",
      "Fold: 7  Epoch: 11  Training loss = 1.6793  Validation loss = 1.0376  \n",
      "\n",
      "Fold: 7  Epoch: 12  Training loss = 1.6785  Validation loss = 1.0365  \n",
      "\n",
      "Fold: 7  Epoch: 13  Training loss = 1.6781  Validation loss = 1.0360  \n",
      "\n",
      "Fold: 7  Epoch: 14  Training loss = 1.6776  Validation loss = 1.0349  \n",
      "\n",
      "Fold: 7  Epoch: 15  Training loss = 1.6770  Validation loss = 1.0347  \n",
      "\n",
      "Fold: 7  Epoch: 16  Training loss = 1.6767  Validation loss = 1.0352  \n",
      "\n",
      "Fold: 7  Epoch: 17  Training loss = 1.6764  Validation loss = 1.0363  \n",
      "\n",
      "Fold: 7  Epoch: 18  Training loss = 1.6757  Validation loss = 1.0343  \n",
      "\n",
      "Fold: 7  Epoch: 19  Training loss = 1.6752  Validation loss = 1.0329  \n",
      "\n",
      "Fold: 7  Epoch: 20  Training loss = 1.6745  Validation loss = 1.0311  \n",
      "\n",
      "Fold: 7  Epoch: 21  Training loss = 1.6740  Validation loss = 1.0294  \n",
      "\n",
      "Fold: 7  Epoch: 22  Training loss = 1.6735  Validation loss = 1.0294  \n",
      "\n",
      "Fold: 7  Epoch: 23  Training loss = 1.6730  Validation loss = 1.0295  \n",
      "\n",
      "Fold: 7  Epoch: 24  Training loss = 1.6726  Validation loss = 1.0284  \n",
      "\n",
      "Fold: 7  Epoch: 25  Training loss = 1.6721  Validation loss = 1.0274  \n",
      "\n",
      "Fold: 7  Epoch: 26  Training loss = 1.6715  Validation loss = 1.0259  \n",
      "\n",
      "Fold: 7  Epoch: 27  Training loss = 1.6711  Validation loss = 1.0266  \n",
      "\n",
      "Fold: 7  Epoch: 28  Training loss = 1.6707  Validation loss = 1.0276  \n",
      "\n",
      "Fold: 7  Epoch: 29  Training loss = 1.6703  Validation loss = 1.0286  \n",
      "\n",
      "Fold: 7  Epoch: 30  Training loss = 1.6699  Validation loss = 1.0288  \n",
      "\n",
      "Fold: 7  Epoch: 31  Training loss = 1.6694  Validation loss = 1.0287  \n",
      "\n",
      "Fold: 7  Epoch: 32  Training loss = 1.6686  Validation loss = 1.0265  \n",
      "\n",
      "Fold: 7  Epoch: 33  Training loss = 1.6681  Validation loss = 1.0249  \n",
      "\n",
      "Fold: 7  Epoch: 34  Training loss = 1.6678  Validation loss = 1.0251  \n",
      "\n",
      "Fold: 7  Epoch: 35  Training loss = 1.6674  Validation loss = 1.0251  \n",
      "\n",
      "Fold: 7  Epoch: 36  Training loss = 1.6670  Validation loss = 1.0250  \n",
      "\n",
      "Fold: 7  Epoch: 37  Training loss = 1.6666  Validation loss = 1.0237  \n",
      "\n",
      "Fold: 7  Epoch: 38  Training loss = 1.6661  Validation loss = 1.0230  \n",
      "\n",
      "Fold: 7  Epoch: 39  Training loss = 1.6654  Validation loss = 1.0217  \n",
      "\n",
      "Fold: 7  Epoch: 40  Training loss = 1.6651  Validation loss = 1.0215  \n",
      "\n",
      "Fold: 7  Epoch: 41  Training loss = 1.6643  Validation loss = 1.0199  \n",
      "\n",
      "Fold: 7  Epoch: 42  Training loss = 1.6637  Validation loss = 1.0184  \n",
      "\n",
      "Fold: 7  Epoch: 43  Training loss = 1.6632  Validation loss = 1.0165  \n",
      "\n",
      "Fold: 7  Epoch: 44  Training loss = 1.6627  Validation loss = 1.0147  \n",
      "\n",
      "Fold: 7  Epoch: 45  Training loss = 1.6623  Validation loss = 1.0145  \n",
      "\n",
      "Fold: 7  Epoch: 46  Training loss = 1.6619  Validation loss = 1.0129  \n",
      "\n",
      "Fold: 7  Epoch: 47  Training loss = 1.6614  Validation loss = 1.0126  \n",
      "\n",
      "Fold: 7  Epoch: 48  Training loss = 1.6610  Validation loss = 1.0124  \n",
      "\n",
      "Fold: 7  Epoch: 49  Training loss = 1.6606  Validation loss = 1.0120  \n",
      "\n",
      "Fold: 7  Epoch: 50  Training loss = 1.6599  Validation loss = 1.0109  \n",
      "\n",
      "Fold: 7  Epoch: 51  Training loss = 1.6594  Validation loss = 1.0095  \n",
      "\n",
      "Fold: 7  Epoch: 52  Training loss = 1.6588  Validation loss = 1.0102  \n",
      "\n",
      "Fold: 7  Epoch: 53  Training loss = 1.6584  Validation loss = 1.0092  \n",
      "\n",
      "Fold: 7  Epoch: 54  Training loss = 1.6577  Validation loss = 1.0068  \n",
      "\n",
      "Fold: 7  Epoch: 55  Training loss = 1.6571  Validation loss = 1.0048  \n",
      "\n",
      "Fold: 7  Epoch: 56  Training loss = 1.6564  Validation loss = 1.0032  \n",
      "\n",
      "Fold: 7  Epoch: 57  Training loss = 1.6559  Validation loss = 1.0031  \n",
      "\n",
      "Fold: 7  Epoch: 58  Training loss = 1.6555  Validation loss = 1.0033  \n",
      "\n",
      "Fold: 7  Epoch: 59  Training loss = 1.6550  Validation loss = 1.0023  \n",
      "\n",
      "Fold: 7  Epoch: 60  Training loss = 1.6544  Validation loss = 1.0005  \n",
      "\n",
      "Fold: 7  Epoch: 61  Training loss = 1.6541  Validation loss = 1.0007  \n",
      "\n",
      "Fold: 7  Epoch: 62  Training loss = 1.6535  Validation loss = 1.0000  \n",
      "\n",
      "Fold: 7  Epoch: 63  Training loss = 1.6530  Validation loss = 0.9991  \n",
      "\n",
      "Fold: 7  Epoch: 64  Training loss = 1.6525  Validation loss = 0.9980  \n",
      "\n",
      "Fold: 7  Epoch: 65  Training loss = 1.6522  Validation loss = 0.9973  \n",
      "\n",
      "Fold: 7  Epoch: 66  Training loss = 1.6516  Validation loss = 0.9962  \n",
      "\n",
      "Fold: 7  Epoch: 67  Training loss = 1.6511  Validation loss = 0.9954  \n",
      "\n",
      "Fold: 7  Epoch: 68  Training loss = 1.6506  Validation loss = 0.9942  \n",
      "\n",
      "Fold: 7  Epoch: 69  Training loss = 1.6502  Validation loss = 0.9932  \n",
      "\n",
      "Fold: 7  Epoch: 70  Training loss = 1.6497  Validation loss = 0.9915  \n",
      "\n",
      "Fold: 7  Epoch: 71  Training loss = 1.6492  Validation loss = 0.9924  \n",
      "\n",
      "Fold: 7  Epoch: 72  Training loss = 1.6487  Validation loss = 0.9915  \n",
      "\n",
      "Fold: 7  Epoch: 73  Training loss = 1.6483  Validation loss = 0.9918  \n",
      "\n",
      "Fold: 7  Epoch: 74  Training loss = 1.6479  Validation loss = 0.9911  \n",
      "\n",
      "Fold: 7  Epoch: 75  Training loss = 1.6475  Validation loss = 0.9905  \n",
      "\n",
      "Fold: 7  Epoch: 76  Training loss = 1.6470  Validation loss = 0.9917  \n",
      "\n",
      "Fold: 7  Epoch: 77  Training loss = 1.6468  Validation loss = 0.9937  \n",
      "\n",
      "Fold: 7  Epoch: 78  Training loss = 1.6462  Validation loss = 0.9925  \n",
      "\n",
      "Fold: 7  Epoch: 79  Training loss = 1.6458  Validation loss = 0.9932  \n",
      "\n",
      "Fold: 7  Epoch: 80  Training loss = 1.6454  Validation loss = 0.9928  \n",
      "\n",
      "Fold: 7  Epoch: 81  Training loss = 1.6449  Validation loss = 0.9926  \n",
      "\n",
      "Fold: 7  Epoch: 82  Training loss = 1.6443  Validation loss = 0.9917  \n",
      "\n",
      "Fold: 7  Epoch: 83  Training loss = 1.6439  Validation loss = 0.9921  \n",
      "\n",
      "Fold: 7  Epoch: 84  Training loss = 1.6435  Validation loss = 0.9908  \n",
      "\n",
      "Fold: 7  Epoch: 85  Training loss = 1.6431  Validation loss = 0.9919  \n",
      "\n",
      "Fold: 7  Epoch: 86  Training loss = 1.6426  Validation loss = 0.9915  \n",
      "\n",
      "Fold: 7  Epoch: 87  Training loss = 1.6420  Validation loss = 0.9913  \n",
      "\n",
      "Fold: 7  Epoch: 88  Training loss = 1.6414  Validation loss = 0.9905  \n",
      "\n",
      "Fold: 7  Epoch: 89  Training loss = 1.6410  Validation loss = 0.9904  \n",
      "\n",
      "Fold: 7  Epoch: 90  Training loss = 1.6407  Validation loss = 0.9900  \n",
      "\n",
      "Fold: 7  Epoch: 91  Training loss = 1.6401  Validation loss = 0.9885  \n",
      "\n",
      "Fold: 7  Epoch: 92  Training loss = 1.6397  Validation loss = 0.9882  \n",
      "\n",
      "Fold: 7  Epoch: 93  Training loss = 1.6393  Validation loss = 0.9867  \n",
      "\n",
      "Fold: 7  Epoch: 94  Training loss = 1.6390  Validation loss = 0.9871  \n",
      "\n",
      "Fold: 7  Epoch: 95  Training loss = 1.6385  Validation loss = 0.9866  \n",
      "\n",
      "Fold: 7  Epoch: 96  Training loss = 1.6380  Validation loss = 0.9853  \n",
      "\n",
      "Fold: 7  Epoch: 97  Training loss = 1.6376  Validation loss = 0.9850  \n",
      "\n",
      "Fold: 7  Epoch: 98  Training loss = 1.6373  Validation loss = 0.9856  \n",
      "\n",
      "Fold: 7  Epoch: 99  Training loss = 1.6369  Validation loss = 0.9846  \n",
      "\n",
      "Fold: 7  Epoch: 100  Training loss = 1.6366  Validation loss = 0.9843  \n",
      "\n",
      "Fold: 7  Epoch: 101  Training loss = 1.6360  Validation loss = 0.9828  \n",
      "\n",
      "Fold: 7  Epoch: 102  Training loss = 1.6357  Validation loss = 0.9834  \n",
      "\n",
      "Fold: 7  Epoch: 103  Training loss = 1.6353  Validation loss = 0.9836  \n",
      "\n",
      "Fold: 7  Epoch: 104  Training loss = 1.6349  Validation loss = 0.9813  \n",
      "\n",
      "Fold: 7  Epoch: 105  Training loss = 1.6342  Validation loss = 0.9807  \n",
      "\n",
      "Fold: 7  Epoch: 106  Training loss = 1.6338  Validation loss = 0.9797  \n",
      "\n",
      "Fold: 7  Epoch: 107  Training loss = 1.6335  Validation loss = 0.9786  \n",
      "\n",
      "Fold: 7  Epoch: 108  Training loss = 1.6329  Validation loss = 0.9767  \n",
      "\n",
      "Fold: 7  Epoch: 109  Training loss = 1.6326  Validation loss = 0.9776  \n",
      "\n",
      "Fold: 7  Epoch: 110  Training loss = 1.6322  Validation loss = 0.9781  \n",
      "\n",
      "Fold: 7  Epoch: 111  Training loss = 1.6318  Validation loss = 0.9781  \n",
      "\n",
      "Fold: 7  Epoch: 112  Training loss = 1.6310  Validation loss = 0.9762  \n",
      "\n",
      "Fold: 7  Epoch: 113  Training loss = 1.6305  Validation loss = 0.9756  \n",
      "\n",
      "Fold: 7  Epoch: 114  Training loss = 1.6300  Validation loss = 0.9748  \n",
      "\n",
      "Fold: 7  Epoch: 115  Training loss = 1.6294  Validation loss = 0.9734  \n",
      "\n",
      "Fold: 7  Epoch: 116  Training loss = 1.6288  Validation loss = 0.9713  \n",
      "\n",
      "Fold: 7  Epoch: 117  Training loss = 1.6285  Validation loss = 0.9708  \n",
      "\n",
      "Fold: 7  Epoch: 118  Training loss = 1.6280  Validation loss = 0.9712  \n",
      "\n",
      "Fold: 7  Epoch: 119  Training loss = 1.6275  Validation loss = 0.9701  \n",
      "\n",
      "Fold: 7  Epoch: 120  Training loss = 1.6268  Validation loss = 0.9689  \n",
      "\n",
      "Fold: 7  Epoch: 121  Training loss = 1.6263  Validation loss = 0.9683  \n",
      "\n",
      "Fold: 7  Epoch: 122  Training loss = 1.6259  Validation loss = 0.9675  \n",
      "\n",
      "Fold: 7  Epoch: 123  Training loss = 1.6255  Validation loss = 0.9680  \n",
      "\n",
      "Fold: 7  Epoch: 124  Training loss = 1.6251  Validation loss = 0.9669  \n",
      "\n",
      "Fold: 7  Epoch: 125  Training loss = 1.6244  Validation loss = 0.9651  \n",
      "\n",
      "Fold: 7  Epoch: 126  Training loss = 1.6239  Validation loss = 0.9661  \n",
      "\n",
      "Fold: 7  Epoch: 127  Training loss = 1.6233  Validation loss = 0.9660  \n",
      "\n",
      "Fold: 7  Epoch: 128  Training loss = 1.6230  Validation loss = 0.9667  \n",
      "\n",
      "Fold: 7  Epoch: 129  Training loss = 1.6226  Validation loss = 0.9660  \n",
      "\n",
      "Fold: 7  Epoch: 130  Training loss = 1.6221  Validation loss = 0.9649  \n",
      "\n",
      "Fold: 7  Epoch: 131  Training loss = 1.6216  Validation loss = 0.9622  \n",
      "\n",
      "Fold: 7  Epoch: 132  Training loss = 1.6209  Validation loss = 0.9590  \n",
      "\n",
      "Fold: 7  Epoch: 133  Training loss = 1.6205  Validation loss = 0.9586  \n",
      "\n",
      "Fold: 7  Epoch: 134  Training loss = 1.6198  Validation loss = 0.9578  \n",
      "\n",
      "Fold: 7  Epoch: 135  Training loss = 1.6195  Validation loss = 0.9587  \n",
      "\n",
      "Fold: 7  Epoch: 136  Training loss = 1.6188  Validation loss = 0.9569  \n",
      "\n",
      "Fold: 7  Epoch: 137  Training loss = 1.6183  Validation loss = 0.9571  \n",
      "\n",
      "Fold: 7  Epoch: 138  Training loss = 1.6177  Validation loss = 0.9539  \n",
      "\n",
      "Fold: 7  Epoch: 139  Training loss = 1.6173  Validation loss = 0.9520  \n",
      "\n",
      "Fold: 7  Epoch: 140  Training loss = 1.6169  Validation loss = 0.9527  \n",
      "\n",
      "Fold: 7  Epoch: 141  Training loss = 1.6163  Validation loss = 0.9506  \n",
      "\n",
      "Fold: 7  Epoch: 142  Training loss = 1.6161  Validation loss = 0.9512  \n",
      "\n",
      "Fold: 7  Epoch: 143  Training loss = 1.6155  Validation loss = 0.9502  \n",
      "\n",
      "Fold: 7  Epoch: 144  Training loss = 1.6152  Validation loss = 0.9509  \n",
      "\n",
      "Fold: 7  Epoch: 145  Training loss = 1.6148  Validation loss = 0.9510  \n",
      "\n",
      "Fold: 7  Epoch: 146  Training loss = 1.6144  Validation loss = 0.9505  \n",
      "\n",
      "Fold: 7  Epoch: 147  Training loss = 1.6137  Validation loss = 0.9486  \n",
      "\n",
      "Fold: 7  Epoch: 148  Training loss = 1.6134  Validation loss = 0.9487  \n",
      "\n",
      "Fold: 7  Epoch: 149  Training loss = 1.6131  Validation loss = 0.9486  \n",
      "\n",
      "Fold: 7  Epoch: 150  Training loss = 1.6126  Validation loss = 0.9493  \n",
      "\n",
      "Fold: 7  Epoch: 151  Training loss = 1.6120  Validation loss = 0.9472  \n",
      "\n",
      "Fold: 7  Epoch: 152  Training loss = 1.6114  Validation loss = 0.9463  \n",
      "\n",
      "Fold: 7  Epoch: 153  Training loss = 1.6111  Validation loss = 0.9456  \n",
      "\n",
      "Fold: 7  Epoch: 154  Training loss = 1.6108  Validation loss = 0.9444  \n",
      "\n",
      "Fold: 7  Epoch: 155  Training loss = 1.6105  Validation loss = 0.9469  \n",
      "\n",
      "Fold: 7  Epoch: 156  Training loss = 1.6102  Validation loss = 0.9466  \n",
      "\n",
      "Fold: 7  Epoch: 157  Training loss = 1.6095  Validation loss = 0.9434  \n",
      "\n",
      "Fold: 7  Epoch: 158  Training loss = 1.6091  Validation loss = 0.9436  \n",
      "\n",
      "Fold: 7  Epoch: 159  Training loss = 1.6088  Validation loss = 0.9433  \n",
      "\n",
      "Fold: 7  Epoch: 160  Training loss = 1.6083  Validation loss = 0.9410  \n",
      "\n",
      "Fold: 7  Epoch: 161  Training loss = 1.6080  Validation loss = 0.9414  \n",
      "\n",
      "Fold: 7  Epoch: 162  Training loss = 1.6076  Validation loss = 0.9416  \n",
      "\n",
      "Fold: 7  Epoch: 163  Training loss = 1.6071  Validation loss = 0.9411  \n",
      "\n",
      "Fold: 7  Epoch: 164  Training loss = 1.6068  Validation loss = 0.9424  \n",
      "\n",
      "Fold: 7  Epoch: 165  Training loss = 1.6064  Validation loss = 0.9416  \n",
      "\n",
      "Fold: 7  Epoch: 166  Training loss = 1.6060  Validation loss = 0.9418  \n",
      "\n",
      "Fold: 7  Epoch: 167  Training loss = 1.6055  Validation loss = 0.9403  \n",
      "\n",
      "Fold: 7  Epoch: 168  Training loss = 1.6049  Validation loss = 0.9398  \n",
      "\n",
      "Fold: 7  Epoch: 169  Training loss = 1.6045  Validation loss = 0.9397  \n",
      "\n",
      "Fold: 7  Epoch: 170  Training loss = 1.6040  Validation loss = 0.9398  \n",
      "\n",
      "Fold: 7  Epoch: 171  Training loss = 1.6034  Validation loss = 0.9386  \n",
      "\n",
      "Fold: 7  Epoch: 172  Training loss = 1.6029  Validation loss = 0.9373  \n",
      "\n",
      "Fold: 7  Epoch: 173  Training loss = 1.6024  Validation loss = 0.9359  \n",
      "\n",
      "Fold: 7  Epoch: 174  Training loss = 1.6019  Validation loss = 0.9351  \n",
      "\n",
      "Fold: 7  Epoch: 175  Training loss = 1.6014  Validation loss = 0.9340  \n",
      "\n",
      "Fold: 7  Epoch: 176  Training loss = 1.6008  Validation loss = 0.9337  \n",
      "\n",
      "Fold: 7  Epoch: 177  Training loss = 1.6005  Validation loss = 0.9332  \n",
      "\n",
      "Fold: 7  Epoch: 178  Training loss = 1.6001  Validation loss = 0.9317  \n",
      "\n",
      "Fold: 7  Epoch: 179  Training loss = 1.5995  Validation loss = 0.9311  \n",
      "\n",
      "Fold: 7  Epoch: 180  Training loss = 1.5992  Validation loss = 0.9299  \n",
      "\n",
      "Fold: 7  Epoch: 181  Training loss = 1.5988  Validation loss = 0.9308  \n",
      "\n",
      "Fold: 7  Epoch: 182  Training loss = 1.5984  Validation loss = 0.9306  \n",
      "\n",
      "Fold: 7  Epoch: 183  Training loss = 1.5981  Validation loss = 0.9309  \n",
      "\n",
      "Fold: 7  Epoch: 184  Training loss = 1.5977  Validation loss = 0.9312  \n",
      "\n",
      "Fold: 7  Epoch: 185  Training loss = 1.5971  Validation loss = 0.9296  \n",
      "\n",
      "Fold: 7  Epoch: 186  Training loss = 1.5967  Validation loss = 0.9277  \n",
      "\n",
      "Fold: 7  Epoch: 187  Training loss = 1.5962  Validation loss = 0.9276  \n",
      "\n",
      "Fold: 7  Epoch: 188  Training loss = 1.5958  Validation loss = 0.9285  \n",
      "\n",
      "Fold: 7  Epoch: 189  Training loss = 1.5954  Validation loss = 0.9282  \n",
      "\n",
      "Fold: 7  Epoch: 190  Training loss = 1.5950  Validation loss = 0.9281  \n",
      "\n",
      "Fold: 7  Epoch: 191  Training loss = 1.5947  Validation loss = 0.9306  \n",
      "\n",
      "Fold: 7  Epoch: 192  Training loss = 1.5941  Validation loss = 0.9295  \n",
      "\n",
      "Fold: 7  Epoch: 193  Training loss = 1.5936  Validation loss = 0.9288  \n",
      "\n",
      "Fold: 7  Epoch: 194  Training loss = 1.5933  Validation loss = 0.9280  \n",
      "\n",
      "Fold: 7  Epoch: 195  Training loss = 1.5928  Validation loss = 0.9275  \n",
      "\n",
      "Fold: 7  Epoch: 196  Training loss = 1.5922  Validation loss = 0.9267  \n",
      "\n",
      "Fold: 7  Epoch: 197  Training loss = 1.5919  Validation loss = 0.9274  \n",
      "\n",
      "Fold: 7  Epoch: 198  Training loss = 1.5913  Validation loss = 0.9259  \n",
      "\n",
      "Fold: 7  Epoch: 199  Training loss = 1.5909  Validation loss = 0.9268  \n",
      "\n",
      "Fold: 7  Epoch: 200  Training loss = 1.5904  Validation loss = 0.9273  \n",
      "\n",
      "Fold: 7  Epoch: 201  Training loss = 1.5898  Validation loss = 0.9264  \n",
      "\n",
      "Fold: 7  Epoch: 202  Training loss = 1.5895  Validation loss = 0.9268  \n",
      "\n",
      "Fold: 7  Epoch: 203  Training loss = 1.5890  Validation loss = 0.9239  \n",
      "\n",
      "Fold: 7  Epoch: 204  Training loss = 1.5885  Validation loss = 0.9234  \n",
      "\n",
      "Fold: 7  Epoch: 205  Training loss = 1.5881  Validation loss = 0.9233  \n",
      "\n",
      "Fold: 7  Epoch: 206  Training loss = 1.5875  Validation loss = 0.9244  \n",
      "\n",
      "Fold: 7  Epoch: 207  Training loss = 1.5870  Validation loss = 0.9250  \n",
      "\n",
      "Fold: 7  Epoch: 208  Training loss = 1.5866  Validation loss = 0.9263  \n",
      "\n",
      "Fold: 7  Epoch: 209  Training loss = 1.5862  Validation loss = 0.9253  \n",
      "\n",
      "Fold: 7  Epoch: 210  Training loss = 1.5857  Validation loss = 0.9237  \n",
      "\n",
      "Fold: 7  Epoch: 211  Training loss = 1.5853  Validation loss = 0.9232  \n",
      "\n",
      "Fold: 7  Epoch: 212  Training loss = 1.5848  Validation loss = 0.9228  \n",
      "\n",
      "Fold: 7  Epoch: 213  Training loss = 1.5845  Validation loss = 0.9234  \n",
      "\n",
      "Fold: 7  Epoch: 214  Training loss = 1.5840  Validation loss = 0.9250  \n",
      "\n",
      "Fold: 7  Epoch: 215  Training loss = 1.5835  Validation loss = 0.9260  \n",
      "\n",
      "Fold: 7  Epoch: 216  Training loss = 1.5831  Validation loss = 0.9264  \n",
      "\n",
      "Check model:  Fold: 7  Optimal epoch: 212  \n",
      "\n",
      "Fold: 8  Epoch: 1  Training loss = 1.5434  Validation loss = 5.7316  \n",
      "\n",
      "Fold: 8  Epoch: 2  Training loss = 1.5428  Validation loss = 5.7298  \n",
      "\n",
      "Fold: 8  Epoch: 3  Training loss = 1.5423  Validation loss = 5.7288  \n",
      "\n",
      "Fold: 8  Epoch: 4  Training loss = 1.5420  Validation loss = 5.7288  \n",
      "\n",
      "Fold: 8  Epoch: 5  Training loss = 1.5415  Validation loss = 5.7273  \n",
      "\n",
      "Fold: 8  Epoch: 6  Training loss = 1.5413  Validation loss = 5.7276  \n",
      "\n",
      "Fold: 8  Epoch: 7  Training loss = 1.5407  Validation loss = 5.7255  \n",
      "\n",
      "Fold: 8  Epoch: 8  Training loss = 1.5404  Validation loss = 5.7253  \n",
      "\n",
      "Fold: 8  Epoch: 9  Training loss = 1.5400  Validation loss = 5.7246  \n",
      "\n",
      "Fold: 8  Epoch: 10  Training loss = 1.5395  Validation loss = 5.7230  \n",
      "\n",
      "Fold: 8  Epoch: 11  Training loss = 1.5389  Validation loss = 5.7215  \n",
      "\n",
      "Fold: 8  Epoch: 12  Training loss = 1.5385  Validation loss = 5.7218  \n",
      "\n",
      "Fold: 8  Epoch: 13  Training loss = 1.5380  Validation loss = 5.7198  \n",
      "\n",
      "Fold: 8  Epoch: 14  Training loss = 1.5376  Validation loss = 5.7188  \n",
      "\n",
      "Fold: 8  Epoch: 15  Training loss = 1.5374  Validation loss = 5.7187  \n",
      "\n",
      "Fold: 8  Epoch: 16  Training loss = 1.5370  Validation loss = 5.7182  \n",
      "\n",
      "Fold: 8  Epoch: 17  Training loss = 1.5369  Validation loss = 5.7198  \n",
      "\n",
      "Fold: 8  Epoch: 18  Training loss = 1.5366  Validation loss = 5.7198  \n",
      "\n",
      "Fold: 8  Epoch: 19  Training loss = 1.5361  Validation loss = 5.7179  \n",
      "\n",
      "Fold: 8  Epoch: 20  Training loss = 1.5355  Validation loss = 5.7156  \n",
      "\n",
      "Fold: 8  Epoch: 21  Training loss = 1.5351  Validation loss = 5.7149  \n",
      "\n",
      "Fold: 8  Epoch: 22  Training loss = 1.5347  Validation loss = 5.7144  \n",
      "\n",
      "Fold: 8  Epoch: 23  Training loss = 1.5341  Validation loss = 5.7132  \n",
      "\n",
      "Fold: 8  Epoch: 24  Training loss = 1.5338  Validation loss = 5.7127  \n",
      "\n",
      "Fold: 8  Epoch: 25  Training loss = 1.5333  Validation loss = 5.7107  \n",
      "\n",
      "Fold: 8  Epoch: 26  Training loss = 1.5328  Validation loss = 5.7097  \n",
      "\n",
      "Fold: 8  Epoch: 27  Training loss = 1.5324  Validation loss = 5.7090  \n",
      "\n",
      "Fold: 8  Epoch: 28  Training loss = 1.5320  Validation loss = 5.7084  \n",
      "\n",
      "Fold: 8  Epoch: 29  Training loss = 1.5314  Validation loss = 5.7069  \n",
      "\n",
      "Fold: 8  Epoch: 30  Training loss = 1.5309  Validation loss = 5.7049  \n",
      "\n",
      "Fold: 8  Epoch: 31  Training loss = 1.5305  Validation loss = 5.7041  \n",
      "\n",
      "Fold: 8  Epoch: 32  Training loss = 1.5301  Validation loss = 5.7049  \n",
      "\n",
      "Fold: 8  Epoch: 33  Training loss = 1.5297  Validation loss = 5.7032  \n",
      "\n",
      "Fold: 8  Epoch: 34  Training loss = 1.5293  Validation loss = 5.7028  \n",
      "\n",
      "Fold: 8  Epoch: 35  Training loss = 1.5287  Validation loss = 5.7007  \n",
      "\n",
      "Fold: 8  Epoch: 36  Training loss = 1.5283  Validation loss = 5.7005  \n",
      "\n",
      "Fold: 8  Epoch: 37  Training loss = 1.5279  Validation loss = 5.7012  \n",
      "\n",
      "Fold: 8  Epoch: 38  Training loss = 1.5273  Validation loss = 5.7003  \n",
      "\n",
      "Fold: 8  Epoch: 39  Training loss = 1.5270  Validation loss = 5.6991  \n",
      "\n",
      "Fold: 8  Epoch: 40  Training loss = 1.5264  Validation loss = 5.6973  \n",
      "\n",
      "Fold: 8  Epoch: 41  Training loss = 1.5262  Validation loss = 5.6975  \n",
      "\n",
      "Fold: 8  Epoch: 42  Training loss = 1.5258  Validation loss = 5.6968  \n",
      "\n",
      "Fold: 8  Epoch: 43  Training loss = 1.5250  Validation loss = 5.6943  \n",
      "\n",
      "Fold: 8  Epoch: 44  Training loss = 1.5247  Validation loss = 5.6943  \n",
      "\n",
      "Fold: 8  Epoch: 45  Training loss = 1.5245  Validation loss = 5.6946  \n",
      "\n",
      "Fold: 8  Epoch: 46  Training loss = 1.5240  Validation loss = 5.6939  \n",
      "\n",
      "Fold: 8  Epoch: 47  Training loss = 1.5235  Validation loss = 5.6931  \n",
      "\n",
      "Fold: 8  Epoch: 48  Training loss = 1.5230  Validation loss = 5.6907  \n",
      "\n",
      "Fold: 8  Epoch: 49  Training loss = 1.5225  Validation loss = 5.6891  \n",
      "\n",
      "Fold: 8  Epoch: 50  Training loss = 1.5220  Validation loss = 5.6864  \n",
      "\n",
      "Fold: 8  Epoch: 51  Training loss = 1.5212  Validation loss = 5.6845  \n",
      "\n",
      "Fold: 8  Epoch: 52  Training loss = 1.5210  Validation loss = 5.6837  \n",
      "\n",
      "Fold: 8  Epoch: 53  Training loss = 1.5208  Validation loss = 5.6836  \n",
      "\n",
      "Fold: 8  Epoch: 54  Training loss = 1.5204  Validation loss = 5.6835  \n",
      "\n",
      "Fold: 8  Epoch: 55  Training loss = 1.5199  Validation loss = 5.6824  \n",
      "\n",
      "Fold: 8  Epoch: 56  Training loss = 1.5194  Validation loss = 5.6811  \n",
      "\n",
      "Fold: 8  Epoch: 57  Training loss = 1.5192  Validation loss = 5.6812  \n",
      "\n",
      "Fold: 8  Epoch: 58  Training loss = 1.5187  Validation loss = 5.6811  \n",
      "\n",
      "Fold: 8  Epoch: 59  Training loss = 1.5182  Validation loss = 5.6790  \n",
      "\n",
      "Fold: 8  Epoch: 60  Training loss = 1.5179  Validation loss = 5.6785  \n",
      "\n",
      "Fold: 8  Epoch: 61  Training loss = 1.5174  Validation loss = 5.6783  \n",
      "\n",
      "Fold: 8  Epoch: 62  Training loss = 1.5170  Validation loss = 5.6768  \n",
      "\n",
      "Fold: 8  Epoch: 63  Training loss = 1.5165  Validation loss = 5.6748  \n",
      "\n",
      "Fold: 8  Epoch: 64  Training loss = 1.5161  Validation loss = 5.6727  \n",
      "\n",
      "Fold: 8  Epoch: 65  Training loss = 1.5156  Validation loss = 5.6724  \n",
      "\n",
      "Fold: 8  Epoch: 66  Training loss = 1.5152  Validation loss = 5.6720  \n",
      "\n",
      "Fold: 8  Epoch: 67  Training loss = 1.5148  Validation loss = 5.6726  \n",
      "\n",
      "Fold: 8  Epoch: 68  Training loss = 1.5142  Validation loss = 5.6715  \n",
      "\n",
      "Fold: 8  Epoch: 69  Training loss = 1.5140  Validation loss = 5.6714  \n",
      "\n",
      "Fold: 8  Epoch: 70  Training loss = 1.5134  Validation loss = 5.6688  \n",
      "\n",
      "Fold: 8  Epoch: 71  Training loss = 1.5128  Validation loss = 5.6670  \n",
      "\n",
      "Fold: 8  Epoch: 72  Training loss = 1.5124  Validation loss = 5.6653  \n",
      "\n",
      "Fold: 8  Epoch: 73  Training loss = 1.5119  Validation loss = 5.6648  \n",
      "\n",
      "Fold: 8  Epoch: 74  Training loss = 1.5116  Validation loss = 5.6661  \n",
      "\n",
      "Fold: 8  Epoch: 75  Training loss = 1.5112  Validation loss = 5.6643  \n",
      "\n",
      "Fold: 8  Epoch: 76  Training loss = 1.5109  Validation loss = 5.6628  \n",
      "\n",
      "Fold: 8  Epoch: 77  Training loss = 1.5106  Validation loss = 5.6629  \n",
      "\n",
      "Fold: 8  Epoch: 78  Training loss = 1.5099  Validation loss = 5.6612  \n",
      "\n",
      "Fold: 8  Epoch: 79  Training loss = 1.5095  Validation loss = 5.6597  \n",
      "\n",
      "Fold: 8  Epoch: 80  Training loss = 1.5092  Validation loss = 5.6603  \n",
      "\n",
      "Fold: 8  Epoch: 81  Training loss = 1.5088  Validation loss = 5.6596  \n",
      "\n",
      "Fold: 8  Epoch: 82  Training loss = 1.5084  Validation loss = 5.6576  \n",
      "\n",
      "Fold: 8  Epoch: 83  Training loss = 1.5081  Validation loss = 5.6581  \n",
      "\n",
      "Fold: 8  Epoch: 84  Training loss = 1.5076  Validation loss = 5.6585  \n",
      "\n",
      "Fold: 8  Epoch: 85  Training loss = 1.5073  Validation loss = 5.6578  \n",
      "\n",
      "Fold: 8  Epoch: 86  Training loss = 1.5070  Validation loss = 5.6570  \n",
      "\n",
      "Fold: 8  Epoch: 87  Training loss = 1.5066  Validation loss = 5.6563  \n",
      "\n",
      "Fold: 8  Epoch: 88  Training loss = 1.5064  Validation loss = 5.6570  \n",
      "\n",
      "Fold: 8  Epoch: 89  Training loss = 1.5057  Validation loss = 5.6555  \n",
      "\n",
      "Fold: 8  Epoch: 90  Training loss = 1.5053  Validation loss = 5.6530  \n",
      "\n",
      "Fold: 8  Epoch: 91  Training loss = 1.5049  Validation loss = 5.6520  \n",
      "\n",
      "Fold: 8  Epoch: 92  Training loss = 1.5045  Validation loss = 5.6513  \n",
      "\n",
      "Fold: 8  Epoch: 93  Training loss = 1.5041  Validation loss = 5.6501  \n",
      "\n",
      "Fold: 8  Epoch: 94  Training loss = 1.5037  Validation loss = 5.6503  \n",
      "\n",
      "Fold: 8  Epoch: 95  Training loss = 1.5034  Validation loss = 5.6502  \n",
      "\n",
      "Fold: 8  Epoch: 96  Training loss = 1.5029  Validation loss = 5.6491  \n",
      "\n",
      "Fold: 8  Epoch: 97  Training loss = 1.5026  Validation loss = 5.6483  \n",
      "\n",
      "Fold: 8  Epoch: 98  Training loss = 1.5022  Validation loss = 5.6472  \n",
      "\n",
      "Fold: 8  Epoch: 99  Training loss = 1.5018  Validation loss = 5.6463  \n",
      "\n",
      "Fold: 8  Epoch: 100  Training loss = 1.5014  Validation loss = 5.6457  \n",
      "\n",
      "Fold: 8  Epoch: 101  Training loss = 1.5009  Validation loss = 5.6440  \n",
      "\n",
      "Fold: 8  Epoch: 102  Training loss = 1.5005  Validation loss = 5.6432  \n",
      "\n",
      "Fold: 8  Epoch: 103  Training loss = 1.5001  Validation loss = 5.6414  \n",
      "\n",
      "Fold: 8  Epoch: 104  Training loss = 1.4995  Validation loss = 5.6392  \n",
      "\n",
      "Fold: 8  Epoch: 105  Training loss = 1.4991  Validation loss = 5.6389  \n",
      "\n",
      "Fold: 8  Epoch: 106  Training loss = 1.4986  Validation loss = 5.6372  \n",
      "\n",
      "Fold: 8  Epoch: 107  Training loss = 1.4980  Validation loss = 5.6348  \n",
      "\n",
      "Fold: 8  Epoch: 108  Training loss = 1.4975  Validation loss = 5.6336  \n",
      "\n",
      "Fold: 8  Epoch: 109  Training loss = 1.4971  Validation loss = 5.6331  \n",
      "\n",
      "Fold: 8  Epoch: 110  Training loss = 1.4965  Validation loss = 5.6313  \n",
      "\n",
      "Fold: 8  Epoch: 111  Training loss = 1.4961  Validation loss = 5.6306  \n",
      "\n",
      "Fold: 8  Epoch: 112  Training loss = 1.4959  Validation loss = 5.6312  \n",
      "\n",
      "Fold: 8  Epoch: 113  Training loss = 1.4955  Validation loss = 5.6293  \n",
      "\n",
      "Fold: 8  Epoch: 114  Training loss = 1.4952  Validation loss = 5.6288  \n",
      "\n",
      "Fold: 8  Epoch: 115  Training loss = 1.4949  Validation loss = 5.6279  \n",
      "\n",
      "Fold: 8  Epoch: 116  Training loss = 1.4945  Validation loss = 5.6272  \n",
      "\n",
      "Fold: 8  Epoch: 117  Training loss = 1.4940  Validation loss = 5.6253  \n",
      "\n",
      "Fold: 8  Epoch: 118  Training loss = 1.4935  Validation loss = 5.6243  \n",
      "\n",
      "Fold: 8  Epoch: 119  Training loss = 1.4931  Validation loss = 5.6230  \n",
      "\n",
      "Fold: 8  Epoch: 120  Training loss = 1.4925  Validation loss = 5.6220  \n",
      "\n",
      "Fold: 8  Epoch: 121  Training loss = 1.4922  Validation loss = 5.6218  \n",
      "\n",
      "Fold: 8  Epoch: 122  Training loss = 1.4917  Validation loss = 5.6206  \n",
      "\n",
      "Fold: 8  Epoch: 123  Training loss = 1.4913  Validation loss = 5.6197  \n",
      "\n",
      "Fold: 8  Epoch: 124  Training loss = 1.4909  Validation loss = 5.6199  \n",
      "\n",
      "Fold: 8  Epoch: 125  Training loss = 1.4905  Validation loss = 5.6195  \n",
      "\n",
      "Fold: 8  Epoch: 126  Training loss = 1.4900  Validation loss = 5.6183  \n",
      "\n",
      "Fold: 8  Epoch: 127  Training loss = 1.4896  Validation loss = 5.6164  \n",
      "\n",
      "Fold: 8  Epoch: 128  Training loss = 1.4892  Validation loss = 5.6163  \n",
      "\n",
      "Fold: 8  Epoch: 129  Training loss = 1.4887  Validation loss = 5.6151  \n",
      "\n",
      "Fold: 8  Epoch: 130  Training loss = 1.4885  Validation loss = 5.6146  \n",
      "\n",
      "Fold: 8  Epoch: 131  Training loss = 1.4881  Validation loss = 5.6130  \n",
      "\n",
      "Fold: 8  Epoch: 132  Training loss = 1.4877  Validation loss = 5.6114  \n",
      "\n",
      "Fold: 8  Epoch: 133  Training loss = 1.4873  Validation loss = 5.6109  \n",
      "\n",
      "Fold: 8  Epoch: 134  Training loss = 1.4868  Validation loss = 5.6100  \n",
      "\n",
      "Fold: 8  Epoch: 135  Training loss = 1.4865  Validation loss = 5.6090  \n",
      "\n",
      "Fold: 8  Epoch: 136  Training loss = 1.4860  Validation loss = 5.6075  \n",
      "\n",
      "Fold: 8  Epoch: 137  Training loss = 1.4855  Validation loss = 5.6062  \n",
      "\n",
      "Fold: 8  Epoch: 138  Training loss = 1.4850  Validation loss = 5.6055  \n",
      "\n",
      "Fold: 8  Epoch: 139  Training loss = 1.4845  Validation loss = 5.6051  \n",
      "\n",
      "Fold: 8  Epoch: 140  Training loss = 1.4840  Validation loss = 5.6047  \n",
      "\n",
      "Fold: 8  Epoch: 141  Training loss = 1.4837  Validation loss = 5.6054  \n",
      "\n",
      "Fold: 8  Epoch: 142  Training loss = 1.4833  Validation loss = 5.6051  \n",
      "\n",
      "Fold: 8  Epoch: 143  Training loss = 1.4829  Validation loss = 5.6043  \n",
      "\n",
      "Fold: 8  Epoch: 144  Training loss = 1.4825  Validation loss = 5.6027  \n",
      "\n",
      "Fold: 8  Epoch: 145  Training loss = 1.4819  Validation loss = 5.6008  \n",
      "\n",
      "Fold: 8  Epoch: 146  Training loss = 1.4815  Validation loss = 5.5996  \n",
      "\n",
      "Fold: 8  Epoch: 147  Training loss = 1.4810  Validation loss = 5.5989  \n",
      "\n",
      "Fold: 8  Epoch: 148  Training loss = 1.4807  Validation loss = 5.5986  \n",
      "\n",
      "Fold: 8  Epoch: 149  Training loss = 1.4803  Validation loss = 5.5994  \n",
      "\n",
      "Fold: 8  Epoch: 150  Training loss = 1.4796  Validation loss = 5.5986  \n",
      "\n",
      "Fold: 8  Epoch: 151  Training loss = 1.4793  Validation loss = 5.5967  \n",
      "\n",
      "Fold: 8  Epoch: 152  Training loss = 1.4789  Validation loss = 5.5971  \n",
      "\n",
      "Fold: 8  Epoch: 153  Training loss = 1.4784  Validation loss = 5.5959  \n",
      "\n",
      "Fold: 8  Epoch: 154  Training loss = 1.4781  Validation loss = 5.5942  \n",
      "\n",
      "Fold: 8  Epoch: 155  Training loss = 1.4776  Validation loss = 5.5933  \n",
      "\n",
      "Fold: 8  Epoch: 156  Training loss = 1.4773  Validation loss = 5.5923  \n",
      "\n",
      "Fold: 8  Epoch: 157  Training loss = 1.4769  Validation loss = 5.5910  \n",
      "\n",
      "Fold: 8  Epoch: 158  Training loss = 1.4766  Validation loss = 5.5898  \n",
      "\n",
      "Fold: 8  Epoch: 159  Training loss = 1.4759  Validation loss = 5.5877  \n",
      "\n",
      "Fold: 8  Epoch: 160  Training loss = 1.4756  Validation loss = 5.5878  \n",
      "\n",
      "Fold: 8  Epoch: 161  Training loss = 1.4753  Validation loss = 5.5876  \n",
      "\n",
      "Fold: 8  Epoch: 162  Training loss = 1.4750  Validation loss = 5.5855  \n",
      "\n",
      "Fold: 8  Epoch: 163  Training loss = 1.4746  Validation loss = 5.5858  \n",
      "\n",
      "Fold: 8  Epoch: 164  Training loss = 1.4743  Validation loss = 5.5859  \n",
      "\n",
      "Fold: 8  Epoch: 165  Training loss = 1.4739  Validation loss = 5.5839  \n",
      "\n",
      "Fold: 8  Epoch: 166  Training loss = 1.4735  Validation loss = 5.5830  \n",
      "\n",
      "Fold: 8  Epoch: 167  Training loss = 1.4733  Validation loss = 5.5830  \n",
      "\n",
      "Fold: 8  Epoch: 168  Training loss = 1.4728  Validation loss = 5.5829  \n",
      "\n",
      "Fold: 8  Epoch: 169  Training loss = 1.4725  Validation loss = 5.5820  \n",
      "\n",
      "Fold: 8  Epoch: 170  Training loss = 1.4723  Validation loss = 5.5821  \n",
      "\n",
      "Fold: 8  Epoch: 171  Training loss = 1.4719  Validation loss = 5.5812  \n",
      "\n",
      "Fold: 8  Epoch: 172  Training loss = 1.4715  Validation loss = 5.5802  \n",
      "\n",
      "Fold: 8  Epoch: 173  Training loss = 1.4712  Validation loss = 5.5805  \n",
      "\n",
      "Fold: 8  Epoch: 174  Training loss = 1.4708  Validation loss = 5.5797  \n",
      "\n",
      "Fold: 8  Epoch: 175  Training loss = 1.4704  Validation loss = 5.5787  \n",
      "\n",
      "Fold: 8  Epoch: 176  Training loss = 1.4702  Validation loss = 5.5788  \n",
      "\n",
      "Fold: 8  Epoch: 177  Training loss = 1.4697  Validation loss = 5.5784  \n",
      "\n",
      "Fold: 8  Epoch: 178  Training loss = 1.4693  Validation loss = 5.5771  \n",
      "\n",
      "Fold: 8  Epoch: 179  Training loss = 1.4689  Validation loss = 5.5757  \n",
      "\n",
      "Fold: 8  Epoch: 180  Training loss = 1.4686  Validation loss = 5.5747  \n",
      "\n",
      "Fold: 8  Epoch: 181  Training loss = 1.4684  Validation loss = 5.5746  \n",
      "\n",
      "Fold: 8  Epoch: 182  Training loss = 1.4681  Validation loss = 5.5737  \n",
      "\n",
      "Fold: 8  Epoch: 183  Training loss = 1.4677  Validation loss = 5.5736  \n",
      "\n",
      "Fold: 8  Epoch: 184  Training loss = 1.4674  Validation loss = 5.5732  \n",
      "\n",
      "Fold: 8  Epoch: 185  Training loss = 1.4669  Validation loss = 5.5719  \n",
      "\n",
      "Fold: 8  Epoch: 186  Training loss = 1.4666  Validation loss = 5.5728  \n",
      "\n",
      "Fold: 8  Epoch: 187  Training loss = 1.4662  Validation loss = 5.5723  \n",
      "\n",
      "Fold: 8  Epoch: 188  Training loss = 1.4657  Validation loss = 5.5704  \n",
      "\n",
      "Fold: 8  Epoch: 189  Training loss = 1.4652  Validation loss = 5.5694  \n",
      "\n",
      "Fold: 8  Epoch: 190  Training loss = 1.4648  Validation loss = 5.5682  \n",
      "\n",
      "Fold: 8  Epoch: 191  Training loss = 1.4643  Validation loss = 5.5665  \n",
      "\n",
      "Fold: 8  Epoch: 192  Training loss = 1.4639  Validation loss = 5.5644  \n",
      "\n",
      "Fold: 8  Epoch: 193  Training loss = 1.4634  Validation loss = 5.5631  \n",
      "\n",
      "Fold: 8  Epoch: 194  Training loss = 1.4631  Validation loss = 5.5621  \n",
      "\n",
      "Fold: 8  Epoch: 195  Training loss = 1.4628  Validation loss = 5.5628  \n",
      "\n",
      "Fold: 8  Epoch: 196  Training loss = 1.4625  Validation loss = 5.5626  \n",
      "\n",
      "Fold: 8  Epoch: 197  Training loss = 1.4620  Validation loss = 5.5611  \n",
      "\n",
      "Fold: 8  Epoch: 198  Training loss = 1.4618  Validation loss = 5.5614  \n",
      "\n",
      "Fold: 8  Epoch: 199  Training loss = 1.4614  Validation loss = 5.5603  \n",
      "\n",
      "Fold: 8  Epoch: 200  Training loss = 1.4611  Validation loss = 5.5599  \n",
      "\n",
      "Fold: 8  Epoch: 201  Training loss = 1.4608  Validation loss = 5.5601  \n",
      "\n",
      "Fold: 8  Epoch: 202  Training loss = 1.4604  Validation loss = 5.5592  \n",
      "\n",
      "Fold: 8  Epoch: 203  Training loss = 1.4599  Validation loss = 5.5585  \n",
      "\n",
      "Fold: 8  Epoch: 204  Training loss = 1.4596  Validation loss = 5.5574  \n",
      "\n",
      "Fold: 8  Epoch: 205  Training loss = 1.4593  Validation loss = 5.5559  \n",
      "\n",
      "Fold: 8  Epoch: 206  Training loss = 1.4589  Validation loss = 5.5550  \n",
      "\n",
      "Fold: 8  Epoch: 207  Training loss = 1.4586  Validation loss = 5.5552  \n",
      "\n",
      "Fold: 8  Epoch: 208  Training loss = 1.4582  Validation loss = 5.5537  \n",
      "\n",
      "Fold: 8  Epoch: 209  Training loss = 1.4579  Validation loss = 5.5518  \n",
      "\n",
      "Fold: 8  Epoch: 210  Training loss = 1.4575  Validation loss = 5.5512  \n",
      "\n",
      "Fold: 8  Epoch: 211  Training loss = 1.4572  Validation loss = 5.5495  \n",
      "\n",
      "Fold: 8  Epoch: 212  Training loss = 1.4568  Validation loss = 5.5485  \n",
      "\n",
      "Fold: 8  Epoch: 213  Training loss = 1.4564  Validation loss = 5.5471  \n",
      "\n",
      "Fold: 8  Epoch: 214  Training loss = 1.4560  Validation loss = 5.5462  \n",
      "\n",
      "Fold: 8  Epoch: 215  Training loss = 1.4556  Validation loss = 5.5453  \n",
      "\n",
      "Fold: 8  Epoch: 216  Training loss = 1.4551  Validation loss = 5.5452  \n",
      "\n",
      "Fold: 8  Epoch: 217  Training loss = 1.4547  Validation loss = 5.5457  \n",
      "\n",
      "Fold: 8  Epoch: 218  Training loss = 1.4543  Validation loss = 5.5437  \n",
      "\n",
      "Fold: 8  Epoch: 219  Training loss = 1.4541  Validation loss = 5.5435  \n",
      "\n",
      "Fold: 8  Epoch: 220  Training loss = 1.4537  Validation loss = 5.5418  \n",
      "\n",
      "Fold: 8  Epoch: 221  Training loss = 1.4534  Validation loss = 5.5421  \n",
      "\n",
      "Fold: 8  Epoch: 222  Training loss = 1.4530  Validation loss = 5.5417  \n",
      "\n",
      "Fold: 8  Epoch: 223  Training loss = 1.4527  Validation loss = 5.5417  \n",
      "\n",
      "Fold: 8  Epoch: 224  Training loss = 1.4523  Validation loss = 5.5412  \n",
      "\n",
      "Fold: 8  Epoch: 225  Training loss = 1.4520  Validation loss = 5.5404  \n",
      "\n",
      "Fold: 8  Epoch: 226  Training loss = 1.4515  Validation loss = 5.5398  \n",
      "\n",
      "Fold: 8  Epoch: 227  Training loss = 1.4511  Validation loss = 5.5383  \n",
      "\n",
      "Fold: 8  Epoch: 228  Training loss = 1.4509  Validation loss = 5.5379  \n",
      "\n",
      "Fold: 8  Epoch: 229  Training loss = 1.4507  Validation loss = 5.5383  \n",
      "\n",
      "Fold: 8  Epoch: 230  Training loss = 1.4504  Validation loss = 5.5379  \n",
      "\n",
      "Fold: 8  Epoch: 231  Training loss = 1.4502  Validation loss = 5.5386  \n",
      "\n",
      "Fold: 8  Epoch: 232  Training loss = 1.4499  Validation loss = 5.5378  \n",
      "\n",
      "Fold: 8  Epoch: 233  Training loss = 1.4496  Validation loss = 5.5377  \n",
      "\n",
      "Fold: 8  Epoch: 234  Training loss = 1.4493  Validation loss = 5.5376  \n",
      "\n",
      "Fold: 8  Epoch: 235  Training loss = 1.4489  Validation loss = 5.5358  \n",
      "\n",
      "Fold: 8  Epoch: 236  Training loss = 1.4485  Validation loss = 5.5357  \n",
      "\n",
      "Fold: 8  Epoch: 237  Training loss = 1.4482  Validation loss = 5.5352  \n",
      "\n",
      "Fold: 8  Epoch: 238  Training loss = 1.4479  Validation loss = 5.5339  \n",
      "\n",
      "Fold: 8  Epoch: 239  Training loss = 1.4475  Validation loss = 5.5313  \n",
      "\n",
      "Fold: 8  Epoch: 240  Training loss = 1.4471  Validation loss = 5.5309  \n",
      "\n",
      "Fold: 8  Epoch: 241  Training loss = 1.4468  Validation loss = 5.5308  \n",
      "\n",
      "Fold: 8  Epoch: 242  Training loss = 1.4463  Validation loss = 5.5295  \n",
      "\n",
      "Fold: 8  Epoch: 243  Training loss = 1.4458  Validation loss = 5.5300  \n",
      "\n",
      "Fold: 8  Epoch: 244  Training loss = 1.4456  Validation loss = 5.5299  \n",
      "\n",
      "Fold: 8  Epoch: 245  Training loss = 1.4452  Validation loss = 5.5295  \n",
      "\n",
      "Fold: 8  Epoch: 246  Training loss = 1.4451  Validation loss = 5.5304  \n",
      "\n",
      "Fold: 8  Epoch: 247  Training loss = 1.4446  Validation loss = 5.5284  \n",
      "\n",
      "Fold: 8  Epoch: 248  Training loss = 1.4443  Validation loss = 5.5272  \n",
      "\n",
      "Fold: 8  Epoch: 249  Training loss = 1.4439  Validation loss = 5.5262  \n",
      "\n",
      "Fold: 8  Epoch: 250  Training loss = 1.4435  Validation loss = 5.5257  \n",
      "\n",
      "Fold: 8  Epoch: 251  Training loss = 1.4432  Validation loss = 5.5254  \n",
      "\n",
      "Fold: 8  Epoch: 252  Training loss = 1.4429  Validation loss = 5.5246  \n",
      "\n",
      "Fold: 8  Epoch: 253  Training loss = 1.4426  Validation loss = 5.5245  \n",
      "\n",
      "Fold: 8  Epoch: 254  Training loss = 1.4424  Validation loss = 5.5244  \n",
      "\n",
      "Fold: 8  Epoch: 255  Training loss = 1.4421  Validation loss = 5.5237  \n",
      "\n",
      "Fold: 8  Epoch: 256  Training loss = 1.4418  Validation loss = 5.5237  \n",
      "\n",
      "Fold: 8  Epoch: 257  Training loss = 1.4415  Validation loss = 5.5233  \n",
      "\n",
      "Fold: 8  Epoch: 258  Training loss = 1.4410  Validation loss = 5.5226  \n",
      "\n",
      "Fold: 8  Epoch: 259  Training loss = 1.4407  Validation loss = 5.5220  \n",
      "\n",
      "Fold: 8  Epoch: 260  Training loss = 1.4404  Validation loss = 5.5208  \n",
      "\n",
      "Fold: 8  Epoch: 261  Training loss = 1.4401  Validation loss = 5.5214  \n",
      "\n",
      "Fold: 8  Epoch: 262  Training loss = 1.4398  Validation loss = 5.5220  \n",
      "\n",
      "Fold: 8  Epoch: 263  Training loss = 1.4395  Validation loss = 5.5217  \n",
      "\n",
      "Fold: 8  Epoch: 264  Training loss = 1.4391  Validation loss = 5.5204  \n",
      "\n",
      "Fold: 8  Epoch: 265  Training loss = 1.4390  Validation loss = 5.5211  \n",
      "\n",
      "Fold: 8  Epoch: 266  Training loss = 1.4387  Validation loss = 5.5206  \n",
      "\n",
      "Fold: 8  Epoch: 267  Training loss = 1.4384  Validation loss = 5.5201  \n",
      "\n",
      "Fold: 8  Epoch: 268  Training loss = 1.4382  Validation loss = 5.5205  \n",
      "\n",
      "Fold: 8  Epoch: 269  Training loss = 1.4379  Validation loss = 5.5192  \n",
      "\n",
      "Fold: 8  Epoch: 270  Training loss = 1.4376  Validation loss = 5.5181  \n",
      "\n",
      "Fold: 8  Epoch: 271  Training loss = 1.4373  Validation loss = 5.5180  \n",
      "\n",
      "Fold: 8  Epoch: 272  Training loss = 1.4372  Validation loss = 5.5190  \n",
      "\n",
      "Fold: 8  Epoch: 273  Training loss = 1.4368  Validation loss = 5.5181  \n",
      "\n",
      "Fold: 8  Epoch: 274  Training loss = 1.4364  Validation loss = 5.5173  \n",
      "\n",
      "Fold: 8  Epoch: 275  Training loss = 1.4362  Validation loss = 5.5167  \n",
      "\n",
      "Fold: 8  Epoch: 276  Training loss = 1.4359  Validation loss = 5.5152  \n",
      "\n",
      "Fold: 8  Epoch: 277  Training loss = 1.4355  Validation loss = 5.5139  \n",
      "\n",
      "Fold: 8  Epoch: 278  Training loss = 1.4351  Validation loss = 5.5129  \n",
      "\n",
      "Fold: 8  Epoch: 279  Training loss = 1.4349  Validation loss = 5.5134  \n",
      "\n",
      "Fold: 8  Epoch: 280  Training loss = 1.4346  Validation loss = 5.5139  \n",
      "\n",
      "Fold: 8  Epoch: 281  Training loss = 1.4342  Validation loss = 5.5121  \n",
      "\n",
      "Fold: 8  Epoch: 282  Training loss = 1.4339  Validation loss = 5.5123  \n",
      "\n",
      "Fold: 8  Epoch: 283  Training loss = 1.4336  Validation loss = 5.5126  \n",
      "\n",
      "Fold: 8  Epoch: 284  Training loss = 1.4333  Validation loss = 5.5114  \n",
      "\n",
      "Fold: 8  Epoch: 285  Training loss = 1.4328  Validation loss = 5.5098  \n",
      "\n",
      "Fold: 8  Epoch: 286  Training loss = 1.4324  Validation loss = 5.5087  \n",
      "\n",
      "Fold: 8  Epoch: 287  Training loss = 1.4321  Validation loss = 5.5091  \n",
      "\n",
      "Fold: 8  Epoch: 288  Training loss = 1.4316  Validation loss = 5.5072  \n",
      "\n",
      "Fold: 8  Epoch: 289  Training loss = 1.4314  Validation loss = 5.5074  \n",
      "\n",
      "Fold: 8  Epoch: 290  Training loss = 1.4311  Validation loss = 5.5066  \n",
      "\n",
      "Fold: 8  Epoch: 291  Training loss = 1.4309  Validation loss = 5.5071  \n",
      "\n",
      "Fold: 8  Epoch: 292  Training loss = 1.4307  Validation loss = 5.5062  \n",
      "\n",
      "Fold: 8  Epoch: 293  Training loss = 1.4303  Validation loss = 5.5046  \n",
      "\n",
      "Fold: 8  Epoch: 294  Training loss = 1.4300  Validation loss = 5.5030  \n",
      "\n",
      "Fold: 8  Epoch: 295  Training loss = 1.4297  Validation loss = 5.5016  \n",
      "\n",
      "Fold: 8  Epoch: 296  Training loss = 1.4294  Validation loss = 5.5001  \n",
      "\n",
      "Fold: 8  Epoch: 297  Training loss = 1.4291  Validation loss = 5.4992  \n",
      "\n",
      "Fold: 8  Epoch: 298  Training loss = 1.4287  Validation loss = 5.4984  \n",
      "\n",
      "Fold: 8  Epoch: 299  Training loss = 1.4286  Validation loss = 5.4992  \n",
      "\n",
      "Fold: 8  Epoch: 300  Training loss = 1.4282  Validation loss = 5.4969  \n",
      "\n",
      "Fold: 8  Epoch: 301  Training loss = 1.4279  Validation loss = 5.4966  \n",
      "\n",
      "Fold: 8  Epoch: 302  Training loss = 1.4275  Validation loss = 5.4957  \n",
      "\n",
      "Fold: 8  Epoch: 303  Training loss = 1.4273  Validation loss = 5.4955  \n",
      "\n",
      "Fold: 8  Epoch: 304  Training loss = 1.4269  Validation loss = 5.4951  \n",
      "\n",
      "Fold: 8  Epoch: 305  Training loss = 1.4267  Validation loss = 5.4955  \n",
      "\n",
      "Fold: 8  Epoch: 306  Training loss = 1.4264  Validation loss = 5.4950  \n",
      "\n",
      "Fold: 8  Epoch: 307  Training loss = 1.4262  Validation loss = 5.4950  \n",
      "\n",
      "Fold: 8  Epoch: 308  Training loss = 1.4259  Validation loss = 5.4931  \n",
      "\n",
      "Fold: 8  Epoch: 309  Training loss = 1.4257  Validation loss = 5.4945  \n",
      "\n",
      "Fold: 8  Epoch: 310  Training loss = 1.4254  Validation loss = 5.4939  \n",
      "\n",
      "Fold: 8  Epoch: 311  Training loss = 1.4252  Validation loss = 5.4952  \n",
      "\n",
      "Fold: 8  Epoch: 312  Training loss = 1.4248  Validation loss = 5.4941  \n",
      "\n",
      "Fold: 8  Epoch: 313  Training loss = 1.4247  Validation loss = 5.4945  \n",
      "\n",
      "Fold: 8  Epoch: 314  Training loss = 1.4244  Validation loss = 5.4943  \n",
      "\n",
      "Fold: 8  Epoch: 315  Training loss = 1.4241  Validation loss = 5.4936  \n",
      "\n",
      "Fold: 8  Epoch: 316  Training loss = 1.4238  Validation loss = 5.4915  \n",
      "\n",
      "Fold: 8  Epoch: 317  Training loss = 1.4234  Validation loss = 5.4896  \n",
      "\n",
      "Fold: 8  Epoch: 318  Training loss = 1.4231  Validation loss = 5.4886  \n",
      "\n",
      "Fold: 8  Epoch: 319  Training loss = 1.4228  Validation loss = 5.4882  \n",
      "\n",
      "Fold: 8  Epoch: 320  Training loss = 1.4224  Validation loss = 5.4871  \n",
      "\n",
      "Fold: 8  Epoch: 321  Training loss = 1.4222  Validation loss = 5.4880  \n",
      "\n",
      "Fold: 8  Epoch: 322  Training loss = 1.4218  Validation loss = 5.4881  \n",
      "\n",
      "Fold: 8  Epoch: 323  Training loss = 1.4216  Validation loss = 5.4890  \n",
      "\n",
      "Fold: 8  Epoch: 324  Training loss = 1.4213  Validation loss = 5.4883  \n",
      "\n",
      "Fold: 8  Epoch: 325  Training loss = 1.4210  Validation loss = 5.4876  \n",
      "\n",
      "Fold: 8  Epoch: 326  Training loss = 1.4206  Validation loss = 5.4866  \n",
      "\n",
      "Fold: 8  Epoch: 327  Training loss = 1.4202  Validation loss = 5.4846  \n",
      "\n",
      "Fold: 8  Epoch: 328  Training loss = 1.4200  Validation loss = 5.4842  \n",
      "\n",
      "Fold: 8  Epoch: 329  Training loss = 1.4195  Validation loss = 5.4824  \n",
      "\n",
      "Fold: 8  Epoch: 330  Training loss = 1.4193  Validation loss = 5.4823  \n",
      "\n",
      "Fold: 8  Epoch: 331  Training loss = 1.4190  Validation loss = 5.4817  \n",
      "\n",
      "Fold: 8  Epoch: 332  Training loss = 1.4187  Validation loss = 5.4816  \n",
      "\n",
      "Fold: 8  Epoch: 333  Training loss = 1.4185  Validation loss = 5.4826  \n",
      "\n",
      "Fold: 8  Epoch: 334  Training loss = 1.4182  Validation loss = 5.4821  \n",
      "\n",
      "Fold: 8  Epoch: 335  Training loss = 1.4178  Validation loss = 5.4811  \n",
      "\n",
      "Fold: 8  Epoch: 336  Training loss = 1.4175  Validation loss = 5.4797  \n",
      "\n",
      "Fold: 8  Epoch: 337  Training loss = 1.4171  Validation loss = 5.4794  \n",
      "\n",
      "Fold: 8  Epoch: 338  Training loss = 1.4168  Validation loss = 5.4791  \n",
      "\n",
      "Fold: 8  Epoch: 339  Training loss = 1.4165  Validation loss = 5.4782  \n",
      "\n",
      "Fold: 8  Epoch: 340  Training loss = 1.4161  Validation loss = 5.4766  \n",
      "\n",
      "Fold: 8  Epoch: 341  Training loss = 1.4158  Validation loss = 5.4754  \n",
      "\n",
      "Fold: 8  Epoch: 342  Training loss = 1.4154  Validation loss = 5.4729  \n",
      "\n",
      "Fold: 8  Epoch: 343  Training loss = 1.4150  Validation loss = 5.4717  \n",
      "\n",
      "Fold: 8  Epoch: 344  Training loss = 1.4147  Validation loss = 5.4701  \n",
      "\n",
      "Fold: 8  Epoch: 345  Training loss = 1.4144  Validation loss = 5.4693  \n",
      "\n",
      "Fold: 8  Epoch: 346  Training loss = 1.4141  Validation loss = 5.4677  \n",
      "\n",
      "Fold: 8  Epoch: 347  Training loss = 1.4139  Validation loss = 5.4665  \n",
      "\n",
      "Fold: 8  Epoch: 348  Training loss = 1.4136  Validation loss = 5.4672  \n",
      "\n",
      "Fold: 8  Epoch: 349  Training loss = 1.4134  Validation loss = 5.4668  \n",
      "\n",
      "Fold: 8  Epoch: 350  Training loss = 1.4130  Validation loss = 5.4653  \n",
      "\n",
      "Fold: 8  Epoch: 351  Training loss = 1.4127  Validation loss = 5.4640  \n",
      "\n",
      "Fold: 8  Epoch: 352  Training loss = 1.4124  Validation loss = 5.4633  \n",
      "\n",
      "Fold: 8  Epoch: 353  Training loss = 1.4121  Validation loss = 5.4625  \n",
      "\n",
      "Fold: 8  Epoch: 354  Training loss = 1.4117  Validation loss = 5.4608  \n",
      "\n",
      "Fold: 8  Epoch: 355  Training loss = 1.4113  Validation loss = 5.4593  \n",
      "\n",
      "Fold: 8  Epoch: 356  Training loss = 1.4110  Validation loss = 5.4594  \n",
      "\n",
      "Fold: 8  Epoch: 357  Training loss = 1.4109  Validation loss = 5.4597  \n",
      "\n",
      "Fold: 8  Epoch: 358  Training loss = 1.4107  Validation loss = 5.4593  \n",
      "\n",
      "Fold: 8  Epoch: 359  Training loss = 1.4105  Validation loss = 5.4590  \n",
      "\n",
      "Fold: 8  Epoch: 360  Training loss = 1.4101  Validation loss = 5.4567  \n",
      "\n",
      "Fold: 8  Epoch: 361  Training loss = 1.4098  Validation loss = 5.4566  \n",
      "\n",
      "Fold: 8  Epoch: 362  Training loss = 1.4095  Validation loss = 5.4565  \n",
      "\n",
      "Fold: 8  Epoch: 363  Training loss = 1.4090  Validation loss = 5.4543  \n",
      "\n",
      "Fold: 8  Epoch: 364  Training loss = 1.4089  Validation loss = 5.4542  \n",
      "\n",
      "Fold: 8  Epoch: 365  Training loss = 1.4086  Validation loss = 5.4516  \n",
      "\n",
      "Fold: 8  Epoch: 366  Training loss = 1.4082  Validation loss = 5.4503  \n",
      "\n",
      "Fold: 8  Epoch: 367  Training loss = 1.4079  Validation loss = 5.4490  \n",
      "\n",
      "Fold: 8  Epoch: 368  Training loss = 1.4077  Validation loss = 5.4497  \n",
      "\n",
      "Fold: 8  Epoch: 369  Training loss = 1.4074  Validation loss = 5.4504  \n",
      "\n",
      "Fold: 8  Epoch: 370  Training loss = 1.4073  Validation loss = 5.4513  \n",
      "\n",
      "Fold: 8  Epoch: 371  Training loss = 1.4069  Validation loss = 5.4506  \n",
      "\n",
      "Fold: 8  Epoch: 372  Training loss = 1.4069  Validation loss = 5.4509  \n",
      "\n",
      "Fold: 8  Epoch: 373  Training loss = 1.4066  Validation loss = 5.4501  \n",
      "\n",
      "Fold: 8  Epoch: 374  Training loss = 1.4062  Validation loss = 5.4488  \n",
      "\n",
      "Fold: 8  Epoch: 375  Training loss = 1.4060  Validation loss = 5.4498  \n",
      "\n",
      "Fold: 8  Epoch: 376  Training loss = 1.4057  Validation loss = 5.4496  \n",
      "\n",
      "Fold: 8  Epoch: 377  Training loss = 1.4055  Validation loss = 5.4490  \n",
      "\n",
      "Fold: 8  Epoch: 378  Training loss = 1.4051  Validation loss = 5.4472  \n",
      "\n",
      "Fold: 8  Epoch: 379  Training loss = 1.4047  Validation loss = 5.4474  \n",
      "\n",
      "Fold: 8  Epoch: 380  Training loss = 1.4045  Validation loss = 5.4466  \n",
      "\n",
      "Fold: 8  Epoch: 381  Training loss = 1.4042  Validation loss = 5.4454  \n",
      "\n",
      "Fold: 8  Epoch: 382  Training loss = 1.4040  Validation loss = 5.4456  \n",
      "\n",
      "Fold: 8  Epoch: 383  Training loss = 1.4036  Validation loss = 5.4437  \n",
      "\n",
      "Fold: 8  Epoch: 384  Training loss = 1.4033  Validation loss = 5.4437  \n",
      "\n",
      "Fold: 8  Epoch: 385  Training loss = 1.4031  Validation loss = 5.4425  \n",
      "\n",
      "Fold: 8  Epoch: 386  Training loss = 1.4027  Validation loss = 5.4408  \n",
      "\n",
      "Fold: 8  Epoch: 387  Training loss = 1.4025  Validation loss = 5.4404  \n",
      "\n",
      "Fold: 8  Epoch: 388  Training loss = 1.4023  Validation loss = 5.4405  \n",
      "\n",
      "Fold: 8  Epoch: 389  Training loss = 1.4021  Validation loss = 5.4398  \n",
      "\n",
      "Fold: 8  Epoch: 390  Training loss = 1.4018  Validation loss = 5.4387  \n",
      "\n",
      "Fold: 8  Epoch: 391  Training loss = 1.4016  Validation loss = 5.4383  \n",
      "\n",
      "Fold: 8  Epoch: 392  Training loss = 1.4013  Validation loss = 5.4365  \n",
      "\n",
      "Fold: 8  Epoch: 393  Training loss = 1.4011  Validation loss = 5.4375  \n",
      "\n",
      "Fold: 8  Epoch: 394  Training loss = 1.4008  Validation loss = 5.4373  \n",
      "\n",
      "Fold: 8  Epoch: 395  Training loss = 1.4005  Validation loss = 5.4373  \n",
      "\n",
      "Fold: 8  Epoch: 396  Training loss = 1.4003  Validation loss = 5.4384  \n",
      "\n",
      "Fold: 8  Epoch: 397  Training loss = 1.3999  Validation loss = 5.4365  \n",
      "\n",
      "Fold: 8  Epoch: 398  Training loss = 1.3997  Validation loss = 5.4355  \n",
      "\n",
      "Fold: 8  Epoch: 399  Training loss = 1.3993  Validation loss = 5.4350  \n",
      "\n",
      "Fold: 8  Epoch: 400  Training loss = 1.3992  Validation loss = 5.4364  \n",
      "\n",
      "Fold: 8  Epoch: 401  Training loss = 1.3990  Validation loss = 5.4348  \n",
      "\n",
      "Fold: 8  Epoch: 402  Training loss = 1.3988  Validation loss = 5.4359  \n",
      "\n",
      "Fold: 8  Epoch: 403  Training loss = 1.3985  Validation loss = 5.4346  \n",
      "\n",
      "Fold: 8  Epoch: 404  Training loss = 1.3982  Validation loss = 5.4329  \n",
      "\n",
      "Fold: 8  Epoch: 405  Training loss = 1.3978  Validation loss = 5.4327  \n",
      "\n",
      "Fold: 8  Epoch: 406  Training loss = 1.3976  Validation loss = 5.4314  \n",
      "\n",
      "Fold: 8  Epoch: 407  Training loss = 1.3974  Validation loss = 5.4305  \n",
      "\n",
      "Fold: 8  Epoch: 408  Training loss = 1.3971  Validation loss = 5.4295  \n",
      "\n",
      "Fold: 8  Epoch: 409  Training loss = 1.3968  Validation loss = 5.4295  \n",
      "\n",
      "Fold: 8  Epoch: 410  Training loss = 1.3965  Validation loss = 5.4288  \n",
      "\n",
      "Fold: 8  Epoch: 411  Training loss = 1.3963  Validation loss = 5.4291  \n",
      "\n",
      "Fold: 8  Epoch: 412  Training loss = 1.3960  Validation loss = 5.4272  \n",
      "\n",
      "Fold: 8  Epoch: 413  Training loss = 1.3956  Validation loss = 5.4262  \n",
      "\n",
      "Fold: 8  Epoch: 414  Training loss = 1.3953  Validation loss = 5.4261  \n",
      "\n",
      "Fold: 8  Epoch: 415  Training loss = 1.3950  Validation loss = 5.4245  \n",
      "\n",
      "Fold: 8  Epoch: 416  Training loss = 1.3947  Validation loss = 5.4238  \n",
      "\n",
      "Fold: 8  Epoch: 417  Training loss = 1.3945  Validation loss = 5.4235  \n",
      "\n",
      "Fold: 8  Epoch: 418  Training loss = 1.3943  Validation loss = 5.4212  \n",
      "\n",
      "Fold: 8  Epoch: 419  Training loss = 1.3940  Validation loss = 5.4212  \n",
      "\n",
      "Fold: 8  Epoch: 420  Training loss = 1.3937  Validation loss = 5.4210  \n",
      "\n",
      "Fold: 8  Epoch: 421  Training loss = 1.3934  Validation loss = 5.4215  \n",
      "\n",
      "Fold: 8  Epoch: 422  Training loss = 1.3933  Validation loss = 5.4212  \n",
      "\n",
      "Fold: 8  Epoch: 423  Training loss = 1.3929  Validation loss = 5.4208  \n",
      "\n",
      "Fold: 8  Epoch: 424  Training loss = 1.3925  Validation loss = 5.4198  \n",
      "\n",
      "Fold: 8  Epoch: 425  Training loss = 1.3923  Validation loss = 5.4196  \n",
      "\n",
      "Fold: 8  Epoch: 426  Training loss = 1.3921  Validation loss = 5.4188  \n",
      "\n",
      "Fold: 8  Epoch: 427  Training loss = 1.3919  Validation loss = 5.4184  \n",
      "\n",
      "Fold: 8  Epoch: 428  Training loss = 1.3917  Validation loss = 5.4173  \n",
      "\n",
      "Fold: 8  Epoch: 429  Training loss = 1.3915  Validation loss = 5.4172  \n",
      "\n",
      "Fold: 8  Epoch: 430  Training loss = 1.3911  Validation loss = 5.4158  \n",
      "\n",
      "Fold: 8  Epoch: 431  Training loss = 1.3909  Validation loss = 5.4165  \n",
      "\n",
      "Fold: 8  Epoch: 432  Training loss = 1.3906  Validation loss = 5.4151  \n",
      "\n",
      "Fold: 8  Epoch: 433  Training loss = 1.3903  Validation loss = 5.4148  \n",
      "\n",
      "Fold: 8  Epoch: 434  Training loss = 1.3901  Validation loss = 5.4152  \n",
      "\n",
      "Fold: 8  Epoch: 435  Training loss = 1.3899  Validation loss = 5.4159  \n",
      "\n",
      "Fold: 8  Epoch: 436  Training loss = 1.3896  Validation loss = 5.4162  \n",
      "\n",
      "Fold: 8  Epoch: 437  Training loss = 1.3894  Validation loss = 5.4167  \n",
      "\n",
      "Fold: 8  Epoch: 438  Training loss = 1.3893  Validation loss = 5.4169  \n",
      "\n",
      "Fold: 8  Epoch: 439  Training loss = 1.3890  Validation loss = 5.4163  \n",
      "\n",
      "Fold: 8  Epoch: 440  Training loss = 1.3888  Validation loss = 5.4161  \n",
      "\n",
      "Fold: 8  Epoch: 441  Training loss = 1.3884  Validation loss = 5.4165  \n",
      "\n",
      "Fold: 8  Epoch: 442  Training loss = 1.3882  Validation loss = 5.4151  \n",
      "\n",
      "Fold: 8  Epoch: 443  Training loss = 1.3880  Validation loss = 5.4155  \n",
      "\n",
      "Fold: 8  Epoch: 444  Training loss = 1.3877  Validation loss = 5.4138  \n",
      "\n",
      "Fold: 8  Epoch: 445  Training loss = 1.3873  Validation loss = 5.4117  \n",
      "\n",
      "Fold: 8  Epoch: 446  Training loss = 1.3869  Validation loss = 5.4097  \n",
      "\n",
      "Fold: 8  Epoch: 447  Training loss = 1.3868  Validation loss = 5.4099  \n",
      "\n",
      "Fold: 8  Epoch: 448  Training loss = 1.3866  Validation loss = 5.4085  \n",
      "\n",
      "Fold: 8  Epoch: 449  Training loss = 1.3864  Validation loss = 5.4074  \n",
      "\n",
      "Fold: 8  Epoch: 450  Training loss = 1.3861  Validation loss = 5.4053  \n",
      "\n",
      "Fold: 8  Epoch: 451  Training loss = 1.3860  Validation loss = 5.4056  \n",
      "\n",
      "Fold: 8  Epoch: 452  Training loss = 1.3859  Validation loss = 5.4070  \n",
      "\n",
      "Fold: 8  Epoch: 453  Training loss = 1.3855  Validation loss = 5.4061  \n",
      "\n",
      "Fold: 8  Epoch: 454  Training loss = 1.3853  Validation loss = 5.4060  \n",
      "\n",
      "Fold: 8  Epoch: 455  Training loss = 1.3850  Validation loss = 5.4043  \n",
      "\n",
      "Fold: 8  Epoch: 456  Training loss = 1.3848  Validation loss = 5.4034  \n",
      "\n",
      "Fold: 8  Epoch: 457  Training loss = 1.3845  Validation loss = 5.4030  \n",
      "\n",
      "Fold: 8  Epoch: 458  Training loss = 1.3842  Validation loss = 5.4031  \n",
      "\n",
      "Fold: 8  Epoch: 459  Training loss = 1.3839  Validation loss = 5.3991  \n",
      "\n",
      "Fold: 8  Epoch: 460  Training loss = 1.3836  Validation loss = 5.3985  \n",
      "\n",
      "Fold: 8  Epoch: 461  Training loss = 1.3833  Validation loss = 5.3994  \n",
      "\n",
      "Fold: 8  Epoch: 462  Training loss = 1.3829  Validation loss = 5.3971  \n",
      "\n",
      "Fold: 8  Epoch: 463  Training loss = 1.3827  Validation loss = 5.3992  \n",
      "\n",
      "Fold: 8  Epoch: 464  Training loss = 1.3823  Validation loss = 5.3963  \n",
      "\n",
      "Fold: 8  Epoch: 465  Training loss = 1.3820  Validation loss = 5.3960  \n",
      "\n",
      "Fold: 8  Epoch: 466  Training loss = 1.3818  Validation loss = 5.3961  \n",
      "\n",
      "Fold: 8  Epoch: 467  Training loss = 1.3814  Validation loss = 5.3953  \n",
      "\n",
      "Fold: 8  Epoch: 468  Training loss = 1.3812  Validation loss = 5.3958  \n",
      "\n",
      "Fold: 8  Epoch: 469  Training loss = 1.3810  Validation loss = 5.3965  \n",
      "\n",
      "Fold: 8  Epoch: 470  Training loss = 1.3808  Validation loss = 5.3973  \n",
      "\n",
      "Fold: 8  Epoch: 471  Training loss = 1.3806  Validation loss = 5.3969  \n",
      "\n",
      "Fold: 8  Epoch: 472  Training loss = 1.3803  Validation loss = 5.3946  \n",
      "\n",
      "Fold: 8  Epoch: 473  Training loss = 1.3802  Validation loss = 5.3935  \n",
      "\n",
      "Fold: 8  Epoch: 474  Training loss = 1.3799  Validation loss = 5.3931  \n",
      "\n",
      "Fold: 8  Epoch: 475  Training loss = 1.3797  Validation loss = 5.3938  \n",
      "\n",
      "Fold: 8  Epoch: 476  Training loss = 1.3795  Validation loss = 5.3944  \n",
      "\n",
      "Fold: 8  Epoch: 477  Training loss = 1.3793  Validation loss = 5.3955  \n",
      "\n",
      "Fold: 8  Epoch: 478  Training loss = 1.3790  Validation loss = 5.3942  \n",
      "\n",
      "Fold: 8  Epoch: 479  Training loss = 1.3788  Validation loss = 5.3936  \n",
      "\n",
      "Fold: 8  Epoch: 480  Training loss = 1.3785  Validation loss = 5.3929  \n",
      "\n",
      "Fold: 8  Epoch: 481  Training loss = 1.3783  Validation loss = 5.3922  \n",
      "\n",
      "Fold: 8  Epoch: 482  Training loss = 1.3779  Validation loss = 5.3884  \n",
      "\n",
      "Fold: 8  Epoch: 483  Training loss = 1.3776  Validation loss = 5.3887  \n",
      "\n",
      "Fold: 8  Epoch: 484  Training loss = 1.3774  Validation loss = 5.3890  \n",
      "\n",
      "Fold: 8  Epoch: 485  Training loss = 1.3772  Validation loss = 5.3872  \n",
      "\n",
      "Fold: 8  Epoch: 486  Training loss = 1.3770  Validation loss = 5.3871  \n",
      "\n",
      "Fold: 8  Epoch: 487  Training loss = 1.3767  Validation loss = 5.3854  \n",
      "\n",
      "Fold: 8  Epoch: 488  Training loss = 1.3766  Validation loss = 5.3850  \n",
      "\n",
      "Fold: 8  Epoch: 489  Training loss = 1.3763  Validation loss = 5.3838  \n",
      "\n",
      "Fold: 8  Epoch: 490  Training loss = 1.3762  Validation loss = 5.3840  \n",
      "\n",
      "Fold: 8  Epoch: 491  Training loss = 1.3760  Validation loss = 5.3859  \n",
      "\n",
      "Fold: 8  Epoch: 492  Training loss = 1.3756  Validation loss = 5.3854  \n",
      "\n",
      "Fold: 8  Epoch: 493  Training loss = 1.3755  Validation loss = 5.3866  \n",
      "\n",
      "Fold: 8  Epoch: 494  Training loss = 1.3752  Validation loss = 5.3865  \n",
      "\n",
      "Fold: 8  Epoch: 495  Training loss = 1.3750  Validation loss = 5.3869  \n",
      "\n",
      "Fold: 8  Epoch: 496  Training loss = 1.3748  Validation loss = 5.3859  \n",
      "\n",
      "Fold: 8  Epoch: 497  Training loss = 1.3745  Validation loss = 5.3860  \n",
      "\n",
      "Fold: 8  Epoch: 498  Training loss = 1.3744  Validation loss = 5.3860  \n",
      "\n",
      "Fold: 8  Epoch: 499  Training loss = 1.3740  Validation loss = 5.3839  \n",
      "\n",
      "Fold: 8  Epoch: 500  Training loss = 1.3737  Validation loss = 5.3840  \n",
      "\n",
      "Check model:  Fold: 8  Optimal epoch: 489  \n",
      "\n",
      "Fold: 9  Epoch: 1  Training loss = 1.9012  Validation loss = 8.5628  \n",
      "\n",
      "Fold: 9  Epoch: 2  Training loss = 1.9008  Validation loss = 8.5616  \n",
      "\n",
      "Fold: 9  Epoch: 3  Training loss = 1.9001  Validation loss = 8.5599  \n",
      "\n",
      "Fold: 9  Epoch: 4  Training loss = 1.8998  Validation loss = 8.5591  \n",
      "\n",
      "Fold: 9  Epoch: 5  Training loss = 1.8992  Validation loss = 8.5575  \n",
      "\n",
      "Fold: 9  Epoch: 6  Training loss = 1.8984  Validation loss = 8.5557  \n",
      "\n",
      "Fold: 9  Epoch: 7  Training loss = 1.8975  Validation loss = 8.5534  \n",
      "\n",
      "Fold: 9  Epoch: 8  Training loss = 1.8968  Validation loss = 8.5519  \n",
      "\n",
      "Fold: 9  Epoch: 9  Training loss = 1.8960  Validation loss = 8.5501  \n",
      "\n",
      "Fold: 9  Epoch: 10  Training loss = 1.8953  Validation loss = 8.5485  \n",
      "\n",
      "Fold: 9  Epoch: 11  Training loss = 1.8943  Validation loss = 8.5464  \n",
      "\n",
      "Fold: 9  Epoch: 12  Training loss = 1.8939  Validation loss = 8.5452  \n",
      "\n",
      "Fold: 9  Epoch: 13  Training loss = 1.8931  Validation loss = 8.5434  \n",
      "\n",
      "Fold: 9  Epoch: 14  Training loss = 1.8925  Validation loss = 8.5421  \n",
      "\n",
      "Fold: 9  Epoch: 15  Training loss = 1.8916  Validation loss = 8.5399  \n",
      "\n",
      "Fold: 9  Epoch: 16  Training loss = 1.8914  Validation loss = 8.5388  \n",
      "\n",
      "Fold: 9  Epoch: 17  Training loss = 1.8908  Validation loss = 8.5370  \n",
      "\n",
      "Fold: 9  Epoch: 18  Training loss = 1.8901  Validation loss = 8.5353  \n",
      "\n",
      "Fold: 9  Epoch: 19  Training loss = 1.8894  Validation loss = 8.5339  \n",
      "\n",
      "Fold: 9  Epoch: 20  Training loss = 1.8888  Validation loss = 8.5321  \n",
      "\n",
      "Fold: 9  Epoch: 21  Training loss = 1.8885  Validation loss = 8.5313  \n",
      "\n",
      "Fold: 9  Epoch: 22  Training loss = 1.8879  Validation loss = 8.5296  \n",
      "\n",
      "Fold: 9  Epoch: 23  Training loss = 1.8873  Validation loss = 8.5281  \n",
      "\n",
      "Fold: 9  Epoch: 24  Training loss = 1.8864  Validation loss = 8.5258  \n",
      "\n",
      "Fold: 9  Epoch: 25  Training loss = 1.8859  Validation loss = 8.5243  \n",
      "\n",
      "Fold: 9  Epoch: 26  Training loss = 1.8854  Validation loss = 8.5230  \n",
      "\n",
      "Fold: 9  Epoch: 27  Training loss = 1.8850  Validation loss = 8.5222  \n",
      "\n",
      "Fold: 9  Epoch: 28  Training loss = 1.8843  Validation loss = 8.5203  \n",
      "\n",
      "Fold: 9  Epoch: 29  Training loss = 1.8837  Validation loss = 8.5185  \n",
      "\n",
      "Fold: 9  Epoch: 30  Training loss = 1.8832  Validation loss = 8.5172  \n",
      "\n",
      "Fold: 9  Epoch: 31  Training loss = 1.8828  Validation loss = 8.5158  \n",
      "\n",
      "Fold: 9  Epoch: 32  Training loss = 1.8823  Validation loss = 8.5143  \n",
      "\n",
      "Fold: 9  Epoch: 33  Training loss = 1.8819  Validation loss = 8.5132  \n",
      "\n",
      "Fold: 9  Epoch: 34  Training loss = 1.8814  Validation loss = 8.5118  \n",
      "\n",
      "Fold: 9  Epoch: 35  Training loss = 1.8812  Validation loss = 8.5110  \n",
      "\n",
      "Fold: 9  Epoch: 36  Training loss = 1.8805  Validation loss = 8.5094  \n",
      "\n",
      "Fold: 9  Epoch: 37  Training loss = 1.8799  Validation loss = 8.5082  \n",
      "\n",
      "Fold: 9  Epoch: 38  Training loss = 1.8794  Validation loss = 8.5070  \n",
      "\n",
      "Fold: 9  Epoch: 39  Training loss = 1.8789  Validation loss = 8.5052  \n",
      "\n",
      "Fold: 9  Epoch: 40  Training loss = 1.8785  Validation loss = 8.5041  \n",
      "\n",
      "Fold: 9  Epoch: 41  Training loss = 1.8779  Validation loss = 8.5027  \n",
      "\n",
      "Fold: 9  Epoch: 42  Training loss = 1.8772  Validation loss = 8.5010  \n",
      "\n",
      "Fold: 9  Epoch: 43  Training loss = 1.8767  Validation loss = 8.4995  \n",
      "\n",
      "Fold: 9  Epoch: 44  Training loss = 1.8764  Validation loss = 8.4984  \n",
      "\n",
      "Fold: 9  Epoch: 45  Training loss = 1.8760  Validation loss = 8.4971  \n",
      "\n",
      "Fold: 9  Epoch: 46  Training loss = 1.8753  Validation loss = 8.4952  \n",
      "\n",
      "Fold: 9  Epoch: 47  Training loss = 1.8748  Validation loss = 8.4938  \n",
      "\n",
      "Fold: 9  Epoch: 48  Training loss = 1.8747  Validation loss = 8.4931  \n",
      "\n",
      "Fold: 9  Epoch: 49  Training loss = 1.8741  Validation loss = 8.4917  \n",
      "\n",
      "Fold: 9  Epoch: 50  Training loss = 1.8738  Validation loss = 8.4906  \n",
      "\n",
      "Fold: 9  Epoch: 51  Training loss = 1.8733  Validation loss = 8.4891  \n",
      "\n",
      "Fold: 9  Epoch: 52  Training loss = 1.8729  Validation loss = 8.4878  \n",
      "\n",
      "Fold: 9  Epoch: 53  Training loss = 1.8726  Validation loss = 8.4869  \n",
      "\n",
      "Fold: 9  Epoch: 54  Training loss = 1.8722  Validation loss = 8.4859  \n",
      "\n",
      "Fold: 9  Epoch: 55  Training loss = 1.8717  Validation loss = 8.4847  \n",
      "\n",
      "Fold: 9  Epoch: 56  Training loss = 1.8714  Validation loss = 8.4839  \n",
      "\n",
      "Fold: 9  Epoch: 57  Training loss = 1.8710  Validation loss = 8.4827  \n",
      "\n",
      "Fold: 9  Epoch: 58  Training loss = 1.8705  Validation loss = 8.4809  \n",
      "\n",
      "Fold: 9  Epoch: 59  Training loss = 1.8701  Validation loss = 8.4796  \n",
      "\n",
      "Fold: 9  Epoch: 60  Training loss = 1.8695  Validation loss = 8.4778  \n",
      "\n",
      "Fold: 9  Epoch: 61  Training loss = 1.8690  Validation loss = 8.4764  \n",
      "\n",
      "Fold: 9  Epoch: 62  Training loss = 1.8687  Validation loss = 8.4757  \n",
      "\n",
      "Fold: 9  Epoch: 63  Training loss = 1.8682  Validation loss = 8.4744  \n",
      "\n",
      "Fold: 9  Epoch: 64  Training loss = 1.8678  Validation loss = 8.4736  \n",
      "\n",
      "Fold: 9  Epoch: 65  Training loss = 1.8674  Validation loss = 8.4724  \n",
      "\n",
      "Fold: 9  Epoch: 66  Training loss = 1.8668  Validation loss = 8.4706  \n",
      "\n",
      "Fold: 9  Epoch: 67  Training loss = 1.8663  Validation loss = 8.4692  \n",
      "\n",
      "Fold: 9  Epoch: 68  Training loss = 1.8657  Validation loss = 8.4672  \n",
      "\n",
      "Fold: 9  Epoch: 69  Training loss = 1.8651  Validation loss = 8.4653  \n",
      "\n",
      "Fold: 9  Epoch: 70  Training loss = 1.8648  Validation loss = 8.4644  \n",
      "\n",
      "Fold: 9  Epoch: 71  Training loss = 1.8642  Validation loss = 8.4624  \n",
      "\n",
      "Fold: 9  Epoch: 72  Training loss = 1.8636  Validation loss = 8.4605  \n",
      "\n",
      "Fold: 9  Epoch: 73  Training loss = 1.8634  Validation loss = 8.4597  \n",
      "\n",
      "Fold: 9  Epoch: 74  Training loss = 1.8630  Validation loss = 8.4586  \n",
      "\n",
      "Fold: 9  Epoch: 75  Training loss = 1.8623  Validation loss = 8.4563  \n",
      "\n",
      "Fold: 9  Epoch: 76  Training loss = 1.8619  Validation loss = 8.4549  \n",
      "\n",
      "Fold: 9  Epoch: 77  Training loss = 1.8615  Validation loss = 8.4538  \n",
      "\n",
      "Fold: 9  Epoch: 78  Training loss = 1.8612  Validation loss = 8.4528  \n",
      "\n",
      "Fold: 9  Epoch: 79  Training loss = 1.8608  Validation loss = 8.4517  \n",
      "\n",
      "Fold: 9  Epoch: 80  Training loss = 1.8601  Validation loss = 8.4497  \n",
      "\n",
      "Fold: 9  Epoch: 81  Training loss = 1.8595  Validation loss = 8.4481  \n",
      "\n",
      "Fold: 9  Epoch: 82  Training loss = 1.8591  Validation loss = 8.4466  \n",
      "\n",
      "Fold: 9  Epoch: 83  Training loss = 1.8587  Validation loss = 8.4455  \n",
      "\n",
      "Fold: 9  Epoch: 84  Training loss = 1.8584  Validation loss = 8.4444  \n",
      "\n",
      "Fold: 9  Epoch: 85  Training loss = 1.8580  Validation loss = 8.4433  \n",
      "\n",
      "Fold: 9  Epoch: 86  Training loss = 1.8575  Validation loss = 8.4416  \n",
      "\n",
      "Fold: 9  Epoch: 87  Training loss = 1.8571  Validation loss = 8.4405  \n",
      "\n",
      "Fold: 9  Epoch: 88  Training loss = 1.8566  Validation loss = 8.4387  \n",
      "\n",
      "Fold: 9  Epoch: 89  Training loss = 1.8563  Validation loss = 8.4379  \n",
      "\n",
      "Fold: 9  Epoch: 90  Training loss = 1.8559  Validation loss = 8.4365  \n",
      "\n",
      "Fold: 9  Epoch: 91  Training loss = 1.8556  Validation loss = 8.4355  \n",
      "\n",
      "Fold: 9  Epoch: 92  Training loss = 1.8551  Validation loss = 8.4339  \n",
      "\n",
      "Fold: 9  Epoch: 93  Training loss = 1.8547  Validation loss = 8.4326  \n",
      "\n",
      "Fold: 9  Epoch: 94  Training loss = 1.8543  Validation loss = 8.4312  \n",
      "\n",
      "Fold: 9  Epoch: 95  Training loss = 1.8539  Validation loss = 8.4300  \n",
      "\n",
      "Fold: 9  Epoch: 96  Training loss = 1.8537  Validation loss = 8.4294  \n",
      "\n",
      "Fold: 9  Epoch: 97  Training loss = 1.8533  Validation loss = 8.4280  \n",
      "\n",
      "Fold: 9  Epoch: 98  Training loss = 1.8527  Validation loss = 8.4260  \n",
      "\n",
      "Fold: 9  Epoch: 99  Training loss = 1.8522  Validation loss = 8.4246  \n",
      "\n",
      "Fold: 9  Epoch: 100  Training loss = 1.8519  Validation loss = 8.4239  \n",
      "\n",
      "Fold: 9  Epoch: 101  Training loss = 1.8514  Validation loss = 8.4223  \n",
      "\n",
      "Fold: 9  Epoch: 102  Training loss = 1.8513  Validation loss = 8.4220  \n",
      "\n",
      "Fold: 9  Epoch: 103  Training loss = 1.8510  Validation loss = 8.4210  \n",
      "\n",
      "Fold: 9  Epoch: 104  Training loss = 1.8507  Validation loss = 8.4204  \n",
      "\n",
      "Fold: 9  Epoch: 105  Training loss = 1.8503  Validation loss = 8.4193  \n",
      "\n",
      "Fold: 9  Epoch: 106  Training loss = 1.8499  Validation loss = 8.4181  \n",
      "\n",
      "Fold: 9  Epoch: 107  Training loss = 1.8496  Validation loss = 8.4172  \n",
      "\n",
      "Fold: 9  Epoch: 108  Training loss = 1.8492  Validation loss = 8.4163  \n",
      "\n",
      "Fold: 9  Epoch: 109  Training loss = 1.8489  Validation loss = 8.4153  \n",
      "\n",
      "Fold: 9  Epoch: 110  Training loss = 1.8486  Validation loss = 8.4146  \n",
      "\n",
      "Fold: 9  Epoch: 111  Training loss = 1.8481  Validation loss = 8.4131  \n",
      "\n",
      "Fold: 9  Epoch: 112  Training loss = 1.8479  Validation loss = 8.4125  \n",
      "\n",
      "Fold: 9  Epoch: 113  Training loss = 1.8475  Validation loss = 8.4113  \n",
      "\n",
      "Fold: 9  Epoch: 114  Training loss = 1.8472  Validation loss = 8.4107  \n",
      "\n",
      "Fold: 9  Epoch: 115  Training loss = 1.8468  Validation loss = 8.4091  \n",
      "\n",
      "Fold: 9  Epoch: 116  Training loss = 1.8464  Validation loss = 8.4079  \n",
      "\n",
      "Fold: 9  Epoch: 117  Training loss = 1.8462  Validation loss = 8.4073  \n",
      "\n",
      "Fold: 9  Epoch: 118  Training loss = 1.8457  Validation loss = 8.4056  \n",
      "\n",
      "Fold: 9  Epoch: 119  Training loss = 1.8454  Validation loss = 8.4048  \n",
      "\n",
      "Fold: 9  Epoch: 120  Training loss = 1.8448  Validation loss = 8.4030  \n",
      "\n",
      "Fold: 9  Epoch: 121  Training loss = 1.8444  Validation loss = 8.4016  \n",
      "\n",
      "Fold: 9  Epoch: 122  Training loss = 1.8441  Validation loss = 8.4008  \n",
      "\n",
      "Fold: 9  Epoch: 123  Training loss = 1.8438  Validation loss = 8.3995  \n",
      "\n",
      "Fold: 9  Epoch: 124  Training loss = 1.8435  Validation loss = 8.3986  \n",
      "\n",
      "Fold: 9  Epoch: 125  Training loss = 1.8431  Validation loss = 8.3971  \n",
      "\n",
      "Fold: 9  Epoch: 126  Training loss = 1.8427  Validation loss = 8.3962  \n",
      "\n",
      "Fold: 9  Epoch: 127  Training loss = 1.8421  Validation loss = 8.3943  \n",
      "\n",
      "Fold: 9  Epoch: 128  Training loss = 1.8418  Validation loss = 8.3934  \n",
      "\n",
      "Fold: 9  Epoch: 129  Training loss = 1.8412  Validation loss = 8.3914  \n",
      "\n",
      "Fold: 9  Epoch: 130  Training loss = 1.8407  Validation loss = 8.3898  \n",
      "\n",
      "Fold: 9  Epoch: 131  Training loss = 1.8403  Validation loss = 8.3884  \n",
      "\n",
      "Fold: 9  Epoch: 132  Training loss = 1.8401  Validation loss = 8.3880  \n",
      "\n",
      "Fold: 9  Epoch: 133  Training loss = 1.8397  Validation loss = 8.3869  \n",
      "\n",
      "Fold: 9  Epoch: 134  Training loss = 1.8393  Validation loss = 8.3859  \n",
      "\n",
      "Fold: 9  Epoch: 135  Training loss = 1.8387  Validation loss = 8.3838  \n",
      "\n",
      "Fold: 9  Epoch: 136  Training loss = 1.8382  Validation loss = 8.3824  \n",
      "\n",
      "Fold: 9  Epoch: 137  Training loss = 1.8377  Validation loss = 8.3807  \n",
      "\n",
      "Fold: 9  Epoch: 138  Training loss = 1.8374  Validation loss = 8.3800  \n",
      "\n",
      "Fold: 9  Epoch: 139  Training loss = 1.8371  Validation loss = 8.3792  \n",
      "\n",
      "Fold: 9  Epoch: 140  Training loss = 1.8368  Validation loss = 8.3784  \n",
      "\n",
      "Fold: 9  Epoch: 141  Training loss = 1.8364  Validation loss = 8.3770  \n",
      "\n",
      "Fold: 9  Epoch: 142  Training loss = 1.8361  Validation loss = 8.3760  \n",
      "\n",
      "Fold: 9  Epoch: 143  Training loss = 1.8357  Validation loss = 8.3749  \n",
      "\n",
      "Fold: 9  Epoch: 144  Training loss = 1.8354  Validation loss = 8.3739  \n",
      "\n",
      "Fold: 9  Epoch: 145  Training loss = 1.8350  Validation loss = 8.3723  \n",
      "\n",
      "Fold: 9  Epoch: 146  Training loss = 1.8346  Validation loss = 8.3712  \n",
      "\n",
      "Fold: 9  Epoch: 147  Training loss = 1.8341  Validation loss = 8.3697  \n",
      "\n",
      "Fold: 9  Epoch: 148  Training loss = 1.8338  Validation loss = 8.3688  \n",
      "\n",
      "Fold: 9  Epoch: 149  Training loss = 1.8336  Validation loss = 8.3681  \n",
      "\n",
      "Fold: 9  Epoch: 150  Training loss = 1.8331  Validation loss = 8.3668  \n",
      "\n",
      "Fold: 9  Epoch: 151  Training loss = 1.8326  Validation loss = 8.3651  \n",
      "\n",
      "Fold: 9  Epoch: 152  Training loss = 1.8322  Validation loss = 8.3638  \n",
      "\n",
      "Fold: 9  Epoch: 153  Training loss = 1.8314  Validation loss = 8.3611  \n",
      "\n",
      "Fold: 9  Epoch: 154  Training loss = 1.8310  Validation loss = 8.3594  \n",
      "\n",
      "Fold: 9  Epoch: 155  Training loss = 1.8305  Validation loss = 8.3579  \n",
      "\n",
      "Fold: 9  Epoch: 156  Training loss = 1.8299  Validation loss = 8.3559  \n",
      "\n",
      "Fold: 9  Epoch: 157  Training loss = 1.8297  Validation loss = 8.3552  \n",
      "\n",
      "Fold: 9  Epoch: 158  Training loss = 1.8295  Validation loss = 8.3544  \n",
      "\n",
      "Fold: 9  Epoch: 159  Training loss = 1.8290  Validation loss = 8.3529  \n",
      "\n",
      "Fold: 9  Epoch: 160  Training loss = 1.8285  Validation loss = 8.3512  \n",
      "\n",
      "Fold: 9  Epoch: 161  Training loss = 1.8280  Validation loss = 8.3496  \n",
      "\n",
      "Fold: 9  Epoch: 162  Training loss = 1.8275  Validation loss = 8.3479  \n",
      "\n",
      "Fold: 9  Epoch: 163  Training loss = 1.8271  Validation loss = 8.3464  \n",
      "\n",
      "Fold: 9  Epoch: 164  Training loss = 1.8267  Validation loss = 8.3453  \n",
      "\n",
      "Fold: 9  Epoch: 165  Training loss = 1.8263  Validation loss = 8.3439  \n",
      "\n",
      "Fold: 9  Epoch: 166  Training loss = 1.8259  Validation loss = 8.3427  \n",
      "\n",
      "Fold: 9  Epoch: 167  Training loss = 1.8254  Validation loss = 8.3413  \n",
      "\n",
      "Fold: 9  Epoch: 168  Training loss = 1.8250  Validation loss = 8.3399  \n",
      "\n",
      "Fold: 9  Epoch: 169  Training loss = 1.8245  Validation loss = 8.3383  \n",
      "\n",
      "Fold: 9  Epoch: 170  Training loss = 1.8242  Validation loss = 8.3373  \n",
      "\n",
      "Fold: 9  Epoch: 171  Training loss = 1.8238  Validation loss = 8.3361  \n",
      "\n",
      "Fold: 9  Epoch: 172  Training loss = 1.8236  Validation loss = 8.3354  \n",
      "\n",
      "Fold: 9  Epoch: 173  Training loss = 1.8231  Validation loss = 8.3340  \n",
      "\n",
      "Fold: 9  Epoch: 174  Training loss = 1.8227  Validation loss = 8.3329  \n",
      "\n",
      "Fold: 9  Epoch: 175  Training loss = 1.8222  Validation loss = 8.3312  \n",
      "\n",
      "Fold: 9  Epoch: 176  Training loss = 1.8218  Validation loss = 8.3297  \n",
      "\n",
      "Fold: 9  Epoch: 177  Training loss = 1.8215  Validation loss = 8.3287  \n",
      "\n",
      "Fold: 9  Epoch: 178  Training loss = 1.8210  Validation loss = 8.3267  \n",
      "\n",
      "Fold: 9  Epoch: 179  Training loss = 1.8206  Validation loss = 8.3252  \n",
      "\n",
      "Fold: 9  Epoch: 180  Training loss = 1.8200  Validation loss = 8.3233  \n",
      "\n",
      "Fold: 9  Epoch: 181  Training loss = 1.8197  Validation loss = 8.3226  \n",
      "\n",
      "Fold: 9  Epoch: 182  Training loss = 1.8193  Validation loss = 8.3215  \n",
      "\n",
      "Fold: 9  Epoch: 183  Training loss = 1.8189  Validation loss = 8.3202  \n",
      "\n",
      "Fold: 9  Epoch: 184  Training loss = 1.8185  Validation loss = 8.3190  \n",
      "\n",
      "Fold: 9  Epoch: 185  Training loss = 1.8183  Validation loss = 8.3186  \n",
      "\n",
      "Fold: 9  Epoch: 186  Training loss = 1.8178  Validation loss = 8.3168  \n",
      "\n",
      "Fold: 9  Epoch: 187  Training loss = 1.8174  Validation loss = 8.3154  \n",
      "\n",
      "Fold: 9  Epoch: 188  Training loss = 1.8170  Validation loss = 8.3137  \n",
      "\n",
      "Fold: 9  Epoch: 189  Training loss = 1.8168  Validation loss = 8.3134  \n",
      "\n",
      "Fold: 9  Epoch: 190  Training loss = 1.8165  Validation loss = 8.3122  \n",
      "\n",
      "Fold: 9  Epoch: 191  Training loss = 1.8161  Validation loss = 8.3105  \n",
      "\n",
      "Fold: 9  Epoch: 192  Training loss = 1.8159  Validation loss = 8.3104  \n",
      "\n",
      "Fold: 9  Epoch: 193  Training loss = 1.8157  Validation loss = 8.3099  \n",
      "\n",
      "Fold: 9  Epoch: 194  Training loss = 1.8154  Validation loss = 8.3087  \n",
      "\n",
      "Fold: 9  Epoch: 195  Training loss = 1.8149  Validation loss = 8.3071  \n",
      "\n",
      "Fold: 9  Epoch: 196  Training loss = 1.8145  Validation loss = 8.3060  \n",
      "\n",
      "Fold: 9  Epoch: 197  Training loss = 1.8142  Validation loss = 8.3052  \n",
      "\n",
      "Fold: 9  Epoch: 198  Training loss = 1.8139  Validation loss = 8.3041  \n",
      "\n",
      "Fold: 9  Epoch: 199  Training loss = 1.8134  Validation loss = 8.3024  \n",
      "\n",
      "Fold: 9  Epoch: 200  Training loss = 1.8130  Validation loss = 8.3009  \n",
      "\n",
      "Fold: 9  Epoch: 201  Training loss = 1.8126  Validation loss = 8.3000  \n",
      "\n",
      "Fold: 9  Epoch: 202  Training loss = 1.8123  Validation loss = 8.2991  \n",
      "\n",
      "Fold: 9  Epoch: 203  Training loss = 1.8118  Validation loss = 8.2974  \n",
      "\n",
      "Fold: 9  Epoch: 204  Training loss = 1.8114  Validation loss = 8.2959  \n",
      "\n",
      "Fold: 9  Epoch: 205  Training loss = 1.8109  Validation loss = 8.2943  \n",
      "\n",
      "Fold: 9  Epoch: 206  Training loss = 1.8106  Validation loss = 8.2933  \n",
      "\n",
      "Fold: 9  Epoch: 207  Training loss = 1.8103  Validation loss = 8.2922  \n",
      "\n",
      "Fold: 9  Epoch: 208  Training loss = 1.8101  Validation loss = 8.2919  \n",
      "\n",
      "Fold: 9  Epoch: 209  Training loss = 1.8098  Validation loss = 8.2907  \n",
      "\n",
      "Fold: 9  Epoch: 210  Training loss = 1.8096  Validation loss = 8.2904  \n",
      "\n",
      "Fold: 9  Epoch: 211  Training loss = 1.8093  Validation loss = 8.2898  \n",
      "\n",
      "Fold: 9  Epoch: 212  Training loss = 1.8089  Validation loss = 8.2889  \n",
      "\n",
      "Fold: 9  Epoch: 213  Training loss = 1.8085  Validation loss = 8.2872  \n",
      "\n",
      "Fold: 9  Epoch: 214  Training loss = 1.8080  Validation loss = 8.2855  \n",
      "\n",
      "Fold: 9  Epoch: 215  Training loss = 1.8079  Validation loss = 8.2852  \n",
      "\n",
      "Fold: 9  Epoch: 216  Training loss = 1.8076  Validation loss = 8.2841  \n",
      "\n",
      "Fold: 9  Epoch: 217  Training loss = 1.8073  Validation loss = 8.2833  \n",
      "\n",
      "Fold: 9  Epoch: 218  Training loss = 1.8070  Validation loss = 8.2823  \n",
      "\n",
      "Fold: 9  Epoch: 219  Training loss = 1.8067  Validation loss = 8.2814  \n",
      "\n",
      "Fold: 9  Epoch: 220  Training loss = 1.8064  Validation loss = 8.2808  \n",
      "\n",
      "Fold: 9  Epoch: 221  Training loss = 1.8062  Validation loss = 8.2802  \n",
      "\n",
      "Fold: 9  Epoch: 222  Training loss = 1.8057  Validation loss = 8.2786  \n",
      "\n",
      "Fold: 9  Epoch: 223  Training loss = 1.8054  Validation loss = 8.2772  \n",
      "\n",
      "Fold: 9  Epoch: 224  Training loss = 1.8049  Validation loss = 8.2755  \n",
      "\n",
      "Fold: 9  Epoch: 225  Training loss = 1.8045  Validation loss = 8.2745  \n",
      "\n",
      "Fold: 9  Epoch: 226  Training loss = 1.8042  Validation loss = 8.2734  \n",
      "\n",
      "Fold: 9  Epoch: 227  Training loss = 1.8039  Validation loss = 8.2724  \n",
      "\n",
      "Fold: 9  Epoch: 228  Training loss = 1.8038  Validation loss = 8.2720  \n",
      "\n",
      "Fold: 9  Epoch: 229  Training loss = 1.8034  Validation loss = 8.2708  \n",
      "\n",
      "Fold: 9  Epoch: 230  Training loss = 1.8032  Validation loss = 8.2705  \n",
      "\n",
      "Fold: 9  Epoch: 231  Training loss = 1.8030  Validation loss = 8.2701  \n",
      "\n",
      "Fold: 9  Epoch: 232  Training loss = 1.8026  Validation loss = 8.2686  \n",
      "\n",
      "Fold: 9  Epoch: 233  Training loss = 1.8023  Validation loss = 8.2677  \n",
      "\n",
      "Fold: 9  Epoch: 234  Training loss = 1.8021  Validation loss = 8.2672  \n",
      "\n",
      "Fold: 9  Epoch: 235  Training loss = 1.8017  Validation loss = 8.2659  \n",
      "\n",
      "Fold: 9  Epoch: 236  Training loss = 1.8013  Validation loss = 8.2648  \n",
      "\n",
      "Fold: 9  Epoch: 237  Training loss = 1.8008  Validation loss = 8.2628  \n",
      "\n",
      "Fold: 9  Epoch: 238  Training loss = 1.8004  Validation loss = 8.2613  \n",
      "\n",
      "Fold: 9  Epoch: 239  Training loss = 1.8001  Validation loss = 8.2606  \n",
      "\n",
      "Fold: 9  Epoch: 240  Training loss = 1.7998  Validation loss = 8.2595  \n",
      "\n",
      "Fold: 9  Epoch: 241  Training loss = 1.7996  Validation loss = 8.2594  \n",
      "\n",
      "Fold: 9  Epoch: 242  Training loss = 1.7991  Validation loss = 8.2579  \n",
      "\n",
      "Fold: 9  Epoch: 243  Training loss = 1.7989  Validation loss = 8.2574  \n",
      "\n",
      "Fold: 9  Epoch: 244  Training loss = 1.7985  Validation loss = 8.2558  \n",
      "\n",
      "Fold: 9  Epoch: 245  Training loss = 1.7982  Validation loss = 8.2550  \n",
      "\n",
      "Fold: 9  Epoch: 246  Training loss = 1.7979  Validation loss = 8.2541  \n",
      "\n",
      "Fold: 9  Epoch: 247  Training loss = 1.7976  Validation loss = 8.2534  \n",
      "\n",
      "Fold: 9  Epoch: 248  Training loss = 1.7973  Validation loss = 8.2525  \n",
      "\n",
      "Fold: 9  Epoch: 249  Training loss = 1.7969  Validation loss = 8.2513  \n",
      "\n",
      "Fold: 9  Epoch: 250  Training loss = 1.7966  Validation loss = 8.2503  \n",
      "\n",
      "Fold: 9  Epoch: 251  Training loss = 1.7963  Validation loss = 8.2489  \n",
      "\n",
      "Fold: 9  Epoch: 252  Training loss = 1.7960  Validation loss = 8.2479  \n",
      "\n",
      "Fold: 9  Epoch: 253  Training loss = 1.7957  Validation loss = 8.2471  \n",
      "\n",
      "Fold: 9  Epoch: 254  Training loss = 1.7953  Validation loss = 8.2460  \n",
      "\n",
      "Fold: 9  Epoch: 255  Training loss = 1.7948  Validation loss = 8.2443  \n",
      "\n",
      "Fold: 9  Epoch: 256  Training loss = 1.7946  Validation loss = 8.2435  \n",
      "\n",
      "Fold: 9  Epoch: 257  Training loss = 1.7942  Validation loss = 8.2426  \n",
      "\n",
      "Fold: 9  Epoch: 258  Training loss = 1.7939  Validation loss = 8.2413  \n",
      "\n",
      "Fold: 9  Epoch: 259  Training loss = 1.7936  Validation loss = 8.2400  \n",
      "\n",
      "Fold: 9  Epoch: 260  Training loss = 1.7932  Validation loss = 8.2388  \n",
      "\n",
      "Fold: 9  Epoch: 261  Training loss = 1.7930  Validation loss = 8.2380  \n",
      "\n",
      "Fold: 9  Epoch: 262  Training loss = 1.7926  Validation loss = 8.2367  \n",
      "\n",
      "Fold: 9  Epoch: 263  Training loss = 1.7924  Validation loss = 8.2360  \n",
      "\n",
      "Fold: 9  Epoch: 264  Training loss = 1.7920  Validation loss = 8.2347  \n",
      "\n",
      "Fold: 9  Epoch: 265  Training loss = 1.7917  Validation loss = 8.2343  \n",
      "\n",
      "Fold: 9  Epoch: 266  Training loss = 1.7914  Validation loss = 8.2336  \n",
      "\n",
      "Fold: 9  Epoch: 267  Training loss = 1.7912  Validation loss = 8.2327  \n",
      "\n",
      "Fold: 9  Epoch: 268  Training loss = 1.7908  Validation loss = 8.2318  \n",
      "\n",
      "Fold: 9  Epoch: 269  Training loss = 1.7905  Validation loss = 8.2308  \n",
      "\n",
      "Fold: 9  Epoch: 270  Training loss = 1.7900  Validation loss = 8.2294  \n",
      "\n",
      "Fold: 9  Epoch: 271  Training loss = 1.7898  Validation loss = 8.2291  \n",
      "\n",
      "Fold: 9  Epoch: 272  Training loss = 1.7894  Validation loss = 8.2276  \n",
      "\n",
      "Fold: 9  Epoch: 273  Training loss = 1.7891  Validation loss = 8.2265  \n",
      "\n",
      "Fold: 9  Epoch: 274  Training loss = 1.7888  Validation loss = 8.2254  \n",
      "\n",
      "Fold: 9  Epoch: 275  Training loss = 1.7883  Validation loss = 8.2237  \n",
      "\n",
      "Fold: 9  Epoch: 276  Training loss = 1.7877  Validation loss = 8.2212  \n",
      "\n",
      "Fold: 9  Epoch: 277  Training loss = 1.7874  Validation loss = 8.2203  \n",
      "\n",
      "Fold: 9  Epoch: 278  Training loss = 1.7872  Validation loss = 8.2199  \n",
      "\n",
      "Fold: 9  Epoch: 279  Training loss = 1.7871  Validation loss = 8.2200  \n",
      "\n",
      "Fold: 9  Epoch: 280  Training loss = 1.7868  Validation loss = 8.2189  \n",
      "\n",
      "Fold: 9  Epoch: 281  Training loss = 1.7863  Validation loss = 8.2171  \n",
      "\n",
      "Fold: 9  Epoch: 282  Training loss = 1.7859  Validation loss = 8.2155  \n",
      "\n",
      "Fold: 9  Epoch: 283  Training loss = 1.7855  Validation loss = 8.2144  \n",
      "\n",
      "Fold: 9  Epoch: 284  Training loss = 1.7853  Validation loss = 8.2136  \n",
      "\n",
      "Fold: 9  Epoch: 285  Training loss = 1.7851  Validation loss = 8.2132  \n",
      "\n",
      "Fold: 9  Epoch: 286  Training loss = 1.7848  Validation loss = 8.2122  \n",
      "\n",
      "Fold: 9  Epoch: 287  Training loss = 1.7845  Validation loss = 8.2117  \n",
      "\n",
      "Fold: 9  Epoch: 288  Training loss = 1.7842  Validation loss = 8.2108  \n",
      "\n",
      "Fold: 9  Epoch: 289  Training loss = 1.7838  Validation loss = 8.2095  \n",
      "\n",
      "Fold: 9  Epoch: 290  Training loss = 1.7835  Validation loss = 8.2082  \n",
      "\n",
      "Fold: 9  Epoch: 291  Training loss = 1.7831  Validation loss = 8.2071  \n",
      "\n",
      "Fold: 9  Epoch: 292  Training loss = 1.7829  Validation loss = 8.2067  \n",
      "\n",
      "Fold: 9  Epoch: 293  Training loss = 1.7826  Validation loss = 8.2060  \n",
      "\n",
      "Fold: 9  Epoch: 294  Training loss = 1.7822  Validation loss = 8.2045  \n",
      "\n",
      "Fold: 9  Epoch: 295  Training loss = 1.7817  Validation loss = 8.2027  \n",
      "\n",
      "Fold: 9  Epoch: 296  Training loss = 1.7813  Validation loss = 8.2012  \n",
      "\n",
      "Fold: 9  Epoch: 297  Training loss = 1.7810  Validation loss = 8.2003  \n",
      "\n",
      "Fold: 9  Epoch: 298  Training loss = 1.7807  Validation loss = 8.1990  \n",
      "\n",
      "Fold: 9  Epoch: 299  Training loss = 1.7805  Validation loss = 8.1985  \n",
      "\n",
      "Fold: 9  Epoch: 300  Training loss = 1.7800  Validation loss = 8.1966  \n",
      "\n",
      "Fold: 9  Epoch: 301  Training loss = 1.7796  Validation loss = 8.1951  \n",
      "\n",
      "Fold: 9  Epoch: 302  Training loss = 1.7791  Validation loss = 8.1933  \n",
      "\n",
      "Fold: 9  Epoch: 303  Training loss = 1.7788  Validation loss = 8.1920  \n",
      "\n",
      "Fold: 9  Epoch: 304  Training loss = 1.7784  Validation loss = 8.1910  \n",
      "\n",
      "Fold: 9  Epoch: 305  Training loss = 1.7780  Validation loss = 8.1896  \n",
      "\n",
      "Fold: 9  Epoch: 306  Training loss = 1.7778  Validation loss = 8.1886  \n",
      "\n",
      "Fold: 9  Epoch: 307  Training loss = 1.7774  Validation loss = 8.1872  \n",
      "\n",
      "Fold: 9  Epoch: 308  Training loss = 1.7770  Validation loss = 8.1857  \n",
      "\n",
      "Fold: 9  Epoch: 309  Training loss = 1.7768  Validation loss = 8.1853  \n",
      "\n",
      "Fold: 9  Epoch: 310  Training loss = 1.7765  Validation loss = 8.1844  \n",
      "\n",
      "Fold: 9  Epoch: 311  Training loss = 1.7762  Validation loss = 8.1836  \n",
      "\n",
      "Fold: 9  Epoch: 312  Training loss = 1.7760  Validation loss = 8.1826  \n",
      "\n",
      "Fold: 9  Epoch: 313  Training loss = 1.7757  Validation loss = 8.1817  \n",
      "\n",
      "Fold: 9  Epoch: 314  Training loss = 1.7754  Validation loss = 8.1807  \n",
      "\n",
      "Fold: 9  Epoch: 315  Training loss = 1.7750  Validation loss = 8.1789  \n",
      "\n",
      "Fold: 9  Epoch: 316  Training loss = 1.7747  Validation loss = 8.1774  \n",
      "\n",
      "Fold: 9  Epoch: 317  Training loss = 1.7743  Validation loss = 8.1766  \n",
      "\n",
      "Fold: 9  Epoch: 318  Training loss = 1.7740  Validation loss = 8.1753  \n",
      "\n",
      "Fold: 9  Epoch: 319  Training loss = 1.7734  Validation loss = 8.1736  \n",
      "\n",
      "Fold: 9  Epoch: 320  Training loss = 1.7730  Validation loss = 8.1722  \n",
      "\n",
      "Fold: 9  Epoch: 321  Training loss = 1.7727  Validation loss = 8.1710  \n",
      "\n",
      "Fold: 9  Epoch: 322  Training loss = 1.7722  Validation loss = 8.1694  \n",
      "\n",
      "Fold: 9  Epoch: 323  Training loss = 1.7717  Validation loss = 8.1680  \n",
      "\n",
      "Fold: 9  Epoch: 324  Training loss = 1.7715  Validation loss = 8.1673  \n",
      "\n",
      "Fold: 9  Epoch: 325  Training loss = 1.7713  Validation loss = 8.1670  \n",
      "\n",
      "Fold: 9  Epoch: 326  Training loss = 1.7711  Validation loss = 8.1662  \n",
      "\n",
      "Fold: 9  Epoch: 327  Training loss = 1.7709  Validation loss = 8.1659  \n",
      "\n",
      "Fold: 9  Epoch: 328  Training loss = 1.7707  Validation loss = 8.1655  \n",
      "\n",
      "Fold: 9  Epoch: 329  Training loss = 1.7703  Validation loss = 8.1643  \n",
      "\n",
      "Fold: 9  Epoch: 330  Training loss = 1.7700  Validation loss = 8.1627  \n",
      "\n",
      "Fold: 9  Epoch: 331  Training loss = 1.7697  Validation loss = 8.1620  \n",
      "\n",
      "Fold: 9  Epoch: 332  Training loss = 1.7694  Validation loss = 8.1610  \n",
      "\n",
      "Fold: 9  Epoch: 333  Training loss = 1.7690  Validation loss = 8.1596  \n",
      "\n",
      "Fold: 9  Epoch: 334  Training loss = 1.7685  Validation loss = 8.1580  \n",
      "\n",
      "Fold: 9  Epoch: 335  Training loss = 1.7684  Validation loss = 8.1575  \n",
      "\n",
      "Fold: 9  Epoch: 336  Training loss = 1.7681  Validation loss = 8.1565  \n",
      "\n",
      "Fold: 9  Epoch: 337  Training loss = 1.7678  Validation loss = 8.1554  \n",
      "\n",
      "Fold: 9  Epoch: 338  Training loss = 1.7675  Validation loss = 8.1543  \n",
      "\n",
      "Fold: 9  Epoch: 339  Training loss = 1.7670  Validation loss = 8.1525  \n",
      "\n",
      "Fold: 9  Epoch: 340  Training loss = 1.7666  Validation loss = 8.1509  \n",
      "\n",
      "Fold: 9  Epoch: 341  Training loss = 1.7664  Validation loss = 8.1508  \n",
      "\n",
      "Fold: 9  Epoch: 342  Training loss = 1.7659  Validation loss = 8.1487  \n",
      "\n",
      "Fold: 9  Epoch: 343  Training loss = 1.7658  Validation loss = 8.1486  \n",
      "\n",
      "Fold: 9  Epoch: 344  Training loss = 1.7656  Validation loss = 8.1478  \n",
      "\n",
      "Fold: 9  Epoch: 345  Training loss = 1.7653  Validation loss = 8.1470  \n",
      "\n",
      "Fold: 9  Epoch: 346  Training loss = 1.7648  Validation loss = 8.1458  \n",
      "\n",
      "Fold: 9  Epoch: 347  Training loss = 1.7645  Validation loss = 8.1449  \n",
      "\n",
      "Fold: 9  Epoch: 348  Training loss = 1.7643  Validation loss = 8.1444  \n",
      "\n",
      "Fold: 9  Epoch: 349  Training loss = 1.7641  Validation loss = 8.1440  \n",
      "\n",
      "Fold: 9  Epoch: 350  Training loss = 1.7639  Validation loss = 8.1437  \n",
      "\n",
      "Fold: 9  Epoch: 351  Training loss = 1.7634  Validation loss = 8.1419  \n",
      "\n",
      "Fold: 9  Epoch: 352  Training loss = 1.7630  Validation loss = 8.1404  \n",
      "\n",
      "Fold: 9  Epoch: 353  Training loss = 1.7628  Validation loss = 8.1399  \n",
      "\n",
      "Fold: 9  Epoch: 354  Training loss = 1.7625  Validation loss = 8.1387  \n",
      "\n",
      "Fold: 9  Epoch: 355  Training loss = 1.7621  Validation loss = 8.1371  \n",
      "\n",
      "Fold: 9  Epoch: 356  Training loss = 1.7617  Validation loss = 8.1358  \n",
      "\n",
      "Fold: 9  Epoch: 357  Training loss = 1.7615  Validation loss = 8.1353  \n",
      "\n",
      "Fold: 9  Epoch: 358  Training loss = 1.7612  Validation loss = 8.1345  \n",
      "\n",
      "Fold: 9  Epoch: 359  Training loss = 1.7611  Validation loss = 8.1342  \n",
      "\n",
      "Fold: 9  Epoch: 360  Training loss = 1.7607  Validation loss = 8.1324  \n",
      "\n",
      "Fold: 9  Epoch: 361  Training loss = 1.7606  Validation loss = 8.1324  \n",
      "\n",
      "Fold: 9  Epoch: 362  Training loss = 1.7603  Validation loss = 8.1317  \n",
      "\n",
      "Fold: 9  Epoch: 363  Training loss = 1.7600  Validation loss = 8.1306  \n",
      "\n",
      "Fold: 9  Epoch: 364  Training loss = 1.7598  Validation loss = 8.1301  \n",
      "\n",
      "Fold: 9  Epoch: 365  Training loss = 1.7596  Validation loss = 8.1296  \n",
      "\n",
      "Fold: 9  Epoch: 366  Training loss = 1.7594  Validation loss = 8.1288  \n",
      "\n",
      "Fold: 9  Epoch: 367  Training loss = 1.7590  Validation loss = 8.1277  \n",
      "\n",
      "Fold: 9  Epoch: 368  Training loss = 1.7587  Validation loss = 8.1267  \n",
      "\n",
      "Fold: 9  Epoch: 369  Training loss = 1.7582  Validation loss = 8.1250  \n",
      "\n",
      "Fold: 9  Epoch: 370  Training loss = 1.7578  Validation loss = 8.1236  \n",
      "\n",
      "Fold: 9  Epoch: 371  Training loss = 1.7574  Validation loss = 8.1221  \n",
      "\n",
      "Fold: 9  Epoch: 372  Training loss = 1.7568  Validation loss = 8.1201  \n",
      "\n",
      "Fold: 9  Epoch: 373  Training loss = 1.7565  Validation loss = 8.1190  \n",
      "\n",
      "Fold: 9  Epoch: 374  Training loss = 1.7560  Validation loss = 8.1171  \n",
      "\n",
      "Fold: 9  Epoch: 375  Training loss = 1.7557  Validation loss = 8.1160  \n",
      "\n",
      "Fold: 9  Epoch: 376  Training loss = 1.7555  Validation loss = 8.1160  \n",
      "\n",
      "Fold: 9  Epoch: 377  Training loss = 1.7553  Validation loss = 8.1155  \n",
      "\n",
      "Fold: 9  Epoch: 378  Training loss = 1.7552  Validation loss = 8.1152  \n",
      "\n",
      "Fold: 9  Epoch: 379  Training loss = 1.7550  Validation loss = 8.1145  \n",
      "\n",
      "Fold: 9  Epoch: 380  Training loss = 1.7546  Validation loss = 8.1129  \n",
      "\n",
      "Fold: 9  Epoch: 381  Training loss = 1.7543  Validation loss = 8.1119  \n",
      "\n",
      "Fold: 9  Epoch: 382  Training loss = 1.7541  Validation loss = 8.1110  \n",
      "\n",
      "Fold: 9  Epoch: 383  Training loss = 1.7537  Validation loss = 8.1097  \n",
      "\n",
      "Fold: 9  Epoch: 384  Training loss = 1.7536  Validation loss = 8.1089  \n",
      "\n",
      "Fold: 9  Epoch: 385  Training loss = 1.7532  Validation loss = 8.1076  \n",
      "\n",
      "Fold: 9  Epoch: 386  Training loss = 1.7530  Validation loss = 8.1073  \n",
      "\n",
      "Fold: 9  Epoch: 387  Training loss = 1.7528  Validation loss = 8.1067  \n",
      "\n",
      "Fold: 9  Epoch: 388  Training loss = 1.7524  Validation loss = 8.1059  \n",
      "\n",
      "Fold: 9  Epoch: 389  Training loss = 1.7523  Validation loss = 8.1058  \n",
      "\n",
      "Fold: 9  Epoch: 390  Training loss = 1.7520  Validation loss = 8.1048  \n",
      "\n",
      "Fold: 9  Epoch: 391  Training loss = 1.7518  Validation loss = 8.1044  \n",
      "\n",
      "Fold: 9  Epoch: 392  Training loss = 1.7515  Validation loss = 8.1032  \n",
      "\n",
      "Fold: 9  Epoch: 393  Training loss = 1.7512  Validation loss = 8.1025  \n",
      "\n",
      "Fold: 9  Epoch: 394  Training loss = 1.7509  Validation loss = 8.1015  \n",
      "\n",
      "Fold: 9  Epoch: 395  Training loss = 1.7505  Validation loss = 8.0996  \n",
      "\n",
      "Fold: 9  Epoch: 396  Training loss = 1.7503  Validation loss = 8.0991  \n",
      "\n",
      "Fold: 9  Epoch: 397  Training loss = 1.7500  Validation loss = 8.0985  \n",
      "\n",
      "Fold: 9  Epoch: 398  Training loss = 1.7497  Validation loss = 8.0974  \n",
      "\n",
      "Fold: 9  Epoch: 399  Training loss = 1.7495  Validation loss = 8.0969  \n",
      "\n",
      "Fold: 9  Epoch: 400  Training loss = 1.7492  Validation loss = 8.0960  \n",
      "\n",
      "Fold: 9  Epoch: 401  Training loss = 1.7490  Validation loss = 8.0953  \n",
      "\n",
      "Fold: 9  Epoch: 402  Training loss = 1.7487  Validation loss = 8.0947  \n",
      "\n",
      "Fold: 9  Epoch: 403  Training loss = 1.7484  Validation loss = 8.0937  \n",
      "\n",
      "Fold: 9  Epoch: 404  Training loss = 1.7481  Validation loss = 8.0925  \n",
      "\n",
      "Fold: 9  Epoch: 405  Training loss = 1.7478  Validation loss = 8.0916  \n",
      "\n",
      "Fold: 9  Epoch: 406  Training loss = 1.7476  Validation loss = 8.0907  \n",
      "\n",
      "Fold: 9  Epoch: 407  Training loss = 1.7472  Validation loss = 8.0890  \n",
      "\n",
      "Fold: 9  Epoch: 408  Training loss = 1.7470  Validation loss = 8.0886  \n",
      "\n",
      "Fold: 9  Epoch: 409  Training loss = 1.7466  Validation loss = 8.0872  \n",
      "\n",
      "Fold: 9  Epoch: 410  Training loss = 1.7465  Validation loss = 8.0867  \n",
      "\n",
      "Fold: 9  Epoch: 411  Training loss = 1.7461  Validation loss = 8.0852  \n",
      "\n",
      "Fold: 9  Epoch: 412  Training loss = 1.7459  Validation loss = 8.0847  \n",
      "\n",
      "Fold: 9  Epoch: 413  Training loss = 1.7457  Validation loss = 8.0844  \n",
      "\n",
      "Fold: 9  Epoch: 414  Training loss = 1.7453  Validation loss = 8.0830  \n",
      "\n",
      "Fold: 9  Epoch: 415  Training loss = 1.7452  Validation loss = 8.0825  \n",
      "\n",
      "Fold: 9  Epoch: 416  Training loss = 1.7449  Validation loss = 8.0817  \n",
      "\n",
      "Fold: 9  Epoch: 417  Training loss = 1.7447  Validation loss = 8.0812  \n",
      "\n",
      "Fold: 9  Epoch: 418  Training loss = 1.7444  Validation loss = 8.0804  \n",
      "\n",
      "Fold: 9  Epoch: 419  Training loss = 1.7441  Validation loss = 8.0791  \n",
      "\n",
      "Fold: 9  Epoch: 420  Training loss = 1.7437  Validation loss = 8.0779  \n",
      "\n",
      "Fold: 9  Epoch: 421  Training loss = 1.7434  Validation loss = 8.0768  \n",
      "\n",
      "Fold: 9  Epoch: 422  Training loss = 1.7431  Validation loss = 8.0759  \n",
      "\n",
      "Fold: 9  Epoch: 423  Training loss = 1.7426  Validation loss = 8.0744  \n",
      "\n",
      "Fold: 9  Epoch: 424  Training loss = 1.7423  Validation loss = 8.0736  \n",
      "\n",
      "Fold: 9  Epoch: 425  Training loss = 1.7421  Validation loss = 8.0729  \n",
      "\n",
      "Fold: 9  Epoch: 426  Training loss = 1.7418  Validation loss = 8.0717  \n",
      "\n",
      "Fold: 9  Epoch: 427  Training loss = 1.7415  Validation loss = 8.0704  \n",
      "\n",
      "Fold: 9  Epoch: 428  Training loss = 1.7411  Validation loss = 8.0689  \n",
      "\n",
      "Fold: 9  Epoch: 429  Training loss = 1.7408  Validation loss = 8.0677  \n",
      "\n",
      "Fold: 9  Epoch: 430  Training loss = 1.7407  Validation loss = 8.0674  \n",
      "\n",
      "Fold: 9  Epoch: 431  Training loss = 1.7405  Validation loss = 8.0669  \n",
      "\n",
      "Fold: 9  Epoch: 432  Training loss = 1.7399  Validation loss = 8.0646  \n",
      "\n",
      "Fold: 9  Epoch: 433  Training loss = 1.7398  Validation loss = 8.0644  \n",
      "\n",
      "Fold: 9  Epoch: 434  Training loss = 1.7395  Validation loss = 8.0630  \n",
      "\n",
      "Fold: 9  Epoch: 435  Training loss = 1.7394  Validation loss = 8.0628  \n",
      "\n",
      "Fold: 9  Epoch: 436  Training loss = 1.7389  Validation loss = 8.0614  \n",
      "\n",
      "Fold: 9  Epoch: 437  Training loss = 1.7387  Validation loss = 8.0606  \n",
      "\n",
      "Fold: 9  Epoch: 438  Training loss = 1.7384  Validation loss = 8.0598  \n",
      "\n",
      "Fold: 9  Epoch: 439  Training loss = 1.7381  Validation loss = 8.0587  \n",
      "\n",
      "Fold: 9  Epoch: 440  Training loss = 1.7378  Validation loss = 8.0577  \n",
      "\n",
      "Fold: 9  Epoch: 441  Training loss = 1.7376  Validation loss = 8.0575  \n",
      "\n",
      "Fold: 9  Epoch: 442  Training loss = 1.7374  Validation loss = 8.0566  \n",
      "\n",
      "Fold: 9  Epoch: 443  Training loss = 1.7370  Validation loss = 8.0554  \n",
      "\n",
      "Fold: 9  Epoch: 444  Training loss = 1.7368  Validation loss = 8.0546  \n",
      "\n",
      "Fold: 9  Epoch: 445  Training loss = 1.7366  Validation loss = 8.0542  \n",
      "\n",
      "Fold: 9  Epoch: 446  Training loss = 1.7365  Validation loss = 8.0541  \n",
      "\n",
      "Fold: 9  Epoch: 447  Training loss = 1.7362  Validation loss = 8.0534  \n",
      "\n",
      "Fold: 9  Epoch: 448  Training loss = 1.7358  Validation loss = 8.0522  \n",
      "\n",
      "Fold: 9  Epoch: 449  Training loss = 1.7356  Validation loss = 8.0514  \n",
      "\n",
      "Fold: 9  Epoch: 450  Training loss = 1.7354  Validation loss = 8.0506  \n",
      "\n",
      "Fold: 9  Epoch: 451  Training loss = 1.7352  Validation loss = 8.0502  \n",
      "\n",
      "Fold: 9  Epoch: 452  Training loss = 1.7350  Validation loss = 8.0497  \n",
      "\n",
      "Fold: 9  Epoch: 453  Training loss = 1.7349  Validation loss = 8.0500  \n",
      "\n",
      "Fold: 9  Epoch: 454  Training loss = 1.7346  Validation loss = 8.0491  \n",
      "\n",
      "Fold: 9  Epoch: 455  Training loss = 1.7342  Validation loss = 8.0478  \n",
      "\n",
      "Fold: 9  Epoch: 456  Training loss = 1.7340  Validation loss = 8.0469  \n",
      "\n",
      "Fold: 9  Epoch: 457  Training loss = 1.7336  Validation loss = 8.0458  \n",
      "\n",
      "Fold: 9  Epoch: 458  Training loss = 1.7336  Validation loss = 8.0458  \n",
      "\n",
      "Fold: 9  Epoch: 459  Training loss = 1.7333  Validation loss = 8.0449  \n",
      "\n",
      "Fold: 9  Epoch: 460  Training loss = 1.7331  Validation loss = 8.0447  \n",
      "\n",
      "Fold: 9  Epoch: 461  Training loss = 1.7329  Validation loss = 8.0440  \n",
      "\n",
      "Fold: 9  Epoch: 462  Training loss = 1.7326  Validation loss = 8.0428  \n",
      "\n",
      "Fold: 9  Epoch: 463  Training loss = 1.7323  Validation loss = 8.0418  \n",
      "\n",
      "Fold: 9  Epoch: 464  Training loss = 1.7319  Validation loss = 8.0406  \n",
      "\n",
      "Fold: 9  Epoch: 465  Training loss = 1.7319  Validation loss = 8.0405  \n",
      "\n",
      "Fold: 9  Epoch: 466  Training loss = 1.7315  Validation loss = 8.0392  \n",
      "\n",
      "Fold: 9  Epoch: 467  Training loss = 1.7313  Validation loss = 8.0389  \n",
      "\n",
      "Fold: 9  Epoch: 468  Training loss = 1.7311  Validation loss = 8.0384  \n",
      "\n",
      "Fold: 9  Epoch: 469  Training loss = 1.7310  Validation loss = 8.0380  \n",
      "\n",
      "Fold: 9  Epoch: 470  Training loss = 1.7309  Validation loss = 8.0377  \n",
      "\n",
      "Fold: 9  Epoch: 471  Training loss = 1.7306  Validation loss = 8.0365  \n",
      "\n",
      "Fold: 9  Epoch: 472  Training loss = 1.7302  Validation loss = 8.0351  \n",
      "\n",
      "Fold: 9  Epoch: 473  Training loss = 1.7300  Validation loss = 8.0343  \n",
      "\n",
      "Fold: 9  Epoch: 474  Training loss = 1.7297  Validation loss = 8.0334  \n",
      "\n",
      "Fold: 9  Epoch: 475  Training loss = 1.7295  Validation loss = 8.0327  \n",
      "\n",
      "Fold: 9  Epoch: 476  Training loss = 1.7292  Validation loss = 8.0318  \n",
      "\n",
      "Fold: 9  Epoch: 477  Training loss = 1.7289  Validation loss = 8.0307  \n",
      "\n",
      "Fold: 9  Epoch: 478  Training loss = 1.7286  Validation loss = 8.0296  \n",
      "\n",
      "Fold: 9  Epoch: 479  Training loss = 1.7284  Validation loss = 8.0287  \n",
      "\n",
      "Fold: 9  Epoch: 480  Training loss = 1.7281  Validation loss = 8.0278  \n",
      "\n",
      "Fold: 9  Epoch: 481  Training loss = 1.7279  Validation loss = 8.0271  \n",
      "\n",
      "Fold: 9  Epoch: 482  Training loss = 1.7275  Validation loss = 8.0256  \n",
      "\n",
      "Fold: 9  Epoch: 483  Training loss = 1.7270  Validation loss = 8.0240  \n",
      "\n",
      "Fold: 9  Epoch: 484  Training loss = 1.7266  Validation loss = 8.0225  \n",
      "\n",
      "Fold: 9  Epoch: 485  Training loss = 1.7262  Validation loss = 8.0211  \n",
      "\n",
      "Fold: 9  Epoch: 486  Training loss = 1.7259  Validation loss = 8.0203  \n",
      "\n",
      "Fold: 9  Epoch: 487  Training loss = 1.7256  Validation loss = 8.0194  \n",
      "\n",
      "Fold: 9  Epoch: 488  Training loss = 1.7251  Validation loss = 8.0177  \n",
      "\n",
      "Fold: 9  Epoch: 489  Training loss = 1.7247  Validation loss = 8.0163  \n",
      "\n",
      "Fold: 9  Epoch: 490  Training loss = 1.7244  Validation loss = 8.0149  \n",
      "\n",
      "Fold: 9  Epoch: 491  Training loss = 1.7242  Validation loss = 8.0148  \n",
      "\n",
      "Fold: 9  Epoch: 492  Training loss = 1.7241  Validation loss = 8.0147  \n",
      "\n",
      "Fold: 9  Epoch: 493  Training loss = 1.7238  Validation loss = 8.0138  \n",
      "\n",
      "Fold: 9  Epoch: 494  Training loss = 1.7236  Validation loss = 8.0128  \n",
      "\n",
      "Fold: 9  Epoch: 495  Training loss = 1.7235  Validation loss = 8.0128  \n",
      "\n",
      "Fold: 9  Epoch: 496  Training loss = 1.7233  Validation loss = 8.0120  \n",
      "\n",
      "Fold: 9  Epoch: 497  Training loss = 1.7229  Validation loss = 8.0106  \n",
      "\n",
      "Fold: 9  Epoch: 498  Training loss = 1.7227  Validation loss = 8.0099  \n",
      "\n",
      "Fold: 9  Epoch: 499  Training loss = 1.7223  Validation loss = 8.0082  \n",
      "\n",
      "Fold: 9  Epoch: 500  Training loss = 1.7219  Validation loss = 8.0069  \n",
      "\n",
      "Check model:  Fold: 9  Optimal epoch: 500  \n",
      "\n",
      "Fold: 10  Epoch: 1  Training loss = 2.5837  Validation loss = 3.5909  \n",
      "\n",
      "Fold: 10  Epoch: 2  Training loss = 2.5833  Validation loss = 3.5900  \n",
      "\n",
      "Fold: 10  Epoch: 3  Training loss = 2.5826  Validation loss = 3.5885  \n",
      "\n",
      "Fold: 10  Epoch: 4  Training loss = 2.5818  Validation loss = 3.5867  \n",
      "\n",
      "Fold: 10  Epoch: 5  Training loss = 2.5812  Validation loss = 3.5855  \n",
      "\n",
      "Fold: 10  Epoch: 6  Training loss = 2.5802  Validation loss = 3.5832  \n",
      "\n",
      "Fold: 10  Epoch: 7  Training loss = 2.5793  Validation loss = 3.5812  \n",
      "\n",
      "Fold: 10  Epoch: 8  Training loss = 2.5780  Validation loss = 3.5784  \n",
      "\n",
      "Fold: 10  Epoch: 9  Training loss = 2.5776  Validation loss = 3.5775  \n",
      "\n",
      "Fold: 10  Epoch: 10  Training loss = 2.5757  Validation loss = 3.5735  \n",
      "\n",
      "Fold: 10  Epoch: 11  Training loss = 2.5741  Validation loss = 3.5699  \n",
      "\n",
      "Fold: 10  Epoch: 12  Training loss = 2.5736  Validation loss = 3.5688  \n",
      "\n",
      "Fold: 10  Epoch: 13  Training loss = 2.5730  Validation loss = 3.5674  \n",
      "\n",
      "Fold: 10  Epoch: 14  Training loss = 2.5719  Validation loss = 3.5650  \n",
      "\n",
      "Fold: 10  Epoch: 15  Training loss = 2.5716  Validation loss = 3.5644  \n",
      "\n",
      "Fold: 10  Epoch: 16  Training loss = 2.5701  Validation loss = 3.5613  \n",
      "\n",
      "Fold: 10  Epoch: 17  Training loss = 2.5694  Validation loss = 3.5598  \n",
      "\n",
      "Fold: 10  Epoch: 18  Training loss = 2.5684  Validation loss = 3.5575  \n",
      "\n",
      "Fold: 10  Epoch: 19  Training loss = 2.5671  Validation loss = 3.5548  \n",
      "\n",
      "Fold: 10  Epoch: 20  Training loss = 2.5664  Validation loss = 3.5531  \n",
      "\n",
      "Fold: 10  Epoch: 21  Training loss = 2.5658  Validation loss = 3.5520  \n",
      "\n",
      "Fold: 10  Epoch: 22  Training loss = 2.5640  Validation loss = 3.5481  \n",
      "\n",
      "Fold: 10  Epoch: 23  Training loss = 2.5631  Validation loss = 3.5459  \n",
      "\n",
      "Fold: 10  Epoch: 24  Training loss = 2.5618  Validation loss = 3.5430  \n",
      "\n",
      "Fold: 10  Epoch: 25  Training loss = 2.5608  Validation loss = 3.5407  \n",
      "\n",
      "Fold: 10  Epoch: 26  Training loss = 2.5596  Validation loss = 3.5382  \n",
      "\n",
      "Fold: 10  Epoch: 27  Training loss = 2.5591  Validation loss = 3.5370  \n",
      "\n",
      "Fold: 10  Epoch: 28  Training loss = 2.5579  Validation loss = 3.5345  \n",
      "\n",
      "Fold: 10  Epoch: 29  Training loss = 2.5570  Validation loss = 3.5325  \n",
      "\n",
      "Fold: 10  Epoch: 30  Training loss = 2.5560  Validation loss = 3.5305  \n",
      "\n",
      "Fold: 10  Epoch: 31  Training loss = 2.5542  Validation loss = 3.5263  \n",
      "\n",
      "Fold: 10  Epoch: 32  Training loss = 2.5532  Validation loss = 3.5240  \n",
      "\n",
      "Fold: 10  Epoch: 33  Training loss = 2.5520  Validation loss = 3.5215  \n",
      "\n",
      "Fold: 10  Epoch: 34  Training loss = 2.5508  Validation loss = 3.5189  \n",
      "\n",
      "Fold: 10  Epoch: 35  Training loss = 2.5500  Validation loss = 3.5172  \n",
      "\n",
      "Fold: 10  Epoch: 36  Training loss = 2.5487  Validation loss = 3.5144  \n",
      "\n",
      "Fold: 10  Epoch: 37  Training loss = 2.5479  Validation loss = 3.5126  \n",
      "\n",
      "Fold: 10  Epoch: 38  Training loss = 2.5472  Validation loss = 3.5110  \n",
      "\n",
      "Fold: 10  Epoch: 39  Training loss = 2.5464  Validation loss = 3.5093  \n",
      "\n",
      "Fold: 10  Epoch: 40  Training loss = 2.5457  Validation loss = 3.5078  \n",
      "\n",
      "Fold: 10  Epoch: 41  Training loss = 2.5438  Validation loss = 3.5037  \n",
      "\n",
      "Fold: 10  Epoch: 42  Training loss = 2.5426  Validation loss = 3.5010  \n",
      "\n",
      "Fold: 10  Epoch: 43  Training loss = 2.5418  Validation loss = 3.4994  \n",
      "\n",
      "Fold: 10  Epoch: 44  Training loss = 2.5409  Validation loss = 3.4972  \n",
      "\n",
      "Fold: 10  Epoch: 45  Training loss = 2.5401  Validation loss = 3.4955  \n",
      "\n",
      "Fold: 10  Epoch: 46  Training loss = 2.5390  Validation loss = 3.4932  \n",
      "\n",
      "Fold: 10  Epoch: 47  Training loss = 2.5382  Validation loss = 3.4913  \n",
      "\n",
      "Fold: 10  Epoch: 48  Training loss = 2.5367  Validation loss = 3.4880  \n",
      "\n",
      "Fold: 10  Epoch: 49  Training loss = 2.5363  Validation loss = 3.4872  \n",
      "\n",
      "Fold: 10  Epoch: 50  Training loss = 2.5347  Validation loss = 3.4836  \n",
      "\n",
      "Fold: 10  Epoch: 51  Training loss = 2.5337  Validation loss = 3.4815  \n",
      "\n",
      "Fold: 10  Epoch: 52  Training loss = 2.5325  Validation loss = 3.4788  \n",
      "\n",
      "Fold: 10  Epoch: 53  Training loss = 2.5317  Validation loss = 3.4772  \n",
      "\n",
      "Fold: 10  Epoch: 54  Training loss = 2.5309  Validation loss = 3.4757  \n",
      "\n",
      "Fold: 10  Epoch: 55  Training loss = 2.5303  Validation loss = 3.4742  \n",
      "\n",
      "Fold: 10  Epoch: 56  Training loss = 2.5291  Validation loss = 3.4716  \n",
      "\n",
      "Fold: 10  Epoch: 57  Training loss = 2.5277  Validation loss = 3.4683  \n",
      "\n",
      "Fold: 10  Epoch: 58  Training loss = 2.5267  Validation loss = 3.4661  \n",
      "\n",
      "Fold: 10  Epoch: 59  Training loss = 2.5258  Validation loss = 3.4644  \n",
      "\n",
      "Fold: 10  Epoch: 60  Training loss = 2.5250  Validation loss = 3.4624  \n",
      "\n",
      "Fold: 10  Epoch: 61  Training loss = 2.5244  Validation loss = 3.4612  \n",
      "\n",
      "Fold: 10  Epoch: 62  Training loss = 2.5240  Validation loss = 3.4603  \n",
      "\n",
      "Fold: 10  Epoch: 63  Training loss = 2.5227  Validation loss = 3.4576  \n",
      "\n",
      "Fold: 10  Epoch: 64  Training loss = 2.5220  Validation loss = 3.4559  \n",
      "\n",
      "Fold: 10  Epoch: 65  Training loss = 2.5206  Validation loss = 3.4529  \n",
      "\n",
      "Fold: 10  Epoch: 66  Training loss = 2.5200  Validation loss = 3.4517  \n",
      "\n",
      "Fold: 10  Epoch: 67  Training loss = 2.5192  Validation loss = 3.4498  \n",
      "\n",
      "Fold: 10  Epoch: 68  Training loss = 2.5178  Validation loss = 3.4469  \n",
      "\n",
      "Fold: 10  Epoch: 69  Training loss = 2.5171  Validation loss = 3.4454  \n",
      "\n",
      "Fold: 10  Epoch: 70  Training loss = 2.5160  Validation loss = 3.4428  \n",
      "\n",
      "Fold: 10  Epoch: 71  Training loss = 2.5148  Validation loss = 3.4402  \n",
      "\n",
      "Fold: 10  Epoch: 72  Training loss = 2.5144  Validation loss = 3.4395  \n",
      "\n",
      "Fold: 10  Epoch: 73  Training loss = 2.5135  Validation loss = 3.4376  \n",
      "\n",
      "Fold: 10  Epoch: 74  Training loss = 2.5124  Validation loss = 3.4350  \n",
      "\n",
      "Fold: 10  Epoch: 75  Training loss = 2.5115  Validation loss = 3.4330  \n",
      "\n",
      "Fold: 10  Epoch: 76  Training loss = 2.5105  Validation loss = 3.4308  \n",
      "\n",
      "Fold: 10  Epoch: 77  Training loss = 2.5093  Validation loss = 3.4281  \n",
      "\n",
      "Fold: 10  Epoch: 78  Training loss = 2.5084  Validation loss = 3.4261  \n",
      "\n",
      "Fold: 10  Epoch: 79  Training loss = 2.5076  Validation loss = 3.4243  \n",
      "\n",
      "Fold: 10  Epoch: 80  Training loss = 2.5072  Validation loss = 3.4234  \n",
      "\n",
      "Fold: 10  Epoch: 81  Training loss = 2.5064  Validation loss = 3.4219  \n",
      "\n",
      "Fold: 10  Epoch: 82  Training loss = 2.5051  Validation loss = 3.4191  \n",
      "\n",
      "Fold: 10  Epoch: 83  Training loss = 2.5045  Validation loss = 3.4178  \n",
      "\n",
      "Fold: 10  Epoch: 84  Training loss = 2.5035  Validation loss = 3.4157  \n",
      "\n",
      "Fold: 10  Epoch: 85  Training loss = 2.5031  Validation loss = 3.4148  \n",
      "\n",
      "Fold: 10  Epoch: 86  Training loss = 2.5021  Validation loss = 3.4126  \n",
      "\n",
      "Fold: 10  Epoch: 87  Training loss = 2.5011  Validation loss = 3.4103  \n",
      "\n",
      "Fold: 10  Epoch: 88  Training loss = 2.5000  Validation loss = 3.4080  \n",
      "\n",
      "Fold: 10  Epoch: 89  Training loss = 2.4996  Validation loss = 3.4069  \n",
      "\n",
      "Fold: 10  Epoch: 90  Training loss = 2.4989  Validation loss = 3.4056  \n",
      "\n",
      "Fold: 10  Epoch: 91  Training loss = 2.4973  Validation loss = 3.4019  \n",
      "\n",
      "Fold: 10  Epoch: 92  Training loss = 2.4968  Validation loss = 3.4008  \n",
      "\n",
      "Fold: 10  Epoch: 93  Training loss = 2.4961  Validation loss = 3.3992  \n",
      "\n",
      "Fold: 10  Epoch: 94  Training loss = 2.4953  Validation loss = 3.3976  \n",
      "\n",
      "Fold: 10  Epoch: 95  Training loss = 2.4948  Validation loss = 3.3964  \n",
      "\n",
      "Fold: 10  Epoch: 96  Training loss = 2.4944  Validation loss = 3.3958  \n",
      "\n",
      "Fold: 10  Epoch: 97  Training loss = 2.4934  Validation loss = 3.3936  \n",
      "\n",
      "Fold: 10  Epoch: 98  Training loss = 2.4924  Validation loss = 3.3916  \n",
      "\n",
      "Fold: 10  Epoch: 99  Training loss = 2.4914  Validation loss = 3.3895  \n",
      "\n",
      "Fold: 10  Epoch: 100  Training loss = 2.4910  Validation loss = 3.3885  \n",
      "\n",
      "Fold: 10  Epoch: 101  Training loss = 2.4901  Validation loss = 3.3866  \n",
      "\n",
      "Fold: 10  Epoch: 102  Training loss = 2.4896  Validation loss = 3.3854  \n",
      "\n",
      "Fold: 10  Epoch: 103  Training loss = 2.4888  Validation loss = 3.3839  \n",
      "\n",
      "Fold: 10  Epoch: 104  Training loss = 2.4882  Validation loss = 3.3822  \n",
      "\n",
      "Fold: 10  Epoch: 105  Training loss = 2.4872  Validation loss = 3.3800  \n",
      "\n",
      "Fold: 10  Epoch: 106  Training loss = 2.4864  Validation loss = 3.3782  \n",
      "\n",
      "Fold: 10  Epoch: 107  Training loss = 2.4856  Validation loss = 3.3767  \n",
      "\n",
      "Fold: 10  Epoch: 108  Training loss = 2.4847  Validation loss = 3.3747  \n",
      "\n",
      "Fold: 10  Epoch: 109  Training loss = 2.4839  Validation loss = 3.3727  \n",
      "\n",
      "Fold: 10  Epoch: 110  Training loss = 2.4834  Validation loss = 3.3716  \n",
      "\n",
      "Fold: 10  Epoch: 111  Training loss = 2.4827  Validation loss = 3.3699  \n",
      "\n",
      "Fold: 10  Epoch: 112  Training loss = 2.4820  Validation loss = 3.3684  \n",
      "\n",
      "Fold: 10  Epoch: 113  Training loss = 2.4809  Validation loss = 3.3656  \n",
      "\n",
      "Fold: 10  Epoch: 114  Training loss = 2.4799  Validation loss = 3.3636  \n",
      "\n",
      "Fold: 10  Epoch: 115  Training loss = 2.4789  Validation loss = 3.3614  \n",
      "\n",
      "Fold: 10  Epoch: 116  Training loss = 2.4775  Validation loss = 3.3581  \n",
      "\n",
      "Fold: 10  Epoch: 117  Training loss = 2.4767  Validation loss = 3.3563  \n",
      "\n",
      "Fold: 10  Epoch: 118  Training loss = 2.4760  Validation loss = 3.3550  \n",
      "\n",
      "Fold: 10  Epoch: 119  Training loss = 2.4752  Validation loss = 3.3532  \n",
      "\n",
      "Fold: 10  Epoch: 120  Training loss = 2.4746  Validation loss = 3.3519  \n",
      "\n",
      "Fold: 10  Epoch: 121  Training loss = 2.4740  Validation loss = 3.3507  \n",
      "\n",
      "Fold: 10  Epoch: 122  Training loss = 2.4732  Validation loss = 3.3488  \n",
      "\n",
      "Fold: 10  Epoch: 123  Training loss = 2.4727  Validation loss = 3.3478  \n",
      "\n",
      "Fold: 10  Epoch: 124  Training loss = 2.4721  Validation loss = 3.3463  \n",
      "\n",
      "Fold: 10  Epoch: 125  Training loss = 2.4712  Validation loss = 3.3443  \n",
      "\n",
      "Fold: 10  Epoch: 126  Training loss = 2.4704  Validation loss = 3.3424  \n",
      "\n",
      "Fold: 10  Epoch: 127  Training loss = 2.4692  Validation loss = 3.3396  \n",
      "\n",
      "Fold: 10  Epoch: 128  Training loss = 2.4686  Validation loss = 3.3382  \n",
      "\n",
      "Fold: 10  Epoch: 129  Training loss = 2.4678  Validation loss = 3.3363  \n",
      "\n",
      "Fold: 10  Epoch: 130  Training loss = 2.4672  Validation loss = 3.3348  \n",
      "\n",
      "Fold: 10  Epoch: 131  Training loss = 2.4667  Validation loss = 3.3337  \n",
      "\n",
      "Fold: 10  Epoch: 132  Training loss = 2.4660  Validation loss = 3.3320  \n",
      "\n",
      "Fold: 10  Epoch: 133  Training loss = 2.4651  Validation loss = 3.3297  \n",
      "\n",
      "Fold: 10  Epoch: 134  Training loss = 2.4640  Validation loss = 3.3263  \n",
      "\n",
      "Fold: 10  Epoch: 135  Training loss = 2.4634  Validation loss = 3.3247  \n",
      "\n",
      "Fold: 10  Epoch: 136  Training loss = 2.4626  Validation loss = 3.3217  \n",
      "\n",
      "Fold: 10  Epoch: 137  Training loss = 2.4617  Validation loss = 3.3171  \n",
      "\n",
      "Fold: 10  Epoch: 138  Training loss = 2.4606  Validation loss = 3.3123  \n",
      "\n",
      "Fold: 10  Epoch: 139  Training loss = 2.4598  Validation loss = 3.3050  \n",
      "\n",
      "Fold: 10  Epoch: 140  Training loss = 2.4591  Validation loss = 3.2921  \n",
      "\n",
      "Fold: 10  Epoch: 141  Training loss = 2.4584  Validation loss = 3.2873  \n",
      "\n",
      "Fold: 10  Epoch: 142  Training loss = 2.4572  Validation loss = 3.2257  \n",
      "\n",
      "Fold: 10  Epoch: 143  Training loss = 2.4564  Validation loss = 3.2187  \n",
      "\n",
      "Fold: 10  Epoch: 144  Training loss = 2.4556  Validation loss = 3.2124  \n",
      "\n",
      "Fold: 10  Epoch: 145  Training loss = 2.4553  Validation loss = 3.2102  \n",
      "\n",
      "Fold: 10  Epoch: 146  Training loss = 2.4545  Validation loss = 3.2065  \n",
      "\n",
      "Fold: 10  Epoch: 147  Training loss = 2.4534  Validation loss = 3.2018  \n",
      "\n",
      "Fold: 10  Epoch: 148  Training loss = 2.4529  Validation loss = 3.2003  \n",
      "\n",
      "Fold: 10  Epoch: 149  Training loss = 2.4514  Validation loss = 3.1954  \n",
      "\n",
      "Fold: 10  Epoch: 150  Training loss = 2.4505  Validation loss = 3.1929  \n",
      "\n",
      "Fold: 10  Epoch: 151  Training loss = 2.4495  Validation loss = 3.1904  \n",
      "\n",
      "Fold: 10  Epoch: 152  Training loss = 2.4490  Validation loss = 3.1893  \n",
      "\n",
      "Fold: 10  Epoch: 153  Training loss = 2.4482  Validation loss = 3.1874  \n",
      "\n",
      "Fold: 10  Epoch: 154  Training loss = 2.4472  Validation loss = 3.1850  \n",
      "\n",
      "Fold: 10  Epoch: 155  Training loss = 2.4469  Validation loss = 3.1849  \n",
      "\n",
      "Fold: 10  Epoch: 156  Training loss = 2.4464  Validation loss = 3.1836  \n",
      "\n",
      "Fold: 10  Epoch: 157  Training loss = 2.4455  Validation loss = 3.1817  \n",
      "\n",
      "Fold: 10  Epoch: 158  Training loss = 2.4451  Validation loss = 3.1806  \n",
      "\n",
      "Fold: 10  Epoch: 159  Training loss = 2.4443  Validation loss = 3.1791  \n",
      "\n",
      "Fold: 10  Epoch: 160  Training loss = 2.4440  Validation loss = 3.1782  \n",
      "\n",
      "Fold: 10  Epoch: 161  Training loss = 2.4435  Validation loss = 3.1776  \n",
      "\n",
      "Fold: 10  Epoch: 162  Training loss = 2.4429  Validation loss = 3.1761  \n",
      "\n",
      "Fold: 10  Epoch: 163  Training loss = 2.4423  Validation loss = 3.1748  \n",
      "\n",
      "Fold: 10  Epoch: 164  Training loss = 2.4415  Validation loss = 3.1726  \n",
      "\n",
      "Fold: 10  Epoch: 165  Training loss = 2.4405  Validation loss = 3.1704  \n",
      "\n",
      "Fold: 10  Epoch: 166  Training loss = 2.4397  Validation loss = 3.1683  \n",
      "\n",
      "Fold: 10  Epoch: 167  Training loss = 2.4391  Validation loss = 3.1665  \n",
      "\n",
      "Fold: 10  Epoch: 168  Training loss = 2.4385  Validation loss = 3.1651  \n",
      "\n",
      "Fold: 10  Epoch: 169  Training loss = 2.4379  Validation loss = 3.1639  \n",
      "\n",
      "Fold: 10  Epoch: 170  Training loss = 2.4372  Validation loss = 3.1622  \n",
      "\n",
      "Fold: 10  Epoch: 171  Training loss = 2.4361  Validation loss = 3.1594  \n",
      "\n",
      "Fold: 10  Epoch: 172  Training loss = 2.4359  Validation loss = 3.1593  \n",
      "\n",
      "Fold: 10  Epoch: 173  Training loss = 2.4352  Validation loss = 3.1575  \n",
      "\n",
      "Fold: 10  Epoch: 174  Training loss = 2.4347  Validation loss = 3.1561  \n",
      "\n",
      "Fold: 10  Epoch: 175  Training loss = 2.4341  Validation loss = 3.1547  \n",
      "\n",
      "Fold: 10  Epoch: 176  Training loss = 2.4331  Validation loss = 3.1524  \n",
      "\n",
      "Fold: 10  Epoch: 177  Training loss = 2.4326  Validation loss = 3.1512  \n",
      "\n",
      "Fold: 10  Epoch: 178  Training loss = 2.4319  Validation loss = 3.1495  \n",
      "\n",
      "Fold: 10  Epoch: 179  Training loss = 2.4312  Validation loss = 3.1478  \n",
      "\n",
      "Fold: 10  Epoch: 180  Training loss = 2.4306  Validation loss = 3.1466  \n",
      "\n",
      "Fold: 10  Epoch: 181  Training loss = 2.4302  Validation loss = 3.1456  \n",
      "\n",
      "Fold: 10  Epoch: 182  Training loss = 2.4296  Validation loss = 3.1444  \n",
      "\n",
      "Fold: 10  Epoch: 183  Training loss = 2.4289  Validation loss = 3.1431  \n",
      "\n",
      "Fold: 10  Epoch: 184  Training loss = 2.4286  Validation loss = 3.1425  \n",
      "\n",
      "Fold: 10  Epoch: 185  Training loss = 2.4281  Validation loss = 3.1416  \n",
      "\n",
      "Fold: 10  Epoch: 186  Training loss = 2.4273  Validation loss = 3.1396  \n",
      "\n",
      "Fold: 10  Epoch: 187  Training loss = 2.4267  Validation loss = 3.1381  \n",
      "\n",
      "Fold: 10  Epoch: 188  Training loss = 2.4258  Validation loss = 3.1360  \n",
      "\n",
      "Fold: 10  Epoch: 189  Training loss = 2.4250  Validation loss = 3.1340  \n",
      "\n",
      "Fold: 10  Epoch: 190  Training loss = 2.4239  Validation loss = 3.1313  \n",
      "\n",
      "Fold: 10  Epoch: 191  Training loss = 2.4232  Validation loss = 3.1296  \n",
      "\n",
      "Fold: 10  Epoch: 192  Training loss = 2.4226  Validation loss = 3.1286  \n",
      "\n",
      "Fold: 10  Epoch: 193  Training loss = 2.4221  Validation loss = 3.1276  \n",
      "\n",
      "Fold: 10  Epoch: 194  Training loss = 2.4213  Validation loss = 3.1258  \n",
      "\n",
      "Fold: 10  Epoch: 195  Training loss = 2.4204  Validation loss = 3.1235  \n",
      "\n",
      "Fold: 10  Epoch: 196  Training loss = 2.4197  Validation loss = 3.1219  \n",
      "\n",
      "Fold: 10  Epoch: 197  Training loss = 2.4191  Validation loss = 3.1204  \n",
      "\n",
      "Fold: 10  Epoch: 198  Training loss = 2.4183  Validation loss = 3.1183  \n",
      "\n",
      "Fold: 10  Epoch: 199  Training loss = 2.4173  Validation loss = 3.1158  \n",
      "\n",
      "Fold: 10  Epoch: 200  Training loss = 2.4165  Validation loss = 3.1141  \n",
      "\n",
      "Fold: 10  Epoch: 201  Training loss = 2.4160  Validation loss = 3.1130  \n",
      "\n",
      "Fold: 10  Epoch: 202  Training loss = 2.4156  Validation loss = 3.1121  \n",
      "\n",
      "Fold: 10  Epoch: 203  Training loss = 2.4147  Validation loss = 3.1096  \n",
      "\n",
      "Fold: 10  Epoch: 204  Training loss = 2.4143  Validation loss = 3.1086  \n",
      "\n",
      "Fold: 10  Epoch: 205  Training loss = 2.4128  Validation loss = 3.1037  \n",
      "\n",
      "Fold: 10  Epoch: 206  Training loss = 2.4122  Validation loss = 3.1022  \n",
      "\n",
      "Fold: 10  Epoch: 207  Training loss = 2.4119  Validation loss = 3.1002  \n",
      "\n",
      "Fold: 10  Epoch: 208  Training loss = 2.4113  Validation loss = 3.0986  \n",
      "\n",
      "Fold: 10  Epoch: 209  Training loss = 2.4103  Validation loss = 3.0888  \n",
      "\n",
      "Fold: 10  Epoch: 210  Training loss = 2.4098  Validation loss = 3.0867  \n",
      "\n",
      "Fold: 10  Epoch: 211  Training loss = 2.4093  Validation loss = 3.0786  \n",
      "\n",
      "Fold: 10  Epoch: 212  Training loss = 2.4091  Validation loss = 3.0791  \n",
      "\n",
      "Fold: 10  Epoch: 213  Training loss = 2.4082  Validation loss = 3.0668  \n",
      "\n",
      "Fold: 10  Epoch: 214  Training loss = 2.4078  Validation loss = 3.0620  \n",
      "\n",
      "Fold: 10  Epoch: 215  Training loss = 2.4063  Validation loss = 3.0147  \n",
      "\n",
      "Fold: 10  Epoch: 216  Training loss = 2.4054  Validation loss = 3.0059  \n",
      "\n",
      "Fold: 10  Epoch: 217  Training loss = 2.4049  Validation loss = 3.0027  \n",
      "\n",
      "Fold: 10  Epoch: 218  Training loss = 2.4044  Validation loss = 2.9992  \n",
      "\n",
      "Fold: 10  Epoch: 219  Training loss = 2.4039  Validation loss = 2.9974  \n",
      "\n",
      "Fold: 10  Epoch: 220  Training loss = 2.4031  Validation loss = 2.9947  \n",
      "\n",
      "Fold: 10  Epoch: 221  Training loss = 2.4025  Validation loss = 2.9932  \n",
      "\n",
      "Fold: 10  Epoch: 222  Training loss = 2.4019  Validation loss = 2.9914  \n",
      "\n",
      "Fold: 10  Epoch: 223  Training loss = 2.4014  Validation loss = 2.9900  \n",
      "\n",
      "Fold: 10  Epoch: 224  Training loss = 2.4009  Validation loss = 2.9888  \n",
      "\n",
      "Fold: 10  Epoch: 225  Training loss = 2.4003  Validation loss = 2.9874  \n",
      "\n",
      "Fold: 10  Epoch: 226  Training loss = 2.3995  Validation loss = 2.9854  \n",
      "\n",
      "Fold: 10  Epoch: 227  Training loss = 2.3985  Validation loss = 2.9828  \n",
      "\n",
      "Fold: 10  Epoch: 228  Training loss = 2.3975  Validation loss = 2.9801  \n",
      "\n",
      "Fold: 10  Epoch: 229  Training loss = 2.3970  Validation loss = 2.9786  \n",
      "\n",
      "Fold: 10  Epoch: 230  Training loss = 2.3966  Validation loss = 2.9778  \n",
      "\n",
      "Fold: 10  Epoch: 231  Training loss = 2.3959  Validation loss = 2.9761  \n",
      "\n",
      "Fold: 10  Epoch: 232  Training loss = 2.3951  Validation loss = 2.9742  \n",
      "\n",
      "Fold: 10  Epoch: 233  Training loss = 2.3946  Validation loss = 2.9731  \n",
      "\n",
      "Fold: 10  Epoch: 234  Training loss = 2.3938  Validation loss = 2.9712  \n",
      "\n",
      "Fold: 10  Epoch: 235  Training loss = 2.3929  Validation loss = 2.9688  \n",
      "\n",
      "Fold: 10  Epoch: 236  Training loss = 2.3919  Validation loss = 2.9657  \n",
      "\n",
      "Fold: 10  Epoch: 237  Training loss = 2.3917  Validation loss = 2.9659  \n",
      "\n",
      "Fold: 10  Epoch: 238  Training loss = 2.3913  Validation loss = 2.9650  \n",
      "\n",
      "Fold: 10  Epoch: 239  Training loss = 2.3907  Validation loss = 2.9633  \n",
      "\n",
      "Fold: 10  Epoch: 240  Training loss = 2.3900  Validation loss = 2.9619  \n",
      "\n",
      "Fold: 10  Epoch: 241  Training loss = 2.3892  Validation loss = 2.9597  \n",
      "\n",
      "Fold: 10  Epoch: 242  Training loss = 2.3885  Validation loss = 2.9577  \n",
      "\n",
      "Fold: 10  Epoch: 243  Training loss = 2.3879  Validation loss = 2.9560  \n",
      "\n",
      "Fold: 10  Epoch: 244  Training loss = 2.3873  Validation loss = 2.9544  \n",
      "\n",
      "Fold: 10  Epoch: 245  Training loss = 2.3863  Validation loss = 2.9518  \n",
      "\n",
      "Fold: 10  Epoch: 246  Training loss = 2.3860  Validation loss = 2.9507  \n",
      "\n",
      "Fold: 10  Epoch: 247  Training loss = 2.3854  Validation loss = 2.9498  \n",
      "\n",
      "Fold: 10  Epoch: 248  Training loss = 2.3849  Validation loss = 2.9486  \n",
      "\n",
      "Fold: 10  Epoch: 249  Training loss = 2.3837  Validation loss = 2.9453  \n",
      "\n",
      "Fold: 10  Epoch: 250  Training loss = 2.3834  Validation loss = 2.9447  \n",
      "\n",
      "Fold: 10  Epoch: 251  Training loss = 2.3829  Validation loss = 2.9435  \n",
      "\n",
      "Fold: 10  Epoch: 252  Training loss = 2.3822  Validation loss = 2.9414  \n",
      "\n",
      "Fold: 10  Epoch: 253  Training loss = 2.3820  Validation loss = 2.9412  \n",
      "\n",
      "Fold: 10  Epoch: 254  Training loss = 2.3816  Validation loss = 2.9405  \n",
      "\n",
      "Fold: 10  Epoch: 255  Training loss = 2.3806  Validation loss = 2.9377  \n",
      "\n",
      "Fold: 10  Epoch: 256  Training loss = 2.3801  Validation loss = 2.9362  \n",
      "\n",
      "Fold: 10  Epoch: 257  Training loss = 2.3792  Validation loss = 2.9335  \n",
      "\n",
      "Fold: 10  Epoch: 258  Training loss = 2.3784  Validation loss = 2.9308  \n",
      "\n",
      "Fold: 10  Epoch: 259  Training loss = 2.3777  Validation loss = 2.9274  \n",
      "\n",
      "Fold: 10  Epoch: 260  Training loss = 2.3769  Validation loss = 2.9234  \n",
      "\n",
      "Fold: 10  Epoch: 261  Training loss = 2.3755  Validation loss = 2.8964  \n",
      "\n",
      "Fold: 10  Epoch: 262  Training loss = 2.3741  Validation loss = 2.8697  \n",
      "\n",
      "Fold: 10  Epoch: 263  Training loss = 2.3737  Validation loss = 2.8631  \n",
      "\n",
      "Fold: 10  Epoch: 264  Training loss = 2.3731  Validation loss = 2.8601  \n",
      "\n",
      "Fold: 10  Epoch: 265  Training loss = 2.3727  Validation loss = 2.8583  \n",
      "\n",
      "Fold: 10  Epoch: 266  Training loss = 2.3720  Validation loss = 2.8555  \n",
      "\n",
      "Fold: 10  Epoch: 267  Training loss = 2.3714  Validation loss = 2.8536  \n",
      "\n",
      "Fold: 10  Epoch: 268  Training loss = 2.3706  Validation loss = 2.8515  \n",
      "\n",
      "Fold: 10  Epoch: 269  Training loss = 2.3704  Validation loss = 2.8510  \n",
      "\n",
      "Fold: 10  Epoch: 270  Training loss = 2.3696  Validation loss = 2.8487  \n",
      "\n",
      "Fold: 10  Epoch: 271  Training loss = 2.3688  Validation loss = 2.8462  \n",
      "\n",
      "Fold: 10  Epoch: 272  Training loss = 2.3682  Validation loss = 2.8446  \n",
      "\n",
      "Fold: 10  Epoch: 273  Training loss = 2.3677  Validation loss = 2.8435  \n",
      "\n",
      "Fold: 10  Epoch: 274  Training loss = 2.3675  Validation loss = 2.8434  \n",
      "\n",
      "Fold: 10  Epoch: 275  Training loss = 2.3668  Validation loss = 2.8416  \n",
      "\n",
      "Fold: 10  Epoch: 276  Training loss = 2.3661  Validation loss = 2.8398  \n",
      "\n",
      "Fold: 10  Epoch: 277  Training loss = 2.3657  Validation loss = 2.8386  \n",
      "\n",
      "Fold: 10  Epoch: 278  Training loss = 2.3651  Validation loss = 2.8373  \n",
      "\n",
      "Fold: 10  Epoch: 279  Training loss = 2.3645  Validation loss = 2.8354  \n",
      "\n",
      "Fold: 10  Epoch: 280  Training loss = 2.3640  Validation loss = 2.8344  \n",
      "\n",
      "Fold: 10  Epoch: 281  Training loss = 2.3636  Validation loss = 2.8335  \n",
      "\n",
      "Fold: 10  Epoch: 282  Training loss = 2.3629  Validation loss = 2.8317  \n",
      "\n",
      "Fold: 10  Epoch: 283  Training loss = 2.3622  Validation loss = 2.8302  \n",
      "\n",
      "Fold: 10  Epoch: 284  Training loss = 2.3617  Validation loss = 2.8285  \n",
      "\n",
      "Fold: 10  Epoch: 285  Training loss = 2.3611  Validation loss = 2.8272  \n",
      "\n",
      "Fold: 10  Epoch: 286  Training loss = 2.3604  Validation loss = 2.8254  \n",
      "\n",
      "Fold: 10  Epoch: 287  Training loss = 2.3598  Validation loss = 2.8241  \n",
      "\n",
      "Fold: 10  Epoch: 288  Training loss = 2.3589  Validation loss = 2.8218  \n",
      "\n",
      "Fold: 10  Epoch: 289  Training loss = 2.3584  Validation loss = 2.8207  \n",
      "\n",
      "Fold: 10  Epoch: 290  Training loss = 2.3575  Validation loss = 2.8189  \n",
      "\n",
      "Fold: 10  Epoch: 291  Training loss = 2.3571  Validation loss = 2.8180  \n",
      "\n",
      "Fold: 10  Epoch: 292  Training loss = 2.3566  Validation loss = 2.8169  \n",
      "\n",
      "Fold: 10  Epoch: 293  Training loss = 2.3562  Validation loss = 2.8162  \n",
      "\n",
      "Fold: 10  Epoch: 294  Training loss = 2.3556  Validation loss = 2.8143  \n",
      "\n",
      "Fold: 10  Epoch: 295  Training loss = 2.3552  Validation loss = 2.8138  \n",
      "\n",
      "Fold: 10  Epoch: 296  Training loss = 2.3548  Validation loss = 2.8135  \n",
      "\n",
      "Fold: 10  Epoch: 297  Training loss = 2.3541  Validation loss = 2.8114  \n",
      "\n",
      "Fold: 10  Epoch: 298  Training loss = 2.3536  Validation loss = 2.8106  \n",
      "\n",
      "Fold: 10  Epoch: 299  Training loss = 2.3530  Validation loss = 2.8090  \n",
      "\n",
      "Fold: 10  Epoch: 300  Training loss = 2.3523  Validation loss = 2.8077  \n",
      "\n",
      "Fold: 10  Epoch: 301  Training loss = 2.3512  Validation loss = 2.8040  \n",
      "\n",
      "Fold: 10  Epoch: 302  Training loss = 2.3504  Validation loss = 2.8020  \n",
      "\n",
      "Fold: 10  Epoch: 303  Training loss = 2.3498  Validation loss = 2.8006  \n",
      "\n",
      "Fold: 10  Epoch: 304  Training loss = 2.3492  Validation loss = 2.7992  \n",
      "\n",
      "Fold: 10  Epoch: 305  Training loss = 2.3486  Validation loss = 2.7978  \n",
      "\n",
      "Fold: 10  Epoch: 306  Training loss = 2.3480  Validation loss = 2.7964  \n",
      "\n",
      "Fold: 10  Epoch: 307  Training loss = 2.3474  Validation loss = 2.7947  \n",
      "\n",
      "Fold: 10  Epoch: 308  Training loss = 2.3469  Validation loss = 2.7938  \n",
      "\n",
      "Fold: 10  Epoch: 309  Training loss = 2.3456  Validation loss = 2.7902  \n",
      "\n",
      "Fold: 10  Epoch: 310  Training loss = 2.3450  Validation loss = 2.7882  \n",
      "\n",
      "Fold: 10  Epoch: 311  Training loss = 2.3448  Validation loss = 2.7880  \n",
      "\n",
      "Fold: 10  Epoch: 312  Training loss = 2.3444  Validation loss = 2.7875  \n",
      "\n",
      "Fold: 10  Epoch: 313  Training loss = 2.3438  Validation loss = 2.7860  \n",
      "\n",
      "Fold: 10  Epoch: 314  Training loss = 2.3430  Validation loss = 2.7842  \n",
      "\n",
      "Fold: 10  Epoch: 315  Training loss = 2.3425  Validation loss = 2.7826  \n",
      "\n",
      "Fold: 10  Epoch: 316  Training loss = 2.3418  Validation loss = 2.7816  \n",
      "\n",
      "Fold: 10  Epoch: 317  Training loss = 2.3413  Validation loss = 2.7803  \n",
      "\n",
      "Fold: 10  Epoch: 318  Training loss = 2.3406  Validation loss = 2.7786  \n",
      "\n",
      "Fold: 10  Epoch: 319  Training loss = 2.3400  Validation loss = 2.7772  \n",
      "\n",
      "Fold: 10  Epoch: 320  Training loss = 2.3390  Validation loss = 2.7744  \n",
      "\n",
      "Fold: 10  Epoch: 321  Training loss = 2.3388  Validation loss = 2.7741  \n",
      "\n",
      "Fold: 10  Epoch: 322  Training loss = 2.3380  Validation loss = 2.7721  \n",
      "\n",
      "Fold: 10  Epoch: 323  Training loss = 2.3373  Validation loss = 2.7702  \n",
      "\n",
      "Fold: 10  Epoch: 324  Training loss = 2.3366  Validation loss = 2.7690  \n",
      "\n",
      "Fold: 10  Epoch: 325  Training loss = 2.3361  Validation loss = 2.7678  \n",
      "\n",
      "Fold: 10  Epoch: 326  Training loss = 2.3355  Validation loss = 2.7664  \n",
      "\n",
      "Fold: 10  Epoch: 327  Training loss = 2.3351  Validation loss = 2.7653  \n",
      "\n",
      "Fold: 10  Epoch: 328  Training loss = 2.3342  Validation loss = 2.7623  \n",
      "\n",
      "Fold: 10  Epoch: 329  Training loss = 2.3337  Validation loss = 2.7612  \n",
      "\n",
      "Fold: 10  Epoch: 330  Training loss = 2.3328  Validation loss = 2.7592  \n",
      "\n",
      "Fold: 10  Epoch: 331  Training loss = 2.3324  Validation loss = 2.7581  \n",
      "\n",
      "Fold: 10  Epoch: 332  Training loss = 2.3322  Validation loss = 2.7579  \n",
      "\n",
      "Fold: 10  Epoch: 333  Training loss = 2.3319  Validation loss = 2.7573  \n",
      "\n",
      "Fold: 10  Epoch: 334  Training loss = 2.3315  Validation loss = 2.7567  \n",
      "\n",
      "Fold: 10  Epoch: 335  Training loss = 2.3308  Validation loss = 2.7544  \n",
      "\n",
      "Fold: 10  Epoch: 336  Training loss = 2.3303  Validation loss = 2.7529  \n",
      "\n",
      "Fold: 10  Epoch: 337  Training loss = 2.3297  Validation loss = 2.7516  \n",
      "\n",
      "Fold: 10  Epoch: 338  Training loss = 2.3294  Validation loss = 2.7512  \n",
      "\n",
      "Fold: 10  Epoch: 339  Training loss = 2.3287  Validation loss = 2.7494  \n",
      "\n",
      "Fold: 10  Epoch: 340  Training loss = 2.3283  Validation loss = 2.7485  \n",
      "\n",
      "Fold: 10  Epoch: 341  Training loss = 2.3280  Validation loss = 2.7479  \n",
      "\n",
      "Fold: 10  Epoch: 342  Training loss = 2.3274  Validation loss = 2.7465  \n",
      "\n",
      "Fold: 10  Epoch: 343  Training loss = 2.3269  Validation loss = 2.7458  \n",
      "\n",
      "Fold: 10  Epoch: 344  Training loss = 2.3263  Validation loss = 2.7441  \n",
      "\n",
      "Fold: 10  Epoch: 345  Training loss = 2.3258  Validation loss = 2.7431  \n",
      "\n",
      "Fold: 10  Epoch: 346  Training loss = 2.3252  Validation loss = 2.7417  \n",
      "\n",
      "Fold: 10  Epoch: 347  Training loss = 2.3247  Validation loss = 2.7405  \n",
      "\n",
      "Fold: 10  Epoch: 348  Training loss = 2.3240  Validation loss = 2.7387  \n",
      "\n",
      "Fold: 10  Epoch: 349  Training loss = 2.3233  Validation loss = 2.7369  \n",
      "\n",
      "Fold: 10  Epoch: 350  Training loss = 2.3227  Validation loss = 2.7351  \n",
      "\n",
      "Fold: 10  Epoch: 351  Training loss = 2.3218  Validation loss = 2.7324  \n",
      "\n",
      "Fold: 10  Epoch: 352  Training loss = 2.3213  Validation loss = 2.7307  \n",
      "\n",
      "Fold: 10  Epoch: 353  Training loss = 2.3206  Validation loss = 2.7289  \n",
      "\n",
      "Fold: 10  Epoch: 354  Training loss = 2.3198  Validation loss = 2.7261  \n",
      "\n",
      "Fold: 10  Epoch: 355  Training loss = 2.3195  Validation loss = 2.7255  \n",
      "\n",
      "Fold: 10  Epoch: 356  Training loss = 2.3186  Validation loss = 2.7223  \n",
      "\n",
      "Fold: 10  Epoch: 357  Training loss = 2.3176  Validation loss = 2.7182  \n",
      "\n",
      "Fold: 10  Epoch: 358  Training loss = 2.3168  Validation loss = 2.7157  \n",
      "\n",
      "Fold: 10  Epoch: 359  Training loss = 2.3161  Validation loss = 2.7138  \n",
      "\n",
      "Fold: 10  Epoch: 360  Training loss = 2.3153  Validation loss = 2.7112  \n",
      "\n",
      "Fold: 10  Epoch: 361  Training loss = 2.3147  Validation loss = 2.7096  \n",
      "\n",
      "Fold: 10  Epoch: 362  Training loss = 2.3141  Validation loss = 2.7081  \n",
      "\n",
      "Fold: 10  Epoch: 363  Training loss = 2.3135  Validation loss = 2.7074  \n",
      "\n",
      "Fold: 10  Epoch: 364  Training loss = 2.3132  Validation loss = 2.7066  \n",
      "\n",
      "Fold: 10  Epoch: 365  Training loss = 2.3123  Validation loss = 2.7040  \n",
      "\n",
      "Fold: 10  Epoch: 366  Training loss = 2.3119  Validation loss = 2.7029  \n",
      "\n",
      "Fold: 10  Epoch: 367  Training loss = 2.3113  Validation loss = 2.7014  \n",
      "\n",
      "Fold: 10  Epoch: 368  Training loss = 2.3109  Validation loss = 2.7005  \n",
      "\n",
      "Fold: 10  Epoch: 369  Training loss = 2.3103  Validation loss = 2.6992  \n",
      "\n",
      "Fold: 10  Epoch: 370  Training loss = 2.3097  Validation loss = 2.6979  \n",
      "\n",
      "Fold: 10  Epoch: 371  Training loss = 2.3090  Validation loss = 2.6964  \n",
      "\n",
      "Fold: 10  Epoch: 372  Training loss = 2.3084  Validation loss = 2.6942  \n",
      "\n",
      "Fold: 10  Epoch: 373  Training loss = 2.3079  Validation loss = 2.6930  \n",
      "\n",
      "Fold: 10  Epoch: 374  Training loss = 2.3072  Validation loss = 2.6913  \n",
      "\n",
      "Fold: 10  Epoch: 375  Training loss = 2.3065  Validation loss = 2.6898  \n",
      "\n",
      "Fold: 10  Epoch: 376  Training loss = 2.3058  Validation loss = 2.6875  \n",
      "\n",
      "Fold: 10  Epoch: 377  Training loss = 2.3053  Validation loss = 2.6861  \n",
      "\n",
      "Fold: 10  Epoch: 378  Training loss = 2.3047  Validation loss = 2.6844  \n",
      "\n",
      "Fold: 10  Epoch: 379  Training loss = 2.3040  Validation loss = 2.6827  \n",
      "\n",
      "Fold: 10  Epoch: 380  Training loss = 2.3034  Validation loss = 2.6812  \n",
      "\n",
      "Fold: 10  Epoch: 381  Training loss = 2.3032  Validation loss = 2.6812  \n",
      "\n",
      "Fold: 10  Epoch: 382  Training loss = 2.3027  Validation loss = 2.6805  \n",
      "\n",
      "Fold: 10  Epoch: 383  Training loss = 2.3022  Validation loss = 2.6794  \n",
      "\n",
      "Fold: 10  Epoch: 384  Training loss = 2.3017  Validation loss = 2.6786  \n",
      "\n",
      "Fold: 10  Epoch: 385  Training loss = 2.3010  Validation loss = 2.6763  \n",
      "\n",
      "Fold: 10  Epoch: 386  Training loss = 2.3003  Validation loss = 2.6749  \n",
      "\n",
      "Fold: 10  Epoch: 387  Training loss = 2.2999  Validation loss = 2.6737  \n",
      "\n",
      "Fold: 10  Epoch: 388  Training loss = 2.2994  Validation loss = 2.6726  \n",
      "\n",
      "Fold: 10  Epoch: 389  Training loss = 2.2990  Validation loss = 2.6719  \n",
      "\n",
      "Fold: 10  Epoch: 390  Training loss = 2.2988  Validation loss = 2.6713  \n",
      "\n",
      "Fold: 10  Epoch: 391  Training loss = 2.2980  Validation loss = 2.6694  \n",
      "\n",
      "Fold: 10  Epoch: 392  Training loss = 2.2975  Validation loss = 2.6680  \n",
      "\n",
      "Fold: 10  Epoch: 393  Training loss = 2.2968  Validation loss = 2.6659  \n",
      "\n",
      "Fold: 10  Epoch: 394  Training loss = 2.2963  Validation loss = 2.6647  \n",
      "\n",
      "Fold: 10  Epoch: 395  Training loss = 2.2959  Validation loss = 2.6639  \n",
      "\n",
      "Fold: 10  Epoch: 396  Training loss = 2.2953  Validation loss = 2.6624  \n",
      "\n",
      "Fold: 10  Epoch: 397  Training loss = 2.2948  Validation loss = 2.6612  \n",
      "\n",
      "Fold: 10  Epoch: 398  Training loss = 2.2942  Validation loss = 2.6596  \n",
      "\n",
      "Fold: 10  Epoch: 399  Training loss = 2.2935  Validation loss = 2.6577  \n",
      "\n",
      "Fold: 10  Epoch: 400  Training loss = 2.2930  Validation loss = 2.6562  \n",
      "\n",
      "Fold: 10  Epoch: 401  Training loss = 2.2925  Validation loss = 2.6551  \n",
      "\n",
      "Fold: 10  Epoch: 402  Training loss = 2.2920  Validation loss = 2.6539  \n",
      "\n",
      "Fold: 10  Epoch: 403  Training loss = 2.2915  Validation loss = 2.6531  \n",
      "\n",
      "Fold: 10  Epoch: 404  Training loss = 2.2909  Validation loss = 2.6514  \n",
      "\n",
      "Fold: 10  Epoch: 405  Training loss = 2.2905  Validation loss = 2.6508  \n",
      "\n",
      "Fold: 10  Epoch: 406  Training loss = 2.2901  Validation loss = 2.6499  \n",
      "\n",
      "Fold: 10  Epoch: 407  Training loss = 2.2892  Validation loss = 2.6471  \n",
      "\n",
      "Fold: 10  Epoch: 408  Training loss = 2.2888  Validation loss = 2.6463  \n",
      "\n",
      "Fold: 10  Epoch: 409  Training loss = 2.2884  Validation loss = 2.6458  \n",
      "\n",
      "Fold: 10  Epoch: 410  Training loss = 2.2878  Validation loss = 2.6440  \n",
      "\n",
      "Fold: 10  Epoch: 411  Training loss = 2.2874  Validation loss = 2.6431  \n",
      "\n",
      "Fold: 10  Epoch: 412  Training loss = 2.2868  Validation loss = 2.6416  \n",
      "\n",
      "Fold: 10  Epoch: 413  Training loss = 2.2865  Validation loss = 2.6412  \n",
      "\n",
      "Fold: 10  Epoch: 414  Training loss = 2.2859  Validation loss = 2.6398  \n",
      "\n",
      "Fold: 10  Epoch: 415  Training loss = 2.2855  Validation loss = 2.6387  \n",
      "\n",
      "Fold: 10  Epoch: 416  Training loss = 2.2848  Validation loss = 2.6368  \n",
      "\n",
      "Fold: 10  Epoch: 417  Training loss = 2.2845  Validation loss = 2.6359  \n",
      "\n",
      "Fold: 10  Epoch: 418  Training loss = 2.2840  Validation loss = 2.6351  \n",
      "\n",
      "Fold: 10  Epoch: 419  Training loss = 2.2835  Validation loss = 2.6340  \n",
      "\n",
      "Fold: 10  Epoch: 420  Training loss = 2.2832  Validation loss = 2.6332  \n",
      "\n",
      "Fold: 10  Epoch: 421  Training loss = 2.2828  Validation loss = 2.6324  \n",
      "\n",
      "Fold: 10  Epoch: 422  Training loss = 2.2825  Validation loss = 2.6320  \n",
      "\n",
      "Fold: 10  Epoch: 423  Training loss = 2.2823  Validation loss = 2.6318  \n",
      "\n",
      "Fold: 10  Epoch: 424  Training loss = 2.2817  Validation loss = 2.6301  \n",
      "\n",
      "Fold: 10  Epoch: 425  Training loss = 2.2810  Validation loss = 2.6284  \n",
      "\n",
      "Fold: 10  Epoch: 426  Training loss = 2.2801  Validation loss = 2.6260  \n",
      "\n",
      "Fold: 10  Epoch: 427  Training loss = 2.2793  Validation loss = 2.6244  \n",
      "\n",
      "Fold: 10  Epoch: 428  Training loss = 2.2791  Validation loss = 2.6239  \n",
      "\n",
      "Fold: 10  Epoch: 429  Training loss = 2.2783  Validation loss = 2.6218  \n",
      "\n",
      "Fold: 10  Epoch: 430  Training loss = 2.2780  Validation loss = 2.6212  \n",
      "\n",
      "Fold: 10  Epoch: 431  Training loss = 2.2774  Validation loss = 2.6195  \n",
      "\n",
      "Fold: 10  Epoch: 432  Training loss = 2.2768  Validation loss = 2.6184  \n",
      "\n",
      "Fold: 10  Epoch: 433  Training loss = 2.2766  Validation loss = 2.6181  \n",
      "\n",
      "Fold: 10  Epoch: 434  Training loss = 2.2759  Validation loss = 2.6163  \n",
      "\n",
      "Fold: 10  Epoch: 435  Training loss = 2.2756  Validation loss = 2.6157  \n",
      "\n",
      "Fold: 10  Epoch: 436  Training loss = 2.2750  Validation loss = 2.6140  \n",
      "\n",
      "Fold: 10  Epoch: 437  Training loss = 2.2742  Validation loss = 2.6114  \n",
      "\n",
      "Fold: 10  Epoch: 438  Training loss = 2.2738  Validation loss = 2.6108  \n",
      "\n",
      "Fold: 10  Epoch: 439  Training loss = 2.2735  Validation loss = 2.6101  \n",
      "\n",
      "Fold: 10  Epoch: 440  Training loss = 2.2729  Validation loss = 2.6086  \n",
      "\n",
      "Fold: 10  Epoch: 441  Training loss = 2.2720  Validation loss = 2.6062  \n",
      "\n",
      "Fold: 10  Epoch: 442  Training loss = 2.2714  Validation loss = 2.6051  \n",
      "\n",
      "Fold: 10  Epoch: 443  Training loss = 2.2706  Validation loss = 2.6025  \n",
      "\n",
      "Fold: 10  Epoch: 444  Training loss = 2.2702  Validation loss = 2.6012  \n",
      "\n",
      "Fold: 10  Epoch: 445  Training loss = 2.2697  Validation loss = 2.5999  \n",
      "\n",
      "Fold: 10  Epoch: 446  Training loss = 2.2693  Validation loss = 2.5989  \n",
      "\n",
      "Fold: 10  Epoch: 447  Training loss = 2.2688  Validation loss = 2.5977  \n",
      "\n",
      "Fold: 10  Epoch: 448  Training loss = 2.2680  Validation loss = 2.5952  \n",
      "\n",
      "Fold: 10  Epoch: 449  Training loss = 2.2676  Validation loss = 2.5943  \n",
      "\n",
      "Fold: 10  Epoch: 450  Training loss = 2.2671  Validation loss = 2.5929  \n",
      "\n",
      "Fold: 10  Epoch: 451  Training loss = 2.2665  Validation loss = 2.5909  \n",
      "\n",
      "Fold: 10  Epoch: 452  Training loss = 2.2659  Validation loss = 2.5892  \n",
      "\n",
      "Fold: 10  Epoch: 453  Training loss = 2.2654  Validation loss = 2.5881  \n",
      "\n",
      "Fold: 10  Epoch: 454  Training loss = 2.2649  Validation loss = 2.5872  \n",
      "\n",
      "Fold: 10  Epoch: 455  Training loss = 2.2645  Validation loss = 2.5863  \n",
      "\n",
      "Fold: 10  Epoch: 456  Training loss = 2.2639  Validation loss = 2.5850  \n",
      "\n",
      "Fold: 10  Epoch: 457  Training loss = 2.2637  Validation loss = 2.5848  \n",
      "\n",
      "Fold: 10  Epoch: 458  Training loss = 2.2631  Validation loss = 2.5829  \n",
      "\n",
      "Fold: 10  Epoch: 459  Training loss = 2.2623  Validation loss = 2.5804  \n",
      "\n",
      "Fold: 10  Epoch: 460  Training loss = 2.2618  Validation loss = 2.5793  \n",
      "\n",
      "Fold: 10  Epoch: 461  Training loss = 2.2613  Validation loss = 2.5784  \n",
      "\n",
      "Fold: 10  Epoch: 462  Training loss = 2.2606  Validation loss = 2.5763  \n",
      "\n",
      "Fold: 10  Epoch: 463  Training loss = 2.2599  Validation loss = 2.5743  \n",
      "\n",
      "Fold: 10  Epoch: 464  Training loss = 2.2592  Validation loss = 2.5727  \n",
      "\n",
      "Fold: 10  Epoch: 465  Training loss = 2.2584  Validation loss = 2.5701  \n",
      "\n",
      "Fold: 10  Epoch: 466  Training loss = 2.2579  Validation loss = 2.5688  \n",
      "\n",
      "Fold: 10  Epoch: 467  Training loss = 2.2572  Validation loss = 2.5671  \n",
      "\n",
      "Fold: 10  Epoch: 468  Training loss = 2.2567  Validation loss = 2.5656  \n",
      "\n",
      "Fold: 10  Epoch: 469  Training loss = 2.2564  Validation loss = 2.5649  \n",
      "\n",
      "Fold: 10  Epoch: 470  Training loss = 2.2560  Validation loss = 2.5637  \n",
      "\n",
      "Fold: 10  Epoch: 471  Training loss = 2.2554  Validation loss = 2.5628  \n",
      "\n",
      "Fold: 10  Epoch: 472  Training loss = 2.2553  Validation loss = 2.5628  \n",
      "\n",
      "Fold: 10  Epoch: 473  Training loss = 2.2547  Validation loss = 2.5614  \n",
      "\n",
      "Fold: 10  Epoch: 474  Training loss = 2.2543  Validation loss = 2.5601  \n",
      "\n",
      "Fold: 10  Epoch: 475  Training loss = 2.2537  Validation loss = 2.5585  \n",
      "\n",
      "Fold: 10  Epoch: 476  Training loss = 2.2534  Validation loss = 2.5579  \n",
      "\n",
      "Fold: 10  Epoch: 477  Training loss = 2.2527  Validation loss = 2.5558  \n",
      "\n",
      "Fold: 10  Epoch: 478  Training loss = 2.2524  Validation loss = 2.5554  \n",
      "\n",
      "Fold: 10  Epoch: 479  Training loss = 2.2519  Validation loss = 2.5544  \n",
      "\n",
      "Fold: 10  Epoch: 480  Training loss = 2.2514  Validation loss = 2.5534  \n",
      "\n",
      "Fold: 10  Epoch: 481  Training loss = 2.2511  Validation loss = 2.5526  \n",
      "\n",
      "Fold: 10  Epoch: 482  Training loss = 2.2507  Validation loss = 2.5514  \n",
      "\n",
      "Fold: 10  Epoch: 483  Training loss = 2.2501  Validation loss = 2.5501  \n",
      "\n",
      "Fold: 10  Epoch: 484  Training loss = 2.2498  Validation loss = 2.5497  \n",
      "\n",
      "Fold: 10  Epoch: 485  Training loss = 2.2494  Validation loss = 2.5489  \n",
      "\n",
      "Fold: 10  Epoch: 486  Training loss = 2.2489  Validation loss = 2.5470  \n",
      "\n",
      "Fold: 10  Epoch: 487  Training loss = 2.2486  Validation loss = 2.5467  \n",
      "\n",
      "Fold: 10  Epoch: 488  Training loss = 2.2482  Validation loss = 2.5453  \n",
      "\n",
      "Fold: 10  Epoch: 489  Training loss = 2.2477  Validation loss = 2.5444  \n",
      "\n",
      "Fold: 10  Epoch: 490  Training loss = 2.2475  Validation loss = 2.5438  \n",
      "\n",
      "Fold: 10  Epoch: 491  Training loss = 2.2468  Validation loss = 2.5418  \n",
      "\n",
      "Fold: 10  Epoch: 492  Training loss = 2.2463  Validation loss = 2.5403  \n",
      "\n",
      "Fold: 10  Epoch: 493  Training loss = 2.2460  Validation loss = 2.5397  \n",
      "\n",
      "Fold: 10  Epoch: 494  Training loss = 2.2456  Validation loss = 2.5384  \n",
      "\n",
      "Fold: 10  Epoch: 495  Training loss = 2.2452  Validation loss = 2.5374  \n",
      "\n",
      "Fold: 10  Epoch: 496  Training loss = 2.2448  Validation loss = 2.5362  \n",
      "\n",
      "Fold: 10  Epoch: 497  Training loss = 2.2445  Validation loss = 2.5356  \n",
      "\n",
      "Fold: 10  Epoch: 498  Training loss = 2.2441  Validation loss = 2.5346  \n",
      "\n",
      "Fold: 10  Epoch: 499  Training loss = 2.2436  Validation loss = 2.5335  \n",
      "\n",
      "Fold: 10  Epoch: 500  Training loss = 2.2429  Validation loss = 2.5300  \n",
      "\n",
      "Check model:  Fold: 10  Optimal epoch: 500  \n",
      "\n",
      "Fold: 11  Epoch: 1  Training loss = 2.2987  Validation loss = 1.1917  \n",
      "\n",
      "Fold: 11  Epoch: 2  Training loss = 2.2960  Validation loss = 1.1917  \n",
      "\n",
      "Fold: 11  Epoch: 3  Training loss = 2.2949  Validation loss = 1.1915  \n",
      "\n",
      "Fold: 11  Epoch: 4  Training loss = 2.2942  Validation loss = 1.1919  \n",
      "\n",
      "Fold: 11  Epoch: 5  Training loss = 2.2938  Validation loss = 1.1919  \n",
      "\n",
      "Fold: 11  Epoch: 6  Training loss = 2.2933  Validation loss = 1.1924  \n",
      "\n",
      "Fold: 11  Epoch: 7  Training loss = 2.2926  Validation loss = 1.1928  \n",
      "\n",
      "Fold: 11  Epoch: 8  Training loss = 2.2919  Validation loss = 1.1929  \n",
      "\n",
      "Fold: 11  Epoch: 9  Training loss = 2.2917  Validation loss = 1.1930  \n",
      "\n",
      "Fold: 11  Epoch: 10  Training loss = 2.2910  Validation loss = 1.1933  \n",
      "\n",
      "Fold: 11  Epoch: 11  Training loss = 2.2906  Validation loss = 1.1932  \n",
      "\n",
      "Fold: 11  Epoch: 12  Training loss = 2.2904  Validation loss = 1.1932  \n",
      "\n",
      "Fold: 11  Epoch: 13  Training loss = 2.2899  Validation loss = 1.1935  \n",
      "\n",
      "Check model:  Fold: 11  Optimal epoch: 3  \n",
      "\n",
      "Fold: 12  Epoch: 1  Training loss = 2.2845  Validation loss = 2.0201  \n",
      "\n",
      "Fold: 12  Epoch: 2  Training loss = 2.2836  Validation loss = 2.0168  \n",
      "\n",
      "Fold: 12  Epoch: 3  Training loss = 2.2829  Validation loss = 2.0141  \n",
      "\n",
      "Fold: 12  Epoch: 4  Training loss = 2.2817  Validation loss = 2.0104  \n",
      "\n",
      "Fold: 12  Epoch: 5  Training loss = 2.2812  Validation loss = 2.0091  \n",
      "\n",
      "Fold: 12  Epoch: 6  Training loss = 2.2803  Validation loss = 2.0068  \n",
      "\n",
      "Fold: 12  Epoch: 7  Training loss = 2.2796  Validation loss = 2.0040  \n",
      "\n",
      "Fold: 12  Epoch: 8  Training loss = 2.2790  Validation loss = 2.0025  \n",
      "\n",
      "Fold: 12  Epoch: 9  Training loss = 2.2786  Validation loss = 2.0012  \n",
      "\n",
      "Fold: 12  Epoch: 10  Training loss = 2.2778  Validation loss = 1.9983  \n",
      "\n",
      "Fold: 12  Epoch: 11  Training loss = 2.2774  Validation loss = 1.9973  \n",
      "\n",
      "Fold: 12  Epoch: 12  Training loss = 2.2766  Validation loss = 1.9950  \n",
      "\n",
      "Fold: 12  Epoch: 13  Training loss = 2.2760  Validation loss = 1.9935  \n",
      "\n",
      "Fold: 12  Epoch: 14  Training loss = 2.2755  Validation loss = 1.9914  \n",
      "\n",
      "Fold: 12  Epoch: 15  Training loss = 2.2751  Validation loss = 1.9913  \n",
      "\n",
      "Fold: 12  Epoch: 16  Training loss = 2.2746  Validation loss = 1.9889  \n",
      "\n",
      "Fold: 12  Epoch: 17  Training loss = 2.2735  Validation loss = 1.9851  \n",
      "\n",
      "Fold: 12  Epoch: 18  Training loss = 2.2724  Validation loss = 1.9821  \n",
      "\n",
      "Fold: 12  Epoch: 19  Training loss = 2.2716  Validation loss = 1.9793  \n",
      "\n",
      "Fold: 12  Epoch: 20  Training loss = 2.2708  Validation loss = 1.9765  \n",
      "\n",
      "Fold: 12  Epoch: 21  Training loss = 2.2698  Validation loss = 1.9737  \n",
      "\n",
      "Fold: 12  Epoch: 22  Training loss = 2.2693  Validation loss = 1.9726  \n",
      "\n",
      "Fold: 12  Epoch: 23  Training loss = 2.2689  Validation loss = 1.9716  \n",
      "\n",
      "Fold: 12  Epoch: 24  Training loss = 2.2684  Validation loss = 1.9704  \n",
      "\n",
      "Fold: 12  Epoch: 25  Training loss = 2.2673  Validation loss = 1.9669  \n",
      "\n",
      "Fold: 12  Epoch: 26  Training loss = 2.2664  Validation loss = 1.9643  \n",
      "\n",
      "Fold: 12  Epoch: 27  Training loss = 2.2657  Validation loss = 1.9626  \n",
      "\n",
      "Fold: 12  Epoch: 28  Training loss = 2.2654  Validation loss = 1.9622  \n",
      "\n",
      "Fold: 12  Epoch: 29  Training loss = 2.2650  Validation loss = 1.9620  \n",
      "\n",
      "Fold: 12  Epoch: 30  Training loss = 2.2644  Validation loss = 1.9596  \n",
      "\n",
      "Fold: 12  Epoch: 31  Training loss = 2.2643  Validation loss = 1.9600  \n",
      "\n",
      "Fold: 12  Epoch: 32  Training loss = 2.2635  Validation loss = 1.9576  \n",
      "\n",
      "Fold: 12  Epoch: 33  Training loss = 2.2630  Validation loss = 1.9568  \n",
      "\n",
      "Fold: 12  Epoch: 34  Training loss = 2.2624  Validation loss = 1.9556  \n",
      "\n",
      "Fold: 12  Epoch: 35  Training loss = 2.2616  Validation loss = 1.9533  \n",
      "\n",
      "Fold: 12  Epoch: 36  Training loss = 2.2608  Validation loss = 1.9498  \n",
      "\n",
      "Fold: 12  Epoch: 37  Training loss = 2.2604  Validation loss = 1.9497  \n",
      "\n",
      "Fold: 12  Epoch: 38  Training loss = 2.2597  Validation loss = 1.9475  \n",
      "\n",
      "Fold: 12  Epoch: 39  Training loss = 2.2590  Validation loss = 1.9453  \n",
      "\n",
      "Fold: 12  Epoch: 40  Training loss = 2.2583  Validation loss = 1.9447  \n",
      "\n",
      "Fold: 12  Epoch: 41  Training loss = 2.2583  Validation loss = 1.9456  \n",
      "\n",
      "Fold: 12  Epoch: 42  Training loss = 2.2579  Validation loss = 1.9446  \n",
      "\n",
      "Fold: 12  Epoch: 43  Training loss = 2.2571  Validation loss = 1.9418  \n",
      "\n",
      "Fold: 12  Epoch: 44  Training loss = 2.2568  Validation loss = 1.9407  \n",
      "\n",
      "Fold: 12  Epoch: 45  Training loss = 2.2557  Validation loss = 1.9371  \n",
      "\n",
      "Fold: 12  Epoch: 46  Training loss = 2.2551  Validation loss = 1.9352  \n",
      "\n",
      "Fold: 12  Epoch: 47  Training loss = 2.2544  Validation loss = 1.9330  \n",
      "\n",
      "Fold: 12  Epoch: 48  Training loss = 2.2539  Validation loss = 1.9319  \n",
      "\n",
      "Fold: 12  Epoch: 49  Training loss = 2.2535  Validation loss = 1.9313  \n",
      "\n",
      "Fold: 12  Epoch: 50  Training loss = 2.2530  Validation loss = 1.9293  \n",
      "\n",
      "Fold: 12  Epoch: 51  Training loss = 2.2524  Validation loss = 1.9272  \n",
      "\n",
      "Fold: 12  Epoch: 52  Training loss = 2.2519  Validation loss = 1.9260  \n",
      "\n",
      "Fold: 12  Epoch: 53  Training loss = 2.2515  Validation loss = 1.9244  \n",
      "\n",
      "Fold: 12  Epoch: 54  Training loss = 2.2511  Validation loss = 1.9223  \n",
      "\n",
      "Fold: 12  Epoch: 55  Training loss = 2.2502  Validation loss = 1.9187  \n",
      "\n",
      "Fold: 12  Epoch: 56  Training loss = 2.2497  Validation loss = 1.9176  \n",
      "\n",
      "Fold: 12  Epoch: 57  Training loss = 2.2495  Validation loss = 1.9164  \n",
      "\n",
      "Fold: 12  Epoch: 58  Training loss = 2.2490  Validation loss = 1.9162  \n",
      "\n",
      "Fold: 12  Epoch: 59  Training loss = 2.2483  Validation loss = 1.9148  \n",
      "\n",
      "Fold: 12  Epoch: 60  Training loss = 2.2482  Validation loss = 1.9149  \n",
      "\n",
      "Fold: 12  Epoch: 61  Training loss = 2.2475  Validation loss = 1.9131  \n",
      "\n",
      "Fold: 12  Epoch: 62  Training loss = 2.2471  Validation loss = 1.9126  \n",
      "\n",
      "Fold: 12  Epoch: 63  Training loss = 2.2466  Validation loss = 1.9122  \n",
      "\n",
      "Fold: 12  Epoch: 64  Training loss = 2.2457  Validation loss = 1.9082  \n",
      "\n",
      "Fold: 12  Epoch: 65  Training loss = 2.2458  Validation loss = 1.9090  \n",
      "\n",
      "Fold: 12  Epoch: 66  Training loss = 2.2452  Validation loss = 1.9078  \n",
      "\n",
      "Fold: 12  Epoch: 67  Training loss = 2.2450  Validation loss = 1.9068  \n",
      "\n",
      "Fold: 12  Epoch: 68  Training loss = 2.2445  Validation loss = 1.9056  \n",
      "\n",
      "Fold: 12  Epoch: 69  Training loss = 2.2440  Validation loss = 1.9046  \n",
      "\n",
      "Fold: 12  Epoch: 70  Training loss = 2.2434  Validation loss = 1.9025  \n",
      "\n",
      "Fold: 12  Epoch: 71  Training loss = 2.2426  Validation loss = 1.8996  \n",
      "\n",
      "Fold: 12  Epoch: 72  Training loss = 2.2423  Validation loss = 1.8993  \n",
      "\n",
      "Fold: 12  Epoch: 73  Training loss = 2.2421  Validation loss = 1.8989  \n",
      "\n",
      "Fold: 12  Epoch: 74  Training loss = 2.2419  Validation loss = 1.8989  \n",
      "\n",
      "Fold: 12  Epoch: 75  Training loss = 2.2412  Validation loss = 1.8970  \n",
      "\n",
      "Fold: 12  Epoch: 76  Training loss = 2.2402  Validation loss = 1.8944  \n",
      "\n",
      "Fold: 12  Epoch: 77  Training loss = 2.2398  Validation loss = 1.8939  \n",
      "\n",
      "Fold: 12  Epoch: 78  Training loss = 2.2396  Validation loss = 1.8937  \n",
      "\n",
      "Fold: 12  Epoch: 79  Training loss = 2.2389  Validation loss = 1.8914  \n",
      "\n",
      "Fold: 12  Epoch: 80  Training loss = 2.2381  Validation loss = 1.8896  \n",
      "\n",
      "Fold: 12  Epoch: 81  Training loss = 2.2374  Validation loss = 1.8878  \n",
      "\n",
      "Fold: 12  Epoch: 82  Training loss = 2.2370  Validation loss = 1.8874  \n",
      "\n",
      "Fold: 12  Epoch: 83  Training loss = 2.2368  Validation loss = 1.8876  \n",
      "\n",
      "Fold: 12  Epoch: 84  Training loss = 2.2364  Validation loss = 1.8871  \n",
      "\n",
      "Fold: 12  Epoch: 85  Training loss = 2.2355  Validation loss = 1.8836  \n",
      "\n",
      "Fold: 12  Epoch: 86  Training loss = 2.2351  Validation loss = 1.8821  \n",
      "\n",
      "Fold: 12  Epoch: 87  Training loss = 2.2348  Validation loss = 1.8815  \n",
      "\n",
      "Fold: 12  Epoch: 88  Training loss = 2.2345  Validation loss = 1.8807  \n",
      "\n",
      "Fold: 12  Epoch: 89  Training loss = 2.2339  Validation loss = 1.8791  \n",
      "\n",
      "Fold: 12  Epoch: 90  Training loss = 2.2337  Validation loss = 1.8801  \n",
      "\n",
      "Fold: 12  Epoch: 91  Training loss = 2.2337  Validation loss = 1.8808  \n",
      "\n",
      "Fold: 12  Epoch: 92  Training loss = 2.2332  Validation loss = 1.8799  \n",
      "\n",
      "Fold: 12  Epoch: 93  Training loss = 2.2325  Validation loss = 1.8781  \n",
      "\n",
      "Fold: 12  Epoch: 94  Training loss = 2.2321  Validation loss = 1.8764  \n",
      "\n",
      "Fold: 12  Epoch: 95  Training loss = 2.2319  Validation loss = 1.8759  \n",
      "\n",
      "Fold: 12  Epoch: 96  Training loss = 2.2315  Validation loss = 1.8759  \n",
      "\n",
      "Fold: 12  Epoch: 97  Training loss = 2.2307  Validation loss = 1.8736  \n",
      "\n",
      "Fold: 12  Epoch: 98  Training loss = 2.2304  Validation loss = 1.8727  \n",
      "\n",
      "Fold: 12  Epoch: 99  Training loss = 2.2299  Validation loss = 1.8715  \n",
      "\n",
      "Fold: 12  Epoch: 100  Training loss = 2.2296  Validation loss = 1.8718  \n",
      "\n",
      "Fold: 12  Epoch: 101  Training loss = 2.2292  Validation loss = 1.8709  \n",
      "\n",
      "Fold: 12  Epoch: 102  Training loss = 2.2286  Validation loss = 1.8698  \n",
      "\n",
      "Fold: 12  Epoch: 103  Training loss = 2.2281  Validation loss = 1.8683  \n",
      "\n",
      "Fold: 12  Epoch: 104  Training loss = 2.2274  Validation loss = 1.8659  \n",
      "\n",
      "Fold: 12  Epoch: 105  Training loss = 2.2271  Validation loss = 1.8650  \n",
      "\n",
      "Fold: 12  Epoch: 106  Training loss = 2.2268  Validation loss = 1.8652  \n",
      "\n",
      "Fold: 12  Epoch: 107  Training loss = 2.2267  Validation loss = 1.8650  \n",
      "\n",
      "Fold: 12  Epoch: 108  Training loss = 2.2264  Validation loss = 1.8658  \n",
      "\n",
      "Fold: 12  Epoch: 109  Training loss = 2.2259  Validation loss = 1.8654  \n",
      "\n",
      "Fold: 12  Epoch: 110  Training loss = 2.2255  Validation loss = 1.8634  \n",
      "\n",
      "Fold: 12  Epoch: 111  Training loss = 2.2250  Validation loss = 1.8624  \n",
      "\n",
      "Fold: 12  Epoch: 112  Training loss = 2.2242  Validation loss = 1.8594  \n",
      "\n",
      "Fold: 12  Epoch: 113  Training loss = 2.2236  Validation loss = 1.8582  \n",
      "\n",
      "Fold: 12  Epoch: 114  Training loss = 2.2229  Validation loss = 1.8559  \n",
      "\n",
      "Fold: 12  Epoch: 115  Training loss = 2.2224  Validation loss = 1.8538  \n",
      "\n",
      "Fold: 12  Epoch: 116  Training loss = 2.2218  Validation loss = 1.8527  \n",
      "\n",
      "Fold: 12  Epoch: 117  Training loss = 2.2213  Validation loss = 1.8505  \n",
      "\n",
      "Fold: 12  Epoch: 118  Training loss = 2.2208  Validation loss = 1.8493  \n",
      "\n",
      "Fold: 12  Epoch: 119  Training loss = 2.2204  Validation loss = 1.8494  \n",
      "\n",
      "Fold: 12  Epoch: 120  Training loss = 2.2198  Validation loss = 1.8480  \n",
      "\n",
      "Fold: 12  Epoch: 121  Training loss = 2.2191  Validation loss = 1.8471  \n",
      "\n",
      "Fold: 12  Epoch: 122  Training loss = 2.2186  Validation loss = 1.8448  \n",
      "\n",
      "Fold: 12  Epoch: 123  Training loss = 2.2177  Validation loss = 1.8418  \n",
      "\n",
      "Fold: 12  Epoch: 124  Training loss = 2.2173  Validation loss = 1.8402  \n",
      "\n",
      "Fold: 12  Epoch: 125  Training loss = 2.2169  Validation loss = 1.8394  \n",
      "\n",
      "Fold: 12  Epoch: 126  Training loss = 2.2162  Validation loss = 1.8374  \n",
      "\n",
      "Fold: 12  Epoch: 127  Training loss = 2.2159  Validation loss = 1.8382  \n",
      "\n",
      "Fold: 12  Epoch: 128  Training loss = 2.2156  Validation loss = 1.8388  \n",
      "\n",
      "Fold: 12  Epoch: 129  Training loss = 2.2152  Validation loss = 1.8375  \n",
      "\n",
      "Fold: 12  Epoch: 130  Training loss = 2.2146  Validation loss = 1.8353  \n",
      "\n",
      "Fold: 12  Epoch: 131  Training loss = 2.2142  Validation loss = 1.8337  \n",
      "\n",
      "Fold: 12  Epoch: 132  Training loss = 2.2135  Validation loss = 1.8329  \n",
      "\n",
      "Fold: 12  Epoch: 133  Training loss = 2.2128  Validation loss = 1.8313  \n",
      "\n",
      "Fold: 12  Epoch: 134  Training loss = 2.2126  Validation loss = 1.8331  \n",
      "\n",
      "Fold: 12  Epoch: 135  Training loss = 2.2121  Validation loss = 1.8324  \n",
      "\n",
      "Fold: 12  Epoch: 136  Training loss = 2.2119  Validation loss = 1.8321  \n",
      "\n",
      "Fold: 12  Epoch: 137  Training loss = 2.2111  Validation loss = 1.8288  \n",
      "\n",
      "Fold: 12  Epoch: 138  Training loss = 2.2105  Validation loss = 1.8271  \n",
      "\n",
      "Fold: 12  Epoch: 139  Training loss = 2.2101  Validation loss = 1.8259  \n",
      "\n",
      "Fold: 12  Epoch: 140  Training loss = 2.2096  Validation loss = 1.8247  \n",
      "\n",
      "Fold: 12  Epoch: 141  Training loss = 2.2093  Validation loss = 1.8239  \n",
      "\n",
      "Fold: 12  Epoch: 142  Training loss = 2.2091  Validation loss = 1.8243  \n",
      "\n",
      "Fold: 12  Epoch: 143  Training loss = 2.2089  Validation loss = 1.8239  \n",
      "\n",
      "Fold: 12  Epoch: 144  Training loss = 2.2086  Validation loss = 1.8226  \n",
      "\n",
      "Fold: 12  Epoch: 145  Training loss = 2.2080  Validation loss = 1.8211  \n",
      "\n",
      "Fold: 12  Epoch: 146  Training loss = 2.2077  Validation loss = 1.8196  \n",
      "\n",
      "Fold: 12  Epoch: 147  Training loss = 2.2073  Validation loss = 1.8178  \n",
      "\n",
      "Fold: 12  Epoch: 148  Training loss = 2.2064  Validation loss = 1.8154  \n",
      "\n",
      "Fold: 12  Epoch: 149  Training loss = 2.2059  Validation loss = 1.8132  \n",
      "\n",
      "Fold: 12  Epoch: 150  Training loss = 2.2056  Validation loss = 1.8125  \n",
      "\n",
      "Fold: 12  Epoch: 151  Training loss = 2.2054  Validation loss = 1.8129  \n",
      "\n",
      "Fold: 12  Epoch: 152  Training loss = 2.2048  Validation loss = 1.8103  \n",
      "\n",
      "Fold: 12  Epoch: 153  Training loss = 2.2040  Validation loss = 1.8079  \n",
      "\n",
      "Fold: 12  Epoch: 154  Training loss = 2.2036  Validation loss = 1.8076  \n",
      "\n",
      "Fold: 12  Epoch: 155  Training loss = 2.2033  Validation loss = 1.8056  \n",
      "\n",
      "Fold: 12  Epoch: 156  Training loss = 2.2031  Validation loss = 1.8049  \n",
      "\n",
      "Fold: 12  Epoch: 157  Training loss = 2.2028  Validation loss = 1.8043  \n",
      "\n",
      "Fold: 12  Epoch: 158  Training loss = 2.2021  Validation loss = 1.8008  \n",
      "\n",
      "Fold: 12  Epoch: 159  Training loss = 2.2014  Validation loss = 1.7977  \n",
      "\n",
      "Fold: 12  Epoch: 160  Training loss = 2.2007  Validation loss = 1.7936  \n",
      "\n",
      "Fold: 12  Epoch: 161  Training loss = 2.2007  Validation loss = 1.7952  \n",
      "\n",
      "Fold: 12  Epoch: 162  Training loss = 2.2004  Validation loss = 1.7951  \n",
      "\n",
      "Fold: 12  Epoch: 163  Training loss = 2.1999  Validation loss = 1.7932  \n",
      "\n",
      "Fold: 12  Epoch: 164  Training loss = 2.1990  Validation loss = 1.7905  \n",
      "\n",
      "Fold: 12  Epoch: 165  Training loss = 2.1986  Validation loss = 1.7903  \n",
      "\n",
      "Fold: 12  Epoch: 166  Training loss = 2.1979  Validation loss = 1.7882  \n",
      "\n",
      "Fold: 12  Epoch: 167  Training loss = 2.1977  Validation loss = 1.7872  \n",
      "\n",
      "Fold: 12  Epoch: 168  Training loss = 2.1975  Validation loss = 1.7886  \n",
      "\n",
      "Fold: 12  Epoch: 169  Training loss = 2.1970  Validation loss = 1.7873  \n",
      "\n",
      "Fold: 12  Epoch: 170  Training loss = 2.1966  Validation loss = 1.7852  \n",
      "\n",
      "Fold: 12  Epoch: 171  Training loss = 2.1965  Validation loss = 1.7854  \n",
      "\n",
      "Fold: 12  Epoch: 172  Training loss = 2.1956  Validation loss = 1.7820  \n",
      "\n",
      "Fold: 12  Epoch: 173  Training loss = 2.1954  Validation loss = 1.7818  \n",
      "\n",
      "Fold: 12  Epoch: 174  Training loss = 2.1949  Validation loss = 1.7793  \n",
      "\n",
      "Fold: 12  Epoch: 175  Training loss = 2.1941  Validation loss = 1.7762  \n",
      "\n",
      "Fold: 12  Epoch: 176  Training loss = 2.1936  Validation loss = 1.7744  \n",
      "\n",
      "Fold: 12  Epoch: 177  Training loss = 2.1932  Validation loss = 1.7734  \n",
      "\n",
      "Fold: 12  Epoch: 178  Training loss = 2.1927  Validation loss = 1.7725  \n",
      "\n",
      "Fold: 12  Epoch: 179  Training loss = 2.1925  Validation loss = 1.7739  \n",
      "\n",
      "Fold: 12  Epoch: 180  Training loss = 2.1918  Validation loss = 1.7707  \n",
      "\n",
      "Fold: 12  Epoch: 181  Training loss = 2.1914  Validation loss = 1.7706  \n",
      "\n",
      "Fold: 12  Epoch: 182  Training loss = 2.1910  Validation loss = 1.7720  \n",
      "\n",
      "Fold: 12  Epoch: 183  Training loss = 2.1906  Validation loss = 1.7712  \n",
      "\n",
      "Fold: 12  Epoch: 184  Training loss = 2.1902  Validation loss = 1.7697  \n",
      "\n",
      "Fold: 12  Epoch: 185  Training loss = 2.1900  Validation loss = 1.7699  \n",
      "\n",
      "Fold: 12  Epoch: 186  Training loss = 2.1898  Validation loss = 1.7701  \n",
      "\n",
      "Fold: 12  Epoch: 187  Training loss = 2.1890  Validation loss = 1.7674  \n",
      "\n",
      "Fold: 12  Epoch: 188  Training loss = 2.1887  Validation loss = 1.7672  \n",
      "\n",
      "Fold: 12  Epoch: 189  Training loss = 2.1881  Validation loss = 1.7660  \n",
      "\n",
      "Fold: 12  Epoch: 190  Training loss = 2.1877  Validation loss = 1.7655  \n",
      "\n",
      "Fold: 12  Epoch: 191  Training loss = 2.1871  Validation loss = 1.7626  \n",
      "\n",
      "Fold: 12  Epoch: 192  Training loss = 2.1866  Validation loss = 1.7600  \n",
      "\n",
      "Fold: 12  Epoch: 193  Training loss = 2.1862  Validation loss = 1.7591  \n",
      "\n",
      "Fold: 12  Epoch: 194  Training loss = 2.1857  Validation loss = 1.7575  \n",
      "\n",
      "Fold: 12  Epoch: 195  Training loss = 2.1854  Validation loss = 1.7577  \n",
      "\n",
      "Fold: 12  Epoch: 196  Training loss = 2.1850  Validation loss = 1.7583  \n",
      "\n",
      "Fold: 12  Epoch: 197  Training loss = 2.1847  Validation loss = 1.7582  \n",
      "\n",
      "Fold: 12  Epoch: 198  Training loss = 2.1843  Validation loss = 1.7578  \n",
      "\n",
      "Fold: 12  Epoch: 199  Training loss = 2.1841  Validation loss = 1.7579  \n",
      "\n",
      "Fold: 12  Epoch: 200  Training loss = 2.1835  Validation loss = 1.7559  \n",
      "\n",
      "Fold: 12  Epoch: 201  Training loss = 2.1832  Validation loss = 1.7541  \n",
      "\n",
      "Fold: 12  Epoch: 202  Training loss = 2.1824  Validation loss = 1.7519  \n",
      "\n",
      "Fold: 12  Epoch: 203  Training loss = 2.1820  Validation loss = 1.7510  \n",
      "\n",
      "Fold: 12  Epoch: 204  Training loss = 2.1818  Validation loss = 1.7506  \n",
      "\n",
      "Fold: 12  Epoch: 205  Training loss = 2.1814  Validation loss = 1.7501  \n",
      "\n",
      "Fold: 12  Epoch: 206  Training loss = 2.1809  Validation loss = 1.7484  \n",
      "\n",
      "Fold: 12  Epoch: 207  Training loss = 2.1807  Validation loss = 1.7486  \n",
      "\n",
      "Fold: 12  Epoch: 208  Training loss = 2.1799  Validation loss = 1.7463  \n",
      "\n",
      "Fold: 12  Epoch: 209  Training loss = 2.1793  Validation loss = 1.7445  \n",
      "\n",
      "Fold: 12  Epoch: 210  Training loss = 2.1791  Validation loss = 1.7454  \n",
      "\n",
      "Fold: 12  Epoch: 211  Training loss = 2.1787  Validation loss = 1.7461  \n",
      "\n",
      "Fold: 12  Epoch: 212  Training loss = 2.1783  Validation loss = 1.7450  \n",
      "\n",
      "Fold: 12  Epoch: 213  Training loss = 2.1779  Validation loss = 1.7451  \n",
      "\n",
      "Fold: 12  Epoch: 214  Training loss = 2.1776  Validation loss = 1.7441  \n",
      "\n",
      "Fold: 12  Epoch: 215  Training loss = 2.1772  Validation loss = 1.7435  \n",
      "\n",
      "Fold: 12  Epoch: 216  Training loss = 2.1770  Validation loss = 1.7454  \n",
      "\n",
      "Fold: 12  Epoch: 217  Training loss = 2.1766  Validation loss = 1.7452  \n",
      "\n",
      "Fold: 12  Epoch: 218  Training loss = 2.1762  Validation loss = 1.7445  \n",
      "\n",
      "Fold: 12  Epoch: 219  Training loss = 2.1758  Validation loss = 1.7417  \n",
      "\n",
      "Fold: 12  Epoch: 220  Training loss = 2.1754  Validation loss = 1.7408  \n",
      "\n",
      "Fold: 12  Epoch: 221  Training loss = 2.1750  Validation loss = 1.7399  \n",
      "\n",
      "Fold: 12  Epoch: 222  Training loss = 2.1747  Validation loss = 1.7404  \n",
      "\n",
      "Fold: 12  Epoch: 223  Training loss = 2.1742  Validation loss = 1.7392  \n",
      "\n",
      "Fold: 12  Epoch: 224  Training loss = 2.1735  Validation loss = 1.7376  \n",
      "\n",
      "Fold: 12  Epoch: 225  Training loss = 2.1732  Validation loss = 1.7378  \n",
      "\n",
      "Fold: 12  Epoch: 226  Training loss = 2.1729  Validation loss = 1.7385  \n",
      "\n",
      "Fold: 12  Epoch: 227  Training loss = 2.1724  Validation loss = 1.7376  \n",
      "\n",
      "Fold: 12  Epoch: 228  Training loss = 2.1721  Validation loss = 1.7367  \n",
      "\n",
      "Fold: 12  Epoch: 229  Training loss = 2.1718  Validation loss = 1.7362  \n",
      "\n",
      "Fold: 12  Epoch: 230  Training loss = 2.1710  Validation loss = 1.7343  \n",
      "\n",
      "Fold: 12  Epoch: 231  Training loss = 2.1706  Validation loss = 1.7357  \n",
      "\n",
      "Fold: 12  Epoch: 232  Training loss = 2.1704  Validation loss = 1.7363  \n",
      "\n",
      "Fold: 12  Epoch: 233  Training loss = 2.1701  Validation loss = 1.7357  \n",
      "\n",
      "Fold: 12  Epoch: 234  Training loss = 2.1696  Validation loss = 1.7343  \n",
      "\n",
      "Fold: 12  Epoch: 235  Training loss = 2.1693  Validation loss = 1.7337  \n",
      "\n",
      "Fold: 12  Epoch: 236  Training loss = 2.1688  Validation loss = 1.7314  \n",
      "\n",
      "Fold: 12  Epoch: 237  Training loss = 2.1686  Validation loss = 1.7333  \n",
      "\n",
      "Fold: 12  Epoch: 238  Training loss = 2.1682  Validation loss = 1.7317  \n",
      "\n",
      "Fold: 12  Epoch: 239  Training loss = 2.1680  Validation loss = 1.7329  \n",
      "\n",
      "Fold: 12  Epoch: 240  Training loss = 2.1678  Validation loss = 1.7339  \n",
      "\n",
      "Fold: 12  Epoch: 241  Training loss = 2.1676  Validation loss = 1.7351  \n",
      "\n",
      "Fold: 12  Epoch: 242  Training loss = 2.1672  Validation loss = 1.7340  \n",
      "\n",
      "Fold: 12  Epoch: 243  Training loss = 2.1667  Validation loss = 1.7343  \n",
      "\n",
      "Fold: 12  Epoch: 244  Training loss = 2.1656  Validation loss = 1.7346  \n",
      "\n",
      "Fold: 12  Epoch: 245  Training loss = 2.1656  Validation loss = 1.7346  \n",
      "\n",
      "Fold: 12  Epoch: 246  Training loss = 2.1653  Validation loss = 1.7338  \n",
      "\n",
      "Fold: 12  Epoch: 247  Training loss = 2.1645  Validation loss = 1.7349  \n",
      "\n",
      "Fold: 12  Epoch: 248  Training loss = 2.1643  Validation loss = 1.7344  \n",
      "\n",
      "Fold: 12  Epoch: 249  Training loss = 2.1642  Validation loss = 1.7342  \n",
      "\n",
      "Fold: 12  Epoch: 250  Training loss = 2.1637  Validation loss = 1.7305  \n",
      "\n",
      "Fold: 12  Epoch: 251  Training loss = 2.1622  Validation loss = 1.7295  \n",
      "\n",
      "Fold: 12  Epoch: 252  Training loss = 2.1619  Validation loss = 1.7302  \n",
      "\n",
      "Fold: 12  Epoch: 253  Training loss = 2.1618  Validation loss = 1.7317  \n",
      "\n",
      "Fold: 12  Epoch: 254  Training loss = 2.1612  Validation loss = 1.7300  \n",
      "\n",
      "Fold: 12  Epoch: 255  Training loss = 2.1608  Validation loss = 1.7284  \n",
      "\n",
      "Fold: 12  Epoch: 256  Training loss = 2.1602  Validation loss = 1.7275  \n",
      "\n",
      "Fold: 12  Epoch: 257  Training loss = 2.1598  Validation loss = 1.7264  \n",
      "\n",
      "Fold: 12  Epoch: 258  Training loss = 2.1594  Validation loss = 1.7263  \n",
      "\n",
      "Fold: 12  Epoch: 259  Training loss = 2.1589  Validation loss = 1.7259  \n",
      "\n",
      "Fold: 12  Epoch: 260  Training loss = 2.1587  Validation loss = 1.7252  \n",
      "\n",
      "Fold: 12  Epoch: 261  Training loss = 2.1584  Validation loss = 1.7253  \n",
      "\n",
      "Fold: 12  Epoch: 262  Training loss = 2.1580  Validation loss = 1.7246  \n",
      "\n",
      "Fold: 12  Epoch: 263  Training loss = 2.1575  Validation loss = 1.7217  \n",
      "\n",
      "Fold: 12  Epoch: 264  Training loss = 2.1571  Validation loss = 1.7230  \n",
      "\n",
      "Fold: 12  Epoch: 265  Training loss = 2.1565  Validation loss = 1.7200  \n",
      "\n",
      "Fold: 12  Epoch: 266  Training loss = 2.1563  Validation loss = 1.7199  \n",
      "\n",
      "Fold: 12  Epoch: 267  Training loss = 2.1558  Validation loss = 1.7192  \n",
      "\n",
      "Fold: 12  Epoch: 268  Training loss = 2.1554  Validation loss = 1.7187  \n",
      "\n",
      "Fold: 12  Epoch: 269  Training loss = 2.1550  Validation loss = 1.7177  \n",
      "\n",
      "Fold: 12  Epoch: 270  Training loss = 2.1548  Validation loss = 1.7169  \n",
      "\n",
      "Fold: 12  Epoch: 271  Training loss = 2.1545  Validation loss = 1.7183  \n",
      "\n",
      "Fold: 12  Epoch: 272  Training loss = 2.1538  Validation loss = 1.7172  \n",
      "\n",
      "Fold: 12  Epoch: 273  Training loss = 2.1531  Validation loss = 1.7152  \n",
      "\n",
      "Fold: 12  Epoch: 274  Training loss = 2.1526  Validation loss = 1.7128  \n",
      "\n",
      "Fold: 12  Epoch: 275  Training loss = 2.1522  Validation loss = 1.7141  \n",
      "\n",
      "Fold: 12  Epoch: 276  Training loss = 2.1515  Validation loss = 1.7134  \n",
      "\n",
      "Fold: 12  Epoch: 277  Training loss = 2.1512  Validation loss = 1.7125  \n",
      "\n",
      "Fold: 12  Epoch: 278  Training loss = 2.1508  Validation loss = 1.7138  \n",
      "\n",
      "Fold: 12  Epoch: 279  Training loss = 2.1504  Validation loss = 1.7142  \n",
      "\n",
      "Fold: 12  Epoch: 280  Training loss = 2.1499  Validation loss = 1.7125  \n",
      "\n",
      "Fold: 12  Epoch: 281  Training loss = 2.1495  Validation loss = 1.7129  \n",
      "\n",
      "Fold: 12  Epoch: 282  Training loss = 2.1488  Validation loss = 1.7099  \n",
      "\n",
      "Fold: 12  Epoch: 283  Training loss = 2.1484  Validation loss = 1.7111  \n",
      "\n",
      "Fold: 12  Epoch: 284  Training loss = 2.1479  Validation loss = 1.7102  \n",
      "\n",
      "Fold: 12  Epoch: 285  Training loss = 2.1477  Validation loss = 1.7130  \n",
      "\n",
      "Fold: 12  Epoch: 286  Training loss = 2.1474  Validation loss = 1.7137  \n",
      "\n",
      "Fold: 12  Epoch: 287  Training loss = 2.1467  Validation loss = 1.7106  \n",
      "\n",
      "Fold: 12  Epoch: 288  Training loss = 2.1464  Validation loss = 1.7120  \n",
      "\n",
      "Fold: 12  Epoch: 289  Training loss = 2.1458  Validation loss = 1.7128  \n",
      "\n",
      "Fold: 12  Epoch: 290  Training loss = 2.1453  Validation loss = 1.7114  \n",
      "\n",
      "Fold: 12  Epoch: 291  Training loss = 2.1450  Validation loss = 1.7096  \n",
      "\n",
      "Fold: 12  Epoch: 292  Training loss = 2.1444  Validation loss = 1.7080  \n",
      "\n",
      "Fold: 12  Epoch: 293  Training loss = 2.1440  Validation loss = 1.7085  \n",
      "\n",
      "Fold: 12  Epoch: 294  Training loss = 2.1436  Validation loss = 1.7098  \n",
      "\n",
      "Fold: 12  Epoch: 295  Training loss = 2.1434  Validation loss = 1.7121  \n",
      "\n",
      "Fold: 12  Epoch: 296  Training loss = 2.1430  Validation loss = 1.7115  \n",
      "\n",
      "Fold: 12  Epoch: 297  Training loss = 2.1424  Validation loss = 1.7102  \n",
      "\n",
      "Fold: 12  Epoch: 298  Training loss = 2.1421  Validation loss = 1.7121  \n",
      "\n",
      "Fold: 12  Epoch: 299  Training loss = 2.1416  Validation loss = 1.7118  \n",
      "\n",
      "Fold: 12  Epoch: 300  Training loss = 2.1414  Validation loss = 1.7131  \n",
      "\n",
      "Check model:  Fold: 12  Optimal epoch: 292  \n",
      "\n",
      "Fold: 13  Epoch: 1  Training loss = 2.1597  Validation loss = 3.2557  \n",
      "\n",
      "Fold: 13  Epoch: 2  Training loss = 2.1594  Validation loss = 3.2546  \n",
      "\n",
      "Fold: 13  Epoch: 3  Training loss = 2.1590  Validation loss = 3.2542  \n",
      "\n",
      "Fold: 13  Epoch: 4  Training loss = 2.1584  Validation loss = 3.2527  \n",
      "\n",
      "Fold: 13  Epoch: 5  Training loss = 2.1574  Validation loss = 3.2493  \n",
      "\n",
      "Fold: 13  Epoch: 6  Training loss = 2.1570  Validation loss = 3.2488  \n",
      "\n",
      "Fold: 13  Epoch: 7  Training loss = 2.1564  Validation loss = 3.2473  \n",
      "\n",
      "Fold: 13  Epoch: 8  Training loss = 2.1558  Validation loss = 3.2453  \n",
      "\n",
      "Fold: 13  Epoch: 9  Training loss = 2.1554  Validation loss = 3.2435  \n",
      "\n",
      "Fold: 13  Epoch: 10  Training loss = 2.1551  Validation loss = 3.2423  \n",
      "\n",
      "Fold: 13  Epoch: 11  Training loss = 2.1541  Validation loss = 3.2387  \n",
      "\n",
      "Fold: 13  Epoch: 12  Training loss = 2.1533  Validation loss = 3.2363  \n",
      "\n",
      "Fold: 13  Epoch: 13  Training loss = 2.1527  Validation loss = 3.2346  \n",
      "\n",
      "Fold: 13  Epoch: 14  Training loss = 2.1520  Validation loss = 3.2323  \n",
      "\n",
      "Fold: 13  Epoch: 15  Training loss = 2.1515  Validation loss = 3.2311  \n",
      "\n",
      "Fold: 13  Epoch: 16  Training loss = 2.1506  Validation loss = 3.2287  \n",
      "\n",
      "Fold: 13  Epoch: 17  Training loss = 2.1498  Validation loss = 3.2268  \n",
      "\n",
      "Fold: 13  Epoch: 18  Training loss = 2.1494  Validation loss = 3.2256  \n",
      "\n",
      "Fold: 13  Epoch: 19  Training loss = 2.1489  Validation loss = 3.2252  \n",
      "\n",
      "Fold: 13  Epoch: 20  Training loss = 2.1484  Validation loss = 3.2238  \n",
      "\n",
      "Fold: 13  Epoch: 21  Training loss = 2.1477  Validation loss = 3.2209  \n",
      "\n",
      "Fold: 13  Epoch: 22  Training loss = 2.1472  Validation loss = 3.2186  \n",
      "\n",
      "Fold: 13  Epoch: 23  Training loss = 2.1464  Validation loss = 3.2157  \n",
      "\n",
      "Fold: 13  Epoch: 24  Training loss = 2.1459  Validation loss = 3.2147  \n",
      "\n",
      "Fold: 13  Epoch: 25  Training loss = 2.1451  Validation loss = 3.2128  \n",
      "\n",
      "Fold: 13  Epoch: 26  Training loss = 2.1444  Validation loss = 3.2101  \n",
      "\n",
      "Fold: 13  Epoch: 27  Training loss = 2.1440  Validation loss = 3.2099  \n",
      "\n",
      "Fold: 13  Epoch: 28  Training loss = 2.1433  Validation loss = 3.2076  \n",
      "\n",
      "Fold: 13  Epoch: 29  Training loss = 2.1428  Validation loss = 3.2062  \n",
      "\n",
      "Fold: 13  Epoch: 30  Training loss = 2.1423  Validation loss = 3.2041  \n",
      "\n",
      "Fold: 13  Epoch: 31  Training loss = 2.1418  Validation loss = 3.2031  \n",
      "\n",
      "Fold: 13  Epoch: 32  Training loss = 2.1413  Validation loss = 3.2014  \n",
      "\n",
      "Fold: 13  Epoch: 33  Training loss = 2.1408  Validation loss = 3.2008  \n",
      "\n",
      "Fold: 13  Epoch: 34  Training loss = 2.1402  Validation loss = 3.1984  \n",
      "\n",
      "Fold: 13  Epoch: 35  Training loss = 2.1396  Validation loss = 3.1966  \n",
      "\n",
      "Fold: 13  Epoch: 36  Training loss = 2.1390  Validation loss = 3.1942  \n",
      "\n",
      "Fold: 13  Epoch: 37  Training loss = 2.1387  Validation loss = 3.1929  \n",
      "\n",
      "Fold: 13  Epoch: 38  Training loss = 2.1382  Validation loss = 3.1912  \n",
      "\n",
      "Fold: 13  Epoch: 39  Training loss = 2.1375  Validation loss = 3.1894  \n",
      "\n",
      "Fold: 13  Epoch: 40  Training loss = 2.1368  Validation loss = 3.1864  \n",
      "\n",
      "Fold: 13  Epoch: 41  Training loss = 2.1360  Validation loss = 3.1835  \n",
      "\n",
      "Fold: 13  Epoch: 42  Training loss = 2.1354  Validation loss = 3.1807  \n",
      "\n",
      "Fold: 13  Epoch: 43  Training loss = 2.1348  Validation loss = 3.1796  \n",
      "\n",
      "Fold: 13  Epoch: 44  Training loss = 2.1343  Validation loss = 3.1784  \n",
      "\n",
      "Fold: 13  Epoch: 45  Training loss = 2.1339  Validation loss = 3.1764  \n",
      "\n",
      "Fold: 13  Epoch: 46  Training loss = 2.1334  Validation loss = 3.1743  \n",
      "\n",
      "Fold: 13  Epoch: 47  Training loss = 2.1328  Validation loss = 3.1718  \n",
      "\n",
      "Fold: 13  Epoch: 48  Training loss = 2.1325  Validation loss = 3.1722  \n",
      "\n",
      "Fold: 13  Epoch: 49  Training loss = 2.1322  Validation loss = 3.1715  \n",
      "\n",
      "Fold: 13  Epoch: 50  Training loss = 2.1316  Validation loss = 3.1702  \n",
      "\n",
      "Fold: 13  Epoch: 51  Training loss = 2.1313  Validation loss = 3.1696  \n",
      "\n",
      "Fold: 13  Epoch: 52  Training loss = 2.1311  Validation loss = 3.1696  \n",
      "\n",
      "Fold: 13  Epoch: 53  Training loss = 2.1307  Validation loss = 3.1679  \n",
      "\n",
      "Fold: 13  Epoch: 54  Training loss = 2.1301  Validation loss = 3.1654  \n",
      "\n",
      "Fold: 13  Epoch: 55  Training loss = 2.1296  Validation loss = 3.1638  \n",
      "\n",
      "Fold: 13  Epoch: 56  Training loss = 2.1289  Validation loss = 3.1622  \n",
      "\n",
      "Fold: 13  Epoch: 57  Training loss = 2.1283  Validation loss = 3.1605  \n",
      "\n",
      "Fold: 13  Epoch: 58  Training loss = 2.1278  Validation loss = 3.1588  \n",
      "\n",
      "Fold: 13  Epoch: 59  Training loss = 2.1275  Validation loss = 3.1586  \n",
      "\n",
      "Fold: 13  Epoch: 60  Training loss = 2.1271  Validation loss = 3.1584  \n",
      "\n",
      "Fold: 13  Epoch: 61  Training loss = 2.1269  Validation loss = 3.1575  \n",
      "\n",
      "Fold: 13  Epoch: 62  Training loss = 2.1260  Validation loss = 3.1543  \n",
      "\n",
      "Fold: 13  Epoch: 63  Training loss = 2.1257  Validation loss = 3.1542  \n",
      "\n",
      "Fold: 13  Epoch: 64  Training loss = 2.1253  Validation loss = 3.1523  \n",
      "\n",
      "Fold: 13  Epoch: 65  Training loss = 2.1246  Validation loss = 3.1504  \n",
      "\n",
      "Fold: 13  Epoch: 66  Training loss = 2.1241  Validation loss = 3.1480  \n",
      "\n",
      "Fold: 13  Epoch: 67  Training loss = 2.1236  Validation loss = 3.1471  \n",
      "\n",
      "Fold: 13  Epoch: 68  Training loss = 2.1233  Validation loss = 3.1460  \n",
      "\n",
      "Fold: 13  Epoch: 69  Training loss = 2.1230  Validation loss = 3.1468  \n",
      "\n",
      "Fold: 13  Epoch: 70  Training loss = 2.1226  Validation loss = 3.1455  \n",
      "\n",
      "Fold: 13  Epoch: 71  Training loss = 2.1220  Validation loss = 3.1426  \n",
      "\n",
      "Fold: 13  Epoch: 72  Training loss = 2.1214  Validation loss = 3.1420  \n",
      "\n",
      "Fold: 13  Epoch: 73  Training loss = 2.1209  Validation loss = 3.1417  \n",
      "\n",
      "Fold: 13  Epoch: 74  Training loss = 2.1200  Validation loss = 3.1385  \n",
      "\n",
      "Fold: 13  Epoch: 75  Training loss = 2.1197  Validation loss = 3.1384  \n",
      "\n",
      "Fold: 13  Epoch: 76  Training loss = 2.1194  Validation loss = 3.1375  \n",
      "\n",
      "Fold: 13  Epoch: 77  Training loss = 2.1187  Validation loss = 3.1352  \n",
      "\n",
      "Fold: 13  Epoch: 78  Training loss = 2.1182  Validation loss = 3.1331  \n",
      "\n",
      "Fold: 13  Epoch: 79  Training loss = 2.1178  Validation loss = 3.1327  \n",
      "\n",
      "Fold: 13  Epoch: 80  Training loss = 2.1171  Validation loss = 3.1295  \n",
      "\n",
      "Fold: 13  Epoch: 81  Training loss = 2.1167  Validation loss = 3.1281  \n",
      "\n",
      "Fold: 13  Epoch: 82  Training loss = 2.1162  Validation loss = 3.1265  \n",
      "\n",
      "Fold: 13  Epoch: 83  Training loss = 2.1157  Validation loss = 3.1253  \n",
      "\n",
      "Fold: 13  Epoch: 84  Training loss = 2.1152  Validation loss = 3.1230  \n",
      "\n",
      "Fold: 13  Epoch: 85  Training loss = 2.1148  Validation loss = 3.1231  \n",
      "\n",
      "Fold: 13  Epoch: 86  Training loss = 2.1142  Validation loss = 3.1204  \n",
      "\n",
      "Fold: 13  Epoch: 87  Training loss = 2.1136  Validation loss = 3.1187  \n",
      "\n",
      "Fold: 13  Epoch: 88  Training loss = 2.1131  Validation loss = 3.1161  \n",
      "\n",
      "Fold: 13  Epoch: 89  Training loss = 2.1126  Validation loss = 3.1139  \n",
      "\n",
      "Fold: 13  Epoch: 90  Training loss = 2.1122  Validation loss = 3.1137  \n",
      "\n",
      "Fold: 13  Epoch: 91  Training loss = 2.1120  Validation loss = 3.1130  \n",
      "\n",
      "Fold: 13  Epoch: 92  Training loss = 2.1116  Validation loss = 3.1114  \n",
      "\n",
      "Fold: 13  Epoch: 93  Training loss = 2.1108  Validation loss = 3.1082  \n",
      "\n",
      "Fold: 13  Epoch: 94  Training loss = 2.1103  Validation loss = 3.1064  \n",
      "\n",
      "Fold: 13  Epoch: 95  Training loss = 2.1100  Validation loss = 3.1059  \n",
      "\n",
      "Fold: 13  Epoch: 96  Training loss = 2.1097  Validation loss = 3.1052  \n",
      "\n",
      "Fold: 13  Epoch: 97  Training loss = 2.1089  Validation loss = 3.1014  \n",
      "\n",
      "Fold: 13  Epoch: 98  Training loss = 2.1082  Validation loss = 3.0982  \n",
      "\n",
      "Fold: 13  Epoch: 99  Training loss = 2.1079  Validation loss = 3.0964  \n",
      "\n",
      "Fold: 13  Epoch: 100  Training loss = 2.1075  Validation loss = 3.0948  \n",
      "\n",
      "Fold: 13  Epoch: 101  Training loss = 2.1070  Validation loss = 3.0932  \n",
      "\n",
      "Fold: 13  Epoch: 102  Training loss = 2.1068  Validation loss = 3.0927  \n",
      "\n",
      "Fold: 13  Epoch: 103  Training loss = 2.1065  Validation loss = 3.0908  \n",
      "\n",
      "Fold: 13  Epoch: 104  Training loss = 2.1060  Validation loss = 3.0896  \n",
      "\n",
      "Fold: 13  Epoch: 105  Training loss = 2.1054  Validation loss = 3.0879  \n",
      "\n",
      "Fold: 13  Epoch: 106  Training loss = 2.1046  Validation loss = 3.0854  \n",
      "\n",
      "Fold: 13  Epoch: 107  Training loss = 2.1044  Validation loss = 3.0850  \n",
      "\n",
      "Fold: 13  Epoch: 108  Training loss = 2.1038  Validation loss = 3.0815  \n",
      "\n",
      "Fold: 13  Epoch: 109  Training loss = 2.1036  Validation loss = 3.0816  \n",
      "\n",
      "Fold: 13  Epoch: 110  Training loss = 2.1029  Validation loss = 3.0790  \n",
      "\n",
      "Fold: 13  Epoch: 111  Training loss = 2.1026  Validation loss = 3.0780  \n",
      "\n",
      "Fold: 13  Epoch: 112  Training loss = 2.1020  Validation loss = 3.0754  \n",
      "\n",
      "Fold: 13  Epoch: 113  Training loss = 2.1019  Validation loss = 3.0757  \n",
      "\n",
      "Fold: 13  Epoch: 114  Training loss = 2.1012  Validation loss = 3.0728  \n",
      "\n",
      "Fold: 13  Epoch: 115  Training loss = 2.1009  Validation loss = 3.0724  \n",
      "\n",
      "Fold: 13  Epoch: 116  Training loss = 2.1005  Validation loss = 3.0704  \n",
      "\n",
      "Fold: 13  Epoch: 117  Training loss = 2.1002  Validation loss = 3.0697  \n",
      "\n",
      "Fold: 13  Epoch: 118  Training loss = 2.1001  Validation loss = 3.0701  \n",
      "\n",
      "Fold: 13  Epoch: 119  Training loss = 2.1000  Validation loss = 3.0706  \n",
      "\n",
      "Fold: 13  Epoch: 120  Training loss = 2.0995  Validation loss = 3.0691  \n",
      "\n",
      "Fold: 13  Epoch: 121  Training loss = 2.0989  Validation loss = 3.0668  \n",
      "\n",
      "Fold: 13  Epoch: 122  Training loss = 2.0986  Validation loss = 3.0656  \n",
      "\n",
      "Fold: 13  Epoch: 123  Training loss = 2.0982  Validation loss = 3.0648  \n",
      "\n",
      "Fold: 13  Epoch: 124  Training loss = 2.0976  Validation loss = 3.0628  \n",
      "\n",
      "Fold: 13  Epoch: 125  Training loss = 2.0971  Validation loss = 3.0604  \n",
      "\n",
      "Fold: 13  Epoch: 126  Training loss = 2.0965  Validation loss = 3.0586  \n",
      "\n",
      "Fold: 13  Epoch: 127  Training loss = 2.0959  Validation loss = 3.0567  \n",
      "\n",
      "Fold: 13  Epoch: 128  Training loss = 2.0952  Validation loss = 3.0543  \n",
      "\n",
      "Fold: 13  Epoch: 129  Training loss = 2.0952  Validation loss = 3.0563  \n",
      "\n",
      "Fold: 13  Epoch: 130  Training loss = 2.0951  Validation loss = 3.0563  \n",
      "\n",
      "Fold: 13  Epoch: 131  Training loss = 2.0950  Validation loss = 3.0557  \n",
      "\n",
      "Fold: 13  Epoch: 132  Training loss = 2.0942  Validation loss = 3.0523  \n",
      "\n",
      "Fold: 13  Epoch: 133  Training loss = 2.0937  Validation loss = 3.0505  \n",
      "\n",
      "Fold: 13  Epoch: 134  Training loss = 2.0934  Validation loss = 3.0489  \n",
      "\n",
      "Fold: 13  Epoch: 135  Training loss = 2.0926  Validation loss = 3.0453  \n",
      "\n",
      "Fold: 13  Epoch: 136  Training loss = 2.0925  Validation loss = 3.0463  \n",
      "\n",
      "Fold: 13  Epoch: 137  Training loss = 2.0921  Validation loss = 3.0447  \n",
      "\n",
      "Fold: 13  Epoch: 138  Training loss = 2.0920  Validation loss = 3.0449  \n",
      "\n",
      "Fold: 13  Epoch: 139  Training loss = 2.0911  Validation loss = 3.0422  \n",
      "\n",
      "Fold: 13  Epoch: 140  Training loss = 2.0906  Validation loss = 3.0419  \n",
      "\n",
      "Fold: 13  Epoch: 141  Training loss = 2.0903  Validation loss = 3.0405  \n",
      "\n",
      "Fold: 13  Epoch: 142  Training loss = 2.0900  Validation loss = 3.0388  \n",
      "\n",
      "Fold: 13  Epoch: 143  Training loss = 2.0896  Validation loss = 3.0378  \n",
      "\n",
      "Fold: 13  Epoch: 144  Training loss = 2.0894  Validation loss = 3.0373  \n",
      "\n",
      "Fold: 13  Epoch: 145  Training loss = 2.0893  Validation loss = 3.0357  \n",
      "\n",
      "Fold: 13  Epoch: 146  Training loss = 2.0887  Validation loss = 3.0328  \n",
      "\n",
      "Fold: 13  Epoch: 147  Training loss = 2.0883  Validation loss = 3.0306  \n",
      "\n",
      "Fold: 13  Epoch: 148  Training loss = 2.0879  Validation loss = 3.0292  \n",
      "\n",
      "Fold: 13  Epoch: 149  Training loss = 2.0873  Validation loss = 3.0272  \n",
      "\n",
      "Fold: 13  Epoch: 150  Training loss = 2.0871  Validation loss = 3.0269  \n",
      "\n",
      "Fold: 13  Epoch: 151  Training loss = 2.0869  Validation loss = 3.0264  \n",
      "\n",
      "Fold: 13  Epoch: 152  Training loss = 2.0865  Validation loss = 3.0250  \n",
      "\n",
      "Fold: 13  Epoch: 153  Training loss = 2.0864  Validation loss = 3.0244  \n",
      "\n",
      "Fold: 13  Epoch: 154  Training loss = 2.0858  Validation loss = 3.0221  \n",
      "\n",
      "Fold: 13  Epoch: 155  Training loss = 2.0849  Validation loss = 3.0187  \n",
      "\n",
      "Fold: 13  Epoch: 156  Training loss = 2.0847  Validation loss = 3.0191  \n",
      "\n",
      "Fold: 13  Epoch: 157  Training loss = 2.0841  Validation loss = 3.0174  \n",
      "\n",
      "Fold: 13  Epoch: 158  Training loss = 2.0839  Validation loss = 3.0155  \n",
      "\n",
      "Fold: 13  Epoch: 159  Training loss = 2.0836  Validation loss = 3.0140  \n",
      "\n",
      "Fold: 13  Epoch: 160  Training loss = 2.0834  Validation loss = 3.0131  \n",
      "\n",
      "Fold: 13  Epoch: 161  Training loss = 2.0831  Validation loss = 3.0120  \n",
      "\n",
      "Fold: 13  Epoch: 162  Training loss = 2.0827  Validation loss = 3.0119  \n",
      "\n",
      "Fold: 13  Epoch: 163  Training loss = 2.0826  Validation loss = 3.0107  \n",
      "\n",
      "Fold: 13  Epoch: 164  Training loss = 2.0825  Validation loss = 3.0087  \n",
      "\n",
      "Fold: 13  Epoch: 165  Training loss = 2.0823  Validation loss = 3.0081  \n",
      "\n",
      "Fold: 13  Epoch: 166  Training loss = 2.0820  Validation loss = 3.0072  \n",
      "\n",
      "Fold: 13  Epoch: 167  Training loss = 2.0816  Validation loss = 3.0059  \n",
      "\n",
      "Fold: 13  Epoch: 168  Training loss = 2.0813  Validation loss = 3.0045  \n",
      "\n",
      "Fold: 13  Epoch: 169  Training loss = 2.0811  Validation loss = 3.0046  \n",
      "\n",
      "Fold: 13  Epoch: 170  Training loss = 2.0809  Validation loss = 3.0050  \n",
      "\n",
      "Fold: 13  Epoch: 171  Training loss = 2.0803  Validation loss = 3.0055  \n",
      "\n",
      "Fold: 13  Epoch: 172  Training loss = 2.0800  Validation loss = 3.0056  \n",
      "\n",
      "Fold: 13  Epoch: 173  Training loss = 2.0794  Validation loss = 3.0027  \n",
      "\n",
      "Fold: 13  Epoch: 174  Training loss = 2.0790  Validation loss = 3.0023  \n",
      "\n",
      "Fold: 13  Epoch: 175  Training loss = 2.0787  Validation loss = 3.0004  \n",
      "\n",
      "Fold: 13  Epoch: 176  Training loss = 2.0781  Validation loss = 2.9977  \n",
      "\n",
      "Fold: 13  Epoch: 177  Training loss = 2.0775  Validation loss = 2.9951  \n",
      "\n",
      "Fold: 13  Epoch: 178  Training loss = 2.0770  Validation loss = 2.9932  \n",
      "\n",
      "Fold: 13  Epoch: 179  Training loss = 2.0766  Validation loss = 2.9925  \n",
      "\n",
      "Fold: 13  Epoch: 180  Training loss = 2.0763  Validation loss = 2.9915  \n",
      "\n",
      "Fold: 13  Epoch: 181  Training loss = 2.0760  Validation loss = 2.9904  \n",
      "\n",
      "Fold: 13  Epoch: 182  Training loss = 2.0760  Validation loss = 2.9908  \n",
      "\n",
      "Fold: 13  Epoch: 183  Training loss = 2.0759  Validation loss = 2.9912  \n",
      "\n",
      "Fold: 13  Epoch: 184  Training loss = 2.0755  Validation loss = 2.9901  \n",
      "\n",
      "Fold: 13  Epoch: 185  Training loss = 2.0750  Validation loss = 2.9881  \n",
      "\n",
      "Fold: 13  Epoch: 186  Training loss = 2.0744  Validation loss = 2.9844  \n",
      "\n",
      "Fold: 13  Epoch: 187  Training loss = 2.0740  Validation loss = 2.9841  \n",
      "\n",
      "Fold: 13  Epoch: 188  Training loss = 2.0736  Validation loss = 2.9830  \n",
      "\n",
      "Fold: 13  Epoch: 189  Training loss = 2.0732  Validation loss = 2.9826  \n",
      "\n",
      "Fold: 13  Epoch: 190  Training loss = 2.0732  Validation loss = 2.9822  \n",
      "\n",
      "Fold: 13  Epoch: 191  Training loss = 2.0727  Validation loss = 2.9808  \n",
      "\n",
      "Fold: 13  Epoch: 192  Training loss = 2.0724  Validation loss = 2.9810  \n",
      "\n",
      "Fold: 13  Epoch: 193  Training loss = 2.0720  Validation loss = 2.9800  \n",
      "\n",
      "Fold: 13  Epoch: 194  Training loss = 2.0718  Validation loss = 2.9800  \n",
      "\n",
      "Fold: 13  Epoch: 195  Training loss = 2.0716  Validation loss = 2.9797  \n",
      "\n",
      "Fold: 13  Epoch: 196  Training loss = 2.0715  Validation loss = 2.9809  \n",
      "\n",
      "Fold: 13  Epoch: 197  Training loss = 2.0711  Validation loss = 2.9796  \n",
      "\n",
      "Fold: 13  Epoch: 198  Training loss = 2.0706  Validation loss = 2.9780  \n",
      "\n",
      "Fold: 13  Epoch: 199  Training loss = 2.0700  Validation loss = 2.9765  \n",
      "\n",
      "Fold: 13  Epoch: 200  Training loss = 2.0697  Validation loss = 2.9754  \n",
      "\n",
      "Fold: 13  Epoch: 201  Training loss = 2.0692  Validation loss = 2.9740  \n",
      "\n",
      "Fold: 13  Epoch: 202  Training loss = 2.0687  Validation loss = 2.9714  \n",
      "\n",
      "Fold: 13  Epoch: 203  Training loss = 2.0685  Validation loss = 2.9706  \n",
      "\n",
      "Fold: 13  Epoch: 204  Training loss = 2.0684  Validation loss = 2.9701  \n",
      "\n",
      "Fold: 13  Epoch: 205  Training loss = 2.0677  Validation loss = 2.9672  \n",
      "\n",
      "Fold: 13  Epoch: 206  Training loss = 2.0675  Validation loss = 2.9664  \n",
      "\n",
      "Fold: 13  Epoch: 207  Training loss = 2.0674  Validation loss = 2.9659  \n",
      "\n",
      "Fold: 13  Epoch: 208  Training loss = 2.0673  Validation loss = 2.9656  \n",
      "\n",
      "Fold: 13  Epoch: 209  Training loss = 2.0671  Validation loss = 2.9617  \n",
      "\n",
      "Fold: 13  Epoch: 210  Training loss = 2.0669  Validation loss = 2.9605  \n",
      "\n",
      "Fold: 13  Epoch: 211  Training loss = 2.0667  Validation loss = 2.9601  \n",
      "\n",
      "Fold: 13  Epoch: 212  Training loss = 2.0662  Validation loss = 2.9564  \n",
      "\n",
      "Fold: 13  Epoch: 213  Training loss = 2.0662  Validation loss = 2.9545  \n",
      "\n",
      "Fold: 13  Epoch: 214  Training loss = 2.0658  Validation loss = 2.9533  \n",
      "\n",
      "Fold: 13  Epoch: 215  Training loss = 2.0655  Validation loss = 2.9507  \n",
      "\n",
      "Fold: 13  Epoch: 216  Training loss = 2.0649  Validation loss = 2.9493  \n",
      "\n",
      "Fold: 13  Epoch: 217  Training loss = 2.0647  Validation loss = 2.9493  \n",
      "\n",
      "Fold: 13  Epoch: 218  Training loss = 2.0645  Validation loss = 2.9489  \n",
      "\n",
      "Fold: 13  Epoch: 219  Training loss = 2.0643  Validation loss = 2.9491  \n",
      "\n",
      "Fold: 13  Epoch: 220  Training loss = 2.0642  Validation loss = 2.9498  \n",
      "\n",
      "Fold: 13  Epoch: 221  Training loss = 2.0637  Validation loss = 2.9501  \n",
      "\n",
      "Fold: 13  Epoch: 222  Training loss = 2.0636  Validation loss = 2.9500  \n",
      "\n",
      "Fold: 13  Epoch: 223  Training loss = 2.0633  Validation loss = 2.9482  \n",
      "\n",
      "Fold: 13  Epoch: 224  Training loss = 2.0631  Validation loss = 2.9488  \n",
      "\n",
      "Fold: 13  Epoch: 225  Training loss = 2.0626  Validation loss = 2.9479  \n",
      "\n",
      "Fold: 13  Epoch: 226  Training loss = 2.0624  Validation loss = 2.9457  \n",
      "\n",
      "Fold: 13  Epoch: 227  Training loss = 2.0622  Validation loss = 2.9435  \n",
      "\n",
      "Fold: 13  Epoch: 228  Training loss = 2.0617  Validation loss = 2.9409  \n",
      "\n",
      "Fold: 13  Epoch: 229  Training loss = 2.0615  Validation loss = 2.9419  \n",
      "\n",
      "Fold: 13  Epoch: 230  Training loss = 2.0613  Validation loss = 2.9413  \n",
      "\n",
      "Fold: 13  Epoch: 231  Training loss = 2.0609  Validation loss = 2.9391  \n",
      "\n",
      "Fold: 13  Epoch: 232  Training loss = 2.0607  Validation loss = 2.9374  \n",
      "\n",
      "Fold: 13  Epoch: 233  Training loss = 2.0604  Validation loss = 2.9366  \n",
      "\n",
      "Fold: 13  Epoch: 234  Training loss = 2.0598  Validation loss = 2.9356  \n",
      "\n",
      "Fold: 13  Epoch: 235  Training loss = 2.0595  Validation loss = 2.9353  \n",
      "\n",
      "Fold: 13  Epoch: 236  Training loss = 2.0596  Validation loss = 2.9333  \n",
      "\n",
      "Fold: 13  Epoch: 237  Training loss = 2.0593  Validation loss = 2.9351  \n",
      "\n",
      "Fold: 13  Epoch: 238  Training loss = 2.0591  Validation loss = 2.9335  \n",
      "\n",
      "Fold: 13  Epoch: 239  Training loss = 2.0589  Validation loss = 2.9327  \n",
      "\n",
      "Fold: 13  Epoch: 240  Training loss = 2.0585  Validation loss = 2.9333  \n",
      "\n",
      "Fold: 13  Epoch: 241  Training loss = 2.0582  Validation loss = 2.9319  \n",
      "\n",
      "Fold: 13  Epoch: 242  Training loss = 2.0579  Validation loss = 2.9300  \n",
      "\n",
      "Fold: 13  Epoch: 243  Training loss = 2.0576  Validation loss = 2.9297  \n",
      "\n",
      "Fold: 13  Epoch: 244  Training loss = 2.0572  Validation loss = 2.9283  \n",
      "\n",
      "Fold: 13  Epoch: 245  Training loss = 2.0570  Validation loss = 2.9259  \n",
      "\n",
      "Fold: 13  Epoch: 246  Training loss = 2.0568  Validation loss = 2.9229  \n",
      "\n",
      "Fold: 13  Epoch: 247  Training loss = 2.0562  Validation loss = 2.9215  \n",
      "\n",
      "Fold: 13  Epoch: 248  Training loss = 2.0559  Validation loss = 2.9224  \n",
      "\n",
      "Fold: 13  Epoch: 249  Training loss = 2.0556  Validation loss = 2.9217  \n",
      "\n",
      "Fold: 13  Epoch: 250  Training loss = 2.0554  Validation loss = 2.9228  \n",
      "\n",
      "Fold: 13  Epoch: 251  Training loss = 2.0551  Validation loss = 2.9210  \n",
      "\n",
      "Fold: 13  Epoch: 252  Training loss = 2.0548  Validation loss = 2.9208  \n",
      "\n",
      "Fold: 13  Epoch: 253  Training loss = 2.0545  Validation loss = 2.9206  \n",
      "\n",
      "Fold: 13  Epoch: 254  Training loss = 2.0540  Validation loss = 2.9180  \n",
      "\n",
      "Fold: 13  Epoch: 255  Training loss = 2.0539  Validation loss = 2.9174  \n",
      "\n",
      "Fold: 13  Epoch: 256  Training loss = 2.0539  Validation loss = 2.9190  \n",
      "\n",
      "Fold: 13  Epoch: 257  Training loss = 2.0539  Validation loss = 2.9195  \n",
      "\n",
      "Fold: 13  Epoch: 258  Training loss = 2.0534  Validation loss = 2.9182  \n",
      "\n",
      "Fold: 13  Epoch: 259  Training loss = 2.0530  Validation loss = 2.9184  \n",
      "\n",
      "Fold: 13  Epoch: 260  Training loss = 2.0521  Validation loss = 2.9147  \n",
      "\n",
      "Fold: 13  Epoch: 261  Training loss = 2.0516  Validation loss = 2.9134  \n",
      "\n",
      "Fold: 13  Epoch: 262  Training loss = 2.0514  Validation loss = 2.9118  \n",
      "\n",
      "Fold: 13  Epoch: 263  Training loss = 2.0511  Validation loss = 2.9107  \n",
      "\n",
      "Fold: 13  Epoch: 264  Training loss = 2.0510  Validation loss = 2.9082  \n",
      "\n",
      "Fold: 13  Epoch: 265  Training loss = 2.0507  Validation loss = 2.9074  \n",
      "\n",
      "Fold: 13  Epoch: 266  Training loss = 2.0504  Validation loss = 2.9053  \n",
      "\n",
      "Fold: 13  Epoch: 267  Training loss = 2.0502  Validation loss = 2.9054  \n",
      "\n",
      "Fold: 13  Epoch: 268  Training loss = 2.0502  Validation loss = 2.9039  \n",
      "\n",
      "Fold: 13  Epoch: 269  Training loss = 2.0500  Validation loss = 2.9053  \n",
      "\n",
      "Fold: 13  Epoch: 270  Training loss = 2.0498  Validation loss = 2.9049  \n",
      "\n",
      "Fold: 13  Epoch: 271  Training loss = 2.0494  Validation loss = 2.9056  \n",
      "\n",
      "Fold: 13  Epoch: 272  Training loss = 2.0490  Validation loss = 2.9048  \n",
      "\n",
      "Fold: 13  Epoch: 273  Training loss = 2.0485  Validation loss = 2.9026  \n",
      "\n",
      "Fold: 13  Epoch: 274  Training loss = 2.0482  Validation loss = 2.9025  \n",
      "\n",
      "Fold: 13  Epoch: 275  Training loss = 2.0482  Validation loss = 2.9029  \n",
      "\n",
      "Fold: 13  Epoch: 276  Training loss = 2.0481  Validation loss = 2.9028  \n",
      "\n",
      "Fold: 13  Epoch: 277  Training loss = 2.0477  Validation loss = 2.9013  \n",
      "\n",
      "Fold: 13  Epoch: 278  Training loss = 2.0477  Validation loss = 2.8981  \n",
      "\n",
      "Fold: 13  Epoch: 279  Training loss = 2.0475  Validation loss = 2.8975  \n",
      "\n",
      "Fold: 13  Epoch: 280  Training loss = 2.0469  Validation loss = 2.8986  \n",
      "\n",
      "Fold: 13  Epoch: 281  Training loss = 2.0466  Validation loss = 2.8976  \n",
      "\n",
      "Fold: 13  Epoch: 282  Training loss = 2.0462  Validation loss = 2.8965  \n",
      "\n",
      "Fold: 13  Epoch: 283  Training loss = 2.0460  Validation loss = 2.8965  \n",
      "\n",
      "Fold: 13  Epoch: 284  Training loss = 2.0455  Validation loss = 2.8946  \n",
      "\n",
      "Fold: 13  Epoch: 285  Training loss = 2.0451  Validation loss = 2.8926  \n",
      "\n",
      "Fold: 13  Epoch: 286  Training loss = 2.0449  Validation loss = 2.8931  \n",
      "\n",
      "Fold: 13  Epoch: 287  Training loss = 2.0450  Validation loss = 2.8931  \n",
      "\n",
      "Fold: 13  Epoch: 288  Training loss = 2.0443  Validation loss = 2.8902  \n",
      "\n",
      "Fold: 13  Epoch: 289  Training loss = 2.0440  Validation loss = 2.8873  \n",
      "\n",
      "Fold: 13  Epoch: 290  Training loss = 2.0438  Validation loss = 2.8871  \n",
      "\n",
      "Fold: 13  Epoch: 291  Training loss = 2.0437  Validation loss = 2.8885  \n",
      "\n",
      "Fold: 13  Epoch: 292  Training loss = 2.0435  Validation loss = 2.8889  \n",
      "\n",
      "Fold: 13  Epoch: 293  Training loss = 2.0429  Validation loss = 2.8871  \n",
      "\n",
      "Fold: 13  Epoch: 294  Training loss = 2.0423  Validation loss = 2.8831  \n",
      "\n",
      "Fold: 13  Epoch: 295  Training loss = 2.0421  Validation loss = 2.8827  \n",
      "\n",
      "Fold: 13  Epoch: 296  Training loss = 2.0421  Validation loss = 2.8838  \n",
      "\n",
      "Fold: 13  Epoch: 297  Training loss = 2.0418  Validation loss = 2.8827  \n",
      "\n",
      "Fold: 13  Epoch: 298  Training loss = 2.0422  Validation loss = 2.8825  \n",
      "\n",
      "Fold: 13  Epoch: 299  Training loss = 2.0411  Validation loss = 2.8786  \n",
      "\n",
      "Fold: 13  Epoch: 300  Training loss = 2.0410  Validation loss = 2.8777  \n",
      "\n",
      "Fold: 13  Epoch: 301  Training loss = 2.0408  Validation loss = 2.8762  \n",
      "\n",
      "Fold: 13  Epoch: 302  Training loss = 2.0408  Validation loss = 2.8715  \n",
      "\n",
      "Fold: 13  Epoch: 303  Training loss = 2.0406  Validation loss = 2.8700  \n",
      "\n",
      "Fold: 13  Epoch: 304  Training loss = 2.0404  Validation loss = 2.8702  \n",
      "\n",
      "Fold: 13  Epoch: 305  Training loss = 2.0404  Validation loss = 2.8663  \n",
      "\n",
      "Fold: 13  Epoch: 306  Training loss = 2.0398  Validation loss = 2.8645  \n",
      "\n",
      "Fold: 13  Epoch: 307  Training loss = 2.0396  Validation loss = 2.8642  \n",
      "\n",
      "Fold: 13  Epoch: 308  Training loss = 2.0397  Validation loss = 2.8585  \n",
      "\n",
      "Fold: 13  Epoch: 309  Training loss = 2.0396  Validation loss = 2.8564  \n",
      "\n",
      "Fold: 13  Epoch: 310  Training loss = 2.0396  Validation loss = 2.8534  \n",
      "\n",
      "Fold: 13  Epoch: 311  Training loss = 2.0393  Validation loss = 2.8518  \n",
      "\n",
      "Fold: 13  Epoch: 312  Training loss = 2.0384  Validation loss = 2.8515  \n",
      "\n",
      "Fold: 13  Epoch: 313  Training loss = 2.0376  Validation loss = 2.8499  \n",
      "\n",
      "Fold: 13  Epoch: 314  Training loss = 2.0369  Validation loss = 2.8511  \n",
      "\n",
      "Fold: 13  Epoch: 315  Training loss = 2.0366  Validation loss = 2.8506  \n",
      "\n",
      "Fold: 13  Epoch: 316  Training loss = 2.0365  Validation loss = 2.8515  \n",
      "\n",
      "Fold: 13  Epoch: 317  Training loss = 2.0365  Validation loss = 2.8532  \n",
      "\n",
      "Fold: 13  Epoch: 318  Training loss = 2.0367  Validation loss = 2.8528  \n",
      "\n",
      "Fold: 13  Epoch: 319  Training loss = 2.0366  Validation loss = 2.8524  \n",
      "\n",
      "Fold: 13  Epoch: 320  Training loss = 2.0352  Validation loss = 2.8501  \n",
      "\n",
      "Fold: 13  Epoch: 321  Training loss = 2.0345  Validation loss = 2.8461  \n",
      "\n",
      "Fold: 13  Epoch: 322  Training loss = 2.0341  Validation loss = 2.8429  \n",
      "\n",
      "Fold: 13  Epoch: 323  Training loss = 2.0337  Validation loss = 2.8419  \n",
      "\n",
      "Fold: 13  Epoch: 324  Training loss = 2.0334  Validation loss = 2.8418  \n",
      "\n",
      "Fold: 13  Epoch: 325  Training loss = 2.0331  Validation loss = 2.8397  \n",
      "\n",
      "Fold: 13  Epoch: 326  Training loss = 2.0324  Validation loss = 2.8407  \n",
      "\n",
      "Fold: 13  Epoch: 327  Training loss = 2.0323  Validation loss = 2.8390  \n",
      "\n",
      "Fold: 13  Epoch: 328  Training loss = 2.0324  Validation loss = 2.8358  \n",
      "\n",
      "Fold: 13  Epoch: 329  Training loss = 2.0317  Validation loss = 2.8362  \n",
      "\n",
      "Fold: 13  Epoch: 330  Training loss = 2.0311  Validation loss = 2.8351  \n",
      "\n",
      "Fold: 13  Epoch: 331  Training loss = 2.0309  Validation loss = 2.8340  \n",
      "\n",
      "Fold: 13  Epoch: 332  Training loss = 2.0304  Validation loss = 2.8342  \n",
      "\n",
      "Fold: 13  Epoch: 333  Training loss = 2.0304  Validation loss = 2.8330  \n",
      "\n",
      "Fold: 13  Epoch: 334  Training loss = 2.0297  Validation loss = 2.8355  \n",
      "\n",
      "Fold: 13  Epoch: 335  Training loss = 2.0294  Validation loss = 2.8370  \n",
      "\n",
      "Fold: 13  Epoch: 336  Training loss = 2.0289  Validation loss = 2.8331  \n",
      "\n",
      "Fold: 13  Epoch: 337  Training loss = 2.0288  Validation loss = 2.8371  \n",
      "\n",
      "Check model:  Fold: 13  Optimal epoch: 333  \n",
      "\n",
      "Fold: 14  Epoch: 1  Training loss = 2.1450  Validation loss = 6.2769  \n",
      "\n",
      "Fold: 14  Epoch: 2  Training loss = 2.1453  Validation loss = 6.2765  \n",
      "\n",
      "Fold: 14  Epoch: 3  Training loss = 2.1445  Validation loss = 6.2752  \n",
      "\n",
      "Fold: 14  Epoch: 4  Training loss = 2.1430  Validation loss = 6.2722  \n",
      "\n",
      "Fold: 14  Epoch: 5  Training loss = 2.1427  Validation loss = 6.2717  \n",
      "\n",
      "Fold: 14  Epoch: 6  Training loss = 2.1422  Validation loss = 6.2694  \n",
      "\n",
      "Fold: 14  Epoch: 7  Training loss = 2.1419  Validation loss = 6.2689  \n",
      "\n",
      "Fold: 14  Epoch: 8  Training loss = 2.1409  Validation loss = 6.2657  \n",
      "\n",
      "Fold: 14  Epoch: 9  Training loss = 2.1403  Validation loss = 6.2635  \n",
      "\n",
      "Fold: 14  Epoch: 10  Training loss = 2.1401  Validation loss = 6.2628  \n",
      "\n",
      "Fold: 14  Epoch: 11  Training loss = 2.1397  Validation loss = 6.2627  \n",
      "\n",
      "Fold: 14  Epoch: 12  Training loss = 2.1394  Validation loss = 6.2616  \n",
      "\n",
      "Fold: 14  Epoch: 13  Training loss = 2.1392  Validation loss = 6.2604  \n",
      "\n",
      "Fold: 14  Epoch: 14  Training loss = 2.1393  Validation loss = 6.2599  \n",
      "\n",
      "Fold: 14  Epoch: 15  Training loss = 2.1391  Validation loss = 6.2593  \n",
      "\n",
      "Fold: 14  Epoch: 16  Training loss = 2.1387  Validation loss = 6.2577  \n",
      "\n",
      "Fold: 14  Epoch: 17  Training loss = 2.1387  Validation loss = 6.2570  \n",
      "\n",
      "Fold: 14  Epoch: 18  Training loss = 2.1375  Validation loss = 6.2549  \n",
      "\n",
      "Fold: 14  Epoch: 19  Training loss = 2.1371  Validation loss = 6.2529  \n",
      "\n",
      "Fold: 14  Epoch: 20  Training loss = 2.1363  Validation loss = 6.2517  \n",
      "\n",
      "Fold: 14  Epoch: 21  Training loss = 2.1363  Validation loss = 6.2506  \n",
      "\n",
      "Fold: 14  Epoch: 22  Training loss = 2.1359  Validation loss = 6.2487  \n",
      "\n",
      "Fold: 14  Epoch: 23  Training loss = 2.1347  Validation loss = 6.2455  \n",
      "\n",
      "Fold: 14  Epoch: 24  Training loss = 2.1339  Validation loss = 6.2428  \n",
      "\n",
      "Fold: 14  Epoch: 25  Training loss = 2.1334  Validation loss = 6.2417  \n",
      "\n",
      "Fold: 14  Epoch: 26  Training loss = 2.1332  Validation loss = 6.2411  \n",
      "\n",
      "Fold: 14  Epoch: 27  Training loss = 2.1327  Validation loss = 6.2397  \n",
      "\n",
      "Fold: 14  Epoch: 28  Training loss = 2.1323  Validation loss = 6.2360  \n",
      "\n",
      "Fold: 14  Epoch: 29  Training loss = 2.1317  Validation loss = 6.2344  \n",
      "\n",
      "Fold: 14  Epoch: 30  Training loss = 2.1314  Validation loss = 6.2344  \n",
      "\n",
      "Fold: 14  Epoch: 31  Training loss = 2.1307  Validation loss = 6.2334  \n",
      "\n",
      "Fold: 14  Epoch: 32  Training loss = 2.1303  Validation loss = 6.2317  \n",
      "\n",
      "Fold: 14  Epoch: 33  Training loss = 2.1299  Validation loss = 6.2300  \n",
      "\n",
      "Fold: 14  Epoch: 34  Training loss = 2.1296  Validation loss = 6.2293  \n",
      "\n",
      "Fold: 14  Epoch: 35  Training loss = 2.1290  Validation loss = 6.2292  \n",
      "\n",
      "Fold: 14  Epoch: 36  Training loss = 2.1285  Validation loss = 6.2269  \n",
      "\n",
      "Fold: 14  Epoch: 37  Training loss = 2.1277  Validation loss = 6.2242  \n",
      "\n",
      "Fold: 14  Epoch: 38  Training loss = 2.1270  Validation loss = 6.2222  \n",
      "\n",
      "Fold: 14  Epoch: 39  Training loss = 2.1265  Validation loss = 6.2201  \n",
      "\n",
      "Fold: 14  Epoch: 40  Training loss = 2.1261  Validation loss = 6.2179  \n",
      "\n",
      "Fold: 14  Epoch: 41  Training loss = 2.1258  Validation loss = 6.2155  \n",
      "\n",
      "Fold: 14  Epoch: 42  Training loss = 2.1255  Validation loss = 6.2147  \n",
      "\n",
      "Fold: 14  Epoch: 43  Training loss = 2.1250  Validation loss = 6.2117  \n",
      "\n",
      "Fold: 14  Epoch: 44  Training loss = 2.1242  Validation loss = 6.2100  \n",
      "\n",
      "Fold: 14  Epoch: 45  Training loss = 2.1240  Validation loss = 6.2074  \n",
      "\n",
      "Fold: 14  Epoch: 46  Training loss = 2.1234  Validation loss = 6.2066  \n",
      "\n",
      "Fold: 14  Epoch: 47  Training loss = 2.1231  Validation loss = 6.2042  \n",
      "\n",
      "Fold: 14  Epoch: 48  Training loss = 2.1221  Validation loss = 6.2003  \n",
      "\n",
      "Fold: 14  Epoch: 49  Training loss = 2.1224  Validation loss = 6.1976  \n",
      "\n",
      "Fold: 14  Epoch: 50  Training loss = 2.1221  Validation loss = 6.1946  \n",
      "\n",
      "Fold: 14  Epoch: 51  Training loss = 2.1217  Validation loss = 6.1931  \n",
      "\n",
      "Fold: 14  Epoch: 52  Training loss = 2.1211  Validation loss = 6.1912  \n",
      "\n",
      "Fold: 14  Epoch: 53  Training loss = 2.1201  Validation loss = 6.1915  \n",
      "\n",
      "Fold: 14  Epoch: 54  Training loss = 2.1193  Validation loss = 6.1899  \n",
      "\n",
      "Fold: 14  Epoch: 55  Training loss = 2.1191  Validation loss = 6.1909  \n",
      "\n",
      "Fold: 14  Epoch: 56  Training loss = 2.1185  Validation loss = 6.1881  \n",
      "\n",
      "Fold: 14  Epoch: 57  Training loss = 2.1181  Validation loss = 6.1873  \n",
      "\n",
      "Fold: 14  Epoch: 58  Training loss = 2.1174  Validation loss = 6.1843  \n",
      "\n",
      "Fold: 14  Epoch: 59  Training loss = 2.1165  Validation loss = 6.1805  \n",
      "\n",
      "Fold: 14  Epoch: 60  Training loss = 2.1160  Validation loss = 6.1774  \n",
      "\n",
      "Fold: 14  Epoch: 61  Training loss = 2.1154  Validation loss = 6.1759  \n",
      "\n",
      "Fold: 14  Epoch: 62  Training loss = 2.1150  Validation loss = 6.1746  \n",
      "\n",
      "Fold: 14  Epoch: 63  Training loss = 2.1145  Validation loss = 6.1723  \n",
      "\n",
      "Fold: 14  Epoch: 64  Training loss = 2.1139  Validation loss = 6.1708  \n",
      "\n",
      "Fold: 14  Epoch: 65  Training loss = 2.1138  Validation loss = 6.1704  \n",
      "\n",
      "Fold: 14  Epoch: 66  Training loss = 2.1126  Validation loss = 6.1682  \n",
      "\n",
      "Fold: 14  Epoch: 67  Training loss = 2.1125  Validation loss = 6.1681  \n",
      "\n",
      "Fold: 14  Epoch: 68  Training loss = 2.1120  Validation loss = 6.1670  \n",
      "\n",
      "Fold: 14  Epoch: 69  Training loss = 2.1118  Validation loss = 6.1652  \n",
      "\n",
      "Fold: 14  Epoch: 70  Training loss = 2.1114  Validation loss = 6.1624  \n",
      "\n",
      "Fold: 14  Epoch: 71  Training loss = 2.1111  Validation loss = 6.1610  \n",
      "\n",
      "Fold: 14  Epoch: 72  Training loss = 2.1109  Validation loss = 6.1605  \n",
      "\n",
      "Fold: 14  Epoch: 73  Training loss = 2.1105  Validation loss = 6.1582  \n",
      "\n",
      "Fold: 14  Epoch: 74  Training loss = 2.1100  Validation loss = 6.1571  \n",
      "\n",
      "Fold: 14  Epoch: 75  Training loss = 2.1101  Validation loss = 6.1556  \n",
      "\n",
      "Fold: 14  Epoch: 76  Training loss = 2.1105  Validation loss = 6.1539  \n",
      "\n",
      "Fold: 14  Epoch: 77  Training loss = 2.1092  Validation loss = 6.1507  \n",
      "\n",
      "Fold: 14  Epoch: 78  Training loss = 2.1097  Validation loss = 6.1493  \n",
      "\n",
      "Fold: 14  Epoch: 79  Training loss = 2.1103  Validation loss = 6.1491  \n",
      "\n",
      "Fold: 14  Epoch: 80  Training loss = 2.1113  Validation loss = 6.1473  \n",
      "\n",
      "Fold: 14  Epoch: 81  Training loss = 2.1099  Validation loss = 6.1445  \n",
      "\n",
      "Fold: 14  Epoch: 82  Training loss = 2.1071  Validation loss = 6.1423  \n",
      "\n",
      "Fold: 14  Epoch: 83  Training loss = 2.1055  Validation loss = 6.1413  \n",
      "\n",
      "Fold: 14  Epoch: 84  Training loss = 2.1054  Validation loss = 6.1404  \n",
      "\n",
      "Fold: 14  Epoch: 85  Training loss = 2.1046  Validation loss = 6.1381  \n",
      "\n",
      "Fold: 14  Epoch: 86  Training loss = 2.1038  Validation loss = 6.1381  \n",
      "\n",
      "Fold: 14  Epoch: 87  Training loss = 2.1035  Validation loss = 6.1374  \n",
      "\n",
      "Fold: 14  Epoch: 88  Training loss = 2.1031  Validation loss = 6.1361  \n",
      "\n",
      "Fold: 14  Epoch: 89  Training loss = 2.1027  Validation loss = 6.1347  \n",
      "\n",
      "Fold: 14  Epoch: 90  Training loss = 2.1022  Validation loss = 6.1344  \n",
      "\n",
      "Fold: 14  Epoch: 91  Training loss = 2.1017  Validation loss = 6.1322  \n",
      "\n",
      "Fold: 14  Epoch: 92  Training loss = 2.1009  Validation loss = 6.1283  \n",
      "\n",
      "Fold: 14  Epoch: 93  Training loss = 2.1002  Validation loss = 6.1254  \n",
      "\n",
      "Fold: 14  Epoch: 94  Training loss = 2.0998  Validation loss = 6.1228  \n",
      "\n",
      "Fold: 14  Epoch: 95  Training loss = 2.0995  Validation loss = 6.1214  \n",
      "\n",
      "Fold: 14  Epoch: 96  Training loss = 2.0991  Validation loss = 6.1200  \n",
      "\n",
      "Fold: 14  Epoch: 97  Training loss = 2.0984  Validation loss = 6.1167  \n",
      "\n",
      "Fold: 14  Epoch: 98  Training loss = 2.0981  Validation loss = 6.1153  \n",
      "\n",
      "Fold: 14  Epoch: 99  Training loss = 2.0973  Validation loss = 6.1124  \n",
      "\n",
      "Fold: 14  Epoch: 100  Training loss = 2.0970  Validation loss = 6.1106  \n",
      "\n",
      "Fold: 14  Epoch: 101  Training loss = 2.0967  Validation loss = 6.1082  \n",
      "\n",
      "Fold: 14  Epoch: 102  Training loss = 2.0959  Validation loss = 6.1059  \n",
      "\n",
      "Fold: 14  Epoch: 103  Training loss = 2.0952  Validation loss = 6.1036  \n",
      "\n",
      "Fold: 14  Epoch: 104  Training loss = 2.0944  Validation loss = 6.1013  \n",
      "\n",
      "Fold: 14  Epoch: 105  Training loss = 2.0937  Validation loss = 6.0988  \n",
      "\n",
      "Fold: 14  Epoch: 106  Training loss = 2.0934  Validation loss = 6.0989  \n",
      "\n",
      "Fold: 14  Epoch: 107  Training loss = 2.0930  Validation loss = 6.0964  \n",
      "\n",
      "Fold: 14  Epoch: 108  Training loss = 2.0926  Validation loss = 6.0948  \n",
      "\n",
      "Fold: 14  Epoch: 109  Training loss = 2.0921  Validation loss = 6.0931  \n",
      "\n",
      "Fold: 14  Epoch: 110  Training loss = 2.0917  Validation loss = 6.0935  \n",
      "\n",
      "Fold: 14  Epoch: 111  Training loss = 2.0908  Validation loss = 6.0909  \n",
      "\n",
      "Fold: 14  Epoch: 112  Training loss = 2.0908  Validation loss = 6.0893  \n",
      "\n",
      "Fold: 14  Epoch: 113  Training loss = 2.0906  Validation loss = 6.0886  \n",
      "\n",
      "Fold: 14  Epoch: 114  Training loss = 2.0903  Validation loss = 6.0868  \n",
      "\n",
      "Fold: 14  Epoch: 115  Training loss = 2.0899  Validation loss = 6.0870  \n",
      "\n",
      "Fold: 14  Epoch: 116  Training loss = 2.0897  Validation loss = 6.0861  \n",
      "\n",
      "Fold: 14  Epoch: 117  Training loss = 2.0895  Validation loss = 6.0851  \n",
      "\n",
      "Fold: 14  Epoch: 118  Training loss = 2.0884  Validation loss = 6.0823  \n",
      "\n",
      "Fold: 14  Epoch: 119  Training loss = 2.0884  Validation loss = 6.0804  \n",
      "\n",
      "Fold: 14  Epoch: 120  Training loss = 2.0876  Validation loss = 6.0782  \n",
      "\n",
      "Fold: 14  Epoch: 121  Training loss = 2.0874  Validation loss = 6.0773  \n",
      "\n",
      "Fold: 14  Epoch: 122  Training loss = 2.0870  Validation loss = 6.0754  \n",
      "\n",
      "Fold: 14  Epoch: 123  Training loss = 2.0866  Validation loss = 6.0743  \n",
      "\n",
      "Fold: 14  Epoch: 124  Training loss = 2.0860  Validation loss = 6.0714  \n",
      "\n",
      "Fold: 14  Epoch: 125  Training loss = 2.0851  Validation loss = 6.0698  \n",
      "\n",
      "Fold: 14  Epoch: 126  Training loss = 2.0849  Validation loss = 6.0693  \n",
      "\n",
      "Fold: 14  Epoch: 127  Training loss = 2.0844  Validation loss = 6.0683  \n",
      "\n",
      "Fold: 14  Epoch: 128  Training loss = 2.0836  Validation loss = 6.0654  \n",
      "\n",
      "Fold: 14  Epoch: 129  Training loss = 2.0829  Validation loss = 6.0620  \n",
      "\n",
      "Fold: 14  Epoch: 130  Training loss = 2.0823  Validation loss = 6.0594  \n",
      "\n",
      "Fold: 14  Epoch: 131  Training loss = 2.0821  Validation loss = 6.0582  \n",
      "\n",
      "Fold: 14  Epoch: 132  Training loss = 2.0817  Validation loss = 6.0574  \n",
      "\n",
      "Fold: 14  Epoch: 133  Training loss = 2.0816  Validation loss = 6.0566  \n",
      "\n",
      "Fold: 14  Epoch: 134  Training loss = 2.0818  Validation loss = 6.0561  \n",
      "\n",
      "Fold: 14  Epoch: 135  Training loss = 2.0815  Validation loss = 6.0564  \n",
      "\n",
      "Fold: 14  Epoch: 136  Training loss = 2.0815  Validation loss = 6.0564  \n",
      "\n",
      "Fold: 14  Epoch: 137  Training loss = 2.0810  Validation loss = 6.0552  \n",
      "\n",
      "Fold: 14  Epoch: 138  Training loss = 2.0803  Validation loss = 6.0526  \n",
      "\n",
      "Fold: 14  Epoch: 139  Training loss = 2.0800  Validation loss = 6.0519  \n",
      "\n",
      "Fold: 14  Epoch: 140  Training loss = 2.0799  Validation loss = 6.0511  \n",
      "\n",
      "Fold: 14  Epoch: 141  Training loss = 2.0788  Validation loss = 6.0470  \n",
      "\n",
      "Fold: 14  Epoch: 142  Training loss = 2.0782  Validation loss = 6.0438  \n",
      "\n",
      "Fold: 14  Epoch: 143  Training loss = 2.0777  Validation loss = 6.0422  \n",
      "\n",
      "Fold: 14  Epoch: 144  Training loss = 2.0776  Validation loss = 6.0419  \n",
      "\n",
      "Fold: 14  Epoch: 145  Training loss = 2.0772  Validation loss = 6.0396  \n",
      "\n",
      "Fold: 14  Epoch: 146  Training loss = 2.0766  Validation loss = 6.0375  \n",
      "\n",
      "Fold: 14  Epoch: 147  Training loss = 2.0764  Validation loss = 6.0359  \n",
      "\n",
      "Fold: 14  Epoch: 148  Training loss = 2.0762  Validation loss = 6.0346  \n",
      "\n",
      "Fold: 14  Epoch: 149  Training loss = 2.0757  Validation loss = 6.0317  \n",
      "\n",
      "Fold: 14  Epoch: 150  Training loss = 2.0756  Validation loss = 6.0283  \n",
      "\n",
      "Fold: 14  Epoch: 151  Training loss = 2.0751  Validation loss = 6.0277  \n",
      "\n",
      "Fold: 14  Epoch: 152  Training loss = 2.0745  Validation loss = 6.0266  \n",
      "\n",
      "Fold: 14  Epoch: 153  Training loss = 2.0741  Validation loss = 6.0257  \n",
      "\n",
      "Fold: 14  Epoch: 154  Training loss = 2.0738  Validation loss = 6.0237  \n",
      "\n",
      "Fold: 14  Epoch: 155  Training loss = 2.0735  Validation loss = 6.0222  \n",
      "\n",
      "Fold: 14  Epoch: 156  Training loss = 2.0727  Validation loss = 6.0187  \n",
      "\n",
      "Fold: 14  Epoch: 157  Training loss = 2.0722  Validation loss = 6.0172  \n",
      "\n",
      "Fold: 14  Epoch: 158  Training loss = 2.0716  Validation loss = 6.0162  \n",
      "\n",
      "Fold: 14  Epoch: 159  Training loss = 2.0708  Validation loss = 6.0124  \n",
      "\n",
      "Fold: 14  Epoch: 160  Training loss = 2.0705  Validation loss = 6.0112  \n",
      "\n",
      "Fold: 14  Epoch: 161  Training loss = 2.0700  Validation loss = 6.0086  \n",
      "\n",
      "Fold: 14  Epoch: 162  Training loss = 2.0696  Validation loss = 6.0065  \n",
      "\n",
      "Fold: 14  Epoch: 163  Training loss = 2.0691  Validation loss = 6.0033  \n",
      "\n",
      "Fold: 14  Epoch: 164  Training loss = 2.0688  Validation loss = 6.0012  \n",
      "\n",
      "Fold: 14  Epoch: 165  Training loss = 2.0682  Validation loss = 5.9995  \n",
      "\n",
      "Fold: 14  Epoch: 166  Training loss = 2.0679  Validation loss = 5.9986  \n",
      "\n",
      "Fold: 14  Epoch: 167  Training loss = 2.0677  Validation loss = 5.9978  \n",
      "\n",
      "Fold: 14  Epoch: 168  Training loss = 2.0673  Validation loss = 5.9972  \n",
      "\n",
      "Fold: 14  Epoch: 169  Training loss = 2.0668  Validation loss = 5.9960  \n",
      "\n",
      "Fold: 14  Epoch: 170  Training loss = 2.0662  Validation loss = 5.9934  \n",
      "\n",
      "Fold: 14  Epoch: 171  Training loss = 2.0658  Validation loss = 5.9915  \n",
      "\n",
      "Fold: 14  Epoch: 172  Training loss = 2.0655  Validation loss = 5.9894  \n",
      "\n",
      "Fold: 14  Epoch: 173  Training loss = 2.0656  Validation loss = 5.9883  \n",
      "\n",
      "Fold: 14  Epoch: 174  Training loss = 2.0652  Validation loss = 5.9865  \n",
      "\n",
      "Fold: 14  Epoch: 175  Training loss = 2.0650  Validation loss = 5.9854  \n",
      "\n",
      "Fold: 14  Epoch: 176  Training loss = 2.0647  Validation loss = 5.9843  \n",
      "\n",
      "Fold: 14  Epoch: 177  Training loss = 2.0640  Validation loss = 5.9820  \n",
      "\n",
      "Fold: 14  Epoch: 178  Training loss = 2.0636  Validation loss = 5.9808  \n",
      "\n",
      "Fold: 14  Epoch: 179  Training loss = 2.0630  Validation loss = 5.9791  \n",
      "\n",
      "Fold: 14  Epoch: 180  Training loss = 2.0626  Validation loss = 5.9777  \n",
      "\n",
      "Fold: 14  Epoch: 181  Training loss = 2.0622  Validation loss = 5.9768  \n",
      "\n",
      "Fold: 14  Epoch: 182  Training loss = 2.0619  Validation loss = 5.9760  \n",
      "\n",
      "Fold: 14  Epoch: 183  Training loss = 2.0614  Validation loss = 5.9733  \n",
      "\n",
      "Fold: 14  Epoch: 184  Training loss = 2.0611  Validation loss = 5.9716  \n",
      "\n",
      "Fold: 14  Epoch: 185  Training loss = 2.0608  Validation loss = 5.9681  \n",
      "\n",
      "Fold: 14  Epoch: 186  Training loss = 2.0603  Validation loss = 5.9670  \n",
      "\n",
      "Fold: 14  Epoch: 187  Training loss = 2.0600  Validation loss = 5.9682  \n",
      "\n",
      "Fold: 14  Epoch: 188  Training loss = 2.0593  Validation loss = 5.9648  \n",
      "\n",
      "Fold: 14  Epoch: 189  Training loss = 2.0593  Validation loss = 5.9633  \n",
      "\n",
      "Fold: 14  Epoch: 190  Training loss = 2.0587  Validation loss = 5.9619  \n",
      "\n",
      "Fold: 14  Epoch: 191  Training loss = 2.0585  Validation loss = 5.9617  \n",
      "\n",
      "Fold: 14  Epoch: 192  Training loss = 2.0583  Validation loss = 5.9603  \n",
      "\n",
      "Fold: 14  Epoch: 193  Training loss = 2.0580  Validation loss = 5.9590  \n",
      "\n",
      "Fold: 14  Epoch: 194  Training loss = 2.0577  Validation loss = 5.9576  \n",
      "\n",
      "Fold: 14  Epoch: 195  Training loss = 2.0573  Validation loss = 5.9549  \n",
      "\n",
      "Fold: 14  Epoch: 196  Training loss = 2.0572  Validation loss = 5.9550  \n",
      "\n",
      "Fold: 14  Epoch: 197  Training loss = 2.0568  Validation loss = 5.9533  \n",
      "\n",
      "Fold: 14  Epoch: 198  Training loss = 2.0565  Validation loss = 5.9523  \n",
      "\n",
      "Fold: 14  Epoch: 199  Training loss = 2.0559  Validation loss = 5.9499  \n",
      "\n",
      "Fold: 14  Epoch: 200  Training loss = 2.0555  Validation loss = 5.9481  \n",
      "\n",
      "Fold: 14  Epoch: 201  Training loss = 2.0554  Validation loss = 5.9481  \n",
      "\n",
      "Fold: 14  Epoch: 202  Training loss = 2.0550  Validation loss = 5.9466  \n",
      "\n",
      "Fold: 14  Epoch: 203  Training loss = 2.0544  Validation loss = 5.9441  \n",
      "\n",
      "Fold: 14  Epoch: 204  Training loss = 2.0540  Validation loss = 5.9411  \n",
      "\n",
      "Fold: 14  Epoch: 205  Training loss = 2.0537  Validation loss = 5.9400  \n",
      "\n",
      "Fold: 14  Epoch: 206  Training loss = 2.0535  Validation loss = 5.9385  \n",
      "\n",
      "Fold: 14  Epoch: 207  Training loss = 2.0541  Validation loss = 5.9387  \n",
      "\n",
      "Fold: 14  Epoch: 208  Training loss = 2.0540  Validation loss = 5.9366  \n",
      "\n",
      "Fold: 14  Epoch: 209  Training loss = 2.0540  Validation loss = 5.9348  \n",
      "\n",
      "Fold: 14  Epoch: 210  Training loss = 2.0542  Validation loss = 5.9347  \n",
      "\n",
      "Fold: 14  Epoch: 211  Training loss = 2.0541  Validation loss = 5.9343  \n",
      "\n",
      "Fold: 14  Epoch: 212  Training loss = 2.0533  Validation loss = 5.9332  \n",
      "\n",
      "Fold: 14  Epoch: 213  Training loss = 2.0530  Validation loss = 5.9331  \n",
      "\n",
      "Fold: 14  Epoch: 214  Training loss = 2.0539  Validation loss = 5.9329  \n",
      "\n",
      "Fold: 14  Epoch: 215  Training loss = 2.0539  Validation loss = 5.9317  \n",
      "\n",
      "Fold: 14  Epoch: 216  Training loss = 2.0522  Validation loss = 5.9294  \n",
      "\n",
      "Fold: 14  Epoch: 217  Training loss = 2.0511  Validation loss = 5.9279  \n",
      "\n",
      "Fold: 14  Epoch: 218  Training loss = 2.0506  Validation loss = 5.9265  \n",
      "\n",
      "Fold: 14  Epoch: 219  Training loss = 2.0497  Validation loss = 5.9254  \n",
      "\n",
      "Fold: 14  Epoch: 220  Training loss = 2.0493  Validation loss = 5.9242  \n",
      "\n",
      "Fold: 14  Epoch: 221  Training loss = 2.0489  Validation loss = 5.9227  \n",
      "\n",
      "Fold: 14  Epoch: 222  Training loss = 2.0482  Validation loss = 5.9190  \n",
      "\n",
      "Fold: 14  Epoch: 223  Training loss = 2.0479  Validation loss = 5.9173  \n",
      "\n",
      "Fold: 14  Epoch: 224  Training loss = 2.0474  Validation loss = 5.9155  \n",
      "\n",
      "Fold: 14  Epoch: 225  Training loss = 2.0477  Validation loss = 5.9157  \n",
      "\n",
      "Fold: 14  Epoch: 226  Training loss = 2.0479  Validation loss = 5.9160  \n",
      "\n",
      "Fold: 14  Epoch: 227  Training loss = 2.0484  Validation loss = 5.9161  \n",
      "\n",
      "Fold: 14  Epoch: 228  Training loss = 2.0485  Validation loss = 5.9147  \n",
      "\n",
      "Fold: 14  Epoch: 229  Training loss = 2.0481  Validation loss = 5.9133  \n",
      "\n",
      "Fold: 14  Epoch: 230  Training loss = 2.0473  Validation loss = 5.9104  \n",
      "\n",
      "Fold: 14  Epoch: 231  Training loss = 2.0454  Validation loss = 5.9058  \n",
      "\n",
      "Fold: 14  Epoch: 232  Training loss = 2.0451  Validation loss = 5.9055  \n",
      "\n",
      "Fold: 14  Epoch: 233  Training loss = 2.0445  Validation loss = 5.9023  \n",
      "\n",
      "Fold: 14  Epoch: 234  Training loss = 2.0441  Validation loss = 5.9012  \n",
      "\n",
      "Fold: 14  Epoch: 235  Training loss = 2.0440  Validation loss = 5.8991  \n",
      "\n",
      "Fold: 14  Epoch: 236  Training loss = 2.0430  Validation loss = 5.8957  \n",
      "\n",
      "Fold: 14  Epoch: 237  Training loss = 2.0425  Validation loss = 5.8925  \n",
      "\n",
      "Fold: 14  Epoch: 238  Training loss = 2.0420  Validation loss = 5.8896  \n",
      "\n",
      "Fold: 14  Epoch: 239  Training loss = 2.0417  Validation loss = 5.8896  \n",
      "\n",
      "Fold: 14  Epoch: 240  Training loss = 2.0415  Validation loss = 5.8884  \n",
      "\n",
      "Fold: 14  Epoch: 241  Training loss = 2.0410  Validation loss = 5.8860  \n",
      "\n",
      "Fold: 14  Epoch: 242  Training loss = 2.0406  Validation loss = 5.8843  \n",
      "\n",
      "Fold: 14  Epoch: 243  Training loss = 2.0406  Validation loss = 5.8828  \n",
      "\n",
      "Fold: 14  Epoch: 244  Training loss = 2.0402  Validation loss = 5.8819  \n",
      "\n",
      "Fold: 14  Epoch: 245  Training loss = 2.0400  Validation loss = 5.8820  \n",
      "\n",
      "Fold: 14  Epoch: 246  Training loss = 2.0397  Validation loss = 5.8804  \n",
      "\n",
      "Fold: 14  Epoch: 247  Training loss = 2.0394  Validation loss = 5.8789  \n",
      "\n",
      "Fold: 14  Epoch: 248  Training loss = 2.0394  Validation loss = 5.8762  \n",
      "\n",
      "Fold: 14  Epoch: 249  Training loss = 2.0396  Validation loss = 5.8752  \n",
      "\n",
      "Fold: 14  Epoch: 250  Training loss = 2.0392  Validation loss = 5.8746  \n",
      "\n",
      "Fold: 14  Epoch: 251  Training loss = 2.0390  Validation loss = 5.8714  \n",
      "\n",
      "Fold: 14  Epoch: 252  Training loss = 2.0382  Validation loss = 5.8710  \n",
      "\n",
      "Fold: 14  Epoch: 253  Training loss = 2.0378  Validation loss = 5.8707  \n",
      "\n",
      "Fold: 14  Epoch: 254  Training loss = 2.0376  Validation loss = 5.8688  \n",
      "\n",
      "Fold: 14  Epoch: 255  Training loss = 2.0369  Validation loss = 5.8682  \n",
      "\n",
      "Fold: 14  Epoch: 256  Training loss = 2.0369  Validation loss = 5.8682  \n",
      "\n",
      "Fold: 14  Epoch: 257  Training loss = 2.0367  Validation loss = 5.8671  \n",
      "\n",
      "Fold: 14  Epoch: 258  Training loss = 2.0365  Validation loss = 5.8660  \n",
      "\n",
      "Fold: 14  Epoch: 259  Training loss = 2.0357  Validation loss = 5.8641  \n",
      "\n",
      "Fold: 14  Epoch: 260  Training loss = 2.0354  Validation loss = 5.8624  \n",
      "\n",
      "Fold: 14  Epoch: 261  Training loss = 2.0350  Validation loss = 5.8604  \n",
      "\n",
      "Fold: 14  Epoch: 262  Training loss = 2.0347  Validation loss = 5.8599  \n",
      "\n",
      "Fold: 14  Epoch: 263  Training loss = 2.0344  Validation loss = 5.8587  \n",
      "\n",
      "Fold: 14  Epoch: 264  Training loss = 2.0338  Validation loss = 5.8548  \n",
      "\n",
      "Fold: 14  Epoch: 265  Training loss = 2.0336  Validation loss = 5.8539  \n",
      "\n",
      "Fold: 14  Epoch: 266  Training loss = 2.0335  Validation loss = 5.8539  \n",
      "\n",
      "Fold: 14  Epoch: 267  Training loss = 2.0335  Validation loss = 5.8540  \n",
      "\n",
      "Fold: 14  Epoch: 268  Training loss = 2.0330  Validation loss = 5.8522  \n",
      "\n",
      "Fold: 14  Epoch: 269  Training loss = 2.0327  Validation loss = 5.8516  \n",
      "\n",
      "Fold: 14  Epoch: 270  Training loss = 2.0326  Validation loss = 5.8503  \n",
      "\n",
      "Fold: 14  Epoch: 271  Training loss = 2.0321  Validation loss = 5.8489  \n",
      "\n",
      "Fold: 14  Epoch: 272  Training loss = 2.0321  Validation loss = 5.8484  \n",
      "\n",
      "Fold: 14  Epoch: 273  Training loss = 2.0319  Validation loss = 5.8484  \n",
      "\n",
      "Fold: 14  Epoch: 274  Training loss = 2.0316  Validation loss = 5.8469  \n",
      "\n",
      "Fold: 14  Epoch: 275  Training loss = 2.0310  Validation loss = 5.8441  \n",
      "\n",
      "Fold: 14  Epoch: 276  Training loss = 2.0302  Validation loss = 5.8405  \n",
      "\n",
      "Fold: 14  Epoch: 277  Training loss = 2.0299  Validation loss = 5.8392  \n",
      "\n",
      "Fold: 14  Epoch: 278  Training loss = 2.0302  Validation loss = 5.8382  \n",
      "\n",
      "Fold: 14  Epoch: 279  Training loss = 2.0290  Validation loss = 5.8346  \n",
      "\n",
      "Fold: 14  Epoch: 280  Training loss = 2.0285  Validation loss = 5.8330  \n",
      "\n",
      "Fold: 14  Epoch: 281  Training loss = 2.0281  Validation loss = 5.8304  \n",
      "\n",
      "Fold: 14  Epoch: 282  Training loss = 2.0277  Validation loss = 5.8296  \n",
      "\n",
      "Fold: 14  Epoch: 283  Training loss = 2.0275  Validation loss = 5.8292  \n",
      "\n",
      "Fold: 14  Epoch: 284  Training loss = 2.0272  Validation loss = 5.8271  \n",
      "\n",
      "Fold: 14  Epoch: 285  Training loss = 2.0269  Validation loss = 5.8261  \n",
      "\n",
      "Fold: 14  Epoch: 286  Training loss = 2.0269  Validation loss = 5.8258  \n",
      "\n",
      "Fold: 14  Epoch: 287  Training loss = 2.0265  Validation loss = 5.8244  \n",
      "\n",
      "Fold: 14  Epoch: 288  Training loss = 2.0263  Validation loss = 5.8230  \n",
      "\n",
      "Fold: 14  Epoch: 289  Training loss = 2.0258  Validation loss = 5.8209  \n",
      "\n",
      "Fold: 14  Epoch: 290  Training loss = 2.0258  Validation loss = 5.8207  \n",
      "\n",
      "Fold: 14  Epoch: 291  Training loss = 2.0262  Validation loss = 5.8208  \n",
      "\n",
      "Fold: 14  Epoch: 292  Training loss = 2.0260  Validation loss = 5.8212  \n",
      "\n",
      "Fold: 14  Epoch: 293  Training loss = 2.0259  Validation loss = 5.8199  \n",
      "\n",
      "Fold: 14  Epoch: 294  Training loss = 2.0254  Validation loss = 5.8187  \n",
      "\n",
      "Fold: 14  Epoch: 295  Training loss = 2.0247  Validation loss = 5.8157  \n",
      "\n",
      "Fold: 14  Epoch: 296  Training loss = 2.0242  Validation loss = 5.8140  \n",
      "\n",
      "Fold: 14  Epoch: 297  Training loss = 2.0238  Validation loss = 5.8125  \n",
      "\n",
      "Fold: 14  Epoch: 298  Training loss = 2.0236  Validation loss = 5.8101  \n",
      "\n",
      "Fold: 14  Epoch: 299  Training loss = 2.0232  Validation loss = 5.8095  \n",
      "\n",
      "Fold: 14  Epoch: 300  Training loss = 2.0229  Validation loss = 5.8087  \n",
      "\n",
      "Fold: 14  Epoch: 301  Training loss = 2.0229  Validation loss = 5.8093  \n",
      "\n",
      "Fold: 14  Epoch: 302  Training loss = 2.0230  Validation loss = 5.8085  \n",
      "\n",
      "Fold: 14  Epoch: 303  Training loss = 2.0227  Validation loss = 5.8064  \n",
      "\n",
      "Fold: 14  Epoch: 304  Training loss = 2.0228  Validation loss = 5.8059  \n",
      "\n",
      "Fold: 14  Epoch: 305  Training loss = 2.0222  Validation loss = 5.8056  \n",
      "\n",
      "Fold: 14  Epoch: 306  Training loss = 2.0223  Validation loss = 5.8040  \n",
      "\n",
      "Fold: 14  Epoch: 307  Training loss = 2.0219  Validation loss = 5.8045  \n",
      "\n",
      "Fold: 14  Epoch: 308  Training loss = 2.0216  Validation loss = 5.8036  \n",
      "\n",
      "Fold: 14  Epoch: 309  Training loss = 2.0212  Validation loss = 5.8035  \n",
      "\n",
      "Fold: 14  Epoch: 310  Training loss = 2.0208  Validation loss = 5.8029  \n",
      "\n",
      "Fold: 14  Epoch: 311  Training loss = 2.0202  Validation loss = 5.8005  \n",
      "\n",
      "Fold: 14  Epoch: 312  Training loss = 2.0174  Validation loss = 5.7981  \n",
      "\n",
      "Fold: 14  Epoch: 313  Training loss = 2.0172  Validation loss = 5.7980  \n",
      "\n",
      "Fold: 14  Epoch: 314  Training loss = 2.0170  Validation loss = 5.7974  \n",
      "\n",
      "Fold: 14  Epoch: 315  Training loss = 2.0166  Validation loss = 5.7954  \n",
      "\n",
      "Fold: 14  Epoch: 316  Training loss = 2.0165  Validation loss = 5.7950  \n",
      "\n",
      "Fold: 14  Epoch: 317  Training loss = 2.0160  Validation loss = 5.7930  \n",
      "\n",
      "Fold: 14  Epoch: 318  Training loss = 2.0158  Validation loss = 5.7921  \n",
      "\n",
      "Fold: 14  Epoch: 319  Training loss = 2.0156  Validation loss = 5.7908  \n",
      "\n",
      "Fold: 14  Epoch: 320  Training loss = 2.0153  Validation loss = 5.7894  \n",
      "\n",
      "Fold: 14  Epoch: 321  Training loss = 2.0149  Validation loss = 5.7876  \n",
      "\n",
      "Fold: 14  Epoch: 322  Training loss = 2.0144  Validation loss = 5.7852  \n",
      "\n",
      "Fold: 14  Epoch: 323  Training loss = 2.0142  Validation loss = 5.7842  \n",
      "\n",
      "Fold: 14  Epoch: 324  Training loss = 2.0140  Validation loss = 5.7821  \n",
      "\n",
      "Fold: 14  Epoch: 325  Training loss = 2.0138  Validation loss = 5.7825  \n",
      "\n",
      "Fold: 14  Epoch: 326  Training loss = 2.0134  Validation loss = 5.7798  \n",
      "\n",
      "Fold: 14  Epoch: 327  Training loss = 2.0129  Validation loss = 5.7774  \n",
      "\n",
      "Fold: 14  Epoch: 328  Training loss = 2.0125  Validation loss = 5.7759  \n",
      "\n",
      "Fold: 14  Epoch: 329  Training loss = 2.0123  Validation loss = 5.7761  \n",
      "\n",
      "Fold: 14  Epoch: 330  Training loss = 2.0121  Validation loss = 5.7746  \n",
      "\n",
      "Fold: 14  Epoch: 331  Training loss = 2.0131  Validation loss = 5.7764  \n",
      "\n",
      "Fold: 14  Epoch: 332  Training loss = 2.0126  Validation loss = 5.7744  \n",
      "\n",
      "Fold: 14  Epoch: 333  Training loss = 2.0114  Validation loss = 5.7720  \n",
      "\n",
      "Fold: 14  Epoch: 334  Training loss = 2.0111  Validation loss = 5.7703  \n",
      "\n",
      "Fold: 14  Epoch: 335  Training loss = 2.0111  Validation loss = 5.7682  \n",
      "\n",
      "Fold: 14  Epoch: 336  Training loss = 2.0106  Validation loss = 5.7665  \n",
      "\n",
      "Fold: 14  Epoch: 337  Training loss = 2.0102  Validation loss = 5.7668  \n",
      "\n",
      "Fold: 14  Epoch: 338  Training loss = 2.0098  Validation loss = 5.7646  \n",
      "\n",
      "Fold: 14  Epoch: 339  Training loss = 2.0097  Validation loss = 5.7641  \n",
      "\n",
      "Fold: 14  Epoch: 340  Training loss = 2.0093  Validation loss = 5.7620  \n",
      "\n",
      "Fold: 14  Epoch: 341  Training loss = 2.0091  Validation loss = 5.7607  \n",
      "\n",
      "Fold: 14  Epoch: 342  Training loss = 2.0092  Validation loss = 5.7574  \n",
      "\n",
      "Fold: 14  Epoch: 343  Training loss = 2.0088  Validation loss = 5.7555  \n",
      "\n",
      "Fold: 14  Epoch: 344  Training loss = 2.0086  Validation loss = 5.7536  \n",
      "\n",
      "Fold: 14  Epoch: 345  Training loss = 2.0081  Validation loss = 5.7525  \n",
      "\n",
      "Fold: 14  Epoch: 346  Training loss = 2.0077  Validation loss = 5.7510  \n",
      "\n",
      "Fold: 14  Epoch: 347  Training loss = 2.0072  Validation loss = 5.7507  \n",
      "\n",
      "Fold: 14  Epoch: 348  Training loss = 2.0071  Validation loss = 5.7491  \n",
      "\n",
      "Fold: 14  Epoch: 349  Training loss = 2.0064  Validation loss = 5.7480  \n",
      "\n",
      "Fold: 14  Epoch: 350  Training loss = 2.0063  Validation loss = 5.7455  \n",
      "\n",
      "Fold: 14  Epoch: 351  Training loss = 2.0063  Validation loss = 5.7439  \n",
      "\n",
      "Fold: 14  Epoch: 352  Training loss = 2.0061  Validation loss = 5.7416  \n",
      "\n",
      "Fold: 14  Epoch: 353  Training loss = 2.0056  Validation loss = 5.7408  \n",
      "\n",
      "Fold: 14  Epoch: 354  Training loss = 2.0051  Validation loss = 5.7383  \n",
      "\n",
      "Fold: 14  Epoch: 355  Training loss = 2.0048  Validation loss = 5.7387  \n",
      "\n",
      "Fold: 14  Epoch: 356  Training loss = 2.0044  Validation loss = 5.7385  \n",
      "\n",
      "Fold: 14  Epoch: 357  Training loss = 2.0042  Validation loss = 5.7363  \n",
      "\n",
      "Fold: 14  Epoch: 358  Training loss = 2.0042  Validation loss = 5.7356  \n",
      "\n",
      "Fold: 14  Epoch: 359  Training loss = 2.0037  Validation loss = 5.7351  \n",
      "\n",
      "Fold: 14  Epoch: 360  Training loss = 2.0034  Validation loss = 5.7329  \n",
      "\n",
      "Fold: 14  Epoch: 361  Training loss = 2.0030  Validation loss = 5.7321  \n",
      "\n",
      "Fold: 14  Epoch: 362  Training loss = 2.0028  Validation loss = 5.7303  \n",
      "\n",
      "Fold: 14  Epoch: 363  Training loss = 2.0025  Validation loss = 5.7300  \n",
      "\n",
      "Fold: 14  Epoch: 364  Training loss = 2.0022  Validation loss = 5.7296  \n",
      "\n",
      "Fold: 14  Epoch: 365  Training loss = 2.0021  Validation loss = 5.7298  \n",
      "\n",
      "Fold: 14  Epoch: 366  Training loss = 2.0025  Validation loss = 5.7300  \n",
      "\n",
      "Fold: 14  Epoch: 367  Training loss = 2.0023  Validation loss = 5.7295  \n",
      "\n",
      "Fold: 14  Epoch: 368  Training loss = 2.0014  Validation loss = 5.7266  \n",
      "\n",
      "Fold: 14  Epoch: 369  Training loss = 2.0009  Validation loss = 5.7248  \n",
      "\n",
      "Fold: 14  Epoch: 370  Training loss = 2.0010  Validation loss = 5.7246  \n",
      "\n",
      "Fold: 14  Epoch: 371  Training loss = 2.0004  Validation loss = 5.7230  \n",
      "\n",
      "Fold: 14  Epoch: 372  Training loss = 2.0000  Validation loss = 5.7214  \n",
      "\n",
      "Fold: 14  Epoch: 373  Training loss = 1.9998  Validation loss = 5.7202  \n",
      "\n",
      "Fold: 14  Epoch: 374  Training loss = 2.0000  Validation loss = 5.7210  \n",
      "\n",
      "Fold: 14  Epoch: 375  Training loss = 1.9994  Validation loss = 5.7169  \n",
      "\n",
      "Fold: 14  Epoch: 376  Training loss = 1.9991  Validation loss = 5.7153  \n",
      "\n",
      "Fold: 14  Epoch: 377  Training loss = 1.9986  Validation loss = 5.7124  \n",
      "\n",
      "Fold: 14  Epoch: 378  Training loss = 1.9981  Validation loss = 5.7111  \n",
      "\n",
      "Fold: 14  Epoch: 379  Training loss = 1.9981  Validation loss = 5.7117  \n",
      "\n",
      "Fold: 14  Epoch: 380  Training loss = 1.9976  Validation loss = 5.7091  \n",
      "\n",
      "Fold: 14  Epoch: 381  Training loss = 1.9976  Validation loss = 5.7089  \n",
      "\n",
      "Fold: 14  Epoch: 382  Training loss = 1.9972  Validation loss = 5.7076  \n",
      "\n",
      "Fold: 14  Epoch: 383  Training loss = 1.9971  Validation loss = 5.7049  \n",
      "\n",
      "Fold: 14  Epoch: 384  Training loss = 1.9970  Validation loss = 5.7060  \n",
      "\n",
      "Fold: 14  Epoch: 385  Training loss = 1.9967  Validation loss = 5.7054  \n",
      "\n",
      "Fold: 14  Epoch: 386  Training loss = 1.9968  Validation loss = 5.7034  \n",
      "\n",
      "Fold: 14  Epoch: 387  Training loss = 1.9966  Validation loss = 5.7030  \n",
      "\n",
      "Fold: 14  Epoch: 388  Training loss = 1.9967  Validation loss = 5.7036  \n",
      "\n",
      "Fold: 14  Epoch: 389  Training loss = 1.9962  Validation loss = 5.7033  \n",
      "\n",
      "Fold: 14  Epoch: 390  Training loss = 1.9962  Validation loss = 5.7034  \n",
      "\n",
      "Fold: 14  Epoch: 391  Training loss = 1.9963  Validation loss = 5.7007  \n",
      "\n",
      "Fold: 14  Epoch: 392  Training loss = 1.9956  Validation loss = 5.6987  \n",
      "\n",
      "Fold: 14  Epoch: 393  Training loss = 1.9951  Validation loss = 5.6958  \n",
      "\n",
      "Fold: 14  Epoch: 394  Training loss = 1.9944  Validation loss = 5.6941  \n",
      "\n",
      "Fold: 14  Epoch: 395  Training loss = 1.9940  Validation loss = 5.6921  \n",
      "\n",
      "Fold: 14  Epoch: 396  Training loss = 1.9937  Validation loss = 5.6884  \n",
      "\n",
      "Fold: 14  Epoch: 397  Training loss = 1.9931  Validation loss = 5.6869  \n",
      "\n",
      "Fold: 14  Epoch: 398  Training loss = 1.9927  Validation loss = 5.6860  \n",
      "\n",
      "Fold: 14  Epoch: 399  Training loss = 1.9925  Validation loss = 5.6845  \n",
      "\n",
      "Fold: 14  Epoch: 400  Training loss = 1.9922  Validation loss = 5.6833  \n",
      "\n",
      "Fold: 14  Epoch: 401  Training loss = 1.9921  Validation loss = 5.6823  \n",
      "\n",
      "Fold: 14  Epoch: 402  Training loss = 1.9920  Validation loss = 5.6816  \n",
      "\n",
      "Fold: 14  Epoch: 403  Training loss = 1.9920  Validation loss = 5.6817  \n",
      "\n",
      "Fold: 14  Epoch: 404  Training loss = 1.9920  Validation loss = 5.6818  \n",
      "\n",
      "Fold: 14  Epoch: 405  Training loss = 1.9916  Validation loss = 5.6808  \n",
      "\n",
      "Fold: 14  Epoch: 406  Training loss = 1.9914  Validation loss = 5.6796  \n",
      "\n",
      "Fold: 14  Epoch: 407  Training loss = 1.9908  Validation loss = 5.6775  \n",
      "\n",
      "Fold: 14  Epoch: 408  Training loss = 1.9904  Validation loss = 5.6765  \n",
      "\n",
      "Fold: 14  Epoch: 409  Training loss = 1.9899  Validation loss = 5.6733  \n",
      "\n",
      "Fold: 14  Epoch: 410  Training loss = 1.9896  Validation loss = 5.6724  \n",
      "\n",
      "Fold: 14  Epoch: 411  Training loss = 1.9894  Validation loss = 5.6696  \n",
      "\n",
      "Fold: 14  Epoch: 412  Training loss = 1.9889  Validation loss = 5.6684  \n",
      "\n",
      "Fold: 14  Epoch: 413  Training loss = 1.9888  Validation loss = 5.6682  \n",
      "\n",
      "Fold: 14  Epoch: 414  Training loss = 1.9884  Validation loss = 5.6665  \n",
      "\n",
      "Fold: 14  Epoch: 415  Training loss = 1.9878  Validation loss = 5.6637  \n",
      "\n",
      "Fold: 14  Epoch: 416  Training loss = 1.9875  Validation loss = 5.6622  \n",
      "\n",
      "Fold: 14  Epoch: 417  Training loss = 1.9873  Validation loss = 5.6606  \n",
      "\n",
      "Fold: 14  Epoch: 418  Training loss = 1.9870  Validation loss = 5.6589  \n",
      "\n",
      "Fold: 14  Epoch: 419  Training loss = 1.9869  Validation loss = 5.6566  \n",
      "\n",
      "Fold: 14  Epoch: 420  Training loss = 1.9867  Validation loss = 5.6572  \n",
      "\n",
      "Fold: 14  Epoch: 421  Training loss = 1.9863  Validation loss = 5.6562  \n",
      "\n",
      "Fold: 14  Epoch: 422  Training loss = 1.9866  Validation loss = 5.6561  \n",
      "\n",
      "Fold: 14  Epoch: 423  Training loss = 1.9856  Validation loss = 5.6524  \n",
      "\n",
      "Fold: 14  Epoch: 424  Training loss = 1.9854  Validation loss = 5.6513  \n",
      "\n",
      "Fold: 14  Epoch: 425  Training loss = 1.9851  Validation loss = 5.6487  \n",
      "\n",
      "Fold: 14  Epoch: 426  Training loss = 1.9849  Validation loss = 5.6467  \n",
      "\n",
      "Fold: 14  Epoch: 427  Training loss = 1.9845  Validation loss = 5.6448  \n",
      "\n",
      "Fold: 14  Epoch: 428  Training loss = 1.9846  Validation loss = 5.6422  \n",
      "\n",
      "Fold: 14  Epoch: 429  Training loss = 1.9843  Validation loss = 5.6423  \n",
      "\n",
      "Fold: 14  Epoch: 430  Training loss = 1.9840  Validation loss = 5.6431  \n",
      "\n",
      "Fold: 14  Epoch: 431  Training loss = 1.9836  Validation loss = 5.6420  \n",
      "\n",
      "Fold: 14  Epoch: 432  Training loss = 1.9833  Validation loss = 5.6400  \n",
      "\n",
      "Fold: 14  Epoch: 433  Training loss = 1.9836  Validation loss = 5.6376  \n",
      "\n",
      "Fold: 14  Epoch: 434  Training loss = 1.9837  Validation loss = 5.6358  \n",
      "\n",
      "Fold: 14  Epoch: 435  Training loss = 1.9842  Validation loss = 5.6345  \n",
      "\n",
      "Fold: 14  Epoch: 436  Training loss = 1.9827  Validation loss = 5.6346  \n",
      "\n",
      "Fold: 14  Epoch: 437  Training loss = 1.9822  Validation loss = 5.6343  \n",
      "\n",
      "Fold: 14  Epoch: 438  Training loss = 1.9822  Validation loss = 5.6325  \n",
      "\n",
      "Fold: 14  Epoch: 439  Training loss = 1.9817  Validation loss = 5.6315  \n",
      "\n",
      "Fold: 14  Epoch: 440  Training loss = 1.9816  Validation loss = 5.6297  \n",
      "\n",
      "Fold: 14  Epoch: 441  Training loss = 1.9817  Validation loss = 5.6291  \n",
      "\n",
      "Fold: 14  Epoch: 442  Training loss = 1.9815  Validation loss = 5.6267  \n",
      "\n",
      "Fold: 14  Epoch: 443  Training loss = 1.9809  Validation loss = 5.6254  \n",
      "\n",
      "Fold: 14  Epoch: 444  Training loss = 1.9810  Validation loss = 5.6234  \n",
      "\n",
      "Fold: 14  Epoch: 445  Training loss = 1.9814  Validation loss = 5.6225  \n",
      "\n",
      "Fold: 14  Epoch: 446  Training loss = 1.9804  Validation loss = 5.6224  \n",
      "\n",
      "Fold: 14  Epoch: 447  Training loss = 1.9810  Validation loss = 5.6205  \n",
      "\n",
      "Fold: 14  Epoch: 448  Training loss = 1.9809  Validation loss = 5.6185  \n",
      "\n",
      "Fold: 14  Epoch: 449  Training loss = 1.9798  Validation loss = 5.6198  \n",
      "\n",
      "Fold: 14  Epoch: 450  Training loss = 1.9795  Validation loss = 5.6185  \n",
      "\n",
      "Fold: 14  Epoch: 451  Training loss = 1.9791  Validation loss = 5.6174  \n",
      "\n",
      "Fold: 14  Epoch: 452  Training loss = 1.9789  Validation loss = 5.6161  \n",
      "\n",
      "Fold: 14  Epoch: 453  Training loss = 1.9785  Validation loss = 5.6127  \n",
      "\n",
      "Fold: 14  Epoch: 454  Training loss = 1.9782  Validation loss = 5.6107  \n",
      "\n",
      "Fold: 14  Epoch: 455  Training loss = 1.9779  Validation loss = 5.6098  \n",
      "\n",
      "Fold: 14  Epoch: 456  Training loss = 1.9777  Validation loss = 5.6068  \n",
      "\n",
      "Fold: 14  Epoch: 457  Training loss = 1.9775  Validation loss = 5.6070  \n",
      "\n",
      "Fold: 14  Epoch: 458  Training loss = 1.9775  Validation loss = 5.6040  \n",
      "\n",
      "Fold: 14  Epoch: 459  Training loss = 1.9770  Validation loss = 5.6025  \n",
      "\n",
      "Fold: 14  Epoch: 460  Training loss = 1.9767  Validation loss = 5.6017  \n",
      "\n",
      "Fold: 14  Epoch: 461  Training loss = 1.9764  Validation loss = 5.5994  \n",
      "\n",
      "Fold: 14  Epoch: 462  Training loss = 1.9759  Validation loss = 5.5990  \n",
      "\n",
      "Fold: 14  Epoch: 463  Training loss = 1.9756  Validation loss = 5.5975  \n",
      "\n",
      "Fold: 14  Epoch: 464  Training loss = 1.9754  Validation loss = 5.5954  \n",
      "\n",
      "Fold: 14  Epoch: 465  Training loss = 1.9752  Validation loss = 5.5937  \n",
      "\n",
      "Fold: 14  Epoch: 466  Training loss = 1.9750  Validation loss = 5.5941  \n",
      "\n",
      "Fold: 14  Epoch: 467  Training loss = 1.9745  Validation loss = 5.5928  \n",
      "\n",
      "Fold: 14  Epoch: 468  Training loss = 1.9745  Validation loss = 5.5906  \n",
      "\n",
      "Fold: 14  Epoch: 469  Training loss = 1.9743  Validation loss = 5.5897  \n",
      "\n",
      "Fold: 14  Epoch: 470  Training loss = 1.9741  Validation loss = 5.5885  \n",
      "\n",
      "Fold: 14  Epoch: 471  Training loss = 1.9738  Validation loss = 5.5878  \n",
      "\n",
      "Fold: 14  Epoch: 472  Training loss = 1.9732  Validation loss = 5.5859  \n",
      "\n",
      "Fold: 14  Epoch: 473  Training loss = 1.9730  Validation loss = 5.5835  \n",
      "\n",
      "Fold: 14  Epoch: 474  Training loss = 1.9725  Validation loss = 5.5824  \n",
      "\n",
      "Fold: 14  Epoch: 475  Training loss = 1.9728  Validation loss = 5.5810  \n",
      "\n",
      "Fold: 14  Epoch: 476  Training loss = 1.9722  Validation loss = 5.5823  \n",
      "\n",
      "Fold: 14  Epoch: 477  Training loss = 1.9718  Validation loss = 5.5825  \n",
      "\n",
      "Fold: 14  Epoch: 478  Training loss = 1.9717  Validation loss = 5.5815  \n",
      "\n",
      "Fold: 14  Epoch: 479  Training loss = 1.9714  Validation loss = 5.5807  \n",
      "\n",
      "Fold: 14  Epoch: 480  Training loss = 1.9714  Validation loss = 5.5803  \n",
      "\n",
      "Fold: 14  Epoch: 481  Training loss = 1.9711  Validation loss = 5.5794  \n",
      "\n",
      "Fold: 14  Epoch: 482  Training loss = 1.9708  Validation loss = 5.5781  \n",
      "\n",
      "Fold: 14  Epoch: 483  Training loss = 1.9705  Validation loss = 5.5764  \n",
      "\n",
      "Fold: 14  Epoch: 484  Training loss = 1.9704  Validation loss = 5.5760  \n",
      "\n",
      "Fold: 14  Epoch: 485  Training loss = 1.9702  Validation loss = 5.5729  \n",
      "\n",
      "Fold: 14  Epoch: 486  Training loss = 1.9697  Validation loss = 5.5707  \n",
      "\n",
      "Fold: 14  Epoch: 487  Training loss = 1.9694  Validation loss = 5.5703  \n",
      "\n",
      "Fold: 14  Epoch: 488  Training loss = 1.9694  Validation loss = 5.5686  \n",
      "\n",
      "Fold: 14  Epoch: 489  Training loss = 1.9690  Validation loss = 5.5671  \n",
      "\n",
      "Fold: 14  Epoch: 490  Training loss = 1.9689  Validation loss = 5.5643  \n",
      "\n",
      "Fold: 14  Epoch: 491  Training loss = 1.9687  Validation loss = 5.5635  \n",
      "\n",
      "Fold: 14  Epoch: 492  Training loss = 1.9683  Validation loss = 5.5599  \n",
      "\n",
      "Fold: 14  Epoch: 493  Training loss = 1.9680  Validation loss = 5.5590  \n",
      "\n",
      "Fold: 14  Epoch: 494  Training loss = 1.9682  Validation loss = 5.5577  \n",
      "\n",
      "Fold: 14  Epoch: 495  Training loss = 1.9685  Validation loss = 5.5566  \n",
      "\n",
      "Fold: 14  Epoch: 496  Training loss = 1.9675  Validation loss = 5.5576  \n",
      "\n",
      "Fold: 14  Epoch: 497  Training loss = 1.9669  Validation loss = 5.5586  \n",
      "\n",
      "Fold: 14  Epoch: 498  Training loss = 1.9671  Validation loss = 5.5576  \n",
      "\n",
      "Fold: 14  Epoch: 499  Training loss = 1.9663  Validation loss = 5.5568  \n",
      "\n",
      "Fold: 14  Epoch: 500  Training loss = 1.9662  Validation loss = 5.5554  \n",
      "\n",
      "Check model:  Fold: 14  Optimal epoch: 500  \n",
      "\n",
      "Fold: 15  Epoch: 1  Training loss = 2.3920  Validation loss = 6.4801  \n",
      "\n",
      "Fold: 15  Epoch: 2  Training loss = 2.3916  Validation loss = 6.4782  \n",
      "\n",
      "Fold: 15  Epoch: 3  Training loss = 2.3903  Validation loss = 6.4757  \n",
      "\n",
      "Fold: 15  Epoch: 4  Training loss = 2.3897  Validation loss = 6.4736  \n",
      "\n",
      "Fold: 15  Epoch: 5  Training loss = 2.3888  Validation loss = 6.4721  \n",
      "\n",
      "Fold: 15  Epoch: 6  Training loss = 2.3879  Validation loss = 6.4697  \n",
      "\n",
      "Fold: 15  Epoch: 7  Training loss = 2.3872  Validation loss = 6.4680  \n",
      "\n",
      "Fold: 15  Epoch: 8  Training loss = 2.3865  Validation loss = 6.4659  \n",
      "\n",
      "Fold: 15  Epoch: 9  Training loss = 2.3855  Validation loss = 6.4634  \n",
      "\n",
      "Fold: 15  Epoch: 10  Training loss = 2.3847  Validation loss = 6.4611  \n",
      "\n",
      "Fold: 15  Epoch: 11  Training loss = 2.3839  Validation loss = 6.4592  \n",
      "\n",
      "Fold: 15  Epoch: 12  Training loss = 2.3830  Validation loss = 6.4565  \n",
      "\n",
      "Fold: 15  Epoch: 13  Training loss = 2.3824  Validation loss = 6.4550  \n",
      "\n",
      "Fold: 15  Epoch: 14  Training loss = 2.3820  Validation loss = 6.4532  \n",
      "\n",
      "Fold: 15  Epoch: 15  Training loss = 2.3813  Validation loss = 6.4511  \n",
      "\n",
      "Fold: 15  Epoch: 16  Training loss = 2.3808  Validation loss = 6.4499  \n",
      "\n",
      "Fold: 15  Epoch: 17  Training loss = 2.3797  Validation loss = 6.4467  \n",
      "\n",
      "Fold: 15  Epoch: 18  Training loss = 2.3788  Validation loss = 6.4446  \n",
      "\n",
      "Fold: 15  Epoch: 19  Training loss = 2.3780  Validation loss = 6.4429  \n",
      "\n",
      "Fold: 15  Epoch: 20  Training loss = 2.3774  Validation loss = 6.4414  \n",
      "\n",
      "Fold: 15  Epoch: 21  Training loss = 2.3768  Validation loss = 6.4392  \n",
      "\n",
      "Fold: 15  Epoch: 22  Training loss = 2.3753  Validation loss = 6.4353  \n",
      "\n",
      "Fold: 15  Epoch: 23  Training loss = 2.3747  Validation loss = 6.4335  \n",
      "\n",
      "Fold: 15  Epoch: 24  Training loss = 2.3737  Validation loss = 6.4298  \n",
      "\n",
      "Fold: 15  Epoch: 25  Training loss = 2.3733  Validation loss = 6.4262  \n",
      "\n",
      "Fold: 15  Epoch: 26  Training loss = 2.3721  Validation loss = 6.4234  \n",
      "\n",
      "Fold: 15  Epoch: 27  Training loss = 2.3710  Validation loss = 6.4219  \n",
      "\n",
      "Fold: 15  Epoch: 28  Training loss = 2.3698  Validation loss = 6.4181  \n",
      "\n",
      "Fold: 15  Epoch: 29  Training loss = 2.3691  Validation loss = 6.4168  \n",
      "\n",
      "Fold: 15  Epoch: 30  Training loss = 2.3682  Validation loss = 6.4140  \n",
      "\n",
      "Fold: 15  Epoch: 31  Training loss = 2.3678  Validation loss = 6.4117  \n",
      "\n",
      "Fold: 15  Epoch: 32  Training loss = 2.3670  Validation loss = 6.4098  \n",
      "\n",
      "Fold: 15  Epoch: 33  Training loss = 2.3665  Validation loss = 6.4081  \n",
      "\n",
      "Fold: 15  Epoch: 34  Training loss = 2.3657  Validation loss = 6.4064  \n",
      "\n",
      "Fold: 15  Epoch: 35  Training loss = 2.3650  Validation loss = 6.4043  \n",
      "\n",
      "Fold: 15  Epoch: 36  Training loss = 2.3645  Validation loss = 6.4027  \n",
      "\n",
      "Fold: 15  Epoch: 37  Training loss = 2.3638  Validation loss = 6.4009  \n",
      "\n",
      "Fold: 15  Epoch: 38  Training loss = 2.3631  Validation loss = 6.4003  \n",
      "\n",
      "Fold: 15  Epoch: 39  Training loss = 2.3623  Validation loss = 6.3977  \n",
      "\n",
      "Fold: 15  Epoch: 40  Training loss = 2.3616  Validation loss = 6.3967  \n",
      "\n",
      "Fold: 15  Epoch: 41  Training loss = 2.3614  Validation loss = 6.3959  \n",
      "\n",
      "Fold: 15  Epoch: 42  Training loss = 2.3599  Validation loss = 6.3919  \n",
      "\n",
      "Fold: 15  Epoch: 43  Training loss = 2.3591  Validation loss = 6.3900  \n",
      "\n",
      "Fold: 15  Epoch: 44  Training loss = 2.3579  Validation loss = 6.3865  \n",
      "\n",
      "Fold: 15  Epoch: 45  Training loss = 2.3574  Validation loss = 6.3852  \n",
      "\n",
      "Fold: 15  Epoch: 46  Training loss = 2.3571  Validation loss = 6.3839  \n",
      "\n",
      "Fold: 15  Epoch: 47  Training loss = 2.3565  Validation loss = 6.3820  \n",
      "\n",
      "Fold: 15  Epoch: 48  Training loss = 2.3560  Validation loss = 6.3797  \n",
      "\n",
      "Fold: 15  Epoch: 49  Training loss = 2.3549  Validation loss = 6.3772  \n",
      "\n",
      "Fold: 15  Epoch: 50  Training loss = 2.3546  Validation loss = 6.3757  \n",
      "\n",
      "Fold: 15  Epoch: 51  Training loss = 2.3546  Validation loss = 6.3739  \n",
      "\n",
      "Fold: 15  Epoch: 52  Training loss = 2.3539  Validation loss = 6.3718  \n",
      "\n",
      "Fold: 15  Epoch: 53  Training loss = 2.3530  Validation loss = 6.3679  \n",
      "\n",
      "Fold: 15  Epoch: 54  Training loss = 2.3520  Validation loss = 6.3652  \n",
      "\n",
      "Fold: 15  Epoch: 55  Training loss = 2.3524  Validation loss = 6.3633  \n",
      "\n",
      "Fold: 15  Epoch: 56  Training loss = 2.3515  Validation loss = 6.3618  \n",
      "\n",
      "Fold: 15  Epoch: 57  Training loss = 2.3503  Validation loss = 6.3614  \n",
      "\n",
      "Fold: 15  Epoch: 58  Training loss = 2.3492  Validation loss = 6.3602  \n",
      "\n",
      "Fold: 15  Epoch: 59  Training loss = 2.3488  Validation loss = 6.3588  \n",
      "\n",
      "Fold: 15  Epoch: 60  Training loss = 2.3486  Validation loss = 6.3575  \n",
      "\n",
      "Fold: 15  Epoch: 61  Training loss = 2.3475  Validation loss = 6.3556  \n",
      "\n",
      "Fold: 15  Epoch: 62  Training loss = 2.3469  Validation loss = 6.3540  \n",
      "\n",
      "Fold: 15  Epoch: 63  Training loss = 2.3463  Validation loss = 6.3521  \n",
      "\n",
      "Fold: 15  Epoch: 64  Training loss = 2.3458  Validation loss = 6.3507  \n",
      "\n",
      "Fold: 15  Epoch: 65  Training loss = 2.3452  Validation loss = 6.3478  \n",
      "\n",
      "Fold: 15  Epoch: 66  Training loss = 2.3444  Validation loss = 6.3463  \n",
      "\n",
      "Fold: 15  Epoch: 67  Training loss = 2.3437  Validation loss = 6.3445  \n",
      "\n",
      "Fold: 15  Epoch: 68  Training loss = 2.3431  Validation loss = 6.3429  \n",
      "\n",
      "Fold: 15  Epoch: 69  Training loss = 2.3424  Validation loss = 6.3404  \n",
      "\n",
      "Fold: 15  Epoch: 70  Training loss = 2.3421  Validation loss = 6.3386  \n",
      "\n",
      "Fold: 15  Epoch: 71  Training loss = 2.3411  Validation loss = 6.3363  \n",
      "\n",
      "Fold: 15  Epoch: 72  Training loss = 2.3404  Validation loss = 6.3346  \n",
      "\n",
      "Fold: 15  Epoch: 73  Training loss = 2.3400  Validation loss = 6.3325  \n",
      "\n",
      "Fold: 15  Epoch: 74  Training loss = 2.3394  Validation loss = 6.3305  \n",
      "\n",
      "Fold: 15  Epoch: 75  Training loss = 2.3387  Validation loss = 6.3276  \n",
      "\n",
      "Fold: 15  Epoch: 76  Training loss = 2.3382  Validation loss = 6.3266  \n",
      "\n",
      "Fold: 15  Epoch: 77  Training loss = 2.3377  Validation loss = 6.3237  \n",
      "\n",
      "Fold: 15  Epoch: 78  Training loss = 2.3369  Validation loss = 6.3225  \n",
      "\n",
      "Fold: 15  Epoch: 79  Training loss = 2.3361  Validation loss = 6.3196  \n",
      "\n",
      "Fold: 15  Epoch: 80  Training loss = 2.3358  Validation loss = 6.3176  \n",
      "\n",
      "Fold: 15  Epoch: 81  Training loss = 2.3358  Validation loss = 6.3160  \n",
      "\n",
      "Fold: 15  Epoch: 82  Training loss = 2.3344  Validation loss = 6.3146  \n",
      "\n",
      "Fold: 15  Epoch: 83  Training loss = 2.3339  Validation loss = 6.3131  \n",
      "\n",
      "Fold: 15  Epoch: 84  Training loss = 2.3334  Validation loss = 6.3110  \n",
      "\n",
      "Fold: 15  Epoch: 85  Training loss = 2.3326  Validation loss = 6.3097  \n",
      "\n",
      "Fold: 15  Epoch: 86  Training loss = 2.3331  Validation loss = 6.3078  \n",
      "\n",
      "Fold: 15  Epoch: 87  Training loss = 2.3327  Validation loss = 6.3062  \n",
      "\n",
      "Fold: 15  Epoch: 88  Training loss = 2.3324  Validation loss = 6.3039  \n",
      "\n",
      "Fold: 15  Epoch: 89  Training loss = 2.3316  Validation loss = 6.3024  \n",
      "\n",
      "Fold: 15  Epoch: 90  Training loss = 2.3304  Validation loss = 6.2998  \n",
      "\n",
      "Fold: 15  Epoch: 91  Training loss = 2.3301  Validation loss = 6.2962  \n",
      "\n",
      "Fold: 15  Epoch: 92  Training loss = 2.3293  Validation loss = 6.2952  \n",
      "\n",
      "Fold: 15  Epoch: 93  Training loss = 2.3286  Validation loss = 6.2917  \n",
      "\n",
      "Fold: 15  Epoch: 94  Training loss = 2.3273  Validation loss = 6.2911  \n",
      "\n",
      "Fold: 15  Epoch: 95  Training loss = 2.3262  Validation loss = 6.2893  \n",
      "\n",
      "Fold: 15  Epoch: 96  Training loss = 2.3259  Validation loss = 6.2868  \n",
      "\n",
      "Fold: 15  Epoch: 97  Training loss = 2.3264  Validation loss = 6.2849  \n",
      "\n",
      "Fold: 15  Epoch: 98  Training loss = 2.3262  Validation loss = 6.2832  \n",
      "\n",
      "Fold: 15  Epoch: 99  Training loss = 2.3253  Validation loss = 6.2827  \n",
      "\n",
      "Fold: 15  Epoch: 100  Training loss = 2.3241  Validation loss = 6.2806  \n",
      "\n",
      "Fold: 15  Epoch: 101  Training loss = 2.3236  Validation loss = 6.2789  \n",
      "\n",
      "Fold: 15  Epoch: 102  Training loss = 2.3234  Validation loss = 6.2781  \n",
      "\n",
      "Fold: 15  Epoch: 103  Training loss = 2.3221  Validation loss = 6.2760  \n",
      "\n",
      "Fold: 15  Epoch: 104  Training loss = 2.3210  Validation loss = 6.2741  \n",
      "\n",
      "Fold: 15  Epoch: 105  Training loss = 2.3205  Validation loss = 6.2724  \n",
      "\n",
      "Fold: 15  Epoch: 106  Training loss = 2.3203  Validation loss = 6.2701  \n",
      "\n",
      "Fold: 15  Epoch: 107  Training loss = 2.3192  Validation loss = 6.2682  \n",
      "\n",
      "Fold: 15  Epoch: 108  Training loss = 2.3186  Validation loss = 6.2670  \n",
      "\n",
      "Fold: 15  Epoch: 109  Training loss = 2.3184  Validation loss = 6.2661  \n",
      "\n",
      "Fold: 15  Epoch: 110  Training loss = 2.3178  Validation loss = 6.2643  \n",
      "\n",
      "Fold: 15  Epoch: 111  Training loss = 2.3170  Validation loss = 6.2620  \n",
      "\n",
      "Fold: 15  Epoch: 112  Training loss = 2.3163  Validation loss = 6.2600  \n",
      "\n",
      "Fold: 15  Epoch: 113  Training loss = 2.3154  Validation loss = 6.2575  \n",
      "\n",
      "Fold: 15  Epoch: 114  Training loss = 2.3149  Validation loss = 6.2557  \n",
      "\n",
      "Fold: 15  Epoch: 115  Training loss = 2.3139  Validation loss = 6.2532  \n",
      "\n",
      "Fold: 15  Epoch: 116  Training loss = 2.3136  Validation loss = 6.2520  \n",
      "\n",
      "Fold: 15  Epoch: 117  Training loss = 2.3132  Validation loss = 6.2494  \n",
      "\n",
      "Fold: 15  Epoch: 118  Training loss = 2.3134  Validation loss = 6.2469  \n",
      "\n",
      "Fold: 15  Epoch: 119  Training loss = 2.3124  Validation loss = 6.2461  \n",
      "\n",
      "Fold: 15  Epoch: 120  Training loss = 2.3112  Validation loss = 6.2442  \n",
      "\n",
      "Fold: 15  Epoch: 121  Training loss = 2.3110  Validation loss = 6.2430  \n",
      "\n",
      "Fold: 15  Epoch: 122  Training loss = 2.3111  Validation loss = 6.2411  \n",
      "\n",
      "Fold: 15  Epoch: 123  Training loss = 2.3098  Validation loss = 6.2383  \n",
      "\n",
      "Fold: 15  Epoch: 124  Training loss = 2.3089  Validation loss = 6.2382  \n",
      "\n",
      "Fold: 15  Epoch: 125  Training loss = 2.3082  Validation loss = 6.2358  \n",
      "\n",
      "Fold: 15  Epoch: 126  Training loss = 2.3078  Validation loss = 6.2346  \n",
      "\n",
      "Fold: 15  Epoch: 127  Training loss = 2.3070  Validation loss = 6.2318  \n",
      "\n",
      "Fold: 15  Epoch: 128  Training loss = 2.3065  Validation loss = 6.2291  \n",
      "\n",
      "Fold: 15  Epoch: 129  Training loss = 2.3057  Validation loss = 6.2275  \n",
      "\n",
      "Fold: 15  Epoch: 130  Training loss = 2.3051  Validation loss = 6.2254  \n",
      "\n",
      "Fold: 15  Epoch: 131  Training loss = 2.3043  Validation loss = 6.2237  \n",
      "\n",
      "Fold: 15  Epoch: 132  Training loss = 2.3040  Validation loss = 6.2216  \n",
      "\n",
      "Fold: 15  Epoch: 133  Training loss = 2.3036  Validation loss = 6.2206  \n",
      "\n",
      "Fold: 15  Epoch: 134  Training loss = 2.3027  Validation loss = 6.2194  \n",
      "\n",
      "Fold: 15  Epoch: 135  Training loss = 2.3023  Validation loss = 6.2181  \n",
      "\n",
      "Fold: 15  Epoch: 136  Training loss = 2.3018  Validation loss = 6.2168  \n",
      "\n",
      "Fold: 15  Epoch: 137  Training loss = 2.3011  Validation loss = 6.2149  \n",
      "\n",
      "Fold: 15  Epoch: 138  Training loss = 2.3003  Validation loss = 6.2126  \n",
      "\n",
      "Fold: 15  Epoch: 139  Training loss = 2.2998  Validation loss = 6.2111  \n",
      "\n",
      "Fold: 15  Epoch: 140  Training loss = 2.2994  Validation loss = 6.2093  \n",
      "\n",
      "Fold: 15  Epoch: 141  Training loss = 2.3003  Validation loss = 6.2073  \n",
      "\n",
      "Fold: 15  Epoch: 142  Training loss = 2.2993  Validation loss = 6.2052  \n",
      "\n",
      "Fold: 15  Epoch: 143  Training loss = 2.2991  Validation loss = 6.2040  \n",
      "\n",
      "Fold: 15  Epoch: 144  Training loss = 2.2971  Validation loss = 6.2029  \n",
      "\n",
      "Fold: 15  Epoch: 145  Training loss = 2.2963  Validation loss = 6.1999  \n",
      "\n",
      "Fold: 15  Epoch: 146  Training loss = 2.2960  Validation loss = 6.1988  \n",
      "\n",
      "Fold: 15  Epoch: 147  Training loss = 2.2955  Validation loss = 6.1964  \n",
      "\n",
      "Fold: 15  Epoch: 148  Training loss = 2.2949  Validation loss = 6.1950  \n",
      "\n",
      "Fold: 15  Epoch: 149  Training loss = 2.2948  Validation loss = 6.1935  \n",
      "\n",
      "Fold: 15  Epoch: 150  Training loss = 2.2940  Validation loss = 6.1923  \n",
      "\n",
      "Fold: 15  Epoch: 151  Training loss = 2.2926  Validation loss = 6.1892  \n",
      "\n",
      "Fold: 15  Epoch: 152  Training loss = 2.2922  Validation loss = 6.1869  \n",
      "\n",
      "Fold: 15  Epoch: 153  Training loss = 2.2921  Validation loss = 6.1853  \n",
      "\n",
      "Fold: 15  Epoch: 154  Training loss = 2.2914  Validation loss = 6.1827  \n",
      "\n",
      "Fold: 15  Epoch: 155  Training loss = 2.2933  Validation loss = 6.1821  \n",
      "\n",
      "Fold: 15  Epoch: 156  Training loss = 2.2899  Validation loss = 6.1781  \n",
      "\n",
      "Fold: 15  Epoch: 157  Training loss = 2.2885  Validation loss = 6.1754  \n",
      "\n",
      "Fold: 15  Epoch: 158  Training loss = 2.2873  Validation loss = 6.1725  \n",
      "\n",
      "Fold: 15  Epoch: 159  Training loss = 2.2868  Validation loss = 6.1710  \n",
      "\n",
      "Fold: 15  Epoch: 160  Training loss = 2.2870  Validation loss = 6.1704  \n",
      "\n",
      "Fold: 15  Epoch: 161  Training loss = 2.2865  Validation loss = 6.1697  \n",
      "\n",
      "Fold: 15  Epoch: 162  Training loss = 2.2850  Validation loss = 6.1665  \n",
      "\n",
      "Fold: 15  Epoch: 163  Training loss = 2.2845  Validation loss = 6.1647  \n",
      "\n",
      "Fold: 15  Epoch: 164  Training loss = 2.2841  Validation loss = 6.1635  \n",
      "\n",
      "Fold: 15  Epoch: 165  Training loss = 2.2834  Validation loss = 6.1617  \n",
      "\n",
      "Fold: 15  Epoch: 166  Training loss = 2.2831  Validation loss = 6.1594  \n",
      "\n",
      "Fold: 15  Epoch: 167  Training loss = 2.2823  Validation loss = 6.1584  \n",
      "\n",
      "Fold: 15  Epoch: 168  Training loss = 2.2820  Validation loss = 6.1577  \n",
      "\n",
      "Fold: 15  Epoch: 169  Training loss = 2.2817  Validation loss = 6.1561  \n",
      "\n",
      "Fold: 15  Epoch: 170  Training loss = 2.2808  Validation loss = 6.1540  \n",
      "\n",
      "Fold: 15  Epoch: 171  Training loss = 2.2800  Validation loss = 6.1513  \n",
      "\n",
      "Fold: 15  Epoch: 172  Training loss = 2.2800  Validation loss = 6.1504  \n",
      "\n",
      "Fold: 15  Epoch: 173  Training loss = 2.2798  Validation loss = 6.1484  \n",
      "\n",
      "Fold: 15  Epoch: 174  Training loss = 2.2794  Validation loss = 6.1469  \n",
      "\n",
      "Fold: 15  Epoch: 175  Training loss = 2.2790  Validation loss = 6.1452  \n",
      "\n",
      "Fold: 15  Epoch: 176  Training loss = 2.2772  Validation loss = 6.1423  \n",
      "\n",
      "Fold: 15  Epoch: 177  Training loss = 2.2765  Validation loss = 6.1399  \n",
      "\n",
      "Fold: 15  Epoch: 178  Training loss = 2.2758  Validation loss = 6.1386  \n",
      "\n",
      "Fold: 15  Epoch: 179  Training loss = 2.2755  Validation loss = 6.1375  \n",
      "\n",
      "Fold: 15  Epoch: 180  Training loss = 2.2748  Validation loss = 6.1345  \n",
      "\n",
      "Fold: 15  Epoch: 181  Training loss = 2.2734  Validation loss = 6.1314  \n",
      "\n",
      "Fold: 15  Epoch: 182  Training loss = 2.2733  Validation loss = 6.1297  \n",
      "\n",
      "Fold: 15  Epoch: 183  Training loss = 2.2724  Validation loss = 6.1272  \n",
      "\n",
      "Fold: 15  Epoch: 184  Training loss = 2.2718  Validation loss = 6.1271  \n",
      "\n",
      "Fold: 15  Epoch: 185  Training loss = 2.2721  Validation loss = 6.1271  \n",
      "\n",
      "Fold: 15  Epoch: 186  Training loss = 2.2716  Validation loss = 6.1263  \n",
      "\n",
      "Fold: 15  Epoch: 187  Training loss = 2.2709  Validation loss = 6.1242  \n",
      "\n",
      "Fold: 15  Epoch: 188  Training loss = 2.2706  Validation loss = 6.1229  \n",
      "\n",
      "Fold: 15  Epoch: 189  Training loss = 2.2702  Validation loss = 6.1206  \n",
      "\n",
      "Fold: 15  Epoch: 190  Training loss = 2.2693  Validation loss = 6.1184  \n",
      "\n",
      "Fold: 15  Epoch: 191  Training loss = 2.2692  Validation loss = 6.1159  \n",
      "\n",
      "Fold: 15  Epoch: 192  Training loss = 2.2679  Validation loss = 6.1133  \n",
      "\n",
      "Fold: 15  Epoch: 193  Training loss = 2.2673  Validation loss = 6.1122  \n",
      "\n",
      "Fold: 15  Epoch: 194  Training loss = 2.2662  Validation loss = 6.1106  \n",
      "\n",
      "Fold: 15  Epoch: 195  Training loss = 2.2651  Validation loss = 6.1076  \n",
      "\n",
      "Fold: 15  Epoch: 196  Training loss = 2.2645  Validation loss = 6.1055  \n",
      "\n",
      "Fold: 15  Epoch: 197  Training loss = 2.2639  Validation loss = 6.1043  \n",
      "\n",
      "Fold: 15  Epoch: 198  Training loss = 2.2642  Validation loss = 6.1026  \n",
      "\n",
      "Fold: 15  Epoch: 199  Training loss = 2.2632  Validation loss = 6.1013  \n",
      "\n",
      "Fold: 15  Epoch: 200  Training loss = 2.2626  Validation loss = 6.1009  \n",
      "\n",
      "Fold: 15  Epoch: 201  Training loss = 2.2621  Validation loss = 6.0990  \n",
      "\n",
      "Fold: 15  Epoch: 202  Training loss = 2.2614  Validation loss = 6.0969  \n",
      "\n",
      "Fold: 15  Epoch: 203  Training loss = 2.2618  Validation loss = 6.0944  \n",
      "\n",
      "Fold: 15  Epoch: 204  Training loss = 2.2607  Validation loss = 6.0938  \n",
      "\n",
      "Fold: 15  Epoch: 205  Training loss = 2.2599  Validation loss = 6.0928  \n",
      "\n",
      "Fold: 15  Epoch: 206  Training loss = 2.2598  Validation loss = 6.0923  \n",
      "\n",
      "Fold: 15  Epoch: 207  Training loss = 2.2593  Validation loss = 6.0909  \n",
      "\n",
      "Fold: 15  Epoch: 208  Training loss = 2.2598  Validation loss = 6.0907  \n",
      "\n",
      "Fold: 15  Epoch: 209  Training loss = 2.2591  Validation loss = 6.0879  \n",
      "\n",
      "Fold: 15  Epoch: 210  Training loss = 2.2582  Validation loss = 6.0874  \n",
      "\n",
      "Fold: 15  Epoch: 211  Training loss = 2.2579  Validation loss = 6.0869  \n",
      "\n",
      "Fold: 15  Epoch: 212  Training loss = 2.2571  Validation loss = 6.0845  \n",
      "\n",
      "Fold: 15  Epoch: 213  Training loss = 2.2564  Validation loss = 6.0816  \n",
      "\n",
      "Fold: 15  Epoch: 214  Training loss = 2.2574  Validation loss = 6.0814  \n",
      "\n",
      "Fold: 15  Epoch: 215  Training loss = 2.2555  Validation loss = 6.0795  \n",
      "\n",
      "Fold: 15  Epoch: 216  Training loss = 2.2549  Validation loss = 6.0781  \n",
      "\n",
      "Fold: 15  Epoch: 217  Training loss = 2.2552  Validation loss = 6.0781  \n",
      "\n",
      "Fold: 15  Epoch: 218  Training loss = 2.2542  Validation loss = 6.0762  \n",
      "\n",
      "Fold: 15  Epoch: 219  Training loss = 2.2541  Validation loss = 6.0745  \n",
      "\n",
      "Fold: 15  Epoch: 220  Training loss = 2.2535  Validation loss = 6.0738  \n",
      "\n",
      "Fold: 15  Epoch: 221  Training loss = 2.2531  Validation loss = 6.0727  \n",
      "\n",
      "Fold: 15  Epoch: 222  Training loss = 2.2527  Validation loss = 6.0714  \n",
      "\n",
      "Fold: 15  Epoch: 223  Training loss = 2.2524  Validation loss = 6.0707  \n",
      "\n",
      "Fold: 15  Epoch: 224  Training loss = 2.2517  Validation loss = 6.0691  \n",
      "\n",
      "Fold: 15  Epoch: 225  Training loss = 2.2513  Validation loss = 6.0679  \n",
      "\n",
      "Fold: 15  Epoch: 226  Training loss = 2.2506  Validation loss = 6.0668  \n",
      "\n",
      "Fold: 15  Epoch: 227  Training loss = 2.2497  Validation loss = 6.0645  \n",
      "\n",
      "Fold: 15  Epoch: 228  Training loss = 2.2492  Validation loss = 6.0631  \n",
      "\n",
      "Fold: 15  Epoch: 229  Training loss = 2.2487  Validation loss = 6.0615  \n",
      "\n",
      "Fold: 15  Epoch: 230  Training loss = 2.2492  Validation loss = 6.0617  \n",
      "\n",
      "Fold: 15  Epoch: 231  Training loss = 2.2480  Validation loss = 6.0602  \n",
      "\n",
      "Fold: 15  Epoch: 232  Training loss = 2.2477  Validation loss = 6.0582  \n",
      "\n",
      "Fold: 15  Epoch: 233  Training loss = 2.2469  Validation loss = 6.0568  \n",
      "\n",
      "Fold: 15  Epoch: 234  Training loss = 2.2461  Validation loss = 6.0545  \n",
      "\n",
      "Fold: 15  Epoch: 235  Training loss = 2.2458  Validation loss = 6.0532  \n",
      "\n",
      "Fold: 15  Epoch: 236  Training loss = 2.2456  Validation loss = 6.0522  \n",
      "\n",
      "Fold: 15  Epoch: 237  Training loss = 2.2455  Validation loss = 6.0507  \n",
      "\n",
      "Fold: 15  Epoch: 238  Training loss = 2.2442  Validation loss = 6.0490  \n",
      "\n",
      "Fold: 15  Epoch: 239  Training loss = 2.2434  Validation loss = 6.0471  \n",
      "\n",
      "Fold: 15  Epoch: 240  Training loss = 2.2435  Validation loss = 6.0464  \n",
      "\n",
      "Fold: 15  Epoch: 241  Training loss = 2.2422  Validation loss = 6.0433  \n",
      "\n",
      "Fold: 15  Epoch: 242  Training loss = 2.2430  Validation loss = 6.0405  \n",
      "\n",
      "Fold: 15  Epoch: 243  Training loss = 2.2418  Validation loss = 6.0390  \n",
      "\n",
      "Fold: 15  Epoch: 244  Training loss = 2.2422  Validation loss = 6.0374  \n",
      "\n",
      "Fold: 15  Epoch: 245  Training loss = 2.2417  Validation loss = 6.0346  \n",
      "\n",
      "Fold: 15  Epoch: 246  Training loss = 2.2403  Validation loss = 6.0333  \n",
      "\n",
      "Fold: 15  Epoch: 247  Training loss = 2.2391  Validation loss = 6.0318  \n",
      "\n",
      "Fold: 15  Epoch: 248  Training loss = 2.2383  Validation loss = 6.0315  \n",
      "\n",
      "Fold: 15  Epoch: 249  Training loss = 2.2385  Validation loss = 6.0296  \n",
      "\n",
      "Fold: 15  Epoch: 250  Training loss = 2.2379  Validation loss = 6.0277  \n",
      "\n",
      "Fold: 15  Epoch: 251  Training loss = 2.2385  Validation loss = 6.0255  \n",
      "\n",
      "Fold: 15  Epoch: 252  Training loss = 2.2369  Validation loss = 6.0247  \n",
      "\n",
      "Fold: 15  Epoch: 253  Training loss = 2.2362  Validation loss = 6.0226  \n",
      "\n",
      "Fold: 15  Epoch: 254  Training loss = 2.2350  Validation loss = 6.0215  \n",
      "\n",
      "Fold: 15  Epoch: 255  Training loss = 2.2347  Validation loss = 6.0198  \n",
      "\n",
      "Fold: 15  Epoch: 256  Training loss = 2.2347  Validation loss = 6.0185  \n",
      "\n",
      "Fold: 15  Epoch: 257  Training loss = 2.2336  Validation loss = 6.0172  \n",
      "\n",
      "Fold: 15  Epoch: 258  Training loss = 2.2331  Validation loss = 6.0160  \n",
      "\n",
      "Fold: 15  Epoch: 259  Training loss = 2.2325  Validation loss = 6.0148  \n",
      "\n",
      "Fold: 15  Epoch: 260  Training loss = 2.2321  Validation loss = 6.0143  \n",
      "\n",
      "Fold: 15  Epoch: 261  Training loss = 2.2313  Validation loss = 6.0123  \n",
      "\n",
      "Fold: 15  Epoch: 262  Training loss = 2.2306  Validation loss = 6.0098  \n",
      "\n",
      "Fold: 15  Epoch: 263  Training loss = 2.2304  Validation loss = 6.0086  \n",
      "\n",
      "Fold: 15  Epoch: 264  Training loss = 2.2297  Validation loss = 6.0075  \n",
      "\n",
      "Fold: 15  Epoch: 265  Training loss = 2.2296  Validation loss = 6.0064  \n",
      "\n",
      "Fold: 15  Epoch: 266  Training loss = 2.2297  Validation loss = 6.0063  \n",
      "\n",
      "Fold: 15  Epoch: 267  Training loss = 2.2288  Validation loss = 6.0053  \n",
      "\n",
      "Fold: 15  Epoch: 268  Training loss = 2.2281  Validation loss = 6.0040  \n",
      "\n",
      "Fold: 15  Epoch: 269  Training loss = 2.2283  Validation loss = 6.0029  \n",
      "\n",
      "Fold: 15  Epoch: 270  Training loss = 2.2269  Validation loss = 6.0004  \n",
      "\n",
      "Fold: 15  Epoch: 271  Training loss = 2.2264  Validation loss = 5.9974  \n",
      "\n",
      "Fold: 15  Epoch: 272  Training loss = 2.2255  Validation loss = 5.9949  \n",
      "\n",
      "Fold: 15  Epoch: 273  Training loss = 2.2251  Validation loss = 5.9940  \n",
      "\n",
      "Fold: 15  Epoch: 274  Training loss = 2.2249  Validation loss = 5.9923  \n",
      "\n",
      "Fold: 15  Epoch: 275  Training loss = 2.2241  Validation loss = 5.9917  \n",
      "\n",
      "Fold: 15  Epoch: 276  Training loss = 2.2238  Validation loss = 5.9907  \n",
      "\n",
      "Fold: 15  Epoch: 277  Training loss = 2.2232  Validation loss = 5.9890  \n",
      "\n",
      "Fold: 15  Epoch: 278  Training loss = 2.2227  Validation loss = 5.9875  \n",
      "\n",
      "Fold: 15  Epoch: 279  Training loss = 2.2218  Validation loss = 5.9853  \n",
      "\n",
      "Fold: 15  Epoch: 280  Training loss = 2.2214  Validation loss = 5.9836  \n",
      "\n",
      "Fold: 15  Epoch: 281  Training loss = 2.2210  Validation loss = 5.9827  \n",
      "\n",
      "Fold: 15  Epoch: 282  Training loss = 2.2210  Validation loss = 5.9809  \n",
      "\n",
      "Fold: 15  Epoch: 283  Training loss = 2.2201  Validation loss = 5.9798  \n",
      "\n",
      "Fold: 15  Epoch: 284  Training loss = 2.2200  Validation loss = 5.9786  \n",
      "\n",
      "Fold: 15  Epoch: 285  Training loss = 2.2219  Validation loss = 5.9763  \n",
      "\n",
      "Fold: 15  Epoch: 286  Training loss = 2.2213  Validation loss = 5.9736  \n",
      "\n",
      "Fold: 15  Epoch: 287  Training loss = 2.2209  Validation loss = 5.9721  \n",
      "\n",
      "Fold: 15  Epoch: 288  Training loss = 2.2208  Validation loss = 5.9700  \n",
      "\n",
      "Fold: 15  Epoch: 289  Training loss = 2.2192  Validation loss = 5.9693  \n",
      "\n",
      "Fold: 15  Epoch: 290  Training loss = 2.2178  Validation loss = 5.9701  \n",
      "\n",
      "Fold: 15  Epoch: 291  Training loss = 2.2205  Validation loss = 5.9682  \n",
      "\n",
      "Fold: 15  Epoch: 292  Training loss = 2.2195  Validation loss = 5.9663  \n",
      "\n",
      "Fold: 15  Epoch: 293  Training loss = 2.2186  Validation loss = 5.9658  \n",
      "\n",
      "Fold: 15  Epoch: 294  Training loss = 2.2165  Validation loss = 5.9656  \n",
      "\n",
      "Fold: 15  Epoch: 295  Training loss = 2.2157  Validation loss = 5.9644  \n",
      "\n",
      "Fold: 15  Epoch: 296  Training loss = 2.2144  Validation loss = 5.9622  \n",
      "\n",
      "Fold: 15  Epoch: 297  Training loss = 2.2138  Validation loss = 5.9617  \n",
      "\n",
      "Fold: 15  Epoch: 298  Training loss = 2.2135  Validation loss = 5.9609  \n",
      "\n",
      "Fold: 15  Epoch: 299  Training loss = 2.2127  Validation loss = 5.9586  \n",
      "\n",
      "Fold: 15  Epoch: 300  Training loss = 2.2127  Validation loss = 5.9553  \n",
      "\n",
      "Fold: 15  Epoch: 301  Training loss = 2.2120  Validation loss = 5.9552  \n",
      "\n",
      "Fold: 15  Epoch: 302  Training loss = 2.2119  Validation loss = 5.9532  \n",
      "\n",
      "Fold: 15  Epoch: 303  Training loss = 2.2109  Validation loss = 5.9523  \n",
      "\n",
      "Fold: 15  Epoch: 304  Training loss = 2.2109  Validation loss = 5.9512  \n",
      "\n",
      "Fold: 15  Epoch: 305  Training loss = 2.2101  Validation loss = 5.9494  \n",
      "\n",
      "Fold: 15  Epoch: 306  Training loss = 2.2102  Validation loss = 5.9486  \n",
      "\n",
      "Fold: 15  Epoch: 307  Training loss = 2.2095  Validation loss = 5.9473  \n",
      "\n",
      "Fold: 15  Epoch: 308  Training loss = 2.2087  Validation loss = 5.9470  \n",
      "\n",
      "Fold: 15  Epoch: 309  Training loss = 2.2084  Validation loss = 5.9459  \n",
      "\n",
      "Fold: 15  Epoch: 310  Training loss = 2.2079  Validation loss = 5.9445  \n",
      "\n",
      "Fold: 15  Epoch: 311  Training loss = 2.2072  Validation loss = 5.9426  \n",
      "\n",
      "Fold: 15  Epoch: 312  Training loss = 2.2071  Validation loss = 5.9418  \n",
      "\n",
      "Fold: 15  Epoch: 313  Training loss = 2.2065  Validation loss = 5.9390  \n",
      "\n",
      "Fold: 15  Epoch: 314  Training loss = 2.2073  Validation loss = 5.9366  \n",
      "\n",
      "Fold: 15  Epoch: 315  Training loss = 2.2068  Validation loss = 5.9350  \n",
      "\n",
      "Fold: 15  Epoch: 316  Training loss = 2.2058  Validation loss = 5.9330  \n",
      "\n",
      "Fold: 15  Epoch: 317  Training loss = 2.2063  Validation loss = 5.9321  \n",
      "\n",
      "Fold: 15  Epoch: 318  Training loss = 2.2058  Validation loss = 5.9313  \n",
      "\n",
      "Fold: 15  Epoch: 319  Training loss = 2.2046  Validation loss = 5.9309  \n",
      "\n",
      "Fold: 15  Epoch: 320  Training loss = 2.2042  Validation loss = 5.9297  \n",
      "\n",
      "Fold: 15  Epoch: 321  Training loss = 2.2033  Validation loss = 5.9270  \n",
      "\n",
      "Fold: 15  Epoch: 322  Training loss = 2.2027  Validation loss = 5.9268  \n",
      "\n",
      "Fold: 15  Epoch: 323  Training loss = 2.2021  Validation loss = 5.9252  \n",
      "\n",
      "Fold: 15  Epoch: 324  Training loss = 2.2019  Validation loss = 5.9237  \n",
      "\n",
      "Fold: 15  Epoch: 325  Training loss = 2.2015  Validation loss = 5.9225  \n",
      "\n",
      "Fold: 15  Epoch: 326  Training loss = 2.2007  Validation loss = 5.9209  \n",
      "\n",
      "Fold: 15  Epoch: 327  Training loss = 2.2001  Validation loss = 5.9187  \n",
      "\n",
      "Fold: 15  Epoch: 328  Training loss = 2.2006  Validation loss = 5.9173  \n",
      "\n",
      "Fold: 15  Epoch: 329  Training loss = 2.2011  Validation loss = 5.9157  \n",
      "\n",
      "Fold: 15  Epoch: 330  Training loss = 2.2012  Validation loss = 5.9155  \n",
      "\n",
      "Fold: 15  Epoch: 331  Training loss = 2.2009  Validation loss = 5.9145  \n",
      "\n",
      "Fold: 15  Epoch: 332  Training loss = 2.1990  Validation loss = 5.9129  \n",
      "\n",
      "Fold: 15  Epoch: 333  Training loss = 2.1981  Validation loss = 5.9104  \n",
      "\n",
      "Fold: 15  Epoch: 334  Training loss = 2.1981  Validation loss = 5.9099  \n",
      "\n",
      "Fold: 15  Epoch: 335  Training loss = 2.1978  Validation loss = 5.9089  \n",
      "\n",
      "Fold: 15  Epoch: 336  Training loss = 2.1970  Validation loss = 5.9074  \n",
      "\n",
      "Fold: 15  Epoch: 337  Training loss = 2.1961  Validation loss = 5.9054  \n",
      "\n",
      "Fold: 15  Epoch: 338  Training loss = 2.1957  Validation loss = 5.9051  \n",
      "\n",
      "Fold: 15  Epoch: 339  Training loss = 2.1951  Validation loss = 5.9043  \n",
      "\n",
      "Fold: 15  Epoch: 340  Training loss = 2.1943  Validation loss = 5.9012  \n",
      "\n",
      "Fold: 15  Epoch: 341  Training loss = 2.1939  Validation loss = 5.9000  \n",
      "\n",
      "Fold: 15  Epoch: 342  Training loss = 2.1932  Validation loss = 5.8979  \n",
      "\n",
      "Fold: 15  Epoch: 343  Training loss = 2.1929  Validation loss = 5.8958  \n",
      "\n",
      "Fold: 15  Epoch: 344  Training loss = 2.1927  Validation loss = 5.8946  \n",
      "\n",
      "Fold: 15  Epoch: 345  Training loss = 2.1920  Validation loss = 5.8942  \n",
      "\n",
      "Fold: 15  Epoch: 346  Training loss = 2.1923  Validation loss = 5.8925  \n",
      "\n",
      "Fold: 15  Epoch: 347  Training loss = 2.1916  Validation loss = 5.8909  \n",
      "\n",
      "Fold: 15  Epoch: 348  Training loss = 2.1915  Validation loss = 5.8877  \n",
      "\n",
      "Fold: 15  Epoch: 349  Training loss = 2.1913  Validation loss = 5.8869  \n",
      "\n",
      "Fold: 15  Epoch: 350  Training loss = 2.1904  Validation loss = 5.8860  \n",
      "\n",
      "Fold: 15  Epoch: 351  Training loss = 2.1915  Validation loss = 5.8834  \n",
      "\n",
      "Fold: 15  Epoch: 352  Training loss = 2.1897  Validation loss = 5.8829  \n",
      "\n",
      "Fold: 15  Epoch: 353  Training loss = 2.1886  Validation loss = 5.8828  \n",
      "\n",
      "Fold: 15  Epoch: 354  Training loss = 2.1880  Validation loss = 5.8808  \n",
      "\n",
      "Fold: 15  Epoch: 355  Training loss = 2.1876  Validation loss = 5.8791  \n",
      "\n",
      "Fold: 15  Epoch: 356  Training loss = 2.1870  Validation loss = 5.8780  \n",
      "\n",
      "Fold: 15  Epoch: 357  Training loss = 2.1866  Validation loss = 5.8759  \n",
      "\n",
      "Fold: 15  Epoch: 358  Training loss = 2.1869  Validation loss = 5.8746  \n",
      "\n",
      "Fold: 15  Epoch: 359  Training loss = 2.1868  Validation loss = 5.8737  \n",
      "\n",
      "Fold: 15  Epoch: 360  Training loss = 2.1861  Validation loss = 5.8732  \n",
      "\n",
      "Fold: 15  Epoch: 361  Training loss = 2.1870  Validation loss = 5.8718  \n",
      "\n",
      "Fold: 15  Epoch: 362  Training loss = 2.1866  Validation loss = 5.8704  \n",
      "\n",
      "Fold: 15  Epoch: 363  Training loss = 2.1854  Validation loss = 5.8700  \n",
      "\n",
      "Fold: 15  Epoch: 364  Training loss = 2.1840  Validation loss = 5.8698  \n",
      "\n",
      "Fold: 15  Epoch: 365  Training loss = 2.1834  Validation loss = 5.8678  \n",
      "\n",
      "Fold: 15  Epoch: 366  Training loss = 2.1840  Validation loss = 5.8677  \n",
      "\n",
      "Fold: 15  Epoch: 367  Training loss = 2.1829  Validation loss = 5.8663  \n",
      "\n",
      "Fold: 15  Epoch: 368  Training loss = 2.1826  Validation loss = 5.8652  \n",
      "\n",
      "Fold: 15  Epoch: 369  Training loss = 2.1822  Validation loss = 5.8638  \n",
      "\n",
      "Fold: 15  Epoch: 370  Training loss = 2.1814  Validation loss = 5.8614  \n",
      "\n",
      "Fold: 15  Epoch: 371  Training loss = 2.1813  Validation loss = 5.8592  \n",
      "\n",
      "Fold: 15  Epoch: 372  Training loss = 2.1810  Validation loss = 5.8573  \n",
      "\n",
      "Fold: 15  Epoch: 373  Training loss = 2.1808  Validation loss = 5.8546  \n",
      "\n",
      "Fold: 15  Epoch: 374  Training loss = 2.1797  Validation loss = 5.8542  \n",
      "\n",
      "Fold: 15  Epoch: 375  Training loss = 2.1790  Validation loss = 5.8532  \n",
      "\n",
      "Fold: 15  Epoch: 376  Training loss = 2.1788  Validation loss = 5.8523  \n",
      "\n",
      "Fold: 15  Epoch: 377  Training loss = 2.1780  Validation loss = 5.8496  \n",
      "\n",
      "Fold: 15  Epoch: 378  Training loss = 2.1779  Validation loss = 5.8495  \n",
      "\n",
      "Fold: 15  Epoch: 379  Training loss = 2.1776  Validation loss = 5.8487  \n",
      "\n",
      "Fold: 15  Epoch: 380  Training loss = 2.1787  Validation loss = 5.8471  \n",
      "\n",
      "Fold: 15  Epoch: 381  Training loss = 2.1789  Validation loss = 5.8458  \n",
      "\n",
      "Fold: 15  Epoch: 382  Training loss = 2.1791  Validation loss = 5.8439  \n",
      "\n",
      "Fold: 15  Epoch: 383  Training loss = 2.1790  Validation loss = 5.8441  \n",
      "\n",
      "Fold: 15  Epoch: 384  Training loss = 2.1798  Validation loss = 5.8432  \n",
      "\n",
      "Fold: 15  Epoch: 385  Training loss = 2.1792  Validation loss = 5.8414  \n",
      "\n",
      "Fold: 15  Epoch: 386  Training loss = 2.1762  Validation loss = 5.8389  \n",
      "\n",
      "Fold: 15  Epoch: 387  Training loss = 2.1745  Validation loss = 5.8379  \n",
      "\n",
      "Fold: 15  Epoch: 388  Training loss = 2.1743  Validation loss = 5.8380  \n",
      "\n",
      "Fold: 15  Epoch: 389  Training loss = 2.1739  Validation loss = 5.8362  \n",
      "\n",
      "Fold: 15  Epoch: 390  Training loss = 2.1736  Validation loss = 5.8350  \n",
      "\n",
      "Fold: 15  Epoch: 391  Training loss = 2.1731  Validation loss = 5.8333  \n",
      "\n",
      "Fold: 15  Epoch: 392  Training loss = 2.1733  Validation loss = 5.8331  \n",
      "\n",
      "Fold: 15  Epoch: 393  Training loss = 2.1733  Validation loss = 5.8320  \n",
      "\n",
      "Fold: 15  Epoch: 394  Training loss = 2.1745  Validation loss = 5.8319  \n",
      "\n",
      "Fold: 15  Epoch: 395  Training loss = 2.1718  Validation loss = 5.8297  \n",
      "\n",
      "Fold: 15  Epoch: 396  Training loss = 2.1706  Validation loss = 5.8262  \n",
      "\n",
      "Fold: 15  Epoch: 397  Training loss = 2.1705  Validation loss = 5.8243  \n",
      "\n",
      "Fold: 15  Epoch: 398  Training loss = 2.1695  Validation loss = 5.8227  \n",
      "\n",
      "Fold: 15  Epoch: 399  Training loss = 2.1693  Validation loss = 5.8223  \n",
      "\n",
      "Fold: 15  Epoch: 400  Training loss = 2.1686  Validation loss = 5.8198  \n",
      "\n",
      "Fold: 15  Epoch: 401  Training loss = 2.1687  Validation loss = 5.8177  \n",
      "\n",
      "Fold: 15  Epoch: 402  Training loss = 2.1688  Validation loss = 5.8180  \n",
      "\n",
      "Fold: 15  Epoch: 403  Training loss = 2.1705  Validation loss = 5.8175  \n",
      "\n",
      "Fold: 15  Epoch: 404  Training loss = 2.1695  Validation loss = 5.8171  \n",
      "\n",
      "Fold: 15  Epoch: 405  Training loss = 2.1684  Validation loss = 5.8158  \n",
      "\n",
      "Fold: 15  Epoch: 406  Training loss = 2.1680  Validation loss = 5.8143  \n",
      "\n",
      "Fold: 15  Epoch: 407  Training loss = 2.1665  Validation loss = 5.8129  \n",
      "\n",
      "Fold: 15  Epoch: 408  Training loss = 2.1663  Validation loss = 5.8119  \n",
      "\n",
      "Fold: 15  Epoch: 409  Training loss = 2.1667  Validation loss = 5.8110  \n",
      "\n",
      "Fold: 15  Epoch: 410  Training loss = 2.1657  Validation loss = 5.8101  \n",
      "\n",
      "Fold: 15  Epoch: 411  Training loss = 2.1653  Validation loss = 5.8092  \n",
      "\n",
      "Fold: 15  Epoch: 412  Training loss = 2.1650  Validation loss = 5.8081  \n",
      "\n",
      "Fold: 15  Epoch: 413  Training loss = 2.1647  Validation loss = 5.8074  \n",
      "\n",
      "Fold: 15  Epoch: 414  Training loss = 2.1643  Validation loss = 5.8061  \n",
      "\n",
      "Fold: 15  Epoch: 415  Training loss = 2.1639  Validation loss = 5.8044  \n",
      "\n",
      "Fold: 15  Epoch: 416  Training loss = 2.1641  Validation loss = 5.8035  \n",
      "\n",
      "Fold: 15  Epoch: 417  Training loss = 2.1634  Validation loss = 5.8027  \n",
      "\n",
      "Fold: 15  Epoch: 418  Training loss = 2.1628  Validation loss = 5.8010  \n",
      "\n",
      "Fold: 15  Epoch: 419  Training loss = 2.1625  Validation loss = 5.7996  \n",
      "\n",
      "Fold: 15  Epoch: 420  Training loss = 2.1631  Validation loss = 5.7981  \n",
      "\n",
      "Fold: 15  Epoch: 421  Training loss = 2.1624  Validation loss = 5.7976  \n",
      "\n",
      "Fold: 15  Epoch: 422  Training loss = 2.1616  Validation loss = 5.7969  \n",
      "\n",
      "Fold: 15  Epoch: 423  Training loss = 2.1611  Validation loss = 5.7955  \n",
      "\n",
      "Fold: 15  Epoch: 424  Training loss = 2.1608  Validation loss = 5.7940  \n",
      "\n",
      "Fold: 15  Epoch: 425  Training loss = 2.1604  Validation loss = 5.7926  \n",
      "\n",
      "Fold: 15  Epoch: 426  Training loss = 2.1597  Validation loss = 5.7897  \n",
      "\n",
      "Fold: 15  Epoch: 427  Training loss = 2.1593  Validation loss = 5.7886  \n",
      "\n",
      "Fold: 15  Epoch: 428  Training loss = 2.1591  Validation loss = 5.7872  \n",
      "\n",
      "Fold: 15  Epoch: 429  Training loss = 2.1587  Validation loss = 5.7861  \n",
      "\n",
      "Fold: 15  Epoch: 430  Training loss = 2.1587  Validation loss = 5.7856  \n",
      "\n",
      "Fold: 15  Epoch: 431  Training loss = 2.1599  Validation loss = 5.7841  \n",
      "\n",
      "Fold: 15  Epoch: 432  Training loss = 2.1586  Validation loss = 5.7824  \n",
      "\n",
      "Fold: 15  Epoch: 433  Training loss = 2.1583  Validation loss = 5.7799  \n",
      "\n",
      "Fold: 15  Epoch: 434  Training loss = 2.1585  Validation loss = 5.7793  \n",
      "\n",
      "Fold: 15  Epoch: 435  Training loss = 2.1590  Validation loss = 5.7780  \n",
      "\n",
      "Fold: 15  Epoch: 436  Training loss = 2.1572  Validation loss = 5.7761  \n",
      "\n",
      "Fold: 15  Epoch: 437  Training loss = 2.1570  Validation loss = 5.7746  \n",
      "\n",
      "Fold: 15  Epoch: 438  Training loss = 2.1562  Validation loss = 5.7740  \n",
      "\n",
      "Fold: 15  Epoch: 439  Training loss = 2.1554  Validation loss = 5.7728  \n",
      "\n",
      "Fold: 15  Epoch: 440  Training loss = 2.1547  Validation loss = 5.7711  \n",
      "\n",
      "Fold: 15  Epoch: 441  Training loss = 2.1559  Validation loss = 5.7705  \n",
      "\n",
      "Fold: 15  Epoch: 442  Training loss = 2.1583  Validation loss = 5.7710  \n",
      "\n",
      "Fold: 15  Epoch: 443  Training loss = 2.1584  Validation loss = 5.7700  \n",
      "\n",
      "Fold: 15  Epoch: 444  Training loss = 2.1560  Validation loss = 5.7685  \n",
      "\n",
      "Fold: 15  Epoch: 445  Training loss = 2.1537  Validation loss = 5.7675  \n",
      "\n",
      "Fold: 15  Epoch: 446  Training loss = 2.1527  Validation loss = 5.7657  \n",
      "\n",
      "Fold: 15  Epoch: 447  Training loss = 2.1524  Validation loss = 5.7643  \n",
      "\n",
      "Fold: 15  Epoch: 448  Training loss = 2.1523  Validation loss = 5.7635  \n",
      "\n",
      "Fold: 15  Epoch: 449  Training loss = 2.1514  Validation loss = 5.7613  \n",
      "\n",
      "Fold: 15  Epoch: 450  Training loss = 2.1510  Validation loss = 5.7601  \n",
      "\n",
      "Fold: 15  Epoch: 451  Training loss = 2.1510  Validation loss = 5.7595  \n",
      "\n",
      "Fold: 15  Epoch: 452  Training loss = 2.1503  Validation loss = 5.7583  \n",
      "\n",
      "Fold: 15  Epoch: 453  Training loss = 2.1501  Validation loss = 5.7569  \n",
      "\n",
      "Fold: 15  Epoch: 454  Training loss = 2.1494  Validation loss = 5.7548  \n",
      "\n",
      "Fold: 15  Epoch: 455  Training loss = 2.1490  Validation loss = 5.7531  \n",
      "\n",
      "Fold: 15  Epoch: 456  Training loss = 2.1500  Validation loss = 5.7512  \n",
      "\n",
      "Fold: 15  Epoch: 457  Training loss = 2.1497  Validation loss = 5.7499  \n",
      "\n",
      "Fold: 15  Epoch: 458  Training loss = 2.1485  Validation loss = 5.7487  \n",
      "\n",
      "Fold: 15  Epoch: 459  Training loss = 2.1479  Validation loss = 5.7486  \n",
      "\n",
      "Fold: 15  Epoch: 460  Training loss = 2.1473  Validation loss = 5.7473  \n",
      "\n",
      "Fold: 15  Epoch: 461  Training loss = 2.1468  Validation loss = 5.7457  \n",
      "\n",
      "Fold: 15  Epoch: 462  Training loss = 2.1467  Validation loss = 5.7456  \n",
      "\n",
      "Fold: 15  Epoch: 463  Training loss = 2.1464  Validation loss = 5.7444  \n",
      "\n",
      "Fold: 15  Epoch: 464  Training loss = 2.1457  Validation loss = 5.7422  \n",
      "\n",
      "Fold: 15  Epoch: 465  Training loss = 2.1454  Validation loss = 5.7410  \n",
      "\n",
      "Fold: 15  Epoch: 466  Training loss = 2.1454  Validation loss = 5.7407  \n",
      "\n",
      "Fold: 15  Epoch: 467  Training loss = 2.1455  Validation loss = 5.7395  \n",
      "\n",
      "Fold: 15  Epoch: 468  Training loss = 2.1447  Validation loss = 5.7387  \n",
      "\n",
      "Fold: 15  Epoch: 469  Training loss = 2.1443  Validation loss = 5.7371  \n",
      "\n",
      "Fold: 15  Epoch: 470  Training loss = 2.1442  Validation loss = 5.7362  \n",
      "\n",
      "Fold: 15  Epoch: 471  Training loss = 2.1438  Validation loss = 5.7356  \n",
      "\n",
      "Fold: 15  Epoch: 472  Training loss = 2.1439  Validation loss = 5.7349  \n",
      "\n",
      "Fold: 15  Epoch: 473  Training loss = 2.1436  Validation loss = 5.7356  \n",
      "\n",
      "Fold: 15  Epoch: 474  Training loss = 2.1433  Validation loss = 5.7350  \n",
      "\n",
      "Fold: 15  Epoch: 475  Training loss = 2.1433  Validation loss = 5.7351  \n",
      "\n",
      "Fold: 15  Epoch: 476  Training loss = 2.1436  Validation loss = 5.7350  \n",
      "\n",
      "Fold: 15  Epoch: 477  Training loss = 2.1430  Validation loss = 5.7338  \n",
      "\n",
      "Fold: 15  Epoch: 478  Training loss = 2.1434  Validation loss = 5.7332  \n",
      "\n",
      "Fold: 15  Epoch: 479  Training loss = 2.1439  Validation loss = 5.7329  \n",
      "\n",
      "Fold: 15  Epoch: 480  Training loss = 2.1429  Validation loss = 5.7313  \n",
      "\n",
      "Fold: 15  Epoch: 481  Training loss = 2.1426  Validation loss = 5.7302  \n",
      "\n",
      "Fold: 15  Epoch: 482  Training loss = 2.1413  Validation loss = 5.7286  \n",
      "\n",
      "Fold: 15  Epoch: 483  Training loss = 2.1412  Validation loss = 5.7276  \n",
      "\n",
      "Fold: 15  Epoch: 484  Training loss = 2.1407  Validation loss = 5.7267  \n",
      "\n",
      "Fold: 15  Epoch: 485  Training loss = 2.1402  Validation loss = 5.7250  \n",
      "\n",
      "Fold: 15  Epoch: 486  Training loss = 2.1396  Validation loss = 5.7233  \n",
      "\n",
      "Fold: 15  Epoch: 487  Training loss = 2.1394  Validation loss = 5.7221  \n",
      "\n",
      "Fold: 15  Epoch: 488  Training loss = 2.1392  Validation loss = 5.7221  \n",
      "\n",
      "Fold: 15  Epoch: 489  Training loss = 2.1391  Validation loss = 5.7212  \n",
      "\n",
      "Fold: 15  Epoch: 490  Training loss = 2.1390  Validation loss = 5.7203  \n",
      "\n",
      "Fold: 15  Epoch: 491  Training loss = 2.1396  Validation loss = 5.7195  \n",
      "\n",
      "Fold: 15  Epoch: 492  Training loss = 2.1401  Validation loss = 5.7194  \n",
      "\n",
      "Fold: 15  Epoch: 493  Training loss = 2.1376  Validation loss = 5.7170  \n",
      "\n",
      "Fold: 15  Epoch: 494  Training loss = 2.1374  Validation loss = 5.7163  \n",
      "\n",
      "Fold: 15  Epoch: 495  Training loss = 2.1385  Validation loss = 5.7169  \n",
      "\n",
      "Fold: 15  Epoch: 496  Training loss = 2.1373  Validation loss = 5.7145  \n",
      "\n",
      "Fold: 15  Epoch: 497  Training loss = 2.1362  Validation loss = 5.7128  \n",
      "\n",
      "Fold: 15  Epoch: 498  Training loss = 2.1358  Validation loss = 5.7114  \n",
      "\n",
      "Fold: 15  Epoch: 499  Training loss = 2.1353  Validation loss = 5.7087  \n",
      "\n",
      "Fold: 15  Epoch: 500  Training loss = 2.1350  Validation loss = 5.7081  \n",
      "\n",
      "Check model:  Fold: 15  Optimal epoch: 500  \n",
      "\n",
      "Fold: 16  Epoch: 1  Training loss = 2.5534  Validation loss = 4.1317  \n",
      "\n",
      "Fold: 16  Epoch: 2  Training loss = 2.5528  Validation loss = 4.1351  \n",
      "\n",
      "Fold: 16  Epoch: 3  Training loss = 2.5519  Validation loss = 4.1233  \n",
      "\n",
      "Fold: 16  Epoch: 4  Training loss = 2.5510  Validation loss = 4.1209  \n",
      "\n",
      "Fold: 16  Epoch: 5  Training loss = 2.5501  Validation loss = 4.1336  \n",
      "\n",
      "Fold: 16  Epoch: 6  Training loss = 2.5507  Validation loss = 4.1511  \n",
      "\n",
      "Fold: 16  Epoch: 7  Training loss = 2.5493  Validation loss = 4.1561  \n",
      "\n",
      "Fold: 16  Epoch: 8  Training loss = 2.5486  Validation loss = 4.1369  \n",
      "\n",
      "Fold: 16  Epoch: 9  Training loss = 2.5476  Validation loss = 4.1336  \n",
      "\n",
      "Fold: 16  Epoch: 10  Training loss = 2.5477  Validation loss = 4.1119  \n",
      "\n",
      "Fold: 16  Epoch: 11  Training loss = 2.5457  Validation loss = 4.1172  \n",
      "\n",
      "Fold: 16  Epoch: 12  Training loss = 2.5449  Validation loss = 4.1194  \n",
      "\n",
      "Fold: 16  Epoch: 13  Training loss = 2.5445  Validation loss = 4.1098  \n",
      "\n",
      "Fold: 16  Epoch: 14  Training loss = 2.5453  Validation loss = 4.0811  \n",
      "\n",
      "Fold: 16  Epoch: 15  Training loss = 2.5446  Validation loss = 4.0739  \n",
      "\n",
      "Fold: 16  Epoch: 16  Training loss = 2.5429  Validation loss = 4.0779  \n",
      "\n",
      "Fold: 16  Epoch: 17  Training loss = 2.5416  Validation loss = 4.0810  \n",
      "\n",
      "Fold: 16  Epoch: 18  Training loss = 2.5424  Validation loss = 4.0709  \n",
      "\n",
      "Fold: 16  Epoch: 19  Training loss = 2.5400  Validation loss = 4.0916  \n",
      "\n",
      "Fold: 16  Epoch: 20  Training loss = 2.5399  Validation loss = 4.0789  \n",
      "\n",
      "Fold: 16  Epoch: 21  Training loss = 2.5385  Validation loss = 4.0887  \n",
      "\n",
      "Fold: 16  Epoch: 22  Training loss = 2.5381  Validation loss = 4.0743  \n",
      "\n",
      "Fold: 16  Epoch: 23  Training loss = 2.5362  Validation loss = 4.0816  \n",
      "\n",
      "Fold: 16  Epoch: 24  Training loss = 2.5352  Validation loss = 4.0928  \n",
      "\n",
      "Check model:  Fold: 16  Optimal epoch: 18  \n",
      "\n",
      "Fold: 17  Epoch: 1  Training loss = 2.7238  Validation loss = 2.3599  \n",
      "\n",
      "Fold: 17  Epoch: 2  Training loss = 2.7206  Validation loss = 2.3603  \n",
      "\n",
      "Fold: 17  Epoch: 3  Training loss = 2.7180  Validation loss = 2.3608  \n",
      "\n",
      "Fold: 17  Epoch: 4  Training loss = 2.7150  Validation loss = 2.3722  \n",
      "\n",
      "Fold: 17  Epoch: 5  Training loss = 2.7108  Validation loss = 2.3816  \n",
      "\n",
      "Fold: 17  Epoch: 6  Training loss = 2.7079  Validation loss = 2.3926  \n",
      "\n",
      "Fold: 17  Epoch: 7  Training loss = 2.7056  Validation loss = 2.3994  \n",
      "\n",
      "Fold: 17  Epoch: 8  Training loss = 2.7020  Validation loss = 2.4017  \n",
      "\n",
      "Fold: 17  Epoch: 9  Training loss = 2.7008  Validation loss = 2.4054  \n",
      "\n",
      "Fold: 17  Epoch: 10  Training loss = 2.7005  Validation loss = 2.3982  \n",
      "\n",
      "Fold: 17  Epoch: 11  Training loss = 2.6991  Validation loss = 2.3990  \n",
      "\n",
      "Fold: 17  Epoch: 12  Training loss = 2.6988  Validation loss = 2.3956  \n",
      "\n",
      "Fold: 17  Epoch: 13  Training loss = 2.6974  Validation loss = 2.3994  \n",
      "\n",
      "Fold: 17  Epoch: 14  Training loss = 2.6983  Validation loss = 2.3920  \n",
      "\n",
      "Fold: 17  Epoch: 15  Training loss = 2.6940  Validation loss = 2.4039  \n",
      "\n",
      "Fold: 17  Epoch: 16  Training loss = 2.6911  Validation loss = 2.4168  \n",
      "\n",
      "Check model:  Fold: 17  Optimal epoch: 1  \n",
      "\n",
      "Fold: 18  Epoch: 1  Training loss = 2.7534  Validation loss = 1.7237  \n",
      "\n",
      "Fold: 18  Epoch: 2  Training loss = 2.7524  Validation loss = 1.7208  \n",
      "\n",
      "Fold: 18  Epoch: 3  Training loss = 2.7535  Validation loss = 1.7234  \n",
      "\n",
      "Fold: 18  Epoch: 4  Training loss = 2.7523  Validation loss = 1.7263  \n",
      "\n",
      "Fold: 18  Epoch: 5  Training loss = 2.7488  Validation loss = 1.7221  \n",
      "\n",
      "Fold: 18  Epoch: 6  Training loss = 2.7488  Validation loss = 1.7258  \n",
      "\n",
      "Fold: 18  Epoch: 7  Training loss = 2.7486  Validation loss = 1.7296  \n",
      "\n",
      "Fold: 18  Epoch: 8  Training loss = 2.7461  Validation loss = 1.7268  \n",
      "\n",
      "Fold: 18  Epoch: 9  Training loss = 2.7473  Validation loss = 1.7314  \n",
      "\n",
      "Fold: 18  Epoch: 10  Training loss = 2.7456  Validation loss = 1.7318  \n",
      "\n",
      "Fold: 18  Epoch: 11  Training loss = 2.7425  Validation loss = 1.7305  \n",
      "\n",
      "Fold: 18  Epoch: 12  Training loss = 2.7417  Validation loss = 1.7321  \n",
      "\n",
      "Check model:  Fold: 18  Optimal epoch: 2  \n",
      "\n",
      "Fold: 19  Epoch: 1  Training loss = 2.7031  Validation loss = 2.2190  \n",
      "\n",
      "Fold: 19  Epoch: 2  Training loss = 2.7029  Validation loss = 2.2199  \n",
      "\n",
      "Fold: 19  Epoch: 3  Training loss = 2.7034  Validation loss = 2.2223  \n",
      "\n",
      "Fold: 19  Epoch: 4  Training loss = 2.6991  Validation loss = 2.2171  \n",
      "\n",
      "Fold: 19  Epoch: 5  Training loss = 2.6977  Validation loss = 2.2149  \n",
      "\n",
      "Fold: 19  Epoch: 6  Training loss = 2.6987  Validation loss = 2.2180  \n",
      "\n",
      "Fold: 19  Epoch: 7  Training loss = 2.6965  Validation loss = 2.2152  \n",
      "\n",
      "Fold: 19  Epoch: 8  Training loss = 2.6968  Validation loss = 2.2167  \n",
      "\n",
      "Fold: 19  Epoch: 9  Training loss = 2.6947  Validation loss = 2.2125  \n",
      "\n",
      "Fold: 19  Epoch: 10  Training loss = 2.6970  Validation loss = 2.2148  \n",
      "\n",
      "Fold: 19  Epoch: 11  Training loss = 2.6963  Validation loss = 2.2146  \n",
      "\n",
      "Fold: 19  Epoch: 12  Training loss = 2.6930  Validation loss = 2.2114  \n",
      "\n",
      "Fold: 19  Epoch: 13  Training loss = 2.6923  Validation loss = 2.2107  \n",
      "\n",
      "Fold: 19  Epoch: 14  Training loss = 2.6891  Validation loss = 2.2061  \n",
      "\n",
      "Fold: 19  Epoch: 15  Training loss = 2.6878  Validation loss = 2.2055  \n",
      "\n",
      "Fold: 19  Epoch: 16  Training loss = 2.6856  Validation loss = 2.2024  \n",
      "\n",
      "Fold: 19  Epoch: 17  Training loss = 2.6851  Validation loss = 2.2039  \n",
      "\n",
      "Fold: 19  Epoch: 18  Training loss = 2.6837  Validation loss = 2.2003  \n",
      "\n",
      "Fold: 19  Epoch: 19  Training loss = 2.6829  Validation loss = 2.1995  \n",
      "\n",
      "Fold: 19  Epoch: 20  Training loss = 2.6821  Validation loss = 2.1994  \n",
      "\n",
      "Fold: 19  Epoch: 21  Training loss = 2.6819  Validation loss = 2.1997  \n",
      "\n",
      "Fold: 19  Epoch: 22  Training loss = 2.6804  Validation loss = 2.2000  \n",
      "\n",
      "Fold: 19  Epoch: 23  Training loss = 2.6795  Validation loss = 2.1991  \n",
      "\n",
      "Fold: 19  Epoch: 24  Training loss = 2.6793  Validation loss = 2.1958  \n",
      "\n",
      "Fold: 19  Epoch: 25  Training loss = 2.6777  Validation loss = 2.1945  \n",
      "\n",
      "Fold: 19  Epoch: 26  Training loss = 2.6773  Validation loss = 2.1957  \n",
      "\n",
      "Fold: 19  Epoch: 27  Training loss = 2.6765  Validation loss = 2.1957  \n",
      "\n",
      "Fold: 19  Epoch: 28  Training loss = 2.6760  Validation loss = 2.1950  \n",
      "\n",
      "Fold: 19  Epoch: 29  Training loss = 2.6749  Validation loss = 2.1954  \n",
      "\n",
      "Fold: 19  Epoch: 30  Training loss = 2.6741  Validation loss = 2.1926  \n",
      "\n",
      "Fold: 19  Epoch: 31  Training loss = 2.6740  Validation loss = 2.1904  \n",
      "\n",
      "Fold: 19  Epoch: 32  Training loss = 2.6728  Validation loss = 2.1902  \n",
      "\n",
      "Fold: 19  Epoch: 33  Training loss = 2.6717  Validation loss = 2.1889  \n",
      "\n",
      "Fold: 19  Epoch: 34  Training loss = 2.6704  Validation loss = 2.1887  \n",
      "\n",
      "Fold: 19  Epoch: 35  Training loss = 2.6691  Validation loss = 2.1880  \n",
      "\n",
      "Fold: 19  Epoch: 36  Training loss = 2.6683  Validation loss = 2.1890  \n",
      "\n",
      "Fold: 19  Epoch: 37  Training loss = 2.6675  Validation loss = 2.1851  \n",
      "\n",
      "Fold: 19  Epoch: 38  Training loss = 2.6665  Validation loss = 2.1845  \n",
      "\n",
      "Fold: 19  Epoch: 39  Training loss = 2.6653  Validation loss = 2.1840  \n",
      "\n",
      "Fold: 19  Epoch: 40  Training loss = 2.6648  Validation loss = 2.1858  \n",
      "\n",
      "Fold: 19  Epoch: 41  Training loss = 2.6636  Validation loss = 2.1868  \n",
      "\n",
      "Fold: 19  Epoch: 42  Training loss = 2.6629  Validation loss = 2.1869  \n",
      "\n",
      "Fold: 19  Epoch: 43  Training loss = 2.6637  Validation loss = 2.1908  \n",
      "\n",
      "Check model:  Fold: 19  Optimal epoch: 39  \n",
      "\n",
      "Fold: 20  Epoch: 1  Training loss = 2.7086  Validation loss = 1.3180  \n",
      "\n",
      "Fold: 20  Epoch: 2  Training loss = 2.7063  Validation loss = 1.3145  \n",
      "\n",
      "Fold: 20  Epoch: 3  Training loss = 2.7051  Validation loss = 1.3105  \n",
      "\n",
      "Fold: 20  Epoch: 4  Training loss = 2.7041  Validation loss = 1.3056  \n",
      "\n",
      "Fold: 20  Epoch: 5  Training loss = 2.7023  Validation loss = 1.2989  \n",
      "\n",
      "Fold: 20  Epoch: 6  Training loss = 2.7008  Validation loss = 1.2899  \n",
      "\n",
      "Fold: 20  Epoch: 7  Training loss = 2.7013  Validation loss = 1.2856  \n",
      "\n",
      "Fold: 20  Epoch: 8  Training loss = 2.6998  Validation loss = 1.2912  \n",
      "\n",
      "Fold: 20  Epoch: 9  Training loss = 2.6987  Validation loss = 1.2844  \n",
      "\n",
      "Fold: 20  Epoch: 10  Training loss = 2.6982  Validation loss = 1.2806  \n",
      "\n",
      "Fold: 20  Epoch: 11  Training loss = 2.6969  Validation loss = 1.2774  \n",
      "\n",
      "Fold: 20  Epoch: 12  Training loss = 2.6961  Validation loss = 1.2842  \n",
      "\n",
      "Fold: 20  Epoch: 13  Training loss = 2.6953  Validation loss = 1.2810  \n",
      "\n",
      "Fold: 20  Epoch: 14  Training loss = 2.6948  Validation loss = 1.2799  \n",
      "\n",
      "Fold: 20  Epoch: 15  Training loss = 2.6938  Validation loss = 1.2779  \n",
      "\n",
      "Fold: 20  Epoch: 16  Training loss = 2.6922  Validation loss = 1.2672  \n",
      "\n",
      "Fold: 20  Epoch: 17  Training loss = 2.6914  Validation loss = 1.2622  \n",
      "\n",
      "Fold: 20  Epoch: 18  Training loss = 2.6909  Validation loss = 1.2630  \n",
      "\n",
      "Fold: 20  Epoch: 19  Training loss = 2.6901  Validation loss = 1.2612  \n",
      "\n",
      "Fold: 20  Epoch: 20  Training loss = 2.6891  Validation loss = 1.2604  \n",
      "\n",
      "Fold: 20  Epoch: 21  Training loss = 2.6888  Validation loss = 1.2533  \n",
      "\n",
      "Fold: 20  Epoch: 22  Training loss = 2.6873  Validation loss = 1.2462  \n",
      "\n",
      "Fold: 20  Epoch: 23  Training loss = 2.6866  Validation loss = 1.2443  \n",
      "\n",
      "Fold: 20  Epoch: 24  Training loss = 2.6869  Validation loss = 1.2469  \n",
      "\n",
      "Fold: 20  Epoch: 25  Training loss = 2.6853  Validation loss = 1.2459  \n",
      "\n",
      "Fold: 20  Epoch: 26  Training loss = 2.6857  Validation loss = 1.2357  \n",
      "\n",
      "Fold: 20  Epoch: 27  Training loss = 2.6876  Validation loss = 1.2280  \n",
      "\n",
      "Fold: 20  Epoch: 28  Training loss = 2.6846  Validation loss = 1.2285  \n",
      "\n",
      "Fold: 20  Epoch: 29  Training loss = 2.6828  Validation loss = 1.2291  \n",
      "\n",
      "Fold: 20  Epoch: 30  Training loss = 2.6808  Validation loss = 1.2319  \n",
      "\n",
      "Fold: 20  Epoch: 31  Training loss = 2.6801  Validation loss = 1.2311  \n",
      "\n",
      "Fold: 20  Epoch: 32  Training loss = 2.6790  Validation loss = 1.2278  \n",
      "\n",
      "Fold: 20  Epoch: 33  Training loss = 2.6791  Validation loss = 1.2224  \n",
      "\n",
      "Fold: 20  Epoch: 34  Training loss = 2.6773  Validation loss = 1.2235  \n",
      "\n",
      "Fold: 20  Epoch: 35  Training loss = 2.6769  Validation loss = 1.2227  \n",
      "\n",
      "Fold: 20  Epoch: 36  Training loss = 2.6768  Validation loss = 1.2193  \n",
      "\n",
      "Fold: 20  Epoch: 37  Training loss = 2.6757  Validation loss = 1.2155  \n",
      "\n",
      "Fold: 20  Epoch: 38  Training loss = 2.6750  Validation loss = 1.2146  \n",
      "\n",
      "Fold: 20  Epoch: 39  Training loss = 2.6739  Validation loss = 1.2097  \n",
      "\n",
      "Fold: 20  Epoch: 40  Training loss = 2.6728  Validation loss = 1.2074  \n",
      "\n",
      "Fold: 20  Epoch: 41  Training loss = 2.6722  Validation loss = 1.2022  \n",
      "\n",
      "Fold: 20  Epoch: 42  Training loss = 2.6711  Validation loss = 1.1940  \n",
      "\n",
      "Fold: 20  Epoch: 43  Training loss = 2.6708  Validation loss = 1.1943  \n",
      "\n",
      "Fold: 20  Epoch: 44  Training loss = 2.6702  Validation loss = 1.1864  \n",
      "\n",
      "Fold: 20  Epoch: 45  Training loss = 2.6688  Validation loss = 1.1832  \n",
      "\n",
      "Fold: 20  Epoch: 46  Training loss = 2.6681  Validation loss = 1.1821  \n",
      "\n",
      "Fold: 20  Epoch: 47  Training loss = 2.6674  Validation loss = 1.1828  \n",
      "\n",
      "Fold: 20  Epoch: 48  Training loss = 2.6664  Validation loss = 1.1783  \n",
      "\n",
      "Fold: 20  Epoch: 49  Training loss = 2.6658  Validation loss = 1.1751  \n",
      "\n",
      "Fold: 20  Epoch: 50  Training loss = 2.6646  Validation loss = 1.1764  \n",
      "\n",
      "Fold: 20  Epoch: 51  Training loss = 2.6638  Validation loss = 1.1667  \n",
      "\n",
      "Fold: 20  Epoch: 52  Training loss = 2.6632  Validation loss = 1.1658  \n",
      "\n",
      "Fold: 20  Epoch: 53  Training loss = 2.6625  Validation loss = 1.1652  \n",
      "\n",
      "Fold: 20  Epoch: 54  Training loss = 2.6619  Validation loss = 1.1625  \n",
      "\n",
      "Fold: 20  Epoch: 55  Training loss = 2.6616  Validation loss = 1.1636  \n",
      "\n",
      "Fold: 20  Epoch: 56  Training loss = 2.6608  Validation loss = 1.1641  \n",
      "\n",
      "Fold: 20  Epoch: 57  Training loss = 2.6603  Validation loss = 1.1648  \n",
      "\n",
      "Fold: 20  Epoch: 58  Training loss = 2.6608  Validation loss = 1.1677  \n",
      "\n",
      "Fold: 20  Epoch: 59  Training loss = 2.6582  Validation loss = 1.1606  \n",
      "\n",
      "Fold: 20  Epoch: 60  Training loss = 2.6570  Validation loss = 1.1580  \n",
      "\n",
      "Fold: 20  Epoch: 61  Training loss = 2.6566  Validation loss = 1.1541  \n",
      "\n",
      "Fold: 20  Epoch: 62  Training loss = 2.6549  Validation loss = 1.1529  \n",
      "\n",
      "Fold: 20  Epoch: 63  Training loss = 2.6542  Validation loss = 1.1479  \n",
      "\n",
      "Fold: 20  Epoch: 64  Training loss = 2.6528  Validation loss = 1.1449  \n",
      "\n",
      "Fold: 20  Epoch: 65  Training loss = 2.6524  Validation loss = 1.1421  \n",
      "\n",
      "Fold: 20  Epoch: 66  Training loss = 2.6523  Validation loss = 1.1439  \n",
      "\n",
      "Fold: 20  Epoch: 67  Training loss = 2.6502  Validation loss = 1.1346  \n",
      "\n",
      "Fold: 20  Epoch: 68  Training loss = 2.6495  Validation loss = 1.1342  \n",
      "\n",
      "Fold: 20  Epoch: 69  Training loss = 2.6473  Validation loss = 1.1281  \n",
      "\n",
      "Fold: 20  Epoch: 70  Training loss = 2.6467  Validation loss = 1.1279  \n",
      "\n",
      "Fold: 20  Epoch: 71  Training loss = 2.6463  Validation loss = 1.1261  \n",
      "\n",
      "Fold: 20  Epoch: 72  Training loss = 2.6450  Validation loss = 1.1294  \n",
      "\n",
      "Fold: 20  Epoch: 73  Training loss = 2.6442  Validation loss = 1.1269  \n",
      "\n",
      "Fold: 20  Epoch: 74  Training loss = 2.6445  Validation loss = 1.1300  \n",
      "\n",
      "Fold: 20  Epoch: 75  Training loss = 2.6435  Validation loss = 1.1267  \n",
      "\n",
      "Fold: 20  Epoch: 76  Training loss = 2.6425  Validation loss = 1.1241  \n",
      "\n",
      "Fold: 20  Epoch: 77  Training loss = 2.6408  Validation loss = 1.1150  \n",
      "\n",
      "Fold: 20  Epoch: 78  Training loss = 2.6407  Validation loss = 1.1155  \n",
      "\n",
      "Fold: 20  Epoch: 79  Training loss = 2.6399  Validation loss = 1.1111  \n",
      "\n",
      "Fold: 20  Epoch: 80  Training loss = 2.6395  Validation loss = 1.1087  \n",
      "\n",
      "Fold: 20  Epoch: 81  Training loss = 2.6390  Validation loss = 1.1091  \n",
      "\n",
      "Fold: 20  Epoch: 82  Training loss = 2.6387  Validation loss = 1.1084  \n",
      "\n",
      "Fold: 20  Epoch: 83  Training loss = 2.6369  Validation loss = 1.1064  \n",
      "\n",
      "Fold: 20  Epoch: 84  Training loss = 2.6367  Validation loss = 1.1114  \n",
      "\n",
      "Fold: 20  Epoch: 85  Training loss = 2.6365  Validation loss = 1.1128  \n",
      "\n",
      "Fold: 20  Epoch: 86  Training loss = 2.6353  Validation loss = 1.1071  \n",
      "\n",
      "Fold: 20  Epoch: 87  Training loss = 2.6352  Validation loss = 1.1069  \n",
      "\n",
      "Fold: 20  Epoch: 88  Training loss = 2.6355  Validation loss = 1.1082  \n",
      "\n",
      "Fold: 20  Epoch: 89  Training loss = 2.6344  Validation loss = 1.1092  \n",
      "\n",
      "Fold: 20  Epoch: 90  Training loss = 2.6346  Validation loss = 1.1077  \n",
      "\n",
      "Fold: 20  Epoch: 91  Training loss = 2.6328  Validation loss = 1.1034  \n",
      "\n",
      "Fold: 20  Epoch: 92  Training loss = 2.6329  Validation loss = 1.1049  \n",
      "\n",
      "Fold: 20  Epoch: 93  Training loss = 2.6316  Validation loss = 1.0973  \n",
      "\n",
      "Fold: 20  Epoch: 94  Training loss = 2.6310  Validation loss = 1.0912  \n",
      "\n",
      "Fold: 20  Epoch: 95  Training loss = 2.6297  Validation loss = 1.0903  \n",
      "\n",
      "Fold: 20  Epoch: 96  Training loss = 2.6291  Validation loss = 1.0950  \n",
      "\n",
      "Fold: 20  Epoch: 97  Training loss = 2.6294  Validation loss = 1.0980  \n",
      "\n",
      "Fold: 20  Epoch: 98  Training loss = 2.6316  Validation loss = 1.1009  \n",
      "\n",
      "Fold: 20  Epoch: 99  Training loss = 2.6275  Validation loss = 1.0965  \n",
      "\n",
      "Fold: 20  Epoch: 100  Training loss = 2.6267  Validation loss = 1.0965  \n",
      "\n",
      "Fold: 20  Epoch: 101  Training loss = 2.6258  Validation loss = 1.0955  \n",
      "\n",
      "Fold: 20  Epoch: 102  Training loss = 2.6258  Validation loss = 1.0976  \n",
      "\n",
      "Fold: 20  Epoch: 103  Training loss = 2.6261  Validation loss = 1.0963  \n",
      "\n",
      "Fold: 20  Epoch: 104  Training loss = 2.6259  Validation loss = 1.0983  \n",
      "\n",
      "Fold: 20  Epoch: 105  Training loss = 2.6267  Validation loss = 1.0939  \n",
      "\n",
      "Fold: 20  Epoch: 106  Training loss = 2.6239  Validation loss = 1.0867  \n",
      "\n",
      "Fold: 20  Epoch: 107  Training loss = 2.6236  Validation loss = 1.0873  \n",
      "\n",
      "Fold: 20  Epoch: 108  Training loss = 2.6226  Validation loss = 1.0826  \n",
      "\n",
      "Fold: 20  Epoch: 109  Training loss = 2.6220  Validation loss = 1.0803  \n",
      "\n",
      "Fold: 20  Epoch: 110  Training loss = 2.6209  Validation loss = 1.0782  \n",
      "\n",
      "Fold: 20  Epoch: 111  Training loss = 2.6222  Validation loss = 1.0767  \n",
      "\n",
      "Fold: 20  Epoch: 112  Training loss = 2.6228  Validation loss = 1.0758  \n",
      "\n",
      "Fold: 20  Epoch: 113  Training loss = 2.6194  Validation loss = 1.0701  \n",
      "\n",
      "Fold: 20  Epoch: 114  Training loss = 2.6190  Validation loss = 1.0687  \n",
      "\n",
      "Fold: 20  Epoch: 115  Training loss = 2.6162  Validation loss = 1.0606  \n",
      "\n",
      "Fold: 20  Epoch: 116  Training loss = 2.6167  Validation loss = 1.0544  \n",
      "\n",
      "Fold: 20  Epoch: 117  Training loss = 2.6151  Validation loss = 1.0535  \n",
      "\n",
      "Fold: 20  Epoch: 118  Training loss = 2.6143  Validation loss = 1.0516  \n",
      "\n",
      "Fold: 20  Epoch: 119  Training loss = 2.6136  Validation loss = 1.0493  \n",
      "\n",
      "Fold: 20  Epoch: 120  Training loss = 2.6132  Validation loss = 1.0487  \n",
      "\n",
      "Fold: 20  Epoch: 121  Training loss = 2.6126  Validation loss = 1.0512  \n",
      "\n",
      "Fold: 20  Epoch: 122  Training loss = 2.6151  Validation loss = 1.0539  \n",
      "\n",
      "Fold: 20  Epoch: 123  Training loss = 2.6132  Validation loss = 1.0429  \n",
      "\n",
      "Fold: 20  Epoch: 124  Training loss = 2.6102  Validation loss = 1.0377  \n",
      "\n",
      "Fold: 20  Epoch: 125  Training loss = 2.6095  Validation loss = 1.0375  \n",
      "\n",
      "Fold: 20  Epoch: 126  Training loss = 2.6101  Validation loss = 1.0376  \n",
      "\n",
      "Fold: 20  Epoch: 127  Training loss = 2.6105  Validation loss = 1.0374  \n",
      "\n",
      "Fold: 20  Epoch: 128  Training loss = 2.6105  Validation loss = 1.0342  \n",
      "\n",
      "Fold: 20  Epoch: 129  Training loss = 2.6091  Validation loss = 1.0345  \n",
      "\n",
      "Fold: 20  Epoch: 130  Training loss = 2.6061  Validation loss = 1.0313  \n",
      "\n",
      "Fold: 20  Epoch: 131  Training loss = 2.6043  Validation loss = 1.0255  \n",
      "\n",
      "Fold: 20  Epoch: 132  Training loss = 2.6036  Validation loss = 1.0246  \n",
      "\n",
      "Fold: 20  Epoch: 133  Training loss = 2.6043  Validation loss = 1.0220  \n",
      "\n",
      "Fold: 20  Epoch: 134  Training loss = 2.6033  Validation loss = 1.0232  \n",
      "\n",
      "Fold: 20  Epoch: 135  Training loss = 2.6023  Validation loss = 1.0257  \n",
      "\n",
      "Fold: 20  Epoch: 136  Training loss = 2.6018  Validation loss = 1.0282  \n",
      "\n",
      "Fold: 20  Epoch: 137  Training loss = 2.6008  Validation loss = 1.0241  \n",
      "\n",
      "Fold: 20  Epoch: 138  Training loss = 2.6021  Validation loss = 1.0296  \n",
      "\n",
      "Fold: 20  Epoch: 139  Training loss = 2.6009  Validation loss = 1.0252  \n",
      "\n",
      "Fold: 20  Epoch: 140  Training loss = 2.5986  Validation loss = 1.0219  \n",
      "\n",
      "Fold: 20  Epoch: 141  Training loss = 2.5987  Validation loss = 1.0269  \n",
      "\n",
      "Fold: 20  Epoch: 142  Training loss = 2.5988  Validation loss = 1.0288  \n",
      "\n",
      "Fold: 20  Epoch: 143  Training loss = 2.5971  Validation loss = 1.0246  \n",
      "\n",
      "Fold: 20  Epoch: 144  Training loss = 2.5963  Validation loss = 1.0249  \n",
      "\n",
      "Fold: 20  Epoch: 145  Training loss = 2.5954  Validation loss = 1.0253  \n",
      "\n",
      "Fold: 20  Epoch: 146  Training loss = 2.5947  Validation loss = 1.0236  \n",
      "\n",
      "Fold: 20  Epoch: 147  Training loss = 2.5940  Validation loss = 1.0209  \n",
      "\n",
      "Fold: 20  Epoch: 148  Training loss = 2.5937  Validation loss = 1.0186  \n",
      "\n",
      "Fold: 20  Epoch: 149  Training loss = 2.5928  Validation loss = 1.0183  \n",
      "\n",
      "Fold: 20  Epoch: 150  Training loss = 2.5926  Validation loss = 1.0196  \n",
      "\n",
      "Fold: 20  Epoch: 151  Training loss = 2.5922  Validation loss = 1.0211  \n",
      "\n",
      "Fold: 20  Epoch: 152  Training loss = 2.5920  Validation loss = 1.0187  \n",
      "\n",
      "Fold: 20  Epoch: 153  Training loss = 2.5909  Validation loss = 1.0148  \n",
      "\n",
      "Fold: 20  Epoch: 154  Training loss = 2.5910  Validation loss = 1.0123  \n",
      "\n",
      "Fold: 20  Epoch: 155  Training loss = 2.5884  Validation loss = 1.0058  \n",
      "\n",
      "Fold: 20  Epoch: 156  Training loss = 2.5882  Validation loss = 1.0047  \n",
      "\n",
      "Fold: 20  Epoch: 157  Training loss = 2.5871  Validation loss = 1.0011  \n",
      "\n",
      "Fold: 20  Epoch: 158  Training loss = 2.5878  Validation loss = 0.9998  \n",
      "\n",
      "Fold: 20  Epoch: 159  Training loss = 2.5883  Validation loss = 0.9975  \n",
      "\n",
      "Fold: 20  Epoch: 160  Training loss = 2.5876  Validation loss = 0.9997  \n",
      "\n",
      "Fold: 20  Epoch: 161  Training loss = 2.5887  Validation loss = 1.0014  \n",
      "\n",
      "Fold: 20  Epoch: 162  Training loss = 2.5851  Validation loss = 0.9944  \n",
      "\n",
      "Fold: 20  Epoch: 163  Training loss = 2.5827  Validation loss = 0.9889  \n",
      "\n",
      "Fold: 20  Epoch: 164  Training loss = 2.5826  Validation loss = 0.9854  \n",
      "\n",
      "Fold: 20  Epoch: 165  Training loss = 2.5813  Validation loss = 0.9850  \n",
      "\n",
      "Fold: 20  Epoch: 166  Training loss = 2.5804  Validation loss = 0.9811  \n",
      "\n",
      "Fold: 20  Epoch: 167  Training loss = 2.5799  Validation loss = 0.9803  \n",
      "\n",
      "Fold: 20  Epoch: 168  Training loss = 2.5794  Validation loss = 0.9816  \n",
      "\n",
      "Fold: 20  Epoch: 169  Training loss = 2.5788  Validation loss = 0.9766  \n",
      "\n",
      "Fold: 20  Epoch: 170  Training loss = 2.5765  Validation loss = 0.9705  \n",
      "\n",
      "Fold: 20  Epoch: 171  Training loss = 2.5766  Validation loss = 0.9727  \n",
      "\n",
      "Fold: 20  Epoch: 172  Training loss = 2.5760  Validation loss = 0.9740  \n",
      "\n",
      "Fold: 20  Epoch: 173  Training loss = 2.5754  Validation loss = 0.9713  \n",
      "\n",
      "Fold: 20  Epoch: 174  Training loss = 2.5749  Validation loss = 0.9745  \n",
      "\n",
      "Fold: 20  Epoch: 175  Training loss = 2.5754  Validation loss = 0.9708  \n",
      "\n",
      "Fold: 20  Epoch: 176  Training loss = 2.5753  Validation loss = 0.9691  \n",
      "\n",
      "Fold: 20  Epoch: 177  Training loss = 2.5757  Validation loss = 0.9679  \n",
      "\n",
      "Fold: 20  Epoch: 178  Training loss = 2.5731  Validation loss = 0.9652  \n",
      "\n",
      "Fold: 20  Epoch: 179  Training loss = 2.5725  Validation loss = 0.9673  \n",
      "\n",
      "Fold: 20  Epoch: 180  Training loss = 2.5722  Validation loss = 0.9697  \n",
      "\n",
      "Fold: 20  Epoch: 181  Training loss = 2.5741  Validation loss = 0.9682  \n",
      "\n",
      "Fold: 20  Epoch: 182  Training loss = 2.5750  Validation loss = 0.9724  \n",
      "\n",
      "Fold: 20  Epoch: 183  Training loss = 2.5702  Validation loss = 0.9673  \n",
      "\n",
      "Fold: 20  Epoch: 184  Training loss = 2.5703  Validation loss = 0.9662  \n",
      "\n",
      "Fold: 20  Epoch: 185  Training loss = 2.5719  Validation loss = 0.9634  \n",
      "\n",
      "Fold: 20  Epoch: 186  Training loss = 2.5687  Validation loss = 0.9617  \n",
      "\n",
      "Fold: 20  Epoch: 187  Training loss = 2.5680  Validation loss = 0.9584  \n",
      "\n",
      "Fold: 20  Epoch: 188  Training loss = 2.5669  Validation loss = 0.9619  \n",
      "\n",
      "Fold: 20  Epoch: 189  Training loss = 2.5664  Validation loss = 0.9588  \n",
      "\n",
      "Fold: 20  Epoch: 190  Training loss = 2.5659  Validation loss = 0.9625  \n",
      "\n",
      "Fold: 20  Epoch: 191  Training loss = 2.5655  Validation loss = 0.9608  \n",
      "\n",
      "Fold: 20  Epoch: 192  Training loss = 2.5654  Validation loss = 0.9644  \n",
      "\n",
      "Fold: 20  Epoch: 193  Training loss = 2.5645  Validation loss = 0.9631  \n",
      "\n",
      "Fold: 20  Epoch: 194  Training loss = 2.5633  Validation loss = 0.9598  \n",
      "\n",
      "Fold: 20  Epoch: 195  Training loss = 2.5633  Validation loss = 0.9601  \n",
      "\n",
      "Fold: 20  Epoch: 196  Training loss = 2.5626  Validation loss = 0.9606  \n",
      "\n",
      "Fold: 20  Epoch: 197  Training loss = 2.5613  Validation loss = 0.9606  \n",
      "\n",
      "Fold: 20  Epoch: 198  Training loss = 2.5603  Validation loss = 0.9578  \n",
      "\n",
      "Fold: 20  Epoch: 199  Training loss = 2.5610  Validation loss = 0.9533  \n",
      "\n",
      "Fold: 20  Epoch: 200  Training loss = 2.5604  Validation loss = 0.9536  \n",
      "\n",
      "Fold: 20  Epoch: 201  Training loss = 2.5586  Validation loss = 0.9534  \n",
      "\n",
      "Fold: 20  Epoch: 202  Training loss = 2.5576  Validation loss = 0.9530  \n",
      "\n",
      "Fold: 20  Epoch: 203  Training loss = 2.5574  Validation loss = 0.9518  \n",
      "\n",
      "Fold: 20  Epoch: 204  Training loss = 2.5564  Validation loss = 0.9469  \n",
      "\n",
      "Fold: 20  Epoch: 205  Training loss = 2.5573  Validation loss = 0.9488  \n",
      "\n",
      "Fold: 20  Epoch: 206  Training loss = 2.5560  Validation loss = 0.9447  \n",
      "\n",
      "Fold: 20  Epoch: 207  Training loss = 2.5564  Validation loss = 0.9450  \n",
      "\n",
      "Fold: 20  Epoch: 208  Training loss = 2.5554  Validation loss = 0.9420  \n",
      "\n",
      "Fold: 20  Epoch: 209  Training loss = 2.5554  Validation loss = 0.9460  \n",
      "\n",
      "Fold: 20  Epoch: 210  Training loss = 2.5540  Validation loss = 0.9408  \n",
      "\n",
      "Fold: 20  Epoch: 211  Training loss = 2.5526  Validation loss = 0.9337  \n",
      "\n",
      "Fold: 20  Epoch: 212  Training loss = 2.5524  Validation loss = 0.9352  \n",
      "\n",
      "Fold: 20  Epoch: 213  Training loss = 2.5537  Validation loss = 0.9354  \n",
      "\n",
      "Fold: 20  Epoch: 214  Training loss = 2.5538  Validation loss = 0.9345  \n",
      "\n",
      "Fold: 20  Epoch: 215  Training loss = 2.5528  Validation loss = 0.9348  \n",
      "\n",
      "Fold: 20  Epoch: 216  Training loss = 2.5511  Validation loss = 0.9341  \n",
      "\n",
      "Fold: 20  Epoch: 217  Training loss = 2.5514  Validation loss = 0.9332  \n",
      "\n",
      "Fold: 20  Epoch: 218  Training loss = 2.5502  Validation loss = 0.9279  \n",
      "\n",
      "Fold: 20  Epoch: 219  Training loss = 2.5485  Validation loss = 0.9246  \n",
      "\n",
      "Fold: 20  Epoch: 220  Training loss = 2.5480  Validation loss = 0.9260  \n",
      "\n",
      "Fold: 20  Epoch: 221  Training loss = 2.5474  Validation loss = 0.9223  \n",
      "\n",
      "Fold: 20  Epoch: 222  Training loss = 2.5466  Validation loss = 0.9225  \n",
      "\n",
      "Fold: 20  Epoch: 223  Training loss = 2.5470  Validation loss = 0.9206  \n",
      "\n",
      "Fold: 20  Epoch: 224  Training loss = 2.5470  Validation loss = 0.9231  \n",
      "\n",
      "Fold: 20  Epoch: 225  Training loss = 2.5480  Validation loss = 0.9236  \n",
      "\n",
      "Fold: 20  Epoch: 226  Training loss = 2.5462  Validation loss = 0.9244  \n",
      "\n",
      "Fold: 20  Epoch: 227  Training loss = 2.5445  Validation loss = 0.9232  \n",
      "\n",
      "Fold: 20  Epoch: 228  Training loss = 2.5438  Validation loss = 0.9255  \n",
      "\n",
      "Fold: 20  Epoch: 229  Training loss = 2.5420  Validation loss = 0.9228  \n",
      "\n",
      "Fold: 20  Epoch: 230  Training loss = 2.5423  Validation loss = 0.9212  \n",
      "\n",
      "Fold: 20  Epoch: 231  Training loss = 2.5414  Validation loss = 0.9208  \n",
      "\n",
      "Fold: 20  Epoch: 232  Training loss = 2.5408  Validation loss = 0.9215  \n",
      "\n",
      "Fold: 20  Epoch: 233  Training loss = 2.5398  Validation loss = 0.9214  \n",
      "\n",
      "Fold: 20  Epoch: 234  Training loss = 2.5389  Validation loss = 0.9222  \n",
      "\n",
      "Fold: 20  Epoch: 235  Training loss = 2.5390  Validation loss = 0.9197  \n",
      "\n",
      "Fold: 20  Epoch: 236  Training loss = 2.5377  Validation loss = 0.9195  \n",
      "\n",
      "Fold: 20  Epoch: 237  Training loss = 2.5372  Validation loss = 0.9157  \n",
      "\n",
      "Fold: 20  Epoch: 238  Training loss = 2.5364  Validation loss = 0.9139  \n",
      "\n",
      "Fold: 20  Epoch: 239  Training loss = 2.5360  Validation loss = 0.9149  \n",
      "\n",
      "Fold: 20  Epoch: 240  Training loss = 2.5354  Validation loss = 0.9171  \n",
      "\n",
      "Fold: 20  Epoch: 241  Training loss = 2.5350  Validation loss = 0.9148  \n",
      "\n",
      "Fold: 20  Epoch: 242  Training loss = 2.5350  Validation loss = 0.9183  \n",
      "\n",
      "Fold: 20  Epoch: 243  Training loss = 2.5352  Validation loss = 0.9213  \n",
      "\n",
      "Fold: 20  Epoch: 244  Training loss = 2.5334  Validation loss = 0.9155  \n",
      "\n",
      "Fold: 20  Epoch: 245  Training loss = 2.5343  Validation loss = 0.9185  \n",
      "\n",
      "Fold: 20  Epoch: 246  Training loss = 2.5345  Validation loss = 0.9164  \n",
      "\n",
      "Fold: 20  Epoch: 247  Training loss = 2.5328  Validation loss = 0.9152  \n",
      "\n",
      "Fold: 20  Epoch: 248  Training loss = 2.5314  Validation loss = 0.9089  \n",
      "\n",
      "Fold: 20  Epoch: 249  Training loss = 2.5309  Validation loss = 0.9063  \n",
      "\n",
      "Fold: 20  Epoch: 250  Training loss = 2.5300  Validation loss = 0.9051  \n",
      "\n",
      "Fold: 20  Epoch: 251  Training loss = 2.5295  Validation loss = 0.9040  \n",
      "\n",
      "Fold: 20  Epoch: 252  Training loss = 2.5289  Validation loss = 0.9036  \n",
      "\n",
      "Fold: 20  Epoch: 253  Training loss = 2.5291  Validation loss = 0.9010  \n",
      "\n",
      "Fold: 20  Epoch: 254  Training loss = 2.5290  Validation loss = 0.9002  \n",
      "\n",
      "Fold: 20  Epoch: 255  Training loss = 2.5282  Validation loss = 0.9020  \n",
      "\n",
      "Fold: 20  Epoch: 256  Training loss = 2.5298  Validation loss = 0.8988  \n",
      "\n",
      "Fold: 20  Epoch: 257  Training loss = 2.5311  Validation loss = 0.8969  \n",
      "\n",
      "Fold: 20  Epoch: 258  Training loss = 2.5280  Validation loss = 0.8997  \n",
      "\n",
      "Fold: 20  Epoch: 259  Training loss = 2.5255  Validation loss = 0.9048  \n",
      "\n",
      "Fold: 20  Epoch: 260  Training loss = 2.5249  Validation loss = 0.8991  \n",
      "\n",
      "Fold: 20  Epoch: 261  Training loss = 2.5249  Validation loss = 0.9032  \n",
      "\n",
      "Fold: 20  Epoch: 262  Training loss = 2.5248  Validation loss = 0.9024  \n",
      "\n",
      "Fold: 20  Epoch: 263  Training loss = 2.5236  Validation loss = 0.9065  \n",
      "\n",
      "Check model:  Fold: 20  Optimal epoch: 257  \n",
      "\n",
      "Fold: 21  Epoch: 1  Training loss = 2.4970  Validation loss = 3.0300  \n",
      "\n",
      "Fold: 21  Epoch: 2  Training loss = 2.4965  Validation loss = 3.0299  \n",
      "\n",
      "Fold: 21  Epoch: 3  Training loss = 2.4954  Validation loss = 3.0299  \n",
      "\n",
      "Fold: 21  Epoch: 4  Training loss = 2.4954  Validation loss = 3.0356  \n",
      "\n",
      "Fold: 21  Epoch: 5  Training loss = 2.4952  Validation loss = 3.0394  \n",
      "\n",
      "Fold: 21  Epoch: 6  Training loss = 2.4947  Validation loss = 3.0586  \n",
      "\n",
      "Fold: 21  Epoch: 7  Training loss = 2.4926  Validation loss = 3.0501  \n",
      "\n",
      "Fold: 21  Epoch: 8  Training loss = 2.4917  Validation loss = 3.0531  \n",
      "\n",
      "Fold: 21  Epoch: 9  Training loss = 2.4916  Validation loss = 3.0735  \n",
      "\n",
      "Fold: 21  Epoch: 10  Training loss = 2.4893  Validation loss = 3.0726  \n",
      "\n",
      "Fold: 21  Epoch: 11  Training loss = 2.4915  Validation loss = 3.0860  \n",
      "\n",
      "Check model:  Fold: 21  Optimal epoch: 2  \n",
      "\n",
      "Fold: 22  Epoch: 1  Training loss = 2.5318  Validation loss = 2.7774  \n",
      "\n",
      "Fold: 22  Epoch: 2  Training loss = 2.5292  Validation loss = 2.7531  \n",
      "\n",
      "Fold: 22  Epoch: 3  Training loss = 2.5280  Validation loss = 2.7533  \n",
      "\n",
      "Fold: 22  Epoch: 4  Training loss = 2.5264  Validation loss = 2.7791  \n",
      "\n",
      "Fold: 22  Epoch: 5  Training loss = 2.5253  Validation loss = 2.7675  \n",
      "\n",
      "Fold: 22  Epoch: 6  Training loss = 2.5250  Validation loss = 2.7387  \n",
      "\n",
      "Fold: 22  Epoch: 7  Training loss = 2.5234  Validation loss = 2.7749  \n",
      "\n",
      "Fold: 22  Epoch: 8  Training loss = 2.5228  Validation loss = 2.7874  \n",
      "\n",
      "Fold: 22  Epoch: 9  Training loss = 2.5213  Validation loss = 2.7946  \n",
      "\n",
      "Fold: 22  Epoch: 10  Training loss = 2.5207  Validation loss = 2.7807  \n",
      "\n",
      "Fold: 22  Epoch: 11  Training loss = 2.5195  Validation loss = 2.7434  \n",
      "\n",
      "Fold: 22  Epoch: 12  Training loss = 2.5191  Validation loss = 2.7035  \n",
      "\n",
      "Fold: 22  Epoch: 13  Training loss = 2.5183  Validation loss = 2.7025  \n",
      "\n",
      "Fold: 22  Epoch: 14  Training loss = 2.5172  Validation loss = 2.7292  \n",
      "\n",
      "Fold: 22  Epoch: 15  Training loss = 2.5187  Validation loss = 2.8413  \n",
      "\n",
      "Check model:  Fold: 22  Optimal epoch: 13  \n",
      "\n",
      "Fold: 23  Epoch: 1  Training loss = 2.5580  Validation loss = 2.4765  \n",
      "\n",
      "Fold: 23  Epoch: 2  Training loss = 2.5589  Validation loss = 2.5234  \n",
      "\n",
      "Fold: 23  Epoch: 3  Training loss = 2.5495  Validation loss = 2.4186  \n",
      "\n",
      "Fold: 23  Epoch: 4  Training loss = 2.5428  Validation loss = 2.2998  \n",
      "\n",
      "Fold: 23  Epoch: 5  Training loss = 2.5354  Validation loss = 2.3088  \n",
      "\n",
      "Fold: 23  Epoch: 6  Training loss = 2.5276  Validation loss = 2.2238  \n",
      "\n",
      "Fold: 23  Epoch: 7  Training loss = 2.5281  Validation loss = 2.2868  \n",
      "\n",
      "Fold: 23  Epoch: 8  Training loss = 2.5262  Validation loss = 2.2453  \n",
      "\n",
      "Fold: 23  Epoch: 9  Training loss = 2.5235  Validation loss = 2.2378  \n",
      "\n",
      "Fold: 23  Epoch: 10  Training loss = 2.5215  Validation loss = 2.2537  \n",
      "\n",
      "Fold: 23  Epoch: 11  Training loss = 2.5180  Validation loss = 2.2327  \n",
      "\n",
      "Fold: 23  Epoch: 12  Training loss = 2.5147  Validation loss = 2.1883  \n",
      "\n",
      "Fold: 23  Epoch: 13  Training loss = 2.5253  Validation loss = 2.0612  \n",
      "\n",
      "Fold: 23  Epoch: 14  Training loss = 2.5249  Validation loss = 2.2756  \n",
      "\n",
      "Fold: 23  Epoch: 15  Training loss = 2.5231  Validation loss = 2.2965  \n",
      "\n",
      "Check model:  Fold: 23  Optimal epoch: 13  \n",
      "\n",
      "Fold: 24  Epoch: 1  Training loss = 2.5586  Validation loss = 1.2780  \n",
      "\n",
      "Fold: 24  Epoch: 2  Training loss = 2.5578  Validation loss = 1.2783  \n",
      "\n",
      "Fold: 24  Epoch: 3  Training loss = 2.5498  Validation loss = 1.2776  \n",
      "\n",
      "Fold: 24  Epoch: 4  Training loss = 2.5392  Validation loss = 1.2797  \n",
      "\n",
      "Fold: 24  Epoch: 5  Training loss = 2.4998  Validation loss = 1.2835  \n",
      "\n",
      "Fold: 24  Epoch: 6  Training loss = 2.4939  Validation loss = 1.2855  \n",
      "\n",
      "Fold: 24  Epoch: 7  Training loss = 2.4880  Validation loss = 1.2911  \n",
      "\n",
      "Fold: 24  Epoch: 8  Training loss = 2.4857  Validation loss = 1.2931  \n",
      "\n",
      "Fold: 24  Epoch: 9  Training loss = 2.4832  Validation loss = 1.2929  \n",
      "\n",
      "Fold: 24  Epoch: 10  Training loss = 2.4811  Validation loss = 1.2964  \n",
      "\n",
      "Fold: 24  Epoch: 11  Training loss = 2.4790  Validation loss = 1.2929  \n",
      "\n",
      "Fold: 24  Epoch: 12  Training loss = 2.4776  Validation loss = 1.2883  \n",
      "\n",
      "Fold: 24  Epoch: 13  Training loss = 2.4791  Validation loss = 1.2837  \n",
      "\n",
      "Fold: 24  Epoch: 14  Training loss = 2.4771  Validation loss = 1.2845  \n",
      "\n",
      "Fold: 24  Epoch: 15  Training loss = 2.4732  Validation loss = 1.2920  \n",
      "\n",
      "Fold: 24  Epoch: 16  Training loss = 2.4732  Validation loss = 1.2832  \n",
      "\n",
      "Fold: 24  Epoch: 17  Training loss = 2.4704  Validation loss = 1.2787  \n",
      "\n",
      "Fold: 24  Epoch: 18  Training loss = 2.4746  Validation loss = 1.2582  \n",
      "\n",
      "Fold: 24  Epoch: 19  Training loss = 2.4725  Validation loss = 1.2596  \n",
      "\n",
      "Fold: 24  Epoch: 20  Training loss = 2.4711  Validation loss = 1.2669  \n",
      "\n",
      "Fold: 24  Epoch: 21  Training loss = 2.4722  Validation loss = 1.2731  \n",
      "\n",
      "Fold: 24  Epoch: 22  Training loss = 2.4694  Validation loss = 1.2665  \n",
      "\n",
      "Fold: 24  Epoch: 23  Training loss = 2.4672  Validation loss = 1.2637  \n",
      "\n",
      "Fold: 24  Epoch: 24  Training loss = 2.4658  Validation loss = 1.2581  \n",
      "\n",
      "Fold: 24  Epoch: 25  Training loss = 2.4630  Validation loss = 1.2656  \n",
      "\n",
      "Fold: 24  Epoch: 26  Training loss = 2.4612  Validation loss = 1.2659  \n",
      "\n",
      "Fold: 24  Epoch: 27  Training loss = 2.4599  Validation loss = 1.2593  \n",
      "\n",
      "Fold: 24  Epoch: 28  Training loss = 2.4586  Validation loss = 1.2715  \n",
      "\n",
      "Fold: 24  Epoch: 29  Training loss = 2.4570  Validation loss = 1.2739  \n",
      "\n",
      "Check model:  Fold: 24  Optimal epoch: 24  \n",
      "\n",
      "Fold: 25  Epoch: 1  Training loss = 2.4121  Validation loss = 2.4435  \n",
      "\n",
      "Fold: 25  Epoch: 2  Training loss = 2.4101  Validation loss = 2.4682  \n",
      "\n",
      "Fold: 25  Epoch: 3  Training loss = 2.4156  Validation loss = 2.4849  \n",
      "\n",
      "Fold: 25  Epoch: 4  Training loss = 2.4150  Validation loss = 2.5169  \n",
      "\n",
      "Fold: 25  Epoch: 5  Training loss = 2.4138  Validation loss = 2.5403  \n",
      "\n",
      "Fold: 25  Epoch: 6  Training loss = 2.4128  Validation loss = 2.5880  \n",
      "\n",
      "Fold: 25  Epoch: 7  Training loss = 2.4130  Validation loss = 2.6110  \n",
      "\n",
      "Fold: 25  Epoch: 8  Training loss = 2.4096  Validation loss = 2.4214  \n",
      "\n",
      "Fold: 25  Epoch: 9  Training loss = 2.4059  Validation loss = 2.4997  \n",
      "\n",
      "Fold: 25  Epoch: 10  Training loss = 2.4046  Validation loss = 2.5299  \n",
      "\n",
      "Fold: 25  Epoch: 11  Training loss = 2.4024  Validation loss = 2.5024  \n",
      "\n",
      "Fold: 25  Epoch: 12  Training loss = 2.4024  Validation loss = 2.5487  \n",
      "\n",
      "Fold: 25  Epoch: 13  Training loss = 2.3999  Validation loss = 2.5043  \n",
      "\n",
      "Fold: 25  Epoch: 14  Training loss = 2.3991  Validation loss = 2.4776  \n",
      "\n",
      "Fold: 25  Epoch: 15  Training loss = 2.3989  Validation loss = 2.5357  \n",
      "\n",
      "Fold: 25  Epoch: 16  Training loss = 2.3981  Validation loss = 2.5440  \n",
      "\n",
      "Fold: 25  Epoch: 17  Training loss = 2.3972  Validation loss = 2.4831  \n",
      "\n",
      "Fold: 25  Epoch: 18  Training loss = 2.3963  Validation loss = 2.4906  \n",
      "\n",
      "Fold: 25  Epoch: 19  Training loss = 2.3956  Validation loss = 2.5272  \n",
      "\n",
      "Fold: 25  Epoch: 20  Training loss = 2.3946  Validation loss = 2.5326  \n",
      "\n",
      "Fold: 25  Epoch: 21  Training loss = 2.3932  Validation loss = 2.4934  \n",
      "\n",
      "Fold: 25  Epoch: 22  Training loss = 2.3921  Validation loss = 2.4699  \n",
      "\n",
      "Fold: 25  Epoch: 23  Training loss = 2.3914  Validation loss = 2.4642  \n",
      "\n",
      "Fold: 25  Epoch: 24  Training loss = 2.3955  Validation loss = 2.5086  \n",
      "\n",
      "Fold: 25  Epoch: 25  Training loss = 2.3954  Validation loss = 2.5513  \n",
      "\n",
      "Check model:  Fold: 25  Optimal epoch: 8  \n",
      "\n",
      "Fold: 26  Epoch: 1  Training loss = 2.3877  Validation loss = 3.3579  \n",
      "\n",
      "Fold: 26  Epoch: 2  Training loss = 2.3877  Validation loss = 3.3624  \n",
      "\n",
      "Fold: 26  Epoch: 3  Training loss = 2.3819  Validation loss = 3.2427  \n",
      "\n",
      "Fold: 26  Epoch: 4  Training loss = 2.3864  Validation loss = 3.3747  \n",
      "\n",
      "Fold: 26  Epoch: 5  Training loss = 2.3779  Validation loss = 2.6907  \n",
      "\n",
      "Fold: 26  Epoch: 6  Training loss = 2.3783  Validation loss = 3.1024  \n",
      "\n",
      "Fold: 26  Epoch: 7  Training loss = 2.3750  Validation loss = 2.9871  \n",
      "\n",
      "Fold: 26  Epoch: 8  Training loss = 2.3730  Validation loss = 2.7537  \n",
      "\n",
      "Fold: 26  Epoch: 9  Training loss = 2.3737  Validation loss = 3.1920  \n",
      "\n",
      "Fold: 26  Epoch: 10  Training loss = 2.3705  Validation loss = 3.1023  \n",
      "\n",
      "Fold: 26  Epoch: 11  Training loss = 2.3692  Validation loss = 3.1578  \n",
      "\n",
      "Fold: 26  Epoch: 12  Training loss = 2.3685  Validation loss = 3.1957  \n",
      "\n",
      "Fold: 26  Epoch: 13  Training loss = 2.3797  Validation loss = 2.2748  \n",
      "\n",
      "Fold: 26  Epoch: 14  Training loss = 2.3754  Validation loss = 2.5962  \n",
      "\n",
      "Fold: 26  Epoch: 15  Training loss = 2.3679  Validation loss = 2.5602  \n",
      "\n",
      "Fold: 26  Epoch: 16  Training loss = 2.3631  Validation loss = 3.0976  \n",
      "\n",
      "Fold: 26  Epoch: 17  Training loss = 2.3703  Validation loss = 3.4494  \n",
      "\n",
      "Check model:  Fold: 26  Optimal epoch: 13  \n",
      "\n",
      "Fold: 27  Epoch: 1  Training loss = 2.3098  Validation loss = 0.5354  \n",
      "\n",
      "Fold: 27  Epoch: 2  Training loss = 2.2963  Validation loss = 0.5376  \n",
      "\n",
      "Fold: 27  Epoch: 3  Training loss = 2.2984  Validation loss = 0.5424  \n",
      "\n",
      "Fold: 27  Epoch: 4  Training loss = 2.2930  Validation loss = 0.5426  \n",
      "\n",
      "Fold: 27  Epoch: 5  Training loss = 2.2880  Validation loss = 0.5367  \n",
      "\n",
      "Fold: 27  Epoch: 6  Training loss = 2.2872  Validation loss = 0.5352  \n",
      "\n",
      "Fold: 27  Epoch: 7  Training loss = 2.2808  Validation loss = 0.5346  \n",
      "\n",
      "Fold: 27  Epoch: 8  Training loss = 2.2776  Validation loss = 0.5403  \n",
      "\n",
      "Fold: 27  Epoch: 9  Training loss = 2.2767  Validation loss = 0.5418  \n",
      "\n",
      "Fold: 27  Epoch: 10  Training loss = 2.2822  Validation loss = 0.5469  \n",
      "\n",
      "Fold: 27  Epoch: 11  Training loss = 2.2759  Validation loss = 0.5406  \n",
      "\n",
      "Fold: 27  Epoch: 12  Training loss = 2.2757  Validation loss = 0.5467  \n",
      "\n",
      "Fold: 27  Epoch: 13  Training loss = 2.2709  Validation loss = 0.5536  \n",
      "\n",
      "Check model:  Fold: 27  Optimal epoch: 7  \n",
      "\n",
      "Fold: 28  Epoch: 1  Training loss = 2.2423  Validation loss = 0.7915  \n",
      "\n",
      "Fold: 28  Epoch: 2  Training loss = 2.2411  Validation loss = 0.7888  \n",
      "\n",
      "Fold: 28  Epoch: 3  Training loss = 2.2385  Validation loss = 0.7886  \n",
      "\n",
      "Fold: 28  Epoch: 4  Training loss = 2.2371  Validation loss = 0.7941  \n",
      "\n",
      "Fold: 28  Epoch: 5  Training loss = 2.2457  Validation loss = 0.7845  \n",
      "\n",
      "Fold: 28  Epoch: 6  Training loss = 2.2371  Validation loss = 0.7866  \n",
      "\n",
      "Fold: 28  Epoch: 7  Training loss = 2.2367  Validation loss = 0.7888  \n",
      "\n",
      "Fold: 28  Epoch: 8  Training loss = 2.2355  Validation loss = 0.7875  \n",
      "\n",
      "Fold: 28  Epoch: 9  Training loss = 2.2333  Validation loss = 0.7902  \n",
      "\n",
      "Fold: 28  Epoch: 10  Training loss = 2.2319  Validation loss = 0.7886  \n",
      "\n",
      "Fold: 28  Epoch: 11  Training loss = 2.2309  Validation loss = 0.7888  \n",
      "\n",
      "Fold: 28  Epoch: 12  Training loss = 2.2347  Validation loss = 0.7889  \n",
      "\n",
      "Fold: 28  Epoch: 13  Training loss = 2.2280  Validation loss = 0.7906  \n",
      "\n",
      "Fold: 28  Epoch: 14  Training loss = 2.2471  Validation loss = 0.7945  \n",
      "\n",
      "Check model:  Fold: 28  Optimal epoch: 5  \n",
      "\n",
      "Fold: 29  Epoch: 1  Training loss = 2.1955  Validation loss = 0.6436  \n",
      "\n",
      "Fold: 29  Epoch: 2  Training loss = 2.2136  Validation loss = 0.6339  \n",
      "\n",
      "Fold: 29  Epoch: 3  Training loss = 2.1915  Validation loss = 0.6413  \n",
      "\n",
      "Fold: 29  Epoch: 4  Training loss = 2.1895  Validation loss = 0.6420  \n",
      "\n",
      "Fold: 29  Epoch: 5  Training loss = 2.1872  Validation loss = 0.6394  \n",
      "\n",
      "Fold: 29  Epoch: 6  Training loss = 2.1936  Validation loss = 0.6409  \n",
      "\n",
      "Fold: 29  Epoch: 7  Training loss = 2.1865  Validation loss = 0.6383  \n",
      "\n",
      "Fold: 29  Epoch: 8  Training loss = 2.1856  Validation loss = 0.6348  \n",
      "\n",
      "Fold: 29  Epoch: 9  Training loss = 2.1832  Validation loss = 0.6346  \n",
      "\n",
      "Fold: 29  Epoch: 10  Training loss = 2.1875  Validation loss = 0.6312  \n",
      "\n",
      "Fold: 29  Epoch: 11  Training loss = 2.1811  Validation loss = 0.6340  \n",
      "\n",
      "Fold: 29  Epoch: 12  Training loss = 2.1825  Validation loss = 0.6335  \n",
      "\n",
      "Fold: 29  Epoch: 13  Training loss = 2.1784  Validation loss = 0.6316  \n",
      "\n",
      "Fold: 29  Epoch: 14  Training loss = 2.1847  Validation loss = 0.6315  \n",
      "\n",
      "Fold: 29  Epoch: 15  Training loss = 2.1809  Validation loss = 0.6300  \n",
      "\n",
      "Fold: 29  Epoch: 16  Training loss = 2.1756  Validation loss = 0.6277  \n",
      "\n",
      "Fold: 29  Epoch: 17  Training loss = 2.1757  Validation loss = 0.6261  \n",
      "\n",
      "Fold: 29  Epoch: 18  Training loss = 2.1744  Validation loss = 0.6253  \n",
      "\n",
      "Fold: 29  Epoch: 19  Training loss = 2.1766  Validation loss = 0.6257  \n",
      "\n",
      "Fold: 29  Epoch: 20  Training loss = 2.1763  Validation loss = 0.6256  \n",
      "\n",
      "Fold: 29  Epoch: 21  Training loss = 2.1747  Validation loss = 0.6247  \n",
      "\n",
      "Fold: 29  Epoch: 22  Training loss = 2.1700  Validation loss = 0.6235  \n",
      "\n",
      "Fold: 29  Epoch: 23  Training loss = 2.1703  Validation loss = 0.6236  \n",
      "\n",
      "Fold: 29  Epoch: 24  Training loss = 2.1684  Validation loss = 0.6234  \n",
      "\n",
      "Fold: 29  Epoch: 25  Training loss = 2.1785  Validation loss = 0.6227  \n",
      "\n",
      "Fold: 29  Epoch: 26  Training loss = 2.1663  Validation loss = 0.6207  \n",
      "\n",
      "Fold: 29  Epoch: 27  Training loss = 2.1671  Validation loss = 0.6201  \n",
      "\n",
      "Fold: 29  Epoch: 28  Training loss = 2.1644  Validation loss = 0.6197  \n",
      "\n",
      "Fold: 29  Epoch: 29  Training loss = 2.1627  Validation loss = 0.6174  \n",
      "\n",
      "Fold: 29  Epoch: 30  Training loss = 2.1627  Validation loss = 0.6158  \n",
      "\n",
      "Fold: 29  Epoch: 31  Training loss = 2.1603  Validation loss = 0.6148  \n",
      "\n",
      "Fold: 29  Epoch: 32  Training loss = 2.1594  Validation loss = 0.6141  \n",
      "\n",
      "Fold: 29  Epoch: 33  Training loss = 2.1595  Validation loss = 0.6143  \n",
      "\n",
      "Fold: 29  Epoch: 34  Training loss = 2.1591  Validation loss = 0.6134  \n",
      "\n",
      "Fold: 29  Epoch: 35  Training loss = 2.1643  Validation loss = 0.6138  \n",
      "\n",
      "Fold: 29  Epoch: 36  Training loss = 2.1579  Validation loss = 0.6128  \n",
      "\n",
      "Fold: 29  Epoch: 37  Training loss = 2.1612  Validation loss = 0.6126  \n",
      "\n",
      "Fold: 29  Epoch: 38  Training loss = 2.1541  Validation loss = 0.6120  \n",
      "\n",
      "Fold: 29  Epoch: 39  Training loss = 2.1557  Validation loss = 0.6106  \n",
      "\n",
      "Fold: 29  Epoch: 40  Training loss = 2.1535  Validation loss = 0.6093  \n",
      "\n",
      "Fold: 29  Epoch: 41  Training loss = 2.1552  Validation loss = 0.6084  \n",
      "\n",
      "Fold: 29  Epoch: 42  Training loss = 2.1529  Validation loss = 0.6071  \n",
      "\n",
      "Fold: 29  Epoch: 43  Training loss = 2.1494  Validation loss = 0.6068  \n",
      "\n",
      "Fold: 29  Epoch: 44  Training loss = 2.1600  Validation loss = 0.6069  \n",
      "\n",
      "Fold: 29  Epoch: 45  Training loss = 2.1519  Validation loss = 0.6054  \n",
      "\n",
      "Fold: 29  Epoch: 46  Training loss = 2.1506  Validation loss = 0.6050  \n",
      "\n",
      "Fold: 29  Epoch: 47  Training loss = 2.1507  Validation loss = 0.6042  \n",
      "\n",
      "Fold: 29  Epoch: 48  Training loss = 2.1480  Validation loss = 0.6039  \n",
      "\n",
      "Fold: 29  Epoch: 49  Training loss = 2.1451  Validation loss = 0.6021  \n",
      "\n",
      "Fold: 29  Epoch: 50  Training loss = 2.1454  Validation loss = 0.6019  \n",
      "\n",
      "Fold: 29  Epoch: 51  Training loss = 2.1463  Validation loss = 0.6026  \n",
      "\n",
      "Fold: 29  Epoch: 52  Training loss = 2.1478  Validation loss = 0.6029  \n",
      "\n",
      "Fold: 29  Epoch: 53  Training loss = 2.1459  Validation loss = 0.6019  \n",
      "\n",
      "Fold: 29  Epoch: 54  Training loss = 2.1437  Validation loss = 0.6012  \n",
      "\n",
      "Fold: 29  Epoch: 55  Training loss = 2.1419  Validation loss = 0.6001  \n",
      "\n",
      "Fold: 29  Epoch: 56  Training loss = 2.1401  Validation loss = 0.6013  \n",
      "\n",
      "Fold: 29  Epoch: 57  Training loss = 2.1412  Validation loss = 0.6008  \n",
      "\n",
      "Fold: 29  Epoch: 58  Training loss = 2.1402  Validation loss = 0.6026  \n",
      "\n",
      "Fold: 29  Epoch: 59  Training loss = 2.1455  Validation loss = 0.6026  \n",
      "\n",
      "Fold: 29  Epoch: 60  Training loss = 2.1374  Validation loss = 0.6025  \n",
      "\n",
      "Fold: 29  Epoch: 61  Training loss = 2.1367  Validation loss = 0.6017  \n",
      "\n",
      "Fold: 29  Epoch: 62  Training loss = 2.1381  Validation loss = 0.6010  \n",
      "\n",
      "Fold: 29  Epoch: 63  Training loss = 2.1374  Validation loss = 0.6006  \n",
      "\n",
      "Fold: 29  Epoch: 64  Training loss = 2.1352  Validation loss = 0.6000  \n",
      "\n",
      "Fold: 29  Epoch: 65  Training loss = 2.1362  Validation loss = 0.5999  \n",
      "\n",
      "Fold: 29  Epoch: 66  Training loss = 2.1395  Validation loss = 0.6003  \n",
      "\n",
      "Fold: 29  Epoch: 67  Training loss = 2.1339  Validation loss = 0.6010  \n",
      "\n",
      "Fold: 29  Epoch: 68  Training loss = 2.1362  Validation loss = 0.6021  \n",
      "\n",
      "Fold: 29  Epoch: 69  Training loss = 2.1335  Validation loss = 0.6002  \n",
      "\n",
      "Fold: 29  Epoch: 70  Training loss = 2.1333  Validation loss = 0.5991  \n",
      "\n",
      "Fold: 29  Epoch: 71  Training loss = 2.1296  Validation loss = 0.6011  \n",
      "\n",
      "Fold: 29  Epoch: 72  Training loss = 2.1290  Validation loss = 0.5996  \n",
      "\n",
      "Fold: 29  Epoch: 73  Training loss = 2.1322  Validation loss = 0.6016  \n",
      "\n",
      "Fold: 29  Epoch: 74  Training loss = 2.1301  Validation loss = 0.6018  \n",
      "\n",
      "Fold: 29  Epoch: 75  Training loss = 2.1298  Validation loss = 0.6007  \n",
      "\n",
      "Fold: 29  Epoch: 76  Training loss = 2.1275  Validation loss = 0.5989  \n",
      "\n",
      "Fold: 29  Epoch: 77  Training loss = 2.1256  Validation loss = 0.5985  \n",
      "\n",
      "Fold: 29  Epoch: 78  Training loss = 2.1265  Validation loss = 0.5994  \n",
      "\n",
      "Fold: 29  Epoch: 79  Training loss = 2.1284  Validation loss = 0.5994  \n",
      "\n",
      "Fold: 29  Epoch: 80  Training loss = 2.1265  Validation loss = 0.5961  \n",
      "\n",
      "Fold: 29  Epoch: 81  Training loss = 2.1234  Validation loss = 0.5957  \n",
      "\n",
      "Fold: 29  Epoch: 82  Training loss = 2.1241  Validation loss = 0.5948  \n",
      "\n",
      "Fold: 29  Epoch: 83  Training loss = 2.1292  Validation loss = 0.5934  \n",
      "\n",
      "Fold: 29  Epoch: 84  Training loss = 2.1236  Validation loss = 0.5933  \n",
      "\n",
      "Fold: 29  Epoch: 85  Training loss = 2.1219  Validation loss = 0.5928  \n",
      "\n",
      "Fold: 29  Epoch: 86  Training loss = 2.1208  Validation loss = 0.5936  \n",
      "\n",
      "Fold: 29  Epoch: 87  Training loss = 2.1203  Validation loss = 0.5942  \n",
      "\n",
      "Fold: 29  Epoch: 88  Training loss = 2.1222  Validation loss = 0.5952  \n",
      "\n",
      "Fold: 29  Epoch: 89  Training loss = 2.1550  Validation loss = 0.5988  \n",
      "\n",
      "Check model:  Fold: 29  Optimal epoch: 85  \n",
      "\n",
      "Fold: 30  Epoch: 1  Training loss = 2.1106  Validation loss = 1.1101  \n",
      "\n",
      "Fold: 30  Epoch: 2  Training loss = 2.1113  Validation loss = 1.1219  \n",
      "\n",
      "Fold: 30  Epoch: 3  Training loss = 2.1111  Validation loss = 1.0966  \n",
      "\n",
      "Fold: 30  Epoch: 4  Training loss = 2.1090  Validation loss = 1.1111  \n",
      "\n",
      "Fold: 30  Epoch: 5  Training loss = 2.1117  Validation loss = 1.1315  \n",
      "\n",
      "Fold: 30  Epoch: 6  Training loss = 2.1094  Validation loss = 1.1230  \n",
      "\n",
      "Fold: 30  Epoch: 7  Training loss = 2.1088  Validation loss = 1.1016  \n",
      "\n",
      "Fold: 30  Epoch: 8  Training loss = 2.1074  Validation loss = 1.1243  \n",
      "\n",
      "Fold: 30  Epoch: 9  Training loss = 2.1048  Validation loss = 1.1071  \n",
      "\n",
      "Fold: 30  Epoch: 10  Training loss = 2.1065  Validation loss = 1.0894  \n",
      "\n",
      "Fold: 30  Epoch: 11  Training loss = 2.1035  Validation loss = 1.1043  \n",
      "\n",
      "Fold: 30  Epoch: 12  Training loss = 2.1031  Validation loss = 1.1080  \n",
      "\n",
      "Fold: 30  Epoch: 13  Training loss = 2.1030  Validation loss = 1.1109  \n",
      "\n",
      "Fold: 30  Epoch: 14  Training loss = 2.1055  Validation loss = 1.1380  \n",
      "\n",
      "Check model:  Fold: 30  Optimal epoch: 10  \n",
      "\n",
      "Fold: 31  Epoch: 1  Training loss = 2.0117  Validation loss = 0.4785  \n",
      "\n",
      "Fold: 31  Epoch: 2  Training loss = 2.0110  Validation loss = 0.4768  \n",
      "\n",
      "Fold: 31  Epoch: 3  Training loss = 2.0108  Validation loss = 0.4779  \n",
      "\n",
      "Fold: 31  Epoch: 4  Training loss = 2.0105  Validation loss = 0.4726  \n",
      "\n",
      "Fold: 31  Epoch: 5  Training loss = 2.0091  Validation loss = 0.4779  \n",
      "\n",
      "Fold: 31  Epoch: 6  Training loss = 2.0448  Validation loss = 0.5180  \n",
      "\n",
      "Fold: 31  Epoch: 7  Training loss = 2.0128  Validation loss = 0.4878  \n",
      "\n",
      "Fold: 31  Epoch: 8  Training loss = 2.0215  Validation loss = 0.4928  \n",
      "\n",
      "Fold: 31  Epoch: 9  Training loss = 2.0164  Validation loss = 0.4699  \n",
      "\n",
      "Fold: 31  Epoch: 10  Training loss = 2.0097  Validation loss = 0.4911  \n",
      "\n",
      "Fold: 31  Epoch: 11  Training loss = 2.0081  Validation loss = 0.4823  \n",
      "\n",
      "Fold: 31  Epoch: 12  Training loss = 2.0094  Validation loss = 0.4949  \n",
      "\n",
      "Fold: 31  Epoch: 13  Training loss = 2.0084  Validation loss = 0.4984  \n",
      "\n",
      "Fold: 31  Epoch: 14  Training loss = 2.0080  Validation loss = 0.4866  \n",
      "\n",
      "Fold: 31  Epoch: 15  Training loss = 2.0069  Validation loss = 0.4879  \n",
      "\n",
      "Fold: 31  Epoch: 16  Training loss = 2.0482  Validation loss = 0.5296  \n",
      "\n",
      "Check model:  Fold: 31  Optimal epoch: 9  \n",
      "\n",
      "Fold: 32  Epoch: 1  Training loss = 1.5993  Validation loss = 1.9580  \n",
      "\n",
      "Fold: 32  Epoch: 2  Training loss = 1.6008  Validation loss = 1.9881  \n",
      "\n",
      "Fold: 32  Epoch: 3  Training loss = 1.6010  Validation loss = 1.9012  \n",
      "\n",
      "Fold: 32  Epoch: 4  Training loss = 1.6007  Validation loss = 1.8927  \n",
      "\n",
      "Fold: 32  Epoch: 5  Training loss = 1.5950  Validation loss = 1.9654  \n",
      "\n",
      "Fold: 32  Epoch: 6  Training loss = 1.5952  Validation loss = 1.9803  \n",
      "\n",
      "Fold: 32  Epoch: 7  Training loss = 1.5962  Validation loss = 1.9819  \n",
      "\n",
      "Fold: 32  Epoch: 8  Training loss = 1.5970  Validation loss = 1.9368  \n",
      "\n",
      "Fold: 32  Epoch: 9  Training loss = 1.6021  Validation loss = 2.0920  \n",
      "\n",
      "Fold: 32  Epoch: 10  Training loss = 1.6033  Validation loss = 2.1169  \n",
      "\n",
      "Fold: 32  Epoch: 11  Training loss = 1.5980  Validation loss = 2.1002  \n",
      "\n",
      "Fold: 32  Epoch: 12  Training loss = 1.5959  Validation loss = 2.0964  \n",
      "\n",
      "Fold: 32  Epoch: 13  Training loss = 1.5964  Validation loss = 2.0999  \n",
      "\n",
      "Fold: 32  Epoch: 14  Training loss = 1.5949  Validation loss = 2.0683  \n",
      "\n",
      "Fold: 32  Epoch: 15  Training loss = 1.5949  Validation loss = 2.0684  \n",
      "\n",
      "Fold: 32  Epoch: 16  Training loss = 1.5926  Validation loss = 2.0046  \n",
      "\n",
      "Fold: 32  Epoch: 17  Training loss = 1.5914  Validation loss = 2.0286  \n",
      "\n",
      "Fold: 32  Epoch: 18  Training loss = 1.5895  Validation loss = 2.0285  \n",
      "\n",
      "Fold: 32  Epoch: 19  Training loss = 1.5895  Validation loss = 1.9579  \n",
      "\n",
      "Fold: 32  Epoch: 20  Training loss = 1.5876  Validation loss = 2.0192  \n",
      "\n",
      "Fold: 32  Epoch: 21  Training loss = 1.5882  Validation loss = 1.9558  \n",
      "\n",
      "Fold: 32  Epoch: 22  Training loss = 1.5872  Validation loss = 2.0615  \n",
      "\n",
      "Fold: 32  Epoch: 23  Training loss = 1.5868  Validation loss = 2.0220  \n",
      "\n",
      "Fold: 32  Epoch: 24  Training loss = 1.5866  Validation loss = 2.0402  \n",
      "\n",
      "Fold: 32  Epoch: 25  Training loss = 1.5862  Validation loss = 2.0452  \n",
      "\n",
      "Fold: 32  Epoch: 26  Training loss = 1.5854  Validation loss = 1.9411  \n",
      "\n",
      "Fold: 32  Epoch: 27  Training loss = 1.5882  Validation loss = 1.8680  \n",
      "\n",
      "Fold: 32  Epoch: 28  Training loss = 1.5859  Validation loss = 1.8827  \n",
      "\n",
      "Fold: 32  Epoch: 29  Training loss = 1.5834  Validation loss = 1.9141  \n",
      "\n",
      "Fold: 32  Epoch: 30  Training loss = 1.5819  Validation loss = 1.9425  \n",
      "\n",
      "Fold: 32  Epoch: 31  Training loss = 1.5846  Validation loss = 1.8765  \n",
      "\n",
      "Fold: 32  Epoch: 32  Training loss = 1.5824  Validation loss = 1.9056  \n",
      "\n",
      "Fold: 32  Epoch: 33  Training loss = 1.5816  Validation loss = 1.9025  \n",
      "\n",
      "Fold: 32  Epoch: 34  Training loss = 1.5793  Validation loss = 1.9494  \n",
      "\n",
      "Fold: 32  Epoch: 35  Training loss = 1.5794  Validation loss = 1.9493  \n",
      "\n",
      "Fold: 32  Epoch: 36  Training loss = 1.5791  Validation loss = 2.0036  \n",
      "\n",
      "Check model:  Fold: 32  Optimal epoch: 27  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 2. Train model\n",
    "# ==================================\n",
    "sess = tf.InteractiveSession()  # Launch Graph\n",
    "sess.run(tf.global_variables_initializer())  # Initialise all variables\n",
    "\n",
    "print(\"Start training\", \n",
    "      \"\\nHyperparameters:\",\n",
    "      \"\\nDimension of recurrent unit =\", n_hidden,\n",
    "      \"\\nLearning rate =\", learning_rate,\n",
    "      \"\\nEpochs =\", epochs,\n",
    "      \"\\nBatch size =\", batch_size,\n",
    "      \"\\nEarly stopping epochs =\", early_stop_iters,\n",
    "      \"\\nLearning rate =\", learning_rate)\n",
    "\n",
    "total_batch = int(window_length / batch_size)\n",
    "validation_fold_error = [] # store validation error of each fold\n",
    "optimal_epochs = []\n",
    "\n",
    "# loop through folds\n",
    "for fold in range(1, len(valIndex)):\n",
    "    validx = train_features[valIndex[fold-1]:valIndex[fold]]\n",
    "    validy = train_target[valIndex[fold-1]:valIndex[fold]]\n",
    "    trainx = train_features[(fold-1)*4:valIndex[(fold-1)]]\n",
    "    trainy = train_target[(fold-1)*4:valIndex[(fold-1)]]\n",
    "\n",
    "    loss_list = [] # store validation loss after each epoch for early stopping\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i in range(total_batch):\n",
    "            # Backprop\n",
    "            batch_xs, batch_ys = next_batch(num=batch_size, data=trainx, labels=trainy)\n",
    "            optimizer.run(feed_dict={x:batch_xs, y:batch_ys, lr:learning_rate})\n",
    "\n",
    "        # Loss\n",
    "        loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "        loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "        loss_list.append(loss_valid)\n",
    "\n",
    "        print(\"Fold: {0:d}\".format(fold),\n",
    "              \" Epoch: {0:d}\".format(epoch+1),\n",
    "              \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "              \" Validation loss = {0:.4f}\".format(np.sqrt(loss_valid)),\n",
    "              \" \\n\")\n",
    "\n",
    "        if all(j <= loss_valid for j in loss_list[-early_stop_iters:]) and len(loss_list)>early_stop_iters:\n",
    "            break\n",
    "    \n",
    "    # Load model with lowest validation error for each fold\n",
    "    epoch_hat = np.argmin(loss_list) + 1\n",
    "    optimal_epochs.append(epoch_hat) # store optimal number of epochs for each fold\n",
    "    \n",
    "    # RMSE\n",
    "    loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "    loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "    validation_fold_error.append(np.sqrt(loss_valid))\n",
    "    \n",
    "    print(\"Check model:\",\n",
    "          \" Fold: {0:d}\".format(fold),\n",
    "          \" Optimal epoch: {0:d}\".format(epoch_hat),\n",
    "          \" \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average number of epochs: 214\n",
      "Average validation error: 2.61047\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 3. Optimal epoch choice\n",
    "# ==================================\n",
    "# Pick number of epochs to train model for out-of-sample testing\n",
    "epoch_hat = int(np.mean(optimal_epochs))\n",
    "print(\"\\nAverage number of epochs:\", epoch_hat)\n",
    "# Average validation error\n",
    "print(\"Average validation error:\", np.mean(validation_fold_error))\n",
    "\n",
    "# Save validated model\n",
    "saveModel(sess, \n",
    "          MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + str(epoch_hat) + \"_validated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fixed scheme:\n",
      "Epoch: 1  Training loss = 1.5243  Test loss = 2.5655  \n",
      "\n",
      "Epoch: 2  Training loss = 1.5236  Test loss = 2.5622  \n",
      "\n",
      "Epoch: 3  Training loss = 1.5230  Test loss = 2.5591  \n",
      "\n",
      "Epoch: 4  Training loss = 1.5224  Test loss = 2.5561  \n",
      "\n",
      "Epoch: 5  Training loss = 1.5219  Test loss = 2.5532  \n",
      "\n",
      "Epoch: 6  Training loss = 1.5214  Test loss = 2.5505  \n",
      "\n",
      "Epoch: 7  Training loss = 1.5209  Test loss = 2.5479  \n",
      "\n",
      "Epoch: 8  Training loss = 1.5205  Test loss = 2.5454  \n",
      "\n",
      "Epoch: 9  Training loss = 1.5201  Test loss = 2.5430  \n",
      "\n",
      "Epoch: 10  Training loss = 1.5197  Test loss = 2.5407  \n",
      "\n",
      "Epoch: 11  Training loss = 1.5193  Test loss = 2.5385  \n",
      "\n",
      "Epoch: 12  Training loss = 1.5189  Test loss = 2.5364  \n",
      "\n",
      "Epoch: 13  Training loss = 1.5186  Test loss = 2.5344  \n",
      "\n",
      "Epoch: 14  Training loss = 1.5183  Test loss = 2.5325  \n",
      "\n",
      "Epoch: 15  Training loss = 1.5180  Test loss = 2.5307  \n",
      "\n",
      "Epoch: 16  Training loss = 1.5177  Test loss = 2.5290  \n",
      "\n",
      "Epoch: 17  Training loss = 1.5174  Test loss = 2.5273  \n",
      "\n",
      "Epoch: 18  Training loss = 1.5172  Test loss = 2.5257  \n",
      "\n",
      "Epoch: 19  Training loss = 1.5169  Test loss = 2.5242  \n",
      "\n",
      "Epoch: 20  Training loss = 1.5167  Test loss = 2.5228  \n",
      "\n",
      "Epoch: 21  Training loss = 1.5165  Test loss = 2.5214  \n",
      "\n",
      "Epoch: 22  Training loss = 1.5163  Test loss = 2.5200  \n",
      "\n",
      "Epoch: 23  Training loss = 1.5161  Test loss = 2.5188  \n",
      "\n",
      "Epoch: 24  Training loss = 1.5159  Test loss = 2.5176  \n",
      "\n",
      "Epoch: 25  Training loss = 1.5157  Test loss = 2.5164  \n",
      "\n",
      "Epoch: 26  Training loss = 1.5155  Test loss = 2.5153  \n",
      "\n",
      "Epoch: 27  Training loss = 1.5153  Test loss = 2.5142  \n",
      "\n",
      "Epoch: 28  Training loss = 1.5151  Test loss = 2.5132  \n",
      "\n",
      "Epoch: 29  Training loss = 1.5150  Test loss = 2.5122  \n",
      "\n",
      "Epoch: 30  Training loss = 1.5148  Test loss = 2.5113  \n",
      "\n",
      "Epoch: 31  Training loss = 1.5146  Test loss = 2.5104  \n",
      "\n",
      "Epoch: 32  Training loss = 1.5145  Test loss = 2.5096  \n",
      "\n",
      "Epoch: 33  Training loss = 1.5143  Test loss = 2.5088  \n",
      "\n",
      "Epoch: 34  Training loss = 1.5142  Test loss = 2.5080  \n",
      "\n",
      "Epoch: 35  Training loss = 1.5140  Test loss = 2.5072  \n",
      "\n",
      "Epoch: 36  Training loss = 1.5139  Test loss = 2.5065  \n",
      "\n",
      "Epoch: 37  Training loss = 1.5137  Test loss = 2.5058  \n",
      "\n",
      "Epoch: 38  Training loss = 1.5136  Test loss = 2.5052  \n",
      "\n",
      "Epoch: 39  Training loss = 1.5135  Test loss = 2.5045  \n",
      "\n",
      "Epoch: 40  Training loss = 1.5133  Test loss = 2.5039  \n",
      "\n",
      "Epoch: 41  Training loss = 1.5132  Test loss = 2.5033  \n",
      "\n",
      "Epoch: 42  Training loss = 1.5131  Test loss = 2.5028  \n",
      "\n",
      "Epoch: 43  Training loss = 1.5129  Test loss = 2.5022  \n",
      "\n",
      "Epoch: 44  Training loss = 1.5128  Test loss = 2.5017  \n",
      "\n",
      "Epoch: 45  Training loss = 1.5127  Test loss = 2.5012  \n",
      "\n",
      "Epoch: 46  Training loss = 1.5126  Test loss = 2.5007  \n",
      "\n",
      "Epoch: 47  Training loss = 1.5125  Test loss = 2.5003  \n",
      "\n",
      "Epoch: 48  Training loss = 1.5123  Test loss = 2.4998  \n",
      "\n",
      "Epoch: 49  Training loss = 1.5122  Test loss = 2.4994  \n",
      "\n",
      "Epoch: 50  Training loss = 1.5121  Test loss = 2.4990  \n",
      "\n",
      "Epoch: 51  Training loss = 1.5120  Test loss = 2.4986  \n",
      "\n",
      "Epoch: 52  Training loss = 1.5119  Test loss = 2.4982  \n",
      "\n",
      "Epoch: 53  Training loss = 1.5117  Test loss = 2.4979  \n",
      "\n",
      "Epoch: 54  Training loss = 1.5116  Test loss = 2.4975  \n",
      "\n",
      "Epoch: 55  Training loss = 1.5115  Test loss = 2.4972  \n",
      "\n",
      "Epoch: 56  Training loss = 1.5114  Test loss = 2.4969  \n",
      "\n",
      "Epoch: 57  Training loss = 1.5113  Test loss = 2.4966  \n",
      "\n",
      "Epoch: 58  Training loss = 1.5112  Test loss = 2.4963  \n",
      "\n",
      "Epoch: 59  Training loss = 1.5111  Test loss = 2.4960  \n",
      "\n",
      "Epoch: 60  Training loss = 1.5110  Test loss = 2.4957  \n",
      "\n",
      "Epoch: 61  Training loss = 1.5108  Test loss = 2.4954  \n",
      "\n",
      "Epoch: 62  Training loss = 1.5107  Test loss = 2.4952  \n",
      "\n",
      "Epoch: 63  Training loss = 1.5106  Test loss = 2.4949  \n",
      "\n",
      "Epoch: 64  Training loss = 1.5105  Test loss = 2.4947  \n",
      "\n",
      "Epoch: 65  Training loss = 1.5104  Test loss = 2.4944  \n",
      "\n",
      "Epoch: 66  Training loss = 1.5103  Test loss = 2.4942  \n",
      "\n",
      "Epoch: 67  Training loss = 1.5102  Test loss = 2.4940  \n",
      "\n",
      "Epoch: 68  Training loss = 1.5101  Test loss = 2.4938  \n",
      "\n",
      "Epoch: 69  Training loss = 1.5100  Test loss = 2.4936  \n",
      "\n",
      "Epoch: 70  Training loss = 1.5099  Test loss = 2.4934  \n",
      "\n",
      "Epoch: 71  Training loss = 1.5098  Test loss = 2.4932  \n",
      "\n",
      "Epoch: 72  Training loss = 1.5097  Test loss = 2.4930  \n",
      "\n",
      "Epoch: 73  Training loss = 1.5096  Test loss = 2.4928  \n",
      "\n",
      "Epoch: 74  Training loss = 1.5095  Test loss = 2.4926  \n",
      "\n",
      "Epoch: 75  Training loss = 1.5094  Test loss = 2.4925  \n",
      "\n",
      "Epoch: 76  Training loss = 1.5092  Test loss = 2.4923  \n",
      "\n",
      "Epoch: 77  Training loss = 1.5091  Test loss = 2.4922  \n",
      "\n",
      "Epoch: 78  Training loss = 1.5090  Test loss = 2.4920  \n",
      "\n",
      "Epoch: 79  Training loss = 1.5089  Test loss = 2.4919  \n",
      "\n",
      "Epoch: 80  Training loss = 1.5088  Test loss = 2.4917  \n",
      "\n",
      "Epoch: 81  Training loss = 1.5087  Test loss = 2.4916  \n",
      "\n",
      "Epoch: 82  Training loss = 1.5086  Test loss = 2.4914  \n",
      "\n",
      "Epoch: 83  Training loss = 1.5085  Test loss = 2.4913  \n",
      "\n",
      "Epoch: 84  Training loss = 1.5084  Test loss = 2.4912  \n",
      "\n",
      "Epoch: 85  Training loss = 1.5083  Test loss = 2.4911  \n",
      "\n",
      "Epoch: 86  Training loss = 1.5082  Test loss = 2.4909  \n",
      "\n",
      "Epoch: 87  Training loss = 1.5081  Test loss = 2.4908  \n",
      "\n",
      "Epoch: 88  Training loss = 1.5080  Test loss = 2.4907  \n",
      "\n",
      "Epoch: 89  Training loss = 1.5079  Test loss = 2.4906  \n",
      "\n",
      "Epoch: 90  Training loss = 1.5078  Test loss = 2.4905  \n",
      "\n",
      "Epoch: 91  Training loss = 1.5077  Test loss = 2.4904  \n",
      "\n",
      "Epoch: 92  Training loss = 1.5076  Test loss = 2.4903  \n",
      "\n",
      "Epoch: 93  Training loss = 1.5075  Test loss = 2.4902  \n",
      "\n",
      "Epoch: 94  Training loss = 1.5074  Test loss = 2.4901  \n",
      "\n",
      "Epoch: 95  Training loss = 1.5073  Test loss = 2.4900  \n",
      "\n",
      "Epoch: 96  Training loss = 1.5072  Test loss = 2.4899  \n",
      "\n",
      "Epoch: 97  Training loss = 1.5071  Test loss = 2.4898  \n",
      "\n",
      "Epoch: 98  Training loss = 1.5070  Test loss = 2.4897  \n",
      "\n",
      "Epoch: 99  Training loss = 1.5069  Test loss = 2.4897  \n",
      "\n",
      "Epoch: 100  Training loss = 1.5068  Test loss = 2.4896  \n",
      "\n",
      "Epoch: 101  Training loss = 1.5067  Test loss = 2.4895  \n",
      "\n",
      "Epoch: 102  Training loss = 1.5066  Test loss = 2.4894  \n",
      "\n",
      "Epoch: 103  Training loss = 1.5065  Test loss = 2.4894  \n",
      "\n",
      "Epoch: 104  Training loss = 1.5064  Test loss = 2.4893  \n",
      "\n",
      "Epoch: 105  Training loss = 1.5063  Test loss = 2.4892  \n",
      "\n",
      "Epoch: 106  Training loss = 1.5062  Test loss = 2.4891  \n",
      "\n",
      "Epoch: 107  Training loss = 1.5061  Test loss = 2.4891  \n",
      "\n",
      "Epoch: 108  Training loss = 1.5060  Test loss = 2.4890  \n",
      "\n",
      "Epoch: 109  Training loss = 1.5059  Test loss = 2.4889  \n",
      "\n",
      "Epoch: 110  Training loss = 1.5058  Test loss = 2.4889  \n",
      "\n",
      "Epoch: 111  Training loss = 1.5057  Test loss = 2.4888  \n",
      "\n",
      "Epoch: 112  Training loss = 1.5056  Test loss = 2.4888  \n",
      "\n",
      "Epoch: 113  Training loss = 1.5055  Test loss = 2.4887  \n",
      "\n",
      "Epoch: 114  Training loss = 1.5054  Test loss = 2.4886  \n",
      "\n",
      "Epoch: 115  Training loss = 1.5053  Test loss = 2.4886  \n",
      "\n",
      "Epoch: 116  Training loss = 1.5052  Test loss = 2.4885  \n",
      "\n",
      "Epoch: 117  Training loss = 1.5051  Test loss = 2.4885  \n",
      "\n",
      "Epoch: 118  Training loss = 1.5050  Test loss = 2.4884  \n",
      "\n",
      "Epoch: 119  Training loss = 1.5049  Test loss = 2.4884  \n",
      "\n",
      "Epoch: 120  Training loss = 1.5048  Test loss = 2.4883  \n",
      "\n",
      "Epoch: 121  Training loss = 1.5047  Test loss = 2.4883  \n",
      "\n",
      "Epoch: 122  Training loss = 1.5046  Test loss = 2.4882  \n",
      "\n",
      "Epoch: 123  Training loss = 1.5045  Test loss = 2.4882  \n",
      "\n",
      "Epoch: 124  Training loss = 1.5044  Test loss = 2.4881  \n",
      "\n",
      "Epoch: 125  Training loss = 1.5043  Test loss = 2.4881  \n",
      "\n",
      "Epoch: 126  Training loss = 1.5042  Test loss = 2.4881  \n",
      "\n",
      "Epoch: 127  Training loss = 1.5041  Test loss = 2.4880  \n",
      "\n",
      "Epoch: 128  Training loss = 1.5040  Test loss = 2.4880  \n",
      "\n",
      "Epoch: 129  Training loss = 1.5039  Test loss = 2.4879  \n",
      "\n",
      "Epoch: 130  Training loss = 1.5038  Test loss = 2.4879  \n",
      "\n",
      "Epoch: 131  Training loss = 1.5037  Test loss = 2.4878  \n",
      "\n",
      "Epoch: 132  Training loss = 1.5036  Test loss = 2.4878  \n",
      "\n",
      "Epoch: 133  Training loss = 1.5035  Test loss = 2.4878  \n",
      "\n",
      "Epoch: 134  Training loss = 1.5034  Test loss = 2.4877  \n",
      "\n",
      "Epoch: 135  Training loss = 1.5033  Test loss = 2.4877  \n",
      "\n",
      "Epoch: 136  Training loss = 1.5032  Test loss = 2.4877  \n",
      "\n",
      "Epoch: 137  Training loss = 1.5031  Test loss = 2.4876  \n",
      "\n",
      "Epoch: 138  Training loss = 1.5030  Test loss = 2.4876  \n",
      "\n",
      "Epoch: 139  Training loss = 1.5029  Test loss = 2.4876  \n",
      "\n",
      "Epoch: 140  Training loss = 1.5028  Test loss = 2.4875  \n",
      "\n",
      "Epoch: 141  Training loss = 1.5027  Test loss = 2.4875  \n",
      "\n",
      "Epoch: 142  Training loss = 1.5026  Test loss = 2.4875  \n",
      "\n",
      "Epoch: 143  Training loss = 1.5025  Test loss = 2.4874  \n",
      "\n",
      "Epoch: 144  Training loss = 1.5024  Test loss = 2.4874  \n",
      "\n",
      "Epoch: 145  Training loss = 1.5023  Test loss = 2.4874  \n",
      "\n",
      "Epoch: 146  Training loss = 1.5022  Test loss = 2.4873  \n",
      "\n",
      "Epoch: 147  Training loss = 1.5022  Test loss = 2.4873  \n",
      "\n",
      "Epoch: 148  Training loss = 1.5021  Test loss = 2.4873  \n",
      "\n",
      "Epoch: 149  Training loss = 1.5020  Test loss = 2.4872  \n",
      "\n",
      "Epoch: 150  Training loss = 1.5019  Test loss = 2.4872  \n",
      "\n",
      "Epoch: 151  Training loss = 1.5018  Test loss = 2.4872  \n",
      "\n",
      "Epoch: 152  Training loss = 1.5017  Test loss = 2.4872  \n",
      "\n",
      "Epoch: 153  Training loss = 1.5016  Test loss = 2.4871  \n",
      "\n",
      "Epoch: 154  Training loss = 1.5015  Test loss = 2.4871  \n",
      "\n",
      "Epoch: 155  Training loss = 1.5014  Test loss = 2.4871  \n",
      "\n",
      "Epoch: 156  Training loss = 1.5013  Test loss = 2.4871  \n",
      "\n",
      "Epoch: 157  Training loss = 1.5012  Test loss = 2.4870  \n",
      "\n",
      "Epoch: 158  Training loss = 1.5011  Test loss = 2.4870  \n",
      "\n",
      "Epoch: 159  Training loss = 1.5010  Test loss = 2.4870  \n",
      "\n",
      "Epoch: 160  Training loss = 1.5009  Test loss = 2.4870  \n",
      "\n",
      "Epoch: 161  Training loss = 1.5008  Test loss = 2.4869  \n",
      "\n",
      "Epoch: 162  Training loss = 1.5007  Test loss = 2.4869  \n",
      "\n",
      "Epoch: 163  Training loss = 1.5006  Test loss = 2.4869  \n",
      "\n",
      "Epoch: 164  Training loss = 1.5005  Test loss = 2.4869  \n",
      "\n",
      "Epoch: 165  Training loss = 1.5004  Test loss = 2.4868  \n",
      "\n",
      "Epoch: 166  Training loss = 1.5003  Test loss = 2.4868  \n",
      "\n",
      "Epoch: 167  Training loss = 1.5002  Test loss = 2.4868  \n",
      "\n",
      "Epoch: 168  Training loss = 1.5001  Test loss = 2.4868  \n",
      "\n",
      "Epoch: 169  Training loss = 1.5000  Test loss = 2.4868  \n",
      "\n",
      "Epoch: 170  Training loss = 1.4999  Test loss = 2.4867  \n",
      "\n",
      "Epoch: 171  Training loss = 1.4998  Test loss = 2.4867  \n",
      "\n",
      "Epoch: 172  Training loss = 1.4997  Test loss = 2.4867  \n",
      "\n",
      "Epoch: 173  Training loss = 1.4996  Test loss = 2.4867  \n",
      "\n",
      "Epoch: 174  Training loss = 1.4995  Test loss = 2.4867  \n",
      "\n",
      "Epoch: 175  Training loss = 1.4994  Test loss = 2.4866  \n",
      "\n",
      "Epoch: 176  Training loss = 1.4993  Test loss = 2.4866  \n",
      "\n",
      "Epoch: 177  Training loss = 1.4992  Test loss = 2.4866  \n",
      "\n",
      "Epoch: 178  Training loss = 1.4991  Test loss = 2.4866  \n",
      "\n",
      "Epoch: 179  Training loss = 1.4990  Test loss = 2.4866  \n",
      "\n",
      "Epoch: 180  Training loss = 1.4989  Test loss = 2.4866  \n",
      "\n",
      "Epoch: 181  Training loss = 1.4988  Test loss = 2.4865  \n",
      "\n",
      "Epoch: 182  Training loss = 1.4987  Test loss = 2.4865  \n",
      "\n",
      "Epoch: 183  Training loss = 1.4986  Test loss = 2.4865  \n",
      "\n",
      "Epoch: 184  Training loss = 1.4985  Test loss = 2.4865  \n",
      "\n",
      "Epoch: 185  Training loss = 1.4984  Test loss = 2.4865  \n",
      "\n",
      "Epoch: 186  Training loss = 1.4983  Test loss = 2.4865  \n",
      "\n",
      "Epoch: 187  Training loss = 1.4982  Test loss = 2.4864  \n",
      "\n",
      "Epoch: 188  Training loss = 1.4981  Test loss = 2.4864  \n",
      "\n",
      "Epoch: 189  Training loss = 1.4981  Test loss = 2.4864  \n",
      "\n",
      "Epoch: 190  Training loss = 1.4980  Test loss = 2.4864  \n",
      "\n",
      "Epoch: 191  Training loss = 1.4979  Test loss = 2.4864  \n",
      "\n",
      "Epoch: 192  Training loss = 1.4978  Test loss = 2.4864  \n",
      "\n",
      "Epoch: 193  Training loss = 1.4977  Test loss = 2.4864  \n",
      "\n",
      "Epoch: 194  Training loss = 1.4976  Test loss = 2.4863  \n",
      "\n",
      "Epoch: 195  Training loss = 1.4975  Test loss = 2.4863  \n",
      "\n",
      "Epoch: 196  Training loss = 1.4974  Test loss = 2.4863  \n",
      "\n",
      "Epoch: 197  Training loss = 1.4973  Test loss = 2.4863  \n",
      "\n",
      "Epoch: 198  Training loss = 1.4972  Test loss = 2.4863  \n",
      "\n",
      "Epoch: 199  Training loss = 1.4971  Test loss = 2.4863  \n",
      "\n",
      "Epoch: 200  Training loss = 1.4970  Test loss = 2.4863  \n",
      "\n",
      "Epoch: 201  Training loss = 1.4969  Test loss = 2.4863  \n",
      "\n",
      "Epoch: 202  Training loss = 1.4968  Test loss = 2.4862  \n",
      "\n",
      "Epoch: 203  Training loss = 1.4967  Test loss = 2.4862  \n",
      "\n",
      "Epoch: 204  Training loss = 1.4966  Test loss = 2.4862  \n",
      "\n",
      "Epoch: 205  Training loss = 1.4965  Test loss = 2.4862  \n",
      "\n",
      "Epoch: 206  Training loss = 1.4964  Test loss = 2.4862  \n",
      "\n",
      "Epoch: 207  Training loss = 1.4963  Test loss = 2.4862  \n",
      "\n",
      "Epoch: 208  Training loss = 1.4962  Test loss = 2.4862  \n",
      "\n",
      "Epoch: 209  Training loss = 1.4961  Test loss = 2.4862  \n",
      "\n",
      "Epoch: 210  Training loss = 1.4960  Test loss = 2.4862  \n",
      "\n",
      "Epoch: 211  Training loss = 1.4959  Test loss = 2.4861  \n",
      "\n",
      "Epoch: 212  Training loss = 1.4958  Test loss = 2.4861  \n",
      "\n",
      "Epoch: 213  Training loss = 1.4957  Test loss = 2.4861  \n",
      "\n",
      "Epoch: 214  Training loss = 1.4956  Test loss = 2.4861  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 4. Fixed scheme\n",
    "# ==================================\n",
    "print(\"\\nFixed scheme:\")\n",
    "for epoch in range(epoch_hat):\n",
    "    x_train = train_features[-window_length:]\n",
    "    y_train = train_target[-window_length:]\n",
    "    optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:test_features, y:test_target})\n",
    "    print(\"Epoch: {0:d}\".format(epoch+1),\n",
    "          \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "          \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "          \" \\n\")\n",
    "\n",
    "# Forecasts\n",
    "yhat_test_fixed = pred.eval(feed_dict={x:test_features})\n",
    "yhat_train_fixed = pred.eval(feed_dict={x:x_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc5b9128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train set\n",
    "plt.plot(y_train, 'black')\n",
    "plt.plot(yhat_train_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xcc8fba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: fixed scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_test_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed scheme RMSE: 2.48611361425 \n",
      "Fixed scheme MAE:  1.55252424697\n"
     ]
    }
   ],
   "source": [
    "rmse_fixed = np.sqrt(np.mean((yhat_test_fixed[:,0]-test_target)**2))\n",
    "mae_fixed = np.mean(np.abs((yhat_test_fixed[:,0]-test_target)))\n",
    "print(\"Fixed scheme RMSE:\", rmse_fixed,\n",
    "     \"\\nFixed scheme MAE: \", mae_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Stack training and test set, this makes updating scheme easier to train\n",
    "all_features = np.concatenate((train_features[-window_length:], test_features), axis=0)\n",
    "all_target = np.concatenate((train_target[-window_length:], test_target), axis=0)\n",
    "\n",
    "# Vectors to store loss and forecasts\n",
    "test_loss = np.zeros(len(test_target))\n",
    "yhat_update = np.zeros(len(test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test period = 1  Training loss = 1.4956  Test loss = 2.2432  Model updated 0 times  \n",
      "\n",
      "Test period = 2  Training loss = 1.5072  Test loss = 1.7752  Model updated 0 times  \n",
      "\n",
      "Test period = 3  Training loss = 1.4154  Test loss = 0.3034  Model updated 0 times  \n",
      "\n",
      "Test period = 4  Training loss = 1.4155  Test loss = 0.3094  Model updated 0 times  \n",
      "\n",
      "Test period = 5  Training loss = 1.3530  Test loss = 0.9162  Model updated 1 times  \n",
      "\n",
      "Test period = 6  Training loss = 1.3199  Test loss = 0.2098  Model updated 1 times  \n",
      "\n",
      "Test period = 7  Training loss = 1.2711  Test loss = 0.0471  Model updated 1 times  \n",
      "\n",
      "Test period = 8  Training loss = 1.2525  Test loss = 0.2203  Model updated 1 times  \n",
      "\n",
      "Test period = 9  Training loss = 1.2094  Test loss = 0.5703  Model updated 2 times  \n",
      "\n",
      "Test period = 10  Training loss = 1.1947  Test loss = 0.4685  Model updated 2 times  \n",
      "\n",
      "Test period = 11  Training loss = 1.1690  Test loss = 0.6346  Model updated 2 times  \n",
      "\n",
      "Test period = 12  Training loss = 1.1683  Test loss = 1.5171  Model updated 2 times  \n",
      "\n",
      "Test period = 13  Training loss = 1.1401  Test loss = 0.6136  Model updated 3 times  \n",
      "\n",
      "Test period = 14  Training loss = 1.1426  Test loss = 1.3460  Model updated 3 times  \n",
      "\n",
      "Test period = 15  Training loss = 1.1544  Test loss = 2.8554  Model updated 3 times  \n",
      "\n",
      "Test period = 16  Training loss = 1.2058  Test loss = 3.6510  Model updated 3 times  \n",
      "\n",
      "Test period = 17  Training loss = 1.2417  Test loss = 1.1688  Model updated 4 times  \n",
      "\n",
      "Test period = 18  Training loss = 1.2460  Test loss = 0.2305  Model updated 4 times  \n",
      "\n",
      "Test period = 19  Training loss = 1.2407  Test loss = 1.1387  Model updated 4 times  \n",
      "\n",
      "Test period = 20  Training loss = 1.1458  Test loss = 0.9155  Model updated 4 times  \n",
      "\n",
      "Test period = 21  Training loss = 1.1047  Test loss = 1.7501  Model updated 5 times  \n",
      "\n",
      "Test period = 22  Training loss = 1.1255  Test loss = 3.7109  Model updated 5 times  \n",
      "\n",
      "Test period = 23  Training loss = 1.2055  Test loss = 0.6819  Model updated 5 times  \n",
      "\n",
      "Test period = 24  Training loss = 1.2002  Test loss = 0.9589  Model updated 5 times  \n",
      "\n",
      "Test period = 25  Training loss = 1.1469  Test loss = 1.4991  Model updated 6 times  \n",
      "\n",
      "Test period = 26  Training loss = 1.1586  Test loss = 0.3168  Model updated 6 times  \n",
      "\n",
      "Test period = 27  Training loss = 1.1588  Test loss = 0.0430  Model updated 6 times  \n",
      "\n",
      "Test period = 28  Training loss = 1.1514  Test loss = 1.9533  Model updated 6 times  \n",
      "\n",
      "Test period = 29  Training loss = 1.1505  Test loss = 0.2208  Model updated 7 times  \n",
      "\n",
      "Test period = 30  Training loss = 1.1454  Test loss = 0.3216  Model updated 7 times  \n",
      "\n",
      "Test period = 31  Training loss = 1.1344  Test loss = 3.9183  Model updated 7 times  \n",
      "\n",
      "Test period = 32  Training loss = 1.2095  Test loss = 1.0972  Model updated 7 times  \n",
      "\n",
      "Test period = 33  Training loss = 1.1602  Test loss = 1.0201  Model updated 8 times  \n",
      "\n",
      "Test period = 34  Training loss = 1.1670  Test loss = 0.4181  Model updated 8 times  \n",
      "\n",
      "Test period = 35  Training loss = 1.1106  Test loss = 0.3975  Model updated 8 times  \n",
      "\n",
      "Test period = 36  Training loss = 1.0987  Test loss = 5.0687  Model updated 8 times  \n",
      "\n",
      "Test period = 37  Training loss = 1.1960  Test loss = 0.8839  Model updated 9 times  \n",
      "\n",
      "Test period = 38  Training loss = 1.1830  Test loss = 1.7266  Model updated 9 times  \n",
      "\n",
      "Test period = 39  Training loss = 1.1926  Test loss = 1.2992  Model updated 9 times  \n",
      "\n",
      "Test period = 40  Training loss = 1.2033  Test loss = 2.0695  Model updated 9 times  \n",
      "\n",
      "Test period = 41  Training loss = 1.1604  Test loss = 1.2262  Model updated 10 times  \n",
      "\n",
      "Test period = 42  Training loss = 1.1689  Test loss = 1.6535  Model updated 10 times  \n",
      "\n",
      "Test period = 43  Training loss = 1.1861  Test loss = 2.6989  Model updated 10 times  \n",
      "\n",
      "Test period = 44  Training loss = 1.2279  Test loss = 12.5618  Model updated 10 times  \n",
      "\n",
      "Test period = 45  Training loss = 1.9839  Test loss = 6.4807  Model updated 11 times  \n",
      "\n",
      "Test period = 46  Training loss = 2.1353  Test loss = 1.2197  Model updated 11 times  \n",
      "\n",
      "Test period = 47  Training loss = 2.1402  Test loss = 0.0197  Model updated 11 times  \n",
      "\n",
      "Test period = 48  Training loss = 2.1387  Test loss = 0.9204  Model updated 11 times  \n",
      "\n",
      "Test period = 49  Training loss = 1.9689  Test loss = 2.0305  Model updated 12 times  \n",
      "\n",
      "Test period = 50  Training loss = 1.9754  Test loss = 3.0531  Model updated 12 times  \n",
      "\n",
      "Test period = 51  Training loss = 2.0113  Test loss = 1.6209  Model updated 12 times  \n",
      "\n",
      "Test period = 52  Training loss = 2.0198  Test loss = 1.2233  Model updated 12 times  \n",
      "\n",
      "Test period = 53  Training loss = 1.9953  Test loss = 2.8029  Model updated 13 times  \n",
      "\n",
      "Test period = 54  Training loss = 2.0253  Test loss = 2.9842  Model updated 13 times  \n",
      "\n",
      "Test period = 55  Training loss = 2.0577  Test loss = 0.2590  Model updated 13 times  \n",
      "\n",
      "Test period = 56  Training loss = 2.0522  Test loss = 0.2337  Model updated 13 times  \n",
      "\n",
      "Test period = 57  Training loss = 2.0297  Test loss = 0.1608  Model updated 14 times  \n",
      "\n",
      "Test period = 58  Training loss = 2.0298  Test loss = 0.8771  Model updated 14 times  \n",
      "\n",
      "Test period = 59  Training loss = 2.0309  Test loss = 0.8271  Model updated 14 times  \n",
      "\n",
      "Test period = 60  Training loss = 2.0268  Test loss = 0.4668  Model updated 14 times  \n",
      "\n",
      "Test period = 61  Training loss = 2.0103  Test loss = 0.3769  Model updated 15 times  \n",
      "\n",
      "Test period = 62  Training loss = 2.0106  Test loss = 2.7322  Model updated 15 times  \n",
      "\n",
      "Test period = 63  Training loss = 2.0355  Test loss = 0.0475  Model updated 15 times  \n",
      "\n",
      "Test period = 64  Training loss = 2.0307  Test loss = 0.2409  Model updated 15 times  \n",
      "\n",
      "Test period = 65  Training loss = 2.0088  Test loss = 0.5562  Model updated 16 times  \n",
      "\n",
      "Test period = 66  Training loss = 2.0082  Test loss = 0.3021  Model updated 16 times  \n",
      "\n",
      "Test period = 67  Training loss = 2.0021  Test loss = 0.3561  Model updated 16 times  \n",
      "\n",
      "Test period = 68  Training loss = 2.0005  Test loss = 2.7694  Model updated 16 times  \n",
      "\n",
      "Test period = 69  Training loss = 2.0109  Test loss = 4.8615  Model updated 17 times  \n",
      "\n",
      "Test period = 70  Training loss = 2.0988  Test loss = 0.7364  Model updated 17 times  \n",
      "\n",
      "Test period = 71  Training loss = 2.1007  Test loss = 1.1280  Model updated 17 times  \n",
      "\n",
      "Test period = 72  Training loss = 2.1013  Test loss = 2.6799  Model updated 17 times  \n",
      "\n",
      "Test period = 73  Training loss = 2.0995  Test loss = 2.6359  Model updated 18 times  \n",
      "\n",
      "Test period = 74  Training loss = 2.1199  Test loss = 1.0031  Model updated 18 times  \n",
      "\n",
      "Test period = 75  Training loss = 2.1204  Test loss = 1.0250  Model updated 18 times  \n",
      "\n",
      "Test period = 76  Training loss = 2.1206  Test loss = 0.5298  Model updated 18 times  \n",
      "\n",
      "Test period = 77  Training loss = 2.0852  Test loss = 1.2900  Model updated 19 times  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "retrain_count = 0\n",
    "for t in range(len(test_target)):\n",
    "    x_test = np.reshape(test_features[t], newshape=(1,4,3))\n",
    "    y_test = test_target[t]\n",
    "    test_loss[t] = np.sqrt(sess.run(loss, feed_dict={x:x_test, y:y_test}))\n",
    "    yhat_update[t] = pred.eval(feed_dict={x:x_test})\n",
    "\n",
    "    x_train = all_features[t:(window_length+t)]\n",
    "    y_train = all_target[t:(window_length+t)]\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:x_test, y:y_test})\n",
    "    \n",
    "    print(\"Test period = {0:d}\".format(t+1),\n",
    "      \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "      \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "      \" Model updated {0:d} times\".format(retrain_count),\n",
    "      \" \\n\")\n",
    "\n",
    "    if (t+1)%4==0:\n",
    "        retrain_count += 1\n",
    "        for epoch in range(epoch_hat):\n",
    "            for i in range(total_batch):\n",
    "                optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nPLE7juPkDE/sjuM4OeM3z6m9MSXqa2YAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x742fb00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: updating scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_update, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating scheme RMSE: 2.35465435976 \n",
      "Updating scheme MAE:  1.52053712208\n"
     ]
    }
   ],
   "source": [
    "rmse_update = np.sqrt(np.mean((yhat_update-test_target)**2))\n",
    "mae_update = np.mean(np.abs((yhat_update-test_target)))\n",
    "print(\"Updating scheme RMSE:\", rmse_update,\n",
    "     \"\\nUpdating scheme MAE: \", mae_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + \"yhat_test_fixed.csv\", yhat_test_fixed)\n",
    "np.savetxt(MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + \"yhat_update.csv\", yhat_update)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
